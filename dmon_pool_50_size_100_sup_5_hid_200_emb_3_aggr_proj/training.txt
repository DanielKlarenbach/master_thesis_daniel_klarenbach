Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 4.625612258911133
Batch 2/64 loss: 4.6468024253845215
Batch 3/64 loss: 4.639519214630127
Batch 4/64 loss: 4.622183799743652
Batch 5/64 loss: 4.607401371002197
Batch 6/64 loss: 4.60217809677124
Batch 7/64 loss: 4.5985107421875
Batch 8/64 loss: 4.589456558227539
Batch 9/64 loss: 4.591964244842529
Batch 10/64 loss: 4.587128639221191
Batch 11/64 loss: 4.584707260131836
Batch 12/64 loss: 4.584821701049805
Batch 13/64 loss: 4.583419322967529
Batch 14/64 loss: 4.580502510070801
Batch 15/64 loss: 4.581950664520264
Batch 16/64 loss: 4.579837322235107
Batch 17/64 loss: 4.578168869018555
Batch 18/64 loss: 4.577158451080322
Batch 19/64 loss: 4.57635498046875
Batch 20/64 loss: 4.577275276184082
Batch 21/64 loss: 4.581535816192627
Batch 22/64 loss: 4.57932710647583
Batch 23/64 loss: 4.5759477615356445
Batch 24/64 loss: 4.5768866539001465
Batch 25/64 loss: 4.576168537139893
Batch 26/64 loss: 4.575994968414307
Batch 27/64 loss: 4.574060440063477
Batch 28/64 loss: 4.573375701904297
Batch 29/64 loss: 4.571677207946777
Batch 30/64 loss: 4.573659420013428
Batch 31/64 loss: 4.571763038635254
Batch 32/64 loss: 4.5705037117004395
Batch 33/64 loss: 4.571693420410156
Batch 34/64 loss: 4.566779136657715
Batch 35/64 loss: 4.5672688484191895
Batch 36/64 loss: 4.565343856811523
Batch 37/64 loss: 4.563155174255371
Batch 38/64 loss: 4.560065269470215
Batch 39/64 loss: 4.558692932128906
Batch 40/64 loss: 4.557245254516602
Batch 41/64 loss: 4.558595657348633
Batch 42/64 loss: 4.557591438293457
Batch 43/64 loss: 4.547618865966797
Batch 44/64 loss: 4.551619052886963
Batch 45/64 loss: 4.5579071044921875
Batch 46/64 loss: 4.552006244659424
Batch 47/64 loss: 4.533377647399902
Batch 48/64 loss: 4.542240142822266
Batch 49/64 loss: 4.533057689666748
Batch 50/64 loss: 4.52347993850708
Batch 51/64 loss: 4.525518417358398
Batch 52/64 loss: 4.5182647705078125
Batch 53/64 loss: 4.510433673858643
Batch 54/64 loss: 4.530317783355713
Batch 55/64 loss: 4.516114234924316
Batch 56/64 loss: 4.4898271560668945
Batch 57/64 loss: 4.497348308563232
Batch 58/64 loss: 4.4856133460998535
Batch 59/64 loss: 4.479820251464844
Batch 60/64 loss: 4.459626197814941
Batch 61/64 loss: 4.815816402435303
Batch 62/64 loss: 4.474218845367432
Batch 63/64 loss: 4.478438854217529
Batch 64/64 loss: 3.615579843521118
Epoch 1  Train loss: 4.553358978383681  Val loss: 4.606139472260098
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 4.493811130523682
Batch 2/64 loss: 4.498882293701172
Batch 3/64 loss: 4.488790512084961
Batch 4/64 loss: 4.492450714111328
Batch 5/64 loss: 4.487736225128174
Batch 6/64 loss: 4.491444110870361
Batch 7/64 loss: 4.471043586730957
Batch 8/64 loss: 4.454526901245117
Batch 9/64 loss: 4.459503173828125
Batch 10/64 loss: 4.449871063232422
Batch 11/64 loss: 4.45781135559082
Batch 12/64 loss: 4.423213481903076
Batch 13/64 loss: 4.390219211578369
Batch 14/64 loss: 4.558685779571533
Batch 15/64 loss: 4.459441184997559
Batch 16/64 loss: 4.446351528167725
Batch 17/64 loss: 4.429396629333496
Batch 18/64 loss: 4.475663661956787
Batch 19/64 loss: 4.431031703948975
Batch 20/64 loss: 4.429470062255859
Batch 21/64 loss: 4.459554672241211
Batch 22/64 loss: 4.45559549331665
Batch 23/64 loss: 4.452711582183838
Batch 24/64 loss: 4.416968822479248
Batch 25/64 loss: 4.414270401000977
Batch 26/64 loss: 4.4088616371154785
Batch 27/64 loss: 4.396299362182617
Batch 28/64 loss: 4.411526679992676
Batch 29/64 loss: 4.372447967529297
Batch 30/64 loss: 4.32797908782959
Batch 31/64 loss: 4.316946029663086
Batch 32/64 loss: 4.3966383934021
Batch 33/64 loss: 4.256145000457764
Batch 34/64 loss: 4.319344520568848
Batch 35/64 loss: 4.34052848815918
Batch 36/64 loss: 4.3181915283203125
Batch 37/64 loss: 4.342486381530762
Batch 38/64 loss: 4.287452220916748
Batch 39/64 loss: 4.265559196472168
Batch 40/64 loss: 4.2589569091796875
Batch 41/64 loss: 4.284257888793945
Batch 42/64 loss: 4.345667839050293
Batch 43/64 loss: 4.321873664855957
Batch 44/64 loss: 4.299525737762451
Batch 45/64 loss: 4.277849197387695
Batch 46/64 loss: 4.211251258850098
Batch 47/64 loss: 4.234306335449219
Batch 48/64 loss: 4.230515003204346
Batch 49/64 loss: 4.189694404602051
Batch 50/64 loss: 4.365615367889404
Batch 51/64 loss: 4.155369281768799
Batch 52/64 loss: 4.206482887268066
Batch 53/64 loss: 4.360556602478027
Batch 54/64 loss: 4.186123371124268
Batch 55/64 loss: 4.193263053894043
Batch 56/64 loss: 4.269197463989258
Batch 57/64 loss: 4.228265762329102
Batch 58/64 loss: 4.165738105773926
Batch 59/64 loss: 4.082883834838867
Batch 60/64 loss: 4.078295707702637
Batch 61/64 loss: 4.080081462860107
Batch 62/64 loss: 4.066682815551758
Batch 63/64 loss: 4.301557540893555
Batch 64/64 loss: 2.903855323791504
Epoch 2  Train loss: 4.326600074768066  Val loss: 4.141055850228903
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 4.124203205108643
Batch 2/64 loss: 4.087827682495117
Batch 3/64 loss: 4.28980016708374
Batch 4/64 loss: 4.151263236999512
Batch 5/64 loss: 4.042730808258057
Batch 6/64 loss: 4.210339069366455
Batch 7/64 loss: 4.064269542694092
Batch 8/64 loss: 4.140392303466797
Batch 9/64 loss: 4.195953369140625
Batch 10/64 loss: 3.9964823722839355
Batch 11/64 loss: 4.045431613922119
Batch 12/64 loss: 4.098101615905762
Batch 13/64 loss: 4.059619903564453
Batch 14/64 loss: 4.010262489318848
Batch 15/64 loss: 3.982412099838257
Batch 16/64 loss: 4.322125434875488
Batch 17/64 loss: 4.040948867797852
Batch 18/64 loss: 3.974977493286133
Batch 19/64 loss: 4.064797401428223
Batch 20/64 loss: 4.071881294250488
Batch 21/64 loss: 4.025119781494141
Batch 22/64 loss: 3.9155635833740234
Batch 23/64 loss: 4.522231578826904
Batch 24/64 loss: 3.9121766090393066
Batch 25/64 loss: 3.92234206199646
Batch 26/64 loss: 4.173008441925049
Batch 27/64 loss: 4.054591178894043
Batch 28/64 loss: 4.035755634307861
Batch 29/64 loss: 4.0416364669799805
Batch 30/64 loss: 4.2675395011901855
Batch 31/64 loss: 4.030780792236328
Batch 32/64 loss: 4.082362174987793
Batch 33/64 loss: 4.0545172691345215
Batch 34/64 loss: 3.903841972351074
Batch 35/64 loss: 3.947937488555908
Batch 36/64 loss: 3.9859986305236816
Batch 37/64 loss: 4.058526992797852
Batch 38/64 loss: 3.951378345489502
Batch 39/64 loss: 3.903642177581787
Batch 40/64 loss: 3.9086754322052
Batch 41/64 loss: 3.9096763134002686
Batch 42/64 loss: 3.8081440925598145
Batch 43/64 loss: 3.727020740509033
Batch 44/64 loss: 4.009454250335693
Batch 45/64 loss: 3.912431240081787
Batch 46/64 loss: 3.8331735134124756
Batch 47/64 loss: 4.1226091384887695
Batch 48/64 loss: 3.7667312622070312
Batch 49/64 loss: 3.8848538398742676
Batch 50/64 loss: 3.9009900093078613
Batch 51/64 loss: 3.9030799865722656
Batch 52/64 loss: 3.812826633453369
Batch 53/64 loss: 3.775686502456665
Batch 54/64 loss: 3.8987507820129395
Batch 55/64 loss: 3.871011257171631
Batch 56/64 loss: 3.837786912918091
Batch 57/64 loss: 3.6827099323272705
Batch 58/64 loss: 4.003239154815674
Batch 59/64 loss: 3.8132567405700684
Batch 60/64 loss: 3.755030632019043
Batch 61/64 loss: 3.878016948699951
Batch 62/64 loss: 3.707139730453491
Batch 63/64 loss: 3.680840492248535
Batch 64/64 loss: 2.211691379547119
Epoch 3  Train loss: 3.9658772505965887  Val loss: 4.591598582841277
Epoch 4
-------------------------------
Batch 1/64 loss: 3.5945725440979004
Batch 2/64 loss: 3.795031785964966
Batch 3/64 loss: 3.629772186279297
Batch 4/64 loss: 4.068328857421875
Batch 5/64 loss: 3.6695477962493896
Batch 6/64 loss: 3.6406283378601074
Batch 7/64 loss: 3.4331753253936768
Batch 8/64 loss: 3.535097122192383
Batch 9/64 loss: 3.663133144378662
Batch 10/64 loss: 3.559648036956787
Batch 11/64 loss: 3.4356043338775635
Batch 12/64 loss: 3.526613712310791
Batch 13/64 loss: 3.5995969772338867
Batch 14/64 loss: 3.386897087097168
Batch 15/64 loss: 3.298542022705078
Batch 16/64 loss: 3.5437862873077393
Batch 17/64 loss: 3.5518722534179688
Batch 18/64 loss: 3.457097053527832
Batch 19/64 loss: 3.587425470352173
Batch 20/64 loss: 3.4972245693206787
Batch 21/64 loss: 3.4740841388702393
Batch 22/64 loss: 3.53790545463562
Batch 23/64 loss: 3.73416805267334
Batch 24/64 loss: 3.4135217666625977
Batch 25/64 loss: 3.44914174079895
Batch 26/64 loss: 3.4499824047088623
Batch 27/64 loss: 3.441356897354126
Batch 28/64 loss: 3.5070438385009766
Batch 29/64 loss: 3.306960105895996
Batch 30/64 loss: 3.335259199142456
Batch 31/64 loss: 3.492664098739624
Batch 32/64 loss: 3.2531001567840576
Batch 33/64 loss: 3.608177423477173
Batch 34/64 loss: 3.4734225273132324
Batch 35/64 loss: 3.423929214477539
Batch 36/64 loss: 3.401118755340576
Batch 37/64 loss: 3.328733205795288
Batch 38/64 loss: 3.325139045715332
Batch 39/64 loss: 3.3262226581573486
Batch 40/64 loss: 3.3534584045410156
Batch 41/64 loss: 3.3897972106933594
Batch 42/64 loss: 3.3285961151123047
Batch 43/64 loss: 3.5716874599456787
Batch 44/64 loss: 3.2258400917053223
Batch 45/64 loss: 3.215555429458618
Batch 46/64 loss: 3.506575584411621
Batch 47/64 loss: 3.394812822341919
Batch 48/64 loss: 3.313647747039795
Batch 49/64 loss: 3.3013641834259033
Batch 50/64 loss: 3.6888108253479004
Batch 51/64 loss: 3.2414791584014893
Batch 52/64 loss: 3.4073216915130615
Batch 53/64 loss: 3.28377366065979
Batch 54/64 loss: 3.2739171981811523
Batch 55/64 loss: 3.5428380966186523
Batch 56/64 loss: 3.235623836517334
Batch 57/64 loss: 3.200106620788574
Batch 58/64 loss: 3.1965372562408447
Batch 59/64 loss: 3.4457664489746094
Batch 60/64 loss: 3.5550312995910645
Batch 61/64 loss: 3.152613878250122
Batch 62/64 loss: 3.194377899169922
Batch 63/64 loss: 3.282902956008911
Batch 64/64 loss: 1.274017095565796
Epoch 4  Train loss: 3.4198192044800404  Val loss: 3.5554723051405444
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 3.2145638465881348
Batch 2/64 loss: 3.1702306270599365
Batch 3/64 loss: 3.0970678329467773
Batch 4/64 loss: 3.4203362464904785
Batch 5/64 loss: 3.216493606567383
Batch 6/64 loss: 2.9981040954589844
Batch 7/64 loss: 2.9500174522399902
Batch 8/64 loss: 3.111283540725708
Batch 9/64 loss: 3.2574498653411865
Batch 10/64 loss: 3.058967351913452
Batch 11/64 loss: 3.040036678314209
Batch 12/64 loss: 3.176239252090454
Batch 13/64 loss: 3.16989803314209
Batch 14/64 loss: 3.105191469192505
Batch 15/64 loss: 2.9976308345794678
Batch 16/64 loss: 2.9704017639160156
Batch 17/64 loss: 3.094987630844116
Batch 18/64 loss: 2.8819949626922607
Batch 19/64 loss: 2.8589107990264893
Batch 20/64 loss: 2.9398365020751953
Batch 21/64 loss: 2.8114802837371826
Batch 22/64 loss: 3.0191650390625
Batch 23/64 loss: 3.0281970500946045
Batch 24/64 loss: 2.8711187839508057
Batch 25/64 loss: 2.9604744911193848
Batch 26/64 loss: 2.8456268310546875
Batch 27/64 loss: 2.871955394744873
Batch 28/64 loss: 3.100550651550293
Batch 29/64 loss: 3.1598682403564453
Batch 30/64 loss: 2.809981107711792
Batch 31/64 loss: 3.1229727268218994
Batch 32/64 loss: 3.0526459217071533
Batch 33/64 loss: 3.2794792652130127
Batch 34/64 loss: 3.0156309604644775
Batch 35/64 loss: 3.0469207763671875
Batch 36/64 loss: 3.017390012741089
Batch 37/64 loss: 2.9091615676879883
Batch 38/64 loss: 2.9868552684783936
Batch 39/64 loss: 2.8968734741210938
Batch 40/64 loss: 2.872304677963257
Batch 41/64 loss: 2.689513683319092
Batch 42/64 loss: 3.001570224761963
Batch 43/64 loss: 3.2992820739746094
Batch 44/64 loss: 3.0657050609588623
Batch 45/64 loss: 3.069182872772217
Batch 46/64 loss: 2.875702142715454
Batch 47/64 loss: 3.041015148162842
Batch 48/64 loss: 2.9739224910736084
Batch 49/64 loss: 2.679262399673462
Batch 50/64 loss: 3.159512758255005
Batch 51/64 loss: 2.7455880641937256
Batch 52/64 loss: 2.9147098064422607
Batch 53/64 loss: 2.816119432449341
Batch 54/64 loss: 2.893683671951294
Batch 55/64 loss: 2.9165232181549072
Batch 56/64 loss: 2.744307279586792
Batch 57/64 loss: 2.7196056842803955
Batch 58/64 loss: 2.759075880050659
Batch 59/64 loss: 2.752603054046631
Batch 60/64 loss: 3.0391294956207275
Batch 61/64 loss: 2.6859679222106934
Batch 62/64 loss: 2.825795888900757
Batch 63/64 loss: 2.9296562671661377
Batch 64/64 loss: 0.6219878196716309
Epoch 5  Train loss: 2.9564269851235783  Val loss: 2.992534499807456
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 3.034548282623291
Batch 2/64 loss: 3.1616392135620117
Batch 3/64 loss: 2.8277626037597656
Batch 4/64 loss: 2.8870439529418945
Batch 5/64 loss: 3.2648677825927734
Batch 6/64 loss: 2.914839744567871
Batch 7/64 loss: 2.6615729331970215
Batch 8/64 loss: 2.8559722900390625
Batch 9/64 loss: 3.0255422592163086
Batch 10/64 loss: 2.6596174240112305
Batch 11/64 loss: 3.051632881164551
Batch 12/64 loss: 2.88832950592041
Batch 13/64 loss: 2.668785333633423
Batch 14/64 loss: 2.667664051055908
Batch 15/64 loss: 2.785611152648926
Batch 16/64 loss: 2.645467758178711
Batch 17/64 loss: 2.8201241493225098
Batch 18/64 loss: 2.8298075199127197
Batch 19/64 loss: 2.9403183460235596
Batch 20/64 loss: 2.7186522483825684
Batch 21/64 loss: 2.545579671859741
Batch 22/64 loss: 2.4405930042266846
Batch 23/64 loss: 2.642155885696411
Batch 24/64 loss: 2.8706655502319336
Batch 25/64 loss: 2.5426437854766846
Batch 26/64 loss: 2.5617220401763916
Batch 27/64 loss: 2.4961795806884766
Batch 28/64 loss: 2.7196154594421387
Batch 29/64 loss: 2.5945894718170166
Batch 30/64 loss: 2.6602632999420166
Batch 31/64 loss: 2.8922266960144043
Batch 32/64 loss: 2.2723865509033203
Batch 33/64 loss: 2.563495635986328
Batch 34/64 loss: 2.334752082824707
Batch 35/64 loss: 2.42417049407959
Batch 36/64 loss: 2.241551399230957
Batch 37/64 loss: 2.376556873321533
Batch 38/64 loss: 2.4559311866760254
Batch 39/64 loss: 2.5130019187927246
Batch 40/64 loss: 2.3920440673828125
Batch 41/64 loss: 2.4660286903381348
Batch 42/64 loss: 2.87332820892334
Batch 43/64 loss: 2.498338222503662
Batch 44/64 loss: 2.476742744445801
Batch 45/64 loss: 2.507202625274658
Batch 46/64 loss: 2.4130711555480957
Batch 47/64 loss: 2.558371067047119
Batch 48/64 loss: 2.4467954635620117
Batch 49/64 loss: 2.5209827423095703
Batch 50/64 loss: 2.438716411590576
Batch 51/64 loss: 2.364109516143799
Batch 52/64 loss: 2.1457901000976562
Batch 53/64 loss: 2.6141934394836426
Batch 54/64 loss: 2.29856014251709
Batch 55/64 loss: 2.36405086517334
Batch 56/64 loss: 2.5045166015625
Batch 57/64 loss: 2.287125587463379
Batch 58/64 loss: 2.6408071517944336
Batch 59/64 loss: 2.2955923080444336
Batch 60/64 loss: 2.106106758117676
Batch 61/64 loss: 2.663483142852783
Batch 62/64 loss: 2.2780823707580566
Batch 63/64 loss: 2.4553332328796387
Batch 64/64 loss: -0.4564809799194336
Epoch 6  Train loss: 2.5682335984473137  Val loss: 2.311995044197004
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 2.154083728790283
Batch 2/64 loss: 2.3771705627441406
Batch 3/64 loss: 2.1492133140563965
Batch 4/64 loss: 2.04567289352417
Batch 5/64 loss: 2.3612918853759766
Batch 6/64 loss: 2.219237804412842
Batch 7/64 loss: 2.0287609100341797
Batch 8/64 loss: 2.2355775833129883
Batch 9/64 loss: 2.033989429473877
Batch 10/64 loss: 1.9582066535949707
Batch 11/64 loss: 2.304502487182617
Batch 12/64 loss: 2.1428275108337402
Batch 13/64 loss: 2.328824520111084
Batch 14/64 loss: 2.4909567832946777
Batch 15/64 loss: 2.2650718688964844
Batch 16/64 loss: 1.9374494552612305
Batch 17/64 loss: 1.955796241760254
Batch 18/64 loss: 1.7708854675292969
Batch 19/64 loss: 1.9778270721435547
Batch 20/64 loss: 2.179481029510498
Batch 21/64 loss: 2.5520577430725098
Batch 22/64 loss: 2.431084632873535
Batch 23/64 loss: 2.0599584579467773
Batch 24/64 loss: 1.9357070922851562
Batch 25/64 loss: 2.097137928009033
Batch 26/64 loss: 2.146113395690918
Batch 27/64 loss: 2.106266498565674
Batch 28/64 loss: 1.8268346786499023
Batch 29/64 loss: 1.9758667945861816
Batch 30/64 loss: 1.7240819931030273
Batch 31/64 loss: 2.0511112213134766
Batch 32/64 loss: 1.9900145530700684
Batch 33/64 loss: 1.9676876068115234
Batch 34/64 loss: 2.2648439407348633
Batch 35/64 loss: 1.8984379768371582
Batch 36/64 loss: 1.7483038902282715
Batch 37/64 loss: 1.7716622352600098
Batch 38/64 loss: 1.7883853912353516
Batch 39/64 loss: 2.0412964820861816
Batch 40/64 loss: 1.9913558959960938
Batch 41/64 loss: 1.5503206253051758
Batch 42/64 loss: 1.8606953620910645
Batch 43/64 loss: 1.778975486755371
Batch 44/64 loss: 2.1032328605651855
Batch 45/64 loss: 2.0323715209960938
Batch 46/64 loss: 1.8221206665039062
Batch 47/64 loss: 1.9126710891723633
Batch 48/64 loss: 1.8636465072631836
Batch 49/64 loss: 2.1775379180908203
Batch 50/64 loss: 1.8519229888916016
Batch 51/64 loss: 1.8867816925048828
Batch 52/64 loss: 1.87819242477417
Batch 53/64 loss: 1.9883694648742676
Batch 54/64 loss: 1.9875221252441406
Batch 55/64 loss: 1.699082374572754
Batch 56/64 loss: 2.044656753540039
Batch 57/64 loss: 1.8115267753601074
Batch 58/64 loss: 1.7302899360656738
Batch 59/64 loss: 1.9368433952331543
Batch 60/64 loss: 1.7261972427368164
Batch 61/64 loss: 1.8758907318115234
Batch 62/64 loss: 2.11539363861084
Batch 63/64 loss: 1.8687000274658203
Batch 64/64 loss: -0.7585968971252441
Epoch 7  Train loss: 1.9799063458162196  Val loss: 1.9228389123870744
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 1.8256115913391113
Batch 2/64 loss: 1.866269588470459
Batch 3/64 loss: 1.7481951713562012
Batch 4/64 loss: 2.024796485900879
Batch 5/64 loss: 1.5601005554199219
Batch 6/64 loss: 1.3765130043029785
Batch 7/64 loss: 1.513720989227295
Batch 8/64 loss: 1.6743369102478027
Batch 9/64 loss: 1.8218183517456055
Batch 10/64 loss: 1.6771841049194336
Batch 11/64 loss: 1.7800869941711426
Batch 12/64 loss: 1.8441863059997559
Batch 13/64 loss: 1.415529727935791
Batch 14/64 loss: 1.7786927223205566
Batch 15/64 loss: 1.4867243766784668
Batch 16/64 loss: 1.562781810760498
Batch 17/64 loss: 1.8328814506530762
Batch 18/64 loss: 1.5019326210021973
Batch 19/64 loss: 1.9485454559326172
Batch 20/64 loss: 1.5677261352539062
Batch 21/64 loss: 1.5003061294555664
Batch 22/64 loss: 1.28001070022583
Batch 23/64 loss: 1.7565078735351562
Batch 24/64 loss: 1.400047779083252
Batch 25/64 loss: 1.5773439407348633
Batch 26/64 loss: 1.4221057891845703
Batch 27/64 loss: 1.591796875
Batch 28/64 loss: 1.4538617134094238
Batch 29/64 loss: 1.4097495079040527
Batch 30/64 loss: 1.2844276428222656
Batch 31/64 loss: 1.489130973815918
Batch 32/64 loss: 1.5553364753723145
Batch 33/64 loss: 1.6166205406188965
Batch 34/64 loss: 1.324608325958252
Batch 35/64 loss: 1.3900175094604492
Batch 36/64 loss: 1.2289199829101562
Batch 37/64 loss: 1.0788393020629883
Batch 38/64 loss: 1.4984722137451172
Batch 39/64 loss: 1.3547024726867676
Batch 40/64 loss: 1.314694881439209
Batch 41/64 loss: 1.488907814025879
Batch 42/64 loss: 1.3493800163269043
Batch 43/64 loss: 1.0767230987548828
Batch 44/64 loss: 1.3008694648742676
Batch 45/64 loss: 0.9594464302062988
Batch 46/64 loss: 1.5002918243408203
Batch 47/64 loss: 1.0739479064941406
Batch 48/64 loss: 1.437328815460205
Batch 49/64 loss: 1.5628252029418945
Batch 50/64 loss: 1.5627994537353516
Batch 51/64 loss: 1.1198053359985352
Batch 52/64 loss: 1.5502338409423828
Batch 53/64 loss: 1.4082651138305664
Batch 54/64 loss: 1.8284001350402832
Batch 55/64 loss: 1.5956101417541504
Batch 56/64 loss: 1.4846596717834473
Batch 57/64 loss: 1.4202818870544434
Batch 58/64 loss: 1.3378386497497559
Batch 59/64 loss: 1.2728452682495117
Batch 60/64 loss: 1.7342910766601562
Batch 61/64 loss: 0.9926209449768066
Batch 62/64 loss: 1.4103937149047852
Batch 63/64 loss: 1.0042757987976074
Batch 64/64 loss: -1.9493656158447266
Epoch 8  Train loss: 1.448551409852271  Val loss: 1.7797139223498577
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 1.1754584312438965
Batch 2/64 loss: 1.041299819946289
Batch 3/64 loss: 0.9718141555786133
Batch 4/64 loss: 1.2854290008544922
Batch 5/64 loss: 1.54410982131958
Batch 6/64 loss: 1.000619888305664
Batch 7/64 loss: 1.6641912460327148
Batch 8/64 loss: 0.8585052490234375
Batch 9/64 loss: 1.33528470993042
Batch 10/64 loss: 1.2732892036437988
Batch 11/64 loss: 1.3651189804077148
Batch 12/64 loss: 1.195906162261963
Batch 13/64 loss: 1.0336799621582031
Batch 14/64 loss: 1.3441963195800781
Batch 15/64 loss: 0.8855066299438477
Batch 16/64 loss: 1.3488245010375977
Batch 17/64 loss: 0.7095279693603516
Batch 18/64 loss: 1.1306228637695312
Batch 19/64 loss: 0.9909791946411133
Batch 20/64 loss: 1.4708123207092285
Batch 21/64 loss: 1.0843195915222168
Batch 22/64 loss: 1.3993101119995117
Batch 23/64 loss: 1.0665154457092285
Batch 24/64 loss: 0.8577356338500977
Batch 25/64 loss: 1.2264461517333984
Batch 26/64 loss: 1.5996356010437012
Batch 27/64 loss: 1.4392833709716797
Batch 28/64 loss: 1.1023602485656738
Batch 29/64 loss: 1.2055110931396484
Batch 30/64 loss: 1.0478153228759766
Batch 31/64 loss: 1.0627942085266113
Batch 32/64 loss: 1.3311753273010254
Batch 33/64 loss: 1.0095553398132324
Batch 34/64 loss: 0.9708414077758789
Batch 35/64 loss: 0.6689066886901855
Batch 36/64 loss: 1.1652112007141113
Batch 37/64 loss: 1.051079273223877
Batch 38/64 loss: 0.9566373825073242
Batch 39/64 loss: 0.9086470603942871
Batch 40/64 loss: 1.0418248176574707
Batch 41/64 loss: 0.9153499603271484
Batch 42/64 loss: 0.8042011260986328
Batch 43/64 loss: 1.0194406509399414
Batch 44/64 loss: 1.1326937675476074
Batch 45/64 loss: 0.894320011138916
Batch 46/64 loss: 0.8362655639648438
Batch 47/64 loss: 1.2643489837646484
Batch 48/64 loss: 1.2465567588806152
Batch 49/64 loss: 1.0057330131530762
Batch 50/64 loss: 1.1716642379760742
Batch 51/64 loss: 1.369511604309082
Batch 52/64 loss: 0.8288464546203613
Batch 53/64 loss: 1.0997371673583984
Batch 54/64 loss: 0.963864803314209
Batch 55/64 loss: 1.1798810958862305
Batch 56/64 loss: 1.0431785583496094
Batch 57/64 loss: 0.660430908203125
Batch 58/64 loss: 0.7441058158874512
Batch 59/64 loss: 1.2070727348327637
Batch 60/64 loss: 0.7073745727539062
Batch 61/64 loss: 1.2163877487182617
Batch 62/64 loss: 0.8490781784057617
Batch 63/64 loss: 0.9394063949584961
Batch 64/64 loss: -2.1140193939208984
Epoch 9  Train loss: 1.0562308591954848  Val loss: 1.204348691959971
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: 1.0283284187316895
Batch 2/64 loss: 1.179697036743164
Batch 3/64 loss: 1.5725908279418945
Batch 4/64 loss: 0.8926382064819336
Batch 5/64 loss: 1.121042251586914
Batch 6/64 loss: 1.1110115051269531
Batch 7/64 loss: 0.8438959121704102
Batch 8/64 loss: 0.753049373626709
Batch 9/64 loss: 0.8020820617675781
Batch 10/64 loss: 1.1929636001586914
Batch 11/64 loss: 0.7474331855773926
Batch 12/64 loss: 1.3882393836975098
Batch 13/64 loss: 0.7624621391296387
Batch 14/64 loss: 0.9769654273986816
Batch 15/64 loss: 1.3449797630310059
Batch 16/64 loss: 1.2712664604187012
Batch 17/64 loss: 1.1521296501159668
Batch 18/64 loss: 0.7264962196350098
Batch 19/64 loss: 0.6494002342224121
Batch 20/64 loss: 0.9180831909179688
Batch 21/64 loss: 0.8623838424682617
Batch 22/64 loss: 0.44597625732421875
Batch 23/64 loss: 0.9348316192626953
Batch 24/64 loss: 0.5326781272888184
Batch 25/64 loss: 0.6870169639587402
Batch 26/64 loss: 0.6961994171142578
Batch 27/64 loss: 0.9782896041870117
Batch 28/64 loss: 0.6594295501708984
Batch 29/64 loss: 1.0678472518920898
Batch 30/64 loss: 0.21088457107543945
Batch 31/64 loss: 0.48627138137817383
Batch 32/64 loss: 1.3807644844055176
Batch 33/64 loss: 0.7895650863647461
Batch 34/64 loss: 0.9117445945739746
Batch 35/64 loss: 0.7530951499938965
Batch 36/64 loss: 0.8645730018615723
Batch 37/64 loss: 1.0890350341796875
Batch 38/64 loss: 0.6322770118713379
Batch 39/64 loss: 0.9108099937438965
Batch 40/64 loss: 0.7257771492004395
Batch 41/64 loss: 0.6007089614868164
Batch 42/64 loss: 0.7373814582824707
Batch 43/64 loss: 0.7361540794372559
Batch 44/64 loss: 0.9298582077026367
Batch 45/64 loss: 0.9655194282531738
Batch 46/64 loss: 0.6145944595336914
Batch 47/64 loss: 0.7752976417541504
Batch 48/64 loss: 0.8880853652954102
Batch 49/64 loss: 0.7791843414306641
Batch 50/64 loss: 0.8921093940734863
Batch 51/64 loss: 0.6204538345336914
Batch 52/64 loss: 0.7811799049377441
Batch 53/64 loss: 0.4708266258239746
Batch 54/64 loss: 0.7956480979919434
Batch 55/64 loss: 1.1464838981628418
Batch 56/64 loss: 0.6001052856445312
Batch 57/64 loss: 0.2658662796020508
Batch 58/64 loss: 0.5586881637573242
Batch 59/64 loss: 0.9280219078063965
Batch 60/64 loss: 1.0541973114013672
Batch 61/64 loss: 1.1678805351257324
Batch 62/64 loss: 0.561582088470459
Batch 63/64 loss: 1.1644916534423828
Batch 64/64 loss: -2.590517520904541
Epoch 10  Train loss: 0.8179707564559637  Val loss: 0.5595381038705098
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: 0.5354290008544922
Batch 2/64 loss: 0.7228221893310547
Batch 3/64 loss: 0.6601524353027344
Batch 4/64 loss: 0.6522068977355957
Batch 5/64 loss: 0.5038046836853027
Batch 6/64 loss: 0.46808719635009766
Batch 7/64 loss: 0.6945886611938477
Batch 8/64 loss: 0.5032463073730469
Batch 9/64 loss: 0.8677730560302734
Batch 10/64 loss: 0.6465859413146973
Batch 11/64 loss: 0.44419193267822266
Batch 12/64 loss: 0.6042656898498535
Batch 13/64 loss: 1.4572272300720215
Batch 14/64 loss: 0.4396810531616211
Batch 15/64 loss: 0.8460760116577148
Batch 16/64 loss: 0.5735974311828613
Batch 17/64 loss: 0.30623626708984375
Batch 18/64 loss: 0.8095321655273438
Batch 19/64 loss: 0.6851925849914551
Batch 20/64 loss: 0.3012967109680176
Batch 21/64 loss: 0.7407240867614746
Batch 22/64 loss: 0.6720972061157227
Batch 23/64 loss: 0.9458169937133789
Batch 24/64 loss: 0.36781978607177734
Batch 25/64 loss: 1.118821620941162
Batch 26/64 loss: 0.5457663536071777
Batch 27/64 loss: 1.0599679946899414
Batch 28/64 loss: 0.7778282165527344
Batch 29/64 loss: 0.7441835403442383
Batch 30/64 loss: 1.052011489868164
Batch 31/64 loss: 0.6753416061401367
Batch 32/64 loss: 0.591792106628418
Batch 33/64 loss: 0.799705982208252
Batch 34/64 loss: 0.5223097801208496
Batch 35/64 loss: 0.712122917175293
Batch 36/64 loss: 0.6212582588195801
Batch 37/64 loss: 1.6343154907226562
Batch 38/64 loss: 0.8516864776611328
Batch 39/64 loss: 0.9064793586730957
Batch 40/64 loss: 0.5037961006164551
Batch 41/64 loss: 0.7314538955688477
Batch 42/64 loss: 0.8221273422241211
Batch 43/64 loss: 0.2942171096801758
Batch 44/64 loss: 0.47042036056518555
Batch 45/64 loss: 0.23671674728393555
Batch 46/64 loss: 0.7333064079284668
Batch 47/64 loss: 1.080256462097168
Batch 48/64 loss: 0.5213789939880371
Batch 49/64 loss: 0.6821284294128418
Batch 50/64 loss: 0.7591447830200195
Batch 51/64 loss: 0.4012455940246582
Batch 52/64 loss: 1.1187705993652344
Batch 53/64 loss: 0.5278811454772949
Batch 54/64 loss: 0.36243343353271484
Batch 55/64 loss: 0.40087890625
Batch 56/64 loss: 0.7598443031311035
Batch 57/64 loss: 0.6855850219726562
Batch 58/64 loss: 0.6383638381958008
Batch 59/64 loss: 0.47214460372924805
Batch 60/64 loss: 0.2540550231933594
Batch 61/64 loss: 0.35309648513793945
Batch 62/64 loss: 0.6034636497497559
Batch 63/64 loss: 0.3779163360595703
Batch 64/64 loss: -3.031540870666504
Epoch 11  Train loss: 0.6208472569783529  Val loss: 0.35448092693315747
Saving best model, epoch: 11
Epoch 12
-------------------------------
Batch 1/64 loss: 0.3652806282043457
Batch 2/64 loss: 0.346710205078125
Batch 3/64 loss: 0.662785530090332
Batch 4/64 loss: 0.15204477310180664
Batch 5/64 loss: 0.45067358016967773
Batch 6/64 loss: 0.39422607421875
Batch 7/64 loss: 0.5795416831970215
Batch 8/64 loss: 0.32004308700561523
Batch 9/64 loss: 0.03086090087890625
Batch 10/64 loss: 0.7158265113830566
Batch 11/64 loss: 0.5579514503479004
Batch 12/64 loss: 0.8942737579345703
Batch 13/64 loss: 0.7149291038513184
Batch 14/64 loss: 0.5395197868347168
Batch 15/64 loss: 0.1813364028930664
Batch 16/64 loss: 0.4369640350341797
Batch 17/64 loss: 0.474611759185791
Batch 18/64 loss: 0.8608264923095703
Batch 19/64 loss: 0.5666904449462891
Batch 20/64 loss: 0.22069263458251953
Batch 21/64 loss: 0.8192896842956543
Batch 22/64 loss: 0.37471723556518555
Batch 23/64 loss: 0.04607820510864258
Batch 24/64 loss: 0.36320972442626953
Batch 25/64 loss: 0.53533935546875
Batch 26/64 loss: 0.13416385650634766
Batch 27/64 loss: 0.2453608512878418
Batch 28/64 loss: 0.556027889251709
Batch 29/64 loss: 0.4973001480102539
Batch 30/64 loss: 0.44565725326538086
Batch 31/64 loss: 0.7363533973693848
Batch 32/64 loss: 0.41594696044921875
Batch 33/64 loss: 0.20743036270141602
Batch 34/64 loss: 0.5960044860839844
Batch 35/64 loss: 0.48096275329589844
Batch 36/64 loss: 0.0015974044799804688
Batch 37/64 loss: 0.5577073097229004
Batch 38/64 loss: 0.43825769424438477
Batch 39/64 loss: 0.2345423698425293
Batch 40/64 loss: 0.5895261764526367
Batch 41/64 loss: 1.4245071411132812
Batch 42/64 loss: 0.25713062286376953
Batch 43/64 loss: 0.44051456451416016
Batch 44/64 loss: 0.3130984306335449
Batch 45/64 loss: 0.07500410079956055
Batch 46/64 loss: 0.35898351669311523
Batch 47/64 loss: 0.623131275177002
Batch 48/64 loss: 0.7272782325744629
Batch 49/64 loss: 0.5028352737426758
Batch 50/64 loss: 0.19116926193237305
Batch 51/64 loss: 0.47587013244628906
Batch 52/64 loss: 0.4708442687988281
Batch 53/64 loss: 0.22393226623535156
Batch 54/64 loss: 0.26545095443725586
Batch 55/64 loss: 0.35657405853271484
Batch 56/64 loss: 1.1760945320129395
Batch 57/64 loss: 0.19200754165649414
Batch 58/64 loss: 0.3115081787109375
Batch 59/64 loss: 0.8022146224975586
Batch 60/64 loss: 0.6294713020324707
Batch 61/64 loss: 0.4618411064147949
Batch 62/64 loss: 1.034684181213379
Batch 63/64 loss: 0.7028408050537109
Batch 64/64 loss: -2.8784732818603516
Epoch 12  Train loss: 0.43293166067086014  Val loss: 0.5608666803418976
Epoch 13
-------------------------------
Batch 1/64 loss: 0.3699359893798828
Batch 2/64 loss: 0.7855682373046875
Batch 3/64 loss: 0.575469970703125
Batch 4/64 loss: 0.8465204238891602
Batch 5/64 loss: 1.0271215438842773
Batch 6/64 loss: 0.781984806060791
Batch 7/64 loss: 0.4071173667907715
Batch 8/64 loss: 0.15276479721069336
Batch 9/64 loss: 0.45899534225463867
Batch 10/64 loss: 0.31238508224487305
Batch 11/64 loss: 0.842522144317627
Batch 12/64 loss: 0.4303131103515625
Batch 13/64 loss: 0.3910088539123535
Batch 14/64 loss: 0.24576139450073242
Batch 15/64 loss: 0.16867303848266602
Batch 16/64 loss: 0.38976526260375977
Batch 17/64 loss: 0.4360966682434082
Batch 18/64 loss: 0.32766246795654297
Batch 19/64 loss: 0.6708946228027344
Batch 20/64 loss: 0.13799238204956055
Batch 21/64 loss: 0.37457799911499023
Batch 22/64 loss: 0.38968896865844727
Batch 23/64 loss: 0.10985088348388672
Batch 24/64 loss: 0.4550318717956543
Batch 25/64 loss: 0.415006160736084
Batch 26/64 loss: -0.0250091552734375
Batch 27/64 loss: 0.18652963638305664
Batch 28/64 loss: 0.13065242767333984
Batch 29/64 loss: 0.6908392906188965
Batch 30/64 loss: 0.2510194778442383
Batch 31/64 loss: 0.23154830932617188
Batch 32/64 loss: 0.44927024841308594
Batch 33/64 loss: 0.2668795585632324
Batch 34/64 loss: 0.37625932693481445
Batch 35/64 loss: 0.4407072067260742
Batch 36/64 loss: 0.8907260894775391
Batch 37/64 loss: 0.02775430679321289
Batch 38/64 loss: 0.5649428367614746
Batch 39/64 loss: 0.8906850814819336
Batch 40/64 loss: 0.6651606559753418
Batch 41/64 loss: 0.903017520904541
Batch 42/64 loss: 0.6075258255004883
Batch 43/64 loss: 0.4391622543334961
Batch 44/64 loss: 0.711850643157959
Batch 45/64 loss: 0.2801051139831543
Batch 46/64 loss: 0.3808574676513672
Batch 47/64 loss: 1.329455852508545
Batch 48/64 loss: 0.3433876037597656
Batch 49/64 loss: 0.37255001068115234
Batch 50/64 loss: 0.8927273750305176
Batch 51/64 loss: 0.4045991897583008
Batch 52/64 loss: 0.5574579238891602
Batch 53/64 loss: 0.4538846015930176
Batch 54/64 loss: 1.308481216430664
Batch 55/64 loss: 0.47454404830932617
Batch 56/64 loss: 0.9413022994995117
Batch 57/64 loss: 0.6657567024230957
Batch 58/64 loss: 0.40706872940063477
Batch 59/64 loss: 0.2481708526611328
Batch 60/64 loss: 0.39825916290283203
Batch 61/64 loss: 0.3078937530517578
Batch 62/64 loss: 0.5576076507568359
Batch 63/64 loss: 0.9691705703735352
Batch 64/64 loss: -3.504704475402832
Epoch 13  Train loss: 0.4528154148774989  Val loss: 0.35500355356747343
Epoch 14
-------------------------------
Batch 1/64 loss: 0.3698291778564453
Batch 2/64 loss: 0.38767385482788086
Batch 3/64 loss: 0.7788352966308594
Batch 4/64 loss: 0.8319950103759766
Batch 5/64 loss: 0.1839919090270996
Batch 6/64 loss: 0.6632833480834961
Batch 7/64 loss: 0.43685245513916016
Batch 8/64 loss: 0.36528778076171875
Batch 9/64 loss: 0.2678184509277344
Batch 10/64 loss: 0.15624666213989258
Batch 11/64 loss: -0.15599346160888672
Batch 12/64 loss: 0.17176008224487305
Batch 13/64 loss: 0.21956253051757812
Batch 14/64 loss: 0.9268488883972168
Batch 15/64 loss: 0.11181974411010742
Batch 16/64 loss: 0.6209926605224609
Batch 17/64 loss: 0.5687522888183594
Batch 18/64 loss: 0.49130725860595703
Batch 19/64 loss: 0.5615429878234863
Batch 20/64 loss: 0.7842526435852051
Batch 21/64 loss: 0.30518531799316406
Batch 22/64 loss: 0.4977593421936035
Batch 23/64 loss: 0.844268798828125
Batch 24/64 loss: 0.5499205589294434
Batch 25/64 loss: 0.41070556640625
Batch 26/64 loss: 0.2795424461364746
Batch 27/64 loss: 0.36952877044677734
Batch 28/64 loss: 0.22587871551513672
Batch 29/64 loss: 0.2584562301635742
Batch 30/64 loss: 0.6512742042541504
Batch 31/64 loss: 0.3625640869140625
Batch 32/64 loss: 0.316650390625
Batch 33/64 loss: 0.9074420928955078
Batch 34/64 loss: 0.40708303451538086
Batch 35/64 loss: -0.13828229904174805
Batch 36/64 loss: 0.4060211181640625
Batch 37/64 loss: 0.0863032341003418
Batch 38/64 loss: 0.25804901123046875
Batch 39/64 loss: 0.34592771530151367
Batch 40/64 loss: 0.1599106788635254
Batch 41/64 loss: 0.5934886932373047
Batch 42/64 loss: 0.4879937171936035
Batch 43/64 loss: 0.39829444885253906
Batch 44/64 loss: 0.42293882369995117
Batch 45/64 loss: 0.9364719390869141
Batch 46/64 loss: 0.10108757019042969
Batch 47/64 loss: 0.07846927642822266
Batch 48/64 loss: 0.3308854103088379
Batch 49/64 loss: 0.49364280700683594
Batch 50/64 loss: 0.2432546615600586
Batch 51/64 loss: -0.029446125030517578
Batch 52/64 loss: 0.6685080528259277
Batch 53/64 loss: 0.414945125579834
Batch 54/64 loss: 0.20485353469848633
Batch 55/64 loss: 0.11745262145996094
Batch 56/64 loss: 0.15717363357543945
Batch 57/64 loss: 0.08803176879882812
Batch 58/64 loss: 0.2714810371398926
Batch 59/64 loss: 0.4155435562133789
Batch 60/64 loss: 0.34831953048706055
Batch 61/64 loss: 0.34578609466552734
Batch 62/64 loss: 0.2112722396850586
Batch 63/64 loss: 0.27628087997436523
Batch 64/64 loss: -3.805880546569824
Epoch 14  Train loss: 0.32892811719109033  Val loss: 0.9490555438798728
Epoch 15
-------------------------------
Batch 1/64 loss: 0.03871488571166992
Batch 2/64 loss: -0.04930305480957031
Batch 3/64 loss: 0.15231561660766602
Batch 4/64 loss: 0.07232666015625
Batch 5/64 loss: 0.27370643615722656
Batch 6/64 loss: 0.2741074562072754
Batch 7/64 loss: 0.4509768486022949
Batch 8/64 loss: 0.005904197692871094
Batch 9/64 loss: 0.41979026794433594
Batch 10/64 loss: 0.4059596061706543
Batch 11/64 loss: 0.09694576263427734
Batch 12/64 loss: 0.20420265197753906
Batch 13/64 loss: 0.25493812561035156
Batch 14/64 loss: 0.5095105171203613
Batch 15/64 loss: 0.1448349952697754
Batch 16/64 loss: 0.29834794998168945
Batch 17/64 loss: 1.0567078590393066
Batch 18/64 loss: 0.008821964263916016
Batch 19/64 loss: 0.579404354095459
Batch 20/64 loss: 0.5140595436096191
Batch 21/64 loss: 0.061521053314208984
Batch 22/64 loss: -0.013003349304199219
Batch 23/64 loss: 0.05643510818481445
Batch 24/64 loss: 0.43396663665771484
Batch 25/64 loss: 0.5055661201477051
Batch 26/64 loss: 0.39323997497558594
Batch 27/64 loss: 0.26096582412719727
Batch 28/64 loss: 0.48962974548339844
Batch 29/64 loss: 0.23418712615966797
Batch 30/64 loss: 0.7062206268310547
Batch 31/64 loss: 0.002453327178955078
Batch 32/64 loss: 0.33110904693603516
Batch 33/64 loss: 0.2948727607727051
Batch 34/64 loss: 0.0838155746459961
Batch 35/64 loss: -0.02106618881225586
Batch 36/64 loss: 0.46010828018188477
Batch 37/64 loss: 0.20832109451293945
Batch 38/64 loss: 0.09118223190307617
Batch 39/64 loss: -0.11272716522216797
Batch 40/64 loss: 0.48497629165649414
Batch 41/64 loss: 0.4542045593261719
Batch 42/64 loss: 0.13519620895385742
Batch 43/64 loss: 0.2691774368286133
Batch 44/64 loss: 0.32529163360595703
Batch 45/64 loss: 0.1463170051574707
Batch 46/64 loss: 0.3496675491333008
Batch 47/64 loss: 0.11425542831420898
Batch 48/64 loss: 0.24970531463623047
Batch 49/64 loss: 0.18847417831420898
Batch 50/64 loss: 0.08141136169433594
Batch 51/64 loss: 0.6339387893676758
Batch 52/64 loss: 0.17704486846923828
Batch 53/64 loss: 0.16933965682983398
Batch 54/64 loss: -0.24425983428955078
Batch 55/64 loss: 0.7917633056640625
Batch 56/64 loss: -0.014188289642333984
Batch 57/64 loss: 0.24547863006591797
Batch 58/64 loss: 0.6732087135314941
Batch 59/64 loss: 0.16968345642089844
Batch 60/64 loss: 0.6106066703796387
Batch 61/64 loss: 0.7406301498413086
Batch 62/64 loss: 0.25369787216186523
Batch 63/64 loss: 0.08556222915649414
Batch 64/64 loss: -3.7237234115600586
Epoch 15  Train loss: 0.22709742901371974  Val loss: 0.3859271937629202
Epoch 16
-------------------------------
Batch 1/64 loss: 0.044219970703125
Batch 2/64 loss: 0.10306549072265625
Batch 3/64 loss: 0.2633476257324219
Batch 4/64 loss: 0.5661530494689941
Batch 5/64 loss: 0.41930246353149414
Batch 6/64 loss: 0.1390242576599121
Batch 7/64 loss: 0.12561941146850586
Batch 8/64 loss: 0.6910343170166016
Batch 9/64 loss: 0.30222368240356445
Batch 10/64 loss: -0.03053426742553711
Batch 11/64 loss: 0.7518100738525391
Batch 12/64 loss: 0.38964366912841797
Batch 13/64 loss: -0.21123313903808594
Batch 14/64 loss: 0.21014976501464844
Batch 15/64 loss: 0.01682424545288086
Batch 16/64 loss: 0.7344293594360352
Batch 17/64 loss: 0.14655208587646484
Batch 18/64 loss: 0.04375123977661133
Batch 19/64 loss: -0.12403678894042969
Batch 20/64 loss: 0.2958378791809082
Batch 21/64 loss: 0.03896760940551758
Batch 22/64 loss: 0.17725086212158203
Batch 23/64 loss: 0.3563351631164551
Batch 24/64 loss: 0.20196771621704102
Batch 25/64 loss: 0.5283946990966797
Batch 26/64 loss: 0.11779069900512695
Batch 27/64 loss: 0.3121061325073242
Batch 28/64 loss: 0.2909884452819824
Batch 29/64 loss: 0.20969724655151367
Batch 30/64 loss: 0.0060863494873046875
Batch 31/64 loss: -0.017649173736572266
Batch 32/64 loss: 0.6785964965820312
Batch 33/64 loss: 0.2913527488708496
Batch 34/64 loss: 0.5972247123718262
Batch 35/64 loss: 0.13154029846191406
Batch 36/64 loss: 0.17983436584472656
Batch 37/64 loss: 0.07987642288208008
Batch 38/64 loss: -0.004313945770263672
Batch 39/64 loss: 0.8756594657897949
Batch 40/64 loss: -0.023128509521484375
Batch 41/64 loss: 0.07683753967285156
Batch 42/64 loss: 0.4038052558898926
Batch 43/64 loss: 0.15656471252441406
Batch 44/64 loss: 0.18291854858398438
Batch 45/64 loss: 0.5816307067871094
Batch 46/64 loss: 0.1907176971435547
Batch 47/64 loss: 0.0020279884338378906
Batch 48/64 loss: -0.018296241760253906
Batch 49/64 loss: 1.0915732383728027
Batch 50/64 loss: -0.06808280944824219
Batch 51/64 loss: -0.1479935646057129
Batch 52/64 loss: 0.07652425765991211
Batch 53/64 loss: 0.12317895889282227
Batch 54/64 loss: 0.16405773162841797
Batch 55/64 loss: 0.10051250457763672
Batch 56/64 loss: 0.35687923431396484
Batch 57/64 loss: -0.13501453399658203
Batch 58/64 loss: 0.05480241775512695
Batch 59/64 loss: -0.20590829849243164
Batch 60/64 loss: 0.9675321578979492
Batch 61/64 loss: 0.28931236267089844
Batch 62/64 loss: 0.48862123489379883
Batch 63/64 loss: 0.34862613677978516
Batch 64/64 loss: -4.039798736572266
Epoch 16  Train loss: 0.1875567118326823  Val loss: 0.44520682895306457
Epoch 17
-------------------------------
Batch 1/64 loss: 0.40208864212036133
Batch 2/64 loss: 0.9560747146606445
Batch 3/64 loss: 0.4709901809692383
Batch 4/64 loss: 0.16097354888916016
Batch 5/64 loss: 0.25401830673217773
Batch 6/64 loss: 1.1944046020507812
Batch 7/64 loss: 0.12297821044921875
Batch 8/64 loss: 0.013608455657958984
Batch 9/64 loss: 0.21643781661987305
Batch 10/64 loss: 0.007426738739013672
Batch 11/64 loss: 0.10816001892089844
Batch 12/64 loss: 0.29389286041259766
Batch 13/64 loss: 0.23254728317260742
Batch 14/64 loss: 0.12322759628295898
Batch 15/64 loss: 0.18332958221435547
Batch 16/64 loss: 0.18908309936523438
Batch 17/64 loss: -0.19635009765625
Batch 18/64 loss: 0.4139385223388672
Batch 19/64 loss: 0.35759544372558594
Batch 20/64 loss: -0.05225324630737305
Batch 21/64 loss: 0.2914600372314453
Batch 22/64 loss: 0.1763477325439453
Batch 23/64 loss: -0.0705108642578125
Batch 24/64 loss: 0.09384632110595703
Batch 25/64 loss: 0.3344717025756836
Batch 26/64 loss: 0.14658784866333008
Batch 27/64 loss: 0.3131575584411621
Batch 28/64 loss: 0.3622875213623047
Batch 29/64 loss: 0.41176795959472656
Batch 30/64 loss: -0.04296302795410156
Batch 31/64 loss: 0.5401325225830078
Batch 32/64 loss: 0.10821962356567383
Batch 33/64 loss: -0.03974628448486328
Batch 34/64 loss: 0.43053293228149414
Batch 35/64 loss: -0.08793830871582031
Batch 36/64 loss: 0.16031551361083984
Batch 37/64 loss: 0.06564903259277344
Batch 38/64 loss: -0.13750553131103516
Batch 39/64 loss: -0.2384481430053711
Batch 40/64 loss: 0.08562898635864258
Batch 41/64 loss: 0.08641529083251953
Batch 42/64 loss: 0.29801177978515625
Batch 43/64 loss: 0.02973318099975586
Batch 44/64 loss: 0.17359352111816406
Batch 45/64 loss: -0.1772003173828125
Batch 46/64 loss: -0.1098947525024414
Batch 47/64 loss: 0.4317760467529297
Batch 48/64 loss: 0.08021116256713867
Batch 49/64 loss: -0.00812387466430664
Batch 50/64 loss: 0.29651451110839844
Batch 51/64 loss: 0.020069122314453125
Batch 52/64 loss: -0.007892131805419922
Batch 53/64 loss: 0.022002220153808594
Batch 54/64 loss: -0.21225500106811523
Batch 55/64 loss: 0.3303065299987793
Batch 56/64 loss: -0.10274744033813477
Batch 57/64 loss: 0.05382585525512695
Batch 58/64 loss: 0.037102699279785156
Batch 59/64 loss: 0.050412654876708984
Batch 60/64 loss: 0.5173172950744629
Batch 61/64 loss: 0.11596012115478516
Batch 62/64 loss: 0.19986629486083984
Batch 63/64 loss: -0.0626983642578125
Batch 64/64 loss: -3.9083824157714844
Epoch 17  Train loss: 0.11743505889294194  Val loss: -0.07431756507899753
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: 0.2528672218322754
Batch 2/64 loss: -0.0842437744140625
Batch 3/64 loss: 0.09577560424804688
Batch 4/64 loss: -0.03692483901977539
Batch 5/64 loss: -0.26433563232421875
Batch 6/64 loss: 0.10175085067749023
Batch 7/64 loss: -0.13727235794067383
Batch 8/64 loss: 0.23917627334594727
Batch 9/64 loss: -0.3107433319091797
Batch 10/64 loss: 0.29883337020874023
Batch 11/64 loss: -0.14293432235717773
Batch 12/64 loss: 0.07617521286010742
Batch 13/64 loss: 0.1327061653137207
Batch 14/64 loss: 0.00923013687133789
Batch 15/64 loss: -0.06481313705444336
Batch 16/64 loss: -0.09360027313232422
Batch 17/64 loss: -0.0823526382446289
Batch 18/64 loss: 0.06368112564086914
Batch 19/64 loss: -0.02330160140991211
Batch 20/64 loss: -0.045493125915527344
Batch 21/64 loss: 0.24910211563110352
Batch 22/64 loss: -0.22085285186767578
Batch 23/64 loss: -0.1928400993347168
Batch 24/64 loss: -0.5067405700683594
Batch 25/64 loss: 0.1312718391418457
Batch 26/64 loss: -0.10549306869506836
Batch 27/64 loss: -0.25189971923828125
Batch 28/64 loss: -0.0027799606323242188
Batch 29/64 loss: -0.42566680908203125
Batch 30/64 loss: 0.463836669921875
Batch 31/64 loss: 0.3038468360900879
Batch 32/64 loss: -0.14514732360839844
Batch 33/64 loss: 0.6662454605102539
Batch 34/64 loss: 0.7049999237060547
Batch 35/64 loss: 0.590886116027832
Batch 36/64 loss: 1.0230622291564941
Batch 37/64 loss: 0.5843825340270996
Batch 38/64 loss: 0.8681368827819824
Batch 39/64 loss: 0.47817039489746094
Batch 40/64 loss: 0.7769899368286133
Batch 41/64 loss: 0.6304135322570801
Batch 42/64 loss: 0.7455945014953613
Batch 43/64 loss: 0.6254372596740723
Batch 44/64 loss: 0.7234306335449219
Batch 45/64 loss: 0.7192001342773438
Batch 46/64 loss: 0.886845588684082
Batch 47/64 loss: 0.28489160537719727
Batch 48/64 loss: 0.4002809524536133
Batch 49/64 loss: 0.4500575065612793
Batch 50/64 loss: 0.2696352005004883
Batch 51/64 loss: 1.1833195686340332
Batch 52/64 loss: 0.38748884201049805
Batch 53/64 loss: 0.7309331893920898
Batch 54/64 loss: 0.44876909255981445
Batch 55/64 loss: 0.04567670822143555
Batch 56/64 loss: 0.7872476577758789
Batch 57/64 loss: 0.38408517837524414
Batch 58/64 loss: 0.16354131698608398
Batch 59/64 loss: 0.6201953887939453
Batch 60/64 loss: 0.3717365264892578
Batch 61/64 loss: 0.5810513496398926
Batch 62/64 loss: 0.42009544372558594
Batch 63/64 loss: 0.33164358139038086
Batch 64/64 loss: -2.6670970916748047
Epoch 18  Train loss: 0.23788140240837546  Val loss: 0.2151232453965649
Epoch 19
-------------------------------
Batch 1/64 loss: 0.2464427947998047
Batch 2/64 loss: 0.18944692611694336
Batch 3/64 loss: 0.24097871780395508
Batch 4/64 loss: 0.14614152908325195
Batch 5/64 loss: 0.5271410942077637
Batch 6/64 loss: 0.1368880271911621
Batch 7/64 loss: 0.4021153450012207
Batch 8/64 loss: 0.5700082778930664
Batch 9/64 loss: 0.08796119689941406
Batch 10/64 loss: 0.07359981536865234
Batch 11/64 loss: 0.4999561309814453
Batch 12/64 loss: 0.5455560684204102
Batch 13/64 loss: 0.10723590850830078
Batch 14/64 loss: 0.4650444984436035
Batch 15/64 loss: 0.09462356567382812
Batch 16/64 loss: 0.10288429260253906
Batch 17/64 loss: 0.40875959396362305
Batch 18/64 loss: 0.14776849746704102
Batch 19/64 loss: -0.08300018310546875
Batch 20/64 loss: 0.4025077819824219
Batch 21/64 loss: -0.10755157470703125
Batch 22/64 loss: 0.1872234344482422
Batch 23/64 loss: 0.3822331428527832
Batch 24/64 loss: -0.2498607635498047
Batch 25/64 loss: -0.22834253311157227
Batch 26/64 loss: 0.15912723541259766
Batch 27/64 loss: 0.259554386138916
Batch 28/64 loss: 0.09895563125610352
Batch 29/64 loss: 0.21974515914916992
Batch 30/64 loss: 0.10859060287475586
Batch 31/64 loss: -0.11323738098144531
Batch 32/64 loss: 0.26323986053466797
Batch 33/64 loss: -0.04550457000732422
Batch 34/64 loss: 0.23617076873779297
Batch 35/64 loss: 0.23886775970458984
Batch 36/64 loss: 0.34397125244140625
Batch 37/64 loss: 0.05838966369628906
Batch 38/64 loss: -0.0579075813293457
Batch 39/64 loss: -0.16585206985473633
Batch 40/64 loss: 0.24276304244995117
Batch 41/64 loss: 0.159515380859375
Batch 42/64 loss: 0.07883691787719727
Batch 43/64 loss: -0.2970089912414551
Batch 44/64 loss: -0.15044641494750977
Batch 45/64 loss: 0.09602975845336914
Batch 46/64 loss: 0.12821197509765625
Batch 47/64 loss: -0.31666135787963867
Batch 48/64 loss: 0.5501184463500977
Batch 49/64 loss: -0.27210330963134766
Batch 50/64 loss: 0.14827632904052734
Batch 51/64 loss: -0.30696821212768555
Batch 52/64 loss: 0.21764802932739258
Batch 53/64 loss: 0.04119682312011719
Batch 54/64 loss: 0.03703117370605469
Batch 55/64 loss: 0.171905517578125
Batch 56/64 loss: 0.014379024505615234
Batch 57/64 loss: -0.16594314575195312
Batch 58/64 loss: 0.13935327529907227
Batch 59/64 loss: -0.017915725708007812
Batch 60/64 loss: 0.3730506896972656
Batch 61/64 loss: -0.037955284118652344
Batch 62/64 loss: 0.48706722259521484
Batch 63/64 loss: -0.09436511993408203
Batch 64/64 loss: -3.556530475616455
Epoch 19  Train loss: 0.08562338024962182  Val loss: 0.32385508219401044
Epoch 20
-------------------------------
Batch 1/64 loss: -0.12445545196533203
Batch 2/64 loss: 1.2022953033447266
Batch 3/64 loss: 0.5054874420166016
Batch 4/64 loss: 0.5363864898681641
Batch 5/64 loss: 0.20896244049072266
Batch 6/64 loss: 0.16215848922729492
Batch 7/64 loss: 0.12047243118286133
Batch 8/64 loss: 0.11041641235351562
Batch 9/64 loss: 0.5300307273864746
Batch 10/64 loss: -0.16353178024291992
Batch 11/64 loss: 0.2824883460998535
Batch 12/64 loss: 0.5254435539245605
Batch 13/64 loss: 0.2964143753051758
Batch 14/64 loss: 0.3309941291809082
Batch 15/64 loss: 0.13847684860229492
Batch 16/64 loss: -0.07219696044921875
Batch 17/64 loss: 0.11829137802124023
Batch 18/64 loss: 0.43248796463012695
Batch 19/64 loss: 0.23081398010253906
Batch 20/64 loss: 0.02320718765258789
Batch 21/64 loss: 0.21625137329101562
Batch 22/64 loss: 0.35644006729125977
Batch 23/64 loss: 0.609154224395752
Batch 24/64 loss: -0.15396738052368164
Batch 25/64 loss: 0.3089561462402344
Batch 26/64 loss: 0.5126800537109375
Batch 27/64 loss: -0.047005653381347656
Batch 28/64 loss: 0.5674991607666016
Batch 29/64 loss: -0.23311281204223633
Batch 30/64 loss: -0.2028794288635254
Batch 31/64 loss: -0.18148231506347656
Batch 32/64 loss: -0.09585380554199219
Batch 33/64 loss: -0.11360883712768555
Batch 34/64 loss: -0.04918670654296875
Batch 35/64 loss: 0.15830183029174805
Batch 36/64 loss: -0.10303640365600586
Batch 37/64 loss: 0.17469453811645508
Batch 38/64 loss: -0.2232828140258789
Batch 39/64 loss: -0.12745094299316406
Batch 40/64 loss: -0.09209442138671875
Batch 41/64 loss: 0.05025339126586914
Batch 42/64 loss: -0.08855581283569336
Batch 43/64 loss: 0.023357391357421875
Batch 44/64 loss: -0.2698984146118164
Batch 45/64 loss: 0.3781752586364746
Batch 46/64 loss: 0.1231222152709961
Batch 47/64 loss: 0.2897052764892578
Batch 48/64 loss: 0.6020846366882324
Batch 49/64 loss: -0.36595678329467773
Batch 50/64 loss: -0.21295499801635742
Batch 51/64 loss: -0.10702133178710938
Batch 52/64 loss: -0.08629941940307617
Batch 53/64 loss: 0.10682868957519531
Batch 54/64 loss: -0.04183053970336914
Batch 55/64 loss: -0.04640483856201172
Batch 56/64 loss: 0.14159393310546875
Batch 57/64 loss: -0.4265880584716797
Batch 58/64 loss: 0.2410440444946289
Batch 59/64 loss: -0.22841358184814453
Batch 60/64 loss: -0.12854671478271484
Batch 61/64 loss: 0.3654160499572754
Batch 62/64 loss: -0.15444374084472656
Batch 63/64 loss: 0.06505775451660156
Batch 64/64 loss: -3.5814647674560547
Epoch 20  Train loss: 0.06618486292221967  Val loss: 0.3541358475832595
Epoch 21
-------------------------------
Batch 1/64 loss: -0.03452014923095703
Batch 2/64 loss: 0.1539316177368164
Batch 3/64 loss: -0.24333763122558594
Batch 4/64 loss: -0.14002037048339844
Batch 5/64 loss: 0.5077962875366211
Batch 6/64 loss: -0.31464481353759766
Batch 7/64 loss: -0.5581445693969727
Batch 8/64 loss: 0.4630913734436035
Batch 9/64 loss: 0.4063720703125
Batch 10/64 loss: 0.20437908172607422
Batch 11/64 loss: 0.08873891830444336
Batch 12/64 loss: -0.036629676818847656
Batch 13/64 loss: -0.11086416244506836
Batch 14/64 loss: 0.20355606079101562
Batch 15/64 loss: 0.27266359329223633
Batch 16/64 loss: -0.09864616394042969
Batch 17/64 loss: 0.07465362548828125
Batch 18/64 loss: -0.2854576110839844
Batch 19/64 loss: -0.517186164855957
Batch 20/64 loss: -0.11786174774169922
Batch 21/64 loss: -0.16101551055908203
Batch 22/64 loss: -0.40592098236083984
Batch 23/64 loss: 0.611760139465332
Batch 24/64 loss: -0.06883525848388672
Batch 25/64 loss: 0.22111129760742188
Batch 26/64 loss: -0.0023345947265625
Batch 27/64 loss: -0.18511295318603516
Batch 28/64 loss: 0.6221513748168945
Batch 29/64 loss: 0.054970741271972656
Batch 30/64 loss: 0.2125720977783203
Batch 31/64 loss: 0.03718852996826172
Batch 32/64 loss: 0.1332263946533203
Batch 33/64 loss: 0.03520393371582031
Batch 34/64 loss: 0.22144317626953125
Batch 35/64 loss: 0.1387782096862793
Batch 36/64 loss: -0.09697294235229492
Batch 37/64 loss: 0.15903234481811523
Batch 38/64 loss: 0.04290771484375
Batch 39/64 loss: 0.6742844581604004
Batch 40/64 loss: 0.24929332733154297
Batch 41/64 loss: 0.31177759170532227
Batch 42/64 loss: -0.2240128517150879
Batch 43/64 loss: 0.6617746353149414
Batch 44/64 loss: -0.0543513298034668
Batch 45/64 loss: 0.5549821853637695
Batch 46/64 loss: -0.19382905960083008
Batch 47/64 loss: -0.008075714111328125
Batch 48/64 loss: -0.051735877990722656
Batch 49/64 loss: 0.05237531661987305
Batch 50/64 loss: -0.26416921615600586
Batch 51/64 loss: 0.18319082260131836
Batch 52/64 loss: -0.07338428497314453
Batch 53/64 loss: 0.05832719802856445
Batch 54/64 loss: -0.14137935638427734
Batch 55/64 loss: 0.04918098449707031
Batch 56/64 loss: 0.1352405548095703
Batch 57/64 loss: -0.26023340225219727
Batch 58/64 loss: -0.23314476013183594
Batch 59/64 loss: -0.214111328125
Batch 60/64 loss: -0.0828409194946289
Batch 61/64 loss: 0.44558143615722656
Batch 62/64 loss: -0.05570220947265625
Batch 63/64 loss: 0.19051456451416016
Batch 64/64 loss: -3.8976616859436035
Epoch 21  Train loss: 0.004303212259330002  Val loss: -0.0799413726911512
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 0.4836387634277344
Batch 2/64 loss: 0.033173561096191406
Batch 3/64 loss: -0.014765739440917969
Batch 4/64 loss: -0.11564826965332031
Batch 5/64 loss: -0.42499256134033203
Batch 6/64 loss: 0.6020288467407227
Batch 7/64 loss: 0.44747161865234375
Batch 8/64 loss: 0.014101028442382812
Batch 9/64 loss: -0.2602090835571289
Batch 10/64 loss: -0.3901386260986328
Batch 11/64 loss: -0.062358856201171875
Batch 12/64 loss: -0.0801534652709961
Batch 13/64 loss: -0.3896942138671875
Batch 14/64 loss: -0.49857234954833984
Batch 15/64 loss: -0.15980958938598633
Batch 16/64 loss: 0.15168380737304688
Batch 17/64 loss: -0.2671942710876465
Batch 18/64 loss: 0.1318225860595703
Batch 19/64 loss: -0.18843841552734375
Batch 20/64 loss: 0.12830352783203125
Batch 21/64 loss: -0.34800243377685547
Batch 22/64 loss: -0.10479736328125
Batch 23/64 loss: -0.3758735656738281
Batch 24/64 loss: -0.212646484375
Batch 25/64 loss: -0.051137447357177734
Batch 26/64 loss: 0.16587066650390625
Batch 27/64 loss: -0.10723447799682617
Batch 28/64 loss: -0.17249536514282227
Batch 29/64 loss: 0.08430767059326172
Batch 30/64 loss: 0.057494163513183594
Batch 31/64 loss: -0.17914581298828125
Batch 32/64 loss: -0.18356609344482422
Batch 33/64 loss: 0.026315689086914062
Batch 34/64 loss: -0.2918820381164551
Batch 35/64 loss: -0.255157470703125
Batch 36/64 loss: 0.5172691345214844
Batch 37/64 loss: -0.08205986022949219
Batch 38/64 loss: 0.5020084381103516
Batch 39/64 loss: -0.20596981048583984
Batch 40/64 loss: -0.07783317565917969
Batch 41/64 loss: -0.6755104064941406
Batch 42/64 loss: 0.20583152770996094
Batch 43/64 loss: -0.28012943267822266
Batch 44/64 loss: -0.01576852798461914
Batch 45/64 loss: -0.02120494842529297
Batch 46/64 loss: -0.11115074157714844
Batch 47/64 loss: 0.02167987823486328
Batch 48/64 loss: -0.11893558502197266
Batch 49/64 loss: -0.27466297149658203
Batch 50/64 loss: -0.17509078979492188
Batch 51/64 loss: -0.3143796920776367
Batch 52/64 loss: -0.1736459732055664
Batch 53/64 loss: 0.6226520538330078
Batch 54/64 loss: 0.2863459587097168
Batch 55/64 loss: -0.0019378662109375
Batch 56/64 loss: 0.0383453369140625
Batch 57/64 loss: 0.3223137855529785
Batch 58/64 loss: 0.05691671371459961
Batch 59/64 loss: -0.06869935989379883
Batch 60/64 loss: -0.14658594131469727
Batch 61/64 loss: 0.28470849990844727
Batch 62/64 loss: -0.6360864639282227
Batch 63/64 loss: -0.30324792861938477
Batch 64/64 loss: -3.842966079711914
Epoch 22  Train loss: -0.10219223172056908  Val loss: -0.1449656011312688
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: -0.16160106658935547
Batch 2/64 loss: -0.23972606658935547
Batch 3/64 loss: 0.2710847854614258
Batch 4/64 loss: -0.5770730972290039
Batch 5/64 loss: -0.24077701568603516
Batch 6/64 loss: -0.1710672378540039
Batch 7/64 loss: 0.010183334350585938
Batch 8/64 loss: 0.09792900085449219
Batch 9/64 loss: -0.18582630157470703
Batch 10/64 loss: 0.3457503318786621
Batch 11/64 loss: -0.11258840560913086
Batch 12/64 loss: 0.2312765121459961
Batch 13/64 loss: 0.2478351593017578
Batch 14/64 loss: -0.2543630599975586
Batch 15/64 loss: -0.34621524810791016
Batch 16/64 loss: 0.022260665893554688
Batch 17/64 loss: -0.22385406494140625
Batch 18/64 loss: -0.055066585540771484
Batch 19/64 loss: -0.42082881927490234
Batch 20/64 loss: 0.24953746795654297
Batch 21/64 loss: -0.039687156677246094
Batch 22/64 loss: -0.39758872985839844
Batch 23/64 loss: -0.025679588317871094
Batch 24/64 loss: -0.008151054382324219
Batch 25/64 loss: -0.19871234893798828
Batch 26/64 loss: -0.3033742904663086
Batch 27/64 loss: 0.27565765380859375
Batch 28/64 loss: -0.49988365173339844
Batch 29/64 loss: -0.2439870834350586
Batch 30/64 loss: -0.5252904891967773
Batch 31/64 loss: 0.38867950439453125
Batch 32/64 loss: 0.18011760711669922
Batch 33/64 loss: -0.34996700286865234
Batch 34/64 loss: -0.03608226776123047
Batch 35/64 loss: 0.0169525146484375
Batch 36/64 loss: -0.11849498748779297
Batch 37/64 loss: 0.11925315856933594
Batch 38/64 loss: 0.43106794357299805
Batch 39/64 loss: 0.043938636779785156
Batch 40/64 loss: 0.31882524490356445
Batch 41/64 loss: 0.27747201919555664
Batch 42/64 loss: 0.09669971466064453
Batch 43/64 loss: 0.4990682601928711
Batch 44/64 loss: 0.08826494216918945
Batch 45/64 loss: 0.1261434555053711
Batch 46/64 loss: 0.06763458251953125
Batch 47/64 loss: 0.6559019088745117
Batch 48/64 loss: 0.5155324935913086
Batch 49/64 loss: -0.11586332321166992
Batch 50/64 loss: 0.15430736541748047
Batch 51/64 loss: 0.8127026557922363
Batch 52/64 loss: 0.45532703399658203
Batch 53/64 loss: -0.12230348587036133
Batch 54/64 loss: 0.40027713775634766
Batch 55/64 loss: 0.7437634468078613
Batch 56/64 loss: 0.35733699798583984
Batch 57/64 loss: 0.24907541275024414
Batch 58/64 loss: -0.018215656280517578
Batch 59/64 loss: -0.07294559478759766
Batch 60/64 loss: 0.2330775260925293
Batch 61/64 loss: 0.24629497528076172
Batch 62/64 loss: -0.44251537322998047
Batch 63/64 loss: -0.03355550765991211
Batch 64/64 loss: -3.8954086303710938
Epoch 23  Train loss: -0.0036644954307406556  Val loss: 0.007960552202467247
Epoch 24
-------------------------------
Batch 1/64 loss: -0.18393325805664062
Batch 2/64 loss: 0.1619882583618164
Batch 3/64 loss: -0.1151723861694336
Batch 4/64 loss: 0.14940643310546875
Batch 5/64 loss: -0.004112720489501953
Batch 6/64 loss: 0.5396642684936523
Batch 7/64 loss: -0.23976707458496094
Batch 8/64 loss: -0.034173011779785156
Batch 9/64 loss: -0.05172157287597656
Batch 10/64 loss: -0.3321828842163086
Batch 11/64 loss: -0.140899658203125
Batch 12/64 loss: 0.10221099853515625
Batch 13/64 loss: -0.5280599594116211
Batch 14/64 loss: -0.0962214469909668
Batch 15/64 loss: -0.1056666374206543
Batch 16/64 loss: 0.28991270065307617
Batch 17/64 loss: -0.006046772003173828
Batch 18/64 loss: -0.28948163986206055
Batch 19/64 loss: -0.21127843856811523
Batch 20/64 loss: 0.021862506866455078
Batch 21/64 loss: 0.18938827514648438
Batch 22/64 loss: -0.3993091583251953
Batch 23/64 loss: 0.27415895462036133
Batch 24/64 loss: 0.40298032760620117
Batch 25/64 loss: -0.036590576171875
Batch 26/64 loss: 0.13143539428710938
Batch 27/64 loss: -0.5392990112304688
Batch 28/64 loss: -0.0874338150024414
Batch 29/64 loss: 0.39473628997802734
Batch 30/64 loss: -0.14580535888671875
Batch 31/64 loss: -0.36213016510009766
Batch 32/64 loss: 0.009675979614257812
Batch 33/64 loss: -0.15810489654541016
Batch 34/64 loss: 0.07590961456298828
Batch 35/64 loss: 0.21036911010742188
Batch 36/64 loss: 0.07448768615722656
Batch 37/64 loss: -0.2514762878417969
Batch 38/64 loss: -0.35950660705566406
Batch 39/64 loss: 0.16301774978637695
Batch 40/64 loss: -0.3458271026611328
Batch 41/64 loss: -0.37052345275878906
Batch 42/64 loss: -0.32988929748535156
Batch 43/64 loss: -0.2423558235168457
Batch 44/64 loss: 0.03335857391357422
Batch 45/64 loss: -0.11955404281616211
Batch 46/64 loss: -0.4347553253173828
Batch 47/64 loss: 0.5281181335449219
Batch 48/64 loss: 1.1018991470336914
Batch 49/64 loss: 0.10406303405761719
Batch 50/64 loss: 0.8860077857971191
Batch 51/64 loss: -0.4570145606994629
Batch 52/64 loss: -0.27226686477661133
Batch 53/64 loss: 0.35639381408691406
Batch 54/64 loss: 0.42917871475219727
Batch 55/64 loss: 0.3549504280090332
Batch 56/64 loss: -0.4223790168762207
Batch 57/64 loss: -0.18036413192749023
Batch 58/64 loss: -0.0065460205078125
Batch 59/64 loss: -0.1766805648803711
Batch 60/64 loss: -0.23934602737426758
Batch 61/64 loss: 0.34674882888793945
Batch 62/64 loss: -0.004122734069824219
Batch 63/64 loss: 0.5249848365783691
Batch 64/64 loss: -3.2830333709716797
Epoch 24  Train loss: -0.04526063507678462  Val loss: 0.08051404920230616
Epoch 25
-------------------------------
Batch 1/64 loss: -0.22821903228759766
Batch 2/64 loss: -0.03276205062866211
Batch 3/64 loss: -0.07595443725585938
Batch 4/64 loss: -0.15442371368408203
Batch 5/64 loss: 0.005702972412109375
Batch 6/64 loss: -0.18844127655029297
Batch 7/64 loss: -0.14634227752685547
Batch 8/64 loss: 0.1929793357849121
Batch 9/64 loss: -0.12029218673706055
Batch 10/64 loss: -0.03513956069946289
Batch 11/64 loss: 0.09024477005004883
Batch 12/64 loss: -0.017383575439453125
Batch 13/64 loss: 0.5978398323059082
Batch 14/64 loss: 0.09687376022338867
Batch 15/64 loss: -0.028388500213623047
Batch 16/64 loss: -0.24189376831054688
Batch 17/64 loss: 0.34747743606567383
Batch 18/64 loss: 0.4688282012939453
Batch 19/64 loss: -0.20847797393798828
Batch 20/64 loss: 0.025983333587646484
Batch 21/64 loss: -0.03462934494018555
Batch 22/64 loss: -0.19273710250854492
Batch 23/64 loss: 0.25269651412963867
Batch 24/64 loss: -0.40657711029052734
Batch 25/64 loss: -0.16333341598510742
Batch 26/64 loss: -0.11739587783813477
Batch 27/64 loss: -0.18114852905273438
Batch 28/64 loss: 0.6895418167114258
Batch 29/64 loss: -0.5043954849243164
Batch 30/64 loss: -0.0824127197265625
Batch 31/64 loss: 0.28780031204223633
Batch 32/64 loss: -0.18141746520996094
Batch 33/64 loss: -0.15803146362304688
Batch 34/64 loss: 0.8452754020690918
Batch 35/64 loss: 0.24635076522827148
Batch 36/64 loss: -0.29751062393188477
Batch 37/64 loss: 0.10270357131958008
Batch 38/64 loss: -0.2120199203491211
Batch 39/64 loss: -0.20088672637939453
Batch 40/64 loss: -0.07319164276123047
Batch 41/64 loss: -0.051428794860839844
Batch 42/64 loss: -0.5155086517333984
Batch 43/64 loss: 0.03520774841308594
Batch 44/64 loss: 0.121551513671875
Batch 45/64 loss: 0.06746101379394531
Batch 46/64 loss: -0.23010730743408203
Batch 47/64 loss: -0.11028289794921875
Batch 48/64 loss: -0.28000640869140625
Batch 49/64 loss: -0.2647552490234375
Batch 50/64 loss: -0.041968345642089844
Batch 51/64 loss: -0.017673969268798828
Batch 52/64 loss: -0.39702320098876953
Batch 53/64 loss: -0.5670652389526367
Batch 54/64 loss: -0.17160701751708984
Batch 55/64 loss: -0.34133052825927734
Batch 56/64 loss: -0.6686811447143555
Batch 57/64 loss: -0.6046218872070312
Batch 58/64 loss: -0.525843620300293
Batch 59/64 loss: -0.38474369049072266
Batch 60/64 loss: 0.07461833953857422
Batch 61/64 loss: -0.43444347381591797
Batch 62/64 loss: 0.06498050689697266
Batch 63/64 loss: -0.002197265625
Batch 64/64 loss: -4.126132965087891
Epoch 25  Train loss: -0.13134395374971278  Val loss: -0.2521345263084595
Saving best model, epoch: 25
Epoch 26
-------------------------------
Batch 1/64 loss: 0.5082130432128906
Batch 2/64 loss: -0.3080615997314453
Batch 3/64 loss: -0.1415538787841797
Batch 4/64 loss: -0.42673778533935547
Batch 5/64 loss: 0.08899307250976562
Batch 6/64 loss: -0.11116409301757812
Batch 7/64 loss: 0.055251121520996094
Batch 8/64 loss: 0.02592611312866211
Batch 9/64 loss: 0.00953054428100586
Batch 10/64 loss: 0.010823726654052734
Batch 11/64 loss: -0.2095947265625
Batch 12/64 loss: -0.024760723114013672
Batch 13/64 loss: -0.05373859405517578
Batch 14/64 loss: -0.17443132400512695
Batch 15/64 loss: -0.09545564651489258
Batch 16/64 loss: -0.18554162979125977
Batch 17/64 loss: 0.3101649284362793
Batch 18/64 loss: -0.11142444610595703
Batch 19/64 loss: -0.13846302032470703
Batch 20/64 loss: -0.1562337875366211
Batch 21/64 loss: -0.09456348419189453
Batch 22/64 loss: -0.17890357971191406
Batch 23/64 loss: -0.25012874603271484
Batch 24/64 loss: -0.26186466217041016
Batch 25/64 loss: -0.4737577438354492
Batch 26/64 loss: -0.26662540435791016
Batch 27/64 loss: -0.49553775787353516
Batch 28/64 loss: -0.23343563079833984
Batch 29/64 loss: -0.3258504867553711
Batch 30/64 loss: -0.14151763916015625
Batch 31/64 loss: 0.20169878005981445
Batch 32/64 loss: -0.09306716918945312
Batch 33/64 loss: -0.23741722106933594
Batch 34/64 loss: -0.11505794525146484
Batch 35/64 loss: -0.03846549987792969
Batch 36/64 loss: -0.209442138671875
Batch 37/64 loss: 0.010701179504394531
Batch 38/64 loss: 0.17960834503173828
Batch 39/64 loss: -0.3831920623779297
Batch 40/64 loss: 0.018586158752441406
Batch 41/64 loss: -0.1757965087890625
Batch 42/64 loss: -0.4095640182495117
Batch 43/64 loss: 0.28526735305786133
Batch 44/64 loss: -0.5205249786376953
Batch 45/64 loss: -0.3638482093811035
Batch 46/64 loss: -0.054589271545410156
Batch 47/64 loss: -0.11374568939208984
Batch 48/64 loss: -0.573369026184082
Batch 49/64 loss: 0.25936365127563477
Batch 50/64 loss: -0.5615177154541016
Batch 51/64 loss: 0.07004976272583008
Batch 52/64 loss: -0.16843318939208984
Batch 53/64 loss: -0.28177547454833984
Batch 54/64 loss: -0.5388145446777344
Batch 55/64 loss: -0.28788185119628906
Batch 56/64 loss: 0.11711454391479492
Batch 57/64 loss: -0.2547893524169922
Batch 58/64 loss: -0.11500740051269531
Batch 59/64 loss: -0.18780517578125
Batch 60/64 loss: -0.5370082855224609
Batch 61/64 loss: -0.1571512222290039
Batch 62/64 loss: -0.4186525344848633
Batch 63/64 loss: 0.20147037506103516
Batch 64/64 loss: -3.8802528381347656
Epoch 26  Train loss: -0.19158729104434744  Val loss: -0.41610228810523386
Saving best model, epoch: 26
Epoch 27
-------------------------------
Batch 1/64 loss: -0.7144985198974609
Batch 2/64 loss: 0.27170610427856445
Batch 3/64 loss: -0.34846973419189453
Batch 4/64 loss: 0.17451095581054688
Batch 5/64 loss: -0.3387565612792969
Batch 6/64 loss: -0.3244962692260742
Batch 7/64 loss: -0.03765583038330078
Batch 8/64 loss: -0.10269451141357422
Batch 9/64 loss: 0.05336475372314453
Batch 10/64 loss: -0.16446781158447266
Batch 11/64 loss: -0.170074462890625
Batch 12/64 loss: 0.28496837615966797
Batch 13/64 loss: -0.08289241790771484
Batch 14/64 loss: 0.008626937866210938
Batch 15/64 loss: -0.41063785552978516
Batch 16/64 loss: -0.42210865020751953
Batch 17/64 loss: 0.2542743682861328
Batch 18/64 loss: -0.6434841156005859
Batch 19/64 loss: -0.3972015380859375
Batch 20/64 loss: 0.07619762420654297
Batch 21/64 loss: -0.27081966400146484
Batch 22/64 loss: -0.4861764907836914
Batch 23/64 loss: -0.48177146911621094
Batch 24/64 loss: -0.2733125686645508
Batch 25/64 loss: -0.4535980224609375
Batch 26/64 loss: 0.019871234893798828
Batch 27/64 loss: 0.016866683959960938
Batch 28/64 loss: 0.09200859069824219
Batch 29/64 loss: -0.5476198196411133
Batch 30/64 loss: -0.3147611618041992
Batch 31/64 loss: 0.14425373077392578
Batch 32/64 loss: -0.26262760162353516
Batch 33/64 loss: -0.032418251037597656
Batch 34/64 loss: -0.24034404754638672
Batch 35/64 loss: -0.7250919342041016
Batch 36/64 loss: -0.22103118896484375
Batch 37/64 loss: -0.23351764678955078
Batch 38/64 loss: -0.22893905639648438
Batch 39/64 loss: -0.2048187255859375
Batch 40/64 loss: 0.38980674743652344
Batch 41/64 loss: 0.10991430282592773
Batch 42/64 loss: -0.58782958984375
Batch 43/64 loss: -0.30383777618408203
Batch 44/64 loss: -0.5594024658203125
Batch 45/64 loss: -0.6058483123779297
Batch 46/64 loss: -0.08101558685302734
Batch 47/64 loss: -0.3291053771972656
Batch 48/64 loss: -0.5181236267089844
Batch 49/64 loss: -0.48436737060546875
Batch 50/64 loss: -0.4503641128540039
Batch 51/64 loss: -0.1852731704711914
Batch 52/64 loss: -0.28650856018066406
Batch 53/64 loss: -0.3699760437011719
Batch 54/64 loss: -0.3371896743774414
Batch 55/64 loss: -0.32961463928222656
Batch 56/64 loss: -0.2551736831665039
Batch 57/64 loss: 0.49492549896240234
Batch 58/64 loss: 0.02406597137451172
Batch 59/64 loss: -0.2541375160217285
Batch 60/64 loss: -0.07197046279907227
Batch 61/64 loss: 0.0776209831237793
Batch 62/64 loss: -0.48508262634277344
Batch 63/64 loss: -0.19537687301635742
Batch 64/64 loss: -4.018886566162109
Epoch 27  Train loss: -0.25640259537042354  Val loss: -0.3005042059724683
Epoch 28
-------------------------------
Batch 1/64 loss: -0.19866180419921875
Batch 2/64 loss: -0.5670785903930664
Batch 3/64 loss: -0.16307735443115234
Batch 4/64 loss: -0.2941408157348633
Batch 5/64 loss: -0.32681941986083984
Batch 6/64 loss: 0.03363800048828125
Batch 7/64 loss: -0.05744647979736328
Batch 8/64 loss: -0.26801490783691406
Batch 9/64 loss: 0.14235305786132812
Batch 10/64 loss: -0.2937154769897461
Batch 11/64 loss: -0.5004701614379883
Batch 12/64 loss: -0.4474449157714844
Batch 13/64 loss: -0.3897972106933594
Batch 14/64 loss: -0.21280193328857422
Batch 15/64 loss: 0.16902542114257812
Batch 16/64 loss: -0.21748733520507812
Batch 17/64 loss: -0.2509880065917969
Batch 18/64 loss: 0.4846982955932617
Batch 19/64 loss: -0.07702827453613281
Batch 20/64 loss: -0.11577272415161133
Batch 21/64 loss: -0.1691608428955078
Batch 22/64 loss: -0.2747178077697754
Batch 23/64 loss: 0.055058956146240234
Batch 24/64 loss: -0.1441640853881836
Batch 25/64 loss: -0.49251747131347656
Batch 26/64 loss: -0.45597362518310547
Batch 27/64 loss: -0.27867603302001953
Batch 28/64 loss: -0.5329952239990234
Batch 29/64 loss: 0.010425567626953125
Batch 30/64 loss: -0.5627079010009766
Batch 31/64 loss: -0.21384525299072266
Batch 32/64 loss: -0.36356544494628906
Batch 33/64 loss: -0.20939922332763672
Batch 34/64 loss: -0.4573688507080078
Batch 35/64 loss: 0.049323081970214844
Batch 36/64 loss: -0.29258060455322266
Batch 37/64 loss: -0.4946174621582031
Batch 38/64 loss: -0.5546550750732422
Batch 39/64 loss: 0.13051891326904297
Batch 40/64 loss: 0.08025741577148438
Batch 41/64 loss: -0.5955696105957031
Batch 42/64 loss: -0.02044963836669922
Batch 43/64 loss: -0.37589550018310547
Batch 44/64 loss: -0.28864097595214844
Batch 45/64 loss: -0.5293331146240234
Batch 46/64 loss: -0.699859619140625
Batch 47/64 loss: -0.014960289001464844
Batch 48/64 loss: -0.26410865783691406
Batch 49/64 loss: -0.3076162338256836
Batch 50/64 loss: -0.12370681762695312
Batch 51/64 loss: -0.04305553436279297
Batch 52/64 loss: 0.33718299865722656
Batch 53/64 loss: -0.4425315856933594
Batch 54/64 loss: -0.5424442291259766
Batch 55/64 loss: -0.09006786346435547
Batch 56/64 loss: -0.19892120361328125
Batch 57/64 loss: -0.04633903503417969
Batch 58/64 loss: -0.2915363311767578
Batch 59/64 loss: 0.010718345642089844
Batch 60/64 loss: -0.35190391540527344
Batch 61/64 loss: 0.03827333450317383
Batch 62/64 loss: -0.11339664459228516
Batch 63/64 loss: -0.49572181701660156
Batch 64/64 loss: -4.011080741882324
Epoch 28  Train loss: -0.26949938979803345  Val loss: -0.17447900935956293
Epoch 29
-------------------------------
Batch 1/64 loss: -0.2191314697265625
Batch 2/64 loss: 0.5150704383850098
Batch 3/64 loss: -0.08259201049804688
Batch 4/64 loss: -0.08731508255004883
Batch 5/64 loss: -0.2244119644165039
Batch 6/64 loss: -0.2436680793762207
Batch 7/64 loss: 0.30164289474487305
Batch 8/64 loss: 0.07196521759033203
Batch 9/64 loss: 0.13738536834716797
Batch 10/64 loss: -0.1531367301940918
Batch 11/64 loss: -0.2345438003540039
Batch 12/64 loss: -0.4301185607910156
Batch 13/64 loss: -0.4488391876220703
Batch 14/64 loss: -0.2695932388305664
Batch 15/64 loss: 0.07537364959716797
Batch 16/64 loss: -0.4084444046020508
Batch 17/64 loss: 0.18780994415283203
Batch 18/64 loss: -0.47284889221191406
Batch 19/64 loss: -0.6477689743041992
Batch 20/64 loss: -0.10340404510498047
Batch 21/64 loss: -0.6424789428710938
Batch 22/64 loss: -0.5443096160888672
Batch 23/64 loss: 0.014713287353515625
Batch 24/64 loss: -0.4014101028442383
Batch 25/64 loss: -0.42046070098876953
Batch 26/64 loss: 0.07793807983398438
Batch 27/64 loss: -0.5060110092163086
Batch 28/64 loss: -0.31690025329589844
Batch 29/64 loss: -0.2956547737121582
Batch 30/64 loss: 0.3554363250732422
Batch 31/64 loss: -0.5677604675292969
Batch 32/64 loss: -0.3256549835205078
Batch 33/64 loss: -0.0826406478881836
Batch 34/64 loss: -0.4590616226196289
Batch 35/64 loss: -0.22522449493408203
Batch 36/64 loss: -0.6068944931030273
Batch 37/64 loss: -0.1805272102355957
Batch 38/64 loss: -0.06117820739746094
Batch 39/64 loss: -0.2782115936279297
Batch 40/64 loss: -0.6423492431640625
Batch 41/64 loss: -0.3895235061645508
Batch 42/64 loss: -0.0774526596069336
Batch 43/64 loss: -0.4164161682128906
Batch 44/64 loss: -0.15088558197021484
Batch 45/64 loss: 0.1195211410522461
Batch 46/64 loss: -0.3184843063354492
Batch 47/64 loss: -0.5786032676696777
Batch 48/64 loss: -0.2951192855834961
Batch 49/64 loss: -0.46772289276123047
Batch 50/64 loss: -0.18867874145507812
Batch 51/64 loss: -0.36608123779296875
Batch 52/64 loss: -0.4270009994506836
Batch 53/64 loss: -0.10880470275878906
Batch 54/64 loss: -0.4340372085571289
Batch 55/64 loss: -0.49527740478515625
Batch 56/64 loss: -0.2729511260986328
Batch 57/64 loss: 0.002216339111328125
Batch 58/64 loss: -0.4051542282104492
Batch 59/64 loss: -0.06206989288330078
Batch 60/64 loss: -0.6693401336669922
Batch 61/64 loss: -0.1948261260986328
Batch 62/64 loss: -0.35434913635253906
Batch 63/64 loss: -0.5982208251953125
Batch 64/64 loss: -4.267271041870117
Epoch 29  Train loss: -0.3010968601002413  Val loss: -0.12368471597887806
Epoch 30
-------------------------------
Batch 1/64 loss: 0.4980430603027344
Batch 2/64 loss: 0.15628528594970703
Batch 3/64 loss: -0.33003997802734375
Batch 4/64 loss: 0.0015592575073242188
Batch 5/64 loss: 0.06180858612060547
Batch 6/64 loss: -0.5277175903320312
Batch 7/64 loss: 0.035630226135253906
Batch 8/64 loss: -0.5083456039428711
Batch 9/64 loss: -0.17805099487304688
Batch 10/64 loss: 0.14852142333984375
Batch 11/64 loss: -0.4928712844848633
Batch 12/64 loss: -0.10496997833251953
Batch 13/64 loss: -0.010783195495605469
Batch 14/64 loss: -0.15561389923095703
Batch 15/64 loss: -0.42546653747558594
Batch 16/64 loss: -0.4571552276611328
Batch 17/64 loss: -0.14428424835205078
Batch 18/64 loss: 0.01446533203125
Batch 19/64 loss: -0.4462394714355469
Batch 20/64 loss: -0.3144502639770508
Batch 21/64 loss: 1.2438616752624512
Batch 22/64 loss: -0.39925384521484375
Batch 23/64 loss: 0.8366155624389648
Batch 24/64 loss: 0.12425708770751953
Batch 25/64 loss: 0.4317317008972168
Batch 26/64 loss: 0.8463044166564941
Batch 27/64 loss: -0.03610515594482422
Batch 28/64 loss: 0.4000978469848633
Batch 29/64 loss: 0.3930530548095703
Batch 30/64 loss: 0.020829200744628906
Batch 31/64 loss: -0.18215608596801758
Batch 32/64 loss: 0.4408555030822754
Batch 33/64 loss: 0.22748947143554688
Batch 34/64 loss: 0.4005904197692871
Batch 35/64 loss: 0.03478813171386719
Batch 36/64 loss: 0.27253198623657227
Batch 37/64 loss: -0.13167190551757812
Batch 38/64 loss: 0.15340757369995117
Batch 39/64 loss: 0.28298473358154297
Batch 40/64 loss: 0.28538942337036133
Batch 41/64 loss: -0.020720481872558594
Batch 42/64 loss: -0.03724098205566406
Batch 43/64 loss: -0.13227367401123047
Batch 44/64 loss: -0.3155355453491211
Batch 45/64 loss: 0.03654336929321289
Batch 46/64 loss: -0.14489126205444336
Batch 47/64 loss: -0.2079925537109375
Batch 48/64 loss: 0.04242229461669922
Batch 49/64 loss: 0.1692032814025879
Batch 50/64 loss: -0.4332084655761719
Batch 51/64 loss: -0.2777414321899414
Batch 52/64 loss: 0.10939216613769531
Batch 53/64 loss: 0.21900320053100586
Batch 54/64 loss: -0.16901731491088867
Batch 55/64 loss: -0.13775205612182617
Batch 56/64 loss: -0.17254209518432617
Batch 57/64 loss: -0.04498481750488281
Batch 58/64 loss: -0.1277599334716797
Batch 59/64 loss: -0.3539738655090332
Batch 60/64 loss: -0.38984012603759766
Batch 61/64 loss: 0.0009279251098632812
Batch 62/64 loss: -0.4171285629272461
Batch 63/64 loss: 0.1258540153503418
Batch 64/64 loss: -4.23276948928833
Epoch 30  Train loss: -0.05314366022745768  Val loss: 1.1135013226381283
Epoch 31
-------------------------------
Batch 1/64 loss: 0.05773353576660156
Batch 2/64 loss: 0.8385066986083984
Batch 3/64 loss: 0.20023822784423828
Batch 4/64 loss: 0.3306126594543457
Batch 5/64 loss: -0.260345458984375
Batch 6/64 loss: -0.3276033401489258
Batch 7/64 loss: -0.21439266204833984
Batch 8/64 loss: -0.11848926544189453
Batch 9/64 loss: -0.47537994384765625
Batch 10/64 loss: -0.050136566162109375
Batch 11/64 loss: -0.37830543518066406
Batch 12/64 loss: 0.014151573181152344
Batch 13/64 loss: -0.5788421630859375
Batch 14/64 loss: -0.4049797058105469
Batch 15/64 loss: -0.22782039642333984
Batch 16/64 loss: -0.22226428985595703
Batch 17/64 loss: -0.09937095642089844
Batch 18/64 loss: 0.02207469940185547
Batch 19/64 loss: -0.3190650939941406
Batch 20/64 loss: -0.3804283142089844
Batch 21/64 loss: -0.2949714660644531
Batch 22/64 loss: -0.20557212829589844
Batch 23/64 loss: -0.08272075653076172
Batch 24/64 loss: -0.2475452423095703
Batch 25/64 loss: -0.39772605895996094
Batch 26/64 loss: -0.2529335021972656
Batch 27/64 loss: -0.3110218048095703
Batch 28/64 loss: -0.10140562057495117
Batch 29/64 loss: -0.22149276733398438
Batch 30/64 loss: -0.39410972595214844
Batch 31/64 loss: -0.5567121505737305
Batch 32/64 loss: -0.1582622528076172
Batch 33/64 loss: -0.2698984146118164
Batch 34/64 loss: -0.48680591583251953
Batch 35/64 loss: -0.2257223129272461
Batch 36/64 loss: -0.5971870422363281
Batch 37/64 loss: -0.4189872741699219
Batch 38/64 loss: -0.13992977142333984
Batch 39/64 loss: -0.6999349594116211
Batch 40/64 loss: -0.1755809783935547
Batch 41/64 loss: -0.4307060241699219
Batch 42/64 loss: 0.41911888122558594
Batch 43/64 loss: -0.14148235321044922
Batch 44/64 loss: -0.1549386978149414
Batch 45/64 loss: -0.33566761016845703
Batch 46/64 loss: -0.18981647491455078
Batch 47/64 loss: -0.44360923767089844
Batch 48/64 loss: -0.3038663864135742
Batch 49/64 loss: -0.1994333267211914
Batch 50/64 loss: -0.5588569641113281
Batch 51/64 loss: -0.1563434600830078
Batch 52/64 loss: -0.3613004684448242
Batch 53/64 loss: -0.12052249908447266
Batch 54/64 loss: -0.19615459442138672
Batch 55/64 loss: 0.2179241180419922
Batch 56/64 loss: 0.005696296691894531
Batch 57/64 loss: -0.31033897399902344
Batch 58/64 loss: -0.3555259704589844
Batch 59/64 loss: 0.13506126403808594
Batch 60/64 loss: -0.5508594512939453
Batch 61/64 loss: 0.34566307067871094
Batch 62/64 loss: -0.1881866455078125
Batch 63/64 loss: -0.3731393814086914
Batch 64/64 loss: -3.893519401550293
Epoch 31  Train loss: -0.25098118875540937  Val loss: -0.387960794455407
Epoch 32
-------------------------------
Batch 1/64 loss: -0.3697376251220703
Batch 2/64 loss: -0.4322490692138672
Batch 3/64 loss: -0.6609477996826172
Batch 4/64 loss: -0.48673248291015625
Batch 5/64 loss: -0.4654550552368164
Batch 6/64 loss: -0.232574462890625
Batch 7/64 loss: -0.29294681549072266
Batch 8/64 loss: -0.21812915802001953
Batch 9/64 loss: 0.03942584991455078
Batch 10/64 loss: -0.15989112854003906
Batch 11/64 loss: -0.24825000762939453
Batch 12/64 loss: -0.3927783966064453
Batch 13/64 loss: -0.073486328125
Batch 14/64 loss: -0.5641145706176758
Batch 15/64 loss: -0.05683708190917969
Batch 16/64 loss: -0.30760955810546875
Batch 17/64 loss: -0.3952674865722656
Batch 18/64 loss: -0.43166160583496094
Batch 19/64 loss: -0.3563814163208008
Batch 20/64 loss: -0.43599987030029297
Batch 21/64 loss: -0.3146800994873047
Batch 22/64 loss: -0.41110992431640625
Batch 23/64 loss: -0.6473770141601562
Batch 24/64 loss: -0.04746294021606445
Batch 25/64 loss: 0.012081146240234375
Batch 26/64 loss: -0.3562946319580078
Batch 27/64 loss: -0.5165672302246094
Batch 28/64 loss: -0.4863109588623047
Batch 29/64 loss: -0.5066642761230469
Batch 30/64 loss: -0.738001823425293
Batch 31/64 loss: -0.5935745239257812
Batch 32/64 loss: -0.3787965774536133
Batch 33/64 loss: -0.562530517578125
Batch 34/64 loss: -0.07353496551513672
Batch 35/64 loss: -0.613922119140625
Batch 36/64 loss: -0.03722858428955078
Batch 37/64 loss: -0.50421142578125
Batch 38/64 loss: -0.05390739440917969
Batch 39/64 loss: -0.2568702697753906
Batch 40/64 loss: -0.3974275588989258
Batch 41/64 loss: -0.5983400344848633
Batch 42/64 loss: -0.11648368835449219
Batch 43/64 loss: -0.41719913482666016
Batch 44/64 loss: -0.5680017471313477
Batch 45/64 loss: 0.6077632904052734
Batch 46/64 loss: -0.022289276123046875
Batch 47/64 loss: -0.3420696258544922
Batch 48/64 loss: 0.10200023651123047
Batch 49/64 loss: 0.2679738998413086
Batch 50/64 loss: -0.256256103515625
Batch 51/64 loss: -0.7085084915161133
Batch 52/64 loss: 0.10448169708251953
Batch 53/64 loss: -0.4222087860107422
Batch 54/64 loss: 0.044216156005859375
Batch 55/64 loss: 0.14624500274658203
Batch 56/64 loss: -0.317138671875
Batch 57/64 loss: -0.1792011260986328
Batch 58/64 loss: -0.5256242752075195
Batch 59/64 loss: -0.33899784088134766
Batch 60/64 loss: -0.3685598373413086
Batch 61/64 loss: -0.47043895721435547
Batch 62/64 loss: -0.542694091796875
Batch 63/64 loss: 0.21608448028564453
Batch 64/64 loss: -4.751467227935791
Epoch 32  Train loss: -0.3497233428207098  Val loss: -0.3263835448170036
Epoch 33
-------------------------------
Batch 1/64 loss: 0.054775238037109375
Batch 2/64 loss: -0.4589996337890625
Batch 3/64 loss: -0.18461894989013672
Batch 4/64 loss: -0.4857616424560547
Batch 5/64 loss: -0.052590370178222656
Batch 6/64 loss: -0.3453798294067383
Batch 7/64 loss: -0.6285037994384766
Batch 8/64 loss: -0.3623514175415039
Batch 9/64 loss: -0.3139314651489258
Batch 10/64 loss: -0.16927337646484375
Batch 11/64 loss: 0.07175350189208984
Batch 12/64 loss: -0.27731895446777344
Batch 13/64 loss: -0.4887580871582031
Batch 14/64 loss: -0.6365995407104492
Batch 15/64 loss: -0.6230573654174805
Batch 16/64 loss: 0.1101827621459961
Batch 17/64 loss: -0.35913848876953125
Batch 18/64 loss: -0.07344532012939453
Batch 19/64 loss: -0.17822647094726562
Batch 20/64 loss: -0.4514350891113281
Batch 21/64 loss: -0.552459716796875
Batch 22/64 loss: -0.393890380859375
Batch 23/64 loss: -0.35385704040527344
Batch 24/64 loss: -0.4643077850341797
Batch 25/64 loss: -0.33680152893066406
Batch 26/64 loss: -0.5890779495239258
Batch 27/64 loss: -0.47597503662109375
Batch 28/64 loss: -0.4658689498901367
Batch 29/64 loss: -0.4693107604980469
Batch 30/64 loss: -0.03314971923828125
Batch 31/64 loss: -0.45264720916748047
Batch 32/64 loss: -0.4284381866455078
Batch 33/64 loss: 0.41947078704833984
Batch 34/64 loss: -0.4009857177734375
Batch 35/64 loss: -0.3986053466796875
Batch 36/64 loss: -0.38550567626953125
Batch 37/64 loss: -0.2985372543334961
Batch 38/64 loss: -0.28122806549072266
Batch 39/64 loss: -0.07852458953857422
Batch 40/64 loss: -0.2003469467163086
Batch 41/64 loss: -0.6429891586303711
Batch 42/64 loss: -0.3254413604736328
Batch 43/64 loss: -0.4236888885498047
Batch 44/64 loss: -0.25137901306152344
Batch 45/64 loss: -0.5369806289672852
Batch 46/64 loss: -0.17137908935546875
Batch 47/64 loss: -0.5848855972290039
Batch 48/64 loss: -0.47693920135498047
Batch 49/64 loss: -0.1284036636352539
Batch 50/64 loss: 0.047408103942871094
Batch 51/64 loss: -0.1789684295654297
Batch 52/64 loss: 0.18146800994873047
Batch 53/64 loss: -0.6916027069091797
Batch 54/64 loss: -0.4515094757080078
Batch 55/64 loss: -0.10036659240722656
Batch 56/64 loss: -0.10869884490966797
Batch 57/64 loss: -0.6777582168579102
Batch 58/64 loss: -0.35733795166015625
Batch 59/64 loss: -0.09978961944580078
Batch 60/64 loss: -0.5607061386108398
Batch 61/64 loss: -0.059357643127441406
Batch 62/64 loss: -0.33484458923339844
Batch 63/64 loss: -0.2841501235961914
Batch 64/64 loss: -4.459200859069824
Epoch 33  Train loss: -0.36165375429041247  Val loss: 0.5032335786065695
Epoch 34
-------------------------------
Batch 1/64 loss: -0.6890907287597656
Batch 2/64 loss: -0.12004375457763672
Batch 3/64 loss: -0.20102214813232422
Batch 4/64 loss: -0.5342931747436523
Batch 5/64 loss: -0.5153818130493164
Batch 6/64 loss: -0.20386981964111328
Batch 7/64 loss: -0.13749027252197266
Batch 8/64 loss: -0.49521446228027344
Batch 9/64 loss: -0.39576148986816406
Batch 10/64 loss: -0.5235519409179688
Batch 11/64 loss: -0.28498077392578125
Batch 12/64 loss: -0.5654659271240234
Batch 13/64 loss: -0.35598278045654297
Batch 14/64 loss: -0.5863943099975586
Batch 15/64 loss: -0.29390907287597656
Batch 16/64 loss: -0.051207542419433594
Batch 17/64 loss: -0.5603275299072266
Batch 18/64 loss: -0.3640470504760742
Batch 19/64 loss: 0.4608945846557617
Batch 20/64 loss: -0.23288917541503906
Batch 21/64 loss: -0.577911376953125
Batch 22/64 loss: -0.21698474884033203
Batch 23/64 loss: -0.6059598922729492
Batch 24/64 loss: -0.3460731506347656
Batch 25/64 loss: -0.12773895263671875
Batch 26/64 loss: -0.3348388671875
Batch 27/64 loss: -0.4696922302246094
Batch 28/64 loss: -0.37998390197753906
Batch 29/64 loss: -0.01765918731689453
Batch 30/64 loss: -0.9066543579101562
Batch 31/64 loss: -0.2960996627807617
Batch 32/64 loss: -0.6393718719482422
Batch 33/64 loss: -0.17557334899902344
Batch 34/64 loss: -0.3558053970336914
Batch 35/64 loss: -0.2672262191772461
Batch 36/64 loss: -0.7342967987060547
Batch 37/64 loss: -0.36614418029785156
Batch 38/64 loss: 0.06687641143798828
Batch 39/64 loss: -0.2659740447998047
Batch 40/64 loss: -0.37729835510253906
Batch 41/64 loss: -0.12245750427246094
Batch 42/64 loss: -0.35434627532958984
Batch 43/64 loss: -0.1523284912109375
Batch 44/64 loss: -0.43724632263183594
Batch 45/64 loss: -0.48560142517089844
Batch 46/64 loss: 0.015139579772949219
Batch 47/64 loss: -0.5985202789306641
Batch 48/64 loss: 0.04875755310058594
Batch 49/64 loss: -0.3494386672973633
Batch 50/64 loss: -0.2113513946533203
Batch 51/64 loss: -0.2137432098388672
Batch 52/64 loss: -0.1385660171508789
Batch 53/64 loss: 0.012828350067138672
Batch 54/64 loss: 0.3048677444458008
Batch 55/64 loss: -0.4231529235839844
Batch 56/64 loss: -0.042336463928222656
Batch 57/64 loss: -0.1995401382446289
Batch 58/64 loss: 0.11157846450805664
Batch 59/64 loss: -0.2602224349975586
Batch 60/64 loss: 0.18420934677124023
Batch 61/64 loss: -0.071929931640625
Batch 62/64 loss: -0.2922506332397461
Batch 63/64 loss: -0.15999603271484375
Batch 64/64 loss: -4.392336845397949
Epoch 34  Train loss: -0.33214649499631393  Val loss: -0.16063168450319482
Epoch 35
-------------------------------
Batch 1/64 loss: -0.13352203369140625
Batch 2/64 loss: -0.024517536163330078
Batch 3/64 loss: -0.6322345733642578
Batch 4/64 loss: -0.5868282318115234
Batch 5/64 loss: 0.1849203109741211
Batch 6/64 loss: -0.2764015197753906
Batch 7/64 loss: -0.3469257354736328
Batch 8/64 loss: 0.2115631103515625
Batch 9/64 loss: -0.7089481353759766
Batch 10/64 loss: -0.19349098205566406
Batch 11/64 loss: -0.10943412780761719
Batch 12/64 loss: -0.2718191146850586
Batch 13/64 loss: -0.19037818908691406
Batch 14/64 loss: -0.5505704879760742
Batch 15/64 loss: 0.11102104187011719
Batch 16/64 loss: -0.46576881408691406
Batch 17/64 loss: 0.49860143661499023
Batch 18/64 loss: -0.3931398391723633
Batch 19/64 loss: -0.33052730560302734
Batch 20/64 loss: -0.2183542251586914
Batch 21/64 loss: -0.6038961410522461
Batch 22/64 loss: 0.008700370788574219
Batch 23/64 loss: -0.6550207138061523
Batch 24/64 loss: -0.287200927734375
Batch 25/64 loss: -0.4104938507080078
Batch 26/64 loss: -0.029091835021972656
Batch 27/64 loss: -0.04521942138671875
Batch 28/64 loss: -0.5008697509765625
Batch 29/64 loss: 0.3217191696166992
Batch 30/64 loss: -0.7655000686645508
Batch 31/64 loss: -0.43644046783447266
Batch 32/64 loss: -0.38925647735595703
Batch 33/64 loss: -0.39610958099365234
Batch 34/64 loss: -0.1926097869873047
Batch 35/64 loss: -0.1382617950439453
Batch 36/64 loss: -0.12088203430175781
Batch 37/64 loss: 0.03113555908203125
Batch 38/64 loss: -0.4554615020751953
Batch 39/64 loss: -0.6060953140258789
Batch 40/64 loss: -0.4426422119140625
Batch 41/64 loss: -0.6757669448852539
Batch 42/64 loss: -0.000431060791015625
Batch 43/64 loss: -0.5322027206420898
Batch 44/64 loss: -0.47913455963134766
Batch 45/64 loss: 0.5580873489379883
Batch 46/64 loss: -0.3586845397949219
Batch 47/64 loss: -0.1407175064086914
Batch 48/64 loss: -0.04846906661987305
Batch 49/64 loss: -0.2796287536621094
Batch 50/64 loss: 0.12532997131347656
Batch 51/64 loss: 0.13494586944580078
Batch 52/64 loss: -0.20872783660888672
Batch 53/64 loss: 0.32578516006469727
Batch 54/64 loss: -0.1886434555053711
Batch 55/64 loss: -0.4661111831665039
Batch 56/64 loss: -0.13921165466308594
Batch 57/64 loss: 0.3360481262207031
Batch 58/64 loss: -0.26227903366088867
Batch 59/64 loss: 0.7723312377929688
Batch 60/64 loss: -0.37914466857910156
Batch 61/64 loss: -0.45905590057373047
Batch 62/64 loss: 0.01503753662109375
Batch 63/64 loss: -0.4335060119628906
Batch 64/64 loss: -4.069154739379883
Epoch 35  Train loss: -0.25688262640261184  Val loss: 1.4174695621241409
Epoch 36
-------------------------------
Batch 1/64 loss: -0.2281503677368164
Batch 2/64 loss: -0.1960887908935547
Batch 3/64 loss: -0.14072227478027344
Batch 4/64 loss: 0.3690471649169922
Batch 5/64 loss: 0.39096689224243164
Batch 6/64 loss: -0.4420299530029297
Batch 7/64 loss: -0.014317512512207031
Batch 8/64 loss: -0.07513904571533203
Batch 9/64 loss: -0.1146240234375
Batch 10/64 loss: -0.5322132110595703
Batch 11/64 loss: -0.27072620391845703
Batch 12/64 loss: -0.5917901992797852
Batch 13/64 loss: -0.07376289367675781
Batch 14/64 loss: -0.10936737060546875
Batch 15/64 loss: -0.1857748031616211
Batch 16/64 loss: -0.1745128631591797
Batch 17/64 loss: -0.09840202331542969
Batch 18/64 loss: -0.3463888168334961
Batch 19/64 loss: -0.03395557403564453
Batch 20/64 loss: -0.28730010986328125
Batch 21/64 loss: -0.4791097640991211
Batch 22/64 loss: -0.10145854949951172
Batch 23/64 loss: 0.9483175277709961
Batch 24/64 loss: -0.3881387710571289
Batch 25/64 loss: -0.08335399627685547
Batch 26/64 loss: -0.3114480972290039
Batch 27/64 loss: 0.5418834686279297
Batch 28/64 loss: 1.1980571746826172
Batch 29/64 loss: -0.23594379425048828
Batch 30/64 loss: 0.02090930938720703
Batch 31/64 loss: 0.4224715232849121
Batch 32/64 loss: 0.4422025680541992
Batch 33/64 loss: -0.1188211441040039
Batch 34/64 loss: 0.6072430610656738
Batch 35/64 loss: 0.2496652603149414
Batch 36/64 loss: -0.09933137893676758
Batch 37/64 loss: 0.1587386131286621
Batch 38/64 loss: 0.17197942733764648
Batch 39/64 loss: 0.13077688217163086
Batch 40/64 loss: 0.4548659324645996
Batch 41/64 loss: -0.24085235595703125
Batch 42/64 loss: -0.2515869140625
Batch 43/64 loss: -0.32790231704711914
Batch 44/64 loss: -0.1401805877685547
Batch 45/64 loss: -0.04598522186279297
Batch 46/64 loss: 0.8406996726989746
Batch 47/64 loss: -0.13229942321777344
Batch 48/64 loss: -0.3777017593383789
Batch 49/64 loss: -0.11963844299316406
Batch 50/64 loss: -0.16415691375732422
Batch 51/64 loss: 0.021166324615478516
Batch 52/64 loss: -0.19162368774414062
Batch 53/64 loss: 0.1377725601196289
Batch 54/64 loss: -0.2243366241455078
Batch 55/64 loss: -0.33866405487060547
Batch 56/64 loss: -0.16649723052978516
Batch 57/64 loss: -0.5364198684692383
Batch 58/64 loss: -0.33164501190185547
Batch 59/64 loss: -0.0316462516784668
Batch 60/64 loss: -0.3324165344238281
Batch 61/64 loss: -0.48337459564208984
Batch 62/64 loss: -0.07003498077392578
Batch 63/64 loss: -0.11188507080078125
Batch 64/64 loss: -4.3889055252075195
Epoch 36  Train loss: -0.10253545349719477  Val loss: -0.2073982736908693
Epoch 37
-------------------------------
Batch 1/64 loss: -0.14159107208251953
Batch 2/64 loss: -0.07140445709228516
Batch 3/64 loss: -0.42206478118896484
Batch 4/64 loss: 0.0065822601318359375
Batch 5/64 loss: -0.00629425048828125
Batch 6/64 loss: 0.19263839721679688
Batch 7/64 loss: -0.13008499145507812
Batch 8/64 loss: -0.6564159393310547
Batch 9/64 loss: -0.4301567077636719
Batch 10/64 loss: -0.6541166305541992
Batch 11/64 loss: -0.22311687469482422
Batch 12/64 loss: -0.196685791015625
Batch 13/64 loss: 0.6053705215454102
Batch 14/64 loss: -0.059670448303222656
Batch 15/64 loss: 0.38321971893310547
Batch 16/64 loss: -0.6075401306152344
Batch 17/64 loss: -0.08978080749511719
Batch 18/64 loss: -0.3689384460449219
Batch 19/64 loss: -0.5951290130615234
Batch 20/64 loss: -0.2529420852661133
Batch 21/64 loss: -0.5322151184082031
Batch 22/64 loss: -0.37611961364746094
Batch 23/64 loss: -0.4799947738647461
Batch 24/64 loss: -0.19095706939697266
Batch 25/64 loss: -0.04611492156982422
Batch 26/64 loss: -0.1928558349609375
Batch 27/64 loss: -0.6638755798339844
Batch 28/64 loss: -0.3407707214355469
Batch 29/64 loss: -0.5863246917724609
Batch 30/64 loss: -0.24899578094482422
Batch 31/64 loss: -0.6342201232910156
Batch 32/64 loss: -0.3114166259765625
Batch 33/64 loss: -0.4460563659667969
Batch 34/64 loss: -0.34397125244140625
Batch 35/64 loss: -0.1558237075805664
Batch 36/64 loss: -0.032176971435546875
Batch 37/64 loss: -0.12575626373291016
Batch 38/64 loss: -0.34543895721435547
Batch 39/64 loss: -0.23540687561035156
Batch 40/64 loss: -0.3312044143676758
Batch 41/64 loss: -0.41136741638183594
Batch 42/64 loss: -0.31433582305908203
Batch 43/64 loss: -0.33737850189208984
Batch 44/64 loss: -0.5076942443847656
Batch 45/64 loss: -0.26737117767333984
Batch 46/64 loss: -0.6238489151000977
Batch 47/64 loss: -0.21715641021728516
Batch 48/64 loss: -0.40770816802978516
Batch 49/64 loss: -0.5307865142822266
Batch 50/64 loss: -0.4732217788696289
Batch 51/64 loss: 0.06354236602783203
Batch 52/64 loss: -0.5963573455810547
Batch 53/64 loss: -0.004014015197753906
Batch 54/64 loss: -0.3588676452636719
Batch 55/64 loss: -0.22265625
Batch 56/64 loss: -0.03106975555419922
Batch 57/64 loss: -0.4662942886352539
Batch 58/64 loss: -0.1865062713623047
Batch 59/64 loss: 0.025429725646972656
Batch 60/64 loss: -0.5944595336914062
Batch 61/64 loss: -0.4591226577758789
Batch 62/64 loss: 0.5465402603149414
Batch 63/64 loss: 0.1928567886352539
Batch 64/64 loss: -4.24256706237793
Epoch 37  Train loss: -0.3090445499794156  Val loss: -0.3965382657919553
Epoch 38
-------------------------------
Batch 1/64 loss: -0.12781906127929688
Batch 2/64 loss: -0.2901134490966797
Batch 3/64 loss: -0.43630409240722656
Batch 4/64 loss: -0.4046506881713867
Batch 5/64 loss: -0.5659723281860352
Batch 6/64 loss: -0.4661893844604492
Batch 7/64 loss: -0.07749462127685547
Batch 8/64 loss: -0.0912179946899414
Batch 9/64 loss: -0.6124229431152344
Batch 10/64 loss: -0.5745773315429688
Batch 11/64 loss: -0.23435306549072266
Batch 12/64 loss: -0.3480682373046875
Batch 13/64 loss: -0.5221405029296875
Batch 14/64 loss: -0.5243568420410156
Batch 15/64 loss: -0.2885103225708008
Batch 16/64 loss: 0.3852062225341797
Batch 17/64 loss: -0.2635307312011719
Batch 18/64 loss: -0.09671783447265625
Batch 19/64 loss: -0.7416715621948242
Batch 20/64 loss: -0.38244152069091797
Batch 21/64 loss: -0.40227413177490234
Batch 22/64 loss: -0.2933835983276367
Batch 23/64 loss: -0.1381244659423828
Batch 24/64 loss: -0.3570108413696289
Batch 25/64 loss: -0.34271812438964844
Batch 26/64 loss: -0.25891971588134766
Batch 27/64 loss: -0.5597715377807617
Batch 28/64 loss: -0.64447021484375
Batch 29/64 loss: 0.028792381286621094
Batch 30/64 loss: -0.1676769256591797
Batch 31/64 loss: -0.3021965026855469
Batch 32/64 loss: 0.26203489303588867
Batch 33/64 loss: -0.3306407928466797
Batch 34/64 loss: 0.056336402893066406
Batch 35/64 loss: 0.41625547409057617
Batch 36/64 loss: -0.12398910522460938
Batch 37/64 loss: -0.8156108856201172
Batch 38/64 loss: -0.512364387512207
Batch 39/64 loss: -0.6591405868530273
Batch 40/64 loss: -0.2254018783569336
Batch 41/64 loss: -0.3756380081176758
Batch 42/64 loss: -0.5413722991943359
Batch 43/64 loss: -0.4679718017578125
Batch 44/64 loss: 0.12918853759765625
Batch 45/64 loss: -0.6190872192382812
Batch 46/64 loss: -0.2003345489501953
Batch 47/64 loss: -0.4778709411621094
Batch 48/64 loss: -0.5948152542114258
Batch 49/64 loss: -0.3801565170288086
Batch 50/64 loss: -0.6568193435668945
Batch 51/64 loss: -0.0800638198852539
Batch 52/64 loss: -0.3501605987548828
Batch 53/64 loss: -0.46730899810791016
Batch 54/64 loss: -0.5677709579467773
Batch 55/64 loss: -0.6707830429077148
Batch 56/64 loss: -0.5560312271118164
Batch 57/64 loss: -0.5542678833007812
Batch 58/64 loss: -0.5084114074707031
Batch 59/64 loss: -0.6239166259765625
Batch 60/64 loss: 0.31462669372558594
Batch 61/64 loss: -0.7619810104370117
Batch 62/64 loss: -0.4795083999633789
Batch 63/64 loss: -0.41753292083740234
Batch 64/64 loss: -3.9059524536132812
Epoch 38  Train loss: -0.390134474810432  Val loss: -0.4374877169369832
Saving best model, epoch: 38
Epoch 39
-------------------------------
Batch 1/64 loss: -0.08898258209228516
Batch 2/64 loss: -0.17437076568603516
Batch 3/64 loss: -0.40834808349609375
Batch 4/64 loss: -0.6338748931884766
Batch 5/64 loss: -0.4888038635253906
Batch 6/64 loss: -0.6658697128295898
Batch 7/64 loss: -0.4310464859008789
Batch 8/64 loss: -0.7588090896606445
Batch 9/64 loss: -0.5792732238769531
Batch 10/64 loss: -0.33422374725341797
Batch 11/64 loss: -0.25040245056152344
Batch 12/64 loss: -0.1714191436767578
Batch 13/64 loss: -0.7396650314331055
Batch 14/64 loss: -0.6787309646606445
Batch 15/64 loss: -0.6623449325561523
Batch 16/64 loss: -0.5688629150390625
Batch 17/64 loss: -0.5489368438720703
Batch 18/64 loss: -0.17095279693603516
Batch 19/64 loss: -0.22443866729736328
Batch 20/64 loss: -0.8758306503295898
Batch 21/64 loss: -0.2639732360839844
Batch 22/64 loss: -0.2239246368408203
Batch 23/64 loss: -0.5893955230712891
Batch 24/64 loss: -0.2785358428955078
Batch 25/64 loss: -0.6112632751464844
Batch 26/64 loss: -0.8404083251953125
Batch 27/64 loss: -0.15070056915283203
Batch 28/64 loss: -0.3776826858520508
Batch 29/64 loss: -0.19857120513916016
Batch 30/64 loss: -0.4236412048339844
Batch 31/64 loss: -0.4282350540161133
Batch 32/64 loss: -0.36850547790527344
Batch 33/64 loss: -0.7196693420410156
Batch 34/64 loss: -0.5768861770629883
Batch 35/64 loss: -0.5055990219116211
Batch 36/64 loss: -0.13515949249267578
Batch 37/64 loss: -0.3983583450317383
Batch 38/64 loss: -0.6376018524169922
Batch 39/64 loss: -0.277130126953125
Batch 40/64 loss: -0.6317968368530273
Batch 41/64 loss: -0.7076148986816406
Batch 42/64 loss: 0.10144519805908203
Batch 43/64 loss: -0.22670555114746094
Batch 44/64 loss: -0.640233039855957
Batch 45/64 loss: -0.5864381790161133
Batch 46/64 loss: 0.018309593200683594
Batch 47/64 loss: -0.4265584945678711
Batch 48/64 loss: -0.5929231643676758
Batch 49/64 loss: -0.06659317016601562
Batch 50/64 loss: -0.527613639831543
Batch 51/64 loss: -0.3908977508544922
Batch 52/64 loss: -0.7581062316894531
Batch 53/64 loss: -0.3544473648071289
Batch 54/64 loss: -0.5660066604614258
Batch 55/64 loss: -0.20324325561523438
Batch 56/64 loss: -0.33553028106689453
Batch 57/64 loss: -0.4433250427246094
Batch 58/64 loss: -0.6418752670288086
Batch 59/64 loss: -0.4849100112915039
Batch 60/64 loss: -0.49564552307128906
Batch 61/64 loss: -0.6307945251464844
Batch 62/64 loss: 0.03970813751220703
Batch 63/64 loss: -0.32747554779052734
Batch 64/64 loss: -4.804447650909424
Epoch 39  Train loss: -0.4853809487585928  Val loss: 0.18516948214920936
Epoch 40
-------------------------------
Batch 1/64 loss: -0.19746017456054688
Batch 2/64 loss: -0.8445425033569336
Batch 3/64 loss: -0.05814552307128906
Batch 4/64 loss: -0.8649892807006836
Batch 5/64 loss: -0.2901906967163086
Batch 6/64 loss: -0.5470676422119141
Batch 7/64 loss: -0.4557485580444336
Batch 8/64 loss: -0.2667675018310547
Batch 9/64 loss: -0.5337533950805664
Batch 10/64 loss: -0.45566368103027344
Batch 11/64 loss: -0.27799224853515625
Batch 12/64 loss: -0.5438623428344727
Batch 13/64 loss: -0.7896480560302734
Batch 14/64 loss: -0.4385414123535156
Batch 15/64 loss: -0.6614503860473633
Batch 16/64 loss: -0.05893516540527344
Batch 17/64 loss: -0.5308618545532227
Batch 18/64 loss: -0.4734306335449219
Batch 19/64 loss: -0.5484781265258789
Batch 20/64 loss: -0.612055778503418
Batch 21/64 loss: -0.07159709930419922
Batch 22/64 loss: -0.24238967895507812
Batch 23/64 loss: -0.36573028564453125
Batch 24/64 loss: -0.42552757263183594
Batch 25/64 loss: -0.544743537902832
Batch 26/64 loss: -0.2687969207763672
Batch 27/64 loss: -0.3014087677001953
Batch 28/64 loss: -0.5035381317138672
Batch 29/64 loss: -0.6977920532226562
Batch 30/64 loss: -0.6553993225097656
Batch 31/64 loss: -0.5451526641845703
Batch 32/64 loss: -0.4655141830444336
Batch 33/64 loss: 0.4213886260986328
Batch 34/64 loss: -0.7040824890136719
Batch 35/64 loss: -0.16327953338623047
Batch 36/64 loss: -0.6599216461181641
Batch 37/64 loss: -0.45444202423095703
Batch 38/64 loss: -0.5433120727539062
Batch 39/64 loss: -0.6363096237182617
Batch 40/64 loss: -0.6010751724243164
Batch 41/64 loss: -0.42423248291015625
Batch 42/64 loss: -0.30457115173339844
Batch 43/64 loss: 0.11873626708984375
Batch 44/64 loss: -0.4309854507446289
Batch 45/64 loss: 0.954193115234375
Batch 46/64 loss: -0.36070919036865234
Batch 47/64 loss: -0.7184200286865234
Batch 48/64 loss: -0.18309688568115234
Batch 49/64 loss: -0.5681562423706055
Batch 50/64 loss: -0.5286273956298828
Batch 51/64 loss: 0.048919677734375
Batch 52/64 loss: -0.3761758804321289
Batch 53/64 loss: -0.3443107604980469
Batch 54/64 loss: -0.5717906951904297
Batch 55/64 loss: 0.02350330352783203
Batch 56/64 loss: -0.5218114852905273
Batch 57/64 loss: -0.6815671920776367
Batch 58/64 loss: -0.8924493789672852
Batch 59/64 loss: 1.654423713684082
Batch 60/64 loss: -0.3949899673461914
Batch 61/64 loss: -0.4714469909667969
Batch 62/64 loss: 0.1642618179321289
Batch 63/64 loss: -0.42836475372314453
Batch 64/64 loss: -4.229097366333008
Epoch 40  Train loss: -0.4123560811959061  Val loss: 1.2369985940939783
Epoch 41
-------------------------------
Batch 1/64 loss: -0.1724386215209961
Batch 2/64 loss: -0.21451568603515625
Batch 3/64 loss: -0.4871969223022461
Batch 4/64 loss: 0.18984222412109375
Batch 5/64 loss: -0.28375911712646484
Batch 6/64 loss: -0.7155570983886719
Batch 7/64 loss: -0.36568737030029297
Batch 8/64 loss: -0.2614717483520508
Batch 9/64 loss: -0.2494974136352539
Batch 10/64 loss: -0.4355964660644531
Batch 11/64 loss: -0.34920787811279297
Batch 12/64 loss: -0.3023853302001953
Batch 13/64 loss: -0.4291191101074219
Batch 14/64 loss: -0.5703983306884766
Batch 15/64 loss: -0.10053634643554688
Batch 16/64 loss: -0.42029476165771484
Batch 17/64 loss: -0.3374214172363281
Batch 18/64 loss: -0.35334014892578125
Batch 19/64 loss: -0.5438308715820312
Batch 20/64 loss: -0.4234437942504883
Batch 21/64 loss: -0.31132984161376953
Batch 22/64 loss: -0.4474630355834961
Batch 23/64 loss: -0.4110565185546875
Batch 24/64 loss: 0.03335380554199219
Batch 25/64 loss: 0.06595516204833984
Batch 26/64 loss: -0.7473239898681641
Batch 27/64 loss: -0.4479560852050781
Batch 28/64 loss: -0.26424312591552734
Batch 29/64 loss: -0.37869834899902344
Batch 30/64 loss: -0.5722694396972656
Batch 31/64 loss: -0.8037805557250977
Batch 32/64 loss: -0.09449958801269531
Batch 33/64 loss: -0.6652946472167969
Batch 34/64 loss: -0.1954965591430664
Batch 35/64 loss: -0.7031641006469727
Batch 36/64 loss: -0.7086639404296875
Batch 37/64 loss: -0.45038604736328125
Batch 38/64 loss: 0.11910629272460938
Batch 39/64 loss: -0.6704616546630859
Batch 40/64 loss: 0.02075481414794922
Batch 41/64 loss: -0.6144990921020508
Batch 42/64 loss: 0.5262737274169922
Batch 43/64 loss: -0.5470876693725586
Batch 44/64 loss: -0.09603500366210938
Batch 45/64 loss: -0.5258445739746094
Batch 46/64 loss: -0.15807342529296875
Batch 47/64 loss: -0.9551334381103516
Batch 48/64 loss: -0.17282867431640625
Batch 49/64 loss: -0.4352397918701172
Batch 50/64 loss: -0.33359241485595703
Batch 51/64 loss: -0.49211597442626953
Batch 52/64 loss: -0.6809720993041992
Batch 53/64 loss: -0.44110965728759766
Batch 54/64 loss: -0.6927003860473633
Batch 55/64 loss: -0.6344137191772461
Batch 56/64 loss: -0.460540771484375
Batch 57/64 loss: -0.5200605392456055
Batch 58/64 loss: -0.5151443481445312
Batch 59/64 loss: -0.7337665557861328
Batch 60/64 loss: -0.17296791076660156
Batch 61/64 loss: -0.5737447738647461
Batch 62/64 loss: -0.17148399353027344
Batch 63/64 loss: -0.6022520065307617
Batch 64/64 loss: -4.108331680297852
Epoch 41  Train loss: -0.4320526347440832  Val loss: -0.6774558496639081
Saving best model, epoch: 41
Epoch 42
-------------------------------
Batch 1/64 loss: -0.05063152313232422
Batch 2/64 loss: -0.598750114440918
Batch 3/64 loss: -0.6658306121826172
Batch 4/64 loss: -0.2307424545288086
Batch 5/64 loss: -0.7763433456420898
Batch 6/64 loss: -0.6810579299926758
Batch 7/64 loss: -0.22577476501464844
Batch 8/64 loss: -0.1264181137084961
Batch 9/64 loss: -0.723419189453125
Batch 10/64 loss: -0.27843475341796875
Batch 11/64 loss: -0.6302652359008789
Batch 12/64 loss: -0.79730224609375
Batch 13/64 loss: -0.7007265090942383
Batch 14/64 loss: -0.8187408447265625
Batch 15/64 loss: -0.5338497161865234
Batch 16/64 loss: -0.6162967681884766
Batch 17/64 loss: -0.5973262786865234
Batch 18/64 loss: -0.5322046279907227
Batch 19/64 loss: -0.6231374740600586
Batch 20/64 loss: -0.4053678512573242
Batch 21/64 loss: 0.0740957260131836
Batch 22/64 loss: -0.33544063568115234
Batch 23/64 loss: -0.7966699600219727
Batch 24/64 loss: -0.2085256576538086
Batch 25/64 loss: -0.07857799530029297
Batch 26/64 loss: -0.4791069030761719
Batch 27/64 loss: -0.6309919357299805
Batch 28/64 loss: -0.8922052383422852
Batch 29/64 loss: -0.5685644149780273
Batch 30/64 loss: -0.3897848129272461
Batch 31/64 loss: -0.7499628067016602
Batch 32/64 loss: -0.6216659545898438
Batch 33/64 loss: -0.5351076126098633
Batch 34/64 loss: -0.20254802703857422
Batch 35/64 loss: -0.10605049133300781
Batch 36/64 loss: -0.2739715576171875
Batch 37/64 loss: -0.32202816009521484
Batch 38/64 loss: -0.013461112976074219
Batch 39/64 loss: -0.6255054473876953
Batch 40/64 loss: -0.3858022689819336
Batch 41/64 loss: -0.17427921295166016
Batch 42/64 loss: -0.2026824951171875
Batch 43/64 loss: -0.6741819381713867
Batch 44/64 loss: -0.4596271514892578
Batch 45/64 loss: -0.19388675689697266
Batch 46/64 loss: -0.35288047790527344
Batch 47/64 loss: -0.27263450622558594
Batch 48/64 loss: -0.42542552947998047
Batch 49/64 loss: -0.2999095916748047
Batch 50/64 loss: -0.48580360412597656
Batch 51/64 loss: -0.26856231689453125
Batch 52/64 loss: -0.40244293212890625
Batch 53/64 loss: -0.16251373291015625
Batch 54/64 loss: -0.5469942092895508
Batch 55/64 loss: -0.3503446578979492
Batch 56/64 loss: -0.6296730041503906
Batch 57/64 loss: -0.6231460571289062
Batch 58/64 loss: -0.606806755065918
Batch 59/64 loss: -0.6288824081420898
Batch 60/64 loss: -0.34224700927734375
Batch 61/64 loss: -0.6044197082519531
Batch 62/64 loss: -0.2600889205932617
Batch 63/64 loss: -0.5844049453735352
Batch 64/64 loss: -4.287088394165039
Epoch 42  Train loss: -0.49445725235284543  Val loss: -0.5882967132882974
Epoch 43
-------------------------------
Batch 1/64 loss: -0.4980335235595703
Batch 2/64 loss: -0.4271507263183594
Batch 3/64 loss: -0.008906364440917969
Batch 4/64 loss: -0.6100397109985352
Batch 5/64 loss: 0.1910848617553711
Batch 6/64 loss: -0.6199865341186523
Batch 7/64 loss: -0.37592411041259766
Batch 8/64 loss: -0.41843509674072266
Batch 9/64 loss: -0.659881591796875
Batch 10/64 loss: -0.7854976654052734
Batch 11/64 loss: -0.5432825088500977
Batch 12/64 loss: -0.5338363647460938
Batch 13/64 loss: -0.49604034423828125
Batch 14/64 loss: -0.6530561447143555
Batch 15/64 loss: -0.7144174575805664
Batch 16/64 loss: -0.6284580230712891
Batch 17/64 loss: -0.25341320037841797
Batch 18/64 loss: -0.8508815765380859
Batch 19/64 loss: -0.8928518295288086
Batch 20/64 loss: -0.40430736541748047
Batch 21/64 loss: -0.9213542938232422
Batch 22/64 loss: -0.2569761276245117
Batch 23/64 loss: -0.033074378967285156
Batch 24/64 loss: -0.3981924057006836
Batch 25/64 loss: -0.5700101852416992
Batch 26/64 loss: -0.5247278213500977
Batch 27/64 loss: -0.7290325164794922
Batch 28/64 loss: -0.6578474044799805
Batch 29/64 loss: 0.05778694152832031
Batch 30/64 loss: -0.6457700729370117
Batch 31/64 loss: -0.23172760009765625
Batch 32/64 loss: -0.045925140380859375
Batch 33/64 loss: -0.6477603912353516
Batch 34/64 loss: -0.630859375
Batch 35/64 loss: -0.6737022399902344
Batch 36/64 loss: -0.6294469833374023
Batch 37/64 loss: -0.4404153823852539
Batch 38/64 loss: -0.25611019134521484
Batch 39/64 loss: -0.6173982620239258
Batch 40/64 loss: 0.24417400360107422
Batch 41/64 loss: -0.5540256500244141
Batch 42/64 loss: -0.6261444091796875
Batch 43/64 loss: -0.21615123748779297
Batch 44/64 loss: -0.5233821868896484
Batch 45/64 loss: -0.5269575119018555
Batch 46/64 loss: -0.6134347915649414
Batch 47/64 loss: -0.20461368560791016
Batch 48/64 loss: -0.5003900527954102
Batch 49/64 loss: -0.5393056869506836
Batch 50/64 loss: -0.6017360687255859
Batch 51/64 loss: -0.5298604965209961
Batch 52/64 loss: -0.39961910247802734
Batch 53/64 loss: -0.9313192367553711
Batch 54/64 loss: -0.3580760955810547
Batch 55/64 loss: -0.4186086654663086
Batch 56/64 loss: -0.6956167221069336
Batch 57/64 loss: -0.47926998138427734
Batch 58/64 loss: -0.40644264221191406
Batch 59/64 loss: -0.5578594207763672
Batch 60/64 loss: -0.3243389129638672
Batch 61/64 loss: -0.2657155990600586
Batch 62/64 loss: -0.13490581512451172
Batch 63/64 loss: -0.28452491760253906
Batch 64/64 loss: -3.7758874893188477
Epoch 43  Train loss: -0.5069160723218731  Val loss: -0.05223782201812849
Epoch 44
-------------------------------
Batch 1/64 loss: -0.20384693145751953
Batch 2/64 loss: -0.6804084777832031
Batch 3/64 loss: -0.7470073699951172
Batch 4/64 loss: -0.20475196838378906
Batch 5/64 loss: -0.021305084228515625
Batch 6/64 loss: -0.4919910430908203
Batch 7/64 loss: -0.5149517059326172
Batch 8/64 loss: -0.5644931793212891
Batch 9/64 loss: -0.8616151809692383
Batch 10/64 loss: -0.02144336700439453
Batch 11/64 loss: -0.4144477844238281
Batch 12/64 loss: -0.42583560943603516
Batch 13/64 loss: -0.6914710998535156
Batch 14/64 loss: -0.39535999298095703
Batch 15/64 loss: -0.6278543472290039
Batch 16/64 loss: -0.45932960510253906
Batch 17/64 loss: -0.6132612228393555
Batch 18/64 loss: -0.4609098434448242
Batch 19/64 loss: -0.535771369934082
Batch 20/64 loss: -0.027227401733398438
Batch 21/64 loss: -0.6423807144165039
Batch 22/64 loss: -0.7641592025756836
Batch 23/64 loss: -0.2416677474975586
Batch 24/64 loss: -0.4372596740722656
Batch 25/64 loss: -0.33203125
Batch 26/64 loss: -0.6839170455932617
Batch 27/64 loss: -0.3087892532348633
Batch 28/64 loss: -0.8077325820922852
Batch 29/64 loss: -0.17030715942382812
Batch 30/64 loss: -0.48238563537597656
Batch 31/64 loss: -0.4421806335449219
Batch 32/64 loss: -0.709197998046875
Batch 33/64 loss: -0.6843242645263672
Batch 34/64 loss: -0.4924306869506836
Batch 35/64 loss: -0.6097040176391602
Batch 36/64 loss: -0.40036487579345703
Batch 37/64 loss: -0.7952337265014648
Batch 38/64 loss: -0.8091630935668945
Batch 39/64 loss: -0.5230798721313477
Batch 40/64 loss: -0.5407896041870117
Batch 41/64 loss: -0.8532495498657227
Batch 42/64 loss: -0.25841331481933594
Batch 43/64 loss: -0.5074176788330078
Batch 44/64 loss: -0.5841550827026367
Batch 45/64 loss: -0.5251789093017578
Batch 46/64 loss: -0.08088874816894531
Batch 47/64 loss: -0.5775747299194336
Batch 48/64 loss: -0.04263782501220703
Batch 49/64 loss: -0.6578855514526367
Batch 50/64 loss: -0.6540279388427734
Batch 51/64 loss: -0.3372611999511719
Batch 52/64 loss: -0.0831918716430664
Batch 53/64 loss: -0.5720624923706055
Batch 54/64 loss: -0.29250335693359375
Batch 55/64 loss: -0.3980121612548828
Batch 56/64 loss: -0.6252317428588867
Batch 57/64 loss: -0.1516275405883789
Batch 58/64 loss: -0.07781982421875
Batch 59/64 loss: 0.08818721771240234
Batch 60/64 loss: -0.5613565444946289
Batch 61/64 loss: -0.42455577850341797
Batch 62/64 loss: -0.3321714401245117
Batch 63/64 loss: -0.5306615829467773
Batch 64/64 loss: -4.194752216339111
Epoch 44  Train loss: -0.5023708773594276  Val loss: -0.6406518864058137
Epoch 45
-------------------------------
Batch 1/64 loss: 0.5581903457641602
Batch 2/64 loss: -0.4396944046020508
Batch 3/64 loss: -0.4930267333984375
Batch 4/64 loss: -0.37580013275146484
Batch 5/64 loss: -0.2393779754638672
Batch 6/64 loss: -0.5088663101196289
Batch 7/64 loss: -0.28682613372802734
Batch 8/64 loss: -0.4413919448852539
Batch 9/64 loss: -0.6747226715087891
Batch 10/64 loss: -0.667475700378418
Batch 11/64 loss: -0.7535715103149414
Batch 12/64 loss: -0.23005294799804688
Batch 13/64 loss: -0.21537494659423828
Batch 14/64 loss: -0.5067453384399414
Batch 15/64 loss: -0.23165321350097656
Batch 16/64 loss: -0.5757923126220703
Batch 17/64 loss: -0.5589361190795898
Batch 18/64 loss: -0.46956539154052734
Batch 19/64 loss: -0.7446651458740234
Batch 20/64 loss: -0.3103647232055664
Batch 21/64 loss: -0.8877449035644531
Batch 22/64 loss: -0.5049648284912109
Batch 23/64 loss: -0.28639793395996094
Batch 24/64 loss: -0.8117227554321289
Batch 25/64 loss: -0.5748939514160156
Batch 26/64 loss: -0.7070455551147461
Batch 27/64 loss: -0.18596744537353516
Batch 28/64 loss: -0.6526060104370117
Batch 29/64 loss: -0.32252979278564453
Batch 30/64 loss: -0.64599609375
Batch 31/64 loss: -0.33204078674316406
Batch 32/64 loss: -0.6643028259277344
Batch 33/64 loss: -0.03970146179199219
Batch 34/64 loss: -0.696995735168457
Batch 35/64 loss: -0.2841157913208008
Batch 36/64 loss: -0.8903293609619141
Batch 37/64 loss: -0.6678543090820312
Batch 38/64 loss: -0.6921253204345703
Batch 39/64 loss: -0.5979957580566406
Batch 40/64 loss: -0.8824481964111328
Batch 41/64 loss: -0.865727424621582
Batch 42/64 loss: -0.9025154113769531
Batch 43/64 loss: -0.573455810546875
Batch 44/64 loss: -0.39074039459228516
Batch 45/64 loss: -0.5609588623046875
Batch 46/64 loss: -0.515355110168457
Batch 47/64 loss: -0.550994873046875
Batch 48/64 loss: -0.11630916595458984
Batch 49/64 loss: -0.9366884231567383
Batch 50/64 loss: -0.2532176971435547
Batch 51/64 loss: -0.7573099136352539
Batch 52/64 loss: -0.6262617111206055
Batch 53/64 loss: -0.6792936325073242
Batch 54/64 loss: -0.614750862121582
Batch 55/64 loss: -0.6786231994628906
Batch 56/64 loss: -0.5760259628295898
Batch 57/64 loss: -0.4763984680175781
Batch 58/64 loss: -0.013577461242675781
Batch 59/64 loss: -0.7706060409545898
Batch 60/64 loss: 0.16778564453125
Batch 61/64 loss: -0.5520524978637695
Batch 62/64 loss: 0.0716543197631836
Batch 63/64 loss: -0.6364202499389648
Batch 64/64 loss: -4.221793174743652
Epoch 45  Train loss: -0.5406694935817344  Val loss: -0.4799529137889954
Epoch 46
-------------------------------
Batch 1/64 loss: -0.7738113403320312
Batch 2/64 loss: -0.7878284454345703
Batch 3/64 loss: -0.5118494033813477
Batch 4/64 loss: -0.13683319091796875
Batch 5/64 loss: -0.6228809356689453
Batch 6/64 loss: -0.5636768341064453
Batch 7/64 loss: -0.5166406631469727
Batch 8/64 loss: -0.6131620407104492
Batch 9/64 loss: -0.5892400741577148
Batch 10/64 loss: -0.8435087203979492
Batch 11/64 loss: -0.8900690078735352
Batch 12/64 loss: 0.2542734146118164
Batch 13/64 loss: -0.758885383605957
Batch 14/64 loss: -0.6650495529174805
Batch 15/64 loss: 0.43472862243652344
Batch 16/64 loss: -0.8286418914794922
Batch 17/64 loss: -0.8582916259765625
Batch 18/64 loss: -0.6761226654052734
Batch 19/64 loss: -0.49638938903808594
Batch 20/64 loss: -0.19867610931396484
Batch 21/64 loss: -0.5791215896606445
Batch 22/64 loss: -0.6991825103759766
Batch 23/64 loss: 0.1565532684326172
Batch 24/64 loss: -0.1839466094970703
Batch 25/64 loss: -0.43601417541503906
Batch 26/64 loss: -0.7409658432006836
Batch 27/64 loss: -0.8069982528686523
Batch 28/64 loss: -0.7853965759277344
Batch 29/64 loss: -0.23931503295898438
Batch 30/64 loss: -0.5622358322143555
Batch 31/64 loss: -0.12934398651123047
Batch 32/64 loss: -0.6424760818481445
Batch 33/64 loss: -0.19515514373779297
Batch 34/64 loss: -0.13116073608398438
Batch 35/64 loss: -0.7494382858276367
Batch 36/64 loss: -0.683232307434082
Batch 37/64 loss: -0.567927360534668
Batch 38/64 loss: -0.42319297790527344
Batch 39/64 loss: -0.3505716323852539
Batch 40/64 loss: -0.24072837829589844
Batch 41/64 loss: -0.9419240951538086
Batch 42/64 loss: 0.08725261688232422
Batch 43/64 loss: 0.08609676361083984
Batch 44/64 loss: -0.7107353210449219
Batch 45/64 loss: -0.40964412689208984
Batch 46/64 loss: -0.04940032958984375
Batch 47/64 loss: 0.31839466094970703
Batch 48/64 loss: -0.833287239074707
Batch 49/64 loss: -0.2794685363769531
Batch 50/64 loss: -0.8413820266723633
Batch 51/64 loss: 0.6640472412109375
Batch 52/64 loss: -0.7469301223754883
Batch 53/64 loss: -0.3311195373535156
Batch 54/64 loss: -0.8325405120849609
Batch 55/64 loss: -0.3672008514404297
Batch 56/64 loss: 0.06941413879394531
Batch 57/64 loss: -0.3306312561035156
Batch 58/64 loss: -0.18433475494384766
Batch 59/64 loss: -0.43457603454589844
Batch 60/64 loss: 0.2925138473510742
Batch 61/64 loss: -0.5032529830932617
Batch 62/64 loss: -0.6945314407348633
Batch 63/64 loss: 0.13389873504638672
Batch 64/64 loss: -3.931950569152832
Epoch 46  Train loss: -0.4615013234755572  Val loss: -0.3557135460712656
Epoch 47
-------------------------------
Batch 1/64 loss: -0.16793346405029297
Batch 2/64 loss: -0.5455112457275391
Batch 3/64 loss: -0.555145263671875
Batch 4/64 loss: -0.7614603042602539
Batch 5/64 loss: -0.20204734802246094
Batch 6/64 loss: -0.7392034530639648
Batch 7/64 loss: -0.5952529907226562
Batch 8/64 loss: -0.6658973693847656
Batch 9/64 loss: 0.4736757278442383
Batch 10/64 loss: -0.933013916015625
Batch 11/64 loss: -0.6806573867797852
Batch 12/64 loss: -0.8058547973632812
Batch 13/64 loss: -0.34896087646484375
Batch 14/64 loss: -0.47879791259765625
Batch 15/64 loss: -0.9171352386474609
Batch 16/64 loss: -0.4798927307128906
Batch 17/64 loss: -0.13614177703857422
Batch 18/64 loss: -0.7470207214355469
Batch 19/64 loss: -0.3044576644897461
Batch 20/64 loss: -0.31331729888916016
Batch 21/64 loss: -0.5816106796264648
Batch 22/64 loss: -0.3269233703613281
Batch 23/64 loss: -1.0344533920288086
Batch 24/64 loss: 0.3176279067993164
Batch 25/64 loss: -0.6030054092407227
Batch 26/64 loss: -0.522313117980957
Batch 27/64 loss: -0.42664337158203125
Batch 28/64 loss: -0.29258060455322266
Batch 29/64 loss: -0.46454715728759766
Batch 30/64 loss: 0.37694644927978516
Batch 31/64 loss: 0.12193584442138672
Batch 32/64 loss: -0.008742332458496094
Batch 33/64 loss: -0.6508026123046875
Batch 34/64 loss: -0.3128690719604492
Batch 35/64 loss: -0.4263038635253906
Batch 36/64 loss: -0.2712421417236328
Batch 37/64 loss: -0.5725984573364258
Batch 38/64 loss: -0.5949869155883789
Batch 39/64 loss: -0.4602365493774414
Batch 40/64 loss: -0.17017364501953125
Batch 41/64 loss: -0.00305938720703125
Batch 42/64 loss: -0.09427070617675781
Batch 43/64 loss: -0.4730825424194336
Batch 44/64 loss: 0.4072561264038086
Batch 45/64 loss: -0.3692359924316406
Batch 46/64 loss: -0.1919870376586914
Batch 47/64 loss: 1.1960744857788086
Batch 48/64 loss: -0.36406612396240234
Batch 49/64 loss: 0.4152402877807617
Batch 50/64 loss: 1.4320993423461914
Batch 51/64 loss: -0.20404052734375
Batch 52/64 loss: 0.8022575378417969
Batch 53/64 loss: 1.3195600509643555
Batch 54/64 loss: 0.13969802856445312
Batch 55/64 loss: 0.6716766357421875
Batch 56/64 loss: 0.0166473388671875
Batch 57/64 loss: -0.06999969482421875
Batch 58/64 loss: -0.19301700592041016
Batch 59/64 loss: -0.43025684356689453
Batch 60/64 loss: 0.34428977966308594
Batch 61/64 loss: 0.1286029815673828
Batch 62/64 loss: -0.7033166885375977
Batch 63/64 loss: 0.7455072402954102
Batch 64/64 loss: -3.2940549850463867
Epoch 47  Train loss: -0.2314590192308613  Val loss: 0.4362511126855804
Epoch 48
-------------------------------
Batch 1/64 loss: 0.28222179412841797
Batch 2/64 loss: -0.40218162536621094
Batch 3/64 loss: -0.06255626678466797
Batch 4/64 loss: -0.0360260009765625
Batch 5/64 loss: 0.11049365997314453
Batch 6/64 loss: -0.19176673889160156
Batch 7/64 loss: -0.1153249740600586
Batch 8/64 loss: 0.80767822265625
Batch 9/64 loss: -0.369873046875
Batch 10/64 loss: 0.1430225372314453
Batch 11/64 loss: -0.09958839416503906
Batch 12/64 loss: -0.3475027084350586
Batch 13/64 loss: -0.35741424560546875
Batch 14/64 loss: -0.5205097198486328
Batch 15/64 loss: 0.48480892181396484
Batch 16/64 loss: -0.47255802154541016
Batch 17/64 loss: -0.2934608459472656
Batch 18/64 loss: 0.7902011871337891
Batch 19/64 loss: -0.07903003692626953
Batch 20/64 loss: 0.16604137420654297
Batch 21/64 loss: 0.04966449737548828
Batch 22/64 loss: -0.2847919464111328
Batch 23/64 loss: 0.9182529449462891
Batch 24/64 loss: -0.014245033264160156
Batch 25/64 loss: 0.27056312561035156
Batch 26/64 loss: 1.0853796005249023
Batch 27/64 loss: 0.19443893432617188
Batch 28/64 loss: -0.3969144821166992
Batch 29/64 loss: 0.8428249359130859
Batch 30/64 loss: 0.0771036148071289
Batch 31/64 loss: -0.7103376388549805
Batch 32/64 loss: 0.6460866928100586
Batch 33/64 loss: -0.6195402145385742
Batch 34/64 loss: -0.3532075881958008
Batch 35/64 loss: -0.4200935363769531
Batch 36/64 loss: -0.022873878479003906
Batch 37/64 loss: -0.27895069122314453
Batch 38/64 loss: -0.5598516464233398
Batch 39/64 loss: 0.41234874725341797
Batch 40/64 loss: 0.43343162536621094
Batch 41/64 loss: -0.37772464752197266
Batch 42/64 loss: -0.6358966827392578
Batch 43/64 loss: -0.1680583953857422
Batch 44/64 loss: -0.4732027053833008
Batch 45/64 loss: -0.6354246139526367
Batch 46/64 loss: -0.2803316116333008
Batch 47/64 loss: -0.547607421875
Batch 48/64 loss: -0.4720935821533203
Batch 49/64 loss: -0.5857877731323242
Batch 50/64 loss: -0.06559371948242188
Batch 51/64 loss: -0.577387809753418
Batch 52/64 loss: -0.4899482727050781
Batch 53/64 loss: 0.16514015197753906
Batch 54/64 loss: -0.42357921600341797
Batch 55/64 loss: -0.3688993453979492
Batch 56/64 loss: -0.6139984130859375
Batch 57/64 loss: -0.1232452392578125
Batch 58/64 loss: -0.3946533203125
Batch 59/64 loss: -0.4472074508666992
Batch 60/64 loss: -0.38593482971191406
Batch 61/64 loss: -0.49431705474853516
Batch 62/64 loss: 0.5085296630859375
Batch 63/64 loss: -0.26174068450927734
Batch 64/64 loss: -4.618756294250488
Epoch 48  Train loss: -0.17109124800738165  Val loss: 0.16193953576366515
Epoch 49
-------------------------------
Batch 1/64 loss: 0.08718395233154297
Batch 2/64 loss: 0.015049934387207031
Batch 3/64 loss: -0.6007423400878906
Batch 4/64 loss: 0.093841552734375
Batch 5/64 loss: -0.24381542205810547
Batch 6/64 loss: 0.7808504104614258
Batch 7/64 loss: -0.2665719985961914
Batch 8/64 loss: -0.1897745132446289
Batch 9/64 loss: -0.5964527130126953
Batch 10/64 loss: 0.48628902435302734
Batch 11/64 loss: -0.0023870468139648438
Batch 12/64 loss: 0.6105794906616211
Batch 13/64 loss: -0.2562131881713867
Batch 14/64 loss: 0.5658054351806641
Batch 15/64 loss: 1.6253242492675781
Batch 16/64 loss: 0.008235931396484375
Batch 17/64 loss: -0.5144453048706055
Batch 18/64 loss: -0.5587425231933594
Batch 19/64 loss: -0.34020328521728516
Batch 20/64 loss: -0.15030956268310547
Batch 21/64 loss: 0.011590003967285156
Batch 22/64 loss: -0.4697751998901367
Batch 23/64 loss: -0.29889869689941406
Batch 24/64 loss: -0.3833341598510742
Batch 25/64 loss: 0.14270401000976562
Batch 26/64 loss: -0.11892414093017578
Batch 27/64 loss: 0.1739959716796875
Batch 28/64 loss: -0.4415140151977539
Batch 29/64 loss: 0.6133012771606445
Batch 30/64 loss: -0.4747629165649414
Batch 31/64 loss: 0.2367115020751953
Batch 32/64 loss: 0.008061408996582031
Batch 33/64 loss: 0.07628917694091797
Batch 34/64 loss: -0.1119680404663086
Batch 35/64 loss: -0.34852123260498047
Batch 36/64 loss: 0.237823486328125
Batch 37/64 loss: -0.21517467498779297
Batch 38/64 loss: -0.13595294952392578
Batch 39/64 loss: 0.0414276123046875
Batch 40/64 loss: 0.5785932540893555
Batch 41/64 loss: 0.19498729705810547
Batch 42/64 loss: -0.0792074203491211
Batch 43/64 loss: 0.06430435180664062
Batch 44/64 loss: -0.2814159393310547
Batch 45/64 loss: 0.10230255126953125
Batch 46/64 loss: -0.25339317321777344
Batch 47/64 loss: -0.3869791030883789
Batch 48/64 loss: -0.42102813720703125
Batch 49/64 loss: -0.3156108856201172
Batch 50/64 loss: -0.24543380737304688
Batch 51/64 loss: -0.2933616638183594
Batch 52/64 loss: -0.1235799789428711
Batch 53/64 loss: 0.5595216751098633
Batch 54/64 loss: 0.4444732666015625
Batch 55/64 loss: -0.4846000671386719
Batch 56/64 loss: -0.2880239486694336
Batch 57/64 loss: -0.35284900665283203
Batch 58/64 loss: -0.24229812622070312
Batch 59/64 loss: -0.04533958435058594
Batch 60/64 loss: -0.4641437530517578
Batch 61/64 loss: -0.4266471862792969
Batch 62/64 loss: 0.22415637969970703
Batch 63/64 loss: -0.5237016677856445
Batch 64/64 loss: -4.390376091003418
Epoch 49  Train loss: -0.11381139194264131  Val loss: -0.34551687338917525
Epoch 50
-------------------------------
Batch 1/64 loss: -0.1599874496459961
Batch 2/64 loss: -0.32183837890625
Batch 3/64 loss: -0.3076314926147461
Batch 4/64 loss: -0.28925514221191406
Batch 5/64 loss: -0.3579063415527344
Batch 6/64 loss: -0.12710094451904297
Batch 7/64 loss: -0.7625722885131836
Batch 8/64 loss: -0.7437763214111328
Batch 9/64 loss: 0.4724559783935547
Batch 10/64 loss: 0.17233943939208984
Batch 11/64 loss: -0.5414800643920898
Batch 12/64 loss: -0.1195669174194336
Batch 13/64 loss: -0.6244668960571289
Batch 14/64 loss: -0.1390085220336914
Batch 15/64 loss: -0.5109357833862305
Batch 16/64 loss: -0.25804710388183594
Batch 17/64 loss: -0.31009674072265625
Batch 18/64 loss: 0.014090538024902344
Batch 19/64 loss: -0.44237804412841797
Batch 20/64 loss: -0.011548995971679688
Batch 21/64 loss: -0.28101062774658203
Batch 22/64 loss: 1.3091850280761719
Batch 23/64 loss: 0.5552644729614258
Batch 24/64 loss: -0.061285972595214844
Batch 25/64 loss: -0.5175104141235352
Batch 26/64 loss: -0.5724582672119141
Batch 27/64 loss: -0.4234914779663086
Batch 28/64 loss: -0.44168758392333984
Batch 29/64 loss: -0.5453701019287109
Batch 30/64 loss: -0.17293262481689453
Batch 31/64 loss: -0.16283321380615234
Batch 32/64 loss: 0.3200387954711914
Batch 33/64 loss: -0.5094079971313477
Batch 34/64 loss: -0.33763885498046875
Batch 35/64 loss: -0.37444114685058594
Batch 36/64 loss: -0.35851001739501953
Batch 37/64 loss: 0.0019216537475585938
Batch 38/64 loss: 0.8398628234863281
Batch 39/64 loss: 0.833343505859375
Batch 40/64 loss: -0.5282468795776367
Batch 41/64 loss: 0.32270240783691406
Batch 42/64 loss: 0.7786703109741211
Batch 43/64 loss: 0.0075702667236328125
Batch 44/64 loss: 0.059645652770996094
Batch 45/64 loss: -0.5123863220214844
Batch 46/64 loss: 0.2755403518676758
Batch 47/64 loss: -0.14336585998535156
Batch 48/64 loss: -0.5171661376953125
Batch 49/64 loss: 0.052478790283203125
Batch 50/64 loss: 0.08282852172851562
Batch 51/64 loss: -0.3122978210449219
Batch 52/64 loss: -0.12776470184326172
Batch 53/64 loss: 0.462066650390625
Batch 54/64 loss: -0.3616342544555664
Batch 55/64 loss: -0.14188575744628906
Batch 56/64 loss: -0.15251445770263672
Batch 57/64 loss: 0.07412910461425781
Batch 58/64 loss: -0.19565200805664062
Batch 59/64 loss: -0.46120166778564453
Batch 60/64 loss: -0.7061223983764648
Batch 61/64 loss: -0.9018211364746094
Batch 62/64 loss: 0.2150726318359375
Batch 63/64 loss: -0.16022777557373047
Batch 64/64 loss: -4.712929725646973
Epoch 50  Train loss: -0.1991208356969497  Val loss: -0.16396226915706882
Epoch 51
-------------------------------
Batch 1/64 loss: -0.3520059585571289
Batch 2/64 loss: -0.6072502136230469
Batch 3/64 loss: -0.6165943145751953
Batch 4/64 loss: -0.35398101806640625
Batch 5/64 loss: -0.5118179321289062
Batch 6/64 loss: 0.5287981033325195
Batch 7/64 loss: -0.47864818572998047
Batch 8/64 loss: -0.7447595596313477
Batch 9/64 loss: 0.17886066436767578
Batch 10/64 loss: -0.2532482147216797
Batch 11/64 loss: 1.5764646530151367
Batch 12/64 loss: -0.4519948959350586
Batch 13/64 loss: -0.3444252014160156
Batch 14/64 loss: -0.43609619140625
Batch 15/64 loss: 0.7503929138183594
Batch 16/64 loss: -0.16947174072265625
Batch 17/64 loss: -0.32761287689208984
Batch 18/64 loss: 0.13898468017578125
Batch 19/64 loss: -0.36518192291259766
Batch 20/64 loss: 0.5583229064941406
Batch 21/64 loss: -0.39460182189941406
Batch 22/64 loss: 0.6295270919799805
Batch 23/64 loss: 0.8154487609863281
Batch 24/64 loss: -0.5054407119750977
Batch 25/64 loss: -0.3867015838623047
Batch 26/64 loss: 0.2768974304199219
Batch 27/64 loss: -0.34906864166259766
Batch 28/64 loss: 0.47402191162109375
Batch 29/64 loss: -0.16697216033935547
Batch 30/64 loss: -0.7056255340576172
Batch 31/64 loss: 0.3290519714355469
Batch 32/64 loss: 0.11442089080810547
Batch 33/64 loss: -0.35907936096191406
Batch 34/64 loss: -0.26809120178222656
Batch 35/64 loss: -0.4933938980102539
Batch 36/64 loss: -0.6236553192138672
Batch 37/64 loss: -0.5715751647949219
Batch 38/64 loss: -0.10126495361328125
Batch 39/64 loss: 0.7786064147949219
Batch 40/64 loss: -0.0980367660522461
Batch 41/64 loss: 0.2655200958251953
Batch 42/64 loss: -0.874323844909668
Batch 43/64 loss: -0.5272951126098633
Batch 44/64 loss: -0.49851512908935547
Batch 45/64 loss: -0.5115594863891602
Batch 46/64 loss: -0.37145233154296875
Batch 47/64 loss: -0.3499279022216797
Batch 48/64 loss: 0.9599428176879883
Batch 49/64 loss: -0.6077890396118164
Batch 50/64 loss: 1.2565851211547852
Batch 51/64 loss: -0.039521217346191406
Batch 52/64 loss: -0.17441272735595703
Batch 53/64 loss: -0.0904684066772461
Batch 54/64 loss: -0.47014331817626953
Batch 55/64 loss: 0.12998294830322266
Batch 56/64 loss: -0.4138975143432617
Batch 57/64 loss: 0.28557491302490234
Batch 58/64 loss: -0.279632568359375
Batch 59/64 loss: 0.08007621765136719
Batch 60/64 loss: -0.4042854309082031
Batch 61/64 loss: -0.39852237701416016
Batch 62/64 loss: -0.17270946502685547
Batch 63/64 loss: -0.28931427001953125
Batch 64/64 loss: -4.300800323486328
Epoch 51  Train loss: -0.16640761132333792  Val loss: -0.10204957522887134
Epoch 52
-------------------------------
Batch 1/64 loss: 0.2352132797241211
Batch 2/64 loss: -0.2990074157714844
Batch 3/64 loss: -0.1819772720336914
Batch 4/64 loss: -0.5407266616821289
Batch 5/64 loss: 0.3957662582397461
Batch 6/64 loss: -0.0161895751953125
Batch 7/64 loss: -0.11649417877197266
Batch 8/64 loss: -0.02099609375
Batch 9/64 loss: -0.6447868347167969
Batch 10/64 loss: 0.21600723266601562
Batch 11/64 loss: -0.15385055541992188
Batch 12/64 loss: 0.3204975128173828
Batch 13/64 loss: 0.28937244415283203
Batch 14/64 loss: -0.4800987243652344
Batch 15/64 loss: -0.5231256484985352
Batch 16/64 loss: 0.03930950164794922
Batch 17/64 loss: -0.47246551513671875
Batch 18/64 loss: 0.046790122985839844
Batch 19/64 loss: -0.12408924102783203
Batch 20/64 loss: -0.5111351013183594
Batch 21/64 loss: -0.4192514419555664
Batch 22/64 loss: -0.4636068344116211
Batch 23/64 loss: -0.6437520980834961
Batch 24/64 loss: 1.6676807403564453
Batch 25/64 loss: -0.6963977813720703
Batch 26/64 loss: 0.6645574569702148
Batch 27/64 loss: -0.10086631774902344
Batch 28/64 loss: -0.06997966766357422
Batch 29/64 loss: 0.05596733093261719
Batch 30/64 loss: -0.11688899993896484
Batch 31/64 loss: -0.2225341796875
Batch 32/64 loss: -0.3427314758300781
Batch 33/64 loss: -0.4779043197631836
Batch 34/64 loss: -0.09395790100097656
Batch 35/64 loss: -0.4948558807373047
Batch 36/64 loss: -0.3432941436767578
Batch 37/64 loss: -0.12916946411132812
Batch 38/64 loss: -0.2520599365234375
Batch 39/64 loss: -0.09139633178710938
Batch 40/64 loss: -0.3560152053833008
Batch 41/64 loss: -0.6778802871704102
Batch 42/64 loss: -0.6346073150634766
Batch 43/64 loss: -0.38523006439208984
Batch 44/64 loss: -0.3370933532714844
Batch 45/64 loss: -0.47446250915527344
Batch 46/64 loss: -0.20322799682617188
Batch 47/64 loss: -0.7060403823852539
Batch 48/64 loss: -0.6873865127563477
Batch 49/64 loss: 1.3873071670532227
Batch 50/64 loss: -0.011578559875488281
Batch 51/64 loss: 0.4208707809448242
Batch 52/64 loss: -0.27012062072753906
Batch 53/64 loss: 0.37976741790771484
Batch 54/64 loss: -0.5873966217041016
Batch 55/64 loss: 1.0790739059448242
Batch 56/64 loss: -0.3421058654785156
Batch 57/64 loss: -0.3910970687866211
Batch 58/64 loss: -0.24827861785888672
Batch 59/64 loss: -0.4791574478149414
Batch 60/64 loss: 0.9293746948242188
Batch 61/64 loss: -0.890681266784668
Batch 62/64 loss: -0.47539806365966797
Batch 63/64 loss: -0.4332866668701172
Batch 64/64 loss: -4.538491249084473
Epoch 52  Train loss: -0.20252465266807407  Val loss: 0.3768832544280901
Epoch 53
-------------------------------
Batch 1/64 loss: -0.5840845108032227
Batch 2/64 loss: 1.4282379150390625
Batch 3/64 loss: -0.2416849136352539
Batch 4/64 loss: 0.21992015838623047
Batch 5/64 loss: -0.25457191467285156
Batch 6/64 loss: -0.5660505294799805
Batch 7/64 loss: 0.21541976928710938
Batch 8/64 loss: 0.10984611511230469
Batch 9/64 loss: 0.09614181518554688
Batch 10/64 loss: -0.4243154525756836
Batch 11/64 loss: -0.4192018508911133
Batch 12/64 loss: -0.5404806137084961
Batch 13/64 loss: -0.4059267044067383
Batch 14/64 loss: -0.7099800109863281
Batch 15/64 loss: -0.4605522155761719
Batch 16/64 loss: -0.32266902923583984
Batch 17/64 loss: -0.5779151916503906
Batch 18/64 loss: -0.3238229751586914
Batch 19/64 loss: -0.6975040435791016
Batch 20/64 loss: 0.10152816772460938
Batch 21/64 loss: -0.14450740814208984
Batch 22/64 loss: -0.27939510345458984
Batch 23/64 loss: -0.24654006958007812
Batch 24/64 loss: 0.06933021545410156
Batch 25/64 loss: -0.2395343780517578
Batch 26/64 loss: -0.6493434906005859
Batch 27/64 loss: -0.669520378112793
Batch 28/64 loss: -0.3942251205444336
Batch 29/64 loss: -0.8646717071533203
Batch 30/64 loss: -0.4748067855834961
Batch 31/64 loss: -0.4946861267089844
Batch 32/64 loss: 0.16795825958251953
Batch 33/64 loss: -0.572688102722168
Batch 34/64 loss: -0.16562461853027344
Batch 35/64 loss: -0.4405632019042969
Batch 36/64 loss: 0.42360401153564453
Batch 37/64 loss: 0.3759899139404297
Batch 38/64 loss: 0.017698287963867188
Batch 39/64 loss: -0.008572578430175781
Batch 40/64 loss: -0.3510446548461914
Batch 41/64 loss: 0.09310531616210938
Batch 42/64 loss: -0.3794841766357422
Batch 43/64 loss: -0.22947311401367188
Batch 44/64 loss: 0.17716407775878906
Batch 45/64 loss: -0.33220767974853516
Batch 46/64 loss: 0.20749473571777344
Batch 47/64 loss: -0.7394618988037109
Batch 48/64 loss: -0.6716136932373047
Batch 49/64 loss: -0.3793630599975586
Batch 50/64 loss: -0.4347095489501953
Batch 51/64 loss: 0.6164817810058594
Batch 52/64 loss: -0.3832216262817383
Batch 53/64 loss: -0.19858551025390625
Batch 54/64 loss: 0.25859737396240234
Batch 55/64 loss: -0.3153095245361328
Batch 56/64 loss: -0.1410655975341797
Batch 57/64 loss: -0.180511474609375
Batch 58/64 loss: -0.6310052871704102
Batch 59/64 loss: -0.1880817413330078
Batch 60/64 loss: 0.4780759811401367
Batch 61/64 loss: -0.5307760238647461
Batch 62/64 loss: 0.5985479354858398
Batch 63/64 loss: -0.3851594924926758
Batch 64/64 loss: -4.105105400085449
Epoch 53  Train loss: -0.2520502015656116  Val loss: 0.10206938281501692
Epoch 54
-------------------------------
Batch 1/64 loss: 0.1760730743408203
Batch 2/64 loss: -0.1712961196899414
Batch 3/64 loss: -0.09345722198486328
Batch 4/64 loss: 0.3036355972290039
Batch 5/64 loss: -0.27519989013671875
Batch 6/64 loss: 0.035567283630371094
Batch 7/64 loss: -0.08663177490234375
Batch 8/64 loss: -0.2702140808105469
Batch 9/64 loss: -0.3836097717285156
Batch 10/64 loss: 0.41280555725097656
Batch 11/64 loss: -0.01821613311767578
Batch 12/64 loss: 0.06844902038574219
Batch 13/64 loss: 0.21385955810546875
Batch 14/64 loss: -0.41495227813720703
Batch 15/64 loss: -0.1719532012939453
Batch 16/64 loss: 0.2311716079711914
Batch 17/64 loss: -0.32755374908447266
Batch 18/64 loss: 0.07805919647216797
Batch 19/64 loss: -0.7878150939941406
Batch 20/64 loss: 1.1759777069091797
Batch 21/64 loss: 0.24923419952392578
Batch 22/64 loss: 0.1571979522705078
Batch 23/64 loss: -0.11760520935058594
Batch 24/64 loss: -0.6686935424804688
Batch 25/64 loss: -0.03288841247558594
Batch 26/64 loss: 0.44150352478027344
Batch 27/64 loss: 0.5629730224609375
Batch 28/64 loss: 0.4165992736816406
Batch 29/64 loss: 0.046776771545410156
Batch 30/64 loss: -0.4376049041748047
Batch 31/64 loss: -0.3589773178100586
Batch 32/64 loss: 0.23357582092285156
Batch 33/64 loss: -0.3941164016723633
Batch 34/64 loss: 0.6151313781738281
Batch 35/64 loss: 0.7593507766723633
Batch 36/64 loss: 0.8017234802246094
Batch 37/64 loss: -0.22842025756835938
Batch 38/64 loss: 0.04250049591064453
Batch 39/64 loss: 0.2627296447753906
Batch 40/64 loss: -0.04824542999267578
Batch 41/64 loss: -0.25533103942871094
Batch 42/64 loss: 0.09540843963623047
Batch 43/64 loss: -0.06374931335449219
Batch 44/64 loss: -0.013409614562988281
Batch 45/64 loss: 2.1287717819213867
Batch 46/64 loss: -0.5518178939819336
Batch 47/64 loss: 1.876485824584961
Batch 48/64 loss: 0.26533985137939453
Batch 49/64 loss: 0.12835693359375
Batch 50/64 loss: 0.4489469528198242
Batch 51/64 loss: 0.9801483154296875
Batch 52/64 loss: 0.20787811279296875
Batch 53/64 loss: 0.2279033660888672
Batch 54/64 loss: 0.15685558319091797
Batch 55/64 loss: 0.8113527297973633
Batch 56/64 loss: -0.041014671325683594
Batch 57/64 loss: 0.3766956329345703
Batch 58/64 loss: 0.0900869369506836
Batch 59/64 loss: 0.7229118347167969
Batch 60/64 loss: -0.0768890380859375
Batch 61/64 loss: 0.8795051574707031
Batch 62/64 loss: 0.35068798065185547
Batch 63/64 loss: 1.3905220031738281
Batch 64/64 loss: -4.32102108001709
Epoch 54  Train loss: 0.1394874385758942  Val loss: 1.0260438034214925
Epoch 55
-------------------------------
Batch 1/64 loss: 0.1371774673461914
Batch 2/64 loss: 0.10463809967041016
Batch 3/64 loss: -0.07486820220947266
Batch 4/64 loss: 0.39056873321533203
Batch 5/64 loss: 0.15109729766845703
Batch 6/64 loss: 0.9144306182861328
Batch 7/64 loss: -0.03761863708496094
Batch 8/64 loss: -0.4605865478515625
Batch 9/64 loss: -0.3091602325439453
Batch 10/64 loss: -0.17122364044189453
Batch 11/64 loss: 0.08010673522949219
Batch 12/64 loss: 0.798192024230957
Batch 13/64 loss: 0.09926319122314453
Batch 14/64 loss: 1.1914386749267578
Batch 15/64 loss: -0.08103275299072266
Batch 16/64 loss: -0.4058208465576172
Batch 17/64 loss: 0.2759695053100586
Batch 18/64 loss: -0.5239534378051758
Batch 19/64 loss: -0.005138397216796875
Batch 20/64 loss: -0.23125171661376953
Batch 21/64 loss: 0.018944740295410156
Batch 22/64 loss: -0.1476917266845703
Batch 23/64 loss: 0.6484804153442383
Batch 24/64 loss: -0.16593170166015625
Batch 25/64 loss: -0.04725074768066406
Batch 26/64 loss: 0.15742206573486328
Batch 27/64 loss: -0.11518669128417969
Batch 28/64 loss: -0.15713024139404297
Batch 29/64 loss: -0.09088134765625
Batch 30/64 loss: -0.6598873138427734
Batch 31/64 loss: 1.024662971496582
Batch 32/64 loss: 0.02545642852783203
Batch 33/64 loss: 0.032883644104003906
Batch 34/64 loss: 0.3834085464477539
Batch 35/64 loss: 0.16183757781982422
Batch 36/64 loss: 0.1542501449584961
Batch 37/64 loss: 0.23847103118896484
Batch 38/64 loss: 0.2915201187133789
Batch 39/64 loss: -0.3309335708618164
Batch 40/64 loss: -0.1264934539794922
Batch 41/64 loss: -0.35436058044433594
Batch 42/64 loss: 0.09418392181396484
Batch 43/64 loss: -0.0387115478515625
Batch 44/64 loss: 0.007762908935546875
Batch 45/64 loss: -0.06710433959960938
Batch 46/64 loss: -0.4541606903076172
Batch 47/64 loss: -0.36108875274658203
Batch 48/64 loss: -0.11020183563232422
Batch 49/64 loss: 0.22986602783203125
Batch 50/64 loss: 0.3397674560546875
Batch 51/64 loss: 0.3446846008300781
Batch 52/64 loss: -0.08147621154785156
Batch 53/64 loss: 0.5927371978759766
Batch 54/64 loss: -0.35572052001953125
Batch 55/64 loss: -0.42150115966796875
Batch 56/64 loss: -0.36218929290771484
Batch 57/64 loss: 0.05865287780761719
Batch 58/64 loss: -0.3518228530883789
Batch 59/64 loss: 1.023940086364746
Batch 60/64 loss: -0.19022655487060547
Batch 61/64 loss: -0.21514892578125
Batch 62/64 loss: -0.25269222259521484
Batch 63/64 loss: -0.6173419952392578
Batch 64/64 loss: -4.869390487670898
Epoch 55  Train loss: -0.0322512383554496  Val loss: 0.6251959128887793
Epoch 56
-------------------------------
Batch 1/64 loss: -0.15292072296142578
Batch 2/64 loss: -0.5428552627563477
Batch 3/64 loss: -0.07470130920410156
Batch 4/64 loss: -0.45790863037109375
Batch 5/64 loss: -0.2213287353515625
Batch 6/64 loss: -0.7815084457397461
Batch 7/64 loss: 0.060608863830566406
Batch 8/64 loss: -0.3457012176513672
Batch 9/64 loss: -0.5047607421875
Batch 10/64 loss: -0.4734916687011719
Batch 11/64 loss: -0.14130401611328125
Batch 12/64 loss: 0.04224586486816406
Batch 13/64 loss: -0.23978900909423828
Batch 14/64 loss: -0.20507049560546875
Batch 15/64 loss: -0.510502815246582
Batch 16/64 loss: -0.23866558074951172
Batch 17/64 loss: 0.47648143768310547
Batch 18/64 loss: -0.5816259384155273
Batch 19/64 loss: -0.5311727523803711
Batch 20/64 loss: -0.6018209457397461
Batch 21/64 loss: -0.5331325531005859
Batch 22/64 loss: 0.23410987854003906
Batch 23/64 loss: -0.21792984008789062
Batch 24/64 loss: -0.7344551086425781
Batch 25/64 loss: -0.018524169921875
Batch 26/64 loss: -0.6365022659301758
Batch 27/64 loss: -0.5031976699829102
Batch 28/64 loss: -0.291778564453125
Batch 29/64 loss: -0.17185115814208984
Batch 30/64 loss: -0.36638736724853516
Batch 31/64 loss: -0.5021286010742188
Batch 32/64 loss: -0.5779323577880859
Batch 33/64 loss: -0.9224119186401367
Batch 34/64 loss: -0.7226362228393555
Batch 35/64 loss: -0.4792747497558594
Batch 36/64 loss: -0.44202518463134766
Batch 37/64 loss: -0.8187828063964844
Batch 38/64 loss: -0.5406675338745117
Batch 39/64 loss: -0.6444778442382812
Batch 40/64 loss: -0.6558952331542969
Batch 41/64 loss: -0.1310892105102539
Batch 42/64 loss: -0.7731637954711914
Batch 43/64 loss: -0.6776046752929688
Batch 44/64 loss: -0.6604938507080078
Batch 45/64 loss: -0.5434350967407227
Batch 46/64 loss: -0.5947141647338867
Batch 47/64 loss: -0.8571615219116211
Batch 48/64 loss: 0.12972545623779297
Batch 49/64 loss: -0.7278623580932617
Batch 50/64 loss: -0.6217498779296875
Batch 51/64 loss: -0.49228763580322266
Batch 52/64 loss: -0.11581611633300781
Batch 53/64 loss: -0.5292272567749023
Batch 54/64 loss: 0.017675399780273438
Batch 55/64 loss: -0.5473213195800781
Batch 56/64 loss: -0.8117170333862305
Batch 57/64 loss: -0.6226682662963867
Batch 58/64 loss: -0.5968904495239258
Batch 59/64 loss: 0.1861867904663086
Batch 60/64 loss: -0.5880899429321289
Batch 61/64 loss: 0.06386566162109375
Batch 62/64 loss: -0.11505889892578125
Batch 63/64 loss: -0.7270088195800781
Batch 64/64 loss: -4.521728515625
Epoch 56  Train loss: -0.45959022372376684  Val loss: -0.4436589139433661
Epoch 57
-------------------------------
Batch 1/64 loss: 0.5179777145385742
Batch 2/64 loss: -0.4742555618286133
Batch 3/64 loss: -0.6923637390136719
Batch 4/64 loss: -0.6984872817993164
Batch 5/64 loss: -0.10292720794677734
Batch 6/64 loss: -0.3059520721435547
Batch 7/64 loss: 0.2804412841796875
Batch 8/64 loss: 0.11227893829345703
Batch 9/64 loss: -0.5820760726928711
Batch 10/64 loss: -0.35578060150146484
Batch 11/64 loss: -0.09195327758789062
Batch 12/64 loss: -0.6070318222045898
Batch 13/64 loss: -0.4138803482055664
Batch 14/64 loss: -0.3129301071166992
Batch 15/64 loss: -0.6390533447265625
Batch 16/64 loss: -0.6898717880249023
Batch 17/64 loss: 0.10750770568847656
Batch 18/64 loss: -0.1940164566040039
Batch 19/64 loss: -0.46955108642578125
Batch 20/64 loss: -0.7083950042724609
Batch 21/64 loss: -0.12972164154052734
Batch 22/64 loss: -0.7097921371459961
Batch 23/64 loss: -0.6837034225463867
Batch 24/64 loss: -0.45514392852783203
Batch 25/64 loss: -0.8151397705078125
Batch 26/64 loss: -0.36206912994384766
Batch 27/64 loss: -0.6122236251831055
Batch 28/64 loss: 0.36827754974365234
Batch 29/64 loss: -0.5493955612182617
Batch 30/64 loss: -0.5160923004150391
Batch 31/64 loss: -0.7422399520874023
Batch 32/64 loss: -0.49430370330810547
Batch 33/64 loss: 0.35994434356689453
Batch 34/64 loss: -0.6716012954711914
Batch 35/64 loss: -0.6076526641845703
Batch 36/64 loss: -0.8847227096557617
Batch 37/64 loss: -0.45269298553466797
Batch 38/64 loss: -0.04735851287841797
Batch 39/64 loss: -0.019064903259277344
Batch 40/64 loss: -0.4968118667602539
Batch 41/64 loss: -0.5355348587036133
Batch 42/64 loss: -0.19955921173095703
Batch 43/64 loss: -0.5135726928710938
Batch 44/64 loss: -0.6027965545654297
Batch 45/64 loss: -0.7977104187011719
Batch 46/64 loss: -0.7330532073974609
Batch 47/64 loss: -0.6729402542114258
Batch 48/64 loss: 1.5024995803833008
Batch 49/64 loss: -0.6145906448364258
Batch 50/64 loss: -0.8026809692382812
Batch 51/64 loss: -0.4688434600830078
Batch 52/64 loss: -0.7823753356933594
Batch 53/64 loss: -0.6949081420898438
Batch 54/64 loss: -0.5038785934448242
Batch 55/64 loss: -0.07291603088378906
Batch 56/64 loss: -0.6735954284667969
Batch 57/64 loss: -0.5153932571411133
Batch 58/64 loss: -0.3033151626586914
Batch 59/64 loss: -0.48423290252685547
Batch 60/64 loss: -0.8979969024658203
Batch 61/64 loss: -0.6435842514038086
Batch 62/64 loss: -0.5733013153076172
Batch 63/64 loss: -0.9695720672607422
Batch 64/64 loss: -5.173124313354492
Epoch 57  Train loss: -0.4749101750990924  Val loss: -0.6254010413520524
Epoch 58
-------------------------------
Batch 1/64 loss: 1.842081069946289
Batch 2/64 loss: -0.501673698425293
Batch 3/64 loss: -0.5064229965209961
Batch 4/64 loss: -0.020776748657226562
Batch 5/64 loss: -0.841547966003418
Batch 6/64 loss: -0.7255001068115234
Batch 7/64 loss: -0.502833366394043
Batch 8/64 loss: -0.943242073059082
Batch 9/64 loss: -0.08211803436279297
Batch 10/64 loss: -0.6875829696655273
Batch 11/64 loss: -0.5347375869750977
Batch 12/64 loss: 0.514556884765625
Batch 13/64 loss: -0.9717617034912109
Batch 14/64 loss: -0.9012069702148438
Batch 15/64 loss: -0.6554880142211914
Batch 16/64 loss: -0.83172607421875
Batch 17/64 loss: -0.6363430023193359
Batch 18/64 loss: -0.2900819778442383
Batch 19/64 loss: -0.6662940979003906
Batch 20/64 loss: -0.441314697265625
Batch 21/64 loss: 0.1295328140258789
Batch 22/64 loss: -0.5574264526367188
Batch 23/64 loss: 0.06427478790283203
Batch 24/64 loss: -0.11246204376220703
Batch 25/64 loss: -0.45937538146972656
Batch 26/64 loss: -0.19874000549316406
Batch 27/64 loss: -0.23994827270507812
Batch 28/64 loss: -0.01953887939453125
Batch 29/64 loss: 0.7385740280151367
Batch 30/64 loss: -0.5859832763671875
Batch 31/64 loss: -0.1200113296508789
Batch 32/64 loss: -0.5830173492431641
Batch 33/64 loss: -0.38239574432373047
Batch 34/64 loss: -0.07554912567138672
Batch 35/64 loss: 0.4960813522338867
Batch 36/64 loss: -0.34975719451904297
Batch 37/64 loss: -0.17819499969482422
Batch 38/64 loss: -0.6799659729003906
Batch 39/64 loss: 0.3451070785522461
Batch 40/64 loss: -0.15954113006591797
Batch 41/64 loss: -0.1115274429321289
Batch 42/64 loss: -0.41695213317871094
Batch 43/64 loss: -0.2415151596069336
Batch 44/64 loss: -0.5984592437744141
Batch 45/64 loss: 0.24464797973632812
Batch 46/64 loss: -0.6097812652587891
Batch 47/64 loss: -0.4517650604248047
Batch 48/64 loss: -0.4840688705444336
Batch 49/64 loss: -0.5097446441650391
Batch 50/64 loss: -0.30305957794189453
Batch 51/64 loss: -0.1748523712158203
Batch 52/64 loss: -0.6509666442871094
Batch 53/64 loss: -0.3589515686035156
Batch 54/64 loss: -0.6327648162841797
Batch 55/64 loss: -0.4807147979736328
Batch 56/64 loss: -0.448760986328125
Batch 57/64 loss: -0.568638801574707
Batch 58/64 loss: -0.6217374801635742
Batch 59/64 loss: -0.30925559997558594
Batch 60/64 loss: -0.11940670013427734
Batch 61/64 loss: -0.44284820556640625
Batch 62/64 loss: -0.6621427536010742
Batch 63/64 loss: -0.6263837814331055
Batch 64/64 loss: -4.244789123535156
Epoch 58  Train loss: -0.3776563607010187  Val loss: -0.4561461484718978
Epoch 59
-------------------------------
Batch 1/64 loss: -0.5405139923095703
Batch 2/64 loss: -0.587315559387207
Batch 3/64 loss: -0.6584911346435547
Batch 4/64 loss: -0.26725006103515625
Batch 5/64 loss: -0.16488075256347656
Batch 6/64 loss: -0.4124279022216797
Batch 7/64 loss: 0.026025772094726562
Batch 8/64 loss: -0.6011781692504883
Batch 9/64 loss: -0.4977130889892578
Batch 10/64 loss: -0.48348331451416016
Batch 11/64 loss: -0.6927242279052734
Batch 12/64 loss: -0.7343454360961914
Batch 13/64 loss: -0.7743034362792969
Batch 14/64 loss: -0.18407630920410156
Batch 15/64 loss: -0.029237747192382812
Batch 16/64 loss: -0.730194091796875
Batch 17/64 loss: -0.35810184478759766
Batch 18/64 loss: -0.7203140258789062
Batch 19/64 loss: -0.2628307342529297
Batch 20/64 loss: -0.2962350845336914
Batch 21/64 loss: -0.7341232299804688
Batch 22/64 loss: -0.6595306396484375
Batch 23/64 loss: -0.3333320617675781
Batch 24/64 loss: -0.29280948638916016
Batch 25/64 loss: -0.3483152389526367
Batch 26/64 loss: -0.8750677108764648
Batch 27/64 loss: -0.5989875793457031
Batch 28/64 loss: -0.4580812454223633
Batch 29/64 loss: -0.18810272216796875
Batch 30/64 loss: -0.5246458053588867
Batch 31/64 loss: -0.6855926513671875
Batch 32/64 loss: -0.614903450012207
Batch 33/64 loss: -0.7520570755004883
Batch 34/64 loss: -0.4612722396850586
Batch 35/64 loss: -0.28007984161376953
Batch 36/64 loss: -0.7236433029174805
Batch 37/64 loss: -0.05887031555175781
Batch 38/64 loss: -0.4194345474243164
Batch 39/64 loss: -0.8413000106811523
Batch 40/64 loss: -0.5877275466918945
Batch 41/64 loss: -0.7022781372070312
Batch 42/64 loss: -0.5642480850219727
Batch 43/64 loss: -0.8307628631591797
Batch 44/64 loss: -0.18523788452148438
Batch 45/64 loss: -0.7258872985839844
Batch 46/64 loss: -0.7917585372924805
Batch 47/64 loss: -0.8097734451293945
Batch 48/64 loss: -0.8062505722045898
Batch 49/64 loss: -0.7733573913574219
Batch 50/64 loss: -0.6843175888061523
Batch 51/64 loss: -0.8739585876464844
Batch 52/64 loss: -0.5998649597167969
Batch 53/64 loss: -0.8433656692504883
Batch 54/64 loss: -0.21863746643066406
Batch 55/64 loss: -0.25113773345947266
Batch 56/64 loss: -0.31427764892578125
Batch 57/64 loss: -0.7910690307617188
Batch 58/64 loss: -0.28397178649902344
Batch 59/64 loss: -0.29655933380126953
Batch 60/64 loss: -0.684575080871582
Batch 61/64 loss: 0.018095016479492188
Batch 62/64 loss: -0.4334592819213867
Batch 63/64 loss: -0.8724126815795898
Batch 64/64 loss: -4.703754425048828
Epoch 59  Train loss: -0.5686956817028569  Val loss: -0.8040133472980093
Saving best model, epoch: 59
Epoch 60
-------------------------------
Batch 1/64 loss: -0.6132936477661133
Batch 2/64 loss: -0.8371601104736328
Batch 3/64 loss: -0.632237434387207
Batch 4/64 loss: -0.7196331024169922
Batch 5/64 loss: -0.17727088928222656
Batch 6/64 loss: -0.7204599380493164
Batch 7/64 loss: -0.7590179443359375
Batch 8/64 loss: -0.9443769454956055
Batch 9/64 loss: -0.3423500061035156
Batch 10/64 loss: -0.5483131408691406
Batch 11/64 loss: -0.7748117446899414
Batch 12/64 loss: -0.6975040435791016
Batch 13/64 loss: -0.43611907958984375
Batch 14/64 loss: -0.015285491943359375
Batch 15/64 loss: -0.9257621765136719
Batch 16/64 loss: -0.5525312423706055
Batch 17/64 loss: -0.47887611389160156
Batch 18/64 loss: -0.17599105834960938
Batch 19/64 loss: -0.6115913391113281
Batch 20/64 loss: -0.5911140441894531
Batch 21/64 loss: -0.4389657974243164
Batch 22/64 loss: -0.2228679656982422
Batch 23/64 loss: -0.5642843246459961
Batch 24/64 loss: -0.44977378845214844
Batch 25/64 loss: -0.16864776611328125
Batch 26/64 loss: -0.700108528137207
Batch 27/64 loss: 0.4483146667480469
Batch 28/64 loss: -0.3761138916015625
Batch 29/64 loss: -0.6851978302001953
Batch 30/64 loss: 0.2612943649291992
Batch 31/64 loss: -0.4711418151855469
Batch 32/64 loss: -0.39918994903564453
Batch 33/64 loss: -0.645075798034668
Batch 34/64 loss: -0.4783439636230469
Batch 35/64 loss: -0.6194467544555664
Batch 36/64 loss: -0.6484603881835938
Batch 37/64 loss: -0.12380409240722656
Batch 38/64 loss: -0.8655872344970703
Batch 39/64 loss: -0.7350187301635742
Batch 40/64 loss: -0.21892261505126953
Batch 41/64 loss: -0.8545007705688477
Batch 42/64 loss: -0.19115257263183594
Batch 43/64 loss: -0.47480297088623047
Batch 44/64 loss: -0.6466083526611328
Batch 45/64 loss: -0.5355939865112305
Batch 46/64 loss: -0.2312030792236328
Batch 47/64 loss: -0.4909534454345703
Batch 48/64 loss: -0.5440006256103516
Batch 49/64 loss: -0.6075363159179688
Batch 50/64 loss: 0.3148794174194336
Batch 51/64 loss: -0.7648630142211914
Batch 52/64 loss: -0.4518289566040039
Batch 53/64 loss: -0.28899669647216797
Batch 54/64 loss: -0.7615175247192383
Batch 55/64 loss: -0.24149608612060547
Batch 56/64 loss: -0.6065006256103516
Batch 57/64 loss: -0.6585559844970703
Batch 58/64 loss: -0.1204824447631836
Batch 59/64 loss: -0.31154823303222656
Batch 60/64 loss: -0.6918001174926758
Batch 61/64 loss: -0.0670785903930664
Batch 62/64 loss: -0.6334161758422852
Batch 63/64 loss: 0.48111438751220703
Batch 64/64 loss: -4.730052947998047
Epoch 60  Train loss: -0.511074888939951  Val loss: -0.5609253165648156
Epoch 61
-------------------------------
Batch 1/64 loss: -0.3282022476196289
Batch 2/64 loss: -0.46901798248291016
Batch 3/64 loss: -0.6547632217407227
Batch 4/64 loss: -0.403900146484375
Batch 5/64 loss: -0.32913684844970703
Batch 6/64 loss: -0.41591548919677734
Batch 7/64 loss: -0.5066986083984375
Batch 8/64 loss: -0.6149635314941406
Batch 9/64 loss: -0.44420909881591797
Batch 10/64 loss: -0.6529722213745117
Batch 11/64 loss: -0.4774465560913086
Batch 12/64 loss: -0.40567970275878906
Batch 13/64 loss: -0.24331092834472656
Batch 14/64 loss: 0.5093612670898438
Batch 15/64 loss: -0.6690301895141602
Batch 16/64 loss: -0.4937906265258789
Batch 17/64 loss: -0.5588951110839844
Batch 18/64 loss: 1.4198055267333984
Batch 19/64 loss: -0.022765159606933594
Batch 20/64 loss: 0.8983526229858398
Batch 21/64 loss: 0.3915691375732422
Batch 22/64 loss: 0.3404808044433594
Batch 23/64 loss: 1.1508054733276367
Batch 24/64 loss: 1.5092964172363281
Batch 25/64 loss: 1.6897096633911133
Batch 26/64 loss: 2.8673477172851562
Batch 27/64 loss: 1.2044811248779297
Batch 28/64 loss: 1.4144811630249023
Batch 29/64 loss: 1.41156005859375
Batch 30/64 loss: 0.9325056076049805
Batch 31/64 loss: 1.2526636123657227
Batch 32/64 loss: 0.43662261962890625
Batch 33/64 loss: 0.8795757293701172
Batch 34/64 loss: 0.9682140350341797
Batch 35/64 loss: 4.47353458404541
Batch 36/64 loss: 1.0392513275146484
Batch 37/64 loss: 3.1521501541137695
Batch 38/64 loss: 1.3585968017578125
Batch 39/64 loss: 0.847747802734375
Batch 40/64 loss: 3.9476699829101562
Batch 41/64 loss: 2.78745174407959
Batch 42/64 loss: 0.9893999099731445
Batch 43/64 loss: 1.6689329147338867
Batch 44/64 loss: 2.331073760986328
Batch 45/64 loss: 1.769627571105957
Batch 46/64 loss: 1.3115520477294922
Batch 47/64 loss: 3.8416900634765625
Batch 48/64 loss: 1.712179183959961
Batch 49/64 loss: 0.7710781097412109
Batch 50/64 loss: 1.3848676681518555
Batch 51/64 loss: 2.868776321411133
Batch 52/64 loss: 2.2493772506713867
Batch 53/64 loss: 1.7641754150390625
Batch 54/64 loss: 1.3195714950561523
Batch 55/64 loss: 2.122878074645996
Batch 56/64 loss: 2.021556854248047
Batch 57/64 loss: 3.330474853515625
Batch 58/64 loss: 1.1246061325073242
Batch 59/64 loss: 2.796441078186035
Batch 60/64 loss: 2.381742477416992
Batch 61/64 loss: 2.3367366790771484
Batch 62/64 loss: 1.1010255813598633
Batch 63/64 loss: 0.977595329284668
Batch 64/64 loss: -3.4859609603881836
Epoch 61  Train loss: 1.0784851036819758  Val loss: 1.748706345705642
Epoch 62
-------------------------------
Batch 1/64 loss: 0.8225545883178711
Batch 2/64 loss: 3.81613826751709
Batch 3/64 loss: 0.3313875198364258
Batch 4/64 loss: 1.2856636047363281
Batch 5/64 loss: 0.8057260513305664
Batch 6/64 loss: 0.7251148223876953
Batch 7/64 loss: 0.09598350524902344
Batch 8/64 loss: 2.3444204330444336
Batch 9/64 loss: 0.916356086730957
Batch 10/64 loss: 1.4482307434082031
Batch 11/64 loss: 0.1159658432006836
Batch 12/64 loss: 1.0439128875732422
Batch 13/64 loss: 0.3977785110473633
Batch 14/64 loss: 0.07642745971679688
Batch 15/64 loss: 0.2492237091064453
Batch 16/64 loss: 0.5671558380126953
Batch 17/64 loss: 0.1615133285522461
Batch 18/64 loss: 1.5750646591186523
Batch 19/64 loss: 0.5861797332763672
Batch 20/64 loss: 1.028336524963379
Batch 21/64 loss: 1.7164745330810547
Batch 22/64 loss: 1.2285232543945312
Batch 23/64 loss: 0.3639106750488281
Batch 24/64 loss: 0.2273263931274414
Batch 25/64 loss: 0.09995651245117188
Batch 26/64 loss: 0.6136941909790039
Batch 27/64 loss: 0.21894550323486328
Batch 28/64 loss: 0.22094058990478516
Batch 29/64 loss: 1.8082389831542969
Batch 30/64 loss: 0.8712100982666016
Batch 31/64 loss: 2.026447296142578
Batch 32/64 loss: -0.24052715301513672
Batch 33/64 loss: 0.8083095550537109
Batch 34/64 loss: 0.4355592727661133
Batch 35/64 loss: 0.32825565338134766
Batch 36/64 loss: 0.3795032501220703
Batch 37/64 loss: 0.028081893920898438
Batch 38/64 loss: 0.3236579895019531
Batch 39/64 loss: -0.05610942840576172
Batch 40/64 loss: 1.8249950408935547
Batch 41/64 loss: 0.04611396789550781
Batch 42/64 loss: 0.32289600372314453
Batch 43/64 loss: 1.824777603149414
Batch 44/64 loss: 0.350555419921875
Batch 45/64 loss: 0.2100210189819336
Batch 46/64 loss: 0.12199878692626953
Batch 47/64 loss: 0.7331628799438477
Batch 48/64 loss: 0.39165687561035156
Batch 49/64 loss: -0.11967754364013672
Batch 50/64 loss: -0.05608654022216797
Batch 51/64 loss: 0.5641422271728516
Batch 52/64 loss: -0.19923019409179688
Batch 53/64 loss: 0.5756130218505859
Batch 54/64 loss: 0.3281240463256836
Batch 55/64 loss: 1.1835260391235352
Batch 56/64 loss: 0.7296829223632812
Batch 57/64 loss: 0.1866741180419922
Batch 58/64 loss: 2.005282402038574
Batch 59/64 loss: 0.8647909164428711
Batch 60/64 loss: 0.2873096466064453
Batch 61/64 loss: 0.47963905334472656
Batch 62/64 loss: 0.14664745330810547
Batch 63/64 loss: 1.268794059753418
Batch 64/64 loss: -4.134744644165039
Epoch 62  Train loss: 0.6394648458443436  Val loss: 0.6304425373929473
Epoch 63
-------------------------------
Batch 1/64 loss: -0.03289508819580078
Batch 2/64 loss: -0.1154336929321289
Batch 3/64 loss: 0.2526273727416992
Batch 4/64 loss: 1.6825408935546875
Batch 5/64 loss: 0.17195606231689453
Batch 6/64 loss: 0.15934467315673828
Batch 7/64 loss: 0.6730308532714844
Batch 8/64 loss: 0.8498134613037109
Batch 9/64 loss: 0.8127365112304688
Batch 10/64 loss: 0.40372180938720703
Batch 11/64 loss: 0.220550537109375
Batch 12/64 loss: 1.7904071807861328
Batch 13/64 loss: 1.3592653274536133
Batch 14/64 loss: -0.15850257873535156
Batch 15/64 loss: 0.11987590789794922
Batch 16/64 loss: 0.323455810546875
Batch 17/64 loss: -0.03846168518066406
Batch 18/64 loss: 0.6089372634887695
Batch 19/64 loss: 0.45218372344970703
Batch 20/64 loss: -0.12230300903320312
Batch 21/64 loss: 0.12851619720458984
Batch 22/64 loss: 1.0202322006225586
Batch 23/64 loss: -0.048160552978515625
Batch 24/64 loss: -0.07660388946533203
Batch 25/64 loss: 0.9574623107910156
Batch 26/64 loss: 0.018955230712890625
Batch 27/64 loss: 0.041016578674316406
Batch 28/64 loss: -0.3101682662963867
Batch 29/64 loss: 0.04017448425292969
Batch 30/64 loss: 0.6942968368530273
Batch 31/64 loss: 0.25351428985595703
Batch 32/64 loss: 0.22512435913085938
Batch 33/64 loss: -0.2578554153442383
Batch 34/64 loss: 0.9168386459350586
Batch 35/64 loss: 0.011373519897460938
Batch 36/64 loss: 0.026304244995117188
Batch 37/64 loss: 1.6360197067260742
Batch 38/64 loss: 0.39818572998046875
Batch 39/64 loss: -0.0794677734375
Batch 40/64 loss: 0.5580844879150391
Batch 41/64 loss: 0.0658426284790039
Batch 42/64 loss: -0.032149314880371094
Batch 43/64 loss: 0.11792945861816406
Batch 44/64 loss: 0.6318979263305664
Batch 45/64 loss: 0.16422462463378906
Batch 46/64 loss: 0.45316028594970703
Batch 47/64 loss: 0.822138786315918
Batch 48/64 loss: -0.2676811218261719
Batch 49/64 loss: 0.6645097732543945
Batch 50/64 loss: 0.9779062271118164
Batch 51/64 loss: 0.39789867401123047
Batch 52/64 loss: 0.13677501678466797
Batch 53/64 loss: -0.23139381408691406
Batch 54/64 loss: 0.1843719482421875
Batch 55/64 loss: -0.18048763275146484
Batch 56/64 loss: 0.9738283157348633
Batch 57/64 loss: 0.13179588317871094
Batch 58/64 loss: 0.09241390228271484
Batch 59/64 loss: -0.1378927230834961
Batch 60/64 loss: -0.2434215545654297
Batch 61/64 loss: 0.6777687072753906
Batch 62/64 loss: 0.3954286575317383
Batch 63/64 loss: -0.13721561431884766
Batch 64/64 loss: -4.152377128601074
Epoch 63  Train loss: 0.28407937966141045  Val loss: 0.08147156443382866
Epoch 64
-------------------------------
Batch 1/64 loss: -0.18402576446533203
Batch 2/64 loss: -0.08722972869873047
Batch 3/64 loss: -0.09453105926513672
Batch 4/64 loss: 0.09365081787109375
Batch 5/64 loss: 0.32853031158447266
Batch 6/64 loss: 0.410308837890625
Batch 7/64 loss: 0.5828924179077148
Batch 8/64 loss: 0.11936759948730469
Batch 9/64 loss: 0.2432994842529297
Batch 10/64 loss: -0.09006690979003906
Batch 11/64 loss: 0.1619863510131836
Batch 12/64 loss: -0.23362350463867188
Batch 13/64 loss: -0.2686634063720703
Batch 14/64 loss: -0.08591747283935547
Batch 15/64 loss: 0.09546470642089844
Batch 16/64 loss: 0.16315555572509766
Batch 17/64 loss: 0.14351272583007812
Batch 18/64 loss: -0.10870552062988281
Batch 19/64 loss: -0.05602741241455078
Batch 20/64 loss: 0.7236919403076172
Batch 21/64 loss: -0.028847694396972656
Batch 22/64 loss: 0.14896106719970703
Batch 23/64 loss: -0.25015735626220703
Batch 24/64 loss: -0.2097911834716797
Batch 25/64 loss: -0.3257484436035156
Batch 26/64 loss: -0.0010728836059570312
Batch 27/64 loss: 0.13013172149658203
Batch 28/64 loss: 0.5956821441650391
Batch 29/64 loss: -0.12922096252441406
Batch 30/64 loss: -0.09038162231445312
Batch 31/64 loss: -0.23775386810302734
Batch 32/64 loss: -0.14846038818359375
Batch 33/64 loss: -0.046660423278808594
Batch 34/64 loss: -0.5118007659912109
Batch 35/64 loss: -0.23151779174804688
Batch 36/64 loss: 1.2935905456542969
Batch 37/64 loss: 0.1667470932006836
Batch 38/64 loss: 0.49994850158691406
Batch 39/64 loss: -0.3091888427734375
Batch 40/64 loss: -0.15544700622558594
Batch 41/64 loss: -0.31579113006591797
Batch 42/64 loss: -0.2203693389892578
Batch 43/64 loss: -0.3819580078125
Batch 44/64 loss: -0.21523666381835938
Batch 45/64 loss: 0.2412128448486328
Batch 46/64 loss: 0.5567569732666016
Batch 47/64 loss: -0.4429283142089844
Batch 48/64 loss: -0.0923614501953125
Batch 49/64 loss: -0.023283004760742188
Batch 50/64 loss: -0.5051279067993164
Batch 51/64 loss: -0.13767528533935547
Batch 52/64 loss: -0.49854469299316406
Batch 53/64 loss: -0.6421852111816406
Batch 54/64 loss: -0.31739044189453125
Batch 55/64 loss: 0.026474952697753906
Batch 56/64 loss: -0.05791950225830078
Batch 57/64 loss: -0.28575992584228516
Batch 58/64 loss: -0.3165130615234375
Batch 59/64 loss: 0.008210182189941406
Batch 60/64 loss: -0.4821453094482422
Batch 61/64 loss: -0.40527820587158203
Batch 62/64 loss: -0.7519321441650391
Batch 63/64 loss: -0.6008062362670898
Batch 64/64 loss: -4.638416290283203
Epoch 64  Train loss: -0.11487500059838389  Val loss: -0.580770643306352
Epoch 65
-------------------------------
Batch 1/64 loss: 0.26020336151123047
Batch 2/64 loss: -0.5539779663085938
Batch 3/64 loss: -0.6763410568237305
Batch 4/64 loss: -0.9224634170532227
Batch 5/64 loss: -0.6839618682861328
Batch 6/64 loss: 0.3106193542480469
Batch 7/64 loss: -0.08661651611328125
Batch 8/64 loss: -0.5818071365356445
Batch 9/64 loss: -0.3021535873413086
Batch 10/64 loss: -0.3986024856567383
Batch 11/64 loss: -0.7368364334106445
Batch 12/64 loss: 0.021333694458007812
Batch 13/64 loss: -0.045096397399902344
Batch 14/64 loss: -0.41802406311035156
Batch 15/64 loss: -0.7194156646728516
Batch 16/64 loss: 0.0846719741821289
Batch 17/64 loss: 0.18396854400634766
Batch 18/64 loss: 0.4640836715698242
Batch 19/64 loss: -0.2854280471801758
Batch 20/64 loss: -0.16087627410888672
Batch 21/64 loss: -0.6341171264648438
Batch 22/64 loss: -0.6733131408691406
Batch 23/64 loss: -0.07979583740234375
Batch 24/64 loss: -0.22079086303710938
Batch 25/64 loss: -0.3834676742553711
Batch 26/64 loss: -0.10257434844970703
Batch 27/64 loss: -0.6580543518066406
Batch 28/64 loss: -0.3910551071166992
Batch 29/64 loss: 0.5879096984863281
Batch 30/64 loss: -0.12178230285644531
Batch 31/64 loss: -0.24088478088378906
Batch 32/64 loss: 0.06101036071777344
Batch 33/64 loss: -0.11236953735351562
Batch 34/64 loss: -0.28838253021240234
Batch 35/64 loss: 0.01036834716796875
Batch 36/64 loss: -0.3148317337036133
Batch 37/64 loss: -0.4408531188964844
Batch 38/64 loss: 0.16307544708251953
Batch 39/64 loss: -0.17081165313720703
Batch 40/64 loss: -0.46809864044189453
Batch 41/64 loss: 0.13118743896484375
Batch 42/64 loss: 0.21915149688720703
Batch 43/64 loss: -0.3645458221435547
Batch 44/64 loss: 0.8610019683837891
Batch 45/64 loss: -0.016022682189941406
Batch 46/64 loss: -0.2106943130493164
Batch 47/64 loss: 0.05333423614501953
Batch 48/64 loss: -0.49020957946777344
Batch 49/64 loss: 0.13572978973388672
Batch 50/64 loss: -0.2828865051269531
Batch 51/64 loss: -0.40702342987060547
Batch 52/64 loss: 0.1845874786376953
Batch 53/64 loss: -0.4932880401611328
Batch 54/64 loss: -0.1065673828125
Batch 55/64 loss: -0.45438480377197266
Batch 56/64 loss: -0.3896627426147461
Batch 57/64 loss: 0.43741703033447266
Batch 58/64 loss: -0.7178287506103516
Batch 59/64 loss: 0.30970191955566406
Batch 60/64 loss: -0.34897804260253906
Batch 61/64 loss: -0.3156576156616211
Batch 62/64 loss: 0.40126514434814453
Batch 63/64 loss: 0.7569332122802734
Batch 64/64 loss: -2.905782699584961
Epoch 65  Train loss: -0.2041147643444585  Val loss: 0.9374192752379322
Epoch 66
-------------------------------
Batch 1/64 loss: -0.30437469482421875
Batch 2/64 loss: 0.4790515899658203
Batch 3/64 loss: 0.6293258666992188
Batch 4/64 loss: 0.3850288391113281
Batch 5/64 loss: 0.41928863525390625
Batch 6/64 loss: -0.29330921173095703
Batch 7/64 loss: 0.1944255828857422
Batch 8/64 loss: -0.45313358306884766
Batch 9/64 loss: 0.163177490234375
Batch 10/64 loss: 0.07250785827636719
Batch 11/64 loss: -0.16805648803710938
Batch 12/64 loss: -0.5679693222045898
Batch 13/64 loss: -0.4034404754638672
Batch 14/64 loss: 0.37715625762939453
Batch 15/64 loss: 0.15085411071777344
Batch 16/64 loss: -0.2372579574584961
Batch 17/64 loss: -0.4267997741699219
Batch 18/64 loss: -0.12568283081054688
Batch 19/64 loss: -0.199127197265625
Batch 20/64 loss: 0.11784744262695312
Batch 21/64 loss: -0.7632207870483398
Batch 22/64 loss: -0.7663793563842773
Batch 23/64 loss: -0.6060619354248047
Batch 24/64 loss: -0.11570358276367188
Batch 25/64 loss: -0.47365283966064453
Batch 26/64 loss: -0.23865032196044922
Batch 27/64 loss: -0.539820671081543
Batch 28/64 loss: -0.05872058868408203
Batch 29/64 loss: -0.2632913589477539
Batch 30/64 loss: -0.39850616455078125
Batch 31/64 loss: -0.6676826477050781
Batch 32/64 loss: 0.3170795440673828
Batch 33/64 loss: -0.29531192779541016
Batch 34/64 loss: -0.7567319869995117
Batch 35/64 loss: -0.6512136459350586
Batch 36/64 loss: -0.3359518051147461
Batch 37/64 loss: -0.2409505844116211
Batch 38/64 loss: -0.5514869689941406
Batch 39/64 loss: -0.7538642883300781
Batch 40/64 loss: -0.5053138732910156
Batch 41/64 loss: -0.5178661346435547
Batch 42/64 loss: -0.3603048324584961
Batch 43/64 loss: 0.2519569396972656
Batch 44/64 loss: -0.638401985168457
Batch 45/64 loss: -0.4542703628540039
Batch 46/64 loss: -0.6431264877319336
Batch 47/64 loss: -0.17492198944091797
Batch 48/64 loss: -0.49932384490966797
Batch 49/64 loss: 0.5264930725097656
Batch 50/64 loss: -0.2974824905395508
Batch 51/64 loss: -0.6065683364868164
Batch 52/64 loss: -0.5260791778564453
Batch 53/64 loss: -0.5268955230712891
Batch 54/64 loss: -0.4929237365722656
Batch 55/64 loss: -0.7389698028564453
Batch 56/64 loss: 0.26543712615966797
Batch 57/64 loss: -0.06985759735107422
Batch 58/64 loss: -0.5114040374755859
Batch 59/64 loss: -0.6324167251586914
Batch 60/64 loss: -0.6436824798583984
Batch 61/64 loss: -0.20818233489990234
Batch 62/64 loss: -0.5477123260498047
Batch 63/64 loss: -0.7894382476806641
Batch 64/64 loss: -4.244855880737305
Epoch 66  Train loss: -0.3274589314180262  Val loss: -0.4431394203421996
Epoch 67
-------------------------------
Batch 1/64 loss: -0.5965604782104492
Batch 2/64 loss: -0.7957010269165039
Batch 3/64 loss: -0.3033180236816406
Batch 4/64 loss: -0.530604362487793
Batch 5/64 loss: -0.561823844909668
Batch 6/64 loss: -0.5087099075317383
Batch 7/64 loss: -0.2886466979980469
Batch 8/64 loss: -0.7339191436767578
Batch 9/64 loss: 0.502471923828125
Batch 10/64 loss: -0.6498394012451172
Batch 11/64 loss: -0.40677833557128906
Batch 12/64 loss: -0.7026777267456055
Batch 13/64 loss: -0.6108388900756836
Batch 14/64 loss: -0.4297447204589844
Batch 15/64 loss: -0.4908018112182617
Batch 16/64 loss: -0.5578575134277344
Batch 17/64 loss: -0.5252647399902344
Batch 18/64 loss: -0.45673179626464844
Batch 19/64 loss: -0.3379201889038086
Batch 20/64 loss: 0.34971141815185547
Batch 21/64 loss: -0.42201709747314453
Batch 22/64 loss: -0.5807952880859375
Batch 23/64 loss: -0.5703029632568359
Batch 24/64 loss: -0.6886634826660156
Batch 25/64 loss: -0.6753139495849609
Batch 26/64 loss: -0.4214601516723633
Batch 27/64 loss: -0.6769418716430664
Batch 28/64 loss: -0.5067739486694336
Batch 29/64 loss: -0.3389625549316406
Batch 30/64 loss: 0.17979812622070312
Batch 31/64 loss: 0.003977775573730469
Batch 32/64 loss: 0.11909103393554688
Batch 33/64 loss: -0.6932601928710938
Batch 34/64 loss: -0.7814493179321289
Batch 35/64 loss: -0.5453739166259766
Batch 36/64 loss: -0.2914581298828125
Batch 37/64 loss: 0.28056907653808594
Batch 38/64 loss: -0.4735269546508789
Batch 39/64 loss: -0.7204856872558594
Batch 40/64 loss: -0.6682548522949219
Batch 41/64 loss: -0.24067115783691406
Batch 42/64 loss: -0.9212608337402344
Batch 43/64 loss: -0.7963066101074219
Batch 44/64 loss: -0.4738121032714844
Batch 45/64 loss: 0.09613895416259766
Batch 46/64 loss: -0.36098766326904297
Batch 47/64 loss: -0.5690765380859375
Batch 48/64 loss: -0.7042989730834961
Batch 49/64 loss: -0.19844341278076172
Batch 50/64 loss: -0.669672966003418
Batch 51/64 loss: -0.6846599578857422
Batch 52/64 loss: -0.6802148818969727
Batch 53/64 loss: -0.8783884048461914
Batch 54/64 loss: -0.12794780731201172
Batch 55/64 loss: -0.5469245910644531
Batch 56/64 loss: -0.8221511840820312
Batch 57/64 loss: -0.9399099349975586
Batch 58/64 loss: -0.38206958770751953
Batch 59/64 loss: -0.4559812545776367
Batch 60/64 loss: -0.8093233108520508
Batch 61/64 loss: -0.06713390350341797
Batch 62/64 loss: -0.5023670196533203
Batch 63/64 loss: -0.5050992965698242
Batch 64/64 loss: -4.798882961273193
Epoch 67  Train loss: -0.516813870972278  Val loss: -0.854969902956199
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: -0.6494150161743164
Batch 2/64 loss: -0.4426259994506836
Batch 3/64 loss: -0.4765329360961914
Batch 4/64 loss: -0.43259429931640625
Batch 5/64 loss: -0.8878898620605469
Batch 6/64 loss: -0.2829408645629883
Batch 7/64 loss: -0.5226621627807617
Batch 8/64 loss: -0.7799129486083984
Batch 9/64 loss: 0.09706306457519531
Batch 10/64 loss: -0.4819812774658203
Batch 11/64 loss: -0.5506439208984375
Batch 12/64 loss: -0.5340423583984375
Batch 13/64 loss: -0.6829853057861328
Batch 14/64 loss: -0.7280664443969727
Batch 15/64 loss: -0.5780677795410156
Batch 16/64 loss: -0.6299304962158203
Batch 17/64 loss: -0.45914745330810547
Batch 18/64 loss: -0.8627958297729492
Batch 19/64 loss: -0.7924623489379883
Batch 20/64 loss: -0.5658979415893555
Batch 21/64 loss: -0.4781656265258789
Batch 22/64 loss: -0.4456672668457031
Batch 23/64 loss: -0.9804391860961914
Batch 24/64 loss: -0.40219783782958984
Batch 25/64 loss: -0.3400735855102539
Batch 26/64 loss: -0.7396726608276367
Batch 27/64 loss: -0.6702995300292969
Batch 28/64 loss: -0.7202043533325195
Batch 29/64 loss: -0.3314056396484375
Batch 30/64 loss: -0.5292654037475586
Batch 31/64 loss: -1.0723686218261719
Batch 32/64 loss: -0.46866607666015625
Batch 33/64 loss: -0.17513370513916016
Batch 34/64 loss: -1.0250530242919922
Batch 35/64 loss: -0.8445310592651367
Batch 36/64 loss: -0.7856340408325195
Batch 37/64 loss: -0.9259166717529297
Batch 38/64 loss: -0.7652196884155273
Batch 39/64 loss: -0.6090755462646484
Batch 40/64 loss: -0.6370172500610352
Batch 41/64 loss: -0.6217460632324219
Batch 42/64 loss: -0.6553878784179688
Batch 43/64 loss: -0.40537071228027344
Batch 44/64 loss: -0.5740270614624023
Batch 45/64 loss: -0.7100830078125
Batch 46/64 loss: -0.40445423126220703
Batch 47/64 loss: -0.24742794036865234
Batch 48/64 loss: -0.8206520080566406
Batch 49/64 loss: -0.818568229675293
Batch 50/64 loss: -0.6518478393554688
Batch 51/64 loss: 0.40519237518310547
Batch 52/64 loss: -0.9310159683227539
Batch 53/64 loss: -0.40007495880126953
Batch 54/64 loss: -0.37767601013183594
Batch 55/64 loss: -0.23783206939697266
Batch 56/64 loss: -0.8003396987915039
Batch 57/64 loss: -0.39098358154296875
Batch 58/64 loss: -0.7229976654052734
Batch 59/64 loss: -0.7890491485595703
Batch 60/64 loss: -0.8225107192993164
Batch 61/64 loss: -0.9253072738647461
Batch 62/64 loss: -0.08382320404052734
Batch 63/64 loss: -0.7370128631591797
Batch 64/64 loss: -4.993856430053711
Epoch 68  Train loss: -0.6377714044907514  Val loss: -0.9030654618830206
Saving best model, epoch: 68
Epoch 69
-------------------------------
Batch 1/64 loss: -0.5294332504272461
Batch 2/64 loss: -0.4072914123535156
Batch 3/64 loss: -0.6746892929077148
Batch 4/64 loss: -0.41437435150146484
Batch 5/64 loss: -0.49420833587646484
Batch 6/64 loss: 0.021674156188964844
Batch 7/64 loss: -0.7531652450561523
Batch 8/64 loss: -0.8761482238769531
Batch 9/64 loss: -0.2831697463989258
Batch 10/64 loss: -0.9017753601074219
Batch 11/64 loss: -0.29831504821777344
Batch 12/64 loss: -0.19800472259521484
Batch 13/64 loss: -0.35912418365478516
Batch 14/64 loss: -0.7251071929931641
Batch 15/64 loss: -0.6903867721557617
Batch 16/64 loss: -0.8991594314575195
Batch 17/64 loss: -0.6710109710693359
Batch 18/64 loss: -1.0983810424804688
Batch 19/64 loss: -0.5362529754638672
Batch 20/64 loss: -0.9257526397705078
Batch 21/64 loss: -0.7789411544799805
Batch 22/64 loss: -0.7946033477783203
Batch 23/64 loss: -0.7461795806884766
Batch 24/64 loss: -0.7217597961425781
Batch 25/64 loss: -0.7810897827148438
Batch 26/64 loss: -0.7889919281005859
Batch 27/64 loss: -0.9940872192382812
Batch 28/64 loss: -0.5533714294433594
Batch 29/64 loss: -0.68511962890625
Batch 30/64 loss: -0.5121488571166992
Batch 31/64 loss: -0.4729948043823242
Batch 32/64 loss: -0.5601167678833008
Batch 33/64 loss: -0.66357421875
Batch 34/64 loss: -0.6871213912963867
Batch 35/64 loss: -0.7281618118286133
Batch 36/64 loss: -0.6463527679443359
Batch 37/64 loss: -0.6790151596069336
Batch 38/64 loss: -0.7119283676147461
Batch 39/64 loss: -0.723628044128418
Batch 40/64 loss: -0.8008518218994141
Batch 41/64 loss: -0.9503746032714844
Batch 42/64 loss: -0.8227119445800781
Batch 43/64 loss: -0.7420930862426758
Batch 44/64 loss: -0.4298410415649414
Batch 45/64 loss: -0.6479740142822266
Batch 46/64 loss: -0.4585990905761719
Batch 47/64 loss: -0.6643028259277344
Batch 48/64 loss: -0.8205957412719727
Batch 49/64 loss: 0.2557401657104492
Batch 50/64 loss: -0.3585977554321289
Batch 51/64 loss: -0.5913896560668945
Batch 52/64 loss: -0.8995761871337891
Batch 53/64 loss: -0.8716220855712891
Batch 54/64 loss: -0.47307586669921875
Batch 55/64 loss: -0.6237688064575195
Batch 56/64 loss: -0.2839488983154297
Batch 57/64 loss: -0.6661968231201172
Batch 58/64 loss: -0.6166934967041016
Batch 59/64 loss: -0.7974510192871094
Batch 60/64 loss: -0.65740966796875
Batch 61/64 loss: -0.7335939407348633
Batch 62/64 loss: -0.6445446014404297
Batch 63/64 loss: -0.8259706497192383
Batch 64/64 loss: -4.915467262268066
Epoch 69  Train loss: -0.6863577412623986  Val loss: -0.9423721156169459
Saving best model, epoch: 69
Epoch 70
-------------------------------
Batch 1/64 loss: -0.6277046203613281
Batch 2/64 loss: -0.6937808990478516
Batch 3/64 loss: -1.1467361450195312
Batch 4/64 loss: -0.32465076446533203
Batch 5/64 loss: -1.0864171981811523
Batch 6/64 loss: -0.5309810638427734
Batch 7/64 loss: 0.14884376525878906
Batch 8/64 loss: -1.012711524963379
Batch 9/64 loss: -0.6747627258300781
Batch 10/64 loss: -0.812626838684082
Batch 11/64 loss: -0.7922019958496094
Batch 12/64 loss: -0.8320436477661133
Batch 13/64 loss: -0.5243740081787109
Batch 14/64 loss: -0.5154285430908203
Batch 15/64 loss: -0.6828603744506836
Batch 16/64 loss: -0.8922739028930664
Batch 17/64 loss: -0.8126974105834961
Batch 18/64 loss: -0.5464210510253906
Batch 19/64 loss: -0.8348770141601562
Batch 20/64 loss: -0.9954338073730469
Batch 21/64 loss: -0.3156089782714844
Batch 22/64 loss: -0.6693477630615234
Batch 23/64 loss: -0.8925619125366211
Batch 24/64 loss: -0.8174476623535156
Batch 25/64 loss: -0.8515129089355469
Batch 26/64 loss: 0.5260906219482422
Batch 27/64 loss: -0.4343585968017578
Batch 28/64 loss: 0.09297943115234375
Batch 29/64 loss: -0.8967905044555664
Batch 30/64 loss: -0.47211360931396484
Batch 31/64 loss: -0.8746213912963867
Batch 32/64 loss: -0.7300729751586914
Batch 33/64 loss: -0.7948131561279297
Batch 34/64 loss: -0.7351541519165039
Batch 35/64 loss: -0.6093425750732422
Batch 36/64 loss: -1.1060056686401367
Batch 37/64 loss: -1.0878162384033203
Batch 38/64 loss: -0.8928861618041992
Batch 39/64 loss: -0.5347356796264648
Batch 40/64 loss: -0.3378887176513672
Batch 41/64 loss: -1.0872459411621094
Batch 42/64 loss: -0.8668766021728516
Batch 43/64 loss: -0.8356351852416992
Batch 44/64 loss: -0.7447195053100586
Batch 45/64 loss: -0.7186079025268555
Batch 46/64 loss: -0.7647113800048828
Batch 47/64 loss: -0.7813653945922852
Batch 48/64 loss: -0.7436113357543945
Batch 49/64 loss: -0.5726146697998047
Batch 50/64 loss: -0.5858917236328125
Batch 51/64 loss: -0.8053655624389648
Batch 52/64 loss: -0.6017465591430664
Batch 53/64 loss: -0.8967227935791016
Batch 54/64 loss: -0.8332958221435547
Batch 55/64 loss: -0.2592430114746094
Batch 56/64 loss: -0.7087898254394531
Batch 57/64 loss: -0.13042068481445312
Batch 58/64 loss: -0.7573671340942383
Batch 59/64 loss: -0.5502424240112305
Batch 60/64 loss: -0.5368843078613281
Batch 61/64 loss: -0.9007349014282227
Batch 62/64 loss: -0.6611213684082031
Batch 63/64 loss: -0.7306108474731445
Batch 64/64 loss: -4.72238302230835
Epoch 70  Train loss: -0.7253295767541025  Val loss: -0.4118004238482603
Epoch 71
-------------------------------
Batch 1/64 loss: -0.7376480102539062
Batch 2/64 loss: -0.6857538223266602
Batch 3/64 loss: -0.6050214767456055
Batch 4/64 loss: -0.5797853469848633
Batch 5/64 loss: -0.7554492950439453
Batch 6/64 loss: 0.37214088439941406
Batch 7/64 loss: -0.7094974517822266
Batch 8/64 loss: -0.6604223251342773
Batch 9/64 loss: -0.4377174377441406
Batch 10/64 loss: -0.3415794372558594
Batch 11/64 loss: 0.2902402877807617
Batch 12/64 loss: -0.03959846496582031
Batch 13/64 loss: -0.4930849075317383
Batch 14/64 loss: -0.7963113784790039
Batch 15/64 loss: -0.9547252655029297
Batch 16/64 loss: -0.2277965545654297
Batch 17/64 loss: -0.5530776977539062
Batch 18/64 loss: -0.6442527770996094
Batch 19/64 loss: -0.4933509826660156
Batch 20/64 loss: -0.8003149032592773
Batch 21/64 loss: -0.9694032669067383
Batch 22/64 loss: -0.6709976196289062
Batch 23/64 loss: -0.6813201904296875
Batch 24/64 loss: -0.6456756591796875
Batch 25/64 loss: -0.8420038223266602
Batch 26/64 loss: -0.15365123748779297
Batch 27/64 loss: -0.6007041931152344
Batch 28/64 loss: -0.5251121520996094
Batch 29/64 loss: -0.6745357513427734
Batch 30/64 loss: -0.6047029495239258
Batch 31/64 loss: -0.9065513610839844
Batch 32/64 loss: -0.6354942321777344
Batch 33/64 loss: -0.5120878219604492
Batch 34/64 loss: -0.3038339614868164
Batch 35/64 loss: -0.8596296310424805
Batch 36/64 loss: -0.31623172760009766
Batch 37/64 loss: -0.6213550567626953
Batch 38/64 loss: -0.7711830139160156
Batch 39/64 loss: -0.931035041809082
Batch 40/64 loss: -0.26586246490478516
Batch 41/64 loss: -0.7786836624145508
Batch 42/64 loss: -0.9807395935058594
Batch 43/64 loss: -1.1351890563964844
Batch 44/64 loss: -0.7724437713623047
Batch 45/64 loss: -0.897984504699707
Batch 46/64 loss: -0.7285308837890625
Batch 47/64 loss: -0.40708160400390625
Batch 48/64 loss: -1.0952911376953125
Batch 49/64 loss: -0.8148164749145508
Batch 50/64 loss: -0.8132705688476562
Batch 51/64 loss: -0.3816080093383789
Batch 52/64 loss: -0.888545036315918
Batch 53/64 loss: -0.7224159240722656
Batch 54/64 loss: -0.5929574966430664
Batch 55/64 loss: -0.9538202285766602
Batch 56/64 loss: -0.6411380767822266
Batch 57/64 loss: -0.8672447204589844
Batch 58/64 loss: -0.7902050018310547
Batch 59/64 loss: -0.9434003829956055
Batch 60/64 loss: -0.6545782089233398
Batch 61/64 loss: -0.35736846923828125
Batch 62/64 loss: -0.6671371459960938
Batch 63/64 loss: -0.927459716796875
Batch 64/64 loss: -4.298978805541992
Epoch 71  Train loss: -0.6804787654502719  Val loss: -0.6565590822409928
Epoch 72
-------------------------------
Batch 1/64 loss: -0.7391128540039062
Batch 2/64 loss: -0.46038246154785156
Batch 3/64 loss: -0.7914667129516602
Batch 4/64 loss: -0.7095365524291992
Batch 5/64 loss: -0.5861406326293945
Batch 6/64 loss: -0.48638153076171875
Batch 7/64 loss: -0.6647510528564453
Batch 8/64 loss: -0.9330615997314453
Batch 9/64 loss: -0.9919528961181641
Batch 10/64 loss: -0.5380258560180664
Batch 11/64 loss: -0.7815370559692383
Batch 12/64 loss: -0.9321327209472656
Batch 13/64 loss: -0.9628314971923828
Batch 14/64 loss: -0.6502313613891602
Batch 15/64 loss: -0.5686330795288086
Batch 16/64 loss: -0.1444416046142578
Batch 17/64 loss: -0.6683330535888672
Batch 18/64 loss: -0.7360019683837891
Batch 19/64 loss: -0.4200000762939453
Batch 20/64 loss: -0.6026782989501953
Batch 21/64 loss: -0.8559303283691406
Batch 22/64 loss: -0.6979703903198242
Batch 23/64 loss: -0.4033641815185547
Batch 24/64 loss: -0.5561418533325195
Batch 25/64 loss: -0.6214046478271484
Batch 26/64 loss: -0.5885438919067383
Batch 27/64 loss: -0.8421030044555664
Batch 28/64 loss: -0.8840799331665039
Batch 29/64 loss: -0.3090324401855469
Batch 30/64 loss: -0.22789382934570312
Batch 31/64 loss: -0.6416492462158203
Batch 32/64 loss: -0.7995719909667969
Batch 33/64 loss: -0.9800539016723633
Batch 34/64 loss: -0.7622737884521484
Batch 35/64 loss: -0.7173185348510742
Batch 36/64 loss: -0.9489297866821289
Batch 37/64 loss: -0.8487977981567383
Batch 38/64 loss: -0.976099967956543
Batch 39/64 loss: -1.0725507736206055
Batch 40/64 loss: -0.9759531021118164
Batch 41/64 loss: -0.7457675933837891
Batch 42/64 loss: -0.9106740951538086
Batch 43/64 loss: -0.8506879806518555
Batch 44/64 loss: -0.5718011856079102
Batch 45/64 loss: -0.7099847793579102
Batch 46/64 loss: 0.3862724304199219
Batch 47/64 loss: -1.1470575332641602
Batch 48/64 loss: -0.7451972961425781
Batch 49/64 loss: -0.5144214630126953
Batch 50/64 loss: -0.8326826095581055
Batch 51/64 loss: 0.18774700164794922
Batch 52/64 loss: -0.9079561233520508
Batch 53/64 loss: -0.7640657424926758
Batch 54/64 loss: -0.905797004699707
Batch 55/64 loss: -0.47469615936279297
Batch 56/64 loss: -0.4483327865600586
Batch 57/64 loss: -0.6048173904418945
Batch 58/64 loss: -0.7017316818237305
Batch 59/64 loss: -1.0069589614868164
Batch 60/64 loss: -0.7144641876220703
Batch 61/64 loss: 0.19901084899902344
Batch 62/64 loss: -0.8654384613037109
Batch 63/64 loss: -0.6346378326416016
Batch 64/64 loss: -5.077785968780518
Epoch 72  Train loss: -0.7242317854189405  Val loss: -0.8314451892761021
Epoch 73
-------------------------------
Batch 1/64 loss: -1.1900568008422852
Batch 2/64 loss: -0.8362541198730469
Batch 3/64 loss: -0.5957193374633789
Batch 4/64 loss: -0.7896499633789062
Batch 5/64 loss: -0.9735908508300781
Batch 6/64 loss: -0.7285957336425781
Batch 7/64 loss: -0.891118049621582
Batch 8/64 loss: -0.7104320526123047
Batch 9/64 loss: -0.8816909790039062
Batch 10/64 loss: -0.9892787933349609
Batch 11/64 loss: -1.0162630081176758
Batch 12/64 loss: -0.46297645568847656
Batch 13/64 loss: -0.227508544921875
Batch 14/64 loss: -1.0963096618652344
Batch 15/64 loss: -0.4212007522583008
Batch 16/64 loss: -0.646000862121582
Batch 17/64 loss: -0.9680261611938477
Batch 18/64 loss: -0.6685018539428711
Batch 19/64 loss: -0.9454669952392578
Batch 20/64 loss: -0.4111156463623047
Batch 21/64 loss: -0.3919496536254883
Batch 22/64 loss: -0.28858470916748047
Batch 23/64 loss: -0.6382064819335938
Batch 24/64 loss: -1.0230169296264648
Batch 25/64 loss: -0.9167118072509766
Batch 26/64 loss: -0.46442222595214844
Batch 27/64 loss: -0.3582038879394531
Batch 28/64 loss: -0.9454679489135742
Batch 29/64 loss: -0.5404787063598633
Batch 30/64 loss: -0.772186279296875
Batch 31/64 loss: -0.9544601440429688
Batch 32/64 loss: -0.6358537673950195
Batch 33/64 loss: -0.7983236312866211
Batch 34/64 loss: -0.6978492736816406
Batch 35/64 loss: -0.12831497192382812
Batch 36/64 loss: -0.8379592895507812
Batch 37/64 loss: 0.050431251525878906
Batch 38/64 loss: -0.7721700668334961
Batch 39/64 loss: -0.8537673950195312
Batch 40/64 loss: -0.9355640411376953
Batch 41/64 loss: -0.23994064331054688
Batch 42/64 loss: -0.918004035949707
Batch 43/64 loss: -0.7532978057861328
Batch 44/64 loss: -0.4304380416870117
Batch 45/64 loss: -0.8814191818237305
Batch 46/64 loss: -0.7545070648193359
Batch 47/64 loss: -0.6653013229370117
Batch 48/64 loss: -0.8650264739990234
Batch 49/64 loss: -0.8284206390380859
Batch 50/64 loss: -0.8305377960205078
Batch 51/64 loss: -0.62677001953125
Batch 52/64 loss: -0.4434165954589844
Batch 53/64 loss: -1.0547246932983398
Batch 54/64 loss: -1.0102996826171875
Batch 55/64 loss: -0.29139041900634766
Batch 56/64 loss: -0.6527795791625977
Batch 57/64 loss: -0.5991430282592773
Batch 58/64 loss: -0.9743614196777344
Batch 59/64 loss: -0.6686115264892578
Batch 60/64 loss: -0.8848953247070312
Batch 61/64 loss: -0.5133657455444336
Batch 62/64 loss: 0.1725902557373047
Batch 63/64 loss: -1.0321636199951172
Batch 64/64 loss: -4.847559452056885
Epoch 73  Train loss: -0.7487797737121582  Val loss: -0.9226051540309211
Epoch 74
-------------------------------
Batch 1/64 loss: -0.5312652587890625
Batch 2/64 loss: -0.9826412200927734
Batch 3/64 loss: -0.92431640625
Batch 4/64 loss: -0.9740104675292969
Batch 5/64 loss: -0.2742013931274414
Batch 6/64 loss: -0.84515380859375
Batch 7/64 loss: -0.5435895919799805
Batch 8/64 loss: -0.8745479583740234
Batch 9/64 loss: -1.0158329010009766
Batch 10/64 loss: -1.0430164337158203
Batch 11/64 loss: -0.9259662628173828
Batch 12/64 loss: -1.2973899841308594
Batch 13/64 loss: -0.8677024841308594
Batch 14/64 loss: -0.6533994674682617
Batch 15/64 loss: -0.528285026550293
Batch 16/64 loss: 0.1265401840209961
Batch 17/64 loss: 0.11632919311523438
Batch 18/64 loss: -1.1362886428833008
Batch 19/64 loss: -0.30838775634765625
Batch 20/64 loss: -0.7395105361938477
Batch 21/64 loss: -0.3742399215698242
Batch 22/64 loss: -1.1695241928100586
Batch 23/64 loss: -0.5253705978393555
Batch 24/64 loss: -0.0845174789428711
Batch 25/64 loss: -0.9621982574462891
Batch 26/64 loss: -0.6906375885009766
Batch 27/64 loss: -0.31257152557373047
Batch 28/64 loss: -0.5280265808105469
Batch 29/64 loss: -0.6837253570556641
Batch 30/64 loss: -1.1726760864257812
Batch 31/64 loss: -0.7169666290283203
Batch 32/64 loss: -0.6675786972045898
Batch 33/64 loss: -0.7476329803466797
Batch 34/64 loss: -0.4346160888671875
Batch 35/64 loss: -1.1417436599731445
Batch 36/64 loss: -0.8462944030761719
Batch 37/64 loss: -0.5904159545898438
Batch 38/64 loss: -0.6609611511230469
Batch 39/64 loss: -0.6076860427856445
Batch 40/64 loss: -0.6949844360351562
Batch 41/64 loss: -0.809382438659668
Batch 42/64 loss: -0.29460716247558594
Batch 43/64 loss: -0.5996627807617188
Batch 44/64 loss: -1.2045917510986328
Batch 45/64 loss: -0.9123687744140625
Batch 46/64 loss: -0.6741218566894531
Batch 47/64 loss: -0.43880271911621094
Batch 48/64 loss: -0.8661317825317383
Batch 49/64 loss: -0.8257150650024414
Batch 50/64 loss: -0.8173847198486328
Batch 51/64 loss: -0.1900167465209961
Batch 52/64 loss: -0.8218717575073242
Batch 53/64 loss: -0.4060964584350586
Batch 54/64 loss: -1.2399101257324219
Batch 55/64 loss: -0.25609397888183594
Batch 56/64 loss: -0.8270807266235352
Batch 57/64 loss: -0.9080867767333984
Batch 58/64 loss: -0.7438898086547852
Batch 59/64 loss: -0.5083370208740234
Batch 60/64 loss: -0.9377374649047852
Batch 61/64 loss: 0.3199281692504883
Batch 62/64 loss: -0.6095695495605469
Batch 63/64 loss: -0.8382883071899414
Batch 64/64 loss: -4.973647117614746
Epoch 74  Train loss: -0.7368636673572017  Val loss: -0.9504459027162532
Saving best model, epoch: 74
Epoch 75
-------------------------------
Batch 1/64 loss: -1.3165884017944336
Batch 2/64 loss: -0.9218149185180664
Batch 3/64 loss: -0.7200222015380859
Batch 4/64 loss: -0.8502359390258789
Batch 5/64 loss: -0.8408517837524414
Batch 6/64 loss: -0.8954238891601562
Batch 7/64 loss: -0.9510021209716797
Batch 8/64 loss: -0.8070220947265625
Batch 9/64 loss: -0.844782829284668
Batch 10/64 loss: -0.7764854431152344
Batch 11/64 loss: -0.6445245742797852
Batch 12/64 loss: -0.993138313293457
Batch 13/64 loss: -0.9600334167480469
Batch 14/64 loss: -1.013082504272461
Batch 15/64 loss: -0.5182228088378906
Batch 16/64 loss: -0.6906471252441406
Batch 17/64 loss: -0.35918521881103516
Batch 18/64 loss: -0.3391704559326172
Batch 19/64 loss: -0.9143924713134766
Batch 20/64 loss: -0.8501415252685547
Batch 21/64 loss: -0.7284173965454102
Batch 22/64 loss: -0.6714630126953125
Batch 23/64 loss: -0.855677604675293
Batch 24/64 loss: -0.8530330657958984
Batch 25/64 loss: -0.2960987091064453
Batch 26/64 loss: -0.7748737335205078
Batch 27/64 loss: -0.7861423492431641
Batch 28/64 loss: -1.1523551940917969
Batch 29/64 loss: -0.865138053894043
Batch 30/64 loss: -0.8900346755981445
Batch 31/64 loss: -0.7202177047729492
Batch 32/64 loss: -1.2552766799926758
Batch 33/64 loss: -0.9962139129638672
Batch 34/64 loss: -0.7575559616088867
Batch 35/64 loss: -0.7746820449829102
Batch 36/64 loss: -0.8060274124145508
Batch 37/64 loss: -0.46895885467529297
Batch 38/64 loss: -0.8099603652954102
Batch 39/64 loss: -0.7514591217041016
Batch 40/64 loss: -0.8409957885742188
Batch 41/64 loss: -1.0781145095825195
Batch 42/64 loss: -0.7377910614013672
Batch 43/64 loss: -0.43869876861572266
Batch 44/64 loss: -1.055044174194336
Batch 45/64 loss: -0.8523483276367188
Batch 46/64 loss: -0.2784891128540039
Batch 47/64 loss: -1.0523014068603516
Batch 48/64 loss: -0.9196014404296875
Batch 49/64 loss: -0.8174009323120117
Batch 50/64 loss: -0.8477802276611328
Batch 51/64 loss: -0.4041881561279297
Batch 52/64 loss: -0.6347627639770508
Batch 53/64 loss: -0.8563442230224609
Batch 54/64 loss: -0.9004859924316406
Batch 55/64 loss: -0.7540502548217773
Batch 56/64 loss: -1.1871223449707031
Batch 57/64 loss: -0.2944526672363281
Batch 58/64 loss: 0.012206077575683594
Batch 59/64 loss: -0.6694793701171875
Batch 60/64 loss: -1.1114234924316406
Batch 61/64 loss: -0.45201683044433594
Batch 62/64 loss: -0.7806758880615234
Batch 63/64 loss: -0.5050525665283203
Batch 64/64 loss: -4.958079814910889
Epoch 75  Train loss: -0.8250247525233848  Val loss: -0.9587035424930533
Saving best model, epoch: 75
Epoch 76
-------------------------------
Batch 1/64 loss: -0.7921371459960938
Batch 2/64 loss: -0.9632530212402344
Batch 3/64 loss: -0.16771411895751953
Batch 4/64 loss: -0.8079643249511719
Batch 5/64 loss: -0.9511747360229492
Batch 6/64 loss: -0.7879867553710938
Batch 7/64 loss: -1.1990089416503906
Batch 8/64 loss: -1.0531959533691406
Batch 9/64 loss: -0.6169204711914062
Batch 10/64 loss: -0.7865362167358398
Batch 11/64 loss: -0.6982154846191406
Batch 12/64 loss: -0.7951803207397461
Batch 13/64 loss: -0.8010187149047852
Batch 14/64 loss: -0.9204864501953125
Batch 15/64 loss: -1.079024314880371
Batch 16/64 loss: -0.8440103530883789
Batch 17/64 loss: -1.2917022705078125
Batch 18/64 loss: -0.9492645263671875
Batch 19/64 loss: -1.0989770889282227
Batch 20/64 loss: -0.8947439193725586
Batch 21/64 loss: -0.6812448501586914
Batch 22/64 loss: -1.0975303649902344
Batch 23/64 loss: -0.8590812683105469
Batch 24/64 loss: -0.9728422164916992
Batch 25/64 loss: -0.890380859375
Batch 26/64 loss: -0.645421028137207
Batch 27/64 loss: -0.7554922103881836
Batch 28/64 loss: -0.6563081741333008
Batch 29/64 loss: -0.8154354095458984
Batch 30/64 loss: -0.9055461883544922
Batch 31/64 loss: -0.6267795562744141
Batch 32/64 loss: -0.6115283966064453
Batch 33/64 loss: -0.759119987487793
Batch 34/64 loss: -0.5442390441894531
Batch 35/64 loss: -1.042562484741211
Batch 36/64 loss: -0.3304290771484375
Batch 37/64 loss: -0.6730785369873047
Batch 38/64 loss: -1.0430173873901367
Batch 39/64 loss: -0.3206977844238281
Batch 40/64 loss: -0.7691431045532227
Batch 41/64 loss: -0.2679615020751953
Batch 42/64 loss: -0.42679500579833984
Batch 43/64 loss: -0.7150096893310547
Batch 44/64 loss: -0.9977941513061523
Batch 45/64 loss: -0.38771629333496094
Batch 46/64 loss: -0.8831033706665039
Batch 47/64 loss: -0.9752922058105469
Batch 48/64 loss: -0.8356218338012695
Batch 49/64 loss: -0.7347307205200195
Batch 50/64 loss: -0.6008224487304688
Batch 51/64 loss: -1.0762290954589844
Batch 52/64 loss: -0.5657377243041992
Batch 53/64 loss: -0.947667121887207
Batch 54/64 loss: -0.7664823532104492
Batch 55/64 loss: -1.1009407043457031
Batch 56/64 loss: -1.0707015991210938
Batch 57/64 loss: -1.0232906341552734
Batch 58/64 loss: -0.21554183959960938
Batch 59/64 loss: -0.6845216751098633
Batch 60/64 loss: -0.9820871353149414
Batch 61/64 loss: -0.7059955596923828
Batch 62/64 loss: -1.2330379486083984
Batch 63/64 loss: 0.16780567169189453
Batch 64/64 loss: -4.994051456451416
Epoch 76  Train loss: -0.8356581426134296  Val loss: -0.6134339820888034
Epoch 77
-------------------------------
Batch 1/64 loss: 0.24938678741455078
Batch 2/64 loss: -0.2826566696166992
Batch 3/64 loss: -0.4304475784301758
Batch 4/64 loss: -0.6327323913574219
Batch 5/64 loss: -0.34958362579345703
Batch 6/64 loss: -0.5986394882202148
Batch 7/64 loss: -0.9581146240234375
Batch 8/64 loss: -0.7885427474975586
Batch 9/64 loss: 0.11135482788085938
Batch 10/64 loss: -0.26873207092285156
Batch 11/64 loss: -0.561366081237793
Batch 12/64 loss: -0.3504676818847656
Batch 13/64 loss: -0.0775299072265625
Batch 14/64 loss: -0.6383953094482422
Batch 15/64 loss: -0.5660982131958008
Batch 16/64 loss: -0.8521661758422852
Batch 17/64 loss: -0.6465063095092773
Batch 18/64 loss: 0.0008907318115234375
Batch 19/64 loss: -0.6587076187133789
Batch 20/64 loss: -0.7877397537231445
Batch 21/64 loss: -0.9781227111816406
Batch 22/64 loss: -0.8345279693603516
Batch 23/64 loss: -0.40914440155029297
Batch 24/64 loss: -0.14695167541503906
Batch 25/64 loss: -1.0544891357421875
Batch 26/64 loss: 0.3170042037963867
Batch 27/64 loss: 0.1937084197998047
Batch 28/64 loss: -0.9258613586425781
Batch 29/64 loss: -0.804621696472168
Batch 30/64 loss: -0.07320785522460938
Batch 31/64 loss: -0.774662971496582
Batch 32/64 loss: -0.7776851654052734
Batch 33/64 loss: -0.5891666412353516
Batch 34/64 loss: -0.6930332183837891
Batch 35/64 loss: -0.9900894165039062
Batch 36/64 loss: -0.4175539016723633
Batch 37/64 loss: -0.23110103607177734
Batch 38/64 loss: -0.6104373931884766
Batch 39/64 loss: -0.7707633972167969
Batch 40/64 loss: -0.48824214935302734
Batch 41/64 loss: -0.30303192138671875
Batch 42/64 loss: -1.0786151885986328
Batch 43/64 loss: -0.6807937622070312
Batch 44/64 loss: -0.5319309234619141
Batch 45/64 loss: -0.6472015380859375
Batch 46/64 loss: -0.9121360778808594
Batch 47/64 loss: -0.8254165649414062
Batch 48/64 loss: 0.05192279815673828
Batch 49/64 loss: -0.938746452331543
Batch 50/64 loss: -0.8642539978027344
Batch 51/64 loss: -0.29917144775390625
Batch 52/64 loss: -0.7242937088012695
Batch 53/64 loss: -0.14829635620117188
Batch 54/64 loss: -0.9369335174560547
Batch 55/64 loss: -1.0034942626953125
Batch 56/64 loss: -0.939723014831543
Batch 57/64 loss: -1.0120325088500977
Batch 58/64 loss: -0.9118175506591797
Batch 59/64 loss: -0.8737268447875977
Batch 60/64 loss: -0.9002199172973633
Batch 61/64 loss: -0.7970790863037109
Batch 62/64 loss: -0.3989448547363281
Batch 63/64 loss: -0.647700309753418
Batch 64/64 loss: -4.385311126708984
Epoch 77  Train loss: -0.6236606074314491  Val loss: -1.0358851193562406
Saving best model, epoch: 77
Epoch 78
-------------------------------
Batch 1/64 loss: -0.7104902267456055
Batch 2/64 loss: 0.21857547760009766
Batch 3/64 loss: -0.7644643783569336
Batch 4/64 loss: -0.865814208984375
Batch 5/64 loss: -0.655512809753418
Batch 6/64 loss: -0.7174234390258789
Batch 7/64 loss: -0.8592290878295898
Batch 8/64 loss: -0.7535638809204102
Batch 9/64 loss: -0.8172988891601562
Batch 10/64 loss: -0.9174594879150391
Batch 11/64 loss: -0.74749755859375
Batch 12/64 loss: -1.0849113464355469
Batch 13/64 loss: -0.3637104034423828
Batch 14/64 loss: -0.9534664154052734
Batch 15/64 loss: -1.1066083908081055
Batch 16/64 loss: -0.6992816925048828
Batch 17/64 loss: -1.0426311492919922
Batch 18/64 loss: -1.083639144897461
Batch 19/64 loss: -1.0916376113891602
Batch 20/64 loss: -0.8032693862915039
Batch 21/64 loss: -0.5781965255737305
Batch 22/64 loss: -0.8727312088012695
Batch 23/64 loss: -0.8704462051391602
Batch 24/64 loss: -0.34560489654541016
Batch 25/64 loss: -0.6872014999389648
Batch 26/64 loss: -0.8209600448608398
Batch 27/64 loss: -0.9614744186401367
Batch 28/64 loss: -0.7903566360473633
Batch 29/64 loss: -0.49961280822753906
Batch 30/64 loss: -0.7033901214599609
Batch 31/64 loss: -1.1407461166381836
Batch 32/64 loss: -0.9276628494262695
Batch 33/64 loss: -0.20978832244873047
Batch 34/64 loss: -1.0427188873291016
Batch 35/64 loss: -0.6127996444702148
Batch 36/64 loss: -0.810175895690918
Batch 37/64 loss: -0.39270591735839844
Batch 38/64 loss: -1.0494918823242188
Batch 39/64 loss: -0.6652841567993164
Batch 40/64 loss: -0.8338146209716797
Batch 41/64 loss: -0.4720878601074219
Batch 42/64 loss: -0.8856706619262695
Batch 43/64 loss: -0.8892850875854492
Batch 44/64 loss: -0.9691696166992188
Batch 45/64 loss: -0.6494464874267578
Batch 46/64 loss: -0.6297760009765625
Batch 47/64 loss: -0.6673574447631836
Batch 48/64 loss: -0.7688560485839844
Batch 49/64 loss: -1.033517837524414
Batch 50/64 loss: -0.5977287292480469
Batch 51/64 loss: -0.8109807968139648
Batch 52/64 loss: -1.1256990432739258
Batch 53/64 loss: -0.7282590866088867
Batch 54/64 loss: -0.8271074295043945
Batch 55/64 loss: -0.9194879531860352
Batch 56/64 loss: -0.6838197708129883
Batch 57/64 loss: -0.47266197204589844
Batch 58/64 loss: -0.801417350769043
Batch 59/64 loss: -1.0315637588500977
Batch 60/64 loss: -0.7264862060546875
Batch 61/64 loss: -0.40291500091552734
Batch 62/64 loss: -0.9018287658691406
Batch 63/64 loss: -0.6562557220458984
Batch 64/64 loss: -5.143654823303223
Epoch 78  Train loss: -0.8179390813790116  Val loss: -1.0111638754094179
Epoch 79
-------------------------------
Batch 1/64 loss: -0.974583625793457
Batch 2/64 loss: -0.8745641708374023
Batch 3/64 loss: -0.8448543548583984
Batch 4/64 loss: -1.0004158020019531
Batch 5/64 loss: -0.6828947067260742
Batch 6/64 loss: -0.3900260925292969
Batch 7/64 loss: -0.8617830276489258
Batch 8/64 loss: -0.9452123641967773
Batch 9/64 loss: -0.6901702880859375
Batch 10/64 loss: -0.8902015686035156
Batch 11/64 loss: -0.8892011642456055
Batch 12/64 loss: -0.5539131164550781
Batch 13/64 loss: -0.8217964172363281
Batch 14/64 loss: -0.7712993621826172
Batch 15/64 loss: -0.7931070327758789
Batch 16/64 loss: -0.1824951171875
Batch 17/64 loss: -0.7581501007080078
Batch 18/64 loss: -0.6902608871459961
Batch 19/64 loss: -0.671849250793457
Batch 20/64 loss: -1.0396995544433594
Batch 21/64 loss: -1.198594093322754
Batch 22/64 loss: -0.7960586547851562
Batch 23/64 loss: -0.7808475494384766
Batch 24/64 loss: -0.6863279342651367
Batch 25/64 loss: -0.9576749801635742
Batch 26/64 loss: -1.0338220596313477
Batch 27/64 loss: -1.089158058166504
Batch 28/64 loss: -0.3519754409790039
Batch 29/64 loss: -0.8937416076660156
Batch 30/64 loss: -0.6683979034423828
Batch 31/64 loss: -0.39656543731689453
Batch 32/64 loss: -0.8133506774902344
Batch 33/64 loss: -1.0851736068725586
Batch 34/64 loss: -0.6861429214477539
Batch 35/64 loss: -0.8222007751464844
Batch 36/64 loss: -0.7974462509155273
Batch 37/64 loss: -0.9528360366821289
Batch 38/64 loss: -0.8682804107666016
Batch 39/64 loss: -0.7453927993774414
Batch 40/64 loss: -1.1918001174926758
Batch 41/64 loss: -0.8662481307983398
Batch 42/64 loss: -1.106637954711914
Batch 43/64 loss: -0.8189477920532227
Batch 44/64 loss: -0.8179416656494141
Batch 45/64 loss: -0.910374641418457
Batch 46/64 loss: -0.8805809020996094
Batch 47/64 loss: -0.9905605316162109
Batch 48/64 loss: -1.023787498474121
Batch 49/64 loss: -0.8453922271728516
Batch 50/64 loss: -1.0100336074829102
Batch 51/64 loss: -0.8445005416870117
Batch 52/64 loss: -0.88592529296875
Batch 53/64 loss: -0.2297954559326172
Batch 54/64 loss: -0.8302478790283203
Batch 55/64 loss: -0.17551612854003906
Batch 56/64 loss: -1.0732688903808594
Batch 57/64 loss: -0.3181896209716797
Batch 58/64 loss: -1.004547119140625
Batch 59/64 loss: -0.6636838912963867
Batch 60/64 loss: -0.23498249053955078
Batch 61/64 loss: -0.8419160842895508
Batch 62/64 loss: -0.7398166656494141
Batch 63/64 loss: -0.6691350936889648
Batch 64/64 loss: -4.915599346160889
Epoch 79  Train loss: -0.8409567832946777  Val loss: -0.7309327273024726
Epoch 80
-------------------------------
Batch 1/64 loss: -0.8292322158813477
Batch 2/64 loss: -0.9069509506225586
Batch 3/64 loss: -0.9732065200805664
Batch 4/64 loss: -1.013535499572754
Batch 5/64 loss: -0.7640676498413086
Batch 6/64 loss: -0.9178762435913086
Batch 7/64 loss: -0.5560026168823242
Batch 8/64 loss: -1.0866193771362305
Batch 9/64 loss: -0.8826465606689453
Batch 10/64 loss: -1.1442890167236328
Batch 11/64 loss: -0.8887271881103516
Batch 12/64 loss: -0.8489542007446289
Batch 13/64 loss: -1.0079221725463867
Batch 14/64 loss: -0.6090116500854492
Batch 15/64 loss: -0.9360389709472656
Batch 16/64 loss: -0.8663692474365234
Batch 17/64 loss: -0.9234867095947266
Batch 18/64 loss: -1.0323514938354492
Batch 19/64 loss: 0.3576498031616211
Batch 20/64 loss: -0.9565916061401367
Batch 21/64 loss: -1.1858816146850586
Batch 22/64 loss: -0.44533824920654297
Batch 23/64 loss: -0.901158332824707
Batch 24/64 loss: -0.5577898025512695
Batch 25/64 loss: -0.8794336318969727
Batch 26/64 loss: -0.7818784713745117
Batch 27/64 loss: -0.5360631942749023
Batch 28/64 loss: -0.3251066207885742
Batch 29/64 loss: -0.6654767990112305
Batch 30/64 loss: -0.9126701354980469
Batch 31/64 loss: -0.6440029144287109
Batch 32/64 loss: -0.6641473770141602
Batch 33/64 loss: -1.1609516143798828
Batch 34/64 loss: -0.5399618148803711
Batch 35/64 loss: -0.8515815734863281
Batch 36/64 loss: -0.9597702026367188
Batch 37/64 loss: -1.068338394165039
Batch 38/64 loss: -0.9107933044433594
Batch 39/64 loss: -0.6939468383789062
Batch 40/64 loss: -0.780634880065918
Batch 41/64 loss: -1.0994634628295898
Batch 42/64 loss: -0.6984987258911133
Batch 43/64 loss: -0.9605035781860352
Batch 44/64 loss: -0.33437252044677734
Batch 45/64 loss: -0.8947505950927734
Batch 46/64 loss: -0.8756895065307617
Batch 47/64 loss: -0.737518310546875
Batch 48/64 loss: -0.6274785995483398
Batch 49/64 loss: -0.9618206024169922
Batch 50/64 loss: -1.1490116119384766
Batch 51/64 loss: -1.0031452178955078
Batch 52/64 loss: -0.9939060211181641
Batch 53/64 loss: -0.7985172271728516
Batch 54/64 loss: -0.9283361434936523
Batch 55/64 loss: -0.5599765777587891
Batch 56/64 loss: -0.7180328369140625
Batch 57/64 loss: -0.7352056503295898
Batch 58/64 loss: 0.1147613525390625
Batch 59/64 loss: -1.0120134353637695
Batch 60/64 loss: -1.1824893951416016
Batch 61/64 loss: -1.0001296997070312
Batch 62/64 loss: -0.9483509063720703
Batch 63/64 loss: -0.658930778503418
Batch 64/64 loss: -5.161266326904297
Epoch 80  Train loss: -0.8609487944958256  Val loss: -1.1705933010455258
Saving best model, epoch: 80
Epoch 81
-------------------------------
Batch 1/64 loss: -0.7361974716186523
Batch 2/64 loss: -1.144301414489746
Batch 3/64 loss: -0.7069692611694336
Batch 4/64 loss: -1.13433837890625
Batch 5/64 loss: -1.0699262619018555
Batch 6/64 loss: -1.026651382446289
Batch 7/64 loss: -0.5085296630859375
Batch 8/64 loss: -1.0169239044189453
Batch 9/64 loss: -0.9360084533691406
Batch 10/64 loss: -0.5216207504272461
Batch 11/64 loss: -1.018336296081543
Batch 12/64 loss: -0.40920066833496094
Batch 13/64 loss: -0.7559213638305664
Batch 14/64 loss: -0.8700180053710938
Batch 15/64 loss: -1.2323827743530273
Batch 16/64 loss: -0.6772832870483398
Batch 17/64 loss: -0.7900199890136719
Batch 18/64 loss: -1.2310495376586914
Batch 19/64 loss: -0.8294105529785156
Batch 20/64 loss: -0.5222434997558594
Batch 21/64 loss: -1.192173957824707
Batch 22/64 loss: -1.077265739440918
Batch 23/64 loss: -0.3992776870727539
Batch 24/64 loss: -1.079935073852539
Batch 25/64 loss: -0.7812643051147461
Batch 26/64 loss: -0.74017333984375
Batch 27/64 loss: -0.8825922012329102
Batch 28/64 loss: -0.7679939270019531
Batch 29/64 loss: -0.9917392730712891
Batch 30/64 loss: -0.6667499542236328
Batch 31/64 loss: -0.3414268493652344
Batch 32/64 loss: -0.7342929840087891
Batch 33/64 loss: -1.0234928131103516
Batch 34/64 loss: -0.7819452285766602
Batch 35/64 loss: -0.9807157516479492
Batch 36/64 loss: -0.5356817245483398
Batch 37/64 loss: -0.6551790237426758
Batch 38/64 loss: -0.6811361312866211
Batch 39/64 loss: -0.8084888458251953
Batch 40/64 loss: -0.6533546447753906
Batch 41/64 loss: -0.5698108673095703
Batch 42/64 loss: -0.956974983215332
Batch 43/64 loss: -0.7115840911865234
Batch 44/64 loss: -0.6005678176879883
Batch 45/64 loss: -0.9430179595947266
Batch 46/64 loss: -0.9373607635498047
Batch 47/64 loss: -1.2384958267211914
Batch 48/64 loss: -0.2590322494506836
Batch 49/64 loss: -0.47069358825683594
Batch 50/64 loss: -0.9255838394165039
Batch 51/64 loss: -0.7950525283813477
Batch 52/64 loss: -0.9013299942016602
Batch 53/64 loss: -1.0264091491699219
Batch 54/64 loss: -1.0536823272705078
Batch 55/64 loss: -0.7705240249633789
Batch 56/64 loss: -0.8931560516357422
Batch 57/64 loss: -0.7643184661865234
Batch 58/64 loss: -0.9443111419677734
Batch 59/64 loss: -1.0181465148925781
Batch 60/64 loss: -1.2307205200195312
Batch 61/64 loss: -0.6920957565307617
Batch 62/64 loss: -0.5926237106323242
Batch 63/64 loss: -0.5993261337280273
Batch 64/64 loss: -5.052891731262207
Epoch 81  Train loss: -0.872105089823405  Val loss: -0.9608727288000363
Epoch 82
-------------------------------
Batch 1/64 loss: -0.6332969665527344
Batch 2/64 loss: -0.5176792144775391
Batch 3/64 loss: -0.8368215560913086
Batch 4/64 loss: -0.7429876327514648
Batch 5/64 loss: -0.7082386016845703
Batch 6/64 loss: -0.8604373931884766
Batch 7/64 loss: -0.7865056991577148
Batch 8/64 loss: -0.7007560729980469
Batch 9/64 loss: -1.043478012084961
Batch 10/64 loss: -0.712310791015625
Batch 11/64 loss: -0.7458553314208984
Batch 12/64 loss: -1.0067167282104492
Batch 13/64 loss: -0.9151487350463867
Batch 14/64 loss: -1.0310964584350586
Batch 15/64 loss: -1.2177305221557617
Batch 16/64 loss: 0.2240467071533203
Batch 17/64 loss: -0.8666181564331055
Batch 18/64 loss: -0.9763994216918945
Batch 19/64 loss: -0.9236583709716797
Batch 20/64 loss: -0.8947391510009766
Batch 21/64 loss: -0.7919111251831055
Batch 22/64 loss: -1.1281471252441406
Batch 23/64 loss: -0.7102680206298828
Batch 24/64 loss: -0.8719310760498047
Batch 25/64 loss: -0.526728630065918
Batch 26/64 loss: -0.7017784118652344
Batch 27/64 loss: -0.9332218170166016
Batch 28/64 loss: -0.5925407409667969
Batch 29/64 loss: -0.3055915832519531
Batch 30/64 loss: -0.5709943771362305
Batch 31/64 loss: -1.1366233825683594
Batch 32/64 loss: -0.6733369827270508
Batch 33/64 loss: -0.8131160736083984
Batch 34/64 loss: -1.1672563552856445
Batch 35/64 loss: -1.1509733200073242
Batch 36/64 loss: -1.0433349609375
Batch 37/64 loss: -0.8933601379394531
Batch 38/64 loss: -0.9511928558349609
Batch 39/64 loss: -0.9277267456054688
Batch 40/64 loss: -1.082651138305664
Batch 41/64 loss: -0.9667177200317383
Batch 42/64 loss: -0.9764928817749023
Batch 43/64 loss: -0.7826824188232422
Batch 44/64 loss: -1.2392463684082031
Batch 45/64 loss: -1.192317008972168
Batch 46/64 loss: -1.104593276977539
Batch 47/64 loss: -0.6795368194580078
Batch 48/64 loss: -0.802729606628418
Batch 49/64 loss: -0.9549732208251953
Batch 50/64 loss: -1.082961082458496
Batch 51/64 loss: -1.0568351745605469
Batch 52/64 loss: -0.9021100997924805
Batch 53/64 loss: -1.1286630630493164
Batch 54/64 loss: -1.2098636627197266
Batch 55/64 loss: -0.8940744400024414
Batch 56/64 loss: -1.0813522338867188
Batch 57/64 loss: -0.9071168899536133
Batch 58/64 loss: -1.037764549255371
Batch 59/64 loss: -1.2025938034057617
Batch 60/64 loss: -0.35042285919189453
Batch 61/64 loss: -0.6505918502807617
Batch 62/64 loss: -1.1857309341430664
Batch 63/64 loss: -0.8571643829345703
Batch 64/64 loss: -4.1086931228637695
Epoch 82  Train loss: -0.9128967397353228  Val loss: -1.177145653164264
Saving best model, epoch: 82
Epoch 83
-------------------------------
Batch 1/64 loss: -0.84747314453125
Batch 2/64 loss: -1.1223955154418945
Batch 3/64 loss: -0.7843608856201172
Batch 4/64 loss: -1.1087074279785156
Batch 5/64 loss: -1.1879053115844727
Batch 6/64 loss: -1.1343975067138672
Batch 7/64 loss: -1.1475067138671875
Batch 8/64 loss: -0.758906364440918
Batch 9/64 loss: -0.8213233947753906
Batch 10/64 loss: -0.893855094909668
Batch 11/64 loss: -0.007206916809082031
Batch 12/64 loss: -0.29018497467041016
Batch 13/64 loss: -0.7879457473754883
Batch 14/64 loss: -0.7495231628417969
Batch 15/64 loss: -0.899540901184082
Batch 16/64 loss: -0.5794353485107422
Batch 17/64 loss: -1.197169303894043
Batch 18/64 loss: -0.9031906127929688
Batch 19/64 loss: -1.0481395721435547
Batch 20/64 loss: -1.0075368881225586
Batch 21/64 loss: -1.0712881088256836
Batch 22/64 loss: -1.0715389251708984
Batch 23/64 loss: -1.1908283233642578
Batch 24/64 loss: -1.3458843231201172
Batch 25/64 loss: -0.835174560546875
Batch 26/64 loss: -0.9025001525878906
Batch 27/64 loss: -1.003281593322754
Batch 28/64 loss: -0.6284990310668945
Batch 29/64 loss: -0.9949159622192383
Batch 30/64 loss: -0.792759895324707
Batch 31/64 loss: -1.083786964416504
Batch 32/64 loss: -0.45640087127685547
Batch 33/64 loss: -0.7974538803100586
Batch 34/64 loss: -0.43842124938964844
Batch 35/64 loss: -0.6786766052246094
Batch 36/64 loss: -0.6935939788818359
Batch 37/64 loss: -0.19454574584960938
Batch 38/64 loss: -1.0414447784423828
Batch 39/64 loss: -1.103860855102539
Batch 40/64 loss: -0.793980598449707
Batch 41/64 loss: -0.8570013046264648
Batch 42/64 loss: -1.0105419158935547
Batch 43/64 loss: -1.0276832580566406
Batch 44/64 loss: -1.036250114440918
Batch 45/64 loss: -0.810272216796875
Batch 46/64 loss: -1.0450963973999023
Batch 47/64 loss: -0.5020790100097656
Batch 48/64 loss: -0.8117456436157227
Batch 49/64 loss: -1.0047807693481445
Batch 50/64 loss: -1.0269241333007812
Batch 51/64 loss: -0.6762247085571289
Batch 52/64 loss: -0.8737249374389648
Batch 53/64 loss: -0.9766368865966797
Batch 54/64 loss: -1.2232017517089844
Batch 55/64 loss: -0.3121051788330078
Batch 56/64 loss: -1.1809072494506836
Batch 57/64 loss: -1.3060941696166992
Batch 58/64 loss: -0.9234285354614258
Batch 59/64 loss: -1.1459283828735352
Batch 60/64 loss: -0.4847135543823242
Batch 61/64 loss: -0.9856109619140625
Batch 62/64 loss: -0.8943643569946289
Batch 63/64 loss: -0.6847009658813477
Batch 64/64 loss: -4.888269424438477
Epoch 83  Train loss: -0.923321720198089  Val loss: -1.2679524372533424
Saving best model, epoch: 83
Epoch 84
-------------------------------
Batch 1/64 loss: -0.9712162017822266
Batch 2/64 loss: -1.0300788879394531
Batch 3/64 loss: -0.7046976089477539
Batch 4/64 loss: -1.0086603164672852
Batch 5/64 loss: -0.8381786346435547
Batch 6/64 loss: -1.1339178085327148
Batch 7/64 loss: -1.0584096908569336
Batch 8/64 loss: -1.278916358947754
Batch 9/64 loss: -1.0488061904907227
Batch 10/64 loss: -1.2231950759887695
Batch 11/64 loss: -1.0392427444458008
Batch 12/64 loss: -0.9118795394897461
Batch 13/64 loss: -0.7383813858032227
Batch 14/64 loss: -0.36185455322265625
Batch 15/64 loss: -1.0421648025512695
Batch 16/64 loss: -0.9755630493164062
Batch 17/64 loss: -0.8088340759277344
Batch 18/64 loss: -0.645512580871582
Batch 19/64 loss: -1.03973388671875
Batch 20/64 loss: -0.7541675567626953
Batch 21/64 loss: -1.0311145782470703
Batch 22/64 loss: -0.8422269821166992
Batch 23/64 loss: -0.6785545349121094
Batch 24/64 loss: -0.4910135269165039
Batch 25/64 loss: -0.3805418014526367
Batch 26/64 loss: -0.6070165634155273
Batch 27/64 loss: -1.0066699981689453
Batch 28/64 loss: -0.4134359359741211
Batch 29/64 loss: -1.005335807800293
Batch 30/64 loss: -0.6867799758911133
Batch 31/64 loss: -1.0119380950927734
Batch 32/64 loss: -1.0815706253051758
Batch 33/64 loss: -0.6463623046875
Batch 34/64 loss: -0.8860969543457031
Batch 35/64 loss: -0.875401496887207
Batch 36/64 loss: -0.9243612289428711
Batch 37/64 loss: -0.8445901870727539
Batch 38/64 loss: -0.9142074584960938
Batch 39/64 loss: -0.8607606887817383
Batch 40/64 loss: -1.0349063873291016
Batch 41/64 loss: -0.6244869232177734
Batch 42/64 loss: -0.8172130584716797
Batch 43/64 loss: -0.6215105056762695
Batch 44/64 loss: -0.3278532028198242
Batch 45/64 loss: -0.886347770690918
Batch 46/64 loss: -1.043600082397461
Batch 47/64 loss: -0.8744478225708008
Batch 48/64 loss: -1.0383672714233398
Batch 49/64 loss: -1.010305404663086
Batch 50/64 loss: -1.0896930694580078
Batch 51/64 loss: -0.9400243759155273
Batch 52/64 loss: -0.7511444091796875
Batch 53/64 loss: -0.4778919219970703
Batch 54/64 loss: -0.1468038558959961
Batch 55/64 loss: -0.8659753799438477
Batch 56/64 loss: -0.7285375595092773
Batch 57/64 loss: -0.8163433074951172
Batch 58/64 loss: -0.8591985702514648
Batch 59/64 loss: -1.0019664764404297
Batch 60/64 loss: -1.048478126525879
Batch 61/64 loss: -1.0168800354003906
Batch 62/64 loss: -0.47115230560302734
Batch 63/64 loss: -0.6907157897949219
Batch 64/64 loss: -4.912361145019531
Epoch 84  Train loss: -0.8889333986768535  Val loss: -0.9809222401622235
Epoch 85
-------------------------------
Batch 1/64 loss: -0.8802852630615234
Batch 2/64 loss: -1.2364025115966797
Batch 3/64 loss: -1.2060489654541016
Batch 4/64 loss: -0.1870708465576172
Batch 5/64 loss: -0.870854377746582
Batch 6/64 loss: -0.7850122451782227
Batch 7/64 loss: -0.5168600082397461
Batch 8/64 loss: -1.0554122924804688
Batch 9/64 loss: -0.8521213531494141
Batch 10/64 loss: -1.0766382217407227
Batch 11/64 loss: -0.6653890609741211
Batch 12/64 loss: -0.6795902252197266
Batch 13/64 loss: -0.7389621734619141
Batch 14/64 loss: -1.0537090301513672
Batch 15/64 loss: -0.9411859512329102
Batch 16/64 loss: -0.9173746109008789
Batch 17/64 loss: -1.1648225784301758
Batch 18/64 loss: -0.8533115386962891
Batch 19/64 loss: -0.7580089569091797
Batch 20/64 loss: -0.7038660049438477
Batch 21/64 loss: -0.8001785278320312
Batch 22/64 loss: -1.0857696533203125
Batch 23/64 loss: -0.9462070465087891
Batch 24/64 loss: -0.9528894424438477
Batch 25/64 loss: -0.5997104644775391
Batch 26/64 loss: -1.1577415466308594
Batch 27/64 loss: -1.2746238708496094
Batch 28/64 loss: -0.4151039123535156
Batch 29/64 loss: -1.3130731582641602
Batch 30/64 loss: -0.7507572174072266
Batch 31/64 loss: 0.18915748596191406
Batch 32/64 loss: -0.9979763031005859
Batch 33/64 loss: -0.9354801177978516
Batch 34/64 loss: -0.7991867065429688
Batch 35/64 loss: -0.9800376892089844
Batch 36/64 loss: -1.13916015625
Batch 37/64 loss: -0.6026105880737305
Batch 38/64 loss: -0.9209775924682617
Batch 39/64 loss: -1.1948213577270508
Batch 40/64 loss: -1.065176010131836
Batch 41/64 loss: -1.09759521484375
Batch 42/64 loss: -0.9225263595581055
Batch 43/64 loss: -0.8570899963378906
Batch 44/64 loss: -1.1019468307495117
Batch 45/64 loss: -0.7076091766357422
Batch 46/64 loss: -0.9105339050292969
Batch 47/64 loss: -0.9588232040405273
Batch 48/64 loss: -0.8521633148193359
Batch 49/64 loss: -0.38373851776123047
Batch 50/64 loss: -0.3959503173828125
Batch 51/64 loss: -0.7041845321655273
Batch 52/64 loss: -0.8482580184936523
Batch 53/64 loss: -1.294022560119629
Batch 54/64 loss: -0.9896650314331055
Batch 55/64 loss: -0.9510879516601562
Batch 56/64 loss: -1.1189308166503906
Batch 57/64 loss: -0.8546772003173828
Batch 58/64 loss: -1.1587343215942383
Batch 59/64 loss: -0.9378232955932617
Batch 60/64 loss: -0.8608713150024414
Batch 61/64 loss: -1.0274772644042969
Batch 62/64 loss: -1.0285348892211914
Batch 63/64 loss: -0.972376823425293
Batch 64/64 loss: -4.787040710449219
Epoch 85  Train loss: -0.9319239448098575  Val loss: -1.0981792699020754
Epoch 86
-------------------------------
Batch 1/64 loss: -1.049412727355957
Batch 2/64 loss: -0.5367879867553711
Batch 3/64 loss: -0.46366119384765625
Batch 4/64 loss: -1.1326236724853516
Batch 5/64 loss: -0.48175621032714844
Batch 6/64 loss: -1.1945924758911133
Batch 7/64 loss: -0.9375228881835938
Batch 8/64 loss: -0.6378059387207031
Batch 9/64 loss: -0.7622089385986328
Batch 10/64 loss: -0.8866405487060547
Batch 11/64 loss: -1.2456855773925781
Batch 12/64 loss: -0.6656160354614258
Batch 13/64 loss: -0.7905521392822266
Batch 14/64 loss: -0.799159049987793
Batch 15/64 loss: -0.775609016418457
Batch 16/64 loss: -0.5908718109130859
Batch 17/64 loss: -1.0111722946166992
Batch 18/64 loss: -0.6942605972290039
Batch 19/64 loss: -0.8382129669189453
Batch 20/64 loss: -1.0115537643432617
Batch 21/64 loss: -1.0642938613891602
Batch 22/64 loss: -0.9838628768920898
Batch 23/64 loss: -1.1032705307006836
Batch 24/64 loss: -0.9779682159423828
Batch 25/64 loss: -0.9479656219482422
Batch 26/64 loss: -0.9435892105102539
Batch 27/64 loss: -0.22965240478515625
Batch 28/64 loss: -0.6600532531738281
Batch 29/64 loss: -0.8883552551269531
Batch 30/64 loss: -0.9098472595214844
Batch 31/64 loss: -0.8886289596557617
Batch 32/64 loss: -1.2407350540161133
Batch 33/64 loss: -0.5505847930908203
Batch 34/64 loss: -0.8957405090332031
Batch 35/64 loss: -1.2578706741333008
Batch 36/64 loss: -0.9424371719360352
Batch 37/64 loss: -0.5943050384521484
Batch 38/64 loss: -0.8915929794311523
Batch 39/64 loss: -0.9181671142578125
Batch 40/64 loss: -1.0352182388305664
Batch 41/64 loss: -0.6900129318237305
Batch 42/64 loss: -1.0597209930419922
Batch 43/64 loss: -1.1400203704833984
Batch 44/64 loss: -0.9680118560791016
Batch 45/64 loss: -0.9273214340209961
Batch 46/64 loss: -0.7241582870483398
Batch 47/64 loss: -0.6566696166992188
Batch 48/64 loss: -0.6614923477172852
Batch 49/64 loss: -0.8300142288208008
Batch 50/64 loss: -0.9668426513671875
Batch 51/64 loss: -0.9678153991699219
Batch 52/64 loss: -0.8660697937011719
Batch 53/64 loss: -0.9268779754638672
Batch 54/64 loss: -0.9868984222412109
Batch 55/64 loss: -1.0863103866577148
Batch 56/64 loss: -1.1410131454467773
Batch 57/64 loss: -0.6107368469238281
Batch 58/64 loss: -0.7961502075195312
Batch 59/64 loss: -1.3110771179199219
Batch 60/64 loss: -0.6945362091064453
Batch 61/64 loss: -1.1465559005737305
Batch 62/64 loss: -0.8482542037963867
Batch 63/64 loss: -0.6536722183227539
Batch 64/64 loss: -5.081028938293457
Epoch 86  Train loss: -0.9239348879047469  Val loss: -1.1677080790201824
Epoch 87
-------------------------------
Batch 1/64 loss: -0.9959802627563477
Batch 2/64 loss: -1.0936660766601562
Batch 3/64 loss: -0.5005455017089844
Batch 4/64 loss: -1.1944084167480469
Batch 5/64 loss: -1.2020206451416016
Batch 6/64 loss: -1.0585556030273438
Batch 7/64 loss: -0.26558399200439453
Batch 8/64 loss: -1.245366096496582
Batch 9/64 loss: -1.089681625366211
Batch 10/64 loss: -1.3406763076782227
Batch 11/64 loss: -0.2683982849121094
Batch 12/64 loss: -1.2940864562988281
Batch 13/64 loss: -0.9925537109375
Batch 14/64 loss: -1.0350093841552734
Batch 15/64 loss: -0.7938871383666992
Batch 16/64 loss: -0.8106412887573242
Batch 17/64 loss: -0.7224359512329102
Batch 18/64 loss: -0.7571258544921875
Batch 19/64 loss: -0.6710910797119141
Batch 20/64 loss: -0.9671096801757812
Batch 21/64 loss: -1.1713733673095703
Batch 22/64 loss: -0.8222017288208008
Batch 23/64 loss: -0.7325325012207031
Batch 24/64 loss: -0.9463634490966797
Batch 25/64 loss: -0.772674560546875
Batch 26/64 loss: -0.28099536895751953
Batch 27/64 loss: -0.9154272079467773
Batch 28/64 loss: -0.5125064849853516
Batch 29/64 loss: -0.9792594909667969
Batch 30/64 loss: -0.5989198684692383
Batch 31/64 loss: -0.6080665588378906
Batch 32/64 loss: -0.6506824493408203
Batch 33/64 loss: -0.673675537109375
Batch 34/64 loss: -0.995208740234375
Batch 35/64 loss: -1.1785268783569336
Batch 36/64 loss: -1.085378646850586
Batch 37/64 loss: -0.791987419128418
Batch 38/64 loss: -1.0165777206420898
Batch 39/64 loss: -1.0551691055297852
Batch 40/64 loss: -1.043874740600586
Batch 41/64 loss: -0.9020824432373047
Batch 42/64 loss: -0.9751815795898438
Batch 43/64 loss: -0.689579963684082
Batch 44/64 loss: -0.6220607757568359
Batch 45/64 loss: -0.45230770111083984
Batch 46/64 loss: -1.0340232849121094
Batch 47/64 loss: -0.9846267700195312
Batch 48/64 loss: -0.9476213455200195
Batch 49/64 loss: -1.0003271102905273
Batch 50/64 loss: -0.9116306304931641
Batch 51/64 loss: -0.9837026596069336
Batch 52/64 loss: -0.9088335037231445
Batch 53/64 loss: -0.5753164291381836
Batch 54/64 loss: -0.8027276992797852
Batch 55/64 loss: -0.9540815353393555
Batch 56/64 loss: -1.205225944519043
Batch 57/64 loss: -1.046121597290039
Batch 58/64 loss: -1.0471773147583008
Batch 59/64 loss: -0.2092437744140625
Batch 60/64 loss: -1.1765260696411133
Batch 61/64 loss: -0.20655059814453125
Batch 62/64 loss: -0.7494773864746094
Batch 63/64 loss: -1.3932256698608398
Batch 64/64 loss: -5.078189373016357
Epoch 87  Train loss: -0.9210434352650362  Val loss: -1.1354209401763182
Epoch 88
-------------------------------
Batch 1/64 loss: -1.0312881469726562
Batch 2/64 loss: -0.66107177734375
Batch 3/64 loss: -1.011322021484375
Batch 4/64 loss: -1.0941839218139648
Batch 5/64 loss: -1.3371334075927734
Batch 6/64 loss: -0.9775247573852539
Batch 7/64 loss: -1.1994857788085938
Batch 8/64 loss: -0.8382043838500977
Batch 9/64 loss: -0.7023687362670898
Batch 10/64 loss: -0.8472499847412109
Batch 11/64 loss: -0.9348697662353516
Batch 12/64 loss: -0.8620948791503906
Batch 13/64 loss: -0.9616680145263672
Batch 14/64 loss: -1.1006555557250977
Batch 15/64 loss: -0.3489227294921875
Batch 16/64 loss: -1.0228271484375
Batch 17/64 loss: -1.2646465301513672
Batch 18/64 loss: -0.6609220504760742
Batch 19/64 loss: -0.9774942398071289
Batch 20/64 loss: -0.9456663131713867
Batch 21/64 loss: -0.6577997207641602
Batch 22/64 loss: -0.8045368194580078
Batch 23/64 loss: -0.8912506103515625
Batch 24/64 loss: -1.1294031143188477
Batch 25/64 loss: -0.8953886032104492
Batch 26/64 loss: -0.7604455947875977
Batch 27/64 loss: -0.4695882797241211
Batch 28/64 loss: -0.8994731903076172
Batch 29/64 loss: -0.5895919799804688
Batch 30/64 loss: -0.9258279800415039
Batch 31/64 loss: -1.1439809799194336
Batch 32/64 loss: -0.6943912506103516
Batch 33/64 loss: -0.8577480316162109
Batch 34/64 loss: -1.0324392318725586
Batch 35/64 loss: -0.9926748275756836
Batch 36/64 loss: -0.6984968185424805
Batch 37/64 loss: -1.0382051467895508
Batch 38/64 loss: -1.18017578125
Batch 39/64 loss: -0.2289419174194336
Batch 40/64 loss: -0.8326406478881836
Batch 41/64 loss: -0.5792388916015625
Batch 42/64 loss: -0.9231014251708984
Batch 43/64 loss: -1.0121145248413086
Batch 44/64 loss: -0.8718557357788086
Batch 45/64 loss: -1.1543960571289062
Batch 46/64 loss: -0.7645549774169922
Batch 47/64 loss: -1.0480690002441406
Batch 48/64 loss: -0.7845354080200195
Batch 49/64 loss: -0.29769229888916016
Batch 50/64 loss: -0.8783388137817383
Batch 51/64 loss: -1.1666345596313477
Batch 52/64 loss: -1.078944206237793
Batch 53/64 loss: -0.8665246963500977
Batch 54/64 loss: -0.7893142700195312
Batch 55/64 loss: -1.1134653091430664
Batch 56/64 loss: -0.4998931884765625
Batch 57/64 loss: -0.8904819488525391
Batch 58/64 loss: -1.0845069885253906
Batch 59/64 loss: -1.3166723251342773
Batch 60/64 loss: -0.40824317932128906
Batch 61/64 loss: -1.1363639831542969
Batch 62/64 loss: -0.8315887451171875
Batch 63/64 loss: -1.0408220291137695
Batch 64/64 loss: -5.090553283691406
Epoch 88  Train loss: -0.9389469520718443  Val loss: -1.2684032400858771
Saving best model, epoch: 88
Epoch 89
-------------------------------
Batch 1/64 loss: -1.1417598724365234
Batch 2/64 loss: -1.1609201431274414
Batch 3/64 loss: -0.978515625
Batch 4/64 loss: -0.9751815795898438
Batch 5/64 loss: -0.8422174453735352
Batch 6/64 loss: -1.0076055526733398
Batch 7/64 loss: -0.3903789520263672
Batch 8/64 loss: -0.908233642578125
Batch 9/64 loss: -1.2073802947998047
Batch 10/64 loss: -0.9786653518676758
Batch 11/64 loss: -1.0027599334716797
Batch 12/64 loss: -1.029372215270996
Batch 13/64 loss: -0.8751249313354492
Batch 14/64 loss: -1.1253166198730469
Batch 15/64 loss: -0.8876247406005859
Batch 16/64 loss: -1.0155019760131836
Batch 17/64 loss: -1.0591602325439453
Batch 18/64 loss: -1.4004344940185547
Batch 19/64 loss: -1.0853843688964844
Batch 20/64 loss: -1.0929937362670898
Batch 21/64 loss: -0.6653051376342773
Batch 22/64 loss: -0.5685176849365234
Batch 23/64 loss: -0.7887020111083984
Batch 24/64 loss: -0.7858161926269531
Batch 25/64 loss: -1.024825096130371
Batch 26/64 loss: -1.1920671463012695
Batch 27/64 loss: -0.9575338363647461
Batch 28/64 loss: -0.9578876495361328
Batch 29/64 loss: -0.3084735870361328
Batch 30/64 loss: -1.1348543167114258
Batch 31/64 loss: -0.5989780426025391
Batch 32/64 loss: -0.6225824356079102
Batch 33/64 loss: -0.2221221923828125
Batch 34/64 loss: -1.0597553253173828
Batch 35/64 loss: -0.450042724609375
Batch 36/64 loss: -0.9645071029663086
Batch 37/64 loss: -0.9430522918701172
Batch 38/64 loss: -0.9519529342651367
Batch 39/64 loss: -0.533900260925293
Batch 40/64 loss: -0.8055591583251953
Batch 41/64 loss: -1.0860414505004883
Batch 42/64 loss: -1.031402587890625
Batch 43/64 loss: -0.9691524505615234
Batch 44/64 loss: -0.861668586730957
Batch 45/64 loss: -0.7359180450439453
Batch 46/64 loss: -0.8762569427490234
Batch 47/64 loss: -1.209803581237793
Batch 48/64 loss: -0.9281721115112305
Batch 49/64 loss: -0.9420385360717773
Batch 50/64 loss: -0.6938095092773438
Batch 51/64 loss: -1.0444221496582031
Batch 52/64 loss: -1.1899452209472656
Batch 53/64 loss: -1.1281871795654297
Batch 54/64 loss: -1.307570457458496
Batch 55/64 loss: -0.8990554809570312
Batch 56/64 loss: -1.0251178741455078
Batch 57/64 loss: -0.7522411346435547
Batch 58/64 loss: -1.06982421875
Batch 59/64 loss: -0.790959358215332
Batch 60/64 loss: -0.7240457534790039
Batch 61/64 loss: -0.42322254180908203
Batch 62/64 loss: -1.0592060089111328
Batch 63/64 loss: -1.3013067245483398
Batch 64/64 loss: -5.0183634757995605
Epoch 89  Train loss: -0.9649271740632899  Val loss: -1.1630561540216924
Epoch 90
-------------------------------
Batch 1/64 loss: -1.042679786682129
Batch 2/64 loss: -1.150416374206543
Batch 3/64 loss: -1.3089380264282227
Batch 4/64 loss: -1.1545648574829102
Batch 5/64 loss: -0.7483673095703125
Batch 6/64 loss: -0.6689510345458984
Batch 7/64 loss: -1.103867530822754
Batch 8/64 loss: -1.046875
Batch 9/64 loss: -0.8138933181762695
Batch 10/64 loss: -1.3180341720581055
Batch 11/64 loss: -1.0421476364135742
Batch 12/64 loss: -1.1356401443481445
Batch 13/64 loss: -0.975987434387207
Batch 14/64 loss: -1.169942855834961
Batch 15/64 loss: -1.079329490661621
Batch 16/64 loss: -1.191925048828125
Batch 17/64 loss: -0.19061565399169922
Batch 18/64 loss: -0.9791650772094727
Batch 19/64 loss: -1.0880985260009766
Batch 20/64 loss: -0.8881683349609375
Batch 21/64 loss: -1.0812740325927734
Batch 22/64 loss: -1.2168598175048828
Batch 23/64 loss: -0.5971012115478516
Batch 24/64 loss: -1.2595558166503906
Batch 25/64 loss: -1.1139183044433594
Batch 26/64 loss: -1.0565557479858398
Batch 27/64 loss: -0.8262729644775391
Batch 28/64 loss: -1.0407991409301758
Batch 29/64 loss: -1.1026411056518555
Batch 30/64 loss: -0.9602375030517578
Batch 31/64 loss: -0.7076320648193359
Batch 32/64 loss: -1.154062271118164
Batch 33/64 loss: -0.5642662048339844
Batch 34/64 loss: -0.9504919052124023
Batch 35/64 loss: -0.8747730255126953
Batch 36/64 loss: -0.3331756591796875
Batch 37/64 loss: -0.12535667419433594
Batch 38/64 loss: -0.8169326782226562
Batch 39/64 loss: -1.070627212524414
Batch 40/64 loss: -0.4455451965332031
Batch 41/64 loss: -0.9273595809936523
Batch 42/64 loss: -0.4468851089477539
Batch 43/64 loss: -0.7028932571411133
Batch 44/64 loss: -0.7630319595336914
Batch 45/64 loss: -1.0880308151245117
Batch 46/64 loss: -0.86376953125
Batch 47/64 loss: -1.2727746963500977
Batch 48/64 loss: -1.080307960510254
Batch 49/64 loss: -0.5873594284057617
Batch 50/64 loss: -0.9895563125610352
Batch 51/64 loss: -1.0758190155029297
Batch 52/64 loss: -0.1536417007446289
Batch 53/64 loss: -1.0886526107788086
Batch 54/64 loss: -0.8809671401977539
Batch 55/64 loss: -0.7938652038574219
Batch 56/64 loss: -0.8513631820678711
Batch 57/64 loss: -1.3292961120605469
Batch 58/64 loss: -1.349928855895996
Batch 59/64 loss: -0.9656257629394531
Batch 60/64 loss: -0.4239492416381836
Batch 61/64 loss: -0.8762035369873047
Batch 62/64 loss: -0.9598779678344727
Batch 63/64 loss: -1.185969352722168
Batch 64/64 loss: -4.604230880737305
Epoch 90  Train loss: -0.9647998061834597  Val loss: -1.2006415665354515
Epoch 91
-------------------------------
Batch 1/64 loss: -0.9537897109985352
Batch 2/64 loss: -0.3612833023071289
Batch 3/64 loss: -0.6716537475585938
Batch 4/64 loss: -0.677739143371582
Batch 5/64 loss: -0.5720081329345703
Batch 6/64 loss: -0.4583244323730469
Batch 7/64 loss: -0.987086296081543
Batch 8/64 loss: -1.2721128463745117
Batch 9/64 loss: -1.0587749481201172
Batch 10/64 loss: -1.2657861709594727
Batch 11/64 loss: -0.9666175842285156
Batch 12/64 loss: -1.046177864074707
Batch 13/64 loss: -0.8506383895874023
Batch 14/64 loss: -1.1298160552978516
Batch 15/64 loss: -0.9957551956176758
Batch 16/64 loss: -0.8990411758422852
Batch 17/64 loss: -1.2613115310668945
Batch 18/64 loss: -0.7813911437988281
Batch 19/64 loss: -0.8069906234741211
Batch 20/64 loss: -1.2546043395996094
Batch 21/64 loss: -0.65093994140625
Batch 22/64 loss: -1.2614622116088867
Batch 23/64 loss: -1.1590356826782227
Batch 24/64 loss: -1.133622169494629
Batch 25/64 loss: -0.8633403778076172
Batch 26/64 loss: -0.9541034698486328
Batch 27/64 loss: -0.5611639022827148
Batch 28/64 loss: -0.9155473709106445
Batch 29/64 loss: -0.8089094161987305
Batch 30/64 loss: -0.3811159133911133
Batch 31/64 loss: -0.4550008773803711
Batch 32/64 loss: -0.4724302291870117
Batch 33/64 loss: -0.9981021881103516
Batch 34/64 loss: -1.078852653503418
Batch 35/64 loss: -0.9974775314331055
Batch 36/64 loss: -1.001063346862793
Batch 37/64 loss: -1.0434074401855469
Batch 38/64 loss: -0.9535188674926758
Batch 39/64 loss: -0.4738626480102539
Batch 40/64 loss: -1.0358476638793945
Batch 41/64 loss: -0.9489278793334961
Batch 42/64 loss: -1.1716995239257812
Batch 43/64 loss: -0.8729772567749023
Batch 44/64 loss: -0.6224994659423828
Batch 45/64 loss: -0.831507682800293
Batch 46/64 loss: -0.8655729293823242
Batch 47/64 loss: -0.6744756698608398
Batch 48/64 loss: -0.6049890518188477
Batch 49/64 loss: -0.8001585006713867
Batch 50/64 loss: -0.7194900512695312
Batch 51/64 loss: -0.8874588012695312
Batch 52/64 loss: -0.574061393737793
Batch 53/64 loss: -0.7454319000244141
Batch 54/64 loss: -1.1989555358886719
Batch 55/64 loss: -0.9061698913574219
Batch 56/64 loss: -0.7158432006835938
Batch 57/64 loss: -1.1058940887451172
Batch 58/64 loss: -0.9575462341308594
Batch 59/64 loss: -0.6986780166625977
Batch 60/64 loss: -0.9811887741088867
Batch 61/64 loss: -0.9016656875610352
Batch 62/64 loss: -0.7459707260131836
Batch 63/64 loss: -0.7426834106445312
Batch 64/64 loss: -5.017932891845703
Epoch 91  Train loss: -0.9177568921855852  Val loss: -0.8969648564394397
Epoch 92
-------------------------------
Batch 1/64 loss: -0.9311408996582031
Batch 2/64 loss: -0.4732027053833008
Batch 3/64 loss: -0.2667703628540039
Batch 4/64 loss: -1.0021352767944336
Batch 5/64 loss: -1.1142635345458984
Batch 6/64 loss: -1.0601701736450195
Batch 7/64 loss: -0.7958688735961914
Batch 8/64 loss: -0.6791601181030273
Batch 9/64 loss: -0.5614166259765625
Batch 10/64 loss: -0.7556400299072266
Batch 11/64 loss: -0.7680139541625977
Batch 12/64 loss: -1.1467294692993164
Batch 13/64 loss: -1.0708122253417969
Batch 14/64 loss: -1.0011110305786133
Batch 15/64 loss: -1.0891284942626953
Batch 16/64 loss: -0.7070903778076172
Batch 17/64 loss: -0.7127895355224609
Batch 18/64 loss: -1.1558160781860352
Batch 19/64 loss: -0.9976778030395508
Batch 20/64 loss: -0.7119016647338867
Batch 21/64 loss: -0.636509895324707
Batch 22/64 loss: -0.8623619079589844
Batch 23/64 loss: -1.030991554260254
Batch 24/64 loss: -1.0829277038574219
Batch 25/64 loss: -0.9067153930664062
Batch 26/64 loss: -0.6894340515136719
Batch 27/64 loss: -0.5642299652099609
Batch 28/64 loss: -1.0552453994750977
Batch 29/64 loss: -1.288238525390625
Batch 30/64 loss: -1.1561813354492188
Batch 31/64 loss: -0.6404533386230469
Batch 32/64 loss: -1.2509336471557617
Batch 33/64 loss: -0.9447555541992188
Batch 34/64 loss: -0.8140382766723633
Batch 35/64 loss: -0.5937328338623047
Batch 36/64 loss: -1.106821060180664
Batch 37/64 loss: -0.8556480407714844
Batch 38/64 loss: -0.9854621887207031
Batch 39/64 loss: -0.8103132247924805
Batch 40/64 loss: -0.36762142181396484
Batch 41/64 loss: -1.066575050354004
Batch 42/64 loss: -1.1363983154296875
Batch 43/64 loss: -0.8116998672485352
Batch 44/64 loss: -0.8978042602539062
Batch 45/64 loss: -0.4976692199707031
Batch 46/64 loss: -0.621037483215332
Batch 47/64 loss: -0.8712778091430664
Batch 48/64 loss: -1.067154884338379
Batch 49/64 loss: -1.0929813385009766
Batch 50/64 loss: -0.9435300827026367
Batch 51/64 loss: -1.1517343521118164
Batch 52/64 loss: -0.06576728820800781
Batch 53/64 loss: -0.7983512878417969
Batch 54/64 loss: -1.2853755950927734
Batch 55/64 loss: -1.1294746398925781
Batch 56/64 loss: -0.8812437057495117
Batch 57/64 loss: -0.8966159820556641
Batch 58/64 loss: -1.0938377380371094
Batch 59/64 loss: -1.0332622528076172
Batch 60/64 loss: -0.8523521423339844
Batch 61/64 loss: -0.9731826782226562
Batch 62/64 loss: -0.4754199981689453
Batch 63/64 loss: -1.1485700607299805
Batch 64/64 loss: -4.8766889572143555
Epoch 92  Train loss: -0.9269378400316426  Val loss: -1.238593661908022
Epoch 93
-------------------------------
Batch 1/64 loss: -1.191300392150879
Batch 2/64 loss: -1.1545562744140625
Batch 3/64 loss: -0.7121725082397461
Batch 4/64 loss: -1.1420116424560547
Batch 5/64 loss: -0.8979997634887695
Batch 6/64 loss: -0.9538240432739258
Batch 7/64 loss: -1.0715532302856445
Batch 8/64 loss: -0.8181180953979492
Batch 9/64 loss: -0.7382030487060547
Batch 10/64 loss: -1.0055265426635742
Batch 11/64 loss: -0.3653278350830078
Batch 12/64 loss: -0.5943136215209961
Batch 13/64 loss: -0.7455148696899414
Batch 14/64 loss: -1.1367206573486328
Batch 15/64 loss: -0.9749746322631836
Batch 16/64 loss: -0.6849813461303711
Batch 17/64 loss: -0.47964954376220703
Batch 18/64 loss: -0.24269485473632812
Batch 19/64 loss: -1.2914543151855469
Batch 20/64 loss: -1.1282958984375
Batch 21/64 loss: -0.7555341720581055
Batch 22/64 loss: -0.8602685928344727
Batch 23/64 loss: -0.5852155685424805
Batch 24/64 loss: -1.001922607421875
Batch 25/64 loss: -0.9448089599609375
Batch 26/64 loss: -1.0591917037963867
Batch 27/64 loss: -1.1374521255493164
Batch 28/64 loss: -1.2854642868041992
Batch 29/64 loss: -1.259659767150879
Batch 30/64 loss: -0.6125831604003906
Batch 31/64 loss: -1.0116662979125977
Batch 32/64 loss: -1.1896896362304688
Batch 33/64 loss: -1.2625761032104492
Batch 34/64 loss: -0.9825992584228516
Batch 35/64 loss: -1.2399139404296875
Batch 36/64 loss: -0.6327552795410156
Batch 37/64 loss: -1.0416154861450195
Batch 38/64 loss: -1.1416254043579102
Batch 39/64 loss: -0.9656867980957031
Batch 40/64 loss: -1.1650629043579102
Batch 41/64 loss: -1.1775474548339844
Batch 42/64 loss: -0.9461889266967773
Batch 43/64 loss: -1.1119184494018555
Batch 44/64 loss: -0.9231948852539062
Batch 45/64 loss: -0.3415565490722656
Batch 46/64 loss: -1.2880401611328125
Batch 47/64 loss: -1.0496931076049805
Batch 48/64 loss: -0.7981710433959961
Batch 49/64 loss: -0.7923927307128906
Batch 50/64 loss: -1.3066396713256836
Batch 51/64 loss: -0.787043571472168
Batch 52/64 loss: -0.9650745391845703
Batch 53/64 loss: -0.7746820449829102
Batch 54/64 loss: -1.0309009552001953
Batch 55/64 loss: -1.1999483108520508
Batch 56/64 loss: -0.5465869903564453
Batch 57/64 loss: -0.5935916900634766
Batch 58/64 loss: -0.9682626724243164
Batch 59/64 loss: -0.41605091094970703
Batch 60/64 loss: -1.3573541641235352
Batch 61/64 loss: -1.0174121856689453
Batch 62/64 loss: -0.9426717758178711
Batch 63/64 loss: -1.0720348358154297
Batch 64/64 loss: -5.200945854187012
Epoch 93  Train loss: -0.984661210752001  Val loss: -1.166554165869644
Epoch 94
-------------------------------
Batch 1/64 loss: -0.7909355163574219
Batch 2/64 loss: -1.1352777481079102
Batch 3/64 loss: -0.9802217483520508
Batch 4/64 loss: -0.980982780456543
Batch 5/64 loss: -1.198796272277832
Batch 6/64 loss: -1.1896209716796875
Batch 7/64 loss: -1.1501216888427734
Batch 8/64 loss: -0.7702856063842773
Batch 9/64 loss: -0.6756486892700195
Batch 10/64 loss: -0.9973297119140625
Batch 11/64 loss: -1.3098011016845703
Batch 12/64 loss: -0.5684490203857422
Batch 13/64 loss: -1.1624641418457031
Batch 14/64 loss: -0.05785369873046875
Batch 15/64 loss: -0.922698974609375
Batch 16/64 loss: -0.8838129043579102
Batch 17/64 loss: -1.1152076721191406
Batch 18/64 loss: -0.8636102676391602
Batch 19/64 loss: -1.0037126541137695
Batch 20/64 loss: -0.9290189743041992
Batch 21/64 loss: -0.667388916015625
Batch 22/64 loss: -1.1019744873046875
Batch 23/64 loss: -0.9635868072509766
Batch 24/64 loss: -0.9747629165649414
Batch 25/64 loss: -0.5275230407714844
Batch 26/64 loss: -1.2160110473632812
Batch 27/64 loss: -0.9522771835327148
Batch 28/64 loss: -0.8860177993774414
Batch 29/64 loss: -0.7838630676269531
Batch 30/64 loss: -1.3466005325317383
Batch 31/64 loss: -0.9082574844360352
Batch 32/64 loss: -0.9722719192504883
Batch 33/64 loss: -1.1971940994262695
Batch 34/64 loss: -0.8282737731933594
Batch 35/64 loss: -1.0533294677734375
Batch 36/64 loss: -0.9481420516967773
Batch 37/64 loss: -0.8675603866577148
Batch 38/64 loss: -1.0844440460205078
Batch 39/64 loss: -1.0799627304077148
Batch 40/64 loss: -0.6838970184326172
Batch 41/64 loss: -1.0333747863769531
Batch 42/64 loss: -0.6164922714233398
Batch 43/64 loss: -1.1028947830200195
Batch 44/64 loss: -1.090423583984375
Batch 45/64 loss: -1.0945158004760742
Batch 46/64 loss: -0.93402099609375
Batch 47/64 loss: -1.1320600509643555
Batch 48/64 loss: -0.9159183502197266
Batch 49/64 loss: -1.180145263671875
Batch 50/64 loss: -1.0200042724609375
Batch 51/64 loss: -0.848515510559082
Batch 52/64 loss: -0.32747364044189453
Batch 53/64 loss: -0.8295583724975586
Batch 54/64 loss: -0.7649250030517578
Batch 55/64 loss: -1.1015205383300781
Batch 56/64 loss: -0.7734346389770508
Batch 57/64 loss: -0.8167142868041992
Batch 58/64 loss: -1.206040382385254
Batch 59/64 loss: -1.2895288467407227
Batch 60/64 loss: -0.7840452194213867
Batch 61/64 loss: -0.8145246505737305
Batch 62/64 loss: -0.7619752883911133
Batch 63/64 loss: -0.9719409942626953
Batch 64/64 loss: -5.1751813888549805
Epoch 94  Train loss: -0.9885587841856713  Val loss: -1.1382649084137069
Epoch 95
-------------------------------
Batch 1/64 loss: -0.8571033477783203
Batch 2/64 loss: -0.38607025146484375
Batch 3/64 loss: -1.215153694152832
Batch 4/64 loss: -1.2422246932983398
Batch 5/64 loss: -0.9282407760620117
Batch 6/64 loss: -0.8405075073242188
Batch 7/64 loss: -0.5643367767333984
Batch 8/64 loss: -0.9622316360473633
Batch 9/64 loss: -1.0105772018432617
Batch 10/64 loss: -0.7879085540771484
Batch 11/64 loss: -0.7958831787109375
Batch 12/64 loss: -1.2348089218139648
Batch 13/64 loss: -1.1522960662841797
Batch 14/64 loss: -0.5749597549438477
Batch 15/64 loss: -0.6128549575805664
Batch 16/64 loss: -1.0518817901611328
Batch 17/64 loss: -0.508610725402832
Batch 18/64 loss: -1.0775890350341797
Batch 19/64 loss: -1.1467361450195312
Batch 20/64 loss: -0.9666500091552734
Batch 21/64 loss: -1.0209455490112305
Batch 22/64 loss: -1.1711950302124023
Batch 23/64 loss: -1.2559404373168945
Batch 24/64 loss: -1.156916618347168
Batch 25/64 loss: -0.6096982955932617
Batch 26/64 loss: -1.0250024795532227
Batch 27/64 loss: -0.548701286315918
Batch 28/64 loss: -0.5332393646240234
Batch 29/64 loss: -0.7635030746459961
Batch 30/64 loss: -0.9356594085693359
Batch 31/64 loss: -1.1156892776489258
Batch 32/64 loss: -0.9925537109375
Batch 33/64 loss: -0.9783353805541992
Batch 34/64 loss: -0.3040590286254883
Batch 35/64 loss: -0.6693096160888672
Batch 36/64 loss: -0.8413543701171875
Batch 37/64 loss: -0.8631362915039062
Batch 38/64 loss: -0.7832632064819336
Batch 39/64 loss: -1.0787763595581055
Batch 40/64 loss: -0.8806467056274414
Batch 41/64 loss: -1.302474021911621
Batch 42/64 loss: -0.8713054656982422
Batch 43/64 loss: -0.8898591995239258
Batch 44/64 loss: -0.9792766571044922
Batch 45/64 loss: -0.747776985168457
Batch 46/64 loss: -1.2127876281738281
Batch 47/64 loss: -0.8729763031005859
Batch 48/64 loss: -1.2455425262451172
Batch 49/64 loss: -0.5008716583251953
Batch 50/64 loss: -0.8223676681518555
Batch 51/64 loss: -0.8928136825561523
Batch 52/64 loss: -1.0515003204345703
Batch 53/64 loss: -0.9945783615112305
Batch 54/64 loss: -0.8765354156494141
Batch 55/64 loss: -1.0855722427368164
Batch 56/64 loss: -1.2503862380981445
Batch 57/64 loss: -1.2425661087036133
Batch 58/64 loss: -0.6986923217773438
Batch 59/64 loss: -0.7576417922973633
Batch 60/64 loss: -1.113236427307129
Batch 61/64 loss: -0.8598747253417969
Batch 62/64 loss: -0.4094352722167969
Batch 63/64 loss: -0.9329967498779297
Batch 64/64 loss: -5.2529473304748535
Epoch 95  Train loss: -0.9567894711213953  Val loss: -1.2740098356790968
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: -0.58648681640625
Batch 2/64 loss: -0.17567825317382812
Batch 3/64 loss: -0.9346799850463867
Batch 4/64 loss: -0.48092079162597656
Batch 5/64 loss: -0.5712423324584961
Batch 6/64 loss: -1.0422868728637695
Batch 7/64 loss: -1.0308074951171875
Batch 8/64 loss: -1.009176254272461
Batch 9/64 loss: -1.1273794174194336
Batch 10/64 loss: -1.0037250518798828
Batch 11/64 loss: -0.5397825241088867
Batch 12/64 loss: -1.2660694122314453
Batch 13/64 loss: -1.0336227416992188
Batch 14/64 loss: -1.351883888244629
Batch 15/64 loss: -1.0682897567749023
Batch 16/64 loss: -1.1157207489013672
Batch 17/64 loss: -0.9577541351318359
Batch 18/64 loss: -1.1160697937011719
Batch 19/64 loss: -1.052912712097168
Batch 20/64 loss: -0.9214229583740234
Batch 21/64 loss: -1.1169452667236328
Batch 22/64 loss: -1.3280057907104492
Batch 23/64 loss: -1.0508146286010742
Batch 24/64 loss: -0.6074762344360352
Batch 25/64 loss: -0.6075992584228516
Batch 26/64 loss: -1.0482702255249023
Batch 27/64 loss: -1.278346061706543
Batch 28/64 loss: -1.1377506256103516
Batch 29/64 loss: -1.1422195434570312
Batch 30/64 loss: -0.8153743743896484
Batch 31/64 loss: -1.3252410888671875
Batch 32/64 loss: -0.8572597503662109
Batch 33/64 loss: -1.284327507019043
Batch 34/64 loss: -1.2753400802612305
Batch 35/64 loss: -0.6825542449951172
Batch 36/64 loss: -0.9326391220092773
Batch 37/64 loss: -1.1181650161743164
Batch 38/64 loss: -1.007065773010254
Batch 39/64 loss: -0.7469816207885742
Batch 40/64 loss: -0.9075946807861328
Batch 41/64 loss: -1.0715875625610352
Batch 42/64 loss: -0.8818159103393555
Batch 43/64 loss: -1.012253761291504
Batch 44/64 loss: -0.9752397537231445
Batch 45/64 loss: -0.9043464660644531
Batch 46/64 loss: -1.2119112014770508
Batch 47/64 loss: -1.1119461059570312
Batch 48/64 loss: -1.0250988006591797
Batch 49/64 loss: -0.7441310882568359
Batch 50/64 loss: -1.1279468536376953
Batch 51/64 loss: -0.34990501403808594
Batch 52/64 loss: -1.1051225662231445
Batch 53/64 loss: -1.1482572555541992
Batch 54/64 loss: -0.9950695037841797
Batch 55/64 loss: -0.36121273040771484
Batch 56/64 loss: -1.2749404907226562
Batch 57/64 loss: -0.8180303573608398
Batch 58/64 loss: -0.5394134521484375
Batch 59/64 loss: -1.0732078552246094
Batch 60/64 loss: -1.1968660354614258
Batch 61/64 loss: -1.0507402420043945
Batch 62/64 loss: -0.5294723510742188
Batch 63/64 loss: -0.7603139877319336
Batch 64/64 loss: -4.774815559387207
Epoch 96  Train loss: -0.9961697858922621  Val loss: -1.2310022701512497
Epoch 97
-------------------------------
Batch 1/64 loss: -0.91064453125
Batch 2/64 loss: -1.209451675415039
Batch 3/64 loss: -0.9972639083862305
Batch 4/64 loss: -1.0237274169921875
Batch 5/64 loss: -0.6166143417358398
Batch 6/64 loss: -1.023941993713379
Batch 7/64 loss: -0.6094951629638672
Batch 8/64 loss: -1.006174087524414
Batch 9/64 loss: -0.9464988708496094
Batch 10/64 loss: -0.762171745300293
Batch 11/64 loss: -0.4502220153808594
Batch 12/64 loss: -0.5711860656738281
Batch 13/64 loss: -0.9321622848510742
Batch 14/64 loss: -1.359726905822754
Batch 15/64 loss: -0.898716926574707
Batch 16/64 loss: -1.2329769134521484
Batch 17/64 loss: -1.2213544845581055
Batch 18/64 loss: -1.1479291915893555
Batch 19/64 loss: -0.6988544464111328
Batch 20/64 loss: -0.9095869064331055
Batch 21/64 loss: -0.26035022735595703
Batch 22/64 loss: -0.9751176834106445
Batch 23/64 loss: -1.0832023620605469
Batch 24/64 loss: -0.31200695037841797
Batch 25/64 loss: -0.40605831146240234
Batch 26/64 loss: -1.078110694885254
Batch 27/64 loss: -0.8924617767333984
Batch 28/64 loss: -0.6646556854248047
Batch 29/64 loss: -1.0634984970092773
Batch 30/64 loss: -1.0386219024658203
Batch 31/64 loss: -1.1322250366210938
Batch 32/64 loss: -1.2444524765014648
Batch 33/64 loss: -1.1914100646972656
Batch 34/64 loss: -1.2369575500488281
Batch 35/64 loss: -1.012833595275879
Batch 36/64 loss: -0.7928657531738281
Batch 37/64 loss: -1.078847885131836
Batch 38/64 loss: -0.8428010940551758
Batch 39/64 loss: -1.1047382354736328
Batch 40/64 loss: -0.9255523681640625
Batch 41/64 loss: -0.9151229858398438
Batch 42/64 loss: -1.2490711212158203
Batch 43/64 loss: -0.8427000045776367
Batch 44/64 loss: -0.6779594421386719
Batch 45/64 loss: -1.0252885818481445
Batch 46/64 loss: -1.0870695114135742
Batch 47/64 loss: -0.9868268966674805
Batch 48/64 loss: -0.9958410263061523
Batch 49/64 loss: -0.994969367980957
Batch 50/64 loss: -1.1410503387451172
Batch 51/64 loss: -1.0327987670898438
Batch 52/64 loss: -1.0273418426513672
Batch 53/64 loss: -1.362442970275879
Batch 54/64 loss: -0.8102684020996094
Batch 55/64 loss: -0.8993606567382812
Batch 56/64 loss: -0.8060283660888672
Batch 57/64 loss: -1.2724847793579102
Batch 58/64 loss: -1.0271415710449219
Batch 59/64 loss: -0.9054574966430664
Batch 60/64 loss: -0.6512603759765625
Batch 61/64 loss: -0.840764045715332
Batch 62/64 loss: -0.8681678771972656
Batch 63/64 loss: -0.30386829376220703
Batch 64/64 loss: -4.704326629638672
Epoch 97  Train loss: -0.9743842779421339  Val loss: -1.1482018015229005
Epoch 98
-------------------------------
Batch 1/64 loss: -0.5126962661743164
Batch 2/64 loss: -1.349802017211914
Batch 3/64 loss: -0.87249755859375
Batch 4/64 loss: -1.0190811157226562
Batch 5/64 loss: -1.128077507019043
Batch 6/64 loss: -1.0762300491333008
Batch 7/64 loss: -1.3027801513671875
Batch 8/64 loss: -0.6996002197265625
Batch 9/64 loss: -1.0534353256225586
Batch 10/64 loss: -0.9658231735229492
Batch 11/64 loss: -1.1450414657592773
Batch 12/64 loss: -1.0231132507324219
Batch 13/64 loss: -1.3489179611206055
Batch 14/64 loss: -0.941070556640625
Batch 15/64 loss: -1.1327943801879883
Batch 16/64 loss: -1.1404266357421875
Batch 17/64 loss: -1.0104990005493164
Batch 18/64 loss: -1.1220989227294922
Batch 19/64 loss: -0.8906469345092773
Batch 20/64 loss: -1.2194576263427734
Batch 21/64 loss: -1.1925716400146484
Batch 22/64 loss: -1.2165451049804688
Batch 23/64 loss: -1.0164947509765625
Batch 24/64 loss: -0.9341278076171875
Batch 25/64 loss: -0.5138254165649414
Batch 26/64 loss: -0.6359386444091797
Batch 27/64 loss: -1.285792350769043
Batch 28/64 loss: -1.1292057037353516
Batch 29/64 loss: -0.7599496841430664
Batch 30/64 loss: -0.9649286270141602
Batch 31/64 loss: -1.2514429092407227
Batch 32/64 loss: -0.7077732086181641
Batch 33/64 loss: -0.7868785858154297
Batch 34/64 loss: -0.9670639038085938
Batch 35/64 loss: -1.2365007400512695
Batch 36/64 loss: -0.7355070114135742
Batch 37/64 loss: -1.1713647842407227
Batch 38/64 loss: -0.8030471801757812
Batch 39/64 loss: -0.8375930786132812
Batch 40/64 loss: -1.180002212524414
Batch 41/64 loss: -1.047989845275879
Batch 42/64 loss: -0.6184406280517578
Batch 43/64 loss: -0.8222570419311523
Batch 44/64 loss: -0.7843189239501953
Batch 45/64 loss: -0.7357673645019531
Batch 46/64 loss: -1.138981819152832
Batch 47/64 loss: -0.5267419815063477
Batch 48/64 loss: -0.6850881576538086
Batch 49/64 loss: -1.0359039306640625
Batch 50/64 loss: -1.1378488540649414
Batch 51/64 loss: -1.2862119674682617
Batch 52/64 loss: -0.9514970779418945
Batch 53/64 loss: -0.8240728378295898
Batch 54/64 loss: -1.1380462646484375
Batch 55/64 loss: -0.6618337631225586
Batch 56/64 loss: -0.5567502975463867
Batch 57/64 loss: -1.1381416320800781
Batch 58/64 loss: -1.1712570190429688
Batch 59/64 loss: -1.0941944122314453
Batch 60/64 loss: -1.0894231796264648
Batch 61/64 loss: -0.9532098770141602
Batch 62/64 loss: -0.9311618804931641
Batch 63/64 loss: -0.5293006896972656
Batch 64/64 loss: -5.463642597198486
Epoch 98  Train loss: -1.0233225859847723  Val loss: -1.2607305336653982
Epoch 99
-------------------------------
Batch 1/64 loss: -1.1550474166870117
Batch 2/64 loss: -1.1778841018676758
Batch 3/64 loss: -0.7389869689941406
Batch 4/64 loss: -0.8296537399291992
Batch 5/64 loss: -0.8231468200683594
Batch 6/64 loss: -1.1300954818725586
Batch 7/64 loss: -1.1701383590698242
Batch 8/64 loss: -1.1733369827270508
Batch 9/64 loss: -0.7687587738037109
Batch 10/64 loss: -0.7188215255737305
Batch 11/64 loss: -1.0544977188110352
Batch 12/64 loss: -0.9884910583496094
Batch 13/64 loss: -1.417811393737793
Batch 14/64 loss: -1.1427812576293945
Batch 15/64 loss: -1.0257234573364258
Batch 16/64 loss: -1.1998481750488281
Batch 17/64 loss: -1.0488033294677734
Batch 18/64 loss: -0.8885831832885742
Batch 19/64 loss: -1.149062156677246
Batch 20/64 loss: -0.8317546844482422
Batch 21/64 loss: -1.2436599731445312
Batch 22/64 loss: -1.275979995727539
Batch 23/64 loss: -0.969752311706543
Batch 24/64 loss: -1.254338264465332
Batch 25/64 loss: -1.0972023010253906
Batch 26/64 loss: -0.7136125564575195
Batch 27/64 loss: -1.1726837158203125
Batch 28/64 loss: -0.565180778503418
Batch 29/64 loss: -0.5213050842285156
Batch 30/64 loss: 0.020414352416992188
Batch 31/64 loss: 0.0046367645263671875
Batch 32/64 loss: 1.1827974319458008
Batch 33/64 loss: 0.27330875396728516
Batch 34/64 loss: -0.5487070083618164
Batch 35/64 loss: -0.6886119842529297
Batch 36/64 loss: -0.4530754089355469
Batch 37/64 loss: -0.4285850524902344
Batch 38/64 loss: -0.3551769256591797
Batch 39/64 loss: -0.7020292282104492
Batch 40/64 loss: -0.5272607803344727
Batch 41/64 loss: -0.5124416351318359
Batch 42/64 loss: -0.2993602752685547
Batch 43/64 loss: -0.7140254974365234
Batch 44/64 loss: -0.3328065872192383
Batch 45/64 loss: -0.8710260391235352
Batch 46/64 loss: -0.8974170684814453
Batch 47/64 loss: -0.7900161743164062
Batch 48/64 loss: -0.5044078826904297
Batch 49/64 loss: -0.6738357543945312
Batch 50/64 loss: -1.097794532775879
Batch 51/64 loss: 0.20983219146728516
Batch 52/64 loss: -0.7567262649536133
Batch 53/64 loss: -0.4625864028930664
Batch 54/64 loss: -0.9008150100708008
Batch 55/64 loss: -1.1271495819091797
Batch 56/64 loss: -0.3400402069091797
Batch 57/64 loss: -0.7869777679443359
Batch 58/64 loss: -0.5298500061035156
Batch 59/64 loss: -0.6936445236206055
Batch 60/64 loss: -0.9736776351928711
Batch 61/64 loss: -0.7002048492431641
Batch 62/64 loss: -1.1159839630126953
Batch 63/64 loss: -0.6788206100463867
Batch 64/64 loss: -5.198425769805908
Epoch 99  Train loss: -0.7987109969643985  Val loss: -0.9902599111865067
Epoch 100
-------------------------------
Batch 1/64 loss: -0.5160188674926758
Batch 2/64 loss: -1.139120101928711
Batch 3/64 loss: -0.9252357482910156
Batch 4/64 loss: -0.9244661331176758
Batch 5/64 loss: -1.2345829010009766
Batch 6/64 loss: -0.9862442016601562
Batch 7/64 loss: -0.8468179702758789
Batch 8/64 loss: -0.9419403076171875
Batch 9/64 loss: -0.7752523422241211
Batch 10/64 loss: -0.9674587249755859
Batch 11/64 loss: -1.0831518173217773
Batch 12/64 loss: -0.9409799575805664
Batch 13/64 loss: -0.7239255905151367
Batch 14/64 loss: -1.0421724319458008
Batch 15/64 loss: -0.5850658416748047
Batch 16/64 loss: -0.8087358474731445
Batch 17/64 loss: -0.9458427429199219
Batch 18/64 loss: -0.8455753326416016
Batch 19/64 loss: -0.5502805709838867
Batch 20/64 loss: -0.7669906616210938
Batch 21/64 loss: -0.7749414443969727
Batch 22/64 loss: -0.9037437438964844
Batch 23/64 loss: -0.695338249206543
Batch 24/64 loss: -0.6538457870483398
Batch 25/64 loss: -1.015655517578125
Batch 26/64 loss: -0.7628517150878906
Batch 27/64 loss: -0.0681772232055664
Batch 28/64 loss: -0.8325634002685547
Batch 29/64 loss: -0.5396976470947266
Batch 30/64 loss: -0.654937744140625
Batch 31/64 loss: -1.2266311645507812
Batch 32/64 loss: -1.0041179656982422
Batch 33/64 loss: -0.6215925216674805
Batch 34/64 loss: -1.2614631652832031
Batch 35/64 loss: -0.9010801315307617
Batch 36/64 loss: -0.9179496765136719
Batch 37/64 loss: -0.6557674407958984
Batch 38/64 loss: -1.1246671676635742
Batch 39/64 loss: -0.5700416564941406
Batch 40/64 loss: -1.1942577362060547
Batch 41/64 loss: -0.8951597213745117
Batch 42/64 loss: -1.16259765625
Batch 43/64 loss: -1.1055107116699219
Batch 44/64 loss: -1.0314006805419922
Batch 45/64 loss: -0.3427906036376953
Batch 46/64 loss: -0.5468454360961914
Batch 47/64 loss: -0.9697599411010742
Batch 48/64 loss: -0.25111961364746094
Batch 49/64 loss: -0.4505157470703125
Batch 50/64 loss: -0.9656906127929688
Batch 51/64 loss: -1.2724580764770508
Batch 52/64 loss: -1.1309175491333008
Batch 53/64 loss: -0.8581533432006836
Batch 54/64 loss: -1.1478710174560547
Batch 55/64 loss: -0.7552728652954102
Batch 56/64 loss: -0.9471187591552734
Batch 57/64 loss: -1.285151481628418
Batch 58/64 loss: -0.7223262786865234
Batch 59/64 loss: -1.0612621307373047
Batch 60/64 loss: -1.2513971328735352
Batch 61/64 loss: -1.1391592025756836
Batch 62/64 loss: -1.0386896133422852
Batch 63/64 loss: -1.1898765563964844
Batch 64/64 loss: -4.906013488769531
Epoch 100  Train loss: -0.927525239832261  Val loss: -1.2590460629807305
Epoch 101
-------------------------------
Batch 1/64 loss: -1.0615053176879883
Batch 2/64 loss: -1.139582633972168
Batch 3/64 loss: -0.5854625701904297
Batch 4/64 loss: -0.9093990325927734
Batch 5/64 loss: -1.2731027603149414
Batch 6/64 loss: -1.2630805969238281
Batch 7/64 loss: -0.6930465698242188
Batch 8/64 loss: -0.7992687225341797
Batch 9/64 loss: -0.8663330078125
Batch 10/64 loss: -0.8921604156494141
Batch 11/64 loss: -0.8800554275512695
Batch 12/64 loss: -0.5680484771728516
Batch 13/64 loss: -1.0423288345336914
Batch 14/64 loss: -0.9329748153686523
Batch 15/64 loss: -0.9903345108032227
Batch 16/64 loss: -1.2243165969848633
Batch 17/64 loss: -1.0095272064208984
Batch 18/64 loss: -0.41951847076416016
Batch 19/64 loss: -0.7028408050537109
Batch 20/64 loss: -0.9243412017822266
Batch 21/64 loss: -0.3466062545776367
Batch 22/64 loss: -0.8453826904296875
Batch 23/64 loss: -0.1049051284790039
Batch 24/64 loss: -1.0329837799072266
Batch 25/64 loss: -0.9269733428955078
Batch 26/64 loss: -0.967411994934082
Batch 27/64 loss: -0.8444509506225586
Batch 28/64 loss: -0.6675519943237305
Batch 29/64 loss: -0.5788459777832031
Batch 30/64 loss: -1.0526800155639648
Batch 31/64 loss: -0.7679414749145508
Batch 32/64 loss: -0.913996696472168
Batch 33/64 loss: -0.7767629623413086
Batch 34/64 loss: -0.5280027389526367
Batch 35/64 loss: -0.8043146133422852
Batch 36/64 loss: -0.9592685699462891
Batch 37/64 loss: -0.8861894607543945
Batch 38/64 loss: -1.1242055892944336
Batch 39/64 loss: -0.5630760192871094
Batch 40/64 loss: -1.1620330810546875
Batch 41/64 loss: -0.48375415802001953
Batch 42/64 loss: -0.6425237655639648
Batch 43/64 loss: -0.7564105987548828
Batch 44/64 loss: -0.8179473876953125
Batch 45/64 loss: -0.6738319396972656
Batch 46/64 loss: -1.116683006286621
Batch 47/64 loss: -0.9340009689331055
Batch 48/64 loss: -1.197214126586914
Batch 49/64 loss: -0.8281927108764648
Batch 50/64 loss: -0.4020576477050781
Batch 51/64 loss: -1.0253877639770508
Batch 52/64 loss: -0.8683366775512695
Batch 53/64 loss: -1.282700538635254
Batch 54/64 loss: -0.9634103775024414
Batch 55/64 loss: -0.5208187103271484
Batch 56/64 loss: -0.24643516540527344
Batch 57/64 loss: -0.4281768798828125
Batch 58/64 loss: -0.935053825378418
Batch 59/64 loss: -0.6322708129882812
Batch 60/64 loss: -0.7930536270141602
Batch 61/64 loss: -0.7135982513427734
Batch 62/64 loss: -1.0111074447631836
Batch 63/64 loss: -0.8735103607177734
Batch 64/64 loss: -5.356164932250977
Epoch 101  Train loss: -0.8814809686997358  Val loss: -1.0871593698193527
Epoch 102
-------------------------------
Batch 1/64 loss: -1.1619329452514648
Batch 2/64 loss: -0.3700685501098633
Batch 3/64 loss: -0.736384391784668
Batch 4/64 loss: -0.18143177032470703
Batch 5/64 loss: -1.0911149978637695
Batch 6/64 loss: -0.7456150054931641
Batch 7/64 loss: -0.7564802169799805
Batch 8/64 loss: -0.6234521865844727
Batch 9/64 loss: -1.189244270324707
Batch 10/64 loss: -0.8404598236083984
Batch 11/64 loss: -0.7178668975830078
Batch 12/64 loss: -1.1020402908325195
Batch 13/64 loss: -0.4295682907104492
Batch 14/64 loss: -0.993718147277832
Batch 15/64 loss: -1.1156654357910156
Batch 16/64 loss: -0.8303966522216797
Batch 17/64 loss: -0.8774232864379883
Batch 18/64 loss: -0.3728151321411133
Batch 19/64 loss: -0.8588829040527344
Batch 20/64 loss: -0.5630121231079102
Batch 21/64 loss: -0.8124570846557617
Batch 22/64 loss: -1.208465576171875
Batch 23/64 loss: -1.1336755752563477
Batch 24/64 loss: -0.8583574295043945
Batch 25/64 loss: -0.4214515686035156
Batch 26/64 loss: -0.5606040954589844
Batch 27/64 loss: -0.9867963790893555
Batch 28/64 loss: -0.16452980041503906
Batch 29/64 loss: -1.0874366760253906
Batch 30/64 loss: -0.85992431640625
Batch 31/64 loss: -1.0170307159423828
Batch 32/64 loss: -0.9627885818481445
Batch 33/64 loss: -0.35898876190185547
Batch 34/64 loss: -0.11430644989013672
Batch 35/64 loss: -0.8232545852661133
Batch 36/64 loss: -1.041193962097168
Batch 37/64 loss: -0.9017887115478516
Batch 38/64 loss: -0.997096061706543
Batch 39/64 loss: -0.19159793853759766
Batch 40/64 loss: -1.0880117416381836
Batch 41/64 loss: -0.8146867752075195
Batch 42/64 loss: -0.6864356994628906
Batch 43/64 loss: -1.0172882080078125
Batch 44/64 loss: -0.5833826065063477
Batch 45/64 loss: -1.0718164443969727
Batch 46/64 loss: -0.2848653793334961
Batch 47/64 loss: -0.5202512741088867
Batch 48/64 loss: -0.6445550918579102
Batch 49/64 loss: -0.865818977355957
Batch 50/64 loss: -0.8225240707397461
Batch 51/64 loss: -0.621525764465332
Batch 52/64 loss: -1.211050033569336
Batch 53/64 loss: -0.9126358032226562
Batch 54/64 loss: -1.0344905853271484
Batch 55/64 loss: -0.5856027603149414
Batch 56/64 loss: -0.6897649765014648
Batch 57/64 loss: -1.1854162216186523
Batch 58/64 loss: -1.0528497695922852
Batch 59/64 loss: -0.530421257019043
Batch 60/64 loss: -0.6731538772583008
Batch 61/64 loss: -0.9044628143310547
Batch 62/64 loss: -0.8784284591674805
Batch 63/64 loss: -0.8587942123413086
Batch 64/64 loss: -5.035743713378906
Epoch 102  Train loss: -0.8372448341519225  Val loss: -0.977945976650592
Epoch 103
-------------------------------
Batch 1/64 loss: -0.9785346984863281
Batch 2/64 loss: -0.18027496337890625
Batch 3/64 loss: -0.8520879745483398
Batch 4/64 loss: -0.8810615539550781
Batch 5/64 loss: -1.1683406829833984
Batch 6/64 loss: -1.0356740951538086
Batch 7/64 loss: -1.025376319885254
Batch 8/64 loss: -0.9755315780639648
Batch 9/64 loss: -0.9964637756347656
Batch 10/64 loss: -0.26058101654052734
Batch 11/64 loss: -1.0199851989746094
Batch 12/64 loss: -0.9224081039428711
Batch 13/64 loss: -0.7518405914306641
Batch 14/64 loss: -1.1128787994384766
Batch 15/64 loss: -1.0371513366699219
Batch 16/64 loss: -0.24289226531982422
Batch 17/64 loss: -0.5356979370117188
Batch 18/64 loss: -0.641484260559082
Batch 19/64 loss: -0.9829950332641602
Batch 20/64 loss: -0.7628068923950195
Batch 21/64 loss: -0.5338029861450195
Batch 22/64 loss: -0.5850019454956055
Batch 23/64 loss: -0.9228496551513672
Batch 24/64 loss: -0.7471141815185547
Batch 25/64 loss: -0.31731224060058594
Batch 26/64 loss: -0.8964414596557617
Batch 27/64 loss: -0.9854021072387695
Batch 28/64 loss: -0.7237739562988281
Batch 29/64 loss: -0.8292074203491211
Batch 30/64 loss: -0.7327594757080078
Batch 31/64 loss: -0.3114786148071289
Batch 32/64 loss: -0.8458728790283203
Batch 33/64 loss: -0.9034280776977539
Batch 34/64 loss: -0.9137697219848633
Batch 35/64 loss: -0.7458887100219727
Batch 36/64 loss: -0.8229169845581055
Batch 37/64 loss: -0.6676750183105469
Batch 38/64 loss: -1.4333534240722656
Batch 39/64 loss: -1.2084436416625977
Batch 40/64 loss: 0.031604766845703125
Batch 41/64 loss: -0.7938718795776367
Batch 42/64 loss: -0.32312488555908203
Batch 43/64 loss: -1.1118297576904297
Batch 44/64 loss: -1.0596504211425781
Batch 45/64 loss: -0.8977394104003906
Batch 46/64 loss: -0.3946371078491211
Batch 47/64 loss: -1.0045356750488281
Batch 48/64 loss: -1.1751594543457031
Batch 49/64 loss: -1.0083341598510742
Batch 50/64 loss: -0.3534393310546875
Batch 51/64 loss: -0.795745849609375
Batch 52/64 loss: -0.36713123321533203
Batch 53/64 loss: -0.849024772644043
Batch 54/64 loss: -1.0309085845947266
Batch 55/64 loss: -0.8094320297241211
Batch 56/64 loss: -0.49195098876953125
Batch 57/64 loss: -1.0953388214111328
Batch 58/64 loss: -0.6809549331665039
Batch 59/64 loss: -0.8012304306030273
Batch 60/64 loss: -0.996973991394043
Batch 61/64 loss: -0.7602100372314453
Batch 62/64 loss: -0.8997201919555664
Batch 63/64 loss: -0.7723121643066406
Batch 64/64 loss: -4.756230354309082
Epoch 103  Train loss: -0.839206018634871  Val loss: -0.5068957404172707
Epoch 104
-------------------------------
Batch 1/64 loss: -0.8991899490356445
Batch 2/64 loss: -0.5260648727416992
Batch 3/64 loss: -0.9014034271240234
Batch 4/64 loss: -0.8664817810058594
Batch 5/64 loss: -0.6437845230102539
Batch 6/64 loss: 0.2677898406982422
Batch 7/64 loss: -0.46592044830322266
Batch 8/64 loss: -0.7731285095214844
Batch 9/64 loss: -0.6605520248413086
Batch 10/64 loss: -0.7107267379760742
Batch 11/64 loss: -0.3860893249511719
Batch 12/64 loss: -0.19222450256347656
Batch 13/64 loss: -0.5341949462890625
Batch 14/64 loss: -0.6009082794189453
Batch 15/64 loss: -0.5582294464111328
Batch 16/64 loss: -1.1220169067382812
Batch 17/64 loss: 0.7805595397949219
Batch 18/64 loss: -0.32338809967041016
Batch 19/64 loss: -1.2087993621826172
Batch 20/64 loss: -0.7017383575439453
Batch 21/64 loss: -0.9039278030395508
Batch 22/64 loss: -0.9399442672729492
Batch 23/64 loss: -0.6477184295654297
Batch 24/64 loss: -0.34797000885009766
Batch 25/64 loss: -0.9677515029907227
Batch 26/64 loss: -0.981532096862793
Batch 27/64 loss: -0.9697799682617188
Batch 28/64 loss: 0.5572843551635742
Batch 29/64 loss: -0.5982875823974609
Batch 30/64 loss: -0.14948558807373047
Batch 31/64 loss: 0.15307140350341797
Batch 32/64 loss: -0.14659786224365234
Batch 33/64 loss: -0.5234975814819336
Batch 34/64 loss: 0.059314727783203125
Batch 35/64 loss: -0.9581747055053711
Batch 36/64 loss: -0.4549274444580078
Batch 37/64 loss: -0.11626720428466797
Batch 38/64 loss: -0.7859125137329102
Batch 39/64 loss: -0.5192937850952148
Batch 40/64 loss: -0.8897495269775391
Batch 41/64 loss: -0.09568309783935547
Batch 42/64 loss: -0.1638965606689453
Batch 43/64 loss: -0.2636890411376953
Batch 44/64 loss: -0.4863557815551758
Batch 45/64 loss: 0.3822355270385742
Batch 46/64 loss: -0.7916498184204102
Batch 47/64 loss: 0.15003490447998047
Batch 48/64 loss: -0.6582050323486328
Batch 49/64 loss: 0.23341941833496094
Batch 50/64 loss: -0.2509422302246094
Batch 51/64 loss: -0.7756061553955078
Batch 52/64 loss: -0.5744609832763672
Batch 53/64 loss: 0.9187145233154297
Batch 54/64 loss: -0.27982616424560547
Batch 55/64 loss: -0.8217658996582031
Batch 56/64 loss: 0.10464191436767578
Batch 57/64 loss: 0.01880931854248047
Batch 58/64 loss: -0.5145683288574219
Batch 59/64 loss: 0.575291633605957
Batch 60/64 loss: -0.3890390396118164
Batch 61/64 loss: -0.8773155212402344
Batch 62/64 loss: -0.5112848281860352
Batch 63/64 loss: 0.29358577728271484
Batch 64/64 loss: -4.713224411010742
Epoch 104  Train loss: -0.4622762867048675  Val loss: -0.331906190852529
Epoch 105
-------------------------------
Batch 1/64 loss: 0.12763118743896484
Batch 2/64 loss: -0.3611326217651367
Batch 3/64 loss: -0.2441425323486328
Batch 4/64 loss: 1.6456890106201172
Batch 5/64 loss: -0.1726360321044922
Batch 6/64 loss: 0.7562465667724609
Batch 7/64 loss: -0.7524785995483398
Batch 8/64 loss: -0.6069831848144531
Batch 9/64 loss: -0.7319822311401367
Batch 10/64 loss: -0.4491462707519531
Batch 11/64 loss: -0.45148372650146484
Batch 12/64 loss: -0.5837335586547852
Batch 13/64 loss: -0.6938552856445312
Batch 14/64 loss: -0.5598478317260742
Batch 15/64 loss: -0.6934146881103516
Batch 16/64 loss: -0.8869838714599609
Batch 17/64 loss: -0.6004848480224609
Batch 18/64 loss: -0.8097715377807617
Batch 19/64 loss: -0.08335208892822266
Batch 20/64 loss: 0.08344268798828125
Batch 21/64 loss: -0.7821626663208008
Batch 22/64 loss: -0.49332237243652344
Batch 23/64 loss: -0.7819204330444336
Batch 24/64 loss: -0.1878795623779297
Batch 25/64 loss: -0.7818174362182617
Batch 26/64 loss: 0.2583169937133789
Batch 27/64 loss: -0.8190422058105469
Batch 28/64 loss: -0.7659645080566406
Batch 29/64 loss: -0.0033416748046875
Batch 30/64 loss: -1.1619901657104492
Batch 31/64 loss: -0.24904632568359375
Batch 32/64 loss: 0.2300710678100586
Batch 33/64 loss: 1.527787208557129
Batch 34/64 loss: -0.9075117111206055
Batch 35/64 loss: -0.38472652435302734
Batch 36/64 loss: -0.4959716796875
Batch 37/64 loss: 0.5117254257202148
Batch 38/64 loss: -0.5089406967163086
Batch 39/64 loss: -0.23496341705322266
Batch 40/64 loss: -0.1178731918334961
Batch 41/64 loss: 1.598738670349121
Batch 42/64 loss: -0.08606338500976562
Batch 43/64 loss: -0.00988006591796875
Batch 44/64 loss: 1.3765344619750977
Batch 45/64 loss: 0.29466819763183594
Batch 46/64 loss: 0.6123065948486328
Batch 47/64 loss: 0.3350801467895508
Batch 48/64 loss: 1.0161561965942383
Batch 49/64 loss: 0.8628206253051758
Batch 50/64 loss: 0.0025873184204101562
Batch 51/64 loss: -0.058414459228515625
Batch 52/64 loss: 1.0532970428466797
Batch 53/64 loss: 0.11668586730957031
Batch 54/64 loss: 0.641047477722168
Batch 55/64 loss: 0.4006385803222656
Batch 56/64 loss: -0.06145668029785156
Batch 57/64 loss: 0.09267234802246094
Batch 58/64 loss: 1.9712495803833008
Batch 59/64 loss: 2.0018558502197266
Batch 60/64 loss: 1.244532585144043
Batch 61/64 loss: 0.6292581558227539
Batch 62/64 loss: 1.2051639556884766
Batch 63/64 loss: 1.7985448837280273
Batch 64/64 loss: -4.312715530395508
Epoch 105  Train loss: 0.024886179905311733  Val loss: 1.4667800169220495
Epoch 106
-------------------------------
Batch 1/64 loss: 1.2674150466918945
Batch 2/64 loss: 0.3052330017089844
Batch 3/64 loss: -0.3228578567504883
Batch 4/64 loss: 0.32755279541015625
Batch 5/64 loss: 0.8635959625244141
Batch 6/64 loss: 0.20154953002929688
Batch 7/64 loss: 0.6348028182983398
Batch 8/64 loss: 0.10636520385742188
Batch 9/64 loss: 0.5912351608276367
Batch 10/64 loss: -0.22319698333740234
Batch 11/64 loss: 0.24208641052246094
Batch 12/64 loss: 0.5662164688110352
Batch 13/64 loss: -0.4637947082519531
Batch 14/64 loss: 0.83453369140625
Batch 15/64 loss: -0.0882863998413086
Batch 16/64 loss: 0.2667875289916992
Batch 17/64 loss: 1.207707405090332
Batch 18/64 loss: 0.6095771789550781
Batch 19/64 loss: -0.013719558715820312
Batch 20/64 loss: 0.028763771057128906
Batch 21/64 loss: 2.14646053314209
Batch 22/64 loss: -0.0028285980224609375
Batch 23/64 loss: 1.2785263061523438
Batch 24/64 loss: -0.15025711059570312
Batch 25/64 loss: 0.008287429809570312
Batch 26/64 loss: 0.12063407897949219
Batch 27/64 loss: -0.4340038299560547
Batch 28/64 loss: -0.30925464630126953
Batch 29/64 loss: -0.3177957534790039
Batch 30/64 loss: 0.16831588745117188
Batch 31/64 loss: -0.6056690216064453
Batch 32/64 loss: -0.5203971862792969
Batch 33/64 loss: -0.08393001556396484
Batch 34/64 loss: -0.08802032470703125
Batch 35/64 loss: 1.0190191268920898
Batch 36/64 loss: 0.4255332946777344
Batch 37/64 loss: -0.12591934204101562
Batch 38/64 loss: -0.42707252502441406
Batch 39/64 loss: 0.6857719421386719
Batch 40/64 loss: 0.26100635528564453
Batch 41/64 loss: -0.30463123321533203
Batch 42/64 loss: -0.6683521270751953
Batch 43/64 loss: -0.5255794525146484
Batch 44/64 loss: 0.02372455596923828
Batch 45/64 loss: 0.14864158630371094
Batch 46/64 loss: 0.042069435119628906
Batch 47/64 loss: -0.4578895568847656
Batch 48/64 loss: -0.8583240509033203
Batch 49/64 loss: -0.5257492065429688
Batch 50/64 loss: -0.7488279342651367
Batch 51/64 loss: -0.5556697845458984
Batch 52/64 loss: -0.33447265625
Batch 53/64 loss: -0.42775726318359375
Batch 54/64 loss: -0.5624942779541016
Batch 55/64 loss: -0.5665426254272461
Batch 56/64 loss: -0.5771055221557617
Batch 57/64 loss: 0.086456298828125
Batch 58/64 loss: -0.07196235656738281
Batch 59/64 loss: -0.32720470428466797
Batch 60/64 loss: -0.11348152160644531
Batch 61/64 loss: -0.3178873062133789
Batch 62/64 loss: -0.5451812744140625
Batch 63/64 loss: -0.7046995162963867
Batch 64/64 loss: -4.821288108825684
Epoch 106  Train loss: -0.03951236874449487  Val loss: -0.6697855028499853
Epoch 107
-------------------------------
Batch 1/64 loss: -0.7703056335449219
Batch 2/64 loss: -0.3022928237915039
Batch 3/64 loss: -0.24247455596923828
Batch 4/64 loss: -0.7416210174560547
Batch 5/64 loss: -0.38884639739990234
Batch 6/64 loss: -0.5179033279418945
Batch 7/64 loss: -0.595067024230957
Batch 8/64 loss: -0.49340152740478516
Batch 9/64 loss: -0.5547657012939453
Batch 10/64 loss: -0.026830673217773438
Batch 11/64 loss: -0.7416782379150391
Batch 12/64 loss: -0.3785228729248047
Batch 13/64 loss: -0.5437278747558594
Batch 14/64 loss: -0.7661094665527344
Batch 15/64 loss: -0.761418342590332
Batch 16/64 loss: -0.09466743469238281
Batch 17/64 loss: -0.28602027893066406
Batch 18/64 loss: -0.6609573364257812
Batch 19/64 loss: -0.6783390045166016
Batch 20/64 loss: -0.8228330612182617
Batch 21/64 loss: -0.9858646392822266
Batch 22/64 loss: -0.15485000610351562
Batch 23/64 loss: -0.12723731994628906
Batch 24/64 loss: -0.3622922897338867
Batch 25/64 loss: -0.7397556304931641
Batch 26/64 loss: -0.7392129898071289
Batch 27/64 loss: -0.8495759963989258
Batch 28/64 loss: -0.5600080490112305
Batch 29/64 loss: -0.4551677703857422
Batch 30/64 loss: -0.6734628677368164
Batch 31/64 loss: -0.31588077545166016
Batch 32/64 loss: -0.8051052093505859
Batch 33/64 loss: -0.8781366348266602
Batch 34/64 loss: -0.27486419677734375
Batch 35/64 loss: -0.5636653900146484
Batch 36/64 loss: -0.6817092895507812
Batch 37/64 loss: -0.7140569686889648
Batch 38/64 loss: -0.11249828338623047
Batch 39/64 loss: -1.000875473022461
Batch 40/64 loss: -0.6651744842529297
Batch 41/64 loss: 0.3255882263183594
Batch 42/64 loss: -0.9696903228759766
Batch 43/64 loss: -0.649139404296875
Batch 44/64 loss: -0.24661636352539062
Batch 45/64 loss: -0.6438045501708984
Batch 46/64 loss: -0.49421215057373047
Batch 47/64 loss: -0.16630268096923828
Batch 48/64 loss: 0.47891902923583984
Batch 49/64 loss: -0.42592334747314453
Batch 50/64 loss: -0.7098941802978516
Batch 51/64 loss: -0.9234838485717773
Batch 52/64 loss: -0.7219343185424805
Batch 53/64 loss: -0.893946647644043
Batch 54/64 loss: -0.6745357513427734
Batch 55/64 loss: -0.20828914642333984
Batch 56/64 loss: 0.3032073974609375
Batch 57/64 loss: -0.5739011764526367
Batch 58/64 loss: -0.9943389892578125
Batch 59/64 loss: -0.3831787109375
Batch 60/64 loss: -0.5589208602905273
Batch 61/64 loss: -0.791285514831543
Batch 62/64 loss: -0.7222957611083984
Batch 63/64 loss: -0.4512519836425781
Batch 64/64 loss: -4.9147419929504395
Epoch 107  Train loss: -0.5773876769869936  Val loss: -0.9084693148373738
Epoch 108
-------------------------------
Batch 1/64 loss: -0.33812618255615234
Batch 2/64 loss: -0.7448492050170898
Batch 3/64 loss: -0.8678693771362305
Batch 4/64 loss: -0.5213813781738281
Batch 5/64 loss: -0.5817403793334961
Batch 6/64 loss: -1.145486831665039
Batch 7/64 loss: -0.9816570281982422
Batch 8/64 loss: -0.45925235748291016
Batch 9/64 loss: -0.6538448333740234
Batch 10/64 loss: -0.7306995391845703
Batch 11/64 loss: -0.6977643966674805
Batch 12/64 loss: -0.9779787063598633
Batch 13/64 loss: -0.6867637634277344
Batch 14/64 loss: -0.5887155532836914
Batch 15/64 loss: -0.6325740814208984
Batch 16/64 loss: -0.7862014770507812
Batch 17/64 loss: -0.2819843292236328
Batch 18/64 loss: -0.6991748809814453
Batch 19/64 loss: -0.6297941207885742
Batch 20/64 loss: -0.8378620147705078
Batch 21/64 loss: -0.6645164489746094
Batch 22/64 loss: -1.235696792602539
Batch 23/64 loss: -0.4220399856567383
Batch 24/64 loss: -0.4834318161010742
Batch 25/64 loss: -0.9232635498046875
Batch 26/64 loss: -1.0404081344604492
Batch 27/64 loss: -0.7823753356933594
Batch 28/64 loss: -0.7660331726074219
Batch 29/64 loss: -0.3753690719604492
Batch 30/64 loss: -0.41316795349121094
Batch 31/64 loss: -0.9840211868286133
Batch 32/64 loss: -0.5918741226196289
Batch 33/64 loss: -0.8806524276733398
Batch 34/64 loss: -0.2771778106689453
Batch 35/64 loss: -1.0019311904907227
Batch 36/64 loss: -0.6164836883544922
Batch 37/64 loss: -0.4470500946044922
Batch 38/64 loss: -0.40618133544921875
Batch 39/64 loss: -0.8538331985473633
Batch 40/64 loss: -0.3001413345336914
Batch 41/64 loss: -0.7942609786987305
Batch 42/64 loss: -0.5777778625488281
Batch 43/64 loss: -0.6207609176635742
Batch 44/64 loss: -0.7890415191650391
Batch 45/64 loss: -0.9490795135498047
Batch 46/64 loss: -1.0424222946166992
Batch 47/64 loss: -1.0484066009521484
Batch 48/64 loss: -0.7496700286865234
Batch 49/64 loss: -0.5646591186523438
Batch 50/64 loss: -1.0264549255371094
Batch 51/64 loss: -1.0568351745605469
Batch 52/64 loss: -0.8940563201904297
Batch 53/64 loss: -0.8707609176635742
Batch 54/64 loss: -0.09093952178955078
Batch 55/64 loss: -0.7459545135498047
Batch 56/64 loss: 0.18597984313964844
Batch 57/64 loss: -0.6235485076904297
Batch 58/64 loss: -0.9415626525878906
Batch 59/64 loss: -0.6773519515991211
Batch 60/64 loss: 0.17685413360595703
Batch 61/64 loss: -0.2865314483642578
Batch 62/64 loss: -0.18045520782470703
Batch 63/64 loss: -0.5216960906982422
Batch 64/64 loss: -2.870037078857422
Epoch 108  Train loss: -0.6925692389993107  Val loss: 0.002109933964575279
Epoch 109
-------------------------------
Batch 1/64 loss: -0.3560504913330078
Batch 2/64 loss: 0.01129150390625
Batch 3/64 loss: 0.16059589385986328
Batch 4/64 loss: -0.2789592742919922
Batch 5/64 loss: -0.6192646026611328
Batch 6/64 loss: -0.6779851913452148
Batch 7/64 loss: 1.6546564102172852
Batch 8/64 loss: -0.4773988723754883
Batch 9/64 loss: -0.8533086776733398
Batch 10/64 loss: 1.032033920288086
Batch 11/64 loss: -0.5498743057250977
Batch 12/64 loss: -0.5811309814453125
Batch 13/64 loss: -0.7060346603393555
Batch 14/64 loss: 0.024794578552246094
Batch 15/64 loss: -0.2567472457885742
Batch 16/64 loss: -0.2482748031616211
Batch 17/64 loss: -0.01203155517578125
Batch 18/64 loss: -0.5235357284545898
Batch 19/64 loss: -0.4963083267211914
Batch 20/64 loss: -0.33412647247314453
Batch 21/64 loss: -0.21799659729003906
Batch 22/64 loss: -0.8343343734741211
Batch 23/64 loss: -0.4935178756713867
Batch 24/64 loss: 0.07175350189208984
Batch 25/64 loss: 0.09112548828125
Batch 26/64 loss: -0.5977554321289062
Batch 27/64 loss: -0.17625904083251953
Batch 28/64 loss: 0.6373167037963867
Batch 29/64 loss: -0.6395654678344727
Batch 30/64 loss: -0.5699310302734375
Batch 31/64 loss: -0.3731374740600586
Batch 32/64 loss: 0.41537952423095703
Batch 33/64 loss: -0.4935035705566406
Batch 34/64 loss: -0.6924457550048828
Batch 35/64 loss: -0.7475061416625977
Batch 36/64 loss: -0.8008480072021484
Batch 37/64 loss: -0.07929229736328125
Batch 38/64 loss: -0.8088464736938477
Batch 39/64 loss: -0.44632911682128906
Batch 40/64 loss: -0.9071359634399414
Batch 41/64 loss: -0.5895204544067383
Batch 42/64 loss: -0.12199974060058594
Batch 43/64 loss: -0.3393287658691406
Batch 44/64 loss: -0.5627908706665039
Batch 45/64 loss: 0.10106277465820312
Batch 46/64 loss: -0.6060285568237305
Batch 47/64 loss: -0.5696277618408203
Batch 48/64 loss: -0.5402927398681641
Batch 49/64 loss: -0.6723299026489258
Batch 50/64 loss: -1.0146265029907227
Batch 51/64 loss: -0.5525722503662109
Batch 52/64 loss: -0.7616024017333984
Batch 53/64 loss: -0.7957496643066406
Batch 54/64 loss: -0.45317745208740234
Batch 55/64 loss: -0.47455596923828125
Batch 56/64 loss: -0.7964258193969727
Batch 57/64 loss: -0.554107666015625
Batch 58/64 loss: -0.47959232330322266
Batch 59/64 loss: -0.37178802490234375
Batch 60/64 loss: -0.6353187561035156
Batch 61/64 loss: -0.6219234466552734
Batch 62/64 loss: -0.1452655792236328
Batch 63/64 loss: -0.6108369827270508
Batch 64/64 loss: -4.488166809082031
Epoch 109  Train loss: -0.428000192081227  Val loss: -0.5217722863266149
Epoch 110
-------------------------------
Batch 1/64 loss: -0.4802217483520508
Batch 2/64 loss: -0.7032070159912109
Batch 3/64 loss: -0.6138629913330078
Batch 4/64 loss: -0.48767662048339844
Batch 5/64 loss: -1.002655029296875
Batch 6/64 loss: -0.6686897277832031
Batch 7/64 loss: -0.9015159606933594
Batch 8/64 loss: -0.8503055572509766
Batch 9/64 loss: -0.4997110366821289
Batch 10/64 loss: -0.6934680938720703
Batch 11/64 loss: -0.18374252319335938
Batch 12/64 loss: -0.30791568756103516
Batch 13/64 loss: -0.7020797729492188
Batch 14/64 loss: 0.295135498046875
Batch 15/64 loss: -1.059065818786621
Batch 16/64 loss: -0.26930713653564453
Batch 17/64 loss: 0.6386117935180664
Batch 18/64 loss: -0.09008312225341797
Batch 19/64 loss: -0.47063541412353516
Batch 20/64 loss: -0.12235450744628906
Batch 21/64 loss: -0.5050210952758789
Batch 22/64 loss: -0.8369989395141602
Batch 23/64 loss: -0.6161527633666992
Batch 24/64 loss: 0.13227176666259766
Batch 25/64 loss: -0.6158123016357422
Batch 26/64 loss: -0.1723947525024414
Batch 27/64 loss: -0.5837488174438477
Batch 28/64 loss: -0.8952465057373047
Batch 29/64 loss: -0.6968936920166016
Batch 30/64 loss: -0.561488151550293
Batch 31/64 loss: -0.638580322265625
Batch 32/64 loss: -0.9433937072753906
Batch 33/64 loss: -0.7935428619384766
Batch 34/64 loss: -0.9454021453857422
Batch 35/64 loss: -0.950016975402832
Batch 36/64 loss: -0.7404661178588867
Batch 37/64 loss: -0.8613471984863281
Batch 38/64 loss: -0.799036979675293
Batch 39/64 loss: -0.4308185577392578
Batch 40/64 loss: -0.9839010238647461
Batch 41/64 loss: -0.9933137893676758
Batch 42/64 loss: -0.9863557815551758
Batch 43/64 loss: -0.7454357147216797
Batch 44/64 loss: -0.9032936096191406
Batch 45/64 loss: -0.7828369140625
Batch 46/64 loss: -0.6593046188354492
Batch 47/64 loss: -1.0271873474121094
Batch 48/64 loss: -0.8687801361083984
Batch 49/64 loss: -0.5116519927978516
Batch 50/64 loss: -0.9821577072143555
Batch 51/64 loss: -0.7407913208007812
Batch 52/64 loss: -0.8877630233764648
Batch 53/64 loss: -0.8046045303344727
Batch 54/64 loss: -0.5171318054199219
Batch 55/64 loss: -0.6443510055541992
Batch 56/64 loss: -0.5344400405883789
Batch 57/64 loss: -0.6660528182983398
Batch 58/64 loss: -0.08077239990234375
Batch 59/64 loss: -0.635401725769043
Batch 60/64 loss: -0.888885498046875
Batch 61/64 loss: -0.8554267883300781
Batch 62/64 loss: -0.6914539337158203
Batch 63/64 loss: -0.7077541351318359
Batch 64/64 loss: -4.918440818786621
Epoch 110  Train loss: -0.6810151979035022  Val loss: -0.7664235432942709
Epoch 111
-------------------------------
Batch 1/64 loss: -0.9136457443237305
Batch 2/64 loss: -0.6137590408325195
Batch 3/64 loss: -0.8481998443603516
Batch 4/64 loss: -0.843287467956543
Batch 5/64 loss: -0.7762479782104492
Batch 6/64 loss: -1.0625715255737305
Batch 7/64 loss: -0.924220085144043
Batch 8/64 loss: -0.7779808044433594
Batch 9/64 loss: -0.8770294189453125
Batch 10/64 loss: -0.3938179016113281
Batch 11/64 loss: -0.20082378387451172
Batch 12/64 loss: -0.728999137878418
Batch 13/64 loss: -0.8865413665771484
Batch 14/64 loss: -0.5786170959472656
Batch 15/64 loss: -1.0153207778930664
Batch 16/64 loss: -0.39358997344970703
Batch 17/64 loss: -0.7999973297119141
Batch 18/64 loss: -0.959101676940918
Batch 19/64 loss: -1.2612905502319336
Batch 20/64 loss: -0.9463930130004883
Batch 21/64 loss: -0.9322910308837891
Batch 22/64 loss: -1.2056808471679688
Batch 23/64 loss: -0.8436660766601562
Batch 24/64 loss: -0.8908014297485352
Batch 25/64 loss: -1.0939598083496094
Batch 26/64 loss: -0.6979732513427734
Batch 27/64 loss: -0.6215839385986328
Batch 28/64 loss: -0.20548152923583984
Batch 29/64 loss: -1.1178646087646484
Batch 30/64 loss: -0.9174814224243164
Batch 31/64 loss: -1.0723848342895508
Batch 32/64 loss: -1.1746206283569336
Batch 33/64 loss: -1.005722999572754
Batch 34/64 loss: -0.9347591400146484
Batch 35/64 loss: -0.6428108215332031
Batch 36/64 loss: -1.1907882690429688
Batch 37/64 loss: -0.9971275329589844
Batch 38/64 loss: -1.044163703918457
Batch 39/64 loss: -0.6281461715698242
Batch 40/64 loss: -0.3469696044921875
Batch 41/64 loss: -0.5152750015258789
Batch 42/64 loss: -0.6445932388305664
Batch 43/64 loss: -0.9620332717895508
Batch 44/64 loss: -0.9121360778808594
Batch 45/64 loss: -0.9300861358642578
Batch 46/64 loss: 0.27969837188720703
Batch 47/64 loss: -1.2741432189941406
Batch 48/64 loss: -0.9469270706176758
Batch 49/64 loss: -0.1505422592163086
Batch 50/64 loss: -1.1296920776367188
Batch 51/64 loss: -0.6507234573364258
Batch 52/64 loss: 0.529240608215332
Batch 53/64 loss: -0.5682916641235352
Batch 54/64 loss: -0.8129005432128906
Batch 55/64 loss: -0.5695075988769531
Batch 56/64 loss: -1.115020751953125
Batch 57/64 loss: -0.5368137359619141
Batch 58/64 loss: -0.6257772445678711
Batch 59/64 loss: -0.666081428527832
Batch 60/64 loss: -0.75653076171875
Batch 61/64 loss: -0.823063850402832
Batch 62/64 loss: -0.5859546661376953
Batch 63/64 loss: -0.7927446365356445
Batch 64/64 loss: -5.185489177703857
Epoch 111  Train loss: -0.8221918236975576  Val loss: -1.0175869473067345
Epoch 112
-------------------------------
Batch 1/64 loss: -1.0349197387695312
Batch 2/64 loss: -1.0313100814819336
Batch 3/64 loss: -1.1700782775878906
Batch 4/64 loss: -1.0803871154785156
Batch 5/64 loss: -0.8482847213745117
Batch 6/64 loss: -0.8904495239257812
Batch 7/64 loss: -0.8418951034545898
Batch 8/64 loss: -1.0992088317871094
Batch 9/64 loss: -1.2543067932128906
Batch 10/64 loss: -0.9832649230957031
Batch 11/64 loss: -0.8184127807617188
Batch 12/64 loss: -0.7196359634399414
Batch 13/64 loss: -0.8269147872924805
Batch 14/64 loss: -0.9719562530517578
Batch 15/64 loss: -0.3321352005004883
Batch 16/64 loss: -0.8243064880371094
Batch 17/64 loss: -0.697174072265625
Batch 18/64 loss: 0.21663951873779297
Batch 19/64 loss: -0.9542112350463867
Batch 20/64 loss: -0.8895750045776367
Batch 21/64 loss: -0.850764274597168
Batch 22/64 loss: -0.8180809020996094
Batch 23/64 loss: -0.9667215347290039
Batch 24/64 loss: -1.1239252090454102
Batch 25/64 loss: -0.5375375747680664
Batch 26/64 loss: -0.5476713180541992
Batch 27/64 loss: -1.1247482299804688
Batch 28/64 loss: -0.6422500610351562
Batch 29/64 loss: -0.776301383972168
Batch 30/64 loss: -0.7291011810302734
Batch 31/64 loss: -1.0105009078979492
Batch 32/64 loss: -0.9845972061157227
Batch 33/64 loss: -0.8388023376464844
Batch 34/64 loss: -1.0932025909423828
Batch 35/64 loss: -1.1311769485473633
Batch 36/64 loss: -0.4057350158691406
Batch 37/64 loss: -1.0139951705932617
Batch 38/64 loss: -1.178400993347168
Batch 39/64 loss: -1.0754623413085938
Batch 40/64 loss: -0.8412313461303711
Batch 41/64 loss: -0.7394266128540039
Batch 42/64 loss: -0.9661331176757812
Batch 43/64 loss: -0.9353017807006836
Batch 44/64 loss: -1.1743907928466797
Batch 45/64 loss: -1.0929756164550781
Batch 46/64 loss: -0.6871366500854492
Batch 47/64 loss: -1.0120906829833984
Batch 48/64 loss: -0.9321756362915039
Batch 49/64 loss: -1.1039094924926758
Batch 50/64 loss: -0.9515409469604492
Batch 51/64 loss: -0.7483835220336914
Batch 52/64 loss: -0.6157970428466797
Batch 53/64 loss: -0.8614978790283203
Batch 54/64 loss: -1.2689189910888672
Batch 55/64 loss: -0.9897127151489258
Batch 56/64 loss: -0.46616458892822266
Batch 57/64 loss: -1.0090961456298828
Batch 58/64 loss: -0.3571481704711914
Batch 59/64 loss: -0.575347900390625
Batch 60/64 loss: -1.2605724334716797
Batch 61/64 loss: -0.6176528930664062
Batch 62/64 loss: -1.059218406677246
Batch 63/64 loss: -0.6447458267211914
Batch 64/64 loss: -5.249011993408203
Epoch 112  Train loss: -0.921538678337546  Val loss: -0.9876839024914089
Epoch 113
-------------------------------
Batch 1/64 loss: -1.129079818725586
Batch 2/64 loss: -1.0109357833862305
Batch 3/64 loss: -0.6259212493896484
Batch 4/64 loss: -0.9139509201049805
Batch 5/64 loss: -1.0714759826660156
Batch 6/64 loss: -0.3132638931274414
Batch 7/64 loss: -0.9835071563720703
Batch 8/64 loss: -1.0392189025878906
Batch 9/64 loss: 0.16393184661865234
Batch 10/64 loss: -1.0583295822143555
Batch 11/64 loss: -0.7908706665039062
Batch 12/64 loss: -0.5686540603637695
Batch 13/64 loss: -1.0378999710083008
Batch 14/64 loss: -0.7852039337158203
Batch 15/64 loss: -0.9008159637451172
Batch 16/64 loss: -1.0219354629516602
Batch 17/64 loss: -0.9528751373291016
Batch 18/64 loss: -1.0599498748779297
Batch 19/64 loss: -0.9537734985351562
Batch 20/64 loss: -1.1411590576171875
Batch 21/64 loss: -0.42284393310546875
Batch 22/64 loss: -0.7782726287841797
Batch 23/64 loss: -1.2885761260986328
Batch 24/64 loss: -1.102656364440918
Batch 25/64 loss: -0.9551639556884766
Batch 26/64 loss: -0.5849475860595703
Batch 27/64 loss: 0.5460138320922852
Batch 28/64 loss: -0.9957828521728516
Batch 29/64 loss: -1.0554981231689453
Batch 30/64 loss: -0.5529880523681641
Batch 31/64 loss: -0.6119108200073242
Batch 32/64 loss: -0.7930583953857422
Batch 33/64 loss: -1.0759477615356445
Batch 34/64 loss: -1.0735893249511719
Batch 35/64 loss: -1.1191892623901367
Batch 36/64 loss: -1.1162099838256836
Batch 37/64 loss: -0.8017282485961914
Batch 38/64 loss: -1.0998544692993164
Batch 39/64 loss: -0.9048585891723633
Batch 40/64 loss: -1.0405092239379883
Batch 41/64 loss: -1.04559326171875
Batch 42/64 loss: -0.7430143356323242
Batch 43/64 loss: -1.207810401916504
Batch 44/64 loss: -0.2953481674194336
Batch 45/64 loss: -1.1043376922607422
Batch 46/64 loss: -1.3073549270629883
Batch 47/64 loss: -0.8577661514282227
Batch 48/64 loss: -0.7118864059448242
Batch 49/64 loss: -1.2609777450561523
Batch 50/64 loss: -1.0051660537719727
Batch 51/64 loss: -1.0384464263916016
Batch 52/64 loss: -0.7630195617675781
Batch 53/64 loss: -1.1140327453613281
Batch 54/64 loss: -1.2710456848144531
Batch 55/64 loss: -0.7589912414550781
Batch 56/64 loss: -1.0580005645751953
Batch 57/64 loss: -0.5076389312744141
Batch 58/64 loss: -0.8583860397338867
Batch 59/64 loss: -1.159256935119629
Batch 60/64 loss: -1.2525348663330078
Batch 61/64 loss: -0.9553585052490234
Batch 62/64 loss: -1.041600227355957
Batch 63/64 loss: -1.1621246337890625
Batch 64/64 loss: -5.223123550415039
Epoch 113  Train loss: -0.9477567859724456  Val loss: -1.233825552504497
Epoch 114
-------------------------------
Batch 1/64 loss: -1.1174640655517578
Batch 2/64 loss: -0.8948183059692383
Batch 3/64 loss: -1.2668275833129883
Batch 4/64 loss: -0.7819118499755859
Batch 5/64 loss: -1.0063838958740234
Batch 6/64 loss: -0.999755859375
Batch 7/64 loss: -0.8071689605712891
Batch 8/64 loss: -0.5726633071899414
Batch 9/64 loss: -0.749842643737793
Batch 10/64 loss: -0.9680156707763672
Batch 11/64 loss: -0.9751720428466797
Batch 12/64 loss: -1.2661237716674805
Batch 13/64 loss: -1.1758804321289062
Batch 14/64 loss: -0.7087717056274414
Batch 15/64 loss: -1.1903648376464844
Batch 16/64 loss: -1.145486831665039
Batch 17/64 loss: 0.1993732452392578
Batch 18/64 loss: -0.8081951141357422
Batch 19/64 loss: -1.254624366760254
Batch 20/64 loss: -0.2520790100097656
Batch 21/64 loss: -0.5411739349365234
Batch 22/64 loss: -0.8564386367797852
Batch 23/64 loss: -0.9796113967895508
Batch 24/64 loss: -0.9742803573608398
Batch 25/64 loss: -0.5158843994140625
Batch 26/64 loss: -0.9933013916015625
Batch 27/64 loss: -0.9311227798461914
Batch 28/64 loss: -0.8473100662231445
Batch 29/64 loss: -0.34268951416015625
Batch 30/64 loss: -1.2095823287963867
Batch 31/64 loss: -1.0332374572753906
Batch 32/64 loss: -1.0168628692626953
Batch 33/64 loss: -0.956751823425293
Batch 34/64 loss: -0.3549623489379883
Batch 35/64 loss: -1.360788345336914
Batch 36/64 loss: -1.305368423461914
Batch 37/64 loss: -1.0899524688720703
Batch 38/64 loss: -0.535552978515625
Batch 39/64 loss: -1.0268621444702148
Batch 40/64 loss: -1.1525535583496094
Batch 41/64 loss: -0.6618013381958008
Batch 42/64 loss: -1.1815605163574219
Batch 43/64 loss: -1.0161619186401367
Batch 44/64 loss: -1.1944561004638672
Batch 45/64 loss: -0.8834590911865234
Batch 46/64 loss: -1.066584587097168
Batch 47/64 loss: -0.16281890869140625
Batch 48/64 loss: -1.2395238876342773
Batch 49/64 loss: -1.0580501556396484
Batch 50/64 loss: -1.075185775756836
Batch 51/64 loss: -0.6260004043579102
Batch 52/64 loss: -0.9102973937988281
Batch 53/64 loss: -0.7020092010498047
Batch 54/64 loss: -0.8496055603027344
Batch 55/64 loss: -0.8966312408447266
Batch 56/64 loss: -1.0978927612304688
Batch 57/64 loss: -1.1646718978881836
Batch 58/64 loss: -1.0891103744506836
Batch 59/64 loss: -1.1833248138427734
Batch 60/64 loss: -0.8297290802001953
Batch 61/64 loss: -1.249985694885254
Batch 62/64 loss: -0.8394432067871094
Batch 63/64 loss: -1.3186931610107422
Batch 64/64 loss: -5.22356653213501
Epoch 114  Train loss: -0.972253116906858  Val loss: -1.2138534100194978
Epoch 115
-------------------------------
Batch 1/64 loss: -1.2789011001586914
Batch 2/64 loss: -1.2181501388549805
Batch 3/64 loss: -0.4100761413574219
Batch 4/64 loss: -1.241424560546875
Batch 5/64 loss: -0.935063362121582
Batch 6/64 loss: -1.224198341369629
Batch 7/64 loss: -1.1989984512329102
Batch 8/64 loss: -1.1796875
Batch 9/64 loss: -1.016362190246582
Batch 10/64 loss: -1.4322519302368164
Batch 11/64 loss: -0.9204702377319336
Batch 12/64 loss: -0.5811548233032227
Batch 13/64 loss: -1.245894432067871
Batch 14/64 loss: -1.038802146911621
Batch 15/64 loss: -1.1981735229492188
Batch 16/64 loss: -1.2960634231567383
Batch 17/64 loss: -1.0245895385742188
Batch 18/64 loss: -1.056532859802246
Batch 19/64 loss: -1.091496467590332
Batch 20/64 loss: -0.6967029571533203
Batch 21/64 loss: -1.2757577896118164
Batch 22/64 loss: -1.2128334045410156
Batch 23/64 loss: -1.0983562469482422
Batch 24/64 loss: -1.2359085083007812
Batch 25/64 loss: -0.6841306686401367
Batch 26/64 loss: -0.6976413726806641
Batch 27/64 loss: -0.8989315032958984
Batch 28/64 loss: -1.2357616424560547
Batch 29/64 loss: -0.9217185974121094
Batch 30/64 loss: -1.252181053161621
Batch 31/64 loss: -1.154825210571289
Batch 32/64 loss: -1.094679832458496
Batch 33/64 loss: -1.0780000686645508
Batch 34/64 loss: 0.17643451690673828
Batch 35/64 loss: -1.2206964492797852
Batch 36/64 loss: -1.2289867401123047
Batch 37/64 loss: -0.7577428817749023
Batch 38/64 loss: -0.8695602416992188
Batch 39/64 loss: -0.7928581237792969
Batch 40/64 loss: -1.0498676300048828
Batch 41/64 loss: -1.0947942733764648
Batch 42/64 loss: -1.0282278060913086
Batch 43/64 loss: -0.12577342987060547
Batch 44/64 loss: -1.0392866134643555
Batch 45/64 loss: -1.2082748413085938
Batch 46/64 loss: -1.3478975296020508
Batch 47/64 loss: -0.5598115921020508
Batch 48/64 loss: -1.1727991104125977
Batch 49/64 loss: -1.3222627639770508
Batch 50/64 loss: -1.2304372787475586
Batch 51/64 loss: -1.0745830535888672
Batch 52/64 loss: -0.7925519943237305
Batch 53/64 loss: -1.2791271209716797
Batch 54/64 loss: -1.263289451599121
Batch 55/64 loss: -0.8545322418212891
Batch 56/64 loss: -0.5605764389038086
Batch 57/64 loss: -0.5248832702636719
Batch 58/64 loss: -1.0629940032958984
Batch 59/64 loss: -0.5145263671875
Batch 60/64 loss: -0.9283361434936523
Batch 61/64 loss: -0.7787456512451172
Batch 62/64 loss: -1.1608343124389648
Batch 63/64 loss: -1.0966224670410156
Batch 64/64 loss: -5.383903503417969
Epoch 115  Train loss: -1.0498524385340073  Val loss: -1.028083368674996
Epoch 116
-------------------------------
Batch 1/64 loss: -0.9134941101074219
Batch 2/64 loss: -1.100489616394043
Batch 3/64 loss: -1.1160564422607422
Batch 4/64 loss: -0.42097949981689453
Batch 5/64 loss: -1.120142936706543
Batch 6/64 loss: -1.2695789337158203
Batch 7/64 loss: -1.035536766052246
Batch 8/64 loss: -0.8706598281860352
Batch 9/64 loss: -0.8254003524780273
Batch 10/64 loss: -1.2258567810058594
Batch 11/64 loss: -0.7286272048950195
Batch 12/64 loss: -1.197906494140625
Batch 13/64 loss: -1.0527029037475586
Batch 14/64 loss: -0.7690954208374023
Batch 15/64 loss: -0.8952436447143555
Batch 16/64 loss: -1.189004898071289
Batch 17/64 loss: -0.9472675323486328
Batch 18/64 loss: -0.17548274993896484
Batch 19/64 loss: -1.250955581665039
Batch 20/64 loss: -1.1013364791870117
Batch 21/64 loss: -0.9107398986816406
Batch 22/64 loss: -1.0513734817504883
Batch 23/64 loss: -0.9469232559204102
Batch 24/64 loss: -1.0563173294067383
Batch 25/64 loss: -1.0741844177246094
Batch 26/64 loss: -1.1596012115478516
Batch 27/64 loss: -1.2542123794555664
Batch 28/64 loss: -0.8530101776123047
Batch 29/64 loss: -0.5212345123291016
Batch 30/64 loss: -0.7649126052856445
Batch 31/64 loss: -0.49138641357421875
Batch 32/64 loss: -1.1869544982910156
Batch 33/64 loss: -0.7005767822265625
Batch 34/64 loss: -1.1360759735107422
Batch 35/64 loss: -0.42681312561035156
Batch 36/64 loss: -1.1094903945922852
Batch 37/64 loss: -0.9567089080810547
Batch 38/64 loss: -1.2162160873413086
Batch 39/64 loss: 0.24631977081298828
Batch 40/64 loss: -0.46329784393310547
Batch 41/64 loss: -0.9996013641357422
Batch 42/64 loss: -1.0874805450439453
Batch 43/64 loss: -0.32671642303466797
Batch 44/64 loss: -1.282196044921875
Batch 45/64 loss: -1.0164966583251953
Batch 46/64 loss: -1.1678943634033203
Batch 47/64 loss: -1.4385004043579102
Batch 48/64 loss: -1.0405778884887695
Batch 49/64 loss: -1.1298503875732422
Batch 50/64 loss: -1.192774772644043
Batch 51/64 loss: -0.9270410537719727
Batch 52/64 loss: -0.6237697601318359
Batch 53/64 loss: -0.9111442565917969
Batch 54/64 loss: -1.094771385192871
Batch 55/64 loss: -0.7346057891845703
Batch 56/64 loss: -0.6924915313720703
Batch 57/64 loss: -1.1992692947387695
Batch 58/64 loss: -1.1560173034667969
Batch 59/64 loss: -0.5595769882202148
Batch 60/64 loss: 0.3206787109375
Batch 61/64 loss: -1.425302505493164
Batch 62/64 loss: -1.3171567916870117
Batch 63/64 loss: -1.0744132995605469
Batch 64/64 loss: -5.542883396148682
Epoch 116  Train loss: -0.9799789858799355  Val loss: -1.0877817553752887
Epoch 117
-------------------------------
Batch 1/64 loss: -0.5738296508789062
Batch 2/64 loss: -1.1685457229614258
Batch 3/64 loss: -0.9770736694335938
Batch 4/64 loss: -0.7693099975585938
Batch 5/64 loss: -1.0465116500854492
Batch 6/64 loss: -0.9293594360351562
Batch 7/64 loss: -0.6736898422241211
Batch 8/64 loss: -0.9825334548950195
Batch 9/64 loss: -0.8105974197387695
Batch 10/64 loss: -1.1419858932495117
Batch 11/64 loss: -0.5114898681640625
Batch 12/64 loss: -1.0405654907226562
Batch 13/64 loss: -1.169297218322754
Batch 14/64 loss: -1.2233161926269531
Batch 15/64 loss: -1.3307552337646484
Batch 16/64 loss: -1.235595703125
Batch 17/64 loss: -0.7672719955444336
Batch 18/64 loss: -0.43742847442626953
Batch 19/64 loss: -1.236032485961914
Batch 20/64 loss: 0.06863689422607422
Batch 21/64 loss: -1.2905025482177734
Batch 22/64 loss: -0.6179370880126953
Batch 23/64 loss: -1.2398157119750977
Batch 24/64 loss: -0.7883520126342773
Batch 25/64 loss: -1.1998682022094727
Batch 26/64 loss: -0.9197998046875
Batch 27/64 loss: -1.2049455642700195
Batch 28/64 loss: -0.9301614761352539
Batch 29/64 loss: -0.8382720947265625
Batch 30/64 loss: -0.436279296875
Batch 31/64 loss: 0.4376668930053711
Batch 32/64 loss: -1.0061063766479492
Batch 33/64 loss: -0.9901895523071289
Batch 34/64 loss: -1.139801025390625
Batch 35/64 loss: -1.3919429779052734
Batch 36/64 loss: -0.7116661071777344
Batch 37/64 loss: -1.0528383255004883
Batch 38/64 loss: -1.1963863372802734
Batch 39/64 loss: -0.9730024337768555
Batch 40/64 loss: -1.1644201278686523
Batch 41/64 loss: -0.8628034591674805
Batch 42/64 loss: -0.7716121673583984
Batch 43/64 loss: -1.2066774368286133
Batch 44/64 loss: -1.1066255569458008
Batch 45/64 loss: -0.9355230331420898
Batch 46/64 loss: -1.34527587890625
Batch 47/64 loss: -0.9020395278930664
Batch 48/64 loss: -1.3299694061279297
Batch 49/64 loss: -1.1029396057128906
Batch 50/64 loss: -1.3232841491699219
Batch 51/64 loss: -0.9103899002075195
Batch 52/64 loss: -1.02545166015625
Batch 53/64 loss: -0.8729896545410156
Batch 54/64 loss: -1.084756851196289
Batch 55/64 loss: -1.1853666305541992
Batch 56/64 loss: -1.0693111419677734
Batch 57/64 loss: -0.9202966690063477
Batch 58/64 loss: -1.0921201705932617
Batch 59/64 loss: -1.1340179443359375
Batch 60/64 loss: -1.2671279907226562
Batch 61/64 loss: -0.7280502319335938
Batch 62/64 loss: -0.8107213973999023
Batch 63/64 loss: -0.6123123168945312
Batch 64/64 loss: -5.060591697692871
Epoch 117  Train loss: -1.004020066354789  Val loss: -1.1231130226371215
Epoch 118
-------------------------------
Batch 1/64 loss: -0.5689811706542969
Batch 2/64 loss: -1.1175098419189453
Batch 3/64 loss: -1.211568832397461
Batch 4/64 loss: -1.1730108261108398
Batch 5/64 loss: -0.907191276550293
Batch 6/64 loss: -1.0816574096679688
Batch 7/64 loss: -0.5057220458984375
Batch 8/64 loss: -1.0527162551879883
Batch 9/64 loss: -0.33014965057373047
Batch 10/64 loss: -1.185481071472168
Batch 11/64 loss: -1.3057336807250977
Batch 12/64 loss: -1.1158370971679688
Batch 13/64 loss: -0.9706010818481445
Batch 14/64 loss: -0.8027420043945312
Batch 15/64 loss: -1.1405563354492188
Batch 16/64 loss: -0.149169921875
Batch 17/64 loss: -1.1558952331542969
Batch 18/64 loss: -0.9228858947753906
Batch 19/64 loss: -0.974517822265625
Batch 20/64 loss: -1.4490108489990234
Batch 21/64 loss: -1.0193805694580078
Batch 22/64 loss: -1.3644075393676758
Batch 23/64 loss: -1.2335796356201172
Batch 24/64 loss: -0.39380741119384766
Batch 25/64 loss: -1.0339326858520508
Batch 26/64 loss: -1.151510238647461
Batch 27/64 loss: -1.0604219436645508
Batch 28/64 loss: -1.3103408813476562
Batch 29/64 loss: -0.8410682678222656
Batch 30/64 loss: -0.4689340591430664
Batch 31/64 loss: -0.8528642654418945
Batch 32/64 loss: -0.9076910018920898
Batch 33/64 loss: -1.0256013870239258
Batch 34/64 loss: -1.123011589050293
Batch 35/64 loss: -1.096710205078125
Batch 36/64 loss: -0.4022102355957031
Batch 37/64 loss: -1.1773147583007812
Batch 38/64 loss: -0.98175048828125
Batch 39/64 loss: -1.183333396911621
Batch 40/64 loss: -0.9942264556884766
Batch 41/64 loss: -0.8938493728637695
Batch 42/64 loss: -0.888275146484375
Batch 43/64 loss: -1.1921987533569336
Batch 44/64 loss: -1.0815906524658203
Batch 45/64 loss: -1.2375297546386719
Batch 46/64 loss: -0.9576539993286133
Batch 47/64 loss: -1.359039306640625
Batch 48/64 loss: -1.2839393615722656
Batch 49/64 loss: -0.7300949096679688
Batch 50/64 loss: -0.9588460922241211
Batch 51/64 loss: -1.2676200866699219
Batch 52/64 loss: -1.1076850891113281
Batch 53/64 loss: -1.2789297103881836
Batch 54/64 loss: -0.6836557388305664
Batch 55/64 loss: -0.2890758514404297
Batch 56/64 loss: -1.3490571975708008
Batch 57/64 loss: -1.2937421798706055
Batch 58/64 loss: -1.2287311553955078
Batch 59/64 loss: -1.0463190078735352
Batch 60/64 loss: -0.5973834991455078
Batch 61/64 loss: -1.3167791366577148
Batch 62/64 loss: -1.2852869033813477
Batch 63/64 loss: -1.3609428405761719
Batch 64/64 loss: -5.463103294372559
Epoch 118  Train loss: -1.0592719769945331  Val loss: -1.1475668182897405
Epoch 119
-------------------------------
Batch 1/64 loss: -1.3598556518554688
Batch 2/64 loss: -0.8909387588500977
Batch 3/64 loss: -1.3827018737792969
Batch 4/64 loss: -0.8250370025634766
Batch 5/64 loss: -1.146310806274414
Batch 6/64 loss: -1.2378740310668945
Batch 7/64 loss: -1.0619707107543945
Batch 8/64 loss: -1.1083335876464844
Batch 9/64 loss: -1.2733039855957031
Batch 10/64 loss: -1.3687553405761719
Batch 11/64 loss: -1.1705474853515625
Batch 12/64 loss: -1.2236719131469727
Batch 13/64 loss: -0.8673620223999023
Batch 14/64 loss: -0.8422403335571289
Batch 15/64 loss: -1.1096200942993164
Batch 16/64 loss: -1.3117294311523438
Batch 17/64 loss: -1.3650236129760742
Batch 18/64 loss: -1.1869125366210938
Batch 19/64 loss: -0.7504367828369141
Batch 20/64 loss: -1.142207145690918
Batch 21/64 loss: -1.0298128128051758
Batch 22/64 loss: -1.3365612030029297
Batch 23/64 loss: -1.3153362274169922
Batch 24/64 loss: -0.889225959777832
Batch 25/64 loss: -0.3617382049560547
Batch 26/64 loss: -0.9231910705566406
Batch 27/64 loss: -1.0892953872680664
Batch 28/64 loss: -0.9783811569213867
Batch 29/64 loss: -1.3210477828979492
Batch 30/64 loss: -1.1099920272827148
Batch 31/64 loss: -1.182332992553711
Batch 32/64 loss: -0.8276586532592773
Batch 33/64 loss: -0.9019031524658203
Batch 34/64 loss: -0.9509086608886719
Batch 35/64 loss: -0.49957752227783203
Batch 36/64 loss: -0.9287166595458984
Batch 37/64 loss: -0.9769668579101562
Batch 38/64 loss: -0.8080940246582031
Batch 39/64 loss: -0.3965892791748047
Batch 40/64 loss: -0.8589029312133789
Batch 41/64 loss: -1.1625728607177734
Batch 42/64 loss: -0.8583745956420898
Batch 43/64 loss: -1.3025131225585938
Batch 44/64 loss: -1.2370357513427734
Batch 45/64 loss: -1.316411018371582
Batch 46/64 loss: -0.8119335174560547
Batch 47/64 loss: -1.1528329849243164
Batch 48/64 loss: -1.4916801452636719
Batch 49/64 loss: -1.411972999572754
Batch 50/64 loss: -1.151606559753418
Batch 51/64 loss: -1.1803865432739258
Batch 52/64 loss: -0.9008617401123047
Batch 53/64 loss: -1.2902374267578125
Batch 54/64 loss: -1.0804414749145508
Batch 55/64 loss: -1.1138429641723633
Batch 56/64 loss: -1.1316070556640625
Batch 57/64 loss: -1.2314720153808594
Batch 58/64 loss: -1.0415849685668945
Batch 59/64 loss: -1.380965232849121
Batch 60/64 loss: -1.3317880630493164
Batch 61/64 loss: -0.2986640930175781
Batch 62/64 loss: -1.1561126708984375
Batch 63/64 loss: -1.1742095947265625
Batch 64/64 loss: -4.837861061096191
Epoch 119  Train loss: -1.1160559822531309  Val loss: -1.1208804677851831
Epoch 120
-------------------------------
Batch 1/64 loss: -0.8223857879638672
Batch 2/64 loss: -0.9260807037353516
Batch 3/64 loss: -1.164259910583496
Batch 4/64 loss: -1.3944683074951172
Batch 5/64 loss: -1.359360694885254
Batch 6/64 loss: -1.1299686431884766
Batch 7/64 loss: -0.8878698348999023
Batch 8/64 loss: -1.3043766021728516
Batch 9/64 loss: -0.9031686782836914
Batch 10/64 loss: -1.0509510040283203
Batch 11/64 loss: -1.036966323852539
Batch 12/64 loss: -0.6688680648803711
Batch 13/64 loss: -0.28759288787841797
Batch 14/64 loss: -1.013524055480957
Batch 15/64 loss: -1.047774314880371
Batch 16/64 loss: -1.3623332977294922
Batch 17/64 loss: -1.3056621551513672
Batch 18/64 loss: -1.158299446105957
Batch 19/64 loss: -1.2218961715698242
Batch 20/64 loss: -0.24454879760742188
Batch 21/64 loss: -0.8634166717529297
Batch 22/64 loss: -1.0625295639038086
Batch 23/64 loss: -0.9934406280517578
Batch 24/64 loss: -1.2640047073364258
Batch 25/64 loss: -0.9502220153808594
Batch 26/64 loss: -1.0293874740600586
Batch 27/64 loss: -0.4896574020385742
Batch 28/64 loss: -1.4695100784301758
Batch 29/64 loss: -1.020277976989746
Batch 30/64 loss: -1.2451286315917969
Batch 31/64 loss: -1.148630142211914
Batch 32/64 loss: -1.1281461715698242
Batch 33/64 loss: -1.1955947875976562
Batch 34/64 loss: -1.2321796417236328
Batch 35/64 loss: -0.9712343215942383
Batch 36/64 loss: -0.86834716796875
Batch 37/64 loss: -1.1135597229003906
Batch 38/64 loss: -1.0628690719604492
Batch 39/64 loss: -1.2092475891113281
Batch 40/64 loss: -1.2915220260620117
Batch 41/64 loss: -1.0087594985961914
Batch 42/64 loss: -1.0770988464355469
Batch 43/64 loss: -1.3048467636108398
Batch 44/64 loss: -1.2367992401123047
Batch 45/64 loss: -1.1522712707519531
Batch 46/64 loss: -1.2938642501831055
Batch 47/64 loss: -1.1651973724365234
Batch 48/64 loss: -1.144430160522461
Batch 49/64 loss: -1.1208267211914062
Batch 50/64 loss: -1.0527067184448242
Batch 51/64 loss: -1.2474822998046875
Batch 52/64 loss: -0.8919277191162109
Batch 53/64 loss: -1.1839818954467773
Batch 54/64 loss: -1.2335376739501953
Batch 55/64 loss: -0.8256216049194336
Batch 56/64 loss: -1.2599620819091797
Batch 57/64 loss: -1.3311166763305664
Batch 58/64 loss: -1.212900161743164
Batch 59/64 loss: -1.2545394897460938
Batch 60/64 loss: -1.1026220321655273
Batch 61/64 loss: -1.0386972427368164
Batch 62/64 loss: -1.234039306640625
Batch 63/64 loss: -0.9903421401977539
Batch 64/64 loss: -4.513095855712891
Epoch 120  Train loss: -1.123884776994294  Val loss: -1.4284029695176588
Saving best model, epoch: 120
Epoch 121
-------------------------------
Batch 1/64 loss: -1.0771875381469727
Batch 2/64 loss: -1.392542839050293
Batch 3/64 loss: -1.2731561660766602
Batch 4/64 loss: -1.3196792602539062
Batch 5/64 loss: -1.3512659072875977
Batch 6/64 loss: -1.3803596496582031
Batch 7/64 loss: -0.9429397583007812
Batch 8/64 loss: -1.3923606872558594
Batch 9/64 loss: -1.3545122146606445
Batch 10/64 loss: -1.2217988967895508
Batch 11/64 loss: -0.4491405487060547
Batch 12/64 loss: -1.546738624572754
Batch 13/64 loss: -1.3871736526489258
Batch 14/64 loss: -1.518092155456543
Batch 15/64 loss: -1.460829734802246
Batch 16/64 loss: -1.3549175262451172
Batch 17/64 loss: -1.4166698455810547
Batch 18/64 loss: -1.3260602951049805
Batch 19/64 loss: -1.2701215744018555
Batch 20/64 loss: -1.08819580078125
Batch 21/64 loss: -1.3248729705810547
Batch 22/64 loss: -1.3657636642456055
Batch 23/64 loss: -1.4956960678100586
Batch 24/64 loss: -1.4457550048828125
Batch 25/64 loss: -1.139836311340332
Batch 26/64 loss: -1.087000846862793
Batch 27/64 loss: -1.3085155487060547
Batch 28/64 loss: -1.0596923828125
Batch 29/64 loss: -0.7334146499633789
Batch 30/64 loss: -1.1371049880981445
Batch 31/64 loss: -1.1287755966186523
Batch 32/64 loss: -1.1064558029174805
Batch 33/64 loss: -1.0757379531860352
Batch 34/64 loss: -1.3141136169433594
Batch 35/64 loss: -1.178614616394043
Batch 36/64 loss: -1.32989501953125
Batch 37/64 loss: -1.443873405456543
Batch 38/64 loss: -1.0991172790527344
Batch 39/64 loss: -1.1718635559082031
Batch 40/64 loss: -1.3342466354370117
Batch 41/64 loss: -1.269327163696289
Batch 42/64 loss: -1.356231689453125
Batch 43/64 loss: -1.4524955749511719
Batch 44/64 loss: -0.9669904708862305
Batch 45/64 loss: -1.3165512084960938
Batch 46/64 loss: -0.8682022094726562
Batch 47/64 loss: -1.2355232238769531
Batch 48/64 loss: -0.5557594299316406
Batch 49/64 loss: -0.6922235488891602
Batch 50/64 loss: -1.1604700088500977
Batch 51/64 loss: -0.8617515563964844
Batch 52/64 loss: -1.008026123046875
Batch 53/64 loss: -1.0489416122436523
Batch 54/64 loss: -1.0769948959350586
Batch 55/64 loss: -0.6028881072998047
Batch 56/64 loss: -1.219747543334961
Batch 57/64 loss: -1.1561079025268555
Batch 58/64 loss: -0.7062854766845703
Batch 59/64 loss: -1.1112194061279297
Batch 60/64 loss: -1.2463550567626953
Batch 61/64 loss: -1.2611379623413086
Batch 62/64 loss: -1.4191274642944336
Batch 63/64 loss: -0.876338005065918
Batch 64/64 loss: -4.937778472900391
Epoch 121  Train loss: -1.2231547935336244  Val loss: -1.4767050857806123
Saving best model, epoch: 121
Epoch 122
-------------------------------
Batch 1/64 loss: -1.2365913391113281
Batch 2/64 loss: -1.2940387725830078
Batch 3/64 loss: -0.9219875335693359
Batch 4/64 loss: -1.0080747604370117
Batch 5/64 loss: -0.32248878479003906
Batch 6/64 loss: -1.416757583618164
Batch 7/64 loss: -1.4232730865478516
Batch 8/64 loss: -1.1302385330200195
Batch 9/64 loss: -1.3178033828735352
Batch 10/64 loss: -0.5861520767211914
Batch 11/64 loss: -1.1982393264770508
Batch 12/64 loss: -1.4283924102783203
Batch 13/64 loss: -1.3785734176635742
Batch 14/64 loss: -1.449275016784668
Batch 15/64 loss: -1.2913532257080078
Batch 16/64 loss: -1.114419937133789
Batch 17/64 loss: -1.5241222381591797
Batch 18/64 loss: -0.9615774154663086
Batch 19/64 loss: -1.2532720565795898
Batch 20/64 loss: -1.2461357116699219
Batch 21/64 loss: -0.7936935424804688
Batch 22/64 loss: -1.283808708190918
Batch 23/64 loss: -0.6867876052856445
Batch 24/64 loss: -0.9692974090576172
Batch 25/64 loss: -1.274129867553711
Batch 26/64 loss: -1.3086662292480469
Batch 27/64 loss: -1.0856142044067383
Batch 28/64 loss: -1.4339532852172852
Batch 29/64 loss: -1.1518516540527344
Batch 30/64 loss: -1.5045166015625
Batch 31/64 loss: -1.0185298919677734
Batch 32/64 loss: -0.8746042251586914
Batch 33/64 loss: -1.0278081893920898
Batch 34/64 loss: -1.1706819534301758
Batch 35/64 loss: -1.3508892059326172
Batch 36/64 loss: -1.2349023818969727
Batch 37/64 loss: -0.9671821594238281
Batch 38/64 loss: 0.011592864990234375
Batch 39/64 loss: -1.3333463668823242
Batch 40/64 loss: -1.2519006729125977
Batch 41/64 loss: -1.330845832824707
Batch 42/64 loss: -0.30572032928466797
Batch 43/64 loss: -1.2355985641479492
Batch 44/64 loss: -0.6586999893188477
Batch 45/64 loss: -1.069345474243164
Batch 46/64 loss: -0.8118982315063477
Batch 47/64 loss: -0.8565092086791992
Batch 48/64 loss: 0.4955873489379883
Batch 49/64 loss: -1.0171499252319336
Batch 50/64 loss: -0.882960319519043
Batch 51/64 loss: -1.053145408630371
Batch 52/64 loss: -0.8537607192993164
Batch 53/64 loss: -1.0139083862304688
Batch 54/64 loss: -1.2897024154663086
Batch 55/64 loss: -1.1912860870361328
Batch 56/64 loss: -0.5874004364013672
Batch 57/64 loss: -0.9788370132446289
Batch 58/64 loss: -0.974578857421875
Batch 59/64 loss: -1.2375030517578125
Batch 60/64 loss: -1.3361988067626953
Batch 61/64 loss: -0.42147254943847656
Batch 62/64 loss: -1.4634265899658203
Batch 63/64 loss: -1.1112794876098633
Batch 64/64 loss: -5.503383159637451
Epoch 122  Train loss: -1.1062982839696547  Val loss: -1.3364514091989839
Epoch 123
-------------------------------
Batch 1/64 loss: -1.116896629333496
Batch 2/64 loss: -1.3551387786865234
Batch 3/64 loss: -0.9944610595703125
Batch 4/64 loss: -1.2532520294189453
Batch 5/64 loss: -0.799285888671875
Batch 6/64 loss: -0.3896484375
Batch 7/64 loss: -1.4951515197753906
Batch 8/64 loss: -1.488591194152832
Batch 9/64 loss: -1.3217992782592773
Batch 10/64 loss: -1.5185976028442383
Batch 11/64 loss: -1.5286188125610352
Batch 12/64 loss: -0.8816308975219727
Batch 13/64 loss: -1.3473310470581055
Batch 14/64 loss: -0.7111263275146484
Batch 15/64 loss: -1.445556640625
Batch 16/64 loss: -0.6406755447387695
Batch 17/64 loss: -1.1688480377197266
Batch 18/64 loss: -0.4568309783935547
Batch 19/64 loss: -1.3018875122070312
Batch 20/64 loss: -1.2666101455688477
Batch 21/64 loss: -1.2549142837524414
Batch 22/64 loss: -1.2234563827514648
Batch 23/64 loss: -1.2778234481811523
Batch 24/64 loss: -1.1033191680908203
Batch 25/64 loss: -1.1701526641845703
Batch 26/64 loss: -1.0998172760009766
Batch 27/64 loss: -0.9145746231079102
Batch 28/64 loss: -0.9695644378662109
Batch 29/64 loss: -1.0787334442138672
Batch 30/64 loss: -0.9114456176757812
Batch 31/64 loss: -1.2359771728515625
Batch 32/64 loss: -1.481790542602539
Batch 33/64 loss: -1.2565698623657227
Batch 34/64 loss: -1.3088359832763672
Batch 35/64 loss: -1.21429443359375
Batch 36/64 loss: -1.1180543899536133
Batch 37/64 loss: -1.1735076904296875
Batch 38/64 loss: -1.3732948303222656
Batch 39/64 loss: -1.3081893920898438
Batch 40/64 loss: -1.2062921524047852
Batch 41/64 loss: -1.3584108352661133
Batch 42/64 loss: -0.8451957702636719
Batch 43/64 loss: -1.4490079879760742
Batch 44/64 loss: -0.47183704376220703
Batch 45/64 loss: -0.9604015350341797
Batch 46/64 loss: -1.2079524993896484
Batch 47/64 loss: -1.288839340209961
Batch 48/64 loss: -1.0230064392089844
Batch 49/64 loss: -1.3879833221435547
Batch 50/64 loss: -1.3885297775268555
Batch 51/64 loss: -1.3385066986083984
Batch 52/64 loss: -1.2526836395263672
Batch 53/64 loss: -1.4000825881958008
Batch 54/64 loss: -1.4152650833129883
Batch 55/64 loss: -1.2571659088134766
Batch 56/64 loss: -1.3713159561157227
Batch 57/64 loss: -1.1947717666625977
Batch 58/64 loss: -1.3481340408325195
Batch 59/64 loss: -1.1618309020996094
Batch 60/64 loss: -1.1766510009765625
Batch 61/64 loss: -1.2313385009765625
Batch 62/64 loss: -1.222508430480957
Batch 63/64 loss: -1.343454360961914
Batch 64/64 loss: -5.5358076095581055
Epoch 123  Train loss: -1.2299494163662779  Val loss: -1.351014573139833
Epoch 124
-------------------------------
Batch 1/64 loss: -1.199418067932129
Batch 2/64 loss: -1.3521032333374023
Batch 3/64 loss: -1.1463537216186523
Batch 4/64 loss: -1.2969694137573242
Batch 5/64 loss: -1.3651084899902344
Batch 6/64 loss: -1.1476116180419922
Batch 7/64 loss: -1.4721393585205078
Batch 8/64 loss: -1.425948143005371
Batch 9/64 loss: -1.2884597778320312
Batch 10/64 loss: -1.542435646057129
Batch 11/64 loss: -1.3649711608886719
Batch 12/64 loss: -1.5045766830444336
Batch 13/64 loss: -0.6904449462890625
Batch 14/64 loss: -1.3511533737182617
Batch 15/64 loss: -1.0851659774780273
Batch 16/64 loss: -1.357813835144043
Batch 17/64 loss: -0.7183561325073242
Batch 18/64 loss: -1.111785888671875
Batch 19/64 loss: -1.4985980987548828
Batch 20/64 loss: -1.350804328918457
Batch 21/64 loss: -1.376021385192871
Batch 22/64 loss: -1.448775291442871
Batch 23/64 loss: -0.9902257919311523
Batch 24/64 loss: -1.0422677993774414
Batch 25/64 loss: -1.1853675842285156
Batch 26/64 loss: -1.257685661315918
Batch 27/64 loss: -1.4773759841918945
Batch 28/64 loss: -1.1203536987304688
Batch 29/64 loss: -1.3859481811523438
Batch 30/64 loss: -1.3552398681640625
Batch 31/64 loss: -1.4040355682373047
Batch 32/64 loss: -1.402130126953125
Batch 33/64 loss: -1.1368350982666016
Batch 34/64 loss: -1.401932716369629
Batch 35/64 loss: -1.1856803894042969
Batch 36/64 loss: -0.7672595977783203
Batch 37/64 loss: -1.3218927383422852
Batch 38/64 loss: -0.5811729431152344
Batch 39/64 loss: -1.074091911315918
Batch 40/64 loss: -1.2615118026733398
Batch 41/64 loss: -1.228158950805664
Batch 42/64 loss: -1.361903190612793
Batch 43/64 loss: -1.2099065780639648
Batch 44/64 loss: -1.285008430480957
Batch 45/64 loss: -1.0323505401611328
Batch 46/64 loss: -1.2146320343017578
Batch 47/64 loss: -1.3505573272705078
Batch 48/64 loss: -1.1996688842773438
Batch 49/64 loss: -1.2582435607910156
Batch 50/64 loss: -0.9713954925537109
Batch 51/64 loss: -1.4353094100952148
Batch 52/64 loss: -1.0935468673706055
Batch 53/64 loss: -1.1071414947509766
Batch 54/64 loss: -0.6091117858886719
Batch 55/64 loss: -1.2180709838867188
Batch 56/64 loss: -0.8286476135253906
Batch 57/64 loss: -1.019205093383789
Batch 58/64 loss: -1.0721263885498047
Batch 59/64 loss: -0.7827014923095703
Batch 60/64 loss: -1.2718658447265625
Batch 61/64 loss: -1.1696205139160156
Batch 62/64 loss: -1.125199317932129
Batch 63/64 loss: -1.0689544677734375
Batch 64/64 loss: -5.649934768676758
Epoch 124  Train loss: -1.2485772450764974  Val loss: -1.3220098305403982
Epoch 125
-------------------------------
Batch 1/64 loss: -0.5921220779418945
Batch 2/64 loss: -1.2913942337036133
Batch 3/64 loss: -1.2254219055175781
Batch 4/64 loss: -1.3170032501220703
Batch 5/64 loss: -1.0756111145019531
Batch 6/64 loss: -0.9036588668823242
Batch 7/64 loss: -0.9309101104736328
Batch 8/64 loss: -1.5027656555175781
Batch 9/64 loss: -1.1671571731567383
Batch 10/64 loss: -1.1630887985229492
Batch 11/64 loss: -1.3321189880371094
Batch 12/64 loss: -1.3268070220947266
Batch 13/64 loss: -0.9179296493530273
Batch 14/64 loss: -1.048201560974121
Batch 15/64 loss: -1.1893062591552734
Batch 16/64 loss: -1.0638189315795898
Batch 17/64 loss: -0.6310720443725586
Batch 18/64 loss: -1.132436752319336
Batch 19/64 loss: -1.2335872650146484
Batch 20/64 loss: -1.375472068786621
Batch 21/64 loss: -1.3532562255859375
Batch 22/64 loss: -1.4219446182250977
Batch 23/64 loss: -1.3284339904785156
Batch 24/64 loss: -1.1887884140014648
Batch 25/64 loss: -1.183579444885254
Batch 26/64 loss: -1.1156864166259766
Batch 27/64 loss: -1.5238685607910156
Batch 28/64 loss: -1.3927068710327148
Batch 29/64 loss: -1.2519865036010742
Batch 30/64 loss: -1.1854496002197266
Batch 31/64 loss: -0.9225673675537109
Batch 32/64 loss: -1.2783260345458984
Batch 33/64 loss: -1.4165410995483398
Batch 34/64 loss: -1.1447124481201172
Batch 35/64 loss: -1.1667070388793945
Batch 36/64 loss: -1.4568328857421875
Batch 37/64 loss: -0.33480072021484375
Batch 38/64 loss: -1.445754051208496
Batch 39/64 loss: -0.8508224487304688
Batch 40/64 loss: -1.3273954391479492
Batch 41/64 loss: -1.2856836318969727
Batch 42/64 loss: -1.067281723022461
Batch 43/64 loss: -0.6790685653686523
Batch 44/64 loss: -1.2940101623535156
Batch 45/64 loss: -1.324061393737793
Batch 46/64 loss: -1.1379337310791016
Batch 47/64 loss: -1.4568815231323242
Batch 48/64 loss: -0.8197479248046875
Batch 49/64 loss: -1.4202299118041992
Batch 50/64 loss: -0.8181276321411133
Batch 51/64 loss: -1.457376480102539
Batch 52/64 loss: -1.4643049240112305
Batch 53/64 loss: -1.0724773406982422
Batch 54/64 loss: -1.5229501724243164
Batch 55/64 loss: -1.0751924514770508
Batch 56/64 loss: -0.9550304412841797
Batch 57/64 loss: -0.37192726135253906
Batch 58/64 loss: -1.201761245727539
Batch 59/64 loss: -1.4144153594970703
Batch 60/64 loss: -0.607396125793457
Batch 61/64 loss: -1.1627998352050781
Batch 62/64 loss: -1.1422443389892578
Batch 63/64 loss: -1.0852680206298828
Batch 64/64 loss: -5.548841953277588
Epoch 125  Train loss: -1.2032603226455987  Val loss: -1.1815330531588943
Epoch 126
-------------------------------
Batch 1/64 loss: -0.8906106948852539
Batch 2/64 loss: -0.7288188934326172
Batch 3/64 loss: -1.543147087097168
Batch 4/64 loss: -0.6073770523071289
Batch 5/64 loss: -1.1163415908813477
Batch 6/64 loss: -1.0917854309082031
Batch 7/64 loss: -1.309647560119629
Batch 8/64 loss: -0.36884117126464844
Batch 9/64 loss: -1.4039020538330078
Batch 10/64 loss: -0.7278785705566406
Batch 11/64 loss: -1.2202863693237305
Batch 12/64 loss: -1.4338836669921875
Batch 13/64 loss: -0.3476753234863281
Batch 14/64 loss: -1.0704517364501953
Batch 15/64 loss: -1.0484848022460938
Batch 16/64 loss: -1.3497257232666016
Batch 17/64 loss: -1.5220661163330078
Batch 18/64 loss: -1.2459163665771484
Batch 19/64 loss: -1.1379976272583008
Batch 20/64 loss: -1.2483749389648438
Batch 21/64 loss: -1.2858524322509766
Batch 22/64 loss: -0.8465795516967773
Batch 23/64 loss: -1.1397829055786133
Batch 24/64 loss: -0.7702217102050781
Batch 25/64 loss: -1.2810964584350586
Batch 26/64 loss: -1.0304527282714844
Batch 27/64 loss: -0.34993743896484375
Batch 28/64 loss: -1.301112174987793
Batch 29/64 loss: -1.087860107421875
Batch 30/64 loss: -0.9157419204711914
Batch 31/64 loss: -1.19476318359375
Batch 32/64 loss: -1.3638105392456055
Batch 33/64 loss: -1.264139175415039
Batch 34/64 loss: -1.1501598358154297
Batch 35/64 loss: -1.3322620391845703
Batch 36/64 loss: -1.2867164611816406
Batch 37/64 loss: -1.2927055358886719
Batch 38/64 loss: -1.3617219924926758
Batch 39/64 loss: -1.5882673263549805
Batch 40/64 loss: -1.5811262130737305
Batch 41/64 loss: -1.5377445220947266
Batch 42/64 loss: 0.5716962814331055
Batch 43/64 loss: -1.3977537155151367
Batch 44/64 loss: -1.3524866104125977
Batch 45/64 loss: -1.5412511825561523
Batch 46/64 loss: -0.6095714569091797
Batch 47/64 loss: -1.127486228942871
Batch 48/64 loss: -1.2045011520385742
Batch 49/64 loss: -0.3591136932373047
Batch 50/64 loss: -1.204294204711914
Batch 51/64 loss: -0.8440876007080078
Batch 52/64 loss: -0.9413356781005859
Batch 53/64 loss: -1.319819450378418
Batch 54/64 loss: -1.3009166717529297
Batch 55/64 loss: -0.596562385559082
Batch 56/64 loss: -1.066375732421875
Batch 57/64 loss: -0.018474578857421875
Batch 58/64 loss: -0.7182855606079102
Batch 59/64 loss: -1.3303041458129883
Batch 60/64 loss: -1.081289291381836
Batch 61/64 loss: -0.5491628646850586
Batch 62/64 loss: -0.9310016632080078
Batch 63/64 loss: -1.1875829696655273
Batch 64/64 loss: -5.0625200271606445
Epoch 126  Train loss: -1.102464589885637  Val loss: -0.8532484913200038
Epoch 127
-------------------------------
Batch 1/64 loss: -1.184370994567871
Batch 2/64 loss: -1.1495771408081055
Batch 3/64 loss: -1.0042409896850586
Batch 4/64 loss: -1.0173349380493164
Batch 5/64 loss: -0.8854541778564453
Batch 6/64 loss: -0.44690895080566406
Batch 7/64 loss: -1.2468500137329102
Batch 8/64 loss: -1.2554407119750977
Batch 9/64 loss: -0.6985073089599609
Batch 10/64 loss: -1.029282569885254
Batch 11/64 loss: -1.2277898788452148
Batch 12/64 loss: -1.0779037475585938
Batch 13/64 loss: -0.8034839630126953
Batch 14/64 loss: -1.4582481384277344
Batch 15/64 loss: -0.7164039611816406
Batch 16/64 loss: -1.3991146087646484
Batch 17/64 loss: -1.0082244873046875
Batch 18/64 loss: -1.1027765274047852
Batch 19/64 loss: -1.272944450378418
Batch 20/64 loss: -1.127939224243164
Batch 21/64 loss: -1.1728954315185547
Batch 22/64 loss: -1.0869770050048828
Batch 23/64 loss: -0.09981727600097656
Batch 24/64 loss: -1.0640859603881836
Batch 25/64 loss: -0.9703693389892578
Batch 26/64 loss: -1.2883272171020508
Batch 27/64 loss: -1.349151611328125
Batch 28/64 loss: -0.5229454040527344
Batch 29/64 loss: -0.9896249771118164
Batch 30/64 loss: -1.1453418731689453
Batch 31/64 loss: -1.3053712844848633
Batch 32/64 loss: -0.5453376770019531
Batch 33/64 loss: -1.4858570098876953
Batch 34/64 loss: -1.073709487915039
Batch 35/64 loss: -0.7428007125854492
Batch 36/64 loss: -1.3203439712524414
Batch 37/64 loss: -1.283843994140625
Batch 38/64 loss: -0.9937953948974609
Batch 39/64 loss: -1.3051605224609375
Batch 40/64 loss: -1.2901277542114258
Batch 41/64 loss: -0.7753725051879883
Batch 42/64 loss: -1.301926612854004
Batch 43/64 loss: -1.3244504928588867
Batch 44/64 loss: -1.221343994140625
Batch 45/64 loss: -0.8585672378540039
Batch 46/64 loss: -1.2934494018554688
Batch 47/64 loss: -1.2169113159179688
Batch 48/64 loss: -1.2326574325561523
Batch 49/64 loss: -0.3658008575439453
Batch 50/64 loss: -0.6599578857421875
Batch 51/64 loss: -0.9506893157958984
Batch 52/64 loss: -1.3276777267456055
Batch 53/64 loss: -1.368119239807129
Batch 54/64 loss: -1.2420196533203125
Batch 55/64 loss: -1.1827268600463867
Batch 56/64 loss: -0.04626750946044922
Batch 57/64 loss: -1.320760726928711
Batch 58/64 loss: -1.0407161712646484
Batch 59/64 loss: -1.2393217086791992
Batch 60/64 loss: -1.1262645721435547
Batch 61/64 loss: -1.0715255737304688
Batch 62/64 loss: -1.248702049255371
Batch 63/64 loss: -0.8598756790161133
Batch 64/64 loss: -4.3170061111450195
Epoch 127  Train loss: -1.0927300359688552  Val loss: -1.25728233573363
Epoch 128
-------------------------------
Batch 1/64 loss: -1.4808349609375
Batch 2/64 loss: -1.3306074142456055
Batch 3/64 loss: -1.2346858978271484
Batch 4/64 loss: -1.3842334747314453
Batch 5/64 loss: -1.1325616836547852
Batch 6/64 loss: -1.3515138626098633
Batch 7/64 loss: -1.0743227005004883
Batch 8/64 loss: -0.6365470886230469
Batch 9/64 loss: -1.3848075866699219
Batch 10/64 loss: -0.7700023651123047
Batch 11/64 loss: -1.0986804962158203
Batch 12/64 loss: -1.2469196319580078
Batch 13/64 loss: -0.6658601760864258
Batch 14/64 loss: -1.2246952056884766
Batch 15/64 loss: -0.22702312469482422
Batch 16/64 loss: 0.24146366119384766
Batch 17/64 loss: -1.298445701599121
Batch 18/64 loss: -0.9592571258544922
Batch 19/64 loss: -1.2971277236938477
Batch 20/64 loss: -1.378565788269043
Batch 21/64 loss: -0.3537302017211914
Batch 22/64 loss: -1.1638784408569336
Batch 23/64 loss: -0.44431495666503906
Batch 24/64 loss: -0.8349227905273438
Batch 25/64 loss: -1.4930143356323242
Batch 26/64 loss: -0.9376735687255859
Batch 27/64 loss: -1.270956039428711
Batch 28/64 loss: -0.9997777938842773
Batch 29/64 loss: -1.0200395584106445
Batch 30/64 loss: -1.3707952499389648
Batch 31/64 loss: -1.2883577346801758
Batch 32/64 loss: -1.0831422805786133
Batch 33/64 loss: -1.4499902725219727
Batch 34/64 loss: -1.1435441970825195
Batch 35/64 loss: -1.244441032409668
Batch 36/64 loss: -0.9193525314331055
Batch 37/64 loss: -0.5032386779785156
Batch 38/64 loss: -0.4049959182739258
Batch 39/64 loss: -1.4162511825561523
Batch 40/64 loss: -1.0250349044799805
Batch 41/64 loss: -1.3259315490722656
Batch 42/64 loss: -1.3760747909545898
Batch 43/64 loss: -1.2874784469604492
Batch 44/64 loss: -1.412210464477539
Batch 45/64 loss: -1.5150213241577148
Batch 46/64 loss: -1.255082130432129
Batch 47/64 loss: -1.536717414855957
Batch 48/64 loss: -1.1874666213989258
Batch 49/64 loss: -1.217585563659668
Batch 50/64 loss: -1.5689830780029297
Batch 51/64 loss: -1.345658302307129
Batch 52/64 loss: -1.2014045715332031
Batch 53/64 loss: -1.316859245300293
Batch 54/64 loss: -1.4470643997192383
Batch 55/64 loss: -1.4429149627685547
Batch 56/64 loss: -1.5538520812988281
Batch 57/64 loss: -0.8279571533203125
Batch 58/64 loss: -1.0420398712158203
Batch 59/64 loss: -1.17919921875
Batch 60/64 loss: -1.6151094436645508
Batch 61/64 loss: -1.2039117813110352
Batch 62/64 loss: -1.1294546127319336
Batch 63/64 loss: -1.5704851150512695
Batch 64/64 loss: -5.692526340484619
Epoch 128  Train loss: -1.1942045006097533  Val loss: -1.5298893459883751
Saving best model, epoch: 128
Epoch 129
-------------------------------
Batch 1/64 loss: -1.3614397048950195
Batch 2/64 loss: -0.8738775253295898
Batch 3/64 loss: -1.1119709014892578
Batch 4/64 loss: -1.268223762512207
Batch 5/64 loss: -1.2197723388671875
Batch 6/64 loss: -1.213796615600586
Batch 7/64 loss: -1.206502914428711
Batch 8/64 loss: -1.1705751419067383
Batch 9/64 loss: -1.4163503646850586
Batch 10/64 loss: -1.1369075775146484
Batch 11/64 loss: -0.8320913314819336
Batch 12/64 loss: -1.1563215255737305
Batch 13/64 loss: -1.1667966842651367
Batch 14/64 loss: -1.112863540649414
Batch 15/64 loss: -1.4698114395141602
Batch 16/64 loss: -1.3294401168823242
Batch 17/64 loss: -1.3810129165649414
Batch 18/64 loss: -1.4896736145019531
Batch 19/64 loss: -1.5249271392822266
Batch 20/64 loss: -1.3503074645996094
Batch 21/64 loss: -1.6384553909301758
Batch 22/64 loss: -1.5439014434814453
Batch 23/64 loss: -1.3692436218261719
Batch 24/64 loss: -0.9223823547363281
Batch 25/64 loss: -0.8476352691650391
Batch 26/64 loss: -1.1498279571533203
Batch 27/64 loss: -0.9125156402587891
Batch 28/64 loss: -1.2163772583007812
Batch 29/64 loss: -1.6033649444580078
Batch 30/64 loss: -1.3452863693237305
Batch 31/64 loss: -1.2194442749023438
Batch 32/64 loss: -1.06396484375
Batch 33/64 loss: -1.3179149627685547
Batch 34/64 loss: -1.3229341506958008
Batch 35/64 loss: -0.3764028549194336
Batch 36/64 loss: -0.8116846084594727
Batch 37/64 loss: -0.5534982681274414
Batch 38/64 loss: -0.0669870376586914
Batch 39/64 loss: -0.5542993545532227
Batch 40/64 loss: -1.0716667175292969
Batch 41/64 loss: -1.443638801574707
Batch 42/64 loss: -1.2372112274169922
Batch 43/64 loss: -1.3547792434692383
Batch 44/64 loss: -1.2505607604980469
Batch 45/64 loss: -1.2913837432861328
Batch 46/64 loss: -1.427520751953125
Batch 47/64 loss: -1.2296533584594727
Batch 48/64 loss: -1.4257946014404297
Batch 49/64 loss: -1.310399055480957
Batch 50/64 loss: -1.5587549209594727
Batch 51/64 loss: -1.2345390319824219
Batch 52/64 loss: -1.2254867553710938
Batch 53/64 loss: -1.0282907485961914
Batch 54/64 loss: -1.353459358215332
Batch 55/64 loss: -1.5599899291992188
Batch 56/64 loss: -0.9234638214111328
Batch 57/64 loss: -1.0214576721191406
Batch 58/64 loss: -1.0028257369995117
Batch 59/64 loss: -0.7090444564819336
Batch 60/64 loss: -1.2858800888061523
Batch 61/64 loss: -1.407679557800293
Batch 62/64 loss: -1.4852190017700195
Batch 63/64 loss: -1.3304977416992188
Batch 64/64 loss: -5.4218244552612305
Epoch 129  Train loss: -1.2370878219604493  Val loss: -1.402999602642256
Epoch 130
-------------------------------
Batch 1/64 loss: -1.3520755767822266
Batch 2/64 loss: -1.5286998748779297
Batch 3/64 loss: -1.2187366485595703
Batch 4/64 loss: -1.4168624877929688
Batch 5/64 loss: -1.0598974227905273
Batch 6/64 loss: -1.2008018493652344
Batch 7/64 loss: -1.487950325012207
Batch 8/64 loss: -1.5229597091674805
Batch 9/64 loss: -1.0670890808105469
Batch 10/64 loss: -1.4516477584838867
Batch 11/64 loss: -1.532196044921875
Batch 12/64 loss: -1.4704418182373047
Batch 13/64 loss: -1.3145160675048828
Batch 14/64 loss: -1.3735389709472656
Batch 15/64 loss: -1.3479681015014648
Batch 16/64 loss: -1.3104305267333984
Batch 17/64 loss: -1.4390974044799805
Batch 18/64 loss: -1.380864143371582
Batch 19/64 loss: -1.481184959411621
Batch 20/64 loss: -0.7334918975830078
Batch 21/64 loss: -1.1892995834350586
Batch 22/64 loss: -1.2730979919433594
Batch 23/64 loss: -1.3889617919921875
Batch 24/64 loss: -1.2575035095214844
Batch 25/64 loss: -1.4170112609863281
Batch 26/64 loss: -1.3861827850341797
Batch 27/64 loss: -0.3316164016723633
Batch 28/64 loss: -1.4380769729614258
Batch 29/64 loss: -1.5251731872558594
Batch 30/64 loss: -1.558497428894043
Batch 31/64 loss: -1.1127490997314453
Batch 32/64 loss: -1.5249557495117188
Batch 33/64 loss: -1.5049371719360352
Batch 34/64 loss: -1.4940366744995117
Batch 35/64 loss: -1.0342111587524414
Batch 36/64 loss: -1.3218517303466797
Batch 37/64 loss: -1.4310340881347656
Batch 38/64 loss: -1.396982192993164
Batch 39/64 loss: -1.4746665954589844
Batch 40/64 loss: -1.5798702239990234
Batch 41/64 loss: -1.5416498184204102
Batch 42/64 loss: -1.1837835311889648
Batch 43/64 loss: -1.3533782958984375
Batch 44/64 loss: -1.4030876159667969
Batch 45/64 loss: -1.5186595916748047
Batch 46/64 loss: -1.2119531631469727
Batch 47/64 loss: -1.5440120697021484
Batch 48/64 loss: -0.187744140625
Batch 49/64 loss: -1.04364013671875
Batch 50/64 loss: -0.9742527008056641
Batch 51/64 loss: -1.356180191040039
Batch 52/64 loss: -1.3855609893798828
Batch 53/64 loss: -1.3893308639526367
Batch 54/64 loss: -1.6278352737426758
Batch 55/64 loss: -1.34674072265625
Batch 56/64 loss: -1.3964881896972656
Batch 57/64 loss: -1.392599105834961
Batch 58/64 loss: -1.6345577239990234
Batch 59/64 loss: -1.6364946365356445
Batch 60/64 loss: -0.8192243576049805
Batch 61/64 loss: -1.4340620040893555
Batch 62/64 loss: -1.4537887573242188
Batch 63/64 loss: -1.062051773071289
Batch 64/64 loss: -5.695404052734375
Epoch 130  Train loss: -1.3725458032944624  Val loss: -1.3786125576373227
Epoch 131
-------------------------------
Batch 1/64 loss: -1.1546030044555664
Batch 2/64 loss: -1.4287223815917969
Batch 3/64 loss: -1.5246047973632812
Batch 4/64 loss: -1.4625329971313477
Batch 5/64 loss: -1.2510309219360352
Batch 6/64 loss: -1.6711158752441406
Batch 7/64 loss: -0.7096652984619141
Batch 8/64 loss: -0.7260932922363281
Batch 9/64 loss: -1.4664440155029297
Batch 10/64 loss: -1.567387580871582
Batch 11/64 loss: -1.4770917892456055
Batch 12/64 loss: -1.3541498184204102
Batch 13/64 loss: -0.6232805252075195
Batch 14/64 loss: -1.1218271255493164
Batch 15/64 loss: -0.9698095321655273
Batch 16/64 loss: -1.3082590103149414
Batch 17/64 loss: -1.3360309600830078
Batch 18/64 loss: -1.3326101303100586
Batch 19/64 loss: -1.3864316940307617
Batch 20/64 loss: -0.9402303695678711
Batch 21/64 loss: -1.4073514938354492
Batch 22/64 loss: -0.039542198181152344
Batch 23/64 loss: -1.5806102752685547
Batch 24/64 loss: -1.5418462753295898
Batch 25/64 loss: -1.5905027389526367
Batch 26/64 loss: -1.5723552703857422
Batch 27/64 loss: -1.324014663696289
Batch 28/64 loss: -1.1982755661010742
Batch 29/64 loss: -1.5942926406860352
Batch 30/64 loss: -1.5002994537353516
Batch 31/64 loss: -0.9033966064453125
Batch 32/64 loss: -1.3490571975708008
Batch 33/64 loss: -1.3369827270507812
Batch 34/64 loss: -1.277470588684082
Batch 35/64 loss: -1.4363880157470703
Batch 36/64 loss: -1.497629165649414
Batch 37/64 loss: -1.6023797988891602
Batch 38/64 loss: -1.6077280044555664
Batch 39/64 loss: -1.063929557800293
Batch 40/64 loss: -1.4627056121826172
Batch 41/64 loss: -1.0809640884399414
Batch 42/64 loss: -1.4062623977661133
Batch 43/64 loss: -0.9701423645019531
Batch 44/64 loss: -0.7979555130004883
Batch 45/64 loss: -0.968597412109375
Batch 46/64 loss: -1.4365215301513672
Batch 47/64 loss: -1.6496057510375977
Batch 48/64 loss: -1.4111289978027344
Batch 49/64 loss: -1.5632009506225586
Batch 50/64 loss: -1.519017219543457
Batch 51/64 loss: -1.3436107635498047
Batch 52/64 loss: -1.1443471908569336
Batch 53/64 loss: -1.4629993438720703
Batch 54/64 loss: -1.433323860168457
Batch 55/64 loss: -1.422968864440918
Batch 56/64 loss: -0.8019075393676758
Batch 57/64 loss: -1.4058923721313477
Batch 58/64 loss: -1.0863409042358398
Batch 59/64 loss: -1.570291519165039
Batch 60/64 loss: -1.6974210739135742
Batch 61/64 loss: -1.4322566986083984
Batch 62/64 loss: -1.6682233810424805
Batch 63/64 loss: -1.5661125183105469
Batch 64/64 loss: -5.491307258605957
Epoch 131  Train loss: -1.359313751669491  Val loss: -1.5775304446925003
Saving best model, epoch: 131
Epoch 132
-------------------------------
Batch 1/64 loss: -1.1342029571533203
Batch 2/64 loss: -1.3402976989746094
Batch 3/64 loss: -1.3207149505615234
Batch 4/64 loss: -1.3394107818603516
Batch 5/64 loss: -1.7002382278442383
Batch 6/64 loss: -0.5411777496337891
Batch 7/64 loss: -1.3159818649291992
Batch 8/64 loss: -1.2240009307861328
Batch 9/64 loss: -1.7162399291992188
Batch 10/64 loss: -1.3386430740356445
Batch 11/64 loss: -1.4736566543579102
Batch 12/64 loss: -1.3761711120605469
Batch 13/64 loss: -1.1099605560302734
Batch 14/64 loss: -0.9835081100463867
Batch 15/64 loss: -1.3515052795410156
Batch 16/64 loss: -1.2983732223510742
Batch 17/64 loss: -1.1782026290893555
Batch 18/64 loss: -1.4972620010375977
Batch 19/64 loss: -1.1773548126220703
Batch 20/64 loss: -0.4455118179321289
Batch 21/64 loss: -1.4745702743530273
Batch 22/64 loss: -1.110600471496582
Batch 23/64 loss: -0.1391315460205078
Batch 24/64 loss: -1.1604795455932617
Batch 25/64 loss: -1.6075239181518555
Batch 26/64 loss: -1.2460966110229492
Batch 27/64 loss: -1.39947509765625
Batch 28/64 loss: -1.2867088317871094
Batch 29/64 loss: -1.2382841110229492
Batch 30/64 loss: -1.5442228317260742
Batch 31/64 loss: -1.6489191055297852
Batch 32/64 loss: -0.6158628463745117
Batch 33/64 loss: -1.2525367736816406
Batch 34/64 loss: -0.8747625350952148
Batch 35/64 loss: -1.4327964782714844
Batch 36/64 loss: -1.177973747253418
Batch 37/64 loss: -0.9705791473388672
Batch 38/64 loss: -1.067514419555664
Batch 39/64 loss: -1.3941984176635742
Batch 40/64 loss: -1.430821418762207
Batch 41/64 loss: -1.1069927215576172
Batch 42/64 loss: -1.293313980102539
Batch 43/64 loss: -1.0578126907348633
Batch 44/64 loss: -0.2537546157836914
Batch 45/64 loss: -1.3814964294433594
Batch 46/64 loss: -1.4667243957519531
Batch 47/64 loss: -0.7639884948730469
Batch 48/64 loss: -1.022873878479004
Batch 49/64 loss: -0.9665431976318359
Batch 50/64 loss: -1.3905620574951172
Batch 51/64 loss: -1.3264808654785156
Batch 52/64 loss: -1.070784568786621
Batch 53/64 loss: -1.292098045349121
Batch 54/64 loss: -1.2595691680908203
Batch 55/64 loss: -0.7916650772094727
Batch 56/64 loss: -1.4287424087524414
Batch 57/64 loss: -1.2459087371826172
Batch 58/64 loss: -1.2396774291992188
Batch 59/64 loss: -1.0165948867797852
Batch 60/64 loss: -1.328730583190918
Batch 61/64 loss: -0.840977668762207
Batch 62/64 loss: -1.4034433364868164
Batch 63/64 loss: -1.3927898406982422
Batch 64/64 loss: -5.712935924530029
Epoch 132  Train loss: -1.2480266589744418  Val loss: -1.4308779608343065
Epoch 133
-------------------------------
Batch 1/64 loss: -1.2966642379760742
Batch 2/64 loss: -1.0197248458862305
Batch 3/64 loss: -1.2155818939208984
Batch 4/64 loss: -0.8629369735717773
Batch 5/64 loss: -1.3643245697021484
Batch 6/64 loss: -1.450037956237793
Batch 7/64 loss: -1.466059684753418
Batch 8/64 loss: -1.3775463104248047
Batch 9/64 loss: -1.4484844207763672
Batch 10/64 loss: -1.0579023361206055
Batch 11/64 loss: -0.7025289535522461
Batch 12/64 loss: -1.2929134368896484
Batch 13/64 loss: -1.4269065856933594
Batch 14/64 loss: -1.1661434173583984
Batch 15/64 loss: -1.1770782470703125
Batch 16/64 loss: -1.341893196105957
Batch 17/64 loss: -0.886754035949707
Batch 18/64 loss: -1.3784799575805664
Batch 19/64 loss: -1.316823959350586
Batch 20/64 loss: -0.6457633972167969
Batch 21/64 loss: -0.7111740112304688
Batch 22/64 loss: -1.4226188659667969
Batch 23/64 loss: -1.2264156341552734
Batch 24/64 loss: -1.4369697570800781
Batch 25/64 loss: -1.5564451217651367
Batch 26/64 loss: -1.0166091918945312
Batch 27/64 loss: -1.254216194152832
Batch 28/64 loss: -1.2489404678344727
Batch 29/64 loss: -1.5199451446533203
Batch 30/64 loss: -1.3891839981079102
Batch 31/64 loss: -1.3403301239013672
Batch 32/64 loss: -1.0549039840698242
Batch 33/64 loss: -1.3372764587402344
Batch 34/64 loss: -1.4933853149414062
Batch 35/64 loss: -1.3981618881225586
Batch 36/64 loss: -1.028407096862793
Batch 37/64 loss: -1.441568374633789
Batch 38/64 loss: -1.096116065979004
Batch 39/64 loss: -1.254465103149414
Batch 40/64 loss: -1.1610479354858398
Batch 41/64 loss: -1.1148481369018555
Batch 42/64 loss: -1.3798770904541016
Batch 43/64 loss: -1.489821434020996
Batch 44/64 loss: -1.2148122787475586
Batch 45/64 loss: -0.9376153945922852
Batch 46/64 loss: -1.6592578887939453
Batch 47/64 loss: -1.6138839721679688
Batch 48/64 loss: -1.2641735076904297
Batch 49/64 loss: -1.398026466369629
Batch 50/64 loss: -1.1260919570922852
Batch 51/64 loss: -1.5479021072387695
Batch 52/64 loss: -0.8301362991333008
Batch 53/64 loss: -1.5174427032470703
Batch 54/64 loss: -1.0887699127197266
Batch 55/64 loss: -0.930424690246582
Batch 56/64 loss: -1.0533218383789062
Batch 57/64 loss: -1.419663429260254
Batch 58/64 loss: -1.0338926315307617
Batch 59/64 loss: -0.7775335311889648
Batch 60/64 loss: -0.6257638931274414
Batch 61/64 loss: -1.2027196884155273
Batch 62/64 loss: -0.8905735015869141
Batch 63/64 loss: 1.2880935668945312
Batch 64/64 loss: -5.047816276550293
Epoch 133  Train loss: -1.2219145120358934  Val loss: -0.14894944286018713
Epoch 134
-------------------------------
Batch 1/64 loss: -0.3942537307739258
Batch 2/64 loss: 0.4786415100097656
Batch 3/64 loss: -0.5788288116455078
Batch 4/64 loss: 1.210336685180664
Batch 5/64 loss: -0.3805551528930664
Batch 6/64 loss: -0.6576223373413086
Batch 7/64 loss: -1.106119155883789
Batch 8/64 loss: -1.072758674621582
Batch 9/64 loss: -0.10203170776367188
Batch 10/64 loss: -0.6678895950317383
Batch 11/64 loss: -1.2579412460327148
Batch 12/64 loss: 0.6798229217529297
Batch 13/64 loss: -0.8584995269775391
Batch 14/64 loss: -1.0303535461425781
Batch 15/64 loss: -0.42106056213378906
Batch 16/64 loss: -0.39591121673583984
Batch 17/64 loss: -1.3386783599853516
Batch 18/64 loss: -0.9597444534301758
Batch 19/64 loss: -0.6023321151733398
Batch 20/64 loss: -1.3201370239257812
Batch 21/64 loss: -1.1295061111450195
Batch 22/64 loss: -0.8264665603637695
Batch 23/64 loss: -0.49233436584472656
Batch 24/64 loss: -1.211740493774414
Batch 25/64 loss: -0.8928260803222656
Batch 26/64 loss: -1.0256948471069336
Batch 27/64 loss: -1.1280784606933594
Batch 28/64 loss: -0.17141246795654297
Batch 29/64 loss: -1.3093042373657227
Batch 30/64 loss: -0.8805503845214844
Batch 31/64 loss: -0.6058511734008789
Batch 32/64 loss: -1.1834030151367188
Batch 33/64 loss: -1.3073158264160156
Batch 34/64 loss: -1.0125112533569336
Batch 35/64 loss: -0.8930587768554688
Batch 36/64 loss: 0.005345344543457031
Batch 37/64 loss: 0.03213310241699219
Batch 38/64 loss: -1.4839534759521484
Batch 39/64 loss: -1.1798200607299805
Batch 40/64 loss: -0.9399957656860352
Batch 41/64 loss: -1.1345176696777344
Batch 42/64 loss: -0.8975868225097656
Batch 43/64 loss: -1.3334522247314453
Batch 44/64 loss: -1.0585193634033203
Batch 45/64 loss: -0.8903131484985352
Batch 46/64 loss: -1.0523672103881836
Batch 47/64 loss: -1.1227025985717773
Batch 48/64 loss: -0.8082847595214844
Batch 49/64 loss: -1.1714401245117188
Batch 50/64 loss: -0.7027750015258789
Batch 51/64 loss: -0.5106639862060547
Batch 52/64 loss: -1.1730165481567383
Batch 53/64 loss: -0.1615762710571289
Batch 54/64 loss: -1.009939193725586
Batch 55/64 loss: -1.3273000717163086
Batch 56/64 loss: -1.458847999572754
Batch 57/64 loss: -0.23772621154785156
Batch 58/64 loss: -1.415848731994629
Batch 59/64 loss: -1.0550899505615234
Batch 60/64 loss: -1.130354881286621
Batch 61/64 loss: -0.4279203414916992
Batch 62/64 loss: -1.5284175872802734
Batch 63/64 loss: 1.1825504302978516
Batch 64/64 loss: -5.5403523445129395
Epoch 134  Train loss: -0.8312727142782772  Val loss: -1.0165692096723313
Epoch 135
-------------------------------
Batch 1/64 loss: -0.8422145843505859
Batch 2/64 loss: -1.2510929107666016
Batch 3/64 loss: -1.3084888458251953
Batch 4/64 loss: -0.9148769378662109
Batch 5/64 loss: -1.2055740356445312
Batch 6/64 loss: -0.7659463882446289
Batch 7/64 loss: -1.1717138290405273
Batch 8/64 loss: -1.4545516967773438
Batch 9/64 loss: -0.5074014663696289
Batch 10/64 loss: -1.2177009582519531
Batch 11/64 loss: -1.3882665634155273
Batch 12/64 loss: -0.5320281982421875
Batch 13/64 loss: -1.3958940505981445
Batch 14/64 loss: -1.3048515319824219
Batch 15/64 loss: -1.0276613235473633
Batch 16/64 loss: -1.4467058181762695
Batch 17/64 loss: -0.33728790283203125
Batch 18/64 loss: 0.2155447006225586
Batch 19/64 loss: -0.24930667877197266
Batch 20/64 loss: -1.0202341079711914
Batch 21/64 loss: -0.2152261734008789
Batch 22/64 loss: 1.445023536682129
Batch 23/64 loss: -0.7328090667724609
Batch 24/64 loss: 0.022386550903320312
Batch 25/64 loss: -0.8401737213134766
Batch 26/64 loss: -0.15518474578857422
Batch 27/64 loss: -0.05774116516113281
Batch 28/64 loss: -0.9491395950317383
Batch 29/64 loss: -0.6543693542480469
Batch 30/64 loss: 0.7446231842041016
Batch 31/64 loss: -1.0644302368164062
Batch 32/64 loss: -0.5259857177734375
Batch 33/64 loss: -0.9464855194091797
Batch 34/64 loss: -0.13649463653564453
Batch 35/64 loss: 0.4083375930786133
Batch 36/64 loss: -0.9547863006591797
Batch 37/64 loss: -1.2906885147094727
Batch 38/64 loss: -0.48415565490722656
Batch 39/64 loss: -0.6637020111083984
Batch 40/64 loss: -0.9512414932250977
Batch 41/64 loss: -0.48439884185791016
Batch 42/64 loss: -0.7667531967163086
Batch 43/64 loss: -0.9975299835205078
Batch 44/64 loss: 0.3016023635864258
Batch 45/64 loss: -0.2675323486328125
Batch 46/64 loss: -0.45459938049316406
Batch 47/64 loss: -0.5542135238647461
Batch 48/64 loss: -0.9548883438110352
Batch 49/64 loss: -0.7270374298095703
Batch 50/64 loss: -1.3529090881347656
Batch 51/64 loss: -0.5228309631347656
Batch 52/64 loss: -0.12710952758789062
Batch 53/64 loss: -0.8565568923950195
Batch 54/64 loss: -0.7152309417724609
Batch 55/64 loss: -0.5749568939208984
Batch 56/64 loss: 0.5286293029785156
Batch 57/64 loss: -1.0718746185302734
Batch 58/64 loss: -0.7275686264038086
Batch 59/64 loss: -0.9312286376953125
Batch 60/64 loss: -0.8740434646606445
Batch 61/64 loss: -1.1871347427368164
Batch 62/64 loss: -0.5824222564697266
Batch 63/64 loss: -0.8072519302368164
Batch 64/64 loss: -5.690385818481445
Epoch 135  Train loss: -0.7232019686231426  Val loss: -1.0614789195896424
Epoch 136
-------------------------------
Batch 1/64 loss: -0.4388761520385742
Batch 2/64 loss: -1.0325298309326172
Batch 3/64 loss: -1.1991920471191406
Batch 4/64 loss: -1.3794069290161133
Batch 5/64 loss: -0.8622312545776367
Batch 6/64 loss: -1.0818986892700195
Batch 7/64 loss: -1.1681022644042969
Batch 8/64 loss: -1.259537696838379
Batch 9/64 loss: -0.9556131362915039
Batch 10/64 loss: -0.8344135284423828
Batch 11/64 loss: -0.7077159881591797
Batch 12/64 loss: -1.3467321395874023
Batch 13/64 loss: 0.5806608200073242
Batch 14/64 loss: -1.461226463317871
Batch 15/64 loss: -1.2508764266967773
Batch 16/64 loss: -1.3174304962158203
Batch 17/64 loss: -0.5774784088134766
Batch 18/64 loss: -0.7530498504638672
Batch 19/64 loss: -1.456873893737793
Batch 20/64 loss: -1.1770172119140625
Batch 21/64 loss: -0.9317922592163086
Batch 22/64 loss: -1.3922595977783203
Batch 23/64 loss: -0.6275291442871094
Batch 24/64 loss: -0.7820262908935547
Batch 25/64 loss: 0.31831836700439453
Batch 26/64 loss: -0.608220100402832
Batch 27/64 loss: -1.1011524200439453
Batch 28/64 loss: -0.9553003311157227
Batch 29/64 loss: -0.4204893112182617
Batch 30/64 loss: -0.9196920394897461
Batch 31/64 loss: -0.7532997131347656
Batch 32/64 loss: -1.0476799011230469
Batch 33/64 loss: -0.6359643936157227
Batch 34/64 loss: -0.817840576171875
Batch 35/64 loss: 0.31192493438720703
Batch 36/64 loss: -1.2037487030029297
Batch 37/64 loss: -0.9143152236938477
Batch 38/64 loss: -1.0599164962768555
Batch 39/64 loss: -1.3093128204345703
Batch 40/64 loss: -0.9187068939208984
Batch 41/64 loss: -0.7302474975585938
Batch 42/64 loss: -1.0230169296264648
Batch 43/64 loss: -1.2674407958984375
Batch 44/64 loss: -1.1854791641235352
Batch 45/64 loss: 1.3274879455566406
Batch 46/64 loss: -0.6416072845458984
Batch 47/64 loss: -0.5467195510864258
Batch 48/64 loss: -1.3288688659667969
Batch 49/64 loss: -0.8639764785766602
Batch 50/64 loss: -0.7828130722045898
Batch 51/64 loss: -0.8712348937988281
Batch 52/64 loss: -0.5241498947143555
Batch 53/64 loss: -1.215188980102539
Batch 54/64 loss: -0.5297698974609375
Batch 55/64 loss: -0.6261272430419922
Batch 56/64 loss: -1.3084869384765625
Batch 57/64 loss: -1.3042793273925781
Batch 58/64 loss: -1.169382095336914
Batch 59/64 loss: -1.120844841003418
Batch 60/64 loss: -1.1199951171875
Batch 61/64 loss: -0.9461803436279297
Batch 62/64 loss: -1.0224895477294922
Batch 63/64 loss: -0.3558645248413086
Batch 64/64 loss: -5.298270225524902
Epoch 136  Train loss: -0.9188850589826996  Val loss: -1.0735135029271705
Epoch 137
-------------------------------
Batch 1/64 loss: -0.14787960052490234
Batch 2/64 loss: -0.7469558715820312
Batch 3/64 loss: -0.3159914016723633
Batch 4/64 loss: -0.978785514831543
Batch 5/64 loss: -1.2947521209716797
Batch 6/64 loss: -1.3326873779296875
Batch 7/64 loss: -1.1274080276489258
Batch 8/64 loss: -0.8496112823486328
Batch 9/64 loss: -0.9653854370117188
Batch 10/64 loss: 0.00154876708984375
Batch 11/64 loss: -1.345128059387207
Batch 12/64 loss: -1.4412841796875
Batch 13/64 loss: -1.188349723815918
Batch 14/64 loss: -0.27147483825683594
Batch 15/64 loss: -0.5629873275756836
Batch 16/64 loss: -0.8231821060180664
Batch 17/64 loss: -1.1649665832519531
Batch 18/64 loss: -1.182504653930664
Batch 19/64 loss: -0.9428939819335938
Batch 20/64 loss: -1.0242547988891602
Batch 21/64 loss: -1.567215919494629
Batch 22/64 loss: -1.375558853149414
Batch 23/64 loss: -0.7483253479003906
Batch 24/64 loss: -0.07038497924804688
Batch 25/64 loss: -1.1244878768920898
Batch 26/64 loss: -1.0381927490234375
Batch 27/64 loss: -1.2702016830444336
Batch 28/64 loss: -1.283890724182129
Batch 29/64 loss: -1.3945999145507812
Batch 30/64 loss: -0.35422706604003906
Batch 31/64 loss: -1.1631441116333008
Batch 32/64 loss: -0.9932613372802734
Batch 33/64 loss: -0.6634550094604492
Batch 34/64 loss: -0.6587772369384766
Batch 35/64 loss: 0.11910629272460938
Batch 36/64 loss: -0.8136472702026367
Batch 37/64 loss: -1.0310478210449219
Batch 38/64 loss: -1.0730628967285156
Batch 39/64 loss: -1.2275876998901367
Batch 40/64 loss: -0.8315086364746094
Batch 41/64 loss: -0.8468093872070312
Batch 42/64 loss: -0.537440299987793
Batch 43/64 loss: -0.8144283294677734
Batch 44/64 loss: -1.2779951095581055
Batch 45/64 loss: -0.9274101257324219
Batch 46/64 loss: -0.8830375671386719
Batch 47/64 loss: -0.9546947479248047
Batch 48/64 loss: -0.9161853790283203
Batch 49/64 loss: -0.8714027404785156
Batch 50/64 loss: -1.1712446212768555
Batch 51/64 loss: -1.0760231018066406
Batch 52/64 loss: -1.4321422576904297
Batch 53/64 loss: -1.3581962585449219
Batch 54/64 loss: -0.5338649749755859
Batch 55/64 loss: -1.0745296478271484
Batch 56/64 loss: -0.715123176574707
Batch 57/64 loss: -0.616297721862793
Batch 58/64 loss: -0.5599269866943359
Batch 59/64 loss: -1.2141971588134766
Batch 60/64 loss: -0.9032735824584961
Batch 61/64 loss: -1.1033439636230469
Batch 62/64 loss: -1.3012943267822266
Batch 63/64 loss: -0.5504894256591797
Batch 64/64 loss: -4.664432525634766
Epoch 137  Train loss: -0.9632326313093597  Val loss: -1.0101528495447742
Epoch 138
-------------------------------
Batch 1/64 loss: -0.9987316131591797
Batch 2/64 loss: -0.7107715606689453
Batch 3/64 loss: -0.9171304702758789
Batch 4/64 loss: -0.8699216842651367
Batch 5/64 loss: -0.9161863327026367
Batch 6/64 loss: -0.8767538070678711
Batch 7/64 loss: -1.0342292785644531
Batch 8/64 loss: -0.849247932434082
Batch 9/64 loss: -0.4642143249511719
Batch 10/64 loss: -0.9015283584594727
Batch 11/64 loss: -1.097991943359375
Batch 12/64 loss: -1.3266630172729492
Batch 13/64 loss: -0.4482536315917969
Batch 14/64 loss: -0.6696567535400391
Batch 15/64 loss: -0.5444841384887695
Batch 16/64 loss: -0.8392782211303711
Batch 17/64 loss: -1.3821334838867188
Batch 18/64 loss: -0.9916648864746094
Batch 19/64 loss: -0.5502300262451172
Batch 20/64 loss: 0.03151702880859375
Batch 21/64 loss: -1.2249727249145508
Batch 22/64 loss: 0.3796377182006836
Batch 23/64 loss: -0.7930784225463867
Batch 24/64 loss: -0.3006153106689453
Batch 25/64 loss: -1.068232536315918
Batch 26/64 loss: -0.9476518630981445
Batch 27/64 loss: -0.9744415283203125
Batch 28/64 loss: -1.4883832931518555
Batch 29/64 loss: -1.2840499877929688
Batch 30/64 loss: -0.7082920074462891
Batch 31/64 loss: -0.848597526550293
Batch 32/64 loss: -1.345235824584961
Batch 33/64 loss: -0.9710626602172852
Batch 34/64 loss: -0.8476533889770508
Batch 35/64 loss: -1.0942316055297852
Batch 36/64 loss: -0.6091794967651367
Batch 37/64 loss: -1.2760305404663086
Batch 38/64 loss: -0.9382228851318359
Batch 39/64 loss: -0.6583118438720703
Batch 40/64 loss: -1.0980310440063477
Batch 41/64 loss: -1.0998344421386719
Batch 42/64 loss: -0.6541318893432617
Batch 43/64 loss: -1.0302495956420898
Batch 44/64 loss: -0.1963968276977539
Batch 45/64 loss: -0.3572721481323242
Batch 46/64 loss: -0.9665403366088867
Batch 47/64 loss: -0.8472433090209961
Batch 48/64 loss: -1.243483543395996
Batch 49/64 loss: -0.8732490539550781
Batch 50/64 loss: -0.9862346649169922
Batch 51/64 loss: -1.02923583984375
Batch 52/64 loss: -1.337472915649414
Batch 53/64 loss: -0.5358066558837891
Batch 54/64 loss: -1.1269559860229492
Batch 55/64 loss: -0.8934154510498047
Batch 56/64 loss: -1.0512237548828125
Batch 57/64 loss: -1.1735477447509766
Batch 58/64 loss: 0.1630544662475586
Batch 59/64 loss: -1.0472259521484375
Batch 60/64 loss: -1.1020145416259766
Batch 61/64 loss: -0.07831287384033203
Batch 62/64 loss: -1.114924430847168
Batch 63/64 loss: -0.7966794967651367
Batch 64/64 loss: -5.370919227600098
Epoch 138  Train loss: -0.9076200410431506  Val loss: -1.079719779417687
Epoch 139
-------------------------------
Batch 1/64 loss: -1.1577253341674805
Batch 2/64 loss: -1.0417823791503906
Batch 3/64 loss: -1.1178035736083984
Batch 4/64 loss: -0.8845481872558594
Batch 5/64 loss: -0.6956205368041992
Batch 6/64 loss: -0.8236656188964844
Batch 7/64 loss: -0.7878522872924805
Batch 8/64 loss: -1.023733139038086
Batch 9/64 loss: -1.3344850540161133
Batch 10/64 loss: -0.7665281295776367
Batch 11/64 loss: -1.0020790100097656
Batch 12/64 loss: -1.3998632431030273
Batch 13/64 loss: -1.0330638885498047
Batch 14/64 loss: -0.26854801177978516
Batch 15/64 loss: -1.1398181915283203
Batch 16/64 loss: -1.3117008209228516
Batch 17/64 loss: -0.7044286727905273
Batch 18/64 loss: -1.2152032852172852
Batch 19/64 loss: -0.8475112915039062
Batch 20/64 loss: -1.1084527969360352
Batch 21/64 loss: -1.23974609375
Batch 22/64 loss: -0.8017120361328125
Batch 23/64 loss: -1.2218122482299805
Batch 24/64 loss: -0.8903350830078125
Batch 25/64 loss: -0.9680585861206055
Batch 26/64 loss: -1.0053796768188477
Batch 27/64 loss: -1.261336326599121
Batch 28/64 loss: -0.8298883438110352
Batch 29/64 loss: -0.8496866226196289
Batch 30/64 loss: -1.3426313400268555
Batch 31/64 loss: -1.3002500534057617
Batch 32/64 loss: -0.8297338485717773
Batch 33/64 loss: -0.8210849761962891
Batch 34/64 loss: -1.4863061904907227
Batch 35/64 loss: -1.5271492004394531
Batch 36/64 loss: -1.2346630096435547
Batch 37/64 loss: -1.347681999206543
Batch 38/64 loss: -1.335153579711914
Batch 39/64 loss: -0.5196142196655273
Batch 40/64 loss: -1.5439023971557617
Batch 41/64 loss: -0.9168558120727539
Batch 42/64 loss: -1.2651901245117188
Batch 43/64 loss: -0.7513294219970703
Batch 44/64 loss: -1.0634937286376953
Batch 45/64 loss: -1.510599136352539
Batch 46/64 loss: -1.2945737838745117
Batch 47/64 loss: -1.4576873779296875
Batch 48/64 loss: -1.0788860321044922
Batch 49/64 loss: -1.1711359024047852
Batch 50/64 loss: -1.04022216796875
Batch 51/64 loss: -1.2302284240722656
Batch 52/64 loss: -0.5909996032714844
Batch 53/64 loss: -1.2243871688842773
Batch 54/64 loss: -1.2957582473754883
Batch 55/64 loss: -0.41185474395751953
Batch 56/64 loss: -1.3749704360961914
Batch 57/64 loss: -1.5729408264160156
Batch 58/64 loss: -1.36749267578125
Batch 59/64 loss: -1.3221654891967773
Batch 60/64 loss: -1.4316701889038086
Batch 61/64 loss: -1.0819206237792969
Batch 62/64 loss: -0.14038658142089844
Batch 63/64 loss: -0.9494924545288086
Batch 64/64 loss: -5.714303016662598
Epoch 139  Train loss: -1.1270667842790192  Val loss: -1.3069071556694318
Epoch 140
-------------------------------
Batch 1/64 loss: -0.6345720291137695
Batch 2/64 loss: -1.2771062850952148
Batch 3/64 loss: -1.4706239700317383
Batch 4/64 loss: -1.0074796676635742
Batch 5/64 loss: -1.439469337463379
Batch 6/64 loss: -1.3893766403198242
Batch 7/64 loss: -1.011343002319336
Batch 8/64 loss: -1.548543930053711
Batch 9/64 loss: -1.2400150299072266
Batch 10/64 loss: -1.0705337524414062
Batch 11/64 loss: -0.6528530120849609
Batch 12/64 loss: -1.3994112014770508
Batch 13/64 loss: -0.9902381896972656
Batch 14/64 loss: -1.4608573913574219
Batch 15/64 loss: -0.88134765625
Batch 16/64 loss: -1.0348176956176758
Batch 17/64 loss: -0.5816793441772461
Batch 18/64 loss: -1.2958784103393555
Batch 19/64 loss: -1.3680715560913086
Batch 20/64 loss: -1.5238819122314453
Batch 21/64 loss: -1.107722282409668
Batch 22/64 loss: -1.1428442001342773
Batch 23/64 loss: -1.5957202911376953
Batch 24/64 loss: -1.3826274871826172
Batch 25/64 loss: -1.4189205169677734
Batch 26/64 loss: -1.3799114227294922
Batch 27/64 loss: -1.072164535522461
Batch 28/64 loss: -0.6978969573974609
Batch 29/64 loss: -0.5413608551025391
Batch 30/64 loss: -1.1306962966918945
Batch 31/64 loss: -1.3430061340332031
Batch 32/64 loss: -0.6497030258178711
Batch 33/64 loss: -1.5015363693237305
Batch 34/64 loss: -1.5242738723754883
Batch 35/64 loss: -1.5926580429077148
Batch 36/64 loss: -1.371748924255371
Batch 37/64 loss: -1.255936622619629
Batch 38/64 loss: -1.4369726181030273
Batch 39/64 loss: -1.3583154678344727
Batch 40/64 loss: -1.511312484741211
Batch 41/64 loss: -1.526693344116211
Batch 42/64 loss: -1.529768943786621
Batch 43/64 loss: -0.7536945343017578
Batch 44/64 loss: -0.980708122253418
Batch 45/64 loss: -1.1271657943725586
Batch 46/64 loss: -1.1771488189697266
Batch 47/64 loss: -1.1756134033203125
Batch 48/64 loss: -1.0737018585205078
Batch 49/64 loss: -1.0854158401489258
Batch 50/64 loss: -1.6003313064575195
Batch 51/64 loss: -1.4378490447998047
Batch 52/64 loss: -1.5361862182617188
Batch 53/64 loss: -1.3482189178466797
Batch 54/64 loss: -0.7383384704589844
Batch 55/64 loss: -1.6983938217163086
Batch 56/64 loss: -1.4970073699951172
Batch 57/64 loss: -0.8635540008544922
Batch 58/64 loss: -1.4854583740234375
Batch 59/64 loss: -1.3898496627807617
Batch 60/64 loss: -1.2095870971679688
Batch 61/64 loss: -1.529637336730957
Batch 62/64 loss: -1.0378150939941406
Batch 63/64 loss: -0.9555397033691406
Batch 64/64 loss: -5.7867512702941895
Epoch 140  Train loss: -1.2767242188547172  Val loss: -1.35991631996181
Epoch 141
-------------------------------
Batch 1/64 loss: -1.411794662475586
Batch 2/64 loss: -0.8923625946044922
Batch 3/64 loss: -0.8136768341064453
Batch 4/64 loss: -1.4016504287719727
Batch 5/64 loss: -1.4178266525268555
Batch 6/64 loss: -1.3842887878417969
Batch 7/64 loss: -0.5924863815307617
Batch 8/64 loss: -1.1582422256469727
Batch 9/64 loss: -1.3819293975830078
Batch 10/64 loss: -1.0445013046264648
Batch 11/64 loss: -1.2659072875976562
Batch 12/64 loss: -1.565598487854004
Batch 13/64 loss: -1.2615175247192383
Batch 14/64 loss: -0.8796529769897461
Batch 15/64 loss: -1.31939697265625
Batch 16/64 loss: -1.537022590637207
Batch 17/64 loss: -1.5070524215698242
Batch 18/64 loss: -1.133744239807129
Batch 19/64 loss: -1.4597816467285156
Batch 20/64 loss: -1.5685796737670898
Batch 21/64 loss: -1.1042699813842773
Batch 22/64 loss: -1.3006420135498047
Batch 23/64 loss: -1.1622390747070312
Batch 24/64 loss: -0.5541906356811523
Batch 25/64 loss: -0.9603261947631836
Batch 26/64 loss: -1.3236846923828125
Batch 27/64 loss: -0.9899625778198242
Batch 28/64 loss: -0.7889842987060547
Batch 29/64 loss: -1.1078033447265625
Batch 30/64 loss: -1.4767236709594727
Batch 31/64 loss: -1.0378122329711914
Batch 32/64 loss: 0.049117088317871094
Batch 33/64 loss: -1.3858919143676758
Batch 34/64 loss: -1.3882789611816406
Batch 35/64 loss: -1.0001850128173828
Batch 36/64 loss: -1.266097068786621
Batch 37/64 loss: -1.00146484375
Batch 38/64 loss: -0.7035579681396484
Batch 39/64 loss: -1.3999319076538086
Batch 40/64 loss: -1.1397457122802734
Batch 41/64 loss: -0.7614784240722656
Batch 42/64 loss: -1.3152961730957031
Batch 43/64 loss: -1.4549226760864258
Batch 44/64 loss: -1.2949810028076172
Batch 45/64 loss: -1.3772830963134766
Batch 46/64 loss: -0.9117221832275391
Batch 47/64 loss: -1.0527973175048828
Batch 48/64 loss: -0.641871452331543
Batch 49/64 loss: -1.3449726104736328
Batch 50/64 loss: -1.1110525131225586
Batch 51/64 loss: -1.2722911834716797
Batch 52/64 loss: -0.694218635559082
Batch 53/64 loss: -1.188401222229004
Batch 54/64 loss: -0.9201059341430664
Batch 55/64 loss: -0.7465715408325195
Batch 56/64 loss: -1.206563949584961
Batch 57/64 loss: -1.2379322052001953
Batch 58/64 loss: -1.0284614562988281
Batch 59/64 loss: -0.1992025375366211
Batch 60/64 loss: -0.611424446105957
Batch 61/64 loss: -1.2883596420288086
Batch 62/64 loss: -1.3278398513793945
Batch 63/64 loss: -0.6072359085083008
Batch 64/64 loss: -5.338540077209473
Epoch 141  Train loss: -1.1551149667478076  Val loss: -1.270345589549271
Epoch 142
-------------------------------
Batch 1/64 loss: -1.0683813095092773
Batch 2/64 loss: 1.1844367980957031
Batch 3/64 loss: -0.964625358581543
Batch 4/64 loss: -0.9453229904174805
Batch 5/64 loss: -1.4504823684692383
Batch 6/64 loss: -1.3627433776855469
Batch 7/64 loss: -1.1718873977661133
Batch 8/64 loss: -1.2992677688598633
Batch 9/64 loss: -1.3324651718139648
Batch 10/64 loss: -1.5938844680786133
Batch 11/64 loss: -0.7783269882202148
Batch 12/64 loss: -1.2098865509033203
Batch 13/64 loss: -1.3998184204101562
Batch 14/64 loss: -0.9566125869750977
Batch 15/64 loss: -0.8188629150390625
Batch 16/64 loss: -1.3399648666381836
Batch 17/64 loss: -1.300863265991211
Batch 18/64 loss: -1.3696908950805664
Batch 19/64 loss: -1.2035856246948242
Batch 20/64 loss: -1.0639257431030273
Batch 21/64 loss: -1.3714141845703125
Batch 22/64 loss: -0.8309469223022461
Batch 23/64 loss: -0.6318359375
Batch 24/64 loss: -1.4561796188354492
Batch 25/64 loss: -1.637404441833496
Batch 26/64 loss: -1.25201416015625
Batch 27/64 loss: -1.0294952392578125
Batch 28/64 loss: -1.6675806045532227
Batch 29/64 loss: -1.1634492874145508
Batch 30/64 loss: -1.0780220031738281
Batch 31/64 loss: -1.4752960205078125
Batch 32/64 loss: -1.3683156967163086
Batch 33/64 loss: -1.4572668075561523
Batch 34/64 loss: -1.1803693771362305
Batch 35/64 loss: -1.4414653778076172
Batch 36/64 loss: -1.4753475189208984
Batch 37/64 loss: -1.3095006942749023
Batch 38/64 loss: -1.1826200485229492
Batch 39/64 loss: -0.9024286270141602
Batch 40/64 loss: -1.5657520294189453
Batch 41/64 loss: -1.4601068496704102
Batch 42/64 loss: -1.4566116333007812
Batch 43/64 loss: -1.2777910232543945
Batch 44/64 loss: -1.3914785385131836
Batch 45/64 loss: -1.1356687545776367
Batch 46/64 loss: -1.4551811218261719
Batch 47/64 loss: -1.7534360885620117
Batch 48/64 loss: -1.2092266082763672
Batch 49/64 loss: -1.176422119140625
Batch 50/64 loss: -1.325108528137207
Batch 51/64 loss: -1.0667505264282227
Batch 52/64 loss: -0.7870988845825195
Batch 53/64 loss: -1.1209440231323242
Batch 54/64 loss: -1.0787935256958008
Batch 55/64 loss: -1.4221153259277344
Batch 56/64 loss: -1.268742561340332
Batch 57/64 loss: -1.197667121887207
Batch 58/64 loss: -0.9234123229980469
Batch 59/64 loss: -0.5810451507568359
Batch 60/64 loss: -1.5798578262329102
Batch 61/64 loss: -1.4092769622802734
Batch 62/64 loss: -1.2439994812011719
Batch 63/64 loss: -1.5086288452148438
Batch 64/64 loss: -5.69009256362915
Epoch 142  Train loss: -1.2552125351101744  Val loss: -1.3512131078136747
Epoch 143
-------------------------------
Batch 1/64 loss: -1.1384925842285156
Batch 2/64 loss: -1.509486198425293
Batch 3/64 loss: -1.3942232131958008
Batch 4/64 loss: -1.6106071472167969
Batch 5/64 loss: -1.6688652038574219
Batch 6/64 loss: -1.6100311279296875
Batch 7/64 loss: -1.0556573867797852
Batch 8/64 loss: -1.0456390380859375
Batch 9/64 loss: -1.3895339965820312
Batch 10/64 loss: -1.551309585571289
Batch 11/64 loss: -1.4197511672973633
Batch 12/64 loss: -1.3029260635375977
Batch 13/64 loss: -1.3856258392333984
Batch 14/64 loss: -1.0997743606567383
Batch 15/64 loss: -0.543065071105957
Batch 16/64 loss: -1.0583267211914062
Batch 17/64 loss: -1.3644027709960938
Batch 18/64 loss: -1.0560760498046875
Batch 19/64 loss: -0.49657726287841797
Batch 20/64 loss: -1.477128028869629
Batch 21/64 loss: -1.594252586364746
Batch 22/64 loss: -0.8558025360107422
Batch 23/64 loss: -1.1466960906982422
Batch 24/64 loss: -1.251251220703125
Batch 25/64 loss: -1.2878637313842773
Batch 26/64 loss: -1.496556282043457
Batch 27/64 loss: -0.8914070129394531
Batch 28/64 loss: -0.7717933654785156
Batch 29/64 loss: -1.2619924545288086
Batch 30/64 loss: -1.4273624420166016
Batch 31/64 loss: -1.1256303787231445
Batch 32/64 loss: -1.1763858795166016
Batch 33/64 loss: -1.0858221054077148
Batch 34/64 loss: -1.5026168823242188
Batch 35/64 loss: -1.3374996185302734
Batch 36/64 loss: -0.6029253005981445
Batch 37/64 loss: -1.4795351028442383
Batch 38/64 loss: -0.8036003112792969
Batch 39/64 loss: -1.228999137878418
Batch 40/64 loss: -1.1501169204711914
Batch 41/64 loss: -1.296299934387207
Batch 42/64 loss: -1.6565837860107422
Batch 43/64 loss: -1.3375177383422852
Batch 44/64 loss: -1.271836280822754
Batch 45/64 loss: -1.2094602584838867
Batch 46/64 loss: -1.0731515884399414
Batch 47/64 loss: -1.0142736434936523
Batch 48/64 loss: -0.9449377059936523
Batch 49/64 loss: -0.9788551330566406
Batch 50/64 loss: -1.1361379623413086
Batch 51/64 loss: -1.3568916320800781
Batch 52/64 loss: -1.4037981033325195
Batch 53/64 loss: -0.8196306228637695
Batch 54/64 loss: -0.4620990753173828
Batch 55/64 loss: -1.3758220672607422
Batch 56/64 loss: -1.0269603729248047
Batch 57/64 loss: -1.3751201629638672
Batch 58/64 loss: -1.0559167861938477
Batch 59/64 loss: -0.9903230667114258
Batch 60/64 loss: -1.0730514526367188
Batch 61/64 loss: -1.3557872772216797
Batch 62/64 loss: -0.9546709060668945
Batch 63/64 loss: -1.1050395965576172
Batch 64/64 loss: -5.586123943328857
Epoch 143  Train loss: -1.241088098638198  Val loss: -1.3231629178286417
Epoch 144
-------------------------------
Batch 1/64 loss: -0.9887304306030273
Batch 2/64 loss: -1.2623376846313477
Batch 3/64 loss: -1.2206125259399414
Batch 4/64 loss: -1.2717342376708984
Batch 5/64 loss: -1.247126579284668
Batch 6/64 loss: -1.1791315078735352
Batch 7/64 loss: -1.6263313293457031
Batch 8/64 loss: -0.8860969543457031
Batch 9/64 loss: -1.1215696334838867
Batch 10/64 loss: -0.7434282302856445
Batch 11/64 loss: -0.9960517883300781
Batch 12/64 loss: 0.33896827697753906
Batch 13/64 loss: -1.064239501953125
Batch 14/64 loss: -1.360626220703125
Batch 15/64 loss: -1.0312232971191406
Batch 16/64 loss: -1.2695941925048828
Batch 17/64 loss: -1.0922355651855469
Batch 18/64 loss: -1.4974775314331055
Batch 19/64 loss: -1.413008689880371
Batch 20/64 loss: -0.9163551330566406
Batch 21/64 loss: -1.2360925674438477
Batch 22/64 loss: -0.8500528335571289
Batch 23/64 loss: -1.3603124618530273
Batch 24/64 loss: -0.7711896896362305
Batch 25/64 loss: -0.9452266693115234
Batch 26/64 loss: -0.8142156600952148
Batch 27/64 loss: -0.9806480407714844
Batch 28/64 loss: -0.9159212112426758
Batch 29/64 loss: -1.0153322219848633
Batch 30/64 loss: -0.5196685791015625
Batch 31/64 loss: -0.9965896606445312
Batch 32/64 loss: -0.8079919815063477
Batch 33/64 loss: -0.8716049194335938
Batch 34/64 loss: -1.2397451400756836
Batch 35/64 loss: -1.1269445419311523
Batch 36/64 loss: -0.4561758041381836
Batch 37/64 loss: -1.0933589935302734
Batch 38/64 loss: -1.168745994567871
Batch 39/64 loss: -1.1864938735961914
Batch 40/64 loss: -1.1043462753295898
Batch 41/64 loss: -1.3000307083129883
Batch 42/64 loss: -1.1519947052001953
Batch 43/64 loss: -1.2848081588745117
Batch 44/64 loss: -1.3078222274780273
Batch 45/64 loss: -1.260359764099121
Batch 46/64 loss: -1.2290754318237305
Batch 47/64 loss: -1.4294500350952148
Batch 48/64 loss: -1.280959129333496
Batch 49/64 loss: -0.8543710708618164
Batch 50/64 loss: -1.1402263641357422
Batch 51/64 loss: -0.7170495986938477
Batch 52/64 loss: -1.2918376922607422
Batch 53/64 loss: -1.058222770690918
Batch 54/64 loss: -1.101104736328125
Batch 55/64 loss: -0.5586910247802734
Batch 56/64 loss: -0.9438066482543945
Batch 57/64 loss: -1.0441598892211914
Batch 58/64 loss: -1.0087270736694336
Batch 59/64 loss: -0.2150096893310547
Batch 60/64 loss: -1.2206077575683594
Batch 61/64 loss: -0.025382041931152344
Batch 62/64 loss: -1.0679636001586914
Batch 63/64 loss: -0.9236421585083008
Batch 64/64 loss: -5.057858467102051
Epoch 144  Train loss: -1.0747968000524184  Val loss: -1.2557699065847494
Epoch 145
-------------------------------
Batch 1/64 loss: -1.2059364318847656
Batch 2/64 loss: -1.2045230865478516
Batch 3/64 loss: -0.6755847930908203
Batch 4/64 loss: -1.4179096221923828
Batch 5/64 loss: -0.8449411392211914
Batch 6/64 loss: -0.9357805252075195
Batch 7/64 loss: -0.7211246490478516
Batch 8/64 loss: -1.0510787963867188
Batch 9/64 loss: -0.8115348815917969
Batch 10/64 loss: -1.2192020416259766
Batch 11/64 loss: -1.1417865753173828
Batch 12/64 loss: 0.030084609985351562
Batch 13/64 loss: -0.8993806838989258
Batch 14/64 loss: 0.3126335144042969
Batch 15/64 loss: -0.03948688507080078
Batch 16/64 loss: -1.0343818664550781
Batch 17/64 loss: -1.022979736328125
Batch 18/64 loss: 0.0008268356323242188
Batch 19/64 loss: -1.3193769454956055
Batch 20/64 loss: -1.22698974609375
Batch 21/64 loss: -1.1030607223510742
Batch 22/64 loss: -0.9831504821777344
Batch 23/64 loss: -1.1445493698120117
Batch 24/64 loss: -1.1885433197021484
Batch 25/64 loss: -0.5734739303588867
Batch 26/64 loss: -1.234482765197754
Batch 27/64 loss: -0.6307430267333984
Batch 28/64 loss: -0.8379192352294922
Batch 29/64 loss: -1.2010622024536133
Batch 30/64 loss: -0.29122447967529297
Batch 31/64 loss: -1.1975955963134766
Batch 32/64 loss: -1.111372947692871
Batch 33/64 loss: -1.0175666809082031
Batch 34/64 loss: -0.19668197631835938
Batch 35/64 loss: -1.0358705520629883
Batch 36/64 loss: -0.153594970703125
Batch 37/64 loss: -1.1946659088134766
Batch 38/64 loss: -1.219156265258789
Batch 39/64 loss: -1.2513923645019531
Batch 40/64 loss: -1.1266765594482422
Batch 41/64 loss: -0.9013948440551758
Batch 42/64 loss: -1.3081932067871094
Batch 43/64 loss: -0.39917755126953125
Batch 44/64 loss: -1.0296897888183594
Batch 45/64 loss: -0.8687210083007812
Batch 46/64 loss: -1.2281017303466797
Batch 47/64 loss: -0.36147403717041016
Batch 48/64 loss: -1.043961524963379
Batch 49/64 loss: -0.9804067611694336
Batch 50/64 loss: -1.1073579788208008
Batch 51/64 loss: -1.1608686447143555
Batch 52/64 loss: -0.7403659820556641
Batch 53/64 loss: -1.143162727355957
Batch 54/64 loss: -1.0590028762817383
Batch 55/64 loss: -0.41417980194091797
Batch 56/64 loss: -0.8654279708862305
Batch 57/64 loss: -1.0134906768798828
Batch 58/64 loss: -1.1631851196289062
Batch 59/64 loss: -1.307368278503418
Batch 60/64 loss: -1.002528190612793
Batch 61/64 loss: -1.1286211013793945
Batch 62/64 loss: -1.0593757629394531
Batch 63/64 loss: -1.1223268508911133
Batch 64/64 loss: -5.506803512573242
Epoch 145  Train loss: -0.9672113231584137  Val loss: -1.3598389248667713
Epoch 146
-------------------------------
Batch 1/64 loss: -1.1317663192749023
Batch 2/64 loss: -1.435079574584961
Batch 3/64 loss: -1.4008665084838867
Batch 4/64 loss: -0.9389848709106445
Batch 5/64 loss: -0.34809398651123047
Batch 6/64 loss: -1.3967952728271484
Batch 7/64 loss: -1.351271629333496
Batch 8/64 loss: -1.3854875564575195
Batch 9/64 loss: -0.13722801208496094
Batch 10/64 loss: -0.8854131698608398
Batch 11/64 loss: -1.319392204284668
Batch 12/64 loss: -1.246474266052246
Batch 13/64 loss: -1.1976499557495117
Batch 14/64 loss: -1.0399150848388672
Batch 15/64 loss: -1.2190427780151367
Batch 16/64 loss: -1.6155338287353516
Batch 17/64 loss: -0.914586067199707
Batch 18/64 loss: -1.1242685317993164
Batch 19/64 loss: -1.4472675323486328
Batch 20/64 loss: -1.0054893493652344
Batch 21/64 loss: -1.2091827392578125
Batch 22/64 loss: -1.2410964965820312
Batch 23/64 loss: -1.3122014999389648
Batch 24/64 loss: -0.6565237045288086
Batch 25/64 loss: -1.281449317932129
Batch 26/64 loss: -1.0085563659667969
Batch 27/64 loss: -0.1280670166015625
Batch 28/64 loss: -0.694880485534668
Batch 29/64 loss: -1.136775016784668
Batch 30/64 loss: -1.063786506652832
Batch 31/64 loss: -1.2786226272583008
Batch 32/64 loss: -0.8835868835449219
Batch 33/64 loss: -1.121504783630371
Batch 34/64 loss: -1.4624042510986328
Batch 35/64 loss: -0.9548530578613281
Batch 36/64 loss: -1.1373529434204102
Batch 37/64 loss: -0.762298583984375
Batch 38/64 loss: -1.0804920196533203
Batch 39/64 loss: -1.347233772277832
Batch 40/64 loss: -1.4116363525390625
Batch 41/64 loss: -1.1660680770874023
Batch 42/64 loss: -1.172037124633789
Batch 43/64 loss: -1.1563282012939453
Batch 44/64 loss: -1.3737592697143555
Batch 45/64 loss: -1.2822380065917969
Batch 46/64 loss: -1.1977481842041016
Batch 47/64 loss: -1.3501338958740234
Batch 48/64 loss: -1.5161895751953125
Batch 49/64 loss: -0.9104251861572266
Batch 50/64 loss: -1.0578622817993164
Batch 51/64 loss: -1.341740608215332
Batch 52/64 loss: -1.2742490768432617
Batch 53/64 loss: -1.3623037338256836
Batch 54/64 loss: -1.3002862930297852
Batch 55/64 loss: -1.0902519226074219
Batch 56/64 loss: -0.43526649475097656
Batch 57/64 loss: -1.3198919296264648
Batch 58/64 loss: -1.3450126647949219
Batch 59/64 loss: -1.2410430908203125
Batch 60/64 loss: -1.202737808227539
Batch 61/64 loss: -1.4751768112182617
Batch 62/64 loss: -0.9637174606323242
Batch 63/64 loss: -0.8000659942626953
Batch 64/64 loss: -5.6287841796875
Epoch 146  Train loss: -1.180693847057866  Val loss: -1.2685078493098623
Epoch 147
-------------------------------
Batch 1/64 loss: -1.3206043243408203
Batch 2/64 loss: -0.8435745239257812
Batch 3/64 loss: -1.1301183700561523
Batch 4/64 loss: -1.1634912490844727
Batch 5/64 loss: -0.6346235275268555
Batch 6/64 loss: -1.3385934829711914
Batch 7/64 loss: -0.28421592712402344
Batch 8/64 loss: -0.76239013671875
Batch 9/64 loss: -1.301386833190918
Batch 10/64 loss: -1.298828125
Batch 11/64 loss: -1.0963106155395508
Batch 12/64 loss: -1.218153953552246
Batch 13/64 loss: -0.8524541854858398
Batch 14/64 loss: -1.0079421997070312
Batch 15/64 loss: -1.1884632110595703
Batch 16/64 loss: -1.1232423782348633
Batch 17/64 loss: -0.3164501190185547
Batch 18/64 loss: -1.1741666793823242
Batch 19/64 loss: -0.9497251510620117
Batch 20/64 loss: -0.9489269256591797
Batch 21/64 loss: -0.6706972122192383
Batch 22/64 loss: -1.4165229797363281
Batch 23/64 loss: -1.1827764511108398
Batch 24/64 loss: -1.0840492248535156
Batch 25/64 loss: -1.1525163650512695
Batch 26/64 loss: -1.3074102401733398
Batch 27/64 loss: -1.0901927947998047
Batch 28/64 loss: -1.2039823532104492
Batch 29/64 loss: -1.2974023818969727
Batch 30/64 loss: -1.1295976638793945
Batch 31/64 loss: -0.973668098449707
Batch 32/64 loss: -1.2868061065673828
Batch 33/64 loss: -1.3938989639282227
Batch 34/64 loss: -1.1971006393432617
Batch 35/64 loss: -1.0320463180541992
Batch 36/64 loss: -1.0547904968261719
Batch 37/64 loss: -1.0441436767578125
Batch 38/64 loss: -1.2382183074951172
Batch 39/64 loss: -1.0847091674804688
Batch 40/64 loss: -0.9272117614746094
Batch 41/64 loss: -0.7308597564697266
Batch 42/64 loss: -1.3180227279663086
Batch 43/64 loss: -1.1630163192749023
Batch 44/64 loss: -0.9571866989135742
Batch 45/64 loss: -1.186910629272461
Batch 46/64 loss: -1.2779865264892578
Batch 47/64 loss: -0.2861604690551758
Batch 48/64 loss: -1.1354827880859375
Batch 49/64 loss: -1.314784049987793
Batch 50/64 loss: -1.4537725448608398
Batch 51/64 loss: -0.9207839965820312
Batch 52/64 loss: -1.173008918762207
Batch 53/64 loss: -0.9439811706542969
Batch 54/64 loss: -0.6180124282836914
Batch 55/64 loss: -1.100067138671875
Batch 56/64 loss: -0.9944915771484375
Batch 57/64 loss: 0.08795928955078125
Batch 58/64 loss: -0.9801177978515625
Batch 59/64 loss: -0.7623453140258789
Batch 60/64 loss: -1.4311885833740234
Batch 61/64 loss: -0.2421436309814453
Batch 62/64 loss: -0.7301969528198242
Batch 63/64 loss: -0.4938793182373047
Batch 64/64 loss: -5.332363605499268
Epoch 147  Train loss: -1.0642684843025956  Val loss: -1.4528145413218494
Epoch 148
-------------------------------
Batch 1/64 loss: -1.2209587097167969
Batch 2/64 loss: -1.1803464889526367
Batch 3/64 loss: -0.7608852386474609
Batch 4/64 loss: -0.9472217559814453
Batch 5/64 loss: -0.6006898880004883
Batch 6/64 loss: -1.0876083374023438
Batch 7/64 loss: -1.173008918762207
Batch 8/64 loss: -1.172978401184082
Batch 9/64 loss: -1.1865015029907227
Batch 10/64 loss: -1.2907485961914062
Batch 11/64 loss: -1.2246265411376953
Batch 12/64 loss: -0.9752302169799805
Batch 13/64 loss: -1.397817611694336
Batch 14/64 loss: -1.169973373413086
Batch 15/64 loss: -1.3989381790161133
Batch 16/64 loss: -1.1577949523925781
Batch 17/64 loss: -1.2475996017456055
Batch 18/64 loss: -1.2169218063354492
Batch 19/64 loss: -1.4188661575317383
Batch 20/64 loss: -1.244924545288086
Batch 21/64 loss: -1.2161712646484375
Batch 22/64 loss: -1.0028352737426758
Batch 23/64 loss: -1.1000328063964844
Batch 24/64 loss: -1.4668617248535156
Batch 25/64 loss: -0.25224781036376953
Batch 26/64 loss: -1.2901582717895508
Batch 27/64 loss: -1.398153305053711
Batch 28/64 loss: -1.4073925018310547
Batch 29/64 loss: -1.239114761352539
Batch 30/64 loss: -1.4430322647094727
Batch 31/64 loss: -1.2510452270507812
Batch 32/64 loss: -0.7374839782714844
Batch 33/64 loss: -1.3307199478149414
Batch 34/64 loss: -1.0977191925048828
Batch 35/64 loss: -1.2887954711914062
Batch 36/64 loss: -0.7777671813964844
Batch 37/64 loss: -1.486837387084961
Batch 38/64 loss: -0.8716421127319336
Batch 39/64 loss: -1.1918916702270508
Batch 40/64 loss: -1.0070810317993164
Batch 41/64 loss: -1.1638298034667969
Batch 42/64 loss: -1.2216835021972656
Batch 43/64 loss: -1.5026330947875977
Batch 44/64 loss: -0.9866666793823242
Batch 45/64 loss: -1.548604965209961
Batch 46/64 loss: -1.5080270767211914
Batch 47/64 loss: -1.2878303527832031
Batch 48/64 loss: -1.091090202331543
Batch 49/64 loss: -1.3000249862670898
Batch 50/64 loss: -1.3018608093261719
Batch 51/64 loss: -1.3909721374511719
Batch 52/64 loss: -1.5502233505249023
Batch 53/64 loss: -0.9870624542236328
Batch 54/64 loss: -1.1037521362304688
Batch 55/64 loss: -0.9948196411132812
Batch 56/64 loss: -1.1018075942993164
Batch 57/64 loss: -1.3748464584350586
Batch 58/64 loss: -0.4896583557128906
Batch 59/64 loss: -1.6367464065551758
Batch 60/64 loss: -1.0775117874145508
Batch 61/64 loss: -1.0713281631469727
Batch 62/64 loss: -0.7290744781494141
Batch 63/64 loss: -0.7708473205566406
Batch 64/64 loss: -5.268133163452148
Epoch 148  Train loss: -1.2089823629341874  Val loss: -1.0640374278694493
Epoch 149
-------------------------------
Batch 1/64 loss: -1.4166345596313477
Batch 2/64 loss: -1.183889389038086
Batch 3/64 loss: -1.0947046279907227
Batch 4/64 loss: -0.00913238525390625
Batch 5/64 loss: -0.9476785659790039
Batch 6/64 loss: -1.1108837127685547
Batch 7/64 loss: -0.9652976989746094
Batch 8/64 loss: -1.2208223342895508
Batch 9/64 loss: -0.2278575897216797
Batch 10/64 loss: -1.022690773010254
Batch 11/64 loss: -1.2828607559204102
Batch 12/64 loss: -0.4934835433959961
Batch 13/64 loss: -0.6527538299560547
Batch 14/64 loss: -1.011305809020996
Batch 15/64 loss: -1.3806943893432617
Batch 16/64 loss: -1.1829099655151367
Batch 17/64 loss: -1.0649700164794922
Batch 18/64 loss: -1.1579484939575195
Batch 19/64 loss: -0.7621421813964844
Batch 20/64 loss: -1.5197858810424805
Batch 21/64 loss: -0.09191322326660156
Batch 22/64 loss: -0.8744258880615234
Batch 23/64 loss: -1.319284439086914
Batch 24/64 loss: -1.3081474304199219
Batch 25/64 loss: -1.446742057800293
Batch 26/64 loss: -1.2282323837280273
Batch 27/64 loss: -1.2116222381591797
Batch 28/64 loss: -1.4972286224365234
Batch 29/64 loss: -1.3029260635375977
Batch 30/64 loss: -1.4586668014526367
Batch 31/64 loss: -1.2721900939941406
Batch 32/64 loss: -1.3459482192993164
Batch 33/64 loss: -0.3129415512084961
Batch 34/64 loss: -1.3935546875
Batch 35/64 loss: -0.5745992660522461
Batch 36/64 loss: -0.7697439193725586
Batch 37/64 loss: -0.2901792526245117
Batch 38/64 loss: -1.4595975875854492
Batch 39/64 loss: -0.7359428405761719
Batch 40/64 loss: -1.3851642608642578
Batch 41/64 loss: -0.7819232940673828
Batch 42/64 loss: -1.5349273681640625
Batch 43/64 loss: -1.2657604217529297
Batch 44/64 loss: -0.4822092056274414
Batch 45/64 loss: -1.16845703125
Batch 46/64 loss: -1.4935922622680664
Batch 47/64 loss: -1.155111312866211
Batch 48/64 loss: -0.9638967514038086
Batch 49/64 loss: -1.3279333114624023
Batch 50/64 loss: -1.3124637603759766
Batch 51/64 loss: -1.2213306427001953
Batch 52/64 loss: -1.5061168670654297
Batch 53/64 loss: -0.9609193801879883
Batch 54/64 loss: -1.1447172164916992
Batch 55/64 loss: -1.028782844543457
Batch 56/64 loss: -1.1535348892211914
Batch 57/64 loss: -1.4208621978759766
Batch 58/64 loss: -1.1795148849487305
Batch 59/64 loss: -1.1997241973876953
Batch 60/64 loss: -1.3605670928955078
Batch 61/64 loss: -1.5895986557006836
Batch 62/64 loss: -1.1887035369873047
Batch 63/64 loss: -0.8011198043823242
Batch 64/64 loss: -5.3370513916015625
Epoch 149  Train loss: -1.1330518086751302  Val loss: -1.4646447171869965
Epoch 150
-------------------------------
Batch 1/64 loss: -1.2752685546875
Batch 2/64 loss: -1.473475456237793
Batch 3/64 loss: -1.2099885940551758
Batch 4/64 loss: -0.7818708419799805
Batch 5/64 loss: -1.183089256286621
Batch 6/64 loss: -1.1465644836425781
Batch 7/64 loss: -0.9585971832275391
Batch 8/64 loss: -1.5431833267211914
Batch 9/64 loss: -1.5922842025756836
Batch 10/64 loss: -0.5800561904907227
Batch 11/64 loss: -1.181295394897461
Batch 12/64 loss: -1.7131423950195312
Batch 13/64 loss: -0.4979515075683594
Batch 14/64 loss: -1.4375934600830078
Batch 15/64 loss: -1.175816535949707
Batch 16/64 loss: -1.0527524948120117
Batch 17/64 loss: -1.5524311065673828
Batch 18/64 loss: -1.381516456604004
Batch 19/64 loss: -1.420792579650879
Batch 20/64 loss: -0.9842872619628906
Batch 21/64 loss: -1.2911100387573242
Batch 22/64 loss: -1.1294822692871094
Batch 23/64 loss: -0.9890556335449219
Batch 24/64 loss: -1.3265905380249023
Batch 25/64 loss: -1.4422569274902344
Batch 26/64 loss: -0.9974498748779297
Batch 27/64 loss: -0.41763973236083984
Batch 28/64 loss: -1.355086326599121
Batch 29/64 loss: -0.6883096694946289
Batch 30/64 loss: -1.1716241836547852
Batch 31/64 loss: -1.1713600158691406
Batch 32/64 loss: -0.7216291427612305
Batch 33/64 loss: -1.2762432098388672
Batch 34/64 loss: -1.2569255828857422
Batch 35/64 loss: -1.1500053405761719
Batch 36/64 loss: -1.412343978881836
Batch 37/64 loss: -1.279104232788086
Batch 38/64 loss: -1.2862663269042969
Batch 39/64 loss: -1.0793209075927734
Batch 40/64 loss: -1.2579212188720703
Batch 41/64 loss: -1.1500797271728516
Batch 42/64 loss: -1.0598068237304688
Batch 43/64 loss: -1.0342979431152344
Batch 44/64 loss: -0.3492012023925781
Batch 45/64 loss: -1.560159683227539
Batch 46/64 loss: -1.1449623107910156
Batch 47/64 loss: -1.1507930755615234
Batch 48/64 loss: -0.7425260543823242
Batch 49/64 loss: -1.2563848495483398
Batch 50/64 loss: -1.306447982788086
Batch 51/64 loss: -1.1480140686035156
Batch 52/64 loss: -0.9422616958618164
Batch 53/64 loss: -1.3158483505249023
Batch 54/64 loss: -1.4966344833374023
Batch 55/64 loss: -1.4346132278442383
Batch 56/64 loss: -0.9502811431884766
Batch 57/64 loss: -1.5494136810302734
Batch 58/64 loss: -1.2682313919067383
Batch 59/64 loss: -0.6108512878417969
Batch 60/64 loss: -1.605093002319336
Batch 61/64 loss: -1.418665885925293
Batch 62/64 loss: -1.208108901977539
Batch 63/64 loss: -1.3837499618530273
Batch 64/64 loss: -5.7426276206970215
Epoch 150  Train loss: -1.2272169393651626  Val loss: -1.5615257184530043
Epoch 151
-------------------------------
Batch 1/64 loss: -1.5834579467773438
Batch 2/64 loss: -1.2995595932006836
Batch 3/64 loss: -1.3924837112426758
Batch 4/64 loss: -1.5461673736572266
Batch 5/64 loss: -1.2821435928344727
Batch 6/64 loss: -1.335367202758789
Batch 7/64 loss: -1.4354133605957031
Batch 8/64 loss: -1.0576677322387695
Batch 9/64 loss: -1.4380512237548828
Batch 10/64 loss: -1.2741260528564453
Batch 11/64 loss: -0.8980751037597656
Batch 12/64 loss: -0.7598447799682617
Batch 13/64 loss: -1.1816492080688477
Batch 14/64 loss: -1.5605173110961914
Batch 15/64 loss: -1.3766965866088867
Batch 16/64 loss: -1.2626094818115234
Batch 17/64 loss: -1.2737512588500977
Batch 18/64 loss: -1.2432899475097656
Batch 19/64 loss: -1.1041603088378906
Batch 20/64 loss: -1.6265287399291992
Batch 21/64 loss: -0.8300561904907227
Batch 22/64 loss: -1.3938093185424805
Batch 23/64 loss: -1.2520322799682617
Batch 24/64 loss: -0.7420587539672852
Batch 25/64 loss: -1.3469572067260742
Batch 26/64 loss: -1.5134544372558594
Batch 27/64 loss: -1.3342370986938477
Batch 28/64 loss: -1.283015251159668
Batch 29/64 loss: -1.3773984909057617
Batch 30/64 loss: -1.424520492553711
Batch 31/64 loss: -1.1216983795166016
Batch 32/64 loss: -1.4106826782226562
Batch 33/64 loss: -0.24626445770263672
Batch 34/64 loss: -1.4054746627807617
Batch 35/64 loss: -0.8248205184936523
Batch 36/64 loss: -1.7606592178344727
Batch 37/64 loss: -1.4963226318359375
Batch 38/64 loss: -1.4519062042236328
Batch 39/64 loss: -1.4099159240722656
Batch 40/64 loss: -1.0801496505737305
Batch 41/64 loss: -1.5144987106323242
Batch 42/64 loss: -1.4864816665649414
Batch 43/64 loss: -1.339564323425293
Batch 44/64 loss: -1.4117259979248047
Batch 45/64 loss: -1.182413101196289
Batch 46/64 loss: -1.2661142349243164
Batch 47/64 loss: -1.619288444519043
Batch 48/64 loss: -1.0164155960083008
Batch 49/64 loss: -1.540358543395996
Batch 50/64 loss: -1.4115943908691406
Batch 51/64 loss: -1.625168800354004
Batch 52/64 loss: -1.2403182983398438
Batch 53/64 loss: -1.1423845291137695
Batch 54/64 loss: -1.0934104919433594
Batch 55/64 loss: -1.7170333862304688
Batch 56/64 loss: -1.4271354675292969
Batch 57/64 loss: -1.330143928527832
Batch 58/64 loss: -1.6079130172729492
Batch 59/64 loss: -1.516153335571289
Batch 60/64 loss: -1.442068099975586
Batch 61/64 loss: -1.5482769012451172
Batch 62/64 loss: -0.9178562164306641
Batch 63/64 loss: -1.1425657272338867
Batch 64/64 loss: -5.5204572677612305
Epoch 151  Train loss: -1.3539799297557158  Val loss: -1.826394333462535
Saving best model, epoch: 151
Epoch 152
-------------------------------
Batch 1/64 loss: -1.5758256912231445
Batch 2/64 loss: -1.8095684051513672
Batch 3/64 loss: -1.2896976470947266
Batch 4/64 loss: -0.9932031631469727
Batch 5/64 loss: -1.6538562774658203
Batch 6/64 loss: -1.4425086975097656
Batch 7/64 loss: -1.2914094924926758
Batch 8/64 loss: -1.1533288955688477
Batch 9/64 loss: -1.269383430480957
Batch 10/64 loss: -1.6691179275512695
Batch 11/64 loss: -1.2508611679077148
Batch 12/64 loss: -1.159409523010254
Batch 13/64 loss: -1.6269912719726562
Batch 14/64 loss: -1.3253707885742188
Batch 15/64 loss: -0.2004556655883789
Batch 16/64 loss: -1.7725372314453125
Batch 17/64 loss: -1.5948591232299805
Batch 18/64 loss: -1.647714614868164
Batch 19/64 loss: -1.577336311340332
Batch 20/64 loss: -1.4957809448242188
Batch 21/64 loss: -1.2503290176391602
Batch 22/64 loss: -1.2331771850585938
Batch 23/64 loss: -1.446131706237793
Batch 24/64 loss: -1.496485710144043
Batch 25/64 loss: -1.483841896057129
Batch 26/64 loss: -1.504323959350586
Batch 27/64 loss: -1.4867267608642578
Batch 28/64 loss: -1.689131736755371
Batch 29/64 loss: -1.484705924987793
Batch 30/64 loss: -1.0295753479003906
Batch 31/64 loss: -1.8660573959350586
Batch 32/64 loss: -1.4414520263671875
Batch 33/64 loss: -1.6180238723754883
Batch 34/64 loss: -1.190298080444336
Batch 35/64 loss: -1.5209484100341797
Batch 36/64 loss: -1.3998699188232422
Batch 37/64 loss: -1.1569347381591797
Batch 38/64 loss: -1.620274543762207
Batch 39/64 loss: -1.208867073059082
Batch 40/64 loss: -1.2678842544555664
Batch 41/64 loss: -1.638991355895996
Batch 42/64 loss: -0.966853141784668
Batch 43/64 loss: -1.4049615859985352
Batch 44/64 loss: -1.2749528884887695
Batch 45/64 loss: -1.5683517456054688
Batch 46/64 loss: -1.2660856246948242
Batch 47/64 loss: -0.7493066787719727
Batch 48/64 loss: -1.0676202774047852
Batch 49/64 loss: -1.22607421875
Batch 50/64 loss: -1.246377944946289
Batch 51/64 loss: -1.290867805480957
Batch 52/64 loss: -1.1743078231811523
Batch 53/64 loss: -1.3905868530273438
Batch 54/64 loss: -1.4126482009887695
Batch 55/64 loss: -1.621964454650879
Batch 56/64 loss: -1.3154716491699219
Batch 57/64 loss: -1.1870088577270508
Batch 58/64 loss: -1.549271583557129
Batch 59/64 loss: -1.413437843322754
Batch 60/64 loss: -1.5826692581176758
Batch 61/64 loss: -1.6517696380615234
Batch 62/64 loss: -1.1341943740844727
Batch 63/64 loss: -1.6466007232666016
Batch 64/64 loss: -5.7018327713012695
Epoch 152  Train loss: -1.431388312695073  Val loss: -1.7119603894420505
Epoch 153
-------------------------------
Batch 1/64 loss: -1.5750617980957031
Batch 2/64 loss: -1.4021062850952148
Batch 3/64 loss: -1.7698554992675781
Batch 4/64 loss: -0.8270988464355469
Batch 5/64 loss: -1.7029170989990234
Batch 6/64 loss: -1.7670917510986328
Batch 7/64 loss: -1.708108901977539
Batch 8/64 loss: -1.6624345779418945
Batch 9/64 loss: -1.3452072143554688
Batch 10/64 loss: -1.4536972045898438
Batch 11/64 loss: -1.3147869110107422
Batch 12/64 loss: -1.1625680923461914
Batch 13/64 loss: -1.5072526931762695
Batch 14/64 loss: -1.7430572509765625
Batch 15/64 loss: -1.9964570999145508
Batch 16/64 loss: -1.472245216369629
Batch 17/64 loss: -1.6825761795043945
Batch 18/64 loss: -1.817509651184082
Batch 19/64 loss: -1.7385482788085938
Batch 20/64 loss: -1.7562322616577148
Batch 21/64 loss: -1.7659492492675781
Batch 22/64 loss: -1.882284164428711
Batch 23/64 loss: -1.5254440307617188
Batch 24/64 loss: -0.7636098861694336
Batch 25/64 loss: -1.6477022171020508
Batch 26/64 loss: -1.5269145965576172
Batch 27/64 loss: -1.4364566802978516
Batch 28/64 loss: -1.6776123046875
Batch 29/64 loss: -1.4158344268798828
Batch 30/64 loss: -1.3335151672363281
Batch 31/64 loss: -1.5778923034667969
Batch 32/64 loss: -1.3554010391235352
Batch 33/64 loss: -1.8147878646850586
Batch 34/64 loss: -1.2360601425170898
Batch 35/64 loss: -1.739302635192871
Batch 36/64 loss: -1.3733062744140625
Batch 37/64 loss: -1.2413063049316406
Batch 38/64 loss: -1.258230209350586
Batch 39/64 loss: -0.9623985290527344
Batch 40/64 loss: -1.6143598556518555
Batch 41/64 loss: -1.115330696105957
Batch 42/64 loss: -1.3147258758544922
Batch 43/64 loss: -1.3263139724731445
Batch 44/64 loss: -1.3090410232543945
Batch 45/64 loss: -1.4322881698608398
Batch 46/64 loss: -1.1393442153930664
Batch 47/64 loss: -1.089402198791504
Batch 48/64 loss: -0.9457492828369141
Batch 49/64 loss: -0.8560791015625
Batch 50/64 loss: -1.0873126983642578
Batch 51/64 loss: -1.409449577331543
Batch 52/64 loss: 0.17583751678466797
Batch 53/64 loss: -1.2228507995605469
Batch 54/64 loss: -0.4173908233642578
Batch 55/64 loss: -0.9198160171508789
Batch 56/64 loss: -1.2561874389648438
Batch 57/64 loss: -1.0756139755249023
Batch 58/64 loss: -1.0090007781982422
Batch 59/64 loss: -0.9086360931396484
Batch 60/64 loss: -1.2166976928710938
Batch 61/64 loss: -1.325871467590332
Batch 62/64 loss: -0.8661336898803711
Batch 63/64 loss: -1.6464719772338867
Batch 64/64 loss: -5.903875350952148
Epoch 153  Train loss: -1.4069797216677198  Val loss: -1.5438521998035128
Epoch 154
-------------------------------
Batch 1/64 loss: -1.4032907485961914
Batch 2/64 loss: -1.206258773803711
Batch 3/64 loss: -1.7385168075561523
Batch 4/64 loss: -1.327378273010254
Batch 5/64 loss: -1.4619436264038086
Batch 6/64 loss: -1.5613327026367188
Batch 7/64 loss: -1.554610252380371
Batch 8/64 loss: -0.39873600006103516
Batch 9/64 loss: -1.6825923919677734
Batch 10/64 loss: -1.5108509063720703
Batch 11/64 loss: -0.8592662811279297
Batch 12/64 loss: -1.398554801940918
Batch 13/64 loss: -1.2286930084228516
Batch 14/64 loss: -0.5619745254516602
Batch 15/64 loss: -0.6923551559448242
Batch 16/64 loss: -1.141261100769043
Batch 17/64 loss: -0.9649009704589844
Batch 18/64 loss: -1.2646150588989258
Batch 19/64 loss: -1.1447181701660156
Batch 20/64 loss: -1.1173076629638672
Batch 21/64 loss: -1.5468416213989258
Batch 22/64 loss: -0.7846899032592773
Batch 23/64 loss: -1.5821313858032227
Batch 24/64 loss: -1.7119331359863281
Batch 25/64 loss: -1.6011219024658203
Batch 26/64 loss: -1.5399351119995117
Batch 27/64 loss: -1.278407096862793
Batch 28/64 loss: -1.4669189453125
Batch 29/64 loss: -0.7557773590087891
Batch 30/64 loss: -1.941518783569336
Batch 31/64 loss: -1.7097883224487305
Batch 32/64 loss: -0.9949274063110352
Batch 33/64 loss: -1.757965087890625
Batch 34/64 loss: -0.7700862884521484
Batch 35/64 loss: -1.6355161666870117
Batch 36/64 loss: -1.3210372924804688
Batch 37/64 loss: -1.5773820877075195
Batch 38/64 loss: -1.4284305572509766
Batch 39/64 loss: -1.4382810592651367
Batch 40/64 loss: -0.8951091766357422
Batch 41/64 loss: -1.4012689590454102
Batch 42/64 loss: -1.567622184753418
Batch 43/64 loss: -1.3157930374145508
Batch 44/64 loss: -1.6591739654541016
Batch 45/64 loss: -1.6176300048828125
Batch 46/64 loss: -1.4347352981567383
Batch 47/64 loss: -1.7392330169677734
Batch 48/64 loss: -1.5260467529296875
Batch 49/64 loss: -1.4953088760375977
Batch 50/64 loss: -1.1878728866577148
Batch 51/64 loss: -1.4715852737426758
Batch 52/64 loss: -1.4245624542236328
Batch 53/64 loss: -1.2466936111450195
Batch 54/64 loss: -1.824904441833496
Batch 55/64 loss: -0.9897661209106445
Batch 56/64 loss: -1.3747901916503906
Batch 57/64 loss: -1.4575986862182617
Batch 58/64 loss: -1.5644989013671875
Batch 59/64 loss: -1.5315361022949219
Batch 60/64 loss: -1.3439998626708984
Batch 61/64 loss: -1.073319435119629
Batch 62/64 loss: -1.4158554077148438
Batch 63/64 loss: -1.3317852020263672
Batch 64/64 loss: -5.921902179718018
Epoch 154  Train loss: -1.4022582465527105  Val loss: -1.5586626898382128
Epoch 155
-------------------------------
Batch 1/64 loss: -1.0628728866577148
Batch 2/64 loss: -1.0459089279174805
Batch 3/64 loss: -1.5221176147460938
Batch 4/64 loss: -0.7267780303955078
Batch 5/64 loss: -1.6148672103881836
Batch 6/64 loss: -1.1168746948242188
Batch 7/64 loss: -1.2285871505737305
Batch 8/64 loss: -1.1703004837036133
Batch 9/64 loss: -1.2479896545410156
Batch 10/64 loss: -1.2198753356933594
Batch 11/64 loss: -1.3069448471069336
Batch 12/64 loss: -1.553192138671875
Batch 13/64 loss: -1.584151268005371
Batch 14/64 loss: -1.6495475769042969
Batch 15/64 loss: -1.6201591491699219
Batch 16/64 loss: -1.0851850509643555
Batch 17/64 loss: -0.8998556137084961
Batch 18/64 loss: -1.2972564697265625
Batch 19/64 loss: -1.6343498229980469
Batch 20/64 loss: -1.631032943725586
Batch 21/64 loss: -1.7401533126831055
Batch 22/64 loss: -1.5513668060302734
Batch 23/64 loss: -1.2973394393920898
Batch 24/64 loss: -1.4231929779052734
Batch 25/64 loss: -1.370896339416504
Batch 26/64 loss: -1.4594478607177734
Batch 27/64 loss: -1.7100372314453125
Batch 28/64 loss: -1.556899070739746
Batch 29/64 loss: -1.4263858795166016
Batch 30/64 loss: -1.2380599975585938
Batch 31/64 loss: -0.9685764312744141
Batch 32/64 loss: -1.390528678894043
Batch 33/64 loss: -1.4418315887451172
Batch 34/64 loss: -1.78045654296875
Batch 35/64 loss: -1.4699172973632812
Batch 36/64 loss: -1.5083723068237305
Batch 37/64 loss: -1.239065170288086
Batch 38/64 loss: -1.7845067977905273
Batch 39/64 loss: -1.2386455535888672
Batch 40/64 loss: -0.9317808151245117
Batch 41/64 loss: -1.317702293395996
Batch 42/64 loss: -1.2549448013305664
Batch 43/64 loss: -1.460653305053711
Batch 44/64 loss: -0.8850507736206055
Batch 45/64 loss: -1.481551170349121
Batch 46/64 loss: -1.4146766662597656
Batch 47/64 loss: -1.036397933959961
Batch 48/64 loss: -1.5354671478271484
Batch 49/64 loss: -1.639669418334961
Batch 50/64 loss: -1.2837371826171875
Batch 51/64 loss: -1.1796960830688477
Batch 52/64 loss: -1.5507726669311523
Batch 53/64 loss: -1.6646766662597656
Batch 54/64 loss: -1.5523481369018555
Batch 55/64 loss: -0.9934024810791016
Batch 56/64 loss: -1.6203670501708984
Batch 57/64 loss: -1.464756965637207
Batch 58/64 loss: -1.310084342956543
Batch 59/64 loss: -1.646162986755371
Batch 60/64 loss: -1.2605562210083008
Batch 61/64 loss: -1.676203727722168
Batch 62/64 loss: -1.2205801010131836
Batch 63/64 loss: -1.3642520904541016
Batch 64/64 loss: -5.852675437927246
Epoch 155  Train loss: -1.4266435099583046  Val loss: -1.8436480781057036
Saving best model, epoch: 155
Epoch 156
-------------------------------
Batch 1/64 loss: -1.837794303894043
Batch 2/64 loss: -1.7981481552124023
Batch 3/64 loss: -1.6272954940795898
Batch 4/64 loss: -1.5386619567871094
Batch 5/64 loss: -0.5554523468017578
Batch 6/64 loss: -1.4129819869995117
Batch 7/64 loss: -1.6599664688110352
Batch 8/64 loss: -1.5549278259277344
Batch 9/64 loss: -1.7275667190551758
Batch 10/64 loss: -1.4868135452270508
Batch 11/64 loss: -1.2464475631713867
Batch 12/64 loss: -1.5761728286743164
Batch 13/64 loss: -1.154646873474121
Batch 14/64 loss: -1.2953824996948242
Batch 15/64 loss: -1.6264123916625977
Batch 16/64 loss: -1.351424217224121
Batch 17/64 loss: -1.3882904052734375
Batch 18/64 loss: -1.7216997146606445
Batch 19/64 loss: -1.6477508544921875
Batch 20/64 loss: -1.5578012466430664
Batch 21/64 loss: -1.5850677490234375
Batch 22/64 loss: -1.6667289733886719
Batch 23/64 loss: -1.3897266387939453
Batch 24/64 loss: -1.6378917694091797
Batch 25/64 loss: -0.9148597717285156
Batch 26/64 loss: -1.5468568801879883
Batch 27/64 loss: -1.179396629333496
Batch 28/64 loss: -1.3980140686035156
Batch 29/64 loss: -1.2222537994384766
Batch 30/64 loss: -1.6358509063720703
Batch 31/64 loss: -1.4960355758666992
Batch 32/64 loss: -1.4908943176269531
Batch 33/64 loss: -1.3809776306152344
Batch 34/64 loss: -1.298360824584961
Batch 35/64 loss: -1.4650354385375977
Batch 36/64 loss: -1.1307363510131836
Batch 37/64 loss: -1.411611557006836
Batch 38/64 loss: -1.4256086349487305
Batch 39/64 loss: -1.3114509582519531
Batch 40/64 loss: -1.8531856536865234
Batch 41/64 loss: -1.6358366012573242
Batch 42/64 loss: -1.4970788955688477
Batch 43/64 loss: -1.6936626434326172
Batch 44/64 loss: -0.9501447677612305
Batch 45/64 loss: -1.1409015655517578
Batch 46/64 loss: -1.448378562927246
Batch 47/64 loss: -1.3447513580322266
Batch 48/64 loss: -1.492182731628418
Batch 49/64 loss: -1.3988323211669922
Batch 50/64 loss: -1.671004295349121
Batch 51/64 loss: -1.3411474227905273
Batch 52/64 loss: -1.3189544677734375
Batch 53/64 loss: -1.621098518371582
Batch 54/64 loss: -1.4604730606079102
Batch 55/64 loss: -0.41722965240478516
Batch 56/64 loss: -1.6036005020141602
Batch 57/64 loss: -1.4695777893066406
Batch 58/64 loss: -1.562957763671875
Batch 59/64 loss: -0.7521448135375977
Batch 60/64 loss: -1.6706809997558594
Batch 61/64 loss: -1.5971717834472656
Batch 62/64 loss: -1.7539339065551758
Batch 63/64 loss: -1.5774850845336914
Batch 64/64 loss: -5.680418491363525
Epoch 156  Train loss: -1.48840352787691  Val loss: -1.7877956534579038
Epoch 157
-------------------------------
Batch 1/64 loss: -1.472421646118164
Batch 2/64 loss: -1.584303855895996
Batch 3/64 loss: -1.7107534408569336
Batch 4/64 loss: -0.8917522430419922
Batch 5/64 loss: -1.4809226989746094
Batch 6/64 loss: -1.0978727340698242
Batch 7/64 loss: -1.5261850357055664
Batch 8/64 loss: -1.5501651763916016
Batch 9/64 loss: -1.584630012512207
Batch 10/64 loss: -1.8507699966430664
Batch 11/64 loss: -1.3700199127197266
Batch 12/64 loss: -1.7288789749145508
Batch 13/64 loss: -1.3971290588378906
Batch 14/64 loss: -1.1740541458129883
Batch 15/64 loss: -1.557973861694336
Batch 16/64 loss: -1.6128339767456055
Batch 17/64 loss: -1.4895515441894531
Batch 18/64 loss: -1.4351749420166016
Batch 19/64 loss: -1.2900609970092773
Batch 20/64 loss: -1.4686956405639648
Batch 21/64 loss: -1.0999784469604492
Batch 22/64 loss: -1.0099067687988281
Batch 23/64 loss: -1.659571647644043
Batch 24/64 loss: -1.2757444381713867
Batch 25/64 loss: -1.461787223815918
Batch 26/64 loss: -1.371164321899414
Batch 27/64 loss: -1.6568164825439453
Batch 28/64 loss: -1.2765913009643555
Batch 29/64 loss: -1.7071762084960938
Batch 30/64 loss: -1.5411643981933594
Batch 31/64 loss: -1.1082477569580078
Batch 32/64 loss: -1.3679800033569336
Batch 33/64 loss: -1.492605209350586
Batch 34/64 loss: -1.4125280380249023
Batch 35/64 loss: -1.3493242263793945
Batch 36/64 loss: -1.187417984008789
Batch 37/64 loss: -1.672602653503418
Batch 38/64 loss: -1.6468610763549805
Batch 39/64 loss: -1.8892440795898438
Batch 40/64 loss: -1.278914451599121
Batch 41/64 loss: -1.1906747817993164
Batch 42/64 loss: -1.7269935607910156
Batch 43/64 loss: -0.9746026992797852
Batch 44/64 loss: -1.3157262802124023
Batch 45/64 loss: -1.507761001586914
Batch 46/64 loss: -1.432443618774414
Batch 47/64 loss: -1.5473594665527344
Batch 48/64 loss: -0.9628114700317383
Batch 49/64 loss: -1.0262060165405273
Batch 50/64 loss: -0.10371971130371094
Batch 51/64 loss: -1.6623411178588867
Batch 52/64 loss: -0.966425895690918
Batch 53/64 loss: -0.9981231689453125
Batch 54/64 loss: -1.4292240142822266
Batch 55/64 loss: -1.2997150421142578
Batch 56/64 loss: -1.0830259323120117
Batch 57/64 loss: -1.2424488067626953
Batch 58/64 loss: -1.6459951400756836
Batch 59/64 loss: -1.5042142868041992
Batch 60/64 loss: -1.1927604675292969
Batch 61/64 loss: -1.5931873321533203
Batch 62/64 loss: -1.5085926055908203
Batch 63/64 loss: -1.3341875076293945
Batch 64/64 loss: -5.574307918548584
Epoch 157  Train loss: -1.430102705488018  Val loss: -1.770399886717911
Epoch 158
-------------------------------
Batch 1/64 loss: -1.8282623291015625
Batch 2/64 loss: -1.6715192794799805
Batch 3/64 loss: -1.313704490661621
Batch 4/64 loss: -1.3590450286865234
Batch 5/64 loss: -1.3467178344726562
Batch 6/64 loss: -1.4999761581420898
Batch 7/64 loss: -1.3192310333251953
Batch 8/64 loss: -1.8278436660766602
Batch 9/64 loss: -1.4691944122314453
Batch 10/64 loss: -1.1106386184692383
Batch 11/64 loss: -1.5330238342285156
Batch 12/64 loss: -1.3560924530029297
Batch 13/64 loss: -1.4282341003417969
Batch 14/64 loss: -1.1172513961791992
Batch 15/64 loss: -1.473611831665039
Batch 16/64 loss: -1.3627166748046875
Batch 17/64 loss: -1.4145946502685547
Batch 18/64 loss: -0.5958414077758789
Batch 19/64 loss: -1.4939651489257812
Batch 20/64 loss: -1.2255182266235352
Batch 21/64 loss: -1.223358154296875
Batch 22/64 loss: -1.5367059707641602
Batch 23/64 loss: -1.3095779418945312
Batch 24/64 loss: -1.3911504745483398
Batch 25/64 loss: -1.3740959167480469
Batch 26/64 loss: -1.2798995971679688
Batch 27/64 loss: -1.2135887145996094
Batch 28/64 loss: -1.3739356994628906
Batch 29/64 loss: -1.2745447158813477
Batch 30/64 loss: -1.610391616821289
Batch 31/64 loss: -1.411219596862793
Batch 32/64 loss: -1.4517927169799805
Batch 33/64 loss: -1.3082265853881836
Batch 34/64 loss: -1.6876029968261719
Batch 35/64 loss: -1.1451444625854492
Batch 36/64 loss: -1.279958724975586
Batch 37/64 loss: -0.8788881301879883
Batch 38/64 loss: -1.5713214874267578
Batch 39/64 loss: -1.4653854370117188
Batch 40/64 loss: -1.4313135147094727
Batch 41/64 loss: -0.7932825088500977
Batch 42/64 loss: -1.3667964935302734
Batch 43/64 loss: -1.3378934860229492
Batch 44/64 loss: -1.3727197647094727
Batch 45/64 loss: -1.125950813293457
Batch 46/64 loss: -1.2708911895751953
Batch 47/64 loss: -1.4973115921020508
Batch 48/64 loss: -1.6946086883544922
Batch 49/64 loss: -1.617356300354004
Batch 50/64 loss: -0.9697322845458984
Batch 51/64 loss: -1.5528898239135742
Batch 52/64 loss: -1.399789810180664
Batch 53/64 loss: -1.3664827346801758
Batch 54/64 loss: -1.3484258651733398
Batch 55/64 loss: -1.5380964279174805
Batch 56/64 loss: -1.5393266677856445
Batch 57/64 loss: -0.9160833358764648
Batch 58/64 loss: -1.6422758102416992
Batch 59/64 loss: -1.2991828918457031
Batch 60/64 loss: -1.4763898849487305
Batch 61/64 loss: -1.5010652542114258
Batch 62/64 loss: -0.9315376281738281
Batch 63/64 loss: -1.7642059326171875
Batch 64/64 loss: -5.922924041748047
Epoch 158  Train loss: -1.4232089921539905  Val loss: -1.6547522659563936
Epoch 159
-------------------------------
Batch 1/64 loss: -1.482438087463379
Batch 2/64 loss: -1.3363218307495117
Batch 3/64 loss: -1.55535888671875
Batch 4/64 loss: -1.1682634353637695
Batch 5/64 loss: -1.7536602020263672
Batch 6/64 loss: -1.5787296295166016
Batch 7/64 loss: -1.501215934753418
Batch 8/64 loss: -1.5114707946777344
Batch 9/64 loss: -1.5329275131225586
Batch 10/64 loss: -1.4373722076416016
Batch 11/64 loss: -1.540562629699707
Batch 12/64 loss: -1.7332305908203125
Batch 13/64 loss: -0.712428092956543
Batch 14/64 loss: -1.4742345809936523
Batch 15/64 loss: -1.5263166427612305
Batch 16/64 loss: -1.6380805969238281
Batch 17/64 loss: -1.1516780853271484
Batch 18/64 loss: -1.1869115829467773
Batch 19/64 loss: -1.5190467834472656
Batch 20/64 loss: -1.6056833267211914
Batch 21/64 loss: -1.4653825759887695
Batch 22/64 loss: -1.4354686737060547
Batch 23/64 loss: -1.148787498474121
Batch 24/64 loss: -0.8983125686645508
Batch 25/64 loss: -1.6431636810302734
Batch 26/64 loss: -1.8396778106689453
Batch 27/64 loss: -1.8712043762207031
Batch 28/64 loss: -1.9135446548461914
Batch 29/64 loss: -1.6079597473144531
Batch 30/64 loss: -1.5281991958618164
Batch 31/64 loss: -1.7680482864379883
Batch 32/64 loss: -1.4462451934814453
Batch 33/64 loss: -1.685476303100586
Batch 34/64 loss: -1.6927404403686523
Batch 35/64 loss: -1.7592287063598633
Batch 36/64 loss: -1.6022357940673828
Batch 37/64 loss: -1.4715280532836914
Batch 38/64 loss: -1.6964759826660156
Batch 39/64 loss: -1.768829345703125
Batch 40/64 loss: -1.544184684753418
Batch 41/64 loss: -1.811981201171875
Batch 42/64 loss: -1.224869728088379
Batch 43/64 loss: -1.016000747680664
Batch 44/64 loss: -1.4790630340576172
Batch 45/64 loss: -1.6566495895385742
Batch 46/64 loss: -1.6041374206542969
Batch 47/64 loss: -1.3841495513916016
Batch 48/64 loss: -1.3569879531860352
Batch 49/64 loss: -1.4989128112792969
Batch 50/64 loss: -1.7033185958862305
Batch 51/64 loss: -1.491868019104004
Batch 52/64 loss: -1.5111198425292969
Batch 53/64 loss: -1.184804916381836
Batch 54/64 loss: -1.149601936340332
Batch 55/64 loss: -1.2925386428833008
Batch 56/64 loss: -1.6099796295166016
Batch 57/64 loss: -1.5248174667358398
Batch 58/64 loss: -1.4316816329956055
Batch 59/64 loss: -1.6939716339111328
Batch 60/64 loss: -1.6261873245239258
Batch 61/64 loss: -1.4923582077026367
Batch 62/64 loss: -1.6811017990112305
Batch 63/64 loss: -1.3253612518310547
Batch 64/64 loss: -5.702190399169922
Epoch 159  Train loss: -1.5491879332299325  Val loss: -1.8443521715931057
Saving best model, epoch: 159
Epoch 160
-------------------------------
Batch 1/64 loss: -0.9457664489746094
Batch 2/64 loss: -1.599609375
Batch 3/64 loss: -1.6963510513305664
Batch 4/64 loss: -1.5184574127197266
Batch 5/64 loss: -0.84539794921875
Batch 6/64 loss: -1.6705684661865234
Batch 7/64 loss: -1.772073745727539
Batch 8/64 loss: -0.9950990676879883
Batch 9/64 loss: -1.4129362106323242
Batch 10/64 loss: -1.5345773696899414
Batch 11/64 loss: -1.845860481262207
Batch 12/64 loss: -1.3734798431396484
Batch 13/64 loss: -1.4406805038452148
Batch 14/64 loss: -1.7698354721069336
Batch 15/64 loss: -1.6635007858276367
Batch 16/64 loss: -1.7087278366088867
Batch 17/64 loss: -1.6103754043579102
Batch 18/64 loss: -1.7451066970825195
Batch 19/64 loss: -0.9285726547241211
Batch 20/64 loss: -1.7625732421875
Batch 21/64 loss: -1.379624366760254
Batch 22/64 loss: -1.6708078384399414
Batch 23/64 loss: -1.7151851654052734
Batch 24/64 loss: -1.5818138122558594
Batch 25/64 loss: -1.6820554733276367
Batch 26/64 loss: -1.4752788543701172
Batch 27/64 loss: -1.6886720657348633
Batch 28/64 loss: -1.528132438659668
Batch 29/64 loss: -1.1641120910644531
Batch 30/64 loss: -1.1944465637207031
Batch 31/64 loss: -1.106684684753418
Batch 32/64 loss: -1.4828262329101562
Batch 33/64 loss: -1.7429380416870117
Batch 34/64 loss: -1.3665246963500977
Batch 35/64 loss: -1.6723175048828125
Batch 36/64 loss: -1.6821098327636719
Batch 37/64 loss: -1.490920066833496
Batch 38/64 loss: -1.6678876876831055
Batch 39/64 loss: -1.5192899703979492
Batch 40/64 loss: -1.347681999206543
Batch 41/64 loss: -1.179366111755371
Batch 42/64 loss: -0.9568500518798828
Batch 43/64 loss: -1.1971378326416016
Batch 44/64 loss: -1.6480722427368164
Batch 45/64 loss: -1.3483524322509766
Batch 46/64 loss: -1.2402477264404297
Batch 47/64 loss: -1.4539918899536133
Batch 48/64 loss: -1.099710464477539
Batch 49/64 loss: -1.9036922454833984
Batch 50/64 loss: -1.5461664199829102
Batch 51/64 loss: -1.4977903366088867
Batch 52/64 loss: -1.6174421310424805
Batch 53/64 loss: -1.197007179260254
Batch 54/64 loss: -1.4796905517578125
Batch 55/64 loss: -1.4914054870605469
Batch 56/64 loss: -1.5081233978271484
Batch 57/64 loss: -1.7543811798095703
Batch 58/64 loss: -1.5745668411254883
Batch 59/64 loss: -1.2221431732177734
Batch 60/64 loss: -1.356654167175293
Batch 61/64 loss: -1.1587600708007812
Batch 62/64 loss: -1.4730033874511719
Batch 63/64 loss: -0.9021501541137695
Batch 64/64 loss: -5.4974565505981445
Epoch 160  Train loss: -1.504763251659917  Val loss: -1.6050815123463005
Epoch 161
-------------------------------
Batch 1/64 loss: -1.4685583114624023
Batch 2/64 loss: -0.8853034973144531
Batch 3/64 loss: -1.1847257614135742
Batch 4/64 loss: -1.2321081161499023
Batch 5/64 loss: -1.6440534591674805
Batch 6/64 loss: -1.3636608123779297
Batch 7/64 loss: -1.5908203125
Batch 8/64 loss: -1.4738378524780273
Batch 9/64 loss: -1.3952856063842773
Batch 10/64 loss: -1.263418197631836
Batch 11/64 loss: -1.6998100280761719
Batch 12/64 loss: -1.4165420532226562
Batch 13/64 loss: -1.711313247680664
Batch 14/64 loss: -1.6016302108764648
Batch 15/64 loss: -1.2897167205810547
Batch 16/64 loss: -1.2526826858520508
Batch 17/64 loss: -0.9349861145019531
Batch 18/64 loss: -0.8789205551147461
Batch 19/64 loss: -1.3980083465576172
Batch 20/64 loss: -1.3075132369995117
Batch 21/64 loss: -1.1103019714355469
Batch 22/64 loss: -1.5646839141845703
Batch 23/64 loss: -0.6300029754638672
Batch 24/64 loss: -1.6567907333374023
Batch 25/64 loss: -1.4524497985839844
Batch 26/64 loss: -1.0445737838745117
Batch 27/64 loss: -1.5307512283325195
Batch 28/64 loss: -1.1633491516113281
Batch 29/64 loss: -0.9217243194580078
Batch 30/64 loss: -1.4419317245483398
Batch 31/64 loss: -0.5482120513916016
Batch 32/64 loss: -1.0520868301391602
Batch 33/64 loss: -1.5662107467651367
Batch 34/64 loss: -1.5539331436157227
Batch 35/64 loss: -1.4164056777954102
Batch 36/64 loss: -1.326350212097168
Batch 37/64 loss: -0.5056304931640625
Batch 38/64 loss: -1.545496940612793
Batch 39/64 loss: -1.3601388931274414
Batch 40/64 loss: -1.292353630065918
Batch 41/64 loss: -1.6129264831542969
Batch 42/64 loss: -1.4620018005371094
Batch 43/64 loss: -1.3504695892333984
Batch 44/64 loss: -1.5612773895263672
Batch 45/64 loss: -1.5942068099975586
Batch 46/64 loss: -1.4816884994506836
Batch 47/64 loss: -0.7873077392578125
Batch 48/64 loss: -1.499424934387207
Batch 49/64 loss: -1.528207778930664
Batch 50/64 loss: -1.6166048049926758
Batch 51/64 loss: -1.5048952102661133
Batch 52/64 loss: -1.5829286575317383
Batch 53/64 loss: -1.672414779663086
Batch 54/64 loss: -1.4270992279052734
Batch 55/64 loss: -1.4035320281982422
Batch 56/64 loss: -1.4688796997070312
Batch 57/64 loss: -1.5993108749389648
Batch 58/64 loss: -1.4997262954711914
Batch 59/64 loss: -1.7106084823608398
Batch 60/64 loss: -1.0455398559570312
Batch 61/64 loss: -1.5816974639892578
Batch 62/64 loss: -1.460672378540039
Batch 63/64 loss: -1.5468358993530273
Batch 64/64 loss: -5.3326616287231445
Epoch 161  Train loss: -1.4066513921700272  Val loss: -1.8506130336486186
Saving best model, epoch: 161
Epoch 162
-------------------------------
Batch 1/64 loss: -1.5068426132202148
Batch 2/64 loss: -1.4396123886108398
Batch 3/64 loss: -1.6903839111328125
Batch 4/64 loss: -1.5776386260986328
Batch 5/64 loss: -1.074732780456543
Batch 6/64 loss: -1.163100242614746
Batch 7/64 loss: -1.70465087890625
Batch 8/64 loss: -1.8818359375
Batch 9/64 loss: -1.6542739868164062
Batch 10/64 loss: -1.9197816848754883
Batch 11/64 loss: -0.9176006317138672
Batch 12/64 loss: -1.5431327819824219
Batch 13/64 loss: -1.4963493347167969
Batch 14/64 loss: -1.4315414428710938
Batch 15/64 loss: -1.3216209411621094
Batch 16/64 loss: -1.8482332229614258
Batch 17/64 loss: -1.3945140838623047
Batch 18/64 loss: -1.3244667053222656
Batch 19/64 loss: -1.438115119934082
Batch 20/64 loss: -1.5688505172729492
Batch 21/64 loss: -1.2329273223876953
Batch 22/64 loss: -1.6902389526367188
Batch 23/64 loss: -1.3179073333740234
Batch 24/64 loss: -1.7154293060302734
Batch 25/64 loss: -1.5382184982299805
Batch 26/64 loss: -1.557326316833496
Batch 27/64 loss: -1.451472282409668
Batch 28/64 loss: -0.8492870330810547
Batch 29/64 loss: -1.7548713684082031
Batch 30/64 loss: -1.3162994384765625
Batch 31/64 loss: -0.8703498840332031
Batch 32/64 loss: -1.6801395416259766
Batch 33/64 loss: -1.3820075988769531
Batch 34/64 loss: -1.6163787841796875
Batch 35/64 loss: -1.2861242294311523
Batch 36/64 loss: -1.5523109436035156
Batch 37/64 loss: -1.6907329559326172
Batch 38/64 loss: -1.4023075103759766
Batch 39/64 loss: -1.6442575454711914
Batch 40/64 loss: -0.9520463943481445
Batch 41/64 loss: -1.691737174987793
Batch 42/64 loss: -1.2375621795654297
Batch 43/64 loss: -1.4872674942016602
Batch 44/64 loss: -1.5938234329223633
Batch 45/64 loss: -1.8523197174072266
Batch 46/64 loss: -1.5825023651123047
Batch 47/64 loss: -1.6617441177368164
Batch 48/64 loss: -1.289896011352539
Batch 49/64 loss: -0.7872610092163086
Batch 50/64 loss: -1.7707738876342773
Batch 51/64 loss: -1.8720922470092773
Batch 52/64 loss: -1.6521530151367188
Batch 53/64 loss: -1.4231157302856445
Batch 54/64 loss: -1.7819271087646484
Batch 55/64 loss: -1.7229032516479492
Batch 56/64 loss: -1.7817306518554688
Batch 57/64 loss: -1.3624839782714844
Batch 58/64 loss: -1.694441795349121
Batch 59/64 loss: -1.5720396041870117
Batch 60/64 loss: -1.726644515991211
Batch 61/64 loss: -1.7418508529663086
Batch 62/64 loss: -1.353257179260254
Batch 63/64 loss: -1.6766471862792969
Batch 64/64 loss: -5.731973171234131
Epoch 162  Train loss: -1.5531461248210832  Val loss: -1.8058281731359738
Epoch 163
-------------------------------
Batch 1/64 loss: -1.375946044921875
Batch 2/64 loss: -1.8617830276489258
Batch 3/64 loss: -1.6064262390136719
Batch 4/64 loss: -1.7173538208007812
Batch 5/64 loss: -1.5737428665161133
Batch 6/64 loss: -1.695145606994629
Batch 7/64 loss: -1.3561687469482422
Batch 8/64 loss: -1.7598514556884766
Batch 9/64 loss: -1.6663990020751953
Batch 10/64 loss: -1.4783868789672852
Batch 11/64 loss: -1.5774555206298828
Batch 12/64 loss: -1.5083398818969727
Batch 13/64 loss: -1.3815250396728516
Batch 14/64 loss: -1.7337141036987305
Batch 15/64 loss: -1.6629047393798828
Batch 16/64 loss: -1.6541748046875
Batch 17/64 loss: -1.7059392929077148
Batch 18/64 loss: -1.3264341354370117
Batch 19/64 loss: -1.5139446258544922
Batch 20/64 loss: -1.2819557189941406
Batch 21/64 loss: -1.7594451904296875
Batch 22/64 loss: -1.3421297073364258
Batch 23/64 loss: -1.3022537231445312
Batch 24/64 loss: -1.2190837860107422
Batch 25/64 loss: -1.4326505661010742
Batch 26/64 loss: -1.2990150451660156
Batch 27/64 loss: -1.0409250259399414
Batch 28/64 loss: -1.6713848114013672
Batch 29/64 loss: -1.036341667175293
Batch 30/64 loss: -1.6776695251464844
Batch 31/64 loss: -0.8185844421386719
Batch 32/64 loss: -0.8320226669311523
Batch 33/64 loss: -1.0932130813598633
Batch 34/64 loss: -1.6511802673339844
Batch 35/64 loss: -1.3202533721923828
Batch 36/64 loss: -1.6298437118530273
Batch 37/64 loss: -1.5978374481201172
Batch 38/64 loss: -1.191232681274414
Batch 39/64 loss: -1.540461540222168
Batch 40/64 loss: -1.5519990921020508
Batch 41/64 loss: -1.5215139389038086
Batch 42/64 loss: -1.2266063690185547
Batch 43/64 loss: -1.4067211151123047
Batch 44/64 loss: -1.192678451538086
Batch 45/64 loss: -1.3743629455566406
Batch 46/64 loss: -1.3727531433105469
Batch 47/64 loss: -1.4052963256835938
Batch 48/64 loss: -1.3198881149291992
Batch 49/64 loss: -1.1431455612182617
Batch 50/64 loss: -1.3916740417480469
Batch 51/64 loss: -1.2012214660644531
Batch 52/64 loss: -1.122314453125
Batch 53/64 loss: -1.6185951232910156
Batch 54/64 loss: -1.1039228439331055
Batch 55/64 loss: -1.3822240829467773
Batch 56/64 loss: -1.7397937774658203
Batch 57/64 loss: -0.5054521560668945
Batch 58/64 loss: -1.5625581741333008
Batch 59/64 loss: -1.6255455017089844
Batch 60/64 loss: -1.4407854080200195
Batch 61/64 loss: -1.6990089416503906
Batch 62/64 loss: -1.6024446487426758
Batch 63/64 loss: -1.7964973449707031
Batch 64/64 loss: -5.888192653656006
Epoch 163  Train loss: -1.484176742329317  Val loss: -1.6714928092825454
Epoch 164
-------------------------------
Batch 1/64 loss: -1.5550155639648438
Batch 2/64 loss: -1.3355979919433594
Batch 3/64 loss: -1.4748649597167969
Batch 4/64 loss: -1.3352108001708984
Batch 5/64 loss: -1.5457267761230469
Batch 6/64 loss: -1.4499359130859375
Batch 7/64 loss: -1.3323078155517578
Batch 8/64 loss: -1.372422218322754
Batch 9/64 loss: -1.7346153259277344
Batch 10/64 loss: -1.7212848663330078
Batch 11/64 loss: -1.2503108978271484
Batch 12/64 loss: -1.7242841720581055
Batch 13/64 loss: -1.2756309509277344
Batch 14/64 loss: -0.6886367797851562
Batch 15/64 loss: -1.6326837539672852
Batch 16/64 loss: -1.6217784881591797
Batch 17/64 loss: -1.3368844985961914
Batch 18/64 loss: -1.478102684020996
Batch 19/64 loss: -1.6576271057128906
Batch 20/64 loss: -1.2081518173217773
Batch 21/64 loss: -1.452256202697754
Batch 22/64 loss: -1.720001220703125
Batch 23/64 loss: -1.6181831359863281
Batch 24/64 loss: -1.8879928588867188
Batch 25/64 loss: -1.7950067520141602
Batch 26/64 loss: -1.482259750366211
Batch 27/64 loss: -1.5214548110961914
Batch 28/64 loss: -1.097193717956543
Batch 29/64 loss: -1.1465654373168945
Batch 30/64 loss: -1.0491323471069336
Batch 31/64 loss: -1.5004644393920898
Batch 32/64 loss: -1.6152563095092773
Batch 33/64 loss: -1.7107009887695312
Batch 34/64 loss: -1.5782976150512695
Batch 35/64 loss: -1.5482168197631836
Batch 36/64 loss: -1.5837211608886719
Batch 37/64 loss: -1.6481828689575195
Batch 38/64 loss: -1.8654251098632812
Batch 39/64 loss: -1.6898221969604492
Batch 40/64 loss: -1.6973991394042969
Batch 41/64 loss: -1.7360219955444336
Batch 42/64 loss: -1.7045707702636719
Batch 43/64 loss: -1.8187437057495117
Batch 44/64 loss: -1.6510114669799805
Batch 45/64 loss: -1.3661203384399414
Batch 46/64 loss: -1.7161455154418945
Batch 47/64 loss: -1.6826906204223633
Batch 48/64 loss: -1.1544685363769531
Batch 49/64 loss: -1.9227685928344727
Batch 50/64 loss: -1.7241525650024414
Batch 51/64 loss: -1.772104263305664
Batch 52/64 loss: -1.7876720428466797
Batch 53/64 loss: -1.8082408905029297
Batch 54/64 loss: -1.4951095581054688
Batch 55/64 loss: -1.6399116516113281
Batch 56/64 loss: -1.9664955139160156
Batch 57/64 loss: -1.6077508926391602
Batch 58/64 loss: -1.817723274230957
Batch 59/64 loss: -1.830735206604004
Batch 60/64 loss: -1.777876853942871
Batch 61/64 loss: -1.2167978286743164
Batch 62/64 loss: -1.9594306945800781
Batch 63/64 loss: -1.6384258270263672
Batch 64/64 loss: -5.913837909698486
Epoch 164  Train loss: -1.6183365223454493  Val loss: -1.9903058841875738
Saving best model, epoch: 164
Epoch 165
-------------------------------
Batch 1/64 loss: -1.3330907821655273
Batch 2/64 loss: -1.8649559020996094
Batch 3/64 loss: -1.9076528549194336
Batch 4/64 loss: -1.891836166381836
Batch 5/64 loss: -1.2969169616699219
Batch 6/64 loss: -1.6602134704589844
Batch 7/64 loss: -1.6988649368286133
Batch 8/64 loss: -1.6764230728149414
Batch 9/64 loss: -1.745865821838379
Batch 10/64 loss: -1.7480659484863281
Batch 11/64 loss: -1.3223590850830078
Batch 12/64 loss: -1.6702451705932617
Batch 13/64 loss: -1.7219343185424805
Batch 14/64 loss: -1.7645130157470703
Batch 15/64 loss: -1.67205810546875
Batch 16/64 loss: -1.4514036178588867
Batch 17/64 loss: -1.3606739044189453
Batch 18/64 loss: -1.8197402954101562
Batch 19/64 loss: -1.5125436782836914
Batch 20/64 loss: -1.8958282470703125
Batch 21/64 loss: -1.6452159881591797
Batch 22/64 loss: -1.4148740768432617
Batch 23/64 loss: -1.6126775741577148
Batch 24/64 loss: -1.5390052795410156
Batch 25/64 loss: -1.7207508087158203
Batch 26/64 loss: -1.5719881057739258
Batch 27/64 loss: -0.9591588973999023
Batch 28/64 loss: -1.3240690231323242
Batch 29/64 loss: -1.6753358840942383
Batch 30/64 loss: -1.7106819152832031
Batch 31/64 loss: -1.5732488632202148
Batch 32/64 loss: -1.8958559036254883
Batch 33/64 loss: -1.5363950729370117
Batch 34/64 loss: -1.821314811706543
Batch 35/64 loss: -1.6174917221069336
Batch 36/64 loss: -1.8373804092407227
Batch 37/64 loss: -1.8111200332641602
Batch 38/64 loss: -1.5502634048461914
Batch 39/64 loss: -1.6194133758544922
Batch 40/64 loss: -1.8140668869018555
Batch 41/64 loss: -1.512598991394043
Batch 42/64 loss: -1.2038183212280273
Batch 43/64 loss: -1.8629026412963867
Batch 44/64 loss: -1.8627796173095703
Batch 45/64 loss: -2.0151309967041016
Batch 46/64 loss: -1.925786018371582
Batch 47/64 loss: -1.734105110168457
Batch 48/64 loss: -1.8079586029052734
Batch 49/64 loss: -1.5248470306396484
Batch 50/64 loss: -1.8651018142700195
Batch 51/64 loss: -1.787200927734375
Batch 52/64 loss: -1.4965314865112305
Batch 53/64 loss: -1.2501182556152344
Batch 54/64 loss: -1.749650001525879
Batch 55/64 loss: -1.5600366592407227
Batch 56/64 loss: -1.9378471374511719
Batch 57/64 loss: -1.8081855773925781
Batch 58/64 loss: -1.7206478118896484
Batch 59/64 loss: -1.4545631408691406
Batch 60/64 loss: -1.4477663040161133
Batch 61/64 loss: -1.6168327331542969
Batch 62/64 loss: -1.7822742462158203
Batch 63/64 loss: -1.5299530029296875
Batch 64/64 loss: -5.98165225982666
Epoch 165  Train loss: -1.6973861806532915  Val loss: -2.0057873283464884
Saving best model, epoch: 165
Epoch 166
-------------------------------
Batch 1/64 loss: -1.6527070999145508
Batch 2/64 loss: -1.5999565124511719
Batch 3/64 loss: -1.8305168151855469
Batch 4/64 loss: -1.8708477020263672
Batch 5/64 loss: -1.6031303405761719
Batch 6/64 loss: -1.8206825256347656
Batch 7/64 loss: -1.7921438217163086
Batch 8/64 loss: -1.5854082107543945
Batch 9/64 loss: -1.538100242614746
Batch 10/64 loss: -1.6356964111328125
Batch 11/64 loss: -1.3999137878417969
Batch 12/64 loss: -1.6808090209960938
Batch 13/64 loss: -1.6342973709106445
Batch 14/64 loss: -1.6288642883300781
Batch 15/64 loss: -1.7743053436279297
Batch 16/64 loss: -1.6123542785644531
Batch 17/64 loss: -1.4480171203613281
Batch 18/64 loss: -1.5859851837158203
Batch 19/64 loss: -1.793710708618164
Batch 20/64 loss: -1.5739336013793945
Batch 21/64 loss: -1.217484474182129
Batch 22/64 loss: -1.4507923126220703
Batch 23/64 loss: -1.5767078399658203
Batch 24/64 loss: -1.6165504455566406
Batch 25/64 loss: -1.550485610961914
Batch 26/64 loss: -1.2294425964355469
Batch 27/64 loss: -1.5582466125488281
Batch 28/64 loss: -1.453629493713379
Batch 29/64 loss: -0.8454627990722656
Batch 30/64 loss: -1.4297866821289062
Batch 31/64 loss: -1.3877296447753906
Batch 32/64 loss: -1.6133708953857422
Batch 33/64 loss: -1.312058448791504
Batch 34/64 loss: -1.5583620071411133
Batch 35/64 loss: -1.5505151748657227
Batch 36/64 loss: -1.6767148971557617
Batch 37/64 loss: -1.437952995300293
Batch 38/64 loss: -1.3929319381713867
Batch 39/64 loss: -1.2843561172485352
Batch 40/64 loss: -1.358820915222168
Batch 41/64 loss: -1.3735218048095703
Batch 42/64 loss: -0.9873142242431641
Batch 43/64 loss: -1.2212247848510742
Batch 44/64 loss: -1.003676414489746
Batch 45/64 loss: -1.0260257720947266
Batch 46/64 loss: -1.1866083145141602
Batch 47/64 loss: -1.3175201416015625
Batch 48/64 loss: -1.2021045684814453
Batch 49/64 loss: -1.290670394897461
Batch 50/64 loss: -1.2433433532714844
Batch 51/64 loss: -1.5330657958984375
Batch 52/64 loss: -1.3837718963623047
Batch 53/64 loss: -1.3205833435058594
Batch 54/64 loss: -0.6269702911376953
Batch 55/64 loss: -1.3115177154541016
Batch 56/64 loss: -1.6150693893432617
Batch 57/64 loss: -1.2627019882202148
Batch 58/64 loss: -1.2183303833007812
Batch 59/64 loss: -0.41550731658935547
Batch 60/64 loss: -0.31473636627197266
Batch 61/64 loss: -1.2982864379882812
Batch 62/64 loss: -0.9401121139526367
Batch 63/64 loss: -1.464792251586914
Batch 64/64 loss: -4.718199729919434
Epoch 166  Train loss: -1.437786465065152  Val loss: -1.2191933045272565
Epoch 167
-------------------------------
Batch 1/64 loss: -1.1034765243530273
Batch 2/64 loss: -1.223489761352539
Batch 3/64 loss: -1.2474374771118164
Batch 4/64 loss: -0.019555091857910156
Batch 5/64 loss: -0.6659030914306641
Batch 6/64 loss: -1.0838146209716797
Batch 7/64 loss: -1.1202049255371094
Batch 8/64 loss: -0.6908330917358398
Batch 9/64 loss: -1.2039623260498047
Batch 10/64 loss: -0.5913639068603516
Batch 11/64 loss: -1.5017967224121094
Batch 12/64 loss: -1.1598033905029297
Batch 13/64 loss: -1.4933996200561523
Batch 14/64 loss: -1.112640380859375
Batch 15/64 loss: -1.5987348556518555
Batch 16/64 loss: -1.0375442504882812
Batch 17/64 loss: -1.435190200805664
Batch 18/64 loss: -1.0738143920898438
Batch 19/64 loss: -1.1769580841064453
Batch 20/64 loss: -1.435917854309082
Batch 21/64 loss: -1.5731191635131836
Batch 22/64 loss: -1.1622486114501953
Batch 23/64 loss: -0.8639202117919922
Batch 24/64 loss: -1.6415109634399414
Batch 25/64 loss: -1.0206871032714844
Batch 26/64 loss: -1.2589874267578125
Batch 27/64 loss: -1.1306238174438477
Batch 28/64 loss: -1.5138721466064453
Batch 29/64 loss: -1.126333236694336
Batch 30/64 loss: -1.336817741394043
Batch 31/64 loss: -0.6241350173950195
Batch 32/64 loss: -1.1969165802001953
Batch 33/64 loss: -1.3934955596923828
Batch 34/64 loss: -1.2640705108642578
Batch 35/64 loss: 0.8742084503173828
Batch 36/64 loss: -1.1435165405273438
Batch 37/64 loss: -0.9103574752807617
Batch 38/64 loss: -1.4848241806030273
Batch 39/64 loss: -1.2182626724243164
Batch 40/64 loss: -1.2115612030029297
Batch 41/64 loss: -1.3963613510131836
Batch 42/64 loss: -1.264195442199707
Batch 43/64 loss: -0.9387483596801758
Batch 44/64 loss: -1.4121990203857422
Batch 45/64 loss: -0.2929811477661133
Batch 46/64 loss: 0.2862567901611328
Batch 47/64 loss: 0.385223388671875
Batch 48/64 loss: -1.3144159317016602
Batch 49/64 loss: -1.1087026596069336
Batch 50/64 loss: -1.5123443603515625
Batch 51/64 loss: -1.1247797012329102
Batch 52/64 loss: -0.8228731155395508
Batch 53/64 loss: -1.1393413543701172
Batch 54/64 loss: -0.2861652374267578
Batch 55/64 loss: -1.188857078552246
Batch 56/64 loss: -0.25672149658203125
Batch 57/64 loss: -1.1983222961425781
Batch 58/64 loss: -1.178670883178711
Batch 59/64 loss: -0.2925453186035156
Batch 60/64 loss: -1.1803178787231445
Batch 61/64 loss: -0.8370742797851562
Batch 62/64 loss: -1.0552482604980469
Batch 63/64 loss: -1.3160486221313477
Batch 64/64 loss: -5.205556392669678
Epoch 167  Train loss: -1.0749253833995145  Val loss: -1.1790438648761343
Epoch 168
-------------------------------
Batch 1/64 loss: -1.2711753845214844
Batch 2/64 loss: -0.9093341827392578
Batch 3/64 loss: -0.9146575927734375
Batch 4/64 loss: -1.2735366821289062
Batch 5/64 loss: -1.3388862609863281
Batch 6/64 loss: -1.0766992568969727
Batch 7/64 loss: -1.3097667694091797
Batch 8/64 loss: -1.1064233779907227
Batch 9/64 loss: -0.2689943313598633
Batch 10/64 loss: -1.2531232833862305
Batch 11/64 loss: -1.1095666885375977
Batch 12/64 loss: -1.3173141479492188
Batch 13/64 loss: -1.7157678604125977
Batch 14/64 loss: -1.3996505737304688
Batch 15/64 loss: -0.7343330383300781
Batch 16/64 loss: -0.2864103317260742
Batch 17/64 loss: -1.2190332412719727
Batch 18/64 loss: -0.9482326507568359
Batch 19/64 loss: -1.5119762420654297
Batch 20/64 loss: -1.1382417678833008
Batch 21/64 loss: -0.9124088287353516
Batch 22/64 loss: -0.975071907043457
Batch 23/64 loss: -1.1798582077026367
Batch 24/64 loss: -1.6307916641235352
Batch 25/64 loss: -1.2820959091186523
Batch 26/64 loss: -0.41524600982666016
Batch 27/64 loss: -1.3989534378051758
Batch 28/64 loss: -1.0349645614624023
Batch 29/64 loss: -1.7604379653930664
Batch 30/64 loss: -0.9871959686279297
Batch 31/64 loss: -1.5252370834350586
Batch 32/64 loss: -1.1845874786376953
Batch 33/64 loss: -1.370351791381836
Batch 34/64 loss: -1.505605697631836
Batch 35/64 loss: -1.1756668090820312
Batch 36/64 loss: -1.5548009872436523
Batch 37/64 loss: -1.7268848419189453
Batch 38/64 loss: -1.5137863159179688
Batch 39/64 loss: -1.121164321899414
Batch 40/64 loss: -1.557882308959961
Batch 41/64 loss: -1.4699678421020508
Batch 42/64 loss: -1.7352771759033203
Batch 43/64 loss: -1.5500335693359375
Batch 44/64 loss: -1.4826431274414062
Batch 45/64 loss: -1.3773012161254883
Batch 46/64 loss: -1.6581401824951172
Batch 47/64 loss: -1.731337547302246
Batch 48/64 loss: -0.9382953643798828
Batch 49/64 loss: -1.494084358215332
Batch 50/64 loss: -1.6324434280395508
Batch 51/64 loss: -1.4730224609375
Batch 52/64 loss: -1.497757911682129
Batch 53/64 loss: -1.504068374633789
Batch 54/64 loss: -1.4595556259155273
Batch 55/64 loss: -1.3226823806762695
Batch 56/64 loss: -1.367156982421875
Batch 57/64 loss: -1.0785903930664062
Batch 58/64 loss: -1.3387622833251953
Batch 59/64 loss: -1.4095630645751953
Batch 60/64 loss: -1.4435043334960938
Batch 61/64 loss: -1.6606683731079102
Batch 62/64 loss: -1.1227540969848633
Batch 63/64 loss: -0.8699607849121094
Batch 64/64 loss: -5.196139812469482
Epoch 168  Train loss: -1.3244045725055769  Val loss: -1.6166356011354637
Epoch 169
-------------------------------
Batch 1/64 loss: -1.632664680480957
Batch 2/64 loss: -1.4853744506835938
Batch 3/64 loss: -1.3692102432250977
Batch 4/64 loss: -1.4188098907470703
Batch 5/64 loss: -1.3976325988769531
Batch 6/64 loss: -1.6330442428588867
Batch 7/64 loss: -1.1772241592407227
Batch 8/64 loss: -1.4461345672607422
Batch 9/64 loss: -1.4199695587158203
Batch 10/64 loss: -1.5691852569580078
Batch 11/64 loss: -1.6559171676635742
Batch 12/64 loss: -0.930943489074707
Batch 13/64 loss: -1.6689643859863281
Batch 14/64 loss: -0.6605091094970703
Batch 15/64 loss: -1.5793724060058594
Batch 16/64 loss: -1.3627243041992188
Batch 17/64 loss: -1.5318374633789062
Batch 18/64 loss: -1.5644550323486328
Batch 19/64 loss: -1.82623291015625
Batch 20/64 loss: -1.2832412719726562
Batch 21/64 loss: -1.419297218322754
Batch 22/64 loss: -1.5053644180297852
Batch 23/64 loss: -0.6227750778198242
Batch 24/64 loss: -1.5379419326782227
Batch 25/64 loss: -1.4557247161865234
Batch 26/64 loss: -1.711247444152832
Batch 27/64 loss: -1.2460708618164062
Batch 28/64 loss: -1.1770257949829102
Batch 29/64 loss: -1.0697755813598633
Batch 30/64 loss: -1.12158203125
Batch 31/64 loss: -0.1631631851196289
Batch 32/64 loss: -1.1484622955322266
Batch 33/64 loss: -1.430821418762207
Batch 34/64 loss: 0.02497386932373047
Batch 35/64 loss: -1.2342805862426758
Batch 36/64 loss: -1.2048931121826172
Batch 37/64 loss: -1.2261552810668945
Batch 38/64 loss: -0.48049259185791016
Batch 39/64 loss: -1.1593780517578125
Batch 40/64 loss: -1.053288459777832
Batch 41/64 loss: -0.7144708633422852
Batch 42/64 loss: -0.1969623565673828
Batch 43/64 loss: -0.9712953567504883
Batch 44/64 loss: -0.4076242446899414
Batch 45/64 loss: -0.8948354721069336
Batch 46/64 loss: -0.8971347808837891
Batch 47/64 loss: -1.1064872741699219
Batch 48/64 loss: -1.4700689315795898
Batch 49/64 loss: -1.277714729309082
Batch 50/64 loss: -1.0217790603637695
Batch 51/64 loss: 0.9239730834960938
Batch 52/64 loss: -1.7315654754638672
Batch 53/64 loss: 0.8646259307861328
Batch 54/64 loss: -0.6073951721191406
Batch 55/64 loss: -1.354262351989746
Batch 56/64 loss: -1.458932876586914
Batch 57/64 loss: -1.258758544921875
Batch 58/64 loss: -1.052138328552246
Batch 59/64 loss: -1.6628599166870117
Batch 60/64 loss: -0.5016746520996094
Batch 61/64 loss: -1.0503854751586914
Batch 62/64 loss: -1.2813386917114258
Batch 63/64 loss: -0.6947689056396484
Batch 64/64 loss: -5.430754661560059
Epoch 169  Train loss: -1.1678922952390185  Val loss: -1.122172640770981
Epoch 170
-------------------------------
Batch 1/64 loss: -1.3352222442626953
Batch 2/64 loss: -1.4157800674438477
Batch 3/64 loss: -1.478652000427246
Batch 4/64 loss: -0.23743343353271484
Batch 5/64 loss: -1.108363151550293
Batch 6/64 loss: -1.465616226196289
Batch 7/64 loss: -1.3456478118896484
Batch 8/64 loss: -0.887272834777832
Batch 9/64 loss: -0.9060726165771484
Batch 10/64 loss: -1.0549821853637695
Batch 11/64 loss: -1.4251089096069336
Batch 12/64 loss: -1.6414852142333984
Batch 13/64 loss: -1.473611831665039
Batch 14/64 loss: -1.453099250793457
Batch 15/64 loss: -1.5353899002075195
Batch 16/64 loss: -0.24666690826416016
Batch 17/64 loss: -1.2745590209960938
Batch 18/64 loss: -1.3422136306762695
Batch 19/64 loss: -1.120650291442871
Batch 20/64 loss: -0.07429122924804688
Batch 21/64 loss: -1.65191650390625
Batch 22/64 loss: -1.4345645904541016
Batch 23/64 loss: -0.37503528594970703
Batch 24/64 loss: -1.0220146179199219
Batch 25/64 loss: -1.4230108261108398
Batch 26/64 loss: -1.1138925552368164
Batch 27/64 loss: -1.0515213012695312
Batch 28/64 loss: -1.6085281372070312
Batch 29/64 loss: -1.273177146911621
Batch 30/64 loss: -1.2837562561035156
Batch 31/64 loss: -1.2052011489868164
Batch 32/64 loss: -1.479776382446289
Batch 33/64 loss: -1.4782018661499023
Batch 34/64 loss: -1.2771549224853516
Batch 35/64 loss: -1.249013900756836
Batch 36/64 loss: -1.3002042770385742
Batch 37/64 loss: -0.8352622985839844
Batch 38/64 loss: -0.9201440811157227
Batch 39/64 loss: -1.1348190307617188
Batch 40/64 loss: -1.337294578552246
Batch 41/64 loss: -1.3721208572387695
Batch 42/64 loss: -0.9622354507446289
Batch 43/64 loss: -1.4442062377929688
Batch 44/64 loss: -1.510697364807129
Batch 45/64 loss: -1.0938024520874023
Batch 46/64 loss: -1.3570032119750977
Batch 47/64 loss: -1.6001167297363281
Batch 48/64 loss: -1.4925289154052734
Batch 49/64 loss: -1.3575868606567383
Batch 50/64 loss: -1.6379013061523438
Batch 51/64 loss: -1.3202104568481445
Batch 52/64 loss: -1.1881675720214844
Batch 53/64 loss: -1.6334037780761719
Batch 54/64 loss: -1.5821866989135742
Batch 55/64 loss: -1.393141746520996
Batch 56/64 loss: -0.8412637710571289
Batch 57/64 loss: -0.8884010314941406
Batch 58/64 loss: -1.3620176315307617
Batch 59/64 loss: -1.3028249740600586
Batch 60/64 loss: -1.5242376327514648
Batch 61/64 loss: -1.5076332092285156
Batch 62/64 loss: -1.085439682006836
Batch 63/64 loss: -1.3748865127563477
Batch 64/64 loss: -6.0064191818237305
Epoch 170  Train loss: -1.2958970499973672  Val loss: -1.5958224031114088
Epoch 171
-------------------------------
Batch 1/64 loss: -1.1428823471069336
Batch 2/64 loss: -0.8310871124267578
Batch 3/64 loss: -1.7001609802246094
Batch 4/64 loss: -1.7725954055786133
Batch 5/64 loss: -1.2243871688842773
Batch 6/64 loss: -1.428727149963379
Batch 7/64 loss: -1.1605987548828125
Batch 8/64 loss: -1.361328125
Batch 9/64 loss: -1.1746482849121094
Batch 10/64 loss: -1.3441991806030273
Batch 11/64 loss: -1.5833501815795898
Batch 12/64 loss: -1.6693830490112305
Batch 13/64 loss: -1.7963981628417969
Batch 14/64 loss: -1.6839666366577148
Batch 15/64 loss: -1.3094978332519531
Batch 16/64 loss: -1.4722099304199219
Batch 17/64 loss: -1.7145099639892578
Batch 18/64 loss: -1.4513254165649414
Batch 19/64 loss: -1.6478395462036133
Batch 20/64 loss: -1.2571449279785156
Batch 21/64 loss: -1.798426628112793
Batch 22/64 loss: -1.5447015762329102
Batch 23/64 loss: -1.1033334732055664
Batch 24/64 loss: -1.609689712524414
Batch 25/64 loss: -1.7566823959350586
Batch 26/64 loss: -1.8394184112548828
Batch 27/64 loss: -1.6235418319702148
Batch 28/64 loss: -1.307490348815918
Batch 29/64 loss: -1.5274782180786133
Batch 30/64 loss: -1.1643590927124023
Batch 31/64 loss: -1.6942415237426758
Batch 32/64 loss: -1.017380714416504
Batch 33/64 loss: -1.651041030883789
Batch 34/64 loss: -1.5510129928588867
Batch 35/64 loss: -1.8124008178710938
Batch 36/64 loss: -1.3048295974731445
Batch 37/64 loss: -1.8294601440429688
Batch 38/64 loss: -1.6627368927001953
Batch 39/64 loss: -1.587813377380371
Batch 40/64 loss: -1.582077980041504
Batch 41/64 loss: -1.7060060501098633
Batch 42/64 loss: -1.2437477111816406
Batch 43/64 loss: -1.4344148635864258
Batch 44/64 loss: -1.5436515808105469
Batch 45/64 loss: -1.5176515579223633
Batch 46/64 loss: -1.6041603088378906
Batch 47/64 loss: -1.556563377380371
Batch 48/64 loss: -1.6636724472045898
Batch 49/64 loss: -1.642786979675293
Batch 50/64 loss: -1.534163475036621
Batch 51/64 loss: -1.5888137817382812
Batch 52/64 loss: -1.6678237915039062
Batch 53/64 loss: -0.12776947021484375
Batch 54/64 loss: -1.583277702331543
Batch 55/64 loss: -1.0646305084228516
Batch 56/64 loss: -1.3713960647583008
Batch 57/64 loss: -1.836979866027832
Batch 58/64 loss: -1.1032915115356445
Batch 59/64 loss: -1.5168266296386719
Batch 60/64 loss: -1.699087142944336
Batch 61/64 loss: -0.45700740814208984
Batch 62/64 loss: -1.7351531982421875
Batch 63/64 loss: -1.3034687042236328
Batch 64/64 loss: -5.904982566833496
Epoch 171  Train loss: -1.5156931447047812  Val loss: -1.3419320018021101
Epoch 172
-------------------------------
Batch 1/64 loss: -1.214726448059082
Batch 2/64 loss: -1.2311477661132812
Batch 3/64 loss: -0.9192667007446289
Batch 4/64 loss: -0.2771177291870117
Batch 5/64 loss: -1.5831031799316406
Batch 6/64 loss: -1.2973718643188477
Batch 7/64 loss: -0.6362428665161133
Batch 8/64 loss: -0.5907754898071289
Batch 9/64 loss: -0.6697397232055664
Batch 10/64 loss: -0.462982177734375
Batch 11/64 loss: -0.03167247772216797
Batch 12/64 loss: -0.6350193023681641
Batch 13/64 loss: -0.9245424270629883
Batch 14/64 loss: -0.8422508239746094
Batch 15/64 loss: -0.4856863021850586
Batch 16/64 loss: -1.0448570251464844
Batch 17/64 loss: -0.37125396728515625
Batch 18/64 loss: -0.18088817596435547
Batch 19/64 loss: -0.5222196578979492
Batch 20/64 loss: -0.32485103607177734
Batch 21/64 loss: -0.23238754272460938
Batch 22/64 loss: -0.37467098236083984
Batch 23/64 loss: -0.7570590972900391
Batch 24/64 loss: -0.6117181777954102
Batch 25/64 loss: -0.9260368347167969
Batch 26/64 loss: -0.8324966430664062
Batch 27/64 loss: -0.45670604705810547
Batch 28/64 loss: 1.6772146224975586
Batch 29/64 loss: -0.36950111389160156
Batch 30/64 loss: -0.5316505432128906
Batch 31/64 loss: -0.2314596176147461
Batch 32/64 loss: 0.22285842895507812
Batch 33/64 loss: -0.25574207305908203
Batch 34/64 loss: -0.8695669174194336
Batch 35/64 loss: -0.5624485015869141
Batch 36/64 loss: -0.6718530654907227
Batch 37/64 loss: -0.7296218872070312
Batch 38/64 loss: -0.43403148651123047
Batch 39/64 loss: -0.09354782104492188
Batch 40/64 loss: -1.093297004699707
Batch 41/64 loss: -0.6691465377807617
Batch 42/64 loss: 0.4218311309814453
Batch 43/64 loss: -0.9683589935302734
Batch 44/64 loss: -0.8984432220458984
Batch 45/64 loss: 0.04027557373046875
Batch 46/64 loss: -1.1038169860839844
Batch 47/64 loss: -0.7612724304199219
Batch 48/64 loss: -0.27958011627197266
Batch 49/64 loss: -0.7349357604980469
Batch 50/64 loss: -1.2030611038208008
Batch 51/64 loss: -0.035831451416015625
Batch 52/64 loss: -0.33587169647216797
Batch 53/64 loss: -1.2272920608520508
Batch 54/64 loss: 0.03248023986816406
Batch 55/64 loss: -0.7061643600463867
Batch 56/64 loss: 0.9068765640258789
Batch 57/64 loss: -0.07063007354736328
Batch 58/64 loss: -0.8699321746826172
Batch 59/64 loss: -0.1334362030029297
Batch 60/64 loss: -0.8838672637939453
Batch 61/64 loss: -0.8502111434936523
Batch 62/64 loss: -0.7405929565429688
Batch 63/64 loss: -1.2926826477050781
Batch 64/64 loss: -4.785259246826172
Epoch 172  Train loss: -0.6012869890998391  Val loss: -0.8136254012379859
Epoch 173
-------------------------------
Batch 1/64 loss: -0.8119449615478516
Batch 2/64 loss: -0.3529520034790039
Batch 3/64 loss: -0.8670854568481445
Batch 4/64 loss: -1.1172685623168945
Batch 5/64 loss: -1.4676876068115234
Batch 6/64 loss: -1.1423416137695312
Batch 7/64 loss: -0.989008903503418
Batch 8/64 loss: -1.2115297317504883
Batch 9/64 loss: -0.8472204208374023
Batch 10/64 loss: -1.1289787292480469
Batch 11/64 loss: -1.068680763244629
Batch 12/64 loss: -1.3106155395507812
Batch 13/64 loss: -1.408034324645996
Batch 14/64 loss: -1.1983833312988281
Batch 15/64 loss: -0.9859905242919922
Batch 16/64 loss: 0.07140636444091797
Batch 17/64 loss: -0.9565038681030273
Batch 18/64 loss: -1.4711065292358398
Batch 19/64 loss: -0.9310445785522461
Batch 20/64 loss: -1.3428049087524414
Batch 21/64 loss: -1.3368234634399414
Batch 22/64 loss: -0.9302310943603516
Batch 23/64 loss: -0.5665826797485352
Batch 24/64 loss: -1.316462516784668
Batch 25/64 loss: -1.3459014892578125
Batch 26/64 loss: -0.1662130355834961
Batch 27/64 loss: -1.5296745300292969
Batch 28/64 loss: -1.4811420440673828
Batch 29/64 loss: -1.5266141891479492
Batch 30/64 loss: -1.424931526184082
Batch 31/64 loss: -0.7287378311157227
Batch 32/64 loss: -0.05676841735839844
Batch 33/64 loss: -1.2676916122436523
Batch 34/64 loss: -1.2700672149658203
Batch 35/64 loss: -1.0079421997070312
Batch 36/64 loss: -1.2016429901123047
Batch 37/64 loss: -1.5932550430297852
Batch 38/64 loss: -0.8925561904907227
Batch 39/64 loss: -0.8739614486694336
Batch 40/64 loss: -1.5346670150756836
Batch 41/64 loss: -1.0270042419433594
Batch 42/64 loss: -1.4295520782470703
Batch 43/64 loss: -1.3606033325195312
Batch 44/64 loss: -1.6138076782226562
Batch 45/64 loss: -1.7001972198486328
Batch 46/64 loss: -1.6838340759277344
Batch 47/64 loss: -1.1242036819458008
Batch 48/64 loss: -1.6104059219360352
Batch 49/64 loss: -0.18416404724121094
Batch 50/64 loss: -1.2304553985595703
Batch 51/64 loss: -0.9256420135498047
Batch 52/64 loss: -0.7381191253662109
Batch 53/64 loss: -1.1769285202026367
Batch 54/64 loss: -1.5520210266113281
Batch 55/64 loss: -1.503077507019043
Batch 56/64 loss: -1.2539262771606445
Batch 57/64 loss: -1.3829326629638672
Batch 58/64 loss: -0.8285274505615234
Batch 59/64 loss: -1.6479120254516602
Batch 60/64 loss: -1.1232776641845703
Batch 61/64 loss: -1.6706628799438477
Batch 62/64 loss: -1.4640417098999023
Batch 63/64 loss: -1.4822845458984375
Batch 64/64 loss: -5.491246223449707
Epoch 173  Train loss: -1.1987711102354761  Val loss: -1.3815454830418747
Epoch 174
-------------------------------
Batch 1/64 loss: -1.7032451629638672
Batch 2/64 loss: -1.2028141021728516
Batch 3/64 loss: -1.430943489074707
Batch 4/64 loss: -1.4296245574951172
Batch 5/64 loss: -1.6046009063720703
Batch 6/64 loss: -1.6039752960205078
Batch 7/64 loss: -1.2893867492675781
Batch 8/64 loss: -1.5611257553100586
Batch 9/64 loss: -1.4934053421020508
Batch 10/64 loss: -1.576608657836914
Batch 11/64 loss: -1.6387815475463867
Batch 12/64 loss: -1.2906980514526367
Batch 13/64 loss: -1.415079116821289
Batch 14/64 loss: -0.9790143966674805
Batch 15/64 loss: -1.0711889266967773
Batch 16/64 loss: -1.5440559387207031
Batch 17/64 loss: -0.6983165740966797
Batch 18/64 loss: -1.128312110900879
Batch 19/64 loss: -1.6504993438720703
Batch 20/64 loss: -0.9660682678222656
Batch 21/64 loss: -1.3484306335449219
Batch 22/64 loss: -1.3825998306274414
Batch 23/64 loss: -1.330153465270996
Batch 24/64 loss: -1.3655290603637695
Batch 25/64 loss: -1.5552940368652344
Batch 26/64 loss: -1.4130859375
Batch 27/64 loss: -1.7914276123046875
Batch 28/64 loss: -1.3489246368408203
Batch 29/64 loss: -1.5025320053100586
Batch 30/64 loss: -1.7367992401123047
Batch 31/64 loss: -0.9100103378295898
Batch 32/64 loss: -1.5258245468139648
Batch 33/64 loss: -1.5627307891845703
Batch 34/64 loss: -1.5896644592285156
Batch 35/64 loss: -1.7934112548828125
Batch 36/64 loss: -1.5901613235473633
Batch 37/64 loss: -1.712418556213379
Batch 38/64 loss: -0.8064889907836914
Batch 39/64 loss: -1.8111839294433594
Batch 40/64 loss: -1.1872549057006836
Batch 41/64 loss: -1.445572853088379
Batch 42/64 loss: -1.5084810256958008
Batch 43/64 loss: -1.7509794235229492
Batch 44/64 loss: -1.7531585693359375
Batch 45/64 loss: -0.9324283599853516
Batch 46/64 loss: -0.7315616607666016
Batch 47/64 loss: -1.6211938858032227
Batch 48/64 loss: -1.8752965927124023
Batch 49/64 loss: -0.9278812408447266
Batch 50/64 loss: -1.846841812133789
Batch 51/64 loss: -1.8173227310180664
Batch 52/64 loss: -1.698451042175293
Batch 53/64 loss: -1.5460309982299805
Batch 54/64 loss: -1.8784799575805664
Batch 55/64 loss: -1.3738689422607422
Batch 56/64 loss: -1.6974830627441406
Batch 57/64 loss: -1.4439888000488281
Batch 58/64 loss: -1.6648616790771484
Batch 59/64 loss: -1.1324958801269531
Batch 60/64 loss: -1.5534639358520508
Batch 61/64 loss: -1.566873550415039
Batch 62/64 loss: -1.770136833190918
Batch 63/64 loss: -1.7024774551391602
Batch 64/64 loss: -5.8344573974609375
Epoch 174  Train loss: -1.508342638202742  Val loss: -1.7204506733163525
Epoch 175
-------------------------------
Batch 1/64 loss: -1.4424505233764648
Batch 2/64 loss: -1.778036117553711
Batch 3/64 loss: -1.291062355041504
Batch 4/64 loss: -1.6941585540771484
Batch 5/64 loss: -1.6712207794189453
Batch 6/64 loss: -1.5768203735351562
Batch 7/64 loss: -1.6461029052734375
Batch 8/64 loss: -1.4714336395263672
Batch 9/64 loss: -1.651895523071289
Batch 10/64 loss: -1.5607194900512695
Batch 11/64 loss: -1.3862667083740234
Batch 12/64 loss: -1.6470527648925781
Batch 13/64 loss: -1.6698598861694336
Batch 14/64 loss: -0.7233877182006836
Batch 15/64 loss: -1.847238540649414
Batch 16/64 loss: -1.4603347778320312
Batch 17/64 loss: -1.5324087142944336
Batch 18/64 loss: -1.631631851196289
Batch 19/64 loss: -0.7013874053955078
Batch 20/64 loss: -1.7045269012451172
Batch 21/64 loss: -1.684117317199707
Batch 22/64 loss: -1.4456939697265625
Batch 23/64 loss: -1.456019401550293
Batch 24/64 loss: -1.6884918212890625
Batch 25/64 loss: -1.6967048645019531
Batch 26/64 loss: -1.405050277709961
Batch 27/64 loss: -1.459488868713379
Batch 28/64 loss: -1.5029973983764648
Batch 29/64 loss: -1.5259590148925781
Batch 30/64 loss: -1.3481435775756836
Batch 31/64 loss: -1.6068315505981445
Batch 32/64 loss: -1.6511459350585938
Batch 33/64 loss: -1.2938117980957031
Batch 34/64 loss: -1.8347139358520508
Batch 35/64 loss: -1.0932178497314453
Batch 36/64 loss: -1.681920051574707
Batch 37/64 loss: -1.7896718978881836
Batch 38/64 loss: -1.5739078521728516
Batch 39/64 loss: -1.8374147415161133
Batch 40/64 loss: -1.8257780075073242
Batch 41/64 loss: -1.7933807373046875
Batch 42/64 loss: -1.7558021545410156
Batch 43/64 loss: -1.452906608581543
Batch 44/64 loss: -1.6382741928100586
Batch 45/64 loss: -0.698760986328125
Batch 46/64 loss: -1.856790542602539
Batch 47/64 loss: -1.1152610778808594
Batch 48/64 loss: -1.4197673797607422
Batch 49/64 loss: -1.6709318161010742
Batch 50/64 loss: -1.7918128967285156
Batch 51/64 loss: -1.9445991516113281
Batch 52/64 loss: -1.7991514205932617
Batch 53/64 loss: -1.0533628463745117
Batch 54/64 loss: -1.3656244277954102
Batch 55/64 loss: -1.7063846588134766
Batch 56/64 loss: -1.5486059188842773
Batch 57/64 loss: -1.7005128860473633
Batch 58/64 loss: -1.729696273803711
Batch 59/64 loss: -1.6951351165771484
Batch 60/64 loss: -1.6275434494018555
Batch 61/64 loss: -1.8939085006713867
Batch 62/64 loss: -1.508500099182129
Batch 63/64 loss: -1.5843257904052734
Batch 64/64 loss: -5.140599250793457
Epoch 175  Train loss: -1.5952245338290345  Val loss: -1.79159566872718
Epoch 176
-------------------------------
Batch 1/64 loss: -1.7920866012573242
Batch 2/64 loss: -1.3938426971435547
Batch 3/64 loss: -1.4193572998046875
Batch 4/64 loss: -1.1958417892456055
Batch 5/64 loss: -1.6476449966430664
Batch 6/64 loss: -1.6125879287719727
Batch 7/64 loss: -1.581181526184082
Batch 8/64 loss: -1.6341209411621094
Batch 9/64 loss: -1.7552967071533203
Batch 10/64 loss: -1.2593269348144531
Batch 11/64 loss: -1.915999412536621
Batch 12/64 loss: -1.8811302185058594
Batch 13/64 loss: -1.703237533569336
Batch 14/64 loss: -1.7604541778564453
Batch 15/64 loss: -1.3512887954711914
Batch 16/64 loss: -1.7699356079101562
Batch 17/64 loss: -1.8310270309448242
Batch 18/64 loss: -0.8542366027832031
Batch 19/64 loss: -1.8146657943725586
Batch 20/64 loss: -1.6658592224121094
Batch 21/64 loss: -1.5399274826049805
Batch 22/64 loss: -1.0763635635375977
Batch 23/64 loss: -1.7498722076416016
Batch 24/64 loss: -0.60687255859375
Batch 25/64 loss: -1.8501100540161133
Batch 26/64 loss: -1.6022567749023438
Batch 27/64 loss: -1.572427749633789
Batch 28/64 loss: -1.7187824249267578
Batch 29/64 loss: -1.712752342224121
Batch 30/64 loss: -1.336167335510254
Batch 31/64 loss: -1.3445243835449219
Batch 32/64 loss: -1.7861862182617188
Batch 33/64 loss: -1.7450504302978516
Batch 34/64 loss: -1.9723663330078125
Batch 35/64 loss: -1.8223857879638672
Batch 36/64 loss: -1.975168228149414
Batch 37/64 loss: -1.6913347244262695
Batch 38/64 loss: -1.4385805130004883
Batch 39/64 loss: -1.8545770645141602
Batch 40/64 loss: -1.4923791885375977
Batch 41/64 loss: -1.7588224411010742
Batch 42/64 loss: -1.4801912307739258
Batch 43/64 loss: -1.8743400573730469
Batch 44/64 loss: -1.9244117736816406
Batch 45/64 loss: -1.76702880859375
Batch 46/64 loss: -1.8010129928588867
Batch 47/64 loss: -1.350203514099121
Batch 48/64 loss: -1.752065658569336
Batch 49/64 loss: -1.5003833770751953
Batch 50/64 loss: -1.8967781066894531
Batch 51/64 loss: -1.6888713836669922
Batch 52/64 loss: -1.926844596862793
Batch 53/64 loss: -1.660029411315918
Batch 54/64 loss: -1.7040138244628906
Batch 55/64 loss: -1.7516794204711914
Batch 56/64 loss: -1.9161643981933594
Batch 57/64 loss: -1.879110336303711
Batch 58/64 loss: -1.7711334228515625
Batch 59/64 loss: -0.8722057342529297
Batch 60/64 loss: -1.8947381973266602
Batch 61/64 loss: -1.9717435836791992
Batch 62/64 loss: -1.7064275741577148
Batch 63/64 loss: -1.6755313873291016
Batch 64/64 loss: -6.104005813598633
Epoch 176  Train loss: -1.6914343964819816  Val loss: -1.8349002956115092
Epoch 177
-------------------------------
Batch 1/64 loss: -2.0157470703125
Batch 2/64 loss: -1.7199335098266602
Batch 3/64 loss: -1.6123838424682617
Batch 4/64 loss: -1.7455415725708008
Batch 5/64 loss: -1.843790054321289
Batch 6/64 loss: -1.8861474990844727
Batch 7/64 loss: -1.697127342224121
Batch 8/64 loss: -2.053466796875
Batch 9/64 loss: -1.6354913711547852
Batch 10/64 loss: -1.5011157989501953
Batch 11/64 loss: -2.012824058532715
Batch 12/64 loss: -1.4832572937011719
Batch 13/64 loss: -1.6088333129882812
Batch 14/64 loss: -1.9099035263061523
Batch 15/64 loss: -1.7325553894042969
Batch 16/64 loss: -2.034205436706543
Batch 17/64 loss: -1.8481884002685547
Batch 18/64 loss: -1.5996742248535156
Batch 19/64 loss: -1.5483379364013672
Batch 20/64 loss: -1.9127540588378906
Batch 21/64 loss: -1.7972478866577148
Batch 22/64 loss: -1.6968317031860352
Batch 23/64 loss: -1.6009063720703125
Batch 24/64 loss: -1.8231143951416016
Batch 25/64 loss: -1.7251577377319336
Batch 26/64 loss: -1.6801910400390625
Batch 27/64 loss: -1.8850212097167969
Batch 28/64 loss: -1.9018278121948242
Batch 29/64 loss: -1.5464859008789062
Batch 30/64 loss: -0.7669916152954102
Batch 31/64 loss: -1.8008642196655273
Batch 32/64 loss: -1.6634721755981445
Batch 33/64 loss: -1.9559402465820312
Batch 34/64 loss: -1.4572649002075195
Batch 35/64 loss: -1.817152976989746
Batch 36/64 loss: -0.6626482009887695
Batch 37/64 loss: -1.8141679763793945
Batch 38/64 loss: -1.4517459869384766
Batch 39/64 loss: -1.8747339248657227
Batch 40/64 loss: -1.912515640258789
Batch 41/64 loss: -1.8763704299926758
Batch 42/64 loss: -1.6962862014770508
Batch 43/64 loss: -1.7735404968261719
Batch 44/64 loss: -1.9213075637817383
Batch 45/64 loss: -1.877920150756836
Batch 46/64 loss: -1.5760250091552734
Batch 47/64 loss: -1.4854068756103516
Batch 48/64 loss: -1.6818294525146484
Batch 49/64 loss: -1.1673212051391602
Batch 50/64 loss: -1.8491897583007812
Batch 51/64 loss: -1.498758316040039
Batch 52/64 loss: -1.8970022201538086
Batch 53/64 loss: -1.697636604309082
Batch 54/64 loss: -1.9234733581542969
Batch 55/64 loss: -1.4008369445800781
Batch 56/64 loss: -1.8457508087158203
Batch 57/64 loss: -1.6691017150878906
Batch 58/64 loss: -1.6807975769042969
Batch 59/64 loss: -1.825408935546875
Batch 60/64 loss: -1.8118219375610352
Batch 61/64 loss: -1.7639131546020508
Batch 62/64 loss: -1.9072160720825195
Batch 63/64 loss: -2.0112075805664062
Batch 64/64 loss: -6.068126678466797
Epoch 177  Train loss: -1.7666631810805378  Val loss: -2.0863986064478293
Saving best model, epoch: 177
Epoch 178
-------------------------------
Batch 1/64 loss: -1.7905292510986328
Batch 2/64 loss: -1.809187889099121
Batch 3/64 loss: -1.8547983169555664
Batch 4/64 loss: -1.692469596862793
Batch 5/64 loss: -1.6748533248901367
Batch 6/64 loss: -1.9390497207641602
Batch 7/64 loss: -2.0264368057250977
Batch 8/64 loss: -2.0633182525634766
Batch 9/64 loss: -1.8479204177856445
Batch 10/64 loss: -1.8760251998901367
Batch 11/64 loss: -1.7107000350952148
Batch 12/64 loss: -1.8325366973876953
Batch 13/64 loss: -1.708146095275879
Batch 14/64 loss: -1.1319189071655273
Batch 15/64 loss: -1.4033584594726562
Batch 16/64 loss: -1.7339506149291992
Batch 17/64 loss: -1.573007583618164
Batch 18/64 loss: -1.4717025756835938
Batch 19/64 loss: -1.703542709350586
Batch 20/64 loss: -1.6973600387573242
Batch 21/64 loss: -1.4472026824951172
Batch 22/64 loss: -1.6250801086425781
Batch 23/64 loss: -1.617934226989746
Batch 24/64 loss: -1.8853588104248047
Batch 25/64 loss: -1.8440313339233398
Batch 26/64 loss: -1.5194025039672852
Batch 27/64 loss: -1.9697484970092773
Batch 28/64 loss: -1.5511093139648438
Batch 29/64 loss: -1.8839550018310547
Batch 30/64 loss: -1.588242530822754
Batch 31/64 loss: -1.686354637145996
Batch 32/64 loss: -1.6009912490844727
Batch 33/64 loss: -1.7049484252929688
Batch 34/64 loss: -1.761983871459961
Batch 35/64 loss: -1.6773977279663086
Batch 36/64 loss: -1.8476009368896484
Batch 37/64 loss: -1.6346588134765625
Batch 38/64 loss: -1.8488235473632812
Batch 39/64 loss: -1.6834163665771484
Batch 40/64 loss: -1.8023672103881836
Batch 41/64 loss: -1.5200738906860352
Batch 42/64 loss: -1.7367048263549805
Batch 43/64 loss: -1.6614665985107422
Batch 44/64 loss: -1.8540048599243164
Batch 45/64 loss: -1.6739091873168945
Batch 46/64 loss: -0.9660882949829102
Batch 47/64 loss: -1.9637527465820312
Batch 48/64 loss: -1.8867969512939453
Batch 49/64 loss: -1.8557090759277344
Batch 50/64 loss: -1.0966873168945312
Batch 51/64 loss: -1.6496524810791016
Batch 52/64 loss: -1.7603225708007812
Batch 53/64 loss: -1.4321212768554688
Batch 54/64 loss: -1.948054313659668
Batch 55/64 loss: -2.056990623474121
Batch 56/64 loss: -1.8208093643188477
Batch 57/64 loss: -1.9251766204833984
Batch 58/64 loss: -1.6669120788574219
Batch 59/64 loss: -1.3212881088256836
Batch 60/64 loss: -1.405038833618164
Batch 61/64 loss: -1.2691726684570312
Batch 62/64 loss: -1.055562973022461
Batch 63/64 loss: -0.9328937530517578
Batch 64/64 loss: -6.041981220245361
Epoch 178  Train loss: -1.720974048913694  Val loss: -2.067412622196158
Epoch 179
-------------------------------
Batch 1/64 loss: -1.9439573287963867
Batch 2/64 loss: -1.916062355041504
Batch 3/64 loss: -1.7443580627441406
Batch 4/64 loss: -1.7168083190917969
Batch 5/64 loss: -1.3202152252197266
Batch 6/64 loss: -1.7364301681518555
Batch 7/64 loss: -1.5452919006347656
Batch 8/64 loss: -1.6746177673339844
Batch 9/64 loss: -1.3783302307128906
Batch 10/64 loss: -1.7022819519042969
Batch 11/64 loss: -1.140202522277832
Batch 12/64 loss: -1.564168930053711
Batch 13/64 loss: -1.7361087799072266
Batch 14/64 loss: -1.541280746459961
Batch 15/64 loss: -1.931981086730957
Batch 16/64 loss: -1.9187393188476562
Batch 17/64 loss: -1.7431535720825195
Batch 18/64 loss: -1.5337600708007812
Batch 19/64 loss: -1.9648828506469727
Batch 20/64 loss: -1.8845205307006836
Batch 21/64 loss: -1.835768699645996
Batch 22/64 loss: -1.7007884979248047
Batch 23/64 loss: -1.6121511459350586
Batch 24/64 loss: -1.2641239166259766
Batch 25/64 loss: -1.8421154022216797
Batch 26/64 loss: -1.5272026062011719
Batch 27/64 loss: -1.5849552154541016
Batch 28/64 loss: -1.9018278121948242
Batch 29/64 loss: -1.8210649490356445
Batch 30/64 loss: -1.5365180969238281
Batch 31/64 loss: -2.045091152191162
Batch 32/64 loss: -1.8098526000976562
Batch 33/64 loss: -1.734135627746582
Batch 34/64 loss: -1.0457954406738281
Batch 35/64 loss: -1.7314529418945312
Batch 36/64 loss: -1.0731229782104492
Batch 37/64 loss: -1.6095647811889648
Batch 38/64 loss: -1.734633445739746
Batch 39/64 loss: -1.7698945999145508
Batch 40/64 loss: -1.537109375
Batch 41/64 loss: -0.8744363784790039
Batch 42/64 loss: -1.6035041809082031
Batch 43/64 loss: -1.8030996322631836
Batch 44/64 loss: -1.3373308181762695
Batch 45/64 loss: -1.8180551528930664
Batch 46/64 loss: -1.3964776992797852
Batch 47/64 loss: -1.379624366760254
Batch 48/64 loss: -1.285181999206543
Batch 49/64 loss: -1.6520309448242188
Batch 50/64 loss: -1.6055736541748047
Batch 51/64 loss: -1.5617399215698242
Batch 52/64 loss: -1.8626251220703125
Batch 53/64 loss: -1.9258337020874023
Batch 54/64 loss: -1.6159029006958008
Batch 55/64 loss: -1.6252708435058594
Batch 56/64 loss: -1.4602975845336914
Batch 57/64 loss: -1.7282419204711914
Batch 58/64 loss: -1.770395278930664
Batch 59/64 loss: -1.776738166809082
Batch 60/64 loss: -1.5733919143676758
Batch 61/64 loss: -1.8340320587158203
Batch 62/64 loss: -1.5066251754760742
Batch 63/64 loss: -1.697641372680664
Batch 64/64 loss: -6.011861801147461
Epoch 179  Train loss: -1.6871728336109835  Val loss: -1.967568191056399
Epoch 180
-------------------------------
Batch 1/64 loss: -1.6793642044067383
Batch 2/64 loss: -1.8414182662963867
Batch 3/64 loss: -0.9023933410644531
Batch 4/64 loss: -1.700535774230957
Batch 5/64 loss: -1.5818710327148438
Batch 6/64 loss: -1.6442718505859375
Batch 7/64 loss: -1.6208324432373047
Batch 8/64 loss: -0.5001468658447266
Batch 9/64 loss: -0.5093851089477539
Batch 10/64 loss: -0.556818962097168
Batch 11/64 loss: -1.1583681106567383
Batch 12/64 loss: -0.3356447219848633
Batch 13/64 loss: -1.1708297729492188
Batch 14/64 loss: 0.4542980194091797
Batch 15/64 loss: -0.796849250793457
Batch 16/64 loss: -0.7987632751464844
Batch 17/64 loss: -0.8796043395996094
Batch 18/64 loss: -0.4476737976074219
Batch 19/64 loss: -1.0080957412719727
Batch 20/64 loss: -0.9343414306640625
Batch 21/64 loss: 0.02791309356689453
Batch 22/64 loss: -0.6209239959716797
Batch 23/64 loss: -0.42093849182128906
Batch 24/64 loss: -0.9317283630371094
Batch 25/64 loss: -0.4677543640136719
Batch 26/64 loss: -0.6783046722412109
Batch 27/64 loss: 0.08050060272216797
Batch 28/64 loss: -0.5148859024047852
Batch 29/64 loss: 0.39165496826171875
Batch 30/64 loss: 0.018276214599609375
Batch 31/64 loss: -0.9260787963867188
Batch 32/64 loss: -0.5474061965942383
Batch 33/64 loss: 0.2618999481201172
Batch 34/64 loss: -0.6515016555786133
Batch 35/64 loss: 0.2649707794189453
Batch 36/64 loss: -0.8949995040893555
Batch 37/64 loss: -1.191431999206543
Batch 38/64 loss: -1.0968647003173828
Batch 39/64 loss: -0.9284591674804688
Batch 40/64 loss: -1.3707494735717773
Batch 41/64 loss: -1.0557708740234375
Batch 42/64 loss: -0.6224746704101562
Batch 43/64 loss: -0.43892478942871094
Batch 44/64 loss: -1.3612356185913086
Batch 45/64 loss: -0.41878509521484375
Batch 46/64 loss: -1.2485179901123047
Batch 47/64 loss: -1.2183094024658203
Batch 48/64 loss: -1.1976680755615234
Batch 49/64 loss: -1.370798110961914
Batch 50/64 loss: -1.1627941131591797
Batch 51/64 loss: -0.13463783264160156
Batch 52/64 loss: -1.6048221588134766
Batch 53/64 loss: -0.8507175445556641
Batch 54/64 loss: -0.25417232513427734
Batch 55/64 loss: -0.6791486740112305
Batch 56/64 loss: -1.0398921966552734
Batch 57/64 loss: -0.8627119064331055
Batch 58/64 loss: -0.8574914932250977
Batch 59/64 loss: -0.7634096145629883
Batch 60/64 loss: -1.112844467163086
Batch 61/64 loss: -1.178055763244629
Batch 62/64 loss: -1.3624114990234375
Batch 63/64 loss: -0.7849435806274414
Batch 64/64 loss: -5.628032684326172
Epoch 180  Train loss: -0.8723338706820619  Val loss: -1.2368921889472253
Epoch 181
-------------------------------
Batch 1/64 loss: -0.8726739883422852
Batch 2/64 loss: -1.2600927352905273
Batch 3/64 loss: -0.46552562713623047
Batch 4/64 loss: 0.9087581634521484
Batch 5/64 loss: -0.4136075973510742
Batch 6/64 loss: -0.9276609420776367
Batch 7/64 loss: -0.7909135818481445
Batch 8/64 loss: -0.4358367919921875
Batch 9/64 loss: -0.8203725814819336
Batch 10/64 loss: 0.2280426025390625
Batch 11/64 loss: -0.7673091888427734
Batch 12/64 loss: -0.8747081756591797
Batch 13/64 loss: -0.1173248291015625
Batch 14/64 loss: -0.30532169342041016
Batch 15/64 loss: -1.223775863647461
Batch 16/64 loss: -1.1400260925292969
Batch 17/64 loss: -1.0408353805541992
Batch 18/64 loss: -0.8681449890136719
Batch 19/64 loss: -0.3993949890136719
Batch 20/64 loss: -0.06552314758300781
Batch 21/64 loss: -0.5058469772338867
Batch 22/64 loss: -0.614222526550293
Batch 23/64 loss: -0.6689901351928711
Batch 24/64 loss: -1.118825912475586
Batch 25/64 loss: -0.43716907501220703
Batch 26/64 loss: -1.3425884246826172
Batch 27/64 loss: -1.0536375045776367
Batch 28/64 loss: 0.3998727798461914
Batch 29/64 loss: -1.146071434020996
Batch 30/64 loss: -1.1153068542480469
Batch 31/64 loss: -1.120875358581543
Batch 32/64 loss: -1.1603593826293945
Batch 33/64 loss: -0.6803722381591797
Batch 34/64 loss: -1.1471376419067383
Batch 35/64 loss: -0.1881256103515625
Batch 36/64 loss: -1.1816034317016602
Batch 37/64 loss: -1.468526840209961
Batch 38/64 loss: -1.0668001174926758
Batch 39/64 loss: -0.9029502868652344
Batch 40/64 loss: -0.8411216735839844
Batch 41/64 loss: -1.1211919784545898
Batch 42/64 loss: -1.4427423477172852
Batch 43/64 loss: -1.3653106689453125
Batch 44/64 loss: -1.2190837860107422
Batch 45/64 loss: -1.0658159255981445
Batch 46/64 loss: -0.9729347229003906
Batch 47/64 loss: -0.9264163970947266
Batch 48/64 loss: -0.840336799621582
Batch 49/64 loss: -1.2844676971435547
Batch 50/64 loss: -1.1146659851074219
Batch 51/64 loss: -1.496079444885254
Batch 52/64 loss: -1.4264945983886719
Batch 53/64 loss: -1.1769933700561523
Batch 54/64 loss: -1.2058134078979492
Batch 55/64 loss: -1.216050148010254
Batch 56/64 loss: -1.1745624542236328
Batch 57/64 loss: -1.345132827758789
Batch 58/64 loss: -1.1426963806152344
Batch 59/64 loss: -1.6764659881591797
Batch 60/64 loss: -1.4505300521850586
Batch 61/64 loss: -0.8404550552368164
Batch 62/64 loss: -1.3264484405517578
Batch 63/64 loss: -0.7737836837768555
Batch 64/64 loss: -5.942002773284912
Epoch 181  Train loss: -0.9580216519972857  Val loss: -1.6924913544015787
Epoch 182
-------------------------------
Batch 1/64 loss: -1.5589427947998047
Batch 2/64 loss: -1.3732051849365234
Batch 3/64 loss: -1.0602445602416992
Batch 4/64 loss: -1.5871171951293945
Batch 5/64 loss: -1.5407066345214844
Batch 6/64 loss: -1.2786149978637695
Batch 7/64 loss: -1.7419853210449219
Batch 8/64 loss: -1.354508399963379
Batch 9/64 loss: -1.461329460144043
Batch 10/64 loss: -1.5076828002929688
Batch 11/64 loss: -1.274815559387207
Batch 12/64 loss: -1.7448902130126953
Batch 13/64 loss: -1.8276443481445312
Batch 14/64 loss: -1.255345344543457
Batch 15/64 loss: -1.3933238983154297
Batch 16/64 loss: -1.032301902770996
Batch 17/64 loss: -1.5040359497070312
Batch 18/64 loss: -0.9050979614257812
Batch 19/64 loss: -1.7838592529296875
Batch 20/64 loss: -0.5679159164428711
Batch 21/64 loss: -1.5778207778930664
Batch 22/64 loss: -1.413818359375
Batch 23/64 loss: -1.4156389236450195
Batch 24/64 loss: -0.830108642578125
Batch 25/64 loss: -1.3141288757324219
Batch 26/64 loss: -1.3808765411376953
Batch 27/64 loss: -1.0079355239868164
Batch 28/64 loss: -1.561722755432129
Batch 29/64 loss: -1.1057653427124023
Batch 30/64 loss: -1.4086036682128906
Batch 31/64 loss: -1.697052001953125
Batch 32/64 loss: -1.494302749633789
Batch 33/64 loss: -1.5860233306884766
Batch 34/64 loss: -1.3368854522705078
Batch 35/64 loss: -1.4087915420532227
Batch 36/64 loss: -1.4935874938964844
Batch 37/64 loss: -1.1287364959716797
Batch 38/64 loss: -0.6135215759277344
Batch 39/64 loss: -1.3212347030639648
Batch 40/64 loss: -1.491480827331543
Batch 41/64 loss: -1.7746210098266602
Batch 42/64 loss: -1.7216815948486328
Batch 43/64 loss: -0.7965574264526367
Batch 44/64 loss: -1.3669633865356445
Batch 45/64 loss: -1.451864242553711
Batch 46/64 loss: -1.6176185607910156
Batch 47/64 loss: -0.6492729187011719
Batch 48/64 loss: -1.4828720092773438
Batch 49/64 loss: -1.7444868087768555
Batch 50/64 loss: -1.5982894897460938
Batch 51/64 loss: -1.7425918579101562
Batch 52/64 loss: -1.3343801498413086
Batch 53/64 loss: -1.414504051208496
Batch 54/64 loss: -0.708216667175293
Batch 55/64 loss: -1.4731836318969727
Batch 56/64 loss: -1.2754392623901367
Batch 57/64 loss: -1.4429187774658203
Batch 58/64 loss: -1.5016899108886719
Batch 59/64 loss: -1.405080795288086
Batch 60/64 loss: -1.3340463638305664
Batch 61/64 loss: -0.9938364028930664
Batch 62/64 loss: -1.1724166870117188
Batch 63/64 loss: -0.07001018524169922
Batch 64/64 loss: -5.77501106262207
Epoch 182  Train loss: -1.3920847649667778  Val loss: -1.4673579501122544
Epoch 183
-------------------------------
Batch 1/64 loss: -1.0838146209716797
Batch 2/64 loss: -1.1244640350341797
Batch 3/64 loss: -1.6015357971191406
Batch 4/64 loss: -0.9627113342285156
Batch 5/64 loss: -1.7569713592529297
Batch 6/64 loss: -1.8406248092651367
Batch 7/64 loss: -1.1243410110473633
Batch 8/64 loss: -1.4779176712036133
Batch 9/64 loss: -0.9523496627807617
Batch 10/64 loss: -0.7604255676269531
Batch 11/64 loss: -1.582448959350586
Batch 12/64 loss: -1.4108562469482422
Batch 13/64 loss: -1.304060935974121
Batch 14/64 loss: -1.153550148010254
Batch 15/64 loss: -0.8503952026367188
Batch 16/64 loss: -1.585280418395996
Batch 17/64 loss: -1.4332647323608398
Batch 18/64 loss: -1.7648582458496094
Batch 19/64 loss: -1.435124397277832
Batch 20/64 loss: -1.6058597564697266
Batch 21/64 loss: -1.279555320739746
Batch 22/64 loss: -0.8071765899658203
Batch 23/64 loss: -1.1989202499389648
Batch 24/64 loss: -1.3363637924194336
Batch 25/64 loss: -1.1761674880981445
Batch 26/64 loss: -1.0743446350097656
Batch 27/64 loss: -1.5381507873535156
Batch 28/64 loss: -0.9692792892456055
Batch 29/64 loss: -1.4701900482177734
Batch 30/64 loss: -1.4892854690551758
Batch 31/64 loss: -1.229264259338379
Batch 32/64 loss: -1.650712013244629
Batch 33/64 loss: -1.6338729858398438
Batch 34/64 loss: -1.7445259094238281
Batch 35/64 loss: -1.5927371978759766
Batch 36/64 loss: -1.6168298721313477
Batch 37/64 loss: -0.9920520782470703
Batch 38/64 loss: -1.803262710571289
Batch 39/64 loss: -1.6567230224609375
Batch 40/64 loss: -1.34405517578125
Batch 41/64 loss: -0.8385276794433594
Batch 42/64 loss: -1.2874431610107422
Batch 43/64 loss: -0.8151712417602539
Batch 44/64 loss: -1.814596176147461
Batch 45/64 loss: -1.5587167739868164
Batch 46/64 loss: -1.0877656936645508
Batch 47/64 loss: -1.7755908966064453
Batch 48/64 loss: -1.6317806243896484
Batch 49/64 loss: -1.2174863815307617
Batch 50/64 loss: -0.5797042846679688
Batch 51/64 loss: -1.3144340515136719
Batch 52/64 loss: -1.2784643173217773
Batch 53/64 loss: -1.4693527221679688
Batch 54/64 loss: -1.3583993911743164
Batch 55/64 loss: -1.737142562866211
Batch 56/64 loss: -1.7239980697631836
Batch 57/64 loss: -1.504547119140625
Batch 58/64 loss: -1.0211114883422852
Batch 59/64 loss: -1.4348478317260742
Batch 60/64 loss: -0.8481464385986328
Batch 61/64 loss: -1.3734464645385742
Batch 62/64 loss: -1.5420379638671875
Batch 63/64 loss: -1.8665685653686523
Batch 64/64 loss: -5.390525817871094
Epoch 183  Train loss: -1.4044940873688343  Val loss: -1.5180203283775304
Epoch 184
-------------------------------
Batch 1/64 loss: -1.4669437408447266
Batch 2/64 loss: -1.414907455444336
Batch 3/64 loss: -1.7635469436645508
Batch 4/64 loss: -1.4803714752197266
Batch 5/64 loss: -1.1958961486816406
Batch 6/64 loss: -1.3230924606323242
Batch 7/64 loss: -1.5013952255249023
Batch 8/64 loss: -1.6126747131347656
Batch 9/64 loss: -1.4182443618774414
Batch 10/64 loss: -1.608372688293457
Batch 11/64 loss: -1.3772592544555664
Batch 12/64 loss: -1.7263174057006836
Batch 13/64 loss: -1.4002952575683594
Batch 14/64 loss: -1.6864347457885742
Batch 15/64 loss: -1.073744773864746
Batch 16/64 loss: -1.145944595336914
Batch 17/64 loss: -1.6761655807495117
Batch 18/64 loss: -0.17599964141845703
Batch 19/64 loss: -1.2664556503295898
Batch 20/64 loss: -1.5717496871948242
Batch 21/64 loss: -1.1444807052612305
Batch 22/64 loss: -0.9079742431640625
Batch 23/64 loss: -0.9784574508666992
Batch 24/64 loss: -1.7578630447387695
Batch 25/64 loss: -1.6060562133789062
Batch 26/64 loss: -0.6064558029174805
Batch 27/64 loss: -1.316950798034668
Batch 28/64 loss: -1.4671611785888672
Batch 29/64 loss: -1.3228864669799805
Batch 30/64 loss: -1.6053047180175781
Batch 31/64 loss: -1.4610004425048828
Batch 32/64 loss: -1.6262998580932617
Batch 33/64 loss: -1.799403190612793
Batch 34/64 loss: -1.4727144241333008
Batch 35/64 loss: -1.58428955078125
Batch 36/64 loss: -1.084059715270996
Batch 37/64 loss: -1.1106443405151367
Batch 38/64 loss: -1.631368637084961
Batch 39/64 loss: -1.5721759796142578
Batch 40/64 loss: -1.2702150344848633
Batch 41/64 loss: -1.2344751358032227
Batch 42/64 loss: -1.182870864868164
Batch 43/64 loss: -1.5497846603393555
Batch 44/64 loss: -1.5317907333374023
Batch 45/64 loss: -1.6345043182373047
Batch 46/64 loss: -1.6203508377075195
Batch 47/64 loss: -1.693375587463379
Batch 48/64 loss: -1.6777620315551758
Batch 49/64 loss: -1.5574712753295898
Batch 50/64 loss: -1.5794258117675781
Batch 51/64 loss: -1.6164865493774414
Batch 52/64 loss: -0.8645534515380859
Batch 53/64 loss: -1.5080242156982422
Batch 54/64 loss: -1.4878854751586914
Batch 55/64 loss: -1.7410039901733398
Batch 56/64 loss: -1.6867132186889648
Batch 57/64 loss: -1.7258625030517578
Batch 58/64 loss: -1.3556852340698242
Batch 59/64 loss: -1.224715232849121
Batch 60/64 loss: -1.2535200119018555
Batch 61/64 loss: -1.8084001541137695
Batch 62/64 loss: -1.3755130767822266
Batch 63/64 loss: -1.485743522644043
Batch 64/64 loss: -6.045555114746094
Epoch 184  Train loss: -1.476731887518191  Val loss: -1.8349247437572151
Epoch 185
-------------------------------
Batch 1/64 loss: -1.5883522033691406
Batch 2/64 loss: -1.3529281616210938
Batch 3/64 loss: -1.6682634353637695
Batch 4/64 loss: -1.717996597290039
Batch 5/64 loss: -1.6819829940795898
Batch 6/64 loss: -1.4180231094360352
Batch 7/64 loss: -1.7589607238769531
Batch 8/64 loss: -1.7649688720703125
Batch 9/64 loss: -1.890751838684082
Batch 10/64 loss: -0.6443243026733398
Batch 11/64 loss: -1.8516597747802734
Batch 12/64 loss: -1.7242136001586914
Batch 13/64 loss: -1.4670391082763672
Batch 14/64 loss: -1.4813146591186523
Batch 15/64 loss: -1.5337285995483398
Batch 16/64 loss: -1.306382179260254
Batch 17/64 loss: -1.6632375717163086
Batch 18/64 loss: -1.7945289611816406
Batch 19/64 loss: -1.1146726608276367
Batch 20/64 loss: -1.7255563735961914
Batch 21/64 loss: -1.7946834564208984
Batch 22/64 loss: -1.6223974227905273
Batch 23/64 loss: -1.4346513748168945
Batch 24/64 loss: -1.7689027786254883
Batch 25/64 loss: -1.7036705017089844
Batch 26/64 loss: -1.5834541320800781
Batch 27/64 loss: -0.9593849182128906
Batch 28/64 loss: -1.3759040832519531
Batch 29/64 loss: -1.7570419311523438
Batch 30/64 loss: -1.8347959518432617
Batch 31/64 loss: -1.2192058563232422
Batch 32/64 loss: -1.3567781448364258
Batch 33/64 loss: -1.809269905090332
Batch 34/64 loss: -1.308028221130371
Batch 35/64 loss: -1.672271728515625
Batch 36/64 loss: -1.9508123397827148
Batch 37/64 loss: -1.757516860961914
Batch 38/64 loss: -1.2166900634765625
Batch 39/64 loss: -1.7834672927856445
Batch 40/64 loss: -0.8175277709960938
Batch 41/64 loss: -1.2451963424682617
Batch 42/64 loss: -1.7880048751831055
Batch 43/64 loss: -0.9164743423461914
Batch 44/64 loss: -1.6587944030761719
Batch 45/64 loss: -1.7374868392944336
Batch 46/64 loss: -0.9959077835083008
Batch 47/64 loss: -0.6294050216674805
Batch 48/64 loss: -0.42932891845703125
Batch 49/64 loss: -1.6906566619873047
Batch 50/64 loss: -1.7371206283569336
Batch 51/64 loss: -1.1546258926391602
Batch 52/64 loss: -1.7631521224975586
Batch 53/64 loss: -0.8107452392578125
Batch 54/64 loss: -1.749730110168457
Batch 55/64 loss: -1.6639089584350586
Batch 56/64 loss: -1.8690309524536133
Batch 57/64 loss: -1.5187110900878906
Batch 58/64 loss: -1.1704883575439453
Batch 59/64 loss: -1.7175416946411133
Batch 60/64 loss: -1.9395999908447266
Batch 61/64 loss: -1.7310380935668945
Batch 62/64 loss: -1.7909135818481445
Batch 63/64 loss: -1.4898805618286133
Batch 64/64 loss: -5.70995569229126
Epoch 185  Train loss: -1.5585184265585508  Val loss: -1.7671643810993207
Epoch 186
-------------------------------
Batch 1/64 loss: -1.6629037857055664
Batch 2/64 loss: -1.272756576538086
Batch 3/64 loss: -1.5517702102661133
Batch 4/64 loss: -1.4184846878051758
Batch 5/64 loss: -1.5311470031738281
Batch 6/64 loss: -1.570810317993164
Batch 7/64 loss: -1.548661231994629
Batch 8/64 loss: -1.7242536544799805
Batch 9/64 loss: -1.4162845611572266
Batch 10/64 loss: -1.209700584411621
Batch 11/64 loss: -1.8015623092651367
Batch 12/64 loss: -1.7350311279296875
Batch 13/64 loss: -1.3982257843017578
Batch 14/64 loss: -1.5264959335327148
Batch 15/64 loss: -1.3914146423339844
Batch 16/64 loss: -1.8009843826293945
Batch 17/64 loss: -1.803696632385254
Batch 18/64 loss: -1.3918781280517578
Batch 19/64 loss: -1.256643295288086
Batch 20/64 loss: -1.1902294158935547
Batch 21/64 loss: -1.071610450744629
Batch 22/64 loss: -1.522237777709961
Batch 23/64 loss: -1.3709726333618164
Batch 24/64 loss: -1.6232852935791016
Batch 25/64 loss: -1.0247459411621094
Batch 26/64 loss: -1.6424684524536133
Batch 27/64 loss: -1.6751670837402344
Batch 28/64 loss: -1.7550468444824219
Batch 29/64 loss: -1.5435924530029297
Batch 30/64 loss: -1.6379432678222656
Batch 31/64 loss: -1.431570053100586
Batch 32/64 loss: -1.4149665832519531
Batch 33/64 loss: -1.4372568130493164
Batch 34/64 loss: -1.7336034774780273
Batch 35/64 loss: -1.8645687103271484
Batch 36/64 loss: -1.4772653579711914
Batch 37/64 loss: -1.370905876159668
Batch 38/64 loss: -1.0521039962768555
Batch 39/64 loss: -1.5318832397460938
Batch 40/64 loss: -1.4129562377929688
Batch 41/64 loss: -1.7583084106445312
Batch 42/64 loss: -1.0709218978881836
Batch 43/64 loss: -1.5516128540039062
Batch 44/64 loss: -1.8012514114379883
Batch 45/64 loss: -1.517674446105957
Batch 46/64 loss: -1.3976678848266602
Batch 47/64 loss: -1.4230260848999023
Batch 48/64 loss: -1.6540107727050781
Batch 49/64 loss: -1.7758913040161133
Batch 50/64 loss: -1.3658599853515625
Batch 51/64 loss: -1.8882522583007812
Batch 52/64 loss: -0.6704034805297852
Batch 53/64 loss: -1.6879072189331055
Batch 54/64 loss: -1.462799072265625
Batch 55/64 loss: -1.9183454513549805
Batch 56/64 loss: -1.784501075744629
Batch 57/64 loss: -1.4856891632080078
Batch 58/64 loss: -1.446335792541504
Batch 59/64 loss: -1.6363811492919922
Batch 60/64 loss: -1.72344970703125
Batch 61/64 loss: -0.5609149932861328
Batch 62/64 loss: -1.6398983001708984
Batch 63/64 loss: -1.5130071640014648
Batch 64/64 loss: -6.00738525390625
Epoch 186  Train loss: -1.5535173902324602  Val loss: -1.6745309469216467
Epoch 187
-------------------------------
Batch 1/64 loss: -1.978825569152832
Batch 2/64 loss: -1.2376832962036133
Batch 3/64 loss: -1.4753026962280273
Batch 4/64 loss: -1.5884008407592773
Batch 5/64 loss: -1.1687450408935547
Batch 6/64 loss: -1.624380111694336
Batch 7/64 loss: -1.6392850875854492
Batch 8/64 loss: -1.502018928527832
Batch 9/64 loss: -1.740976333618164
Batch 10/64 loss: -1.5501108169555664
Batch 11/64 loss: -1.398859977722168
Batch 12/64 loss: -0.878718376159668
Batch 13/64 loss: -1.4967517852783203
Batch 14/64 loss: -1.5644350051879883
Batch 15/64 loss: -1.5356531143188477
Batch 16/64 loss: -1.6728630065917969
Batch 17/64 loss: -1.7367143630981445
Batch 18/64 loss: -1.8813886642456055
Batch 19/64 loss: -1.653519630432129
Batch 20/64 loss: -1.625955581665039
Batch 21/64 loss: -1.8218650817871094
Batch 22/64 loss: -1.294856071472168
Batch 23/64 loss: -1.4823713302612305
Batch 24/64 loss: -1.594675064086914
Batch 25/64 loss: -1.5707931518554688
Batch 26/64 loss: -1.8395605087280273
Batch 27/64 loss: -1.6651811599731445
Batch 28/64 loss: -1.7053241729736328
Batch 29/64 loss: -1.5409021377563477
Batch 30/64 loss: -1.6303672790527344
Batch 31/64 loss: -1.7884807586669922
Batch 32/64 loss: -1.3814811706542969
Batch 33/64 loss: -1.2498369216918945
Batch 34/64 loss: -1.542837142944336
Batch 35/64 loss: -1.0146980285644531
Batch 36/64 loss: -1.8201618194580078
Batch 37/64 loss: -1.4101791381835938
Batch 38/64 loss: -1.954854965209961
Batch 39/64 loss: -0.8045196533203125
Batch 40/64 loss: -1.8404903411865234
Batch 41/64 loss: -1.7083454132080078
Batch 42/64 loss: -1.9442987442016602
Batch 43/64 loss: -1.9392099380493164
Batch 44/64 loss: -1.5538196563720703
Batch 45/64 loss: -1.7963733673095703
Batch 46/64 loss: -0.9700260162353516
Batch 47/64 loss: -1.2528018951416016
Batch 48/64 loss: -1.616689682006836
Batch 49/64 loss: -1.809992790222168
Batch 50/64 loss: -1.6390151977539062
Batch 51/64 loss: -1.0220870971679688
Batch 52/64 loss: -1.1668376922607422
Batch 53/64 loss: -1.0024394989013672
Batch 54/64 loss: -1.7438812255859375
Batch 55/64 loss: -1.5059385299682617
Batch 56/64 loss: -1.56103515625
Batch 57/64 loss: -1.570352554321289
Batch 58/64 loss: -1.7770891189575195
Batch 59/64 loss: -1.6155099868774414
Batch 60/64 loss: -1.340646743774414
Batch 61/64 loss: -1.7302894592285156
Batch 62/64 loss: -1.606520652770996
Batch 63/64 loss: -1.6270313262939453
Batch 64/64 loss: -6.02138614654541
Epoch 187  Train loss: -1.5987497329711915  Val loss: -1.85937016280656
Epoch 188
-------------------------------
Batch 1/64 loss: -1.0576133728027344
Batch 2/64 loss: -1.1526851654052734
Batch 3/64 loss: -1.7385339736938477
Batch 4/64 loss: -1.0679254531860352
Batch 5/64 loss: -1.8304405212402344
Batch 6/64 loss: -1.165339469909668
Batch 7/64 loss: -1.4532651901245117
Batch 8/64 loss: -1.3954219818115234
Batch 9/64 loss: -1.3195981979370117
Batch 10/64 loss: -1.6497421264648438
Batch 11/64 loss: -1.7456111907958984
Batch 12/64 loss: -1.1619205474853516
Batch 13/64 loss: -1.5480022430419922
Batch 14/64 loss: -1.6615419387817383
Batch 15/64 loss: -0.6191177368164062
Batch 16/64 loss: -0.8633460998535156
Batch 17/64 loss: -1.7411470413208008
Batch 18/64 loss: -1.8897380828857422
Batch 19/64 loss: -0.9516420364379883
Batch 20/64 loss: -1.7161483764648438
Batch 21/64 loss: -1.530893325805664
Batch 22/64 loss: -1.6921262741088867
Batch 23/64 loss: -1.7850666046142578
Batch 24/64 loss: -1.1511812210083008
Batch 25/64 loss: -1.2880640029907227
Batch 26/64 loss: -1.7498207092285156
Batch 27/64 loss: -1.5161981582641602
Batch 28/64 loss: -1.7257404327392578
Batch 29/64 loss: -1.5549392700195312
Batch 30/64 loss: -1.5506105422973633
Batch 31/64 loss: -1.8406639099121094
Batch 32/64 loss: -1.8936357498168945
Batch 33/64 loss: -1.9489173889160156
Batch 34/64 loss: -1.8398704528808594
Batch 35/64 loss: -1.8388519287109375
Batch 36/64 loss: -1.7455120086669922
Batch 37/64 loss: -1.4072504043579102
Batch 38/64 loss: -1.8005847930908203
Batch 39/64 loss: -1.6598396301269531
Batch 40/64 loss: -1.2605419158935547
Batch 41/64 loss: -1.7419538497924805
Batch 42/64 loss: -1.5884923934936523
Batch 43/64 loss: -1.651066780090332
Batch 44/64 loss: -0.9522428512573242
Batch 45/64 loss: -1.4518146514892578
Batch 46/64 loss: -1.2122411727905273
Batch 47/64 loss: -0.6744880676269531
Batch 48/64 loss: -1.2981996536254883
Batch 49/64 loss: -0.6755447387695312
Batch 50/64 loss: -0.183502197265625
Batch 51/64 loss: -1.6621904373168945
Batch 52/64 loss: -1.412074089050293
Batch 53/64 loss: -1.5770750045776367
Batch 54/64 loss: -1.4938783645629883
Batch 55/64 loss: -0.5902099609375
Batch 56/64 loss: -0.7813024520874023
Batch 57/64 loss: -1.361039161682129
Batch 58/64 loss: -1.5977115631103516
Batch 59/64 loss: -1.876882553100586
Batch 60/64 loss: -1.6269302368164062
Batch 61/64 loss: -0.9053030014038086
Batch 62/64 loss: -1.617262840270996
Batch 63/64 loss: -1.328873634338379
Batch 64/64 loss: -5.623163223266602
Epoch 188  Train loss: -1.4743018281226066  Val loss: -1.5285808523905646
Epoch 189
-------------------------------
Batch 1/64 loss: -0.856989860534668
Batch 2/64 loss: -1.594386100769043
Batch 3/64 loss: -1.288299560546875
Batch 4/64 loss: -0.31856632232666016
Batch 5/64 loss: -1.3070383071899414
Batch 6/64 loss: -1.237802505493164
Batch 7/64 loss: -1.6747303009033203
Batch 8/64 loss: -1.291128158569336
Batch 9/64 loss: -1.3708505630493164
Batch 10/64 loss: -1.1069116592407227
Batch 11/64 loss: -1.0451669692993164
Batch 12/64 loss: -1.061091423034668
Batch 13/64 loss: -1.4454679489135742
Batch 14/64 loss: -1.251704216003418
Batch 15/64 loss: -1.3418588638305664
Batch 16/64 loss: -1.709458351135254
Batch 17/64 loss: -1.255476951599121
Batch 18/64 loss: -1.4354639053344727
Batch 19/64 loss: -1.5267114639282227
Batch 20/64 loss: -1.6379899978637695
Batch 21/64 loss: -1.4372987747192383
Batch 22/64 loss: -0.6823549270629883
Batch 23/64 loss: -1.7373991012573242
Batch 24/64 loss: -1.396352767944336
Batch 25/64 loss: -1.3602590560913086
Batch 26/64 loss: -1.459547996520996
Batch 27/64 loss: -1.0587100982666016
Batch 28/64 loss: -1.733414649963379
Batch 29/64 loss: -1.3316154479980469
Batch 30/64 loss: -1.4946269989013672
Batch 31/64 loss: -1.4620790481567383
Batch 32/64 loss: -1.6904878616333008
Batch 33/64 loss: -1.8632659912109375
Batch 34/64 loss: -1.5572748184204102
Batch 35/64 loss: -1.1519241333007812
Batch 36/64 loss: -1.236557960510254
Batch 37/64 loss: -1.6288480758666992
Batch 38/64 loss: -1.7322092056274414
Batch 39/64 loss: -1.6270456314086914
Batch 40/64 loss: -1.7689399719238281
Batch 41/64 loss: -1.742445945739746
Batch 42/64 loss: -1.7075386047363281
Batch 43/64 loss: -1.4296283721923828
Batch 44/64 loss: -1.3761978149414062
Batch 45/64 loss: -1.523228645324707
Batch 46/64 loss: -1.7839155197143555
Batch 47/64 loss: -1.447199821472168
Batch 48/64 loss: -1.5072746276855469
Batch 49/64 loss: -1.4440927505493164
Batch 50/64 loss: -1.6307506561279297
Batch 51/64 loss: -1.3326492309570312
Batch 52/64 loss: -1.7839984893798828
Batch 53/64 loss: -1.5987586975097656
Batch 54/64 loss: -1.3295392990112305
Batch 55/64 loss: -1.5053043365478516
Batch 56/64 loss: -1.8592920303344727
Batch 57/64 loss: -1.841268539428711
Batch 58/64 loss: -1.418299674987793
Batch 59/64 loss: -1.7253665924072266
Batch 60/64 loss: -1.6806917190551758
Batch 61/64 loss: -1.935678482055664
Batch 62/64 loss: -1.0018243789672852
Batch 63/64 loss: -1.4790983200073242
Batch 64/64 loss: -6.082080841064453
Epoch 189  Train loss: -1.5029475941377528  Val loss: -1.8344667441246845
Epoch 190
-------------------------------
Batch 1/64 loss: -1.7909889221191406
Batch 2/64 loss: -1.9284372329711914
Batch 3/64 loss: -1.2629804611206055
Batch 4/64 loss: -1.3831672668457031
Batch 5/64 loss: -1.7165765762329102
Batch 6/64 loss: -1.357142448425293
Batch 7/64 loss: -1.1792240142822266
Batch 8/64 loss: -1.459702491760254
Batch 9/64 loss: -1.6909847259521484
Batch 10/64 loss: -1.700754165649414
Batch 11/64 loss: -0.9847698211669922
Batch 12/64 loss: -1.7034215927124023
Batch 13/64 loss: -1.7528676986694336
Batch 14/64 loss: -1.4045019149780273
Batch 15/64 loss: -1.5834894180297852
Batch 16/64 loss: -1.875558853149414
Batch 17/64 loss: -1.630986213684082
Batch 18/64 loss: -1.2614707946777344
Batch 19/64 loss: -1.4669151306152344
Batch 20/64 loss: -1.42962646484375
Batch 21/64 loss: -1.6147117614746094
Batch 22/64 loss: -1.7338876724243164
Batch 23/64 loss: -2.016737937927246
Batch 24/64 loss: -1.5573949813842773
Batch 25/64 loss: -1.8203973770141602
Batch 26/64 loss: -1.4882192611694336
Batch 27/64 loss: -1.6264533996582031
Batch 28/64 loss: -1.2631464004516602
Batch 29/64 loss: -1.6701812744140625
Batch 30/64 loss: -1.621133804321289
Batch 31/64 loss: -1.775679588317871
Batch 32/64 loss: -1.1277656555175781
Batch 33/64 loss: -1.9851770401000977
Batch 34/64 loss: -1.892282485961914
Batch 35/64 loss: -1.3463201522827148
Batch 36/64 loss: -1.4704036712646484
Batch 37/64 loss: -1.631403923034668
Batch 38/64 loss: -1.575547218322754
Batch 39/64 loss: -1.6735010147094727
Batch 40/64 loss: -1.5992908477783203
Batch 41/64 loss: -1.7110834121704102
Batch 42/64 loss: -1.5371894836425781
Batch 43/64 loss: -1.583937644958496
Batch 44/64 loss: -1.5257434844970703
Batch 45/64 loss: -1.564056396484375
Batch 46/64 loss: -1.470327377319336
Batch 47/64 loss: -1.695734977722168
Batch 48/64 loss: -1.4414100646972656
Batch 49/64 loss: -1.464858055114746
Batch 50/64 loss: -1.2368297576904297
Batch 51/64 loss: -1.7086200714111328
Batch 52/64 loss: -1.670989990234375
Batch 53/64 loss: -1.6130895614624023
Batch 54/64 loss: -1.966217041015625
Batch 55/64 loss: -1.1463775634765625
Batch 56/64 loss: -0.828923225402832
Batch 57/64 loss: -1.6299686431884766
Batch 58/64 loss: -0.8652734756469727
Batch 59/64 loss: -1.0362329483032227
Batch 60/64 loss: -1.439803123474121
Batch 61/64 loss: -1.372629165649414
Batch 62/64 loss: -1.1910858154296875
Batch 63/64 loss: -1.6661605834960938
Batch 64/64 loss: -5.176233768463135
Epoch 190  Train loss: -1.5733634331647088  Val loss: -1.706702622351368
Epoch 191
-------------------------------
Batch 1/64 loss: -1.4196844100952148
Batch 2/64 loss: -1.5724029541015625
Batch 3/64 loss: -1.5560321807861328
Batch 4/64 loss: -1.143681526184082
Batch 5/64 loss: -1.655247688293457
Batch 6/64 loss: -1.6719398498535156
Batch 7/64 loss: -1.3257551193237305
Batch 8/64 loss: -1.5993833541870117
Batch 9/64 loss: -1.1892356872558594
Batch 10/64 loss: -1.7205381393432617
Batch 11/64 loss: -1.5044126510620117
Batch 12/64 loss: -1.3358078002929688
Batch 13/64 loss: -1.5699195861816406
Batch 14/64 loss: -1.5332002639770508
Batch 15/64 loss: -1.6698312759399414
Batch 16/64 loss: -1.4883289337158203
Batch 17/64 loss: -1.8616714477539062
Batch 18/64 loss: -1.8101835250854492
Batch 19/64 loss: -1.5915422439575195
Batch 20/64 loss: -1.3207178115844727
Batch 21/64 loss: -1.1519651412963867
Batch 22/64 loss: -1.851933479309082
Batch 23/64 loss: -1.753152847290039
Batch 24/64 loss: -1.5126276016235352
Batch 25/64 loss: -1.8004751205444336
Batch 26/64 loss: -1.2491130828857422
Batch 27/64 loss: -1.7642326354980469
Batch 28/64 loss: -1.511052131652832
Batch 29/64 loss: -1.6346569061279297
Batch 30/64 loss: -1.6882638931274414
Batch 31/64 loss: -1.2688636779785156
Batch 32/64 loss: -1.8193368911743164
Batch 33/64 loss: -1.529831886291504
Batch 34/64 loss: -1.0103683471679688
Batch 35/64 loss: -1.2859458923339844
Batch 36/64 loss: -1.7440824508666992
Batch 37/64 loss: -1.8290624618530273
Batch 38/64 loss: -1.3214635848999023
Batch 39/64 loss: -1.8171815872192383
Batch 40/64 loss: -1.7416048049926758
Batch 41/64 loss: -1.234980583190918
Batch 42/64 loss: -1.0367670059204102
Batch 43/64 loss: -1.1163339614868164
Batch 44/64 loss: -1.7743701934814453
Batch 45/64 loss: -0.8941774368286133
Batch 46/64 loss: -1.3549108505249023
Batch 47/64 loss: -1.765458106994629
Batch 48/64 loss: -1.7872705459594727
Batch 49/64 loss: -1.5418014526367188
Batch 50/64 loss: -1.8348464965820312
Batch 51/64 loss: -1.7185516357421875
Batch 52/64 loss: -1.176025390625
Batch 53/64 loss: -1.4837722778320312
Batch 54/64 loss: -1.881138801574707
Batch 55/64 loss: -1.7846145629882812
Batch 56/64 loss: -0.8607912063598633
Batch 57/64 loss: -1.7757654190063477
Batch 58/64 loss: -1.1408109664916992
Batch 59/64 loss: -1.702789306640625
Batch 60/64 loss: -1.6248531341552734
Batch 61/64 loss: -1.6930389404296875
Batch 62/64 loss: -1.0915851593017578
Batch 63/64 loss: -1.5560150146484375
Batch 64/64 loss: -5.944149017333984
Epoch 191  Train loss: -1.5704080170276118  Val loss: -1.747569828098992
Epoch 192
-------------------------------
Batch 1/64 loss: -1.761031150817871
Batch 2/64 loss: -0.9490375518798828
Batch 3/64 loss: -1.6365938186645508
Batch 4/64 loss: -1.3361597061157227
Batch 5/64 loss: -1.3737354278564453
Batch 6/64 loss: -1.433380126953125
Batch 7/64 loss: -1.4422264099121094
Batch 8/64 loss: -1.5956850051879883
Batch 9/64 loss: -1.7445125579833984
Batch 10/64 loss: -0.47144126892089844
Batch 11/64 loss: -1.4339828491210938
Batch 12/64 loss: -1.1665868759155273
Batch 13/64 loss: -1.7769594192504883
Batch 14/64 loss: -1.3848094940185547
Batch 15/64 loss: -1.660691261291504
Batch 16/64 loss: -1.5156478881835938
Batch 17/64 loss: -1.1626367568969727
Batch 18/64 loss: -1.5779361724853516
Batch 19/64 loss: -1.5925006866455078
Batch 20/64 loss: -1.6661081314086914
Batch 21/64 loss: -1.4540023803710938
Batch 22/64 loss: -1.626570701599121
Batch 23/64 loss: -1.6107749938964844
Batch 24/64 loss: -1.5146007537841797
Batch 25/64 loss: -1.5418853759765625
Batch 26/64 loss: -1.2183990478515625
Batch 27/64 loss: -1.743546485900879
Batch 28/64 loss: -1.7660770416259766
Batch 29/64 loss: -1.7311334609985352
Batch 30/64 loss: -1.7952070236206055
Batch 31/64 loss: -1.5268058776855469
Batch 32/64 loss: -1.5892753601074219
Batch 33/64 loss: -1.3002281188964844
Batch 34/64 loss: -1.8545961380004883
Batch 35/64 loss: -1.6304264068603516
Batch 36/64 loss: -1.824666976928711
Batch 37/64 loss: -1.653738021850586
Batch 38/64 loss: -1.9178953170776367
Batch 39/64 loss: -1.5792560577392578
Batch 40/64 loss: -1.5349645614624023
Batch 41/64 loss: -1.5209455490112305
Batch 42/64 loss: -1.135385513305664
Batch 43/64 loss: -1.5637617111206055
Batch 44/64 loss: -1.817307472229004
Batch 45/64 loss: -1.4601736068725586
Batch 46/64 loss: -1.1086616516113281
Batch 47/64 loss: -1.5562286376953125
Batch 48/64 loss: -1.7675113677978516
Batch 49/64 loss: -1.8468990325927734
Batch 50/64 loss: -1.629776954650879
Batch 51/64 loss: -1.4887676239013672
Batch 52/64 loss: -1.4978828430175781
Batch 53/64 loss: -1.0866613388061523
Batch 54/64 loss: -0.8404245376586914
Batch 55/64 loss: -1.3093109130859375
Batch 56/64 loss: -1.8221845626831055
Batch 57/64 loss: -1.7651395797729492
Batch 58/64 loss: -1.656123161315918
Batch 59/64 loss: -1.7589845657348633
Batch 60/64 loss: -1.3864097595214844
Batch 61/64 loss: -1.6271247863769531
Batch 62/64 loss: -1.1746540069580078
Batch 63/64 loss: -1.753774642944336
Batch 64/64 loss: -6.0724778175354
Epoch 192  Train loss: -1.57214376225191  Val loss: -1.926478317103435
Epoch 193
-------------------------------
Batch 1/64 loss: -1.6229219436645508
Batch 2/64 loss: -1.942652702331543
Batch 3/64 loss: -1.4635906219482422
Batch 4/64 loss: -1.8622360229492188
Batch 5/64 loss: -1.577712059020996
Batch 6/64 loss: -1.5599069595336914
Batch 7/64 loss: -1.2557430267333984
Batch 8/64 loss: -1.8092985153198242
Batch 9/64 loss: -1.743514060974121
Batch 10/64 loss: -1.9496288299560547
Batch 11/64 loss: -1.8231630325317383
Batch 12/64 loss: -1.6538238525390625
Batch 13/64 loss: -1.7867164611816406
Batch 14/64 loss: -1.5309028625488281
Batch 15/64 loss: -1.624251365661621
Batch 16/64 loss: -1.3265485763549805
Batch 17/64 loss: -1.4755134582519531
Batch 18/64 loss: -1.8330154418945312
Batch 19/64 loss: -1.0540714263916016
Batch 20/64 loss: -1.8036737442016602
Batch 21/64 loss: -1.5461950302124023
Batch 22/64 loss: -1.7283964157104492
Batch 23/64 loss: -0.6299076080322266
Batch 24/64 loss: -1.5706815719604492
Batch 25/64 loss: -1.5512666702270508
Batch 26/64 loss: -1.6414594650268555
Batch 27/64 loss: -1.2877216339111328
Batch 28/64 loss: -1.4432744979858398
Batch 29/64 loss: -1.8019132614135742
Batch 30/64 loss: -1.5023889541625977
Batch 31/64 loss: -1.1347923278808594
Batch 32/64 loss: -1.4110527038574219
Batch 33/64 loss: -1.4350337982177734
Batch 34/64 loss: -1.8326969146728516
Batch 35/64 loss: -1.762765884399414
Batch 36/64 loss: -1.4222431182861328
Batch 37/64 loss: -1.2777347564697266
Batch 38/64 loss: -1.2314071655273438
Batch 39/64 loss: -1.666733741760254
Batch 40/64 loss: -1.6161251068115234
Batch 41/64 loss: -1.8181514739990234
Batch 42/64 loss: -1.7228431701660156
Batch 43/64 loss: -1.485508918762207
Batch 44/64 loss: -1.8787193298339844
Batch 45/64 loss: -1.7196464538574219
Batch 46/64 loss: -1.705240249633789
Batch 47/64 loss: -1.2112360000610352
Batch 48/64 loss: -1.5310020446777344
Batch 49/64 loss: -1.4448680877685547
Batch 50/64 loss: -1.349130630493164
Batch 51/64 loss: -1.7468795776367188
Batch 52/64 loss: -1.8815841674804688
Batch 53/64 loss: -1.836029052734375
Batch 54/64 loss: -1.1801471710205078
Batch 55/64 loss: -1.830078125
Batch 56/64 loss: -1.7704219818115234
Batch 57/64 loss: -1.1625823974609375
Batch 58/64 loss: -1.3693265914916992
Batch 59/64 loss: -1.6966428756713867
Batch 60/64 loss: -1.8360719680786133
Batch 61/64 loss: -1.519155502319336
Batch 62/64 loss: -1.628830909729004
Batch 63/64 loss: -1.704380989074707
Batch 64/64 loss: -6.041799545288086
Epoch 193  Train loss: -1.6274902418547985  Val loss: -2.0034242872520003
Epoch 194
-------------------------------
Batch 1/64 loss: -1.8186616897583008
Batch 2/64 loss: -1.776078224182129
Batch 3/64 loss: -1.5738191604614258
Batch 4/64 loss: -1.0420494079589844
Batch 5/64 loss: -1.0331401824951172
Batch 6/64 loss: -1.2288475036621094
Batch 7/64 loss: -1.6350927352905273
Batch 8/64 loss: -1.4640378952026367
Batch 9/64 loss: -1.4335393905639648
Batch 10/64 loss: -1.7759923934936523
Batch 11/64 loss: -1.6455583572387695
Batch 12/64 loss: -1.587972640991211
Batch 13/64 loss: -1.8083486557006836
Batch 14/64 loss: -1.6039142608642578
Batch 15/64 loss: -1.687265396118164
Batch 16/64 loss: -1.6866130828857422
Batch 17/64 loss: -1.724247932434082
Batch 18/64 loss: -0.593653678894043
Batch 19/64 loss: -0.8223295211791992
Batch 20/64 loss: -1.8986454010009766
Batch 21/64 loss: -1.6723270416259766
Batch 22/64 loss: -1.5534954071044922
Batch 23/64 loss: -1.570948600769043
Batch 24/64 loss: -1.8731470108032227
Batch 25/64 loss: -1.4341564178466797
Batch 26/64 loss: -1.914337158203125
Batch 27/64 loss: -1.8742351531982422
Batch 28/64 loss: -1.5494699478149414
Batch 29/64 loss: -1.528203010559082
Batch 30/64 loss: -1.5972785949707031
Batch 31/64 loss: -0.523686408996582
Batch 32/64 loss: -1.5779008865356445
Batch 33/64 loss: -1.7695655822753906
Batch 34/64 loss: -1.7891912460327148
Batch 35/64 loss: -1.7036447525024414
Batch 36/64 loss: -0.09567642211914062
Batch 37/64 loss: -1.2503118515014648
Batch 38/64 loss: -1.635009765625
Batch 39/64 loss: -1.5023488998413086
Batch 40/64 loss: -0.775111198425293
Batch 41/64 loss: -1.6537857055664062
Batch 42/64 loss: -1.2604799270629883
Batch 43/64 loss: -1.6091842651367188
Batch 44/64 loss: -1.8640575408935547
Batch 45/64 loss: -1.771449089050293
Batch 46/64 loss: -1.9188032150268555
Batch 47/64 loss: -1.7740821838378906
Batch 48/64 loss: -1.6716365814208984
Batch 49/64 loss: -1.5312480926513672
Batch 50/64 loss: -1.7486333847045898
Batch 51/64 loss: -1.6959075927734375
Batch 52/64 loss: -1.748795509338379
Batch 53/64 loss: -1.6295509338378906
Batch 54/64 loss: -1.7468585968017578
Batch 55/64 loss: -1.596522331237793
Batch 56/64 loss: -1.6652421951293945
Batch 57/64 loss: -1.9692840576171875
Batch 58/64 loss: -1.4894790649414062
Batch 59/64 loss: -1.6933774948120117
Batch 60/64 loss: -1.9194450378417969
Batch 61/64 loss: -1.7872934341430664
Batch 62/64 loss: -1.8461036682128906
Batch 63/64 loss: -1.6915016174316406
Batch 64/64 loss: -5.737827301025391
Epoch 194  Train loss: -1.6096618801939722  Val loss: -2.016033474112704
Epoch 195
-------------------------------
Batch 1/64 loss: -1.590012550354004
Batch 2/64 loss: -1.980478286743164
Batch 3/64 loss: -1.8564119338989258
Batch 4/64 loss: -1.9783096313476562
Batch 5/64 loss: -1.4011316299438477
Batch 6/64 loss: -1.3852672576904297
Batch 7/64 loss: -1.6075878143310547
Batch 8/64 loss: -1.7075490951538086
Batch 9/64 loss: -1.7675752639770508
Batch 10/64 loss: -1.7610998153686523
Batch 11/64 loss: -1.4235658645629883
Batch 12/64 loss: -1.7899045944213867
Batch 13/64 loss: -1.799264907836914
Batch 14/64 loss: -1.4274263381958008
Batch 15/64 loss: -1.8801336288452148
Batch 16/64 loss: -1.8176298141479492
Batch 17/64 loss: -1.6273345947265625
Batch 18/64 loss: -2.0148420333862305
Batch 19/64 loss: -1.7525396347045898
Batch 20/64 loss: -1.6319084167480469
Batch 21/64 loss: -1.6524314880371094
Batch 22/64 loss: -1.6720705032348633
Batch 23/64 loss: -1.677896499633789
Batch 24/64 loss: -1.1115293502807617
Batch 25/64 loss: -1.748396873474121
Batch 26/64 loss: -1.7220849990844727
Batch 27/64 loss: -1.8325719833374023
Batch 28/64 loss: -1.8751201629638672
Batch 29/64 loss: -1.930887222290039
Batch 30/64 loss: -1.9559431076049805
Batch 31/64 loss: -1.9278745651245117
Batch 32/64 loss: -1.8475217819213867
Batch 33/64 loss: -1.1811542510986328
Batch 34/64 loss: -1.4486169815063477
Batch 35/64 loss: -1.743783950805664
Batch 36/64 loss: -1.659367561340332
Batch 37/64 loss: -1.8537187576293945
Batch 38/64 loss: -1.863051414489746
Batch 39/64 loss: -1.6107730865478516
Batch 40/64 loss: -1.2800674438476562
Batch 41/64 loss: -1.8783416748046875
Batch 42/64 loss: -1.947676658630371
Batch 43/64 loss: -1.821390151977539
Batch 44/64 loss: -1.6036014556884766
Batch 45/64 loss: -1.7474327087402344
Batch 46/64 loss: -1.9690132141113281
Batch 47/64 loss: -1.9268550872802734
Batch 48/64 loss: -1.9815912246704102
Batch 49/64 loss: -1.6732187271118164
Batch 50/64 loss: -1.7724790573120117
Batch 51/64 loss: -1.7967700958251953
Batch 52/64 loss: -1.9491815567016602
Batch 53/64 loss: -1.7920446395874023
Batch 54/64 loss: -1.2687349319458008
Batch 55/64 loss: -1.237203598022461
Batch 56/64 loss: -1.6921634674072266
Batch 57/64 loss: -1.3649959564208984
Batch 58/64 loss: -1.8100099563598633
Batch 59/64 loss: -1.7960739135742188
Batch 60/64 loss: -1.7102413177490234
Batch 61/64 loss: -1.3889389038085938
Batch 62/64 loss: -1.318678855895996
Batch 63/64 loss: -1.5986719131469727
Batch 64/64 loss: -5.04837703704834
Epoch 195  Train loss: -1.7353165009442497  Val loss: -1.8799842493640597
Epoch 196
-------------------------------
Batch 1/64 loss: -1.0932159423828125
Batch 2/64 loss: -1.7532377243041992
Batch 3/64 loss: -1.4960908889770508
Batch 4/64 loss: -1.5156631469726562
Batch 5/64 loss: -1.7358884811401367
Batch 6/64 loss: -1.819718360900879
Batch 7/64 loss: -1.7423477172851562
Batch 8/64 loss: -1.6359663009643555
Batch 9/64 loss: -1.1608037948608398
Batch 10/64 loss: -1.5754938125610352
Batch 11/64 loss: -1.7261199951171875
Batch 12/64 loss: -1.331160545349121
Batch 13/64 loss: -1.8861265182495117
Batch 14/64 loss: -1.3545598983764648
Batch 15/64 loss: -1.6613569259643555
Batch 16/64 loss: -1.5039186477661133
Batch 17/64 loss: -1.7031879425048828
Batch 18/64 loss: -1.621969223022461
Batch 19/64 loss: -1.826594352722168
Batch 20/64 loss: -1.5650739669799805
Batch 21/64 loss: -1.7827816009521484
Batch 22/64 loss: -1.0901565551757812
Batch 23/64 loss: -1.3397178649902344
Batch 24/64 loss: -1.7182703018188477
Batch 25/64 loss: -1.7196874618530273
Batch 26/64 loss: -1.4192466735839844
Batch 27/64 loss: -1.8556690216064453
Batch 28/64 loss: -1.1674680709838867
Batch 29/64 loss: -1.6553049087524414
Batch 30/64 loss: -2.0768795013427734
Batch 31/64 loss: -1.3069000244140625
Batch 32/64 loss: -1.8219451904296875
Batch 33/64 loss: -2.0272512435913086
Batch 34/64 loss: -1.919332504272461
Batch 35/64 loss: -1.5838203430175781
Batch 36/64 loss: -1.7412223815917969
Batch 37/64 loss: -1.7243452072143555
Batch 38/64 loss: -1.32574462890625
Batch 39/64 loss: -1.8421306610107422
Batch 40/64 loss: -1.8028488159179688
Batch 41/64 loss: -1.8801040649414062
Batch 42/64 loss: -1.9271907806396484
Batch 43/64 loss: -1.7354698181152344
Batch 44/64 loss: -1.6449851989746094
Batch 45/64 loss: -1.860764503479004
Batch 46/64 loss: -1.6689043045043945
Batch 47/64 loss: -0.9701614379882812
Batch 48/64 loss: -1.462937355041504
Batch 49/64 loss: -1.7500247955322266
Batch 50/64 loss: -1.845524787902832
Batch 51/64 loss: -1.0992069244384766
Batch 52/64 loss: -1.762563705444336
Batch 53/64 loss: -1.7353506088256836
Batch 54/64 loss: -1.56475830078125
Batch 55/64 loss: -1.5338859558105469
Batch 56/64 loss: -1.6901683807373047
Batch 57/64 loss: -1.2123451232910156
Batch 58/64 loss: -1.5968618392944336
Batch 59/64 loss: -1.7149944305419922
Batch 60/64 loss: -1.9736623764038086
Batch 61/64 loss: -1.810318946838379
Batch 62/64 loss: -1.7450037002563477
Batch 63/64 loss: -1.9285097122192383
Batch 64/64 loss: -6.114983558654785
Epoch 196  Train loss: -1.6835945391187481  Val loss: -2.1040913427818273
Saving best model, epoch: 196
Epoch 197
-------------------------------
Batch 1/64 loss: -1.9445457458496094
Batch 2/64 loss: -1.7292938232421875
Batch 3/64 loss: -1.706669807434082
Batch 4/64 loss: -1.7843427658081055
Batch 5/64 loss: -1.5482263565063477
Batch 6/64 loss: -1.8272533416748047
Batch 7/64 loss: -1.906428337097168
Batch 8/64 loss: -2.014632225036621
Batch 9/64 loss: -1.9785404205322266
Batch 10/64 loss: -1.7779455184936523
Batch 11/64 loss: -1.948847770690918
Batch 12/64 loss: -1.1144561767578125
Batch 13/64 loss: -1.8443098068237305
Batch 14/64 loss: -1.612147331237793
Batch 15/64 loss: -1.792719841003418
Batch 16/64 loss: -1.580561637878418
Batch 17/64 loss: -1.742715835571289
Batch 18/64 loss: -1.826075553894043
Batch 19/64 loss: -1.3855924606323242
Batch 20/64 loss: -0.8826322555541992
Batch 21/64 loss: -1.6790752410888672
Batch 22/64 loss: -1.8139305114746094
Batch 23/64 loss: -1.718679428100586
Batch 24/64 loss: -1.546208381652832
Batch 25/64 loss: -1.7501039505004883
Batch 26/64 loss: -1.2733287811279297
Batch 27/64 loss: -1.7221832275390625
Batch 28/64 loss: -1.7912702560424805
Batch 29/64 loss: -1.5351572036743164
Batch 30/64 loss: -1.835897445678711
Batch 31/64 loss: -1.9282102584838867
Batch 32/64 loss: -1.9451112747192383
Batch 33/64 loss: -1.6741762161254883
Batch 34/64 loss: -1.8177299499511719
Batch 35/64 loss: -1.8266544342041016
Batch 36/64 loss: -1.762801170349121
Batch 37/64 loss: -1.7943706512451172
Batch 38/64 loss: -1.675187110900879
Batch 39/64 loss: -1.0253963470458984
Batch 40/64 loss: -1.8362913131713867
Batch 41/64 loss: -1.7702760696411133
Batch 42/64 loss: -2.1835336685180664
Batch 43/64 loss: -1.830245018005371
Batch 44/64 loss: -2.0873069763183594
Batch 45/64 loss: -2.055474281311035
Batch 46/64 loss: -1.9630184173583984
Batch 47/64 loss: -1.5400476455688477
Batch 48/64 loss: -2.0452661514282227
Batch 49/64 loss: -1.3274154663085938
Batch 50/64 loss: -1.5942792892456055
Batch 51/64 loss: -1.3665037155151367
Batch 52/64 loss: -1.850691795349121
Batch 53/64 loss: -1.9376907348632812
Batch 54/64 loss: -1.5848913192749023
Batch 55/64 loss: -1.6082086563110352
Batch 56/64 loss: -1.7901020050048828
Batch 57/64 loss: -1.5223979949951172
Batch 58/64 loss: -1.5265636444091797
Batch 59/64 loss: -1.8025970458984375
Batch 60/64 loss: -1.8929767608642578
Batch 61/64 loss: -1.7487144470214844
Batch 62/64 loss: -1.479426383972168
Batch 63/64 loss: -1.9731483459472656
Batch 64/64 loss: -6.1335859298706055
Epoch 197  Train loss: -1.7722457324757295  Val loss: -2.1004207257143
Epoch 198
-------------------------------
Batch 1/64 loss: -1.9123506546020508
Batch 2/64 loss: -1.4531440734863281
Batch 3/64 loss: -1.6791391372680664
Batch 4/64 loss: -1.5497550964355469
Batch 5/64 loss: -1.3004980087280273
Batch 6/64 loss: -1.3696823120117188
Batch 7/64 loss: -1.7744789123535156
Batch 8/64 loss: -2.035214424133301
Batch 9/64 loss: -1.6817703247070312
Batch 10/64 loss: -2.0571136474609375
Batch 11/64 loss: -2.014739990234375
Batch 12/64 loss: -1.9441204071044922
Batch 13/64 loss: -1.7774391174316406
Batch 14/64 loss: -1.9628477096557617
Batch 15/64 loss: -1.3819618225097656
Batch 16/64 loss: -2.0390310287475586
Batch 17/64 loss: -2.072749137878418
Batch 18/64 loss: -1.2613639831542969
Batch 19/64 loss: -1.8611745834350586
Batch 20/64 loss: -1.6837759017944336
Batch 21/64 loss: -1.8741817474365234
Batch 22/64 loss: -1.8783378601074219
Batch 23/64 loss: -1.567063331604004
Batch 24/64 loss: -1.7900991439819336
Batch 25/64 loss: -1.8234682083129883
Batch 26/64 loss: -2.0039491653442383
Batch 27/64 loss: -1.7684097290039062
Batch 28/64 loss: -1.656355857849121
Batch 29/64 loss: -1.6079721450805664
Batch 30/64 loss: -1.444833755493164
Batch 31/64 loss: -1.4806699752807617
Batch 32/64 loss: -1.897679328918457
Batch 33/64 loss: -1.7754411697387695
Batch 34/64 loss: -1.9779138565063477
Batch 35/64 loss: -1.689199447631836
Batch 36/64 loss: -1.678415298461914
Batch 37/64 loss: -1.769948959350586
Batch 38/64 loss: -1.5509166717529297
Batch 39/64 loss: -1.285832405090332
Batch 40/64 loss: -1.644923210144043
Batch 41/64 loss: -1.8253974914550781
Batch 42/64 loss: -1.8130617141723633
Batch 43/64 loss: -1.8167572021484375
Batch 44/64 loss: -1.619603157043457
Batch 45/64 loss: -1.9535083770751953
Batch 46/64 loss: -1.4570121765136719
Batch 47/64 loss: -1.7819490432739258
Batch 48/64 loss: -1.3783998489379883
Batch 49/64 loss: -1.7004480361938477
Batch 50/64 loss: -1.9525079727172852
Batch 51/64 loss: -1.500406265258789
Batch 52/64 loss: -1.3081417083740234
Batch 53/64 loss: -1.7542037963867188
Batch 54/64 loss: -1.7527589797973633
Batch 55/64 loss: -1.7152881622314453
Batch 56/64 loss: -1.909876823425293
Batch 57/64 loss: -0.9759931564331055
Batch 58/64 loss: -1.7409887313842773
Batch 59/64 loss: -1.7206039428710938
Batch 60/64 loss: -1.8454704284667969
Batch 61/64 loss: -1.0800819396972656
Batch 62/64 loss: -1.8172388076782227
Batch 63/64 loss: -1.900369644165039
Batch 64/64 loss: -5.882800102233887
Epoch 198  Train loss: -1.7523157493740904  Val loss: -1.8381428407229918
Epoch 199
-------------------------------
Batch 1/64 loss: -1.8916988372802734
Batch 2/64 loss: -1.9072771072387695
Batch 3/64 loss: -1.7639598846435547
Batch 4/64 loss: -1.5059175491333008
Batch 5/64 loss: -1.9726238250732422
Batch 6/64 loss: -1.628188133239746
Batch 7/64 loss: -1.925374984741211
Batch 8/64 loss: -1.6670951843261719
Batch 9/64 loss: -1.618149757385254
Batch 10/64 loss: -1.7033710479736328
Batch 11/64 loss: -1.8008127212524414
Batch 12/64 loss: -1.8410263061523438
Batch 13/64 loss: -1.6650333404541016
Batch 14/64 loss: -1.3240108489990234
Batch 15/64 loss: -1.694234848022461
Batch 16/64 loss: -2.034280776977539
Batch 17/64 loss: -1.541398048400879
Batch 18/64 loss: -1.9418458938598633
Batch 19/64 loss: -1.9129629135131836
Batch 20/64 loss: -0.5299768447875977
Batch 21/64 loss: -1.3404626846313477
Batch 22/64 loss: -1.691269874572754
Batch 23/64 loss: -1.6261301040649414
Batch 24/64 loss: -1.9448719024658203
Batch 25/64 loss: -1.8139963150024414
Batch 26/64 loss: -1.9469079971313477
Batch 27/64 loss: -1.8766765594482422
Batch 28/64 loss: -1.6094846725463867
Batch 29/64 loss: -1.6933097839355469
Batch 30/64 loss: -2.019054412841797
Batch 31/64 loss: -1.2223138809204102
Batch 32/64 loss: -2.0210018157958984
Batch 33/64 loss: -1.8937864303588867
Batch 34/64 loss: -1.9779338836669922
Batch 35/64 loss: -1.4617767333984375
Batch 36/64 loss: -1.7586698532104492
Batch 37/64 loss: -1.250056266784668
Batch 38/64 loss: -1.5803146362304688
Batch 39/64 loss: -1.7813282012939453
Batch 40/64 loss: -1.9006643295288086
Batch 41/64 loss: -1.4874610900878906
Batch 42/64 loss: -1.8326854705810547
Batch 43/64 loss: -1.7096328735351562
Batch 44/64 loss: -1.6802120208740234
Batch 45/64 loss: -1.889103889465332
Batch 46/64 loss: -1.6627445220947266
Batch 47/64 loss: -1.959406852722168
Batch 48/64 loss: -1.4772615432739258
Batch 49/64 loss: -1.5797719955444336
Batch 50/64 loss: -1.7887182235717773
Batch 51/64 loss: -1.4893369674682617
Batch 52/64 loss: -1.7410316467285156
Batch 53/64 loss: -1.9286870956420898
Batch 54/64 loss: -1.6667041778564453
Batch 55/64 loss: -1.7495403289794922
Batch 56/64 loss: -1.4289579391479492
Batch 57/64 loss: -2.0070934295654297
Batch 58/64 loss: -1.8475065231323242
Batch 59/64 loss: -1.769078254699707
Batch 60/64 loss: -1.7971467971801758
Batch 61/64 loss: -1.5420856475830078
Batch 62/64 loss: -1.542881965637207
Batch 63/64 loss: -1.8278083801269531
Batch 64/64 loss: -5.960908889770508
Epoch 199  Train loss: -1.7592907999076095  Val loss: -2.128086522682426
Saving best model, epoch: 199
Epoch 200
-------------------------------
Batch 1/64 loss: -1.6641273498535156
Batch 2/64 loss: -1.6227474212646484
Batch 3/64 loss: -1.809366226196289
Batch 4/64 loss: -1.9079036712646484
Batch 5/64 loss: -1.8296566009521484
Batch 6/64 loss: -1.8127021789550781
Batch 7/64 loss: -1.5899381637573242
Batch 8/64 loss: -1.8080329895019531
Batch 9/64 loss: -1.5674495697021484
Batch 10/64 loss: -1.324629783630371
Batch 11/64 loss: -1.8644704818725586
Batch 12/64 loss: -1.0241508483886719
Batch 13/64 loss: -1.604619026184082
Batch 14/64 loss: -1.5065927505493164
Batch 15/64 loss: -1.8214445114135742
Batch 16/64 loss: -1.2468271255493164
Batch 17/64 loss: -1.1553287506103516
Batch 18/64 loss: -1.9130191802978516
Batch 19/64 loss: -1.916585922241211
Batch 20/64 loss: -2.0399742126464844
Batch 21/64 loss: -1.4193716049194336
Batch 22/64 loss: -1.9008703231811523
Batch 23/64 loss: -1.5148935317993164
Batch 24/64 loss: -1.7184457778930664
Batch 25/64 loss: -1.5353460311889648
Batch 26/64 loss: -1.6632862091064453
Batch 27/64 loss: -1.6505565643310547
Batch 28/64 loss: -1.4106454849243164
Batch 29/64 loss: -1.8233757019042969
Batch 30/64 loss: -1.9823989868164062
Batch 31/64 loss: -1.707200050354004
Batch 32/64 loss: -1.9086322784423828
Batch 33/64 loss: -1.9165983200073242
Batch 34/64 loss: -1.6190004348754883
Batch 35/64 loss: -1.2611732482910156
Batch 36/64 loss: -1.4821081161499023
Batch 37/64 loss: -1.6841506958007812
Batch 38/64 loss: -1.8503522872924805
Batch 39/64 loss: -1.5699806213378906
Batch 40/64 loss: -1.6032304763793945
Batch 41/64 loss: -0.8700714111328125
Batch 42/64 loss: -1.5502500534057617
Batch 43/64 loss: -1.8104705810546875
Batch 44/64 loss: -1.5150566101074219
Batch 45/64 loss: -1.9850282669067383
Batch 46/64 loss: -1.6563091278076172
Batch 47/64 loss: -1.8898143768310547
Batch 48/64 loss: -1.5328388214111328
Batch 49/64 loss: -1.6246976852416992
Batch 50/64 loss: -1.7150325775146484
Batch 51/64 loss: -1.5529050827026367
Batch 52/64 loss: -1.280756950378418
Batch 53/64 loss: -1.549607276916504
Batch 54/64 loss: -1.6474723815917969
Batch 55/64 loss: -1.7273197174072266
Batch 56/64 loss: -1.4991455078125
Batch 57/64 loss: -1.7309226989746094
Batch 58/64 loss: -1.4972162246704102
Batch 59/64 loss: -1.2183656692504883
Batch 60/64 loss: -1.416731834411621
Batch 61/64 loss: -1.6048059463500977
Batch 62/64 loss: -1.8321008682250977
Batch 63/64 loss: -1.6663923263549805
Batch 64/64 loss: -5.347293853759766
Epoch 200  Train loss: -1.6727053473977482  Val loss: -1.7833092548593212
Epoch 201
-------------------------------
Batch 1/64 loss: -1.8159751892089844
Batch 2/64 loss: -1.9123821258544922
Batch 3/64 loss: -1.4990463256835938
Batch 4/64 loss: -0.05321216583251953
Batch 5/64 loss: -1.085103988647461
Batch 6/64 loss: -1.6860055923461914
Batch 7/64 loss: -1.4006414413452148
Batch 8/64 loss: -1.1310644149780273
Batch 9/64 loss: -1.5892972946166992
Batch 10/64 loss: -1.9051198959350586
Batch 11/64 loss: -1.6514272689819336
Batch 12/64 loss: -1.1542367935180664
Batch 13/64 loss: -1.667872428894043
Batch 14/64 loss: -1.2447519302368164
Batch 15/64 loss: -1.8480949401855469
Batch 16/64 loss: -1.5367565155029297
Batch 17/64 loss: -1.6319074630737305
Batch 18/64 loss: -1.6716203689575195
Batch 19/64 loss: -1.5541772842407227
Batch 20/64 loss: -1.6041040420532227
Batch 21/64 loss: -1.9207582473754883
Batch 22/64 loss: -1.572993278503418
Batch 23/64 loss: -1.6695737838745117
Batch 24/64 loss: -1.5836362838745117
Batch 25/64 loss: -1.6324005126953125
Batch 26/64 loss: -1.941451072692871
Batch 27/64 loss: -1.617173194885254
Batch 28/64 loss: -1.493769645690918
Batch 29/64 loss: -1.9075632095336914
Batch 30/64 loss: -1.1344690322875977
Batch 31/64 loss: -1.4880695343017578
Batch 32/64 loss: -1.7187690734863281
Batch 33/64 loss: -1.7450485229492188
Batch 34/64 loss: -1.618978500366211
Batch 35/64 loss: -1.4050140380859375
Batch 36/64 loss: -1.9590682983398438
Batch 37/64 loss: -2.021942138671875
Batch 38/64 loss: -1.6397781372070312
Batch 39/64 loss: -1.667037010192871
Batch 40/64 loss: -1.5549230575561523
Batch 41/64 loss: -1.9430208206176758
Batch 42/64 loss: -1.533987045288086
Batch 43/64 loss: -1.8238945007324219
Batch 44/64 loss: -1.719320297241211
Batch 45/64 loss: -1.6424493789672852
Batch 46/64 loss: -1.243514060974121
Batch 47/64 loss: -1.9064664840698242
Batch 48/64 loss: -1.6022987365722656
Batch 49/64 loss: -1.2225723266601562
Batch 50/64 loss: -1.7756414413452148
Batch 51/64 loss: -1.8639163970947266
Batch 52/64 loss: -1.9047355651855469
Batch 53/64 loss: -1.912405014038086
Batch 54/64 loss: -1.6712474822998047
Batch 55/64 loss: -0.9687118530273438
Batch 56/64 loss: -1.2925090789794922
Batch 57/64 loss: -1.7854042053222656
Batch 58/64 loss: -1.9031953811645508
Batch 59/64 loss: -1.6267499923706055
Batch 60/64 loss: -2.046605110168457
Batch 61/64 loss: -1.7265253067016602
Batch 62/64 loss: -1.7541875839233398
Batch 63/64 loss: -1.3759031295776367
Batch 64/64 loss: -5.813471794128418
Epoch 201  Train loss: -1.6555384953816732  Val loss: -2.031503618378
Epoch 202
-------------------------------
Batch 1/64 loss: -1.4084434509277344
Batch 2/64 loss: -1.85736083984375
Batch 3/64 loss: -1.9762201309204102
Batch 4/64 loss: -0.7350587844848633
Batch 5/64 loss: -1.609999656677246
Batch 6/64 loss: -1.8845157623291016
Batch 7/64 loss: -1.7256155014038086
Batch 8/64 loss: -2.0609331130981445
Batch 9/64 loss: -1.3374662399291992
Batch 10/64 loss: -1.9337711334228516
Batch 11/64 loss: -1.9130611419677734
Batch 12/64 loss: -1.7446470260620117
Batch 13/64 loss: -1.5634002685546875
Batch 14/64 loss: -1.4407339096069336
Batch 15/64 loss: -1.698150634765625
Batch 16/64 loss: -1.8780136108398438
Batch 17/64 loss: -1.6659564971923828
Batch 18/64 loss: -1.6480293273925781
Batch 19/64 loss: -1.8841943740844727
Batch 20/64 loss: -1.7088289260864258
Batch 21/64 loss: -1.9975719451904297
Batch 22/64 loss: -1.7107677459716797
Batch 23/64 loss: -1.5443897247314453
Batch 24/64 loss: -1.4175796508789062
Batch 25/64 loss: -2.017031669616699
Batch 26/64 loss: -1.9028453826904297
Batch 27/64 loss: -1.615065574645996
Batch 28/64 loss: -1.8392095565795898
Batch 29/64 loss: -1.912367820739746
Batch 30/64 loss: -1.8830528259277344
Batch 31/64 loss: -2.0136537551879883
Batch 32/64 loss: -1.748316764831543
Batch 33/64 loss: -1.8597946166992188
Batch 34/64 loss: -1.5261507034301758
Batch 35/64 loss: -1.6772031784057617
Batch 36/64 loss: -1.6821069717407227
Batch 37/64 loss: -1.5796403884887695
Batch 38/64 loss: -1.9437456130981445
Batch 39/64 loss: -1.7364883422851562
Batch 40/64 loss: -1.8963632583618164
Batch 41/64 loss: -1.0116510391235352
Batch 42/64 loss: -2.0032453536987305
Batch 43/64 loss: -1.4624748229980469
Batch 44/64 loss: -1.8367671966552734
Batch 45/64 loss: -1.8418779373168945
Batch 46/64 loss: -1.8386526107788086
Batch 47/64 loss: -1.5945167541503906
Batch 48/64 loss: -1.6751861572265625
Batch 49/64 loss: -1.6149988174438477
Batch 50/64 loss: -1.6982307434082031
Batch 51/64 loss: -1.2807188034057617
Batch 52/64 loss: -1.6203556060791016
Batch 53/64 loss: -1.289621353149414
Batch 54/64 loss: -2.090987205505371
Batch 55/64 loss: -1.5162477493286133
Batch 56/64 loss: -1.6671409606933594
Batch 57/64 loss: -2.0482187271118164
Batch 58/64 loss: -1.909738540649414
Batch 59/64 loss: -1.9189987182617188
Batch 60/64 loss: -1.511693000793457
Batch 61/64 loss: -1.8625297546386719
Batch 62/64 loss: -1.8523359298706055
Batch 63/64 loss: -1.5331239700317383
Batch 64/64 loss: -5.681569576263428
Epoch 202  Train loss: -1.7587174078997443  Val loss: -1.9475778271652169
Epoch 203
-------------------------------
Batch 1/64 loss: -1.6694097518920898
Batch 2/64 loss: -1.2362632751464844
Batch 3/64 loss: -1.726644515991211
Batch 4/64 loss: -1.3329572677612305
Batch 5/64 loss: -1.6984329223632812
Batch 6/64 loss: -1.8361387252807617
Batch 7/64 loss: -1.7921743392944336
Batch 8/64 loss: -1.8162612915039062
Batch 9/64 loss: -1.7988052368164062
Batch 10/64 loss: -1.4811944961547852
Batch 11/64 loss: -1.8741445541381836
Batch 12/64 loss: -0.710026741027832
Batch 13/64 loss: -1.7649497985839844
Batch 14/64 loss: -1.6457452774047852
Batch 15/64 loss: -1.6465911865234375
Batch 16/64 loss: -1.850407600402832
Batch 17/64 loss: -1.8226737976074219
Batch 18/64 loss: -1.6058235168457031
Batch 19/64 loss: -1.7195653915405273
Batch 20/64 loss: -1.9439220428466797
Batch 21/64 loss: -1.7491340637207031
Batch 22/64 loss: -1.4076919555664062
Batch 23/64 loss: -1.6660575866699219
Batch 24/64 loss: -1.9786968231201172
Batch 25/64 loss: -1.4535560607910156
Batch 26/64 loss: -1.8278684616088867
Batch 27/64 loss: -1.3795576095581055
Batch 28/64 loss: -1.9568986892700195
Batch 29/64 loss: -1.854842185974121
Batch 30/64 loss: -1.8011274337768555
Batch 31/64 loss: -1.769791603088379
Batch 32/64 loss: -1.9261131286621094
Batch 33/64 loss: -1.7505464553833008
Batch 34/64 loss: -1.7583808898925781
Batch 35/64 loss: -1.71661376953125
Batch 36/64 loss: -1.758148193359375
Batch 37/64 loss: -1.3790912628173828
Batch 38/64 loss: -1.7204761505126953
Batch 39/64 loss: -1.8406009674072266
Batch 40/64 loss: -1.7712459564208984
Batch 41/64 loss: -2.1551036834716797
Batch 42/64 loss: -1.802781105041504
Batch 43/64 loss: -1.6076879501342773
Batch 44/64 loss: -1.8956480026245117
Batch 45/64 loss: -1.6309986114501953
Batch 46/64 loss: -1.9357271194458008
Batch 47/64 loss: -2.1720218658447266
Batch 48/64 loss: -1.8729362487792969
Batch 49/64 loss: -2.1223201751708984
Batch 50/64 loss: -1.4219551086425781
Batch 51/64 loss: -2.01619815826416
Batch 52/64 loss: -2.025179862976074
Batch 53/64 loss: -1.4732599258422852
Batch 54/64 loss: -2.0095319747924805
Batch 55/64 loss: -2.00461483001709
Batch 56/64 loss: -2.048694610595703
Batch 57/64 loss: -1.7016687393188477
Batch 58/64 loss: -1.917677879333496
Batch 59/64 loss: -1.5034027099609375
Batch 60/64 loss: -2.0366554260253906
Batch 61/64 loss: -1.4930849075317383
Batch 62/64 loss: -2.00093936920166
Batch 63/64 loss: -1.7825136184692383
Batch 64/64 loss: -6.293684005737305
Epoch 203  Train loss: -1.8006186017803116  Val loss: -2.165299327103133
Saving best model, epoch: 203
Epoch 204
-------------------------------
Batch 1/64 loss: -1.85626220703125
Batch 2/64 loss: -2.0308837890625
Batch 3/64 loss: -2.0262012481689453
Batch 4/64 loss: -1.9468164443969727
Batch 5/64 loss: -1.9817380905151367
Batch 6/64 loss: -1.641007423400879
Batch 7/64 loss: -1.8946151733398438
Batch 8/64 loss: -1.9389877319335938
Batch 9/64 loss: -1.3013525009155273
Batch 10/64 loss: -1.5508384704589844
Batch 11/64 loss: -2.045933723449707
Batch 12/64 loss: -1.8560609817504883
Batch 13/64 loss: -1.8953781127929688
Batch 14/64 loss: -1.953721046447754
Batch 15/64 loss: -2.0544309616088867
Batch 16/64 loss: -1.4353313446044922
Batch 17/64 loss: -1.5932941436767578
Batch 18/64 loss: -1.8997478485107422
Batch 19/64 loss: -1.5547246932983398
Batch 20/64 loss: -2.1177845001220703
Batch 21/64 loss: -1.9817609786987305
Batch 22/64 loss: -1.582249641418457
Batch 23/64 loss: -1.677206039428711
Batch 24/64 loss: -2.047372817993164
Batch 25/64 loss: -1.9626245498657227
Batch 26/64 loss: -1.692997932434082
Batch 27/64 loss: -1.3610286712646484
Batch 28/64 loss: -1.846053123474121
Batch 29/64 loss: -1.843297004699707
Batch 30/64 loss: -1.946660041809082
Batch 31/64 loss: -2.038344383239746
Batch 32/64 loss: -2.0535593032836914
Batch 33/64 loss: -2.0735254287719727
Batch 34/64 loss: -0.9607534408569336
Batch 35/64 loss: -2.0584707260131836
Batch 36/64 loss: -1.5098257064819336
Batch 37/64 loss: -2.010739326477051
Batch 38/64 loss: -1.5172042846679688
Batch 39/64 loss: -1.9961423873901367
Batch 40/64 loss: -1.840104103088379
Batch 41/64 loss: -1.682002067565918
Batch 42/64 loss: -1.6040840148925781
Batch 43/64 loss: -1.6181659698486328
Batch 44/64 loss: -2.0723772048950195
Batch 45/64 loss: -1.7149648666381836
Batch 46/64 loss: -1.7600059509277344
Batch 47/64 loss: -1.9351139068603516
Batch 48/64 loss: -1.8583984375
Batch 49/64 loss: -1.4354429244995117
Batch 50/64 loss: -1.9716920852661133
Batch 51/64 loss: -1.9241085052490234
Batch 52/64 loss: -1.3948116302490234
Batch 53/64 loss: -1.6028327941894531
Batch 54/64 loss: -1.3641681671142578
Batch 55/64 loss: -1.9689674377441406
Batch 56/64 loss: -1.3727102279663086
Batch 57/64 loss: -1.775350570678711
Batch 58/64 loss: -1.8422632217407227
Batch 59/64 loss: -1.7946853637695312
Batch 60/64 loss: -1.6857032775878906
Batch 61/64 loss: -1.8953094482421875
Batch 62/64 loss: -1.9302082061767578
Batch 63/64 loss: -1.873927116394043
Batch 64/64 loss: -6.084971904754639
Epoch 204  Train loss: -1.838683178845574  Val loss: -2.0789864137000644
Epoch 205
-------------------------------
Batch 1/64 loss: -1.5683879852294922
Batch 2/64 loss: -0.8347997665405273
Batch 3/64 loss: -1.8881492614746094
Batch 4/64 loss: -1.7964744567871094
Batch 5/64 loss: -1.5533819198608398
Batch 6/64 loss: -1.553964614868164
Batch 7/64 loss: -2.0885610580444336
Batch 8/64 loss: -1.814544677734375
Batch 9/64 loss: -1.8140869140625
Batch 10/64 loss: -1.3168210983276367
Batch 11/64 loss: -2.0881948471069336
Batch 12/64 loss: -1.995976448059082
Batch 13/64 loss: -1.860086441040039
Batch 14/64 loss: -1.5109148025512695
Batch 15/64 loss: -1.6448402404785156
Batch 16/64 loss: -1.9239730834960938
Batch 17/64 loss: -1.5160083770751953
Batch 18/64 loss: -1.8782663345336914
Batch 19/64 loss: -2.1497888565063477
Batch 20/64 loss: -1.84130859375
Batch 21/64 loss: -1.9477386474609375
Batch 22/64 loss: -1.1019973754882812
Batch 23/64 loss: -1.4055042266845703
Batch 24/64 loss: -1.2684288024902344
Batch 25/64 loss: -1.8526458740234375
Batch 26/64 loss: -1.8349647521972656
Batch 27/64 loss: -1.939310073852539
Batch 28/64 loss: -1.5496368408203125
Batch 29/64 loss: -1.8854331970214844
Batch 30/64 loss: -2.058133125305176
Batch 31/64 loss: -1.7182016372680664
Batch 32/64 loss: -1.620218276977539
Batch 33/64 loss: -1.8146553039550781
Batch 34/64 loss: -1.897909164428711
Batch 35/64 loss: -1.952535629272461
Batch 36/64 loss: -1.8556547164916992
Batch 37/64 loss: -2.0641584396362305
Batch 38/64 loss: -1.5620965957641602
Batch 39/64 loss: -2.0742311477661133
Batch 40/64 loss: -1.8229293823242188
Batch 41/64 loss: -1.7024545669555664
Batch 42/64 loss: -1.8652973175048828
Batch 43/64 loss: -1.8417282104492188
Batch 44/64 loss: -1.9336748123168945
Batch 45/64 loss: -2.0447845458984375
Batch 46/64 loss: -1.4610700607299805
Batch 47/64 loss: -1.5136699676513672
Batch 48/64 loss: -1.6549015045166016
Batch 49/64 loss: -1.8907709121704102
Batch 50/64 loss: -1.2282800674438477
Batch 51/64 loss: -1.6631784439086914
Batch 52/64 loss: -1.846543312072754
Batch 53/64 loss: -1.8423786163330078
Batch 54/64 loss: -1.9865570068359375
Batch 55/64 loss: -1.9155521392822266
Batch 56/64 loss: -1.91986083984375
Batch 57/64 loss: -1.4758434295654297
Batch 58/64 loss: -2.0136775970458984
Batch 59/64 loss: -2.1079912185668945
Batch 60/64 loss: -2.1429853439331055
Batch 61/64 loss: -1.9786148071289062
Batch 62/64 loss: -1.9052143096923828
Batch 63/64 loss: -1.3135566711425781
Batch 64/64 loss: -6.154789447784424
Epoch 205  Train loss: -1.8153661297816857  Val loss: -2.261895864689883
Saving best model, epoch: 205
Epoch 206
-------------------------------
Batch 1/64 loss: -2.062467575073242
Batch 2/64 loss: -1.5897493362426758
Batch 3/64 loss: -1.9289989471435547
Batch 4/64 loss: -1.665480613708496
Batch 5/64 loss: -1.865203857421875
Batch 6/64 loss: -1.6508903503417969
Batch 7/64 loss: -1.7972431182861328
Batch 8/64 loss: -1.8911933898925781
Batch 9/64 loss: -2.0722579956054688
Batch 10/64 loss: -2.0937442779541016
Batch 11/64 loss: -1.4857845306396484
Batch 12/64 loss: -1.617441177368164
Batch 13/64 loss: -1.7593278884887695
Batch 14/64 loss: -1.4730167388916016
Batch 15/64 loss: -1.6701393127441406
Batch 16/64 loss: -2.0231943130493164
Batch 17/64 loss: -1.860102653503418
Batch 18/64 loss: -1.8341808319091797
Batch 19/64 loss: -1.832921028137207
Batch 20/64 loss: -1.2731456756591797
Batch 21/64 loss: -2.102236747741699
Batch 22/64 loss: -1.5449762344360352
Batch 23/64 loss: -1.9285717010498047
Batch 24/64 loss: -1.8022089004516602
Batch 25/64 loss: -1.6502189636230469
Batch 26/64 loss: -1.8320894241333008
Batch 27/64 loss: -1.9769258499145508
Batch 28/64 loss: -0.7124910354614258
Batch 29/64 loss: -1.8414621353149414
Batch 30/64 loss: -1.225687026977539
Batch 31/64 loss: -1.9132709503173828
Batch 32/64 loss: -2.156731605529785
Batch 33/64 loss: -1.8880853652954102
Batch 34/64 loss: -1.889204978942871
Batch 35/64 loss: -1.6207160949707031
Batch 36/64 loss: -1.7316522598266602
Batch 37/64 loss: -1.782628059387207
Batch 38/64 loss: -1.2907133102416992
Batch 39/64 loss: -2.1256637573242188
Batch 40/64 loss: -1.8170843124389648
Batch 41/64 loss: -1.0796709060668945
Batch 42/64 loss: -0.9613332748413086
Batch 43/64 loss: -1.752309799194336
Batch 44/64 loss: -2.0050573348999023
Batch 45/64 loss: -1.9530096054077148
Batch 46/64 loss: -2.07070255279541
Batch 47/64 loss: -1.8826446533203125
Batch 48/64 loss: -1.695840835571289
Batch 49/64 loss: -1.4862842559814453
Batch 50/64 loss: -1.9317398071289062
Batch 51/64 loss: -1.7203140258789062
Batch 52/64 loss: -1.824070930480957
Batch 53/64 loss: -1.852992057800293
Batch 54/64 loss: -1.8129968643188477
Batch 55/64 loss: -1.7304916381835938
Batch 56/64 loss: -1.8981313705444336
Batch 57/64 loss: -1.8482370376586914
Batch 58/64 loss: -2.07724666595459
Batch 59/64 loss: -2.0267887115478516
Batch 60/64 loss: -1.784449577331543
Batch 61/64 loss: -1.982987403869629
Batch 62/64 loss: -1.9374370574951172
Batch 63/64 loss: -2.143366813659668
Batch 64/64 loss: -6.304350852966309
Epoch 206  Train loss: -1.8269093120799345  Val loss: -2.1679779131387926
Epoch 207
-------------------------------
Batch 1/64 loss: -1.9490060806274414
Batch 2/64 loss: -2.0003013610839844
Batch 3/64 loss: -2.0245542526245117
Batch 4/64 loss: -1.9886484146118164
Batch 5/64 loss: -1.9563274383544922
Batch 6/64 loss: -1.8332128524780273
Batch 7/64 loss: -1.253209114074707
Batch 8/64 loss: -1.9164495468139648
Batch 9/64 loss: -2.1310768127441406
Batch 10/64 loss: -1.8403615951538086
Batch 11/64 loss: -1.7159900665283203
Batch 12/64 loss: -1.7406787872314453
Batch 13/64 loss: -1.6951332092285156
Batch 14/64 loss: -1.9045391082763672
Batch 15/64 loss: -1.8428621292114258
Batch 16/64 loss: -1.2420053482055664
Batch 17/64 loss: -1.7814149856567383
Batch 18/64 loss: -1.8733444213867188
Batch 19/64 loss: -1.953293800354004
Batch 20/64 loss: -1.8303537368774414
Batch 21/64 loss: -1.7767963409423828
Batch 22/64 loss: -1.1508207321166992
Batch 23/64 loss: -1.1766538619995117
Batch 24/64 loss: -1.9638795852661133
Batch 25/64 loss: -1.7477779388427734
Batch 26/64 loss: -2.027255058288574
Batch 27/64 loss: -2.057659149169922
Batch 28/64 loss: -1.6628122329711914
Batch 29/64 loss: -1.8141117095947266
Batch 30/64 loss: -1.7046661376953125
Batch 31/64 loss: -1.7981491088867188
Batch 32/64 loss: -1.856095314025879
Batch 33/64 loss: -1.9851188659667969
Batch 34/64 loss: -1.7207574844360352
Batch 35/64 loss: -1.6658716201782227
Batch 36/64 loss: -1.6781015396118164
Batch 37/64 loss: -1.9275455474853516
Batch 38/64 loss: -1.7720823287963867
Batch 39/64 loss: -2.1875171661376953
Batch 40/64 loss: -1.9347734451293945
Batch 41/64 loss: -2.0280113220214844
Batch 42/64 loss: -1.7381591796875
Batch 43/64 loss: -2.1515750885009766
Batch 44/64 loss: -2.155923843383789
Batch 45/64 loss: -1.7228403091430664
Batch 46/64 loss: -1.896824836730957
Batch 47/64 loss: -1.9770288467407227
Batch 48/64 loss: -2.1185054779052734
Batch 49/64 loss: -1.8641538619995117
Batch 50/64 loss: -1.640829086303711
Batch 51/64 loss: -1.659388542175293
Batch 52/64 loss: -1.9836444854736328
Batch 53/64 loss: -1.8211278915405273
Batch 54/64 loss: -1.694009780883789
Batch 55/64 loss: -1.4313020706176758
Batch 56/64 loss: -1.8977231979370117
Batch 57/64 loss: -1.9047584533691406
Batch 58/64 loss: -1.8524675369262695
Batch 59/64 loss: -1.7322282791137695
Batch 60/64 loss: -1.3433141708374023
Batch 61/64 loss: -1.1357660293579102
Batch 62/64 loss: -1.523263931274414
Batch 63/64 loss: -1.302297592163086
Batch 64/64 loss: -5.977949619293213
Epoch 207  Train loss: -1.8374872824724984  Val loss: -2.0010737782901096
Epoch 208
-------------------------------
Batch 1/64 loss: -1.9511909484863281
Batch 2/64 loss: -1.714223861694336
Batch 3/64 loss: -1.6811342239379883
Batch 4/64 loss: -1.7422094345092773
Batch 5/64 loss: -1.781473159790039
Batch 6/64 loss: -1.7588586807250977
Batch 7/64 loss: -1.8709182739257812
Batch 8/64 loss: -1.466689109802246
Batch 9/64 loss: -1.7880182266235352
Batch 10/64 loss: -0.840977668762207
Batch 11/64 loss: -1.8112373352050781
Batch 12/64 loss: -2.0204734802246094
Batch 13/64 loss: -1.370208740234375
Batch 14/64 loss: -1.3734397888183594
Batch 15/64 loss: -1.5428314208984375
Batch 16/64 loss: -1.8274860382080078
Batch 17/64 loss: -1.7421960830688477
Batch 18/64 loss: -1.6969127655029297
Batch 19/64 loss: -1.6580133438110352
Batch 20/64 loss: -1.7291488647460938
Batch 21/64 loss: -1.9831886291503906
Batch 22/64 loss: -1.5327672958374023
Batch 23/64 loss: -1.9105186462402344
Batch 24/64 loss: -1.7605514526367188
Batch 25/64 loss: -1.9336376190185547
Batch 26/64 loss: -1.5790691375732422
Batch 27/64 loss: -1.557464599609375
Batch 28/64 loss: -1.8020257949829102
Batch 29/64 loss: -1.9221343994140625
Batch 30/64 loss: -1.8638038635253906
Batch 31/64 loss: -1.7521305084228516
Batch 32/64 loss: -1.712538719177246
Batch 33/64 loss: -1.910201072692871
Batch 34/64 loss: -1.691925048828125
Batch 35/64 loss: -1.6252288818359375
Batch 36/64 loss: -1.913492202758789
Batch 37/64 loss: -1.8060121536254883
Batch 38/64 loss: -1.4160642623901367
Batch 39/64 loss: -1.6636161804199219
Batch 40/64 loss: -1.5458927154541016
Batch 41/64 loss: -1.6909494400024414
Batch 42/64 loss: -1.8810443878173828
Batch 43/64 loss: -1.9606332778930664
Batch 44/64 loss: -1.6046733856201172
Batch 45/64 loss: -0.8291826248168945
Batch 46/64 loss: -1.3382434844970703
Batch 47/64 loss: -1.9788331985473633
Batch 48/64 loss: -1.757756233215332
Batch 49/64 loss: -1.0498228073120117
Batch 50/64 loss: -1.003957748413086
Batch 51/64 loss: -1.932175636291504
Batch 52/64 loss: -1.8075675964355469
Batch 53/64 loss: -1.8889799118041992
Batch 54/64 loss: -1.7337665557861328
Batch 55/64 loss: -1.6661338806152344
Batch 56/64 loss: -1.9399328231811523
Batch 57/64 loss: -1.7573795318603516
Batch 58/64 loss: -1.6969938278198242
Batch 59/64 loss: -1.9467639923095703
Batch 60/64 loss: -1.6468582153320312
Batch 61/64 loss: -1.7379837036132812
Batch 62/64 loss: -1.581644058227539
Batch 63/64 loss: -1.774275779724121
Batch 64/64 loss: -6.179537296295166
Epoch 208  Train loss: -1.7425899561713725  Val loss: -2.0553480718553683
Epoch 209
-------------------------------
Batch 1/64 loss: -2.1252126693725586
Batch 2/64 loss: -1.683537483215332
Batch 3/64 loss: -1.7641115188598633
Batch 4/64 loss: -1.7621517181396484
Batch 5/64 loss: -2.042825698852539
Batch 6/64 loss: -1.5141468048095703
Batch 7/64 loss: -1.9132966995239258
Batch 8/64 loss: -1.9402828216552734
Batch 9/64 loss: -2.054677963256836
Batch 10/64 loss: -1.8805294036865234
Batch 11/64 loss: -1.7903108596801758
Batch 12/64 loss: -1.7981500625610352
Batch 13/64 loss: -2.0690765380859375
Batch 14/64 loss: -1.955678939819336
Batch 15/64 loss: -1.7928037643432617
Batch 16/64 loss: -1.7758569717407227
Batch 17/64 loss: -1.7456779479980469
Batch 18/64 loss: -1.6124067306518555
Batch 19/64 loss: -1.6565561294555664
Batch 20/64 loss: -1.9256210327148438
Batch 21/64 loss: -1.6471672058105469
Batch 22/64 loss: -1.7598800659179688
Batch 23/64 loss: -1.660501480102539
Batch 24/64 loss: -1.268437385559082
Batch 25/64 loss: -1.8575553894042969
Batch 26/64 loss: -1.9360895156860352
Batch 27/64 loss: -1.146662712097168
Batch 28/64 loss: -1.782999038696289
Batch 29/64 loss: -1.9471235275268555
Batch 30/64 loss: -1.9944515228271484
Batch 31/64 loss: -1.7208023071289062
Batch 32/64 loss: -1.9721040725708008
Batch 33/64 loss: -1.3687524795532227
Batch 34/64 loss: -1.8216838836669922
Batch 35/64 loss: -1.90753173828125
Batch 36/64 loss: -1.7749862670898438
Batch 37/64 loss: -1.71826171875
Batch 38/64 loss: -1.7669076919555664
Batch 39/64 loss: -1.8940954208374023
Batch 40/64 loss: -1.681229591369629
Batch 41/64 loss: -1.6982688903808594
Batch 42/64 loss: -1.9235830307006836
Batch 43/64 loss: -1.9054088592529297
Batch 44/64 loss: -2.001336097717285
Batch 45/64 loss: -1.675048828125
Batch 46/64 loss: -1.6185798645019531
Batch 47/64 loss: -1.952352523803711
Batch 48/64 loss: -1.6601133346557617
Batch 49/64 loss: -1.7411479949951172
Batch 50/64 loss: -0.7507972717285156
Batch 51/64 loss: -1.5858583450317383
Batch 52/64 loss: -2.0478515625
Batch 53/64 loss: -1.9529485702514648
Batch 54/64 loss: -1.9555931091308594
Batch 55/64 loss: -1.3097953796386719
Batch 56/64 loss: -1.9759645462036133
Batch 57/64 loss: -2.035825729370117
Batch 58/64 loss: -2.0468740463256836
Batch 59/64 loss: -1.5542659759521484
Batch 60/64 loss: -1.670985221862793
Batch 61/64 loss: -1.814889907836914
Batch 62/64 loss: -2.0628719329833984
Batch 63/64 loss: -2.0905590057373047
Batch 64/64 loss: -5.995545864105225
Epoch 209  Train loss: -1.8346308109807032  Val loss: -1.988102444258752
Epoch 210
-------------------------------
Batch 1/64 loss: -1.551473617553711
Batch 2/64 loss: -1.9675817489624023
Batch 3/64 loss: -1.4264087677001953
Batch 4/64 loss: -1.9701995849609375
Batch 5/64 loss: -2.046283721923828
Batch 6/64 loss: -1.5866947174072266
Batch 7/64 loss: -1.7839202880859375
Batch 8/64 loss: -1.7867937088012695
Batch 9/64 loss: -1.4470939636230469
Batch 10/64 loss: -1.9163141250610352
Batch 11/64 loss: -1.9906606674194336
Batch 12/64 loss: -1.8328065872192383
Batch 13/64 loss: -1.5286016464233398
Batch 14/64 loss: -1.9434843063354492
Batch 15/64 loss: -1.909571647644043
Batch 16/64 loss: -1.8742609024047852
Batch 17/64 loss: -1.9760551452636719
Batch 18/64 loss: -1.937957763671875
Batch 19/64 loss: -1.6731176376342773
Batch 20/64 loss: -1.7168540954589844
Batch 21/64 loss: -1.5817689895629883
Batch 22/64 loss: -1.1197500228881836
Batch 23/64 loss: -1.2166013717651367
Batch 24/64 loss: -2.0397653579711914
Batch 25/64 loss: -1.9718236923217773
Batch 26/64 loss: -1.563735008239746
Batch 27/64 loss: -1.3665494918823242
Batch 28/64 loss: -1.7772493362426758
Batch 29/64 loss: -1.9314508438110352
Batch 30/64 loss: -1.7701053619384766
Batch 31/64 loss: -1.8991374969482422
Batch 32/64 loss: -1.513895034790039
Batch 33/64 loss: -1.6062383651733398
Batch 34/64 loss: -2.077045440673828
Batch 35/64 loss: -1.9538803100585938
Batch 36/64 loss: -2.0049638748168945
Batch 37/64 loss: -2.087587356567383
Batch 38/64 loss: -0.9065427780151367
Batch 39/64 loss: -1.9539642333984375
Batch 40/64 loss: -1.9732532501220703
Batch 41/64 loss: -1.8553390502929688
Batch 42/64 loss: -1.3706369400024414
Batch 43/64 loss: -1.929743766784668
Batch 44/64 loss: -2.2890357971191406
Batch 45/64 loss: -1.922433853149414
Batch 46/64 loss: -1.4771833419799805
Batch 47/64 loss: -1.94573974609375
Batch 48/64 loss: -2.20388126373291
Batch 49/64 loss: -1.6425552368164062
Batch 50/64 loss: -1.5948352813720703
Batch 51/64 loss: -1.8436470031738281
Batch 52/64 loss: -1.8552093505859375
Batch 53/64 loss: -2.0018491744995117
Batch 54/64 loss: -1.9131336212158203
Batch 55/64 loss: -1.9260530471801758
Batch 56/64 loss: -1.6812505722045898
Batch 57/64 loss: -1.751358985900879
Batch 58/64 loss: -1.4843130111694336
Batch 59/64 loss: -1.8817167282104492
Batch 60/64 loss: -1.8365659713745117
Batch 61/64 loss: -1.9339332580566406
Batch 62/64 loss: -2.1542749404907227
Batch 63/64 loss: -2.0664987564086914
Batch 64/64 loss: -6.115915775299072
Epoch 210  Train loss: -1.8404638084710814  Val loss: -2.187728803182386
Epoch 211
-------------------------------
Batch 1/64 loss: -1.912856101989746
Batch 2/64 loss: -1.5168380737304688
Batch 3/64 loss: -1.921980857849121
Batch 4/64 loss: -1.4345178604125977
Batch 5/64 loss: -1.8778467178344727
Batch 6/64 loss: -2.0190210342407227
Batch 7/64 loss: -2.045037269592285
Batch 8/64 loss: -1.3709259033203125
Batch 9/64 loss: -2.0641603469848633
Batch 10/64 loss: -1.8420000076293945
Batch 11/64 loss: -1.8788671493530273
Batch 12/64 loss: -1.7016925811767578
Batch 13/64 loss: -1.7503070831298828
Batch 14/64 loss: -1.8947820663452148
Batch 15/64 loss: -1.421015739440918
Batch 16/64 loss: -1.4037294387817383
Batch 17/64 loss: -2.0201797485351562
Batch 18/64 loss: -1.2349519729614258
Batch 19/64 loss: -1.9434623718261719
Batch 20/64 loss: -1.6966800689697266
Batch 21/64 loss: -2.0496530532836914
Batch 22/64 loss: -1.7079744338989258
Batch 23/64 loss: -1.8045883178710938
Batch 24/64 loss: -1.720571517944336
Batch 25/64 loss: -1.7186708450317383
Batch 26/64 loss: -1.313741683959961
Batch 27/64 loss: -1.9313077926635742
Batch 28/64 loss: -1.5977630615234375
Batch 29/64 loss: -1.7822837829589844
Batch 30/64 loss: -1.859323501586914
Batch 31/64 loss: -1.7816267013549805
Batch 32/64 loss: -1.8360309600830078
Batch 33/64 loss: -1.634347915649414
Batch 34/64 loss: -2.0170745849609375
Batch 35/64 loss: -1.8825998306274414
Batch 36/64 loss: -1.5885734558105469
Batch 37/64 loss: -1.934493064880371
Batch 38/64 loss: -1.0380048751831055
Batch 39/64 loss: -1.9050579071044922
Batch 40/64 loss: -1.8974103927612305
Batch 41/64 loss: -1.593094825744629
Batch 42/64 loss: -2.058248519897461
Batch 43/64 loss: -2.1332998275756836
Batch 44/64 loss: -1.9539365768432617
Batch 45/64 loss: -1.5214824676513672
Batch 46/64 loss: -1.6592073440551758
Batch 47/64 loss: -1.2781400680541992
Batch 48/64 loss: -2.066709518432617
Batch 49/64 loss: -1.7372779846191406
Batch 50/64 loss: -1.7705297470092773
Batch 51/64 loss: -1.9022912979125977
Batch 52/64 loss: -1.7608261108398438
Batch 53/64 loss: -1.3345918655395508
Batch 54/64 loss: -1.9144678115844727
Batch 55/64 loss: -1.3876028060913086
Batch 56/64 loss: -1.6567258834838867
Batch 57/64 loss: -1.7726097106933594
Batch 58/64 loss: -1.6823949813842773
Batch 59/64 loss: -1.864542007446289
Batch 60/64 loss: -1.4965600967407227
Batch 61/64 loss: -1.9352397918701172
Batch 62/64 loss: -1.9083013534545898
Batch 63/64 loss: -2.0249242782592773
Batch 64/64 loss: -6.083380222320557
Epoch 211  Train loss: -1.8027841586692661  Val loss: -1.86516092569148
Epoch 212
-------------------------------
Batch 1/64 loss: -1.4544315338134766
Batch 2/64 loss: -1.4476242065429688
Batch 3/64 loss: -1.5387964248657227
Batch 4/64 loss: -1.4858455657958984
Batch 5/64 loss: -1.5940790176391602
Batch 6/64 loss: -1.0660343170166016
Batch 7/64 loss: -1.4202470779418945
Batch 8/64 loss: -1.6590518951416016
Batch 9/64 loss: -1.6919212341308594
Batch 10/64 loss: -1.5234003067016602
Batch 11/64 loss: -1.6111259460449219
Batch 12/64 loss: -1.5043573379516602
Batch 13/64 loss: -1.3784122467041016
Batch 14/64 loss: -1.5277748107910156
Batch 15/64 loss: -1.1211357116699219
Batch 16/64 loss: -1.6727399826049805
Batch 17/64 loss: -1.3697662353515625
Batch 18/64 loss: -1.4290447235107422
Batch 19/64 loss: -1.8326644897460938
Batch 20/64 loss: -1.6702899932861328
Batch 21/64 loss: -1.5147476196289062
Batch 22/64 loss: -1.1640033721923828
Batch 23/64 loss: -1.7592096328735352
Batch 24/64 loss: -1.782308578491211
Batch 25/64 loss: -2.014972686767578
Batch 26/64 loss: -2.007335662841797
Batch 27/64 loss: -1.9052515029907227
Batch 28/64 loss: -1.7608137130737305
Batch 29/64 loss: -1.8527450561523438
Batch 30/64 loss: -1.5576200485229492
Batch 31/64 loss: -1.702840805053711
Batch 32/64 loss: -1.6232175827026367
Batch 33/64 loss: -1.8827381134033203
Batch 34/64 loss: -1.9703550338745117
Batch 35/64 loss: -1.6836013793945312
Batch 36/64 loss: -1.8144950866699219
Batch 37/64 loss: -1.3787412643432617
Batch 38/64 loss: -1.2025833129882812
Batch 39/64 loss: -1.8643150329589844
Batch 40/64 loss: -0.9864597320556641
Batch 41/64 loss: -1.6487598419189453
Batch 42/64 loss: -0.9406538009643555
Batch 43/64 loss: -1.0224733352661133
Batch 44/64 loss: -1.7680749893188477
Batch 45/64 loss: -1.4949579238891602
Batch 46/64 loss: -1.326451301574707
Batch 47/64 loss: -1.7128620147705078
Batch 48/64 loss: -1.7930107116699219
Batch 49/64 loss: -1.088850975036621
Batch 50/64 loss: -1.5499181747436523
Batch 51/64 loss: -1.6739368438720703
Batch 52/64 loss: -1.5153627395629883
Batch 53/64 loss: -1.3859825134277344
Batch 54/64 loss: -1.6374921798706055
Batch 55/64 loss: -1.6775054931640625
Batch 56/64 loss: -1.9518623352050781
Batch 57/64 loss: -1.8759536743164062
Batch 58/64 loss: -2.0245466232299805
Batch 59/64 loss: -2.099978446960449
Batch 60/64 loss: -1.7509164810180664
Batch 61/64 loss: -1.8437767028808594
Batch 62/64 loss: -1.9247446060180664
Batch 63/64 loss: -1.378596305847168
Batch 64/64 loss: -5.334861755371094
Epoch 212  Train loss: -1.6394496094946769  Val loss: -1.5787871055996294
Epoch 213
-------------------------------
Batch 1/64 loss: -1.8967714309692383
Batch 2/64 loss: -1.746023178100586
Batch 3/64 loss: -1.0086965560913086
Batch 4/64 loss: -1.8987789154052734
Batch 5/64 loss: -2.085315704345703
Batch 6/64 loss: -1.890049934387207
Batch 7/64 loss: -1.151646614074707
Batch 8/64 loss: -1.3077726364135742
Batch 9/64 loss: -1.9950027465820312
Batch 10/64 loss: -1.8103151321411133
Batch 11/64 loss: -1.7345142364501953
Batch 12/64 loss: -1.9574508666992188
Batch 13/64 loss: -1.9908418655395508
Batch 14/64 loss: -1.6011409759521484
Batch 15/64 loss: -2.015392303466797
Batch 16/64 loss: -0.9843969345092773
Batch 17/64 loss: -2.160612106323242
Batch 18/64 loss: -1.344761848449707
Batch 19/64 loss: -1.6910219192504883
Batch 20/64 loss: -1.4078989028930664
Batch 21/64 loss: -1.5452947616577148
Batch 22/64 loss: -0.3447999954223633
Batch 23/64 loss: -2.014354705810547
Batch 24/64 loss: -1.6814699172973633
Batch 25/64 loss: -1.1150646209716797
Batch 26/64 loss: -1.6984128952026367
Batch 27/64 loss: -1.4631280899047852
Batch 28/64 loss: -2.052532196044922
Batch 29/64 loss: -1.859670639038086
Batch 30/64 loss: -2.081510543823242
Batch 31/64 loss: -1.6857376098632812
Batch 32/64 loss: -1.7347869873046875
Batch 33/64 loss: -1.6168622970581055
Batch 34/64 loss: -1.3078937530517578
Batch 35/64 loss: -1.7930526733398438
Batch 36/64 loss: -1.894455909729004
Batch 37/64 loss: -1.853529930114746
Batch 38/64 loss: -1.7133798599243164
Batch 39/64 loss: 2.269174575805664
Batch 40/64 loss: -0.3734588623046875
Batch 41/64 loss: -1.701681137084961
Batch 42/64 loss: -1.7572956085205078
Batch 43/64 loss: -1.851902961730957
Batch 44/64 loss: -1.6040410995483398
Batch 45/64 loss: -1.9942779541015625
Batch 46/64 loss: -1.9955596923828125
Batch 47/64 loss: -1.4718751907348633
Batch 48/64 loss: -2.129998207092285
Batch 49/64 loss: -1.773580551147461
Batch 50/64 loss: -1.531005859375
Batch 51/64 loss: -1.856271743774414
Batch 52/64 loss: -1.9484634399414062
Batch 53/64 loss: -1.6901359558105469
Batch 54/64 loss: -1.5391044616699219
Batch 55/64 loss: -1.9330148696899414
Batch 56/64 loss: -1.8705987930297852
Batch 57/64 loss: -2.0470056533813477
Batch 58/64 loss: -1.6500434875488281
Batch 59/64 loss: -2.0130815505981445
Batch 60/64 loss: -1.8959894180297852
Batch 61/64 loss: -2.037891387939453
Batch 62/64 loss: -1.7355833053588867
Batch 63/64 loss: -0.9475784301757812
Batch 64/64 loss: -6.052618026733398
Epoch 213  Train loss: -1.6745736589618758  Val loss: -1.9707634260564326
Epoch 214
-------------------------------
Batch 1/64 loss: -1.759786605834961
Batch 2/64 loss: -1.6105518341064453
Batch 3/64 loss: -1.7961578369140625
Batch 4/64 loss: -1.8750314712524414
Batch 5/64 loss: -1.786433219909668
Batch 6/64 loss: -1.9712953567504883
Batch 7/64 loss: -1.7921228408813477
Batch 8/64 loss: -2.058002471923828
Batch 9/64 loss: -1.9015913009643555
Batch 10/64 loss: -2.0712833404541016
Batch 11/64 loss: -1.747675895690918
Batch 12/64 loss: -1.40948486328125
Batch 13/64 loss: -1.3810863494873047
Batch 14/64 loss: -1.8593635559082031
Batch 15/64 loss: -1.535456657409668
Batch 16/64 loss: -1.5536251068115234
Batch 17/64 loss: -1.7208786010742188
Batch 18/64 loss: -1.832444190979004
Batch 19/64 loss: -2.036348342895508
Batch 20/64 loss: -1.9418363571166992
Batch 21/64 loss: -1.5958576202392578
Batch 22/64 loss: -2.0365257263183594
Batch 23/64 loss: -1.977158546447754
Batch 24/64 loss: -1.03875732421875
Batch 25/64 loss: -1.865488052368164
Batch 26/64 loss: -1.9762725830078125
Batch 27/64 loss: -1.6742525100708008
Batch 28/64 loss: -1.874527931213379
Batch 29/64 loss: -1.465372085571289
Batch 30/64 loss: -1.6768484115600586
Batch 31/64 loss: -1.847884178161621
Batch 32/64 loss: -1.8326587677001953
Batch 33/64 loss: -1.6939172744750977
Batch 34/64 loss: -1.712672233581543
Batch 35/64 loss: -1.7865886688232422
Batch 36/64 loss: -1.8580684661865234
Batch 37/64 loss: -1.6852731704711914
Batch 38/64 loss: -1.6895723342895508
Batch 39/64 loss: -1.4297943115234375
Batch 40/64 loss: -1.7270517349243164
Batch 41/64 loss: -1.6241655349731445
Batch 42/64 loss: -0.9914045333862305
Batch 43/64 loss: -1.2604379653930664
Batch 44/64 loss: -2.1182003021240234
Batch 45/64 loss: -1.6795930862426758
Batch 46/64 loss: -1.926386833190918
Batch 47/64 loss: -1.9363765716552734
Batch 48/64 loss: -1.7455005645751953
Batch 49/64 loss: -1.586287498474121
Batch 50/64 loss: -1.8944530487060547
Batch 51/64 loss: -1.984816551208496
Batch 52/64 loss: -1.5415067672729492
Batch 53/64 loss: -1.7913990020751953
Batch 54/64 loss: -2.058340072631836
Batch 55/64 loss: -1.581075668334961
Batch 56/64 loss: -1.7850170135498047
Batch 57/64 loss: -1.780024528503418
Batch 58/64 loss: -1.3534908294677734
Batch 59/64 loss: -1.7943925857543945
Batch 60/64 loss: -1.9513750076293945
Batch 61/64 loss: -1.890695571899414
Batch 62/64 loss: -1.5448246002197266
Batch 63/64 loss: -2.157853126525879
Batch 64/64 loss: -6.195406913757324
Epoch 214  Train loss: -1.7993595385083965  Val loss: -2.1487026280144237
Epoch 215
-------------------------------
Batch 1/64 loss: -2.0766849517822266
Batch 2/64 loss: -1.9160690307617188
Batch 3/64 loss: -1.6808967590332031
Batch 4/64 loss: -1.7191123962402344
Batch 5/64 loss: -2.0022315979003906
Batch 6/64 loss: -2.112794876098633
Batch 7/64 loss: -2.0006256103515625
Batch 8/64 loss: -1.9226417541503906
Batch 9/64 loss: -1.71417236328125
Batch 10/64 loss: -1.4694433212280273
Batch 11/64 loss: -1.9491348266601562
Batch 12/64 loss: -2.1181859970092773
Batch 13/64 loss: -2.0369997024536133
Batch 14/64 loss: -2.124190330505371
Batch 15/64 loss: -1.2417211532592773
Batch 16/64 loss: -1.807016372680664
Batch 17/64 loss: -2.0444726943969727
Batch 18/64 loss: -2.004514694213867
Batch 19/64 loss: -1.878504753112793
Batch 20/64 loss: -2.0328617095947266
Batch 21/64 loss: -1.5001401901245117
Batch 22/64 loss: -1.8733978271484375
Batch 23/64 loss: -1.8289070129394531
Batch 24/64 loss: -1.922835350036621
Batch 25/64 loss: -1.5058517456054688
Batch 26/64 loss: -2.0189599990844727
Batch 27/64 loss: -1.5850133895874023
Batch 28/64 loss: -2.081881523132324
Batch 29/64 loss: -1.8294734954833984
Batch 30/64 loss: -2.0101375579833984
Batch 31/64 loss: -1.996337890625
Batch 32/64 loss: -1.9642581939697266
Batch 33/64 loss: -1.9097843170166016
Batch 34/64 loss: -1.7047443389892578
Batch 35/64 loss: -1.7038888931274414
Batch 36/64 loss: -1.8122215270996094
Batch 37/64 loss: -2.0949363708496094
Batch 38/64 loss: -1.8267555236816406
Batch 39/64 loss: -2.0110387802124023
Batch 40/64 loss: -1.8569774627685547
Batch 41/64 loss: -1.6985416412353516
Batch 42/64 loss: -1.9875307083129883
Batch 43/64 loss: -2.1133337020874023
Batch 44/64 loss: -1.9324760437011719
Batch 45/64 loss: -2.021900177001953
Batch 46/64 loss: -1.6223430633544922
Batch 47/64 loss: -1.8656587600708008
Batch 48/64 loss: -2.217733383178711
Batch 49/64 loss: -1.948526382446289
Batch 50/64 loss: -1.7752275466918945
Batch 51/64 loss: -1.839747428894043
Batch 52/64 loss: -1.7199335098266602
Batch 53/64 loss: -1.4299936294555664
Batch 54/64 loss: -2.100346565246582
Batch 55/64 loss: -1.4437122344970703
Batch 56/64 loss: -1.9210309982299805
Batch 57/64 loss: -1.9839649200439453
Batch 58/64 loss: -1.7156906127929688
Batch 59/64 loss: -1.666764259338379
Batch 60/64 loss: -1.623642921447754
Batch 61/64 loss: -1.700556755065918
Batch 62/64 loss: -1.0042524337768555
Batch 63/64 loss: -1.5574331283569336
Batch 64/64 loss: -5.864542007446289
Epoch 215  Train loss: -1.885153938742245  Val loss: -1.9847648332209111
Epoch 216
-------------------------------
Batch 1/64 loss: -1.8981313705444336
Batch 2/64 loss: -1.8493995666503906
Batch 3/64 loss: -1.9834918975830078
Batch 4/64 loss: -1.8235740661621094
Batch 5/64 loss: -1.772099494934082
Batch 6/64 loss: -1.5412368774414062
Batch 7/64 loss: -1.9028568267822266
Batch 8/64 loss: -1.6057300567626953
Batch 9/64 loss: -1.7959213256835938
Batch 10/64 loss: -1.8310117721557617
Batch 11/64 loss: -1.6826257705688477
Batch 12/64 loss: -1.937342643737793
Batch 13/64 loss: -1.8407344818115234
Batch 14/64 loss: -1.5316858291625977
Batch 15/64 loss: -1.8826370239257812
Batch 16/64 loss: -2.050723075866699
Batch 17/64 loss: -1.8381662368774414
Batch 18/64 loss: -1.4551191329956055
Batch 19/64 loss: -1.9632596969604492
Batch 20/64 loss: -1.7767448425292969
Batch 21/64 loss: -1.8671255111694336
Batch 22/64 loss: -1.8381166458129883
Batch 23/64 loss: -1.2600879669189453
Batch 24/64 loss: -1.3408288955688477
Batch 25/64 loss: -1.678049087524414
Batch 26/64 loss: -1.7728700637817383
Batch 27/64 loss: -1.6966962814331055
Batch 28/64 loss: -1.4862689971923828
Batch 29/64 loss: -1.8948173522949219
Batch 30/64 loss: -1.61004638671875
Batch 31/64 loss: -1.6529731750488281
Batch 32/64 loss: -1.978811264038086
Batch 33/64 loss: -1.8605432510375977
Batch 34/64 loss: -1.9150934219360352
Batch 35/64 loss: -1.718606948852539
Batch 36/64 loss: -2.01309871673584
Batch 37/64 loss: -2.007948875427246
Batch 38/64 loss: -1.7564077377319336
Batch 39/64 loss: -1.679203987121582
Batch 40/64 loss: -2.0596494674682617
Batch 41/64 loss: -1.901331901550293
Batch 42/64 loss: -1.5279579162597656
Batch 43/64 loss: -2.0705976486206055
Batch 44/64 loss: -1.9823904037475586
Batch 45/64 loss: -1.8306798934936523
Batch 46/64 loss: -1.8742332458496094
Batch 47/64 loss: -1.3717422485351562
Batch 48/64 loss: -2.0373945236206055
Batch 49/64 loss: -2.055877685546875
Batch 50/64 loss: -1.8244342803955078
Batch 51/64 loss: -1.279489517211914
Batch 52/64 loss: -1.2330217361450195
Batch 53/64 loss: -1.7462759017944336
Batch 54/64 loss: -1.5771474838256836
Batch 55/64 loss: -1.1723642349243164
Batch 56/64 loss: -1.6761360168457031
Batch 57/64 loss: -2.077363967895508
Batch 58/64 loss: -1.3240766525268555
Batch 59/64 loss: -1.7448034286499023
Batch 60/64 loss: -1.7468976974487305
Batch 61/64 loss: -1.7995185852050781
Batch 62/64 loss: -1.973012924194336
Batch 63/64 loss: -1.947810173034668
Batch 64/64 loss: -6.137787818908691
Epoch 216  Train loss: -1.8106295679129807  Val loss: -2.09885802383685
Epoch 217
-------------------------------
Batch 1/64 loss: -2.10471248626709
Batch 2/64 loss: -1.581146240234375
Batch 3/64 loss: -1.744929313659668
Batch 4/64 loss: -1.8712882995605469
Batch 5/64 loss: -1.8805866241455078
Batch 6/64 loss: -1.8306779861450195
Batch 7/64 loss: -1.934382438659668
Batch 8/64 loss: -1.3019132614135742
Batch 9/64 loss: -1.5599584579467773
Batch 10/64 loss: -2.1263904571533203
Batch 11/64 loss: -1.8273239135742188
Batch 12/64 loss: -2.0211868286132812
Batch 13/64 loss: -1.748809814453125
Batch 14/64 loss: -1.7802772521972656
Batch 15/64 loss: -1.8298978805541992
Batch 16/64 loss: -1.883641242980957
Batch 17/64 loss: -1.9731788635253906
Batch 18/64 loss: -2.1268348693847656
Batch 19/64 loss: -1.720261573791504
Batch 20/64 loss: -2.017775535583496
Batch 21/64 loss: -1.9824810028076172
Batch 22/64 loss: -1.9051589965820312
Batch 23/64 loss: -2.023709297180176
Batch 24/64 loss: -1.6921319961547852
Batch 25/64 loss: -1.5839166641235352
Batch 26/64 loss: -0.8548707962036133
Batch 27/64 loss: -1.1425447463989258
Batch 28/64 loss: -1.8729143142700195
Batch 29/64 loss: -1.871556282043457
Batch 30/64 loss: -1.5000934600830078
Batch 31/64 loss: -1.82958984375
Batch 32/64 loss: -1.9121017456054688
Batch 33/64 loss: -1.6618680953979492
Batch 34/64 loss: -1.6158199310302734
Batch 35/64 loss: -1.8785505294799805
Batch 36/64 loss: -1.7789478302001953
Batch 37/64 loss: -1.6618385314941406
Batch 38/64 loss: -1.6685905456542969
Batch 39/64 loss: -1.873678207397461
Batch 40/64 loss: -0.658782958984375
Batch 41/64 loss: -1.9062833786010742
Batch 42/64 loss: -1.859548568725586
Batch 43/64 loss: -2.047274589538574
Batch 44/64 loss: -1.894150733947754
Batch 45/64 loss: -1.8131217956542969
Batch 46/64 loss: -1.5343494415283203
Batch 47/64 loss: -1.725855827331543
Batch 48/64 loss: -1.827596664428711
Batch 49/64 loss: -1.8775205612182617
Batch 50/64 loss: -1.850541114807129
Batch 51/64 loss: -1.7435121536254883
Batch 52/64 loss: -1.937312126159668
Batch 53/64 loss: -1.7560224533081055
Batch 54/64 loss: -1.8267316818237305
Batch 55/64 loss: -1.8785877227783203
Batch 56/64 loss: -1.7421283721923828
Batch 57/64 loss: -1.682326316833496
Batch 58/64 loss: -1.701690673828125
Batch 59/64 loss: -1.447845458984375
Batch 60/64 loss: -1.869729995727539
Batch 61/64 loss: -1.8215675354003906
Batch 62/64 loss: -1.8958673477172852
Batch 63/64 loss: -1.9864654541015625
Batch 64/64 loss: -5.457819938659668
Epoch 217  Train loss: -1.8126072790108474  Val loss: -1.961814041399874
Epoch 218
-------------------------------
Batch 1/64 loss: -1.8005056381225586
Batch 2/64 loss: -1.7748146057128906
Batch 3/64 loss: -1.764115333557129
Batch 4/64 loss: -1.5889596939086914
Batch 5/64 loss: -1.8678855895996094
Batch 6/64 loss: -1.7842435836791992
Batch 7/64 loss: -1.7717866897583008
Batch 8/64 loss: -1.450526237487793
Batch 9/64 loss: -1.3482036590576172
Batch 10/64 loss: -1.6395025253295898
Batch 11/64 loss: -1.5777130126953125
Batch 12/64 loss: -1.844447135925293
Batch 13/64 loss: -1.7032299041748047
Batch 14/64 loss: -1.7540931701660156
Batch 15/64 loss: -1.887406349182129
Batch 16/64 loss: -1.5485382080078125
Batch 17/64 loss: -1.2223930358886719
Batch 18/64 loss: -1.6913728713989258
Batch 19/64 loss: -1.3940067291259766
Batch 20/64 loss: -1.750746726989746
Batch 21/64 loss: -1.3906993865966797
Batch 22/64 loss: -1.5421943664550781
Batch 23/64 loss: -1.6578712463378906
Batch 24/64 loss: -1.674485206604004
Batch 25/64 loss: -1.431365966796875
Batch 26/64 loss: -1.818284034729004
Batch 27/64 loss: -1.8055992126464844
Batch 28/64 loss: -1.7279911041259766
Batch 29/64 loss: -1.915226936340332
Batch 30/64 loss: -2.089365005493164
Batch 31/64 loss: -1.6041908264160156
Batch 32/64 loss: -1.5235891342163086
Batch 33/64 loss: -0.9548006057739258
Batch 34/64 loss: -1.9870243072509766
Batch 35/64 loss: -1.7159233093261719
Batch 36/64 loss: -1.4742851257324219
Batch 37/64 loss: -1.1900043487548828
Batch 38/64 loss: -1.3768491744995117
Batch 39/64 loss: -1.7429742813110352
Batch 40/64 loss: -1.9291296005249023
Batch 41/64 loss: -1.7027111053466797
Batch 42/64 loss: -1.7267084121704102
Batch 43/64 loss: -1.8526697158813477
Batch 44/64 loss: -1.616455078125
Batch 45/64 loss: -1.6764488220214844
Batch 46/64 loss: -1.7417716979980469
Batch 47/64 loss: -1.5367650985717773
Batch 48/64 loss: -1.35272216796875
Batch 49/64 loss: -1.527623176574707
Batch 50/64 loss: -1.6998357772827148
Batch 51/64 loss: -1.5653228759765625
Batch 52/64 loss: -1.7116775512695312
Batch 53/64 loss: -1.3314638137817383
Batch 54/64 loss: -1.502676010131836
Batch 55/64 loss: -1.5328149795532227
Batch 56/64 loss: -1.7759685516357422
Batch 57/64 loss: -2.0226097106933594
Batch 58/64 loss: -1.7022018432617188
Batch 59/64 loss: -1.6821355819702148
Batch 60/64 loss: -1.846571922302246
Batch 61/64 loss: -1.8294057846069336
Batch 62/64 loss: -1.6717948913574219
Batch 63/64 loss: -1.8193540573120117
Batch 64/64 loss: -6.016912460327148
Epoch 218  Train loss: -1.704419401580212  Val loss: -2.1309004714808513
Epoch 219
-------------------------------
Batch 1/64 loss: -1.9601831436157227
Batch 2/64 loss: -1.8891105651855469
Batch 3/64 loss: -1.6597366333007812
Batch 4/64 loss: -2.0034561157226562
Batch 5/64 loss: -1.8126144409179688
Batch 6/64 loss: -1.9355993270874023
Batch 7/64 loss: -2.0965824127197266
Batch 8/64 loss: -1.6063308715820312
Batch 9/64 loss: -1.9747095108032227
Batch 10/64 loss: -1.9193925857543945
Batch 11/64 loss: -1.5715503692626953
Batch 12/64 loss: -1.848738670349121
Batch 13/64 loss: -2.0233945846557617
Batch 14/64 loss: -1.9765863418579102
Batch 15/64 loss: -1.8747854232788086
Batch 16/64 loss: -1.4842243194580078
Batch 17/64 loss: -1.870987892150879
Batch 18/64 loss: -2.064969062805176
Batch 19/64 loss: -1.9706201553344727
Batch 20/64 loss: -1.6565933227539062
Batch 21/64 loss: -1.808985710144043
Batch 22/64 loss: -1.7645816802978516
Batch 23/64 loss: -1.7813396453857422
Batch 24/64 loss: -1.6234407424926758
Batch 25/64 loss: -1.8017683029174805
Batch 26/64 loss: -1.9744443893432617
Batch 27/64 loss: -1.7703027725219727
Batch 28/64 loss: -1.6702003479003906
Batch 29/64 loss: -1.7690715789794922
Batch 30/64 loss: -1.5371465682983398
Batch 31/64 loss: -1.9589509963989258
Batch 32/64 loss: -1.2312030792236328
Batch 33/64 loss: -1.7358894348144531
Batch 34/64 loss: -2.0258007049560547
Batch 35/64 loss: -1.8244609832763672
Batch 36/64 loss: -2.019230842590332
Batch 37/64 loss: -1.7845706939697266
Batch 38/64 loss: -1.8866910934448242
Batch 39/64 loss: -2.0105504989624023
Batch 40/64 loss: -1.880141258239746
Batch 41/64 loss: -2.061603546142578
Batch 42/64 loss: -1.862213134765625
Batch 43/64 loss: -1.5588502883911133
Batch 44/64 loss: -1.7884654998779297
Batch 45/64 loss: -1.9949979782104492
Batch 46/64 loss: -1.9247560501098633
Batch 47/64 loss: -1.8873682022094727
Batch 48/64 loss: -1.7838058471679688
Batch 49/64 loss: -1.8133964538574219
Batch 50/64 loss: -1.6283693313598633
Batch 51/64 loss: -1.7891359329223633
Batch 52/64 loss: -0.9326333999633789
Batch 53/64 loss: -1.8944416046142578
Batch 54/64 loss: -1.7618160247802734
Batch 55/64 loss: -1.8043527603149414
Batch 56/64 loss: -1.8292503356933594
Batch 57/64 loss: -1.9082345962524414
Batch 58/64 loss: -1.8872413635253906
Batch 59/64 loss: -2.0024805068969727
Batch 60/64 loss: -1.5264968872070312
Batch 61/64 loss: -1.7135381698608398
Batch 62/64 loss: -1.8038330078125
Batch 63/64 loss: -1.9019098281860352
Batch 64/64 loss: -6.017031669616699
Epoch 219  Train loss: -1.8608768874523687  Val loss: -1.950247210735308
Epoch 220
-------------------------------
Batch 1/64 loss: -1.6205711364746094
Batch 2/64 loss: -1.5746183395385742
Batch 3/64 loss: -2.135218620300293
Batch 4/64 loss: -1.9631967544555664
Batch 5/64 loss: -1.7943620681762695
Batch 6/64 loss: -1.631296157836914
Batch 7/64 loss: -1.6363115310668945
Batch 8/64 loss: -1.838460922241211
Batch 9/64 loss: -1.9864978790283203
Batch 10/64 loss: -1.554621696472168
Batch 11/64 loss: -1.8345556259155273
Batch 12/64 loss: -1.807927131652832
Batch 13/64 loss: -1.8285131454467773
Batch 14/64 loss: -1.778712272644043
Batch 15/64 loss: -1.517716407775879
Batch 16/64 loss: -1.7429256439208984
Batch 17/64 loss: -1.9209966659545898
Batch 18/64 loss: -1.5214929580688477
Batch 19/64 loss: -1.8856801986694336
Batch 20/64 loss: -1.9695730209350586
Batch 21/64 loss: -2.1246910095214844
Batch 22/64 loss: -1.8107223510742188
Batch 23/64 loss: -1.9192657470703125
Batch 24/64 loss: -1.704726219177246
Batch 25/64 loss: -2.0953731536865234
Batch 26/64 loss: -2.0403242111206055
Batch 27/64 loss: -2.0821304321289062
Batch 28/64 loss: -1.8394250869750977
Batch 29/64 loss: -1.6228723526000977
Batch 30/64 loss: -1.3534822463989258
Batch 31/64 loss: -1.9729280471801758
Batch 32/64 loss: -1.937443733215332
Batch 33/64 loss: -2.0385522842407227
Batch 34/64 loss: -2.1316404342651367
Batch 35/64 loss: -1.6732406616210938
Batch 36/64 loss: -1.9183998107910156
Batch 37/64 loss: -1.9333009719848633
Batch 38/64 loss: -1.7728395462036133
Batch 39/64 loss: -2.0796117782592773
Batch 40/64 loss: -1.8464431762695312
Batch 41/64 loss: -1.7093658447265625
Batch 42/64 loss: -1.6696977615356445
Batch 43/64 loss: -1.7991619110107422
Batch 44/64 loss: -2.1699018478393555
Batch 45/64 loss: -1.6989479064941406
Batch 46/64 loss: -2.1026525497436523
Batch 47/64 loss: -1.2035274505615234
Batch 48/64 loss: -1.975977897644043
Batch 49/64 loss: -2.056669235229492
Batch 50/64 loss: -1.9055910110473633
Batch 51/64 loss: -1.662191390991211
Batch 52/64 loss: -2.1750402450561523
Batch 53/64 loss: -1.809065818786621
Batch 54/64 loss: -1.9124774932861328
Batch 55/64 loss: -2.040656089782715
Batch 56/64 loss: -1.6191768646240234
Batch 57/64 loss: -2.074345588684082
Batch 58/64 loss: -1.8299846649169922
Batch 59/64 loss: -2.0619640350341797
Batch 60/64 loss: -2.1143264770507812
Batch 61/64 loss: -2.2372326850891113
Batch 62/64 loss: -2.0866355895996094
Batch 63/64 loss: -2.0343408584594727
Batch 64/64 loss: -5.88655948638916
Epoch 220  Train loss: -1.9106590158799115  Val loss: -1.9929029851434976
Epoch 221
-------------------------------
Batch 1/64 loss: -2.1739282608032227
Batch 2/64 loss: -1.9898605346679688
Batch 3/64 loss: -1.4332752227783203
Batch 4/64 loss: -1.9167509078979492
Batch 5/64 loss: -1.9288482666015625
Batch 6/64 loss: -2.062333106994629
Batch 7/64 loss: -2.078911781311035
Batch 8/64 loss: -1.6545658111572266
Batch 9/64 loss: -1.9207038879394531
Batch 10/64 loss: -1.8742265701293945
Batch 11/64 loss: -1.9938545227050781
Batch 12/64 loss: -1.410008430480957
Batch 13/64 loss: -1.8784475326538086
Batch 14/64 loss: -1.4276018142700195
Batch 15/64 loss: -1.580927848815918
Batch 16/64 loss: -1.7456445693969727
Batch 17/64 loss: -1.7576093673706055
Batch 18/64 loss: -1.7230205535888672
Batch 19/64 loss: -2.0295982360839844
Batch 20/64 loss: -1.4008665084838867
Batch 21/64 loss: -2.0595216751098633
Batch 22/64 loss: -1.4311933517456055
Batch 23/64 loss: -1.700932502746582
Batch 24/64 loss: -1.7657032012939453
Batch 25/64 loss: -2.0680313110351562
Batch 26/64 loss: -1.612955093383789
Batch 27/64 loss: -1.7267580032348633
Batch 28/64 loss: -1.903590202331543
Batch 29/64 loss: -1.881601333618164
Batch 30/64 loss: -1.7286186218261719
Batch 31/64 loss: -1.9281511306762695
Batch 32/64 loss: -1.9444351196289062
Batch 33/64 loss: -2.0258302688598633
Batch 34/64 loss: -1.6265497207641602
Batch 35/64 loss: -1.2677583694458008
Batch 36/64 loss: -1.6524171829223633
Batch 37/64 loss: -2.085505485534668
Batch 38/64 loss: -2.058086395263672
Batch 39/64 loss: -1.8108243942260742
Batch 40/64 loss: -1.824136734008789
Batch 41/64 loss: -1.7988576889038086
Batch 42/64 loss: -1.9980230331420898
Batch 43/64 loss: -1.1497831344604492
Batch 44/64 loss: -1.678441047668457
Batch 45/64 loss: -1.8556528091430664
Batch 46/64 loss: -1.8991327285766602
Batch 47/64 loss: -1.4563827514648438
Batch 48/64 loss: -1.6615562438964844
Batch 49/64 loss: -1.539656639099121
Batch 50/64 loss: -1.932657241821289
Batch 51/64 loss: -1.9529657363891602
Batch 52/64 loss: -1.4503183364868164
Batch 53/64 loss: -1.9480886459350586
Batch 54/64 loss: -1.7610301971435547
Batch 55/64 loss: -2.062570571899414
Batch 56/64 loss: -1.8551101684570312
Batch 57/64 loss: -1.9289541244506836
Batch 58/64 loss: -1.9089107513427734
Batch 59/64 loss: -1.5782499313354492
Batch 60/64 loss: -1.8489151000976562
Batch 61/64 loss: -2.034052848815918
Batch 62/64 loss: -1.5531911849975586
Batch 63/64 loss: -1.8768854141235352
Batch 64/64 loss: -5.666754722595215
Epoch 221  Train loss: -1.8362829208374023  Val loss: -2.1283115111675457
Epoch 222
-------------------------------
Batch 1/64 loss: -1.9251861572265625
Batch 2/64 loss: -1.8225746154785156
Batch 3/64 loss: -1.5130958557128906
Batch 4/64 loss: -1.7804079055786133
Batch 5/64 loss: -2.070866584777832
Batch 6/64 loss: -1.9051704406738281
Batch 7/64 loss: -1.6648035049438477
Batch 8/64 loss: -1.7425594329833984
Batch 9/64 loss: -1.9996833801269531
Batch 10/64 loss: -1.8323345184326172
Batch 11/64 loss: -2.0058460235595703
Batch 12/64 loss: -1.5400962829589844
Batch 13/64 loss: -1.867569923400879
Batch 14/64 loss: -1.6677274703979492
Batch 15/64 loss: -1.7686195373535156
Batch 16/64 loss: -1.552140235900879
Batch 17/64 loss: -1.7703638076782227
Batch 18/64 loss: -1.9525327682495117
Batch 19/64 loss: -1.893514633178711
Batch 20/64 loss: -1.8568000793457031
Batch 21/64 loss: -2.0299625396728516
Batch 22/64 loss: -1.7086076736450195
Batch 23/64 loss: -2.0190439224243164
Batch 24/64 loss: -1.5783472061157227
Batch 25/64 loss: -2.0724143981933594
Batch 26/64 loss: -1.7825613021850586
Batch 27/64 loss: -1.783848762512207
Batch 28/64 loss: -1.5331249237060547
Batch 29/64 loss: -1.2142200469970703
Batch 30/64 loss: -2.005796432495117
Batch 31/64 loss: -1.8584470748901367
Batch 32/64 loss: -1.8765478134155273
Batch 33/64 loss: -2.011284828186035
Batch 34/64 loss: -1.9594354629516602
Batch 35/64 loss: -2.0131731033325195
Batch 36/64 loss: -2.0880680084228516
Batch 37/64 loss: -1.9452943801879883
Batch 38/64 loss: -1.7850427627563477
Batch 39/64 loss: -1.6437501907348633
Batch 40/64 loss: -1.7066621780395508
Batch 41/64 loss: -1.9547853469848633
Batch 42/64 loss: -1.4617729187011719
Batch 43/64 loss: -1.8623008728027344
Batch 44/64 loss: -1.5167417526245117
Batch 45/64 loss: -1.8251628875732422
Batch 46/64 loss: -1.8037214279174805
Batch 47/64 loss: -1.8027982711791992
Batch 48/64 loss: -1.8799076080322266
Batch 49/64 loss: -1.9412946701049805
Batch 50/64 loss: -1.8089628219604492
Batch 51/64 loss: -1.681513786315918
Batch 52/64 loss: -1.9006128311157227
Batch 53/64 loss: -1.9174776077270508
Batch 54/64 loss: -1.90789794921875
Batch 55/64 loss: -1.812056541442871
Batch 56/64 loss: -1.380197525024414
Batch 57/64 loss: -1.9536800384521484
Batch 58/64 loss: -1.8953924179077148
Batch 59/64 loss: -2.0632495880126953
Batch 60/64 loss: -1.8584699630737305
Batch 61/64 loss: -1.6558647155761719
Batch 62/64 loss: -1.8288488388061523
Batch 63/64 loss: -1.441939353942871
Batch 64/64 loss: -6.266605854034424
Epoch 222  Train loss: -1.860425573236802  Val loss: -2.1328373020866893
Epoch 223
-------------------------------
Batch 1/64 loss: -1.1231002807617188
Batch 2/64 loss: -1.893580436706543
Batch 3/64 loss: -1.956507682800293
Batch 4/64 loss: -1.966465950012207
Batch 5/64 loss: -1.821767807006836
Batch 6/64 loss: -1.6465682983398438
Batch 7/64 loss: -1.2953777313232422
Batch 8/64 loss: -1.7389440536499023
Batch 9/64 loss: -1.552983283996582
Batch 10/64 loss: -1.9092864990234375
Batch 11/64 loss: -1.1663579940795898
Batch 12/64 loss: -1.9786319732666016
Batch 13/64 loss: -1.9748249053955078
Batch 14/64 loss: -0.9586734771728516
Batch 15/64 loss: -1.896707534790039
Batch 16/64 loss: -1.9747676849365234
Batch 17/64 loss: -1.7627010345458984
Batch 18/64 loss: -1.5510234832763672
Batch 19/64 loss: -1.732375144958496
Batch 20/64 loss: -2.0279760360717773
Batch 21/64 loss: -1.9496498107910156
Batch 22/64 loss: -2.2085185050964355
Batch 23/64 loss: -2.0424985885620117
Batch 24/64 loss: -1.8189573287963867
Batch 25/64 loss: -1.9071941375732422
Batch 26/64 loss: -1.7732830047607422
Batch 27/64 loss: -1.892136573791504
Batch 28/64 loss: -1.6750764846801758
Batch 29/64 loss: -1.457906723022461
Batch 30/64 loss: -2.128389358520508
Batch 31/64 loss: -1.8664798736572266
Batch 32/64 loss: -1.9743766784667969
Batch 33/64 loss: -2.1560134887695312
Batch 34/64 loss: -2.143303871154785
Batch 35/64 loss: -1.549607276916504
Batch 36/64 loss: -1.662618637084961
Batch 37/64 loss: -2.0938568115234375
Batch 38/64 loss: -1.9064092636108398
Batch 39/64 loss: -2.2152042388916016
Batch 40/64 loss: -2.217301368713379
Batch 41/64 loss: -1.8150291442871094
Batch 42/64 loss: -2.0447444915771484
Batch 43/64 loss: -1.8506622314453125
Batch 44/64 loss: -2.092916488647461
Batch 45/64 loss: -1.8054370880126953
Batch 46/64 loss: -2.048516273498535
Batch 47/64 loss: -2.109072685241699
Batch 48/64 loss: -1.8658418655395508
Batch 49/64 loss: -2.2035694122314453
Batch 50/64 loss: -1.7386054992675781
Batch 51/64 loss: -2.1935644149780273
Batch 52/64 loss: -2.1089887619018555
Batch 53/64 loss: -2.0130157470703125
Batch 54/64 loss: -1.6141481399536133
Batch 55/64 loss: -1.7688465118408203
Batch 56/64 loss: -1.987278938293457
Batch 57/64 loss: -1.872309684753418
Batch 58/64 loss: -2.0957250595092773
Batch 59/64 loss: -1.8899126052856445
Batch 60/64 loss: -2.016779899597168
Batch 61/64 loss: -1.798539161682129
Batch 62/64 loss: -1.4524126052856445
Batch 63/64 loss: -1.9909753799438477
Batch 64/64 loss: -6.410843372344971
Epoch 223  Train loss: -1.9098420068329456  Val loss: -2.1137936778904236
Epoch 224
-------------------------------
Batch 1/64 loss: -1.7792940139770508
Batch 2/64 loss: -1.9868621826171875
Batch 3/64 loss: -1.9712800979614258
Batch 4/64 loss: -2.0590953826904297
Batch 5/64 loss: -1.3915090560913086
Batch 6/64 loss: -1.7014245986938477
Batch 7/64 loss: -1.4953203201293945
Batch 8/64 loss: -2.0706539154052734
Batch 9/64 loss: -1.7970647811889648
Batch 10/64 loss: -1.6804018020629883
Batch 11/64 loss: -1.9455442428588867
Batch 12/64 loss: -1.9268417358398438
Batch 13/64 loss: -1.9938068389892578
Batch 14/64 loss: -1.6378841400146484
Batch 15/64 loss: -1.9178476333618164
Batch 16/64 loss: -0.4136924743652344
Batch 17/64 loss: -2.0726776123046875
Batch 18/64 loss: -2.011981964111328
Batch 19/64 loss: -1.8498144149780273
Batch 20/64 loss: -2.024764060974121
Batch 21/64 loss: -2.1875085830688477
Batch 22/64 loss: -2.132110595703125
Batch 23/64 loss: -2.0330286026000977
Batch 24/64 loss: -2.1690902709960938
Batch 25/64 loss: -1.999934196472168
Batch 26/64 loss: -1.8971824645996094
Batch 27/64 loss: -1.9050683975219727
Batch 28/64 loss: -1.5890178680419922
Batch 29/64 loss: -1.7783432006835938
Batch 30/64 loss: -1.5720939636230469
Batch 31/64 loss: -2.005490303039551
Batch 32/64 loss: -1.7042198181152344
Batch 33/64 loss: -1.5587615966796875
Batch 34/64 loss: -2.1816883087158203
Batch 35/64 loss: -1.7921218872070312
Batch 36/64 loss: -1.7641410827636719
Batch 37/64 loss: -1.8781299591064453
Batch 38/64 loss: -1.7765121459960938
Batch 39/64 loss: -2.0801000595092773
Batch 40/64 loss: -1.7111930847167969
Batch 41/64 loss: -1.865962028503418
Batch 42/64 loss: -1.7697172164916992
Batch 43/64 loss: -1.8893852233886719
Batch 44/64 loss: -1.2320833206176758
Batch 45/64 loss: -1.8709726333618164
Batch 46/64 loss: -1.9577417373657227
Batch 47/64 loss: -2.0785703659057617
Batch 48/64 loss: -1.9652481079101562
Batch 49/64 loss: -1.9451627731323242
Batch 50/64 loss: -1.8220252990722656
Batch 51/64 loss: -1.9929428100585938
Batch 52/64 loss: -1.9945354461669922
Batch 53/64 loss: -1.842646598815918
Batch 54/64 loss: -1.8722209930419922
Batch 55/64 loss: -1.6501646041870117
Batch 56/64 loss: -1.7292604446411133
Batch 57/64 loss: -1.806915283203125
Batch 58/64 loss: -1.8591079711914062
Batch 59/64 loss: -1.925161361694336
Batch 60/64 loss: -1.917048454284668
Batch 61/64 loss: -2.149322509765625
Batch 62/64 loss: -1.8461427688598633
Batch 63/64 loss: -1.997908592224121
Batch 64/64 loss: -5.349485874176025
Epoch 224  Train loss: -1.8891899389379165  Val loss: -1.7424680834373658
Epoch 225
-------------------------------
Batch 1/64 loss: -1.7360706329345703
Batch 2/64 loss: -1.4724149703979492
Batch 3/64 loss: -1.7232856750488281
Batch 4/64 loss: -1.752131462097168
Batch 5/64 loss: -1.9123830795288086
Batch 6/64 loss: -1.0764122009277344
Batch 7/64 loss: -1.9034996032714844
Batch 8/64 loss: -1.418416976928711
Batch 9/64 loss: -1.1100168228149414
Batch 10/64 loss: -1.4857826232910156
Batch 11/64 loss: -1.600092887878418
Batch 12/64 loss: -1.6823997497558594
Batch 13/64 loss: -1.636575698852539
Batch 14/64 loss: -1.7632312774658203
Batch 15/64 loss: -2.0177841186523438
Batch 16/64 loss: -1.402451515197754
Batch 17/64 loss: -1.8251028060913086
Batch 18/64 loss: -2.0428009033203125
Batch 19/64 loss: -1.7111997604370117
Batch 20/64 loss: -1.8869152069091797
Batch 21/64 loss: -1.9614448547363281
Batch 22/64 loss: -1.862234115600586
Batch 23/64 loss: -1.7271499633789062
Batch 24/64 loss: -1.861368179321289
Batch 25/64 loss: -1.994476318359375
Batch 26/64 loss: -1.9372663497924805
Batch 27/64 loss: -1.834249496459961
Batch 28/64 loss: -1.8833608627319336
Batch 29/64 loss: -1.6286640167236328
Batch 30/64 loss: -1.6765813827514648
Batch 31/64 loss: -1.5537118911743164
Batch 32/64 loss: -2.051436424255371
Batch 33/64 loss: -1.64300537109375
Batch 34/64 loss: -1.8222341537475586
Batch 35/64 loss: -1.7265710830688477
Batch 36/64 loss: -1.553675651550293
Batch 37/64 loss: -1.8716812133789062
Batch 38/64 loss: -2.0014867782592773
Batch 39/64 loss: -1.3573284149169922
Batch 40/64 loss: -2.0664758682250977
Batch 41/64 loss: -1.9905242919921875
Batch 42/64 loss: -1.9998865127563477
Batch 43/64 loss: -1.9063997268676758
Batch 44/64 loss: -2.019561767578125
Batch 45/64 loss: -1.8171501159667969
Batch 46/64 loss: -1.819228172302246
Batch 47/64 loss: -1.9444122314453125
Batch 48/64 loss: -2.0188465118408203
Batch 49/64 loss: -1.878549575805664
Batch 50/64 loss: -2.0583009719848633
Batch 51/64 loss: -1.1896133422851562
Batch 52/64 loss: -2.088306427001953
Batch 53/64 loss: -1.8168830871582031
Batch 54/64 loss: -1.3758611679077148
Batch 55/64 loss: -2.1137075424194336
Batch 56/64 loss: -1.999197006225586
Batch 57/64 loss: -1.9110174179077148
Batch 58/64 loss: -1.865992546081543
Batch 59/64 loss: -1.9879999160766602
Batch 60/64 loss: -2.0103254318237305
Batch 61/64 loss: -2.065762519836426
Batch 62/64 loss: -1.4708385467529297
Batch 63/64 loss: -2.146198272705078
Batch 64/64 loss: -6.237499237060547
Epoch 225  Train loss: -1.8407224767348345  Val loss: -2.220234205632685
Epoch 226
-------------------------------
Batch 1/64 loss: -1.9149742126464844
Batch 2/64 loss: -1.8065204620361328
Batch 3/64 loss: -1.8248319625854492
Batch 4/64 loss: -1.8592395782470703
Batch 5/64 loss: -2.003232955932617
Batch 6/64 loss: -1.8404827117919922
Batch 7/64 loss: -1.9077873229980469
Batch 8/64 loss: -1.9568462371826172
Batch 9/64 loss: -1.957773208618164
Batch 10/64 loss: -1.8866081237792969
Batch 11/64 loss: -2.039189338684082
Batch 12/64 loss: -1.8654203414916992
Batch 13/64 loss: -1.769693374633789
Batch 14/64 loss: -2.138570785522461
Batch 15/64 loss: -2.0661020278930664
Batch 16/64 loss: -1.0433263778686523
Batch 17/64 loss: -1.6378498077392578
Batch 18/64 loss: -1.928919792175293
Batch 19/64 loss: -2.0296144485473633
Batch 20/64 loss: -1.9715604782104492
Batch 21/64 loss: -2.013263702392578
Batch 22/64 loss: -2.0032243728637695
Batch 23/64 loss: -2.1211843490600586
Batch 24/64 loss: -1.7578086853027344
Batch 25/64 loss: -1.332529067993164
Batch 26/64 loss: -1.8744850158691406
Batch 27/64 loss: -1.6422767639160156
Batch 28/64 loss: -2.104010581970215
Batch 29/64 loss: -1.8312206268310547
Batch 30/64 loss: -2.1153087615966797
Batch 31/64 loss: -1.7570066452026367
Batch 32/64 loss: -1.8801765441894531
Batch 33/64 loss: -2.164914131164551
Batch 34/64 loss: -1.7120189666748047
Batch 35/64 loss: -1.7541751861572266
Batch 36/64 loss: -1.9566173553466797
Batch 37/64 loss: -1.7735023498535156
Batch 38/64 loss: -1.6823101043701172
Batch 39/64 loss: -2.0505495071411133
Batch 40/64 loss: -2.071796417236328
Batch 41/64 loss: -2.0216493606567383
Batch 42/64 loss: -1.6207752227783203
Batch 43/64 loss: -1.7325401306152344
Batch 44/64 loss: -1.8810482025146484
Batch 45/64 loss: -1.9344158172607422
Batch 46/64 loss: -2.013364791870117
Batch 47/64 loss: -2.0278635025024414
Batch 48/64 loss: -1.9095458984375
Batch 49/64 loss: -2.072439193725586
Batch 50/64 loss: -1.9787473678588867
Batch 51/64 loss: -1.885904312133789
Batch 52/64 loss: -1.3884305953979492
Batch 53/64 loss: -2.0126609802246094
Batch 54/64 loss: -1.8051929473876953
Batch 55/64 loss: -1.8514223098754883
Batch 56/64 loss: -1.880096435546875
Batch 57/64 loss: -2.1924753189086914
Batch 58/64 loss: -1.4710798263549805
Batch 59/64 loss: -1.776993751525879
Batch 60/64 loss: -1.9724273681640625
Batch 61/64 loss: -1.9942541122436523
Batch 62/64 loss: -1.8710269927978516
Batch 63/64 loss: -1.8540353775024414
Batch 64/64 loss: -5.808320045471191
Epoch 226  Train loss: -1.9223772946526023  Val loss: -2.177408867275592
Epoch 227
-------------------------------
Batch 1/64 loss: -1.9222097396850586
Batch 2/64 loss: -1.5725641250610352
Batch 3/64 loss: -1.873946189880371
Batch 4/64 loss: -1.6058626174926758
Batch 5/64 loss: -1.5667743682861328
Batch 6/64 loss: -1.4350147247314453
Batch 7/64 loss: -1.9404239654541016
Batch 8/64 loss: -1.6540279388427734
Batch 9/64 loss: -1.8532133102416992
Batch 10/64 loss: -1.7949905395507812
Batch 11/64 loss: -1.6781120300292969
Batch 12/64 loss: -2.14620304107666
Batch 13/64 loss: -1.8433475494384766
Batch 14/64 loss: -1.832672119140625
Batch 15/64 loss: -1.7891731262207031
Batch 16/64 loss: -1.8081388473510742
Batch 17/64 loss: -1.9695854187011719
Batch 18/64 loss: -2.082583427429199
Batch 19/64 loss: -1.804265022277832
Batch 20/64 loss: -1.4965810775756836
Batch 21/64 loss: -1.5529937744140625
Batch 22/64 loss: -1.9731884002685547
Batch 23/64 loss: -1.9063596725463867
Batch 24/64 loss: -2.105592727661133
Batch 25/64 loss: -2.01717472076416
Batch 26/64 loss: -2.0720252990722656
Batch 27/64 loss: -1.9580621719360352
Batch 28/64 loss: -2.085103988647461
Batch 29/64 loss: -1.9936952590942383
Batch 30/64 loss: -2.1223154067993164
Batch 31/64 loss: -2.126521110534668
Batch 32/64 loss: -1.6267242431640625
Batch 33/64 loss: -1.747110366821289
Batch 34/64 loss: -1.9587421417236328
Batch 35/64 loss: -1.3372478485107422
Batch 36/64 loss: -1.8657712936401367
Batch 37/64 loss: -2.119525909423828
Batch 38/64 loss: -1.9462032318115234
Batch 39/64 loss: -1.9787664413452148
Batch 40/64 loss: -2.0117416381835938
Batch 41/64 loss: -1.8262977600097656
Batch 42/64 loss: -1.618626594543457
Batch 43/64 loss: -2.137934684753418
Batch 44/64 loss: -2.1610031127929688
Batch 45/64 loss: -1.9073295593261719
Batch 46/64 loss: -1.9571151733398438
Batch 47/64 loss: -1.7132816314697266
Batch 48/64 loss: -1.8931217193603516
Batch 49/64 loss: -1.659210205078125
Batch 50/64 loss: -1.8923568725585938
Batch 51/64 loss: -2.0759048461914062
Batch 52/64 loss: -1.7409934997558594
Batch 53/64 loss: -2.2289323806762695
Batch 54/64 loss: -2.1409101486206055
Batch 55/64 loss: -0.6080284118652344
Batch 56/64 loss: -2.211782455444336
Batch 57/64 loss: -2.0832996368408203
Batch 58/64 loss: -2.1841840744018555
Batch 59/64 loss: -1.5554418563842773
Batch 60/64 loss: -2.1494712829589844
Batch 61/64 loss: -2.044536590576172
Batch 62/64 loss: -1.951385498046875
Batch 63/64 loss: -2.0514659881591797
Batch 64/64 loss: -6.234313011169434
Epoch 227  Train loss: -1.9238102520213407  Val loss: -2.1455704731629885
Epoch 228
-------------------------------
Batch 1/64 loss: -2.08852481842041
Batch 2/64 loss: -2.2254838943481445
Batch 3/64 loss: -1.940176010131836
Batch 4/64 loss: -1.3793067932128906
Batch 5/64 loss: -2.2219982147216797
Batch 6/64 loss: -1.7870206832885742
Batch 7/64 loss: -2.0053462982177734
Batch 8/64 loss: -1.1694164276123047
Batch 9/64 loss: -1.9170112609863281
Batch 10/64 loss: -2.0783309936523438
Batch 11/64 loss: -2.0407180786132812
Batch 12/64 loss: -1.8388891220092773
Batch 13/64 loss: -1.873086929321289
Batch 14/64 loss: -1.9165410995483398
Batch 15/64 loss: -1.905710220336914
Batch 16/64 loss: -1.848170280456543
Batch 17/64 loss: -2.230998992919922
Batch 18/64 loss: -2.182788848876953
Batch 19/64 loss: -1.815384864807129
Batch 20/64 loss: -2.0197830200195312
Batch 21/64 loss: -1.945119857788086
Batch 22/64 loss: -1.9228458404541016
Batch 23/64 loss: -2.0306224822998047
Batch 24/64 loss: -1.8021554946899414
Batch 25/64 loss: -2.0446395874023438
Batch 26/64 loss: -2.0295677185058594
Batch 27/64 loss: -2.0076446533203125
Batch 28/64 loss: -2.0977954864501953
Batch 29/64 loss: -2.0011091232299805
Batch 30/64 loss: -1.8313417434692383
Batch 31/64 loss: -1.975381851196289
Batch 32/64 loss: -2.0450048446655273
Batch 33/64 loss: -2.1154794692993164
Batch 34/64 loss: -1.8413782119750977
Batch 35/64 loss: -1.1693649291992188
Batch 36/64 loss: -1.8568801879882812
Batch 37/64 loss: -0.7754945755004883
Batch 38/64 loss: -1.7172698974609375
Batch 39/64 loss: -1.9669208526611328
Batch 40/64 loss: -1.6944599151611328
Batch 41/64 loss: -1.681142807006836
Batch 42/64 loss: -2.0076351165771484
Batch 43/64 loss: -1.9216413497924805
Batch 44/64 loss: -2.1301937103271484
Batch 45/64 loss: -1.9125394821166992
Batch 46/64 loss: -1.695277214050293
Batch 47/64 loss: -1.275308609008789
Batch 48/64 loss: -1.7476654052734375
Batch 49/64 loss: -1.9048709869384766
Batch 50/64 loss: -1.8711185455322266
Batch 51/64 loss: -1.7100458145141602
Batch 52/64 loss: -1.7387056350708008
Batch 53/64 loss: -2.0398902893066406
Batch 54/64 loss: -1.8705835342407227
Batch 55/64 loss: -1.914133071899414
Batch 56/64 loss: -1.4388246536254883
Batch 57/64 loss: -1.5299882888793945
Batch 58/64 loss: -1.8190631866455078
Batch 59/64 loss: -2.0220632553100586
Batch 60/64 loss: -1.7602815628051758
Batch 61/64 loss: -2.1094675064086914
Batch 62/64 loss: -1.9858808517456055
Batch 63/64 loss: -2.0935144424438477
Batch 64/64 loss: -6.4723896980285645
Epoch 228  Train loss: -1.9198320183099484  Val loss: -2.2138855924311374
Epoch 229
-------------------------------
Batch 1/64 loss: -2.0162267684936523
Batch 2/64 loss: -1.9061107635498047
Batch 3/64 loss: -2.0588550567626953
Batch 4/64 loss: -1.888930320739746
Batch 5/64 loss: -2.0775938034057617
Batch 6/64 loss: -1.8551921844482422
Batch 7/64 loss: -2.0072154998779297
Batch 8/64 loss: -2.098660469055176
Batch 9/64 loss: -2.0904884338378906
Batch 10/64 loss: -1.9574766159057617
Batch 11/64 loss: -1.9447526931762695
Batch 12/64 loss: -1.8160791397094727
Batch 13/64 loss: -1.7317695617675781
Batch 14/64 loss: -1.5611886978149414
Batch 15/64 loss: -1.7339725494384766
Batch 16/64 loss: -2.0618839263916016
Batch 17/64 loss: -1.8326168060302734
Batch 18/64 loss: -1.9628963470458984
Batch 19/64 loss: -1.9338264465332031
Batch 20/64 loss: -2.050996780395508
Batch 21/64 loss: -2.0224456787109375
Batch 22/64 loss: -1.865300178527832
Batch 23/64 loss: -2.132833480834961
Batch 24/64 loss: -0.7089509963989258
Batch 25/64 loss: -2.0396385192871094
Batch 26/64 loss: -1.9151363372802734
Batch 27/64 loss: -2.1377296447753906
Batch 28/64 loss: -1.8213787078857422
Batch 29/64 loss: -1.6988325119018555
Batch 30/64 loss: -1.8834524154663086
Batch 31/64 loss: -2.0390100479125977
Batch 32/64 loss: -2.17800235748291
Batch 33/64 loss: -1.855447769165039
Batch 34/64 loss: -1.9126014709472656
Batch 35/64 loss: -1.467890739440918
Batch 36/64 loss: -1.9700860977172852
Batch 37/64 loss: -1.8021202087402344
Batch 38/64 loss: -2.1519737243652344
Batch 39/64 loss: -1.3974418640136719
Batch 40/64 loss: -1.9581546783447266
Batch 41/64 loss: -2.1184396743774414
Batch 42/64 loss: -1.8241558074951172
Batch 43/64 loss: -2.1408281326293945
Batch 44/64 loss: -1.9817438125610352
Batch 45/64 loss: -1.916666030883789
Batch 46/64 loss: -1.9601993560791016
Batch 47/64 loss: -2.132266044616699
Batch 48/64 loss: -1.6978425979614258
Batch 49/64 loss: -1.929295539855957
Batch 50/64 loss: -1.880356788635254
Batch 51/64 loss: -2.026251792907715
Batch 52/64 loss: -2.080592155456543
Batch 53/64 loss: -2.203494071960449
Batch 54/64 loss: -1.6293144226074219
Batch 55/64 loss: -2.220181465148926
Batch 56/64 loss: -2.0065412521362305
Batch 57/64 loss: -2.002760887145996
Batch 58/64 loss: -1.6364803314208984
Batch 59/64 loss: -2.057480812072754
Batch 60/64 loss: -1.8533458709716797
Batch 61/64 loss: -1.9798898696899414
Batch 62/64 loss: -2.09896183013916
Batch 63/64 loss: -1.9446191787719727
Batch 64/64 loss: -5.552177429199219
Epoch 229  Train loss: -1.9612706053490732  Val loss: -2.0413172482624904
Epoch 230
-------------------------------
Batch 1/64 loss: -1.6549291610717773
Batch 2/64 loss: -2.1095046997070312
Batch 3/64 loss: -1.5958385467529297
Batch 4/64 loss: -1.8793764114379883
Batch 5/64 loss: -2.0332860946655273
Batch 6/64 loss: -2.007871627807617
Batch 7/64 loss: -1.8383541107177734
Batch 8/64 loss: -1.612375259399414
Batch 9/64 loss: -1.9125213623046875
Batch 10/64 loss: -1.7379732131958008
Batch 11/64 loss: -1.6533184051513672
Batch 12/64 loss: -1.0844430923461914
Batch 13/64 loss: -2.0667362213134766
Batch 14/64 loss: -1.811488151550293
Batch 15/64 loss: -1.996816635131836
Batch 16/64 loss: -1.6077642440795898
Batch 17/64 loss: -1.7844524383544922
Batch 18/64 loss: -1.9936103820800781
Batch 19/64 loss: -2.1751480102539062
Batch 20/64 loss: -1.8554468154907227
Batch 21/64 loss: -2.093918800354004
Batch 22/64 loss: -1.7260684967041016
Batch 23/64 loss: -1.569697380065918
Batch 24/64 loss: -1.8121223449707031
Batch 25/64 loss: -1.7301740646362305
Batch 26/64 loss: -2.150576591491699
Batch 27/64 loss: -1.6134977340698242
Batch 28/64 loss: -1.9968891143798828
Batch 29/64 loss: -2.009352684020996
Batch 30/64 loss: -1.7654609680175781
Batch 31/64 loss: -2.2368574142456055
Batch 32/64 loss: -2.0527305603027344
Batch 33/64 loss: -1.905618667602539
Batch 34/64 loss: -2.055342674255371
Batch 35/64 loss: -2.091263771057129
Batch 36/64 loss: -2.016169548034668
Batch 37/64 loss: -2.096400260925293
Batch 38/64 loss: -2.1834487915039062
Batch 39/64 loss: -1.3163576126098633
Batch 40/64 loss: -1.7723798751831055
Batch 41/64 loss: -1.929931640625
Batch 42/64 loss: -2.1490020751953125
Batch 43/64 loss: -2.0498695373535156
Batch 44/64 loss: -2.0123977661132812
Batch 45/64 loss: -1.4699592590332031
Batch 46/64 loss: -1.9372291564941406
Batch 47/64 loss: -1.6871929168701172
Batch 48/64 loss: -1.3210458755493164
Batch 49/64 loss: -2.061067581176758
Batch 50/64 loss: -1.714284896850586
Batch 51/64 loss: -2.0541458129882812
Batch 52/64 loss: -2.200925827026367
Batch 53/64 loss: -2.029566764831543
Batch 54/64 loss: -2.053250312805176
Batch 55/64 loss: -1.8304119110107422
Batch 56/64 loss: -1.9144115447998047
Batch 57/64 loss: -2.113870620727539
Batch 58/64 loss: -1.9427547454833984
Batch 59/64 loss: -2.0776119232177734
Batch 60/64 loss: -1.775014877319336
Batch 61/64 loss: -2.0236968994140625
Batch 62/64 loss: -2.1346864700317383
Batch 63/64 loss: -1.2366514205932617
Batch 64/64 loss: -6.296002388000488
Epoch 230  Train loss: -1.930142178254969  Val loss: -2.2170204608301116
Epoch 231
-------------------------------
Batch 1/64 loss: -1.9434614181518555
Batch 2/64 loss: -2.1921300888061523
Batch 3/64 loss: -2.0965662002563477
Batch 4/64 loss: -1.8950042724609375
Batch 5/64 loss: -2.098438262939453
Batch 6/64 loss: -1.7011089324951172
Batch 7/64 loss: -1.9459857940673828
Batch 8/64 loss: -1.9586429595947266
Batch 9/64 loss: -2.178860664367676
Batch 10/64 loss: -1.5477685928344727
Batch 11/64 loss: -2.1258459091186523
Batch 12/64 loss: -2.0751590728759766
Batch 13/64 loss: -2.098154067993164
Batch 14/64 loss: -1.7801361083984375
Batch 15/64 loss: -1.9542951583862305
Batch 16/64 loss: -1.3490028381347656
Batch 17/64 loss: -2.154547691345215
Batch 18/64 loss: -1.7571678161621094
Batch 19/64 loss: -2.139087677001953
Batch 20/64 loss: -1.9269866943359375
Batch 21/64 loss: -2.1485233306884766
Batch 22/64 loss: -1.9951696395874023
Batch 23/64 loss: -1.7009096145629883
Batch 24/64 loss: -2.168642044067383
Batch 25/64 loss: -1.9201011657714844
Batch 26/64 loss: -1.8215999603271484
Batch 27/64 loss: -2.061016082763672
Batch 28/64 loss: -2.1038198471069336
Batch 29/64 loss: -2.0974531173706055
Batch 30/64 loss: -1.7320480346679688
Batch 31/64 loss: -1.3521461486816406
Batch 32/64 loss: -1.8914909362792969
Batch 33/64 loss: -1.994659423828125
Batch 34/64 loss: -2.032430648803711
Batch 35/64 loss: -1.7989978790283203
Batch 36/64 loss: -1.453932762145996
Batch 37/64 loss: -1.8370418548583984
Batch 38/64 loss: -2.193035125732422
Batch 39/64 loss: -2.020519256591797
Batch 40/64 loss: -1.9454326629638672
Batch 41/64 loss: -1.769516944885254
Batch 42/64 loss: -1.8910455703735352
Batch 43/64 loss: -2.108297348022461
Batch 44/64 loss: -2.076155662536621
Batch 45/64 loss: -2.19081974029541
Batch 46/64 loss: -2.0240421295166016
Batch 47/64 loss: -1.6768674850463867
Batch 48/64 loss: -1.2102422714233398
Batch 49/64 loss: -2.0284042358398438
Batch 50/64 loss: -1.8955326080322266
Batch 51/64 loss: -1.9881820678710938
Batch 52/64 loss: -1.8393259048461914
Batch 53/64 loss: -1.6026315689086914
Batch 54/64 loss: -2.032931327819824
Batch 55/64 loss: -1.7174386978149414
Batch 56/64 loss: -1.9042139053344727
Batch 57/64 loss: -1.6956005096435547
Batch 58/64 loss: -1.8505573272705078
Batch 59/64 loss: -1.8427867889404297
Batch 60/64 loss: -1.870046615600586
Batch 61/64 loss: -1.8117265701293945
Batch 62/64 loss: -1.8734378814697266
Batch 63/64 loss: -0.8538064956665039
Batch 64/64 loss: -5.7248053550720215
Epoch 231  Train loss: -1.9330907204571892  Val loss: -1.9809821479508967
Epoch 232
-------------------------------
Batch 1/64 loss: -1.613966941833496
Batch 2/64 loss: -1.4273662567138672
Batch 3/64 loss: -1.7273807525634766
Batch 4/64 loss: -1.7871551513671875
Batch 5/64 loss: -1.948349952697754
Batch 6/64 loss: -1.7826642990112305
Batch 7/64 loss: -1.464585304260254
Batch 8/64 loss: -1.5170135498046875
Batch 9/64 loss: -1.2848997116088867
Batch 10/64 loss: -1.5088138580322266
Batch 11/64 loss: -1.8424444198608398
Batch 12/64 loss: -1.7951602935791016
Batch 13/64 loss: -1.7592592239379883
Batch 14/64 loss: -1.8509187698364258
Batch 15/64 loss: -1.7949295043945312
Batch 16/64 loss: -1.9226799011230469
Batch 17/64 loss: -1.9908742904663086
Batch 18/64 loss: -1.6144523620605469
Batch 19/64 loss: -1.674839973449707
Batch 20/64 loss: -1.8205757141113281
Batch 21/64 loss: -1.9134435653686523
Batch 22/64 loss: -1.1930646896362305
Batch 23/64 loss: -1.8928422927856445
Batch 24/64 loss: -1.650604248046875
Batch 25/64 loss: -1.4391841888427734
Batch 26/64 loss: -1.7396440505981445
Batch 27/64 loss: -1.9346904754638672
Batch 28/64 loss: -1.9037094116210938
Batch 29/64 loss: -1.8048467636108398
Batch 30/64 loss: -0.9509773254394531
Batch 31/64 loss: -1.0782642364501953
Batch 32/64 loss: -1.725508689880371
Batch 33/64 loss: -2.0383596420288086
Batch 34/64 loss: -1.7579164505004883
Batch 35/64 loss: -1.6228761672973633
Batch 36/64 loss: -1.9388084411621094
Batch 37/64 loss: -1.8948850631713867
Batch 38/64 loss: -1.984055519104004
Batch 39/64 loss: -1.9453544616699219
Batch 40/64 loss: -1.4817390441894531
Batch 41/64 loss: -2.139153480529785
Batch 42/64 loss: -2.187732696533203
Batch 43/64 loss: -2.0130348205566406
Batch 44/64 loss: -1.8790359497070312
Batch 45/64 loss: -1.9872512817382812
Batch 46/64 loss: -1.988241195678711
Batch 47/64 loss: -2.0604143142700195
Batch 48/64 loss: -1.9914655685424805
Batch 49/64 loss: -1.6462430953979492
Batch 50/64 loss: -2.126034736633301
Batch 51/64 loss: -1.889352798461914
Batch 52/64 loss: -2.0931224822998047
Batch 53/64 loss: -1.760519027709961
Batch 54/64 loss: -2.1204376220703125
Batch 55/64 loss: -2.124087333679199
Batch 56/64 loss: -2.1318578720092773
Batch 57/64 loss: -1.820901870727539
Batch 58/64 loss: -1.941014289855957
Batch 59/64 loss: -2.0152368545532227
Batch 60/64 loss: -1.8763151168823242
Batch 61/64 loss: -1.9634971618652344
Batch 62/64 loss: -2.060725212097168
Batch 63/64 loss: -2.1373491287231445
Batch 64/64 loss: -5.99146032333374
Epoch 232  Train loss: -1.8582858684016208  Val loss: -2.1447661881594313
Epoch 233
-------------------------------
Batch 1/64 loss: -1.7192163467407227
Batch 2/64 loss: -2.007449150085449
Batch 3/64 loss: -2.0185470581054688
Batch 4/64 loss: -1.8496208190917969
Batch 5/64 loss: -1.7513351440429688
Batch 6/64 loss: -1.2160568237304688
Batch 7/64 loss: -1.8490638732910156
Batch 8/64 loss: -1.7837438583374023
Batch 9/64 loss: -1.9743432998657227
Batch 10/64 loss: -1.7973737716674805
Batch 11/64 loss: -1.9657697677612305
Batch 12/64 loss: -2.063711166381836
Batch 13/64 loss: -1.3810834884643555
Batch 14/64 loss: -1.9167871475219727
Batch 15/64 loss: -1.8100652694702148
Batch 16/64 loss: -1.9907197952270508
Batch 17/64 loss: -1.9906206130981445
Batch 18/64 loss: -1.5418214797973633
Batch 19/64 loss: -1.9889955520629883
Batch 20/64 loss: -1.9286088943481445
Batch 21/64 loss: -1.7624120712280273
Batch 22/64 loss: -1.9109773635864258
Batch 23/64 loss: -1.8602581024169922
Batch 24/64 loss: -2.080320358276367
Batch 25/64 loss: -1.9664192199707031
Batch 26/64 loss: -2.097196578979492
Batch 27/64 loss: -2.133390426635742
Batch 28/64 loss: -2.0331850051879883
Batch 29/64 loss: -1.888326644897461
Batch 30/64 loss: -2.0757856369018555
Batch 31/64 loss: -1.9812116622924805
Batch 32/64 loss: -1.5854530334472656
Batch 33/64 loss: -2.0324172973632812
Batch 34/64 loss: -1.7187728881835938
Batch 35/64 loss: -1.268660545349121
Batch 36/64 loss: -1.6160850524902344
Batch 37/64 loss: -1.6808452606201172
Batch 38/64 loss: -1.7695093154907227
Batch 39/64 loss: -2.0116539001464844
Batch 40/64 loss: -2.010197639465332
Batch 41/64 loss: -1.358616828918457
Batch 42/64 loss: -1.790095329284668
Batch 43/64 loss: -1.7274971008300781
Batch 44/64 loss: -2.006349563598633
Batch 45/64 loss: -1.9505672454833984
Batch 46/64 loss: -1.7075796127319336
Batch 47/64 loss: -1.8446359634399414
Batch 48/64 loss: -2.049441337585449
Batch 49/64 loss: -1.9708490371704102
Batch 50/64 loss: -1.6531095504760742
Batch 51/64 loss: -2.1203126907348633
Batch 52/64 loss: -1.9636240005493164
Batch 53/64 loss: -1.6464166641235352
Batch 54/64 loss: -1.8562278747558594
Batch 55/64 loss: -1.8023204803466797
Batch 56/64 loss: -1.895045280456543
Batch 57/64 loss: -1.8940086364746094
Batch 58/64 loss: -2.0794429779052734
Batch 59/64 loss: -2.103700637817383
Batch 60/64 loss: -1.7923784255981445
Batch 61/64 loss: -1.433929443359375
Batch 62/64 loss: -2.0564775466918945
Batch 63/64 loss: -2.058590888977051
Batch 64/64 loss: -5.928056716918945
Epoch 233  Train loss: -1.901729740816004  Val loss: -1.933284104075219
Epoch 234
-------------------------------
Batch 1/64 loss: -1.6270313262939453
Batch 2/64 loss: -1.874227523803711
Batch 3/64 loss: -1.9322013854980469
Batch 4/64 loss: -1.9673175811767578
Batch 5/64 loss: -1.7405357360839844
Batch 6/64 loss: -1.8068504333496094
Batch 7/64 loss: -1.5865974426269531
Batch 8/64 loss: -1.4117326736450195
Batch 9/64 loss: -0.9487342834472656
Batch 10/64 loss: -1.1135549545288086
Batch 11/64 loss: -1.6914873123168945
Batch 12/64 loss: -1.6228151321411133
Batch 13/64 loss: -1.449197769165039
Batch 14/64 loss: -1.5714073181152344
Batch 15/64 loss: -1.7166576385498047
Batch 16/64 loss: -1.53955078125
Batch 17/64 loss: -1.8580074310302734
Batch 18/64 loss: -1.784749984741211
Batch 19/64 loss: -1.8010406494140625
Batch 20/64 loss: -1.7787256240844727
Batch 21/64 loss: -1.7842607498168945
Batch 22/64 loss: -1.5848312377929688
Batch 23/64 loss: -1.7786941528320312
Batch 24/64 loss: -1.4950103759765625
Batch 25/64 loss: -1.6735296249389648
Batch 26/64 loss: -1.8292694091796875
Batch 27/64 loss: -1.0846853256225586
Batch 28/64 loss: -1.6020879745483398
Batch 29/64 loss: -2.0446882247924805
Batch 30/64 loss: -1.8956413269042969
Batch 31/64 loss: -1.8012218475341797
Batch 32/64 loss: -1.8794689178466797
Batch 33/64 loss: -1.9270124435424805
Batch 34/64 loss: -1.7529211044311523
Batch 35/64 loss: -1.838348388671875
Batch 36/64 loss: -2.1377477645874023
Batch 37/64 loss: -1.7288122177124023
Batch 38/64 loss: -2.0344419479370117
Batch 39/64 loss: -1.7893295288085938
Batch 40/64 loss: -1.9071903228759766
Batch 41/64 loss: -1.9262332916259766
Batch 42/64 loss: -1.8626489639282227
Batch 43/64 loss: -2.1659421920776367
Batch 44/64 loss: -2.015751838684082
Batch 45/64 loss: -1.884322166442871
Batch 46/64 loss: -1.9523506164550781
Batch 47/64 loss: -2.0272626876831055
Batch 48/64 loss: -1.771286964416504
Batch 49/64 loss: -1.9684219360351562
Batch 50/64 loss: -1.732574462890625
Batch 51/64 loss: -1.5828313827514648
Batch 52/64 loss: -1.8399763107299805
Batch 53/64 loss: -2.138853073120117
Batch 54/64 loss: -1.8812799453735352
Batch 55/64 loss: -1.9554862976074219
Batch 56/64 loss: -1.702199935913086
Batch 57/64 loss: -1.624786376953125
Batch 58/64 loss: -1.953343391418457
Batch 59/64 loss: -1.6712474822998047
Batch 60/64 loss: -1.7781143188476562
Batch 61/64 loss: -1.774209976196289
Batch 62/64 loss: -2.0127153396606445
Batch 63/64 loss: -1.8765363693237305
Batch 64/64 loss: -5.804940700531006
Epoch 234  Train loss: -1.817156026877609  Val loss: -2.1588590825136587
Epoch 235
-------------------------------
Batch 1/64 loss: -1.858647346496582
Batch 2/64 loss: -2.1065711975097656
Batch 3/64 loss: -2.0228824615478516
Batch 4/64 loss: -2.1448049545288086
Batch 5/64 loss: -2.0102787017822266
Batch 6/64 loss: -1.5284175872802734
Batch 7/64 loss: -1.7127504348754883
Batch 8/64 loss: -1.8893699645996094
Batch 9/64 loss: -2.074740409851074
Batch 10/64 loss: -1.6597929000854492
Batch 11/64 loss: -2.0701169967651367
Batch 12/64 loss: -1.5898313522338867
Batch 13/64 loss: -2.031498908996582
Batch 14/64 loss: -1.3522844314575195
Batch 15/64 loss: -1.8267107009887695
Batch 16/64 loss: -1.6894092559814453
Batch 17/64 loss: -2.030214309692383
Batch 18/64 loss: -1.9848947525024414
Batch 19/64 loss: -1.2873477935791016
Batch 20/64 loss: -2.1544923782348633
Batch 21/64 loss: -2.068514823913574
Batch 22/64 loss: -1.7448577880859375
Batch 23/64 loss: -1.8524036407470703
Batch 24/64 loss: -1.6164979934692383
Batch 25/64 loss: -1.981125831604004
Batch 26/64 loss: -1.821908950805664
Batch 27/64 loss: -1.6023149490356445
Batch 28/64 loss: -1.9552240371704102
Batch 29/64 loss: -1.9199800491333008
Batch 30/64 loss: -1.77215576171875
Batch 31/64 loss: -1.7895593643188477
Batch 32/64 loss: -2.1044187545776367
Batch 33/64 loss: -1.6438703536987305
Batch 34/64 loss: -1.652115821838379
Batch 35/64 loss: -1.8555307388305664
Batch 36/64 loss: -1.836287498474121
Batch 37/64 loss: -1.8682327270507812
Batch 38/64 loss: -2.0111160278320312
Batch 39/64 loss: -1.3552350997924805
Batch 40/64 loss: -1.2954444885253906
Batch 41/64 loss: -1.6459016799926758
Batch 42/64 loss: -1.6950902938842773
Batch 43/64 loss: -1.6820354461669922
Batch 44/64 loss: -1.6400213241577148
Batch 45/64 loss: -1.906015396118164
Batch 46/64 loss: -1.5066137313842773
Batch 47/64 loss: -1.906494140625
Batch 48/64 loss: -1.7661895751953125
Batch 49/64 loss: -1.9919404983520508
Batch 50/64 loss: -1.774557113647461
Batch 51/64 loss: -1.9279842376708984
Batch 52/64 loss: -1.906503677368164
Batch 53/64 loss: -1.925461769104004
Batch 54/64 loss: -1.8914985656738281
Batch 55/64 loss: -1.8026304244995117
Batch 56/64 loss: -1.920405387878418
Batch 57/64 loss: -1.7748165130615234
Batch 58/64 loss: -0.9970779418945312
Batch 59/64 loss: -1.5602903366088867
Batch 60/64 loss: -1.3090019226074219
Batch 61/64 loss: -2.0320215225219727
Batch 62/64 loss: -2.0379104614257812
Batch 63/64 loss: -1.9148502349853516
Batch 64/64 loss: -5.963421821594238
Epoch 235  Train loss: -1.847211452558929  Val loss: -2.1016350841194495
Epoch 236
-------------------------------
Batch 1/64 loss: -1.907033920288086
Batch 2/64 loss: -1.992279052734375
Batch 3/64 loss: -1.6345415115356445
Batch 4/64 loss: -1.489384651184082
Batch 5/64 loss: -1.8873233795166016
Batch 6/64 loss: -1.9106664657592773
Batch 7/64 loss: -1.8258705139160156
Batch 8/64 loss: -1.931900978088379
Batch 9/64 loss: -1.8569135665893555
Batch 10/64 loss: -1.727712631225586
Batch 11/64 loss: -1.8448486328125
Batch 12/64 loss: -1.663517951965332
Batch 13/64 loss: -1.7843904495239258
Batch 14/64 loss: -2.0358667373657227
Batch 15/64 loss: -1.1823720932006836
Batch 16/64 loss: -1.9645471572875977
Batch 17/64 loss: -1.9370403289794922
Batch 18/64 loss: -1.7067451477050781
Batch 19/64 loss: -1.9155893325805664
Batch 20/64 loss: -1.6638755798339844
Batch 21/64 loss: -1.076004981994629
Batch 22/64 loss: -1.358260154724121
Batch 23/64 loss: -1.7839889526367188
Batch 24/64 loss: -1.496403694152832
Batch 25/64 loss: -1.9842748641967773
Batch 26/64 loss: -1.767012596130371
Batch 27/64 loss: -1.7611618041992188
Batch 28/64 loss: -2.0645647048950195
Batch 29/64 loss: -1.7857322692871094
Batch 30/64 loss: -1.519303321838379
Batch 31/64 loss: -2.0417566299438477
Batch 32/64 loss: -1.9071044921875
Batch 33/64 loss: -1.9183549880981445
Batch 34/64 loss: -1.7770919799804688
Batch 35/64 loss: -1.9737520217895508
Batch 36/64 loss: -1.9729986190795898
Batch 37/64 loss: -1.8834619522094727
Batch 38/64 loss: -1.967259407043457
Batch 39/64 loss: -2.1605215072631836
Batch 40/64 loss: -1.9563474655151367
Batch 41/64 loss: -1.8460025787353516
Batch 42/64 loss: -1.9723577499389648
Batch 43/64 loss: -1.6849212646484375
Batch 44/64 loss: -2.0394287109375
Batch 45/64 loss: -1.7336091995239258
Batch 46/64 loss: -1.925023078918457
Batch 47/64 loss: -1.507126808166504
Batch 48/64 loss: -1.9678926467895508
Batch 49/64 loss: -1.7494573593139648
Batch 50/64 loss: -2.0646533966064453
Batch 51/64 loss: -1.988907814025879
Batch 52/64 loss: -1.8044214248657227
Batch 53/64 loss: -1.5661754608154297
Batch 54/64 loss: -1.6395187377929688
Batch 55/64 loss: -2.0008277893066406
Batch 56/64 loss: -2.0767221450805664
Batch 57/64 loss: -2.0285730361938477
Batch 58/64 loss: -2.050905227661133
Batch 59/64 loss: -2.047247886657715
Batch 60/64 loss: -1.9452743530273438
Batch 61/64 loss: -1.9514408111572266
Batch 62/64 loss: -1.4941482543945312
Batch 63/64 loss: -1.414590835571289
Batch 64/64 loss: -6.128720283508301
Epoch 236  Train loss: -1.868447737600289  Val loss: -2.036227773554956
Epoch 237
-------------------------------
Batch 1/64 loss: -1.9035711288452148
Batch 2/64 loss: -2.0295915603637695
Batch 3/64 loss: -1.8760261535644531
Batch 4/64 loss: -2.026339530944824
Batch 5/64 loss: -1.7591705322265625
Batch 6/64 loss: -2.077700614929199
Batch 7/64 loss: -2.0162181854248047
Batch 8/64 loss: -2.154277801513672
Batch 9/64 loss: -2.0282440185546875
Batch 10/64 loss: -2.0401124954223633
Batch 11/64 loss: -1.8927507400512695
Batch 12/64 loss: -2.085272789001465
Batch 13/64 loss: -1.8990907669067383
Batch 14/64 loss: -1.895848274230957
Batch 15/64 loss: -1.805776596069336
Batch 16/64 loss: -2.100846290588379
Batch 17/64 loss: -1.873025894165039
Batch 18/64 loss: -1.8616018295288086
Batch 19/64 loss: -2.0193710327148438
Batch 20/64 loss: -1.5612716674804688
Batch 21/64 loss: -1.982407569885254
Batch 22/64 loss: -1.869755744934082
Batch 23/64 loss: -1.981328010559082
Batch 24/64 loss: -1.897456169128418
Batch 25/64 loss: -2.19234561920166
Batch 26/64 loss: -1.8378753662109375
Batch 27/64 loss: -1.812936782836914
Batch 28/64 loss: -2.0519819259643555
Batch 29/64 loss: -1.9417181015014648
Batch 30/64 loss: -2.0553884506225586
Batch 31/64 loss: -1.6884479522705078
Batch 32/64 loss: -1.7730274200439453
Batch 33/64 loss: -1.0028791427612305
Batch 34/64 loss: -1.796102523803711
Batch 35/64 loss: -1.835820198059082
Batch 36/64 loss: -1.3522071838378906
Batch 37/64 loss: -1.6752586364746094
Batch 38/64 loss: -1.8097105026245117
Batch 39/64 loss: -1.6936235427856445
Batch 40/64 loss: -1.4990959167480469
Batch 41/64 loss: -1.3078317642211914
Batch 42/64 loss: -0.7983627319335938
Batch 43/64 loss: -1.3487300872802734
Batch 44/64 loss: -1.7001361846923828
Batch 45/64 loss: -1.8666715621948242
Batch 46/64 loss: -0.8324356079101562
Batch 47/64 loss: -1.5414810180664062
Batch 48/64 loss: -1.8660717010498047
Batch 49/64 loss: -1.2057933807373047
Batch 50/64 loss: -1.6905937194824219
Batch 51/64 loss: -1.4418964385986328
Batch 52/64 loss: -1.1619682312011719
Batch 53/64 loss: -1.663893699645996
Batch 54/64 loss: -1.2370262145996094
Batch 55/64 loss: -1.6539440155029297
Batch 56/64 loss: -1.4198646545410156
Batch 57/64 loss: -1.1680574417114258
Batch 58/64 loss: -1.0848808288574219
Batch 59/64 loss: -1.7788591384887695
Batch 60/64 loss: -1.440114974975586
Batch 61/64 loss: -1.7949304580688477
Batch 62/64 loss: -1.894209861755371
Batch 63/64 loss: -1.9203882217407227
Batch 64/64 loss: -5.725222110748291
Epoch 237  Train loss: -1.7689024813034955  Val loss: -1.9446617467296903
Epoch 238
-------------------------------
Batch 1/64 loss: -0.9216785430908203
Batch 2/64 loss: -1.9644250869750977
Batch 3/64 loss: -1.8203821182250977
Batch 4/64 loss: -1.8540096282958984
Batch 5/64 loss: -1.6490764617919922
Batch 6/64 loss: -1.5635900497436523
Batch 7/64 loss: -1.5841760635375977
Batch 8/64 loss: -1.8315391540527344
Batch 9/64 loss: -1.67449951171875
Batch 10/64 loss: -1.355423927307129
Batch 11/64 loss: -1.5899276733398438
Batch 12/64 loss: -1.3736400604248047
Batch 13/64 loss: -1.6282072067260742
Batch 14/64 loss: -1.7826480865478516
Batch 15/64 loss: -1.890397071838379
Batch 16/64 loss: -1.415654182434082
Batch 17/64 loss: -1.7452726364135742
Batch 18/64 loss: -1.520705223083496
Batch 19/64 loss: -1.8729438781738281
Batch 20/64 loss: -1.8560705184936523
Batch 21/64 loss: -1.9072065353393555
Batch 22/64 loss: -1.9634733200073242
Batch 23/64 loss: -1.8478994369506836
Batch 24/64 loss: -1.8774690628051758
Batch 25/64 loss: -1.6625099182128906
Batch 26/64 loss: -1.808354377746582
Batch 27/64 loss: -2.0417909622192383
Batch 28/64 loss: -1.8843154907226562
Batch 29/64 loss: -2.0783615112304688
Batch 30/64 loss: -2.1508655548095703
Batch 31/64 loss: -1.2567338943481445
Batch 32/64 loss: -2.0370006561279297
Batch 33/64 loss: -1.902674674987793
Batch 34/64 loss: -1.9549331665039062
Batch 35/64 loss: -1.780421257019043
Batch 36/64 loss: -1.9110279083251953
Batch 37/64 loss: -2.010622978210449
Batch 38/64 loss: -1.970550537109375
Batch 39/64 loss: -1.947305679321289
Batch 40/64 loss: -2.063899040222168
Batch 41/64 loss: -1.7779312133789062
Batch 42/64 loss: -2.039605140686035
Batch 43/64 loss: -2.0734338760375977
Batch 44/64 loss: -1.9863100051879883
Batch 45/64 loss: -1.9750499725341797
Batch 46/64 loss: -1.644749641418457
Batch 47/64 loss: -2.0086774826049805
Batch 48/64 loss: -1.8462276458740234
Batch 49/64 loss: -2.014486312866211
Batch 50/64 loss: -1.4093894958496094
Batch 51/64 loss: -2.0274219512939453
Batch 52/64 loss: -2.0536184310913086
Batch 53/64 loss: -2.040459632873535
Batch 54/64 loss: -1.529703140258789
Batch 55/64 loss: -2.0816650390625
Batch 56/64 loss: -1.8728485107421875
Batch 57/64 loss: -1.9917545318603516
Batch 58/64 loss: -2.0243587493896484
Batch 59/64 loss: -1.9093074798583984
Batch 60/64 loss: -1.6960554122924805
Batch 61/64 loss: -2.082451820373535
Batch 62/64 loss: -2.01889705657959
Batch 63/64 loss: -1.9245147705078125
Batch 64/64 loss: -6.292624473571777
Epoch 238  Train loss: -1.877648136662502  Val loss: -2.290590148611167
Saving best model, epoch: 238
Epoch 239
-------------------------------
Batch 1/64 loss: -2.1453418731689453
Batch 2/64 loss: -2.0479249954223633
Batch 3/64 loss: -2.1305360794067383
Batch 4/64 loss: -2.078815460205078
Batch 5/64 loss: -2.004312515258789
Batch 6/64 loss: -1.8731670379638672
Batch 7/64 loss: -1.9082021713256836
Batch 8/64 loss: -2.191497802734375
Batch 9/64 loss: -2.086674690246582
Batch 10/64 loss: -1.9462518692016602
Batch 11/64 loss: -2.0160350799560547
Batch 12/64 loss: -2.0462493896484375
Batch 13/64 loss: -1.5593547821044922
Batch 14/64 loss: -1.7229843139648438
Batch 15/64 loss: -2.239320755004883
Batch 16/64 loss: -2.095796585083008
Batch 17/64 loss: -1.8591909408569336
Batch 18/64 loss: -1.7949237823486328
Batch 19/64 loss: -1.734086036682129
Batch 20/64 loss: -2.0038022994995117
Batch 21/64 loss: -1.847294807434082
Batch 22/64 loss: -2.168572425842285
Batch 23/64 loss: -1.841975212097168
Batch 24/64 loss: -2.1084861755371094
Batch 25/64 loss: -1.3792104721069336
Batch 26/64 loss: -1.8395662307739258
Batch 27/64 loss: -2.0899887084960938
Batch 28/64 loss: -2.1988182067871094
Batch 29/64 loss: -2.1025209426879883
Batch 30/64 loss: -1.8436031341552734
Batch 31/64 loss: -1.9166669845581055
Batch 32/64 loss: -1.747666358947754
Batch 33/64 loss: -2.131657600402832
Batch 34/64 loss: -1.765519142150879
Batch 35/64 loss: -2.1395883560180664
Batch 36/64 loss: -1.8802404403686523
Batch 37/64 loss: -2.0327796936035156
Batch 38/64 loss: -1.877284049987793
Batch 39/64 loss: -2.245756149291992
Batch 40/64 loss: -1.918837547302246
Batch 41/64 loss: -2.1655616760253906
Batch 42/64 loss: -1.8162670135498047
Batch 43/64 loss: -2.125764846801758
Batch 44/64 loss: -1.4158821105957031
Batch 45/64 loss: -1.9874343872070312
Batch 46/64 loss: -1.973907470703125
Batch 47/64 loss: -1.7334327697753906
Batch 48/64 loss: -2.006155014038086
Batch 49/64 loss: -1.9931764602661133
Batch 50/64 loss: -1.2141799926757812
Batch 51/64 loss: -1.4819698333740234
Batch 52/64 loss: -1.7055778503417969
Batch 53/64 loss: -2.123157501220703
Batch 54/64 loss: -1.9185400009155273
Batch 55/64 loss: -1.8712854385375977
Batch 56/64 loss: -1.9803857803344727
Batch 57/64 loss: -2.006298065185547
Batch 58/64 loss: -2.0613327026367188
Batch 59/64 loss: -1.8059320449829102
Batch 60/64 loss: -2.017728805541992
Batch 61/64 loss: -1.9840316772460938
Batch 62/64 loss: -1.838235855102539
Batch 63/64 loss: -2.072842597961426
Batch 64/64 loss: -5.868011951446533
Epoch 239  Train loss: -1.9805582738390155  Val loss: -2.3254877595147727
Saving best model, epoch: 239
Epoch 240
-------------------------------
Batch 1/64 loss: -2.0233287811279297
Batch 2/64 loss: -2.011746406555176
Batch 3/64 loss: -1.999629020690918
Batch 4/64 loss: -1.1072473526000977
Batch 5/64 loss: -1.9978561401367188
Batch 6/64 loss: -2.17777156829834
Batch 7/64 loss: -2.161792755126953
Batch 8/64 loss: -1.8038511276245117
Batch 9/64 loss: -1.8820381164550781
Batch 10/64 loss: -1.6366252899169922
Batch 11/64 loss: -2.056511878967285
Batch 12/64 loss: -2.1424551010131836
Batch 13/64 loss: -2.128314971923828
Batch 14/64 loss: -1.818044662475586
Batch 15/64 loss: -2.0416316986083984
Batch 16/64 loss: -1.992757797241211
Batch 17/64 loss: -2.206326484680176
Batch 18/64 loss: -1.9880075454711914
Batch 19/64 loss: -1.6003522872924805
Batch 20/64 loss: -1.7147397994995117
Batch 21/64 loss: -2.076396942138672
Batch 22/64 loss: -2.0695037841796875
Batch 23/64 loss: -2.038301467895508
Batch 24/64 loss: -1.9789848327636719
Batch 25/64 loss: -1.94873046875
Batch 26/64 loss: -1.5555124282836914
Batch 27/64 loss: -1.8372373580932617
Batch 28/64 loss: -2.11350154876709
Batch 29/64 loss: -1.8630743026733398
Batch 30/64 loss: -1.6535835266113281
Batch 31/64 loss: -1.7492361068725586
Batch 32/64 loss: -1.931839942932129
Batch 33/64 loss: -1.7938613891601562
Batch 34/64 loss: -1.9191598892211914
Batch 35/64 loss: -2.087714195251465
Batch 36/64 loss: -2.0796899795532227
Batch 37/64 loss: -1.0504865646362305
Batch 38/64 loss: -1.6082258224487305
Batch 39/64 loss: -2.002248764038086
Batch 40/64 loss: -2.1297731399536133
Batch 41/64 loss: -0.3998689651489258
Batch 42/64 loss: -1.2037229537963867
Batch 43/64 loss: -1.8715124130249023
Batch 44/64 loss: -1.895716667175293
Batch 45/64 loss: -2.121260643005371
Batch 46/64 loss: -1.9311609268188477
Batch 47/64 loss: -2.3004913330078125
Batch 48/64 loss: -1.882288932800293
Batch 49/64 loss: -1.6736326217651367
Batch 50/64 loss: -2.1089324951171875
Batch 51/64 loss: -2.1502914428710938
Batch 52/64 loss: -1.9576759338378906
Batch 53/64 loss: -2.1929121017456055
Batch 54/64 loss: -2.0748729705810547
Batch 55/64 loss: -1.6146612167358398
Batch 56/64 loss: -2.0766963958740234
Batch 57/64 loss: -1.8976879119873047
Batch 58/64 loss: -2.031479835510254
Batch 59/64 loss: -2.0255165100097656
Batch 60/64 loss: -2.1656179428100586
Batch 61/64 loss: -2.05118465423584
Batch 62/64 loss: -2.16872501373291
Batch 63/64 loss: -1.912440299987793
Batch 64/64 loss: -6.2253313064575195
Epoch 240  Train loss: -1.9506735670800301  Val loss: -2.2376745296098113
Epoch 241
-------------------------------
Batch 1/64 loss: -2.109251022338867
Batch 2/64 loss: -2.140007972717285
Batch 3/64 loss: -2.103482246398926
Batch 4/64 loss: -1.9339609146118164
Batch 5/64 loss: -1.7493982315063477
Batch 6/64 loss: -2.0077381134033203
Batch 7/64 loss: -2.027501106262207
Batch 8/64 loss: -1.6172761917114258
Batch 9/64 loss: -1.5314865112304688
Batch 10/64 loss: -1.4082794189453125
Batch 11/64 loss: -1.8891372680664062
Batch 12/64 loss: -2.070751190185547
Batch 13/64 loss: -1.3322458267211914
Batch 14/64 loss: -1.1615657806396484
Batch 15/64 loss: -1.8811655044555664
Batch 16/64 loss: -2.1764602661132812
Batch 17/64 loss: -1.7199316024780273
Batch 18/64 loss: -1.9855165481567383
Batch 19/64 loss: -0.9033517837524414
Batch 20/64 loss: -1.9862127304077148
Batch 21/64 loss: -1.048487663269043
Batch 22/64 loss: -1.8327713012695312
Batch 23/64 loss: -2.0305986404418945
Batch 24/64 loss: -2.015467643737793
Batch 25/64 loss: -1.8954439163208008
Batch 26/64 loss: -1.929800033569336
Batch 27/64 loss: -1.8205146789550781
Batch 28/64 loss: -1.7349376678466797
Batch 29/64 loss: -1.84552001953125
Batch 30/64 loss: -1.1659936904907227
Batch 31/64 loss: -2.2537918090820312
Batch 32/64 loss: -1.8295249938964844
Batch 33/64 loss: -1.8376598358154297
Batch 34/64 loss: -2.0868663787841797
Batch 35/64 loss: -2.1203441619873047
Batch 36/64 loss: -1.8724403381347656
Batch 37/64 loss: -1.5992813110351562
Batch 38/64 loss: -2.094305992126465
Batch 39/64 loss: -1.6746463775634766
Batch 40/64 loss: -1.9908390045166016
Batch 41/64 loss: -1.3813972473144531
Batch 42/64 loss: -1.9735450744628906
Batch 43/64 loss: -1.9878034591674805
Batch 44/64 loss: -1.8041410446166992
Batch 45/64 loss: -1.9559783935546875
Batch 46/64 loss: -1.8128728866577148
Batch 47/64 loss: -1.756155014038086
Batch 48/64 loss: -2.1622982025146484
Batch 49/64 loss: -1.9027175903320312
Batch 50/64 loss: -1.8887567520141602
Batch 51/64 loss: -2.0697288513183594
Batch 52/64 loss: -2.1934547424316406
Batch 53/64 loss: -2.148003578186035
Batch 54/64 loss: -2.115842819213867
Batch 55/64 loss: -2.0725669860839844
Batch 56/64 loss: -2.0691184997558594
Batch 57/64 loss: -2.102071762084961
Batch 58/64 loss: -2.462993621826172
Batch 59/64 loss: -2.2026548385620117
Batch 60/64 loss: -2.1536664962768555
Batch 61/64 loss: -2.283519744873047
Batch 62/64 loss: -1.5596952438354492
Batch 63/64 loss: -1.7962417602539062
Batch 64/64 loss: -6.225616931915283
Epoch 241  Train loss: -1.928445380341773  Val loss: -2.2796378512562754
Epoch 242
-------------------------------
Batch 1/64 loss: -2.025223731994629
Batch 2/64 loss: -1.631484031677246
Batch 3/64 loss: -2.065359115600586
Batch 4/64 loss: -1.785902976989746
Batch 5/64 loss: -1.926865577697754
Batch 6/64 loss: -1.8915348052978516
Batch 7/64 loss: -2.035372734069824
Batch 8/64 loss: -2.2430620193481445
Batch 9/64 loss: -1.9863195419311523
Batch 10/64 loss: -2.3912763595581055
Batch 11/64 loss: -2.033493995666504
Batch 12/64 loss: -1.9333782196044922
Batch 13/64 loss: -2.0443429946899414
Batch 14/64 loss: -1.680293083190918
Batch 15/64 loss: -2.140779495239258
Batch 16/64 loss: -2.252987861633301
Batch 17/64 loss: -1.9304742813110352
Batch 18/64 loss: -1.911677360534668
Batch 19/64 loss: -2.17832088470459
Batch 20/64 loss: -2.1694698333740234
Batch 21/64 loss: -2.2566261291503906
Batch 22/64 loss: -1.9289875030517578
Batch 23/64 loss: -1.8913545608520508
Batch 24/64 loss: -2.2281131744384766
Batch 25/64 loss: -2.143247604370117
Batch 26/64 loss: -2.2183704376220703
Batch 27/64 loss: -1.597951889038086
Batch 28/64 loss: -1.7312870025634766
Batch 29/64 loss: -2.1748523712158203
Batch 30/64 loss: -1.9746332168579102
Batch 31/64 loss: -1.7187423706054688
Batch 32/64 loss: -2.099349021911621
Batch 33/64 loss: -1.953603744506836
Batch 34/64 loss: -1.593414306640625
Batch 35/64 loss: -1.7383146286010742
Batch 36/64 loss: -1.8411369323730469
Batch 37/64 loss: -2.0724363327026367
Batch 38/64 loss: -2.150376319885254
Batch 39/64 loss: -1.8189067840576172
Batch 40/64 loss: -1.9985780715942383
Batch 41/64 loss: -2.019054412841797
Batch 42/64 loss: -1.3749237060546875
Batch 43/64 loss: -1.8888044357299805
Batch 44/64 loss: -1.7868280410766602
Batch 45/64 loss: -1.6600589752197266
Batch 46/64 loss: -1.9029951095581055
Batch 47/64 loss: -1.5122623443603516
Batch 48/64 loss: -1.2043886184692383
Batch 49/64 loss: -1.9049673080444336
Batch 50/64 loss: -1.557021141052246
Batch 51/64 loss: -2.0861692428588867
Batch 52/64 loss: -1.979893684387207
Batch 53/64 loss: -1.9638471603393555
Batch 54/64 loss: -2.207469940185547
Batch 55/64 loss: -1.3723888397216797
Batch 56/64 loss: -2.1580381393432617
Batch 57/64 loss: -1.9386777877807617
Batch 58/64 loss: -2.021786689758301
Batch 59/64 loss: -1.8658809661865234
Batch 60/64 loss: -1.561788558959961
Batch 61/64 loss: -2.22634220123291
Batch 62/64 loss: -1.9644012451171875
Batch 63/64 loss: -2.189211845397949
Batch 64/64 loss: -6.176770210266113
Epoch 242  Train loss: -1.9822381075690774  Val loss: -2.0665557572931768
Epoch 243
-------------------------------
Batch 1/64 loss: -0.9501132965087891
Batch 2/64 loss: -2.035165786743164
Batch 3/64 loss: -1.8539447784423828
Batch 4/64 loss: -1.0403470993041992
Batch 5/64 loss: -2.20150089263916
Batch 6/64 loss: -1.5282020568847656
Batch 7/64 loss: -2.147676467895508
Batch 8/64 loss: -1.6968822479248047
Batch 9/64 loss: -1.9544601440429688
Batch 10/64 loss: -1.3740768432617188
Batch 11/64 loss: -2.098163604736328
Batch 12/64 loss: -2.110982894897461
Batch 13/64 loss: -2.0537118911743164
Batch 14/64 loss: -2.1010875701904297
Batch 15/64 loss: -2.3336286544799805
Batch 16/64 loss: -1.8748407363891602
Batch 17/64 loss: -1.6685476303100586
Batch 18/64 loss: -1.7907629013061523
Batch 19/64 loss: -1.809037208557129
Batch 20/64 loss: -2.087761878967285
Batch 21/64 loss: -2.17349910736084
Batch 22/64 loss: -2.252346992492676
Batch 23/64 loss: -2.2184200286865234
Batch 24/64 loss: -1.953547477722168
Batch 25/64 loss: -2.1472654342651367
Batch 26/64 loss: -2.304083824157715
Batch 27/64 loss: -1.968092918395996
Batch 28/64 loss: -2.0873289108276367
Batch 29/64 loss: -2.2061614990234375
Batch 30/64 loss: -2.0850439071655273
Batch 31/64 loss: -2.1198549270629883
Batch 32/64 loss: -2.1980676651000977
Batch 33/64 loss: -2.201353073120117
Batch 34/64 loss: -1.7347440719604492
Batch 35/64 loss: -1.7788591384887695
Batch 36/64 loss: -1.8595914840698242
Batch 37/64 loss: -2.1604738235473633
Batch 38/64 loss: -2.215869903564453
Batch 39/64 loss: -1.9753198623657227
Batch 40/64 loss: -1.6687898635864258
Batch 41/64 loss: -1.8059921264648438
Batch 42/64 loss: -2.1143798828125
Batch 43/64 loss: -1.6996183395385742
Batch 44/64 loss: -2.1850414276123047
Batch 45/64 loss: -1.3327083587646484
Batch 46/64 loss: -2.1494760513305664
Batch 47/64 loss: -1.7564849853515625
Batch 48/64 loss: -1.8905467987060547
Batch 49/64 loss: -2.1013622283935547
Batch 50/64 loss: -2.243454933166504
Batch 51/64 loss: -2.071012496948242
Batch 52/64 loss: -2.1934242248535156
Batch 53/64 loss: -2.0106945037841797
Batch 54/64 loss: -1.9350814819335938
Batch 55/64 loss: -2.2303085327148438
Batch 56/64 loss: -2.055914878845215
Batch 57/64 loss: -2.1346797943115234
Batch 58/64 loss: -1.8257522583007812
Batch 59/64 loss: -1.798116683959961
Batch 60/64 loss: -1.8622312545776367
Batch 61/64 loss: -1.9292793273925781
Batch 62/64 loss: -2.2985572814941406
Batch 63/64 loss: -1.4496431350708008
Batch 64/64 loss: -6.161332607269287
Epoch 243  Train loss: -2.0033626500297994  Val loss: -1.9509120823181783
Epoch 244
-------------------------------
Batch 1/64 loss: -2.0083770751953125
Batch 2/64 loss: -2.2530250549316406
Batch 3/64 loss: -1.8372631072998047
Batch 4/64 loss: -2.093994140625
Batch 5/64 loss: -2.0560970306396484
Batch 6/64 loss: -1.9384651184082031
Batch 7/64 loss: -1.848555564880371
Batch 8/64 loss: -1.9787664413452148
Batch 9/64 loss: -2.181157112121582
Batch 10/64 loss: -2.173215866088867
Batch 11/64 loss: -2.0920753479003906
Batch 12/64 loss: -2.261643886566162
Batch 13/64 loss: -2.046982765197754
Batch 14/64 loss: -2.168452262878418
Batch 15/64 loss: -1.3690862655639648
Batch 16/64 loss: -2.150763511657715
Batch 17/64 loss: -2.2286815643310547
Batch 18/64 loss: -2.0022544860839844
Batch 19/64 loss: -1.4538354873657227
Batch 20/64 loss: -1.7714662551879883
Batch 21/64 loss: -2.040079116821289
Batch 22/64 loss: -1.5597190856933594
Batch 23/64 loss: -2.0121536254882812
Batch 24/64 loss: -1.9305763244628906
Batch 25/64 loss: -1.704214096069336
Batch 26/64 loss: -2.060087203979492
Batch 27/64 loss: -1.8219528198242188
Batch 28/64 loss: -1.8898496627807617
Batch 29/64 loss: -1.7528352737426758
Batch 30/64 loss: -2.035466194152832
Batch 31/64 loss: -1.8871850967407227
Batch 32/64 loss: -1.9051475524902344
Batch 33/64 loss: -2.114504814147949
Batch 34/64 loss: -1.7120351791381836
Batch 35/64 loss: -1.8293142318725586
Batch 36/64 loss: -1.7582292556762695
Batch 37/64 loss: -2.238801956176758
Batch 38/64 loss: -2.0644893646240234
Batch 39/64 loss: -2.1684999465942383
Batch 40/64 loss: -1.9199752807617188
Batch 41/64 loss: -2.1516590118408203
Batch 42/64 loss: -1.859084129333496
Batch 43/64 loss: -2.1235485076904297
Batch 44/64 loss: -2.079586982727051
Batch 45/64 loss: -2.1940689086914062
Batch 46/64 loss: -2.030592918395996
Batch 47/64 loss: -1.6916704177856445
Batch 48/64 loss: -1.3315181732177734
Batch 49/64 loss: -1.9644184112548828
Batch 50/64 loss: -1.4678277969360352
Batch 51/64 loss: -2.260037899017334
Batch 52/64 loss: -1.9249839782714844
Batch 53/64 loss: -2.1475439071655273
Batch 54/64 loss: -2.0350465774536133
Batch 55/64 loss: -1.6928291320800781
Batch 56/64 loss: -1.883626937866211
Batch 57/64 loss: -1.8908014297485352
Batch 58/64 loss: -2.1342525482177734
Batch 59/64 loss: -1.7925119400024414
Batch 60/64 loss: -2.157586097717285
Batch 61/64 loss: -2.057478904724121
Batch 62/64 loss: -1.7544689178466797
Batch 63/64 loss: -2.059324264526367
Batch 64/64 loss: -6.073788166046143
Epoch 244  Train loss: -2.0009267975302305  Val loss: -2.2834706650566807
Epoch 245
-------------------------------
Batch 1/64 loss: -2.1091270446777344
Batch 2/64 loss: -1.9450607299804688
Batch 3/64 loss: -1.9093742370605469
Batch 4/64 loss: -2.043585777282715
Batch 5/64 loss: -2.169459342956543
Batch 6/64 loss: -2.122396469116211
Batch 7/64 loss: -1.748861312866211
Batch 8/64 loss: -1.9055747985839844
Batch 9/64 loss: -2.094414710998535
Batch 10/64 loss: -2.1340932846069336
Batch 11/64 loss: -2.0209131240844727
Batch 12/64 loss: -2.1280288696289062
Batch 13/64 loss: -1.5735702514648438
Batch 14/64 loss: -1.932356834411621
Batch 15/64 loss: -1.4533319473266602
Batch 16/64 loss: -2.2483673095703125
Batch 17/64 loss: -2.1265411376953125
Batch 18/64 loss: -2.0870304107666016
Batch 19/64 loss: -1.8875970840454102
Batch 20/64 loss: -1.9005489349365234
Batch 21/64 loss: -1.7564115524291992
Batch 22/64 loss: -1.5688819885253906
Batch 23/64 loss: -2.0850629806518555
Batch 24/64 loss: -2.179553985595703
Batch 25/64 loss: -2.078118324279785
Batch 26/64 loss: -1.9930620193481445
Batch 27/64 loss: -1.9594802856445312
Batch 28/64 loss: -1.7122077941894531
Batch 29/64 loss: -1.6674270629882812
Batch 30/64 loss: -1.482335090637207
Batch 31/64 loss: -1.884425163269043
Batch 32/64 loss: -1.8428049087524414
Batch 33/64 loss: -1.9358673095703125
Batch 34/64 loss: -2.178691864013672
Batch 35/64 loss: -1.947275161743164
Batch 36/64 loss: -1.5457954406738281
Batch 37/64 loss: -1.9039039611816406
Batch 38/64 loss: -2.1174936294555664
Batch 39/64 loss: -2.2418527603149414
Batch 40/64 loss: -2.19284725189209
Batch 41/64 loss: -2.26129150390625
Batch 42/64 loss: -2.12860107421875
Batch 43/64 loss: -2.1929311752319336
Batch 44/64 loss: -1.9416685104370117
Batch 45/64 loss: -2.142886161804199
Batch 46/64 loss: -2.0088720321655273
Batch 47/64 loss: -2.0968971252441406
Batch 48/64 loss: -1.6449966430664062
Batch 49/64 loss: -1.8812599182128906
Batch 50/64 loss: -2.1597795486450195
Batch 51/64 loss: -2.0819435119628906
Batch 52/64 loss: -1.8649730682373047
Batch 53/64 loss: -1.9461736679077148
Batch 54/64 loss: -2.141927719116211
Batch 55/64 loss: -1.9791793823242188
Batch 56/64 loss: -2.293701648712158
Batch 57/64 loss: -2.07257080078125
Batch 58/64 loss: -1.6558313369750977
Batch 59/64 loss: -1.790201187133789
Batch 60/64 loss: -1.355550765991211
Batch 61/64 loss: -1.5475349426269531
Batch 62/64 loss: -1.8800601959228516
Batch 63/64 loss: -1.6694774627685547
Batch 64/64 loss: -6.3575873374938965
Epoch 245  Train loss: -1.9971801103330127  Val loss: -2.1370926820945084
Epoch 246
-------------------------------
Batch 1/64 loss: -1.7749204635620117
Batch 2/64 loss: -1.9505958557128906
Batch 3/64 loss: -2.077853202819824
Batch 4/64 loss: -2.2001495361328125
Batch 5/64 loss: -1.8544721603393555
Batch 6/64 loss: -2.073863983154297
Batch 7/64 loss: -2.0958175659179688
Batch 8/64 loss: -1.703695297241211
Batch 9/64 loss: -2.0452613830566406
Batch 10/64 loss: -1.9465551376342773
Batch 11/64 loss: -2.1475706100463867
Batch 12/64 loss: -1.9875526428222656
Batch 13/64 loss: -1.9450178146362305
Batch 14/64 loss: -2.106781005859375
Batch 15/64 loss: -1.6355667114257812
Batch 16/64 loss: -2.0421133041381836
Batch 17/64 loss: -2.089141845703125
Batch 18/64 loss: -1.9077739715576172
Batch 19/64 loss: -2.096407890319824
Batch 20/64 loss: -2.0119247436523438
Batch 21/64 loss: -2.165884017944336
Batch 22/64 loss: -2.1651477813720703
Batch 23/64 loss: -2.1512107849121094
Batch 24/64 loss: -2.290678024291992
Batch 25/64 loss: -2.190770149230957
Batch 26/64 loss: -1.592667579650879
Batch 27/64 loss: -2.217823028564453
Batch 28/64 loss: -1.9929084777832031
Batch 29/64 loss: -2.222048759460449
Batch 30/64 loss: -1.5172128677368164
Batch 31/64 loss: -2.1538333892822266
Batch 32/64 loss: -1.8986835479736328
Batch 33/64 loss: -2.149993896484375
Batch 34/64 loss: -2.1312789916992188
Batch 35/64 loss: -2.157107353210449
Batch 36/64 loss: -2.192927360534668
Batch 37/64 loss: -2.0324392318725586
Batch 38/64 loss: -1.9568233489990234
Batch 39/64 loss: -1.55047607421875
Batch 40/64 loss: -2.3352746963500977
Batch 41/64 loss: -2.018909454345703
Batch 42/64 loss: -2.128678321838379
Batch 43/64 loss: -2.241199493408203
Batch 44/64 loss: -2.0389108657836914
Batch 45/64 loss: -2.2290687561035156
Batch 46/64 loss: -2.1416234970092773
Batch 47/64 loss: -2.002309799194336
Batch 48/64 loss: -1.9323854446411133
Batch 49/64 loss: -2.1585426330566406
Batch 50/64 loss: -2.0356969833374023
Batch 51/64 loss: -1.862523078918457
Batch 52/64 loss: -1.8171710968017578
Batch 53/64 loss: -2.069302558898926
Batch 54/64 loss: -1.915999412536621
Batch 55/64 loss: -1.8950729370117188
Batch 56/64 loss: -2.1311769485473633
Batch 57/64 loss: -1.8639945983886719
Batch 58/64 loss: -2.3589301109313965
Batch 59/64 loss: -2.0197324752807617
Batch 60/64 loss: -1.9979066848754883
Batch 61/64 loss: -2.0456342697143555
Batch 62/64 loss: -1.979945182800293
Batch 63/64 loss: -2.223825454711914
Batch 64/64 loss: -5.497474670410156
Epoch 246  Train loss: -2.0704293419333064  Val loss: -2.314278618986254
Epoch 247
-------------------------------
Batch 1/64 loss: -2.1495676040649414
Batch 2/64 loss: -1.7512483596801758
Batch 3/64 loss: -2.092728614807129
Batch 4/64 loss: -2.1206283569335938
Batch 5/64 loss: -2.3434481620788574
Batch 6/64 loss: -2.198091506958008
Batch 7/64 loss: -2.2460947036743164
Batch 8/64 loss: -1.9820966720581055
Batch 9/64 loss: -2.2242822647094727
Batch 10/64 loss: -2.224681854248047
Batch 11/64 loss: -2.161224365234375
Batch 12/64 loss: -1.9332847595214844
Batch 13/64 loss: -1.4640626907348633
Batch 14/64 loss: -1.90594482421875
Batch 15/64 loss: -2.135221481323242
Batch 16/64 loss: -2.242532730102539
Batch 17/64 loss: -2.0010299682617188
Batch 18/64 loss: -1.8657875061035156
Batch 19/64 loss: -2.0507869720458984
Batch 20/64 loss: -2.321169376373291
Batch 21/64 loss: -1.9698848724365234
Batch 22/64 loss: -1.54925537109375
Batch 23/64 loss: -2.1066341400146484
Batch 24/64 loss: -1.947641372680664
Batch 25/64 loss: -1.6194534301757812
Batch 26/64 loss: -2.06479549407959
Batch 27/64 loss: -1.9498281478881836
Batch 28/64 loss: -1.8476018905639648
Batch 29/64 loss: -2.1085071563720703
Batch 30/64 loss: -1.9390621185302734
Batch 31/64 loss: -1.5825700759887695
Batch 32/64 loss: -1.8982715606689453
Batch 33/64 loss: -1.7657852172851562
Batch 34/64 loss: -2.1913318634033203
Batch 35/64 loss: -2.00264835357666
Batch 36/64 loss: -2.018533706665039
Batch 37/64 loss: -2.0495948791503906
Batch 38/64 loss: -1.4513797760009766
Batch 39/64 loss: -1.781996726989746
Batch 40/64 loss: -1.9500455856323242
Batch 41/64 loss: -2.125368118286133
Batch 42/64 loss: -1.8162641525268555
Batch 43/64 loss: -1.9587459564208984
Batch 44/64 loss: -1.9005889892578125
Batch 45/64 loss: -2.0624160766601562
Batch 46/64 loss: -1.9643001556396484
Batch 47/64 loss: -1.1643667221069336
Batch 48/64 loss: -2.0002355575561523
Batch 49/64 loss: -1.941314697265625
Batch 50/64 loss: -1.967996597290039
Batch 51/64 loss: -1.9376811981201172
Batch 52/64 loss: -2.1711502075195312
Batch 53/64 loss: -2.021879196166992
Batch 54/64 loss: -2.0600767135620117
Batch 55/64 loss: -1.9438791275024414
Batch 56/64 loss: -2.259640693664551
Batch 57/64 loss: -2.001101493835449
Batch 58/64 loss: -2.2100353240966797
Batch 59/64 loss: -1.8348703384399414
Batch 60/64 loss: -1.9182167053222656
Batch 61/64 loss: -2.073502540588379
Batch 62/64 loss: -2.1419496536254883
Batch 63/64 loss: -1.655613899230957
Batch 64/64 loss: -6.096306324005127
Epoch 247  Train loss: -2.02215150384342  Val loss: -2.162491631262081
Epoch 248
-------------------------------
Batch 1/64 loss: -2.016728401184082
Batch 2/64 loss: -1.846205711364746
Batch 3/64 loss: -1.8662433624267578
Batch 4/64 loss: -1.8615474700927734
Batch 5/64 loss: -2.0023183822631836
Batch 6/64 loss: -1.6464862823486328
Batch 7/64 loss: -1.7652254104614258
Batch 8/64 loss: -2.017086982727051
Batch 9/64 loss: -2.0702686309814453
Batch 10/64 loss: -2.079463005065918
Batch 11/64 loss: -2.190044403076172
Batch 12/64 loss: -1.942098617553711
Batch 13/64 loss: -1.9805793762207031
Batch 14/64 loss: -1.9140634536743164
Batch 15/64 loss: -2.01657772064209
Batch 16/64 loss: -1.8210840225219727
Batch 17/64 loss: -1.93951416015625
Batch 18/64 loss: -2.1826553344726562
Batch 19/64 loss: -1.8666887283325195
Batch 20/64 loss: -2.0800418853759766
Batch 21/64 loss: -2.112185478210449
Batch 22/64 loss: -2.11240291595459
Batch 23/64 loss: -1.7868900299072266
Batch 24/64 loss: -2.175394058227539
Batch 25/64 loss: -1.937453269958496
Batch 26/64 loss: -1.8950910568237305
Batch 27/64 loss: -1.3011245727539062
Batch 28/64 loss: -1.9867897033691406
Batch 29/64 loss: -1.928314208984375
Batch 30/64 loss: -2.1577911376953125
Batch 31/64 loss: -2.292339324951172
Batch 32/64 loss: -2.0745410919189453
Batch 33/64 loss: -1.9624643325805664
Batch 34/64 loss: -1.5266551971435547
Batch 35/64 loss: -1.653609275817871
Batch 36/64 loss: -1.833033561706543
Batch 37/64 loss: -1.9392681121826172
Batch 38/64 loss: -2.17484188079834
Batch 39/64 loss: -2.0617151260375977
Batch 40/64 loss: -1.8512258529663086
Batch 41/64 loss: -2.011749267578125
Batch 42/64 loss: -2.14276123046875
Batch 43/64 loss: -2.1086788177490234
Batch 44/64 loss: -2.0774917602539062
Batch 45/64 loss: -1.2444772720336914
Batch 46/64 loss: -2.0426130294799805
Batch 47/64 loss: -1.8982305526733398
Batch 48/64 loss: -1.9970932006835938
Batch 49/64 loss: -1.8926572799682617
Batch 50/64 loss: -1.8742790222167969
Batch 51/64 loss: -2.1184778213500977
Batch 52/64 loss: -1.5685091018676758
Batch 53/64 loss: -1.9903287887573242
Batch 54/64 loss: -1.9993066787719727
Batch 55/64 loss: -2.0684995651245117
Batch 56/64 loss: -1.9412059783935547
Batch 57/64 loss: -1.784886360168457
Batch 58/64 loss: -1.74066162109375
Batch 59/64 loss: -2.1465654373168945
Batch 60/64 loss: -1.9802064895629883
Batch 61/64 loss: -2.0459537506103516
Batch 62/64 loss: -2.2028236389160156
Batch 63/64 loss: -2.084660530090332
Batch 64/64 loss: -6.33219051361084
Epoch 248  Train loss: -2.001244103674795  Val loss: -2.3502859659620987
Saving best model, epoch: 248
Epoch 249
-------------------------------
Batch 1/64 loss: -1.9538021087646484
Batch 2/64 loss: -2.14090633392334
Batch 3/64 loss: -1.6055936813354492
Batch 4/64 loss: -2.2719860076904297
Batch 5/64 loss: -2.1756954193115234
Batch 6/64 loss: -2.077143669128418
Batch 7/64 loss: -2.249190330505371
Batch 8/64 loss: -2.0878820419311523
Batch 9/64 loss: -2.1055707931518555
Batch 10/64 loss: -2.016735076904297
Batch 11/64 loss: -2.1158151626586914
Batch 12/64 loss: -1.9373588562011719
Batch 13/64 loss: -1.6074390411376953
Batch 14/64 loss: -1.7483024597167969
Batch 15/64 loss: -2.215611457824707
Batch 16/64 loss: -2.1644277572631836
Batch 17/64 loss: -2.1770782470703125
Batch 18/64 loss: -2.211366653442383
Batch 19/64 loss: -1.4365453720092773
Batch 20/64 loss: -2.100919723510742
Batch 21/64 loss: -2.0184507369995117
Batch 22/64 loss: -2.367879867553711
Batch 23/64 loss: -1.7903165817260742
Batch 24/64 loss: -1.7834844589233398
Batch 25/64 loss: -2.365145683288574
Batch 26/64 loss: -2.112401008605957
Batch 27/64 loss: -2.1764678955078125
Batch 28/64 loss: -1.846658706665039
Batch 29/64 loss: -2.087749481201172
Batch 30/64 loss: -2.104414939880371
Batch 31/64 loss: -1.8759889602661133
Batch 32/64 loss: -2.064335823059082
Batch 33/64 loss: -2.0087203979492188
Batch 34/64 loss: -2.1846141815185547
Batch 35/64 loss: -2.189141273498535
Batch 36/64 loss: -1.8141021728515625
Batch 37/64 loss: -2.0901622772216797
Batch 38/64 loss: -2.022305488586426
Batch 39/64 loss: -1.3842191696166992
Batch 40/64 loss: -2.2423534393310547
Batch 41/64 loss: -1.6749534606933594
Batch 42/64 loss: -1.9733381271362305
Batch 43/64 loss: -2.1278038024902344
Batch 44/64 loss: -2.200350761413574
Batch 45/64 loss: -2.1588258743286133
Batch 46/64 loss: -2.1943016052246094
Batch 47/64 loss: -2.170135498046875
Batch 48/64 loss: -1.8244085311889648
Batch 49/64 loss: -2.3559226989746094
Batch 50/64 loss: -2.1073122024536133
Batch 51/64 loss: -2.2342357635498047
Batch 52/64 loss: -2.241497039794922
Batch 53/64 loss: -2.1752471923828125
Batch 54/64 loss: -2.3260984420776367
Batch 55/64 loss: -2.3866591453552246
Batch 56/64 loss: -2.1930923461914062
Batch 57/64 loss: -2.0457420349121094
Batch 58/64 loss: -1.837113380432129
Batch 59/64 loss: -2.055365562438965
Batch 60/64 loss: -1.9367303848266602
Batch 61/64 loss: -2.2016849517822266
Batch 62/64 loss: -2.1027984619140625
Batch 63/64 loss: -2.1939449310302734
Batch 64/64 loss: -6.327505111694336
Epoch 249  Train loss: -2.1081015493355544  Val loss: -2.475128973472569
Saving best model, epoch: 249
Epoch 250
-------------------------------
Batch 1/64 loss: -1.8432207107543945
Batch 2/64 loss: -2.2758750915527344
Batch 3/64 loss: -1.1096420288085938
Batch 4/64 loss: -2.163558006286621
Batch 5/64 loss: -2.100250244140625
Batch 6/64 loss: -1.924509048461914
Batch 7/64 loss: -2.1492395401000977
Batch 8/64 loss: -2.2087764739990234
Batch 9/64 loss: -2.1590051651000977
Batch 10/64 loss: -2.0044679641723633
Batch 11/64 loss: -2.161250114440918
Batch 12/64 loss: -2.2241811752319336
Batch 13/64 loss: -1.6055707931518555
Batch 14/64 loss: -2.1489667892456055
Batch 15/64 loss: -2.1497631072998047
Batch 16/64 loss: -1.8147096633911133
Batch 17/64 loss: -2.0483713150024414
Batch 18/64 loss: -1.606684684753418
Batch 19/64 loss: -1.7346153259277344
Batch 20/64 loss: -1.6633234024047852
Batch 21/64 loss: -1.8436775207519531
Batch 22/64 loss: -2.086575508117676
Batch 23/64 loss: -1.9467058181762695
Batch 24/64 loss: -2.048884391784668
Batch 25/64 loss: -2.149725914001465
Batch 26/64 loss: -1.8441667556762695
Batch 27/64 loss: -1.6352415084838867
Batch 28/64 loss: -1.6424522399902344
Batch 29/64 loss: -1.9552536010742188
Batch 30/64 loss: -2.0580673217773438
Batch 31/64 loss: -1.479766845703125
Batch 32/64 loss: -1.8187179565429688
Batch 33/64 loss: -2.008167266845703
Batch 34/64 loss: -1.8836355209350586
Batch 35/64 loss: -1.9926471710205078
Batch 36/64 loss: -2.108914375305176
Batch 37/64 loss: -1.7665681838989258
Batch 38/64 loss: -1.9315710067749023
Batch 39/64 loss: -1.9509830474853516
Batch 40/64 loss: -1.994828224182129
Batch 41/64 loss: -1.9324874877929688
Batch 42/64 loss: -1.7686891555786133
Batch 43/64 loss: -2.124704360961914
Batch 44/64 loss: -1.9913702011108398
Batch 45/64 loss: -1.7995576858520508
Batch 46/64 loss: -1.949462890625
Batch 47/64 loss: -2.0316781997680664
Batch 48/64 loss: -1.8808259963989258
Batch 49/64 loss: -2.0268774032592773
Batch 50/64 loss: -1.935288429260254
Batch 51/64 loss: -2.13173770904541
Batch 52/64 loss: -2.1633262634277344
Batch 53/64 loss: -1.728022575378418
Batch 54/64 loss: -2.268069267272949
Batch 55/64 loss: -1.8923959732055664
Batch 56/64 loss: -2.1364316940307617
Batch 57/64 loss: -2.221714973449707
Batch 58/64 loss: -2.1322708129882812
Batch 59/64 loss: -1.957554817199707
Batch 60/64 loss: -2.1258134841918945
Batch 61/64 loss: -2.082892417907715
Batch 62/64 loss: -1.9147462844848633
Batch 63/64 loss: -2.09250545501709
Batch 64/64 loss: -6.311655521392822
Epoch 250  Train loss: -2.011995231404024  Val loss: -2.4079627990722656
Epoch 251
-------------------------------
Batch 1/64 loss: -2.259256362915039
Batch 2/64 loss: -1.6830463409423828
Batch 3/64 loss: -2.2170724868774414
Batch 4/64 loss: -1.8541173934936523
Batch 5/64 loss: -2.126626968383789
Batch 6/64 loss: -1.7662944793701172
Batch 7/64 loss: -2.171884536743164
Batch 8/64 loss: -2.2207765579223633
Batch 9/64 loss: -2.13515567779541
Batch 10/64 loss: -2.095301628112793
Batch 11/64 loss: -1.9210538864135742
Batch 12/64 loss: -2.311461925506592
Batch 13/64 loss: -1.6306037902832031
Batch 14/64 loss: -2.0776548385620117
Batch 15/64 loss: -2.087887763977051
Batch 16/64 loss: -1.9267463684082031
Batch 17/64 loss: -2.0164737701416016
Batch 18/64 loss: -1.9188461303710938
Batch 19/64 loss: -2.0338964462280273
Batch 20/64 loss: -1.9197149276733398
Batch 21/64 loss: -2.042329788208008
Batch 22/64 loss: -1.773421287536621
Batch 23/64 loss: -1.9629087448120117
Batch 24/64 loss: -2.0710811614990234
Batch 25/64 loss: -1.971426010131836
Batch 26/64 loss: -2.0816497802734375
Batch 27/64 loss: -2.0785980224609375
Batch 28/64 loss: -2.0392303466796875
Batch 29/64 loss: -2.049764633178711
Batch 30/64 loss: -1.927079200744629
Batch 31/64 loss: -1.755147933959961
Batch 32/64 loss: -1.8889741897583008
Batch 33/64 loss: -1.7989673614501953
Batch 34/64 loss: -1.9863100051879883
Batch 35/64 loss: -2.0217275619506836
Batch 36/64 loss: -2.1025400161743164
Batch 37/64 loss: -2.121729850769043
Batch 38/64 loss: -2.050558090209961
Batch 39/64 loss: -2.032088279724121
Batch 40/64 loss: -2.1266183853149414
Batch 41/64 loss: -1.8631467819213867
Batch 42/64 loss: -1.9818248748779297
Batch 43/64 loss: -1.826375961303711
Batch 44/64 loss: -2.039565086364746
Batch 45/64 loss: -2.1661205291748047
Batch 46/64 loss: -2.086674690246582
Batch 47/64 loss: -1.30718994140625
Batch 48/64 loss: -2.1414575576782227
Batch 49/64 loss: -2.219667434692383
Batch 50/64 loss: -1.5147638320922852
Batch 51/64 loss: -2.207693099975586
Batch 52/64 loss: -1.9953908920288086
Batch 53/64 loss: -2.1071529388427734
Batch 54/64 loss: -2.068246841430664
Batch 55/64 loss: -1.6483049392700195
Batch 56/64 loss: -2.2285919189453125
Batch 57/64 loss: -1.9122085571289062
Batch 58/64 loss: -2.022528648376465
Batch 59/64 loss: -2.1094188690185547
Batch 60/64 loss: -2.136026382446289
Batch 61/64 loss: -2.1604738235473633
Batch 62/64 loss: -1.7880220413208008
Batch 63/64 loss: -1.7711400985717773
Batch 64/64 loss: -6.051736354827881
Epoch 251  Train loss: -2.0407342892067106  Val loss: -2.305537535152894
Epoch 252
-------------------------------
Batch 1/64 loss: -2.2222442626953125
Batch 2/64 loss: -1.6917848587036133
Batch 3/64 loss: -2.072667121887207
Batch 4/64 loss: -2.0031747817993164
Batch 5/64 loss: -1.9466686248779297
Batch 6/64 loss: -2.0901527404785156
Batch 7/64 loss: -1.823014259338379
Batch 8/64 loss: -2.099154472351074
Batch 9/64 loss: -2.209604263305664
Batch 10/64 loss: -1.9776439666748047
Batch 11/64 loss: -2.0805320739746094
Batch 12/64 loss: -2.0862855911254883
Batch 13/64 loss: -2.099696159362793
Batch 14/64 loss: -2.1761932373046875
Batch 15/64 loss: -1.951462745666504
Batch 16/64 loss: -1.9044017791748047
Batch 17/64 loss: -2.137173652648926
Batch 18/64 loss: -2.162212371826172
Batch 19/64 loss: -1.865159034729004
Batch 20/64 loss: -2.1915831565856934
Batch 21/64 loss: -2.210564613342285
Batch 22/64 loss: -1.6731719970703125
Batch 23/64 loss: -1.9876785278320312
Batch 24/64 loss: -1.9333648681640625
Batch 25/64 loss: -1.6812076568603516
Batch 26/64 loss: -1.555191993713379
Batch 27/64 loss: -1.908609390258789
Batch 28/64 loss: -2.1467180252075195
Batch 29/64 loss: -2.096893310546875
Batch 30/64 loss: -2.155733108520508
Batch 31/64 loss: -1.8540334701538086
Batch 32/64 loss: -1.6830768585205078
Batch 33/64 loss: -1.994070053100586
Batch 34/64 loss: -1.9567184448242188
Batch 35/64 loss: -1.8865203857421875
Batch 36/64 loss: -2.1799793243408203
Batch 37/64 loss: -2.08413028717041
Batch 38/64 loss: -2.22359037399292
Batch 39/64 loss: -2.170172691345215
Batch 40/64 loss: -2.0696353912353516
Batch 41/64 loss: -1.7657337188720703
Batch 42/64 loss: -1.955510139465332
Batch 43/64 loss: -2.0476808547973633
Batch 44/64 loss: -1.9533271789550781
Batch 45/64 loss: -2.1655750274658203
Batch 46/64 loss: -2.320117473602295
Batch 47/64 loss: -1.9924793243408203
Batch 48/64 loss: -2.337780475616455
Batch 49/64 loss: -1.8568334579467773
Batch 50/64 loss: -2.067628860473633
Batch 51/64 loss: -2.13144588470459
Batch 52/64 loss: -1.9933080673217773
Batch 53/64 loss: -2.1815366744995117
Batch 54/64 loss: -2.330770492553711
Batch 55/64 loss: -1.6785097122192383
Batch 56/64 loss: -1.7168588638305664
Batch 57/64 loss: -2.3141427040100098
Batch 58/64 loss: -1.9565238952636719
Batch 59/64 loss: -2.078794479370117
Batch 60/64 loss: -2.2428131103515625
Batch 61/64 loss: -1.3323907852172852
Batch 62/64 loss: -2.1920547485351562
Batch 63/64 loss: -2.246227741241455
Batch 64/64 loss: -6.370851516723633
Epoch 252  Train loss: -2.068675329170975  Val loss: -2.334086362438923
Epoch 253
-------------------------------
Batch 1/64 loss: -2.0969057083129883
Batch 2/64 loss: -2.214818000793457
Batch 3/64 loss: -2.02927303314209
Batch 4/64 loss: -2.2689151763916016
Batch 5/64 loss: -2.224308967590332
Batch 6/64 loss: -1.6613655090332031
Batch 7/64 loss: -1.849442481994629
Batch 8/64 loss: -1.7401256561279297
Batch 9/64 loss: -2.2392029762268066
Batch 10/64 loss: -2.193068504333496
Batch 11/64 loss: -1.9252490997314453
Batch 12/64 loss: -2.2801380157470703
Batch 13/64 loss: -1.9533920288085938
Batch 14/64 loss: -2.095036506652832
Batch 15/64 loss: -2.1005916595458984
Batch 16/64 loss: -2.0779361724853516
Batch 17/64 loss: -2.15909481048584
Batch 18/64 loss: -2.051783561706543
Batch 19/64 loss: -2.0544614791870117
Batch 20/64 loss: -2.073641777038574
Batch 21/64 loss: -2.2337656021118164
Batch 22/64 loss: -1.9380922317504883
Batch 23/64 loss: -1.7398052215576172
Batch 24/64 loss: -1.9583768844604492
Batch 25/64 loss: -1.7947778701782227
Batch 26/64 loss: -2.1951828002929688
Batch 27/64 loss: -2.092820167541504
Batch 28/64 loss: -1.8116397857666016
Batch 29/64 loss: -2.0639076232910156
Batch 30/64 loss: -2.274970054626465
Batch 31/64 loss: -1.827836036682129
Batch 32/64 loss: -2.17415714263916
Batch 33/64 loss: -2.2620625495910645
Batch 34/64 loss: -1.9486780166625977
Batch 35/64 loss: -2.136263847351074
Batch 36/64 loss: -2.1554527282714844
Batch 37/64 loss: -1.9742622375488281
Batch 38/64 loss: -2.0726585388183594
Batch 39/64 loss: -1.9658937454223633
Batch 40/64 loss: -1.961073875427246
Batch 41/64 loss: -1.862234115600586
Batch 42/64 loss: -2.0355796813964844
Batch 43/64 loss: -1.7730093002319336
Batch 44/64 loss: -2.1822290420532227
Batch 45/64 loss: -1.9199256896972656
Batch 46/64 loss: -2.290956497192383
Batch 47/64 loss: -2.0423078536987305
Batch 48/64 loss: -2.1983861923217773
Batch 49/64 loss: -2.070619583129883
Batch 50/64 loss: -2.134746551513672
Batch 51/64 loss: -1.7709283828735352
Batch 52/64 loss: -2.047182083129883
Batch 53/64 loss: -2.231578826904297
Batch 54/64 loss: -2.157794952392578
Batch 55/64 loss: -2.221676826477051
Batch 56/64 loss: -2.073932647705078
Batch 57/64 loss: -1.8944330215454102
Batch 58/64 loss: -2.0102710723876953
Batch 59/64 loss: -1.6388025283813477
Batch 60/64 loss: -1.9396486282348633
Batch 61/64 loss: -2.1513671875
Batch 62/64 loss: -1.3496732711791992
Batch 63/64 loss: -2.1243534088134766
Batch 64/64 loss: -6.409932613372803
Epoch 253  Train loss: -2.0831296453288957  Val loss: -2.2969817590877364
Epoch 254
-------------------------------
Batch 1/64 loss: -2.0934839248657227
Batch 2/64 loss: -2.2975168228149414
Batch 3/64 loss: -2.1620311737060547
Batch 4/64 loss: -2.160304069519043
Batch 5/64 loss: -2.04030704498291
Batch 6/64 loss: -1.2545347213745117
Batch 7/64 loss: -2.272083282470703
Batch 8/64 loss: -2.098931312561035
Batch 9/64 loss: -1.8991146087646484
Batch 10/64 loss: -1.8414945602416992
Batch 11/64 loss: -2.218477249145508
Batch 12/64 loss: -2.2315378189086914
Batch 13/64 loss: -2.06613826751709
Batch 14/64 loss: -1.8650293350219727
Batch 15/64 loss: -2.1074295043945312
Batch 16/64 loss: -2.044757843017578
Batch 17/64 loss: -2.0773792266845703
Batch 18/64 loss: -1.6150445938110352
Batch 19/64 loss: -2.074557304382324
Batch 20/64 loss: -1.9256315231323242
Batch 21/64 loss: -1.8829841613769531
Batch 22/64 loss: -2.204193115234375
Batch 23/64 loss: -2.188213348388672
Batch 24/64 loss: -2.0477943420410156
Batch 25/64 loss: -2.098316192626953
Batch 26/64 loss: -2.041213035583496
Batch 27/64 loss: -2.331320285797119
Batch 28/64 loss: -2.199228286743164
Batch 29/64 loss: -2.295714855194092
Batch 30/64 loss: -2.2885475158691406
Batch 31/64 loss: -2.171499252319336
Batch 32/64 loss: -1.9439220428466797
Batch 33/64 loss: -2.044632911682129
Batch 34/64 loss: -2.2969155311584473
Batch 35/64 loss: -2.052785873413086
Batch 36/64 loss: -2.3387722969055176
Batch 37/64 loss: -2.2684812545776367
Batch 38/64 loss: -2.155097007751465
Batch 39/64 loss: -1.756662368774414
Batch 40/64 loss: -2.040989875793457
Batch 41/64 loss: -2.19431209564209
Batch 42/64 loss: -1.9641990661621094
Batch 43/64 loss: -1.9705820083618164
Batch 44/64 loss: -1.9953813552856445
Batch 45/64 loss: -1.7384958267211914
Batch 46/64 loss: -1.9898881912231445
Batch 47/64 loss: -2.109137535095215
Batch 48/64 loss: -2.1523609161376953
Batch 49/64 loss: -2.1273651123046875
Batch 50/64 loss: -2.242464065551758
Batch 51/64 loss: -2.032815933227539
Batch 52/64 loss: -2.180750846862793
Batch 53/64 loss: -2.3672776222229004
Batch 54/64 loss: -2.153902053833008
Batch 55/64 loss: -2.2750401496887207
Batch 56/64 loss: -2.016879081726074
Batch 57/64 loss: -2.2117204666137695
Batch 58/64 loss: -2.1808671951293945
Batch 59/64 loss: -2.141507148742676
Batch 60/64 loss: -1.509993553161621
Batch 61/64 loss: -2.326707363128662
Batch 62/64 loss: -1.9907426834106445
Batch 63/64 loss: -2.408379554748535
Batch 64/64 loss: -6.170698165893555
Epoch 254  Train loss: -2.1317939010320925  Val loss: -2.487076080951494
Saving best model, epoch: 254
Epoch 255
-------------------------------
Batch 1/64 loss: -2.1852941513061523
Batch 2/64 loss: -2.2153425216674805
Batch 3/64 loss: -2.2316675186157227
Batch 4/64 loss: -2.113168716430664
Batch 5/64 loss: -1.9065179824829102
Batch 6/64 loss: -2.215974807739258
Batch 7/64 loss: -2.1418771743774414
Batch 8/64 loss: -1.9489927291870117
Batch 9/64 loss: -1.9698772430419922
Batch 10/64 loss: -2.222879409790039
Batch 11/64 loss: -2.0349016189575195
Batch 12/64 loss: -2.1823158264160156
Batch 13/64 loss: -1.9770708084106445
Batch 14/64 loss: -2.2239294052124023
Batch 15/64 loss: -2.2091312408447266
Batch 16/64 loss: -2.0751218795776367
Batch 17/64 loss: -2.2630977630615234
Batch 18/64 loss: -1.9898109436035156
Batch 19/64 loss: -2.1333189010620117
Batch 20/64 loss: -1.9220600128173828
Batch 21/64 loss: -2.1289072036743164
Batch 22/64 loss: -1.8538646697998047
Batch 23/64 loss: -2.176849365234375
Batch 24/64 loss: -2.0229673385620117
Batch 25/64 loss: -2.0983190536499023
Batch 26/64 loss: -1.4681396484375
Batch 27/64 loss: -2.2739953994750977
Batch 28/64 loss: -2.144160270690918
Batch 29/64 loss: -2.1022558212280273
Batch 30/64 loss: -1.9454002380371094
Batch 31/64 loss: -1.4881963729858398
Batch 32/64 loss: -2.2833962440490723
Batch 33/64 loss: -2.2277631759643555
Batch 34/64 loss: -2.372897148132324
Batch 35/64 loss: -1.9321069717407227
Batch 36/64 loss: -2.0250463485717773
Batch 37/64 loss: -2.153988838195801
Batch 38/64 loss: -2.4081578254699707
Batch 39/64 loss: -2.2800464630126953
Batch 40/64 loss: -2.404893398284912
Batch 41/64 loss: -2.276947021484375
Batch 42/64 loss: -1.8665571212768555
Batch 43/64 loss: -2.177854537963867
Batch 44/64 loss: -2.152332305908203
Batch 45/64 loss: -2.0902538299560547
Batch 46/64 loss: -2.1371355056762695
Batch 47/64 loss: -1.9932861328125
Batch 48/64 loss: -1.9699792861938477
Batch 49/64 loss: -2.071992874145508
Batch 50/64 loss: -2.228022575378418
Batch 51/64 loss: -2.2351226806640625
Batch 52/64 loss: -2.074713706970215
Batch 53/64 loss: -1.7979860305786133
Batch 54/64 loss: -2.190922737121582
Batch 55/64 loss: -2.0475521087646484
Batch 56/64 loss: -1.4417972564697266
Batch 57/64 loss: -2.0450267791748047
Batch 58/64 loss: -2.1423282623291016
Batch 59/64 loss: -2.1847877502441406
Batch 60/64 loss: -2.0817527770996094
Batch 61/64 loss: -2.232891082763672
Batch 62/64 loss: -2.2589969635009766
Batch 63/64 loss: -2.209829330444336
Batch 64/64 loss: -6.204720497131348
Epoch 255  Train loss: -2.141416650659898  Val loss: -2.400819562145115
Epoch 256
-------------------------------
Batch 1/64 loss: -2.01633358001709
Batch 2/64 loss: -2.1814756393432617
Batch 3/64 loss: -2.3370485305786133
Batch 4/64 loss: -2.178516387939453
Batch 5/64 loss: -2.182435989379883
Batch 6/64 loss: -2.1021108627319336
Batch 7/64 loss: -1.9410572052001953
Batch 8/64 loss: -2.1153202056884766
Batch 9/64 loss: -2.125272750854492
Batch 10/64 loss: -1.9979524612426758
Batch 11/64 loss: -2.153165817260742
Batch 12/64 loss: -2.2498693466186523
Batch 13/64 loss: -2.1011409759521484
Batch 14/64 loss: -2.1399478912353516
Batch 15/64 loss: -2.0970163345336914
Batch 16/64 loss: -2.150503158569336
Batch 17/64 loss: -2.019639015197754
Batch 18/64 loss: -2.206338882446289
Batch 19/64 loss: -2.015125274658203
Batch 20/64 loss: -2.2986321449279785
Batch 21/64 loss: -2.1120996475219727
Batch 22/64 loss: -2.0641050338745117
Batch 23/64 loss: -2.2937521934509277
Batch 24/64 loss: -1.8746099472045898
Batch 25/64 loss: -2.287689208984375
Batch 26/64 loss: -2.038161277770996
Batch 27/64 loss: -2.251983642578125
Batch 28/64 loss: -1.1925745010375977
Batch 29/64 loss: -1.2673587799072266
Batch 30/64 loss: -2.274609088897705
Batch 31/64 loss: -2.101963996887207
Batch 32/64 loss: -2.050997734069824
Batch 33/64 loss: -2.043210983276367
Batch 34/64 loss: -1.0649595260620117
Batch 35/64 loss: -1.9753170013427734
Batch 36/64 loss: -1.7048397064208984
Batch 37/64 loss: -2.2266998291015625
Batch 38/64 loss: -2.1608896255493164
Batch 39/64 loss: -1.99298095703125
Batch 40/64 loss: -1.265070915222168
Batch 41/64 loss: -1.9277162551879883
Batch 42/64 loss: -2.1390867233276367
Batch 43/64 loss: -2.095953941345215
Batch 44/64 loss: -1.855423927307129
Batch 45/64 loss: -1.623504638671875
Batch 46/64 loss: -2.3414149284362793
Batch 47/64 loss: -1.9686212539672852
Batch 48/64 loss: -2.116352081298828
Batch 49/64 loss: -2.0800485610961914
Batch 50/64 loss: -2.1178369522094727
Batch 51/64 loss: -1.1755504608154297
Batch 52/64 loss: -1.7391328811645508
Batch 53/64 loss: -2.0150699615478516
Batch 54/64 loss: -1.851715087890625
Batch 55/64 loss: -1.4083032608032227
Batch 56/64 loss: -2.0299272537231445
Batch 57/64 loss: -2.138962745666504
Batch 58/64 loss: -2.3955941200256348
Batch 59/64 loss: -2.0991153717041016
Batch 60/64 loss: -2.2716708183288574
Batch 61/64 loss: -2.084200859069824
Batch 62/64 loss: -2.301999092102051
Batch 63/64 loss: -2.263157367706299
Batch 64/64 loss: -6.290317535400391
Epoch 256  Train loss: -2.0644842783610025  Val loss: -2.407784373489852
Epoch 257
-------------------------------
Batch 1/64 loss: -2.3000059127807617
Batch 2/64 loss: -2.2403106689453125
Batch 3/64 loss: -2.3257007598876953
Batch 4/64 loss: -2.2827906608581543
Batch 5/64 loss: -1.8468084335327148
Batch 6/64 loss: -1.7663116455078125
Batch 7/64 loss: -2.2471389770507812
Batch 8/64 loss: -1.8852424621582031
Batch 9/64 loss: -1.3759775161743164
Batch 10/64 loss: -2.397738456726074
Batch 11/64 loss: -1.9964160919189453
Batch 12/64 loss: -2.265702247619629
Batch 13/64 loss: -2.099350929260254
Batch 14/64 loss: -1.4035091400146484
Batch 15/64 loss: -1.885014533996582
Batch 16/64 loss: -2.132780075073242
Batch 17/64 loss: -2.2302017211914062
Batch 18/64 loss: -2.05557918548584
Batch 19/64 loss: -1.9102668762207031
Batch 20/64 loss: -2.1349945068359375
Batch 21/64 loss: -2.155855178833008
Batch 22/64 loss: -1.097346305847168
Batch 23/64 loss: -2.2093353271484375
Batch 24/64 loss: -2.2954869270324707
Batch 25/64 loss: -1.897064208984375
Batch 26/64 loss: -2.0901641845703125
Batch 27/64 loss: -2.0124893188476562
Batch 28/64 loss: -2.208005905151367
Batch 29/64 loss: -2.045146942138672
Batch 30/64 loss: -2.2060775756835938
Batch 31/64 loss: -1.4413347244262695
Batch 32/64 loss: -2.2788443565368652
Batch 33/64 loss: -2.199502944946289
Batch 34/64 loss: -2.2248830795288086
Batch 35/64 loss: -2.041872024536133
Batch 36/64 loss: -1.645543098449707
Batch 37/64 loss: -2.046468734741211
Batch 38/64 loss: -2.3205366134643555
Batch 39/64 loss: -2.240015983581543
Batch 40/64 loss: -2.18387508392334
Batch 41/64 loss: -2.0033493041992188
Batch 42/64 loss: -2.0632734298706055
Batch 43/64 loss: -2.2538747787475586
Batch 44/64 loss: -2.1919660568237305
Batch 45/64 loss: -2.272833824157715
Batch 46/64 loss: -2.0670509338378906
Batch 47/64 loss: -1.7984142303466797
Batch 48/64 loss: -2.083456039428711
Batch 49/64 loss: -1.730276107788086
Batch 50/64 loss: -1.7155275344848633
Batch 51/64 loss: -2.21073055267334
Batch 52/64 loss: -1.5187854766845703
Batch 53/64 loss: -1.9673395156860352
Batch 54/64 loss: -2.2741851806640625
Batch 55/64 loss: -2.2820658683776855
Batch 56/64 loss: -2.2356910705566406
Batch 57/64 loss: -2.1341161727905273
Batch 58/64 loss: -2.3100404739379883
Batch 59/64 loss: -2.2107505798339844
Batch 60/64 loss: -2.281587600708008
Batch 61/64 loss: -2.293065071105957
Batch 62/64 loss: -2.342020034790039
Batch 63/64 loss: -1.984872817993164
Batch 64/64 loss: -6.386347770690918
Epoch 257  Train loss: -2.1119485929900526  Val loss: -2.4557428523846916
Epoch 258
-------------------------------
Batch 1/64 loss: -1.8835296630859375
Batch 2/64 loss: -2.21457576751709
Batch 3/64 loss: -1.9560813903808594
Batch 4/64 loss: -2.311896324157715
Batch 5/64 loss: -2.4137954711914062
Batch 6/64 loss: -1.5921058654785156
Batch 7/64 loss: -2.1567134857177734
Batch 8/64 loss: -2.1538639068603516
Batch 9/64 loss: -2.136402130126953
Batch 10/64 loss: -2.2613887786865234
Batch 11/64 loss: -2.126950263977051
Batch 12/64 loss: -2.114762306213379
Batch 13/64 loss: -2.131214141845703
Batch 14/64 loss: -2.0299692153930664
Batch 15/64 loss: -2.0220346450805664
Batch 16/64 loss: -2.292348861694336
Batch 17/64 loss: -1.3628301620483398
Batch 18/64 loss: -2.221038818359375
Batch 19/64 loss: -2.2157936096191406
Batch 20/64 loss: -2.2865166664123535
Batch 21/64 loss: -2.3691744804382324
Batch 22/64 loss: -2.130605697631836
Batch 23/64 loss: -2.2569808959960938
Batch 24/64 loss: -1.625138282775879
Batch 25/64 loss: -2.2168989181518555
Batch 26/64 loss: -2.000483512878418
Batch 27/64 loss: -2.1338376998901367
Batch 28/64 loss: -1.803680419921875
Batch 29/64 loss: -2.309732437133789
Batch 30/64 loss: -2.099186897277832
Batch 31/64 loss: -1.8276786804199219
Batch 32/64 loss: -2.154376983642578
Batch 33/64 loss: -1.9867286682128906
Batch 34/64 loss: -2.085214614868164
Batch 35/64 loss: -2.1394386291503906
Batch 36/64 loss: -1.253030776977539
Batch 37/64 loss: -2.0640792846679688
Batch 38/64 loss: -1.7488508224487305
Batch 39/64 loss: -2.046116828918457
Batch 40/64 loss: -2.139248847961426
Batch 41/64 loss: -1.923440933227539
Batch 42/64 loss: -1.995011329650879
Batch 43/64 loss: -2.1334972381591797
Batch 44/64 loss: -1.8221778869628906
Batch 45/64 loss: -2.0293521881103516
Batch 46/64 loss: -1.943446159362793
Batch 47/64 loss: -2.093364715576172
Batch 48/64 loss: -2.10506534576416
Batch 49/64 loss: -2.0830068588256836
Batch 50/64 loss: -1.9819746017456055
Batch 51/64 loss: -2.1162185668945312
Batch 52/64 loss: -2.1167850494384766
Batch 53/64 loss: -1.960444450378418
Batch 54/64 loss: -2.2433414459228516
Batch 55/64 loss: -2.015547752380371
Batch 56/64 loss: -1.6961135864257812
Batch 57/64 loss: -2.213784694671631
Batch 58/64 loss: -1.8536005020141602
Batch 59/64 loss: -2.131824493408203
Batch 60/64 loss: -2.014481544494629
Batch 61/64 loss: -2.1295413970947266
Batch 62/64 loss: -1.9892044067382812
Batch 63/64 loss: -2.157315254211426
Batch 64/64 loss: -6.111489295959473
Epoch 258  Train loss: -2.0957874859080596  Val loss: -2.3424169402761557
Epoch 259
-------------------------------
Batch 1/64 loss: -1.9410371780395508
Batch 2/64 loss: -2.1394901275634766
Batch 3/64 loss: -2.2223024368286133
Batch 4/64 loss: -1.617569923400879
Batch 5/64 loss: -2.173356056213379
Batch 6/64 loss: -1.7451896667480469
Batch 7/64 loss: -2.2782716751098633
Batch 8/64 loss: -2.0262680053710938
Batch 9/64 loss: -1.9235143661499023
Batch 10/64 loss: -2.185243606567383
Batch 11/64 loss: -1.9130048751831055
Batch 12/64 loss: -1.3662605285644531
Batch 13/64 loss: -2.2245426177978516
Batch 14/64 loss: -1.804844856262207
Batch 15/64 loss: -2.011301040649414
Batch 16/64 loss: -1.9193191528320312
Batch 17/64 loss: -2.096236228942871
Batch 18/64 loss: -1.8472652435302734
Batch 19/64 loss: -1.9739761352539062
Batch 20/64 loss: -1.8976240158081055
Batch 21/64 loss: -1.993438720703125
Batch 22/64 loss: -1.9986085891723633
Batch 23/64 loss: -1.7113275527954102
Batch 24/64 loss: -2.1048336029052734
Batch 25/64 loss: -1.9513778686523438
Batch 26/64 loss: -1.6826553344726562
Batch 27/64 loss: -2.1367626190185547
Batch 28/64 loss: -2.002293586730957
Batch 29/64 loss: -1.9098024368286133
Batch 30/64 loss: -1.7868480682373047
Batch 31/64 loss: -2.014608383178711
Batch 32/64 loss: -2.0736923217773438
Batch 33/64 loss: -1.619948387145996
Batch 34/64 loss: -1.8977117538452148
Batch 35/64 loss: -1.0395517349243164
Batch 36/64 loss: -1.8431148529052734
Batch 37/64 loss: -2.1360855102539062
Batch 38/64 loss: -1.5338506698608398
Batch 39/64 loss: -1.7670354843139648
Batch 40/64 loss: -2.010483741760254
Batch 41/64 loss: -2.0707311630249023
Batch 42/64 loss: -1.7582340240478516
Batch 43/64 loss: -1.9829120635986328
Batch 44/64 loss: -1.1236553192138672
Batch 45/64 loss: -2.197506904602051
Batch 46/64 loss: -2.088717460632324
Batch 47/64 loss: -2.0801820755004883
Batch 48/64 loss: -2.0942983627319336
Batch 49/64 loss: -2.081369400024414
Batch 50/64 loss: -1.8949756622314453
Batch 51/64 loss: -2.1348400115966797
Batch 52/64 loss: -1.9490928649902344
Batch 53/64 loss: -1.9067792892456055
Batch 54/64 loss: -1.770817756652832
Batch 55/64 loss: -2.147279739379883
Batch 56/64 loss: -2.046627998352051
Batch 57/64 loss: -1.9472885131835938
Batch 58/64 loss: -1.9914989471435547
Batch 59/64 loss: -1.867671012878418
Batch 60/64 loss: -2.116912841796875
Batch 61/64 loss: -1.9349088668823242
Batch 62/64 loss: -2.1535863876342773
Batch 63/64 loss: -2.241827964782715
Batch 64/64 loss: -6.44122314453125
Epoch 259  Train loss: -1.9911102893305759  Val loss: -2.216376314458159
Epoch 260
-------------------------------
Batch 1/64 loss: -1.842428207397461
Batch 2/64 loss: -2.083559036254883
Batch 3/64 loss: -2.0798234939575195
Batch 4/64 loss: -1.999312400817871
Batch 5/64 loss: -1.9975147247314453
Batch 6/64 loss: -2.065260887145996
Batch 7/64 loss: -1.9407987594604492
Batch 8/64 loss: -1.6100397109985352
Batch 9/64 loss: -2.137904167175293
Batch 10/64 loss: -1.709554672241211
Batch 11/64 loss: -2.0356826782226562
Batch 12/64 loss: -2.139089584350586
Batch 13/64 loss: -1.8776092529296875
Batch 14/64 loss: -1.6856298446655273
Batch 15/64 loss: -1.7203092575073242
Batch 16/64 loss: -2.005880355834961
Batch 17/64 loss: -1.9592885971069336
Batch 18/64 loss: -1.609663963317871
Batch 19/64 loss: -2.189150810241699
Batch 20/64 loss: -1.9236173629760742
Batch 21/64 loss: -2.1140613555908203
Batch 22/64 loss: -1.7924938201904297
Batch 23/64 loss: -2.0726490020751953
Batch 24/64 loss: -1.8363819122314453
Batch 25/64 loss: -1.9894351959228516
Batch 26/64 loss: -2.1664209365844727
Batch 27/64 loss: -1.8381872177124023
Batch 28/64 loss: -1.6422615051269531
Batch 29/64 loss: -1.8687877655029297
Batch 30/64 loss: -2.0146446228027344
Batch 31/64 loss: -2.104355812072754
Batch 32/64 loss: -2.2483654022216797
Batch 33/64 loss: -1.8871278762817383
Batch 34/64 loss: -2.139388084411621
Batch 35/64 loss: -2.1522445678710938
Batch 36/64 loss: -2.2146739959716797
Batch 37/64 loss: -1.5783796310424805
Batch 38/64 loss: -1.3817663192749023
Batch 39/64 loss: -2.110201835632324
Batch 40/64 loss: -1.9610347747802734
Batch 41/64 loss: -2.195094108581543
Batch 42/64 loss: -1.9900312423706055
Batch 43/64 loss: -2.1075305938720703
Batch 44/64 loss: -2.02323055267334
Batch 45/64 loss: -1.799027442932129
Batch 46/64 loss: -2.0166587829589844
Batch 47/64 loss: -1.5019750595092773
Batch 48/64 loss: -1.9907875061035156
Batch 49/64 loss: -2.007526397705078
Batch 50/64 loss: -1.7931156158447266
Batch 51/64 loss: -1.762700080871582
Batch 52/64 loss: -1.4294557571411133
Batch 53/64 loss: -2.1969385147094727
Batch 54/64 loss: -2.127504348754883
Batch 55/64 loss: -1.918813705444336
Batch 56/64 loss: -2.1080713272094727
Batch 57/64 loss: -1.8968639373779297
Batch 58/64 loss: -2.052257537841797
Batch 59/64 loss: -2.001173973083496
Batch 60/64 loss: -1.7439031600952148
Batch 61/64 loss: -2.0029802322387695
Batch 62/64 loss: -1.7802400588989258
Batch 63/64 loss: -1.9811134338378906
Batch 64/64 loss: -6.005266189575195
Epoch 260  Train loss: -1.986759567260742  Val loss: -2.0532067944503734
Epoch 261
-------------------------------
Batch 1/64 loss: -1.9500322341918945
Batch 2/64 loss: -1.767460823059082
Batch 3/64 loss: -1.6051721572875977
Batch 4/64 loss: -2.0559797286987305
Batch 5/64 loss: -2.181291103363037
Batch 6/64 loss: -1.950709342956543
Batch 7/64 loss: -2.0573225021362305
Batch 8/64 loss: -2.1422929763793945
Batch 9/64 loss: -2.047628402709961
Batch 10/64 loss: -2.157350540161133
Batch 11/64 loss: -2.083327293395996
Batch 12/64 loss: -2.213250160217285
Batch 13/64 loss: -2.0569400787353516
Batch 14/64 loss: -1.9328584671020508
Batch 15/64 loss: -1.6166000366210938
Batch 16/64 loss: -1.9708137512207031
Batch 17/64 loss: -1.9881219863891602
Batch 18/64 loss: -2.1311120986938477
Batch 19/64 loss: -1.8605098724365234
Batch 20/64 loss: -2.007823944091797
Batch 21/64 loss: -2.1204404830932617
Batch 22/64 loss: -2.042727470397949
Batch 23/64 loss: -1.7251310348510742
Batch 24/64 loss: -2.047663688659668
Batch 25/64 loss: -1.8391380310058594
Batch 26/64 loss: -1.357666015625
Batch 27/64 loss: -2.164181709289551
Batch 28/64 loss: -2.0562868118286133
Batch 29/64 loss: -1.8550662994384766
Batch 30/64 loss: -1.7009916305541992
Batch 31/64 loss: -1.9046754837036133
Batch 32/64 loss: -1.3174495697021484
Batch 33/64 loss: -2.098875045776367
Batch 34/64 loss: -2.0762577056884766
Batch 35/64 loss: -1.7196521759033203
Batch 36/64 loss: -1.9018144607543945
Batch 37/64 loss: -1.943974494934082
Batch 38/64 loss: -2.008908271789551
Batch 39/64 loss: -1.814988136291504
Batch 40/64 loss: -1.7884407043457031
Batch 41/64 loss: -1.9272289276123047
Batch 42/64 loss: -1.7280044555664062
Batch 43/64 loss: -2.2169909477233887
Batch 44/64 loss: -1.894331932067871
Batch 45/64 loss: -1.873208999633789
Batch 46/64 loss: -1.8034629821777344
Batch 47/64 loss: -1.8229503631591797
Batch 48/64 loss: -2.0030517578125
Batch 49/64 loss: -2.0442686080932617
Batch 50/64 loss: -1.913909912109375
Batch 51/64 loss: -1.398890495300293
Batch 52/64 loss: -2.028879165649414
Batch 53/64 loss: -1.8659248352050781
Batch 54/64 loss: -1.9836320877075195
Batch 55/64 loss: -1.8004512786865234
Batch 56/64 loss: -2.125687599182129
Batch 57/64 loss: -2.314493179321289
Batch 58/64 loss: -0.9345855712890625
Batch 59/64 loss: -1.989964485168457
Batch 60/64 loss: -2.0912952423095703
Batch 61/64 loss: -1.5760784149169922
Batch 62/64 loss: -2.1223955154418945
Batch 63/64 loss: -1.7325773239135742
Batch 64/64 loss: -6.179451942443848
Epoch 261  Train loss: -1.9621612511429132  Val loss: -2.274748117243711
Epoch 262
-------------------------------
Batch 1/64 loss: -2.145174026489258
Batch 2/64 loss: -1.8869285583496094
Batch 3/64 loss: -1.8541193008422852
Batch 4/64 loss: -2.0148658752441406
Batch 5/64 loss: -2.1634950637817383
Batch 6/64 loss: -2.1029281616210938
Batch 7/64 loss: -2.230318069458008
Batch 8/64 loss: -2.1870851516723633
Batch 9/64 loss: -2.03640079498291
Batch 10/64 loss: -1.6257257461547852
Batch 11/64 loss: -2.234800338745117
Batch 12/64 loss: -2.0796661376953125
Batch 13/64 loss: -1.268540382385254
Batch 14/64 loss: -2.1605329513549805
Batch 15/64 loss: -2.1341867446899414
Batch 16/64 loss: -1.9020767211914062
Batch 17/64 loss: -1.3333930969238281
Batch 18/64 loss: -2.02445125579834
Batch 19/64 loss: -1.9710807800292969
Batch 20/64 loss: -1.931666374206543
Batch 21/64 loss: -2.038167953491211
Batch 22/64 loss: -1.6806821823120117
Batch 23/64 loss: -2.1100940704345703
Batch 24/64 loss: -2.2195310592651367
Batch 25/64 loss: -2.245983123779297
Batch 26/64 loss: -1.612722396850586
Batch 27/64 loss: -2.089573860168457
Batch 28/64 loss: -2.2248783111572266
Batch 29/64 loss: -1.8934268951416016
Batch 30/64 loss: -1.54888916015625
Batch 31/64 loss: -2.1398134231567383
Batch 32/64 loss: -2.246295928955078
Batch 33/64 loss: -1.9136972427368164
Batch 34/64 loss: -1.799931526184082
Batch 35/64 loss: -1.9495906829833984
Batch 36/64 loss: -2.011397361755371
Batch 37/64 loss: -1.9149951934814453
Batch 38/64 loss: -2.144434928894043
Batch 39/64 loss: -1.2909431457519531
Batch 40/64 loss: -1.994093894958496
Batch 41/64 loss: -1.487548828125
Batch 42/64 loss: -1.0115022659301758
Batch 43/64 loss: -1.5123252868652344
Batch 44/64 loss: -1.6167325973510742
Batch 45/64 loss: -1.83050537109375
Batch 46/64 loss: -1.833033561706543
Batch 47/64 loss: -1.4965200424194336
Batch 48/64 loss: -1.886103630065918
Batch 49/64 loss: -1.892568588256836
Batch 50/64 loss: -1.9268569946289062
Batch 51/64 loss: -1.8157052993774414
Batch 52/64 loss: -2.07351016998291
Batch 53/64 loss: -1.90960693359375
Batch 54/64 loss: -2.090622901916504
Batch 55/64 loss: -1.9273157119750977
Batch 56/64 loss: -1.8984336853027344
Batch 57/64 loss: -1.6183576583862305
Batch 58/64 loss: -2.10593318939209
Batch 59/64 loss: -1.6505069732666016
Batch 60/64 loss: -2.0129013061523438
Batch 61/64 loss: -2.061145782470703
Batch 62/64 loss: -1.991745948791504
Batch 63/64 loss: -2.105149269104004
Batch 64/64 loss: -6.378839492797852
Epoch 262  Train loss: -1.9591425802193436  Val loss: -2.328796006559916
Epoch 263
-------------------------------
Batch 1/64 loss: -2.1332931518554688
Batch 2/64 loss: -1.8107109069824219
Batch 3/64 loss: -1.9147052764892578
Batch 4/64 loss: -2.2390952110290527
Batch 5/64 loss: -1.8154592514038086
Batch 6/64 loss: -2.0261077880859375
Batch 7/64 loss: -0.7530660629272461
Batch 8/64 loss: -2.270059585571289
Batch 9/64 loss: -1.854990005493164
Batch 10/64 loss: -2.010833740234375
Batch 11/64 loss: -2.105044364929199
Batch 12/64 loss: -2.1186904907226562
Batch 13/64 loss: -2.030148506164551
Batch 14/64 loss: -2.2942004203796387
Batch 15/64 loss: -1.985407829284668
Batch 16/64 loss: -1.795048713684082
Batch 17/64 loss: -2.0380859375
Batch 18/64 loss: -1.8173999786376953
Batch 19/64 loss: -1.7244863510131836
Batch 20/64 loss: -1.9987201690673828
Batch 21/64 loss: -1.9813346862792969
Batch 22/64 loss: -1.7834081649780273
Batch 23/64 loss: -1.9670782089233398
Batch 24/64 loss: -1.8883056640625
Batch 25/64 loss: -2.065105438232422
Batch 26/64 loss: -2.060018539428711
Batch 27/64 loss: -2.240126609802246
Batch 28/64 loss: -2.13702392578125
Batch 29/64 loss: -2.066431999206543
Batch 30/64 loss: -1.6983013153076172
Batch 31/64 loss: -2.2317323684692383
Batch 32/64 loss: -2.159780502319336
Batch 33/64 loss: -2.031275749206543
Batch 34/64 loss: -2.0929126739501953
Batch 35/64 loss: -2.0403308868408203
Batch 36/64 loss: -2.1371612548828125
Batch 37/64 loss: -1.5709915161132812
Batch 38/64 loss: -2.0262889862060547
Batch 39/64 loss: -2.145904541015625
Batch 40/64 loss: -2.121401786804199
Batch 41/64 loss: -2.2532424926757812
Batch 42/64 loss: -2.1966943740844727
Batch 43/64 loss: -2.1108341217041016
Batch 44/64 loss: -2.0279359817504883
Batch 45/64 loss: -2.0206966400146484
Batch 46/64 loss: -2.2983531951904297
Batch 47/64 loss: -1.70013427734375
Batch 48/64 loss: -2.007735252380371
Batch 49/64 loss: -2.12130069732666
Batch 50/64 loss: -1.9531049728393555
Batch 51/64 loss: -1.9941072463989258
Batch 52/64 loss: -2.161285400390625
Batch 53/64 loss: -2.1857194900512695
Batch 54/64 loss: -1.915318489074707
Batch 55/64 loss: -2.0083847045898438
Batch 56/64 loss: -2.166266441345215
Batch 57/64 loss: -2.131730079650879
Batch 58/64 loss: -2.0042200088500977
Batch 59/64 loss: -1.819936752319336
Batch 60/64 loss: -2.0807056427001953
Batch 61/64 loss: -1.9505348205566406
Batch 62/64 loss: -2.031355857849121
Batch 63/64 loss: -1.9239616394042969
Batch 64/64 loss: -5.542968273162842
Epoch 263  Train loss: -2.0455098563549567  Val loss: -2.343303811509175
Epoch 264
-------------------------------
Batch 1/64 loss: -2.1283340454101562
Batch 2/64 loss: -1.7418203353881836
Batch 3/64 loss: -2.1756906509399414
Batch 4/64 loss: -2.0833253860473633
Batch 5/64 loss: -2.005868911743164
Batch 6/64 loss: -2.1990232467651367
Batch 7/64 loss: -2.2595019340515137
Batch 8/64 loss: -1.902597427368164
Batch 9/64 loss: -1.9903364181518555
Batch 10/64 loss: -2.0478382110595703
Batch 11/64 loss: -2.189450263977051
Batch 12/64 loss: -2.1975297927856445
Batch 13/64 loss: -2.1028547286987305
Batch 14/64 loss: -1.9435539245605469
Batch 15/64 loss: -1.9802827835083008
Batch 16/64 loss: -1.6218891143798828
Batch 17/64 loss: -1.977823257446289
Batch 18/64 loss: -2.209026336669922
Batch 19/64 loss: -1.9142742156982422
Batch 20/64 loss: -2.0394601821899414
Batch 21/64 loss: -2.2397098541259766
Batch 22/64 loss: -1.099104881286621
Batch 23/64 loss: -2.121784210205078
Batch 24/64 loss: -1.8733530044555664
Batch 25/64 loss: -1.8879375457763672
Batch 26/64 loss: -1.875636100769043
Batch 27/64 loss: -2.018474578857422
Batch 28/64 loss: -2.04532527923584
Batch 29/64 loss: -1.4553442001342773
Batch 30/64 loss: -2.0869760513305664
Batch 31/64 loss: -2.162029266357422
Batch 32/64 loss: -1.9457159042358398
Batch 33/64 loss: -1.988865852355957
Batch 34/64 loss: -2.0424938201904297
Batch 35/64 loss: -1.666916847229004
Batch 36/64 loss: -1.479482650756836
Batch 37/64 loss: -1.8272075653076172
Batch 38/64 loss: -1.9244508743286133
Batch 39/64 loss: -1.3210411071777344
Batch 40/64 loss: -1.7621488571166992
Batch 41/64 loss: -2.055781364440918
Batch 42/64 loss: -1.8363428115844727
Batch 43/64 loss: -1.9427814483642578
Batch 44/64 loss: -1.973404884338379
Batch 45/64 loss: -2.221688747406006
Batch 46/64 loss: -1.864424705505371
Batch 47/64 loss: -2.0080127716064453
Batch 48/64 loss: -1.7161064147949219
Batch 49/64 loss: -1.7916975021362305
Batch 50/64 loss: -1.8480587005615234
Batch 51/64 loss: -1.8737678527832031
Batch 52/64 loss: -1.869485855102539
Batch 53/64 loss: -1.203481674194336
Batch 54/64 loss: -1.966522216796875
Batch 55/64 loss: -1.627263069152832
Batch 56/64 loss: -2.2623214721679688
Batch 57/64 loss: -1.6864395141601562
Batch 58/64 loss: -1.9935541152954102
Batch 59/64 loss: -1.802713394165039
Batch 60/64 loss: -1.7799968719482422
Batch 61/64 loss: -1.8828372955322266
Batch 62/64 loss: -1.8501701354980469
Batch 63/64 loss: -1.8734235763549805
Batch 64/64 loss: -6.130101203918457
Epoch 264  Train loss: -1.9617620692533606  Val loss: -2.1651147141079723
Epoch 265
-------------------------------
Batch 1/64 loss: -2.108579635620117
Batch 2/64 loss: -1.9412479400634766
Batch 3/64 loss: -2.1177635192871094
Batch 4/64 loss: -1.9604473114013672
Batch 5/64 loss: -2.1862316131591797
Batch 6/64 loss: -1.7264156341552734
Batch 7/64 loss: -1.7501001358032227
Batch 8/64 loss: -2.0412187576293945
Batch 9/64 loss: -1.985769271850586
Batch 10/64 loss: -1.7673053741455078
Batch 11/64 loss: -1.8608198165893555
Batch 12/64 loss: -1.8817644119262695
Batch 13/64 loss: -2.02974796295166
Batch 14/64 loss: -2.0561437606811523
Batch 15/64 loss: -2.097170829772949
Batch 16/64 loss: -2.209317207336426
Batch 17/64 loss: -2.085757255554199
Batch 18/64 loss: -1.6684598922729492
Batch 19/64 loss: -1.8498821258544922
Batch 20/64 loss: -1.710195541381836
Batch 21/64 loss: -2.0359268188476562
Batch 22/64 loss: -1.8655271530151367
Batch 23/64 loss: -1.979243278503418
Batch 24/64 loss: -1.9995574951171875
Batch 25/64 loss: -2.0380468368530273
Batch 26/64 loss: -1.9707880020141602
Batch 27/64 loss: -1.9558019638061523
Batch 28/64 loss: -1.973830223083496
Batch 29/64 loss: -1.7791948318481445
Batch 30/64 loss: -1.8130254745483398
Batch 31/64 loss: -2.05300235748291
Batch 32/64 loss: -2.271944999694824
Batch 33/64 loss: -2.2918667793273926
Batch 34/64 loss: -1.9569826126098633
Batch 35/64 loss: -2.172271728515625
Batch 36/64 loss: -1.048232078552246
Batch 37/64 loss: -2.0132837295532227
Batch 38/64 loss: -1.8770027160644531
Batch 39/64 loss: -1.80609130859375
Batch 40/64 loss: -2.1088743209838867
Batch 41/64 loss: -1.975881576538086
Batch 42/64 loss: -2.1812515258789062
Batch 43/64 loss: -2.0582275390625
Batch 44/64 loss: -1.9444694519042969
Batch 45/64 loss: -2.3140010833740234
Batch 46/64 loss: -2.008209228515625
Batch 47/64 loss: -2.103091239929199
Batch 48/64 loss: -2.171572685241699
Batch 49/64 loss: -2.320335865020752
Batch 50/64 loss: -2.2196903228759766
Batch 51/64 loss: -1.8009834289550781
Batch 52/64 loss: -2.062999725341797
Batch 53/64 loss: -1.910771369934082
Batch 54/64 loss: -1.7414236068725586
Batch 55/64 loss: -1.5932254791259766
Batch 56/64 loss: -2.1989355087280273
Batch 57/64 loss: -2.1740894317626953
Batch 58/64 loss: -1.3291549682617188
Batch 59/64 loss: -1.4714984893798828
Batch 60/64 loss: -2.07761287689209
Batch 61/64 loss: -2.079202651977539
Batch 62/64 loss: -2.1267528533935547
Batch 63/64 loss: -1.8963956832885742
Batch 64/64 loss: -6.163029193878174
Epoch 265  Train loss: -2.014539312848858  Val loss: -2.246820731670996
Epoch 266
-------------------------------
Batch 1/64 loss: -2.1980533599853516
Batch 2/64 loss: -1.8603897094726562
Batch 3/64 loss: -2.203568458557129
Batch 4/64 loss: -2.248171806335449
Batch 5/64 loss: -1.8306846618652344
Batch 6/64 loss: -2.2130861282348633
Batch 7/64 loss: -1.9193553924560547
Batch 8/64 loss: -2.195193290710449
Batch 9/64 loss: -1.9538345336914062
Batch 10/64 loss: -2.039112091064453
Batch 11/64 loss: -2.204479217529297
Batch 12/64 loss: -1.6741046905517578
Batch 13/64 loss: -2.124887466430664
Batch 14/64 loss: -2.1859359741210938
Batch 15/64 loss: -1.8814277648925781
Batch 16/64 loss: -1.8037853240966797
Batch 17/64 loss: -2.067708969116211
Batch 18/64 loss: -2.045384407043457
Batch 19/64 loss: -1.8499488830566406
Batch 20/64 loss: -1.9873237609863281
Batch 21/64 loss: -2.1209211349487305
Batch 22/64 loss: -1.9481306076049805
Batch 23/64 loss: -2.17710018157959
Batch 24/64 loss: -2.1066675186157227
Batch 25/64 loss: -2.123201370239258
Batch 26/64 loss: -1.849635124206543
Batch 27/64 loss: -2.2438173294067383
Batch 28/64 loss: -2.1505680084228516
Batch 29/64 loss: -2.1295042037963867
Batch 30/64 loss: -2.218576431274414
Batch 31/64 loss: -2.206557273864746
Batch 32/64 loss: -1.9197654724121094
Batch 33/64 loss: -1.8873462677001953
Batch 34/64 loss: -2.2059783935546875
Batch 35/64 loss: -2.179189682006836
Batch 36/64 loss: -2.036269187927246
Batch 37/64 loss: -1.4886360168457031
Batch 38/64 loss: -2.268634796142578
Batch 39/64 loss: -2.0415821075439453
Batch 40/64 loss: -2.0904226303100586
Batch 41/64 loss: -1.467996597290039
Batch 42/64 loss: -2.21041202545166
Batch 43/64 loss: -2.109147071838379
Batch 44/64 loss: -2.212407112121582
Batch 45/64 loss: -1.8205204010009766
Batch 46/64 loss: -2.0627641677856445
Batch 47/64 loss: -1.8766183853149414
Batch 48/64 loss: -1.9940853118896484
Batch 49/64 loss: -2.212409019470215
Batch 50/64 loss: -2.03817081451416
Batch 51/64 loss: -1.8928346633911133
Batch 52/64 loss: -1.577646255493164
Batch 53/64 loss: -2.036684989929199
Batch 54/64 loss: -2.198854446411133
Batch 55/64 loss: -2.221250534057617
Batch 56/64 loss: -1.437016487121582
Batch 57/64 loss: -1.9968748092651367
Batch 58/64 loss: -2.0808563232421875
Batch 59/64 loss: -1.981337547302246
Batch 60/64 loss: -2.082919120788574
Batch 61/64 loss: -2.3872900009155273
Batch 62/64 loss: -2.3092126846313477
Batch 63/64 loss: -2.2132797241210938
Batch 64/64 loss: -6.370536804199219
Epoch 266  Train loss: -2.0874891094132964  Val loss: -2.386345945273068
Epoch 267
-------------------------------
Batch 1/64 loss: -2.1421890258789062
Batch 2/64 loss: -2.0812463760375977
Batch 3/64 loss: -2.192951202392578
Batch 4/64 loss: -2.132992744445801
Batch 5/64 loss: -2.072977066040039
Batch 6/64 loss: -2.2326526641845703
Batch 7/64 loss: -2.126007080078125
Batch 8/64 loss: -2.1140317916870117
Batch 9/64 loss: -2.1982202529907227
Batch 10/64 loss: -2.1479225158691406
Batch 11/64 loss: -2.2515182495117188
Batch 12/64 loss: -2.2277450561523438
Batch 13/64 loss: -2.123340606689453
Batch 14/64 loss: -1.9203405380249023
Batch 15/64 loss: -2.213237762451172
Batch 16/64 loss: -2.1803693771362305
Batch 17/64 loss: -1.798065185546875
Batch 18/64 loss: -1.5260629653930664
Batch 19/64 loss: -2.2525033950805664
Batch 20/64 loss: -1.726837158203125
Batch 21/64 loss: -2.3839101791381836
Batch 22/64 loss: -1.9911298751831055
Batch 23/64 loss: -1.7825593948364258
Batch 24/64 loss: -1.8278217315673828
Batch 25/64 loss: -2.0035228729248047
Batch 26/64 loss: -2.0297365188598633
Batch 27/64 loss: -2.1663970947265625
Batch 28/64 loss: -1.9737157821655273
Batch 29/64 loss: -1.8337879180908203
Batch 30/64 loss: -2.050055503845215
Batch 31/64 loss: -1.856856346130371
Batch 32/64 loss: -1.6586990356445312
Batch 33/64 loss: -1.9945125579833984
Batch 34/64 loss: -2.0414657592773438
Batch 35/64 loss: -1.7948646545410156
Batch 36/64 loss: -2.0667924880981445
Batch 37/64 loss: -2.0714797973632812
Batch 38/64 loss: -1.6061410903930664
Batch 39/64 loss: -1.9625768661499023
Batch 40/64 loss: -1.7442922592163086
Batch 41/64 loss: -1.9057416915893555
Batch 42/64 loss: -1.0170955657958984
Batch 43/64 loss: -2.226954460144043
Batch 44/64 loss: -1.9054813385009766
Batch 45/64 loss: -2.1562929153442383
Batch 46/64 loss: -1.9842157363891602
Batch 47/64 loss: -1.8895416259765625
Batch 48/64 loss: -1.980879783630371
Batch 49/64 loss: -1.9425687789916992
Batch 50/64 loss: -2.046624183654785
Batch 51/64 loss: -1.8408203125
Batch 52/64 loss: -1.5896320343017578
Batch 53/64 loss: -1.9535465240478516
Batch 54/64 loss: -1.9427986145019531
Batch 55/64 loss: -1.908919334411621
Batch 56/64 loss: -1.3758172988891602
Batch 57/64 loss: -0.9462661743164062
Batch 58/64 loss: -1.7605371475219727
Batch 59/64 loss: -2.0571746826171875
Batch 60/64 loss: -1.2320728302001953
Batch 61/64 loss: -2.048908233642578
Batch 62/64 loss: -2.0229759216308594
Batch 63/64 loss: -2.2209672927856445
Batch 64/64 loss: -6.401035785675049
Epoch 267  Train loss: -1.9962060872246237  Val loss: -2.1067885566003546
Epoch 268
-------------------------------
Batch 1/64 loss: -1.95159912109375
Batch 2/64 loss: -2.09993839263916
Batch 3/64 loss: -2.2387681007385254
Batch 4/64 loss: -2.2316808700561523
Batch 5/64 loss: -2.0017471313476562
Batch 6/64 loss: -2.1640748977661133
Batch 7/64 loss: -1.8460941314697266
Batch 8/64 loss: -2.1640892028808594
Batch 9/64 loss: -2.1274900436401367
Batch 10/64 loss: -2.1851987838745117
Batch 11/64 loss: -1.121438980102539
Batch 12/64 loss: -1.6504430770874023
Batch 13/64 loss: -1.9805240631103516
Batch 14/64 loss: -1.4157896041870117
Batch 15/64 loss: -2.0712814331054688
Batch 16/64 loss: -2.1312828063964844
Batch 17/64 loss: -1.9475669860839844
Batch 18/64 loss: -2.148503303527832
Batch 19/64 loss: -1.8104286193847656
Batch 20/64 loss: -2.1282196044921875
Batch 21/64 loss: -1.7260370254516602
Batch 22/64 loss: -1.8648271560668945
Batch 23/64 loss: -2.056631088256836
Batch 24/64 loss: -2.1936683654785156
Batch 25/64 loss: -2.219602584838867
Batch 26/64 loss: -2.1200685501098633
Batch 27/64 loss: -2.2492618560791016
Batch 28/64 loss: -1.3978910446166992
Batch 29/64 loss: -1.868947982788086
Batch 30/64 loss: -1.9473657608032227
Batch 31/64 loss: -2.2459964752197266
Batch 32/64 loss: -2.076061248779297
Batch 33/64 loss: -1.5474777221679688
Batch 34/64 loss: -2.149168014526367
Batch 35/64 loss: -1.9313068389892578
Batch 36/64 loss: -2.0618534088134766
Batch 37/64 loss: -1.8207311630249023
Batch 38/64 loss: -2.0998401641845703
Batch 39/64 loss: -1.7797183990478516
Batch 40/64 loss: -2.125187873840332
Batch 41/64 loss: -1.9291067123413086
Batch 42/64 loss: -1.8350334167480469
Batch 43/64 loss: -2.1773719787597656
Batch 44/64 loss: -1.9296483993530273
Batch 45/64 loss: -2.2892656326293945
Batch 46/64 loss: -2.1429262161254883
Batch 47/64 loss: -1.8229608535766602
Batch 48/64 loss: -2.3192453384399414
Batch 49/64 loss: -2.1180992126464844
Batch 50/64 loss: -2.297809600830078
Batch 51/64 loss: -2.162360191345215
Batch 52/64 loss: -1.9746580123901367
Batch 53/64 loss: -2.04056453704834
Batch 54/64 loss: -1.5997276306152344
Batch 55/64 loss: -2.159724235534668
Batch 56/64 loss: -2.1356096267700195
Batch 57/64 loss: -2.0175533294677734
Batch 58/64 loss: -2.159242630004883
Batch 59/64 loss: -2.2621288299560547
Batch 60/64 loss: -1.9140710830688477
Batch 61/64 loss: -2.0084829330444336
Batch 62/64 loss: -2.119657516479492
Batch 63/64 loss: -2.034213066101074
Batch 64/64 loss: -5.876965045928955
Epoch 268  Train loss: -2.051058614020254  Val loss: -2.10730106314433
Epoch 269
-------------------------------
Batch 1/64 loss: -2.163106918334961
Batch 2/64 loss: -2.195713996887207
Batch 3/64 loss: -2.206700325012207
Batch 4/64 loss: -1.9621925354003906
Batch 5/64 loss: -2.0495405197143555
Batch 6/64 loss: -2.1368980407714844
Batch 7/64 loss: -2.0835952758789062
Batch 8/64 loss: -2.092616081237793
Batch 9/64 loss: -1.7997093200683594
Batch 10/64 loss: -1.7419357299804688
Batch 11/64 loss: -1.6930160522460938
Batch 12/64 loss: -2.026277542114258
Batch 13/64 loss: -2.153763771057129
Batch 14/64 loss: -1.7394371032714844
Batch 15/64 loss: -2.0538721084594727
Batch 16/64 loss: -2.1576900482177734
Batch 17/64 loss: -2.1372718811035156
Batch 18/64 loss: -2.079258918762207
Batch 19/64 loss: -1.9766778945922852
Batch 20/64 loss: -2.1698179244995117
Batch 21/64 loss: -2.0013809204101562
Batch 22/64 loss: -2.059568405151367
Batch 23/64 loss: -2.141864776611328
Batch 24/64 loss: -2.2999744415283203
Batch 25/64 loss: -2.142451286315918
Batch 26/64 loss: -1.2082653045654297
Batch 27/64 loss: -1.9503183364868164
Batch 28/64 loss: -2.067011833190918
Batch 29/64 loss: -2.0562314987182617
Batch 30/64 loss: -2.001091957092285
Batch 31/64 loss: -1.9768743515014648
Batch 32/64 loss: -1.9817590713500977
Batch 33/64 loss: -2.0312538146972656
Batch 34/64 loss: -1.9859142303466797
Batch 35/64 loss: -2.1021928787231445
Batch 36/64 loss: -2.079390525817871
Batch 37/64 loss: -1.9293088912963867
Batch 38/64 loss: -1.8919429779052734
Batch 39/64 loss: -2.2726402282714844
Batch 40/64 loss: -2.4132843017578125
Batch 41/64 loss: -2.287238121032715
Batch 42/64 loss: -2.2791900634765625
Batch 43/64 loss: -2.015687942504883
Batch 44/64 loss: -1.4612770080566406
Batch 45/64 loss: -1.3594427108764648
Batch 46/64 loss: -2.065993309020996
Batch 47/64 loss: -2.1599597930908203
Batch 48/64 loss: -1.5695524215698242
Batch 49/64 loss: -2.0461511611938477
Batch 50/64 loss: -2.085163116455078
Batch 51/64 loss: -2.357545852661133
Batch 52/64 loss: -0.49813175201416016
Batch 53/64 loss: -2.216012954711914
Batch 54/64 loss: -1.9684514999389648
Batch 55/64 loss: -2.225968360900879
Batch 56/64 loss: -2.0840959548950195
Batch 57/64 loss: -2.0352487564086914
Batch 58/64 loss: -2.20249080657959
Batch 59/64 loss: -2.14188289642334
Batch 60/64 loss: -2.033235549926758
Batch 61/64 loss: -1.6596498489379883
Batch 62/64 loss: -1.779709815979004
Batch 63/64 loss: -2.1452503204345703
Batch 64/64 loss: -5.714671611785889
Epoch 269  Train loss: -2.0419630705141554  Val loss: -2.3145812254181433
Epoch 270
-------------------------------
Batch 1/64 loss: -1.9880342483520508
Batch 2/64 loss: -2.1006898880004883
Batch 3/64 loss: -1.7694807052612305
Batch 4/64 loss: -2.189084053039551
Batch 5/64 loss: -1.8872442245483398
Batch 6/64 loss: -2.090423583984375
Batch 7/64 loss: -2.364405632019043
Batch 8/64 loss: -2.205930709838867
Batch 9/64 loss: -2.2693119049072266
Batch 10/64 loss: -2.3021621704101562
Batch 11/64 loss: -1.9079303741455078
Batch 12/64 loss: -2.027667999267578
Batch 13/64 loss: -2.2844343185424805
Batch 14/64 loss: -2.0932159423828125
Batch 15/64 loss: -1.968857765197754
Batch 16/64 loss: -2.12062931060791
Batch 17/64 loss: -1.9339513778686523
Batch 18/64 loss: -2.032735824584961
Batch 19/64 loss: -1.6006898880004883
Batch 20/64 loss: -2.23635196685791
Batch 21/64 loss: -1.218306541442871
Batch 22/64 loss: -2.011916160583496
Batch 23/64 loss: -1.713343620300293
Batch 24/64 loss: -1.5492372512817383
Batch 25/64 loss: -1.5673847198486328
Batch 26/64 loss: -2.0252037048339844
Batch 27/64 loss: -1.9918460845947266
Batch 28/64 loss: -2.0249481201171875
Batch 29/64 loss: -2.0687246322631836
Batch 30/64 loss: -2.1384782791137695
Batch 31/64 loss: -1.7631521224975586
Batch 32/64 loss: -2.137815475463867
Batch 33/64 loss: -2.0237903594970703
Batch 34/64 loss: -2.05013370513916
Batch 35/64 loss: -2.060518264770508
Batch 36/64 loss: -1.9994592666625977
Batch 37/64 loss: -2.099740982055664
Batch 38/64 loss: -1.979264259338379
Batch 39/64 loss: -2.210453987121582
Batch 40/64 loss: -2.0199851989746094
Batch 41/64 loss: -2.1018171310424805
Batch 42/64 loss: -2.2384910583496094
Batch 43/64 loss: -2.1614761352539062
Batch 44/64 loss: -2.2701172828674316
Batch 45/64 loss: -2.3643722534179688
Batch 46/64 loss: -2.1910476684570312
Batch 47/64 loss: -2.2419815063476562
Batch 48/64 loss: -2.259209632873535
Batch 49/64 loss: -2.138026237487793
Batch 50/64 loss: -1.192824363708496
Batch 51/64 loss: -2.2193775177001953
Batch 52/64 loss: -2.207676887512207
Batch 53/64 loss: -2.1671628952026367
Batch 54/64 loss: -2.248448371887207
Batch 55/64 loss: -2.158590316772461
Batch 56/64 loss: -1.9395341873168945
Batch 57/64 loss: -2.1856536865234375
Batch 58/64 loss: -2.136937141418457
Batch 59/64 loss: -1.9814891815185547
Batch 60/64 loss: -1.9222126007080078
Batch 61/64 loss: -2.205319404602051
Batch 62/64 loss: -2.02828311920166
Batch 63/64 loss: -2.048945426940918
Batch 64/64 loss: -6.348910808563232
Epoch 270  Train loss: -2.0925115566627652  Val loss: -2.3785137949940265
Epoch 271
-------------------------------
Batch 1/64 loss: -2.1155500411987305
Batch 2/64 loss: -2.1705188751220703
Batch 3/64 loss: -2.17099666595459
Batch 4/64 loss: -2.074944496154785
Batch 5/64 loss: -2.2642784118652344
Batch 6/64 loss: -2.184048652648926
Batch 7/64 loss: -1.969365119934082
Batch 8/64 loss: -2.139725685119629
Batch 9/64 loss: -1.9069719314575195
Batch 10/64 loss: -1.6938791275024414
Batch 11/64 loss: -2.0491104125976562
Batch 12/64 loss: -2.1394777297973633
Batch 13/64 loss: -1.7377185821533203
Batch 14/64 loss: -2.037982940673828
Batch 15/64 loss: -1.6946344375610352
Batch 16/64 loss: -1.4791765213012695
Batch 17/64 loss: -1.5428590774536133
Batch 18/64 loss: -1.4611167907714844
Batch 19/64 loss: -1.0014753341674805
Batch 20/64 loss: -0.8640823364257812
Batch 21/64 loss: -1.3205270767211914
Batch 22/64 loss: -1.2373428344726562
Batch 23/64 loss: -1.1355257034301758
Batch 24/64 loss: -1.0914630889892578
Batch 25/64 loss: -1.335310935974121
Batch 26/64 loss: -0.8252592086791992
Batch 27/64 loss: -0.7728967666625977
Batch 28/64 loss: -0.39179039001464844
Batch 29/64 loss: -1.253103256225586
Batch 30/64 loss: 0.5894622802734375
Batch 31/64 loss: -1.510279655456543
Batch 32/64 loss: -1.6663398742675781
Batch 33/64 loss: -1.567495346069336
Batch 34/64 loss: -0.8708992004394531
Batch 35/64 loss: -1.2764215469360352
Batch 36/64 loss: -1.5679349899291992
Batch 37/64 loss: -0.8795709609985352
Batch 38/64 loss: -1.4440326690673828
Batch 39/64 loss: -1.5063514709472656
Batch 40/64 loss: -1.4900903701782227
Batch 41/64 loss: -1.529129981994629
Batch 42/64 loss: -1.4223947525024414
Batch 43/64 loss: -1.386068344116211
Batch 44/64 loss: -1.6048660278320312
Batch 45/64 loss: -1.432875633239746
Batch 46/64 loss: -1.7765121459960938
Batch 47/64 loss: -1.767552375793457
Batch 48/64 loss: -1.8303213119506836
Batch 49/64 loss: -2.0386486053466797
Batch 50/64 loss: -1.660257339477539
Batch 51/64 loss: -1.6206789016723633
Batch 52/64 loss: -1.8791208267211914
Batch 53/64 loss: -1.2781610488891602
Batch 54/64 loss: -1.8136186599731445
Batch 55/64 loss: -1.8718843460083008
Batch 56/64 loss: -2.016385078430176
Batch 57/64 loss: -1.710057258605957
Batch 58/64 loss: -1.7805747985839844
Batch 59/64 loss: -1.856170654296875
Batch 60/64 loss: -2.0074644088745117
Batch 61/64 loss: -1.8862638473510742
Batch 62/64 loss: -0.9469747543334961
Batch 63/64 loss: -0.9466829299926758
Batch 64/64 loss: -6.159264087677002
Epoch 271  Train loss: -1.5989521307103773  Val loss: -2.0393163019029545
Epoch 272
-------------------------------
Batch 1/64 loss: -1.9274120330810547
Batch 2/64 loss: -2.0606679916381836
Batch 3/64 loss: -1.6510992050170898
Batch 4/64 loss: -1.2647066116333008
Batch 5/64 loss: -1.960287094116211
Batch 6/64 loss: -1.942866325378418
Batch 7/64 loss: -1.7015247344970703
Batch 8/64 loss: -1.9016714096069336
Batch 9/64 loss: -2.134341239929199
Batch 10/64 loss: -1.8890657424926758
Batch 11/64 loss: -1.86004638671875
Batch 12/64 loss: -2.0948848724365234
Batch 13/64 loss: -1.8177976608276367
Batch 14/64 loss: -1.152583122253418
Batch 15/64 loss: -1.7851448059082031
Batch 16/64 loss: -2.182262897491455
Batch 17/64 loss: -2.098529815673828
Batch 18/64 loss: -2.134876251220703
Batch 19/64 loss: -1.7348146438598633
Batch 20/64 loss: -1.6796808242797852
Batch 21/64 loss: -1.8120174407958984
Batch 22/64 loss: -1.1673355102539062
Batch 23/64 loss: -2.094247817993164
Batch 24/64 loss: -2.001582145690918
Batch 25/64 loss: -1.9730100631713867
Batch 26/64 loss: -1.118617057800293
Batch 27/64 loss: -1.7444887161254883
Batch 28/64 loss: -1.9146194458007812
Batch 29/64 loss: -2.082036018371582
Batch 30/64 loss: -1.984304428100586
Batch 31/64 loss: -2.1737279891967773
Batch 32/64 loss: -2.1296796798706055
Batch 33/64 loss: -2.074477195739746
Batch 34/64 loss: -1.6101551055908203
Batch 35/64 loss: -2.1230201721191406
Batch 36/64 loss: -1.9922122955322266
Batch 37/64 loss: -2.1000308990478516
Batch 38/64 loss: -1.9357852935791016
Batch 39/64 loss: -2.088393211364746
Batch 40/64 loss: -2.2329702377319336
Batch 41/64 loss: -1.732377052307129
Batch 42/64 loss: -2.234036445617676
Batch 43/64 loss: -1.8049345016479492
Batch 44/64 loss: -1.975081443786621
Batch 45/64 loss: -2.2499594688415527
Batch 46/64 loss: -2.1933741569519043
Batch 47/64 loss: -1.6308584213256836
Batch 48/64 loss: -1.5722427368164062
Batch 49/64 loss: -1.9027528762817383
Batch 50/64 loss: -2.0579004287719727
Batch 51/64 loss: -2.050135612487793
Batch 52/64 loss: -2.21614933013916
Batch 53/64 loss: -2.1357593536376953
Batch 54/64 loss: -2.116879463195801
Batch 55/64 loss: -1.5106658935546875
Batch 56/64 loss: -2.2288150787353516
Batch 57/64 loss: -2.1482810974121094
Batch 58/64 loss: -1.8563041687011719
Batch 59/64 loss: -2.0299243927001953
Batch 60/64 loss: -2.199185371398926
Batch 61/64 loss: -2.250168800354004
Batch 62/64 loss: -2.143596649169922
Batch 63/64 loss: -2.285573959350586
Batch 64/64 loss: -6.371469497680664
Epoch 272  Train loss: -1.9863613053864124  Val loss: -2.2595205536413028
Epoch 273
-------------------------------
Batch 1/64 loss: -2.1658267974853516
Batch 2/64 loss: -1.7965030670166016
Batch 3/64 loss: -2.1320505142211914
Batch 4/64 loss: -1.9488611221313477
Batch 5/64 loss: -2.0013160705566406
Batch 6/64 loss: -1.7532548904418945
Batch 7/64 loss: -2.2573986053466797
Batch 8/64 loss: -2.229045867919922
Batch 9/64 loss: -2.143509864807129
Batch 10/64 loss: -1.9561948776245117
Batch 11/64 loss: -2.1462039947509766
Batch 12/64 loss: -2.1235294342041016
Batch 13/64 loss: -2.1973047256469727
Batch 14/64 loss: -2.0259361267089844
Batch 15/64 loss: -2.211668014526367
Batch 16/64 loss: -2.2998504638671875
Batch 17/64 loss: -2.053694725036621
Batch 18/64 loss: -1.0394601821899414
Batch 19/64 loss: -1.987741470336914
Batch 20/64 loss: -2.015866279602051
Batch 21/64 loss: -1.4617738723754883
Batch 22/64 loss: -1.8435859680175781
Batch 23/64 loss: -2.1522741317749023
Batch 24/64 loss: -2.170063018798828
Batch 25/64 loss: -1.8262157440185547
Batch 26/64 loss: -1.9978256225585938
Batch 27/64 loss: -2.019198417663574
Batch 28/64 loss: -2.2290782928466797
Batch 29/64 loss: -1.9114360809326172
Batch 30/64 loss: -1.9976224899291992
Batch 31/64 loss: -2.0711841583251953
Batch 32/64 loss: -2.1851272583007812
Batch 33/64 loss: -2.224930763244629
Batch 34/64 loss: -2.2641191482543945
Batch 35/64 loss: -1.9261484146118164
Batch 36/64 loss: -2.116946220397949
Batch 37/64 loss: -1.9158334732055664
Batch 38/64 loss: -2.1109189987182617
Batch 39/64 loss: -2.0635719299316406
Batch 40/64 loss: -1.9809255599975586
Batch 41/64 loss: -1.9172039031982422
Batch 42/64 loss: -2.1150026321411133
Batch 43/64 loss: -2.106818199157715
Batch 44/64 loss: -1.6134395599365234
Batch 45/64 loss: -2.1889095306396484
Batch 46/64 loss: -2.1972923278808594
Batch 47/64 loss: -2.0247678756713867
Batch 48/64 loss: -1.9517974853515625
Batch 49/64 loss: -2.213742256164551
Batch 50/64 loss: -2.196152687072754
Batch 51/64 loss: -2.1496286392211914
Batch 52/64 loss: -2.14404296875
Batch 53/64 loss: -2.1639537811279297
Batch 54/64 loss: -2.0930328369140625
Batch 55/64 loss: -2.1856565475463867
Batch 56/64 loss: -2.0788326263427734
Batch 57/64 loss: -1.8984642028808594
Batch 58/64 loss: -2.1387176513671875
Batch 59/64 loss: -2.2412586212158203
Batch 60/64 loss: -1.5637998580932617
Batch 61/64 loss: -1.7319002151489258
Batch 62/64 loss: -1.9137611389160156
Batch 63/64 loss: -2.1255931854248047
Batch 64/64 loss: -5.847108840942383
Epoch 273  Train loss: -2.0751858355952244  Val loss: -2.10803264604811
Epoch 274
-------------------------------
Batch 1/64 loss: -1.832864761352539
Batch 2/64 loss: -1.9007539749145508
Batch 3/64 loss: -1.5077505111694336
Batch 4/64 loss: -1.9780950546264648
Batch 5/64 loss: -1.6818761825561523
Batch 6/64 loss: -1.9268321990966797
Batch 7/64 loss: -1.9859046936035156
Batch 8/64 loss: -2.0376977920532227
Batch 9/64 loss: -1.859212875366211
Batch 10/64 loss: -1.3571281433105469
Batch 11/64 loss: -1.9460620880126953
Batch 12/64 loss: -1.9685993194580078
Batch 13/64 loss: -1.9192161560058594
Batch 14/64 loss: -1.8486127853393555
Batch 15/64 loss: -2.1295013427734375
Batch 16/64 loss: -2.132200241088867
Batch 17/64 loss: -1.8302030563354492
Batch 18/64 loss: -1.9367589950561523
Batch 19/64 loss: -2.11557674407959
Batch 20/64 loss: -1.9200725555419922
Batch 21/64 loss: -1.6885013580322266
Batch 22/64 loss: -1.4922752380371094
Batch 23/64 loss: -2.210392951965332
Batch 24/64 loss: -2.2622756958007812
Batch 25/64 loss: -2.1820383071899414
Batch 26/64 loss: -2.28688907623291
Batch 27/64 loss: -1.873788833618164
Batch 28/64 loss: -1.8084344863891602
Batch 29/64 loss: -2.2368741035461426
Batch 30/64 loss: -2.289029121398926
Batch 31/64 loss: -2.211700439453125
Batch 32/64 loss: -2.1853466033935547
Batch 33/64 loss: -2.0610551834106445
Batch 34/64 loss: -2.0683107376098633
Batch 35/64 loss: -1.7460432052612305
Batch 36/64 loss: -1.0939550399780273
Batch 37/64 loss: -1.6332569122314453
Batch 38/64 loss: -2.293978214263916
Batch 39/64 loss: -1.2241878509521484
Batch 40/64 loss: -2.209188461303711
Batch 41/64 loss: -1.7871179580688477
Batch 42/64 loss: -2.131535530090332
Batch 43/64 loss: -2.109564781188965
Batch 44/64 loss: -1.5305070877075195
Batch 45/64 loss: -2.0873031616210938
Batch 46/64 loss: -2.187464714050293
Batch 47/64 loss: -2.050440788269043
Batch 48/64 loss: -2.0630178451538086
Batch 49/64 loss: -2.172013282775879
Batch 50/64 loss: -2.002682685852051
Batch 51/64 loss: -2.216824531555176
Batch 52/64 loss: -2.083319664001465
Batch 53/64 loss: -2.232362747192383
Batch 54/64 loss: -2.04949951171875
Batch 55/64 loss: -0.8835906982421875
Batch 56/64 loss: -1.990316390991211
Batch 57/64 loss: -2.1614255905151367
Batch 58/64 loss: -2.100529670715332
Batch 59/64 loss: -2.1109695434570312
Batch 60/64 loss: -1.4749641418457031
Batch 61/64 loss: -1.9426841735839844
Batch 62/64 loss: -1.7328414916992188
Batch 63/64 loss: -2.1555328369140625
Batch 64/64 loss: -6.176719665527344
Epoch 274  Train loss: -1.98841552734375  Val loss: -2.4540747285298874
Epoch 275
-------------------------------
Batch 1/64 loss: -2.088620185852051
Batch 2/64 loss: -1.8912954330444336
Batch 3/64 loss: -2.1353635787963867
Batch 4/64 loss: -2.2543420791625977
Batch 5/64 loss: -2.2517518997192383
Batch 6/64 loss: -2.1900434494018555
Batch 7/64 loss: -2.261516571044922
Batch 8/64 loss: -2.0706167221069336
Batch 9/64 loss: -1.9883737564086914
Batch 10/64 loss: -2.2588024139404297
Batch 11/64 loss: -2.1326160430908203
Batch 12/64 loss: -2.0511531829833984
Batch 13/64 loss: -2.141598701477051
Batch 14/64 loss: -2.134549140930176
Batch 15/64 loss: -1.9863691329956055
Batch 16/64 loss: -1.9733343124389648
Batch 17/64 loss: -1.6091680526733398
Batch 18/64 loss: -2.0267200469970703
Batch 19/64 loss: -2.067747116088867
Batch 20/64 loss: -1.865518569946289
Batch 21/64 loss: -2.008066177368164
Batch 22/64 loss: -1.5718860626220703
Batch 23/64 loss: -2.004317283630371
Batch 24/64 loss: -0.608036994934082
Batch 25/64 loss: -2.153177261352539
Batch 26/64 loss: -2.2956924438476562
Batch 27/64 loss: -2.222926139831543
Batch 28/64 loss: -2.155299186706543
Batch 29/64 loss: -1.7553319931030273
Batch 30/64 loss: -1.4188385009765625
Batch 31/64 loss: -2.160734176635742
Batch 32/64 loss: -2.0027084350585938
Batch 33/64 loss: -1.4004039764404297
Batch 34/64 loss: -2.2588539123535156
Batch 35/64 loss: -2.2852392196655273
Batch 36/64 loss: -1.9070405960083008
Batch 37/64 loss: -2.170299530029297
Batch 38/64 loss: -2.058131217956543
Batch 39/64 loss: -1.2236557006835938
Batch 40/64 loss: -2.1534223556518555
Batch 41/64 loss: -1.8306217193603516
Batch 42/64 loss: -2.1820993423461914
Batch 43/64 loss: -2.1579275131225586
Batch 44/64 loss: -1.998495101928711
Batch 45/64 loss: -1.9491033554077148
Batch 46/64 loss: -2.179680824279785
Batch 47/64 loss: -1.857553482055664
Batch 48/64 loss: -1.9120607376098633
Batch 49/64 loss: -2.2704548835754395
Batch 50/64 loss: -2.0798988342285156
Batch 51/64 loss: -2.2649097442626953
Batch 52/64 loss: -1.6286029815673828
Batch 53/64 loss: -2.2974462509155273
Batch 54/64 loss: -2.197376251220703
Batch 55/64 loss: -1.9747896194458008
Batch 56/64 loss: -1.820566177368164
Batch 57/64 loss: -2.2665629386901855
Batch 58/64 loss: -2.127285957336426
Batch 59/64 loss: -2.0204849243164062
Batch 60/64 loss: -1.925093650817871
Batch 61/64 loss: -2.1305627822875977
Batch 62/64 loss: -2.0545501708984375
Batch 63/64 loss: -2.0883350372314453
Batch 64/64 loss: -6.411974906921387
Epoch 275  Train loss: -2.058305961010503  Val loss: -2.3913232731245637
Epoch 276
-------------------------------
Batch 1/64 loss: -2.0734663009643555
Batch 2/64 loss: -2.1103506088256836
Batch 3/64 loss: -2.0247888565063477
Batch 4/64 loss: -2.174868583679199
Batch 5/64 loss: -2.211148262023926
Batch 6/64 loss: -1.8903083801269531
Batch 7/64 loss: -2.1295671463012695
Batch 8/64 loss: -2.1516075134277344
Batch 9/64 loss: -2.2882747650146484
Batch 10/64 loss: -2.349503993988037
Batch 11/64 loss: -2.0575084686279297
Batch 12/64 loss: -2.042325019836426
Batch 13/64 loss: -2.0859241485595703
Batch 14/64 loss: -2.0769662857055664
Batch 15/64 loss: -2.1985864639282227
Batch 16/64 loss: -2.089808464050293
Batch 17/64 loss: -2.191460609436035
Batch 18/64 loss: -2.0362396240234375
Batch 19/64 loss: -2.31198787689209
Batch 20/64 loss: -2.159426689147949
Batch 21/64 loss: -2.055543899536133
Batch 22/64 loss: -2.354198455810547
Batch 23/64 loss: -2.2763671875
Batch 24/64 loss: -1.905472755432129
Batch 25/64 loss: -2.119622230529785
Batch 26/64 loss: -2.021224021911621
Batch 27/64 loss: -2.140665054321289
Batch 28/64 loss: -2.037289619445801
Batch 29/64 loss: -2.0235538482666016
Batch 30/64 loss: -1.7928199768066406
Batch 31/64 loss: -2.2315855026245117
Batch 32/64 loss: -2.080129623413086
Batch 33/64 loss: -2.1045265197753906
Batch 34/64 loss: -2.051142692565918
Batch 35/64 loss: -2.1923980712890625
Batch 36/64 loss: -2.171144485473633
Batch 37/64 loss: -1.7559890747070312
Batch 38/64 loss: -2.0174779891967773
Batch 39/64 loss: -2.2309226989746094
Batch 40/64 loss: -1.514261245727539
Batch 41/64 loss: -1.607961654663086
Batch 42/64 loss: -2.0075464248657227
Batch 43/64 loss: -2.2623825073242188
Batch 44/64 loss: -2.1529388427734375
Batch 45/64 loss: -2.064192771911621
Batch 46/64 loss: -2.378040313720703
Batch 47/64 loss: -2.220844268798828
Batch 48/64 loss: -2.03273868560791
Batch 49/64 loss: -2.1224489212036133
Batch 50/64 loss: -2.1319122314453125
Batch 51/64 loss: -2.2524824142456055
Batch 52/64 loss: -2.3001108169555664
Batch 53/64 loss: -1.8223876953125
Batch 54/64 loss: -2.1355342864990234
Batch 55/64 loss: -2.029825210571289
Batch 56/64 loss: -2.3873543739318848
Batch 57/64 loss: -1.6683378219604492
Batch 58/64 loss: -1.3890094757080078
Batch 59/64 loss: -2.081064224243164
Batch 60/64 loss: -2.0791053771972656
Batch 61/64 loss: -1.9555072784423828
Batch 62/64 loss: -2.2604055404663086
Batch 63/64 loss: -2.257692337036133
Batch 64/64 loss: -6.104126930236816
Epoch 276  Train loss: -2.131896026461732  Val loss: -2.597410247907606
Saving best model, epoch: 276
Epoch 277
-------------------------------
Batch 1/64 loss: -2.2745895385742188
Batch 2/64 loss: -2.075007438659668
Batch 3/64 loss: -2.4123916625976562
Batch 4/64 loss: -2.1441030502319336
Batch 5/64 loss: -2.1115217208862305
Batch 6/64 loss: -2.096799850463867
Batch 7/64 loss: -2.146958351135254
Batch 8/64 loss: -2.224919319152832
Batch 9/64 loss: -1.5952062606811523
Batch 10/64 loss: -2.1609573364257812
Batch 11/64 loss: -2.3497142791748047
Batch 12/64 loss: -2.252903938293457
Batch 13/64 loss: -2.1250953674316406
Batch 14/64 loss: -1.889521598815918
Batch 15/64 loss: -2.3309407234191895
Batch 16/64 loss: -2.4126992225646973
Batch 17/64 loss: -2.252176284790039
Batch 18/64 loss: -2.1277036666870117
Batch 19/64 loss: -2.425088405609131
Batch 20/64 loss: -1.7545595169067383
Batch 21/64 loss: -2.024311065673828
Batch 22/64 loss: -2.408604145050049
Batch 23/64 loss: -2.238719940185547
Batch 24/64 loss: -2.4338669776916504
Batch 25/64 loss: -2.1346511840820312
Batch 26/64 loss: -2.342683792114258
Batch 27/64 loss: -2.3538427352905273
Batch 28/64 loss: -2.126002311706543
Batch 29/64 loss: -2.2361955642700195
Batch 30/64 loss: -1.9851055145263672
Batch 31/64 loss: -2.272372245788574
Batch 32/64 loss: -1.9735517501831055
Batch 33/64 loss: -2.0837841033935547
Batch 34/64 loss: -2.135354995727539
Batch 35/64 loss: -1.9493293762207031
Batch 36/64 loss: -1.9954967498779297
Batch 37/64 loss: -1.8716812133789062
Batch 38/64 loss: -2.2889976501464844
Batch 39/64 loss: -2.1014585494995117
Batch 40/64 loss: -2.0429983139038086
Batch 41/64 loss: -2.2879114151000977
Batch 42/64 loss: -2.169048309326172
Batch 43/64 loss: -1.6816139221191406
Batch 44/64 loss: -2.3257408142089844
Batch 45/64 loss: -2.009990692138672
Batch 46/64 loss: -2.2237348556518555
Batch 47/64 loss: -2.0610151290893555
Batch 48/64 loss: -2.102508544921875
Batch 49/64 loss: -1.9862871170043945
Batch 50/64 loss: -2.0710020065307617
Batch 51/64 loss: -2.2421207427978516
Batch 52/64 loss: -2.149807929992676
Batch 53/64 loss: -1.8205718994140625
Batch 54/64 loss: -2.063211441040039
Batch 55/64 loss: -2.013981819152832
Batch 56/64 loss: -1.8746337890625
Batch 57/64 loss: -2.138197898864746
Batch 58/64 loss: -1.9128828048706055
Batch 59/64 loss: -0.6056489944458008
Batch 60/64 loss: -2.0467042922973633
Batch 61/64 loss: -2.058873176574707
Batch 62/64 loss: -1.9633731842041016
Batch 63/64 loss: -2.1373538970947266
Batch 64/64 loss: -6.433793544769287
Epoch 277  Train loss: -2.1479753026775286  Val loss: -2.320819159963287
Epoch 278
-------------------------------
Batch 1/64 loss: -2.1214914321899414
Batch 2/64 loss: -2.0498600006103516
Batch 3/64 loss: -2.049196243286133
Batch 4/64 loss: -2.070134162902832
Batch 5/64 loss: -2.1265697479248047
Batch 6/64 loss: -1.6435422897338867
Batch 7/64 loss: -2.2571725845336914
Batch 8/64 loss: -2.0588178634643555
Batch 9/64 loss: -2.264883041381836
Batch 10/64 loss: -2.2779417037963867
Batch 11/64 loss: -2.0088577270507812
Batch 12/64 loss: -2.1619386672973633
Batch 13/64 loss: -1.911905288696289
Batch 14/64 loss: -2.0599308013916016
Batch 15/64 loss: -2.1917781829833984
Batch 16/64 loss: -2.1957759857177734
Batch 17/64 loss: -1.7118377685546875
Batch 18/64 loss: -2.4145126342773438
Batch 19/64 loss: -2.296769618988037
Batch 20/64 loss: -2.081754684448242
Batch 21/64 loss: -2.3456649780273438
Batch 22/64 loss: -1.2443227767944336
Batch 23/64 loss: -2.2983598709106445
Batch 24/64 loss: -2.1430511474609375
Batch 25/64 loss: -1.9206771850585938
Batch 26/64 loss: -1.9279632568359375
Batch 27/64 loss: -2.212294578552246
Batch 28/64 loss: -2.2147912979125977
Batch 29/64 loss: -2.012537956237793
Batch 30/64 loss: -2.077106475830078
Batch 31/64 loss: -2.0168581008911133
Batch 32/64 loss: -1.7820253372192383
Batch 33/64 loss: -1.7507362365722656
Batch 34/64 loss: -2.273731231689453
Batch 35/64 loss: -1.9484548568725586
Batch 36/64 loss: -1.7954320907592773
Batch 37/64 loss: -1.324376106262207
Batch 38/64 loss: -1.9024715423583984
Batch 39/64 loss: -1.9830045700073242
Batch 40/64 loss: -1.9545412063598633
Batch 41/64 loss: -1.5652055740356445
Batch 42/64 loss: -1.479945182800293
Batch 43/64 loss: -1.5083770751953125
Batch 44/64 loss: -2.084284782409668
Batch 45/64 loss: -1.8544378280639648
Batch 46/64 loss: -1.7888574600219727
Batch 47/64 loss: -1.9150705337524414
Batch 48/64 loss: -1.8813066482543945
Batch 49/64 loss: -2.176762580871582
Batch 50/64 loss: -2.140483856201172
Batch 51/64 loss: -1.6428642272949219
Batch 52/64 loss: -2.148548126220703
Batch 53/64 loss: -1.960677146911621
Batch 54/64 loss: -1.906966209411621
Batch 55/64 loss: -2.0402345657348633
Batch 56/64 loss: -2.021040916442871
Batch 57/64 loss: -1.1368827819824219
Batch 58/64 loss: -1.9250555038452148
Batch 59/64 loss: -1.965683937072754
Batch 60/64 loss: -2.1210336685180664
Batch 61/64 loss: -1.8952503204345703
Batch 62/64 loss: -2.0222091674804688
Batch 63/64 loss: -2.169833183288574
Batch 64/64 loss: -6.067148685455322
Epoch 278  Train loss: -2.0232853964263318  Val loss: -2.2753152880062353
Epoch 279
-------------------------------
Batch 1/64 loss: -1.8163471221923828
Batch 2/64 loss: -1.5142335891723633
Batch 3/64 loss: -1.5530567169189453
Batch 4/64 loss: -2.137948989868164
Batch 5/64 loss: -2.043440818786621
Batch 6/64 loss: -2.1423158645629883
Batch 7/64 loss: -1.7650470733642578
Batch 8/64 loss: -2.0144424438476562
Batch 9/64 loss: -2.0339183807373047
Batch 10/64 loss: -1.992452621459961
Batch 11/64 loss: -2.2004470825195312
Batch 12/64 loss: -2.0965471267700195
Batch 13/64 loss: -1.9613676071166992
Batch 14/64 loss: -2.1737747192382812
Batch 15/64 loss: -1.8924036026000977
Batch 16/64 loss: -1.7970142364501953
Batch 17/64 loss: -2.125762939453125
Batch 18/64 loss: -1.895193099975586
Batch 19/64 loss: -2.1766576766967773
Batch 20/64 loss: -1.930729866027832
Batch 21/64 loss: -1.7758426666259766
Batch 22/64 loss: -1.8531360626220703
Batch 23/64 loss: -1.8437471389770508
Batch 24/64 loss: -1.5872859954833984
Batch 25/64 loss: -1.9885244369506836
Batch 26/64 loss: -1.7037668228149414
Batch 27/64 loss: -1.7438478469848633
Batch 28/64 loss: -1.934861183166504
Batch 29/64 loss: -1.560013771057129
Batch 30/64 loss: -1.9957714080810547
Batch 31/64 loss: -2.1739959716796875
Batch 32/64 loss: -1.8788738250732422
Batch 33/64 loss: -1.591750144958496
Batch 34/64 loss: -1.585618019104004
Batch 35/64 loss: -2.0704431533813477
Batch 36/64 loss: -1.930257797241211
Batch 37/64 loss: -1.8801908493041992
Batch 38/64 loss: -2.154231071472168
Batch 39/64 loss: -2.070296287536621
Batch 40/64 loss: -1.9861860275268555
Batch 41/64 loss: -2.1232004165649414
Batch 42/64 loss: -2.048611640930176
Batch 43/64 loss: -2.065585136413574
Batch 44/64 loss: -1.9047212600708008
Batch 45/64 loss: -2.1017837524414062
Batch 46/64 loss: -2.181027412414551
Batch 47/64 loss: -1.8514270782470703
Batch 48/64 loss: -1.180826187133789
Batch 49/64 loss: -1.8146696090698242
Batch 50/64 loss: -1.9965934753417969
Batch 51/64 loss: -1.9108543395996094
Batch 52/64 loss: -1.9719743728637695
Batch 53/64 loss: -2.10178279876709
Batch 54/64 loss: -1.9593467712402344
Batch 55/64 loss: -1.9857053756713867
Batch 56/64 loss: -1.5852127075195312
Batch 57/64 loss: -2.2260074615478516
Batch 58/64 loss: -1.920741081237793
Batch 59/64 loss: -2.108652114868164
Batch 60/64 loss: -2.112926483154297
Batch 61/64 loss: -1.717360496520996
Batch 62/64 loss: -1.9906072616577148
Batch 63/64 loss: -1.1474390029907227
Batch 64/64 loss: -6.280234336853027
Epoch 279  Train loss: -1.9653172399483474  Val loss: -2.139853225131215
Epoch 280
-------------------------------
Batch 1/64 loss: -1.9903583526611328
Batch 2/64 loss: -2.120279312133789
Batch 3/64 loss: -2.156174659729004
Batch 4/64 loss: -1.8918800354003906
Batch 5/64 loss: -2.188483238220215
Batch 6/64 loss: -1.9201898574829102
Batch 7/64 loss: -1.550994873046875
Batch 8/64 loss: -1.8570976257324219
Batch 9/64 loss: -1.9087648391723633
Batch 10/64 loss: -2.022500991821289
Batch 11/64 loss: -1.9355087280273438
Batch 12/64 loss: -2.114919662475586
Batch 13/64 loss: -1.9484996795654297
Batch 14/64 loss: -1.8651561737060547
Batch 15/64 loss: -1.7581195831298828
Batch 16/64 loss: -1.6614198684692383
Batch 17/64 loss: -1.8969802856445312
Batch 18/64 loss: -1.1953659057617188
Batch 19/64 loss: -1.799769401550293
Batch 20/64 loss: -1.835158348083496
Batch 21/64 loss: -1.6421747207641602
Batch 22/64 loss: -2.027256965637207
Batch 23/64 loss: -1.555802345275879
Batch 24/64 loss: -1.9274578094482422
Batch 25/64 loss: -1.6436576843261719
Batch 26/64 loss: -1.4517993927001953
Batch 27/64 loss: -2.0010814666748047
Batch 28/64 loss: -1.3546810150146484
Batch 29/64 loss: -1.8886337280273438
Batch 30/64 loss: -2.0463056564331055
Batch 31/64 loss: -1.8228778839111328
Batch 32/64 loss: -1.4088687896728516
Batch 33/64 loss: -1.6377582550048828
Batch 34/64 loss: -1.9510517120361328
Batch 35/64 loss: -1.215261459350586
Batch 36/64 loss: -2.0929298400878906
Batch 37/64 loss: -1.579380989074707
Batch 38/64 loss: -1.4603242874145508
Batch 39/64 loss: 0.22126483917236328
Batch 40/64 loss: -1.665318489074707
Batch 41/64 loss: -1.7096319198608398
Batch 42/64 loss: -1.3251886367797852
Batch 43/64 loss: -1.3485946655273438
Batch 44/64 loss: -1.7054948806762695
Batch 45/64 loss: -1.3849315643310547
Batch 46/64 loss: -1.2967491149902344
Batch 47/64 loss: -1.676466941833496
Batch 48/64 loss: -1.6024513244628906
Batch 49/64 loss: -1.906229019165039
Batch 50/64 loss: -1.4262542724609375
Batch 51/64 loss: -1.4906435012817383
Batch 52/64 loss: -1.6328964233398438
Batch 53/64 loss: -2.0212860107421875
Batch 54/64 loss: -1.8940773010253906
Batch 55/64 loss: -1.658493995666504
Batch 56/64 loss: -1.9000244140625
Batch 57/64 loss: -1.8245019912719727
Batch 58/64 loss: -1.6871490478515625
Batch 59/64 loss: -2.1208810806274414
Batch 60/64 loss: -1.7954797744750977
Batch 61/64 loss: -1.26483154296875
Batch 62/64 loss: -1.7376327514648438
Batch 63/64 loss: -1.646061897277832
Batch 64/64 loss: -6.024540901184082
Epoch 280  Train loss: -1.762248420715332  Val loss: -1.7973455317651283
Epoch 281
-------------------------------
Batch 1/64 loss: -1.5681114196777344
Batch 2/64 loss: -1.9765958786010742
Batch 3/64 loss: -2.039468765258789
Batch 4/64 loss: -1.5363082885742188
Batch 5/64 loss: -1.8819599151611328
Batch 6/64 loss: -2.0625476837158203
Batch 7/64 loss: -1.6579914093017578
Batch 8/64 loss: -1.6836137771606445
Batch 9/64 loss: -1.998103141784668
Batch 10/64 loss: -1.966562271118164
Batch 11/64 loss: -1.6112289428710938
Batch 12/64 loss: -2.02493953704834
Batch 13/64 loss: -1.8667926788330078
Batch 14/64 loss: -1.144108772277832
Batch 15/64 loss: -1.9933290481567383
Batch 16/64 loss: -1.9069585800170898
Batch 17/64 loss: -1.8136405944824219
Batch 18/64 loss: -2.1007747650146484
Batch 19/64 loss: -2.06272029876709
Batch 20/64 loss: -1.2708234786987305
Batch 21/64 loss: -1.7379140853881836
Batch 22/64 loss: -1.8767595291137695
Batch 23/64 loss: -1.657400131225586
Batch 24/64 loss: -2.055124282836914
Batch 25/64 loss: -1.9746341705322266
Batch 26/64 loss: -1.8690252304077148
Batch 27/64 loss: -2.048323631286621
Batch 28/64 loss: -2.046510696411133
Batch 29/64 loss: -1.765512466430664
Batch 30/64 loss: -1.6048650741577148
Batch 31/64 loss: -0.7623395919799805
Batch 32/64 loss: -1.7911567687988281
Batch 33/64 loss: -2.1532506942749023
Batch 34/64 loss: -1.8783283233642578
Batch 35/64 loss: -2.1469802856445312
Batch 36/64 loss: -1.5718889236450195
Batch 37/64 loss: -1.9956989288330078
Batch 38/64 loss: -2.192098617553711
Batch 39/64 loss: -2.1623220443725586
Batch 40/64 loss: -2.0633296966552734
Batch 41/64 loss: -1.4211788177490234
Batch 42/64 loss: -1.477910041809082
Batch 43/64 loss: -1.7438631057739258
Batch 44/64 loss: -2.045574188232422
Batch 45/64 loss: -2.048276901245117
Batch 46/64 loss: -1.8590688705444336
Batch 47/64 loss: -2.0020627975463867
Batch 48/64 loss: -2.0854835510253906
Batch 49/64 loss: -1.223501205444336
Batch 50/64 loss: -1.5689496994018555
Batch 51/64 loss: -2.3198652267456055
Batch 52/64 loss: -2.0770511627197266
Batch 53/64 loss: -2.26999568939209
Batch 54/64 loss: -2.0905466079711914
Batch 55/64 loss: -2.0525026321411133
Batch 56/64 loss: -2.0907087326049805
Batch 57/64 loss: -1.940505027770996
Batch 58/64 loss: -1.9961977005004883
Batch 59/64 loss: -1.8031749725341797
Batch 60/64 loss: -1.8453264236450195
Batch 61/64 loss: -1.9350461959838867
Batch 62/64 loss: -2.219715118408203
Batch 63/64 loss: -1.904515266418457
Batch 64/64 loss: -6.134825706481934
Epoch 281  Train loss: -1.9159557903514188  Val loss: -2.3810569920490696
Epoch 282
-------------------------------
Batch 1/64 loss: -2.1345291137695312
Batch 2/64 loss: -2.2026844024658203
Batch 3/64 loss: -2.056807518005371
Batch 4/64 loss: -1.9569292068481445
Batch 5/64 loss: -2.027118682861328
Batch 6/64 loss: -2.026606559753418
Batch 7/64 loss: -1.6115312576293945
Batch 8/64 loss: -2.265101432800293
Batch 9/64 loss: -1.9328174591064453
Batch 10/64 loss: -1.764664649963379
Batch 11/64 loss: -1.9569196701049805
Batch 12/64 loss: -1.8812179565429688
Batch 13/64 loss: -1.6070451736450195
Batch 14/64 loss: -2.145437240600586
Batch 15/64 loss: -1.3899192810058594
Batch 16/64 loss: -1.7492303848266602
Batch 17/64 loss: -1.9363555908203125
Batch 18/64 loss: -1.6947154998779297
Batch 19/64 loss: -1.8722057342529297
Batch 20/64 loss: -1.5617609024047852
Batch 21/64 loss: -1.4864120483398438
Batch 22/64 loss: -1.862381935119629
Batch 23/64 loss: -2.0381784439086914
Batch 24/64 loss: -1.9461250305175781
Batch 25/64 loss: -2.024704933166504
Batch 26/64 loss: -1.7241325378417969
Batch 27/64 loss: -2.13962459564209
Batch 28/64 loss: -1.5112810134887695
Batch 29/64 loss: -1.7793922424316406
Batch 30/64 loss: -1.995957374572754
Batch 31/64 loss: -2.0157203674316406
Batch 32/64 loss: -2.0097131729125977
Batch 33/64 loss: -2.118271827697754
Batch 34/64 loss: -1.5364933013916016
Batch 35/64 loss: -1.789982795715332
Batch 36/64 loss: -1.8415412902832031
Batch 37/64 loss: -1.9735479354858398
Batch 38/64 loss: -1.8565788269042969
Batch 39/64 loss: -1.807281494140625
Batch 40/64 loss: -1.3890905380249023
Batch 41/64 loss: -0.9863433837890625
Batch 42/64 loss: -1.795928955078125
Batch 43/64 loss: -1.7300310134887695
Batch 44/64 loss: -1.861577033996582
Batch 45/64 loss: -1.1219062805175781
Batch 46/64 loss: -1.598750114440918
Batch 47/64 loss: -1.9678783416748047
Batch 48/64 loss: -1.3976526260375977
Batch 49/64 loss: -1.8435325622558594
Batch 50/64 loss: -1.9496955871582031
Batch 51/64 loss: -1.9832038879394531
Batch 52/64 loss: -1.6381092071533203
Batch 53/64 loss: -1.7608566284179688
Batch 54/64 loss: -2.056234359741211
Batch 55/64 loss: -1.6416006088256836
Batch 56/64 loss: -1.9009428024291992
Batch 57/64 loss: -1.9859685897827148
Batch 58/64 loss: -1.9433679580688477
Batch 59/64 loss: -1.0268182754516602
Batch 60/64 loss: -0.9203395843505859
Batch 61/64 loss: -1.6355695724487305
Batch 62/64 loss: -2.0295047760009766
Batch 63/64 loss: -1.9410953521728516
Batch 64/64 loss: -6.1048736572265625
Epoch 282  Train loss: -1.8496560339834176  Val loss: -1.9629673515398478
Epoch 283
-------------------------------
Batch 1/64 loss: -1.932058334350586
Batch 2/64 loss: -1.8749542236328125
Batch 3/64 loss: -1.9679908752441406
Batch 4/64 loss: -2.1415462493896484
Batch 5/64 loss: -1.3896427154541016
Batch 6/64 loss: -1.6212663650512695
Batch 7/64 loss: -1.8829021453857422
Batch 8/64 loss: -1.9038448333740234
Batch 9/64 loss: -1.474064826965332
Batch 10/64 loss: -1.8027143478393555
Batch 11/64 loss: -1.421762466430664
Batch 12/64 loss: -1.637563705444336
Batch 13/64 loss: -1.5698604583740234
Batch 14/64 loss: -1.4738788604736328
Batch 15/64 loss: -1.677229881286621
Batch 16/64 loss: -1.3646917343139648
Batch 17/64 loss: -1.854583740234375
Batch 18/64 loss: -1.907440185546875
Batch 19/64 loss: -1.6164283752441406
Batch 20/64 loss: -1.9009428024291992
Batch 21/64 loss: -1.6048307418823242
Batch 22/64 loss: -1.9209165573120117
Batch 23/64 loss: -1.1433115005493164
Batch 24/64 loss: -1.5768146514892578
Batch 25/64 loss: -1.8488178253173828
Batch 26/64 loss: -1.5714912414550781
Batch 27/64 loss: -1.679551124572754
Batch 28/64 loss: -1.5560884475708008
Batch 29/64 loss: -1.7410345077514648
Batch 30/64 loss: -1.4925355911254883
Batch 31/64 loss: -1.8569145202636719
Batch 32/64 loss: -1.8659286499023438
Batch 33/64 loss: -1.7732982635498047
Batch 34/64 loss: -1.7028398513793945
Batch 35/64 loss: -1.6830549240112305
Batch 36/64 loss: -1.027374267578125
Batch 37/64 loss: -1.7698545455932617
Batch 38/64 loss: -2.0717620849609375
Batch 39/64 loss: -1.8829383850097656
Batch 40/64 loss: -1.759211540222168
Batch 41/64 loss: -1.254755973815918
Batch 42/64 loss: -1.9825973510742188
Batch 43/64 loss: -1.9679288864135742
Batch 44/64 loss: -1.9182796478271484
Batch 45/64 loss: -1.6605339050292969
Batch 46/64 loss: -1.834364891052246
Batch 47/64 loss: -1.790022850036621
Batch 48/64 loss: -1.5520591735839844
Batch 49/64 loss: -2.007129669189453
Batch 50/64 loss: -1.9229459762573242
Batch 51/64 loss: -1.345597267150879
Batch 52/64 loss: -2.049370765686035
Batch 53/64 loss: -1.8939361572265625
Batch 54/64 loss: -1.730743408203125
Batch 55/64 loss: -0.6882829666137695
Batch 56/64 loss: -2.0510244369506836
Batch 57/64 loss: -1.8806591033935547
Batch 58/64 loss: -2.087087631225586
Batch 59/64 loss: -1.930415153503418
Batch 60/64 loss: -1.4086484909057617
Batch 61/64 loss: -2.239315986633301
Batch 62/64 loss: -1.7937707901000977
Batch 63/64 loss: -1.965768814086914
Batch 64/64 loss: -6.20591402053833
Epoch 283  Train loss: -1.7812331162247004  Val loss: -2.21282179003319
Epoch 284
-------------------------------
Batch 1/64 loss: -1.4912328720092773
Batch 2/64 loss: -2.1071739196777344
Batch 3/64 loss: -1.9076366424560547
Batch 4/64 loss: -1.6414709091186523
Batch 5/64 loss: -1.2232627868652344
Batch 6/64 loss: -2.056610107421875
Batch 7/64 loss: -1.7530021667480469
Batch 8/64 loss: -1.485483169555664
Batch 9/64 loss: -1.6095190048217773
Batch 10/64 loss: -1.7656002044677734
Batch 11/64 loss: -2.0026960372924805
Batch 12/64 loss: -1.2313261032104492
Batch 13/64 loss: -1.560598373413086
Batch 14/64 loss: -0.9570245742797852
Batch 15/64 loss: -1.7425851821899414
Batch 16/64 loss: -1.7696733474731445
Batch 17/64 loss: -1.8730382919311523
Batch 18/64 loss: -1.9210281372070312
Batch 19/64 loss: -1.6197834014892578
Batch 20/64 loss: -2.1185503005981445
Batch 21/64 loss: -1.8367528915405273
Batch 22/64 loss: -1.711709976196289
Batch 23/64 loss: -1.7116117477416992
Batch 24/64 loss: -1.7531747817993164
Batch 25/64 loss: -1.1021919250488281
Batch 26/64 loss: -1.912186622619629
Batch 27/64 loss: -2.05013370513916
Batch 28/64 loss: -1.9695491790771484
Batch 29/64 loss: -1.6449460983276367
Batch 30/64 loss: -1.9483766555786133
Batch 31/64 loss: -2.0657033920288086
Batch 32/64 loss: -2.0735387802124023
Batch 33/64 loss: -2.0357542037963867
Batch 34/64 loss: -1.5647516250610352
Batch 35/64 loss: -2.1686153411865234
Batch 36/64 loss: -1.5001277923583984
Batch 37/64 loss: -1.9014892578125
Batch 38/64 loss: -1.6215229034423828
Batch 39/64 loss: -1.3236913681030273
Batch 40/64 loss: -1.4766483306884766
Batch 41/64 loss: -1.473470687866211
Batch 42/64 loss: -1.807363510131836
Batch 43/64 loss: -0.6040706634521484
Batch 44/64 loss: -1.744156837463379
Batch 45/64 loss: -1.7303953170776367
Batch 46/64 loss: -1.6950960159301758
Batch 47/64 loss: -0.988616943359375
Batch 48/64 loss: -1.7875661849975586
Batch 49/64 loss: -1.6639289855957031
Batch 50/64 loss: -0.8454256057739258
Batch 51/64 loss: -1.664036750793457
Batch 52/64 loss: -1.655472755432129
Batch 53/64 loss: -1.3623065948486328
Batch 54/64 loss: -1.5252819061279297
Batch 55/64 loss: -1.7010107040405273
Batch 56/64 loss: -1.8711814880371094
Batch 57/64 loss: -1.395665168762207
Batch 58/64 loss: -1.4107227325439453
Batch 59/64 loss: -1.5650291442871094
Batch 60/64 loss: -1.735976219177246
Batch 61/64 loss: -1.90960693359375
Batch 62/64 loss: -1.6711082458496094
Batch 63/64 loss: -1.3771324157714844
Batch 64/64 loss: -5.94687032699585
Epoch 284  Train loss: -1.7075223006454168  Val loss: -1.9569731905697958
Epoch 285
-------------------------------
Batch 1/64 loss: -1.626943588256836
Batch 2/64 loss: -1.968729019165039
Batch 3/64 loss: -2.0418519973754883
Batch 4/64 loss: -1.746145248413086
Batch 5/64 loss: -1.5626211166381836
Batch 6/64 loss: -1.6971120834350586
Batch 7/64 loss: -1.9826679229736328
Batch 8/64 loss: -1.012939453125
Batch 9/64 loss: -2.086820602416992
Batch 10/64 loss: -2.023430824279785
Batch 11/64 loss: -1.701894760131836
Batch 12/64 loss: -1.6714935302734375
Batch 13/64 loss: -1.6673994064331055
Batch 14/64 loss: -2.019650459289551
Batch 15/64 loss: -2.127518653869629
Batch 16/64 loss: -2.0052623748779297
Batch 17/64 loss: -1.9450855255126953
Batch 18/64 loss: -2.1363468170166016
Batch 19/64 loss: -1.8359355926513672
Batch 20/64 loss: -2.128939628601074
Batch 21/64 loss: -1.852543830871582
Batch 22/64 loss: -2.1239919662475586
Batch 23/64 loss: -2.088899612426758
Batch 24/64 loss: -2.0482616424560547
Batch 25/64 loss: -1.9445915222167969
Batch 26/64 loss: -1.8895244598388672
Batch 27/64 loss: -2.180361747741699
Batch 28/64 loss: -2.1080751419067383
Batch 29/64 loss: -2.1028804779052734
Batch 30/64 loss: -2.2456917762756348
Batch 31/64 loss: -1.4875850677490234
Batch 32/64 loss: -2.1637840270996094
Batch 33/64 loss: -2.268754482269287
Batch 34/64 loss: -2.0112361907958984
Batch 35/64 loss: -1.5542211532592773
Batch 36/64 loss: -1.9202518463134766
Batch 37/64 loss: -2.1000547409057617
Batch 38/64 loss: -2.1583480834960938
Batch 39/64 loss: -2.1058731079101562
Batch 40/64 loss: -2.2653698921203613
Batch 41/64 loss: -2.051974296569824
Batch 42/64 loss: -1.9780044555664062
Batch 43/64 loss: -1.5951929092407227
Batch 44/64 loss: -2.1532278060913086
Batch 45/64 loss: -2.10288143157959
Batch 46/64 loss: -1.875382423400879
Batch 47/64 loss: -2.1663551330566406
Batch 48/64 loss: -2.0655622482299805
Batch 49/64 loss: -2.254744052886963
Batch 50/64 loss: -2.1072044372558594
Batch 51/64 loss: -2.0526905059814453
Batch 52/64 loss: -1.6260948181152344
Batch 53/64 loss: -2.1941146850585938
Batch 54/64 loss: -1.7562732696533203
Batch 55/64 loss: -1.9066390991210938
Batch 56/64 loss: -2.2461719512939453
Batch 57/64 loss: -2.248218536376953
Batch 58/64 loss: -2.1570911407470703
Batch 59/64 loss: -1.3118667602539062
Batch 60/64 loss: -2.1293821334838867
Batch 61/64 loss: -1.836287498474121
Batch 62/64 loss: -1.7056589126586914
Batch 63/64 loss: -2.3414173126220703
Batch 64/64 loss: -6.06022310256958
Epoch 285  Train loss: -2.008104980693144  Val loss: -2.285652265515934
Epoch 286
-------------------------------
Batch 1/64 loss: -2.1157169342041016
Batch 2/64 loss: -2.045927047729492
Batch 3/64 loss: -2.251722812652588
Batch 4/64 loss: -1.975285530090332
Batch 5/64 loss: -1.8915348052978516
Batch 6/64 loss: -1.8948755264282227
Batch 7/64 loss: -1.973158836364746
Batch 8/64 loss: -2.1025171279907227
Batch 9/64 loss: -1.3134450912475586
Batch 10/64 loss: -2.1630630493164062
Batch 11/64 loss: -2.438894271850586
Batch 12/64 loss: -2.0655412673950195
Batch 13/64 loss: -2.16750431060791
Batch 14/64 loss: -2.0443620681762695
Batch 15/64 loss: -2.308619499206543
Batch 16/64 loss: -2.1272764205932617
Batch 17/64 loss: -2.1603164672851562
Batch 18/64 loss: -2.129495620727539
Batch 19/64 loss: -1.4634552001953125
Batch 20/64 loss: -1.989980697631836
Batch 21/64 loss: -2.179443359375
Batch 22/64 loss: -1.99835205078125
Batch 23/64 loss: -1.9737319946289062
Batch 24/64 loss: -1.9774646759033203
Batch 25/64 loss: -2.0601987838745117
Batch 26/64 loss: -2.1416807174682617
Batch 27/64 loss: -1.815652847290039
Batch 28/64 loss: -2.2751526832580566
Batch 29/64 loss: -2.244288444519043
Batch 30/64 loss: -2.1276464462280273
Batch 31/64 loss: -1.7586746215820312
Batch 32/64 loss: -2.0878801345825195
Batch 33/64 loss: -2.1239852905273438
Batch 34/64 loss: -2.047123908996582
Batch 35/64 loss: -1.8000001907348633
Batch 36/64 loss: -2.3011422157287598
Batch 37/64 loss: -2.1175403594970703
Batch 38/64 loss: -1.4203014373779297
Batch 39/64 loss: -2.209705352783203
Batch 40/64 loss: -1.648482322692871
Batch 41/64 loss: -1.9518442153930664
Batch 42/64 loss: -2.204204559326172
Batch 43/64 loss: -2.289499282836914
Batch 44/64 loss: -2.200589179992676
Batch 45/64 loss: -2.054610252380371
Batch 46/64 loss: -2.2801613807678223
Batch 47/64 loss: -2.263944625854492
Batch 48/64 loss: -1.5969772338867188
Batch 49/64 loss: -2.2499094009399414
Batch 50/64 loss: -2.147075653076172
Batch 51/64 loss: -1.6286840438842773
Batch 52/64 loss: -2.0835371017456055
Batch 53/64 loss: -1.903670310974121
Batch 54/64 loss: -2.1999168395996094
Batch 55/64 loss: -2.312905788421631
Batch 56/64 loss: -2.147385597229004
Batch 57/64 loss: -2.2937369346618652
Batch 58/64 loss: -2.275322914123535
Batch 59/64 loss: -2.1007919311523438
Batch 60/64 loss: -1.8020057678222656
Batch 61/64 loss: -2.260077476501465
Batch 62/64 loss: -2.308964252471924
Batch 63/64 loss: -1.8140554428100586
Batch 64/64 loss: -6.3732805252075195
Epoch 286  Train loss: -2.1032309176875095  Val loss: -2.2962847050932265
Epoch 287
-------------------------------
Batch 1/64 loss: -2.023740768432617
Batch 2/64 loss: -2.13181209564209
Batch 3/64 loss: -2.2208147048950195
Batch 4/64 loss: -2.332648277282715
Batch 5/64 loss: -2.228482723236084
Batch 6/64 loss: -2.3108668327331543
Batch 7/64 loss: -2.179415702819824
Batch 8/64 loss: -2.2360692024230957
Batch 9/64 loss: -2.1835336685180664
Batch 10/64 loss: -1.6905059814453125
Batch 11/64 loss: -1.3478431701660156
Batch 12/64 loss: -2.044788360595703
Batch 13/64 loss: -2.004868507385254
Batch 14/64 loss: -2.29374361038208
Batch 15/64 loss: -1.9026460647583008
Batch 16/64 loss: -1.776576042175293
Batch 17/64 loss: -1.3175172805786133
Batch 18/64 loss: -1.9195404052734375
Batch 19/64 loss: -2.1871824264526367
Batch 20/64 loss: -2.0748062133789062
Batch 21/64 loss: -1.8575639724731445
Batch 22/64 loss: -2.2179689407348633
Batch 23/64 loss: -2.1711530685424805
Batch 24/64 loss: -2.0262460708618164
Batch 25/64 loss: -1.7130823135375977
Batch 26/64 loss: -1.9204778671264648
Batch 27/64 loss: -2.052968978881836
Batch 28/64 loss: -2.1031856536865234
Batch 29/64 loss: -1.9065370559692383
Batch 30/64 loss: -2.0673437118530273
Batch 31/64 loss: -2.1802120208740234
Batch 32/64 loss: -2.143887519836426
Batch 33/64 loss: -2.2325639724731445
Batch 34/64 loss: -2.180607795715332
Batch 35/64 loss: -2.1269912719726562
Batch 36/64 loss: -2.1683225631713867
Batch 37/64 loss: -2.129779815673828
Batch 38/64 loss: -2.206249237060547
Batch 39/64 loss: -2.061001777648926
Batch 40/64 loss: -2.272383689880371
Batch 41/64 loss: -1.774104118347168
Batch 42/64 loss: -2.0773696899414062
Batch 43/64 loss: -2.2736682891845703
Batch 44/64 loss: -2.007143020629883
Batch 45/64 loss: -1.8739328384399414
Batch 46/64 loss: -2.2734427452087402
Batch 47/64 loss: -1.744236946105957
Batch 48/64 loss: -2.2848353385925293
Batch 49/64 loss: -2.178953170776367
Batch 50/64 loss: -2.0003652572631836
Batch 51/64 loss: -1.9053373336791992
Batch 52/64 loss: -2.0512475967407227
Batch 53/64 loss: -1.3619003295898438
Batch 54/64 loss: -2.276704788208008
Batch 55/64 loss: -2.256129264831543
Batch 56/64 loss: -2.4553470611572266
Batch 57/64 loss: -2.17136287689209
Batch 58/64 loss: -2.1992063522338867
Batch 59/64 loss: -2.15645694732666
Batch 60/64 loss: -1.8944196701049805
Batch 61/64 loss: -1.9152088165283203
Batch 62/64 loss: -2.1787986755371094
Batch 63/64 loss: -2.326247215270996
Batch 64/64 loss: -6.516619682312012
Epoch 287  Train loss: -2.1124676461313285  Val loss: -2.4699802726404774
Epoch 288
-------------------------------
Batch 1/64 loss: -2.412600040435791
Batch 2/64 loss: -2.1740541458129883
Batch 3/64 loss: -2.2660789489746094
Batch 4/64 loss: -2.134953498840332
Batch 5/64 loss: -2.0536842346191406
Batch 6/64 loss: -2.1157913208007812
Batch 7/64 loss: -2.018604278564453
Batch 8/64 loss: -2.209134101867676
Batch 9/64 loss: -2.2803292274475098
Batch 10/64 loss: -2.36507511138916
Batch 11/64 loss: -2.2654829025268555
Batch 12/64 loss: -2.325103282928467
Batch 13/64 loss: -2.225820541381836
Batch 14/64 loss: -2.0196714401245117
Batch 15/64 loss: -1.404592514038086
Batch 16/64 loss: -2.2835073471069336
Batch 17/64 loss: -2.29949951171875
Batch 18/64 loss: -1.4649324417114258
Batch 19/64 loss: -1.895218849182129
Batch 20/64 loss: -2.24460506439209
Batch 21/64 loss: -2.1073122024536133
Batch 22/64 loss: -1.8499479293823242
Batch 23/64 loss: -1.8479509353637695
Batch 24/64 loss: -2.134079933166504
Batch 25/64 loss: -2.229759693145752
Batch 26/64 loss: -2.412956714630127
Batch 27/64 loss: -2.104252815246582
Batch 28/64 loss: -2.0529136657714844
Batch 29/64 loss: -2.0827627182006836
Batch 30/64 loss: -2.0082693099975586
Batch 31/64 loss: -2.043393135070801
Batch 32/64 loss: -2.0883703231811523
Batch 33/64 loss: -2.281968116760254
Batch 34/64 loss: -2.072207450866699
Batch 35/64 loss: -1.9754257202148438
Batch 36/64 loss: -1.9970645904541016
Batch 37/64 loss: -2.075758934020996
Batch 38/64 loss: -1.943307876586914
Batch 39/64 loss: -2.2397947311401367
Batch 40/64 loss: -2.1124353408813477
Batch 41/64 loss: -2.3294382095336914
Batch 42/64 loss: -2.099538803100586
Batch 43/64 loss: -2.281937599182129
Batch 44/64 loss: -1.9880714416503906
Batch 45/64 loss: -2.201669692993164
Batch 46/64 loss: -1.8693828582763672
Batch 47/64 loss: -1.9943218231201172
Batch 48/64 loss: -2.3277506828308105
Batch 49/64 loss: -1.7224302291870117
Batch 50/64 loss: -2.396246910095215
Batch 51/64 loss: -2.0252151489257812
Batch 52/64 loss: -2.1354589462280273
Batch 53/64 loss: -2.1284608840942383
Batch 54/64 loss: -2.256755828857422
Batch 55/64 loss: -2.19815731048584
Batch 56/64 loss: -2.274252414703369
Batch 57/64 loss: -2.256575584411621
Batch 58/64 loss: -1.833754539489746
Batch 59/64 loss: -1.6883020401000977
Batch 60/64 loss: -2.188955307006836
Batch 61/64 loss: -1.8950262069702148
Batch 62/64 loss: -2.297293186187744
Batch 63/64 loss: -2.3090386390686035
Batch 64/64 loss: -6.252720832824707
Epoch 288  Train loss: -2.156960719239478  Val loss: -2.4688576636035826
Epoch 289
-------------------------------
Batch 1/64 loss: -1.9496936798095703
Batch 2/64 loss: -2.068028450012207
Batch 3/64 loss: -2.0831117630004883
Batch 4/64 loss: -2.3702988624572754
Batch 5/64 loss: -2.1797876358032227
Batch 6/64 loss: -2.138683319091797
Batch 7/64 loss: -2.0060157775878906
Batch 8/64 loss: -2.1775588989257812
Batch 9/64 loss: -2.014505386352539
Batch 10/64 loss: -2.2057838439941406
Batch 11/64 loss: -1.9611892700195312
Batch 12/64 loss: -2.1968421936035156
Batch 13/64 loss: -2.3026933670043945
Batch 14/64 loss: -2.2387800216674805
Batch 15/64 loss: -2.173067092895508
Batch 16/64 loss: -1.65301513671875
Batch 17/64 loss: -1.9580888748168945
Batch 18/64 loss: -2.3090686798095703
Batch 19/64 loss: -2.004786491394043
Batch 20/64 loss: -2.3325538635253906
Batch 21/64 loss: -1.9661626815795898
Batch 22/64 loss: -1.9515142440795898
Batch 23/64 loss: -2.1890335083007812
Batch 24/64 loss: -2.0755958557128906
Batch 25/64 loss: -1.9209623336791992
Batch 26/64 loss: -2.2212181091308594
Batch 27/64 loss: -2.0699644088745117
Batch 28/64 loss: -2.319098949432373
Batch 29/64 loss: -2.217667579650879
Batch 30/64 loss: -2.1332082748413086
Batch 31/64 loss: -2.0041980743408203
Batch 32/64 loss: -2.281195640563965
Batch 33/64 loss: -1.9663162231445312
Batch 34/64 loss: -2.3708434104919434
Batch 35/64 loss: -2.267399787902832
Batch 36/64 loss: -0.5632762908935547
Batch 37/64 loss: -2.0602054595947266
Batch 38/64 loss: -2.2592430114746094
Batch 39/64 loss: -2.2797422409057617
Batch 40/64 loss: -2.2109365463256836
Batch 41/64 loss: -2.3363609313964844
Batch 42/64 loss: -2.2081832885742188
Batch 43/64 loss: -1.4364986419677734
Batch 44/64 loss: -2.26239013671875
Batch 45/64 loss: -2.106954574584961
Batch 46/64 loss: -2.212005615234375
Batch 47/64 loss: -2.3432869911193848
Batch 48/64 loss: -2.1686840057373047
Batch 49/64 loss: -1.9129657745361328
Batch 50/64 loss: -2.2022972106933594
Batch 51/64 loss: -2.2242860794067383
Batch 52/64 loss: -2.226316452026367
Batch 53/64 loss: -2.0514163970947266
Batch 54/64 loss: -2.152444839477539
Batch 55/64 loss: -2.075773239135742
Batch 56/64 loss: -2.226992607116699
Batch 57/64 loss: -2.019289970397949
Batch 58/64 loss: -2.270106315612793
Batch 59/64 loss: -2.077672004699707
Batch 60/64 loss: -2.1316280364990234
Batch 61/64 loss: -1.6777410507202148
Batch 62/64 loss: -1.998046875
Batch 63/64 loss: -2.077167510986328
Batch 64/64 loss: -6.246458530426025
Epoch 289  Train loss: -2.1448578460543763  Val loss: -2.323139950991496
Epoch 290
-------------------------------
Batch 1/64 loss: -2.2466354370117188
Batch 2/64 loss: -2.1147308349609375
Batch 3/64 loss: -2.1865129470825195
Batch 4/64 loss: -1.9625663757324219
Batch 5/64 loss: -1.9231986999511719
Batch 6/64 loss: -2.2780656814575195
Batch 7/64 loss: -2.1485862731933594
Batch 8/64 loss: -1.9836006164550781
Batch 9/64 loss: -2.390193462371826
Batch 10/64 loss: -1.643528938293457
Batch 11/64 loss: -2.1903133392333984
Batch 12/64 loss: -1.3972148895263672
Batch 13/64 loss: -2.1271724700927734
Batch 14/64 loss: -2.158639907836914
Batch 15/64 loss: -2.1984033584594727
Batch 16/64 loss: -2.1376895904541016
Batch 17/64 loss: -2.2738027572631836
Batch 18/64 loss: -2.116086006164551
Batch 19/64 loss: -1.8957548141479492
Batch 20/64 loss: -2.3056445121765137
Batch 21/64 loss: -2.2269983291625977
Batch 22/64 loss: -1.7981815338134766
Batch 23/64 loss: -2.1805591583251953
Batch 24/64 loss: -2.2441015243530273
Batch 25/64 loss: -1.8508625030517578
Batch 26/64 loss: -2.0949010848999023
Batch 27/64 loss: -2.20346736907959
Batch 28/64 loss: -1.787576675415039
Batch 29/64 loss: -2.4373860359191895
Batch 30/64 loss: -2.101593017578125
Batch 31/64 loss: -1.9834566116333008
Batch 32/64 loss: -2.3198442459106445
Batch 33/64 loss: -2.0472183227539062
Batch 34/64 loss: -2.2476511001586914
Batch 35/64 loss: -2.161463737487793
Batch 36/64 loss: -1.9737205505371094
Batch 37/64 loss: -2.1823644638061523
Batch 38/64 loss: -2.0078001022338867
Batch 39/64 loss: -2.3306074142456055
Batch 40/64 loss: -2.160830497741699
Batch 41/64 loss: -2.138124465942383
Batch 42/64 loss: -2.025754928588867
Batch 43/64 loss: -2.204697608947754
Batch 44/64 loss: -2.132784843444824
Batch 45/64 loss: -2.237626075744629
Batch 46/64 loss: -2.1863346099853516
Batch 47/64 loss: -2.091263771057129
Batch 48/64 loss: -2.245823860168457
Batch 49/64 loss: -1.981368064880371
Batch 50/64 loss: -2.2647781372070312
Batch 51/64 loss: -1.9074525833129883
Batch 52/64 loss: -2.0290451049804688
Batch 53/64 loss: -2.2542991638183594
Batch 54/64 loss: -1.983591079711914
Batch 55/64 loss: -1.350987434387207
Batch 56/64 loss: -2.1494674682617188
Batch 57/64 loss: -2.1825780868530273
Batch 58/64 loss: -2.1068849563598633
Batch 59/64 loss: -1.889967918395996
Batch 60/64 loss: -2.266935348510742
Batch 61/64 loss: -2.0403404235839844
Batch 62/64 loss: -1.8513708114624023
Batch 63/64 loss: -2.250485420227051
Batch 64/64 loss: -6.196346759796143
Epoch 290  Train loss: -2.1402062341278674  Val loss: -2.3305181785137794
Epoch 291
-------------------------------
Batch 1/64 loss: -2.089695930480957
Batch 2/64 loss: -1.0721254348754883
Batch 3/64 loss: -2.1569480895996094
Batch 4/64 loss: -2.1323184967041016
Batch 5/64 loss: -2.0997753143310547
Batch 6/64 loss: -2.093928337097168
Batch 7/64 loss: -2.154417037963867
Batch 8/64 loss: -2.1277599334716797
Batch 9/64 loss: -2.395693778991699
Batch 10/64 loss: -2.241443634033203
Batch 11/64 loss: -2.0718345642089844
Batch 12/64 loss: -2.1913986206054688
Batch 13/64 loss: -2.220280647277832
Batch 14/64 loss: -1.6115961074829102
Batch 15/64 loss: -1.6750030517578125
Batch 16/64 loss: -2.0868005752563477
Batch 17/64 loss: -2.0986013412475586
Batch 18/64 loss: -2.0718860626220703
Batch 19/64 loss: -1.753401756286621
Batch 20/64 loss: -1.9360809326171875
Batch 21/64 loss: -2.239168167114258
Batch 22/64 loss: -2.1783809661865234
Batch 23/64 loss: -1.7193727493286133
Batch 24/64 loss: -1.594818115234375
Batch 25/64 loss: -2.0396060943603516
Batch 26/64 loss: -2.1955642700195312
Batch 27/64 loss: -1.8855714797973633
Batch 28/64 loss: -1.6220273971557617
Batch 29/64 loss: -1.8521270751953125
Batch 30/64 loss: -2.0462779998779297
Batch 31/64 loss: -2.1757469177246094
Batch 32/64 loss: -2.2506675720214844
Batch 33/64 loss: -1.5668754577636719
Batch 34/64 loss: -1.9818601608276367
Batch 35/64 loss: -1.997182846069336
Batch 36/64 loss: -2.1277637481689453
Batch 37/64 loss: -2.2337465286254883
Batch 38/64 loss: -2.1252307891845703
Batch 39/64 loss: -1.817784309387207
Batch 40/64 loss: -2.370291233062744
Batch 41/64 loss: -1.9457941055297852
Batch 42/64 loss: -2.040102958679199
Batch 43/64 loss: -2.366222858428955
Batch 44/64 loss: -2.204622268676758
Batch 45/64 loss: -2.223094940185547
Batch 46/64 loss: -2.061582565307617
Batch 47/64 loss: -2.0456161499023438
Batch 48/64 loss: -1.9559946060180664
Batch 49/64 loss: -2.3034305572509766
Batch 50/64 loss: -2.3360519409179688
Batch 51/64 loss: -2.3682284355163574
Batch 52/64 loss: -2.238886833190918
Batch 53/64 loss: -2.2408456802368164
Batch 54/64 loss: -2.1047868728637695
Batch 55/64 loss: -1.9659690856933594
Batch 56/64 loss: -1.695246696472168
Batch 57/64 loss: -2.0658702850341797
Batch 58/64 loss: -2.040310859680176
Batch 59/64 loss: -1.3076000213623047
Batch 60/64 loss: -2.32132625579834
Batch 61/64 loss: -2.1212167739868164
Batch 62/64 loss: -2.325953483581543
Batch 63/64 loss: -1.7088537216186523
Batch 64/64 loss: -6.468346118927002
Epoch 291  Train loss: -2.0884693501042384  Val loss: -2.361154313759296
Epoch 292
-------------------------------
Batch 1/64 loss: -2.142303466796875
Batch 2/64 loss: -2.214710235595703
Batch 3/64 loss: -1.8340654373168945
Batch 4/64 loss: -2.2950496673583984
Batch 5/64 loss: -2.303529739379883
Batch 6/64 loss: -2.208775520324707
Batch 7/64 loss: -2.124323844909668
Batch 8/64 loss: -2.2739524841308594
Batch 9/64 loss: -2.278548240661621
Batch 10/64 loss: -2.2336950302124023
Batch 11/64 loss: -2.0857534408569336
Batch 12/64 loss: -2.1566162109375
Batch 13/64 loss: -1.8029680252075195
Batch 14/64 loss: -1.9142446517944336
Batch 15/64 loss: -2.0849647521972656
Batch 16/64 loss: -1.6457195281982422
Batch 17/64 loss: -2.202779769897461
Batch 18/64 loss: -2.161351203918457
Batch 19/64 loss: -2.026362419128418
Batch 20/64 loss: -2.1881542205810547
Batch 21/64 loss: -1.8810129165649414
Batch 22/64 loss: -2.301335334777832
Batch 23/64 loss: -2.1449146270751953
Batch 24/64 loss: -2.2988672256469727
Batch 25/64 loss: -2.2420644760131836
Batch 26/64 loss: -2.2330589294433594
Batch 27/64 loss: -1.8977680206298828
Batch 28/64 loss: -2.2471981048583984
Batch 29/64 loss: -2.2271156311035156
Batch 30/64 loss: -2.0058069229125977
Batch 31/64 loss: -2.18264102935791
Batch 32/64 loss: -1.9911651611328125
Batch 33/64 loss: -2.155620574951172
Batch 34/64 loss: -1.9468975067138672
Batch 35/64 loss: -2.0879898071289062
Batch 36/64 loss: -2.067075729370117
Batch 37/64 loss: -2.3887953758239746
Batch 38/64 loss: -2.2272109985351562
Batch 39/64 loss: -2.292430877685547
Batch 40/64 loss: -2.0947446823120117
Batch 41/64 loss: -2.171933174133301
Batch 42/64 loss: -1.852860450744629
Batch 43/64 loss: -2.1374130249023438
Batch 44/64 loss: -2.151174545288086
Batch 45/64 loss: -1.1788215637207031
Batch 46/64 loss: -2.309539318084717
Batch 47/64 loss: -2.0646896362304688
Batch 48/64 loss: -2.06890869140625
Batch 49/64 loss: -2.23378849029541
Batch 50/64 loss: -1.910104751586914
Batch 51/64 loss: -2.1490135192871094
Batch 52/64 loss: -1.9332103729248047
Batch 53/64 loss: -1.9000940322875977
Batch 54/64 loss: -2.180452346801758
Batch 55/64 loss: -2.3354296684265137
Batch 56/64 loss: -1.9492425918579102
Batch 57/64 loss: -2.073678970336914
Batch 58/64 loss: -2.1357879638671875
Batch 59/64 loss: -2.296171188354492
Batch 60/64 loss: -1.922616958618164
Batch 61/64 loss: -2.260772228240967
Batch 62/64 loss: -1.8294363021850586
Batch 63/64 loss: -2.0210351943969727
Batch 64/64 loss: -6.336314678192139
Epoch 292  Train loss: -2.1476077304166905  Val loss: -2.475049716910136
Epoch 293
-------------------------------
Batch 1/64 loss: -1.8981952667236328
Batch 2/64 loss: -2.2572126388549805
Batch 3/64 loss: -2.226078987121582
Batch 4/64 loss: -2.2282676696777344
Batch 5/64 loss: -2.263723373413086
Batch 6/64 loss: -2.1783857345581055
Batch 7/64 loss: -2.243499279022217
Batch 8/64 loss: -1.9720935821533203
Batch 9/64 loss: -1.9294071197509766
Batch 10/64 loss: -2.273202896118164
Batch 11/64 loss: -2.225846290588379
Batch 12/64 loss: -2.218446731567383
Batch 13/64 loss: -2.1821184158325195
Batch 14/64 loss: -1.6044931411743164
Batch 15/64 loss: -2.293391227722168
Batch 16/64 loss: -1.916158676147461
Batch 17/64 loss: -2.018890380859375
Batch 18/64 loss: -2.082122802734375
Batch 19/64 loss: -2.109424591064453
Batch 20/64 loss: -2.225137710571289
Batch 21/64 loss: -1.316258430480957
Batch 22/64 loss: -2.0582332611083984
Batch 23/64 loss: -2.3799519538879395
Batch 24/64 loss: -2.2632083892822266
Batch 25/64 loss: -2.2973737716674805
Batch 26/64 loss: -2.289773464202881
Batch 27/64 loss: -2.1635255813598633
Batch 28/64 loss: -2.0289430618286133
Batch 29/64 loss: -2.2445554733276367
Batch 30/64 loss: -2.202169418334961
Batch 31/64 loss: -2.176637649536133
Batch 32/64 loss: -2.115939140319824
Batch 33/64 loss: -2.2632246017456055
Batch 34/64 loss: -1.9217472076416016
Batch 35/64 loss: -2.185304641723633
Batch 36/64 loss: -2.0190582275390625
Batch 37/64 loss: -2.249408721923828
Batch 38/64 loss: -2.2547225952148438
Batch 39/64 loss: -1.8314380645751953
Batch 40/64 loss: -2.1340818405151367
Batch 41/64 loss: -2.120722770690918
Batch 42/64 loss: -2.1750869750976562
Batch 43/64 loss: -2.176881790161133
Batch 44/64 loss: -1.4676752090454102
Batch 45/64 loss: -1.3919658660888672
Batch 46/64 loss: -2.2800674438476562
Batch 47/64 loss: -2.1841259002685547
Batch 48/64 loss: -1.6729516983032227
Batch 49/64 loss: -2.192514419555664
Batch 50/64 loss: -2.173328399658203
Batch 51/64 loss: -2.0595932006835938
Batch 52/64 loss: -2.157076835632324
Batch 53/64 loss: -2.28708553314209
Batch 54/64 loss: -1.7813959121704102
Batch 55/64 loss: -2.3347530364990234
Batch 56/64 loss: -2.2021379470825195
Batch 57/64 loss: -2.170938491821289
Batch 58/64 loss: -1.84344482421875
Batch 59/64 loss: -2.042133331298828
Batch 60/64 loss: -2.20084285736084
Batch 61/64 loss: -2.1519412994384766
Batch 62/64 loss: -2.1484575271606445
Batch 63/64 loss: -2.3779501914978027
Batch 64/64 loss: -6.032591819763184
Epoch 293  Train loss: -2.146810468037923  Val loss: -2.395588327519263
Epoch 294
-------------------------------
Batch 1/64 loss: -2.1375246047973633
Batch 2/64 loss: -2.1004199981689453
Batch 3/64 loss: -2.274660110473633
Batch 4/64 loss: -2.061373710632324
Batch 5/64 loss: -2.1876087188720703
Batch 6/64 loss: -1.9582386016845703
Batch 7/64 loss: -2.0515213012695312
Batch 8/64 loss: -2.0040159225463867
Batch 9/64 loss: -2.235301971435547
Batch 10/64 loss: -2.071565628051758
Batch 11/64 loss: -2.0799360275268555
Batch 12/64 loss: -1.9576787948608398
Batch 13/64 loss: -1.7208261489868164
Batch 14/64 loss: -1.969325065612793
Batch 15/64 loss: -1.9659481048583984
Batch 16/64 loss: -1.9810762405395508
Batch 17/64 loss: -2.073640823364258
Batch 18/64 loss: -1.9328889846801758
Batch 19/64 loss: -1.9801645278930664
Batch 20/64 loss: -2.1785430908203125
Batch 21/64 loss: -1.7412633895874023
Batch 22/64 loss: -1.9818296432495117
Batch 23/64 loss: -1.2529430389404297
Batch 24/64 loss: -1.4788646697998047
Batch 25/64 loss: -1.999567985534668
Batch 26/64 loss: -1.6812744140625
Batch 27/64 loss: -1.9298362731933594
Batch 28/64 loss: -2.1747570037841797
Batch 29/64 loss: -2.124619483947754
Batch 30/64 loss: -2.1798362731933594
Batch 31/64 loss: -2.2627029418945312
Batch 32/64 loss: -2.159482002258301
Batch 33/64 loss: -1.605565071105957
Batch 34/64 loss: -1.849252700805664
Batch 35/64 loss: -1.7489652633666992
Batch 36/64 loss: -2.122736930847168
Batch 37/64 loss: -2.0166540145874023
Batch 38/64 loss: -1.9012794494628906
Batch 39/64 loss: -2.0995216369628906
Batch 40/64 loss: -2.125438690185547
Batch 41/64 loss: -2.1240692138671875
Batch 42/64 loss: -2.164003372192383
Batch 43/64 loss: -2.2908668518066406
Batch 44/64 loss: -1.5571556091308594
Batch 45/64 loss: -2.029129981994629
Batch 46/64 loss: -1.805068016052246
Batch 47/64 loss: -2.0585098266601562
Batch 48/64 loss: -1.9910249710083008
Batch 49/64 loss: -1.701995849609375
Batch 50/64 loss: -1.8810434341430664
Batch 51/64 loss: -1.1369247436523438
Batch 52/64 loss: -1.7557287216186523
Batch 53/64 loss: -2.265573501586914
Batch 54/64 loss: -2.2025299072265625
Batch 55/64 loss: -2.315948963165283
Batch 56/64 loss: -2.1245718002319336
Batch 57/64 loss: -2.301806926727295
Batch 58/64 loss: -2.2415666580200195
Batch 59/64 loss: -2.040618896484375
Batch 60/64 loss: -1.8450422286987305
Batch 61/64 loss: -2.3189926147460938
Batch 62/64 loss: -2.3318796157836914
Batch 63/64 loss: -1.9868078231811523
Batch 64/64 loss: -6.541347026824951
Epoch 294  Train loss: -2.0507532400243424  Val loss: -2.508740100663962
Epoch 295
-------------------------------
Batch 1/64 loss: -1.7929401397705078
Batch 2/64 loss: -1.714034080505371
Batch 3/64 loss: -2.231783866882324
Batch 4/64 loss: -1.223658561706543
Batch 5/64 loss: -2.126148223876953
Batch 6/64 loss: -2.254300117492676
Batch 7/64 loss: -2.417214870452881
Batch 8/64 loss: -2.214672088623047
Batch 9/64 loss: -2.195857048034668
Batch 10/64 loss: -2.34450626373291
Batch 11/64 loss: -2.085968017578125
Batch 12/64 loss: -2.220658302307129
Batch 13/64 loss: -2.058950424194336
Batch 14/64 loss: -2.193937301635742
Batch 15/64 loss: -1.8279151916503906
Batch 16/64 loss: -2.1398096084594727
Batch 17/64 loss: -1.8994178771972656
Batch 18/64 loss: -1.7092523574829102
Batch 19/64 loss: -2.274566650390625
Batch 20/64 loss: -1.999405860900879
Batch 21/64 loss: -2.2041749954223633
Batch 22/64 loss: -2.077651023864746
Batch 23/64 loss: -2.287137031555176
Batch 24/64 loss: -2.184176445007324
Batch 25/64 loss: -2.1489944458007812
Batch 26/64 loss: -1.982060432434082
Batch 27/64 loss: -1.2672185897827148
Batch 28/64 loss: -2.3028197288513184
Batch 29/64 loss: -2.0814132690429688
Batch 30/64 loss: -2.117701530456543
Batch 31/64 loss: -2.1096267700195312
Batch 32/64 loss: -2.2208242416381836
Batch 33/64 loss: -2.108366012573242
Batch 34/64 loss: -2.118821144104004
Batch 35/64 loss: -2.0508031845092773
Batch 36/64 loss: -2.0689468383789062
Batch 37/64 loss: -2.1292152404785156
Batch 38/64 loss: -2.087985038757324
Batch 39/64 loss: -1.8131513595581055
Batch 40/64 loss: -2.000340461730957
Batch 41/64 loss: -2.308189868927002
Batch 42/64 loss: -2.2094688415527344
Batch 43/64 loss: -2.1561203002929688
Batch 44/64 loss: -2.035459518432617
Batch 45/64 loss: -2.279782295227051
Batch 46/64 loss: -2.053887367248535
Batch 47/64 loss: -2.0652284622192383
Batch 48/64 loss: -2.1954898834228516
Batch 49/64 loss: -2.1195383071899414
Batch 50/64 loss: -1.8919687271118164
Batch 51/64 loss: -2.1906213760375977
Batch 52/64 loss: -2.20358943939209
Batch 53/64 loss: -1.7763357162475586
Batch 54/64 loss: -2.248896598815918
Batch 55/64 loss: -2.246652603149414
Batch 56/64 loss: -2.123188018798828
Batch 57/64 loss: -1.8716907501220703
Batch 58/64 loss: -1.9792098999023438
Batch 59/64 loss: -2.225226402282715
Batch 60/64 loss: -2.227987289428711
Batch 61/64 loss: -2.162088394165039
Batch 62/64 loss: -2.379770278930664
Batch 63/64 loss: -2.2358293533325195
Batch 64/64 loss: -5.88253927230835
Epoch 295  Train loss: -2.1315223338557225  Val loss: -2.4245802626986683
Epoch 296
-------------------------------
Batch 1/64 loss: -2.1645193099975586
Batch 2/64 loss: -2.307222366333008
Batch 3/64 loss: -2.03680419921875
Batch 4/64 loss: -2.159451484680176
Batch 5/64 loss: -1.9670610427856445
Batch 6/64 loss: -2.2876176834106445
Batch 7/64 loss: -2.177715301513672
Batch 8/64 loss: -1.7064428329467773
Batch 9/64 loss: -2.314480781555176
Batch 10/64 loss: -2.015294075012207
Batch 11/64 loss: -2.317223072052002
Batch 12/64 loss: -2.1142539978027344
Batch 13/64 loss: -1.9307985305786133
Batch 14/64 loss: -2.301793098449707
Batch 15/64 loss: -2.0526304244995117
Batch 16/64 loss: -2.333932399749756
Batch 17/64 loss: -2.1556596755981445
Batch 18/64 loss: -2.128347396850586
Batch 19/64 loss: -2.2497730255126953
Batch 20/64 loss: -1.725067138671875
Batch 21/64 loss: -2.031862258911133
Batch 22/64 loss: -1.0689334869384766
Batch 23/64 loss: -2.2249794006347656
Batch 24/64 loss: -2.0055532455444336
Batch 25/64 loss: -1.5063467025756836
Batch 26/64 loss: -2.2037057876586914
Batch 27/64 loss: -1.8273963928222656
Batch 28/64 loss: -2.0342979431152344
Batch 29/64 loss: -1.5129194259643555
Batch 30/64 loss: -2.1497793197631836
Batch 31/64 loss: -2.2819137573242188
Batch 32/64 loss: -2.099888801574707
Batch 33/64 loss: -2.0185365676879883
Batch 34/64 loss: -1.9690427780151367
Batch 35/64 loss: -2.095827102661133
Batch 36/64 loss: -2.1914052963256836
Batch 37/64 loss: -2.264852523803711
Batch 38/64 loss: -1.9613151550292969
Batch 39/64 loss: -2.31666898727417
Batch 40/64 loss: -2.2960848808288574
Batch 41/64 loss: -2.062920570373535
Batch 42/64 loss: -1.4470691680908203
Batch 43/64 loss: -2.2185001373291016
Batch 44/64 loss: -2.081454277038574
Batch 45/64 loss: -2.0024328231811523
Batch 46/64 loss: -2.1953792572021484
Batch 47/64 loss: -1.8941211700439453
Batch 48/64 loss: -2.1659555435180664
Batch 49/64 loss: -2.0612401962280273
Batch 50/64 loss: -2.0918712615966797
Batch 51/64 loss: -2.2119312286376953
Batch 52/64 loss: -1.7881183624267578
Batch 53/64 loss: -2.140444755554199
Batch 54/64 loss: -2.080974578857422
Batch 55/64 loss: -1.9969778060913086
Batch 56/64 loss: -2.051177978515625
Batch 57/64 loss: -2.085362434387207
Batch 58/64 loss: -1.9876432418823242
Batch 59/64 loss: -2.1717605590820312
Batch 60/64 loss: -2.115799903869629
Batch 61/64 loss: -2.0732688903808594
Batch 62/64 loss: -2.241739273071289
Batch 63/64 loss: -2.0858640670776367
Batch 64/64 loss: -6.408167362213135
Epoch 296  Train loss: -2.1108318534551884  Val loss: -2.415413650040774
Epoch 297
-------------------------------
Batch 1/64 loss: -1.9254341125488281
Batch 2/64 loss: -1.492842674255371
Batch 3/64 loss: -2.127408027648926
Batch 4/64 loss: -2.181131362915039
Batch 5/64 loss: -1.9138555526733398
Batch 6/64 loss: -1.886073112487793
Batch 7/64 loss: -2.20444393157959
Batch 8/64 loss: -2.237112045288086
Batch 9/64 loss: -1.9396600723266602
Batch 10/64 loss: -2.025554656982422
Batch 11/64 loss: -2.140608787536621
Batch 12/64 loss: -1.9273958206176758
Batch 13/64 loss: -1.8073310852050781
Batch 14/64 loss: -1.9797687530517578
Batch 15/64 loss: -1.9698705673217773
Batch 16/64 loss: -2.0638914108276367
Batch 17/64 loss: -1.8450212478637695
Batch 18/64 loss: -1.836165428161621
Batch 19/64 loss: -1.9232597351074219
Batch 20/64 loss: -1.8973503112792969
Batch 21/64 loss: -1.8020219802856445
Batch 22/64 loss: -1.200387954711914
Batch 23/64 loss: -2.0463972091674805
Batch 24/64 loss: -1.9108619689941406
Batch 25/64 loss: -1.9586973190307617
Batch 26/64 loss: -1.7830238342285156
Batch 27/64 loss: -1.0019054412841797
Batch 28/64 loss: -1.8204841613769531
Batch 29/64 loss: -1.9898605346679688
Batch 30/64 loss: -1.7779779434204102
Batch 31/64 loss: -1.626007080078125
Batch 32/64 loss: -1.7555532455444336
Batch 33/64 loss: -1.941544532775879
Batch 34/64 loss: -1.9017343521118164
Batch 35/64 loss: -2.139802932739258
Batch 36/64 loss: -1.9840927124023438
Batch 37/64 loss: -2.0423898696899414
Batch 38/64 loss: -1.9547185897827148
Batch 39/64 loss: -1.8363733291625977
Batch 40/64 loss: -1.9080066680908203
Batch 41/64 loss: -1.9272699356079102
Batch 42/64 loss: -1.976414680480957
Batch 43/64 loss: -1.8438339233398438
Batch 44/64 loss: -1.6613531112670898
Batch 45/64 loss: -1.854440689086914
Batch 46/64 loss: -1.8964872360229492
Batch 47/64 loss: -1.791234016418457
Batch 48/64 loss: -2.103396415710449
Batch 49/64 loss: -1.6089553833007812
Batch 50/64 loss: -1.4819374084472656
Batch 51/64 loss: -2.146808624267578
Batch 52/64 loss: -2.055744171142578
Batch 53/64 loss: -1.6830320358276367
Batch 54/64 loss: -1.8227434158325195
Batch 55/64 loss: -2.20272159576416
Batch 56/64 loss: -1.9501895904541016
Batch 57/64 loss: -1.9946775436401367
Batch 58/64 loss: -2.0467529296875
Batch 59/64 loss: -1.951507568359375
Batch 60/64 loss: -1.8432769775390625
Batch 61/64 loss: -2.1488218307495117
Batch 62/64 loss: -2.0233755111694336
Batch 63/64 loss: -1.9335298538208008
Batch 64/64 loss: -6.2403974533081055
Epoch 297  Train loss: -1.9503501630296893  Val loss: -2.048971117157297
Epoch 298
-------------------------------
Batch 1/64 loss: -1.9889564514160156
Batch 2/64 loss: -1.8069629669189453
Batch 3/64 loss: -2.0311155319213867
Batch 4/64 loss: -1.8531694412231445
Batch 5/64 loss: -1.9588146209716797
Batch 6/64 loss: -1.7338438034057617
Batch 7/64 loss: -1.9521245956420898
Batch 8/64 loss: -1.9287214279174805
Batch 9/64 loss: -1.7307233810424805
Batch 10/64 loss: -1.68206787109375
Batch 11/64 loss: -1.6666374206542969
Batch 12/64 loss: -1.5336618423461914
Batch 13/64 loss: -1.7706260681152344
Batch 14/64 loss: -1.6996192932128906
Batch 15/64 loss: -1.923482894897461
Batch 16/64 loss: -2.0308094024658203
Batch 17/64 loss: -1.1255521774291992
Batch 18/64 loss: -1.8233098983764648
Batch 19/64 loss: -1.0961999893188477
Batch 20/64 loss: -1.7153053283691406
Batch 21/64 loss: -1.9371824264526367
Batch 22/64 loss: -1.9421491622924805
Batch 23/64 loss: -1.620889663696289
Batch 24/64 loss: -1.8444538116455078
Batch 25/64 loss: -1.9252729415893555
Batch 26/64 loss: -1.7271728515625
Batch 27/64 loss: -1.9533252716064453
Batch 28/64 loss: -1.9994573593139648
Batch 29/64 loss: -1.8422622680664062
Batch 30/64 loss: -1.5919408798217773
Batch 31/64 loss: -1.7196359634399414
Batch 32/64 loss: -1.9950494766235352
Batch 33/64 loss: -1.8841972351074219
Batch 34/64 loss: -1.8619747161865234
Batch 35/64 loss: -1.7721567153930664
Batch 36/64 loss: -2.0322694778442383
Batch 37/64 loss: -1.5229549407958984
Batch 38/64 loss: -1.0592451095581055
Batch 39/64 loss: -1.6790218353271484
Batch 40/64 loss: -1.9377498626708984
Batch 41/64 loss: -1.9491262435913086
Batch 42/64 loss: -1.8390235900878906
Batch 43/64 loss: -1.8933544158935547
Batch 44/64 loss: -1.6639518737792969
Batch 45/64 loss: -1.833205223083496
Batch 46/64 loss: -1.744089126586914
Batch 47/64 loss: -1.1850624084472656
Batch 48/64 loss: -1.7979745864868164
Batch 49/64 loss: -1.460087776184082
Batch 50/64 loss: -1.6462173461914062
Batch 51/64 loss: -1.6788444519042969
Batch 52/64 loss: -1.366063117980957
Batch 53/64 loss: -1.9622869491577148
Batch 54/64 loss: -1.9474849700927734
Batch 55/64 loss: -1.9878044128417969
Batch 56/64 loss: -1.9664325714111328
Batch 57/64 loss: -1.4098939895629883
Batch 58/64 loss: -1.8603734970092773
Batch 59/64 loss: -1.952315330505371
Batch 60/64 loss: -1.2720012664794922
Batch 61/64 loss: -1.541365623474121
Batch 62/64 loss: -1.9837121963500977
Batch 63/64 loss: -1.880661964416504
Batch 64/64 loss: -6.416089057922363
Epoch 298  Train loss: -1.812289664324592  Val loss: -2.2817622181476187
Epoch 299
-------------------------------
Batch 1/64 loss: -2.1364364624023438
Batch 2/64 loss: -1.8380060195922852
Batch 3/64 loss: -1.9240951538085938
Batch 4/64 loss: -1.81109619140625
Batch 5/64 loss: -1.5872325897216797
Batch 6/64 loss: -2.036550521850586
Batch 7/64 loss: -2.101346969604492
Batch 8/64 loss: -1.8235359191894531
Batch 9/64 loss: -1.9552297592163086
Batch 10/64 loss: -1.6487340927124023
Batch 11/64 loss: -2.1229629516601562
Batch 12/64 loss: -1.9294261932373047
Batch 13/64 loss: -2.0009775161743164
Batch 14/64 loss: -1.8130130767822266
Batch 15/64 loss: -2.0699987411499023
Batch 16/64 loss: -1.8668851852416992
Batch 17/64 loss: -2.1003293991088867
Batch 18/64 loss: -1.6443462371826172
Batch 19/64 loss: -2.1659984588623047
Batch 20/64 loss: -2.071409225463867
Batch 21/64 loss: -2.20950984954834
Batch 22/64 loss: -2.305572509765625
Batch 23/64 loss: -2.2057857513427734
Batch 24/64 loss: -1.42889404296875
Batch 25/64 loss: -2.070345878601074
Batch 26/64 loss: -2.029299736022949
Batch 27/64 loss: -1.6209907531738281
Batch 28/64 loss: -1.9353675842285156
Batch 29/64 loss: -2.273191452026367
Batch 30/64 loss: -1.8973274230957031
Batch 31/64 loss: -1.9563045501708984
Batch 32/64 loss: -1.8121232986450195
Batch 33/64 loss: -2.108891487121582
Batch 34/64 loss: -2.0813865661621094
Batch 35/64 loss: -1.168684959411621
Batch 36/64 loss: -2.1134233474731445
Batch 37/64 loss: -2.207071304321289
Batch 38/64 loss: -2.293471336364746
Batch 39/64 loss: -2.1861572265625
Batch 40/64 loss: -2.157468795776367
Batch 41/64 loss: -2.1680831909179688
Batch 42/64 loss: -2.1947526931762695
Batch 43/64 loss: -1.488037109375
Batch 44/64 loss: -1.6077203750610352
Batch 45/64 loss: -1.7325658798217773
Batch 46/64 loss: -2.264820098876953
Batch 47/64 loss: -1.8442268371582031
Batch 48/64 loss: -2.25058650970459
Batch 49/64 loss: -2.305333137512207
Batch 50/64 loss: -1.7265548706054688
Batch 51/64 loss: -2.2295703887939453
Batch 52/64 loss: -2.1334571838378906
Batch 53/64 loss: -2.3137073516845703
Batch 54/64 loss: -1.9154481887817383
Batch 55/64 loss: -2.062084197998047
Batch 56/64 loss: -2.13454532623291
Batch 57/64 loss: -2.2965879440307617
Batch 58/64 loss: -1.9920921325683594
Batch 59/64 loss: -1.9872236251831055
Batch 60/64 loss: -2.2570228576660156
Batch 61/64 loss: -2.3634891510009766
Batch 62/64 loss: -2.3457727432250977
Batch 63/64 loss: -2.3657546043395996
Batch 64/64 loss: -6.544417381286621
Epoch 299  Train loss: -2.064260830598719  Val loss: -2.5787457731581225
Epoch 300
-------------------------------
Batch 1/64 loss: -2.2883520126342773
Batch 2/64 loss: -2.2217607498168945
Batch 3/64 loss: -2.2177085876464844
Batch 4/64 loss: -2.0527524948120117
Batch 5/64 loss: -2.065840721130371
Batch 6/64 loss: -2.2528762817382812
Batch 7/64 loss: -2.1941919326782227
Batch 8/64 loss: -2.130941390991211
Batch 9/64 loss: -2.405270576477051
Batch 10/64 loss: -2.1406469345092773
Batch 11/64 loss: -2.311758041381836
Batch 12/64 loss: -2.314298629760742
Batch 13/64 loss: -1.4889774322509766
Batch 14/64 loss: -2.3392066955566406
Batch 15/64 loss: -2.1057052612304688
Batch 16/64 loss: -2.079432487487793
Batch 17/64 loss: -2.1797561645507812
Batch 18/64 loss: -2.359668731689453
Batch 19/64 loss: -2.1974592208862305
Batch 20/64 loss: -2.116459846496582
Batch 21/64 loss: -2.4015188217163086
Batch 22/64 loss: -2.4346046447753906
Batch 23/64 loss: -2.2038116455078125
Batch 24/64 loss: -2.2038135528564453
Batch 25/64 loss: -2.2695817947387695
Batch 26/64 loss: -2.3462376594543457
Batch 27/64 loss: -2.080735206604004
Batch 28/64 loss: -2.271787643432617
Batch 29/64 loss: -2.208249092102051
Batch 30/64 loss: -2.517031669616699
Batch 31/64 loss: -2.318182945251465
Batch 32/64 loss: -2.3552398681640625
Batch 33/64 loss: -2.4491944313049316
Batch 34/64 loss: -2.286212921142578
Batch 35/64 loss: -2.212632179260254
Batch 36/64 loss: -1.9659595489501953
Batch 37/64 loss: -2.4253292083740234
Batch 38/64 loss: -2.2661542892456055
Batch 39/64 loss: -1.5629463195800781
Batch 40/64 loss: -2.266240119934082
Batch 41/64 loss: -2.3223509788513184
Batch 42/64 loss: -2.088472366333008
Batch 43/64 loss: -2.1261558532714844
Batch 44/64 loss: -1.9039583206176758
Batch 45/64 loss: -1.9134016036987305
Batch 46/64 loss: -2.3387112617492676
Batch 47/64 loss: -2.0071516036987305
Batch 48/64 loss: -2.2007665634155273
Batch 49/64 loss: -2.1149330139160156
Batch 50/64 loss: -1.9103670120239258
Batch 51/64 loss: -1.5519914627075195
Batch 52/64 loss: -2.069003105163574
Batch 53/64 loss: -2.3585500717163086
Batch 54/64 loss: -1.5366735458374023
Batch 55/64 loss: -2.2785158157348633
Batch 56/64 loss: -2.0920867919921875
Batch 57/64 loss: -2.215402603149414
Batch 58/64 loss: -2.332736015319824
Batch 59/64 loss: -2.0656232833862305
Batch 60/64 loss: -2.4088172912597656
Batch 61/64 loss: -2.2659225463867188
Batch 62/64 loss: -2.096721649169922
Batch 63/64 loss: -2.288886070251465
Batch 64/64 loss: -6.325186252593994
Epoch 300  Train loss: -2.2233665298013126  Val loss: -2.5658650873452937
Epoch 301
-------------------------------
Batch 1/64 loss: -2.2870655059814453
Batch 2/64 loss: -2.1380863189697266
Batch 3/64 loss: -2.2464990615844727
Batch 4/64 loss: -2.476651668548584
Batch 5/64 loss: -2.2463836669921875
Batch 6/64 loss: -2.2296037673950195
Batch 7/64 loss: -1.987192153930664
Batch 8/64 loss: -2.1849374771118164
Batch 9/64 loss: -2.139087677001953
Batch 10/64 loss: -2.0313405990600586
Batch 11/64 loss: -2.115926742553711
Batch 12/64 loss: -2.1420373916625977
Batch 13/64 loss: -2.1943912506103516
Batch 14/64 loss: -2.295930862426758
Batch 15/64 loss: -2.5275139808654785
Batch 16/64 loss: -2.158747673034668
Batch 17/64 loss: -1.9467344284057617
Batch 18/64 loss: -2.1740427017211914
Batch 19/64 loss: -2.177694320678711
Batch 20/64 loss: -1.356633186340332
Batch 21/64 loss: -2.157132148742676
Batch 22/64 loss: -2.046504020690918
Batch 23/64 loss: -2.0893354415893555
Batch 24/64 loss: -1.5977258682250977
Batch 25/64 loss: -2.313601493835449
Batch 26/64 loss: -2.2640562057495117
Batch 27/64 loss: -2.1739883422851562
Batch 28/64 loss: -2.2700300216674805
Batch 29/64 loss: -2.390659809112549
Batch 30/64 loss: -2.266779899597168
Batch 31/64 loss: -2.1593284606933594
Batch 32/64 loss: -1.5757503509521484
Batch 33/64 loss: -2.0701684951782227
Batch 34/64 loss: -2.2225284576416016
Batch 35/64 loss: -2.3260250091552734
Batch 36/64 loss: -2.2889461517333984
Batch 37/64 loss: -2.304502487182617
Batch 38/64 loss: -2.0968685150146484
Batch 39/64 loss: -2.357999324798584
Batch 40/64 loss: -2.1220693588256836
Batch 41/64 loss: -2.2155609130859375
Batch 42/64 loss: -2.1531848907470703
Batch 43/64 loss: -2.2890148162841797
Batch 44/64 loss: -2.2936201095581055
Batch 45/64 loss: -2.290989875793457
Batch 46/64 loss: -2.3465423583984375
Batch 47/64 loss: -1.8890066146850586
Batch 48/64 loss: -2.151169776916504
Batch 49/64 loss: -2.3664331436157227
Batch 50/64 loss: -2.199787139892578
Batch 51/64 loss: -2.1871185302734375
Batch 52/64 loss: -2.4237723350524902
Batch 53/64 loss: -2.249959945678711
Batch 54/64 loss: -2.269293785095215
Batch 55/64 loss: -2.1828060150146484
Batch 56/64 loss: -2.2279491424560547
Batch 57/64 loss: -2.284268379211426
Batch 58/64 loss: -2.1674890518188477
Batch 59/64 loss: -2.175774574279785
Batch 60/64 loss: -2.2815847396850586
Batch 61/64 loss: -1.9833402633666992
Batch 62/64 loss: -1.880366325378418
Batch 63/64 loss: -2.102726936340332
Batch 64/64 loss: -6.556488513946533
Epoch 301  Train loss: -2.22242551130407  Val loss: -2.5724458465051816
Epoch 302
-------------------------------
Batch 1/64 loss: -1.8501625061035156
Batch 2/64 loss: -2.2004804611206055
Batch 3/64 loss: -2.4143667221069336
Batch 4/64 loss: -2.3486557006835938
Batch 5/64 loss: -2.2349491119384766
Batch 6/64 loss: -2.2533464431762695
Batch 7/64 loss: -2.171520233154297
Batch 8/64 loss: -1.9264097213745117
Batch 9/64 loss: -2.090921401977539
Batch 10/64 loss: -2.1817331314086914
Batch 11/64 loss: -2.416435718536377
Batch 12/64 loss: -2.2659521102905273
Batch 13/64 loss: -2.266263961791992
Batch 14/64 loss: -2.3225793838500977
Batch 15/64 loss: -2.353525161743164
Batch 16/64 loss: -2.364811420440674
Batch 17/64 loss: -2.07675838470459
Batch 18/64 loss: -2.2430620193481445
Batch 19/64 loss: -1.6674079895019531
Batch 20/64 loss: -1.9703187942504883
Batch 21/64 loss: -2.0301198959350586
Batch 22/64 loss: -2.1462554931640625
Batch 23/64 loss: -2.2746763229370117
Batch 24/64 loss: -2.2232465744018555
Batch 25/64 loss: -1.5352325439453125
Batch 26/64 loss: -2.3435769081115723
Batch 27/64 loss: -2.071290969848633
Batch 28/64 loss: -2.078465461730957
Batch 29/64 loss: -2.3154239654541016
Batch 30/64 loss: -2.3065881729125977
Batch 31/64 loss: -2.1763086318969727
Batch 32/64 loss: -2.17620849609375
Batch 33/64 loss: -2.202742576599121
Batch 34/64 loss: -2.3960447311401367
Batch 35/64 loss: -1.9228277206420898
Batch 36/64 loss: -1.9764108657836914
Batch 37/64 loss: -2.022979736328125
Batch 38/64 loss: -2.265040397644043
Batch 39/64 loss: -1.9689445495605469
Batch 40/64 loss: -1.7411870956420898
Batch 41/64 loss: -1.7838754653930664
Batch 42/64 loss: -1.8812694549560547
Batch 43/64 loss: -2.13055419921875
Batch 44/64 loss: -2.020221710205078
Batch 45/64 loss: -2.13326358795166
Batch 46/64 loss: -1.7621870040893555
Batch 47/64 loss: -2.0665903091430664
Batch 48/64 loss: -2.017436981201172
Batch 49/64 loss: -1.7825946807861328
Batch 50/64 loss: -2.036128044128418
Batch 51/64 loss: -1.8921070098876953
Batch 52/64 loss: -2.180800437927246
Batch 53/64 loss: -1.6954536437988281
Batch 54/64 loss: -2.074090003967285
Batch 55/64 loss: -2.1727542877197266
Batch 56/64 loss: -2.213613510131836
Batch 57/64 loss: -2.0121030807495117
Batch 58/64 loss: -2.2261581420898438
Batch 59/64 loss: -2.174215316772461
Batch 60/64 loss: -1.540696144104004
Batch 61/64 loss: -2.1468753814697266
Batch 62/64 loss: -1.9335956573486328
Batch 63/64 loss: -2.2375431060791016
Batch 64/64 loss: -6.304255962371826
Epoch 302  Train loss: -2.14330275479485  Val loss: -2.4825539867492887
Epoch 303
-------------------------------
Batch 1/64 loss: -2.179079055786133
Batch 2/64 loss: -2.0221519470214844
Batch 3/64 loss: -2.304323673248291
Batch 4/64 loss: -2.0561981201171875
Batch 5/64 loss: -2.2493629455566406
Batch 6/64 loss: -2.153620719909668
Batch 7/64 loss: -2.2026681900024414
Batch 8/64 loss: -2.2001781463623047
Batch 9/64 loss: -2.089715003967285
Batch 10/64 loss: -2.2127504348754883
Batch 11/64 loss: -2.015486717224121
Batch 12/64 loss: -2.078305244445801
Batch 13/64 loss: -2.0947771072387695
Batch 14/64 loss: -2.3732919692993164
Batch 15/64 loss: -1.3330373764038086
Batch 16/64 loss: -2.1637277603149414
Batch 17/64 loss: -1.8053598403930664
Batch 18/64 loss: -2.0673580169677734
Batch 19/64 loss: -2.1455764770507812
Batch 20/64 loss: -1.599761962890625
Batch 21/64 loss: -2.4047927856445312
Batch 22/64 loss: -1.7590017318725586
Batch 23/64 loss: -2.2723941802978516
Batch 24/64 loss: -1.9848651885986328
Batch 25/64 loss: -2.2564697265625
Batch 26/64 loss: -2.1064300537109375
Batch 27/64 loss: -2.2481765747070312
Batch 28/64 loss: -2.10330867767334
Batch 29/64 loss: -1.9628162384033203
Batch 30/64 loss: -2.1859397888183594
Batch 31/64 loss: -1.9158287048339844
Batch 32/64 loss: -1.508749008178711
Batch 33/64 loss: -2.1065073013305664
Batch 34/64 loss: -2.2281789779663086
Batch 35/64 loss: -2.0959787368774414
Batch 36/64 loss: -2.112751007080078
Batch 37/64 loss: -2.0541276931762695
Batch 38/64 loss: -2.2049827575683594
Batch 39/64 loss: -2.152623176574707
Batch 40/64 loss: -2.0993032455444336
Batch 41/64 loss: -1.9801244735717773
Batch 42/64 loss: -2.099148750305176
Batch 43/64 loss: -2.2449493408203125
Batch 44/64 loss: -1.6694250106811523
Batch 45/64 loss: -2.189602851867676
Batch 46/64 loss: -1.9781150817871094
Batch 47/64 loss: -1.9228458404541016
Batch 48/64 loss: -2.020277976989746
Batch 49/64 loss: -2.301969528198242
Batch 50/64 loss: -2.167424201965332
Batch 51/64 loss: -2.1919240951538086
Batch 52/64 loss: -2.2213592529296875
Batch 53/64 loss: -2.141068458557129
Batch 54/64 loss: -2.283121109008789
Batch 55/64 loss: -2.221790313720703
Batch 56/64 loss: -2.154094696044922
Batch 57/64 loss: -2.1807994842529297
Batch 58/64 loss: -2.2811622619628906
Batch 59/64 loss: -2.049159049987793
Batch 60/64 loss: -2.029766082763672
Batch 61/64 loss: -2.0276975631713867
Batch 62/64 loss: -2.106997489929199
Batch 63/64 loss: -1.385584831237793
Batch 64/64 loss: -6.23306941986084
Epoch 303  Train loss: -2.127579075682397  Val loss: -2.47033733354811
Epoch 304
-------------------------------
Batch 1/64 loss: -1.8946962356567383
Batch 2/64 loss: -2.144341468811035
Batch 3/64 loss: -1.961318016052246
Batch 4/64 loss: -2.09405517578125
Batch 5/64 loss: -2.0589656829833984
Batch 6/64 loss: -2.0994462966918945
Batch 7/64 loss: -2.1687240600585938
Batch 8/64 loss: -2.2383785247802734
Batch 9/64 loss: -2.279639720916748
Batch 10/64 loss: -2.0400753021240234
Batch 11/64 loss: -2.1473331451416016
Batch 12/64 loss: -2.200181007385254
Batch 13/64 loss: -1.6870613098144531
Batch 14/64 loss: -1.9933280944824219
Batch 15/64 loss: -2.195460319519043
Batch 16/64 loss: -2.05515193939209
Batch 17/64 loss: -1.8092432022094727
Batch 18/64 loss: -2.2354230880737305
Batch 19/64 loss: -2.1687545776367188
Batch 20/64 loss: -2.131442070007324
Batch 21/64 loss: -2.161020278930664
Batch 22/64 loss: -2.1902694702148438
Batch 23/64 loss: -1.8945960998535156
Batch 24/64 loss: -2.0472822189331055
Batch 25/64 loss: -2.1747865676879883
Batch 26/64 loss: -2.387737274169922
Batch 27/64 loss: -2.2564754486083984
Batch 28/64 loss: -2.0126495361328125
Batch 29/64 loss: -1.9607505798339844
Batch 30/64 loss: -2.114654541015625
Batch 31/64 loss: -2.2188405990600586
Batch 32/64 loss: -2.089035987854004
Batch 33/64 loss: -2.117555618286133
Batch 34/64 loss: -2.124755859375
Batch 35/64 loss: -2.0377912521362305
Batch 36/64 loss: -2.12998104095459
Batch 37/64 loss: -2.205862045288086
Batch 38/64 loss: -1.9792957305908203
Batch 39/64 loss: -2.313052177429199
Batch 40/64 loss: -2.1542673110961914
Batch 41/64 loss: -2.2325944900512695
Batch 42/64 loss: -2.1116933822631836
Batch 43/64 loss: -1.466172218322754
Batch 44/64 loss: -2.1673803329467773
Batch 45/64 loss: -2.2808218002319336
Batch 46/64 loss: -1.5761280059814453
Batch 47/64 loss: -1.5009679794311523
Batch 48/64 loss: -2.106045722961426
Batch 49/64 loss: -2.307447910308838
Batch 50/64 loss: -1.383988380432129
Batch 51/64 loss: -2.3710269927978516
Batch 52/64 loss: -2.0532007217407227
Batch 53/64 loss: -2.167536735534668
Batch 54/64 loss: -1.7993946075439453
Batch 55/64 loss: -2.2518720626831055
Batch 56/64 loss: -2.1303234100341797
Batch 57/64 loss: -2.069723129272461
Batch 58/64 loss: -2.085103988647461
Batch 59/64 loss: -2.140604019165039
Batch 60/64 loss: -1.9638299942016602
Batch 61/64 loss: -1.3767890930175781
Batch 62/64 loss: -1.5613269805908203
Batch 63/64 loss: -2.0890846252441406
Batch 64/64 loss: -6.501730918884277
Epoch 304  Train loss: -2.1057730768241134  Val loss: -2.3972831018192253
Epoch 305
-------------------------------
Batch 1/64 loss: -2.1256837844848633
Batch 2/64 loss: -2.133791923522949
Batch 3/64 loss: -2.0834503173828125
Batch 4/64 loss: -2.0880327224731445
Batch 5/64 loss: -2.0630369186401367
Batch 6/64 loss: -2.101480484008789
Batch 7/64 loss: -2.3431758880615234
Batch 8/64 loss: -1.9652719497680664
Batch 9/64 loss: -2.078920364379883
Batch 10/64 loss: -2.2809295654296875
Batch 11/64 loss: -1.5124988555908203
Batch 12/64 loss: -2.2130050659179688
Batch 13/64 loss: -2.2297534942626953
Batch 14/64 loss: -1.9065361022949219
Batch 15/64 loss: -1.9540863037109375
Batch 16/64 loss: -1.7307548522949219
Batch 17/64 loss: -2.189359664916992
Batch 18/64 loss: -2.0543527603149414
Batch 19/64 loss: -2.2963504791259766
Batch 20/64 loss: -1.5750446319580078
Batch 21/64 loss: -2.0423355102539062
Batch 22/64 loss: -2.188589096069336
Batch 23/64 loss: -2.1345701217651367
Batch 24/64 loss: -2.1857128143310547
Batch 25/64 loss: -2.003683090209961
Batch 26/64 loss: -1.3058528900146484
Batch 27/64 loss: -1.7094316482543945
Batch 28/64 loss: -1.7549018859863281
Batch 29/64 loss: -2.111562728881836
Batch 30/64 loss: -2.0819015502929688
Batch 31/64 loss: -1.9396705627441406
Batch 32/64 loss: -2.0734024047851562
Batch 33/64 loss: -2.057805061340332
Batch 34/64 loss: -1.6820430755615234
Batch 35/64 loss: -2.1648855209350586
Batch 36/64 loss: -2.117532730102539
Batch 37/64 loss: -2.15596866607666
Batch 38/64 loss: -1.9896316528320312
Batch 39/64 loss: -1.6406183242797852
Batch 40/64 loss: -1.9578781127929688
Batch 41/64 loss: -2.4237680435180664
Batch 42/64 loss: -2.0485429763793945
Batch 43/64 loss: -2.1742477416992188
Batch 44/64 loss: -1.2123584747314453
Batch 45/64 loss: -2.246265411376953
Batch 46/64 loss: -2.0076589584350586
Batch 47/64 loss: -2.093316078186035
Batch 48/64 loss: -2.0246944427490234
Batch 49/64 loss: -2.0721988677978516
Batch 50/64 loss: -2.2581310272216797
Batch 51/64 loss: -2.3052029609680176
Batch 52/64 loss: -2.1698951721191406
Batch 53/64 loss: -1.777573585510254
Batch 54/64 loss: -2.1116886138916016
Batch 55/64 loss: -2.2179036140441895
Batch 56/64 loss: -2.174701690673828
Batch 57/64 loss: -1.9496536254882812
Batch 58/64 loss: -2.01418399810791
Batch 59/64 loss: -2.2199840545654297
Batch 60/64 loss: -2.250674247741699
Batch 61/64 loss: -2.1113996505737305
Batch 62/64 loss: -2.1376123428344727
Batch 63/64 loss: -2.218979835510254
Batch 64/64 loss: -6.524013996124268
Epoch 305  Train loss: -2.091562972349279  Val loss: -2.4141958833150436
Epoch 306
-------------------------------
Batch 1/64 loss: -2.0199060440063477
Batch 2/64 loss: -1.9895448684692383
Batch 3/64 loss: -1.9246759414672852
Batch 4/64 loss: -2.363011360168457
Batch 5/64 loss: -1.6167325973510742
Batch 6/64 loss: -1.8542556762695312
Batch 7/64 loss: -2.0237112045288086
Batch 8/64 loss: -2.047811508178711
Batch 9/64 loss: -2.093247413635254
Batch 10/64 loss: -2.080080986022949
Batch 11/64 loss: -2.206326484680176
Batch 12/64 loss: -1.7023811340332031
Batch 13/64 loss: -1.736180305480957
Batch 14/64 loss: -1.5891132354736328
Batch 15/64 loss: -1.9985971450805664
Batch 16/64 loss: -2.1201858520507812
Batch 17/64 loss: -1.5965852737426758
Batch 18/64 loss: -1.951272964477539
Batch 19/64 loss: -1.9715070724487305
Batch 20/64 loss: -1.9544296264648438
Batch 21/64 loss: -2.0832290649414062
Batch 22/64 loss: -1.9412860870361328
Batch 23/64 loss: -2.147068977355957
Batch 24/64 loss: -1.9576492309570312
Batch 25/64 loss: -2.0420541763305664
Batch 26/64 loss: -1.8912315368652344
Batch 27/64 loss: -1.8580236434936523
Batch 28/64 loss: -2.0563554763793945
Batch 29/64 loss: -2.0231924057006836
Batch 30/64 loss: -1.9863357543945312
Batch 31/64 loss: -1.8599138259887695
Batch 32/64 loss: -1.8282442092895508
Batch 33/64 loss: -1.7004756927490234
Batch 34/64 loss: -2.1452770233154297
Batch 35/64 loss: -1.7046489715576172
Batch 36/64 loss: -1.4344406127929688
Batch 37/64 loss: -2.092317581176758
Batch 38/64 loss: -1.8901100158691406
Batch 39/64 loss: -1.9171018600463867
Batch 40/64 loss: -2.0333614349365234
Batch 41/64 loss: -2.0106544494628906
Batch 42/64 loss: -2.0508499145507812
Batch 43/64 loss: -1.971135139465332
Batch 44/64 loss: -1.9852790832519531
Batch 45/64 loss: -1.982828140258789
Batch 46/64 loss: -2.1554031372070312
Batch 47/64 loss: -2.2684245109558105
Batch 48/64 loss: -2.0729923248291016
Batch 49/64 loss: -2.1014060974121094
Batch 50/64 loss: -2.0477895736694336
Batch 51/64 loss: -2.1450719833374023
Batch 52/64 loss: -2.182159423828125
Batch 53/64 loss: -2.1724252700805664
Batch 54/64 loss: -2.159482002258301
Batch 55/64 loss: -1.986638069152832
Batch 56/64 loss: -1.8296489715576172
Batch 57/64 loss: -2.010748863220215
Batch 58/64 loss: -2.1597442626953125
Batch 59/64 loss: -1.9973526000976562
Batch 60/64 loss: -1.272409439086914
Batch 61/64 loss: -2.105905532836914
Batch 62/64 loss: -1.9487104415893555
Batch 63/64 loss: -1.8892154693603516
Batch 64/64 loss: -6.1881866455078125
Epoch 306  Train loss: -2.0169300228941673  Val loss: -2.329583354831971
Epoch 307
-------------------------------
Batch 1/64 loss: -2.2427244186401367
Batch 2/64 loss: -1.4269685745239258
Batch 3/64 loss: -1.7009410858154297
Batch 4/64 loss: -2.1130075454711914
Batch 5/64 loss: -1.9237756729125977
Batch 6/64 loss: -2.02768611907959
Batch 7/64 loss: -2.278021812438965
Batch 8/64 loss: -1.6621179580688477
Batch 9/64 loss: -2.0884227752685547
Batch 10/64 loss: -2.072747230529785
Batch 11/64 loss: -2.1400699615478516
Batch 12/64 loss: -0.9077625274658203
Batch 13/64 loss: -1.7632389068603516
Batch 14/64 loss: -1.672358512878418
Batch 15/64 loss: -2.08603572845459
Batch 16/64 loss: -1.882349967956543
Batch 17/64 loss: -1.8028478622436523
Batch 18/64 loss: -1.9605016708374023
Batch 19/64 loss: -1.9216842651367188
Batch 20/64 loss: -2.1148452758789062
Batch 21/64 loss: -2.035045623779297
Batch 22/64 loss: -2.031487464904785
Batch 23/64 loss: -2.0747365951538086
Batch 24/64 loss: -2.279038429260254
Batch 25/64 loss: -2.1076669692993164
Batch 26/64 loss: -2.242701530456543
Batch 27/64 loss: -2.361715793609619
Batch 28/64 loss: -2.005345344543457
Batch 29/64 loss: -2.1886119842529297
Batch 30/64 loss: -1.991220474243164
Batch 31/64 loss: -2.192098617553711
Batch 32/64 loss: -1.3523311614990234
Batch 33/64 loss: -2.269977569580078
Batch 34/64 loss: -2.1634597778320312
Batch 35/64 loss: -1.5336437225341797
Batch 36/64 loss: -1.8595695495605469
Batch 37/64 loss: -1.9331445693969727
Batch 38/64 loss: -1.9475831985473633
Batch 39/64 loss: -2.1044254302978516
Batch 40/64 loss: -1.7128839492797852
Batch 41/64 loss: -2.1094436645507812
Batch 42/64 loss: -2.1268606185913086
Batch 43/64 loss: -1.765629768371582
Batch 44/64 loss: -2.049428939819336
Batch 45/64 loss: -2.058694839477539
Batch 46/64 loss: -2.2580976486206055
Batch 47/64 loss: -1.7971172332763672
Batch 48/64 loss: -1.994283676147461
Batch 49/64 loss: -2.1384143829345703
Batch 50/64 loss: -1.915816307067871
Batch 51/64 loss: -2.088040351867676
Batch 52/64 loss: -1.9307136535644531
Batch 53/64 loss: -2.1749658584594727
Batch 54/64 loss: -2.1665868759155273
Batch 55/64 loss: -2.241495132446289
Batch 56/64 loss: -2.1821794509887695
Batch 57/64 loss: -1.8478899002075195
Batch 58/64 loss: -2.40224552154541
Batch 59/64 loss: -1.977569580078125
Batch 60/64 loss: -2.312950611114502
Batch 61/64 loss: -1.8343868255615234
Batch 62/64 loss: -2.0651960372924805
Batch 63/64 loss: -2.057279586791992
Batch 64/64 loss: -6.379321098327637
Epoch 307  Train loss: -2.046346241820092  Val loss: -2.2664551489131965
Epoch 308
-------------------------------
Batch 1/64 loss: -1.5203132629394531
Batch 2/64 loss: -2.057267189025879
Batch 3/64 loss: -1.9559297561645508
Batch 4/64 loss: -2.0836849212646484
Batch 5/64 loss: -1.7632436752319336
Batch 6/64 loss: -2.198197364807129
Batch 7/64 loss: -2.3399152755737305
Batch 8/64 loss: -1.8904972076416016
Batch 9/64 loss: -2.1275510787963867
Batch 10/64 loss: -1.790945053100586
Batch 11/64 loss: -1.9511356353759766
Batch 12/64 loss: -2.0737972259521484
Batch 13/64 loss: -1.5222387313842773
Batch 14/64 loss: -1.7886390686035156
Batch 15/64 loss: -1.4609880447387695
Batch 16/64 loss: -1.700357437133789
Batch 17/64 loss: -2.0418033599853516
Batch 18/64 loss: -2.1892290115356445
Batch 19/64 loss: -1.7134027481079102
Batch 20/64 loss: -2.1629905700683594
Batch 21/64 loss: -1.6595439910888672
Batch 22/64 loss: -2.0249996185302734
Batch 23/64 loss: -1.8920726776123047
Batch 24/64 loss: -1.9822072982788086
Batch 25/64 loss: -2.0839195251464844
Batch 26/64 loss: -2.0872602462768555
Batch 27/64 loss: -2.2250871658325195
Batch 28/64 loss: -2.2198190689086914
Batch 29/64 loss: -1.4109392166137695
Batch 30/64 loss: -2.1324901580810547
Batch 31/64 loss: -1.9589614868164062
Batch 32/64 loss: -2.1039419174194336
Batch 33/64 loss: -2.068431854248047
Batch 34/64 loss: -2.139857292175293
Batch 35/64 loss: -2.0965728759765625
Batch 36/64 loss: -1.9414997100830078
Batch 37/64 loss: -2.1301536560058594
Batch 38/64 loss: -2.08394718170166
Batch 39/64 loss: -2.28702974319458
Batch 40/64 loss: -2.1076011657714844
Batch 41/64 loss: -2.2426490783691406
Batch 42/64 loss: -2.146087646484375
Batch 43/64 loss: -2.0556869506835938
Batch 44/64 loss: -1.979659080505371
Batch 45/64 loss: -2.127791404724121
Batch 46/64 loss: -1.9779138565063477
Batch 47/64 loss: -2.360276222229004
Batch 48/64 loss: -2.1208486557006836
Batch 49/64 loss: -2.0940418243408203
Batch 50/64 loss: -2.1716041564941406
Batch 51/64 loss: -1.657761573791504
Batch 52/64 loss: -1.4097356796264648
Batch 53/64 loss: -1.531667709350586
Batch 54/64 loss: -2.001667022705078
Batch 55/64 loss: -1.9855737686157227
Batch 56/64 loss: -1.9797821044921875
Batch 57/64 loss: -2.053462028503418
Batch 58/64 loss: -1.892735481262207
Batch 59/64 loss: -1.976283073425293
Batch 60/64 loss: -1.7652225494384766
Batch 61/64 loss: -2.0625343322753906
Batch 62/64 loss: -2.1229896545410156
Batch 63/64 loss: -2.163212776184082
Batch 64/64 loss: -5.6296186447143555
Epoch 308  Train loss: -2.0246253032310335  Val loss: -2.3306194187439595
Epoch 309
-------------------------------
Batch 1/64 loss: -1.5505752563476562
Batch 2/64 loss: -2.0330324172973633
Batch 3/64 loss: -1.8822994232177734
Batch 4/64 loss: -1.9717464447021484
Batch 5/64 loss: -2.172311782836914
Batch 6/64 loss: -2.020766258239746
Batch 7/64 loss: -2.125150680541992
Batch 8/64 loss: -2.060976982116699
Batch 9/64 loss: -2.067068099975586
Batch 10/64 loss: -2.0307207107543945
Batch 11/64 loss: -2.205876350402832
Batch 12/64 loss: -2.0776824951171875
Batch 13/64 loss: -1.9957075119018555
Batch 14/64 loss: -2.283085823059082
Batch 15/64 loss: -2.076181411743164
Batch 16/64 loss: -2.1611404418945312
Batch 17/64 loss: -2.0972700119018555
Batch 18/64 loss: -1.8113574981689453
Batch 19/64 loss: -1.9586305618286133
Batch 20/64 loss: -2.0942983627319336
Batch 21/64 loss: -2.1513547897338867
Batch 22/64 loss: -1.8992252349853516
Batch 23/64 loss: -2.267354965209961
Batch 24/64 loss: -2.193181037902832
Batch 25/64 loss: -2.0870513916015625
Batch 26/64 loss: -1.5237369537353516
Batch 27/64 loss: -2.158100128173828
Batch 28/64 loss: -2.0936355590820312
Batch 29/64 loss: -2.2370119094848633
Batch 30/64 loss: -2.1529369354248047
Batch 31/64 loss: -2.143993377685547
Batch 32/64 loss: -1.4418554306030273
Batch 33/64 loss: -2.0939207077026367
Batch 34/64 loss: -2.284554958343506
Batch 35/64 loss: -1.9581718444824219
Batch 36/64 loss: -1.6152420043945312
Batch 37/64 loss: -1.4699554443359375
Batch 38/64 loss: -1.8816251754760742
Batch 39/64 loss: -2.123371124267578
Batch 40/64 loss: -2.1695642471313477
Batch 41/64 loss: -2.0870189666748047
Batch 42/64 loss: -1.493692398071289
Batch 43/64 loss: -2.025935173034668
Batch 44/64 loss: -1.934218406677246
Batch 45/64 loss: -1.961991310119629
Batch 46/64 loss: -2.0991039276123047
Batch 47/64 loss: -2.0598230361938477
Batch 48/64 loss: -2.1160526275634766
Batch 49/64 loss: -1.5076713562011719
Batch 50/64 loss: -2.2364377975463867
Batch 51/64 loss: -1.788858413696289
Batch 52/64 loss: -2.2530784606933594
Batch 53/64 loss: -2.170468330383301
Batch 54/64 loss: -2.271243095397949
Batch 55/64 loss: -2.206331253051758
Batch 56/64 loss: -2.039083480834961
Batch 57/64 loss: -2.140268325805664
Batch 58/64 loss: -2.2386035919189453
Batch 59/64 loss: -2.3545875549316406
Batch 60/64 loss: -1.834808349609375
Batch 61/64 loss: -2.280135154724121
Batch 62/64 loss: -2.0884532928466797
Batch 63/64 loss: -2.0882186889648438
Batch 64/64 loss: -6.354349136352539
Epoch 309  Train loss: -2.080997122970282  Val loss: -2.27728945283136
Epoch 310
-------------------------------
Batch 1/64 loss: -2.31640625
Batch 2/64 loss: -2.218240737915039
Batch 3/64 loss: -2.0621843338012695
Batch 4/64 loss: -1.6845617294311523
Batch 5/64 loss: -2.113591194152832
Batch 6/64 loss: -2.1945295333862305
Batch 7/64 loss: -2.2310256958007812
Batch 8/64 loss: -1.3936357498168945
Batch 9/64 loss: -1.82940673828125
Batch 10/64 loss: -1.9029417037963867
Batch 11/64 loss: -2.129805564880371
Batch 12/64 loss: -2.0429515838623047
Batch 13/64 loss: -2.224935531616211
Batch 14/64 loss: -2.0677080154418945
Batch 15/64 loss: -2.2321672439575195
Batch 16/64 loss: -2.1288833618164062
Batch 17/64 loss: -1.8273591995239258
Batch 18/64 loss: -2.2470712661743164
Batch 19/64 loss: -2.1136484146118164
Batch 20/64 loss: -1.0982789993286133
Batch 21/64 loss: -1.8377199172973633
Batch 22/64 loss: -2.394343376159668
Batch 23/64 loss: -2.024759292602539
Batch 24/64 loss: -2.1185245513916016
Batch 25/64 loss: -1.9749011993408203
Batch 26/64 loss: -1.6819076538085938
Batch 27/64 loss: -1.8490304946899414
Batch 28/64 loss: -1.8942232131958008
Batch 29/64 loss: -2.197183609008789
Batch 30/64 loss: -2.1272172927856445
Batch 31/64 loss: -1.8146076202392578
Batch 32/64 loss: -2.245145797729492
Batch 33/64 loss: -1.8399076461791992
Batch 34/64 loss: -2.218780517578125
Batch 35/64 loss: -2.110032081604004
Batch 36/64 loss: -2.236964225769043
Batch 37/64 loss: -2.029815673828125
Batch 38/64 loss: -2.064408302307129
Batch 39/64 loss: -2.018848419189453
Batch 40/64 loss: -2.1272830963134766
Batch 41/64 loss: -1.8102960586547852
Batch 42/64 loss: -2.174844741821289
Batch 43/64 loss: -2.0903310775756836
Batch 44/64 loss: -1.7690849304199219
Batch 45/64 loss: -1.9993295669555664
Batch 46/64 loss: -1.9378910064697266
Batch 47/64 loss: -2.0198936462402344
Batch 48/64 loss: -1.9437637329101562
Batch 49/64 loss: -1.9226627349853516
Batch 50/64 loss: -2.3490028381347656
Batch 51/64 loss: -1.7926130294799805
Batch 52/64 loss: -2.082578659057617
Batch 53/64 loss: -2.108067512512207
Batch 54/64 loss: -2.1974878311157227
Batch 55/64 loss: -1.7394418716430664
Batch 56/64 loss: -2.0886144638061523
Batch 57/64 loss: -2.2721786499023438
Batch 58/64 loss: -1.6314420700073242
Batch 59/64 loss: -1.8922185897827148
Batch 60/64 loss: -1.649505615234375
Batch 61/64 loss: -2.061037063598633
Batch 62/64 loss: -1.8230266571044922
Batch 63/64 loss: -2.1998443603515625
Batch 64/64 loss: -6.179458141326904
Epoch 310  Train loss: -2.0557597983117195  Val loss: -2.1996853228696844
Epoch 311
-------------------------------
Batch 1/64 loss: -2.1831626892089844
Batch 2/64 loss: -2.031073570251465
Batch 3/64 loss: -2.0230588912963867
Batch 4/64 loss: -1.5639886856079102
Batch 5/64 loss: -2.3259520530700684
Batch 6/64 loss: -2.235508918762207
Batch 7/64 loss: -2.2600536346435547
Batch 8/64 loss: -2.001053810119629
Batch 9/64 loss: -2.2982068061828613
Batch 10/64 loss: -2.01778507232666
Batch 11/64 loss: -2.2529802322387695
Batch 12/64 loss: -2.0421218872070312
Batch 13/64 loss: -1.5127630233764648
Batch 14/64 loss: -1.7766637802124023
Batch 15/64 loss: -2.1628808975219727
Batch 16/64 loss: -2.091120719909668
Batch 17/64 loss: -2.0199460983276367
Batch 18/64 loss: -1.8609933853149414
Batch 19/64 loss: -1.9636402130126953
Batch 20/64 loss: -2.0419692993164062
Batch 21/64 loss: -2.096353530883789
Batch 22/64 loss: -1.9222478866577148
Batch 23/64 loss: -2.095158576965332
Batch 24/64 loss: -1.7070035934448242
Batch 25/64 loss: -1.9723587036132812
Batch 26/64 loss: -1.7220382690429688
Batch 27/64 loss: -2.0524959564208984
Batch 28/64 loss: -1.7745208740234375
Batch 29/64 loss: -2.087815284729004
Batch 30/64 loss: -1.3024206161499023
Batch 31/64 loss: -1.8135490417480469
Batch 32/64 loss: -1.9553184509277344
Batch 33/64 loss: -2.0826234817504883
Batch 34/64 loss: -1.9766359329223633
Batch 35/64 loss: -2.3139266967773438
Batch 36/64 loss: -1.2743377685546875
Batch 37/64 loss: -2.144650459289551
Batch 38/64 loss: -2.296797752380371
Batch 39/64 loss: -2.169525146484375
Batch 40/64 loss: -1.794142723083496
Batch 41/64 loss: -1.896697998046875
Batch 42/64 loss: -1.653975486755371
Batch 43/64 loss: -1.5199470520019531
Batch 44/64 loss: -2.10537052154541
Batch 45/64 loss: -2.1000757217407227
Batch 46/64 loss: -2.19606876373291
Batch 47/64 loss: -2.2509570121765137
Batch 48/64 loss: -2.28676176071167
Batch 49/64 loss: -2.100926399230957
Batch 50/64 loss: -2.0149288177490234
Batch 51/64 loss: -2.195736885070801
Batch 52/64 loss: -2.2345314025878906
Batch 53/64 loss: -2.0667200088500977
Batch 54/64 loss: -1.9861392974853516
Batch 55/64 loss: -1.9389839172363281
Batch 56/64 loss: -1.758096694946289
Batch 57/64 loss: -1.7330741882324219
Batch 58/64 loss: -2.138528823852539
Batch 59/64 loss: -1.5772275924682617
Batch 60/64 loss: -2.2222533226013184
Batch 61/64 loss: -2.0073938369750977
Batch 62/64 loss: -1.3828134536743164
Batch 63/64 loss: -1.820871353149414
Batch 64/64 loss: -6.201100826263428
Epoch 311  Train loss: -2.0244352995180614  Val loss: -2.2940732556110395
Epoch 312
-------------------------------
Batch 1/64 loss: -2.3190550804138184
Batch 2/64 loss: -2.1450319290161133
Batch 3/64 loss: -1.870112419128418
Batch 4/64 loss: -1.9589004516601562
Batch 5/64 loss: -2.186709403991699
Batch 6/64 loss: -2.0073251724243164
Batch 7/64 loss: -2.226327896118164
Batch 8/64 loss: -2.1674633026123047
Batch 9/64 loss: -2.0972461700439453
Batch 10/64 loss: -2.0886173248291016
Batch 11/64 loss: -2.143691062927246
Batch 12/64 loss: -2.0802764892578125
Batch 13/64 loss: -2.2120189666748047
Batch 14/64 loss: -2.074009895324707
Batch 15/64 loss: -1.982757568359375
Batch 16/64 loss: -2.0522823333740234
Batch 17/64 loss: -2.0442638397216797
Batch 18/64 loss: -2.084705352783203
Batch 19/64 loss: -1.6016731262207031
Batch 20/64 loss: -1.6731681823730469
Batch 21/64 loss: -2.1062374114990234
Batch 22/64 loss: -1.8831853866577148
Batch 23/64 loss: -2.1446752548217773
Batch 24/64 loss: -2.277568817138672
Batch 25/64 loss: -2.046605110168457
Batch 26/64 loss: -2.084183692932129
Batch 27/64 loss: -2.2685422897338867
Batch 28/64 loss: -1.329237937927246
Batch 29/64 loss: -2.1834402084350586
Batch 30/64 loss: -2.1344375610351562
Batch 31/64 loss: -2.0303354263305664
Batch 32/64 loss: -2.3442444801330566
Batch 33/64 loss: -1.8945989608764648
Batch 34/64 loss: -2.1512222290039062
Batch 35/64 loss: -2.0473861694335938
Batch 36/64 loss: -2.103729248046875
Batch 37/64 loss: -1.0336837768554688
Batch 38/64 loss: -2.105158805847168
Batch 39/64 loss: -2.143092155456543
Batch 40/64 loss: -2.3230342864990234
Batch 41/64 loss: -2.004979133605957
Batch 42/64 loss: -2.2115602493286133
Batch 43/64 loss: -2.088409423828125
Batch 44/64 loss: -2.0787782669067383
Batch 45/64 loss: -2.075758934020996
Batch 46/64 loss: -2.2370119094848633
Batch 47/64 loss: -1.9943008422851562
Batch 48/64 loss: -2.331455707550049
Batch 49/64 loss: -1.8403863906860352
Batch 50/64 loss: -2.023472785949707
Batch 51/64 loss: -1.6860895156860352
Batch 52/64 loss: -1.996739387512207
Batch 53/64 loss: -1.9654855728149414
Batch 54/64 loss: -2.103792190551758
Batch 55/64 loss: -2.1402101516723633
Batch 56/64 loss: -1.7385129928588867
Batch 57/64 loss: -1.680109977722168
Batch 58/64 loss: -2.198904037475586
Batch 59/64 loss: -2.1493606567382812
Batch 60/64 loss: -1.3234987258911133
Batch 61/64 loss: -1.8771896362304688
Batch 62/64 loss: -2.1076202392578125
Batch 63/64 loss: -2.0141544342041016
Batch 64/64 loss: -6.358590126037598
Epoch 312  Train loss: -2.07508955188826  Val loss: -2.395829059823682
Epoch 313
-------------------------------
Batch 1/64 loss: -2.1066083908081055
Batch 2/64 loss: -2.0069026947021484
Batch 3/64 loss: -2.0873184204101562
Batch 4/64 loss: -2.1648550033569336
Batch 5/64 loss: -2.0730209350585938
Batch 6/64 loss: -1.804396629333496
Batch 7/64 loss: -2.210071563720703
Batch 8/64 loss: -2.2834091186523438
Batch 9/64 loss: -2.2287025451660156
Batch 10/64 loss: -2.1761598587036133
Batch 11/64 loss: -1.9192495346069336
Batch 12/64 loss: -1.8021049499511719
Batch 13/64 loss: -2.0584182739257812
Batch 14/64 loss: -2.188023567199707
Batch 15/64 loss: -1.7904329299926758
Batch 16/64 loss: -2.147571563720703
Batch 17/64 loss: -2.048394203186035
Batch 18/64 loss: -1.8693571090698242
Batch 19/64 loss: -1.8679170608520508
Batch 20/64 loss: -1.9996700286865234
Batch 21/64 loss: -1.8465261459350586
Batch 22/64 loss: -2.2404584884643555
Batch 23/64 loss: -2.2321290969848633
Batch 24/64 loss: -1.9524478912353516
Batch 25/64 loss: -1.9969682693481445
Batch 26/64 loss: -2.017949104309082
Batch 27/64 loss: -2.0321550369262695
Batch 28/64 loss: -1.858072280883789
Batch 29/64 loss: -1.511922836303711
Batch 30/64 loss: -1.722315788269043
Batch 31/64 loss: -2.105210304260254
Batch 32/64 loss: -1.8833398818969727
Batch 33/64 loss: -1.5522527694702148
Batch 34/64 loss: -1.4098453521728516
Batch 35/64 loss: -1.6683053970336914
Batch 36/64 loss: -1.8580961227416992
Batch 37/64 loss: -2.0064144134521484
Batch 38/64 loss: -1.5322418212890625
Batch 39/64 loss: -1.900299072265625
Batch 40/64 loss: -1.8076257705688477
Batch 41/64 loss: -1.895920753479004
Batch 42/64 loss: -1.92425537109375
Batch 43/64 loss: -1.900435447692871
Batch 44/64 loss: -1.0583457946777344
Batch 45/64 loss: -1.4332380294799805
Batch 46/64 loss: -1.827153205871582
Batch 47/64 loss: -1.6299753189086914
Batch 48/64 loss: -1.970754623413086
Batch 49/64 loss: -2.0406455993652344
Batch 50/64 loss: -1.313136100769043
Batch 51/64 loss: -1.9087772369384766
Batch 52/64 loss: -1.7688684463500977
Batch 53/64 loss: -1.857996940612793
Batch 54/64 loss: -1.7926158905029297
Batch 55/64 loss: -1.6341962814331055
Batch 56/64 loss: -1.8245458602905273
Batch 57/64 loss: -1.8687410354614258
Batch 58/64 loss: -1.4978227615356445
Batch 59/64 loss: -1.8348026275634766
Batch 60/64 loss: -1.530348777770996
Batch 61/64 loss: -1.9960269927978516
Batch 62/64 loss: -1.5378408432006836
Batch 63/64 loss: -2.0402164459228516
Batch 64/64 loss: -6.229786396026611
Epoch 313  Train loss: -1.925116241679472  Val loss: -2.0473232334831737
Epoch 314
-------------------------------
Batch 1/64 loss: -1.625035285949707
Batch 2/64 loss: -2.1112422943115234
Batch 3/64 loss: -1.7123832702636719
Batch 4/64 loss: -2.0591392517089844
Batch 5/64 loss: -1.8340559005737305
Batch 6/64 loss: -1.8873023986816406
Batch 7/64 loss: -1.8270597457885742
Batch 8/64 loss: -1.7984809875488281
Batch 9/64 loss: -2.081329345703125
Batch 10/64 loss: -1.3945636749267578
Batch 11/64 loss: -2.184774398803711
Batch 12/64 loss: -2.0016183853149414
Batch 13/64 loss: -1.718277931213379
Batch 14/64 loss: -2.164461135864258
Batch 15/64 loss: -1.9627561569213867
Batch 16/64 loss: -1.9396896362304688
Batch 17/64 loss: -2.107344627380371
Batch 18/64 loss: -1.9383764266967773
Batch 19/64 loss: -2.2982826232910156
Batch 20/64 loss: -2.1962852478027344
Batch 21/64 loss: -2.359661102294922
Batch 22/64 loss: -2.3815650939941406
Batch 23/64 loss: -1.918625831604004
Batch 24/64 loss: -2.28311824798584
Batch 25/64 loss: -2.176579475402832
Batch 26/64 loss: -2.205629348754883
Batch 27/64 loss: -2.16605281829834
Batch 28/64 loss: -2.197831153869629
Batch 29/64 loss: -2.3296031951904297
Batch 30/64 loss: -2.2599658966064453
Batch 31/64 loss: -2.227691650390625
Batch 32/64 loss: -2.2799649238586426
Batch 33/64 loss: -1.6966896057128906
Batch 34/64 loss: -1.6258811950683594
Batch 35/64 loss: -2.120785713195801
Batch 36/64 loss: -2.0856542587280273
Batch 37/64 loss: -2.097574234008789
Batch 38/64 loss: -2.1690635681152344
Batch 39/64 loss: -2.226776123046875
Batch 40/64 loss: -1.9398994445800781
Batch 41/64 loss: -2.193934440612793
Batch 42/64 loss: -2.06771183013916
Batch 43/64 loss: -2.0522851943969727
Batch 44/64 loss: -2.3868541717529297
Batch 45/64 loss: -1.7105865478515625
Batch 46/64 loss: -2.32525634765625
Batch 47/64 loss: -2.225430488586426
Batch 48/64 loss: -2.2420434951782227
Batch 49/64 loss: -2.2480573654174805
Batch 50/64 loss: -1.9670648574829102
Batch 51/64 loss: -2.2094593048095703
Batch 52/64 loss: -2.0241384506225586
Batch 53/64 loss: -2.381845474243164
Batch 54/64 loss: -2.2360525131225586
Batch 55/64 loss: -2.325881004333496
Batch 56/64 loss: -2.2647695541381836
Batch 57/64 loss: -2.2308120727539062
Batch 58/64 loss: -2.1449413299560547
Batch 59/64 loss: -2.336963176727295
Batch 60/64 loss: -2.0788745880126953
Batch 61/64 loss: -2.463527202606201
Batch 62/64 loss: -2.1637916564941406
Batch 63/64 loss: -2.175570487976074
Batch 64/64 loss: -6.2403717041015625
Epoch 314  Train loss: -2.144740422566732  Val loss: -2.5528786125052014
Epoch 315
-------------------------------
Batch 1/64 loss: -2.280644416809082
Batch 2/64 loss: -2.280702590942383
Batch 3/64 loss: -2.3213424682617188
Batch 4/64 loss: -2.369124412536621
Batch 5/64 loss: -2.2594070434570312
Batch 6/64 loss: -2.5124783515930176
Batch 7/64 loss: -2.3134918212890625
Batch 8/64 loss: -2.2870969772338867
Batch 9/64 loss: -2.2751340866088867
Batch 10/64 loss: -2.189603805541992
Batch 11/64 loss: -2.2629833221435547
Batch 12/64 loss: -2.209789276123047
Batch 13/64 loss: -2.12998104095459
Batch 14/64 loss: -2.1722917556762695
Batch 15/64 loss: -1.9482965469360352
Batch 16/64 loss: -1.9265871047973633
Batch 17/64 loss: -2.349057674407959
Batch 18/64 loss: -2.323970317840576
Batch 19/64 loss: -1.9773483276367188
Batch 20/64 loss: -1.611562728881836
Batch 21/64 loss: -2.323746681213379
Batch 22/64 loss: -1.9743690490722656
Batch 23/64 loss: -2.43388032913208
Batch 24/64 loss: -2.283379554748535
Batch 25/64 loss: -2.062976837158203
Batch 26/64 loss: -2.280378818511963
Batch 27/64 loss: -1.502192497253418
Batch 28/64 loss: -2.363769054412842
Batch 29/64 loss: -2.2166271209716797
Batch 30/64 loss: -1.405996322631836
Batch 31/64 loss: -2.2145795822143555
Batch 32/64 loss: -2.4118261337280273
Batch 33/64 loss: -2.3175225257873535
Batch 34/64 loss: -2.029271125793457
Batch 35/64 loss: -1.8265838623046875
Batch 36/64 loss: -2.0108442306518555
Batch 37/64 loss: -2.097784996032715
Batch 38/64 loss: -2.3360977172851562
Batch 39/64 loss: -2.253054618835449
Batch 40/64 loss: -2.066255569458008
Batch 41/64 loss: -2.1378955841064453
Batch 42/64 loss: -2.098173141479492
Batch 43/64 loss: -1.9301433563232422
Batch 44/64 loss: -2.2336578369140625
Batch 45/64 loss: -2.2364063262939453
Batch 46/64 loss: -2.1538219451904297
Batch 47/64 loss: -2.287430763244629
Batch 48/64 loss: -2.2264280319213867
Batch 49/64 loss: -2.063187599182129
Batch 50/64 loss: -2.208669662475586
Batch 51/64 loss: -2.2758054733276367
Batch 52/64 loss: -2.2557826042175293
Batch 53/64 loss: -1.9236602783203125
Batch 54/64 loss: -2.209622383117676
Batch 55/64 loss: -2.2894725799560547
Batch 56/64 loss: -2.18865966796875
Batch 57/64 loss: -2.269693374633789
Batch 58/64 loss: -2.116453170776367
Batch 59/64 loss: -2.4291367530822754
Batch 60/64 loss: -2.316019058227539
Batch 61/64 loss: -2.370115280151367
Batch 62/64 loss: -2.0406713485717773
Batch 63/64 loss: -2.3148484230041504
Batch 64/64 loss: -6.440930366516113
Epoch 315  Train loss: -2.224603656694001  Val loss: -2.5426362814362515
Epoch 316
-------------------------------
Batch 1/64 loss: -2.3844027519226074
Batch 2/64 loss: -2.279566764831543
Batch 3/64 loss: -2.1821746826171875
Batch 4/64 loss: -2.1611175537109375
Batch 5/64 loss: -2.266552448272705
Batch 6/64 loss: -2.2707948684692383
Batch 7/64 loss: -2.1136083602905273
Batch 8/64 loss: -2.016554832458496
Batch 9/64 loss: -2.284726619720459
Batch 10/64 loss: -2.0582075119018555
Batch 11/64 loss: -2.181995391845703
Batch 12/64 loss: -2.2133560180664062
Batch 13/64 loss: -2.1028738021850586
Batch 14/64 loss: -2.117588996887207
Batch 15/64 loss: -1.544271469116211
Batch 16/64 loss: -1.982661247253418
Batch 17/64 loss: -2.067427635192871
Batch 18/64 loss: -2.1398706436157227
Batch 19/64 loss: -2.1199846267700195
Batch 20/64 loss: -1.887552261352539
Batch 21/64 loss: -2.298640251159668
Batch 22/64 loss: -1.7821502685546875
Batch 23/64 loss: -2.2245874404907227
Batch 24/64 loss: -2.232546806335449
Batch 25/64 loss: -2.222444534301758
Batch 26/64 loss: -2.069854736328125
Batch 27/64 loss: -2.0217113494873047
Batch 28/64 loss: -2.0930023193359375
Batch 29/64 loss: -2.123453140258789
Batch 30/64 loss: -2.394582748413086
Batch 31/64 loss: -2.203335762023926
Batch 32/64 loss: -2.0423755645751953
Batch 33/64 loss: -2.22589111328125
Batch 34/64 loss: -2.242386817932129
Batch 35/64 loss: -2.130392074584961
Batch 36/64 loss: -1.8140487670898438
Batch 37/64 loss: -2.215193748474121
Batch 38/64 loss: -1.9697513580322266
Batch 39/64 loss: -1.3977479934692383
Batch 40/64 loss: -2.151370048522949
Batch 41/64 loss: -2.335205078125
Batch 42/64 loss: -2.202545166015625
Batch 43/64 loss: -1.8370513916015625
Batch 44/64 loss: -2.1250104904174805
Batch 45/64 loss: -2.2407960891723633
Batch 46/64 loss: -1.3200387954711914
Batch 47/64 loss: -2.438210964202881
Batch 48/64 loss: -2.1487226486206055
Batch 49/64 loss: -1.9359636306762695
Batch 50/64 loss: -2.09871768951416
Batch 51/64 loss: -2.0008649826049805
Batch 52/64 loss: -2.256403923034668
Batch 53/64 loss: -2.1762170791625977
Batch 54/64 loss: -2.1344757080078125
Batch 55/64 loss: -2.331608295440674
Batch 56/64 loss: -2.2203292846679688
Batch 57/64 loss: -2.2292957305908203
Batch 58/64 loss: -1.927290916442871
Batch 59/64 loss: -2.1810197830200195
Batch 60/64 loss: -2.139662742614746
Batch 61/64 loss: -2.120573043823242
Batch 62/64 loss: -2.209718704223633
Batch 63/64 loss: -2.0723018646240234
Batch 64/64 loss: -6.48967981338501
Epoch 316  Train loss: -2.161255516725428  Val loss: -2.503387792003933
Epoch 317
-------------------------------
Batch 1/64 loss: -2.0878000259399414
Batch 2/64 loss: -2.343994617462158
Batch 3/64 loss: -2.312284469604492
Batch 4/64 loss: -1.9696769714355469
Batch 5/64 loss: -2.270644187927246
Batch 6/64 loss: -1.4742250442504883
Batch 7/64 loss: -2.084026336669922
Batch 8/64 loss: -2.164309501647949
Batch 9/64 loss: -2.16220760345459
Batch 10/64 loss: -2.0880136489868164
Batch 11/64 loss: -2.159639358520508
Batch 12/64 loss: -2.0179738998413086
Batch 13/64 loss: -2.2185897827148438
Batch 14/64 loss: -2.2294368743896484
Batch 15/64 loss: -2.1776342391967773
Batch 16/64 loss: -2.1454524993896484
Batch 17/64 loss: -2.337244987487793
Batch 18/64 loss: -2.023575782775879
Batch 19/64 loss: -1.829427719116211
Batch 20/64 loss: -1.9585323333740234
Batch 21/64 loss: -2.049448013305664
Batch 22/64 loss: -2.0985450744628906
Batch 23/64 loss: -1.9569501876831055
Batch 24/64 loss: -2.2169151306152344
Batch 25/64 loss: -2.11398983001709
Batch 26/64 loss: -1.9408531188964844
Batch 27/64 loss: -2.2209529876708984
Batch 28/64 loss: -1.6333684921264648
Batch 29/64 loss: -1.6003351211547852
Batch 30/64 loss: -2.1720962524414062
Batch 31/64 loss: -2.05515193939209
Batch 32/64 loss: -1.7956657409667969
Batch 33/64 loss: -2.174896240234375
Batch 34/64 loss: -2.1923933029174805
Batch 35/64 loss: -2.1731252670288086
Batch 36/64 loss: -1.998103141784668
Batch 37/64 loss: -2.15664005279541
Batch 38/64 loss: -2.2304506301879883
Batch 39/64 loss: -1.9972257614135742
Batch 40/64 loss: -2.1140518188476562
Batch 41/64 loss: -2.1270275115966797
Batch 42/64 loss: -1.6228036880493164
Batch 43/64 loss: -2.2424020767211914
Batch 44/64 loss: -2.1366405487060547
Batch 45/64 loss: -2.184016227722168
Batch 46/64 loss: -1.7234182357788086
Batch 47/64 loss: -2.05916690826416
Batch 48/64 loss: -2.32431697845459
Batch 49/64 loss: -2.1835289001464844
Batch 50/64 loss: -2.1696882247924805
Batch 51/64 loss: -1.633183479309082
Batch 52/64 loss: -2.1463918685913086
Batch 53/64 loss: -2.3226451873779297
Batch 54/64 loss: -1.804457664489746
Batch 55/64 loss: -2.147282600402832
Batch 56/64 loss: -1.8139400482177734
Batch 57/64 loss: -1.9602088928222656
Batch 58/64 loss: -2.295816421508789
Batch 59/64 loss: -2.3436570167541504
Batch 60/64 loss: -1.8427982330322266
Batch 61/64 loss: -2.251781463623047
Batch 62/64 loss: -2.198413848876953
Batch 63/64 loss: -2.145291328430176
Batch 64/64 loss: -6.441895008087158
Epoch 317  Train loss: -2.1248022995743097  Val loss: -2.470464332816527
Epoch 318
-------------------------------
Batch 1/64 loss: -2.304436683654785
Batch 2/64 loss: -1.9882898330688477
Batch 3/64 loss: -1.9914216995239258
Batch 4/64 loss: -2.3165740966796875
Batch 5/64 loss: -2.1238927841186523
Batch 6/64 loss: -2.1318349838256836
Batch 7/64 loss: -1.975327491760254
Batch 8/64 loss: -2.0530385971069336
Batch 9/64 loss: -2.2363719940185547
Batch 10/64 loss: -2.025019645690918
Batch 11/64 loss: -2.1071348190307617
Batch 12/64 loss: -2.074429512023926
Batch 13/64 loss: -1.9765872955322266
Batch 14/64 loss: -2.1071043014526367
Batch 15/64 loss: -2.316211700439453
Batch 16/64 loss: -2.128626823425293
Batch 17/64 loss: -2.029513359069824
Batch 18/64 loss: -1.7639398574829102
Batch 19/64 loss: -1.2458133697509766
Batch 20/64 loss: -2.028736114501953
Batch 21/64 loss: -2.1696643829345703
Batch 22/64 loss: -2.235279083251953
Batch 23/64 loss: -2.0360889434814453
Batch 24/64 loss: -2.006411552429199
Batch 25/64 loss: -2.061433792114258
Batch 26/64 loss: -1.9681978225708008
Batch 27/64 loss: -2.149667739868164
Batch 28/64 loss: -1.6795473098754883
Batch 29/64 loss: -2.0644845962524414
Batch 30/64 loss: -2.2613525390625
Batch 31/64 loss: -1.9064598083496094
Batch 32/64 loss: -2.027756690979004
Batch 33/64 loss: -2.1223955154418945
Batch 34/64 loss: -1.948533058166504
Batch 35/64 loss: -2.182276725769043
Batch 36/64 loss: -1.9650201797485352
Batch 37/64 loss: -2.113954544067383
Batch 38/64 loss: -1.7847929000854492
Batch 39/64 loss: -2.025181770324707
Batch 40/64 loss: -2.2795915603637695
Batch 41/64 loss: -2.2848167419433594
Batch 42/64 loss: -1.7167816162109375
Batch 43/64 loss: -2.063108444213867
Batch 44/64 loss: -2.06378173828125
Batch 45/64 loss: -1.6679811477661133
Batch 46/64 loss: -2.2119503021240234
Batch 47/64 loss: -2.310110092163086
Batch 48/64 loss: -2.1881446838378906
Batch 49/64 loss: -2.073206901550293
Batch 50/64 loss: -2.2200422286987305
Batch 51/64 loss: -2.24240779876709
Batch 52/64 loss: -2.077817916870117
Batch 53/64 loss: -2.150681495666504
Batch 54/64 loss: -1.6999845504760742
Batch 55/64 loss: -2.0803651809692383
Batch 56/64 loss: -2.0947093963623047
Batch 57/64 loss: -2.0131120681762695
Batch 58/64 loss: -1.5031299591064453
Batch 59/64 loss: -2.239065647125244
Batch 60/64 loss: -2.1452713012695312
Batch 61/64 loss: -2.0974864959716797
Batch 62/64 loss: -1.8023252487182617
Batch 63/64 loss: -2.278082847595215
Batch 64/64 loss: -6.2762908935546875
Epoch 318  Train loss: -2.099513371785482  Val loss: -2.4026182640049467
Epoch 319
-------------------------------
Batch 1/64 loss: -1.8794631958007812
Batch 2/64 loss: -2.20694637298584
Batch 3/64 loss: -2.0595932006835938
Batch 4/64 loss: -2.2240238189697266
Batch 5/64 loss: -2.240325927734375
Batch 6/64 loss: -2.2703890800476074
Batch 7/64 loss: -2.2389912605285645
Batch 8/64 loss: -2.0804643630981445
Batch 9/64 loss: -1.8947668075561523
Batch 10/64 loss: -2.0050411224365234
Batch 11/64 loss: -2.1294660568237305
Batch 12/64 loss: -1.8571290969848633
Batch 13/64 loss: -1.962203025817871
Batch 14/64 loss: -2.220526695251465
Batch 15/64 loss: -2.0902347564697266
Batch 16/64 loss: -2.122692108154297
Batch 17/64 loss: -2.0717830657958984
Batch 18/64 loss: -2.020395278930664
Batch 19/64 loss: -1.4151172637939453
Batch 20/64 loss: -2.0142316818237305
Batch 21/64 loss: -1.9645318984985352
Batch 22/64 loss: -2.1050033569335938
Batch 23/64 loss: -2.053802490234375
Batch 24/64 loss: -2.046828269958496
Batch 25/64 loss: -2.18973445892334
Batch 26/64 loss: -1.9029474258422852
Batch 27/64 loss: -2.0350894927978516
Batch 28/64 loss: -1.9174175262451172
Batch 29/64 loss: -1.8146038055419922
Batch 30/64 loss: -1.717564582824707
Batch 31/64 loss: -1.9801435470581055
Batch 32/64 loss: -1.9237432479858398
Batch 33/64 loss: -2.0372142791748047
Batch 34/64 loss: -1.999654769897461
Batch 35/64 loss: -1.8188838958740234
Batch 36/64 loss: -2.0445728302001953
Batch 37/64 loss: -1.8926677703857422
Batch 38/64 loss: -1.9201946258544922
Batch 39/64 loss: -1.912027359008789
Batch 40/64 loss: -2.156245231628418
Batch 41/64 loss: -2.0791397094726562
Batch 42/64 loss: -2.078091621398926
Batch 43/64 loss: -2.233902931213379
Batch 44/64 loss: -1.9715089797973633
Batch 45/64 loss: -2.164125442504883
Batch 46/64 loss: -1.9312915802001953
Batch 47/64 loss: -2.2725839614868164
Batch 48/64 loss: -1.884500503540039
Batch 49/64 loss: -2.2560482025146484
Batch 50/64 loss: -1.943221092224121
Batch 51/64 loss: -2.3507680892944336
Batch 52/64 loss: -1.8796138763427734
Batch 53/64 loss: -1.9266319274902344
Batch 54/64 loss: -1.4788026809692383
Batch 55/64 loss: -1.9574556350708008
Batch 56/64 loss: -2.079258918762207
Batch 57/64 loss: -2.2872018814086914
Batch 58/64 loss: -1.7964305877685547
Batch 59/64 loss: -2.2005882263183594
Batch 60/64 loss: -1.8571062088012695
Batch 61/64 loss: -1.8845834732055664
Batch 62/64 loss: -0.8428106307983398
Batch 63/64 loss: -2.076536178588867
Batch 64/64 loss: -6.395352840423584
Epoch 319  Train loss: -2.049652894337972  Val loss: -2.2792680615821657
Epoch 320
-------------------------------
Batch 1/64 loss: -1.8442611694335938
Batch 2/64 loss: -2.1293087005615234
Batch 3/64 loss: -1.852625846862793
Batch 4/64 loss: -1.9740371704101562
Batch 5/64 loss: -2.077775001525879
Batch 6/64 loss: -1.8887004852294922
Batch 7/64 loss: -2.1423606872558594
Batch 8/64 loss: -2.0174808502197266
Batch 9/64 loss: -1.7853059768676758
Batch 10/64 loss: -2.109874725341797
Batch 11/64 loss: -1.5280561447143555
Batch 12/64 loss: -2.1197566986083984
Batch 13/64 loss: -2.2226505279541016
Batch 14/64 loss: -1.6758432388305664
Batch 15/64 loss: -2.048166275024414
Batch 16/64 loss: -2.027125358581543
Batch 17/64 loss: -1.5594024658203125
Batch 18/64 loss: -2.095698356628418
Batch 19/64 loss: -2.0394954681396484
Batch 20/64 loss: -1.9116077423095703
Batch 21/64 loss: -2.167278289794922
Batch 22/64 loss: -2.0429468154907227
Batch 23/64 loss: -2.004286766052246
Batch 24/64 loss: -2.2080392837524414
Batch 25/64 loss: -2.2501296997070312
Batch 26/64 loss: -2.178342819213867
Batch 27/64 loss: -2.120049476623535
Batch 28/64 loss: -2.069124221801758
Batch 29/64 loss: -1.9053716659545898
Batch 30/64 loss: -1.6656951904296875
Batch 31/64 loss: -2.0757503509521484
Batch 32/64 loss: -2.0625905990600586
Batch 33/64 loss: -2.1478967666625977
Batch 34/64 loss: -1.4493703842163086
Batch 35/64 loss: -2.0773534774780273
Batch 36/64 loss: -1.821242332458496
Batch 37/64 loss: -2.1650285720825195
Batch 38/64 loss: -2.2492127418518066
Batch 39/64 loss: -2.2601089477539062
Batch 40/64 loss: -1.9448165893554688
Batch 41/64 loss: -2.121622085571289
Batch 42/64 loss: -2.1385345458984375
Batch 43/64 loss: -2.035233497619629
Batch 44/64 loss: -2.1978893280029297
Batch 45/64 loss: -2.1510095596313477
Batch 46/64 loss: -1.7690391540527344
Batch 47/64 loss: -2.356350898742676
Batch 48/64 loss: -2.2189159393310547
Batch 49/64 loss: -2.2848477363586426
Batch 50/64 loss: -2.2200584411621094
Batch 51/64 loss: -2.1725826263427734
Batch 52/64 loss: -1.868917465209961
Batch 53/64 loss: -1.3529672622680664
Batch 54/64 loss: -2.346217155456543
Batch 55/64 loss: -2.1410274505615234
Batch 56/64 loss: -2.3318262100219727
Batch 57/64 loss: -2.234834671020508
Batch 58/64 loss: -2.107375144958496
Batch 59/64 loss: -2.146010398864746
Batch 60/64 loss: -2.206216812133789
Batch 61/64 loss: -2.036222457885742
Batch 62/64 loss: -2.1458911895751953
Batch 63/64 loss: -1.7451667785644531
Batch 64/64 loss: -6.457592964172363
Epoch 320  Train loss: -2.0876254025627583  Val loss: -2.4198109210561642
Epoch 321
-------------------------------
Batch 1/64 loss: -1.9861078262329102
Batch 2/64 loss: -1.6170225143432617
Batch 3/64 loss: -1.9262657165527344
Batch 4/64 loss: -2.1060800552368164
Batch 5/64 loss: -1.8122692108154297
Batch 6/64 loss: -2.258843421936035
Batch 7/64 loss: -1.941941261291504
Batch 8/64 loss: -2.119502067565918
Batch 9/64 loss: -2.2762346267700195
Batch 10/64 loss: -2.030766487121582
Batch 11/64 loss: -2.037609100341797
Batch 12/64 loss: -2.0542964935302734
Batch 13/64 loss: -2.1015100479125977
Batch 14/64 loss: -2.1201248168945312
Batch 15/64 loss: -2.0566444396972656
Batch 16/64 loss: -2.231800079345703
Batch 17/64 loss: -1.983942985534668
Batch 18/64 loss: -2.3466153144836426
Batch 19/64 loss: -2.3375368118286133
Batch 20/64 loss: -1.9872150421142578
Batch 21/64 loss: -1.9768152236938477
Batch 22/64 loss: -1.911417007446289
Batch 23/64 loss: -2.2420148849487305
Batch 24/64 loss: -1.973597526550293
Batch 25/64 loss: -2.2688183784484863
Batch 26/64 loss: -1.4543228149414062
Batch 27/64 loss: -2.060708999633789
Batch 28/64 loss: -2.222764492034912
Batch 29/64 loss: -0.9534292221069336
Batch 30/64 loss: -1.2767810821533203
Batch 31/64 loss: -2.199751377105713
Batch 32/64 loss: -2.2534608840942383
Batch 33/64 loss: -2.1794166564941406
Batch 34/64 loss: -2.298617362976074
Batch 35/64 loss: -2.141324996948242
Batch 36/64 loss: -2.2873220443725586
Batch 37/64 loss: -2.3593740463256836
Batch 38/64 loss: -1.9793548583984375
Batch 39/64 loss: -2.1276378631591797
Batch 40/64 loss: -2.0032825469970703
Batch 41/64 loss: -2.167813301086426
Batch 42/64 loss: -2.145279884338379
Batch 43/64 loss: -2.0373926162719727
Batch 44/64 loss: -2.298238754272461
Batch 45/64 loss: -2.2234115600585938
Batch 46/64 loss: -2.305927276611328
Batch 47/64 loss: -2.2227020263671875
Batch 48/64 loss: -2.3448519706726074
Batch 49/64 loss: -2.2583065032958984
Batch 50/64 loss: -2.249910831451416
Batch 51/64 loss: -2.26461124420166
Batch 52/64 loss: -2.258805274963379
Batch 53/64 loss: -2.180164337158203
Batch 54/64 loss: -2.024425506591797
Batch 55/64 loss: -1.9873409271240234
Batch 56/64 loss: -1.7806816101074219
Batch 57/64 loss: -2.140261650085449
Batch 58/64 loss: -2.3286638259887695
Batch 59/64 loss: -1.9874067306518555
Batch 60/64 loss: -2.218566417694092
Batch 61/64 loss: -2.2292327880859375
Batch 62/64 loss: -2.107611656188965
Batch 63/64 loss: -1.9023971557617188
Batch 64/64 loss: -6.450454235076904
Epoch 321  Train loss: -2.133402119430841  Val loss: -2.5116524581647
Epoch 322
-------------------------------
Batch 1/64 loss: -2.2178449630737305
Batch 2/64 loss: -1.8969898223876953
Batch 3/64 loss: -2.1785507202148438
Batch 4/64 loss: -2.035097122192383
Batch 5/64 loss: -2.0237512588500977
Batch 6/64 loss: -2.2126426696777344
Batch 7/64 loss: -1.936767578125
Batch 8/64 loss: -2.3712892532348633
Batch 9/64 loss: -2.184981346130371
Batch 10/64 loss: -1.774195671081543
Batch 11/64 loss: -2.205991744995117
Batch 12/64 loss: -2.199307441711426
Batch 13/64 loss: -2.0173416137695312
Batch 14/64 loss: -2.1151742935180664
Batch 15/64 loss: -2.084636688232422
Batch 16/64 loss: -2.0790319442749023
Batch 17/64 loss: -2.2816896438598633
Batch 18/64 loss: -2.1418094635009766
Batch 19/64 loss: -2.1840505599975586
Batch 20/64 loss: -2.453036308288574
Batch 21/64 loss: -2.091170310974121
Batch 22/64 loss: -2.245565414428711
Batch 23/64 loss: -1.4992876052856445
Batch 24/64 loss: -2.2095565795898438
Batch 25/64 loss: -2.2763490676879883
Batch 26/64 loss: -2.0588865280151367
Batch 27/64 loss: -2.03177547454834
Batch 28/64 loss: -1.8033504486083984
Batch 29/64 loss: -2.107746124267578
Batch 30/64 loss: -2.2864856719970703
Batch 31/64 loss: -1.9720687866210938
Batch 32/64 loss: -1.8621387481689453
Batch 33/64 loss: -2.226810932159424
Batch 34/64 loss: -2.137253761291504
Batch 35/64 loss: -1.9818334579467773
Batch 36/64 loss: -1.828291893005371
Batch 37/64 loss: -2.1598472595214844
Batch 38/64 loss: -2.0987939834594727
Batch 39/64 loss: -2.085434913635254
Batch 40/64 loss: -1.8790740966796875
Batch 41/64 loss: -2.031126022338867
Batch 42/64 loss: -1.9966707229614258
Batch 43/64 loss: -2.1041297912597656
Batch 44/64 loss: -2.112837791442871
Batch 45/64 loss: -2.0103836059570312
Batch 46/64 loss: -2.1615676879882812
Batch 47/64 loss: -2.1428050994873047
Batch 48/64 loss: -2.154214859008789
Batch 49/64 loss: -1.941110610961914
Batch 50/64 loss: -2.1483306884765625
Batch 51/64 loss: -1.9841794967651367
Batch 52/64 loss: -2.1546812057495117
Batch 53/64 loss: -1.8392438888549805
Batch 54/64 loss: -1.878011703491211
Batch 55/64 loss: -1.3199663162231445
Batch 56/64 loss: -1.4039716720581055
Batch 57/64 loss: -2.2363333702087402
Batch 58/64 loss: -2.138869285583496
Batch 59/64 loss: -2.234499931335449
Batch 60/64 loss: -2.3064985275268555
Batch 61/64 loss: -2.0789031982421875
Batch 62/64 loss: -2.269272804260254
Batch 63/64 loss: -2.153278350830078
Batch 64/64 loss: -6.269804954528809
Epoch 322  Train loss: -2.1166924158732097  Val loss: -2.2423727291146505
Epoch 323
-------------------------------
Batch 1/64 loss: -2.034611701965332
Batch 2/64 loss: -2.156238555908203
Batch 3/64 loss: -2.1212158203125
Batch 4/64 loss: -1.9390649795532227
Batch 5/64 loss: -2.0301055908203125
Batch 6/64 loss: -2.1568784713745117
Batch 7/64 loss: -2.145655632019043
Batch 8/64 loss: -2.1178693771362305
Batch 9/64 loss: -2.1165075302124023
Batch 10/64 loss: -2.0368385314941406
Batch 11/64 loss: -2.035114288330078
Batch 12/64 loss: -2.0638256072998047
Batch 13/64 loss: -2.116570472717285
Batch 14/64 loss: -1.6497840881347656
Batch 15/64 loss: -2.0700321197509766
Batch 16/64 loss: -1.8985137939453125
Batch 17/64 loss: -1.8864030838012695
Batch 18/64 loss: -1.887960433959961
Batch 19/64 loss: -2.0404491424560547
Batch 20/64 loss: -2.077033042907715
Batch 21/64 loss: -2.0426578521728516
Batch 22/64 loss: -1.8641510009765625
Batch 23/64 loss: -2.0587358474731445
Batch 24/64 loss: -1.9617948532104492
Batch 25/64 loss: -1.8177728652954102
Batch 26/64 loss: -1.6095972061157227
Batch 27/64 loss: -1.971482276916504
Batch 28/64 loss: -2.1173362731933594
Batch 29/64 loss: -1.9357967376708984
Batch 30/64 loss: -2.0122900009155273
Batch 31/64 loss: -1.8248701095581055
Batch 32/64 loss: -1.6627864837646484
Batch 33/64 loss: -2.001209259033203
Batch 34/64 loss: -2.0508365631103516
Batch 35/64 loss: -1.9527597427368164
Batch 36/64 loss: -2.007685661315918
Batch 37/64 loss: -1.9808015823364258
Batch 38/64 loss: -1.3661718368530273
Batch 39/64 loss: -2.045718193054199
Batch 40/64 loss: -1.6867809295654297
Batch 41/64 loss: -2.1260690689086914
Batch 42/64 loss: -1.8433494567871094
Batch 43/64 loss: -1.2903976440429688
Batch 44/64 loss: -2.057558059692383
Batch 45/64 loss: -1.8063173294067383
Batch 46/64 loss: -2.0382699966430664
Batch 47/64 loss: -1.9298076629638672
Batch 48/64 loss: -2.1835670471191406
Batch 49/64 loss: -1.7565221786499023
Batch 50/64 loss: -1.96514892578125
Batch 51/64 loss: -1.0646352767944336
Batch 52/64 loss: -2.0085649490356445
Batch 53/64 loss: -2.070530891418457
Batch 54/64 loss: -1.881291389465332
Batch 55/64 loss: -2.051863670349121
Batch 56/64 loss: -1.9870529174804688
Batch 57/64 loss: -1.7687044143676758
Batch 58/64 loss: -1.8901777267456055
Batch 59/64 loss: -2.0747547149658203
Batch 60/64 loss: -1.7486906051635742
Batch 61/64 loss: -1.9660329818725586
Batch 62/64 loss: -1.9004335403442383
Batch 63/64 loss: -1.7963323593139648
Batch 64/64 loss: -5.947606086730957
Epoch 323  Train loss: -1.9799009397918104  Val loss: -2.2471712381159725
Epoch 324
-------------------------------
Batch 1/64 loss: -1.5520381927490234
Batch 2/64 loss: -2.02658748626709
Batch 3/64 loss: -1.5600566864013672
Batch 4/64 loss: -1.808645248413086
Batch 5/64 loss: -1.9441871643066406
Batch 6/64 loss: -2.0005970001220703
Batch 7/64 loss: -2.115239143371582
Batch 8/64 loss: -1.5748624801635742
Batch 9/64 loss: -2.138296127319336
Batch 10/64 loss: -1.6827945709228516
Batch 11/64 loss: -2.126667022705078
Batch 12/64 loss: -1.8727779388427734
Batch 13/64 loss: -2.142061233520508
Batch 14/64 loss: -1.7447338104248047
Batch 15/64 loss: -2.150716781616211
Batch 16/64 loss: -1.9966182708740234
Batch 17/64 loss: -2.112959861755371
Batch 18/64 loss: -2.098949432373047
Batch 19/64 loss: -2.051302909851074
Batch 20/64 loss: -1.7977266311645508
Batch 21/64 loss: -2.2359018325805664
Batch 22/64 loss: -2.031630516052246
Batch 23/64 loss: -2.0519819259643555
Batch 24/64 loss: -2.1038074493408203
Batch 25/64 loss: -1.657090187072754
Batch 26/64 loss: -2.2275619506835938
Batch 27/64 loss: -2.295836925506592
Batch 28/64 loss: -1.5892467498779297
Batch 29/64 loss: -1.7746086120605469
Batch 30/64 loss: -1.4660358428955078
Batch 31/64 loss: -1.9985427856445312
Batch 32/64 loss: -2.270397186279297
Batch 33/64 loss: -2.138833999633789
Batch 34/64 loss: -2.0268678665161133
Batch 35/64 loss: -2.1906514167785645
Batch 36/64 loss: -2.2308263778686523
Batch 37/64 loss: -2.136615753173828
Batch 38/64 loss: -2.2182955741882324
Batch 39/64 loss: -2.09814453125
Batch 40/64 loss: -2.017970085144043
Batch 41/64 loss: -2.314830780029297
Batch 42/64 loss: -2.2562127113342285
Batch 43/64 loss: -2.008241653442383
Batch 44/64 loss: -2.24446439743042
Batch 45/64 loss: -1.9679298400878906
Batch 46/64 loss: -1.8629083633422852
Batch 47/64 loss: -1.9947948455810547
Batch 48/64 loss: -1.8346195220947266
Batch 49/64 loss: -1.9692935943603516
Batch 50/64 loss: -2.154566764831543
Batch 51/64 loss: -2.0825929641723633
Batch 52/64 loss: -1.3427114486694336
Batch 53/64 loss: -2.0826969146728516
Batch 54/64 loss: -1.7393312454223633
Batch 55/64 loss: -1.877579689025879
Batch 56/64 loss: -1.8047151565551758
Batch 57/64 loss: -1.8578615188598633
Batch 58/64 loss: -2.0985288619995117
Batch 59/64 loss: -2.0154552459716797
Batch 60/64 loss: -1.9899797439575195
Batch 61/64 loss: -1.860417366027832
Batch 62/64 loss: -2.143216133117676
Batch 63/64 loss: -2.065077781677246
Batch 64/64 loss: -6.217903137207031
Epoch 324  Train loss: -2.031217560113645  Val loss: -2.2910577308681
Epoch 325
-------------------------------
Batch 1/64 loss: -2.040487289428711
Batch 2/64 loss: -2.1032791137695312
Batch 3/64 loss: -1.8913516998291016
Batch 4/64 loss: -2.132540702819824
Batch 5/64 loss: -2.068182945251465
Batch 6/64 loss: -2.213984489440918
Batch 7/64 loss: -2.171590805053711
Batch 8/64 loss: -2.0359878540039062
Batch 9/64 loss: -2.1266679763793945
Batch 10/64 loss: -2.0722455978393555
Batch 11/64 loss: -2.069706916809082
Batch 12/64 loss: -2.1723012924194336
Batch 13/64 loss: -1.826340675354004
Batch 14/64 loss: -2.0791091918945312
Batch 15/64 loss: -2.0850610733032227
Batch 16/64 loss: -2.140817642211914
Batch 17/64 loss: -1.7474288940429688
Batch 18/64 loss: -1.9036836624145508
Batch 19/64 loss: -1.4803266525268555
Batch 20/64 loss: -2.2644972801208496
Batch 21/64 loss: -2.174239158630371
Batch 22/64 loss: -2.14300537109375
Batch 23/64 loss: -2.1437273025512695
Batch 24/64 loss: -2.1315994262695312
Batch 25/64 loss: -2.1113643646240234
Batch 26/64 loss: -1.9973297119140625
Batch 27/64 loss: -2.167078971862793
Batch 28/64 loss: -2.1382932662963867
Batch 29/64 loss: -2.032848358154297
Batch 30/64 loss: -1.9125967025756836
Batch 31/64 loss: -2.0439510345458984
Batch 32/64 loss: -2.116225242614746
Batch 33/64 loss: -1.9315471649169922
Batch 34/64 loss: -2.129484176635742
Batch 35/64 loss: -1.7462949752807617
Batch 36/64 loss: -2.1822128295898438
Batch 37/64 loss: -1.4110565185546875
Batch 38/64 loss: -1.9123849868774414
Batch 39/64 loss: -1.9523420333862305
Batch 40/64 loss: -1.8913679122924805
Batch 41/64 loss: -2.011056900024414
Batch 42/64 loss: -2.0839128494262695
Batch 43/64 loss: -1.9343700408935547
Batch 44/64 loss: -2.065654754638672
Batch 45/64 loss: -1.9708318710327148
Batch 46/64 loss: -2.1778249740600586
Batch 47/64 loss: -1.972555160522461
Batch 48/64 loss: -1.3585052490234375
Batch 49/64 loss: -1.6799259185791016
Batch 50/64 loss: -2.2321481704711914
Batch 51/64 loss: -2.034327507019043
Batch 52/64 loss: -1.5876312255859375
Batch 53/64 loss: -1.9889049530029297
Batch 54/64 loss: -1.8652257919311523
Batch 55/64 loss: -2.0319671630859375
Batch 56/64 loss: -2.212810516357422
Batch 57/64 loss: -2.0150270462036133
Batch 58/64 loss: -2.016781806945801
Batch 59/64 loss: -1.9189033508300781
Batch 60/64 loss: -2.082958221435547
Batch 61/64 loss: -2.2418103218078613
Batch 62/64 loss: -2.0212326049804688
Batch 63/64 loss: -1.8828840255737305
Batch 64/64 loss: -6.249879837036133
Epoch 325  Train loss: -2.0544188480751187  Val loss: -2.3859132851931646
Epoch 326
-------------------------------
Batch 1/64 loss: -1.8673219680786133
Batch 2/64 loss: -1.949239730834961
Batch 3/64 loss: -1.5454072952270508
Batch 4/64 loss: -2.265695571899414
Batch 5/64 loss: -2.008469581604004
Batch 6/64 loss: -1.791280746459961
Batch 7/64 loss: -2.1341447830200195
Batch 8/64 loss: -2.0899124145507812
Batch 9/64 loss: -1.7512178421020508
Batch 10/64 loss: -1.9267406463623047
Batch 11/64 loss: -1.9487762451171875
Batch 12/64 loss: -2.022648811340332
Batch 13/64 loss: -2.106740951538086
Batch 14/64 loss: -1.9946212768554688
Batch 15/64 loss: -2.1306581497192383
Batch 16/64 loss: -1.9308080673217773
Batch 17/64 loss: -2.023798942565918
Batch 18/64 loss: -2.0646591186523438
Batch 19/64 loss: -2.156956195831299
Batch 20/64 loss: -1.9656791687011719
Batch 21/64 loss: -2.0517187118530273
Batch 22/64 loss: -1.8990497589111328
Batch 23/64 loss: -2.1131210327148438
Batch 24/64 loss: -2.2741613388061523
Batch 25/64 loss: -2.2916016578674316
Batch 26/64 loss: -2.1153135299682617
Batch 27/64 loss: -2.0931453704833984
Batch 28/64 loss: -1.8521928787231445
Batch 29/64 loss: -2.1673831939697266
Batch 30/64 loss: -2.320197582244873
Batch 31/64 loss: -2.1586923599243164
Batch 32/64 loss: -2.1041746139526367
Batch 33/64 loss: -1.9619503021240234
Batch 34/64 loss: -2.2533202171325684
Batch 35/64 loss: -1.887507438659668
Batch 36/64 loss: -1.3270883560180664
Batch 37/64 loss: -2.218545913696289
Batch 38/64 loss: -2.1054677963256836
Batch 39/64 loss: -2.238673210144043
Batch 40/64 loss: -2.2066659927368164
Batch 41/64 loss: -2.1369895935058594
Batch 42/64 loss: -1.8580236434936523
Batch 43/64 loss: -2.0599870681762695
Batch 44/64 loss: -2.2838821411132812
Batch 45/64 loss: -2.108565330505371
Batch 46/64 loss: -2.076016426086426
Batch 47/64 loss: -2.0659265518188477
Batch 48/64 loss: -2.1447010040283203
Batch 49/64 loss: -1.5204181671142578
Batch 50/64 loss: -1.8698234558105469
Batch 51/64 loss: -2.047957420349121
Batch 52/64 loss: -1.7488899230957031
Batch 53/64 loss: -1.8118047714233398
Batch 54/64 loss: -1.9787845611572266
Batch 55/64 loss: -1.9840097427368164
Batch 56/64 loss: -2.107537269592285
Batch 57/64 loss: -2.15594482421875
Batch 58/64 loss: -2.241361141204834
Batch 59/64 loss: -2.02530574798584
Batch 60/64 loss: -2.132927894592285
Batch 61/64 loss: -1.9789409637451172
Batch 62/64 loss: -1.5403156280517578
Batch 63/64 loss: -2.2815890312194824
Batch 64/64 loss: -6.168769836425781
Epoch 326  Train loss: -2.072172995174632  Val loss: -2.417516714928486
Epoch 327
-------------------------------
Batch 1/64 loss: -2.1715736389160156
Batch 2/64 loss: -2.190577983856201
Batch 3/64 loss: -2.285606861114502
Batch 4/64 loss: -1.4297847747802734
Batch 5/64 loss: -2.0903196334838867
Batch 6/64 loss: -2.103793144226074
Batch 7/64 loss: -2.100250244140625
Batch 8/64 loss: -1.8973932266235352
Batch 9/64 loss: -2.1675949096679688
Batch 10/64 loss: -1.4263534545898438
Batch 11/64 loss: -2.1417760848999023
Batch 12/64 loss: -1.9335260391235352
Batch 13/64 loss: -2.240896224975586
Batch 14/64 loss: -1.9497127532958984
Batch 15/64 loss: -2.087045669555664
Batch 16/64 loss: -2.101572036743164
Batch 17/64 loss: -2.226745128631592
Batch 18/64 loss: -2.164234161376953
Batch 19/64 loss: -2.1269454956054688
Batch 20/64 loss: -2.0231685638427734
Batch 21/64 loss: -2.0928916931152344
Batch 22/64 loss: -1.9273204803466797
Batch 23/64 loss: -2.2122344970703125
Batch 24/64 loss: -2.072525978088379
Batch 25/64 loss: -2.2958154678344727
Batch 26/64 loss: -2.0585098266601562
Batch 27/64 loss: -1.8749408721923828
Batch 28/64 loss: -2.0655717849731445
Batch 29/64 loss: -2.0083513259887695
Batch 30/64 loss: -2.1020631790161133
Batch 31/64 loss: -2.3761963844299316
Batch 32/64 loss: -2.1119327545166016
Batch 33/64 loss: -2.037898063659668
Batch 34/64 loss: -2.183879852294922
Batch 35/64 loss: -2.141019821166992
Batch 36/64 loss: -1.873697280883789
Batch 37/64 loss: -2.137989044189453
Batch 38/64 loss: -2.178253173828125
Batch 39/64 loss: -2.16414737701416
Batch 40/64 loss: -2.219290256500244
Batch 41/64 loss: -2.224111557006836
Batch 42/64 loss: -1.9403791427612305
Batch 43/64 loss: -2.2547197341918945
Batch 44/64 loss: -2.1514644622802734
Batch 45/64 loss: -2.0949230194091797
Batch 46/64 loss: -2.123225212097168
Batch 47/64 loss: -1.9970998764038086
Batch 48/64 loss: -1.888859748840332
Batch 49/64 loss: -2.2869014739990234
Batch 50/64 loss: -1.8986873626708984
Batch 51/64 loss: -1.6484699249267578
Batch 52/64 loss: -1.5505905151367188
Batch 53/64 loss: -2.108748435974121
Batch 54/64 loss: -1.9174680709838867
Batch 55/64 loss: -2.101071357727051
Batch 56/64 loss: -2.1415767669677734
Batch 57/64 loss: -1.621140480041504
Batch 58/64 loss: -1.9614009857177734
Batch 59/64 loss: -1.8387985229492188
Batch 60/64 loss: -1.968733787536621
Batch 61/64 loss: -2.1895103454589844
Batch 62/64 loss: -1.8681564331054688
Batch 63/64 loss: -2.1133499145507812
Batch 64/64 loss: -6.262959003448486
Epoch 327  Train loss: -2.095372635710473  Val loss: -2.3907638759547494
Epoch 328
-------------------------------
Batch 1/64 loss: -2.1848630905151367
Batch 2/64 loss: -2.1759634017944336
Batch 3/64 loss: -1.720423698425293
Batch 4/64 loss: -1.8665685653686523
Batch 5/64 loss: -2.119814872741699
Batch 6/64 loss: -1.8997573852539062
Batch 7/64 loss: -2.074228286743164
Batch 8/64 loss: -1.9505643844604492
Batch 9/64 loss: -1.9675540924072266
Batch 10/64 loss: -2.1453495025634766
Batch 11/64 loss: -2.129772186279297
Batch 12/64 loss: -1.923090934753418
Batch 13/64 loss: -2.1671142578125
Batch 14/64 loss: -2.26922607421875
Batch 15/64 loss: -2.1898136138916016
Batch 16/64 loss: -2.029263496398926
Batch 17/64 loss: -2.072047233581543
Batch 18/64 loss: -2.2680983543395996
Batch 19/64 loss: -1.4807004928588867
Batch 20/64 loss: -2.1226682662963867
Batch 21/64 loss: -2.1319313049316406
Batch 22/64 loss: -2.175119400024414
Batch 23/64 loss: -2.1002731323242188
Batch 24/64 loss: -2.2235255241394043
Batch 25/64 loss: -2.1569957733154297
Batch 26/64 loss: -2.1117734909057617
Batch 27/64 loss: -2.0110044479370117
Batch 28/64 loss: -2.074859619140625
Batch 29/64 loss: -2.065516471862793
Batch 30/64 loss: -2.148357391357422
Batch 31/64 loss: -2.2800111770629883
Batch 32/64 loss: -2.1992626190185547
Batch 33/64 loss: -2.0711708068847656
Batch 34/64 loss: -2.270911693572998
Batch 35/64 loss: -1.5310735702514648
Batch 36/64 loss: -2.143331527709961
Batch 37/64 loss: -2.2078185081481934
Batch 38/64 loss: -2.150120735168457
Batch 39/64 loss: -1.3088035583496094
Batch 40/64 loss: -2.193314552307129
Batch 41/64 loss: -2.1075687408447266
Batch 42/64 loss: -2.0533485412597656
Batch 43/64 loss: -2.0338096618652344
Batch 44/64 loss: -1.6928300857543945
Batch 45/64 loss: -2.1149215698242188
Batch 46/64 loss: -2.1707887649536133
Batch 47/64 loss: -2.3052263259887695
Batch 48/64 loss: -2.126368522644043
Batch 49/64 loss: -1.9743328094482422
Batch 50/64 loss: -2.138667106628418
Batch 51/64 loss: -1.8479251861572266
Batch 52/64 loss: -1.8786354064941406
Batch 53/64 loss: -1.9726381301879883
Batch 54/64 loss: -2.1887407302856445
Batch 55/64 loss: -2.181839942932129
Batch 56/64 loss: -1.6761856079101562
Batch 57/64 loss: -1.882065773010254
Batch 58/64 loss: -2.0377559661865234
Batch 59/64 loss: -1.947035789489746
Batch 60/64 loss: -2.2338294982910156
Batch 61/64 loss: -2.2703847885131836
Batch 62/64 loss: -1.9316339492797852
Batch 63/64 loss: -2.2592878341674805
Batch 64/64 loss: -6.115911960601807
Epoch 328  Train loss: -2.1007813678068272  Val loss: -2.5100788103346154
Epoch 329
-------------------------------
Batch 1/64 loss: -1.9401435852050781
Batch 2/64 loss: -2.2003517150878906
Batch 3/64 loss: -2.216167449951172
Batch 4/64 loss: -2.314281940460205
Batch 5/64 loss: -2.152642250061035
Batch 6/64 loss: -2.1814403533935547
Batch 7/64 loss: -2.2790117263793945
Batch 8/64 loss: -1.8967781066894531
Batch 9/64 loss: -1.9083213806152344
Batch 10/64 loss: -1.6937332153320312
Batch 11/64 loss: -2.3911848068237305
Batch 12/64 loss: -2.3055667877197266
Batch 13/64 loss: -1.9669685363769531
Batch 14/64 loss: -2.2634267807006836
Batch 15/64 loss: -2.217418670654297
Batch 16/64 loss: -2.0578479766845703
Batch 17/64 loss: -2.1308393478393555
Batch 18/64 loss: -2.2361011505126953
Batch 19/64 loss: -2.173895835876465
Batch 20/64 loss: -2.2709574699401855
Batch 21/64 loss: -2.109142303466797
Batch 22/64 loss: -2.0646915435791016
Batch 23/64 loss: -2.0178756713867188
Batch 24/64 loss: -2.2759909629821777
Batch 25/64 loss: -2.3377952575683594
Batch 26/64 loss: -1.826507568359375
Batch 27/64 loss: -2.268921375274658
Batch 28/64 loss: -2.251760959625244
Batch 29/64 loss: -2.1515398025512695
Batch 30/64 loss: -2.1603622436523438
Batch 31/64 loss: -1.9973602294921875
Batch 32/64 loss: -2.2879114151000977
Batch 33/64 loss: -1.9973459243774414
Batch 34/64 loss: -2.2373762130737305
Batch 35/64 loss: -2.1603384017944336
Batch 36/64 loss: -2.0874147415161133
Batch 37/64 loss: -2.113445281982422
Batch 38/64 loss: -2.254326820373535
Batch 39/64 loss: -2.2417778968811035
Batch 40/64 loss: -2.1186704635620117
Batch 41/64 loss: -2.3294687271118164
Batch 42/64 loss: -1.5740413665771484
Batch 43/64 loss: -1.2645893096923828
Batch 44/64 loss: -1.966080665588379
Batch 45/64 loss: -1.8584928512573242
Batch 46/64 loss: -2.0212888717651367
Batch 47/64 loss: -2.2803730964660645
Batch 48/64 loss: -2.1327743530273438
Batch 49/64 loss: -2.1313095092773438
Batch 50/64 loss: -2.350203037261963
Batch 51/64 loss: -2.256059169769287
Batch 52/64 loss: -2.266116142272949
Batch 53/64 loss: -1.9624919891357422
Batch 54/64 loss: -2.284604549407959
Batch 55/64 loss: -2.1957216262817383
Batch 56/64 loss: -2.2178516387939453
Batch 57/64 loss: -2.253328323364258
Batch 58/64 loss: -2.2899913787841797
Batch 59/64 loss: -2.1248655319213867
Batch 60/64 loss: -2.0003662109375
Batch 61/64 loss: -2.006802558898926
Batch 62/64 loss: -1.816690444946289
Batch 63/64 loss: -2.2620162963867188
Batch 64/64 loss: -6.348791122436523
Epoch 329  Train loss: -2.170427531822055  Val loss: -2.5181485992117025
Epoch 330
-------------------------------
Batch 1/64 loss: -2.241086959838867
Batch 2/64 loss: -1.7338228225708008
Batch 3/64 loss: -1.4557561874389648
Batch 4/64 loss: -2.120945930480957
Batch 5/64 loss: -1.8567943572998047
Batch 6/64 loss: -2.2037367820739746
Batch 7/64 loss: -2.0258541107177734
Batch 8/64 loss: -2.2942543029785156
Batch 9/64 loss: -1.9853839874267578
Batch 10/64 loss: -2.225764274597168
Batch 11/64 loss: -2.1903953552246094
Batch 12/64 loss: -2.249680995941162
Batch 13/64 loss: -2.2089405059814453
Batch 14/64 loss: -2.1081247329711914
Batch 15/64 loss: -2.0765695571899414
Batch 16/64 loss: -2.2560372352600098
Batch 17/64 loss: -2.1217803955078125
Batch 18/64 loss: -2.054248809814453
Batch 19/64 loss: -2.2102746963500977
Batch 20/64 loss: -1.9435386657714844
Batch 21/64 loss: -2.108854293823242
Batch 22/64 loss: -2.2424216270446777
Batch 23/64 loss: -1.962386131286621
Batch 24/64 loss: -1.9444046020507812
Batch 25/64 loss: -2.257081985473633
Batch 26/64 loss: -2.3389177322387695
Batch 27/64 loss: -2.0462112426757812
Batch 28/64 loss: -2.05544376373291
Batch 29/64 loss: -2.1500349044799805
Batch 30/64 loss: -2.2274465560913086
Batch 31/64 loss: -2.1567859649658203
Batch 32/64 loss: -2.1323795318603516
Batch 33/64 loss: -2.1579151153564453
Batch 34/64 loss: -1.9926824569702148
Batch 35/64 loss: -2.3011960983276367
Batch 36/64 loss: -2.0767393112182617
Batch 37/64 loss: -2.0996856689453125
Batch 38/64 loss: -2.217744827270508
Batch 39/64 loss: -2.06289005279541
Batch 40/64 loss: -2.294729709625244
Batch 41/64 loss: -1.6294097900390625
Batch 42/64 loss: -2.0479955673217773
Batch 43/64 loss: -2.107717514038086
Batch 44/64 loss: -2.2725954055786133
Batch 45/64 loss: -2.27858829498291
Batch 46/64 loss: -1.8066167831420898
Batch 47/64 loss: -2.1664915084838867
Batch 48/64 loss: -2.1182146072387695
Batch 49/64 loss: -2.200775146484375
Batch 50/64 loss: -2.1379451751708984
Batch 51/64 loss: -2.0211400985717773
Batch 52/64 loss: -2.176724433898926
Batch 53/64 loss: -2.042149543762207
Batch 54/64 loss: -1.8944635391235352
Batch 55/64 loss: -1.9981575012207031
Batch 56/64 loss: -2.035533905029297
Batch 57/64 loss: -2.0121870040893555
Batch 58/64 loss: -1.9360628128051758
Batch 59/64 loss: -2.1053857803344727
Batch 60/64 loss: -2.28060245513916
Batch 61/64 loss: -2.103555679321289
Batch 62/64 loss: -2.362236499786377
Batch 63/64 loss: -2.192622184753418
Batch 64/64 loss: -6.387552261352539
Epoch 330  Train loss: -2.1506945516548903  Val loss: -2.5142047528139093
Epoch 331
-------------------------------
Batch 1/64 loss: -2.210521697998047
Batch 2/64 loss: -1.7465324401855469
Batch 3/64 loss: -2.1676130294799805
Batch 4/64 loss: -2.2413926124572754
Batch 5/64 loss: -2.204361915588379
Batch 6/64 loss: -2.220968246459961
Batch 7/64 loss: -2.0024261474609375
Batch 8/64 loss: -2.246586322784424
Batch 9/64 loss: -1.9901762008666992
Batch 10/64 loss: -2.2850942611694336
Batch 11/64 loss: -2.2111568450927734
Batch 12/64 loss: -2.1230087280273438
Batch 13/64 loss: -2.425873279571533
Batch 14/64 loss: -2.19290828704834
Batch 15/64 loss: -2.256829261779785
Batch 16/64 loss: -2.119093894958496
Batch 17/64 loss: -2.0253515243530273
Batch 18/64 loss: -2.24971866607666
Batch 19/64 loss: -1.8891000747680664
Batch 20/64 loss: -1.949697494506836
Batch 21/64 loss: -2.2266974449157715
Batch 22/64 loss: -2.1957521438598633
Batch 23/64 loss: -1.8780527114868164
Batch 24/64 loss: -1.9365720748901367
Batch 25/64 loss: -1.8606481552124023
Batch 26/64 loss: -1.859452247619629
Batch 27/64 loss: -2.243834972381592
Batch 28/64 loss: -2.2696218490600586
Batch 29/64 loss: -2.0328283309936523
Batch 30/64 loss: -1.9081850051879883
Batch 31/64 loss: -2.0957069396972656
Batch 32/64 loss: -2.196669578552246
Batch 33/64 loss: -2.182250499725342
Batch 34/64 loss: -2.0878868103027344
Batch 35/64 loss: -2.232855796813965
Batch 36/64 loss: -2.207277297973633
Batch 37/64 loss: -1.4390373229980469
Batch 38/64 loss: -1.896291732788086
Batch 39/64 loss: -2.053709030151367
Batch 40/64 loss: -2.108729362487793
Batch 41/64 loss: -2.43953800201416
Batch 42/64 loss: -2.344874382019043
Batch 43/64 loss: -2.238966464996338
Batch 44/64 loss: -1.8495168685913086
Batch 45/64 loss: -2.2191553115844727
Batch 46/64 loss: -2.3797497749328613
Batch 47/64 loss: -2.2649788856506348
Batch 48/64 loss: -2.191160202026367
Batch 49/64 loss: -1.2268896102905273
Batch 50/64 loss: -2.205430030822754
Batch 51/64 loss: -2.3159255981445312
Batch 52/64 loss: -1.9494924545288086
Batch 53/64 loss: -2.1301488876342773
Batch 54/64 loss: -2.0684661865234375
Batch 55/64 loss: -2.205447196960449
Batch 56/64 loss: -2.0215682983398438
Batch 57/64 loss: -2.109766960144043
Batch 58/64 loss: -2.0986948013305664
Batch 59/64 loss: -2.170764923095703
Batch 60/64 loss: -2.335879325866699
Batch 61/64 loss: -2.141500473022461
Batch 62/64 loss: -1.9615097045898438
Batch 63/64 loss: -1.6207342147827148
Batch 64/64 loss: -6.349287986755371
Epoch 331  Train loss: -2.147805408402985  Val loss: -2.406594292814379
Epoch 332
-------------------------------
Batch 1/64 loss: -2.1973724365234375
Batch 2/64 loss: -2.210916519165039
Batch 3/64 loss: -2.0369176864624023
Batch 4/64 loss: -2.0447826385498047
Batch 5/64 loss: -2.2998428344726562
Batch 6/64 loss: -1.323124885559082
Batch 7/64 loss: -2.208846092224121
Batch 8/64 loss: -2.230879306793213
Batch 9/64 loss: -2.2160110473632812
Batch 10/64 loss: -1.610978126525879
Batch 11/64 loss: -1.9892034530639648
Batch 12/64 loss: -2.0055131912231445
Batch 13/64 loss: -1.9617576599121094
Batch 14/64 loss: -1.4825372695922852
Batch 15/64 loss: -1.9899539947509766
Batch 16/64 loss: -1.9595203399658203
Batch 17/64 loss: -1.7566871643066406
Batch 18/64 loss: -2.064480781555176
Batch 19/64 loss: -2.161393165588379
Batch 20/64 loss: -2.199625015258789
Batch 21/64 loss: -2.0295791625976562
Batch 22/64 loss: -2.1127891540527344
Batch 23/64 loss: -1.7754182815551758
Batch 24/64 loss: -1.7706727981567383
Batch 25/64 loss: -2.2768325805664062
Batch 26/64 loss: -2.2398738861083984
Batch 27/64 loss: -2.178898811340332
Batch 28/64 loss: -2.058380126953125
Batch 29/64 loss: -2.125408172607422
Batch 30/64 loss: -2.232083320617676
Batch 31/64 loss: -2.3015336990356445
Batch 32/64 loss: -2.170191764831543
Batch 33/64 loss: -2.318582534790039
Batch 34/64 loss: -2.1784753799438477
Batch 35/64 loss: -1.949519157409668
Batch 36/64 loss: -2.2624711990356445
Batch 37/64 loss: -2.2463998794555664
Batch 38/64 loss: -2.3126392364501953
Batch 39/64 loss: -2.107274055480957
Batch 40/64 loss: -1.9730005264282227
Batch 41/64 loss: -2.1879358291625977
Batch 42/64 loss: -2.2916603088378906
Batch 43/64 loss: -2.3016982078552246
Batch 44/64 loss: -2.275768280029297
Batch 45/64 loss: -2.225320816040039
Batch 46/64 loss: -2.1634178161621094
Batch 47/64 loss: -2.250187873840332
Batch 48/64 loss: -2.1562938690185547
Batch 49/64 loss: -2.3430566787719727
Batch 50/64 loss: -2.237807273864746
Batch 51/64 loss: -1.992365837097168
Batch 52/64 loss: -2.443333625793457
Batch 53/64 loss: -2.3304314613342285
Batch 54/64 loss: -2.360647201538086
Batch 55/64 loss: -2.1711196899414062
Batch 56/64 loss: -2.159296989440918
Batch 57/64 loss: -2.2054529190063477
Batch 58/64 loss: -2.199185371398926
Batch 59/64 loss: -1.9507484436035156
Batch 60/64 loss: -2.216318130493164
Batch 61/64 loss: -2.313049793243408
Batch 62/64 loss: -2.2870497703552246
Batch 63/64 loss: -1.9309778213500977
Batch 64/64 loss: -5.778603553771973
Epoch 332  Train loss: -2.163097160937739  Val loss: -2.5146033427969288
Epoch 333
-------------------------------
Batch 1/64 loss: -2.169915199279785
Batch 2/64 loss: -1.9224128723144531
Batch 3/64 loss: -2.1128692626953125
Batch 4/64 loss: -1.5422582626342773
Batch 5/64 loss: -2.2288074493408203
Batch 6/64 loss: -2.0171051025390625
Batch 7/64 loss: -2.215269088745117
Batch 8/64 loss: -1.9132986068725586
Batch 9/64 loss: -1.7990703582763672
Batch 10/64 loss: -2.353710651397705
Batch 11/64 loss: -2.0085649490356445
Batch 12/64 loss: -2.2580580711364746
Batch 13/64 loss: -2.0415334701538086
Batch 14/64 loss: -1.9693679809570312
Batch 15/64 loss: -2.291179656982422
Batch 16/64 loss: -2.11224365234375
Batch 17/64 loss: -2.0099077224731445
Batch 18/64 loss: -2.0698471069335938
Batch 19/64 loss: -2.1938982009887695
Batch 20/64 loss: -2.031005859375
Batch 21/64 loss: -2.084341049194336
Batch 22/64 loss: -2.1718406677246094
Batch 23/64 loss: -2.239485740661621
Batch 24/64 loss: -2.308396339416504
Batch 25/64 loss: -2.2083024978637695
Batch 26/64 loss: -1.9331579208374023
Batch 27/64 loss: -2.146944999694824
Batch 28/64 loss: -2.196383476257324
Batch 29/64 loss: -2.188161849975586
Batch 30/64 loss: -2.25441837310791
Batch 31/64 loss: -1.9337167739868164
Batch 32/64 loss: -1.7575130462646484
Batch 33/64 loss: -2.16082763671875
Batch 34/64 loss: -1.856837272644043
Batch 35/64 loss: -2.129362106323242
Batch 36/64 loss: -2.0469846725463867
Batch 37/64 loss: -1.8065948486328125
Batch 38/64 loss: -2.1822872161865234
Batch 39/64 loss: -2.187063217163086
Batch 40/64 loss: -2.3460006713867188
Batch 41/64 loss: -2.2453231811523438
Batch 42/64 loss: -2.219325065612793
Batch 43/64 loss: -2.1958093643188477
Batch 44/64 loss: -2.2269554138183594
Batch 45/64 loss: -2.27987003326416
Batch 46/64 loss: -1.896000862121582
Batch 47/64 loss: -2.279414176940918
Batch 48/64 loss: -2.2082157135009766
Batch 49/64 loss: -1.9556713104248047
Batch 50/64 loss: -2.118732452392578
Batch 51/64 loss: -2.268024444580078
Batch 52/64 loss: -2.1522350311279297
Batch 53/64 loss: -1.956040382385254
Batch 54/64 loss: -2.333308219909668
Batch 55/64 loss: -2.080124855041504
Batch 56/64 loss: -2.118405342102051
Batch 57/64 loss: -1.5731830596923828
Batch 58/64 loss: -2.059870719909668
Batch 59/64 loss: -2.153867721557617
Batch 60/64 loss: -2.0705413818359375
Batch 61/64 loss: -2.2362489700317383
Batch 62/64 loss: -2.1002960205078125
Batch 63/64 loss: -2.1744041442871094
Batch 64/64 loss: -6.300419807434082
Epoch 333  Train loss: -2.1494294372259404  Val loss: -2.5694447940157863
Epoch 334
-------------------------------
Batch 1/64 loss: -2.333829402923584
Batch 2/64 loss: -2.2236862182617188
Batch 3/64 loss: -2.2143983840942383
Batch 4/64 loss: -2.100147247314453
Batch 5/64 loss: -2.3003358840942383
Batch 6/64 loss: -2.2283058166503906
Batch 7/64 loss: -2.2326278686523438
Batch 8/64 loss: -2.249420166015625
Batch 9/64 loss: -2.363247871398926
Batch 10/64 loss: -2.256920337677002
Batch 11/64 loss: -2.445845603942871
Batch 12/64 loss: -2.396723747253418
Batch 13/64 loss: -2.2534074783325195
Batch 14/64 loss: -2.3741211891174316
Batch 15/64 loss: -2.1503658294677734
Batch 16/64 loss: -1.589879035949707
Batch 17/64 loss: -2.213186264038086
Batch 18/64 loss: -2.041165351867676
Batch 19/64 loss: -2.131503105163574
Batch 20/64 loss: -2.265695095062256
Batch 21/64 loss: -2.2344698905944824
Batch 22/64 loss: -1.5259065628051758
Batch 23/64 loss: -2.0047903060913086
Batch 24/64 loss: -2.002653121948242
Batch 25/64 loss: -1.4359254837036133
Batch 26/64 loss: -2.259982109069824
Batch 27/64 loss: -1.8837776184082031
Batch 28/64 loss: -2.3539419174194336
Batch 29/64 loss: -2.0898380279541016
Batch 30/64 loss: -2.145880699157715
Batch 31/64 loss: -1.8849821090698242
Batch 32/64 loss: -2.2858638763427734
Batch 33/64 loss: -2.3065009117126465
Batch 34/64 loss: -2.2758893966674805
Batch 35/64 loss: -2.1401519775390625
Batch 36/64 loss: -2.335977077484131
Batch 37/64 loss: -2.3035473823547363
Batch 38/64 loss: -2.136807441711426
Batch 39/64 loss: -2.4857912063598633
Batch 40/64 loss: -2.3238959312438965
Batch 41/64 loss: -2.2169876098632812
Batch 42/64 loss: -2.4752283096313477
Batch 43/64 loss: -2.273294448852539
Batch 44/64 loss: -2.2653913497924805
Batch 45/64 loss: -1.9592552185058594
Batch 46/64 loss: -2.2455759048461914
Batch 47/64 loss: -2.2196531295776367
Batch 48/64 loss: -2.25978946685791
Batch 49/64 loss: -2.292609214782715
Batch 50/64 loss: -2.159067153930664
Batch 51/64 loss: -2.3214025497436523
Batch 52/64 loss: -1.466019630432129
Batch 53/64 loss: -2.0642833709716797
Batch 54/64 loss: -2.211245536804199
Batch 55/64 loss: -2.188528060913086
Batch 56/64 loss: -1.8069534301757812
Batch 57/64 loss: -2.019227981567383
Batch 58/64 loss: -2.1017255783081055
Batch 59/64 loss: -2.0033674240112305
Batch 60/64 loss: -2.217409133911133
Batch 61/64 loss: -1.9025964736938477
Batch 62/64 loss: -1.996901512145996
Batch 63/64 loss: -2.0927562713623047
Batch 64/64 loss: -6.059023380279541
Epoch 334  Train loss: -2.1974105292675543  Val loss: -2.531065649183345
Epoch 335
-------------------------------
Batch 1/64 loss: -2.427786350250244
Batch 2/64 loss: -2.1036691665649414
Batch 3/64 loss: -2.384821891784668
Batch 4/64 loss: -2.190300941467285
Batch 5/64 loss: -2.376708984375
Batch 6/64 loss: -2.432112693786621
Batch 7/64 loss: -2.0686187744140625
Batch 8/64 loss: -2.2932052612304688
Batch 9/64 loss: -2.07552433013916
Batch 10/64 loss: -2.3058595657348633
Batch 11/64 loss: -2.219839096069336
Batch 12/64 loss: -2.2224769592285156
Batch 13/64 loss: -2.1642398834228516
Batch 14/64 loss: -2.3924832344055176
Batch 15/64 loss: -2.057107925415039
Batch 16/64 loss: -2.165236473083496
Batch 17/64 loss: -2.324522018432617
Batch 18/64 loss: -2.220913887023926
Batch 19/64 loss: -2.3009328842163086
Batch 20/64 loss: -2.3027548789978027
Batch 21/64 loss: -1.8191032409667969
Batch 22/64 loss: -1.9935903549194336
Batch 23/64 loss: -0.99542236328125
Batch 24/64 loss: -2.300966739654541
Batch 25/64 loss: -1.6788244247436523
Batch 26/64 loss: -1.4968185424804688
Batch 27/64 loss: -2.02420711517334
Batch 28/64 loss: -2.1723203659057617
Batch 29/64 loss: -2.027284622192383
Batch 30/64 loss: -2.001394271850586
Batch 31/64 loss: -1.9545526504516602
Batch 32/64 loss: -1.631143569946289
Batch 33/64 loss: -1.8505029678344727
Batch 34/64 loss: -1.7602357864379883
Batch 35/64 loss: -2.0661706924438477
Batch 36/64 loss: -0.9877510070800781
Batch 37/64 loss: -1.8696517944335938
Batch 38/64 loss: -2.010385513305664
Batch 39/64 loss: -1.7578802108764648
Batch 40/64 loss: -2.02850341796875
Batch 41/64 loss: -1.7204837799072266
Batch 42/64 loss: -1.7682075500488281
Batch 43/64 loss: -1.5779809951782227
Batch 44/64 loss: -1.9874029159545898
Batch 45/64 loss: -1.9125967025756836
Batch 46/64 loss: -1.6597328186035156
Batch 47/64 loss: -1.4435234069824219
Batch 48/64 loss: -1.7163619995117188
Batch 49/64 loss: -1.604649543762207
Batch 50/64 loss: -2.094982147216797
Batch 51/64 loss: -1.6439628601074219
Batch 52/64 loss: -1.7815017700195312
Batch 53/64 loss: -2.095791816711426
Batch 54/64 loss: -1.77398681640625
Batch 55/64 loss: -1.177083969116211
Batch 56/64 loss: -1.5974617004394531
Batch 57/64 loss: -1.953080177307129
Batch 58/64 loss: -2.0908632278442383
Batch 59/64 loss: -2.0634775161743164
Batch 60/64 loss: -1.892770767211914
Batch 61/64 loss: -1.7724924087524414
Batch 62/64 loss: -1.8109865188598633
Batch 63/64 loss: -1.6221599578857422
Batch 64/64 loss: -6.116722106933594
Epoch 335  Train loss: -1.9890965929218367  Val loss: -1.8770585863041305
Epoch 336
-------------------------------
Batch 1/64 loss: -2.050602912902832
Batch 2/64 loss: -1.730332374572754
Batch 3/64 loss: -1.8426008224487305
Batch 4/64 loss: -2.0320510864257812
Batch 5/64 loss: -1.7861194610595703
Batch 6/64 loss: -2.1979856491088867
Batch 7/64 loss: -1.8516340255737305
Batch 8/64 loss: -2.088590621948242
Batch 9/64 loss: -1.268564224243164
Batch 10/64 loss: -2.1732101440429688
Batch 11/64 loss: -1.7700319290161133
Batch 12/64 loss: -2.090439796447754
Batch 13/64 loss: -2.063638687133789
Batch 14/64 loss: -1.8822021484375
Batch 15/64 loss: -2.1629719734191895
Batch 16/64 loss: -1.8879261016845703
Batch 17/64 loss: -2.266185760498047
Batch 18/64 loss: -2.085010528564453
Batch 19/64 loss: -2.087553024291992
Batch 20/64 loss: -1.7690668106079102
Batch 21/64 loss: -2.142939567565918
Batch 22/64 loss: -2.083065986633301
Batch 23/64 loss: -2.1616058349609375
Batch 24/64 loss: -1.9654836654663086
Batch 25/64 loss: -1.9724483489990234
Batch 26/64 loss: -1.88714599609375
Batch 27/64 loss: -2.2425384521484375
Batch 28/64 loss: -2.181377410888672
Batch 29/64 loss: -2.20668888092041
Batch 30/64 loss: -1.8718080520629883
Batch 31/64 loss: -1.3626747131347656
Batch 32/64 loss: -2.17830753326416
Batch 33/64 loss: -2.1431331634521484
Batch 34/64 loss: -1.9744186401367188
Batch 35/64 loss: -1.9911909103393555
Batch 36/64 loss: -2.108501434326172
Batch 37/64 loss: -1.8314437866210938
Batch 38/64 loss: -2.1976771354675293
Batch 39/64 loss: -2.1053075790405273
Batch 40/64 loss: -2.2071757316589355
Batch 41/64 loss: -2.1417760848999023
Batch 42/64 loss: -1.9990873336791992
Batch 43/64 loss: -2.0888900756835938
Batch 44/64 loss: -2.292853355407715
Batch 45/64 loss: -1.900054931640625
Batch 46/64 loss: -2.1408939361572266
Batch 47/64 loss: -1.9837093353271484
Batch 48/64 loss: -2.186267852783203
Batch 49/64 loss: -2.187030792236328
Batch 50/64 loss: -2.269888401031494
Batch 51/64 loss: -2.140679359436035
Batch 52/64 loss: -2.183872699737549
Batch 53/64 loss: -1.8608474731445312
Batch 54/64 loss: -2.1657028198242188
Batch 55/64 loss: -2.107168197631836
Batch 56/64 loss: -1.813863754272461
Batch 57/64 loss: -2.2367806434631348
Batch 58/64 loss: -2.115910530090332
Batch 59/64 loss: -2.232865333557129
Batch 60/64 loss: -2.104564666748047
Batch 61/64 loss: -2.0385608673095703
Batch 62/64 loss: -2.244760036468506
Batch 63/64 loss: -1.9321174621582031
Batch 64/64 loss: -6.418663024902344
Epoch 336  Train loss: -2.0875889273250805  Val loss: -2.368499716532599
Epoch 337
-------------------------------
Batch 1/64 loss: -2.061093330383301
Batch 2/64 loss: -2.1559581756591797
Batch 3/64 loss: -2.0820045471191406
Batch 4/64 loss: -1.965458869934082
Batch 5/64 loss: -2.1729488372802734
Batch 6/64 loss: -2.174488067626953
Batch 7/64 loss: -2.3053665161132812
Batch 8/64 loss: -2.240347385406494
Batch 9/64 loss: -1.9480924606323242
Batch 10/64 loss: -2.0808334350585938
Batch 11/64 loss: -2.1894760131835938
Batch 12/64 loss: -2.119561195373535
Batch 13/64 loss: -2.131882667541504
Batch 14/64 loss: -2.246832847595215
Batch 15/64 loss: -2.0518722534179688
Batch 16/64 loss: -1.9490928649902344
Batch 17/64 loss: -2.3870906829833984
Batch 18/64 loss: -2.175070285797119
Batch 19/64 loss: -2.192598342895508
Batch 20/64 loss: -2.0698089599609375
Batch 21/64 loss: -2.276148796081543
Batch 22/64 loss: -2.252923011779785
Batch 23/64 loss: -2.1933517456054688
Batch 24/64 loss: -2.2242612838745117
Batch 25/64 loss: -2.2212743759155273
Batch 26/64 loss: -1.5316400527954102
Batch 27/64 loss: -2.27639102935791
Batch 28/64 loss: -2.020414352416992
Batch 29/64 loss: -2.2237210273742676
Batch 30/64 loss: -2.163334846496582
Batch 31/64 loss: -2.340031623840332
Batch 32/64 loss: -2.141111373901367
Batch 33/64 loss: -2.1026105880737305
Batch 34/64 loss: -2.118260383605957
Batch 35/64 loss: -2.2408413887023926
Batch 36/64 loss: -2.139192581176758
Batch 37/64 loss: -2.1047935485839844
Batch 38/64 loss: -2.153553009033203
Batch 39/64 loss: -2.0715198516845703
Batch 40/64 loss: -2.231752872467041
Batch 41/64 loss: -1.748544692993164
Batch 42/64 loss: -2.1965298652648926
Batch 43/64 loss: -2.242341995239258
Batch 44/64 loss: -2.2415356636047363
Batch 45/64 loss: -1.5096235275268555
Batch 46/64 loss: -1.9712324142456055
Batch 47/64 loss: -2.2411704063415527
Batch 48/64 loss: -2.1783065795898438
Batch 49/64 loss: -2.271505832672119
Batch 50/64 loss: -2.034881591796875
Batch 51/64 loss: -1.6764211654663086
Batch 52/64 loss: -2.0983963012695312
Batch 53/64 loss: -2.1969480514526367
Batch 54/64 loss: -2.2032766342163086
Batch 55/64 loss: -2.10336971282959
Batch 56/64 loss: -1.9699621200561523
Batch 57/64 loss: -2.0831222534179688
Batch 58/64 loss: -2.2202839851379395
Batch 59/64 loss: -2.218451976776123
Batch 60/64 loss: -2.282683849334717
Batch 61/64 loss: -2.1656675338745117
Batch 62/64 loss: -1.4492559432983398
Batch 63/64 loss: -2.176298141479492
Batch 64/64 loss: -6.353662967681885
Epoch 337  Train loss: -2.1642676540449552  Val loss: -2.524370462214414
Epoch 338
-------------------------------
Batch 1/64 loss: -2.281752109527588
Batch 2/64 loss: -2.0536880493164062
Batch 3/64 loss: -2.219552993774414
Batch 4/64 loss: -2.160557746887207
Batch 5/64 loss: -2.1916885375976562
Batch 6/64 loss: -2.087554931640625
Batch 7/64 loss: -2.0541677474975586
Batch 8/64 loss: -1.7185611724853516
Batch 9/64 loss: -2.1595821380615234
Batch 10/64 loss: -2.0011682510375977
Batch 11/64 loss: -2.201472282409668
Batch 12/64 loss: -2.3054633140563965
Batch 13/64 loss: -2.258232593536377
Batch 14/64 loss: -2.2289934158325195
Batch 15/64 loss: -2.101498603820801
Batch 16/64 loss: -1.6307029724121094
Batch 17/64 loss: -2.284834384918213
Batch 18/64 loss: -2.358142375946045
Batch 19/64 loss: -2.2640609741210938
Batch 20/64 loss: -2.126572608947754
Batch 21/64 loss: -2.1543588638305664
Batch 22/64 loss: -1.4444360733032227
Batch 23/64 loss: -2.254627227783203
Batch 24/64 loss: -1.9654951095581055
Batch 25/64 loss: -2.073990821838379
Batch 26/64 loss: -2.239497661590576
Batch 27/64 loss: -2.349905490875244
Batch 28/64 loss: -2.264777660369873
Batch 29/64 loss: -2.1131601333618164
Batch 30/64 loss: -2.3554391860961914
Batch 31/64 loss: -2.339301586151123
Batch 32/64 loss: -2.148951530456543
Batch 33/64 loss: -2.1987810134887695
Batch 34/64 loss: -1.9405813217163086
Batch 35/64 loss: -2.193024158477783
Batch 36/64 loss: -2.0006418228149414
Batch 37/64 loss: -2.270406723022461
Batch 38/64 loss: -1.9406499862670898
Batch 39/64 loss: -2.2864184379577637
Batch 40/64 loss: -2.1473140716552734
Batch 41/64 loss: -2.030035972595215
Batch 42/64 loss: -2.255545139312744
Batch 43/64 loss: -1.9065771102905273
Batch 44/64 loss: -2.236970901489258
Batch 45/64 loss: -2.1234989166259766
Batch 46/64 loss: -2.3121790885925293
Batch 47/64 loss: -2.1833620071411133
Batch 48/64 loss: -2.015026092529297
Batch 49/64 loss: -2.144336700439453
Batch 50/64 loss: -2.4707236289978027
Batch 51/64 loss: -2.212740898132324
Batch 52/64 loss: -2.379837989807129
Batch 53/64 loss: -2.1547622680664062
Batch 54/64 loss: -2.340928077697754
Batch 55/64 loss: -2.2861552238464355
Batch 56/64 loss: -1.9351224899291992
Batch 57/64 loss: -2.119145393371582
Batch 58/64 loss: -2.3046536445617676
Batch 59/64 loss: -2.3037056922912598
Batch 60/64 loss: -2.1510839462280273
Batch 61/64 loss: -2.305715560913086
Batch 62/64 loss: -2.1847620010375977
Batch 63/64 loss: -2.3643088340759277
Batch 64/64 loss: -6.346190452575684
Epoch 338  Train loss: -2.2094247294407263  Val loss: -2.6200917824027465
Saving best model, epoch: 338
Epoch 339
-------------------------------
Batch 1/64 loss: -2.307701587677002
Batch 2/64 loss: -2.1172237396240234
Batch 3/64 loss: -2.316375732421875
Batch 4/64 loss: -2.225052833557129
Batch 5/64 loss: -2.255720615386963
Batch 6/64 loss: -2.326382637023926
Batch 7/64 loss: -1.8605070114135742
Batch 8/64 loss: -2.290076732635498
Batch 9/64 loss: -1.9560441970825195
Batch 10/64 loss: -2.338296890258789
Batch 11/64 loss: -2.3466105461120605
Batch 12/64 loss: -2.064300537109375
Batch 13/64 loss: -2.3769211769104004
Batch 14/64 loss: -2.307279109954834
Batch 15/64 loss: -2.172578811645508
Batch 16/64 loss: -2.2344207763671875
Batch 17/64 loss: -2.155519485473633
Batch 18/64 loss: -2.2692461013793945
Batch 19/64 loss: -2.1690969467163086
Batch 20/64 loss: -2.3379688262939453
Batch 21/64 loss: -2.344365119934082
Batch 22/64 loss: -2.1250619888305664
Batch 23/64 loss: -2.135390281677246
Batch 24/64 loss: -1.5215377807617188
Batch 25/64 loss: -2.33978271484375
Batch 26/64 loss: -2.14774227142334
Batch 27/64 loss: -2.144458770751953
Batch 28/64 loss: -2.1287965774536133
Batch 29/64 loss: -2.149979591369629
Batch 30/64 loss: -2.369100570678711
Batch 31/64 loss: -2.23757266998291
Batch 32/64 loss: -2.029844284057617
Batch 33/64 loss: -2.0727996826171875
Batch 34/64 loss: -1.690521240234375
Batch 35/64 loss: -2.26046085357666
Batch 36/64 loss: -2.390852928161621
Batch 37/64 loss: -2.058551788330078
Batch 38/64 loss: -2.0342884063720703
Batch 39/64 loss: -2.240645408630371
Batch 40/64 loss: -2.06050968170166
Batch 41/64 loss: -2.2080888748168945
Batch 42/64 loss: -2.135395050048828
Batch 43/64 loss: -2.0196924209594727
Batch 44/64 loss: -2.2599267959594727
Batch 45/64 loss: -2.145801544189453
Batch 46/64 loss: -2.024862289428711
Batch 47/64 loss: -2.093785285949707
Batch 48/64 loss: -1.717794418334961
Batch 49/64 loss: -2.2251195907592773
Batch 50/64 loss: -2.096207618713379
Batch 51/64 loss: -1.9835329055786133
Batch 52/64 loss: -2.365954875946045
Batch 53/64 loss: -2.1403636932373047
Batch 54/64 loss: -2.1570301055908203
Batch 55/64 loss: -2.2213211059570312
Batch 56/64 loss: -2.0037918090820312
Batch 57/64 loss: -2.109170913696289
Batch 58/64 loss: -2.286503791809082
Batch 59/64 loss: -2.3673324584960938
Batch 60/64 loss: -2.373844623565674
Batch 61/64 loss: -2.0419883728027344
Batch 62/64 loss: -1.956613540649414
Batch 63/64 loss: -2.3701610565185547
Batch 64/64 loss: -6.462414264678955
Epoch 339  Train loss: -2.2127165607377592  Val loss: -2.519626132401404
Epoch 340
-------------------------------
Batch 1/64 loss: -2.0258665084838867
Batch 2/64 loss: -2.064997673034668
Batch 3/64 loss: -2.1073379516601562
Batch 4/64 loss: -2.2221202850341797
Batch 5/64 loss: -2.1797266006469727
Batch 6/64 loss: -2.2927870750427246
Batch 7/64 loss: -2.404435157775879
Batch 8/64 loss: -2.2052154541015625
Batch 9/64 loss: -2.304410457611084
Batch 10/64 loss: -2.088441848754883
Batch 11/64 loss: -2.256288528442383
Batch 12/64 loss: -2.0216569900512695
Batch 13/64 loss: -2.1946868896484375
Batch 14/64 loss: -2.0541629791259766
Batch 15/64 loss: -2.213909149169922
Batch 16/64 loss: -1.93316650390625
Batch 17/64 loss: -2.3395442962646484
Batch 18/64 loss: -2.19124698638916
Batch 19/64 loss: -2.0196056365966797
Batch 20/64 loss: -2.329533100128174
Batch 21/64 loss: -2.1074390411376953
Batch 22/64 loss: -2.395242214202881
Batch 23/64 loss: -2.3230533599853516
Batch 24/64 loss: -2.2508649826049805
Batch 25/64 loss: -2.1275901794433594
Batch 26/64 loss: -1.7071456909179688
Batch 27/64 loss: -2.26625919342041
Batch 28/64 loss: -2.153740882873535
Batch 29/64 loss: -2.2130603790283203
Batch 30/64 loss: -2.2587900161743164
Batch 31/64 loss: -2.025141716003418
Batch 32/64 loss: -2.269068717956543
Batch 33/64 loss: -2.1740970611572266
Batch 34/64 loss: -2.3837995529174805
Batch 35/64 loss: -2.2008352279663086
Batch 36/64 loss: -2.075328826904297
Batch 37/64 loss: -1.9980154037475586
Batch 38/64 loss: -2.2839903831481934
Batch 39/64 loss: -2.062403678894043
Batch 40/64 loss: -2.30875301361084
Batch 41/64 loss: -1.9854354858398438
Batch 42/64 loss: -2.2958760261535645
Batch 43/64 loss: -2.2676753997802734
Batch 44/64 loss: -2.1574792861938477
Batch 45/64 loss: -2.353820323944092
Batch 46/64 loss: -1.7232837677001953
Batch 47/64 loss: -2.311913013458252
Batch 48/64 loss: -2.2439022064208984
Batch 49/64 loss: -1.74688720703125
Batch 50/64 loss: -1.2692537307739258
Batch 51/64 loss: -2.320220947265625
Batch 52/64 loss: -2.1113204956054688
Batch 53/64 loss: -2.307739734649658
Batch 54/64 loss: -2.215968132019043
Batch 55/64 loss: -1.9482364654541016
Batch 56/64 loss: -2.178037643432617
Batch 57/64 loss: -2.310706615447998
Batch 58/64 loss: -2.2723159790039062
Batch 59/64 loss: -2.111647605895996
Batch 60/64 loss: -2.2414188385009766
Batch 61/64 loss: -1.9447154998779297
Batch 62/64 loss: -2.168689727783203
Batch 63/64 loss: -2.1954193115234375
Batch 64/64 loss: -5.99450159072876
Epoch 340  Train loss: -2.1993976349924127  Val loss: -2.3320189276102075
Epoch 341
-------------------------------
Batch 1/64 loss: -1.9504117965698242
Batch 2/64 loss: -2.298041820526123
Batch 3/64 loss: -2.366668224334717
Batch 4/64 loss: -2.0809707641601562
Batch 5/64 loss: -2.157388687133789
Batch 6/64 loss: -2.009129524230957
Batch 7/64 loss: -2.090625762939453
Batch 8/64 loss: -1.8215227127075195
Batch 9/64 loss: -1.9158992767333984
Batch 10/64 loss: -2.008429527282715
Batch 11/64 loss: -1.953444480895996
Batch 12/64 loss: -1.8941211700439453
Batch 13/64 loss: -2.0003089904785156
Batch 14/64 loss: -2.0512876510620117
Batch 15/64 loss: -2.058438301086426
Batch 16/64 loss: -2.263382911682129
Batch 17/64 loss: -2.1180028915405273
Batch 18/64 loss: -2.217892646789551
Batch 19/64 loss: -1.7234678268432617
Batch 20/64 loss: -1.8917083740234375
Batch 21/64 loss: -2.042032241821289
Batch 22/64 loss: -2.13651180267334
Batch 23/64 loss: -2.21877384185791
Batch 24/64 loss: -2.0780696868896484
Batch 25/64 loss: -2.2017393112182617
Batch 26/64 loss: -2.260403633117676
Batch 27/64 loss: -1.2969446182250977
Batch 28/64 loss: -2.267911911010742
Batch 29/64 loss: -2.198221206665039
Batch 30/64 loss: -2.1805334091186523
Batch 31/64 loss: -2.241415023803711
Batch 32/64 loss: -2.0376462936401367
Batch 33/64 loss: -2.0457868576049805
Batch 34/64 loss: -2.116511344909668
Batch 35/64 loss: -1.4380817413330078
Batch 36/64 loss: -2.302469253540039
Batch 37/64 loss: -2.3616819381713867
Batch 38/64 loss: -2.361971855163574
Batch 39/64 loss: -1.8443822860717773
Batch 40/64 loss: -1.811798095703125
Batch 41/64 loss: -2.0112791061401367
Batch 42/64 loss: -1.8850784301757812
Batch 43/64 loss: -2.130239486694336
Batch 44/64 loss: -2.2908191680908203
Batch 45/64 loss: -2.1988134384155273
Batch 46/64 loss: -2.1219635009765625
Batch 47/64 loss: -2.258822441101074
Batch 48/64 loss: -2.29947566986084
Batch 49/64 loss: -1.95361328125
Batch 50/64 loss: -2.185360908508301
Batch 51/64 loss: -2.44842529296875
Batch 52/64 loss: -2.4108762741088867
Batch 53/64 loss: -2.24725341796875
Batch 54/64 loss: -2.2628250122070312
Batch 55/64 loss: -2.252999782562256
Batch 56/64 loss: -2.0649709701538086
Batch 57/64 loss: -2.392941474914551
Batch 58/64 loss: -2.284735679626465
Batch 59/64 loss: -2.222426414489746
Batch 60/64 loss: -2.1741256713867188
Batch 61/64 loss: -2.2186317443847656
Batch 62/64 loss: -2.089212417602539
Batch 63/64 loss: -2.1931867599487305
Batch 64/64 loss: -6.435076713562012
Epoch 341  Train loss: -2.1606025658401786  Val loss: -2.624454340983912
Saving best model, epoch: 341
Epoch 342
-------------------------------
Batch 1/64 loss: -2.056631088256836
Batch 2/64 loss: -2.1967992782592773
Batch 3/64 loss: -2.3701701164245605
Batch 4/64 loss: -2.1542253494262695
Batch 5/64 loss: -1.781900405883789
Batch 6/64 loss: -2.1690731048583984
Batch 7/64 loss: -2.1782941818237305
Batch 8/64 loss: -2.1517333984375
Batch 9/64 loss: -2.211122512817383
Batch 10/64 loss: -2.2629919052124023
Batch 11/64 loss: -2.3729162216186523
Batch 12/64 loss: -2.301347255706787
Batch 13/64 loss: -2.377129077911377
Batch 14/64 loss: -2.184436798095703
Batch 15/64 loss: -1.9926862716674805
Batch 16/64 loss: -2.362191677093506
Batch 17/64 loss: -2.372706413269043
Batch 18/64 loss: -2.221111297607422
Batch 19/64 loss: -2.071751594543457
Batch 20/64 loss: -2.3925671577453613
Batch 21/64 loss: -2.3171634674072266
Batch 22/64 loss: -2.278231143951416
Batch 23/64 loss: -2.2492971420288086
Batch 24/64 loss: -2.239884376525879
Batch 25/64 loss: -2.1355409622192383
Batch 26/64 loss: -2.2597060203552246
Batch 27/64 loss: -2.1838111877441406
Batch 28/64 loss: -2.177295684814453
Batch 29/64 loss: -2.1879425048828125
Batch 30/64 loss: -2.3052778244018555
Batch 31/64 loss: -2.086282730102539
Batch 32/64 loss: -2.04720401763916
Batch 33/64 loss: -2.1789283752441406
Batch 34/64 loss: -2.2553577423095703
Batch 35/64 loss: -2.1035194396972656
Batch 36/64 loss: -2.197032928466797
Batch 37/64 loss: -2.1260557174682617
Batch 38/64 loss: -1.208399772644043
Batch 39/64 loss: -1.33135986328125
Batch 40/64 loss: -2.206266403198242
Batch 41/64 loss: -2.122194290161133
Batch 42/64 loss: -2.010525703430176
Batch 43/64 loss: -1.9925289154052734
Batch 44/64 loss: -2.292109489440918
Batch 45/64 loss: -2.227290153503418
Batch 46/64 loss: -2.280146598815918
Batch 47/64 loss: -2.106001853942871
Batch 48/64 loss: -2.1907730102539062
Batch 49/64 loss: -2.137786865234375
Batch 50/64 loss: -2.2495832443237305
Batch 51/64 loss: -2.298586845397949
Batch 52/64 loss: -1.7852373123168945
Batch 53/64 loss: -1.9669256210327148
Batch 54/64 loss: -2.2238197326660156
Batch 55/64 loss: -2.381124496459961
Batch 56/64 loss: -2.255478858947754
Batch 57/64 loss: -2.0806102752685547
Batch 58/64 loss: -2.199728012084961
Batch 59/64 loss: -2.1971092224121094
Batch 60/64 loss: -2.302837371826172
Batch 61/64 loss: -2.071234703063965
Batch 62/64 loss: -2.0599231719970703
Batch 63/64 loss: -2.2246341705322266
Batch 64/64 loss: -6.464871883392334
Epoch 342  Train loss: -2.208018607719272  Val loss: -2.3652720631602704
Epoch 343
-------------------------------
Batch 1/64 loss: -2.1058263778686523
Batch 2/64 loss: -2.0198211669921875
Batch 3/64 loss: -2.144735336303711
Batch 4/64 loss: -2.1599550247192383
Batch 5/64 loss: -2.0804309844970703
Batch 6/64 loss: -2.193881034851074
Batch 7/64 loss: -2.04315185546875
Batch 8/64 loss: -1.9272356033325195
Batch 9/64 loss: -2.1366024017333984
Batch 10/64 loss: -2.0780553817749023
Batch 11/64 loss: -2.3609580993652344
Batch 12/64 loss: -2.177154541015625
Batch 13/64 loss: -2.3076086044311523
Batch 14/64 loss: -2.3386669158935547
Batch 15/64 loss: -1.9690265655517578
Batch 16/64 loss: -2.3079910278320312
Batch 17/64 loss: -2.0778112411499023
Batch 18/64 loss: -1.9090766906738281
Batch 19/64 loss: -2.3644275665283203
Batch 20/64 loss: -2.266387939453125
Batch 21/64 loss: -2.265573501586914
Batch 22/64 loss: -1.538313865661621
Batch 23/64 loss: -1.5898551940917969
Batch 24/64 loss: -2.150167465209961
Batch 25/64 loss: -2.3618087768554688
Batch 26/64 loss: -2.289854049682617
Batch 27/64 loss: -2.0960817337036133
Batch 28/64 loss: -2.1780223846435547
Batch 29/64 loss: -2.354846477508545
Batch 30/64 loss: -2.1969566345214844
Batch 31/64 loss: -2.3599729537963867
Batch 32/64 loss: -2.057724952697754
Batch 33/64 loss: -2.3008642196655273
Batch 34/64 loss: -2.3389835357666016
Batch 35/64 loss: -2.335402488708496
Batch 36/64 loss: -2.2110767364501953
Batch 37/64 loss: -1.770289421081543
Batch 38/64 loss: -2.359738826751709
Batch 39/64 loss: -2.2341747283935547
Batch 40/64 loss: -1.9478445053100586
Batch 41/64 loss: -2.28208065032959
Batch 42/64 loss: -2.147428512573242
Batch 43/64 loss: -2.3671202659606934
Batch 44/64 loss: -2.240314483642578
Batch 45/64 loss: -2.2125282287597656
Batch 46/64 loss: -2.0726194381713867
Batch 47/64 loss: -2.2739181518554688
Batch 48/64 loss: -2.085038185119629
Batch 49/64 loss: -1.882772445678711
Batch 50/64 loss: -1.986119270324707
Batch 51/64 loss: -2.1683168411254883
Batch 52/64 loss: -2.234889030456543
Batch 53/64 loss: -2.3587865829467773
Batch 54/64 loss: -2.2794570922851562
Batch 55/64 loss: -2.129918098449707
Batch 56/64 loss: -1.978653907775879
Batch 57/64 loss: -2.2617645263671875
Batch 58/64 loss: -2.238619804382324
Batch 59/64 loss: -2.422051429748535
Batch 60/64 loss: -2.141448974609375
Batch 61/64 loss: -2.177546501159668
Batch 62/64 loss: -1.9869403839111328
Batch 63/64 loss: -1.8894720077514648
Batch 64/64 loss: -6.108171463012695
Epoch 343  Train loss: -2.2008672976026347  Val loss: -2.536381449486382
Epoch 344
-------------------------------
Batch 1/64 loss: -2.305635452270508
Batch 2/64 loss: -2.3300442695617676
Batch 3/64 loss: -2.116199493408203
Batch 4/64 loss: -2.2254066467285156
Batch 5/64 loss: -2.346586227416992
Batch 6/64 loss: -2.2460479736328125
Batch 7/64 loss: -1.7892303466796875
Batch 8/64 loss: -2.3439674377441406
Batch 9/64 loss: -2.1557579040527344
Batch 10/64 loss: -2.2477245330810547
Batch 11/64 loss: -2.288601875305176
Batch 12/64 loss: -2.267531394958496
Batch 13/64 loss: -2.2171096801757812
Batch 14/64 loss: -2.343954563140869
Batch 15/64 loss: -1.8573036193847656
Batch 16/64 loss: -2.0405893325805664
Batch 17/64 loss: -1.5672063827514648
Batch 18/64 loss: -2.4009714126586914
Batch 19/64 loss: -2.1216440200805664
Batch 20/64 loss: -1.3398714065551758
Batch 21/64 loss: -2.185680389404297
Batch 22/64 loss: -2.1790056228637695
Batch 23/64 loss: -2.003188133239746
Batch 24/64 loss: -2.3569135665893555
Batch 25/64 loss: -2.102137565612793
Batch 26/64 loss: -2.2983951568603516
Batch 27/64 loss: -2.090221405029297
Batch 28/64 loss: -2.2748031616210938
Batch 29/64 loss: -2.2285890579223633
Batch 30/64 loss: -2.0879058837890625
Batch 31/64 loss: -2.1985597610473633
Batch 32/64 loss: -2.1683311462402344
Batch 33/64 loss: -2.242107391357422
Batch 34/64 loss: -2.267374038696289
Batch 35/64 loss: -2.2882299423217773
Batch 36/64 loss: -2.2964086532592773
Batch 37/64 loss: -2.172144889831543
Batch 38/64 loss: -2.190232276916504
Batch 39/64 loss: -2.3162479400634766
Batch 40/64 loss: -2.179245948791504
Batch 41/64 loss: -2.0088253021240234
Batch 42/64 loss: -2.07489013671875
Batch 43/64 loss: -2.056222915649414
Batch 44/64 loss: -2.116119384765625
Batch 45/64 loss: -2.060222625732422
Batch 46/64 loss: -1.438497543334961
Batch 47/64 loss: -1.817246437072754
Batch 48/64 loss: -2.1907148361206055
Batch 49/64 loss: -2.147928237915039
Batch 50/64 loss: -2.341061592102051
Batch 51/64 loss: -1.2909955978393555
Batch 52/64 loss: -1.980752944946289
Batch 53/64 loss: -1.9651222229003906
Batch 54/64 loss: -1.443751335144043
Batch 55/64 loss: -2.130356788635254
Batch 56/64 loss: -2.10357666015625
Batch 57/64 loss: -2.0393943786621094
Batch 58/64 loss: -2.2579545974731445
Batch 59/64 loss: -2.1200990676879883
Batch 60/64 loss: -2.201663017272949
Batch 61/64 loss: -2.1743459701538086
Batch 62/64 loss: -2.212390899658203
Batch 63/64 loss: -1.9769306182861328
Batch 64/64 loss: -6.490037441253662
Epoch 344  Train loss: -2.1599011309006633  Val loss: -2.4005682771558203
Epoch 345
-------------------------------
Batch 1/64 loss: -1.8949241638183594
Batch 2/64 loss: -2.2559356689453125
Batch 3/64 loss: -1.8742132186889648
Batch 4/64 loss: -2.125176429748535
Batch 5/64 loss: -2.3141469955444336
Batch 6/64 loss: -2.029905319213867
Batch 7/64 loss: -2.1454343795776367
Batch 8/64 loss: -2.2183151245117188
Batch 9/64 loss: -2.043398857116699
Batch 10/64 loss: -1.973184585571289
Batch 11/64 loss: -2.151618003845215
Batch 12/64 loss: -2.172165870666504
Batch 13/64 loss: -2.075493812561035
Batch 14/64 loss: -2.304412841796875
Batch 15/64 loss: -1.9145212173461914
Batch 16/64 loss: -1.8401498794555664
Batch 17/64 loss: -2.222414970397949
Batch 18/64 loss: -2.154573440551758
Batch 19/64 loss: -2.0197877883911133
Batch 20/64 loss: -2.2555179595947266
Batch 21/64 loss: -2.167464256286621
Batch 22/64 loss: -2.1624536514282227
Batch 23/64 loss: -2.3086938858032227
Batch 24/64 loss: -2.252969741821289
Batch 25/64 loss: -1.8441686630249023
Batch 26/64 loss: -2.1546478271484375
Batch 27/64 loss: -2.197596549987793
Batch 28/64 loss: -2.2151851654052734
Batch 29/64 loss: -2.3608150482177734
Batch 30/64 loss: -1.8061256408691406
Batch 31/64 loss: -1.8822031021118164
Batch 32/64 loss: -2.2029457092285156
Batch 33/64 loss: -2.380751132965088
Batch 34/64 loss: -1.9010581970214844
Batch 35/64 loss: -2.377431869506836
Batch 36/64 loss: -2.0809764862060547
Batch 37/64 loss: -2.358011245727539
Batch 38/64 loss: -1.9073734283447266
Batch 39/64 loss: -1.5375118255615234
Batch 40/64 loss: -2.159308433532715
Batch 41/64 loss: -2.189504623413086
Batch 42/64 loss: -2.2174911499023438
Batch 43/64 loss: -2.1687088012695312
Batch 44/64 loss: -2.0227479934692383
Batch 45/64 loss: -2.0365962982177734
Batch 46/64 loss: -2.2982521057128906
Batch 47/64 loss: -2.1769485473632812
Batch 48/64 loss: -2.1310739517211914
Batch 49/64 loss: -1.4545249938964844
Batch 50/64 loss: -2.0688133239746094
Batch 51/64 loss: -2.2343053817749023
Batch 52/64 loss: -2.2090225219726562
Batch 53/64 loss: -1.9623279571533203
Batch 54/64 loss: -2.1642770767211914
Batch 55/64 loss: -2.3583507537841797
Batch 56/64 loss: -1.9367341995239258
Batch 57/64 loss: -2.27101993560791
Batch 58/64 loss: -2.0307540893554688
Batch 59/64 loss: -2.2367048263549805
Batch 60/64 loss: -2.282076835632324
Batch 61/64 loss: -2.016036033630371
Batch 62/64 loss: -2.0785999298095703
Batch 63/64 loss: -2.274613857269287
Batch 64/64 loss: -6.208662986755371
Epoch 345  Train loss: -2.1602974872963103  Val loss: -2.5394301267014336
Epoch 346
-------------------------------
Batch 1/64 loss: -2.273664951324463
Batch 2/64 loss: -2.2354660034179688
Batch 3/64 loss: -2.3642044067382812
Batch 4/64 loss: -2.264280319213867
Batch 5/64 loss: -1.1763010025024414
Batch 6/64 loss: -2.097109794616699
Batch 7/64 loss: -2.4090709686279297
Batch 8/64 loss: -2.3113694190979004
Batch 9/64 loss: -2.1838855743408203
Batch 10/64 loss: -2.101263999938965
Batch 11/64 loss: -2.130528450012207
Batch 12/64 loss: -1.8027324676513672
Batch 13/64 loss: -2.331768035888672
Batch 14/64 loss: -2.329601287841797
Batch 15/64 loss: -2.202559471130371
Batch 16/64 loss: -2.0226783752441406
Batch 17/64 loss: -2.184199333190918
Batch 18/64 loss: -2.1242475509643555
Batch 19/64 loss: -2.2492904663085938
Batch 20/64 loss: -2.0930681228637695
Batch 21/64 loss: -2.290058135986328
Batch 22/64 loss: -2.3027443885803223
Batch 23/64 loss: -2.3701629638671875
Batch 24/64 loss: -1.8371047973632812
Batch 25/64 loss: -1.6101274490356445
Batch 26/64 loss: -2.2411327362060547
Batch 27/64 loss: -2.1628055572509766
Batch 28/64 loss: -2.2241411209106445
Batch 29/64 loss: -1.9637384414672852
Batch 30/64 loss: -2.2169113159179688
Batch 31/64 loss: -2.1984291076660156
Batch 32/64 loss: -2.3328771591186523
Batch 33/64 loss: -2.232227325439453
Batch 34/64 loss: -2.13527774810791
Batch 35/64 loss: -2.1923513412475586
Batch 36/64 loss: -2.118661880493164
Batch 37/64 loss: -2.330015182495117
Batch 38/64 loss: -2.0473079681396484
Batch 39/64 loss: -2.024876594543457
Batch 40/64 loss: -2.1157360076904297
Batch 41/64 loss: -2.192066192626953
Batch 42/64 loss: -2.221652030944824
Batch 43/64 loss: -2.186610221862793
Batch 44/64 loss: -2.226008415222168
Batch 45/64 loss: -2.3874406814575195
Batch 46/64 loss: -2.3091654777526855
Batch 47/64 loss: -2.3498620986938477
Batch 48/64 loss: -2.1778478622436523
Batch 49/64 loss: -2.5891504287719727
Batch 50/64 loss: -1.9173479080200195
Batch 51/64 loss: -1.4033966064453125
Batch 52/64 loss: -2.1188840866088867
Batch 53/64 loss: -2.405517578125
Batch 54/64 loss: -1.9686107635498047
Batch 55/64 loss: -2.271341323852539
Batch 56/64 loss: -2.004836082458496
Batch 57/64 loss: -2.0879831314086914
Batch 58/64 loss: -1.9598875045776367
Batch 59/64 loss: -1.5122661590576172
Batch 60/64 loss: -1.970566749572754
Batch 61/64 loss: -2.3340301513671875
Batch 62/64 loss: -2.3076696395874023
Batch 63/64 loss: -2.519941806793213
Batch 64/64 loss: -6.600158214569092
Epoch 346  Train loss: -2.199312608382281  Val loss: -2.516878790052486
Epoch 347
-------------------------------
Batch 1/64 loss: -2.2034730911254883
Batch 2/64 loss: -2.3743696212768555
Batch 3/64 loss: -2.1581907272338867
Batch 4/64 loss: -2.193305015563965
Batch 5/64 loss: -1.7445716857910156
Batch 6/64 loss: -2.251816749572754
Batch 7/64 loss: -2.1469287872314453
Batch 8/64 loss: -2.1160078048706055
Batch 9/64 loss: -2.1879987716674805
Batch 10/64 loss: -2.2215089797973633
Batch 11/64 loss: -1.5605497360229492
Batch 12/64 loss: -2.185995101928711
Batch 13/64 loss: -1.7028703689575195
Batch 14/64 loss: -2.263507843017578
Batch 15/64 loss: -2.23038387298584
Batch 16/64 loss: -2.168172836303711
Batch 17/64 loss: -2.3338661193847656
Batch 18/64 loss: -2.282689094543457
Batch 19/64 loss: -2.03983211517334
Batch 20/64 loss: -2.154329299926758
Batch 21/64 loss: -2.0673818588256836
Batch 22/64 loss: -2.308628559112549
Batch 23/64 loss: -2.158397674560547
Batch 24/64 loss: -2.123713493347168
Batch 25/64 loss: -2.240995407104492
Batch 26/64 loss: -2.3885817527770996
Batch 27/64 loss: -2.280226707458496
Batch 28/64 loss: -2.4182019233703613
Batch 29/64 loss: -2.2995309829711914
Batch 30/64 loss: -2.2587451934814453
Batch 31/64 loss: -1.984959602355957
Batch 32/64 loss: -2.190976142883301
Batch 33/64 loss: -2.329738140106201
Batch 34/64 loss: -2.1167287826538086
Batch 35/64 loss: -2.2439746856689453
Batch 36/64 loss: -2.0144729614257812
Batch 37/64 loss: -2.3351845741271973
Batch 38/64 loss: -2.168850898742676
Batch 39/64 loss: -2.3505678176879883
Batch 40/64 loss: -2.2067556381225586
Batch 41/64 loss: -1.2732124328613281
Batch 42/64 loss: -2.419495105743408
Batch 43/64 loss: -2.3122472763061523
Batch 44/64 loss: -2.10703182220459
Batch 45/64 loss: -2.011702537536621
Batch 46/64 loss: -2.198434829711914
Batch 47/64 loss: -2.19650936126709
Batch 48/64 loss: -2.270543098449707
Batch 49/64 loss: -2.301593780517578
Batch 50/64 loss: -2.259763717651367
Batch 51/64 loss: -2.1635971069335938
Batch 52/64 loss: -2.4405503273010254
Batch 53/64 loss: -2.3215036392211914
Batch 54/64 loss: -2.348388671875
Batch 55/64 loss: -2.265188217163086
Batch 56/64 loss: -2.0463409423828125
Batch 57/64 loss: -1.7541208267211914
Batch 58/64 loss: -2.113462448120117
Batch 59/64 loss: -2.447068214416504
Batch 60/64 loss: -2.3587541580200195
Batch 61/64 loss: -2.012971878051758
Batch 62/64 loss: -2.2249746322631836
Batch 63/64 loss: -2.2700443267822266
Batch 64/64 loss: -6.440387725830078
Epoch 347  Train loss: -2.2267414990593406  Val loss: -2.513305926241006
Epoch 348
-------------------------------
Batch 1/64 loss: -2.294735908508301
Batch 2/64 loss: -2.164670944213867
Batch 3/64 loss: -1.995427131652832
Batch 4/64 loss: -2.2313241958618164
Batch 5/64 loss: -2.2708892822265625
Batch 6/64 loss: -1.9051580429077148
Batch 7/64 loss: -1.7686614990234375
Batch 8/64 loss: -2.1693458557128906
Batch 9/64 loss: -2.0418777465820312
Batch 10/64 loss: -2.0617876052856445
Batch 11/64 loss: -2.1376686096191406
Batch 12/64 loss: -2.0955591201782227
Batch 13/64 loss: -1.6190547943115234
Batch 14/64 loss: -2.2180166244506836
Batch 15/64 loss: -1.8508014678955078
Batch 16/64 loss: -2.054873466491699
Batch 17/64 loss: -1.9163389205932617
Batch 18/64 loss: -1.9598627090454102
Batch 19/64 loss: -2.115325927734375
Batch 20/64 loss: -2.3217291831970215
Batch 21/64 loss: -2.2460079193115234
Batch 22/64 loss: -2.214628219604492
Batch 23/64 loss: -2.0688037872314453
Batch 24/64 loss: -2.2875871658325195
Batch 25/64 loss: -2.101323127746582
Batch 26/64 loss: -2.330099105834961
Batch 27/64 loss: -2.405684471130371
Batch 28/64 loss: -2.2403573989868164
Batch 29/64 loss: -2.4261484146118164
Batch 30/64 loss: -2.2135677337646484
Batch 31/64 loss: -2.245880126953125
Batch 32/64 loss: -2.4446539878845215
Batch 33/64 loss: -2.4897050857543945
Batch 34/64 loss: -2.3793678283691406
Batch 35/64 loss: -2.228334426879883
Batch 36/64 loss: -2.292001247406006
Batch 37/64 loss: -2.3563876152038574
Batch 38/64 loss: -2.3520703315734863
Batch 39/64 loss: -2.3557052612304688
Batch 40/64 loss: -1.4256601333618164
Batch 41/64 loss: -2.1888818740844727
Batch 42/64 loss: -2.277019500732422
Batch 43/64 loss: -2.2676753997802734
Batch 44/64 loss: -2.0699892044067383
Batch 45/64 loss: -2.149869918823242
Batch 46/64 loss: -2.2757997512817383
Batch 47/64 loss: -1.540440559387207
Batch 48/64 loss: -2.1199283599853516
Batch 49/64 loss: -2.18656063079834
Batch 50/64 loss: -2.0182762145996094
Batch 51/64 loss: -2.0736513137817383
Batch 52/64 loss: -2.318236827850342
Batch 53/64 loss: -1.8430328369140625
Batch 54/64 loss: -1.2919025421142578
Batch 55/64 loss: -2.2974228858947754
Batch 56/64 loss: -2.2741708755493164
Batch 57/64 loss: -1.970259666442871
Batch 58/64 loss: -2.329634189605713
Batch 59/64 loss: -2.061483383178711
Batch 60/64 loss: -2.166691780090332
Batch 61/64 loss: -2.284451484680176
Batch 62/64 loss: -2.0062780380249023
Batch 63/64 loss: -2.2164268493652344
Batch 64/64 loss: -6.42275857925415
Epoch 348  Train loss: -2.185760556015314  Val loss: -2.5370708740863606
Epoch 349
-------------------------------
Batch 1/64 loss: -2.1473464965820312
Batch 2/64 loss: -2.1082191467285156
Batch 3/64 loss: -2.1724796295166016
Batch 4/64 loss: -2.26436710357666
Batch 5/64 loss: -2.3102030754089355
Batch 6/64 loss: -1.4946537017822266
Batch 7/64 loss: -1.9669570922851562
Batch 8/64 loss: -2.319448471069336
Batch 9/64 loss: -1.9964351654052734
Batch 10/64 loss: -2.144397735595703
Batch 11/64 loss: -2.140873908996582
Batch 12/64 loss: -2.3868141174316406
Batch 13/64 loss: -1.905797004699707
Batch 14/64 loss: -2.2781496047973633
Batch 15/64 loss: -1.6383123397827148
Batch 16/64 loss: -2.4212026596069336
Batch 17/64 loss: -2.0555295944213867
Batch 18/64 loss: -2.0954513549804688
Batch 19/64 loss: -2.3010339736938477
Batch 20/64 loss: -2.2004013061523438
Batch 21/64 loss: -2.406625747680664
Batch 22/64 loss: -1.6756515502929688
Batch 23/64 loss: -2.3502020835876465
Batch 24/64 loss: -2.2516746520996094
Batch 25/64 loss: -2.2235946655273438
Batch 26/64 loss: -1.9413270950317383
Batch 27/64 loss: -2.36110782623291
Batch 28/64 loss: -2.421015739440918
Batch 29/64 loss: -1.8221960067749023
Batch 30/64 loss: -2.3109583854675293
Batch 31/64 loss: -2.188486099243164
Batch 32/64 loss: -2.0593490600585938
Batch 33/64 loss: -2.2667112350463867
Batch 34/64 loss: -2.3603501319885254
Batch 35/64 loss: -2.0783987045288086
Batch 36/64 loss: -2.0793657302856445
Batch 37/64 loss: -2.3927693367004395
Batch 38/64 loss: -2.289653778076172
Batch 39/64 loss: -2.0049924850463867
Batch 40/64 loss: -2.2964353561401367
Batch 41/64 loss: -2.0586938858032227
Batch 42/64 loss: -2.2949981689453125
Batch 43/64 loss: -2.1456527709960938
Batch 44/64 loss: -2.4665145874023438
Batch 45/64 loss: -1.9206790924072266
Batch 46/64 loss: -2.360116958618164
Batch 47/64 loss: -2.3505306243896484
Batch 48/64 loss: -2.1726388931274414
Batch 49/64 loss: -2.3805041313171387
Batch 50/64 loss: -2.1841344833374023
Batch 51/64 loss: -2.3315181732177734
Batch 52/64 loss: -2.022885322570801
Batch 53/64 loss: -2.3585081100463867
Batch 54/64 loss: -1.969569206237793
Batch 55/64 loss: -2.067172050476074
Batch 56/64 loss: -2.371697425842285
Batch 57/64 loss: -2.340790271759033
Batch 58/64 loss: -2.2515268325805664
Batch 59/64 loss: -2.132664680480957
Batch 60/64 loss: -2.237384796142578
Batch 61/64 loss: -2.2540740966796875
Batch 62/64 loss: -2.0373668670654297
Batch 63/64 loss: -2.4011545181274414
Batch 64/64 loss: -6.320199012756348
Epoch 349  Train loss: -2.2271351271984625  Val loss: -2.622598838150706
Epoch 350
-------------------------------
Batch 1/64 loss: -1.8077983856201172
Batch 2/64 loss: -2.103644371032715
Batch 3/64 loss: -2.3597617149353027
Batch 4/64 loss: -2.2432823181152344
Batch 5/64 loss: -2.2613086700439453
Batch 6/64 loss: -2.3365845680236816
Batch 7/64 loss: -2.2764978408813477
Batch 8/64 loss: -2.2977418899536133
Batch 9/64 loss: -2.335299491882324
Batch 10/64 loss: -2.2110233306884766
Batch 11/64 loss: -2.1572084426879883
Batch 12/64 loss: -1.929183006286621
Batch 13/64 loss: -2.370530128479004
Batch 14/64 loss: -2.3600006103515625
Batch 15/64 loss: -2.1758222579956055
Batch 16/64 loss: -2.437922477722168
Batch 17/64 loss: -2.414583206176758
Batch 18/64 loss: -2.161670684814453
Batch 19/64 loss: -2.1784210205078125
Batch 20/64 loss: -2.062227249145508
Batch 21/64 loss: -2.180020332336426
Batch 22/64 loss: -2.3762598037719727
Batch 23/64 loss: -1.5781145095825195
Batch 24/64 loss: -2.3158206939697266
Batch 25/64 loss: -1.679952621459961
Batch 26/64 loss: -2.3376917839050293
Batch 27/64 loss: -2.1420249938964844
Batch 28/64 loss: -2.2476587295532227
Batch 29/64 loss: -2.3593688011169434
Batch 30/64 loss: -2.4289722442626953
Batch 31/64 loss: -2.449514389038086
Batch 32/64 loss: -1.9880590438842773
Batch 33/64 loss: -2.323516845703125
Batch 34/64 loss: -2.3427324295043945
Batch 35/64 loss: -2.0539445877075195
Batch 36/64 loss: -2.3571696281433105
Batch 37/64 loss: -2.403189182281494
Batch 38/64 loss: -2.304086685180664
Batch 39/64 loss: -2.180479049682617
Batch 40/64 loss: -2.3223910331726074
Batch 41/64 loss: -2.1725893020629883
Batch 42/64 loss: -2.1170578002929688
Batch 43/64 loss: -2.206906318664551
Batch 44/64 loss: -2.3588428497314453
Batch 45/64 loss: -2.300306797027588
Batch 46/64 loss: -2.3496012687683105
Batch 47/64 loss: -2.1881895065307617
Batch 48/64 loss: -2.1797990798950195
Batch 49/64 loss: -1.9309148788452148
Batch 50/64 loss: -2.1029186248779297
Batch 51/64 loss: -2.3459010124206543
Batch 52/64 loss: -1.8628158569335938
Batch 53/64 loss: -2.1934127807617188
Batch 54/64 loss: -2.1056747436523438
Batch 55/64 loss: -2.1407718658447266
Batch 56/64 loss: -2.272963523864746
Batch 57/64 loss: -2.4146156311035156
Batch 58/64 loss: -1.4143199920654297
Batch 59/64 loss: -2.327542304992676
Batch 60/64 loss: -2.223233222961426
Batch 61/64 loss: -2.299015998840332
Batch 62/64 loss: -2.353327751159668
Batch 63/64 loss: -1.783574104309082
Batch 64/64 loss: -6.6016130447387695
Epoch 350  Train loss: -2.25014876945346  Val loss: -2.5147613971094085
Epoch 351
-------------------------------
Batch 1/64 loss: -2.127317428588867
Batch 2/64 loss: -2.2067031860351562
Batch 3/64 loss: -2.321807861328125
Batch 4/64 loss: -2.2361326217651367
Batch 5/64 loss: -2.2849693298339844
Batch 6/64 loss: -2.106776237487793
Batch 7/64 loss: -1.9649658203125
Batch 8/64 loss: -1.9220085144042969
Batch 9/64 loss: -2.2347278594970703
Batch 10/64 loss: -2.1923818588256836
Batch 11/64 loss: -1.1013498306274414
Batch 12/64 loss: -2.266630172729492
Batch 13/64 loss: -1.976973533630371
Batch 14/64 loss: -2.3181257247924805
Batch 15/64 loss: -2.259413719177246
Batch 16/64 loss: -2.158106803894043
Batch 17/64 loss: -2.263731002807617
Batch 18/64 loss: -2.00698184967041
Batch 19/64 loss: -2.2671070098876953
Batch 20/64 loss: -2.043516159057617
Batch 21/64 loss: -2.266421318054199
Batch 22/64 loss: -2.1623191833496094
Batch 23/64 loss: -2.1504039764404297
Batch 24/64 loss: -2.305386543273926
Batch 25/64 loss: -2.0684661865234375
Batch 26/64 loss: -2.062196731567383
Batch 27/64 loss: -1.6303997039794922
Batch 28/64 loss: -1.8092031478881836
Batch 29/64 loss: -2.28555965423584
Batch 30/64 loss: -1.9544000625610352
Batch 31/64 loss: -2.2115917205810547
Batch 32/64 loss: -2.2522964477539062
Batch 33/64 loss: -2.366650104522705
Batch 34/64 loss: -2.4190454483032227
Batch 35/64 loss: -2.242243766784668
Batch 36/64 loss: -2.250905990600586
Batch 37/64 loss: -2.132004737854004
Batch 38/64 loss: -2.2345495223999023
Batch 39/64 loss: -2.370133876800537
Batch 40/64 loss: -1.91180419921875
Batch 41/64 loss: -1.6639890670776367
Batch 42/64 loss: -2.1916818618774414
Batch 43/64 loss: -2.25162410736084
Batch 44/64 loss: -2.222503662109375
Batch 45/64 loss: -2.145321846008301
Batch 46/64 loss: -2.0951919555664062
Batch 47/64 loss: -1.5974340438842773
Batch 48/64 loss: -2.3661394119262695
Batch 49/64 loss: -1.9293222427368164
Batch 50/64 loss: -2.035921096801758
Batch 51/64 loss: -1.864619255065918
Batch 52/64 loss: -2.1832199096679688
Batch 53/64 loss: -2.1661577224731445
Batch 54/64 loss: -1.9624948501586914
Batch 55/64 loss: -2.212726593017578
Batch 56/64 loss: -2.271648406982422
Batch 57/64 loss: -2.303025245666504
Batch 58/64 loss: -1.7997865676879883
Batch 59/64 loss: -2.057332992553711
Batch 60/64 loss: -1.8550338745117188
Batch 61/64 loss: -2.2184057235717773
Batch 62/64 loss: -1.3014497756958008
Batch 63/64 loss: -2.2775049209594727
Batch 64/64 loss: -6.04954719543457
Epoch 351  Train loss: -2.1467514412075865  Val loss: -2.357437710581776
Epoch 352
-------------------------------
Batch 1/64 loss: -2.119717597961426
Batch 2/64 loss: -2.1984434127807617
Batch 3/64 loss: -1.925649642944336
Batch 4/64 loss: -2.242091178894043
Batch 5/64 loss: -2.2899961471557617
Batch 6/64 loss: -2.3427200317382812
Batch 7/64 loss: -1.9892244338989258
Batch 8/64 loss: -1.512639045715332
Batch 9/64 loss: -2.0076494216918945
Batch 10/64 loss: -2.0902795791625977
Batch 11/64 loss: -2.171412467956543
Batch 12/64 loss: -2.1311941146850586
Batch 13/64 loss: -2.273970603942871
Batch 14/64 loss: -2.0777416229248047
Batch 15/64 loss: -2.220956802368164
Batch 16/64 loss: -2.1995391845703125
Batch 17/64 loss: -2.0611705780029297
Batch 18/64 loss: -2.074869155883789
Batch 19/64 loss: -2.0490427017211914
Batch 20/64 loss: -2.2176809310913086
Batch 21/64 loss: -2.1903905868530273
Batch 22/64 loss: -2.4059510231018066
Batch 23/64 loss: -2.3457794189453125
Batch 24/64 loss: -2.140467643737793
Batch 25/64 loss: -2.3803844451904297
Batch 26/64 loss: -1.7049055099487305
Batch 27/64 loss: -2.0556716918945312
Batch 28/64 loss: -2.3840436935424805
Batch 29/64 loss: -1.6817598342895508
Batch 30/64 loss: -2.1845970153808594
Batch 31/64 loss: -1.9971771240234375
Batch 32/64 loss: -2.2861156463623047
Batch 33/64 loss: -2.1403369903564453
Batch 34/64 loss: -2.185643196105957
Batch 35/64 loss: -2.199230194091797
Batch 36/64 loss: -2.0353755950927734
Batch 37/64 loss: -1.3755807876586914
Batch 38/64 loss: -1.81512451171875
Batch 39/64 loss: -2.0474166870117188
Batch 40/64 loss: -2.256711006164551
Batch 41/64 loss: -1.8026304244995117
Batch 42/64 loss: -1.9095439910888672
Batch 43/64 loss: -2.2469663619995117
Batch 44/64 loss: -2.231265068054199
Batch 45/64 loss: -2.0488100051879883
Batch 46/64 loss: -2.228839874267578
Batch 47/64 loss: -2.080934524536133
Batch 48/64 loss: -2.392429828643799
Batch 49/64 loss: -1.9026670455932617
Batch 50/64 loss: -2.1432390213012695
Batch 51/64 loss: -2.3227505683898926
Batch 52/64 loss: -1.851607322692871
Batch 53/64 loss: -2.1710548400878906
Batch 54/64 loss: -2.0080795288085938
Batch 55/64 loss: -2.13051700592041
Batch 56/64 loss: -1.9959754943847656
Batch 57/64 loss: -1.966475486755371
Batch 58/64 loss: -1.0619220733642578
Batch 59/64 loss: -2.045114517211914
Batch 60/64 loss: -2.0445632934570312
Batch 61/64 loss: -2.1213512420654297
Batch 62/64 loss: -2.048919677734375
Batch 63/64 loss: -2.0929346084594727
Batch 64/64 loss: -6.444731712341309
Epoch 352  Train loss: -2.128483009338379  Val loss: -2.44834868440923
Epoch 353
-------------------------------
Batch 1/64 loss: -1.9450960159301758
Batch 2/64 loss: -2.2928781509399414
Batch 3/64 loss: -1.3588037490844727
Batch 4/64 loss: -2.3022727966308594
Batch 5/64 loss: -2.222148895263672
Batch 6/64 loss: -1.9839859008789062
Batch 7/64 loss: -2.2984228134155273
Batch 8/64 loss: -2.215325355529785
Batch 9/64 loss: -2.254847526550293
Batch 10/64 loss: -1.995589256286621
Batch 11/64 loss: -2.2446250915527344
Batch 12/64 loss: -2.089092254638672
Batch 13/64 loss: -2.27420711517334
Batch 14/64 loss: -1.6934032440185547
Batch 15/64 loss: -2.381998062133789
Batch 16/64 loss: -2.025655746459961
Batch 17/64 loss: -2.198634147644043
Batch 18/64 loss: -2.02651309967041
Batch 19/64 loss: -1.782670021057129
Batch 20/64 loss: -1.6673736572265625
Batch 21/64 loss: -1.8056697845458984
Batch 22/64 loss: -2.1264896392822266
Batch 23/64 loss: -2.018899917602539
Batch 24/64 loss: -1.791849136352539
Batch 25/64 loss: -1.4117164611816406
Batch 26/64 loss: -2.288595199584961
Batch 27/64 loss: -1.7748775482177734
Batch 28/64 loss: -2.0291099548339844
Batch 29/64 loss: -2.023013114929199
Batch 30/64 loss: -2.0439624786376953
Batch 31/64 loss: -1.9740686416625977
Batch 32/64 loss: -2.079730987548828
Batch 33/64 loss: -2.189767837524414
Batch 34/64 loss: -2.0255908966064453
Batch 35/64 loss: -1.0684003829956055
Batch 36/64 loss: -2.1516504287719727
Batch 37/64 loss: -2.006471633911133
Batch 38/64 loss: -1.8473224639892578
Batch 39/64 loss: -2.1317005157470703
Batch 40/64 loss: -2.1880102157592773
Batch 41/64 loss: -1.9502992630004883
Batch 42/64 loss: -1.8430166244506836
Batch 43/64 loss: -2.1389026641845703
Batch 44/64 loss: -2.1428565979003906
Batch 45/64 loss: -2.033599853515625
Batch 46/64 loss: -2.2796249389648438
Batch 47/64 loss: -1.8083581924438477
Batch 48/64 loss: -2.1384239196777344
Batch 49/64 loss: -2.018829345703125
Batch 50/64 loss: -2.0208873748779297
Batch 51/64 loss: -2.201519012451172
Batch 52/64 loss: -2.0779991149902344
Batch 53/64 loss: -2.0591211318969727
Batch 54/64 loss: -2.144211769104004
Batch 55/64 loss: -2.0787315368652344
Batch 56/64 loss: -1.996908187866211
Batch 57/64 loss: -2.245309829711914
Batch 58/64 loss: -1.858851432800293
Batch 59/64 loss: -1.8791265487670898
Batch 60/64 loss: -2.240255355834961
Batch 61/64 loss: -2.1895132064819336
Batch 62/64 loss: -2.1277360916137695
Batch 63/64 loss: -1.9274406433105469
Batch 64/64 loss: -6.4301042556762695
Epoch 353  Train loss: -2.0777182896931965  Val loss: -2.355424048564688
Epoch 354
-------------------------------
Batch 1/64 loss: -1.5544414520263672
Batch 2/64 loss: -2.202633857727051
Batch 3/64 loss: -1.8614587783813477
Batch 4/64 loss: -2.0578536987304688
Batch 5/64 loss: -2.1499099731445312
Batch 6/64 loss: -1.9828786849975586
Batch 7/64 loss: -2.217991828918457
Batch 8/64 loss: -1.2641716003417969
Batch 9/64 loss: -2.023068428039551
Batch 10/64 loss: -1.9036331176757812
Batch 11/64 loss: -2.11885929107666
Batch 12/64 loss: -1.9598264694213867
Batch 13/64 loss: -2.0025405883789062
Batch 14/64 loss: -2.0315122604370117
Batch 15/64 loss: -1.7140817642211914
Batch 16/64 loss: -2.092561721801758
Batch 17/64 loss: -2.123936653137207
Batch 18/64 loss: -2.126946449279785
Batch 19/64 loss: -1.9758415222167969
Batch 20/64 loss: -2.0694704055786133
Batch 21/64 loss: -2.10373592376709
Batch 22/64 loss: -2.0185060501098633
Batch 23/64 loss: -2.2119579315185547
Batch 24/64 loss: -1.9089775085449219
Batch 25/64 loss: -2.16768741607666
Batch 26/64 loss: -2.052474021911621
Batch 27/64 loss: -2.107257843017578
Batch 28/64 loss: -2.2505035400390625
Batch 29/64 loss: -1.7070016860961914
Batch 30/64 loss: -1.8019819259643555
Batch 31/64 loss: -1.9609613418579102
Batch 32/64 loss: -2.077609062194824
Batch 33/64 loss: -1.8207788467407227
Batch 34/64 loss: -2.294623374938965
Batch 35/64 loss: -2.224165916442871
Batch 36/64 loss: -2.0580949783325195
Batch 37/64 loss: -2.0812034606933594
Batch 38/64 loss: -2.194472312927246
Batch 39/64 loss: -2.078925132751465
Batch 40/64 loss: -2.2705631256103516
Batch 41/64 loss: -2.071444511413574
Batch 42/64 loss: -2.1704816818237305
Batch 43/64 loss: -2.207925796508789
Batch 44/64 loss: -2.226426124572754
Batch 45/64 loss: -1.9323663711547852
Batch 46/64 loss: -2.2121963500976562
Batch 47/64 loss: -1.5640535354614258
Batch 48/64 loss: -2.1801748275756836
Batch 49/64 loss: -2.3256454467773438
Batch 50/64 loss: -2.2178030014038086
Batch 51/64 loss: -1.665614128112793
Batch 52/64 loss: -2.1967124938964844
Batch 53/64 loss: -1.8891000747680664
Batch 54/64 loss: -2.1366405487060547
Batch 55/64 loss: -2.2827887535095215
Batch 56/64 loss: -2.346506118774414
Batch 57/64 loss: -2.208601951599121
Batch 58/64 loss: -2.3985447883605957
Batch 59/64 loss: -2.1936330795288086
Batch 60/64 loss: -2.23105525970459
Batch 61/64 loss: -2.3020858764648438
Batch 62/64 loss: -2.259453773498535
Batch 63/64 loss: -2.044668197631836
Batch 64/64 loss: -6.326216697692871
Epoch 354  Train loss: -2.1150381985832665  Val loss: -2.4529544135549224
Epoch 355
-------------------------------
Batch 1/64 loss: -2.151545524597168
Batch 2/64 loss: -2.3119964599609375
Batch 3/64 loss: -2.1276559829711914
Batch 4/64 loss: -2.3199663162231445
Batch 5/64 loss: -2.2805404663085938
Batch 6/64 loss: -2.2168378829956055
Batch 7/64 loss: -2.2078704833984375
Batch 8/64 loss: -2.187930107116699
Batch 9/64 loss: -2.1282243728637695
Batch 10/64 loss: -2.349559783935547
Batch 11/64 loss: -2.1264781951904297
Batch 12/64 loss: -2.305304527282715
Batch 13/64 loss: -2.214536666870117
Batch 14/64 loss: -1.6089563369750977
Batch 15/64 loss: -2.2636632919311523
Batch 16/64 loss: -2.318819999694824
Batch 17/64 loss: -1.9181785583496094
Batch 18/64 loss: -1.9983978271484375
Batch 19/64 loss: -2.1399993896484375
Batch 20/64 loss: -2.349640369415283
Batch 21/64 loss: -1.5867958068847656
Batch 22/64 loss: -1.708022117614746
Batch 23/64 loss: -2.090886116027832
Batch 24/64 loss: -2.3155269622802734
Batch 25/64 loss: -2.180665969848633
Batch 26/64 loss: -2.261075973510742
Batch 27/64 loss: -2.117704391479492
Batch 28/64 loss: -2.401392936706543
Batch 29/64 loss: -1.4901514053344727
Batch 30/64 loss: -2.1041202545166016
Batch 31/64 loss: -2.322307586669922
Batch 32/64 loss: -2.0150375366210938
Batch 33/64 loss: -2.237384796142578
Batch 34/64 loss: -2.169260025024414
Batch 35/64 loss: -2.116863250732422
Batch 36/64 loss: -2.0973806381225586
Batch 37/64 loss: -2.335543632507324
Batch 38/64 loss: -2.216114044189453
Batch 39/64 loss: -2.1119823455810547
Batch 40/64 loss: -2.140395164489746
Batch 41/64 loss: -2.307967185974121
Batch 42/64 loss: -2.0704345703125
Batch 43/64 loss: -2.3296566009521484
Batch 44/64 loss: -2.0191287994384766
Batch 45/64 loss: -2.360372543334961
Batch 46/64 loss: -2.047252655029297
Batch 47/64 loss: -2.1525306701660156
Batch 48/64 loss: -1.7953987121582031
Batch 49/64 loss: -2.1837501525878906
Batch 50/64 loss: -2.237201690673828
Batch 51/64 loss: -2.271615982055664
Batch 52/64 loss: -2.0872182846069336
Batch 53/64 loss: -1.951289176940918
Batch 54/64 loss: -1.751551628112793
Batch 55/64 loss: -2.0539331436157227
Batch 56/64 loss: -2.1668357849121094
Batch 57/64 loss: -1.9866180419921875
Batch 58/64 loss: -1.9837398529052734
Batch 59/64 loss: -2.1831188201904297
Batch 60/64 loss: -2.15634822845459
Batch 61/64 loss: -2.0067739486694336
Batch 62/64 loss: -2.15328311920166
Batch 63/64 loss: -2.1606245040893555
Batch 64/64 loss: -6.09848690032959
Epoch 355  Train loss: -2.1731015336279778  Val loss: -2.4174646724949995
Epoch 356
-------------------------------
Batch 1/64 loss: -1.5304059982299805
Batch 2/64 loss: -2.1422061920166016
Batch 3/64 loss: -2.2972259521484375
Batch 4/64 loss: -2.0325794219970703
Batch 5/64 loss: -2.285101890563965
Batch 6/64 loss: -2.0938539505004883
Batch 7/64 loss: -2.136368751525879
Batch 8/64 loss: -2.235330581665039
Batch 9/64 loss: -2.140880584716797
Batch 10/64 loss: -2.239511489868164
Batch 11/64 loss: -2.029911994934082
Batch 12/64 loss: -1.8163700103759766
Batch 13/64 loss: -2.2242307662963867
Batch 14/64 loss: -2.3338422775268555
Batch 15/64 loss: -1.852095603942871
Batch 16/64 loss: -1.9975919723510742
Batch 17/64 loss: -2.183840751647949
Batch 18/64 loss: -2.1223573684692383
Batch 19/64 loss: -2.0758018493652344
Batch 20/64 loss: -2.416828155517578
Batch 21/64 loss: -2.386589527130127
Batch 22/64 loss: -2.0943660736083984
Batch 23/64 loss: -2.0699071884155273
Batch 24/64 loss: -2.231142997741699
Batch 25/64 loss: -2.2634048461914062
Batch 26/64 loss: -2.373537063598633
Batch 27/64 loss: -2.214890480041504
Batch 28/64 loss: -2.3949460983276367
Batch 29/64 loss: -1.9332761764526367
Batch 30/64 loss: -2.2028932571411133
Batch 31/64 loss: -2.071587562561035
Batch 32/64 loss: -1.5459918975830078
Batch 33/64 loss: -1.9735240936279297
Batch 34/64 loss: -2.15533447265625
Batch 35/64 loss: -1.262746810913086
Batch 36/64 loss: -2.3280768394470215
Batch 37/64 loss: -2.234312057495117
Batch 38/64 loss: -2.27933406829834
Batch 39/64 loss: -2.105954170227051
Batch 40/64 loss: -2.09039306640625
Batch 41/64 loss: -2.2148666381835938
Batch 42/64 loss: -2.208831787109375
Batch 43/64 loss: -2.4239959716796875
Batch 44/64 loss: -2.336136817932129
Batch 45/64 loss: -2.348921775817871
Batch 46/64 loss: -1.9806489944458008
Batch 47/64 loss: -2.099663734436035
Batch 48/64 loss: -2.3752384185791016
Batch 49/64 loss: -2.301900863647461
Batch 50/64 loss: -2.438142776489258
Batch 51/64 loss: -2.2337684631347656
Batch 52/64 loss: -2.3037109375
Batch 53/64 loss: -1.937087059020996
Batch 54/64 loss: -1.4302387237548828
Batch 55/64 loss: -2.1713714599609375
Batch 56/64 loss: -2.343827247619629
Batch 57/64 loss: -2.2626161575317383
Batch 58/64 loss: -2.291738510131836
Batch 59/64 loss: -2.253389358520508
Batch 60/64 loss: -2.031439781188965
Batch 61/64 loss: -2.205608367919922
Batch 62/64 loss: -2.030245780944824
Batch 63/64 loss: -2.162989616394043
Batch 64/64 loss: -5.878381729125977
Epoch 356  Train loss: -2.183430742749981  Val loss: -2.436603952519263
Epoch 357
-------------------------------
Batch 1/64 loss: -1.4742307662963867
Batch 2/64 loss: -1.7009468078613281
Batch 3/64 loss: -1.8666877746582031
Batch 4/64 loss: -2.215982437133789
Batch 5/64 loss: -2.183852195739746
Batch 6/64 loss: -2.229313850402832
Batch 7/64 loss: -2.050252914428711
Batch 8/64 loss: -1.8477230072021484
Batch 9/64 loss: -2.1388444900512695
Batch 10/64 loss: -2.2434730529785156
Batch 11/64 loss: -2.04776668548584
Batch 12/64 loss: -2.2664566040039062
Batch 13/64 loss: -2.1684398651123047
Batch 14/64 loss: -2.213625907897949
Batch 15/64 loss: -2.031435966491699
Batch 16/64 loss: -2.1130847930908203
Batch 17/64 loss: -2.3038864135742188
Batch 18/64 loss: -1.8885955810546875
Batch 19/64 loss: -2.4003500938415527
Batch 20/64 loss: -2.275162696838379
Batch 21/64 loss: -2.2373342514038086
Batch 22/64 loss: -2.1327648162841797
Batch 23/64 loss: -1.517653465270996
Batch 24/64 loss: -2.051985740661621
Batch 25/64 loss: -2.3112239837646484
Batch 26/64 loss: -1.8678274154663086
Batch 27/64 loss: -2.374124526977539
Batch 28/64 loss: -2.3108482360839844
Batch 29/64 loss: -2.262399673461914
Batch 30/64 loss: -2.39070987701416
Batch 31/64 loss: -1.8927936553955078
Batch 32/64 loss: -2.1584415435791016
Batch 33/64 loss: -2.2311182022094727
Batch 34/64 loss: -1.3514070510864258
Batch 35/64 loss: -2.0857391357421875
Batch 36/64 loss: -2.299670696258545
Batch 37/64 loss: -2.2163562774658203
Batch 38/64 loss: -2.285737991333008
Batch 39/64 loss: -1.6733312606811523
Batch 40/64 loss: -2.1120376586914062
Batch 41/64 loss: -2.2806873321533203
Batch 42/64 loss: -2.2981643676757812
Batch 43/64 loss: -2.341313362121582
Batch 44/64 loss: -2.151909828186035
Batch 45/64 loss: -2.142045021057129
Batch 46/64 loss: -2.310317039489746
Batch 47/64 loss: -2.056851387023926
Batch 48/64 loss: -1.9143095016479492
Batch 49/64 loss: -2.012460708618164
Batch 50/64 loss: -2.1015005111694336
Batch 51/64 loss: -2.0134105682373047
Batch 52/64 loss: -2.2996902465820312
Batch 53/64 loss: -2.0858402252197266
Batch 54/64 loss: -2.193845748901367
Batch 55/64 loss: -2.3529515266418457
Batch 56/64 loss: -2.1960830688476562
Batch 57/64 loss: -2.077713966369629
Batch 58/64 loss: -2.192782402038574
Batch 59/64 loss: -2.008390426635742
Batch 60/64 loss: -2.242307662963867
Batch 61/64 loss: -1.9567451477050781
Batch 62/64 loss: -2.2108192443847656
Batch 63/64 loss: -2.206679344177246
Batch 64/64 loss: -6.529416084289551
Epoch 357  Train loss: -2.1641960480633906  Val loss: -2.461825157768538
Epoch 358
-------------------------------
Batch 1/64 loss: -2.2744522094726562
Batch 2/64 loss: -2.2206039428710938
Batch 3/64 loss: -2.1050119400024414
Batch 4/64 loss: -2.2481603622436523
Batch 5/64 loss: -2.329000949859619
Batch 6/64 loss: -2.046632766723633
Batch 7/64 loss: -2.3450002670288086
Batch 8/64 loss: -1.9924860000610352
Batch 9/64 loss: -2.2388954162597656
Batch 10/64 loss: -2.2172317504882812
Batch 11/64 loss: -2.2573041915893555
Batch 12/64 loss: -1.3481569290161133
Batch 13/64 loss: -2.4313302040100098
Batch 14/64 loss: -2.2997450828552246
Batch 15/64 loss: -2.1731958389282227
Batch 16/64 loss: -2.026675224304199
Batch 17/64 loss: -2.0450334548950195
Batch 18/64 loss: -2.176690101623535
Batch 19/64 loss: -1.7952938079833984
Batch 20/64 loss: -2.1329050064086914
Batch 21/64 loss: -1.819143295288086
Batch 22/64 loss: -1.8726778030395508
Batch 23/64 loss: -2.3552207946777344
Batch 24/64 loss: -2.2227916717529297
Batch 25/64 loss: -2.0859909057617188
Batch 26/64 loss: -2.0758819580078125
Batch 27/64 loss: -2.1551733016967773
Batch 28/64 loss: -2.4514036178588867
Batch 29/64 loss: -1.9901714324951172
Batch 30/64 loss: -2.4338440895080566
Batch 31/64 loss: -2.2331390380859375
Batch 32/64 loss: -2.005002975463867
Batch 33/64 loss: -2.2805209159851074
Batch 34/64 loss: -2.356013298034668
Batch 35/64 loss: -2.3310980796813965
Batch 36/64 loss: -1.7549018859863281
Batch 37/64 loss: -2.403646945953369
Batch 38/64 loss: -2.011991500854492
Batch 39/64 loss: -2.2997360229492188
Batch 40/64 loss: -2.105010986328125
Batch 41/64 loss: -1.7697372436523438
Batch 42/64 loss: -2.307720184326172
Batch 43/64 loss: -1.6821060180664062
Batch 44/64 loss: -2.3293161392211914
Batch 45/64 loss: -2.082709312438965
Batch 46/64 loss: -2.2088871002197266
Batch 47/64 loss: -2.10781192779541
Batch 48/64 loss: -2.2423267364501953
Batch 49/64 loss: -2.2471303939819336
Batch 50/64 loss: -2.0148849487304688
Batch 51/64 loss: -2.3465828895568848
Batch 52/64 loss: -2.1767988204956055
Batch 53/64 loss: -1.826498031616211
Batch 54/64 loss: -2.061063766479492
Batch 55/64 loss: -2.1431093215942383
Batch 56/64 loss: -2.0824413299560547
Batch 57/64 loss: -2.2736988067626953
Batch 58/64 loss: -1.5395584106445312
Batch 59/64 loss: -1.9134864807128906
Batch 60/64 loss: -2.295623779296875
Batch 61/64 loss: -2.064542770385742
Batch 62/64 loss: -2.188868522644043
Batch 63/64 loss: -2.227691650390625
Batch 64/64 loss: -6.44962215423584
Epoch 358  Train loss: -2.179089837915757  Val loss: -2.4970271841357254
Epoch 359
-------------------------------
Batch 1/64 loss: -2.0634078979492188
Batch 2/64 loss: -1.2699642181396484
Batch 3/64 loss: -2.3094592094421387
Batch 4/64 loss: -2.064793586730957
Batch 5/64 loss: -1.946772575378418
Batch 6/64 loss: -2.139592170715332
Batch 7/64 loss: -2.2385168075561523
Batch 8/64 loss: -2.0654296875
Batch 9/64 loss: -2.134532928466797
Batch 10/64 loss: -2.0296506881713867
Batch 11/64 loss: -1.6288747787475586
Batch 12/64 loss: -2.322355270385742
Batch 13/64 loss: -1.8653717041015625
Batch 14/64 loss: -1.8774566650390625
Batch 15/64 loss: -1.3943824768066406
Batch 16/64 loss: -2.0865440368652344
Batch 17/64 loss: -1.9780635833740234
Batch 18/64 loss: -1.6669607162475586
Batch 19/64 loss: -2.0647945404052734
Batch 20/64 loss: -2.355348587036133
Batch 21/64 loss: -2.2358779907226562
Batch 22/64 loss: -2.458343029022217
Batch 23/64 loss: -2.018527030944824
Batch 24/64 loss: -2.2076053619384766
Batch 25/64 loss: -2.0482749938964844
Batch 26/64 loss: -2.1778125762939453
Batch 27/64 loss: -2.1769399642944336
Batch 28/64 loss: -2.113872528076172
Batch 29/64 loss: -2.1006927490234375
Batch 30/64 loss: -2.1806020736694336
Batch 31/64 loss: -2.3810038566589355
Batch 32/64 loss: -2.0901451110839844
Batch 33/64 loss: -2.039966583251953
Batch 34/64 loss: -2.2739830017089844
Batch 35/64 loss: -2.303736686706543
Batch 36/64 loss: -2.268927574157715
Batch 37/64 loss: -2.378957748413086
Batch 38/64 loss: -2.2227535247802734
Batch 39/64 loss: -1.968806266784668
Batch 40/64 loss: -2.2945446968078613
Batch 41/64 loss: -2.0979843139648438
Batch 42/64 loss: -2.10781192779541
Batch 43/64 loss: -2.381916046142578
Batch 44/64 loss: -2.053689956665039
Batch 45/64 loss: -2.272573471069336
Batch 46/64 loss: -2.0174999237060547
Batch 47/64 loss: -2.111225128173828
Batch 48/64 loss: -2.2280893325805664
Batch 49/64 loss: -2.2064437866210938
Batch 50/64 loss: -2.2295541763305664
Batch 51/64 loss: -2.4054012298583984
Batch 52/64 loss: -2.1043310165405273
Batch 53/64 loss: -2.38716983795166
Batch 54/64 loss: -2.1713171005249023
Batch 55/64 loss: -1.9003572463989258
Batch 56/64 loss: -2.2852258682250977
Batch 57/64 loss: -2.3191871643066406
Batch 58/64 loss: -2.335538387298584
Batch 59/64 loss: -2.2911453247070312
Batch 60/64 loss: -2.006784439086914
Batch 61/64 loss: -2.3916268348693848
Batch 62/64 loss: -2.3383326530456543
Batch 63/64 loss: -2.3556013107299805
Batch 64/64 loss: -6.673608779907227
Epoch 359  Train loss: -2.1874142515893076  Val loss: -2.5537785533367563
Epoch 360
-------------------------------
Batch 1/64 loss: -2.230955123901367
Batch 2/64 loss: -2.3438682556152344
Batch 3/64 loss: -1.6410999298095703
Batch 4/64 loss: -2.2361936569213867
Batch 5/64 loss: -2.3991479873657227
Batch 6/64 loss: -1.9465970993041992
Batch 7/64 loss: -2.2712392807006836
Batch 8/64 loss: -2.0259933471679688
Batch 9/64 loss: -2.3203506469726562
Batch 10/64 loss: -2.1579055786132812
Batch 11/64 loss: -2.1954355239868164
Batch 12/64 loss: -2.29293155670166
Batch 13/64 loss: -2.1874351501464844
Batch 14/64 loss: -2.2624549865722656
Batch 15/64 loss: -2.3135080337524414
Batch 16/64 loss: -1.990849494934082
Batch 17/64 loss: -2.285053253173828
Batch 18/64 loss: -2.2708005905151367
Batch 19/64 loss: -2.296872138977051
Batch 20/64 loss: -2.2336959838867188
Batch 21/64 loss: -2.2743120193481445
Batch 22/64 loss: -2.3534116744995117
Batch 23/64 loss: -2.265925407409668
Batch 24/64 loss: -1.7083635330200195
Batch 25/64 loss: -1.8594131469726562
Batch 26/64 loss: -2.2936363220214844
Batch 27/64 loss: -1.7904863357543945
Batch 28/64 loss: -2.4141454696655273
Batch 29/64 loss: -2.4108853340148926
Batch 30/64 loss: -1.9660148620605469
Batch 31/64 loss: -2.1764612197875977
Batch 32/64 loss: -2.2645368576049805
Batch 33/64 loss: -2.379133701324463
Batch 34/64 loss: -2.397554397583008
Batch 35/64 loss: -2.3487377166748047
Batch 36/64 loss: -2.3510360717773438
Batch 37/64 loss: -2.168264389038086
Batch 38/64 loss: -2.3069629669189453
Batch 39/64 loss: -1.9818153381347656
Batch 40/64 loss: -2.257465362548828
Batch 41/64 loss: -2.11466121673584
Batch 42/64 loss: -2.1708602905273438
Batch 43/64 loss: -2.2366275787353516
Batch 44/64 loss: -2.2817087173461914
Batch 45/64 loss: -2.0306968688964844
Batch 46/64 loss: -2.120772361755371
Batch 47/64 loss: -2.1126766204833984
Batch 48/64 loss: -2.1997528076171875
Batch 49/64 loss: -1.4840831756591797
Batch 50/64 loss: -2.401041030883789
Batch 51/64 loss: -2.1010055541992188
Batch 52/64 loss: -1.7562541961669922
Batch 53/64 loss: -2.4382176399230957
Batch 54/64 loss: -2.2683372497558594
Batch 55/64 loss: -2.2208499908447266
Batch 56/64 loss: -1.5758962631225586
Batch 57/64 loss: -1.9675607681274414
Batch 58/64 loss: -2.016611099243164
Batch 59/64 loss: -1.6295270919799805
Batch 60/64 loss: -2.214954376220703
Batch 61/64 loss: -2.3627896308898926
Batch 62/64 loss: -2.1239423751831055
Batch 63/64 loss: -2.2489566802978516
Batch 64/64 loss: -6.44296932220459
Epoch 360  Train loss: -2.208328789355708  Val loss: -2.507720855503148
Epoch 361
-------------------------------
Batch 1/64 loss: -2.2208251953125
Batch 2/64 loss: -2.3280677795410156
Batch 3/64 loss: -2.3221683502197266
Batch 4/64 loss: -1.8634834289550781
Batch 5/64 loss: -2.240205764770508
Batch 6/64 loss: -2.2510976791381836
Batch 7/64 loss: -2.2582883834838867
Batch 8/64 loss: -2.1704349517822266
Batch 9/64 loss: -2.0949411392211914
Batch 10/64 loss: -2.007518768310547
Batch 11/64 loss: -2.0808334350585938
Batch 12/64 loss: -2.3758363723754883
Batch 13/64 loss: -2.409359931945801
Batch 14/64 loss: -2.29207706451416
Batch 15/64 loss: -2.325247287750244
Batch 16/64 loss: -1.8497467041015625
Batch 17/64 loss: -2.217677116394043
Batch 18/64 loss: -2.315674304962158
Batch 19/64 loss: -2.3580474853515625
Batch 20/64 loss: -2.3207950592041016
Batch 21/64 loss: -2.415550708770752
Batch 22/64 loss: -1.976506233215332
Batch 23/64 loss: -2.321981906890869
Batch 24/64 loss: -2.338827133178711
Batch 25/64 loss: -2.5144219398498535
Batch 26/64 loss: -2.2805519104003906
Batch 27/64 loss: -2.3603663444519043
Batch 28/64 loss: -2.2382545471191406
Batch 29/64 loss: -2.402859687805176
Batch 30/64 loss: -2.2102298736572266
Batch 31/64 loss: -2.3139896392822266
Batch 32/64 loss: -2.3448104858398438
Batch 33/64 loss: -2.348135471343994
Batch 34/64 loss: -2.0968971252441406
Batch 35/64 loss: -2.248602867126465
Batch 36/64 loss: -2.3649559020996094
Batch 37/64 loss: -1.5368099212646484
Batch 38/64 loss: -2.3517098426818848
Batch 39/64 loss: -1.8266754150390625
Batch 40/64 loss: -2.4633073806762695
Batch 41/64 loss: -2.260502815246582
Batch 42/64 loss: -2.3884429931640625
Batch 43/64 loss: -2.266572952270508
Batch 44/64 loss: -1.5945348739624023
Batch 45/64 loss: -2.2644901275634766
Batch 46/64 loss: -2.4089555740356445
Batch 47/64 loss: -2.0899734497070312
Batch 48/64 loss: -2.177450180053711
Batch 49/64 loss: -1.799020767211914
Batch 50/64 loss: -2.153860092163086
Batch 51/64 loss: -2.0562429428100586
Batch 52/64 loss: -2.266444206237793
Batch 53/64 loss: -2.1690683364868164
Batch 54/64 loss: -2.2460155487060547
Batch 55/64 loss: -2.1530466079711914
Batch 56/64 loss: -2.33026123046875
Batch 57/64 loss: -2.2736997604370117
Batch 58/64 loss: -2.2628049850463867
Batch 59/64 loss: -2.3529586791992188
Batch 60/64 loss: -2.1949901580810547
Batch 61/64 loss: -2.073160171508789
Batch 62/64 loss: -2.236104965209961
Batch 63/64 loss: -2.3525047302246094
Batch 64/64 loss: -6.312745094299316
Epoch 361  Train loss: -2.264524478538364  Val loss: -2.6620207848827455
Saving best model, epoch: 361
Epoch 362
-------------------------------
Batch 1/64 loss: -1.821568489074707
Batch 2/64 loss: -2.2902092933654785
Batch 3/64 loss: -2.389923572540283
Batch 4/64 loss: -2.271575927734375
Batch 5/64 loss: -2.348437786102295
Batch 6/64 loss: -2.2945055961608887
Batch 7/64 loss: -2.276172637939453
Batch 8/64 loss: -2.3838648796081543
Batch 9/64 loss: -2.135049819946289
Batch 10/64 loss: -2.129854202270508
Batch 11/64 loss: -2.266508102416992
Batch 12/64 loss: -2.0997190475463867
Batch 13/64 loss: -2.3688273429870605
Batch 14/64 loss: -2.3170299530029297
Batch 15/64 loss: -2.205916404724121
Batch 16/64 loss: -2.0760879516601562
Batch 17/64 loss: -2.2880496978759766
Batch 18/64 loss: -2.2387609481811523
Batch 19/64 loss: -2.3886399269104004
Batch 20/64 loss: -2.2972412109375
Batch 21/64 loss: -2.3399953842163086
Batch 22/64 loss: -1.7922735214233398
Batch 23/64 loss: -2.3681459426879883
Batch 24/64 loss: -2.1356706619262695
Batch 25/64 loss: -2.233966827392578
Batch 26/64 loss: -2.2323532104492188
Batch 27/64 loss: -2.4126620292663574
Batch 28/64 loss: -2.229111671447754
Batch 29/64 loss: -2.297372817993164
Batch 30/64 loss: -2.050058364868164
Batch 31/64 loss: -1.8745460510253906
Batch 32/64 loss: -2.28924560546875
Batch 33/64 loss: -2.0220232009887695
Batch 34/64 loss: -2.272523880004883
Batch 35/64 loss: -2.152371406555176
Batch 36/64 loss: -2.2223262786865234
Batch 37/64 loss: -2.211261749267578
Batch 38/64 loss: -2.145313262939453
Batch 39/64 loss: -2.2999277114868164
Batch 40/64 loss: -2.3374314308166504
Batch 41/64 loss: -1.8114700317382812
Batch 42/64 loss: -2.195171356201172
Batch 43/64 loss: -1.9197454452514648
Batch 44/64 loss: -2.1567840576171875
Batch 45/64 loss: -1.7085456848144531
Batch 46/64 loss: -1.8807344436645508
Batch 47/64 loss: -1.7412490844726562
Batch 48/64 loss: -1.0962905883789062
Batch 49/64 loss: -1.9111900329589844
Batch 50/64 loss: -1.613825798034668
Batch 51/64 loss: -1.809783935546875
Batch 52/64 loss: -1.9154415130615234
Batch 53/64 loss: -2.1263723373413086
Batch 54/64 loss: -1.7113714218139648
Batch 55/64 loss: -2.030303955078125
Batch 56/64 loss: -2.0488462448120117
Batch 57/64 loss: -2.091257095336914
Batch 58/64 loss: -2.006484031677246
Batch 59/64 loss: -1.61566162109375
Batch 60/64 loss: -2.107060432434082
Batch 61/64 loss: -1.824204444885254
Batch 62/64 loss: -1.9705209732055664
Batch 63/64 loss: -1.9757118225097656
Batch 64/64 loss: -6.240983009338379
Epoch 362  Train loss: -2.1451809789620193  Val loss: -2.39628673173308
Epoch 363
-------------------------------
Batch 1/64 loss: -2.111029624938965
Batch 2/64 loss: -2.1635055541992188
Batch 3/64 loss: -1.9561681747436523
Batch 4/64 loss: -2.176637649536133
Batch 5/64 loss: -1.9601125717163086
Batch 6/64 loss: -2.225187301635742
Batch 7/64 loss: -1.9490489959716797
Batch 8/64 loss: -2.0934677124023438
Batch 9/64 loss: -1.753220558166504
Batch 10/64 loss: -1.7957239151000977
Batch 11/64 loss: -2.265991687774658
Batch 12/64 loss: -1.7842483520507812
Batch 13/64 loss: -2.1041555404663086
Batch 14/64 loss: -1.4820976257324219
Batch 15/64 loss: -2.028064727783203
Batch 16/64 loss: -2.0458364486694336
Batch 17/64 loss: -2.144317626953125
Batch 18/64 loss: -1.9830799102783203
Batch 19/64 loss: -1.485224723815918
Batch 20/64 loss: -2.2301931381225586
Batch 21/64 loss: -2.1653642654418945
Batch 22/64 loss: -1.395035743713379
Batch 23/64 loss: -2.150430679321289
Batch 24/64 loss: -1.917618751525879
Batch 25/64 loss: -1.6592750549316406
Batch 26/64 loss: -2.2071971893310547
Batch 27/64 loss: -2.197183609008789
Batch 28/64 loss: -2.0802879333496094
Batch 29/64 loss: -2.133242607116699
Batch 30/64 loss: -2.063314437866211
Batch 31/64 loss: -1.8373403549194336
Batch 32/64 loss: -1.5892305374145508
Batch 33/64 loss: -1.8028926849365234
Batch 34/64 loss: -2.1841773986816406
Batch 35/64 loss: -2.161126136779785
Batch 36/64 loss: -1.97662353515625
Batch 37/64 loss: -2.1548681259155273
Batch 38/64 loss: -1.8907203674316406
Batch 39/64 loss: -2.1668615341186523
Batch 40/64 loss: -2.3394269943237305
Batch 41/64 loss: -1.6054792404174805
Batch 42/64 loss: -1.8212995529174805
Batch 43/64 loss: -1.8706178665161133
Batch 44/64 loss: -2.246805191040039
Batch 45/64 loss: -1.9856586456298828
Batch 46/64 loss: -2.204941749572754
Batch 47/64 loss: -2.2023448944091797
Batch 48/64 loss: -2.0789880752563477
Batch 49/64 loss: -2.1374807357788086
Batch 50/64 loss: -1.5881662368774414
Batch 51/64 loss: -2.135641098022461
Batch 52/64 loss: -1.8437108993530273
Batch 53/64 loss: -1.9751644134521484
Batch 54/64 loss: -2.1851749420166016
Batch 55/64 loss: -2.243901252746582
Batch 56/64 loss: -2.1505956649780273
Batch 57/64 loss: -2.131641387939453
Batch 58/64 loss: -2.2096405029296875
Batch 59/64 loss: -2.117795944213867
Batch 60/64 loss: -2.3774800300598145
Batch 61/64 loss: -2.3466033935546875
Batch 62/64 loss: -2.3209824562072754
Batch 63/64 loss: -2.202829360961914
Batch 64/64 loss: -6.410175800323486
Epoch 363  Train loss: -2.0800016496695726  Val loss: -2.496632500612449
Epoch 364
-------------------------------
Batch 1/64 loss: -2.1096696853637695
Batch 2/64 loss: -2.215277671813965
Batch 3/64 loss: -1.737959861755371
Batch 4/64 loss: -1.9872093200683594
Batch 5/64 loss: -2.2937707901000977
Batch 6/64 loss: -1.9073810577392578
Batch 7/64 loss: -2.0315065383911133
Batch 8/64 loss: -2.320291519165039
Batch 9/64 loss: -2.3224611282348633
Batch 10/64 loss: -2.0088729858398438
Batch 11/64 loss: -2.215060234069824
Batch 12/64 loss: -1.920888900756836
Batch 13/64 loss: -2.070934295654297
Batch 14/64 loss: -2.3140993118286133
Batch 15/64 loss: -2.1968765258789062
Batch 16/64 loss: -2.4102048873901367
Batch 17/64 loss: -2.2806596755981445
Batch 18/64 loss: -2.402926445007324
Batch 19/64 loss: -2.3218841552734375
Batch 20/64 loss: -2.057535171508789
Batch 21/64 loss: -2.3285884857177734
Batch 22/64 loss: -1.996230125427246
Batch 23/64 loss: -2.392880916595459
Batch 24/64 loss: -1.7931041717529297
Batch 25/64 loss: -2.2263126373291016
Batch 26/64 loss: -2.3747806549072266
Batch 27/64 loss: -2.119387626647949
Batch 28/64 loss: -2.299135208129883
Batch 29/64 loss: -2.1694717407226562
Batch 30/64 loss: -2.195408821105957
Batch 31/64 loss: -1.8973407745361328
Batch 32/64 loss: -2.3784313201904297
Batch 33/64 loss: -1.9463605880737305
Batch 34/64 loss: -2.3487510681152344
Batch 35/64 loss: -1.871938705444336
Batch 36/64 loss: -2.3140387535095215
Batch 37/64 loss: -2.3046064376831055
Batch 38/64 loss: -2.397103786468506
Batch 39/64 loss: -2.42264461517334
Batch 40/64 loss: -1.737473487854004
Batch 41/64 loss: -2.0606861114501953
Batch 42/64 loss: -2.3053345680236816
Batch 43/64 loss: -2.2575302124023438
Batch 44/64 loss: -2.381645679473877
Batch 45/64 loss: -2.4200119972229004
Batch 46/64 loss: -1.94952392578125
Batch 47/64 loss: -2.288064956665039
Batch 48/64 loss: -2.2018613815307617
Batch 49/64 loss: -2.1418581008911133
Batch 50/64 loss: -2.441051483154297
Batch 51/64 loss: -2.434692859649658
Batch 52/64 loss: -2.352623462677002
Batch 53/64 loss: -2.2424325942993164
Batch 54/64 loss: -2.346494674682617
Batch 55/64 loss: -2.3403892517089844
Batch 56/64 loss: -2.271914482116699
Batch 57/64 loss: -2.2717466354370117
Batch 58/64 loss: -2.312307357788086
Batch 59/64 loss: -2.0765724182128906
Batch 60/64 loss: -1.3139848709106445
Batch 61/64 loss: -2.2242822647094727
Batch 62/64 loss: -2.1819047927856445
Batch 63/64 loss: -2.128779411315918
Batch 64/64 loss: -6.430871486663818
Epoch 364  Train loss: -2.2338557991327024  Val loss: -2.558913162074138
Epoch 365
-------------------------------
Batch 1/64 loss: -2.3603763580322266
Batch 2/64 loss: -2.216395378112793
Batch 3/64 loss: -2.403440475463867
Batch 4/64 loss: -2.160959243774414
Batch 5/64 loss: -2.3481593132019043
Batch 6/64 loss: -2.1808528900146484
Batch 7/64 loss: -2.151362419128418
Batch 8/64 loss: -2.2200469970703125
Batch 9/64 loss: -2.064173698425293
Batch 10/64 loss: -1.7951669692993164
Batch 11/64 loss: -2.400599479675293
Batch 12/64 loss: -2.341073989868164
Batch 13/64 loss: -2.0722694396972656
Batch 14/64 loss: -1.9727458953857422
Batch 15/64 loss: -2.0869140625
Batch 16/64 loss: -2.199069023132324
Batch 17/64 loss: -2.0650243759155273
Batch 18/64 loss: -2.115121841430664
Batch 19/64 loss: -1.7494621276855469
Batch 20/64 loss: -2.3693885803222656
Batch 21/64 loss: -2.0896949768066406
Batch 22/64 loss: -2.383213520050049
Batch 23/64 loss: -2.292595863342285
Batch 24/64 loss: -1.3766851425170898
Batch 25/64 loss: -2.285114288330078
Batch 26/64 loss: -2.2718734741210938
Batch 27/64 loss: -2.309414863586426
Batch 28/64 loss: -2.380556106567383
Batch 29/64 loss: -2.329397201538086
Batch 30/64 loss: -1.6530494689941406
Batch 31/64 loss: -2.2350502014160156
Batch 32/64 loss: -2.3102970123291016
Batch 33/64 loss: -2.2691783905029297
Batch 34/64 loss: -2.1563024520874023
Batch 35/64 loss: -1.6965808868408203
Batch 36/64 loss: -2.023557662963867
Batch 37/64 loss: -2.1725425720214844
Batch 38/64 loss: -2.0924072265625
Batch 39/64 loss: -2.1756668090820312
Batch 40/64 loss: -2.1017627716064453
Batch 41/64 loss: -1.7828655242919922
Batch 42/64 loss: -2.1976709365844727
Batch 43/64 loss: -2.212596893310547
Batch 44/64 loss: -1.9992046356201172
Batch 45/64 loss: -2.361896514892578
Batch 46/64 loss: -2.247425079345703
Batch 47/64 loss: -2.078354835510254
Batch 48/64 loss: -2.2197742462158203
Batch 49/64 loss: -2.1050901412963867
Batch 50/64 loss: -2.3171091079711914
Batch 51/64 loss: -2.335526466369629
Batch 52/64 loss: -2.420480728149414
Batch 53/64 loss: -2.26861572265625
Batch 54/64 loss: -2.1940746307373047
Batch 55/64 loss: -2.3283920288085938
Batch 56/64 loss: -2.1939516067504883
Batch 57/64 loss: -2.0481700897216797
Batch 58/64 loss: -2.3209056854248047
Batch 59/64 loss: -2.1612205505371094
Batch 60/64 loss: -2.246480941772461
Batch 61/64 loss: -2.1145219802856445
Batch 62/64 loss: -2.444701671600342
Batch 63/64 loss: -2.121048927307129
Batch 64/64 loss: -6.299256801605225
Epoch 365  Train loss: -2.2168167058159325  Val loss: -2.5200766992732833
Epoch 366
-------------------------------
Batch 1/64 loss: -2.213686943054199
Batch 2/64 loss: -2.2899341583251953
Batch 3/64 loss: -0.6168117523193359
Batch 4/64 loss: -2.3366427421569824
Batch 5/64 loss: -2.3581533432006836
Batch 6/64 loss: -2.429445266723633
Batch 7/64 loss: -2.24481201171875
Batch 8/64 loss: -2.033625602722168
Batch 9/64 loss: -2.186577796936035
Batch 10/64 loss: -2.0818634033203125
Batch 11/64 loss: -1.755843162536621
Batch 12/64 loss: -2.3288421630859375
Batch 13/64 loss: -1.9717445373535156
Batch 14/64 loss: -2.1752548217773438
Batch 15/64 loss: -2.1545658111572266
Batch 16/64 loss: -2.2875051498413086
Batch 17/64 loss: -2.3245668411254883
Batch 18/64 loss: -2.3962273597717285
Batch 19/64 loss: -2.290461540222168
Batch 20/64 loss: -2.284992218017578
Batch 21/64 loss: -1.9928903579711914
Batch 22/64 loss: -2.099207878112793
Batch 23/64 loss: -2.3544883728027344
Batch 24/64 loss: -2.1510210037231445
Batch 25/64 loss: -2.0841760635375977
Batch 26/64 loss: -1.7356195449829102
Batch 27/64 loss: -2.204585075378418
Batch 28/64 loss: -2.0997848510742188
Batch 29/64 loss: -2.3480300903320312
Batch 30/64 loss: -1.8269500732421875
Batch 31/64 loss: -1.8501224517822266
Batch 32/64 loss: -2.202378273010254
Batch 33/64 loss: -1.961665153503418
Batch 34/64 loss: -1.8112592697143555
Batch 35/64 loss: -2.155122756958008
Batch 36/64 loss: -1.702977180480957
Batch 37/64 loss: -2.0808639526367188
Batch 38/64 loss: -2.1803359985351562
Batch 39/64 loss: -2.037379264831543
Batch 40/64 loss: -2.1994028091430664
Batch 41/64 loss: -2.059145927429199
Batch 42/64 loss: -2.1557483673095703
Batch 43/64 loss: -1.68707275390625
Batch 44/64 loss: -2.1017446517944336
Batch 45/64 loss: -1.9591073989868164
Batch 46/64 loss: -2.031033515930176
Batch 47/64 loss: -2.2932615280151367
Batch 48/64 loss: -2.158590316772461
Batch 49/64 loss: -2.14827823638916
Batch 50/64 loss: -2.245210647583008
Batch 51/64 loss: -2.1179447174072266
Batch 52/64 loss: -1.9914321899414062
Batch 53/64 loss: -2.3649344444274902
Batch 54/64 loss: -1.9826126098632812
Batch 55/64 loss: -2.210968017578125
Batch 56/64 loss: -2.234116554260254
Batch 57/64 loss: -2.30611515045166
Batch 58/64 loss: -2.2839889526367188
Batch 59/64 loss: -2.0384159088134766
Batch 60/64 loss: -2.135836601257324
Batch 61/64 loss: -1.703730583190918
Batch 62/64 loss: -2.022952079772949
Batch 63/64 loss: -2.1710901260375977
Batch 64/64 loss: -6.534337997436523
Epoch 366  Train loss: -2.1512768913717832  Val loss: -2.4599413396566594
Epoch 367
-------------------------------
Batch 1/64 loss: -2.2567663192749023
Batch 2/64 loss: -2.243596076965332
Batch 3/64 loss: -2.1528005599975586
Batch 4/64 loss: -2.4332056045532227
Batch 5/64 loss: -1.292724609375
Batch 6/64 loss: -2.218937873840332
Batch 7/64 loss: -2.3095970153808594
Batch 8/64 loss: -2.169135093688965
Batch 9/64 loss: -2.290593147277832
Batch 10/64 loss: -2.379629611968994
Batch 11/64 loss: -2.1909008026123047
Batch 12/64 loss: -2.1919336318969727
Batch 13/64 loss: -1.9271793365478516
Batch 14/64 loss: -2.2169246673583984
Batch 15/64 loss: -1.4231138229370117
Batch 16/64 loss: -2.185574531555176
Batch 17/64 loss: -2.13124942779541
Batch 18/64 loss: -2.282492160797119
Batch 19/64 loss: -2.3092503547668457
Batch 20/64 loss: -2.4134020805358887
Batch 21/64 loss: -2.2345075607299805
Batch 22/64 loss: -2.2005157470703125
Batch 23/64 loss: -2.2272567749023438
Batch 24/64 loss: -2.354344367980957
Batch 25/64 loss: -2.0480384826660156
Batch 26/64 loss: -2.3801021575927734
Batch 27/64 loss: -1.9386606216430664
Batch 28/64 loss: -2.103205680847168
Batch 29/64 loss: -2.087766647338867
Batch 30/64 loss: -2.110079765319824
Batch 31/64 loss: -2.2464599609375
Batch 32/64 loss: -1.7369260787963867
Batch 33/64 loss: -2.380911350250244
Batch 34/64 loss: -2.205556869506836
Batch 35/64 loss: -1.941227912902832
Batch 36/64 loss: -2.2676382064819336
Batch 37/64 loss: -2.2965173721313477
Batch 38/64 loss: -2.070047378540039
Batch 39/64 loss: -2.090817451477051
Batch 40/64 loss: -2.1705379486083984
Batch 41/64 loss: -1.948988914489746
Batch 42/64 loss: -2.4911279678344727
Batch 43/64 loss: -2.247298240661621
Batch 44/64 loss: -1.8610687255859375
Batch 45/64 loss: -2.141397476196289
Batch 46/64 loss: -1.9685182571411133
Batch 47/64 loss: -2.1958541870117188
Batch 48/64 loss: -2.3705496788024902
Batch 49/64 loss: -2.3828210830688477
Batch 50/64 loss: -2.2418441772460938
Batch 51/64 loss: -2.2345571517944336
Batch 52/64 loss: -2.1482648849487305
Batch 53/64 loss: -2.2813901901245117
Batch 54/64 loss: -2.156370162963867
Batch 55/64 loss: -1.9140195846557617
Batch 56/64 loss: -2.088876724243164
Batch 57/64 loss: -2.4512619972229004
Batch 58/64 loss: -2.3116254806518555
Batch 59/64 loss: -2.2110719680786133
Batch 60/64 loss: -2.2975120544433594
Batch 61/64 loss: -2.3503904342651367
Batch 62/64 loss: -2.1202640533447266
Batch 63/64 loss: -2.117368698120117
Batch 64/64 loss: -6.397180557250977
Epoch 367  Train loss: -2.218673765893076  Val loss: -2.4600159294416812
Epoch 368
-------------------------------
Batch 1/64 loss: -2.342397689819336
Batch 2/64 loss: -2.416534900665283
Batch 3/64 loss: -2.376473903656006
Batch 4/64 loss: -1.7088098526000977
Batch 5/64 loss: -2.3037662506103516
Batch 6/64 loss: -2.071568489074707
Batch 7/64 loss: -2.1864871978759766
Batch 8/64 loss: -2.2889404296875
Batch 9/64 loss: -1.860748291015625
Batch 10/64 loss: -2.1494178771972656
Batch 11/64 loss: -2.1955556869506836
Batch 12/64 loss: -2.3398447036743164
Batch 13/64 loss: -2.1843080520629883
Batch 14/64 loss: -2.104969024658203
Batch 15/64 loss: -2.445232391357422
Batch 16/64 loss: -2.196293830871582
Batch 17/64 loss: -2.0386409759521484
Batch 18/64 loss: -2.28778076171875
Batch 19/64 loss: -2.222442626953125
Batch 20/64 loss: -2.1743602752685547
Batch 21/64 loss: -2.39955997467041
Batch 22/64 loss: -2.3111534118652344
Batch 23/64 loss: -2.367558479309082
Batch 24/64 loss: -2.326904773712158
Batch 25/64 loss: -2.258943557739258
Batch 26/64 loss: -1.9601383209228516
Batch 27/64 loss: -2.329819679260254
Batch 28/64 loss: -2.3676748275756836
Batch 29/64 loss: -2.3197851181030273
Batch 30/64 loss: -2.340414047241211
Batch 31/64 loss: -2.0902576446533203
Batch 32/64 loss: -1.8953475952148438
Batch 33/64 loss: -2.3684377670288086
Batch 34/64 loss: -2.193073272705078
Batch 35/64 loss: -2.33695125579834
Batch 36/64 loss: -2.3090267181396484
Batch 37/64 loss: -2.211918830871582
Batch 38/64 loss: -2.156597137451172
Batch 39/64 loss: -2.2961983680725098
Batch 40/64 loss: -2.021350860595703
Batch 41/64 loss: -2.1997861862182617
Batch 42/64 loss: -2.3781957626342773
Batch 43/64 loss: -2.1701297760009766
Batch 44/64 loss: -2.0494585037231445
Batch 45/64 loss: -2.45535945892334
Batch 46/64 loss: -2.22914981842041
Batch 47/64 loss: -2.191176414489746
Batch 48/64 loss: -2.121377944946289
Batch 49/64 loss: -1.5990524291992188
Batch 50/64 loss: -2.1979751586914062
Batch 51/64 loss: -2.0350160598754883
Batch 52/64 loss: -1.637557029724121
Batch 53/64 loss: -2.2617835998535156
Batch 54/64 loss: -2.15987491607666
Batch 55/64 loss: -2.4401721954345703
Batch 56/64 loss: -2.0920724868774414
Batch 57/64 loss: -2.228422164916992
Batch 58/64 loss: -2.226909637451172
Batch 59/64 loss: -2.2151384353637695
Batch 60/64 loss: -2.0495967864990234
Batch 61/64 loss: -2.0747718811035156
Batch 62/64 loss: -2.233938217163086
Batch 63/64 loss: -2.324824810028076
Batch 64/64 loss: -5.27150821685791
Epoch 368  Train loss: -2.231859697080126  Val loss: -2.5020645377562216
Epoch 369
-------------------------------
Batch 1/64 loss: -2.3246335983276367
Batch 2/64 loss: -2.159494400024414
Batch 3/64 loss: -2.180476188659668
Batch 4/64 loss: -2.3949413299560547
Batch 5/64 loss: -2.1377391815185547
Batch 6/64 loss: -2.178983688354492
Batch 7/64 loss: -2.3819785118103027
Batch 8/64 loss: -2.2950453758239746
Batch 9/64 loss: -2.061089515686035
Batch 10/64 loss: -1.937361717224121
Batch 11/64 loss: -1.692296028137207
Batch 12/64 loss: -2.4062814712524414
Batch 13/64 loss: -2.195100784301758
Batch 14/64 loss: -2.169631004333496
Batch 15/64 loss: -2.3988828659057617
Batch 16/64 loss: -2.2240610122680664
Batch 17/64 loss: -2.2581005096435547
Batch 18/64 loss: -2.3944644927978516
Batch 19/64 loss: -1.964961051940918
Batch 20/64 loss: -2.3182811737060547
Batch 21/64 loss: -2.313173294067383
Batch 22/64 loss: -1.319234848022461
Batch 23/64 loss: -2.33754825592041
Batch 24/64 loss: -2.153916358947754
Batch 25/64 loss: -2.048874855041504
Batch 26/64 loss: -2.326498508453369
Batch 27/64 loss: -2.0283031463623047
Batch 28/64 loss: -2.2435998916625977
Batch 29/64 loss: -2.2497072219848633
Batch 30/64 loss: -2.2367563247680664
Batch 31/64 loss: -1.870285987854004
Batch 32/64 loss: -1.714818000793457
Batch 33/64 loss: -2.184889793395996
Batch 34/64 loss: -1.750828742980957
Batch 35/64 loss: -2.0037240982055664
Batch 36/64 loss: -2.227293014526367
Batch 37/64 loss: -2.3049678802490234
Batch 38/64 loss: -2.156834602355957
Batch 39/64 loss: -1.5326776504516602
Batch 40/64 loss: -2.204364776611328
Batch 41/64 loss: -2.211798667907715
Batch 42/64 loss: -2.0792341232299805
Batch 43/64 loss: -2.053882598876953
Batch 44/64 loss: -1.6404962539672852
Batch 45/64 loss: -2.2566099166870117
Batch 46/64 loss: -2.2248926162719727
Batch 47/64 loss: -2.02451229095459
Batch 48/64 loss: -2.0310869216918945
Batch 49/64 loss: -2.1102523803710938
Batch 50/64 loss: -2.1448240280151367
Batch 51/64 loss: -2.253037452697754
Batch 52/64 loss: -2.101742744445801
Batch 53/64 loss: -2.203075408935547
Batch 54/64 loss: -1.3041725158691406
Batch 55/64 loss: -2.0784311294555664
Batch 56/64 loss: -2.46793270111084
Batch 57/64 loss: -2.1677465438842773
Batch 58/64 loss: -2.3145627975463867
Batch 59/64 loss: -1.9629755020141602
Batch 60/64 loss: -2.147642135620117
Batch 61/64 loss: -2.339083671569824
Batch 62/64 loss: -2.320004463195801
Batch 63/64 loss: -2.294497489929199
Batch 64/64 loss: -6.186639308929443
Epoch 369  Train loss: -2.1749737253376082  Val loss: -2.4048875893923833
Epoch 370
-------------------------------
Batch 1/64 loss: -2.1871509552001953
Batch 2/64 loss: -1.787485122680664
Batch 3/64 loss: -2.220160484313965
Batch 4/64 loss: -2.145505905151367
Batch 5/64 loss: -2.289438247680664
Batch 6/64 loss: -2.4617719650268555
Batch 7/64 loss: -2.2260217666625977
Batch 8/64 loss: -1.7345046997070312
Batch 9/64 loss: -2.1150007247924805
Batch 10/64 loss: -2.226742744445801
Batch 11/64 loss: -2.079216957092285
Batch 12/64 loss: -2.0636377334594727
Batch 13/64 loss: -2.2763004302978516
Batch 14/64 loss: -1.9586896896362305
Batch 15/64 loss: -2.1294050216674805
Batch 16/64 loss: -1.6713647842407227
Batch 17/64 loss: -2.077042579650879
Batch 18/64 loss: -1.9835643768310547
Batch 19/64 loss: -2.3219871520996094
Batch 20/64 loss: -2.151726722717285
Batch 21/64 loss: -0.3588743209838867
Batch 22/64 loss: -2.2035999298095703
Batch 23/64 loss: -2.42635440826416
Batch 24/64 loss: -1.8433141708374023
Batch 25/64 loss: -2.3721961975097656
Batch 26/64 loss: -2.096498489379883
Batch 27/64 loss: -2.3389434814453125
Batch 28/64 loss: -2.2314043045043945
Batch 29/64 loss: -2.269582748413086
Batch 30/64 loss: -2.0721330642700195
Batch 31/64 loss: -2.05191707611084
Batch 32/64 loss: -2.2329330444335938
Batch 33/64 loss: -1.4942350387573242
Batch 34/64 loss: -2.307713508605957
Batch 35/64 loss: -2.199756622314453
Batch 36/64 loss: -2.327996253967285
Batch 37/64 loss: -2.2009057998657227
Batch 38/64 loss: -2.3139991760253906
Batch 39/64 loss: -2.3245177268981934
Batch 40/64 loss: -2.198577880859375
Batch 41/64 loss: -2.109434127807617
Batch 42/64 loss: -2.1448726654052734
Batch 43/64 loss: -2.173868179321289
Batch 44/64 loss: -2.1119489669799805
Batch 45/64 loss: -1.8781614303588867
Batch 46/64 loss: -1.9948434829711914
Batch 47/64 loss: -2.1920337677001953
Batch 48/64 loss: -2.2585182189941406
Batch 49/64 loss: -2.2864465713500977
Batch 50/64 loss: -2.3852529525756836
Batch 51/64 loss: -1.632720947265625
Batch 52/64 loss: -2.310209274291992
Batch 53/64 loss: -1.5427331924438477
Batch 54/64 loss: -2.2531938552856445
Batch 55/64 loss: -2.49055814743042
Batch 56/64 loss: -2.445558547973633
Batch 57/64 loss: -2.207277297973633
Batch 58/64 loss: -2.142475128173828
Batch 59/64 loss: -2.0642175674438477
Batch 60/64 loss: -2.3050107955932617
Batch 61/64 loss: -2.4191627502441406
Batch 62/64 loss: -2.2792415618896484
Batch 63/64 loss: -2.0310115814208984
Batch 64/64 loss: -6.32693338394165
Epoch 370  Train loss: -2.170605840869978  Val loss: -2.392493061183654
Epoch 371
-------------------------------
Batch 1/64 loss: -2.1035823822021484
Batch 2/64 loss: -1.600743293762207
Batch 3/64 loss: -2.1090145111083984
Batch 4/64 loss: -2.1770429611206055
Batch 5/64 loss: -2.3898072242736816
Batch 6/64 loss: -2.3978934288024902
Batch 7/64 loss: -2.006960868835449
Batch 8/64 loss: -2.239138603210449
Batch 9/64 loss: -2.3311243057250977
Batch 10/64 loss: -2.2338247299194336
Batch 11/64 loss: -2.157918930053711
Batch 12/64 loss: -2.279153823852539
Batch 13/64 loss: -2.271991729736328
Batch 14/64 loss: -2.040895462036133
Batch 15/64 loss: -2.3308582305908203
Batch 16/64 loss: -2.2302780151367188
Batch 17/64 loss: -2.11379337310791
Batch 18/64 loss: -2.2966508865356445
Batch 19/64 loss: -2.3542404174804688
Batch 20/64 loss: -2.207822799682617
Batch 21/64 loss: -2.0629777908325195
Batch 22/64 loss: -2.4595232009887695
Batch 23/64 loss: -2.266481399536133
Batch 24/64 loss: -2.20361328125
Batch 25/64 loss: -2.19525146484375
Batch 26/64 loss: -1.450296401977539
Batch 27/64 loss: -1.3639287948608398
Batch 28/64 loss: -2.310192108154297
Batch 29/64 loss: -2.3646974563598633
Batch 30/64 loss: -2.109142303466797
Batch 31/64 loss: -2.2661561965942383
Batch 32/64 loss: -2.2558107376098633
Batch 33/64 loss: -1.9891958236694336
Batch 34/64 loss: -2.3296260833740234
Batch 35/64 loss: -2.4706568717956543
Batch 36/64 loss: -2.216801643371582
Batch 37/64 loss: -1.7838611602783203
Batch 38/64 loss: -2.4532947540283203
Batch 39/64 loss: -2.310361862182617
Batch 40/64 loss: -2.297931671142578
Batch 41/64 loss: -2.09500789642334
Batch 42/64 loss: -1.2804040908813477
Batch 43/64 loss: -2.377415657043457
Batch 44/64 loss: -2.0925369262695312
Batch 45/64 loss: -2.4439821243286133
Batch 46/64 loss: -2.056241035461426
Batch 47/64 loss: -2.3684377670288086
Batch 48/64 loss: -2.179854393005371
Batch 49/64 loss: -2.254511833190918
Batch 50/64 loss: -2.355520248413086
Batch 51/64 loss: -2.1120071411132812
Batch 52/64 loss: -2.418825149536133
Batch 53/64 loss: -2.2813053131103516
Batch 54/64 loss: -2.4004969596862793
Batch 55/64 loss: -2.445067882537842
Batch 56/64 loss: -1.2290430068969727
Batch 57/64 loss: -2.234424591064453
Batch 58/64 loss: -2.0764780044555664
Batch 59/64 loss: -2.346846580505371
Batch 60/64 loss: -2.3211984634399414
Batch 61/64 loss: -2.1986961364746094
Batch 62/64 loss: -2.3135499954223633
Batch 63/64 loss: -2.354490280151367
Batch 64/64 loss: -6.44222354888916
Epoch 371  Train loss: -2.229028174456428  Val loss: -2.644485657157767
Epoch 372
-------------------------------
Batch 1/64 loss: -2.358522415161133
Batch 2/64 loss: -2.1492862701416016
Batch 3/64 loss: -2.475717544555664
Batch 4/64 loss: -2.2882442474365234
Batch 5/64 loss: -1.818521499633789
Batch 6/64 loss: -2.3671226501464844
Batch 7/64 loss: -2.188627243041992
Batch 8/64 loss: -2.300668716430664
Batch 9/64 loss: -2.2733211517333984
Batch 10/64 loss: -1.526413917541504
Batch 11/64 loss: -2.3405561447143555
Batch 12/64 loss: -2.108671188354492
Batch 13/64 loss: -2.317540168762207
Batch 14/64 loss: -2.277134895324707
Batch 15/64 loss: -2.3856825828552246
Batch 16/64 loss: -2.3413238525390625
Batch 17/64 loss: -2.2605819702148438
Batch 18/64 loss: -2.2063980102539062
Batch 19/64 loss: -2.175591468811035
Batch 20/64 loss: -2.3232498168945312
Batch 21/64 loss: -2.285733222961426
Batch 22/64 loss: -2.364414691925049
Batch 23/64 loss: -2.305068016052246
Batch 24/64 loss: -2.2857542037963867
Batch 25/64 loss: -2.3872146606445312
Batch 26/64 loss: -2.2136974334716797
Batch 27/64 loss: -2.2967824935913086
Batch 28/64 loss: -2.047083854675293
Batch 29/64 loss: -2.1199655532836914
Batch 30/64 loss: -2.3767776489257812
Batch 31/64 loss: -1.5721263885498047
Batch 32/64 loss: -2.1118602752685547
Batch 33/64 loss: -2.2213125228881836
Batch 34/64 loss: -2.37662935256958
Batch 35/64 loss: -2.3943872451782227
Batch 36/64 loss: -2.402482032775879
Batch 37/64 loss: -2.277963638305664
Batch 38/64 loss: -2.308370590209961
Batch 39/64 loss: -2.053607940673828
Batch 40/64 loss: -2.3156538009643555
Batch 41/64 loss: -2.3637752532958984
Batch 42/64 loss: -2.348538398742676
Batch 43/64 loss: -2.16552734375
Batch 44/64 loss: -2.021944046020508
Batch 45/64 loss: -2.2494802474975586
Batch 46/64 loss: -2.3132076263427734
Batch 47/64 loss: -2.216883659362793
Batch 48/64 loss: -2.315617561340332
Batch 49/64 loss: -2.2571067810058594
Batch 50/64 loss: -2.3572726249694824
Batch 51/64 loss: -2.3145523071289062
Batch 52/64 loss: -2.3894548416137695
Batch 53/64 loss: -2.1891517639160156
Batch 54/64 loss: -2.2486696243286133
Batch 55/64 loss: -2.2825326919555664
Batch 56/64 loss: -2.3283681869506836
Batch 57/64 loss: -2.1567630767822266
Batch 58/64 loss: -2.333672523498535
Batch 59/64 loss: -2.353766441345215
Batch 60/64 loss: -2.2813730239868164
Batch 61/64 loss: -2.2861804962158203
Batch 62/64 loss: -2.405867099761963
Batch 63/64 loss: -2.2603626251220703
Batch 64/64 loss: -6.556743144989014
Epoch 372  Train loss: -2.2989441086264217  Val loss: -2.619512276141504
Epoch 373
-------------------------------
Batch 1/64 loss: -2.1761045455932617
Batch 2/64 loss: -2.3558034896850586
Batch 3/64 loss: -1.7703380584716797
Batch 4/64 loss: -2.4449844360351562
Batch 5/64 loss: -2.4084439277648926
Batch 6/64 loss: -2.3092851638793945
Batch 7/64 loss: -1.9280967712402344
Batch 8/64 loss: -2.394929885864258
Batch 9/64 loss: -2.2837400436401367
Batch 10/64 loss: -2.081545829772949
Batch 11/64 loss: -2.278292655944824
Batch 12/64 loss: -2.3751420974731445
Batch 13/64 loss: -2.2607908248901367
Batch 14/64 loss: -2.1616134643554688
Batch 15/64 loss: -2.337761878967285
Batch 16/64 loss: -2.4263620376586914
Batch 17/64 loss: -2.2591352462768555
Batch 18/64 loss: -1.8121652603149414
Batch 19/64 loss: -2.4282007217407227
Batch 20/64 loss: -1.2936506271362305
Batch 21/64 loss: -2.360165596008301
Batch 22/64 loss: -2.330617904663086
Batch 23/64 loss: -2.3078551292419434
Batch 24/64 loss: -2.078850746154785
Batch 25/64 loss: -1.8867511749267578
Batch 26/64 loss: -2.3018765449523926
Batch 27/64 loss: -2.2408742904663086
Batch 28/64 loss: -2.2141427993774414
Batch 29/64 loss: -2.078030586242676
Batch 30/64 loss: -2.0209951400756836
Batch 31/64 loss: -2.2154130935668945
Batch 32/64 loss: -2.23699951171875
Batch 33/64 loss: -1.9448070526123047
Batch 34/64 loss: -1.9737138748168945
Batch 35/64 loss: -1.7859077453613281
Batch 36/64 loss: -2.041520118713379
Batch 37/64 loss: -2.157848358154297
Batch 38/64 loss: -2.2280588150024414
Batch 39/64 loss: -2.299067497253418
Batch 40/64 loss: -1.9476432800292969
Batch 41/64 loss: -2.4072771072387695
Batch 42/64 loss: -2.1943845748901367
Batch 43/64 loss: -2.254939079284668
Batch 44/64 loss: -2.3257851600646973
Batch 45/64 loss: -2.252565383911133
Batch 46/64 loss: -2.438436508178711
Batch 47/64 loss: -2.208003044128418
Batch 48/64 loss: -2.1804113388061523
Batch 49/64 loss: -2.2054500579833984
Batch 50/64 loss: -1.9575252532958984
Batch 51/64 loss: -2.1689910888671875
Batch 52/64 loss: -2.1323814392089844
Batch 53/64 loss: -2.278285026550293
Batch 54/64 loss: -2.2884979248046875
Batch 55/64 loss: -1.7228660583496094
Batch 56/64 loss: -2.4374914169311523
Batch 57/64 loss: -2.157914161682129
Batch 58/64 loss: -2.4035749435424805
Batch 59/64 loss: -2.266354560852051
Batch 60/64 loss: -2.349137306213379
Batch 61/64 loss: -2.1598987579345703
Batch 62/64 loss: -2.178341865539551
Batch 63/64 loss: -2.0741872787475586
Batch 64/64 loss: -6.498729228973389
Epoch 373  Train loss: -2.2330081958396764  Val loss: -2.4927403820339347
Epoch 374
-------------------------------
Batch 1/64 loss: -2.3009815216064453
Batch 2/64 loss: -2.0942554473876953
Batch 3/64 loss: -2.1707448959350586
Batch 4/64 loss: -2.2611141204833984
Batch 5/64 loss: -2.3141160011291504
Batch 6/64 loss: -2.332106113433838
Batch 7/64 loss: -2.283230781555176
Batch 8/64 loss: -2.1894168853759766
Batch 9/64 loss: -2.3747291564941406
Batch 10/64 loss: -2.1220035552978516
Batch 11/64 loss: -2.134340286254883
Batch 12/64 loss: -1.9049768447875977
Batch 13/64 loss: -2.2100706100463867
Batch 14/64 loss: -2.1239566802978516
Batch 15/64 loss: -2.044611930847168
Batch 16/64 loss: -2.0261306762695312
Batch 17/64 loss: -1.9148073196411133
Batch 18/64 loss: -2.236659049987793
Batch 19/64 loss: -1.5275945663452148
Batch 20/64 loss: -2.1537675857543945
Batch 21/64 loss: -2.2003374099731445
Batch 22/64 loss: -1.9726943969726562
Batch 23/64 loss: -2.351167678833008
Batch 24/64 loss: -2.2980518341064453
Batch 25/64 loss: -2.1997146606445312
Batch 26/64 loss: -2.3325414657592773
Batch 27/64 loss: -1.143132209777832
Batch 28/64 loss: -1.930063247680664
Batch 29/64 loss: -2.2141504287719727
Batch 30/64 loss: -1.6022930145263672
Batch 31/64 loss: -2.1361780166625977
Batch 32/64 loss: -1.9646492004394531
Batch 33/64 loss: -2.096846580505371
Batch 34/64 loss: -2.312924385070801
Batch 35/64 loss: -2.292963981628418
Batch 36/64 loss: -2.247178077697754
Batch 37/64 loss: -1.986276626586914
Batch 38/64 loss: -2.18612003326416
Batch 39/64 loss: -2.0740890502929688
Batch 40/64 loss: -1.7711257934570312
Batch 41/64 loss: -2.2236928939819336
Batch 42/64 loss: -2.1512794494628906
Batch 43/64 loss: -2.26165771484375
Batch 44/64 loss: -2.117344856262207
Batch 45/64 loss: -2.2721519470214844
Batch 46/64 loss: -2.3349356651306152
Batch 47/64 loss: -2.142867088317871
Batch 48/64 loss: -1.970942497253418
Batch 49/64 loss: -2.2183942794799805
Batch 50/64 loss: -2.0454511642456055
Batch 51/64 loss: -2.439906120300293
Batch 52/64 loss: -1.9310588836669922
Batch 53/64 loss: -2.162820816040039
Batch 54/64 loss: -2.358700752258301
Batch 55/64 loss: -1.6340713500976562
Batch 56/64 loss: -1.7599725723266602
Batch 57/64 loss: -2.298381805419922
Batch 58/64 loss: -2.23227596282959
Batch 59/64 loss: -2.2071542739868164
Batch 60/64 loss: -2.225226402282715
Batch 61/64 loss: -2.2092056274414062
Batch 62/64 loss: -2.2004003524780273
Batch 63/64 loss: -1.9157695770263672
Batch 64/64 loss: -6.433380126953125
Epoch 374  Train loss: -2.167385243434532  Val loss: -2.4311859812523493
Epoch 375
-------------------------------
Batch 1/64 loss: -1.9708881378173828
Batch 2/64 loss: -1.7595443725585938
Batch 3/64 loss: -1.942514419555664
Batch 4/64 loss: -2.219594955444336
Batch 5/64 loss: -2.271089553833008
Batch 6/64 loss: -2.1827354431152344
Batch 7/64 loss: -1.9629669189453125
Batch 8/64 loss: -2.338932514190674
Batch 9/64 loss: -2.1113338470458984
Batch 10/64 loss: -2.3864879608154297
Batch 11/64 loss: -2.310410499572754
Batch 12/64 loss: -1.7519340515136719
Batch 13/64 loss: -2.3736391067504883
Batch 14/64 loss: -2.184907913208008
Batch 15/64 loss: -2.1454572677612305
Batch 16/64 loss: -2.3643064498901367
Batch 17/64 loss: -2.1560373306274414
Batch 18/64 loss: -2.133975028991699
Batch 19/64 loss: -2.2006072998046875
Batch 20/64 loss: -2.260382652282715
Batch 21/64 loss: -2.2873802185058594
Batch 22/64 loss: -1.5743694305419922
Batch 23/64 loss: -2.2815732955932617
Batch 24/64 loss: -2.3107056617736816
Batch 25/64 loss: -2.3553009033203125
Batch 26/64 loss: -2.0612192153930664
Batch 27/64 loss: -2.3060436248779297
Batch 28/64 loss: -2.0840415954589844
Batch 29/64 loss: -2.2221946716308594
Batch 30/64 loss: -2.4120635986328125
Batch 31/64 loss: -2.2157793045043945
Batch 32/64 loss: -2.1367664337158203
Batch 33/64 loss: -2.2626991271972656
Batch 34/64 loss: -1.3946990966796875
Batch 35/64 loss: -2.121109962463379
Batch 36/64 loss: -2.326002597808838
Batch 37/64 loss: -2.2910499572753906
Batch 38/64 loss: -2.1513776779174805
Batch 39/64 loss: -2.3128414154052734
Batch 40/64 loss: -1.5500469207763672
Batch 41/64 loss: -2.3768868446350098
Batch 42/64 loss: -1.953324317932129
Batch 43/64 loss: -2.2567930221557617
Batch 44/64 loss: -2.286189079284668
Batch 45/64 loss: -1.8495550155639648
Batch 46/64 loss: -2.295962333679199
Batch 47/64 loss: -2.244582176208496
Batch 48/64 loss: -2.4052090644836426
Batch 49/64 loss: -2.322193145751953
Batch 50/64 loss: -1.9838151931762695
Batch 51/64 loss: -2.2309646606445312
Batch 52/64 loss: -2.1665468215942383
Batch 53/64 loss: -2.3116540908813477
Batch 54/64 loss: -2.407254695892334
Batch 55/64 loss: -2.3297982215881348
Batch 56/64 loss: -2.197371482849121
Batch 57/64 loss: -2.072490692138672
Batch 58/64 loss: -2.2079391479492188
Batch 59/64 loss: -2.279521942138672
Batch 60/64 loss: -2.2551145553588867
Batch 61/64 loss: -2.137293815612793
Batch 62/64 loss: -1.7600679397583008
Batch 63/64 loss: -2.2779035568237305
Batch 64/64 loss: -6.532850742340088
Epoch 375  Train loss: -2.2147934165655396  Val loss: -2.4910524243751344
Epoch 376
-------------------------------
Batch 1/64 loss: -2.1257429122924805
Batch 2/64 loss: -2.25112247467041
Batch 3/64 loss: -2.1920289993286133
Batch 4/64 loss: -2.253361701965332
Batch 5/64 loss: -2.3460655212402344
Batch 6/64 loss: -2.083970069885254
Batch 7/64 loss: -1.7195186614990234
Batch 8/64 loss: -1.9315910339355469
Batch 9/64 loss: -2.130483627319336
Batch 10/64 loss: -2.3114633560180664
Batch 11/64 loss: -2.2367963790893555
Batch 12/64 loss: -2.140660285949707
Batch 13/64 loss: -1.914494514465332
Batch 14/64 loss: -2.124905586242676
Batch 15/64 loss: -2.202310562133789
Batch 16/64 loss: -2.438265800476074
Batch 17/64 loss: -2.385237216949463
Batch 18/64 loss: -2.3136091232299805
Batch 19/64 loss: -2.041423797607422
Batch 20/64 loss: -2.3208723068237305
Batch 21/64 loss: -1.9622421264648438
Batch 22/64 loss: -2.3887557983398438
Batch 23/64 loss: -2.2271690368652344
Batch 24/64 loss: -2.044243812561035
Batch 25/64 loss: -2.368236541748047
Batch 26/64 loss: -2.3941426277160645
Batch 27/64 loss: -2.206751823425293
Batch 28/64 loss: -2.1819419860839844
Batch 29/64 loss: -2.3331260681152344
Batch 30/64 loss: -2.216275215148926
Batch 31/64 loss: -1.9737424850463867
Batch 32/64 loss: -2.287240982055664
Batch 33/64 loss: -1.4785852432250977
Batch 34/64 loss: -2.1294679641723633
Batch 35/64 loss: -2.151865005493164
Batch 36/64 loss: -2.0105104446411133
Batch 37/64 loss: -2.1953954696655273
Batch 38/64 loss: -2.1303443908691406
Batch 39/64 loss: -2.4037961959838867
Batch 40/64 loss: -2.309267997741699
Batch 41/64 loss: -2.3333234786987305
Batch 42/64 loss: -2.2355871200561523
Batch 43/64 loss: -2.2240352630615234
Batch 44/64 loss: -2.232285499572754
Batch 45/64 loss: -2.2850799560546875
Batch 46/64 loss: -2.336118698120117
Batch 47/64 loss: -2.283684253692627
Batch 48/64 loss: -2.351008415222168
Batch 49/64 loss: -2.4566073417663574
Batch 50/64 loss: -2.3622050285339355
Batch 51/64 loss: -2.19368839263916
Batch 52/64 loss: -2.338326930999756
Batch 53/64 loss: -1.7451133728027344
Batch 54/64 loss: -2.491021156311035
Batch 55/64 loss: -2.200484275817871
Batch 56/64 loss: -2.2024717330932617
Batch 57/64 loss: -2.18106746673584
Batch 58/64 loss: -0.9356117248535156
Batch 59/64 loss: -2.1086854934692383
Batch 60/64 loss: -2.332038402557373
Batch 61/64 loss: -2.477778434753418
Batch 62/64 loss: -2.447150707244873
Batch 63/64 loss: -2.469766616821289
Batch 64/64 loss: -6.524274826049805
Epoch 376  Train loss: -2.242719545551375  Val loss: -2.6258546363856783
Epoch 377
-------------------------------
Batch 1/64 loss: -2.248171806335449
Batch 2/64 loss: -2.3296399116516113
Batch 3/64 loss: -2.086859703063965
Batch 4/64 loss: -2.3720836639404297
Batch 5/64 loss: -2.356464385986328
Batch 6/64 loss: -2.3662805557250977
Batch 7/64 loss: -2.4108681678771973
Batch 8/64 loss: -2.392828941345215
Batch 9/64 loss: -2.043503761291504
Batch 10/64 loss: -1.9709901809692383
Batch 11/64 loss: -1.9526395797729492
Batch 12/64 loss: -2.3893041610717773
Batch 13/64 loss: -1.4712018966674805
Batch 14/64 loss: -2.220846176147461
Batch 15/64 loss: -2.448659896850586
Batch 16/64 loss: -2.3218088150024414
Batch 17/64 loss: -2.1709365844726562
Batch 18/64 loss: -2.335287570953369
Batch 19/64 loss: -2.235997200012207
Batch 20/64 loss: -1.7909774780273438
Batch 21/64 loss: -2.400097370147705
Batch 22/64 loss: -2.3295021057128906
Batch 23/64 loss: -2.3539061546325684
Batch 24/64 loss: -2.290633201599121
Batch 25/64 loss: -2.378159999847412
Batch 26/64 loss: -2.1544904708862305
Batch 27/64 loss: -2.2635116577148438
Batch 28/64 loss: -2.3860650062561035
Batch 29/64 loss: -2.277374267578125
Batch 30/64 loss: -2.333491802215576
Batch 31/64 loss: -2.3819751739501953
Batch 32/64 loss: -2.355252742767334
Batch 33/64 loss: -2.1762962341308594
Batch 34/64 loss: -2.4060416221618652
Batch 35/64 loss: -2.221731185913086
Batch 36/64 loss: -2.3362627029418945
Batch 37/64 loss: -2.238955497741699
Batch 38/64 loss: -2.259075164794922
Batch 39/64 loss: -2.324371337890625
Batch 40/64 loss: -2.4203362464904785
Batch 41/64 loss: -2.431081771850586
Batch 42/64 loss: -2.380101203918457
Batch 43/64 loss: -2.433706283569336
Batch 44/64 loss: -2.356529712677002
Batch 45/64 loss: -2.3899550437927246
Batch 46/64 loss: -2.492687225341797
Batch 47/64 loss: -2.1544933319091797
Batch 48/64 loss: -2.387784957885742
Batch 49/64 loss: -1.958251953125
Batch 50/64 loss: -2.353559970855713
Batch 51/64 loss: -2.2665958404541016
Batch 52/64 loss: -2.323263168334961
Batch 53/64 loss: -2.3618650436401367
Batch 54/64 loss: -1.9788541793823242
Batch 55/64 loss: -2.113888740539551
Batch 56/64 loss: -2.38308048248291
Batch 57/64 loss: -2.398098945617676
Batch 58/64 loss: -2.3231897354125977
Batch 59/64 loss: -1.920607566833496
Batch 60/64 loss: -2.061321258544922
Batch 61/64 loss: -2.1453237533569336
Batch 62/64 loss: -2.362567901611328
Batch 63/64 loss: -2.3501834869384766
Batch 64/64 loss: -6.376346588134766
Epoch 377  Train loss: -2.3107785393210016  Val loss: -2.642295181956078
Epoch 378
-------------------------------
Batch 1/64 loss: -2.1836137771606445
Batch 2/64 loss: -2.435610294342041
Batch 3/64 loss: -2.2546987533569336
Batch 4/64 loss: -2.2373123168945312
Batch 5/64 loss: -2.31980562210083
Batch 6/64 loss: -2.3419275283813477
Batch 7/64 loss: -2.3225841522216797
Batch 8/64 loss: -2.233962059020996
Batch 9/64 loss: -2.297687530517578
Batch 10/64 loss: -1.8369665145874023
Batch 11/64 loss: -2.0757551193237305
Batch 12/64 loss: -2.334671974182129
Batch 13/64 loss: -2.311169147491455
Batch 14/64 loss: -1.3300275802612305
Batch 15/64 loss: -2.36392879486084
Batch 16/64 loss: -2.3915328979492188
Batch 17/64 loss: -1.9919805526733398
Batch 18/64 loss: -2.2352781295776367
Batch 19/64 loss: -2.0904760360717773
Batch 20/64 loss: -2.2596912384033203
Batch 21/64 loss: -2.200956344604492
Batch 22/64 loss: -2.358603000640869
Batch 23/64 loss: -2.4004621505737305
Batch 24/64 loss: -2.464057445526123
Batch 25/64 loss: -2.432694911956787
Batch 26/64 loss: -2.3359060287475586
Batch 27/64 loss: -2.3429007530212402
Batch 28/64 loss: -2.25783634185791
Batch 29/64 loss: -2.153125762939453
Batch 30/64 loss: -2.269820213317871
Batch 31/64 loss: -2.4390792846679688
Batch 32/64 loss: -2.1497840881347656
Batch 33/64 loss: -2.347270965576172
Batch 34/64 loss: -2.407292366027832
Batch 35/64 loss: -2.331542491912842
Batch 36/64 loss: -2.2706751823425293
Batch 37/64 loss: -2.1740341186523438
Batch 38/64 loss: -2.302621841430664
Batch 39/64 loss: -2.3737411499023438
Batch 40/64 loss: -2.058091163635254
Batch 41/64 loss: -2.226827621459961
Batch 42/64 loss: -2.2477588653564453
Batch 43/64 loss: -2.297337532043457
Batch 44/64 loss: -2.4234619140625
Batch 45/64 loss: -1.7516660690307617
Batch 46/64 loss: -2.297244071960449
Batch 47/64 loss: -2.343782901763916
Batch 48/64 loss: -2.398776054382324
Batch 49/64 loss: -2.103074073791504
Batch 50/64 loss: -1.9912395477294922
Batch 51/64 loss: -2.313659191131592
Batch 52/64 loss: -2.288577079772949
Batch 53/64 loss: -2.396315574645996
Batch 54/64 loss: -2.271373748779297
Batch 55/64 loss: -2.3258724212646484
Batch 56/64 loss: -2.3676586151123047
Batch 57/64 loss: -1.8309059143066406
Batch 58/64 loss: -2.3785400390625
Batch 59/64 loss: -2.352973461151123
Batch 60/64 loss: -2.420966625213623
Batch 61/64 loss: -2.288078784942627
Batch 62/64 loss: -2.2439651489257812
Batch 63/64 loss: -2.379708766937256
Batch 64/64 loss: -5.911823272705078
Epoch 378  Train loss: -2.2947891310149546  Val loss: -2.4610136235292837
Epoch 379
-------------------------------
Batch 1/64 loss: -1.4883508682250977
Batch 2/64 loss: -2.459904193878174
Batch 3/64 loss: -2.2281274795532227
Batch 4/64 loss: -2.0867843627929688
Batch 5/64 loss: -2.2790842056274414
Batch 6/64 loss: -1.9988298416137695
Batch 7/64 loss: -2.034494400024414
Batch 8/64 loss: -1.4278497695922852
Batch 9/64 loss: -1.9519929885864258
Batch 10/64 loss: -0.4121437072753906
Batch 11/64 loss: -1.6270017623901367
Batch 12/64 loss: -1.1278400421142578
Batch 13/64 loss: -2.0055904388427734
Batch 14/64 loss: -2.036836624145508
Batch 15/64 loss: -2.048887252807617
Batch 16/64 loss: -1.2234573364257812
Batch 17/64 loss: -1.8923301696777344
Batch 18/64 loss: -2.131485939025879
Batch 19/64 loss: -1.618647575378418
Batch 20/64 loss: -2.184030532836914
Batch 21/64 loss: -1.2544469833374023
Batch 22/64 loss: -1.5006942749023438
Batch 23/64 loss: -1.7044553756713867
Batch 24/64 loss: -1.9729719161987305
Batch 25/64 loss: -1.602372169494629
Batch 26/64 loss: -1.967489242553711
Batch 27/64 loss: -1.8458175659179688
Batch 28/64 loss: -2.017483711242676
Batch 29/64 loss: -1.8460712432861328
Batch 30/64 loss: -1.7891550064086914
Batch 31/64 loss: -2.085993766784668
Batch 32/64 loss: -2.063662528991699
Batch 33/64 loss: -1.8679523468017578
Batch 34/64 loss: -1.6607999801635742
Batch 35/64 loss: -1.4165935516357422
Batch 36/64 loss: -2.1776962280273438
Batch 37/64 loss: -2.089670181274414
Batch 38/64 loss: -1.9159526824951172
Batch 39/64 loss: -1.953322410583496
Batch 40/64 loss: -1.6961069107055664
Batch 41/64 loss: -1.7648773193359375
Batch 42/64 loss: -2.136260986328125
Batch 43/64 loss: -2.09751033782959
Batch 44/64 loss: -2.0856542587280273
Batch 45/64 loss: -1.9595727920532227
Batch 46/64 loss: -1.6425466537475586
Batch 47/64 loss: -2.255596160888672
Batch 48/64 loss: -2.298701286315918
Batch 49/64 loss: -1.0870332717895508
Batch 50/64 loss: -2.008692741394043
Batch 51/64 loss: -1.8715848922729492
Batch 52/64 loss: -1.9953060150146484
Batch 53/64 loss: -2.0320281982421875
Batch 54/64 loss: -1.902303695678711
Batch 55/64 loss: -1.9352502822875977
Batch 56/64 loss: -1.2640304565429688
Batch 57/64 loss: -1.989180564880371
Batch 58/64 loss: -1.9468002319335938
Batch 59/64 loss: -2.0770606994628906
Batch 60/64 loss: -2.093092918395996
Batch 61/64 loss: -2.0399932861328125
Batch 62/64 loss: -1.9679555892944336
Batch 63/64 loss: -2.012505531311035
Batch 64/64 loss: -6.123391628265381
Epoch 379  Train loss: -1.9097797562094296  Val loss: -2.269277133482838
Epoch 380
-------------------------------
Batch 1/64 loss: -2.1089744567871094
Batch 2/64 loss: -1.9028539657592773
Batch 3/64 loss: -2.239900588989258
Batch 4/64 loss: -2.011979103088379
Batch 5/64 loss: -2.2624263763427734
Batch 6/64 loss: -2.258756637573242
Batch 7/64 loss: -2.0194311141967773
Batch 8/64 loss: -2.2093915939331055
Batch 9/64 loss: -1.9948091506958008
Batch 10/64 loss: -2.076409339904785
Batch 11/64 loss: -2.437830924987793
Batch 12/64 loss: -2.021498680114746
Batch 13/64 loss: -2.2379064559936523
Batch 14/64 loss: -1.7396211624145508
Batch 15/64 loss: -2.273135185241699
Batch 16/64 loss: -2.1420907974243164
Batch 17/64 loss: -1.7114067077636719
Batch 18/64 loss: -1.8690576553344727
Batch 19/64 loss: -2.1211538314819336
Batch 20/64 loss: -2.305521011352539
Batch 21/64 loss: -1.7981605529785156
Batch 22/64 loss: -2.1250152587890625
Batch 23/64 loss: -2.1721057891845703
Batch 24/64 loss: -1.1162939071655273
Batch 25/64 loss: -2.13348388671875
Batch 26/64 loss: -1.8359794616699219
Batch 27/64 loss: -2.1474571228027344
Batch 28/64 loss: -1.9884300231933594
Batch 29/64 loss: -2.2638731002807617
Batch 30/64 loss: -2.2601776123046875
Batch 31/64 loss: -2.28009033203125
Batch 32/64 loss: -1.938206672668457
Batch 33/64 loss: -1.913858413696289
Batch 34/64 loss: -2.053936004638672
Batch 35/64 loss: -2.144044876098633
Batch 36/64 loss: -2.1618452072143555
Batch 37/64 loss: -2.1565685272216797
Batch 38/64 loss: -2.0125999450683594
Batch 39/64 loss: -2.1687698364257812
Batch 40/64 loss: -2.026752471923828
Batch 41/64 loss: -2.173314094543457
Batch 42/64 loss: -1.4800825119018555
Batch 43/64 loss: -1.9992914199829102
Batch 44/64 loss: -2.059798240661621
Batch 45/64 loss: -2.145918846130371
Batch 46/64 loss: -2.2513427734375
Batch 47/64 loss: -2.104146957397461
Batch 48/64 loss: -2.1953697204589844
Batch 49/64 loss: -2.1364221572875977
Batch 50/64 loss: -1.6383323669433594
Batch 51/64 loss: -2.0303592681884766
Batch 52/64 loss: -2.2119054794311523
Batch 53/64 loss: -2.0888586044311523
Batch 54/64 loss: -1.8729591369628906
Batch 55/64 loss: -1.8015985488891602
Batch 56/64 loss: -1.804229736328125
Batch 57/64 loss: -1.6302433013916016
Batch 58/64 loss: -2.073894500732422
Batch 59/64 loss: -1.3065614700317383
Batch 60/64 loss: -2.158156394958496
Batch 61/64 loss: -2.2208290100097656
Batch 62/64 loss: -2.1300716400146484
Batch 63/64 loss: -1.8251419067382812
Batch 64/64 loss: -6.239730358123779
Epoch 380  Train loss: -2.080947915245505  Val loss: -2.272293025275686
Epoch 381
-------------------------------
Batch 1/64 loss: -1.6776313781738281
Batch 2/64 loss: -2.232119560241699
Batch 3/64 loss: -1.9684514999389648
Batch 4/64 loss: -2.2024354934692383
Batch 5/64 loss: -1.6916942596435547
Batch 6/64 loss: -2.090667724609375
Batch 7/64 loss: -1.760258674621582
Batch 8/64 loss: -1.1223583221435547
Batch 9/64 loss: -2.1020030975341797
Batch 10/64 loss: -2.0544023513793945
Batch 11/64 loss: -1.773331642150879
Batch 12/64 loss: -1.9020805358886719
Batch 13/64 loss: -2.145578384399414
Batch 14/64 loss: -2.0934505462646484
Batch 15/64 loss: -1.5962715148925781
Batch 16/64 loss: -1.970658302307129
Batch 17/64 loss: -2.0669050216674805
Batch 18/64 loss: -1.6185588836669922
Batch 19/64 loss: -2.0614166259765625
Batch 20/64 loss: -1.9770870208740234
Batch 21/64 loss: -2.060910224914551
Batch 22/64 loss: -2.2633790969848633
Batch 23/64 loss: -2.17545223236084
Batch 24/64 loss: -1.9783926010131836
Batch 25/64 loss: -2.016263961791992
Batch 26/64 loss: -1.514200210571289
Batch 27/64 loss: -2.2987518310546875
Batch 28/64 loss: -2.02683162689209
Batch 29/64 loss: -2.282832145690918
Batch 30/64 loss: -1.605452537536621
Batch 31/64 loss: -1.9658279418945312
Batch 32/64 loss: -2.061178207397461
Batch 33/64 loss: -2.0316123962402344
Batch 34/64 loss: -2.037731170654297
Batch 35/64 loss: -1.9775657653808594
Batch 36/64 loss: -2.156221389770508
Batch 37/64 loss: -1.8132638931274414
Batch 38/64 loss: -2.203828811645508
Batch 39/64 loss: -2.164483070373535
Batch 40/64 loss: -1.9935340881347656
Batch 41/64 loss: -2.13771915435791
Batch 42/64 loss: -1.6420001983642578
Batch 43/64 loss: -2.00203800201416
Batch 44/64 loss: -2.0766210556030273
Batch 45/64 loss: -2.1587400436401367
Batch 46/64 loss: -1.8965682983398438
Batch 47/64 loss: -2.092470169067383
Batch 48/64 loss: -2.1484718322753906
Batch 49/64 loss: -0.9669618606567383
Batch 50/64 loss: -1.7520828247070312
Batch 51/64 loss: -1.9744491577148438
Batch 52/64 loss: -2.219729423522949
Batch 53/64 loss: -1.929997444152832
Batch 54/64 loss: -1.8238554000854492
Batch 55/64 loss: -2.250713348388672
Batch 56/64 loss: -2.0116405487060547
Batch 57/64 loss: -1.993849754333496
Batch 58/64 loss: -2.3635964393615723
Batch 59/64 loss: -2.016901969909668
Batch 60/64 loss: -1.9880037307739258
Batch 61/64 loss: -2.246964454650879
Batch 62/64 loss: -2.1277170181274414
Batch 63/64 loss: -1.9528264999389648
Batch 64/64 loss: -6.549359321594238
Epoch 381  Train loss: -2.030133524128035  Val loss: -2.3364233560988175
Epoch 382
-------------------------------
Batch 1/64 loss: -2.264702796936035
Batch 2/64 loss: -2.229367256164551
Batch 3/64 loss: -1.586416244506836
Batch 4/64 loss: -2.2268171310424805
Batch 5/64 loss: -2.0426082611083984
Batch 6/64 loss: -2.1769466400146484
Batch 7/64 loss: -1.9934110641479492
Batch 8/64 loss: -1.7224740982055664
Batch 9/64 loss: -2.1454334259033203
Batch 10/64 loss: -2.072031021118164
Batch 11/64 loss: -1.6467704772949219
Batch 12/64 loss: -2.1101856231689453
Batch 13/64 loss: -1.8886938095092773
Batch 14/64 loss: -1.8386859893798828
Batch 15/64 loss: -1.687591552734375
Batch 16/64 loss: -2.00393009185791
Batch 17/64 loss: -2.101909637451172
Batch 18/64 loss: -2.035673141479492
Batch 19/64 loss: -2.0226593017578125
Batch 20/64 loss: -2.1985349655151367
Batch 21/64 loss: -2.2002248764038086
Batch 22/64 loss: -2.154996871948242
Batch 23/64 loss: -2.0294055938720703
Batch 24/64 loss: -2.0557899475097656
Batch 25/64 loss: -1.8621187210083008
Batch 26/64 loss: -1.8567676544189453
Batch 27/64 loss: -2.3435864448547363
Batch 28/64 loss: -2.2554492950439453
Batch 29/64 loss: -1.8832244873046875
Batch 30/64 loss: -2.108736991882324
Batch 31/64 loss: -2.169968605041504
Batch 32/64 loss: -2.234750747680664
Batch 33/64 loss: -2.153665542602539
Batch 34/64 loss: -2.141007423400879
Batch 35/64 loss: -1.475783348083496
Batch 36/64 loss: -1.519866943359375
Batch 37/64 loss: -2.0541677474975586
Batch 38/64 loss: -0.9913473129272461
Batch 39/64 loss: -2.210820198059082
Batch 40/64 loss: -1.8925142288208008
Batch 41/64 loss: -2.1537599563598633
Batch 42/64 loss: -2.0508689880371094
Batch 43/64 loss: -2.2773923873901367
Batch 44/64 loss: -1.840860366821289
Batch 45/64 loss: -2.020421028137207
Batch 46/64 loss: -2.057241439819336
Batch 47/64 loss: -2.1988210678100586
Batch 48/64 loss: -2.0241708755493164
Batch 49/64 loss: -1.9633264541625977
Batch 50/64 loss: -2.189746856689453
Batch 51/64 loss: -2.162750244140625
Batch 52/64 loss: -2.1280717849731445
Batch 53/64 loss: -2.199957847595215
Batch 54/64 loss: -1.9835243225097656
Batch 55/64 loss: -2.286190986633301
Batch 56/64 loss: -1.6621637344360352
Batch 57/64 loss: -2.0399999618530273
Batch 58/64 loss: -2.157547950744629
Batch 59/64 loss: -2.050889015197754
Batch 60/64 loss: -2.0032310485839844
Batch 61/64 loss: -2.1097822189331055
Batch 62/64 loss: -2.233717918395996
Batch 63/64 loss: -2.122873306274414
Batch 64/64 loss: -6.071095943450928
Epoch 382  Train loss: -2.071524191837685  Val loss: -2.266292978398169
Epoch 383
-------------------------------
Batch 1/64 loss: -1.7866430282592773
Batch 2/64 loss: -1.973710060119629
Batch 3/64 loss: -2.002068519592285
Batch 4/64 loss: -2.0261526107788086
Batch 5/64 loss: -2.140531539916992
Batch 6/64 loss: -2.3284454345703125
Batch 7/64 loss: -2.086361885070801
Batch 8/64 loss: -1.6124334335327148
Batch 9/64 loss: -2.226302146911621
Batch 10/64 loss: -1.8254060745239258
Batch 11/64 loss: -2.1067676544189453
Batch 12/64 loss: -1.5964889526367188
Batch 13/64 loss: -2.366880416870117
Batch 14/64 loss: -2.0543737411499023
Batch 15/64 loss: -2.1883716583251953
Batch 16/64 loss: -2.2365236282348633
Batch 17/64 loss: -2.103243827819824
Batch 18/64 loss: -1.9943275451660156
Batch 19/64 loss: -2.2415008544921875
Batch 20/64 loss: -2.168212890625
Batch 21/64 loss: -1.6364812850952148
Batch 22/64 loss: -1.7666559219360352
Batch 23/64 loss: -2.2138566970825195
Batch 24/64 loss: -2.085099220275879
Batch 25/64 loss: -2.111149787902832
Batch 26/64 loss: -2.27512264251709
Batch 27/64 loss: -2.335784912109375
Batch 28/64 loss: -2.0763416290283203
Batch 29/64 loss: -1.719376564025879
Batch 30/64 loss: -2.023695945739746
Batch 31/64 loss: -2.2312984466552734
Batch 32/64 loss: -2.2823338508605957
Batch 33/64 loss: -2.1426544189453125
Batch 34/64 loss: -2.175126075744629
Batch 35/64 loss: -2.0150909423828125
Batch 36/64 loss: -2.2211198806762695
Batch 37/64 loss: -2.049229621887207
Batch 38/64 loss: -2.0810728073120117
Batch 39/64 loss: -2.0227222442626953
Batch 40/64 loss: -2.1434335708618164
Batch 41/64 loss: -2.157693862915039
Batch 42/64 loss: -2.327981948852539
Batch 43/64 loss: -2.174544334411621
Batch 44/64 loss: -2.0828704833984375
Batch 45/64 loss: -2.1226673126220703
Batch 46/64 loss: -1.9888076782226562
Batch 47/64 loss: -2.1172962188720703
Batch 48/64 loss: -2.304410457611084
Batch 49/64 loss: -2.2742042541503906
Batch 50/64 loss: -2.013338088989258
Batch 51/64 loss: -1.572556495666504
Batch 52/64 loss: -1.884653091430664
Batch 53/64 loss: -2.0040407180786133
Batch 54/64 loss: -2.345086097717285
Batch 55/64 loss: -1.9097051620483398
Batch 56/64 loss: -2.0421037673950195
Batch 57/64 loss: -1.903432846069336
Batch 58/64 loss: -2.2289867401123047
Batch 59/64 loss: -2.2126617431640625
Batch 60/64 loss: -2.171811103820801
Batch 61/64 loss: -1.984480857849121
Batch 62/64 loss: -2.161076545715332
Batch 63/64 loss: -1.9914798736572266
Batch 64/64 loss: -6.2659406661987305
Epoch 383  Train loss: -2.123101765501733  Val loss: -2.486455386446923
Epoch 384
-------------------------------
Batch 1/64 loss: -2.186992645263672
Batch 2/64 loss: -1.927659034729004
Batch 3/64 loss: -2.1907567977905273
Batch 4/64 loss: -2.093250274658203
Batch 5/64 loss: -2.390503406524658
Batch 6/64 loss: -2.1755218505859375
Batch 7/64 loss: -2.2426700592041016
Batch 8/64 loss: -2.149369239807129
Batch 9/64 loss: -1.9709053039550781
Batch 10/64 loss: -1.432063102722168
Batch 11/64 loss: -2.2224349975585938
Batch 12/64 loss: -2.08304500579834
Batch 13/64 loss: -2.3252487182617188
Batch 14/64 loss: -2.1010732650756836
Batch 15/64 loss: -2.1914844512939453
Batch 16/64 loss: -2.243650436401367
Batch 17/64 loss: -1.7239151000976562
Batch 18/64 loss: -2.0031652450561523
Batch 19/64 loss: -2.1220054626464844
Batch 20/64 loss: -2.200662612915039
Batch 21/64 loss: -2.207282066345215
Batch 22/64 loss: -1.9828433990478516
Batch 23/64 loss: -2.134408950805664
Batch 24/64 loss: -1.9533042907714844
Batch 25/64 loss: -1.9676332473754883
Batch 26/64 loss: -2.0589065551757812
Batch 27/64 loss: -2.3807363510131836
Batch 28/64 loss: -2.2441978454589844
Batch 29/64 loss: -2.164541244506836
Batch 30/64 loss: -2.198068618774414
Batch 31/64 loss: -2.285252571105957
Batch 32/64 loss: -2.017810821533203
Batch 33/64 loss: -2.090512275695801
Batch 34/64 loss: -2.159679412841797
Batch 35/64 loss: -1.959686279296875
Batch 36/64 loss: -2.3828558921813965
Batch 37/64 loss: -2.1389007568359375
Batch 38/64 loss: -2.1627883911132812
Batch 39/64 loss: -2.212773323059082
Batch 40/64 loss: -2.053478240966797
Batch 41/64 loss: -2.0302038192749023
Batch 42/64 loss: -2.2942910194396973
Batch 43/64 loss: -2.172403335571289
Batch 44/64 loss: -2.0728111267089844
Batch 45/64 loss: -1.731210708618164
Batch 46/64 loss: -2.246588706970215
Batch 47/64 loss: -1.8558073043823242
Batch 48/64 loss: -1.845388412475586
Batch 49/64 loss: -1.8149642944335938
Batch 50/64 loss: -2.3931102752685547
Batch 51/64 loss: -2.1845579147338867
Batch 52/64 loss: -2.301729202270508
Batch 53/64 loss: -2.1328468322753906
Batch 54/64 loss: -2.1754417419433594
Batch 55/64 loss: -2.1355905532836914
Batch 56/64 loss: -2.088991165161133
Batch 57/64 loss: -1.9720830917358398
Batch 58/64 loss: -2.2180938720703125
Batch 59/64 loss: -2.3118057250976562
Batch 60/64 loss: -2.312875747680664
Batch 61/64 loss: -2.391477108001709
Batch 62/64 loss: -2.116269111633301
Batch 63/64 loss: -2.389535903930664
Batch 64/64 loss: -6.376096725463867
Epoch 384  Train loss: -2.1757205813538794  Val loss: -2.522337897127027
Epoch 385
-------------------------------
Batch 1/64 loss: -2.1348495483398438
Batch 2/64 loss: -1.2955589294433594
Batch 3/64 loss: -2.249131202697754
Batch 4/64 loss: -2.2025585174560547
Batch 5/64 loss: -2.406848907470703
Batch 6/64 loss: -1.740736961364746
Batch 7/64 loss: -2.0768566131591797
Batch 8/64 loss: -2.0120954513549805
Batch 9/64 loss: -1.9848060607910156
Batch 10/64 loss: -1.6633224487304688
Batch 11/64 loss: -2.33284330368042
Batch 12/64 loss: -2.0273571014404297
Batch 13/64 loss: -2.220362663269043
Batch 14/64 loss: -2.041611671447754
Batch 15/64 loss: -1.4341363906860352
Batch 16/64 loss: -2.1932058334350586
Batch 17/64 loss: -2.138249397277832
Batch 18/64 loss: -2.131434440612793
Batch 19/64 loss: -2.0531463623046875
Batch 20/64 loss: -2.02606201171875
Batch 21/64 loss: -2.2283363342285156
Batch 22/64 loss: -2.2405967712402344
Batch 23/64 loss: -2.302114486694336
Batch 24/64 loss: -2.091615676879883
Batch 25/64 loss: -2.049208641052246
Batch 26/64 loss: -2.0744972229003906
Batch 27/64 loss: -2.267025947570801
Batch 28/64 loss: -1.9257125854492188
Batch 29/64 loss: -2.293288230895996
Batch 30/64 loss: -2.2178688049316406
Batch 31/64 loss: -1.9352664947509766
Batch 32/64 loss: -2.2919912338256836
Batch 33/64 loss: -1.9768390655517578
Batch 34/64 loss: -1.9342260360717773
Batch 35/64 loss: -2.4234299659729004
Batch 36/64 loss: -2.0772457122802734
Batch 37/64 loss: -2.3008852005004883
Batch 38/64 loss: -2.31319522857666
Batch 39/64 loss: -2.221217155456543
Batch 40/64 loss: -2.323197364807129
Batch 41/64 loss: -2.1821727752685547
Batch 42/64 loss: -2.102254867553711
Batch 43/64 loss: -2.305882453918457
Batch 44/64 loss: -1.9039373397827148
Batch 45/64 loss: -2.0866355895996094
Batch 46/64 loss: -2.373112678527832
Batch 47/64 loss: -1.621088981628418
Batch 48/64 loss: -1.9844303131103516
Batch 49/64 loss: -2.0207748413085938
Batch 50/64 loss: -2.275421142578125
Batch 51/64 loss: -2.3835248947143555
Batch 52/64 loss: -2.1575241088867188
Batch 53/64 loss: -2.242839813232422
Batch 54/64 loss: -2.349222183227539
Batch 55/64 loss: -2.2075366973876953
Batch 56/64 loss: -2.1436538696289062
Batch 57/64 loss: -2.2084455490112305
Batch 58/64 loss: -2.2810487747192383
Batch 59/64 loss: -2.182295799255371
Batch 60/64 loss: -2.203587532043457
Batch 61/64 loss: -2.2531967163085938
Batch 62/64 loss: -2.235086441040039
Batch 63/64 loss: -2.0779953002929688
Batch 64/64 loss: -6.479454040527344
Epoch 385  Train loss: -2.172457900701785  Val loss: -2.5522304941288794
Epoch 386
-------------------------------
Batch 1/64 loss: -2.1421127319335938
Batch 2/64 loss: -1.9740610122680664
Batch 3/64 loss: -2.350487232208252
Batch 4/64 loss: -1.8196401596069336
Batch 5/64 loss: -2.166717529296875
Batch 6/64 loss: -2.3120126724243164
Batch 7/64 loss: -2.0127315521240234
Batch 8/64 loss: -2.2194366455078125
Batch 9/64 loss: -2.166775703430176
Batch 10/64 loss: -1.5550460815429688
Batch 11/64 loss: -2.2016191482543945
Batch 12/64 loss: -2.1388111114501953
Batch 13/64 loss: -2.2082958221435547
Batch 14/64 loss: -1.8918142318725586
Batch 15/64 loss: -2.148362159729004
Batch 16/64 loss: -2.2658424377441406
Batch 17/64 loss: -2.241103172302246
Batch 18/64 loss: -2.2358789443969727
Batch 19/64 loss: -2.2704429626464844
Batch 20/64 loss: -2.259214401245117
Batch 21/64 loss: -2.0786142349243164
Batch 22/64 loss: -2.1127147674560547
Batch 23/64 loss: -2.108687400817871
Batch 24/64 loss: -2.250411033630371
Batch 25/64 loss: -2.188047409057617
Batch 26/64 loss: -2.0829896926879883
Batch 27/64 loss: -2.2099599838256836
Batch 28/64 loss: -1.3479032516479492
Batch 29/64 loss: -2.1645631790161133
Batch 30/64 loss: -2.348130226135254
Batch 31/64 loss: -2.094400405883789
Batch 32/64 loss: -2.1561803817749023
Batch 33/64 loss: -2.1247262954711914
Batch 34/64 loss: -2.154031753540039
Batch 35/64 loss: -1.6317358016967773
Batch 36/64 loss: -2.01455020904541
Batch 37/64 loss: -1.618494987487793
Batch 38/64 loss: -2.3394570350646973
Batch 39/64 loss: -1.908930778503418
Batch 40/64 loss: -2.2421398162841797
Batch 41/64 loss: -2.325105667114258
Batch 42/64 loss: -1.619257926940918
Batch 43/64 loss: -2.208735466003418
Batch 44/64 loss: -2.0417919158935547
Batch 45/64 loss: -1.9975547790527344
Batch 46/64 loss: -2.311253070831299
Batch 47/64 loss: -2.004611015319824
Batch 48/64 loss: -1.8400964736938477
Batch 49/64 loss: -2.1681365966796875
Batch 50/64 loss: -2.1266860961914062
Batch 51/64 loss: -2.4704174995422363
Batch 52/64 loss: -2.1443214416503906
Batch 53/64 loss: -1.7822227478027344
Batch 54/64 loss: -1.6281099319458008
Batch 55/64 loss: -2.1390275955200195
Batch 56/64 loss: -2.329803466796875
Batch 57/64 loss: -1.8616886138916016
Batch 58/64 loss: -1.9997339248657227
Batch 59/64 loss: -2.045598030090332
Batch 60/64 loss: -2.208585739135742
Batch 61/64 loss: -1.9883155822753906
Batch 62/64 loss: -2.1764183044433594
Batch 63/64 loss: -1.7393808364868164
Batch 64/64 loss: -6.448173999786377
Epoch 386  Train loss: -2.1294126678915584  Val loss: -2.3547303635639834
Epoch 387
-------------------------------
Batch 1/64 loss: -2.083950996398926
Batch 2/64 loss: -2.192476272583008
Batch 3/64 loss: -2.1165552139282227
Batch 4/64 loss: -2.2767791748046875
Batch 5/64 loss: -2.1610116958618164
Batch 6/64 loss: -2.0810117721557617
Batch 7/64 loss: -1.7625951766967773
Batch 8/64 loss: -2.0850486755371094
Batch 9/64 loss: -1.9214391708374023
Batch 10/64 loss: -1.7623329162597656
Batch 11/64 loss: -1.2054824829101562
Batch 12/64 loss: -2.0152339935302734
Batch 13/64 loss: -2.2358951568603516
Batch 14/64 loss: -2.052016258239746
Batch 15/64 loss: -2.126619338989258
Batch 16/64 loss: -2.207522392272949
Batch 17/64 loss: -2.0772714614868164
Batch 18/64 loss: -2.070755958557129
Batch 19/64 loss: -1.2247657775878906
Batch 20/64 loss: -2.2039995193481445
Batch 21/64 loss: -2.1677427291870117
Batch 22/64 loss: -2.2882680892944336
Batch 23/64 loss: -2.1619443893432617
Batch 24/64 loss: -1.9957590103149414
Batch 25/64 loss: -1.508169174194336
Batch 26/64 loss: -1.9700508117675781
Batch 27/64 loss: -1.8766632080078125
Batch 28/64 loss: -1.9132623672485352
Batch 29/64 loss: -1.8679141998291016
Batch 30/64 loss: -2.079833984375
Batch 31/64 loss: -2.1784629821777344
Batch 32/64 loss: -1.5213184356689453
Batch 33/64 loss: -1.8940000534057617
Batch 34/64 loss: -2.225851058959961
Batch 35/64 loss: -2.1035022735595703
Batch 36/64 loss: -2.231109619140625
Batch 37/64 loss: -1.987980842590332
Batch 38/64 loss: -2.1319332122802734
Batch 39/64 loss: -2.2429981231689453
Batch 40/64 loss: -2.135589599609375
Batch 41/64 loss: -2.1588830947875977
Batch 42/64 loss: -2.060861587524414
Batch 43/64 loss: -1.7630701065063477
Batch 44/64 loss: -2.1040430068969727
Batch 45/64 loss: -2.229673385620117
Batch 46/64 loss: -2.2123422622680664
Batch 47/64 loss: -2.139105796813965
Batch 48/64 loss: -1.8742408752441406
Batch 49/64 loss: -2.374960422515869
Batch 50/64 loss: -2.056020736694336
Batch 51/64 loss: -2.0577821731567383
Batch 52/64 loss: -2.1042661666870117
Batch 53/64 loss: -2.2385377883911133
Batch 54/64 loss: -2.3080673217773438
Batch 55/64 loss: -2.116002082824707
Batch 56/64 loss: -1.8494110107421875
Batch 57/64 loss: -2.142303466796875
Batch 58/64 loss: -2.0991554260253906
Batch 59/64 loss: -1.5468320846557617
Batch 60/64 loss: -2.2204666137695312
Batch 61/64 loss: -2.0168819427490234
Batch 62/64 loss: -2.145296096801758
Batch 63/64 loss: -2.2943496704101562
Batch 64/64 loss: -6.312654495239258
Epoch 387  Train loss: -2.089288808785233  Val loss: -2.3406641983084664
Epoch 388
-------------------------------
Batch 1/64 loss: -1.9318904876708984
Batch 2/64 loss: -2.19711971282959
Batch 3/64 loss: -2.2297983169555664
Batch 4/64 loss: -2.3297085762023926
Batch 5/64 loss: -1.987166404724121
Batch 6/64 loss: -2.008143424987793
Batch 7/64 loss: -2.1457319259643555
Batch 8/64 loss: -1.9797935485839844
Batch 9/64 loss: -2.3313393592834473
Batch 10/64 loss: -2.2662649154663086
Batch 11/64 loss: -2.0878524780273438
Batch 12/64 loss: -2.2431821823120117
Batch 13/64 loss: -1.8460273742675781
Batch 14/64 loss: -2.0614166259765625
Batch 15/64 loss: -1.7651052474975586
Batch 16/64 loss: -2.1756591796875
Batch 17/64 loss: -1.527827262878418
Batch 18/64 loss: -2.0406007766723633
Batch 19/64 loss: -2.1870365142822266
Batch 20/64 loss: -2.201292037963867
Batch 21/64 loss: -2.0421180725097656
Batch 22/64 loss: -1.904794692993164
Batch 23/64 loss: -1.8362102508544922
Batch 24/64 loss: -2.3555092811584473
Batch 25/64 loss: -2.1455392837524414
Batch 26/64 loss: -1.9138307571411133
Batch 27/64 loss: -2.156252861022949
Batch 28/64 loss: -1.6306352615356445
Batch 29/64 loss: -1.227839469909668
Batch 30/64 loss: -2.290689468383789
Batch 31/64 loss: -2.1092004776000977
Batch 32/64 loss: -1.9899206161499023
Batch 33/64 loss: -2.130803108215332
Batch 34/64 loss: -2.080160140991211
Batch 35/64 loss: -1.8264942169189453
Batch 36/64 loss: -2.089869499206543
Batch 37/64 loss: -2.2503299713134766
Batch 38/64 loss: -2.2812204360961914
Batch 39/64 loss: -2.016071319580078
Batch 40/64 loss: -2.1911516189575195
Batch 41/64 loss: -2.166719436645508
Batch 42/64 loss: -1.863229751586914
Batch 43/64 loss: -2.073657989501953
Batch 44/64 loss: -2.1387739181518555
Batch 45/64 loss: -2.1379737854003906
Batch 46/64 loss: -1.8753414154052734
Batch 47/64 loss: -1.653355598449707
Batch 48/64 loss: -2.2392425537109375
Batch 49/64 loss: -2.076615333557129
Batch 50/64 loss: -2.161813735961914
Batch 51/64 loss: -2.2322521209716797
Batch 52/64 loss: -2.3116769790649414
Batch 53/64 loss: -2.3576784133911133
Batch 54/64 loss: -2.0456533432006836
Batch 55/64 loss: -2.3119964599609375
Batch 56/64 loss: -1.9929485321044922
Batch 57/64 loss: -1.9785795211791992
Batch 58/64 loss: -2.065524101257324
Batch 59/64 loss: -2.07358455657959
Batch 60/64 loss: -2.128148078918457
Batch 61/64 loss: -2.049628257751465
Batch 62/64 loss: -2.2471370697021484
Batch 63/64 loss: -1.9465513229370117
Batch 64/64 loss: -6.406441688537598
Epoch 388  Train loss: -2.1167766384049957  Val loss: -2.477649636285002
Epoch 389
-------------------------------
Batch 1/64 loss: -2.1421499252319336
Batch 2/64 loss: -2.150832176208496
Batch 3/64 loss: -1.9108142852783203
Batch 4/64 loss: -2.247987747192383
Batch 5/64 loss: -2.2155494689941406
Batch 6/64 loss: -2.015688896179199
Batch 7/64 loss: -2.101715087890625
Batch 8/64 loss: -1.8580780029296875
Batch 9/64 loss: -2.1215171813964844
Batch 10/64 loss: -2.0825204849243164
Batch 11/64 loss: -1.8462419509887695
Batch 12/64 loss: -2.12381649017334
Batch 13/64 loss: -1.5991525650024414
Batch 14/64 loss: -2.032979965209961
Batch 15/64 loss: -2.2644176483154297
Batch 16/64 loss: -2.227095603942871
Batch 17/64 loss: -1.9987030029296875
Batch 18/64 loss: -2.071796417236328
Batch 19/64 loss: -2.1238269805908203
Batch 20/64 loss: -2.282547950744629
Batch 21/64 loss: -1.6412696838378906
Batch 22/64 loss: -2.153799057006836
Batch 23/64 loss: -2.1075057983398438
Batch 24/64 loss: -2.2469043731689453
Batch 25/64 loss: -2.1835508346557617
Batch 26/64 loss: -2.058098793029785
Batch 27/64 loss: -1.6144990921020508
Batch 28/64 loss: -1.9589271545410156
Batch 29/64 loss: -1.9901037216186523
Batch 30/64 loss: -2.0926523208618164
Batch 31/64 loss: -2.277738094329834
Batch 32/64 loss: -2.0508041381835938
Batch 33/64 loss: -2.2170095443725586
Batch 34/64 loss: -1.8556928634643555
Batch 35/64 loss: -1.9503669738769531
Batch 36/64 loss: -2.1090641021728516
Batch 37/64 loss: -2.1816253662109375
Batch 38/64 loss: -2.2206010818481445
Batch 39/64 loss: -2.0700149536132812
Batch 40/64 loss: -2.3192954063415527
Batch 41/64 loss: -2.1074695587158203
Batch 42/64 loss: -2.357844352722168
Batch 43/64 loss: -2.108370780944824
Batch 44/64 loss: -2.0432891845703125
Batch 45/64 loss: -1.5248136520385742
Batch 46/64 loss: -2.1231651306152344
Batch 47/64 loss: -2.156296730041504
Batch 48/64 loss: -2.3518457412719727
Batch 49/64 loss: -2.055792808532715
Batch 50/64 loss: -2.151765823364258
Batch 51/64 loss: -2.1432743072509766
Batch 52/64 loss: -2.112025260925293
Batch 53/64 loss: -1.9869365692138672
Batch 54/64 loss: -2.056163787841797
Batch 55/64 loss: -1.5472803115844727
Batch 56/64 loss: -1.6905603408813477
Batch 57/64 loss: -2.162273406982422
Batch 58/64 loss: -2.3494410514831543
Batch 59/64 loss: -2.0398807525634766
Batch 60/64 loss: -2.0948667526245117
Batch 61/64 loss: -2.03314208984375
Batch 62/64 loss: -2.2068166732788086
Batch 63/64 loss: -2.065887451171875
Batch 64/64 loss: -6.433191299438477
Epoch 389  Train loss: -2.117820410634957  Val loss: -2.4128116070200076
Epoch 390
-------------------------------
Batch 1/64 loss: -1.9980316162109375
Batch 2/64 loss: -2.12747859954834
Batch 3/64 loss: -2.1031932830810547
Batch 4/64 loss: -2.042323112487793
Batch 5/64 loss: -2.260883331298828
Batch 6/64 loss: -1.9406061172485352
Batch 7/64 loss: -2.1833009719848633
Batch 8/64 loss: -1.6678686141967773
Batch 9/64 loss: -2.2666869163513184
Batch 10/64 loss: -1.809718132019043
Batch 11/64 loss: -2.2008161544799805
Batch 12/64 loss: -2.2031736373901367
Batch 13/64 loss: -2.1650819778442383
Batch 14/64 loss: -2.3175697326660156
Batch 15/64 loss: -2.139176368713379
Batch 16/64 loss: -2.093600273132324
Batch 17/64 loss: -2.146047592163086
Batch 18/64 loss: -2.2484989166259766
Batch 19/64 loss: -2.12168025970459
Batch 20/64 loss: -2.082146644592285
Batch 21/64 loss: -1.1077604293823242
Batch 22/64 loss: -1.8950996398925781
Batch 23/64 loss: -2.0633907318115234
Batch 24/64 loss: -1.8359947204589844
Batch 25/64 loss: -2.356977939605713
Batch 26/64 loss: -2.225691795349121
Batch 27/64 loss: -2.3080244064331055
Batch 28/64 loss: -2.11104679107666
Batch 29/64 loss: -2.0588293075561523
Batch 30/64 loss: -1.0614547729492188
Batch 31/64 loss: -2.2028894424438477
Batch 32/64 loss: -2.0676231384277344
Batch 33/64 loss: -2.198904037475586
Batch 34/64 loss: -1.8300724029541016
Batch 35/64 loss: -1.7747516632080078
Batch 36/64 loss: -2.1228160858154297
Batch 37/64 loss: -2.1114606857299805
Batch 38/64 loss: -1.5358810424804688
Batch 39/64 loss: -2.315573215484619
Batch 40/64 loss: -2.188267707824707
Batch 41/64 loss: -2.29818058013916
Batch 42/64 loss: -1.8602981567382812
Batch 43/64 loss: -1.408381462097168
Batch 44/64 loss: -2.305694103240967
Batch 45/64 loss: -1.9967069625854492
Batch 46/64 loss: -2.414215087890625
Batch 47/64 loss: -2.262091636657715
Batch 48/64 loss: -2.2664785385131836
Batch 49/64 loss: -2.025716781616211
Batch 50/64 loss: -2.2833242416381836
Batch 51/64 loss: -2.050609588623047
Batch 52/64 loss: -1.6999616622924805
Batch 53/64 loss: -2.2938971519470215
Batch 54/64 loss: -2.179692268371582
Batch 55/64 loss: -2.220335006713867
Batch 56/64 loss: -1.7850704193115234
Batch 57/64 loss: -2.140199661254883
Batch 58/64 loss: -2.0811100006103516
Batch 59/64 loss: -2.423346996307373
Batch 60/64 loss: -2.1960792541503906
Batch 61/64 loss: -1.766362190246582
Batch 62/64 loss: -2.148623466491699
Batch 63/64 loss: -1.8198089599609375
Batch 64/64 loss: -6.176403045654297
Epoch 390  Train loss: -2.102727508544922  Val loss: -2.426652587156525
Epoch 391
-------------------------------
Batch 1/64 loss: -2.1992712020874023
Batch 2/64 loss: -2.407984733581543
Batch 3/64 loss: -2.267207145690918
Batch 4/64 loss: -2.1582717895507812
Batch 5/64 loss: -2.231564521789551
Batch 6/64 loss: -2.238565444946289
Batch 7/64 loss: -2.3644185066223145
Batch 8/64 loss: -2.1983299255371094
Batch 9/64 loss: -1.5250482559204102
Batch 10/64 loss: -2.0450477600097656
Batch 11/64 loss: -1.2516260147094727
Batch 12/64 loss: -2.2478132247924805
Batch 13/64 loss: -1.6829156875610352
Batch 14/64 loss: -2.363891124725342
Batch 15/64 loss: -2.325881004333496
Batch 16/64 loss: -2.336578369140625
Batch 17/64 loss: -2.2204904556274414
Batch 18/64 loss: -2.2222976684570312
Batch 19/64 loss: -2.3099966049194336
Batch 20/64 loss: -2.2170228958129883
Batch 21/64 loss: -2.077681541442871
Batch 22/64 loss: -2.1761417388916016
Batch 23/64 loss: -2.2525949478149414
Batch 24/64 loss: -2.2980737686157227
Batch 25/64 loss: -2.139026641845703
Batch 26/64 loss: -2.1300792694091797
Batch 27/64 loss: -2.1071014404296875
Batch 28/64 loss: -1.6828727722167969
Batch 29/64 loss: -2.145120620727539
Batch 30/64 loss: -2.2912702560424805
Batch 31/64 loss: -2.159738540649414
Batch 32/64 loss: -1.9928627014160156
Batch 33/64 loss: -2.2531356811523438
Batch 34/64 loss: -2.2394371032714844
Batch 35/64 loss: -2.208742141723633
Batch 36/64 loss: -2.2387619018554688
Batch 37/64 loss: -2.237921714782715
Batch 38/64 loss: -2.3193063735961914
Batch 39/64 loss: -2.089893341064453
Batch 40/64 loss: -2.4348645210266113
Batch 41/64 loss: -2.186878204345703
Batch 42/64 loss: -2.2339887619018555
Batch 43/64 loss: -2.0823593139648438
Batch 44/64 loss: -2.3731985092163086
Batch 45/64 loss: -2.476132392883301
Batch 46/64 loss: -2.0085601806640625
Batch 47/64 loss: -2.255002975463867
Batch 48/64 loss: -2.3123035430908203
Batch 49/64 loss: -2.302262306213379
Batch 50/64 loss: -2.145893096923828
Batch 51/64 loss: -2.36041259765625
Batch 52/64 loss: -2.189420700073242
Batch 53/64 loss: -2.0380640029907227
Batch 54/64 loss: -2.309762954711914
Batch 55/64 loss: -2.2407054901123047
Batch 56/64 loss: -2.175130844116211
Batch 57/64 loss: -2.311458110809326
Batch 58/64 loss: -2.325399875640869
Batch 59/64 loss: -2.3605690002441406
Batch 60/64 loss: -2.1451616287231445
Batch 61/64 loss: -2.1710596084594727
Batch 62/64 loss: -2.3095340728759766
Batch 63/64 loss: -2.097731590270996
Batch 64/64 loss: -6.168957710266113
Epoch 391  Train loss: -2.23257344937792  Val loss: -2.471936622436104
Epoch 392
-------------------------------
Batch 1/64 loss: -2.0293664932250977
Batch 2/64 loss: -2.1283702850341797
Batch 3/64 loss: -1.401087760925293
Batch 4/64 loss: -1.3569555282592773
Batch 5/64 loss: -2.213912010192871
Batch 6/64 loss: -2.1009531021118164
Batch 7/64 loss: -2.249910354614258
Batch 8/64 loss: -1.905996322631836
Batch 9/64 loss: -2.208540916442871
Batch 10/64 loss: -1.9161138534545898
Batch 11/64 loss: -1.871912956237793
Batch 12/64 loss: -2.263850212097168
Batch 13/64 loss: -2.2494325637817383
Batch 14/64 loss: -2.2233333587646484
Batch 15/64 loss: -2.0835132598876953
Batch 16/64 loss: -2.2958765029907227
Batch 17/64 loss: -2.26318359375
Batch 18/64 loss: -2.08499813079834
Batch 19/64 loss: -1.997243881225586
Batch 20/64 loss: -1.9956111907958984
Batch 21/64 loss: -1.6659765243530273
Batch 22/64 loss: -2.1841869354248047
Batch 23/64 loss: -2.1189136505126953
Batch 24/64 loss: -1.951420783996582
Batch 25/64 loss: -2.2594985961914062
Batch 26/64 loss: -2.1885786056518555
Batch 27/64 loss: -2.2120771408081055
Batch 28/64 loss: -2.135587692260742
Batch 29/64 loss: -1.9972658157348633
Batch 30/64 loss: -2.1963510513305664
Batch 31/64 loss: -1.8031330108642578
Batch 32/64 loss: -2.2420778274536133
Batch 33/64 loss: -2.04312801361084
Batch 34/64 loss: -2.0111913681030273
Batch 35/64 loss: -2.048142433166504
Batch 36/64 loss: -1.8476190567016602
Batch 37/64 loss: -1.9700403213500977
Batch 38/64 loss: -2.203913688659668
Batch 39/64 loss: -2.0724010467529297
Batch 40/64 loss: -2.329190731048584
Batch 41/64 loss: -2.2975330352783203
Batch 42/64 loss: -2.1073198318481445
Batch 43/64 loss: -1.2721519470214844
Batch 44/64 loss: -2.1879682540893555
Batch 45/64 loss: -2.254383087158203
Batch 46/64 loss: -2.124588966369629
Batch 47/64 loss: -2.2589783668518066
Batch 48/64 loss: -1.9561233520507812
Batch 49/64 loss: -2.1550064086914062
Batch 50/64 loss: -2.100857734680176
Batch 51/64 loss: -1.746556282043457
Batch 52/64 loss: -2.29457950592041
Batch 53/64 loss: -2.2974929809570312
Batch 54/64 loss: -2.282674789428711
Batch 55/64 loss: -2.262683868408203
Batch 56/64 loss: -2.3129677772521973
Batch 57/64 loss: -2.1482810974121094
Batch 58/64 loss: -2.4748001098632812
Batch 59/64 loss: -2.4727673530578613
Batch 60/64 loss: -2.258474349975586
Batch 61/64 loss: -2.29510498046875
Batch 62/64 loss: -2.4261417388916016
Batch 63/64 loss: -1.5431432723999023
Batch 64/64 loss: -6.505633354187012
Epoch 392  Train loss: -2.1447946772855873  Val loss: -2.5429129715228
Epoch 393
-------------------------------
Batch 1/64 loss: -2.1618852615356445
Batch 2/64 loss: -2.3885746002197266
Batch 3/64 loss: -2.3650617599487305
Batch 4/64 loss: -2.232895851135254
Batch 5/64 loss: -2.109617233276367
Batch 6/64 loss: -1.941676139831543
Batch 7/64 loss: -2.3244290351867676
Batch 8/64 loss: -2.267697334289551
Batch 9/64 loss: -2.1095752716064453
Batch 10/64 loss: -2.2617883682250977
Batch 11/64 loss: -2.3151779174804688
Batch 12/64 loss: -2.2875466346740723
Batch 13/64 loss: -2.232675552368164
Batch 14/64 loss: -2.123196601867676
Batch 15/64 loss: -2.284090042114258
Batch 16/64 loss: -2.3632493019104004
Batch 17/64 loss: -2.1821231842041016
Batch 18/64 loss: -2.140735626220703
Batch 19/64 loss: -2.481226921081543
Batch 20/64 loss: -2.3191237449645996
Batch 21/64 loss: -1.847987174987793
Batch 22/64 loss: -2.434610366821289
Batch 23/64 loss: -2.2102136611938477
Batch 24/64 loss: -1.886916160583496
Batch 25/64 loss: -2.0646610260009766
Batch 26/64 loss: -2.391326904296875
Batch 27/64 loss: -1.8646478652954102
Batch 28/64 loss: -2.3486227989196777
Batch 29/64 loss: -2.172830581665039
Batch 30/64 loss: -2.029940605163574
Batch 31/64 loss: -1.481217384338379
Batch 32/64 loss: -2.199188232421875
Batch 33/64 loss: -1.9553241729736328
Batch 34/64 loss: -1.8939847946166992
Batch 35/64 loss: -2.3113460540771484
Batch 36/64 loss: -2.274557113647461
Batch 37/64 loss: -1.9115228652954102
Batch 38/64 loss: -2.2784814834594727
Batch 39/64 loss: -2.090250015258789
Batch 40/64 loss: -2.2673959732055664
Batch 41/64 loss: -2.341493606567383
Batch 42/64 loss: -2.1089296340942383
Batch 43/64 loss: -2.2250185012817383
Batch 44/64 loss: -2.319014072418213
Batch 45/64 loss: -2.159280776977539
Batch 46/64 loss: -2.1009645462036133
Batch 47/64 loss: -2.079906463623047
Batch 48/64 loss: -2.1056766510009766
Batch 49/64 loss: -2.181407928466797
Batch 50/64 loss: -2.338332176208496
Batch 51/64 loss: -2.325169563293457
Batch 52/64 loss: -2.253398895263672
Batch 53/64 loss: -1.9531221389770508
Batch 54/64 loss: -1.7573366165161133
Batch 55/64 loss: -2.2256698608398438
Batch 56/64 loss: -1.6531658172607422
Batch 57/64 loss: -1.9664306640625
Batch 58/64 loss: -1.734431266784668
Batch 59/64 loss: -2.2867650985717773
Batch 60/64 loss: -2.014474868774414
Batch 61/64 loss: -1.6221485137939453
Batch 62/64 loss: -2.0142555236816406
Batch 63/64 loss: -2.3023719787597656
Batch 64/64 loss: -6.070900917053223
Epoch 393  Train loss: -2.187126470079609  Val loss: -2.3697624861989235
Epoch 394
-------------------------------
Batch 1/64 loss: -2.2587661743164062
Batch 2/64 loss: -2.1217870712280273
Batch 3/64 loss: -2.2745656967163086
Batch 4/64 loss: -1.9698972702026367
Batch 5/64 loss: -1.2438268661499023
Batch 6/64 loss: -2.313234329223633
Batch 7/64 loss: -2.171799659729004
Batch 8/64 loss: -2.064332962036133
Batch 9/64 loss: -2.1310901641845703
Batch 10/64 loss: -2.020796775817871
Batch 11/64 loss: -2.3070755004882812
Batch 12/64 loss: -2.177578926086426
Batch 13/64 loss: -2.1306581497192383
Batch 14/64 loss: -2.3093814849853516
Batch 15/64 loss: -1.84478759765625
Batch 16/64 loss: -2.197737693786621
Batch 17/64 loss: -2.077359199523926
Batch 18/64 loss: -2.3469629287719727
Batch 19/64 loss: -2.218754768371582
Batch 20/64 loss: -2.104975700378418
Batch 21/64 loss: -2.1681299209594727
Batch 22/64 loss: -1.9646291732788086
Batch 23/64 loss: -2.137345314025879
Batch 24/64 loss: -2.3049278259277344
Batch 25/64 loss: -2.123289108276367
Batch 26/64 loss: -1.9963102340698242
Batch 27/64 loss: -1.9216842651367188
Batch 28/64 loss: -1.752528190612793
Batch 29/64 loss: -2.315983772277832
Batch 30/64 loss: -2.2387895584106445
Batch 31/64 loss: -2.217958450317383
Batch 32/64 loss: -1.828415870666504
Batch 33/64 loss: -2.2392349243164062
Batch 34/64 loss: -2.1618518829345703
Batch 35/64 loss: -1.9711503982543945
Batch 36/64 loss: -2.1759033203125
Batch 37/64 loss: -2.0218963623046875
Batch 38/64 loss: -2.1897544860839844
Batch 39/64 loss: -2.1916446685791016
Batch 40/64 loss: -2.0108537673950195
Batch 41/64 loss: -2.2322731018066406
Batch 42/64 loss: -1.9324283599853516
Batch 43/64 loss: -2.270358085632324
Batch 44/64 loss: -2.227640151977539
Batch 45/64 loss: -2.0698862075805664
Batch 46/64 loss: -2.32657527923584
Batch 47/64 loss: -1.9156179428100586
Batch 48/64 loss: -2.3781633377075195
Batch 49/64 loss: -1.5237674713134766
Batch 50/64 loss: -2.1298818588256836
Batch 51/64 loss: -2.296492576599121
Batch 52/64 loss: -2.1324996948242188
Batch 53/64 loss: -1.9133882522583008
Batch 54/64 loss: -2.2967329025268555
Batch 55/64 loss: -2.144529342651367
Batch 56/64 loss: -2.3553466796875
Batch 57/64 loss: -2.221597671508789
Batch 58/64 loss: -1.4833955764770508
Batch 59/64 loss: -2.176025390625
Batch 60/64 loss: -2.317347526550293
Batch 61/64 loss: -1.7518444061279297
Batch 62/64 loss: -1.9225654602050781
Batch 63/64 loss: -2.266263961791992
Batch 64/64 loss: -6.40946102142334
Epoch 394  Train loss: -2.1538724300908108  Val loss: -2.4387764684932747
Epoch 395
-------------------------------
Batch 1/64 loss: -2.1485424041748047
Batch 2/64 loss: -2.3363137245178223
Batch 3/64 loss: -2.0494632720947266
Batch 4/64 loss: -2.2339649200439453
Batch 5/64 loss: -2.3771133422851562
Batch 6/64 loss: -2.2345046997070312
Batch 7/64 loss: -2.216644287109375
Batch 8/64 loss: -2.346221446990967
Batch 9/64 loss: -2.1461782455444336
Batch 10/64 loss: -2.3333911895751953
Batch 11/64 loss: -2.196763038635254
Batch 12/64 loss: -1.995340347290039
Batch 13/64 loss: -2.310546875
Batch 14/64 loss: -1.3053560256958008
Batch 15/64 loss: -2.2025327682495117
Batch 16/64 loss: -2.4200124740600586
Batch 17/64 loss: -2.3888893127441406
Batch 18/64 loss: -2.198296546936035
Batch 19/64 loss: -2.3560924530029297
Batch 20/64 loss: -1.8853168487548828
Batch 21/64 loss: -1.711552619934082
Batch 22/64 loss: -2.2812633514404297
Batch 23/64 loss: -2.2167482376098633
Batch 24/64 loss: -2.037750244140625
Batch 25/64 loss: -2.164252281188965
Batch 26/64 loss: -2.233351707458496
Batch 27/64 loss: -2.0117673873901367
Batch 28/64 loss: -2.3400697708129883
Batch 29/64 loss: -2.1883535385131836
Batch 30/64 loss: -2.165435791015625
Batch 31/64 loss: -2.2509965896606445
Batch 32/64 loss: -2.157949447631836
Batch 33/64 loss: -2.177981376647949
Batch 34/64 loss: -2.1847686767578125
Batch 35/64 loss: -2.224964141845703
Batch 36/64 loss: -2.243973731994629
Batch 37/64 loss: -2.085369110107422
Batch 38/64 loss: -1.6203126907348633
Batch 39/64 loss: -2.2179746627807617
Batch 40/64 loss: -1.9008979797363281
Batch 41/64 loss: -2.4710354804992676
Batch 42/64 loss: -2.097227096557617
Batch 43/64 loss: -2.254304885864258
Batch 44/64 loss: -2.363607406616211
Batch 45/64 loss: -2.1469526290893555
Batch 46/64 loss: -2.122987747192383
Batch 47/64 loss: -1.9796218872070312
Batch 48/64 loss: -2.3106179237365723
Batch 49/64 loss: -2.4006590843200684
Batch 50/64 loss: -2.235419273376465
Batch 51/64 loss: -2.292896270751953
Batch 52/64 loss: -2.193842887878418
Batch 53/64 loss: -2.159121513366699
Batch 54/64 loss: -2.290886878967285
Batch 55/64 loss: -2.2645483016967773
Batch 56/64 loss: -2.2051773071289062
Batch 57/64 loss: -1.947770118713379
Batch 58/64 loss: -2.32303524017334
Batch 59/64 loss: -2.198765754699707
Batch 60/64 loss: -1.8190975189208984
Batch 61/64 loss: -2.139378547668457
Batch 62/64 loss: -2.049875259399414
Batch 63/64 loss: -2.2342405319213867
Batch 64/64 loss: -6.631030559539795
Epoch 395  Train loss: -2.2207303533367084  Val loss: -2.3301808465387404
Epoch 396
-------------------------------
Batch 1/64 loss: -2.3190507888793945
Batch 2/64 loss: -2.3230056762695312
Batch 3/64 loss: -2.2769956588745117
Batch 4/64 loss: -2.2207469940185547
Batch 5/64 loss: -2.181051254272461
Batch 6/64 loss: -2.328052520751953
Batch 7/64 loss: -2.2592287063598633
Batch 8/64 loss: -2.214376449584961
Batch 9/64 loss: -2.2411794662475586
Batch 10/64 loss: -2.063753128051758
Batch 11/64 loss: -2.421952247619629
Batch 12/64 loss: -2.3627920150756836
Batch 13/64 loss: -2.2834415435791016
Batch 14/64 loss: -2.301053047180176
Batch 15/64 loss: -2.2572922706604004
Batch 16/64 loss: -2.3382434844970703
Batch 17/64 loss: -2.305473804473877
Batch 18/64 loss: -2.048192024230957
Batch 19/64 loss: -2.023202896118164
Batch 20/64 loss: -2.336270332336426
Batch 21/64 loss: -2.372129440307617
Batch 22/64 loss: -2.187786102294922
Batch 23/64 loss: -2.456357955932617
Batch 24/64 loss: -1.8153085708618164
Batch 25/64 loss: -2.278445243835449
Batch 26/64 loss: -2.2596426010131836
Batch 27/64 loss: -2.4485487937927246
Batch 28/64 loss: -2.4485244750976562
Batch 29/64 loss: -2.1579132080078125
Batch 30/64 loss: -2.437814712524414
Batch 31/64 loss: -1.9894704818725586
Batch 32/64 loss: -2.3300132751464844
Batch 33/64 loss: -2.3258047103881836
Batch 34/64 loss: -2.4271278381347656
Batch 35/64 loss: -2.176666259765625
Batch 36/64 loss: -1.7908296585083008
Batch 37/64 loss: -2.2978320121765137
Batch 38/64 loss: -2.0458974838256836
Batch 39/64 loss: -2.1319494247436523
Batch 40/64 loss: -1.8233003616333008
Batch 41/64 loss: -2.3530874252319336
Batch 42/64 loss: -2.3327507972717285
Batch 43/64 loss: -2.3015012741088867
Batch 44/64 loss: -2.1679248809814453
Batch 45/64 loss: -2.4713878631591797
Batch 46/64 loss: -2.0962181091308594
Batch 47/64 loss: -1.7865514755249023
Batch 48/64 loss: -1.8584470748901367
Batch 49/64 loss: -2.2000579833984375
Batch 50/64 loss: -2.3838982582092285
Batch 51/64 loss: -2.467426300048828
Batch 52/64 loss: -2.483717918395996
Batch 53/64 loss: -2.1675796508789062
Batch 54/64 loss: -2.3642678260803223
Batch 55/64 loss: -2.128599166870117
Batch 56/64 loss: -2.32303524017334
Batch 57/64 loss: -2.308434009552002
Batch 58/64 loss: -2.2958803176879883
Batch 59/64 loss: -1.6197223663330078
Batch 60/64 loss: -2.345609188079834
Batch 61/64 loss: -1.8512516021728516
Batch 62/64 loss: -2.111846923828125
Batch 63/64 loss: -2.26104736328125
Batch 64/64 loss: -6.465044021606445
Epoch 396  Train loss: -2.2719332227519913  Val loss: -2.608514661231811
Epoch 397
-------------------------------
Batch 1/64 loss: -2.1814537048339844
Batch 2/64 loss: -2.3461990356445312
Batch 3/64 loss: -2.200216293334961
Batch 4/64 loss: -2.1090402603149414
Batch 5/64 loss: -2.208911895751953
Batch 6/64 loss: -2.222701072692871
Batch 7/64 loss: -2.000659942626953
Batch 8/64 loss: -2.402052879333496
Batch 9/64 loss: -2.2950849533081055
Batch 10/64 loss: -2.370419979095459
Batch 11/64 loss: -2.410554885864258
Batch 12/64 loss: -2.1204376220703125
Batch 13/64 loss: -2.125255584716797
Batch 14/64 loss: -2.3732309341430664
Batch 15/64 loss: -2.2860641479492188
Batch 16/64 loss: -2.285327911376953
Batch 17/64 loss: -2.104278564453125
Batch 18/64 loss: -2.043977737426758
Batch 19/64 loss: -2.3501033782958984
Batch 20/64 loss: -2.3290634155273438
Batch 21/64 loss: -2.367432117462158
Batch 22/64 loss: -2.187580108642578
Batch 23/64 loss: -2.275175094604492
Batch 24/64 loss: -2.1582155227661133
Batch 25/64 loss: -2.3595619201660156
Batch 26/64 loss: -2.2995519638061523
Batch 27/64 loss: -2.195694923400879
Batch 28/64 loss: -1.9989547729492188
Batch 29/64 loss: -2.34317684173584
Batch 30/64 loss: -1.8196697235107422
Batch 31/64 loss: -1.4854860305786133
Batch 32/64 loss: -1.3171615600585938
Batch 33/64 loss: -2.2656917572021484
Batch 34/64 loss: -2.428262710571289
Batch 35/64 loss: -2.2218704223632812
Batch 36/64 loss: -2.0525341033935547
Batch 37/64 loss: -2.417093276977539
Batch 38/64 loss: -2.163288116455078
Batch 39/64 loss: -2.2625465393066406
Batch 40/64 loss: -2.1526269912719727
Batch 41/64 loss: -2.244800567626953
Batch 42/64 loss: -2.3483200073242188
Batch 43/64 loss: -2.253763198852539
Batch 44/64 loss: -2.30948543548584
Batch 45/64 loss: -2.153226852416992
Batch 46/64 loss: -2.0125732421875
Batch 47/64 loss: -1.8443994522094727
Batch 48/64 loss: -2.1972179412841797
Batch 49/64 loss: -2.2022218704223633
Batch 50/64 loss: -2.3221960067749023
Batch 51/64 loss: -2.3668317794799805
Batch 52/64 loss: -2.1057844161987305
Batch 53/64 loss: -2.430333137512207
Batch 54/64 loss: -1.7737932205200195
Batch 55/64 loss: -2.2403764724731445
Batch 56/64 loss: -2.356496810913086
Batch 57/64 loss: -2.0520553588867188
Batch 58/64 loss: -2.0382604598999023
Batch 59/64 loss: -2.316804885864258
Batch 60/64 loss: -2.2822532653808594
Batch 61/64 loss: -2.2215499877929688
Batch 62/64 loss: -2.1284561157226562
Batch 63/64 loss: -1.870758056640625
Batch 64/64 loss: -6.247737407684326
Epoch 397  Train loss: -2.2320685536253686  Val loss: -2.499732119111261
Epoch 398
-------------------------------
Batch 1/64 loss: -2.3599843978881836
Batch 2/64 loss: -2.146059989929199
Batch 3/64 loss: -1.8500137329101562
Batch 4/64 loss: -2.2528867721557617
Batch 5/64 loss: -2.1971092224121094
Batch 6/64 loss: -2.2660751342773438
Batch 7/64 loss: -2.1202011108398438
Batch 8/64 loss: -2.095309257507324
Batch 9/64 loss: -2.1474313735961914
Batch 10/64 loss: -1.8560523986816406
Batch 11/64 loss: -2.1831483840942383
Batch 12/64 loss: -2.117255210876465
Batch 13/64 loss: -2.352349281311035
Batch 14/64 loss: -2.379904270172119
Batch 15/64 loss: -2.2772722244262695
Batch 16/64 loss: -2.3612194061279297
Batch 17/64 loss: -2.095351219177246
Batch 18/64 loss: -2.3441481590270996
Batch 19/64 loss: -2.1439762115478516
Batch 20/64 loss: -2.3091979026794434
Batch 21/64 loss: -2.1542234420776367
Batch 22/64 loss: -2.37459659576416
Batch 23/64 loss: -2.328794002532959
Batch 24/64 loss: -2.2764906883239746
Batch 25/64 loss: -2.177628517150879
Batch 26/64 loss: -2.3535561561584473
Batch 27/64 loss: -2.4942030906677246
Batch 28/64 loss: -2.293168067932129
Batch 29/64 loss: -2.4183483123779297
Batch 30/64 loss: -1.9324913024902344
Batch 31/64 loss: -2.3761844635009766
Batch 32/64 loss: -2.4900050163269043
Batch 33/64 loss: -2.162346839904785
Batch 34/64 loss: -2.534010410308838
Batch 35/64 loss: -2.5220694541931152
Batch 36/64 loss: -2.3071107864379883
Batch 37/64 loss: -2.2419967651367188
Batch 38/64 loss: -2.2993550300598145
Batch 39/64 loss: -2.4782190322875977
Batch 40/64 loss: -2.227482795715332
Batch 41/64 loss: -2.4154529571533203
Batch 42/64 loss: -2.390902519226074
Batch 43/64 loss: -2.423043727874756
Batch 44/64 loss: -2.3259077072143555
Batch 45/64 loss: -2.382941246032715
Batch 46/64 loss: -2.1372690200805664
Batch 47/64 loss: -2.4254913330078125
Batch 48/64 loss: -2.3481593132019043
Batch 49/64 loss: -2.3002967834472656
Batch 50/64 loss: -2.3859434127807617
Batch 51/64 loss: -2.3360280990600586
Batch 52/64 loss: -2.3035836219787598
Batch 53/64 loss: -2.131960868835449
Batch 54/64 loss: -2.36904239654541
Batch 55/64 loss: -2.2066140174865723
Batch 56/64 loss: -2.3624954223632812
Batch 57/64 loss: -2.021099090576172
Batch 58/64 loss: -2.1125717163085938
Batch 59/64 loss: -0.9798974990844727
Batch 60/64 loss: -1.751668930053711
Batch 61/64 loss: -1.8615427017211914
Batch 62/64 loss: -2.130290985107422
Batch 63/64 loss: -2.1527185440063477
Batch 64/64 loss: -6.285967826843262
Epoch 398  Train loss: -2.2786921445061177  Val loss: -2.478200106276679
Epoch 399
-------------------------------
Batch 1/64 loss: -1.5913286209106445
Batch 2/64 loss: -2.282290458679199
Batch 3/64 loss: -2.222357749938965
Batch 4/64 loss: -2.1677732467651367
Batch 5/64 loss: -2.2351531982421875
Batch 6/64 loss: -1.9941482543945312
Batch 7/64 loss: -2.3527517318725586
Batch 8/64 loss: -2.006000518798828
Batch 9/64 loss: -1.557565689086914
Batch 10/64 loss: -1.7447395324707031
Batch 11/64 loss: -2.0368528366088867
Batch 12/64 loss: -2.3431925773620605
Batch 13/64 loss: -2.2217702865600586
Batch 14/64 loss: -2.0312557220458984
Batch 15/64 loss: -2.2347211837768555
Batch 16/64 loss: -2.0420141220092773
Batch 17/64 loss: -1.8080682754516602
Batch 18/64 loss: -1.6161422729492188
Batch 19/64 loss: -2.004589080810547
Batch 20/64 loss: -1.8316116333007812
Batch 21/64 loss: -2.104039192199707
Batch 22/64 loss: -2.1974897384643555
Batch 23/64 loss: -2.083664894104004
Batch 24/64 loss: -2.2752628326416016
Batch 25/64 loss: -2.102950096130371
Batch 26/64 loss: -1.8318376541137695
Batch 27/64 loss: -2.1206398010253906
Batch 28/64 loss: -2.2372169494628906
Batch 29/64 loss: -2.119887351989746
Batch 30/64 loss: -1.8784255981445312
Batch 31/64 loss: -1.996596336364746
Batch 32/64 loss: -1.9510974884033203
Batch 33/64 loss: -2.311598300933838
Batch 34/64 loss: -2.2244110107421875
Batch 35/64 loss: -2.05686092376709
Batch 36/64 loss: -1.734492301940918
Batch 37/64 loss: -2.0596466064453125
Batch 38/64 loss: -2.1358137130737305
Batch 39/64 loss: -2.018801689147949
Batch 40/64 loss: -2.0004072189331055
Batch 41/64 loss: -2.0285139083862305
Batch 42/64 loss: -2.1620311737060547
Batch 43/64 loss: -1.8702669143676758
Batch 44/64 loss: -2.1146316528320312
Batch 45/64 loss: -2.1744441986083984
Batch 46/64 loss: -2.1033554077148438
Batch 47/64 loss: -2.323611259460449
Batch 48/64 loss: -2.2300186157226562
Batch 49/64 loss: -2.1570234298706055
Batch 50/64 loss: -2.0616559982299805
Batch 51/64 loss: -2.212085723876953
Batch 52/64 loss: -2.084177017211914
Batch 53/64 loss: -2.274895668029785
Batch 54/64 loss: -2.185262680053711
Batch 55/64 loss: -2.3379359245300293
Batch 56/64 loss: -2.275390625
Batch 57/64 loss: -2.2911128997802734
Batch 58/64 loss: -2.2990245819091797
Batch 59/64 loss: -1.6840715408325195
Batch 60/64 loss: -2.0879316329956055
Batch 61/64 loss: -2.216061592102051
Batch 62/64 loss: -2.3214826583862305
Batch 63/64 loss: -2.3262109756469727
Batch 64/64 loss: -6.307423114776611
Epoch 399  Train loss: -2.138309491849413  Val loss: -2.319772608911049
Epoch 400
-------------------------------
Batch 1/64 loss: -2.1248912811279297
Batch 2/64 loss: -2.3408126831054688
Batch 3/64 loss: -1.9721202850341797
Batch 4/64 loss: -2.091914176940918
Batch 5/64 loss: -2.132575035095215
Batch 6/64 loss: -2.187729835510254
Batch 7/64 loss: -2.1139612197875977
Batch 8/64 loss: -2.0232162475585938
Batch 9/64 loss: -2.1363019943237305
Batch 10/64 loss: -2.1350231170654297
Batch 11/64 loss: -2.0436744689941406
Batch 12/64 loss: -1.9415655136108398
Batch 13/64 loss: -2.042048454284668
Batch 14/64 loss: -2.1060447692871094
Batch 15/64 loss: -2.2422094345092773
Batch 16/64 loss: -1.8429670333862305
Batch 17/64 loss: -1.951284408569336
Batch 18/64 loss: -1.9688568115234375
Batch 19/64 loss: -1.8263826370239258
Batch 20/64 loss: -1.9430456161499023
Batch 21/64 loss: -2.271760940551758
Batch 22/64 loss: -2.032057762145996
Batch 23/64 loss: -2.1169891357421875
Batch 24/64 loss: -2.0200119018554688
Batch 25/64 loss: -1.8124618530273438
Batch 26/64 loss: -2.2938289642333984
Batch 27/64 loss: -2.1352415084838867
Batch 28/64 loss: -1.7670612335205078
Batch 29/64 loss: -2.058863639831543
Batch 30/64 loss: -1.9019966125488281
Batch 31/64 loss: -2.2375831604003906
Batch 32/64 loss: -1.992218017578125
Batch 33/64 loss: -2.0096025466918945
Batch 34/64 loss: -2.31504487991333
Batch 35/64 loss: -1.6082572937011719
Batch 36/64 loss: -2.2703795433044434
Batch 37/64 loss: -2.1844520568847656
Batch 38/64 loss: -2.1992673873901367
Batch 39/64 loss: -1.9187183380126953
Batch 40/64 loss: -2.0960426330566406
Batch 41/64 loss: -2.237407684326172
Batch 42/64 loss: -1.911320686340332
Batch 43/64 loss: -2.029142379760742
Batch 44/64 loss: -1.2356929779052734
Batch 45/64 loss: -2.014728546142578
Batch 46/64 loss: -2.18438720703125
Batch 47/64 loss: -1.925374984741211
Batch 48/64 loss: -1.517822265625
Batch 49/64 loss: -2.198187828063965
Batch 50/64 loss: -1.8628206253051758
Batch 51/64 loss: -2.0035667419433594
Batch 52/64 loss: -2.1881017684936523
Batch 53/64 loss: -2.322896957397461
Batch 54/64 loss: -2.3276662826538086
Batch 55/64 loss: -1.9331331253051758
Batch 56/64 loss: -2.08347225189209
Batch 57/64 loss: -2.159086227416992
Batch 58/64 loss: -2.2553577423095703
Batch 59/64 loss: -2.2451305389404297
Batch 60/64 loss: -2.2050390243530273
Batch 61/64 loss: -1.932602882385254
Batch 62/64 loss: -2.1161651611328125
Batch 63/64 loss: -1.9708423614501953
Batch 64/64 loss: -5.672310829162598
Epoch 400  Train loss: -2.0944728439929436  Val loss: -2.360780368555862
Epoch 401
-------------------------------
Batch 1/64 loss: -2.1044750213623047
Batch 2/64 loss: -2.0158863067626953
Batch 3/64 loss: -2.2940568923950195
Batch 4/64 loss: -1.9328441619873047
Batch 5/64 loss: -2.3608384132385254
Batch 6/64 loss: -2.220221519470215
Batch 7/64 loss: -2.3358154296875
Batch 8/64 loss: -1.5517148971557617
Batch 9/64 loss: -2.377521514892578
Batch 10/64 loss: -1.8787050247192383
Batch 11/64 loss: -1.9965343475341797
Batch 12/64 loss: -1.9521236419677734
Batch 13/64 loss: -2.3511857986450195
Batch 14/64 loss: -1.8263111114501953
Batch 15/64 loss: -2.1861143112182617
Batch 16/64 loss: -2.2469348907470703
Batch 17/64 loss: -2.190732002258301
Batch 18/64 loss: -2.3932085037231445
Batch 19/64 loss: -2.3672094345092773
Batch 20/64 loss: -1.6356868743896484
Batch 21/64 loss: -2.138422966003418
Batch 22/64 loss: -2.313852310180664
Batch 23/64 loss: -2.085378646850586
Batch 24/64 loss: -2.2003984451293945
Batch 25/64 loss: -2.3762383460998535
Batch 26/64 loss: -2.2086963653564453
Batch 27/64 loss: -2.120849609375
Batch 28/64 loss: -2.3169593811035156
Batch 29/64 loss: -2.362745761871338
Batch 30/64 loss: -2.153031349182129
Batch 31/64 loss: -1.8347597122192383
Batch 32/64 loss: -2.3202219009399414
Batch 33/64 loss: -2.291261672973633
Batch 34/64 loss: -2.106599807739258
Batch 35/64 loss: -2.4025630950927734
Batch 36/64 loss: -2.2583580017089844
Batch 37/64 loss: -2.234912872314453
Batch 38/64 loss: -2.2726593017578125
Batch 39/64 loss: -2.261922836303711
Batch 40/64 loss: -2.4012045860290527
Batch 41/64 loss: -2.107600212097168
Batch 42/64 loss: -2.2825260162353516
Batch 43/64 loss: -2.1474227905273438
Batch 44/64 loss: -2.334505081176758
Batch 45/64 loss: -1.8547487258911133
Batch 46/64 loss: -2.1195268630981445
Batch 47/64 loss: -2.350404739379883
Batch 48/64 loss: -2.294340133666992
Batch 49/64 loss: -2.382676124572754
Batch 50/64 loss: -2.156534194946289
Batch 51/64 loss: -2.3479537963867188
Batch 52/64 loss: -2.1648130416870117
Batch 53/64 loss: -1.857771873474121
Batch 54/64 loss: -2.226437568664551
Batch 55/64 loss: -2.46157169342041
Batch 56/64 loss: -1.4252567291259766
Batch 57/64 loss: -2.0186548233032227
Batch 58/64 loss: -1.5967779159545898
Batch 59/64 loss: -2.0649309158325195
Batch 60/64 loss: -2.251209259033203
Batch 61/64 loss: -2.051053047180176
Batch 62/64 loss: -2.32466983795166
Batch 63/64 loss: -1.9996747970581055
Batch 64/64 loss: -6.396183967590332
Epoch 401  Train loss: -2.2038800819247375  Val loss: -2.4309891769566487
Epoch 402
-------------------------------
Batch 1/64 loss: -2.2892112731933594
Batch 2/64 loss: -2.0826778411865234
Batch 3/64 loss: -1.8707609176635742
Batch 4/64 loss: -2.084317207336426
Batch 5/64 loss: -2.2672195434570312
Batch 6/64 loss: -2.3039464950561523
Batch 7/64 loss: -2.376563549041748
Batch 8/64 loss: -2.102659225463867
Batch 9/64 loss: -1.8435211181640625
Batch 10/64 loss: -1.7643003463745117
Batch 11/64 loss: -2.1550865173339844
Batch 12/64 loss: -1.8711433410644531
Batch 13/64 loss: -2.2828235626220703
Batch 14/64 loss: -2.0813827514648438
Batch 15/64 loss: -2.1658287048339844
Batch 16/64 loss: -2.4044713973999023
Batch 17/64 loss: -1.4502410888671875
Batch 18/64 loss: -2.132020950317383
Batch 19/64 loss: -2.1639347076416016
Batch 20/64 loss: -1.6099519729614258
Batch 21/64 loss: -2.1840620040893555
Batch 22/64 loss: -2.1118335723876953
Batch 23/64 loss: -1.9934635162353516
Batch 24/64 loss: -2.212137222290039
Batch 25/64 loss: -1.9792861938476562
Batch 26/64 loss: -2.0499401092529297
Batch 27/64 loss: -2.106175422668457
Batch 28/64 loss: -2.235187530517578
Batch 29/64 loss: -1.8497858047485352
Batch 30/64 loss: -1.8604326248168945
Batch 31/64 loss: -2.1570358276367188
Batch 32/64 loss: -2.0224685668945312
Batch 33/64 loss: -2.0025835037231445
Batch 34/64 loss: -1.7076044082641602
Batch 35/64 loss: -2.2501678466796875
Batch 36/64 loss: -1.861252784729004
Batch 37/64 loss: -1.839125633239746
Batch 38/64 loss: -2.131941795349121
Batch 39/64 loss: -2.1040964126586914
Batch 40/64 loss: -2.0992231369018555
Batch 41/64 loss: -1.9836063385009766
Batch 42/64 loss: -1.9426536560058594
Batch 43/64 loss: -1.7025079727172852
Batch 44/64 loss: -2.0406179428100586
Batch 45/64 loss: -2.0352869033813477
Batch 46/64 loss: -2.233273506164551
Batch 47/64 loss: -2.225224494934082
Batch 48/64 loss: -2.302074432373047
Batch 49/64 loss: -1.1054811477661133
Batch 50/64 loss: -2.2592716217041016
Batch 51/64 loss: -2.211544990539551
Batch 52/64 loss: -2.175337791442871
Batch 53/64 loss: -1.0036020278930664
Batch 54/64 loss: -1.2051820755004883
Batch 55/64 loss: -1.9511241912841797
Batch 56/64 loss: -1.983759880065918
Batch 57/64 loss: -1.5930547714233398
Batch 58/64 loss: -1.8636713027954102
Batch 59/64 loss: -2.097102165222168
Batch 60/64 loss: -1.887986183166504
Batch 61/64 loss: -2.150392532348633
Batch 62/64 loss: -1.9683961868286133
Batch 63/64 loss: -1.9321613311767578
Batch 64/64 loss: -6.217122554779053
Epoch 402  Train loss: -2.0482513222039915  Val loss: -2.110301132464327
Epoch 403
-------------------------------
Batch 1/64 loss: -2.1234054565429688
Batch 2/64 loss: -1.580580711364746
Batch 3/64 loss: -1.8912467956542969
Batch 4/64 loss: -1.8351964950561523
Batch 5/64 loss: -1.7913837432861328
Batch 6/64 loss: -1.8373136520385742
Batch 7/64 loss: -2.0020294189453125
Batch 8/64 loss: -1.9487113952636719
Batch 9/64 loss: -1.9694137573242188
Batch 10/64 loss: -1.9311742782592773
Batch 11/64 loss: -1.8728322982788086
Batch 12/64 loss: -2.0994224548339844
Batch 13/64 loss: -2.090841293334961
Batch 14/64 loss: -1.9439888000488281
Batch 15/64 loss: -2.326202869415283
Batch 16/64 loss: -1.9058141708374023
Batch 17/64 loss: -1.6200523376464844
Batch 18/64 loss: -1.4853897094726562
Batch 19/64 loss: -2.2650070190429688
Batch 20/64 loss: -1.1725473403930664
Batch 21/64 loss: -2.0014867782592773
Batch 22/64 loss: -1.6360359191894531
Batch 23/64 loss: -2.277738571166992
Batch 24/64 loss: -2.023970603942871
Batch 25/64 loss: -2.073240280151367
Batch 26/64 loss: -1.8267316818237305
Batch 27/64 loss: -1.9874391555786133
Batch 28/64 loss: -1.6269826889038086
Batch 29/64 loss: -2.0171613693237305
Batch 30/64 loss: -1.7592363357543945
Batch 31/64 loss: -1.8162784576416016
Batch 32/64 loss: -2.2493629455566406
Batch 33/64 loss: -1.7076520919799805
Batch 34/64 loss: -1.6690092086791992
Batch 35/64 loss: -1.7690629959106445
Batch 36/64 loss: -1.8635530471801758
Batch 37/64 loss: -1.907501220703125
Batch 38/64 loss: -1.6505680084228516
Batch 39/64 loss: -1.9915990829467773
Batch 40/64 loss: -1.9852323532104492
Batch 41/64 loss: -2.098733901977539
Batch 42/64 loss: -2.1090736389160156
Batch 43/64 loss: -1.9552850723266602
Batch 44/64 loss: -1.988123893737793
Batch 45/64 loss: -2.2269296646118164
Batch 46/64 loss: -2.253437042236328
Batch 47/64 loss: -1.7120962142944336
Batch 48/64 loss: -1.7575750350952148
Batch 49/64 loss: -1.8903350830078125
Batch 50/64 loss: -1.7966241836547852
Batch 51/64 loss: -2.130704879760742
Batch 52/64 loss: -1.2562370300292969
Batch 53/64 loss: -2.045313835144043
Batch 54/64 loss: -1.9978160858154297
Batch 55/64 loss: -1.992293357849121
Batch 56/64 loss: -1.3383188247680664
Batch 57/64 loss: -1.8674736022949219
Batch 58/64 loss: -1.4815177917480469
Batch 59/64 loss: -2.0324535369873047
Batch 60/64 loss: -2.138669013977051
Batch 61/64 loss: -1.6794929504394531
Batch 62/64 loss: -2.0432376861572266
Batch 63/64 loss: -2.181429862976074
Batch 64/64 loss: -6.453500747680664
Epoch 403  Train loss: -1.9505206986969592  Val loss: -2.0499760211538205
Epoch 404
-------------------------------
Batch 1/64 loss: -1.9751911163330078
Batch 2/64 loss: -1.577188491821289
Batch 3/64 loss: -1.982314109802246
Batch 4/64 loss: -2.058208465576172
Batch 5/64 loss: -2.135171890258789
Batch 6/64 loss: -1.9699983596801758
Batch 7/64 loss: -2.2152605056762695
Batch 8/64 loss: -1.9492454528808594
Batch 9/64 loss: -2.19036865234375
Batch 10/64 loss: -1.956695556640625
Batch 11/64 loss: -2.0735387802124023
Batch 12/64 loss: -2.1659984588623047
Batch 13/64 loss: -2.280038833618164
Batch 14/64 loss: -1.933396339416504
Batch 15/64 loss: -2.263042449951172
Batch 16/64 loss: -1.5567512512207031
Batch 17/64 loss: -2.1104278564453125
Batch 18/64 loss: -2.0711889266967773
Batch 19/64 loss: -2.256227493286133
Batch 20/64 loss: -2.2666311264038086
Batch 21/64 loss: -1.9127235412597656
Batch 22/64 loss: -1.9754905700683594
Batch 23/64 loss: -1.8092947006225586
Batch 24/64 loss: -2.260599136352539
Batch 25/64 loss: -2.049382209777832
Batch 26/64 loss: -1.9999895095825195
Batch 27/64 loss: -2.134258270263672
Batch 28/64 loss: -2.0129051208496094
Batch 29/64 loss: -2.2426528930664062
Batch 30/64 loss: -2.137669563293457
Batch 31/64 loss: -2.0006961822509766
Batch 32/64 loss: -1.4664478302001953
Batch 33/64 loss: -2.169009208679199
Batch 34/64 loss: -2.0461654663085938
Batch 35/64 loss: -1.429581642150879
Batch 36/64 loss: -2.173511505126953
Batch 37/64 loss: -2.050037384033203
Batch 38/64 loss: -1.747328758239746
Batch 39/64 loss: -2.280130386352539
Batch 40/64 loss: -2.028876304626465
Batch 41/64 loss: -1.7803773880004883
Batch 42/64 loss: -1.3274965286254883
Batch 43/64 loss: -2.0533313751220703
Batch 44/64 loss: -1.9371528625488281
Batch 45/64 loss: -1.8062114715576172
Batch 46/64 loss: -2.1836090087890625
Batch 47/64 loss: -1.8047819137573242
Batch 48/64 loss: -2.0476207733154297
Batch 49/64 loss: -1.993849754333496
Batch 50/64 loss: -1.8075447082519531
Batch 51/64 loss: -1.9986705780029297
Batch 52/64 loss: -2.147049903869629
Batch 53/64 loss: -2.0725135803222656
Batch 54/64 loss: -2.344482421875
Batch 55/64 loss: -1.36419677734375
Batch 56/64 loss: -1.968912124633789
Batch 57/64 loss: -2.1778087615966797
Batch 58/64 loss: -2.1583023071289062
Batch 59/64 loss: -2.2036561965942383
Batch 60/64 loss: -2.138190269470215
Batch 61/64 loss: -2.1798315048217773
Batch 62/64 loss: -2.1426963806152344
Batch 63/64 loss: -2.2566442489624023
Batch 64/64 loss: -6.284985542297363
Epoch 404  Train loss: -2.063094969356761  Val loss: -2.4481156470439687
Epoch 405
-------------------------------
Batch 1/64 loss: -2.168712615966797
Batch 2/64 loss: -2.0801143646240234
Batch 3/64 loss: -1.9764442443847656
Batch 4/64 loss: -2.1912717819213867
Batch 5/64 loss: -2.041590690612793
Batch 6/64 loss: -2.194295883178711
Batch 7/64 loss: -1.9775896072387695
Batch 8/64 loss: -2.1436614990234375
Batch 9/64 loss: -2.027401924133301
Batch 10/64 loss: -2.0841875076293945
Batch 11/64 loss: -2.169529914855957
Batch 12/64 loss: -1.8309412002563477
Batch 13/64 loss: -1.8450889587402344
Batch 14/64 loss: -2.1174240112304688
Batch 15/64 loss: -2.108555793762207
Batch 16/64 loss: -2.039933204650879
Batch 17/64 loss: -2.057347297668457
Batch 18/64 loss: -2.14438533782959
Batch 19/64 loss: -2.1428003311157227
Batch 20/64 loss: -2.145732879638672
Batch 21/64 loss: -2.0861387252807617
Batch 22/64 loss: -2.017947196960449
Batch 23/64 loss: -2.0297651290893555
Batch 24/64 loss: -2.1662673950195312
Batch 25/64 loss: -2.16353702545166
Batch 26/64 loss: -2.3770923614501953
Batch 27/64 loss: -2.326838493347168
Batch 28/64 loss: -2.0142393112182617
Batch 29/64 loss: -2.058605194091797
Batch 30/64 loss: -2.1639537811279297
Batch 31/64 loss: -1.8869733810424805
Batch 32/64 loss: -1.9238805770874023
Batch 33/64 loss: -2.3833789825439453
Batch 34/64 loss: -2.244457721710205
Batch 35/64 loss: -2.0381927490234375
Batch 36/64 loss: -1.7207098007202148
Batch 37/64 loss: -0.7652587890625
Batch 38/64 loss: -1.9336442947387695
Batch 39/64 loss: -1.9906597137451172
Batch 40/64 loss: -2.092463493347168
Batch 41/64 loss: -1.7480945587158203
Batch 42/64 loss: -2.1034984588623047
Batch 43/64 loss: -2.253446578979492
Batch 44/64 loss: -2.0897369384765625
Batch 45/64 loss: -2.2464041709899902
Batch 46/64 loss: -1.8293638229370117
Batch 47/64 loss: -2.1523237228393555
Batch 48/64 loss: -1.9692974090576172
Batch 49/64 loss: -1.8276147842407227
Batch 50/64 loss: -2.2486276626586914
Batch 51/64 loss: -2.084195137023926
Batch 52/64 loss: -2.0341100692749023
Batch 53/64 loss: -2.3138790130615234
Batch 54/64 loss: -2.337878704071045
Batch 55/64 loss: -2.0459728240966797
Batch 56/64 loss: -2.2533397674560547
Batch 57/64 loss: -2.326113700866699
Batch 58/64 loss: -2.100381851196289
Batch 59/64 loss: -1.7189741134643555
Batch 60/64 loss: -2.0410757064819336
Batch 61/64 loss: -2.0677709579467773
Batch 62/64 loss: -2.362521171569824
Batch 63/64 loss: -2.4089159965515137
Batch 64/64 loss: -6.315040111541748
Epoch 405  Train loss: -2.1203267508862065  Val loss: -2.4942228179617025
Epoch 406
-------------------------------
Batch 1/64 loss: -1.898116111755371
Batch 2/64 loss: -2.0964555740356445
Batch 3/64 loss: -2.4129319190979004
Batch 4/64 loss: -2.330596923828125
Batch 5/64 loss: -2.211519241333008
Batch 6/64 loss: -2.122431755065918
Batch 7/64 loss: -1.2543535232543945
Batch 8/64 loss: -2.39986515045166
Batch 9/64 loss: -2.2671613693237305
Batch 10/64 loss: -2.111715316772461
Batch 11/64 loss: -2.1947898864746094
Batch 12/64 loss: -1.7609539031982422
Batch 13/64 loss: -2.237908363342285
Batch 14/64 loss: -2.2326393127441406
Batch 15/64 loss: -2.0866050720214844
Batch 16/64 loss: -2.126239776611328
Batch 17/64 loss: -2.1491451263427734
Batch 18/64 loss: -2.038593292236328
Batch 19/64 loss: -2.2998781204223633
Batch 20/64 loss: -2.3208236694335938
Batch 21/64 loss: -2.070209503173828
Batch 22/64 loss: -2.374295711517334
Batch 23/64 loss: -2.181364059448242
Batch 24/64 loss: -1.8939781188964844
Batch 25/64 loss: -2.164815902709961
Batch 26/64 loss: -2.2922544479370117
Batch 27/64 loss: -2.3907108306884766
Batch 28/64 loss: -2.1665306091308594
Batch 29/64 loss: -1.6004619598388672
Batch 30/64 loss: -2.292111396789551
Batch 31/64 loss: -2.0431079864501953
Batch 32/64 loss: -2.2217321395874023
Batch 33/64 loss: -2.320265769958496
Batch 34/64 loss: -2.059260368347168
Batch 35/64 loss: -1.9923715591430664
Batch 36/64 loss: -1.6030521392822266
Batch 37/64 loss: -2.1609725952148438
Batch 38/64 loss: -1.9870777130126953
Batch 39/64 loss: -1.9115047454833984
Batch 40/64 loss: -2.231159210205078
Batch 41/64 loss: -2.3232011795043945
Batch 42/64 loss: -2.172245979309082
Batch 43/64 loss: -2.2518739700317383
Batch 44/64 loss: -2.2269182205200195
Batch 45/64 loss: -2.2482528686523438
Batch 46/64 loss: -2.170328140258789
Batch 47/64 loss: -2.056774139404297
Batch 48/64 loss: -2.2427244186401367
Batch 49/64 loss: -2.045254707336426
Batch 50/64 loss: -2.354310989379883
Batch 51/64 loss: -1.9951143264770508
Batch 52/64 loss: -2.214299201965332
Batch 53/64 loss: -1.950490951538086
Batch 54/64 loss: -2.236112594604492
Batch 55/64 loss: -2.170717239379883
Batch 56/64 loss: -1.9989147186279297
Batch 57/64 loss: -2.2364063262939453
Batch 58/64 loss: -2.2943029403686523
Batch 59/64 loss: -2.3382081985473633
Batch 60/64 loss: -2.295991897583008
Batch 61/64 loss: -2.1557464599609375
Batch 62/64 loss: -1.9903411865234375
Batch 63/64 loss: -1.8803815841674805
Batch 64/64 loss: -6.103492736816406
Epoch 406  Train loss: -2.1793959524117263  Val loss: -2.475754767349086
Epoch 407
-------------------------------
Batch 1/64 loss: -2.0982894897460938
Batch 2/64 loss: -2.197840690612793
Batch 3/64 loss: -2.043869972229004
Batch 4/64 loss: -2.2191057205200195
Batch 5/64 loss: -2.285954475402832
Batch 6/64 loss: -1.9360380172729492
Batch 7/64 loss: -2.2325172424316406
Batch 8/64 loss: -2.1575918197631836
Batch 9/64 loss: -1.9997339248657227
Batch 10/64 loss: -1.6325435638427734
Batch 11/64 loss: -2.0230560302734375
Batch 12/64 loss: -2.0995969772338867
Batch 13/64 loss: -2.202383041381836
Batch 14/64 loss: -1.722799301147461
Batch 15/64 loss: -2.4413557052612305
Batch 16/64 loss: -2.293513298034668
Batch 17/64 loss: -2.334742546081543
Batch 18/64 loss: -2.226252555847168
Batch 19/64 loss: -2.2907609939575195
Batch 20/64 loss: -2.2757463455200195
Batch 21/64 loss: -2.3144636154174805
Batch 22/64 loss: -2.246967315673828
Batch 23/64 loss: -2.165670394897461
Batch 24/64 loss: -2.336446762084961
Batch 25/64 loss: -2.2123146057128906
Batch 26/64 loss: -2.2204904556274414
Batch 27/64 loss: -2.2370834350585938
Batch 28/64 loss: -1.9906177520751953
Batch 29/64 loss: -2.1949901580810547
Batch 30/64 loss: -2.293365478515625
Batch 31/64 loss: -2.0666189193725586
Batch 32/64 loss: -2.3045969009399414
Batch 33/64 loss: -2.1753101348876953
Batch 34/64 loss: -2.3732452392578125
Batch 35/64 loss: -2.25931453704834
Batch 36/64 loss: -1.9576835632324219
Batch 37/64 loss: -2.3261756896972656
Batch 38/64 loss: -1.3774175643920898
Batch 39/64 loss: -2.502225875854492
Batch 40/64 loss: -2.4005517959594727
Batch 41/64 loss: -2.4028806686401367
Batch 42/64 loss: -2.105010986328125
Batch 43/64 loss: -2.1385374069213867
Batch 44/64 loss: -2.2113218307495117
Batch 45/64 loss: -2.0629005432128906
Batch 46/64 loss: -2.2602462768554688
Batch 47/64 loss: -2.12021541595459
Batch 48/64 loss: -2.2494373321533203
Batch 49/64 loss: -2.331470489501953
Batch 50/64 loss: -2.436884880065918
Batch 51/64 loss: -2.2580995559692383
Batch 52/64 loss: -1.9196996688842773
Batch 53/64 loss: -2.3702783584594727
Batch 54/64 loss: -2.1452274322509766
Batch 55/64 loss: -2.2596921920776367
Batch 56/64 loss: -2.252656936645508
Batch 57/64 loss: -2.0428953170776367
Batch 58/64 loss: -2.2247390747070312
Batch 59/64 loss: -2.023251533508301
Batch 60/64 loss: -2.304917335510254
Batch 61/64 loss: -2.318206787109375
Batch 62/64 loss: -2.229935646057129
Batch 63/64 loss: -2.3375015258789062
Batch 64/64 loss: -6.6119890213012695
Epoch 407  Train loss: -2.2373998567169786  Val loss: -2.4697922906515113
Epoch 408
-------------------------------
Batch 1/64 loss: -2.164584159851074
Batch 2/64 loss: -2.3457870483398438
Batch 3/64 loss: -1.7876081466674805
Batch 4/64 loss: -2.3659801483154297
Batch 5/64 loss: -2.2679052352905273
Batch 6/64 loss: -2.2499303817749023
Batch 7/64 loss: -2.213994026184082
Batch 8/64 loss: -1.6468267440795898
Batch 9/64 loss: -2.1830291748046875
Batch 10/64 loss: -2.3720831871032715
Batch 11/64 loss: -2.1976728439331055
Batch 12/64 loss: -2.288943290710449
Batch 13/64 loss: -2.2164344787597656
Batch 14/64 loss: -2.1138267517089844
Batch 15/64 loss: -1.8830957412719727
Batch 16/64 loss: -2.03391170501709
Batch 17/64 loss: -2.1566553115844727
Batch 18/64 loss: -2.0722780227661133
Batch 19/64 loss: -1.6397476196289062
Batch 20/64 loss: -2.164984703063965
Batch 21/64 loss: -2.2682905197143555
Batch 22/64 loss: -2.1097307205200195
Batch 23/64 loss: -2.100386619567871
Batch 24/64 loss: -2.1836509704589844
Batch 25/64 loss: -2.2044572830200195
Batch 26/64 loss: -1.8986930847167969
Batch 27/64 loss: -1.953068733215332
Batch 28/64 loss: -2.311616897583008
Batch 29/64 loss: -2.1516952514648438
Batch 30/64 loss: -2.3506622314453125
Batch 31/64 loss: -2.2378435134887695
Batch 32/64 loss: -2.333156108856201
Batch 33/64 loss: -1.9045591354370117
Batch 34/64 loss: -2.0911245346069336
Batch 35/64 loss: -2.1349802017211914
Batch 36/64 loss: -2.1349964141845703
Batch 37/64 loss: -2.2601165771484375
Batch 38/64 loss: -2.3291397094726562
Batch 39/64 loss: -2.459228992462158
Batch 40/64 loss: -2.0685882568359375
Batch 41/64 loss: -2.2947096824645996
Batch 42/64 loss: -2.2522802352905273
Batch 43/64 loss: -2.2889671325683594
Batch 44/64 loss: -2.427842617034912
Batch 45/64 loss: -2.416144371032715
Batch 46/64 loss: -2.241840362548828
Batch 47/64 loss: -2.11946964263916
Batch 48/64 loss: -2.1931800842285156
Batch 49/64 loss: -2.214998245239258
Batch 50/64 loss: -2.105600357055664
Batch 51/64 loss: -2.4889001846313477
Batch 52/64 loss: -2.4314942359924316
Batch 53/64 loss: -2.2053394317626953
Batch 54/64 loss: -2.234433174133301
Batch 55/64 loss: -1.937302589416504
Batch 56/64 loss: -2.09121036529541
Batch 57/64 loss: -2.2543373107910156
Batch 58/64 loss: -2.40621280670166
Batch 59/64 loss: -2.3285269737243652
Batch 60/64 loss: -2.309685707092285
Batch 61/64 loss: -2.454979419708252
Batch 62/64 loss: -1.8228492736816406
Batch 63/64 loss: -2.2934412956237793
Batch 64/64 loss: -6.467890739440918
Epoch 408  Train loss: -2.2355439690982593  Val loss: -2.5264617552871966
Epoch 409
-------------------------------
Batch 1/64 loss: -2.050790786743164
Batch 2/64 loss: -2.4329891204833984
Batch 3/64 loss: -2.208401679992676
Batch 4/64 loss: -2.0679922103881836
Batch 5/64 loss: -2.363161087036133
Batch 6/64 loss: -2.2157859802246094
Batch 7/64 loss: -2.2256059646606445
Batch 8/64 loss: -2.2674245834350586
Batch 9/64 loss: -1.2257061004638672
Batch 10/64 loss: -2.2141008377075195
Batch 11/64 loss: -2.2264938354492188
Batch 12/64 loss: -2.262566566467285
Batch 13/64 loss: -2.333841323852539
Batch 14/64 loss: -2.304936408996582
Batch 15/64 loss: -1.8811416625976562
Batch 16/64 loss: -2.244938850402832
Batch 17/64 loss: -2.5024571418762207
Batch 18/64 loss: -2.2678213119506836
Batch 19/64 loss: -2.464282989501953
Batch 20/64 loss: -2.3905625343322754
Batch 21/64 loss: -2.2576370239257812
Batch 22/64 loss: -2.2744903564453125
Batch 23/64 loss: -2.351748466491699
Batch 24/64 loss: -2.058286666870117
Batch 25/64 loss: -2.22125244140625
Batch 26/64 loss: -2.504075527191162
Batch 27/64 loss: -2.3533668518066406
Batch 28/64 loss: -2.338562488555908
Batch 29/64 loss: -2.1816816329956055
Batch 30/64 loss: -2.387571334838867
Batch 31/64 loss: -2.194204330444336
Batch 32/64 loss: -2.3248496055603027
Batch 33/64 loss: -2.2006263732910156
Batch 34/64 loss: -1.5482158660888672
Batch 35/64 loss: -1.9716434478759766
Batch 36/64 loss: -2.0417823791503906
Batch 37/64 loss: -2.3035926818847656
Batch 38/64 loss: -2.1920166015625
Batch 39/64 loss: -2.2975645065307617
Batch 40/64 loss: -2.1978683471679688
Batch 41/64 loss: -2.2160024642944336
Batch 42/64 loss: -2.184380531311035
Batch 43/64 loss: -2.136625289916992
Batch 44/64 loss: -2.3815174102783203
Batch 45/64 loss: -2.266084671020508
Batch 46/64 loss: -2.2077484130859375
Batch 47/64 loss: -2.2251510620117188
Batch 48/64 loss: -2.0956287384033203
Batch 49/64 loss: -2.2567176818847656
Batch 50/64 loss: -2.2703514099121094
Batch 51/64 loss: -2.3365068435668945
Batch 52/64 loss: -2.2890586853027344
Batch 53/64 loss: -2.4096126556396484
Batch 54/64 loss: -2.2815656661987305
Batch 55/64 loss: -1.9335880279541016
Batch 56/64 loss: -2.261155128479004
Batch 57/64 loss: -2.250826835632324
Batch 58/64 loss: -2.297398567199707
Batch 59/64 loss: -2.3636474609375
Batch 60/64 loss: -2.2932519912719727
Batch 61/64 loss: -1.4711360931396484
Batch 62/64 loss: -2.1421566009521484
Batch 63/64 loss: -1.9539260864257812
Batch 64/64 loss: -6.56301212310791
Epoch 409  Train loss: -2.255660161785051  Val loss: -2.513785857105583
Epoch 410
-------------------------------
Batch 1/64 loss: -2.3455724716186523
Batch 2/64 loss: -2.4297332763671875
Batch 3/64 loss: -2.236689567565918
Batch 4/64 loss: -2.3703155517578125
Batch 5/64 loss: -2.4399938583374023
Batch 6/64 loss: -2.321536064147949
Batch 7/64 loss: -2.3258471488952637
Batch 8/64 loss: -2.2934064865112305
Batch 9/64 loss: -2.0058937072753906
Batch 10/64 loss: -2.436800956726074
Batch 11/64 loss: -2.2772750854492188
Batch 12/64 loss: -2.4360761642456055
Batch 13/64 loss: -1.889796257019043
Batch 14/64 loss: -2.444639205932617
Batch 15/64 loss: -2.3278255462646484
Batch 16/64 loss: -1.9461450576782227
Batch 17/64 loss: -2.339418411254883
Batch 18/64 loss: -1.8695545196533203
Batch 19/64 loss: -2.146564483642578
Batch 20/64 loss: -2.3270115852355957
Batch 21/64 loss: -2.2248849868774414
Batch 22/64 loss: -2.054501533508301
Batch 23/64 loss: -1.4311590194702148
Batch 24/64 loss: -1.97662353515625
Batch 25/64 loss: -2.3597183227539062
Batch 26/64 loss: -2.217519760131836
Batch 27/64 loss: -2.311481475830078
Batch 28/64 loss: -2.143749237060547
Batch 29/64 loss: -2.255648612976074
Batch 30/64 loss: -2.223313331604004
Batch 31/64 loss: -2.2414684295654297
Batch 32/64 loss: -2.320925712585449
Batch 33/64 loss: -1.932692527770996
Batch 34/64 loss: -1.8515748977661133
Batch 35/64 loss: -2.300145149230957
Batch 36/64 loss: -2.0049819946289062
Batch 37/64 loss: -2.2958879470825195
Batch 38/64 loss: -1.6679115295410156
Batch 39/64 loss: -2.1313085556030273
Batch 40/64 loss: -1.8966617584228516
Batch 41/64 loss: -2.3582100868225098
Batch 42/64 loss: -2.278964042663574
Batch 43/64 loss: -2.291375160217285
Batch 44/64 loss: -2.400439739227295
Batch 45/64 loss: -2.306576728820801
Batch 46/64 loss: -2.096785545349121
Batch 47/64 loss: -2.3259525299072266
Batch 48/64 loss: -1.7421131134033203
Batch 49/64 loss: -2.0028305053710938
Batch 50/64 loss: -2.0150318145751953
Batch 51/64 loss: -2.354233741760254
Batch 52/64 loss: -1.7853221893310547
Batch 53/64 loss: -2.1834936141967773
Batch 54/64 loss: -1.9441843032836914
Batch 55/64 loss: -1.6613731384277344
Batch 56/64 loss: -1.7334957122802734
Batch 57/64 loss: -1.7488422393798828
Batch 58/64 loss: -2.0996503829956055
Batch 59/64 loss: -2.2623376846313477
Batch 60/64 loss: -2.0447444915771484
Batch 61/64 loss: -2.0225143432617188
Batch 62/64 loss: -2.2447242736816406
Batch 63/64 loss: -2.057284355163574
Batch 64/64 loss: -6.2744622230529785
Epoch 410  Train loss: -2.1916640019884297  Val loss: -2.318678524895632
Epoch 411
-------------------------------
Batch 1/64 loss: -2.0528554916381836
Batch 2/64 loss: -1.8201303482055664
Batch 3/64 loss: -1.9350357055664062
Batch 4/64 loss: -2.046992301940918
Batch 5/64 loss: -2.3077802658081055
Batch 6/64 loss: -1.336298942565918
Batch 7/64 loss: -1.5462331771850586
Batch 8/64 loss: -2.40482234954834
Batch 9/64 loss: -2.032952308654785
Batch 10/64 loss: -1.8949947357177734
Batch 11/64 loss: -1.7996034622192383
Batch 12/64 loss: -1.920994758605957
Batch 13/64 loss: -2.165224075317383
Batch 14/64 loss: -2.1102066040039062
Batch 15/64 loss: -2.2049694061279297
Batch 16/64 loss: -1.922994613647461
Batch 17/64 loss: -2.3424973487854004
Batch 18/64 loss: -2.2625036239624023
Batch 19/64 loss: -2.08469295501709
Batch 20/64 loss: -2.4108967781066895
Batch 21/64 loss: -2.0586042404174805
Batch 22/64 loss: -2.3165640830993652
Batch 23/64 loss: -1.9069223403930664
Batch 24/64 loss: -2.2951407432556152
Batch 25/64 loss: -2.0635318756103516
Batch 26/64 loss: -2.3305606842041016
Batch 27/64 loss: -2.2918758392333984
Batch 28/64 loss: -1.9075736999511719
Batch 29/64 loss: -1.7679481506347656
Batch 30/64 loss: -2.1662063598632812
Batch 31/64 loss: -1.9492607116699219
Batch 32/64 loss: -2.0246362686157227
Batch 33/64 loss: -2.2001075744628906
Batch 34/64 loss: -2.292233943939209
Batch 35/64 loss: -2.2075672149658203
Batch 36/64 loss: -2.1215667724609375
Batch 37/64 loss: -2.2277746200561523
Batch 38/64 loss: -1.849686622619629
Batch 39/64 loss: -2.078232765197754
Batch 40/64 loss: -1.7220573425292969
Batch 41/64 loss: -2.245486259460449
Batch 42/64 loss: -2.13763427734375
Batch 43/64 loss: -1.8139057159423828
Batch 44/64 loss: -2.3048782348632812
Batch 45/64 loss: -2.3992433547973633
Batch 46/64 loss: -1.945673942565918
Batch 47/64 loss: -2.147794723510742
Batch 48/64 loss: -1.9233293533325195
Batch 49/64 loss: -2.3095321655273438
Batch 50/64 loss: -2.276665687561035
Batch 51/64 loss: -1.8054847717285156
Batch 52/64 loss: -1.172755241394043
Batch 53/64 loss: -2.17950439453125
Batch 54/64 loss: -2.2284774780273438
Batch 55/64 loss: -2.3445324897766113
Batch 56/64 loss: -2.2470760345458984
Batch 57/64 loss: -2.2931156158447266
Batch 58/64 loss: -2.1391000747680664
Batch 59/64 loss: -1.936781883239746
Batch 60/64 loss: -1.7995080947875977
Batch 61/64 loss: -2.194056510925293
Batch 62/64 loss: -2.228074073791504
Batch 63/64 loss: -2.315328598022461
Batch 64/64 loss: -6.594051361083984
Epoch 411  Train loss: -2.128850331025965  Val loss: -2.433554226590186
Epoch 412
-------------------------------
Batch 1/64 loss: -1.9713029861450195
Batch 2/64 loss: -2.3412723541259766
Batch 3/64 loss: -2.1482410430908203
Batch 4/64 loss: -2.450042724609375
Batch 5/64 loss: -1.9062871932983398
Batch 6/64 loss: -1.9718093872070312
Batch 7/64 loss: -2.159642219543457
Batch 8/64 loss: -2.3091392517089844
Batch 9/64 loss: -2.28444766998291
Batch 10/64 loss: -2.363734722137451
Batch 11/64 loss: -2.2765016555786133
Batch 12/64 loss: -2.432690143585205
Batch 13/64 loss: -2.2972116470336914
Batch 14/64 loss: -1.8191766738891602
Batch 15/64 loss: -1.9021930694580078
Batch 16/64 loss: -2.202326774597168
Batch 17/64 loss: -1.9105825424194336
Batch 18/64 loss: -2.2436399459838867
Batch 19/64 loss: -2.3381576538085938
Batch 20/64 loss: -2.4139509201049805
Batch 21/64 loss: -2.230483055114746
Batch 22/64 loss: -2.2893762588500977
Batch 23/64 loss: -2.452116012573242
Batch 24/64 loss: -2.4477181434631348
Batch 25/64 loss: -1.9223127365112305
Batch 26/64 loss: -1.5121049880981445
Batch 27/64 loss: -2.3401780128479004
Batch 28/64 loss: -2.4837818145751953
Batch 29/64 loss: -2.2150650024414062
Batch 30/64 loss: -2.4109902381896973
Batch 31/64 loss: -2.3184261322021484
Batch 32/64 loss: -2.2164907455444336
Batch 33/64 loss: -2.376084804534912
Batch 34/64 loss: -2.2097787857055664
Batch 35/64 loss: -1.9300909042358398
Batch 36/64 loss: -2.121188163757324
Batch 37/64 loss: -2.3664722442626953
Batch 38/64 loss: -2.4296884536743164
Batch 39/64 loss: -2.3647079467773438
Batch 40/64 loss: -2.412400245666504
Batch 41/64 loss: -2.193988800048828
Batch 42/64 loss: -2.2731199264526367
Batch 43/64 loss: -2.4822802543640137
Batch 44/64 loss: -2.358457088470459
Batch 45/64 loss: -2.400092124938965
Batch 46/64 loss: -2.313286781311035
Batch 47/64 loss: -2.1071386337280273
Batch 48/64 loss: -2.434091567993164
Batch 49/64 loss: -2.389800548553467
Batch 50/64 loss: -2.2572879791259766
Batch 51/64 loss: -2.2240962982177734
Batch 52/64 loss: -2.4476981163024902
Batch 53/64 loss: -2.207451820373535
Batch 54/64 loss: -2.427621841430664
Batch 55/64 loss: -2.1038084030151367
Batch 56/64 loss: -2.1929807662963867
Batch 57/64 loss: -2.213810920715332
Batch 58/64 loss: -2.0137996673583984
Batch 59/64 loss: -2.2961626052856445
Batch 60/64 loss: -2.353900909423828
Batch 61/64 loss: -1.9053668975830078
Batch 62/64 loss: -0.8454990386962891
Batch 63/64 loss: -2.405674457550049
Batch 64/64 loss: -6.661908149719238
Epoch 412  Train loss: -2.2687945384605257  Val loss: -2.546015709945836
Epoch 413
-------------------------------
Batch 1/64 loss: -2.1077651977539062
Batch 2/64 loss: -2.0813474655151367
Batch 3/64 loss: -1.7773323059082031
Batch 4/64 loss: -2.3300094604492188
Batch 5/64 loss: -2.0271129608154297
Batch 6/64 loss: -2.5075573921203613
Batch 7/64 loss: -1.9908294677734375
Batch 8/64 loss: -2.255091667175293
Batch 9/64 loss: -2.4768924713134766
Batch 10/64 loss: -2.5210742950439453
Batch 11/64 loss: -2.330477237701416
Batch 12/64 loss: -2.0267553329467773
Batch 13/64 loss: -2.247317314147949
Batch 14/64 loss: -2.418600082397461
Batch 15/64 loss: -2.339491367340088
Batch 16/64 loss: -2.4873194694519043
Batch 17/64 loss: -2.175701141357422
Batch 18/64 loss: -2.344240188598633
Batch 19/64 loss: -2.4149718284606934
Batch 20/64 loss: -2.387308120727539
Batch 21/64 loss: -2.378312110900879
Batch 22/64 loss: -2.316709518432617
Batch 23/64 loss: -2.0510921478271484
Batch 24/64 loss: -2.444244861602783
Batch 25/64 loss: -2.514530658721924
Batch 26/64 loss: -1.9378070831298828
Batch 27/64 loss: -2.0243606567382812
Batch 28/64 loss: -2.5122904777526855
Batch 29/64 loss: -1.519331932067871
Batch 30/64 loss: -2.230463981628418
Batch 31/64 loss: -2.3651251792907715
Batch 32/64 loss: -2.0010528564453125
Batch 33/64 loss: -1.850419044494629
Batch 34/64 loss: -2.198086738586426
Batch 35/64 loss: -2.3799610137939453
Batch 36/64 loss: -2.1597604751586914
Batch 37/64 loss: -2.262247085571289
Batch 38/64 loss: -2.2735719680786133
Batch 39/64 loss: -2.441351890563965
Batch 40/64 loss: -2.3258018493652344
Batch 41/64 loss: -2.463290214538574
Batch 42/64 loss: -2.216729164123535
Batch 43/64 loss: -2.2455739974975586
Batch 44/64 loss: -2.0326662063598633
Batch 45/64 loss: -2.3571462631225586
Batch 46/64 loss: -2.0675811767578125
Batch 47/64 loss: -2.212858200073242
Batch 48/64 loss: -2.281322479248047
Batch 49/64 loss: -2.1243906021118164
Batch 50/64 loss: -1.9671783447265625
Batch 51/64 loss: -2.25799560546875
Batch 52/64 loss: -1.8421382904052734
Batch 53/64 loss: -2.053633689880371
Batch 54/64 loss: -2.1314287185668945
Batch 55/64 loss: -1.8964252471923828
Batch 56/64 loss: -2.1817150115966797
Batch 57/64 loss: -1.8918161392211914
Batch 58/64 loss: -2.335249900817871
Batch 59/64 loss: -2.0319976806640625
Batch 60/64 loss: -2.361079216003418
Batch 61/64 loss: -2.209695816040039
Batch 62/64 loss: -1.8711557388305664
Batch 63/64 loss: -2.202322006225586
Batch 64/64 loss: -6.319829940795898
Epoch 413  Train loss: -2.249552603328929  Val loss: -2.2255875498978135
Epoch 414
-------------------------------
Batch 1/64 loss: -2.3062877655029297
Batch 2/64 loss: -2.0951671600341797
Batch 3/64 loss: -2.128830909729004
Batch 4/64 loss: -2.157369613647461
Batch 5/64 loss: -1.944575309753418
Batch 6/64 loss: -2.3852272033691406
Batch 7/64 loss: -2.350979804992676
Batch 8/64 loss: -1.8910188674926758
Batch 9/64 loss: -2.029489517211914
Batch 10/64 loss: -2.434584617614746
Batch 11/64 loss: -2.2903308868408203
Batch 12/64 loss: -2.3079118728637695
Batch 13/64 loss: -2.0195131301879883
Batch 14/64 loss: -2.2840757369995117
Batch 15/64 loss: -2.286074638366699
Batch 16/64 loss: -2.30106782913208
Batch 17/64 loss: -2.274521827697754
Batch 18/64 loss: -2.1972198486328125
Batch 19/64 loss: -2.0693225860595703
Batch 20/64 loss: -1.8790245056152344
Batch 21/64 loss: -2.349973678588867
Batch 22/64 loss: -1.8615350723266602
Batch 23/64 loss: -2.425877571105957
Batch 24/64 loss: -1.826756477355957
Batch 25/64 loss: -1.2466726303100586
Batch 26/64 loss: -2.0158157348632812
Batch 27/64 loss: -2.0868682861328125
Batch 28/64 loss: -2.2906265258789062
Batch 29/64 loss: -2.1046018600463867
Batch 30/64 loss: -1.692112922668457
Batch 31/64 loss: -2.2120285034179688
Batch 32/64 loss: -2.275148391723633
Batch 33/64 loss: -2.2754077911376953
Batch 34/64 loss: -1.254990577697754
Batch 35/64 loss: -2.24251651763916
Batch 36/64 loss: -1.8440418243408203
Batch 37/64 loss: -2.3408846855163574
Batch 38/64 loss: -2.24099063873291
Batch 39/64 loss: -2.2946815490722656
Batch 40/64 loss: -1.8388051986694336
Batch 41/64 loss: -2.1026620864868164
Batch 42/64 loss: -2.365755081176758
Batch 43/64 loss: -1.9166755676269531
Batch 44/64 loss: -2.220879554748535
Batch 45/64 loss: -1.9423446655273438
Batch 46/64 loss: -2.3391528129577637
Batch 47/64 loss: -1.939539909362793
Batch 48/64 loss: -1.853785514831543
Batch 49/64 loss: -2.3277535438537598
Batch 50/64 loss: -1.8327016830444336
Batch 51/64 loss: -1.8372726440429688
Batch 52/64 loss: -2.3346405029296875
Batch 53/64 loss: -2.2419519424438477
Batch 54/64 loss: -2.065164566040039
Batch 55/64 loss: -2.368068218231201
Batch 56/64 loss: -2.324164867401123
Batch 57/64 loss: -1.669804573059082
Batch 58/64 loss: -2.1785879135131836
Batch 59/64 loss: -2.390230178833008
Batch 60/64 loss: -1.1687593460083008
Batch 61/64 loss: -2.099367141723633
Batch 62/64 loss: -2.4737319946289062
Batch 63/64 loss: -2.0845232009887695
Batch 64/64 loss: -6.410726070404053
Epoch 414  Train loss: -2.1527606608820897  Val loss: -2.4129061354804286
Epoch 415
-------------------------------
Batch 1/64 loss: -2.191361427307129
Batch 2/64 loss: -1.8686161041259766
Batch 3/64 loss: -2.1565380096435547
Batch 4/64 loss: -2.1427459716796875
Batch 5/64 loss: -2.2818593978881836
Batch 6/64 loss: -2.4172778129577637
Batch 7/64 loss: -2.3303680419921875
Batch 8/64 loss: -2.420933246612549
Batch 9/64 loss: -1.8445215225219727
Batch 10/64 loss: -1.7082405090332031
Batch 11/64 loss: -1.881068229675293
Batch 12/64 loss: -2.189967155456543
Batch 13/64 loss: -2.3431291580200195
Batch 14/64 loss: -2.1284713745117188
Batch 15/64 loss: -2.2587108612060547
Batch 16/64 loss: -2.175790786743164
Batch 17/64 loss: -1.7301216125488281
Batch 18/64 loss: -1.0060415267944336
Batch 19/64 loss: -2.4862565994262695
Batch 20/64 loss: -1.981318473815918
Batch 21/64 loss: -2.264629364013672
Batch 22/64 loss: -1.6663618087768555
Batch 23/64 loss: -1.6492443084716797
Batch 24/64 loss: -2.122441291809082
Batch 25/64 loss: -2.4155311584472656
Batch 26/64 loss: -1.9108543395996094
Batch 27/64 loss: -2.116787910461426
Batch 28/64 loss: -2.3283004760742188
Batch 29/64 loss: -1.7039995193481445
Batch 30/64 loss: -2.082150459289551
Batch 31/64 loss: -2.209383964538574
Batch 32/64 loss: -2.227491855621338
Batch 33/64 loss: -2.303694725036621
Batch 34/64 loss: -2.2721176147460938
Batch 35/64 loss: -2.1095762252807617
Batch 36/64 loss: -2.287161350250244
Batch 37/64 loss: -2.3482823371887207
Batch 38/64 loss: -1.381546974182129
Batch 39/64 loss: -2.08431339263916
Batch 40/64 loss: -2.2103443145751953
Batch 41/64 loss: -1.9100160598754883
Batch 42/64 loss: -2.168140411376953
Batch 43/64 loss: -2.1012115478515625
Batch 44/64 loss: -2.393200397491455
Batch 45/64 loss: -2.444373607635498
Batch 46/64 loss: -2.1194839477539062
Batch 47/64 loss: -2.376288414001465
Batch 48/64 loss: -2.1795482635498047
Batch 49/64 loss: -2.3858985900878906
Batch 50/64 loss: -2.2160520553588867
Batch 51/64 loss: -1.9561681747436523
Batch 52/64 loss: -2.324812889099121
Batch 53/64 loss: -2.121596336364746
Batch 54/64 loss: -2.198953628540039
Batch 55/64 loss: -2.2269644737243652
Batch 56/64 loss: -2.2909116744995117
Batch 57/64 loss: -1.4553565979003906
Batch 58/64 loss: -2.0208826065063477
Batch 59/64 loss: -2.316342353820801
Batch 60/64 loss: -2.4413208961486816
Batch 61/64 loss: -2.3180527687072754
Batch 62/64 loss: -2.1836671829223633
Batch 63/64 loss: -2.3660483360290527
Batch 64/64 loss: -6.544764995574951
Epoch 415  Train loss: -2.175081038007549  Val loss: -2.554968856863959
Epoch 416
-------------------------------
Batch 1/64 loss: -2.2494497299194336
Batch 2/64 loss: -2.2127065658569336
Batch 3/64 loss: -2.3941755294799805
Batch 4/64 loss: -2.3629918098449707
Batch 5/64 loss: -2.009521484375
Batch 6/64 loss: -2.217611312866211
Batch 7/64 loss: -1.7688846588134766
Batch 8/64 loss: -2.3322181701660156
Batch 9/64 loss: -1.5098962783813477
Batch 10/64 loss: -1.9923744201660156
Batch 11/64 loss: -1.6405935287475586
Batch 12/64 loss: -1.9052228927612305
Batch 13/64 loss: -2.218667984008789
Batch 14/64 loss: -2.1351099014282227
Batch 15/64 loss: -2.215579032897949
Batch 16/64 loss: -1.9967660903930664
Batch 17/64 loss: -2.200929641723633
Batch 18/64 loss: -1.8758211135864258
Batch 19/64 loss: -2.2621231079101562
Batch 20/64 loss: -2.177927017211914
Batch 21/64 loss: -2.0202693939208984
Batch 22/64 loss: -2.4597291946411133
Batch 23/64 loss: -2.302285671234131
Batch 24/64 loss: -1.7964000701904297
Batch 25/64 loss: -1.1369342803955078
Batch 26/64 loss: -2.353616714477539
Batch 27/64 loss: -2.308464527130127
Batch 28/64 loss: -2.237213134765625
Batch 29/64 loss: -2.308444023132324
Batch 30/64 loss: -2.3079147338867188
Batch 31/64 loss: -2.086935043334961
Batch 32/64 loss: -2.254115104675293
Batch 33/64 loss: -2.299572467803955
Batch 34/64 loss: -2.3581104278564453
Batch 35/64 loss: -2.1684646606445312
Batch 36/64 loss: -2.2591371536254883
Batch 37/64 loss: -2.3600878715515137
Batch 38/64 loss: -2.172213554382324
Batch 39/64 loss: -2.0523300170898438
Batch 40/64 loss: -2.1654319763183594
Batch 41/64 loss: -2.291109085083008
Batch 42/64 loss: -1.9798097610473633
Batch 43/64 loss: -2.2543087005615234
Batch 44/64 loss: -2.0990514755249023
Batch 45/64 loss: -2.1949872970581055
Batch 46/64 loss: -2.2277917861938477
Batch 47/64 loss: -2.3119192123413086
Batch 48/64 loss: -2.343578815460205
Batch 49/64 loss: -2.2553892135620117
Batch 50/64 loss: -2.2518997192382812
Batch 51/64 loss: -2.224180221557617
Batch 52/64 loss: -1.755406379699707
Batch 53/64 loss: -2.3718652725219727
Batch 54/64 loss: -2.2195968627929688
Batch 55/64 loss: -1.9661855697631836
Batch 56/64 loss: -2.5118613243103027
Batch 57/64 loss: -2.4983105659484863
Batch 58/64 loss: -2.2997522354125977
Batch 59/64 loss: -2.454559803009033
Batch 60/64 loss: -1.5966777801513672
Batch 61/64 loss: -2.3689961433410645
Batch 62/64 loss: -2.3464584350585938
Batch 63/64 loss: -1.623941421508789
Batch 64/64 loss: -6.520745277404785
Epoch 416  Train loss: -2.202736256169338  Val loss: -2.6207068531783584
Epoch 417
-------------------------------
Batch 1/64 loss: -2.1924076080322266
Batch 2/64 loss: -2.2449493408203125
Batch 3/64 loss: -2.3894920349121094
Batch 4/64 loss: -2.1815080642700195
Batch 5/64 loss: -1.9505023956298828
Batch 6/64 loss: -2.2053089141845703
Batch 7/64 loss: -2.2220325469970703
Batch 8/64 loss: -2.39630126953125
Batch 9/64 loss: -2.2362842559814453
Batch 10/64 loss: -2.2995681762695312
Batch 11/64 loss: -2.0059642791748047
Batch 12/64 loss: -0.9416713714599609
Batch 13/64 loss: -2.1974077224731445
Batch 14/64 loss: -1.89593505859375
Batch 15/64 loss: -2.2725915908813477
Batch 16/64 loss: -1.9751386642456055
Batch 17/64 loss: -2.4081978797912598
Batch 18/64 loss: -2.174571990966797
Batch 19/64 loss: -2.061579704284668
Batch 20/64 loss: -2.3701086044311523
Batch 21/64 loss: -2.2360801696777344
Batch 22/64 loss: -2.0167551040649414
Batch 23/64 loss: -2.0871400833129883
Batch 24/64 loss: -2.161407470703125
Batch 25/64 loss: -2.331559181213379
Batch 26/64 loss: -2.011969566345215
Batch 27/64 loss: -2.107602119445801
Batch 28/64 loss: -2.274961471557617
Batch 29/64 loss: -2.1193227767944336
Batch 30/64 loss: -2.229869842529297
Batch 31/64 loss: -2.325162887573242
Batch 32/64 loss: -0.9761438369750977
Batch 33/64 loss: -2.275019645690918
Batch 34/64 loss: -2.08236026763916
Batch 35/64 loss: -1.7954339981079102
Batch 36/64 loss: -2.010286331176758
Batch 37/64 loss: -1.117462158203125
Batch 38/64 loss: -2.240170478820801
Batch 39/64 loss: -2.0894718170166016
Batch 40/64 loss: -2.3023366928100586
Batch 41/64 loss: -2.35103702545166
Batch 42/64 loss: -2.1750402450561523
Batch 43/64 loss: -1.7746858596801758
Batch 44/64 loss: -1.4662752151489258
Batch 45/64 loss: -2.3323183059692383
Batch 46/64 loss: -2.350296974182129
Batch 47/64 loss: -1.6306848526000977
Batch 48/64 loss: -1.9504632949829102
Batch 49/64 loss: -2.0652294158935547
Batch 50/64 loss: -0.8822603225708008
Batch 51/64 loss: -1.6456146240234375
Batch 52/64 loss: -1.8493146896362305
Batch 53/64 loss: -1.1914958953857422
Batch 54/64 loss: -1.6785650253295898
Batch 55/64 loss: -2.0190963745117188
Batch 56/64 loss: -2.006096839904785
Batch 57/64 loss: -1.683699607849121
Batch 58/64 loss: -1.7879114151000977
Batch 59/64 loss: -1.7738304138183594
Batch 60/64 loss: -1.4613819122314453
Batch 61/64 loss: -2.288360118865967
Batch 62/64 loss: -0.9071969985961914
Batch 63/64 loss: -1.9789905548095703
Batch 64/64 loss: -6.186046600341797
Epoch 417  Train loss: -2.028257542030484  Val loss: -1.9351327771583373
Epoch 418
-------------------------------
Batch 1/64 loss: -1.9260053634643555
Batch 2/64 loss: -1.5789508819580078
Batch 3/64 loss: -1.9077224731445312
Batch 4/64 loss: -1.791947364807129
Batch 5/64 loss: -1.616250991821289
Batch 6/64 loss: -1.7139911651611328
Batch 7/64 loss: -1.9518804550170898
Batch 8/64 loss: -1.2629833221435547
Batch 9/64 loss: -1.821925163269043
Batch 10/64 loss: -1.7958707809448242
Batch 11/64 loss: -1.9361906051635742
Batch 12/64 loss: -1.739048957824707
Batch 13/64 loss: -1.7576141357421875
Batch 14/64 loss: -2.013983726501465
Batch 15/64 loss: -1.1434593200683594
Batch 16/64 loss: -0.7184982299804688
Batch 17/64 loss: -2.119227409362793
Batch 18/64 loss: -1.9234275817871094
Batch 19/64 loss: -2.0448875427246094
Batch 20/64 loss: -2.113300323486328
Batch 21/64 loss: -2.288900375366211
Batch 22/64 loss: -2.407223701477051
Batch 23/64 loss: -1.8709526062011719
Batch 24/64 loss: -2.3041305541992188
Batch 25/64 loss: -2.153789520263672
Batch 26/64 loss: -1.945047378540039
Batch 27/64 loss: -1.9198179244995117
Batch 28/64 loss: -1.9080886840820312
Batch 29/64 loss: -2.14205265045166
Batch 30/64 loss: -2.3035459518432617
Batch 31/64 loss: -2.268467903137207
Batch 32/64 loss: -2.2308883666992188
Batch 33/64 loss: -2.1565237045288086
Batch 34/64 loss: -2.1933364868164062
Batch 35/64 loss: -2.11538028717041
Batch 36/64 loss: -2.210137367248535
Batch 37/64 loss: -2.0902481079101562
Batch 38/64 loss: -2.0759477615356445
Batch 39/64 loss: -2.062811851501465
Batch 40/64 loss: -1.980245590209961
Batch 41/64 loss: -2.1984376907348633
Batch 42/64 loss: -2.327315330505371
Batch 43/64 loss: -2.18814754486084
Batch 44/64 loss: -2.0286054611206055
Batch 45/64 loss: -2.397477626800537
Batch 46/64 loss: -2.0393714904785156
Batch 47/64 loss: -1.8177566528320312
Batch 48/64 loss: -1.7293157577514648
Batch 49/64 loss: -2.228731155395508
Batch 50/64 loss: -1.4785566329956055
Batch 51/64 loss: -2.1403141021728516
Batch 52/64 loss: -2.3780927658081055
Batch 53/64 loss: -1.6976556777954102
Batch 54/64 loss: -2.302676200866699
Batch 55/64 loss: -2.247873306274414
Batch 56/64 loss: -2.147740364074707
Batch 57/64 loss: -1.6573047637939453
Batch 58/64 loss: -2.124905586242676
Batch 59/64 loss: -2.3998661041259766
Batch 60/64 loss: -1.8777828216552734
Batch 61/64 loss: -2.227418899536133
Batch 62/64 loss: -2.28023624420166
Batch 63/64 loss: -2.285956382751465
Batch 64/64 loss: -6.4761762619018555
Epoch 418  Train loss: -2.048052914937337  Val loss: -2.471718149086864
Epoch 419
-------------------------------
Batch 1/64 loss: -2.2236766815185547
Batch 2/64 loss: -2.256742477416992
Batch 3/64 loss: -2.1472644805908203
Batch 4/64 loss: -2.1438207626342773
Batch 5/64 loss: -2.038097381591797
Batch 6/64 loss: -1.5819196701049805
Batch 7/64 loss: -1.8878440856933594
Batch 8/64 loss: -2.0249109268188477
Batch 9/64 loss: -2.049710273742676
Batch 10/64 loss: -1.7678852081298828
Batch 11/64 loss: -1.3817853927612305
Batch 12/64 loss: -2.2490644454956055
Batch 13/64 loss: -2.2297325134277344
Batch 14/64 loss: -2.27200984954834
Batch 15/64 loss: -1.8803634643554688
Batch 16/64 loss: -2.0897045135498047
Batch 17/64 loss: -2.3458242416381836
Batch 18/64 loss: -2.2794852256774902
Batch 19/64 loss: -2.2188901901245117
Batch 20/64 loss: -2.174549102783203
Batch 21/64 loss: -2.2005014419555664
Batch 22/64 loss: -1.9891271591186523
Batch 23/64 loss: -2.2947912216186523
Batch 24/64 loss: -2.2497949600219727
Batch 25/64 loss: -2.1808061599731445
Batch 26/64 loss: -2.330791473388672
Batch 27/64 loss: -2.3754758834838867
Batch 28/64 loss: -2.3066720962524414
Batch 29/64 loss: -2.5158400535583496
Batch 30/64 loss: -2.182992935180664
Batch 31/64 loss: -2.2269697189331055
Batch 32/64 loss: -2.2417993545532227
Batch 33/64 loss: -2.0630264282226562
Batch 34/64 loss: -2.1018552780151367
Batch 35/64 loss: -2.0246458053588867
Batch 36/64 loss: -2.0805511474609375
Batch 37/64 loss: -2.014667510986328
Batch 38/64 loss: -2.0208568572998047
Batch 39/64 loss: -1.5816917419433594
Batch 40/64 loss: -2.056947708129883
Batch 41/64 loss: -2.1005373001098633
Batch 42/64 loss: -2.102757453918457
Batch 43/64 loss: -2.326064109802246
Batch 44/64 loss: -2.2704391479492188
Batch 45/64 loss: -2.281622886657715
Batch 46/64 loss: -2.271620750427246
Batch 47/64 loss: -2.249476432800293
Batch 48/64 loss: -2.2466564178466797
Batch 49/64 loss: -2.0572996139526367
Batch 50/64 loss: -2.141216278076172
Batch 51/64 loss: -0.6768779754638672
Batch 52/64 loss: -2.169931411743164
Batch 53/64 loss: -2.325809955596924
Batch 54/64 loss: -2.112964630126953
Batch 55/64 loss: -2.3233375549316406
Batch 56/64 loss: -2.2437009811401367
Batch 57/64 loss: -1.9085197448730469
Batch 58/64 loss: -2.2775559425354004
Batch 59/64 loss: -1.3718233108520508
Batch 60/64 loss: -1.9093313217163086
Batch 61/64 loss: -1.1945123672485352
Batch 62/64 loss: -1.5571680068969727
Batch 63/64 loss: -2.178187370300293
Batch 64/64 loss: -5.531464576721191
Epoch 419  Train loss: -2.1133975720873064  Val loss: -2.358700585119503
Epoch 420
-------------------------------
Batch 1/64 loss: -2.1614294052124023
Batch 2/64 loss: -2.315249443054199
Batch 3/64 loss: -1.921513557434082
Batch 4/64 loss: -1.5885772705078125
Batch 5/64 loss: -1.7648286819458008
Batch 6/64 loss: -2.2932991981506348
Batch 7/64 loss: -2.1836700439453125
Batch 8/64 loss: -2.2827625274658203
Batch 9/64 loss: -2.0594348907470703
Batch 10/64 loss: -2.0734786987304688
Batch 11/64 loss: -1.9767704010009766
Batch 12/64 loss: -2.15081787109375
Batch 13/64 loss: -2.3701133728027344
Batch 14/64 loss: -1.9846506118774414
Batch 15/64 loss: -2.172534942626953
Batch 16/64 loss: -2.3136444091796875
Batch 17/64 loss: -2.275798797607422
Batch 18/64 loss: -2.285183906555176
Batch 19/64 loss: -2.391704559326172
Batch 20/64 loss: -1.9833984375
Batch 21/64 loss: -2.338587760925293
Batch 22/64 loss: -1.9296684265136719
Batch 23/64 loss: -2.177504539489746
Batch 24/64 loss: -2.2422609329223633
Batch 25/64 loss: -1.7466344833374023
Batch 26/64 loss: -2.138054847717285
Batch 27/64 loss: -2.4766435623168945
Batch 28/64 loss: -1.0775938034057617
Batch 29/64 loss: -1.745162010192871
Batch 30/64 loss: -1.5120315551757812
Batch 31/64 loss: -2.1026220321655273
Batch 32/64 loss: -2.301083564758301
Batch 33/64 loss: -2.148634910583496
Batch 34/64 loss: -2.111882209777832
Batch 35/64 loss: -1.4717731475830078
Batch 36/64 loss: -2.2581911087036133
Batch 37/64 loss: -2.066481590270996
Batch 38/64 loss: -2.1394615173339844
Batch 39/64 loss: -1.8954744338989258
Batch 40/64 loss: -2.0297927856445312
Batch 41/64 loss: -1.3868331909179688
Batch 42/64 loss: -2.0646181106567383
Batch 43/64 loss: -2.360736846923828
Batch 44/64 loss: -2.3148937225341797
Batch 45/64 loss: -2.3165454864501953
Batch 46/64 loss: -2.131007194519043
Batch 47/64 loss: -2.038534164428711
Batch 48/64 loss: -2.3223514556884766
Batch 49/64 loss: -1.8041610717773438
Batch 50/64 loss: -2.074319839477539
Batch 51/64 loss: -1.9987010955810547
Batch 52/64 loss: -1.472599983215332
Batch 53/64 loss: -1.581517219543457
Batch 54/64 loss: -2.277346611022949
Batch 55/64 loss: -1.9975461959838867
Batch 56/64 loss: -2.3241777420043945
Batch 57/64 loss: -2.238093376159668
Batch 58/64 loss: -2.0762386322021484
Batch 59/64 loss: -1.9261293411254883
Batch 60/64 loss: -2.3295154571533203
Batch 61/64 loss: -2.176485061645508
Batch 62/64 loss: -2.029033660888672
Batch 63/64 loss: -2.276766777038574
Batch 64/64 loss: -6.501236438751221
Epoch 420  Train loss: -2.11533301671346  Val loss: -2.547759210121181
Epoch 421
-------------------------------
Batch 1/64 loss: -2.1931285858154297
Batch 2/64 loss: -2.2450056076049805
Batch 3/64 loss: -2.32845401763916
Batch 4/64 loss: -2.1748790740966797
Batch 5/64 loss: -2.31331729888916
Batch 6/64 loss: -2.353179931640625
Batch 7/64 loss: -2.1972227096557617
Batch 8/64 loss: -2.3426895141601562
Batch 9/64 loss: -2.4307680130004883
Batch 10/64 loss: -2.3657093048095703
Batch 11/64 loss: -2.437556266784668
Batch 12/64 loss: -2.3976187705993652
Batch 13/64 loss: -2.0802717208862305
Batch 14/64 loss: -2.2710886001586914
Batch 15/64 loss: -2.320026397705078
Batch 16/64 loss: -2.3071117401123047
Batch 17/64 loss: -2.4332618713378906
Batch 18/64 loss: -1.7754497528076172
Batch 19/64 loss: -2.187119483947754
Batch 20/64 loss: -2.41156005859375
Batch 21/64 loss: -2.005812644958496
Batch 22/64 loss: -2.322697162628174
Batch 23/64 loss: -2.3571901321411133
Batch 24/64 loss: -2.3575987815856934
Batch 25/64 loss: -1.899531364440918
Batch 26/64 loss: -2.1317739486694336
Batch 27/64 loss: -2.3122730255126953
Batch 28/64 loss: -1.5502376556396484
Batch 29/64 loss: -2.118124008178711
Batch 30/64 loss: -2.156352996826172
Batch 31/64 loss: -2.184149742126465
Batch 32/64 loss: -1.9653873443603516
Batch 33/64 loss: -2.4149723052978516
Batch 34/64 loss: -2.291921615600586
Batch 35/64 loss: -2.358523368835449
Batch 36/64 loss: -2.129701614379883
Batch 37/64 loss: -2.055243492126465
Batch 38/64 loss: -1.7526264190673828
Batch 39/64 loss: -2.476795196533203
Batch 40/64 loss: -2.298086166381836
Batch 41/64 loss: -2.1713972091674805
Batch 42/64 loss: -2.386559009552002
Batch 43/64 loss: -2.3808794021606445
Batch 44/64 loss: -2.1952924728393555
Batch 45/64 loss: -2.010472297668457
Batch 46/64 loss: -1.0493965148925781
Batch 47/64 loss: -2.304279327392578
Batch 48/64 loss: -2.398165702819824
Batch 49/64 loss: -2.2690649032592773
Batch 50/64 loss: -2.2559194564819336
Batch 51/64 loss: -2.31396484375
Batch 52/64 loss: -1.9504432678222656
Batch 53/64 loss: -2.299468994140625
Batch 54/64 loss: -2.322956085205078
Batch 55/64 loss: -2.113539695739746
Batch 56/64 loss: -1.9935712814331055
Batch 57/64 loss: -2.2104759216308594
Batch 58/64 loss: -2.3485450744628906
Batch 59/64 loss: -2.1751413345336914
Batch 60/64 loss: -2.39919376373291
Batch 61/64 loss: -1.8171262741088867
Batch 62/64 loss: -2.2444019317626953
Batch 63/64 loss: -2.372833251953125
Batch 64/64 loss: -6.536781311035156
Epoch 421  Train loss: -2.252393595377604  Val loss: -2.558216553783089
Epoch 422
-------------------------------
Batch 1/64 loss: -2.246305465698242
Batch 2/64 loss: -2.3436450958251953
Batch 3/64 loss: -2.3191680908203125
Batch 4/64 loss: -2.1884994506835938
Batch 5/64 loss: -1.5966501235961914
Batch 6/64 loss: -2.4421563148498535
Batch 7/64 loss: -2.4688549041748047
Batch 8/64 loss: -2.1237010955810547
Batch 9/64 loss: -2.5147290229797363
Batch 10/64 loss: -2.141094207763672
Batch 11/64 loss: -2.2545528411865234
Batch 12/64 loss: -2.317498207092285
Batch 13/64 loss: -2.2321462631225586
Batch 14/64 loss: -2.2024946212768555
Batch 15/64 loss: -2.349245071411133
Batch 16/64 loss: -1.540475845336914
Batch 17/64 loss: -2.232177734375
Batch 18/64 loss: -2.3659706115722656
Batch 19/64 loss: -1.9818229675292969
Batch 20/64 loss: -2.42618465423584
Batch 21/64 loss: -2.283784866333008
Batch 22/64 loss: -2.3230648040771484
Batch 23/64 loss: -2.350086212158203
Batch 24/64 loss: -2.2460193634033203
Batch 25/64 loss: -2.2427425384521484
Batch 26/64 loss: -2.3193359375
Batch 27/64 loss: -2.4904088973999023
Batch 28/64 loss: -2.0492544174194336
Batch 29/64 loss: -2.324871063232422
Batch 30/64 loss: -2.359333038330078
Batch 31/64 loss: -2.265176773071289
Batch 32/64 loss: -2.410797119140625
Batch 33/64 loss: -2.2120046615600586
Batch 34/64 loss: -2.204408645629883
Batch 35/64 loss: -2.320096969604492
Batch 36/64 loss: -2.212122917175293
Batch 37/64 loss: -1.831979751586914
Batch 38/64 loss: -2.3078136444091797
Batch 39/64 loss: -2.282557487487793
Batch 40/64 loss: -2.1035938262939453
Batch 41/64 loss: -1.9757795333862305
Batch 42/64 loss: -2.280074119567871
Batch 43/64 loss: -2.4096083641052246
Batch 44/64 loss: -2.4744768142700195
Batch 45/64 loss: -2.141289710998535
Batch 46/64 loss: -2.0472545623779297
Batch 47/64 loss: -2.1767654418945312
Batch 48/64 loss: -1.5620059967041016
Batch 49/64 loss: -2.349942207336426
Batch 50/64 loss: -2.191556930541992
Batch 51/64 loss: -2.392972946166992
Batch 52/64 loss: -2.0882349014282227
Batch 53/64 loss: -1.969130516052246
Batch 54/64 loss: -2.2466630935668945
Batch 55/64 loss: -2.3336143493652344
Batch 56/64 loss: -2.19301700592041
Batch 57/64 loss: -2.3501338958740234
Batch 58/64 loss: -2.4705991744995117
Batch 59/64 loss: -2.17655086517334
Batch 60/64 loss: -2.22805118560791
Batch 61/64 loss: -2.242001533508301
Batch 62/64 loss: -2.2525129318237305
Batch 63/64 loss: -1.9766778945922852
Batch 64/64 loss: -6.41396951675415
Epoch 422  Train loss: -2.2708426138933966  Val loss: -2.42804774385957
Epoch 423
-------------------------------
Batch 1/64 loss: -2.039881706237793
Batch 2/64 loss: -2.1683883666992188
Batch 3/64 loss: -2.2487478256225586
Batch 4/64 loss: -2.3571724891662598
Batch 5/64 loss: -2.498694896697998
Batch 6/64 loss: -2.1810293197631836
Batch 7/64 loss: -2.2290477752685547
Batch 8/64 loss: -2.151029586791992
Batch 9/64 loss: -2.2575178146362305
Batch 10/64 loss: -2.0463037490844727
Batch 11/64 loss: -2.1381025314331055
Batch 12/64 loss: -1.8881816864013672
Batch 13/64 loss: -2.158243179321289
Batch 14/64 loss: -1.845602035522461
Batch 15/64 loss: -2.1434078216552734
Batch 16/64 loss: -1.7015314102172852
Batch 17/64 loss: -2.331817626953125
Batch 18/64 loss: -2.3172483444213867
Batch 19/64 loss: -2.1400041580200195
Batch 20/64 loss: -2.150181770324707
Batch 21/64 loss: -2.1613216400146484
Batch 22/64 loss: -2.2764081954956055
Batch 23/64 loss: -2.1469545364379883
Batch 24/64 loss: -2.3964409828186035
Batch 25/64 loss: -2.1269683837890625
Batch 26/64 loss: -2.158209800720215
Batch 27/64 loss: -2.318331718444824
Batch 28/64 loss: -2.2032365798950195
Batch 29/64 loss: -1.9983139038085938
Batch 30/64 loss: -2.0831966400146484
Batch 31/64 loss: -2.369234085083008
Batch 32/64 loss: -1.2129344940185547
Batch 33/64 loss: -2.3319082260131836
Batch 34/64 loss: -2.070558547973633
Batch 35/64 loss: -2.2216081619262695
Batch 36/64 loss: -2.274026870727539
Batch 37/64 loss: -2.2489185333251953
Batch 38/64 loss: -2.4257001876831055
Batch 39/64 loss: -1.860377311706543
Batch 40/64 loss: -1.7115840911865234
Batch 41/64 loss: -2.033954620361328
Batch 42/64 loss: -2.2943992614746094
Batch 43/64 loss: -2.025975227355957
Batch 44/64 loss: -2.1504573822021484
Batch 45/64 loss: -2.355515956878662
Batch 46/64 loss: -2.088245391845703
Batch 47/64 loss: -1.9708175659179688
Batch 48/64 loss: -1.8702678680419922
Batch 49/64 loss: -2.2878684997558594
Batch 50/64 loss: -2.344496726989746
Batch 51/64 loss: -2.109145164489746
Batch 52/64 loss: -2.325392723083496
Batch 53/64 loss: -2.12979793548584
Batch 54/64 loss: -1.8804035186767578
Batch 55/64 loss: -1.9466524124145508
Batch 56/64 loss: -2.1745452880859375
Batch 57/64 loss: -2.126201629638672
Batch 58/64 loss: -2.3528952598571777
Batch 59/64 loss: -2.197941780090332
Batch 60/64 loss: -2.012814521789551
Batch 61/64 loss: -2.3341126441955566
Batch 62/64 loss: -2.320394515991211
Batch 63/64 loss: -2.159749984741211
Batch 64/64 loss: -6.408124923706055
Epoch 423  Train loss: -2.194298142077876  Val loss: -2.455702031191272
Epoch 424
-------------------------------
Batch 1/64 loss: -2.285428047180176
Batch 2/64 loss: -2.3290176391601562
Batch 3/64 loss: -2.282703399658203
Batch 4/64 loss: -1.7564325332641602
Batch 5/64 loss: -1.666341781616211
Batch 6/64 loss: -1.6456193923950195
Batch 7/64 loss: -2.282388687133789
Batch 8/64 loss: -2.368828773498535
Batch 9/64 loss: -2.2025489807128906
Batch 10/64 loss: -2.359738349914551
Batch 11/64 loss: -1.3284082412719727
Batch 12/64 loss: -2.065837860107422
Batch 13/64 loss: -2.085759162902832
Batch 14/64 loss: -2.296462059020996
Batch 15/64 loss: -2.3029184341430664
Batch 16/64 loss: -2.3128933906555176
Batch 17/64 loss: -2.1062870025634766
Batch 18/64 loss: -2.2203054428100586
Batch 19/64 loss: -2.279862403869629
Batch 20/64 loss: -1.996866226196289
Batch 21/64 loss: -2.180561065673828
Batch 22/64 loss: -2.3124799728393555
Batch 23/64 loss: -2.3014297485351562
Batch 24/64 loss: -2.293424606323242
Batch 25/64 loss: -2.0402355194091797
Batch 26/64 loss: -2.286348342895508
Batch 27/64 loss: -2.2569007873535156
Batch 28/64 loss: -2.362577438354492
Batch 29/64 loss: -2.290882110595703
Batch 30/64 loss: -2.3043928146362305
Batch 31/64 loss: -1.8795280456542969
Batch 32/64 loss: -2.144375801086426
Batch 33/64 loss: -2.410031318664551
Batch 34/64 loss: -2.1521081924438477
Batch 35/64 loss: -2.224381446838379
Batch 36/64 loss: -2.445431709289551
Batch 37/64 loss: -2.2243614196777344
Batch 38/64 loss: -2.089848518371582
Batch 39/64 loss: -2.4759960174560547
Batch 40/64 loss: -2.4861178398132324
Batch 41/64 loss: -2.212582588195801
Batch 42/64 loss: -1.3707914352416992
Batch 43/64 loss: -2.2801942825317383
Batch 44/64 loss: -2.248049736022949
Batch 45/64 loss: -2.248143196105957
Batch 46/64 loss: -2.317046642303467
Batch 47/64 loss: -2.24021053314209
Batch 48/64 loss: -1.79193115234375
Batch 49/64 loss: -2.2550010681152344
Batch 50/64 loss: -2.2918310165405273
Batch 51/64 loss: -2.2369813919067383
Batch 52/64 loss: -2.0296754837036133
Batch 53/64 loss: -2.3647146224975586
Batch 54/64 loss: -2.357186794281006
Batch 55/64 loss: -2.169734001159668
Batch 56/64 loss: -2.3498549461364746
Batch 57/64 loss: -2.395415782928467
Batch 58/64 loss: -2.1622066497802734
Batch 59/64 loss: -2.1928329467773438
Batch 60/64 loss: -2.2465105056762695
Batch 61/64 loss: -2.007587432861328
Batch 62/64 loss: -2.2878360748291016
Batch 63/64 loss: -2.4536943435668945
Batch 64/64 loss: -6.3484649658203125
Epoch 424  Train loss: -2.2369791666666665  Val loss: -2.560079305851992
Epoch 425
-------------------------------
Batch 1/64 loss: -2.5156707763671875
Batch 2/64 loss: -2.427323341369629
Batch 3/64 loss: -2.469729423522949
Batch 4/64 loss: -2.3518972396850586
Batch 5/64 loss: -2.280461311340332
Batch 6/64 loss: -2.262356758117676
Batch 7/64 loss: -2.300724983215332
Batch 8/64 loss: -2.114609718322754
Batch 9/64 loss: -2.357171058654785
Batch 10/64 loss: -2.366182327270508
Batch 11/64 loss: -2.3604774475097656
Batch 12/64 loss: -2.1836624145507812
Batch 13/64 loss: -2.1668272018432617
Batch 14/64 loss: -2.3816471099853516
Batch 15/64 loss: -1.5403470993041992
Batch 16/64 loss: -2.2826967239379883
Batch 17/64 loss: -2.527398109436035
Batch 18/64 loss: -2.4559144973754883
Batch 19/64 loss: -2.2034378051757812
Batch 20/64 loss: -2.2795963287353516
Batch 21/64 loss: -2.2760820388793945
Batch 22/64 loss: -2.2351207733154297
Batch 23/64 loss: -2.1980485916137695
Batch 24/64 loss: -2.416360378265381
Batch 25/64 loss: -2.453279495239258
Batch 26/64 loss: -1.5780458450317383
Batch 27/64 loss: -2.246901512145996
Batch 28/64 loss: -2.2585134506225586
Batch 29/64 loss: -1.7132368087768555
Batch 30/64 loss: -2.5276408195495605
Batch 31/64 loss: -2.014444351196289
Batch 32/64 loss: -1.9902057647705078
Batch 33/64 loss: -2.2569828033447266
Batch 34/64 loss: -2.3323187828063965
Batch 35/64 loss: -2.3000402450561523
Batch 36/64 loss: -2.1517162322998047
Batch 37/64 loss: -2.342672348022461
Batch 38/64 loss: -2.3886537551879883
Batch 39/64 loss: -2.1968154907226562
Batch 40/64 loss: -2.182061195373535
Batch 41/64 loss: -2.2054033279418945
Batch 42/64 loss: -2.340686798095703
Batch 43/64 loss: -2.2862658500671387
Batch 44/64 loss: -2.239974021911621
Batch 45/64 loss: -2.2683968544006348
Batch 46/64 loss: -2.326569080352783
Batch 47/64 loss: -2.3810062408447266
Batch 48/64 loss: -2.3371729850769043
Batch 49/64 loss: -1.9605426788330078
Batch 50/64 loss: -2.234480857849121
Batch 51/64 loss: -2.1107406616210938
Batch 52/64 loss: -2.4005088806152344
Batch 53/64 loss: -2.1419944763183594
Batch 54/64 loss: -2.2456278800964355
Batch 55/64 loss: -2.055588722229004
Batch 56/64 loss: -2.356077194213867
Batch 57/64 loss: -2.276905059814453
Batch 58/64 loss: -2.2976865768432617
Batch 59/64 loss: -1.8978996276855469
Batch 60/64 loss: -2.1744632720947266
Batch 61/64 loss: -2.229151725769043
Batch 62/64 loss: -2.205108642578125
Batch 63/64 loss: -2.383122444152832
Batch 64/64 loss: -6.437516212463379
Epoch 425  Train loss: -2.291306405908921  Val loss: -2.6785014568735233
Saving best model, epoch: 425
Epoch 426
-------------------------------
Batch 1/64 loss: -2.320134162902832
Batch 2/64 loss: -2.386812210083008
Batch 3/64 loss: -2.290436267852783
Batch 4/64 loss: -2.287975311279297
Batch 5/64 loss: -2.373546600341797
Batch 6/64 loss: -2.524444580078125
Batch 7/64 loss: -2.2602691650390625
Batch 8/64 loss: -2.139394760131836
Batch 9/64 loss: -2.4108595848083496
Batch 10/64 loss: -2.3985557556152344
Batch 11/64 loss: -2.096377372741699
Batch 12/64 loss: -2.3434252738952637
Batch 13/64 loss: -2.407526969909668
Batch 14/64 loss: -2.0092201232910156
Batch 15/64 loss: -2.3184866905212402
Batch 16/64 loss: -2.2728357315063477
Batch 17/64 loss: -2.394282817840576
Batch 18/64 loss: -2.173604965209961
Batch 19/64 loss: -2.148238182067871
Batch 20/64 loss: -2.137118339538574
Batch 21/64 loss: -2.5131425857543945
Batch 22/64 loss: -2.382333755493164
Batch 23/64 loss: -2.4032835960388184
Batch 24/64 loss: -2.4740166664123535
Batch 25/64 loss: -2.086695671081543
Batch 26/64 loss: -2.2997751235961914
Batch 27/64 loss: -1.6546993255615234
Batch 28/64 loss: -2.412583827972412
Batch 29/64 loss: -2.238673210144043
Batch 30/64 loss: -2.5776214599609375
Batch 31/64 loss: -2.2077035903930664
Batch 32/64 loss: -2.203038215637207
Batch 33/64 loss: -1.5386114120483398
Batch 34/64 loss: -2.3765430450439453
Batch 35/64 loss: -2.4423828125
Batch 36/64 loss: -2.214038848876953
Batch 37/64 loss: -2.1279659271240234
Batch 38/64 loss: -2.456181526184082
Batch 39/64 loss: -2.4770994186401367
Batch 40/64 loss: -2.5762033462524414
Batch 41/64 loss: -2.445969581604004
Batch 42/64 loss: -2.373202323913574
Batch 43/64 loss: -2.352004051208496
Batch 44/64 loss: -2.383707046508789
Batch 45/64 loss: -2.5187525749206543
Batch 46/64 loss: -2.519197940826416
Batch 47/64 loss: -2.4581875801086426
Batch 48/64 loss: -2.2896976470947266
Batch 49/64 loss: -2.4920883178710938
Batch 50/64 loss: -2.309511661529541
Batch 51/64 loss: -2.4783334732055664
Batch 52/64 loss: -2.018831253051758
Batch 53/64 loss: -2.384066104888916
Batch 54/64 loss: -2.5483036041259766
Batch 55/64 loss: -2.5230460166931152
Batch 56/64 loss: -2.3680076599121094
Batch 57/64 loss: -2.1150741577148438
Batch 58/64 loss: -2.478982925415039
Batch 59/64 loss: -2.5159993171691895
Batch 60/64 loss: -2.402695655822754
Batch 61/64 loss: -2.328190803527832
Batch 62/64 loss: -2.341121196746826
Batch 63/64 loss: -2.6840248107910156
Batch 64/64 loss: -6.591165542602539
Epoch 426  Train loss: -2.378486401427026  Val loss: -2.812905695020538
Saving best model, epoch: 426
Epoch 427
-------------------------------
Batch 1/64 loss: -2.206362724304199
Batch 2/64 loss: -2.566275119781494
Batch 3/64 loss: -2.385793685913086
Batch 4/64 loss: -2.205301284790039
Batch 5/64 loss: -2.3761963844299316
Batch 6/64 loss: -2.5208921432495117
Batch 7/64 loss: -2.5519227981567383
Batch 8/64 loss: -2.1995859146118164
Batch 9/64 loss: -2.3580398559570312
Batch 10/64 loss: -2.4575681686401367
Batch 11/64 loss: -2.4695777893066406
Batch 12/64 loss: -2.2171411514282227
Batch 13/64 loss: -2.3746652603149414
Batch 14/64 loss: -2.2655506134033203
Batch 15/64 loss: -1.815241813659668
Batch 16/64 loss: -2.356597423553467
Batch 17/64 loss: -2.3658294677734375
Batch 18/64 loss: -2.147933006286621
Batch 19/64 loss: -2.1689653396606445
Batch 20/64 loss: -2.034867286682129
Batch 21/64 loss: -2.2622976303100586
Batch 22/64 loss: -2.1393632888793945
Batch 23/64 loss: -2.2191333770751953
Batch 24/64 loss: -2.457669734954834
Batch 25/64 loss: -2.320110321044922
Batch 26/64 loss: -2.2582101821899414
Batch 27/64 loss: -1.8570356369018555
Batch 28/64 loss: -2.1573171615600586
Batch 29/64 loss: -2.3616647720336914
Batch 30/64 loss: -2.380795478820801
Batch 31/64 loss: -2.399517059326172
Batch 32/64 loss: -2.197495460510254
Batch 33/64 loss: -2.2949600219726562
Batch 34/64 loss: -2.316380500793457
Batch 35/64 loss: -2.290999412536621
Batch 36/64 loss: -2.2822742462158203
Batch 37/64 loss: -2.1083545684814453
Batch 38/64 loss: -2.3874731063842773
Batch 39/64 loss: -2.1567373275756836
Batch 40/64 loss: -2.553677558898926
Batch 41/64 loss: -2.3965225219726562
Batch 42/64 loss: -2.2883358001708984
Batch 43/64 loss: -2.3406128883361816
Batch 44/64 loss: -2.2282981872558594
Batch 45/64 loss: -2.0502843856811523
Batch 46/64 loss: -2.317289352416992
Batch 47/64 loss: -2.31638240814209
Batch 48/64 loss: -2.3869242668151855
Batch 49/64 loss: -2.3267273902893066
Batch 50/64 loss: -2.2679195404052734
Batch 51/64 loss: -2.4201583862304688
Batch 52/64 loss: -2.1616697311401367
Batch 53/64 loss: -2.3548574447631836
Batch 54/64 loss: -2.240960121154785
Batch 55/64 loss: -1.4997777938842773
Batch 56/64 loss: -2.2013978958129883
Batch 57/64 loss: -2.358647346496582
Batch 58/64 loss: -1.3821353912353516
Batch 59/64 loss: -1.3367557525634766
Batch 60/64 loss: -1.9213943481445312
Batch 61/64 loss: -2.127936363220215
Batch 62/64 loss: -2.197024345397949
Batch 63/64 loss: -2.4226884841918945
Batch 64/64 loss: -6.716554641723633
Epoch 427  Train loss: -2.29063357184915  Val loss: -2.611935369747201
Epoch 428
-------------------------------
Batch 1/64 loss: -2.424931526184082
Batch 2/64 loss: -2.174666404724121
Batch 3/64 loss: -2.0528507232666016
Batch 4/64 loss: -1.5023632049560547
Batch 5/64 loss: -0.9336633682250977
Batch 6/64 loss: -2.234135627746582
Batch 7/64 loss: -2.471834182739258
Batch 8/64 loss: -2.4042744636535645
Batch 9/64 loss: -2.407540798187256
Batch 10/64 loss: -2.4132795333862305
Batch 11/64 loss: -2.437653064727783
Batch 12/64 loss: -1.906961441040039
Batch 13/64 loss: -2.071931838989258
Batch 14/64 loss: -2.2994823455810547
Batch 15/64 loss: -2.3663744926452637
Batch 16/64 loss: -2.072331428527832
Batch 17/64 loss: -2.014772415161133
Batch 18/64 loss: -2.062593460083008
Batch 19/64 loss: -2.2219066619873047
Batch 20/64 loss: -2.2945384979248047
Batch 21/64 loss: -2.226773262023926
Batch 22/64 loss: -2.3300275802612305
Batch 23/64 loss: -2.3398075103759766
Batch 24/64 loss: -1.8410577774047852
Batch 25/64 loss: -2.368968963623047
Batch 26/64 loss: -2.412364959716797
Batch 27/64 loss: -2.1158952713012695
Batch 28/64 loss: -2.263033866882324
Batch 29/64 loss: -2.384723663330078
Batch 30/64 loss: -2.371912956237793
Batch 31/64 loss: -2.271632194519043
Batch 32/64 loss: -2.343381881713867
Batch 33/64 loss: -2.183969497680664
Batch 34/64 loss: -2.4601001739501953
Batch 35/64 loss: -2.0681991577148438
Batch 36/64 loss: -2.3518004417419434
Batch 37/64 loss: -2.157383918762207
Batch 38/64 loss: -2.206035614013672
Batch 39/64 loss: -2.299314498901367
Batch 40/64 loss: -2.2087273597717285
Batch 41/64 loss: -2.0320568084716797
Batch 42/64 loss: -2.094179153442383
Batch 43/64 loss: -2.1939949989318848
Batch 44/64 loss: -1.337911605834961
Batch 45/64 loss: -1.957723617553711
Batch 46/64 loss: -2.097214698791504
Batch 47/64 loss: -2.179412364959717
Batch 48/64 loss: -1.9589757919311523
Batch 49/64 loss: -2.0159263610839844
Batch 50/64 loss: -2.2169809341430664
Batch 51/64 loss: -2.031041145324707
Batch 52/64 loss: -2.169564723968506
Batch 53/64 loss: -2.078545570373535
Batch 54/64 loss: -2.063229560852051
Batch 55/64 loss: -2.0724658966064453
Batch 56/64 loss: -2.0339107513427734
Batch 57/64 loss: -1.9937562942504883
Batch 58/64 loss: -2.1672592163085938
Batch 59/64 loss: -2.3228116035461426
Batch 60/64 loss: -2.0930967330932617
Batch 61/64 loss: -1.904520034790039
Batch 62/64 loss: -2.029541015625
Batch 63/64 loss: -2.2832961082458496
Batch 64/64 loss: -6.324884414672852
Epoch 428  Train loss: -2.1967729306688497  Val loss: -2.5266140023457635
Epoch 429
-------------------------------
Batch 1/64 loss: -2.2680931091308594
Batch 2/64 loss: -2.2530770301818848
Batch 3/64 loss: -2.3313422203063965
Batch 4/64 loss: -1.9444770812988281
Batch 5/64 loss: -1.9562702178955078
Batch 6/64 loss: -2.074840545654297
Batch 7/64 loss: -2.247542381286621
Batch 8/64 loss: -2.388032913208008
Batch 9/64 loss: -2.161222457885742
Batch 10/64 loss: -2.0408544540405273
Batch 11/64 loss: -2.3469929695129395
Batch 12/64 loss: -2.1790037155151367
Batch 13/64 loss: -2.0533742904663086
Batch 14/64 loss: -1.7712993621826172
Batch 15/64 loss: -1.5966100692749023
Batch 16/64 loss: -2.0103626251220703
Batch 17/64 loss: -1.9399642944335938
Batch 18/64 loss: -2.3342556953430176
Batch 19/64 loss: -1.6345853805541992
Batch 20/64 loss: -2.056856155395508
Batch 21/64 loss: -2.2619876861572266
Batch 22/64 loss: -2.1740732192993164
Batch 23/64 loss: -2.2731094360351562
Batch 24/64 loss: -2.0894384384155273
Batch 25/64 loss: -1.940138816833496
Batch 26/64 loss: -2.126424789428711
Batch 27/64 loss: -1.6562614440917969
Batch 28/64 loss: -1.5804834365844727
Batch 29/64 loss: -2.1006202697753906
Batch 30/64 loss: -2.235447883605957
Batch 31/64 loss: -2.264887809753418
Batch 32/64 loss: -2.0396499633789062
Batch 33/64 loss: -1.7692232131958008
Batch 34/64 loss: -2.1097335815429688
Batch 35/64 loss: -2.3688840866088867
Batch 36/64 loss: -2.2589263916015625
Batch 37/64 loss: -2.067018508911133
Batch 38/64 loss: -2.084549903869629
Batch 39/64 loss: -2.222614288330078
Batch 40/64 loss: -2.372493267059326
Batch 41/64 loss: -1.9776782989501953
Batch 42/64 loss: -2.0225696563720703
Batch 43/64 loss: -2.461008071899414
Batch 44/64 loss: -2.046708106994629
Batch 45/64 loss: -2.132650375366211
Batch 46/64 loss: -2.3980026245117188
Batch 47/64 loss: -2.408618927001953
Batch 48/64 loss: -2.178927421569824
Batch 49/64 loss: -2.113412857055664
Batch 50/64 loss: -2.4864583015441895
Batch 51/64 loss: -2.338252544403076
Batch 52/64 loss: -2.13460636138916
Batch 53/64 loss: -2.4074721336364746
Batch 54/64 loss: -2.40268611907959
Batch 55/64 loss: -2.2359676361083984
Batch 56/64 loss: -2.3652029037475586
Batch 57/64 loss: -2.402963638305664
Batch 58/64 loss: -2.299882411956787
Batch 59/64 loss: -2.403805732727051
Batch 60/64 loss: -2.320591926574707
Batch 61/64 loss: -2.0974721908569336
Batch 62/64 loss: -1.8761920928955078
Batch 63/64 loss: -2.333751678466797
Batch 64/64 loss: -6.296765327453613
Epoch 429  Train loss: -2.1984702652575923  Val loss: -2.5914897722067294
Epoch 430
-------------------------------
Batch 1/64 loss: -2.327850341796875
Batch 2/64 loss: -2.3085131645202637
Batch 3/64 loss: -2.294192314147949
Batch 4/64 loss: -2.3842878341674805
Batch 5/64 loss: -2.149761199951172
Batch 6/64 loss: -2.170499801635742
Batch 7/64 loss: -2.239591598510742
Batch 8/64 loss: -2.3844170570373535
Batch 9/64 loss: -2.3177456855773926
Batch 10/64 loss: -2.2353386878967285
Batch 11/64 loss: -2.136547088623047
Batch 12/64 loss: -1.4344367980957031
Batch 13/64 loss: -2.2607603073120117
Batch 14/64 loss: -2.360154628753662
Batch 15/64 loss: -2.4280471801757812
Batch 16/64 loss: -2.258310317993164
Batch 17/64 loss: -2.327458381652832
Batch 18/64 loss: -2.3807544708251953
Batch 19/64 loss: -2.043576240539551
Batch 20/64 loss: -2.4338693618774414
Batch 21/64 loss: -2.396818161010742
Batch 22/64 loss: -2.4973063468933105
Batch 23/64 loss: -2.207490921020508
Batch 24/64 loss: -2.275787830352783
Batch 25/64 loss: -2.3760733604431152
Batch 26/64 loss: -2.469414710998535
Batch 27/64 loss: -2.3328561782836914
Batch 28/64 loss: -2.2360448837280273
Batch 29/64 loss: -2.4967222213745117
Batch 30/64 loss: -2.3850436210632324
Batch 31/64 loss: -2.3235373497009277
Batch 32/64 loss: -2.3534140586853027
Batch 33/64 loss: -2.408053398132324
Batch 34/64 loss: -2.372224807739258
Batch 35/64 loss: -1.3194427490234375
Batch 36/64 loss: -2.3910136222839355
Batch 37/64 loss: -2.115337371826172
Batch 38/64 loss: -2.454395294189453
Batch 39/64 loss: -2.4684572219848633
Batch 40/64 loss: -2.485495090484619
Batch 41/64 loss: -2.4098048210144043
Batch 42/64 loss: -2.311819076538086
Batch 43/64 loss: -1.909937858581543
Batch 44/64 loss: -2.3063673973083496
Batch 45/64 loss: -2.4386773109436035
Batch 46/64 loss: -2.2806835174560547
Batch 47/64 loss: -2.5414581298828125
Batch 48/64 loss: -1.9989404678344727
Batch 49/64 loss: -2.4257640838623047
Batch 50/64 loss: -2.3671889305114746
Batch 51/64 loss: -2.395843029022217
Batch 52/64 loss: -2.1393117904663086
Batch 53/64 loss: -2.156658172607422
Batch 54/64 loss: -2.108658790588379
Batch 55/64 loss: -2.284937858581543
Batch 56/64 loss: -1.2479209899902344
Batch 57/64 loss: -2.4346885681152344
Batch 58/64 loss: -2.001255989074707
Batch 59/64 loss: -2.150811195373535
Batch 60/64 loss: -2.2935638427734375
Batch 61/64 loss: -2.317020893096924
Batch 62/64 loss: -2.3495779037475586
Batch 63/64 loss: -2.4472742080688477
Batch 64/64 loss: -6.595941066741943
Epoch 430  Train loss: -2.3138221535028194  Val loss: -2.630205160973408
Epoch 431
-------------------------------
Batch 1/64 loss: -2.418950080871582
Batch 2/64 loss: -2.287116050720215
Batch 3/64 loss: -2.365849018096924
Batch 4/64 loss: -2.0485639572143555
Batch 5/64 loss: -2.4118547439575195
Batch 6/64 loss: -2.537053108215332
Batch 7/64 loss: -2.3790721893310547
Batch 8/64 loss: -2.127908706665039
Batch 9/64 loss: -2.253995895385742
Batch 10/64 loss: -2.2924318313598633
Batch 11/64 loss: -2.297041893005371
Batch 12/64 loss: -2.4598422050476074
Batch 13/64 loss: -2.2454833984375
Batch 14/64 loss: -2.3833794593811035
Batch 15/64 loss: -2.345637798309326
Batch 16/64 loss: -2.4466443061828613
Batch 17/64 loss: -2.4838624000549316
Batch 18/64 loss: -2.369441032409668
Batch 19/64 loss: -2.175318717956543
Batch 20/64 loss: -2.3652191162109375
Batch 21/64 loss: -2.3169689178466797
Batch 22/64 loss: -2.195876121520996
Batch 23/64 loss: -2.3151302337646484
Batch 24/64 loss: -1.7839994430541992
Batch 25/64 loss: -2.3357629776000977
Batch 26/64 loss: -2.370919704437256
Batch 27/64 loss: -2.3981528282165527
Batch 28/64 loss: -2.258544445037842
Batch 29/64 loss: -2.2019643783569336
Batch 30/64 loss: -2.289867401123047
Batch 31/64 loss: -1.7922821044921875
Batch 32/64 loss: -2.342538356781006
Batch 33/64 loss: -2.350719451904297
Batch 34/64 loss: -2.089916229248047
Batch 35/64 loss: -2.326730728149414
Batch 36/64 loss: -2.2510194778442383
Batch 37/64 loss: -2.2311391830444336
Batch 38/64 loss: -1.5965967178344727
Batch 39/64 loss: -2.373220443725586
Batch 40/64 loss: -2.2637667655944824
Batch 41/64 loss: -2.3500447273254395
Batch 42/64 loss: -2.454841136932373
Batch 43/64 loss: -2.5215587615966797
Batch 44/64 loss: -2.081942558288574
Batch 45/64 loss: -2.3315820693969727
Batch 46/64 loss: -2.2553329467773438
Batch 47/64 loss: -2.259373664855957
Batch 48/64 loss: -2.357393741607666
Batch 49/64 loss: -2.5241851806640625
Batch 50/64 loss: -2.4528989791870117
Batch 51/64 loss: -2.3177242279052734
Batch 52/64 loss: -2.3829331398010254
Batch 53/64 loss: -2.228689193725586
Batch 54/64 loss: -2.13723087310791
Batch 55/64 loss: -2.4600977897644043
Batch 56/64 loss: -2.2963690757751465
Batch 57/64 loss: -1.556711196899414
Batch 58/64 loss: -2.290980815887451
Batch 59/64 loss: -2.2585153579711914
Batch 60/64 loss: -2.2189130783081055
Batch 61/64 loss: -1.729151725769043
Batch 62/64 loss: -2.3155674934387207
Batch 63/64 loss: -2.1581039428710938
Batch 64/64 loss: -6.374209403991699
Epoch 431  Train loss: -2.3137345968508254  Val loss: -2.4839919703113256
Epoch 432
-------------------------------
Batch 1/64 loss: -1.657623291015625
Batch 2/64 loss: -2.3559060096740723
Batch 3/64 loss: -2.27402400970459
Batch 4/64 loss: -2.2366790771484375
Batch 5/64 loss: -2.2694320678710938
Batch 6/64 loss: -2.048288345336914
Batch 7/64 loss: -2.2790770530700684
Batch 8/64 loss: -2.204298973083496
Batch 9/64 loss: -2.2489047050476074
Batch 10/64 loss: -2.36275577545166
Batch 11/64 loss: -2.062417984008789
Batch 12/64 loss: -2.1382904052734375
Batch 13/64 loss: -2.2925620079040527
Batch 14/64 loss: -2.247136116027832
Batch 15/64 loss: -2.080038070678711
Batch 16/64 loss: -2.062673568725586
Batch 17/64 loss: -2.11209774017334
Batch 18/64 loss: -2.29062557220459
Batch 19/64 loss: -2.419748306274414
Batch 20/64 loss: -2.409360885620117
Batch 21/64 loss: -2.0026369094848633
Batch 22/64 loss: -2.049221992492676
Batch 23/64 loss: -2.326688289642334
Batch 24/64 loss: -2.2469310760498047
Batch 25/64 loss: -2.4033689498901367
Batch 26/64 loss: -1.5986032485961914
Batch 27/64 loss: -2.1341724395751953
Batch 28/64 loss: -2.084418296813965
Batch 29/64 loss: -2.084334373474121
Batch 30/64 loss: -2.0565881729125977
Batch 31/64 loss: -2.448164939880371
Batch 32/64 loss: -2.35048770904541
Batch 33/64 loss: -2.2408199310302734
Batch 34/64 loss: -2.34547758102417
Batch 35/64 loss: -2.349667549133301
Batch 36/64 loss: -2.028440475463867
Batch 37/64 loss: -2.1779966354370117
Batch 38/64 loss: -2.2862319946289062
Batch 39/64 loss: -1.9385128021240234
Batch 40/64 loss: -2.3682374954223633
Batch 41/64 loss: -2.1064491271972656
Batch 42/64 loss: -2.4032320976257324
Batch 43/64 loss: -2.1319704055786133
Batch 44/64 loss: -2.166834831237793
Batch 45/64 loss: -2.238583564758301
Batch 46/64 loss: -2.305605888366699
Batch 47/64 loss: -2.2063913345336914
Batch 48/64 loss: -1.5353565216064453
Batch 49/64 loss: -2.299679756164551
Batch 50/64 loss: -2.0372886657714844
Batch 51/64 loss: -2.404719352722168
Batch 52/64 loss: -2.292222499847412
Batch 53/64 loss: -2.263813018798828
Batch 54/64 loss: -2.413522243499756
Batch 55/64 loss: -2.0198211669921875
Batch 56/64 loss: -2.2815418243408203
Batch 57/64 loss: -2.3286032676696777
Batch 58/64 loss: -2.251412868499756
Batch 59/64 loss: -2.2900590896606445
Batch 60/64 loss: -2.241683006286621
Batch 61/64 loss: -2.469902992248535
Batch 62/64 loss: -2.531632423400879
Batch 63/64 loss: -2.169950485229492
Batch 64/64 loss: -6.5825042724609375
Epoch 432  Train loss: -2.257256399416456  Val loss: -2.650837350956763
Epoch 433
-------------------------------
Batch 1/64 loss: -2.5165185928344727
Batch 2/64 loss: -2.481016159057617
Batch 3/64 loss: -2.2837204933166504
Batch 4/64 loss: -2.346951961517334
Batch 5/64 loss: -2.1458168029785156
Batch 6/64 loss: -2.1513500213623047
Batch 7/64 loss: -2.2716550827026367
Batch 8/64 loss: -2.182124137878418
Batch 9/64 loss: -2.181532859802246
Batch 10/64 loss: -2.233133316040039
Batch 11/64 loss: -2.4839577674865723
Batch 12/64 loss: -2.1510086059570312
Batch 13/64 loss: -2.4303531646728516
Batch 14/64 loss: -2.0444602966308594
Batch 15/64 loss: -2.247300148010254
Batch 16/64 loss: -2.449343681335449
Batch 17/64 loss: -2.0584716796875
Batch 18/64 loss: -2.1923036575317383
Batch 19/64 loss: -2.208798408508301
Batch 20/64 loss: -2.1409034729003906
Batch 21/64 loss: -2.4071950912475586
Batch 22/64 loss: -1.9627809524536133
Batch 23/64 loss: -2.2602081298828125
Batch 24/64 loss: -2.2519755363464355
Batch 25/64 loss: -2.072148323059082
Batch 26/64 loss: -2.1755542755126953
Batch 27/64 loss: -2.109283447265625
Batch 28/64 loss: -1.9965267181396484
Batch 29/64 loss: -2.312906265258789
Batch 30/64 loss: -2.09039306640625
Batch 31/64 loss: -2.291775703430176
Batch 32/64 loss: -2.0616092681884766
Batch 33/64 loss: -2.0752477645874023
Batch 34/64 loss: -2.267117500305176
Batch 35/64 loss: -2.286189079284668
Batch 36/64 loss: -1.7597341537475586
Batch 37/64 loss: -1.6829099655151367
Batch 38/64 loss: -2.263927459716797
Batch 39/64 loss: -1.8713188171386719
Batch 40/64 loss: -1.9642915725708008
Batch 41/64 loss: -2.2821712493896484
Batch 42/64 loss: -1.5104312896728516
Batch 43/64 loss: -2.166248321533203
Batch 44/64 loss: -2.223146438598633
Batch 45/64 loss: -1.3859748840332031
Batch 46/64 loss: -2.283510684967041
Batch 47/64 loss: -2.050398826599121
Batch 48/64 loss: -2.178691864013672
Batch 49/64 loss: -1.9081497192382812
Batch 50/64 loss: -1.8643426895141602
Batch 51/64 loss: -2.1642045974731445
Batch 52/64 loss: -2.307736873626709
Batch 53/64 loss: -1.9669561386108398
Batch 54/64 loss: -2.200244903564453
Batch 55/64 loss: -2.18051815032959
Batch 56/64 loss: -2.181757926940918
Batch 57/64 loss: -1.5452213287353516
Batch 58/64 loss: -2.2376675605773926
Batch 59/64 loss: -2.2194576263427734
Batch 60/64 loss: -1.8637933731079102
Batch 61/64 loss: -2.127199172973633
Batch 62/64 loss: -2.2489137649536133
Batch 63/64 loss: -2.0993547439575195
Batch 64/64 loss: -6.410790920257568
Epoch 433  Train loss: -2.186164685791614  Val loss: -2.401902228286586
Epoch 434
-------------------------------
Batch 1/64 loss: -1.6923561096191406
Batch 2/64 loss: -2.430215835571289
Batch 3/64 loss: -2.022162437438965
Batch 4/64 loss: -2.1309194564819336
Batch 5/64 loss: -2.20796537399292
Batch 6/64 loss: -1.9274606704711914
Batch 7/64 loss: -2.3187780380249023
Batch 8/64 loss: -2.37735652923584
Batch 9/64 loss: -1.9963884353637695
Batch 10/64 loss: -2.1770477294921875
Batch 11/64 loss: -2.4005656242370605
Batch 12/64 loss: -2.12554931640625
Batch 13/64 loss: -2.2276506423950195
Batch 14/64 loss: -1.7674636840820312
Batch 15/64 loss: -1.8583555221557617
Batch 16/64 loss: -2.022310256958008
Batch 17/64 loss: -2.0788211822509766
Batch 18/64 loss: -2.157589912414551
Batch 19/64 loss: -2.24139404296875
Batch 20/64 loss: -2.2382688522338867
Batch 21/64 loss: -2.285397529602051
Batch 22/64 loss: -2.0279998779296875
Batch 23/64 loss: -2.2500648498535156
Batch 24/64 loss: -2.232680320739746
Batch 25/64 loss: -2.4960131645202637
Batch 26/64 loss: -2.3024535179138184
Batch 27/64 loss: -2.3195648193359375
Batch 28/64 loss: -2.3362231254577637
Batch 29/64 loss: -2.242471694946289
Batch 30/64 loss: -2.3302206993103027
Batch 31/64 loss: -1.4147653579711914
Batch 32/64 loss: -2.434817314147949
Batch 33/64 loss: -2.1560821533203125
Batch 34/64 loss: -2.308424949645996
Batch 35/64 loss: -1.8956985473632812
Batch 36/64 loss: -2.4683942794799805
Batch 37/64 loss: -2.1956701278686523
Batch 38/64 loss: -2.342247486114502
Batch 39/64 loss: -2.25534725189209
Batch 40/64 loss: -2.389066219329834
Batch 41/64 loss: -2.193598747253418
Batch 42/64 loss: -2.3133902549743652
Batch 43/64 loss: -2.2218008041381836
Batch 44/64 loss: -2.2125511169433594
Batch 45/64 loss: -2.2580437660217285
Batch 46/64 loss: -2.171025276184082
Batch 47/64 loss: -2.3284525871276855
Batch 48/64 loss: -2.21903133392334
Batch 49/64 loss: -2.326272964477539
Batch 50/64 loss: -2.2729392051696777
Batch 51/64 loss: -2.094416618347168
Batch 52/64 loss: -2.343120574951172
Batch 53/64 loss: -2.29917573928833
Batch 54/64 loss: -2.306417465209961
Batch 55/64 loss: -2.071528434753418
Batch 56/64 loss: -2.347963333129883
Batch 57/64 loss: -1.211935043334961
Batch 58/64 loss: -2.390489101409912
Batch 59/64 loss: -2.2956814765930176
Batch 60/64 loss: -1.8538293838500977
Batch 61/64 loss: -2.1535110473632812
Batch 62/64 loss: -2.24033260345459
Batch 63/64 loss: -2.2856035232543945
Batch 64/64 loss: -6.378364086151123
Epoch 434  Train loss: -2.231797747518502  Val loss: -2.5693976281025157
Epoch 435
-------------------------------
Batch 1/64 loss: -2.3606653213500977
Batch 2/64 loss: -2.405055522918701
Batch 3/64 loss: -2.1202850341796875
Batch 4/64 loss: -2.17380428314209
Batch 5/64 loss: -2.281660556793213
Batch 6/64 loss: -2.136651039123535
Batch 7/64 loss: -2.355196475982666
Batch 8/64 loss: -2.3537187576293945
Batch 9/64 loss: -2.226130485534668
Batch 10/64 loss: -2.4779181480407715
Batch 11/64 loss: -2.335383892059326
Batch 12/64 loss: -2.274404525756836
Batch 13/64 loss: -1.9815587997436523
Batch 14/64 loss: -2.2710752487182617
Batch 15/64 loss: -2.2635297775268555
Batch 16/64 loss: -2.460031509399414
Batch 17/64 loss: -2.197568893432617
Batch 18/64 loss: -2.4201812744140625
Batch 19/64 loss: -2.16367244720459
Batch 20/64 loss: -1.734471321105957
Batch 21/64 loss: -2.239858627319336
Batch 22/64 loss: -2.475712299346924
Batch 23/64 loss: -2.404033660888672
Batch 24/64 loss: -1.495065689086914
Batch 25/64 loss: -2.2435102462768555
Batch 26/64 loss: -2.3216819763183594
Batch 27/64 loss: -2.2314453125
Batch 28/64 loss: -2.4824180603027344
Batch 29/64 loss: -2.290731430053711
Batch 30/64 loss: -2.3351922035217285
Batch 31/64 loss: -2.121424674987793
Batch 32/64 loss: -2.363949775695801
Batch 33/64 loss: -2.326796054840088
Batch 34/64 loss: -1.3617277145385742
Batch 35/64 loss: -1.88623046875
Batch 36/64 loss: -2.3954505920410156
Batch 37/64 loss: -1.9483518600463867
Batch 38/64 loss: -2.402503490447998
Batch 39/64 loss: -2.2580318450927734
Batch 40/64 loss: -2.392580986022949
Batch 41/64 loss: -2.398646831512451
Batch 42/64 loss: -2.338329792022705
Batch 43/64 loss: -1.6600351333618164
Batch 44/64 loss: -2.1591644287109375
Batch 45/64 loss: -2.152773857116699
Batch 46/64 loss: -2.245661735534668
Batch 47/64 loss: -2.2163915634155273
Batch 48/64 loss: -2.324652671813965
Batch 49/64 loss: -2.3548855781555176
Batch 50/64 loss: -2.4320764541625977
Batch 51/64 loss: -2.3773274421691895
Batch 52/64 loss: -2.3408846855163574
Batch 53/64 loss: -2.032533645629883
Batch 54/64 loss: -2.309455394744873
Batch 55/64 loss: -2.223651885986328
Batch 56/64 loss: -2.2967963218688965
Batch 57/64 loss: -2.3230552673339844
Batch 58/64 loss: -2.4437179565429688
Batch 59/64 loss: -2.2469043731689453
Batch 60/64 loss: -2.31685733795166
Batch 61/64 loss: -2.3221378326416016
Batch 62/64 loss: -2.385467052459717
Batch 63/64 loss: -2.297666549682617
Batch 64/64 loss: -6.403034210205078
Epoch 435  Train loss: -2.2897413291183173  Val loss: -2.5444156869580246
Epoch 436
-------------------------------
Batch 1/64 loss: -2.2362117767333984
Batch 2/64 loss: -2.252638816833496
Batch 3/64 loss: -2.272672176361084
Batch 4/64 loss: -1.4600238800048828
Batch 5/64 loss: -2.366387367248535
Batch 6/64 loss: -2.221956253051758
Batch 7/64 loss: -2.0954885482788086
Batch 8/64 loss: -2.070240020751953
Batch 9/64 loss: -2.371100902557373
Batch 10/64 loss: -2.4850244522094727
Batch 11/64 loss: -2.1409530639648438
Batch 12/64 loss: -2.398684501647949
Batch 13/64 loss: -2.2229442596435547
Batch 14/64 loss: -1.9964628219604492
Batch 15/64 loss: -2.1081972122192383
Batch 16/64 loss: -1.6885042190551758
Batch 17/64 loss: -2.209872245788574
Batch 18/64 loss: -1.798487663269043
Batch 19/64 loss: -2.2214174270629883
Batch 20/64 loss: -2.278280258178711
Batch 21/64 loss: -2.2999420166015625
Batch 22/64 loss: -2.319777488708496
Batch 23/64 loss: -2.386813163757324
Batch 24/64 loss: -2.1802501678466797
Batch 25/64 loss: -1.4975004196166992
Batch 26/64 loss: -1.880049705505371
Batch 27/64 loss: -1.9901514053344727
Batch 28/64 loss: -2.030524253845215
Batch 29/64 loss: -2.3155784606933594
Batch 30/64 loss: -2.0570459365844727
Batch 31/64 loss: -2.075122833251953
Batch 32/64 loss: -1.6776161193847656
Batch 33/64 loss: -2.3919448852539062
Batch 34/64 loss: -2.1316022872924805
Batch 35/64 loss: -2.346097469329834
Batch 36/64 loss: -1.4277582168579102
Batch 37/64 loss: -1.9216928482055664
Batch 38/64 loss: -2.4282360076904297
Batch 39/64 loss: -2.2049713134765625
Batch 40/64 loss: -2.350856304168701
Batch 41/64 loss: -2.399521827697754
Batch 42/64 loss: -2.2198848724365234
Batch 43/64 loss: -2.2962398529052734
Batch 44/64 loss: -2.233506202697754
Batch 45/64 loss: -2.191300392150879
Batch 46/64 loss: -2.284566879272461
Batch 47/64 loss: -2.3708486557006836
Batch 48/64 loss: -2.0857391357421875
Batch 49/64 loss: -2.2012500762939453
Batch 50/64 loss: -2.030035972595215
Batch 51/64 loss: -2.1379470825195312
Batch 52/64 loss: -2.0612411499023438
Batch 53/64 loss: -2.075495719909668
Batch 54/64 loss: -2.262059211730957
Batch 55/64 loss: -2.289066791534424
Batch 56/64 loss: -2.2755212783813477
Batch 57/64 loss: -2.326784133911133
Batch 58/64 loss: -2.0014734268188477
Batch 59/64 loss: -2.0251541137695312
Batch 60/64 loss: -2.2474355697631836
Batch 61/64 loss: -2.0861759185791016
Batch 62/64 loss: -2.2114601135253906
Batch 63/64 loss: -2.4200220108032227
Batch 64/64 loss: -6.45176887512207
Epoch 436  Train loss: -2.2020491955327053  Val loss: -2.5614187234046124
Epoch 437
-------------------------------
Batch 1/64 loss: -1.2962160110473633
Batch 2/64 loss: -2.3171982765197754
Batch 3/64 loss: -1.9885663986206055
Batch 4/64 loss: -1.9907989501953125
Batch 5/64 loss: -2.261951446533203
Batch 6/64 loss: -2.296489715576172
Batch 7/64 loss: -2.4195938110351562
Batch 8/64 loss: -1.9260025024414062
Batch 9/64 loss: -2.346334934234619
Batch 10/64 loss: -2.285768508911133
Batch 11/64 loss: -2.2816457748413086
Batch 12/64 loss: -2.3693976402282715
Batch 13/64 loss: -2.211336135864258
Batch 14/64 loss: -2.2698707580566406
Batch 15/64 loss: -2.419330596923828
Batch 16/64 loss: -2.2423057556152344
Batch 17/64 loss: -2.4090681076049805
Batch 18/64 loss: -2.1769275665283203
Batch 19/64 loss: -2.406877040863037
Batch 20/64 loss: -2.3648271560668945
Batch 21/64 loss: -2.4160423278808594
Batch 22/64 loss: -2.3212804794311523
Batch 23/64 loss: -2.033407211303711
Batch 24/64 loss: -2.252979278564453
Batch 25/64 loss: -2.421879768371582
Batch 26/64 loss: -2.0246267318725586
Batch 27/64 loss: -2.279876232147217
Batch 28/64 loss: -2.3115248680114746
Batch 29/64 loss: -2.171666145324707
Batch 30/64 loss: -2.175103187561035
Batch 31/64 loss: -2.1662092208862305
Batch 32/64 loss: -2.421719551086426
Batch 33/64 loss: -2.225187301635742
Batch 34/64 loss: -2.302395820617676
Batch 35/64 loss: -2.3238744735717773
Batch 36/64 loss: -2.1707239151000977
Batch 37/64 loss: -2.349775791168213
Batch 38/64 loss: -2.016063690185547
Batch 39/64 loss: -2.3401966094970703
Batch 40/64 loss: -1.9606199264526367
Batch 41/64 loss: -2.287546157836914
Batch 42/64 loss: -2.261697769165039
Batch 43/64 loss: -2.175265312194824
Batch 44/64 loss: -1.485055923461914
Batch 45/64 loss: -1.7457361221313477
Batch 46/64 loss: -2.25640869140625
Batch 47/64 loss: -2.243101119995117
Batch 48/64 loss: -2.311307907104492
Batch 49/64 loss: -2.252619743347168
Batch 50/64 loss: -1.915511131286621
Batch 51/64 loss: -2.142728805541992
Batch 52/64 loss: -2.0896100997924805
Batch 53/64 loss: -2.508962631225586
Batch 54/64 loss: -2.163144111633301
Batch 55/64 loss: -2.342367172241211
Batch 56/64 loss: -2.1298294067382812
Batch 57/64 loss: -2.145279884338379
Batch 58/64 loss: -1.8687419891357422
Batch 59/64 loss: -2.357686996459961
Batch 60/64 loss: -2.2768964767456055
Batch 61/64 loss: -2.4125561714172363
Batch 62/64 loss: -2.2485265731811523
Batch 63/64 loss: -2.1547813415527344
Batch 64/64 loss: -6.641950607299805
Epoch 437  Train loss: -2.254470339008406  Val loss: -2.7302723782988347
Epoch 438
-------------------------------
Batch 1/64 loss: -2.4324898719787598
Batch 2/64 loss: -2.3771162033081055
Batch 3/64 loss: -2.389432907104492
Batch 4/64 loss: -2.3620052337646484
Batch 5/64 loss: -2.278965950012207
Batch 6/64 loss: -2.4007840156555176
Batch 7/64 loss: -2.366670608520508
Batch 8/64 loss: -2.417421817779541
Batch 9/64 loss: -2.0524940490722656
Batch 10/64 loss: -2.1789045333862305
Batch 11/64 loss: -2.308009147644043
Batch 12/64 loss: -2.3270764350891113
Batch 13/64 loss: -2.3472604751586914
Batch 14/64 loss: -2.315887928009033
Batch 15/64 loss: -1.572336196899414
Batch 16/64 loss: -2.1956024169921875
Batch 17/64 loss: -2.530580997467041
Batch 18/64 loss: -2.2871170043945312
Batch 19/64 loss: -2.358015537261963
Batch 20/64 loss: -1.8495302200317383
Batch 21/64 loss: -2.005784034729004
Batch 22/64 loss: -2.420745372772217
Batch 23/64 loss: -2.14176082611084
Batch 24/64 loss: -2.2399473190307617
Batch 25/64 loss: -2.46443510055542
Batch 26/64 loss: -2.308110237121582
Batch 27/64 loss: -2.366391658782959
Batch 28/64 loss: -2.5219640731811523
Batch 29/64 loss: -2.3713669776916504
Batch 30/64 loss: -2.351022720336914
Batch 31/64 loss: -2.263339042663574
Batch 32/64 loss: -2.412062644958496
Batch 33/64 loss: -2.1468915939331055
Batch 34/64 loss: -2.3612728118896484
Batch 35/64 loss: -1.7232818603515625
Batch 36/64 loss: -2.305940628051758
Batch 37/64 loss: -2.3534908294677734
Batch 38/64 loss: -2.488605499267578
Batch 39/64 loss: -2.372427463531494
Batch 40/64 loss: -2.4296674728393555
Batch 41/64 loss: -1.9962873458862305
Batch 42/64 loss: -2.29683780670166
Batch 43/64 loss: -2.297008991241455
Batch 44/64 loss: -2.3758411407470703
Batch 45/64 loss: -2.436197280883789
Batch 46/64 loss: -2.4137563705444336
Batch 47/64 loss: -2.3844127655029297
Batch 48/64 loss: -2.118252754211426
Batch 49/64 loss: -2.3489623069763184
Batch 50/64 loss: -2.3042430877685547
Batch 51/64 loss: -2.4319896697998047
Batch 52/64 loss: -2.348515510559082
Batch 53/64 loss: -1.6828804016113281
Batch 54/64 loss: -2.392859935760498
Batch 55/64 loss: -1.8214483261108398
Batch 56/64 loss: -2.1866140365600586
Batch 57/64 loss: -2.3045692443847656
Batch 58/64 loss: -2.2240543365478516
Batch 59/64 loss: -2.185664176940918
Batch 60/64 loss: -2.258695602416992
Batch 61/64 loss: -2.2347421646118164
Batch 62/64 loss: -1.980940818786621
Batch 63/64 loss: -2.166147232055664
Batch 64/64 loss: -6.61662483215332
Epoch 438  Train loss: -2.3145035238826974  Val loss: -2.62948945297818
Epoch 439
-------------------------------
Batch 1/64 loss: -2.180617332458496
Batch 2/64 loss: -2.445441246032715
Batch 3/64 loss: -1.8508977890014648
Batch 4/64 loss: -2.222066879272461
Batch 5/64 loss: -2.202983856201172
Batch 6/64 loss: -2.3690385818481445
Batch 7/64 loss: -2.120546340942383
Batch 8/64 loss: -2.317753791809082
Batch 9/64 loss: -2.244354248046875
Batch 10/64 loss: -2.422943592071533
Batch 11/64 loss: -2.341460704803467
Batch 12/64 loss: -2.4197540283203125
Batch 13/64 loss: -2.2951555252075195
Batch 14/64 loss: -2.4629502296447754
Batch 15/64 loss: -1.8166532516479492
Batch 16/64 loss: -1.859513282775879
Batch 17/64 loss: -2.3308982849121094
Batch 18/64 loss: -2.53175687789917
Batch 19/64 loss: -2.1326704025268555
Batch 20/64 loss: -2.4640254974365234
Batch 21/64 loss: -2.3870649337768555
Batch 22/64 loss: -2.3112049102783203
Batch 23/64 loss: -2.4066948890686035
Batch 24/64 loss: -2.275996208190918
Batch 25/64 loss: -2.3281946182250977
Batch 26/64 loss: -2.4907588958740234
Batch 27/64 loss: -2.2658557891845703
Batch 28/64 loss: -2.1704654693603516
Batch 29/64 loss: -2.122751235961914
Batch 30/64 loss: -2.22731876373291
Batch 31/64 loss: -2.143092155456543
Batch 32/64 loss: -2.278306007385254
Batch 33/64 loss: -2.162835121154785
Batch 34/64 loss: -2.448777675628662
Batch 35/64 loss: -2.2960963249206543
Batch 36/64 loss: -2.2542781829833984
Batch 37/64 loss: -2.0625410079956055
Batch 38/64 loss: -2.400501251220703
Batch 39/64 loss: -2.3644418716430664
Batch 40/64 loss: -1.5050487518310547
Batch 41/64 loss: -2.211122512817383
Batch 42/64 loss: -2.274951934814453
Batch 43/64 loss: -2.3627963066101074
Batch 44/64 loss: -2.460495948791504
Batch 45/64 loss: -2.3677144050598145
Batch 46/64 loss: -2.4886584281921387
Batch 47/64 loss: -2.4874091148376465
Batch 48/64 loss: -2.232534408569336
Batch 49/64 loss: -2.4449071884155273
Batch 50/64 loss: -2.426788806915283
Batch 51/64 loss: -2.3918094635009766
Batch 52/64 loss: -2.261800765991211
Batch 53/64 loss: -2.4903130531311035
Batch 54/64 loss: -2.4925856590270996
Batch 55/64 loss: -2.307927131652832
Batch 56/64 loss: -2.1871719360351562
Batch 57/64 loss: -2.4532809257507324
Batch 58/64 loss: -2.251063346862793
Batch 59/64 loss: -2.1615467071533203
Batch 60/64 loss: -2.1776084899902344
Batch 61/64 loss: -2.417766571044922
Batch 62/64 loss: -2.1894617080688477
Batch 63/64 loss: -2.3803443908691406
Batch 64/64 loss: -6.433271408081055
Epoch 439  Train loss: -2.3322151932061885  Val loss: -2.6081222848793897
Epoch 440
-------------------------------
Batch 1/64 loss: -2.3140029907226562
Batch 2/64 loss: -2.329739570617676
Batch 3/64 loss: -1.8374643325805664
Batch 4/64 loss: -2.31954288482666
Batch 5/64 loss: -2.344437599182129
Batch 6/64 loss: -2.153172492980957
Batch 7/64 loss: -2.3551483154296875
Batch 8/64 loss: -2.36012601852417
Batch 9/64 loss: -2.1760520935058594
Batch 10/64 loss: -2.202723503112793
Batch 11/64 loss: -2.221978187561035
Batch 12/64 loss: -2.496832847595215
Batch 13/64 loss: -2.3792638778686523
Batch 14/64 loss: -2.354041576385498
Batch 15/64 loss: -2.3278465270996094
Batch 16/64 loss: -2.433476448059082
Batch 17/64 loss: -2.440030574798584
Batch 18/64 loss: -2.1635284423828125
Batch 19/64 loss: -2.3283233642578125
Batch 20/64 loss: -2.402073860168457
Batch 21/64 loss: -2.2805709838867188
Batch 22/64 loss: -2.4006223678588867
Batch 23/64 loss: -2.384697437286377
Batch 24/64 loss: -2.2622060775756836
Batch 25/64 loss: -2.1011266708374023
Batch 26/64 loss: -2.4185633659362793
Batch 27/64 loss: -2.0095090866088867
Batch 28/64 loss: -2.3884291648864746
Batch 29/64 loss: -2.192291259765625
Batch 30/64 loss: -2.3671655654907227
Batch 31/64 loss: -2.1831369400024414
Batch 32/64 loss: -2.1863203048706055
Batch 33/64 loss: -2.2666425704956055
Batch 34/64 loss: -2.2474288940429688
Batch 35/64 loss: -2.3421897888183594
Batch 36/64 loss: -2.444108009338379
Batch 37/64 loss: -2.089503288269043
Batch 38/64 loss: -2.283820152282715
Batch 39/64 loss: -2.3728270530700684
Batch 40/64 loss: -2.410010814666748
Batch 41/64 loss: -1.802504539489746
Batch 42/64 loss: -1.9053525924682617
Batch 43/64 loss: -2.2411088943481445
Batch 44/64 loss: -2.1064329147338867
Batch 45/64 loss: -1.842576026916504
Batch 46/64 loss: -2.3797178268432617
Batch 47/64 loss: -2.1661109924316406
Batch 48/64 loss: -1.9769611358642578
Batch 49/64 loss: -1.9492645263671875
Batch 50/64 loss: -2.137091636657715
Batch 51/64 loss: -2.2329750061035156
Batch 52/64 loss: -2.0091161727905273
Batch 53/64 loss: -2.2217111587524414
Batch 54/64 loss: -2.2792224884033203
Batch 55/64 loss: -2.244455337524414
Batch 56/64 loss: -2.2484092712402344
Batch 57/64 loss: -2.3324756622314453
Batch 58/64 loss: -1.52264404296875
Batch 59/64 loss: -2.1775875091552734
Batch 60/64 loss: -2.2692718505859375
Batch 61/64 loss: -1.9427213668823242
Batch 62/64 loss: -2.2983179092407227
Batch 63/64 loss: -2.3860344886779785
Batch 64/64 loss: -6.392149925231934
Epoch 440  Train loss: -2.27509256624708  Val loss: -2.5614549695830986
Epoch 441
-------------------------------
Batch 1/64 loss: -2.0782976150512695
Batch 2/64 loss: -1.739119529724121
Batch 3/64 loss: -2.411468982696533
Batch 4/64 loss: -2.3616256713867188
Batch 5/64 loss: -1.867380142211914
Batch 6/64 loss: -2.05698299407959
Batch 7/64 loss: -2.129960060119629
Batch 8/64 loss: -2.0716733932495117
Batch 9/64 loss: -2.1129817962646484
Batch 10/64 loss: -1.9665098190307617
Batch 11/64 loss: -2.416330337524414
Batch 12/64 loss: -2.3433823585510254
Batch 13/64 loss: -2.1448192596435547
Batch 14/64 loss: -2.3363380432128906
Batch 15/64 loss: -2.3344764709472656
Batch 16/64 loss: -2.3068246841430664
Batch 17/64 loss: -2.1951866149902344
Batch 18/64 loss: -2.359053611755371
Batch 19/64 loss: -2.3111438751220703
Batch 20/64 loss: -1.858154296875
Batch 21/64 loss: -2.3264808654785156
Batch 22/64 loss: -2.044279098510742
Batch 23/64 loss: -2.3391456604003906
Batch 24/64 loss: -2.0771484375
Batch 25/64 loss: -2.2628698348999023
Batch 26/64 loss: -2.3642640113830566
Batch 27/64 loss: -2.237179756164551
Batch 28/64 loss: -2.2752914428710938
Batch 29/64 loss: -2.4190826416015625
Batch 30/64 loss: -2.427098274230957
Batch 31/64 loss: -1.9342222213745117
Batch 32/64 loss: -2.140615463256836
Batch 33/64 loss: -2.2333145141601562
Batch 34/64 loss: -2.2877635955810547
Batch 35/64 loss: -2.1950082778930664
Batch 36/64 loss: -2.2618751525878906
Batch 37/64 loss: -2.224545478820801
Batch 38/64 loss: -2.357800006866455
Batch 39/64 loss: -2.205045700073242
Batch 40/64 loss: -2.164093017578125
Batch 41/64 loss: -2.2842416763305664
Batch 42/64 loss: -2.3093466758728027
Batch 43/64 loss: -2.0469512939453125
Batch 44/64 loss: -2.1647586822509766
Batch 45/64 loss: -2.356006145477295
Batch 46/64 loss: -2.3012380599975586
Batch 47/64 loss: -2.1824588775634766
Batch 48/64 loss: -2.2268524169921875
Batch 49/64 loss: -2.1936140060424805
Batch 50/64 loss: -2.331892967224121
Batch 51/64 loss: -2.2721433639526367
Batch 52/64 loss: -2.3076210021972656
Batch 53/64 loss: -1.4861822128295898
Batch 54/64 loss: -2.1217403411865234
Batch 55/64 loss: -2.3851566314697266
Batch 56/64 loss: -1.8981313705444336
Batch 57/64 loss: -2.2941131591796875
Batch 58/64 loss: -2.2676753997802734
Batch 59/64 loss: -2.2835617065429688
Batch 60/64 loss: -2.415663719177246
Batch 61/64 loss: -2.361149787902832
Batch 62/64 loss: -2.105192184448242
Batch 63/64 loss: -2.280287265777588
Batch 64/64 loss: -6.680846691131592
Epoch 441  Train loss: -2.2598501485936784  Val loss: -2.4877342014378288
Epoch 442
-------------------------------
Batch 1/64 loss: -2.1663217544555664
Batch 2/64 loss: -1.3404817581176758
Batch 3/64 loss: -2.404888153076172
Batch 4/64 loss: -2.4145679473876953
Batch 5/64 loss: -2.2507128715515137
Batch 6/64 loss: -2.3511691093444824
Batch 7/64 loss: -2.497614860534668
Batch 8/64 loss: -2.4819302558898926
Batch 9/64 loss: -2.4480533599853516
Batch 10/64 loss: -2.242643356323242
Batch 11/64 loss: -2.4693503379821777
Batch 12/64 loss: -2.4037575721740723
Batch 13/64 loss: -2.4564099311828613
Batch 14/64 loss: -2.2915878295898438
Batch 15/64 loss: -2.442030429840088
Batch 16/64 loss: -2.0107269287109375
Batch 17/64 loss: -2.327993392944336
Batch 18/64 loss: -2.2049198150634766
Batch 19/64 loss: -2.3309173583984375
Batch 20/64 loss: -2.481405258178711
Batch 21/64 loss: -2.484410285949707
Batch 22/64 loss: -2.3350343704223633
Batch 23/64 loss: -1.7650842666625977
Batch 24/64 loss: -2.3761720657348633
Batch 25/64 loss: -2.269200325012207
Batch 26/64 loss: -2.377884864807129
Batch 27/64 loss: -2.3107333183288574
Batch 28/64 loss: -2.296144962310791
Batch 29/64 loss: -2.391188621520996
Batch 30/64 loss: -2.5382766723632812
Batch 31/64 loss: -2.0401153564453125
Batch 32/64 loss: -2.4060211181640625
Batch 33/64 loss: -1.5982694625854492
Batch 34/64 loss: -2.4960098266601562
Batch 35/64 loss: -2.4676246643066406
Batch 36/64 loss: -2.5025486946105957
Batch 37/64 loss: -2.3923511505126953
Batch 38/64 loss: -2.082095146179199
Batch 39/64 loss: -2.1815032958984375
Batch 40/64 loss: -2.48964262008667
Batch 41/64 loss: -2.570554256439209
Batch 42/64 loss: -2.540292263031006
Batch 43/64 loss: -2.544586181640625
Batch 44/64 loss: -2.36749267578125
Batch 45/64 loss: -2.5681939125061035
Batch 46/64 loss: -2.305356025695801
Batch 47/64 loss: -2.50311279296875
Batch 48/64 loss: -2.3981170654296875
Batch 49/64 loss: -2.4820775985717773
Batch 50/64 loss: -2.352555274963379
Batch 51/64 loss: -2.1763839721679688
Batch 52/64 loss: -2.534245491027832
Batch 53/64 loss: -2.243556022644043
Batch 54/64 loss: -2.320760726928711
Batch 55/64 loss: -2.4043846130371094
Batch 56/64 loss: -2.4770727157592773
Batch 57/64 loss: -2.275175094604492
Batch 58/64 loss: -2.2638702392578125
Batch 59/64 loss: -2.494133949279785
Batch 60/64 loss: -2.421825408935547
Batch 61/64 loss: -2.362844944000244
Batch 62/64 loss: -2.0543270111083984
Batch 63/64 loss: -2.194133758544922
Batch 64/64 loss: -6.604178428649902
Epoch 442  Train loss: -2.378446732315363  Val loss: -2.655624756698346
Epoch 443
-------------------------------
Batch 1/64 loss: -2.5109567642211914
Batch 2/64 loss: -1.6666536331176758
Batch 3/64 loss: -2.012554168701172
Batch 4/64 loss: -2.1149845123291016
Batch 5/64 loss: -2.509512424468994
Batch 6/64 loss: -2.3495101928710938
Batch 7/64 loss: -2.5271220207214355
Batch 8/64 loss: -2.411245346069336
Batch 9/64 loss: -2.4716897010803223
Batch 10/64 loss: -2.3778486251831055
Batch 11/64 loss: -2.3091516494750977
Batch 12/64 loss: -2.391867160797119
Batch 13/64 loss: -2.353030204772949
Batch 14/64 loss: -2.4333653450012207
Batch 15/64 loss: -2.4520926475524902
Batch 16/64 loss: -2.2318687438964844
Batch 17/64 loss: -2.2616186141967773
Batch 18/64 loss: -2.382841110229492
Batch 19/64 loss: -2.4021801948547363
Batch 20/64 loss: -2.2877206802368164
Batch 21/64 loss: -2.4822769165039062
Batch 22/64 loss: -2.490147590637207
Batch 23/64 loss: -2.386749744415283
Batch 24/64 loss: -2.305929660797119
Batch 25/64 loss: -2.1795654296875
Batch 26/64 loss: -2.4502477645874023
Batch 27/64 loss: -2.3150501251220703
Batch 28/64 loss: -2.3187265396118164
Batch 29/64 loss: -2.166670799255371
Batch 30/64 loss: -1.960897445678711
Batch 31/64 loss: -2.3843116760253906
Batch 32/64 loss: -2.4353957176208496
Batch 33/64 loss: -2.5226211547851562
Batch 34/64 loss: -2.482733726501465
Batch 35/64 loss: -2.2455520629882812
Batch 36/64 loss: -2.444279670715332
Batch 37/64 loss: -1.9337043762207031
Batch 38/64 loss: -2.2393789291381836
Batch 39/64 loss: -2.4894657135009766
Batch 40/64 loss: -2.371826171875
Batch 41/64 loss: -2.267125129699707
Batch 42/64 loss: -2.465266227722168
Batch 43/64 loss: -2.3079471588134766
Batch 44/64 loss: -2.2559986114501953
Batch 45/64 loss: -2.268400192260742
Batch 46/64 loss: -2.3314270973205566
Batch 47/64 loss: -2.4726157188415527
Batch 48/64 loss: -2.3110837936401367
Batch 49/64 loss: -2.270176887512207
Batch 50/64 loss: -2.3521728515625
Batch 51/64 loss: -2.3271918296813965
Batch 52/64 loss: -2.3647947311401367
Batch 53/64 loss: -2.3490872383117676
Batch 54/64 loss: -1.4533605575561523
Batch 55/64 loss: -2.464240074157715
Batch 56/64 loss: -2.009922981262207
Batch 57/64 loss: -2.240736961364746
Batch 58/64 loss: -1.83258056640625
Batch 59/64 loss: -2.2554235458374023
Batch 60/64 loss: -2.230581283569336
Batch 61/64 loss: -1.8866891860961914
Batch 62/64 loss: -2.308058738708496
Batch 63/64 loss: -2.1905174255371094
Batch 64/64 loss: -6.64608097076416
Epoch 443  Train loss: -2.3413851681877587  Val loss: -2.6224856950163433
Epoch 444
-------------------------------
Batch 1/64 loss: -2.0819473266601562
Batch 2/64 loss: -2.3390350341796875
Batch 3/64 loss: -2.459467887878418
Batch 4/64 loss: -2.3374719619750977
Batch 5/64 loss: -2.3942251205444336
Batch 6/64 loss: -2.3001232147216797
Batch 7/64 loss: -2.233060836791992
Batch 8/64 loss: -2.131655693054199
Batch 9/64 loss: -2.2128915786743164
Batch 10/64 loss: -1.5082311630249023
Batch 11/64 loss: -2.3755531311035156
Batch 12/64 loss: -2.151972770690918
Batch 13/64 loss: -2.223456382751465
Batch 14/64 loss: -2.240032196044922
Batch 15/64 loss: -2.034865379333496
Batch 16/64 loss: -2.3554582595825195
Batch 17/64 loss: -2.086787223815918
Batch 18/64 loss: -2.3668928146362305
Batch 19/64 loss: -1.8580846786499023
Batch 20/64 loss: -2.3144102096557617
Batch 21/64 loss: -2.1327104568481445
Batch 22/64 loss: -1.8538799285888672
Batch 23/64 loss: -2.2756052017211914
Batch 24/64 loss: -2.300355911254883
Batch 25/64 loss: -2.014920234680176
Batch 26/64 loss: -2.2848567962646484
Batch 27/64 loss: -2.1967382431030273
Batch 28/64 loss: -2.3420186042785645
Batch 29/64 loss: -2.182149887084961
Batch 30/64 loss: -2.2362918853759766
Batch 31/64 loss: -1.931818962097168
Batch 32/64 loss: -1.9029455184936523
Batch 33/64 loss: -2.222352981567383
Batch 34/64 loss: -2.0244789123535156
Batch 35/64 loss: -1.8788299560546875
Batch 36/64 loss: -2.055715560913086
Batch 37/64 loss: -1.8273372650146484
Batch 38/64 loss: -2.0187435150146484
Batch 39/64 loss: -2.2605676651000977
Batch 40/64 loss: -2.088852882385254
Batch 41/64 loss: -1.9896173477172852
Batch 42/64 loss: -2.354346752166748
Batch 43/64 loss: -2.143887519836426
Batch 44/64 loss: -2.1691360473632812
Batch 45/64 loss: -2.156195640563965
Batch 46/64 loss: -2.094109535217285
Batch 47/64 loss: -2.3841843605041504
Batch 48/64 loss: -2.285722255706787
Batch 49/64 loss: -1.7379398345947266
Batch 50/64 loss: -2.075833320617676
Batch 51/64 loss: -2.181764602661133
Batch 52/64 loss: -1.7137947082519531
Batch 53/64 loss: -2.0029754638671875
Batch 54/64 loss: -1.6933469772338867
Batch 55/64 loss: -2.227642059326172
Batch 56/64 loss: -2.332231044769287
Batch 57/64 loss: -1.1818618774414062
Batch 58/64 loss: -2.0472230911254883
Batch 59/64 loss: -2.2390050888061523
Batch 60/64 loss: -2.2860774993896484
Batch 61/64 loss: -2.108262062072754
Batch 62/64 loss: -2.1477622985839844
Batch 63/64 loss: -2.2859487533569336
Batch 64/64 loss: -5.825754165649414
Epoch 444  Train loss: -2.1685486587823606  Val loss: -2.552083700383242
Epoch 445
-------------------------------
Batch 1/64 loss: -2.3523874282836914
Batch 2/64 loss: -2.3217430114746094
Batch 3/64 loss: -2.224508285522461
Batch 4/64 loss: -2.1516342163085938
Batch 5/64 loss: -2.228508949279785
Batch 6/64 loss: -2.17948055267334
Batch 7/64 loss: -2.2501955032348633
Batch 8/64 loss: -2.3040900230407715
Batch 9/64 loss: -2.377690315246582
Batch 10/64 loss: -2.3506579399108887
Batch 11/64 loss: -2.4207963943481445
Batch 12/64 loss: -2.1955041885375977
Batch 13/64 loss: -2.357579231262207
Batch 14/64 loss: -2.266569137573242
Batch 15/64 loss: -2.027425765991211
Batch 16/64 loss: -2.271559715270996
Batch 17/64 loss: -1.8107566833496094
Batch 18/64 loss: -2.377324104309082
Batch 19/64 loss: -2.178140640258789
Batch 20/64 loss: -1.1525707244873047
Batch 21/64 loss: -2.2822322845458984
Batch 22/64 loss: -2.323988914489746
Batch 23/64 loss: -2.170635223388672
Batch 24/64 loss: -2.154149055480957
Batch 25/64 loss: -2.2469491958618164
Batch 26/64 loss: -2.0904788970947266
Batch 27/64 loss: -2.2290210723876953
Batch 28/64 loss: -1.721705436706543
Batch 29/64 loss: -2.2347307205200195
Batch 30/64 loss: -1.7401199340820312
Batch 31/64 loss: -2.305055618286133
Batch 32/64 loss: -2.3006324768066406
Batch 33/64 loss: -2.0020360946655273
Batch 34/64 loss: -2.3020715713500977
Batch 35/64 loss: -2.112081527709961
Batch 36/64 loss: -2.2813773155212402
Batch 37/64 loss: -2.3573904037475586
Batch 38/64 loss: -2.1887550354003906
Batch 39/64 loss: -2.087418556213379
Batch 40/64 loss: -2.3597512245178223
Batch 41/64 loss: -2.2780323028564453
Batch 42/64 loss: -1.9914846420288086
Batch 43/64 loss: -2.037930488586426
Batch 44/64 loss: -2.1269969940185547
Batch 45/64 loss: -2.2180538177490234
Batch 46/64 loss: -2.258028030395508
Batch 47/64 loss: -2.1387319564819336
Batch 48/64 loss: -2.2848029136657715
Batch 49/64 loss: -2.077012062072754
Batch 50/64 loss: -2.353705883026123
Batch 51/64 loss: -2.226803779602051
Batch 52/64 loss: -2.3193817138671875
Batch 53/64 loss: -2.305455207824707
Batch 54/64 loss: -1.588766098022461
Batch 55/64 loss: -2.150261878967285
Batch 56/64 loss: -2.3454885482788086
Batch 57/64 loss: -1.685892105102539
Batch 58/64 loss: -2.221005439758301
Batch 59/64 loss: -2.1937694549560547
Batch 60/64 loss: -2.3500723838806152
Batch 61/64 loss: -2.294301986694336
Batch 62/64 loss: -2.425917625427246
Batch 63/64 loss: -1.9430561065673828
Batch 64/64 loss: -6.4571380615234375
Epoch 445  Train loss: -2.226627581727271  Val loss: -2.6204310676076568
Epoch 446
-------------------------------
Batch 1/64 loss: -2.3583874702453613
Batch 2/64 loss: -2.394718647003174
Batch 3/64 loss: -2.411691188812256
Batch 4/64 loss: -2.0770864486694336
Batch 5/64 loss: -2.400625705718994
Batch 6/64 loss: -2.4617648124694824
Batch 7/64 loss: -2.4009056091308594
Batch 8/64 loss: -2.2707033157348633
Batch 9/64 loss: -2.2503662109375
Batch 10/64 loss: -2.176968574523926
Batch 11/64 loss: -1.7302627563476562
Batch 12/64 loss: -1.8846244812011719
Batch 13/64 loss: -2.251150131225586
Batch 14/64 loss: -2.2370128631591797
Batch 15/64 loss: -2.21746826171875
Batch 16/64 loss: -2.383481025695801
Batch 17/64 loss: -2.2196197509765625
Batch 18/64 loss: -2.372797966003418
Batch 19/64 loss: -2.1662425994873047
Batch 20/64 loss: -2.10237979888916
Batch 21/64 loss: -1.532449722290039
Batch 22/64 loss: -2.346923828125
Batch 23/64 loss: -2.167703628540039
Batch 24/64 loss: -2.327228546142578
Batch 25/64 loss: -2.1689491271972656
Batch 26/64 loss: -2.4087119102478027
Batch 27/64 loss: -2.133150100708008
Batch 28/64 loss: -1.8068256378173828
Batch 29/64 loss: -2.1282482147216797
Batch 30/64 loss: -2.2351512908935547
Batch 31/64 loss: -2.1455984115600586
Batch 32/64 loss: -2.2837343215942383
Batch 33/64 loss: -2.327296257019043
Batch 34/64 loss: -2.15122127532959
Batch 35/64 loss: -2.198643684387207
Batch 36/64 loss: -2.4150943756103516
Batch 37/64 loss: -2.286052703857422
Batch 38/64 loss: -2.305039405822754
Batch 39/64 loss: -2.2186851501464844
Batch 40/64 loss: -2.294546604156494
Batch 41/64 loss: -2.2386960983276367
Batch 42/64 loss: -2.2406444549560547
Batch 43/64 loss: -2.040742874145508
Batch 44/64 loss: -2.0485477447509766
Batch 45/64 loss: -1.8976469039916992
Batch 46/64 loss: -2.1035470962524414
Batch 47/64 loss: -2.182638168334961
Batch 48/64 loss: -2.0185155868530273
Batch 49/64 loss: -2.420828342437744
Batch 50/64 loss: -2.1743316650390625
Batch 51/64 loss: -2.400628089904785
Batch 52/64 loss: -2.2656497955322266
Batch 53/64 loss: -1.1508054733276367
Batch 54/64 loss: -2.261263847351074
Batch 55/64 loss: -2.1830854415893555
Batch 56/64 loss: -2.1594295501708984
Batch 57/64 loss: -2.0653696060180664
Batch 58/64 loss: -2.236647605895996
Batch 59/64 loss: -2.112689971923828
Batch 60/64 loss: -2.028430938720703
Batch 61/64 loss: -2.2701539993286133
Batch 62/64 loss: -2.241032600402832
Batch 63/64 loss: -2.1484975814819336
Batch 64/64 loss: -6.32637882232666
Epoch 446  Train loss: -2.2319077547858743  Val loss: -2.4640071646044754
Epoch 447
-------------------------------
Batch 1/64 loss: -2.276866912841797
Batch 2/64 loss: -1.3961362838745117
Batch 3/64 loss: -2.28317928314209
Batch 4/64 loss: -2.0189027786254883
Batch 5/64 loss: -2.2101736068725586
Batch 6/64 loss: -2.336954116821289
Batch 7/64 loss: -2.0697364807128906
Batch 8/64 loss: -2.0828800201416016
Batch 9/64 loss: -2.3191046714782715
Batch 10/64 loss: -2.2012643814086914
Batch 11/64 loss: -2.0952157974243164
Batch 12/64 loss: -2.0784053802490234
Batch 13/64 loss: -2.230417251586914
Batch 14/64 loss: -2.380009174346924
Batch 15/64 loss: -2.3332786560058594
Batch 16/64 loss: -2.135223388671875
Batch 17/64 loss: -2.1564979553222656
Batch 18/64 loss: -2.0948524475097656
Batch 19/64 loss: -2.032489776611328
Batch 20/64 loss: -1.8464908599853516
Batch 21/64 loss: -2.194268226623535
Batch 22/64 loss: -1.7285528182983398
Batch 23/64 loss: -2.0503664016723633
Batch 24/64 loss: -2.258373260498047
Batch 25/64 loss: -2.3213510513305664
Batch 26/64 loss: -2.3076138496398926
Batch 27/64 loss: -1.8753595352172852
Batch 28/64 loss: -1.9388751983642578
Batch 29/64 loss: -2.0630035400390625
Batch 30/64 loss: -2.0949277877807617
Batch 31/64 loss: -2.1730666160583496
Batch 32/64 loss: -2.0075693130493164
Batch 33/64 loss: -2.2298593521118164
Batch 34/64 loss: -1.9792003631591797
Batch 35/64 loss: -2.230085849761963
Batch 36/64 loss: -2.106027603149414
Batch 37/64 loss: -2.124701499938965
Batch 38/64 loss: -2.2564830780029297
Batch 39/64 loss: -1.4651660919189453
Batch 40/64 loss: -2.3316898345947266
Batch 41/64 loss: -2.4436120986938477
Batch 42/64 loss: -2.320549488067627
Batch 43/64 loss: -2.296189308166504
Batch 44/64 loss: -2.3320136070251465
Batch 45/64 loss: -2.300163745880127
Batch 46/64 loss: -2.2868165969848633
Batch 47/64 loss: -2.2695717811584473
Batch 48/64 loss: -2.4546146392822266
Batch 49/64 loss: -2.2868247032165527
Batch 50/64 loss: -2.2207536697387695
Batch 51/64 loss: -2.28256893157959
Batch 52/64 loss: -2.124842643737793
Batch 53/64 loss: -2.4427881240844727
Batch 54/64 loss: -2.164679527282715
Batch 55/64 loss: -2.1467514038085938
Batch 56/64 loss: -2.467991828918457
Batch 57/64 loss: -1.7420825958251953
Batch 58/64 loss: -1.9414453506469727
Batch 59/64 loss: -2.1341018676757812
Batch 60/64 loss: -2.084718704223633
Batch 61/64 loss: -2.1059112548828125
Batch 62/64 loss: -2.327305793762207
Batch 63/64 loss: -2.4515929222106934
Batch 64/64 loss: -6.343574523925781
Epoch 447  Train loss: -2.207061834896312  Val loss: -2.5679887201368192
Epoch 448
-------------------------------
Batch 1/64 loss: -2.1401357650756836
Batch 2/64 loss: -2.3679251670837402
Batch 3/64 loss: -2.1739320755004883
Batch 4/64 loss: -2.295424461364746
Batch 5/64 loss: -2.226588249206543
Batch 6/64 loss: -2.361617088317871
Batch 7/64 loss: -2.3613462448120117
Batch 8/64 loss: -2.0162153244018555
Batch 9/64 loss: -2.2444238662719727
Batch 10/64 loss: -2.1378564834594727
Batch 11/64 loss: -2.3206605911254883
Batch 12/64 loss: -2.31204891204834
Batch 13/64 loss: -2.4100284576416016
Batch 14/64 loss: -2.165999412536621
Batch 15/64 loss: -2.348247528076172
Batch 16/64 loss: -2.332825183868408
Batch 17/64 loss: -2.204287528991699
Batch 18/64 loss: -2.3446502685546875
Batch 19/64 loss: -2.336419105529785
Batch 20/64 loss: -2.369114398956299
Batch 21/64 loss: -2.3944334983825684
Batch 22/64 loss: -1.964463233947754
Batch 23/64 loss: -2.2612228393554688
Batch 24/64 loss: -2.443819999694824
Batch 25/64 loss: -2.2983713150024414
Batch 26/64 loss: -2.4342174530029297
Batch 27/64 loss: -2.26138973236084
Batch 28/64 loss: -2.4778451919555664
Batch 29/64 loss: -2.5333118438720703
Batch 30/64 loss: -2.2366085052490234
Batch 31/64 loss: -2.3342843055725098
Batch 32/64 loss: -2.398308753967285
Batch 33/64 loss: -2.299344062805176
Batch 34/64 loss: -2.367326259613037
Batch 35/64 loss: -2.326993465423584
Batch 36/64 loss: -2.1203842163085938
Batch 37/64 loss: -2.213094711303711
Batch 38/64 loss: -2.297297954559326
Batch 39/64 loss: -2.2614293098449707
Batch 40/64 loss: -2.3800439834594727
Batch 41/64 loss: -2.3765616416931152
Batch 42/64 loss: -2.4787607192993164
Batch 43/64 loss: -2.3189854621887207
Batch 44/64 loss: -1.8309803009033203
Batch 45/64 loss: -2.209545135498047
Batch 46/64 loss: -2.2410597801208496
Batch 47/64 loss: -2.2546749114990234
Batch 48/64 loss: -2.2972497940063477
Batch 49/64 loss: -2.286850929260254
Batch 50/64 loss: -2.060347557067871
Batch 51/64 loss: -2.254460334777832
Batch 52/64 loss: -2.114246368408203
Batch 53/64 loss: -2.2263174057006836
Batch 54/64 loss: -2.327241897583008
Batch 55/64 loss: -2.2111778259277344
Batch 56/64 loss: -2.282745361328125
Batch 57/64 loss: -2.053058624267578
Batch 58/64 loss: -2.2765579223632812
Batch 59/64 loss: -2.154865264892578
Batch 60/64 loss: -1.7973213195800781
Batch 61/64 loss: -1.9466581344604492
Batch 62/64 loss: -1.345489501953125
Batch 63/64 loss: -2.0085296630859375
Batch 64/64 loss: -6.505676746368408
Epoch 448  Train loss: -2.290304002574846  Val loss: -2.510354635232093
Epoch 449
-------------------------------
Batch 1/64 loss: -2.2060604095458984
Batch 2/64 loss: -2.241802215576172
Batch 3/64 loss: -2.3060855865478516
Batch 4/64 loss: -2.2763943672180176
Batch 5/64 loss: -2.305206298828125
Batch 6/64 loss: -1.5228862762451172
Batch 7/64 loss: -2.109246253967285
Batch 8/64 loss: -2.2992496490478516
Batch 9/64 loss: -2.218486785888672
Batch 10/64 loss: -2.1928634643554688
Batch 11/64 loss: -1.8787708282470703
Batch 12/64 loss: -2.145212173461914
Batch 13/64 loss: -2.1376590728759766
Batch 14/64 loss: -2.066561698913574
Batch 15/64 loss: -2.266787528991699
Batch 16/64 loss: -2.014505386352539
Batch 17/64 loss: -2.125429153442383
Batch 18/64 loss: -2.2450437545776367
Batch 19/64 loss: -2.287388801574707
Batch 20/64 loss: -2.5062289237976074
Batch 21/64 loss: -2.0953989028930664
Batch 22/64 loss: -1.7181987762451172
Batch 23/64 loss: -2.2051258087158203
Batch 24/64 loss: -2.304645538330078
Batch 25/64 loss: -2.0497379302978516
Batch 26/64 loss: -2.0268983840942383
Batch 27/64 loss: -2.4012908935546875
Batch 28/64 loss: -2.338298797607422
Batch 29/64 loss: -2.1862897872924805
Batch 30/64 loss: -2.092686653137207
Batch 31/64 loss: -2.354307174682617
Batch 32/64 loss: -2.3111486434936523
Batch 33/64 loss: -2.3032283782958984
Batch 34/64 loss: -2.25516414642334
Batch 35/64 loss: -2.3799333572387695
Batch 36/64 loss: -2.391374111175537
Batch 37/64 loss: -2.245100975036621
Batch 38/64 loss: -2.389786720275879
Batch 39/64 loss: -2.2719650268554688
Batch 40/64 loss: -2.28731632232666
Batch 41/64 loss: -2.167125701904297
Batch 42/64 loss: -2.4328784942626953
Batch 43/64 loss: -2.444748878479004
Batch 44/64 loss: -2.442777156829834
Batch 45/64 loss: -2.385751724243164
Batch 46/64 loss: -2.0305051803588867
Batch 47/64 loss: -2.477797508239746
Batch 48/64 loss: -2.36618709564209
Batch 49/64 loss: -2.2273902893066406
Batch 50/64 loss: -2.3794965744018555
Batch 51/64 loss: -2.4983930587768555
Batch 52/64 loss: -2.4211935997009277
Batch 53/64 loss: -2.306429862976074
Batch 54/64 loss: -2.303253173828125
Batch 55/64 loss: -2.358062744140625
Batch 56/64 loss: -2.1413583755493164
Batch 57/64 loss: -2.3613171577453613
Batch 58/64 loss: -2.5533623695373535
Batch 59/64 loss: -2.4735517501831055
Batch 60/64 loss: -2.433444023132324
Batch 61/64 loss: -1.892125129699707
Batch 62/64 loss: -2.080502510070801
Batch 63/64 loss: -2.429180145263672
Batch 64/64 loss: -6.5824384689331055
Epoch 449  Train loss: -2.2980929617788277  Val loss: -2.5390209315978374
Epoch 450
-------------------------------
Batch 1/64 loss: -2.489315986633301
Batch 2/64 loss: -2.4516377449035645
Batch 3/64 loss: -2.250535011291504
Batch 4/64 loss: -1.8427009582519531
Batch 5/64 loss: -2.340156078338623
Batch 6/64 loss: -2.412071704864502
Batch 7/64 loss: -2.320183277130127
Batch 8/64 loss: -2.2271299362182617
Batch 9/64 loss: -2.275639533996582
Batch 10/64 loss: -2.1977672576904297
Batch 11/64 loss: -2.4598236083984375
Batch 12/64 loss: -2.170032501220703
Batch 13/64 loss: -2.2089014053344727
Batch 14/64 loss: -1.9442253112792969
Batch 15/64 loss: -2.4530444145202637
Batch 16/64 loss: -2.184734344482422
Batch 17/64 loss: -2.2324066162109375
Batch 18/64 loss: -2.27616024017334
Batch 19/64 loss: -2.051671028137207
Batch 20/64 loss: -2.3278369903564453
Batch 21/64 loss: -2.262478828430176
Batch 22/64 loss: -2.232818603515625
Batch 23/64 loss: -2.361271381378174
Batch 24/64 loss: -2.3148984909057617
Batch 25/64 loss: -2.408885955810547
Batch 26/64 loss: -2.3871641159057617
Batch 27/64 loss: -2.3081884384155273
Batch 28/64 loss: -2.318866729736328
Batch 29/64 loss: -2.4386730194091797
Batch 30/64 loss: -2.4412646293640137
Batch 31/64 loss: -2.322141647338867
Batch 32/64 loss: -2.286959648132324
Batch 33/64 loss: -2.511807918548584
Batch 34/64 loss: -2.4411020278930664
Batch 35/64 loss: -2.1146297454833984
Batch 36/64 loss: -2.4202957153320312
Batch 37/64 loss: -2.3556976318359375
Batch 38/64 loss: -2.076807975769043
Batch 39/64 loss: -2.3159379959106445
Batch 40/64 loss: -2.176942825317383
Batch 41/64 loss: -1.9773826599121094
Batch 42/64 loss: -2.1805858612060547
Batch 43/64 loss: -1.605072021484375
Batch 44/64 loss: -2.3891711235046387
Batch 45/64 loss: -2.1916675567626953
Batch 46/64 loss: -1.9445695877075195
Batch 47/64 loss: -2.357415199279785
Batch 48/64 loss: -2.2593564987182617
Batch 49/64 loss: -2.3905210494995117
Batch 50/64 loss: -1.9325475692749023
Batch 51/64 loss: -2.4923925399780273
Batch 52/64 loss: -2.3294525146484375
Batch 53/64 loss: -2.0540294647216797
Batch 54/64 loss: -2.3871002197265625
Batch 55/64 loss: -2.191253662109375
Batch 56/64 loss: -2.284602165222168
Batch 57/64 loss: -2.373602867126465
Batch 58/64 loss: -2.4424734115600586
Batch 59/64 loss: -2.3101186752319336
Batch 60/64 loss: -2.290599822998047
Batch 61/64 loss: -2.437678813934326
Batch 62/64 loss: -2.4368858337402344
Batch 63/64 loss: -2.32444429397583
Batch 64/64 loss: -6.442648887634277
Epoch 450  Train loss: -2.3220034094417796  Val loss: -2.486492995953642
Epoch 451
-------------------------------
Batch 1/64 loss: -2.3558273315429688
Batch 2/64 loss: -1.9408588409423828
Batch 3/64 loss: -2.4810400009155273
Batch 4/64 loss: -2.254000663757324
Batch 5/64 loss: -2.3520522117614746
Batch 6/64 loss: -2.359217643737793
Batch 7/64 loss: -2.2507801055908203
Batch 8/64 loss: -2.521407127380371
Batch 9/64 loss: -2.220794677734375
Batch 10/64 loss: -2.2338476181030273
Batch 11/64 loss: -2.016751289367676
Batch 12/64 loss: -2.319262981414795
Batch 13/64 loss: -2.4266719818115234
Batch 14/64 loss: -1.770798683166504
Batch 15/64 loss: -2.183051109313965
Batch 16/64 loss: -2.361349582672119
Batch 17/64 loss: -2.159754753112793
Batch 18/64 loss: -2.3665771484375
Batch 19/64 loss: -2.504089832305908
Batch 20/64 loss: -2.278313636779785
Batch 21/64 loss: -2.1248855590820312
Batch 22/64 loss: -2.4278178215026855
Batch 23/64 loss: -1.9868440628051758
Batch 24/64 loss: -2.4271392822265625
Batch 25/64 loss: -2.3827390670776367
Batch 26/64 loss: -2.233309745788574
Batch 27/64 loss: -2.321906089782715
Batch 28/64 loss: -2.389861583709717
Batch 29/64 loss: -2.4358696937561035
Batch 30/64 loss: -2.4309592247009277
Batch 31/64 loss: -2.4188528060913086
Batch 32/64 loss: -1.9370088577270508
Batch 33/64 loss: -2.477977752685547
Batch 34/64 loss: -2.387448310852051
Batch 35/64 loss: -2.450371742248535
Batch 36/64 loss: -2.3870954513549805
Batch 37/64 loss: -2.283839225769043
Batch 38/64 loss: -2.4486947059631348
Batch 39/64 loss: -2.379432201385498
Batch 40/64 loss: -2.4134693145751953
Batch 41/64 loss: -1.4856948852539062
Batch 42/64 loss: -2.358757972717285
Batch 43/64 loss: -2.371701240539551
Batch 44/64 loss: -2.2728090286254883
Batch 45/64 loss: -2.467092990875244
Batch 46/64 loss: -2.4487686157226562
Batch 47/64 loss: -2.402775287628174
Batch 48/64 loss: -2.5043210983276367
Batch 49/64 loss: -2.1794862747192383
Batch 50/64 loss: -2.200934410095215
Batch 51/64 loss: -2.37056827545166
Batch 52/64 loss: -2.041902542114258
Batch 53/64 loss: -2.3558030128479004
Batch 54/64 loss: -2.2433176040649414
Batch 55/64 loss: -2.4433798789978027
Batch 56/64 loss: -2.38248348236084
Batch 57/64 loss: -2.387855052947998
Batch 58/64 loss: -2.2357254028320312
Batch 59/64 loss: -2.328144073486328
Batch 60/64 loss: -2.3907828330993652
Batch 61/64 loss: -2.1146745681762695
Batch 62/64 loss: -2.2086448669433594
Batch 63/64 loss: -2.2894811630249023
Batch 64/64 loss: -6.308566093444824
Epoch 451  Train loss: -2.342250962350883  Val loss: -2.559671120135645
Epoch 452
-------------------------------
Batch 1/64 loss: -2.407642364501953
Batch 2/64 loss: -2.3862180709838867
Batch 3/64 loss: -2.3197970390319824
Batch 4/64 loss: -2.3844895362854004
Batch 5/64 loss: -2.3675880432128906
Batch 6/64 loss: -2.1847896575927734
Batch 7/64 loss: -2.3534703254699707
Batch 8/64 loss: -2.3632164001464844
Batch 9/64 loss: -2.3792452812194824
Batch 10/64 loss: -1.8198833465576172
Batch 11/64 loss: -2.3913846015930176
Batch 12/64 loss: -2.563838481903076
Batch 13/64 loss: -2.306403160095215
Batch 14/64 loss: -2.4960098266601562
Batch 15/64 loss: -2.3349666595458984
Batch 16/64 loss: -2.1309194564819336
Batch 17/64 loss: -2.401297092437744
Batch 18/64 loss: -2.303403854370117
Batch 19/64 loss: -2.404569625854492
Batch 20/64 loss: -2.4974184036254883
Batch 21/64 loss: -2.4809694290161133
Batch 22/64 loss: -2.429109573364258
Batch 23/64 loss: -2.1666955947875977
Batch 24/64 loss: -2.2492055892944336
Batch 25/64 loss: -2.501732349395752
Batch 26/64 loss: -2.346693992614746
Batch 27/64 loss: -2.082282066345215
Batch 28/64 loss: -2.384920597076416
Batch 29/64 loss: -2.305415153503418
Batch 30/64 loss: -2.2099151611328125
Batch 31/64 loss: -2.354402542114258
Batch 32/64 loss: -2.3947505950927734
Batch 33/64 loss: -2.334451675415039
Batch 34/64 loss: -1.6680316925048828
Batch 35/64 loss: -2.1435470581054688
Batch 36/64 loss: -2.220778465270996
Batch 37/64 loss: -2.3648366928100586
Batch 38/64 loss: -1.5168256759643555
Batch 39/64 loss: -2.2881593704223633
Batch 40/64 loss: -2.3938193321228027
Batch 41/64 loss: -2.3624801635742188
Batch 42/64 loss: -2.4292030334472656
Batch 43/64 loss: -2.188629150390625
Batch 44/64 loss: -2.271179676055908
Batch 45/64 loss: -2.3041257858276367
Batch 46/64 loss: -2.340311050415039
Batch 47/64 loss: -1.9047069549560547
Batch 48/64 loss: -2.369658946990967
Batch 49/64 loss: -2.2968826293945312
Batch 50/64 loss: -2.1871957778930664
Batch 51/64 loss: -2.3861780166625977
Batch 52/64 loss: -2.2031354904174805
Batch 53/64 loss: -2.3850841522216797
Batch 54/64 loss: -2.3251500129699707
Batch 55/64 loss: -1.7553844451904297
Batch 56/64 loss: -2.279749870300293
Batch 57/64 loss: -2.227571487426758
Batch 58/64 loss: -2.309694290161133
Batch 59/64 loss: -2.143392562866211
Batch 60/64 loss: -2.1695518493652344
Batch 61/64 loss: -2.2959442138671875
Batch 62/64 loss: -1.9406356811523438
Batch 63/64 loss: -2.2807059288024902
Batch 64/64 loss: -6.275882720947266
Epoch 452  Train loss: -2.3168087379605162  Val loss: -2.4950695234475675
Epoch 453
-------------------------------
Batch 1/64 loss: -2.4495372772216797
Batch 2/64 loss: -2.102296829223633
Batch 3/64 loss: -1.3208627700805664
Batch 4/64 loss: -2.325559139251709
Batch 5/64 loss: -2.1076908111572266
Batch 6/64 loss: -2.4310030937194824
Batch 7/64 loss: -2.477419376373291
Batch 8/64 loss: -2.187002182006836
Batch 9/64 loss: -2.150082588195801
Batch 10/64 loss: -2.1007261276245117
Batch 11/64 loss: -2.334807872772217
Batch 12/64 loss: -2.293221950531006
Batch 13/64 loss: -2.324835777282715
Batch 14/64 loss: -2.1518545150756836
Batch 15/64 loss: -2.373673439025879
Batch 16/64 loss: -2.26308536529541
Batch 17/64 loss: -1.5569305419921875
Batch 18/64 loss: -2.2827205657958984
Batch 19/64 loss: -2.2417426109313965
Batch 20/64 loss: -2.2378368377685547
Batch 21/64 loss: -2.379486560821533
Batch 22/64 loss: -2.3720197677612305
Batch 23/64 loss: -1.8163127899169922
Batch 24/64 loss: -2.1121644973754883
Batch 25/64 loss: -2.1746273040771484
Batch 26/64 loss: -2.4159812927246094
Batch 27/64 loss: -2.1694536209106445
Batch 28/64 loss: -2.2590346336364746
Batch 29/64 loss: -2.2635107040405273
Batch 30/64 loss: -2.208207130432129
Batch 31/64 loss: -2.149587631225586
Batch 32/64 loss: -2.1435651779174805
Batch 33/64 loss: -2.2368946075439453
Batch 34/64 loss: -2.40718936920166
Batch 35/64 loss: -2.1411304473876953
Batch 36/64 loss: -2.3712844848632812
Batch 37/64 loss: -2.1609134674072266
Batch 38/64 loss: -2.2575411796569824
Batch 39/64 loss: -2.2765140533447266
Batch 40/64 loss: -2.1034936904907227
Batch 41/64 loss: -2.2898240089416504
Batch 42/64 loss: -2.339660167694092
Batch 43/64 loss: -2.215643882751465
Batch 44/64 loss: -2.09536075592041
Batch 45/64 loss: -2.387305736541748
Batch 46/64 loss: -2.389080047607422
Batch 47/64 loss: -2.1543025970458984
Batch 48/64 loss: -2.3390321731567383
Batch 49/64 loss: -1.988037109375
Batch 50/64 loss: -2.5433554649353027
Batch 51/64 loss: -2.2453784942626953
Batch 52/64 loss: -2.308436393737793
Batch 53/64 loss: -2.4677505493164062
Batch 54/64 loss: -2.2205305099487305
Batch 55/64 loss: -2.4800076484680176
Batch 56/64 loss: -2.3718533515930176
Batch 57/64 loss: -2.3848352432250977
Batch 58/64 loss: -2.5290212631225586
Batch 59/64 loss: -2.2349510192871094
Batch 60/64 loss: -2.0457706451416016
Batch 61/64 loss: -2.163027763366699
Batch 62/64 loss: -2.2200002670288086
Batch 63/64 loss: -2.376934051513672
Batch 64/64 loss: -6.441686153411865
Epoch 453  Train loss: -2.2863241700565116  Val loss: -2.6045937030176116
Epoch 454
-------------------------------
Batch 1/64 loss: -1.394561767578125
Batch 2/64 loss: -2.3139190673828125
Batch 3/64 loss: -2.200155258178711
Batch 4/64 loss: -2.138774871826172
Batch 5/64 loss: -2.3495545387268066
Batch 6/64 loss: -2.0076189041137695
Batch 7/64 loss: -2.2495851516723633
Batch 8/64 loss: -2.356553077697754
Batch 9/64 loss: -2.0211076736450195
Batch 10/64 loss: -2.3645009994506836
Batch 11/64 loss: -2.099886894226074
Batch 12/64 loss: -2.2791290283203125
Batch 13/64 loss: -2.4373011589050293
Batch 14/64 loss: -2.331462860107422
Batch 15/64 loss: -2.2988243103027344
Batch 16/64 loss: -2.3745737075805664
Batch 17/64 loss: -2.5305542945861816
Batch 18/64 loss: -2.146195411682129
Batch 19/64 loss: -2.2470855712890625
Batch 20/64 loss: -2.5202908515930176
Batch 21/64 loss: -2.3198938369750977
Batch 22/64 loss: -1.953394889831543
Batch 23/64 loss: -2.104130744934082
Batch 24/64 loss: -2.518436908721924
Batch 25/64 loss: -2.4288277626037598
Batch 26/64 loss: -2.2687487602233887
Batch 27/64 loss: -2.4537243843078613
Batch 28/64 loss: -2.4178037643432617
Batch 29/64 loss: -2.4398531913757324
Batch 30/64 loss: -2.5556607246398926
Batch 31/64 loss: -2.1183433532714844
Batch 32/64 loss: -2.3293137550354004
Batch 33/64 loss: -2.3291873931884766
Batch 34/64 loss: -2.2533111572265625
Batch 35/64 loss: -2.2950687408447266
Batch 36/64 loss: -2.184544563293457
Batch 37/64 loss: -2.275938034057617
Batch 38/64 loss: -2.042074203491211
Batch 39/64 loss: -2.42539119720459
Batch 40/64 loss: -2.49184513092041
Batch 41/64 loss: -2.2800073623657227
Batch 42/64 loss: -2.269524574279785
Batch 43/64 loss: -2.313809394836426
Batch 44/64 loss: -2.4573111534118652
Batch 45/64 loss: -2.3111109733581543
Batch 46/64 loss: -2.2224435806274414
Batch 47/64 loss: -2.262345314025879
Batch 48/64 loss: -2.4165592193603516
Batch 49/64 loss: -2.3321399688720703
Batch 50/64 loss: -2.400911808013916
Batch 51/64 loss: -2.3735408782958984
Batch 52/64 loss: -2.224018096923828
Batch 53/64 loss: -2.178792953491211
Batch 54/64 loss: -2.3690738677978516
Batch 55/64 loss: -2.288299560546875
Batch 56/64 loss: -2.3418397903442383
Batch 57/64 loss: -2.246964454650879
Batch 58/64 loss: -1.8482389450073242
Batch 59/64 loss: -2.468024253845215
Batch 60/64 loss: -2.325139045715332
Batch 61/64 loss: -2.324342727661133
Batch 62/64 loss: -2.1810569763183594
Batch 63/64 loss: -1.8114862442016602
Batch 64/64 loss: -6.421553134918213
Epoch 454  Train loss: -2.320474884556789  Val loss: -2.6562483220575603
Epoch 455
-------------------------------
Batch 1/64 loss: -2.3758316040039062
Batch 2/64 loss: -2.3181495666503906
Batch 3/64 loss: -2.3933401107788086
Batch 4/64 loss: -2.4189395904541016
Batch 5/64 loss: -2.404480457305908
Batch 6/64 loss: -2.528691291809082
Batch 7/64 loss: -2.450054168701172
Batch 8/64 loss: -2.2681589126586914
Batch 9/64 loss: -2.498795509338379
Batch 10/64 loss: -2.442598819732666
Batch 11/64 loss: -2.4717578887939453
Batch 12/64 loss: -2.3834052085876465
Batch 13/64 loss: -2.2672643661499023
Batch 14/64 loss: -2.0637645721435547
Batch 15/64 loss: -1.307051658630371
Batch 16/64 loss: -2.3680858612060547
Batch 17/64 loss: -2.4004483222961426
Batch 18/64 loss: -2.244570732116699
Batch 19/64 loss: -2.2586050033569336
Batch 20/64 loss: -2.3806233406066895
Batch 21/64 loss: -2.4954404830932617
Batch 22/64 loss: -2.290337562561035
Batch 23/64 loss: -2.4980969429016113
Batch 24/64 loss: -2.4339914321899414
Batch 25/64 loss: -2.4072256088256836
Batch 26/64 loss: -2.4638586044311523
Batch 27/64 loss: -2.271444320678711
Batch 28/64 loss: -2.454103946685791
Batch 29/64 loss: -2.4220714569091797
Batch 30/64 loss: -2.5014638900756836
Batch 31/64 loss: -2.361867904663086
Batch 32/64 loss: -2.1367568969726562
Batch 33/64 loss: -2.397029399871826
Batch 34/64 loss: -2.4440712928771973
Batch 35/64 loss: -2.250687599182129
Batch 36/64 loss: -2.549506187438965
Batch 37/64 loss: -2.406374931335449
Batch 38/64 loss: -1.6764240264892578
Batch 39/64 loss: -2.4244322776794434
Batch 40/64 loss: -2.0918455123901367
Batch 41/64 loss: -2.2062149047851562
Batch 42/64 loss: -1.2265644073486328
Batch 43/64 loss: -2.200654983520508
Batch 44/64 loss: -1.8959016799926758
Batch 45/64 loss: -1.9617576599121094
Batch 46/64 loss: -2.184957504272461
Batch 47/64 loss: -2.2183237075805664
Batch 48/64 loss: -2.3363099098205566
Batch 49/64 loss: -2.204092025756836
Batch 50/64 loss: -2.036958694458008
Batch 51/64 loss: -2.3448972702026367
Batch 52/64 loss: -1.8891983032226562
Batch 53/64 loss: -1.7325782775878906
Batch 54/64 loss: -2.238347053527832
Batch 55/64 loss: -2.335310935974121
Batch 56/64 loss: -2.1116209030151367
Batch 57/64 loss: -2.328555107116699
Batch 58/64 loss: -2.008681297302246
Batch 59/64 loss: -2.024664878845215
Batch 60/64 loss: -2.387632369995117
Batch 61/64 loss: -2.098939895629883
Batch 62/64 loss: -2.237152099609375
Batch 63/64 loss: -2.278538227081299
Batch 64/64 loss: -6.48645544052124
Epoch 455  Train loss: -2.29920534807093  Val loss: -2.5077389458200776
Epoch 456
-------------------------------
Batch 1/64 loss: -2.4000391960144043
Batch 2/64 loss: -2.042013168334961
Batch 3/64 loss: -2.1877031326293945
Batch 4/64 loss: -2.084120750427246
Batch 5/64 loss: -2.362698554992676
Batch 6/64 loss: -2.389073371887207
Batch 7/64 loss: -2.363797664642334
Batch 8/64 loss: -2.3696656227111816
Batch 9/64 loss: -2.1747875213623047
Batch 10/64 loss: -2.339914321899414
Batch 11/64 loss: -1.7819929122924805
Batch 12/64 loss: -2.2733850479125977
Batch 13/64 loss: -2.0561695098876953
Batch 14/64 loss: -1.8171958923339844
Batch 15/64 loss: -2.330502510070801
Batch 16/64 loss: -2.3370838165283203
Batch 17/64 loss: -2.2686777114868164
Batch 18/64 loss: -2.0959692001342773
Batch 19/64 loss: -2.4046764373779297
Batch 20/64 loss: -2.3637161254882812
Batch 21/64 loss: -1.3337430953979492
Batch 22/64 loss: -2.153435707092285
Batch 23/64 loss: -2.3530750274658203
Batch 24/64 loss: -2.272759437561035
Batch 25/64 loss: -2.1973142623901367
Batch 26/64 loss: -2.182633399963379
Batch 27/64 loss: -2.2186126708984375
Batch 28/64 loss: -2.1978044509887695
Batch 29/64 loss: -2.400204658508301
Batch 30/64 loss: -1.811056137084961
Batch 31/64 loss: -2.2248611450195312
Batch 32/64 loss: -2.170656204223633
Batch 33/64 loss: -2.222500801086426
Batch 34/64 loss: -2.1965150833129883
Batch 35/64 loss: -2.255061149597168
Batch 36/64 loss: -2.16558837890625
Batch 37/64 loss: -2.1677379608154297
Batch 38/64 loss: -2.0824851989746094
Batch 39/64 loss: -2.3945837020874023
Batch 40/64 loss: -2.4064512252807617
Batch 41/64 loss: -2.120364189147949
Batch 42/64 loss: -2.1408872604370117
Batch 43/64 loss: -2.1491622924804688
Batch 44/64 loss: -2.2598791122436523
Batch 45/64 loss: -2.358250617980957
Batch 46/64 loss: -2.3417234420776367
Batch 47/64 loss: -2.324185371398926
Batch 48/64 loss: -2.1289453506469727
Batch 49/64 loss: -1.4683046340942383
Batch 50/64 loss: -1.25421142578125
Batch 51/64 loss: -2.2957162857055664
Batch 52/64 loss: -2.334336280822754
Batch 53/64 loss: -1.8199710845947266
Batch 54/64 loss: -1.9685258865356445
Batch 55/64 loss: -2.1038951873779297
Batch 56/64 loss: -1.8665180206298828
Batch 57/64 loss: -2.0567684173583984
Batch 58/64 loss: -1.9324378967285156
Batch 59/64 loss: -2.092975616455078
Batch 60/64 loss: -2.0894155502319336
Batch 61/64 loss: -2.160045623779297
Batch 62/64 loss: -2.0901193618774414
Batch 63/64 loss: -2.07265567779541
Batch 64/64 loss: -6.253086090087891
Epoch 456  Train loss: -2.1955979814716415  Val loss: -2.3296408112516107
Epoch 457
-------------------------------
Batch 1/64 loss: -2.454068660736084
Batch 2/64 loss: -2.0113582611083984
Batch 3/64 loss: -1.9316673278808594
Batch 4/64 loss: -2.0550785064697266
Batch 5/64 loss: -1.8788185119628906
Batch 6/64 loss: -1.930105209350586
Batch 7/64 loss: -1.7423410415649414
Batch 8/64 loss: -2.122652053833008
Batch 9/64 loss: -2.240835189819336
Batch 10/64 loss: -1.9801292419433594
Batch 11/64 loss: -2.2450246810913086
Batch 12/64 loss: -1.8462324142456055
Batch 13/64 loss: -1.9923210144042969
Batch 14/64 loss: -2.0648298263549805
Batch 15/64 loss: -2.006610870361328
Batch 16/64 loss: -2.131564140319824
Batch 17/64 loss: -2.3036022186279297
Batch 18/64 loss: -2.2121591567993164
Batch 19/64 loss: -2.107344627380371
Batch 20/64 loss: -1.3861942291259766
Batch 21/64 loss: -2.3000874519348145
Batch 22/64 loss: -2.34478759765625
Batch 23/64 loss: -2.164081573486328
Batch 24/64 loss: -2.4021997451782227
Batch 25/64 loss: -2.1466188430786133
Batch 26/64 loss: -2.242222785949707
Batch 27/64 loss: -2.3346505165100098
Batch 28/64 loss: -2.441856861114502
Batch 29/64 loss: -2.226276397705078
Batch 30/64 loss: -2.305398941040039
Batch 31/64 loss: -2.368905544281006
Batch 32/64 loss: -1.468031883239746
Batch 33/64 loss: -2.190030097961426
Batch 34/64 loss: -2.2760348320007324
Batch 35/64 loss: -2.280691146850586
Batch 36/64 loss: -2.0269927978515625
Batch 37/64 loss: -2.0528202056884766
Batch 38/64 loss: -1.9542999267578125
Batch 39/64 loss: -2.3467488288879395
Batch 40/64 loss: -2.3897290229797363
Batch 41/64 loss: -2.094996452331543
Batch 42/64 loss: -2.288010597229004
Batch 43/64 loss: -2.3703107833862305
Batch 44/64 loss: -2.226236343383789
Batch 45/64 loss: -1.9300460815429688
Batch 46/64 loss: -2.309872627258301
Batch 47/64 loss: -1.8829755783081055
Batch 48/64 loss: -1.3489341735839844
Batch 49/64 loss: -2.265511989593506
Batch 50/64 loss: -2.2517948150634766
Batch 51/64 loss: -2.2155847549438477
Batch 52/64 loss: -2.3036136627197266
Batch 53/64 loss: -2.275214195251465
Batch 54/64 loss: -2.2370681762695312
Batch 55/64 loss: -1.8100404739379883
Batch 56/64 loss: -2.325176239013672
Batch 57/64 loss: -2.2411890029907227
Batch 58/64 loss: -2.3806705474853516
Batch 59/64 loss: -2.1063499450683594
Batch 60/64 loss: -2.216891288757324
Batch 61/64 loss: -2.030385971069336
Batch 62/64 loss: -2.0707969665527344
Batch 63/64 loss: -2.0226917266845703
Batch 64/64 loss: -6.387598037719727
Epoch 457  Train loss: -2.1788307937921263  Val loss: -2.3603318860031077
Epoch 458
-------------------------------
Batch 1/64 loss: -2.026768684387207
Batch 2/64 loss: -1.4343996047973633
Batch 3/64 loss: -1.496133804321289
Batch 4/64 loss: -1.271805763244629
Batch 5/64 loss: -2.086458206176758
Batch 6/64 loss: -2.189777374267578
Batch 7/64 loss: -2.158254623413086
Batch 8/64 loss: -2.3512444496154785
Batch 9/64 loss: -2.222597122192383
Batch 10/64 loss: -1.9959297180175781
Batch 11/64 loss: -2.2698135375976562
Batch 12/64 loss: -1.652984619140625
Batch 13/64 loss: -2.304886817932129
Batch 14/64 loss: -2.313723564147949
Batch 15/64 loss: -2.0826244354248047
Batch 16/64 loss: -2.3132357597351074
Batch 17/64 loss: -1.871591567993164
Batch 18/64 loss: -2.1438379287719727
Batch 19/64 loss: -2.2740182876586914
Batch 20/64 loss: -2.204519271850586
Batch 21/64 loss: -2.258742332458496
Batch 22/64 loss: -2.3492918014526367
Batch 23/64 loss: -2.2732205390930176
Batch 24/64 loss: -2.1462631225585938
Batch 25/64 loss: -2.15289306640625
Batch 26/64 loss: -2.222524642944336
Batch 27/64 loss: -2.2662582397460938
Batch 28/64 loss: -1.6477327346801758
Batch 29/64 loss: -2.2856783866882324
Batch 30/64 loss: -2.2084732055664062
Batch 31/64 loss: -2.4604873657226562
Batch 32/64 loss: -2.096893310546875
Batch 33/64 loss: -2.2044315338134766
Batch 34/64 loss: -1.864914894104004
Batch 35/64 loss: -2.1413564682006836
Batch 36/64 loss: -2.4777774810791016
Batch 37/64 loss: -2.3879661560058594
Batch 38/64 loss: -2.231106758117676
Batch 39/64 loss: -2.3797764778137207
Batch 40/64 loss: -2.2110795974731445
Batch 41/64 loss: -2.158937454223633
Batch 42/64 loss: -1.983856201171875
Batch 43/64 loss: -2.337808132171631
Batch 44/64 loss: -2.222635269165039
Batch 45/64 loss: -2.384354591369629
Batch 46/64 loss: -2.365058422088623
Batch 47/64 loss: -2.4467644691467285
Batch 48/64 loss: -2.1695146560668945
Batch 49/64 loss: -2.299825668334961
Batch 50/64 loss: -2.121994972229004
Batch 51/64 loss: -2.27630615234375
Batch 52/64 loss: -2.148207664489746
Batch 53/64 loss: -2.0434303283691406
Batch 54/64 loss: -2.2088022232055664
Batch 55/64 loss: -2.270702362060547
Batch 56/64 loss: -2.290177345275879
Batch 57/64 loss: -2.3050999641418457
Batch 58/64 loss: -2.3509726524353027
Batch 59/64 loss: -2.383944034576416
Batch 60/64 loss: -2.08172607421875
Batch 61/64 loss: -2.301499366760254
Batch 62/64 loss: -2.1792640686035156
Batch 63/64 loss: -2.294754981994629
Batch 64/64 loss: -6.240870952606201
Epoch 458  Train loss: -2.2154943297891054  Val loss: -2.615958852866261
Epoch 459
-------------------------------
Batch 1/64 loss: -2.2290258407592773
Batch 2/64 loss: -2.300212860107422
Batch 3/64 loss: -2.32883358001709
Batch 4/64 loss: -2.198314666748047
Batch 5/64 loss: -2.3699073791503906
Batch 6/64 loss: -1.6766014099121094
Batch 7/64 loss: -2.2253952026367188
Batch 8/64 loss: -2.5194616317749023
Batch 9/64 loss: -2.429067611694336
Batch 10/64 loss: -2.236212730407715
Batch 11/64 loss: -2.1512222290039062
Batch 12/64 loss: -2.363347053527832
Batch 13/64 loss: -1.3557872772216797
Batch 14/64 loss: -2.1277589797973633
Batch 15/64 loss: -2.4432997703552246
Batch 16/64 loss: -1.5313520431518555
Batch 17/64 loss: -2.0282669067382812
Batch 18/64 loss: -2.286128044128418
Batch 19/64 loss: -2.139775276184082
Batch 20/64 loss: -2.2846784591674805
Batch 21/64 loss: -2.515674114227295
Batch 22/64 loss: -2.2716665267944336
Batch 23/64 loss: -2.000356674194336
Batch 24/64 loss: -2.263662338256836
Batch 25/64 loss: -2.3022050857543945
Batch 26/64 loss: -2.247098922729492
Batch 27/64 loss: -2.33380126953125
Batch 28/64 loss: -2.1146974563598633
Batch 29/64 loss: -2.4172096252441406
Batch 30/64 loss: -2.3539528846740723
Batch 31/64 loss: -2.3324499130249023
Batch 32/64 loss: -2.05935001373291
Batch 33/64 loss: -2.288816452026367
Batch 34/64 loss: -2.331691265106201
Batch 35/64 loss: -2.1647987365722656
Batch 36/64 loss: -2.4744176864624023
Batch 37/64 loss: -2.232914924621582
Batch 38/64 loss: -2.366166591644287
Batch 39/64 loss: -2.3235273361206055
Batch 40/64 loss: -2.364307403564453
Batch 41/64 loss: -1.8178625106811523
Batch 42/64 loss: -2.3300485610961914
Batch 43/64 loss: -2.356411933898926
Batch 44/64 loss: -1.5246562957763672
Batch 45/64 loss: -2.224423408508301
Batch 46/64 loss: -2.2896738052368164
Batch 47/64 loss: -2.328643798828125
Batch 48/64 loss: -2.193110466003418
Batch 49/64 loss: -2.38677978515625
Batch 50/64 loss: -2.2107467651367188
Batch 51/64 loss: -2.303175926208496
Batch 52/64 loss: -2.0818843841552734
Batch 53/64 loss: -2.263643264770508
Batch 54/64 loss: -2.0179271697998047
Batch 55/64 loss: -2.34427547454834
Batch 56/64 loss: -2.292541980743408
Batch 57/64 loss: -1.857865333557129
Batch 58/64 loss: -2.4308414459228516
Batch 59/64 loss: -2.020601272583008
Batch 60/64 loss: -2.429009437561035
Batch 61/64 loss: -2.2311458587646484
Batch 62/64 loss: -2.050079345703125
Batch 63/64 loss: -2.4381723403930664
Batch 64/64 loss: -6.456114292144775
Epoch 459  Train loss: -2.262729732663024  Val loss: -2.5499060981462094
Epoch 460
-------------------------------
Batch 1/64 loss: -2.286411762237549
Batch 2/64 loss: -1.524165153503418
Batch 3/64 loss: -2.40169095993042
Batch 4/64 loss: -2.2428207397460938
Batch 5/64 loss: -2.1377038955688477
Batch 6/64 loss: -2.2416892051696777
Batch 7/64 loss: -2.2113332748413086
Batch 8/64 loss: -2.0493059158325195
Batch 9/64 loss: -2.325821876525879
Batch 10/64 loss: -1.6811256408691406
Batch 11/64 loss: -2.2502336502075195
Batch 12/64 loss: -2.304647922515869
Batch 13/64 loss: -1.8546113967895508
Batch 14/64 loss: -2.253415107727051
Batch 15/64 loss: -2.026325225830078
Batch 16/64 loss: -2.393573760986328
Batch 17/64 loss: -2.124788284301758
Batch 18/64 loss: -2.094986915588379
Batch 19/64 loss: -2.2671542167663574
Batch 20/64 loss: -2.3282008171081543
Batch 21/64 loss: -2.4665966033935547
Batch 22/64 loss: -2.3417792320251465
Batch 23/64 loss: -2.5584664344787598
Batch 24/64 loss: -2.4063491821289062
Batch 25/64 loss: -2.1329450607299805
Batch 26/64 loss: -2.4100289344787598
Batch 27/64 loss: -2.2298107147216797
Batch 28/64 loss: -2.1801939010620117
Batch 29/64 loss: -2.43361759185791
Batch 30/64 loss: -2.476468086242676
Batch 31/64 loss: -2.3245692253112793
Batch 32/64 loss: -2.4060544967651367
Batch 33/64 loss: -2.426150321960449
Batch 34/64 loss: -2.3538618087768555
Batch 35/64 loss: -2.4034061431884766
Batch 36/64 loss: -2.2710933685302734
Batch 37/64 loss: -2.2966365814208984
Batch 38/64 loss: -2.3769826889038086
Batch 39/64 loss: -2.2203369140625
Batch 40/64 loss: -2.5233559608459473
Batch 41/64 loss: -2.42138671875
Batch 42/64 loss: -2.465791702270508
Batch 43/64 loss: -2.4065699577331543
Batch 44/64 loss: -2.3820924758911133
Batch 45/64 loss: -2.3288984298706055
Batch 46/64 loss: -2.293701171875
Batch 47/64 loss: -2.295045852661133
Batch 48/64 loss: -2.33290433883667
Batch 49/64 loss: -2.299236297607422
Batch 50/64 loss: -2.192319869995117
Batch 51/64 loss: -2.365736961364746
Batch 52/64 loss: -2.226719856262207
Batch 53/64 loss: -2.2031469345092773
Batch 54/64 loss: -1.8998737335205078
Batch 55/64 loss: -2.34666109085083
Batch 56/64 loss: -2.4046120643615723
Batch 57/64 loss: -2.4456214904785156
Batch 58/64 loss: -2.391623020172119
Batch 59/64 loss: -2.5767364501953125
Batch 60/64 loss: -2.460278034210205
Batch 61/64 loss: -2.5047826766967773
Batch 62/64 loss: -2.2021360397338867
Batch 63/64 loss: -2.2280635833740234
Batch 64/64 loss: -6.4164509773254395
Epoch 460  Train loss: -2.3329409561905208  Val loss: -2.5799096884186734
Epoch 461
-------------------------------
Batch 1/64 loss: -2.246458053588867
Batch 2/64 loss: -2.1443586349487305
Batch 3/64 loss: -2.1196861267089844
Batch 4/64 loss: -2.4807701110839844
Batch 5/64 loss: -2.389528751373291
Batch 6/64 loss: -2.346222400665283
Batch 7/64 loss: -2.505770683288574
Batch 8/64 loss: -2.358506679534912
Batch 9/64 loss: -2.3583059310913086
Batch 10/64 loss: -2.4912261962890625
Batch 11/64 loss: -2.434030055999756
Batch 12/64 loss: -2.4532642364501953
Batch 13/64 loss: -2.4491066932678223
Batch 14/64 loss: -2.487412452697754
Batch 15/64 loss: -2.4406027793884277
Batch 16/64 loss: -2.5253114700317383
Batch 17/64 loss: -1.7503652572631836
Batch 18/64 loss: -2.4772214889526367
Batch 19/64 loss: -2.1408042907714844
Batch 20/64 loss: -2.411644458770752
Batch 21/64 loss: -2.145270347595215
Batch 22/64 loss: -2.452667236328125
Batch 23/64 loss: -2.527555465698242
Batch 24/64 loss: -2.3560938835144043
Batch 25/64 loss: -2.2577877044677734
Batch 26/64 loss: -2.1428537368774414
Batch 27/64 loss: -2.28466796875
Batch 28/64 loss: -2.3203086853027344
Batch 29/64 loss: -2.461817741394043
Batch 30/64 loss: -2.365614414215088
Batch 31/64 loss: -2.126544952392578
Batch 32/64 loss: -2.4154744148254395
Batch 33/64 loss: -2.351975917816162
Batch 34/64 loss: -2.1666479110717773
Batch 35/64 loss: -2.4308810234069824
Batch 36/64 loss: -2.5031356811523438
Batch 37/64 loss: -1.5913419723510742
Batch 38/64 loss: -2.3394241333007812
Batch 39/64 loss: -2.3279685974121094
Batch 40/64 loss: -2.1263723373413086
Batch 41/64 loss: -2.270989418029785
Batch 42/64 loss: -2.447355270385742
Batch 43/64 loss: -2.281113624572754
Batch 44/64 loss: -2.2050161361694336
Batch 45/64 loss: -2.4058871269226074
Batch 46/64 loss: -2.319647789001465
Batch 47/64 loss: -1.744558334350586
Batch 48/64 loss: -2.335873603820801
Batch 49/64 loss: -2.265212059020996
Batch 50/64 loss: -2.070042610168457
Batch 51/64 loss: -2.376133918762207
Batch 52/64 loss: -2.425943374633789
Batch 53/64 loss: -2.1443920135498047
Batch 54/64 loss: -2.218433380126953
Batch 55/64 loss: -2.21673583984375
Batch 56/64 loss: -2.2808542251586914
Batch 57/64 loss: -2.222195625305176
Batch 58/64 loss: -2.363438606262207
Batch 59/64 loss: -2.290407180786133
Batch 60/64 loss: -2.0251007080078125
Batch 61/64 loss: -2.02352237701416
Batch 62/64 loss: -2.2414560317993164
Batch 63/64 loss: -2.056342124938965
Batch 64/64 loss: -6.538512706756592
Epoch 461  Train loss: -2.3347378319385004  Val loss: -2.600851288366154
Epoch 462
-------------------------------
Batch 1/64 loss: -2.153341293334961
Batch 2/64 loss: -2.4464573860168457
Batch 3/64 loss: -2.3855504989624023
Batch 4/64 loss: -2.4050159454345703
Batch 5/64 loss: -2.440506935119629
Batch 6/64 loss: -2.263397216796875
Batch 7/64 loss: -2.303823471069336
Batch 8/64 loss: -2.339888572692871
Batch 9/64 loss: -2.292325019836426
Batch 10/64 loss: -2.330911159515381
Batch 11/64 loss: -2.3423848152160645
Batch 12/64 loss: -2.336585521697998
Batch 13/64 loss: -2.391084671020508
Batch 14/64 loss: -2.369142532348633
Batch 15/64 loss: -2.3385086059570312
Batch 16/64 loss: -1.9217185974121094
Batch 17/64 loss: -2.2573471069335938
Batch 18/64 loss: -2.0335521697998047
Batch 19/64 loss: -2.3626151084899902
Batch 20/64 loss: -2.3282241821289062
Batch 21/64 loss: -2.312236785888672
Batch 22/64 loss: -2.17181396484375
Batch 23/64 loss: -2.229511260986328
Batch 24/64 loss: -2.10927677154541
Batch 25/64 loss: -2.35243558883667
Batch 26/64 loss: -2.408937454223633
Batch 27/64 loss: -1.8335981369018555
Batch 28/64 loss: -2.276139259338379
Batch 29/64 loss: -2.2545700073242188
Batch 30/64 loss: -2.408787727355957
Batch 31/64 loss: -2.153622627258301
Batch 32/64 loss: -2.447877883911133
Batch 33/64 loss: -2.236957550048828
Batch 34/64 loss: -1.5486221313476562
Batch 35/64 loss: -1.9310979843139648
Batch 36/64 loss: -2.340606212615967
Batch 37/64 loss: -2.343202590942383
Batch 38/64 loss: -2.231149673461914
Batch 39/64 loss: -2.153736114501953
Batch 40/64 loss: -2.300081729888916
Batch 41/64 loss: -1.2101268768310547
Batch 42/64 loss: -2.0510759353637695
Batch 43/64 loss: -2.229013442993164
Batch 44/64 loss: -1.360814094543457
Batch 45/64 loss: -2.061507225036621
Batch 46/64 loss: -2.2015609741210938
Batch 47/64 loss: -2.033710479736328
Batch 48/64 loss: -2.1243467330932617
Batch 49/64 loss: -1.8944902420043945
Batch 50/64 loss: -2.18194580078125
Batch 51/64 loss: -2.0265016555786133
Batch 52/64 loss: -1.713876724243164
Batch 53/64 loss: -1.5965957641601562
Batch 54/64 loss: -2.2289085388183594
Batch 55/64 loss: -2.296137809753418
Batch 56/64 loss: -2.447676181793213
Batch 57/64 loss: -2.123419761657715
Batch 58/64 loss: -1.8820104598999023
Batch 59/64 loss: -2.2131309509277344
Batch 60/64 loss: -2.321904182434082
Batch 61/64 loss: -2.291083335876465
Batch 62/64 loss: -2.0567874908447266
Batch 63/64 loss: -2.1601390838623047
Batch 64/64 loss: -6.377420902252197
Epoch 462  Train loss: -2.220807399001776  Val loss: -2.5221454712123808
Epoch 463
-------------------------------
Batch 1/64 loss: -2.460630416870117
Batch 2/64 loss: -2.121729850769043
Batch 3/64 loss: -2.2080211639404297
Batch 4/64 loss: -1.7147703170776367
Batch 5/64 loss: -1.8937568664550781
Batch 6/64 loss: -2.300806999206543
Batch 7/64 loss: -2.37320613861084
Batch 8/64 loss: -2.268775463104248
Batch 9/64 loss: -2.379833221435547
Batch 10/64 loss: -2.2111740112304688
Batch 11/64 loss: -2.183683395385742
Batch 12/64 loss: -2.294682502746582
Batch 13/64 loss: -2.3619136810302734
Batch 14/64 loss: -2.12615966796875
Batch 15/64 loss: -2.38059139251709
Batch 16/64 loss: -1.922867774963379
Batch 17/64 loss: -2.411074161529541
Batch 18/64 loss: -2.2919511795043945
Batch 19/64 loss: -2.1005897521972656
Batch 20/64 loss: -1.9779233932495117
Batch 21/64 loss: -2.2775745391845703
Batch 22/64 loss: -2.438411235809326
Batch 23/64 loss: -2.230154037475586
Batch 24/64 loss: -2.084026336669922
Batch 25/64 loss: -2.274139404296875
Batch 26/64 loss: -2.280449867248535
Batch 27/64 loss: -2.3527302742004395
Batch 28/64 loss: -2.4273252487182617
Batch 29/64 loss: -2.409900665283203
Batch 30/64 loss: -2.2902002334594727
Batch 31/64 loss: -2.2151927947998047
Batch 32/64 loss: -2.4999899864196777
Batch 33/64 loss: -2.4544191360473633
Batch 34/64 loss: -2.396106719970703
Batch 35/64 loss: -2.34814453125
Batch 36/64 loss: -2.19301700592041
Batch 37/64 loss: -2.124495506286621
Batch 38/64 loss: -2.244203567504883
Batch 39/64 loss: -2.588129997253418
Batch 40/64 loss: -2.3326549530029297
Batch 41/64 loss: -1.719243049621582
Batch 42/64 loss: -2.4537644386291504
Batch 43/64 loss: -2.19643497467041
Batch 44/64 loss: -2.1657676696777344
Batch 45/64 loss: -2.308499336242676
Batch 46/64 loss: -2.368332862854004
Batch 47/64 loss: -2.339902877807617
Batch 48/64 loss: -2.1803674697875977
Batch 49/64 loss: -2.3295493125915527
Batch 50/64 loss: -2.5607714653015137
Batch 51/64 loss: -2.45035457611084
Batch 52/64 loss: -2.3402156829833984
Batch 53/64 loss: -2.3388919830322266
Batch 54/64 loss: -2.3730268478393555
Batch 55/64 loss: -2.434767246246338
Batch 56/64 loss: -2.4051995277404785
Batch 57/64 loss: -2.320103645324707
Batch 58/64 loss: -1.5157194137573242
Batch 59/64 loss: -2.336123466491699
Batch 60/64 loss: -2.4005417823791504
Batch 61/64 loss: -2.5368905067443848
Batch 62/64 loss: -2.123445510864258
Batch 63/64 loss: -2.3857669830322266
Batch 64/64 loss: -6.3597731590271
Epoch 463  Train loss: -2.3184143982681573  Val loss: -2.663922247608093
Epoch 464
-------------------------------
Batch 1/64 loss: -1.9599123001098633
Batch 2/64 loss: -2.4042601585388184
Batch 3/64 loss: -2.2903642654418945
Batch 4/64 loss: -2.1710195541381836
Batch 5/64 loss: -2.312136173248291
Batch 6/64 loss: -2.219970703125
Batch 7/64 loss: -2.4964351654052734
Batch 8/64 loss: -2.4854683876037598
Batch 9/64 loss: -2.289616584777832
Batch 10/64 loss: -2.4646682739257812
Batch 11/64 loss: -2.461655616760254
Batch 12/64 loss: -2.157663345336914
Batch 13/64 loss: -2.3985185623168945
Batch 14/64 loss: -2.0068254470825195
Batch 15/64 loss: -2.3053483963012695
Batch 16/64 loss: -2.4496164321899414
Batch 17/64 loss: -1.9626531600952148
Batch 18/64 loss: -2.4153499603271484
Batch 19/64 loss: -2.347614288330078
Batch 20/64 loss: -2.512362003326416
Batch 21/64 loss: -2.480868339538574
Batch 22/64 loss: -2.480482578277588
Batch 23/64 loss: -2.282825469970703
Batch 24/64 loss: -2.497720718383789
Batch 25/64 loss: -2.1087493896484375
Batch 26/64 loss: -2.275784969329834
Batch 27/64 loss: -2.362921714782715
Batch 28/64 loss: -2.3713207244873047
Batch 29/64 loss: -2.2476043701171875
Batch 30/64 loss: -2.527773857116699
Batch 31/64 loss: -2.399508476257324
Batch 32/64 loss: -2.4635820388793945
Batch 33/64 loss: -1.8773365020751953
Batch 34/64 loss: -1.835134506225586
Batch 35/64 loss: -2.4201908111572266
Batch 36/64 loss: -2.2851390838623047
Batch 37/64 loss: -2.443807601928711
Batch 38/64 loss: -2.354062557220459
Batch 39/64 loss: -2.4743824005126953
Batch 40/64 loss: -2.4516968727111816
Batch 41/64 loss: -2.5217857360839844
Batch 42/64 loss: -2.3968052864074707
Batch 43/64 loss: -1.694931983947754
Batch 44/64 loss: -2.338212013244629
Batch 45/64 loss: -2.143413543701172
Batch 46/64 loss: -2.3522377014160156
Batch 47/64 loss: -2.3001108169555664
Batch 48/64 loss: -2.0751638412475586
Batch 49/64 loss: -2.347036361694336
Batch 50/64 loss: -2.203606605529785
Batch 51/64 loss: -2.444878578186035
Batch 52/64 loss: -2.429746627807617
Batch 53/64 loss: -2.6083245277404785
Batch 54/64 loss: -2.3145523071289062
Batch 55/64 loss: -2.5670056343078613
Batch 56/64 loss: -2.4324216842651367
Batch 57/64 loss: -2.4335737228393555
Batch 58/64 loss: -2.5284337997436523
Batch 59/64 loss: -2.442837715148926
Batch 60/64 loss: -2.477036476135254
Batch 61/64 loss: -1.7331409454345703
Batch 62/64 loss: -2.181887626647949
Batch 63/64 loss: -2.346853256225586
Batch 64/64 loss: -6.440916061401367
Epoch 464  Train loss: -2.3670123231177236  Val loss: -2.667048686968092
Epoch 465
-------------------------------
Batch 1/64 loss: -2.4744768142700195
Batch 2/64 loss: -2.417888641357422
Batch 3/64 loss: -2.241680145263672
Batch 4/64 loss: -2.4735469818115234
Batch 5/64 loss: -1.6569385528564453
Batch 6/64 loss: -2.3678793907165527
Batch 7/64 loss: -2.299981117248535
Batch 8/64 loss: -2.3244452476501465
Batch 9/64 loss: -2.414670467376709
Batch 10/64 loss: -2.586315631866455
Batch 11/64 loss: -2.0178136825561523
Batch 12/64 loss: -2.172098159790039
Batch 13/64 loss: -2.0803966522216797
Batch 14/64 loss: -2.3585848808288574
Batch 15/64 loss: -2.459074020385742
Batch 16/64 loss: -2.4702587127685547
Batch 17/64 loss: -2.25277042388916
Batch 18/64 loss: -2.019576072692871
Batch 19/64 loss: -2.3000240325927734
Batch 20/64 loss: -2.4295897483825684
Batch 21/64 loss: -1.8320703506469727
Batch 22/64 loss: -2.3225889205932617
Batch 23/64 loss: -2.21114444732666
Batch 24/64 loss: -2.2303695678710938
Batch 25/64 loss: -2.2745323181152344
Batch 26/64 loss: -2.365603446960449
Batch 27/64 loss: -2.5452308654785156
Batch 28/64 loss: -2.4493770599365234
Batch 29/64 loss: -2.291776657104492
Batch 30/64 loss: -2.433450698852539
Batch 31/64 loss: -2.239047050476074
Batch 32/64 loss: -2.478165626525879
Batch 33/64 loss: -2.3210926055908203
Batch 34/64 loss: -1.673476219177246
Batch 35/64 loss: -1.9724645614624023
Batch 36/64 loss: -2.4870028495788574
Batch 37/64 loss: -2.1027488708496094
Batch 38/64 loss: -2.171380043029785
Batch 39/64 loss: -2.305927276611328
Batch 40/64 loss: -2.1915512084960938
Batch 41/64 loss: -2.2545318603515625
Batch 42/64 loss: -1.6985750198364258
Batch 43/64 loss: -2.36484956741333
Batch 44/64 loss: -2.338470935821533
Batch 45/64 loss: -2.064009666442871
Batch 46/64 loss: -2.235330104827881
Batch 47/64 loss: -2.4103808403015137
Batch 48/64 loss: -2.3077754974365234
Batch 49/64 loss: -2.0651283264160156
Batch 50/64 loss: -2.3210806846618652
Batch 51/64 loss: -1.6434087753295898
Batch 52/64 loss: -2.159945487976074
Batch 53/64 loss: -2.2739200592041016
Batch 54/64 loss: -2.363740921020508
Batch 55/64 loss: -1.979238510131836
Batch 56/64 loss: -2.362761974334717
Batch 57/64 loss: -2.2736048698425293
Batch 58/64 loss: -2.167426109313965
Batch 59/64 loss: -2.2933759689331055
Batch 60/64 loss: -2.2862987518310547
Batch 61/64 loss: -1.940328598022461
Batch 62/64 loss: -2.2112789154052734
Batch 63/64 loss: -2.2500228881835938
Batch 64/64 loss: -6.272873878479004
Epoch 465  Train loss: -2.2852886237350165  Val loss: -2.4657858098085805
Epoch 466
-------------------------------
Batch 1/64 loss: -2.0454635620117188
Batch 2/64 loss: -2.4070992469787598
Batch 3/64 loss: -1.8708419799804688
Batch 4/64 loss: -2.32191801071167
Batch 5/64 loss: -2.287973403930664
Batch 6/64 loss: -2.4398856163024902
Batch 7/64 loss: -2.361996650695801
Batch 8/64 loss: -2.1000137329101562
Batch 9/64 loss: -1.9001445770263672
Batch 10/64 loss: -2.2042551040649414
Batch 11/64 loss: -2.2443714141845703
Batch 12/64 loss: -2.327665328979492
Batch 13/64 loss: -2.112330436706543
Batch 14/64 loss: -2.1455135345458984
Batch 15/64 loss: -2.1752262115478516
Batch 16/64 loss: -2.282766342163086
Batch 17/64 loss: -2.3997859954833984
Batch 18/64 loss: -2.2957205772399902
Batch 19/64 loss: -1.920196533203125
Batch 20/64 loss: -1.5066289901733398
Batch 21/64 loss: -1.9932470321655273
Batch 22/64 loss: -1.9418344497680664
Batch 23/64 loss: -2.040437698364258
Batch 24/64 loss: -2.330132484436035
Batch 25/64 loss: -2.1532983779907227
Batch 26/64 loss: -2.103485107421875
Batch 27/64 loss: -2.068140983581543
Batch 28/64 loss: -2.1904592514038086
Batch 29/64 loss: -2.1948013305664062
Batch 30/64 loss: -2.188680648803711
Batch 31/64 loss: -2.236489772796631
Batch 32/64 loss: -2.2977328300476074
Batch 33/64 loss: -2.0702428817749023
Batch 34/64 loss: -2.373063087463379
Batch 35/64 loss: -2.2005081176757812
Batch 36/64 loss: -2.3030762672424316
Batch 37/64 loss: -2.316194534301758
Batch 38/64 loss: -2.301323890686035
Batch 39/64 loss: -2.1040000915527344
Batch 40/64 loss: -1.714543342590332
Batch 41/64 loss: -2.3737354278564453
Batch 42/64 loss: -2.3290910720825195
Batch 43/64 loss: -2.351029396057129
Batch 44/64 loss: -2.135514259338379
Batch 45/64 loss: -2.2561774253845215
Batch 46/64 loss: -2.491065502166748
Batch 47/64 loss: -2.164682388305664
Batch 48/64 loss: -1.8126983642578125
Batch 49/64 loss: -2.3183422088623047
Batch 50/64 loss: -2.278128147125244
Batch 51/64 loss: -2.448129177093506
Batch 52/64 loss: -2.3150272369384766
Batch 53/64 loss: -2.42885160446167
Batch 54/64 loss: -2.4497108459472656
Batch 55/64 loss: -2.1003589630126953
Batch 56/64 loss: -1.5912103652954102
Batch 57/64 loss: -2.2814626693725586
Batch 58/64 loss: -2.40859317779541
Batch 59/64 loss: -2.3817853927612305
Batch 60/64 loss: -2.2237119674682617
Batch 61/64 loss: -2.248875617980957
Batch 62/64 loss: -2.2745914459228516
Batch 63/64 loss: -2.3129687309265137
Batch 64/64 loss: -6.5073699951171875
Epoch 466  Train loss: -2.2482785617603973  Val loss: -2.649477588352059
Epoch 467
-------------------------------
Batch 1/64 loss: -2.307096481323242
Batch 2/64 loss: -1.9738874435424805
Batch 3/64 loss: -2.0063772201538086
Batch 4/64 loss: -2.112447738647461
Batch 5/64 loss: -2.3679070472717285
Batch 6/64 loss: -2.142899513244629
Batch 7/64 loss: -2.209731101989746
Batch 8/64 loss: -2.4565677642822266
Batch 9/64 loss: -2.2160472869873047
Batch 10/64 loss: -1.666555404663086
Batch 11/64 loss: -2.3010196685791016
Batch 12/64 loss: -2.245242118835449
Batch 13/64 loss: -2.4558629989624023
Batch 14/64 loss: -1.775705337524414
Batch 15/64 loss: -2.170098304748535
Batch 16/64 loss: -2.4032039642333984
Batch 17/64 loss: -2.4117798805236816
Batch 18/64 loss: -2.209808349609375
Batch 19/64 loss: -2.129697799682617
Batch 20/64 loss: -2.249302864074707
Batch 21/64 loss: -2.336066722869873
Batch 22/64 loss: -1.893021583557129
Batch 23/64 loss: -1.9268684387207031
Batch 24/64 loss: -1.817647933959961
Batch 25/64 loss: -2.502349376678467
Batch 26/64 loss: -2.075015068054199
Batch 27/64 loss: -2.4652156829833984
Batch 28/64 loss: -2.420602798461914
Batch 29/64 loss: -2.5286049842834473
Batch 30/64 loss: -2.202268600463867
Batch 31/64 loss: -2.3447608947753906
Batch 32/64 loss: -2.3310699462890625
Batch 33/64 loss: -2.621066093444824
Batch 34/64 loss: -2.3884153366088867
Batch 35/64 loss: -2.4098405838012695
Batch 36/64 loss: -2.1538658142089844
Batch 37/64 loss: -2.359612464904785
Batch 38/64 loss: -2.1786880493164062
Batch 39/64 loss: -2.5611610412597656
Batch 40/64 loss: -2.419830799102783
Batch 41/64 loss: -2.383680820465088
Batch 42/64 loss: -2.558152198791504
Batch 43/64 loss: -1.962198257446289
Batch 44/64 loss: -1.741445541381836
Batch 45/64 loss: -2.314377784729004
Batch 46/64 loss: -2.502530097961426
Batch 47/64 loss: -1.9110174179077148
Batch 48/64 loss: -2.3474597930908203
Batch 49/64 loss: -2.5059103965759277
Batch 50/64 loss: -2.0938987731933594
Batch 51/64 loss: -2.198927879333496
Batch 52/64 loss: -1.1378469467163086
Batch 53/64 loss: -2.231302261352539
Batch 54/64 loss: -2.487849712371826
Batch 55/64 loss: -2.4114632606506348
Batch 56/64 loss: -2.3884029388427734
Batch 57/64 loss: -2.2623300552368164
Batch 58/64 loss: -2.5476250648498535
Batch 59/64 loss: -2.429325580596924
Batch 60/64 loss: -1.7475194931030273
Batch 61/64 loss: -2.5271482467651367
Batch 62/64 loss: -2.1434946060180664
Batch 63/64 loss: -2.2767791748046875
Batch 64/64 loss: -6.483109474182129
Epoch 467  Train loss: -2.285807512320724  Val loss: -2.644723400627215
Epoch 468
-------------------------------
Batch 1/64 loss: -2.498621940612793
Batch 2/64 loss: -2.4762964248657227
Batch 3/64 loss: -2.4960575103759766
Batch 4/64 loss: -2.09652042388916
Batch 5/64 loss: -1.8465909957885742
Batch 6/64 loss: -1.7642936706542969
Batch 7/64 loss: -2.3522791862487793
Batch 8/64 loss: -2.28444766998291
Batch 9/64 loss: -1.8478660583496094
Batch 10/64 loss: -2.399454116821289
Batch 11/64 loss: -2.304184913635254
Batch 12/64 loss: -2.4376330375671387
Batch 13/64 loss: -2.401123046875
Batch 14/64 loss: -2.4235167503356934
Batch 15/64 loss: -2.3493223190307617
Batch 16/64 loss: -2.4993510246276855
Batch 17/64 loss: -2.4991540908813477
Batch 18/64 loss: -2.2651968002319336
Batch 19/64 loss: -2.37260103225708
Batch 20/64 loss: -2.43227481842041
Batch 21/64 loss: -2.4753732681274414
Batch 22/64 loss: -2.4195518493652344
Batch 23/64 loss: -2.612844467163086
Batch 24/64 loss: -2.2645225524902344
Batch 25/64 loss: -2.3058624267578125
Batch 26/64 loss: -2.5027642250061035
Batch 27/64 loss: -2.291447639465332
Batch 28/64 loss: -2.301201820373535
Batch 29/64 loss: -2.2066707611083984
Batch 30/64 loss: -2.1989450454711914
Batch 31/64 loss: -2.303342819213867
Batch 32/64 loss: -2.052365303039551
Batch 33/64 loss: -2.199814796447754
Batch 34/64 loss: -2.411264419555664
Batch 35/64 loss: -2.2115936279296875
Batch 36/64 loss: -2.196493148803711
Batch 37/64 loss: -2.052227020263672
Batch 38/64 loss: -2.428542137145996
Batch 39/64 loss: -2.31404972076416
Batch 40/64 loss: -1.681304931640625
Batch 41/64 loss: -2.3606739044189453
Batch 42/64 loss: -2.3629016876220703
Batch 43/64 loss: -2.0932512283325195
Batch 44/64 loss: -2.2125091552734375
Batch 45/64 loss: -2.0890884399414062
Batch 46/64 loss: -2.2164602279663086
Batch 47/64 loss: -2.3537940979003906
Batch 48/64 loss: -1.9713783264160156
Batch 49/64 loss: -1.713888168334961
Batch 50/64 loss: -2.2592105865478516
Batch 51/64 loss: -2.4013705253601074
Batch 52/64 loss: -2.306698799133301
Batch 53/64 loss: -2.478635787963867
Batch 54/64 loss: -2.478048324584961
Batch 55/64 loss: -2.30063533782959
Batch 56/64 loss: -1.9844169616699219
Batch 57/64 loss: -2.397639274597168
Batch 58/64 loss: -2.2246646881103516
Batch 59/64 loss: -2.2795724868774414
Batch 60/64 loss: -1.9760684967041016
Batch 61/64 loss: -2.413285732269287
Batch 62/64 loss: -2.6344966888427734
Batch 63/64 loss: -1.9996976852416992
Batch 64/64 loss: -6.475949287414551
Epoch 468  Train loss: -2.3190951590444526  Val loss: -2.6226239548516026
Epoch 469
-------------------------------
Batch 1/64 loss: -2.3713197708129883
Batch 2/64 loss: -2.319477081298828
Batch 3/64 loss: -2.409388542175293
Batch 4/64 loss: -2.3077707290649414
Batch 5/64 loss: -2.3941173553466797
Batch 6/64 loss: -2.1341552734375
Batch 7/64 loss: -1.9955511093139648
Batch 8/64 loss: -2.19952392578125
Batch 9/64 loss: -2.0315752029418945
Batch 10/64 loss: -2.274796485900879
Batch 11/64 loss: -2.4419631958007812
Batch 12/64 loss: -2.252650260925293
Batch 13/64 loss: -2.454861640930176
Batch 14/64 loss: -2.271285057067871
Batch 15/64 loss: -2.5788769721984863
Batch 16/64 loss: -1.4736738204956055
Batch 17/64 loss: -2.158519744873047
Batch 18/64 loss: -2.395430564880371
Batch 19/64 loss: -2.460610866546631
Batch 20/64 loss: -2.048211097717285
Batch 21/64 loss: -2.336500644683838
Batch 22/64 loss: -2.646106719970703
Batch 23/64 loss: -2.347416877746582
Batch 24/64 loss: -2.361753463745117
Batch 25/64 loss: -2.385087490081787
Batch 26/64 loss: -2.474519729614258
Batch 27/64 loss: -2.373159408569336
Batch 28/64 loss: -2.3005075454711914
Batch 29/64 loss: -2.270975112915039
Batch 30/64 loss: -2.46490478515625
Batch 31/64 loss: -2.491710662841797
Batch 32/64 loss: -2.36679744720459
Batch 33/64 loss: -2.4486117362976074
Batch 34/64 loss: -2.38248348236084
Batch 35/64 loss: -2.4535388946533203
Batch 36/64 loss: -2.070505142211914
Batch 37/64 loss: -2.2804346084594727
Batch 38/64 loss: -2.0598363876342773
Batch 39/64 loss: -2.493347644805908
Batch 40/64 loss: -2.1453723907470703
Batch 41/64 loss: -2.2104005813598633
Batch 42/64 loss: -2.4394588470458984
Batch 43/64 loss: -2.1733264923095703
Batch 44/64 loss: -2.5124950408935547
Batch 45/64 loss: -1.9823293685913086
Batch 46/64 loss: -2.2415847778320312
Batch 47/64 loss: -2.1241464614868164
Batch 48/64 loss: -2.1577720642089844
Batch 49/64 loss: -2.1867189407348633
Batch 50/64 loss: -2.000412940979004
Batch 51/64 loss: -2.128358840942383
Batch 52/64 loss: -2.3723649978637695
Batch 53/64 loss: -1.563685417175293
Batch 54/64 loss: -2.3946900367736816
Batch 55/64 loss: -2.331233501434326
Batch 56/64 loss: -2.305424690246582
Batch 57/64 loss: -2.2363271713256836
Batch 58/64 loss: -2.4420313835144043
Batch 59/64 loss: -2.354321002960205
Batch 60/64 loss: -2.3593649864196777
Batch 61/64 loss: -1.6460304260253906
Batch 62/64 loss: -1.5987958908081055
Batch 63/64 loss: -2.396862506866455
Batch 64/64 loss: -6.496999740600586
Epoch 469  Train loss: -2.3083641575831995  Val loss: -2.5977059721537064
Epoch 470
-------------------------------
Batch 1/64 loss: -2.430305004119873
Batch 2/64 loss: -2.382883071899414
Batch 3/64 loss: -2.361626625061035
Batch 4/64 loss: -2.4692277908325195
Batch 5/64 loss: -1.7033500671386719
Batch 6/64 loss: -2.415787696838379
Batch 7/64 loss: -2.3471498489379883
Batch 8/64 loss: -2.353057861328125
Batch 9/64 loss: -1.6882638931274414
Batch 10/64 loss: -2.131119728088379
Batch 11/64 loss: -1.9917888641357422
Batch 12/64 loss: -2.043349266052246
Batch 13/64 loss: -2.340453624725342
Batch 14/64 loss: -2.238798141479492
Batch 15/64 loss: -2.0938920974731445
Batch 16/64 loss: -2.0784244537353516
Batch 17/64 loss: -2.3700551986694336
Batch 18/64 loss: -2.2639904022216797
Batch 19/64 loss: -2.3438873291015625
Batch 20/64 loss: -2.1984987258911133
Batch 21/64 loss: -2.5233020782470703
Batch 22/64 loss: -2.1233224868774414
Batch 23/64 loss: -2.3114089965820312
Batch 24/64 loss: -2.3363022804260254
Batch 25/64 loss: -2.018014907836914
Batch 26/64 loss: -2.4087295532226562
Batch 27/64 loss: -2.4032626152038574
Batch 28/64 loss: -2.4619407653808594
Batch 29/64 loss: -2.308497428894043
Batch 30/64 loss: -2.413120746612549
Batch 31/64 loss: -2.458047866821289
Batch 32/64 loss: -2.46413516998291
Batch 33/64 loss: -2.4412078857421875
Batch 34/64 loss: -2.4214282035827637
Batch 35/64 loss: -2.2553491592407227
Batch 36/64 loss: -2.3537116050720215
Batch 37/64 loss: -2.073953628540039
Batch 38/64 loss: -1.7057247161865234
Batch 39/64 loss: -2.350383758544922
Batch 40/64 loss: -2.161985397338867
Batch 41/64 loss: -2.294126510620117
Batch 42/64 loss: -1.8575448989868164
Batch 43/64 loss: -2.2486915588378906
Batch 44/64 loss: -2.0743932723999023
Batch 45/64 loss: -2.06595516204834
Batch 46/64 loss: -2.2528562545776367
Batch 47/64 loss: -2.406850814819336
Batch 48/64 loss: -2.3634605407714844
Batch 49/64 loss: -2.213498115539551
Batch 50/64 loss: -2.1987552642822266
Batch 51/64 loss: -2.253387451171875
Batch 52/64 loss: -2.502593994140625
Batch 53/64 loss: -2.4140357971191406
Batch 54/64 loss: -2.3466386795043945
Batch 55/64 loss: -2.530428886413574
Batch 56/64 loss: -2.5229740142822266
Batch 57/64 loss: -2.39327335357666
Batch 58/64 loss: -2.152830123901367
Batch 59/64 loss: -2.4844188690185547
Batch 60/64 loss: -2.355104446411133
Batch 61/64 loss: -2.3053627014160156
Batch 62/64 loss: -2.3081045150756836
Batch 63/64 loss: -2.4332752227783203
Batch 64/64 loss: -6.80131721496582
Epoch 470  Train loss: -2.3265770556879977  Val loss: -2.6436949530008325
Epoch 471
-------------------------------
Batch 1/64 loss: -2.2925453186035156
Batch 2/64 loss: -2.2898941040039062
Batch 3/64 loss: -2.210038185119629
Batch 4/64 loss: -2.54129695892334
Batch 5/64 loss: -2.4619340896606445
Batch 6/64 loss: -2.5555171966552734
Batch 7/64 loss: -2.402944564819336
Batch 8/64 loss: -2.2802953720092773
Batch 9/64 loss: -2.414236545562744
Batch 10/64 loss: -2.0970582962036133
Batch 11/64 loss: -2.300006866455078
Batch 12/64 loss: -2.3752923011779785
Batch 13/64 loss: -2.426567554473877
Batch 14/64 loss: -2.1415977478027344
Batch 15/64 loss: -2.4155683517456055
Batch 16/64 loss: -2.1162681579589844
Batch 17/64 loss: -2.0753135681152344
Batch 18/64 loss: -2.2264881134033203
Batch 19/64 loss: -2.2963171005249023
Batch 20/64 loss: -2.447573661804199
Batch 21/64 loss: -2.2461376190185547
Batch 22/64 loss: -2.151914596557617
Batch 23/64 loss: -2.2389116287231445
Batch 24/64 loss: -1.9587736129760742
Batch 25/64 loss: -2.4892945289611816
Batch 26/64 loss: -2.1401138305664062
Batch 27/64 loss: -2.3056259155273438
Batch 28/64 loss: -2.262319564819336
Batch 29/64 loss: -2.415426731109619
Batch 30/64 loss: -2.443406581878662
Batch 31/64 loss: -2.244922637939453
Batch 32/64 loss: -2.2308483123779297
Batch 33/64 loss: -2.285202980041504
Batch 34/64 loss: -2.386829376220703
Batch 35/64 loss: -1.8465909957885742
Batch 36/64 loss: -2.114961624145508
Batch 37/64 loss: -2.3387413024902344
Batch 38/64 loss: -2.074991226196289
Batch 39/64 loss: -2.2005434036254883
Batch 40/64 loss: -1.8601655960083008
Batch 41/64 loss: -1.9667539596557617
Batch 42/64 loss: -2.445988655090332
Batch 43/64 loss: -2.048497200012207
Batch 44/64 loss: -2.3738298416137695
Batch 45/64 loss: -2.3453378677368164
Batch 46/64 loss: -2.0122947692871094
Batch 47/64 loss: -2.4405641555786133
Batch 48/64 loss: -2.3930654525756836
Batch 49/64 loss: -2.401449680328369
Batch 50/64 loss: -2.184795379638672
Batch 51/64 loss: -2.3798880577087402
Batch 52/64 loss: -2.3889989852905273
Batch 53/64 loss: -1.8481407165527344
Batch 54/64 loss: -2.2838945388793945
Batch 55/64 loss: -2.135676383972168
Batch 56/64 loss: -2.316455364227295
Batch 57/64 loss: -2.238539695739746
Batch 58/64 loss: -2.4869909286499023
Batch 59/64 loss: -1.7753190994262695
Batch 60/64 loss: -1.9114294052124023
Batch 61/64 loss: -2.2723865509033203
Batch 62/64 loss: -1.5974416732788086
Batch 63/64 loss: -2.336613655090332
Batch 64/64 loss: -6.471668243408203
Epoch 471  Train loss: -2.2908326167686313  Val loss: -2.432911456655391
Epoch 472
-------------------------------
Batch 1/64 loss: -2.187596321105957
Batch 2/64 loss: -2.306515693664551
Batch 3/64 loss: -2.0167999267578125
Batch 4/64 loss: -2.281468391418457
Batch 5/64 loss: -2.088132858276367
Batch 6/64 loss: -2.0251855850219727
Batch 7/64 loss: -1.8256416320800781
Batch 8/64 loss: -2.236546516418457
Batch 9/64 loss: -2.260242462158203
Batch 10/64 loss: -2.0404815673828125
Batch 11/64 loss: -2.1009979248046875
Batch 12/64 loss: -1.4476995468139648
Batch 13/64 loss: -2.1631460189819336
Batch 14/64 loss: -2.5197978019714355
Batch 15/64 loss: -2.428351402282715
Batch 16/64 loss: -2.3415584564208984
Batch 17/64 loss: -2.146566390991211
Batch 18/64 loss: -2.467283248901367
Batch 19/64 loss: -2.2772269248962402
Batch 20/64 loss: -2.1225805282592773
Batch 21/64 loss: -2.418886184692383
Batch 22/64 loss: -2.2682294845581055
Batch 23/64 loss: -2.418459892272949
Batch 24/64 loss: -1.8984813690185547
Batch 25/64 loss: -2.040170669555664
Batch 26/64 loss: -2.2334632873535156
Batch 27/64 loss: -2.376713752746582
Batch 28/64 loss: -2.3413949012756348
Batch 29/64 loss: -2.4840054512023926
Batch 30/64 loss: -1.675248146057129
Batch 31/64 loss: -2.4738101959228516
Batch 32/64 loss: -2.5237693786621094
Batch 33/64 loss: -2.2729835510253906
Batch 34/64 loss: -2.3211355209350586
Batch 35/64 loss: -1.9319171905517578
Batch 36/64 loss: -2.1728029251098633
Batch 37/64 loss: -2.1604604721069336
Batch 38/64 loss: -2.5665740966796875
Batch 39/64 loss: -2.339569091796875
Batch 40/64 loss: -2.3413925170898438
Batch 41/64 loss: -2.3652243614196777
Batch 42/64 loss: -2.4130382537841797
Batch 43/64 loss: -2.414158344268799
Batch 44/64 loss: -2.1747560501098633
Batch 45/64 loss: -2.374990463256836
Batch 46/64 loss: -2.399845600128174
Batch 47/64 loss: -2.0819311141967773
Batch 48/64 loss: -2.519320487976074
Batch 49/64 loss: -2.4603052139282227
Batch 50/64 loss: -2.4330530166625977
Batch 51/64 loss: -2.529428005218506
Batch 52/64 loss: -2.5051093101501465
Batch 53/64 loss: -2.426325798034668
Batch 54/64 loss: -2.4252614974975586
Batch 55/64 loss: -2.3198280334472656
Batch 56/64 loss: -2.460057258605957
Batch 57/64 loss: -2.5589652061462402
Batch 58/64 loss: -2.546736717224121
Batch 59/64 loss: -2.3533411026000977
Batch 60/64 loss: -2.4641146659851074
Batch 61/64 loss: -2.536341667175293
Batch 62/64 loss: -2.666781425476074
Batch 63/64 loss: -2.286226272583008
Batch 64/64 loss: -6.4457292556762695
Epoch 472  Train loss: -2.3387093974094766  Val loss: -2.7346362608814565
Epoch 473
-------------------------------
Batch 1/64 loss: -2.11922550201416
Batch 2/64 loss: -2.338078022003174
Batch 3/64 loss: -2.4819436073303223
Batch 4/64 loss: -2.124392509460449
Batch 5/64 loss: -2.075089454650879
Batch 6/64 loss: -1.8330049514770508
Batch 7/64 loss: -2.2911415100097656
Batch 8/64 loss: -2.2008323669433594
Batch 9/64 loss: -2.3972039222717285
Batch 10/64 loss: -2.489778518676758
Batch 11/64 loss: -2.3696956634521484
Batch 12/64 loss: -2.4040327072143555
Batch 13/64 loss: -2.1591615676879883
Batch 14/64 loss: -2.241419792175293
Batch 15/64 loss: -2.4532904624938965
Batch 16/64 loss: -2.2492237091064453
Batch 17/64 loss: -2.3401174545288086
Batch 18/64 loss: -2.5984692573547363
Batch 19/64 loss: -2.295262336730957
Batch 20/64 loss: -2.4421181678771973
Batch 21/64 loss: -2.460031509399414
Batch 22/64 loss: -2.472484588623047
Batch 23/64 loss: -1.8135128021240234
Batch 24/64 loss: -2.4557456970214844
Batch 25/64 loss: -2.282528877258301
Batch 26/64 loss: -2.482119560241699
Batch 27/64 loss: -2.162400245666504
Batch 28/64 loss: -2.3978500366210938
Batch 29/64 loss: -2.0964698791503906
Batch 30/64 loss: -2.2056007385253906
Batch 31/64 loss: -2.243903160095215
Batch 32/64 loss: -2.2010440826416016
Batch 33/64 loss: -2.4727301597595215
Batch 34/64 loss: -2.3880038261413574
Batch 35/64 loss: -2.2906723022460938
Batch 36/64 loss: -2.377812385559082
Batch 37/64 loss: -2.3766088485717773
Batch 38/64 loss: -2.2991819381713867
Batch 39/64 loss: -2.218168258666992
Batch 40/64 loss: -2.316974639892578
Batch 41/64 loss: -2.206366539001465
Batch 42/64 loss: -2.4361696243286133
Batch 43/64 loss: -2.4605789184570312
Batch 44/64 loss: -2.3955917358398438
Batch 45/64 loss: -2.317354202270508
Batch 46/64 loss: -2.320901870727539
Batch 47/64 loss: -2.406893730163574
Batch 48/64 loss: -2.4125099182128906
Batch 49/64 loss: -2.488081932067871
Batch 50/64 loss: -2.337998390197754
Batch 51/64 loss: -2.2742996215820312
Batch 52/64 loss: -2.3709030151367188
Batch 53/64 loss: -2.213017463684082
Batch 54/64 loss: -2.373239040374756
Batch 55/64 loss: -2.558224678039551
Batch 56/64 loss: -1.8859586715698242
Batch 57/64 loss: -2.237645149230957
Batch 58/64 loss: -2.27944278717041
Batch 59/64 loss: -2.409379005432129
Batch 60/64 loss: -2.358147621154785
Batch 61/64 loss: -2.4402599334716797
Batch 62/64 loss: -2.345797538757324
Batch 63/64 loss: -2.491154193878174
Batch 64/64 loss: -6.57855749130249
Epoch 473  Train loss: -2.3666064112794167  Val loss: -2.68574681232885
Epoch 474
-------------------------------
Batch 1/64 loss: -2.2222070693969727
Batch 2/64 loss: -2.509760856628418
Batch 3/64 loss: -2.2512807846069336
Batch 4/64 loss: -2.4023609161376953
Batch 5/64 loss: -2.3854236602783203
Batch 6/64 loss: -2.3315839767456055
Batch 7/64 loss: -2.169875144958496
Batch 8/64 loss: -1.421727180480957
Batch 9/64 loss: -2.280801773071289
Batch 10/64 loss: -2.2374496459960938
Batch 11/64 loss: -2.502699375152588
Batch 12/64 loss: -2.243563652038574
Batch 13/64 loss: -2.201038360595703
Batch 14/64 loss: -2.437397003173828
Batch 15/64 loss: -2.41641902923584
Batch 16/64 loss: -2.24338436126709
Batch 17/64 loss: -2.35258150100708
Batch 18/64 loss: -2.474869728088379
Batch 19/64 loss: -2.315858840942383
Batch 20/64 loss: -2.3587021827697754
Batch 21/64 loss: -2.283823013305664
Batch 22/64 loss: -2.29296875
Batch 23/64 loss: -2.426163673400879
Batch 24/64 loss: -2.3527135848999023
Batch 25/64 loss: -2.4353837966918945
Batch 26/64 loss: -2.358987808227539
Batch 27/64 loss: -2.450448513031006
Batch 28/64 loss: -2.37992000579834
Batch 29/64 loss: -2.228449821472168
Batch 30/64 loss: -2.2548952102661133
Batch 31/64 loss: -2.451244831085205
Batch 32/64 loss: -2.3263511657714844
Batch 33/64 loss: -2.1479110717773438
Batch 34/64 loss: -2.322021961212158
Batch 35/64 loss: -2.359528064727783
Batch 36/64 loss: -2.357452392578125
Batch 37/64 loss: -1.3648462295532227
Batch 38/64 loss: -2.230402946472168
Batch 39/64 loss: -2.149491310119629
Batch 40/64 loss: -2.4072060585021973
Batch 41/64 loss: -2.4828925132751465
Batch 42/64 loss: -2.4574131965637207
Batch 43/64 loss: -2.3360471725463867
Batch 44/64 loss: -2.4346446990966797
Batch 45/64 loss: -2.280193328857422
Batch 46/64 loss: -2.462294578552246
Batch 47/64 loss: -2.3115758895874023
Batch 48/64 loss: -2.183793067932129
Batch 49/64 loss: -2.223369598388672
Batch 50/64 loss: -2.2269067764282227
Batch 51/64 loss: -1.8676633834838867
Batch 52/64 loss: -2.2250900268554688
Batch 53/64 loss: -2.465791702270508
Batch 54/64 loss: -2.3178634643554688
Batch 55/64 loss: -2.29030704498291
Batch 56/64 loss: -2.2751779556274414
Batch 57/64 loss: -1.6697769165039062
Batch 58/64 loss: -2.2210474014282227
Batch 59/64 loss: -2.1230459213256836
Batch 60/64 loss: -2.3016910552978516
Batch 61/64 loss: -2.10565185546875
Batch 62/64 loss: -2.160916328430176
Batch 63/64 loss: -2.3177623748779297
Batch 64/64 loss: -6.4048309326171875
Epoch 474  Train loss: -2.3197448580872777  Val loss: -2.6548556429413996
Epoch 475
-------------------------------
Batch 1/64 loss: -2.4696035385131836
Batch 2/64 loss: -1.814326286315918
Batch 3/64 loss: -2.254887580871582
Batch 4/64 loss: -2.091787338256836
Batch 5/64 loss: -2.3061084747314453
Batch 6/64 loss: -2.5457630157470703
Batch 7/64 loss: -2.2730302810668945
Batch 8/64 loss: -2.338139533996582
Batch 9/64 loss: -2.2239742279052734
Batch 10/64 loss: -2.3643369674682617
Batch 11/64 loss: -2.3203468322753906
Batch 12/64 loss: -2.3828563690185547
Batch 13/64 loss: -2.2558975219726562
Batch 14/64 loss: -2.390458106994629
Batch 15/64 loss: -2.296701431274414
Batch 16/64 loss: -2.386845111846924
Batch 17/64 loss: -2.2197494506835938
Batch 18/64 loss: -2.2674808502197266
Batch 19/64 loss: -2.2872562408447266
Batch 20/64 loss: -2.4565649032592773
Batch 21/64 loss: -2.320754051208496
Batch 22/64 loss: -2.459855079650879
Batch 23/64 loss: -2.1996021270751953
Batch 24/64 loss: -2.34151029586792
Batch 25/64 loss: -2.34158992767334
Batch 26/64 loss: -2.4576497077941895
Batch 27/64 loss: -2.4370861053466797
Batch 28/64 loss: -2.4374217987060547
Batch 29/64 loss: -2.234316825866699
Batch 30/64 loss: -1.956690788269043
Batch 31/64 loss: -2.441296100616455
Batch 32/64 loss: -2.5115041732788086
Batch 33/64 loss: -1.5194578170776367
Batch 34/64 loss: -2.4810757637023926
Batch 35/64 loss: -2.472095489501953
Batch 36/64 loss: -1.8522825241088867
Batch 37/64 loss: -2.5129809379577637
Batch 38/64 loss: -1.6247997283935547
Batch 39/64 loss: -1.928553581237793
Batch 40/64 loss: -2.345982551574707
Batch 41/64 loss: -2.5473766326904297
Batch 42/64 loss: -2.3227453231811523
Batch 43/64 loss: -2.471311569213867
Batch 44/64 loss: -2.5085320472717285
Batch 45/64 loss: -2.5692291259765625
Batch 46/64 loss: -2.2815637588500977
Batch 47/64 loss: -2.089550018310547
Batch 48/64 loss: -2.324467658996582
Batch 49/64 loss: -2.3120975494384766
Batch 50/64 loss: -2.324862480163574
Batch 51/64 loss: -2.427949905395508
Batch 52/64 loss: -2.419821262359619
Batch 53/64 loss: -2.3519458770751953
Batch 54/64 loss: -2.455963134765625
Batch 55/64 loss: -2.3086671829223633
Batch 56/64 loss: -2.136786460876465
Batch 57/64 loss: -2.439932346343994
Batch 58/64 loss: -2.3613595962524414
Batch 59/64 loss: -2.504916191101074
Batch 60/64 loss: -2.445235252380371
Batch 61/64 loss: -2.105926513671875
Batch 62/64 loss: -2.348642349243164
Batch 63/64 loss: -2.491260051727295
Batch 64/64 loss: -6.293460845947266
Epoch 475  Train loss: -2.3543977625229777  Val loss: -2.6625299093239905
Epoch 476
-------------------------------
Batch 1/64 loss: -2.5003089904785156
Batch 2/64 loss: -2.5715112686157227
Batch 3/64 loss: -2.620375633239746
Batch 4/64 loss: -2.0499534606933594
Batch 5/64 loss: -1.8101119995117188
Batch 6/64 loss: -2.4603214263916016
Batch 7/64 loss: -2.2527570724487305
Batch 8/64 loss: -2.564716339111328
Batch 9/64 loss: -2.1024818420410156
Batch 10/64 loss: -2.4019789695739746
Batch 11/64 loss: -2.4210004806518555
Batch 12/64 loss: -2.4265594482421875
Batch 13/64 loss: -2.387073516845703
Batch 14/64 loss: -2.361440658569336
Batch 15/64 loss: -2.2598190307617188
Batch 16/64 loss: -2.3752365112304688
Batch 17/64 loss: -1.9293842315673828
Batch 18/64 loss: -2.3045034408569336
Batch 19/64 loss: -2.231731414794922
Batch 20/64 loss: -2.082608222961426
Batch 21/64 loss: -2.2029056549072266
Batch 22/64 loss: -2.328803062438965
Batch 23/64 loss: -1.4208736419677734
Batch 24/64 loss: -2.4220972061157227
Batch 25/64 loss: -2.181290626525879
Batch 26/64 loss: -2.3898024559020996
Batch 27/64 loss: -2.4493770599365234
Batch 28/64 loss: -2.2679443359375
Batch 29/64 loss: -2.5691871643066406
Batch 30/64 loss: -2.400355339050293
Batch 31/64 loss: -2.317704677581787
Batch 32/64 loss: -2.4392333030700684
Batch 33/64 loss: -2.180757522583008
Batch 34/64 loss: -2.2545976638793945
Batch 35/64 loss: -2.0288686752319336
Batch 36/64 loss: -2.4373106956481934
Batch 37/64 loss: -2.4065208435058594
Batch 38/64 loss: -2.402785301208496
Batch 39/64 loss: -2.51485538482666
Batch 40/64 loss: -2.220348358154297
Batch 41/64 loss: -2.4570884704589844
Batch 42/64 loss: -2.389601230621338
Batch 43/64 loss: -1.8775453567504883
Batch 44/64 loss: -2.2641592025756836
Batch 45/64 loss: -2.3781442642211914
Batch 46/64 loss: -2.2521677017211914
Batch 47/64 loss: -2.458643913269043
Batch 48/64 loss: -2.1609458923339844
Batch 49/64 loss: -1.754861831665039
Batch 50/64 loss: -2.374101161956787
Batch 51/64 loss: -2.408477306365967
Batch 52/64 loss: -2.44978666305542
Batch 53/64 loss: -2.491269111633301
Batch 54/64 loss: -2.491274833679199
Batch 55/64 loss: -2.47314453125
Batch 56/64 loss: -2.0417728424072266
Batch 57/64 loss: -2.022568702697754
Batch 58/64 loss: -2.232076644897461
Batch 59/64 loss: -2.3053388595581055
Batch 60/64 loss: -2.2740001678466797
Batch 61/64 loss: -2.3877015113830566
Batch 62/64 loss: -1.9333257675170898
Batch 63/64 loss: -2.4363245964050293
Batch 64/64 loss: -6.645290374755859
Epoch 476  Train loss: -2.341141667085535  Val loss: -2.6905101369746363
Epoch 477
-------------------------------
Batch 1/64 loss: -2.458425521850586
Batch 2/64 loss: -2.4195942878723145
Batch 3/64 loss: -2.4862890243530273
Batch 4/64 loss: -2.1320724487304688
Batch 5/64 loss: -2.388490676879883
Batch 6/64 loss: -2.09702205657959
Batch 7/64 loss: -2.3287606239318848
Batch 8/64 loss: -2.5038766860961914
Batch 9/64 loss: -2.1031875610351562
Batch 10/64 loss: -2.0656204223632812
Batch 11/64 loss: -1.6277656555175781
Batch 12/64 loss: -2.3702831268310547
Batch 13/64 loss: -2.35791015625
Batch 14/64 loss: -2.320262908935547
Batch 15/64 loss: -1.9375696182250977
Batch 16/64 loss: -2.3451128005981445
Batch 17/64 loss: -2.286025047302246
Batch 18/64 loss: -2.3570427894592285
Batch 19/64 loss: -1.8763294219970703
Batch 20/64 loss: -2.32798433303833
Batch 21/64 loss: -2.450995445251465
Batch 22/64 loss: -2.2982358932495117
Batch 23/64 loss: -2.214658737182617
Batch 24/64 loss: -2.486311435699463
Batch 25/64 loss: -2.116302490234375
Batch 26/64 loss: -2.311939239501953
Batch 27/64 loss: -2.1098861694335938
Batch 28/64 loss: -2.306857109069824
Batch 29/64 loss: -2.254837989807129
Batch 30/64 loss: -1.9205522537231445
Batch 31/64 loss: -2.193905830383301
Batch 32/64 loss: -2.2288084030151367
Batch 33/64 loss: -2.190382957458496
Batch 34/64 loss: -2.331770896911621
Batch 35/64 loss: -2.198333740234375
Batch 36/64 loss: -2.456075668334961
Batch 37/64 loss: -2.231776237487793
Batch 38/64 loss: -1.6865291595458984
Batch 39/64 loss: -2.311267375946045
Batch 40/64 loss: -2.3883633613586426
Batch 41/64 loss: -2.4705543518066406
Batch 42/64 loss: -2.3879780769348145
Batch 43/64 loss: -2.1959543228149414
Batch 44/64 loss: -2.3884639739990234
Batch 45/64 loss: -2.1206274032592773
Batch 46/64 loss: -2.3689146041870117
Batch 47/64 loss: -2.176161766052246
Batch 48/64 loss: -2.387968063354492
Batch 49/64 loss: -2.3265886306762695
Batch 50/64 loss: -2.4860076904296875
Batch 51/64 loss: -2.257906913757324
Batch 52/64 loss: -2.1777963638305664
Batch 53/64 loss: -2.421447277069092
Batch 54/64 loss: -2.270819664001465
Batch 55/64 loss: -2.147810935974121
Batch 56/64 loss: -2.4032864570617676
Batch 57/64 loss: -2.4527883529663086
Batch 58/64 loss: -2.101072311401367
Batch 59/64 loss: -2.3989548683166504
Batch 60/64 loss: -2.289320945739746
Batch 61/64 loss: -1.869720458984375
Batch 62/64 loss: -2.317321300506592
Batch 63/64 loss: -2.279181480407715
Batch 64/64 loss: -6.445377349853516
Epoch 477  Train loss: -2.306009330001532  Val loss: -2.5865816725898036
Epoch 478
-------------------------------
Batch 1/64 loss: -2.3351449966430664
Batch 2/64 loss: -2.2257518768310547
Batch 3/64 loss: -2.0242319107055664
Batch 4/64 loss: -2.303861618041992
Batch 5/64 loss: -2.160594940185547
Batch 6/64 loss: -2.224381446838379
Batch 7/64 loss: -1.5918807983398438
Batch 8/64 loss: -2.0447921752929688
Batch 9/64 loss: -2.143260955810547
Batch 10/64 loss: -2.263439178466797
Batch 11/64 loss: -2.319993495941162
Batch 12/64 loss: -2.431088447570801
Batch 13/64 loss: -2.19283390045166
Batch 14/64 loss: -1.9443635940551758
Batch 15/64 loss: -2.3601841926574707
Batch 16/64 loss: -2.30364990234375
Batch 17/64 loss: -2.531339645385742
Batch 18/64 loss: -2.219815254211426
Batch 19/64 loss: -2.3212080001831055
Batch 20/64 loss: -2.382138252258301
Batch 21/64 loss: -1.7270984649658203
Batch 22/64 loss: -2.353304862976074
Batch 23/64 loss: -1.6792869567871094
Batch 24/64 loss: -2.4027457237243652
Batch 25/64 loss: -2.4223389625549316
Batch 26/64 loss: -2.267573356628418
Batch 27/64 loss: -2.263321876525879
Batch 28/64 loss: -2.3105063438415527
Batch 29/64 loss: -2.3159399032592773
Batch 30/64 loss: -2.3810882568359375
Batch 31/64 loss: -2.3132848739624023
Batch 32/64 loss: -2.439352035522461
Batch 33/64 loss: -2.447017192840576
Batch 34/64 loss: -2.4825992584228516
Batch 35/64 loss: -2.200615882873535
Batch 36/64 loss: -2.2039718627929688
Batch 37/64 loss: -2.2113380432128906
Batch 38/64 loss: -2.4859533309936523
Batch 39/64 loss: -2.265864372253418
Batch 40/64 loss: -2.3045454025268555
Batch 41/64 loss: -2.4558238983154297
Batch 42/64 loss: -2.4774880409240723
Batch 43/64 loss: -2.0951061248779297
Batch 44/64 loss: -2.070828437805176
Batch 45/64 loss: -2.2275781631469727
Batch 46/64 loss: -2.4217066764831543
Batch 47/64 loss: -2.349055290222168
Batch 48/64 loss: -2.5306692123413086
Batch 49/64 loss: -2.1470460891723633
Batch 50/64 loss: -2.3687076568603516
Batch 51/64 loss: -2.458733081817627
Batch 52/64 loss: -2.2685680389404297
Batch 53/64 loss: -2.379652976989746
Batch 54/64 loss: -2.0078210830688477
Batch 55/64 loss: -2.1749982833862305
Batch 56/64 loss: -2.271305561065674
Batch 57/64 loss: -2.3903884887695312
Batch 58/64 loss: -2.392042636871338
Batch 59/64 loss: -2.4547252655029297
Batch 60/64 loss: -2.2679853439331055
Batch 61/64 loss: -2.3608012199401855
Batch 62/64 loss: -2.5406389236450195
Batch 63/64 loss: -2.3405823707580566
Batch 64/64 loss: -6.283186435699463
Epoch 478  Train loss: -2.321040693918864  Val loss: -2.6650525909109213
Epoch 479
-------------------------------
Batch 1/64 loss: -2.1564884185791016
Batch 2/64 loss: -2.3130807876586914
Batch 3/64 loss: -2.2768306732177734
Batch 4/64 loss: -2.481236457824707
Batch 5/64 loss: -2.5386877059936523
Batch 6/64 loss: -2.3261656761169434
Batch 7/64 loss: -2.1923141479492188
Batch 8/64 loss: -2.3919878005981445
Batch 9/64 loss: -2.373138427734375
Batch 10/64 loss: -2.087797164916992
Batch 11/64 loss: -2.571112632751465
Batch 12/64 loss: -2.3892650604248047
Batch 13/64 loss: -1.6359491348266602
Batch 14/64 loss: -2.4100704193115234
Batch 15/64 loss: -2.344282627105713
Batch 16/64 loss: -2.2698020935058594
Batch 17/64 loss: -2.2354230880737305
Batch 18/64 loss: -2.2844347953796387
Batch 19/64 loss: -2.4365687370300293
Batch 20/64 loss: -2.380056381225586
Batch 21/64 loss: -2.329559326171875
Batch 22/64 loss: -2.2034835815429688
Batch 23/64 loss: -2.086545944213867
Batch 24/64 loss: -2.141965866088867
Batch 25/64 loss: -2.419548511505127
Batch 26/64 loss: -2.214019775390625
Batch 27/64 loss: -2.534823417663574
Batch 28/64 loss: -2.2833032608032227
Batch 29/64 loss: -2.17806339263916
Batch 30/64 loss: -2.3399810791015625
Batch 31/64 loss: -2.4314422607421875
Batch 32/64 loss: -2.116323471069336
Batch 33/64 loss: -2.217555046081543
Batch 34/64 loss: -2.200425148010254
Batch 35/64 loss: -2.149953842163086
Batch 36/64 loss: -2.4362244606018066
Batch 37/64 loss: -2.384402275085449
Batch 38/64 loss: -2.4424595832824707
Batch 39/64 loss: -2.3531837463378906
Batch 40/64 loss: -2.356905937194824
Batch 41/64 loss: -2.3565454483032227
Batch 42/64 loss: -2.365682601928711
Batch 43/64 loss: -2.3867998123168945
Batch 44/64 loss: -2.122593879699707
Batch 45/64 loss: -1.4729423522949219
Batch 46/64 loss: -2.162099838256836
Batch 47/64 loss: -2.491931438446045
Batch 48/64 loss: -2.1741514205932617
Batch 49/64 loss: -2.288130760192871
Batch 50/64 loss: -1.9009838104248047
Batch 51/64 loss: -2.057149887084961
Batch 52/64 loss: -2.4105005264282227
Batch 53/64 loss: -2.3257179260253906
Batch 54/64 loss: -2.3460917472839355
Batch 55/64 loss: -2.1462669372558594
Batch 56/64 loss: -2.247685432434082
Batch 57/64 loss: -2.3077402114868164
Batch 58/64 loss: -2.3668971061706543
Batch 59/64 loss: -2.3386192321777344
Batch 60/64 loss: -2.292141914367676
Batch 61/64 loss: -2.3227128982543945
Batch 62/64 loss: -2.303999900817871
Batch 63/64 loss: -2.5244903564453125
Batch 64/64 loss: -6.54264497756958
Epoch 479  Train loss: -2.329940726710301  Val loss: -2.613672577638397
Epoch 480
-------------------------------
Batch 1/64 loss: -2.121591567993164
Batch 2/64 loss: -2.368736743927002
Batch 3/64 loss: -2.2932491302490234
Batch 4/64 loss: -1.9476852416992188
Batch 5/64 loss: -2.1061105728149414
Batch 6/64 loss: -2.2669191360473633
Batch 7/64 loss: -2.272193431854248
Batch 8/64 loss: -2.2080917358398438
Batch 9/64 loss: -1.8799104690551758
Batch 10/64 loss: -2.1996545791625977
Batch 11/64 loss: -2.117304801940918
Batch 12/64 loss: -2.1496410369873047
Batch 13/64 loss: -2.4245166778564453
Batch 14/64 loss: -2.138829231262207
Batch 15/64 loss: -1.5133399963378906
Batch 16/64 loss: -2.324894905090332
Batch 17/64 loss: -2.320157051086426
Batch 18/64 loss: -2.435563087463379
Batch 19/64 loss: -2.285506248474121
Batch 20/64 loss: -2.3822860717773438
Batch 21/64 loss: -2.253973960876465
Batch 22/64 loss: -2.136948585510254
Batch 23/64 loss: -2.066061019897461
Batch 24/64 loss: -2.1382923126220703
Batch 25/64 loss: -2.4206390380859375
Batch 26/64 loss: -2.092529296875
Batch 27/64 loss: -1.2900466918945312
Batch 28/64 loss: -2.338043689727783
Batch 29/64 loss: -2.433833122253418
Batch 30/64 loss: -2.10915470123291
Batch 31/64 loss: -2.3137474060058594
Batch 32/64 loss: -2.1393909454345703
Batch 33/64 loss: -2.308767795562744
Batch 34/64 loss: -2.2815465927124023
Batch 35/64 loss: -2.333469867706299
Batch 36/64 loss: -2.2542009353637695
Batch 37/64 loss: -2.281909465789795
Batch 38/64 loss: -2.3022499084472656
Batch 39/64 loss: -2.256887912750244
Batch 40/64 loss: -1.9087677001953125
Batch 41/64 loss: -2.287952423095703
Batch 42/64 loss: -2.304189682006836
Batch 43/64 loss: -2.041752815246582
Batch 44/64 loss: -1.905991554260254
Batch 45/64 loss: -2.361313819885254
Batch 46/64 loss: -2.253434181213379
Batch 47/64 loss: -2.3692898750305176
Batch 48/64 loss: -1.5759458541870117
Batch 49/64 loss: -2.21297550201416
Batch 50/64 loss: -2.3793129920959473
Batch 51/64 loss: -1.8076086044311523
Batch 52/64 loss: -1.9777803421020508
Batch 53/64 loss: -2.2205944061279297
Batch 54/64 loss: -2.173839569091797
Batch 55/64 loss: -2.167104721069336
Batch 56/64 loss: -2.3196725845336914
Batch 57/64 loss: -2.2437076568603516
Batch 58/64 loss: -2.0924720764160156
Batch 59/64 loss: -2.112581253051758
Batch 60/64 loss: -2.1650333404541016
Batch 61/64 loss: -2.381058692932129
Batch 62/64 loss: -2.0464353561401367
Batch 63/64 loss: -1.1252422332763672
Batch 64/64 loss: -6.423877716064453
Epoch 480  Train loss: -2.207997497857786  Val loss: -2.558554305243738
Epoch 481
-------------------------------
Batch 1/64 loss: -2.268105983734131
Batch 2/64 loss: -2.267629623413086
Batch 3/64 loss: -2.167027473449707
Batch 4/64 loss: -2.2172508239746094
Batch 5/64 loss: -2.0930776596069336
Batch 6/64 loss: -2.266538619995117
Batch 7/64 loss: -1.7621736526489258
Batch 8/64 loss: -2.183119773864746
Batch 9/64 loss: -1.8323822021484375
Batch 10/64 loss: -2.254826068878174
Batch 11/64 loss: -1.947371482849121
Batch 12/64 loss: -1.9691228866577148
Batch 13/64 loss: -2.2914161682128906
Batch 14/64 loss: -2.1900787353515625
Batch 15/64 loss: -2.1839818954467773
Batch 16/64 loss: -2.2385830879211426
Batch 17/64 loss: -2.3960628509521484
Batch 18/64 loss: -2.0910797119140625
Batch 19/64 loss: -2.2716379165649414
Batch 20/64 loss: -2.3139514923095703
Batch 21/64 loss: -2.3609542846679688
Batch 22/64 loss: -2.1645870208740234
Batch 23/64 loss: -2.3529419898986816
Batch 24/64 loss: -1.4343185424804688
Batch 25/64 loss: -2.2232494354248047
Batch 26/64 loss: -2.2110891342163086
Batch 27/64 loss: -2.2295923233032227
Batch 28/64 loss: -2.33243465423584
Batch 29/64 loss: -2.0497264862060547
Batch 30/64 loss: -2.2159671783447266
Batch 31/64 loss: -2.3322439193725586
Batch 32/64 loss: -2.2167482376098633
Batch 33/64 loss: -2.074305534362793
Batch 34/64 loss: -2.2099380493164062
Batch 35/64 loss: -1.950240135192871
Batch 36/64 loss: -2.0844249725341797
Batch 37/64 loss: -1.9845218658447266
Batch 38/64 loss: -2.2520346641540527
Batch 39/64 loss: -2.255263328552246
Batch 40/64 loss: -1.3901681900024414
Batch 41/64 loss: -2.209779739379883
Batch 42/64 loss: -2.528292179107666
Batch 43/64 loss: -2.0079450607299805
Batch 44/64 loss: -2.2509403228759766
Batch 45/64 loss: -2.4050750732421875
Batch 46/64 loss: -2.310850143432617
Batch 47/64 loss: -2.2137794494628906
Batch 48/64 loss: -2.3604893684387207
Batch 49/64 loss: -2.0798215866088867
Batch 50/64 loss: -2.477665424346924
Batch 51/64 loss: -2.449408531188965
Batch 52/64 loss: -1.7831687927246094
Batch 53/64 loss: -2.075986862182617
Batch 54/64 loss: -2.2582664489746094
Batch 55/64 loss: -2.3746261596679688
Batch 56/64 loss: -2.253856658935547
Batch 57/64 loss: -2.448265552520752
Batch 58/64 loss: -2.305495262145996
Batch 59/64 loss: -2.2316646575927734
Batch 60/64 loss: -2.496662139892578
Batch 61/64 loss: -2.0148916244506836
Batch 62/64 loss: -2.3460421562194824
Batch 63/64 loss: -2.3821163177490234
Batch 64/64 loss: -6.594808101654053
Epoch 481  Train loss: -2.2390802140329398  Val loss: -2.596679189360838
Epoch 482
-------------------------------
Batch 1/64 loss: -2.2745704650878906
Batch 2/64 loss: -2.217343330383301
Batch 3/64 loss: -1.9626731872558594
Batch 4/64 loss: -2.4852442741394043
Batch 5/64 loss: -1.9322195053100586
Batch 6/64 loss: -2.2557592391967773
Batch 7/64 loss: -2.439908027648926
Batch 8/64 loss: -2.3982787132263184
Batch 9/64 loss: -2.4959464073181152
Batch 10/64 loss: -2.3742051124572754
Batch 11/64 loss: -2.342008590698242
Batch 12/64 loss: -2.2949371337890625
Batch 13/64 loss: -2.283719539642334
Batch 14/64 loss: -2.340571403503418
Batch 15/64 loss: -2.488048553466797
Batch 16/64 loss: -2.4199233055114746
Batch 17/64 loss: -2.4806017875671387
Batch 18/64 loss: -2.3401412963867188
Batch 19/64 loss: -2.2258529663085938
Batch 20/64 loss: -2.41810941696167
Batch 21/64 loss: -2.338716983795166
Batch 22/64 loss: -2.385833263397217
Batch 23/64 loss: -2.4028148651123047
Batch 24/64 loss: -2.368596076965332
Batch 25/64 loss: -1.6990671157836914
Batch 26/64 loss: -2.182840347290039
Batch 27/64 loss: -2.381183624267578
Batch 28/64 loss: -2.391695499420166
Batch 29/64 loss: -2.480074882507324
Batch 30/64 loss: -2.2646541595458984
Batch 31/64 loss: -1.9946975708007812
Batch 32/64 loss: -2.6113157272338867
Batch 33/64 loss: -2.4297728538513184
Batch 34/64 loss: -2.4187774658203125
Batch 35/64 loss: -1.930649757385254
Batch 36/64 loss: -2.387691020965576
Batch 37/64 loss: -2.3192405700683594
Batch 38/64 loss: -2.3635239601135254
Batch 39/64 loss: -2.294093132019043
Batch 40/64 loss: -2.391751289367676
Batch 41/64 loss: -2.4266791343688965
Batch 42/64 loss: -2.3229432106018066
Batch 43/64 loss: -2.3956480026245117
Batch 44/64 loss: -2.489089012145996
Batch 45/64 loss: -2.403773307800293
Batch 46/64 loss: -2.1857776641845703
Batch 47/64 loss: -2.448017120361328
Batch 48/64 loss: -2.3209376335144043
Batch 49/64 loss: -2.1932382583618164
Batch 50/64 loss: -2.376293182373047
Batch 51/64 loss: -2.3908514976501465
Batch 52/64 loss: -2.3257317543029785
Batch 53/64 loss: -2.152857780456543
Batch 54/64 loss: -2.241983413696289
Batch 55/64 loss: -2.0792884826660156
Batch 56/64 loss: -2.473100185394287
Batch 57/64 loss: -1.7565345764160156
Batch 58/64 loss: -2.2920913696289062
Batch 59/64 loss: -2.2818307876586914
Batch 60/64 loss: -2.2124319076538086
Batch 61/64 loss: -2.486708641052246
Batch 62/64 loss: -2.274477958679199
Batch 63/64 loss: -2.3573923110961914
Batch 64/64 loss: -6.48799991607666
Epoch 482  Train loss: -2.3570310517853383  Val loss: -2.56623745947769
Epoch 483
-------------------------------
Batch 1/64 loss: -2.4610371589660645
Batch 2/64 loss: -2.449496269226074
Batch 3/64 loss: -2.2256717681884766
Batch 4/64 loss: -2.421855926513672
Batch 5/64 loss: -2.323984146118164
Batch 6/64 loss: -2.461644172668457
Batch 7/64 loss: -2.5291996002197266
Batch 8/64 loss: -2.4681882858276367
Batch 9/64 loss: -1.9379425048828125
Batch 10/64 loss: -2.441601276397705
Batch 11/64 loss: -2.2737655639648438
Batch 12/64 loss: -1.7744007110595703
Batch 13/64 loss: -2.164849281311035
Batch 14/64 loss: -2.2558231353759766
Batch 15/64 loss: -2.245608329772949
Batch 16/64 loss: -2.250809669494629
Batch 17/64 loss: -2.292085647583008
Batch 18/64 loss: -2.272183418273926
Batch 19/64 loss: -2.4070825576782227
Batch 20/64 loss: -2.455829620361328
Batch 21/64 loss: -2.539767265319824
Batch 22/64 loss: -2.414076328277588
Batch 23/64 loss: -2.329179286956787
Batch 24/64 loss: -2.454005241394043
Batch 25/64 loss: -2.1356029510498047
Batch 26/64 loss: -2.4532861709594727
Batch 27/64 loss: -2.3415164947509766
Batch 28/64 loss: -2.441134452819824
Batch 29/64 loss: -2.3711838722229004
Batch 30/64 loss: -2.525761604309082
Batch 31/64 loss: -2.171290397644043
Batch 32/64 loss: -2.3843679428100586
Batch 33/64 loss: -2.347350597381592
Batch 34/64 loss: -2.363548755645752
Batch 35/64 loss: -2.5764923095703125
Batch 36/64 loss: -2.335409641265869
Batch 37/64 loss: -2.351363182067871
Batch 38/64 loss: -2.3692245483398438
Batch 39/64 loss: -2.113863945007324
Batch 40/64 loss: -1.7545480728149414
Batch 41/64 loss: -1.673715591430664
Batch 42/64 loss: -2.2427964210510254
Batch 43/64 loss: -2.2313880920410156
Batch 44/64 loss: -2.341104030609131
Batch 45/64 loss: -2.578742027282715
Batch 46/64 loss: -2.3141965866088867
Batch 47/64 loss: -2.4353227615356445
Batch 48/64 loss: -2.454590320587158
Batch 49/64 loss: -1.903493881225586
Batch 50/64 loss: -2.136547088623047
Batch 51/64 loss: -2.4879822731018066
Batch 52/64 loss: -2.369309425354004
Batch 53/64 loss: -2.428837776184082
Batch 54/64 loss: -2.1322059631347656
Batch 55/64 loss: -2.57741641998291
Batch 56/64 loss: -2.2329940795898438
Batch 57/64 loss: -2.3623600006103516
Batch 58/64 loss: -2.403583526611328
Batch 59/64 loss: -2.3241500854492188
Batch 60/64 loss: -2.124002456665039
Batch 61/64 loss: -2.3911309242248535
Batch 62/64 loss: -2.189761161804199
Batch 63/64 loss: -2.1869335174560547
Batch 64/64 loss: -6.5798726081848145
Epoch 483  Train loss: -2.3583294270085355  Val loss: -2.599243216498201
Epoch 484
-------------------------------
Batch 1/64 loss: -2.2278003692626953
Batch 2/64 loss: -2.3414835929870605
Batch 3/64 loss: -2.473792552947998
Batch 4/64 loss: -2.256321907043457
Batch 5/64 loss: -2.4945478439331055
Batch 6/64 loss: -2.3797531127929688
Batch 7/64 loss: -2.3069376945495605
Batch 8/64 loss: -2.3619117736816406
Batch 9/64 loss: -2.283966064453125
Batch 10/64 loss: -2.373154640197754
Batch 11/64 loss: -1.755605697631836
Batch 12/64 loss: -2.3035507202148438
Batch 13/64 loss: -2.3569459915161133
Batch 14/64 loss: -2.1829137802124023
Batch 15/64 loss: -2.4123573303222656
Batch 16/64 loss: -2.19512939453125
Batch 17/64 loss: -2.3875904083251953
Batch 18/64 loss: -2.3036928176879883
Batch 19/64 loss: -1.7627277374267578
Batch 20/64 loss: -2.324099540710449
Batch 21/64 loss: -2.031352996826172
Batch 22/64 loss: -2.1658458709716797
Batch 23/64 loss: -2.2295799255371094
Batch 24/64 loss: -2.156269073486328
Batch 25/64 loss: -2.333645820617676
Batch 26/64 loss: -2.294127941131592
Batch 27/64 loss: -2.3719053268432617
Batch 28/64 loss: -2.2456207275390625
Batch 29/64 loss: -2.302828788757324
Batch 30/64 loss: -2.0789709091186523
Batch 31/64 loss: -2.340066909790039
Batch 32/64 loss: -2.304342746734619
Batch 33/64 loss: -2.057302474975586
Batch 34/64 loss: -2.3745412826538086
Batch 35/64 loss: -2.11807918548584
Batch 36/64 loss: -1.8806991577148438
Batch 37/64 loss: -2.311314105987549
Batch 38/64 loss: -2.27591609954834
Batch 39/64 loss: -1.3195056915283203
Batch 40/64 loss: -2.2739410400390625
Batch 41/64 loss: -2.185429573059082
Batch 42/64 loss: -2.3184618949890137
Batch 43/64 loss: -2.159213066101074
Batch 44/64 loss: -2.3726792335510254
Batch 45/64 loss: -2.0918569564819336
Batch 46/64 loss: -2.290417194366455
Batch 47/64 loss: -2.135228157043457
Batch 48/64 loss: -2.257415771484375
Batch 49/64 loss: -2.3585023880004883
Batch 50/64 loss: -2.102198600769043
Batch 51/64 loss: -2.2691869735717773
Batch 52/64 loss: -2.3414201736450195
Batch 53/64 loss: -2.3330698013305664
Batch 54/64 loss: -2.102768898010254
Batch 55/64 loss: -2.0281267166137695
Batch 56/64 loss: -2.1451854705810547
Batch 57/64 loss: -1.594599723815918
Batch 58/64 loss: -1.9006280899047852
Batch 59/64 loss: -2.1592578887939453
Batch 60/64 loss: -2.4506101608276367
Batch 61/64 loss: -2.3978753089904785
Batch 62/64 loss: -2.38090181350708
Batch 63/64 loss: -2.467635154724121
Batch 64/64 loss: -6.509457111358643
Epoch 484  Train loss: -2.2694102100297515  Val loss: -2.565769759240429
Epoch 485
-------------------------------
Batch 1/64 loss: -2.472123146057129
Batch 2/64 loss: -2.4273791313171387
Batch 3/64 loss: -2.4194283485412598
Batch 4/64 loss: -2.2823495864868164
Batch 5/64 loss: -2.003192901611328
Batch 6/64 loss: -2.233160972595215
Batch 7/64 loss: -2.3661532402038574
Batch 8/64 loss: -2.3049378395080566
Batch 9/64 loss: -2.6063876152038574
Batch 10/64 loss: -2.426449775695801
Batch 11/64 loss: -2.31156587600708
Batch 12/64 loss: -2.243159294128418
Batch 13/64 loss: -2.430612564086914
Batch 14/64 loss: -2.1081199645996094
Batch 15/64 loss: -2.312802314758301
Batch 16/64 loss: -1.9610223770141602
Batch 17/64 loss: -2.5581912994384766
Batch 18/64 loss: -2.253148078918457
Batch 19/64 loss: -2.2197303771972656
Batch 20/64 loss: -2.2966442108154297
Batch 21/64 loss: -2.3622312545776367
Batch 22/64 loss: -2.3936753273010254
Batch 23/64 loss: -2.3636069297790527
Batch 24/64 loss: -2.422024726867676
Batch 25/64 loss: -1.2875633239746094
Batch 26/64 loss: -2.319927215576172
Batch 27/64 loss: -2.3049392700195312
Batch 28/64 loss: -2.2085580825805664
Batch 29/64 loss: -2.5559635162353516
Batch 30/64 loss: -2.4190969467163086
Batch 31/64 loss: -2.2115249633789062
Batch 32/64 loss: -2.1495161056518555
Batch 33/64 loss: -2.5475196838378906
Batch 34/64 loss: -2.3490381240844727
Batch 35/64 loss: -2.4238815307617188
Batch 36/64 loss: -2.3299527168273926
Batch 37/64 loss: -2.4238462448120117
Batch 38/64 loss: -2.2129430770874023
Batch 39/64 loss: -2.1263742446899414
Batch 40/64 loss: -2.4808521270751953
Batch 41/64 loss: -2.3245458602905273
Batch 42/64 loss: -2.336358070373535
Batch 43/64 loss: -2.5116233825683594
Batch 44/64 loss: -2.436687469482422
Batch 45/64 loss: -2.0501327514648438
Batch 46/64 loss: -2.5019888877868652
Batch 47/64 loss: -2.557321548461914
Batch 48/64 loss: -2.3808603286743164
Batch 49/64 loss: -2.551609516143799
Batch 50/64 loss: -2.4203872680664062
Batch 51/64 loss: -2.462170124053955
Batch 52/64 loss: -2.4543581008911133
Batch 53/64 loss: -2.48457670211792
Batch 54/64 loss: -2.601870536804199
Batch 55/64 loss: -2.468212604522705
Batch 56/64 loss: -2.3722119331359863
Batch 57/64 loss: -2.004026412963867
Batch 58/64 loss: -2.0722885131835938
Batch 59/64 loss: -2.2042922973632812
Batch 60/64 loss: -2.354189872741699
Batch 61/64 loss: -1.8150053024291992
Batch 62/64 loss: -2.639941692352295
Batch 63/64 loss: -2.574493408203125
Batch 64/64 loss: -6.687624454498291
Epoch 485  Train loss: -2.379991611779905  Val loss: -2.7403865302960897
Epoch 486
-------------------------------
Batch 1/64 loss: -2.319394111633301
Batch 2/64 loss: -2.556753635406494
Batch 3/64 loss: -2.516160011291504
Batch 4/64 loss: -2.258758544921875
Batch 5/64 loss: -2.528374671936035
Batch 6/64 loss: -1.7115535736083984
Batch 7/64 loss: -2.4448280334472656
Batch 8/64 loss: -2.351541519165039
Batch 9/64 loss: -2.3631715774536133
Batch 10/64 loss: -2.631194591522217
Batch 11/64 loss: -2.3769969940185547
Batch 12/64 loss: -2.294097900390625
Batch 13/64 loss: -2.2303476333618164
Batch 14/64 loss: -2.0266008377075195
Batch 15/64 loss: -1.846954345703125
Batch 16/64 loss: -2.443819999694824
Batch 17/64 loss: -2.0164613723754883
Batch 18/64 loss: -2.3578433990478516
Batch 19/64 loss: -1.7587461471557617
Batch 20/64 loss: -2.219118118286133
Batch 21/64 loss: -2.2961502075195312
Batch 22/64 loss: -2.3316211700439453
Batch 23/64 loss: -2.3223037719726562
Batch 24/64 loss: -2.389779567718506
Batch 25/64 loss: -2.0647506713867188
Batch 26/64 loss: -2.129828453063965
Batch 27/64 loss: -2.1237688064575195
Batch 28/64 loss: -2.3782925605773926
Batch 29/64 loss: -2.2474231719970703
Batch 30/64 loss: -2.397522449493408
Batch 31/64 loss: -2.377074718475342
Batch 32/64 loss: -2.19571590423584
Batch 33/64 loss: -2.138373374938965
Batch 34/64 loss: -2.5636940002441406
Batch 35/64 loss: -2.526244640350342
Batch 36/64 loss: -2.236318588256836
Batch 37/64 loss: -2.2855615615844727
Batch 38/64 loss: -2.4576878547668457
Batch 39/64 loss: -2.3209962844848633
Batch 40/64 loss: -2.4822864532470703
Batch 41/64 loss: -2.541851043701172
Batch 42/64 loss: -2.53098201751709
Batch 43/64 loss: -2.2820472717285156
Batch 44/64 loss: -2.2037525177001953
Batch 45/64 loss: -2.2960357666015625
Batch 46/64 loss: -2.3877997398376465
Batch 47/64 loss: -2.5076193809509277
Batch 48/64 loss: -2.4441580772399902
Batch 49/64 loss: -2.570789337158203
Batch 50/64 loss: -2.366110324859619
Batch 51/64 loss: -2.4221506118774414
Batch 52/64 loss: -2.6048455238342285
Batch 53/64 loss: -2.501504898071289
Batch 54/64 loss: -2.3941245079040527
Batch 55/64 loss: -2.29803466796875
Batch 56/64 loss: -2.2566452026367188
Batch 57/64 loss: -2.2056751251220703
Batch 58/64 loss: -2.5524158477783203
Batch 59/64 loss: -2.3637523651123047
Batch 60/64 loss: -2.346191883087158
Batch 61/64 loss: -2.531773090362549
Batch 62/64 loss: -2.575807571411133
Batch 63/64 loss: -2.408473014831543
Batch 64/64 loss: -6.69822359085083
Epoch 486  Train loss: -2.3864206856372308  Val loss: -2.7351790883696774
Epoch 487
-------------------------------
Batch 1/64 loss: -2.5606303215026855
Batch 2/64 loss: -2.4621644020080566
Batch 3/64 loss: -2.46600341796875
Batch 4/64 loss: -2.42329740524292
Batch 5/64 loss: -2.2224388122558594
Batch 6/64 loss: -2.572999954223633
Batch 7/64 loss: -2.3467931747436523
Batch 8/64 loss: -2.5105533599853516
Batch 9/64 loss: -2.365243434906006
Batch 10/64 loss: -2.206362724304199
Batch 11/64 loss: -2.4235119819641113
Batch 12/64 loss: -2.4411635398864746
Batch 13/64 loss: -2.344193458557129
Batch 14/64 loss: -2.436614513397217
Batch 15/64 loss: -2.359457015991211
Batch 16/64 loss: -1.6131372451782227
Batch 17/64 loss: -2.3925657272338867
Batch 18/64 loss: -2.6014528274536133
Batch 19/64 loss: -2.5534653663635254
Batch 20/64 loss: -2.4205169677734375
Batch 21/64 loss: -2.339871406555176
Batch 22/64 loss: -2.314218521118164
Batch 23/64 loss: -2.2595911026000977
Batch 24/64 loss: -2.3835721015930176
Batch 25/64 loss: -2.1846885681152344
Batch 26/64 loss: -2.4936795234680176
Batch 27/64 loss: -2.45401668548584
Batch 28/64 loss: -2.608114242553711
Batch 29/64 loss: -2.5058960914611816
Batch 30/64 loss: -2.505070209503174
Batch 31/64 loss: -2.248067855834961
Batch 32/64 loss: -2.3921566009521484
Batch 33/64 loss: -2.3965091705322266
Batch 34/64 loss: -2.393446922302246
Batch 35/64 loss: -2.4864559173583984
Batch 36/64 loss: -2.5735769271850586
Batch 37/64 loss: -2.3534159660339355
Batch 38/64 loss: -1.9740324020385742
Batch 39/64 loss: -2.370856285095215
Batch 40/64 loss: -2.417823314666748
Batch 41/64 loss: -2.32350492477417
Batch 42/64 loss: -1.6359500885009766
Batch 43/64 loss: -2.4537220001220703
Batch 44/64 loss: -2.183699607849121
Batch 45/64 loss: -2.5037031173706055
Batch 46/64 loss: -2.5208826065063477
Batch 47/64 loss: -2.4090957641601562
Batch 48/64 loss: -2.4458961486816406
Batch 49/64 loss: -2.4817495346069336
Batch 50/64 loss: -2.347527027130127
Batch 51/64 loss: -2.0622358322143555
Batch 52/64 loss: -2.2565536499023438
Batch 53/64 loss: -2.441775321960449
Batch 54/64 loss: -2.23476505279541
Batch 55/64 loss: -2.156351089477539
Batch 56/64 loss: -2.523115634918213
Batch 57/64 loss: -2.452732563018799
Batch 58/64 loss: -2.4288039207458496
Batch 59/64 loss: -2.2319812774658203
Batch 60/64 loss: -2.506411552429199
Batch 61/64 loss: -2.256929397583008
Batch 62/64 loss: -2.409367084503174
Batch 63/64 loss: -2.409611701965332
Batch 64/64 loss: -6.618127822875977
Epoch 487  Train loss: -2.415962136960497  Val loss: -2.6559368933189367
Epoch 488
-------------------------------
Batch 1/64 loss: -2.1701011657714844
Batch 2/64 loss: -2.2640156745910645
Batch 3/64 loss: -2.3121895790100098
Batch 4/64 loss: -2.2983760833740234
Batch 5/64 loss: -2.3229217529296875
Batch 6/64 loss: -2.4300503730773926
Batch 7/64 loss: -2.3690552711486816
Batch 8/64 loss: -2.4547276496887207
Batch 9/64 loss: -2.1368837356567383
Batch 10/64 loss: -1.7569990158081055
Batch 11/64 loss: -2.323611259460449
Batch 12/64 loss: -1.8380870819091797
Batch 13/64 loss: -2.440357208251953
Batch 14/64 loss: -2.396331787109375
Batch 15/64 loss: -2.3728275299072266
Batch 16/64 loss: -2.406430721282959
Batch 17/64 loss: -2.431731700897217
Batch 18/64 loss: -2.504943370819092
Batch 19/64 loss: -2.298046112060547
Batch 20/64 loss: -2.574801445007324
Batch 21/64 loss: -2.178495407104492
Batch 22/64 loss: -2.5151453018188477
Batch 23/64 loss: -2.2410812377929688
Batch 24/64 loss: -2.366832733154297
Batch 25/64 loss: -2.4283180236816406
Batch 26/64 loss: -2.523791790008545
Batch 27/64 loss: -2.2413034439086914
Batch 28/64 loss: -2.4070310592651367
Batch 29/64 loss: -1.9282417297363281
Batch 30/64 loss: -2.191263198852539
Batch 31/64 loss: -2.3575525283813477
Batch 32/64 loss: -2.425572395324707
Batch 33/64 loss: -2.3935017585754395
Batch 34/64 loss: -2.3468551635742188
Batch 35/64 loss: -2.39359712600708
Batch 36/64 loss: -2.5308799743652344
Batch 37/64 loss: -2.34450626373291
Batch 38/64 loss: -2.34706449508667
Batch 39/64 loss: -1.975006103515625
Batch 40/64 loss: -2.4331836700439453
Batch 41/64 loss: -2.487760543823242
Batch 42/64 loss: -2.476236343383789
Batch 43/64 loss: -1.8598175048828125
Batch 44/64 loss: -2.473940849304199
Batch 45/64 loss: -2.4026904106140137
Batch 46/64 loss: -2.3263702392578125
Batch 47/64 loss: -2.4454751014709473
Batch 48/64 loss: -2.3277969360351562
Batch 49/64 loss: -2.0689754486083984
Batch 50/64 loss: -2.4923477172851562
Batch 51/64 loss: -2.4368629455566406
Batch 52/64 loss: -2.2951860427856445
Batch 53/64 loss: -2.0149831771850586
Batch 54/64 loss: -2.3953089714050293
Batch 55/64 loss: -2.2529191970825195
Batch 56/64 loss: -2.2636022567749023
Batch 57/64 loss: -2.436462879180908
Batch 58/64 loss: -2.2805986404418945
Batch 59/64 loss: -2.3302669525146484
Batch 60/64 loss: -2.4563350677490234
Batch 61/64 loss: -2.4621429443359375
Batch 62/64 loss: -2.4833879470825195
Batch 63/64 loss: -2.439849376678467
Batch 64/64 loss: -6.616076469421387
Epoch 488  Train loss: -2.377146459093281  Val loss: -2.655690301324903
Epoch 489
-------------------------------
Batch 1/64 loss: -2.3310041427612305
Batch 2/64 loss: -2.5378780364990234
Batch 3/64 loss: -2.1261234283447266
Batch 4/64 loss: -2.453279495239258
Batch 5/64 loss: -2.346609115600586
Batch 6/64 loss: -2.0717029571533203
Batch 7/64 loss: -2.256747245788574
Batch 8/64 loss: -2.42642879486084
Batch 9/64 loss: -2.2132701873779297
Batch 10/64 loss: -2.245332717895508
Batch 11/64 loss: -2.251309394836426
Batch 12/64 loss: -2.354496955871582
Batch 13/64 loss: -2.308298110961914
Batch 14/64 loss: -1.9472026824951172
Batch 15/64 loss: -2.307267189025879
Batch 16/64 loss: -2.375575542449951
Batch 17/64 loss: -2.487708568572998
Batch 18/64 loss: -2.346132278442383
Batch 19/64 loss: -2.458804130554199
Batch 20/64 loss: -2.3522000312805176
Batch 21/64 loss: -0.9862833023071289
Batch 22/64 loss: -2.331246852874756
Batch 23/64 loss: -2.3788771629333496
Batch 24/64 loss: -2.2208681106567383
Batch 25/64 loss: -2.384244918823242
Batch 26/64 loss: -2.2480592727661133
Batch 27/64 loss: -2.2769522666931152
Batch 28/64 loss: -2.2849035263061523
Batch 29/64 loss: -2.315075397491455
Batch 30/64 loss: -2.2367477416992188
Batch 31/64 loss: -1.8706655502319336
Batch 32/64 loss: -2.4454574584960938
Batch 33/64 loss: -2.34000301361084
Batch 34/64 loss: -2.1854124069213867
Batch 35/64 loss: -2.2319068908691406
Batch 36/64 loss: -2.270169258117676
Batch 37/64 loss: -2.3603601455688477
Batch 38/64 loss: -1.6658315658569336
Batch 39/64 loss: -2.2172927856445312
Batch 40/64 loss: -2.3363800048828125
Batch 41/64 loss: -2.251718521118164
Batch 42/64 loss: -2.254659652709961
Batch 43/64 loss: -2.4257378578186035
Batch 44/64 loss: -2.3989686965942383
Batch 45/64 loss: -2.027218818664551
Batch 46/64 loss: -2.205259323120117
Batch 47/64 loss: -2.303495407104492
Batch 48/64 loss: -2.3911972045898438
Batch 49/64 loss: -2.0798940658569336
Batch 50/64 loss: -2.3733181953430176
Batch 51/64 loss: -2.4135046005249023
Batch 52/64 loss: -2.031590461730957
Batch 53/64 loss: -2.24127197265625
Batch 54/64 loss: -2.334969997406006
Batch 55/64 loss: -2.374556064605713
Batch 56/64 loss: -2.3623132705688477
Batch 57/64 loss: -2.465390205383301
Batch 58/64 loss: -2.3971056938171387
Batch 59/64 loss: -2.4073753356933594
Batch 60/64 loss: -2.456881523132324
Batch 61/64 loss: -2.258251190185547
Batch 62/64 loss: -2.40911865234375
Batch 63/64 loss: -2.443617343902588
Batch 64/64 loss: -6.566249847412109
Epoch 489  Train loss: -2.3218229032030293  Val loss: -2.7380134608737383
Epoch 490
-------------------------------
Batch 1/64 loss: -2.51273775100708
Batch 2/64 loss: -2.450641632080078
Batch 3/64 loss: -2.315707206726074
Batch 4/64 loss: -2.3035030364990234
Batch 5/64 loss: -2.1959571838378906
Batch 6/64 loss: -2.487250804901123
Batch 7/64 loss: -2.3900370597839355
Batch 8/64 loss: -2.3030405044555664
Batch 9/64 loss: -2.3097915649414062
Batch 10/64 loss: -2.385671615600586
Batch 11/64 loss: -2.2899932861328125
Batch 12/64 loss: -2.1894330978393555
Batch 13/64 loss: -2.1936302185058594
Batch 14/64 loss: -2.433137893676758
Batch 15/64 loss: -2.3582115173339844
Batch 16/64 loss: -2.49253511428833
Batch 17/64 loss: -2.2922229766845703
Batch 18/64 loss: -2.321261405944824
Batch 19/64 loss: -2.3816075325012207
Batch 20/64 loss: -2.135003089904785
Batch 21/64 loss: -2.448030471801758
Batch 22/64 loss: -2.178360939025879
Batch 23/64 loss: -2.3010873794555664
Batch 24/64 loss: -2.357469081878662
Batch 25/64 loss: -2.2974119186401367
Batch 26/64 loss: -2.4035444259643555
Batch 27/64 loss: -2.4907889366149902
Batch 28/64 loss: -2.3827648162841797
Batch 29/64 loss: -2.2771596908569336
Batch 30/64 loss: -2.5210037231445312
Batch 31/64 loss: -2.340373992919922
Batch 32/64 loss: -2.405406951904297
Batch 33/64 loss: -2.374227523803711
Batch 34/64 loss: -2.5047645568847656
Batch 35/64 loss: -2.4352684020996094
Batch 36/64 loss: -1.9033212661743164
Batch 37/64 loss: -2.105998992919922
Batch 38/64 loss: -2.285984992980957
Batch 39/64 loss: -2.4675636291503906
Batch 40/64 loss: -1.6492176055908203
Batch 41/64 loss: -2.437407970428467
Batch 42/64 loss: -2.510221004486084
Batch 43/64 loss: -2.177496910095215
Batch 44/64 loss: -2.4358973503112793
Batch 45/64 loss: -2.4705095291137695
Batch 46/64 loss: -2.434673309326172
Batch 47/64 loss: -2.2270679473876953
Batch 48/64 loss: -2.4856839179992676
Batch 49/64 loss: -1.888533592224121
Batch 50/64 loss: -2.1699628829956055
Batch 51/64 loss: -2.219898223876953
Batch 52/64 loss: -2.496170997619629
Batch 53/64 loss: -2.551671028137207
Batch 54/64 loss: -2.581148624420166
Batch 55/64 loss: -2.256010055541992
Batch 56/64 loss: -2.013237953186035
Batch 57/64 loss: -2.5402159690856934
Batch 58/64 loss: -2.2690062522888184
Batch 59/64 loss: -2.258657455444336
Batch 60/64 loss: -2.5493669509887695
Batch 61/64 loss: -2.434535503387451
Batch 62/64 loss: -2.400874614715576
Batch 63/64 loss: -2.591764450073242
Batch 64/64 loss: -6.713502407073975
Epoch 490  Train loss: -2.389117852379294  Val loss: -2.6878122283830677
Epoch 491
-------------------------------
Batch 1/64 loss: -2.354273796081543
Batch 2/64 loss: -2.4160566329956055
Batch 3/64 loss: -2.455634117126465
Batch 4/64 loss: -2.3805742263793945
Batch 5/64 loss: -1.6878271102905273
Batch 6/64 loss: -2.2753067016601562
Batch 7/64 loss: -2.333833694458008
Batch 8/64 loss: -2.4852218627929688
Batch 9/64 loss: -2.530482769012451
Batch 10/64 loss: -2.449953079223633
Batch 11/64 loss: -2.503826141357422
Batch 12/64 loss: -2.2791237831115723
Batch 13/64 loss: -2.2260704040527344
Batch 14/64 loss: -1.6446456909179688
Batch 15/64 loss: -2.258429527282715
Batch 16/64 loss: -2.4907636642456055
Batch 17/64 loss: -2.525937080383301
Batch 18/64 loss: -2.0272369384765625
Batch 19/64 loss: -2.1851024627685547
Batch 20/64 loss: -2.151738166809082
Batch 21/64 loss: -2.4844627380371094
Batch 22/64 loss: -2.183730125427246
Batch 23/64 loss: -2.2309341430664062
Batch 24/64 loss: -2.0601654052734375
Batch 25/64 loss: -2.0926694869995117
Batch 26/64 loss: -2.4276914596557617
Batch 27/64 loss: -2.1964778900146484
Batch 28/64 loss: -1.9022140502929688
Batch 29/64 loss: -1.9710817337036133
Batch 30/64 loss: -2.430972099304199
Batch 31/64 loss: -2.205002784729004
Batch 32/64 loss: -2.512392520904541
Batch 33/64 loss: -2.1709184646606445
Batch 34/64 loss: -2.2686166763305664
Batch 35/64 loss: -2.466891288757324
Batch 36/64 loss: -1.9626646041870117
Batch 37/64 loss: -2.384575843811035
Batch 38/64 loss: -2.4507627487182617
Batch 39/64 loss: -2.12496280670166
Batch 40/64 loss: -2.290332794189453
Batch 41/64 loss: -2.3746848106384277
Batch 42/64 loss: -2.330010414123535
Batch 43/64 loss: -2.348729133605957
Batch 44/64 loss: -2.5586585998535156
Batch 45/64 loss: -2.5519065856933594
Batch 46/64 loss: -2.29367733001709
Batch 47/64 loss: -2.2657060623168945
Batch 48/64 loss: -2.253793716430664
Batch 49/64 loss: -2.4450178146362305
Batch 50/64 loss: -1.6756362915039062
Batch 51/64 loss: -2.584164619445801
Batch 52/64 loss: -2.4319067001342773
Batch 53/64 loss: -2.518087387084961
Batch 54/64 loss: -2.436405658721924
Batch 55/64 loss: -2.4545764923095703
Batch 56/64 loss: -2.3673276901245117
Batch 57/64 loss: -2.471129894256592
Batch 58/64 loss: -2.4001498222351074
Batch 59/64 loss: -2.395447254180908
Batch 60/64 loss: -2.4096150398254395
Batch 61/64 loss: -2.35677433013916
Batch 62/64 loss: -2.4175028800964355
Batch 63/64 loss: -2.290675163269043
Batch 64/64 loss: -6.730561256408691
Epoch 491  Train loss: -2.355436268974753  Val loss: -2.7089215177031316
Epoch 492
-------------------------------
Batch 1/64 loss: -2.447307586669922
Batch 2/64 loss: -2.4404311180114746
Batch 3/64 loss: -2.5026979446411133
Batch 4/64 loss: -2.403657913208008
Batch 5/64 loss: -2.4044318199157715
Batch 6/64 loss: -2.3387651443481445
Batch 7/64 loss: -2.4925742149353027
Batch 8/64 loss: -2.2711181640625
Batch 9/64 loss: -2.1897621154785156
Batch 10/64 loss: -2.2852134704589844
Batch 11/64 loss: -2.4995102882385254
Batch 12/64 loss: -2.4149208068847656
Batch 13/64 loss: -2.3853840827941895
Batch 14/64 loss: -2.571366310119629
Batch 15/64 loss: -2.3223838806152344
Batch 16/64 loss: -2.342538833618164
Batch 17/64 loss: -2.4798784255981445
Batch 18/64 loss: -2.193706512451172
Batch 19/64 loss: -2.3583035469055176
Batch 20/64 loss: -2.470872402191162
Batch 21/64 loss: -2.346787452697754
Batch 22/64 loss: -2.4994335174560547
Batch 23/64 loss: -2.342670440673828
Batch 24/64 loss: -2.523538589477539
Batch 25/64 loss: -2.0902490615844727
Batch 26/64 loss: -2.2432384490966797
Batch 27/64 loss: -2.533719062805176
Batch 28/64 loss: -2.3879518508911133
Batch 29/64 loss: -2.3809027671813965
Batch 30/64 loss: -2.3844847679138184
Batch 31/64 loss: -2.2610130310058594
Batch 32/64 loss: -2.3699464797973633
Batch 33/64 loss: -2.4118380546569824
Batch 34/64 loss: -1.9913549423217773
Batch 35/64 loss: -2.428852081298828
Batch 36/64 loss: -2.379693031311035
Batch 37/64 loss: -2.499112129211426
Batch 38/64 loss: -2.4787979125976562
Batch 39/64 loss: -2.5050268173217773
Batch 40/64 loss: -2.4619932174682617
Batch 41/64 loss: -2.348268508911133
Batch 42/64 loss: -2.4928855895996094
Batch 43/64 loss: -2.580507755279541
Batch 44/64 loss: -2.540605068206787
Batch 45/64 loss: -2.228221893310547
Batch 46/64 loss: -2.0025177001953125
Batch 47/64 loss: -2.465909004211426
Batch 48/64 loss: -2.507244110107422
Batch 49/64 loss: -2.3316774368286133
Batch 50/64 loss: -2.499002456665039
Batch 51/64 loss: -1.4703922271728516
Batch 52/64 loss: -2.453050136566162
Batch 53/64 loss: -2.3760437965393066
Batch 54/64 loss: -2.4519052505493164
Batch 55/64 loss: -2.2494821548461914
Batch 56/64 loss: -2.6007580757141113
Batch 57/64 loss: -2.482968330383301
Batch 58/64 loss: -1.8294849395751953
Batch 59/64 loss: -2.3523354530334473
Batch 60/64 loss: -2.3781304359436035
Batch 61/64 loss: -2.3112096786499023
Batch 62/64 loss: -2.6189255714416504
Batch 63/64 loss: -2.309427261352539
Batch 64/64 loss: -6.504127025604248
Epoch 492  Train loss: -2.417168256348255  Val loss: -2.7273625901474574
Epoch 493
-------------------------------
Batch 1/64 loss: -1.8249473571777344
Batch 2/64 loss: -2.3699426651000977
Batch 3/64 loss: -2.506417751312256
Batch 4/64 loss: -2.3517212867736816
Batch 5/64 loss: -2.3451013565063477
Batch 6/64 loss: -2.4436912536621094
Batch 7/64 loss: -2.519695281982422
Batch 8/64 loss: -2.468308448791504
Batch 9/64 loss: -1.9809226989746094
Batch 10/64 loss: -2.3009424209594727
Batch 11/64 loss: -2.297863006591797
Batch 12/64 loss: -2.5846095085144043
Batch 13/64 loss: -2.4457082748413086
Batch 14/64 loss: -1.641606330871582
Batch 15/64 loss: -2.397336006164551
Batch 16/64 loss: -2.410980701446533
Batch 17/64 loss: -2.167469024658203
Batch 18/64 loss: -2.3936033248901367
Batch 19/64 loss: -2.3735361099243164
Batch 20/64 loss: -2.3728294372558594
Batch 21/64 loss: -2.3242979049682617
Batch 22/64 loss: -2.4142627716064453
Batch 23/64 loss: -2.2353763580322266
Batch 24/64 loss: -2.4288625717163086
Batch 25/64 loss: -2.3411760330200195
Batch 26/64 loss: -2.47035551071167
Batch 27/64 loss: -2.436610221862793
Batch 28/64 loss: -1.6798477172851562
Batch 29/64 loss: -2.470407009124756
Batch 30/64 loss: -2.3567981719970703
Batch 31/64 loss: -2.3161888122558594
Batch 32/64 loss: -2.5362672805786133
Batch 33/64 loss: -2.3233633041381836
Batch 34/64 loss: -2.229562759399414
Batch 35/64 loss: -2.5086965560913086
Batch 36/64 loss: -2.4896936416625977
Batch 37/64 loss: -2.4680581092834473
Batch 38/64 loss: -2.480757713317871
Batch 39/64 loss: -2.4211158752441406
Batch 40/64 loss: -2.341546058654785
Batch 41/64 loss: -2.455050468444824
Batch 42/64 loss: -2.3283252716064453
Batch 43/64 loss: -2.4090232849121094
Batch 44/64 loss: -2.3073129653930664
Batch 45/64 loss: -2.403447151184082
Batch 46/64 loss: -2.5012097358703613
Batch 47/64 loss: -2.2238588333129883
Batch 48/64 loss: -2.4312472343444824
Batch 49/64 loss: -1.8211240768432617
Batch 50/64 loss: -2.4654760360717773
Batch 51/64 loss: -2.4029159545898438
Batch 52/64 loss: -2.442584991455078
Batch 53/64 loss: -2.660942554473877
Batch 54/64 loss: -2.178574562072754
Batch 55/64 loss: -2.473209857940674
Batch 56/64 loss: -2.295741081237793
Batch 57/64 loss: -2.462343215942383
Batch 58/64 loss: -2.2846546173095703
Batch 59/64 loss: -2.475351333618164
Batch 60/64 loss: -2.385406494140625
Batch 61/64 loss: -2.386960983276367
Batch 62/64 loss: -2.4287333488464355
Batch 63/64 loss: -2.507103443145752
Batch 64/64 loss: -6.676023960113525
Epoch 493  Train loss: -2.403264189701454  Val loss: -2.760190930972804
Epoch 494
-------------------------------
Batch 1/64 loss: -2.521979331970215
Batch 2/64 loss: -2.4459218978881836
Batch 3/64 loss: -2.6955814361572266
Batch 4/64 loss: -2.5035347938537598
Batch 5/64 loss: -2.507091522216797
Batch 6/64 loss: -2.349832534790039
Batch 7/64 loss: -2.521817684173584
Batch 8/64 loss: -2.544247627258301
Batch 9/64 loss: -2.569432258605957
Batch 10/64 loss: -2.554067611694336
Batch 11/64 loss: -2.4707412719726562
Batch 12/64 loss: -2.468935489654541
Batch 13/64 loss: -2.388808250427246
Batch 14/64 loss: -2.365560531616211
Batch 15/64 loss: -2.393876075744629
Batch 16/64 loss: -2.174654006958008
Batch 17/64 loss: -2.5169677734375
Batch 18/64 loss: -2.400857925415039
Batch 19/64 loss: -2.336854934692383
Batch 20/64 loss: -2.4036502838134766
Batch 21/64 loss: -2.4432640075683594
Batch 22/64 loss: -2.325606346130371
Batch 23/64 loss: -2.3467159271240234
Batch 24/64 loss: -2.29288387298584
Batch 25/64 loss: -2.280742645263672
Batch 26/64 loss: -2.6037049293518066
Batch 27/64 loss: -2.221284866333008
Batch 28/64 loss: -2.405013084411621
Batch 29/64 loss: -2.0916919708251953
Batch 30/64 loss: -2.473224639892578
Batch 31/64 loss: -2.485152244567871
Batch 32/64 loss: -2.3564834594726562
Batch 33/64 loss: -2.528985023498535
Batch 34/64 loss: -2.2826271057128906
Batch 35/64 loss: -2.407947063446045
Batch 36/64 loss: -2.5816292762756348
Batch 37/64 loss: -2.3101320266723633
Batch 38/64 loss: -1.9884681701660156
Batch 39/64 loss: -2.0960817337036133
Batch 40/64 loss: -2.4379749298095703
Batch 41/64 loss: -2.497835636138916
Batch 42/64 loss: -2.3876523971557617
Batch 43/64 loss: -2.401120185852051
Batch 44/64 loss: -2.480349540710449
Batch 45/64 loss: -2.3204269409179688
Batch 46/64 loss: -1.9918594360351562
Batch 47/64 loss: -1.5969963073730469
Batch 48/64 loss: -2.3965988159179688
Batch 49/64 loss: -2.254915237426758
Batch 50/64 loss: -2.2448549270629883
Batch 51/64 loss: -2.289719581604004
Batch 52/64 loss: -2.325821876525879
Batch 53/64 loss: -2.436465263366699
Batch 54/64 loss: -2.2518959045410156
Batch 55/64 loss: -2.337444305419922
Batch 56/64 loss: -2.5254669189453125
Batch 57/64 loss: -2.5790023803710938
Batch 58/64 loss: -2.220142364501953
Batch 59/64 loss: -2.4289588928222656
Batch 60/64 loss: -2.426723003387451
Batch 61/64 loss: -2.525674819946289
Batch 62/64 loss: -2.7196412086486816
Batch 63/64 loss: -2.348865509033203
Batch 64/64 loss: -6.613425254821777
Epoch 494  Train loss: -2.4320396385940852  Val loss: -2.740476654157606
Epoch 495
-------------------------------
Batch 1/64 loss: -2.4891538619995117
Batch 2/64 loss: -2.4987101554870605
Batch 3/64 loss: -2.298295021057129
Batch 4/64 loss: -2.0546436309814453
Batch 5/64 loss: -2.211629867553711
Batch 6/64 loss: -2.369021415710449
Batch 7/64 loss: -1.9350967407226562
Batch 8/64 loss: -2.5281167030334473
Batch 9/64 loss: -2.224689483642578
Batch 10/64 loss: -2.377955913543701
Batch 11/64 loss: -2.473496437072754
Batch 12/64 loss: -2.3333945274353027
Batch 13/64 loss: -2.5364151000976562
Batch 14/64 loss: -2.513702869415283
Batch 15/64 loss: -2.1371212005615234
Batch 16/64 loss: -2.5327839851379395
Batch 17/64 loss: -2.288393974304199
Batch 18/64 loss: -2.348605155944824
Batch 19/64 loss: -2.333682060241699
Batch 20/64 loss: -2.3627943992614746
Batch 21/64 loss: -2.178546905517578
Batch 22/64 loss: -2.3964452743530273
Batch 23/64 loss: -2.420630931854248
Batch 24/64 loss: -2.243406295776367
Batch 25/64 loss: -2.209836959838867
Batch 26/64 loss: -2.327341079711914
Batch 27/64 loss: -2.3701858520507812
Batch 28/64 loss: -2.528496742248535
Batch 29/64 loss: -2.512369155883789
Batch 30/64 loss: -1.8040390014648438
Batch 31/64 loss: -2.240340232849121
Batch 32/64 loss: -2.201626777648926
Batch 33/64 loss: -2.3189773559570312
Batch 34/64 loss: -2.4040145874023438
Batch 35/64 loss: -2.6360974311828613
Batch 36/64 loss: -2.1838693618774414
Batch 37/64 loss: -2.394317150115967
Batch 38/64 loss: -1.6353073120117188
Batch 39/64 loss: -2.6213016510009766
Batch 40/64 loss: -2.263214111328125
Batch 41/64 loss: -2.367462158203125
Batch 42/64 loss: -2.463977813720703
Batch 43/64 loss: -2.215378761291504
Batch 44/64 loss: -2.1119117736816406
Batch 45/64 loss: -2.029677391052246
Batch 46/64 loss: -2.270981788635254
Batch 47/64 loss: -2.41180419921875
Batch 48/64 loss: -1.8575029373168945
Batch 49/64 loss: -2.506230354309082
Batch 50/64 loss: -2.5315942764282227
Batch 51/64 loss: -2.117608070373535
Batch 52/64 loss: -2.2878332138061523
Batch 53/64 loss: -2.2704687118530273
Batch 54/64 loss: -2.422896385192871
Batch 55/64 loss: -2.486088275909424
Batch 56/64 loss: -2.260777473449707
Batch 57/64 loss: -2.526482582092285
Batch 58/64 loss: -2.272934913635254
Batch 59/64 loss: -2.1486949920654297
Batch 60/64 loss: -2.3630971908569336
Batch 61/64 loss: -2.497372627258301
Batch 62/64 loss: -2.351564407348633
Batch 63/64 loss: -2.384826183319092
Batch 64/64 loss: -6.5286078453063965
Epoch 495  Train loss: -2.3653598280513988  Val loss: -2.366886873015833
Epoch 496
-------------------------------
Batch 1/64 loss: -2.2784719467163086
Batch 2/64 loss: -2.082958221435547
Batch 3/64 loss: -2.340641975402832
Batch 4/64 loss: -1.8032770156860352
Batch 5/64 loss: -2.2164440155029297
Batch 6/64 loss: -1.8826932907104492
Batch 7/64 loss: -2.204461097717285
Batch 8/64 loss: -1.9077425003051758
Batch 9/64 loss: -2.179441452026367
Batch 10/64 loss: -2.431490421295166
Batch 11/64 loss: -2.2149553298950195
Batch 12/64 loss: -2.25836181640625
Batch 13/64 loss: -2.2201108932495117
Batch 14/64 loss: -1.6817741394042969
Batch 15/64 loss: -2.317934036254883
Batch 16/64 loss: -2.363999366760254
Batch 17/64 loss: -2.204096794128418
Batch 18/64 loss: -2.2107343673706055
Batch 19/64 loss: -1.678762435913086
Batch 20/64 loss: -2.4513320922851562
Batch 21/64 loss: -2.155941963195801
Batch 22/64 loss: -2.434109687805176
Batch 23/64 loss: -2.3482866287231445
Batch 24/64 loss: -2.3028407096862793
Batch 25/64 loss: -2.386198043823242
Batch 26/64 loss: -2.4004721641540527
Batch 27/64 loss: -2.4296278953552246
Batch 28/64 loss: -2.290888786315918
Batch 29/64 loss: -2.5230159759521484
Batch 30/64 loss: -2.3560357093811035
Batch 31/64 loss: -2.3196163177490234
Batch 32/64 loss: -2.384341239929199
Batch 33/64 loss: -2.0201587677001953
Batch 34/64 loss: -2.1119699478149414
Batch 35/64 loss: -2.398308277130127
Batch 36/64 loss: -2.3921051025390625
Batch 37/64 loss: -2.37050199508667
Batch 38/64 loss: -2.1298465728759766
Batch 39/64 loss: -2.5102524757385254
Batch 40/64 loss: -2.112363815307617
Batch 41/64 loss: -1.6862821578979492
Batch 42/64 loss: -2.2723121643066406
Batch 43/64 loss: -2.206942558288574
Batch 44/64 loss: -2.256093978881836
Batch 45/64 loss: -2.304715156555176
Batch 46/64 loss: -2.415865898132324
Batch 47/64 loss: -2.407008171081543
Batch 48/64 loss: -2.2824325561523438
Batch 49/64 loss: -2.333134651184082
Batch 50/64 loss: -2.400261878967285
Batch 51/64 loss: -2.376154899597168
Batch 52/64 loss: -2.564319610595703
Batch 53/64 loss: -2.076571464538574
Batch 54/64 loss: -2.4362354278564453
Batch 55/64 loss: -2.237813949584961
Batch 56/64 loss: -2.2228708267211914
Batch 57/64 loss: -1.4505205154418945
Batch 58/64 loss: -1.763289451599121
Batch 59/64 loss: -2.3420114517211914
Batch 60/64 loss: -2.1978464126586914
Batch 61/64 loss: -2.376955032348633
Batch 62/64 loss: -1.9350948333740234
Batch 63/64 loss: -2.382868766784668
Batch 64/64 loss: -6.285287857055664
Epoch 496  Train loss: -2.2736962037927966  Val loss: -2.5264134095706483
Epoch 497
-------------------------------
Batch 1/64 loss: -1.8823862075805664
Batch 2/64 loss: -2.314605236053467
Batch 3/64 loss: -2.2787771224975586
Batch 4/64 loss: -2.367661476135254
Batch 5/64 loss: -2.2481422424316406
Batch 6/64 loss: -2.092679023742676
Batch 7/64 loss: -2.317913055419922
Batch 8/64 loss: -1.9005126953125
Batch 9/64 loss: -2.3002943992614746
Batch 10/64 loss: -2.150589942932129
Batch 11/64 loss: -2.2973709106445312
Batch 12/64 loss: -1.3127555847167969
Batch 13/64 loss: -1.543269157409668
Batch 14/64 loss: -2.514096260070801
Batch 15/64 loss: -2.3788928985595703
Batch 16/64 loss: -2.192873001098633
Batch 17/64 loss: -2.4175233840942383
Batch 18/64 loss: -2.127749443054199
Batch 19/64 loss: -2.2406044006347656
Batch 20/64 loss: -2.30946683883667
Batch 21/64 loss: -2.12213134765625
Batch 22/64 loss: -2.3520889282226562
Batch 23/64 loss: -2.2216806411743164
Batch 24/64 loss: -2.2219085693359375
Batch 25/64 loss: -2.1663341522216797
Batch 26/64 loss: -2.3694868087768555
Batch 27/64 loss: -2.2231874465942383
Batch 28/64 loss: -2.1524009704589844
Batch 29/64 loss: -2.241497039794922
Batch 30/64 loss: -2.246377944946289
Batch 31/64 loss: -2.2012405395507812
Batch 32/64 loss: -0.8648262023925781
Batch 33/64 loss: -2.2169408798217773
Batch 34/64 loss: -1.8503999710083008
Batch 35/64 loss: -2.013382911682129
Batch 36/64 loss: -2.187258720397949
Batch 37/64 loss: -2.10146427154541
Batch 38/64 loss: -2.3483195304870605
Batch 39/64 loss: -2.156844139099121
Batch 40/64 loss: -2.350710868835449
Batch 41/64 loss: -2.2795519828796387
Batch 42/64 loss: -2.2981858253479004
Batch 43/64 loss: -2.4249396324157715
Batch 44/64 loss: -1.9936800003051758
Batch 45/64 loss: -2.138174057006836
Batch 46/64 loss: -1.9083852767944336
Batch 47/64 loss: -2.1986913681030273
Batch 48/64 loss: -2.0759239196777344
Batch 49/64 loss: -2.122772216796875
Batch 50/64 loss: -2.245321273803711
Batch 51/64 loss: -2.1309375762939453
Batch 52/64 loss: -1.1235532760620117
Batch 53/64 loss: -2.2951817512512207
Batch 54/64 loss: -2.224686622619629
Batch 55/64 loss: -2.3012895584106445
Batch 56/64 loss: -2.243680000305176
Batch 57/64 loss: -2.2737064361572266
Batch 58/64 loss: -2.205456256866455
Batch 59/64 loss: -2.12685489654541
Batch 60/64 loss: -2.0816831588745117
Batch 61/64 loss: -1.924546241760254
Batch 62/64 loss: -1.9599018096923828
Batch 63/64 loss: -2.183042526245117
Batch 64/64 loss: -6.428267478942871
Epoch 497  Train loss: -2.186321434320188  Val loss: -2.5189072389373255
Epoch 498
-------------------------------
Batch 1/64 loss: -2.3797731399536133
Batch 2/64 loss: -2.0740623474121094
Batch 3/64 loss: -2.1972837448120117
Batch 4/64 loss: -1.8318538665771484
Batch 5/64 loss: -2.1405229568481445
Batch 6/64 loss: -2.192734718322754
Batch 7/64 loss: -2.253859519958496
Batch 8/64 loss: -2.139566421508789
Batch 9/64 loss: -1.971456527709961
Batch 10/64 loss: -2.3350396156311035
Batch 11/64 loss: -2.1867074966430664
Batch 12/64 loss: -2.2578353881835938
Batch 13/64 loss: -2.4765725135803223
Batch 14/64 loss: -2.364593505859375
Batch 15/64 loss: -2.3437814712524414
Batch 16/64 loss: -1.5329523086547852
Batch 17/64 loss: -1.8960046768188477
Batch 18/64 loss: -2.3968305587768555
Batch 19/64 loss: -2.161393165588379
Batch 20/64 loss: -2.173704147338867
Batch 21/64 loss: -2.3317079544067383
Batch 22/64 loss: -2.2533531188964844
Batch 23/64 loss: -2.385514736175537
Batch 24/64 loss: -2.1678457260131836
Batch 25/64 loss: -2.32279109954834
Batch 26/64 loss: -2.294651508331299
Batch 27/64 loss: -1.9747629165649414
Batch 28/64 loss: -2.047880172729492
Batch 29/64 loss: -2.2817554473876953
Batch 30/64 loss: -2.199979782104492
Batch 31/64 loss: -1.9311647415161133
Batch 32/64 loss: -2.2416725158691406
Batch 33/64 loss: -2.200063705444336
Batch 34/64 loss: -2.3129959106445312
Batch 35/64 loss: -2.3559489250183105
Batch 36/64 loss: -1.3882665634155273
Batch 37/64 loss: -2.3192296028137207
Batch 38/64 loss: -2.054755210876465
Batch 39/64 loss: -2.405041217803955
Batch 40/64 loss: -1.5994415283203125
Batch 41/64 loss: -1.7657804489135742
Batch 42/64 loss: -2.339287757873535
Batch 43/64 loss: -2.2287063598632812
Batch 44/64 loss: -2.4059929847717285
Batch 45/64 loss: -2.2126388549804688
Batch 46/64 loss: -2.255197525024414
Batch 47/64 loss: -2.129060745239258
Batch 48/64 loss: -2.381340980529785
Batch 49/64 loss: -2.3450684547424316
Batch 50/64 loss: -1.8140754699707031
Batch 51/64 loss: -2.3459315299987793
Batch 52/64 loss: -2.213040351867676
Batch 53/64 loss: -2.35897159576416
Batch 54/64 loss: -0.9949874877929688
Batch 55/64 loss: -2.3383517265319824
Batch 56/64 loss: -2.143916130065918
Batch 57/64 loss: -2.4561262130737305
Batch 58/64 loss: -2.1230220794677734
Batch 59/64 loss: -2.399728298187256
Batch 60/64 loss: -2.3048715591430664
Batch 61/64 loss: -2.3017873764038086
Batch 62/64 loss: -2.1011619567871094
Batch 63/64 loss: -1.9380836486816406
Batch 64/64 loss: -6.321467399597168
Epoch 498  Train loss: -2.2119777342852425  Val loss: -2.468607755051446
Epoch 499
-------------------------------
Batch 1/64 loss: -1.6934051513671875
Batch 2/64 loss: -2.405041217803955
Batch 3/64 loss: -2.3912081718444824
Batch 4/64 loss: -2.107086181640625
Batch 5/64 loss: -2.273761749267578
Batch 6/64 loss: -2.060941696166992
Batch 7/64 loss: -2.231058120727539
Batch 8/64 loss: -2.160917282104492
Batch 9/64 loss: -2.3086509704589844
Batch 10/64 loss: -2.0805530548095703
Batch 11/64 loss: -2.343308448791504
Batch 12/64 loss: -2.112330436706543
Batch 13/64 loss: -2.3624448776245117
Batch 14/64 loss: -2.386115074157715
Batch 15/64 loss: -1.5623979568481445
Batch 16/64 loss: -2.146181106567383
Batch 17/64 loss: -1.275599479675293
Batch 18/64 loss: -2.2836360931396484
Batch 19/64 loss: -2.2557592391967773
Batch 20/64 loss: -2.1062116622924805
Batch 21/64 loss: -2.4657344818115234
Batch 22/64 loss: -2.4589672088623047
Batch 23/64 loss: -2.341463088989258
Batch 24/64 loss: -2.3052892684936523
Batch 25/64 loss: -2.422057628631592
Batch 26/64 loss: -2.3026695251464844
Batch 27/64 loss: -2.4363622665405273
Batch 28/64 loss: -2.3075332641601562
Batch 29/64 loss: -2.3752269744873047
Batch 30/64 loss: -2.400484561920166
Batch 31/64 loss: -2.4146242141723633
Batch 32/64 loss: -2.297013282775879
Batch 33/64 loss: -2.4032630920410156
Batch 34/64 loss: -2.4277257919311523
Batch 35/64 loss: -2.4348602294921875
Batch 36/64 loss: -2.5749688148498535
Batch 37/64 loss: -2.346463203430176
Batch 38/64 loss: -2.0264244079589844
Batch 39/64 loss: -2.416048049926758
Batch 40/64 loss: -2.4532032012939453
Batch 41/64 loss: -2.221707344055176
Batch 42/64 loss: -2.376084327697754
Batch 43/64 loss: -2.126856803894043
Batch 44/64 loss: -2.5475211143493652
Batch 45/64 loss: -2.3695507049560547
Batch 46/64 loss: -2.2370967864990234
Batch 47/64 loss: -2.417937755584717
Batch 48/64 loss: -2.446582317352295
Batch 49/64 loss: -2.2124767303466797
Batch 50/64 loss: -2.3193254470825195
Batch 51/64 loss: -2.312760353088379
Batch 52/64 loss: -1.2810211181640625
Batch 53/64 loss: -2.1539955139160156
Batch 54/64 loss: -2.3092517852783203
Batch 55/64 loss: -2.3862037658691406
Batch 56/64 loss: -2.336620330810547
Batch 57/64 loss: -2.411109447479248
Batch 58/64 loss: -2.555344581604004
Batch 59/64 loss: -1.8191099166870117
Batch 60/64 loss: -2.289736747741699
Batch 61/64 loss: -2.3225107192993164
Batch 62/64 loss: -2.4281816482543945
Batch 63/64 loss: -2.458073139190674
Batch 64/64 loss: -6.615708827972412
Epoch 499  Train loss: -2.3130640086005716  Val loss: -2.7123215403343806
Epoch 500
-------------------------------
Batch 1/64 loss: -2.372926712036133
Batch 2/64 loss: -2.1052865982055664
Batch 3/64 loss: -2.506007671356201
Batch 4/64 loss: -2.3645520210266113
Batch 5/64 loss: -2.548224449157715
Batch 6/64 loss: -2.4097838401794434
Batch 7/64 loss: -1.2290210723876953
Batch 8/64 loss: -2.2272443771362305
Batch 9/64 loss: -2.17568302154541
Batch 10/64 loss: -2.3002090454101562
Batch 11/64 loss: -2.3767342567443848
Batch 12/64 loss: -2.2310523986816406
Batch 13/64 loss: -2.5385398864746094
Batch 14/64 loss: -2.588829517364502
Batch 15/64 loss: -2.438338279724121
Batch 16/64 loss: -2.3553199768066406
Batch 17/64 loss: -2.449028968811035
Batch 18/64 loss: -2.5146255493164062
Batch 19/64 loss: -1.9375019073486328
Batch 20/64 loss: -2.0987424850463867
Batch 21/64 loss: -2.02034854888916
Batch 22/64 loss: -2.3372879028320312
Batch 23/64 loss: -2.3382978439331055
Batch 24/64 loss: -2.4020352363586426
Batch 25/64 loss: -2.5375661849975586
Batch 26/64 loss: -2.6053762435913086
Batch 27/64 loss: -2.4932141304016113
Batch 28/64 loss: -2.2843894958496094
Batch 29/64 loss: -2.4288296699523926
Batch 30/64 loss: -2.494399070739746
Batch 31/64 loss: -2.359621047973633
Batch 32/64 loss: -2.3298964500427246
Batch 33/64 loss: -2.421748161315918
Batch 34/64 loss: -2.4808807373046875
Batch 35/64 loss: -2.4239730834960938
Batch 36/64 loss: -2.5497117042541504
Batch 37/64 loss: -2.0817785263061523
Batch 38/64 loss: -2.4511919021606445
Batch 39/64 loss: -2.431849479675293
Batch 40/64 loss: -2.3014841079711914
Batch 41/64 loss: -2.4689950942993164
Batch 42/64 loss: -2.3625640869140625
Batch 43/64 loss: -1.4494943618774414
Batch 44/64 loss: -2.170654296875
Batch 45/64 loss: -2.2469024658203125
Batch 46/64 loss: -2.1428632736206055
Batch 47/64 loss: -2.36733341217041
Batch 48/64 loss: -2.3051023483276367
Batch 49/64 loss: -1.7349824905395508
Batch 50/64 loss: -2.350736618041992
Batch 51/64 loss: -1.7437915802001953
Batch 52/64 loss: -2.374629497528076
Batch 53/64 loss: -2.373913288116455
Batch 54/64 loss: -2.3231382369995117
Batch 55/64 loss: -2.1609582901000977
Batch 56/64 loss: -2.337566375732422
Batch 57/64 loss: -2.33077335357666
Batch 58/64 loss: -2.3864059448242188
Batch 59/64 loss: -2.290726661682129
Batch 60/64 loss: -2.3905868530273438
Batch 61/64 loss: -2.329665184020996
Batch 62/64 loss: -2.1670236587524414
Batch 63/64 loss: -2.1410350799560547
Batch 64/64 loss: -6.149159908294678
Epoch 500  Train loss: -2.3388744148553586  Val loss: -2.5278014874540244
SLIC undersegmentation error: 0.12412920962199316
SLIC inter-cluster variation: 0.13904419774313004
SLIC number of superpixels: 21483
SLIC superpixels per image: 73.82474226804123
Model loaded
Test metrics:
-3.406249449425137 0.33616494845360817 22.9942073460926 tensor(0.2928, dtype=torch.float64) 0.7499886893181921 3.1962177080034384 22103
Inference time: 0.0033600985799048773 seconds
Relabeled undersegmentation error: 0.11492920962199309
Relabeled inter-cluster variation: 0.0706132252477928
Relabeled mean superpixels count: 242.76975945017182
Original mean superpixels count: 75.9553264604811
Done!
Job id: 488557
Job id: 492265
