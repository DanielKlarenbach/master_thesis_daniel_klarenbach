Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 0.496066689491272
Batch 2/64 loss: 0.41394758224487305
Batch 3/64 loss: 0.3952277898788452
Batch 4/64 loss: 0.39134615659713745
Batch 5/64 loss: 0.38736212253570557
Batch 6/64 loss: 0.3861576318740845
Batch 7/64 loss: 0.3844311833381653
Batch 8/64 loss: 0.38266217708587646
Batch 9/64 loss: 0.3831058740615845
Batch 10/64 loss: 0.3837357759475708
Batch 11/64 loss: 0.38187700510025024
Batch 12/64 loss: 0.3812004327774048
Batch 13/64 loss: 0.38129568099975586
Batch 14/64 loss: 0.3804306387901306
Batch 15/64 loss: 0.38057833909988403
Batch 16/64 loss: 0.38043212890625
Batch 17/64 loss: 0.37924516201019287
Batch 18/64 loss: 0.3810872435569763
Batch 19/64 loss: 0.3796205520629883
Batch 20/64 loss: 0.3781888484954834
Batch 21/64 loss: 0.3802632689476013
Batch 22/64 loss: 0.37983113527297974
Batch 23/64 loss: 0.37993085384368896
Batch 24/64 loss: 0.378670871257782
Batch 25/64 loss: 0.3797413110733032
Batch 26/64 loss: 0.37969017028808594
Batch 27/64 loss: 0.378595769405365
Batch 28/64 loss: 0.37909185886383057
Batch 29/64 loss: 0.3794161081314087
Batch 30/64 loss: 0.378179669380188
Batch 31/64 loss: 0.3788982629776001
Batch 32/64 loss: 0.37743890285491943
Batch 33/64 loss: 0.3794139623641968
Batch 34/64 loss: 0.3778423070907593
Batch 35/64 loss: 0.376675009727478
Batch 36/64 loss: 0.3776127099990845
Batch 37/64 loss: 0.37682998180389404
Batch 38/64 loss: 0.37670111656188965
Batch 39/64 loss: 0.37893736362457275
Batch 40/64 loss: 0.3781546354293823
Batch 41/64 loss: 0.37769925594329834
Batch 42/64 loss: 0.37745803594589233
Batch 43/64 loss: 0.37750905752182007
Batch 44/64 loss: 0.37509334087371826
Batch 45/64 loss: 0.37667179107666016
Batch 46/64 loss: 0.3767131567001343
Batch 47/64 loss: 0.3760911822319031
Batch 48/64 loss: 0.3764876127243042
Batch 49/64 loss: 0.3762083053588867
Batch 50/64 loss: 0.3767050504684448
Batch 51/64 loss: 0.3767542839050293
Batch 52/64 loss: 0.3754847049713135
Batch 53/64 loss: 0.375413179397583
Batch 54/64 loss: 0.375929057598114
Batch 55/64 loss: 0.3752610683441162
Batch 56/64 loss: 0.37580591440200806
Batch 57/64 loss: 0.37547069787979126
Batch 58/64 loss: 0.3755570650100708
Batch 59/64 loss: 0.37610334157943726
Batch 60/64 loss: 0.3755952715873718
Batch 61/64 loss: 0.37439388036727905
Batch 62/64 loss: 0.3752160668373108
Batch 63/64 loss: 0.3736221194267273
Batch 64/64 loss: 0.37506967782974243
Epoch 1  Train loss: 0.3813091761925641  Val loss: 0.37645278026148216
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 0.37441134452819824
Batch 2/64 loss: 0.37454211711883545
Batch 3/64 loss: 0.37440383434295654
Batch 4/64 loss: 0.37494325637817383
Batch 5/64 loss: 0.37488073110580444
Batch 6/64 loss: 0.37475693225860596
Batch 7/64 loss: 0.3730008006095886
Batch 8/64 loss: 0.3738403916358948
Batch 9/64 loss: 0.3759061098098755
Batch 10/64 loss: 0.3752779960632324
Batch 11/64 loss: 0.37486129999160767
Batch 12/64 loss: 0.3724946975708008
Batch 13/64 loss: 0.37273019552230835
Batch 14/64 loss: 0.37316733598709106
Batch 15/64 loss: 0.3729848861694336
Batch 16/64 loss: 0.3725159764289856
Batch 17/64 loss: 0.3725312352180481
Batch 18/64 loss: 0.37146806716918945
Batch 19/64 loss: 0.3728243112564087
Batch 20/64 loss: 0.3715471625328064
Batch 21/64 loss: 0.3727715015411377
Batch 22/64 loss: 0.37245070934295654
Batch 23/64 loss: 0.37313592433929443
Batch 24/64 loss: 0.3734673261642456
Batch 25/64 loss: 0.372794508934021
Batch 26/64 loss: 0.3724789619445801
Batch 27/64 loss: 0.3691842555999756
Batch 28/64 loss: 0.3724328875541687
Batch 29/64 loss: 0.37385761737823486
Batch 30/64 loss: 0.37093114852905273
Batch 31/64 loss: 0.37041693925857544
Batch 32/64 loss: 0.3704630136489868
Batch 33/64 loss: 0.37154269218444824
Batch 34/64 loss: 0.3693997859954834
Batch 35/64 loss: 0.3713095188140869
Batch 36/64 loss: 0.371825635433197
Batch 37/64 loss: 0.3718611001968384
Batch 38/64 loss: 0.36968016624450684
Batch 39/64 loss: 0.3716270923614502
Batch 40/64 loss: 0.36798059940338135
Batch 41/64 loss: 0.3723248839378357
Batch 42/64 loss: 0.3723616600036621
Batch 43/64 loss: 0.3700014352798462
Batch 44/64 loss: 0.37163716554641724
Batch 45/64 loss: 0.3740028142929077
Batch 46/64 loss: 0.3685770630836487
Batch 47/64 loss: 0.370643675327301
Batch 48/64 loss: 0.36738723516464233
Batch 49/64 loss: 0.3673907518386841
Batch 50/64 loss: 0.37013745307922363
Batch 51/64 loss: 0.3677006959915161
Batch 52/64 loss: 0.3718907833099365
Batch 53/64 loss: 0.3711918592453003
Batch 54/64 loss: 0.368180513381958
Batch 55/64 loss: 0.3673163652420044
Batch 56/64 loss: 0.36969679594039917
Batch 57/64 loss: 0.3680105209350586
Batch 58/64 loss: 0.3672751784324646
Batch 59/64 loss: 0.3671693205833435
Batch 60/64 loss: 0.3691740036010742
Batch 61/64 loss: 0.36883044242858887
Batch 62/64 loss: 0.36847352981567383
Batch 63/64 loss: 0.36710190773010254
Batch 64/64 loss: 0.3709571957588196
Epoch 2  Train loss: 0.37141010223650467  Val loss: 0.3706440565102698
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 0.37149715423583984
Batch 2/64 loss: 0.36823928356170654
Batch 3/64 loss: 0.367034912109375
Batch 4/64 loss: 0.3685067892074585
Batch 5/64 loss: 0.36715441942214966
Batch 6/64 loss: 0.36838334798812866
Batch 7/64 loss: 0.36898767948150635
Batch 8/64 loss: 0.36800479888916016
Batch 9/64 loss: 0.3682515621185303
Batch 10/64 loss: 0.3670716881752014
Batch 11/64 loss: 0.36841702461242676
Batch 12/64 loss: 0.36679649353027344
Batch 13/64 loss: 0.36692243814468384
Batch 14/64 loss: 0.3670262098312378
Batch 15/64 loss: 0.3683742880821228
Batch 16/64 loss: 0.3681771755218506
Batch 17/64 loss: 0.3666696548461914
Batch 18/64 loss: 0.369351863861084
Batch 19/64 loss: 0.36953407526016235
Batch 20/64 loss: 0.3663783073425293
Batch 21/64 loss: 0.3683295249938965
Batch 22/64 loss: 0.36756765842437744
Batch 23/64 loss: 0.36748194694519043
Batch 24/64 loss: 0.36884891986846924
Batch 25/64 loss: 0.3656883239746094
Batch 26/64 loss: 0.3661382794380188
Batch 27/64 loss: 0.36710190773010254
Batch 28/64 loss: 0.3662976622581482
Batch 29/64 loss: 0.3698121905326843
Batch 30/64 loss: 0.3663511276245117
Batch 31/64 loss: 0.36799442768096924
Batch 32/64 loss: 0.3674333691596985
Batch 33/64 loss: 0.3657846450805664
Batch 34/64 loss: 0.36643004417419434
Batch 35/64 loss: 0.3648742437362671
Batch 36/64 loss: 0.36348211765289307
Batch 37/64 loss: 0.36589497327804565
Batch 38/64 loss: 0.3673560619354248
Batch 39/64 loss: 0.3682304620742798
Batch 40/64 loss: 0.36602532863616943
Batch 41/64 loss: 0.3662848472595215
Batch 42/64 loss: 0.3635944128036499
Batch 43/64 loss: 0.3664752244949341
Batch 44/64 loss: 0.36656033992767334
Batch 45/64 loss: 0.36450278759002686
Batch 46/64 loss: 0.3643902540206909
Batch 47/64 loss: 0.3654704689979553
Batch 48/64 loss: 0.3635563254356384
Batch 49/64 loss: 0.36815619468688965
Batch 50/64 loss: 0.3639645576477051
Batch 51/64 loss: 0.3664959669113159
Batch 52/64 loss: 0.36586523056030273
Batch 53/64 loss: 0.3668963313102722
Batch 54/64 loss: 0.3646509647369385
Batch 55/64 loss: 0.36860793828964233
Batch 56/64 loss: 0.3653533458709717
Batch 57/64 loss: 0.3677786588668823
Batch 58/64 loss: 0.36610764265060425
Batch 59/64 loss: 0.36532294750213623
Batch 60/64 loss: 0.36579227447509766
Batch 61/64 loss: 0.36765527725219727
Batch 62/64 loss: 0.36787158250808716
Batch 63/64 loss: 0.36447542905807495
Batch 64/64 loss: 0.3661190867424011
Epoch 3  Train loss: 0.3668756188130846  Val loss: 0.36588967788670074
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 0.365959107875824
Batch 2/64 loss: 0.36566591262817383
Batch 3/64 loss: 0.36399924755096436
Batch 4/64 loss: 0.36492985486984253
Batch 5/64 loss: 0.36619728803634644
Batch 6/64 loss: 0.3652235269546509
Batch 7/64 loss: 0.36575067043304443
Batch 8/64 loss: 0.36462879180908203
Batch 9/64 loss: 0.3646039366722107
Batch 10/64 loss: 0.36503827571868896
Batch 11/64 loss: 0.3619983196258545
Batch 12/64 loss: 0.36326754093170166
Batch 13/64 loss: 0.36259496212005615
Batch 14/64 loss: 0.3638263940811157
Batch 15/64 loss: 0.3661162257194519
Batch 16/64 loss: 0.36479467153549194
Batch 17/64 loss: 0.3642376661300659
Batch 18/64 loss: 0.36614394187927246
Batch 19/64 loss: 0.36334800720214844
Batch 20/64 loss: 0.3607865571975708
Batch 21/64 loss: 0.36241281032562256
Batch 22/64 loss: 0.36665159463882446
Batch 23/64 loss: 0.3644513487815857
Batch 24/64 loss: 0.36105239391326904
Batch 25/64 loss: 0.3654494285583496
Batch 26/64 loss: 0.3635672330856323
Batch 27/64 loss: 0.3644953966140747
Batch 28/64 loss: 0.3624457120895386
Batch 29/64 loss: 0.364284873008728
Batch 30/64 loss: 0.36336541175842285
Batch 31/64 loss: 0.36587512493133545
Batch 32/64 loss: 0.36394596099853516
Batch 33/64 loss: 0.3618568778038025
Batch 34/64 loss: 0.3636515736579895
Batch 35/64 loss: 0.3638019561767578
Batch 36/64 loss: 0.3637683391571045
Batch 37/64 loss: 0.3637259006500244
Batch 38/64 loss: 0.3587524890899658
Batch 39/64 loss: 0.36108988523483276
Batch 40/64 loss: 0.36210745573043823
Batch 41/64 loss: 0.36345601081848145
Batch 42/64 loss: 0.36480557918548584
Batch 43/64 loss: 0.3650272488594055
Batch 44/64 loss: 0.36460596323013306
Batch 45/64 loss: 0.36271536350250244
Batch 46/64 loss: 0.36324894428253174
Batch 47/64 loss: 0.36428892612457275
Batch 48/64 loss: 0.36562323570251465
Batch 49/64 loss: 0.36374813318252563
Batch 50/64 loss: 0.36405062675476074
Batch 51/64 loss: 0.36227190494537354
Batch 52/64 loss: 0.36070871353149414
Batch 53/64 loss: 0.3627673387527466
Batch 54/64 loss: 0.3616299629211426
Batch 55/64 loss: 0.3647325038909912
Batch 56/64 loss: 0.36447930335998535
Batch 57/64 loss: 0.36150169372558594
Batch 58/64 loss: 0.3644113540649414
Batch 59/64 loss: 0.36175382137298584
Batch 60/64 loss: 0.3596915602684021
Batch 61/64 loss: 0.3633367419242859
Batch 62/64 loss: 0.3628656268119812
Batch 63/64 loss: 0.36117231845855713
Batch 64/64 loss: 0.3597511053085327
Epoch 4  Train loss: 0.3635853940365361  Val loss: 0.3618789931752837
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 0.36135101318359375
Batch 2/64 loss: 0.36085397005081177
Batch 3/64 loss: 0.3605678677558899
Batch 4/64 loss: 0.3605532646179199
Batch 5/64 loss: 0.3609919548034668
Batch 6/64 loss: 0.3641258478164673
Batch 7/64 loss: 0.3622058033943176
Batch 8/64 loss: 0.35902488231658936
Batch 9/64 loss: 0.3632619380950928
Batch 10/64 loss: 0.3609347343444824
Batch 11/64 loss: 0.3607073426246643
Batch 12/64 loss: 0.36123764514923096
Batch 13/64 loss: 0.36136937141418457
Batch 14/64 loss: 0.363789439201355
Batch 15/64 loss: 0.3619768023490906
Batch 16/64 loss: 0.3612130880355835
Batch 17/64 loss: 0.3615637421607971
Batch 18/64 loss: 0.36002910137176514
Batch 19/64 loss: 0.35855376720428467
Batch 20/64 loss: 0.3608604073524475
Batch 21/64 loss: 0.36183393001556396
Batch 22/64 loss: 0.35705238580703735
Batch 23/64 loss: 0.35932302474975586
Batch 24/64 loss: 0.36028146743774414
Batch 25/64 loss: 0.3658904433250427
Batch 26/64 loss: 0.3583800792694092
Batch 27/64 loss: 0.3638686537742615
Batch 28/64 loss: 0.3662877082824707
Batch 29/64 loss: 0.3624569773674011
Batch 30/64 loss: 0.35885143280029297
Batch 31/64 loss: 0.363619327545166
Batch 32/64 loss: 0.3592982292175293
Batch 33/64 loss: 0.36090749502182007
Batch 34/64 loss: 0.3602834939956665
Batch 35/64 loss: 0.35941797494888306
Batch 36/64 loss: 0.36118537187576294
Batch 37/64 loss: 0.35798168182373047
Batch 38/64 loss: 0.36406266689300537
Batch 39/64 loss: 0.3605306148529053
Batch 40/64 loss: 0.36059486865997314
Batch 41/64 loss: 0.36104583740234375
Batch 42/64 loss: 0.3593742847442627
Batch 43/64 loss: 0.3581780195236206
Batch 44/64 loss: 0.3580204248428345
Batch 45/64 loss: 0.36205005645751953
Batch 46/64 loss: 0.36121666431427
Batch 47/64 loss: 0.3574700355529785
Batch 48/64 loss: 0.3589487075805664
Batch 49/64 loss: 0.36058199405670166
Batch 50/64 loss: 0.36000120639801025
Batch 51/64 loss: 0.36070144176483154
Batch 52/64 loss: 0.3604879379272461
Batch 53/64 loss: 0.36036109924316406
Batch 54/64 loss: 0.3621861934661865
Batch 55/64 loss: 0.3618309497833252
Batch 56/64 loss: 0.3605220317840576
Batch 57/64 loss: 0.36127209663391113
Batch 58/64 loss: 0.36181938648223877
Batch 59/64 loss: 0.36307477951049805
Batch 60/64 loss: 0.35944902896881104
Batch 61/64 loss: 0.3593980073928833
Batch 62/64 loss: 0.3597365617752075
Batch 63/64 loss: 0.3618462085723877
Batch 64/64 loss: 0.36585861444473267
Epoch 5  Train loss: 0.36096073295555864  Val loss: 0.3620704502584189
Epoch 6
-------------------------------
Batch 1/64 loss: 0.35950934886932373
Batch 2/64 loss: 0.3580549955368042
Batch 3/64 loss: 0.3581644296646118
Batch 4/64 loss: 0.36113810539245605
Batch 5/64 loss: 0.36113250255584717
Batch 6/64 loss: 0.35683906078338623
Batch 7/64 loss: 0.36065876483917236
Batch 8/64 loss: 0.36206352710723877
Batch 9/64 loss: 0.3572162389755249
Batch 10/64 loss: 0.35572242736816406
Batch 11/64 loss: 0.35926854610443115
Batch 12/64 loss: 0.35835379362106323
Batch 13/64 loss: 0.35680127143859863
Batch 14/64 loss: 0.3564295768737793
Batch 15/64 loss: 0.3587287664413452
Batch 16/64 loss: 0.35816776752471924
Batch 17/64 loss: 0.35804682970046997
Batch 18/64 loss: 0.35752618312835693
Batch 19/64 loss: 0.3595878481864929
Batch 20/64 loss: 0.35835951566696167
Batch 21/64 loss: 0.359971821308136
Batch 22/64 loss: 0.3615013360977173
Batch 23/64 loss: 0.3566276431083679
Batch 24/64 loss: 0.3597673177719116
Batch 25/64 loss: 0.3604912757873535
Batch 26/64 loss: 0.35517388582229614
Batch 27/64 loss: 0.35781627893447876
Batch 28/64 loss: 0.3599811792373657
Batch 29/64 loss: 0.35651296377182007
Batch 30/64 loss: 0.35825014114379883
Batch 31/64 loss: 0.3528887629508972
Batch 32/64 loss: 0.3571436405181885
Batch 33/64 loss: 0.3599565029144287
Batch 34/64 loss: 0.35766661167144775
Batch 35/64 loss: 0.3587932586669922
Batch 36/64 loss: 0.36184585094451904
Batch 37/64 loss: 0.3553939461708069
Batch 38/64 loss: 0.36021602153778076
Batch 39/64 loss: 0.3592195510864258
Batch 40/64 loss: 0.3565869927406311
Batch 41/64 loss: 0.3558248281478882
Batch 42/64 loss: 0.35786497592926025
Batch 43/64 loss: 0.3588801622390747
Batch 44/64 loss: 0.35721659660339355
Batch 45/64 loss: 0.3572908639907837
Batch 46/64 loss: 0.3617805242538452
Batch 47/64 loss: 0.3600066304206848
Batch 48/64 loss: 0.3562183380126953
Batch 49/64 loss: 0.3599163293838501
Batch 50/64 loss: 0.35600197315216064
Batch 51/64 loss: 0.3583880662918091
Batch 52/64 loss: 0.359139621257782
Batch 53/64 loss: 0.3593710660934448
Batch 54/64 loss: 0.3575791120529175
Batch 55/64 loss: 0.3587723970413208
Batch 56/64 loss: 0.3577522039413452
Batch 57/64 loss: 0.356386661529541
Batch 58/64 loss: 0.35789239406585693
Batch 59/64 loss: 0.36049747467041016
Batch 60/64 loss: 0.35758888721466064
Batch 61/64 loss: 0.3586918115615845
Batch 62/64 loss: 0.35712748765945435
Batch 63/64 loss: 0.3571469783782959
Batch 64/64 loss: 0.36112749576568604
Epoch 6  Train loss: 0.35836479196361465  Val loss: 0.3604904867939113
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.3581084609031677
Batch 2/64 loss: 0.3586927652359009
Batch 3/64 loss: 0.35836195945739746
Batch 4/64 loss: 0.3563862442970276
Batch 5/64 loss: 0.36097681522369385
Batch 6/64 loss: 0.3595951795578003
Batch 7/64 loss: 0.3561983108520508
Batch 8/64 loss: 0.35566437244415283
Batch 9/64 loss: 0.3574560880661011
Batch 10/64 loss: 0.354870080947876
Batch 11/64 loss: 0.35549795627593994
Batch 12/64 loss: 0.35961586236953735
Batch 13/64 loss: 0.3616707921028137
Batch 14/64 loss: 0.3606313467025757
Batch 15/64 loss: 0.35436874628067017
Batch 16/64 loss: 0.35581183433532715
Batch 17/64 loss: 0.3554207682609558
Batch 18/64 loss: 0.3571241497993469
Batch 19/64 loss: 0.3573680520057678
Batch 20/64 loss: 0.3616434335708618
Batch 21/64 loss: 0.3570009469985962
Batch 22/64 loss: 0.35837864875793457
Batch 23/64 loss: 0.36015141010284424
Batch 24/64 loss: 0.35644346475601196
Batch 25/64 loss: 0.3620666265487671
Batch 26/64 loss: 0.35705018043518066
Batch 27/64 loss: 0.3534677028656006
Batch 28/64 loss: 0.3584479093551636
Batch 29/64 loss: 0.3602501153945923
Batch 30/64 loss: 0.3572145700454712
Batch 31/64 loss: 0.3522617816925049
Batch 32/64 loss: 0.3576732873916626
Batch 33/64 loss: 0.35460174083709717
Batch 34/64 loss: 0.35667872428894043
Batch 35/64 loss: 0.35701847076416016
Batch 36/64 loss: 0.3604589104652405
Batch 37/64 loss: 0.35654348134994507
Batch 38/64 loss: 0.35615694522857666
Batch 39/64 loss: 0.3564925193786621
Batch 40/64 loss: 0.36040663719177246
Batch 41/64 loss: 0.3555009365081787
Batch 42/64 loss: 0.3528987169265747
Batch 43/64 loss: 0.35495442152023315
Batch 44/64 loss: 0.3519779443740845
Batch 45/64 loss: 0.35441887378692627
Batch 46/64 loss: 0.35589301586151123
Batch 47/64 loss: 0.3533508777618408
Batch 48/64 loss: 0.3530381917953491
Batch 49/64 loss: 0.3501158356666565
Batch 50/64 loss: 0.35501623153686523
Batch 51/64 loss: 0.35376453399658203
Batch 52/64 loss: 0.35670536756515503
Batch 53/64 loss: 0.3574131727218628
Batch 54/64 loss: 0.35415083169937134
Batch 55/64 loss: 0.35511231422424316
Batch 56/64 loss: 0.35543131828308105
Batch 57/64 loss: 0.3555741310119629
Batch 58/64 loss: 0.35354703664779663
Batch 59/64 loss: 0.3608388900756836
Batch 60/64 loss: 0.3577113747596741
Batch 61/64 loss: 0.35651957988739014
Batch 62/64 loss: 0.3570258617401123
Batch 63/64 loss: 0.35338473320007324
Batch 64/64 loss: 0.3498551845550537
Epoch 7  Train loss: 0.35656412349027744  Val loss: 0.35725648890655887
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 0.3518484830856323
Batch 2/64 loss: 0.35769081115722656
Batch 3/64 loss: 0.3595697283744812
Batch 4/64 loss: 0.35559409856796265
Batch 5/64 loss: 0.3546004891395569
Batch 6/64 loss: 0.35737109184265137
Batch 7/64 loss: 0.35622990131378174
Batch 8/64 loss: 0.3532130718231201
Batch 9/64 loss: 0.3559824228286743
Batch 10/64 loss: 0.35328423976898193
Batch 11/64 loss: 0.3550882339477539
Batch 12/64 loss: 0.35496389865875244
Batch 13/64 loss: 0.3592689037322998
Batch 14/64 loss: 0.3578551411628723
Batch 15/64 loss: 0.35631120204925537
Batch 16/64 loss: 0.36070793867111206
Batch 17/64 loss: 0.3543907403945923
Batch 18/64 loss: 0.3568204641342163
Batch 19/64 loss: 0.36071252822875977
Batch 20/64 loss: 0.3561508059501648
Batch 21/64 loss: 0.35410118103027344
Batch 22/64 loss: 0.3520582914352417
Batch 23/64 loss: 0.3561708927154541
Batch 24/64 loss: 0.36056017875671387
Batch 25/64 loss: 0.35481059551239014
Batch 26/64 loss: 0.3542485237121582
Batch 27/64 loss: 0.3555043935775757
Batch 28/64 loss: 0.3537602424621582
Batch 29/64 loss: 0.3598167896270752
Batch 30/64 loss: 0.35663771629333496
Batch 31/64 loss: 0.35674405097961426
Batch 32/64 loss: 0.3552529811859131
Batch 33/64 loss: 0.3538220524787903
Batch 34/64 loss: 0.35530245304107666
Batch 35/64 loss: 0.3569679260253906
Batch 36/64 loss: 0.3563864231109619
Batch 37/64 loss: 0.35310912132263184
Batch 38/64 loss: 0.3522151708602905
Batch 39/64 loss: 0.3541991710662842
Batch 40/64 loss: 0.3543146252632141
Batch 41/64 loss: 0.3548445701599121
Batch 42/64 loss: 0.3512760400772095
Batch 43/64 loss: 0.3562978506088257
Batch 44/64 loss: 0.35534119606018066
Batch 45/64 loss: 0.35888397693634033
Batch 46/64 loss: 0.35432952642440796
Batch 47/64 loss: 0.3534771800041199
Batch 48/64 loss: 0.3555307388305664
Batch 49/64 loss: 0.3537070155143738
Batch 50/64 loss: 0.35497206449508667
Batch 51/64 loss: 0.3539700508117676
Batch 52/64 loss: 0.3578396439552307
Batch 53/64 loss: 0.35373324155807495
Batch 54/64 loss: 0.3556746244430542
Batch 55/64 loss: 0.355424165725708
Batch 56/64 loss: 0.3517343997955322
Batch 57/64 loss: 0.355985164642334
Batch 58/64 loss: 0.35506629943847656
Batch 59/64 loss: 0.3532247543334961
Batch 60/64 loss: 0.35379117727279663
Batch 61/64 loss: 0.3551250100135803
Batch 62/64 loss: 0.35529786348342896
Batch 63/64 loss: 0.3536772131919861
Batch 64/64 loss: 0.35572177171707153
Epoch 8  Train loss: 0.3554452089702382  Val loss: 0.3571527553178191
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 0.3566718101501465
Batch 2/64 loss: 0.35518747568130493
Batch 3/64 loss: 0.3523818254470825
Batch 4/64 loss: 0.3532102108001709
Batch 5/64 loss: 0.3522636890411377
Batch 6/64 loss: 0.3558576703071594
Batch 7/64 loss: 0.3536757826805115
Batch 8/64 loss: 0.35741859674453735
Batch 9/64 loss: 0.3552159070968628
Batch 10/64 loss: 0.355646014213562
Batch 11/64 loss: 0.3546886444091797
Batch 12/64 loss: 0.3523191213607788
Batch 13/64 loss: 0.356525182723999
Batch 14/64 loss: 0.3584507703781128
Batch 15/64 loss: 0.35639435052871704
Batch 16/64 loss: 0.35409897565841675
Batch 17/64 loss: 0.35808783769607544
Batch 18/64 loss: 0.3578643798828125
Batch 19/64 loss: 0.3540497422218323
Batch 20/64 loss: 0.35621118545532227
Batch 21/64 loss: 0.35829126834869385
Batch 22/64 loss: 0.35581982135772705
Batch 23/64 loss: 0.3536418080329895
Batch 24/64 loss: 0.35047483444213867
Batch 25/64 loss: 0.3556727170944214
Batch 26/64 loss: 0.35455322265625
Batch 27/64 loss: 0.3494669198989868
Batch 28/64 loss: 0.35434865951538086
Batch 29/64 loss: 0.3519352674484253
Batch 30/64 loss: 0.3540618419647217
Batch 31/64 loss: 0.35467708110809326
Batch 32/64 loss: 0.351004958152771
Batch 33/64 loss: 0.3555765748023987
Batch 34/64 loss: 0.34853869676589966
Batch 35/64 loss: 0.3559476137161255
Batch 36/64 loss: 0.35147523880004883
Batch 37/64 loss: 0.35871565341949463
Batch 38/64 loss: 0.35887080430984497
Batch 39/64 loss: 0.35068202018737793
Batch 40/64 loss: 0.3607368469238281
Batch 41/64 loss: 0.3541306257247925
Batch 42/64 loss: 0.3568151593208313
Batch 43/64 loss: 0.35555487871170044
Batch 44/64 loss: 0.3553938865661621
Batch 45/64 loss: 0.3529829978942871
Batch 46/64 loss: 0.3526648283004761
Batch 47/64 loss: 0.35336410999298096
Batch 48/64 loss: 0.3512451648712158
Batch 49/64 loss: 0.3535943031311035
Batch 50/64 loss: 0.35688316822052
Batch 51/64 loss: 0.35311830043792725
Batch 52/64 loss: 0.3528863787651062
Batch 53/64 loss: 0.3487688899040222
Batch 54/64 loss: 0.3504674434661865
Batch 55/64 loss: 0.3559802174568176
Batch 56/64 loss: 0.3570942282676697
Batch 57/64 loss: 0.3547089099884033
Batch 58/64 loss: 0.35256123542785645
Batch 59/64 loss: 0.35333096981048584
Batch 60/64 loss: 0.35595351457595825
Batch 61/64 loss: 0.35191965103149414
Batch 62/64 loss: 0.35508811473846436
Batch 63/64 loss: 0.3536497950553894
Batch 64/64 loss: 0.35313987731933594
Epoch 9  Train loss: 0.3544113364874148  Val loss: 0.3561633751564419
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: 0.35274702310562134
Batch 2/64 loss: 0.3473705053329468
Batch 3/64 loss: 0.35684704780578613
Batch 4/64 loss: 0.3518025875091553
Batch 5/64 loss: 0.3562033772468567
Batch 6/64 loss: 0.3549332022666931
Batch 7/64 loss: 0.35199642181396484
Batch 8/64 loss: 0.359647274017334
Batch 9/64 loss: 0.351757287979126
Batch 10/64 loss: 0.3523745536804199
Batch 11/64 loss: 0.35273516178131104
Batch 12/64 loss: 0.3562076687812805
Batch 13/64 loss: 0.35320067405700684
Batch 14/64 loss: 0.35801446437835693
Batch 15/64 loss: 0.35373473167419434
Batch 16/64 loss: 0.35522568225860596
Batch 17/64 loss: 0.3524608612060547
Batch 18/64 loss: 0.3534088134765625
Batch 19/64 loss: 0.3570546507835388
Batch 20/64 loss: 0.3510127067565918
Batch 21/64 loss: 0.3510427474975586
Batch 22/64 loss: 0.3586069941520691
Batch 23/64 loss: 0.3537241220474243
Batch 24/64 loss: 0.35183095932006836
Batch 25/64 loss: 0.3538872003555298
Batch 26/64 loss: 0.35101139545440674
Batch 27/64 loss: 0.3530048131942749
Batch 28/64 loss: 0.35742008686065674
Batch 29/64 loss: 0.35397613048553467
Batch 30/64 loss: 0.3553420305252075
Batch 31/64 loss: 0.3567465543746948
Batch 32/64 loss: 0.35459399223327637
Batch 33/64 loss: 0.3540101647377014
Batch 34/64 loss: 0.3567999601364136
Batch 35/64 loss: 0.3537335991859436
Batch 36/64 loss: 0.35617971420288086
Batch 37/64 loss: 0.352569580078125
Batch 38/64 loss: 0.3548908233642578
Batch 39/64 loss: 0.3520231246948242
Batch 40/64 loss: 0.35598695278167725
Batch 41/64 loss: 0.3541756868362427
Batch 42/64 loss: 0.35174059867858887
Batch 43/64 loss: 0.35389041900634766
Batch 44/64 loss: 0.3502171039581299
Batch 45/64 loss: 0.3543059825897217
Batch 46/64 loss: 0.35260218381881714
Batch 47/64 loss: 0.3498910665512085
Batch 48/64 loss: 0.3521769642829895
Batch 49/64 loss: 0.3575636148452759
Batch 50/64 loss: 0.3544957637786865
Batch 51/64 loss: 0.3534674644470215
Batch 52/64 loss: 0.35827839374542236
Batch 53/64 loss: 0.356609582901001
Batch 54/64 loss: 0.3557094931602478
Batch 55/64 loss: 0.3514259457588196
Batch 56/64 loss: 0.3518061637878418
Batch 57/64 loss: 0.355016827583313
Batch 58/64 loss: 0.35379481315612793
Batch 59/64 loss: 0.3509564995765686
Batch 60/64 loss: 0.350574254989624
Batch 61/64 loss: 0.3513399362564087
Batch 62/64 loss: 0.3526473641395569
Batch 63/64 loss: 0.35250532627105713
Batch 64/64 loss: 0.3543776273727417
Epoch 10  Train loss: 0.3538367107802746  Val loss: 0.35751096960605216
Epoch 11
-------------------------------
Batch 1/64 loss: 0.3565146327018738
Batch 2/64 loss: 0.3510439395904541
Batch 3/64 loss: 0.35287725925445557
Batch 4/64 loss: 0.35136961936950684
Batch 5/64 loss: 0.35229945182800293
Batch 6/64 loss: 0.3528748154640198
Batch 7/64 loss: 0.35209596157073975
Batch 8/64 loss: 0.35838085412979126
Batch 9/64 loss: 0.3519185185432434
Batch 10/64 loss: 0.35398972034454346
Batch 11/64 loss: 0.3478738069534302
Batch 12/64 loss: 0.35235679149627686
Batch 13/64 loss: 0.35259509086608887
Batch 14/64 loss: 0.35262060165405273
Batch 15/64 loss: 0.3535752296447754
Batch 16/64 loss: 0.34994179010391235
Batch 17/64 loss: 0.354896605014801
Batch 18/64 loss: 0.35222071409225464
Batch 19/64 loss: 0.353396475315094
Batch 20/64 loss: 0.3510494828224182
Batch 21/64 loss: 0.3527129888534546
Batch 22/64 loss: 0.3543820381164551
Batch 23/64 loss: 0.34869223833084106
Batch 24/64 loss: 0.35259807109832764
Batch 25/64 loss: 0.35208046436309814
Batch 26/64 loss: 0.3492233157157898
Batch 27/64 loss: 0.3527989983558655
Batch 28/64 loss: 0.34934842586517334
Batch 29/64 loss: 0.343855082988739
Batch 30/64 loss: 0.3526226878166199
Batch 31/64 loss: 0.3558870553970337
Batch 32/64 loss: 0.35236674547195435
Batch 33/64 loss: 0.349876344203949
Batch 34/64 loss: 0.35049736499786377
Batch 35/64 loss: 0.35239899158477783
Batch 36/64 loss: 0.3507341146469116
Batch 37/64 loss: 0.3514050245285034
Batch 38/64 loss: 0.35217034816741943
Batch 39/64 loss: 0.35040199756622314
Batch 40/64 loss: 0.35166728496551514
Batch 41/64 loss: 0.3532688617706299
Batch 42/64 loss: 0.3537633419036865
Batch 43/64 loss: 0.34830987453460693
Batch 44/64 loss: 0.3530067205429077
Batch 45/64 loss: 0.3545033931732178
Batch 46/64 loss: 0.35133588314056396
Batch 47/64 loss: 0.35330259799957275
Batch 48/64 loss: 0.3525351285934448
Batch 49/64 loss: 0.3552740812301636
Batch 50/64 loss: 0.3495551347732544
Batch 51/64 loss: 0.3524121046066284
Batch 52/64 loss: 0.3554309606552124
Batch 53/64 loss: 0.3528512120246887
Batch 54/64 loss: 0.3545013666152954
Batch 55/64 loss: 0.3542003035545349
Batch 56/64 loss: 0.3513161540031433
Batch 57/64 loss: 0.35013604164123535
Batch 58/64 loss: 0.3529430627822876
Batch 59/64 loss: 0.35360270738601685
Batch 60/64 loss: 0.3457448482513428
Batch 61/64 loss: 0.34946316480636597
Batch 62/64 loss: 0.3525153398513794
Batch 63/64 loss: 0.35180675983428955
Batch 64/64 loss: 0.35354000329971313
Epoch 11  Train loss: 0.3521026665089177  Val loss: 0.35390437939732344
Saving best model, epoch: 11
Epoch 12
-------------------------------
Batch 1/64 loss: 0.35018420219421387
Batch 2/64 loss: 0.34970033168792725
Batch 3/64 loss: 0.3516439199447632
Batch 4/64 loss: 0.35190993547439575
Batch 5/64 loss: 0.34874773025512695
Batch 6/64 loss: 0.35154205560684204
Batch 7/64 loss: 0.35036933422088623
Batch 8/64 loss: 0.3524155020713806
Batch 9/64 loss: 0.34696102142333984
Batch 10/64 loss: 0.3503316044807434
Batch 11/64 loss: 0.35137975215911865
Batch 12/64 loss: 0.35152727365493774
Batch 13/64 loss: 0.35256659984588623
Batch 14/64 loss: 0.3496461510658264
Batch 15/64 loss: 0.3499915599822998
Batch 16/64 loss: 0.3525370955467224
Batch 17/64 loss: 0.3521687388420105
Batch 18/64 loss: 0.35195738077163696
Batch 19/64 loss: 0.35499393939971924
Batch 20/64 loss: 0.356059193611145
Batch 21/64 loss: 0.3491576910018921
Batch 22/64 loss: 0.3505730628967285
Batch 23/64 loss: 0.3513745069503784
Batch 24/64 loss: 0.35124659538269043
Batch 25/64 loss: 0.347520112991333
Batch 26/64 loss: 0.35323071479797363
Batch 27/64 loss: 0.35479289293289185
Batch 28/64 loss: 0.35243338346481323
Batch 29/64 loss: 0.3507099747657776
Batch 30/64 loss: 0.3509857654571533
Batch 31/64 loss: 0.35444313287734985
Batch 32/64 loss: 0.35169899463653564
Batch 33/64 loss: 0.35265082120895386
Batch 34/64 loss: 0.35400068759918213
Batch 35/64 loss: 0.3558166027069092
Batch 36/64 loss: 0.35570353269577026
Batch 37/64 loss: 0.35015302896499634
Batch 38/64 loss: 0.34678560495376587
Batch 39/64 loss: 0.3484460115432739
Batch 40/64 loss: 0.35206496715545654
Batch 41/64 loss: 0.3537425994873047
Batch 42/64 loss: 0.35344749689102173
Batch 43/64 loss: 0.35316789150238037
Batch 44/64 loss: 0.35586798191070557
Batch 45/64 loss: 0.347469687461853
Batch 46/64 loss: 0.3488374948501587
Batch 47/64 loss: 0.35351407527923584
Batch 48/64 loss: 0.3474388122558594
Batch 49/64 loss: 0.3481743335723877
Batch 50/64 loss: 0.35298728942871094
Batch 51/64 loss: 0.3522512912750244
Batch 52/64 loss: 0.35539865493774414
Batch 53/64 loss: 0.35235440731048584
Batch 54/64 loss: 0.35248708724975586
Batch 55/64 loss: 0.35410284996032715
Batch 56/64 loss: 0.3567761778831482
Batch 57/64 loss: 0.3513338565826416
Batch 58/64 loss: 0.3531273603439331
Batch 59/64 loss: 0.3531796932220459
Batch 60/64 loss: 0.3482423424720764
Batch 61/64 loss: 0.35012054443359375
Batch 62/64 loss: 0.3532944917678833
Batch 63/64 loss: 0.3517577052116394
Batch 64/64 loss: 0.3508909344673157
Epoch 12  Train loss: 0.35172805856255923  Val loss: 0.3534955640429074
Saving best model, epoch: 12
Epoch 13
-------------------------------
Batch 1/64 loss: 0.35286974906921387
Batch 2/64 loss: 0.35112833976745605
Batch 3/64 loss: 0.3530738949775696
Batch 4/64 loss: 0.34747248888015747
Batch 5/64 loss: 0.34953320026397705
Batch 6/64 loss: 0.34896576404571533
Batch 7/64 loss: 0.3520270586013794
Batch 8/64 loss: 0.3493313789367676
Batch 9/64 loss: 0.3498704433441162
Batch 10/64 loss: 0.3517385721206665
Batch 11/64 loss: 0.3525245785713196
Batch 12/64 loss: 0.3514382243156433
Batch 13/64 loss: 0.35550206899642944
Batch 14/64 loss: 0.35247403383255005
Batch 15/64 loss: 0.34970080852508545
Batch 16/64 loss: 0.3516160845756531
Batch 17/64 loss: 0.3528410792350769
Batch 18/64 loss: 0.35300445556640625
Batch 19/64 loss: 0.35129016637802124
Batch 20/64 loss: 0.3532625436782837
Batch 21/64 loss: 0.35388481616973877
Batch 22/64 loss: 0.3501138687133789
Batch 23/64 loss: 0.349642276763916
Batch 24/64 loss: 0.351287841796875
Batch 25/64 loss: 0.3489633798599243
Batch 26/64 loss: 0.34705299139022827
Batch 27/64 loss: 0.35052746534347534
Batch 28/64 loss: 0.35310637950897217
Batch 29/64 loss: 0.3521919250488281
Batch 30/64 loss: 0.3496120572090149
Batch 31/64 loss: 0.35310912132263184
Batch 32/64 loss: 0.3523496985435486
Batch 33/64 loss: 0.3469201326370239
Batch 34/64 loss: 0.35411226749420166
Batch 35/64 loss: 0.3483794927597046
Batch 36/64 loss: 0.35369443893432617
Batch 37/64 loss: 0.35265523195266724
Batch 38/64 loss: 0.35084545612335205
Batch 39/64 loss: 0.3523452877998352
Batch 40/64 loss: 0.35118454694747925
Batch 41/64 loss: 0.3492826223373413
Batch 42/64 loss: 0.34765541553497314
Batch 43/64 loss: 0.3508836030960083
Batch 44/64 loss: 0.3514893054962158
Batch 45/64 loss: 0.3540548086166382
Batch 46/64 loss: 0.34838879108428955
Batch 47/64 loss: 0.3493858575820923
Batch 48/64 loss: 0.3522722125053406
Batch 49/64 loss: 0.357671856880188
Batch 50/64 loss: 0.3494992256164551
Batch 51/64 loss: 0.34732651710510254
Batch 52/64 loss: 0.3496963381767273
Batch 53/64 loss: 0.35052865743637085
Batch 54/64 loss: 0.3484116792678833
Batch 55/64 loss: 0.35201048851013184
Batch 56/64 loss: 0.35337334871292114
Batch 57/64 loss: 0.34958499670028687
Batch 58/64 loss: 0.3514695167541504
Batch 59/64 loss: 0.3504912257194519
Batch 60/64 loss: 0.3491499423980713
Batch 61/64 loss: 0.34710800647735596
Batch 62/64 loss: 0.3487994074821472
Batch 63/64 loss: 0.35168731212615967
Batch 64/64 loss: 0.3513842821121216
Epoch 13  Train loss: 0.35098671305413337  Val loss: 0.35337470384807523
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: 0.35287296772003174
Batch 2/64 loss: 0.35163187980651855
Batch 3/64 loss: 0.3484652042388916
Batch 4/64 loss: 0.347653865814209
Batch 5/64 loss: 0.3471468687057495
Batch 6/64 loss: 0.35182225704193115
Batch 7/64 loss: 0.35123884677886963
Batch 8/64 loss: 0.3504486680030823
Batch 9/64 loss: 0.34529417753219604
Batch 10/64 loss: 0.34823840856552124
Batch 11/64 loss: 0.3534749746322632
Batch 12/64 loss: 0.3499366044998169
Batch 13/64 loss: 0.34622830152511597
Batch 14/64 loss: 0.3518911600112915
Batch 15/64 loss: 0.3517037630081177
Batch 16/64 loss: 0.34781479835510254
Batch 17/64 loss: 0.35108381509780884
Batch 18/64 loss: 0.35400259494781494
Batch 19/64 loss: 0.34715867042541504
Batch 20/64 loss: 0.3487509489059448
Batch 21/64 loss: 0.35046690702438354
Batch 22/64 loss: 0.34646475315093994
Batch 23/64 loss: 0.35015928745269775
Batch 24/64 loss: 0.35028505325317383
Batch 25/64 loss: 0.3506990671157837
Batch 26/64 loss: 0.34544265270233154
Batch 27/64 loss: 0.3493533730506897
Batch 28/64 loss: 0.3513491153717041
Batch 29/64 loss: 0.35003161430358887
Batch 30/64 loss: 0.3502836227416992
Batch 31/64 loss: 0.349995493888855
Batch 32/64 loss: 0.352189302444458
Batch 33/64 loss: 0.34891122579574585
Batch 34/64 loss: 0.346088707447052
Batch 35/64 loss: 0.354620099067688
Batch 36/64 loss: 0.3541354537010193
Batch 37/64 loss: 0.35530638694763184
Batch 38/64 loss: 0.34655678272247314
Batch 39/64 loss: 0.3491232395172119
Batch 40/64 loss: 0.351143479347229
Batch 41/64 loss: 0.3467838168144226
Batch 42/64 loss: 0.3514195680618286
Batch 43/64 loss: 0.34899652004241943
Batch 44/64 loss: 0.3458346128463745
Batch 45/64 loss: 0.3495534658432007
Batch 46/64 loss: 0.3516174554824829
Batch 47/64 loss: 0.3495181202888489
Batch 48/64 loss: 0.3525933027267456
Batch 49/64 loss: 0.35243988037109375
Batch 50/64 loss: 0.35463404655456543
Batch 51/64 loss: 0.3495175838470459
Batch 52/64 loss: 0.3488253355026245
Batch 53/64 loss: 0.3511660099029541
Batch 54/64 loss: 0.3488476872444153
Batch 55/64 loss: 0.35316890478134155
Batch 56/64 loss: 0.3524583578109741
Batch 57/64 loss: 0.3467165231704712
Batch 58/64 loss: 0.352094829082489
Batch 59/64 loss: 0.3536243438720703
Batch 60/64 loss: 0.34774112701416016
Batch 61/64 loss: 0.3513906002044678
Batch 62/64 loss: 0.35534441471099854
Batch 63/64 loss: 0.3482089042663574
Batch 64/64 loss: 0.34979331493377686
Epoch 14  Train loss: 0.35018517316556447  Val loss: 0.35155378010674443
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: 0.3489629030227661
Batch 2/64 loss: 0.3503406047821045
Batch 3/64 loss: 0.3459141254425049
Batch 4/64 loss: 0.3529386520385742
Batch 5/64 loss: 0.3464984893798828
Batch 6/64 loss: 0.3515983819961548
Batch 7/64 loss: 0.3478577136993408
Batch 8/64 loss: 0.3512547016143799
Batch 9/64 loss: 0.35407811403274536
Batch 10/64 loss: 0.3527141213417053
Batch 11/64 loss: 0.3506889343261719
Batch 12/64 loss: 0.3472058176994324
Batch 13/64 loss: 0.3436306118965149
Batch 14/64 loss: 0.3481864333152771
Batch 15/64 loss: 0.34876537322998047
Batch 16/64 loss: 0.35179346799850464
Batch 17/64 loss: 0.3502451181411743
Batch 18/64 loss: 0.3423830270767212
Batch 19/64 loss: 0.34802722930908203
Batch 20/64 loss: 0.3476337790489197
Batch 21/64 loss: 0.3484557271003723
Batch 22/64 loss: 0.35030603408813477
Batch 23/64 loss: 0.3487192988395691
Batch 24/64 loss: 0.34943222999572754
Batch 25/64 loss: 0.34496378898620605
Batch 26/64 loss: 0.3519064784049988
Batch 27/64 loss: 0.3500913977622986
Batch 28/64 loss: 0.35420358180999756
Batch 29/64 loss: 0.34794169664382935
Batch 30/64 loss: 0.34950268268585205
Batch 31/64 loss: 0.34302496910095215
Batch 32/64 loss: 0.3515998125076294
Batch 33/64 loss: 0.34972578287124634
Batch 34/64 loss: 0.3524514436721802
Batch 35/64 loss: 0.35042983293533325
Batch 36/64 loss: 0.34746021032333374
Batch 37/64 loss: 0.35199475288391113
Batch 38/64 loss: 0.3501781225204468
Batch 39/64 loss: 0.3468538522720337
Batch 40/64 loss: 0.3506277799606323
Batch 41/64 loss: 0.34544360637664795
Batch 42/64 loss: 0.34647178649902344
Batch 43/64 loss: 0.3511189818382263
Batch 44/64 loss: 0.3473550081253052
Batch 45/64 loss: 0.35282254219055176
Batch 46/64 loss: 0.3512614965438843
Batch 47/64 loss: 0.3502211570739746
Batch 48/64 loss: 0.35189253091812134
Batch 49/64 loss: 0.34879398345947266
Batch 50/64 loss: 0.3511759638786316
Batch 51/64 loss: 0.35135531425476074
Batch 52/64 loss: 0.3453589677810669
Batch 53/64 loss: 0.3523746132850647
Batch 54/64 loss: 0.34850549697875977
Batch 55/64 loss: 0.35057854652404785
Batch 56/64 loss: 0.34921127557754517
Batch 57/64 loss: 0.3499223589897156
Batch 58/64 loss: 0.34718847274780273
Batch 59/64 loss: 0.35091888904571533
Batch 60/64 loss: 0.34744811058044434
Batch 61/64 loss: 0.35065168142318726
Batch 62/64 loss: 0.3481447696685791
Batch 63/64 loss: 0.34993910789489746
Batch 64/64 loss: 0.35197341442108154
Epoch 15  Train loss: 0.3493760281918096  Val loss: 0.3532505961218241
Epoch 16
-------------------------------
Batch 1/64 loss: 0.3497805595397949
Batch 2/64 loss: 0.34760582447052
Batch 3/64 loss: 0.3486936688423157
Batch 4/64 loss: 0.3471568822860718
Batch 5/64 loss: 0.3479987382888794
Batch 6/64 loss: 0.3504689931869507
Batch 7/64 loss: 0.35386621952056885
Batch 8/64 loss: 0.3523123264312744
Batch 9/64 loss: 0.3526872396469116
Batch 10/64 loss: 0.3489307165145874
Batch 11/64 loss: 0.3523982763290405
Batch 12/64 loss: 0.35019075870513916
Batch 13/64 loss: 0.3550776243209839
Batch 14/64 loss: 0.34970623254776
Batch 15/64 loss: 0.35085803270339966
Batch 16/64 loss: 0.35043609142303467
Batch 17/64 loss: 0.349878191947937
Batch 18/64 loss: 0.35188156366348267
Batch 19/64 loss: 0.34951984882354736
Batch 20/64 loss: 0.35130560398101807
Batch 21/64 loss: 0.350705623626709
Batch 22/64 loss: 0.34849828481674194
Batch 23/64 loss: 0.35149770975112915
Batch 24/64 loss: 0.3493441343307495
Batch 25/64 loss: 0.3478599190711975
Batch 26/64 loss: 0.34850287437438965
Batch 27/64 loss: 0.34966617822647095
Batch 28/64 loss: 0.3509973883628845
Batch 29/64 loss: 0.3462643027305603
Batch 30/64 loss: 0.3483099937438965
Batch 31/64 loss: 0.3506973385810852
Batch 32/64 loss: 0.3486669659614563
Batch 33/64 loss: 0.3515546917915344
Batch 34/64 loss: 0.3501631021499634
Batch 35/64 loss: 0.3480456471443176
Batch 36/64 loss: 0.35218364000320435
Batch 37/64 loss: 0.3486671447753906
Batch 38/64 loss: 0.34612226486206055
Batch 39/64 loss: 0.35192030668258667
Batch 40/64 loss: 0.34985315799713135
Batch 41/64 loss: 0.35137712955474854
Batch 42/64 loss: 0.35020172595977783
Batch 43/64 loss: 0.349554181098938
Batch 44/64 loss: 0.3481595516204834
Batch 45/64 loss: 0.349977970123291
Batch 46/64 loss: 0.34772706031799316
Batch 47/64 loss: 0.35236048698425293
Batch 48/64 loss: 0.3498484492301941
Batch 49/64 loss: 0.3513224124908447
Batch 50/64 loss: 0.35243767499923706
Batch 51/64 loss: 0.34688740968704224
Batch 52/64 loss: 0.34803539514541626
Batch 53/64 loss: 0.3513360023498535
Batch 54/64 loss: 0.349121630191803
Batch 55/64 loss: 0.34281420707702637
Batch 56/64 loss: 0.34663963317871094
Batch 57/64 loss: 0.3473125100135803
Batch 58/64 loss: 0.34687483310699463
Batch 59/64 loss: 0.34923654794692993
Batch 60/64 loss: 0.3524254560470581
Batch 61/64 loss: 0.34358352422714233
Batch 62/64 loss: 0.3531533479690552
Batch 63/64 loss: 0.3471047282218933
Batch 64/64 loss: 0.34818148612976074
Epoch 16  Train loss: 0.349629835988961  Val loss: 0.35198813533455237
Epoch 17
-------------------------------
Batch 1/64 loss: 0.34701067209243774
Batch 2/64 loss: 0.35187387466430664
Batch 3/64 loss: 0.35025179386138916
Batch 4/64 loss: 0.3472520709037781
Batch 5/64 loss: 0.34876900911331177
Batch 6/64 loss: 0.34949934482574463
Batch 7/64 loss: 0.34913384914398193
Batch 8/64 loss: 0.34763777256011963
Batch 9/64 loss: 0.35070663690567017
Batch 10/64 loss: 0.34939515590667725
Batch 11/64 loss: 0.34480059146881104
Batch 12/64 loss: 0.3478934168815613
Batch 13/64 loss: 0.346774160861969
Batch 14/64 loss: 0.35001009702682495
Batch 15/64 loss: 0.35098791122436523
Batch 16/64 loss: 0.34957289695739746
Batch 17/64 loss: 0.3476993441581726
Batch 18/64 loss: 0.3506154417991638
Batch 19/64 loss: 0.350443959236145
Batch 20/64 loss: 0.34881675243377686
Batch 21/64 loss: 0.3498936891555786
Batch 22/64 loss: 0.35008394718170166
Batch 23/64 loss: 0.3492387533187866
Batch 24/64 loss: 0.34435683488845825
Batch 25/64 loss: 0.3487851023674011
Batch 26/64 loss: 0.34818387031555176
Batch 27/64 loss: 0.34982532262802124
Batch 28/64 loss: 0.35101622343063354
Batch 29/64 loss: 0.34641599655151367
Batch 30/64 loss: 0.3482933044433594
Batch 31/64 loss: 0.345477819442749
Batch 32/64 loss: 0.347334623336792
Batch 33/64 loss: 0.3475513458251953
Batch 34/64 loss: 0.3492218255996704
Batch 35/64 loss: 0.3463671803474426
Batch 36/64 loss: 0.3487550616264343
Batch 37/64 loss: 0.3513723611831665
Batch 38/64 loss: 0.3445603847503662
Batch 39/64 loss: 0.3526954650878906
Batch 40/64 loss: 0.3465227484703064
Batch 41/64 loss: 0.34907758235931396
Batch 42/64 loss: 0.3511708378791809
Batch 43/64 loss: 0.3507142663002014
Batch 44/64 loss: 0.3490592837333679
Batch 45/64 loss: 0.34667831659317017
Batch 46/64 loss: 0.3500325679779053
Batch 47/64 loss: 0.3455392122268677
Batch 48/64 loss: 0.349107027053833
Batch 49/64 loss: 0.3447420597076416
Batch 50/64 loss: 0.3503607511520386
Batch 51/64 loss: 0.34621256589889526
Batch 52/64 loss: 0.3536684513092041
Batch 53/64 loss: 0.34883058071136475
Batch 54/64 loss: 0.34521400928497314
Batch 55/64 loss: 0.34647125005722046
Batch 56/64 loss: 0.34922105073928833
Batch 57/64 loss: 0.34960633516311646
Batch 58/64 loss: 0.34861379861831665
Batch 59/64 loss: 0.35085785388946533
Batch 60/64 loss: 0.3504006266593933
Batch 61/64 loss: 0.3460197448730469
Batch 62/64 loss: 0.3442652225494385
Batch 63/64 loss: 0.3523479700088501
Batch 64/64 loss: 0.35156476497650146
Epoch 17  Train loss: 0.34865853412478576  Val loss: 0.3497533771590269
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: 0.3454601764678955
Batch 2/64 loss: 0.3460594415664673
Batch 3/64 loss: 0.3467063307762146
Batch 4/64 loss: 0.35114240646362305
Batch 5/64 loss: 0.3495427966117859
Batch 6/64 loss: 0.3448629379272461
Batch 7/64 loss: 0.35048580169677734
Batch 8/64 loss: 0.34926313161849976
Batch 9/64 loss: 0.34647077322006226
Batch 10/64 loss: 0.35123950242996216
Batch 11/64 loss: 0.34659671783447266
Batch 12/64 loss: 0.3475301265716553
Batch 13/64 loss: 0.34458041191101074
Batch 14/64 loss: 0.3516358733177185
Batch 15/64 loss: 0.34855979681015015
Batch 16/64 loss: 0.3450666666030884
Batch 17/64 loss: 0.3447028398513794
Batch 18/64 loss: 0.3465099334716797
Batch 19/64 loss: 0.3459380865097046
Batch 20/64 loss: 0.3435327410697937
Batch 21/64 loss: 0.34451454877853394
Batch 22/64 loss: 0.3450963497161865
Batch 23/64 loss: 0.3460645079612732
Batch 24/64 loss: 0.34969139099121094
Batch 25/64 loss: 0.3454611301422119
Batch 26/64 loss: 0.34954214096069336
Batch 27/64 loss: 0.3419080972671509
Batch 28/64 loss: 0.34937548637390137
Batch 29/64 loss: 0.34287023544311523
Batch 30/64 loss: 0.3467547297477722
Batch 31/64 loss: 0.34880876541137695
Batch 32/64 loss: 0.3481861352920532
Batch 33/64 loss: 0.34980517625808716
Batch 34/64 loss: 0.3499096632003784
Batch 35/64 loss: 0.3503448963165283
Batch 36/64 loss: 0.3486241102218628
Batch 37/64 loss: 0.34817636013031006
Batch 38/64 loss: 0.3481396436691284
Batch 39/64 loss: 0.34835708141326904
Batch 40/64 loss: 0.3462545871734619
Batch 41/64 loss: 0.3511711359024048
Batch 42/64 loss: 0.3507659435272217
Batch 43/64 loss: 0.3461088538169861
Batch 44/64 loss: 0.34802085161209106
Batch 45/64 loss: 0.34602946043014526
Batch 46/64 loss: 0.34881794452667236
Batch 47/64 loss: 0.3487604856491089
Batch 48/64 loss: 0.3477534055709839
Batch 49/64 loss: 0.34605133533477783
Batch 50/64 loss: 0.3500479459762573
Batch 51/64 loss: 0.3482104539871216
Batch 52/64 loss: 0.3475698232650757
Batch 53/64 loss: 0.35111016035079956
Batch 54/64 loss: 0.3472195863723755
Batch 55/64 loss: 0.34647172689437866
Batch 56/64 loss: 0.3424414396286011
Batch 57/64 loss: 0.3486102819442749
Batch 58/64 loss: 0.344529390335083
Batch 59/64 loss: 0.34894853830337524
Batch 60/64 loss: 0.35126549005508423
Batch 61/64 loss: 0.35037654638290405
Batch 62/64 loss: 0.3505192995071411
Batch 63/64 loss: 0.34596091508865356
Batch 64/64 loss: 0.34727293252944946
Epoch 18  Train loss: 0.3476233293028439  Val loss: 0.35005690531222683
Epoch 19
-------------------------------
Batch 1/64 loss: 0.345426082611084
Batch 2/64 loss: 0.34618330001831055
Batch 3/64 loss: 0.3474324941635132
Batch 4/64 loss: 0.35052669048309326
Batch 5/64 loss: 0.34452587366104126
Batch 6/64 loss: 0.344399094581604
Batch 7/64 loss: 0.34415102005004883
Batch 8/64 loss: 0.3507261872291565
Batch 9/64 loss: 0.34938764572143555
Batch 10/64 loss: 0.3450623154640198
Batch 11/64 loss: 0.35212117433547974
Batch 12/64 loss: 0.3471295237541199
Batch 13/64 loss: 0.34250009059906006
Batch 14/64 loss: 0.3499860167503357
Batch 15/64 loss: 0.35097622871398926
Batch 16/64 loss: 0.34664082527160645
Batch 17/64 loss: 0.3454703092575073
Batch 18/64 loss: 0.3480566740036011
Batch 19/64 loss: 0.34429705142974854
Batch 20/64 loss: 0.34822016954421997
Batch 21/64 loss: 0.3486529588699341
Batch 22/64 loss: 0.3478946089744568
Batch 23/64 loss: 0.34802114963531494
Batch 24/64 loss: 0.34859198331832886
Batch 25/64 loss: 0.34761810302734375
Batch 26/64 loss: 0.35287290811538696
Batch 27/64 loss: 0.3439286947250366
Batch 28/64 loss: 0.34490084648132324
Batch 29/64 loss: 0.35203951597213745
Batch 30/64 loss: 0.34535670280456543
Batch 31/64 loss: 0.34965741634368896
Batch 32/64 loss: 0.35122495889663696
Batch 33/64 loss: 0.3504018783569336
Batch 34/64 loss: 0.3480304479598999
Batch 35/64 loss: 0.34938299655914307
Batch 36/64 loss: 0.34905266761779785
Batch 37/64 loss: 0.3495032787322998
Batch 38/64 loss: 0.3480573892593384
Batch 39/64 loss: 0.34405219554901123
Batch 40/64 loss: 0.3471027612686157
Batch 41/64 loss: 0.35033702850341797
Batch 42/64 loss: 0.34409183263778687
Batch 43/64 loss: 0.3493293523788452
Batch 44/64 loss: 0.34568357467651367
Batch 45/64 loss: 0.34317588806152344
Batch 46/64 loss: 0.3475459814071655
Batch 47/64 loss: 0.3454101085662842
Batch 48/64 loss: 0.3484140634536743
Batch 49/64 loss: 0.3489505648612976
Batch 50/64 loss: 0.35256022214889526
Batch 51/64 loss: 0.3479902744293213
Batch 52/64 loss: 0.3422911763191223
Batch 53/64 loss: 0.34499120712280273
Batch 54/64 loss: 0.344246506690979
Batch 55/64 loss: 0.347547709941864
Batch 56/64 loss: 0.34588468074798584
Batch 57/64 loss: 0.340440034866333
Batch 58/64 loss: 0.3438154458999634
Batch 59/64 loss: 0.35022449493408203
Batch 60/64 loss: 0.3484199047088623
Batch 61/64 loss: 0.3487182855606079
Batch 62/64 loss: 0.34545278549194336
Batch 63/64 loss: 0.3488694429397583
Batch 64/64 loss: 0.34947389364242554
Epoch 19  Train loss: 0.347389148497114  Val loss: 0.34932875203103136
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 0.35134994983673096
Batch 2/64 loss: 0.34683406352996826
Batch 3/64 loss: 0.34433937072753906
Batch 4/64 loss: 0.34583693742752075
Batch 5/64 loss: 0.34410417079925537
Batch 6/64 loss: 0.34412622451782227
Batch 7/64 loss: 0.34498870372772217
Batch 8/64 loss: 0.34594106674194336
Batch 9/64 loss: 0.3420180082321167
Batch 10/64 loss: 0.34631508588790894
Batch 11/64 loss: 0.3498579263687134
Batch 12/64 loss: 0.3483138680458069
Batch 13/64 loss: 0.34701859951019287
Batch 14/64 loss: 0.34515076875686646
Batch 15/64 loss: 0.34971392154693604
Batch 16/64 loss: 0.34666872024536133
Batch 17/64 loss: 0.3477433919906616
Batch 18/64 loss: 0.34635770320892334
Batch 19/64 loss: 0.34822720289230347
Batch 20/64 loss: 0.34633302688598633
Batch 21/64 loss: 0.34535300731658936
Batch 22/64 loss: 0.34401988983154297
Batch 23/64 loss: 0.3454747796058655
Batch 24/64 loss: 0.35242223739624023
Batch 25/64 loss: 0.3494913578033447
Batch 26/64 loss: 0.34291279315948486
Batch 27/64 loss: 0.3530536890029907
Batch 28/64 loss: 0.3488295078277588
Batch 29/64 loss: 0.3481353521347046
Batch 30/64 loss: 0.34776198863983154
Batch 31/64 loss: 0.3477116823196411
Batch 32/64 loss: 0.3506130576133728
Batch 33/64 loss: 0.3457358479499817
Batch 34/64 loss: 0.34877872467041016
Batch 35/64 loss: 0.3451499938964844
Batch 36/64 loss: 0.34176385402679443
Batch 37/64 loss: 0.34664905071258545
Batch 38/64 loss: 0.34552693367004395
Batch 39/64 loss: 0.3439595699310303
Batch 40/64 loss: 0.34888720512390137
Batch 41/64 loss: 0.35348349809646606
Batch 42/64 loss: 0.34570151567459106
Batch 43/64 loss: 0.34353113174438477
Batch 44/64 loss: 0.34432268142700195
Batch 45/64 loss: 0.34968745708465576
Batch 46/64 loss: 0.34743958711624146
Batch 47/64 loss: 0.34712255001068115
Batch 48/64 loss: 0.3460325598716736
Batch 49/64 loss: 0.343669056892395
Batch 50/64 loss: 0.34656572341918945
Batch 51/64 loss: 0.3420366644859314
Batch 52/64 loss: 0.3493555784225464
Batch 53/64 loss: 0.3458141088485718
Batch 54/64 loss: 0.34954583644866943
Batch 55/64 loss: 0.3477158546447754
Batch 56/64 loss: 0.34835320711135864
Batch 57/64 loss: 0.34499865770339966
Batch 58/64 loss: 0.3475501537322998
Batch 59/64 loss: 0.3441281318664551
Batch 60/64 loss: 0.3456364870071411
Batch 61/64 loss: 0.3453878164291382
Batch 62/64 loss: 0.3474613428115845
Batch 63/64 loss: 0.3497017025947571
Batch 64/64 loss: 0.34705018997192383
Epoch 20  Train loss: 0.346807814579384  Val loss: 0.3505529118157744
Epoch 21
-------------------------------
Batch 1/64 loss: 0.3503459095954895
Batch 2/64 loss: 0.34792137145996094
Batch 3/64 loss: 0.3492470979690552
Batch 4/64 loss: 0.3477064371109009
Batch 5/64 loss: 0.3499707579612732
Batch 6/64 loss: 0.34640979766845703
Batch 7/64 loss: 0.3505823612213135
Batch 8/64 loss: 0.3471071720123291
Batch 9/64 loss: 0.3447960615158081
Batch 10/64 loss: 0.3519256114959717
Batch 11/64 loss: 0.34701859951019287
Batch 12/64 loss: 0.34486979246139526
Batch 13/64 loss: 0.3455612063407898
Batch 14/64 loss: 0.3501688241958618
Batch 15/64 loss: 0.34715819358825684
Batch 16/64 loss: 0.34673619270324707
Batch 17/64 loss: 0.34455811977386475
Batch 18/64 loss: 0.34455037117004395
Batch 19/64 loss: 0.34192752838134766
Batch 20/64 loss: 0.3442389965057373
Batch 21/64 loss: 0.3513270616531372
Batch 22/64 loss: 0.3490716218948364
Batch 23/64 loss: 0.3509998917579651
Batch 24/64 loss: 0.34725141525268555
Batch 25/64 loss: 0.34404557943344116
Batch 26/64 loss: 0.34446728229522705
Batch 27/64 loss: 0.34168827533721924
Batch 28/64 loss: 0.34475207328796387
Batch 29/64 loss: 0.34626126289367676
Batch 30/64 loss: 0.3469935655593872
Batch 31/64 loss: 0.3424261808395386
Batch 32/64 loss: 0.3477895259857178
Batch 33/64 loss: 0.347023606300354
Batch 34/64 loss: 0.3426312208175659
Batch 35/64 loss: 0.3435478210449219
Batch 36/64 loss: 0.34660542011260986
Batch 37/64 loss: 0.3448095917701721
Batch 38/64 loss: 0.3478686809539795
Batch 39/64 loss: 0.34472334384918213
Batch 40/64 loss: 0.3465304374694824
Batch 41/64 loss: 0.3467189073562622
Batch 42/64 loss: 0.34696054458618164
Batch 43/64 loss: 0.34519660472869873
Batch 44/64 loss: 0.34303998947143555
Batch 45/64 loss: 0.3494163751602173
Batch 46/64 loss: 0.3433290123939514
Batch 47/64 loss: 0.34907495975494385
Batch 48/64 loss: 0.343736469745636
Batch 49/64 loss: 0.34179580211639404
Batch 50/64 loss: 0.34821832180023193
Batch 51/64 loss: 0.3479849100112915
Batch 52/64 loss: 0.3476991653442383
Batch 53/64 loss: 0.34641480445861816
Batch 54/64 loss: 0.34233856201171875
Batch 55/64 loss: 0.3472108244895935
Batch 56/64 loss: 0.3502299189567566
Batch 57/64 loss: 0.34481537342071533
Batch 58/64 loss: 0.3453323245048523
Batch 59/64 loss: 0.346549391746521
Batch 60/64 loss: 0.3492199182510376
Batch 61/64 loss: 0.34700119495391846
Batch 62/64 loss: 0.343447744846344
Batch 63/64 loss: 0.3434144854545593
Batch 64/64 loss: 0.347009539604187
Epoch 21  Train loss: 0.3464002670026293  Val loss: 0.3512217664636697
Epoch 22
-------------------------------
Batch 1/64 loss: 0.3441668152809143
Batch 2/64 loss: 0.3468615412712097
Batch 3/64 loss: 0.34903281927108765
Batch 4/64 loss: 0.34488725662231445
Batch 5/64 loss: 0.3462147116661072
Batch 6/64 loss: 0.3455994129180908
Batch 7/64 loss: 0.3443347215652466
Batch 8/64 loss: 0.34513282775878906
Batch 9/64 loss: 0.3446776270866394
Batch 10/64 loss: 0.34714293479919434
Batch 11/64 loss: 0.3454986810684204
Batch 12/64 loss: 0.3472609519958496
Batch 13/64 loss: 0.34462153911590576
Batch 14/64 loss: 0.34578144550323486
Batch 15/64 loss: 0.344338595867157
Batch 16/64 loss: 0.34487801790237427
Batch 17/64 loss: 0.34528541564941406
Batch 18/64 loss: 0.3497292995452881
Batch 19/64 loss: 0.34370678663253784
Batch 20/64 loss: 0.34602367877960205
Batch 21/64 loss: 0.34525054693222046
Batch 22/64 loss: 0.34756743907928467
Batch 23/64 loss: 0.35008054971694946
Batch 24/64 loss: 0.34482336044311523
Batch 25/64 loss: 0.3462600111961365
Batch 26/64 loss: 0.3435162305831909
Batch 27/64 loss: 0.3471447825431824
Batch 28/64 loss: 0.34793621301651
Batch 29/64 loss: 0.35054171085357666
Batch 30/64 loss: 0.341410756111145
Batch 31/64 loss: 0.34805136919021606
Batch 32/64 loss: 0.3449864387512207
Batch 33/64 loss: 0.34923017024993896
Batch 34/64 loss: 0.3427742123603821
Batch 35/64 loss: 0.34348905086517334
Batch 36/64 loss: 0.34689152240753174
Batch 37/64 loss: 0.35463201999664307
Batch 38/64 loss: 0.346160888671875
Batch 39/64 loss: 0.34728217124938965
Batch 40/64 loss: 0.34411025047302246
Batch 41/64 loss: 0.34877681732177734
Batch 42/64 loss: 0.3500896692276001
Batch 43/64 loss: 0.34484612941741943
Batch 44/64 loss: 0.3499387502670288
Batch 45/64 loss: 0.35032379627227783
Batch 46/64 loss: 0.34515511989593506
Batch 47/64 loss: 0.3478882312774658
Batch 48/64 loss: 0.34368765354156494
Batch 49/64 loss: 0.3496541976928711
Batch 50/64 loss: 0.3482557535171509
Batch 51/64 loss: 0.34586942195892334
Batch 52/64 loss: 0.34322017431259155
Batch 53/64 loss: 0.3493691682815552
Batch 54/64 loss: 0.34463632106781006
Batch 55/64 loss: 0.3473625183105469
Batch 56/64 loss: 0.3431508541107178
Batch 57/64 loss: 0.34322023391723633
Batch 58/64 loss: 0.3447471857070923
Batch 59/64 loss: 0.34339481592178345
Batch 60/64 loss: 0.3476598262786865
Batch 61/64 loss: 0.3474329113960266
Batch 62/64 loss: 0.3457341194152832
Batch 63/64 loss: 0.34688735008239746
Batch 64/64 loss: 0.3485730290412903
Epoch 22  Train loss: 0.3463536559366712  Val loss: 0.34834440180526155
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: 0.347606897354126
Batch 2/64 loss: 0.34673774242401123
Batch 3/64 loss: 0.3441486954689026
Batch 4/64 loss: 0.3437168598175049
Batch 5/64 loss: 0.34780240058898926
Batch 6/64 loss: 0.3431662321090698
Batch 7/64 loss: 0.34513580799102783
Batch 8/64 loss: 0.34660494327545166
Batch 9/64 loss: 0.34076130390167236
Batch 10/64 loss: 0.3475002646446228
Batch 11/64 loss: 0.3443608283996582
Batch 12/64 loss: 0.3430752754211426
Batch 13/64 loss: 0.34048986434936523
Batch 14/64 loss: 0.345065712928772
Batch 15/64 loss: 0.34197747707366943
Batch 16/64 loss: 0.3469884395599365
Batch 17/64 loss: 0.34756970405578613
Batch 18/64 loss: 0.34788376092910767
Batch 19/64 loss: 0.3477737307548523
Batch 20/64 loss: 0.3472653031349182
Batch 21/64 loss: 0.34468114376068115
Batch 22/64 loss: 0.34460771083831787
Batch 23/64 loss: 0.35068053007125854
Batch 24/64 loss: 0.345867395401001
Batch 25/64 loss: 0.34567904472351074
Batch 26/64 loss: 0.34287023544311523
Batch 27/64 loss: 0.3426460027694702
Batch 28/64 loss: 0.3457578420639038
Batch 29/64 loss: 0.3487136960029602
Batch 30/64 loss: 0.3443378210067749
Batch 31/64 loss: 0.3454657793045044
Batch 32/64 loss: 0.3493412137031555
Batch 33/64 loss: 0.34440696239471436
Batch 34/64 loss: 0.3475024700164795
Batch 35/64 loss: 0.3468160629272461
Batch 36/64 loss: 0.34921813011169434
Batch 37/64 loss: 0.3445037007331848
Batch 38/64 loss: 0.3468976616859436
Batch 39/64 loss: 0.34308719635009766
Batch 40/64 loss: 0.343833327293396
Batch 41/64 loss: 0.3431044816970825
Batch 42/64 loss: 0.3475611209869385
Batch 43/64 loss: 0.3440735340118408
Batch 44/64 loss: 0.34472405910491943
Batch 45/64 loss: 0.3439330458641052
Batch 46/64 loss: 0.34021925926208496
Batch 47/64 loss: 0.34539222717285156
Batch 48/64 loss: 0.3418475389480591
Batch 49/64 loss: 0.3480112552642822
Batch 50/64 loss: 0.34398913383483887
Batch 51/64 loss: 0.3470219373703003
Batch 52/64 loss: 0.34356290102005005
Batch 53/64 loss: 0.3464180827140808
Batch 54/64 loss: 0.34359753131866455
Batch 55/64 loss: 0.34302037954330444
Batch 56/64 loss: 0.34270548820495605
Batch 57/64 loss: 0.3477596640586853
Batch 58/64 loss: 0.3451157808303833
Batch 59/64 loss: 0.34312641620635986
Batch 60/64 loss: 0.3465573787689209
Batch 61/64 loss: 0.35219740867614746
Batch 62/64 loss: 0.3490014672279358
Batch 63/64 loss: 0.3489208221435547
Batch 64/64 loss: 0.3454946279525757
Epoch 23  Train loss: 0.3454670910741769  Val loss: 0.34779429702005027
Saving best model, epoch: 23
Epoch 24
-------------------------------
Batch 1/64 loss: 0.3422301411628723
Batch 2/64 loss: 0.34522974491119385
Batch 3/64 loss: 0.3423558473587036
Batch 4/64 loss: 0.35273438692092896
Batch 5/64 loss: 0.34492599964141846
Batch 6/64 loss: 0.3446453809738159
Batch 7/64 loss: 0.34061408042907715
Batch 8/64 loss: 0.3447710871696472
Batch 9/64 loss: 0.34275275468826294
Batch 10/64 loss: 0.3444545269012451
Batch 11/64 loss: 0.3406057357788086
Batch 12/64 loss: 0.34931957721710205
Batch 13/64 loss: 0.3434026837348938
Batch 14/64 loss: 0.3462100625038147
Batch 15/64 loss: 0.3468043804168701
Batch 16/64 loss: 0.34279775619506836
Batch 17/64 loss: 0.3428552746772766
Batch 18/64 loss: 0.3415888547897339
Batch 19/64 loss: 0.3475910425186157
Batch 20/64 loss: 0.3428904414176941
Batch 21/64 loss: 0.3442249894142151
Batch 22/64 loss: 0.34626996517181396
Batch 23/64 loss: 0.34621232748031616
Batch 24/64 loss: 0.34234291315078735
Batch 25/64 loss: 0.3479728698730469
Batch 26/64 loss: 0.3451118469238281
Batch 27/64 loss: 0.342956006526947
Batch 28/64 loss: 0.3483198285102844
Batch 29/64 loss: 0.34500181674957275
Batch 30/64 loss: 0.34712743759155273
Batch 31/64 loss: 0.34882456064224243
Batch 32/64 loss: 0.34400075674057007
Batch 33/64 loss: 0.3473433256149292
Batch 34/64 loss: 0.34856748580932617
Batch 35/64 loss: 0.3433530330657959
Batch 36/64 loss: 0.34735429286956787
Batch 37/64 loss: 0.3451366424560547
Batch 38/64 loss: 0.34498095512390137
Batch 39/64 loss: 0.34620070457458496
Batch 40/64 loss: 0.34404778480529785
Batch 41/64 loss: 0.3434334993362427
Batch 42/64 loss: 0.3454108238220215
Batch 43/64 loss: 0.3418213129043579
Batch 44/64 loss: 0.3415811061859131
Batch 45/64 loss: 0.34286898374557495
Batch 46/64 loss: 0.34696662425994873
Batch 47/64 loss: 0.3478636145591736
Batch 48/64 loss: 0.346752405166626
Batch 49/64 loss: 0.342920184135437
Batch 50/64 loss: 0.34747785329818726
Batch 51/64 loss: 0.3451099991798401
Batch 52/64 loss: 0.3426644802093506
Batch 53/64 loss: 0.3461158275604248
Batch 54/64 loss: 0.3427755832672119
Batch 55/64 loss: 0.3443061113357544
Batch 56/64 loss: 0.34617483615875244
Batch 57/64 loss: 0.345389187335968
Batch 58/64 loss: 0.3446352481842041
Batch 59/64 loss: 0.34611356258392334
Batch 60/64 loss: 0.3440040349960327
Batch 61/64 loss: 0.34300148487091064
Batch 62/64 loss: 0.3464411497116089
Batch 63/64 loss: 0.3441140055656433
Batch 64/64 loss: 0.3434675335884094
Epoch 24  Train loss: 0.34493602935005635  Val loss: 0.3475917884983967
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 0.3448222875595093
Batch 2/64 loss: 0.3421034812927246
Batch 3/64 loss: 0.345966100692749
Batch 4/64 loss: 0.3440546989440918
Batch 5/64 loss: 0.3436894416809082
Batch 6/64 loss: 0.3433495759963989
Batch 7/64 loss: 0.34370338916778564
Batch 8/64 loss: 0.3410763740539551
Batch 9/64 loss: 0.3509805202484131
Batch 10/64 loss: 0.35016071796417236
Batch 11/64 loss: 0.3428954482078552
Batch 12/64 loss: 0.3428584933280945
Batch 13/64 loss: 0.33865487575531006
Batch 14/64 loss: 0.3426896333694458
Batch 15/64 loss: 0.3393280506134033
Batch 16/64 loss: 0.3442593216896057
Batch 17/64 loss: 0.34297120571136475
Batch 18/64 loss: 0.34314411878585815
Batch 19/64 loss: 0.3422163724899292
Batch 20/64 loss: 0.345963716506958
Batch 21/64 loss: 0.3511035442352295
Batch 22/64 loss: 0.34398770332336426
Batch 23/64 loss: 0.34477174282073975
Batch 24/64 loss: 0.34373998641967773
Batch 25/64 loss: 0.3443111181259155
Batch 26/64 loss: 0.34229230880737305
Batch 27/64 loss: 0.347070574760437
Batch 28/64 loss: 0.34200137853622437
Batch 29/64 loss: 0.3452490568161011
Batch 30/64 loss: 0.33977317810058594
Batch 31/64 loss: 0.3439332842826843
Batch 32/64 loss: 0.3412928581237793
Batch 33/64 loss: 0.3447765111923218
Batch 34/64 loss: 0.3446062207221985
Batch 35/64 loss: 0.3400194048881531
Batch 36/64 loss: 0.34274518489837646
Batch 37/64 loss: 0.34217989444732666
Batch 38/64 loss: 0.34525585174560547
Batch 39/64 loss: 0.3436168432235718
Batch 40/64 loss: 0.3458590507507324
Batch 41/64 loss: 0.34318768978118896
Batch 42/64 loss: 0.3416249752044678
Batch 43/64 loss: 0.34159719944000244
Batch 44/64 loss: 0.34274518489837646
Batch 45/64 loss: 0.34585851430892944
Batch 46/64 loss: 0.34123992919921875
Batch 47/64 loss: 0.3406503200531006
Batch 48/64 loss: 0.3413792848587036
Batch 49/64 loss: 0.34470367431640625
Batch 50/64 loss: 0.3424825072288513
Batch 51/64 loss: 0.34612715244293213
Batch 52/64 loss: 0.3445832133293152
Batch 53/64 loss: 0.34341955184936523
Batch 54/64 loss: 0.34392690658569336
Batch 55/64 loss: 0.34470033645629883
Batch 56/64 loss: 0.3437528610229492
Batch 57/64 loss: 0.34033727645874023
Batch 58/64 loss: 0.34432876110076904
Batch 59/64 loss: 0.3434690833091736
Batch 60/64 loss: 0.3400372862815857
Batch 61/64 loss: 0.3483346700668335
Batch 62/64 loss: 0.3446551561355591
Batch 63/64 loss: 0.344632625579834
Batch 64/64 loss: 0.3387916684150696
Epoch 25  Train loss: 0.3436131989254671  Val loss: 0.3471722627423473
Saving best model, epoch: 25
Epoch 26
-------------------------------
Batch 1/64 loss: 0.33727848529815674
Batch 2/64 loss: 0.3459080457687378
Batch 3/64 loss: 0.3454745411872864
Batch 4/64 loss: 0.3427867293357849
Batch 5/64 loss: 0.34821856021881104
Batch 6/64 loss: 0.34176915884017944
Batch 7/64 loss: 0.34821468591690063
Batch 8/64 loss: 0.34431636333465576
Batch 9/64 loss: 0.343947172164917
Batch 10/64 loss: 0.348477840423584
Batch 11/64 loss: 0.3415403366088867
Batch 12/64 loss: 0.3440479040145874
Batch 13/64 loss: 0.34344297647476196
Batch 14/64 loss: 0.3429017663002014
Batch 15/64 loss: 0.3443009853363037
Batch 16/64 loss: 0.34187161922454834
Batch 17/64 loss: 0.344507098197937
Batch 18/64 loss: 0.3422114849090576
Batch 19/64 loss: 0.3469409942626953
Batch 20/64 loss: 0.34488314390182495
Batch 21/64 loss: 0.34417474269866943
Batch 22/64 loss: 0.347553014755249
Batch 23/64 loss: 0.342540442943573
Batch 24/64 loss: 0.3439352512359619
Batch 25/64 loss: 0.3416048288345337
Batch 26/64 loss: 0.34737807512283325
Batch 27/64 loss: 0.3448917269706726
Batch 28/64 loss: 0.3412514328956604
Batch 29/64 loss: 0.3478429913520813
Batch 30/64 loss: 0.3454916477203369
Batch 31/64 loss: 0.3461533784866333
Batch 32/64 loss: 0.34397804737091064
Batch 33/64 loss: 0.348891019821167
Batch 34/64 loss: 0.34631311893463135
Batch 35/64 loss: 0.3473503589630127
Batch 36/64 loss: 0.3448134660720825
Batch 37/64 loss: 0.3426310420036316
Batch 38/64 loss: 0.34360241889953613
Batch 39/64 loss: 0.34961533546447754
Batch 40/64 loss: 0.3422468304634094
Batch 41/64 loss: 0.3420764207839966
Batch 42/64 loss: 0.34135282039642334
Batch 43/64 loss: 0.3429785966873169
Batch 44/64 loss: 0.34464967250823975
Batch 45/64 loss: 0.3400686979293823
Batch 46/64 loss: 0.34444063901901245
Batch 47/64 loss: 0.34167051315307617
Batch 48/64 loss: 0.3426048755645752
Batch 49/64 loss: 0.3437870144844055
Batch 50/64 loss: 0.3415558934211731
Batch 51/64 loss: 0.34346556663513184
Batch 52/64 loss: 0.34242331981658936
Batch 53/64 loss: 0.34531259536743164
Batch 54/64 loss: 0.340969443321228
Batch 55/64 loss: 0.3399738073348999
Batch 56/64 loss: 0.3443397283554077
Batch 57/64 loss: 0.34267449378967285
Batch 58/64 loss: 0.33966875076293945
Batch 59/64 loss: 0.34617340564727783
Batch 60/64 loss: 0.3440435528755188
Batch 61/64 loss: 0.341636061668396
Batch 62/64 loss: 0.34658581018447876
Batch 63/64 loss: 0.34866029024124146
Batch 64/64 loss: 0.3444918394088745
Epoch 26  Train loss: 0.34407497901542516  Val loss: 0.3475950116554077
Epoch 27
-------------------------------
Batch 1/64 loss: 0.345694899559021
Batch 2/64 loss: 0.34506016969680786
Batch 3/64 loss: 0.341457724571228
Batch 4/64 loss: 0.34151995182037354
Batch 5/64 loss: 0.34783709049224854
Batch 6/64 loss: 0.3429783582687378
Batch 7/64 loss: 0.3435094356536865
Batch 8/64 loss: 0.3469228744506836
Batch 9/64 loss: 0.3383307456970215
Batch 10/64 loss: 0.3390953540802002
Batch 11/64 loss: 0.34267938137054443
Batch 12/64 loss: 0.3402246832847595
Batch 13/64 loss: 0.34410274028778076
Batch 14/64 loss: 0.343259334564209
Batch 15/64 loss: 0.34681546688079834
Batch 16/64 loss: 0.3465888500213623
Batch 17/64 loss: 0.34698599576950073
Batch 18/64 loss: 0.34495341777801514
Batch 19/64 loss: 0.34508419036865234
Batch 20/64 loss: 0.34320902824401855
Batch 21/64 loss: 0.343792200088501
Batch 22/64 loss: 0.3415986895561218
Batch 23/64 loss: 0.33880168199539185
Batch 24/64 loss: 0.3382531404495239
Batch 25/64 loss: 0.34287601709365845
Batch 26/64 loss: 0.34004372358322144
Batch 27/64 loss: 0.3436216711997986
Batch 28/64 loss: 0.3457323908805847
Batch 29/64 loss: 0.33914053440093994
Batch 30/64 loss: 0.33822643756866455
Batch 31/64 loss: 0.3422502279281616
Batch 32/64 loss: 0.34480059146881104
Batch 33/64 loss: 0.3420076370239258
Batch 34/64 loss: 0.34602034091949463
Batch 35/64 loss: 0.33863455057144165
Batch 36/64 loss: 0.3441518545150757
Batch 37/64 loss: 0.33979809284210205
Batch 38/64 loss: 0.3426527976989746
Batch 39/64 loss: 0.3405231833457947
Batch 40/64 loss: 0.33904314041137695
Batch 41/64 loss: 0.345797598361969
Batch 42/64 loss: 0.34236669540405273
Batch 43/64 loss: 0.3419034481048584
Batch 44/64 loss: 0.34730398654937744
Batch 45/64 loss: 0.33869582414627075
Batch 46/64 loss: 0.3435145616531372
Batch 47/64 loss: 0.34619295597076416
Batch 48/64 loss: 0.3400067687034607
Batch 49/64 loss: 0.3460174798965454
Batch 50/64 loss: 0.344667911529541
Batch 51/64 loss: 0.34541821479797363
Batch 52/64 loss: 0.3424168825149536
Batch 53/64 loss: 0.3421487808227539
Batch 54/64 loss: 0.3423154950141907
Batch 55/64 loss: 0.34650784730911255
Batch 56/64 loss: 0.342559814453125
Batch 57/64 loss: 0.34416794776916504
Batch 58/64 loss: 0.34433335065841675
Batch 59/64 loss: 0.34573400020599365
Batch 60/64 loss: 0.34266209602355957
Batch 61/64 loss: 0.3430027365684509
Batch 62/64 loss: 0.3417854309082031
Batch 63/64 loss: 0.339882493019104
Batch 64/64 loss: 0.34506702423095703
Epoch 27  Train loss: 0.34300362643073584  Val loss: 0.3454315490329388
Saving best model, epoch: 27
Epoch 28
-------------------------------
Batch 1/64 loss: 0.3445807099342346
Batch 2/64 loss: 0.3390105962753296
Batch 3/64 loss: 0.34047067165374756
Batch 4/64 loss: 0.345434308052063
Batch 5/64 loss: 0.3440728187561035
Batch 6/64 loss: 0.34321314096450806
Batch 7/64 loss: 0.3441801071166992
Batch 8/64 loss: 0.3381032347679138
Batch 9/64 loss: 0.3335360288619995
Batch 10/64 loss: 0.3452717065811157
Batch 11/64 loss: 0.3417510986328125
Batch 12/64 loss: 0.34426939487457275
Batch 13/64 loss: 0.3433724641799927
Batch 14/64 loss: 0.34194785356521606
Batch 15/64 loss: 0.338886022567749
Batch 16/64 loss: 0.3399485945701599
Batch 17/64 loss: 0.34046369791030884
Batch 18/64 loss: 0.3450285792350769
Batch 19/64 loss: 0.34132087230682373
Batch 20/64 loss: 0.3401668071746826
Batch 21/64 loss: 0.3452640771865845
Batch 22/64 loss: 0.34276872873306274
Batch 23/64 loss: 0.34670549631118774
Batch 24/64 loss: 0.34105080366134644
Batch 25/64 loss: 0.3459205627441406
Batch 26/64 loss: 0.34664297103881836
Batch 27/64 loss: 0.3437679409980774
Batch 28/64 loss: 0.3426852822303772
Batch 29/64 loss: 0.343874454498291
Batch 30/64 loss: 0.3478313684463501
Batch 31/64 loss: 0.34446609020233154
Batch 32/64 loss: 0.3403342366218567
Batch 33/64 loss: 0.3403170704841614
Batch 34/64 loss: 0.3475688695907593
Batch 35/64 loss: 0.3493145704269409
Batch 36/64 loss: 0.34350669384002686
Batch 37/64 loss: 0.3456149101257324
Batch 38/64 loss: 0.341000497341156
Batch 39/64 loss: 0.3420282006263733
Batch 40/64 loss: 0.33959078788757324
Batch 41/64 loss: 0.34237879514694214
Batch 42/64 loss: 0.34464752674102783
Batch 43/64 loss: 0.345672070980072
Batch 44/64 loss: 0.3447136878967285
Batch 45/64 loss: 0.34290850162506104
Batch 46/64 loss: 0.343631386756897
Batch 47/64 loss: 0.3421109914779663
Batch 48/64 loss: 0.34032154083251953
Batch 49/64 loss: 0.3434089422225952
Batch 50/64 loss: 0.34217584133148193
Batch 51/64 loss: 0.3470471501350403
Batch 52/64 loss: 0.3461706042289734
Batch 53/64 loss: 0.3401883840560913
Batch 54/64 loss: 0.3364587426185608
Batch 55/64 loss: 0.343852698802948
Batch 56/64 loss: 0.3458636999130249
Batch 57/64 loss: 0.3406778573989868
Batch 58/64 loss: 0.3426915407180786
Batch 59/64 loss: 0.33852559328079224
Batch 60/64 loss: 0.3373984098434448
Batch 61/64 loss: 0.3428117036819458
Batch 62/64 loss: 0.34175145626068115
Batch 63/64 loss: 0.3398069739341736
Batch 64/64 loss: 0.3433274030685425
Epoch 28  Train loss: 0.34271359957900704  Val loss: 0.34456928427686395
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: 0.3419637680053711
Batch 2/64 loss: 0.3435474634170532
Batch 3/64 loss: 0.3383360505104065
Batch 4/64 loss: 0.34016144275665283
Batch 5/64 loss: 0.34364134073257446
Batch 6/64 loss: 0.3412477970123291
Batch 7/64 loss: 0.3429373502731323
Batch 8/64 loss: 0.3413083553314209
Batch 9/64 loss: 0.33788013458251953
Batch 10/64 loss: 0.3419163227081299
Batch 11/64 loss: 0.34114396572113037
Batch 12/64 loss: 0.34297502040863037
Batch 13/64 loss: 0.34152376651763916
Batch 14/64 loss: 0.3457341194152832
Batch 15/64 loss: 0.34202897548675537
Batch 16/64 loss: 0.34215009212493896
Batch 17/64 loss: 0.34448540210723877
Batch 18/64 loss: 0.34511804580688477
Batch 19/64 loss: 0.34025275707244873
Batch 20/64 loss: 0.3402348756790161
Batch 21/64 loss: 0.3391353487968445
Batch 22/64 loss: 0.3360002040863037
Batch 23/64 loss: 0.3420024514198303
Batch 24/64 loss: 0.3425464630126953
Batch 25/64 loss: 0.34354639053344727
Batch 26/64 loss: 0.33873170614242554
Batch 27/64 loss: 0.34366440773010254
Batch 28/64 loss: 0.3415919542312622
Batch 29/64 loss: 0.344956636428833
Batch 30/64 loss: 0.33908581733703613
Batch 31/64 loss: 0.3429229259490967
Batch 32/64 loss: 0.34429943561553955
Batch 33/64 loss: 0.33953428268432617
Batch 34/64 loss: 0.3428431749343872
Batch 35/64 loss: 0.3446882963180542
Batch 36/64 loss: 0.3441165089607239
Batch 37/64 loss: 0.344510018825531
Batch 38/64 loss: 0.34334003925323486
Batch 39/64 loss: 0.3453230857849121
Batch 40/64 loss: 0.3436182141304016
Batch 41/64 loss: 0.3426336646080017
Batch 42/64 loss: 0.33642250299453735
Batch 43/64 loss: 0.33850157260894775
Batch 44/64 loss: 0.33991754055023193
Batch 45/64 loss: 0.3399288058280945
Batch 46/64 loss: 0.3409663438796997
Batch 47/64 loss: 0.33604705333709717
Batch 48/64 loss: 0.3403112292289734
Batch 49/64 loss: 0.3376733064651489
Batch 50/64 loss: 0.34234076738357544
Batch 51/64 loss: 0.34213703870773315
Batch 52/64 loss: 0.3374515175819397
Batch 53/64 loss: 0.3462628126144409
Batch 54/64 loss: 0.3397599458694458
Batch 55/64 loss: 0.34298527240753174
Batch 56/64 loss: 0.34179842472076416
Batch 57/64 loss: 0.3399338126182556
Batch 58/64 loss: 0.3446539640426636
Batch 59/64 loss: 0.3424800634384155
Batch 60/64 loss: 0.3379906415939331
Batch 61/64 loss: 0.34105002880096436
Batch 62/64 loss: 0.3463813066482544
Batch 63/64 loss: 0.34306037425994873
Batch 64/64 loss: 0.3347699046134949
Epoch 29  Train loss: 0.34159701688616884  Val loss: 0.3455243878757831
Epoch 30
-------------------------------
Batch 1/64 loss: 0.3425314426422119
Batch 2/64 loss: 0.34370100498199463
Batch 3/64 loss: 0.3435624837875366
Batch 4/64 loss: 0.34279412031173706
Batch 5/64 loss: 0.3378298282623291
Batch 6/64 loss: 0.3405951261520386
Batch 7/64 loss: 0.34825432300567627
Batch 8/64 loss: 0.34299468994140625
Batch 9/64 loss: 0.34230417013168335
Batch 10/64 loss: 0.3442988395690918
Batch 11/64 loss: 0.343616247177124
Batch 12/64 loss: 0.3413096070289612
Batch 13/64 loss: 0.3456312417984009
Batch 14/64 loss: 0.3421591520309448
Batch 15/64 loss: 0.3430805206298828
Batch 16/64 loss: 0.33771222829818726
Batch 17/64 loss: 0.3452426791191101
Batch 18/64 loss: 0.34710490703582764
Batch 19/64 loss: 0.33977651596069336
Batch 20/64 loss: 0.33845168352127075
Batch 21/64 loss: 0.34611332416534424
Batch 22/64 loss: 0.339421808719635
Batch 23/64 loss: 0.33865678310394287
Batch 24/64 loss: 0.33895212411880493
Batch 25/64 loss: 0.3400189280509949
Batch 26/64 loss: 0.33969056606292725
Batch 27/64 loss: 0.34171515703201294
Batch 28/64 loss: 0.34304100275039673
Batch 29/64 loss: 0.34731900691986084
Batch 30/64 loss: 0.34324395656585693
Batch 31/64 loss: 0.3411223888397217
Batch 32/64 loss: 0.3430919647216797
Batch 33/64 loss: 0.34505343437194824
Batch 34/64 loss: 0.34453123807907104
Batch 35/64 loss: 0.3440229892730713
Batch 36/64 loss: 0.3432425260543823
Batch 37/64 loss: 0.33877891302108765
Batch 38/64 loss: 0.34564054012298584
Batch 39/64 loss: 0.3354429006576538
Batch 40/64 loss: 0.34503936767578125
Batch 41/64 loss: 0.3426995277404785
Batch 42/64 loss: 0.3411468267440796
Batch 43/64 loss: 0.3426118493080139
Batch 44/64 loss: 0.3391977548599243
Batch 45/64 loss: 0.3389238715171814
Batch 46/64 loss: 0.3397327661514282
Batch 47/64 loss: 0.3392986059188843
Batch 48/64 loss: 0.34376847743988037
Batch 49/64 loss: 0.34520626068115234
Batch 50/64 loss: 0.3414822220802307
Batch 51/64 loss: 0.34413355588912964
Batch 52/64 loss: 0.3402829170227051
Batch 53/64 loss: 0.34260302782058716
Batch 54/64 loss: 0.34214675426483154
Batch 55/64 loss: 0.33511531352996826
Batch 56/64 loss: 0.33510005474090576
Batch 57/64 loss: 0.3407028913497925
Batch 58/64 loss: 0.3400511145591736
Batch 59/64 loss: 0.3396686315536499
Batch 60/64 loss: 0.34279680252075195
Batch 61/64 loss: 0.3404972553253174
Batch 62/64 loss: 0.3386010527610779
Batch 63/64 loss: 0.340887188911438
Batch 64/64 loss: 0.33984798192977905
Epoch 30  Train loss: 0.341782438287548  Val loss: 0.3441252007926862
Saving best model, epoch: 30
Epoch 31
-------------------------------
Batch 1/64 loss: 0.3396943211555481
Batch 2/64 loss: 0.3393160104751587
Batch 3/64 loss: 0.3446226716041565
Batch 4/64 loss: 0.34075939655303955
Batch 5/64 loss: 0.34128814935684204
Batch 6/64 loss: 0.3377443552017212
Batch 7/64 loss: 0.34027934074401855
Batch 8/64 loss: 0.3427733778953552
Batch 9/64 loss: 0.33824801445007324
Batch 10/64 loss: 0.339604914188385
Batch 11/64 loss: 0.3391951322555542
Batch 12/64 loss: 0.33987897634506226
Batch 13/64 loss: 0.3362698554992676
Batch 14/64 loss: 0.3390316367149353
Batch 15/64 loss: 0.3393462896347046
Batch 16/64 loss: 0.34874236583709717
Batch 17/64 loss: 0.3483894467353821
Batch 18/64 loss: 0.34066855907440186
Batch 19/64 loss: 0.34385740756988525
Batch 20/64 loss: 0.3486918807029724
Batch 21/64 loss: 0.3440202474594116
Batch 22/64 loss: 0.3443795442581177
Batch 23/64 loss: 0.34148597717285156
Batch 24/64 loss: 0.34202486276626587
Batch 25/64 loss: 0.33613330125808716
Batch 26/64 loss: 0.3424680829048157
Batch 27/64 loss: 0.3383389115333557
Batch 28/64 loss: 0.3425576686859131
Batch 29/64 loss: 0.3390301465988159
Batch 30/64 loss: 0.3418848514556885
Batch 31/64 loss: 0.33866071701049805
Batch 32/64 loss: 0.34153348207473755
Batch 33/64 loss: 0.341418981552124
Batch 34/64 loss: 0.3389385938644409
Batch 35/64 loss: 0.3383309841156006
Batch 36/64 loss: 0.34087204933166504
Batch 37/64 loss: 0.3441340923309326
Batch 38/64 loss: 0.34264981746673584
Batch 39/64 loss: 0.33935660123825073
Batch 40/64 loss: 0.3359871506690979
Batch 41/64 loss: 0.3419231176376343
Batch 42/64 loss: 0.34448307752609253
Batch 43/64 loss: 0.33945727348327637
Batch 44/64 loss: 0.3400586247444153
Batch 45/64 loss: 0.33423733711242676
Batch 46/64 loss: 0.342068076133728
Batch 47/64 loss: 0.34279030561447144
Batch 48/64 loss: 0.340049684047699
Batch 49/64 loss: 0.341087281703949
Batch 50/64 loss: 0.34214794635772705
Batch 51/64 loss: 0.3396525979042053
Batch 52/64 loss: 0.3424278497695923
Batch 53/64 loss: 0.34652239084243774
Batch 54/64 loss: 0.3378066420555115
Batch 55/64 loss: 0.3450472354888916
Batch 56/64 loss: 0.33724987506866455
Batch 57/64 loss: 0.33879101276397705
Batch 58/64 loss: 0.3469456434249878
Batch 59/64 loss: 0.34441453218460083
Batch 60/64 loss: 0.33817899227142334
Batch 61/64 loss: 0.34251976013183594
Batch 62/64 loss: 0.3398171663284302
Batch 63/64 loss: 0.34112977981567383
Batch 64/64 loss: 0.3373798131942749
Epoch 31  Train loss: 0.34108939965566  Val loss: 0.3457696761462287
Epoch 32
-------------------------------
Batch 1/64 loss: 0.33643412590026855
Batch 2/64 loss: 0.33967339992523193
Batch 3/64 loss: 0.3442750573158264
Batch 4/64 loss: 0.3442578911781311
Batch 5/64 loss: 0.34220457077026367
Batch 6/64 loss: 0.33830535411834717
Batch 7/64 loss: 0.3450049161911011
Batch 8/64 loss: 0.3433923125267029
Batch 9/64 loss: 0.34304237365722656
Batch 10/64 loss: 0.34117990732192993
Batch 11/64 loss: 0.33926016092300415
Batch 12/64 loss: 0.3382638692855835
Batch 13/64 loss: 0.33638375997543335
Batch 14/64 loss: 0.33714818954467773
Batch 15/64 loss: 0.342604398727417
Batch 16/64 loss: 0.3369343876838684
Batch 17/64 loss: 0.3387265205383301
Batch 18/64 loss: 0.3401023745536804
Batch 19/64 loss: 0.3426409363746643
Batch 20/64 loss: 0.33798277378082275
Batch 21/64 loss: 0.3410681486129761
Batch 22/64 loss: 0.33819127082824707
Batch 23/64 loss: 0.3389508128166199
Batch 24/64 loss: 0.33910906314849854
Batch 25/64 loss: 0.33945560455322266
Batch 26/64 loss: 0.33905577659606934
Batch 27/64 loss: 0.34111475944519043
Batch 28/64 loss: 0.3431571125984192
Batch 29/64 loss: 0.3403090238571167
Batch 30/64 loss: 0.33992695808410645
Batch 31/64 loss: 0.33657145500183105
Batch 32/64 loss: 0.33951079845428467
Batch 33/64 loss: 0.3398573398590088
Batch 34/64 loss: 0.34359776973724365
Batch 35/64 loss: 0.3394874930381775
Batch 36/64 loss: 0.3393241763114929
Batch 37/64 loss: 0.3433048725128174
Batch 38/64 loss: 0.3490651845932007
Batch 39/64 loss: 0.3405451774597168
Batch 40/64 loss: 0.33930838108062744
Batch 41/64 loss: 0.34290122985839844
Batch 42/64 loss: 0.33995890617370605
Batch 43/64 loss: 0.3407416343688965
Batch 44/64 loss: 0.34159648418426514
Batch 45/64 loss: 0.33887600898742676
Batch 46/64 loss: 0.3412402272224426
Batch 47/64 loss: 0.34452664852142334
Batch 48/64 loss: 0.34088218212127686
Batch 49/64 loss: 0.3387424945831299
Batch 50/64 loss: 0.3392544984817505
Batch 51/64 loss: 0.3426077365875244
Batch 52/64 loss: 0.34062767028808594
Batch 53/64 loss: 0.3427428603172302
Batch 54/64 loss: 0.3414386510848999
Batch 55/64 loss: 0.3420324921607971
Batch 56/64 loss: 0.3401615619659424
Batch 57/64 loss: 0.3407684564590454
Batch 58/64 loss: 0.33866143226623535
Batch 59/64 loss: 0.3414880633354187
Batch 60/64 loss: 0.3401873707771301
Batch 61/64 loss: 0.33867788314819336
Batch 62/64 loss: 0.3385469913482666
Batch 63/64 loss: 0.34011608362197876
Batch 64/64 loss: 0.3456265926361084
Epoch 32  Train loss: 0.34062315248975567  Val loss: 0.3452559768948768
Epoch 33
-------------------------------
Batch 1/64 loss: 0.34247374534606934
Batch 2/64 loss: 0.33958977460861206
Batch 3/64 loss: 0.3433109521865845
Batch 4/64 loss: 0.34308934211730957
Batch 5/64 loss: 0.339450478553772
Batch 6/64 loss: 0.3362719416618347
Batch 7/64 loss: 0.3473525643348694
Batch 8/64 loss: 0.34328222274780273
Batch 9/64 loss: 0.33830559253692627
Batch 10/64 loss: 0.3375076651573181
Batch 11/64 loss: 0.3378264307975769
Batch 12/64 loss: 0.3423854112625122
Batch 13/64 loss: 0.3393244743347168
Batch 14/64 loss: 0.3369227647781372
Batch 15/64 loss: 0.3385636806488037
Batch 16/64 loss: 0.33763372898101807
Batch 17/64 loss: 0.3378294110298157
Batch 18/64 loss: 0.342551589012146
Batch 19/64 loss: 0.3394564390182495
Batch 20/64 loss: 0.3420588970184326
Batch 21/64 loss: 0.3378729820251465
Batch 22/64 loss: 0.34244871139526367
Batch 23/64 loss: 0.3397133946418762
Batch 24/64 loss: 0.34315502643585205
Batch 25/64 loss: 0.33869004249572754
Batch 26/64 loss: 0.34045588970184326
Batch 27/64 loss: 0.33761322498321533
Batch 28/64 loss: 0.3420976996421814
Batch 29/64 loss: 0.3371269702911377
Batch 30/64 loss: 0.3407493829727173
Batch 31/64 loss: 0.34133368730545044
Batch 32/64 loss: 0.3375619649887085
Batch 33/64 loss: 0.3405057191848755
Batch 34/64 loss: 0.341549813747406
Batch 35/64 loss: 0.34040558338165283
Batch 36/64 loss: 0.33815956115722656
Batch 37/64 loss: 0.34192562103271484
Batch 38/64 loss: 0.33757275342941284
Batch 39/64 loss: 0.3428020477294922
Batch 40/64 loss: 0.34221315383911133
Batch 41/64 loss: 0.33750462532043457
Batch 42/64 loss: 0.33945775032043457
Batch 43/64 loss: 0.3379631042480469
Batch 44/64 loss: 0.3409295678138733
Batch 45/64 loss: 0.3357545733451843
Batch 46/64 loss: 0.33578282594680786
Batch 47/64 loss: 0.34180909395217896
Batch 48/64 loss: 0.3398563265800476
Batch 49/64 loss: 0.33474504947662354
Batch 50/64 loss: 0.33574455976486206
Batch 51/64 loss: 0.3404279947280884
Batch 52/64 loss: 0.3404042720794678
Batch 53/64 loss: 0.338950514793396
Batch 54/64 loss: 0.33592987060546875
Batch 55/64 loss: 0.3359094262123108
Batch 56/64 loss: 0.3425871729850769
Batch 57/64 loss: 0.3393312096595764
Batch 58/64 loss: 0.34013086557388306
Batch 59/64 loss: 0.34113478660583496
Batch 60/64 loss: 0.3420402407646179
Batch 61/64 loss: 0.3424649238586426
Batch 62/64 loss: 0.34123754501342773
Batch 63/64 loss: 0.34320592880249023
Batch 64/64 loss: 0.34034067392349243
Epoch 33  Train loss: 0.3398854599279516  Val loss: 0.3440727122460854
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: 0.339249849319458
Batch 2/64 loss: 0.33295583724975586
Batch 3/64 loss: 0.3415236473083496
Batch 4/64 loss: 0.331574022769928
Batch 5/64 loss: 0.34049975872039795
Batch 6/64 loss: 0.34200429916381836
Batch 7/64 loss: 0.3367948532104492
Batch 8/64 loss: 0.34128957986831665
Batch 9/64 loss: 0.34125661849975586
Batch 10/64 loss: 0.34582728147506714
Batch 11/64 loss: 0.3363361954689026
Batch 12/64 loss: 0.341259241104126
Batch 13/64 loss: 0.3383635878562927
Batch 14/64 loss: 0.3369278907775879
Batch 15/64 loss: 0.3362274169921875
Batch 16/64 loss: 0.3419925570487976
Batch 17/64 loss: 0.33595752716064453
Batch 18/64 loss: 0.33551299571990967
Batch 19/64 loss: 0.3347075581550598
Batch 20/64 loss: 0.3402472734451294
Batch 21/64 loss: 0.34195005893707275
Batch 22/64 loss: 0.337584912776947
Batch 23/64 loss: 0.3386686444282532
Batch 24/64 loss: 0.33791565895080566
Batch 25/64 loss: 0.3449952006340027
Batch 26/64 loss: 0.34189164638519287
Batch 27/64 loss: 0.3432309627532959
Batch 28/64 loss: 0.34039628505706787
Batch 29/64 loss: 0.341198205947876
Batch 30/64 loss: 0.3414020538330078
Batch 31/64 loss: 0.3415592908859253
Batch 32/64 loss: 0.3325939178466797
Batch 33/64 loss: 0.34060120582580566
Batch 34/64 loss: 0.3424745798110962
Batch 35/64 loss: 0.33421361446380615
Batch 36/64 loss: 0.3392716646194458
Batch 37/64 loss: 0.3428294062614441
Batch 38/64 loss: 0.34159815311431885
Batch 39/64 loss: 0.33805525302886963
Batch 40/64 loss: 0.33469367027282715
Batch 41/64 loss: 0.342254638671875
Batch 42/64 loss: 0.3411358594894409
Batch 43/64 loss: 0.3408700227737427
Batch 44/64 loss: 0.3403611183166504
Batch 45/64 loss: 0.33487367630004883
Batch 46/64 loss: 0.3387119770050049
Batch 47/64 loss: 0.33248186111450195
Batch 48/64 loss: 0.33920443058013916
Batch 49/64 loss: 0.3444979190826416
Batch 50/64 loss: 0.33984220027923584
Batch 51/64 loss: 0.3406028747558594
Batch 52/64 loss: 0.3410719037055969
Batch 53/64 loss: 0.33747005462646484
Batch 54/64 loss: 0.3356563448905945
Batch 55/64 loss: 0.34534597396850586
Batch 56/64 loss: 0.3376917839050293
Batch 57/64 loss: 0.33806008100509644
Batch 58/64 loss: 0.34211552143096924
Batch 59/64 loss: 0.3390868902206421
Batch 60/64 loss: 0.33749455213546753
Batch 61/64 loss: 0.33919358253479004
Batch 62/64 loss: 0.3406798243522644
Batch 63/64 loss: 0.33554279804229736
Batch 64/64 loss: 0.3387598991394043
Epoch 34  Train loss: 0.33923055985394646  Val loss: 0.34388237126504434
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: 0.3392007350921631
Batch 2/64 loss: 0.3442138433456421
Batch 3/64 loss: 0.33460474014282227
Batch 4/64 loss: 0.33856284618377686
Batch 5/64 loss: 0.3419310450553894
Batch 6/64 loss: 0.3364381790161133
Batch 7/64 loss: 0.33717358112335205
Batch 8/64 loss: 0.3381109833717346
Batch 9/64 loss: 0.33667266368865967
Batch 10/64 loss: 0.3406810760498047
Batch 11/64 loss: 0.33750081062316895
Batch 12/64 loss: 0.3383840322494507
Batch 13/64 loss: 0.3383854627609253
Batch 14/64 loss: 0.34192830324172974
Batch 15/64 loss: 0.33493900299072266
Batch 16/64 loss: 0.335973858833313
Batch 17/64 loss: 0.3353155851364136
Batch 18/64 loss: 0.33700060844421387
Batch 19/64 loss: 0.3389240503311157
Batch 20/64 loss: 0.34449732303619385
Batch 21/64 loss: 0.3369044065475464
Batch 22/64 loss: 0.3347674012184143
Batch 23/64 loss: 0.33893460035324097
Batch 24/64 loss: 0.3385576009750366
Batch 25/64 loss: 0.33593809604644775
Batch 26/64 loss: 0.33553850650787354
Batch 27/64 loss: 0.3426741361618042
Batch 28/64 loss: 0.3434510827064514
Batch 29/64 loss: 0.3399110436439514
Batch 30/64 loss: 0.34427571296691895
Batch 31/64 loss: 0.3418978452682495
Batch 32/64 loss: 0.339138388633728
Batch 33/64 loss: 0.3403337597846985
Batch 34/64 loss: 0.3363603353500366
Batch 35/64 loss: 0.34545546770095825
Batch 36/64 loss: 0.33614468574523926
Batch 37/64 loss: 0.3376178741455078
Batch 38/64 loss: 0.33823657035827637
Batch 39/64 loss: 0.33603233098983765
Batch 40/64 loss: 0.3411485552787781
Batch 41/64 loss: 0.3366504907608032
Batch 42/64 loss: 0.3389453887939453
Batch 43/64 loss: 0.3366076946258545
Batch 44/64 loss: 0.33693528175354004
Batch 45/64 loss: 0.3398839831352234
Batch 46/64 loss: 0.33930784463882446
Batch 47/64 loss: 0.3317582607269287
Batch 48/64 loss: 0.3439122438430786
Batch 49/64 loss: 0.3361721634864807
Batch 50/64 loss: 0.33169233798980713
Batch 51/64 loss: 0.34271419048309326
Batch 52/64 loss: 0.33516108989715576
Batch 53/64 loss: 0.3338189125061035
Batch 54/64 loss: 0.3417832851409912
Batch 55/64 loss: 0.3403897285461426
Batch 56/64 loss: 0.34146928787231445
Batch 57/64 loss: 0.33904212713241577
Batch 58/64 loss: 0.3417704105377197
Batch 59/64 loss: 0.34172528982162476
Batch 60/64 loss: 0.33951473236083984
Batch 61/64 loss: 0.33834195137023926
Batch 62/64 loss: 0.33656907081604004
Batch 63/64 loss: 0.3381459712982178
Batch 64/64 loss: 0.3401418924331665
Epoch 35  Train loss: 0.33868510255626605  Val loss: 0.34200791190170343
Saving best model, epoch: 35
Epoch 36
-------------------------------
Batch 1/64 loss: 0.3327842354774475
Batch 2/64 loss: 0.33818501234054565
Batch 3/64 loss: 0.3400421142578125
Batch 4/64 loss: 0.3401627540588379
Batch 5/64 loss: 0.3366659879684448
Batch 6/64 loss: 0.33721286058425903
Batch 7/64 loss: 0.34287548065185547
Batch 8/64 loss: 0.3361870050430298
Batch 9/64 loss: 0.3379431962966919
Batch 10/64 loss: 0.3410608768463135
Batch 11/64 loss: 0.339474081993103
Batch 12/64 loss: 0.3406639099121094
Batch 13/64 loss: 0.3414030075073242
Batch 14/64 loss: 0.3368605375289917
Batch 15/64 loss: 0.33891087770462036
Batch 16/64 loss: 0.3378394842147827
Batch 17/64 loss: 0.33552253246307373
Batch 18/64 loss: 0.3432960510253906
Batch 19/64 loss: 0.3390693664550781
Batch 20/64 loss: 0.3374418020248413
Batch 21/64 loss: 0.34014397859573364
Batch 22/64 loss: 0.33998095989227295
Batch 23/64 loss: 0.3417128920555115
Batch 24/64 loss: 0.33135735988616943
Batch 25/64 loss: 0.337527871131897
Batch 26/64 loss: 0.3394145965576172
Batch 27/64 loss: 0.3392866849899292
Batch 28/64 loss: 0.3345649838447571
Batch 29/64 loss: 0.33736586570739746
Batch 30/64 loss: 0.3330641984939575
Batch 31/64 loss: 0.3424755930900574
Batch 32/64 loss: 0.338595986366272
Batch 33/64 loss: 0.33452343940734863
Batch 34/64 loss: 0.33888524770736694
Batch 35/64 loss: 0.3392944931983948
Batch 36/64 loss: 0.3430882692337036
Batch 37/64 loss: 0.34252309799194336
Batch 38/64 loss: 0.33765101432800293
Batch 39/64 loss: 0.33610934019088745
Batch 40/64 loss: 0.3329097628593445
Batch 41/64 loss: 0.33455049991607666
Batch 42/64 loss: 0.342496395111084
Batch 43/64 loss: 0.33782869577407837
Batch 44/64 loss: 0.3414507508277893
Batch 45/64 loss: 0.33699071407318115
Batch 46/64 loss: 0.34246736764907837
Batch 47/64 loss: 0.33364272117614746
Batch 48/64 loss: 0.3303872346878052
Batch 49/64 loss: 0.33745789527893066
Batch 50/64 loss: 0.33985424041748047
Batch 51/64 loss: 0.33564597368240356
Batch 52/64 loss: 0.33717018365859985
Batch 53/64 loss: 0.3477832078933716
Batch 54/64 loss: 0.34043383598327637
Batch 55/64 loss: 0.3420197367668152
Batch 56/64 loss: 0.3385257124900818
Batch 57/64 loss: 0.34017157554626465
Batch 58/64 loss: 0.33384406566619873
Batch 59/64 loss: 0.3367408514022827
Batch 60/64 loss: 0.3371469974517822
Batch 61/64 loss: 0.338290810585022
Batch 62/64 loss: 0.3364347815513611
Batch 63/64 loss: 0.3407125473022461
Batch 64/64 loss: 0.3330153822898865
Epoch 36  Train loss: 0.3382883943763434  Val loss: 0.34087868961681617
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 0.3372119665145874
Batch 2/64 loss: 0.33477360010147095
Batch 3/64 loss: 0.33830487728118896
Batch 4/64 loss: 0.33675694465637207
Batch 5/64 loss: 0.3458132743835449
Batch 6/64 loss: 0.33425045013427734
Batch 7/64 loss: 0.33554768562316895
Batch 8/64 loss: 0.3390793800354004
Batch 9/64 loss: 0.3327651023864746
Batch 10/64 loss: 0.3356269598007202
Batch 11/64 loss: 0.3357614278793335
Batch 12/64 loss: 0.3332141637802124
Batch 13/64 loss: 0.3425934314727783
Batch 14/64 loss: 0.34082329273223877
Batch 15/64 loss: 0.3381531238555908
Batch 16/64 loss: 0.3362218141555786
Batch 17/64 loss: 0.3389309048652649
Batch 18/64 loss: 0.3402218818664551
Batch 19/64 loss: 0.336481511592865
Batch 20/64 loss: 0.3377000689506531
Batch 21/64 loss: 0.3337686061859131
Batch 22/64 loss: 0.3357691168785095
Batch 23/64 loss: 0.33584702014923096
Batch 24/64 loss: 0.337943434715271
Batch 25/64 loss: 0.3317289352416992
Batch 26/64 loss: 0.3369356393814087
Batch 27/64 loss: 0.3382880687713623
Batch 28/64 loss: 0.3416951894760132
Batch 29/64 loss: 0.34054994583129883
Batch 30/64 loss: 0.3377333879470825
Batch 31/64 loss: 0.34085148572921753
Batch 32/64 loss: 0.3345465660095215
Batch 33/64 loss: 0.3344811201095581
Batch 34/64 loss: 0.34089726209640503
Batch 35/64 loss: 0.33666324615478516
Batch 36/64 loss: 0.33689630031585693
Batch 37/64 loss: 0.3428236246109009
Batch 38/64 loss: 0.3415714502334595
Batch 39/64 loss: 0.33785271644592285
Batch 40/64 loss: 0.33936578035354614
Batch 41/64 loss: 0.33523571491241455
Batch 42/64 loss: 0.3361736536026001
Batch 43/64 loss: 0.33817631006240845
Batch 44/64 loss: 0.33894550800323486
Batch 45/64 loss: 0.3340367078781128
Batch 46/64 loss: 0.33414244651794434
Batch 47/64 loss: 0.34140533208847046
Batch 48/64 loss: 0.3366672992706299
Batch 49/64 loss: 0.3392121195793152
Batch 50/64 loss: 0.3371995687484741
Batch 51/64 loss: 0.3325527310371399
Batch 52/64 loss: 0.3361237049102783
Batch 53/64 loss: 0.3379793167114258
Batch 54/64 loss: 0.336483359336853
Batch 55/64 loss: 0.3335200548171997
Batch 56/64 loss: 0.33716702461242676
Batch 57/64 loss: 0.33571159839630127
Batch 58/64 loss: 0.3397332429885864
Batch 59/64 loss: 0.3357582092285156
Batch 60/64 loss: 0.33274662494659424
Batch 61/64 loss: 0.33954161405563354
Batch 62/64 loss: 0.338894248008728
Batch 63/64 loss: 0.33673596382141113
Batch 64/64 loss: 0.3364652395248413
Epoch 37  Train loss: 0.33730089477464265  Val loss: 0.3404199577279107
Saving best model, epoch: 37
Epoch 38
-------------------------------
Batch 1/64 loss: 0.335232138633728
Batch 2/64 loss: 0.33625656366348267
Batch 3/64 loss: 0.33281564712524414
Batch 4/64 loss: 0.3331248164176941
Batch 5/64 loss: 0.3357440233230591
Batch 6/64 loss: 0.3328953981399536
Batch 7/64 loss: 0.3334551453590393
Batch 8/64 loss: 0.3332700729370117
Batch 9/64 loss: 0.3394935727119446
Batch 10/64 loss: 0.3350977897644043
Batch 11/64 loss: 0.33080899715423584
Batch 12/64 loss: 0.34317731857299805
Batch 13/64 loss: 0.3410317897796631
Batch 14/64 loss: 0.33368051052093506
Batch 15/64 loss: 0.33654898405075073
Batch 16/64 loss: 0.33738136291503906
Batch 17/64 loss: 0.34117937088012695
Batch 18/64 loss: 0.33574217557907104
Batch 19/64 loss: 0.3335660696029663
Batch 20/64 loss: 0.33937978744506836
Batch 21/64 loss: 0.3362026810646057
Batch 22/64 loss: 0.3383520841598511
Batch 23/64 loss: 0.3385443091392517
Batch 24/64 loss: 0.33278727531433105
Batch 25/64 loss: 0.3363989591598511
Batch 26/64 loss: 0.3426840305328369
Batch 27/64 loss: 0.3398047089576721
Batch 28/64 loss: 0.33347946405410767
Batch 29/64 loss: 0.33597075939178467
Batch 30/64 loss: 0.33977222442626953
Batch 31/64 loss: 0.3346899151802063
Batch 32/64 loss: 0.33792686462402344
Batch 33/64 loss: 0.34026777744293213
Batch 34/64 loss: 0.34114283323287964
Batch 35/64 loss: 0.3312254548072815
Batch 36/64 loss: 0.33473384380340576
Batch 37/64 loss: 0.3403955101966858
Batch 38/64 loss: 0.33697283267974854
Batch 39/64 loss: 0.3352304697036743
Batch 40/64 loss: 0.3407157063484192
Batch 41/64 loss: 0.33972418308258057
Batch 42/64 loss: 0.3370795249938965
Batch 43/64 loss: 0.3426344394683838
Batch 44/64 loss: 0.3356398344039917
Batch 45/64 loss: 0.3313382863998413
Batch 46/64 loss: 0.3382072448730469
Batch 47/64 loss: 0.34224069118499756
Batch 48/64 loss: 0.33832067251205444
Batch 49/64 loss: 0.3385504484176636
Batch 50/64 loss: 0.3370906710624695
Batch 51/64 loss: 0.3389594554901123
Batch 52/64 loss: 0.3379681706428528
Batch 53/64 loss: 0.3388073444366455
Batch 54/64 loss: 0.3314014673233032
Batch 55/64 loss: 0.3349496126174927
Batch 56/64 loss: 0.33455049991607666
Batch 57/64 loss: 0.3342158794403076
Batch 58/64 loss: 0.3335118293762207
Batch 59/64 loss: 0.3393183946609497
Batch 60/64 loss: 0.3328225612640381
Batch 61/64 loss: 0.33934903144836426
Batch 62/64 loss: 0.3352753520011902
Batch 63/64 loss: 0.33713334798812866
Batch 64/64 loss: 0.3374830484390259
Epoch 38  Train loss: 0.3367745955785116  Val loss: 0.3395161591854292
Saving best model, epoch: 38
Epoch 39
-------------------------------
Batch 1/64 loss: 0.3355163335800171
Batch 2/64 loss: 0.33738183975219727
Batch 3/64 loss: 0.33266544342041016
Batch 4/64 loss: 0.33305346965789795
Batch 5/64 loss: 0.3339507579803467
Batch 6/64 loss: 0.3352147340774536
Batch 7/64 loss: 0.3335809111595154
Batch 8/64 loss: 0.33676815032958984
Batch 9/64 loss: 0.3364368677139282
Batch 10/64 loss: 0.33626431226730347
Batch 11/64 loss: 0.3351594805717468
Batch 12/64 loss: 0.333690345287323
Batch 13/64 loss: 0.33484339714050293
Batch 14/64 loss: 0.3387256860733032
Batch 15/64 loss: 0.33332252502441406
Batch 16/64 loss: 0.3351747989654541
Batch 17/64 loss: 0.3428831696510315
Batch 18/64 loss: 0.3343653678894043
Batch 19/64 loss: 0.33585137128829956
Batch 20/64 loss: 0.3386574387550354
Batch 21/64 loss: 0.33224666118621826
Batch 22/64 loss: 0.3341658115386963
Batch 23/64 loss: 0.33351874351501465
Batch 24/64 loss: 0.3383209705352783
Batch 25/64 loss: 0.3417568802833557
Batch 26/64 loss: 0.34035634994506836
Batch 27/64 loss: 0.33378690481185913
Batch 28/64 loss: 0.3373297452926636
Batch 29/64 loss: 0.33739930391311646
Batch 30/64 loss: 0.3350696563720703
Batch 31/64 loss: 0.3370070457458496
Batch 32/64 loss: 0.33591002225875854
Batch 33/64 loss: 0.3321685194969177
Batch 34/64 loss: 0.3338891863822937
Batch 35/64 loss: 0.3403502106666565
Batch 36/64 loss: 0.3379729986190796
Batch 37/64 loss: 0.33357906341552734
Batch 38/64 loss: 0.3426424264907837
Batch 39/64 loss: 0.33484435081481934
Batch 40/64 loss: 0.3336606025695801
Batch 41/64 loss: 0.33271586894989014
Batch 42/64 loss: 0.3365379571914673
Batch 43/64 loss: 0.33622753620147705
Batch 44/64 loss: 0.3342430591583252
Batch 45/64 loss: 0.33370113372802734
Batch 46/64 loss: 0.3360024690628052
Batch 47/64 loss: 0.3378032445907593
Batch 48/64 loss: 0.33756840229034424
Batch 49/64 loss: 0.3340531587600708
Batch 50/64 loss: 0.3345677852630615
Batch 51/64 loss: 0.33844560384750366
Batch 52/64 loss: 0.3342972993850708
Batch 53/64 loss: 0.33791130781173706
Batch 54/64 loss: 0.33947837352752686
Batch 55/64 loss: 0.33669841289520264
Batch 56/64 loss: 0.3340263366699219
Batch 57/64 loss: 0.33898699283599854
Batch 58/64 loss: 0.33256930112838745
Batch 59/64 loss: 0.33701980113983154
Batch 60/64 loss: 0.3374168872833252
Batch 61/64 loss: 0.3329075574874878
Batch 62/64 loss: 0.3359055519104004
Batch 63/64 loss: 0.3383733034133911
Batch 64/64 loss: 0.3295348882675171
Epoch 39  Train loss: 0.3359072998458264  Val loss: 0.3395198348051904
Epoch 40
-------------------------------
Batch 1/64 loss: 0.3338487148284912
Batch 2/64 loss: 0.3338621258735657
Batch 3/64 loss: 0.3420218825340271
Batch 4/64 loss: 0.33571624755859375
Batch 5/64 loss: 0.33637547492980957
Batch 6/64 loss: 0.33674609661102295
Batch 7/64 loss: 0.33488965034484863
Batch 8/64 loss: 0.3314396142959595
Batch 9/64 loss: 0.3378492593765259
Batch 10/64 loss: 0.33536863327026367
Batch 11/64 loss: 0.33527421951293945
Batch 12/64 loss: 0.3357943296432495
Batch 13/64 loss: 0.33768969774246216
Batch 14/64 loss: 0.33533143997192383
Batch 15/64 loss: 0.3287334442138672
Batch 16/64 loss: 0.32984399795532227
Batch 17/64 loss: 0.33473730087280273
Batch 18/64 loss: 0.3362271785736084
Batch 19/64 loss: 0.33588021993637085
Batch 20/64 loss: 0.33196866512298584
Batch 21/64 loss: 0.3373543620109558
Batch 22/64 loss: 0.3332291841506958
Batch 23/64 loss: 0.3304945230484009
Batch 24/64 loss: 0.33455491065979004
Batch 25/64 loss: 0.3305824398994446
Batch 26/64 loss: 0.3370596170425415
Batch 27/64 loss: 0.3414088487625122
Batch 28/64 loss: 0.3399989604949951
Batch 29/64 loss: 0.3357200026512146
Batch 30/64 loss: 0.3349955677986145
Batch 31/64 loss: 0.34053516387939453
Batch 32/64 loss: 0.3386514186859131
Batch 33/64 loss: 0.3352065086364746
Batch 34/64 loss: 0.33851730823516846
Batch 35/64 loss: 0.3344038724899292
Batch 36/64 loss: 0.33442264795303345
Batch 37/64 loss: 0.3413954973220825
Batch 38/64 loss: 0.33690202236175537
Batch 39/64 loss: 0.3404000997543335
Batch 40/64 loss: 0.3336876630783081
Batch 41/64 loss: 0.33497869968414307
Batch 42/64 loss: 0.33810073137283325
Batch 43/64 loss: 0.3332958221435547
Batch 44/64 loss: 0.3336458206176758
Batch 45/64 loss: 0.33729785680770874
Batch 46/64 loss: 0.3339378833770752
Batch 47/64 loss: 0.33486688137054443
Batch 48/64 loss: 0.3365635871887207
Batch 49/64 loss: 0.3359038233757019
Batch 50/64 loss: 0.33622288703918457
Batch 51/64 loss: 0.33059370517730713
Batch 52/64 loss: 0.34145253896713257
Batch 53/64 loss: 0.3338797092437744
Batch 54/64 loss: 0.33216631412506104
Batch 55/64 loss: 0.33711719512939453
Batch 56/64 loss: 0.3430017828941345
Batch 57/64 loss: 0.33598780632019043
Batch 58/64 loss: 0.33500027656555176
Batch 59/64 loss: 0.33539652824401855
Batch 60/64 loss: 0.33264559507369995
Batch 61/64 loss: 0.33943498134613037
Batch 62/64 loss: 0.33398115634918213
Batch 63/64 loss: 0.33527660369873047
Batch 64/64 loss: 0.3299773931503296
Epoch 40  Train loss: 0.3356447065577787  Val loss: 0.33897797246159556
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: 0.3308139443397522
Batch 2/64 loss: 0.3316948413848877
Batch 3/64 loss: 0.3349374532699585
Batch 4/64 loss: 0.32977449893951416
Batch 5/64 loss: 0.3275490999221802
Batch 6/64 loss: 0.3330349922180176
Batch 7/64 loss: 0.333743691444397
Batch 8/64 loss: 0.3335026502609253
Batch 9/64 loss: 0.3371497392654419
Batch 10/64 loss: 0.3315821886062622
Batch 11/64 loss: 0.3349643349647522
Batch 12/64 loss: 0.331085205078125
Batch 13/64 loss: 0.33692383766174316
Batch 14/64 loss: 0.33064115047454834
Batch 15/64 loss: 0.33269941806793213
Batch 16/64 loss: 0.3355281352996826
Batch 17/64 loss: 0.3305089473724365
Batch 18/64 loss: 0.33286231756210327
Batch 19/64 loss: 0.3353387117385864
Batch 20/64 loss: 0.3309311866760254
Batch 21/64 loss: 0.33828556537628174
Batch 22/64 loss: 0.33737266063690186
Batch 23/64 loss: 0.3362917900085449
Batch 24/64 loss: 0.3347381353378296
Batch 25/64 loss: 0.3335670232772827
Batch 26/64 loss: 0.3383636474609375
Batch 27/64 loss: 0.33027517795562744
Batch 28/64 loss: 0.33189088106155396
Batch 29/64 loss: 0.32973045110702515
Batch 30/64 loss: 0.33987778425216675
Batch 31/64 loss: 0.33627259731292725
Batch 32/64 loss: 0.33518290519714355
Batch 33/64 loss: 0.3341190218925476
Batch 34/64 loss: 0.3350244164466858
Batch 35/64 loss: 0.3373734951019287
Batch 36/64 loss: 0.3336993455886841
Batch 37/64 loss: 0.3339495062828064
Batch 38/64 loss: 0.3339637517929077
Batch 39/64 loss: 0.3331722021102905
Batch 40/64 loss: 0.33884644508361816
Batch 41/64 loss: 0.33907419443130493
Batch 42/64 loss: 0.331678569316864
Batch 43/64 loss: 0.3354303240776062
Batch 44/64 loss: 0.33738279342651367
Batch 45/64 loss: 0.3324962258338928
Batch 46/64 loss: 0.3392314910888672
Batch 47/64 loss: 0.3329848051071167
Batch 48/64 loss: 0.3344084620475769
Batch 49/64 loss: 0.33820831775665283
Batch 50/64 loss: 0.33524954319000244
Batch 51/64 loss: 0.33399200439453125
Batch 52/64 loss: 0.33329737186431885
Batch 53/64 loss: 0.3351162075996399
Batch 54/64 loss: 0.3399820923805237
Batch 55/64 loss: 0.3358362913131714
Batch 56/64 loss: 0.3373284339904785
Batch 57/64 loss: 0.328031063079834
Batch 58/64 loss: 0.33021974563598633
Batch 59/64 loss: 0.3389759063720703
Batch 60/64 loss: 0.3342663049697876
Batch 61/64 loss: 0.33024322986602783
Batch 62/64 loss: 0.3376670479774475
Batch 63/64 loss: 0.3353390693664551
Batch 64/64 loss: 0.3326096534729004
Epoch 41  Train loss: 0.3343240765964284  Val loss: 0.3399890427736892
Epoch 42
-------------------------------
Batch 1/64 loss: 0.3376654386520386
Batch 2/64 loss: 0.3439316749572754
Batch 3/64 loss: 0.3302464485168457
Batch 4/64 loss: 0.337840735912323
Batch 5/64 loss: 0.3377842307090759
Batch 6/64 loss: 0.33418381214141846
Batch 7/64 loss: 0.33285558223724365
Batch 8/64 loss: 0.33259880542755127
Batch 9/64 loss: 0.33594298362731934
Batch 10/64 loss: 0.33298397064208984
Batch 11/64 loss: 0.33105164766311646
Batch 12/64 loss: 0.3320099115371704
Batch 13/64 loss: 0.3377062678337097
Batch 14/64 loss: 0.33201783895492554
Batch 15/64 loss: 0.3381877541542053
Batch 16/64 loss: 0.334500789642334
Batch 17/64 loss: 0.328991174697876
Batch 18/64 loss: 0.3383086919784546
Batch 19/64 loss: 0.331906795501709
Batch 20/64 loss: 0.3338119387626648
Batch 21/64 loss: 0.3364938497543335
Batch 22/64 loss: 0.3341364860534668
Batch 23/64 loss: 0.33466625213623047
Batch 24/64 loss: 0.3300982713699341
Batch 25/64 loss: 0.3296390771865845
Batch 26/64 loss: 0.33364731073379517
Batch 27/64 loss: 0.32480114698410034
Batch 28/64 loss: 0.3336866497993469
Batch 29/64 loss: 0.32548046112060547
Batch 30/64 loss: 0.33521056175231934
Batch 31/64 loss: 0.33737802505493164
Batch 32/64 loss: 0.341377854347229
Batch 33/64 loss: 0.33521634340286255
Batch 34/64 loss: 0.33266234397888184
Batch 35/64 loss: 0.3355805277824402
Batch 36/64 loss: 0.3284286856651306
Batch 37/64 loss: 0.33259832859039307
Batch 38/64 loss: 0.33596259355545044
Batch 39/64 loss: 0.330025315284729
Batch 40/64 loss: 0.3348439335823059
Batch 41/64 loss: 0.329903244972229
Batch 42/64 loss: 0.32980334758758545
Batch 43/64 loss: 0.3353530168533325
Batch 44/64 loss: 0.33829665184020996
Batch 45/64 loss: 0.33400601148605347
Batch 46/64 loss: 0.33316510915756226
Batch 47/64 loss: 0.32514244318008423
Batch 48/64 loss: 0.3351781368255615
Batch 49/64 loss: 0.33628928661346436
Batch 50/64 loss: 0.3282428979873657
Batch 51/64 loss: 0.3352762460708618
Batch 52/64 loss: 0.33849960565567017
Batch 53/64 loss: 0.3300151824951172
Batch 54/64 loss: 0.334067702293396
Batch 55/64 loss: 0.33591198921203613
Batch 56/64 loss: 0.33054113388061523
Batch 57/64 loss: 0.3372691869735718
Batch 58/64 loss: 0.3339136838912964
Batch 59/64 loss: 0.3366479277610779
Batch 60/64 loss: 0.3330780267715454
Batch 61/64 loss: 0.3329489827156067
Batch 62/64 loss: 0.33237147331237793
Batch 63/64 loss: 0.32842516899108887
Batch 64/64 loss: 0.3294220566749573
Epoch 42  Train loss: 0.3336137021289152  Val loss: 0.3369907886301939
Saving best model, epoch: 42
Epoch 43
-------------------------------
Batch 1/64 loss: 0.3352506160736084
Batch 2/64 loss: 0.33355480432510376
Batch 3/64 loss: 0.33532047271728516
Batch 4/64 loss: 0.32503485679626465
Batch 5/64 loss: 0.3343958854675293
Batch 6/64 loss: 0.3262244462966919
Batch 7/64 loss: 0.332381010055542
Batch 8/64 loss: 0.33461886644363403
Batch 9/64 loss: 0.33752310276031494
Batch 10/64 loss: 0.3299974203109741
Batch 11/64 loss: 0.3304394483566284
Batch 12/64 loss: 0.33192944526672363
Batch 13/64 loss: 0.3342015743255615
Batch 14/64 loss: 0.33779066801071167
Batch 15/64 loss: 0.33361947536468506
Batch 16/64 loss: 0.3321155309677124
Batch 17/64 loss: 0.3356958031654358
Batch 18/64 loss: 0.33439385890960693
Batch 19/64 loss: 0.3368806838989258
Batch 20/64 loss: 0.3342432379722595
Batch 21/64 loss: 0.33372628688812256
Batch 22/64 loss: 0.33170580863952637
Batch 23/64 loss: 0.3378850221633911
Batch 24/64 loss: 0.3316408395767212
Batch 25/64 loss: 0.33330976963043213
Batch 26/64 loss: 0.3262587785720825
Batch 27/64 loss: 0.3342974781990051
Batch 28/64 loss: 0.3388504385948181
Batch 29/64 loss: 0.33455324172973633
Batch 30/64 loss: 0.32944005727767944
Batch 31/64 loss: 0.33722227811813354
Batch 32/64 loss: 0.3363765478134155
Batch 33/64 loss: 0.3294113874435425
Batch 34/64 loss: 0.3310365080833435
Batch 35/64 loss: 0.33169353008270264
Batch 36/64 loss: 0.33654147386550903
Batch 37/64 loss: 0.33851921558380127
Batch 38/64 loss: 0.32991135120391846
Batch 39/64 loss: 0.33146917819976807
Batch 40/64 loss: 0.32705211639404297
Batch 41/64 loss: 0.3274341821670532
Batch 42/64 loss: 0.3313714265823364
Batch 43/64 loss: 0.33199620246887207
Batch 44/64 loss: 0.33329713344573975
Batch 45/64 loss: 0.3325996398925781
Batch 46/64 loss: 0.332690954208374
Batch 47/64 loss: 0.33085155487060547
Batch 48/64 loss: 0.33275824785232544
Batch 49/64 loss: 0.3323194980621338
Batch 50/64 loss: 0.3330158591270447
Batch 51/64 loss: 0.33337438106536865
Batch 52/64 loss: 0.33707571029663086
Batch 53/64 loss: 0.32935214042663574
Batch 54/64 loss: 0.33382296562194824
Batch 55/64 loss: 0.3303907513618469
Batch 56/64 loss: 0.33166658878326416
Batch 57/64 loss: 0.33499598503112793
Batch 58/64 loss: 0.3315255045890808
Batch 59/64 loss: 0.3303234577178955
Batch 60/64 loss: 0.3287413716316223
Batch 61/64 loss: 0.332159161567688
Batch 62/64 loss: 0.33059966564178467
Batch 63/64 loss: 0.332206130027771
Batch 64/64 loss: 0.33828747272491455
Epoch 43  Train loss: 0.33278112364750284  Val loss: 0.3373789598851679
Epoch 44
-------------------------------
Batch 1/64 loss: 0.3264334797859192
Batch 2/64 loss: 0.3360940217971802
Batch 3/64 loss: 0.33000612258911133
Batch 4/64 loss: 0.335288405418396
Batch 5/64 loss: 0.333221971988678
Batch 6/64 loss: 0.3376914858818054
Batch 7/64 loss: 0.33459770679473877
Batch 8/64 loss: 0.32964062690734863
Batch 9/64 loss: 0.3316534757614136
Batch 10/64 loss: 0.3312026262283325
Batch 11/64 loss: 0.3303508162498474
Batch 12/64 loss: 0.32519352436065674
Batch 13/64 loss: 0.333598792552948
Batch 14/64 loss: 0.33147215843200684
Batch 15/64 loss: 0.32695430517196655
Batch 16/64 loss: 0.33484703302383423
Batch 17/64 loss: 0.3286924362182617
Batch 18/64 loss: 0.3334507942199707
Batch 19/64 loss: 0.3362351059913635
Batch 20/64 loss: 0.33571338653564453
Batch 21/64 loss: 0.33822381496429443
Batch 22/64 loss: 0.33680200576782227
Batch 23/64 loss: 0.33085042238235474
Batch 24/64 loss: 0.33038830757141113
Batch 25/64 loss: 0.3310335874557495
Batch 26/64 loss: 0.33687329292297363
Batch 27/64 loss: 0.3355001211166382
Batch 28/64 loss: 0.3361860513687134
Batch 29/64 loss: 0.33179253339767456
Batch 30/64 loss: 0.3329758048057556
Batch 31/64 loss: 0.3325592279434204
Batch 32/64 loss: 0.33350831270217896
Batch 33/64 loss: 0.32915163040161133
Batch 34/64 loss: 0.3318742513656616
Batch 35/64 loss: 0.33184921741485596
Batch 36/64 loss: 0.332492470741272
Batch 37/64 loss: 0.33155715465545654
Batch 38/64 loss: 0.33612072467803955
Batch 39/64 loss: 0.3266121745109558
Batch 40/64 loss: 0.33238035440444946
Batch 41/64 loss: 0.33603912591934204
Batch 42/64 loss: 0.3290051817893982
Batch 43/64 loss: 0.33200645446777344
Batch 44/64 loss: 0.33150362968444824
Batch 45/64 loss: 0.3306446671485901
Batch 46/64 loss: 0.3351469039916992
Batch 47/64 loss: 0.3340527415275574
Batch 48/64 loss: 0.3301140069961548
Batch 49/64 loss: 0.33360129594802856
Batch 50/64 loss: 0.33126187324523926
Batch 51/64 loss: 0.32961463928222656
Batch 52/64 loss: 0.32917845249176025
Batch 53/64 loss: 0.32943153381347656
Batch 54/64 loss: 0.3282428979873657
Batch 55/64 loss: 0.32940757274627686
Batch 56/64 loss: 0.32139480113983154
Batch 57/64 loss: 0.32706165313720703
Batch 58/64 loss: 0.3295888900756836
Batch 59/64 loss: 0.328937292098999
Batch 60/64 loss: 0.32963675260543823
Batch 61/64 loss: 0.33089685440063477
Batch 62/64 loss: 0.3352658152580261
Batch 63/64 loss: 0.33309948444366455
Batch 64/64 loss: 0.3287407159805298
Epoch 44  Train loss: 0.33180796539082247  Val loss: 0.3355961911047447
Saving best model, epoch: 44
Epoch 45
-------------------------------
Batch 1/64 loss: 0.3276940584182739
Batch 2/64 loss: 0.33615642786026
Batch 3/64 loss: 0.32880091667175293
Batch 4/64 loss: 0.3283197283744812
Batch 5/64 loss: 0.3334606885910034
Batch 6/64 loss: 0.33006584644317627
Batch 7/64 loss: 0.32914483547210693
Batch 8/64 loss: 0.32837045192718506
Batch 9/64 loss: 0.33806848526000977
Batch 10/64 loss: 0.3337571620941162
Batch 11/64 loss: 0.3365747332572937
Batch 12/64 loss: 0.32502955198287964
Batch 13/64 loss: 0.32934945821762085
Batch 14/64 loss: 0.3305431008338928
Batch 15/64 loss: 0.3277088403701782
Batch 16/64 loss: 0.32605457305908203
Batch 17/64 loss: 0.3352165222167969
Batch 18/64 loss: 0.3327571153640747
Batch 19/64 loss: 0.33300602436065674
Batch 20/64 loss: 0.3364604115486145
Batch 21/64 loss: 0.3324751853942871
Batch 22/64 loss: 0.33451199531555176
Batch 23/64 loss: 0.335770845413208
Batch 24/64 loss: 0.32671165466308594
Batch 25/64 loss: 0.3304826617240906
Batch 26/64 loss: 0.33035528659820557
Batch 27/64 loss: 0.3369332551956177
Batch 28/64 loss: 0.3271380662918091
Batch 29/64 loss: 0.3381335735321045
Batch 30/64 loss: 0.3308916687965393
Batch 31/64 loss: 0.3317309021949768
Batch 32/64 loss: 0.3290184736251831
Batch 33/64 loss: 0.3351075053215027
Batch 34/64 loss: 0.32876336574554443
Batch 35/64 loss: 0.32933926582336426
Batch 36/64 loss: 0.32966792583465576
Batch 37/64 loss: 0.3328845500946045
Batch 38/64 loss: 0.33358705043792725
Batch 39/64 loss: 0.3319278955459595
Batch 40/64 loss: 0.33175933361053467
Batch 41/64 loss: 0.33144694566726685
Batch 42/64 loss: 0.3342163562774658
Batch 43/64 loss: 0.3282366991043091
Batch 44/64 loss: 0.3329530954360962
Batch 45/64 loss: 0.3302772641181946
Batch 46/64 loss: 0.3353872299194336
Batch 47/64 loss: 0.3366018533706665
Batch 48/64 loss: 0.3312150239944458
Batch 49/64 loss: 0.3325697183609009
Batch 50/64 loss: 0.32798147201538086
Batch 51/64 loss: 0.3328969478607178
Batch 52/64 loss: 0.32824504375457764
Batch 53/64 loss: 0.33367598056793213
Batch 54/64 loss: 0.3258373737335205
Batch 55/64 loss: 0.33031463623046875
Batch 56/64 loss: 0.33598577976226807
Batch 57/64 loss: 0.32936882972717285
Batch 58/64 loss: 0.333442747592926
Batch 59/64 loss: 0.3277353048324585
Batch 60/64 loss: 0.3299594521522522
Batch 61/64 loss: 0.3314340114593506
Batch 62/64 loss: 0.33442628383636475
Batch 63/64 loss: 0.3360888957977295
Batch 64/64 loss: 0.3308623433113098
Epoch 45  Train loss: 0.33164193092607985  Val loss: 0.3357298955884586
Epoch 46
-------------------------------
Batch 1/64 loss: 0.3323993682861328
Batch 2/64 loss: 0.3287733793258667
Batch 3/64 loss: 0.3260529041290283
Batch 4/64 loss: 0.3315465450286865
Batch 5/64 loss: 0.32466959953308105
Batch 6/64 loss: 0.3289220929145813
Batch 7/64 loss: 0.3266981840133667
Batch 8/64 loss: 0.33141469955444336
Batch 9/64 loss: 0.32915323972702026
Batch 10/64 loss: 0.3295740485191345
Batch 11/64 loss: 0.3267737030982971
Batch 12/64 loss: 0.33452296257019043
Batch 13/64 loss: 0.32998770475387573
Batch 14/64 loss: 0.3321312665939331
Batch 15/64 loss: 0.33133870363235474
Batch 16/64 loss: 0.33169955015182495
Batch 17/64 loss: 0.3331291675567627
Batch 18/64 loss: 0.3315153121948242
Batch 19/64 loss: 0.33111488819122314
Batch 20/64 loss: 0.33014047145843506
Batch 21/64 loss: 0.3256218433380127
Batch 22/64 loss: 0.3307915925979614
Batch 23/64 loss: 0.3313101530075073
Batch 24/64 loss: 0.3302488923072815
Batch 25/64 loss: 0.3332352638244629
Batch 26/64 loss: 0.33302855491638184
Batch 27/64 loss: 0.3338550329208374
Batch 28/64 loss: 0.33265459537506104
Batch 29/64 loss: 0.3337782621383667
Batch 30/64 loss: 0.32778918743133545
Batch 31/64 loss: 0.3327692747116089
Batch 32/64 loss: 0.3285561800003052
Batch 33/64 loss: 0.3324428200721741
Batch 34/64 loss: 0.335101842880249
Batch 35/64 loss: 0.3295730948448181
Batch 36/64 loss: 0.3260791301727295
Batch 37/64 loss: 0.3289642930030823
Batch 38/64 loss: 0.3235814571380615
Batch 39/64 loss: 0.32879531383514404
Batch 40/64 loss: 0.33421897888183594
Batch 41/64 loss: 0.3306688070297241
Batch 42/64 loss: 0.3316037654876709
Batch 43/64 loss: 0.3367403745651245
Batch 44/64 loss: 0.33317697048187256
Batch 45/64 loss: 0.32681626081466675
Batch 46/64 loss: 0.33000093698501587
Batch 47/64 loss: 0.3280588984489441
Batch 48/64 loss: 0.3274707794189453
Batch 49/64 loss: 0.3265937566757202
Batch 50/64 loss: 0.3318225145339966
Batch 51/64 loss: 0.32722246646881104
Batch 52/64 loss: 0.326526939868927
Batch 53/64 loss: 0.3290269374847412
Batch 54/64 loss: 0.3303787112236023
Batch 55/64 loss: 0.32779228687286377
Batch 56/64 loss: 0.3304134011268616
Batch 57/64 loss: 0.3286094665527344
Batch 58/64 loss: 0.3312535881996155
Batch 59/64 loss: 0.33300328254699707
Batch 60/64 loss: 0.3317025899887085
Batch 61/64 loss: 0.3297629952430725
Batch 62/64 loss: 0.32654649019241333
Batch 63/64 loss: 0.33311593532562256
Batch 64/64 loss: 0.33496028184890747
Epoch 46  Train loss: 0.33025069680868413  Val loss: 0.33408895513855713
Saving best model, epoch: 46
Epoch 47
-------------------------------
Batch 1/64 loss: 0.3292640447616577
Batch 2/64 loss: 0.32660311460494995
Batch 3/64 loss: 0.3308243751525879
Batch 4/64 loss: 0.3283296823501587
Batch 5/64 loss: 0.32968324422836304
Batch 6/64 loss: 0.32909464836120605
Batch 7/64 loss: 0.3302697539329529
Batch 8/64 loss: 0.328460693359375
Batch 9/64 loss: 0.3250730037689209
Batch 10/64 loss: 0.32881617546081543
Batch 11/64 loss: 0.32429444789886475
Batch 12/64 loss: 0.33506208658218384
Batch 13/64 loss: 0.3278714418411255
Batch 14/64 loss: 0.325223445892334
Batch 15/64 loss: 0.33223211765289307
Batch 16/64 loss: 0.32376712560653687
Batch 17/64 loss: 0.3265349268913269
Batch 18/64 loss: 0.32598984241485596
Batch 19/64 loss: 0.3306429982185364
Batch 20/64 loss: 0.32484304904937744
Batch 21/64 loss: 0.3240950107574463
Batch 22/64 loss: 0.3273085355758667
Batch 23/64 loss: 0.33390361070632935
Batch 24/64 loss: 0.33082741498947144
Batch 25/64 loss: 0.32738733291625977
Batch 26/64 loss: 0.33054161071777344
Batch 27/64 loss: 0.3298003077507019
Batch 28/64 loss: 0.3297228217124939
Batch 29/64 loss: 0.332033634185791
Batch 30/64 loss: 0.3379138708114624
Batch 31/64 loss: 0.32770848274230957
Batch 32/64 loss: 0.33056366443634033
Batch 33/64 loss: 0.3298298120498657
Batch 34/64 loss: 0.3282029628753662
Batch 35/64 loss: 0.33329784870147705
Batch 36/64 loss: 0.3240658640861511
Batch 37/64 loss: 0.3282890319824219
Batch 38/64 loss: 0.3251384496688843
Batch 39/64 loss: 0.32468247413635254
Batch 40/64 loss: 0.32634657621383667
Batch 41/64 loss: 0.32964450120925903
Batch 42/64 loss: 0.3338630199432373
Batch 43/64 loss: 0.32932937145233154
Batch 44/64 loss: 0.3314542770385742
Batch 45/64 loss: 0.3305155038833618
Batch 46/64 loss: 0.32709527015686035
Batch 47/64 loss: 0.32424724102020264
Batch 48/64 loss: 0.32640349864959717
Batch 49/64 loss: 0.33179938793182373
Batch 50/64 loss: 0.33159011602401733
Batch 51/64 loss: 0.32350462675094604
Batch 52/64 loss: 0.3376462459564209
Batch 53/64 loss: 0.33187752962112427
Batch 54/64 loss: 0.32843250036239624
Batch 55/64 loss: 0.325813353061676
Batch 56/64 loss: 0.3282495141029358
Batch 57/64 loss: 0.3307858109474182
Batch 58/64 loss: 0.3329721689224243
Batch 59/64 loss: 0.3221953511238098
Batch 60/64 loss: 0.3269212245941162
Batch 61/64 loss: 0.331787109375
Batch 62/64 loss: 0.3223384618759155
Batch 63/64 loss: 0.3298882842063904
Batch 64/64 loss: 0.32718604803085327
Epoch 47  Train loss: 0.3287573872828016  Val loss: 0.33311691153090434
Saving best model, epoch: 47
Epoch 48
-------------------------------
Batch 1/64 loss: 0.3303595781326294
Batch 2/64 loss: 0.3231830596923828
Batch 3/64 loss: 0.33197659254074097
Batch 4/64 loss: 0.3284883499145508
Batch 5/64 loss: 0.33518874645233154
Batch 6/64 loss: 0.3269009590148926
Batch 7/64 loss: 0.33192068338394165
Batch 8/64 loss: 0.3318786025047302
Batch 9/64 loss: 0.3261798620223999
Batch 10/64 loss: 0.32768362760543823
Batch 11/64 loss: 0.32592910528182983
Batch 12/64 loss: 0.32181739807128906
Batch 13/64 loss: 0.3274010419845581
Batch 14/64 loss: 0.3257228136062622
Batch 15/64 loss: 0.32824182510375977
Batch 16/64 loss: 0.33319443464279175
Batch 17/64 loss: 0.3274737596511841
Batch 18/64 loss: 0.32054662704467773
Batch 19/64 loss: 0.3223297595977783
Batch 20/64 loss: 0.32528436183929443
Batch 21/64 loss: 0.33208298683166504
Batch 22/64 loss: 0.3286980390548706
Batch 23/64 loss: 0.33304738998413086
Batch 24/64 loss: 0.32860755920410156
Batch 25/64 loss: 0.3234966993331909
Batch 26/64 loss: 0.3335012197494507
Batch 27/64 loss: 0.3267195224761963
Batch 28/64 loss: 0.3265269994735718
Batch 29/64 loss: 0.3282056450843811
Batch 30/64 loss: 0.32528531551361084
Batch 31/64 loss: 0.3294534683227539
Batch 32/64 loss: 0.3233630657196045
Batch 33/64 loss: 0.3270782232284546
Batch 34/64 loss: 0.3232489824295044
Batch 35/64 loss: 0.3267849087715149
Batch 36/64 loss: 0.32373344898223877
Batch 37/64 loss: 0.32674920558929443
Batch 38/64 loss: 0.3327367305755615
Batch 39/64 loss: 0.32243072986602783
Batch 40/64 loss: 0.3260692358016968
Batch 41/64 loss: 0.32763683795928955
Batch 42/64 loss: 0.3299393653869629
Batch 43/64 loss: 0.3228911757469177
Batch 44/64 loss: 0.3251066207885742
Batch 45/64 loss: 0.32384192943573
Batch 46/64 loss: 0.32663512229919434
Batch 47/64 loss: 0.32906097173690796
Batch 48/64 loss: 0.3258988857269287
Batch 49/64 loss: 0.33380138874053955
Batch 50/64 loss: 0.32971781492233276
Batch 51/64 loss: 0.32441043853759766
Batch 52/64 loss: 0.3308129906654358
Batch 53/64 loss: 0.3267883062362671
Batch 54/64 loss: 0.32820427417755127
Batch 55/64 loss: 0.3340635299682617
Batch 56/64 loss: 0.3308711051940918
Batch 57/64 loss: 0.3262820243835449
Batch 58/64 loss: 0.32375937700271606
Batch 59/64 loss: 0.32699209451675415
Batch 60/64 loss: 0.3239569664001465
Batch 61/64 loss: 0.3309735059738159
Batch 62/64 loss: 0.32899177074432373
Batch 63/64 loss: 0.3289823532104492
Batch 64/64 loss: 0.3391174077987671
Epoch 48  Train loss: 0.32774082305384616  Val loss: 0.333814249005924
Epoch 49
-------------------------------
Batch 1/64 loss: 0.32837772369384766
Batch 2/64 loss: 0.3258647918701172
Batch 3/64 loss: 0.32998883724212646
Batch 4/64 loss: 0.3271348476409912
Batch 5/64 loss: 0.326465368270874
Batch 6/64 loss: 0.32043468952178955
Batch 7/64 loss: 0.3297464847564697
Batch 8/64 loss: 0.3223887085914612
Batch 9/64 loss: 0.3301176428794861
Batch 10/64 loss: 0.33257901668548584
Batch 11/64 loss: 0.3276493549346924
Batch 12/64 loss: 0.3250107765197754
Batch 13/64 loss: 0.3276386260986328
Batch 14/64 loss: 0.3210642337799072
Batch 15/64 loss: 0.3240355849266052
Batch 16/64 loss: 0.32427096366882324
Batch 17/64 loss: 0.3322625160217285
Batch 18/64 loss: 0.320712685585022
Batch 19/64 loss: 0.333359956741333
Batch 20/64 loss: 0.32147741317749023
Batch 21/64 loss: 0.3241879343986511
Batch 22/64 loss: 0.3327452540397644
Batch 23/64 loss: 0.33281028270721436
Batch 24/64 loss: 0.3252190947532654
Batch 25/64 loss: 0.3227693438529968
Batch 26/64 loss: 0.3268176317214966
Batch 27/64 loss: 0.3295503854751587
Batch 28/64 loss: 0.3279917240142822
Batch 29/64 loss: 0.32153284549713135
Batch 30/64 loss: 0.32130104303359985
Batch 31/64 loss: 0.32363641262054443
Batch 32/64 loss: 0.33157050609588623
Batch 33/64 loss: 0.324349045753479
Batch 34/64 loss: 0.32481473684310913
Batch 35/64 loss: 0.32527923583984375
Batch 36/64 loss: 0.32459598779678345
Batch 37/64 loss: 0.32446157932281494
Batch 38/64 loss: 0.32431674003601074
Batch 39/64 loss: 0.32951444387435913
Batch 40/64 loss: 0.32836973667144775
Batch 41/64 loss: 0.325469970703125
Batch 42/64 loss: 0.3237565755844116
Batch 43/64 loss: 0.3226890563964844
Batch 44/64 loss: 0.33207547664642334
Batch 45/64 loss: 0.3224334716796875
Batch 46/64 loss: 0.3276817798614502
Batch 47/64 loss: 0.3267151117324829
Batch 48/64 loss: 0.3278106451034546
Batch 49/64 loss: 0.32884907722473145
Batch 50/64 loss: 0.32050400972366333
Batch 51/64 loss: 0.32622140645980835
Batch 52/64 loss: 0.32623571157455444
Batch 53/64 loss: 0.3273383378982544
Batch 54/64 loss: 0.32398247718811035
Batch 55/64 loss: 0.32961440086364746
Batch 56/64 loss: 0.3243008852005005
Batch 57/64 loss: 0.3250424265861511
Batch 58/64 loss: 0.3255000114440918
Batch 59/64 loss: 0.3259540796279907
Batch 60/64 loss: 0.32885706424713135
Batch 61/64 loss: 0.3247135281562805
Batch 62/64 loss: 0.32573843002319336
Batch 63/64 loss: 0.32115310430526733
Batch 64/64 loss: 0.3213399648666382
Epoch 49  Train loss: 0.32611852860918233  Val loss: 0.3297043778642346
Saving best model, epoch: 49
Epoch 50
-------------------------------
Batch 1/64 loss: 0.32473981380462646
Batch 2/64 loss: 0.3248157501220703
Batch 3/64 loss: 0.324729323387146
Batch 4/64 loss: 0.3293352723121643
Batch 5/64 loss: 0.321804404258728
Batch 6/64 loss: 0.3316970467567444
Batch 7/64 loss: 0.32336270809173584
Batch 8/64 loss: 0.3284510374069214
Batch 9/64 loss: 0.32758939266204834
Batch 10/64 loss: 0.3209235668182373
Batch 11/64 loss: 0.3204081654548645
Batch 12/64 loss: 0.3275231122970581
Batch 13/64 loss: 0.32698363065719604
Batch 14/64 loss: 0.3278869390487671
Batch 15/64 loss: 0.3249737620353699
Batch 16/64 loss: 0.3307013511657715
Batch 17/64 loss: 0.3244805335998535
Batch 18/64 loss: 0.3318527340888977
Batch 19/64 loss: 0.3294733762741089
Batch 20/64 loss: 0.3290008306503296
Batch 21/64 loss: 0.3228902816772461
Batch 22/64 loss: 0.32682669162750244
Batch 23/64 loss: 0.3279627561569214
Batch 24/64 loss: 0.32808607816696167
Batch 25/64 loss: 0.32617223262786865
Batch 26/64 loss: 0.324856162071228
Batch 27/64 loss: 0.3245496153831482
Batch 28/64 loss: 0.32146888971328735
Batch 29/64 loss: 0.3227550983428955
Batch 30/64 loss: 0.33115947246551514
Batch 31/64 loss: 0.3269214630126953
Batch 32/64 loss: 0.31899917125701904
Batch 33/64 loss: 0.3185974359512329
Batch 34/64 loss: 0.3248337507247925
Batch 35/64 loss: 0.3253304958343506
Batch 36/64 loss: 0.3212928771972656
Batch 37/64 loss: 0.32224225997924805
Batch 38/64 loss: 0.3256295919418335
Batch 39/64 loss: 0.33305472135543823
Batch 40/64 loss: 0.32605278491973877
Batch 41/64 loss: 0.32458603382110596
Batch 42/64 loss: 0.3300044536590576
Batch 43/64 loss: 0.3291761875152588
Batch 44/64 loss: 0.32391273975372314
Batch 45/64 loss: 0.3218700885772705
Batch 46/64 loss: 0.3213884234428406
Batch 47/64 loss: 0.3251303434371948
Batch 48/64 loss: 0.3230718970298767
Batch 49/64 loss: 0.3260951042175293
Batch 50/64 loss: 0.3217287063598633
Batch 51/64 loss: 0.3244096636772156
Batch 52/64 loss: 0.3305177688598633
Batch 53/64 loss: 0.32550036907196045
Batch 54/64 loss: 0.3215292692184448
Batch 55/64 loss: 0.32986998558044434
Batch 56/64 loss: 0.3247462511062622
Batch 57/64 loss: 0.3244975805282593
Batch 58/64 loss: 0.32169103622436523
Batch 59/64 loss: 0.3241100311279297
Batch 60/64 loss: 0.32629406452178955
Batch 61/64 loss: 0.32816386222839355
Batch 62/64 loss: 0.32207179069519043
Batch 63/64 loss: 0.3268897533416748
Batch 64/64 loss: 0.32421547174453735
Epoch 50  Train loss: 0.3255032406133764  Val loss: 0.33208649879468677
Epoch 51
-------------------------------
Batch 1/64 loss: 0.3236032724380493
Batch 2/64 loss: 0.325549840927124
Batch 3/64 loss: 0.3278568983078003
Batch 4/64 loss: 0.32369524240493774
Batch 5/64 loss: 0.33493900299072266
Batch 6/64 loss: 0.325150728225708
Batch 7/64 loss: 0.32796645164489746
Batch 8/64 loss: 0.3259376287460327
Batch 9/64 loss: 0.31975895166397095
Batch 10/64 loss: 0.31855636835098267
Batch 11/64 loss: 0.3188587427139282
Batch 12/64 loss: 0.3230251669883728
Batch 13/64 loss: 0.320334255695343
Batch 14/64 loss: 0.32495570182800293
Batch 15/64 loss: 0.3218097686767578
Batch 16/64 loss: 0.3313690423965454
Batch 17/64 loss: 0.3253188133239746
Batch 18/64 loss: 0.3219022750854492
Batch 19/64 loss: 0.31837624311447144
Batch 20/64 loss: 0.3222571611404419
Batch 21/64 loss: 0.3210833668708801
Batch 22/64 loss: 0.3274954557418823
Batch 23/64 loss: 0.3272610902786255
Batch 24/64 loss: 0.32245421409606934
Batch 25/64 loss: 0.32921302318573
Batch 26/64 loss: 0.32787054777145386
Batch 27/64 loss: 0.32456016540527344
Batch 28/64 loss: 0.3201269507408142
Batch 29/64 loss: 0.3237260580062866
Batch 30/64 loss: 0.3226677179336548
Batch 31/64 loss: 0.3299363851547241
Batch 32/64 loss: 0.31897079944610596
Batch 33/64 loss: 0.32566535472869873
Batch 34/64 loss: 0.32102036476135254
Batch 35/64 loss: 0.3173326253890991
Batch 36/64 loss: 0.32074785232543945
Batch 37/64 loss: 0.3280656337738037
Batch 38/64 loss: 0.32552671432495117
Batch 39/64 loss: 0.3229791522026062
Batch 40/64 loss: 0.32250452041625977
Batch 41/64 loss: 0.3167916536331177
Batch 42/64 loss: 0.3211038112640381
Batch 43/64 loss: 0.3284844160079956
Batch 44/64 loss: 0.3251221776008606
Batch 45/64 loss: 0.32762157917022705
Batch 46/64 loss: 0.3182746171951294
Batch 47/64 loss: 0.32124149799346924
Batch 48/64 loss: 0.33107805252075195
Batch 49/64 loss: 0.3300400376319885
Batch 50/64 loss: 0.3210026025772095
Batch 51/64 loss: 0.3310769200325012
Batch 52/64 loss: 0.3201369047164917
Batch 53/64 loss: 0.31951427459716797
Batch 54/64 loss: 0.3241114616394043
Batch 55/64 loss: 0.3229963183403015
Batch 56/64 loss: 0.32026320695877075
Batch 57/64 loss: 0.32806360721588135
Batch 58/64 loss: 0.32481706142425537
Batch 59/64 loss: 0.32415568828582764
Batch 60/64 loss: 0.3255753517150879
Batch 61/64 loss: 0.32381731271743774
Batch 62/64 loss: 0.3255513906478882
Batch 63/64 loss: 0.3220289945602417
Batch 64/64 loss: 0.31663674116134644
Epoch 51  Train loss: 0.32393374185936125  Val loss: 0.3292178525957455
Saving best model, epoch: 51
Epoch 52
-------------------------------
Batch 1/64 loss: 0.3222272992134094
Batch 2/64 loss: 0.3219956159591675
Batch 3/64 loss: 0.32168054580688477
Batch 4/64 loss: 0.3227698802947998
Batch 5/64 loss: 0.3173326849937439
Batch 6/64 loss: 0.32238996028900146
Batch 7/64 loss: 0.3201115131378174
Batch 8/64 loss: 0.3204905390739441
Batch 9/64 loss: 0.3196343183517456
Batch 10/64 loss: 0.3267782926559448
Batch 11/64 loss: 0.3211066722869873
Batch 12/64 loss: 0.3240818381309509
Batch 13/64 loss: 0.3242567777633667
Batch 14/64 loss: 0.31871485710144043
Batch 15/64 loss: 0.32595527172088623
Batch 16/64 loss: 0.31975090503692627
Batch 17/64 loss: 0.3251197934150696
Batch 18/64 loss: 0.32744085788726807
Batch 19/64 loss: 0.32494354248046875
Batch 20/64 loss: 0.33320653438568115
Batch 21/64 loss: 0.33019012212753296
Batch 22/64 loss: 0.32216519117355347
Batch 23/64 loss: 0.3252299427986145
Batch 24/64 loss: 0.32602524757385254
Batch 25/64 loss: 0.31999146938323975
Batch 26/64 loss: 0.32412493228912354
Batch 27/64 loss: 0.32426512241363525
Batch 28/64 loss: 0.3263781666755676
Batch 29/64 loss: 0.32328832149505615
Batch 30/64 loss: 0.3241862654685974
Batch 31/64 loss: 0.32402074337005615
Batch 32/64 loss: 0.31770235300064087
Batch 33/64 loss: 0.32297283411026
Batch 34/64 loss: 0.3221946358680725
Batch 35/64 loss: 0.3246108293533325
Batch 36/64 loss: 0.32316887378692627
Batch 37/64 loss: 0.32383644580841064
Batch 38/64 loss: 0.3299403786659241
Batch 39/64 loss: 0.32182037830352783
Batch 40/64 loss: 0.31708723306655884
Batch 41/64 loss: 0.32474464178085327
Batch 42/64 loss: 0.3323463201522827
Batch 43/64 loss: 0.3234109878540039
Batch 44/64 loss: 0.31890660524368286
Batch 45/64 loss: 0.3282454013824463
Batch 46/64 loss: 0.32274752855300903
Batch 47/64 loss: 0.3275216817855835
Batch 48/64 loss: 0.33158838748931885
Batch 49/64 loss: 0.32251453399658203
Batch 50/64 loss: 0.3202613592147827
Batch 51/64 loss: 0.32422685623168945
Batch 52/64 loss: 0.31997501850128174
Batch 53/64 loss: 0.3190023899078369
Batch 54/64 loss: 0.32517188787460327
Batch 55/64 loss: 0.32456105947494507
Batch 56/64 loss: 0.32053232192993164
Batch 57/64 loss: 0.31538552045822144
Batch 58/64 loss: 0.32182419300079346
Batch 59/64 loss: 0.3204055428504944
Batch 60/64 loss: 0.33054375648498535
Batch 61/64 loss: 0.319990873336792
Batch 62/64 loss: 0.3218846321105957
Batch 63/64 loss: 0.32468724250793457
Batch 64/64 loss: 0.32834047079086304
Epoch 52  Train loss: 0.32344974559896134  Val loss: 0.3267326971509612
Saving best model, epoch: 52
Epoch 53
-------------------------------
Batch 1/64 loss: 0.31887388229370117
Batch 2/64 loss: 0.3197200298309326
Batch 3/64 loss: 0.3183576464653015
Batch 4/64 loss: 0.31683677434921265
Batch 5/64 loss: 0.3176161050796509
Batch 6/64 loss: 0.3176867961883545
Batch 7/64 loss: 0.3212078809738159
Batch 8/64 loss: 0.32175731658935547
Batch 9/64 loss: 0.32151269912719727
Batch 10/64 loss: 0.31786489486694336
Batch 11/64 loss: 0.32537609338760376
Batch 12/64 loss: 0.3211851716041565
Batch 13/64 loss: 0.333624005317688
Batch 14/64 loss: 0.3209336996078491
Batch 15/64 loss: 0.32491207122802734
Batch 16/64 loss: 0.3149212598800659
Batch 17/64 loss: 0.32325369119644165
Batch 18/64 loss: 0.31922924518585205
Batch 19/64 loss: 0.32562708854675293
Batch 20/64 loss: 0.31716835498809814
Batch 21/64 loss: 0.3188445568084717
Batch 22/64 loss: 0.32088905572891235
Batch 23/64 loss: 0.3183583617210388
Batch 24/64 loss: 0.316381573677063
Batch 25/64 loss: 0.3207184076309204
Batch 26/64 loss: 0.3218204975128174
Batch 27/64 loss: 0.3179922103881836
Batch 28/64 loss: 0.32124000787734985
Batch 29/64 loss: 0.31919950246810913
Batch 30/64 loss: 0.32173609733581543
Batch 31/64 loss: 0.31766849756240845
Batch 32/64 loss: 0.31982845067977905
Batch 33/64 loss: 0.3235398530960083
Batch 34/64 loss: 0.3227335214614868
Batch 35/64 loss: 0.3239903450012207
Batch 36/64 loss: 0.3196704387664795
Batch 37/64 loss: 0.3194003105163574
Batch 38/64 loss: 0.31848710775375366
Batch 39/64 loss: 0.324476957321167
Batch 40/64 loss: 0.3169574737548828
Batch 41/64 loss: 0.3175344467163086
Batch 42/64 loss: 0.3214629292488098
Batch 43/64 loss: 0.32257723808288574
Batch 44/64 loss: 0.320906400680542
Batch 45/64 loss: 0.3226281404495239
Batch 46/64 loss: 0.3202793598175049
Batch 47/64 loss: 0.31340521574020386
Batch 48/64 loss: 0.32028889656066895
Batch 49/64 loss: 0.31880366802215576
Batch 50/64 loss: 0.3185311555862427
Batch 51/64 loss: 0.32168978452682495
Batch 52/64 loss: 0.3242298364639282
Batch 53/64 loss: 0.32282811403274536
Batch 54/64 loss: 0.31981372833251953
Batch 55/64 loss: 0.32442736625671387
Batch 56/64 loss: 0.3297896385192871
Batch 57/64 loss: 0.32532715797424316
Batch 58/64 loss: 0.3210296630859375
Batch 59/64 loss: 0.3237558603286743
Batch 60/64 loss: 0.3300447463989258
Batch 61/64 loss: 0.3231121301651001
Batch 62/64 loss: 0.3197118043899536
Batch 63/64 loss: 0.3227344751358032
Batch 64/64 loss: 0.31636762619018555
Epoch 53  Train loss: 0.3210005554498411  Val loss: 0.32667224145017537
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: 0.3147718906402588
Batch 2/64 loss: 0.32109206914901733
Batch 3/64 loss: 0.32583415508270264
Batch 4/64 loss: 0.3208196759223938
Batch 5/64 loss: 0.31997162103652954
Batch 6/64 loss: 0.31600964069366455
Batch 7/64 loss: 0.3197106122970581
Batch 8/64 loss: 0.31978321075439453
Batch 9/64 loss: 0.32261723279953003
Batch 10/64 loss: 0.32153427600860596
Batch 11/64 loss: 0.3215813636779785
Batch 12/64 loss: 0.31828057765960693
Batch 13/64 loss: 0.31446921825408936
Batch 14/64 loss: 0.31500744819641113
Batch 15/64 loss: 0.32357072830200195
Batch 16/64 loss: 0.32069844007492065
Batch 17/64 loss: 0.3175472021102905
Batch 18/64 loss: 0.3204249143600464
Batch 19/64 loss: 0.32474571466445923
Batch 20/64 loss: 0.3246983289718628
Batch 21/64 loss: 0.3247036933898926
Batch 22/64 loss: 0.323819100856781
Batch 23/64 loss: 0.31910037994384766
Batch 24/64 loss: 0.32305794954299927
Batch 25/64 loss: 0.32221031188964844
Batch 26/64 loss: 0.32200920581817627
Batch 27/64 loss: 0.3160405158996582
Batch 28/64 loss: 0.32002097368240356
Batch 29/64 loss: 0.32210665941238403
Batch 30/64 loss: 0.3184621334075928
Batch 31/64 loss: 0.31924617290496826
Batch 32/64 loss: 0.32104170322418213
Batch 33/64 loss: 0.3165133595466614
Batch 34/64 loss: 0.31818175315856934
Batch 35/64 loss: 0.3174062967300415
Batch 36/64 loss: 0.32362961769104004
Batch 37/64 loss: 0.31719082593917847
Batch 38/64 loss: 0.3240854740142822
Batch 39/64 loss: 0.3171157240867615
Batch 40/64 loss: 0.3241753578186035
Batch 41/64 loss: 0.3159424662590027
Batch 42/64 loss: 0.32946574687957764
Batch 43/64 loss: 0.3216145634651184
Batch 44/64 loss: 0.3176143169403076
Batch 45/64 loss: 0.3195783495903015
Batch 46/64 loss: 0.31888270378112793
Batch 47/64 loss: 0.3229031562805176
Batch 48/64 loss: 0.32369399070739746
Batch 49/64 loss: 0.32048630714416504
Batch 50/64 loss: 0.3204786777496338
Batch 51/64 loss: 0.3176354169845581
Batch 52/64 loss: 0.3182413578033447
Batch 53/64 loss: 0.32484447956085205
Batch 54/64 loss: 0.3195613622665405
Batch 55/64 loss: 0.3216502070426941
Batch 56/64 loss: 0.31926530599594116
Batch 57/64 loss: 0.3163835406303406
Batch 58/64 loss: 0.3240410089492798
Batch 59/64 loss: 0.3138595223426819
Batch 60/64 loss: 0.3234201669692993
Batch 61/64 loss: 0.3206120729446411
Batch 62/64 loss: 0.31655406951904297
Batch 63/64 loss: 0.312610387802124
Batch 64/64 loss: 0.31987690925598145
Epoch 54  Train loss: 0.32019658649668975  Val loss: 0.3258034427141406
Saving best model, epoch: 54
Epoch 55
-------------------------------
Batch 1/64 loss: 0.3171095848083496
Batch 2/64 loss: 0.3253519535064697
Batch 3/64 loss: 0.315771222114563
Batch 4/64 loss: 0.32424187660217285
Batch 5/64 loss: 0.31960248947143555
Batch 6/64 loss: 0.3217862844467163
Batch 7/64 loss: 0.31997913122177124
Batch 8/64 loss: 0.32521486282348633
Batch 9/64 loss: 0.31496095657348633
Batch 10/64 loss: 0.3158484697341919
Batch 11/64 loss: 0.3144800066947937
Batch 12/64 loss: 0.314106285572052
Batch 13/64 loss: 0.32167869806289673
Batch 14/64 loss: 0.31763148307800293
Batch 15/64 loss: 0.3157089352607727
Batch 16/64 loss: 0.32104766368865967
Batch 17/64 loss: 0.31757211685180664
Batch 18/64 loss: 0.31629085540771484
Batch 19/64 loss: 0.31615686416625977
Batch 20/64 loss: 0.32172709703445435
Batch 21/64 loss: 0.32253313064575195
Batch 22/64 loss: 0.318243145942688
Batch 23/64 loss: 0.3165363073348999
Batch 24/64 loss: 0.3143843412399292
Batch 25/64 loss: 0.31614136695861816
Batch 26/64 loss: 0.3213692307472229
Batch 27/64 loss: 0.3158509135246277
Batch 28/64 loss: 0.3234407901763916
Batch 29/64 loss: 0.32143205404281616
Batch 30/64 loss: 0.3119009733200073
Batch 31/64 loss: 0.3264579772949219
Batch 32/64 loss: 0.31870198249816895
Batch 33/64 loss: 0.3227548599243164
Batch 34/64 loss: 0.31668901443481445
Batch 35/64 loss: 0.31952011585235596
Batch 36/64 loss: 0.3139377236366272
Batch 37/64 loss: 0.31699419021606445
Batch 38/64 loss: 0.3181171417236328
Batch 39/64 loss: 0.3146982192993164
Batch 40/64 loss: 0.3179432153701782
Batch 41/64 loss: 0.31531447172164917
Batch 42/64 loss: 0.31986522674560547
Batch 43/64 loss: 0.3176546096801758
Batch 44/64 loss: 0.3160278797149658
Batch 45/64 loss: 0.3192041516304016
Batch 46/64 loss: 0.32130134105682373
Batch 47/64 loss: 0.32213956117630005
Batch 48/64 loss: 0.3197646141052246
Batch 49/64 loss: 0.3179720640182495
Batch 50/64 loss: 0.3191457986831665
Batch 51/64 loss: 0.3182114362716675
Batch 52/64 loss: 0.3213026523590088
Batch 53/64 loss: 0.3198453187942505
Batch 54/64 loss: 0.321344792842865
Batch 55/64 loss: 0.3143819570541382
Batch 56/64 loss: 0.32277238368988037
Batch 57/64 loss: 0.31902074813842773
Batch 58/64 loss: 0.3192111849784851
Batch 59/64 loss: 0.3122413158416748
Batch 60/64 loss: 0.31840062141418457
Batch 61/64 loss: 0.3182128667831421
Batch 62/64 loss: 0.3153117299079895
Batch 63/64 loss: 0.3109307289123535
Batch 64/64 loss: 0.3159067630767822
Epoch 55  Train loss: 0.3184379773981431  Val loss: 0.32350209468009133
Saving best model, epoch: 55
Epoch 56
-------------------------------
Batch 1/64 loss: 0.3145608901977539
Batch 2/64 loss: 0.3146287202835083
Batch 3/64 loss: 0.30624067783355713
Batch 4/64 loss: 0.317868709564209
Batch 5/64 loss: 0.3204050064086914
Batch 6/64 loss: 0.3147808313369751
Batch 7/64 loss: 0.3152376413345337
Batch 8/64 loss: 0.32001179456710815
Batch 9/64 loss: 0.32192158699035645
Batch 10/64 loss: 0.31765812635421753
Batch 11/64 loss: 0.32465094327926636
Batch 12/64 loss: 0.3183249235153198
Batch 13/64 loss: 0.3207165002822876
Batch 14/64 loss: 0.32493865489959717
Batch 15/64 loss: 0.3240867257118225
Batch 16/64 loss: 0.31715792417526245
Batch 17/64 loss: 0.3192265033721924
Batch 18/64 loss: 0.32382333278656006
Batch 19/64 loss: 0.3257249593734741
Batch 20/64 loss: 0.3202313184738159
Batch 21/64 loss: 0.31889450550079346
Batch 22/64 loss: 0.3178064823150635
Batch 23/64 loss: 0.3197472095489502
Batch 24/64 loss: 0.3127291202545166
Batch 25/64 loss: 0.31928640604019165
Batch 26/64 loss: 0.3202773928642273
Batch 27/64 loss: 0.3140350580215454
Batch 28/64 loss: 0.3178161382675171
Batch 29/64 loss: 0.3122478127479553
Batch 30/64 loss: 0.3150712251663208
Batch 31/64 loss: 0.3170003294944763
Batch 32/64 loss: 0.32021307945251465
Batch 33/64 loss: 0.3154010772705078
Batch 34/64 loss: 0.320132315158844
Batch 35/64 loss: 0.32220208644866943
Batch 36/64 loss: 0.3097766041755676
Batch 37/64 loss: 0.3142646551132202
Batch 38/64 loss: 0.3186274766921997
Batch 39/64 loss: 0.3140350580215454
Batch 40/64 loss: 0.32226109504699707
Batch 41/64 loss: 0.31497907638549805
Batch 42/64 loss: 0.3228614330291748
Batch 43/64 loss: 0.3183431029319763
Batch 44/64 loss: 0.327711820602417
Batch 45/64 loss: 0.3230423927307129
Batch 46/64 loss: 0.3109544515609741
Batch 47/64 loss: 0.3195963501930237
Batch 48/64 loss: 0.3158649206161499
Batch 49/64 loss: 0.3204134702682495
Batch 50/64 loss: 0.3208863139152527
Batch 51/64 loss: 0.3164633512496948
Batch 52/64 loss: 0.315096378326416
Batch 53/64 loss: 0.32165682315826416
Batch 54/64 loss: 0.3126852512359619
Batch 55/64 loss: 0.3161907196044922
Batch 56/64 loss: 0.3110923171043396
Batch 57/64 loss: 0.3201099634170532
Batch 58/64 loss: 0.3195602297782898
Batch 59/64 loss: 0.3198046088218689
Batch 60/64 loss: 0.3149486780166626
Batch 61/64 loss: 0.3182605504989624
Batch 62/64 loss: 0.3160938024520874
Batch 63/64 loss: 0.3207799196243286
Batch 64/64 loss: 0.3239940404891968
Epoch 56  Train loss: 0.3181868604585236  Val loss: 0.3256745807493675
Epoch 57
-------------------------------
Batch 1/64 loss: 0.31403040885925293
Batch 2/64 loss: 0.31980597972869873
Batch 3/64 loss: 0.32473552227020264
Batch 4/64 loss: 0.32129496335983276
Batch 5/64 loss: 0.31804776191711426
Batch 6/64 loss: 0.3156254291534424
Batch 7/64 loss: 0.3168472647666931
Batch 8/64 loss: 0.31846094131469727
Batch 9/64 loss: 0.32187169790267944
Batch 10/64 loss: 0.32022660970687866
Batch 11/64 loss: 0.31898343563079834
Batch 12/64 loss: 0.32238590717315674
Batch 13/64 loss: 0.3157618045806885
Batch 14/64 loss: 0.32033419609069824
Batch 15/64 loss: 0.3234686851501465
Batch 16/64 loss: 0.3164016008377075
Batch 17/64 loss: 0.31495916843414307
Batch 18/64 loss: 0.31806671619415283
Batch 19/64 loss: 0.3132082223892212
Batch 20/64 loss: 0.31841403245925903
Batch 21/64 loss: 0.3158010244369507
Batch 22/64 loss: 0.3099386692047119
Batch 23/64 loss: 0.31184208393096924
Batch 24/64 loss: 0.3174173831939697
Batch 25/64 loss: 0.32113492488861084
Batch 26/64 loss: 0.31571006774902344
Batch 27/64 loss: 0.317361056804657
Batch 28/64 loss: 0.31523746252059937
Batch 29/64 loss: 0.3127177953720093
Batch 30/64 loss: 0.3141244649887085
Batch 31/64 loss: 0.31499606370925903
Batch 32/64 loss: 0.31963860988616943
Batch 33/64 loss: 0.31002259254455566
Batch 34/64 loss: 0.3148898482322693
Batch 35/64 loss: 0.3126538395881653
Batch 36/64 loss: 0.3153620958328247
Batch 37/64 loss: 0.3190208673477173
Batch 38/64 loss: 0.3193480372428894
Batch 39/64 loss: 0.31545013189315796
Batch 40/64 loss: 0.3153177499771118
Batch 41/64 loss: 0.3167778253555298
Batch 42/64 loss: 0.32303833961486816
Batch 43/64 loss: 0.32580244541168213
Batch 44/64 loss: 0.3232994079589844
Batch 45/64 loss: 0.31562352180480957
Batch 46/64 loss: 0.3158111572265625
Batch 47/64 loss: 0.32261431217193604
Batch 48/64 loss: 0.30901920795440674
Batch 49/64 loss: 0.31739121675491333
Batch 50/64 loss: 0.31434518098831177
Batch 51/64 loss: 0.31588733196258545
Batch 52/64 loss: 0.3238403797149658
Batch 53/64 loss: 0.3159548044204712
Batch 54/64 loss: 0.3161734938621521
Batch 55/64 loss: 0.31773269176483154
Batch 56/64 loss: 0.314372181892395
Batch 57/64 loss: 0.3138890862464905
Batch 58/64 loss: 0.31840062141418457
Batch 59/64 loss: 0.31949830055236816
Batch 60/64 loss: 0.3145864009857178
Batch 61/64 loss: 0.3178712725639343
Batch 62/64 loss: 0.3211858868598938
Batch 63/64 loss: 0.3167821764945984
Batch 64/64 loss: 0.31704914569854736
Epoch 57  Train loss: 0.3173113603217929  Val loss: 0.3212215552215314
Saving best model, epoch: 57
Epoch 58
-------------------------------
Batch 1/64 loss: 0.3166086673736572
Batch 2/64 loss: 0.3136943578720093
Batch 3/64 loss: 0.3132135272026062
Batch 4/64 loss: 0.32107019424438477
Batch 5/64 loss: 0.31344568729400635
Batch 6/64 loss: 0.31551414728164673
Batch 7/64 loss: 0.31418466567993164
Batch 8/64 loss: 0.31555652618408203
Batch 9/64 loss: 0.3211350440979004
Batch 10/64 loss: 0.3086632490158081
Batch 11/64 loss: 0.3211195468902588
Batch 12/64 loss: 0.31481754779815674
Batch 13/64 loss: 0.3142591714859009
Batch 14/64 loss: 0.31745636463165283
Batch 15/64 loss: 0.319156289100647
Batch 16/64 loss: 0.3160592317581177
Batch 17/64 loss: 0.3145923614501953
Batch 18/64 loss: 0.32144975662231445
Batch 19/64 loss: 0.31614458560943604
Batch 20/64 loss: 0.31913089752197266
Batch 21/64 loss: 0.3152120113372803
Batch 22/64 loss: 0.3199154734611511
Batch 23/64 loss: 0.3151799440383911
Batch 24/64 loss: 0.31118565797805786
Batch 25/64 loss: 0.3146861791610718
Batch 26/64 loss: 0.31186866760253906
Batch 27/64 loss: 0.3197568655014038
Batch 28/64 loss: 0.32186996936798096
Batch 29/64 loss: 0.31005752086639404
Batch 30/64 loss: 0.3213544487953186
Batch 31/64 loss: 0.3144679069519043
Batch 32/64 loss: 0.31956493854522705
Batch 33/64 loss: 0.3192289471626282
Batch 34/64 loss: 0.31628698110580444
Batch 35/64 loss: 0.32573699951171875
Batch 36/64 loss: 0.3123117685317993
Batch 37/64 loss: 0.3114638328552246
Batch 38/64 loss: 0.3101867437362671
Batch 39/64 loss: 0.3175771236419678
Batch 40/64 loss: 0.3159228563308716
Batch 41/64 loss: 0.3175429701805115
Batch 42/64 loss: 0.31495654582977295
Batch 43/64 loss: 0.31603729724884033
Batch 44/64 loss: 0.3183974027633667
Batch 45/64 loss: 0.31229788064956665
Batch 46/64 loss: 0.3205001950263977
Batch 47/64 loss: 0.3188844919204712
Batch 48/64 loss: 0.3127574324607849
Batch 49/64 loss: 0.31040823459625244
Batch 50/64 loss: 0.3203582763671875
Batch 51/64 loss: 0.31994813680648804
Batch 52/64 loss: 0.3172307014465332
Batch 53/64 loss: 0.3159390687942505
Batch 54/64 loss: 0.3196340799331665
Batch 55/64 loss: 0.31314724683761597
Batch 56/64 loss: 0.31540602445602417
Batch 57/64 loss: 0.31370311975479126
Batch 58/64 loss: 0.31886595487594604
Batch 59/64 loss: 0.3250763416290283
Batch 60/64 loss: 0.3183203935623169
Batch 61/64 loss: 0.31608688831329346
Batch 62/64 loss: 0.31948429346084595
Batch 63/64 loss: 0.31372809410095215
Batch 64/64 loss: 0.31837040185928345
Epoch 58  Train loss: 0.3165269886746126  Val loss: 0.3217945807578228
Epoch 59
-------------------------------
Batch 1/64 loss: 0.30951493978500366
Batch 2/64 loss: 0.3225855827331543
Batch 3/64 loss: 0.31316226720809937
Batch 4/64 loss: 0.3155708312988281
Batch 5/64 loss: 0.3173031806945801
Batch 6/64 loss: 0.31361645460128784
Batch 7/64 loss: 0.3201407790184021
Batch 8/64 loss: 0.32020699977874756
Batch 9/64 loss: 0.31732606887817383
Batch 10/64 loss: 0.3180469870567322
Batch 11/64 loss: 0.31317317485809326
Batch 12/64 loss: 0.311184287071228
Batch 13/64 loss: 0.313451886177063
Batch 14/64 loss: 0.3185691237449646
Batch 15/64 loss: 0.32434070110321045
Batch 16/64 loss: 0.3125361204147339
Batch 17/64 loss: 0.31686973571777344
Batch 18/64 loss: 0.3140709400177002
Batch 19/64 loss: 0.3153468370437622
Batch 20/64 loss: 0.3164370059967041
Batch 21/64 loss: 0.31826531887054443
Batch 22/64 loss: 0.3190229535102844
Batch 23/64 loss: 0.31658387184143066
Batch 24/64 loss: 0.3137516975402832
Batch 25/64 loss: 0.31560027599334717
Batch 26/64 loss: 0.3150632381439209
Batch 27/64 loss: 0.31188052892684937
Batch 28/64 loss: 0.3152335286140442
Batch 29/64 loss: 0.3054482340812683
Batch 30/64 loss: 0.3148167133331299
Batch 31/64 loss: 0.31271159648895264
Batch 32/64 loss: 0.31430429220199585
Batch 33/64 loss: 0.3131493330001831
Batch 34/64 loss: 0.3268369436264038
Batch 35/64 loss: 0.3168015480041504
Batch 36/64 loss: 0.3078431487083435
Batch 37/64 loss: 0.3164500594139099
Batch 38/64 loss: 0.3221029043197632
Batch 39/64 loss: 0.3137351870536804
Batch 40/64 loss: 0.31657862663269043
Batch 41/64 loss: 0.320345401763916
Batch 42/64 loss: 0.3122381567955017
Batch 43/64 loss: 0.317161500453949
Batch 44/64 loss: 0.3098645806312561
Batch 45/64 loss: 0.3260042667388916
Batch 46/64 loss: 0.31088191270828247
Batch 47/64 loss: 0.31874436140060425
Batch 48/64 loss: 0.31547266244888306
Batch 49/64 loss: 0.31552088260650635
Batch 50/64 loss: 0.3146646022796631
Batch 51/64 loss: 0.31940507888793945
Batch 52/64 loss: 0.3170853853225708
Batch 53/64 loss: 0.3204178214073181
Batch 54/64 loss: 0.31269216537475586
Batch 55/64 loss: 0.31301307678222656
Batch 56/64 loss: 0.31435245275497437
Batch 57/64 loss: 0.3120110034942627
Batch 58/64 loss: 0.3187636137008667
Batch 59/64 loss: 0.31488269567489624
Batch 60/64 loss: 0.3254518508911133
Batch 61/64 loss: 0.30959171056747437
Batch 62/64 loss: 0.3230642080307007
Batch 63/64 loss: 0.31457948684692383
Batch 64/64 loss: 0.3201291561126709
Epoch 59  Train loss: 0.31601473957884546  Val loss: 0.32398429932872863
Epoch 60
-------------------------------
Batch 1/64 loss: 0.31647658348083496
Batch 2/64 loss: 0.3153572082519531
Batch 3/64 loss: 0.31808292865753174
Batch 4/64 loss: 0.32168418169021606
Batch 5/64 loss: 0.31374287605285645
Batch 6/64 loss: 0.3185808062553406
Batch 7/64 loss: 0.31535542011260986
Batch 8/64 loss: 0.314095139503479
Batch 9/64 loss: 0.31598395109176636
Batch 10/64 loss: 0.31836509704589844
Batch 11/64 loss: 0.3104398250579834
Batch 12/64 loss: 0.31551527976989746
Batch 13/64 loss: 0.30883049964904785
Batch 14/64 loss: 0.3132408857345581
Batch 15/64 loss: 0.3221989870071411
Batch 16/64 loss: 0.315250039100647
Batch 17/64 loss: 0.3151869773864746
Batch 18/64 loss: 0.31177735328674316
Batch 19/64 loss: 0.30947744846343994
Batch 20/64 loss: 0.31558215618133545
Batch 21/64 loss: 0.3196421265602112
Batch 22/64 loss: 0.31765007972717285
Batch 23/64 loss: 0.31429505348205566
Batch 24/64 loss: 0.31496691703796387
Batch 25/64 loss: 0.3126291036605835
Batch 26/64 loss: 0.3124462366104126
Batch 27/64 loss: 0.31524503231048584
Batch 28/64 loss: 0.3164908289909363
Batch 29/64 loss: 0.31307142972946167
Batch 30/64 loss: 0.31236541271209717
Batch 31/64 loss: 0.31147879362106323
Batch 32/64 loss: 0.31575679779052734
Batch 33/64 loss: 0.317240834236145
Batch 34/64 loss: 0.31571799516677856
Batch 35/64 loss: 0.31850874423980713
Batch 36/64 loss: 0.3116180896759033
Batch 37/64 loss: 0.30737602710723877
Batch 38/64 loss: 0.31732094287872314
Batch 39/64 loss: 0.32247090339660645
Batch 40/64 loss: 0.3180081844329834
Batch 41/64 loss: 0.319230318069458
Batch 42/64 loss: 0.31878530979156494
Batch 43/64 loss: 0.31799501180648804
Batch 44/64 loss: 0.3227921724319458
Batch 45/64 loss: 0.3137744069099426
Batch 46/64 loss: 0.3085888624191284
Batch 47/64 loss: 0.30909550189971924
Batch 48/64 loss: 0.30981385707855225
Batch 49/64 loss: 0.3106701374053955
Batch 50/64 loss: 0.3226795196533203
Batch 51/64 loss: 0.31697332859039307
Batch 52/64 loss: 0.30869925022125244
Batch 53/64 loss: 0.3117513060569763
Batch 54/64 loss: 0.3096948266029358
Batch 55/64 loss: 0.3176767826080322
Batch 56/64 loss: 0.3108113408088684
Batch 57/64 loss: 0.31860220432281494
Batch 58/64 loss: 0.315395712852478
Batch 59/64 loss: 0.31987643241882324
Batch 60/64 loss: 0.31671231985092163
Batch 61/64 loss: 0.3225923776626587
Batch 62/64 loss: 0.30932754278182983
Batch 63/64 loss: 0.31667429208755493
Batch 64/64 loss: 0.30417531728744507
Epoch 60  Train loss: 0.3150724310500949  Val loss: 0.32094030773516785
Saving best model, epoch: 60
Epoch 61
-------------------------------
Batch 1/64 loss: 0.31486034393310547
Batch 2/64 loss: 0.31716758012771606
Batch 3/64 loss: 0.31841158866882324
Batch 4/64 loss: 0.3196854591369629
Batch 5/64 loss: 0.3070046901702881
Batch 6/64 loss: 0.3118901252746582
Batch 7/64 loss: 0.3122439384460449
Batch 8/64 loss: 0.3101806640625
Batch 9/64 loss: 0.307167649269104
Batch 10/64 loss: 0.3172162175178528
Batch 11/64 loss: 0.3135916590690613
Batch 12/64 loss: 0.31231188774108887
Batch 13/64 loss: 0.32025980949401855
Batch 14/64 loss: 0.3141186237335205
Batch 15/64 loss: 0.3113754391670227
Batch 16/64 loss: 0.3189507722854614
Batch 17/64 loss: 0.31080925464630127
Batch 18/64 loss: 0.3120619058609009
Batch 19/64 loss: 0.3065760135650635
Batch 20/64 loss: 0.31416821479797363
Batch 21/64 loss: 0.3118821978569031
Batch 22/64 loss: 0.312735915184021
Batch 23/64 loss: 0.31206977367401123
Batch 24/64 loss: 0.315351665019989
Batch 25/64 loss: 0.31424009799957275
Batch 26/64 loss: 0.3139766454696655
Batch 27/64 loss: 0.31498539447784424
Batch 28/64 loss: 0.3172943592071533
Batch 29/64 loss: 0.310249924659729
Batch 30/64 loss: 0.3131132125854492
Batch 31/64 loss: 0.3203202486038208
Batch 32/64 loss: 0.317344069480896
Batch 33/64 loss: 0.3111644387245178
Batch 34/64 loss: 0.3211301565170288
Batch 35/64 loss: 0.31684523820877075
Batch 36/64 loss: 0.30557727813720703
Batch 37/64 loss: 0.3136305809020996
Batch 38/64 loss: 0.3157222270965576
Batch 39/64 loss: 0.3096766471862793
Batch 40/64 loss: 0.3249734044075012
Batch 41/64 loss: 0.31749093532562256
Batch 42/64 loss: 0.31341516971588135
Batch 43/64 loss: 0.316261887550354
Batch 44/64 loss: 0.3189454674720764
Batch 45/64 loss: 0.3109351396560669
Batch 46/64 loss: 0.3210868835449219
Batch 47/64 loss: 0.31048667430877686
Batch 48/64 loss: 0.3137636184692383
Batch 49/64 loss: 0.31242239475250244
Batch 50/64 loss: 0.30915939807891846
Batch 51/64 loss: 0.3125038743019104
Batch 52/64 loss: 0.3138144016265869
Batch 53/64 loss: 0.3139886260032654
Batch 54/64 loss: 0.31335318088531494
Batch 55/64 loss: 0.31865179538726807
Batch 56/64 loss: 0.3138447403907776
Batch 57/64 loss: 0.3185310363769531
Batch 58/64 loss: 0.32114171981811523
Batch 59/64 loss: 0.3103470206260681
Batch 60/64 loss: 0.315416157245636
Batch 61/64 loss: 0.30930113792419434
Batch 62/64 loss: 0.32167232036590576
Batch 63/64 loss: 0.31130993366241455
Batch 64/64 loss: 0.3136603832244873
Epoch 61  Train loss: 0.31428116256115485  Val loss: 0.319756430653772
Saving best model, epoch: 61
Epoch 62
-------------------------------
Batch 1/64 loss: 0.31502628326416016
Batch 2/64 loss: 0.3089359998703003
Batch 3/64 loss: 0.3093675971031189
Batch 4/64 loss: 0.3052483797073364
Batch 5/64 loss: 0.3137432932853699
Batch 6/64 loss: 0.3127305507659912
Batch 7/64 loss: 0.3177680969238281
Batch 8/64 loss: 0.30867862701416016
Batch 9/64 loss: 0.3115413188934326
Batch 10/64 loss: 0.3154705762863159
Batch 11/64 loss: 0.31921160221099854
Batch 12/64 loss: 0.3106166124343872
Batch 13/64 loss: 0.3095782995223999
Batch 14/64 loss: 0.31908923387527466
Batch 15/64 loss: 0.3225080966949463
Batch 16/64 loss: 0.3196578025817871
Batch 17/64 loss: 0.3158036470413208
Batch 18/64 loss: 0.30981117486953735
Batch 19/64 loss: 0.31544095277786255
Batch 20/64 loss: 0.3104349970817566
Batch 21/64 loss: 0.3149665594100952
Batch 22/64 loss: 0.3188154697418213
Batch 23/64 loss: 0.31597113609313965
Batch 24/64 loss: 0.32238805294036865
Batch 25/64 loss: 0.3136770725250244
Batch 26/64 loss: 0.31751883029937744
Batch 27/64 loss: 0.3139166831970215
Batch 28/64 loss: 0.3071889877319336
Batch 29/64 loss: 0.31038016080856323
Batch 30/64 loss: 0.3173658847808838
Batch 31/64 loss: 0.3126901388168335
Batch 32/64 loss: 0.31453561782836914
Batch 33/64 loss: 0.31445372104644775
Batch 34/64 loss: 0.3129870891571045
Batch 35/64 loss: 0.31426334381103516
Batch 36/64 loss: 0.31254708766937256
Batch 37/64 loss: 0.31362009048461914
Batch 38/64 loss: 0.30767202377319336
Batch 39/64 loss: 0.3191326856613159
Batch 40/64 loss: 0.3128315210342407
Batch 41/64 loss: 0.31525737047195435
Batch 42/64 loss: 0.31162166595458984
Batch 43/64 loss: 0.31544220447540283
Batch 44/64 loss: 0.31793326139450073
Batch 45/64 loss: 0.31663262844085693
Batch 46/64 loss: 0.31567203998565674
Batch 47/64 loss: 0.3102356195449829
Batch 48/64 loss: 0.3136128783226013
Batch 49/64 loss: 0.31330692768096924
Batch 50/64 loss: 0.3091736435890198
Batch 51/64 loss: 0.3135654926300049
Batch 52/64 loss: 0.3158445358276367
Batch 53/64 loss: 0.3153594732284546
Batch 54/64 loss: 0.3112589716911316
Batch 55/64 loss: 0.3131861686706543
Batch 56/64 loss: 0.3119357228279114
Batch 57/64 loss: 0.31233423948287964
Batch 58/64 loss: 0.31659996509552
Batch 59/64 loss: 0.30760788917541504
Batch 60/64 loss: 0.31170767545700073
Batch 61/64 loss: 0.3157273530960083
Batch 62/64 loss: 0.30949318408966064
Batch 63/64 loss: 0.3190881609916687
Batch 64/64 loss: 0.3130912780761719
Epoch 62  Train loss: 0.31380393458347694  Val loss: 0.3205621351081481
Epoch 63
-------------------------------
Batch 1/64 loss: 0.3168110251426697
Batch 2/64 loss: 0.30667340755462646
Batch 3/64 loss: 0.31055498123168945
Batch 4/64 loss: 0.3104536533355713
Batch 5/64 loss: 0.31838852167129517
Batch 6/64 loss: 0.3141735792160034
Batch 7/64 loss: 0.30786675214767456
Batch 8/64 loss: 0.3042886257171631
Batch 9/64 loss: 0.3110491633415222
Batch 10/64 loss: 0.3121938109397888
Batch 11/64 loss: 0.31786471605300903
Batch 12/64 loss: 0.31098151206970215
Batch 13/64 loss: 0.3223709464073181
Batch 14/64 loss: 0.3113609552383423
Batch 15/64 loss: 0.3050820231437683
Batch 16/64 loss: 0.3091517686843872
Batch 17/64 loss: 0.31469398736953735
Batch 18/64 loss: 0.3155394196510315
Batch 19/64 loss: 0.31485825777053833
Batch 20/64 loss: 0.31222158670425415
Batch 21/64 loss: 0.31444454193115234
Batch 22/64 loss: 0.30914777517318726
Batch 23/64 loss: 0.3055301904678345
Batch 24/64 loss: 0.3112650513648987
Batch 25/64 loss: 0.30998826026916504
Batch 26/64 loss: 0.3186277747154236
Batch 27/64 loss: 0.3158690929412842
Batch 28/64 loss: 0.31626367568969727
Batch 29/64 loss: 0.31313538551330566
Batch 30/64 loss: 0.3066732883453369
Batch 31/64 loss: 0.31001579761505127
Batch 32/64 loss: 0.32018715143203735
Batch 33/64 loss: 0.3028264045715332
Batch 34/64 loss: 0.30529284477233887
Batch 35/64 loss: 0.31547486782073975
Batch 36/64 loss: 0.31816720962524414
Batch 37/64 loss: 0.31491339206695557
Batch 38/64 loss: 0.3098412752151489
Batch 39/64 loss: 0.3110203146934509
Batch 40/64 loss: 0.31068241596221924
Batch 41/64 loss: 0.31154870986938477
Batch 42/64 loss: 0.3121080994606018
Batch 43/64 loss: 0.30571359395980835
Batch 44/64 loss: 0.3218631148338318
Batch 45/64 loss: 0.31391453742980957
Batch 46/64 loss: 0.3136153221130371
Batch 47/64 loss: 0.3126680850982666
Batch 48/64 loss: 0.31248676776885986
Batch 49/64 loss: 0.3121010661125183
Batch 50/64 loss: 0.317971408367157
Batch 51/64 loss: 0.311714768409729
Batch 52/64 loss: 0.31771087646484375
Batch 53/64 loss: 0.30564045906066895
Batch 54/64 loss: 0.30530399084091187
Batch 55/64 loss: 0.31621253490448
Batch 56/64 loss: 0.3108646869659424
Batch 57/64 loss: 0.3098299503326416
Batch 58/64 loss: 0.31725025177001953
Batch 59/64 loss: 0.30747783184051514
Batch 60/64 loss: 0.31617867946624756
Batch 61/64 loss: 0.3121452331542969
Batch 62/64 loss: 0.3148878812789917
Batch 63/64 loss: 0.3133231997489929
Batch 64/64 loss: 0.3117571473121643
Epoch 63  Train loss: 0.31234971471861295  Val loss: 0.3194186947599719
Saving best model, epoch: 63
Epoch 64
-------------------------------
Batch 1/64 loss: 0.31456637382507324
Batch 2/64 loss: 0.3126974105834961
Batch 3/64 loss: 0.3116888403892517
Batch 4/64 loss: 0.3153376579284668
Batch 5/64 loss: 0.30896782875061035
Batch 6/64 loss: 0.3050191402435303
Batch 7/64 loss: 0.30647140741348267
Batch 8/64 loss: 0.3133896589279175
Batch 9/64 loss: 0.3081759214401245
Batch 10/64 loss: 0.30571794509887695
Batch 11/64 loss: 0.3149615526199341
Batch 12/64 loss: 0.309637188911438
Batch 13/64 loss: 0.3155239224433899
Batch 14/64 loss: 0.313122034072876
Batch 15/64 loss: 0.31238853931427
Batch 16/64 loss: 0.31178057193756104
Batch 17/64 loss: 0.31341123580932617
Batch 18/64 loss: 0.3156996965408325
Batch 19/64 loss: 0.3101860284805298
Batch 20/64 loss: 0.3059619665145874
Batch 21/64 loss: 0.3078744411468506
Batch 22/64 loss: 0.31603050231933594
Batch 23/64 loss: 0.3187897205352783
Batch 24/64 loss: 0.31089556217193604
Batch 25/64 loss: 0.30802756547927856
Batch 26/64 loss: 0.3079228401184082
Batch 27/64 loss: 0.3071383237838745
Batch 28/64 loss: 0.31327521800994873
Batch 29/64 loss: 0.3108406066894531
Batch 30/64 loss: 0.3051748275756836
Batch 31/64 loss: 0.3135342597961426
Batch 32/64 loss: 0.31522226333618164
Batch 33/64 loss: 0.3055366277694702
Batch 34/64 loss: 0.3158468008041382
Batch 35/64 loss: 0.30800938606262207
Batch 36/64 loss: 0.3079991936683655
Batch 37/64 loss: 0.3175257444381714
Batch 38/64 loss: 0.3108072876930237
Batch 39/64 loss: 0.31394875049591064
Batch 40/64 loss: 0.3084557056427002
Batch 41/64 loss: 0.31535136699676514
Batch 42/64 loss: 0.3136732578277588
Batch 43/64 loss: 0.30737996101379395
Batch 44/64 loss: 0.30796581506729126
Batch 45/64 loss: 0.3047217130661011
Batch 46/64 loss: 0.3107255697250366
Batch 47/64 loss: 0.3086533546447754
Batch 48/64 loss: 0.31362950801849365
Batch 49/64 loss: 0.3106043338775635
Batch 50/64 loss: 0.31273776292800903
Batch 51/64 loss: 0.31469058990478516
Batch 52/64 loss: 0.31118059158325195
Batch 53/64 loss: 0.3103921413421631
Batch 54/64 loss: 0.3091379404067993
Batch 55/64 loss: 0.31141233444213867
Batch 56/64 loss: 0.31028681993484497
Batch 57/64 loss: 0.31158435344696045
Batch 58/64 loss: 0.3159472942352295
Batch 59/64 loss: 0.31053394079208374
Batch 60/64 loss: 0.31365764141082764
Batch 61/64 loss: 0.31656473875045776
Batch 62/64 loss: 0.30672919750213623
Batch 63/64 loss: 0.3040565252304077
Batch 64/64 loss: 0.3111512064933777
Epoch 64  Train loss: 0.3110986777380401  Val loss: 0.3164764978631665
Saving best model, epoch: 64
Epoch 65
-------------------------------
Batch 1/64 loss: 0.31039857864379883
Batch 2/64 loss: 0.3141378164291382
Batch 3/64 loss: 0.31246721744537354
Batch 4/64 loss: 0.30967187881469727
Batch 5/64 loss: 0.3125753402709961
Batch 6/64 loss: 0.3125349283218384
Batch 7/64 loss: 0.30619513988494873
Batch 8/64 loss: 0.3105710744857788
Batch 9/64 loss: 0.307522177696228
Batch 10/64 loss: 0.2999817132949829
Batch 11/64 loss: 0.3111337423324585
Batch 12/64 loss: 0.31127190589904785
Batch 13/64 loss: 0.31123077869415283
Batch 14/64 loss: 0.31180131435394287
Batch 15/64 loss: 0.3102983236312866
Batch 16/64 loss: 0.31316155195236206
Batch 17/64 loss: 0.306665301322937
Batch 18/64 loss: 0.30570048093795776
Batch 19/64 loss: 0.3156372308731079
Batch 20/64 loss: 0.3078826665878296
Batch 21/64 loss: 0.3099719285964966
Batch 22/64 loss: 0.3184394836425781
Batch 23/64 loss: 0.3077179789543152
Batch 24/64 loss: 0.3086196184158325
Batch 25/64 loss: 0.3142852187156677
Batch 26/64 loss: 0.31159496307373047
Batch 27/64 loss: 0.31213581562042236
Batch 28/64 loss: 0.3079691529273987
Batch 29/64 loss: 0.3049629330635071
Batch 30/64 loss: 0.3122352361679077
Batch 31/64 loss: 0.30931538343429565
Batch 32/64 loss: 0.3148832321166992
Batch 33/64 loss: 0.3124030828475952
Batch 34/64 loss: 0.3102228045463562
Batch 35/64 loss: 0.31051212549209595
Batch 36/64 loss: 0.3053918480873108
Batch 37/64 loss: 0.31501877307891846
Batch 38/64 loss: 0.3141820430755615
Batch 39/64 loss: 0.30864417552948
Batch 40/64 loss: 0.30708611011505127
Batch 41/64 loss: 0.3071458339691162
Batch 42/64 loss: 0.30359041690826416
Batch 43/64 loss: 0.30371272563934326
Batch 44/64 loss: 0.3037436008453369
Batch 45/64 loss: 0.30970728397369385
Batch 46/64 loss: 0.31244611740112305
Batch 47/64 loss: 0.31421196460723877
Batch 48/64 loss: 0.30920863151550293
Batch 49/64 loss: 0.30821871757507324
Batch 50/64 loss: 0.3066149950027466
Batch 51/64 loss: 0.3073279857635498
Batch 52/64 loss: 0.3124358654022217
Batch 53/64 loss: 0.3202168345451355
Batch 54/64 loss: 0.30902886390686035
Batch 55/64 loss: 0.3072216510772705
Batch 56/64 loss: 0.3072073459625244
Batch 57/64 loss: 0.308854341506958
Batch 58/64 loss: 0.30869925022125244
Batch 59/64 loss: 0.31254708766937256
Batch 60/64 loss: 0.3051726818084717
Batch 61/64 loss: 0.3144960403442383
Batch 62/64 loss: 0.3101787567138672
Batch 63/64 loss: 0.3096885681152344
Batch 64/64 loss: 0.3060670495033264
Epoch 65  Train loss: 0.30992403007021135  Val loss: 0.3155221525336459
Saving best model, epoch: 65
Epoch 66
-------------------------------
Batch 1/64 loss: 0.3156837821006775
Batch 2/64 loss: 0.3034806251525879
Batch 3/64 loss: 0.31205272674560547
Batch 4/64 loss: 0.3129047155380249
Batch 5/64 loss: 0.31299901008605957
Batch 6/64 loss: 0.30047935247421265
Batch 7/64 loss: 0.3081427216529846
Batch 8/64 loss: 0.30913543701171875
Batch 9/64 loss: 0.31792497634887695
Batch 10/64 loss: 0.30400192737579346
Batch 11/64 loss: 0.3168342113494873
Batch 12/64 loss: 0.30906760692596436
Batch 13/64 loss: 0.3103829026222229
Batch 14/64 loss: 0.31029045581817627
Batch 15/64 loss: 0.3089108467102051
Batch 16/64 loss: 0.3016711473464966
Batch 17/64 loss: 0.31346917152404785
Batch 18/64 loss: 0.3092985153198242
Batch 19/64 loss: 0.3039654493331909
Batch 20/64 loss: 0.3074605464935303
Batch 21/64 loss: 0.3137127161026001
Batch 22/64 loss: 0.312674880027771
Batch 23/64 loss: 0.30743110179901123
Batch 24/64 loss: 0.3074270486831665
Batch 25/64 loss: 0.31404197216033936
Batch 26/64 loss: 0.3097328543663025
Batch 27/64 loss: 0.30980873107910156
Batch 28/64 loss: 0.3115062713623047
Batch 29/64 loss: 0.3120619058609009
Batch 30/64 loss: 0.3112396001815796
Batch 31/64 loss: 0.2986065149307251
Batch 32/64 loss: 0.3074456453323364
Batch 33/64 loss: 0.3109005093574524
Batch 34/64 loss: 0.31523603200912476
Batch 35/64 loss: 0.30866146087646484
Batch 36/64 loss: 0.31257784366607666
Batch 37/64 loss: 0.3148893117904663
Batch 38/64 loss: 0.3136707544326782
Batch 39/64 loss: 0.3047109842300415
Batch 40/64 loss: 0.3036962151527405
Batch 41/64 loss: 0.3063235282897949
Batch 42/64 loss: 0.30771076679229736
Batch 43/64 loss: 0.3037482500076294
Batch 44/64 loss: 0.3069331645965576
Batch 45/64 loss: 0.3117663860321045
Batch 46/64 loss: 0.30522459745407104
Batch 47/64 loss: 0.30841153860092163
Batch 48/64 loss: 0.31163036823272705
Batch 49/64 loss: 0.30592596530914307
Batch 50/64 loss: 0.3151553273200989
Batch 51/64 loss: 0.30695509910583496
Batch 52/64 loss: 0.30594682693481445
Batch 53/64 loss: 0.30908966064453125
Batch 54/64 loss: 0.3010103702545166
Batch 55/64 loss: 0.30949002504348755
Batch 56/64 loss: 0.3089825510978699
Batch 57/64 loss: 0.31007468700408936
Batch 58/64 loss: 0.3062920570373535
Batch 59/64 loss: 0.30906856060028076
Batch 60/64 loss: 0.3118501305580139
Batch 61/64 loss: 0.30470192432403564
Batch 62/64 loss: 0.31309354305267334
Batch 63/64 loss: 0.316386342048645
Batch 64/64 loss: 0.307849645614624
Epoch 66  Train loss: 0.3092525080138562  Val loss: 0.31435455960506425
Saving best model, epoch: 66
Epoch 67
-------------------------------
Batch 1/64 loss: 0.3062669038772583
Batch 2/64 loss: 0.3108009099960327
Batch 3/64 loss: 0.3042386770248413
Batch 4/64 loss: 0.3030291795730591
Batch 5/64 loss: 0.3093132972717285
Batch 6/64 loss: 0.30419236421585083
Batch 7/64 loss: 0.31286895275115967
Batch 8/64 loss: 0.31080204248428345
Batch 9/64 loss: 0.30979835987091064
Batch 10/64 loss: 0.3039342164993286
Batch 11/64 loss: 0.30672574043273926
Batch 12/64 loss: 0.3041059970855713
Batch 13/64 loss: 0.30922752618789673
Batch 14/64 loss: 0.3094750642776489
Batch 15/64 loss: 0.3070904612541199
Batch 16/64 loss: 0.30782413482666016
Batch 17/64 loss: 0.3081216812133789
Batch 18/64 loss: 0.3081367015838623
Batch 19/64 loss: 0.3106975555419922
Batch 20/64 loss: 0.30938923358917236
Batch 21/64 loss: 0.3068758249282837
Batch 22/64 loss: 0.3089682459831238
Batch 23/64 loss: 0.3014107346534729
Batch 24/64 loss: 0.30649518966674805
Batch 25/64 loss: 0.2985725402832031
Batch 26/64 loss: 0.3152056932449341
Batch 27/64 loss: 0.3117384910583496
Batch 28/64 loss: 0.3084101676940918
Batch 29/64 loss: 0.30801916122436523
Batch 30/64 loss: 0.31415116786956787
Batch 31/64 loss: 0.3204467296600342
Batch 32/64 loss: 0.30381572246551514
Batch 33/64 loss: 0.3050450086593628
Batch 34/64 loss: 0.3072096109390259
Batch 35/64 loss: 0.30772221088409424
Batch 36/64 loss: 0.30910998582839966
Batch 37/64 loss: 0.30326414108276367
Batch 38/64 loss: 0.31437134742736816
Batch 39/64 loss: 0.30801868438720703
Batch 40/64 loss: 0.31369340419769287
Batch 41/64 loss: 0.30699169635772705
Batch 42/64 loss: 0.30836784839630127
Batch 43/64 loss: 0.3048895597457886
Batch 44/64 loss: 0.3099648356437683
Batch 45/64 loss: 0.30896055698394775
Batch 46/64 loss: 0.30826663970947266
Batch 47/64 loss: 0.310665488243103
Batch 48/64 loss: 0.3054337501525879
Batch 49/64 loss: 0.3115798234939575
Batch 50/64 loss: 0.31134581565856934
Batch 51/64 loss: 0.30639588832855225
Batch 52/64 loss: 0.30588817596435547
Batch 53/64 loss: 0.30282139778137207
Batch 54/64 loss: 0.30637139081954956
Batch 55/64 loss: 0.30761343240737915
Batch 56/64 loss: 0.3066293001174927
Batch 57/64 loss: 0.304524302482605
Batch 58/64 loss: 0.31292444467544556
Batch 59/64 loss: 0.31115543842315674
Batch 60/64 loss: 0.3042409420013428
Batch 61/64 loss: 0.30399250984191895
Batch 62/64 loss: 0.3095247745513916
Batch 63/64 loss: 0.3099600076675415
Batch 64/64 loss: 0.30625271797180176
Epoch 67  Train loss: 0.3080279312881769  Val loss: 0.3140913280834447
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: 0.29927217960357666
Batch 2/64 loss: 0.3084146976470947
Batch 3/64 loss: 0.3037940263748169
Batch 4/64 loss: 0.3076295852661133
Batch 5/64 loss: 0.3084357976913452
Batch 6/64 loss: 0.3128328323364258
Batch 7/64 loss: 0.3113008737564087
Batch 8/64 loss: 0.3142123222351074
Batch 9/64 loss: 0.31137287616729736
Batch 10/64 loss: 0.31105613708496094
Batch 11/64 loss: 0.3066888451576233
Batch 12/64 loss: 0.30614209175109863
Batch 13/64 loss: 0.2980722188949585
Batch 14/64 loss: 0.3182107210159302
Batch 15/64 loss: 0.3084139823913574
Batch 16/64 loss: 0.30575692653656006
Batch 17/64 loss: 0.2985617518424988
Batch 18/64 loss: 0.3083372116088867
Batch 19/64 loss: 0.3090311288833618
Batch 20/64 loss: 0.31028860807418823
Batch 21/64 loss: 0.3049285411834717
Batch 22/64 loss: 0.3063693046569824
Batch 23/64 loss: 0.3026353120803833
Batch 24/64 loss: 0.30826079845428467
Batch 25/64 loss: 0.30897343158721924
Batch 26/64 loss: 0.30696189403533936
Batch 27/64 loss: 0.3089137077331543
Batch 28/64 loss: 0.3033263683319092
Batch 29/64 loss: 0.30841052532196045
Batch 30/64 loss: 0.3062870502471924
Batch 31/64 loss: 0.30453336238861084
Batch 32/64 loss: 0.3128920793533325
Batch 33/64 loss: 0.3066157102584839
Batch 34/64 loss: 0.3086572289466858
Batch 35/64 loss: 0.3109133839607239
Batch 36/64 loss: 0.3106732964515686
Batch 37/64 loss: 0.3053290843963623
Batch 38/64 loss: 0.3042186498641968
Batch 39/64 loss: 0.3040608763694763
Batch 40/64 loss: 0.3088708519935608
Batch 41/64 loss: 0.3038392663002014
Batch 42/64 loss: 0.3125406503677368
Batch 43/64 loss: 0.3086565136909485
Batch 44/64 loss: 0.30484241247177124
Batch 45/64 loss: 0.3146839141845703
Batch 46/64 loss: 0.3040962219238281
Batch 47/64 loss: 0.3168296217918396
Batch 48/64 loss: 0.30668163299560547
Batch 49/64 loss: 0.306649386882782
Batch 50/64 loss: 0.3099706768989563
Batch 51/64 loss: 0.30815160274505615
Batch 52/64 loss: 0.30643194913864136
Batch 53/64 loss: 0.3160244822502136
Batch 54/64 loss: 0.31185388565063477
Batch 55/64 loss: 0.30105459690093994
Batch 56/64 loss: 0.3008266091346741
Batch 57/64 loss: 0.30810242891311646
Batch 58/64 loss: 0.3049309253692627
Batch 59/64 loss: 0.3114190101623535
Batch 60/64 loss: 0.29952752590179443
Batch 61/64 loss: 0.306083083152771
Batch 62/64 loss: 0.30371570587158203
Batch 63/64 loss: 0.31174570322036743
Batch 64/64 loss: 0.3069413900375366
Epoch 68  Train loss: 0.30758462933933034  Val loss: 0.3142629861831665
Epoch 69
-------------------------------
Batch 1/64 loss: 0.3028305768966675
Batch 2/64 loss: 0.3094257116317749
Batch 3/64 loss: 0.307891845703125
Batch 4/64 loss: 0.31550657749176025
Batch 5/64 loss: 0.3073984384536743
Batch 6/64 loss: 0.3054888844490051
Batch 7/64 loss: 0.30764472484588623
Batch 8/64 loss: 0.30607300996780396
Batch 9/64 loss: 0.31061553955078125
Batch 10/64 loss: 0.3091769218444824
Batch 11/64 loss: 0.31173402070999146
Batch 12/64 loss: 0.30568039417266846
Batch 13/64 loss: 0.3104882836341858
Batch 14/64 loss: 0.3068699836730957
Batch 15/64 loss: 0.3073996901512146
Batch 16/64 loss: 0.309495210647583
Batch 17/64 loss: 0.30785149335861206
Batch 18/64 loss: 0.30844318866729736
Batch 19/64 loss: 0.3049544095993042
Batch 20/64 loss: 0.3084155321121216
Batch 21/64 loss: 0.3078591823577881
Batch 22/64 loss: 0.3077481985092163
Batch 23/64 loss: 0.30229824781417847
Batch 24/64 loss: 0.307236909866333
Batch 25/64 loss: 0.30203330516815186
Batch 26/64 loss: 0.3068925738334656
Batch 27/64 loss: 0.30320829153060913
Batch 28/64 loss: 0.3057536482810974
Batch 29/64 loss: 0.3095968961715698
Batch 30/64 loss: 0.31056058406829834
Batch 31/64 loss: 0.3026195168495178
Batch 32/64 loss: 0.30464643239974976
Batch 33/64 loss: 0.3113389015197754
Batch 34/64 loss: 0.3139241337776184
Batch 35/64 loss: 0.3100602626800537
Batch 36/64 loss: 0.3101615905761719
Batch 37/64 loss: 0.30558115243911743
Batch 38/64 loss: 0.31861162185668945
Batch 39/64 loss: 0.3059198260307312
Batch 40/64 loss: 0.30686652660369873
Batch 41/64 loss: 0.30261802673339844
Batch 42/64 loss: 0.3081335425376892
Batch 43/64 loss: 0.30618882179260254
Batch 44/64 loss: 0.3061521053314209
Batch 45/64 loss: 0.311769962310791
Batch 46/64 loss: 0.3005906343460083
Batch 47/64 loss: 0.3131314516067505
Batch 48/64 loss: 0.30906641483306885
Batch 49/64 loss: 0.308841347694397
Batch 50/64 loss: 0.30506646633148193
Batch 51/64 loss: 0.31030499935150146
Batch 52/64 loss: 0.31245195865631104
Batch 53/64 loss: 0.30456507205963135
Batch 54/64 loss: 0.29843825101852417
Batch 55/64 loss: 0.32010865211486816
Batch 56/64 loss: 0.3057774305343628
Batch 57/64 loss: 0.30241042375564575
Batch 58/64 loss: 0.30264419317245483
Batch 59/64 loss: 0.30249738693237305
Batch 60/64 loss: 0.30386924743652344
Batch 61/64 loss: 0.30491316318511963
Batch 62/64 loss: 0.30027061700820923
Batch 63/64 loss: 0.311845064163208
Batch 64/64 loss: 0.30885714292526245
Epoch 69  Train loss: 0.30744471105874754  Val loss: 0.31400711757620586
Saving best model, epoch: 69
Epoch 70
-------------------------------
Batch 1/64 loss: 0.30704933404922485
Batch 2/64 loss: 0.30599308013916016
Batch 3/64 loss: 0.30720484256744385
Batch 4/64 loss: 0.3077976107597351
Batch 5/64 loss: 0.30940186977386475
Batch 6/64 loss: 0.3065730333328247
Batch 7/64 loss: 0.30623483657836914
Batch 8/64 loss: 0.30361032485961914
Batch 9/64 loss: 0.30753493309020996
Batch 10/64 loss: 0.302665114402771
Batch 11/64 loss: 0.3054906725883484
Batch 12/64 loss: 0.3105454444885254
Batch 13/64 loss: 0.3037669062614441
Batch 14/64 loss: 0.30981069803237915
Batch 15/64 loss: 0.3042425513267517
Batch 16/64 loss: 0.3080757260322571
Batch 17/64 loss: 0.2997560501098633
Batch 18/64 loss: 0.3075631856918335
Batch 19/64 loss: 0.3059960603713989
Batch 20/64 loss: 0.30742913484573364
Batch 21/64 loss: 0.3052855134010315
Batch 22/64 loss: 0.3031826615333557
Batch 23/64 loss: 0.2983686923980713
Batch 24/64 loss: 0.30762720108032227
Batch 25/64 loss: 0.3126399517059326
Batch 26/64 loss: 0.30434083938598633
Batch 27/64 loss: 0.3076190948486328
Batch 28/64 loss: 0.3147927522659302
Batch 29/64 loss: 0.30344057083129883
Batch 30/64 loss: 0.3050273656845093
Batch 31/64 loss: 0.30554866790771484
Batch 32/64 loss: 0.3031988739967346
Batch 33/64 loss: 0.30969005823135376
Batch 34/64 loss: 0.30177390575408936
Batch 35/64 loss: 0.30209314823150635
Batch 36/64 loss: 0.3038743734359741
Batch 37/64 loss: 0.3009326457977295
Batch 38/64 loss: 0.30625736713409424
Batch 39/64 loss: 0.3086671233177185
Batch 40/64 loss: 0.3068596124649048
Batch 41/64 loss: 0.30896705389022827
Batch 42/64 loss: 0.31098759174346924
Batch 43/64 loss: 0.30609822273254395
Batch 44/64 loss: 0.3061220645904541
Batch 45/64 loss: 0.30485963821411133
Batch 46/64 loss: 0.30253350734710693
Batch 47/64 loss: 0.3052031993865967
Batch 48/64 loss: 0.30276525020599365
Batch 49/64 loss: 0.3024284839630127
Batch 50/64 loss: 0.304962158203125
Batch 51/64 loss: 0.30139780044555664
Batch 52/64 loss: 0.30639052391052246
Batch 53/64 loss: 0.3065375089645386
Batch 54/64 loss: 0.31046128273010254
Batch 55/64 loss: 0.30316394567489624
Batch 56/64 loss: 0.303181529045105
Batch 57/64 loss: 0.30605244636535645
Batch 58/64 loss: 0.30511313676834106
Batch 59/64 loss: 0.3073359727859497
Batch 60/64 loss: 0.29993975162506104
Batch 61/64 loss: 0.31666070222854614
Batch 62/64 loss: 0.31322842836380005
Batch 63/64 loss: 0.3037462830543518
Batch 64/64 loss: 0.2999178171157837
Epoch 70  Train loss: 0.3058986144907334  Val loss: 0.31197348247279005
Saving best model, epoch: 70
Epoch 71
-------------------------------
Batch 1/64 loss: 0.3040400743484497
Batch 2/64 loss: 0.2967992424964905
Batch 3/64 loss: 0.2992016077041626
Batch 4/64 loss: 0.3045910596847534
Batch 5/64 loss: 0.30256515741348267
Batch 6/64 loss: 0.30016404390335083
Batch 7/64 loss: 0.30146121978759766
Batch 8/64 loss: 0.304037868976593
Batch 9/64 loss: 0.3111652135848999
Batch 10/64 loss: 0.3037499189376831
Batch 11/64 loss: 0.30581438541412354
Batch 12/64 loss: 0.3054695129394531
Batch 13/64 loss: 0.31596648693084717
Batch 14/64 loss: 0.31334763765335083
Batch 15/64 loss: 0.3115715980529785
Batch 16/64 loss: 0.30295395851135254
Batch 17/64 loss: 0.30584192276000977
Batch 18/64 loss: 0.3053175210952759
Batch 19/64 loss: 0.3015766143798828
Batch 20/64 loss: 0.3102140426635742
Batch 21/64 loss: 0.30630362033843994
Batch 22/64 loss: 0.30361127853393555
Batch 23/64 loss: 0.3080054521560669
Batch 24/64 loss: 0.30956757068634033
Batch 25/64 loss: 0.3058805465698242
Batch 26/64 loss: 0.3071901798248291
Batch 27/64 loss: 0.318992018699646
Batch 28/64 loss: 0.30789732933044434
Batch 29/64 loss: 0.30329430103302
Batch 30/64 loss: 0.29872989654541016
Batch 31/64 loss: 0.3094673156738281
Batch 32/64 loss: 0.30078160762786865
Batch 33/64 loss: 0.3020783066749573
Batch 34/64 loss: 0.300217866897583
Batch 35/64 loss: 0.3020658493041992
Batch 36/64 loss: 0.30599695444107056
Batch 37/64 loss: 0.30281126499176025
Batch 38/64 loss: 0.30669188499450684
Batch 39/64 loss: 0.30806994438171387
Batch 40/64 loss: 0.3063926696777344
Batch 41/64 loss: 0.3086397647857666
Batch 42/64 loss: 0.3071470856666565
Batch 43/64 loss: 0.31068217754364014
Batch 44/64 loss: 0.30593228340148926
Batch 45/64 loss: 0.3057081699371338
Batch 46/64 loss: 0.29521721601486206
Batch 47/64 loss: 0.30476653575897217
Batch 48/64 loss: 0.303274929523468
Batch 49/64 loss: 0.31196922063827515
Batch 50/64 loss: 0.2988661527633667
Batch 51/64 loss: 0.30331259965896606
Batch 52/64 loss: 0.29941898584365845
Batch 53/64 loss: 0.307502806186676
Batch 54/64 loss: 0.3038831949234009
Batch 55/64 loss: 0.2999916076660156
Batch 56/64 loss: 0.3022434711456299
Batch 57/64 loss: 0.30357563495635986
Batch 58/64 loss: 0.3040153980255127
Batch 59/64 loss: 0.3041977286338806
Batch 60/64 loss: 0.30946046113967896
Batch 61/64 loss: 0.3065124750137329
Batch 62/64 loss: 0.30898404121398926
Batch 63/64 loss: 0.3062000870704651
Batch 64/64 loss: 0.3092536926269531
Epoch 71  Train loss: 0.3053072508643655  Val loss: 0.3106627990699716
Saving best model, epoch: 71
Epoch 72
-------------------------------
Batch 1/64 loss: 0.3021732568740845
Batch 2/64 loss: 0.30781054496765137
Batch 3/64 loss: 0.2998499274253845
Batch 4/64 loss: 0.30168211460113525
Batch 5/64 loss: 0.3024080991744995
Batch 6/64 loss: 0.3076028823852539
Batch 7/64 loss: 0.3079540729522705
Batch 8/64 loss: 0.31271952390670776
Batch 9/64 loss: 0.2966700792312622
Batch 10/64 loss: 0.2950281500816345
Batch 11/64 loss: 0.2950860261917114
Batch 12/64 loss: 0.30096936225891113
Batch 13/64 loss: 0.29361772537231445
Batch 14/64 loss: 0.30018651485443115
Batch 15/64 loss: 0.30664825439453125
Batch 16/64 loss: 0.2996046543121338
Batch 17/64 loss: 0.30775153636932373
Batch 18/64 loss: 0.31041765213012695
Batch 19/64 loss: 0.3051227331161499
Batch 20/64 loss: 0.3023982048034668
Batch 21/64 loss: 0.30026137828826904
Batch 22/64 loss: 0.30741506814956665
Batch 23/64 loss: 0.30149853229522705
Batch 24/64 loss: 0.3046364188194275
Batch 25/64 loss: 0.31125372648239136
Batch 26/64 loss: 0.3060165047645569
Batch 27/64 loss: 0.29881751537323
Batch 28/64 loss: 0.308721661567688
Batch 29/64 loss: 0.3026585578918457
Batch 30/64 loss: 0.3053009510040283
Batch 31/64 loss: 0.3096850514411926
Batch 32/64 loss: 0.3030814528465271
Batch 33/64 loss: 0.299411416053772
Batch 34/64 loss: 0.30610883235931396
Batch 35/64 loss: 0.2975388169288635
Batch 36/64 loss: 0.30436134338378906
Batch 37/64 loss: 0.30665260553359985
Batch 38/64 loss: 0.29962635040283203
Batch 39/64 loss: 0.3021465539932251
Batch 40/64 loss: 0.3064873218536377
Batch 41/64 loss: 0.3008769750595093
Batch 42/64 loss: 0.3110042214393616
Batch 43/64 loss: 0.30446434020996094
Batch 44/64 loss: 0.3018377423286438
Batch 45/64 loss: 0.30271363258361816
Batch 46/64 loss: 0.30467015504837036
Batch 47/64 loss: 0.3040132522583008
Batch 48/64 loss: 0.30785369873046875
Batch 49/64 loss: 0.3059092164039612
Batch 50/64 loss: 0.30484825372695923
Batch 51/64 loss: 0.30717962980270386
Batch 52/64 loss: 0.29869771003723145
Batch 53/64 loss: 0.30610960721969604
Batch 54/64 loss: 0.3042454719543457
Batch 55/64 loss: 0.3040093183517456
Batch 56/64 loss: 0.30090051889419556
Batch 57/64 loss: 0.3044590950012207
Batch 58/64 loss: 0.3050738573074341
Batch 59/64 loss: 0.30001187324523926
Batch 60/64 loss: 0.3078542947769165
Batch 61/64 loss: 0.30044180154800415
Batch 62/64 loss: 0.3057102560997009
Batch 63/64 loss: 0.30528295040130615
Batch 64/64 loss: 0.29755520820617676
Epoch 72  Train loss: 0.3036661278967764  Val loss: 0.313182020924755
Epoch 73
-------------------------------
Batch 1/64 loss: 0.29817134141921997
Batch 2/64 loss: 0.3017078638076782
Batch 3/64 loss: 0.29617005586624146
Batch 4/64 loss: 0.3053871989250183
Batch 5/64 loss: 0.30003660917282104
Batch 6/64 loss: 0.30307018756866455
Batch 7/64 loss: 0.30415916442871094
Batch 8/64 loss: 0.30870139598846436
Batch 9/64 loss: 0.3048959970474243
Batch 10/64 loss: 0.30364012718200684
Batch 11/64 loss: 0.3034554719924927
Batch 12/64 loss: 0.2983713746070862
Batch 13/64 loss: 0.3081958293914795
Batch 14/64 loss: 0.30359363555908203
Batch 15/64 loss: 0.3022899031639099
Batch 16/64 loss: 0.3046135902404785
Batch 17/64 loss: 0.3009490966796875
Batch 18/64 loss: 0.3059816360473633
Batch 19/64 loss: 0.30763745307922363
Batch 20/64 loss: 0.3159068822860718
Batch 21/64 loss: 0.3074069023132324
Batch 22/64 loss: 0.3088221549987793
Batch 23/64 loss: 0.301582932472229
Batch 24/64 loss: 0.3024895191192627
Batch 25/64 loss: 0.3044983148574829
Batch 26/64 loss: 0.29969072341918945
Batch 27/64 loss: 0.302232027053833
Batch 28/64 loss: 0.29593080282211304
Batch 29/64 loss: 0.3010701537132263
Batch 30/64 loss: 0.30178725719451904
Batch 31/64 loss: 0.29578202962875366
Batch 32/64 loss: 0.3026914596557617
Batch 33/64 loss: 0.3021695613861084
Batch 34/64 loss: 0.3070223331451416
Batch 35/64 loss: 0.29884397983551025
Batch 36/64 loss: 0.304646372795105
Batch 37/64 loss: 0.30252325534820557
Batch 38/64 loss: 0.30355656147003174
Batch 39/64 loss: 0.31148481369018555
Batch 40/64 loss: 0.3094310164451599
Batch 41/64 loss: 0.2974473237991333
Batch 42/64 loss: 0.30114173889160156
Batch 43/64 loss: 0.3107259273529053
Batch 44/64 loss: 0.3017790913581848
Batch 45/64 loss: 0.3015362024307251
Batch 46/64 loss: 0.30796486139297485
Batch 47/64 loss: 0.30234360694885254
Batch 48/64 loss: 0.3052246570587158
Batch 49/64 loss: 0.29882490634918213
Batch 50/64 loss: 0.29724597930908203
Batch 51/64 loss: 0.2978188991546631
Batch 52/64 loss: 0.30607616901397705
Batch 53/64 loss: 0.310219407081604
Batch 54/64 loss: 0.30310964584350586
Batch 55/64 loss: 0.30722057819366455
Batch 56/64 loss: 0.30542564392089844
Batch 57/64 loss: 0.31170880794525146
Batch 58/64 loss: 0.308191180229187
Batch 59/64 loss: 0.29576390981674194
Batch 60/64 loss: 0.2977050542831421
Batch 61/64 loss: 0.30882084369659424
Batch 62/64 loss: 0.2990865707397461
Batch 63/64 loss: 0.30975639820098877
Batch 64/64 loss: 0.3061276078224182
Epoch 73  Train loss: 0.30361302109325633  Val loss: 0.3114527033776352
Epoch 74
-------------------------------
Batch 1/64 loss: 0.30333083868026733
Batch 2/64 loss: 0.3014969825744629
Batch 3/64 loss: 0.2999025583267212
Batch 4/64 loss: 0.3033844828605652
Batch 5/64 loss: 0.29733526706695557
Batch 6/64 loss: 0.3012148141860962
Batch 7/64 loss: 0.29638588428497314
Batch 8/64 loss: 0.30796825885772705
Batch 9/64 loss: 0.3057582378387451
Batch 10/64 loss: 0.3084220886230469
Batch 11/64 loss: 0.3072930574417114
Batch 12/64 loss: 0.29889267683029175
Batch 13/64 loss: 0.3050994277000427
Batch 14/64 loss: 0.3070940375328064
Batch 15/64 loss: 0.3064800500869751
Batch 16/64 loss: 0.31006377935409546
Batch 17/64 loss: 0.2965314984321594
Batch 18/64 loss: 0.2976263761520386
Batch 19/64 loss: 0.3044254779815674
Batch 20/64 loss: 0.3028700351715088
Batch 21/64 loss: 0.30396145582199097
Batch 22/64 loss: 0.30083078145980835
Batch 23/64 loss: 0.2925196886062622
Batch 24/64 loss: 0.300295352935791
Batch 25/64 loss: 0.3019499182701111
Batch 26/64 loss: 0.3050585985183716
Batch 27/64 loss: 0.2983574867248535
Batch 28/64 loss: 0.299713671207428
Batch 29/64 loss: 0.3102235198020935
Batch 30/64 loss: 0.2990211248397827
Batch 31/64 loss: 0.30505573749542236
Batch 32/64 loss: 0.30543291568756104
Batch 33/64 loss: 0.29851698875427246
Batch 34/64 loss: 0.30642855167388916
Batch 35/64 loss: 0.3050811290740967
Batch 36/64 loss: 0.3017917275428772
Batch 37/64 loss: 0.29887521266937256
Batch 38/64 loss: 0.30141258239746094
Batch 39/64 loss: 0.3001580238342285
Batch 40/64 loss: 0.30173760652542114
Batch 41/64 loss: 0.2992931008338928
Batch 42/64 loss: 0.301998496055603
Batch 43/64 loss: 0.30358731746673584
Batch 44/64 loss: 0.30510830879211426
Batch 45/64 loss: 0.30146634578704834
Batch 46/64 loss: 0.301530122756958
Batch 47/64 loss: 0.29727375507354736
Batch 48/64 loss: 0.3106943368911743
Batch 49/64 loss: 0.30922186374664307
Batch 50/64 loss: 0.30289554595947266
Batch 51/64 loss: 0.3024735450744629
Batch 52/64 loss: 0.30461400747299194
Batch 53/64 loss: 0.30058133602142334
Batch 54/64 loss: 0.30394983291625977
Batch 55/64 loss: 0.30605578422546387
Batch 56/64 loss: 0.30636918544769287
Batch 57/64 loss: 0.296467661857605
Batch 58/64 loss: 0.29562002420425415
Batch 59/64 loss: 0.31365537643432617
Batch 60/64 loss: 0.3069039583206177
Batch 61/64 loss: 0.30435848236083984
Batch 62/64 loss: 0.30240458250045776
Batch 63/64 loss: 0.29482942819595337
Batch 64/64 loss: 0.3064758777618408
Epoch 74  Train loss: 0.30273266212612976  Val loss: 0.3085958480425307
Saving best model, epoch: 74
Epoch 75
-------------------------------
Batch 1/64 loss: 0.3054758906364441
Batch 2/64 loss: 0.3062173128128052
Batch 3/64 loss: 0.29963135719299316
Batch 4/64 loss: 0.2987692356109619
Batch 5/64 loss: 0.30473655462265015
Batch 6/64 loss: 0.29253339767456055
Batch 7/64 loss: 0.30079543590545654
Batch 8/64 loss: 0.3010108470916748
Batch 9/64 loss: 0.3030891418457031
Batch 10/64 loss: 0.3041524887084961
Batch 11/64 loss: 0.3052070140838623
Batch 12/64 loss: 0.3025243878364563
Batch 13/64 loss: 0.2985110878944397
Batch 14/64 loss: 0.30443131923675537
Batch 15/64 loss: 0.29809701442718506
Batch 16/64 loss: 0.3040749430656433
Batch 17/64 loss: 0.3002973198890686
Batch 18/64 loss: 0.3063358664512634
Batch 19/64 loss: 0.2999277114868164
Batch 20/64 loss: 0.30084455013275146
Batch 21/64 loss: 0.30030184984207153
Batch 22/64 loss: 0.30168336629867554
Batch 23/64 loss: 0.30036282539367676
Batch 24/64 loss: 0.30716800689697266
Batch 25/64 loss: 0.3013232946395874
Batch 26/64 loss: 0.2987802028656006
Batch 27/64 loss: 0.2953885793685913
Batch 28/64 loss: 0.2987593412399292
Batch 29/64 loss: 0.29883795976638794
Batch 30/64 loss: 0.3015587329864502
Batch 31/64 loss: 0.3012723922729492
Batch 32/64 loss: 0.29978513717651367
Batch 33/64 loss: 0.30064135789871216
Batch 34/64 loss: 0.30188751220703125
Batch 35/64 loss: 0.2961897850036621
Batch 36/64 loss: 0.29714035987854004
Batch 37/64 loss: 0.30423277616500854
Batch 38/64 loss: 0.2981839179992676
Batch 39/64 loss: 0.3073430061340332
Batch 40/64 loss: 0.2956084609031677
Batch 41/64 loss: 0.3083305358886719
Batch 42/64 loss: 0.30107855796813965
Batch 43/64 loss: 0.3020109534263611
Batch 44/64 loss: 0.3016599416732788
Batch 45/64 loss: 0.2972646951675415
Batch 46/64 loss: 0.30110031366348267
Batch 47/64 loss: 0.29824697971343994
Batch 48/64 loss: 0.3051098585128784
Batch 49/64 loss: 0.3025110363960266
Batch 50/64 loss: 0.3048741817474365
Batch 51/64 loss: 0.3038386106491089
Batch 52/64 loss: 0.2987135648727417
Batch 53/64 loss: 0.3068443536758423
Batch 54/64 loss: 0.2999308109283447
Batch 55/64 loss: 0.3071593642234802
Batch 56/64 loss: 0.3017319440841675
Batch 57/64 loss: 0.30701589584350586
Batch 58/64 loss: 0.30108481645584106
Batch 59/64 loss: 0.30250251293182373
Batch 60/64 loss: 0.29924798011779785
Batch 61/64 loss: 0.30398261547088623
Batch 62/64 loss: 0.30794191360473633
Batch 63/64 loss: 0.3021587133407593
Batch 64/64 loss: 0.3001580834388733
Epoch 75  Train loss: 0.3016873796780904  Val loss: 0.30907897932832595
Epoch 76
-------------------------------
Batch 1/64 loss: 0.2960318326950073
Batch 2/64 loss: 0.3010594844818115
Batch 3/64 loss: 0.3002626895904541
Batch 4/64 loss: 0.2999476194381714
Batch 5/64 loss: 0.30437207221984863
Batch 6/64 loss: 0.2942467927932739
Batch 7/64 loss: 0.30945199728012085
Batch 8/64 loss: 0.301921010017395
Batch 9/64 loss: 0.3011733293533325
Batch 10/64 loss: 0.3017469048500061
Batch 11/64 loss: 0.30079805850982666
Batch 12/64 loss: 0.29996752738952637
Batch 13/64 loss: 0.3003779649734497
Batch 14/64 loss: 0.2992546558380127
Batch 15/64 loss: 0.29413139820098877
Batch 16/64 loss: 0.295967698097229
Batch 17/64 loss: 0.3057107925415039
Batch 18/64 loss: 0.3033078908920288
Batch 19/64 loss: 0.2982231378555298
Batch 20/64 loss: 0.2919238805770874
Batch 21/64 loss: 0.3045826554298401
Batch 22/64 loss: 0.29587817192077637
Batch 23/64 loss: 0.31166744232177734
Batch 24/64 loss: 0.31069403886795044
Batch 25/64 loss: 0.3009520173072815
Batch 26/64 loss: 0.30003124475479126
Batch 27/64 loss: 0.3031712770462036
Batch 28/64 loss: 0.31115972995758057
Batch 29/64 loss: 0.3007364869117737
Batch 30/64 loss: 0.2948903441429138
Batch 31/64 loss: 0.3060153126716614
Batch 32/64 loss: 0.2986077070236206
Batch 33/64 loss: 0.30131012201309204
Batch 34/64 loss: 0.29631030559539795
Batch 35/64 loss: 0.2958282232284546
Batch 36/64 loss: 0.30466222763061523
Batch 37/64 loss: 0.29878246784210205
Batch 38/64 loss: 0.3077971935272217
Batch 39/64 loss: 0.3163813352584839
Batch 40/64 loss: 0.30362188816070557
Batch 41/64 loss: 0.3004354238510132
Batch 42/64 loss: 0.30071020126342773
Batch 43/64 loss: 0.30426180362701416
Batch 44/64 loss: 0.3020141124725342
Batch 45/64 loss: 0.29813599586486816
Batch 46/64 loss: 0.3022814989089966
Batch 47/64 loss: 0.30130934715270996
Batch 48/64 loss: 0.3008297085762024
Batch 49/64 loss: 0.3016831874847412
Batch 50/64 loss: 0.2998558282852173
Batch 51/64 loss: 0.30396997928619385
Batch 52/64 loss: 0.301327109336853
Batch 53/64 loss: 0.3101298213005066
Batch 54/64 loss: 0.2912193536758423
Batch 55/64 loss: 0.3084995150566101
Batch 56/64 loss: 0.29958462715148926
Batch 57/64 loss: 0.30023229122161865
Batch 58/64 loss: 0.30275046825408936
Batch 59/64 loss: 0.30338889360427856
Batch 60/64 loss: 0.3042638301849365
Batch 61/64 loss: 0.3012934923171997
Batch 62/64 loss: 0.30783551931381226
Batch 63/64 loss: 0.30599093437194824
Batch 64/64 loss: 0.2904450297355652
Epoch 76  Train loss: 0.30169088069130395  Val loss: 0.31141904170570506
Epoch 77
-------------------------------
Batch 1/64 loss: 0.29988884925842285
Batch 2/64 loss: 0.30326277017593384
Batch 3/64 loss: 0.2991330623626709
Batch 4/64 loss: 0.29566526412963867
Batch 5/64 loss: 0.3017153739929199
Batch 6/64 loss: 0.30428797006607056
Batch 7/64 loss: 0.298326313495636
Batch 8/64 loss: 0.2971614599227905
Batch 9/64 loss: 0.2969982624053955
Batch 10/64 loss: 0.2960907220840454
Batch 11/64 loss: 0.3055762052536011
Batch 12/64 loss: 0.3131113052368164
Batch 13/64 loss: 0.2944601774215698
Batch 14/64 loss: 0.30691784620285034
Batch 15/64 loss: 0.30805861949920654
Batch 16/64 loss: 0.30086493492126465
Batch 17/64 loss: 0.299416184425354
Batch 18/64 loss: 0.30009758472442627
Batch 19/64 loss: 0.29379206895828247
Batch 20/64 loss: 0.3048880100250244
Batch 21/64 loss: 0.30086565017700195
Batch 22/64 loss: 0.30689191818237305
Batch 23/64 loss: 0.2934454679489136
Batch 24/64 loss: 0.30199140310287476
Batch 25/64 loss: 0.2987060546875
Batch 26/64 loss: 0.3059394359588623
Batch 27/64 loss: 0.30669766664505005
Batch 28/64 loss: 0.3023446798324585
Batch 29/64 loss: 0.3116123676300049
Batch 30/64 loss: 0.2909121513366699
Batch 31/64 loss: 0.3005516529083252
Batch 32/64 loss: 0.3044097423553467
Batch 33/64 loss: 0.30643582344055176
Batch 34/64 loss: 0.30815303325653076
Batch 35/64 loss: 0.29825204610824585
Batch 36/64 loss: 0.2974490523338318
Batch 37/64 loss: 0.2960233688354492
Batch 38/64 loss: 0.30718863010406494
Batch 39/64 loss: 0.29468417167663574
Batch 40/64 loss: 0.30140620470046997
Batch 41/64 loss: 0.2997029423713684
Batch 42/64 loss: 0.3000624179840088
Batch 43/64 loss: 0.29617130756378174
Batch 44/64 loss: 0.29960358142852783
Batch 45/64 loss: 0.29903048276901245
Batch 46/64 loss: 0.29878509044647217
Batch 47/64 loss: 0.30410367250442505
Batch 48/64 loss: 0.2968604564666748
Batch 49/64 loss: 0.2949960231781006
Batch 50/64 loss: 0.29667842388153076
Batch 51/64 loss: 0.3125736713409424
Batch 52/64 loss: 0.31539928913116455
Batch 53/64 loss: 0.3047661781311035
Batch 54/64 loss: 0.2950472831726074
Batch 55/64 loss: 0.2943456172943115
Batch 56/64 loss: 0.2971166968345642
Batch 57/64 loss: 0.30015021562576294
Batch 58/64 loss: 0.2964423894882202
Batch 59/64 loss: 0.3036729097366333
Batch 60/64 loss: 0.2936347723007202
Batch 61/64 loss: 0.30859309434890747
Batch 62/64 loss: 0.3005223274230957
Batch 63/64 loss: 0.30091267824172974
Batch 64/64 loss: 0.29500579833984375
Epoch 77  Train loss: 0.30092704903845696  Val loss: 0.3088180228197288
Epoch 78
-------------------------------
Batch 1/64 loss: 0.300031840801239
Batch 2/64 loss: 0.3043994903564453
Batch 3/64 loss: 0.30877625942230225
Batch 4/64 loss: 0.30196893215179443
Batch 5/64 loss: 0.30279988050460815
Batch 6/64 loss: 0.2942291498184204
Batch 7/64 loss: 0.2984082102775574
Batch 8/64 loss: 0.3001347780227661
Batch 9/64 loss: 0.30726438760757446
Batch 10/64 loss: 0.2987707853317261
Batch 11/64 loss: 0.305281400680542
Batch 12/64 loss: 0.3036360740661621
Batch 13/64 loss: 0.30168330669403076
Batch 14/64 loss: 0.2898515462875366
Batch 15/64 loss: 0.30388039350509644
Batch 16/64 loss: 0.30238866806030273
Batch 17/64 loss: 0.29879146814346313
Batch 18/64 loss: 0.29946452379226685
Batch 19/64 loss: 0.294833779335022
Batch 20/64 loss: 0.30105626583099365
Batch 21/64 loss: 0.2953808307647705
Batch 22/64 loss: 0.2986263036727905
Batch 23/64 loss: 0.29904496669769287
Batch 24/64 loss: 0.3003445267677307
Batch 25/64 loss: 0.3060346245765686
Batch 26/64 loss: 0.3039724826812744
Batch 27/64 loss: 0.295413613319397
Batch 28/64 loss: 0.29145199060440063
Batch 29/64 loss: 0.3044712543487549
Batch 30/64 loss: 0.30047744512557983
Batch 31/64 loss: 0.29712605476379395
Batch 32/64 loss: 0.2964133024215698
Batch 33/64 loss: 0.3039577007293701
Batch 34/64 loss: 0.3143305778503418
Batch 35/64 loss: 0.3019505739212036
Batch 36/64 loss: 0.2997565269470215
Batch 37/64 loss: 0.3022158741950989
Batch 38/64 loss: 0.293609619140625
Batch 39/64 loss: 0.3014918565750122
Batch 40/64 loss: 0.30021607875823975
Batch 41/64 loss: 0.30791032314300537
Batch 42/64 loss: 0.30668342113494873
Batch 43/64 loss: 0.3042869567871094
Batch 44/64 loss: 0.30704164505004883
Batch 45/64 loss: 0.3043711185455322
Batch 46/64 loss: 0.2998344898223877
Batch 47/64 loss: 0.3055275082588196
Batch 48/64 loss: 0.29496777057647705
Batch 49/64 loss: 0.30090177059173584
Batch 50/64 loss: 0.29172712564468384
Batch 51/64 loss: 0.2944049835205078
Batch 52/64 loss: 0.29589390754699707
Batch 53/64 loss: 0.29117345809936523
Batch 54/64 loss: 0.2896310091018677
Batch 55/64 loss: 0.29870176315307617
Batch 56/64 loss: 0.30040907859802246
Batch 57/64 loss: 0.3072511553764343
Batch 58/64 loss: 0.2992551326751709
Batch 59/64 loss: 0.2974739074707031
Batch 60/64 loss: 0.2964223623275757
Batch 61/64 loss: 0.29361480474472046
Batch 62/64 loss: 0.29688405990600586
Batch 63/64 loss: 0.29863888025283813
Batch 64/64 loss: 0.30373769998550415
Epoch 78  Train loss: 0.3001528980685215  Val loss: 0.3082685927345171
Saving best model, epoch: 78
Epoch 79
-------------------------------
Batch 1/64 loss: 0.3053550720214844
Batch 2/64 loss: 0.2976824641227722
Batch 3/64 loss: 0.2989121079444885
Batch 4/64 loss: 0.29317140579223633
Batch 5/64 loss: 0.30407392978668213
Batch 6/64 loss: 0.299648642539978
Batch 7/64 loss: 0.29560452699661255
Batch 8/64 loss: 0.3008110523223877
Batch 9/64 loss: 0.29829227924346924
Batch 10/64 loss: 0.3038337826728821
Batch 11/64 loss: 0.29042428731918335
Batch 12/64 loss: 0.2985098361968994
Batch 13/64 loss: 0.29714715480804443
Batch 14/64 loss: 0.3023947477340698
Batch 15/64 loss: 0.294020414352417
Batch 16/64 loss: 0.2881739139556885
Batch 17/64 loss: 0.29209208488464355
Batch 18/64 loss: 0.3051178455352783
Batch 19/64 loss: 0.2959822416305542
Batch 20/64 loss: 0.3067903518676758
Batch 21/64 loss: 0.31062912940979004
Batch 22/64 loss: 0.2985725402832031
Batch 23/64 loss: 0.28928816318511963
Batch 24/64 loss: 0.2944427728652954
Batch 25/64 loss: 0.29809874296188354
Batch 26/64 loss: 0.2999613285064697
Batch 27/64 loss: 0.29969120025634766
Batch 28/64 loss: 0.3093833923339844
Batch 29/64 loss: 0.29308199882507324
Batch 30/64 loss: 0.30462712049484253
Batch 31/64 loss: 0.30265045166015625
Batch 32/64 loss: 0.3027080297470093
Batch 33/64 loss: 0.3004198670387268
Batch 34/64 loss: 0.30063050985336304
Batch 35/64 loss: 0.2984524965286255
Batch 36/64 loss: 0.2977464199066162
Batch 37/64 loss: 0.3046748638153076
Batch 38/64 loss: 0.2989831566810608
Batch 39/64 loss: 0.3007699251174927
Batch 40/64 loss: 0.2970162034034729
Batch 41/64 loss: 0.2969449758529663
Batch 42/64 loss: 0.3013138175010681
Batch 43/64 loss: 0.30027246475219727
Batch 44/64 loss: 0.29756271839141846
Batch 45/64 loss: 0.3031679391860962
Batch 46/64 loss: 0.30167877674102783
Batch 47/64 loss: 0.29642951488494873
Batch 48/64 loss: 0.3037821054458618
Batch 49/64 loss: 0.30456095933914185
Batch 50/64 loss: 0.29085099697113037
Batch 51/64 loss: 0.2925378084182739
Batch 52/64 loss: 0.3042415380477905
Batch 53/64 loss: 0.3079072833061218
Batch 54/64 loss: 0.29614508152008057
Batch 55/64 loss: 0.2900722026824951
Batch 56/64 loss: 0.2989170551300049
Batch 57/64 loss: 0.29984456300735474
Batch 58/64 loss: 0.302154541015625
Batch 59/64 loss: 0.2943960428237915
Batch 60/64 loss: 0.30275166034698486
Batch 61/64 loss: 0.2924412488937378
Batch 62/64 loss: 0.29373180866241455
Batch 63/64 loss: 0.29105836153030396
Batch 64/64 loss: 0.2971160411834717
Epoch 79  Train loss: 0.2989092854892506  Val loss: 0.30714815855026245
Saving best model, epoch: 79
Epoch 80
-------------------------------
Batch 1/64 loss: 0.2908281087875366
Batch 2/64 loss: 0.29754114151000977
Batch 3/64 loss: 0.29387760162353516
Batch 4/64 loss: 0.29458868503570557
Batch 5/64 loss: 0.30238014459609985
Batch 6/64 loss: 0.29635918140411377
Batch 7/64 loss: 0.30029016733169556
Batch 8/64 loss: 0.29742658138275146
Batch 9/64 loss: 0.29896461963653564
Batch 10/64 loss: 0.2989685535430908
Batch 11/64 loss: 0.29542970657348633
Batch 12/64 loss: 0.29199302196502686
Batch 13/64 loss: 0.3030662536621094
Batch 14/64 loss: 0.29690778255462646
Batch 15/64 loss: 0.2952718734741211
Batch 16/64 loss: 0.29984843730926514
Batch 17/64 loss: 0.293174147605896
Batch 18/64 loss: 0.30247610807418823
Batch 19/64 loss: 0.2991374731063843
Batch 20/64 loss: 0.2912502884864807
Batch 21/64 loss: 0.2948527932167053
Batch 22/64 loss: 0.2963674068450928
Batch 23/64 loss: 0.2952619791030884
Batch 24/64 loss: 0.3081854581832886
Batch 25/64 loss: 0.30401772260665894
Batch 26/64 loss: 0.298331618309021
Batch 27/64 loss: 0.29600250720977783
Batch 28/64 loss: 0.29227256774902344
Batch 29/64 loss: 0.292308509349823
Batch 30/64 loss: 0.3009513020515442
Batch 31/64 loss: 0.30210041999816895
Batch 32/64 loss: 0.30138397216796875
Batch 33/64 loss: 0.3006019592285156
Batch 34/64 loss: 0.29897797107696533
Batch 35/64 loss: 0.3039358854293823
Batch 36/64 loss: 0.2976153492927551
Batch 37/64 loss: 0.2991856336593628
Batch 38/64 loss: 0.3052132725715637
Batch 39/64 loss: 0.2904322147369385
Batch 40/64 loss: 0.29697519540786743
Batch 41/64 loss: 0.29922330379486084
Batch 42/64 loss: 0.2964327931404114
Batch 43/64 loss: 0.29451441764831543
Batch 44/64 loss: 0.2965703010559082
Batch 45/64 loss: 0.30074089765548706
Batch 46/64 loss: 0.2982807159423828
Batch 47/64 loss: 0.3052403926849365
Batch 48/64 loss: 0.30363965034484863
Batch 49/64 loss: 0.3050207495689392
Batch 50/64 loss: 0.2994495630264282
Batch 51/64 loss: 0.29464787244796753
Batch 52/64 loss: 0.2941359281539917
Batch 53/64 loss: 0.3073267936706543
Batch 54/64 loss: 0.29964202642440796
Batch 55/64 loss: 0.3018970489501953
Batch 56/64 loss: 0.29333508014678955
Batch 57/64 loss: 0.30144524574279785
Batch 58/64 loss: 0.29392653703689575
Batch 59/64 loss: 0.30095452070236206
Batch 60/64 loss: 0.30639028549194336
Batch 61/64 loss: 0.3058152198791504
Batch 62/64 loss: 0.30081605911254883
Batch 63/64 loss: 0.2993365526199341
Batch 64/64 loss: 0.30660486221313477
Epoch 80  Train loss: 0.2987213994942459  Val loss: 0.3087504411890744
Epoch 81
-------------------------------
Batch 1/64 loss: 0.2937660217285156
Batch 2/64 loss: 0.29846370220184326
Batch 3/64 loss: 0.3016529083251953
Batch 4/64 loss: 0.2991485595703125
Batch 5/64 loss: 0.3062436580657959
Batch 6/64 loss: 0.2990529537200928
Batch 7/64 loss: 0.30531591176986694
Batch 8/64 loss: 0.3120154142379761
Batch 9/64 loss: 0.29853224754333496
Batch 10/64 loss: 0.29536354541778564
Batch 11/64 loss: 0.2935417890548706
Batch 12/64 loss: 0.29738515615463257
Batch 13/64 loss: 0.3032498359680176
Batch 14/64 loss: 0.2949399948120117
Batch 15/64 loss: 0.29768407344818115
Batch 16/64 loss: 0.29268819093704224
Batch 17/64 loss: 0.29842132329940796
Batch 18/64 loss: 0.29823780059814453
Batch 19/64 loss: 0.29519498348236084
Batch 20/64 loss: 0.2989537715911865
Batch 21/64 loss: 0.297993540763855
Batch 22/64 loss: 0.3027656078338623
Batch 23/64 loss: 0.29877758026123047
Batch 24/64 loss: 0.2957509756088257
Batch 25/64 loss: 0.2952750325202942
Batch 26/64 loss: 0.2924027442932129
Batch 27/64 loss: 0.29046666622161865
Batch 28/64 loss: 0.2942224144935608
Batch 29/64 loss: 0.2937527298927307
Batch 30/64 loss: 0.3024247884750366
Batch 31/64 loss: 0.30428969860076904
Batch 32/64 loss: 0.29307031631469727
Batch 33/64 loss: 0.30052340030670166
Batch 34/64 loss: 0.29975390434265137
Batch 35/64 loss: 0.30048781633377075
Batch 36/64 loss: 0.3002309799194336
Batch 37/64 loss: 0.2870219349861145
Batch 38/64 loss: 0.3017053008079529
Batch 39/64 loss: 0.29355454444885254
Batch 40/64 loss: 0.29976141452789307
Batch 41/64 loss: 0.2880837917327881
Batch 42/64 loss: 0.29266679286956787
Batch 43/64 loss: 0.3039771318435669
Batch 44/64 loss: 0.2934229373931885
Batch 45/64 loss: 0.3015463352203369
Batch 46/64 loss: 0.2959291934967041
Batch 47/64 loss: 0.2941650152206421
Batch 48/64 loss: 0.29957932233810425
Batch 49/64 loss: 0.30043792724609375
Batch 50/64 loss: 0.2968951463699341
Batch 51/64 loss: 0.3028567433357239
Batch 52/64 loss: 0.3096420168876648
Batch 53/64 loss: 0.2946956157684326
Batch 54/64 loss: 0.3019890785217285
Batch 55/64 loss: 0.2936908006668091
Batch 56/64 loss: 0.29771602153778076
Batch 57/64 loss: 0.295650839805603
Batch 58/64 loss: 0.2927372455596924
Batch 59/64 loss: 0.291683554649353
Batch 60/64 loss: 0.2981879711151123
Batch 61/64 loss: 0.30308103561401367
Batch 62/64 loss: 0.2994648218154907
Batch 63/64 loss: 0.300902783870697
Batch 64/64 loss: 0.29348617792129517
Epoch 81  Train loss: 0.2979325488501904  Val loss: 0.30628090093225957
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: 0.2963303327560425
Batch 2/64 loss: 0.29246532917022705
Batch 3/64 loss: 0.29398900270462036
Batch 4/64 loss: 0.303424596786499
Batch 5/64 loss: 0.2971593141555786
Batch 6/64 loss: 0.30634546279907227
Batch 7/64 loss: 0.29825711250305176
Batch 8/64 loss: 0.3005788326263428
Batch 9/64 loss: 0.29940497875213623
Batch 10/64 loss: 0.2912505865097046
Batch 11/64 loss: 0.2928037643432617
Batch 12/64 loss: 0.2960747480392456
Batch 13/64 loss: 0.2943766117095947
Batch 14/64 loss: 0.295288622379303
Batch 15/64 loss: 0.2896592617034912
Batch 16/64 loss: 0.2987186908721924
Batch 17/64 loss: 0.29992079734802246
Batch 18/64 loss: 0.3009645938873291
Batch 19/64 loss: 0.29334747791290283
Batch 20/64 loss: 0.30387771129608154
Batch 21/64 loss: 0.29405367374420166
Batch 22/64 loss: 0.30432450771331787
Batch 23/64 loss: 0.295268177986145
Batch 24/64 loss: 0.2930362820625305
Batch 25/64 loss: 0.29690366983413696
Batch 26/64 loss: 0.2994171977043152
Batch 27/64 loss: 0.2999296188354492
Batch 28/64 loss: 0.2947812080383301
Batch 29/64 loss: 0.29356813430786133
Batch 30/64 loss: 0.2967466115951538
Batch 31/64 loss: 0.2913864254951477
Batch 32/64 loss: 0.2927858233451843
Batch 33/64 loss: 0.29869866371154785
Batch 34/64 loss: 0.3009488582611084
Batch 35/64 loss: 0.29560065269470215
Batch 36/64 loss: 0.29968416690826416
Batch 37/64 loss: 0.2967548370361328
Batch 38/64 loss: 0.3032981753349304
Batch 39/64 loss: 0.2937126159667969
Batch 40/64 loss: 0.2909495234489441
Batch 41/64 loss: 0.299935519695282
Batch 42/64 loss: 0.28740668296813965
Batch 43/64 loss: 0.29743343591690063
Batch 44/64 loss: 0.28639358282089233
Batch 45/64 loss: 0.3009927272796631
Batch 46/64 loss: 0.30071860551834106
Batch 47/64 loss: 0.2956622838973999
Batch 48/64 loss: 0.3039591312408447
Batch 49/64 loss: 0.29657667875289917
Batch 50/64 loss: 0.293842077255249
Batch 51/64 loss: 0.29408276081085205
Batch 52/64 loss: 0.30258768796920776
Batch 53/64 loss: 0.3035968542098999
Batch 54/64 loss: 0.3020150661468506
Batch 55/64 loss: 0.296400249004364
Batch 56/64 loss: 0.29956376552581787
Batch 57/64 loss: 0.29734373092651367
Batch 58/64 loss: 0.29339486360549927
Batch 59/64 loss: 0.29167526960372925
Batch 60/64 loss: 0.3028695583343506
Batch 61/64 loss: 0.297096848487854
Batch 62/64 loss: 0.2964876890182495
Batch 63/64 loss: 0.3031461238861084
Batch 64/64 loss: 0.3008825182914734
Epoch 82  Train loss: 0.29717536837446923  Val loss: 0.30699907422475387
Epoch 83
-------------------------------
Batch 1/64 loss: 0.30433404445648193
Batch 2/64 loss: 0.30018705129623413
Batch 3/64 loss: 0.29834818840026855
Batch 4/64 loss: 0.293438196182251
Batch 5/64 loss: 0.2949650287628174
Batch 6/64 loss: 0.2945520877838135
Batch 7/64 loss: 0.2957908511161804
Batch 8/64 loss: 0.2966405153274536
Batch 9/64 loss: 0.2944490909576416
Batch 10/64 loss: 0.29530274868011475
Batch 11/64 loss: 0.2921000123023987
Batch 12/64 loss: 0.2997030019760132
Batch 13/64 loss: 0.2984468340873718
Batch 14/64 loss: 0.2958497405052185
Batch 15/64 loss: 0.2954913377761841
Batch 16/64 loss: 0.29968947172164917
Batch 17/64 loss: 0.29586803913116455
Batch 18/64 loss: 0.2968883514404297
Batch 19/64 loss: 0.29898059368133545
Batch 20/64 loss: 0.29043567180633545
Batch 21/64 loss: 0.2933826446533203
Batch 22/64 loss: 0.29424989223480225
Batch 23/64 loss: 0.292971134185791
Batch 24/64 loss: 0.29431819915771484
Batch 25/64 loss: 0.2999619245529175
Batch 26/64 loss: 0.2954827547073364
Batch 27/64 loss: 0.3002333641052246
Batch 28/64 loss: 0.29692864418029785
Batch 29/64 loss: 0.29595714807510376
Batch 30/64 loss: 0.29761481285095215
Batch 31/64 loss: 0.3011050820350647
Batch 32/64 loss: 0.29196274280548096
Batch 33/64 loss: 0.2906262278556824
Batch 34/64 loss: 0.2997317314147949
Batch 35/64 loss: 0.2985307574272156
Batch 36/64 loss: 0.2986936569213867
Batch 37/64 loss: 0.299649715423584
Batch 38/64 loss: 0.29165464639663696
Batch 39/64 loss: 0.3032034635543823
Batch 40/64 loss: 0.29180246591567993
Batch 41/64 loss: 0.29246407747268677
Batch 42/64 loss: 0.29615288972854614
Batch 43/64 loss: 0.3003003001213074
Batch 44/64 loss: 0.29272085428237915
Batch 45/64 loss: 0.2889127731323242
Batch 46/64 loss: 0.30336546897888184
Batch 47/64 loss: 0.30569350719451904
Batch 48/64 loss: 0.3046502470970154
Batch 49/64 loss: 0.29633069038391113
Batch 50/64 loss: 0.2974964380264282
Batch 51/64 loss: 0.29621565341949463
Batch 52/64 loss: 0.30681633949279785
Batch 53/64 loss: 0.29487162828445435
Batch 54/64 loss: 0.30408596992492676
Batch 55/64 loss: 0.29699790477752686
Batch 56/64 loss: 0.30391639471054077
Batch 57/64 loss: 0.2947651147842407
Batch 58/64 loss: 0.29502052068710327
Batch 59/64 loss: 0.2967945337295532
Batch 60/64 loss: 0.29460567235946655
Batch 61/64 loss: 0.30335038900375366
Batch 62/64 loss: 0.2888145446777344
Batch 63/64 loss: 0.29587793350219727
Batch 64/64 loss: 0.2953137159347534
Epoch 83  Train loss: 0.29696042350694246  Val loss: 0.3074503155918056
Epoch 84
-------------------------------
Batch 1/64 loss: 0.29586172103881836
Batch 2/64 loss: 0.2942013144493103
Batch 3/64 loss: 0.3003793954849243
Batch 4/64 loss: 0.2917096018791199
Batch 5/64 loss: 0.29881811141967773
Batch 6/64 loss: 0.2961897850036621
Batch 7/64 loss: 0.29227691888809204
Batch 8/64 loss: 0.2935614585876465
Batch 9/64 loss: 0.3005799651145935
Batch 10/64 loss: 0.29166126251220703
Batch 11/64 loss: 0.2984277009963989
Batch 12/64 loss: 0.2928941249847412
Batch 13/64 loss: 0.2952688932418823
Batch 14/64 loss: 0.2933192253112793
Batch 15/64 loss: 0.2923187017440796
Batch 16/64 loss: 0.29497838020324707
Batch 17/64 loss: 0.2946705222129822
Batch 18/64 loss: 0.2999499440193176
Batch 19/64 loss: 0.29505419731140137
Batch 20/64 loss: 0.3058320879936218
Batch 21/64 loss: 0.3003629446029663
Batch 22/64 loss: 0.30089282989501953
Batch 23/64 loss: 0.29422974586486816
Batch 24/64 loss: 0.30255186557769775
Batch 25/64 loss: 0.3048098087310791
Batch 26/64 loss: 0.2944035530090332
Batch 27/64 loss: 0.2974073886871338
Batch 28/64 loss: 0.30553650856018066
Batch 29/64 loss: 0.29583972692489624
Batch 30/64 loss: 0.3011847734451294
Batch 31/64 loss: 0.29619330167770386
Batch 32/64 loss: 0.2953276038169861
Batch 33/64 loss: 0.2965748906135559
Batch 34/64 loss: 0.29409801959991455
Batch 35/64 loss: 0.30908459424972534
Batch 36/64 loss: 0.29480040073394775
Batch 37/64 loss: 0.28999757766723633
Batch 38/64 loss: 0.3008995056152344
Batch 39/64 loss: 0.2990056872367859
Batch 40/64 loss: 0.2969760298728943
Batch 41/64 loss: 0.29466712474823
Batch 42/64 loss: 0.29277241230010986
Batch 43/64 loss: 0.29595285654067993
Batch 44/64 loss: 0.2955911159515381
Batch 45/64 loss: 0.2977321147918701
Batch 46/64 loss: 0.29517030715942383
Batch 47/64 loss: 0.29998958110809326
Batch 48/64 loss: 0.29609811305999756
Batch 49/64 loss: 0.29980313777923584
Batch 50/64 loss: 0.2922894358634949
Batch 51/64 loss: 0.3006325960159302
Batch 52/64 loss: 0.2852213382720947
Batch 53/64 loss: 0.29646122455596924
Batch 54/64 loss: 0.2902267575263977
Batch 55/64 loss: 0.3048267364501953
Batch 56/64 loss: 0.29432564973831177
Batch 57/64 loss: 0.29919326305389404
Batch 58/64 loss: 0.2924240827560425
Batch 59/64 loss: 0.2933264970779419
Batch 60/64 loss: 0.29422926902770996
Batch 61/64 loss: 0.2984888553619385
Batch 62/64 loss: 0.29597926139831543
Batch 63/64 loss: 0.3030889630317688
Batch 64/64 loss: 0.2987247109413147
Epoch 84  Train loss: 0.2967947340479084  Val loss: 0.3076052891020103
Epoch 85
-------------------------------
Batch 1/64 loss: 0.2938361167907715
Batch 2/64 loss: 0.28907573223114014
Batch 3/64 loss: 0.2943354845046997
Batch 4/64 loss: 0.2962125539779663
Batch 5/64 loss: 0.30040502548217773
Batch 6/64 loss: 0.29110270738601685
Batch 7/64 loss: 0.29031074047088623
Batch 8/64 loss: 0.29736506938934326
Batch 9/64 loss: 0.3075869083404541
Batch 10/64 loss: 0.3003275394439697
Batch 11/64 loss: 0.297818660736084
Batch 12/64 loss: 0.293213427066803
Batch 13/64 loss: 0.2944490313529968
Batch 14/64 loss: 0.29186224937438965
Batch 15/64 loss: 0.3018333911895752
Batch 16/64 loss: 0.29169702529907227
Batch 17/64 loss: 0.30451011657714844
Batch 18/64 loss: 0.29778754711151123
Batch 19/64 loss: 0.3000072240829468
Batch 20/64 loss: 0.29785895347595215
Batch 21/64 loss: 0.29137730598449707
Batch 22/64 loss: 0.29308855533599854
Batch 23/64 loss: 0.30049604177474976
Batch 24/64 loss: 0.29492855072021484
Batch 25/64 loss: 0.30100739002227783
Batch 26/64 loss: 0.30844104290008545
Batch 27/64 loss: 0.30109429359436035
Batch 28/64 loss: 0.29119402170181274
Batch 29/64 loss: 0.29028403759002686
Batch 30/64 loss: 0.29585397243499756
Batch 31/64 loss: 0.293010950088501
Batch 32/64 loss: 0.29342037439346313
Batch 33/64 loss: 0.2881779670715332
Batch 34/64 loss: 0.2983347773551941
Batch 35/64 loss: 0.3001190423965454
Batch 36/64 loss: 0.2994025945663452
Batch 37/64 loss: 0.2892305254936218
Batch 38/64 loss: 0.29775190353393555
Batch 39/64 loss: 0.2950516939163208
Batch 40/64 loss: 0.29092854261398315
Batch 41/64 loss: 0.28734415769577026
Batch 42/64 loss: 0.2948766350746155
Batch 43/64 loss: 0.29226160049438477
Batch 44/64 loss: 0.2910851240158081
Batch 45/64 loss: 0.3012809753417969
Batch 46/64 loss: 0.29792320728302
Batch 47/64 loss: 0.29420608282089233
Batch 48/64 loss: 0.29635828733444214
Batch 49/64 loss: 0.2943606376647949
Batch 50/64 loss: 0.29640042781829834
Batch 51/64 loss: 0.2876083254814148
Batch 52/64 loss: 0.2915974259376526
Batch 53/64 loss: 0.290712833404541
Batch 54/64 loss: 0.29539477825164795
Batch 55/64 loss: 0.2966412901878357
Batch 56/64 loss: 0.29671865701675415
Batch 57/64 loss: 0.2916002869606018
Batch 58/64 loss: 0.2937885522842407
Batch 59/64 loss: 0.2966243624687195
Batch 60/64 loss: 0.289911687374115
Batch 61/64 loss: 0.29219961166381836
Batch 62/64 loss: 0.29371070861816406
Batch 63/64 loss: 0.28586506843566895
Batch 64/64 loss: 0.2952168583869934
Epoch 85  Train loss: 0.2951321169441822  Val loss: 0.3050410817169242
Saving best model, epoch: 85
Epoch 86
-------------------------------
Batch 1/64 loss: 0.2862224578857422
Batch 2/64 loss: 0.294836163520813
Batch 3/64 loss: 0.2942705750465393
Batch 4/64 loss: 0.3001139760017395
Batch 5/64 loss: 0.287730872631073
Batch 6/64 loss: 0.3006148934364319
Batch 7/64 loss: 0.29269683361053467
Batch 8/64 loss: 0.3017815947532654
Batch 9/64 loss: 0.291367769241333
Batch 10/64 loss: 0.28835535049438477
Batch 11/64 loss: 0.2894524335861206
Batch 12/64 loss: 0.28800106048583984
Batch 13/64 loss: 0.29280686378479004
Batch 14/64 loss: 0.30066418647766113
Batch 15/64 loss: 0.29405856132507324
Batch 16/64 loss: 0.2853030562400818
Batch 17/64 loss: 0.2897223234176636
Batch 18/64 loss: 0.2911936044692993
Batch 19/64 loss: 0.3002464175224304
Batch 20/64 loss: 0.2987658977508545
Batch 21/64 loss: 0.29529762268066406
Batch 22/64 loss: 0.2966688871383667
Batch 23/64 loss: 0.28984367847442627
Batch 24/64 loss: 0.29621773958206177
Batch 25/64 loss: 0.29431653022766113
Batch 26/64 loss: 0.29229187965393066
Batch 27/64 loss: 0.2930601239204407
Batch 28/64 loss: 0.2924955487251282
Batch 29/64 loss: 0.3013100028038025
Batch 30/64 loss: 0.2965483069419861
Batch 31/64 loss: 0.297701895236969
Batch 32/64 loss: 0.30085527896881104
Batch 33/64 loss: 0.2967437505722046
Batch 34/64 loss: 0.2969846725463867
Batch 35/64 loss: 0.2943652272224426
Batch 36/64 loss: 0.31083226203918457
Batch 37/64 loss: 0.2939731478691101
Batch 38/64 loss: 0.2957465648651123
Batch 39/64 loss: 0.2938368320465088
Batch 40/64 loss: 0.3018476366996765
Batch 41/64 loss: 0.29396939277648926
Batch 42/64 loss: 0.293786883354187
Batch 43/64 loss: 0.29787254333496094
Batch 44/64 loss: 0.3043941259384155
Batch 45/64 loss: 0.3043522834777832
Batch 46/64 loss: 0.29470503330230713
Batch 47/64 loss: 0.29433417320251465
Batch 48/64 loss: 0.29783421754837036
Batch 49/64 loss: 0.29719722270965576
Batch 50/64 loss: 0.293471097946167
Batch 51/64 loss: 0.2939743399620056
Batch 52/64 loss: 0.30269211530685425
Batch 53/64 loss: 0.2908480167388916
Batch 54/64 loss: 0.2858484983444214
Batch 55/64 loss: 0.2922172546386719
Batch 56/64 loss: 0.29167282581329346
Batch 57/64 loss: 0.2895923852920532
Batch 58/64 loss: 0.3021467924118042
Batch 59/64 loss: 0.28843915462493896
Batch 60/64 loss: 0.29773950576782227
Batch 61/64 loss: 0.3002002239227295
Batch 62/64 loss: 0.29343104362487793
Batch 63/64 loss: 0.28871309757232666
Batch 64/64 loss: 0.2997962236404419
Epoch 86  Train loss: 0.2951125000037399  Val loss: 0.30412589971142534
Saving best model, epoch: 86
Epoch 87
-------------------------------
Batch 1/64 loss: 0.29145848751068115
Batch 2/64 loss: 0.29880738258361816
Batch 3/64 loss: 0.29393309354782104
Batch 4/64 loss: 0.2910228967666626
Batch 5/64 loss: 0.2956400513648987
Batch 6/64 loss: 0.29197293519973755
Batch 7/64 loss: 0.2921662926673889
Batch 8/64 loss: 0.28530001640319824
Batch 9/64 loss: 0.28493499755859375
Batch 10/64 loss: 0.29478752613067627
Batch 11/64 loss: 0.29091382026672363
Batch 12/64 loss: 0.29483550786972046
Batch 13/64 loss: 0.2841517925262451
Batch 14/64 loss: 0.28686559200286865
Batch 15/64 loss: 0.30041801929473877
Batch 16/64 loss: 0.2899102568626404
Batch 17/64 loss: 0.2899860739707947
Batch 18/64 loss: 0.29634785652160645
Batch 19/64 loss: 0.29958081245422363
Batch 20/64 loss: 0.28999269008636475
Batch 21/64 loss: 0.2931164503097534
Batch 22/64 loss: 0.28881943225860596
Batch 23/64 loss: 0.29509615898132324
Batch 24/64 loss: 0.29627788066864014
Batch 25/64 loss: 0.2888500690460205
Batch 26/64 loss: 0.28765785694122314
Batch 27/64 loss: 0.2982932925224304
Batch 28/64 loss: 0.3004935383796692
Batch 29/64 loss: 0.2898601293563843
Batch 30/64 loss: 0.2931966781616211
Batch 31/64 loss: 0.2968665361404419
Batch 32/64 loss: 0.2941526770591736
Batch 33/64 loss: 0.2895643711090088
Batch 34/64 loss: 0.28994494676589966
Batch 35/64 loss: 0.28814589977264404
Batch 36/64 loss: 0.29509437084198
Batch 37/64 loss: 0.28744345903396606
Batch 38/64 loss: 0.2966042757034302
Batch 39/64 loss: 0.2937511205673218
Batch 40/64 loss: 0.3006817102432251
Batch 41/64 loss: 0.29992061853408813
Batch 42/64 loss: 0.298214852809906
Batch 43/64 loss: 0.2933047413825989
Batch 44/64 loss: 0.29523563385009766
Batch 45/64 loss: 0.30332058668136597
Batch 46/64 loss: 0.29951393604278564
Batch 47/64 loss: 0.2928851842880249
Batch 48/64 loss: 0.30019640922546387
Batch 49/64 loss: 0.2923557758331299
Batch 50/64 loss: 0.29707062244415283
Batch 51/64 loss: 0.29525673389434814
Batch 52/64 loss: 0.30433595180511475
Batch 53/64 loss: 0.2969434857368469
Batch 54/64 loss: 0.2966383695602417
Batch 55/64 loss: 0.2893345355987549
Batch 56/64 loss: 0.29651105403900146
Batch 57/64 loss: 0.29130280017852783
Batch 58/64 loss: 0.29044222831726074
Batch 59/64 loss: 0.29707998037338257
Batch 60/64 loss: 0.2984201908111572
Batch 61/64 loss: 0.2938610315322876
Batch 62/64 loss: 0.29465752840042114
Batch 63/64 loss: 0.2957382798194885
Batch 64/64 loss: 0.29322367906570435
Epoch 87  Train loss: 0.293951297975054  Val loss: 0.30276390449287965
Saving best model, epoch: 87
Epoch 88
-------------------------------
Batch 1/64 loss: 0.30462467670440674
Batch 2/64 loss: 0.29485100507736206
Batch 3/64 loss: 0.29474014043807983
Batch 4/64 loss: 0.2977098822593689
Batch 5/64 loss: 0.2942342162132263
Batch 6/64 loss: 0.29040491580963135
Batch 7/64 loss: 0.2952842712402344
Batch 8/64 loss: 0.2939186096191406
Batch 9/64 loss: 0.2895026206970215
Batch 10/64 loss: 0.2914334535598755
Batch 11/64 loss: 0.2924572825431824
Batch 12/64 loss: 0.2912188768386841
Batch 13/64 loss: 0.29186326265335083
Batch 14/64 loss: 0.29536235332489014
Batch 15/64 loss: 0.29188430309295654
Batch 16/64 loss: 0.2868426442146301
Batch 17/64 loss: 0.29576051235198975
Batch 18/64 loss: 0.29439777135849
Batch 19/64 loss: 0.2915533781051636
Batch 20/64 loss: 0.29654932022094727
Batch 21/64 loss: 0.29820865392684937
Batch 22/64 loss: 0.29417091608047485
Batch 23/64 loss: 0.29180002212524414
Batch 24/64 loss: 0.30019843578338623
Batch 25/64 loss: 0.29375743865966797
Batch 26/64 loss: 0.29225534200668335
Batch 27/64 loss: 0.29130882024765015
Batch 28/64 loss: 0.2898150086402893
Batch 29/64 loss: 0.2941102981567383
Batch 30/64 loss: 0.2889763116836548
Batch 31/64 loss: 0.2963988184928894
Batch 32/64 loss: 0.2887255549430847
Batch 33/64 loss: 0.2919556498527527
Batch 34/64 loss: 0.2942444086074829
Batch 35/64 loss: 0.2901148796081543
Batch 36/64 loss: 0.29424357414245605
Batch 37/64 loss: 0.2929190397262573
Batch 38/64 loss: 0.29683905839920044
Batch 39/64 loss: 0.28828978538513184
Batch 40/64 loss: 0.2958410978317261
Batch 41/64 loss: 0.2946857213973999
Batch 42/64 loss: 0.29763174057006836
Batch 43/64 loss: 0.28610336780548096
Batch 44/64 loss: 0.2905551791191101
Batch 45/64 loss: 0.2947365641593933
Batch 46/64 loss: 0.3011568784713745
Batch 47/64 loss: 0.29362863302230835
Batch 48/64 loss: 0.28818851709365845
Batch 49/64 loss: 0.2965317368507385
Batch 50/64 loss: 0.2976225018501282
Batch 51/64 loss: 0.2922587990760803
Batch 52/64 loss: 0.28857219219207764
Batch 53/64 loss: 0.2943733334541321
Batch 54/64 loss: 0.2929738759994507
Batch 55/64 loss: 0.2882069945335388
Batch 56/64 loss: 0.28767216205596924
Batch 57/64 loss: 0.29843175411224365
Batch 58/64 loss: 0.296843945980072
Batch 59/64 loss: 0.2919602394104004
Batch 60/64 loss: 0.30275046825408936
Batch 61/64 loss: 0.2920241355895996
Batch 62/64 loss: 0.2944236993789673
Batch 63/64 loss: 0.28628915548324585
Batch 64/64 loss: 0.2848513722419739
Epoch 88  Train loss: 0.29333375271628886  Val loss: 0.3013955031063958
Saving best model, epoch: 88
Epoch 89
-------------------------------
Batch 1/64 loss: 0.2829320430755615
Batch 2/64 loss: 0.287286639213562
Batch 3/64 loss: 0.2853221893310547
Batch 4/64 loss: 0.29263049364089966
Batch 5/64 loss: 0.29086899757385254
Batch 6/64 loss: 0.29381024837493896
Batch 7/64 loss: 0.2893608808517456
Batch 8/64 loss: 0.28023695945739746
Batch 9/64 loss: 0.2833322286605835
Batch 10/64 loss: 0.29123079776763916
Batch 11/64 loss: 0.28844863176345825
Batch 12/64 loss: 0.3027958273887634
Batch 13/64 loss: 0.2961171865463257
Batch 14/64 loss: 0.28942859172821045
Batch 15/64 loss: 0.2925494909286499
Batch 16/64 loss: 0.299175500869751
Batch 17/64 loss: 0.30278193950653076
Batch 18/64 loss: 0.29086554050445557
Batch 19/64 loss: 0.2908686399459839
Batch 20/64 loss: 0.30163562297821045
Batch 21/64 loss: 0.2857694625854492
Batch 22/64 loss: 0.2904090881347656
Batch 23/64 loss: 0.29376429319381714
Batch 24/64 loss: 0.29493486881256104
Batch 25/64 loss: 0.3013664484024048
Batch 26/64 loss: 0.2978731393814087
Batch 27/64 loss: 0.2929390072822571
Batch 28/64 loss: 0.29916059970855713
Batch 29/64 loss: 0.29101747274398804
Batch 30/64 loss: 0.29389357566833496
Batch 31/64 loss: 0.2930312156677246
Batch 32/64 loss: 0.2891305088996887
Batch 33/64 loss: 0.29431474208831787
Batch 34/64 loss: 0.291795015335083
Batch 35/64 loss: 0.2912476062774658
Batch 36/64 loss: 0.2938317656517029
Batch 37/64 loss: 0.29997217655181885
Batch 38/64 loss: 0.2903096079826355
Batch 39/64 loss: 0.2955138683319092
Batch 40/64 loss: 0.2880784273147583
Batch 41/64 loss: 0.2883913516998291
Batch 42/64 loss: 0.29194802045822144
Batch 43/64 loss: 0.2947691082954407
Batch 44/64 loss: 0.2951035499572754
Batch 45/64 loss: 0.28628718852996826
Batch 46/64 loss: 0.30290687084198
Batch 47/64 loss: 0.2945054769515991
Batch 48/64 loss: 0.3001260757446289
Batch 49/64 loss: 0.2992922067642212
Batch 50/64 loss: 0.2909585237503052
Batch 51/64 loss: 0.2970895767211914
Batch 52/64 loss: 0.2913660407066345
Batch 53/64 loss: 0.2896069884300232
Batch 54/64 loss: 0.29478633403778076
Batch 55/64 loss: 0.286840558052063
Batch 56/64 loss: 0.2958853244781494
Batch 57/64 loss: 0.2919929027557373
Batch 58/64 loss: 0.2883412837982178
Batch 59/64 loss: 0.2987091541290283
Batch 60/64 loss: 0.2933086156845093
Batch 61/64 loss: 0.2930736541748047
Batch 62/64 loss: 0.2948240041732788
Batch 63/64 loss: 0.2964557409286499
Batch 64/64 loss: 0.29171323776245117
Epoch 89  Train loss: 0.2929472128550212  Val loss: 0.3011606640832121
Saving best model, epoch: 89
Epoch 90
-------------------------------
Batch 1/64 loss: 0.2921069860458374
Batch 2/64 loss: 0.287062406539917
Batch 3/64 loss: 0.28490614891052246
Batch 4/64 loss: 0.2951810359954834
Batch 5/64 loss: 0.291374146938324
Batch 6/64 loss: 0.29077744483947754
Batch 7/64 loss: 0.2913057804107666
Batch 8/64 loss: 0.29342520236968994
Batch 9/64 loss: 0.29996979236602783
Batch 10/64 loss: 0.3030574917793274
Batch 11/64 loss: 0.28550612926483154
Batch 12/64 loss: 0.2961777448654175
Batch 13/64 loss: 0.29445934295654297
Batch 14/64 loss: 0.2866445779800415
Batch 15/64 loss: 0.29038918018341064
Batch 16/64 loss: 0.2960638999938965
Batch 17/64 loss: 0.29997074604034424
Batch 18/64 loss: 0.2917059063911438
Batch 19/64 loss: 0.2966831922531128
Batch 20/64 loss: 0.2907024621963501
Batch 21/64 loss: 0.2931262254714966
Batch 22/64 loss: 0.2976667881011963
Batch 23/64 loss: 0.29355359077453613
Batch 24/64 loss: 0.2891765832901001
Batch 25/64 loss: 0.2906164526939392
Batch 26/64 loss: 0.28875142335891724
Batch 27/64 loss: 0.2948930263519287
Batch 28/64 loss: 0.289459764957428
Batch 29/64 loss: 0.2931710481643677
Batch 30/64 loss: 0.2930152416229248
Batch 31/64 loss: 0.29079943895339966
Batch 32/64 loss: 0.29212242364883423
Batch 33/64 loss: 0.2872081995010376
Batch 34/64 loss: 0.29137712717056274
Batch 35/64 loss: 0.29696547985076904
Batch 36/64 loss: 0.2925392985343933
Batch 37/64 loss: 0.28961479663848877
Batch 38/64 loss: 0.29281407594680786
Batch 39/64 loss: 0.294688880443573
Batch 40/64 loss: 0.28501278162002563
Batch 41/64 loss: 0.2980731129646301
Batch 42/64 loss: 0.3031156659126282
Batch 43/64 loss: 0.28987330198287964
Batch 44/64 loss: 0.29310524463653564
Batch 45/64 loss: 0.29338473081588745
Batch 46/64 loss: 0.29394984245300293
Batch 47/64 loss: 0.2894260883331299
Batch 48/64 loss: 0.28849369287490845
Batch 49/64 loss: 0.293007493019104
Batch 50/64 loss: 0.2912343144416809
Batch 51/64 loss: 0.2907140851020813
Batch 52/64 loss: 0.30125027894973755
Batch 53/64 loss: 0.289789617061615
Batch 54/64 loss: 0.2935396432876587
Batch 55/64 loss: 0.29026466608047485
Batch 56/64 loss: 0.286376953125
Batch 57/64 loss: 0.2916092872619629
Batch 58/64 loss: 0.2931227684020996
Batch 59/64 loss: 0.2907383441925049
Batch 60/64 loss: 0.29456400871276855
Batch 61/64 loss: 0.28017693758010864
Batch 62/64 loss: 0.29468488693237305
Batch 63/64 loss: 0.28849780559539795
Batch 64/64 loss: 0.28770577907562256
Epoch 90  Train loss: 0.2922166959912169  Val loss: 0.3017160134626828
Epoch 91
-------------------------------
Batch 1/64 loss: 0.2855820655822754
Batch 2/64 loss: 0.29793548583984375
Batch 3/64 loss: 0.2913205027580261
Batch 4/64 loss: 0.296602725982666
Batch 5/64 loss: 0.290141761302948
Batch 6/64 loss: 0.2920875549316406
Batch 7/64 loss: 0.28754568099975586
Batch 8/64 loss: 0.2890416383743286
Batch 9/64 loss: 0.29853588342666626
Batch 10/64 loss: 0.30093270540237427
Batch 11/64 loss: 0.2912166118621826
Batch 12/64 loss: 0.28738391399383545
Batch 13/64 loss: 0.29274362325668335
Batch 14/64 loss: 0.2922205328941345
Batch 15/64 loss: 0.29099416732788086
Batch 16/64 loss: 0.28802239894866943
Batch 17/64 loss: 0.2883536219596863
Batch 18/64 loss: 0.2891867160797119
Batch 19/64 loss: 0.3036442995071411
Batch 20/64 loss: 0.2877628207206726
Batch 21/64 loss: 0.2980000972747803
Batch 22/64 loss: 0.2914004921913147
Batch 23/64 loss: 0.30306124687194824
Batch 24/64 loss: 0.29273468255996704
Batch 25/64 loss: 0.29390740394592285
Batch 26/64 loss: 0.2886161208152771
Batch 27/64 loss: 0.294064462184906
Batch 28/64 loss: 0.2941066026687622
Batch 29/64 loss: 0.29097652435302734
Batch 30/64 loss: 0.2910459041595459
Batch 31/64 loss: 0.29259586334228516
Batch 32/64 loss: 0.2885843515396118
Batch 33/64 loss: 0.29572153091430664
Batch 34/64 loss: 0.289445161819458
Batch 35/64 loss: 0.29533851146698
Batch 36/64 loss: 0.2935510277748108
Batch 37/64 loss: 0.2895764112472534
Batch 38/64 loss: 0.2889278531074524
Batch 39/64 loss: 0.29954981803894043
Batch 40/64 loss: 0.29008495807647705
Batch 41/64 loss: 0.28731751441955566
Batch 42/64 loss: 0.29378652572631836
Batch 43/64 loss: 0.2852258086204529
Batch 44/64 loss: 0.28908705711364746
Batch 45/64 loss: 0.2929326295852661
Batch 46/64 loss: 0.28818023204803467
Batch 47/64 loss: 0.28401505947113037
Batch 48/64 loss: 0.2905809283256531
Batch 49/64 loss: 0.2935152053833008
Batch 50/64 loss: 0.2828301191329956
Batch 51/64 loss: 0.28895068168640137
Batch 52/64 loss: 0.2945864200592041
Batch 53/64 loss: 0.2917684316635132
Batch 54/64 loss: 0.2974684238433838
Batch 55/64 loss: 0.2887430191040039
Batch 56/64 loss: 0.2958632707595825
Batch 57/64 loss: 0.29655754566192627
Batch 58/64 loss: 0.2909553647041321
Batch 59/64 loss: 0.29435694217681885
Batch 60/64 loss: 0.2900592088699341
Batch 61/64 loss: 0.2879025936126709
Batch 62/64 loss: 0.2917135953903198
Batch 63/64 loss: 0.2892048954963684
Batch 64/64 loss: 0.2969766855239868
Epoch 91  Train loss: 0.29193533682355693  Val loss: 0.300103700447738
Saving best model, epoch: 91
Epoch 92
-------------------------------
Batch 1/64 loss: 0.28730309009552
Batch 2/64 loss: 0.2887779474258423
Batch 3/64 loss: 0.2819051742553711
Batch 4/64 loss: 0.29851746559143066
Batch 5/64 loss: 0.2852930426597595
Batch 6/64 loss: 0.29070866107940674
Batch 7/64 loss: 0.29521048069000244
Batch 8/64 loss: 0.287229061126709
Batch 9/64 loss: 0.28709912300109863
Batch 10/64 loss: 0.2910531759262085
Batch 11/64 loss: 0.2977309823036194
Batch 12/64 loss: 0.29678642749786377
Batch 13/64 loss: 0.28328293561935425
Batch 14/64 loss: 0.289139986038208
Batch 15/64 loss: 0.2872195243835449
Batch 16/64 loss: 0.29525089263916016
Batch 17/64 loss: 0.2909810543060303
Batch 18/64 loss: 0.2954130172729492
Batch 19/64 loss: 0.2932429909706116
Batch 20/64 loss: 0.2966247797012329
Batch 21/64 loss: 0.2893584966659546
Batch 22/64 loss: 0.28650879859924316
Batch 23/64 loss: 0.28962063789367676
Batch 24/64 loss: 0.28089141845703125
Batch 25/64 loss: 0.2907443046569824
Batch 26/64 loss: 0.2875128984451294
Batch 27/64 loss: 0.2930176258087158
Batch 28/64 loss: 0.28657007217407227
Batch 29/64 loss: 0.29600900411605835
Batch 30/64 loss: 0.2915562391281128
Batch 31/64 loss: 0.28791284561157227
Batch 32/64 loss: 0.29427897930145264
Batch 33/64 loss: 0.2905610203742981
Batch 34/64 loss: 0.2955131530761719
Batch 35/64 loss: 0.2866712212562561
Batch 36/64 loss: 0.2872258424758911
Batch 37/64 loss: 0.2912166118621826
Batch 38/64 loss: 0.2884114980697632
Batch 39/64 loss: 0.2949081063270569
Batch 40/64 loss: 0.28925663232803345
Batch 41/64 loss: 0.2915017604827881
Batch 42/64 loss: 0.29014527797698975
Batch 43/64 loss: 0.2921651005744934
Batch 44/64 loss: 0.29382020235061646
Batch 45/64 loss: 0.2974388599395752
Batch 46/64 loss: 0.29943764209747314
Batch 47/64 loss: 0.29269880056381226
Batch 48/64 loss: 0.29459941387176514
Batch 49/64 loss: 0.2924785614013672
Batch 50/64 loss: 0.29348504543304443
Batch 51/64 loss: 0.29136383533477783
Batch 52/64 loss: 0.29533475637435913
Batch 53/64 loss: 0.2949914336204529
Batch 54/64 loss: 0.29568934440612793
Batch 55/64 loss: 0.29248976707458496
Batch 56/64 loss: 0.29054850339889526
Batch 57/64 loss: 0.29126954078674316
Batch 58/64 loss: 0.2857639789581299
Batch 59/64 loss: 0.292505145072937
Batch 60/64 loss: 0.29505860805511475
Batch 61/64 loss: 0.28696733713150024
Batch 62/64 loss: 0.29989951848983765
Batch 63/64 loss: 0.29263007640838623
Batch 64/64 loss: 0.2902008891105652
Epoch 92  Train loss: 0.29139526895448276  Val loss: 0.3014585101317704
Epoch 93
-------------------------------
Batch 1/64 loss: 0.2907940149307251
Batch 2/64 loss: 0.28836625814437866
Batch 3/64 loss: 0.2931433916091919
Batch 4/64 loss: 0.2878565192222595
Batch 5/64 loss: 0.294486939907074
Batch 6/64 loss: 0.2898377776145935
Batch 7/64 loss: 0.29584211111068726
Batch 8/64 loss: 0.29132401943206787
Batch 9/64 loss: 0.29625046253204346
Batch 10/64 loss: 0.289059042930603
Batch 11/64 loss: 0.2883542776107788
Batch 12/64 loss: 0.29401659965515137
Batch 13/64 loss: 0.2908996343612671
Batch 14/64 loss: 0.29126501083374023
Batch 15/64 loss: 0.2992440462112427
Batch 16/64 loss: 0.2857022285461426
Batch 17/64 loss: 0.2837789058685303
Batch 18/64 loss: 0.2812528610229492
Batch 19/64 loss: 0.29096871614456177
Batch 20/64 loss: 0.2852736711502075
Batch 21/64 loss: 0.28674954175949097
Batch 22/64 loss: 0.2861393690109253
Batch 23/64 loss: 0.2899731397628784
Batch 24/64 loss: 0.29768073558807373
Batch 25/64 loss: 0.282509446144104
Batch 26/64 loss: 0.2840381860733032
Batch 27/64 loss: 0.29379671812057495
Batch 28/64 loss: 0.3038024306297302
Batch 29/64 loss: 0.2914581298828125
Batch 30/64 loss: 0.3005549907684326
Batch 31/64 loss: 0.2905290722846985
Batch 32/64 loss: 0.293415904045105
Batch 33/64 loss: 0.29444336891174316
Batch 34/64 loss: 0.28606152534484863
Batch 35/64 loss: 0.2898908853530884
Batch 36/64 loss: 0.29180604219436646
Batch 37/64 loss: 0.28910142183303833
Batch 38/64 loss: 0.2958970069885254
Batch 39/64 loss: 0.2927592992782593
Batch 40/64 loss: 0.2895011305809021
Batch 41/64 loss: 0.28904974460601807
Batch 42/64 loss: 0.29268908500671387
Batch 43/64 loss: 0.29593390226364136
Batch 44/64 loss: 0.29029107093811035
Batch 45/64 loss: 0.287597119808197
Batch 46/64 loss: 0.2891502380371094
Batch 47/64 loss: 0.30446934700012207
Batch 48/64 loss: 0.29084324836730957
Batch 49/64 loss: 0.29453253746032715
Batch 50/64 loss: 0.2963217496871948
Batch 51/64 loss: 0.2896616458892822
Batch 52/64 loss: 0.287609338760376
Batch 53/64 loss: 0.2853846549987793
Batch 54/64 loss: 0.2943655252456665
Batch 55/64 loss: 0.29135453701019287
Batch 56/64 loss: 0.2844141721725464
Batch 57/64 loss: 0.3036413788795471
Batch 58/64 loss: 0.29533499479293823
Batch 59/64 loss: 0.2886766195297241
Batch 60/64 loss: 0.2871395945549011
Batch 61/64 loss: 0.28825843334198
Batch 62/64 loss: 0.2953794002532959
Batch 63/64 loss: 0.2883005142211914
Batch 64/64 loss: 0.28745925426483154
Epoch 93  Train loss: 0.2911971470888923  Val loss: 0.30191517982286276
Epoch 94
-------------------------------
Batch 1/64 loss: 0.2836494445800781
Batch 2/64 loss: 0.28945672512054443
Batch 3/64 loss: 0.29528355598449707
Batch 4/64 loss: 0.28875261545181274
Batch 5/64 loss: 0.28855860233306885
Batch 6/64 loss: 0.29484105110168457
Batch 7/64 loss: 0.2899973392486572
Batch 8/64 loss: 0.2912604808807373
Batch 9/64 loss: 0.2914040684700012
Batch 10/64 loss: 0.28750985860824585
Batch 11/64 loss: 0.2862560749053955
Batch 12/64 loss: 0.28890562057495117
Batch 13/64 loss: 0.2893616557121277
Batch 14/64 loss: 0.2922213077545166
Batch 15/64 loss: 0.29789531230926514
Batch 16/64 loss: 0.2886006832122803
Batch 17/64 loss: 0.2838708162307739
Batch 18/64 loss: 0.2892659902572632
Batch 19/64 loss: 0.303871750831604
Batch 20/64 loss: 0.2897442579269409
Batch 21/64 loss: 0.2790144085884094
Batch 22/64 loss: 0.28988081216812134
Batch 23/64 loss: 0.2899348735809326
Batch 24/64 loss: 0.2832316756248474
Batch 25/64 loss: 0.290280818939209
Batch 26/64 loss: 0.2876863479614258
Batch 27/64 loss: 0.28473591804504395
Batch 28/64 loss: 0.28822070360183716
Batch 29/64 loss: 0.2909887433052063
Batch 30/64 loss: 0.2875850200653076
Batch 31/64 loss: 0.2876713275909424
Batch 32/64 loss: 0.29134082794189453
Batch 33/64 loss: 0.2888519763946533
Batch 34/64 loss: 0.2920718789100647
Batch 35/64 loss: 0.28634846210479736
Batch 36/64 loss: 0.2936442494392395
Batch 37/64 loss: 0.28757238388061523
Batch 38/64 loss: 0.2849602699279785
Batch 39/64 loss: 0.300431489944458
Batch 40/64 loss: 0.2912272810935974
Batch 41/64 loss: 0.28809475898742676
Batch 42/64 loss: 0.2867344617843628
Batch 43/64 loss: 0.290945827960968
Batch 44/64 loss: 0.28789854049682617
Batch 45/64 loss: 0.2967537045478821
Batch 46/64 loss: 0.287666916847229
Batch 47/64 loss: 0.2989051342010498
Batch 48/64 loss: 0.2919287085533142
Batch 49/64 loss: 0.2932727336883545
Batch 50/64 loss: 0.288102388381958
Batch 51/64 loss: 0.2957337498664856
Batch 52/64 loss: 0.29296016693115234
Batch 53/64 loss: 0.29693710803985596
Batch 54/64 loss: 0.30420082807540894
Batch 55/64 loss: 0.29841822385787964
Batch 56/64 loss: 0.29032111167907715
Batch 57/64 loss: 0.2873522639274597
Batch 58/64 loss: 0.2921789884567261
Batch 59/64 loss: 0.28691089153289795
Batch 60/64 loss: 0.2855032682418823
Batch 61/64 loss: 0.2884114384651184
Batch 62/64 loss: 0.2885957956314087
Batch 63/64 loss: 0.29114508628845215
Batch 64/64 loss: 0.29785704612731934
Epoch 94  Train loss: 0.29049022057477164  Val loss: 0.302621266481393
Epoch 95
-------------------------------
Batch 1/64 loss: 0.29073596000671387
Batch 2/64 loss: 0.28901565074920654
Batch 3/64 loss: 0.2949792146682739
Batch 4/64 loss: 0.29392194747924805
Batch 5/64 loss: 0.2814664840698242
Batch 6/64 loss: 0.2880905270576477
Batch 7/64 loss: 0.2895700931549072
Batch 8/64 loss: 0.287874698638916
Batch 9/64 loss: 0.2893977761268616
Batch 10/64 loss: 0.2890242338180542
Batch 11/64 loss: 0.2857826352119446
Batch 12/64 loss: 0.2899777889251709
Batch 13/64 loss: 0.2879332900047302
Batch 14/64 loss: 0.2885040044784546
Batch 15/64 loss: 0.2849719524383545
Batch 16/64 loss: 0.2826024293899536
Batch 17/64 loss: 0.2868579626083374
Batch 18/64 loss: 0.29529356956481934
Batch 19/64 loss: 0.29204678535461426
Batch 20/64 loss: 0.29375994205474854
Batch 21/64 loss: 0.291088342666626
Batch 22/64 loss: 0.28134602308273315
Batch 23/64 loss: 0.2871221899986267
Batch 24/64 loss: 0.28654128313064575
Batch 25/64 loss: 0.28970831632614136
Batch 26/64 loss: 0.28878653049468994
Batch 27/64 loss: 0.29076945781707764
Batch 28/64 loss: 0.28337639570236206
Batch 29/64 loss: 0.2921745777130127
Batch 30/64 loss: 0.2984985113143921
Batch 31/64 loss: 0.2849258780479431
Batch 32/64 loss: 0.2924284338951111
Batch 33/64 loss: 0.2819482684135437
Batch 34/64 loss: 0.29063892364501953
Batch 35/64 loss: 0.2902097702026367
Batch 36/64 loss: 0.29274702072143555
Batch 37/64 loss: 0.2944374084472656
Batch 38/64 loss: 0.2866685390472412
Batch 39/64 loss: 0.2843860387802124
Batch 40/64 loss: 0.28662586212158203
Batch 41/64 loss: 0.2854752540588379
Batch 42/64 loss: 0.28978121280670166
Batch 43/64 loss: 0.2899278998374939
Batch 44/64 loss: 0.2980990409851074
Batch 45/64 loss: 0.2831941843032837
Batch 46/64 loss: 0.28469765186309814
Batch 47/64 loss: 0.29250144958496094
Batch 48/64 loss: 0.2860720157623291
Batch 49/64 loss: 0.2862784266471863
Batch 50/64 loss: 0.29059362411499023
Batch 51/64 loss: 0.28685760498046875
Batch 52/64 loss: 0.2888143062591553
Batch 53/64 loss: 0.2853890061378479
Batch 54/64 loss: 0.282858669757843
Batch 55/64 loss: 0.2857332229614258
Batch 56/64 loss: 0.2945173978805542
Batch 57/64 loss: 0.29060548543930054
Batch 58/64 loss: 0.29035621881484985
Batch 59/64 loss: 0.2990802526473999
Batch 60/64 loss: 0.2942361831665039
Batch 61/64 loss: 0.2899075746536255
Batch 62/64 loss: 0.2879410982131958
Batch 63/64 loss: 0.2853947877883911
Batch 64/64 loss: 0.2920100688934326
Epoch 95  Train loss: 0.28899693863064635  Val loss: 0.2991868218605461
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: 0.28742802143096924
Batch 2/64 loss: 0.2952115535736084
Batch 3/64 loss: 0.28695642948150635
Batch 4/64 loss: 0.2928212881088257
Batch 5/64 loss: 0.28410208225250244
Batch 6/64 loss: 0.2878068685531616
Batch 7/64 loss: 0.28950178623199463
Batch 8/64 loss: 0.28159767389297485
Batch 9/64 loss: 0.2869328260421753
Batch 10/64 loss: 0.2868592143058777
Batch 11/64 loss: 0.27855151891708374
Batch 12/64 loss: 0.29303598403930664
Batch 13/64 loss: 0.29472267627716064
Batch 14/64 loss: 0.2902791500091553
Batch 15/64 loss: 0.2862842082977295
Batch 16/64 loss: 0.2832396626472473
Batch 17/64 loss: 0.2948717474937439
Batch 18/64 loss: 0.29411405324935913
Batch 19/64 loss: 0.2961016893386841
Batch 20/64 loss: 0.28799009323120117
Batch 21/64 loss: 0.28560566902160645
Batch 22/64 loss: 0.291604220867157
Batch 23/64 loss: 0.2888122797012329
Batch 24/64 loss: 0.28990620374679565
Batch 25/64 loss: 0.30202174186706543
Batch 26/64 loss: 0.28750431537628174
Batch 27/64 loss: 0.2814520001411438
Batch 28/64 loss: 0.28222978115081787
Batch 29/64 loss: 0.2945411205291748
Batch 30/64 loss: 0.2923099398612976
Batch 31/64 loss: 0.2927062511444092
Batch 32/64 loss: 0.287456750869751
Batch 33/64 loss: 0.29460638761520386
Batch 34/64 loss: 0.2903802990913391
Batch 35/64 loss: 0.29009097814559937
Batch 36/64 loss: 0.2879951000213623
Batch 37/64 loss: 0.29300665855407715
Batch 38/64 loss: 0.28813862800598145
Batch 39/64 loss: 0.291016161441803
Batch 40/64 loss: 0.2915841341018677
Batch 41/64 loss: 0.2865123748779297
Batch 42/64 loss: 0.2954843044281006
Batch 43/64 loss: 0.2913707494735718
Batch 44/64 loss: 0.28858935832977295
Batch 45/64 loss: 0.2868443727493286
Batch 46/64 loss: 0.2919272184371948
Batch 47/64 loss: 0.2885793447494507
Batch 48/64 loss: 0.2903714179992676
Batch 49/64 loss: 0.2888394594192505
Batch 50/64 loss: 0.28743529319763184
Batch 51/64 loss: 0.28819966316223145
Batch 52/64 loss: 0.2998112440109253
Batch 53/64 loss: 0.30177557468414307
Batch 54/64 loss: 0.28936684131622314
Batch 55/64 loss: 0.28131401538848877
Batch 56/64 loss: 0.28177714347839355
Batch 57/64 loss: 0.29697954654693604
Batch 58/64 loss: 0.28421878814697266
Batch 59/64 loss: 0.2970397472381592
Batch 60/64 loss: 0.30120623111724854
Batch 61/64 loss: 0.28339290618896484
Batch 62/64 loss: 0.2929239869117737
Batch 63/64 loss: 0.28049707412719727
Batch 64/64 loss: 0.28342825174331665
Epoch 96  Train loss: 0.2897004704849393  Val loss: 0.3016266175561754
Epoch 97
-------------------------------
Batch 1/64 loss: 0.2870326042175293
Batch 2/64 loss: 0.29410219192504883
Batch 3/64 loss: 0.2923562526702881
Batch 4/64 loss: 0.2896662950515747
Batch 5/64 loss: 0.2923387289047241
Batch 6/64 loss: 0.290554404258728
Batch 7/64 loss: 0.2905080318450928
Batch 8/64 loss: 0.29038500785827637
Batch 9/64 loss: 0.2942160964012146
Batch 10/64 loss: 0.29137206077575684
Batch 11/64 loss: 0.2916415333747864
Batch 12/64 loss: 0.2920013666152954
Batch 13/64 loss: 0.2956780791282654
Batch 14/64 loss: 0.29979944229125977
Batch 15/64 loss: 0.28927385807037354
Batch 16/64 loss: 0.29442065954208374
Batch 17/64 loss: 0.2889232635498047
Batch 18/64 loss: 0.28656673431396484
Batch 19/64 loss: 0.28268933296203613
Batch 20/64 loss: 0.2893483638763428
Batch 21/64 loss: 0.28022390604019165
Batch 22/64 loss: 0.27665406465530396
Batch 23/64 loss: 0.2860374450683594
Batch 24/64 loss: 0.29138320684432983
Batch 25/64 loss: 0.2878979444503784
Batch 26/64 loss: 0.2867830991744995
Batch 27/64 loss: 0.2954467535018921
Batch 28/64 loss: 0.2920123338699341
Batch 29/64 loss: 0.29253673553466797
Batch 30/64 loss: 0.29389894008636475
Batch 31/64 loss: 0.300032377243042
Batch 32/64 loss: 0.28536832332611084
Batch 33/64 loss: 0.2856023907661438
Batch 34/64 loss: 0.28746312856674194
Batch 35/64 loss: 0.2877107262611389
Batch 36/64 loss: 0.2868213653564453
Batch 37/64 loss: 0.2897570729255676
Batch 38/64 loss: 0.2919492721557617
Batch 39/64 loss: 0.2876009941101074
Batch 40/64 loss: 0.28687095642089844
Batch 41/64 loss: 0.28482627868652344
Batch 42/64 loss: 0.28802013397216797
Batch 43/64 loss: 0.29169803857803345
Batch 44/64 loss: 0.2965877652168274
Batch 45/64 loss: 0.2834377884864807
Batch 46/64 loss: 0.2922379970550537
Batch 47/64 loss: 0.2884373664855957
Batch 48/64 loss: 0.29148006439208984
Batch 49/64 loss: 0.2847350835800171
Batch 50/64 loss: 0.28286874294281006
Batch 51/64 loss: 0.2869199514389038
Batch 52/64 loss: 0.27953040599823
Batch 53/64 loss: 0.28145891427993774
Batch 54/64 loss: 0.2912938594818115
Batch 55/64 loss: 0.28516680002212524
Batch 56/64 loss: 0.2947924733161926
Batch 57/64 loss: 0.2855255603790283
Batch 58/64 loss: 0.28570711612701416
Batch 59/64 loss: 0.2900489568710327
Batch 60/64 loss: 0.29302096366882324
Batch 61/64 loss: 0.2934214472770691
Batch 62/64 loss: 0.28786683082580566
Batch 63/64 loss: 0.2817727327346802
Batch 64/64 loss: 0.2895965576171875
Epoch 97  Train loss: 0.2891447534748152  Val loss: 0.2984086121480489
Saving best model, epoch: 97
Epoch 98
-------------------------------
Batch 1/64 loss: 0.2863776683807373
Batch 2/64 loss: 0.2836316227912903
Batch 3/64 loss: 0.28612208366394043
Batch 4/64 loss: 0.2876253128051758
Batch 5/64 loss: 0.2851727604866028
Batch 6/64 loss: 0.29038166999816895
Batch 7/64 loss: 0.2868712544441223
Batch 8/64 loss: 0.28921765089035034
Batch 9/64 loss: 0.28188198804855347
Batch 10/64 loss: 0.28537559509277344
Batch 11/64 loss: 0.28956490755081177
Batch 12/64 loss: 0.29617440700531006
Batch 13/64 loss: 0.2868298292160034
Batch 14/64 loss: 0.2893397808074951
Batch 15/64 loss: 0.28800344467163086
Batch 16/64 loss: 0.29125750064849854
Batch 17/64 loss: 0.28372007608413696
Batch 18/64 loss: 0.29258400201797485
Batch 19/64 loss: 0.2922857999801636
Batch 20/64 loss: 0.287534236907959
Batch 21/64 loss: 0.2891794443130493
Batch 22/64 loss: 0.277385950088501
Batch 23/64 loss: 0.29072731733322144
Batch 24/64 loss: 0.2917732000350952
Batch 25/64 loss: 0.28851228952407837
Batch 26/64 loss: 0.2917916774749756
Batch 27/64 loss: 0.2864232659339905
Batch 28/64 loss: 0.2872132658958435
Batch 29/64 loss: 0.2853580713272095
Batch 30/64 loss: 0.28519582748413086
Batch 31/64 loss: 0.2870047092437744
Batch 32/64 loss: 0.2899589538574219
Batch 33/64 loss: 0.2913588881492615
Batch 34/64 loss: 0.2869701385498047
Batch 35/64 loss: 0.27792370319366455
Batch 36/64 loss: 0.2871987819671631
Batch 37/64 loss: 0.2868093252182007
Batch 38/64 loss: 0.2897181510925293
Batch 39/64 loss: 0.28061509132385254
Batch 40/64 loss: 0.29812121391296387
Batch 41/64 loss: 0.2892393469810486
Batch 42/64 loss: 0.28915488719940186
Batch 43/64 loss: 0.28772687911987305
Batch 44/64 loss: 0.2921551465988159
Batch 45/64 loss: 0.27816540002822876
Batch 46/64 loss: 0.28549325466156006
Batch 47/64 loss: 0.28666824102401733
Batch 48/64 loss: 0.29336822032928467
Batch 49/64 loss: 0.2863471508026123
Batch 50/64 loss: 0.2867659330368042
Batch 51/64 loss: 0.28810083866119385
Batch 52/64 loss: 0.2867498993873596
Batch 53/64 loss: 0.2908393144607544
Batch 54/64 loss: 0.2857624888420105
Batch 55/64 loss: 0.281096875667572
Batch 56/64 loss: 0.2807267904281616
Batch 57/64 loss: 0.28962069749832153
Batch 58/64 loss: 0.2907397747039795
Batch 59/64 loss: 0.28898370265960693
Batch 60/64 loss: 0.293765664100647
Batch 61/64 loss: 0.29082322120666504
Batch 62/64 loss: 0.28295713663101196
Batch 63/64 loss: 0.288791298866272
Batch 64/64 loss: 0.2891518473625183
Epoch 98  Train loss: 0.287687794601216  Val loss: 0.2982472359519644
Saving best model, epoch: 98
Epoch 99
-------------------------------
Batch 1/64 loss: 0.2909007668495178
Batch 2/64 loss: 0.28553617000579834
Batch 3/64 loss: 0.2890803813934326
Batch 4/64 loss: 0.29544007778167725
Batch 5/64 loss: 0.28640878200531006
Batch 6/64 loss: 0.28719186782836914
Batch 7/64 loss: 0.29220229387283325
Batch 8/64 loss: 0.28215712308883667
Batch 9/64 loss: 0.28720736503601074
Batch 10/64 loss: 0.2838073968887329
Batch 11/64 loss: 0.2932788133621216
Batch 12/64 loss: 0.28473126888275146
Batch 13/64 loss: 0.2899129390716553
Batch 14/64 loss: 0.2794305682182312
Batch 15/64 loss: 0.28508836030960083
Batch 16/64 loss: 0.2906186580657959
Batch 17/64 loss: 0.28432244062423706
Batch 18/64 loss: 0.2862933874130249
Batch 19/64 loss: 0.2884122133255005
Batch 20/64 loss: 0.2847924828529358
Batch 21/64 loss: 0.27993690967559814
Batch 22/64 loss: 0.2846391797065735
Batch 23/64 loss: 0.2887701392173767
Batch 24/64 loss: 0.2853769063949585
Batch 25/64 loss: 0.2893525958061218
Batch 26/64 loss: 0.28079015016555786
Batch 27/64 loss: 0.2884960174560547
Batch 28/64 loss: 0.2924433946609497
Batch 29/64 loss: 0.29145532846450806
Batch 30/64 loss: 0.2894827127456665
Batch 31/64 loss: 0.2902117967605591
Batch 32/64 loss: 0.2778041958808899
Batch 33/64 loss: 0.2935013771057129
Batch 34/64 loss: 0.2833625078201294
Batch 35/64 loss: 0.28462541103363037
Batch 36/64 loss: 0.28412413597106934
Batch 37/64 loss: 0.2930590510368347
Batch 38/64 loss: 0.28699588775634766
Batch 39/64 loss: 0.28526681661605835
Batch 40/64 loss: 0.2981448769569397
Batch 41/64 loss: 0.28226709365844727
Batch 42/64 loss: 0.27826690673828125
Batch 43/64 loss: 0.29059094190597534
Batch 44/64 loss: 0.28947341442108154
Batch 45/64 loss: 0.2906135320663452
Batch 46/64 loss: 0.2886073589324951
Batch 47/64 loss: 0.28474491834640503
Batch 48/64 loss: 0.28662705421447754
Batch 49/64 loss: 0.28996068239212036
Batch 50/64 loss: 0.2893962860107422
Batch 51/64 loss: 0.28801435232162476
Batch 52/64 loss: 0.28655338287353516
Batch 53/64 loss: 0.28054630756378174
Batch 54/64 loss: 0.2874886393547058
Batch 55/64 loss: 0.2822967767715454
Batch 56/64 loss: 0.29105961322784424
Batch 57/64 loss: 0.2964293956756592
Batch 58/64 loss: 0.294674813747406
Batch 59/64 loss: 0.29028117656707764
Batch 60/64 loss: 0.29046130180358887
Batch 61/64 loss: 0.28402066230773926
Batch 62/64 loss: 0.28440219163894653
Batch 63/64 loss: 0.2895461916923523
Batch 64/64 loss: 0.29014086723327637
Epoch 99  Train loss: 0.28750715910219676  Val loss: 0.29922289803265706
Epoch 100
-------------------------------
Batch 1/64 loss: 0.2866830825805664
Batch 2/64 loss: 0.2826646566390991
Batch 3/64 loss: 0.29118990898132324
Batch 4/64 loss: 0.29098987579345703
Batch 5/64 loss: 0.28834009170532227
Batch 6/64 loss: 0.2886766195297241
Batch 7/64 loss: 0.2880532741546631
Batch 8/64 loss: 0.3038828372955322
Batch 9/64 loss: 0.28465163707733154
Batch 10/64 loss: 0.2884131669998169
Batch 11/64 loss: 0.2816702127456665
Batch 12/64 loss: 0.28684210777282715
Batch 13/64 loss: 0.28480398654937744
Batch 14/64 loss: 0.28644585609436035
Batch 15/64 loss: 0.27894705533981323
Batch 16/64 loss: 0.2761322259902954
Batch 17/64 loss: 0.2885620594024658
Batch 18/64 loss: 0.28099745512008667
Batch 19/64 loss: 0.28775596618652344
Batch 20/64 loss: 0.29222381114959717
Batch 21/64 loss: 0.28879064321517944
Batch 22/64 loss: 0.28427624702453613
Batch 23/64 loss: 0.2812654376029968
Batch 24/64 loss: 0.28937727212905884
Batch 25/64 loss: 0.2854580879211426
Batch 26/64 loss: 0.2874159812927246
Batch 27/64 loss: 0.28475338220596313
Batch 28/64 loss: 0.2848605513572693
Batch 29/64 loss: 0.27748554944992065
Batch 30/64 loss: 0.2916405200958252
Batch 31/64 loss: 0.2902705669403076
Batch 32/64 loss: 0.28773200511932373
Batch 33/64 loss: 0.2899945378303528
Batch 34/64 loss: 0.28563445806503296
Batch 35/64 loss: 0.2936047911643982
Batch 36/64 loss: 0.2782851457595825
Batch 37/64 loss: 0.2876245379447937
Batch 38/64 loss: 0.2890222668647766
Batch 39/64 loss: 0.2898126244544983
Batch 40/64 loss: 0.28579914569854736
Batch 41/64 loss: 0.27900052070617676
Batch 42/64 loss: 0.2899513244628906
Batch 43/64 loss: 0.29273247718811035
Batch 44/64 loss: 0.28330135345458984
Batch 45/64 loss: 0.2911868095397949
Batch 46/64 loss: 0.28211724758148193
Batch 47/64 loss: 0.29295051097869873
Batch 48/64 loss: 0.2851686477661133
Batch 49/64 loss: 0.2853654623031616
Batch 50/64 loss: 0.2879418730735779
Batch 51/64 loss: 0.29242467880249023
Batch 52/64 loss: 0.28636133670806885
Batch 53/64 loss: 0.2912209630012512
Batch 54/64 loss: 0.2869994044303894
Batch 55/64 loss: 0.28166335821151733
Batch 56/64 loss: 0.29496490955352783
Batch 57/64 loss: 0.2900165319442749
Batch 58/64 loss: 0.2875182628631592
Batch 59/64 loss: 0.2823699712753296
Batch 60/64 loss: 0.27906137704849243
Batch 61/64 loss: 0.29067540168762207
Batch 62/64 loss: 0.2909344434738159
Batch 63/64 loss: 0.29092293977737427
Batch 64/64 loss: 0.28443223237991333
Epoch 100  Train loss: 0.2870463312840929  Val loss: 0.2973133124846363
Saving best model, epoch: 100
Epoch 101
-------------------------------
Batch 1/64 loss: 0.28684794902801514
Batch 2/64 loss: 0.29344701766967773
Batch 3/64 loss: 0.2790423035621643
Batch 4/64 loss: 0.29336798191070557
Batch 5/64 loss: 0.28473377227783203
Batch 6/64 loss: 0.2881367802619934
Batch 7/64 loss: 0.27596449851989746
Batch 8/64 loss: 0.2893165349960327
Batch 9/64 loss: 0.28218168020248413
Batch 10/64 loss: 0.2821018099784851
Batch 11/64 loss: 0.28542643785476685
Batch 12/64 loss: 0.2924015522003174
Batch 13/64 loss: 0.2864645719528198
Batch 14/64 loss: 0.2856816053390503
Batch 15/64 loss: 0.287461519241333
Batch 16/64 loss: 0.2865229845046997
Batch 17/64 loss: 0.2843327522277832
Batch 18/64 loss: 0.28675246238708496
Batch 19/64 loss: 0.2837967872619629
Batch 20/64 loss: 0.29139864444732666
Batch 21/64 loss: 0.28549885749816895
Batch 22/64 loss: 0.2786438465118408
Batch 23/64 loss: 0.2855978012084961
Batch 24/64 loss: 0.2834761142730713
Batch 25/64 loss: 0.29350101947784424
Batch 26/64 loss: 0.2817600965499878
Batch 27/64 loss: 0.2774895429611206
Batch 28/64 loss: 0.2800537347793579
Batch 29/64 loss: 0.29278630018234253
Batch 30/64 loss: 0.28453946113586426
Batch 31/64 loss: 0.2864294648170471
Batch 32/64 loss: 0.2895928621292114
Batch 33/64 loss: 0.289225697517395
Batch 34/64 loss: 0.2835959196090698
Batch 35/64 loss: 0.284853458404541
Batch 36/64 loss: 0.29300248622894287
Batch 37/64 loss: 0.2853449583053589
Batch 38/64 loss: 0.2859152555465698
Batch 39/64 loss: 0.29247117042541504
Batch 40/64 loss: 0.2845754623413086
Batch 41/64 loss: 0.2900724411010742
Batch 42/64 loss: 0.28792595863342285
Batch 43/64 loss: 0.2791874408721924
Batch 44/64 loss: 0.2839592695236206
Batch 45/64 loss: 0.28108060359954834
Batch 46/64 loss: 0.2933650612831116
Batch 47/64 loss: 0.2803890109062195
Batch 48/64 loss: 0.2836869955062866
Batch 49/64 loss: 0.2915475368499756
Batch 50/64 loss: 0.28862500190734863
Batch 51/64 loss: 0.2929779291152954
Batch 52/64 loss: 0.2906913757324219
Batch 53/64 loss: 0.2842499017715454
Batch 54/64 loss: 0.28426873683929443
Batch 55/64 loss: 0.2933632731437683
Batch 56/64 loss: 0.284992516040802
Batch 57/64 loss: 0.28044581413269043
Batch 58/64 loss: 0.28575706481933594
Batch 59/64 loss: 0.2862534523010254
Batch 60/64 loss: 0.29083144664764404
Batch 61/64 loss: 0.2864220142364502
Batch 62/64 loss: 0.3028755187988281
Batch 63/64 loss: 0.27958518266677856
Batch 64/64 loss: 0.28193145990371704
Epoch 101  Train loss: 0.2863958477973938  Val loss: 0.2967344567538127
Saving best model, epoch: 101
Epoch 102
-------------------------------
Batch 1/64 loss: 0.28131014108657837
Batch 2/64 loss: 0.2760730981826782
Batch 3/64 loss: 0.28465157747268677
Batch 4/64 loss: 0.28305137157440186
Batch 5/64 loss: 0.2924584150314331
Batch 6/64 loss: 0.28049182891845703
Batch 7/64 loss: 0.2833881378173828
Batch 8/64 loss: 0.2890739440917969
Batch 9/64 loss: 0.2796722650527954
Batch 10/64 loss: 0.28688788414001465
Batch 11/64 loss: 0.2913658022880554
Batch 12/64 loss: 0.2826916575431824
Batch 13/64 loss: 0.29002904891967773
Batch 14/64 loss: 0.28393030166625977
Batch 15/64 loss: 0.2802342176437378
Batch 16/64 loss: 0.2897493839263916
Batch 17/64 loss: 0.28278452157974243
Batch 18/64 loss: 0.28337037563323975
Batch 19/64 loss: 0.28893977403640747
Batch 20/64 loss: 0.28338831663131714
Batch 21/64 loss: 0.2884730100631714
Batch 22/64 loss: 0.28880369663238525
Batch 23/64 loss: 0.28715986013412476
Batch 24/64 loss: 0.2804114818572998
Batch 25/64 loss: 0.2924473285675049
Batch 26/64 loss: 0.28751683235168457
Batch 27/64 loss: 0.28737974166870117
Batch 28/64 loss: 0.2768111228942871
Batch 29/64 loss: 0.2824007272720337
Batch 30/64 loss: 0.28167724609375
Batch 31/64 loss: 0.27947914600372314
Batch 32/64 loss: 0.2910882234573364
Batch 33/64 loss: 0.2911716103553772
Batch 34/64 loss: 0.28555238246917725
Batch 35/64 loss: 0.2845449447631836
Batch 36/64 loss: 0.28844791650772095
Batch 37/64 loss: 0.279390811920166
Batch 38/64 loss: 0.28775060176849365
Batch 39/64 loss: 0.2920379638671875
Batch 40/64 loss: 0.2816213369369507
Batch 41/64 loss: 0.28548556566238403
Batch 42/64 loss: 0.286474347114563
Batch 43/64 loss: 0.2947121858596802
Batch 44/64 loss: 0.2902560234069824
Batch 45/64 loss: 0.2923402190208435
Batch 46/64 loss: 0.2800230383872986
Batch 47/64 loss: 0.2848116159439087
Batch 48/64 loss: 0.2864040732383728
Batch 49/64 loss: 0.29136335849761963
Batch 50/64 loss: 0.28334641456604004
Batch 51/64 loss: 0.288188099861145
Batch 52/64 loss: 0.28860414028167725
Batch 53/64 loss: 0.28082311153411865
Batch 54/64 loss: 0.2885968089103699
Batch 55/64 loss: 0.2765437364578247
Batch 56/64 loss: 0.2907518148422241
Batch 57/64 loss: 0.2826046943664551
Batch 58/64 loss: 0.2865769863128662
Batch 59/64 loss: 0.28078997135162354
Batch 60/64 loss: 0.2787242531776428
Batch 61/64 loss: 0.28830546140670776
Batch 62/64 loss: 0.29065191745758057
Batch 63/64 loss: 0.287225604057312
Batch 64/64 loss: 0.2873876690864563
Epoch 102  Train loss: 0.28559768223295023  Val loss: 0.29860022489967214
Epoch 103
-------------------------------
Batch 1/64 loss: 0.2811535596847534
Batch 2/64 loss: 0.29004013538360596
Batch 3/64 loss: 0.2819538116455078
Batch 4/64 loss: 0.2847735285758972
Batch 5/64 loss: 0.2821906805038452
Batch 6/64 loss: 0.27648913860321045
Batch 7/64 loss: 0.2834465503692627
Batch 8/64 loss: 0.28673505783081055
Batch 9/64 loss: 0.2811394929885864
Batch 10/64 loss: 0.2826002836227417
Batch 11/64 loss: 0.28342175483703613
Batch 12/64 loss: 0.2868403196334839
Batch 13/64 loss: 0.28685909509658813
Batch 14/64 loss: 0.27881699800491333
Batch 15/64 loss: 0.278698205947876
Batch 16/64 loss: 0.2884352207183838
Batch 17/64 loss: 0.27819275856018066
Batch 18/64 loss: 0.28159916400909424
Batch 19/64 loss: 0.29176902770996094
Batch 20/64 loss: 0.2917584180831909
Batch 21/64 loss: 0.2892926335334778
Batch 22/64 loss: 0.29011428356170654
Batch 23/64 loss: 0.2897530794143677
Batch 24/64 loss: 0.2869875431060791
Batch 25/64 loss: 0.28292059898376465
Batch 26/64 loss: 0.2847871780395508
Batch 27/64 loss: 0.28723716735839844
Batch 28/64 loss: 0.28025418519973755
Batch 29/64 loss: 0.29186683893203735
Batch 30/64 loss: 0.28366219997406006
Batch 31/64 loss: 0.2797278165817261
Batch 32/64 loss: 0.2810225486755371
Batch 33/64 loss: 0.2883960008621216
Batch 34/64 loss: 0.2801421284675598
Batch 35/64 loss: 0.27590763568878174
Batch 36/64 loss: 0.2847621440887451
Batch 37/64 loss: 0.2886805534362793
Batch 38/64 loss: 0.285919189453125
Batch 39/64 loss: 0.28099381923675537
Batch 40/64 loss: 0.2897915244102478
Batch 41/64 loss: 0.28436732292175293
Batch 42/64 loss: 0.2883114814758301
Batch 43/64 loss: 0.28469085693359375
Batch 44/64 loss: 0.2874823212623596
Batch 45/64 loss: 0.2772402763366699
Batch 46/64 loss: 0.27763789892196655
Batch 47/64 loss: 0.2883896827697754
Batch 48/64 loss: 0.2856583595275879
Batch 49/64 loss: 0.2898329496383667
Batch 50/64 loss: 0.29573458433151245
Batch 51/64 loss: 0.2771414518356323
Batch 52/64 loss: 0.2846890687942505
Batch 53/64 loss: 0.2819209098815918
Batch 54/64 loss: 0.27713412046432495
Batch 55/64 loss: 0.29303574562072754
Batch 56/64 loss: 0.284775972366333
Batch 57/64 loss: 0.28273868560791016
Batch 58/64 loss: 0.2814129590988159
Batch 59/64 loss: 0.28459203243255615
Batch 60/64 loss: 0.2919921278953552
Batch 61/64 loss: 0.28791844844818115
Batch 62/64 loss: 0.2878835201263428
Batch 63/64 loss: 0.2868647575378418
Batch 64/64 loss: 0.2806273102760315
Epoch 103  Train loss: 0.2847223260823418  Val loss: 0.29821047156127456
Epoch 104
-------------------------------
Batch 1/64 loss: 0.2821768522262573
Batch 2/64 loss: 0.2789696455001831
Batch 3/64 loss: 0.285544753074646
Batch 4/64 loss: 0.28638994693756104
Batch 5/64 loss: 0.29352807998657227
Batch 6/64 loss: 0.27687597274780273
Batch 7/64 loss: 0.2811049222946167
Batch 8/64 loss: 0.2921062111854553
Batch 9/64 loss: 0.28759706020355225
Batch 10/64 loss: 0.28152716159820557
Batch 11/64 loss: 0.28940874338150024
Batch 12/64 loss: 0.28128230571746826
Batch 13/64 loss: 0.29066938161849976
Batch 14/64 loss: 0.27686166763305664
Batch 15/64 loss: 0.28394168615341187
Batch 16/64 loss: 0.28366410732269287
Batch 17/64 loss: 0.29505062103271484
Batch 18/64 loss: 0.28763312101364136
Batch 19/64 loss: 0.28137385845184326
Batch 20/64 loss: 0.2824477553367615
Batch 21/64 loss: 0.28818655014038086
Batch 22/64 loss: 0.2848076820373535
Batch 23/64 loss: 0.2832883596420288
Batch 24/64 loss: 0.27867162227630615
Batch 25/64 loss: 0.28685951232910156
Batch 26/64 loss: 0.2879001498222351
Batch 27/64 loss: 0.29129111766815186
Batch 28/64 loss: 0.2846691608428955
Batch 29/64 loss: 0.28777074813842773
Batch 30/64 loss: 0.29041820764541626
Batch 31/64 loss: 0.28020405769348145
Batch 32/64 loss: 0.28838789463043213
Batch 33/64 loss: 0.2860296368598938
Batch 34/64 loss: 0.2977134585380554
Batch 35/64 loss: 0.2891491651535034
Batch 36/64 loss: 0.2847200632095337
Batch 37/64 loss: 0.2830468416213989
Batch 38/64 loss: 0.2841072678565979
Batch 39/64 loss: 0.2857987880706787
Batch 40/64 loss: 0.27922356128692627
Batch 41/64 loss: 0.28445130586624146
Batch 42/64 loss: 0.27743029594421387
Batch 43/64 loss: 0.28466981649398804
Batch 44/64 loss: 0.27830684185028076
Batch 45/64 loss: 0.2804222106933594
Batch 46/64 loss: 0.286477267742157
Batch 47/64 loss: 0.28066694736480713
Batch 48/64 loss: 0.2826368808746338
Batch 49/64 loss: 0.28299760818481445
Batch 50/64 loss: 0.2783771753311157
Batch 51/64 loss: 0.28399133682250977
Batch 52/64 loss: 0.2854667901992798
Batch 53/64 loss: 0.28956568241119385
Batch 54/64 loss: 0.28509533405303955
Batch 55/64 loss: 0.2862473130226135
Batch 56/64 loss: 0.27657055854797363
Batch 57/64 loss: 0.2856959104537964
Batch 58/64 loss: 0.2775723338127136
Batch 59/64 loss: 0.28756892681121826
Batch 60/64 loss: 0.27706098556518555
Batch 61/64 loss: 0.29062318801879883
Batch 62/64 loss: 0.285040020942688
Batch 63/64 loss: 0.28830480575561523
Batch 64/64 loss: 0.28910088539123535
Epoch 104  Train loss: 0.2847445160734887  Val loss: 0.29462976103386107
Saving best model, epoch: 104
Epoch 105
-------------------------------
Batch 1/64 loss: 0.27993667125701904
Batch 2/64 loss: 0.27852094173431396
Batch 3/64 loss: 0.2780994176864624
Batch 4/64 loss: 0.28291821479797363
Batch 5/64 loss: 0.28252673149108887
Batch 6/64 loss: 0.28984177112579346
Batch 7/64 loss: 0.2838571071624756
Batch 8/64 loss: 0.2805633544921875
Batch 9/64 loss: 0.29067695140838623
Batch 10/64 loss: 0.2864915132522583
Batch 11/64 loss: 0.2843031883239746
Batch 12/64 loss: 0.2880118489265442
Batch 13/64 loss: 0.29055339097976685
Batch 14/64 loss: 0.29049980640411377
Batch 15/64 loss: 0.28638696670532227
Batch 16/64 loss: 0.29004257917404175
Batch 17/64 loss: 0.2872394323348999
Batch 18/64 loss: 0.2888633608818054
Batch 19/64 loss: 0.2787860631942749
Batch 20/64 loss: 0.27983570098876953
Batch 21/64 loss: 0.2745388150215149
Batch 22/64 loss: 0.28340303897857666
Batch 23/64 loss: 0.28761017322540283
Batch 24/64 loss: 0.2852696180343628
Batch 25/64 loss: 0.2785884737968445
Batch 26/64 loss: 0.2844356298446655
Batch 27/64 loss: 0.28738510608673096
Batch 28/64 loss: 0.2824912667274475
Batch 29/64 loss: 0.28593266010284424
Batch 30/64 loss: 0.2783857583999634
Batch 31/64 loss: 0.27928727865219116
Batch 32/64 loss: 0.2886611223220825
Batch 33/64 loss: 0.2915339469909668
Batch 34/64 loss: 0.2815876007080078
Batch 35/64 loss: 0.2910919189453125
Batch 36/64 loss: 0.28581392765045166
Batch 37/64 loss: 0.28193211555480957
Batch 38/64 loss: 0.2874232530593872
Batch 39/64 loss: 0.28705674409866333
Batch 40/64 loss: 0.28270119428634644
Batch 41/64 loss: 0.28592443466186523
Batch 42/64 loss: 0.286271333694458
Batch 43/64 loss: 0.27997130155563354
Batch 44/64 loss: 0.28810417652130127
Batch 45/64 loss: 0.28787243366241455
Batch 46/64 loss: 0.27766335010528564
Batch 47/64 loss: 0.28538984060287476
Batch 48/64 loss: 0.28831613063812256
Batch 49/64 loss: 0.2826918363571167
Batch 50/64 loss: 0.2828099727630615
Batch 51/64 loss: 0.2830984592437744
Batch 52/64 loss: 0.2816962003707886
Batch 53/64 loss: 0.285284161567688
Batch 54/64 loss: 0.2840048670768738
Batch 55/64 loss: 0.28560853004455566
Batch 56/64 loss: 0.27696692943573
Batch 57/64 loss: 0.28504639863967896
Batch 58/64 loss: 0.28970009088516235
Batch 59/64 loss: 0.2825131416320801
Batch 60/64 loss: 0.27869904041290283
Batch 61/64 loss: 0.28618359565734863
Batch 62/64 loss: 0.2787667512893677
Batch 63/64 loss: 0.2822139263153076
Batch 64/64 loss: 0.2793735861778259
Epoch 105  Train loss: 0.2841946940796048  Val loss: 0.2960634893158457
Epoch 106
-------------------------------
Batch 1/64 loss: 0.2827235460281372
Batch 2/64 loss: 0.28408926725387573
Batch 3/64 loss: 0.2865673303604126
Batch 4/64 loss: 0.28900694847106934
Batch 5/64 loss: 0.2827025055885315
Batch 6/64 loss: 0.2832247018814087
Batch 7/64 loss: 0.28524476289749146
Batch 8/64 loss: 0.2883882522583008
Batch 9/64 loss: 0.2787736654281616
Batch 10/64 loss: 0.2882518768310547
Batch 11/64 loss: 0.27229976654052734
Batch 12/64 loss: 0.28345799446105957
Batch 13/64 loss: 0.29175734519958496
Batch 14/64 loss: 0.28870922327041626
Batch 15/64 loss: 0.2891343832015991
Batch 16/64 loss: 0.288110613822937
Batch 17/64 loss: 0.2908751368522644
Batch 18/64 loss: 0.28007447719573975
Batch 19/64 loss: 0.287713885307312
Batch 20/64 loss: 0.27862000465393066
Batch 21/64 loss: 0.2823340892791748
Batch 22/64 loss: 0.2860848903656006
Batch 23/64 loss: 0.28379929065704346
Batch 24/64 loss: 0.28241509199142456
Batch 25/64 loss: 0.2789958715438843
Batch 26/64 loss: 0.28851330280303955
Batch 27/64 loss: 0.2803981304168701
Batch 28/64 loss: 0.2759021520614624
Batch 29/64 loss: 0.29299986362457275
Batch 30/64 loss: 0.2868058681488037
Batch 31/64 loss: 0.2813009023666382
Batch 32/64 loss: 0.28128695487976074
Batch 33/64 loss: 0.2929554581642151
Batch 34/64 loss: 0.28491753339767456
Batch 35/64 loss: 0.2884867191314697
Batch 36/64 loss: 0.2938958406448364
Batch 37/64 loss: 0.28547918796539307
Batch 38/64 loss: 0.294291615486145
Batch 39/64 loss: 0.28486454486846924
Batch 40/64 loss: 0.2892751693725586
Batch 41/64 loss: 0.2808474898338318
Batch 42/64 loss: 0.2800080180168152
Batch 43/64 loss: 0.2750539779663086
Batch 44/64 loss: 0.2820091247558594
Batch 45/64 loss: 0.28017449378967285
Batch 46/64 loss: 0.28214532136917114
Batch 47/64 loss: 0.2783988118171692
Batch 48/64 loss: 0.2762439250946045
Batch 49/64 loss: 0.28158682584762573
Batch 50/64 loss: 0.2839237451553345
Batch 51/64 loss: 0.28828155994415283
Batch 52/64 loss: 0.2775331735610962
Batch 53/64 loss: 0.28287047147750854
Batch 54/64 loss: 0.2851673364639282
Batch 55/64 loss: 0.2917053699493408
Batch 56/64 loss: 0.28529077768325806
Batch 57/64 loss: 0.2790820002555847
Batch 58/64 loss: 0.28200864791870117
Batch 59/64 loss: 0.28505510091781616
Batch 60/64 loss: 0.28443288803100586
Batch 61/64 loss: 0.2918766736984253
Batch 62/64 loss: 0.2806342840194702
Batch 63/64 loss: 0.2731611132621765
Batch 64/64 loss: 0.2861045002937317
Epoch 106  Train loss: 0.2841850615015217  Val loss: 0.2947962148902343
Epoch 107
-------------------------------
Batch 1/64 loss: 0.2809438705444336
Batch 2/64 loss: 0.28042566776275635
Batch 3/64 loss: 0.28175175189971924
Batch 4/64 loss: 0.28782516717910767
Batch 5/64 loss: 0.2698441743850708
Batch 6/64 loss: 0.27943849563598633
Batch 7/64 loss: 0.2882652282714844
Batch 8/64 loss: 0.28355085849761963
Batch 9/64 loss: 0.27790969610214233
Batch 10/64 loss: 0.2754640579223633
Batch 11/64 loss: 0.2872394323348999
Batch 12/64 loss: 0.27596020698547363
Batch 13/64 loss: 0.2837076187133789
Batch 14/64 loss: 0.2860625386238098
Batch 15/64 loss: 0.2807120084762573
Batch 16/64 loss: 0.2907237410545349
Batch 17/64 loss: 0.28414785861968994
Batch 18/64 loss: 0.28017473220825195
Batch 19/64 loss: 0.288604736328125
Batch 20/64 loss: 0.28964221477508545
Batch 21/64 loss: 0.27444136142730713
Batch 22/64 loss: 0.2862347960472107
Batch 23/64 loss: 0.2875335216522217
Batch 24/64 loss: 0.2836111783981323
Batch 25/64 loss: 0.2862059473991394
Batch 26/64 loss: 0.28258073329925537
Batch 27/64 loss: 0.2893220782279968
Batch 28/64 loss: 0.287875771522522
Batch 29/64 loss: 0.2923634648323059
Batch 30/64 loss: 0.2841925621032715
Batch 31/64 loss: 0.2842174768447876
Batch 32/64 loss: 0.2855449914932251
Batch 33/64 loss: 0.2829042673110962
Batch 34/64 loss: 0.28681039810180664
Batch 35/64 loss: 0.28429198265075684
Batch 36/64 loss: 0.2848285436630249
Batch 37/64 loss: 0.27957284450531006
Batch 38/64 loss: 0.2877610921859741
Batch 39/64 loss: 0.2857457399368286
Batch 40/64 loss: 0.28243112564086914
Batch 41/64 loss: 0.29673218727111816
Batch 42/64 loss: 0.2910342216491699
Batch 43/64 loss: 0.2823854684829712
Batch 44/64 loss: 0.28709208965301514
Batch 45/64 loss: 0.28403985500335693
Batch 46/64 loss: 0.28408026695251465
Batch 47/64 loss: 0.28652411699295044
Batch 48/64 loss: 0.27538496255874634
Batch 49/64 loss: 0.28416287899017334
Batch 50/64 loss: 0.2765910029411316
Batch 51/64 loss: 0.2788792848587036
Batch 52/64 loss: 0.28346097469329834
Batch 53/64 loss: 0.2904496192932129
Batch 54/64 loss: 0.28502511978149414
Batch 55/64 loss: 0.2810819149017334
Batch 56/64 loss: 0.28375566005706787
Batch 57/64 loss: 0.28098011016845703
Batch 58/64 loss: 0.28382259607315063
Batch 59/64 loss: 0.2808513641357422
Batch 60/64 loss: 0.3011147975921631
Batch 61/64 loss: 0.2839430570602417
Batch 62/64 loss: 0.27689069509506226
Batch 63/64 loss: 0.2847791314125061
Batch 64/64 loss: 0.2811610698699951
Epoch 107  Train loss: 0.2839968017503327  Val loss: 0.2948749391074033
Epoch 108
-------------------------------
Batch 1/64 loss: 0.28031766414642334
Batch 2/64 loss: 0.2846183776855469
Batch 3/64 loss: 0.2817392945289612
Batch 4/64 loss: 0.2812141180038452
Batch 5/64 loss: 0.287811279296875
Batch 6/64 loss: 0.27571773529052734
Batch 7/64 loss: 0.2770155668258667
Batch 8/64 loss: 0.28082960844039917
Batch 9/64 loss: 0.2755163908004761
Batch 10/64 loss: 0.2821120023727417
Batch 11/64 loss: 0.27874016761779785
Batch 12/64 loss: 0.287237286567688
Batch 13/64 loss: 0.27786076068878174
Batch 14/64 loss: 0.27992939949035645
Batch 15/64 loss: 0.27855658531188965
Batch 16/64 loss: 0.28588932752609253
Batch 17/64 loss: 0.28383880853652954
Batch 18/64 loss: 0.27070462703704834
Batch 19/64 loss: 0.282218337059021
Batch 20/64 loss: 0.2812160849571228
Batch 21/64 loss: 0.28593742847442627
Batch 22/64 loss: 0.2816088795661926
Batch 23/64 loss: 0.27616357803344727
Batch 24/64 loss: 0.28204119205474854
Batch 25/64 loss: 0.29179275035858154
Batch 26/64 loss: 0.279935359954834
Batch 27/64 loss: 0.2784034013748169
Batch 28/64 loss: 0.2768901586532593
Batch 29/64 loss: 0.283280611038208
Batch 30/64 loss: 0.2871130704879761
Batch 31/64 loss: 0.286857545375824
Batch 32/64 loss: 0.2826993465423584
Batch 33/64 loss: 0.27935272455215454
Batch 34/64 loss: 0.2758256793022156
Batch 35/64 loss: 0.2768405079841614
Batch 36/64 loss: 0.28067266941070557
Batch 37/64 loss: 0.28116393089294434
Batch 38/64 loss: 0.28616034984588623
Batch 39/64 loss: 0.2850182056427002
Batch 40/64 loss: 0.27466702461242676
Batch 41/64 loss: 0.2819916605949402
Batch 42/64 loss: 0.28235912322998047
Batch 43/64 loss: 0.2881024479866028
Batch 44/64 loss: 0.28624314069747925
Batch 45/64 loss: 0.28050631284713745
Batch 46/64 loss: 0.28546202182769775
Batch 47/64 loss: 0.2819327116012573
Batch 48/64 loss: 0.2874688506126404
Batch 49/64 loss: 0.28845489025115967
Batch 50/64 loss: 0.2846517562866211
Batch 51/64 loss: 0.2931351661682129
Batch 52/64 loss: 0.28729361295700073
Batch 53/64 loss: 0.28053975105285645
Batch 54/64 loss: 0.28382372856140137
Batch 55/64 loss: 0.2782056927680969
Batch 56/64 loss: 0.28191304206848145
Batch 57/64 loss: 0.2833002805709839
Batch 58/64 loss: 0.28146862983703613
Batch 59/64 loss: 0.291286826133728
Batch 60/64 loss: 0.2796872854232788
Batch 61/64 loss: 0.2762777805328369
Batch 62/64 loss: 0.2872043251991272
Batch 63/64 loss: 0.2854617238044739
Batch 64/64 loss: 0.28670454025268555
Epoch 108  Train loss: 0.2823106980791279  Val loss: 0.29347173250008285
Saving best model, epoch: 108
Epoch 109
-------------------------------
Batch 1/64 loss: 0.2808837890625
Batch 2/64 loss: 0.28425443172454834
Batch 3/64 loss: 0.28127557039260864
Batch 4/64 loss: 0.28245365619659424
Batch 5/64 loss: 0.27748095989227295
Batch 6/64 loss: 0.28106558322906494
Batch 7/64 loss: 0.2835295796394348
Batch 8/64 loss: 0.2814062237739563
Batch 9/64 loss: 0.2819584012031555
Batch 10/64 loss: 0.2848914861679077
Batch 11/64 loss: 0.27763915061950684
Batch 12/64 loss: 0.28321242332458496
Batch 13/64 loss: 0.28156018257141113
Batch 14/64 loss: 0.2805842161178589
Batch 15/64 loss: 0.2821210026741028
Batch 16/64 loss: 0.2817881107330322
Batch 17/64 loss: 0.28147196769714355
Batch 18/64 loss: 0.279582142829895
Batch 19/64 loss: 0.28144383430480957
Batch 20/64 loss: 0.28445732593536377
Batch 21/64 loss: 0.28097355365753174
Batch 22/64 loss: 0.28999006748199463
Batch 23/64 loss: 0.27429425716400146
Batch 24/64 loss: 0.2755226492881775
Batch 25/64 loss: 0.2969764471054077
Batch 26/64 loss: 0.2823365330696106
Batch 27/64 loss: 0.2791905403137207
Batch 28/64 loss: 0.2855041027069092
Batch 29/64 loss: 0.2769283056259155
Batch 30/64 loss: 0.2791461944580078
Batch 31/64 loss: 0.28471118211746216
Batch 32/64 loss: 0.2820850610733032
Batch 33/64 loss: 0.27380549907684326
Batch 34/64 loss: 0.2766876816749573
Batch 35/64 loss: 0.2853994369506836
Batch 36/64 loss: 0.27514803409576416
Batch 37/64 loss: 0.2856013774871826
Batch 38/64 loss: 0.2869575023651123
Batch 39/64 loss: 0.2758251428604126
Batch 40/64 loss: 0.27591419219970703
Batch 41/64 loss: 0.28666847944259644
Batch 42/64 loss: 0.2769259214401245
Batch 43/64 loss: 0.27982109785079956
Batch 44/64 loss: 0.28469932079315186
Batch 45/64 loss: 0.28839653730392456
Batch 46/64 loss: 0.2809891700744629
Batch 47/64 loss: 0.279066801071167
Batch 48/64 loss: 0.28116369247436523
Batch 49/64 loss: 0.28095269203186035
Batch 50/64 loss: 0.2799466848373413
Batch 51/64 loss: 0.28709012269973755
Batch 52/64 loss: 0.27992844581604004
Batch 53/64 loss: 0.289972186088562
Batch 54/64 loss: 0.2715398073196411
Batch 55/64 loss: 0.28244978189468384
Batch 56/64 loss: 0.2800077199935913
Batch 57/64 loss: 0.2869441509246826
Batch 58/64 loss: 0.2815030813217163
Batch 59/64 loss: 0.27837032079696655
Batch 60/64 loss: 0.28526777029037476
Batch 61/64 loss: 0.28274065256118774
Batch 62/64 loss: 0.28667497634887695
Batch 63/64 loss: 0.275493323802948
Batch 64/64 loss: 0.28265154361724854
Epoch 109  Train loss: 0.28164171284320305  Val loss: 0.2945553301945585
Epoch 110
-------------------------------
Batch 1/64 loss: 0.27184367179870605
Batch 2/64 loss: 0.284151554107666
Batch 3/64 loss: 0.28871530294418335
Batch 4/64 loss: 0.2789808511734009
Batch 5/64 loss: 0.2789708971977234
Batch 6/64 loss: 0.28535425662994385
Batch 7/64 loss: 0.28047919273376465
Batch 8/64 loss: 0.27484285831451416
Batch 9/64 loss: 0.2763959765434265
Batch 10/64 loss: 0.2728784680366516
Batch 11/64 loss: 0.2829117774963379
Batch 12/64 loss: 0.28478074073791504
Batch 13/64 loss: 0.27839529514312744
Batch 14/64 loss: 0.28084826469421387
Batch 15/64 loss: 0.2762415409088135
Batch 16/64 loss: 0.2803899645805359
Batch 17/64 loss: 0.2793862819671631
Batch 18/64 loss: 0.2811920642852783
Batch 19/64 loss: 0.2831522822380066
Batch 20/64 loss: 0.28443217277526855
Batch 21/64 loss: 0.2892153263092041
Batch 22/64 loss: 0.2776510715484619
Batch 23/64 loss: 0.2755815386772156
Batch 24/64 loss: 0.28514331579208374
Batch 25/64 loss: 0.2851712703704834
Batch 26/64 loss: 0.29065221548080444
Batch 27/64 loss: 0.28383004665374756
Batch 28/64 loss: 0.2817322611808777
Batch 29/64 loss: 0.28038567304611206
Batch 30/64 loss: 0.28469598293304443
Batch 31/64 loss: 0.2801632285118103
Batch 32/64 loss: 0.2802788019180298
Batch 33/64 loss: 0.28118324279785156
Batch 34/64 loss: 0.29768460988998413
Batch 35/64 loss: 0.2830985188484192
Batch 36/64 loss: 0.27822256088256836
Batch 37/64 loss: 0.28277504444122314
Batch 38/64 loss: 0.2763960361480713
Batch 39/64 loss: 0.2939797043800354
Batch 40/64 loss: 0.2758938670158386
Batch 41/64 loss: 0.2887566089630127
Batch 42/64 loss: 0.2848399877548218
Batch 43/64 loss: 0.28151851892471313
Batch 44/64 loss: 0.2777444124221802
Batch 45/64 loss: 0.2829486131668091
Batch 46/64 loss: 0.28378963470458984
Batch 47/64 loss: 0.28528112173080444
Batch 48/64 loss: 0.298212468624115
Batch 49/64 loss: 0.2860971689224243
Batch 50/64 loss: 0.2875248193740845
Batch 51/64 loss: 0.28615736961364746
Batch 52/64 loss: 0.2800407409667969
Batch 53/64 loss: 0.2816333770751953
Batch 54/64 loss: 0.28363490104675293
Batch 55/64 loss: 0.28497421741485596
Batch 56/64 loss: 0.2781493663787842
Batch 57/64 loss: 0.28024542331695557
Batch 58/64 loss: 0.27437329292297363
Batch 59/64 loss: 0.2847975492477417
Batch 60/64 loss: 0.27861058712005615
Batch 61/64 loss: 0.2787899971008301
Batch 62/64 loss: 0.28018271923065186
Batch 63/64 loss: 0.2857488989830017
Batch 64/64 loss: 0.2779726982116699
Epoch 110  Train loss: 0.28220563215367933  Val loss: 0.2931700084627289
Saving best model, epoch: 110
Epoch 111
-------------------------------
Batch 1/64 loss: 0.2805880308151245
Batch 2/64 loss: 0.2760807275772095
Batch 3/64 loss: 0.2793262004852295
Batch 4/64 loss: 0.27531927824020386
Batch 5/64 loss: 0.27886533737182617
Batch 6/64 loss: 0.2811708450317383
Batch 7/64 loss: 0.2861438989639282
Batch 8/64 loss: 0.27112799882888794
Batch 9/64 loss: 0.2740135192871094
Batch 10/64 loss: 0.2778841257095337
Batch 11/64 loss: 0.27462828159332275
Batch 12/64 loss: 0.27866286039352417
Batch 13/64 loss: 0.27778077125549316
Batch 14/64 loss: 0.2779589891433716
Batch 15/64 loss: 0.2837700843811035
Batch 16/64 loss: 0.2848202586174011
Batch 17/64 loss: 0.2757303714752197
Batch 18/64 loss: 0.29203832149505615
Batch 19/64 loss: 0.281158447265625
Batch 20/64 loss: 0.2807021737098694
Batch 21/64 loss: 0.28161752223968506
Batch 22/64 loss: 0.29260969161987305
Batch 23/64 loss: 0.28573763370513916
Batch 24/64 loss: 0.2774387001991272
Batch 25/64 loss: 0.28490352630615234
Batch 26/64 loss: 0.2755916118621826
Batch 27/64 loss: 0.2860453128814697
Batch 28/64 loss: 0.28327077627182007
Batch 29/64 loss: 0.27973222732543945
Batch 30/64 loss: 0.28609102964401245
Batch 31/64 loss: 0.27901291847229004
Batch 32/64 loss: 0.27413856983184814
Batch 33/64 loss: 0.27568554878234863
Batch 34/64 loss: 0.29266357421875
Batch 35/64 loss: 0.2884054183959961
Batch 36/64 loss: 0.278348445892334
Batch 37/64 loss: 0.2764936089515686
Batch 38/64 loss: 0.2878890037536621
Batch 39/64 loss: 0.27912670373916626
Batch 40/64 loss: 0.28348851203918457
Batch 41/64 loss: 0.2786831259727478
Batch 42/64 loss: 0.27372753620147705
Batch 43/64 loss: 0.28301048278808594
Batch 44/64 loss: 0.2736583948135376
Batch 45/64 loss: 0.27993935346603394
Batch 46/64 loss: 0.27404093742370605
Batch 47/64 loss: 0.2827008366584778
Batch 48/64 loss: 0.28058791160583496
Batch 49/64 loss: 0.2792019844055176
Batch 50/64 loss: 0.29270660877227783
Batch 51/64 loss: 0.28215742111206055
Batch 52/64 loss: 0.27933406829833984
Batch 53/64 loss: 0.27970457077026367
Batch 54/64 loss: 0.2812935709953308
Batch 55/64 loss: 0.2915358543395996
Batch 56/64 loss: 0.28224730491638184
Batch 57/64 loss: 0.27526819705963135
Batch 58/64 loss: 0.281521201133728
Batch 59/64 loss: 0.2759002447128296
Batch 60/64 loss: 0.2784731388092041
Batch 61/64 loss: 0.28791868686676025
Batch 62/64 loss: 0.2828642725944519
Batch 63/64 loss: 0.28028690814971924
Batch 64/64 loss: 0.28090333938598633
Epoch 111  Train loss: 0.28083923096750296  Val loss: 0.2929235246173295
Saving best model, epoch: 111
Epoch 112
-------------------------------
Batch 1/64 loss: 0.2843031883239746
Batch 2/64 loss: 0.27420419454574585
Batch 3/64 loss: 0.2833811044692993
Batch 4/64 loss: 0.2799842357635498
Batch 5/64 loss: 0.2802862524986267
Batch 6/64 loss: 0.28059446811676025
Batch 7/64 loss: 0.2809145450592041
Batch 8/64 loss: 0.284141480922699
Batch 9/64 loss: 0.2902715802192688
Batch 10/64 loss: 0.284168541431427
Batch 11/64 loss: 0.27911943197250366
Batch 12/64 loss: 0.28790926933288574
Batch 13/64 loss: 0.2813846468925476
Batch 14/64 loss: 0.2790491580963135
Batch 15/64 loss: 0.27962613105773926
Batch 16/64 loss: 0.28191041946411133
Batch 17/64 loss: 0.2865726351737976
Batch 18/64 loss: 0.2791862487792969
Batch 19/64 loss: 0.27622801065444946
Batch 20/64 loss: 0.27781587839126587
Batch 21/64 loss: 0.28607773780822754
Batch 22/64 loss: 0.2797900438308716
Batch 23/64 loss: 0.283686101436615
Batch 24/64 loss: 0.2808973789215088
Batch 25/64 loss: 0.27187734842300415
Batch 26/64 loss: 0.28620362281799316
Batch 27/64 loss: 0.2819092869758606
Batch 28/64 loss: 0.27914637327194214
Batch 29/64 loss: 0.2810649871826172
Batch 30/64 loss: 0.282257080078125
Batch 31/64 loss: 0.2810882329940796
Batch 32/64 loss: 0.27416837215423584
Batch 33/64 loss: 0.2816614508628845
Batch 34/64 loss: 0.27944260835647583
Batch 35/64 loss: 0.275568425655365
Batch 36/64 loss: 0.27240604162216187
Batch 37/64 loss: 0.2772470712661743
Batch 38/64 loss: 0.28291797637939453
Batch 39/64 loss: 0.2839665412902832
Batch 40/64 loss: 0.2749636769294739
Batch 41/64 loss: 0.27456390857696533
Batch 42/64 loss: 0.28489887714385986
Batch 43/64 loss: 0.28994274139404297
Batch 44/64 loss: 0.2772402763366699
Batch 45/64 loss: 0.28051483631134033
Batch 46/64 loss: 0.27597469091415405
Batch 47/64 loss: 0.27099186182022095
Batch 48/64 loss: 0.2813947796821594
Batch 49/64 loss: 0.2794368267059326
Batch 50/64 loss: 0.2771049737930298
Batch 51/64 loss: 0.273728609085083
Batch 52/64 loss: 0.28214263916015625
Batch 53/64 loss: 0.28140485286712646
Batch 54/64 loss: 0.2791783809661865
Batch 55/64 loss: 0.28354060649871826
Batch 56/64 loss: 0.27458423376083374
Batch 57/64 loss: 0.2788931131362915
Batch 58/64 loss: 0.2857774496078491
Batch 59/64 loss: 0.28084224462509155
Batch 60/64 loss: 0.28712040185928345
Batch 61/64 loss: 0.2748473882675171
Batch 62/64 loss: 0.28620612621307373
Batch 63/64 loss: 0.284368634223938
Batch 64/64 loss: 0.28215086460113525
Epoch 112  Train loss: 0.28052868048350016  Val loss: 0.2937650184860754
Epoch 113
-------------------------------
Batch 1/64 loss: 0.28013503551483154
Batch 2/64 loss: 0.28288471698760986
Batch 3/64 loss: 0.2833355665206909
Batch 4/64 loss: 0.2765581011772156
Batch 5/64 loss: 0.2800792455673218
Batch 6/64 loss: 0.2720836400985718
Batch 7/64 loss: 0.2730105519294739
Batch 8/64 loss: 0.28080445528030396
Batch 9/64 loss: 0.2768009901046753
Batch 10/64 loss: 0.27507901191711426
Batch 11/64 loss: 0.2912495732307434
Batch 12/64 loss: 0.28584474325180054
Batch 13/64 loss: 0.2819986343383789
Batch 14/64 loss: 0.27718013525009155
Batch 15/64 loss: 0.2858397960662842
Batch 16/64 loss: 0.278289794921875
Batch 17/64 loss: 0.2758670449256897
Batch 18/64 loss: 0.2833929657936096
Batch 19/64 loss: 0.28054094314575195
Batch 20/64 loss: 0.2760120630264282
Batch 21/64 loss: 0.2850329875946045
Batch 22/64 loss: 0.278464674949646
Batch 23/64 loss: 0.27790939807891846
Batch 24/64 loss: 0.2802208662033081
Batch 25/64 loss: 0.2745412588119507
Batch 26/64 loss: 0.27719640731811523
Batch 27/64 loss: 0.2839546203613281
Batch 28/64 loss: 0.27493590116500854
Batch 29/64 loss: 0.28135281801223755
Batch 30/64 loss: 0.27799439430236816
Batch 31/64 loss: 0.27917373180389404
Batch 32/64 loss: 0.28078168630599976
Batch 33/64 loss: 0.2840982675552368
Batch 34/64 loss: 0.2807600498199463
Batch 35/64 loss: 0.2854776382446289
Batch 36/64 loss: 0.27570533752441406
Batch 37/64 loss: 0.28140681982040405
Batch 38/64 loss: 0.28645050525665283
Batch 39/64 loss: 0.2822965383529663
Batch 40/64 loss: 0.2801475524902344
Batch 41/64 loss: 0.2815972566604614
Batch 42/64 loss: 0.27238190174102783
Batch 43/64 loss: 0.27386927604675293
Batch 44/64 loss: 0.279116153717041
Batch 45/64 loss: 0.2777271270751953
Batch 46/64 loss: 0.2823801636695862
Batch 47/64 loss: 0.2826828956604004
Batch 48/64 loss: 0.2844231128692627
Batch 49/64 loss: 0.27685272693634033
Batch 50/64 loss: 0.28016966581344604
Batch 51/64 loss: 0.27760618925094604
Batch 52/64 loss: 0.28346866369247437
Batch 53/64 loss: 0.28568601608276367
Batch 54/64 loss: 0.2786574959754944
Batch 55/64 loss: 0.2800581455230713
Batch 56/64 loss: 0.27802497148513794
Batch 57/64 loss: 0.2877888083457947
Batch 58/64 loss: 0.283939003944397
Batch 59/64 loss: 0.28327810764312744
Batch 60/64 loss: 0.2779051661491394
Batch 61/64 loss: 0.2792145013809204
Batch 62/64 loss: 0.27715492248535156
Batch 63/64 loss: 0.28054845333099365
Batch 64/64 loss: 0.2832317352294922
Epoch 113  Train loss: 0.28018577239092657  Val loss: 0.29142936541862097
Saving best model, epoch: 113
Epoch 114
-------------------------------
Batch 1/64 loss: 0.27515244483947754
Batch 2/64 loss: 0.2774035930633545
Batch 3/64 loss: 0.2787684202194214
Batch 4/64 loss: 0.276666522026062
Batch 5/64 loss: 0.2749338150024414
Batch 6/64 loss: 0.2787027359008789
Batch 7/64 loss: 0.2777097225189209
Batch 8/64 loss: 0.2831416130065918
Batch 9/64 loss: 0.2881983518600464
Batch 10/64 loss: 0.27183157205581665
Batch 11/64 loss: 0.27782803773880005
Batch 12/64 loss: 0.281038761138916
Batch 13/64 loss: 0.2739908695220947
Batch 14/64 loss: 0.2749558687210083
Batch 15/64 loss: 0.28749167919158936
Batch 16/64 loss: 0.2832297086715698
Batch 17/64 loss: 0.2748957872390747
Batch 18/64 loss: 0.27827489376068115
Batch 19/64 loss: 0.27644097805023193
Batch 20/64 loss: 0.27403974533081055
Batch 21/64 loss: 0.27444541454315186
Batch 22/64 loss: 0.278125524520874
Batch 23/64 loss: 0.2842414379119873
Batch 24/64 loss: 0.2820886969566345
Batch 25/64 loss: 0.2753775715827942
Batch 26/64 loss: 0.28624701499938965
Batch 27/64 loss: 0.28206902742385864
Batch 28/64 loss: 0.28287357091903687
Batch 29/64 loss: 0.27839553356170654
Batch 30/64 loss: 0.2763197422027588
Batch 31/64 loss: 0.28528332710266113
Batch 32/64 loss: 0.28099286556243896
Batch 33/64 loss: 0.2802685499191284
Batch 34/64 loss: 0.2776416540145874
Batch 35/64 loss: 0.27144837379455566
Batch 36/64 loss: 0.28030484914779663
Batch 37/64 loss: 0.27201879024505615
Batch 38/64 loss: 0.271845281124115
Batch 39/64 loss: 0.2774465084075928
Batch 40/64 loss: 0.28252696990966797
Batch 41/64 loss: 0.27376002073287964
Batch 42/64 loss: 0.2900174856185913
Batch 43/64 loss: 0.27734804153442383
Batch 44/64 loss: 0.27809178829193115
Batch 45/64 loss: 0.2826871871948242
Batch 46/64 loss: 0.28083479404449463
Batch 47/64 loss: 0.28182268142700195
Batch 48/64 loss: 0.2742440700531006
Batch 49/64 loss: 0.2780684232711792
Batch 50/64 loss: 0.28109484910964966
Batch 51/64 loss: 0.2772022485733032
Batch 52/64 loss: 0.28805989027023315
Batch 53/64 loss: 0.279480516910553
Batch 54/64 loss: 0.2787257432937622
Batch 55/64 loss: 0.28475695848464966
Batch 56/64 loss: 0.27932047843933105
Batch 57/64 loss: 0.2808343172073364
Batch 58/64 loss: 0.28556668758392334
Batch 59/64 loss: 0.28564387559890747
Batch 60/64 loss: 0.2928938865661621
Batch 61/64 loss: 0.2796705961227417
Batch 62/64 loss: 0.28701043128967285
Batch 63/64 loss: 0.28106391429901123
Batch 64/64 loss: 0.2727891802787781
Epoch 114  Train loss: 0.27964622109544046  Val loss: 0.2937532130795246
Epoch 115
-------------------------------
Batch 1/64 loss: 0.2812225818634033
Batch 2/64 loss: 0.2779744863510132
Batch 3/64 loss: 0.27963221073150635
Batch 4/64 loss: 0.2748599052429199
Batch 5/64 loss: 0.27597737312316895
Batch 6/64 loss: 0.28529345989227295
Batch 7/64 loss: 0.2746783494949341
Batch 8/64 loss: 0.28633761405944824
Batch 9/64 loss: 0.27562379837036133
Batch 10/64 loss: 0.2740684747695923
Batch 11/64 loss: 0.2850691080093384
Batch 12/64 loss: 0.2763124704360962
Batch 13/64 loss: 0.28026533126831055
Batch 14/64 loss: 0.27265191078186035
Batch 15/64 loss: 0.27583831548690796
Batch 16/64 loss: 0.27410954236984253
Batch 17/64 loss: 0.27658170461654663
Batch 18/64 loss: 0.2775930166244507
Batch 19/64 loss: 0.273080050945282
Batch 20/64 loss: 0.2761821150779724
Batch 21/64 loss: 0.28570127487182617
Batch 22/64 loss: 0.2826378345489502
Batch 23/64 loss: 0.2806236743927002
Batch 24/64 loss: 0.28039228916168213
Batch 25/64 loss: 0.28396904468536377
Batch 26/64 loss: 0.2747552990913391
Batch 27/64 loss: 0.27417004108428955
Batch 28/64 loss: 0.2798386812210083
Batch 29/64 loss: 0.2760772109031677
Batch 30/64 loss: 0.27950119972229004
Batch 31/64 loss: 0.2828265428543091
Batch 32/64 loss: 0.28616321086883545
Batch 33/64 loss: 0.2798994779586792
Batch 34/64 loss: 0.27521389722824097
Batch 35/64 loss: 0.2703162431716919
Batch 36/64 loss: 0.2827206254005432
Batch 37/64 loss: 0.28626322746276855
Batch 38/64 loss: 0.28177809715270996
Batch 39/64 loss: 0.2734757661819458
Batch 40/64 loss: 0.2820662260055542
Batch 41/64 loss: 0.2863413095474243
Batch 42/64 loss: 0.2841259241104126
Batch 43/64 loss: 0.294040322303772
Batch 44/64 loss: 0.2762349843978882
Batch 45/64 loss: 0.28262728452682495
Batch 46/64 loss: 0.28671127557754517
Batch 47/64 loss: 0.28430604934692383
Batch 48/64 loss: 0.2737658619880676
Batch 49/64 loss: 0.29146528244018555
Batch 50/64 loss: 0.2837909460067749
Batch 51/64 loss: 0.2792326807975769
Batch 52/64 loss: 0.27429598569869995
Batch 53/64 loss: 0.2735954523086548
Batch 54/64 loss: 0.2746013402938843
Batch 55/64 loss: 0.2745704650878906
Batch 56/64 loss: 0.2726125121116638
Batch 57/64 loss: 0.2797682285308838
Batch 58/64 loss: 0.278437077999115
Batch 59/64 loss: 0.2696540355682373
Batch 60/64 loss: 0.28240448236465454
Batch 61/64 loss: 0.28963369131088257
Batch 62/64 loss: 0.272418737411499
Batch 63/64 loss: 0.27590835094451904
Batch 64/64 loss: 0.2745339274406433
Epoch 115  Train loss: 0.27918720642725625  Val loss: 0.29253365125033454
Epoch 116
-------------------------------
Batch 1/64 loss: 0.28519153594970703
Batch 2/64 loss: 0.2877092957496643
Batch 3/64 loss: 0.2750661373138428
Batch 4/64 loss: 0.28221380710601807
Batch 5/64 loss: 0.27385544776916504
Batch 6/64 loss: 0.28339362144470215
Batch 7/64 loss: 0.2864096164703369
Batch 8/64 loss: 0.2716255187988281
Batch 9/64 loss: 0.281247615814209
Batch 10/64 loss: 0.2773890495300293
Batch 11/64 loss: 0.27814245223999023
Batch 12/64 loss: 0.2778729796409607
Batch 13/64 loss: 0.2774893045425415
Batch 14/64 loss: 0.2687227725982666
Batch 15/64 loss: 0.2814157009124756
Batch 16/64 loss: 0.2800356149673462
Batch 17/64 loss: 0.28118836879730225
Batch 18/64 loss: 0.2759135961532593
Batch 19/64 loss: 0.2829256057739258
Batch 20/64 loss: 0.2744640111923218
Batch 21/64 loss: 0.27188223600387573
Batch 22/64 loss: 0.2765238881111145
Batch 23/64 loss: 0.2757911682128906
Batch 24/64 loss: 0.2783987522125244
Batch 25/64 loss: 0.2787812352180481
Batch 26/64 loss: 0.28007322549819946
Batch 27/64 loss: 0.2827828526496887
Batch 28/64 loss: 0.2755783796310425
Batch 29/64 loss: 0.27353399991989136
Batch 30/64 loss: 0.27313512563705444
Batch 31/64 loss: 0.27546262741088867
Batch 32/64 loss: 0.28003501892089844
Batch 33/64 loss: 0.27328604459762573
Batch 34/64 loss: 0.281848669052124
Batch 35/64 loss: 0.27632755041122437
Batch 36/64 loss: 0.2773716449737549
Batch 37/64 loss: 0.2729019522666931
Batch 38/64 loss: 0.2782396674156189
Batch 39/64 loss: 0.27474385499954224
Batch 40/64 loss: 0.27787017822265625
Batch 41/64 loss: 0.2796633839607239
Batch 42/64 loss: 0.28156590461730957
Batch 43/64 loss: 0.28108394145965576
Batch 44/64 loss: 0.28006279468536377
Batch 45/64 loss: 0.2907167673110962
Batch 46/64 loss: 0.2706267833709717
Batch 47/64 loss: 0.29090386629104614
Batch 48/64 loss: 0.2785112261772156
Batch 49/64 loss: 0.2872440814971924
Batch 50/64 loss: 0.2690300941467285
Batch 51/64 loss: 0.27916479110717773
Batch 52/64 loss: 0.27803850173950195
Batch 53/64 loss: 0.2798333168029785
Batch 54/64 loss: 0.27515286207199097
Batch 55/64 loss: 0.28501129150390625
Batch 56/64 loss: 0.2783999443054199
Batch 57/64 loss: 0.27096396684646606
Batch 58/64 loss: 0.2676571011543274
Batch 59/64 loss: 0.2768939137458801
Batch 60/64 loss: 0.2820323705673218
Batch 61/64 loss: 0.28370416164398193
Batch 62/64 loss: 0.282345175743103
Batch 63/64 loss: 0.2666100263595581
Batch 64/64 loss: 0.28009355068206787
Epoch 116  Train loss: 0.2783078675176583  Val loss: 0.2939876574011603
Epoch 117
-------------------------------
Batch 1/64 loss: 0.2805362343788147
Batch 2/64 loss: 0.28959745168685913
Batch 3/64 loss: 0.2751193046569824
Batch 4/64 loss: 0.27927643060684204
Batch 5/64 loss: 0.2791494131088257
Batch 6/64 loss: 0.27665209770202637
Batch 7/64 loss: 0.27632808685302734
Batch 8/64 loss: 0.27569329738616943
Batch 9/64 loss: 0.26785075664520264
Batch 10/64 loss: 0.28076785802841187
Batch 11/64 loss: 0.2771183252334595
Batch 12/64 loss: 0.28088343143463135
Batch 13/64 loss: 0.2731691598892212
Batch 14/64 loss: 0.27088916301727295
Batch 15/64 loss: 0.2788933515548706
Batch 16/64 loss: 0.275329053401947
Batch 17/64 loss: 0.2784251570701599
Batch 18/64 loss: 0.289786696434021
Batch 19/64 loss: 0.28066909313201904
Batch 20/64 loss: 0.2745285630226135
Batch 21/64 loss: 0.27819621562957764
Batch 22/64 loss: 0.27540117502212524
Batch 23/64 loss: 0.2765282988548279
Batch 24/64 loss: 0.28301262855529785
Batch 25/64 loss: 0.27281975746154785
Batch 26/64 loss: 0.280017614364624
Batch 27/64 loss: 0.2707456350326538
Batch 28/64 loss: 0.28427422046661377
Batch 29/64 loss: 0.27945685386657715
Batch 30/64 loss: 0.2793835401535034
Batch 31/64 loss: 0.28114819526672363
Batch 32/64 loss: 0.27507078647613525
Batch 33/64 loss: 0.27050477266311646
Batch 34/64 loss: 0.2740664482116699
Batch 35/64 loss: 0.27766019105911255
Batch 36/64 loss: 0.2763561010360718
Batch 37/64 loss: 0.2771790027618408
Batch 38/64 loss: 0.27465105056762695
Batch 39/64 loss: 0.274408757686615
Batch 40/64 loss: 0.27139854431152344
Batch 41/64 loss: 0.29178810119628906
Batch 42/64 loss: 0.27858471870422363
Batch 43/64 loss: 0.2785472869873047
Batch 44/64 loss: 0.2781916856765747
Batch 45/64 loss: 0.2794872522354126
Batch 46/64 loss: 0.28290724754333496
Batch 47/64 loss: 0.27853667736053467
Batch 48/64 loss: 0.27970361709594727
Batch 49/64 loss: 0.2780805826187134
Batch 50/64 loss: 0.2758183479309082
Batch 51/64 loss: 0.28219377994537354
Batch 52/64 loss: 0.2810935974121094
Batch 53/64 loss: 0.2759096622467041
Batch 54/64 loss: 0.28134387731552124
Batch 55/64 loss: 0.2783546447753906
Batch 56/64 loss: 0.28509724140167236
Batch 57/64 loss: 0.2745809555053711
Batch 58/64 loss: 0.27903854846954346
Batch 59/64 loss: 0.26913708448410034
Batch 60/64 loss: 0.2767026424407959
Batch 61/64 loss: 0.27275550365448
Batch 62/64 loss: 0.2780848741531372
Batch 63/64 loss: 0.27367329597473145
Batch 64/64 loss: 0.2821658253669739
Epoch 117  Train loss: 0.2778694636681501  Val loss: 0.29170521632912233
Epoch 118
-------------------------------
Batch 1/64 loss: 0.27586984634399414
Batch 2/64 loss: 0.27550625801086426
Batch 3/64 loss: 0.2805343270301819
Batch 4/64 loss: 0.2716284990310669
Batch 5/64 loss: 0.28030961751937866
Batch 6/64 loss: 0.27641117572784424
Batch 7/64 loss: 0.2759881019592285
Batch 8/64 loss: 0.27172744274139404
Batch 9/64 loss: 0.27074265480041504
Batch 10/64 loss: 0.2728946805000305
Batch 11/64 loss: 0.27812933921813965
Batch 12/64 loss: 0.2819662094116211
Batch 13/64 loss: 0.27022862434387207
Batch 14/64 loss: 0.2801823019981384
Batch 15/64 loss: 0.27692365646362305
Batch 16/64 loss: 0.27484381198883057
Batch 17/64 loss: 0.2691037058830261
Batch 18/64 loss: 0.27658915519714355
Batch 19/64 loss: 0.2866327166557312
Batch 20/64 loss: 0.28088462352752686
Batch 21/64 loss: 0.28021711111068726
Batch 22/64 loss: 0.2852298617362976
Batch 23/64 loss: 0.27826035022735596
Batch 24/64 loss: 0.27077895402908325
Batch 25/64 loss: 0.2799253463745117
Batch 26/64 loss: 0.2820749282836914
Batch 27/64 loss: 0.28280651569366455
Batch 28/64 loss: 0.2848210334777832
Batch 29/64 loss: 0.2804693579673767
Batch 30/64 loss: 0.27675408124923706
Batch 31/64 loss: 0.2727842926979065
Batch 32/64 loss: 0.2753533124923706
Batch 33/64 loss: 0.27061527967453003
Batch 34/64 loss: 0.2766491770744324
Batch 35/64 loss: 0.2779574394226074
Batch 36/64 loss: 0.2783437967300415
Batch 37/64 loss: 0.2855978012084961
Batch 38/64 loss: 0.2772715091705322
Batch 39/64 loss: 0.28173017501831055
Batch 40/64 loss: 0.27740323543548584
Batch 41/64 loss: 0.28377747535705566
Batch 42/64 loss: 0.27732527256011963
Batch 43/64 loss: 0.27459847927093506
Batch 44/64 loss: 0.28072041273117065
Batch 45/64 loss: 0.27465128898620605
Batch 46/64 loss: 0.27647513151168823
Batch 47/64 loss: 0.2720233201980591
Batch 48/64 loss: 0.27773112058639526
Batch 49/64 loss: 0.2821107506752014
Batch 50/64 loss: 0.2804405689239502
Batch 51/64 loss: 0.2734549045562744
Batch 52/64 loss: 0.27455174922943115
Batch 53/64 loss: 0.2789945602416992
Batch 54/64 loss: 0.2772557735443115
Batch 55/64 loss: 0.2838110327720642
Batch 56/64 loss: 0.2751448154449463
Batch 57/64 loss: 0.2828024625778198
Batch 58/64 loss: 0.27491748332977295
Batch 59/64 loss: 0.27324050664901733
Batch 60/64 loss: 0.2682826519012451
Batch 61/64 loss: 0.2752947211265564
Batch 62/64 loss: 0.29099929332733154
Batch 63/64 loss: 0.2737768888473511
Batch 64/64 loss: 0.2766547203063965
Epoch 118  Train loss: 0.27752175705105653  Val loss: 0.29155382339897024
Epoch 119
-------------------------------
Batch 1/64 loss: 0.27092647552490234
Batch 2/64 loss: 0.2893451452255249
Batch 3/64 loss: 0.27660346031188965
Batch 4/64 loss: 0.27352267503738403
Batch 5/64 loss: 0.27682220935821533
Batch 6/64 loss: 0.27568167448043823
Batch 7/64 loss: 0.2718108296394348
Batch 8/64 loss: 0.27946579456329346
Batch 9/64 loss: 0.2696858048439026
Batch 10/64 loss: 0.27037370204925537
Batch 11/64 loss: 0.27208709716796875
Batch 12/64 loss: 0.2688779830932617
Batch 13/64 loss: 0.27630525827407837
Batch 14/64 loss: 0.28121471405029297
Batch 15/64 loss: 0.2730525732040405
Batch 16/64 loss: 0.26708900928497314
Batch 17/64 loss: 0.2780243158340454
Batch 18/64 loss: 0.2772265076637268
Batch 19/64 loss: 0.27004706859588623
Batch 20/64 loss: 0.2732580304145813
Batch 21/64 loss: 0.27926701307296753
Batch 22/64 loss: 0.2798497676849365
Batch 23/64 loss: 0.27667462825775146
Batch 24/64 loss: 0.2719765901565552
Batch 25/64 loss: 0.27192455530166626
Batch 26/64 loss: 0.2777758836746216
Batch 27/64 loss: 0.28373122215270996
Batch 28/64 loss: 0.2762411832809448
Batch 29/64 loss: 0.2736309766769409
Batch 30/64 loss: 0.28101491928100586
Batch 31/64 loss: 0.27534180879592896
Batch 32/64 loss: 0.276633620262146
Batch 33/64 loss: 0.2698005437850952
Batch 34/64 loss: 0.2823888659477234
Batch 35/64 loss: 0.2700576186180115
Batch 36/64 loss: 0.2935299873352051
Batch 37/64 loss: 0.28551703691482544
Batch 38/64 loss: 0.2831013798713684
Batch 39/64 loss: 0.27296721935272217
Batch 40/64 loss: 0.2784806489944458
Batch 41/64 loss: 0.27326643466949463
Batch 42/64 loss: 0.27262842655181885
Batch 43/64 loss: 0.2811990976333618
Batch 44/64 loss: 0.28436362743377686
Batch 45/64 loss: 0.28697144985198975
Batch 46/64 loss: 0.2753903865814209
Batch 47/64 loss: 0.2731074094772339
Batch 48/64 loss: 0.28124523162841797
Batch 49/64 loss: 0.27596020698547363
Batch 50/64 loss: 0.2778240442276001
Batch 51/64 loss: 0.287456214427948
Batch 52/64 loss: 0.27834445238113403
Batch 53/64 loss: 0.28273242712020874
Batch 54/64 loss: 0.278170108795166
Batch 55/64 loss: 0.2757093906402588
Batch 56/64 loss: 0.27955514192581177
Batch 57/64 loss: 0.2795194983482361
Batch 58/64 loss: 0.2827821969985962
Batch 59/64 loss: 0.27752119302749634
Batch 60/64 loss: 0.2763782739639282
Batch 61/64 loss: 0.27585113048553467
Batch 62/64 loss: 0.2779166102409363
Batch 63/64 loss: 0.27125293016433716
Batch 64/64 loss: 0.28121185302734375
Epoch 119  Train loss: 0.27713538151161343  Val loss: 0.29033268092014536
Saving best model, epoch: 119
Epoch 120
-------------------------------
Batch 1/64 loss: 0.2770833969116211
Batch 2/64 loss: 0.2725633382797241
Batch 3/64 loss: 0.2772756814956665
Batch 4/64 loss: 0.2758386731147766
Batch 5/64 loss: 0.2780018448829651
Batch 6/64 loss: 0.279623806476593
Batch 7/64 loss: 0.27780842781066895
Batch 8/64 loss: 0.27967727184295654
Batch 9/64 loss: 0.2803035378456116
Batch 10/64 loss: 0.2693101763725281
Batch 11/64 loss: 0.27839815616607666
Batch 12/64 loss: 0.27051907777786255
Batch 13/64 loss: 0.27538055181503296
Batch 14/64 loss: 0.2734397053718567
Batch 15/64 loss: 0.2846451997756958
Batch 16/64 loss: 0.273220419883728
Batch 17/64 loss: 0.28067082166671753
Batch 18/64 loss: 0.2811218500137329
Batch 19/64 loss: 0.2778998017311096
Batch 20/64 loss: 0.28022491931915283
Batch 21/64 loss: 0.2734644412994385
Batch 22/64 loss: 0.271614670753479
Batch 23/64 loss: 0.2745954990386963
Batch 24/64 loss: 0.27331238985061646
Batch 25/64 loss: 0.28174448013305664
Batch 26/64 loss: 0.27875638008117676
Batch 27/64 loss: 0.2704888582229614
Batch 28/64 loss: 0.26698803901672363
Batch 29/64 loss: 0.2722775936126709
Batch 30/64 loss: 0.2966325879096985
Batch 31/64 loss: 0.27949321269989014
Batch 32/64 loss: 0.2771064043045044
Batch 33/64 loss: 0.27988338470458984
Batch 34/64 loss: 0.27570652961730957
Batch 35/64 loss: 0.2740001082420349
Batch 36/64 loss: 0.2756228446960449
Batch 37/64 loss: 0.2724812626838684
Batch 38/64 loss: 0.2699207663536072
Batch 39/64 loss: 0.2737473249435425
Batch 40/64 loss: 0.2837064266204834
Batch 41/64 loss: 0.27921193838119507
Batch 42/64 loss: 0.2774718999862671
Batch 43/64 loss: 0.2779352068901062
Batch 44/64 loss: 0.2757256031036377
Batch 45/64 loss: 0.27738869190216064
Batch 46/64 loss: 0.2806822657585144
Batch 47/64 loss: 0.28577739000320435
Batch 48/64 loss: 0.2741311192512512
Batch 49/64 loss: 0.2807428240776062
Batch 50/64 loss: 0.2793987989425659
Batch 51/64 loss: 0.28183913230895996
Batch 52/64 loss: 0.28460752964019775
Batch 53/64 loss: 0.2749561071395874
Batch 54/64 loss: 0.27508145570755005
Batch 55/64 loss: 0.28400516510009766
Batch 56/64 loss: 0.2831524610519409
Batch 57/64 loss: 0.2675204873085022
Batch 58/64 loss: 0.2861347198486328
Batch 59/64 loss: 0.28331220149993896
Batch 60/64 loss: 0.2771267294883728
Batch 61/64 loss: 0.277197003364563
Batch 62/64 loss: 0.2705339193344116
Batch 63/64 loss: 0.2750183343887329
Batch 64/64 loss: 0.2864237427711487
Epoch 120  Train loss: 0.2774638220375659  Val loss: 0.2925564730699939
Epoch 121
-------------------------------
Batch 1/64 loss: 0.26913756132125854
Batch 2/64 loss: 0.27707481384277344
Batch 3/64 loss: 0.29014188051223755
Batch 4/64 loss: 0.2830442190170288
Batch 5/64 loss: 0.2874995470046997
Batch 6/64 loss: 0.2667926549911499
Batch 7/64 loss: 0.2727295160293579
Batch 8/64 loss: 0.2787485718727112
Batch 9/64 loss: 0.27711743116378784
Batch 10/64 loss: 0.28094935417175293
Batch 11/64 loss: 0.2769303321838379
Batch 12/64 loss: 0.2817723751068115
Batch 13/64 loss: 0.28235065937042236
Batch 14/64 loss: 0.28043174743652344
Batch 15/64 loss: 0.27795130014419556
Batch 16/64 loss: 0.2741871476173401
Batch 17/64 loss: 0.2703186869621277
Batch 18/64 loss: 0.2754506468772888
Batch 19/64 loss: 0.278820276260376
Batch 20/64 loss: 0.27223241329193115
Batch 21/64 loss: 0.2870832681655884
Batch 22/64 loss: 0.26939791440963745
Batch 23/64 loss: 0.28285861015319824
Batch 24/64 loss: 0.27758586406707764
Batch 25/64 loss: 0.2776148319244385
Batch 26/64 loss: 0.2748701572418213
Batch 27/64 loss: 0.2738145589828491
Batch 28/64 loss: 0.2782214879989624
Batch 29/64 loss: 0.2704334259033203
Batch 30/64 loss: 0.27585655450820923
Batch 31/64 loss: 0.27253109216690063
Batch 32/64 loss: 0.2761898636817932
Batch 33/64 loss: 0.28623366355895996
Batch 34/64 loss: 0.28183674812316895
Batch 35/64 loss: 0.2652432918548584
Batch 36/64 loss: 0.2776836156845093
Batch 37/64 loss: 0.27892637252807617
Batch 38/64 loss: 0.27640479803085327
Batch 39/64 loss: 0.2726055383682251
Batch 40/64 loss: 0.2752344608306885
Batch 41/64 loss: 0.2765381336212158
Batch 42/64 loss: 0.27837759256362915
Batch 43/64 loss: 0.2855350971221924
Batch 44/64 loss: 0.2746708393096924
Batch 45/64 loss: 0.2762261629104614
Batch 46/64 loss: 0.26698923110961914
Batch 47/64 loss: 0.29103660583496094
Batch 48/64 loss: 0.2867933511734009
Batch 49/64 loss: 0.28605103492736816
Batch 50/64 loss: 0.2755082845687866
Batch 51/64 loss: 0.27365535497665405
Batch 52/64 loss: 0.27630746364593506
Batch 53/64 loss: 0.28015726804733276
Batch 54/64 loss: 0.27526021003723145
Batch 55/64 loss: 0.2793447971343994
Batch 56/64 loss: 0.2735182046890259
Batch 57/64 loss: 0.28195858001708984
Batch 58/64 loss: 0.2795076370239258
Batch 59/64 loss: 0.27454495429992676
Batch 60/64 loss: 0.27234625816345215
Batch 61/64 loss: 0.2776023745536804
Batch 62/64 loss: 0.2798038721084595
Batch 63/64 loss: 0.27398931980133057
Batch 64/64 loss: 0.2757111191749573
Epoch 121  Train loss: 0.27744020737853703  Val loss: 0.2899477231953152
Saving best model, epoch: 121
Epoch 122
-------------------------------
Batch 1/64 loss: 0.27948009967803955
Batch 2/64 loss: 0.2914290428161621
Batch 3/64 loss: 0.274591326713562
Batch 4/64 loss: 0.280636191368103
Batch 5/64 loss: 0.2763093113899231
Batch 6/64 loss: 0.26959872245788574
Batch 7/64 loss: 0.27456700801849365
Batch 8/64 loss: 0.27910906076431274
Batch 9/64 loss: 0.26934635639190674
Batch 10/64 loss: 0.27076590061187744
Batch 11/64 loss: 0.27726686000823975
Batch 12/64 loss: 0.276658296585083
Batch 13/64 loss: 0.2871115207672119
Batch 14/64 loss: 0.2752261161804199
Batch 15/64 loss: 0.2662582993507385
Batch 16/64 loss: 0.2721706032752991
Batch 17/64 loss: 0.2728878855705261
Batch 18/64 loss: 0.2860979437828064
Batch 19/64 loss: 0.26986682415008545
Batch 20/64 loss: 0.26636189222335815
Batch 21/64 loss: 0.27360862493515015
Batch 22/64 loss: 0.2683796286582947
Batch 23/64 loss: 0.27881622314453125
Batch 24/64 loss: 0.27993249893188477
Batch 25/64 loss: 0.2753923535346985
Batch 26/64 loss: 0.2766401767730713
Batch 27/64 loss: 0.28366005420684814
Batch 28/64 loss: 0.26858627796173096
Batch 29/64 loss: 0.2635965347290039
Batch 30/64 loss: 0.2741544246673584
Batch 31/64 loss: 0.2748243808746338
Batch 32/64 loss: 0.2725977897644043
Batch 33/64 loss: 0.27834552526474
Batch 34/64 loss: 0.2798813581466675
Batch 35/64 loss: 0.26684796810150146
Batch 36/64 loss: 0.2714797258377075
Batch 37/64 loss: 0.2763611674308777
Batch 38/64 loss: 0.2796984910964966
Batch 39/64 loss: 0.284130334854126
Batch 40/64 loss: 0.2792987823486328
Batch 41/64 loss: 0.2765635848045349
Batch 42/64 loss: 0.2721322774887085
Batch 43/64 loss: 0.27401483058929443
Batch 44/64 loss: 0.27712559700012207
Batch 45/64 loss: 0.2805987596511841
Batch 46/64 loss: 0.2719123363494873
Batch 47/64 loss: 0.27689552307128906
Batch 48/64 loss: 0.2832362651824951
Batch 49/64 loss: 0.2772681713104248
Batch 50/64 loss: 0.2804645299911499
Batch 51/64 loss: 0.2743654251098633
Batch 52/64 loss: 0.2783515453338623
Batch 53/64 loss: 0.28226304054260254
Batch 54/64 loss: 0.27572304010391235
Batch 55/64 loss: 0.2676173448562622
Batch 56/64 loss: 0.27288687229156494
Batch 57/64 loss: 0.27588188648223877
Batch 58/64 loss: 0.27624011039733887
Batch 59/64 loss: 0.2798196077346802
Batch 60/64 loss: 0.2826470136642456
Batch 61/64 loss: 0.27464067935943604
Batch 62/64 loss: 0.27951133251190186
Batch 63/64 loss: 0.2759120464324951
Batch 64/64 loss: 0.279843807220459
Epoch 122  Train loss: 0.27604590210260127  Val loss: 0.2884858772926724
Saving best model, epoch: 122
Epoch 123
-------------------------------
Batch 1/64 loss: 0.26999056339263916
Batch 2/64 loss: 0.2733563184738159
Batch 3/64 loss: 0.2772786021232605
Batch 4/64 loss: 0.27468156814575195
Batch 5/64 loss: 0.2733447551727295
Batch 6/64 loss: 0.2763587236404419
Batch 7/64 loss: 0.26721781492233276
Batch 8/64 loss: 0.2677571773529053
Batch 9/64 loss: 0.26977747678756714
Batch 10/64 loss: 0.27417004108428955
Batch 11/64 loss: 0.2792208194732666
Batch 12/64 loss: 0.2687011957168579
Batch 13/64 loss: 0.2884504795074463
Batch 14/64 loss: 0.2742561101913452
Batch 15/64 loss: 0.27545756101608276
Batch 16/64 loss: 0.2889353036880493
Batch 17/64 loss: 0.27415013313293457
Batch 18/64 loss: 0.2809516191482544
Batch 19/64 loss: 0.27241015434265137
Batch 20/64 loss: 0.2750898599624634
Batch 21/64 loss: 0.27935731410980225
Batch 22/64 loss: 0.27347564697265625
Batch 23/64 loss: 0.26692014932632446
Batch 24/64 loss: 0.27495014667510986
Batch 25/64 loss: 0.2727494239807129
Batch 26/64 loss: 0.2694563865661621
Batch 27/64 loss: 0.2753361463546753
Batch 28/64 loss: 0.2727750539779663
Batch 29/64 loss: 0.2837762236595154
Batch 30/64 loss: 0.2801625728607178
Batch 31/64 loss: 0.2646139860153198
Batch 32/64 loss: 0.2793673872947693
Batch 33/64 loss: 0.2699558138847351
Batch 34/64 loss: 0.2696518898010254
Batch 35/64 loss: 0.28153443336486816
Batch 36/64 loss: 0.2758272886276245
Batch 37/64 loss: 0.27484893798828125
Batch 38/64 loss: 0.2750723361968994
Batch 39/64 loss: 0.27748632431030273
Batch 40/64 loss: 0.268513560295105
Batch 41/64 loss: 0.2784322500228882
Batch 42/64 loss: 0.26936304569244385
Batch 43/64 loss: 0.2718566060066223
Batch 44/64 loss: 0.27411890029907227
Batch 45/64 loss: 0.2730666399002075
Batch 46/64 loss: 0.2767566442489624
Batch 47/64 loss: 0.26796966791152954
Batch 48/64 loss: 0.2692449688911438
Batch 49/64 loss: 0.28153812885284424
Batch 50/64 loss: 0.27181434631347656
Batch 51/64 loss: 0.28464871644973755
Batch 52/64 loss: 0.27937716245651245
Batch 53/64 loss: 0.27705198526382446
Batch 54/64 loss: 0.27768564224243164
Batch 55/64 loss: 0.2709012031555176
Batch 56/64 loss: 0.276668906211853
Batch 57/64 loss: 0.27559804916381836
Batch 58/64 loss: 0.2796812057495117
Batch 59/64 loss: 0.2812025547027588
Batch 60/64 loss: 0.2767941355705261
Batch 61/64 loss: 0.27905547618865967
Batch 62/64 loss: 0.275507390499115
Batch 63/64 loss: 0.27497583627700806
Batch 64/64 loss: 0.27904415130615234
Epoch 123  Train loss: 0.27513693921706256  Val loss: 0.2883180601080668
Saving best model, epoch: 123
Epoch 124
-------------------------------
Batch 1/64 loss: 0.2743263244628906
Batch 2/64 loss: 0.2772718071937561
Batch 3/64 loss: 0.2766772508621216
Batch 4/64 loss: 0.27714091539382935
Batch 5/64 loss: 0.277019739151001
Batch 6/64 loss: 0.276569128036499
Batch 7/64 loss: 0.27499282360076904
Batch 8/64 loss: 0.26722508668899536
Batch 9/64 loss: 0.27572983503341675
Batch 10/64 loss: 0.2672988176345825
Batch 11/64 loss: 0.27188539505004883
Batch 12/64 loss: 0.27261537313461304
Batch 13/64 loss: 0.27150166034698486
Batch 14/64 loss: 0.2743902802467346
Batch 15/64 loss: 0.2703092098236084
Batch 16/64 loss: 0.27787166833877563
Batch 17/64 loss: 0.2697679400444031
Batch 18/64 loss: 0.2793007493019104
Batch 19/64 loss: 0.2726856470108032
Batch 20/64 loss: 0.288612961769104
Batch 21/64 loss: 0.27576887607574463
Batch 22/64 loss: 0.2820298671722412
Batch 23/64 loss: 0.27551257610321045
Batch 24/64 loss: 0.2830618619918823
Batch 25/64 loss: 0.28076183795928955
Batch 26/64 loss: 0.27040040493011475
Batch 27/64 loss: 0.2695556879043579
Batch 28/64 loss: 0.26943695545196533
Batch 29/64 loss: 0.280411958694458
Batch 30/64 loss: 0.2791275978088379
Batch 31/64 loss: 0.27966630458831787
Batch 32/64 loss: 0.27009057998657227
Batch 33/64 loss: 0.26842254400253296
Batch 34/64 loss: 0.2820013761520386
Batch 35/64 loss: 0.27452385425567627
Batch 36/64 loss: 0.27634531259536743
Batch 37/64 loss: 0.2759508490562439
Batch 38/64 loss: 0.2799108028411865
Batch 39/64 loss: 0.2716556787490845
Batch 40/64 loss: 0.27429378032684326
Batch 41/64 loss: 0.2732764482498169
Batch 42/64 loss: 0.27039068937301636
Batch 43/64 loss: 0.2733062505722046
Batch 44/64 loss: 0.2772390842437744
Batch 45/64 loss: 0.27475905418395996
Batch 46/64 loss: 0.26780736446380615
Batch 47/64 loss: 0.2816706895828247
Batch 48/64 loss: 0.26889359951019287
Batch 49/64 loss: 0.2718812823295593
Batch 50/64 loss: 0.2730848789215088
Batch 51/64 loss: 0.27654415369033813
Batch 52/64 loss: 0.2736353874206543
Batch 53/64 loss: 0.27964919805526733
Batch 54/64 loss: 0.2713395357131958
Batch 55/64 loss: 0.2704256772994995
Batch 56/64 loss: 0.28803545236587524
Batch 57/64 loss: 0.2677985429763794
Batch 58/64 loss: 0.27677589654922485
Batch 59/64 loss: 0.2744538187980652
Batch 60/64 loss: 0.26779311895370483
Batch 61/64 loss: 0.27783483266830444
Batch 62/64 loss: 0.27367663383483887
Batch 63/64 loss: 0.28014904260635376
Batch 64/64 loss: 0.28561902046203613
Epoch 124  Train loss: 0.27508637203889735  Val loss: 0.2873394812914924
Saving best model, epoch: 124
Epoch 125
-------------------------------
Batch 1/64 loss: 0.2835557460784912
Batch 2/64 loss: 0.27954286336898804
Batch 3/64 loss: 0.2766304016113281
Batch 4/64 loss: 0.27071666717529297
Batch 5/64 loss: 0.27288609743118286
Batch 6/64 loss: 0.27149301767349243
Batch 7/64 loss: 0.2762417793273926
Batch 8/64 loss: 0.2666236162185669
Batch 9/64 loss: 0.2774508595466614
Batch 10/64 loss: 0.2720535397529602
Batch 11/64 loss: 0.26958608627319336
Batch 12/64 loss: 0.27733415365219116
Batch 13/64 loss: 0.27889347076416016
Batch 14/64 loss: 0.27982401847839355
Batch 15/64 loss: 0.27867043018341064
Batch 16/64 loss: 0.2716120481491089
Batch 17/64 loss: 0.27653270959854126
Batch 18/64 loss: 0.28535330295562744
Batch 19/64 loss: 0.27698588371276855
Batch 20/64 loss: 0.26979053020477295
Batch 21/64 loss: 0.27058088779449463
Batch 22/64 loss: 0.27041131258010864
Batch 23/64 loss: 0.2766396999359131
Batch 24/64 loss: 0.2743120789527893
Batch 25/64 loss: 0.2735520601272583
Batch 26/64 loss: 0.268481969833374
Batch 27/64 loss: 0.27597594261169434
Batch 28/64 loss: 0.27821779251098633
Batch 29/64 loss: 0.27972882986068726
Batch 30/64 loss: 0.2831847667694092
Batch 31/64 loss: 0.27455008029937744
Batch 32/64 loss: 0.2773275375366211
Batch 33/64 loss: 0.2715468406677246
Batch 34/64 loss: 0.27577733993530273
Batch 35/64 loss: 0.27579033374786377
Batch 36/64 loss: 0.27154576778411865
Batch 37/64 loss: 0.28109467029571533
Batch 38/64 loss: 0.2797199487686157
Batch 39/64 loss: 0.2716197371482849
Batch 40/64 loss: 0.27019888162612915
Batch 41/64 loss: 0.27307796478271484
Batch 42/64 loss: 0.27338433265686035
Batch 43/64 loss: 0.28367066383361816
Batch 44/64 loss: 0.2721244692802429
Batch 45/64 loss: 0.2724151015281677
Batch 46/64 loss: 0.2809862494468689
Batch 47/64 loss: 0.27743643522262573
Batch 48/64 loss: 0.2813448905944824
Batch 49/64 loss: 0.2704744338989258
Batch 50/64 loss: 0.2753676176071167
Batch 51/64 loss: 0.276084840297699
Batch 52/64 loss: 0.27124106884002686
Batch 53/64 loss: 0.274112343788147
Batch 54/64 loss: 0.27924442291259766
Batch 55/64 loss: 0.26940858364105225
Batch 56/64 loss: 0.27577364444732666
Batch 57/64 loss: 0.26791220903396606
Batch 58/64 loss: 0.2688564658164978
Batch 59/64 loss: 0.2812449336051941
Batch 60/64 loss: 0.2710685133934021
Batch 61/64 loss: 0.2747964859008789
Batch 62/64 loss: 0.2736856937408447
Batch 63/64 loss: 0.26522916555404663
Batch 64/64 loss: 0.2828279733657837
Epoch 125  Train loss: 0.27502894448299037  Val loss: 0.28765791347346353
Epoch 126
-------------------------------
Batch 1/64 loss: 0.27455830574035645
Batch 2/64 loss: 0.2631721496582031
Batch 3/64 loss: 0.2766762971878052
Batch 4/64 loss: 0.27299827337265015
Batch 5/64 loss: 0.2681906223297119
Batch 6/64 loss: 0.2668609023094177
Batch 7/64 loss: 0.27540111541748047
Batch 8/64 loss: 0.2755690813064575
Batch 9/64 loss: 0.2762939929962158
Batch 10/64 loss: 0.2740796208381653
Batch 11/64 loss: 0.27160102128982544
Batch 12/64 loss: 0.27516812086105347
Batch 13/64 loss: 0.2772871255874634
Batch 14/64 loss: 0.27151358127593994
Batch 15/64 loss: 0.27687734365463257
Batch 16/64 loss: 0.2703266143798828
Batch 17/64 loss: 0.27694594860076904
Batch 18/64 loss: 0.2728707790374756
Batch 19/64 loss: 0.28167396783828735
Batch 20/64 loss: 0.2763546109199524
Batch 21/64 loss: 0.2713254690170288
Batch 22/64 loss: 0.26544833183288574
Batch 23/64 loss: 0.2755542993545532
Batch 24/64 loss: 0.27643507719039917
Batch 25/64 loss: 0.28192800283432007
Batch 26/64 loss: 0.27519357204437256
Batch 27/64 loss: 0.27907514572143555
Batch 28/64 loss: 0.2721162438392639
Batch 29/64 loss: 0.2767789363861084
Batch 30/64 loss: 0.27011585235595703
Batch 31/64 loss: 0.2728835344314575
Batch 32/64 loss: 0.27801573276519775
Batch 33/64 loss: 0.2742670774459839
Batch 34/64 loss: 0.2698713541030884
Batch 35/64 loss: 0.27684420347213745
Batch 36/64 loss: 0.2698168158531189
Batch 37/64 loss: 0.27379119396209717
Batch 38/64 loss: 0.27184969186782837
Batch 39/64 loss: 0.27892082929611206
Batch 40/64 loss: 0.2692323923110962
Batch 41/64 loss: 0.2714478373527527
Batch 42/64 loss: 0.2693227529525757
Batch 43/64 loss: 0.273992121219635
Batch 44/64 loss: 0.27475476264953613
Batch 45/64 loss: 0.2814311981201172
Batch 46/64 loss: 0.2715545892715454
Batch 47/64 loss: 0.2683015465736389
Batch 48/64 loss: 0.27900081872940063
Batch 49/64 loss: 0.2805129289627075
Batch 50/64 loss: 0.2791798710823059
Batch 51/64 loss: 0.27046436071395874
Batch 52/64 loss: 0.2788822650909424
Batch 53/64 loss: 0.2727307081222534
Batch 54/64 loss: 0.27261555194854736
Batch 55/64 loss: 0.2746676206588745
Batch 56/64 loss: 0.2859596610069275
Batch 57/64 loss: 0.2632702589035034
Batch 58/64 loss: 0.27193665504455566
Batch 59/64 loss: 0.27858126163482666
Batch 60/64 loss: 0.2753821611404419
Batch 61/64 loss: 0.2816150188446045
Batch 62/64 loss: 0.28105729818344116
Batch 63/64 loss: 0.27951276302337646
Batch 64/64 loss: 0.2744622230529785
Epoch 126  Train loss: 0.274445551516963  Val loss: 0.2890794414425224
Epoch 127
-------------------------------
Batch 1/64 loss: 0.2682293653488159
Batch 2/64 loss: 0.2754955291748047
Batch 3/64 loss: 0.2683495283126831
Batch 4/64 loss: 0.26719003915786743
Batch 5/64 loss: 0.2681286931037903
Batch 6/64 loss: 0.2662716507911682
Batch 7/64 loss: 0.27374833822250366
Batch 8/64 loss: 0.2742065191268921
Batch 9/64 loss: 0.27590805292129517
Batch 10/64 loss: 0.2654816508293152
Batch 11/64 loss: 0.26980912685394287
Batch 12/64 loss: 0.27113258838653564
Batch 13/64 loss: 0.26620280742645264
Batch 14/64 loss: 0.26771122217178345
Batch 15/64 loss: 0.27460557222366333
Batch 16/64 loss: 0.27827274799346924
Batch 17/64 loss: 0.27406466007232666
Batch 18/64 loss: 0.272916316986084
Batch 19/64 loss: 0.27560025453567505
Batch 20/64 loss: 0.2686843276023865
Batch 21/64 loss: 0.2775258421897888
Batch 22/64 loss: 0.26670581102371216
Batch 23/64 loss: 0.2627526521682739
Batch 24/64 loss: 0.2800559997558594
Batch 25/64 loss: 0.2799782156944275
Batch 26/64 loss: 0.26921892166137695
Batch 27/64 loss: 0.2716084122657776
Batch 28/64 loss: 0.27373528480529785
Batch 29/64 loss: 0.2721925973892212
Batch 30/64 loss: 0.28063905239105225
Batch 31/64 loss: 0.28133392333984375
Batch 32/64 loss: 0.26590675115585327
Batch 33/64 loss: 0.26880234479904175
Batch 34/64 loss: 0.2741631269454956
Batch 35/64 loss: 0.2668013572692871
Batch 36/64 loss: 0.2831125259399414
Batch 37/64 loss: 0.2745952606201172
Batch 38/64 loss: 0.27224159240722656
Batch 39/64 loss: 0.27092689275741577
Batch 40/64 loss: 0.28728675842285156
Batch 41/64 loss: 0.2756441831588745
Batch 42/64 loss: 0.2706814408302307
Batch 43/64 loss: 0.26458579301834106
Batch 44/64 loss: 0.2707228660583496
Batch 45/64 loss: 0.2739524841308594
Batch 46/64 loss: 0.27811866998672485
Batch 47/64 loss: 0.27744221687316895
Batch 48/64 loss: 0.2685798406600952
Batch 49/64 loss: 0.2718285322189331
Batch 50/64 loss: 0.2786039113998413
Batch 51/64 loss: 0.27215683460235596
Batch 52/64 loss: 0.2725983262062073
Batch 53/64 loss: 0.2722820043563843
Batch 54/64 loss: 0.27287375926971436
Batch 55/64 loss: 0.28014183044433594
Batch 56/64 loss: 0.273379385471344
Batch 57/64 loss: 0.2771095037460327
Batch 58/64 loss: 0.2690376043319702
Batch 59/64 loss: 0.27212679386138916
Batch 60/64 loss: 0.2745116353034973
Batch 61/64 loss: 0.2852998971939087
Batch 62/64 loss: 0.28688549995422363
Batch 63/64 loss: 0.2720600366592407
Batch 64/64 loss: 0.2702261805534363
Epoch 127  Train loss: 0.27317466665716733  Val loss: 0.28724856495447587
Saving best model, epoch: 127
Epoch 128
-------------------------------
Batch 1/64 loss: 0.27070122957229614
Batch 2/64 loss: 0.27891993522644043
Batch 3/64 loss: 0.2637177109718323
Batch 4/64 loss: 0.2730522155761719
Batch 5/64 loss: 0.2673330307006836
Batch 6/64 loss: 0.2691459655761719
Batch 7/64 loss: 0.28265154361724854
Batch 8/64 loss: 0.2658141255378723
Batch 9/64 loss: 0.26757973432540894
Batch 10/64 loss: 0.28394997119903564
Batch 11/64 loss: 0.2810050845146179
Batch 12/64 loss: 0.27971041202545166
Batch 13/64 loss: 0.27548110485076904
Batch 14/64 loss: 0.2811046838760376
Batch 15/64 loss: 0.27247750759124756
Batch 16/64 loss: 0.2609550952911377
Batch 17/64 loss: 0.266762375831604
Batch 18/64 loss: 0.27308493852615356
Batch 19/64 loss: 0.27008235454559326
Batch 20/64 loss: 0.2646670341491699
Batch 21/64 loss: 0.2724313735961914
Batch 22/64 loss: 0.2732498049736023
Batch 23/64 loss: 0.272182822227478
Batch 24/64 loss: 0.276716947555542
Batch 25/64 loss: 0.2697347402572632
Batch 26/64 loss: 0.2703191041946411
Batch 27/64 loss: 0.26487231254577637
Batch 28/64 loss: 0.2739028334617615
Batch 29/64 loss: 0.2739248275756836
Batch 30/64 loss: 0.27678942680358887
Batch 31/64 loss: 0.2788430452346802
Batch 32/64 loss: 0.2841961979866028
Batch 33/64 loss: 0.2754098176956177
Batch 34/64 loss: 0.2698575258255005
Batch 35/64 loss: 0.27722036838531494
Batch 36/64 loss: 0.27179402112960815
Batch 37/64 loss: 0.2743924856185913
Batch 38/64 loss: 0.27748942375183105
Batch 39/64 loss: 0.27910512685775757
Batch 40/64 loss: 0.27340710163116455
Batch 41/64 loss: 0.26342570781707764
Batch 42/64 loss: 0.26450228691101074
Batch 43/64 loss: 0.27391159534454346
Batch 44/64 loss: 0.26468992233276367
Batch 45/64 loss: 0.28228074312210083
Batch 46/64 loss: 0.27306991815567017
Batch 47/64 loss: 0.2748486399650574
Batch 48/64 loss: 0.2676897644996643
Batch 49/64 loss: 0.27283239364624023
Batch 50/64 loss: 0.27668988704681396
Batch 51/64 loss: 0.2821323871612549
Batch 52/64 loss: 0.2804000973701477
Batch 53/64 loss: 0.2744644284248352
Batch 54/64 loss: 0.27388817071914673
Batch 55/64 loss: 0.28041326999664307
Batch 56/64 loss: 0.2727094888687134
Batch 57/64 loss: 0.2729372978210449
Batch 58/64 loss: 0.27571308612823486
Batch 59/64 loss: 0.2714839577674866
Batch 60/64 loss: 0.27359282970428467
Batch 61/64 loss: 0.27852725982666016
Batch 62/64 loss: 0.27229321002960205
Batch 63/64 loss: 0.283088743686676
Batch 64/64 loss: 0.27760255336761475
Epoch 128  Train loss: 0.27369133117152195  Val loss: 0.2868678074112463
Saving best model, epoch: 128
Epoch 129
-------------------------------
Batch 1/64 loss: 0.2809600234031677
Batch 2/64 loss: 0.2736532688140869
Batch 3/64 loss: 0.2685146927833557
Batch 4/64 loss: 0.2685306668281555
Batch 5/64 loss: 0.26606398820877075
Batch 6/64 loss: 0.26818209886550903
Batch 7/64 loss: 0.2708611488342285
Batch 8/64 loss: 0.26519858837127686
Batch 9/64 loss: 0.27810144424438477
Batch 10/64 loss: 0.2724696397781372
Batch 11/64 loss: 0.2834268808364868
Batch 12/64 loss: 0.28191888332366943
Batch 13/64 loss: 0.2800743579864502
Batch 14/64 loss: 0.2814466953277588
Batch 15/64 loss: 0.27419912815093994
Batch 16/64 loss: 0.270050048828125
Batch 17/64 loss: 0.2621701955795288
Batch 18/64 loss: 0.2675322890281677
Batch 19/64 loss: 0.27381378412246704
Batch 20/64 loss: 0.2636677026748657
Batch 21/64 loss: 0.2718598246574402
Batch 22/64 loss: 0.2747598886489868
Batch 23/64 loss: 0.2705799341201782
Batch 24/64 loss: 0.2697434425354004
Batch 25/64 loss: 0.27280962467193604
Batch 26/64 loss: 0.2673523426055908
Batch 27/64 loss: 0.2726781964302063
Batch 28/64 loss: 0.264909565448761
Batch 29/64 loss: 0.2717628479003906
Batch 30/64 loss: 0.2671954035758972
Batch 31/64 loss: 0.2755305767059326
Batch 32/64 loss: 0.2761162519454956
Batch 33/64 loss: 0.27823275327682495
Batch 34/64 loss: 0.27044153213500977
Batch 35/64 loss: 0.2708970308303833
Batch 36/64 loss: 0.2764662504196167
Batch 37/64 loss: 0.2785570025444031
Batch 38/64 loss: 0.2692576050758362
Batch 39/64 loss: 0.27111291885375977
Batch 40/64 loss: 0.267985463142395
Batch 41/64 loss: 0.27081596851348877
Batch 42/64 loss: 0.28145623207092285
Batch 43/64 loss: 0.2666972875595093
Batch 44/64 loss: 0.27763956785202026
Batch 45/64 loss: 0.272766649723053
Batch 46/64 loss: 0.2678418755531311
Batch 47/64 loss: 0.2842038869857788
Batch 48/64 loss: 0.27045392990112305
Batch 49/64 loss: 0.26550477743148804
Batch 50/64 loss: 0.2777491807937622
Batch 51/64 loss: 0.2699601650238037
Batch 52/64 loss: 0.2768872380256653
Batch 53/64 loss: 0.28605765104293823
Batch 54/64 loss: 0.2665616273880005
Batch 55/64 loss: 0.27516186237335205
Batch 56/64 loss: 0.2683725357055664
Batch 57/64 loss: 0.2825630307197571
Batch 58/64 loss: 0.2762903571128845
Batch 59/64 loss: 0.2717728614807129
Batch 60/64 loss: 0.2698671817779541
Batch 61/64 loss: 0.2671293616294861
Batch 62/64 loss: 0.26708734035491943
Batch 63/64 loss: 0.2670361399650574
Batch 64/64 loss: 0.28184932470321655
Epoch 129  Train loss: 0.272632904847463  Val loss: 0.2871479074569912
Epoch 130
-------------------------------
Batch 1/64 loss: 0.27252620458602905
Batch 2/64 loss: 0.2612968683242798
Batch 3/64 loss: 0.2753342390060425
Batch 4/64 loss: 0.27163243293762207
Batch 5/64 loss: 0.27074122428894043
Batch 6/64 loss: 0.2728119492530823
Batch 7/64 loss: 0.274929404258728
Batch 8/64 loss: 0.26731252670288086
Batch 9/64 loss: 0.272724449634552
Batch 10/64 loss: 0.27434974908828735
Batch 11/64 loss: 0.2650414705276489
Batch 12/64 loss: 0.2665550112724304
Batch 13/64 loss: 0.2699297070503235
Batch 14/64 loss: 0.26940637826919556
Batch 15/64 loss: 0.28048455715179443
Batch 16/64 loss: 0.2707470655441284
Batch 17/64 loss: 0.2670607566833496
Batch 18/64 loss: 0.27223730087280273
Batch 19/64 loss: 0.27367985248565674
Batch 20/64 loss: 0.2715573310852051
Batch 21/64 loss: 0.27675938606262207
Batch 22/64 loss: 0.2723473310470581
Batch 23/64 loss: 0.27412450313568115
Batch 24/64 loss: 0.2713441848754883
Batch 25/64 loss: 0.2694888710975647
Batch 26/64 loss: 0.2838934659957886
Batch 27/64 loss: 0.2687309980392456
Batch 28/64 loss: 0.2733493447303772
Batch 29/64 loss: 0.26827168464660645
Batch 30/64 loss: 0.2761862277984619
Batch 31/64 loss: 0.27457815408706665
Batch 32/64 loss: 0.26845335960388184
Batch 33/64 loss: 0.26299625635147095
Batch 34/64 loss: 0.2735917568206787
Batch 35/64 loss: 0.27049779891967773
Batch 36/64 loss: 0.2814161777496338
Batch 37/64 loss: 0.27286088466644287
Batch 38/64 loss: 0.28326141834259033
Batch 39/64 loss: 0.2694406509399414
Batch 40/64 loss: 0.2744464874267578
Batch 41/64 loss: 0.2671700716018677
Batch 42/64 loss: 0.27986663579940796
Batch 43/64 loss: 0.262015700340271
Batch 44/64 loss: 0.27932703495025635
Batch 45/64 loss: 0.2723747491836548
Batch 46/64 loss: 0.2711774706840515
Batch 47/64 loss: 0.2697948217391968
Batch 48/64 loss: 0.2677118182182312
Batch 49/64 loss: 0.27327191829681396
Batch 50/64 loss: 0.2845017910003662
Batch 51/64 loss: 0.2808520793914795
Batch 52/64 loss: 0.26527726650238037
Batch 53/64 loss: 0.27838820219039917
Batch 54/64 loss: 0.26643502712249756
Batch 55/64 loss: 0.2762683629989624
Batch 56/64 loss: 0.26645076274871826
Batch 57/64 loss: 0.2762589454650879
Batch 58/64 loss: 0.27576112747192383
Batch 59/64 loss: 0.26741981506347656
Batch 60/64 loss: 0.2789115309715271
Batch 61/64 loss: 0.2678379416465759
Batch 62/64 loss: 0.27537238597869873
Batch 63/64 loss: 0.2761561870574951
Batch 64/64 loss: 0.27480292320251465
Epoch 130  Train loss: 0.27248786290486654  Val loss: 0.286131271791622
Saving best model, epoch: 130
Epoch 131
-------------------------------
Batch 1/64 loss: 0.27752459049224854
Batch 2/64 loss: 0.27462291717529297
Batch 3/64 loss: 0.2715105414390564
Batch 4/64 loss: 0.2749050259590149
Batch 5/64 loss: 0.27286815643310547
Batch 6/64 loss: 0.2672618627548218
Batch 7/64 loss: 0.2676047682762146
Batch 8/64 loss: 0.2777782678604126
Batch 9/64 loss: 0.2699963450431824
Batch 10/64 loss: 0.2735559940338135
Batch 11/64 loss: 0.26656603813171387
Batch 12/64 loss: 0.2642398476600647
Batch 13/64 loss: 0.2821129560470581
Batch 14/64 loss: 0.26202404499053955
Batch 15/64 loss: 0.2791714668273926
Batch 16/64 loss: 0.25990593433380127
Batch 17/64 loss: 0.28122061491012573
Batch 18/64 loss: 0.26694875955581665
Batch 19/64 loss: 0.26758694648742676
Batch 20/64 loss: 0.27224016189575195
Batch 21/64 loss: 0.26924383640289307
Batch 22/64 loss: 0.28050434589385986
Batch 23/64 loss: 0.26256465911865234
Batch 24/64 loss: 0.2812042832374573
Batch 25/64 loss: 0.26649749279022217
Batch 26/64 loss: 0.27205920219421387
Batch 27/64 loss: 0.26082712411880493
Batch 28/64 loss: 0.27478837966918945
Batch 29/64 loss: 0.26833730936050415
Batch 30/64 loss: 0.2750263214111328
Batch 31/64 loss: 0.272283673286438
Batch 32/64 loss: 0.27436256408691406
Batch 33/64 loss: 0.2741049528121948
Batch 34/64 loss: 0.2638653516769409
Batch 35/64 loss: 0.2706969976425171
Batch 36/64 loss: 0.27474379539489746
Batch 37/64 loss: 0.27473878860473633
Batch 38/64 loss: 0.27163124084472656
Batch 39/64 loss: 0.2741115689277649
Batch 40/64 loss: 0.2739596962928772
Batch 41/64 loss: 0.2710621953010559
Batch 42/64 loss: 0.2727561593055725
Batch 43/64 loss: 0.2725733518600464
Batch 44/64 loss: 0.2656867504119873
Batch 45/64 loss: 0.2693859338760376
Batch 46/64 loss: 0.28200602531433105
Batch 47/64 loss: 0.26086580753326416
Batch 48/64 loss: 0.2701658606529236
Batch 49/64 loss: 0.27569955587387085
Batch 50/64 loss: 0.2682610750198364
Batch 51/64 loss: 0.2728431820869446
Batch 52/64 loss: 0.272513747215271
Batch 53/64 loss: 0.27221691608428955
Batch 54/64 loss: 0.268332839012146
Batch 55/64 loss: 0.26779454946517944
Batch 56/64 loss: 0.27033531665802
Batch 57/64 loss: 0.27704596519470215
Batch 58/64 loss: 0.2700369358062744
Batch 59/64 loss: 0.27113741636276245
Batch 60/64 loss: 0.2672220468521118
Batch 61/64 loss: 0.27750706672668457
Batch 62/64 loss: 0.27021729946136475
Batch 63/64 loss: 0.270915687084198
Batch 64/64 loss: 0.2708664536476135
Epoch 131  Train loss: 0.2714498564308765  Val loss: 0.2862398745268071
Epoch 132
-------------------------------
Batch 1/64 loss: 0.26387614011764526
Batch 2/64 loss: 0.2739294767379761
Batch 3/64 loss: 0.26459604501724243
Batch 4/64 loss: 0.27880316972732544
Batch 5/64 loss: 0.27398157119750977
Batch 6/64 loss: 0.2720406651496887
Batch 7/64 loss: 0.28033292293548584
Batch 8/64 loss: 0.27311062812805176
Batch 9/64 loss: 0.27674078941345215
Batch 10/64 loss: 0.2674102783203125
Batch 11/64 loss: 0.26910632848739624
Batch 12/64 loss: 0.27237796783447266
Batch 13/64 loss: 0.26622456312179565
Batch 14/64 loss: 0.26914656162261963
Batch 15/64 loss: 0.26283544301986694
Batch 16/64 loss: 0.27033185958862305
Batch 17/64 loss: 0.28172123432159424
Batch 18/64 loss: 0.2769385576248169
Batch 19/64 loss: 0.26893913745880127
Batch 20/64 loss: 0.27171945571899414
Batch 21/64 loss: 0.27089911699295044
Batch 22/64 loss: 0.2695772647857666
Batch 23/64 loss: 0.2633568048477173
Batch 24/64 loss: 0.27000880241394043
Batch 25/64 loss: 0.2671515941619873
Batch 26/64 loss: 0.2771371603012085
Batch 27/64 loss: 0.27625054121017456
Batch 28/64 loss: 0.2657091021537781
Batch 29/64 loss: 0.271173894405365
Batch 30/64 loss: 0.2657114267349243
Batch 31/64 loss: 0.26931047439575195
Batch 32/64 loss: 0.2764310836791992
Batch 33/64 loss: 0.27322232723236084
Batch 34/64 loss: 0.27080249786376953
Batch 35/64 loss: 0.2721792459487915
Batch 36/64 loss: 0.26901060342788696
Batch 37/64 loss: 0.2660801410675049
Batch 38/64 loss: 0.2729271650314331
Batch 39/64 loss: 0.2793480157852173
Batch 40/64 loss: 0.26910436153411865
Batch 41/64 loss: 0.2684420347213745
Batch 42/64 loss: 0.28278565406799316
Batch 43/64 loss: 0.26759207248687744
Batch 44/64 loss: 0.2787649631500244
Batch 45/64 loss: 0.26484817266464233
Batch 46/64 loss: 0.27063941955566406
Batch 47/64 loss: 0.27255475521087646
Batch 48/64 loss: 0.27350831031799316
Batch 49/64 loss: 0.269542396068573
Batch 50/64 loss: 0.26919758319854736
Batch 51/64 loss: 0.27445489168167114
Batch 52/64 loss: 0.27367091178894043
Batch 53/64 loss: 0.26557403802871704
Batch 54/64 loss: 0.2828907370567322
Batch 55/64 loss: 0.274516224861145
Batch 56/64 loss: 0.2755436301231384
Batch 57/64 loss: 0.2694545388221741
Batch 58/64 loss: 0.2704589366912842
Batch 59/64 loss: 0.27214515209198
Batch 60/64 loss: 0.2679654359817505
Batch 61/64 loss: 0.2740286588668823
Batch 62/64 loss: 0.2776249647140503
Batch 63/64 loss: 0.26911109685897827
Batch 64/64 loss: 0.2656863331794739
Epoch 132  Train loss: 0.2715942548770531  Val loss: 0.28746107394752635
Epoch 133
-------------------------------
Batch 1/64 loss: 0.2696413993835449
Batch 2/64 loss: 0.27430951595306396
Batch 3/64 loss: 0.2697286605834961
Batch 4/64 loss: 0.2724316716194153
Batch 5/64 loss: 0.2717586159706116
Batch 6/64 loss: 0.27407753467559814
Batch 7/64 loss: 0.2765454053878784
Batch 8/64 loss: 0.26561516523361206
Batch 9/64 loss: 0.2667846083641052
Batch 10/64 loss: 0.26873111724853516
Batch 11/64 loss: 0.2605101466178894
Batch 12/64 loss: 0.26972496509552
Batch 13/64 loss: 0.26842236518859863
Batch 14/64 loss: 0.27417826652526855
Batch 15/64 loss: 0.2795315980911255
Batch 16/64 loss: 0.2676081657409668
Batch 17/64 loss: 0.27675533294677734
Batch 18/64 loss: 0.27461397647857666
Batch 19/64 loss: 0.2767559885978699
Batch 20/64 loss: 0.27161967754364014
Batch 21/64 loss: 0.26856839656829834
Batch 22/64 loss: 0.27978724241256714
Batch 23/64 loss: 0.27149736881256104
Batch 24/64 loss: 0.2806240916252136
Batch 25/64 loss: 0.27514195442199707
Batch 26/64 loss: 0.26237666606903076
Batch 27/64 loss: 0.27038824558258057
Batch 28/64 loss: 0.2659703493118286
Batch 29/64 loss: 0.2754811644554138
Batch 30/64 loss: 0.2710850238800049
Batch 31/64 loss: 0.27837955951690674
Batch 32/64 loss: 0.2672303318977356
Batch 33/64 loss: 0.2681310176849365
Batch 34/64 loss: 0.27257102727890015
Batch 35/64 loss: 0.26901787519454956
Batch 36/64 loss: 0.2730870842933655
Batch 37/64 loss: 0.28094780445098877
Batch 38/64 loss: 0.27765655517578125
Batch 39/64 loss: 0.2744939923286438
Batch 40/64 loss: 0.26973044872283936
Batch 41/64 loss: 0.2752823829650879
Batch 42/64 loss: 0.2749837636947632
Batch 43/64 loss: 0.2685953378677368
Batch 44/64 loss: 0.27141714096069336
Batch 45/64 loss: 0.2718527317047119
Batch 46/64 loss: 0.27244842052459717
Batch 47/64 loss: 0.27035456895828247
Batch 48/64 loss: 0.2661515474319458
Batch 49/64 loss: 0.2653934955596924
Batch 50/64 loss: 0.27775657176971436
Batch 51/64 loss: 0.2687292695045471
Batch 52/64 loss: 0.26848745346069336
Batch 53/64 loss: 0.26716166734695435
Batch 54/64 loss: 0.26908326148986816
Batch 55/64 loss: 0.2707784175872803
Batch 56/64 loss: 0.28079384565353394
Batch 57/64 loss: 0.2818235754966736
Batch 58/64 loss: 0.2713925242424011
Batch 59/64 loss: 0.2717564105987549
Batch 60/64 loss: 0.266196072101593
Batch 61/64 loss: 0.2739185690879822
Batch 62/64 loss: 0.2727413773536682
Batch 63/64 loss: 0.2741197943687439
Batch 64/64 loss: 0.2672196626663208
Epoch 133  Train loss: 0.27189244429270426  Val loss: 0.2870491745136038
Epoch 134
-------------------------------
Batch 1/64 loss: 0.27184057235717773
Batch 2/64 loss: 0.2737407684326172
Batch 3/64 loss: 0.2701619863510132
Batch 4/64 loss: 0.26988106966018677
Batch 5/64 loss: 0.2603455185890198
Batch 6/64 loss: 0.26954221725463867
Batch 7/64 loss: 0.27371716499328613
Batch 8/64 loss: 0.2580071687698364
Batch 9/64 loss: 0.2748897671699524
Batch 10/64 loss: 0.27778828144073486
Batch 11/64 loss: 0.2551215887069702
Batch 12/64 loss: 0.2802697420120239
Batch 13/64 loss: 0.2781020402908325
Batch 14/64 loss: 0.2735443115234375
Batch 15/64 loss: 0.2708418369293213
Batch 16/64 loss: 0.27584946155548096
Batch 17/64 loss: 0.28183305263519287
Batch 18/64 loss: 0.2680894732475281
Batch 19/64 loss: 0.2702751159667969
Batch 20/64 loss: 0.27479422092437744
Batch 21/64 loss: 0.26221078634262085
Batch 22/64 loss: 0.2632104158401489
Batch 23/64 loss: 0.27342885732650757
Batch 24/64 loss: 0.27085840702056885
Batch 25/64 loss: 0.27277594804763794
Batch 26/64 loss: 0.2667182683944702
Batch 27/64 loss: 0.2763012647628784
Batch 28/64 loss: 0.27335160970687866
Batch 29/64 loss: 0.2634034752845764
Batch 30/64 loss: 0.2739444971084595
Batch 31/64 loss: 0.2780906558036804
Batch 32/64 loss: 0.27932119369506836
Batch 33/64 loss: 0.2792245149612427
Batch 34/64 loss: 0.2803455591201782
Batch 35/64 loss: 0.2706131935119629
Batch 36/64 loss: 0.2663206458091736
Batch 37/64 loss: 0.2606819272041321
Batch 38/64 loss: 0.27081942558288574
Batch 39/64 loss: 0.2827765941619873
Batch 40/64 loss: 0.284946084022522
Batch 41/64 loss: 0.26477402448654175
Batch 42/64 loss: 0.27084362506866455
Batch 43/64 loss: 0.27523088455200195
Batch 44/64 loss: 0.26880455017089844
Batch 45/64 loss: 0.2730525732040405
Batch 46/64 loss: 0.2757212519645691
Batch 47/64 loss: 0.26646924018859863
Batch 48/64 loss: 0.2681140899658203
Batch 49/64 loss: 0.27643662691116333
Batch 50/64 loss: 0.26834964752197266
Batch 51/64 loss: 0.271999716758728
Batch 52/64 loss: 0.2798295021057129
Batch 53/64 loss: 0.27258652448654175
Batch 54/64 loss: 0.2710745334625244
Batch 55/64 loss: 0.27264559268951416
Batch 56/64 loss: 0.27100735902786255
Batch 57/64 loss: 0.2651856541633606
Batch 58/64 loss: 0.2680943012237549
Batch 59/64 loss: 0.265691339969635
Batch 60/64 loss: 0.2654862403869629
Batch 61/64 loss: 0.2738823890686035
Batch 62/64 loss: 0.2719186544418335
Batch 63/64 loss: 0.26260948181152344
Batch 64/64 loss: 0.2728622555732727
Epoch 134  Train loss: 0.2714107165149614  Val loss: 0.2867868161693062
Epoch 135
-------------------------------
Batch 1/64 loss: 0.2692245841026306
Batch 2/64 loss: 0.28265178203582764
Batch 3/64 loss: 0.2675231695175171
Batch 4/64 loss: 0.26660823822021484
Batch 5/64 loss: 0.26686471700668335
Batch 6/64 loss: 0.2688472867012024
Batch 7/64 loss: 0.2668790817260742
Batch 8/64 loss: 0.2676791548728943
Batch 9/64 loss: 0.27546191215515137
Batch 10/64 loss: 0.2670578956604004
Batch 11/64 loss: 0.27177679538726807
Batch 12/64 loss: 0.268379271030426
Batch 13/64 loss: 0.2617621421813965
Batch 14/64 loss: 0.2757473587989807
Batch 15/64 loss: 0.2673577070236206
Batch 16/64 loss: 0.2762094736099243
Batch 17/64 loss: 0.2636646032333374
Batch 18/64 loss: 0.27017754316329956
Batch 19/64 loss: 0.2712005376815796
Batch 20/64 loss: 0.2775205969810486
Batch 21/64 loss: 0.26118922233581543
Batch 22/64 loss: 0.27331405878067017
Batch 23/64 loss: 0.2603510618209839
Batch 24/64 loss: 0.2765488028526306
Batch 25/64 loss: 0.27272212505340576
Batch 26/64 loss: 0.2624248266220093
Batch 27/64 loss: 0.2735581398010254
Batch 28/64 loss: 0.2687048316001892
Batch 29/64 loss: 0.2715737223625183
Batch 30/64 loss: 0.27615463733673096
Batch 31/64 loss: 0.2709338665008545
Batch 32/64 loss: 0.26613742113113403
Batch 33/64 loss: 0.2750585675239563
Batch 34/64 loss: 0.2660714387893677
Batch 35/64 loss: 0.2649192810058594
Batch 36/64 loss: 0.2692524194717407
Batch 37/64 loss: 0.2735127806663513
Batch 38/64 loss: 0.2662109136581421
Batch 39/64 loss: 0.2726392149925232
Batch 40/64 loss: 0.2669798731803894
Batch 41/64 loss: 0.27582621574401855
Batch 42/64 loss: 0.2705496549606323
Batch 43/64 loss: 0.2730565071105957
Batch 44/64 loss: 0.2765939235687256
Batch 45/64 loss: 0.2738229036331177
Batch 46/64 loss: 0.27137184143066406
Batch 47/64 loss: 0.26779705286026
Batch 48/64 loss: 0.2706458568572998
Batch 49/64 loss: 0.27196431159973145
Batch 50/64 loss: 0.270906925201416
Batch 51/64 loss: 0.2762569785118103
Batch 52/64 loss: 0.27656614780426025
Batch 53/64 loss: 0.2800087332725525
Batch 54/64 loss: 0.2770204544067383
Batch 55/64 loss: 0.2689552903175354
Batch 56/64 loss: 0.2744690775871277
Batch 57/64 loss: 0.26899290084838867
Batch 58/64 loss: 0.26410627365112305
Batch 59/64 loss: 0.27887874841690063
Batch 60/64 loss: 0.2646937966346741
Batch 61/64 loss: 0.2650042772293091
Batch 62/64 loss: 0.2662414312362671
Batch 63/64 loss: 0.27074533700942993
Batch 64/64 loss: 0.27344322204589844
Epoch 135  Train loss: 0.2705946370667102  Val loss: 0.28691722089072685
Epoch 136
-------------------------------
Batch 1/64 loss: 0.27428990602493286
Batch 2/64 loss: 0.27347302436828613
Batch 3/64 loss: 0.27985477447509766
Batch 4/64 loss: 0.2678738236427307
Batch 5/64 loss: 0.268831729888916
Batch 6/64 loss: 0.2675137519836426
Batch 7/64 loss: 0.27135366201400757
Batch 8/64 loss: 0.2714122533798218
Batch 9/64 loss: 0.2703225612640381
Batch 10/64 loss: 0.2778705954551697
Batch 11/64 loss: 0.268879771232605
Batch 12/64 loss: 0.2753877639770508
Batch 13/64 loss: 0.26547980308532715
Batch 14/64 loss: 0.2647966742515564
Batch 15/64 loss: 0.26585954427719116
Batch 16/64 loss: 0.26943516731262207
Batch 17/64 loss: 0.26505810022354126
Batch 18/64 loss: 0.2634534239768982
Batch 19/64 loss: 0.2728360891342163
Batch 20/64 loss: 0.2692612409591675
Batch 21/64 loss: 0.2731902599334717
Batch 22/64 loss: 0.2702077031135559
Batch 23/64 loss: 0.2724090814590454
Batch 24/64 loss: 0.2707024812698364
Batch 25/64 loss: 0.2695731520652771
Batch 26/64 loss: 0.27112245559692383
Batch 27/64 loss: 0.2554229497909546
Batch 28/64 loss: 0.2754877805709839
Batch 29/64 loss: 0.27225637435913086
Batch 30/64 loss: 0.2647489309310913
Batch 31/64 loss: 0.26955747604370117
Batch 32/64 loss: 0.2756924629211426
Batch 33/64 loss: 0.2715229392051697
Batch 34/64 loss: 0.26874053478240967
Batch 35/64 loss: 0.26335829496383667
Batch 36/64 loss: 0.2622646689414978
Batch 37/64 loss: 0.2674189805984497
Batch 38/64 loss: 0.27265000343322754
Batch 39/64 loss: 0.2737154960632324
Batch 40/64 loss: 0.2760380506515503
Batch 41/64 loss: 0.2816227674484253
Batch 42/64 loss: 0.2686308026313782
Batch 43/64 loss: 0.2738243341445923
Batch 44/64 loss: 0.2698911428451538
Batch 45/64 loss: 0.2611362338066101
Batch 46/64 loss: 0.27062761783599854
Batch 47/64 loss: 0.26890337467193604
Batch 48/64 loss: 0.2728230953216553
Batch 49/64 loss: 0.2700008153915405
Batch 50/64 loss: 0.26611655950546265
Batch 51/64 loss: 0.2681591510772705
Batch 52/64 loss: 0.27090680599212646
Batch 53/64 loss: 0.2740209102630615
Batch 54/64 loss: 0.2783619165420532
Batch 55/64 loss: 0.2719685435295105
Batch 56/64 loss: 0.26878780126571655
Batch 57/64 loss: 0.2709639072418213
Batch 58/64 loss: 0.27171260118484497
Batch 59/64 loss: 0.26573246717453003
Batch 60/64 loss: 0.27559077739715576
Batch 61/64 loss: 0.27421021461486816
Batch 62/64 loss: 0.27428674697875977
Batch 63/64 loss: 0.2640378475189209
Batch 64/64 loss: 0.2697460651397705
Epoch 136  Train loss: 0.2703364662095612  Val loss: 0.28726876539872687
Epoch 137
-------------------------------
Batch 1/64 loss: 0.2686768174171448
Batch 2/64 loss: 0.2651515603065491
Batch 3/64 loss: 0.26356321573257446
Batch 4/64 loss: 0.276017963886261
Batch 5/64 loss: 0.2753819227218628
Batch 6/64 loss: 0.2722221612930298
Batch 7/64 loss: 0.2705201506614685
Batch 8/64 loss: 0.26642560958862305
Batch 9/64 loss: 0.26640206575393677
Batch 10/64 loss: 0.2635089159011841
Batch 11/64 loss: 0.2671220302581787
Batch 12/64 loss: 0.27387863397598267
Batch 13/64 loss: 0.27750277519226074
Batch 14/64 loss: 0.27214694023132324
Batch 15/64 loss: 0.2671997547149658
Batch 16/64 loss: 0.2668968439102173
Batch 17/64 loss: 0.26782435178756714
Batch 18/64 loss: 0.2673325538635254
Batch 19/64 loss: 0.2641727924346924
Batch 20/64 loss: 0.27951300144195557
Batch 21/64 loss: 0.2732763886451721
Batch 22/64 loss: 0.2679187059402466
Batch 23/64 loss: 0.2702491879463196
Batch 24/64 loss: 0.26752734184265137
Batch 25/64 loss: 0.2614760994911194
Batch 26/64 loss: 0.2674325704574585
Batch 27/64 loss: 0.2661099433898926
Batch 28/64 loss: 0.2801317572593689
Batch 29/64 loss: 0.2669065594673157
Batch 30/64 loss: 0.26920974254608154
Batch 31/64 loss: 0.28033483028411865
Batch 32/64 loss: 0.27826404571533203
Batch 33/64 loss: 0.27670323848724365
Batch 34/64 loss: 0.2659788131713867
Batch 35/64 loss: 0.2741857171058655
Batch 36/64 loss: 0.263827919960022
Batch 37/64 loss: 0.2671654224395752
Batch 38/64 loss: 0.2656223773956299
Batch 39/64 loss: 0.28041189908981323
Batch 40/64 loss: 0.26585209369659424
Batch 41/64 loss: 0.26241809129714966
Batch 42/64 loss: 0.26994848251342773
Batch 43/64 loss: 0.2676352262496948
Batch 44/64 loss: 0.27470552921295166
Batch 45/64 loss: 0.27476000785827637
Batch 46/64 loss: 0.2758883833885193
Batch 47/64 loss: 0.27093660831451416
Batch 48/64 loss: 0.27082228660583496
Batch 49/64 loss: 0.2710888981819153
Batch 50/64 loss: 0.281787633895874
Batch 51/64 loss: 0.2753232717514038
Batch 52/64 loss: 0.274189829826355
Batch 53/64 loss: 0.2718452215194702
Batch 54/64 loss: 0.27777212858200073
Batch 55/64 loss: 0.2738134264945984
Batch 56/64 loss: 0.27638429403305054
Batch 57/64 loss: 0.2785347104072571
Batch 58/64 loss: 0.2690856456756592
Batch 59/64 loss: 0.26105034351348877
Batch 60/64 loss: 0.27471357583999634
Batch 61/64 loss: 0.2734972834587097
Batch 62/64 loss: 0.2699317932128906
Batch 63/64 loss: 0.2681152820587158
Batch 64/64 loss: 0.2730996608734131
Epoch 137  Train loss: 0.27088811631296195  Val loss: 0.28472007652328596
Saving best model, epoch: 137
Epoch 138
-------------------------------
Batch 1/64 loss: 0.2688213586807251
Batch 2/64 loss: 0.27091407775878906
Batch 3/64 loss: 0.27721405029296875
Batch 4/64 loss: 0.2662062644958496
Batch 5/64 loss: 0.26704925298690796
Batch 6/64 loss: 0.2803053855895996
Batch 7/64 loss: 0.26642584800720215
Batch 8/64 loss: 0.2724193334579468
Batch 9/64 loss: 0.26132524013519287
Batch 10/64 loss: 0.2707481384277344
Batch 11/64 loss: 0.263674259185791
Batch 12/64 loss: 0.2700689435005188
Batch 13/64 loss: 0.26821571588516235
Batch 14/64 loss: 0.2693609595298767
Batch 15/64 loss: 0.27285993099212646
Batch 16/64 loss: 0.2728992700576782
Batch 17/64 loss: 0.27466464042663574
Batch 18/64 loss: 0.2709537744522095
Batch 19/64 loss: 0.26876747608184814
Batch 20/64 loss: 0.27027368545532227
Batch 21/64 loss: 0.2798123359680176
Batch 22/64 loss: 0.2732795476913452
Batch 23/64 loss: 0.2637408375740051
Batch 24/64 loss: 0.2657954692840576
Batch 25/64 loss: 0.2643316984176636
Batch 26/64 loss: 0.27589309215545654
Batch 27/64 loss: 0.2747367024421692
Batch 28/64 loss: 0.26694315671920776
Batch 29/64 loss: 0.2684229612350464
Batch 30/64 loss: 0.2637052536010742
Batch 31/64 loss: 0.2772252559661865
Batch 32/64 loss: 0.2657833695411682
Batch 33/64 loss: 0.2619103193283081
Batch 34/64 loss: 0.26748985052108765
Batch 35/64 loss: 0.27250802516937256
Batch 36/64 loss: 0.26927196979522705
Batch 37/64 loss: 0.26849615573883057
Batch 38/64 loss: 0.2726624608039856
Batch 39/64 loss: 0.2705744504928589
Batch 40/64 loss: 0.26241886615753174
Batch 41/64 loss: 0.26188552379608154
Batch 42/64 loss: 0.2730393409729004
Batch 43/64 loss: 0.26323866844177246
Batch 44/64 loss: 0.27704131603240967
Batch 45/64 loss: 0.27574968338012695
Batch 46/64 loss: 0.2746538519859314
Batch 47/64 loss: 0.26088404655456543
Batch 48/64 loss: 0.26556646823883057
Batch 49/64 loss: 0.2608984708786011
Batch 50/64 loss: 0.26554012298583984
Batch 51/64 loss: 0.2633352279663086
Batch 52/64 loss: 0.2780138850212097
Batch 53/64 loss: 0.26180189847946167
Batch 54/64 loss: 0.27188360691070557
Batch 55/64 loss: 0.2693138122558594
Batch 56/64 loss: 0.27580416202545166
Batch 57/64 loss: 0.259691059589386
Batch 58/64 loss: 0.2689090967178345
Batch 59/64 loss: 0.2701374292373657
Batch 60/64 loss: 0.2722346782684326
Batch 61/64 loss: 0.27579963207244873
Batch 62/64 loss: 0.2641984820365906
Batch 63/64 loss: 0.27797210216522217
Batch 64/64 loss: 0.26883387565612793
Epoch 138  Train loss: 0.269449213439343  Val loss: 0.284570833252058
Saving best model, epoch: 138
Epoch 139
-------------------------------
Batch 1/64 loss: 0.27203166484832764
Batch 2/64 loss: 0.2718999981880188
Batch 3/64 loss: 0.2746472954750061
Batch 4/64 loss: 0.26885366439819336
Batch 5/64 loss: 0.265444815158844
Batch 6/64 loss: 0.26000189781188965
Batch 7/64 loss: 0.2747223377227783
Batch 8/64 loss: 0.26364219188690186
Batch 9/64 loss: 0.2699958086013794
Batch 10/64 loss: 0.26830506324768066
Batch 11/64 loss: 0.27113282680511475
Batch 12/64 loss: 0.2671394348144531
Batch 13/64 loss: 0.2746995687484741
Batch 14/64 loss: 0.2651948928833008
Batch 15/64 loss: 0.26517796516418457
Batch 16/64 loss: 0.26892584562301636
Batch 17/64 loss: 0.25960874557495117
Batch 18/64 loss: 0.2657466530799866
Batch 19/64 loss: 0.28160446882247925
Batch 20/64 loss: 0.27075040340423584
Batch 21/64 loss: 0.2670009732246399
Batch 22/64 loss: 0.2718225121498108
Batch 23/64 loss: 0.2608102560043335
Batch 24/64 loss: 0.26813703775405884
Batch 25/64 loss: 0.2660437822341919
Batch 26/64 loss: 0.27096229791641235
Batch 27/64 loss: 0.2699939012527466
Batch 28/64 loss: 0.2661004066467285
Batch 29/64 loss: 0.27792131900787354
Batch 30/64 loss: 0.2648316025733948
Batch 31/64 loss: 0.2608001232147217
Batch 32/64 loss: 0.2687796354293823
Batch 33/64 loss: 0.26607072353363037
Batch 34/64 loss: 0.2711408734321594
Batch 35/64 loss: 0.2682079076766968
Batch 36/64 loss: 0.2756838798522949
Batch 37/64 loss: 0.2650870680809021
Batch 38/64 loss: 0.27247464656829834
Batch 39/64 loss: 0.27102935314178467
Batch 40/64 loss: 0.26918137073516846
Batch 41/64 loss: 0.2667790651321411
Batch 42/64 loss: 0.2713329792022705
Batch 43/64 loss: 0.2630136013031006
Batch 44/64 loss: 0.2623974680900574
Batch 45/64 loss: 0.27240586280822754
Batch 46/64 loss: 0.2714691162109375
Batch 47/64 loss: 0.2723901867866516
Batch 48/64 loss: 0.27423858642578125
Batch 49/64 loss: 0.2670513987541199
Batch 50/64 loss: 0.27670931816101074
Batch 51/64 loss: 0.264564573764801
Batch 52/64 loss: 0.2743375301361084
Batch 53/64 loss: 0.2789636254310608
Batch 54/64 loss: 0.2715339660644531
Batch 55/64 loss: 0.27344465255737305
Batch 56/64 loss: 0.27435535192489624
Batch 57/64 loss: 0.2662498950958252
Batch 58/64 loss: 0.2719821333885193
Batch 59/64 loss: 0.26773643493652344
Batch 60/64 loss: 0.2650038003921509
Batch 61/64 loss: 0.2692897915840149
Batch 62/64 loss: 0.26933956146240234
Batch 63/64 loss: 0.27431750297546387
Batch 64/64 loss: 0.2644358277320862
Epoch 139  Train loss: 0.2693151135070651  Val loss: 0.28374887598339227
Saving best model, epoch: 139
Epoch 140
-------------------------------
Batch 1/64 loss: 0.26439911127090454
Batch 2/64 loss: 0.2781020402908325
Batch 3/64 loss: 0.27046555280685425
Batch 4/64 loss: 0.25953924655914307
Batch 5/64 loss: 0.2653611898422241
Batch 6/64 loss: 0.27123379707336426
Batch 7/64 loss: 0.26425206661224365
Batch 8/64 loss: 0.2634541988372803
Batch 9/64 loss: 0.26917457580566406
Batch 10/64 loss: 0.2637110948562622
Batch 11/64 loss: 0.25934112071990967
Batch 12/64 loss: 0.26598381996154785
Batch 13/64 loss: 0.2715235948562622
Batch 14/64 loss: 0.2617950439453125
Batch 15/64 loss: 0.2759056091308594
Batch 16/64 loss: 0.2712206244468689
Batch 17/64 loss: 0.26331162452697754
Batch 18/64 loss: 0.27297574281692505
Batch 19/64 loss: 0.26907873153686523
Batch 20/64 loss: 0.2686516046524048
Batch 21/64 loss: 0.268451988697052
Batch 22/64 loss: 0.26802337169647217
Batch 23/64 loss: 0.2642093896865845
Batch 24/64 loss: 0.26614677906036377
Batch 25/64 loss: 0.27679282426834106
Batch 26/64 loss: 0.27823954820632935
Batch 27/64 loss: 0.26754897832870483
Batch 28/64 loss: 0.27289295196533203
Batch 29/64 loss: 0.27049577236175537
Batch 30/64 loss: 0.2646958827972412
Batch 31/64 loss: 0.26279711723327637
Batch 32/64 loss: 0.27510184049606323
Batch 33/64 loss: 0.2593799829483032
Batch 34/64 loss: 0.27106761932373047
Batch 35/64 loss: 0.26814472675323486
Batch 36/64 loss: 0.2607426643371582
Batch 37/64 loss: 0.2750099301338196
Batch 38/64 loss: 0.27225780487060547
Batch 39/64 loss: 0.26213377714157104
Batch 40/64 loss: 0.27270233631134033
Batch 41/64 loss: 0.27231478691101074
Batch 42/64 loss: 0.26754117012023926
Batch 43/64 loss: 0.27104002237319946
Batch 44/64 loss: 0.2710835933685303
Batch 45/64 loss: 0.2655104398727417
Batch 46/64 loss: 0.2764359712600708
Batch 47/64 loss: 0.2653971314430237
Batch 48/64 loss: 0.2699030041694641
Batch 49/64 loss: 0.27412480115890503
Batch 50/64 loss: 0.2593536376953125
Batch 51/64 loss: 0.2666313648223877
Batch 52/64 loss: 0.27255797386169434
Batch 53/64 loss: 0.26912933588027954
Batch 54/64 loss: 0.26374244689941406
Batch 55/64 loss: 0.2649714946746826
Batch 56/64 loss: 0.26859045028686523
Batch 57/64 loss: 0.2661815881729126
Batch 58/64 loss: 0.26876330375671387
Batch 59/64 loss: 0.2678278684616089
Batch 60/64 loss: 0.2685251235961914
Batch 61/64 loss: 0.27635109424591064
Batch 62/64 loss: 0.2646700143814087
Batch 63/64 loss: 0.27169084548950195
Batch 64/64 loss: 0.2661765217781067
Epoch 140  Train loss: 0.2683652632376727  Val loss: 0.28473914632272884
Epoch 141
-------------------------------
Batch 1/64 loss: 0.26684772968292236
Batch 2/64 loss: 0.26513874530792236
Batch 3/64 loss: 0.26968204975128174
Batch 4/64 loss: 0.25986987352371216
Batch 5/64 loss: 0.27721720933914185
Batch 6/64 loss: 0.26454293727874756
Batch 7/64 loss: 0.2686212658882141
Batch 8/64 loss: 0.2632948160171509
Batch 9/64 loss: 0.2618769407272339
Batch 10/64 loss: 0.26537346839904785
Batch 11/64 loss: 0.2617224454879761
Batch 12/64 loss: 0.26873475313186646
Batch 13/64 loss: 0.27689677476882935
Batch 14/64 loss: 0.26470816135406494
Batch 15/64 loss: 0.2678658366203308
Batch 16/64 loss: 0.26004475355148315
Batch 17/64 loss: 0.2734646201133728
Batch 18/64 loss: 0.2694178819656372
Batch 19/64 loss: 0.27062177658081055
Batch 20/64 loss: 0.2610281705856323
Batch 21/64 loss: 0.26857423782348633
Batch 22/64 loss: 0.2604801058769226
Batch 23/64 loss: 0.27630263566970825
Batch 24/64 loss: 0.2708247900009155
Batch 25/64 loss: 0.2651708722114563
Batch 26/64 loss: 0.2657233476638794
Batch 27/64 loss: 0.2725628614425659
Batch 28/64 loss: 0.27060747146606445
Batch 29/64 loss: 0.2748994827270508
Batch 30/64 loss: 0.2730441689491272
Batch 31/64 loss: 0.2637106776237488
Batch 32/64 loss: 0.27184927463531494
Batch 33/64 loss: 0.2685791850090027
Batch 34/64 loss: 0.26937615871429443
Batch 35/64 loss: 0.2666712999343872
Batch 36/64 loss: 0.27533257007598877
Batch 37/64 loss: 0.264068067073822
Batch 38/64 loss: 0.26755857467651367
Batch 39/64 loss: 0.27429765462875366
Batch 40/64 loss: 0.27242225408554077
Batch 41/64 loss: 0.2660139203071594
Batch 42/64 loss: 0.2767120599746704
Batch 43/64 loss: 0.26891887187957764
Batch 44/64 loss: 0.2661476135253906
Batch 45/64 loss: 0.2665059566497803
Batch 46/64 loss: 0.2606877088546753
Batch 47/64 loss: 0.2680490016937256
Batch 48/64 loss: 0.27207088470458984
Batch 49/64 loss: 0.2626194953918457
Batch 50/64 loss: 0.2681037187576294
Batch 51/64 loss: 0.26804065704345703
Batch 52/64 loss: 0.2659808397293091
Batch 53/64 loss: 0.2689225673675537
Batch 54/64 loss: 0.2652233839035034
Batch 55/64 loss: 0.2717016935348511
Batch 56/64 loss: 0.2691408395767212
Batch 57/64 loss: 0.27137041091918945
Batch 58/64 loss: 0.28306591510772705
Batch 59/64 loss: 0.2661808729171753
Batch 60/64 loss: 0.26752519607543945
Batch 61/64 loss: 0.2683504819869995
Batch 62/64 loss: 0.2724300026893616
Batch 63/64 loss: 0.27354544401168823
Batch 64/64 loss: 0.282781720161438
Epoch 141  Train loss: 0.2686810937582278  Val loss: 0.28592108697006385
Epoch 142
-------------------------------
Batch 1/64 loss: 0.2674611806869507
Batch 2/64 loss: 0.2693248391151428
Batch 3/64 loss: 0.2574193477630615
Batch 4/64 loss: 0.26600849628448486
Batch 5/64 loss: 0.26445436477661133
Batch 6/64 loss: 0.26967453956604004
Batch 7/64 loss: 0.2653123140335083
Batch 8/64 loss: 0.26474714279174805
Batch 9/64 loss: 0.26897358894348145
Batch 10/64 loss: 0.2655491232872009
Batch 11/64 loss: 0.27910566329956055
Batch 12/64 loss: 0.2609666585922241
Batch 13/64 loss: 0.2747936248779297
Batch 14/64 loss: 0.26048600673675537
Batch 15/64 loss: 0.268810510635376
Batch 16/64 loss: 0.2717030644416809
Batch 17/64 loss: 0.2673865556716919
Batch 18/64 loss: 0.26223093271255493
Batch 19/64 loss: 0.2779623866081238
Batch 20/64 loss: 0.2682858109474182
Batch 21/64 loss: 0.26577866077423096
Batch 22/64 loss: 0.27634334564208984
Batch 23/64 loss: 0.26853787899017334
Batch 24/64 loss: 0.25615835189819336
Batch 25/64 loss: 0.27208173274993896
Batch 26/64 loss: 0.27091169357299805
Batch 27/64 loss: 0.2729364037513733
Batch 28/64 loss: 0.2685897946357727
Batch 29/64 loss: 0.2676600217819214
Batch 30/64 loss: 0.2680070400238037
Batch 31/64 loss: 0.27725785970687866
Batch 32/64 loss: 0.27230894565582275
Batch 33/64 loss: 0.27039873600006104
Batch 34/64 loss: 0.26338350772857666
Batch 35/64 loss: 0.264928936958313
Batch 36/64 loss: 0.27844464778900146
Batch 37/64 loss: 0.2600070834159851
Batch 38/64 loss: 0.26799607276916504
Batch 39/64 loss: 0.26316094398498535
Batch 40/64 loss: 0.28105103969573975
Batch 41/64 loss: 0.26933038234710693
Batch 42/64 loss: 0.2714107036590576
Batch 43/64 loss: 0.26652008295059204
Batch 44/64 loss: 0.2598590850830078
Batch 45/64 loss: 0.2704240083694458
Batch 46/64 loss: 0.2721707820892334
Batch 47/64 loss: 0.2650226950645447
Batch 48/64 loss: 0.26970911026000977
Batch 49/64 loss: 0.2723006010055542
Batch 50/64 loss: 0.26702284812927246
Batch 51/64 loss: 0.2710276246070862
Batch 52/64 loss: 0.2650938034057617
Batch 53/64 loss: 0.26611924171447754
Batch 54/64 loss: 0.26747429370880127
Batch 55/64 loss: 0.2548027038574219
Batch 56/64 loss: 0.2702840566635132
Batch 57/64 loss: 0.2695256471633911
Batch 58/64 loss: 0.2687947750091553
Batch 59/64 loss: 0.2712920904159546
Batch 60/64 loss: 0.25902247428894043
Batch 61/64 loss: 0.27041423320770264
Batch 62/64 loss: 0.2711751461029053
Batch 63/64 loss: 0.2582307457923889
Batch 64/64 loss: 0.26208794116973877
Epoch 142  Train loss: 0.2679245794520659  Val loss: 0.2847967160116766
Epoch 143
-------------------------------
Batch 1/64 loss: 0.26654934883117676
Batch 2/64 loss: 0.2727547287940979
Batch 3/64 loss: 0.26754361391067505
Batch 4/64 loss: 0.26455068588256836
Batch 5/64 loss: 0.27299821376800537
Batch 6/64 loss: 0.26519858837127686
Batch 7/64 loss: 0.26680588722229004
Batch 8/64 loss: 0.26196396350860596
Batch 9/64 loss: 0.27489960193634033
Batch 10/64 loss: 0.2673717737197876
Batch 11/64 loss: 0.2655630111694336
Batch 12/64 loss: 0.2598928213119507
Batch 13/64 loss: 0.2706313133239746
Batch 14/64 loss: 0.2661059498786926
Batch 15/64 loss: 0.26805126667022705
Batch 16/64 loss: 0.2719067335128784
Batch 17/64 loss: 0.26169252395629883
Batch 18/64 loss: 0.2668663263320923
Batch 19/64 loss: 0.26658880710601807
Batch 20/64 loss: 0.2635064125061035
Batch 21/64 loss: 0.27204298973083496
Batch 22/64 loss: 0.2642284631729126
Batch 23/64 loss: 0.26983922719955444
Batch 24/64 loss: 0.2669186592102051
Batch 25/64 loss: 0.27170658111572266
Batch 26/64 loss: 0.26643913984298706
Batch 27/64 loss: 0.27564096450805664
Batch 28/64 loss: 0.2666109800338745
Batch 29/64 loss: 0.270698606967926
Batch 30/64 loss: 0.26666259765625
Batch 31/64 loss: 0.2701796293258667
Batch 32/64 loss: 0.2726312279701233
Batch 33/64 loss: 0.2692532539367676
Batch 34/64 loss: 0.27374953031539917
Batch 35/64 loss: 0.2631502151489258
Batch 36/64 loss: 0.27187395095825195
Batch 37/64 loss: 0.2609657049179077
Batch 38/64 loss: 0.26655125617980957
Batch 39/64 loss: 0.26196396350860596
Batch 40/64 loss: 0.26797395944595337
Batch 41/64 loss: 0.27918386459350586
Batch 42/64 loss: 0.2678478956222534
Batch 43/64 loss: 0.2712517976760864
Batch 44/64 loss: 0.2704688310623169
Batch 45/64 loss: 0.2679833173751831
Batch 46/64 loss: 0.26695704460144043
Batch 47/64 loss: 0.25902289152145386
Batch 48/64 loss: 0.26002490520477295
Batch 49/64 loss: 0.2656468152999878
Batch 50/64 loss: 0.26942896842956543
Batch 51/64 loss: 0.27253258228302
Batch 52/64 loss: 0.272271990776062
Batch 53/64 loss: 0.25994598865509033
Batch 54/64 loss: 0.26270467042922974
Batch 55/64 loss: 0.2693510055541992
Batch 56/64 loss: 0.26454412937164307
Batch 57/64 loss: 0.26986610889434814
Batch 58/64 loss: 0.2715240716934204
Batch 59/64 loss: 0.26876699924468994
Batch 60/64 loss: 0.2671389579772949
Batch 61/64 loss: 0.25891733169555664
Batch 62/64 loss: 0.2741880416870117
Batch 63/64 loss: 0.2696835398674011
Batch 64/64 loss: 0.275851845741272
Epoch 143  Train loss: 0.2678692252028222  Val loss: 0.2854810244438984
Epoch 144
-------------------------------
Batch 1/64 loss: 0.2728039026260376
Batch 2/64 loss: 0.25962865352630615
Batch 3/64 loss: 0.2560117244720459
Batch 4/64 loss: 0.2700338363647461
Batch 5/64 loss: 0.2636392116546631
Batch 6/64 loss: 0.2679871916770935
Batch 7/64 loss: 0.2696378231048584
Batch 8/64 loss: 0.27087485790252686
Batch 9/64 loss: 0.2622935175895691
Batch 10/64 loss: 0.25912415981292725
Batch 11/64 loss: 0.2681598663330078
Batch 12/64 loss: 0.26367366313934326
Batch 13/64 loss: 0.2680761218070984
Batch 14/64 loss: 0.2642238140106201
Batch 15/64 loss: 0.2576131820678711
Batch 16/64 loss: 0.2616550922393799
Batch 17/64 loss: 0.2692597508430481
Batch 18/64 loss: 0.26331329345703125
Batch 19/64 loss: 0.2809867858886719
Batch 20/64 loss: 0.2670867443084717
Batch 21/64 loss: 0.27048778533935547
Batch 22/64 loss: 0.26845782995224
Batch 23/64 loss: 0.26191163063049316
Batch 24/64 loss: 0.2682660222053528
Batch 25/64 loss: 0.2757387161254883
Batch 26/64 loss: 0.2683144807815552
Batch 27/64 loss: 0.2629636526107788
Batch 28/64 loss: 0.26343274116516113
Batch 29/64 loss: 0.26942533254623413
Batch 30/64 loss: 0.27511441707611084
Batch 31/64 loss: 0.2657296061515808
Batch 32/64 loss: 0.2632664442062378
Batch 33/64 loss: 0.26423710584640503
Batch 34/64 loss: 0.253947377204895
Batch 35/64 loss: 0.27035772800445557
Batch 36/64 loss: 0.27156513929367065
Batch 37/64 loss: 0.2688251733779907
Batch 38/64 loss: 0.267375111579895
Batch 39/64 loss: 0.2655031681060791
Batch 40/64 loss: 0.2661781311035156
Batch 41/64 loss: 0.270078182220459
Batch 42/64 loss: 0.27025526762008667
Batch 43/64 loss: 0.27333855628967285
Batch 44/64 loss: 0.26606500148773193
Batch 45/64 loss: 0.26482272148132324
Batch 46/64 loss: 0.2741813659667969
Batch 47/64 loss: 0.2607261538505554
Batch 48/64 loss: 0.2655365467071533
Batch 49/64 loss: 0.26325082778930664
Batch 50/64 loss: 0.2670140266418457
Batch 51/64 loss: 0.2649991512298584
Batch 52/64 loss: 0.267245888710022
Batch 53/64 loss: 0.27382856607437134
Batch 54/64 loss: 0.26691877841949463
Batch 55/64 loss: 0.2657661437988281
Batch 56/64 loss: 0.27047955989837646
Batch 57/64 loss: 0.2644959092140198
Batch 58/64 loss: 0.2679879069328308
Batch 59/64 loss: 0.2642282247543335
Batch 60/64 loss: 0.2683097720146179
Batch 61/64 loss: 0.276905357837677
Batch 62/64 loss: 0.26806867122650146
Batch 63/64 loss: 0.2642322778701782
Batch 64/64 loss: 0.2627239227294922
Epoch 144  Train loss: 0.2668699386073094  Val loss: 0.28453441338031155
Epoch 145
-------------------------------
Batch 1/64 loss: 0.263782799243927
Batch 2/64 loss: 0.25923097133636475
Batch 3/64 loss: 0.2729618549346924
Batch 4/64 loss: 0.26567232608795166
Batch 5/64 loss: 0.2613757848739624
Batch 6/64 loss: 0.267048716545105
Batch 7/64 loss: 0.26126527786254883
Batch 8/64 loss: 0.2654087543487549
Batch 9/64 loss: 0.2603187561035156
Batch 10/64 loss: 0.26439690589904785
Batch 11/64 loss: 0.27386558055877686
Batch 12/64 loss: 0.27106404304504395
Batch 13/64 loss: 0.2615498900413513
Batch 14/64 loss: 0.2711336016654968
Batch 15/64 loss: 0.2698560953140259
Batch 16/64 loss: 0.25998353958129883
Batch 17/64 loss: 0.2670566439628601
Batch 18/64 loss: 0.2633415460586548
Batch 19/64 loss: 0.26120448112487793
Batch 20/64 loss: 0.26991939544677734
Batch 21/64 loss: 0.2617819309234619
Batch 22/64 loss: 0.26516371965408325
Batch 23/64 loss: 0.2598276734352112
Batch 24/64 loss: 0.2632710337638855
Batch 25/64 loss: 0.2758316993713379
Batch 26/64 loss: 0.27048730850219727
Batch 27/64 loss: 0.2748534083366394
Batch 28/64 loss: 0.26313579082489014
Batch 29/64 loss: 0.2650107145309448
Batch 30/64 loss: 0.266049861907959
Batch 31/64 loss: 0.2714220881462097
Batch 32/64 loss: 0.27128106355667114
Batch 33/64 loss: 0.2696268558502197
Batch 34/64 loss: 0.26583051681518555
Batch 35/64 loss: 0.26730072498321533
Batch 36/64 loss: 0.278547465801239
Batch 37/64 loss: 0.2651218771934509
Batch 38/64 loss: 0.27352190017700195
Batch 39/64 loss: 0.2731785774230957
Batch 40/64 loss: 0.2760138511657715
Batch 41/64 loss: 0.26293790340423584
Batch 42/64 loss: 0.27010613679885864
Batch 43/64 loss: 0.2636420726776123
Batch 44/64 loss: 0.26898884773254395
Batch 45/64 loss: 0.26821649074554443
Batch 46/64 loss: 0.26603198051452637
Batch 47/64 loss: 0.2638666033744812
Batch 48/64 loss: 0.26224416494369507
Batch 49/64 loss: 0.26080334186553955
Batch 50/64 loss: 0.2601448893547058
Batch 51/64 loss: 0.26744723320007324
Batch 52/64 loss: 0.26748454570770264
Batch 53/64 loss: 0.27122962474823
Batch 54/64 loss: 0.26550281047821045
Batch 55/64 loss: 0.26799148321151733
Batch 56/64 loss: 0.2633710503578186
Batch 57/64 loss: 0.26147162914276123
Batch 58/64 loss: 0.2799801230430603
Batch 59/64 loss: 0.26690274477005005
Batch 60/64 loss: 0.26513737440109253
Batch 61/64 loss: 0.2646867036819458
Batch 62/64 loss: 0.26851701736450195
Batch 63/64 loss: 0.26868945360183716
Batch 64/64 loss: 0.2712293863296509
Epoch 145  Train loss: 0.26692566731396844  Val loss: 0.2843828993974273
Epoch 146
-------------------------------
Batch 1/64 loss: 0.2620273232460022
Batch 2/64 loss: 0.2717711925506592
Batch 3/64 loss: 0.2675306797027588
Batch 4/64 loss: 0.2687605619430542
Batch 5/64 loss: 0.2724485993385315
Batch 6/64 loss: 0.2622753977775574
Batch 7/64 loss: 0.27508604526519775
Batch 8/64 loss: 0.26740193367004395
Batch 9/64 loss: 0.259319543838501
Batch 10/64 loss: 0.26936018466949463
Batch 11/64 loss: 0.2682797908782959
Batch 12/64 loss: 0.27307528257369995
Batch 13/64 loss: 0.2770695686340332
Batch 14/64 loss: 0.26747703552246094
Batch 15/64 loss: 0.2579624056816101
Batch 16/64 loss: 0.27349239587783813
Batch 17/64 loss: 0.2760673761367798
Batch 18/64 loss: 0.2594946622848511
Batch 19/64 loss: 0.26930058002471924
Batch 20/64 loss: 0.2672138810157776
Batch 21/64 loss: 0.26507681608200073
Batch 22/64 loss: 0.26470667123794556
Batch 23/64 loss: 0.26540887355804443
Batch 24/64 loss: 0.2644383907318115
Batch 25/64 loss: 0.27357780933380127
Batch 26/64 loss: 0.25991225242614746
Batch 27/64 loss: 0.2735937237739563
Batch 28/64 loss: 0.2599935531616211
Batch 29/64 loss: 0.27653568983078003
Batch 30/64 loss: 0.26510411500930786
Batch 31/64 loss: 0.2683503031730652
Batch 32/64 loss: 0.2615699768066406
Batch 33/64 loss: 0.26883524656295776
Batch 34/64 loss: 0.26394057273864746
Batch 35/64 loss: 0.2619625926017761
Batch 36/64 loss: 0.2752871513366699
Batch 37/64 loss: 0.25922369956970215
Batch 38/64 loss: 0.2657577395439148
Batch 39/64 loss: 0.26446664333343506
Batch 40/64 loss: 0.2621515989303589
Batch 41/64 loss: 0.2659512758255005
Batch 42/64 loss: 0.26931488513946533
Batch 43/64 loss: 0.26644670963287354
Batch 44/64 loss: 0.2644420862197876
Batch 45/64 loss: 0.25850439071655273
Batch 46/64 loss: 0.2669694423675537
Batch 47/64 loss: 0.2680235505104065
Batch 48/64 loss: 0.268655002117157
Batch 49/64 loss: 0.2712804079055786
Batch 50/64 loss: 0.2637585401535034
Batch 51/64 loss: 0.26965534687042236
Batch 52/64 loss: 0.2703445553779602
Batch 53/64 loss: 0.25757676362991333
Batch 54/64 loss: 0.26126962900161743
Batch 55/64 loss: 0.2642102837562561
Batch 56/64 loss: 0.2695235013961792
Batch 57/64 loss: 0.2713767886161804
Batch 58/64 loss: 0.2668238878250122
Batch 59/64 loss: 0.2626270055770874
Batch 60/64 loss: 0.27489542961120605
Batch 61/64 loss: 0.26600056886672974
Batch 62/64 loss: 0.27173101902008057
Batch 63/64 loss: 0.26150357723236084
Batch 64/64 loss: 0.26527613401412964
Epoch 146  Train loss: 0.2669043075804617  Val loss: 0.2837857796564135
Epoch 147
-------------------------------
Batch 1/64 loss: 0.2609558701515198
Batch 2/64 loss: 0.26897478103637695
Batch 3/64 loss: 0.26613426208496094
Batch 4/64 loss: 0.2645186185836792
Batch 5/64 loss: 0.25955796241760254
Batch 6/64 loss: 0.2628673315048218
Batch 7/64 loss: 0.26752591133117676
Batch 8/64 loss: 0.2698761224746704
Batch 9/64 loss: 0.26551008224487305
Batch 10/64 loss: 0.2750200629234314
Batch 11/64 loss: 0.2662454843521118
Batch 12/64 loss: 0.2646057605743408
Batch 13/64 loss: 0.2703721523284912
Batch 14/64 loss: 0.2725621461868286
Batch 15/64 loss: 0.26692748069763184
Batch 16/64 loss: 0.2631368637084961
Batch 17/64 loss: 0.2670491933822632
Batch 18/64 loss: 0.26803791522979736
Batch 19/64 loss: 0.2605799436569214
Batch 20/64 loss: 0.2740740180015564
Batch 21/64 loss: 0.26365625858306885
Batch 22/64 loss: 0.2627488374710083
Batch 23/64 loss: 0.2662665843963623
Batch 24/64 loss: 0.26117241382598877
Batch 25/64 loss: 0.2711595892906189
Batch 26/64 loss: 0.2631959915161133
Batch 27/64 loss: 0.25965237617492676
Batch 28/64 loss: 0.27488017082214355
Batch 29/64 loss: 0.2637060880661011
Batch 30/64 loss: 0.2569158673286438
Batch 31/64 loss: 0.26952463388442993
Batch 32/64 loss: 0.26359987258911133
Batch 33/64 loss: 0.2685290575027466
Batch 34/64 loss: 0.28155672550201416
Batch 35/64 loss: 0.27025628089904785
Batch 36/64 loss: 0.26090002059936523
Batch 37/64 loss: 0.2584247589111328
Batch 38/64 loss: 0.26532256603240967
Batch 39/64 loss: 0.26658332347869873
Batch 40/64 loss: 0.2628369927406311
Batch 41/64 loss: 0.2592703700065613
Batch 42/64 loss: 0.2658526301383972
Batch 43/64 loss: 0.2621394395828247
Batch 44/64 loss: 0.25710582733154297
Batch 45/64 loss: 0.27480483055114746
Batch 46/64 loss: 0.26147615909576416
Batch 47/64 loss: 0.2673550844192505
Batch 48/64 loss: 0.2640256881713867
Batch 49/64 loss: 0.2682533264160156
Batch 50/64 loss: 0.2669972777366638
Batch 51/64 loss: 0.2628297805786133
Batch 52/64 loss: 0.2620701789855957
Batch 53/64 loss: 0.2756798267364502
Batch 54/64 loss: 0.2706059217453003
Batch 55/64 loss: 0.26709818840026855
Batch 56/64 loss: 0.2614060640335083
Batch 57/64 loss: 0.26724374294281006
Batch 58/64 loss: 0.26477575302124023
Batch 59/64 loss: 0.2620689868927002
Batch 60/64 loss: 0.264018177986145
Batch 61/64 loss: 0.27311813831329346
Batch 62/64 loss: 0.2621554732322693
Batch 63/64 loss: 0.26701658964157104
Batch 64/64 loss: 0.2802746295928955
Epoch 147  Train loss: 0.2660861772649428  Val loss: 0.28449776348789124
Epoch 148
-------------------------------
Batch 1/64 loss: 0.2656666040420532
Batch 2/64 loss: 0.2662004232406616
Batch 3/64 loss: 0.2662087678909302
Batch 4/64 loss: 0.27170097827911377
Batch 5/64 loss: 0.25761330127716064
Batch 6/64 loss: 0.25506818294525146
Batch 7/64 loss: 0.26354551315307617
Batch 8/64 loss: 0.2668841481208801
Batch 9/64 loss: 0.264255166053772
Batch 10/64 loss: 0.26098334789276123
Batch 11/64 loss: 0.2701479196548462
Batch 12/64 loss: 0.2649686336517334
Batch 13/64 loss: 0.2677820920944214
Batch 14/64 loss: 0.2599295377731323
Batch 15/64 loss: 0.26784586906433105
Batch 16/64 loss: 0.2718903422355652
Batch 17/64 loss: 0.26812148094177246
Batch 18/64 loss: 0.2668203115463257
Batch 19/64 loss: 0.2661740779876709
Batch 20/64 loss: 0.25978994369506836
Batch 21/64 loss: 0.2711935043334961
Batch 22/64 loss: 0.26057112216949463
Batch 23/64 loss: 0.26890313625335693
Batch 24/64 loss: 0.25894689559936523
Batch 25/64 loss: 0.25761842727661133
Batch 26/64 loss: 0.2619565725326538
Batch 27/64 loss: 0.26664137840270996
Batch 28/64 loss: 0.27149683237075806
Batch 29/64 loss: 0.2581712007522583
Batch 30/64 loss: 0.26505064964294434
Batch 31/64 loss: 0.2663087248802185
Batch 32/64 loss: 0.27120816707611084
Batch 33/64 loss: 0.2678787112236023
Batch 34/64 loss: 0.25938987731933594
Batch 35/64 loss: 0.2604713439941406
Batch 36/64 loss: 0.2689751386642456
Batch 37/64 loss: 0.2660123109817505
Batch 38/64 loss: 0.2638168931007385
Batch 39/64 loss: 0.26618289947509766
Batch 40/64 loss: 0.2658551335334778
Batch 41/64 loss: 0.2649754285812378
Batch 42/64 loss: 0.27184754610061646
Batch 43/64 loss: 0.26173561811447144
Batch 44/64 loss: 0.27958357334136963
Batch 45/64 loss: 0.26768434047698975
Batch 46/64 loss: 0.26507216691970825
Batch 47/64 loss: 0.27065062522888184
Batch 48/64 loss: 0.2650628685951233
Batch 49/64 loss: 0.26724326610565186
Batch 50/64 loss: 0.27068984508514404
Batch 51/64 loss: 0.2671756148338318
Batch 52/64 loss: 0.27061736583709717
Batch 53/64 loss: 0.26316773891448975
Batch 54/64 loss: 0.2694861888885498
Batch 55/64 loss: 0.2626166343688965
Batch 56/64 loss: 0.2636685371398926
Batch 57/64 loss: 0.2690924406051636
Batch 58/64 loss: 0.2633429765701294
Batch 59/64 loss: 0.26770925521850586
Batch 60/64 loss: 0.26457929611206055
Batch 61/64 loss: 0.2718757390975952
Batch 62/64 loss: 0.2719910144805908
Batch 63/64 loss: 0.26016801595687866
Batch 64/64 loss: 0.27004319429397583
Epoch 148  Train loss: 0.26589512240652946  Val loss: 0.2854108959948484
Epoch 149
-------------------------------
Batch 1/64 loss: 0.2666921615600586
Batch 2/64 loss: 0.2738853693008423
Batch 3/64 loss: 0.2644643187522888
Batch 4/64 loss: 0.26606374979019165
Batch 5/64 loss: 0.2645230293273926
Batch 6/64 loss: 0.26712310314178467
Batch 7/64 loss: 0.26057302951812744
Batch 8/64 loss: 0.26211369037628174
Batch 9/64 loss: 0.2642976641654968
Batch 10/64 loss: 0.2645533084869385
Batch 11/64 loss: 0.2653409242630005
Batch 12/64 loss: 0.27489686012268066
Batch 13/64 loss: 0.2759901285171509
Batch 14/64 loss: 0.2699697017669678
Batch 15/64 loss: 0.27003443241119385
Batch 16/64 loss: 0.26275575160980225
Batch 17/64 loss: 0.28413712978363037
Batch 18/64 loss: 0.26345139741897583
Batch 19/64 loss: 0.2579044699668884
Batch 20/64 loss: 0.26568353176116943
Batch 21/64 loss: 0.2575199007987976
Batch 22/64 loss: 0.2799340486526489
Batch 23/64 loss: 0.2591811418533325
Batch 24/64 loss: 0.27412688732147217
Batch 25/64 loss: 0.26160818338394165
Batch 26/64 loss: 0.26751822233200073
Batch 27/64 loss: 0.2722017765045166
Batch 28/64 loss: 0.2638446092605591
Batch 29/64 loss: 0.2665081024169922
Batch 30/64 loss: 0.2673690915107727
Batch 31/64 loss: 0.26372039318084717
Batch 32/64 loss: 0.2618839740753174
Batch 33/64 loss: 0.2669616937637329
Batch 34/64 loss: 0.26681071519851685
Batch 35/64 loss: 0.2610759139060974
Batch 36/64 loss: 0.2714822292327881
Batch 37/64 loss: 0.2695610523223877
Batch 38/64 loss: 0.2626968026161194
Batch 39/64 loss: 0.2684389352798462
Batch 40/64 loss: 0.25299060344696045
Batch 41/64 loss: 0.2657610774040222
Batch 42/64 loss: 0.25386786460876465
Batch 43/64 loss: 0.26660144329071045
Batch 44/64 loss: 0.2628962993621826
Batch 45/64 loss: 0.26767754554748535
Batch 46/64 loss: 0.2700982093811035
Batch 47/64 loss: 0.26354753971099854
Batch 48/64 loss: 0.26631176471710205
Batch 49/64 loss: 0.26188403367996216
Batch 50/64 loss: 0.26277005672454834
Batch 51/64 loss: 0.2630220651626587
Batch 52/64 loss: 0.265718936920166
Batch 53/64 loss: 0.26592350006103516
Batch 54/64 loss: 0.266650915145874
Batch 55/64 loss: 0.2683642506599426
Batch 56/64 loss: 0.2629581689834595
Batch 57/64 loss: 0.2659893035888672
Batch 58/64 loss: 0.2557497024536133
Batch 59/64 loss: 0.2663906216621399
Batch 60/64 loss: 0.258911669254303
Batch 61/64 loss: 0.2628632187843323
Batch 62/64 loss: 0.25998497009277344
Batch 63/64 loss: 0.2655003070831299
Batch 64/64 loss: 0.26053762435913086
Epoch 149  Train loss: 0.2654860346925025  Val loss: 0.28195564587091665
Saving best model, epoch: 149
Epoch 150
-------------------------------
Batch 1/64 loss: 0.27194470167160034
Batch 2/64 loss: 0.2622438073158264
Batch 3/64 loss: 0.26414811611175537
Batch 4/64 loss: 0.263963520526886
Batch 5/64 loss: 0.2712056040763855
Batch 6/64 loss: 0.26490044593811035
Batch 7/64 loss: 0.268121600151062
Batch 8/64 loss: 0.2589004635810852
Batch 9/64 loss: 0.26825225353240967
Batch 10/64 loss: 0.26119375228881836
Batch 11/64 loss: 0.26479125022888184
Batch 12/64 loss: 0.2615015506744385
Batch 13/64 loss: 0.26292479038238525
Batch 14/64 loss: 0.26478004455566406
Batch 15/64 loss: 0.26794105768203735
Batch 16/64 loss: 0.2620422840118408
Batch 17/64 loss: 0.2739495038986206
Batch 18/64 loss: 0.2693476676940918
Batch 19/64 loss: 0.2668284773826599
Batch 20/64 loss: 0.2587665319442749
Batch 21/64 loss: 0.26202893257141113
Batch 22/64 loss: 0.2625054717063904
Batch 23/64 loss: 0.26434051990509033
Batch 24/64 loss: 0.27261412143707275
Batch 25/64 loss: 0.2647855281829834
Batch 26/64 loss: 0.2674514651298523
Batch 27/64 loss: 0.26806193590164185
Batch 28/64 loss: 0.2615455389022827
Batch 29/64 loss: 0.2628694772720337
Batch 30/64 loss: 0.2601892948150635
Batch 31/64 loss: 0.25621217489242554
Batch 32/64 loss: 0.26960062980651855
Batch 33/64 loss: 0.27222347259521484
Batch 34/64 loss: 0.2663745880126953
Batch 35/64 loss: 0.26758164167404175
Batch 36/64 loss: 0.2686668634414673
Batch 37/64 loss: 0.2766658067703247
Batch 38/64 loss: 0.2665325403213501
Batch 39/64 loss: 0.2626523971557617
Batch 40/64 loss: 0.27051758766174316
Batch 41/64 loss: 0.2693694829940796
Batch 42/64 loss: 0.2575916647911072
Batch 43/64 loss: 0.2666372060775757
Batch 44/64 loss: 0.26467615365982056
Batch 45/64 loss: 0.26062166690826416
Batch 46/64 loss: 0.26055073738098145
Batch 47/64 loss: 0.2584458589553833
Batch 48/64 loss: 0.26622259616851807
Batch 49/64 loss: 0.2545793652534485
Batch 50/64 loss: 0.26106834411621094
Batch 51/64 loss: 0.2761036157608032
Batch 52/64 loss: 0.2654871940612793
Batch 53/64 loss: 0.274796724319458
Batch 54/64 loss: 0.26610076427459717
Batch 55/64 loss: 0.2685438394546509
Batch 56/64 loss: 0.27086514234542847
Batch 57/64 loss: 0.2653433084487915
Batch 58/64 loss: 0.26143133640289307
Batch 59/64 loss: 0.2575364112854004
Batch 60/64 loss: 0.2793961763381958
Batch 61/64 loss: 0.26239633560180664
Batch 62/64 loss: 0.262534499168396
Batch 63/64 loss: 0.26713883876800537
Batch 64/64 loss: 0.2699465751647949
Epoch 150  Train loss: 0.2655853271484375  Val loss: 0.2829776869197072
Epoch 151
-------------------------------
Batch 1/64 loss: 0.2686471939086914
Batch 2/64 loss: 0.26509857177734375
Batch 3/64 loss: 0.26917147636413574
Batch 4/64 loss: 0.26668083667755127
Batch 5/64 loss: 0.26864194869995117
Batch 6/64 loss: 0.2617838382720947
Batch 7/64 loss: 0.26318472623825073
Batch 8/64 loss: 0.2574044466018677
Batch 9/64 loss: 0.26765120029449463
Batch 10/64 loss: 0.2673758268356323
Batch 11/64 loss: 0.26692718267440796
Batch 12/64 loss: 0.2770451307296753
Batch 13/64 loss: 0.2592123746871948
Batch 14/64 loss: 0.2661731243133545
Batch 15/64 loss: 0.2640507221221924
Batch 16/64 loss: 0.2604467272758484
Batch 17/64 loss: 0.2601346969604492
Batch 18/64 loss: 0.2605840563774109
Batch 19/64 loss: 0.26374274492263794
Batch 20/64 loss: 0.2631251811981201
Batch 21/64 loss: 0.26388657093048096
Batch 22/64 loss: 0.2651439309120178
Batch 23/64 loss: 0.2614341378211975
Batch 24/64 loss: 0.26105737686157227
Batch 25/64 loss: 0.2605934143066406
Batch 26/64 loss: 0.264601469039917
Batch 27/64 loss: 0.26392972469329834
Batch 28/64 loss: 0.26514554023742676
Batch 29/64 loss: 0.2641456127166748
Batch 30/64 loss: 0.2628974914550781
Batch 31/64 loss: 0.2645491361618042
Batch 32/64 loss: 0.2572307586669922
Batch 33/64 loss: 0.27381056547164917
Batch 34/64 loss: 0.2565942406654358
Batch 35/64 loss: 0.26363205909729004
Batch 36/64 loss: 0.2640054225921631
Batch 37/64 loss: 0.263203501701355
Batch 38/64 loss: 0.2616152763366699
Batch 39/64 loss: 0.26057082414627075
Batch 40/64 loss: 0.26883751153945923
Batch 41/64 loss: 0.2579854726791382
Batch 42/64 loss: 0.2749589681625366
Batch 43/64 loss: 0.2765064835548401
Batch 44/64 loss: 0.2680521011352539
Batch 45/64 loss: 0.2611382007598877
Batch 46/64 loss: 0.25277912616729736
Batch 47/64 loss: 0.2641029357910156
Batch 48/64 loss: 0.2704395055770874
Batch 49/64 loss: 0.260111927986145
Batch 50/64 loss: 0.2781386971473694
Batch 51/64 loss: 0.27396291494369507
Batch 52/64 loss: 0.2656497359275818
Batch 53/64 loss: 0.26086509227752686
Batch 54/64 loss: 0.25675344467163086
Batch 55/64 loss: 0.26680463552474976
Batch 56/64 loss: 0.2737387418746948
Batch 57/64 loss: 0.26377081871032715
Batch 58/64 loss: 0.27448558807373047
Batch 59/64 loss: 0.2602975368499756
Batch 60/64 loss: 0.2626321315765381
Batch 61/64 loss: 0.2691366672515869
Batch 62/64 loss: 0.2598609924316406
Batch 63/64 loss: 0.2779839038848877
Batch 64/64 loss: 0.25952261686325073
Epoch 151  Train loss: 0.26492179071202  Val loss: 0.28253811454445227
Epoch 152
-------------------------------
Batch 1/64 loss: 0.26139116287231445
Batch 2/64 loss: 0.2584449052810669
Batch 3/64 loss: 0.2561437487602234
Batch 4/64 loss: 0.2677590847015381
Batch 5/64 loss: 0.26926958560943604
Batch 6/64 loss: 0.2608344554901123
Batch 7/64 loss: 0.25851255655288696
Batch 8/64 loss: 0.25703179836273193
Batch 9/64 loss: 0.26399528980255127
Batch 10/64 loss: 0.2668565511703491
Batch 11/64 loss: 0.2650657892227173
Batch 12/64 loss: 0.2704448103904724
Batch 13/64 loss: 0.2583709955215454
Batch 14/64 loss: 0.2553470730781555
Batch 15/64 loss: 0.2634885311126709
Batch 16/64 loss: 0.2660553455352783
Batch 17/64 loss: 0.25975894927978516
Batch 18/64 loss: 0.2645260691642761
Batch 19/64 loss: 0.26199638843536377
Batch 20/64 loss: 0.2535198926925659
Batch 21/64 loss: 0.26602596044540405
Batch 22/64 loss: 0.27027761936187744
Batch 23/64 loss: 0.26035845279693604
Batch 24/64 loss: 0.2644909620285034
Batch 25/64 loss: 0.2700991630554199
Batch 26/64 loss: 0.2670055627822876
Batch 27/64 loss: 0.25322210788726807
Batch 28/64 loss: 0.27083754539489746
Batch 29/64 loss: 0.2737901210784912
Batch 30/64 loss: 0.2557508945465088
Batch 31/64 loss: 0.263879656791687
Batch 32/64 loss: 0.2611438035964966
Batch 33/64 loss: 0.26384007930755615
Batch 34/64 loss: 0.26628661155700684
Batch 35/64 loss: 0.2700517177581787
Batch 36/64 loss: 0.2655690312385559
Batch 37/64 loss: 0.25599050521850586
Batch 38/64 loss: 0.264839768409729
Batch 39/64 loss: 0.27769482135772705
Batch 40/64 loss: 0.25687408447265625
Batch 41/64 loss: 0.2606949210166931
Batch 42/64 loss: 0.26758038997650146
Batch 43/64 loss: 0.26784127950668335
Batch 44/64 loss: 0.26786065101623535
Batch 45/64 loss: 0.264335036277771
Batch 46/64 loss: 0.2689785957336426
Batch 47/64 loss: 0.26386839151382446
Batch 48/64 loss: 0.26474452018737793
Batch 49/64 loss: 0.26245391368865967
Batch 50/64 loss: 0.2641465663909912
Batch 51/64 loss: 0.2623854875564575
Batch 52/64 loss: 0.26919645071029663
Batch 53/64 loss: 0.2723539471626282
Batch 54/64 loss: 0.26654791831970215
Batch 55/64 loss: 0.2772153615951538
Batch 56/64 loss: 0.2775609493255615
Batch 57/64 loss: 0.27676379680633545
Batch 58/64 loss: 0.2650102376937866
Batch 59/64 loss: 0.2663857340812683
Batch 60/64 loss: 0.26132702827453613
Batch 61/64 loss: 0.26180344820022583
Batch 62/64 loss: 0.25919127464294434
Batch 63/64 loss: 0.25977516174316406
Batch 64/64 loss: 0.26325541734695435
Epoch 152  Train loss: 0.2645067306125865  Val loss: 0.28285187093662645
Epoch 153
-------------------------------
Batch 1/64 loss: 0.2590416669845581
Batch 2/64 loss: 0.2741812467575073
Batch 3/64 loss: 0.25912946462631226
Batch 4/64 loss: 0.2792621850967407
Batch 5/64 loss: 0.25162410736083984
Batch 6/64 loss: 0.26630979776382446
Batch 7/64 loss: 0.25818443298339844
Batch 8/64 loss: 0.2642357349395752
Batch 9/64 loss: 0.25747746229171753
Batch 10/64 loss: 0.25922691822052
Batch 11/64 loss: 0.2681703567504883
Batch 12/64 loss: 0.26644009351730347
Batch 13/64 loss: 0.2631712555885315
Batch 14/64 loss: 0.2713962197303772
Batch 15/64 loss: 0.26426219940185547
Batch 16/64 loss: 0.26812660694122314
Batch 17/64 loss: 0.27262061834335327
Batch 18/64 loss: 0.2783951759338379
Batch 19/64 loss: 0.2594938278198242
Batch 20/64 loss: 0.2581995725631714
Batch 21/64 loss: 0.267849326133728
Batch 22/64 loss: 0.27150458097457886
Batch 23/64 loss: 0.2636801600456238
Batch 24/64 loss: 0.2607133984565735
Batch 25/64 loss: 0.2601590156555176
Batch 26/64 loss: 0.2640998363494873
Batch 27/64 loss: 0.26079535484313965
Batch 28/64 loss: 0.2685377597808838
Batch 29/64 loss: 0.2605319023132324
Batch 30/64 loss: 0.2638038396835327
Batch 31/64 loss: 0.2653875946998596
Batch 32/64 loss: 0.2639883756637573
Batch 33/64 loss: 0.26415300369262695
Batch 34/64 loss: 0.27068275213241577
Batch 35/64 loss: 0.2629110813140869
Batch 36/64 loss: 0.2713669538497925
Batch 37/64 loss: 0.2616233825683594
Batch 38/64 loss: 0.26892954111099243
Batch 39/64 loss: 0.2563614249229431
Batch 40/64 loss: 0.267910361289978
Batch 41/64 loss: 0.25783228874206543
Batch 42/64 loss: 0.2626277804374695
Batch 43/64 loss: 0.25409209728240967
Batch 44/64 loss: 0.2652472257614136
Batch 45/64 loss: 0.2644815444946289
Batch 46/64 loss: 0.26944953203201294
Batch 47/64 loss: 0.2707918882369995
Batch 48/64 loss: 0.2526911497116089
Batch 49/64 loss: 0.2546156644821167
Batch 50/64 loss: 0.26042449474334717
Batch 51/64 loss: 0.25919032096862793
Batch 52/64 loss: 0.2547537088394165
Batch 53/64 loss: 0.25868022441864014
Batch 54/64 loss: 0.2563168406486511
Batch 55/64 loss: 0.2596651315689087
Batch 56/64 loss: 0.2572476863861084
Batch 57/64 loss: 0.2676910161972046
Batch 58/64 loss: 0.2694382071495056
Batch 59/64 loss: 0.26843446493148804
Batch 60/64 loss: 0.2684459686279297
Batch 61/64 loss: 0.266055703163147
Batch 62/64 loss: 0.27526426315307617
Batch 63/64 loss: 0.25663650035858154
Batch 64/64 loss: 0.2664297819137573
Epoch 153  Train loss: 0.26390328828026266  Val loss: 0.28169414677570775
Saving best model, epoch: 153
Epoch 154
-------------------------------
Batch 1/64 loss: 0.2582772374153137
Batch 2/64 loss: 0.2617729902267456
Batch 3/64 loss: 0.264013409614563
Batch 4/64 loss: 0.2639737129211426
Batch 5/64 loss: 0.2647700905799866
Batch 6/64 loss: 0.25825148820877075
Batch 7/64 loss: 0.2733726501464844
Batch 8/64 loss: 0.2636016011238098
Batch 9/64 loss: 0.2649313807487488
Batch 10/64 loss: 0.2586511969566345
Batch 11/64 loss: 0.2582475543022156
Batch 12/64 loss: 0.2637985944747925
Batch 13/64 loss: 0.26049214601516724
Batch 14/64 loss: 0.2678789496421814
Batch 15/64 loss: 0.25975626707077026
Batch 16/64 loss: 0.2648158073425293
Batch 17/64 loss: 0.26077568531036377
Batch 18/64 loss: 0.26283586025238037
Batch 19/64 loss: 0.2564692497253418
Batch 20/64 loss: 0.2635105848312378
Batch 21/64 loss: 0.268618643283844
Batch 22/64 loss: 0.26493334770202637
Batch 23/64 loss: 0.2556437849998474
Batch 24/64 loss: 0.26170140504837036
Batch 25/64 loss: 0.26953911781311035
Batch 26/64 loss: 0.2684527635574341
Batch 27/64 loss: 0.25443804264068604
Batch 28/64 loss: 0.26270705461502075
Batch 29/64 loss: 0.25664401054382324
Batch 30/64 loss: 0.25611793994903564
Batch 31/64 loss: 0.26172131299972534
Batch 32/64 loss: 0.26522791385650635
Batch 33/64 loss: 0.27144086360931396
Batch 34/64 loss: 0.2687559127807617
Batch 35/64 loss: 0.2596813440322876
Batch 36/64 loss: 0.26831716299057007
Batch 37/64 loss: 0.26026880741119385
Batch 38/64 loss: 0.2654951214790344
Batch 39/64 loss: 0.2634481191635132
Batch 40/64 loss: 0.2686244249343872
Batch 41/64 loss: 0.2644592523574829
Batch 42/64 loss: 0.2683025002479553
Batch 43/64 loss: 0.2553461194038391
Batch 44/64 loss: 0.2660304307937622
Batch 45/64 loss: 0.25863009691238403
Batch 46/64 loss: 0.26236069202423096
Batch 47/64 loss: 0.2604604959487915
Batch 48/64 loss: 0.2624495029449463
Batch 49/64 loss: 0.26491236686706543
Batch 50/64 loss: 0.2634541392326355
Batch 51/64 loss: 0.2620662450790405
Batch 52/64 loss: 0.2635124921798706
Batch 53/64 loss: 0.2694355249404907
Batch 54/64 loss: 0.2620420455932617
Batch 55/64 loss: 0.25913554430007935
Batch 56/64 loss: 0.2651231288909912
Batch 57/64 loss: 0.2677617073059082
Batch 58/64 loss: 0.26266318559646606
Batch 59/64 loss: 0.2643165588378906
Batch 60/64 loss: 0.26617658138275146
Batch 61/64 loss: 0.2733191251754761
Batch 62/64 loss: 0.2585269808769226
Batch 63/64 loss: 0.25740694999694824
Batch 64/64 loss: 0.2710869312286377
Epoch 154  Train loss: 0.2632655751471426  Val loss: 0.28255544556784873
Epoch 155
-------------------------------
Batch 1/64 loss: 0.26437968015670776
Batch 2/64 loss: 0.2586647868156433
Batch 3/64 loss: 0.26413631439208984
Batch 4/64 loss: 0.2724393606185913
Batch 5/64 loss: 0.2609431743621826
Batch 6/64 loss: 0.2721062898635864
Batch 7/64 loss: 0.2579805254936218
Batch 8/64 loss: 0.259888231754303
Batch 9/64 loss: 0.26241081953048706
Batch 10/64 loss: 0.2606661915779114
Batch 11/64 loss: 0.2711673378944397
Batch 12/64 loss: 0.25845009088516235
Batch 13/64 loss: 0.2589549422264099
Batch 14/64 loss: 0.2630089521408081
Batch 15/64 loss: 0.25937139987945557
Batch 16/64 loss: 0.2717832326889038
Batch 17/64 loss: 0.261832058429718
Batch 18/64 loss: 0.26371127367019653
Batch 19/64 loss: 0.2664300799369812
Batch 20/64 loss: 0.26824456453323364
Batch 21/64 loss: 0.26651543378829956
Batch 22/64 loss: 0.26578348875045776
Batch 23/64 loss: 0.25592923164367676
Batch 24/64 loss: 0.26078230142593384
Batch 25/64 loss: 0.2518540620803833
Batch 26/64 loss: 0.2627198100090027
Batch 27/64 loss: 0.2601613402366638
Batch 28/64 loss: 0.26886892318725586
Batch 29/64 loss: 0.25909221172332764
Batch 30/64 loss: 0.2587556838989258
Batch 31/64 loss: 0.2687380313873291
Batch 32/64 loss: 0.2609971761703491
Batch 33/64 loss: 0.2664108872413635
Batch 34/64 loss: 0.25267237424850464
Batch 35/64 loss: 0.2701380252838135
Batch 36/64 loss: 0.2574780583381653
Batch 37/64 loss: 0.2680816650390625
Batch 38/64 loss: 0.27004677057266235
Batch 39/64 loss: 0.2644736170768738
Batch 40/64 loss: 0.2592860460281372
Batch 41/64 loss: 0.2625308632850647
Batch 42/64 loss: 0.2608187198638916
Batch 43/64 loss: 0.25850915908813477
Batch 44/64 loss: 0.26514822244644165
Batch 45/64 loss: 0.27106761932373047
Batch 46/64 loss: 0.26306092739105225
Batch 47/64 loss: 0.26184046268463135
Batch 48/64 loss: 0.2581180930137634
Batch 49/64 loss: 0.26332640647888184
Batch 50/64 loss: 0.2683352828025818
Batch 51/64 loss: 0.26262909173965454
Batch 52/64 loss: 0.26201021671295166
Batch 53/64 loss: 0.25592607259750366
Batch 54/64 loss: 0.265733003616333
Batch 55/64 loss: 0.2641592025756836
Batch 56/64 loss: 0.26325875520706177
Batch 57/64 loss: 0.26701927185058594
Batch 58/64 loss: 0.2701913118362427
Batch 59/64 loss: 0.2608322501182556
Batch 60/64 loss: 0.26228004693984985
Batch 61/64 loss: 0.25921809673309326
Batch 62/64 loss: 0.26883190870285034
Batch 63/64 loss: 0.2649199962615967
Batch 64/64 loss: 0.26571112871170044
Epoch 155  Train loss: 0.2632847493770076  Val loss: 0.28093806820636763
Saving best model, epoch: 155
Epoch 156
-------------------------------
Batch 1/64 loss: 0.25866907835006714
Batch 2/64 loss: 0.2635289430618286
Batch 3/64 loss: 0.26438724994659424
Batch 4/64 loss: 0.26524555683135986
Batch 5/64 loss: 0.27461832761764526
Batch 6/64 loss: 0.27265799045562744
Batch 7/64 loss: 0.2621426582336426
Batch 8/64 loss: 0.2655595541000366
Batch 9/64 loss: 0.2654993534088135
Batch 10/64 loss: 0.2656899094581604
Batch 11/64 loss: 0.2721226215362549
Batch 12/64 loss: 0.2688117027282715
Batch 13/64 loss: 0.2638286352157593
Batch 14/64 loss: 0.25493818521499634
Batch 15/64 loss: 0.26603996753692627
Batch 16/64 loss: 0.26590120792388916
Batch 17/64 loss: 0.26315027475357056
Batch 18/64 loss: 0.2626364827156067
Batch 19/64 loss: 0.2569494843482971
Batch 20/64 loss: 0.2565826177597046
Batch 21/64 loss: 0.25700175762176514
Batch 22/64 loss: 0.2617088556289673
Batch 23/64 loss: 0.25615233182907104
Batch 24/64 loss: 0.26240694522857666
Batch 25/64 loss: 0.2552694082260132
Batch 26/64 loss: 0.2739773988723755
Batch 27/64 loss: 0.2597818374633789
Batch 28/64 loss: 0.2640124559402466
Batch 29/64 loss: 0.26506364345550537
Batch 30/64 loss: 0.26069992780685425
Batch 31/64 loss: 0.2666809558868408
Batch 32/64 loss: 0.26747286319732666
Batch 33/64 loss: 0.26103293895721436
Batch 34/64 loss: 0.2689563035964966
Batch 35/64 loss: 0.26618266105651855
Batch 36/64 loss: 0.26582813262939453
Batch 37/64 loss: 0.2561214566230774
Batch 38/64 loss: 0.25155019760131836
Batch 39/64 loss: 0.2645895481109619
Batch 40/64 loss: 0.2607458233833313
Batch 41/64 loss: 0.2673451900482178
Batch 42/64 loss: 0.2590543031692505
Batch 43/64 loss: 0.2623862028121948
Batch 44/64 loss: 0.2662564516067505
Batch 45/64 loss: 0.25536441802978516
Batch 46/64 loss: 0.2553720474243164
Batch 47/64 loss: 0.25450146198272705
Batch 48/64 loss: 0.26671159267425537
Batch 49/64 loss: 0.25777530670166016
Batch 50/64 loss: 0.2667904496192932
Batch 51/64 loss: 0.26445215940475464
Batch 52/64 loss: 0.2625120282173157
Batch 53/64 loss: 0.2551536560058594
Batch 54/64 loss: 0.25863462686538696
Batch 55/64 loss: 0.26177167892456055
Batch 56/64 loss: 0.2624698281288147
Batch 57/64 loss: 0.27001190185546875
Batch 58/64 loss: 0.2588158845901489
Batch 59/64 loss: 0.2581373453140259
Batch 60/64 loss: 0.2584560513496399
Batch 61/64 loss: 0.2741471529006958
Batch 62/64 loss: 0.2659531831741333
Batch 63/64 loss: 0.263580858707428
Batch 64/64 loss: 0.2542150020599365
Epoch 156  Train loss: 0.26275310235864974  Val loss: 0.28098309449723496
Epoch 157
-------------------------------
Batch 1/64 loss: 0.2538653612136841
Batch 2/64 loss: 0.2566719651222229
Batch 3/64 loss: 0.2620992660522461
Batch 4/64 loss: 0.26390504837036133
Batch 5/64 loss: 0.26271820068359375
Batch 6/64 loss: 0.251498818397522
Batch 7/64 loss: 0.2581498622894287
Batch 8/64 loss: 0.2673296332359314
Batch 9/64 loss: 0.26410865783691406
Batch 10/64 loss: 0.26932764053344727
Batch 11/64 loss: 0.2611880302429199
Batch 12/64 loss: 0.26603424549102783
Batch 13/64 loss: 0.2649773955345154
Batch 14/64 loss: 0.259518027305603
Batch 15/64 loss: 0.2571644186973572
Batch 16/64 loss: 0.2672354578971863
Batch 17/64 loss: 0.26307082176208496
Batch 18/64 loss: 0.2690020799636841
Batch 19/64 loss: 0.25722241401672363
Batch 20/64 loss: 0.25810474157333374
Batch 21/64 loss: 0.25191575288772583
Batch 22/64 loss: 0.25852298736572266
Batch 23/64 loss: 0.2644009590148926
Batch 24/64 loss: 0.2581004500389099
Batch 25/64 loss: 0.2594754695892334
Batch 26/64 loss: 0.26837730407714844
Batch 27/64 loss: 0.2616034746170044
Batch 28/64 loss: 0.2573312520980835
Batch 29/64 loss: 0.2637360692024231
Batch 30/64 loss: 0.25992846488952637
Batch 31/64 loss: 0.2556290030479431
Batch 32/64 loss: 0.2608758211135864
Batch 33/64 loss: 0.2678120732307434
Batch 34/64 loss: 0.25444769859313965
Batch 35/64 loss: 0.2649874687194824
Batch 36/64 loss: 0.26045823097229004
Batch 37/64 loss: 0.2570706605911255
Batch 38/64 loss: 0.25635814666748047
Batch 39/64 loss: 0.2578466534614563
Batch 40/64 loss: 0.2642931342124939
Batch 41/64 loss: 0.27048444747924805
Batch 42/64 loss: 0.2666788101196289
Batch 43/64 loss: 0.2648346424102783
Batch 44/64 loss: 0.26783138513565063
Batch 45/64 loss: 0.26684993505477905
Batch 46/64 loss: 0.2624152898788452
Batch 47/64 loss: 0.2675902843475342
Batch 48/64 loss: 0.26429468393325806
Batch 49/64 loss: 0.2675884962081909
Batch 50/64 loss: 0.27370309829711914
Batch 51/64 loss: 0.26154619455337524
Batch 52/64 loss: 0.2656864523887634
Batch 53/64 loss: 0.2682511806488037
Batch 54/64 loss: 0.2610360383987427
Batch 55/64 loss: 0.2716175317764282
Batch 56/64 loss: 0.25956618785858154
Batch 57/64 loss: 0.2579067349433899
Batch 58/64 loss: 0.25656282901763916
Batch 59/64 loss: 0.2642509937286377
Batch 60/64 loss: 0.2723846435546875
Batch 61/64 loss: 0.2637512683868408
Batch 62/64 loss: 0.26938915252685547
Batch 63/64 loss: 0.25807952880859375
Batch 64/64 loss: 0.2590665817260742
Epoch 157  Train loss: 0.26247784951153924  Val loss: 0.28135372723910407
Epoch 158
-------------------------------
Batch 1/64 loss: 0.2649194002151489
Batch 2/64 loss: 0.26205742359161377
Batch 3/64 loss: 0.26384174823760986
Batch 4/64 loss: 0.25638675689697266
Batch 5/64 loss: 0.256803035736084
Batch 6/64 loss: 0.2671511173248291
Batch 7/64 loss: 0.2655410170555115
Batch 8/64 loss: 0.2592359185218811
Batch 9/64 loss: 0.25758934020996094
Batch 10/64 loss: 0.2630244493484497
Batch 11/64 loss: 0.26122450828552246
Batch 12/64 loss: 0.26665234565734863
Batch 13/64 loss: 0.2646310329437256
Batch 14/64 loss: 0.2559705972671509
Batch 15/64 loss: 0.26242589950561523
Batch 16/64 loss: 0.2601953148841858
Batch 17/64 loss: 0.25569987297058105
Batch 18/64 loss: 0.26591336727142334
Batch 19/64 loss: 0.2614520788192749
Batch 20/64 loss: 0.2522130012512207
Batch 21/64 loss: 0.2667847275733948
Batch 22/64 loss: 0.25789833068847656
Batch 23/64 loss: 0.25345200300216675
Batch 24/64 loss: 0.25578832626342773
Batch 25/64 loss: 0.2690737247467041
Batch 26/64 loss: 0.2625104784965515
Batch 27/64 loss: 0.2519557476043701
Batch 28/64 loss: 0.2678663730621338
Batch 29/64 loss: 0.25668835639953613
Batch 30/64 loss: 0.2569315433502197
Batch 31/64 loss: 0.2680237889289856
Batch 32/64 loss: 0.2701893448829651
Batch 33/64 loss: 0.26306819915771484
Batch 34/64 loss: 0.2650611996650696
Batch 35/64 loss: 0.2591766119003296
Batch 36/64 loss: 0.25895678997039795
Batch 37/64 loss: 0.26484954357147217
Batch 38/64 loss: 0.2687692642211914
Batch 39/64 loss: 0.2647813558578491
Batch 40/64 loss: 0.2567375898361206
Batch 41/64 loss: 0.26833486557006836
Batch 42/64 loss: 0.254685640335083
Batch 43/64 loss: 0.26726460456848145
Batch 44/64 loss: 0.2631645202636719
Batch 45/64 loss: 0.2748072147369385
Batch 46/64 loss: 0.262770414352417
Batch 47/64 loss: 0.25911998748779297
Batch 48/64 loss: 0.2669183015823364
Batch 49/64 loss: 0.2573128938674927
Batch 50/64 loss: 0.2658182382583618
Batch 51/64 loss: 0.266659140586853
Batch 52/64 loss: 0.2550719976425171
Batch 53/64 loss: 0.2650644779205322
Batch 54/64 loss: 0.27266955375671387
Batch 55/64 loss: 0.2647145390510559
Batch 56/64 loss: 0.2594301700592041
Batch 57/64 loss: 0.26063841581344604
Batch 58/64 loss: 0.26352083683013916
Batch 59/64 loss: 0.2656455636024475
Batch 60/64 loss: 0.2595992088317871
Batch 61/64 loss: 0.2668800950050354
Batch 62/64 loss: 0.2690885066986084
Batch 63/64 loss: 0.2589218020439148
Batch 64/64 loss: 0.2620447874069214
Epoch 158  Train loss: 0.2623706055622475  Val loss: 0.281262121044893
Epoch 159
-------------------------------
Batch 1/64 loss: 0.2565269470214844
Batch 2/64 loss: 0.26192623376846313
Batch 3/64 loss: 0.260050892829895
Batch 4/64 loss: 0.2645375728607178
Batch 5/64 loss: 0.26416754722595215
Batch 6/64 loss: 0.2619408369064331
Batch 7/64 loss: 0.2601548433303833
Batch 8/64 loss: 0.26633763313293457
Batch 9/64 loss: 0.2623419761657715
Batch 10/64 loss: 0.25716203451156616
Batch 11/64 loss: 0.2686729431152344
Batch 12/64 loss: 0.25686514377593994
Batch 13/64 loss: 0.2545454502105713
Batch 14/64 loss: 0.26556694507598877
Batch 15/64 loss: 0.26487088203430176
Batch 16/64 loss: 0.2558637857437134
Batch 17/64 loss: 0.26293712854385376
Batch 18/64 loss: 0.25708508491516113
Batch 19/64 loss: 0.2545125484466553
Batch 20/64 loss: 0.2552937865257263
Batch 21/64 loss: 0.267009973526001
Batch 22/64 loss: 0.26166659593582153
Batch 23/64 loss: 0.2552608251571655
Batch 24/64 loss: 0.2637874484062195
Batch 25/64 loss: 0.25898516178131104
Batch 26/64 loss: 0.2642506957054138
Batch 27/64 loss: 0.2562333345413208
Batch 28/64 loss: 0.261584997177124
Batch 29/64 loss: 0.26653075218200684
Batch 30/64 loss: 0.2569205164909363
Batch 31/64 loss: 0.2620355486869812
Batch 32/64 loss: 0.266751229763031
Batch 33/64 loss: 0.2542320489883423
Batch 34/64 loss: 0.26195037364959717
Batch 35/64 loss: 0.2569117546081543
Batch 36/64 loss: 0.2694879174232483
Batch 37/64 loss: 0.2640058398246765
Batch 38/64 loss: 0.259010910987854
Batch 39/64 loss: 0.25525403022766113
Batch 40/64 loss: 0.2682802081108093
Batch 41/64 loss: 0.2602500915527344
Batch 42/64 loss: 0.26638925075531006
Batch 43/64 loss: 0.25876784324645996
Batch 44/64 loss: 0.26421064138412476
Batch 45/64 loss: 0.270534873008728
Batch 46/64 loss: 0.26477503776550293
Batch 47/64 loss: 0.2592316269874573
Batch 48/64 loss: 0.25858545303344727
Batch 49/64 loss: 0.25442564487457275
Batch 50/64 loss: 0.26808393001556396
Batch 51/64 loss: 0.26352250576019287
Batch 52/64 loss: 0.26070499420166016
Batch 53/64 loss: 0.2520211935043335
Batch 54/64 loss: 0.25582313537597656
Batch 55/64 loss: 0.25750380754470825
Batch 56/64 loss: 0.26709675788879395
Batch 57/64 loss: 0.26494860649108887
Batch 58/64 loss: 0.26579445600509644
Batch 59/64 loss: 0.2602720260620117
Batch 60/64 loss: 0.2667127251625061
Batch 61/64 loss: 0.2559536099433899
Batch 62/64 loss: 0.25390005111694336
Batch 63/64 loss: 0.2617053985595703
Batch 64/64 loss: 0.26735377311706543
Epoch 159  Train loss: 0.2612272842257631  Val loss: 0.28037262126752194
Saving best model, epoch: 159
Epoch 160
-------------------------------
Batch 1/64 loss: 0.2616664171218872
Batch 2/64 loss: 0.2642233967781067
Batch 3/64 loss: 0.25738418102264404
Batch 4/64 loss: 0.2646169066429138
Batch 5/64 loss: 0.26077568531036377
Batch 6/64 loss: 0.26758015155792236
Batch 7/64 loss: 0.2577049732208252
Batch 8/64 loss: 0.2562904953956604
Batch 9/64 loss: 0.2634563446044922
Batch 10/64 loss: 0.26876628398895264
Batch 11/64 loss: 0.26915717124938965
Batch 12/64 loss: 0.26222479343414307
Batch 13/64 loss: 0.2745000123977661
Batch 14/64 loss: 0.26608604192733765
Batch 15/64 loss: 0.2638481855392456
Batch 16/64 loss: 0.26655519008636475
Batch 17/64 loss: 0.26241040229797363
Batch 18/64 loss: 0.2578474283218384
Batch 19/64 loss: 0.2608296275138855
Batch 20/64 loss: 0.2601243853569031
Batch 21/64 loss: 0.25550228357315063
Batch 22/64 loss: 0.26551353931427
Batch 23/64 loss: 0.269112765789032
Batch 24/64 loss: 0.2600333094596863
Batch 25/64 loss: 0.2674601078033447
Batch 26/64 loss: 0.26738524436950684
Batch 27/64 loss: 0.26637154817581177
Batch 28/64 loss: 0.2618327736854553
Batch 29/64 loss: 0.260875940322876
Batch 30/64 loss: 0.25978171825408936
Batch 31/64 loss: 0.25915396213531494
Batch 32/64 loss: 0.25666582584381104
Batch 33/64 loss: 0.2599717378616333
Batch 34/64 loss: 0.26221752166748047
Batch 35/64 loss: 0.264485239982605
Batch 36/64 loss: 0.2706061005592346
Batch 37/64 loss: 0.25508177280426025
Batch 38/64 loss: 0.2667413353919983
Batch 39/64 loss: 0.25698649883270264
Batch 40/64 loss: 0.2617020606994629
Batch 41/64 loss: 0.2647084593772888
Batch 42/64 loss: 0.26303648948669434
Batch 43/64 loss: 0.2646826505661011
Batch 44/64 loss: 0.26677513122558594
Batch 45/64 loss: 0.2658008337020874
Batch 46/64 loss: 0.2685297131538391
Batch 47/64 loss: 0.2525951862335205
Batch 48/64 loss: 0.2669653296470642
Batch 49/64 loss: 0.2670023441314697
Batch 50/64 loss: 0.2604054808616638
Batch 51/64 loss: 0.25078797340393066
Batch 52/64 loss: 0.2634614109992981
Batch 53/64 loss: 0.2541276216506958
Batch 54/64 loss: 0.26742029190063477
Batch 55/64 loss: 0.2611572742462158
Batch 56/64 loss: 0.253926157951355
Batch 57/64 loss: 0.26144587993621826
Batch 58/64 loss: 0.2592052221298218
Batch 59/64 loss: 0.25596654415130615
Batch 60/64 loss: 0.2608257532119751
Batch 61/64 loss: 0.25411999225616455
Batch 62/64 loss: 0.26520752906799316
Batch 63/64 loss: 0.2641058564186096
Batch 64/64 loss: 0.2684537172317505
Epoch 160  Train loss: 0.26238633370866965  Val loss: 0.2825007270701562
Epoch 161
-------------------------------
Batch 1/64 loss: 0.26330500841140747
Batch 2/64 loss: 0.2657794952392578
Batch 3/64 loss: 0.2552516460418701
Batch 4/64 loss: 0.25311481952667236
Batch 5/64 loss: 0.25986117124557495
Batch 6/64 loss: 0.26436281204223633
Batch 7/64 loss: 0.26475220918655396
Batch 8/64 loss: 0.2721823453903198
Batch 9/64 loss: 0.24967730045318604
Batch 10/64 loss: 0.2633417248725891
Batch 11/64 loss: 0.26209551095962524
Batch 12/64 loss: 0.2651386260986328
Batch 13/64 loss: 0.24812793731689453
Batch 14/64 loss: 0.2626171112060547
Batch 15/64 loss: 0.2553452253341675
Batch 16/64 loss: 0.26136523485183716
Batch 17/64 loss: 0.25396424531936646
Batch 18/64 loss: 0.2619175910949707
Batch 19/64 loss: 0.2564733028411865
Batch 20/64 loss: 0.25830990076065063
Batch 21/64 loss: 0.25310075283050537
Batch 22/64 loss: 0.2610211968421936
Batch 23/64 loss: 0.2655891180038452
Batch 24/64 loss: 0.24977898597717285
Batch 25/64 loss: 0.2575036287307739
Batch 26/64 loss: 0.2598990201950073
Batch 27/64 loss: 0.2615663409233093
Batch 28/64 loss: 0.25821202993392944
Batch 29/64 loss: 0.2617892622947693
Batch 30/64 loss: 0.2571909427642822
Batch 31/64 loss: 0.2586374282836914
Batch 32/64 loss: 0.25971633195877075
Batch 33/64 loss: 0.2588493227958679
Batch 34/64 loss: 0.255959153175354
Batch 35/64 loss: 0.252056360244751
Batch 36/64 loss: 0.2598501443862915
Batch 37/64 loss: 0.2617773413658142
Batch 38/64 loss: 0.263877809047699
Batch 39/64 loss: 0.2584993243217468
Batch 40/64 loss: 0.2605159878730774
Batch 41/64 loss: 0.260540246963501
Batch 42/64 loss: 0.2635459899902344
Batch 43/64 loss: 0.2652132511138916
Batch 44/64 loss: 0.2535734176635742
Batch 45/64 loss: 0.26132726669311523
Batch 46/64 loss: 0.26033055782318115
Batch 47/64 loss: 0.25814515352249146
Batch 48/64 loss: 0.26706743240356445
Batch 49/64 loss: 0.2683638334274292
Batch 50/64 loss: 0.2640267610549927
Batch 51/64 loss: 0.2616460919380188
Batch 52/64 loss: 0.26197052001953125
Batch 53/64 loss: 0.2547234296798706
Batch 54/64 loss: 0.2741938829421997
Batch 55/64 loss: 0.2740688920021057
Batch 56/64 loss: 0.262770414352417
Batch 57/64 loss: 0.2684391736984253
Batch 58/64 loss: 0.26556307077407837
Batch 59/64 loss: 0.27030324935913086
Batch 60/64 loss: 0.274172306060791
Batch 61/64 loss: 0.2713010907173157
Batch 62/64 loss: 0.26258283853530884
Batch 63/64 loss: 0.2591683864593506
Batch 64/64 loss: 0.2565954327583313
Epoch 161  Train loss: 0.26114286324557134  Val loss: 0.28268786291895864
Epoch 162
-------------------------------
Batch 1/64 loss: 0.26610201597213745
Batch 2/64 loss: 0.2629159688949585
Batch 3/64 loss: 0.2597786784172058
Batch 4/64 loss: 0.2570704221725464
Batch 5/64 loss: 0.2563631534576416
Batch 6/64 loss: 0.2530245780944824
Batch 7/64 loss: 0.2618449330329895
Batch 8/64 loss: 0.2539252042770386
Batch 9/64 loss: 0.2669088840484619
Batch 10/64 loss: 0.2622137665748596
Batch 11/64 loss: 0.2628607749938965
Batch 12/64 loss: 0.26835620403289795
Batch 13/64 loss: 0.2596522569656372
Batch 14/64 loss: 0.2560439109802246
Batch 15/64 loss: 0.2681562900543213
Batch 16/64 loss: 0.2647165060043335
Batch 17/64 loss: 0.253348708152771
Batch 18/64 loss: 0.2652747631072998
Batch 19/64 loss: 0.259856641292572
Batch 20/64 loss: 0.26062703132629395
Batch 21/64 loss: 0.26959216594696045
Batch 22/64 loss: 0.2555946111679077
Batch 23/64 loss: 0.2634401321411133
Batch 24/64 loss: 0.25372588634490967
Batch 25/64 loss: 0.25993049144744873
Batch 26/64 loss: 0.2600318193435669
Batch 27/64 loss: 0.25345784425735474
Batch 28/64 loss: 0.2626962661743164
Batch 29/64 loss: 0.25613129138946533
Batch 30/64 loss: 0.25617915391921997
Batch 31/64 loss: 0.2578412890434265
Batch 32/64 loss: 0.26430177688598633
Batch 33/64 loss: 0.26636624336242676
Batch 34/64 loss: 0.261166512966156
Batch 35/64 loss: 0.2717134356498718
Batch 36/64 loss: 0.26800763607025146
Batch 37/64 loss: 0.2508435845375061
Batch 38/64 loss: 0.2579669952392578
Batch 39/64 loss: 0.2709461450576782
Batch 40/64 loss: 0.2645419239997864
Batch 41/64 loss: 0.26690495014190674
Batch 42/64 loss: 0.25201380252838135
Batch 43/64 loss: 0.2704174518585205
Batch 44/64 loss: 0.2560334801673889
Batch 45/64 loss: 0.2643851041793823
Batch 46/64 loss: 0.25732797384262085
Batch 47/64 loss: 0.2576267719268799
Batch 48/64 loss: 0.259472131729126
Batch 49/64 loss: 0.26046258211135864
Batch 50/64 loss: 0.2584186792373657
Batch 51/64 loss: 0.26285380125045776
Batch 52/64 loss: 0.2616002559661865
Batch 53/64 loss: 0.26461243629455566
Batch 54/64 loss: 0.26087820529937744
Batch 55/64 loss: 0.253238320350647
Batch 56/64 loss: 0.258953332901001
Batch 57/64 loss: 0.26243162155151367
Batch 58/64 loss: 0.2668999433517456
Batch 59/64 loss: 0.26557672023773193
Batch 60/64 loss: 0.25818097591400146
Batch 61/64 loss: 0.26336371898651123
Batch 62/64 loss: 0.2624039649963379
Batch 63/64 loss: 0.26465678215026855
Batch 64/64 loss: 0.2521212100982666
Epoch 162  Train loss: 0.26104031076618267  Val loss: 0.2801028291384379
Saving best model, epoch: 162
Epoch 163
-------------------------------
Batch 1/64 loss: 0.2670564651489258
Batch 2/64 loss: 0.25814104080200195
Batch 3/64 loss: 0.26610326766967773
Batch 4/64 loss: 0.25522327423095703
Batch 5/64 loss: 0.26856112480163574
Batch 6/64 loss: 0.2614370584487915
Batch 7/64 loss: 0.2597994804382324
Batch 8/64 loss: 0.26882219314575195
Batch 9/64 loss: 0.2678218483924866
Batch 10/64 loss: 0.26104265451431274
Batch 11/64 loss: 0.259918212890625
Batch 12/64 loss: 0.25901901721954346
Batch 13/64 loss: 0.2552623152732849
Batch 14/64 loss: 0.25878918170928955
Batch 15/64 loss: 0.2544715404510498
Batch 16/64 loss: 0.26183825731277466
Batch 17/64 loss: 0.26906096935272217
Batch 18/64 loss: 0.2555690407752991
Batch 19/64 loss: 0.2580726742744446
Batch 20/64 loss: 0.2603995203971863
Batch 21/64 loss: 0.2649471163749695
Batch 22/64 loss: 0.25731325149536133
Batch 23/64 loss: 0.26549291610717773
Batch 24/64 loss: 0.25925880670547485
Batch 25/64 loss: 0.2548428773880005
Batch 26/64 loss: 0.2571007013320923
Batch 27/64 loss: 0.25837230682373047
Batch 28/64 loss: 0.2626175284385681
Batch 29/64 loss: 0.2586771249771118
Batch 30/64 loss: 0.25795263051986694
Batch 31/64 loss: 0.2594202160835266
Batch 32/64 loss: 0.26528501510620117
Batch 33/64 loss: 0.25718259811401367
Batch 34/64 loss: 0.2514488697052002
Batch 35/64 loss: 0.2627931833267212
Batch 36/64 loss: 0.263632595539093
Batch 37/64 loss: 0.2593725323677063
Batch 38/64 loss: 0.2583951950073242
Batch 39/64 loss: 0.26445162296295166
Batch 40/64 loss: 0.2627626657485962
Batch 41/64 loss: 0.263777494430542
Batch 42/64 loss: 0.25874894857406616
Batch 43/64 loss: 0.2587132453918457
Batch 44/64 loss: 0.2619771957397461
Batch 45/64 loss: 0.258328378200531
Batch 46/64 loss: 0.26089274883270264
Batch 47/64 loss: 0.25018537044525146
Batch 48/64 loss: 0.2593313455581665
Batch 49/64 loss: 0.2586026191711426
Batch 50/64 loss: 0.26963305473327637
Batch 51/64 loss: 0.25438451766967773
Batch 52/64 loss: 0.26447242498397827
Batch 53/64 loss: 0.2671471834182739
Batch 54/64 loss: 0.2593296766281128
Batch 55/64 loss: 0.256839394569397
Batch 56/64 loss: 0.25193917751312256
Batch 57/64 loss: 0.25992846488952637
Batch 58/64 loss: 0.25525450706481934
Batch 59/64 loss: 0.26750385761260986
Batch 60/64 loss: 0.252760648727417
Batch 61/64 loss: 0.2608397603034973
Batch 62/64 loss: 0.25436699390411377
Batch 63/64 loss: 0.2575553059577942
Batch 64/64 loss: 0.25806713104248047
Epoch 163  Train loss: 0.2601379067290063  Val loss: 0.28128194112548305
Epoch 164
-------------------------------
Batch 1/64 loss: 0.2593623399734497
Batch 2/64 loss: 0.2585580348968506
Batch 3/64 loss: 0.2570144534111023
Batch 4/64 loss: 0.2577568292617798
Batch 5/64 loss: 0.2550199627876282
Batch 6/64 loss: 0.2660566568374634
Batch 7/64 loss: 0.269353449344635
Batch 8/64 loss: 0.2713569402694702
Batch 9/64 loss: 0.25989294052124023
Batch 10/64 loss: 0.2515016794204712
Batch 11/64 loss: 0.26536262035369873
Batch 12/64 loss: 0.2642167806625366
Batch 13/64 loss: 0.25991588830947876
Batch 14/64 loss: 0.2572459578514099
Batch 15/64 loss: 0.2563977837562561
Batch 16/64 loss: 0.27288752794265747
Batch 17/64 loss: 0.26732659339904785
Batch 18/64 loss: 0.25709450244903564
Batch 19/64 loss: 0.2559988498687744
Batch 20/64 loss: 0.26061147451400757
Batch 21/64 loss: 0.25684428215026855
Batch 22/64 loss: 0.2529487609863281
Batch 23/64 loss: 0.2571144700050354
Batch 24/64 loss: 0.25248098373413086
Batch 25/64 loss: 0.2655002474784851
Batch 26/64 loss: 0.26050400733947754
Batch 27/64 loss: 0.25947368144989014
Batch 28/64 loss: 0.2716221213340759
Batch 29/64 loss: 0.2745736837387085
Batch 30/64 loss: 0.2516489028930664
Batch 31/64 loss: 0.25833094120025635
Batch 32/64 loss: 0.24802690744400024
Batch 33/64 loss: 0.2591143846511841
Batch 34/64 loss: 0.2538003921508789
Batch 35/64 loss: 0.2575312852859497
Batch 36/64 loss: 0.2570270895957947
Batch 37/64 loss: 0.26746225357055664
Batch 38/64 loss: 0.2628047466278076
Batch 39/64 loss: 0.2520284652709961
Batch 40/64 loss: 0.25630664825439453
Batch 41/64 loss: 0.25825023651123047
Batch 42/64 loss: 0.2635464668273926
Batch 43/64 loss: 0.26920199394226074
Batch 44/64 loss: 0.25489211082458496
Batch 45/64 loss: 0.2621803283691406
Batch 46/64 loss: 0.255882203578949
Batch 47/64 loss: 0.2639850378036499
Batch 48/64 loss: 0.2645730972290039
Batch 49/64 loss: 0.26179248094558716
Batch 50/64 loss: 0.2587119936943054
Batch 51/64 loss: 0.25753432512283325
Batch 52/64 loss: 0.25724273920059204
Batch 53/64 loss: 0.2604846954345703
Batch 54/64 loss: 0.27078503370285034
Batch 55/64 loss: 0.257094144821167
Batch 56/64 loss: 0.2575974464416504
Batch 57/64 loss: 0.2643740177154541
Batch 58/64 loss: 0.2580244541168213
Batch 59/64 loss: 0.2589836120605469
Batch 60/64 loss: 0.26299071311950684
Batch 61/64 loss: 0.2651008367538452
Batch 62/64 loss: 0.2584800720214844
Batch 63/64 loss: 0.2581007480621338
Batch 64/64 loss: 0.26150596141815186
Epoch 164  Train loss: 0.2602982553781248  Val loss: 0.28150863868674053
Epoch 165
-------------------------------
Batch 1/64 loss: 0.25450587272644043
Batch 2/64 loss: 0.2532427906990051
Batch 3/64 loss: 0.2530955672264099
Batch 4/64 loss: 0.2486095428466797
Batch 5/64 loss: 0.25937914848327637
Batch 6/64 loss: 0.25741326808929443
Batch 7/64 loss: 0.25290119647979736
Batch 8/64 loss: 0.2674064636230469
Batch 9/64 loss: 0.2543206810951233
Batch 10/64 loss: 0.26753997802734375
Batch 11/64 loss: 0.25983089208602905
Batch 12/64 loss: 0.25338590145111084
Batch 13/64 loss: 0.2628505229949951
Batch 14/64 loss: 0.26021313667297363
Batch 15/64 loss: 0.25923413038253784
Batch 16/64 loss: 0.2675129175186157
Batch 17/64 loss: 0.2599923014640808
Batch 18/64 loss: 0.25221216678619385
Batch 19/64 loss: 0.2573391795158386
Batch 20/64 loss: 0.255668044090271
Batch 21/64 loss: 0.26564550399780273
Batch 22/64 loss: 0.2671924829483032
Batch 23/64 loss: 0.25823038816452026
Batch 24/64 loss: 0.2714551091194153
Batch 25/64 loss: 0.25758206844329834
Batch 26/64 loss: 0.2618035674095154
Batch 27/64 loss: 0.2553563714027405
Batch 28/64 loss: 0.2603342533111572
Batch 29/64 loss: 0.25728774070739746
Batch 30/64 loss: 0.26073890924453735
Batch 31/64 loss: 0.2630631923675537
Batch 32/64 loss: 0.2577444911003113
Batch 33/64 loss: 0.26404869556427
Batch 34/64 loss: 0.25496917963027954
Batch 35/64 loss: 0.2572709321975708
Batch 36/64 loss: 0.2717950940132141
Batch 37/64 loss: 0.2539826035499573
Batch 38/64 loss: 0.25326764583587646
Batch 39/64 loss: 0.2600891590118408
Batch 40/64 loss: 0.2616385221481323
Batch 41/64 loss: 0.2627573013305664
Batch 42/64 loss: 0.25972795486450195
Batch 43/64 loss: 0.2570553421974182
Batch 44/64 loss: 0.25808238983154297
Batch 45/64 loss: 0.2628595232963562
Batch 46/64 loss: 0.2652454376220703
Batch 47/64 loss: 0.2601674199104309
Batch 48/64 loss: 0.25877857208251953
Batch 49/64 loss: 0.2601775527000427
Batch 50/64 loss: 0.2618202567100525
Batch 51/64 loss: 0.26268911361694336
Batch 52/64 loss: 0.25834786891937256
Batch 53/64 loss: 0.25785183906555176
Batch 54/64 loss: 0.2534383535385132
Batch 55/64 loss: 0.2685497999191284
Batch 56/64 loss: 0.25966888666152954
Batch 57/64 loss: 0.25737929344177246
Batch 58/64 loss: 0.26365023851394653
Batch 59/64 loss: 0.2574366331100464
Batch 60/64 loss: 0.25895416736602783
Batch 61/64 loss: 0.2567417025566101
Batch 62/64 loss: 0.2620958089828491
Batch 63/64 loss: 0.25730788707733154
Batch 64/64 loss: 0.2522832155227661
Epoch 165  Train loss: 0.25945326066484636  Val loss: 0.2799727421036291
Saving best model, epoch: 165
Epoch 166
-------------------------------
Batch 1/64 loss: 0.2559925317764282
Batch 2/64 loss: 0.2614009380340576
Batch 3/64 loss: 0.25606292486190796
Batch 4/64 loss: 0.26232486963272095
Batch 5/64 loss: 0.25195515155792236
Batch 6/64 loss: 0.25258320569992065
Batch 7/64 loss: 0.25725579261779785
Batch 8/64 loss: 0.2599760890007019
Batch 9/64 loss: 0.2582458257675171
Batch 10/64 loss: 0.2507888674736023
Batch 11/64 loss: 0.26044517755508423
Batch 12/64 loss: 0.25504934787750244
Batch 13/64 loss: 0.2614327669143677
Batch 14/64 loss: 0.2542456388473511
Batch 15/64 loss: 0.2515547275543213
Batch 16/64 loss: 0.25930917263031006
Batch 17/64 loss: 0.25648605823516846
Batch 18/64 loss: 0.254250705242157
Batch 19/64 loss: 0.261127233505249
Batch 20/64 loss: 0.2615625858306885
Batch 21/64 loss: 0.2609744071960449
Batch 22/64 loss: 0.25998473167419434
Batch 23/64 loss: 0.257570743560791
Batch 24/64 loss: 0.2596559524536133
Batch 25/64 loss: 0.25815248489379883
Batch 26/64 loss: 0.26141542196273804
Batch 27/64 loss: 0.26219356060028076
Batch 28/64 loss: 0.25901854038238525
Batch 29/64 loss: 0.2603495121002197
Batch 30/64 loss: 0.2518196105957031
Batch 31/64 loss: 0.25279903411865234
Batch 32/64 loss: 0.26274192333221436
Batch 33/64 loss: 0.2567439079284668
Batch 34/64 loss: 0.2614016532897949
Batch 35/64 loss: 0.2538560628890991
Batch 36/64 loss: 0.25508809089660645
Batch 37/64 loss: 0.2558136582374573
Batch 38/64 loss: 0.26365673542022705
Batch 39/64 loss: 0.2583848237991333
Batch 40/64 loss: 0.26284509897232056
Batch 41/64 loss: 0.2528437376022339
Batch 42/64 loss: 0.26681989431381226
Batch 43/64 loss: 0.26258915662765503
Batch 44/64 loss: 0.25648748874664307
Batch 45/64 loss: 0.26495933532714844
Batch 46/64 loss: 0.25154948234558105
Batch 47/64 loss: 0.25796449184417725
Batch 48/64 loss: 0.26484882831573486
Batch 49/64 loss: 0.2611839771270752
Batch 50/64 loss: 0.2623833417892456
Batch 51/64 loss: 0.263934850692749
Batch 52/64 loss: 0.2584646940231323
Batch 53/64 loss: 0.2586996555328369
Batch 54/64 loss: 0.26593315601348877
Batch 55/64 loss: 0.25829195976257324
Batch 56/64 loss: 0.2566852569580078
Batch 57/64 loss: 0.26511359214782715
Batch 58/64 loss: 0.2557363510131836
Batch 59/64 loss: 0.2628048062324524
Batch 60/64 loss: 0.26332294940948486
Batch 61/64 loss: 0.26111912727355957
Batch 62/64 loss: 0.25764304399490356
Batch 63/64 loss: 0.2640024423599243
Batch 64/64 loss: 0.26087236404418945
Epoch 166  Train loss: 0.25891061109655045  Val loss: 0.280543370959685
Epoch 167
-------------------------------
Batch 1/64 loss: 0.267209529876709
Batch 2/64 loss: 0.26228559017181396
Batch 3/64 loss: 0.2631687521934509
Batch 4/64 loss: 0.2637758255004883
Batch 5/64 loss: 0.2569233179092407
Batch 6/64 loss: 0.25055521726608276
Batch 7/64 loss: 0.2507550120353699
Batch 8/64 loss: 0.2586439251899719
Batch 9/64 loss: 0.2620964050292969
Batch 10/64 loss: 0.2556118965148926
Batch 11/64 loss: 0.26124143600463867
Batch 12/64 loss: 0.256889283657074
Batch 13/64 loss: 0.25763750076293945
Batch 14/64 loss: 0.25601446628570557
Batch 15/64 loss: 0.256766676902771
Batch 16/64 loss: 0.25512927770614624
Batch 17/64 loss: 0.2595800757408142
Batch 18/64 loss: 0.2667543888092041
Batch 19/64 loss: 0.2672080993652344
Batch 20/64 loss: 0.2644158601760864
Batch 21/64 loss: 0.2589951753616333
Batch 22/64 loss: 0.26142406463623047
Batch 23/64 loss: 0.2546344995498657
Batch 24/64 loss: 0.2603181004524231
Batch 25/64 loss: 0.2595181465148926
Batch 26/64 loss: 0.25358694791793823
Batch 27/64 loss: 0.2565995454788208
Batch 28/64 loss: 0.2609807848930359
Batch 29/64 loss: 0.25265276432037354
Batch 30/64 loss: 0.2544722557067871
Batch 31/64 loss: 0.2537500262260437
Batch 32/64 loss: 0.25659263134002686
Batch 33/64 loss: 0.2584240436553955
Batch 34/64 loss: 0.25354301929473877
Batch 35/64 loss: 0.26133739948272705
Batch 36/64 loss: 0.2607383728027344
Batch 37/64 loss: 0.2543177008628845
Batch 38/64 loss: 0.26484304666519165
Batch 39/64 loss: 0.2499399185180664
Batch 40/64 loss: 0.25545358657836914
Batch 41/64 loss: 0.2674452066421509
Batch 42/64 loss: 0.26246076822280884
Batch 43/64 loss: 0.2634868621826172
Batch 44/64 loss: 0.2573567032814026
Batch 45/64 loss: 0.25763094425201416
Batch 46/64 loss: 0.2593550682067871
Batch 47/64 loss: 0.26205116510391235
Batch 48/64 loss: 0.258742094039917
Batch 49/64 loss: 0.2565537095069885
Batch 50/64 loss: 0.25672686100006104
Batch 51/64 loss: 0.2576528787612915
Batch 52/64 loss: 0.25760316848754883
Batch 53/64 loss: 0.25946998596191406
Batch 54/64 loss: 0.2555732727050781
Batch 55/64 loss: 0.2572785019874573
Batch 56/64 loss: 0.2602841258049011
Batch 57/64 loss: 0.2611593008041382
Batch 58/64 loss: 0.25654280185699463
Batch 59/64 loss: 0.2581639289855957
Batch 60/64 loss: 0.25786280632019043
Batch 61/64 loss: 0.25426554679870605
Batch 62/64 loss: 0.2644413113594055
Batch 63/64 loss: 0.2621711492538452
Batch 64/64 loss: 0.26421838998794556
Epoch 167  Train loss: 0.2587800238646713  Val loss: 0.2793155757012646
Saving best model, epoch: 167
Epoch 168
-------------------------------
Batch 1/64 loss: 0.26108092069625854
Batch 2/64 loss: 0.25264179706573486
Batch 3/64 loss: 0.2615858316421509
Batch 4/64 loss: 0.2593454122543335
Batch 5/64 loss: 0.2558314800262451
Batch 6/64 loss: 0.2607231140136719
Batch 7/64 loss: 0.25305992364883423
Batch 8/64 loss: 0.26599764823913574
Batch 9/64 loss: 0.25623857975006104
Batch 10/64 loss: 0.2559822201728821
Batch 11/64 loss: 0.2563673257827759
Batch 12/64 loss: 0.2624499201774597
Batch 13/64 loss: 0.2608913779258728
Batch 14/64 loss: 0.2603621482849121
Batch 15/64 loss: 0.2657456398010254
Batch 16/64 loss: 0.2619117498397827
Batch 17/64 loss: 0.2551990747451782
Batch 18/64 loss: 0.25016653537750244
Batch 19/64 loss: 0.25620728731155396
Batch 20/64 loss: 0.26419198513031006
Batch 21/64 loss: 0.26437485218048096
Batch 22/64 loss: 0.2633272409439087
Batch 23/64 loss: 0.2503507733345032
Batch 24/64 loss: 0.25617527961730957
Batch 25/64 loss: 0.26071834564208984
Batch 26/64 loss: 0.2537664771080017
Batch 27/64 loss: 0.25427013635635376
Batch 28/64 loss: 0.2578590512275696
Batch 29/64 loss: 0.2600494623184204
Batch 30/64 loss: 0.24977946281433105
Batch 31/64 loss: 0.2532082796096802
Batch 32/64 loss: 0.2565111517906189
Batch 33/64 loss: 0.27115797996520996
Batch 34/64 loss: 0.256191611289978
Batch 35/64 loss: 0.2589852213859558
Batch 36/64 loss: 0.2549898624420166
Batch 37/64 loss: 0.25650709867477417
Batch 38/64 loss: 0.2643167972564697
Batch 39/64 loss: 0.2580421566963196
Batch 40/64 loss: 0.2558823823928833
Batch 41/64 loss: 0.25514042377471924
Batch 42/64 loss: 0.25499212741851807
Batch 43/64 loss: 0.26409876346588135
Batch 44/64 loss: 0.2554793953895569
Batch 45/64 loss: 0.25427186489105225
Batch 46/64 loss: 0.25847315788269043
Batch 47/64 loss: 0.25496768951416016
Batch 48/64 loss: 0.2594722509384155
Batch 49/64 loss: 0.26457667350769043
Batch 50/64 loss: 0.2552036643028259
Batch 51/64 loss: 0.2606525421142578
Batch 52/64 loss: 0.2617965340614319
Batch 53/64 loss: 0.2637134790420532
Batch 54/64 loss: 0.2623305320739746
Batch 55/64 loss: 0.2609570622444153
Batch 56/64 loss: 0.25500428676605225
Batch 57/64 loss: 0.25011390447616577
Batch 58/64 loss: 0.250518798828125
Batch 59/64 loss: 0.25770509243011475
Batch 60/64 loss: 0.25434648990631104
Batch 61/64 loss: 0.2592862844467163
Batch 62/64 loss: 0.25480878353118896
Batch 63/64 loss: 0.26096194982528687
Batch 64/64 loss: 0.2572193145751953
Epoch 168  Train loss: 0.25810556598738127  Val loss: 0.2799070741712433
Epoch 169
-------------------------------
Batch 1/64 loss: 0.2563091516494751
Batch 2/64 loss: 0.25854551792144775
Batch 3/64 loss: 0.2607731819152832
Batch 4/64 loss: 0.26273953914642334
Batch 5/64 loss: 0.266834020614624
Batch 6/64 loss: 0.24946051836013794
Batch 7/64 loss: 0.2607765197753906
Batch 8/64 loss: 0.2561134099960327
Batch 9/64 loss: 0.2767953872680664
Batch 10/64 loss: 0.26006561517715454
Batch 11/64 loss: 0.25303781032562256
Batch 12/64 loss: 0.264137864112854
Batch 13/64 loss: 0.25729238986968994
Batch 14/64 loss: 0.2571290135383606
Batch 15/64 loss: 0.2621191740036011
Batch 16/64 loss: 0.25353842973709106
Batch 17/64 loss: 0.2505565881729126
Batch 18/64 loss: 0.2606077194213867
Batch 19/64 loss: 0.26443201303482056
Batch 20/64 loss: 0.2606619596481323
Batch 21/64 loss: 0.25751328468322754
Batch 22/64 loss: 0.2583112120628357
Batch 23/64 loss: 0.25522875785827637
Batch 24/64 loss: 0.2519036531448364
Batch 25/64 loss: 0.25903940200805664
Batch 26/64 loss: 0.25977087020874023
Batch 27/64 loss: 0.2521434426307678
Batch 28/64 loss: 0.25787079334259033
Batch 29/64 loss: 0.26951920986175537
Batch 30/64 loss: 0.24768632650375366
Batch 31/64 loss: 0.25565576553344727
Batch 32/64 loss: 0.25338107347488403
Batch 33/64 loss: 0.258103609085083
Batch 34/64 loss: 0.26505935192108154
Batch 35/64 loss: 0.2715829610824585
Batch 36/64 loss: 0.2545984387397766
Batch 37/64 loss: 0.2600477933883667
Batch 38/64 loss: 0.2542123794555664
Batch 39/64 loss: 0.2571999430656433
Batch 40/64 loss: 0.27297937870025635
Batch 41/64 loss: 0.25345379114151
Batch 42/64 loss: 0.26276618242263794
Batch 43/64 loss: 0.2636682987213135
Batch 44/64 loss: 0.2626059055328369
Batch 45/64 loss: 0.2610139846801758
Batch 46/64 loss: 0.264634370803833
Batch 47/64 loss: 0.254321813583374
Batch 48/64 loss: 0.2746187448501587
Batch 49/64 loss: 0.2576937675476074
Batch 50/64 loss: 0.25825023651123047
Batch 51/64 loss: 0.25556111335754395
Batch 52/64 loss: 0.2561115026473999
Batch 53/64 loss: 0.2613903880119324
Batch 54/64 loss: 0.2552056908607483
Batch 55/64 loss: 0.25962918996810913
Batch 56/64 loss: 0.26230907440185547
Batch 57/64 loss: 0.2433786392211914
Batch 58/64 loss: 0.2509194016456604
Batch 59/64 loss: 0.2642318606376648
Batch 60/64 loss: 0.25799560546875
Batch 61/64 loss: 0.2621448040008545
Batch 62/64 loss: 0.2501388192176819
Batch 63/64 loss: 0.25871115922927856
Batch 64/64 loss: 0.2528840899467468
Epoch 169  Train loss: 0.25888864129197364  Val loss: 0.2798346051645443
Epoch 170
-------------------------------
Batch 1/64 loss: 0.2581278681755066
Batch 2/64 loss: 0.2633169889450073
Batch 3/64 loss: 0.2588024139404297
Batch 4/64 loss: 0.25132083892822266
Batch 5/64 loss: 0.25562554597854614
Batch 6/64 loss: 0.2564418315887451
Batch 7/64 loss: 0.2618500590324402
Batch 8/64 loss: 0.25423622131347656
Batch 9/64 loss: 0.2479153275489807
Batch 10/64 loss: 0.25372129678726196
Batch 11/64 loss: 0.25509190559387207
Batch 12/64 loss: 0.25178372859954834
Batch 13/64 loss: 0.259313702583313
Batch 14/64 loss: 0.26215267181396484
Batch 15/64 loss: 0.25465792417526245
Batch 16/64 loss: 0.25488531589508057
Batch 17/64 loss: 0.2529416084289551
Batch 18/64 loss: 0.2623474597930908
Batch 19/64 loss: 0.2577459216117859
Batch 20/64 loss: 0.2561911344528198
Batch 21/64 loss: 0.2484811544418335
Batch 22/64 loss: 0.25357747077941895
Batch 23/64 loss: 0.2604758143424988
Batch 24/64 loss: 0.26359081268310547
Batch 25/64 loss: 0.27177542448043823
Batch 26/64 loss: 0.2538912892341614
Batch 27/64 loss: 0.2565082311630249
Batch 28/64 loss: 0.2550467252731323
Batch 29/64 loss: 0.26762890815734863
Batch 30/64 loss: 0.2544705271720886
Batch 31/64 loss: 0.2549111843109131
Batch 32/64 loss: 0.2538018822669983
Batch 33/64 loss: 0.25443387031555176
Batch 34/64 loss: 0.25123077630996704
Batch 35/64 loss: 0.25843995809555054
Batch 36/64 loss: 0.2551039457321167
Batch 37/64 loss: 0.24900329113006592
Batch 38/64 loss: 0.25594204664230347
Batch 39/64 loss: 0.2619767189025879
Batch 40/64 loss: 0.26002371311187744
Batch 41/64 loss: 0.259959876537323
Batch 42/64 loss: 0.2596806287765503
Batch 43/64 loss: 0.2664911150932312
Batch 44/64 loss: 0.2610977292060852
Batch 45/64 loss: 0.25438910722732544
Batch 46/64 loss: 0.25224530696868896
Batch 47/64 loss: 0.25777244567871094
Batch 48/64 loss: 0.25201427936553955
Batch 49/64 loss: 0.25439751148223877
Batch 50/64 loss: 0.261025607585907
Batch 51/64 loss: 0.25349199771881104
Batch 52/64 loss: 0.2589262127876282
Batch 53/64 loss: 0.2680140733718872
Batch 54/64 loss: 0.2651662826538086
Batch 55/64 loss: 0.25914067029953003
Batch 56/64 loss: 0.2564399242401123
Batch 57/64 loss: 0.2607017755508423
Batch 58/64 loss: 0.25972819328308105
Batch 59/64 loss: 0.2528496980667114
Batch 60/64 loss: 0.2550368905067444
Batch 61/64 loss: 0.2653048038482666
Batch 62/64 loss: 0.25229138135910034
Batch 63/64 loss: 0.2691209316253662
Batch 64/64 loss: 0.2642925977706909
Epoch 170  Train loss: 0.25760453962812235  Val loss: 0.2794964712919648
Epoch 171
-------------------------------
Batch 1/64 loss: 0.25859135389328003
Batch 2/64 loss: 0.25323742628097534
Batch 3/64 loss: 0.26310229301452637
Batch 4/64 loss: 0.2605692148208618
Batch 5/64 loss: 0.26191890239715576
Batch 6/64 loss: 0.2569082975387573
Batch 7/64 loss: 0.2578333616256714
Batch 8/64 loss: 0.26878106594085693
Batch 9/64 loss: 0.2590571641921997
Batch 10/64 loss: 0.251312255859375
Batch 11/64 loss: 0.2605332136154175
Batch 12/64 loss: 0.255718469619751
Batch 13/64 loss: 0.2582707405090332
Batch 14/64 loss: 0.2546825408935547
Batch 15/64 loss: 0.25609779357910156
Batch 16/64 loss: 0.25414496660232544
Batch 17/64 loss: 0.25744372606277466
Batch 18/64 loss: 0.253057062625885
Batch 19/64 loss: 0.25577086210250854
Batch 20/64 loss: 0.2583165168762207
Batch 21/64 loss: 0.26525235176086426
Batch 22/64 loss: 0.2559155225753784
Batch 23/64 loss: 0.256317138671875
Batch 24/64 loss: 0.25202369689941406
Batch 25/64 loss: 0.261890172958374
Batch 26/64 loss: 0.2553229331970215
Batch 27/64 loss: 0.25539451837539673
Batch 28/64 loss: 0.2580817937850952
Batch 29/64 loss: 0.2544863224029541
Batch 30/64 loss: 0.2586402893066406
Batch 31/64 loss: 0.249439537525177
Batch 32/64 loss: 0.2544604539871216
Batch 33/64 loss: 0.2579261064529419
Batch 34/64 loss: 0.25450944900512695
Batch 35/64 loss: 0.2590266466140747
Batch 36/64 loss: 0.2566850185394287
Batch 37/64 loss: 0.2513974905014038
Batch 38/64 loss: 0.25743699073791504
Batch 39/64 loss: 0.2510035037994385
Batch 40/64 loss: 0.2548080086708069
Batch 41/64 loss: 0.2536354660987854
Batch 42/64 loss: 0.26059389114379883
Batch 43/64 loss: 0.2644418478012085
Batch 44/64 loss: 0.250529408454895
Batch 45/64 loss: 0.25319117307662964
Batch 46/64 loss: 0.25843024253845215
Batch 47/64 loss: 0.2593114376068115
Batch 48/64 loss: 0.2641928195953369
Batch 49/64 loss: 0.2586228847503662
Batch 50/64 loss: 0.2623329162597656
Batch 51/64 loss: 0.26219987869262695
Batch 52/64 loss: 0.27128899097442627
Batch 53/64 loss: 0.2548791170120239
Batch 54/64 loss: 0.2550877332687378
Batch 55/64 loss: 0.274694561958313
Batch 56/64 loss: 0.26446110010147095
Batch 57/64 loss: 0.25689029693603516
Batch 58/64 loss: 0.2557891607284546
Batch 59/64 loss: 0.26748180389404297
Batch 60/64 loss: 0.261776864528656
Batch 61/64 loss: 0.25387024879455566
Batch 62/64 loss: 0.2530023455619812
Batch 63/64 loss: 0.25090914964675903
Batch 64/64 loss: 0.25548744201660156
Epoch 171  Train loss: 0.2577975544275022  Val loss: 0.27903900482400584
Saving best model, epoch: 171
Epoch 172
-------------------------------
Batch 1/64 loss: 0.25769221782684326
Batch 2/64 loss: 0.25840282440185547
Batch 3/64 loss: 0.26004213094711304
Batch 4/64 loss: 0.2478088140487671
Batch 5/64 loss: 0.2561691999435425
Batch 6/64 loss: 0.25636494159698486
Batch 7/64 loss: 0.2635399103164673
Batch 8/64 loss: 0.26494109630584717
Batch 9/64 loss: 0.2547561526298523
Batch 10/64 loss: 0.2578359842300415
Batch 11/64 loss: 0.253326416015625
Batch 12/64 loss: 0.2496315836906433
Batch 13/64 loss: 0.256655752658844
Batch 14/64 loss: 0.2576766014099121
Batch 15/64 loss: 0.25847601890563965
Batch 16/64 loss: 0.2772068977355957
Batch 17/64 loss: 0.2587125301361084
Batch 18/64 loss: 0.2591474652290344
Batch 19/64 loss: 0.24910366535186768
Batch 20/64 loss: 0.25879812240600586
Batch 21/64 loss: 0.24877750873565674
Batch 22/64 loss: 0.2591225504875183
Batch 23/64 loss: 0.2586512565612793
Batch 24/64 loss: 0.2519350051879883
Batch 25/64 loss: 0.2503122091293335
Batch 26/64 loss: 0.25463366508483887
Batch 27/64 loss: 0.25988250970840454
Batch 28/64 loss: 0.25800979137420654
Batch 29/64 loss: 0.25507616996765137
Batch 30/64 loss: 0.2583957314491272
Batch 31/64 loss: 0.2617108225822449
Batch 32/64 loss: 0.2458997368812561
Batch 33/64 loss: 0.26512885093688965
Batch 34/64 loss: 0.26737338304519653
Batch 35/64 loss: 0.2577122449874878
Batch 36/64 loss: 0.2517783045768738
Batch 37/64 loss: 0.2609383463859558
Batch 38/64 loss: 0.26395756006240845
Batch 39/64 loss: 0.2661129832267761
Batch 40/64 loss: 0.26525115966796875
Batch 41/64 loss: 0.2567068338394165
Batch 42/64 loss: 0.2505214214324951
Batch 43/64 loss: 0.26047754287719727
Batch 44/64 loss: 0.2633664608001709
Batch 45/64 loss: 0.2518808841705322
Batch 46/64 loss: 0.2550312876701355
Batch 47/64 loss: 0.2552404999732971
Batch 48/64 loss: 0.27283287048339844
Batch 49/64 loss: 0.25552719831466675
Batch 50/64 loss: 0.2516368627548218
Batch 51/64 loss: 0.2549523115158081
Batch 52/64 loss: 0.25573134422302246
Batch 53/64 loss: 0.26436495780944824
Batch 54/64 loss: 0.2553499937057495
Batch 55/64 loss: 0.2565191984176636
Batch 56/64 loss: 0.2533787488937378
Batch 57/64 loss: 0.25258249044418335
Batch 58/64 loss: 0.2625277042388916
Batch 59/64 loss: 0.254755437374115
Batch 60/64 loss: 0.26238352060317993
Batch 61/64 loss: 0.25775575637817383
Batch 62/64 loss: 0.2567511796951294
Batch 63/64 loss: 0.261873722076416
Batch 64/64 loss: 0.240526020526886
Epoch 172  Train loss: 0.2575606409241171  Val loss: 0.2775381668326781
Saving best model, epoch: 172
Epoch 173
-------------------------------
Batch 1/64 loss: 0.25151175260543823
Batch 2/64 loss: 0.2540324330329895
Batch 3/64 loss: 0.2588697075843811
Batch 4/64 loss: 0.25264692306518555
Batch 5/64 loss: 0.25544607639312744
Batch 6/64 loss: 0.2578315734863281
Batch 7/64 loss: 0.2519855499267578
Batch 8/64 loss: 0.2607344388961792
Batch 9/64 loss: 0.2643345594406128
Batch 10/64 loss: 0.2530643939971924
Batch 11/64 loss: 0.2562398314476013
Batch 12/64 loss: 0.2571863532066345
Batch 13/64 loss: 0.26261311769485474
Batch 14/64 loss: 0.2609577775001526
Batch 15/64 loss: 0.2562166452407837
Batch 16/64 loss: 0.25301051139831543
Batch 17/64 loss: 0.25793904066085815
Batch 18/64 loss: 0.2543386220932007
Batch 19/64 loss: 0.25688624382019043
Batch 20/64 loss: 0.25082141160964966
Batch 21/64 loss: 0.2558779716491699
Batch 22/64 loss: 0.25160813331604004
Batch 23/64 loss: 0.25125014781951904
Batch 24/64 loss: 0.26195764541625977
Batch 25/64 loss: 0.2609449625015259
Batch 26/64 loss: 0.2561066150665283
Batch 27/64 loss: 0.25522685050964355
Batch 28/64 loss: 0.2596479654312134
Batch 29/64 loss: 0.261554479598999
Batch 30/64 loss: 0.25456440448760986
Batch 31/64 loss: 0.25543898344039917
Batch 32/64 loss: 0.2548564672470093
Batch 33/64 loss: 0.2574741840362549
Batch 34/64 loss: 0.2558356523513794
Batch 35/64 loss: 0.2601463794708252
Batch 36/64 loss: 0.2546667456626892
Batch 37/64 loss: 0.24775826930999756
Batch 38/64 loss: 0.2508142590522766
Batch 39/64 loss: 0.2509046792984009
Batch 40/64 loss: 0.25599145889282227
Batch 41/64 loss: 0.2613403797149658
Batch 42/64 loss: 0.25536930561065674
Batch 43/64 loss: 0.250931978225708
Batch 44/64 loss: 0.2571953535079956
Batch 45/64 loss: 0.2560760974884033
Batch 46/64 loss: 0.2631887197494507
Batch 47/64 loss: 0.25414806604385376
Batch 48/64 loss: 0.25822412967681885
Batch 49/64 loss: 0.2536655068397522
Batch 50/64 loss: 0.25008970499038696
Batch 51/64 loss: 0.2639424204826355
Batch 52/64 loss: 0.2573782205581665
Batch 53/64 loss: 0.2597702741622925
Batch 54/64 loss: 0.2587208151817322
Batch 55/64 loss: 0.25781047344207764
Batch 56/64 loss: 0.26146769523620605
Batch 57/64 loss: 0.2547144889831543
Batch 58/64 loss: 0.2583578824996948
Batch 59/64 loss: 0.2586883306503296
Batch 60/64 loss: 0.2573585510253906
Batch 61/64 loss: 0.2464848756790161
Batch 62/64 loss: 0.25684690475463867
Batch 63/64 loss: 0.25379955768585205
Batch 64/64 loss: 0.26993536949157715
Epoch 173  Train loss: 0.25642846238379385  Val loss: 0.2786172507554805
Epoch 174
-------------------------------
Batch 1/64 loss: 0.2473609447479248
Batch 2/64 loss: 0.25593411922454834
Batch 3/64 loss: 0.25830233097076416
Batch 4/64 loss: 0.25813060998916626
Batch 5/64 loss: 0.2572134733200073
Batch 6/64 loss: 0.27256810665130615
Batch 7/64 loss: 0.2506413459777832
Batch 8/64 loss: 0.2550849914550781
Batch 9/64 loss: 0.2527691125869751
Batch 10/64 loss: 0.25746214389801025
Batch 11/64 loss: 0.26300156116485596
Batch 12/64 loss: 0.24699074029922485
Batch 13/64 loss: 0.2537665367126465
Batch 14/64 loss: 0.26333701610565186
Batch 15/64 loss: 0.26320546865463257
Batch 16/64 loss: 0.2496044635772705
Batch 17/64 loss: 0.2615228295326233
Batch 18/64 loss: 0.2557681202888489
Batch 19/64 loss: 0.26047438383102417
Batch 20/64 loss: 0.25537770986557007
Batch 21/64 loss: 0.26012325286865234
Batch 22/64 loss: 0.2560499906539917
Batch 23/64 loss: 0.2533877491950989
Batch 24/64 loss: 0.24823987483978271
Batch 25/64 loss: 0.2496126890182495
Batch 26/64 loss: 0.2530803680419922
Batch 27/64 loss: 0.26379793882369995
Batch 28/64 loss: 0.2516881227493286
Batch 29/64 loss: 0.26105308532714844
Batch 30/64 loss: 0.2500053644180298
Batch 31/64 loss: 0.26102328300476074
Batch 32/64 loss: 0.2501232624053955
Batch 33/64 loss: 0.26203691959381104
Batch 34/64 loss: 0.2560388445854187
Batch 35/64 loss: 0.25224465131759644
Batch 36/64 loss: 0.25981539487838745
Batch 37/64 loss: 0.253851056098938
Batch 38/64 loss: 0.25894397497177124
Batch 39/64 loss: 0.25676870346069336
Batch 40/64 loss: 0.25239884853363037
Batch 41/64 loss: 0.24651503562927246
Batch 42/64 loss: 0.2602408528327942
Batch 43/64 loss: 0.2483738660812378
Batch 44/64 loss: 0.2565193176269531
Batch 45/64 loss: 0.24811112880706787
Batch 46/64 loss: 0.25619441270828247
Batch 47/64 loss: 0.25153660774230957
Batch 48/64 loss: 0.2626842260360718
Batch 49/64 loss: 0.2518928647041321
Batch 50/64 loss: 0.2529972195625305
Batch 51/64 loss: 0.27089226245880127
Batch 52/64 loss: 0.25112712383270264
Batch 53/64 loss: 0.25556373596191406
Batch 54/64 loss: 0.24841266870498657
Batch 55/64 loss: 0.24790441989898682
Batch 56/64 loss: 0.2537587881088257
Batch 57/64 loss: 0.26541054248809814
Batch 58/64 loss: 0.2602355480194092
Batch 59/64 loss: 0.2518693208694458
Batch 60/64 loss: 0.2606170177459717
Batch 61/64 loss: 0.26011109352111816
Batch 62/64 loss: 0.2707672119140625
Batch 63/64 loss: 0.2580382227897644
Batch 64/64 loss: 0.25743722915649414
Epoch 174  Train loss: 0.25618275754591996  Val loss: 0.2776077637557721
Epoch 175
-------------------------------
Batch 1/64 loss: 0.2615715265274048
Batch 2/64 loss: 0.2591036558151245
Batch 3/64 loss: 0.2602052092552185
Batch 4/64 loss: 0.25617337226867676
Batch 5/64 loss: 0.2540883421897888
Batch 6/64 loss: 0.25544655323028564
Batch 7/64 loss: 0.2501840591430664
Batch 8/64 loss: 0.2620917558670044
Batch 9/64 loss: 0.2517634630203247
Batch 10/64 loss: 0.2576572895050049
Batch 11/64 loss: 0.2602248191833496
Batch 12/64 loss: 0.25476711988449097
Batch 13/64 loss: 0.2631317377090454
Batch 14/64 loss: 0.2523878812789917
Batch 15/64 loss: 0.2436600923538208
Batch 16/64 loss: 0.25533366203308105
Batch 17/64 loss: 0.2569701075553894
Batch 18/64 loss: 0.2461709976196289
Batch 19/64 loss: 0.2601986527442932
Batch 20/64 loss: 0.2527402639389038
Batch 21/64 loss: 0.2539048194885254
Batch 22/64 loss: 0.2510896921157837
Batch 23/64 loss: 0.26005637645721436
Batch 24/64 loss: 0.2596611976623535
Batch 25/64 loss: 0.2495918869972229
Batch 26/64 loss: 0.2536783218383789
Batch 27/64 loss: 0.2621358633041382
Batch 28/64 loss: 0.2508082389831543
Batch 29/64 loss: 0.25242865085601807
Batch 30/64 loss: 0.256039559841156
Batch 31/64 loss: 0.25649893283843994
Batch 32/64 loss: 0.2554272413253784
Batch 33/64 loss: 0.2557687759399414
Batch 34/64 loss: 0.252368688583374
Batch 35/64 loss: 0.25374048948287964
Batch 36/64 loss: 0.258697509765625
Batch 37/64 loss: 0.25560736656188965
Batch 38/64 loss: 0.2647515535354614
Batch 39/64 loss: 0.26028454303741455
Batch 40/64 loss: 0.2709031105041504
Batch 41/64 loss: 0.2638397812843323
Batch 42/64 loss: 0.2633662223815918
Batch 43/64 loss: 0.2537265419960022
Batch 44/64 loss: 0.25733518600463867
Batch 45/64 loss: 0.25906360149383545
Batch 46/64 loss: 0.2513481378555298
Batch 47/64 loss: 0.2564612627029419
Batch 48/64 loss: 0.26390159130096436
Batch 49/64 loss: 0.2599877715110779
Batch 50/64 loss: 0.2594106197357178
Batch 51/64 loss: 0.2518627643585205
Batch 52/64 loss: 0.2512606382369995
Batch 53/64 loss: 0.25644803047180176
Batch 54/64 loss: 0.25700587034225464
Batch 55/64 loss: 0.26151329278945923
Batch 56/64 loss: 0.26025378704071045
Batch 57/64 loss: 0.260745644569397
Batch 58/64 loss: 0.2572331428527832
Batch 59/64 loss: 0.2493762969970703
Batch 60/64 loss: 0.2594650387763977
Batch 61/64 loss: 0.254496693611145
Batch 62/64 loss: 0.2528911828994751
Batch 63/64 loss: 0.2571502923965454
Batch 64/64 loss: 0.2512436509132385
Epoch 175  Train loss: 0.2565316001574198  Val loss: 0.278849823573201
Epoch 176
-------------------------------
Batch 1/64 loss: 0.2638481855392456
Batch 2/64 loss: 0.2642306089401245
Batch 3/64 loss: 0.25486916303634644
Batch 4/64 loss: 0.24981820583343506
Batch 5/64 loss: 0.2562607526779175
Batch 6/64 loss: 0.2518463134765625
Batch 7/64 loss: 0.2529451251029968
Batch 8/64 loss: 0.2573056221008301
Batch 9/64 loss: 0.25553417205810547
Batch 10/64 loss: 0.2593557834625244
Batch 11/64 loss: 0.2537875175476074
Batch 12/64 loss: 0.26048171520233154
Batch 13/64 loss: 0.25405728816986084
Batch 14/64 loss: 0.25357961654663086
Batch 15/64 loss: 0.2564849853515625
Batch 16/64 loss: 0.25131189823150635
Batch 17/64 loss: 0.2606443166732788
Batch 18/64 loss: 0.26564013957977295
Batch 19/64 loss: 0.25538480281829834
Batch 20/64 loss: 0.2580093741416931
Batch 21/64 loss: 0.261218786239624
Batch 22/64 loss: 0.24788695573806763
Batch 23/64 loss: 0.25600922107696533
Batch 24/64 loss: 0.25444459915161133
Batch 25/64 loss: 0.2594517469406128
Batch 26/64 loss: 0.25560253858566284
Batch 27/64 loss: 0.25707876682281494
Batch 28/64 loss: 0.2618870139122009
Batch 29/64 loss: 0.24665337800979614
Batch 30/64 loss: 0.2569923996925354
Batch 31/64 loss: 0.2541942596435547
Batch 32/64 loss: 0.25085461139678955
Batch 33/64 loss: 0.2537980079650879
Batch 34/64 loss: 0.25345420837402344
Batch 35/64 loss: 0.263879656791687
Batch 36/64 loss: 0.25496697425842285
Batch 37/64 loss: 0.2557331919670105
Batch 38/64 loss: 0.2554253935813904
Batch 39/64 loss: 0.2516951560974121
Batch 40/64 loss: 0.2634052038192749
Batch 41/64 loss: 0.252363383769989
Batch 42/64 loss: 0.2476484179496765
Batch 43/64 loss: 0.2518298029899597
Batch 44/64 loss: 0.2619319558143616
Batch 45/64 loss: 0.25280261039733887
Batch 46/64 loss: 0.25761914253234863
Batch 47/64 loss: 0.24962151050567627
Batch 48/64 loss: 0.2538025975227356
Batch 49/64 loss: 0.24789106845855713
Batch 50/64 loss: 0.24891167879104614
Batch 51/64 loss: 0.2507166862487793
Batch 52/64 loss: 0.2628430128097534
Batch 53/64 loss: 0.2561342716217041
Batch 54/64 loss: 0.2531348466873169
Batch 55/64 loss: 0.25885844230651855
Batch 56/64 loss: 0.25945979356765747
Batch 57/64 loss: 0.2537041902542114
Batch 58/64 loss: 0.26144659519195557
Batch 59/64 loss: 0.2650003433227539
Batch 60/64 loss: 0.25926077365875244
Batch 61/64 loss: 0.2580595016479492
Batch 62/64 loss: 0.2589731216430664
Batch 63/64 loss: 0.2557523846626282
Batch 64/64 loss: 0.24832665920257568
Epoch 176  Train loss: 0.25590649071861715  Val loss: 0.2806665198909458
Epoch 177
-------------------------------
Batch 1/64 loss: 0.2574993371963501
Batch 2/64 loss: 0.24723750352859497
Batch 3/64 loss: 0.2552962899208069
Batch 4/64 loss: 0.2588214874267578
Batch 5/64 loss: 0.2541183829307556
Batch 6/64 loss: 0.25526362657546997
Batch 7/64 loss: 0.2550088167190552
Batch 8/64 loss: 0.25201451778411865
Batch 9/64 loss: 0.2598811388015747
Batch 10/64 loss: 0.25641071796417236
Batch 11/64 loss: 0.2532889246940613
Batch 12/64 loss: 0.25440704822540283
Batch 13/64 loss: 0.26041942834854126
Batch 14/64 loss: 0.25434279441833496
Batch 15/64 loss: 0.2597798705101013
Batch 16/64 loss: 0.2527998685836792
Batch 17/64 loss: 0.2543675899505615
Batch 18/64 loss: 0.2546626925468445
Batch 19/64 loss: 0.25172674655914307
Batch 20/64 loss: 0.250521183013916
Batch 21/64 loss: 0.2512972950935364
Batch 22/64 loss: 0.25649261474609375
Batch 23/64 loss: 0.2604296803474426
Batch 24/64 loss: 0.25601518154144287
Batch 25/64 loss: 0.2509887218475342
Batch 26/64 loss: 0.2574503421783447
Batch 27/64 loss: 0.25252217054367065
Batch 28/64 loss: 0.2559317350387573
Batch 29/64 loss: 0.24938207864761353
Batch 30/64 loss: 0.2519545555114746
Batch 31/64 loss: 0.2543182373046875
Batch 32/64 loss: 0.25567787885665894
Batch 33/64 loss: 0.24858999252319336
Batch 34/64 loss: 0.26056694984436035
Batch 35/64 loss: 0.24746191501617432
Batch 36/64 loss: 0.2505941390991211
Batch 37/64 loss: 0.25567352771759033
Batch 38/64 loss: 0.2525007128715515
Batch 39/64 loss: 0.25046926736831665
Batch 40/64 loss: 0.25757789611816406
Batch 41/64 loss: 0.2551811933517456
Batch 42/64 loss: 0.2525407075881958
Batch 43/64 loss: 0.2518181800842285
Batch 44/64 loss: 0.26227813959121704
Batch 45/64 loss: 0.25186604261398315
Batch 46/64 loss: 0.25692951679229736
Batch 47/64 loss: 0.2633870840072632
Batch 48/64 loss: 0.2662498950958252
Batch 49/64 loss: 0.2578311562538147
Batch 50/64 loss: 0.24724656343460083
Batch 51/64 loss: 0.26419585943222046
Batch 52/64 loss: 0.2551997900009155
Batch 53/64 loss: 0.2600862979888916
Batch 54/64 loss: 0.25406819581985474
Batch 55/64 loss: 0.2637602686882019
Batch 56/64 loss: 0.24679052829742432
Batch 57/64 loss: 0.254130482673645
Batch 58/64 loss: 0.255928099155426
Batch 59/64 loss: 0.26425135135650635
Batch 60/64 loss: 0.2525976300239563
Batch 61/64 loss: 0.259810209274292
Batch 62/64 loss: 0.2721938490867615
Batch 63/64 loss: 0.25732994079589844
Batch 64/64 loss: 0.2580028772354126
Epoch 177  Train loss: 0.2555754666234933  Val loss: 0.2764487924035062
Saving best model, epoch: 177
Epoch 178
-------------------------------
Batch 1/64 loss: 0.2541697025299072
Batch 2/64 loss: 0.26112300157546997
Batch 3/64 loss: 0.24351584911346436
Batch 4/64 loss: 0.24752211570739746
Batch 5/64 loss: 0.2616419792175293
Batch 6/64 loss: 0.2553279995918274
Batch 7/64 loss: 0.2664557695388794
Batch 8/64 loss: 0.2549610733985901
Batch 9/64 loss: 0.2581748962402344
Batch 10/64 loss: 0.25475752353668213
Batch 11/64 loss: 0.24636536836624146
Batch 12/64 loss: 0.25200319290161133
Batch 13/64 loss: 0.26235461235046387
Batch 14/64 loss: 0.25573068857192993
Batch 15/64 loss: 0.25261783599853516
Batch 16/64 loss: 0.260418176651001
Batch 17/64 loss: 0.25998222827911377
Batch 18/64 loss: 0.24737763404846191
Batch 19/64 loss: 0.26041167974472046
Batch 20/64 loss: 0.26158565282821655
Batch 21/64 loss: 0.25005024671554565
Batch 22/64 loss: 0.2474961280822754
Batch 23/64 loss: 0.25750720500946045
Batch 24/64 loss: 0.25081390142440796
Batch 25/64 loss: 0.25450706481933594
Batch 26/64 loss: 0.2634962797164917
Batch 27/64 loss: 0.25720781087875366
Batch 28/64 loss: 0.25523102283477783
Batch 29/64 loss: 0.24544966220855713
Batch 30/64 loss: 0.25310301780700684
Batch 31/64 loss: 0.2506309747695923
Batch 32/64 loss: 0.25503838062286377
Batch 33/64 loss: 0.25977224111557007
Batch 34/64 loss: 0.2605431079864502
Batch 35/64 loss: 0.2538543939590454
Batch 36/64 loss: 0.2532414197921753
Batch 37/64 loss: 0.25975924730300903
Batch 38/64 loss: 0.25394362211227417
Batch 39/64 loss: 0.2565210461616516
Batch 40/64 loss: 0.26770150661468506
Batch 41/64 loss: 0.2447117567062378
Batch 42/64 loss: 0.2594761848449707
Batch 43/64 loss: 0.2637801170349121
Batch 44/64 loss: 0.2529069185256958
Batch 45/64 loss: 0.2555086016654968
Batch 46/64 loss: 0.2583070397377014
Batch 47/64 loss: 0.24341917037963867
Batch 48/64 loss: 0.25637269020080566
Batch 49/64 loss: 0.26279836893081665
Batch 50/64 loss: 0.25096428394317627
Batch 51/64 loss: 0.257771372795105
Batch 52/64 loss: 0.25507164001464844
Batch 53/64 loss: 0.26237934827804565
Batch 54/64 loss: 0.2572038173675537
Batch 55/64 loss: 0.2558487057685852
Batch 56/64 loss: 0.26280808448791504
Batch 57/64 loss: 0.25526416301727295
Batch 58/64 loss: 0.2630707025527954
Batch 59/64 loss: 0.24850499629974365
Batch 60/64 loss: 0.253375768661499
Batch 61/64 loss: 0.26382482051849365
Batch 62/64 loss: 0.24871772527694702
Batch 63/64 loss: 0.27113986015319824
Batch 64/64 loss: 0.26226067543029785
Epoch 178  Train loss: 0.256035873001697  Val loss: 0.27767110505874215
Epoch 179
-------------------------------
Batch 1/64 loss: 0.24857527017593384
Batch 2/64 loss: 0.2504310607910156
Batch 3/64 loss: 0.2436283826828003
Batch 4/64 loss: 0.25818586349487305
Batch 5/64 loss: 0.2589983344078064
Batch 6/64 loss: 0.2545931339263916
Batch 7/64 loss: 0.25298845767974854
Batch 8/64 loss: 0.2447948455810547
Batch 9/64 loss: 0.2643073797225952
Batch 10/64 loss: 0.2605808973312378
Batch 11/64 loss: 0.25711798667907715
Batch 12/64 loss: 0.260018527507782
Batch 13/64 loss: 0.25622594356536865
Batch 14/64 loss: 0.2580852508544922
Batch 15/64 loss: 0.26160311698913574
Batch 16/64 loss: 0.24818778038024902
Batch 17/64 loss: 0.25859349966049194
Batch 18/64 loss: 0.25847721099853516
Batch 19/64 loss: 0.25438570976257324
Batch 20/64 loss: 0.24721229076385498
Batch 21/64 loss: 0.25641441345214844
Batch 22/64 loss: 0.2545415163040161
Batch 23/64 loss: 0.2599697709083557
Batch 24/64 loss: 0.25430625677108765
Batch 25/64 loss: 0.2691187262535095
Batch 26/64 loss: 0.2549050450325012
Batch 27/64 loss: 0.2494666576385498
Batch 28/64 loss: 0.2542715072631836
Batch 29/64 loss: 0.263278067111969
Batch 30/64 loss: 0.25356829166412354
Batch 31/64 loss: 0.24604177474975586
Batch 32/64 loss: 0.25132298469543457
Batch 33/64 loss: 0.2548251152038574
Batch 34/64 loss: 0.2504465579986572
Batch 35/64 loss: 0.2579307556152344
Batch 36/64 loss: 0.25146937370300293
Batch 37/64 loss: 0.25021088123321533
Batch 38/64 loss: 0.2598687410354614
Batch 39/64 loss: 0.2482815384864807
Batch 40/64 loss: 0.24516499042510986
Batch 41/64 loss: 0.24995559453964233
Batch 42/64 loss: 0.25889623165130615
Batch 43/64 loss: 0.2568480968475342
Batch 44/64 loss: 0.2451348900794983
Batch 45/64 loss: 0.243405282497406
Batch 46/64 loss: 0.2619761824607849
Batch 47/64 loss: 0.26061272621154785
Batch 48/64 loss: 0.25446581840515137
Batch 49/64 loss: 0.2595164179801941
Batch 50/64 loss: 0.260616660118103
Batch 51/64 loss: 0.26016902923583984
Batch 52/64 loss: 0.257279634475708
Batch 53/64 loss: 0.2636909484863281
Batch 54/64 loss: 0.2587886452674866
Batch 55/64 loss: 0.26059091091156006
Batch 56/64 loss: 0.2559983730316162
Batch 57/64 loss: 0.2577946186065674
Batch 58/64 loss: 0.25064027309417725
Batch 59/64 loss: 0.2548459768295288
Batch 60/64 loss: 0.2680414319038391
Batch 61/64 loss: 0.2514376640319824
Batch 62/64 loss: 0.2569083571434021
Batch 63/64 loss: 0.25725483894348145
Batch 64/64 loss: 0.26245296001434326
Epoch 179  Train loss: 0.25543689774531947  Val loss: 0.27670009480309243
Epoch 180
-------------------------------
Batch 1/64 loss: 0.24706590175628662
Batch 2/64 loss: 0.25698256492614746
Batch 3/64 loss: 0.2621821165084839
Batch 4/64 loss: 0.2570068836212158
Batch 5/64 loss: 0.2576195001602173
Batch 6/64 loss: 0.25272905826568604
Batch 7/64 loss: 0.24923336505889893
Batch 8/64 loss: 0.25601279735565186
Batch 9/64 loss: 0.25989043712615967
Batch 10/64 loss: 0.2520737648010254
Batch 11/64 loss: 0.24943912029266357
Batch 12/64 loss: 0.2603437900543213
Batch 13/64 loss: 0.256982684135437
Batch 14/64 loss: 0.25233668088912964
Batch 15/64 loss: 0.2523021697998047
Batch 16/64 loss: 0.2564808130264282
Batch 17/64 loss: 0.25537222623825073
Batch 18/64 loss: 0.255964994430542
Batch 19/64 loss: 0.2562481164932251
Batch 20/64 loss: 0.2570761442184448
Batch 21/64 loss: 0.25915074348449707
Batch 22/64 loss: 0.2573656439781189
Batch 23/64 loss: 0.2511715888977051
Batch 24/64 loss: 0.2517547607421875
Batch 25/64 loss: 0.24168086051940918
Batch 26/64 loss: 0.25493162870407104
Batch 27/64 loss: 0.2608262300491333
Batch 28/64 loss: 0.25374293327331543
Batch 29/64 loss: 0.2478961944580078
Batch 30/64 loss: 0.24322134256362915
Batch 31/64 loss: 0.2501182556152344
Batch 32/64 loss: 0.2648545503616333
Batch 33/64 loss: 0.24938249588012695
Batch 34/64 loss: 0.2555192708969116
Batch 35/64 loss: 0.24728405475616455
Batch 36/64 loss: 0.24905771017074585
Batch 37/64 loss: 0.2569847106933594
Batch 38/64 loss: 0.25372326374053955
Batch 39/64 loss: 0.24553894996643066
Batch 40/64 loss: 0.25337886810302734
Batch 41/64 loss: 0.25875020027160645
Batch 42/64 loss: 0.2628241777420044
Batch 43/64 loss: 0.26222121715545654
Batch 44/64 loss: 0.2592921853065491
Batch 45/64 loss: 0.25048398971557617
Batch 46/64 loss: 0.2551671862602234
Batch 47/64 loss: 0.24590039253234863
Batch 48/64 loss: 0.24965417385101318
Batch 49/64 loss: 0.25230175256729126
Batch 50/64 loss: 0.24956166744232178
Batch 51/64 loss: 0.2559494972229004
Batch 52/64 loss: 0.25721102952957153
Batch 53/64 loss: 0.26790255308151245
Batch 54/64 loss: 0.2616363763809204
Batch 55/64 loss: 0.24949955940246582
Batch 56/64 loss: 0.24509704113006592
Batch 57/64 loss: 0.26445096731185913
Batch 58/64 loss: 0.2593258023262024
Batch 59/64 loss: 0.25807297229766846
Batch 60/64 loss: 0.2569699287414551
Batch 61/64 loss: 0.25523650646209717
Batch 62/64 loss: 0.26749253273010254
Batch 63/64 loss: 0.25844085216522217
Batch 64/64 loss: 0.24922382831573486
Epoch 180  Train loss: 0.25476529598236086  Val loss: 0.2778032133259724
Epoch 181
-------------------------------
Batch 1/64 loss: 0.25012707710266113
Batch 2/64 loss: 0.25635141134262085
Batch 3/64 loss: 0.2526732087135315
Batch 4/64 loss: 0.2555595636367798
Batch 5/64 loss: 0.24610698223114014
Batch 6/64 loss: 0.24546557664871216
Batch 7/64 loss: 0.264462947845459
Batch 8/64 loss: 0.24790716171264648
Batch 9/64 loss: 0.2592710256576538
Batch 10/64 loss: 0.261730432510376
Batch 11/64 loss: 0.2556067705154419
Batch 12/64 loss: 0.2563144564628601
Batch 13/64 loss: 0.24882161617279053
Batch 14/64 loss: 0.25496339797973633
Batch 15/64 loss: 0.25173860788345337
Batch 16/64 loss: 0.2517735958099365
Batch 17/64 loss: 0.2554394006729126
Batch 18/64 loss: 0.24666357040405273
Batch 19/64 loss: 0.25384068489074707
Batch 20/64 loss: 0.26009994745254517
Batch 21/64 loss: 0.26006239652633667
Batch 22/64 loss: 0.2681325078010559
Batch 23/64 loss: 0.25773119926452637
Batch 24/64 loss: 0.26247286796569824
Batch 25/64 loss: 0.2503313422203064
Batch 26/64 loss: 0.2528078556060791
Batch 27/64 loss: 0.2603153586387634
Batch 28/64 loss: 0.2528425455093384
Batch 29/64 loss: 0.2512379288673401
Batch 30/64 loss: 0.2571015954017639
Batch 31/64 loss: 0.2470901608467102
Batch 32/64 loss: 0.2523527145385742
Batch 33/64 loss: 0.24963915348052979
Batch 34/64 loss: 0.252282977104187
Batch 35/64 loss: 0.25354838371276855
Batch 36/64 loss: 0.2578429579734802
Batch 37/64 loss: 0.2650209665298462
Batch 38/64 loss: 0.24679714441299438
Batch 39/64 loss: 0.26026082038879395
Batch 40/64 loss: 0.25564658641815186
Batch 41/64 loss: 0.2525516748428345
Batch 42/64 loss: 0.2619154453277588
Batch 43/64 loss: 0.24947619438171387
Batch 44/64 loss: 0.2539865970611572
Batch 45/64 loss: 0.2564377784729004
Batch 46/64 loss: 0.2524944543838501
Batch 47/64 loss: 0.25464916229248047
Batch 48/64 loss: 0.2635754346847534
Batch 49/64 loss: 0.24907737970352173
Batch 50/64 loss: 0.2478848099708557
Batch 51/64 loss: 0.25116419792175293
Batch 52/64 loss: 0.2535257339477539
Batch 53/64 loss: 0.2591238021850586
Batch 54/64 loss: 0.25825273990631104
Batch 55/64 loss: 0.26117652654647827
Batch 56/64 loss: 0.25485682487487793
Batch 57/64 loss: 0.2612013816833496
Batch 58/64 loss: 0.2579593062400818
Batch 59/64 loss: 0.2551616430282593
Batch 60/64 loss: 0.25911182165145874
Batch 61/64 loss: 0.25433117151260376
Batch 62/64 loss: 0.2683808207511902
Batch 63/64 loss: 0.2565420866012573
Batch 64/64 loss: 0.2557133436203003
Epoch 181  Train loss: 0.2552636375614241  Val loss: 0.27841107275887456
Epoch 182
-------------------------------
Batch 1/64 loss: 0.24823391437530518
Batch 2/64 loss: 0.2547439932823181
Batch 3/64 loss: 0.25042247772216797
Batch 4/64 loss: 0.253501296043396
Batch 5/64 loss: 0.24803626537322998
Batch 6/64 loss: 0.25102317333221436
Batch 7/64 loss: 0.24891173839569092
Batch 8/64 loss: 0.26141059398651123
Batch 9/64 loss: 0.2521688938140869
Batch 10/64 loss: 0.248907208442688
Batch 11/64 loss: 0.2437272071838379
Batch 12/64 loss: 0.2567700743675232
Batch 13/64 loss: 0.25025999546051025
Batch 14/64 loss: 0.25278395414352417
Batch 15/64 loss: 0.2544918656349182
Batch 16/64 loss: 0.2517986297607422
Batch 17/64 loss: 0.2579907178878784
Batch 18/64 loss: 0.25813519954681396
Batch 19/64 loss: 0.26280200481414795
Batch 20/64 loss: 0.24901211261749268
Batch 21/64 loss: 0.25234413146972656
Batch 22/64 loss: 0.24914848804473877
Batch 23/64 loss: 0.2579859495162964
Batch 24/64 loss: 0.25361186265945435
Batch 25/64 loss: 0.2501600980758667
Batch 26/64 loss: 0.2567272186279297
Batch 27/64 loss: 0.2506255507469177
Batch 28/64 loss: 0.25442206859588623
Batch 29/64 loss: 0.26103031635284424
Batch 30/64 loss: 0.2571427822113037
Batch 31/64 loss: 0.24464476108551025
Batch 32/64 loss: 0.2551923990249634
Batch 33/64 loss: 0.25636518001556396
Batch 34/64 loss: 0.25217050313949585
Batch 35/64 loss: 0.25567495822906494
Batch 36/64 loss: 0.250102162361145
Batch 37/64 loss: 0.2548277974128723
Batch 38/64 loss: 0.2559810280799866
Batch 39/64 loss: 0.25533008575439453
Batch 40/64 loss: 0.24784082174301147
Batch 41/64 loss: 0.2565808892250061
Batch 42/64 loss: 0.2575001120567322
Batch 43/64 loss: 0.25249481201171875
Batch 44/64 loss: 0.2558821439743042
Batch 45/64 loss: 0.2531367540359497
Batch 46/64 loss: 0.24974572658538818
Batch 47/64 loss: 0.26477599143981934
Batch 48/64 loss: 0.2592872977256775
Batch 49/64 loss: 0.26402032375335693
Batch 50/64 loss: 0.25338315963745117
Batch 51/64 loss: 0.25403815507888794
Batch 52/64 loss: 0.25035232305526733
Batch 53/64 loss: 0.25761497020721436
Batch 54/64 loss: 0.2636733651161194
Batch 55/64 loss: 0.25864875316619873
Batch 56/64 loss: 0.24969303607940674
Batch 57/64 loss: 0.2636008858680725
Batch 58/64 loss: 0.2542911767959595
Batch 59/64 loss: 0.2529325485229492
Batch 60/64 loss: 0.2453526258468628
Batch 61/64 loss: 0.2547423243522644
Batch 62/64 loss: 0.26162993907928467
Batch 63/64 loss: 0.26014184951782227
Batch 64/64 loss: 0.24901795387268066
Epoch 182  Train loss: 0.2542234056136187  Val loss: 0.2779043798184477
Epoch 183
-------------------------------
Batch 1/64 loss: 0.2523287534713745
Batch 2/64 loss: 0.25650519132614136
Batch 3/64 loss: 0.24857139587402344
Batch 4/64 loss: 0.25294792652130127
Batch 5/64 loss: 0.2568020820617676
Batch 6/64 loss: 0.2526533007621765
Batch 7/64 loss: 0.2660122513771057
Batch 8/64 loss: 0.2611005902290344
Batch 9/64 loss: 0.2561091184616089
Batch 10/64 loss: 0.2475740909576416
Batch 11/64 loss: 0.2604811191558838
Batch 12/64 loss: 0.25930607318878174
Batch 13/64 loss: 0.2504177689552307
Batch 14/64 loss: 0.24746179580688477
Batch 15/64 loss: 0.25114572048187256
Batch 16/64 loss: 0.2533946633338928
Batch 17/64 loss: 0.2660132646560669
Batch 18/64 loss: 0.2530655860900879
Batch 19/64 loss: 0.25714433193206787
Batch 20/64 loss: 0.2557011842727661
Batch 21/64 loss: 0.2567305564880371
Batch 22/64 loss: 0.25148940086364746
Batch 23/64 loss: 0.25575441122055054
Batch 24/64 loss: 0.2584933638572693
Batch 25/64 loss: 0.2587876319885254
Batch 26/64 loss: 0.25890910625457764
Batch 27/64 loss: 0.2527388334274292
Batch 28/64 loss: 0.2452424168586731
Batch 29/64 loss: 0.26111090183258057
Batch 30/64 loss: 0.25004976987838745
Batch 31/64 loss: 0.25352686643600464
Batch 32/64 loss: 0.25236570835113525
Batch 33/64 loss: 0.25151050090789795
Batch 34/64 loss: 0.24739384651184082
Batch 35/64 loss: 0.25012803077697754
Batch 36/64 loss: 0.2664434313774109
Batch 37/64 loss: 0.26545798778533936
Batch 38/64 loss: 0.25313568115234375
Batch 39/64 loss: 0.24645745754241943
Batch 40/64 loss: 0.2478843331336975
Batch 41/64 loss: 0.2557467222213745
Batch 42/64 loss: 0.25072550773620605
Batch 43/64 loss: 0.24736237525939941
Batch 44/64 loss: 0.24632179737091064
Batch 45/64 loss: 0.2500579357147217
Batch 46/64 loss: 0.25543439388275146
Batch 47/64 loss: 0.25066184997558594
Batch 48/64 loss: 0.2575390934944153
Batch 49/64 loss: 0.2533265948295593
Batch 50/64 loss: 0.2511734962463379
Batch 51/64 loss: 0.2493317723274231
Batch 52/64 loss: 0.2589959502220154
Batch 53/64 loss: 0.2558141350746155
Batch 54/64 loss: 0.25238871574401855
Batch 55/64 loss: 0.2550812363624573
Batch 56/64 loss: 0.2495025396347046
Batch 57/64 loss: 0.24581921100616455
Batch 58/64 loss: 0.2522720694541931
Batch 59/64 loss: 0.25752246379852295
Batch 60/64 loss: 0.2563769817352295
Batch 61/64 loss: 0.2541736364364624
Batch 62/64 loss: 0.25103187561035156
Batch 63/64 loss: 0.25186479091644287
Batch 64/64 loss: 0.25555741786956787
Epoch 183  Train loss: 0.25393787692574893  Val loss: 0.2755764194370545
Saving best model, epoch: 183
Epoch 184
-------------------------------
Batch 1/64 loss: 0.2516235113143921
Batch 2/64 loss: 0.24940192699432373
Batch 3/64 loss: 0.25915491580963135
Batch 4/64 loss: 0.2522090673446655
Batch 5/64 loss: 0.24192941188812256
Batch 6/64 loss: 0.24702119827270508
Batch 7/64 loss: 0.24619215726852417
Batch 8/64 loss: 0.2494327425956726
Batch 9/64 loss: 0.25759822130203247
Batch 10/64 loss: 0.2572702169418335
Batch 11/64 loss: 0.25287920236587524
Batch 12/64 loss: 0.26763981580734253
Batch 13/64 loss: 0.2479088306427002
Batch 14/64 loss: 0.24637997150421143
Batch 15/64 loss: 0.27031898498535156
Batch 16/64 loss: 0.25976282358169556
Batch 17/64 loss: 0.25112175941467285
Batch 18/64 loss: 0.2671056389808655
Batch 19/64 loss: 0.2506134510040283
Batch 20/64 loss: 0.2585495710372925
Batch 21/64 loss: 0.26104414463043213
Batch 22/64 loss: 0.2491600513458252
Batch 23/64 loss: 0.25911152362823486
Batch 24/64 loss: 0.24782299995422363
Batch 25/64 loss: 0.2535824775695801
Batch 26/64 loss: 0.25074464082717896
Batch 27/64 loss: 0.24708187580108643
Batch 28/64 loss: 0.2528994083404541
Batch 29/64 loss: 0.26181304454803467
Batch 30/64 loss: 0.2500736713409424
Batch 31/64 loss: 0.2512187957763672
Batch 32/64 loss: 0.24909913539886475
Batch 33/64 loss: 0.25685179233551025
Batch 34/64 loss: 0.2492833137512207
Batch 35/64 loss: 0.2496626377105713
Batch 36/64 loss: 0.26224029064178467
Batch 37/64 loss: 0.2596420645713806
Batch 38/64 loss: 0.25432848930358887
Batch 39/64 loss: 0.24839627742767334
Batch 40/64 loss: 0.2582724690437317
Batch 41/64 loss: 0.25191253423690796
Batch 42/64 loss: 0.2518749237060547
Batch 43/64 loss: 0.26222145557403564
Batch 44/64 loss: 0.2521064281463623
Batch 45/64 loss: 0.251772940158844
Batch 46/64 loss: 0.2647789716720581
Batch 47/64 loss: 0.24784183502197266
Batch 48/64 loss: 0.24362075328826904
Batch 49/64 loss: 0.24823760986328125
Batch 50/64 loss: 0.24931550025939941
Batch 51/64 loss: 0.25102758407592773
Batch 52/64 loss: 0.2589123845100403
Batch 53/64 loss: 0.24671757221221924
Batch 54/64 loss: 0.25796836614608765
Batch 55/64 loss: 0.2487177848815918
Batch 56/64 loss: 0.25928473472595215
Batch 57/64 loss: 0.25370073318481445
Batch 58/64 loss: 0.24349194765090942
Batch 59/64 loss: 0.25052857398986816
Batch 60/64 loss: 0.2433009147644043
Batch 61/64 loss: 0.25348788499832153
Batch 62/64 loss: 0.25937724113464355
Batch 63/64 loss: 0.2597286105155945
Batch 64/64 loss: 0.27231675386428833
Epoch 184  Train loss: 0.25365658624499454  Val loss: 0.2779069774339289
Epoch 185
-------------------------------
Batch 1/64 loss: 0.2528430223464966
Batch 2/64 loss: 0.25281715393066406
Batch 3/64 loss: 0.244066059589386
Batch 4/64 loss: 0.2480018138885498
Batch 5/64 loss: 0.25044751167297363
Batch 6/64 loss: 0.2475680112838745
Batch 7/64 loss: 0.24548113346099854
Batch 8/64 loss: 0.263036847114563
Batch 9/64 loss: 0.2500951886177063
Batch 10/64 loss: 0.2582336664199829
Batch 11/64 loss: 0.2489088773727417
Batch 12/64 loss: 0.25789111852645874
Batch 13/64 loss: 0.25587499141693115
Batch 14/64 loss: 0.26051557064056396
Batch 15/64 loss: 0.2507898807525635
Batch 16/64 loss: 0.2536284327507019
Batch 17/64 loss: 0.24378299713134766
Batch 18/64 loss: 0.2515438199043274
Batch 19/64 loss: 0.24998581409454346
Batch 20/64 loss: 0.25583165884017944
Batch 21/64 loss: 0.2504633665084839
Batch 22/64 loss: 0.24867123365402222
Batch 23/64 loss: 0.2485935091972351
Batch 24/64 loss: 0.24344921112060547
Batch 25/64 loss: 0.24326777458190918
Batch 26/64 loss: 0.25997674465179443
Batch 27/64 loss: 0.24830055236816406
Batch 28/64 loss: 0.255983829498291
Batch 29/64 loss: 0.2514879107475281
Batch 30/64 loss: 0.2572566270828247
Batch 31/64 loss: 0.25168871879577637
Batch 32/64 loss: 0.2507016062736511
Batch 33/64 loss: 0.25303125381469727
Batch 34/64 loss: 0.2521984577178955
Batch 35/64 loss: 0.2598697543144226
Batch 36/64 loss: 0.24626082181930542
Batch 37/64 loss: 0.25659680366516113
Batch 38/64 loss: 0.2507455348968506
Batch 39/64 loss: 0.2526090145111084
Batch 40/64 loss: 0.25384485721588135
Batch 41/64 loss: 0.2654591202735901
Batch 42/64 loss: 0.2532280683517456
Batch 43/64 loss: 0.25657790899276733
Batch 44/64 loss: 0.2595009207725525
Batch 45/64 loss: 0.24733185768127441
Batch 46/64 loss: 0.26206839084625244
Batch 47/64 loss: 0.25031399726867676
Batch 48/64 loss: 0.25594937801361084
Batch 49/64 loss: 0.25304079055786133
Batch 50/64 loss: 0.2625415325164795
Batch 51/64 loss: 0.260958194732666
Batch 52/64 loss: 0.25028008222579956
Batch 53/64 loss: 0.2506140470504761
Batch 54/64 loss: 0.250874400138855
Batch 55/64 loss: 0.25681281089782715
Batch 56/64 loss: 0.2568378448486328
Batch 57/64 loss: 0.2545328140258789
Batch 58/64 loss: 0.24896448850631714
Batch 59/64 loss: 0.25005197525024414
Batch 60/64 loss: 0.24788427352905273
Batch 61/64 loss: 0.2507258653640747
Batch 62/64 loss: 0.2533841133117676
Batch 63/64 loss: 0.25330281257629395
Batch 64/64 loss: 0.2504549026489258
Epoch 185  Train loss: 0.2527908708534989  Val loss: 0.27744155528209463
Epoch 186
-------------------------------
Batch 1/64 loss: 0.26008909940719604
Batch 2/64 loss: 0.25019848346710205
Batch 3/64 loss: 0.2523736357688904
Batch 4/64 loss: 0.2526860237121582
Batch 5/64 loss: 0.2627473473548889
Batch 6/64 loss: 0.24875390529632568
Batch 7/64 loss: 0.24881970882415771
Batch 8/64 loss: 0.25456082820892334
Batch 9/64 loss: 0.2554205656051636
Batch 10/64 loss: 0.24190998077392578
Batch 11/64 loss: 0.24993574619293213
Batch 12/64 loss: 0.25844383239746094
Batch 13/64 loss: 0.25542569160461426
Batch 14/64 loss: 0.24506789445877075
Batch 15/64 loss: 0.2557377815246582
Batch 16/64 loss: 0.24377155303955078
Batch 17/64 loss: 0.24378764629364014
Batch 18/64 loss: 0.25689685344696045
Batch 19/64 loss: 0.24614965915679932
Batch 20/64 loss: 0.24555623531341553
Batch 21/64 loss: 0.243088960647583
Batch 22/64 loss: 0.2516661286354065
Batch 23/64 loss: 0.2481192946434021
Batch 24/64 loss: 0.24860024452209473
Batch 25/64 loss: 0.257445752620697
Batch 26/64 loss: 0.24808555841445923
Batch 27/64 loss: 0.2513427138328552
Batch 28/64 loss: 0.2498990297317505
Batch 29/64 loss: 0.24828886985778809
Batch 30/64 loss: 0.2529228925704956
Batch 31/64 loss: 0.2556769847869873
Batch 32/64 loss: 0.24341440200805664
Batch 33/64 loss: 0.25603997707366943
Batch 34/64 loss: 0.2529618740081787
Batch 35/64 loss: 0.24712592363357544
Batch 36/64 loss: 0.2507784962654114
Batch 37/64 loss: 0.25471192598342896
Batch 38/64 loss: 0.2552362084388733
Batch 39/64 loss: 0.25726139545440674
Batch 40/64 loss: 0.25274908542633057
Batch 41/64 loss: 0.25548863410949707
Batch 42/64 loss: 0.2528228759765625
Batch 43/64 loss: 0.25222617387771606
Batch 44/64 loss: 0.2524425983428955
Batch 45/64 loss: 0.25151878595352173
Batch 46/64 loss: 0.2576237916946411
Batch 47/64 loss: 0.2535851001739502
Batch 48/64 loss: 0.24788129329681396
Batch 49/64 loss: 0.25002098083496094
Batch 50/64 loss: 0.25917696952819824
Batch 51/64 loss: 0.2552441358566284
Batch 52/64 loss: 0.2607170343399048
Batch 53/64 loss: 0.25492531061172485
Batch 54/64 loss: 0.25240814685821533
Batch 55/64 loss: 0.2547035813331604
Batch 56/64 loss: 0.250516414642334
Batch 57/64 loss: 0.2535884380340576
Batch 58/64 loss: 0.2488342523574829
Batch 59/64 loss: 0.25544273853302
Batch 60/64 loss: 0.25331687927246094
Batch 61/64 loss: 0.25850939750671387
Batch 62/64 loss: 0.26270657777786255
Batch 63/64 loss: 0.2601372003555298
Batch 64/64 loss: 0.2525826096534729
Epoch 186  Train loss: 0.25250231308095594  Val loss: 0.27662424860951007
Epoch 187
-------------------------------
Batch 1/64 loss: 0.250457763671875
Batch 2/64 loss: 0.25076359510421753
Batch 3/64 loss: 0.2503441572189331
Batch 4/64 loss: 0.2507520914077759
Batch 5/64 loss: 0.2500162124633789
Batch 6/64 loss: 0.2375166416168213
Batch 7/64 loss: 0.2498546838760376
Batch 8/64 loss: 0.2517582178115845
Batch 9/64 loss: 0.24912536144256592
Batch 10/64 loss: 0.2486533522605896
Batch 11/64 loss: 0.2548980116844177
Batch 12/64 loss: 0.2466505765914917
Batch 13/64 loss: 0.25091028213500977
Batch 14/64 loss: 0.2518519163131714
Batch 15/64 loss: 0.25329679250717163
Batch 16/64 loss: 0.25521373748779297
Batch 17/64 loss: 0.2623451352119446
Batch 18/64 loss: 0.25554895401000977
Batch 19/64 loss: 0.25479644536972046
Batch 20/64 loss: 0.25378847122192383
Batch 21/64 loss: 0.25064754486083984
Batch 22/64 loss: 0.2554740309715271
Batch 23/64 loss: 0.25223082304000854
Batch 24/64 loss: 0.249639630317688
Batch 25/64 loss: 0.24262171983718872
Batch 26/64 loss: 0.246986985206604
Batch 27/64 loss: 0.2547535300254822
Batch 28/64 loss: 0.25828230381011963
Batch 29/64 loss: 0.2468571662902832
Batch 30/64 loss: 0.252250075340271
Batch 31/64 loss: 0.2472825050354004
Batch 32/64 loss: 0.24898934364318848
Batch 33/64 loss: 0.24830949306488037
Batch 34/64 loss: 0.25302040576934814
Batch 35/64 loss: 0.24904322624206543
Batch 36/64 loss: 0.24646276235580444
Batch 37/64 loss: 0.2495594024658203
Batch 38/64 loss: 0.24508577585220337
Batch 39/64 loss: 0.25908851623535156
Batch 40/64 loss: 0.2518647313117981
Batch 41/64 loss: 0.2501866817474365
Batch 42/64 loss: 0.24890929460525513
Batch 43/64 loss: 0.25829267501831055
Batch 44/64 loss: 0.2570003271102905
Batch 45/64 loss: 0.2593405246734619
Batch 46/64 loss: 0.2587190270423889
Batch 47/64 loss: 0.24535858631134033
Batch 48/64 loss: 0.26039278507232666
Batch 49/64 loss: 0.25240087509155273
Batch 50/64 loss: 0.26084113121032715
Batch 51/64 loss: 0.2522754669189453
Batch 52/64 loss: 0.2521677017211914
Batch 53/64 loss: 0.2521253824234009
Batch 54/64 loss: 0.24837416410446167
Batch 55/64 loss: 0.25606274604797363
Batch 56/64 loss: 0.25926488637924194
Batch 57/64 loss: 0.2621215581893921
Batch 58/64 loss: 0.25595730543136597
Batch 59/64 loss: 0.2563537359237671
Batch 60/64 loss: 0.24890446662902832
Batch 61/64 loss: 0.2594345808029175
Batch 62/64 loss: 0.2540881633758545
Batch 63/64 loss: 0.25442153215408325
Batch 64/64 loss: 0.2547188997268677
Epoch 187  Train loss: 0.25240823755077285  Val loss: 0.27662123847253545
Epoch 188
-------------------------------
Batch 1/64 loss: 0.2529624104499817
Batch 2/64 loss: 0.2529369592666626
Batch 3/64 loss: 0.2537271976470947
Batch 4/64 loss: 0.2529231309890747
Batch 5/64 loss: 0.25004446506500244
Batch 6/64 loss: 0.25201988220214844
Batch 7/64 loss: 0.2534446716308594
Batch 8/64 loss: 0.255026638507843
Batch 9/64 loss: 0.2525668144226074
Batch 10/64 loss: 0.24080407619476318
Batch 11/64 loss: 0.24750185012817383
Batch 12/64 loss: 0.25930559635162354
Batch 13/64 loss: 0.2605079412460327
Batch 14/64 loss: 0.2536855936050415
Batch 15/64 loss: 0.24805551767349243
Batch 16/64 loss: 0.25190842151641846
Batch 17/64 loss: 0.247952401638031
Batch 18/64 loss: 0.2510868310928345
Batch 19/64 loss: 0.24592918157577515
Batch 20/64 loss: 0.2486974000930786
Batch 21/64 loss: 0.2495715618133545
Batch 22/64 loss: 0.25005608797073364
Batch 23/64 loss: 0.25304365158081055
Batch 24/64 loss: 0.24912577867507935
Batch 25/64 loss: 0.24404001235961914
Batch 26/64 loss: 0.24473798274993896
Batch 27/64 loss: 0.24907910823822021
Batch 28/64 loss: 0.25095057487487793
Batch 29/64 loss: 0.2463347315788269
Batch 30/64 loss: 0.2488844394683838
Batch 31/64 loss: 0.2544851303100586
Batch 32/64 loss: 0.24869900941848755
Batch 33/64 loss: 0.2480858564376831
Batch 34/64 loss: 0.256753146648407
Batch 35/64 loss: 0.2594028115272522
Batch 36/64 loss: 0.2544304132461548
Batch 37/64 loss: 0.2511036992073059
Batch 38/64 loss: 0.2529764771461487
Batch 39/64 loss: 0.25787878036499023
Batch 40/64 loss: 0.24972641468048096
Batch 41/64 loss: 0.25067371129989624
Batch 42/64 loss: 0.2616695165634155
Batch 43/64 loss: 0.2550584077835083
Batch 44/64 loss: 0.2561838626861572
Batch 45/64 loss: 0.25130295753479004
Batch 46/64 loss: 0.25249338150024414
Batch 47/64 loss: 0.2573777437210083
Batch 48/64 loss: 0.24679017066955566
Batch 49/64 loss: 0.25150519609451294
Batch 50/64 loss: 0.2542910575866699
Batch 51/64 loss: 0.25375640392303467
Batch 52/64 loss: 0.24809730052947998
Batch 53/64 loss: 0.24978727102279663
Batch 54/64 loss: 0.25183141231536865
Batch 55/64 loss: 0.25619709491729736
Batch 56/64 loss: 0.2586899995803833
Batch 57/64 loss: 0.2504451870918274
Batch 58/64 loss: 0.25928330421447754
Batch 59/64 loss: 0.24743390083312988
Batch 60/64 loss: 0.2503843903541565
Batch 61/64 loss: 0.25356853008270264
Batch 62/64 loss: 0.25590646266937256
Batch 63/64 loss: 0.26173949241638184
Batch 64/64 loss: 0.25161290168762207
Epoch 188  Train loss: 0.2521353581372429  Val loss: 0.27675154692528586
Epoch 189
-------------------------------
Batch 1/64 loss: 0.26754307746887207
Batch 2/64 loss: 0.24609899520874023
Batch 3/64 loss: 0.24224096536636353
Batch 4/64 loss: 0.24536335468292236
Batch 5/64 loss: 0.2581450939178467
Batch 6/64 loss: 0.24336910247802734
Batch 7/64 loss: 0.254393994808197
Batch 8/64 loss: 0.24845194816589355
Batch 9/64 loss: 0.2578319311141968
Batch 10/64 loss: 0.2526639699935913
Batch 11/64 loss: 0.2573460340499878
Batch 12/64 loss: 0.24727988243103027
Batch 13/64 loss: 0.24625509977340698
Batch 14/64 loss: 0.2507355213165283
Batch 15/64 loss: 0.24567806720733643
Batch 16/64 loss: 0.2484506368637085
Batch 17/64 loss: 0.24910426139831543
Batch 18/64 loss: 0.25637030601501465
Batch 19/64 loss: 0.25521767139434814
Batch 20/64 loss: 0.25292956829071045
Batch 21/64 loss: 0.2485055923461914
Batch 22/64 loss: 0.2575254440307617
Batch 23/64 loss: 0.2465968132019043
Batch 24/64 loss: 0.2608204483985901
Batch 25/64 loss: 0.2445765733718872
Batch 26/64 loss: 0.2555365562438965
Batch 27/64 loss: 0.258853554725647
Batch 28/64 loss: 0.24876654148101807
Batch 29/64 loss: 0.24846595525741577
Batch 30/64 loss: 0.24480664730072021
Batch 31/64 loss: 0.25309765338897705
Batch 32/64 loss: 0.2632285952568054
Batch 33/64 loss: 0.24688184261322021
Batch 34/64 loss: 0.24877870082855225
Batch 35/64 loss: 0.24775272607803345
Batch 36/64 loss: 0.24940216541290283
Batch 37/64 loss: 0.2513810396194458
Batch 38/64 loss: 0.245513916015625
Batch 39/64 loss: 0.2623307704925537
Batch 40/64 loss: 0.2437124252319336
Batch 41/64 loss: 0.2550297975540161
Batch 42/64 loss: 0.25760209560394287
Batch 43/64 loss: 0.25361526012420654
Batch 44/64 loss: 0.25161218643188477
Batch 45/64 loss: 0.25782012939453125
Batch 46/64 loss: 0.2614639401435852
Batch 47/64 loss: 0.2636338472366333
Batch 48/64 loss: 0.25581228733062744
Batch 49/64 loss: 0.2532194256782532
Batch 50/64 loss: 0.2574199438095093
Batch 51/64 loss: 0.2617422342300415
Batch 52/64 loss: 0.2493748664855957
Batch 53/64 loss: 0.24990451335906982
Batch 54/64 loss: 0.2540523409843445
Batch 55/64 loss: 0.25715333223342896
Batch 56/64 loss: 0.24645936489105225
Batch 57/64 loss: 0.25561368465423584
Batch 58/64 loss: 0.24557805061340332
Batch 59/64 loss: 0.26047825813293457
Batch 60/64 loss: 0.24897873401641846
Batch 61/64 loss: 0.25198233127593994
Batch 62/64 loss: 0.2513298988342285
Batch 63/64 loss: 0.24925386905670166
Batch 64/64 loss: 0.24191296100616455
Epoch 189  Train loss: 0.25227558519326004  Val loss: 0.2787644277323562
Epoch 190
-------------------------------
Batch 1/64 loss: 0.256717324256897
Batch 2/64 loss: 0.2502661943435669
Batch 3/64 loss: 0.2590392827987671
Batch 4/64 loss: 0.2612186670303345
Batch 5/64 loss: 0.25237101316452026
Batch 6/64 loss: 0.26056742668151855
Batch 7/64 loss: 0.24476969242095947
Batch 8/64 loss: 0.2553218603134155
Batch 9/64 loss: 0.24756979942321777
Batch 10/64 loss: 0.25084608793258667
Batch 11/64 loss: 0.24110567569732666
Batch 12/64 loss: 0.2624577283859253
Batch 13/64 loss: 0.2506089210510254
Batch 14/64 loss: 0.2643451690673828
Batch 15/64 loss: 0.2437295913696289
Batch 16/64 loss: 0.25168848037719727
Batch 17/64 loss: 0.255092978477478
Batch 18/64 loss: 0.2571486830711365
Batch 19/64 loss: 0.2527727484703064
Batch 20/64 loss: 0.25174885988235474
Batch 21/64 loss: 0.24234676361083984
Batch 22/64 loss: 0.2500961422920227
Batch 23/64 loss: 0.24011999368667603
Batch 24/64 loss: 0.2513357400894165
Batch 25/64 loss: 0.25634753704071045
Batch 26/64 loss: 0.24426138401031494
Batch 27/64 loss: 0.2520025968551636
Batch 28/64 loss: 0.24941718578338623
Batch 29/64 loss: 0.24677544832229614
Batch 30/64 loss: 0.24528658390045166
Batch 31/64 loss: 0.25115305185317993
Batch 32/64 loss: 0.2436133623123169
Batch 33/64 loss: 0.25383317470550537
Batch 34/64 loss: 0.25548309087753296
Batch 35/64 loss: 0.25448447465896606
Batch 36/64 loss: 0.2501564621925354
Batch 37/64 loss: 0.24965405464172363
Batch 38/64 loss: 0.2539716958999634
Batch 39/64 loss: 0.2650306820869446
Batch 40/64 loss: 0.2580563426017761
Batch 41/64 loss: 0.2555663585662842
Batch 42/64 loss: 0.26099663972854614
Batch 43/64 loss: 0.2574778199195862
Batch 44/64 loss: 0.25068938732147217
Batch 45/64 loss: 0.2565673589706421
Batch 46/64 loss: 0.25659269094467163
Batch 47/64 loss: 0.2583603858947754
Batch 48/64 loss: 0.25145548582077026
Batch 49/64 loss: 0.2434394359588623
Batch 50/64 loss: 0.2546910047531128
Batch 51/64 loss: 0.2594299912452698
Batch 52/64 loss: 0.25086450576782227
Batch 53/64 loss: 0.24999403953552246
Batch 54/64 loss: 0.24274158477783203
Batch 55/64 loss: 0.24707764387130737
Batch 56/64 loss: 0.25620341300964355
Batch 57/64 loss: 0.24600237607955933
Batch 58/64 loss: 0.2488696575164795
Batch 59/64 loss: 0.2551612854003906
Batch 60/64 loss: 0.25116777420043945
Batch 61/64 loss: 0.24645167589187622
Batch 62/64 loss: 0.2415926456451416
Batch 63/64 loss: 0.25311946868896484
Batch 64/64 loss: 0.2598060369491577
Epoch 190  Train loss: 0.25211261347228403  Val loss: 0.2764787594067682
Epoch 191
-------------------------------
Batch 1/64 loss: 0.24902832508087158
Batch 2/64 loss: 0.258384644985199
Batch 3/64 loss: 0.24438047409057617
Batch 4/64 loss: 0.24786341190338135
Batch 5/64 loss: 0.2510782480239868
Batch 6/64 loss: 0.2619129419326782
Batch 7/64 loss: 0.26220864057540894
Batch 8/64 loss: 0.24809736013412476
Batch 9/64 loss: 0.24988925457000732
Batch 10/64 loss: 0.25061535835266113
Batch 11/64 loss: 0.24527692794799805
Batch 12/64 loss: 0.25477665662765503
Batch 13/64 loss: 0.2567249536514282
Batch 14/64 loss: 0.2534690499305725
Batch 15/64 loss: 0.25817447900772095
Batch 16/64 loss: 0.24739670753479004
Batch 17/64 loss: 0.24224603176116943
Batch 18/64 loss: 0.25786125659942627
Batch 19/64 loss: 0.24922847747802734
Batch 20/64 loss: 0.2482515573501587
Batch 21/64 loss: 0.24996435642242432
Batch 22/64 loss: 0.24845516681671143
Batch 23/64 loss: 0.25021398067474365
Batch 24/64 loss: 0.2492588758468628
Batch 25/64 loss: 0.24803757667541504
Batch 26/64 loss: 0.25078868865966797
Batch 27/64 loss: 0.2581678628921509
Batch 28/64 loss: 0.25154435634613037
Batch 29/64 loss: 0.2613559365272522
Batch 30/64 loss: 0.25280314683914185
Batch 31/64 loss: 0.24668657779693604
Batch 32/64 loss: 0.25116533041000366
Batch 33/64 loss: 0.25514113903045654
Batch 34/64 loss: 0.24920284748077393
Batch 35/64 loss: 0.2493807077407837
Batch 36/64 loss: 0.2538495659828186
Batch 37/64 loss: 0.24947255849838257
Batch 38/64 loss: 0.24688470363616943
Batch 39/64 loss: 0.2497096061706543
Batch 40/64 loss: 0.2506066560745239
Batch 41/64 loss: 0.247484028339386
Batch 42/64 loss: 0.25904107093811035
Batch 43/64 loss: 0.24215900897979736
Batch 44/64 loss: 0.2536197900772095
Batch 45/64 loss: 0.25847160816192627
Batch 46/64 loss: 0.2464885711669922
Batch 47/64 loss: 0.25345027446746826
Batch 48/64 loss: 0.25153231620788574
Batch 49/64 loss: 0.25142645835876465
Batch 50/64 loss: 0.25267255306243896
Batch 51/64 loss: 0.2609214186668396
Batch 52/64 loss: 0.26034367084503174
Batch 53/64 loss: 0.25971519947052
Batch 54/64 loss: 0.25952887535095215
Batch 55/64 loss: 0.24903416633605957
Batch 56/64 loss: 0.2476927638053894
Batch 57/64 loss: 0.24708139896392822
Batch 58/64 loss: 0.25408923625946045
Batch 59/64 loss: 0.24801039695739746
Batch 60/64 loss: 0.24767553806304932
Batch 61/64 loss: 0.25147581100463867
Batch 62/64 loss: 0.25543850660324097
Batch 63/64 loss: 0.24760651588439941
Batch 64/64 loss: 0.25142431259155273
Epoch 191  Train loss: 0.2518130480074415  Val loss: 0.2751665522962092
Saving best model, epoch: 191
Epoch 192
-------------------------------
Batch 1/64 loss: 0.24869513511657715
Batch 2/64 loss: 0.25023114681243896
Batch 3/64 loss: 0.24878919124603271
Batch 4/64 loss: 0.2568345069885254
Batch 5/64 loss: 0.2483118772506714
Batch 6/64 loss: 0.2434229850769043
Batch 7/64 loss: 0.2497032880783081
Batch 8/64 loss: 0.2505948543548584
Batch 9/64 loss: 0.25132477283477783
Batch 10/64 loss: 0.2544010281562805
Batch 11/64 loss: 0.2525692582130432
Batch 12/64 loss: 0.251910924911499
Batch 13/64 loss: 0.25401580333709717
Batch 14/64 loss: 0.2443562150001526
Batch 15/64 loss: 0.24681353569030762
Batch 16/64 loss: 0.25361573696136475
Batch 17/64 loss: 0.24937093257904053
Batch 18/64 loss: 0.24547910690307617
Batch 19/64 loss: 0.24702757596969604
Batch 20/64 loss: 0.24868226051330566
Batch 21/64 loss: 0.2524373531341553
Batch 22/64 loss: 0.2488519549369812
Batch 23/64 loss: 0.24546092748641968
Batch 24/64 loss: 0.2589397430419922
Batch 25/64 loss: 0.24561995267868042
Batch 26/64 loss: 0.2500538229942322
Batch 27/64 loss: 0.24640661478042603
Batch 28/64 loss: 0.24080944061279297
Batch 29/64 loss: 0.24800562858581543
Batch 30/64 loss: 0.24862205982208252
Batch 31/64 loss: 0.25450921058654785
Batch 32/64 loss: 0.2496127486228943
Batch 33/64 loss: 0.24880588054656982
Batch 34/64 loss: 0.2518925666809082
Batch 35/64 loss: 0.24678367376327515
Batch 36/64 loss: 0.25799262523651123
Batch 37/64 loss: 0.2609584331512451
Batch 38/64 loss: 0.250580370426178
Batch 39/64 loss: 0.2539314031600952
Batch 40/64 loss: 0.2538108229637146
Batch 41/64 loss: 0.2537829279899597
Batch 42/64 loss: 0.24109017848968506
Batch 43/64 loss: 0.25723886489868164
Batch 44/64 loss: 0.24610751867294312
Batch 45/64 loss: 0.24225807189941406
Batch 46/64 loss: 0.24837899208068848
Batch 47/64 loss: 0.262363076210022
Batch 48/64 loss: 0.24110627174377441
Batch 49/64 loss: 0.2527424097061157
Batch 50/64 loss: 0.2535218596458435
Batch 51/64 loss: 0.25070178508758545
Batch 52/64 loss: 0.24387365579605103
Batch 53/64 loss: 0.24473726749420166
Batch 54/64 loss: 0.2488466501235962
Batch 55/64 loss: 0.2533191442489624
Batch 56/64 loss: 0.27033495903015137
Batch 57/64 loss: 0.2491949200630188
Batch 58/64 loss: 0.24939900636672974
Batch 59/64 loss: 0.252490758895874
Batch 60/64 loss: 0.2552153468132019
Batch 61/64 loss: 0.2559546232223511
Batch 62/64 loss: 0.24943435192108154
Batch 63/64 loss: 0.24218648672103882
Batch 64/64 loss: 0.25080686807632446
Epoch 192  Train loss: 0.25039403368445  Val loss: 0.27651236638990057
Epoch 193
-------------------------------
Batch 1/64 loss: 0.24668890237808228
Batch 2/64 loss: 0.2490357756614685
Batch 3/64 loss: 0.2554548382759094
Batch 4/64 loss: 0.24955254793167114
Batch 5/64 loss: 0.24373984336853027
Batch 6/64 loss: 0.24969279766082764
Batch 7/64 loss: 0.2544247508049011
Batch 8/64 loss: 0.25539278984069824
Batch 9/64 loss: 0.24892383813858032
Batch 10/64 loss: 0.25770092010498047
Batch 11/64 loss: 0.2474721074104309
Batch 12/64 loss: 0.25496846437454224
Batch 13/64 loss: 0.25047731399536133
Batch 14/64 loss: 0.2554713487625122
Batch 15/64 loss: 0.2544609308242798
Batch 16/64 loss: 0.25340843200683594
Batch 17/64 loss: 0.24929594993591309
Batch 18/64 loss: 0.2528599500656128
Batch 19/64 loss: 0.24939966201782227
Batch 20/64 loss: 0.2517434358596802
Batch 21/64 loss: 0.24742019176483154
Batch 22/64 loss: 0.2593245506286621
Batch 23/64 loss: 0.24368661642074585
Batch 24/64 loss: 0.24677419662475586
Batch 25/64 loss: 0.2448626160621643
Batch 26/64 loss: 0.2508338689804077
Batch 27/64 loss: 0.26080501079559326
Batch 28/64 loss: 0.2498496174812317
Batch 29/64 loss: 0.2433571219444275
Batch 30/64 loss: 0.2545604109764099
Batch 31/64 loss: 0.25721728801727295
Batch 32/64 loss: 0.24900788068771362
Batch 33/64 loss: 0.24841678142547607
Batch 34/64 loss: 0.24906384944915771
Batch 35/64 loss: 0.2582378387451172
Batch 36/64 loss: 0.25040632486343384
Batch 37/64 loss: 0.2517961263656616
Batch 38/64 loss: 0.24892663955688477
Batch 39/64 loss: 0.24730157852172852
Batch 40/64 loss: 0.24541497230529785
Batch 41/64 loss: 0.24588918685913086
Batch 42/64 loss: 0.24644112586975098
Batch 43/64 loss: 0.24798572063446045
Batch 44/64 loss: 0.254957914352417
Batch 45/64 loss: 0.25171077251434326
Batch 46/64 loss: 0.24493050575256348
Batch 47/64 loss: 0.2547317147254944
Batch 48/64 loss: 0.2536088228225708
Batch 49/64 loss: 0.24451357126235962
Batch 50/64 loss: 0.251636266708374
Batch 51/64 loss: 0.2558722496032715
Batch 52/64 loss: 0.25196659564971924
Batch 53/64 loss: 0.24642008543014526
Batch 54/64 loss: 0.25426292419433594
Batch 55/64 loss: 0.2563678026199341
Batch 56/64 loss: 0.26230716705322266
Batch 57/64 loss: 0.2505836486816406
Batch 58/64 loss: 0.2501349449157715
Batch 59/64 loss: 0.24719476699829102
Batch 60/64 loss: 0.25810039043426514
Batch 61/64 loss: 0.24857914447784424
Batch 62/64 loss: 0.2521745562553406
Batch 63/64 loss: 0.2432495355606079
Batch 64/64 loss: 0.24361777305603027
Epoch 193  Train loss: 0.2508825227326038  Val loss: 0.2761877783385339
Epoch 194
-------------------------------
Batch 1/64 loss: 0.24229168891906738
Batch 2/64 loss: 0.2422124147415161
Batch 3/64 loss: 0.26163870096206665
Batch 4/64 loss: 0.2547508478164673
Batch 5/64 loss: 0.25801652669906616
Batch 6/64 loss: 0.2449493408203125
Batch 7/64 loss: 0.24748432636260986
Batch 8/64 loss: 0.24436652660369873
Batch 9/64 loss: 0.24737733602523804
Batch 10/64 loss: 0.2716209888458252
Batch 11/64 loss: 0.25041210651397705
Batch 12/64 loss: 0.2395995855331421
Batch 13/64 loss: 0.2519751191139221
Batch 14/64 loss: 0.24806010723114014
Batch 15/64 loss: 0.25690555572509766
Batch 16/64 loss: 0.2499369978904724
Batch 17/64 loss: 0.2432311773300171
Batch 18/64 loss: 0.2414109706878662
Batch 19/64 loss: 0.2452070116996765
Batch 20/64 loss: 0.25731998682022095
Batch 21/64 loss: 0.24166125059127808
Batch 22/64 loss: 0.25131410360336304
Batch 23/64 loss: 0.25792407989501953
Batch 24/64 loss: 0.2517642378807068
Batch 25/64 loss: 0.25898516178131104
Batch 26/64 loss: 0.25239425897598267
Batch 27/64 loss: 0.24802368879318237
Batch 28/64 loss: 0.24903035163879395
Batch 29/64 loss: 0.2470860481262207
Batch 30/64 loss: 0.24271118640899658
Batch 31/64 loss: 0.2478000521659851
Batch 32/64 loss: 0.24576503038406372
Batch 33/64 loss: 0.2541853189468384
Batch 34/64 loss: 0.2569981813430786
Batch 35/64 loss: 0.25254833698272705
Batch 36/64 loss: 0.25748562812805176
Batch 37/64 loss: 0.24593865871429443
Batch 38/64 loss: 0.24533170461654663
Batch 39/64 loss: 0.243721604347229
Batch 40/64 loss: 0.24627363681793213
Batch 41/64 loss: 0.24762868881225586
Batch 42/64 loss: 0.2515000104904175
Batch 43/64 loss: 0.24732035398483276
Batch 44/64 loss: 0.2562001943588257
Batch 45/64 loss: 0.2432613968849182
Batch 46/64 loss: 0.25906896591186523
Batch 47/64 loss: 0.24914944171905518
Batch 48/64 loss: 0.2551302909851074
Batch 49/64 loss: 0.24606066942214966
Batch 50/64 loss: 0.2527838349342346
Batch 51/64 loss: 0.2510465383529663
Batch 52/64 loss: 0.24737697839736938
Batch 53/64 loss: 0.2522992491722107
Batch 54/64 loss: 0.2555384635925293
Batch 55/64 loss: 0.24664658308029175
Batch 56/64 loss: 0.24922406673431396
Batch 57/64 loss: 0.2463231086730957
Batch 58/64 loss: 0.26187193393707275
Batch 59/64 loss: 0.25341904163360596
Batch 60/64 loss: 0.26381218433380127
Batch 61/64 loss: 0.24730968475341797
Batch 62/64 loss: 0.24880439043045044
Batch 63/64 loss: 0.25208503007888794
Batch 64/64 loss: 0.247844398021698
Epoch 194  Train loss: 0.25043849781447763  Val loss: 0.2764795125554927
Epoch 195
-------------------------------
Batch 1/64 loss: 0.2450193166732788
Batch 2/64 loss: 0.24913787841796875
Batch 3/64 loss: 0.24759316444396973
Batch 4/64 loss: 0.24735486507415771
Batch 5/64 loss: 0.25789153575897217
Batch 6/64 loss: 0.24503052234649658
Batch 7/64 loss: 0.24824023246765137
Batch 8/64 loss: 0.23967134952545166
Batch 9/64 loss: 0.2501787543296814
Batch 10/64 loss: 0.24699199199676514
Batch 11/64 loss: 0.2486676573753357
Batch 12/64 loss: 0.24207115173339844
Batch 13/64 loss: 0.25013017654418945
Batch 14/64 loss: 0.24547266960144043
Batch 15/64 loss: 0.2423231601715088
Batch 16/64 loss: 0.24916565418243408
Batch 17/64 loss: 0.2548810839653015
Batch 18/64 loss: 0.24594104290008545
Batch 19/64 loss: 0.24970734119415283
Batch 20/64 loss: 0.252891480922699
Batch 21/64 loss: 0.2500807046890259
Batch 22/64 loss: 0.24957841634750366
Batch 23/64 loss: 0.24908864498138428
Batch 24/64 loss: 0.24867939949035645
Batch 25/64 loss: 0.24672961235046387
Batch 26/64 loss: 0.2528219223022461
Batch 27/64 loss: 0.25536489486694336
Batch 28/64 loss: 0.2558746337890625
Batch 29/64 loss: 0.2513178586959839
Batch 30/64 loss: 0.2367178201675415
Batch 31/64 loss: 0.2568642497062683
Batch 32/64 loss: 0.2553735375404358
Batch 33/64 loss: 0.2499203085899353
Batch 34/64 loss: 0.26368606090545654
Batch 35/64 loss: 0.2545374035835266
Batch 36/64 loss: 0.24509811401367188
Batch 37/64 loss: 0.24294066429138184
Batch 38/64 loss: 0.24716216325759888
Batch 39/64 loss: 0.24200022220611572
Batch 40/64 loss: 0.25350576639175415
Batch 41/64 loss: 0.2523348331451416
Batch 42/64 loss: 0.2489985227584839
Batch 43/64 loss: 0.25324225425720215
Batch 44/64 loss: 0.24652189016342163
Batch 45/64 loss: 0.2434900999069214
Batch 46/64 loss: 0.24974751472473145
Batch 47/64 loss: 0.25473904609680176
Batch 48/64 loss: 0.2490546703338623
Batch 49/64 loss: 0.24514901638031006
Batch 50/64 loss: 0.2443680763244629
Batch 51/64 loss: 0.2503622770309448
Batch 52/64 loss: 0.24765217304229736
Batch 53/64 loss: 0.2433534860610962
Batch 54/64 loss: 0.26394015550613403
Batch 55/64 loss: 0.25029194355010986
Batch 56/64 loss: 0.26607853174209595
Batch 57/64 loss: 0.2526051998138428
Batch 58/64 loss: 0.26468515396118164
Batch 59/64 loss: 0.2496383786201477
Batch 60/64 loss: 0.25286591053009033
Batch 61/64 loss: 0.2496652603149414
Batch 62/64 loss: 0.25676673650741577
Batch 63/64 loss: 0.24520856142044067
Batch 64/64 loss: 0.23702865839004517
Epoch 195  Train loss: 0.249791915510215  Val loss: 0.2755171834808035
Epoch 196
-------------------------------
Batch 1/64 loss: 0.24105632305145264
Batch 2/64 loss: 0.2470669150352478
Batch 3/64 loss: 0.2503918409347534
Batch 4/64 loss: 0.24687492847442627
Batch 5/64 loss: 0.24348628520965576
Batch 6/64 loss: 0.24892306327819824
Batch 7/64 loss: 0.24679720401763916
Batch 8/64 loss: 0.2510215640068054
Batch 9/64 loss: 0.2592761516571045
Batch 10/64 loss: 0.24946880340576172
Batch 11/64 loss: 0.2493760585784912
Batch 12/64 loss: 0.24593693017959595
Batch 13/64 loss: 0.2548896074295044
Batch 14/64 loss: 0.24481362104415894
Batch 15/64 loss: 0.25096559524536133
Batch 16/64 loss: 0.2571219801902771
Batch 17/64 loss: 0.25598567724227905
Batch 18/64 loss: 0.250851035118103
Batch 19/64 loss: 0.24971413612365723
Batch 20/64 loss: 0.25513964891433716
Batch 21/64 loss: 0.24563568830490112
Batch 22/64 loss: 0.2437363862991333
Batch 23/64 loss: 0.24720001220703125
Batch 24/64 loss: 0.25823521614074707
Batch 25/64 loss: 0.2596762776374817
Batch 26/64 loss: 0.25374919176101685
Batch 27/64 loss: 0.24632304906845093
Batch 28/64 loss: 0.24684208631515503
Batch 29/64 loss: 0.24746596813201904
Batch 30/64 loss: 0.24717336893081665
Batch 31/64 loss: 0.25075697898864746
Batch 32/64 loss: 0.2503318190574646
Batch 33/64 loss: 0.25374728441238403
Batch 34/64 loss: 0.25650572776794434
Batch 35/64 loss: 0.24873805046081543
Batch 36/64 loss: 0.24467921257019043
Batch 37/64 loss: 0.25862205028533936
Batch 38/64 loss: 0.24464428424835205
Batch 39/64 loss: 0.2537238597869873
Batch 40/64 loss: 0.25236308574676514
Batch 41/64 loss: 0.25134217739105225
Batch 42/64 loss: 0.25795865058898926
Batch 43/64 loss: 0.2524418830871582
Batch 44/64 loss: 0.2510240077972412
Batch 45/64 loss: 0.253387451171875
Batch 46/64 loss: 0.2454218864440918
Batch 47/64 loss: 0.25033652782440186
Batch 48/64 loss: 0.2556368112564087
Batch 49/64 loss: 0.25796282291412354
Batch 50/64 loss: 0.24683499336242676
Batch 51/64 loss: 0.25254905223846436
Batch 52/64 loss: 0.2503402829170227
Batch 53/64 loss: 0.24861645698547363
Batch 54/64 loss: 0.25032657384872437
Batch 55/64 loss: 0.2529304027557373
Batch 56/64 loss: 0.24343132972717285
Batch 57/64 loss: 0.2526094913482666
Batch 58/64 loss: 0.24650239944458008
Batch 59/64 loss: 0.24899685382843018
Batch 60/64 loss: 0.25217920541763306
Batch 61/64 loss: 0.24492132663726807
Batch 62/64 loss: 0.24937987327575684
Batch 63/64 loss: 0.248260498046875
Batch 64/64 loss: 0.2560778856277466
Epoch 196  Train loss: 0.2504275504280539  Val loss: 0.27581383170131146
Epoch 197
-------------------------------
Batch 1/64 loss: 0.24417626857757568
Batch 2/64 loss: 0.2420046329498291
Batch 3/64 loss: 0.24313169717788696
Batch 4/64 loss: 0.2504916191101074
Batch 5/64 loss: 0.2471834421157837
Batch 6/64 loss: 0.25605690479278564
Batch 7/64 loss: 0.25211912393569946
Batch 8/64 loss: 0.24029088020324707
Batch 9/64 loss: 0.25792622566223145
Batch 10/64 loss: 0.2502317428588867
Batch 11/64 loss: 0.24993526935577393
Batch 12/64 loss: 0.24298131465911865
Batch 13/64 loss: 0.24574357271194458
Batch 14/64 loss: 0.24657893180847168
Batch 15/64 loss: 0.24489611387252808
Batch 16/64 loss: 0.24702775478363037
Batch 17/64 loss: 0.25024980306625366
Batch 18/64 loss: 0.2571679353713989
Batch 19/64 loss: 0.24361586570739746
Batch 20/64 loss: 0.26239651441574097
Batch 21/64 loss: 0.24900972843170166
Batch 22/64 loss: 0.25068503618240356
Batch 23/64 loss: 0.239116370677948
Batch 24/64 loss: 0.25001323223114014
Batch 25/64 loss: 0.2549554109573364
Batch 26/64 loss: 0.25794196128845215
Batch 27/64 loss: 0.2455921173095703
Batch 28/64 loss: 0.2484074831008911
Batch 29/64 loss: 0.24442332983016968
Batch 30/64 loss: 0.2516971230506897
Batch 31/64 loss: 0.24486511945724487
Batch 32/64 loss: 0.25295835733413696
Batch 33/64 loss: 0.24820148944854736
Batch 34/64 loss: 0.25285232067108154
Batch 35/64 loss: 0.2602119445800781
Batch 36/64 loss: 0.2506043314933777
Batch 37/64 loss: 0.24875593185424805
Batch 38/64 loss: 0.247350811958313
Batch 39/64 loss: 0.2546893358230591
Batch 40/64 loss: 0.2474428415298462
Batch 41/64 loss: 0.2492276430130005
Batch 42/64 loss: 0.25225967168807983
Batch 43/64 loss: 0.2566220760345459
Batch 44/64 loss: 0.24934059381484985
Batch 45/64 loss: 0.24464988708496094
Batch 46/64 loss: 0.24738997220993042
Batch 47/64 loss: 0.2498260736465454
Batch 48/64 loss: 0.2509615421295166
Batch 49/64 loss: 0.2590029835700989
Batch 50/64 loss: 0.26244014501571655
Batch 51/64 loss: 0.24827110767364502
Batch 52/64 loss: 0.2553519010543823
Batch 53/64 loss: 0.24542343616485596
Batch 54/64 loss: 0.24887597560882568
Batch 55/64 loss: 0.2455235719680786
Batch 56/64 loss: 0.2546180486679077
Batch 57/64 loss: 0.25102537870407104
Batch 58/64 loss: 0.23596996068954468
Batch 59/64 loss: 0.24698525667190552
Batch 60/64 loss: 0.2502148151397705
Batch 61/64 loss: 0.2513834238052368
Batch 62/64 loss: 0.2534366846084595
Batch 63/64 loss: 0.2479669451713562
Batch 64/64 loss: 0.25573015213012695
Epoch 197  Train loss: 0.24976540546791226  Val loss: 0.27601899518999445
Epoch 198
-------------------------------
Batch 1/64 loss: 0.2521933913230896
Batch 2/64 loss: 0.24783813953399658
Batch 3/64 loss: 0.24607396125793457
Batch 4/64 loss: 0.24924397468566895
Batch 5/64 loss: 0.24568545818328857
Batch 6/64 loss: 0.24609363079071045
Batch 7/64 loss: 0.24562084674835205
Batch 8/64 loss: 0.25121402740478516
Batch 9/64 loss: 0.2414020299911499
Batch 10/64 loss: 0.25155001878738403
Batch 11/64 loss: 0.2523213028907776
Batch 12/64 loss: 0.24454885721206665
Batch 13/64 loss: 0.24658286571502686
Batch 14/64 loss: 0.24312400817871094
Batch 15/64 loss: 0.2542901039123535
Batch 16/64 loss: 0.2639696002006531
Batch 17/64 loss: 0.25501692295074463
Batch 18/64 loss: 0.23895931243896484
Batch 19/64 loss: 0.26138830184936523
Batch 20/64 loss: 0.25602060556411743
Batch 21/64 loss: 0.2439194917678833
Batch 22/64 loss: 0.24733513593673706
Batch 23/64 loss: 0.25172412395477295
Batch 24/64 loss: 0.24557477235794067
Batch 25/64 loss: 0.2539312243461609
Batch 26/64 loss: 0.24298226833343506
Batch 27/64 loss: 0.24632394313812256
Batch 28/64 loss: 0.24327325820922852
Batch 29/64 loss: 0.24564027786254883
Batch 30/64 loss: 0.2475472092628479
Batch 31/64 loss: 0.25068604946136475
Batch 32/64 loss: 0.24892759323120117
Batch 33/64 loss: 0.24997186660766602
Batch 34/64 loss: 0.24951672554016113
Batch 35/64 loss: 0.2479795217514038
Batch 36/64 loss: 0.2536624073982239
Batch 37/64 loss: 0.25246739387512207
Batch 38/64 loss: 0.25141680240631104
Batch 39/64 loss: 0.24791133403778076
Batch 40/64 loss: 0.254663348197937
Batch 41/64 loss: 0.24614155292510986
Batch 42/64 loss: 0.2562764286994934
Batch 43/64 loss: 0.25021159648895264
Batch 44/64 loss: 0.25169897079467773
Batch 45/64 loss: 0.25046980381011963
Batch 46/64 loss: 0.25127047300338745
Batch 47/64 loss: 0.24806499481201172
Batch 48/64 loss: 0.259990930557251
Batch 49/64 loss: 0.25010204315185547
Batch 50/64 loss: 0.24605214595794678
Batch 51/64 loss: 0.26105189323425293
Batch 52/64 loss: 0.24624550342559814
Batch 53/64 loss: 0.2561761140823364
Batch 54/64 loss: 0.25265568494796753
Batch 55/64 loss: 0.24620813131332397
Batch 56/64 loss: 0.2474147081375122
Batch 57/64 loss: 0.2556716203689575
Batch 58/64 loss: 0.2524442672729492
Batch 59/64 loss: 0.2682199478149414
Batch 60/64 loss: 0.23640435934066772
Batch 61/64 loss: 0.2497064471244812
Batch 62/64 loss: 0.2452331781387329
Batch 63/64 loss: 0.25042903423309326
Batch 64/64 loss: 0.25344663858413696
Epoch 198  Train loss: 0.24998928495481904  Val loss: 0.275744714892607
Epoch 199
-------------------------------
Batch 1/64 loss: 0.24763858318328857
Batch 2/64 loss: 0.2460085153579712
Batch 3/64 loss: 0.2510938048362732
Batch 4/64 loss: 0.24123406410217285
Batch 5/64 loss: 0.24905633926391602
Batch 6/64 loss: 0.24530839920043945
Batch 7/64 loss: 0.2523428201675415
Batch 8/64 loss: 0.24314743280410767
Batch 9/64 loss: 0.24155926704406738
Batch 10/64 loss: 0.24961715936660767
Batch 11/64 loss: 0.24769985675811768
Batch 12/64 loss: 0.2515929937362671
Batch 13/64 loss: 0.2552807331085205
Batch 14/64 loss: 0.24536073207855225
Batch 15/64 loss: 0.24749505519866943
Batch 16/64 loss: 0.23841804265975952
Batch 17/64 loss: 0.2503371238708496
Batch 18/64 loss: 0.252840518951416
Batch 19/64 loss: 0.24800646305084229
Batch 20/64 loss: 0.24973523616790771
Batch 21/64 loss: 0.24358999729156494
Batch 22/64 loss: 0.24492257833480835
Batch 23/64 loss: 0.2574705481529236
Batch 24/64 loss: 0.25550544261932373
Batch 25/64 loss: 0.24553948640823364
Batch 26/64 loss: 0.252951443195343
Batch 27/64 loss: 0.2481653094291687
Batch 28/64 loss: 0.25306105613708496
Batch 29/64 loss: 0.24642956256866455
Batch 30/64 loss: 0.24931448698043823
Batch 31/64 loss: 0.24858474731445312
Batch 32/64 loss: 0.24979591369628906
Batch 33/64 loss: 0.25142669677734375
Batch 34/64 loss: 0.25424671173095703
Batch 35/64 loss: 0.25186657905578613
Batch 36/64 loss: 0.24521654844284058
Batch 37/64 loss: 0.24712932109832764
Batch 38/64 loss: 0.2500525116920471
Batch 39/64 loss: 0.2522960901260376
Batch 40/64 loss: 0.2579585313796997
Batch 41/64 loss: 0.252352774143219
Batch 42/64 loss: 0.2509605288505554
Batch 43/64 loss: 0.24631178379058838
Batch 44/64 loss: 0.2582221031188965
Batch 45/64 loss: 0.24657583236694336
Batch 46/64 loss: 0.2448253035545349
Batch 47/64 loss: 0.26505565643310547
Batch 48/64 loss: 0.25216102600097656
Batch 49/64 loss: 0.2546023726463318
Batch 50/64 loss: 0.2569437026977539
Batch 51/64 loss: 0.2541140913963318
Batch 52/64 loss: 0.24982213973999023
Batch 53/64 loss: 0.2476963996887207
Batch 54/64 loss: 0.2473791241645813
Batch 55/64 loss: 0.24789762496948242
Batch 56/64 loss: 0.2407805323600769
Batch 57/64 loss: 0.24438095092773438
Batch 58/64 loss: 0.24698901176452637
Batch 59/64 loss: 0.24646204710006714
Batch 60/64 loss: 0.2540184259414673
Batch 61/64 loss: 0.2524198293685913
Batch 62/64 loss: 0.2416975498199463
Batch 63/64 loss: 0.24036085605621338
Batch 64/64 loss: 0.2344808578491211
Epoch 199  Train loss: 0.24905391393923293  Val loss: 0.27516660247881386
Epoch 200
-------------------------------
Batch 1/64 loss: 0.2380850911140442
Batch 2/64 loss: 0.2329975962638855
Batch 3/64 loss: 0.24612659215927124
Batch 4/64 loss: 0.2518858313560486
Batch 5/64 loss: 0.23889195919036865
Batch 6/64 loss: 0.2494998574256897
Batch 7/64 loss: 0.25908368825912476
Batch 8/64 loss: 0.24504530429840088
Batch 9/64 loss: 0.2394750714302063
Batch 10/64 loss: 0.24842488765716553
Batch 11/64 loss: 0.25129950046539307
Batch 12/64 loss: 0.2545561194419861
Batch 13/64 loss: 0.24569976329803467
Batch 14/64 loss: 0.24118101596832275
Batch 15/64 loss: 0.24787819385528564
Batch 16/64 loss: 0.25748395919799805
Batch 17/64 loss: 0.24591422080993652
Batch 18/64 loss: 0.25266432762145996
Batch 19/64 loss: 0.24981772899627686
Batch 20/64 loss: 0.24782240390777588
Batch 21/64 loss: 0.2555121183395386
Batch 22/64 loss: 0.24642610549926758
Batch 23/64 loss: 0.24865329265594482
Batch 24/64 loss: 0.24661672115325928
Batch 25/64 loss: 0.2481728196144104
Batch 26/64 loss: 0.25315624475479126
Batch 27/64 loss: 0.25588303804397583
Batch 28/64 loss: 0.24099576473236084
Batch 29/64 loss: 0.2415471076965332
Batch 30/64 loss: 0.244162917137146
Batch 31/64 loss: 0.24976563453674316
Batch 32/64 loss: 0.2528073191642761
Batch 33/64 loss: 0.24827659130096436
Batch 34/64 loss: 0.2483137845993042
Batch 35/64 loss: 0.24335992336273193
Batch 36/64 loss: 0.25212806463241577
Batch 37/64 loss: 0.2455989122390747
Batch 38/64 loss: 0.26628053188323975
Batch 39/64 loss: 0.24011564254760742
Batch 40/64 loss: 0.2548786997795105
Batch 41/64 loss: 0.24059617519378662
Batch 42/64 loss: 0.252344012260437
Batch 43/64 loss: 0.24767088890075684
Batch 44/64 loss: 0.24847400188446045
Batch 45/64 loss: 0.24677729606628418
Batch 46/64 loss: 0.2507550120353699
Batch 47/64 loss: 0.24540406465530396
Batch 48/64 loss: 0.24518072605133057
Batch 49/64 loss: 0.25837457180023193
Batch 50/64 loss: 0.24150347709655762
Batch 51/64 loss: 0.26071059703826904
Batch 52/64 loss: 0.24456572532653809
Batch 53/64 loss: 0.25616776943206787
Batch 54/64 loss: 0.2521516680717468
Batch 55/64 loss: 0.25714385509490967
Batch 56/64 loss: 0.24610096216201782
Batch 57/64 loss: 0.24595904350280762
Batch 58/64 loss: 0.26054489612579346
Batch 59/64 loss: 0.25324928760528564
Batch 60/64 loss: 0.2519127130508423
Batch 61/64 loss: 0.24576592445373535
Batch 62/64 loss: 0.24431955814361572
Batch 63/64 loss: 0.2517364025115967
Batch 64/64 loss: 0.24382615089416504
Epoch 200  Train loss: 0.24873353079253552  Val loss: 0.2746975419857248
Saving best model, epoch: 200
Epoch 201
-------------------------------
Batch 1/64 loss: 0.24580931663513184
Batch 2/64 loss: 0.2444148063659668
Batch 3/64 loss: 0.24044078588485718
Batch 4/64 loss: 0.24185049533843994
Batch 5/64 loss: 0.2462688684463501
Batch 6/64 loss: 0.2592719793319702
Batch 7/64 loss: 0.25331389904022217
Batch 8/64 loss: 0.2388315200805664
Batch 9/64 loss: 0.24677526950836182
Batch 10/64 loss: 0.23963695764541626
Batch 11/64 loss: 0.2445317506790161
Batch 12/64 loss: 0.2359369993209839
Batch 13/64 loss: 0.2505321502685547
Batch 14/64 loss: 0.24727487564086914
Batch 15/64 loss: 0.24263542890548706
Batch 16/64 loss: 0.24821937084197998
Batch 17/64 loss: 0.24135541915893555
Batch 18/64 loss: 0.2482738494873047
Batch 19/64 loss: 0.24740934371948242
Batch 20/64 loss: 0.24528193473815918
Batch 21/64 loss: 0.2518385648727417
Batch 22/64 loss: 0.25402897596359253
Batch 23/64 loss: 0.2527824640274048
Batch 24/64 loss: 0.2507587671279907
Batch 25/64 loss: 0.2480258345603943
Batch 26/64 loss: 0.24761241674423218
Batch 27/64 loss: 0.24108576774597168
Batch 28/64 loss: 0.2449793815612793
Batch 29/64 loss: 0.24779891967773438
Batch 30/64 loss: 0.2439916729927063
Batch 31/64 loss: 0.24603044986724854
Batch 32/64 loss: 0.2539362907409668
Batch 33/64 loss: 0.25144320726394653
Batch 34/64 loss: 0.2422105073928833
Batch 35/64 loss: 0.243413507938385
Batch 36/64 loss: 0.2434297800064087
Batch 37/64 loss: 0.25233930349349976
Batch 38/64 loss: 0.2520526647567749
Batch 39/64 loss: 0.2513023614883423
Batch 40/64 loss: 0.2545959949493408
Batch 41/64 loss: 0.23728466033935547
Batch 42/64 loss: 0.23783040046691895
Batch 43/64 loss: 0.24974948167800903
Batch 44/64 loss: 0.2549593448638916
Batch 45/64 loss: 0.24486130475997925
Batch 46/64 loss: 0.24593573808670044
Batch 47/64 loss: 0.2521483898162842
Batch 48/64 loss: 0.24983549118041992
Batch 49/64 loss: 0.25984764099121094
Batch 50/64 loss: 0.2508516311645508
Batch 51/64 loss: 0.24826616048812866
Batch 52/64 loss: 0.24804258346557617
Batch 53/64 loss: 0.240470290184021
Batch 54/64 loss: 0.25105613470077515
Batch 55/64 loss: 0.24617010354995728
Batch 56/64 loss: 0.2512373924255371
Batch 57/64 loss: 0.2418174147605896
Batch 58/64 loss: 0.24147772789001465
Batch 59/64 loss: 0.24982333183288574
Batch 60/64 loss: 0.25248658657073975
Batch 61/64 loss: 0.24236083030700684
Batch 62/64 loss: 0.24586808681488037
Batch 63/64 loss: 0.2555040121078491
Batch 64/64 loss: 0.2538432478904724
Epoch 201  Train loss: 0.2473723769187927  Val loss: 0.2758344374981123
Epoch 202
-------------------------------
Batch 1/64 loss: 0.2576737403869629
Batch 2/64 loss: 0.24520254135131836
Batch 3/64 loss: 0.2418212890625
Batch 4/64 loss: 0.24116766452789307
Batch 5/64 loss: 0.2480149269104004
Batch 6/64 loss: 0.2615468502044678
Batch 7/64 loss: 0.24826890230178833
Batch 8/64 loss: 0.24566859006881714
Batch 9/64 loss: 0.2533363103866577
Batch 10/64 loss: 0.2506120204925537
Batch 11/64 loss: 0.2536504864692688
Batch 12/64 loss: 0.2383323311805725
Batch 13/64 loss: 0.25447195768356323
Batch 14/64 loss: 0.24302572011947632
Batch 15/64 loss: 0.24791133403778076
Batch 16/64 loss: 0.24271786212921143
Batch 17/64 loss: 0.24528545141220093
Batch 18/64 loss: 0.24490058422088623
Batch 19/64 loss: 0.24542772769927979
Batch 20/64 loss: 0.247248113155365
Batch 21/64 loss: 0.24524396657943726
Batch 22/64 loss: 0.24073410034179688
Batch 23/64 loss: 0.24345839023590088
Batch 24/64 loss: 0.2460237741470337
Batch 25/64 loss: 0.24181413650512695
Batch 26/64 loss: 0.24635279178619385
Batch 27/64 loss: 0.2525367736816406
Batch 28/64 loss: 0.24519723653793335
Batch 29/64 loss: 0.24066412448883057
Batch 30/64 loss: 0.25075840950012207
Batch 31/64 loss: 0.25074315071105957
Batch 32/64 loss: 0.24995625019073486
Batch 33/64 loss: 0.245391845703125
Batch 34/64 loss: 0.24980854988098145
Batch 35/64 loss: 0.24430471658706665
Batch 36/64 loss: 0.24287551641464233
Batch 37/64 loss: 0.2490544319152832
Batch 38/64 loss: 0.2557829022407532
Batch 39/64 loss: 0.25318074226379395
Batch 40/64 loss: 0.2517164945602417
Batch 41/64 loss: 0.24925333261489868
Batch 42/64 loss: 0.24557697772979736
Batch 43/64 loss: 0.2491016983985901
Batch 44/64 loss: 0.2607489824295044
Batch 45/64 loss: 0.2556508779525757
Batch 46/64 loss: 0.25093233585357666
Batch 47/64 loss: 0.24423402547836304
Batch 48/64 loss: 0.2424558401107788
Batch 49/64 loss: 0.25308382511138916
Batch 50/64 loss: 0.2442808747291565
Batch 51/64 loss: 0.23962819576263428
Batch 52/64 loss: 0.24876010417938232
Batch 53/64 loss: 0.2575143575668335
Batch 54/64 loss: 0.24142611026763916
Batch 55/64 loss: 0.24488496780395508
Batch 56/64 loss: 0.2478967308998108
Batch 57/64 loss: 0.2501988410949707
Batch 58/64 loss: 0.24101722240447998
Batch 59/64 loss: 0.25472915172576904
Batch 60/64 loss: 0.2515706419944763
Batch 61/64 loss: 0.2504078149795532
Batch 62/64 loss: 0.24448657035827637
Batch 63/64 loss: 0.2533422112464905
Batch 64/64 loss: 0.2571897506713867
Epoch 202  Train loss: 0.24809343861598596  Val loss: 0.27597855579402436
Epoch 203
-------------------------------
Batch 1/64 loss: 0.24945557117462158
Batch 2/64 loss: 0.2455255389213562
Batch 3/64 loss: 0.2367497682571411
Batch 4/64 loss: 0.24240124225616455
Batch 5/64 loss: 0.247772216796875
Batch 6/64 loss: 0.2379748821258545
Batch 7/64 loss: 0.24258750677108765
Batch 8/64 loss: 0.2510768175125122
Batch 9/64 loss: 0.24715423583984375
Batch 10/64 loss: 0.2552450895309448
Batch 11/64 loss: 0.23520535230636597
Batch 12/64 loss: 0.24996018409729004
Batch 13/64 loss: 0.25321710109710693
Batch 14/64 loss: 0.24986684322357178
Batch 15/64 loss: 0.24755817651748657
Batch 16/64 loss: 0.2622675895690918
Batch 17/64 loss: 0.2441558837890625
Batch 18/64 loss: 0.24813008308410645
Batch 19/64 loss: 0.24756324291229248
Batch 20/64 loss: 0.24608570337295532
Batch 21/64 loss: 0.24878036975860596
Batch 22/64 loss: 0.24918222427368164
Batch 23/64 loss: 0.24653565883636475
Batch 24/64 loss: 0.24809348583221436
Batch 25/64 loss: 0.2451537847518921
Batch 26/64 loss: 0.24265313148498535
Batch 27/64 loss: 0.23536062240600586
Batch 28/64 loss: 0.24534642696380615
Batch 29/64 loss: 0.2482513189315796
Batch 30/64 loss: 0.2414478063583374
Batch 31/64 loss: 0.25207746028900146
Batch 32/64 loss: 0.2481832504272461
Batch 33/64 loss: 0.24583375453948975
Batch 34/64 loss: 0.24968194961547852
Batch 35/64 loss: 0.24734795093536377
Batch 36/64 loss: 0.2462775707244873
Batch 37/64 loss: 0.24267780780792236
Batch 38/64 loss: 0.2359762191772461
Batch 39/64 loss: 0.24926811456680298
Batch 40/64 loss: 0.25221067667007446
Batch 41/64 loss: 0.25160253047943115
Batch 42/64 loss: 0.2656896114349365
Batch 43/64 loss: 0.24322086572647095
Batch 44/64 loss: 0.24203944206237793
Batch 45/64 loss: 0.24087947607040405
Batch 46/64 loss: 0.25644373893737793
Batch 47/64 loss: 0.24202942848205566
Batch 48/64 loss: 0.24734359979629517
Batch 49/64 loss: 0.24782085418701172
Batch 50/64 loss: 0.24586105346679688
Batch 51/64 loss: 0.25171804428100586
Batch 52/64 loss: 0.2535356283187866
Batch 53/64 loss: 0.25047361850738525
Batch 54/64 loss: 0.2506676912307739
Batch 55/64 loss: 0.2515656352043152
Batch 56/64 loss: 0.24885457754135132
Batch 57/64 loss: 0.24397552013397217
Batch 58/64 loss: 0.24858522415161133
Batch 59/64 loss: 0.24930685758590698
Batch 60/64 loss: 0.2588239908218384
Batch 61/64 loss: 0.24206668138504028
Batch 62/64 loss: 0.2431941032409668
Batch 63/64 loss: 0.2495449185371399
Batch 64/64 loss: 0.24697202444076538
Epoch 203  Train loss: 0.24738454468110027  Val loss: 0.2733687596632443
Saving best model, epoch: 203
Epoch 204
-------------------------------
Batch 1/64 loss: 0.24247515201568604
Batch 2/64 loss: 0.24344944953918457
Batch 3/64 loss: 0.24318701028823853
Batch 4/64 loss: 0.2495824098587036
Batch 5/64 loss: 0.24798321723937988
Batch 6/64 loss: 0.251603364944458
Batch 7/64 loss: 0.26184624433517456
Batch 8/64 loss: 0.24591165781021118
Batch 9/64 loss: 0.2441210150718689
Batch 10/64 loss: 0.2483360767364502
Batch 11/64 loss: 0.24021124839782715
Batch 12/64 loss: 0.24085307121276855
Batch 13/64 loss: 0.25068533420562744
Batch 14/64 loss: 0.24792098999023438
Batch 15/64 loss: 0.24245381355285645
Batch 16/64 loss: 0.24796271324157715
Batch 17/64 loss: 0.24284374713897705
Batch 18/64 loss: 0.2456299066543579
Batch 19/64 loss: 0.24159669876098633
Batch 20/64 loss: 0.23920714855194092
Batch 21/64 loss: 0.25425803661346436
Batch 22/64 loss: 0.23927581310272217
Batch 23/64 loss: 0.2373814582824707
Batch 24/64 loss: 0.25610291957855225
Batch 25/64 loss: 0.24401766061782837
Batch 26/64 loss: 0.24279600381851196
Batch 27/64 loss: 0.23949366807937622
Batch 28/64 loss: 0.2429811954498291
Batch 29/64 loss: 0.24823999404907227
Batch 30/64 loss: 0.24344635009765625
Batch 31/64 loss: 0.24625355005264282
Batch 32/64 loss: 0.24548739194869995
Batch 33/64 loss: 0.24523591995239258
Batch 34/64 loss: 0.2512196898460388
Batch 35/64 loss: 0.25477123260498047
Batch 36/64 loss: 0.24930095672607422
Batch 37/64 loss: 0.25335216522216797
Batch 38/64 loss: 0.24950695037841797
Batch 39/64 loss: 0.24432235956192017
Batch 40/64 loss: 0.23890864849090576
Batch 41/64 loss: 0.24451005458831787
Batch 42/64 loss: 0.2472209930419922
Batch 43/64 loss: 0.2500792145729065
Batch 44/64 loss: 0.24524295330047607
Batch 45/64 loss: 0.2433849573135376
Batch 46/64 loss: 0.24258530139923096
Batch 47/64 loss: 0.24960076808929443
Batch 48/64 loss: 0.25046223402023315
Batch 49/64 loss: 0.24772942066192627
Batch 50/64 loss: 0.24371552467346191
Batch 51/64 loss: 0.25549495220184326
Batch 52/64 loss: 0.24413013458251953
Batch 53/64 loss: 0.24187982082366943
Batch 54/64 loss: 0.24732017517089844
Batch 55/64 loss: 0.2483898401260376
Batch 56/64 loss: 0.2473909854888916
Batch 57/64 loss: 0.24691522121429443
Batch 58/64 loss: 0.24667978286743164
Batch 59/64 loss: 0.23985934257507324
Batch 60/64 loss: 0.24488425254821777
Batch 61/64 loss: 0.2484644651412964
Batch 62/64 loss: 0.2428809404373169
Batch 63/64 loss: 0.2522706985473633
Batch 64/64 loss: 0.2620837688446045
Epoch 204  Train loss: 0.24646066029866537  Val loss: 0.2741793084800039
Epoch 205
-------------------------------
Batch 1/64 loss: 0.25349313020706177
Batch 2/64 loss: 0.25187361240386963
Batch 3/64 loss: 0.2554093599319458
Batch 4/64 loss: 0.2483452558517456
Batch 5/64 loss: 0.24506086111068726
Batch 6/64 loss: 0.2460768222808838
Batch 7/64 loss: 0.24406981468200684
Batch 8/64 loss: 0.24841558933258057
Batch 9/64 loss: 0.23990511894226074
Batch 10/64 loss: 0.24298804998397827
Batch 11/64 loss: 0.24769508838653564
Batch 12/64 loss: 0.24102115631103516
Batch 13/64 loss: 0.2581397294998169
Batch 14/64 loss: 0.23847293853759766
Batch 15/64 loss: 0.24407708644866943
Batch 16/64 loss: 0.2536168098449707
Batch 17/64 loss: 0.2568078637123108
Batch 18/64 loss: 0.25276827812194824
Batch 19/64 loss: 0.2502695322036743
Batch 20/64 loss: 0.24724936485290527
Batch 21/64 loss: 0.25694596767425537
Batch 22/64 loss: 0.25364160537719727
Batch 23/64 loss: 0.24639034271240234
Batch 24/64 loss: 0.2553079128265381
Batch 25/64 loss: 0.25687360763549805
Batch 26/64 loss: 0.25062745809555054
Batch 27/64 loss: 0.2468622326850891
Batch 28/64 loss: 0.24677330255508423
Batch 29/64 loss: 0.247763991355896
Batch 30/64 loss: 0.24427270889282227
Batch 31/64 loss: 0.253206729888916
Batch 32/64 loss: 0.2461247444152832
Batch 33/64 loss: 0.24651062488555908
Batch 34/64 loss: 0.24628031253814697
Batch 35/64 loss: 0.24077606201171875
Batch 36/64 loss: 0.250311017036438
Batch 37/64 loss: 0.2501959204673767
Batch 38/64 loss: 0.24018770456314087
Batch 39/64 loss: 0.23748749494552612
Batch 40/64 loss: 0.2410680055618286
Batch 41/64 loss: 0.2475462555885315
Batch 42/64 loss: 0.2450883388519287
Batch 43/64 loss: 0.23947876691818237
Batch 44/64 loss: 0.24221718311309814
Batch 45/64 loss: 0.25370705127716064
Batch 46/64 loss: 0.24491894245147705
Batch 47/64 loss: 0.2620090842247009
Batch 48/64 loss: 0.24373197555541992
Batch 49/64 loss: 0.24510526657104492
Batch 50/64 loss: 0.2501608729362488
Batch 51/64 loss: 0.24972248077392578
Batch 52/64 loss: 0.24761152267456055
Batch 53/64 loss: 0.24419784545898438
Batch 54/64 loss: 0.24837452173233032
Batch 55/64 loss: 0.2505403757095337
Batch 56/64 loss: 0.24364209175109863
Batch 57/64 loss: 0.2588326930999756
Batch 58/64 loss: 0.23790830373764038
Batch 59/64 loss: 0.24020230770111084
Batch 60/64 loss: 0.24624717235565186
Batch 61/64 loss: 0.2479623556137085
Batch 62/64 loss: 0.24315476417541504
Batch 63/64 loss: 0.25439608097076416
Batch 64/64 loss: 0.2532598376274109
Epoch 205  Train loss: 0.24784414651347142  Val loss: 0.2759552860178079
Epoch 206
-------------------------------
Batch 1/64 loss: 0.24923992156982422
Batch 2/64 loss: 0.2523719072341919
Batch 3/64 loss: 0.2531696557998657
Batch 4/64 loss: 0.257408082485199
Batch 5/64 loss: 0.24811315536499023
Batch 6/64 loss: 0.25590336322784424
Batch 7/64 loss: 0.25125038623809814
Batch 8/64 loss: 0.2444549798965454
Batch 9/64 loss: 0.24552243947982788
Batch 10/64 loss: 0.23914963006973267
Batch 11/64 loss: 0.2388032078742981
Batch 12/64 loss: 0.241888165473938
Batch 13/64 loss: 0.24704337120056152
Batch 14/64 loss: 0.24577319622039795
Batch 15/64 loss: 0.24825948476791382
Batch 16/64 loss: 0.2501513957977295
Batch 17/64 loss: 0.2493666410446167
Batch 18/64 loss: 0.23921650648117065
Batch 19/64 loss: 0.23961251974105835
Batch 20/64 loss: 0.2558191418647766
Batch 21/64 loss: 0.24641239643096924
Batch 22/64 loss: 0.24252057075500488
Batch 23/64 loss: 0.2542921304702759
Batch 24/64 loss: 0.24198764562606812
Batch 25/64 loss: 0.24332159757614136
Batch 26/64 loss: 0.24035727977752686
Batch 27/64 loss: 0.24589502811431885
Batch 28/64 loss: 0.24401485919952393
Batch 29/64 loss: 0.24002283811569214
Batch 30/64 loss: 0.2476944923400879
Batch 31/64 loss: 0.2549991011619568
Batch 32/64 loss: 0.24930310249328613
Batch 33/64 loss: 0.23821407556533813
Batch 34/64 loss: 0.2526845932006836
Batch 35/64 loss: 0.2423086166381836
Batch 36/64 loss: 0.2526693344116211
Batch 37/64 loss: 0.23858028650283813
Batch 38/64 loss: 0.24425411224365234
Batch 39/64 loss: 0.2476576566696167
Batch 40/64 loss: 0.2572031021118164
Batch 41/64 loss: 0.2447848916053772
Batch 42/64 loss: 0.2570241093635559
Batch 43/64 loss: 0.2494107484817505
Batch 44/64 loss: 0.23879575729370117
Batch 45/64 loss: 0.2458316683769226
Batch 46/64 loss: 0.255740761756897
Batch 47/64 loss: 0.25482332706451416
Batch 48/64 loss: 0.2533099055290222
Batch 49/64 loss: 0.238575279712677
Batch 50/64 loss: 0.24714136123657227
Batch 51/64 loss: 0.23940688371658325
Batch 52/64 loss: 0.24655675888061523
Batch 53/64 loss: 0.24173206090927124
Batch 54/64 loss: 0.24980586767196655
Batch 55/64 loss: 0.24359989166259766
Batch 56/64 loss: 0.2434324026107788
Batch 57/64 loss: 0.24241340160369873
Batch 58/64 loss: 0.24721598625183105
Batch 59/64 loss: 0.240556001663208
Batch 60/64 loss: 0.2431180477142334
Batch 61/64 loss: 0.26076245307922363
Batch 62/64 loss: 0.24521923065185547
Batch 63/64 loss: 0.2479715347290039
Batch 64/64 loss: 0.24961602687835693
Epoch 206  Train loss: 0.2469231423209695  Val loss: 0.27489318143051517
Epoch 207
-------------------------------
Batch 1/64 loss: 0.24721741676330566
Batch 2/64 loss: 0.2351522445678711
Batch 3/64 loss: 0.25122982263565063
Batch 4/64 loss: 0.23543977737426758
Batch 5/64 loss: 0.23658764362335205
Batch 6/64 loss: 0.24967610836029053
Batch 7/64 loss: 0.24182206392288208
Batch 8/64 loss: 0.23896288871765137
Batch 9/64 loss: 0.2432260513305664
Batch 10/64 loss: 0.2489396333694458
Batch 11/64 loss: 0.24603486061096191
Batch 12/64 loss: 0.25010615587234497
Batch 13/64 loss: 0.24620944261550903
Batch 14/64 loss: 0.24663054943084717
Batch 15/64 loss: 0.245857834815979
Batch 16/64 loss: 0.2581140995025635
Batch 17/64 loss: 0.25630831718444824
Batch 18/64 loss: 0.24551135301589966
Batch 19/64 loss: 0.2460392713546753
Batch 20/64 loss: 0.24178433418273926
Batch 21/64 loss: 0.24774450063705444
Batch 22/64 loss: 0.24692457914352417
Batch 23/64 loss: 0.25067222118377686
Batch 24/64 loss: 0.24880337715148926
Batch 25/64 loss: 0.2409137487411499
Batch 26/64 loss: 0.23750758171081543
Batch 27/64 loss: 0.24088561534881592
Batch 28/64 loss: 0.2510712146759033
Batch 29/64 loss: 0.24525314569473267
Batch 30/64 loss: 0.23873305320739746
Batch 31/64 loss: 0.24813097715377808
Batch 32/64 loss: 0.24746203422546387
Batch 33/64 loss: 0.24352139234542847
Batch 34/64 loss: 0.2524029016494751
Batch 35/64 loss: 0.2514323592185974
Batch 36/64 loss: 0.24324077367782593
Batch 37/64 loss: 0.24510085582733154
Batch 38/64 loss: 0.2467464804649353
Batch 39/64 loss: 0.24589037895202637
Batch 40/64 loss: 0.24272918701171875
Batch 41/64 loss: 0.24348598718643188
Batch 42/64 loss: 0.25484466552734375
Batch 43/64 loss: 0.25507378578186035
Batch 44/64 loss: 0.25236964225769043
Batch 45/64 loss: 0.24996435642242432
Batch 46/64 loss: 0.2522026300430298
Batch 47/64 loss: 0.2507067322731018
Batch 48/64 loss: 0.24640709161758423
Batch 49/64 loss: 0.24814987182617188
Batch 50/64 loss: 0.24808108806610107
Batch 51/64 loss: 0.25117039680480957
Batch 52/64 loss: 0.2518032193183899
Batch 53/64 loss: 0.24882161617279053
Batch 54/64 loss: 0.25214654207229614
Batch 55/64 loss: 0.2478681206703186
Batch 56/64 loss: 0.24542021751403809
Batch 57/64 loss: 0.24704492092132568
Batch 58/64 loss: 0.2511501908302307
Batch 59/64 loss: 0.2411259412765503
Batch 60/64 loss: 0.2484418749809265
Batch 61/64 loss: 0.23864203691482544
Batch 62/64 loss: 0.24274730682373047
Batch 63/64 loss: 0.23783689737319946
Batch 64/64 loss: 0.24301981925964355
Epoch 207  Train loss: 0.2464907646179199  Val loss: 0.27530431337782607
Epoch 208
-------------------------------
Batch 1/64 loss: 0.23946934938430786
Batch 2/64 loss: 0.237196683883667
Batch 3/64 loss: 0.24809229373931885
Batch 4/64 loss: 0.24323368072509766
Batch 5/64 loss: 0.24810791015625
Batch 6/64 loss: 0.2520202398300171
Batch 7/64 loss: 0.24123752117156982
Batch 8/64 loss: 0.2526237964630127
Batch 9/64 loss: 0.24453163146972656
Batch 10/64 loss: 0.25061696767807007
Batch 11/64 loss: 0.24566131830215454
Batch 12/64 loss: 0.24742674827575684
Batch 13/64 loss: 0.2406151294708252
Batch 14/64 loss: 0.24572676420211792
Batch 15/64 loss: 0.24473679065704346
Batch 16/64 loss: 0.23439538478851318
Batch 17/64 loss: 0.2530825138092041
Batch 18/64 loss: 0.25840532779693604
Batch 19/64 loss: 0.24303925037384033
Batch 20/64 loss: 0.24268096685409546
Batch 21/64 loss: 0.25523197650909424
Batch 22/64 loss: 0.24045753479003906
Batch 23/64 loss: 0.2439783811569214
Batch 24/64 loss: 0.24494725465774536
Batch 25/64 loss: 0.25094783306121826
Batch 26/64 loss: 0.244165301322937
Batch 27/64 loss: 0.24422156810760498
Batch 28/64 loss: 0.24432802200317383
Batch 29/64 loss: 0.2408902645111084
Batch 30/64 loss: 0.25902390480041504
Batch 31/64 loss: 0.24836671352386475
Batch 32/64 loss: 0.24283790588378906
Batch 33/64 loss: 0.24864089488983154
Batch 34/64 loss: 0.2462218999862671
Batch 35/64 loss: 0.24114125967025757
Batch 36/64 loss: 0.24346923828125
Batch 37/64 loss: 0.24785852432250977
Batch 38/64 loss: 0.24290132522583008
Batch 39/64 loss: 0.2430248260498047
Batch 40/64 loss: 0.2442082166671753
Batch 41/64 loss: 0.24388599395751953
Batch 42/64 loss: 0.2543926239013672
Batch 43/64 loss: 0.2516016364097595
Batch 44/64 loss: 0.23783183097839355
Batch 45/64 loss: 0.24549591541290283
Batch 46/64 loss: 0.257240891456604
Batch 47/64 loss: 0.25145506858825684
Batch 48/64 loss: 0.2448962926864624
Batch 49/64 loss: 0.2402501106262207
Batch 50/64 loss: 0.24577045440673828
Batch 51/64 loss: 0.23868262767791748
Batch 52/64 loss: 0.24194544553756714
Batch 53/64 loss: 0.24606645107269287
Batch 54/64 loss: 0.24476850032806396
Batch 55/64 loss: 0.25408172607421875
Batch 56/64 loss: 0.2466312050819397
Batch 57/64 loss: 0.2548239827156067
Batch 58/64 loss: 0.2523807883262634
Batch 59/64 loss: 0.2452164888381958
Batch 60/64 loss: 0.24496930837631226
Batch 61/64 loss: 0.2434731125831604
Batch 62/64 loss: 0.2542223334312439
Batch 63/64 loss: 0.2502690553665161
Batch 64/64 loss: 0.25098395347595215
Epoch 208  Train loss: 0.24640553605322743  Val loss: 0.2758698655977282
Epoch 209
-------------------------------
Batch 1/64 loss: 0.24787235260009766
Batch 2/64 loss: 0.24186944961547852
Batch 3/64 loss: 0.25520700216293335
Batch 4/64 loss: 0.25009411573410034
Batch 5/64 loss: 0.2558356523513794
Batch 6/64 loss: 0.24545222520828247
Batch 7/64 loss: 0.23989051580429077
Batch 8/64 loss: 0.24547719955444336
Batch 9/64 loss: 0.2432880401611328
Batch 10/64 loss: 0.25683724880218506
Batch 11/64 loss: 0.24397027492523193
Batch 12/64 loss: 0.24047434329986572
Batch 13/64 loss: 0.24674057960510254
Batch 14/64 loss: 0.24791955947875977
Batch 15/64 loss: 0.23771405220031738
Batch 16/64 loss: 0.2404109239578247
Batch 17/64 loss: 0.24005496501922607
Batch 18/64 loss: 0.2643841505050659
Batch 19/64 loss: 0.2412700057029724
Batch 20/64 loss: 0.24655795097351074
Batch 21/64 loss: 0.2432880997657776
Batch 22/64 loss: 0.2445204257965088
Batch 23/64 loss: 0.2479637861251831
Batch 24/64 loss: 0.2490459680557251
Batch 25/64 loss: 0.24067389965057373
Batch 26/64 loss: 0.2463282346725464
Batch 27/64 loss: 0.25026464462280273
Batch 28/64 loss: 0.24084198474884033
Batch 29/64 loss: 0.2431553602218628
Batch 30/64 loss: 0.24968034029006958
Batch 31/64 loss: 0.2541837692260742
Batch 32/64 loss: 0.2536911964416504
Batch 33/64 loss: 0.24046415090560913
Batch 34/64 loss: 0.24230551719665527
Batch 35/64 loss: 0.2460169792175293
Batch 36/64 loss: 0.24903905391693115
Batch 37/64 loss: 0.24085545539855957
Batch 38/64 loss: 0.23839962482452393
Batch 39/64 loss: 0.24124640226364136
Batch 40/64 loss: 0.2491368055343628
Batch 41/64 loss: 0.23235201835632324
Batch 42/64 loss: 0.24721115827560425
Batch 43/64 loss: 0.24515485763549805
Batch 44/64 loss: 0.24470484256744385
Batch 45/64 loss: 0.2473556399345398
Batch 46/64 loss: 0.24815630912780762
Batch 47/64 loss: 0.24844694137573242
Batch 48/64 loss: 0.23576974868774414
Batch 49/64 loss: 0.24313652515411377
Batch 50/64 loss: 0.25639522075653076
Batch 51/64 loss: 0.24527281522750854
Batch 52/64 loss: 0.2504447102546692
Batch 53/64 loss: 0.24651050567626953
Batch 54/64 loss: 0.23498553037643433
Batch 55/64 loss: 0.24651652574539185
Batch 56/64 loss: 0.2479240894317627
Batch 57/64 loss: 0.250974178314209
Batch 58/64 loss: 0.2503698468208313
Batch 59/64 loss: 0.24479657411575317
Batch 60/64 loss: 0.24468964338302612
Batch 61/64 loss: 0.2456132173538208
Batch 62/64 loss: 0.23822593688964844
Batch 63/64 loss: 0.24473893642425537
Batch 64/64 loss: 0.24210220575332642
Epoch 209  Train loss: 0.24570579972921633  Val loss: 0.27353174538956476
Epoch 210
-------------------------------
Batch 1/64 loss: 0.24951165914535522
Batch 2/64 loss: 0.24054330587387085
Batch 3/64 loss: 0.25278913974761963
Batch 4/64 loss: 0.24351954460144043
Batch 5/64 loss: 0.24162274599075317
Batch 6/64 loss: 0.25013500452041626
Batch 7/64 loss: 0.24554699659347534
Batch 8/64 loss: 0.2470996379852295
Batch 9/64 loss: 0.25001060962677
Batch 10/64 loss: 0.24420642852783203
Batch 11/64 loss: 0.24073290824890137
Batch 12/64 loss: 0.2459961175918579
Batch 13/64 loss: 0.2346310019493103
Batch 14/64 loss: 0.24597316980361938
Batch 15/64 loss: 0.24565893411636353
Batch 16/64 loss: 0.24130284786224365
Batch 17/64 loss: 0.2395176887512207
Batch 18/64 loss: 0.23588842153549194
Batch 19/64 loss: 0.24409055709838867
Batch 20/64 loss: 0.2508997321128845
Batch 21/64 loss: 0.2547609806060791
Batch 22/64 loss: 0.23856955766677856
Batch 23/64 loss: 0.24137365818023682
Batch 24/64 loss: 0.24031251668930054
Batch 25/64 loss: 0.24072110652923584
Batch 26/64 loss: 0.25363266468048096
Batch 27/64 loss: 0.2438371777534485
Batch 28/64 loss: 0.240506112575531
Batch 29/64 loss: 0.2573361396789551
Batch 30/64 loss: 0.23483353853225708
Batch 31/64 loss: 0.24342501163482666
Batch 32/64 loss: 0.24464845657348633
Batch 33/64 loss: 0.2418798804283142
Batch 34/64 loss: 0.2588573098182678
Batch 35/64 loss: 0.24732321500778198
Batch 36/64 loss: 0.24399852752685547
Batch 37/64 loss: 0.24057209491729736
Batch 38/64 loss: 0.24238336086273193
Batch 39/64 loss: 0.24075931310653687
Batch 40/64 loss: 0.2520705461502075
Batch 41/64 loss: 0.24261850118637085
Batch 42/64 loss: 0.23744869232177734
Batch 43/64 loss: 0.2393965721130371
Batch 44/64 loss: 0.2425714135169983
Batch 45/64 loss: 0.2537275552749634
Batch 46/64 loss: 0.2475144863128662
Batch 47/64 loss: 0.24608033895492554
Batch 48/64 loss: 0.24752235412597656
Batch 49/64 loss: 0.24919170141220093
Batch 50/64 loss: 0.2423645257949829
Batch 51/64 loss: 0.23885846138000488
Batch 52/64 loss: 0.2491399049758911
Batch 53/64 loss: 0.2409658432006836
Batch 54/64 loss: 0.25468194484710693
Batch 55/64 loss: 0.25199323892593384
Batch 56/64 loss: 0.2440875768661499
Batch 57/64 loss: 0.24478185176849365
Batch 58/64 loss: 0.23679769039154053
Batch 59/64 loss: 0.24284547567367554
Batch 60/64 loss: 0.2374589443206787
Batch 61/64 loss: 0.24173498153686523
Batch 62/64 loss: 0.2501567602157593
Batch 63/64 loss: 0.24846595525741577
Batch 64/64 loss: 0.25143754482269287
Epoch 210  Train loss: 0.24486996940537994  Val loss: 0.27438077422761425
Epoch 211
-------------------------------
Batch 1/64 loss: 0.2371460199356079
Batch 2/64 loss: 0.24992787837982178
Batch 3/64 loss: 0.24159955978393555
Batch 4/64 loss: 0.24807250499725342
Batch 5/64 loss: 0.24412119388580322
Batch 6/64 loss: 0.2490595579147339
Batch 7/64 loss: 0.24097108840942383
Batch 8/64 loss: 0.24068683385849
Batch 9/64 loss: 0.2400345802307129
Batch 10/64 loss: 0.24116110801696777
Batch 11/64 loss: 0.24587708711624146
Batch 12/64 loss: 0.2453973889350891
Batch 13/64 loss: 0.24359869956970215
Batch 14/64 loss: 0.23945629596710205
Batch 15/64 loss: 0.24358022212982178
Batch 16/64 loss: 0.2562985420227051
Batch 17/64 loss: 0.24199682474136353
Batch 18/64 loss: 0.24709677696228027
Batch 19/64 loss: 0.23794841766357422
Batch 20/64 loss: 0.2358912229537964
Batch 21/64 loss: 0.24012351036071777
Batch 22/64 loss: 0.24394261837005615
Batch 23/64 loss: 0.2455674409866333
Batch 24/64 loss: 0.24054431915283203
Batch 25/64 loss: 0.24944674968719482
Batch 26/64 loss: 0.24891340732574463
Batch 27/64 loss: 0.2446010708808899
Batch 28/64 loss: 0.2480175495147705
Batch 29/64 loss: 0.24295389652252197
Batch 30/64 loss: 0.2520204782485962
Batch 31/64 loss: 0.2503483295440674
Batch 32/64 loss: 0.2506781816482544
Batch 33/64 loss: 0.2460547685623169
Batch 34/64 loss: 0.2453782558441162
Batch 35/64 loss: 0.2569277286529541
Batch 36/64 loss: 0.24186623096466064
Batch 37/64 loss: 0.24257898330688477
Batch 38/64 loss: 0.24283349514007568
Batch 39/64 loss: 0.24616694450378418
Batch 40/64 loss: 0.2583807706832886
Batch 41/64 loss: 0.2469034194946289
Batch 42/64 loss: 0.2504216432571411
Batch 43/64 loss: 0.24048113822937012
Batch 44/64 loss: 0.2450384497642517
Batch 45/64 loss: 0.23758339881896973
Batch 46/64 loss: 0.2413143515586853
Batch 47/64 loss: 0.2504948377609253
Batch 48/64 loss: 0.26025712490081787
Batch 49/64 loss: 0.24513113498687744
Batch 50/64 loss: 0.24052327871322632
Batch 51/64 loss: 0.24759912490844727
Batch 52/64 loss: 0.23435568809509277
Batch 53/64 loss: 0.24885082244873047
Batch 54/64 loss: 0.24760913848876953
Batch 55/64 loss: 0.24595510959625244
Batch 56/64 loss: 0.2487713098526001
Batch 57/64 loss: 0.24320673942565918
Batch 58/64 loss: 0.2537497878074646
Batch 59/64 loss: 0.2441413402557373
Batch 60/64 loss: 0.24295997619628906
Batch 61/64 loss: 0.2449951171875
Batch 62/64 loss: 0.23834359645843506
Batch 63/64 loss: 0.24551641941070557
Batch 64/64 loss: 0.24994796514511108
Epoch 211  Train loss: 0.2453165561545129  Val loss: 0.27557257749780345
Epoch 212
-------------------------------
Batch 1/64 loss: 0.2527484893798828
Batch 2/64 loss: 0.24213069677352905
Batch 3/64 loss: 0.2497035264968872
Batch 4/64 loss: 0.24490654468536377
Batch 5/64 loss: 0.24593663215637207
Batch 6/64 loss: 0.24844545125961304
Batch 7/64 loss: 0.2509992718696594
Batch 8/64 loss: 0.23912972211837769
Batch 9/64 loss: 0.24708831310272217
Batch 10/64 loss: 0.24508798122406006
Batch 11/64 loss: 0.2458515763282776
Batch 12/64 loss: 0.23526298999786377
Batch 13/64 loss: 0.24449896812438965
Batch 14/64 loss: 0.243710458278656
Batch 15/64 loss: 0.2475346326828003
Batch 16/64 loss: 0.24005144834518433
Batch 17/64 loss: 0.252128005027771
Batch 18/64 loss: 0.23833388090133667
Batch 19/64 loss: 0.24645459651947021
Batch 20/64 loss: 0.24435782432556152
Batch 21/64 loss: 0.2541182041168213
Batch 22/64 loss: 0.2502758502960205
Batch 23/64 loss: 0.24673956632614136
Batch 24/64 loss: 0.2465457320213318
Batch 25/64 loss: 0.24541378021240234
Batch 26/64 loss: 0.23842334747314453
Batch 27/64 loss: 0.2455730438232422
Batch 28/64 loss: 0.23724603652954102
Batch 29/64 loss: 0.23553001880645752
Batch 30/64 loss: 0.24195200204849243
Batch 31/64 loss: 0.2483435869216919
Batch 32/64 loss: 0.24320876598358154
Batch 33/64 loss: 0.24479687213897705
Batch 34/64 loss: 0.24699467420578003
Batch 35/64 loss: 0.24015682935714722
Batch 36/64 loss: 0.24822509288787842
Batch 37/64 loss: 0.24858802556991577
Batch 38/64 loss: 0.24978220462799072
Batch 39/64 loss: 0.25652414560317993
Batch 40/64 loss: 0.2501640319824219
Batch 41/64 loss: 0.24277877807617188
Batch 42/64 loss: 0.24096906185150146
Batch 43/64 loss: 0.2379699945449829
Batch 44/64 loss: 0.2418837547302246
Batch 45/64 loss: 0.25567418336868286
Batch 46/64 loss: 0.24594050645828247
Batch 47/64 loss: 0.24776792526245117
Batch 48/64 loss: 0.24598515033721924
Batch 49/64 loss: 0.23995792865753174
Batch 50/64 loss: 0.24720275402069092
Batch 51/64 loss: 0.2421574592590332
Batch 52/64 loss: 0.24415844678878784
Batch 53/64 loss: 0.24479830265045166
Batch 54/64 loss: 0.24534106254577637
Batch 55/64 loss: 0.24722373485565186
Batch 56/64 loss: 0.24678564071655273
Batch 57/64 loss: 0.2542550563812256
Batch 58/64 loss: 0.24822962284088135
Batch 59/64 loss: 0.24741077423095703
Batch 60/64 loss: 0.24368751049041748
Batch 61/64 loss: 0.24969840049743652
Batch 62/64 loss: 0.24237406253814697
Batch 63/64 loss: 0.23842906951904297
Batch 64/64 loss: 0.2505027651786804
Epoch 212  Train loss: 0.24551402470644781  Val loss: 0.27501501291478214
Epoch 213
-------------------------------
Batch 1/64 loss: 0.2458209991455078
Batch 2/64 loss: 0.241796612739563
Batch 3/64 loss: 0.2490302324295044
Batch 4/64 loss: 0.24535536766052246
Batch 5/64 loss: 0.2451878786087036
Batch 6/64 loss: 0.2467302680015564
Batch 7/64 loss: 0.2395530343055725
Batch 8/64 loss: 0.24141132831573486
Batch 9/64 loss: 0.25284290313720703
Batch 10/64 loss: 0.2401742935180664
Batch 11/64 loss: 0.23133671283721924
Batch 12/64 loss: 0.24271559715270996
Batch 13/64 loss: 0.2427607774734497
Batch 14/64 loss: 0.24334955215454102
Batch 15/64 loss: 0.24345874786376953
Batch 16/64 loss: 0.2427443265914917
Batch 17/64 loss: 0.25286465883255005
Batch 18/64 loss: 0.23598814010620117
Batch 19/64 loss: 0.24268114566802979
Batch 20/64 loss: 0.2520214915275574
Batch 21/64 loss: 0.25188809633255005
Batch 22/64 loss: 0.2446463704109192
Batch 23/64 loss: 0.24446386098861694
Batch 24/64 loss: 0.24057632684707642
Batch 25/64 loss: 0.24589192867279053
Batch 26/64 loss: 0.2473757266998291
Batch 27/64 loss: 0.2479156255722046
Batch 28/64 loss: 0.24739807844161987
Batch 29/64 loss: 0.24182403087615967
Batch 30/64 loss: 0.24699842929840088
Batch 31/64 loss: 0.2443993091583252
Batch 32/64 loss: 0.23980319499969482
Batch 33/64 loss: 0.2474321722984314
Batch 34/64 loss: 0.2473832368850708
Batch 35/64 loss: 0.2539045810699463
Batch 36/64 loss: 0.24392402172088623
Batch 37/64 loss: 0.24792802333831787
Batch 38/64 loss: 0.24874615669250488
Batch 39/64 loss: 0.2433706521987915
Batch 40/64 loss: 0.24751627445220947
Batch 41/64 loss: 0.24837124347686768
Batch 42/64 loss: 0.24517130851745605
Batch 43/64 loss: 0.2456979751586914
Batch 44/64 loss: 0.24574387073516846
Batch 45/64 loss: 0.23678267002105713
Batch 46/64 loss: 0.24879872798919678
Batch 47/64 loss: 0.24330365657806396
Batch 48/64 loss: 0.2458546757698059
Batch 49/64 loss: 0.24099957942962646
Batch 50/64 loss: 0.2393505573272705
Batch 51/64 loss: 0.24767577648162842
Batch 52/64 loss: 0.23821419477462769
Batch 53/64 loss: 0.2408696413040161
Batch 54/64 loss: 0.24708342552185059
Batch 55/64 loss: 0.24097323417663574
Batch 56/64 loss: 0.240886390209198
Batch 57/64 loss: 0.25398945808410645
Batch 58/64 loss: 0.24603545665740967
Batch 59/64 loss: 0.24241888523101807
Batch 60/64 loss: 0.25341689586639404
Batch 61/64 loss: 0.24153155088424683
Batch 62/64 loss: 0.23923718929290771
Batch 63/64 loss: 0.24591809511184692
Batch 64/64 loss: 0.24110877513885498
Epoch 213  Train loss: 0.24471162674473781  Val loss: 0.27354220836023285
Epoch 214
-------------------------------
Batch 1/64 loss: 0.24588418006896973
Batch 2/64 loss: 0.24884486198425293
Batch 3/64 loss: 0.24967575073242188
Batch 4/64 loss: 0.2451028823852539
Batch 5/64 loss: 0.25106436014175415
Batch 6/64 loss: 0.2514246106147766
Batch 7/64 loss: 0.24768871068954468
Batch 8/64 loss: 0.23691469430923462
Batch 9/64 loss: 0.24173569679260254
Batch 10/64 loss: 0.24782735109329224
Batch 11/64 loss: 0.237346351146698
Batch 12/64 loss: 0.24485069513320923
Batch 13/64 loss: 0.24014562368392944
Batch 14/64 loss: 0.24440997838974
Batch 15/64 loss: 0.24201583862304688
Batch 16/64 loss: 0.24265432357788086
Batch 17/64 loss: 0.24842798709869385
Batch 18/64 loss: 0.25118017196655273
Batch 19/64 loss: 0.24225127696990967
Batch 20/64 loss: 0.23965978622436523
Batch 21/64 loss: 0.2410496473312378
Batch 22/64 loss: 0.2538517713546753
Batch 23/64 loss: 0.24555426836013794
Batch 24/64 loss: 0.24042463302612305
Batch 25/64 loss: 0.24470418691635132
Batch 26/64 loss: 0.23645401000976562
Batch 27/64 loss: 0.24229377508163452
Batch 28/64 loss: 0.24282801151275635
Batch 29/64 loss: 0.24565088748931885
Batch 30/64 loss: 0.2428891658782959
Batch 31/64 loss: 0.24249267578125
Batch 32/64 loss: 0.23498499393463135
Batch 33/64 loss: 0.2502334713935852
Batch 34/64 loss: 0.24648070335388184
Batch 35/64 loss: 0.24183666706085205
Batch 36/64 loss: 0.24569785594940186
Batch 37/64 loss: 0.24439465999603271
Batch 38/64 loss: 0.24036109447479248
Batch 39/64 loss: 0.24846410751342773
Batch 40/64 loss: 0.23928320407867432
Batch 41/64 loss: 0.24311691522598267
Batch 42/64 loss: 0.2495395541191101
Batch 43/64 loss: 0.24567747116088867
Batch 44/64 loss: 0.24504733085632324
Batch 45/64 loss: 0.2482391595840454
Batch 46/64 loss: 0.24748432636260986
Batch 47/64 loss: 0.24533426761627197
Batch 48/64 loss: 0.2583886981010437
Batch 49/64 loss: 0.24659717082977295
Batch 50/64 loss: 0.2489725947380066
Batch 51/64 loss: 0.23409342765808105
Batch 52/64 loss: 0.25069379806518555
Batch 53/64 loss: 0.2540785074234009
Batch 54/64 loss: 0.24528586864471436
Batch 55/64 loss: 0.2529914379119873
Batch 56/64 loss: 0.23789119720458984
Batch 57/64 loss: 0.24570387601852417
Batch 58/64 loss: 0.24258273839950562
Batch 59/64 loss: 0.24127036333084106
Batch 60/64 loss: 0.2443702220916748
Batch 61/64 loss: 0.2512815594673157
Batch 62/64 loss: 0.24792218208312988
Batch 63/64 loss: 0.24050414562225342
Batch 64/64 loss: 0.24088340997695923
Epoch 214  Train loss: 0.24496885164111268  Val loss: 0.27246479541575375
Saving best model, epoch: 214
Epoch 215
-------------------------------
Batch 1/64 loss: 0.24352222681045532
Batch 2/64 loss: 0.24884355068206787
Batch 3/64 loss: 0.24553972482681274
Batch 4/64 loss: 0.24810588359832764
Batch 5/64 loss: 0.2456505298614502
Batch 6/64 loss: 0.24528825283050537
Batch 7/64 loss: 0.23950934410095215
Batch 8/64 loss: 0.23367410898208618
Batch 9/64 loss: 0.2436487078666687
Batch 10/64 loss: 0.24315273761749268
Batch 11/64 loss: 0.25275683403015137
Batch 12/64 loss: 0.24000006914138794
Batch 13/64 loss: 0.2520790100097656
Batch 14/64 loss: 0.24312281608581543
Batch 15/64 loss: 0.245694100856781
Batch 16/64 loss: 0.23752093315124512
Batch 17/64 loss: 0.23713409900665283
Batch 18/64 loss: 0.24936950206756592
Batch 19/64 loss: 0.2404511570930481
Batch 20/64 loss: 0.25686585903167725
Batch 21/64 loss: 0.25453996658325195
Batch 22/64 loss: 0.23912370204925537
Batch 23/64 loss: 0.2506887912750244
Batch 24/64 loss: 0.25753843784332275
Batch 25/64 loss: 0.24394500255584717
Batch 26/64 loss: 0.247147798538208
Batch 27/64 loss: 0.253261923789978
Batch 28/64 loss: 0.2408515214920044
Batch 29/64 loss: 0.24819189310073853
Batch 30/64 loss: 0.24922394752502441
Batch 31/64 loss: 0.239610493183136
Batch 32/64 loss: 0.23866546154022217
Batch 33/64 loss: 0.23812484741210938
Batch 34/64 loss: 0.2517491579055786
Batch 35/64 loss: 0.24617040157318115
Batch 36/64 loss: 0.2482960820198059
Batch 37/64 loss: 0.24855071306228638
Batch 38/64 loss: 0.24465757608413696
Batch 39/64 loss: 0.24738550186157227
Batch 40/64 loss: 0.2403355836868286
Batch 41/64 loss: 0.2510058283805847
Batch 42/64 loss: 0.24474549293518066
Batch 43/64 loss: 0.24277716875076294
Batch 44/64 loss: 0.24202203750610352
Batch 45/64 loss: 0.24660098552703857
Batch 46/64 loss: 0.2413036823272705
Batch 47/64 loss: 0.24167180061340332
Batch 48/64 loss: 0.2527775764465332
Batch 49/64 loss: 0.24244260787963867
Batch 50/64 loss: 0.2404310703277588
Batch 51/64 loss: 0.2508195638656616
Batch 52/64 loss: 0.2450425624847412
Batch 53/64 loss: 0.23750829696655273
Batch 54/64 loss: 0.24450045824050903
Batch 55/64 loss: 0.2513488531112671
Batch 56/64 loss: 0.24960124492645264
Batch 57/64 loss: 0.2367992401123047
Batch 58/64 loss: 0.24720627069473267
Batch 59/64 loss: 0.24878841638565063
Batch 60/64 loss: 0.24266910552978516
Batch 61/64 loss: 0.24415528774261475
Batch 62/64 loss: 0.24931561946868896
Batch 63/64 loss: 0.24108004570007324
Batch 64/64 loss: 0.24404656887054443
Epoch 215  Train loss: 0.24529625714993944  Val loss: 0.27439010511968553
Epoch 216
-------------------------------
Batch 1/64 loss: 0.23858827352523804
Batch 2/64 loss: 0.23954713344573975
Batch 3/64 loss: 0.24285012483596802
Batch 4/64 loss: 0.24175500869750977
Batch 5/64 loss: 0.23821532726287842
Batch 6/64 loss: 0.23958265781402588
Batch 7/64 loss: 0.257710337638855
Batch 8/64 loss: 0.24748247861862183
Batch 9/64 loss: 0.243882417678833
Batch 10/64 loss: 0.23973405361175537
Batch 11/64 loss: 0.24237394332885742
Batch 12/64 loss: 0.24627548456192017
Batch 13/64 loss: 0.23104149103164673
Batch 14/64 loss: 0.23911970853805542
Batch 15/64 loss: 0.2371450662612915
Batch 16/64 loss: 0.23893868923187256
Batch 17/64 loss: 0.24284082651138306
Batch 18/64 loss: 0.24570542573928833
Batch 19/64 loss: 0.2426549196243286
Batch 20/64 loss: 0.2385154366493225
Batch 21/64 loss: 0.2499469518661499
Batch 22/64 loss: 0.2491847276687622
Batch 23/64 loss: 0.2409120798110962
Batch 24/64 loss: 0.2359691858291626
Batch 25/64 loss: 0.23618531227111816
Batch 26/64 loss: 0.26486581563949585
Batch 27/64 loss: 0.23097634315490723
Batch 28/64 loss: 0.26069605350494385
Batch 29/64 loss: 0.24547743797302246
Batch 30/64 loss: 0.25183773040771484
Batch 31/64 loss: 0.2503510117530823
Batch 32/64 loss: 0.24840772151947021
Batch 33/64 loss: 0.24679672718048096
Batch 34/64 loss: 0.2453940510749817
Batch 35/64 loss: 0.2521296739578247
Batch 36/64 loss: 0.24538546800613403
Batch 37/64 loss: 0.25224369764328003
Batch 38/64 loss: 0.2490546703338623
Batch 39/64 loss: 0.2450089454650879
Batch 40/64 loss: 0.24319171905517578
Batch 41/64 loss: 0.23814761638641357
Batch 42/64 loss: 0.24361026287078857
Batch 43/64 loss: 0.24778175354003906
Batch 44/64 loss: 0.24850177764892578
Batch 45/64 loss: 0.2413545846939087
Batch 46/64 loss: 0.2487981915473938
Batch 47/64 loss: 0.24385464191436768
Batch 48/64 loss: 0.2492421269416809
Batch 49/64 loss: 0.24556535482406616
Batch 50/64 loss: 0.24228620529174805
Batch 51/64 loss: 0.2396220564842224
Batch 52/64 loss: 0.24747717380523682
Batch 53/64 loss: 0.2450573444366455
Batch 54/64 loss: 0.24346351623535156
Batch 55/64 loss: 0.23886889219284058
Batch 56/64 loss: 0.24321424961090088
Batch 57/64 loss: 0.237102210521698
Batch 58/64 loss: 0.24558532238006592
Batch 59/64 loss: 0.2597312331199646
Batch 60/64 loss: 0.24807500839233398
Batch 61/64 loss: 0.24986207485198975
Batch 62/64 loss: 0.24754351377487183
Batch 63/64 loss: 0.24083232879638672
Batch 64/64 loss: 0.23418033123016357
Epoch 216  Train loss: 0.2445362638024723  Val loss: 0.2749768042892115
Epoch 217
-------------------------------
Batch 1/64 loss: 0.25425469875335693
Batch 2/64 loss: 0.2482593059539795
Batch 3/64 loss: 0.23684382438659668
Batch 4/64 loss: 0.23557162284851074
Batch 5/64 loss: 0.24332797527313232
Batch 6/64 loss: 0.23954331874847412
Batch 7/64 loss: 0.2437351942062378
Batch 8/64 loss: 0.23411470651626587
Batch 9/64 loss: 0.23858702182769775
Batch 10/64 loss: 0.24744117259979248
Batch 11/64 loss: 0.24552041292190552
Batch 12/64 loss: 0.2494971752166748
Batch 13/64 loss: 0.23771852254867554
Batch 14/64 loss: 0.24071794748306274
Batch 15/64 loss: 0.24351096153259277
Batch 16/64 loss: 0.2428324818611145
Batch 17/64 loss: 0.2376672625541687
Batch 18/64 loss: 0.23922109603881836
Batch 19/64 loss: 0.24732542037963867
Batch 20/64 loss: 0.24627017974853516
Batch 21/64 loss: 0.2396640181541443
Batch 22/64 loss: 0.24396967887878418
Batch 23/64 loss: 0.23805636167526245
Batch 24/64 loss: 0.252113401889801
Batch 25/64 loss: 0.25010842084884644
Batch 26/64 loss: 0.24523603916168213
Batch 27/64 loss: 0.2462725043296814
Batch 28/64 loss: 0.24151575565338135
Batch 29/64 loss: 0.24449384212493896
Batch 30/64 loss: 0.23513251543045044
Batch 31/64 loss: 0.24221962690353394
Batch 32/64 loss: 0.24989330768585205
Batch 33/64 loss: 0.23563659191131592
Batch 34/64 loss: 0.25242793560028076
Batch 35/64 loss: 0.2433251142501831
Batch 36/64 loss: 0.2452794313430786
Batch 37/64 loss: 0.24506646394729614
Batch 38/64 loss: 0.24415040016174316
Batch 39/64 loss: 0.24438244104385376
Batch 40/64 loss: 0.23923933506011963
Batch 41/64 loss: 0.2413167953491211
Batch 42/64 loss: 0.24960261583328247
Batch 43/64 loss: 0.2558811902999878
Batch 44/64 loss: 0.24394941329956055
Batch 45/64 loss: 0.24776887893676758
Batch 46/64 loss: 0.2405901551246643
Batch 47/64 loss: 0.23538804054260254
Batch 48/64 loss: 0.23836326599121094
Batch 49/64 loss: 0.23717856407165527
Batch 50/64 loss: 0.23975741863250732
Batch 51/64 loss: 0.2534533739089966
Batch 52/64 loss: 0.2508307099342346
Batch 53/64 loss: 0.2489619255065918
Batch 54/64 loss: 0.2364513874053955
Batch 55/64 loss: 0.24636918306350708
Batch 56/64 loss: 0.23820912837982178
Batch 57/64 loss: 0.24350005388259888
Batch 58/64 loss: 0.2369774580001831
Batch 59/64 loss: 0.24061810970306396
Batch 60/64 loss: 0.25463080406188965
Batch 61/64 loss: 0.2449566125869751
Batch 62/64 loss: 0.2538338303565979
Batch 63/64 loss: 0.24222028255462646
Batch 64/64 loss: 0.24200981855392456
Epoch 217  Train loss: 0.2436464321379568  Val loss: 0.2735900913726833
Epoch 218
-------------------------------
Batch 1/64 loss: 0.2414546012878418
Batch 2/64 loss: 0.2461841106414795
Batch 3/64 loss: 0.24802470207214355
Batch 4/64 loss: 0.25180888175964355
Batch 5/64 loss: 0.24578332901000977
Batch 6/64 loss: 0.24604439735412598
Batch 7/64 loss: 0.24910986423492432
Batch 8/64 loss: 0.23958396911621094
Batch 9/64 loss: 0.2374337911605835
Batch 10/64 loss: 0.2539939880371094
Batch 11/64 loss: 0.23393583297729492
Batch 12/64 loss: 0.24347001314163208
Batch 13/64 loss: 0.23997890949249268
Batch 14/64 loss: 0.25910043716430664
Batch 15/64 loss: 0.2458508014678955
Batch 16/64 loss: 0.23578131198883057
Batch 17/64 loss: 0.2545313835144043
Batch 18/64 loss: 0.24171411991119385
Batch 19/64 loss: 0.2506037950515747
Batch 20/64 loss: 0.24571001529693604
Batch 21/64 loss: 0.24678945541381836
Batch 22/64 loss: 0.24581432342529297
Batch 23/64 loss: 0.24454021453857422
Batch 24/64 loss: 0.2386716604232788
Batch 25/64 loss: 0.23823845386505127
Batch 26/64 loss: 0.2445446252822876
Batch 27/64 loss: 0.2371828556060791
Batch 28/64 loss: 0.23846673965454102
Batch 29/64 loss: 0.23456692695617676
Batch 30/64 loss: 0.24666941165924072
Batch 31/64 loss: 0.2419753074645996
Batch 32/64 loss: 0.24599993228912354
Batch 33/64 loss: 0.24279260635375977
Batch 34/64 loss: 0.22956335544586182
Batch 35/64 loss: 0.2538766860961914
Batch 36/64 loss: 0.2415149211883545
Batch 37/64 loss: 0.24438130855560303
Batch 38/64 loss: 0.2373625636100769
Batch 39/64 loss: 0.2450864315032959
Batch 40/64 loss: 0.2374170422554016
Batch 41/64 loss: 0.24019885063171387
Batch 42/64 loss: 0.2437840700149536
Batch 43/64 loss: 0.23667460680007935
Batch 44/64 loss: 0.24570703506469727
Batch 45/64 loss: 0.24614059925079346
Batch 46/64 loss: 0.24728620052337646
Batch 47/64 loss: 0.2325190305709839
Batch 48/64 loss: 0.25231635570526123
Batch 49/64 loss: 0.23474228382110596
Batch 50/64 loss: 0.23865413665771484
Batch 51/64 loss: 0.2392789125442505
Batch 52/64 loss: 0.24608755111694336
Batch 53/64 loss: 0.25389164686203003
Batch 54/64 loss: 0.24222248792648315
Batch 55/64 loss: 0.24593687057495117
Batch 56/64 loss: 0.24121755361557007
Batch 57/64 loss: 0.2378523349761963
Batch 58/64 loss: 0.2341713309288025
Batch 59/64 loss: 0.23658311367034912
Batch 60/64 loss: 0.2448100447654724
Batch 61/64 loss: 0.23475486040115356
Batch 62/64 loss: 0.25107526779174805
Batch 63/64 loss: 0.24443745613098145
Batch 64/64 loss: 0.24673712253570557
Epoch 218  Train loss: 0.24315213362375895  Val loss: 0.2723972049775402
Saving best model, epoch: 218
Epoch 219
-------------------------------
Batch 1/64 loss: 0.24175482988357544
Batch 2/64 loss: 0.24724870920181274
Batch 3/64 loss: 0.2448645830154419
Batch 4/64 loss: 0.23036515712738037
Batch 5/64 loss: 0.23348844051361084
Batch 6/64 loss: 0.2496996521949768
Batch 7/64 loss: 0.24312657117843628
Batch 8/64 loss: 0.24250757694244385
Batch 9/64 loss: 0.25046902894973755
Batch 10/64 loss: 0.24134385585784912
Batch 11/64 loss: 0.23640179634094238
Batch 12/64 loss: 0.2538156509399414
Batch 13/64 loss: 0.24106121063232422
Batch 14/64 loss: 0.2457682490348816
Batch 15/64 loss: 0.2393627166748047
Batch 16/64 loss: 0.24341320991516113
Batch 17/64 loss: 0.24023288488388062
Batch 18/64 loss: 0.24657750129699707
Batch 19/64 loss: 0.23717814683914185
Batch 20/64 loss: 0.242425799369812
Batch 21/64 loss: 0.2354799509048462
Batch 22/64 loss: 0.2372955083847046
Batch 23/64 loss: 0.24415135383605957
Batch 24/64 loss: 0.24778789281845093
Batch 25/64 loss: 0.23626363277435303
Batch 26/64 loss: 0.23870551586151123
Batch 27/64 loss: 0.2541987895965576
Batch 28/64 loss: 0.2456536889076233
Batch 29/64 loss: 0.2388734221458435
Batch 30/64 loss: 0.2431098222732544
Batch 31/64 loss: 0.23846769332885742
Batch 32/64 loss: 0.23543286323547363
Batch 33/64 loss: 0.24253112077713013
Batch 34/64 loss: 0.2464970350265503
Batch 35/64 loss: 0.233739972114563
Batch 36/64 loss: 0.24567341804504395
Batch 37/64 loss: 0.2404876947402954
Batch 38/64 loss: 0.2460840940475464
Batch 39/64 loss: 0.23755061626434326
Batch 40/64 loss: 0.23850584030151367
Batch 41/64 loss: 0.23979854583740234
Batch 42/64 loss: 0.24629294872283936
Batch 43/64 loss: 0.24690544605255127
Batch 44/64 loss: 0.24641776084899902
Batch 45/64 loss: 0.24913513660430908
Batch 46/64 loss: 0.24791043996810913
Batch 47/64 loss: 0.24034202098846436
Batch 48/64 loss: 0.24426400661468506
Batch 49/64 loss: 0.24813634157180786
Batch 50/64 loss: 0.24946588277816772
Batch 51/64 loss: 0.2403503656387329
Batch 52/64 loss: 0.24163633584976196
Batch 53/64 loss: 0.24829357862472534
Batch 54/64 loss: 0.23875081539154053
Batch 55/64 loss: 0.25312674045562744
Batch 56/64 loss: 0.24373602867126465
Batch 57/64 loss: 0.23970824480056763
Batch 58/64 loss: 0.25011444091796875
Batch 59/64 loss: 0.24309104681015015
Batch 60/64 loss: 0.24637019634246826
Batch 61/64 loss: 0.24076247215270996
Batch 62/64 loss: 0.2361738085746765
Batch 63/64 loss: 0.2418765425682068
Batch 64/64 loss: 0.23971211910247803
Epoch 219  Train loss: 0.24282413697710223  Val loss: 0.2763660371918039
Epoch 220
-------------------------------
Batch 1/64 loss: 0.2530672550201416
Batch 2/64 loss: 0.2403622269630432
Batch 3/64 loss: 0.25118380784988403
Batch 4/64 loss: 0.239385724067688
Batch 5/64 loss: 0.24260729551315308
Batch 6/64 loss: 0.2422640323638916
Batch 7/64 loss: 0.24658751487731934
Batch 8/64 loss: 0.2396094799041748
Batch 9/64 loss: 0.2440999150276184
Batch 10/64 loss: 0.24019569158554077
Batch 11/64 loss: 0.24667060375213623
Batch 12/64 loss: 0.24008715152740479
Batch 13/64 loss: 0.2418912649154663
Batch 14/64 loss: 0.2377879023551941
Batch 15/64 loss: 0.2335827350616455
Batch 16/64 loss: 0.23994362354278564
Batch 17/64 loss: 0.23376286029815674
Batch 18/64 loss: 0.2445533275604248
Batch 19/64 loss: 0.23752307891845703
Batch 20/64 loss: 0.2468550205230713
Batch 21/64 loss: 0.23715245723724365
Batch 22/64 loss: 0.23494011163711548
Batch 23/64 loss: 0.24110126495361328
Batch 24/64 loss: 0.2453746795654297
Batch 25/64 loss: 0.2474689483642578
Batch 26/64 loss: 0.23861145973205566
Batch 27/64 loss: 0.24495929479599
Batch 28/64 loss: 0.2525354027748108
Batch 29/64 loss: 0.24671977758407593
Batch 30/64 loss: 0.23448973894119263
Batch 31/64 loss: 0.2390286922454834
Batch 32/64 loss: 0.24945837259292603
Batch 33/64 loss: 0.2349628210067749
Batch 34/64 loss: 0.25262463092803955
Batch 35/64 loss: 0.2433314323425293
Batch 36/64 loss: 0.24263793230056763
Batch 37/64 loss: 0.253751277923584
Batch 38/64 loss: 0.2389298677444458
Batch 39/64 loss: 0.2427128553390503
Batch 40/64 loss: 0.2451995611190796
Batch 41/64 loss: 0.23155838251113892
Batch 42/64 loss: 0.23111587762832642
Batch 43/64 loss: 0.2359086275100708
Batch 44/64 loss: 0.2383471131324768
Batch 45/64 loss: 0.24882662296295166
Batch 46/64 loss: 0.2482379674911499
Batch 47/64 loss: 0.24597859382629395
Batch 48/64 loss: 0.24537301063537598
Batch 49/64 loss: 0.24361073970794678
Batch 50/64 loss: 0.2425403594970703
Batch 51/64 loss: 0.23346441984176636
Batch 52/64 loss: 0.24950647354125977
Batch 53/64 loss: 0.24512732028961182
Batch 54/64 loss: 0.23599839210510254
Batch 55/64 loss: 0.2454841136932373
Batch 56/64 loss: 0.2587110996246338
Batch 57/64 loss: 0.23818659782409668
Batch 58/64 loss: 0.25026369094848633
Batch 59/64 loss: 0.24530762434005737
Batch 60/64 loss: 0.23880797624588013
Batch 61/64 loss: 0.24593585729599
Batch 62/64 loss: 0.24593031406402588
Batch 63/64 loss: 0.24656736850738525
Batch 64/64 loss: 0.26264649629592896
Epoch 220  Train loss: 0.24307112950904697  Val loss: 0.27363607318130967
Epoch 221
-------------------------------
Batch 1/64 loss: 0.23754394054412842
Batch 2/64 loss: 0.24657392501831055
Batch 3/64 loss: 0.23444664478302002
Batch 4/64 loss: 0.24326550960540771
Batch 5/64 loss: 0.23526060581207275
Batch 6/64 loss: 0.23981058597564697
Batch 7/64 loss: 0.2325146198272705
Batch 8/64 loss: 0.2344893217086792
Batch 9/64 loss: 0.24535560607910156
Batch 10/64 loss: 0.24985599517822266
Batch 11/64 loss: 0.24210113286972046
Batch 12/64 loss: 0.24654024839401245
Batch 13/64 loss: 0.23311585187911987
Batch 14/64 loss: 0.22691106796264648
Batch 15/64 loss: 0.24795830249786377
Batch 16/64 loss: 0.2461855411529541
Batch 17/64 loss: 0.2424892783164978
Batch 18/64 loss: 0.24276816844940186
Batch 19/64 loss: 0.2483750581741333
Batch 20/64 loss: 0.2534295320510864
Batch 21/64 loss: 0.24773263931274414
Batch 22/64 loss: 0.23849451541900635
Batch 23/64 loss: 0.23712044954299927
Batch 24/64 loss: 0.24909019470214844
Batch 25/64 loss: 0.24473488330841064
Batch 26/64 loss: 0.2423972487449646
Batch 27/64 loss: 0.24499285221099854
Batch 28/64 loss: 0.24329763650894165
Batch 29/64 loss: 0.2463955283164978
Batch 30/64 loss: 0.24203014373779297
Batch 31/64 loss: 0.23560643196105957
Batch 32/64 loss: 0.24239575862884521
Batch 33/64 loss: 0.25138068199157715
Batch 34/64 loss: 0.2354506254196167
Batch 35/64 loss: 0.2431560754776001
Batch 36/64 loss: 0.23283368349075317
Batch 37/64 loss: 0.24028241634368896
Batch 38/64 loss: 0.23830723762512207
Batch 39/64 loss: 0.23855125904083252
Batch 40/64 loss: 0.23945891857147217
Batch 41/64 loss: 0.2430349588394165
Batch 42/64 loss: 0.2570993900299072
Batch 43/64 loss: 0.24226969480514526
Batch 44/64 loss: 0.23628246784210205
Batch 45/64 loss: 0.23697400093078613
Batch 46/64 loss: 0.2511225938796997
Batch 47/64 loss: 0.2340707778930664
Batch 48/64 loss: 0.23523616790771484
Batch 49/64 loss: 0.24311316013336182
Batch 50/64 loss: 0.2418971061706543
Batch 51/64 loss: 0.2310248613357544
Batch 52/64 loss: 0.23959314823150635
Batch 53/64 loss: 0.24162423610687256
Batch 54/64 loss: 0.2426554560661316
Batch 55/64 loss: 0.24640309810638428
Batch 56/64 loss: 0.24275916814804077
Batch 57/64 loss: 0.24681037664413452
Batch 58/64 loss: 0.24251198768615723
Batch 59/64 loss: 0.24802690744400024
Batch 60/64 loss: 0.25381219387054443
Batch 61/64 loss: 0.24202412366867065
Batch 62/64 loss: 0.25589776039123535
Batch 63/64 loss: 0.24829399585723877
Batch 64/64 loss: 0.2448267936706543
Epoch 221  Train loss: 0.24233502500197468  Val loss: 0.2724141357690608
Epoch 222
-------------------------------
Batch 1/64 loss: 0.24158751964569092
Batch 2/64 loss: 0.23918908834457397
Batch 3/64 loss: 0.2394946813583374
Batch 4/64 loss: 0.2461422085762024
Batch 5/64 loss: 0.24078768491744995
Batch 6/64 loss: 0.24381262063980103
Batch 7/64 loss: 0.2348477840423584
Batch 8/64 loss: 0.24692684412002563
Batch 9/64 loss: 0.24431860446929932
Batch 10/64 loss: 0.24344778060913086
Batch 11/64 loss: 0.23454999923706055
Batch 12/64 loss: 0.24828588962554932
Batch 13/64 loss: 0.2413797378540039
Batch 14/64 loss: 0.23524779081344604
Batch 15/64 loss: 0.2404383420944214
Batch 16/64 loss: 0.2402820587158203
Batch 17/64 loss: 0.253193199634552
Batch 18/64 loss: 0.2442789077758789
Batch 19/64 loss: 0.2392791509628296
Batch 20/64 loss: 0.2476603388786316
Batch 21/64 loss: 0.23968374729156494
Batch 22/64 loss: 0.24533677101135254
Batch 23/64 loss: 0.2379927635192871
Batch 24/64 loss: 0.24462628364562988
Batch 25/64 loss: 0.23808693885803223
Batch 26/64 loss: 0.24238944053649902
Batch 27/64 loss: 0.2419103980064392
Batch 28/64 loss: 0.24962836503982544
Batch 29/64 loss: 0.24056047201156616
Batch 30/64 loss: 0.24622035026550293
Batch 31/64 loss: 0.23813378810882568
Batch 32/64 loss: 0.23745781183242798
Batch 33/64 loss: 0.24356746673583984
Batch 34/64 loss: 0.24547260999679565
Batch 35/64 loss: 0.25130295753479004
Batch 36/64 loss: 0.24432724714279175
Batch 37/64 loss: 0.24697160720825195
Batch 38/64 loss: 0.2487114667892456
Batch 39/64 loss: 0.24490773677825928
Batch 40/64 loss: 0.23816311359405518
Batch 41/64 loss: 0.23415082693099976
Batch 42/64 loss: 0.23944824934005737
Batch 43/64 loss: 0.24877291917800903
Batch 44/64 loss: 0.25335216522216797
Batch 45/64 loss: 0.24606668949127197
Batch 46/64 loss: 0.23488378524780273
Batch 47/64 loss: 0.23469173908233643
Batch 48/64 loss: 0.23744678497314453
Batch 49/64 loss: 0.23782378435134888
Batch 50/64 loss: 0.23873168230056763
Batch 51/64 loss: 0.23140740394592285
Batch 52/64 loss: 0.24076318740844727
Batch 53/64 loss: 0.2530631422996521
Batch 54/64 loss: 0.23843002319335938
Batch 55/64 loss: 0.24502146244049072
Batch 56/64 loss: 0.23968452215194702
Batch 57/64 loss: 0.23931586742401123
Batch 58/64 loss: 0.25274670124053955
Batch 59/64 loss: 0.24354231357574463
Batch 60/64 loss: 0.24572479724884033
Batch 61/64 loss: 0.23496675491333008
Batch 62/64 loss: 0.24345135688781738
Batch 63/64 loss: 0.24319273233413696
Batch 64/64 loss: 0.250146746635437
Epoch 222  Train loss: 0.2424296552059697  Val loss: 0.27563194392882673
Epoch 223
-------------------------------
Batch 1/64 loss: 0.2430880069732666
Batch 2/64 loss: 0.23740452527999878
Batch 3/64 loss: 0.24322593212127686
Batch 4/64 loss: 0.23733460903167725
Batch 5/64 loss: 0.24876517057418823
Batch 6/64 loss: 0.2431873083114624
Batch 7/64 loss: 0.23811644315719604
Batch 8/64 loss: 0.23949038982391357
Batch 9/64 loss: 0.24546992778778076
Batch 10/64 loss: 0.24247848987579346
Batch 11/64 loss: 0.25432008504867554
Batch 12/64 loss: 0.24118757247924805
Batch 13/64 loss: 0.23391592502593994
Batch 14/64 loss: 0.2342061996459961
Batch 15/64 loss: 0.24544543027877808
Batch 16/64 loss: 0.24215149879455566
Batch 17/64 loss: 0.2501019239425659
Batch 18/64 loss: 0.24947649240493774
Batch 19/64 loss: 0.24121570587158203
Batch 20/64 loss: 0.24235272407531738
Batch 21/64 loss: 0.25489139556884766
Batch 22/64 loss: 0.2327573299407959
Batch 23/64 loss: 0.23600542545318604
Batch 24/64 loss: 0.23778438568115234
Batch 25/64 loss: 0.241455078125
Batch 26/64 loss: 0.24171102046966553
Batch 27/64 loss: 0.2532939910888672
Batch 28/64 loss: 0.24040377140045166
Batch 29/64 loss: 0.24776875972747803
Batch 30/64 loss: 0.23790574073791504
Batch 31/64 loss: 0.24529850482940674
Batch 32/64 loss: 0.24571317434310913
Batch 33/64 loss: 0.2415202260017395
Batch 34/64 loss: 0.2372887134552002
Batch 35/64 loss: 0.2431391477584839
Batch 36/64 loss: 0.2407861351966858
Batch 37/64 loss: 0.2341318130493164
Batch 38/64 loss: 0.24369287490844727
Batch 39/64 loss: 0.2436751127243042
Batch 40/64 loss: 0.2405593991279602
Batch 41/64 loss: 0.23177289962768555
Batch 42/64 loss: 0.24330085515975952
Batch 43/64 loss: 0.24988174438476562
Batch 44/64 loss: 0.23685216903686523
Batch 45/64 loss: 0.23886555433273315
Batch 46/64 loss: 0.2362440824508667
Batch 47/64 loss: 0.24946242570877075
Batch 48/64 loss: 0.24094539880752563
Batch 49/64 loss: 0.24960750341415405
Batch 50/64 loss: 0.2478845715522766
Batch 51/64 loss: 0.24505144357681274
Batch 52/64 loss: 0.24018973112106323
Batch 53/64 loss: 0.24140042066574097
Batch 54/64 loss: 0.2386699914932251
Batch 55/64 loss: 0.25224924087524414
Batch 56/64 loss: 0.23549342155456543
Batch 57/64 loss: 0.24355071783065796
Batch 58/64 loss: 0.2410341501235962
Batch 59/64 loss: 0.24042081832885742
Batch 60/64 loss: 0.244195818901062
Batch 61/64 loss: 0.23824948072433472
Batch 62/64 loss: 0.24746495485305786
Batch 63/64 loss: 0.24304068088531494
Batch 64/64 loss: 0.2441718578338623
Epoch 223  Train loss: 0.24237918947257248  Val loss: 0.27337738840850356
Epoch 224
-------------------------------
Batch 1/64 loss: 0.24239540100097656
Batch 2/64 loss: 0.2318437099456787
Batch 3/64 loss: 0.23673808574676514
Batch 4/64 loss: 0.23904740810394287
Batch 5/64 loss: 0.23988556861877441
Batch 6/64 loss: 0.2350400686264038
Batch 7/64 loss: 0.2373133897781372
Batch 8/64 loss: 0.250232458114624
Batch 9/64 loss: 0.23349648714065552
Batch 10/64 loss: 0.23826050758361816
Batch 11/64 loss: 0.23974609375
Batch 12/64 loss: 0.23671847581863403
Batch 13/64 loss: 0.24103617668151855
Batch 14/64 loss: 0.2394113540649414
Batch 15/64 loss: 0.24507248401641846
Batch 16/64 loss: 0.24264216423034668
Batch 17/64 loss: 0.24644684791564941
Batch 18/64 loss: 0.23838424682617188
Batch 19/64 loss: 0.24586063623428345
Batch 20/64 loss: 0.24333661794662476
Batch 21/64 loss: 0.23646187782287598
Batch 22/64 loss: 0.24003863334655762
Batch 23/64 loss: 0.23793840408325195
Batch 24/64 loss: 0.236466646194458
Batch 25/64 loss: 0.2334616780281067
Batch 26/64 loss: 0.24616318941116333
Batch 27/64 loss: 0.23869329690933228
Batch 28/64 loss: 0.24291038513183594
Batch 29/64 loss: 0.24236005544662476
Batch 30/64 loss: 0.2424975037574768
Batch 31/64 loss: 0.2466527223587036
Batch 32/64 loss: 0.2351151704788208
Batch 33/64 loss: 0.25271862745285034
Batch 34/64 loss: 0.2391265630722046
Batch 35/64 loss: 0.23075950145721436
Batch 36/64 loss: 0.24343502521514893
Batch 37/64 loss: 0.23321497440338135
Batch 38/64 loss: 0.23933011293411255
Batch 39/64 loss: 0.25335443019866943
Batch 40/64 loss: 0.2456984519958496
Batch 41/64 loss: 0.2385510802268982
Batch 42/64 loss: 0.2529815435409546
Batch 43/64 loss: 0.25436902046203613
Batch 44/64 loss: 0.24110281467437744
Batch 45/64 loss: 0.23470300436019897
Batch 46/64 loss: 0.23242288827896118
Batch 47/64 loss: 0.251872718334198
Batch 48/64 loss: 0.24927443265914917
Batch 49/64 loss: 0.24268347024917603
Batch 50/64 loss: 0.25080573558807373
Batch 51/64 loss: 0.2398025393486023
Batch 52/64 loss: 0.2314435839653015
Batch 53/64 loss: 0.2425810694694519
Batch 54/64 loss: 0.24409425258636475
Batch 55/64 loss: 0.250818133354187
Batch 56/64 loss: 0.24204063415527344
Batch 57/64 loss: 0.2369963526725769
Batch 58/64 loss: 0.24621009826660156
Batch 59/64 loss: 0.2382115125656128
Batch 60/64 loss: 0.2433263063430786
Batch 61/64 loss: 0.23384833335876465
Batch 62/64 loss: 0.2447127103805542
Batch 63/64 loss: 0.24152618646621704
Batch 64/64 loss: 0.24951136112213135
Epoch 224  Train loss: 0.24142458625868254  Val loss: 0.2737508967160359
Epoch 225
-------------------------------
Batch 1/64 loss: 0.2508102059364319
Batch 2/64 loss: 0.22963321208953857
Batch 3/64 loss: 0.23746788501739502
Batch 4/64 loss: 0.2476637363433838
Batch 5/64 loss: 0.2336776852607727
Batch 6/64 loss: 0.24075931310653687
Batch 7/64 loss: 0.2285841703414917
Batch 8/64 loss: 0.24299877882003784
Batch 9/64 loss: 0.23524123430252075
Batch 10/64 loss: 0.24016785621643066
Batch 11/64 loss: 0.2383030652999878
Batch 12/64 loss: 0.23948907852172852
Batch 13/64 loss: 0.24875032901763916
Batch 14/64 loss: 0.25322794914245605
Batch 15/64 loss: 0.24237322807312012
Batch 16/64 loss: 0.23635149002075195
Batch 17/64 loss: 0.24165606498718262
Batch 18/64 loss: 0.24190574884414673
Batch 19/64 loss: 0.24164968729019165
Batch 20/64 loss: 0.24573814868927002
Batch 21/64 loss: 0.24071931838989258
Batch 22/64 loss: 0.23671239614486694
Batch 23/64 loss: 0.24680602550506592
Batch 24/64 loss: 0.23562699556350708
Batch 25/64 loss: 0.24087035655975342
Batch 26/64 loss: 0.26231032609939575
Batch 27/64 loss: 0.24385052919387817
Batch 28/64 loss: 0.23892104625701904
Batch 29/64 loss: 0.23356831073760986
Batch 30/64 loss: 0.24238812923431396
Batch 31/64 loss: 0.24373537302017212
Batch 32/64 loss: 0.2499285340309143
Batch 33/64 loss: 0.2429640293121338
Batch 34/64 loss: 0.24508905410766602
Batch 35/64 loss: 0.2428746223449707
Batch 36/64 loss: 0.2447029948234558
Batch 37/64 loss: 0.23702239990234375
Batch 38/64 loss: 0.2536463737487793
Batch 39/64 loss: 0.24093449115753174
Batch 40/64 loss: 0.23273462057113647
Batch 41/64 loss: 0.23992156982421875
Batch 42/64 loss: 0.244903564453125
Batch 43/64 loss: 0.23414576053619385
Batch 44/64 loss: 0.24048155546188354
Batch 45/64 loss: 0.25183260440826416
Batch 46/64 loss: 0.2365930676460266
Batch 47/64 loss: 0.24268758296966553
Batch 48/64 loss: 0.24037671089172363
Batch 49/64 loss: 0.23723238706588745
Batch 50/64 loss: 0.24102568626403809
Batch 51/64 loss: 0.2388485074043274
Batch 52/64 loss: 0.24127429723739624
Batch 53/64 loss: 0.2410585880279541
Batch 54/64 loss: 0.2495737075805664
Batch 55/64 loss: 0.23307162523269653
Batch 56/64 loss: 0.2409578561782837
Batch 57/64 loss: 0.2415650486946106
Batch 58/64 loss: 0.2469457983970642
Batch 59/64 loss: 0.24947881698608398
Batch 60/64 loss: 0.23665165901184082
Batch 61/64 loss: 0.25308549404144287
Batch 62/64 loss: 0.24581116437911987
Batch 63/64 loss: 0.23832714557647705
Batch 64/64 loss: 0.24110925197601318
Epoch 225  Train loss: 0.24185940284355015  Val loss: 0.27296121792285305
Epoch 226
-------------------------------
Batch 1/64 loss: 0.24547427892684937
Batch 2/64 loss: 0.23932099342346191
Batch 3/64 loss: 0.24710333347320557
Batch 4/64 loss: 0.24775129556655884
Batch 5/64 loss: 0.24033880233764648
Batch 6/64 loss: 0.23704099655151367
Batch 7/64 loss: 0.23541176319122314
Batch 8/64 loss: 0.23395776748657227
Batch 9/64 loss: 0.23455268144607544
Batch 10/64 loss: 0.2460341453552246
Batch 11/64 loss: 0.23040467500686646
Batch 12/64 loss: 0.2507935166358948
Batch 13/64 loss: 0.24312472343444824
Batch 14/64 loss: 0.23607152700424194
Batch 15/64 loss: 0.23208576440811157
Batch 16/64 loss: 0.24244952201843262
Batch 17/64 loss: 0.25099802017211914
Batch 18/64 loss: 0.2422553300857544
Batch 19/64 loss: 0.246454119682312
Batch 20/64 loss: 0.2359471321105957
Batch 21/64 loss: 0.24047225713729858
Batch 22/64 loss: 0.23525869846343994
Batch 23/64 loss: 0.24532556533813477
Batch 24/64 loss: 0.237718403339386
Batch 25/64 loss: 0.23745757341384888
Batch 26/64 loss: 0.2436535358428955
Batch 27/64 loss: 0.2496023178100586
Batch 28/64 loss: 0.23903381824493408
Batch 29/64 loss: 0.2453518509864807
Batch 30/64 loss: 0.24195730686187744
Batch 31/64 loss: 0.24715018272399902
Batch 32/64 loss: 0.24728429317474365
Batch 33/64 loss: 0.24434751272201538
Batch 34/64 loss: 0.24073851108551025
Batch 35/64 loss: 0.24211198091506958
Batch 36/64 loss: 0.24414241313934326
Batch 37/64 loss: 0.24964970350265503
Batch 38/64 loss: 0.23606514930725098
Batch 39/64 loss: 0.23450982570648193
Batch 40/64 loss: 0.23339027166366577
Batch 41/64 loss: 0.24128198623657227
Batch 42/64 loss: 0.23621898889541626
Batch 43/64 loss: 0.2491587996482849
Batch 44/64 loss: 0.23832130432128906
Batch 45/64 loss: 0.24485093355178833
Batch 46/64 loss: 0.24535930156707764
Batch 47/64 loss: 0.24660146236419678
Batch 48/64 loss: 0.24436378479003906
Batch 49/64 loss: 0.24202680587768555
Batch 50/64 loss: 0.2436835765838623
Batch 51/64 loss: 0.243982195854187
Batch 52/64 loss: 0.24664771556854248
Batch 53/64 loss: 0.24819505214691162
Batch 54/64 loss: 0.24162405729293823
Batch 55/64 loss: 0.24163103103637695
Batch 56/64 loss: 0.243056058883667
Batch 57/64 loss: 0.24315494298934937
Batch 58/64 loss: 0.2401500940322876
Batch 59/64 loss: 0.23694121837615967
Batch 60/64 loss: 0.24090659618377686
Batch 61/64 loss: 0.24415123462677002
Batch 62/64 loss: 0.24512743949890137
Batch 63/64 loss: 0.2546060085296631
Batch 64/64 loss: 0.23564064502716064
Epoch 226  Train loss: 0.2420637275658402  Val loss: 0.2744434664339544
Epoch 227
-------------------------------
Batch 1/64 loss: 0.2486191987991333
Batch 2/64 loss: 0.24000048637390137
Batch 3/64 loss: 0.24386513233184814
Batch 4/64 loss: 0.23857903480529785
Batch 5/64 loss: 0.23247134685516357
Batch 6/64 loss: 0.24572694301605225
Batch 7/64 loss: 0.23484539985656738
Batch 8/64 loss: 0.2351665496826172
Batch 9/64 loss: 0.24170821905136108
Batch 10/64 loss: 0.24208617210388184
Batch 11/64 loss: 0.24068284034729004
Batch 12/64 loss: 0.2383875846862793
Batch 13/64 loss: 0.2385702133178711
Batch 14/64 loss: 0.247064471244812
Batch 15/64 loss: 0.2467789649963379
Batch 16/64 loss: 0.24758148193359375
Batch 17/64 loss: 0.2444666028022766
Batch 18/64 loss: 0.2452613115310669
Batch 19/64 loss: 0.23368215560913086
Batch 20/64 loss: 0.23949837684631348
Batch 21/64 loss: 0.23326706886291504
Batch 22/64 loss: 0.2378765344619751
Batch 23/64 loss: 0.24045008420944214
Batch 24/64 loss: 0.24415147304534912
Batch 25/64 loss: 0.2356187105178833
Batch 26/64 loss: 0.24473506212234497
Batch 27/64 loss: 0.23940801620483398
Batch 28/64 loss: 0.23849129676818848
Batch 29/64 loss: 0.2373473048210144
Batch 30/64 loss: 0.23595082759857178
Batch 31/64 loss: 0.24278515577316284
Batch 32/64 loss: 0.2341533899307251
Batch 33/64 loss: 0.23527485132217407
Batch 34/64 loss: 0.2414928674697876
Batch 35/64 loss: 0.23508667945861816
Batch 36/64 loss: 0.2349349856376648
Batch 37/64 loss: 0.23679637908935547
Batch 38/64 loss: 0.23747199773788452
Batch 39/64 loss: 0.2319124937057495
Batch 40/64 loss: 0.24994665384292603
Batch 41/64 loss: 0.2425329089164734
Batch 42/64 loss: 0.236983060836792
Batch 43/64 loss: 0.22704613208770752
Batch 44/64 loss: 0.24092423915863037
Batch 45/64 loss: 0.24492287635803223
Batch 46/64 loss: 0.2432538866996765
Batch 47/64 loss: 0.23482662439346313
Batch 48/64 loss: 0.2346293330192566
Batch 49/64 loss: 0.23425865173339844
Batch 50/64 loss: 0.2367173433303833
Batch 51/64 loss: 0.24395489692687988
Batch 52/64 loss: 0.23637527227401733
Batch 53/64 loss: 0.23443955183029175
Batch 54/64 loss: 0.2498323917388916
Batch 55/64 loss: 0.2552945613861084
Batch 56/64 loss: 0.24756920337677002
Batch 57/64 loss: 0.24668973684310913
Batch 58/64 loss: 0.2548030614852905
Batch 59/64 loss: 0.23894715309143066
Batch 60/64 loss: 0.2510990500450134
Batch 61/64 loss: 0.24324119091033936
Batch 62/64 loss: 0.24190568923950195
Batch 63/64 loss: 0.24227911233901978
Batch 64/64 loss: 0.23959589004516602
Epoch 227  Train loss: 0.2405398770874622  Val loss: 0.2745236035474797
Epoch 228
-------------------------------
Batch 1/64 loss: 0.2329345941543579
Batch 2/64 loss: 0.2392176389694214
Batch 3/64 loss: 0.23617756366729736
Batch 4/64 loss: 0.249855637550354
Batch 5/64 loss: 0.23688751459121704
Batch 6/64 loss: 0.2388281226158142
Batch 7/64 loss: 0.24473261833190918
Batch 8/64 loss: 0.24144041538238525
Batch 9/64 loss: 0.23476457595825195
Batch 10/64 loss: 0.23971831798553467
Batch 11/64 loss: 0.23793154954910278
Batch 12/64 loss: 0.2323731780052185
Batch 13/64 loss: 0.242062509059906
Batch 14/64 loss: 0.25820350646972656
Batch 15/64 loss: 0.23321294784545898
Batch 16/64 loss: 0.24048876762390137
Batch 17/64 loss: 0.23240911960601807
Batch 18/64 loss: 0.23880410194396973
Batch 19/64 loss: 0.25042104721069336
Batch 20/64 loss: 0.24320566654205322
Batch 21/64 loss: 0.24953579902648926
Batch 22/64 loss: 0.24249368906021118
Batch 23/64 loss: 0.23678481578826904
Batch 24/64 loss: 0.24987798929214478
Batch 25/64 loss: 0.24121081829071045
Batch 26/64 loss: 0.24808937311172485
Batch 27/64 loss: 0.24090158939361572
Batch 28/64 loss: 0.24547433853149414
Batch 29/64 loss: 0.24518799781799316
Batch 30/64 loss: 0.23779821395874023
Batch 31/64 loss: 0.2401028871536255
Batch 32/64 loss: 0.23815739154815674
Batch 33/64 loss: 0.23235201835632324
Batch 34/64 loss: 0.2365925908088684
Batch 35/64 loss: 0.24156439304351807
Batch 36/64 loss: 0.23920047283172607
Batch 37/64 loss: 0.2293384075164795
Batch 38/64 loss: 0.2530636787414551
Batch 39/64 loss: 0.24091219902038574
Batch 40/64 loss: 0.23872047662734985
Batch 41/64 loss: 0.23185086250305176
Batch 42/64 loss: 0.24149274826049805
Batch 43/64 loss: 0.23312866687774658
Batch 44/64 loss: 0.2350376844406128
Batch 45/64 loss: 0.2468622922897339
Batch 46/64 loss: 0.24074959754943848
Batch 47/64 loss: 0.24450230598449707
Batch 48/64 loss: 0.24726945161819458
Batch 49/64 loss: 0.2360985279083252
Batch 50/64 loss: 0.24371975660324097
Batch 51/64 loss: 0.23911750316619873
Batch 52/64 loss: 0.23797357082366943
Batch 53/64 loss: 0.23753637075424194
Batch 54/64 loss: 0.2478986382484436
Batch 55/64 loss: 0.2265869379043579
Batch 56/64 loss: 0.2387087345123291
Batch 57/64 loss: 0.2421177625656128
Batch 58/64 loss: 0.24014443159103394
Batch 59/64 loss: 0.2311171293258667
Batch 60/64 loss: 0.2390049695968628
Batch 61/64 loss: 0.23921167850494385
Batch 62/64 loss: 0.24179446697235107
Batch 63/64 loss: 0.2459620237350464
Batch 64/64 loss: 0.2334916591644287
Epoch 228  Train loss: 0.24022013159359204  Val loss: 0.27372312791568715
Epoch 229
-------------------------------
Batch 1/64 loss: 0.23077315092086792
Batch 2/64 loss: 0.23345553874969482
Batch 3/64 loss: 0.23449915647506714
Batch 4/64 loss: 0.2371985912322998
Batch 5/64 loss: 0.2286807894706726
Batch 6/64 loss: 0.24060600996017456
Batch 7/64 loss: 0.24534547328948975
Batch 8/64 loss: 0.23961544036865234
Batch 9/64 loss: 0.2346411943435669
Batch 10/64 loss: 0.24644505977630615
Batch 11/64 loss: 0.2415860891342163
Batch 12/64 loss: 0.2403915524482727
Batch 13/64 loss: 0.23117834329605103
Batch 14/64 loss: 0.23147332668304443
Batch 15/64 loss: 0.2563067674636841
Batch 16/64 loss: 0.22905826568603516
Batch 17/64 loss: 0.23667728900909424
Batch 18/64 loss: 0.2326192855834961
Batch 19/64 loss: 0.24184191226959229
Batch 20/64 loss: 0.24332845211029053
Batch 21/64 loss: 0.24073290824890137
Batch 22/64 loss: 0.24195516109466553
Batch 23/64 loss: 0.22564983367919922
Batch 24/64 loss: 0.25030893087387085
Batch 25/64 loss: 0.2435370683670044
Batch 26/64 loss: 0.24361586570739746
Batch 27/64 loss: 0.24468636512756348
Batch 28/64 loss: 0.24126875400543213
Batch 29/64 loss: 0.24324077367782593
Batch 30/64 loss: 0.23620903491973877
Batch 31/64 loss: 0.24316632747650146
Batch 32/64 loss: 0.23647278547286987
Batch 33/64 loss: 0.24395287036895752
Batch 34/64 loss: 0.2503235936164856
Batch 35/64 loss: 0.2353827953338623
Batch 36/64 loss: 0.23285835981369019
Batch 37/64 loss: 0.23831743001937866
Batch 38/64 loss: 0.23665761947631836
Batch 39/64 loss: 0.24830389022827148
Batch 40/64 loss: 0.24518412351608276
Batch 41/64 loss: 0.23708808422088623
Batch 42/64 loss: 0.2388162612915039
Batch 43/64 loss: 0.23439180850982666
Batch 44/64 loss: 0.23869866132736206
Batch 45/64 loss: 0.2379581332206726
Batch 46/64 loss: 0.2504372000694275
Batch 47/64 loss: 0.23876070976257324
Batch 48/64 loss: 0.2313239574432373
Batch 49/64 loss: 0.24509447813034058
Batch 50/64 loss: 0.24093639850616455
Batch 51/64 loss: 0.24659419059753418
Batch 52/64 loss: 0.254095196723938
Batch 53/64 loss: 0.24156761169433594
Batch 54/64 loss: 0.24797546863555908
Batch 55/64 loss: 0.24634778499603271
Batch 56/64 loss: 0.24604058265686035
Batch 57/64 loss: 0.23725354671478271
Batch 58/64 loss: 0.23714566230773926
Batch 59/64 loss: 0.2399386167526245
Batch 60/64 loss: 0.23923999071121216
Batch 61/64 loss: 0.23795151710510254
Batch 62/64 loss: 0.2448902726173401
Batch 63/64 loss: 0.24449574947357178
Batch 64/64 loss: 0.23677921295166016
Epoch 229  Train loss: 0.24019094074473663  Val loss: 0.27316318918339577
Epoch 230
-------------------------------
Batch 1/64 loss: 0.23496025800704956
Batch 2/64 loss: 0.23815429210662842
Batch 3/64 loss: 0.2459455132484436
Batch 4/64 loss: 0.23345404863357544
Batch 5/64 loss: 0.24330508708953857
Batch 6/64 loss: 0.23475825786590576
Batch 7/64 loss: 0.23693108558654785
Batch 8/64 loss: 0.23447948694229126
Batch 9/64 loss: 0.23779094219207764
Batch 10/64 loss: 0.23906612396240234
Batch 11/64 loss: 0.24445950984954834
Batch 12/64 loss: 0.232407808303833
Batch 13/64 loss: 0.2397821545600891
Batch 14/64 loss: 0.24033445119857788
Batch 15/64 loss: 0.23807430267333984
Batch 16/64 loss: 0.23707127571105957
Batch 17/64 loss: 0.2434186339378357
Batch 18/64 loss: 0.23867738246917725
Batch 19/64 loss: 0.22949117422103882
Batch 20/64 loss: 0.2399669885635376
Batch 21/64 loss: 0.24207568168640137
Batch 22/64 loss: 0.25522029399871826
Batch 23/64 loss: 0.24980252981185913
Batch 24/64 loss: 0.24130970239639282
Batch 25/64 loss: 0.24090635776519775
Batch 26/64 loss: 0.24097591638565063
Batch 27/64 loss: 0.2431497573852539
Batch 28/64 loss: 0.24713116884231567
Batch 29/64 loss: 0.23603767156600952
Batch 30/64 loss: 0.23782795667648315
Batch 31/64 loss: 0.2475048303604126
Batch 32/64 loss: 0.25031667947769165
Batch 33/64 loss: 0.2524145841598511
Batch 34/64 loss: 0.24667781591415405
Batch 35/64 loss: 0.23538106679916382
Batch 36/64 loss: 0.23571056127548218
Batch 37/64 loss: 0.23644816875457764
Batch 38/64 loss: 0.23560833930969238
Batch 39/64 loss: 0.2512715458869934
Batch 40/64 loss: 0.24251008033752441
Batch 41/64 loss: 0.23667025566101074
Batch 42/64 loss: 0.23703134059906006
Batch 43/64 loss: 0.245683491230011
Batch 44/64 loss: 0.23816537857055664
Batch 45/64 loss: 0.2393743395805359
Batch 46/64 loss: 0.24858254194259644
Batch 47/64 loss: 0.24494212865829468
Batch 48/64 loss: 0.2373645305633545
Batch 49/64 loss: 0.23846495151519775
Batch 50/64 loss: 0.23857522010803223
Batch 51/64 loss: 0.23102688789367676
Batch 52/64 loss: 0.24036192893981934
Batch 53/64 loss: 0.24851560592651367
Batch 54/64 loss: 0.2352169156074524
Batch 55/64 loss: 0.2424166202545166
Batch 56/64 loss: 0.23034954071044922
Batch 57/64 loss: 0.24020355939865112
Batch 58/64 loss: 0.2539753317832947
Batch 59/64 loss: 0.24319922924041748
Batch 60/64 loss: 0.2337619662284851
Batch 61/64 loss: 0.23297715187072754
Batch 62/64 loss: 0.25525784492492676
Batch 63/64 loss: 0.2472214698791504
Batch 64/64 loss: 0.24777960777282715
Epoch 230  Train loss: 0.2408781556522145  Val loss: 0.2730357943941228
Epoch 231
-------------------------------
Batch 1/64 loss: 0.23774290084838867
Batch 2/64 loss: 0.23640596866607666
Batch 3/64 loss: 0.24819636344909668
Batch 4/64 loss: 0.23628604412078857
Batch 5/64 loss: 0.22947365045547485
Batch 6/64 loss: 0.23758703470230103
Batch 7/64 loss: 0.24196279048919678
Batch 8/64 loss: 0.23730993270874023
Batch 9/64 loss: 0.23668783903121948
Batch 10/64 loss: 0.24232614040374756
Batch 11/64 loss: 0.2418729066848755
Batch 12/64 loss: 0.2377079725265503
Batch 13/64 loss: 0.26072782278060913
Batch 14/64 loss: 0.23648399114608765
Batch 15/64 loss: 0.24435436725616455
Batch 16/64 loss: 0.23517835140228271
Batch 17/64 loss: 0.23343300819396973
Batch 18/64 loss: 0.2322239875793457
Batch 19/64 loss: 0.2371947169303894
Batch 20/64 loss: 0.2434116005897522
Batch 21/64 loss: 0.23682737350463867
Batch 22/64 loss: 0.24815034866333008
Batch 23/64 loss: 0.2411181926727295
Batch 24/64 loss: 0.23805665969848633
Batch 25/64 loss: 0.23028504848480225
Batch 26/64 loss: 0.24218207597732544
Batch 27/64 loss: 0.23749172687530518
Batch 28/64 loss: 0.24670028686523438
Batch 29/64 loss: 0.24361741542816162
Batch 30/64 loss: 0.24312597513198853
Batch 31/64 loss: 0.23829877376556396
Batch 32/64 loss: 0.24248945713043213
Batch 33/64 loss: 0.2362123727798462
Batch 34/64 loss: 0.23080575466156006
Batch 35/64 loss: 0.23845064640045166
Batch 36/64 loss: 0.2410142421722412
Batch 37/64 loss: 0.23238372802734375
Batch 38/64 loss: 0.24460899829864502
Batch 39/64 loss: 0.24115407466888428
Batch 40/64 loss: 0.24525576829910278
Batch 41/64 loss: 0.23944193124771118
Batch 42/64 loss: 0.23579490184783936
Batch 43/64 loss: 0.24271327257156372
Batch 44/64 loss: 0.2442663311958313
Batch 45/64 loss: 0.23731422424316406
Batch 46/64 loss: 0.2375631332397461
Batch 47/64 loss: 0.23967814445495605
Batch 48/64 loss: 0.23675590753555298
Batch 49/64 loss: 0.24219274520874023
Batch 50/64 loss: 0.24059486389160156
Batch 51/64 loss: 0.23883020877838135
Batch 52/64 loss: 0.23172926902770996
Batch 53/64 loss: 0.24764484167099
Batch 54/64 loss: 0.2353745698928833
Batch 55/64 loss: 0.23748481273651123
Batch 56/64 loss: 0.23810648918151855
Batch 57/64 loss: 0.23861652612686157
Batch 58/64 loss: 0.24305295944213867
Batch 59/64 loss: 0.2530174255371094
Batch 60/64 loss: 0.23806822299957275
Batch 61/64 loss: 0.24126064777374268
Batch 62/64 loss: 0.2374359369277954
Batch 63/64 loss: 0.24156516790390015
Batch 64/64 loss: 0.2624328136444092
Epoch 231  Train loss: 0.2400019365198472  Val loss: 0.2726049445748739
Epoch 232
-------------------------------
Batch 1/64 loss: 0.24250191450119019
Batch 2/64 loss: 0.23793256282806396
Batch 3/64 loss: 0.24314242601394653
Batch 4/64 loss: 0.2404409646987915
Batch 5/64 loss: 0.24135971069335938
Batch 6/64 loss: 0.24160897731781006
Batch 7/64 loss: 0.23834973573684692
Batch 8/64 loss: 0.2435120940208435
Batch 9/64 loss: 0.24368834495544434
Batch 10/64 loss: 0.23335576057434082
Batch 11/64 loss: 0.2385256290435791
Batch 12/64 loss: 0.23862159252166748
Batch 13/64 loss: 0.23483145236968994
Batch 14/64 loss: 0.24160492420196533
Batch 15/64 loss: 0.2519450783729553
Batch 16/64 loss: 0.2421608567237854
Batch 17/64 loss: 0.25290030241012573
Batch 18/64 loss: 0.2339334487915039
Batch 19/64 loss: 0.24583423137664795
Batch 20/64 loss: 0.24154061079025269
Batch 21/64 loss: 0.2454776167869568
Batch 22/64 loss: 0.2546393871307373
Batch 23/64 loss: 0.2444443702697754
Batch 24/64 loss: 0.23900914192199707
Batch 25/64 loss: 0.23808777332305908
Batch 26/64 loss: 0.23572003841400146
Batch 27/64 loss: 0.24081861972808838
Batch 28/64 loss: 0.2337999939918518
Batch 29/64 loss: 0.23961371183395386
Batch 30/64 loss: 0.2431246042251587
Batch 31/64 loss: 0.22705292701721191
Batch 32/64 loss: 0.23618310689926147
Batch 33/64 loss: 0.24572402238845825
Batch 34/64 loss: 0.23319858312606812
Batch 35/64 loss: 0.23942822217941284
Batch 36/64 loss: 0.23607730865478516
Batch 37/64 loss: 0.23940497636795044
Batch 38/64 loss: 0.25150948762893677
Batch 39/64 loss: 0.23938614130020142
Batch 40/64 loss: 0.2389141321182251
Batch 41/64 loss: 0.23077595233917236
Batch 42/64 loss: 0.24704527854919434
Batch 43/64 loss: 0.23897325992584229
Batch 44/64 loss: 0.2396746277809143
Batch 45/64 loss: 0.23237931728363037
Batch 46/64 loss: 0.2514606714248657
Batch 47/64 loss: 0.2457106113433838
Batch 48/64 loss: 0.23639178276062012
Batch 49/64 loss: 0.24088704586029053
Batch 50/64 loss: 0.2335972785949707
Batch 51/64 loss: 0.24288880825042725
Batch 52/64 loss: 0.245805025100708
Batch 53/64 loss: 0.23505628108978271
Batch 54/64 loss: 0.23841631412506104
Batch 55/64 loss: 0.23578226566314697
Batch 56/64 loss: 0.23769104480743408
Batch 57/64 loss: 0.2480871081352234
Batch 58/64 loss: 0.2536834478378296
Batch 59/64 loss: 0.23595774173736572
Batch 60/64 loss: 0.24482953548431396
Batch 61/64 loss: 0.23592132329940796
Batch 62/64 loss: 0.24864017963409424
Batch 63/64 loss: 0.23699092864990234
Batch 64/64 loss: 0.23993313312530518
Epoch 232  Train loss: 0.24072157588659548  Val loss: 0.273676121152963
Epoch 233
-------------------------------
Batch 1/64 loss: 0.24224108457565308
Batch 2/64 loss: 0.23225104808807373
Batch 3/64 loss: 0.23522520065307617
Batch 4/64 loss: 0.23822742700576782
Batch 5/64 loss: 0.23686182498931885
Batch 6/64 loss: 0.23472535610198975
Batch 7/64 loss: 0.2360638976097107
Batch 8/64 loss: 0.2386537790298462
Batch 9/64 loss: 0.23499435186386108
Batch 10/64 loss: 0.23614394664764404
Batch 11/64 loss: 0.24542081356048584
Batch 12/64 loss: 0.2392166256904602
Batch 13/64 loss: 0.2425752878189087
Batch 14/64 loss: 0.2452964186668396
Batch 15/64 loss: 0.24063503742218018
Batch 16/64 loss: 0.23282390832901
Batch 17/64 loss: 0.237457275390625
Batch 18/64 loss: 0.24578237533569336
Batch 19/64 loss: 0.2333747148513794
Batch 20/64 loss: 0.23161429166793823
Batch 21/64 loss: 0.24000310897827148
Batch 22/64 loss: 0.230779767036438
Batch 23/64 loss: 0.23742687702178955
Batch 24/64 loss: 0.23620009422302246
Batch 25/64 loss: 0.24880385398864746
Batch 26/64 loss: 0.23232579231262207
Batch 27/64 loss: 0.2310107946395874
Batch 28/64 loss: 0.2308640480041504
Batch 29/64 loss: 0.2355749011039734
Batch 30/64 loss: 0.2375277280807495
Batch 31/64 loss: 0.23426145315170288
Batch 32/64 loss: 0.23993515968322754
Batch 33/64 loss: 0.255537748336792
Batch 34/64 loss: 0.23464435338974
Batch 35/64 loss: 0.2448941469192505
Batch 36/64 loss: 0.23693454265594482
Batch 37/64 loss: 0.23700934648513794
Batch 38/64 loss: 0.23399996757507324
Batch 39/64 loss: 0.23448973894119263
Batch 40/64 loss: 0.23855698108673096
Batch 41/64 loss: 0.23552286624908447
Batch 42/64 loss: 0.2363516092300415
Batch 43/64 loss: 0.23759609460830688
Batch 44/64 loss: 0.2400418519973755
Batch 45/64 loss: 0.24706262350082397
Batch 46/64 loss: 0.24109864234924316
Batch 47/64 loss: 0.24434876441955566
Batch 48/64 loss: 0.24519526958465576
Batch 49/64 loss: 0.24064147472381592
Batch 50/64 loss: 0.23661202192306519
Batch 51/64 loss: 0.2508573532104492
Batch 52/64 loss: 0.2462325096130371
Batch 53/64 loss: 0.24103718996047974
Batch 54/64 loss: 0.24471700191497803
Batch 55/64 loss: 0.23835676908493042
Batch 56/64 loss: 0.23597705364227295
Batch 57/64 loss: 0.2523014545440674
Batch 58/64 loss: 0.23919349908828735
Batch 59/64 loss: 0.2473069429397583
Batch 60/64 loss: 0.2382757067680359
Batch 61/64 loss: 0.2352447509765625
Batch 62/64 loss: 0.24329519271850586
Batch 63/64 loss: 0.2461531162261963
Batch 64/64 loss: 0.25754159688949585
Epoch 233  Train loss: 0.2394814278565201  Val loss: 0.27314900348276616
Epoch 234
-------------------------------
Batch 1/64 loss: 0.23762375116348267
Batch 2/64 loss: 0.2407090663909912
Batch 3/64 loss: 0.2324291467666626
Batch 4/64 loss: 0.25261998176574707
Batch 5/64 loss: 0.23728424310684204
Batch 6/64 loss: 0.24686241149902344
Batch 7/64 loss: 0.23098540306091309
Batch 8/64 loss: 0.2328563928604126
Batch 9/64 loss: 0.24173599481582642
Batch 10/64 loss: 0.23958909511566162
Batch 11/64 loss: 0.23104208707809448
Batch 12/64 loss: 0.24078905582427979
Batch 13/64 loss: 0.2401302456855774
Batch 14/64 loss: 0.23520922660827637
Batch 15/64 loss: 0.23555231094360352
Batch 16/64 loss: 0.2405681014060974
Batch 17/64 loss: 0.23917114734649658
Batch 18/64 loss: 0.23988473415374756
Batch 19/64 loss: 0.23667383193969727
Batch 20/64 loss: 0.2339102029800415
Batch 21/64 loss: 0.2353757619857788
Batch 22/64 loss: 0.23587363958358765
Batch 23/64 loss: 0.23883962631225586
Batch 24/64 loss: 0.2297230362892151
Batch 25/64 loss: 0.23653697967529297
Batch 26/64 loss: 0.24647384881973267
Batch 27/64 loss: 0.23905730247497559
Batch 28/64 loss: 0.23687022924423218
Batch 29/64 loss: 0.2361326813697815
Batch 30/64 loss: 0.24528515338897705
Batch 31/64 loss: 0.24272406101226807
Batch 32/64 loss: 0.23666179180145264
Batch 33/64 loss: 0.24124997854232788
Batch 34/64 loss: 0.24669033288955688
Batch 35/64 loss: 0.23360633850097656
Batch 36/64 loss: 0.23739421367645264
Batch 37/64 loss: 0.23866641521453857
Batch 38/64 loss: 0.2417151927947998
Batch 39/64 loss: 0.23497307300567627
Batch 40/64 loss: 0.2492530345916748
Batch 41/64 loss: 0.23151743412017822
Batch 42/64 loss: 0.23386728763580322
Batch 43/64 loss: 0.2363312840461731
Batch 44/64 loss: 0.23882246017456055
Batch 45/64 loss: 0.24552452564239502
Batch 46/64 loss: 0.24445247650146484
Batch 47/64 loss: 0.2450738549232483
Batch 48/64 loss: 0.2450888752937317
Batch 49/64 loss: 0.24147069454193115
Batch 50/64 loss: 0.23295629024505615
Batch 51/64 loss: 0.23171257972717285
Batch 52/64 loss: 0.24447786808013916
Batch 53/64 loss: 0.24138814210891724
Batch 54/64 loss: 0.24504971504211426
Batch 55/64 loss: 0.2367802858352661
Batch 56/64 loss: 0.2424851655960083
Batch 57/64 loss: 0.2379225492477417
Batch 58/64 loss: 0.23846185207366943
Batch 59/64 loss: 0.2371959686279297
Batch 60/64 loss: 0.2447986602783203
Batch 61/64 loss: 0.23745810985565186
Batch 62/64 loss: 0.23812973499298096
Batch 63/64 loss: 0.24266839027404785
Batch 64/64 loss: 0.23901891708374023
Epoch 234  Train loss: 0.239084353166468  Val loss: 0.27278717932422547
Epoch 235
-------------------------------
Batch 1/64 loss: 0.23203730583190918
Batch 2/64 loss: 0.23781287670135498
Batch 3/64 loss: 0.2394317388534546
Batch 4/64 loss: 0.23891109228134155
Batch 5/64 loss: 0.24209129810333252
Batch 6/64 loss: 0.22860288619995117
Batch 7/64 loss: 0.23678767681121826
Batch 8/64 loss: 0.2496786117553711
Batch 9/64 loss: 0.23568516969680786
Batch 10/64 loss: 0.23804724216461182
Batch 11/64 loss: 0.2424018383026123
Batch 12/64 loss: 0.2391095757484436
Batch 13/64 loss: 0.2370341420173645
Batch 14/64 loss: 0.23968732357025146
Batch 15/64 loss: 0.24039924144744873
Batch 16/64 loss: 0.2416626214981079
Batch 17/64 loss: 0.23520195484161377
Batch 18/64 loss: 0.23869025707244873
Batch 19/64 loss: 0.2327650785446167
Batch 20/64 loss: 0.24613499641418457
Batch 21/64 loss: 0.23922127485275269
Batch 22/64 loss: 0.2388530969619751
Batch 23/64 loss: 0.24090224504470825
Batch 24/64 loss: 0.24977576732635498
Batch 25/64 loss: 0.23571324348449707
Batch 26/64 loss: 0.2394556999206543
Batch 27/64 loss: 0.23710811138153076
Batch 28/64 loss: 0.23800837993621826
Batch 29/64 loss: 0.24447298049926758
Batch 30/64 loss: 0.24831277132034302
Batch 31/64 loss: 0.23584049940109253
Batch 32/64 loss: 0.23725807666778564
Batch 33/64 loss: 0.24431073665618896
Batch 34/64 loss: 0.23899608850479126
Batch 35/64 loss: 0.24563837051391602
Batch 36/64 loss: 0.24059897661209106
Batch 37/64 loss: 0.23374611139297485
Batch 38/64 loss: 0.2360835075378418
Batch 39/64 loss: 0.2287583351135254
Batch 40/64 loss: 0.22892212867736816
Batch 41/64 loss: 0.23186737298965454
Batch 42/64 loss: 0.23721575736999512
Batch 43/64 loss: 0.24996590614318848
Batch 44/64 loss: 0.23041725158691406
Batch 45/64 loss: 0.24070817232131958
Batch 46/64 loss: 0.23277658224105835
Batch 47/64 loss: 0.2393435835838318
Batch 48/64 loss: 0.23227226734161377
Batch 49/64 loss: 0.23232495784759521
Batch 50/64 loss: 0.2343859076499939
Batch 51/64 loss: 0.24590295553207397
Batch 52/64 loss: 0.23155176639556885
Batch 53/64 loss: 0.23190462589263916
Batch 54/64 loss: 0.2409684658050537
Batch 55/64 loss: 0.2368096113204956
Batch 56/64 loss: 0.23469364643096924
Batch 57/64 loss: 0.2471606731414795
Batch 58/64 loss: 0.24087220430374146
Batch 59/64 loss: 0.25350165367126465
Batch 60/64 loss: 0.2422870397567749
Batch 61/64 loss: 0.2298058271408081
Batch 62/64 loss: 0.23862886428833008
Batch 63/64 loss: 0.23688393831253052
Batch 64/64 loss: 0.24829363822937012
Epoch 235  Train loss: 0.23862931120629405  Val loss: 0.27175690177380013
Saving best model, epoch: 235
Epoch 236
-------------------------------
Batch 1/64 loss: 0.23839563131332397
Batch 2/64 loss: 0.23695909976959229
Batch 3/64 loss: 0.23910105228424072
Batch 4/64 loss: 0.23393601179122925
Batch 5/64 loss: 0.23225224018096924
Batch 6/64 loss: 0.2363452911376953
Batch 7/64 loss: 0.2303699254989624
Batch 8/64 loss: 0.24492526054382324
Batch 9/64 loss: 0.2434740662574768
Batch 10/64 loss: 0.23193788528442383
Batch 11/64 loss: 0.2371964454650879
Batch 12/64 loss: 0.23316693305969238
Batch 13/64 loss: 0.23482143878936768
Batch 14/64 loss: 0.23875749111175537
Batch 15/64 loss: 0.23574131727218628
Batch 16/64 loss: 0.23315882682800293
Batch 17/64 loss: 0.2307124137878418
Batch 18/64 loss: 0.2359861135482788
Batch 19/64 loss: 0.2352045774459839
Batch 20/64 loss: 0.23273998498916626
Batch 21/64 loss: 0.24314898252487183
Batch 22/64 loss: 0.23929452896118164
Batch 23/64 loss: 0.23983800411224365
Batch 24/64 loss: 0.23619842529296875
Batch 25/64 loss: 0.23829710483551025
Batch 26/64 loss: 0.23094594478607178
Batch 27/64 loss: 0.23697185516357422
Batch 28/64 loss: 0.2454991340637207
Batch 29/64 loss: 0.2438422441482544
Batch 30/64 loss: 0.2474501132965088
Batch 31/64 loss: 0.23746764659881592
Batch 32/64 loss: 0.2257038950920105
Batch 33/64 loss: 0.23711025714874268
Batch 34/64 loss: 0.2385571002960205
Batch 35/64 loss: 0.25329601764678955
Batch 36/64 loss: 0.23661762475967407
Batch 37/64 loss: 0.23505932092666626
Batch 38/64 loss: 0.2383795976638794
Batch 39/64 loss: 0.23774617910385132
Batch 40/64 loss: 0.24145722389221191
Batch 41/64 loss: 0.24385100603103638
Batch 42/64 loss: 0.234779953956604
Batch 43/64 loss: 0.24923932552337646
Batch 44/64 loss: 0.22970175743103027
Batch 45/64 loss: 0.23819231986999512
Batch 46/64 loss: 0.24425113201141357
Batch 47/64 loss: 0.2412225604057312
Batch 48/64 loss: 0.24064838886260986
Batch 49/64 loss: 0.24250543117523193
Batch 50/64 loss: 0.2381569743156433
Batch 51/64 loss: 0.2339843511581421
Batch 52/64 loss: 0.23845326900482178
Batch 53/64 loss: 0.2304600477218628
Batch 54/64 loss: 0.23765826225280762
Batch 55/64 loss: 0.2436603307723999
Batch 56/64 loss: 0.23874998092651367
Batch 57/64 loss: 0.23510092496871948
Batch 58/64 loss: 0.24084687232971191
Batch 59/64 loss: 0.2386634349822998
Batch 60/64 loss: 0.2435396909713745
Batch 61/64 loss: 0.24031776189804077
Batch 62/64 loss: 0.23416483402252197
Batch 63/64 loss: 0.24282777309417725
Batch 64/64 loss: 0.2428891658782959
Epoch 236  Train loss: 0.23813657199635224  Val loss: 0.27326443555838464
Epoch 237
-------------------------------
Batch 1/64 loss: 0.24011969566345215
Batch 2/64 loss: 0.23376601934432983
Batch 3/64 loss: 0.23784512281417847
Batch 4/64 loss: 0.2434188723564148
Batch 5/64 loss: 0.23379039764404297
Batch 6/64 loss: 0.23009228706359863
Batch 7/64 loss: 0.23722195625305176
Batch 8/64 loss: 0.23524677753448486
Batch 9/64 loss: 0.24440842866897583
Batch 10/64 loss: 0.23884272575378418
Batch 11/64 loss: 0.23745304346084595
Batch 12/64 loss: 0.23714274168014526
Batch 13/64 loss: 0.23459386825561523
Batch 14/64 loss: 0.24393856525421143
Batch 15/64 loss: 0.24436944723129272
Batch 16/64 loss: 0.2389223575592041
Batch 17/64 loss: 0.23607969284057617
Batch 18/64 loss: 0.23385769128799438
Batch 19/64 loss: 0.23013067245483398
Batch 20/64 loss: 0.24179929494857788
Batch 21/64 loss: 0.23536652326583862
Batch 22/64 loss: 0.23908519744873047
Batch 23/64 loss: 0.24908149242401123
Batch 24/64 loss: 0.23552340269088745
Batch 25/64 loss: 0.23615700006484985
Batch 26/64 loss: 0.23136961460113525
Batch 27/64 loss: 0.24472075700759888
Batch 28/64 loss: 0.2392897605895996
Batch 29/64 loss: 0.23083281517028809
Batch 30/64 loss: 0.23782360553741455
Batch 31/64 loss: 0.24257594347000122
Batch 32/64 loss: 0.23959380388259888
Batch 33/64 loss: 0.23400306701660156
Batch 34/64 loss: 0.24508965015411377
Batch 35/64 loss: 0.24527651071548462
Batch 36/64 loss: 0.23051780462265015
Batch 37/64 loss: 0.23591041564941406
Batch 38/64 loss: 0.2404131293296814
Batch 39/64 loss: 0.23328840732574463
Batch 40/64 loss: 0.2382042407989502
Batch 41/64 loss: 0.23441839218139648
Batch 42/64 loss: 0.2379465103149414
Batch 43/64 loss: 0.23453187942504883
Batch 44/64 loss: 0.23024916648864746
Batch 45/64 loss: 0.24079501628875732
Batch 46/64 loss: 0.25103265047073364
Batch 47/64 loss: 0.23421764373779297
Batch 48/64 loss: 0.24046850204467773
Batch 49/64 loss: 0.2390761375427246
Batch 50/64 loss: 0.23472285270690918
Batch 51/64 loss: 0.23567545413970947
Batch 52/64 loss: 0.23848497867584229
Batch 53/64 loss: 0.24763000011444092
Batch 54/64 loss: 0.2304735779762268
Batch 55/64 loss: 0.23845767974853516
Batch 56/64 loss: 0.23702692985534668
Batch 57/64 loss: 0.2503387928009033
Batch 58/64 loss: 0.23602420091629028
Batch 59/64 loss: 0.2403346300125122
Batch 60/64 loss: 0.24113714694976807
Batch 61/64 loss: 0.2416514754295349
Batch 62/64 loss: 0.2513630986213684
Batch 63/64 loss: 0.23773086071014404
Batch 64/64 loss: 0.24438750743865967
Epoch 237  Train loss: 0.23849789815790512  Val loss: 0.27192510382825974
Epoch 238
-------------------------------
Batch 1/64 loss: 0.2430185079574585
Batch 2/64 loss: 0.23477911949157715
Batch 3/64 loss: 0.240237295627594
Batch 4/64 loss: 0.23771214485168457
Batch 5/64 loss: 0.23303353786468506
Batch 6/64 loss: 0.2477349042892456
Batch 7/64 loss: 0.23661398887634277
Batch 8/64 loss: 0.22782838344573975
Batch 9/64 loss: 0.23038756847381592
Batch 10/64 loss: 0.23457777500152588
Batch 11/64 loss: 0.23916280269622803
Batch 12/64 loss: 0.23462527990341187
Batch 13/64 loss: 0.241019606590271
Batch 14/64 loss: 0.2482774257659912
Batch 15/64 loss: 0.23543626070022583
Batch 16/64 loss: 0.2366665005683899
Batch 17/64 loss: 0.2335047721862793
Batch 18/64 loss: 0.23440992832183838
Batch 19/64 loss: 0.23766756057739258
Batch 20/64 loss: 0.23118364810943604
Batch 21/64 loss: 0.23743939399719238
Batch 22/64 loss: 0.24554026126861572
Batch 23/64 loss: 0.23599064350128174
Batch 24/64 loss: 0.24522334337234497
Batch 25/64 loss: 0.22997069358825684
Batch 26/64 loss: 0.2345985770225525
Batch 27/64 loss: 0.22911930084228516
Batch 28/64 loss: 0.23527181148529053
Batch 29/64 loss: 0.23514235019683838
Batch 30/64 loss: 0.2327466607093811
Batch 31/64 loss: 0.2395009994506836
Batch 32/64 loss: 0.24528801441192627
Batch 33/64 loss: 0.23374807834625244
Batch 34/64 loss: 0.2386876344680786
Batch 35/64 loss: 0.2422558069229126
Batch 36/64 loss: 0.23662030696868896
Batch 37/64 loss: 0.24538379907608032
Batch 38/64 loss: 0.24755257368087769
Batch 39/64 loss: 0.24854689836502075
Batch 40/64 loss: 0.2383939027786255
Batch 41/64 loss: 0.23123204708099365
Batch 42/64 loss: 0.2328866720199585
Batch 43/64 loss: 0.24059772491455078
Batch 44/64 loss: 0.23194777965545654
Batch 45/64 loss: 0.23909956216812134
Batch 46/64 loss: 0.2437281608581543
Batch 47/64 loss: 0.25619351863861084
Batch 48/64 loss: 0.24687910079956055
Batch 49/64 loss: 0.24314594268798828
Batch 50/64 loss: 0.23522543907165527
Batch 51/64 loss: 0.23543983697891235
Batch 52/64 loss: 0.23803287744522095
Batch 53/64 loss: 0.2311161756515503
Batch 54/64 loss: 0.23216986656188965
Batch 55/64 loss: 0.241013765335083
Batch 56/64 loss: 0.23693883419036865
Batch 57/64 loss: 0.24749869108200073
Batch 58/64 loss: 0.24796807765960693
Batch 59/64 loss: 0.2352498173713684
Batch 60/64 loss: 0.2429046630859375
Batch 61/64 loss: 0.23532408475875854
Batch 62/64 loss: 0.23681741952896118
Batch 63/64 loss: 0.2407638430595398
Batch 64/64 loss: 0.23659515380859375
Epoch 238  Train loss: 0.23834538553275314  Val loss: 0.2724057948056775
Epoch 239
-------------------------------
Batch 1/64 loss: 0.23462772369384766
Batch 2/64 loss: 0.23132145404815674
Batch 3/64 loss: 0.24598127603530884
Batch 4/64 loss: 0.2350693941116333
Batch 5/64 loss: 0.23668408393859863
Batch 6/64 loss: 0.246734619140625
Batch 7/64 loss: 0.23640286922454834
Batch 8/64 loss: 0.2331228256225586
Batch 9/64 loss: 0.2345975637435913
Batch 10/64 loss: 0.23615622520446777
Batch 11/64 loss: 0.2336357831954956
Batch 12/64 loss: 0.23362964391708374
Batch 13/64 loss: 0.23861539363861084
Batch 14/64 loss: 0.23507976531982422
Batch 15/64 loss: 0.24608618021011353
Batch 16/64 loss: 0.23908281326293945
Batch 17/64 loss: 0.24051302671432495
Batch 18/64 loss: 0.23192119598388672
Batch 19/64 loss: 0.2391151785850525
Batch 20/64 loss: 0.2401023507118225
Batch 21/64 loss: 0.2460121512413025
Batch 22/64 loss: 0.2343761920928955
Batch 23/64 loss: 0.23443639278411865
Batch 24/64 loss: 0.2271602749824524
Batch 25/64 loss: 0.2424694299697876
Batch 26/64 loss: 0.22903317213058472
Batch 27/64 loss: 0.23734724521636963
Batch 28/64 loss: 0.23256760835647583
Batch 29/64 loss: 0.23434001207351685
Batch 30/64 loss: 0.24913489818572998
Batch 31/64 loss: 0.2399306297302246
Batch 32/64 loss: 0.2429720163345337
Batch 33/64 loss: 0.24295306205749512
Batch 34/64 loss: 0.24452072381973267
Batch 35/64 loss: 0.2344285249710083
Batch 36/64 loss: 0.23296856880187988
Batch 37/64 loss: 0.24251264333724976
Batch 38/64 loss: 0.23710119724273682
Batch 39/64 loss: 0.2385878562927246
Batch 40/64 loss: 0.2577172517776489
Batch 41/64 loss: 0.2512184977531433
Batch 42/64 loss: 0.2367180585861206
Batch 43/64 loss: 0.2497013807296753
Batch 44/64 loss: 0.23212236166000366
Batch 45/64 loss: 0.23649752140045166
Batch 46/64 loss: 0.2490602731704712
Batch 47/64 loss: 0.23513758182525635
Batch 48/64 loss: 0.23646897077560425
Batch 49/64 loss: 0.24498987197875977
Batch 50/64 loss: 0.23405230045318604
Batch 51/64 loss: 0.23682451248168945
Batch 52/64 loss: 0.2434006929397583
Batch 53/64 loss: 0.23418354988098145
Batch 54/64 loss: 0.2388436198234558
Batch 55/64 loss: 0.22711241245269775
Batch 56/64 loss: 0.25528931617736816
Batch 57/64 loss: 0.2307809591293335
Batch 58/64 loss: 0.23310422897338867
Batch 59/64 loss: 0.23747146129608154
Batch 60/64 loss: 0.22991347312927246
Batch 61/64 loss: 0.22481393814086914
Batch 62/64 loss: 0.239887535572052
Batch 63/64 loss: 0.2287781834602356
Batch 64/64 loss: 0.2344338297843933
Epoch 239  Train loss: 0.2379803183032017  Val loss: 0.27183322193696324
Epoch 240
-------------------------------
Batch 1/64 loss: 0.23797506093978882
Batch 2/64 loss: 0.2375032901763916
Batch 3/64 loss: 0.22952395677566528
Batch 4/64 loss: 0.2390279769897461
Batch 5/64 loss: 0.23822128772735596
Batch 6/64 loss: 0.23693621158599854
Batch 7/64 loss: 0.23466837406158447
Batch 8/64 loss: 0.23634833097457886
Batch 9/64 loss: 0.2457122802734375
Batch 10/64 loss: 0.23954671621322632
Batch 11/64 loss: 0.23503541946411133
Batch 12/64 loss: 0.24567413330078125
Batch 13/64 loss: 0.23812103271484375
Batch 14/64 loss: 0.24562859535217285
Batch 15/64 loss: 0.2371065616607666
Batch 16/64 loss: 0.23137247562408447
Batch 17/64 loss: 0.2312755584716797
Batch 18/64 loss: 0.24099516868591309
Batch 19/64 loss: 0.24424606561660767
Batch 20/64 loss: 0.24872136116027832
Batch 21/64 loss: 0.23836290836334229
Batch 22/64 loss: 0.23194903135299683
Batch 23/64 loss: 0.2305704951286316
Batch 24/64 loss: 0.2424771785736084
Batch 25/64 loss: 0.23043692111968994
Batch 26/64 loss: 0.23265600204467773
Batch 27/64 loss: 0.23911195993423462
Batch 28/64 loss: 0.24244630336761475
Batch 29/64 loss: 0.24888086318969727
Batch 30/64 loss: 0.24249505996704102
Batch 31/64 loss: 0.2393721342086792
Batch 32/64 loss: 0.2358819842338562
Batch 33/64 loss: 0.2376323938369751
Batch 34/64 loss: 0.2400510311126709
Batch 35/64 loss: 0.23096752166748047
Batch 36/64 loss: 0.24159204959869385
Batch 37/64 loss: 0.24004226922988892
Batch 38/64 loss: 0.22636938095092773
Batch 39/64 loss: 0.2355186939239502
Batch 40/64 loss: 0.2311517596244812
Batch 41/64 loss: 0.23191511631011963
Batch 42/64 loss: 0.23328423500061035
Batch 43/64 loss: 0.2433103322982788
Batch 44/64 loss: 0.243918776512146
Batch 45/64 loss: 0.24219006299972534
Batch 46/64 loss: 0.22802072763442993
Batch 47/64 loss: 0.23539316654205322
Batch 48/64 loss: 0.22834384441375732
Batch 49/64 loss: 0.23283803462982178
Batch 50/64 loss: 0.2280517816543579
Batch 51/64 loss: 0.2334045171737671
Batch 52/64 loss: 0.24243760108947754
Batch 53/64 loss: 0.23890864849090576
Batch 54/64 loss: 0.24256014823913574
Batch 55/64 loss: 0.23313772678375244
Batch 56/64 loss: 0.24826180934906006
Batch 57/64 loss: 0.23373258113861084
Batch 58/64 loss: 0.24089264869689941
Batch 59/64 loss: 0.23732733726501465
Batch 60/64 loss: 0.2452526092529297
Batch 61/64 loss: 0.23842471837997437
Batch 62/64 loss: 0.24009990692138672
Batch 63/64 loss: 0.2374265193939209
Batch 64/64 loss: 0.23749041557312012
Epoch 240  Train loss: 0.23762912095761768  Val loss: 0.272025207678477
Epoch 241
-------------------------------
Batch 1/64 loss: 0.2325933575630188
Batch 2/64 loss: 0.241460919380188
Batch 3/64 loss: 0.23878693580627441
Batch 4/64 loss: 0.23271334171295166
Batch 5/64 loss: 0.2336280345916748
Batch 6/64 loss: 0.2349870204925537
Batch 7/64 loss: 0.24440932273864746
Batch 8/64 loss: 0.23690509796142578
Batch 9/64 loss: 0.2402646541595459
Batch 10/64 loss: 0.2406565546989441
Batch 11/64 loss: 0.23828113079071045
Batch 12/64 loss: 0.24178433418273926
Batch 13/64 loss: 0.23249727487564087
Batch 14/64 loss: 0.23732250928878784
Batch 15/64 loss: 0.2380688190460205
Batch 16/64 loss: 0.2337590456008911
Batch 17/64 loss: 0.23552709817886353
Batch 18/64 loss: 0.2328914999961853
Batch 19/64 loss: 0.23581290245056152
Batch 20/64 loss: 0.237848162651062
Batch 21/64 loss: 0.2321230173110962
Batch 22/64 loss: 0.24217045307159424
Batch 23/64 loss: 0.23808449506759644
Batch 24/64 loss: 0.2301505208015442
Batch 25/64 loss: 0.239127516746521
Batch 26/64 loss: 0.2292846441268921
Batch 27/64 loss: 0.24012643098831177
Batch 28/64 loss: 0.23937320709228516
Batch 29/64 loss: 0.23746347427368164
Batch 30/64 loss: 0.23776936531066895
Batch 31/64 loss: 0.23986375331878662
Batch 32/64 loss: 0.2473968267440796
Batch 33/64 loss: 0.2284783124923706
Batch 34/64 loss: 0.23959243297576904
Batch 35/64 loss: 0.23280280828475952
Batch 36/64 loss: 0.23668253421783447
Batch 37/64 loss: 0.23461651802062988
Batch 38/64 loss: 0.23482811450958252
Batch 39/64 loss: 0.2394850254058838
Batch 40/64 loss: 0.23278069496154785
Batch 41/64 loss: 0.23920464515686035
Batch 42/64 loss: 0.24334371089935303
Batch 43/64 loss: 0.23618215322494507
Batch 44/64 loss: 0.2318476438522339
Batch 45/64 loss: 0.23387378454208374
Batch 46/64 loss: 0.23981016874313354
Batch 47/64 loss: 0.2514561414718628
Batch 48/64 loss: 0.23670750856399536
Batch 49/64 loss: 0.2379249930381775
Batch 50/64 loss: 0.23446166515350342
Batch 51/64 loss: 0.24257540702819824
Batch 52/64 loss: 0.23307955265045166
Batch 53/64 loss: 0.24053072929382324
Batch 54/64 loss: 0.23158693313598633
Batch 55/64 loss: 0.24447029829025269
Batch 56/64 loss: 0.2366170883178711
Batch 57/64 loss: 0.23865574598312378
Batch 58/64 loss: 0.2484392523765564
Batch 59/64 loss: 0.23833328485488892
Batch 60/64 loss: 0.24051833152770996
Batch 61/64 loss: 0.24475908279418945
Batch 62/64 loss: 0.24273109436035156
Batch 63/64 loss: 0.23344355821609497
Batch 64/64 loss: 0.24378657341003418
Epoch 241  Train loss: 0.23773789592817718  Val loss: 0.2730183765240961
Epoch 242
-------------------------------
Batch 1/64 loss: 0.23472368717193604
Batch 2/64 loss: 0.23769503831863403
Batch 3/64 loss: 0.2341454029083252
Batch 4/64 loss: 0.23491722345352173
Batch 5/64 loss: 0.233062744140625
Batch 6/64 loss: 0.23039913177490234
Batch 7/64 loss: 0.2347956895828247
Batch 8/64 loss: 0.23758524656295776
Batch 9/64 loss: 0.2320544719696045
Batch 10/64 loss: 0.23161721229553223
Batch 11/64 loss: 0.2409040927886963
Batch 12/64 loss: 0.24514150619506836
Batch 13/64 loss: 0.22947663068771362
Batch 14/64 loss: 0.23771995306015015
Batch 15/64 loss: 0.23271101713180542
Batch 16/64 loss: 0.24157989025115967
Batch 17/64 loss: 0.23236429691314697
Batch 18/64 loss: 0.23315668106079102
Batch 19/64 loss: 0.244124174118042
Batch 20/64 loss: 0.23849356174468994
Batch 21/64 loss: 0.23141878843307495
Batch 22/64 loss: 0.2300153374671936
Batch 23/64 loss: 0.2468777894973755
Batch 24/64 loss: 0.23974579572677612
Batch 25/64 loss: 0.2434646487236023
Batch 26/64 loss: 0.23702514171600342
Batch 27/64 loss: 0.24197208881378174
Batch 28/64 loss: 0.2401430606842041
Batch 29/64 loss: 0.2312173843383789
Batch 30/64 loss: 0.24630939960479736
Batch 31/64 loss: 0.24922454357147217
Batch 32/64 loss: 0.23906803131103516
Batch 33/64 loss: 0.2460615634918213
Batch 34/64 loss: 0.2335105538368225
Batch 35/64 loss: 0.23958337306976318
Batch 36/64 loss: 0.2361050248146057
Batch 37/64 loss: 0.24451792240142822
Batch 38/64 loss: 0.24433434009552002
Batch 39/64 loss: 0.24809157848358154
Batch 40/64 loss: 0.23632365465164185
Batch 41/64 loss: 0.23193222284317017
Batch 42/64 loss: 0.24325144290924072
Batch 43/64 loss: 0.24266475439071655
Batch 44/64 loss: 0.2345564365386963
Batch 45/64 loss: 0.2463131546974182
Batch 46/64 loss: 0.24310040473937988
Batch 47/64 loss: 0.24365419149398804
Batch 48/64 loss: 0.24109244346618652
Batch 49/64 loss: 0.2340177297592163
Batch 50/64 loss: 0.24248230457305908
Batch 51/64 loss: 0.2335219383239746
Batch 52/64 loss: 0.2448352575302124
Batch 53/64 loss: 0.24539166688919067
Batch 54/64 loss: 0.23910796642303467
Batch 55/64 loss: 0.2388218641281128
Batch 56/64 loss: 0.24321281909942627
Batch 57/64 loss: 0.228615403175354
Batch 58/64 loss: 0.2291223406791687
Batch 59/64 loss: 0.2392972707748413
Batch 60/64 loss: 0.23680567741394043
Batch 61/64 loss: 0.23747599124908447
Batch 62/64 loss: 0.23215270042419434
Batch 63/64 loss: 0.23259449005126953
Batch 64/64 loss: 0.23915135860443115
Epoch 242  Train loss: 0.23819704570022285  Val loss: 0.2724203524720628
Epoch 243
-------------------------------
Batch 1/64 loss: 0.2291262149810791
Batch 2/64 loss: 0.23713797330856323
Batch 3/64 loss: 0.23219192028045654
Batch 4/64 loss: 0.23715746402740479
Batch 5/64 loss: 0.23846900463104248
Batch 6/64 loss: 0.23926496505737305
Batch 7/64 loss: 0.2310880422592163
Batch 8/64 loss: 0.23600661754608154
Batch 9/64 loss: 0.23166167736053467
Batch 10/64 loss: 0.24044418334960938
Batch 11/64 loss: 0.23251664638519287
Batch 12/64 loss: 0.2411453127861023
Batch 13/64 loss: 0.2381771206855774
Batch 14/64 loss: 0.2332782745361328
Batch 15/64 loss: 0.23749077320098877
Batch 16/64 loss: 0.2400416135787964
Batch 17/64 loss: 0.24075043201446533
Batch 18/64 loss: 0.24510890245437622
Batch 19/64 loss: 0.23625558614730835
Batch 20/64 loss: 0.2358618974685669
Batch 21/64 loss: 0.230843186378479
Batch 22/64 loss: 0.23041212558746338
Batch 23/64 loss: 0.23658204078674316
Batch 24/64 loss: 0.23411142826080322
Batch 25/64 loss: 0.23752474784851074
Batch 26/64 loss: 0.2353934645652771
Batch 27/64 loss: 0.22738885879516602
Batch 28/64 loss: 0.23704445362091064
Batch 29/64 loss: 0.2321496605873108
Batch 30/64 loss: 0.23400098085403442
Batch 31/64 loss: 0.233917236328125
Batch 32/64 loss: 0.2431582808494568
Batch 33/64 loss: 0.2306702733039856
Batch 34/64 loss: 0.23396408557891846
Batch 35/64 loss: 0.2339411973953247
Batch 36/64 loss: 0.23444271087646484
Batch 37/64 loss: 0.2279883623123169
Batch 38/64 loss: 0.23219412565231323
Batch 39/64 loss: 0.23854678869247437
Batch 40/64 loss: 0.2429577112197876
Batch 41/64 loss: 0.24063140153884888
Batch 42/64 loss: 0.2407057285308838
Batch 43/64 loss: 0.2404012680053711
Batch 44/64 loss: 0.24895095825195312
Batch 45/64 loss: 0.23458707332611084
Batch 46/64 loss: 0.2347712516784668
Batch 47/64 loss: 0.24157047271728516
Batch 48/64 loss: 0.2436721920967102
Batch 49/64 loss: 0.24046975374221802
Batch 50/64 loss: 0.23806041479110718
Batch 51/64 loss: 0.24591028690338135
Batch 52/64 loss: 0.24975967407226562
Batch 53/64 loss: 0.23785442113876343
Batch 54/64 loss: 0.231928288936615
Batch 55/64 loss: 0.24207782745361328
Batch 56/64 loss: 0.23221325874328613
Batch 57/64 loss: 0.23441922664642334
Batch 58/64 loss: 0.24369680881500244
Batch 59/64 loss: 0.23774194717407227
Batch 60/64 loss: 0.2339000701904297
Batch 61/64 loss: 0.24869203567504883
Batch 62/64 loss: 0.23784786462783813
Batch 63/64 loss: 0.2443784475326538
Batch 64/64 loss: 0.23630452156066895
Epoch 243  Train loss: 0.23720588871076995  Val loss: 0.27258200723281023
Epoch 244
-------------------------------
Batch 1/64 loss: 0.23457807302474976
Batch 2/64 loss: 0.22348684072494507
Batch 3/64 loss: 0.23601603507995605
Batch 4/64 loss: 0.24187666177749634
Batch 5/64 loss: 0.23825126886367798
Batch 6/64 loss: 0.22680306434631348
Batch 7/64 loss: 0.23263949155807495
Batch 8/64 loss: 0.2306966781616211
Batch 9/64 loss: 0.22290712594985962
Batch 10/64 loss: 0.235975444316864
Batch 11/64 loss: 0.23973405361175537
Batch 12/64 loss: 0.24134278297424316
Batch 13/64 loss: 0.23304665088653564
Batch 14/64 loss: 0.24057918787002563
Batch 15/64 loss: 0.23444879055023193
Batch 16/64 loss: 0.23640358448028564
Batch 17/64 loss: 0.23070156574249268
Batch 18/64 loss: 0.24021482467651367
Batch 19/64 loss: 0.22595006227493286
Batch 20/64 loss: 0.2253401279449463
Batch 21/64 loss: 0.25034308433532715
Batch 22/64 loss: 0.23678803443908691
Batch 23/64 loss: 0.23863673210144043
Batch 24/64 loss: 0.2391141653060913
Batch 25/64 loss: 0.2331676483154297
Batch 26/64 loss: 0.2392740249633789
Batch 27/64 loss: 0.23693889379501343
Batch 28/64 loss: 0.23476946353912354
Batch 29/64 loss: 0.23474794626235962
Batch 30/64 loss: 0.23186373710632324
Batch 31/64 loss: 0.24669146537780762
Batch 32/64 loss: 0.2315928339958191
Batch 33/64 loss: 0.23036527633666992
Batch 34/64 loss: 0.24051326513290405
Batch 35/64 loss: 0.2420477271080017
Batch 36/64 loss: 0.24075007438659668
Batch 37/64 loss: 0.23568212985992432
Batch 38/64 loss: 0.24418854713439941
Batch 39/64 loss: 0.2418304681777954
Batch 40/64 loss: 0.23671239614486694
Batch 41/64 loss: 0.24478042125701904
Batch 42/64 loss: 0.2520613670349121
Batch 43/64 loss: 0.23875820636749268
Batch 44/64 loss: 0.2310192584991455
Batch 45/64 loss: 0.23391568660736084
Batch 46/64 loss: 0.22952210903167725
Batch 47/64 loss: 0.2356562614440918
Batch 48/64 loss: 0.2347516417503357
Batch 49/64 loss: 0.23528271913528442
Batch 50/64 loss: 0.2350907325744629
Batch 51/64 loss: 0.24911588430404663
Batch 52/64 loss: 0.23623645305633545
Batch 53/64 loss: 0.23569655418395996
Batch 54/64 loss: 0.2392423152923584
Batch 55/64 loss: 0.2419060468673706
Batch 56/64 loss: 0.23752176761627197
Batch 57/64 loss: 0.23467546701431274
Batch 58/64 loss: 0.23341810703277588
Batch 59/64 loss: 0.23365432024002075
Batch 60/64 loss: 0.2332158088684082
Batch 61/64 loss: 0.22880470752716064
Batch 62/64 loss: 0.24492692947387695
Batch 63/64 loss: 0.23954272270202637
Batch 64/64 loss: 0.23971152305603027
Epoch 244  Train loss: 0.23647983307931938  Val loss: 0.2730969587961833
Epoch 245
-------------------------------
Batch 1/64 loss: 0.24212294816970825
Batch 2/64 loss: 0.24829566478729248
Batch 3/64 loss: 0.23538273572921753
Batch 4/64 loss: 0.2324146032333374
Batch 5/64 loss: 0.24521875381469727
Batch 6/64 loss: 0.23719537258148193
Batch 7/64 loss: 0.2372024655342102
Batch 8/64 loss: 0.23825013637542725
Batch 9/64 loss: 0.23652583360671997
Batch 10/64 loss: 0.24890029430389404
Batch 11/64 loss: 0.23168671131134033
Batch 12/64 loss: 0.23267865180969238
Batch 13/64 loss: 0.24287927150726318
Batch 14/64 loss: 0.23575615882873535
Batch 15/64 loss: 0.24026226997375488
Batch 16/64 loss: 0.23920023441314697
Batch 17/64 loss: 0.24122917652130127
Batch 18/64 loss: 0.23466908931732178
Batch 19/64 loss: 0.2287294864654541
Batch 20/64 loss: 0.23265761137008667
Batch 21/64 loss: 0.24107956886291504
Batch 22/64 loss: 0.24655699729919434
Batch 23/64 loss: 0.23399484157562256
Batch 24/64 loss: 0.23980844020843506
Batch 25/64 loss: 0.23806172609329224
Batch 26/64 loss: 0.24007654190063477
Batch 27/64 loss: 0.23022639751434326
Batch 28/64 loss: 0.26104140281677246
Batch 29/64 loss: 0.24343180656433105
Batch 30/64 loss: 0.24354994297027588
Batch 31/64 loss: 0.23246407508850098
Batch 32/64 loss: 0.23054933547973633
Batch 33/64 loss: 0.23281633853912354
Batch 34/64 loss: 0.24376118183135986
Batch 35/64 loss: 0.2425938844680786
Batch 36/64 loss: 0.23713117837905884
Batch 37/64 loss: 0.24149727821350098
Batch 38/64 loss: 0.23214292526245117
Batch 39/64 loss: 0.23896509408950806
Batch 40/64 loss: 0.23176288604736328
Batch 41/64 loss: 0.24008768796920776
Batch 42/64 loss: 0.229397714138031
Batch 43/64 loss: 0.23904496431350708
Batch 44/64 loss: 0.23353946208953857
Batch 45/64 loss: 0.24069058895111084
Batch 46/64 loss: 0.23553401231765747
Batch 47/64 loss: 0.22880637645721436
Batch 48/64 loss: 0.24587535858154297
Batch 49/64 loss: 0.22997260093688965
Batch 50/64 loss: 0.2371159791946411
Batch 51/64 loss: 0.23609817028045654
Batch 52/64 loss: 0.23357754945755005
Batch 53/64 loss: 0.23827719688415527
Batch 54/64 loss: 0.2398775815963745
Batch 55/64 loss: 0.2402535080909729
Batch 56/64 loss: 0.24356144666671753
Batch 57/64 loss: 0.2422618865966797
Batch 58/64 loss: 0.23628175258636475
Batch 59/64 loss: 0.2370559573173523
Batch 60/64 loss: 0.22821933031082153
Batch 61/64 loss: 0.23025763034820557
Batch 62/64 loss: 0.23274099826812744
Batch 63/64 loss: 0.24171406030654907
Batch 64/64 loss: 0.23128092288970947
Epoch 245  Train loss: 0.23774857754800835  Val loss: 0.2717164437385769
Saving best model, epoch: 245
Epoch 246
-------------------------------
Batch 1/64 loss: 0.22761040925979614
Batch 2/64 loss: 0.23297250270843506
Batch 3/64 loss: 0.23591768741607666
Batch 4/64 loss: 0.23354995250701904
Batch 5/64 loss: 0.23955810070037842
Batch 6/64 loss: 0.22896945476531982
Batch 7/64 loss: 0.2304912805557251
Batch 8/64 loss: 0.24387818574905396
Batch 9/64 loss: 0.2364645004272461
Batch 10/64 loss: 0.23996806144714355
Batch 11/64 loss: 0.23016732931137085
Batch 12/64 loss: 0.22773027420043945
Batch 13/64 loss: 0.22986173629760742
Batch 14/64 loss: 0.2338259220123291
Batch 15/64 loss: 0.22658950090408325
Batch 16/64 loss: 0.2383735179901123
Batch 17/64 loss: 0.23405569791793823
Batch 18/64 loss: 0.22833549976348877
Batch 19/64 loss: 0.23502838611602783
Batch 20/64 loss: 0.24183952808380127
Batch 21/64 loss: 0.23735719919204712
Batch 22/64 loss: 0.23240411281585693
Batch 23/64 loss: 0.22891008853912354
Batch 24/64 loss: 0.24435776472091675
Batch 25/64 loss: 0.2305011749267578
Batch 26/64 loss: 0.24051201343536377
Batch 27/64 loss: 0.23795777559280396
Batch 28/64 loss: 0.24554002285003662
Batch 29/64 loss: 0.2482038140296936
Batch 30/64 loss: 0.23146450519561768
Batch 31/64 loss: 0.23195290565490723
Batch 32/64 loss: 0.248199462890625
Batch 33/64 loss: 0.22845011949539185
Batch 34/64 loss: 0.2394489049911499
Batch 35/64 loss: 0.23789209127426147
Batch 36/64 loss: 0.24458014965057373
Batch 37/64 loss: 0.22532296180725098
Batch 38/64 loss: 0.2319631576538086
Batch 39/64 loss: 0.24173849821090698
Batch 40/64 loss: 0.24385404586791992
Batch 41/64 loss: 0.23178410530090332
Batch 42/64 loss: 0.248809814453125
Batch 43/64 loss: 0.22999835014343262
Batch 44/64 loss: 0.23836219310760498
Batch 45/64 loss: 0.2335970401763916
Batch 46/64 loss: 0.24087178707122803
Batch 47/64 loss: 0.24019205570220947
Batch 48/64 loss: 0.2294672727584839
Batch 49/64 loss: 0.22538578510284424
Batch 50/64 loss: 0.23561275005340576
Batch 51/64 loss: 0.23054301738739014
Batch 52/64 loss: 0.23706990480422974
Batch 53/64 loss: 0.2386620044708252
Batch 54/64 loss: 0.24000900983810425
Batch 55/64 loss: 0.23145824670791626
Batch 56/64 loss: 0.2357468605041504
Batch 57/64 loss: 0.23896825313568115
Batch 58/64 loss: 0.23879224061965942
Batch 59/64 loss: 0.23684191703796387
Batch 60/64 loss: 0.2316676378250122
Batch 61/64 loss: 0.2347230315208435
Batch 62/64 loss: 0.23674404621124268
Batch 63/64 loss: 0.23576390743255615
Batch 64/64 loss: 0.24195986986160278
Epoch 246  Train loss: 0.23573865773631078  Val loss: 0.2717200470544219
Epoch 247
-------------------------------
Batch 1/64 loss: 0.2314397096633911
Batch 2/64 loss: 0.23742038011550903
Batch 3/64 loss: 0.25395792722702026
Batch 4/64 loss: 0.2329195737838745
Batch 5/64 loss: 0.24077922105789185
Batch 6/64 loss: 0.23040056228637695
Batch 7/64 loss: 0.2329237461090088
Batch 8/64 loss: 0.23610717058181763
Batch 9/64 loss: 0.23157799243927002
Batch 10/64 loss: 0.2349303960800171
Batch 11/64 loss: 0.2307666540145874
Batch 12/64 loss: 0.22841668128967285
Batch 13/64 loss: 0.23564141988754272
Batch 14/64 loss: 0.2349870204925537
Batch 15/64 loss: 0.2271406650543213
Batch 16/64 loss: 0.2412562370300293
Batch 17/64 loss: 0.23417669534683228
Batch 18/64 loss: 0.23228907585144043
Batch 19/64 loss: 0.23244237899780273
Batch 20/64 loss: 0.23412632942199707
Batch 21/64 loss: 0.24498772621154785
Batch 22/64 loss: 0.22655916213989258
Batch 23/64 loss: 0.24655914306640625
Batch 24/64 loss: 0.24239420890808105
Batch 25/64 loss: 0.2358342409133911
Batch 26/64 loss: 0.24126946926116943
Batch 27/64 loss: 0.2374095320701599
Batch 28/64 loss: 0.2426641583442688
Batch 29/64 loss: 0.23740637302398682
Batch 30/64 loss: 0.23851066827774048
Batch 31/64 loss: 0.22707778215408325
Batch 32/64 loss: 0.2326040267944336
Batch 33/64 loss: 0.23770201206207275
Batch 34/64 loss: 0.24390721321105957
Batch 35/64 loss: 0.2339993715286255
Batch 36/64 loss: 0.2383173108100891
Batch 37/64 loss: 0.23870158195495605
Batch 38/64 loss: 0.2332059144973755
Batch 39/64 loss: 0.2335604429244995
Batch 40/64 loss: 0.23418521881103516
Batch 41/64 loss: 0.23014509677886963
Batch 42/64 loss: 0.23160839080810547
Batch 43/64 loss: 0.2555145025253296
Batch 44/64 loss: 0.23913884162902832
Batch 45/64 loss: 0.23593777418136597
Batch 46/64 loss: 0.24232691526412964
Batch 47/64 loss: 0.23513227701187134
Batch 48/64 loss: 0.2385992407798767
Batch 49/64 loss: 0.23158258199691772
Batch 50/64 loss: 0.23193711042404175
Batch 51/64 loss: 0.23587262630462646
Batch 52/64 loss: 0.23619985580444336
Batch 53/64 loss: 0.23913824558258057
Batch 54/64 loss: 0.2390233278274536
Batch 55/64 loss: 0.23687171936035156
Batch 56/64 loss: 0.24592578411102295
Batch 57/64 loss: 0.23610979318618774
Batch 58/64 loss: 0.23084181547164917
Batch 59/64 loss: 0.23127663135528564
Batch 60/64 loss: 0.2266939878463745
Batch 61/64 loss: 0.23729276657104492
Batch 62/64 loss: 0.23171675205230713
Batch 63/64 loss: 0.23396366834640503
Batch 64/64 loss: 0.2298395037651062
Epoch 247  Train loss: 0.23601230943904203  Val loss: 0.2719636754071999
Epoch 248
-------------------------------
Batch 1/64 loss: 0.23421752452850342
Batch 2/64 loss: 0.23247212171554565
Batch 3/64 loss: 0.23069709539413452
Batch 4/64 loss: 0.2339458465576172
Batch 5/64 loss: 0.2357884645462036
Batch 6/64 loss: 0.2352898120880127
Batch 7/64 loss: 0.2354261875152588
Batch 8/64 loss: 0.23592007160186768
Batch 9/64 loss: 0.23247987031936646
Batch 10/64 loss: 0.23707294464111328
Batch 11/64 loss: 0.23526716232299805
Batch 12/64 loss: 0.24046099185943604
Batch 13/64 loss: 0.23343044519424438
Batch 14/64 loss: 0.24683809280395508
Batch 15/64 loss: 0.2333701252937317
Batch 16/64 loss: 0.2369346022605896
Batch 17/64 loss: 0.2409462332725525
Batch 18/64 loss: 0.22304767370224
Batch 19/64 loss: 0.23631519079208374
Batch 20/64 loss: 0.24399173259735107
Batch 21/64 loss: 0.23733657598495483
Batch 22/64 loss: 0.23125696182250977
Batch 23/64 loss: 0.2348211407661438
Batch 24/64 loss: 0.23179233074188232
Batch 25/64 loss: 0.2332097291946411
Batch 26/64 loss: 0.2390347719192505
Batch 27/64 loss: 0.23546123504638672
Batch 28/64 loss: 0.24123001098632812
Batch 29/64 loss: 0.24661171436309814
Batch 30/64 loss: 0.2440112829208374
Batch 31/64 loss: 0.24799543619155884
Batch 32/64 loss: 0.23454934358596802
Batch 33/64 loss: 0.2379487156867981
Batch 34/64 loss: 0.23870092630386353
Batch 35/64 loss: 0.2371004819869995
Batch 36/64 loss: 0.23990315198898315
Batch 37/64 loss: 0.23687368631362915
Batch 38/64 loss: 0.23854637145996094
Batch 39/64 loss: 0.2307606339454651
Batch 40/64 loss: 0.2360062599182129
Batch 41/64 loss: 0.25000011920928955
Batch 42/64 loss: 0.23969614505767822
Batch 43/64 loss: 0.22639107704162598
Batch 44/64 loss: 0.2373182773590088
Batch 45/64 loss: 0.2321714162826538
Batch 46/64 loss: 0.22719526290893555
Batch 47/64 loss: 0.23174941539764404
Batch 48/64 loss: 0.24254661798477173
Batch 49/64 loss: 0.22239208221435547
Batch 50/64 loss: 0.232580304145813
Batch 51/64 loss: 0.23763322830200195
Batch 52/64 loss: 0.23597615957260132
Batch 53/64 loss: 0.2309003472328186
Batch 54/64 loss: 0.23769116401672363
Batch 55/64 loss: 0.23884224891662598
Batch 56/64 loss: 0.23777014017105103
Batch 57/64 loss: 0.2464447021484375
Batch 58/64 loss: 0.22672438621520996
Batch 59/64 loss: 0.22799110412597656
Batch 60/64 loss: 0.23173338174819946
Batch 61/64 loss: 0.2352832555770874
Batch 62/64 loss: 0.23382902145385742
Batch 63/64 loss: 0.24297797679901123
Batch 64/64 loss: 0.23107129335403442
Epoch 248  Train loss: 0.23601889025931264  Val loss: 0.27145966426613405
Saving best model, epoch: 248
Epoch 249
-------------------------------
Batch 1/64 loss: 0.2312801480293274
Batch 2/64 loss: 0.24034130573272705
Batch 3/64 loss: 0.22894489765167236
Batch 4/64 loss: 0.22664594650268555
Batch 5/64 loss: 0.2297959327697754
Batch 6/64 loss: 0.23840057849884033
Batch 7/64 loss: 0.22944366931915283
Batch 8/64 loss: 0.22857260704040527
Batch 9/64 loss: 0.2354947328567505
Batch 10/64 loss: 0.23998016119003296
Batch 11/64 loss: 0.22640293836593628
Batch 12/64 loss: 0.23536384105682373
Batch 13/64 loss: 0.23043042421340942
Batch 14/64 loss: 0.23273277282714844
Batch 15/64 loss: 0.23862838745117188
Batch 16/64 loss: 0.23635369539260864
Batch 17/64 loss: 0.23157721757888794
Batch 18/64 loss: 0.22964394092559814
Batch 19/64 loss: 0.22332763671875
Batch 20/64 loss: 0.23456251621246338
Batch 21/64 loss: 0.2422182559967041
Batch 22/64 loss: 0.24127286672592163
Batch 23/64 loss: 0.23784661293029785
Batch 24/64 loss: 0.23841214179992676
Batch 25/64 loss: 0.23529952764511108
Batch 26/64 loss: 0.2343752384185791
Batch 27/64 loss: 0.23301780223846436
Batch 28/64 loss: 0.2370288372039795
Batch 29/64 loss: 0.2360137701034546
Batch 30/64 loss: 0.2326514720916748
Batch 31/64 loss: 0.2367480993270874
Batch 32/64 loss: 0.23523402214050293
Batch 33/64 loss: 0.23346930742263794
Batch 34/64 loss: 0.22830802202224731
Batch 35/64 loss: 0.2346506118774414
Batch 36/64 loss: 0.23407363891601562
Batch 37/64 loss: 0.22504311800003052
Batch 38/64 loss: 0.23054301738739014
Batch 39/64 loss: 0.23814666271209717
Batch 40/64 loss: 0.2348005771636963
Batch 41/64 loss: 0.2468966245651245
Batch 42/64 loss: 0.23850411176681519
Batch 43/64 loss: 0.24021100997924805
Batch 44/64 loss: 0.23134386539459229
Batch 45/64 loss: 0.2385590672492981
Batch 46/64 loss: 0.23842263221740723
Batch 47/64 loss: 0.2428271770477295
Batch 48/64 loss: 0.24245715141296387
Batch 49/64 loss: 0.2286829948425293
Batch 50/64 loss: 0.24360978603363037
Batch 51/64 loss: 0.23411977291107178
Batch 52/64 loss: 0.22948598861694336
Batch 53/64 loss: 0.24467957019805908
Batch 54/64 loss: 0.234707772731781
Batch 55/64 loss: 0.22889435291290283
Batch 56/64 loss: 0.2295612096786499
Batch 57/64 loss: 0.22995364665985107
Batch 58/64 loss: 0.23613327741622925
Batch 59/64 loss: 0.2390679121017456
Batch 60/64 loss: 0.23260217905044556
Batch 61/64 loss: 0.2308570146560669
Batch 62/64 loss: 0.2529805302619934
Batch 63/64 loss: 0.2448054552078247
Batch 64/64 loss: 0.23034608364105225
Epoch 249  Train loss: 0.23496783714668423  Val loss: 0.271831024143704
Epoch 250
-------------------------------
Batch 1/64 loss: 0.23232734203338623
Batch 2/64 loss: 0.2394503355026245
Batch 3/64 loss: 0.24565190076828003
Batch 4/64 loss: 0.233445942401886
Batch 5/64 loss: 0.22951102256774902
Batch 6/64 loss: 0.23210549354553223
Batch 7/64 loss: 0.246221125125885
Batch 8/64 loss: 0.23500990867614746
Batch 9/64 loss: 0.24371683597564697
Batch 10/64 loss: 0.22955423593521118
Batch 11/64 loss: 0.22763562202453613
Batch 12/64 loss: 0.22826379537582397
Batch 13/64 loss: 0.23787128925323486
Batch 14/64 loss: 0.23960822820663452
Batch 15/64 loss: 0.23109805583953857
Batch 16/64 loss: 0.23091918230056763
Batch 17/64 loss: 0.22950506210327148
Batch 18/64 loss: 0.23534303903579712
Batch 19/64 loss: 0.2365093231201172
Batch 20/64 loss: 0.2276538610458374
Batch 21/64 loss: 0.23159289360046387
Batch 22/64 loss: 0.23718273639678955
Batch 23/64 loss: 0.22830545902252197
Batch 24/64 loss: 0.2356795072555542
Batch 25/64 loss: 0.23051172494888306
Batch 26/64 loss: 0.23792016506195068
Batch 27/64 loss: 0.24328428506851196
Batch 28/64 loss: 0.23695284128189087
Batch 29/64 loss: 0.22581219673156738
Batch 30/64 loss: 0.22925323247909546
Batch 31/64 loss: 0.2437359094619751
Batch 32/64 loss: 0.22709089517593384
Batch 33/64 loss: 0.23840391635894775
Batch 34/64 loss: 0.23917865753173828
Batch 35/64 loss: 0.2330927848815918
Batch 36/64 loss: 0.23939889669418335
Batch 37/64 loss: 0.24125432968139648
Batch 38/64 loss: 0.23641437292099
Batch 39/64 loss: 0.2434072494506836
Batch 40/64 loss: 0.2309325933456421
Batch 41/64 loss: 0.2322467565536499
Batch 42/64 loss: 0.23857712745666504
Batch 43/64 loss: 0.2343272566795349
Batch 44/64 loss: 0.2324821949005127
Batch 45/64 loss: 0.2332150936126709
Batch 46/64 loss: 0.23685133457183838
Batch 47/64 loss: 0.23654931783676147
Batch 48/64 loss: 0.23890459537506104
Batch 49/64 loss: 0.23504197597503662
Batch 50/64 loss: 0.23297619819641113
Batch 51/64 loss: 0.22896379232406616
Batch 52/64 loss: 0.2369985580444336
Batch 53/64 loss: 0.24352729320526123
Batch 54/64 loss: 0.24110597372055054
Batch 55/64 loss: 0.23460286855697632
Batch 56/64 loss: 0.2290637493133545
Batch 57/64 loss: 0.22887003421783447
Batch 58/64 loss: 0.23369675874710083
Batch 59/64 loss: 0.23615336418151855
Batch 60/64 loss: 0.23854422569274902
Batch 61/64 loss: 0.2333936095237732
Batch 62/64 loss: 0.24396812915802002
Batch 63/64 loss: 0.2415291666984558
Batch 64/64 loss: 0.22920680046081543
Epoch 250  Train loss: 0.23520471722471947  Val loss: 0.27212897772641526
Epoch 251
-------------------------------
Batch 1/64 loss: 0.23094677925109863
Batch 2/64 loss: 0.24287748336791992
Batch 3/64 loss: 0.23293745517730713
Batch 4/64 loss: 0.22578126192092896
Batch 5/64 loss: 0.22642695903778076
Batch 6/64 loss: 0.2447260618209839
Batch 7/64 loss: 0.22926998138427734
Batch 8/64 loss: 0.24080628156661987
Batch 9/64 loss: 0.22918367385864258
Batch 10/64 loss: 0.23177117109298706
Batch 11/64 loss: 0.2324434518814087
Batch 12/64 loss: 0.22992098331451416
Batch 13/64 loss: 0.22534394264221191
Batch 14/64 loss: 0.23282229900360107
Batch 15/64 loss: 0.2256597876548767
Batch 16/64 loss: 0.22985756397247314
Batch 17/64 loss: 0.24079203605651855
Batch 18/64 loss: 0.23183214664459229
Batch 19/64 loss: 0.2299046516418457
Batch 20/64 loss: 0.2296668291091919
Batch 21/64 loss: 0.22321397066116333
Batch 22/64 loss: 0.23616313934326172
Batch 23/64 loss: 0.23205935955047607
Batch 24/64 loss: 0.24427616596221924
Batch 25/64 loss: 0.24306756258010864
Batch 26/64 loss: 0.22934269905090332
Batch 27/64 loss: 0.23154258728027344
Batch 28/64 loss: 0.23227930068969727
Batch 29/64 loss: 0.2376699447631836
Batch 30/64 loss: 0.23245728015899658
Batch 31/64 loss: 0.23214387893676758
Batch 32/64 loss: 0.22935283184051514
Batch 33/64 loss: 0.24048596620559692
Batch 34/64 loss: 0.24069106578826904
Batch 35/64 loss: 0.22814160585403442
Batch 36/64 loss: 0.22827744483947754
Batch 37/64 loss: 0.24518871307373047
Batch 38/64 loss: 0.24294233322143555
Batch 39/64 loss: 0.2420443892478943
Batch 40/64 loss: 0.23312175273895264
Batch 41/64 loss: 0.2527005672454834
Batch 42/64 loss: 0.2413727045059204
Batch 43/64 loss: 0.2480309009552002
Batch 44/64 loss: 0.23254919052124023
Batch 45/64 loss: 0.2340853214263916
Batch 46/64 loss: 0.23619860410690308
Batch 47/64 loss: 0.23221486806869507
Batch 48/64 loss: 0.2496241331100464
Batch 49/64 loss: 0.22914457321166992
Batch 50/64 loss: 0.23514384031295776
Batch 51/64 loss: 0.2365628480911255
Batch 52/64 loss: 0.23455286026000977
Batch 53/64 loss: 0.23978400230407715
Batch 54/64 loss: 0.2381610870361328
Batch 55/64 loss: 0.24068307876586914
Batch 56/64 loss: 0.23428601026535034
Batch 57/64 loss: 0.24009191989898682
Batch 58/64 loss: 0.23137134313583374
Batch 59/64 loss: 0.23398077487945557
Batch 60/64 loss: 0.24519556760787964
Batch 61/64 loss: 0.22981417179107666
Batch 62/64 loss: 0.23212027549743652
Batch 63/64 loss: 0.23237884044647217
Batch 64/64 loss: 0.2415827512741089
Epoch 251  Train loss: 0.23511635041704365  Val loss: 0.2715240712837665
Epoch 252
-------------------------------
Batch 1/64 loss: 0.23363810777664185
Batch 2/64 loss: 0.23413115739822388
Batch 3/64 loss: 0.23556911945343018
Batch 4/64 loss: 0.23633283376693726
Batch 5/64 loss: 0.23438119888305664
Batch 6/64 loss: 0.2387981414794922
Batch 7/64 loss: 0.22835731506347656
Batch 8/64 loss: 0.2372206449508667
Batch 9/64 loss: 0.22985851764678955
Batch 10/64 loss: 0.22729122638702393
Batch 11/64 loss: 0.239751935005188
Batch 12/64 loss: 0.2438873052597046
Batch 13/64 loss: 0.23122990131378174
Batch 14/64 loss: 0.22356659173965454
Batch 15/64 loss: 0.232169508934021
Batch 16/64 loss: 0.23509395122528076
Batch 17/64 loss: 0.23542988300323486
Batch 18/64 loss: 0.2380145788192749
Batch 19/64 loss: 0.2338571548461914
Batch 20/64 loss: 0.24562466144561768
Batch 21/64 loss: 0.23726940155029297
Batch 22/64 loss: 0.23884707689285278
Batch 23/64 loss: 0.2312515377998352
Batch 24/64 loss: 0.23149138689041138
Batch 25/64 loss: 0.23871302604675293
Batch 26/64 loss: 0.2351551055908203
Batch 27/64 loss: 0.23062682151794434
Batch 28/64 loss: 0.23492109775543213
Batch 29/64 loss: 0.23163646459579468
Batch 30/64 loss: 0.23814857006072998
Batch 31/64 loss: 0.23103153705596924
Batch 32/64 loss: 0.23551756143569946
Batch 33/64 loss: 0.2376002073287964
Batch 34/64 loss: 0.23252779245376587
Batch 35/64 loss: 0.2343214750289917
Batch 36/64 loss: 0.23917490243911743
Batch 37/64 loss: 0.2348473072052002
Batch 38/64 loss: 0.24389594793319702
Batch 39/64 loss: 0.23469173908233643
Batch 40/64 loss: 0.23317158222198486
Batch 41/64 loss: 0.23170781135559082
Batch 42/64 loss: 0.2343425154685974
Batch 43/64 loss: 0.2314586043357849
Batch 44/64 loss: 0.22548460960388184
Batch 45/64 loss: 0.23776161670684814
Batch 46/64 loss: 0.22667717933654785
Batch 47/64 loss: 0.22889816761016846
Batch 48/64 loss: 0.24092501401901245
Batch 49/64 loss: 0.23410409688949585
Batch 50/64 loss: 0.2318958044052124
Batch 51/64 loss: 0.24081051349639893
Batch 52/64 loss: 0.2340538501739502
Batch 53/64 loss: 0.22592753171920776
Batch 54/64 loss: 0.23354870080947876
Batch 55/64 loss: 0.2333003282546997
Batch 56/64 loss: 0.23543620109558105
Batch 57/64 loss: 0.24028944969177246
Batch 58/64 loss: 0.23644566535949707
Batch 59/64 loss: 0.24026060104370117
Batch 60/64 loss: 0.2354656457901001
Batch 61/64 loss: 0.23069548606872559
Batch 62/64 loss: 0.22653579711914062
Batch 63/64 loss: 0.23268717527389526
Batch 64/64 loss: 0.23143696784973145
Epoch 252  Train loss: 0.23437387242036709  Val loss: 0.27227969390829815
Epoch 253
-------------------------------
Batch 1/64 loss: 0.22595810890197754
Batch 2/64 loss: 0.23470914363861084
Batch 3/64 loss: 0.24362695217132568
Batch 4/64 loss: 0.22913312911987305
Batch 5/64 loss: 0.2297137975692749
Batch 6/64 loss: 0.2434772253036499
Batch 7/64 loss: 0.2312690019607544
Batch 8/64 loss: 0.23047184944152832
Batch 9/64 loss: 0.24305951595306396
Batch 10/64 loss: 0.23393166065216064
Batch 11/64 loss: 0.23554623126983643
Batch 12/64 loss: 0.23335033655166626
Batch 13/64 loss: 0.23316895961761475
Batch 14/64 loss: 0.23466330766677856
Batch 15/64 loss: 0.22718852758407593
Batch 16/64 loss: 0.2358180284500122
Batch 17/64 loss: 0.23968958854675293
Batch 18/64 loss: 0.23327159881591797
Batch 19/64 loss: 0.2336411476135254
Batch 20/64 loss: 0.23457157611846924
Batch 21/64 loss: 0.23736649751663208
Batch 22/64 loss: 0.23311853408813477
Batch 23/64 loss: 0.22745776176452637
Batch 24/64 loss: 0.2261703610420227
Batch 25/64 loss: 0.23858106136322021
Batch 26/64 loss: 0.23419582843780518
Batch 27/64 loss: 0.2355949878692627
Batch 28/64 loss: 0.24156999588012695
Batch 29/64 loss: 0.23227465152740479
Batch 30/64 loss: 0.22667324542999268
Batch 31/64 loss: 0.2372136116027832
Batch 32/64 loss: 0.23918116092681885
Batch 33/64 loss: 0.24101930856704712
Batch 34/64 loss: 0.2349616289138794
Batch 35/64 loss: 0.24414336681365967
Batch 36/64 loss: 0.23603296279907227
Batch 37/64 loss: 0.23927700519561768
Batch 38/64 loss: 0.247672438621521
Batch 39/64 loss: 0.23470091819763184
Batch 40/64 loss: 0.25254976749420166
Batch 41/64 loss: 0.24555957317352295
Batch 42/64 loss: 0.24420607089996338
Batch 43/64 loss: 0.24075579643249512
Batch 44/64 loss: 0.22993361949920654
Batch 45/64 loss: 0.22876572608947754
Batch 46/64 loss: 0.23489129543304443
Batch 47/64 loss: 0.23133361339569092
Batch 48/64 loss: 0.23260998725891113
Batch 49/64 loss: 0.24358177185058594
Batch 50/64 loss: 0.23452019691467285
Batch 51/64 loss: 0.2289387583732605
Batch 52/64 loss: 0.23794817924499512
Batch 53/64 loss: 0.2275066375732422
Batch 54/64 loss: 0.23589444160461426
Batch 55/64 loss: 0.23371362686157227
Batch 56/64 loss: 0.23441386222839355
Batch 57/64 loss: 0.23266232013702393
Batch 58/64 loss: 0.24460238218307495
Batch 59/64 loss: 0.2409120798110962
Batch 60/64 loss: 0.23400753736495972
Batch 61/64 loss: 0.23625481128692627
Batch 62/64 loss: 0.2351309061050415
Batch 63/64 loss: 0.2333921194076538
Batch 64/64 loss: 0.2288745641708374
Epoch 253  Train loss: 0.23559538850597306  Val loss: 0.2715509480627132
Epoch 254
-------------------------------
Batch 1/64 loss: 0.23353028297424316
Batch 2/64 loss: 0.23710429668426514
Batch 3/64 loss: 0.2280389666557312
Batch 4/64 loss: 0.2329401969909668
Batch 5/64 loss: 0.23249685764312744
Batch 6/64 loss: 0.23000532388687134
Batch 7/64 loss: 0.23940181732177734
Batch 8/64 loss: 0.2369227409362793
Batch 9/64 loss: 0.22245848178863525
Batch 10/64 loss: 0.23951447010040283
Batch 11/64 loss: 0.22488880157470703
Batch 12/64 loss: 0.23241204023361206
Batch 13/64 loss: 0.2342078685760498
Batch 14/64 loss: 0.2505354881286621
Batch 15/64 loss: 0.23279404640197754
Batch 16/64 loss: 0.2401476502418518
Batch 17/64 loss: 0.2363903522491455
Batch 18/64 loss: 0.2346876859664917
Batch 19/64 loss: 0.2386852502822876
Batch 20/64 loss: 0.24492549896240234
Batch 21/64 loss: 0.24317586421966553
Batch 22/64 loss: 0.23836523294448853
Batch 23/64 loss: 0.22946161031723022
Batch 24/64 loss: 0.24018269777297974
Batch 25/64 loss: 0.23824656009674072
Batch 26/64 loss: 0.23220402002334595
Batch 27/64 loss: 0.23790526390075684
Batch 28/64 loss: 0.23341971635818481
Batch 29/64 loss: 0.2375240921974182
Batch 30/64 loss: 0.23518937826156616
Batch 31/64 loss: 0.233098566532135
Batch 32/64 loss: 0.24649834632873535
Batch 33/64 loss: 0.228987455368042
Batch 34/64 loss: 0.2317448854446411
Batch 35/64 loss: 0.2286924123764038
Batch 36/64 loss: 0.23842358589172363
Batch 37/64 loss: 0.2335042953491211
Batch 38/64 loss: 0.22029316425323486
Batch 39/64 loss: 0.2379469871520996
Batch 40/64 loss: 0.23251962661743164
Batch 41/64 loss: 0.24003440141677856
Batch 42/64 loss: 0.23840582370758057
Batch 43/64 loss: 0.23045063018798828
Batch 44/64 loss: 0.23194503784179688
Batch 45/64 loss: 0.23912352323532104
Batch 46/64 loss: 0.22874683141708374
Batch 47/64 loss: 0.2321641445159912
Batch 48/64 loss: 0.23659032583236694
Batch 49/64 loss: 0.2422037124633789
Batch 50/64 loss: 0.23423147201538086
Batch 51/64 loss: 0.23285436630249023
Batch 52/64 loss: 0.24141883850097656
Batch 53/64 loss: 0.22532832622528076
Batch 54/64 loss: 0.22474700212478638
Batch 55/64 loss: 0.2385270595550537
Batch 56/64 loss: 0.23558855056762695
Batch 57/64 loss: 0.23742055892944336
Batch 58/64 loss: 0.239696204662323
Batch 59/64 loss: 0.23124361038208008
Batch 60/64 loss: 0.23996150493621826
Batch 61/64 loss: 0.22815322875976562
Batch 62/64 loss: 0.23357534408569336
Batch 63/64 loss: 0.24654388427734375
Batch 64/64 loss: 0.2378024458885193
Epoch 254  Train loss: 0.23508671522140503  Val loss: 0.27100879445518417
Saving best model, epoch: 254
Epoch 255
-------------------------------
Batch 1/64 loss: 0.23404520750045776
Batch 2/64 loss: 0.22615385055541992
Batch 3/64 loss: 0.22886741161346436
Batch 4/64 loss: 0.243502676486969
Batch 5/64 loss: 0.24171525239944458
Batch 6/64 loss: 0.23085927963256836
Batch 7/64 loss: 0.24377977848052979
Batch 8/64 loss: 0.22181713581085205
Batch 9/64 loss: 0.23380047082901
Batch 10/64 loss: 0.23155122995376587
Batch 11/64 loss: 0.22645652294158936
Batch 12/64 loss: 0.2423875331878662
Batch 13/64 loss: 0.23107552528381348
Batch 14/64 loss: 0.23533278703689575
Batch 15/64 loss: 0.22619909048080444
Batch 16/64 loss: 0.2356891632080078
Batch 17/64 loss: 0.24085533618927002
Batch 18/64 loss: 0.229658305644989
Batch 19/64 loss: 0.2378377914428711
Batch 20/64 loss: 0.23328709602355957
Batch 21/64 loss: 0.2344064712524414
Batch 22/64 loss: 0.23002022504806519
Batch 23/64 loss: 0.22234731912612915
Batch 24/64 loss: 0.23335540294647217
Batch 25/64 loss: 0.23339974880218506
Batch 26/64 loss: 0.23048436641693115
Batch 27/64 loss: 0.22217774391174316
Batch 28/64 loss: 0.233587384223938
Batch 29/64 loss: 0.2309330701828003
Batch 30/64 loss: 0.23485159873962402
Batch 31/64 loss: 0.2386530637741089
Batch 32/64 loss: 0.24154722690582275
Batch 33/64 loss: 0.2293682098388672
Batch 34/64 loss: 0.23383694887161255
Batch 35/64 loss: 0.2392256259918213
Batch 36/64 loss: 0.2413153052330017
Batch 37/64 loss: 0.2339106798171997
Batch 38/64 loss: 0.23862648010253906
Batch 39/64 loss: 0.2399277687072754
Batch 40/64 loss: 0.238470196723938
Batch 41/64 loss: 0.23822170495986938
Batch 42/64 loss: 0.24674534797668457
Batch 43/64 loss: 0.23664450645446777
Batch 44/64 loss: 0.23334312438964844
Batch 45/64 loss: 0.23331594467163086
Batch 46/64 loss: 0.22779518365859985
Batch 47/64 loss: 0.2240060567855835
Batch 48/64 loss: 0.23667186498641968
Batch 49/64 loss: 0.23867547512054443
Batch 50/64 loss: 0.24028033018112183
Batch 51/64 loss: 0.23811674118041992
Batch 52/64 loss: 0.229894757270813
Batch 53/64 loss: 0.23581987619400024
Batch 54/64 loss: 0.22516906261444092
Batch 55/64 loss: 0.23457026481628418
Batch 56/64 loss: 0.23032593727111816
Batch 57/64 loss: 0.2362980842590332
Batch 58/64 loss: 0.2388927936553955
Batch 59/64 loss: 0.2374199628829956
Batch 60/64 loss: 0.23430603742599487
Batch 61/64 loss: 0.23647260665893555
Batch 62/64 loss: 0.2287273406982422
Batch 63/64 loss: 0.23836088180541992
Batch 64/64 loss: 0.23160415887832642
Epoch 255  Train loss: 0.23418185547286388  Val loss: 0.27139700933830024
Epoch 256
-------------------------------
Batch 1/64 loss: 0.23633891344070435
Batch 2/64 loss: 0.22695720195770264
Batch 3/64 loss: 0.23142874240875244
Batch 4/64 loss: 0.23332083225250244
Batch 5/64 loss: 0.23531174659729004
Batch 6/64 loss: 0.23015958070755005
Batch 7/64 loss: 0.24152952432632446
Batch 8/64 loss: 0.2286052703857422
Batch 9/64 loss: 0.23525428771972656
Batch 10/64 loss: 0.2312556505203247
Batch 11/64 loss: 0.234632670879364
Batch 12/64 loss: 0.22711730003356934
Batch 13/64 loss: 0.24115943908691406
Batch 14/64 loss: 0.2309722900390625
Batch 15/64 loss: 0.23671507835388184
Batch 16/64 loss: 0.23491716384887695
Batch 17/64 loss: 0.23912692070007324
Batch 18/64 loss: 0.22405600547790527
Batch 19/64 loss: 0.23977452516555786
Batch 20/64 loss: 0.22887492179870605
Batch 21/64 loss: 0.22841989994049072
Batch 22/64 loss: 0.2409718632698059
Batch 23/64 loss: 0.23474770784378052
Batch 24/64 loss: 0.23822641372680664
Batch 25/64 loss: 0.2370373010635376
Batch 26/64 loss: 0.2283855676651001
Batch 27/64 loss: 0.23383748531341553
Batch 28/64 loss: 0.22563427686691284
Batch 29/64 loss: 0.22897374629974365
Batch 30/64 loss: 0.23821258544921875
Batch 31/64 loss: 0.23675906658172607
Batch 32/64 loss: 0.23615241050720215
Batch 33/64 loss: 0.2467942237854004
Batch 34/64 loss: 0.23220908641815186
Batch 35/64 loss: 0.23301827907562256
Batch 36/64 loss: 0.2348942756652832
Batch 37/64 loss: 0.2300742268562317
Batch 38/64 loss: 0.22987759113311768
Batch 39/64 loss: 0.22371304035186768
Batch 40/64 loss: 0.22692036628723145
Batch 41/64 loss: 0.2404787540435791
Batch 42/64 loss: 0.2357097864151001
Batch 43/64 loss: 0.2426152229309082
Batch 44/64 loss: 0.2434038519859314
Batch 45/64 loss: 0.22646749019622803
Batch 46/64 loss: 0.2395542860031128
Batch 47/64 loss: 0.23372125625610352
Batch 48/64 loss: 0.2293161153793335
Batch 49/64 loss: 0.23039627075195312
Batch 50/64 loss: 0.2330959439277649
Batch 51/64 loss: 0.23028695583343506
Batch 52/64 loss: 0.23570674657821655
Batch 53/64 loss: 0.24935579299926758
Batch 54/64 loss: 0.22775757312774658
Batch 55/64 loss: 0.227664053440094
Batch 56/64 loss: 0.23147380352020264
Batch 57/64 loss: 0.2314521074295044
Batch 58/64 loss: 0.2301045060157776
Batch 59/64 loss: 0.22999465465545654
Batch 60/64 loss: 0.23684477806091309
Batch 61/64 loss: 0.2268463373184204
Batch 62/64 loss: 0.24360477924346924
Batch 63/64 loss: 0.22709763050079346
Batch 64/64 loss: 0.22051143646240234
Epoch 256  Train loss: 0.23342274123547124  Val loss: 0.27099047903342754
Saving best model, epoch: 256
Epoch 257
-------------------------------
Batch 1/64 loss: 0.22335529327392578
Batch 2/64 loss: 0.231536865234375
Batch 3/64 loss: 0.23500311374664307
Batch 4/64 loss: 0.23468351364135742
Batch 5/64 loss: 0.23840832710266113
Batch 6/64 loss: 0.23450100421905518
Batch 7/64 loss: 0.2382001280784607
Batch 8/64 loss: 0.23637235164642334
Batch 9/64 loss: 0.2349112629890442
Batch 10/64 loss: 0.2304898500442505
Batch 11/64 loss: 0.2340657114982605
Batch 12/64 loss: 0.23256170749664307
Batch 13/64 loss: 0.22887367010116577
Batch 14/64 loss: 0.23658382892608643
Batch 15/64 loss: 0.23499548435211182
Batch 16/64 loss: 0.2407512664794922
Batch 17/64 loss: 0.23440086841583252
Batch 18/64 loss: 0.23075497150421143
Batch 19/64 loss: 0.24297308921813965
Batch 20/64 loss: 0.22919774055480957
Batch 21/64 loss: 0.23420870304107666
Batch 22/64 loss: 0.22816908359527588
Batch 23/64 loss: 0.23064422607421875
Batch 24/64 loss: 0.2289181351661682
Batch 25/64 loss: 0.25092196464538574
Batch 26/64 loss: 0.23812764883041382
Batch 27/64 loss: 0.2325606346130371
Batch 28/64 loss: 0.230432391166687
Batch 29/64 loss: 0.23181134462356567
Batch 30/64 loss: 0.24066317081451416
Batch 31/64 loss: 0.23640018701553345
Batch 32/64 loss: 0.2432640790939331
Batch 33/64 loss: 0.2441016435623169
Batch 34/64 loss: 0.23357677459716797
Batch 35/64 loss: 0.22990953922271729
Batch 36/64 loss: 0.23730039596557617
Batch 37/64 loss: 0.23573291301727295
Batch 38/64 loss: 0.22968614101409912
Batch 39/64 loss: 0.2317368984222412
Batch 40/64 loss: 0.22656357288360596
Batch 41/64 loss: 0.23920738697052002
Batch 42/64 loss: 0.23274290561676025
Batch 43/64 loss: 0.22992265224456787
Batch 44/64 loss: 0.22566139698028564
Batch 45/64 loss: 0.23394900560379028
Batch 46/64 loss: 0.2264493703842163
Batch 47/64 loss: 0.2314673662185669
Batch 48/64 loss: 0.22690117359161377
Batch 49/64 loss: 0.22618579864501953
Batch 50/64 loss: 0.24753516912460327
Batch 51/64 loss: 0.23188376426696777
Batch 52/64 loss: 0.22930991649627686
Batch 53/64 loss: 0.24342435598373413
Batch 54/64 loss: 0.23315024375915527
Batch 55/64 loss: 0.22831302881240845
Batch 56/64 loss: 0.2234032154083252
Batch 57/64 loss: 0.24030661582946777
Batch 58/64 loss: 0.23074358701705933
Batch 59/64 loss: 0.2380850911140442
Batch 60/64 loss: 0.2334892749786377
Batch 61/64 loss: 0.22663867473602295
Batch 62/64 loss: 0.23712527751922607
Batch 63/64 loss: 0.2412548065185547
Batch 64/64 loss: 0.22834265232086182
Epoch 257  Train loss: 0.23381578922271729  Val loss: 0.2711915785504371
Epoch 258
-------------------------------
Batch 1/64 loss: 0.2387140989303589
Batch 2/64 loss: 0.23098009824752808
Batch 3/64 loss: 0.2221636176109314
Batch 4/64 loss: 0.23423641920089722
Batch 5/64 loss: 0.22592955827713013
Batch 6/64 loss: 0.2329801321029663
Batch 7/64 loss: 0.23072028160095215
Batch 8/64 loss: 0.2312328815460205
Batch 9/64 loss: 0.22696954011917114
Batch 10/64 loss: 0.23270487785339355
Batch 11/64 loss: 0.24157464504241943
Batch 12/64 loss: 0.23156195878982544
Batch 13/64 loss: 0.23332196474075317
Batch 14/64 loss: 0.2543880343437195
Batch 15/64 loss: 0.24229544401168823
Batch 16/64 loss: 0.24056053161621094
Batch 17/64 loss: 0.23108124732971191
Batch 18/64 loss: 0.24106985330581665
Batch 19/64 loss: 0.23239600658416748
Batch 20/64 loss: 0.24310815334320068
Batch 21/64 loss: 0.23015260696411133
Batch 22/64 loss: 0.23547518253326416
Batch 23/64 loss: 0.2295011281967163
Batch 24/64 loss: 0.23007357120513916
Batch 25/64 loss: 0.23109519481658936
Batch 26/64 loss: 0.23841089010238647
Batch 27/64 loss: 0.23311620950698853
Batch 28/64 loss: 0.2439897060394287
Batch 29/64 loss: 0.23079407215118408
Batch 30/64 loss: 0.2412736415863037
Batch 31/64 loss: 0.2409205436706543
Batch 32/64 loss: 0.2363411784172058
Batch 33/64 loss: 0.22542405128479004
Batch 34/64 loss: 0.22659069299697876
Batch 35/64 loss: 0.2443494200706482
Batch 36/64 loss: 0.2322360873222351
Batch 37/64 loss: 0.23021537065505981
Batch 38/64 loss: 0.2351764440536499
Batch 39/64 loss: 0.23730117082595825
Batch 40/64 loss: 0.2304443120956421
Batch 41/64 loss: 0.2438262701034546
Batch 42/64 loss: 0.22812247276306152
Batch 43/64 loss: 0.2348775863647461
Batch 44/64 loss: 0.23425477743148804
Batch 45/64 loss: 0.2404833436012268
Batch 46/64 loss: 0.22798454761505127
Batch 47/64 loss: 0.23332375288009644
Batch 48/64 loss: 0.23843222856521606
Batch 49/64 loss: 0.23634088039398193
Batch 50/64 loss: 0.23152482509613037
Batch 51/64 loss: 0.23345643281936646
Batch 52/64 loss: 0.2326216697692871
Batch 53/64 loss: 0.2393748164176941
Batch 54/64 loss: 0.23451703786849976
Batch 55/64 loss: 0.24065017700195312
Batch 56/64 loss: 0.22857582569122314
Batch 57/64 loss: 0.24106627702713013
Batch 58/64 loss: 0.23367094993591309
Batch 59/64 loss: 0.2309918999671936
Batch 60/64 loss: 0.22794681787490845
Batch 61/64 loss: 0.23256003856658936
Batch 62/64 loss: 0.23469746112823486
Batch 63/64 loss: 0.23282891511917114
Batch 64/64 loss: 0.2372230887413025
Epoch 258  Train loss: 0.2345241904258728  Val loss: 0.27165568284562364
Epoch 259
-------------------------------
Batch 1/64 loss: 0.22360724210739136
Batch 2/64 loss: 0.22882986068725586
Batch 3/64 loss: 0.24160706996917725
Batch 4/64 loss: 0.2334490418434143
Batch 5/64 loss: 0.22872138023376465
Batch 6/64 loss: 0.23729515075683594
Batch 7/64 loss: 0.22439885139465332
Batch 8/64 loss: 0.23553192615509033
Batch 9/64 loss: 0.22462904453277588
Batch 10/64 loss: 0.22895461320877075
Batch 11/64 loss: 0.23442262411117554
Batch 12/64 loss: 0.22322702407836914
Batch 13/64 loss: 0.222151517868042
Batch 14/64 loss: 0.22932451963424683
Batch 15/64 loss: 0.24280154705047607
Batch 16/64 loss: 0.2358531951904297
Batch 17/64 loss: 0.2313288450241089
Batch 18/64 loss: 0.23461955785751343
Batch 19/64 loss: 0.250024676322937
Batch 20/64 loss: 0.24857616424560547
Batch 21/64 loss: 0.23344480991363525
Batch 22/64 loss: 0.22931551933288574
Batch 23/64 loss: 0.2454777956008911
Batch 24/64 loss: 0.23246890306472778
Batch 25/64 loss: 0.2253265380859375
Batch 26/64 loss: 0.23159945011138916
Batch 27/64 loss: 0.24075478315353394
Batch 28/64 loss: 0.2322772741317749
Batch 29/64 loss: 0.24658238887786865
Batch 30/64 loss: 0.22083687782287598
Batch 31/64 loss: 0.2228844165802002
Batch 32/64 loss: 0.23056483268737793
Batch 33/64 loss: 0.23326683044433594
Batch 34/64 loss: 0.24250376224517822
Batch 35/64 loss: 0.22573363780975342
Batch 36/64 loss: 0.2252824902534485
Batch 37/64 loss: 0.23206210136413574
Batch 38/64 loss: 0.2278437614440918
Batch 39/64 loss: 0.23123931884765625
Batch 40/64 loss: 0.23936456441879272
Batch 41/64 loss: 0.23613882064819336
Batch 42/64 loss: 0.22999680042266846
Batch 43/64 loss: 0.23476552963256836
Batch 44/64 loss: 0.24846899509429932
Batch 45/64 loss: 0.22812998294830322
Batch 46/64 loss: 0.23214071989059448
Batch 47/64 loss: 0.2322482466697693
Batch 48/64 loss: 0.2293097972869873
Batch 49/64 loss: 0.2296159267425537
Batch 50/64 loss: 0.23834753036499023
Batch 51/64 loss: 0.22897428274154663
Batch 52/64 loss: 0.23868966102600098
Batch 53/64 loss: 0.2284080982208252
Batch 54/64 loss: 0.23131048679351807
Batch 55/64 loss: 0.2341083288192749
Batch 56/64 loss: 0.23037970066070557
Batch 57/64 loss: 0.2236061692237854
Batch 58/64 loss: 0.23526114225387573
Batch 59/64 loss: 0.2365819215774536
Batch 60/64 loss: 0.24355900287628174
Batch 61/64 loss: 0.2346435785293579
Batch 62/64 loss: 0.23150420188903809
Batch 63/64 loss: 0.22891849279403687
Batch 64/64 loss: 0.23215508460998535
Epoch 259  Train loss: 0.23290051198473163  Val loss: 0.27190202126388285
Epoch 260
-------------------------------
Batch 1/64 loss: 0.22721076011657715
Batch 2/64 loss: 0.2368394136428833
Batch 3/64 loss: 0.2338758111000061
Batch 4/64 loss: 0.22482025623321533
Batch 5/64 loss: 0.23861700296401978
Batch 6/64 loss: 0.22600358724594116
Batch 7/64 loss: 0.2289654016494751
Batch 8/64 loss: 0.24078774452209473
Batch 9/64 loss: 0.22386765480041504
Batch 10/64 loss: 0.24263709783554077
Batch 11/64 loss: 0.2321547269821167
Batch 12/64 loss: 0.2349955439567566
Batch 13/64 loss: 0.23003888130187988
Batch 14/64 loss: 0.23599350452423096
Batch 15/64 loss: 0.22793900966644287
Batch 16/64 loss: 0.22649085521697998
Batch 17/64 loss: 0.23796099424362183
Batch 18/64 loss: 0.24566781520843506
Batch 19/64 loss: 0.22398900985717773
Batch 20/64 loss: 0.23897051811218262
Batch 21/64 loss: 0.22096365690231323
Batch 22/64 loss: 0.24147236347198486
Batch 23/64 loss: 0.23450696468353271
Batch 24/64 loss: 0.22756820917129517
Batch 25/64 loss: 0.22603893280029297
Batch 26/64 loss: 0.24177789688110352
Batch 27/64 loss: 0.23806005716323853
Batch 28/64 loss: 0.22561579942703247
Batch 29/64 loss: 0.23326343297958374
Batch 30/64 loss: 0.23178714513778687
Batch 31/64 loss: 0.23205941915512085
Batch 32/64 loss: 0.23057258129119873
Batch 33/64 loss: 0.23276466131210327
Batch 34/64 loss: 0.22685670852661133
Batch 35/64 loss: 0.2424468994140625
Batch 36/64 loss: 0.22960638999938965
Batch 37/64 loss: 0.24298369884490967
Batch 38/64 loss: 0.22644567489624023
Batch 39/64 loss: 0.23217415809631348
Batch 40/64 loss: 0.2417747974395752
Batch 41/64 loss: 0.2339603304862976
Batch 42/64 loss: 0.23049545288085938
Batch 43/64 loss: 0.23223447799682617
Batch 44/64 loss: 0.23645758628845215
Batch 45/64 loss: 0.22292256355285645
Batch 46/64 loss: 0.22793376445770264
Batch 47/64 loss: 0.22661155462265015
Batch 48/64 loss: 0.2380847930908203
Batch 49/64 loss: 0.23831027746200562
Batch 50/64 loss: 0.24362552165985107
Batch 51/64 loss: 0.23455554246902466
Batch 52/64 loss: 0.23092705011367798
Batch 53/64 loss: 0.238112211227417
Batch 54/64 loss: 0.23428595066070557
Batch 55/64 loss: 0.23819053173065186
Batch 56/64 loss: 0.23335981369018555
Batch 57/64 loss: 0.23018908500671387
Batch 58/64 loss: 0.23121613264083862
Batch 59/64 loss: 0.2498134970664978
Batch 60/64 loss: 0.2279289960861206
Batch 61/64 loss: 0.23045313358306885
Batch 62/64 loss: 0.2302004098892212
Batch 63/64 loss: 0.23078960180282593
Batch 64/64 loss: 0.23479044437408447
Epoch 260  Train loss: 0.23315005723167867  Val loss: 0.2730098753860316
Epoch 261
-------------------------------
Batch 1/64 loss: 0.22299909591674805
Batch 2/64 loss: 0.24402499198913574
Batch 3/64 loss: 0.22346830368041992
Batch 4/64 loss: 0.23943543434143066
Batch 5/64 loss: 0.23768365383148193
Batch 6/64 loss: 0.23221778869628906
Batch 7/64 loss: 0.23018521070480347
Batch 8/64 loss: 0.2234211564064026
Batch 9/64 loss: 0.22767925262451172
Batch 10/64 loss: 0.22416168451309204
Batch 11/64 loss: 0.23124361038208008
Batch 12/64 loss: 0.22979235649108887
Batch 13/64 loss: 0.2247169017791748
Batch 14/64 loss: 0.22989696264266968
Batch 15/64 loss: 0.2196483612060547
Batch 16/64 loss: 0.23672664165496826
Batch 17/64 loss: 0.23057639598846436
Batch 18/64 loss: 0.23298144340515137
Batch 19/64 loss: 0.23685121536254883
Batch 20/64 loss: 0.23029416799545288
Batch 21/64 loss: 0.23756200075149536
Batch 22/64 loss: 0.23109227418899536
Batch 23/64 loss: 0.22352206707000732
Batch 24/64 loss: 0.23329973220825195
Batch 25/64 loss: 0.22999417781829834
Batch 26/64 loss: 0.2310391664505005
Batch 27/64 loss: 0.2397913932800293
Batch 28/64 loss: 0.2324460744857788
Batch 29/64 loss: 0.24281656742095947
Batch 30/64 loss: 0.2308577299118042
Batch 31/64 loss: 0.2316577434539795
Batch 32/64 loss: 0.22997796535491943
Batch 33/64 loss: 0.2335633635520935
Batch 34/64 loss: 0.23856037855148315
Batch 35/64 loss: 0.2297208309173584
Batch 36/64 loss: 0.2265424132347107
Batch 37/64 loss: 0.22527283430099487
Batch 38/64 loss: 0.22609174251556396
Batch 39/64 loss: 0.2350175380706787
Batch 40/64 loss: 0.241968035697937
Batch 41/64 loss: 0.23548614978790283
Batch 42/64 loss: 0.2357034683227539
Batch 43/64 loss: 0.2315792441368103
Batch 44/64 loss: 0.22854065895080566
Batch 45/64 loss: 0.24166560173034668
Batch 46/64 loss: 0.2363969087600708
Batch 47/64 loss: 0.23011159896850586
Batch 48/64 loss: 0.23631024360656738
Batch 49/64 loss: 0.22849023342132568
Batch 50/64 loss: 0.23650813102722168
Batch 51/64 loss: 0.24057036638259888
Batch 52/64 loss: 0.24659252166748047
Batch 53/64 loss: 0.2320103645324707
Batch 54/64 loss: 0.23448526859283447
Batch 55/64 loss: 0.2392672300338745
Batch 56/64 loss: 0.2357184886932373
Batch 57/64 loss: 0.2362736463546753
Batch 58/64 loss: 0.22816860675811768
Batch 59/64 loss: 0.23011302947998047
Batch 60/64 loss: 0.23372483253479004
Batch 61/64 loss: 0.24370336532592773
Batch 62/64 loss: 0.23647189140319824
Batch 63/64 loss: 0.24134689569473267
Batch 64/64 loss: 0.23592770099639893
Epoch 261  Train loss: 0.23301934401194255  Val loss: 0.27153354330161183
Epoch 262
-------------------------------
Batch 1/64 loss: 0.22833752632141113
Batch 2/64 loss: 0.22467392683029175
Batch 3/64 loss: 0.23468399047851562
Batch 4/64 loss: 0.2297273874282837
Batch 5/64 loss: 0.2340725064277649
Batch 6/64 loss: 0.2340415120124817
Batch 7/64 loss: 0.233822762966156
Batch 8/64 loss: 0.2289881706237793
Batch 9/64 loss: 0.22548246383666992
Batch 10/64 loss: 0.23530727624893188
Batch 11/64 loss: 0.2330978512763977
Batch 12/64 loss: 0.23435229063034058
Batch 13/64 loss: 0.22798144817352295
Batch 14/64 loss: 0.23790359497070312
Batch 15/64 loss: 0.23109841346740723
Batch 16/64 loss: 0.23287999629974365
Batch 17/64 loss: 0.2311040163040161
Batch 18/64 loss: 0.23070955276489258
Batch 19/64 loss: 0.22792088985443115
Batch 20/64 loss: 0.22826671600341797
Batch 21/64 loss: 0.23366475105285645
Batch 22/64 loss: 0.25044333934783936
Batch 23/64 loss: 0.23232543468475342
Batch 24/64 loss: 0.2259601354598999
Batch 25/64 loss: 0.24464571475982666
Batch 26/64 loss: 0.23112601041793823
Batch 27/64 loss: 0.23199057579040527
Batch 28/64 loss: 0.23745280504226685
Batch 29/64 loss: 0.22933268547058105
Batch 30/64 loss: 0.2255406379699707
Batch 31/64 loss: 0.23334789276123047
Batch 32/64 loss: 0.22852027416229248
Batch 33/64 loss: 0.2328660488128662
Batch 34/64 loss: 0.23702216148376465
Batch 35/64 loss: 0.23750102519989014
Batch 36/64 loss: 0.23029768466949463
Batch 37/64 loss: 0.23661696910858154
Batch 38/64 loss: 0.23433053493499756
Batch 39/64 loss: 0.23082125186920166
Batch 40/64 loss: 0.2373669147491455
Batch 41/64 loss: 0.2345752716064453
Batch 42/64 loss: 0.22501647472381592
Batch 43/64 loss: 0.23558324575424194
Batch 44/64 loss: 0.23927098512649536
Batch 45/64 loss: 0.2330418825149536
Batch 46/64 loss: 0.23202180862426758
Batch 47/64 loss: 0.23546016216278076
Batch 48/64 loss: 0.2362527847290039
Batch 49/64 loss: 0.23460888862609863
Batch 50/64 loss: 0.2365952730178833
Batch 51/64 loss: 0.24093914031982422
Batch 52/64 loss: 0.22469091415405273
Batch 53/64 loss: 0.22888469696044922
Batch 54/64 loss: 0.23827648162841797
Batch 55/64 loss: 0.22457551956176758
Batch 56/64 loss: 0.23268508911132812
Batch 57/64 loss: 0.23130065202713013
Batch 58/64 loss: 0.23363065719604492
Batch 59/64 loss: 0.24091053009033203
Batch 60/64 loss: 0.23315531015396118
Batch 61/64 loss: 0.2286536693572998
Batch 62/64 loss: 0.24276912212371826
Batch 63/64 loss: 0.23300325870513916
Batch 64/64 loss: 0.24058115482330322
Epoch 262  Train loss: 0.23312882862839043  Val loss: 0.2708511131325948
Saving best model, epoch: 262
Epoch 263
-------------------------------
Batch 1/64 loss: 0.22648918628692627
Batch 2/64 loss: 0.23509341478347778
Batch 3/64 loss: 0.23501724004745483
Batch 4/64 loss: 0.2319866418838501
Batch 5/64 loss: 0.2321310043334961
Batch 6/64 loss: 0.23314118385314941
Batch 7/64 loss: 0.23350679874420166
Batch 8/64 loss: 0.2332090139389038
Batch 9/64 loss: 0.22438955307006836
Batch 10/64 loss: 0.23910903930664062
Batch 11/64 loss: 0.23648357391357422
Batch 12/64 loss: 0.21889793872833252
Batch 13/64 loss: 0.22999954223632812
Batch 14/64 loss: 0.23247063159942627
Batch 15/64 loss: 0.23310375213623047
Batch 16/64 loss: 0.22609657049179077
Batch 17/64 loss: 0.24182367324829102
Batch 18/64 loss: 0.22881221771240234
Batch 19/64 loss: 0.23252665996551514
Batch 20/64 loss: 0.2446410059928894
Batch 21/64 loss: 0.235906720161438
Batch 22/64 loss: 0.22726845741271973
Batch 23/64 loss: 0.23019903898239136
Batch 24/64 loss: 0.23318731784820557
Batch 25/64 loss: 0.23255646228790283
Batch 26/64 loss: 0.23166799545288086
Batch 27/64 loss: 0.2356950044631958
Batch 28/64 loss: 0.23621070384979248
Batch 29/64 loss: 0.22123616933822632
Batch 30/64 loss: 0.23601043224334717
Batch 31/64 loss: 0.22580063343048096
Batch 32/64 loss: 0.23271292448043823
Batch 33/64 loss: 0.2369554042816162
Batch 34/64 loss: 0.2288961410522461
Batch 35/64 loss: 0.22896313667297363
Batch 36/64 loss: 0.2298269271850586
Batch 37/64 loss: 0.22553420066833496
Batch 38/64 loss: 0.2366276979446411
Batch 39/64 loss: 0.23363518714904785
Batch 40/64 loss: 0.22830432653427124
Batch 41/64 loss: 0.23300087451934814
Batch 42/64 loss: 0.22533279657363892
Batch 43/64 loss: 0.23161101341247559
Batch 44/64 loss: 0.2322971224784851
Batch 45/64 loss: 0.22817540168762207
Batch 46/64 loss: 0.24014121294021606
Batch 47/64 loss: 0.2316673994064331
Batch 48/64 loss: 0.23148101568222046
Batch 49/64 loss: 0.2382136583328247
Batch 50/64 loss: 0.23294222354888916
Batch 51/64 loss: 0.22678238153457642
Batch 52/64 loss: 0.2248765230178833
Batch 53/64 loss: 0.22738736867904663
Batch 54/64 loss: 0.22689521312713623
Batch 55/64 loss: 0.2332007884979248
Batch 56/64 loss: 0.23266065120697021
Batch 57/64 loss: 0.24375206232070923
Batch 58/64 loss: 0.24606966972351074
Batch 59/64 loss: 0.23694169521331787
Batch 60/64 loss: 0.2378305196762085
Batch 61/64 loss: 0.22942107915878296
Batch 62/64 loss: 0.23156893253326416
Batch 63/64 loss: 0.23490649461746216
Batch 64/64 loss: 0.22547602653503418
Epoch 263  Train loss: 0.23219430025886087  Val loss: 0.2709010591621661
Epoch 264
-------------------------------
Batch 1/64 loss: 0.22575360536575317
Batch 2/64 loss: 0.2297292947769165
Batch 3/64 loss: 0.22976982593536377
Batch 4/64 loss: 0.22855621576309204
Batch 5/64 loss: 0.23378145694732666
Batch 6/64 loss: 0.22596430778503418
Batch 7/64 loss: 0.23118185997009277
Batch 8/64 loss: 0.22594225406646729
Batch 9/64 loss: 0.23849397897720337
Batch 10/64 loss: 0.23263299465179443
Batch 11/64 loss: 0.24076330661773682
Batch 12/64 loss: 0.22711235284805298
Batch 13/64 loss: 0.23598849773406982
Batch 14/64 loss: 0.23038768768310547
Batch 15/64 loss: 0.2269303798675537
Batch 16/64 loss: 0.2258455753326416
Batch 17/64 loss: 0.23310035467147827
Batch 18/64 loss: 0.22786468267440796
Batch 19/64 loss: 0.23301172256469727
Batch 20/64 loss: 0.23075610399246216
Batch 21/64 loss: 0.23115676641464233
Batch 22/64 loss: 0.23587679862976074
Batch 23/64 loss: 0.23912811279296875
Batch 24/64 loss: 0.232347309589386
Batch 25/64 loss: 0.2317136526107788
Batch 26/64 loss: 0.2334989309310913
Batch 27/64 loss: 0.24128293991088867
Batch 28/64 loss: 0.2360803484916687
Batch 29/64 loss: 0.231864333152771
Batch 30/64 loss: 0.23235023021697998
Batch 31/64 loss: 0.24200701713562012
Batch 32/64 loss: 0.2264912724494934
Batch 33/64 loss: 0.22997450828552246
Batch 34/64 loss: 0.23487919569015503
Batch 35/64 loss: 0.23413515090942383
Batch 36/64 loss: 0.2350689172744751
Batch 37/64 loss: 0.23282313346862793
Batch 38/64 loss: 0.2361854910850525
Batch 39/64 loss: 0.23902231454849243
Batch 40/64 loss: 0.23932158946990967
Batch 41/64 loss: 0.22913789749145508
Batch 42/64 loss: 0.23394036293029785
Batch 43/64 loss: 0.22347605228424072
Batch 44/64 loss: 0.24718129634857178
Batch 45/64 loss: 0.2331467866897583
Batch 46/64 loss: 0.2394580841064453
Batch 47/64 loss: 0.2354719638824463
Batch 48/64 loss: 0.2264636754989624
Batch 49/64 loss: 0.23509955406188965
Batch 50/64 loss: 0.2345370054244995
Batch 51/64 loss: 0.22128260135650635
Batch 52/64 loss: 0.23000776767730713
Batch 53/64 loss: 0.2257792353630066
Batch 54/64 loss: 0.23113244771957397
Batch 55/64 loss: 0.22857242822647095
Batch 56/64 loss: 0.22669512033462524
Batch 57/64 loss: 0.24268609285354614
Batch 58/64 loss: 0.24786198139190674
Batch 59/64 loss: 0.22726720571517944
Batch 60/64 loss: 0.2319483757019043
Batch 61/64 loss: 0.22793805599212646
Batch 62/64 loss: 0.2300376296043396
Batch 63/64 loss: 0.2372070550918579
Batch 64/64 loss: 0.2236398458480835
Epoch 264  Train loss: 0.23251502794377943  Val loss: 0.27097004795402185
Epoch 265
-------------------------------
Batch 1/64 loss: 0.22741341590881348
Batch 2/64 loss: 0.2261856198310852
Batch 3/64 loss: 0.24499434232711792
Batch 4/64 loss: 0.23400843143463135
Batch 5/64 loss: 0.23093628883361816
Batch 6/64 loss: 0.22356629371643066
Batch 7/64 loss: 0.23657900094985962
Batch 8/64 loss: 0.23623764514923096
Batch 9/64 loss: 0.22717273235321045
Batch 10/64 loss: 0.22585070133209229
Batch 11/64 loss: 0.22256922721862793
Batch 12/64 loss: 0.2269289493560791
Batch 13/64 loss: 0.23188388347625732
Batch 14/64 loss: 0.22282040119171143
Batch 15/64 loss: 0.22221660614013672
Batch 16/64 loss: 0.2330176830291748
Batch 17/64 loss: 0.2330135703086853
Batch 18/64 loss: 0.2304350733757019
Batch 19/64 loss: 0.23111063241958618
Batch 20/64 loss: 0.22806543111801147
Batch 21/64 loss: 0.22657430171966553
Batch 22/64 loss: 0.2277950644493103
Batch 23/64 loss: 0.23235148191452026
Batch 24/64 loss: 0.22453045845031738
Batch 25/64 loss: 0.2312546968460083
Batch 26/64 loss: 0.23129057884216309
Batch 27/64 loss: 0.22923123836517334
Batch 28/64 loss: 0.23751157522201538
Batch 29/64 loss: 0.22649765014648438
Batch 30/64 loss: 0.22600704431533813
Batch 31/64 loss: 0.2371683120727539
Batch 32/64 loss: 0.23412418365478516
Batch 33/64 loss: 0.24285322427749634
Batch 34/64 loss: 0.24010074138641357
Batch 35/64 loss: 0.2364102602005005
Batch 36/64 loss: 0.23707175254821777
Batch 37/64 loss: 0.22369253635406494
Batch 38/64 loss: 0.22925329208374023
Batch 39/64 loss: 0.2283574342727661
Batch 40/64 loss: 0.2275000810623169
Batch 41/64 loss: 0.23036837577819824
Batch 42/64 loss: 0.2310667634010315
Batch 43/64 loss: 0.232291579246521
Batch 44/64 loss: 0.23285263776779175
Batch 45/64 loss: 0.23508977890014648
Batch 46/64 loss: 0.23378372192382812
Batch 47/64 loss: 0.230937659740448
Batch 48/64 loss: 0.23281538486480713
Batch 49/64 loss: 0.2267889380455017
Batch 50/64 loss: 0.2384200096130371
Batch 51/64 loss: 0.23017549514770508
Batch 52/64 loss: 0.2343982458114624
Batch 53/64 loss: 0.23834681510925293
Batch 54/64 loss: 0.228704571723938
Batch 55/64 loss: 0.22829926013946533
Batch 56/64 loss: 0.238991379737854
Batch 57/64 loss: 0.2278348207473755
Batch 58/64 loss: 0.2365531325340271
Batch 59/64 loss: 0.23813176155090332
Batch 60/64 loss: 0.23263919353485107
Batch 61/64 loss: 0.23321175575256348
Batch 62/64 loss: 0.23299753665924072
Batch 63/64 loss: 0.22472798824310303
Batch 64/64 loss: 0.2429090142250061
Epoch 265  Train loss: 0.23146965340072034  Val loss: 0.2716380439673093
Epoch 266
-------------------------------
Batch 1/64 loss: 0.23559677600860596
Batch 2/64 loss: 0.23520565032958984
Batch 3/64 loss: 0.22558611631393433
Batch 4/64 loss: 0.22813105583190918
Batch 5/64 loss: 0.22544831037521362
Batch 6/64 loss: 0.22829055786132812
Batch 7/64 loss: 0.2303212285041809
Batch 8/64 loss: 0.2374172806739807
Batch 9/64 loss: 0.22239017486572266
Batch 10/64 loss: 0.22385680675506592
Batch 11/64 loss: 0.22785818576812744
Batch 12/64 loss: 0.23341894149780273
Batch 13/64 loss: 0.2300993800163269
Batch 14/64 loss: 0.23165619373321533
Batch 15/64 loss: 0.22578728199005127
Batch 16/64 loss: 0.2265528440475464
Batch 17/64 loss: 0.22552001476287842
Batch 18/64 loss: 0.23275160789489746
Batch 19/64 loss: 0.2374265193939209
Batch 20/64 loss: 0.22969937324523926
Batch 21/64 loss: 0.24242043495178223
Batch 22/64 loss: 0.2420549988746643
Batch 23/64 loss: 0.2287503480911255
Batch 24/64 loss: 0.22834110260009766
Batch 25/64 loss: 0.23170912265777588
Batch 26/64 loss: 0.22726547718048096
Batch 27/64 loss: 0.22340166568756104
Batch 28/64 loss: 0.2288299798965454
Batch 29/64 loss: 0.2352815866470337
Batch 30/64 loss: 0.23129308223724365
Batch 31/64 loss: 0.2383040189743042
Batch 32/64 loss: 0.23607265949249268
Batch 33/64 loss: 0.22565114498138428
Batch 34/64 loss: 0.22954976558685303
Batch 35/64 loss: 0.23545116186141968
Batch 36/64 loss: 0.2284914255142212
Batch 37/64 loss: 0.23032236099243164
Batch 38/64 loss: 0.23858052492141724
Batch 39/64 loss: 0.23976242542266846
Batch 40/64 loss: 0.23063361644744873
Batch 41/64 loss: 0.2407994270324707
Batch 42/64 loss: 0.23994696140289307
Batch 43/64 loss: 0.23452365398406982
Batch 44/64 loss: 0.226729154586792
Batch 45/64 loss: 0.23416554927825928
Batch 46/64 loss: 0.23255276679992676
Batch 47/64 loss: 0.23477482795715332
Batch 48/64 loss: 0.22739839553833008
Batch 49/64 loss: 0.23647862672805786
Batch 50/64 loss: 0.2237066626548767
Batch 51/64 loss: 0.2294706106185913
Batch 52/64 loss: 0.2275819182395935
Batch 53/64 loss: 0.23473477363586426
Batch 54/64 loss: 0.22832828760147095
Batch 55/64 loss: 0.2340233325958252
Batch 56/64 loss: 0.23565435409545898
Batch 57/64 loss: 0.22257936000823975
Batch 58/64 loss: 0.23293280601501465
Batch 59/64 loss: 0.23372411727905273
Batch 60/64 loss: 0.22313445806503296
Batch 61/64 loss: 0.2438598871231079
Batch 62/64 loss: 0.22559106349945068
Batch 63/64 loss: 0.22627949714660645
Batch 64/64 loss: 0.22888267040252686
Epoch 266  Train loss: 0.23130688153061213  Val loss: 0.2721888187415002
Epoch 267
-------------------------------
Batch 1/64 loss: 0.22075480222702026
Batch 2/64 loss: 0.2265956997871399
Batch 3/64 loss: 0.2281109094619751
Batch 4/64 loss: 0.23946237564086914
Batch 5/64 loss: 0.22779083251953125
Batch 6/64 loss: 0.2284454107284546
Batch 7/64 loss: 0.2220516800880432
Batch 8/64 loss: 0.2258695363998413
Batch 9/64 loss: 0.22426044940948486
Batch 10/64 loss: 0.22817015647888184
Batch 11/64 loss: 0.2298077940940857
Batch 12/64 loss: 0.22525084018707275
Batch 13/64 loss: 0.2294211983680725
Batch 14/64 loss: 0.22015446424484253
Batch 15/64 loss: 0.2349379062652588
Batch 16/64 loss: 0.22942453622817993
Batch 17/64 loss: 0.23433518409729004
Batch 18/64 loss: 0.2223137617111206
Batch 19/64 loss: 0.2398877739906311
Batch 20/64 loss: 0.23422473669052124
Batch 21/64 loss: 0.24122822284698486
Batch 22/64 loss: 0.22179394960403442
Batch 23/64 loss: 0.23598504066467285
Batch 24/64 loss: 0.2369614839553833
Batch 25/64 loss: 0.23051506280899048
Batch 26/64 loss: 0.22310227155685425
Batch 27/64 loss: 0.25255846977233887
Batch 28/64 loss: 0.2348269820213318
Batch 29/64 loss: 0.23316645622253418
Batch 30/64 loss: 0.23097312450408936
Batch 31/64 loss: 0.23705029487609863
Batch 32/64 loss: 0.22768783569335938
Batch 33/64 loss: 0.23144233226776123
Batch 34/64 loss: 0.2226429581642151
Batch 35/64 loss: 0.22975587844848633
Batch 36/64 loss: 0.23099786043167114
Batch 37/64 loss: 0.23201501369476318
Batch 38/64 loss: 0.23493754863739014
Batch 39/64 loss: 0.23811328411102295
Batch 40/64 loss: 0.24913322925567627
Batch 41/64 loss: 0.23835152387619019
Batch 42/64 loss: 0.23493850231170654
Batch 43/64 loss: 0.22830265760421753
Batch 44/64 loss: 0.23508590459823608
Batch 45/64 loss: 0.23339176177978516
Batch 46/64 loss: 0.23645257949829102
Batch 47/64 loss: 0.23310858011245728
Batch 48/64 loss: 0.23704111576080322
Batch 49/64 loss: 0.22628676891326904
Batch 50/64 loss: 0.23538988828659058
Batch 51/64 loss: 0.23132789134979248
Batch 52/64 loss: 0.23428934812545776
Batch 53/64 loss: 0.24314379692077637
Batch 54/64 loss: 0.23351162672042847
Batch 55/64 loss: 0.2288246750831604
Batch 56/64 loss: 0.2397729754447937
Batch 57/64 loss: 0.22956979274749756
Batch 58/64 loss: 0.22782683372497559
Batch 59/64 loss: 0.22980576753616333
Batch 60/64 loss: 0.22933423519134521
Batch 61/64 loss: 0.2336503267288208
Batch 62/64 loss: 0.23396557569503784
Batch 63/64 loss: 0.22541379928588867
Batch 64/64 loss: 0.23624277114868164
Epoch 267  Train loss: 0.23187647613824583  Val loss: 0.2700377125100991
Saving best model, epoch: 267
Epoch 268
-------------------------------
Batch 1/64 loss: 0.23293864727020264
Batch 2/64 loss: 0.21784460544586182
Batch 3/64 loss: 0.22092288732528687
Batch 4/64 loss: 0.22993570566177368
Batch 5/64 loss: 0.23567843437194824
Batch 6/64 loss: 0.23584246635437012
Batch 7/64 loss: 0.22632157802581787
Batch 8/64 loss: 0.2339966893196106
Batch 9/64 loss: 0.23459243774414062
Batch 10/64 loss: 0.2313826084136963
Batch 11/64 loss: 0.23523247241973877
Batch 12/64 loss: 0.23734116554260254
Batch 13/64 loss: 0.22974133491516113
Batch 14/64 loss: 0.22902101278305054
Batch 15/64 loss: 0.23358607292175293
Batch 16/64 loss: 0.23099493980407715
Batch 17/64 loss: 0.2238972783088684
Batch 18/64 loss: 0.23309218883514404
Batch 19/64 loss: 0.22683072090148926
Batch 20/64 loss: 0.230035662651062
Batch 21/64 loss: 0.23023462295532227
Batch 22/64 loss: 0.2361486554145813
Batch 23/64 loss: 0.23099327087402344
Batch 24/64 loss: 0.23522108793258667
Batch 25/64 loss: 0.22771453857421875
Batch 26/64 loss: 0.23237377405166626
Batch 27/64 loss: 0.2418561577796936
Batch 28/64 loss: 0.2345818281173706
Batch 29/64 loss: 0.22282373905181885
Batch 30/64 loss: 0.22801154851913452
Batch 31/64 loss: 0.23191606998443604
Batch 32/64 loss: 0.23040282726287842
Batch 33/64 loss: 0.21756523847579956
Batch 34/64 loss: 0.23128390312194824
Batch 35/64 loss: 0.23821914196014404
Batch 36/64 loss: 0.22477412223815918
Batch 37/64 loss: 0.22766369581222534
Batch 38/64 loss: 0.22710835933685303
Batch 39/64 loss: 0.22428297996520996
Batch 40/64 loss: 0.22729706764221191
Batch 41/64 loss: 0.23821663856506348
Batch 42/64 loss: 0.2335442304611206
Batch 43/64 loss: 0.231792151927948
Batch 44/64 loss: 0.22265559434890747
Batch 45/64 loss: 0.2353508472442627
Batch 46/64 loss: 0.22840309143066406
Batch 47/64 loss: 0.2397899031639099
Batch 48/64 loss: 0.23303604125976562
Batch 49/64 loss: 0.22530889511108398
Batch 50/64 loss: 0.23442256450653076
Batch 51/64 loss: 0.22739481925964355
Batch 52/64 loss: 0.22485041618347168
Batch 53/64 loss: 0.23208147287368774
Batch 54/64 loss: 0.2323545217514038
Batch 55/64 loss: 0.23826229572296143
Batch 56/64 loss: 0.22246670722961426
Batch 57/64 loss: 0.21863389015197754
Batch 58/64 loss: 0.227910578250885
Batch 59/64 loss: 0.22945398092269897
Batch 60/64 loss: 0.23651599884033203
Batch 61/64 loss: 0.2231982946395874
Batch 62/64 loss: 0.231417715549469
Batch 63/64 loss: 0.24780410528182983
Batch 64/64 loss: 0.22531342506408691
Epoch 268  Train loss: 0.23048708018134623  Val loss: 0.27090599569668067
Epoch 269
-------------------------------
Batch 1/64 loss: 0.23148977756500244
Batch 2/64 loss: 0.22799170017242432
Batch 3/64 loss: 0.231431245803833
Batch 4/64 loss: 0.23670107126235962
Batch 5/64 loss: 0.22779905796051025
Batch 6/64 loss: 0.22764521837234497
Batch 7/64 loss: 0.23174047470092773
Batch 8/64 loss: 0.22174954414367676
Batch 9/64 loss: 0.23486804962158203
Batch 10/64 loss: 0.2298128604888916
Batch 11/64 loss: 0.2301955223083496
Batch 12/64 loss: 0.2228621244430542
Batch 13/64 loss: 0.23156100511550903
Batch 14/64 loss: 0.22566109895706177
Batch 15/64 loss: 0.2174626588821411
Batch 16/64 loss: 0.2203279733657837
Batch 17/64 loss: 0.2296409010887146
Batch 18/64 loss: 0.2327069640159607
Batch 19/64 loss: 0.2336212396621704
Batch 20/64 loss: 0.22440773248672485
Batch 21/64 loss: 0.22636568546295166
Batch 22/64 loss: 0.2321813702583313
Batch 23/64 loss: 0.23528343439102173
Batch 24/64 loss: 0.2262355089187622
Batch 25/64 loss: 0.23505890369415283
Batch 26/64 loss: 0.23050463199615479
Batch 27/64 loss: 0.2410125732421875
Batch 28/64 loss: 0.22134262323379517
Batch 29/64 loss: 0.2357161045074463
Batch 30/64 loss: 0.23378759622573853
Batch 31/64 loss: 0.22583401203155518
Batch 32/64 loss: 0.23149311542510986
Batch 33/64 loss: 0.22525310516357422
Batch 34/64 loss: 0.23119688034057617
Batch 35/64 loss: 0.2291339635848999
Batch 36/64 loss: 0.23535674810409546
Batch 37/64 loss: 0.2257061004638672
Batch 38/64 loss: 0.24427658319473267
Batch 39/64 loss: 0.23325270414352417
Batch 40/64 loss: 0.23244708776474
Batch 41/64 loss: 0.23151612281799316
Batch 42/64 loss: 0.23486614227294922
Batch 43/64 loss: 0.2276782989501953
Batch 44/64 loss: 0.2288118600845337
Batch 45/64 loss: 0.22298860549926758
Batch 46/64 loss: 0.2310352325439453
Batch 47/64 loss: 0.23961114883422852
Batch 48/64 loss: 0.2280612587928772
Batch 49/64 loss: 0.22740942239761353
Batch 50/64 loss: 0.23975533246994019
Batch 51/64 loss: 0.22741711139678955
Batch 52/64 loss: 0.22446686029434204
Batch 53/64 loss: 0.23527652025222778
Batch 54/64 loss: 0.2248239517211914
Batch 55/64 loss: 0.23105919361114502
Batch 56/64 loss: 0.22737008333206177
Batch 57/64 loss: 0.23376256227493286
Batch 58/64 loss: 0.22694694995880127
Batch 59/64 loss: 0.23340260982513428
Batch 60/64 loss: 0.22709763050079346
Batch 61/64 loss: 0.23789477348327637
Batch 62/64 loss: 0.23232126235961914
Batch 63/64 loss: 0.22855806350708008
Batch 64/64 loss: 0.21909451484680176
Epoch 269  Train loss: 0.2300794797785142  Val loss: 0.27057543693948855
Epoch 270
-------------------------------
Batch 1/64 loss: 0.22302591800689697
Batch 2/64 loss: 0.2376192808151245
Batch 3/64 loss: 0.22731006145477295
Batch 4/64 loss: 0.22490906715393066
Batch 5/64 loss: 0.22716397047042847
Batch 6/64 loss: 0.2191988229751587
Batch 7/64 loss: 0.229680597782135
Batch 8/64 loss: 0.23006606101989746
Batch 9/64 loss: 0.22323328256607056
Batch 10/64 loss: 0.2300596833229065
Batch 11/64 loss: 0.2284766435623169
Batch 12/64 loss: 0.22962039709091187
Batch 13/64 loss: 0.24192464351654053
Batch 14/64 loss: 0.23141717910766602
Batch 15/64 loss: 0.2314555048942566
Batch 16/64 loss: 0.22880101203918457
Batch 17/64 loss: 0.22405385971069336
Batch 18/64 loss: 0.22745442390441895
Batch 19/64 loss: 0.2273157835006714
Batch 20/64 loss: 0.22214341163635254
Batch 21/64 loss: 0.23009276390075684
Batch 22/64 loss: 0.24413079023361206
Batch 23/64 loss: 0.2241663932800293
Batch 24/64 loss: 0.23489147424697876
Batch 25/64 loss: 0.22959226369857788
Batch 26/64 loss: 0.24442660808563232
Batch 27/64 loss: 0.2264818549156189
Batch 28/64 loss: 0.22846907377243042
Batch 29/64 loss: 0.22687959671020508
Batch 30/64 loss: 0.23778903484344482
Batch 31/64 loss: 0.23051941394805908
Batch 32/64 loss: 0.24173760414123535
Batch 33/64 loss: 0.224481463432312
Batch 34/64 loss: 0.23123055696487427
Batch 35/64 loss: 0.22441035509109497
Batch 36/64 loss: 0.2358086109161377
Batch 37/64 loss: 0.2315516471862793
Batch 38/64 loss: 0.23700308799743652
Batch 39/64 loss: 0.23719477653503418
Batch 40/64 loss: 0.21622884273529053
Batch 41/64 loss: 0.22701585292816162
Batch 42/64 loss: 0.22976720333099365
Batch 43/64 loss: 0.22413259744644165
Batch 44/64 loss: 0.23061078786849976
Batch 45/64 loss: 0.2246328592300415
Batch 46/64 loss: 0.2340756058692932
Batch 47/64 loss: 0.22636258602142334
Batch 48/64 loss: 0.2301112413406372
Batch 49/64 loss: 0.2373443841934204
Batch 50/64 loss: 0.24210232496261597
Batch 51/64 loss: 0.22644734382629395
Batch 52/64 loss: 0.23255866765975952
Batch 53/64 loss: 0.2257477045059204
Batch 54/64 loss: 0.22474145889282227
Batch 55/64 loss: 0.2467951774597168
Batch 56/64 loss: 0.22400057315826416
Batch 57/64 loss: 0.22249102592468262
Batch 58/64 loss: 0.2281702756881714
Batch 59/64 loss: 0.23189175128936768
Batch 60/64 loss: 0.2278451919555664
Batch 61/64 loss: 0.25024545192718506
Batch 62/64 loss: 0.2300865650177002
Batch 63/64 loss: 0.22813642024993896
Batch 64/64 loss: 0.2172684669494629
Epoch 270  Train loss: 0.23012204263724534  Val loss: 0.27114069379891725
Epoch 271
-------------------------------
Batch 1/64 loss: 0.23059791326522827
Batch 2/64 loss: 0.23654663562774658
Batch 3/64 loss: 0.23418235778808594
Batch 4/64 loss: 0.23383641242980957
Batch 5/64 loss: 0.22698742151260376
Batch 6/64 loss: 0.22738337516784668
Batch 7/64 loss: 0.22639232873916626
Batch 8/64 loss: 0.23348069190979004
Batch 9/64 loss: 0.23547041416168213
Batch 10/64 loss: 0.24635839462280273
Batch 11/64 loss: 0.23016393184661865
Batch 12/64 loss: 0.2377690076828003
Batch 13/64 loss: 0.22007787227630615
Batch 14/64 loss: 0.23605132102966309
Batch 15/64 loss: 0.21824926137924194
Batch 16/64 loss: 0.2258589267730713
Batch 17/64 loss: 0.2328893542289734
Batch 18/64 loss: 0.22851252555847168
Batch 19/64 loss: 0.22580504417419434
Batch 20/64 loss: 0.23085546493530273
Batch 21/64 loss: 0.22883200645446777
Batch 22/64 loss: 0.22207999229431152
Batch 23/64 loss: 0.23648011684417725
Batch 24/64 loss: 0.2250196933746338
Batch 25/64 loss: 0.22455227375030518
Batch 26/64 loss: 0.22862058877944946
Batch 27/64 loss: 0.23297977447509766
Batch 28/64 loss: 0.22940945625305176
Batch 29/64 loss: 0.22585713863372803
Batch 30/64 loss: 0.23901915550231934
Batch 31/64 loss: 0.22626769542694092
Batch 32/64 loss: 0.22879409790039062
Batch 33/64 loss: 0.22836434841156006
Batch 34/64 loss: 0.22476094961166382
Batch 35/64 loss: 0.23037999868392944
Batch 36/64 loss: 0.23235177993774414
Batch 37/64 loss: 0.22909283638000488
Batch 38/64 loss: 0.22651571035385132
Batch 39/64 loss: 0.2388550043106079
Batch 40/64 loss: 0.23290324211120605
Batch 41/64 loss: 0.2254278063774109
Batch 42/64 loss: 0.23418653011322021
Batch 43/64 loss: 0.2283008098602295
Batch 44/64 loss: 0.2293534278869629
Batch 45/64 loss: 0.23733115196228027
Batch 46/64 loss: 0.2330561876296997
Batch 47/64 loss: 0.23514634370803833
Batch 48/64 loss: 0.2403702735900879
Batch 49/64 loss: 0.2281915545463562
Batch 50/64 loss: 0.23261308670043945
Batch 51/64 loss: 0.23985600471496582
Batch 52/64 loss: 0.2429722547531128
Batch 53/64 loss: 0.23135167360305786
Batch 54/64 loss: 0.23489397764205933
Batch 55/64 loss: 0.22357535362243652
Batch 56/64 loss: 0.2273423671722412
Batch 57/64 loss: 0.22473889589309692
Batch 58/64 loss: 0.23553144931793213
Batch 59/64 loss: 0.23153436183929443
Batch 60/64 loss: 0.22242587804794312
Batch 61/64 loss: 0.22432804107666016
Batch 62/64 loss: 0.2191709280014038
Batch 63/64 loss: 0.23227614164352417
Batch 64/64 loss: 0.2305762767791748
Epoch 271  Train loss: 0.23051782308840285  Val loss: 0.2698940030487952
Saving best model, epoch: 271
Epoch 272
-------------------------------
Batch 1/64 loss: 0.23761910200119019
Batch 2/64 loss: 0.22395837306976318
Batch 3/64 loss: 0.22975444793701172
Batch 4/64 loss: 0.22970986366271973
Batch 5/64 loss: 0.22436821460723877
Batch 6/64 loss: 0.2294224500656128
Batch 7/64 loss: 0.2232283353805542
Batch 8/64 loss: 0.2425316572189331
Batch 9/64 loss: 0.22894132137298584
Batch 10/64 loss: 0.23211008310317993
Batch 11/64 loss: 0.22174638509750366
Batch 12/64 loss: 0.2267856001853943
Batch 13/64 loss: 0.2343711256980896
Batch 14/64 loss: 0.2338864803314209
Batch 15/64 loss: 0.22991502285003662
Batch 16/64 loss: 0.23487114906311035
Batch 17/64 loss: 0.24190878868103027
Batch 18/64 loss: 0.2297879457473755
Batch 19/64 loss: 0.22881627082824707
Batch 20/64 loss: 0.2306615114212036
Batch 21/64 loss: 0.23706066608428955
Batch 22/64 loss: 0.22542130947113037
Batch 23/64 loss: 0.24002444744110107
Batch 24/64 loss: 0.2220761775970459
Batch 25/64 loss: 0.23680472373962402
Batch 26/64 loss: 0.22418493032455444
Batch 27/64 loss: 0.22903621196746826
Batch 28/64 loss: 0.23930102586746216
Batch 29/64 loss: 0.22578299045562744
Batch 30/64 loss: 0.2325071096420288
Batch 31/64 loss: 0.23133867979049683
Batch 32/64 loss: 0.21575552225112915
Batch 33/64 loss: 0.23681640625
Batch 34/64 loss: 0.22070026397705078
Batch 35/64 loss: 0.22400248050689697
Batch 36/64 loss: 0.2184610366821289
Batch 37/64 loss: 0.2302904725074768
Batch 38/64 loss: 0.2319873571395874
Batch 39/64 loss: 0.23760950565338135
Batch 40/64 loss: 0.23581218719482422
Batch 41/64 loss: 0.2277379035949707
Batch 42/64 loss: 0.22923237085342407
Batch 43/64 loss: 0.23156261444091797
Batch 44/64 loss: 0.2296733260154724
Batch 45/64 loss: 0.22579485177993774
Batch 46/64 loss: 0.23077088594436646
Batch 47/64 loss: 0.22975826263427734
Batch 48/64 loss: 0.23281532526016235
Batch 49/64 loss: 0.22823560237884521
Batch 50/64 loss: 0.2266523838043213
Batch 51/64 loss: 0.23108768463134766
Batch 52/64 loss: 0.22579026222229004
Batch 53/64 loss: 0.22076821327209473
Batch 54/64 loss: 0.2382909059524536
Batch 55/64 loss: 0.23146796226501465
Batch 56/64 loss: 0.24039876461029053
Batch 57/64 loss: 0.23775076866149902
Batch 58/64 loss: 0.22736704349517822
Batch 59/64 loss: 0.22487092018127441
Batch 60/64 loss: 0.23088842630386353
Batch 61/64 loss: 0.2338496446609497
Batch 62/64 loss: 0.24043583869934082
Batch 63/64 loss: 0.2263643741607666
Batch 64/64 loss: 0.22686368227005005
Epoch 272  Train loss: 0.23029144675123925  Val loss: 0.27045463266241593
Epoch 273
-------------------------------
Batch 1/64 loss: 0.22299468517303467
Batch 2/64 loss: 0.2215174436569214
Batch 3/64 loss: 0.2359561324119568
Batch 4/64 loss: 0.22931981086730957
Batch 5/64 loss: 0.23540908098220825
Batch 6/64 loss: 0.22859472036361694
Batch 7/64 loss: 0.23861372470855713
Batch 8/64 loss: 0.2241532802581787
Batch 9/64 loss: 0.22870928049087524
Batch 10/64 loss: 0.22781872749328613
Batch 11/64 loss: 0.22037231922149658
Batch 12/64 loss: 0.23543572425842285
Batch 13/64 loss: 0.2279699444770813
Batch 14/64 loss: 0.23521208763122559
Batch 15/64 loss: 0.22781336307525635
Batch 16/64 loss: 0.2368943691253662
Batch 17/64 loss: 0.22912776470184326
Batch 18/64 loss: 0.24340742826461792
Batch 19/64 loss: 0.2310495376586914
Batch 20/64 loss: 0.22951042652130127
Batch 21/64 loss: 0.22828638553619385
Batch 22/64 loss: 0.22734904289245605
Batch 23/64 loss: 0.22930878400802612
Batch 24/64 loss: 0.2362300157546997
Batch 25/64 loss: 0.22356116771697998
Batch 26/64 loss: 0.24029958248138428
Batch 27/64 loss: 0.23437070846557617
Batch 28/64 loss: 0.22795212268829346
Batch 29/64 loss: 0.2413041591644287
Batch 30/64 loss: 0.2324039340019226
Batch 31/64 loss: 0.22312688827514648
Batch 32/64 loss: 0.2285083532333374
Batch 33/64 loss: 0.22591054439544678
Batch 34/64 loss: 0.22786295413970947
Batch 35/64 loss: 0.2310084104537964
Batch 36/64 loss: 0.2390507459640503
Batch 37/64 loss: 0.2276221513748169
Batch 38/64 loss: 0.2396206259727478
Batch 39/64 loss: 0.2386322021484375
Batch 40/64 loss: 0.23240262269973755
Batch 41/64 loss: 0.23462915420532227
Batch 42/64 loss: 0.22885984182357788
Batch 43/64 loss: 0.2223779559135437
Batch 44/64 loss: 0.23061734437942505
Batch 45/64 loss: 0.23066437244415283
Batch 46/64 loss: 0.22511589527130127
Batch 47/64 loss: 0.23783737421035767
Batch 48/64 loss: 0.22515195608139038
Batch 49/64 loss: 0.23267483711242676
Batch 50/64 loss: 0.2324199676513672
Batch 51/64 loss: 0.23389720916748047
Batch 52/64 loss: 0.22726768255233765
Batch 53/64 loss: 0.23527806997299194
Batch 54/64 loss: 0.22976869344711304
Batch 55/64 loss: 0.22768902778625488
Batch 56/64 loss: 0.2332656979560852
Batch 57/64 loss: 0.23212909698486328
Batch 58/64 loss: 0.22031676769256592
Batch 59/64 loss: 0.2231684923171997
Batch 60/64 loss: 0.22367221117019653
Batch 61/64 loss: 0.22518867254257202
Batch 62/64 loss: 0.22421377897262573
Batch 63/64 loss: 0.22476816177368164
Batch 64/64 loss: 0.24528497457504272
Epoch 273  Train loss: 0.23042552541284  Val loss: 0.26984288643315896
Saving best model, epoch: 273
Epoch 274
-------------------------------
Batch 1/64 loss: 0.23467588424682617
Batch 2/64 loss: 0.2304595708847046
Batch 3/64 loss: 0.22881603240966797
Batch 4/64 loss: 0.23582136631011963
Batch 5/64 loss: 0.24322259426116943
Batch 6/64 loss: 0.22764742374420166
Batch 7/64 loss: 0.22486668825149536
Batch 8/64 loss: 0.22786253690719604
Batch 9/64 loss: 0.22937631607055664
Batch 10/64 loss: 0.22771620750427246
Batch 11/64 loss: 0.22478210926055908
Batch 12/64 loss: 0.21824896335601807
Batch 13/64 loss: 0.22550535202026367
Batch 14/64 loss: 0.22305166721343994
Batch 15/64 loss: 0.22003507614135742
Batch 16/64 loss: 0.22826135158538818
Batch 17/64 loss: 0.22638219594955444
Batch 18/64 loss: 0.22328495979309082
Batch 19/64 loss: 0.22644978761672974
Batch 20/64 loss: 0.2330838441848755
Batch 21/64 loss: 0.22469717264175415
Batch 22/64 loss: 0.22749292850494385
Batch 23/64 loss: 0.23455405235290527
Batch 24/64 loss: 0.2388635277748108
Batch 25/64 loss: 0.22878479957580566
Batch 26/64 loss: 0.2324603796005249
Batch 27/64 loss: 0.23092925548553467
Batch 28/64 loss: 0.21962523460388184
Batch 29/64 loss: 0.22456085681915283
Batch 30/64 loss: 0.23395276069641113
Batch 31/64 loss: 0.23097115755081177
Batch 32/64 loss: 0.23015141487121582
Batch 33/64 loss: 0.22528988122940063
Batch 34/64 loss: 0.22353851795196533
Batch 35/64 loss: 0.22549086809158325
Batch 36/64 loss: 0.22766125202178955
Batch 37/64 loss: 0.24063736200332642
Batch 38/64 loss: 0.22711431980133057
Batch 39/64 loss: 0.23060214519500732
Batch 40/64 loss: 0.22224092483520508
Batch 41/64 loss: 0.22620266675949097
Batch 42/64 loss: 0.24741458892822266
Batch 43/64 loss: 0.22999250888824463
Batch 44/64 loss: 0.23609590530395508
Batch 45/64 loss: 0.22370803356170654
Batch 46/64 loss: 0.23280870914459229
Batch 47/64 loss: 0.22512829303741455
Batch 48/64 loss: 0.23060375452041626
Batch 49/64 loss: 0.23045331239700317
Batch 50/64 loss: 0.2469029426574707
Batch 51/64 loss: 0.22189325094223022
Batch 52/64 loss: 0.23775124549865723
Batch 53/64 loss: 0.2302781343460083
Batch 54/64 loss: 0.24087285995483398
Batch 55/64 loss: 0.23403429985046387
Batch 56/64 loss: 0.224817156791687
Batch 57/64 loss: 0.2278447151184082
Batch 58/64 loss: 0.22446668148040771
Batch 59/64 loss: 0.23137450218200684
Batch 60/64 loss: 0.23180806636810303
Batch 61/64 loss: 0.23074054718017578
Batch 62/64 loss: 0.2311614751815796
Batch 63/64 loss: 0.23362505435943604
Batch 64/64 loss: 0.24194878339767456
Epoch 274  Train loss: 0.22981347500109206  Val loss: 0.2702436250509675
Epoch 275
-------------------------------
Batch 1/64 loss: 0.23406445980072021
Batch 2/64 loss: 0.23073989152908325
Batch 3/64 loss: 0.22700023651123047
Batch 4/64 loss: 0.23103058338165283
Batch 5/64 loss: 0.23104840517044067
Batch 6/64 loss: 0.2264319658279419
Batch 7/64 loss: 0.21753358840942383
Batch 8/64 loss: 0.23451614379882812
Batch 9/64 loss: 0.2339174747467041
Batch 10/64 loss: 0.23011565208435059
Batch 11/64 loss: 0.2216365933418274
Batch 12/64 loss: 0.2277061939239502
Batch 13/64 loss: 0.23613107204437256
Batch 14/64 loss: 0.22896498441696167
Batch 15/64 loss: 0.22225069999694824
Batch 16/64 loss: 0.2290460467338562
Batch 17/64 loss: 0.22069907188415527
Batch 18/64 loss: 0.22053974866867065
Batch 19/64 loss: 0.227036714553833
Batch 20/64 loss: 0.22150319814682007
Batch 21/64 loss: 0.22553038597106934
Batch 22/64 loss: 0.22653347253799438
Batch 23/64 loss: 0.2326817512512207
Batch 24/64 loss: 0.23782336711883545
Batch 25/64 loss: 0.2256031036376953
Batch 26/64 loss: 0.22571426630020142
Batch 27/64 loss: 0.22847628593444824
Batch 28/64 loss: 0.2361607551574707
Batch 29/64 loss: 0.2243211269378662
Batch 30/64 loss: 0.22817260026931763
Batch 31/64 loss: 0.243050217628479
Batch 32/64 loss: 0.22704356908798218
Batch 33/64 loss: 0.2278217077255249
Batch 34/64 loss: 0.23349112272262573
Batch 35/64 loss: 0.23712033033370972
Batch 36/64 loss: 0.22790926694869995
Batch 37/64 loss: 0.2284940481185913
Batch 38/64 loss: 0.2208939790725708
Batch 39/64 loss: 0.22952890396118164
Batch 40/64 loss: 0.22612428665161133
Batch 41/64 loss: 0.22459256649017334
Batch 42/64 loss: 0.22429317235946655
Batch 43/64 loss: 0.2273939847946167
Batch 44/64 loss: 0.2291942834854126
Batch 45/64 loss: 0.22575098276138306
Batch 46/64 loss: 0.23153376579284668
Batch 47/64 loss: 0.23212838172912598
Batch 48/64 loss: 0.22293460369110107
Batch 49/64 loss: 0.2258509397506714
Batch 50/64 loss: 0.23257821798324585
Batch 51/64 loss: 0.22606563568115234
Batch 52/64 loss: 0.23277372121810913
Batch 53/64 loss: 0.23925256729125977
Batch 54/64 loss: 0.23135483264923096
Batch 55/64 loss: 0.2269079089164734
Batch 56/64 loss: 0.22511744499206543
Batch 57/64 loss: 0.23017168045043945
Batch 58/64 loss: 0.2401403784751892
Batch 59/64 loss: 0.23087668418884277
Batch 60/64 loss: 0.23042404651641846
Batch 61/64 loss: 0.235137939453125
Batch 62/64 loss: 0.23863685131072998
Batch 63/64 loss: 0.2283264398574829
Batch 64/64 loss: 0.24047458171844482
Epoch 275  Train loss: 0.22927372923084333  Val loss: 0.27069331526346635
Epoch 276
-------------------------------
Batch 1/64 loss: 0.22367262840270996
Batch 2/64 loss: 0.23022156953811646
Batch 3/64 loss: 0.2327398657798767
Batch 4/64 loss: 0.23154282569885254
Batch 5/64 loss: 0.22574782371520996
Batch 6/64 loss: 0.23784136772155762
Batch 7/64 loss: 0.23583799600601196
Batch 8/64 loss: 0.23129719495773315
Batch 9/64 loss: 0.22821664810180664
Batch 10/64 loss: 0.2395886778831482
Batch 11/64 loss: 0.22739779949188232
Batch 12/64 loss: 0.231425940990448
Batch 13/64 loss: 0.22378206253051758
Batch 14/64 loss: 0.22741210460662842
Batch 15/64 loss: 0.22814446687698364
Batch 16/64 loss: 0.21848464012145996
Batch 17/64 loss: 0.24130356311798096
Batch 18/64 loss: 0.22889602184295654
Batch 19/64 loss: 0.22989606857299805
Batch 20/64 loss: 0.2342461347579956
Batch 21/64 loss: 0.2172790765762329
Batch 22/64 loss: 0.2304476499557495
Batch 23/64 loss: 0.22480732202529907
Batch 24/64 loss: 0.22005152702331543
Batch 25/64 loss: 0.2282232642173767
Batch 26/64 loss: 0.21700775623321533
Batch 27/64 loss: 0.22981733083724976
Batch 28/64 loss: 0.2380555272102356
Batch 29/64 loss: 0.2205437421798706
Batch 30/64 loss: 0.22888851165771484
Batch 31/64 loss: 0.23902755975723267
Batch 32/64 loss: 0.22532600164413452
Batch 33/64 loss: 0.2241382598876953
Batch 34/64 loss: 0.23520666360855103
Batch 35/64 loss: 0.22965383529663086
Batch 36/64 loss: 0.223175048828125
Batch 37/64 loss: 0.2314167618751526
Batch 38/64 loss: 0.21750962734222412
Batch 39/64 loss: 0.2234666347503662
Batch 40/64 loss: 0.22483479976654053
Batch 41/64 loss: 0.22657155990600586
Batch 42/64 loss: 0.2176918387413025
Batch 43/64 loss: 0.22947931289672852
Batch 44/64 loss: 0.22441339492797852
Batch 45/64 loss: 0.23190736770629883
Batch 46/64 loss: 0.23852980136871338
Batch 47/64 loss: 0.2294001579284668
Batch 48/64 loss: 0.23779445886611938
Batch 49/64 loss: 0.2352684736251831
Batch 50/64 loss: 0.2385096549987793
Batch 51/64 loss: 0.22953617572784424
Batch 52/64 loss: 0.22592294216156006
Batch 53/64 loss: 0.24530577659606934
Batch 54/64 loss: 0.23767411708831787
Batch 55/64 loss: 0.22317492961883545
Batch 56/64 loss: 0.24154740571975708
Batch 57/64 loss: 0.22173559665679932
Batch 58/64 loss: 0.23453128337860107
Batch 59/64 loss: 0.23474693298339844
Batch 60/64 loss: 0.22322237491607666
Batch 61/64 loss: 0.2251451015472412
Batch 62/64 loss: 0.2366797924041748
Batch 63/64 loss: 0.2254774570465088
Batch 64/64 loss: 0.22994357347488403
Epoch 276  Train loss: 0.22938503354203468  Val loss: 0.26963396641806636
Saving best model, epoch: 276
Epoch 277
-------------------------------
Batch 1/64 loss: 0.23030030727386475
Batch 2/64 loss: 0.22787690162658691
Batch 3/64 loss: 0.23238003253936768
Batch 4/64 loss: 0.2208271026611328
Batch 5/64 loss: 0.22723454236984253
Batch 6/64 loss: 0.23139739036560059
Batch 7/64 loss: 0.2250840663909912
Batch 8/64 loss: 0.22534984350204468
Batch 9/64 loss: 0.2279301881790161
Batch 10/64 loss: 0.22464847564697266
Batch 11/64 loss: 0.23222458362579346
Batch 12/64 loss: 0.22934889793395996
Batch 13/64 loss: 0.2308996319770813
Batch 14/64 loss: 0.2396399974822998
Batch 15/64 loss: 0.23534059524536133
Batch 16/64 loss: 0.22312915325164795
Batch 17/64 loss: 0.2275436520576477
Batch 18/64 loss: 0.23397761583328247
Batch 19/64 loss: 0.2270752191543579
Batch 20/64 loss: 0.22490620613098145
Batch 21/64 loss: 0.22887498140335083
Batch 22/64 loss: 0.2256704568862915
Batch 23/64 loss: 0.2362491488456726
Batch 24/64 loss: 0.21858203411102295
Batch 25/64 loss: 0.2302643060684204
Batch 26/64 loss: 0.23343771696090698
Batch 27/64 loss: 0.22259879112243652
Batch 28/64 loss: 0.23320287466049194
Batch 29/64 loss: 0.22374486923217773
Batch 30/64 loss: 0.22628003358840942
Batch 31/64 loss: 0.21921569108963013
Batch 32/64 loss: 0.2298944592475891
Batch 33/64 loss: 0.22493666410446167
Batch 34/64 loss: 0.22490519285202026
Batch 35/64 loss: 0.2262648344039917
Batch 36/64 loss: 0.23123770952224731
Batch 37/64 loss: 0.22301125526428223
Batch 38/64 loss: 0.22756534814834595
Batch 39/64 loss: 0.23081791400909424
Batch 40/64 loss: 0.22273433208465576
Batch 41/64 loss: 0.23236000537872314
Batch 42/64 loss: 0.21640175580978394
Batch 43/64 loss: 0.23052215576171875
Batch 44/64 loss: 0.2343490719795227
Batch 45/64 loss: 0.22716248035430908
Batch 46/64 loss: 0.22313964366912842
Batch 47/64 loss: 0.22284352779388428
Batch 48/64 loss: 0.234175443649292
Batch 49/64 loss: 0.22091370820999146
Batch 50/64 loss: 0.239935040473938
Batch 51/64 loss: 0.22862231731414795
Batch 52/64 loss: 0.25624752044677734
Batch 53/64 loss: 0.23891091346740723
Batch 54/64 loss: 0.22175443172454834
Batch 55/64 loss: 0.22068333625793457
Batch 56/64 loss: 0.23550152778625488
Batch 57/64 loss: 0.2372112274169922
Batch 58/64 loss: 0.23468685150146484
Batch 59/64 loss: 0.22853702306747437
Batch 60/64 loss: 0.2274085283279419
Batch 61/64 loss: 0.22259390354156494
Batch 62/64 loss: 0.2304355502128601
Batch 63/64 loss: 0.2223806381225586
Batch 64/64 loss: 0.22201824188232422
Epoch 277  Train loss: 0.22854734589071835  Val loss: 0.2699356673099741
Epoch 278
-------------------------------
Batch 1/64 loss: 0.23475021123886108
Batch 2/64 loss: 0.22937476634979248
Batch 3/64 loss: 0.23648715019226074
Batch 4/64 loss: 0.21496599912643433
Batch 5/64 loss: 0.230322003364563
Batch 6/64 loss: 0.2345198392868042
Batch 7/64 loss: 0.2269611954689026
Batch 8/64 loss: 0.23975419998168945
Batch 9/64 loss: 0.2334580421447754
Batch 10/64 loss: 0.23228907585144043
Batch 11/64 loss: 0.2258821725845337
Batch 12/64 loss: 0.23056936264038086
Batch 13/64 loss: 0.22488200664520264
Batch 14/64 loss: 0.2303001880645752
Batch 15/64 loss: 0.2255781888961792
Batch 16/64 loss: 0.22998392581939697
Batch 17/64 loss: 0.22554939985275269
Batch 18/64 loss: 0.2298041582107544
Batch 19/64 loss: 0.2212572693824768
Batch 20/64 loss: 0.2361961007118225
Batch 21/64 loss: 0.2322891354560852
Batch 22/64 loss: 0.22614991664886475
Batch 23/64 loss: 0.22765612602233887
Batch 24/64 loss: 0.2267928123474121
Batch 25/64 loss: 0.24366366863250732
Batch 26/64 loss: 0.2285928726196289
Batch 27/64 loss: 0.22507452964782715
Batch 28/64 loss: 0.22570502758026123
Batch 29/64 loss: 0.22517645359039307
Batch 30/64 loss: 0.22688984870910645
Batch 31/64 loss: 0.21813321113586426
Batch 32/64 loss: 0.2282872200012207
Batch 33/64 loss: 0.2348790168762207
Batch 34/64 loss: 0.22741985321044922
Batch 35/64 loss: 0.23958474397659302
Batch 36/64 loss: 0.23074209690093994
Batch 37/64 loss: 0.2281869649887085
Batch 38/64 loss: 0.23511338233947754
Batch 39/64 loss: 0.23039686679840088
Batch 40/64 loss: 0.22135591506958008
Batch 41/64 loss: 0.22688913345336914
Batch 42/64 loss: 0.2261335849761963
Batch 43/64 loss: 0.22324329614639282
Batch 44/64 loss: 0.22986465692520142
Batch 45/64 loss: 0.22976964712142944
Batch 46/64 loss: 0.2327810525894165
Batch 47/64 loss: 0.22855126857757568
Batch 48/64 loss: 0.2268393635749817
Batch 49/64 loss: 0.23023617267608643
Batch 50/64 loss: 0.2392275333404541
Batch 51/64 loss: 0.22683429718017578
Batch 52/64 loss: 0.23097646236419678
Batch 53/64 loss: 0.23702776432037354
Batch 54/64 loss: 0.23765802383422852
Batch 55/64 loss: 0.22909307479858398
Batch 56/64 loss: 0.2291545867919922
Batch 57/64 loss: 0.22334688901901245
Batch 58/64 loss: 0.22535920143127441
Batch 59/64 loss: 0.24119949340820312
Batch 60/64 loss: 0.2200155258178711
Batch 61/64 loss: 0.22971534729003906
Batch 62/64 loss: 0.22959262132644653
Batch 63/64 loss: 0.2318994402885437
Batch 64/64 loss: 0.2290581464767456
Epoch 278  Train loss: 0.2295243445564719  Val loss: 0.27032468450028463
Epoch 279
-------------------------------
Batch 1/64 loss: 0.2232683300971985
Batch 2/64 loss: 0.22693997621536255
Batch 3/64 loss: 0.23987632989883423
Batch 4/64 loss: 0.22773277759552002
Batch 5/64 loss: 0.22747516632080078
Batch 6/64 loss: 0.22814500331878662
Batch 7/64 loss: 0.2204364538192749
Batch 8/64 loss: 0.23291635513305664
Batch 9/64 loss: 0.2214348316192627
Batch 10/64 loss: 0.22198855876922607
Batch 11/64 loss: 0.2354232668876648
Batch 12/64 loss: 0.23412227630615234
Batch 13/64 loss: 0.23299646377563477
Batch 14/64 loss: 0.2278580665588379
Batch 15/64 loss: 0.22966289520263672
Batch 16/64 loss: 0.22369205951690674
Batch 17/64 loss: 0.22391146421432495
Batch 18/64 loss: 0.22379815578460693
Batch 19/64 loss: 0.22459077835083008
Batch 20/64 loss: 0.2363489866256714
Batch 21/64 loss: 0.21490585803985596
Batch 22/64 loss: 0.2302941083908081
Batch 23/64 loss: 0.22589600086212158
Batch 24/64 loss: 0.22600984573364258
Batch 25/64 loss: 0.23614060878753662
Batch 26/64 loss: 0.24192774295806885
Batch 27/64 loss: 0.22050464153289795
Batch 28/64 loss: 0.22870516777038574
Batch 29/64 loss: 0.23111647367477417
Batch 30/64 loss: 0.23057180643081665
Batch 31/64 loss: 0.23575901985168457
Batch 32/64 loss: 0.22901248931884766
Batch 33/64 loss: 0.23554205894470215
Batch 34/64 loss: 0.22517096996307373
Batch 35/64 loss: 0.22856122255325317
Batch 36/64 loss: 0.23779511451721191
Batch 37/64 loss: 0.23719298839569092
Batch 38/64 loss: 0.2254878282546997
Batch 39/64 loss: 0.22347337007522583
Batch 40/64 loss: 0.22558754682540894
Batch 41/64 loss: 0.22121870517730713
Batch 42/64 loss: 0.22704726457595825
Batch 43/64 loss: 0.2355407476425171
Batch 44/64 loss: 0.2327643632888794
Batch 45/64 loss: 0.23318874835968018
Batch 46/64 loss: 0.2331334352493286
Batch 47/64 loss: 0.2178782820701599
Batch 48/64 loss: 0.23278653621673584
Batch 49/64 loss: 0.22868108749389648
Batch 50/64 loss: 0.2216043472290039
Batch 51/64 loss: 0.23145568370819092
Batch 52/64 loss: 0.2309485673904419
Batch 53/64 loss: 0.22970926761627197
Batch 54/64 loss: 0.22754907608032227
Batch 55/64 loss: 0.2335023283958435
Batch 56/64 loss: 0.22913670539855957
Batch 57/64 loss: 0.225716233253479
Batch 58/64 loss: 0.23085284233093262
Batch 59/64 loss: 0.23171687126159668
Batch 60/64 loss: 0.23977798223495483
Batch 61/64 loss: 0.23382091522216797
Batch 62/64 loss: 0.23101365566253662
Batch 63/64 loss: 0.22593528032302856
Batch 64/64 loss: 0.23285436630249023
Epoch 279  Train loss: 0.22920616093803856  Val loss: 0.2697968847563177
Epoch 280
-------------------------------
Batch 1/64 loss: 0.23119109869003296
Batch 2/64 loss: 0.2268444299697876
Batch 3/64 loss: 0.21592295169830322
Batch 4/64 loss: 0.22596150636672974
Batch 5/64 loss: 0.23166728019714355
Batch 6/64 loss: 0.23000359535217285
Batch 7/64 loss: 0.22100871801376343
Batch 8/64 loss: 0.23225706815719604
Batch 9/64 loss: 0.22616267204284668
Batch 10/64 loss: 0.237030029296875
Batch 11/64 loss: 0.2272505760192871
Batch 12/64 loss: 0.22565817832946777
Batch 13/64 loss: 0.22578835487365723
Batch 14/64 loss: 0.24115204811096191
Batch 15/64 loss: 0.2276173233985901
Batch 16/64 loss: 0.2256646752357483
Batch 17/64 loss: 0.2407466173171997
Batch 18/64 loss: 0.2289620041847229
Batch 19/64 loss: 0.22324764728546143
Batch 20/64 loss: 0.22637057304382324
Batch 21/64 loss: 0.22265851497650146
Batch 22/64 loss: 0.229658842086792
Batch 23/64 loss: 0.2242600917816162
Batch 24/64 loss: 0.21675562858581543
Batch 25/64 loss: 0.22928547859191895
Batch 26/64 loss: 0.2338070273399353
Batch 27/64 loss: 0.22464919090270996
Batch 28/64 loss: 0.23139721155166626
Batch 29/64 loss: 0.23441815376281738
Batch 30/64 loss: 0.2291882038116455
Batch 31/64 loss: 0.22428429126739502
Batch 32/64 loss: 0.223718523979187
Batch 33/64 loss: 0.22806131839752197
Batch 34/64 loss: 0.22403723001480103
Batch 35/64 loss: 0.21827304363250732
Batch 36/64 loss: 0.22926998138427734
Batch 37/64 loss: 0.2259078025817871
Batch 38/64 loss: 0.22576618194580078
Batch 39/64 loss: 0.2282201647758484
Batch 40/64 loss: 0.22555923461914062
Batch 41/64 loss: 0.2231830358505249
Batch 42/64 loss: 0.2269359827041626
Batch 43/64 loss: 0.2390679121017456
Batch 44/64 loss: 0.2230377197265625
Batch 45/64 loss: 0.23012644052505493
Batch 46/64 loss: 0.2373674511909485
Batch 47/64 loss: 0.24227362871170044
Batch 48/64 loss: 0.22521734237670898
Batch 49/64 loss: 0.23163330554962158
Batch 50/64 loss: 0.22257888317108154
Batch 51/64 loss: 0.2320648431777954
Batch 52/64 loss: 0.22800755500793457
Batch 53/64 loss: 0.23121458292007446
Batch 54/64 loss: 0.2303457260131836
Batch 55/64 loss: 0.22072923183441162
Batch 56/64 loss: 0.22907394170761108
Batch 57/64 loss: 0.23121464252471924
Batch 58/64 loss: 0.22884654998779297
Batch 59/64 loss: 0.21742719411849976
Batch 60/64 loss: 0.23273998498916626
Batch 61/64 loss: 0.22862547636032104
Batch 62/64 loss: 0.22589260339736938
Batch 63/64 loss: 0.23606908321380615
Batch 64/64 loss: 0.23263299465179443
Epoch 280  Train loss: 0.2282012757133035  Val loss: 0.2725824234411888
Epoch 281
-------------------------------
Batch 1/64 loss: 0.22595179080963135
Batch 2/64 loss: 0.22857946157455444
Batch 3/64 loss: 0.22456610202789307
Batch 4/64 loss: 0.2297276258468628
Batch 5/64 loss: 0.23479944467544556
Batch 6/64 loss: 0.21947050094604492
Batch 7/64 loss: 0.22754162549972534
Batch 8/64 loss: 0.23178690671920776
Batch 9/64 loss: 0.22548741102218628
Batch 10/64 loss: 0.23074489831924438
Batch 11/64 loss: 0.2255481481552124
Batch 12/64 loss: 0.2326514720916748
Batch 13/64 loss: 0.22538971900939941
Batch 14/64 loss: 0.23468327522277832
Batch 15/64 loss: 0.23372691869735718
Batch 16/64 loss: 0.22446465492248535
Batch 17/64 loss: 0.22656476497650146
Batch 18/64 loss: 0.22300010919570923
Batch 19/64 loss: 0.22015249729156494
Batch 20/64 loss: 0.21930909156799316
Batch 21/64 loss: 0.22662824392318726
Batch 22/64 loss: 0.22249794006347656
Batch 23/64 loss: 0.22795408964157104
Batch 24/64 loss: 0.23341143131256104
Batch 25/64 loss: 0.22993850708007812
Batch 26/64 loss: 0.2256675362586975
Batch 27/64 loss: 0.2291269302368164
Batch 28/64 loss: 0.2305891513824463
Batch 29/64 loss: 0.22854399681091309
Batch 30/64 loss: 0.22811627388000488
Batch 31/64 loss: 0.22068941593170166
Batch 32/64 loss: 0.2253684401512146
Batch 33/64 loss: 0.22730952501296997
Batch 34/64 loss: 0.22805637121200562
Batch 35/64 loss: 0.2338605523109436
Batch 36/64 loss: 0.22445940971374512
Batch 37/64 loss: 0.22709721326828003
Batch 38/64 loss: 0.23572540283203125
Batch 39/64 loss: 0.23407483100891113
Batch 40/64 loss: 0.22881591320037842
Batch 41/64 loss: 0.22156476974487305
Batch 42/64 loss: 0.22315728664398193
Batch 43/64 loss: 0.23887741565704346
Batch 44/64 loss: 0.2287759780883789
Batch 45/64 loss: 0.23010778427124023
Batch 46/64 loss: 0.23026812076568604
Batch 47/64 loss: 0.2252899408340454
Batch 48/64 loss: 0.22421908378601074
Batch 49/64 loss: 0.23216724395751953
Batch 50/64 loss: 0.22904515266418457
Batch 51/64 loss: 0.23865967988967896
Batch 52/64 loss: 0.23005461692810059
Batch 53/64 loss: 0.23001337051391602
Batch 54/64 loss: 0.23003244400024414
Batch 55/64 loss: 0.23018866777420044
Batch 56/64 loss: 0.23366302251815796
Batch 57/64 loss: 0.2289295196533203
Batch 58/64 loss: 0.22604161500930786
Batch 59/64 loss: 0.22810935974121094
Batch 60/64 loss: 0.22851979732513428
Batch 61/64 loss: 0.2416517734527588
Batch 62/64 loss: 0.23787164688110352
Batch 63/64 loss: 0.2198789119720459
Batch 64/64 loss: 0.22684258222579956
Epoch 281  Train loss: 0.2285379879614886  Val loss: 0.2708574101277643
Epoch 282
-------------------------------
Batch 1/64 loss: 0.22838592529296875
Batch 2/64 loss: 0.22396087646484375
Batch 3/64 loss: 0.2244088053703308
Batch 4/64 loss: 0.22614073753356934
Batch 5/64 loss: 0.22756922245025635
Batch 6/64 loss: 0.2265351414680481
Batch 7/64 loss: 0.22212642431259155
Batch 8/64 loss: 0.2365623116493225
Batch 9/64 loss: 0.23121637105941772
Batch 10/64 loss: 0.22773021459579468
Batch 11/64 loss: 0.2234196662902832
Batch 12/64 loss: 0.23144817352294922
Batch 13/64 loss: 0.2258368730545044
Batch 14/64 loss: 0.21890926361083984
Batch 15/64 loss: 0.22635865211486816
Batch 16/64 loss: 0.22914791107177734
Batch 17/64 loss: 0.23445671796798706
Batch 18/64 loss: 0.21945136785507202
Batch 19/64 loss: 0.2262020707130432
Batch 20/64 loss: 0.23096919059753418
Batch 21/64 loss: 0.22370898723602295
Batch 22/64 loss: 0.232599139213562
Batch 23/64 loss: 0.22637397050857544
Batch 24/64 loss: 0.24210894107818604
Batch 25/64 loss: 0.22337329387664795
Batch 26/64 loss: 0.23216569423675537
Batch 27/64 loss: 0.22973018884658813
Batch 28/64 loss: 0.23560363054275513
Batch 29/64 loss: 0.23208987712860107
Batch 30/64 loss: 0.22277557849884033
Batch 31/64 loss: 0.2368261218070984
Batch 32/64 loss: 0.2267087697982788
Batch 33/64 loss: 0.2189338207244873
Batch 34/64 loss: 0.2316220998764038
Batch 35/64 loss: 0.22102141380310059
Batch 36/64 loss: 0.22764325141906738
Batch 37/64 loss: 0.23028355836868286
Batch 38/64 loss: 0.22541660070419312
Batch 39/64 loss: 0.22479206323623657
Batch 40/64 loss: 0.2263779640197754
Batch 41/64 loss: 0.22155755758285522
Batch 42/64 loss: 0.2232820987701416
Batch 43/64 loss: 0.22969400882720947
Batch 44/64 loss: 0.23711907863616943
Batch 45/64 loss: 0.2268936038017273
Batch 46/64 loss: 0.23281407356262207
Batch 47/64 loss: 0.22455447912216187
Batch 48/64 loss: 0.23624718189239502
Batch 49/64 loss: 0.2215248942375183
Batch 50/64 loss: 0.22710084915161133
Batch 51/64 loss: 0.22281098365783691
Batch 52/64 loss: 0.2259892225265503
Batch 53/64 loss: 0.23137027025222778
Batch 54/64 loss: 0.22792690992355347
Batch 55/64 loss: 0.2222437858581543
Batch 56/64 loss: 0.23492801189422607
Batch 57/64 loss: 0.2309383749961853
Batch 58/64 loss: 0.2444661259651184
Batch 59/64 loss: 0.22909283638000488
Batch 60/64 loss: 0.22203314304351807
Batch 61/64 loss: 0.22783207893371582
Batch 62/64 loss: 0.22334212064743042
Batch 63/64 loss: 0.2324364185333252
Batch 64/64 loss: 0.2292478084564209
Epoch 282  Train loss: 0.2280647034738578  Val loss: 0.27033826985310033
Epoch 283
-------------------------------
Batch 1/64 loss: 0.22287440299987793
Batch 2/64 loss: 0.22700917720794678
Batch 3/64 loss: 0.22329652309417725
Batch 4/64 loss: 0.2273261547088623
Batch 5/64 loss: 0.22820156812667847
Batch 6/64 loss: 0.22160375118255615
Batch 7/64 loss: 0.22577160596847534
Batch 8/64 loss: 0.22810602188110352
Batch 9/64 loss: 0.23973405361175537
Batch 10/64 loss: 0.2151111364364624
Batch 11/64 loss: 0.23541265726089478
Batch 12/64 loss: 0.2240523099899292
Batch 13/64 loss: 0.22519809007644653
Batch 14/64 loss: 0.2288304567337036
Batch 15/64 loss: 0.23285508155822754
Batch 16/64 loss: 0.22214114665985107
Batch 17/64 loss: 0.22854238748550415
Batch 18/64 loss: 0.2205514907836914
Batch 19/64 loss: 0.22725200653076172
Batch 20/64 loss: 0.21925079822540283
Batch 21/64 loss: 0.21954131126403809
Batch 22/64 loss: 0.23082739114761353
Batch 23/64 loss: 0.22655904293060303
Batch 24/64 loss: 0.22600841522216797
Batch 25/64 loss: 0.22930908203125
Batch 26/64 loss: 0.2280382513999939
Batch 27/64 loss: 0.22827529907226562
Batch 28/64 loss: 0.22284340858459473
Batch 29/64 loss: 0.2181694507598877
Batch 30/64 loss: 0.22726792097091675
Batch 31/64 loss: 0.2259455919265747
Batch 32/64 loss: 0.2237338423728943
Batch 33/64 loss: 0.23288142681121826
Batch 34/64 loss: 0.2352297306060791
Batch 35/64 loss: 0.2182542085647583
Batch 36/64 loss: 0.22035139799118042
Batch 37/64 loss: 0.22291505336761475
Batch 38/64 loss: 0.22523152828216553
Batch 39/64 loss: 0.22033172845840454
Batch 40/64 loss: 0.22471046447753906
Batch 41/64 loss: 0.21464258432388306
Batch 42/64 loss: 0.2230515480041504
Batch 43/64 loss: 0.2228771448135376
Batch 44/64 loss: 0.2265331745147705
Batch 45/64 loss: 0.2251678705215454
Batch 46/64 loss: 0.22682452201843262
Batch 47/64 loss: 0.23811930418014526
Batch 48/64 loss: 0.2252410650253296
Batch 49/64 loss: 0.2205997109413147
Batch 50/64 loss: 0.2283550500869751
Batch 51/64 loss: 0.22650611400604248
Batch 52/64 loss: 0.22515654563903809
Batch 53/64 loss: 0.23178017139434814
Batch 54/64 loss: 0.2325814962387085
Batch 55/64 loss: 0.23398011922836304
Batch 56/64 loss: 0.23734009265899658
Batch 57/64 loss: 0.23139965534210205
Batch 58/64 loss: 0.22120416164398193
Batch 59/64 loss: 0.23155581951141357
Batch 60/64 loss: 0.22995519638061523
Batch 61/64 loss: 0.230796217918396
Batch 62/64 loss: 0.22922945022583008
Batch 63/64 loss: 0.22678744792938232
Batch 64/64 loss: 0.23646414279937744
Epoch 283  Train loss: 0.22661298723781811  Val loss: 0.2704235739314679
Epoch 284
-------------------------------
Batch 1/64 loss: 0.22632074356079102
Batch 2/64 loss: 0.22507786750793457
Batch 3/64 loss: 0.22803646326065063
Batch 4/64 loss: 0.2296208143234253
Batch 5/64 loss: 0.22981047630310059
Batch 6/64 loss: 0.22205257415771484
Batch 7/64 loss: 0.22219419479370117
Batch 8/64 loss: 0.22808468341827393
Batch 9/64 loss: 0.23014193773269653
Batch 10/64 loss: 0.22623419761657715
Batch 11/64 loss: 0.22686409950256348
Batch 12/64 loss: 0.2283036708831787
Batch 13/64 loss: 0.22530746459960938
Batch 14/64 loss: 0.2197403907775879
Batch 15/64 loss: 0.22075039148330688
Batch 16/64 loss: 0.2233126163482666
Batch 17/64 loss: 0.2335796356201172
Batch 18/64 loss: 0.22423791885375977
Batch 19/64 loss: 0.22733324766159058
Batch 20/64 loss: 0.2350541353225708
Batch 21/64 loss: 0.22610509395599365
Batch 22/64 loss: 0.23037654161453247
Batch 23/64 loss: 0.22117388248443604
Batch 24/64 loss: 0.23780697584152222
Batch 25/64 loss: 0.22648018598556519
Batch 26/64 loss: 0.21583253145217896
Batch 27/64 loss: 0.22936755418777466
Batch 28/64 loss: 0.23761147260665894
Batch 29/64 loss: 0.23487931489944458
Batch 30/64 loss: 0.2302950620651245
Batch 31/64 loss: 0.22719889879226685
Batch 32/64 loss: 0.22453486919403076
Batch 33/64 loss: 0.22424280643463135
Batch 34/64 loss: 0.22545462846755981
Batch 35/64 loss: 0.22157979011535645
Batch 36/64 loss: 0.23119032382965088
Batch 37/64 loss: 0.2310941219329834
Batch 38/64 loss: 0.22518199682235718
Batch 39/64 loss: 0.22731226682662964
Batch 40/64 loss: 0.23183727264404297
Batch 41/64 loss: 0.22029590606689453
Batch 42/64 loss: 0.22794890403747559
Batch 43/64 loss: 0.23518753051757812
Batch 44/64 loss: 0.2258995771408081
Batch 45/64 loss: 0.22660040855407715
Batch 46/64 loss: 0.2331380844116211
Batch 47/64 loss: 0.24237370491027832
Batch 48/64 loss: 0.23275887966156006
Batch 49/64 loss: 0.2201451063156128
Batch 50/64 loss: 0.22554171085357666
Batch 51/64 loss: 0.23109090328216553
Batch 52/64 loss: 0.23391425609588623
Batch 53/64 loss: 0.22677552700042725
Batch 54/64 loss: 0.2317134141921997
Batch 55/64 loss: 0.2227921485900879
Batch 56/64 loss: 0.22894823551177979
Batch 57/64 loss: 0.2293335199356079
Batch 58/64 loss: 0.22809910774230957
Batch 59/64 loss: 0.2300659418106079
Batch 60/64 loss: 0.222154438495636
Batch 61/64 loss: 0.22724217176437378
Batch 62/64 loss: 0.2213011384010315
Batch 63/64 loss: 0.22986215353012085
Batch 64/64 loss: 0.23407185077667236
Epoch 284  Train loss: 0.2277701924828922  Val loss: 0.2704501045528556
Epoch 285
-------------------------------
Batch 1/64 loss: 0.22533458471298218
Batch 2/64 loss: 0.23077178001403809
Batch 3/64 loss: 0.22419869899749756
Batch 4/64 loss: 0.22366541624069214
Batch 5/64 loss: 0.22108066082000732
Batch 6/64 loss: 0.2284720540046692
Batch 7/64 loss: 0.2363046407699585
Batch 8/64 loss: 0.23031187057495117
Batch 9/64 loss: 0.226021409034729
Batch 10/64 loss: 0.21654152870178223
Batch 11/64 loss: 0.22754836082458496
Batch 12/64 loss: 0.24184006452560425
Batch 13/64 loss: 0.22580093145370483
Batch 14/64 loss: 0.22157883644104004
Batch 15/64 loss: 0.22440791130065918
Batch 16/64 loss: 0.2365586757659912
Batch 17/64 loss: 0.21957576274871826
Batch 18/64 loss: 0.2337590456008911
Batch 19/64 loss: 0.2250104546546936
Batch 20/64 loss: 0.22862613201141357
Batch 21/64 loss: 0.23368507623672485
Batch 22/64 loss: 0.22219347953796387
Batch 23/64 loss: 0.23303020000457764
Batch 24/64 loss: 0.2242634892463684
Batch 25/64 loss: 0.22239506244659424
Batch 26/64 loss: 0.22898918390274048
Batch 27/64 loss: 0.22624701261520386
Batch 28/64 loss: 0.22982120513916016
Batch 29/64 loss: 0.22988343238830566
Batch 30/64 loss: 0.22244179248809814
Batch 31/64 loss: 0.23561078310012817
Batch 32/64 loss: 0.21834522485733032
Batch 33/64 loss: 0.22485041618347168
Batch 34/64 loss: 0.2253957986831665
Batch 35/64 loss: 0.23545163869857788
Batch 36/64 loss: 0.23269641399383545
Batch 37/64 loss: 0.2242579460144043
Batch 38/64 loss: 0.22634267807006836
Batch 39/64 loss: 0.2249506711959839
Batch 40/64 loss: 0.22865605354309082
Batch 41/64 loss: 0.2261238694190979
Batch 42/64 loss: 0.2287825345993042
Batch 43/64 loss: 0.22478240728378296
Batch 44/64 loss: 0.2466413974761963
Batch 45/64 loss: 0.23514914512634277
Batch 46/64 loss: 0.23154067993164062
Batch 47/64 loss: 0.22903668880462646
Batch 48/64 loss: 0.2245800495147705
Batch 49/64 loss: 0.22983431816101074
Batch 50/64 loss: 0.23305922746658325
Batch 51/64 loss: 0.23642265796661377
Batch 52/64 loss: 0.2236098051071167
Batch 53/64 loss: 0.22370433807373047
Batch 54/64 loss: 0.22483885288238525
Batch 55/64 loss: 0.22959864139556885
Batch 56/64 loss: 0.22165131568908691
Batch 57/64 loss: 0.2235206961631775
Batch 58/64 loss: 0.2239069938659668
Batch 59/64 loss: 0.2285659909248352
Batch 60/64 loss: 0.22575139999389648
Batch 61/64 loss: 0.24425888061523438
Batch 62/64 loss: 0.2250630259513855
Batch 63/64 loss: 0.2254195213317871
Batch 64/64 loss: 0.23146557807922363
Epoch 285  Train loss: 0.2280213019427131  Val loss: 0.26944806813374417
Saving best model, epoch: 285
Epoch 286
-------------------------------
Batch 1/64 loss: 0.2247222661972046
Batch 2/64 loss: 0.22803890705108643
Batch 3/64 loss: 0.2210882306098938
Batch 4/64 loss: 0.22341948747634888
Batch 5/64 loss: 0.22853189706802368
Batch 6/64 loss: 0.22535818815231323
Batch 7/64 loss: 0.22124218940734863
Batch 8/64 loss: 0.22698521614074707
Batch 9/64 loss: 0.2226879596710205
Batch 10/64 loss: 0.22626781463623047
Batch 11/64 loss: 0.22526800632476807
Batch 12/64 loss: 0.22182977199554443
Batch 13/64 loss: 0.22845971584320068
Batch 14/64 loss: 0.2203352451324463
Batch 15/64 loss: 0.21936357021331787
Batch 16/64 loss: 0.2370678186416626
Batch 17/64 loss: 0.22660738229751587
Batch 18/64 loss: 0.2201615571975708
Batch 19/64 loss: 0.22989052534103394
Batch 20/64 loss: 0.21963775157928467
Batch 21/64 loss: 0.22089743614196777
Batch 22/64 loss: 0.2267524003982544
Batch 23/64 loss: 0.2315288782119751
Batch 24/64 loss: 0.22041922807693481
Batch 25/64 loss: 0.2164825201034546
Batch 26/64 loss: 0.22461152076721191
Batch 27/64 loss: 0.2270268201828003
Batch 28/64 loss: 0.22426044940948486
Batch 29/64 loss: 0.22429513931274414
Batch 30/64 loss: 0.22954821586608887
Batch 31/64 loss: 0.23665452003479004
Batch 32/64 loss: 0.2216619849205017
Batch 33/64 loss: 0.22541576623916626
Batch 34/64 loss: 0.23928916454315186
Batch 35/64 loss: 0.22767174243927002
Batch 36/64 loss: 0.23655951023101807
Batch 37/64 loss: 0.23563021421432495
Batch 38/64 loss: 0.2333437204360962
Batch 39/64 loss: 0.21543818712234497
Batch 40/64 loss: 0.2254091501235962
Batch 41/64 loss: 0.22735798358917236
Batch 42/64 loss: 0.23438328504562378
Batch 43/64 loss: 0.21546131372451782
Batch 44/64 loss: 0.22257447242736816
Batch 45/64 loss: 0.22497814893722534
Batch 46/64 loss: 0.2305152416229248
Batch 47/64 loss: 0.23106884956359863
Batch 48/64 loss: 0.22413009405136108
Batch 49/64 loss: 0.2320253849029541
Batch 50/64 loss: 0.2241649627685547
Batch 51/64 loss: 0.23705506324768066
Batch 52/64 loss: 0.22223436832427979
Batch 53/64 loss: 0.22626006603240967
Batch 54/64 loss: 0.22739338874816895
Batch 55/64 loss: 0.2241278886795044
Batch 56/64 loss: 0.2248002290725708
Batch 57/64 loss: 0.22914505004882812
Batch 58/64 loss: 0.22570127248764038
Batch 59/64 loss: 0.23622679710388184
Batch 60/64 loss: 0.23872828483581543
Batch 61/64 loss: 0.22866058349609375
Batch 62/64 loss: 0.23426282405853271
Batch 63/64 loss: 0.2276235818862915
Batch 64/64 loss: 0.22411614656448364
Epoch 286  Train loss: 0.22677374610713885  Val loss: 0.2691636929397321
Saving best model, epoch: 286
Epoch 287
-------------------------------
Batch 1/64 loss: 0.2175489068031311
Batch 2/64 loss: 0.237942636013031
Batch 3/64 loss: 0.21778368949890137
Batch 4/64 loss: 0.21722912788391113
Batch 5/64 loss: 0.22651755809783936
Batch 6/64 loss: 0.22324693202972412
Batch 7/64 loss: 0.22360944747924805
Batch 8/64 loss: 0.22615545988082886
Batch 9/64 loss: 0.22771883010864258
Batch 10/64 loss: 0.24506372213363647
Batch 11/64 loss: 0.2175273895263672
Batch 12/64 loss: 0.22740548849105835
Batch 13/64 loss: 0.22780460119247437
Batch 14/64 loss: 0.22003871202468872
Batch 15/64 loss: 0.22887110710144043
Batch 16/64 loss: 0.23126482963562012
Batch 17/64 loss: 0.23550927639007568
Batch 18/64 loss: 0.22388017177581787
Batch 19/64 loss: 0.22043561935424805
Batch 20/64 loss: 0.23052728176116943
Batch 21/64 loss: 0.225632905960083
Batch 22/64 loss: 0.2235633134841919
Batch 23/64 loss: 0.2239149808883667
Batch 24/64 loss: 0.22507870197296143
Batch 25/64 loss: 0.23493045568466187
Batch 26/64 loss: 0.22542792558670044
Batch 27/64 loss: 0.23203277587890625
Batch 28/64 loss: 0.22168022394180298
Batch 29/64 loss: 0.2265242338180542
Batch 30/64 loss: 0.23894143104553223
Batch 31/64 loss: 0.22292208671569824
Batch 32/64 loss: 0.23536956310272217
Batch 33/64 loss: 0.220384418964386
Batch 34/64 loss: 0.23024755716323853
Batch 35/64 loss: 0.22887468338012695
Batch 36/64 loss: 0.23537349700927734
Batch 37/64 loss: 0.22219085693359375
Batch 38/64 loss: 0.23105883598327637
Batch 39/64 loss: 0.22728347778320312
Batch 40/64 loss: 0.23077309131622314
Batch 41/64 loss: 0.2320631742477417
Batch 42/64 loss: 0.228279709815979
Batch 43/64 loss: 0.23117387294769287
Batch 44/64 loss: 0.22319084405899048
Batch 45/64 loss: 0.2211294174194336
Batch 46/64 loss: 0.22861403226852417
Batch 47/64 loss: 0.22247672080993652
Batch 48/64 loss: 0.2258930802345276
Batch 49/64 loss: 0.22519975900650024
Batch 50/64 loss: 0.2295830249786377
Batch 51/64 loss: 0.23496884107589722
Batch 52/64 loss: 0.22833168506622314
Batch 53/64 loss: 0.22679460048675537
Batch 54/64 loss: 0.23321425914764404
Batch 55/64 loss: 0.23011302947998047
Batch 56/64 loss: 0.21844279766082764
Batch 57/64 loss: 0.22179806232452393
Batch 58/64 loss: 0.24050050973892212
Batch 59/64 loss: 0.23549258708953857
Batch 60/64 loss: 0.22883892059326172
Batch 61/64 loss: 0.22751259803771973
Batch 62/64 loss: 0.22590786218643188
Batch 63/64 loss: 0.22538787126541138
Batch 64/64 loss: 0.2295529842376709
Epoch 287  Train loss: 0.2275350243437524  Val loss: 0.27000015748735146
Epoch 288
-------------------------------
Batch 1/64 loss: 0.22326058149337769
Batch 2/64 loss: 0.22560834884643555
Batch 3/64 loss: 0.22209954261779785
Batch 4/64 loss: 0.22227966785430908
Batch 5/64 loss: 0.21817654371261597
Batch 6/64 loss: 0.22097909450531006
Batch 7/64 loss: 0.22848796844482422
Batch 8/64 loss: 0.222129225730896
Batch 9/64 loss: 0.22695958614349365
Batch 10/64 loss: 0.22614812850952148
Batch 11/64 loss: 0.22330564260482788
Batch 12/64 loss: 0.22163361310958862
Batch 13/64 loss: 0.22302937507629395
Batch 14/64 loss: 0.22458332777023315
Batch 15/64 loss: 0.23784369230270386
Batch 16/64 loss: 0.21872645616531372
Batch 17/64 loss: 0.22841894626617432
Batch 18/64 loss: 0.24369299411773682
Batch 19/64 loss: 0.2227649688720703
Batch 20/64 loss: 0.22540342807769775
Batch 21/64 loss: 0.22335052490234375
Batch 22/64 loss: 0.22020673751831055
Batch 23/64 loss: 0.22182786464691162
Batch 24/64 loss: 0.22765403985977173
Batch 25/64 loss: 0.22415828704833984
Batch 26/64 loss: 0.22821319103240967
Batch 27/64 loss: 0.22531110048294067
Batch 28/64 loss: 0.22330135107040405
Batch 29/64 loss: 0.2282581329345703
Batch 30/64 loss: 0.2330693006515503
Batch 31/64 loss: 0.2267436981201172
Batch 32/64 loss: 0.22342240810394287
Batch 33/64 loss: 0.22898036241531372
Batch 34/64 loss: 0.22494947910308838
Batch 35/64 loss: 0.22968947887420654
Batch 36/64 loss: 0.2271556854248047
Batch 37/64 loss: 0.22844815254211426
Batch 38/64 loss: 0.22819340229034424
Batch 39/64 loss: 0.23300719261169434
Batch 40/64 loss: 0.2225624918937683
Batch 41/64 loss: 0.22898375988006592
Batch 42/64 loss: 0.22016477584838867
Batch 43/64 loss: 0.22515463829040527
Batch 44/64 loss: 0.22288298606872559
Batch 45/64 loss: 0.22103142738342285
Batch 46/64 loss: 0.22576630115509033
Batch 47/64 loss: 0.22840797901153564
Batch 48/64 loss: 0.23183757066726685
Batch 49/64 loss: 0.22583162784576416
Batch 50/64 loss: 0.22157692909240723
Batch 51/64 loss: 0.22600185871124268
Batch 52/64 loss: 0.22607910633087158
Batch 53/64 loss: 0.22635173797607422
Batch 54/64 loss: 0.2220141887664795
Batch 55/64 loss: 0.22017455101013184
Batch 56/64 loss: 0.230152428150177
Batch 57/64 loss: 0.22509801387786865
Batch 58/64 loss: 0.22313594818115234
Batch 59/64 loss: 0.21967196464538574
Batch 60/64 loss: 0.224073588848114
Batch 61/64 loss: 0.23623108863830566
Batch 62/64 loss: 0.23234063386917114
Batch 63/64 loss: 0.22631287574768066
Batch 64/64 loss: 0.22460055351257324
Epoch 288  Train loss: 0.22575310445299335  Val loss: 0.27126667220977574
Epoch 289
-------------------------------
Batch 1/64 loss: 0.22373038530349731
Batch 2/64 loss: 0.2225203514099121
Batch 3/64 loss: 0.22192412614822388
Batch 4/64 loss: 0.2375781536102295
Batch 5/64 loss: 0.22294890880584717
Batch 6/64 loss: 0.2335999608039856
Batch 7/64 loss: 0.22247916460037231
Batch 8/64 loss: 0.2192811369895935
Batch 9/64 loss: 0.22870957851409912
Batch 10/64 loss: 0.22980201244354248
Batch 11/64 loss: 0.2333117127418518
Batch 12/64 loss: 0.23022079467773438
Batch 13/64 loss: 0.2400645613670349
Batch 14/64 loss: 0.23319792747497559
Batch 15/64 loss: 0.23109328746795654
Batch 16/64 loss: 0.2249774932861328
Batch 17/64 loss: 0.23341000080108643
Batch 18/64 loss: 0.23105812072753906
Batch 19/64 loss: 0.22263610363006592
Batch 20/64 loss: 0.22884225845336914
Batch 21/64 loss: 0.23181378841400146
Batch 22/64 loss: 0.2267528772354126
Batch 23/64 loss: 0.22584301233291626
Batch 24/64 loss: 0.22075271606445312
Batch 25/64 loss: 0.22939640283584595
Batch 26/64 loss: 0.223344624042511
Batch 27/64 loss: 0.22750794887542725
Batch 28/64 loss: 0.22485065460205078
Batch 29/64 loss: 0.2308412790298462
Batch 30/64 loss: 0.22491466999053955
Batch 31/64 loss: 0.22679293155670166
Batch 32/64 loss: 0.22514116764068604
Batch 33/64 loss: 0.2272639274597168
Batch 34/64 loss: 0.23297971487045288
Batch 35/64 loss: 0.2313917875289917
Batch 36/64 loss: 0.22535157203674316
Batch 37/64 loss: 0.22460031509399414
Batch 38/64 loss: 0.2268352508544922
Batch 39/64 loss: 0.2237555980682373
Batch 40/64 loss: 0.21927976608276367
Batch 41/64 loss: 0.23445284366607666
Batch 42/64 loss: 0.22889715433120728
Batch 43/64 loss: 0.22216784954071045
Batch 44/64 loss: 0.21715062856674194
Batch 45/64 loss: 0.21647024154663086
Batch 46/64 loss: 0.224981427192688
Batch 47/64 loss: 0.2232261300086975
Batch 48/64 loss: 0.21842610836029053
Batch 49/64 loss: 0.23266452550888062
Batch 50/64 loss: 0.2203364372253418
Batch 51/64 loss: 0.2263268232345581
Batch 52/64 loss: 0.22982686758041382
Batch 53/64 loss: 0.21988821029663086
Batch 54/64 loss: 0.23752069473266602
Batch 55/64 loss: 0.23143470287322998
Batch 56/64 loss: 0.232000470161438
Batch 57/64 loss: 0.21754181385040283
Batch 58/64 loss: 0.2261286973953247
Batch 59/64 loss: 0.23195046186447144
Batch 60/64 loss: 0.2208428978919983
Batch 61/64 loss: 0.22601479291915894
Batch 62/64 loss: 0.22615844011306763
Batch 63/64 loss: 0.22260022163391113
Batch 64/64 loss: 0.23313021659851074
Epoch 289  Train loss: 0.22686513171476477  Val loss: 0.27043929235222414
Epoch 290
-------------------------------
Batch 1/64 loss: 0.21860510110855103
Batch 2/64 loss: 0.22158348560333252
Batch 3/64 loss: 0.2227610945701599
Batch 4/64 loss: 0.22876346111297607
Batch 5/64 loss: 0.2181485891342163
Batch 6/64 loss: 0.2325451374053955
Batch 7/64 loss: 0.22124332189559937
Batch 8/64 loss: 0.21214306354522705
Batch 9/64 loss: 0.2264421582221985
Batch 10/64 loss: 0.21948260068893433
Batch 11/64 loss: 0.22570621967315674
Batch 12/64 loss: 0.22685837745666504
Batch 13/64 loss: 0.2132856845855713
Batch 14/64 loss: 0.22060924768447876
Batch 15/64 loss: 0.22322505712509155
Batch 16/64 loss: 0.22969162464141846
Batch 17/64 loss: 0.23096096515655518
Batch 18/64 loss: 0.24214810132980347
Batch 19/64 loss: 0.22183871269226074
Batch 20/64 loss: 0.22662729024887085
Batch 21/64 loss: 0.22892266511917114
Batch 22/64 loss: 0.22958755493164062
Batch 23/64 loss: 0.2270272970199585
Batch 24/64 loss: 0.23343539237976074
Batch 25/64 loss: 0.25062650442123413
Batch 26/64 loss: 0.23308277130126953
Batch 27/64 loss: 0.21693098545074463
Batch 28/64 loss: 0.22280895709991455
Batch 29/64 loss: 0.2232401967048645
Batch 30/64 loss: 0.22566181421279907
Batch 31/64 loss: 0.2227323055267334
Batch 32/64 loss: 0.22645992040634155
Batch 33/64 loss: 0.22511333227157593
Batch 34/64 loss: 0.22500348091125488
Batch 35/64 loss: 0.23426878452301025
Batch 36/64 loss: 0.23469030857086182
Batch 37/64 loss: 0.22885459661483765
Batch 38/64 loss: 0.22644120454788208
Batch 39/64 loss: 0.22496867179870605
Batch 40/64 loss: 0.22489076852798462
Batch 41/64 loss: 0.22845196723937988
Batch 42/64 loss: 0.22541987895965576
Batch 43/64 loss: 0.2321528196334839
Batch 44/64 loss: 0.23329609632492065
Batch 45/64 loss: 0.22799527645111084
Batch 46/64 loss: 0.22382640838623047
Batch 47/64 loss: 0.23415422439575195
Batch 48/64 loss: 0.22794830799102783
Batch 49/64 loss: 0.23228150606155396
Batch 50/64 loss: 0.22006267309188843
Batch 51/64 loss: 0.2346813678741455
Batch 52/64 loss: 0.23274743556976318
Batch 53/64 loss: 0.2321528196334839
Batch 54/64 loss: 0.2208625078201294
Batch 55/64 loss: 0.22977614402770996
Batch 56/64 loss: 0.2264190912246704
Batch 57/64 loss: 0.22226911783218384
Batch 58/64 loss: 0.2220231294631958
Batch 59/64 loss: 0.22154748439788818
Batch 60/64 loss: 0.22132456302642822
Batch 61/64 loss: 0.2324422001838684
Batch 62/64 loss: 0.21531081199645996
Batch 63/64 loss: 0.22603893280029297
Batch 64/64 loss: 0.22645360231399536
Epoch 290  Train loss: 0.22651673368379183  Val loss: 0.26907452029460893
Saving best model, epoch: 290
Epoch 291
-------------------------------
Batch 1/64 loss: 0.22597110271453857
Batch 2/64 loss: 0.22570085525512695
Batch 3/64 loss: 0.23080062866210938
Batch 4/64 loss: 0.21770989894866943
Batch 5/64 loss: 0.23700833320617676
Batch 6/64 loss: 0.23103785514831543
Batch 7/64 loss: 0.22337830066680908
Batch 8/64 loss: 0.21928036212921143
Batch 9/64 loss: 0.22032105922698975
Batch 10/64 loss: 0.217659592628479
Batch 11/64 loss: 0.21739602088928223
Batch 12/64 loss: 0.22543388605117798
Batch 13/64 loss: 0.21938294172286987
Batch 14/64 loss: 0.22553789615631104
Batch 15/64 loss: 0.22154128551483154
Batch 16/64 loss: 0.22145605087280273
Batch 17/64 loss: 0.22634536027908325
Batch 18/64 loss: 0.22407889366149902
Batch 19/64 loss: 0.23311269283294678
Batch 20/64 loss: 0.2274768352508545
Batch 21/64 loss: 0.22482788562774658
Batch 22/64 loss: 0.21767938137054443
Batch 23/64 loss: 0.21765625476837158
Batch 24/64 loss: 0.22686874866485596
Batch 25/64 loss: 0.23035621643066406
Batch 26/64 loss: 0.21935653686523438
Batch 27/64 loss: 0.2264918088912964
Batch 28/64 loss: 0.21994251012802124
Batch 29/64 loss: 0.22919440269470215
Batch 30/64 loss: 0.2226465940475464
Batch 31/64 loss: 0.22505104541778564
Batch 32/64 loss: 0.22940605878829956
Batch 33/64 loss: 0.22318494319915771
Batch 34/64 loss: 0.21665632724761963
Batch 35/64 loss: 0.22414058446884155
Batch 36/64 loss: 0.21518611907958984
Batch 37/64 loss: 0.23121380805969238
Batch 38/64 loss: 0.22461819648742676
Batch 39/64 loss: 0.22634410858154297
Batch 40/64 loss: 0.22336477041244507
Batch 41/64 loss: 0.22106969356536865
Batch 42/64 loss: 0.23034316301345825
Batch 43/64 loss: 0.21838504076004028
Batch 44/64 loss: 0.22954607009887695
Batch 45/64 loss: 0.21527719497680664
Batch 46/64 loss: 0.231991708278656
Batch 47/64 loss: 0.23151350021362305
Batch 48/64 loss: 0.21668100357055664
Batch 49/64 loss: 0.23583102226257324
Batch 50/64 loss: 0.2328808307647705
Batch 51/64 loss: 0.2267165184020996
Batch 52/64 loss: 0.23672151565551758
Batch 53/64 loss: 0.2273467779159546
Batch 54/64 loss: 0.22704333066940308
Batch 55/64 loss: 0.22943556308746338
Batch 56/64 loss: 0.23358410596847534
Batch 57/64 loss: 0.22487080097198486
Batch 58/64 loss: 0.23035168647766113
Batch 59/64 loss: 0.22369468212127686
Batch 60/64 loss: 0.22407501935958862
Batch 61/64 loss: 0.23774230480194092
Batch 62/64 loss: 0.23184055089950562
Batch 63/64 loss: 0.21898585557937622
Batch 64/64 loss: 0.23421764373779297
Epoch 291  Train loss: 0.22551227176890654  Val loss: 0.27014347511468473
Epoch 292
-------------------------------
Batch 1/64 loss: 0.21739137172698975
Batch 2/64 loss: 0.22203445434570312
Batch 3/64 loss: 0.2364499568939209
Batch 4/64 loss: 0.21995949745178223
Batch 5/64 loss: 0.23569321632385254
Batch 6/64 loss: 0.2310037612915039
Batch 7/64 loss: 0.2364351749420166
Batch 8/64 loss: 0.22786223888397217
Batch 9/64 loss: 0.22142291069030762
Batch 10/64 loss: 0.21518242359161377
Batch 11/64 loss: 0.2198125123977661
Batch 12/64 loss: 0.2373998761177063
Batch 13/64 loss: 0.22245347499847412
Batch 14/64 loss: 0.2280104160308838
Batch 15/64 loss: 0.23449838161468506
Batch 16/64 loss: 0.23940110206604004
Batch 17/64 loss: 0.2271224856376648
Batch 18/64 loss: 0.2228912115097046
Batch 19/64 loss: 0.23051011562347412
Batch 20/64 loss: 0.22208905220031738
Batch 21/64 loss: 0.23151719570159912
Batch 22/64 loss: 0.22493040561676025
Batch 23/64 loss: 0.21911954879760742
Batch 24/64 loss: 0.22554504871368408
Batch 25/64 loss: 0.221235454082489
Batch 26/64 loss: 0.2244434356689453
Batch 27/64 loss: 0.22331643104553223
Batch 28/64 loss: 0.2312517762184143
Batch 29/64 loss: 0.22102147340774536
Batch 30/64 loss: 0.22153055667877197
Batch 31/64 loss: 0.22461706399917603
Batch 32/64 loss: 0.232047438621521
Batch 33/64 loss: 0.22474926710128784
Batch 34/64 loss: 0.23310363292694092
Batch 35/64 loss: 0.22178387641906738
Batch 36/64 loss: 0.22139257192611694
Batch 37/64 loss: 0.22470623254776
Batch 38/64 loss: 0.2207474708557129
Batch 39/64 loss: 0.2286698818206787
Batch 40/64 loss: 0.22808480262756348
Batch 41/64 loss: 0.2203202247619629
Batch 42/64 loss: 0.212663471698761
Batch 43/64 loss: 0.22116565704345703
Batch 44/64 loss: 0.2210780382156372
Batch 45/64 loss: 0.2169433832168579
Batch 46/64 loss: 0.22359418869018555
Batch 47/64 loss: 0.2333071231842041
Batch 48/64 loss: 0.22597038745880127
Batch 49/64 loss: 0.2213578224182129
Batch 50/64 loss: 0.23500841856002808
Batch 51/64 loss: 0.225502610206604
Batch 52/64 loss: 0.2260655164718628
Batch 53/64 loss: 0.22251713275909424
Batch 54/64 loss: 0.22709912061691284
Batch 55/64 loss: 0.21879363059997559
Batch 56/64 loss: 0.2223433256149292
Batch 57/64 loss: 0.23036038875579834
Batch 58/64 loss: 0.22088468074798584
Batch 59/64 loss: 0.22710514068603516
Batch 60/64 loss: 0.24365240335464478
Batch 61/64 loss: 0.22353553771972656
Batch 62/64 loss: 0.22648030519485474
Batch 63/64 loss: 0.22206491231918335
Batch 64/64 loss: 0.23625874519348145
Epoch 292  Train loss: 0.22582658318912283  Val loss: 0.27165746422567727
Epoch 293
-------------------------------
Batch 1/64 loss: 0.2216370701789856
Batch 2/64 loss: 0.23621010780334473
Batch 3/64 loss: 0.2282555103302002
Batch 4/64 loss: 0.22312361001968384
Batch 5/64 loss: 0.21901333332061768
Batch 6/64 loss: 0.2242298126220703
Batch 7/64 loss: 0.23522746562957764
Batch 8/64 loss: 0.23506182432174683
Batch 9/64 loss: 0.22009432315826416
Batch 10/64 loss: 0.2297680377960205
Batch 11/64 loss: 0.22554081678390503
Batch 12/64 loss: 0.2223905324935913
Batch 13/64 loss: 0.22957950830459595
Batch 14/64 loss: 0.2142195701599121
Batch 15/64 loss: 0.22739189863204956
Batch 16/64 loss: 0.23086166381835938
Batch 17/64 loss: 0.21432405710220337
Batch 18/64 loss: 0.21768349409103394
Batch 19/64 loss: 0.2368934154510498
Batch 20/64 loss: 0.22707760334014893
Batch 21/64 loss: 0.22013628482818604
Batch 22/64 loss: 0.2278769612312317
Batch 23/64 loss: 0.21455878019332886
Batch 24/64 loss: 0.23050928115844727
Batch 25/64 loss: 0.228532612323761
Batch 26/64 loss: 0.23486065864562988
Batch 27/64 loss: 0.2255011796951294
Batch 28/64 loss: 0.22291958332061768
Batch 29/64 loss: 0.23314893245697021
Batch 30/64 loss: 0.22043418884277344
Batch 31/64 loss: 0.23514652252197266
Batch 32/64 loss: 0.22336280345916748
Batch 33/64 loss: 0.2308635711669922
Batch 34/64 loss: 0.2274724245071411
Batch 35/64 loss: 0.22603058815002441
Batch 36/64 loss: 0.24072366952896118
Batch 37/64 loss: 0.22853678464889526
Batch 38/64 loss: 0.22790074348449707
Batch 39/64 loss: 0.21500635147094727
Batch 40/64 loss: 0.22893571853637695
Batch 41/64 loss: 0.22591662406921387
Batch 42/64 loss: 0.22642475366592407
Batch 43/64 loss: 0.23176097869873047
Batch 44/64 loss: 0.22219133377075195
Batch 45/64 loss: 0.22349077463150024
Batch 46/64 loss: 0.22257530689239502
Batch 47/64 loss: 0.227921724319458
Batch 48/64 loss: 0.22752666473388672
Batch 49/64 loss: 0.22752654552459717
Batch 50/64 loss: 0.23009967803955078
Batch 51/64 loss: 0.21799254417419434
Batch 52/64 loss: 0.22715193033218384
Batch 53/64 loss: 0.2184097170829773
Batch 54/64 loss: 0.2231384515762329
Batch 55/64 loss: 0.22387754917144775
Batch 56/64 loss: 0.22519779205322266
Batch 57/64 loss: 0.2245703935623169
Batch 58/64 loss: 0.22556835412979126
Batch 59/64 loss: 0.21361839771270752
Batch 60/64 loss: 0.23262524604797363
Batch 61/64 loss: 0.22471249103546143
Batch 62/64 loss: 0.21734017133712769
Batch 63/64 loss: 0.2227708101272583
Batch 64/64 loss: 0.21914297342300415
Epoch 293  Train loss: 0.22569108640446384  Val loss: 0.26962016906934916
Epoch 294
-------------------------------
Batch 1/64 loss: 0.23086488246917725
Batch 2/64 loss: 0.22779881954193115
Batch 3/64 loss: 0.21855199337005615
Batch 4/64 loss: 0.21806073188781738
Batch 5/64 loss: 0.22939932346343994
Batch 6/64 loss: 0.22350549697875977
Batch 7/64 loss: 0.23316556215286255
Batch 8/64 loss: 0.22415006160736084
Batch 9/64 loss: 0.2304466962814331
Batch 10/64 loss: 0.22367513179779053
Batch 11/64 loss: 0.22238528728485107
Batch 12/64 loss: 0.21741360425949097
Batch 13/64 loss: 0.2214091420173645
Batch 14/64 loss: 0.22978460788726807
Batch 15/64 loss: 0.22122526168823242
Batch 16/64 loss: 0.22503215074539185
Batch 17/64 loss: 0.23235666751861572
Batch 18/64 loss: 0.23394626379013062
Batch 19/64 loss: 0.22610032558441162
Batch 20/64 loss: 0.2271496057510376
Batch 21/64 loss: 0.23127645254135132
Batch 22/64 loss: 0.21929514408111572
Batch 23/64 loss: 0.22996509075164795
Batch 24/64 loss: 0.22260808944702148
Batch 25/64 loss: 0.22901785373687744
Batch 26/64 loss: 0.22826969623565674
Batch 27/64 loss: 0.2239062786102295
Batch 28/64 loss: 0.23684191703796387
Batch 29/64 loss: 0.2236396074295044
Batch 30/64 loss: 0.23284101486206055
Batch 31/64 loss: 0.21878111362457275
Batch 32/64 loss: 0.22727274894714355
Batch 33/64 loss: 0.223574697971344
Batch 34/64 loss: 0.2296963930130005
Batch 35/64 loss: 0.22659289836883545
Batch 36/64 loss: 0.2190573811531067
Batch 37/64 loss: 0.22083228826522827
Batch 38/64 loss: 0.23056727647781372
Batch 39/64 loss: 0.22600233554840088
Batch 40/64 loss: 0.22927522659301758
Batch 41/64 loss: 0.22432422637939453
Batch 42/64 loss: 0.21899884939193726
Batch 43/64 loss: 0.22816288471221924
Batch 44/64 loss: 0.22303998470306396
Batch 45/64 loss: 0.2234811782836914
Batch 46/64 loss: 0.23414397239685059
Batch 47/64 loss: 0.22806215286254883
Batch 48/64 loss: 0.2266300916671753
Batch 49/64 loss: 0.24608176946640015
Batch 50/64 loss: 0.22262543439865112
Batch 51/64 loss: 0.21829140186309814
Batch 52/64 loss: 0.22758114337921143
Batch 53/64 loss: 0.22856366634368896
Batch 54/64 loss: 0.22850394248962402
Batch 55/64 loss: 0.21940374374389648
Batch 56/64 loss: 0.2245577573776245
Batch 57/64 loss: 0.23371195793151855
Batch 58/64 loss: 0.22570377588272095
Batch 59/64 loss: 0.22295421361923218
Batch 60/64 loss: 0.22386109828948975
Batch 61/64 loss: 0.22473537921905518
Batch 62/64 loss: 0.22433781623840332
Batch 63/64 loss: 0.22640609741210938
Batch 64/64 loss: 0.22723448276519775
Epoch 294  Train loss: 0.2262011532690011  Val loss: 0.27150718022867576
Epoch 295
-------------------------------
Batch 1/64 loss: 0.22319138050079346
Batch 2/64 loss: 0.22311687469482422
Batch 3/64 loss: 0.22504007816314697
Batch 4/64 loss: 0.23733001947402954
Batch 5/64 loss: 0.21896880865097046
Batch 6/64 loss: 0.22381329536437988
Batch 7/64 loss: 0.22728335857391357
Batch 8/64 loss: 0.22184735536575317
Batch 9/64 loss: 0.23140376806259155
Batch 10/64 loss: 0.22258847951889038
Batch 11/64 loss: 0.2226954698562622
Batch 12/64 loss: 0.22061514854431152
Batch 13/64 loss: 0.2182321548461914
Batch 14/64 loss: 0.2275426983833313
Batch 15/64 loss: 0.22536921501159668
Batch 16/64 loss: 0.21693986654281616
Batch 17/64 loss: 0.2233593463897705
Batch 18/64 loss: 0.22297030687332153
Batch 19/64 loss: 0.22347486019134521
Batch 20/64 loss: 0.22228491306304932
Batch 21/64 loss: 0.2209622859954834
Batch 22/64 loss: 0.2191992998123169
Batch 23/64 loss: 0.22581201791763306
Batch 24/64 loss: 0.22540831565856934
Batch 25/64 loss: 0.23249411582946777
Batch 26/64 loss: 0.2195664644241333
Batch 27/64 loss: 0.22462719678878784
Batch 28/64 loss: 0.22153061628341675
Batch 29/64 loss: 0.22494053840637207
Batch 30/64 loss: 0.21945703029632568
Batch 31/64 loss: 0.23040449619293213
Batch 32/64 loss: 0.22557175159454346
Batch 33/64 loss: 0.21757245063781738
Batch 34/64 loss: 0.2195557951927185
Batch 35/64 loss: 0.2195119857788086
Batch 36/64 loss: 0.21770834922790527
Batch 37/64 loss: 0.22435081005096436
Batch 38/64 loss: 0.2211417555809021
Batch 39/64 loss: 0.22844135761260986
Batch 40/64 loss: 0.2165837287902832
Batch 41/64 loss: 0.23186910152435303
Batch 42/64 loss: 0.22081118822097778
Batch 43/64 loss: 0.21542870998382568
Batch 44/64 loss: 0.22203195095062256
Batch 45/64 loss: 0.23103231191635132
Batch 46/64 loss: 0.22903954982757568
Batch 47/64 loss: 0.22970974445343018
Batch 48/64 loss: 0.22972679138183594
Batch 49/64 loss: 0.23158317804336548
Batch 50/64 loss: 0.22471988201141357
Batch 51/64 loss: 0.2268136739730835
Batch 52/64 loss: 0.22210264205932617
Batch 53/64 loss: 0.24140602350234985
Batch 54/64 loss: 0.22546815872192383
Batch 55/64 loss: 0.2301328182220459
Batch 56/64 loss: 0.2294825315475464
Batch 57/64 loss: 0.235284686088562
Batch 58/64 loss: 0.235573410987854
Batch 59/64 loss: 0.22544699907302856
Batch 60/64 loss: 0.22318172454833984
Batch 61/64 loss: 0.23592102527618408
Batch 62/64 loss: 0.217424213886261
Batch 63/64 loss: 0.22867411375045776
Batch 64/64 loss: 0.22154635190963745
Epoch 295  Train loss: 0.22497148163178388  Val loss: 0.2709470260184245
Epoch 296
-------------------------------
Batch 1/64 loss: 0.22910702228546143
Batch 2/64 loss: 0.2250974178314209
Batch 3/64 loss: 0.22776281833648682
Batch 4/64 loss: 0.223785400390625
Batch 5/64 loss: 0.22531342506408691
Batch 6/64 loss: 0.21288800239562988
Batch 7/64 loss: 0.2273944616317749
Batch 8/64 loss: 0.23081433773040771
Batch 9/64 loss: 0.21537667512893677
Batch 10/64 loss: 0.21259474754333496
Batch 11/64 loss: 0.2268635630607605
Batch 12/64 loss: 0.21546697616577148
Batch 13/64 loss: 0.21936023235321045
Batch 14/64 loss: 0.2287076711654663
Batch 15/64 loss: 0.22715532779693604
Batch 16/64 loss: 0.21735727787017822
Batch 17/64 loss: 0.2188020944595337
Batch 18/64 loss: 0.21934711933135986
Batch 19/64 loss: 0.22099024057388306
Batch 20/64 loss: 0.2298160195350647
Batch 21/64 loss: 0.22419780492782593
Batch 22/64 loss: 0.23108381032943726
Batch 23/64 loss: 0.2155449390411377
Batch 24/64 loss: 0.22444385290145874
Batch 25/64 loss: 0.22754329442977905
Batch 26/64 loss: 0.22263425588607788
Batch 27/64 loss: 0.22077929973602295
Batch 28/64 loss: 0.23154127597808838
Batch 29/64 loss: 0.22632288932800293
Batch 30/64 loss: 0.2216416597366333
Batch 31/64 loss: 0.2266833782196045
Batch 32/64 loss: 0.22857916355133057
Batch 33/64 loss: 0.21773123741149902
Batch 34/64 loss: 0.22189807891845703
Batch 35/64 loss: 0.2327873706817627
Batch 36/64 loss: 0.23601078987121582
Batch 37/64 loss: 0.22952109575271606
Batch 38/64 loss: 0.2377939224243164
Batch 39/64 loss: 0.222680926322937
Batch 40/64 loss: 0.23622262477874756
Batch 41/64 loss: 0.23367857933044434
Batch 42/64 loss: 0.22774434089660645
Batch 43/64 loss: 0.22749078273773193
Batch 44/64 loss: 0.22886890172958374
Batch 45/64 loss: 0.22044694423675537
Batch 46/64 loss: 0.24013495445251465
Batch 47/64 loss: 0.21937543153762817
Batch 48/64 loss: 0.23155343532562256
Batch 49/64 loss: 0.22769951820373535
Batch 50/64 loss: 0.2377367615699768
Batch 51/64 loss: 0.2237035632133484
Batch 52/64 loss: 0.2162829041481018
Batch 53/64 loss: 0.2318326234817505
Batch 54/64 loss: 0.21793556213378906
Batch 55/64 loss: 0.2271047830581665
Batch 56/64 loss: 0.23586469888687134
Batch 57/64 loss: 0.22145366668701172
Batch 58/64 loss: 0.22763925790786743
Batch 59/64 loss: 0.22263860702514648
Batch 60/64 loss: 0.2295209765434265
Batch 61/64 loss: 0.22261518239974976
Batch 62/64 loss: 0.2461179494857788
Batch 63/64 loss: 0.23033714294433594
Batch 64/64 loss: 0.22523820400238037
Epoch 296  Train loss: 0.22598192504808015  Val loss: 0.26957395867383765
Epoch 297
-------------------------------
Batch 1/64 loss: 0.22770380973815918
Batch 2/64 loss: 0.2317103147506714
Batch 3/64 loss: 0.22516870498657227
Batch 4/64 loss: 0.23461544513702393
Batch 5/64 loss: 0.22436916828155518
Batch 6/64 loss: 0.2126837968826294
Batch 7/64 loss: 0.22157227993011475
Batch 8/64 loss: 0.23069775104522705
Batch 9/64 loss: 0.21811282634735107
Batch 10/64 loss: 0.21614861488342285
Batch 11/64 loss: 0.22529613971710205
Batch 12/64 loss: 0.2110193967819214
Batch 13/64 loss: 0.22063422203063965
Batch 14/64 loss: 0.2352832555770874
Batch 15/64 loss: 0.223419189453125
Batch 16/64 loss: 0.2211838960647583
Batch 17/64 loss: 0.22354745864868164
Batch 18/64 loss: 0.2311534881591797
Batch 19/64 loss: 0.22686612606048584
Batch 20/64 loss: 0.22835969924926758
Batch 21/64 loss: 0.22580969333648682
Batch 22/64 loss: 0.2241593599319458
Batch 23/64 loss: 0.2361992597579956
Batch 24/64 loss: 0.21721488237380981
Batch 25/64 loss: 0.22438693046569824
Batch 26/64 loss: 0.22310107946395874
Batch 27/64 loss: 0.22452980279922485
Batch 28/64 loss: 0.22269392013549805
Batch 29/64 loss: 0.22835630178451538
Batch 30/64 loss: 0.22706055641174316
Batch 31/64 loss: 0.22428077459335327
Batch 32/64 loss: 0.22002243995666504
Batch 33/64 loss: 0.23240500688552856
Batch 34/64 loss: 0.22643446922302246
Batch 35/64 loss: 0.21971648931503296
Batch 36/64 loss: 0.22176194190979004
Batch 37/64 loss: 0.22961723804473877
Batch 38/64 loss: 0.220483660697937
Batch 39/64 loss: 0.22562479972839355
Batch 40/64 loss: 0.22230899333953857
Batch 41/64 loss: 0.22731256484985352
Batch 42/64 loss: 0.2258281707763672
Batch 43/64 loss: 0.23145246505737305
Batch 44/64 loss: 0.23398888111114502
Batch 45/64 loss: 0.22217011451721191
Batch 46/64 loss: 0.2314770221710205
Batch 47/64 loss: 0.22656190395355225
Batch 48/64 loss: 0.21664565801620483
Batch 49/64 loss: 0.2216477394104004
Batch 50/64 loss: 0.21778619289398193
Batch 51/64 loss: 0.2274308204650879
Batch 52/64 loss: 0.23037928342819214
Batch 53/64 loss: 0.22057318687438965
Batch 54/64 loss: 0.23474407196044922
Batch 55/64 loss: 0.2268695831298828
Batch 56/64 loss: 0.22157728672027588
Batch 57/64 loss: 0.21597778797149658
Batch 58/64 loss: 0.22524845600128174
Batch 59/64 loss: 0.2292407751083374
Batch 60/64 loss: 0.22983598709106445
Batch 61/64 loss: 0.22108596563339233
Batch 62/64 loss: 0.22041654586791992
Batch 63/64 loss: 0.22202837467193604
Batch 64/64 loss: 0.22250813245773315
Epoch 297  Train loss: 0.2248293822886897  Val loss: 0.2712334496868435
Epoch 298
-------------------------------
Batch 1/64 loss: 0.23135703802108765
Batch 2/64 loss: 0.23277664184570312
Batch 3/64 loss: 0.2190614938735962
Batch 4/64 loss: 0.22928273677825928
Batch 5/64 loss: 0.2213972806930542
Batch 6/64 loss: 0.22356855869293213
Batch 7/64 loss: 0.23070299625396729
Batch 8/64 loss: 0.2306908369064331
Batch 9/64 loss: 0.233240008354187
Batch 10/64 loss: 0.22254526615142822
Batch 11/64 loss: 0.2234702706336975
Batch 12/64 loss: 0.22542142868041992
Batch 13/64 loss: 0.2268223762512207
Batch 14/64 loss: 0.22226083278656006
Batch 15/64 loss: 0.22055912017822266
Batch 16/64 loss: 0.22216224670410156
Batch 17/64 loss: 0.22871911525726318
Batch 18/64 loss: 0.22046047449111938
Batch 19/64 loss: 0.22284889221191406
Batch 20/64 loss: 0.2227213978767395
Batch 21/64 loss: 0.21962970495224
Batch 22/64 loss: 0.22365045547485352
Batch 23/64 loss: 0.2258450984954834
Batch 24/64 loss: 0.217728853225708
Batch 25/64 loss: 0.21960878372192383
Batch 26/64 loss: 0.23252886533737183
Batch 27/64 loss: 0.21739965677261353
Batch 28/64 loss: 0.23160791397094727
Batch 29/64 loss: 0.22208547592163086
Batch 30/64 loss: 0.22964578866958618
Batch 31/64 loss: 0.22880840301513672
Batch 32/64 loss: 0.21668720245361328
Batch 33/64 loss: 0.22681140899658203
Batch 34/64 loss: 0.2228940725326538
Batch 35/64 loss: 0.21938717365264893
Batch 36/64 loss: 0.23568999767303467
Batch 37/64 loss: 0.21691232919692993
Batch 38/64 loss: 0.22455155849456787
Batch 39/64 loss: 0.22419118881225586
Batch 40/64 loss: 0.22959786653518677
Batch 41/64 loss: 0.22706377506256104
Batch 42/64 loss: 0.22060859203338623
Batch 43/64 loss: 0.2189461588859558
Batch 44/64 loss: 0.2292414903640747
Batch 45/64 loss: 0.21746468544006348
Batch 46/64 loss: 0.2256782054901123
Batch 47/64 loss: 0.22777414321899414
Batch 48/64 loss: 0.22729027271270752
Batch 49/64 loss: 0.2212672233581543
Batch 50/64 loss: 0.22973227500915527
Batch 51/64 loss: 0.2195984125137329
Batch 52/64 loss: 0.22973263263702393
Batch 53/64 loss: 0.21869242191314697
Batch 54/64 loss: 0.23671674728393555
Batch 55/64 loss: 0.22184526920318604
Batch 56/64 loss: 0.2218559980392456
Batch 57/64 loss: 0.2276928424835205
Batch 58/64 loss: 0.22464853525161743
Batch 59/64 loss: 0.2346813678741455
Batch 60/64 loss: 0.22467023134231567
Batch 61/64 loss: 0.21843838691711426
Batch 62/64 loss: 0.22563600540161133
Batch 63/64 loss: 0.2214515209197998
Batch 64/64 loss: 0.22137868404388428
Epoch 298  Train loss: 0.22481712967741724  Val loss: 0.27028822222935783
Epoch 299
-------------------------------
Batch 1/64 loss: 0.22242993116378784
Batch 2/64 loss: 0.22527611255645752
Batch 3/64 loss: 0.22513866424560547
Batch 4/64 loss: 0.21730166673660278
Batch 5/64 loss: 0.23257827758789062
Batch 6/64 loss: 0.23281288146972656
Batch 7/64 loss: 0.22260797023773193
Batch 8/64 loss: 0.22755074501037598
Batch 9/64 loss: 0.2283344268798828
Batch 10/64 loss: 0.22309201955795288
Batch 11/64 loss: 0.21555328369140625
Batch 12/64 loss: 0.23061144351959229
Batch 13/64 loss: 0.2231963872909546
Batch 14/64 loss: 0.22141766548156738
Batch 15/64 loss: 0.21333330869674683
Batch 16/64 loss: 0.21821808815002441
Batch 17/64 loss: 0.22188621759414673
Batch 18/64 loss: 0.22103220224380493
Batch 19/64 loss: 0.22571903467178345
Batch 20/64 loss: 0.22666192054748535
Batch 21/64 loss: 0.21931898593902588
Batch 22/64 loss: 0.21316468715667725
Batch 23/64 loss: 0.22474372386932373
Batch 24/64 loss: 0.22556430101394653
Batch 25/64 loss: 0.22363221645355225
Batch 26/64 loss: 0.22587811946868896
Batch 27/64 loss: 0.21399521827697754
Batch 28/64 loss: 0.2232334017753601
Batch 29/64 loss: 0.22138923406600952
Batch 30/64 loss: 0.2242913842201233
Batch 31/64 loss: 0.22800076007843018
Batch 32/64 loss: 0.22447443008422852
Batch 33/64 loss: 0.2216581106185913
Batch 34/64 loss: 0.22620248794555664
Batch 35/64 loss: 0.23047947883605957
Batch 36/64 loss: 0.22178006172180176
Batch 37/64 loss: 0.21990036964416504
Batch 38/64 loss: 0.22501146793365479
Batch 39/64 loss: 0.22661375999450684
Batch 40/64 loss: 0.22571128606796265
Batch 41/64 loss: 0.22480058670043945
Batch 42/64 loss: 0.2266232967376709
Batch 43/64 loss: 0.22614920139312744
Batch 44/64 loss: 0.23401272296905518
Batch 45/64 loss: 0.2173541784286499
Batch 46/64 loss: 0.23122155666351318
Batch 47/64 loss: 0.21522724628448486
Batch 48/64 loss: 0.21863245964050293
Batch 49/64 loss: 0.2204122543334961
Batch 50/64 loss: 0.2178633213043213
Batch 51/64 loss: 0.23394989967346191
Batch 52/64 loss: 0.22086071968078613
Batch 53/64 loss: 0.2263249158859253
Batch 54/64 loss: 0.22347813844680786
Batch 55/64 loss: 0.21789312362670898
Batch 56/64 loss: 0.23714333772659302
Batch 57/64 loss: 0.2243410348892212
Batch 58/64 loss: 0.2245866060256958
Batch 59/64 loss: 0.2185283899307251
Batch 60/64 loss: 0.22820013761520386
Batch 61/64 loss: 0.21817409992218018
Batch 62/64 loss: 0.22078311443328857
Batch 63/64 loss: 0.21689361333847046
Batch 64/64 loss: 0.21884554624557495
Epoch 299  Train loss: 0.22348837408364988  Val loss: 0.2696917005830614
Epoch 300
-------------------------------
Batch 1/64 loss: 0.21388936042785645
Batch 2/64 loss: 0.22170865535736084
Batch 3/64 loss: 0.22535276412963867
Batch 4/64 loss: 0.21450257301330566
Batch 5/64 loss: 0.22744905948638916
Batch 6/64 loss: 0.2204943299293518
Batch 7/64 loss: 0.21987861394882202
Batch 8/64 loss: 0.23141175508499146
Batch 9/64 loss: 0.2157841920852661
Batch 10/64 loss: 0.227794349193573
Batch 11/64 loss: 0.2247401475906372
Batch 12/64 loss: 0.23144835233688354
Batch 13/64 loss: 0.2148788571357727
Batch 14/64 loss: 0.2287030816078186
Batch 15/64 loss: 0.21828866004943848
Batch 16/64 loss: 0.23169851303100586
Batch 17/64 loss: 0.22109448909759521
Batch 18/64 loss: 0.2124556303024292
Batch 19/64 loss: 0.2164977788925171
Batch 20/64 loss: 0.21966111660003662
Batch 21/64 loss: 0.22313308715820312
Batch 22/64 loss: 0.22321856021881104
Batch 23/64 loss: 0.21995770931243896
Batch 24/64 loss: 0.21361839771270752
Batch 25/64 loss: 0.23038113117218018
Batch 26/64 loss: 0.22019577026367188
Batch 27/64 loss: 0.22247737646102905
Batch 28/64 loss: 0.22640609741210938
Batch 29/64 loss: 0.2221904993057251
Batch 30/64 loss: 0.22852766513824463
Batch 31/64 loss: 0.216513991355896
Batch 32/64 loss: 0.22406649589538574
Batch 33/64 loss: 0.2223348617553711
Batch 34/64 loss: 0.22138363122940063
Batch 35/64 loss: 0.23439687490463257
Batch 36/64 loss: 0.22858959436416626
Batch 37/64 loss: 0.22383123636245728
Batch 38/64 loss: 0.22423028945922852
Batch 39/64 loss: 0.22537291049957275
Batch 40/64 loss: 0.22497892379760742
Batch 41/64 loss: 0.237299382686615
Batch 42/64 loss: 0.2200683355331421
Batch 43/64 loss: 0.21969717741012573
Batch 44/64 loss: 0.2202741503715515
Batch 45/64 loss: 0.22363781929016113
Batch 46/64 loss: 0.22143816947937012
Batch 47/64 loss: 0.2230243682861328
Batch 48/64 loss: 0.2268308401107788
Batch 49/64 loss: 0.21816426515579224
Batch 50/64 loss: 0.22589129209518433
Batch 51/64 loss: 0.22821033000946045
Batch 52/64 loss: 0.22519248723983765
Batch 53/64 loss: 0.22728484869003296
Batch 54/64 loss: 0.23195451498031616
Batch 55/64 loss: 0.22645390033721924
Batch 56/64 loss: 0.22333163022994995
Batch 57/64 loss: 0.2289121150970459
Batch 58/64 loss: 0.22667914628982544
Batch 59/64 loss: 0.21919691562652588
Batch 60/64 loss: 0.21813613176345825
Batch 61/64 loss: 0.22973883152008057
Batch 62/64 loss: 0.23078346252441406
Batch 63/64 loss: 0.23349487781524658
Batch 64/64 loss: 0.2266402244567871
Epoch 300  Train loss: 0.22383078500336293  Val loss: 0.270355946009921
Epoch 301
-------------------------------
Batch 1/64 loss: 0.2210097312927246
Batch 2/64 loss: 0.221221923828125
Batch 3/64 loss: 0.221052885055542
Batch 4/64 loss: 0.23396044969558716
Batch 5/64 loss: 0.22863024473190308
Batch 6/64 loss: 0.22006583213806152
Batch 7/64 loss: 0.21571087837219238
Batch 8/64 loss: 0.23807215690612793
Batch 9/64 loss: 0.23939383029937744
Batch 10/64 loss: 0.22728240489959717
Batch 11/64 loss: 0.22015172243118286
Batch 12/64 loss: 0.22347307205200195
Batch 13/64 loss: 0.22337067127227783
Batch 14/64 loss: 0.22949033975601196
Batch 15/64 loss: 0.23307347297668457
Batch 16/64 loss: 0.22452259063720703
Batch 17/64 loss: 0.224257230758667
Batch 18/64 loss: 0.2183384895324707
Batch 19/64 loss: 0.22708898782730103
Batch 20/64 loss: 0.22716057300567627
Batch 21/64 loss: 0.22638165950775146
Batch 22/64 loss: 0.22427654266357422
Batch 23/64 loss: 0.21864551305770874
Batch 24/64 loss: 0.22855734825134277
Batch 25/64 loss: 0.22302109003067017
Batch 26/64 loss: 0.2339942455291748
Batch 27/64 loss: 0.21667814254760742
Batch 28/64 loss: 0.22327470779418945
Batch 29/64 loss: 0.22638118267059326
Batch 30/64 loss: 0.22883015871047974
Batch 31/64 loss: 0.2357560396194458
Batch 32/64 loss: 0.2181950807571411
Batch 33/64 loss: 0.22204220294952393
Batch 34/64 loss: 0.21687370538711548
Batch 35/64 loss: 0.22524583339691162
Batch 36/64 loss: 0.21713054180145264
Batch 37/64 loss: 0.22682702541351318
Batch 38/64 loss: 0.22049790620803833
Batch 39/64 loss: 0.22228682041168213
Batch 40/64 loss: 0.2187620997428894
Batch 41/64 loss: 0.22774040699005127
Batch 42/64 loss: 0.22303742170333862
Batch 43/64 loss: 0.22566914558410645
Batch 44/64 loss: 0.23055362701416016
Batch 45/64 loss: 0.2203800082206726
Batch 46/64 loss: 0.22035610675811768
Batch 47/64 loss: 0.21964645385742188
Batch 48/64 loss: 0.23298156261444092
Batch 49/64 loss: 0.23451071977615356
Batch 50/64 loss: 0.22775685787200928
Batch 51/64 loss: 0.22451066970825195
Batch 52/64 loss: 0.22191262245178223
Batch 53/64 loss: 0.2150372862815857
Batch 54/64 loss: 0.21905523538589478
Batch 55/64 loss: 0.22169804573059082
Batch 56/64 loss: 0.22088706493377686
Batch 57/64 loss: 0.2326805591583252
Batch 58/64 loss: 0.21432363986968994
Batch 59/64 loss: 0.23232758045196533
Batch 60/64 loss: 0.21993470191955566
Batch 61/64 loss: 0.23091089725494385
Batch 62/64 loss: 0.22080671787261963
Batch 63/64 loss: 0.2164263129234314
Batch 64/64 loss: 0.2186053991317749
Epoch 301  Train loss: 0.2244405180800195  Val loss: 0.2705590683979677
Epoch 302
-------------------------------
Batch 1/64 loss: 0.22778713703155518
Batch 2/64 loss: 0.22208702564239502
Batch 3/64 loss: 0.22699296474456787
Batch 4/64 loss: 0.21576780080795288
Batch 5/64 loss: 0.2270669937133789
Batch 6/64 loss: 0.2207636833190918
Batch 7/64 loss: 0.22323298454284668
Batch 8/64 loss: 0.22963809967041016
Batch 9/64 loss: 0.2296386957168579
Batch 10/64 loss: 0.2221285104751587
Batch 11/64 loss: 0.2217954397201538
Batch 12/64 loss: 0.2184416651725769
Batch 13/64 loss: 0.22394061088562012
Batch 14/64 loss: 0.21692246198654175
Batch 15/64 loss: 0.21943318843841553
Batch 16/64 loss: 0.21354663372039795
Batch 17/64 loss: 0.21554327011108398
Batch 18/64 loss: 0.22448241710662842
Batch 19/64 loss: 0.226776123046875
Batch 20/64 loss: 0.21586120128631592
Batch 21/64 loss: 0.21095573902130127
Batch 22/64 loss: 0.2264423370361328
Batch 23/64 loss: 0.22947657108306885
Batch 24/64 loss: 0.21780818700790405
Batch 25/64 loss: 0.23584115505218506
Batch 26/64 loss: 0.22191232442855835
Batch 27/64 loss: 0.21948981285095215
Batch 28/64 loss: 0.21857309341430664
Batch 29/64 loss: 0.2304583191871643
Batch 30/64 loss: 0.22172951698303223
Batch 31/64 loss: 0.22036093473434448
Batch 32/64 loss: 0.2252051830291748
Batch 33/64 loss: 0.23043549060821533
Batch 34/64 loss: 0.22445613145828247
Batch 35/64 loss: 0.22178614139556885
Batch 36/64 loss: 0.2192818522453308
Batch 37/64 loss: 0.2281433343887329
Batch 38/64 loss: 0.22778522968292236
Batch 39/64 loss: 0.22907167673110962
Batch 40/64 loss: 0.2310163378715515
Batch 41/64 loss: 0.23440396785736084
Batch 42/64 loss: 0.22971820831298828
Batch 43/64 loss: 0.2219381332397461
Batch 44/64 loss: 0.22000956535339355
Batch 45/64 loss: 0.2231966257095337
Batch 46/64 loss: 0.2239435315132141
Batch 47/64 loss: 0.2162255048751831
Batch 48/64 loss: 0.22235864400863647
Batch 49/64 loss: 0.2345820665359497
Batch 50/64 loss: 0.22645390033721924
Batch 51/64 loss: 0.22874951362609863
Batch 52/64 loss: 0.21724152565002441
Batch 53/64 loss: 0.21771132946014404
Batch 54/64 loss: 0.21857398748397827
Batch 55/64 loss: 0.21392738819122314
Batch 56/64 loss: 0.22688519954681396
Batch 57/64 loss: 0.22050631046295166
Batch 58/64 loss: 0.21962547302246094
Batch 59/64 loss: 0.21639668941497803
Batch 60/64 loss: 0.22271263599395752
Batch 61/64 loss: 0.23436129093170166
Batch 62/64 loss: 0.2307734489440918
Batch 63/64 loss: 0.21363866329193115
Batch 64/64 loss: 0.22889113426208496
Epoch 302  Train loss: 0.2233361290950401  Val loss: 0.2707914646548504
Epoch 303
-------------------------------
Batch 1/64 loss: 0.22217494249343872
Batch 2/64 loss: 0.22621166706085205
Batch 3/64 loss: 0.21457231044769287
Batch 4/64 loss: 0.2357717752456665
Batch 5/64 loss: 0.22566992044448853
Batch 6/64 loss: 0.2246391773223877
Batch 7/64 loss: 0.2298901081085205
Batch 8/64 loss: 0.22448766231536865
Batch 9/64 loss: 0.21536439657211304
Batch 10/64 loss: 0.21486377716064453
Batch 11/64 loss: 0.22382760047912598
Batch 12/64 loss: 0.21538841724395752
Batch 13/64 loss: 0.23278295993804932
Batch 14/64 loss: 0.2176145315170288
Batch 15/64 loss: 0.221871018409729
Batch 16/64 loss: 0.21575886011123657
Batch 17/64 loss: 0.22390860319137573
Batch 18/64 loss: 0.21289288997650146
Batch 19/64 loss: 0.23179835081100464
Batch 20/64 loss: 0.22144806385040283
Batch 21/64 loss: 0.21698588132858276
Batch 22/64 loss: 0.21559512615203857
Batch 23/64 loss: 0.22455573081970215
Batch 24/64 loss: 0.22134864330291748
Batch 25/64 loss: 0.2341095209121704
Batch 26/64 loss: 0.2201598882675171
Batch 27/64 loss: 0.2206476926803589
Batch 28/64 loss: 0.21798956394195557
Batch 29/64 loss: 0.23024404048919678
Batch 30/64 loss: 0.2273855209350586
Batch 31/64 loss: 0.22719931602478027
Batch 32/64 loss: 0.2307111620903015
Batch 33/64 loss: 0.22872930765151978
Batch 34/64 loss: 0.23758971691131592
Batch 35/64 loss: 0.21654170751571655
Batch 36/64 loss: 0.22363513708114624
Batch 37/64 loss: 0.219953715801239
Batch 38/64 loss: 0.22034382820129395
Batch 39/64 loss: 0.22178125381469727
Batch 40/64 loss: 0.21334147453308105
Batch 41/64 loss: 0.22313141822814941
Batch 42/64 loss: 0.22912120819091797
Batch 43/64 loss: 0.2249985933303833
Batch 44/64 loss: 0.22192341089248657
Batch 45/64 loss: 0.22168147563934326
Batch 46/64 loss: 0.2238173484802246
Batch 47/64 loss: 0.22893458604812622
Batch 48/64 loss: 0.22408461570739746
Batch 49/64 loss: 0.2311638593673706
Batch 50/64 loss: 0.22495317459106445
Batch 51/64 loss: 0.21767562627792358
Batch 52/64 loss: 0.22735941410064697
Batch 53/64 loss: 0.22017526626586914
Batch 54/64 loss: 0.22654247283935547
Batch 55/64 loss: 0.23029875755310059
Batch 56/64 loss: 0.2271636724472046
Batch 57/64 loss: 0.23540204763412476
Batch 58/64 loss: 0.2239922285079956
Batch 59/64 loss: 0.22071099281311035
Batch 60/64 loss: 0.22173452377319336
Batch 61/64 loss: 0.22327935695648193
Batch 62/64 loss: 0.22938930988311768
Batch 63/64 loss: 0.22209370136260986
Batch 64/64 loss: 0.2514028549194336
Epoch 303  Train loss: 0.22412493275661094  Val loss: 0.2700069163673112
Epoch 304
-------------------------------
Batch 1/64 loss: 0.22550272941589355
Batch 2/64 loss: 0.22085916996002197
Batch 3/64 loss: 0.2217191457748413
Batch 4/64 loss: 0.22448718547821045
Batch 5/64 loss: 0.2221091389656067
Batch 6/64 loss: 0.2294541597366333
Batch 7/64 loss: 0.22036659717559814
Batch 8/64 loss: 0.2313966155052185
Batch 9/64 loss: 0.22129619121551514
Batch 10/64 loss: 0.21829962730407715
Batch 11/64 loss: 0.21724414825439453
Batch 12/64 loss: 0.2313835620880127
Batch 13/64 loss: 0.2488383650779724
Batch 14/64 loss: 0.22270214557647705
Batch 15/64 loss: 0.21568381786346436
Batch 16/64 loss: 0.21435260772705078
Batch 17/64 loss: 0.22136545181274414
Batch 18/64 loss: 0.22082149982452393
Batch 19/64 loss: 0.2247486114501953
Batch 20/64 loss: 0.21985256671905518
Batch 21/64 loss: 0.2269078493118286
Batch 22/64 loss: 0.23209631443023682
Batch 23/64 loss: 0.22986042499542236
Batch 24/64 loss: 0.2185611128807068
Batch 25/64 loss: 0.22068047523498535
Batch 26/64 loss: 0.21880406141281128
Batch 27/64 loss: 0.22477418184280396
Batch 28/64 loss: 0.22388029098510742
Batch 29/64 loss: 0.2162611484527588
Batch 30/64 loss: 0.23222607374191284
Batch 31/64 loss: 0.22013890743255615
Batch 32/64 loss: 0.22400081157684326
Batch 33/64 loss: 0.22187823057174683
Batch 34/64 loss: 0.2172682285308838
Batch 35/64 loss: 0.22687166929244995
Batch 36/64 loss: 0.23038560152053833
Batch 37/64 loss: 0.2180194854736328
Batch 38/64 loss: 0.226088285446167
Batch 39/64 loss: 0.2251022458076477
Batch 40/64 loss: 0.2344909906387329
Batch 41/64 loss: 0.21426212787628174
Batch 42/64 loss: 0.21742552518844604
Batch 43/64 loss: 0.2277335524559021
Batch 44/64 loss: 0.22098934650421143
Batch 45/64 loss: 0.2371978759765625
Batch 46/64 loss: 0.21817302703857422
Batch 47/64 loss: 0.227128267288208
Batch 48/64 loss: 0.21281307935714722
Batch 49/64 loss: 0.22856247425079346
Batch 50/64 loss: 0.22098958492279053
Batch 51/64 loss: 0.227830171585083
Batch 52/64 loss: 0.22275400161743164
Batch 53/64 loss: 0.22911858558654785
Batch 54/64 loss: 0.22613924741744995
Batch 55/64 loss: 0.22534912824630737
Batch 56/64 loss: 0.22018194198608398
Batch 57/64 loss: 0.22728753089904785
Batch 58/64 loss: 0.22892379760742188
Batch 59/64 loss: 0.2314748764038086
Batch 60/64 loss: 0.22196877002716064
Batch 61/64 loss: 0.21943128108978271
Batch 62/64 loss: 0.22202849388122559
Batch 63/64 loss: 0.22534221410751343
Batch 64/64 loss: 0.2388097047805786
Epoch 304  Train loss: 0.2242037946102666  Val loss: 0.27012338589147195
Epoch 305
-------------------------------
Batch 1/64 loss: 0.21336549520492554
Batch 2/64 loss: 0.2158879041671753
Batch 3/64 loss: 0.22012168169021606
Batch 4/64 loss: 0.2286473512649536
Batch 5/64 loss: 0.21473050117492676
Batch 6/64 loss: 0.22184985876083374
Batch 7/64 loss: 0.21440398693084717
Batch 8/64 loss: 0.22551262378692627
Batch 9/64 loss: 0.21817034482955933
Batch 10/64 loss: 0.21900677680969238
Batch 11/64 loss: 0.21937745809555054
Batch 12/64 loss: 0.22809743881225586
Batch 13/64 loss: 0.21442610025405884
Batch 14/64 loss: 0.23165059089660645
Batch 15/64 loss: 0.23078233003616333
Batch 16/64 loss: 0.21367043256759644
Batch 17/64 loss: 0.2218179702758789
Batch 18/64 loss: 0.22135251760482788
Batch 19/64 loss: 0.22709929943084717
Batch 20/64 loss: 0.23252546787261963
Batch 21/64 loss: 0.22574007511138916
Batch 22/64 loss: 0.21690326929092407
Batch 23/64 loss: 0.22462129592895508
Batch 24/64 loss: 0.2287832498550415
Batch 25/64 loss: 0.2159343957901001
Batch 26/64 loss: 0.21897435188293457
Batch 27/64 loss: 0.21546459197998047
Batch 28/64 loss: 0.2177448868751526
Batch 29/64 loss: 0.22277235984802246
Batch 30/64 loss: 0.2277124524116516
Batch 31/64 loss: 0.21816492080688477
Batch 32/64 loss: 0.22092032432556152
Batch 33/64 loss: 0.2227720022201538
Batch 34/64 loss: 0.2259414792060852
Batch 35/64 loss: 0.2277703881263733
Batch 36/64 loss: 0.2270798683166504
Batch 37/64 loss: 0.22606098651885986
Batch 38/64 loss: 0.21919071674346924
Batch 39/64 loss: 0.22977912425994873
Batch 40/64 loss: 0.22576689720153809
Batch 41/64 loss: 0.22063994407653809
Batch 42/64 loss: 0.2369234561920166
Batch 43/64 loss: 0.22160100936889648
Batch 44/64 loss: 0.21551930904388428
Batch 45/64 loss: 0.22565007209777832
Batch 46/64 loss: 0.22365427017211914
Batch 47/64 loss: 0.22201460599899292
Batch 48/64 loss: 0.21954506635665894
Batch 49/64 loss: 0.2344149351119995
Batch 50/64 loss: 0.2241954803466797
Batch 51/64 loss: 0.22573107481002808
Batch 52/64 loss: 0.21694636344909668
Batch 53/64 loss: 0.21671032905578613
Batch 54/64 loss: 0.23173272609710693
Batch 55/64 loss: 0.23210018873214722
Batch 56/64 loss: 0.22189593315124512
Batch 57/64 loss: 0.22639524936676025
Batch 58/64 loss: 0.21899759769439697
Batch 59/64 loss: 0.2343997359275818
Batch 60/64 loss: 0.22677963972091675
Batch 61/64 loss: 0.2297317385673523
Batch 62/64 loss: 0.22059905529022217
Batch 63/64 loss: 0.21240508556365967
Batch 64/64 loss: 0.22035151720046997
Epoch 305  Train loss: 0.22297161209817026  Val loss: 0.2710779800857465
Epoch 306
-------------------------------
Batch 1/64 loss: 0.21020865440368652
Batch 2/64 loss: 0.2167540192604065
Batch 3/64 loss: 0.222703754901886
Batch 4/64 loss: 0.22158217430114746
Batch 5/64 loss: 0.2157440185546875
Batch 6/64 loss: 0.2181771993637085
Batch 7/64 loss: 0.22747236490249634
Batch 8/64 loss: 0.22345471382141113
Batch 9/64 loss: 0.21439385414123535
Batch 10/64 loss: 0.21624070405960083
Batch 11/64 loss: 0.2238391637802124
Batch 12/64 loss: 0.2161417007446289
Batch 13/64 loss: 0.22900497913360596
Batch 14/64 loss: 0.21560674905776978
Batch 15/64 loss: 0.21732401847839355
Batch 16/64 loss: 0.2241937518119812
Batch 17/64 loss: 0.22278213500976562
Batch 18/64 loss: 0.21619445085525513
Batch 19/64 loss: 0.22671222686767578
Batch 20/64 loss: 0.22258663177490234
Batch 21/64 loss: 0.22504258155822754
Batch 22/64 loss: 0.2207798957824707
Batch 23/64 loss: 0.23018193244934082
Batch 24/64 loss: 0.21777427196502686
Batch 25/64 loss: 0.22473233938217163
Batch 26/64 loss: 0.23216235637664795
Batch 27/64 loss: 0.22213959693908691
Batch 28/64 loss: 0.22648632526397705
Batch 29/64 loss: 0.22519022226333618
Batch 30/64 loss: 0.22438669204711914
Batch 31/64 loss: 0.22131365537643433
Batch 32/64 loss: 0.21906417608261108
Batch 33/64 loss: 0.22521328926086426
Batch 34/64 loss: 0.23132407665252686
Batch 35/64 loss: 0.21880662441253662
Batch 36/64 loss: 0.22864043712615967
Batch 37/64 loss: 0.2197858691215515
Batch 38/64 loss: 0.22302287817001343
Batch 39/64 loss: 0.22513270378112793
Batch 40/64 loss: 0.2328367829322815
Batch 41/64 loss: 0.22919470071792603
Batch 42/64 loss: 0.2274988889694214
Batch 43/64 loss: 0.22774338722229004
Batch 44/64 loss: 0.21709764003753662
Batch 45/64 loss: 0.2285010814666748
Batch 46/64 loss: 0.23525595664978027
Batch 47/64 loss: 0.2197054624557495
Batch 48/64 loss: 0.23133254051208496
Batch 49/64 loss: 0.22721195220947266
Batch 50/64 loss: 0.21857237815856934
Batch 51/64 loss: 0.21820151805877686
Batch 52/64 loss: 0.21714353561401367
Batch 53/64 loss: 0.22023367881774902
Batch 54/64 loss: 0.23225903511047363
Batch 55/64 loss: 0.22358036041259766
Batch 56/64 loss: 0.22445857524871826
Batch 57/64 loss: 0.2182544469833374
Batch 58/64 loss: 0.21784085035324097
Batch 59/64 loss: 0.22007977962493896
Batch 60/64 loss: 0.21498143672943115
Batch 61/64 loss: 0.2272244691848755
Batch 62/64 loss: 0.23061925172805786
Batch 63/64 loss: 0.22226959466934204
Batch 64/64 loss: 0.22685503959655762
Epoch 306  Train loss: 0.22297311016157562  Val loss: 0.269614011561338
Epoch 307
-------------------------------
Batch 1/64 loss: 0.22455233335494995
Batch 2/64 loss: 0.21600401401519775
Batch 3/64 loss: 0.21972990036010742
Batch 4/64 loss: 0.22217518091201782
Batch 5/64 loss: 0.21728837490081787
Batch 6/64 loss: 0.21532726287841797
Batch 7/64 loss: 0.22143864631652832
Batch 8/64 loss: 0.22919976711273193
Batch 9/64 loss: 0.2155640721321106
Batch 10/64 loss: 0.21548056602478027
Batch 11/64 loss: 0.22395706176757812
Batch 12/64 loss: 0.22592931985855103
Batch 13/64 loss: 0.2224034070968628
Batch 14/64 loss: 0.2203303575515747
Batch 15/64 loss: 0.21732854843139648
Batch 16/64 loss: 0.22367310523986816
Batch 17/64 loss: 0.2188870906829834
Batch 18/64 loss: 0.2247902750968933
Batch 19/64 loss: 0.22717797756195068
Batch 20/64 loss: 0.21838176250457764
Batch 21/64 loss: 0.22584164142608643
Batch 22/64 loss: 0.222669780254364
Batch 23/64 loss: 0.2220158576965332
Batch 24/64 loss: 0.22706711292266846
Batch 25/64 loss: 0.22084248065948486
Batch 26/64 loss: 0.2334233522415161
Batch 27/64 loss: 0.22201353311538696
Batch 28/64 loss: 0.22172105312347412
Batch 29/64 loss: 0.21928274631500244
Batch 30/64 loss: 0.23689579963684082
Batch 31/64 loss: 0.21393489837646484
Batch 32/64 loss: 0.21638554334640503
Batch 33/64 loss: 0.22403907775878906
Batch 34/64 loss: 0.22268545627593994
Batch 35/64 loss: 0.21868181228637695
Batch 36/64 loss: 0.2362140417098999
Batch 37/64 loss: 0.21930921077728271
Batch 38/64 loss: 0.22502237558364868
Batch 39/64 loss: 0.2340756058692932
Batch 40/64 loss: 0.2264881134033203
Batch 41/64 loss: 0.2307313084602356
Batch 42/64 loss: 0.2243853211402893
Batch 43/64 loss: 0.2234262228012085
Batch 44/64 loss: 0.21569442749023438
Batch 45/64 loss: 0.21933794021606445
Batch 46/64 loss: 0.23614490032196045
Batch 47/64 loss: 0.22125029563903809
Batch 48/64 loss: 0.20980775356292725
Batch 49/64 loss: 0.2229088544845581
Batch 50/64 loss: 0.22207432985305786
Batch 51/64 loss: 0.21766293048858643
Batch 52/64 loss: 0.21643733978271484
Batch 53/64 loss: 0.22056150436401367
Batch 54/64 loss: 0.21876919269561768
Batch 55/64 loss: 0.22151631116867065
Batch 56/64 loss: 0.22887569665908813
Batch 57/64 loss: 0.22248148918151855
Batch 58/64 loss: 0.2225988507270813
Batch 59/64 loss: 0.21947813034057617
Batch 60/64 loss: 0.23101961612701416
Batch 61/64 loss: 0.22216343879699707
Batch 62/64 loss: 0.23052167892456055
Batch 63/64 loss: 0.22510039806365967
Batch 64/64 loss: 0.22724783420562744
Epoch 307  Train loss: 0.22277038938858928  Val loss: 0.2696504578557621
Epoch 308
-------------------------------
Batch 1/64 loss: 0.22337394952774048
Batch 2/64 loss: 0.22839558124542236
Batch 3/64 loss: 0.21814602613449097
Batch 4/64 loss: 0.22249913215637207
Batch 5/64 loss: 0.21868544816970825
Batch 6/64 loss: 0.22049874067306519
Batch 7/64 loss: 0.22072118520736694
Batch 8/64 loss: 0.2244601845741272
Batch 9/64 loss: 0.22123301029205322
Batch 10/64 loss: 0.23018473386764526
Batch 11/64 loss: 0.22185158729553223
Batch 12/64 loss: 0.2275073528289795
Batch 13/64 loss: 0.22455966472625732
Batch 14/64 loss: 0.21915072202682495
Batch 15/64 loss: 0.21842527389526367
Batch 16/64 loss: 0.219077467918396
Batch 17/64 loss: 0.21778780221939087
Batch 18/64 loss: 0.22144997119903564
Batch 19/64 loss: 0.22054612636566162
Batch 20/64 loss: 0.23365581035614014
Batch 21/64 loss: 0.22115182876586914
Batch 22/64 loss: 0.2245280146598816
Batch 23/64 loss: 0.21903353929519653
Batch 24/64 loss: 0.22641521692276
Batch 25/64 loss: 0.22949236631393433
Batch 26/64 loss: 0.21630090475082397
Batch 27/64 loss: 0.21512728929519653
Batch 28/64 loss: 0.21407479047775269
Batch 29/64 loss: 0.2256130576133728
Batch 30/64 loss: 0.2309119701385498
Batch 31/64 loss: 0.223504900932312
Batch 32/64 loss: 0.22017133235931396
Batch 33/64 loss: 0.2197248935699463
Batch 34/64 loss: 0.21890926361083984
Batch 35/64 loss: 0.21840274333953857
Batch 36/64 loss: 0.2171439528465271
Batch 37/64 loss: 0.21792840957641602
Batch 38/64 loss: 0.21924316883087158
Batch 39/64 loss: 0.21382379531860352
Batch 40/64 loss: 0.23922514915466309
Batch 41/64 loss: 0.2263498306274414
Batch 42/64 loss: 0.22467190027236938
Batch 43/64 loss: 0.2205122709274292
Batch 44/64 loss: 0.2234203815460205
Batch 45/64 loss: 0.2244964838027954
Batch 46/64 loss: 0.2307412028312683
Batch 47/64 loss: 0.22274959087371826
Batch 48/64 loss: 0.22281962633132935
Batch 49/64 loss: 0.21795415878295898
Batch 50/64 loss: 0.21188998222351074
Batch 51/64 loss: 0.22192686796188354
Batch 52/64 loss: 0.2297753095626831
Batch 53/64 loss: 0.22687602043151855
Batch 54/64 loss: 0.22252357006072998
Batch 55/64 loss: 0.22841691970825195
Batch 56/64 loss: 0.21339523792266846
Batch 57/64 loss: 0.22426700592041016
Batch 58/64 loss: 0.23337340354919434
Batch 59/64 loss: 0.23010331392288208
Batch 60/64 loss: 0.2314925193786621
Batch 61/64 loss: 0.2205263376235962
Batch 62/64 loss: 0.217476487159729
Batch 63/64 loss: 0.22947978973388672
Batch 64/64 loss: 0.24126321077346802
Epoch 308  Train loss: 0.22304505063038246  Val loss: 0.26969376175673965
Epoch 309
-------------------------------
Batch 1/64 loss: 0.22057008743286133
Batch 2/64 loss: 0.23216629028320312
Batch 3/64 loss: 0.2298576831817627
Batch 4/64 loss: 0.22707688808441162
Batch 5/64 loss: 0.23058390617370605
Batch 6/64 loss: 0.23523908853530884
Batch 7/64 loss: 0.2246713638305664
Batch 8/64 loss: 0.2149064540863037
Batch 9/64 loss: 0.23043835163116455
Batch 10/64 loss: 0.2230621576309204
Batch 11/64 loss: 0.21792864799499512
Batch 12/64 loss: 0.2173171043395996
Batch 13/64 loss: 0.21757656335830688
Batch 14/64 loss: 0.21774673461914062
Batch 15/64 loss: 0.22245407104492188
Batch 16/64 loss: 0.22156518697738647
Batch 17/64 loss: 0.2331830859184265
Batch 18/64 loss: 0.22572749853134155
Batch 19/64 loss: 0.22054022550582886
Batch 20/64 loss: 0.21773552894592285
Batch 21/64 loss: 0.23697888851165771
Batch 22/64 loss: 0.22273683547973633
Batch 23/64 loss: 0.21646267175674438
Batch 24/64 loss: 0.2302735447883606
Batch 25/64 loss: 0.21956121921539307
Batch 26/64 loss: 0.231988787651062
Batch 27/64 loss: 0.2316206693649292
Batch 28/64 loss: 0.21897763013839722
Batch 29/64 loss: 0.21690285205841064
Batch 30/64 loss: 0.2229015827178955
Batch 31/64 loss: 0.21823608875274658
Batch 32/64 loss: 0.21818417310714722
Batch 33/64 loss: 0.22401434183120728
Batch 34/64 loss: 0.22499990463256836
Batch 35/64 loss: 0.22250837087631226
Batch 36/64 loss: 0.21264445781707764
Batch 37/64 loss: 0.2165592908859253
Batch 38/64 loss: 0.22279852628707886
Batch 39/64 loss: 0.21614372730255127
Batch 40/64 loss: 0.22576236724853516
Batch 41/64 loss: 0.22454017400741577
Batch 42/64 loss: 0.22434699535369873
Batch 43/64 loss: 0.21908587217330933
Batch 44/64 loss: 0.21858304738998413
Batch 45/64 loss: 0.22884315252304077
Batch 46/64 loss: 0.226406991481781
Batch 47/64 loss: 0.22304463386535645
Batch 48/64 loss: 0.2244856357574463
Batch 49/64 loss: 0.22113609313964844
Batch 50/64 loss: 0.22294116020202637
Batch 51/64 loss: 0.22399836778640747
Batch 52/64 loss: 0.21064633131027222
Batch 53/64 loss: 0.23191964626312256
Batch 54/64 loss: 0.2300553321838379
Batch 55/64 loss: 0.21736228466033936
Batch 56/64 loss: 0.21903401613235474
Batch 57/64 loss: 0.22335869073867798
Batch 58/64 loss: 0.21017378568649292
Batch 59/64 loss: 0.2284366488456726
Batch 60/64 loss: 0.22021102905273438
Batch 61/64 loss: 0.21239936351776123
Batch 62/64 loss: 0.22199445962905884
Batch 63/64 loss: 0.22444546222686768
Batch 64/64 loss: 0.22100281715393066
Epoch 309  Train loss: 0.22280477075015798  Val loss: 0.26912193507263343
Epoch 310
-------------------------------
Batch 1/64 loss: 0.22404015064239502
Batch 2/64 loss: 0.21858012676239014
Batch 3/64 loss: 0.2245088815689087
Batch 4/64 loss: 0.22144615650177002
Batch 5/64 loss: 0.23195326328277588
Batch 6/64 loss: 0.2253817319869995
Batch 7/64 loss: 0.2194657325744629
Batch 8/64 loss: 0.22138530015945435
Batch 9/64 loss: 0.2206292748451233
Batch 10/64 loss: 0.2239169478416443
Batch 11/64 loss: 0.20951354503631592
Batch 12/64 loss: 0.2186894416809082
Batch 13/64 loss: 0.2168945074081421
Batch 14/64 loss: 0.21598470211029053
Batch 15/64 loss: 0.2190449833869934
Batch 16/64 loss: 0.22258788347244263
Batch 17/64 loss: 0.2218027114868164
Batch 18/64 loss: 0.21850603818893433
Batch 19/64 loss: 0.21185505390167236
Batch 20/64 loss: 0.22149962186813354
Batch 21/64 loss: 0.223244309425354
Batch 22/64 loss: 0.21950793266296387
Batch 23/64 loss: 0.2200080156326294
Batch 24/64 loss: 0.22420990467071533
Batch 25/64 loss: 0.22758138179779053
Batch 26/64 loss: 0.2249234914779663
Batch 27/64 loss: 0.21023380756378174
Batch 28/64 loss: 0.22063153982162476
Batch 29/64 loss: 0.22049707174301147
Batch 30/64 loss: 0.21855229139328003
Batch 31/64 loss: 0.23092150688171387
Batch 32/64 loss: 0.21966934204101562
Batch 33/64 loss: 0.21951985359191895
Batch 34/64 loss: 0.21213185787200928
Batch 35/64 loss: 0.2202804684638977
Batch 36/64 loss: 0.2167806625366211
Batch 37/64 loss: 0.22110891342163086
Batch 38/64 loss: 0.21836435794830322
Batch 39/64 loss: 0.23332083225250244
Batch 40/64 loss: 0.22613239288330078
Batch 41/64 loss: 0.21500712633132935
Batch 42/64 loss: 0.2222285270690918
Batch 43/64 loss: 0.22061312198638916
Batch 44/64 loss: 0.22082310914993286
Batch 45/64 loss: 0.2233717441558838
Batch 46/64 loss: 0.22795867919921875
Batch 47/64 loss: 0.21672934293746948
Batch 48/64 loss: 0.2138603925704956
Batch 49/64 loss: 0.22901368141174316
Batch 50/64 loss: 0.2153903841972351
Batch 51/64 loss: 0.22603082656860352
Batch 52/64 loss: 0.22421979904174805
Batch 53/64 loss: 0.22907304763793945
Batch 54/64 loss: 0.2186734676361084
Batch 55/64 loss: 0.23276114463806152
Batch 56/64 loss: 0.23007822036743164
Batch 57/64 loss: 0.21978706121444702
Batch 58/64 loss: 0.22865009307861328
Batch 59/64 loss: 0.22796064615249634
Batch 60/64 loss: 0.22442257404327393
Batch 61/64 loss: 0.22196006774902344
Batch 62/64 loss: 0.22462880611419678
Batch 63/64 loss: 0.22012484073638916
Batch 64/64 loss: 0.22572046518325806
Epoch 310  Train loss: 0.2217719692809909  Val loss: 0.26899899117315756
Saving best model, epoch: 310
Epoch 311
-------------------------------
Batch 1/64 loss: 0.21843880414962769
Batch 2/64 loss: 0.2267146110534668
Batch 3/64 loss: 0.2221720814704895
Batch 4/64 loss: 0.21987807750701904
Batch 5/64 loss: 0.22379940748214722
Batch 6/64 loss: 0.21305644512176514
Batch 7/64 loss: 0.21616202592849731
Batch 8/64 loss: 0.21744704246520996
Batch 9/64 loss: 0.22018861770629883
Batch 10/64 loss: 0.21593308448791504
Batch 11/64 loss: 0.2200750708580017
Batch 12/64 loss: 0.22252380847930908
Batch 13/64 loss: 0.2208716869354248
Batch 14/64 loss: 0.23001420497894287
Batch 15/64 loss: 0.22575277090072632
Batch 16/64 loss: 0.23303747177124023
Batch 17/64 loss: 0.22624289989471436
Batch 18/64 loss: 0.21843814849853516
Batch 19/64 loss: 0.21472036838531494
Batch 20/64 loss: 0.21766448020935059
Batch 21/64 loss: 0.22690331935882568
Batch 22/64 loss: 0.22162920236587524
Batch 23/64 loss: 0.22498035430908203
Batch 24/64 loss: 0.22738981246948242
Batch 25/64 loss: 0.22874563932418823
Batch 26/64 loss: 0.22819066047668457
Batch 27/64 loss: 0.22058779001235962
Batch 28/64 loss: 0.22058379650115967
Batch 29/64 loss: 0.22967469692230225
Batch 30/64 loss: 0.22668194770812988
Batch 31/64 loss: 0.227203369140625
Batch 32/64 loss: 0.21252083778381348
Batch 33/64 loss: 0.22164100408554077
Batch 34/64 loss: 0.23007267713546753
Batch 35/64 loss: 0.21989870071411133
Batch 36/64 loss: 0.2155839204788208
Batch 37/64 loss: 0.22933810949325562
Batch 38/64 loss: 0.23367226123809814
Batch 39/64 loss: 0.2185857892036438
Batch 40/64 loss: 0.2210085391998291
Batch 41/64 loss: 0.22382110357284546
Batch 42/64 loss: 0.22242677211761475
Batch 43/64 loss: 0.23784005641937256
Batch 44/64 loss: 0.21983683109283447
Batch 45/64 loss: 0.22070467472076416
Batch 46/64 loss: 0.2238062620162964
Batch 47/64 loss: 0.21549499034881592
Batch 48/64 loss: 0.2181689739227295
Batch 49/64 loss: 0.22438514232635498
Batch 50/64 loss: 0.21743428707122803
Batch 51/64 loss: 0.21566593647003174
Batch 52/64 loss: 0.22092926502227783
Batch 53/64 loss: 0.22004210948944092
Batch 54/64 loss: 0.22218942642211914
Batch 55/64 loss: 0.222833514213562
Batch 56/64 loss: 0.21816933155059814
Batch 57/64 loss: 0.224157452583313
Batch 58/64 loss: 0.2318788766860962
Batch 59/64 loss: 0.22234201431274414
Batch 60/64 loss: 0.22136831283569336
Batch 61/64 loss: 0.22174429893493652
Batch 62/64 loss: 0.21816033124923706
Batch 63/64 loss: 0.23136824369430542
Batch 64/64 loss: 0.21985435485839844
Epoch 311  Train loss: 0.222551882500742  Val loss: 0.2703663989440682
Epoch 312
-------------------------------
Batch 1/64 loss: 0.22471129894256592
Batch 2/64 loss: 0.22549718618392944
Batch 3/64 loss: 0.2200225591659546
Batch 4/64 loss: 0.22921323776245117
Batch 5/64 loss: 0.22254890203475952
Batch 6/64 loss: 0.22845125198364258
Batch 7/64 loss: 0.228268563747406
Batch 8/64 loss: 0.22207534313201904
Batch 9/64 loss: 0.21778851747512817
Batch 10/64 loss: 0.22553128004074097
Batch 11/64 loss: 0.2138974666595459
Batch 12/64 loss: 0.22554433345794678
Batch 13/64 loss: 0.21786141395568848
Batch 14/64 loss: 0.2210317850112915
Batch 15/64 loss: 0.2223759889602661
Batch 16/64 loss: 0.24002587795257568
Batch 17/64 loss: 0.22809576988220215
Batch 18/64 loss: 0.21295857429504395
Batch 19/64 loss: 0.22146087884902954
Batch 20/64 loss: 0.21789181232452393
Batch 21/64 loss: 0.21953868865966797
Batch 22/64 loss: 0.22109949588775635
Batch 23/64 loss: 0.2120036482810974
Batch 24/64 loss: 0.2194218635559082
Batch 25/64 loss: 0.22184616327285767
Batch 26/64 loss: 0.22422873973846436
Batch 27/64 loss: 0.22880244255065918
Batch 28/64 loss: 0.22193634510040283
Batch 29/64 loss: 0.21817940473556519
Batch 30/64 loss: 0.24034082889556885
Batch 31/64 loss: 0.2226707935333252
Batch 32/64 loss: 0.226173996925354
Batch 33/64 loss: 0.22055363655090332
Batch 34/64 loss: 0.22816342115402222
Batch 35/64 loss: 0.2205747365951538
Batch 36/64 loss: 0.21882951259613037
Batch 37/64 loss: 0.2112804651260376
Batch 38/64 loss: 0.2267436385154724
Batch 39/64 loss: 0.22144782543182373
Batch 40/64 loss: 0.21979230642318726
Batch 41/64 loss: 0.22182196378707886
Batch 42/64 loss: 0.22511756420135498
Batch 43/64 loss: 0.21421366930007935
Batch 44/64 loss: 0.21790361404418945
Batch 45/64 loss: 0.22070211172103882
Batch 46/64 loss: 0.21479976177215576
Batch 47/64 loss: 0.23644524812698364
Batch 48/64 loss: 0.21939170360565186
Batch 49/64 loss: 0.2385297417640686
Batch 50/64 loss: 0.22416526079177856
Batch 51/64 loss: 0.23650699853897095
Batch 52/64 loss: 0.21586394309997559
Batch 53/64 loss: 0.21175235509872437
Batch 54/64 loss: 0.22205007076263428
Batch 55/64 loss: 0.21781611442565918
Batch 56/64 loss: 0.22129058837890625
Batch 57/64 loss: 0.22502541542053223
Batch 58/64 loss: 0.22361981868743896
Batch 59/64 loss: 0.21810829639434814
Batch 60/64 loss: 0.22053194046020508
Batch 61/64 loss: 0.22654253244400024
Batch 62/64 loss: 0.21451234817504883
Batch 63/64 loss: 0.22322732210159302
Batch 64/64 loss: 0.22748959064483643
Epoch 312  Train loss: 0.2225793815126606  Val loss: 0.2693585710427196
Epoch 313
-------------------------------
Batch 1/64 loss: 0.21886134147644043
Batch 2/64 loss: 0.22208356857299805
Batch 3/64 loss: 0.21764105558395386
Batch 4/64 loss: 0.2219206690788269
Batch 5/64 loss: 0.2276616096496582
Batch 6/64 loss: 0.218353271484375
Batch 7/64 loss: 0.22281712293624878
Batch 8/64 loss: 0.2258005142211914
Batch 9/64 loss: 0.22635579109191895
Batch 10/64 loss: 0.21547895669937134
Batch 11/64 loss: 0.217576265335083
Batch 12/64 loss: 0.2321171760559082
Batch 13/64 loss: 0.23143815994262695
Batch 14/64 loss: 0.21757149696350098
Batch 15/64 loss: 0.22054070234298706
Batch 16/64 loss: 0.23116934299468994
Batch 17/64 loss: 0.2203616499900818
Batch 18/64 loss: 0.21591174602508545
Batch 19/64 loss: 0.21710669994354248
Batch 20/64 loss: 0.22512418031692505
Batch 21/64 loss: 0.21690517663955688
Batch 22/64 loss: 0.22006189823150635
Batch 23/64 loss: 0.23806583881378174
Batch 24/64 loss: 0.2256232500076294
Batch 25/64 loss: 0.21456265449523926
Batch 26/64 loss: 0.21573734283447266
Batch 27/64 loss: 0.21320778131484985
Batch 28/64 loss: 0.21172279119491577
Batch 29/64 loss: 0.22163128852844238
Batch 30/64 loss: 0.21603429317474365
Batch 31/64 loss: 0.21568667888641357
Batch 32/64 loss: 0.2255314588546753
Batch 33/64 loss: 0.22291046380996704
Batch 34/64 loss: 0.222525954246521
Batch 35/64 loss: 0.22337687015533447
Batch 36/64 loss: 0.2235594391822815
Batch 37/64 loss: 0.22601115703582764
Batch 38/64 loss: 0.21848785877227783
Batch 39/64 loss: 0.21988290548324585
Batch 40/64 loss: 0.21134334802627563
Batch 41/64 loss: 0.22525852918624878
Batch 42/64 loss: 0.232349693775177
Batch 43/64 loss: 0.22376489639282227
Batch 44/64 loss: 0.2224627137184143
Batch 45/64 loss: 0.22652703523635864
Batch 46/64 loss: 0.22679048776626587
Batch 47/64 loss: 0.2252141237258911
Batch 48/64 loss: 0.22442114353179932
Batch 49/64 loss: 0.21984511613845825
Batch 50/64 loss: 0.22877371311187744
Batch 51/64 loss: 0.23433935642242432
Batch 52/64 loss: 0.21919071674346924
Batch 53/64 loss: 0.2239300012588501
Batch 54/64 loss: 0.21583044528961182
Batch 55/64 loss: 0.2255932092666626
Batch 56/64 loss: 0.21403521299362183
Batch 57/64 loss: 0.22254490852355957
Batch 58/64 loss: 0.21499717235565186
Batch 59/64 loss: 0.22552943229675293
Batch 60/64 loss: 0.22905969619750977
Batch 61/64 loss: 0.21641743183135986
Batch 62/64 loss: 0.22223258018493652
Batch 63/64 loss: 0.22383785247802734
Batch 64/64 loss: 0.22389709949493408
Epoch 313  Train loss: 0.2221118127598482  Val loss: 0.26981507298053337
Epoch 314
-------------------------------
Batch 1/64 loss: 0.21807080507278442
Batch 2/64 loss: 0.21253204345703125
Batch 3/64 loss: 0.21782159805297852
Batch 4/64 loss: 0.21374636888504028
Batch 5/64 loss: 0.22596216201782227
Batch 6/64 loss: 0.22295266389846802
Batch 7/64 loss: 0.23412787914276123
Batch 8/64 loss: 0.21835744380950928
Batch 9/64 loss: 0.2292788028717041
Batch 10/64 loss: 0.22322523593902588
Batch 11/64 loss: 0.23376572132110596
Batch 12/64 loss: 0.2187017798423767
Batch 13/64 loss: 0.21766752004623413
Batch 14/64 loss: 0.22562628984451294
Batch 15/64 loss: 0.22120070457458496
Batch 16/64 loss: 0.22677922248840332
Batch 17/64 loss: 0.23153650760650635
Batch 18/64 loss: 0.22161853313446045
Batch 19/64 loss: 0.22457170486450195
Batch 20/64 loss: 0.2216300368309021
Batch 21/64 loss: 0.2146528959274292
Batch 22/64 loss: 0.2253894805908203
Batch 23/64 loss: 0.21324491500854492
Batch 24/64 loss: 0.2230778932571411
Batch 25/64 loss: 0.22452807426452637
Batch 26/64 loss: 0.22010892629623413
Batch 27/64 loss: 0.2276759147644043
Batch 28/64 loss: 0.23151612281799316
Batch 29/64 loss: 0.2293209433555603
Batch 30/64 loss: 0.21870166063308716
Batch 31/64 loss: 0.209151029586792
Batch 32/64 loss: 0.21354281902313232
Batch 33/64 loss: 0.21736359596252441
Batch 34/64 loss: 0.21359705924987793
Batch 35/64 loss: 0.22684478759765625
Batch 36/64 loss: 0.2267206907272339
Batch 37/64 loss: 0.22439205646514893
Batch 38/64 loss: 0.2181020975112915
Batch 39/64 loss: 0.22006219625473022
Batch 40/64 loss: 0.21884959936141968
Batch 41/64 loss: 0.22855490446090698
Batch 42/64 loss: 0.22334396839141846
Batch 43/64 loss: 0.22003984451293945
Batch 44/64 loss: 0.2253449559211731
Batch 45/64 loss: 0.21860432624816895
Batch 46/64 loss: 0.2130589485168457
Batch 47/64 loss: 0.2178821563720703
Batch 48/64 loss: 0.2278766632080078
Batch 49/64 loss: 0.22626930475234985
Batch 50/64 loss: 0.2235279679298401
Batch 51/64 loss: 0.2300351858139038
Batch 52/64 loss: 0.23109227418899536
Batch 53/64 loss: 0.22411656379699707
Batch 54/64 loss: 0.22720271348953247
Batch 55/64 loss: 0.2199830412864685
Batch 56/64 loss: 0.2114884853363037
Batch 57/64 loss: 0.21949446201324463
Batch 58/64 loss: 0.21532130241394043
Batch 59/64 loss: 0.21734929084777832
Batch 60/64 loss: 0.22492802143096924
Batch 61/64 loss: 0.21735656261444092
Batch 62/64 loss: 0.22139346599578857
Batch 63/64 loss: 0.2256983518600464
Batch 64/64 loss: 0.2239985466003418
Epoch 314  Train loss: 0.22202317574444938  Val loss: 0.2694427747906688
Epoch 315
-------------------------------
Batch 1/64 loss: 0.21410059928894043
Batch 2/64 loss: 0.2268047332763672
Batch 3/64 loss: 0.21304786205291748
Batch 4/64 loss: 0.22096318006515503
Batch 5/64 loss: 0.2225726842880249
Batch 6/64 loss: 0.21557402610778809
Batch 7/64 loss: 0.2203505039215088
Batch 8/64 loss: 0.21600621938705444
Batch 9/64 loss: 0.21637195348739624
Batch 10/64 loss: 0.23354321718215942
Batch 11/64 loss: 0.21963143348693848
Batch 12/64 loss: 0.23214036226272583
Batch 13/64 loss: 0.21780627965927124
Batch 14/64 loss: 0.23465192317962646
Batch 15/64 loss: 0.21712183952331543
Batch 16/64 loss: 0.2213228940963745
Batch 17/64 loss: 0.22225892543792725
Batch 18/64 loss: 0.21923446655273438
Batch 19/64 loss: 0.21651029586791992
Batch 20/64 loss: 0.2118547558784485
Batch 21/64 loss: 0.22070372104644775
Batch 22/64 loss: 0.21521544456481934
Batch 23/64 loss: 0.21723270416259766
Batch 24/64 loss: 0.22282803058624268
Batch 25/64 loss: 0.23025137186050415
Batch 26/64 loss: 0.23030537366867065
Batch 27/64 loss: 0.2202763557434082
Batch 28/64 loss: 0.2226334810256958
Batch 29/64 loss: 0.22179436683654785
Batch 30/64 loss: 0.22695618867874146
Batch 31/64 loss: 0.20497751235961914
Batch 32/64 loss: 0.21451640129089355
Batch 33/64 loss: 0.22828173637390137
Batch 34/64 loss: 0.21763038635253906
Batch 35/64 loss: 0.21410024166107178
Batch 36/64 loss: 0.2212209701538086
Batch 37/64 loss: 0.2180405855178833
Batch 38/64 loss: 0.22268563508987427
Batch 39/64 loss: 0.21682780981063843
Batch 40/64 loss: 0.21227866411209106
Batch 41/64 loss: 0.21711283922195435
Batch 42/64 loss: 0.2248365879058838
Batch 43/64 loss: 0.22602128982543945
Batch 44/64 loss: 0.21017199754714966
Batch 45/64 loss: 0.21828579902648926
Batch 46/64 loss: 0.22165238857269287
Batch 47/64 loss: 0.21957337856292725
Batch 48/64 loss: 0.21815818548202515
Batch 49/64 loss: 0.2280576229095459
Batch 50/64 loss: 0.22473174333572388
Batch 51/64 loss: 0.22745966911315918
Batch 52/64 loss: 0.22940504550933838
Batch 53/64 loss: 0.21634483337402344
Batch 54/64 loss: 0.21921098232269287
Batch 55/64 loss: 0.21978014707565308
Batch 56/64 loss: 0.2297753095626831
Batch 57/64 loss: 0.2201572060585022
Batch 58/64 loss: 0.22378098964691162
Batch 59/64 loss: 0.2186892032623291
Batch 60/64 loss: 0.2262827754020691
Batch 61/64 loss: 0.22330164909362793
Batch 62/64 loss: 0.216691255569458
Batch 63/64 loss: 0.2211000919342041
Batch 64/64 loss: 0.21632415056228638
Epoch 315  Train loss: 0.22075998806485944  Val loss: 0.2703587572599195
Epoch 316
-------------------------------
Batch 1/64 loss: 0.22776591777801514
Batch 2/64 loss: 0.2145746946334839
Batch 3/64 loss: 0.22017276287078857
Batch 4/64 loss: 0.2204216718673706
Batch 5/64 loss: 0.21720373630523682
Batch 6/64 loss: 0.2131580114364624
Batch 7/64 loss: 0.20886337757110596
Batch 8/64 loss: 0.2182072401046753
Batch 9/64 loss: 0.2259618639945984
Batch 10/64 loss: 0.22084712982177734
Batch 11/64 loss: 0.21609115600585938
Batch 12/64 loss: 0.2275736927986145
Batch 13/64 loss: 0.21421027183532715
Batch 14/64 loss: 0.21836340427398682
Batch 15/64 loss: 0.23071420192718506
Batch 16/64 loss: 0.2173604965209961
Batch 17/64 loss: 0.21920734643936157
Batch 18/64 loss: 0.22048383951187134
Batch 19/64 loss: 0.21713930368423462
Batch 20/64 loss: 0.21438562870025635
Batch 21/64 loss: 0.2180686593055725
Batch 22/64 loss: 0.22342604398727417
Batch 23/64 loss: 0.21805310249328613
Batch 24/64 loss: 0.22523778676986694
Batch 25/64 loss: 0.23478412628173828
Batch 26/64 loss: 0.2299443483352661
Batch 27/64 loss: 0.2152385115623474
Batch 28/64 loss: 0.22144556045532227
Batch 29/64 loss: 0.21826279163360596
Batch 30/64 loss: 0.22113388776779175
Batch 31/64 loss: 0.22591686248779297
Batch 32/64 loss: 0.22782278060913086
Batch 33/64 loss: 0.22562658786773682
Batch 34/64 loss: 0.21462517976760864
Batch 35/64 loss: 0.21131330728530884
Batch 36/64 loss: 0.2223556637763977
Batch 37/64 loss: 0.21627455949783325
Batch 38/64 loss: 0.23029029369354248
Batch 39/64 loss: 0.22397565841674805
Batch 40/64 loss: 0.21753454208374023
Batch 41/64 loss: 0.22295153141021729
Batch 42/64 loss: 0.20787209272384644
Batch 43/64 loss: 0.2194194793701172
Batch 44/64 loss: 0.22401463985443115
Batch 45/64 loss: 0.222131609916687
Batch 46/64 loss: 0.21593749523162842
Batch 47/64 loss: 0.22041118144989014
Batch 48/64 loss: 0.21797704696655273
Batch 49/64 loss: 0.21898877620697021
Batch 50/64 loss: 0.2201937437057495
Batch 51/64 loss: 0.238031268119812
Batch 52/64 loss: 0.22179687023162842
Batch 53/64 loss: 0.22118473052978516
Batch 54/64 loss: 0.22843730449676514
Batch 55/64 loss: 0.2203788161277771
Batch 56/64 loss: 0.22325670719146729
Batch 57/64 loss: 0.22516357898712158
Batch 58/64 loss: 0.21923959255218506
Batch 59/64 loss: 0.22072935104370117
Batch 60/64 loss: 0.2232731580734253
Batch 61/64 loss: 0.21822285652160645
Batch 62/64 loss: 0.2290557622909546
Batch 63/64 loss: 0.21377909183502197
Batch 64/64 loss: 0.22442811727523804
Epoch 316  Train loss: 0.22093809843063356  Val loss: 0.27036145851784144
Epoch 317
-------------------------------
Batch 1/64 loss: 0.22370576858520508
Batch 2/64 loss: 0.21209317445755005
Batch 3/64 loss: 0.21482932567596436
Batch 4/64 loss: 0.22143983840942383
Batch 5/64 loss: 0.22761595249176025
Batch 6/64 loss: 0.22534090280532837
Batch 7/64 loss: 0.21047329902648926
Batch 8/64 loss: 0.21776628494262695
Batch 9/64 loss: 0.22068804502487183
Batch 10/64 loss: 0.22185170650482178
Batch 11/64 loss: 0.21267902851104736
Batch 12/64 loss: 0.21697765588760376
Batch 13/64 loss: 0.211450457572937
Batch 14/64 loss: 0.219457745552063
Batch 15/64 loss: 0.22467225790023804
Batch 16/64 loss: 0.21137690544128418
Batch 17/64 loss: 0.21503567695617676
Batch 18/64 loss: 0.21896064281463623
Batch 19/64 loss: 0.22210752964019775
Batch 20/64 loss: 0.21158039569854736
Batch 21/64 loss: 0.22090506553649902
Batch 22/64 loss: 0.22585457563400269
Batch 23/64 loss: 0.22721630334854126
Batch 24/64 loss: 0.22689604759216309
Batch 25/64 loss: 0.22119581699371338
Batch 26/64 loss: 0.22320330142974854
Batch 27/64 loss: 0.22320526838302612
Batch 28/64 loss: 0.2169104814529419
Batch 29/64 loss: 0.22299158573150635
Batch 30/64 loss: 0.21085530519485474
Batch 31/64 loss: 0.22563982009887695
Batch 32/64 loss: 0.2196635603904724
Batch 33/64 loss: 0.21880435943603516
Batch 34/64 loss: 0.22876131534576416
Batch 35/64 loss: 0.22767215967178345
Batch 36/64 loss: 0.20967721939086914
Batch 37/64 loss: 0.22591745853424072
Batch 38/64 loss: 0.23447954654693604
Batch 39/64 loss: 0.23837512731552124
Batch 40/64 loss: 0.23206031322479248
Batch 41/64 loss: 0.21982711553573608
Batch 42/64 loss: 0.21590566635131836
Batch 43/64 loss: 0.21376502513885498
Batch 44/64 loss: 0.21443206071853638
Batch 45/64 loss: 0.21942877769470215
Batch 46/64 loss: 0.21628671884536743
Batch 47/64 loss: 0.22340965270996094
Batch 48/64 loss: 0.22100740671157837
Batch 49/64 loss: 0.2294067144393921
Batch 50/64 loss: 0.22646641731262207
Batch 51/64 loss: 0.22032225131988525
Batch 52/64 loss: 0.22933363914489746
Batch 53/64 loss: 0.21452581882476807
Batch 54/64 loss: 0.2180001139640808
Batch 55/64 loss: 0.21989279985427856
Batch 56/64 loss: 0.22094756364822388
Batch 57/64 loss: 0.2241528034210205
Batch 58/64 loss: 0.22231388092041016
Batch 59/64 loss: 0.21473348140716553
Batch 60/64 loss: 0.2219746708869934
Batch 61/64 loss: 0.21096336841583252
Batch 62/64 loss: 0.21734470129013062
Batch 63/64 loss: 0.2191627025604248
Batch 64/64 loss: 0.23111200332641602
Epoch 317  Train loss: 0.2206639149609734  Val loss: 0.2704310544168007
Epoch 318
-------------------------------
Batch 1/64 loss: 0.21587204933166504
Batch 2/64 loss: 0.219843327999115
Batch 3/64 loss: 0.22261971235275269
Batch 4/64 loss: 0.2207043170928955
Batch 5/64 loss: 0.22408390045166016
Batch 6/64 loss: 0.22188067436218262
Batch 7/64 loss: 0.21659469604492188
Batch 8/64 loss: 0.21712583303451538
Batch 9/64 loss: 0.23048484325408936
Batch 10/64 loss: 0.217829167842865
Batch 11/64 loss: 0.22045868635177612
Batch 12/64 loss: 0.2129136323928833
Batch 13/64 loss: 0.23498892784118652
Batch 14/64 loss: 0.22014915943145752
Batch 15/64 loss: 0.2174816131591797
Batch 16/64 loss: 0.22862225770950317
Batch 17/64 loss: 0.21178144216537476
Batch 18/64 loss: 0.22150743007659912
Batch 19/64 loss: 0.2138965129852295
Batch 20/64 loss: 0.21876031160354614
Batch 21/64 loss: 0.22909367084503174
Batch 22/64 loss: 0.21588045358657837
Batch 23/64 loss: 0.22981929779052734
Batch 24/64 loss: 0.2195693850517273
Batch 25/64 loss: 0.20775866508483887
Batch 26/64 loss: 0.23222637176513672
Batch 27/64 loss: 0.22090673446655273
Batch 28/64 loss: 0.2198430299758911
Batch 29/64 loss: 0.21418273448944092
Batch 30/64 loss: 0.2238423228263855
Batch 31/64 loss: 0.21625542640686035
Batch 32/64 loss: 0.2201654314994812
Batch 33/64 loss: 0.2174011468887329
Batch 34/64 loss: 0.21968698501586914
Batch 35/64 loss: 0.22265851497650146
Batch 36/64 loss: 0.22640502452850342
Batch 37/64 loss: 0.2271677851676941
Batch 38/64 loss: 0.21876859664916992
Batch 39/64 loss: 0.21837544441223145
Batch 40/64 loss: 0.2108675241470337
Batch 41/64 loss: 0.2208172082901001
Batch 42/64 loss: 0.2076817750930786
Batch 43/64 loss: 0.22394007444381714
Batch 44/64 loss: 0.21990174055099487
Batch 45/64 loss: 0.2311421036720276
Batch 46/64 loss: 0.21858763694763184
Batch 47/64 loss: 0.2128831148147583
Batch 48/64 loss: 0.2160794734954834
Batch 49/64 loss: 0.21480441093444824
Batch 50/64 loss: 0.21550339460372925
Batch 51/64 loss: 0.2185637354850769
Batch 52/64 loss: 0.2090015411376953
Batch 53/64 loss: 0.22946536540985107
Batch 54/64 loss: 0.21271276473999023
Batch 55/64 loss: 0.2203218936920166
Batch 56/64 loss: 0.21855568885803223
Batch 57/64 loss: 0.22797775268554688
Batch 58/64 loss: 0.22289294004440308
Batch 59/64 loss: 0.21961236000061035
Batch 60/64 loss: 0.22400295734405518
Batch 61/64 loss: 0.22113382816314697
Batch 62/64 loss: 0.22255408763885498
Batch 63/64 loss: 0.22658801078796387
Batch 64/64 loss: 0.21813338994979858
Epoch 318  Train loss: 0.2201850500761294  Val loss: 0.26980115068737176
Epoch 319
-------------------------------
Batch 1/64 loss: 0.21610212326049805
Batch 2/64 loss: 0.22641175985336304
Batch 3/64 loss: 0.22704100608825684
Batch 4/64 loss: 0.207189679145813
Batch 5/64 loss: 0.21970611810684204
Batch 6/64 loss: 0.2293633222579956
Batch 7/64 loss: 0.2209254503250122
Batch 8/64 loss: 0.23017752170562744
Batch 9/64 loss: 0.22422361373901367
Batch 10/64 loss: 0.20735734701156616
Batch 11/64 loss: 0.2129356861114502
Batch 12/64 loss: 0.21545761823654175
Batch 13/64 loss: 0.22885972261428833
Batch 14/64 loss: 0.2215639352798462
Batch 15/64 loss: 0.20881855487823486
Batch 16/64 loss: 0.214769184589386
Batch 17/64 loss: 0.21846598386764526
Batch 18/64 loss: 0.2368963360786438
Batch 19/64 loss: 0.21333861351013184
Batch 20/64 loss: 0.2141258716583252
Batch 21/64 loss: 0.21647751331329346
Batch 22/64 loss: 0.21630334854125977
Batch 23/64 loss: 0.2184140682220459
Batch 24/64 loss: 0.21072280406951904
Batch 25/64 loss: 0.2216058373451233
Batch 26/64 loss: 0.2160428762435913
Batch 27/64 loss: 0.22777509689331055
Batch 28/64 loss: 0.2205209732055664
Batch 29/64 loss: 0.2141333818435669
Batch 30/64 loss: 0.224817156791687
Batch 31/64 loss: 0.2184131145477295
Batch 32/64 loss: 0.2137758731842041
Batch 33/64 loss: 0.21746623516082764
Batch 34/64 loss: 0.223310649394989
Batch 35/64 loss: 0.2200251817703247
Batch 36/64 loss: 0.21550524234771729
Batch 37/64 loss: 0.21557503938674927
Batch 38/64 loss: 0.22532802820205688
Batch 39/64 loss: 0.2132023572921753
Batch 40/64 loss: 0.21484506130218506
Batch 41/64 loss: 0.22073543071746826
Batch 42/64 loss: 0.23050463199615479
Batch 43/64 loss: 0.2180391550064087
Batch 44/64 loss: 0.22148925065994263
Batch 45/64 loss: 0.22251451015472412
Batch 46/64 loss: 0.2204951047897339
Batch 47/64 loss: 0.22130751609802246
Batch 48/64 loss: 0.22473466396331787
Batch 49/64 loss: 0.21655166149139404
Batch 50/64 loss: 0.2223724126815796
Batch 51/64 loss: 0.22427070140838623
Batch 52/64 loss: 0.21919631958007812
Batch 53/64 loss: 0.2302539348602295
Batch 54/64 loss: 0.2221771478652954
Batch 55/64 loss: 0.22430336475372314
Batch 56/64 loss: 0.22592693567276
Batch 57/64 loss: 0.21748459339141846
Batch 58/64 loss: 0.22797608375549316
Batch 59/64 loss: 0.2203863263130188
Batch 60/64 loss: 0.22184056043624878
Batch 61/64 loss: 0.22229081392288208
Batch 62/64 loss: 0.22485917806625366
Batch 63/64 loss: 0.2191680669784546
Batch 64/64 loss: 0.23864221572875977
Epoch 319  Train loss: 0.22048391080370136  Val loss: 0.2695914822345747
Epoch 320
-------------------------------
Batch 1/64 loss: 0.20835518836975098
Batch 2/64 loss: 0.22067707777023315
Batch 3/64 loss: 0.22403717041015625
Batch 4/64 loss: 0.20974749326705933
Batch 5/64 loss: 0.21489131450653076
Batch 6/64 loss: 0.21999084949493408
Batch 7/64 loss: 0.21715962886810303
Batch 8/64 loss: 0.21946513652801514
Batch 9/64 loss: 0.2161102294921875
Batch 10/64 loss: 0.21712875366210938
Batch 11/64 loss: 0.21523845195770264
Batch 12/64 loss: 0.2149975299835205
Batch 13/64 loss: 0.214155912399292
Batch 14/64 loss: 0.21789222955703735
Batch 15/64 loss: 0.21591001749038696
Batch 16/64 loss: 0.22301626205444336
Batch 17/64 loss: 0.20885860919952393
Batch 18/64 loss: 0.21948570013046265
Batch 19/64 loss: 0.21541613340377808
Batch 20/64 loss: 0.2251756191253662
Batch 21/64 loss: 0.22130268812179565
Batch 22/64 loss: 0.21502971649169922
Batch 23/64 loss: 0.21063274145126343
Batch 24/64 loss: 0.21229559183120728
Batch 25/64 loss: 0.20967936515808105
Batch 26/64 loss: 0.22880280017852783
Batch 27/64 loss: 0.22670990228652954
Batch 28/64 loss: 0.2152044177055359
Batch 29/64 loss: 0.22213596105575562
Batch 30/64 loss: 0.22309184074401855
Batch 31/64 loss: 0.21925514936447144
Batch 32/64 loss: 0.22827112674713135
Batch 33/64 loss: 0.21860629320144653
Batch 34/64 loss: 0.22414803504943848
Batch 35/64 loss: 0.22448378801345825
Batch 36/64 loss: 0.22846674919128418
Batch 37/64 loss: 0.21885818243026733
Batch 38/64 loss: 0.21785509586334229
Batch 39/64 loss: 0.21328872442245483
Batch 40/64 loss: 0.2204732894897461
Batch 41/64 loss: 0.21805667877197266
Batch 42/64 loss: 0.21650004386901855
Batch 43/64 loss: 0.21545040607452393
Batch 44/64 loss: 0.2167189121246338
Batch 45/64 loss: 0.23786324262619019
Batch 46/64 loss: 0.21870267391204834
Batch 47/64 loss: 0.21981501579284668
Batch 48/64 loss: 0.21903496980667114
Batch 49/64 loss: 0.22572141885757446
Batch 50/64 loss: 0.21689069271087646
Batch 51/64 loss: 0.23051214218139648
Batch 52/64 loss: 0.21453875303268433
Batch 53/64 loss: 0.2336631417274475
Batch 54/64 loss: 0.22168362140655518
Batch 55/64 loss: 0.22724950313568115
Batch 56/64 loss: 0.22034215927124023
Batch 57/64 loss: 0.2197878360748291
Batch 58/64 loss: 0.2300577163696289
Batch 59/64 loss: 0.2241886854171753
Batch 60/64 loss: 0.22810733318328857
Batch 61/64 loss: 0.22046279907226562
Batch 62/64 loss: 0.22783273458480835
Batch 63/64 loss: 0.22211861610412598
Batch 64/64 loss: 0.22775375843048096
Epoch 320  Train loss: 0.22011631657095515  Val loss: 0.2706621532997315
Epoch 321
-------------------------------
Batch 1/64 loss: 0.21943414211273193
Batch 2/64 loss: 0.2201446294784546
Batch 3/64 loss: 0.21638822555541992
Batch 4/64 loss: 0.2271406650543213
Batch 5/64 loss: 0.2097306251525879
Batch 6/64 loss: 0.21704351902008057
Batch 7/64 loss: 0.22323572635650635
Batch 8/64 loss: 0.22141015529632568
Batch 9/64 loss: 0.2218812108039856
Batch 10/64 loss: 0.22390413284301758
Batch 11/64 loss: 0.23224246501922607
Batch 12/64 loss: 0.21742689609527588
Batch 13/64 loss: 0.21981191635131836
Batch 14/64 loss: 0.2240772247314453
Batch 15/64 loss: 0.22704869508743286
Batch 16/64 loss: 0.22809374332427979
Batch 17/64 loss: 0.22369056940078735
Batch 18/64 loss: 0.23182237148284912
Batch 19/64 loss: 0.22227591276168823
Batch 20/64 loss: 0.21881884336471558
Batch 21/64 loss: 0.2162647843360901
Batch 22/64 loss: 0.21656113862991333
Batch 23/64 loss: 0.21681368350982666
Batch 24/64 loss: 0.2226959466934204
Batch 25/64 loss: 0.21595734357833862
Batch 26/64 loss: 0.21655642986297607
Batch 27/64 loss: 0.21695029735565186
Batch 28/64 loss: 0.22883445024490356
Batch 29/64 loss: 0.2260342836380005
Batch 30/64 loss: 0.22622931003570557
Batch 31/64 loss: 0.2142784595489502
Batch 32/64 loss: 0.22159695625305176
Batch 33/64 loss: 0.2110753059387207
Batch 34/64 loss: 0.2132585048675537
Batch 35/64 loss: 0.21505767107009888
Batch 36/64 loss: 0.2236308455467224
Batch 37/64 loss: 0.22306841611862183
Batch 38/64 loss: 0.23065364360809326
Batch 39/64 loss: 0.21729910373687744
Batch 40/64 loss: 0.21665185689926147
Batch 41/64 loss: 0.22258538007736206
Batch 42/64 loss: 0.22075217962265015
Batch 43/64 loss: 0.2270205020904541
Batch 44/64 loss: 0.21615219116210938
Batch 45/64 loss: 0.2224014401435852
Batch 46/64 loss: 0.21894395351409912
Batch 47/64 loss: 0.2283782958984375
Batch 48/64 loss: 0.22580480575561523
Batch 49/64 loss: 0.21830594539642334
Batch 50/64 loss: 0.2176758050918579
Batch 51/64 loss: 0.21421945095062256
Batch 52/64 loss: 0.21727824211120605
Batch 53/64 loss: 0.22053146362304688
Batch 54/64 loss: 0.22173762321472168
Batch 55/64 loss: 0.2183765172958374
Batch 56/64 loss: 0.2241363525390625
Batch 57/64 loss: 0.2109280824661255
Batch 58/64 loss: 0.21411538124084473
Batch 59/64 loss: 0.211870014667511
Batch 60/64 loss: 0.22512412071228027
Batch 61/64 loss: 0.21839159727096558
Batch 62/64 loss: 0.22288364171981812
Batch 63/64 loss: 0.21949243545532227
Batch 64/64 loss: 0.21458089351654053
Epoch 321  Train loss: 0.22044127361447202  Val loss: 0.26887117874171723
Saving best model, epoch: 321
Epoch 322
-------------------------------
Batch 1/64 loss: 0.20729291439056396
Batch 2/64 loss: 0.20536494255065918
Batch 3/64 loss: 0.21577537059783936
Batch 4/64 loss: 0.21459722518920898
Batch 5/64 loss: 0.21014583110809326
Batch 6/64 loss: 0.22223782539367676
Batch 7/64 loss: 0.20475280284881592
Batch 8/64 loss: 0.217276930809021
Batch 9/64 loss: 0.2234712839126587
Batch 10/64 loss: 0.212013840675354
Batch 11/64 loss: 0.22443825006484985
Batch 12/64 loss: 0.21141588687896729
Batch 13/64 loss: 0.2074373960494995
Batch 14/64 loss: 0.22108089923858643
Batch 15/64 loss: 0.21658635139465332
Batch 16/64 loss: 0.2273915410041809
Batch 17/64 loss: 0.2276287078857422
Batch 18/64 loss: 0.23359262943267822
Batch 19/64 loss: 0.228105366230011
Batch 20/64 loss: 0.2221466302871704
Batch 21/64 loss: 0.2266749143600464
Batch 22/64 loss: 0.2150055170059204
Batch 23/64 loss: 0.21612918376922607
Batch 24/64 loss: 0.2143254280090332
Batch 25/64 loss: 0.22192412614822388
Batch 26/64 loss: 0.2269434928894043
Batch 27/64 loss: 0.22158706188201904
Batch 28/64 loss: 0.2253708839416504
Batch 29/64 loss: 0.2234797477722168
Batch 30/64 loss: 0.22367125749588013
Batch 31/64 loss: 0.22390365600585938
Batch 32/64 loss: 0.21431183815002441
Batch 33/64 loss: 0.21404463052749634
Batch 34/64 loss: 0.221585214138031
Batch 35/64 loss: 0.21677696704864502
Batch 36/64 loss: 0.22017300128936768
Batch 37/64 loss: 0.226315438747406
Batch 38/64 loss: 0.21592754125595093
Batch 39/64 loss: 0.22491604089736938
Batch 40/64 loss: 0.22500061988830566
Batch 41/64 loss: 0.22258228063583374
Batch 42/64 loss: 0.22891902923583984
Batch 43/64 loss: 0.2115778923034668
Batch 44/64 loss: 0.22531914710998535
Batch 45/64 loss: 0.21864718198776245
Batch 46/64 loss: 0.22258269786834717
Batch 47/64 loss: 0.22197306156158447
Batch 48/64 loss: 0.21532201766967773
Batch 49/64 loss: 0.21932178735733032
Batch 50/64 loss: 0.2235766053199768
Batch 51/64 loss: 0.2285817265510559
Batch 52/64 loss: 0.21517443656921387
Batch 53/64 loss: 0.21740657091140747
Batch 54/64 loss: 0.21568512916564941
Batch 55/64 loss: 0.21484661102294922
Batch 56/64 loss: 0.2197514772415161
Batch 57/64 loss: 0.2192615270614624
Batch 58/64 loss: 0.21556580066680908
Batch 59/64 loss: 0.21879756450653076
Batch 60/64 loss: 0.22865808010101318
Batch 61/64 loss: 0.22331780195236206
Batch 62/64 loss: 0.21841931343078613
Batch 63/64 loss: 0.2215505838394165
Batch 64/64 loss: 0.2318969964981079
Epoch 322  Train loss: 0.21978949425267238  Val loss: 0.2698565389692169
Epoch 323
-------------------------------
Batch 1/64 loss: 0.2189580202102661
Batch 2/64 loss: 0.2169002890586853
Batch 3/64 loss: 0.2296878695487976
Batch 4/64 loss: 0.20678091049194336
Batch 5/64 loss: 0.21365588903427124
Batch 6/64 loss: 0.22658652067184448
Batch 7/64 loss: 0.2166021466255188
Batch 8/64 loss: 0.22063308954238892
Batch 9/64 loss: 0.21878772974014282
Batch 10/64 loss: 0.22090935707092285
Batch 11/64 loss: 0.22164344787597656
Batch 12/64 loss: 0.21780914068222046
Batch 13/64 loss: 0.21954715251922607
Batch 14/64 loss: 0.21879136562347412
Batch 15/64 loss: 0.22788560390472412
Batch 16/64 loss: 0.22059601545333862
Batch 17/64 loss: 0.21399188041687012
Batch 18/64 loss: 0.22933930158615112
Batch 19/64 loss: 0.21839302778244019
Batch 20/64 loss: 0.2180260419845581
Batch 21/64 loss: 0.22206807136535645
Batch 22/64 loss: 0.21577489376068115
Batch 23/64 loss: 0.21879756450653076
Batch 24/64 loss: 0.20646846294403076
Batch 25/64 loss: 0.22210991382598877
Batch 26/64 loss: 0.21149951219558716
Batch 27/64 loss: 0.22223329544067383
Batch 28/64 loss: 0.21381837129592896
Batch 29/64 loss: 0.2201860547065735
Batch 30/64 loss: 0.2266690731048584
Batch 31/64 loss: 0.21783804893493652
Batch 32/64 loss: 0.22153162956237793
Batch 33/64 loss: 0.22121942043304443
Batch 34/64 loss: 0.22348541021347046
Batch 35/64 loss: 0.21777945756912231
Batch 36/64 loss: 0.21705400943756104
Batch 37/64 loss: 0.21628451347351074
Batch 38/64 loss: 0.21633929014205933
Batch 39/64 loss: 0.21462559700012207
Batch 40/64 loss: 0.22552555799484253
Batch 41/64 loss: 0.21040791273117065
Batch 42/64 loss: 0.21856510639190674
Batch 43/64 loss: 0.21719884872436523
Batch 44/64 loss: 0.22461706399917603
Batch 45/64 loss: 0.22531002759933472
Batch 46/64 loss: 0.23005831241607666
Batch 47/64 loss: 0.2275240421295166
Batch 48/64 loss: 0.21519899368286133
Batch 49/64 loss: 0.2148059606552124
Batch 50/64 loss: 0.21699625253677368
Batch 51/64 loss: 0.2198784351348877
Batch 52/64 loss: 0.21730566024780273
Batch 53/64 loss: 0.21347802877426147
Batch 54/64 loss: 0.21986377239227295
Batch 55/64 loss: 0.23014390468597412
Batch 56/64 loss: 0.2240537405014038
Batch 57/64 loss: 0.21501058340072632
Batch 58/64 loss: 0.2147892713546753
Batch 59/64 loss: 0.2223297357559204
Batch 60/64 loss: 0.2189866304397583
Batch 61/64 loss: 0.21866202354431152
Batch 62/64 loss: 0.21747839450836182
Batch 63/64 loss: 0.21934545040130615
Batch 64/64 loss: 0.22372251749038696
Epoch 323  Train loss: 0.2193981645154018  Val loss: 0.2696971864634773
Epoch 324
-------------------------------
Batch 1/64 loss: 0.2198622226715088
Batch 2/64 loss: 0.22200357913970947
Batch 3/64 loss: 0.22611486911773682
Batch 4/64 loss: 0.2115340232849121
Batch 5/64 loss: 0.22790026664733887
Batch 6/64 loss: 0.21278154850006104
Batch 7/64 loss: 0.20985448360443115
Batch 8/64 loss: 0.21667879819869995
Batch 9/64 loss: 0.21570169925689697
Batch 10/64 loss: 0.21612024307250977
Batch 11/64 loss: 0.221194326877594
Batch 12/64 loss: 0.21561163663864136
Batch 13/64 loss: 0.2190260887145996
Batch 14/64 loss: 0.21903842687606812
Batch 15/64 loss: 0.223016619682312
Batch 16/64 loss: 0.2204042673110962
Batch 17/64 loss: 0.2175300121307373
Batch 18/64 loss: 0.22384780645370483
Batch 19/64 loss: 0.2134975790977478
Batch 20/64 loss: 0.22777920961380005
Batch 21/64 loss: 0.2182844877243042
Batch 22/64 loss: 0.23368555307388306
Batch 23/64 loss: 0.2211281657218933
Batch 24/64 loss: 0.221138596534729
Batch 25/64 loss: 0.2218429446220398
Batch 26/64 loss: 0.23840928077697754
Batch 27/64 loss: 0.21707671880722046
Batch 28/64 loss: 0.2262871265411377
Batch 29/64 loss: 0.21508270502090454
Batch 30/64 loss: 0.21346515417099
Batch 31/64 loss: 0.21498119831085205
Batch 32/64 loss: 0.217107892036438
Batch 33/64 loss: 0.21952080726623535
Batch 34/64 loss: 0.2181679606437683
Batch 35/64 loss: 0.22100651264190674
Batch 36/64 loss: 0.21381592750549316
Batch 37/64 loss: 0.2313278317451477
Batch 38/64 loss: 0.2214430570602417
Batch 39/64 loss: 0.21867072582244873
Batch 40/64 loss: 0.22032701969146729
Batch 41/64 loss: 0.22701454162597656
Batch 42/64 loss: 0.2216329574584961
Batch 43/64 loss: 0.21546173095703125
Batch 44/64 loss: 0.22683721780776978
Batch 45/64 loss: 0.22062015533447266
Batch 46/64 loss: 0.2112971544265747
Batch 47/64 loss: 0.21479058265686035
Batch 48/64 loss: 0.22935646772384644
Batch 49/64 loss: 0.21814286708831787
Batch 50/64 loss: 0.21690762042999268
Batch 51/64 loss: 0.22829389572143555
Batch 52/64 loss: 0.21353453397750854
Batch 53/64 loss: 0.22442352771759033
Batch 54/64 loss: 0.2198237180709839
Batch 55/64 loss: 0.21653997898101807
Batch 56/64 loss: 0.22423428297042847
Batch 57/64 loss: 0.21261203289031982
Batch 58/64 loss: 0.2165292501449585
Batch 59/64 loss: 0.2243594527244568
Batch 60/64 loss: 0.21572750806808472
Batch 61/64 loss: 0.2290956974029541
Batch 62/64 loss: 0.21988874673843384
Batch 63/64 loss: 0.21577918529510498
Batch 64/64 loss: 0.21478748321533203
Epoch 324  Train loss: 0.22001978182325177  Val loss: 0.2692116210141133
Epoch 325
-------------------------------
Batch 1/64 loss: 0.22291386127471924
Batch 2/64 loss: 0.2127143144607544
Batch 3/64 loss: 0.2251896858215332
Batch 4/64 loss: 0.21349799633026123
Batch 5/64 loss: 0.2266942858695984
Batch 6/64 loss: 0.21829545497894287
Batch 7/64 loss: 0.21528363227844238
Batch 8/64 loss: 0.22579169273376465
Batch 9/64 loss: 0.22271305322647095
Batch 10/64 loss: 0.22372901439666748
Batch 11/64 loss: 0.22246921062469482
Batch 12/64 loss: 0.21447670459747314
Batch 13/64 loss: 0.2150188684463501
Batch 14/64 loss: 0.21662241220474243
Batch 15/64 loss: 0.21233731508255005
Batch 16/64 loss: 0.22428357601165771
Batch 17/64 loss: 0.21260148286819458
Batch 18/64 loss: 0.20946776866912842
Batch 19/64 loss: 0.21090292930603027
Batch 20/64 loss: 0.20826351642608643
Batch 21/64 loss: 0.22302407026290894
Batch 22/64 loss: 0.20757699012756348
Batch 23/64 loss: 0.21330225467681885
Batch 24/64 loss: 0.21295201778411865
Batch 25/64 loss: 0.22699356079101562
Batch 26/64 loss: 0.23038285970687866
Batch 27/64 loss: 0.21913468837738037
Batch 28/64 loss: 0.214890718460083
Batch 29/64 loss: 0.22303688526153564
Batch 30/64 loss: 0.21638429164886475
Batch 31/64 loss: 0.21941721439361572
Batch 32/64 loss: 0.2199808955192566
Batch 33/64 loss: 0.22582745552062988
Batch 34/64 loss: 0.21761631965637207
Batch 35/64 loss: 0.21401768922805786
Batch 36/64 loss: 0.21765637397766113
Batch 37/64 loss: 0.2207103967666626
Batch 38/64 loss: 0.22269928455352783
Batch 39/64 loss: 0.22775065898895264
Batch 40/64 loss: 0.22182941436767578
Batch 41/64 loss: 0.21992278099060059
Batch 42/64 loss: 0.22043585777282715
Batch 43/64 loss: 0.22616147994995117
Batch 44/64 loss: 0.22711056470870972
Batch 45/64 loss: 0.22715306282043457
Batch 46/64 loss: 0.21482664346694946
Batch 47/64 loss: 0.21747267246246338
Batch 48/64 loss: 0.2283899188041687
Batch 49/64 loss: 0.216525137424469
Batch 50/64 loss: 0.22146999835968018
Batch 51/64 loss: 0.21251016855239868
Batch 52/64 loss: 0.2327796220779419
Batch 53/64 loss: 0.22080659866333008
Batch 54/64 loss: 0.2255801558494568
Batch 55/64 loss: 0.21940433979034424
Batch 56/64 loss: 0.22407793998718262
Batch 57/64 loss: 0.22325944900512695
Batch 58/64 loss: 0.22484004497528076
Batch 59/64 loss: 0.22468829154968262
Batch 60/64 loss: 0.21063745021820068
Batch 61/64 loss: 0.21824026107788086
Batch 62/64 loss: 0.21884876489639282
Batch 63/64 loss: 0.2192707657814026
Batch 64/64 loss: 0.21421539783477783
Epoch 325  Train loss: 0.21966312679589964  Val loss: 0.2694816329225232
Epoch 326
-------------------------------
Batch 1/64 loss: 0.22563934326171875
Batch 2/64 loss: 0.22080552577972412
Batch 3/64 loss: 0.21869826316833496
Batch 4/64 loss: 0.2102900743484497
Batch 5/64 loss: 0.21566486358642578
Batch 6/64 loss: 0.210740327835083
Batch 7/64 loss: 0.2240990400314331
Batch 8/64 loss: 0.21675240993499756
Batch 9/64 loss: 0.22116172313690186
Batch 10/64 loss: 0.21355772018432617
Batch 11/64 loss: 0.21499258279800415
Batch 12/64 loss: 0.21534603834152222
Batch 13/64 loss: 0.22196602821350098
Batch 14/64 loss: 0.21128249168395996
Batch 15/64 loss: 0.22046315670013428
Batch 16/64 loss: 0.22231483459472656
Batch 17/64 loss: 0.2246241569519043
Batch 18/64 loss: 0.21051543951034546
Batch 19/64 loss: 0.22230571508407593
Batch 20/64 loss: 0.23218655586242676
Batch 21/64 loss: 0.21344947814941406
Batch 22/64 loss: 0.21841835975646973
Batch 23/64 loss: 0.22135019302368164
Batch 24/64 loss: 0.22881579399108887
Batch 25/64 loss: 0.22123301029205322
Batch 26/64 loss: 0.2179945707321167
Batch 27/64 loss: 0.219457745552063
Batch 28/64 loss: 0.2214730978012085
Batch 29/64 loss: 0.22437751293182373
Batch 30/64 loss: 0.21798419952392578
Batch 31/64 loss: 0.21763336658477783
Batch 32/64 loss: 0.21858203411102295
Batch 33/64 loss: 0.2078021764755249
Batch 34/64 loss: 0.21351420879364014
Batch 35/64 loss: 0.21632099151611328
Batch 36/64 loss: 0.21834814548492432
Batch 37/64 loss: 0.21710056066513062
Batch 38/64 loss: 0.22406643629074097
Batch 39/64 loss: 0.21689164638519287
Batch 40/64 loss: 0.21459728479385376
Batch 41/64 loss: 0.2212570309638977
Batch 42/64 loss: 0.2168065309524536
Batch 43/64 loss: 0.22012007236480713
Batch 44/64 loss: 0.22167599201202393
Batch 45/64 loss: 0.211248517036438
Batch 46/64 loss: 0.21480965614318848
Batch 47/64 loss: 0.21613377332687378
Batch 48/64 loss: 0.2315763235092163
Batch 49/64 loss: 0.23101377487182617
Batch 50/64 loss: 0.21706652641296387
Batch 51/64 loss: 0.2237757444381714
Batch 52/64 loss: 0.21611183881759644
Batch 53/64 loss: 0.21886026859283447
Batch 54/64 loss: 0.21887433528900146
Batch 55/64 loss: 0.21352773904800415
Batch 56/64 loss: 0.22343778610229492
Batch 57/64 loss: 0.21003705263137817
Batch 58/64 loss: 0.21426326036453247
Batch 59/64 loss: 0.21406763792037964
Batch 60/64 loss: 0.2247563600540161
Batch 61/64 loss: 0.21977871656417847
Batch 62/64 loss: 0.22333097457885742
Batch 63/64 loss: 0.21873998641967773
Batch 64/64 loss: 0.22303330898284912
Epoch 326  Train loss: 0.2188448938668943  Val loss: 0.268863066774873
Saving best model, epoch: 326
Epoch 327
-------------------------------
Batch 1/64 loss: 0.21391773223876953
Batch 2/64 loss: 0.2156437635421753
Batch 3/64 loss: 0.2057816982269287
Batch 4/64 loss: 0.2091611623764038
Batch 5/64 loss: 0.21786141395568848
Batch 6/64 loss: 0.2172638177871704
Batch 7/64 loss: 0.22013133764266968
Batch 8/64 loss: 0.21714502573013306
Batch 9/64 loss: 0.22607767581939697
Batch 10/64 loss: 0.21916401386260986
Batch 11/64 loss: 0.22591233253479004
Batch 12/64 loss: 0.225460946559906
Batch 13/64 loss: 0.21939659118652344
Batch 14/64 loss: 0.22635310888290405
Batch 15/64 loss: 0.22519946098327637
Batch 16/64 loss: 0.21515417098999023
Batch 17/64 loss: 0.2207096815109253
Batch 18/64 loss: 0.220761239528656
Batch 19/64 loss: 0.21135962009429932
Batch 20/64 loss: 0.21503448486328125
Batch 21/64 loss: 0.2216922640800476
Batch 22/64 loss: 0.22627192735671997
Batch 23/64 loss: 0.20901954174041748
Batch 24/64 loss: 0.21841341257095337
Batch 25/64 loss: 0.22189056873321533
Batch 26/64 loss: 0.2181159257888794
Batch 27/64 loss: 0.2219703197479248
Batch 28/64 loss: 0.2223747968673706
Batch 29/64 loss: 0.21893298625946045
Batch 30/64 loss: 0.21307110786437988
Batch 31/64 loss: 0.22705042362213135
Batch 32/64 loss: 0.21291524171829224
Batch 33/64 loss: 0.22853446006774902
Batch 34/64 loss: 0.2250380516052246
Batch 35/64 loss: 0.2204795479774475
Batch 36/64 loss: 0.2212216854095459
Batch 37/64 loss: 0.2217487096786499
Batch 38/64 loss: 0.215545654296875
Batch 39/64 loss: 0.21713536977767944
Batch 40/64 loss: 0.2248086929321289
Batch 41/64 loss: 0.2183353304862976
Batch 42/64 loss: 0.21298331022262573
Batch 43/64 loss: 0.22137248516082764
Batch 44/64 loss: 0.2164444923400879
Batch 45/64 loss: 0.22317492961883545
Batch 46/64 loss: 0.22516405582427979
Batch 47/64 loss: 0.2284144163131714
Batch 48/64 loss: 0.2211068868637085
Batch 49/64 loss: 0.21925151348114014
Batch 50/64 loss: 0.22341299057006836
Batch 51/64 loss: 0.21931713819503784
Batch 52/64 loss: 0.21207839250564575
Batch 53/64 loss: 0.22076880931854248
Batch 54/64 loss: 0.21308255195617676
Batch 55/64 loss: 0.2208818793296814
Batch 56/64 loss: 0.21575039625167847
Batch 57/64 loss: 0.22597193717956543
Batch 58/64 loss: 0.21907150745391846
Batch 59/64 loss: 0.2167060375213623
Batch 60/64 loss: 0.22330623865127563
Batch 61/64 loss: 0.21521711349487305
Batch 62/64 loss: 0.22399431467056274
Batch 63/64 loss: 0.22685813903808594
Batch 64/64 loss: 0.21827584505081177
Epoch 327  Train loss: 0.2196092818297592  Val loss: 0.2694272577148123
Epoch 328
-------------------------------
Batch 1/64 loss: 0.21608543395996094
Batch 2/64 loss: 0.2164456844329834
Batch 3/64 loss: 0.21144378185272217
Batch 4/64 loss: 0.21708881855010986
Batch 5/64 loss: 0.22275817394256592
Batch 6/64 loss: 0.21946680545806885
Batch 7/64 loss: 0.2202218770980835
Batch 8/64 loss: 0.21405965089797974
Batch 9/64 loss: 0.2231234312057495
Batch 10/64 loss: 0.2229354977607727
Batch 11/64 loss: 0.2267841100692749
Batch 12/64 loss: 0.21614694595336914
Batch 13/64 loss: 0.20998328924179077
Batch 14/64 loss: 0.22169780731201172
Batch 15/64 loss: 0.22359514236450195
Batch 16/64 loss: 0.217748761177063
Batch 17/64 loss: 0.2157028317451477
Batch 18/64 loss: 0.22238105535507202
Batch 19/64 loss: 0.21045374870300293
Batch 20/64 loss: 0.22043955326080322
Batch 21/64 loss: 0.20931100845336914
Batch 22/64 loss: 0.2200479507446289
Batch 23/64 loss: 0.21757233142852783
Batch 24/64 loss: 0.22040820121765137
Batch 25/64 loss: 0.21838301420211792
Batch 26/64 loss: 0.2271798849105835
Batch 27/64 loss: 0.22699183225631714
Batch 28/64 loss: 0.22962236404418945
Batch 29/64 loss: 0.21762323379516602
Batch 30/64 loss: 0.22010910511016846
Batch 31/64 loss: 0.21945947408676147
Batch 32/64 loss: 0.20676445960998535
Batch 33/64 loss: 0.2268628478050232
Batch 34/64 loss: 0.20866143703460693
Batch 35/64 loss: 0.2226719856262207
Batch 36/64 loss: 0.21127772331237793
Batch 37/64 loss: 0.2220233678817749
Batch 38/64 loss: 0.221327006816864
Batch 39/64 loss: 0.21236705780029297
Batch 40/64 loss: 0.21085500717163086
Batch 41/64 loss: 0.21535760164260864
Batch 42/64 loss: 0.21938204765319824
Batch 43/64 loss: 0.2270735502243042
Batch 44/64 loss: 0.22294831275939941
Batch 45/64 loss: 0.21474778652191162
Batch 46/64 loss: 0.226459801197052
Batch 47/64 loss: 0.21721971035003662
Batch 48/64 loss: 0.213406503200531
Batch 49/64 loss: 0.21353721618652344
Batch 50/64 loss: 0.22676777839660645
Batch 51/64 loss: 0.22042584419250488
Batch 52/64 loss: 0.2161271572113037
Batch 53/64 loss: 0.22312778234481812
Batch 54/64 loss: 0.22978895902633667
Batch 55/64 loss: 0.23045575618743896
Batch 56/64 loss: 0.2245560884475708
Batch 57/64 loss: 0.21537542343139648
Batch 58/64 loss: 0.22027099132537842
Batch 59/64 loss: 0.217115581035614
Batch 60/64 loss: 0.21390259265899658
Batch 61/64 loss: 0.21036028861999512
Batch 62/64 loss: 0.22336500883102417
Batch 63/64 loss: 0.2242109179496765
Batch 64/64 loss: 0.21669495105743408
Epoch 328  Train loss: 0.21908369578567205  Val loss: 0.26966016972597523
Epoch 329
-------------------------------
Batch 1/64 loss: 0.23097187280654907
Batch 2/64 loss: 0.223080575466156
Batch 3/64 loss: 0.21390187740325928
Batch 4/64 loss: 0.21939605474472046
Batch 5/64 loss: 0.2194775938987732
Batch 6/64 loss: 0.2128967046737671
Batch 7/64 loss: 0.2206323742866516
Batch 8/64 loss: 0.2187955379486084
Batch 9/64 loss: 0.2176661491394043
Batch 10/64 loss: 0.21486634016036987
Batch 11/64 loss: 0.2124028205871582
Batch 12/64 loss: 0.22232544422149658
Batch 13/64 loss: 0.22611194849014282
Batch 14/64 loss: 0.20973944664001465
Batch 15/64 loss: 0.21951806545257568
Batch 16/64 loss: 0.21469348669052124
Batch 17/64 loss: 0.22179239988327026
Batch 18/64 loss: 0.21973443031311035
Batch 19/64 loss: 0.21708589792251587
Batch 20/64 loss: 0.2316245436668396
Batch 21/64 loss: 0.21938550472259521
Batch 22/64 loss: 0.2178875207901001
Batch 23/64 loss: 0.2167765498161316
Batch 24/64 loss: 0.22398525476455688
Batch 25/64 loss: 0.21110576391220093
Batch 26/64 loss: 0.21613025665283203
Batch 27/64 loss: 0.22107923030853271
Batch 28/64 loss: 0.22318458557128906
Batch 29/64 loss: 0.2189115285873413
Batch 30/64 loss: 0.2236396074295044
Batch 31/64 loss: 0.206839919090271
Batch 32/64 loss: 0.2204364538192749
Batch 33/64 loss: 0.22518092393875122
Batch 34/64 loss: 0.22347748279571533
Batch 35/64 loss: 0.21310579776763916
Batch 36/64 loss: 0.21953028440475464
Batch 37/64 loss: 0.2197350263595581
Batch 38/64 loss: 0.2175999879837036
Batch 39/64 loss: 0.22030538320541382
Batch 40/64 loss: 0.21675360202789307
Batch 41/64 loss: 0.21603357791900635
Batch 42/64 loss: 0.21228080987930298
Batch 43/64 loss: 0.22206461429595947
Batch 44/64 loss: 0.22370564937591553
Batch 45/64 loss: 0.2170168161392212
Batch 46/64 loss: 0.2125720977783203
Batch 47/64 loss: 0.21898925304412842
Batch 48/64 loss: 0.21417230367660522
Batch 49/64 loss: 0.22096550464630127
Batch 50/64 loss: 0.22469818592071533
Batch 51/64 loss: 0.2139376401901245
Batch 52/64 loss: 0.20899856090545654
Batch 53/64 loss: 0.21564924716949463
Batch 54/64 loss: 0.22122865915298462
Batch 55/64 loss: 0.21188020706176758
Batch 56/64 loss: 0.21808916330337524
Batch 57/64 loss: 0.2212507724761963
Batch 58/64 loss: 0.22408175468444824
Batch 59/64 loss: 0.22977840900421143
Batch 60/64 loss: 0.2232779860496521
Batch 61/64 loss: 0.22260057926177979
Batch 62/64 loss: 0.23465538024902344
Batch 63/64 loss: 0.22494268417358398
Batch 64/64 loss: 0.22425603866577148
Epoch 329  Train loss: 0.21933844884236653  Val loss: 0.270222427509085
Epoch 330
-------------------------------
Batch 1/64 loss: 0.20837056636810303
Batch 2/64 loss: 0.2173570990562439
Batch 3/64 loss: 0.21628987789154053
Batch 4/64 loss: 0.21051490306854248
Batch 5/64 loss: 0.21998757123947144
Batch 6/64 loss: 0.22309637069702148
Batch 7/64 loss: 0.22421503067016602
Batch 8/64 loss: 0.22729307413101196
Batch 9/64 loss: 0.2257063388824463
Batch 10/64 loss: 0.21965539455413818
Batch 11/64 loss: 0.21513515710830688
Batch 12/64 loss: 0.22085773944854736
Batch 13/64 loss: 0.21966540813446045
Batch 14/64 loss: 0.22620248794555664
Batch 15/64 loss: 0.22185266017913818
Batch 16/64 loss: 0.21309077739715576
Batch 17/64 loss: 0.21615535020828247
Batch 18/64 loss: 0.22280877828598022
Batch 19/64 loss: 0.2235429883003235
Batch 20/64 loss: 0.21557581424713135
Batch 21/64 loss: 0.21112549304962158
Batch 22/64 loss: 0.2194398045539856
Batch 23/64 loss: 0.20955884456634521
Batch 24/64 loss: 0.21064424514770508
Batch 25/64 loss: 0.22455942630767822
Batch 26/64 loss: 0.21412158012390137
Batch 27/64 loss: 0.21020996570587158
Batch 28/64 loss: 0.21886783838272095
Batch 29/64 loss: 0.21494388580322266
Batch 30/64 loss: 0.21403449773788452
Batch 31/64 loss: 0.21956932544708252
Batch 32/64 loss: 0.2294411063194275
Batch 33/64 loss: 0.21434003114700317
Batch 34/64 loss: 0.21184247732162476
Batch 35/64 loss: 0.22745060920715332
Batch 36/64 loss: 0.21244490146636963
Batch 37/64 loss: 0.22678351402282715
Batch 38/64 loss: 0.22284144163131714
Batch 39/64 loss: 0.21968650817871094
Batch 40/64 loss: 0.21909469366073608
Batch 41/64 loss: 0.21835237741470337
Batch 42/64 loss: 0.22440451383590698
Batch 43/64 loss: 0.21986740827560425
Batch 44/64 loss: 0.21786481142044067
Batch 45/64 loss: 0.21807992458343506
Batch 46/64 loss: 0.2289522886276245
Batch 47/64 loss: 0.22260552644729614
Batch 48/64 loss: 0.22359633445739746
Batch 49/64 loss: 0.2288302183151245
Batch 50/64 loss: 0.21656203269958496
Batch 51/64 loss: 0.22646772861480713
Batch 52/64 loss: 0.2234973907470703
Batch 53/64 loss: 0.21901583671569824
Batch 54/64 loss: 0.2128831148147583
Batch 55/64 loss: 0.22444355487823486
Batch 56/64 loss: 0.21552324295043945
Batch 57/64 loss: 0.21596384048461914
Batch 58/64 loss: 0.21488535404205322
Batch 59/64 loss: 0.22125911712646484
Batch 60/64 loss: 0.22082656621932983
Batch 61/64 loss: 0.2097952961921692
Batch 62/64 loss: 0.23113620281219482
Batch 63/64 loss: 0.21453112363815308
Batch 64/64 loss: 0.22152447700500488
Epoch 330  Train loss: 0.21919781553979015  Val loss: 0.2687486197120955
Saving best model, epoch: 330
Epoch 331
-------------------------------
Batch 1/64 loss: 0.22140860557556152
Batch 2/64 loss: 0.21942079067230225
Batch 3/64 loss: 0.22031939029693604
Batch 4/64 loss: 0.21877515316009521
Batch 5/64 loss: 0.21491491794586182
Batch 6/64 loss: 0.2337421178817749
Batch 7/64 loss: 0.20583206415176392
Batch 8/64 loss: 0.2130821943283081
Batch 9/64 loss: 0.21762055158615112
Batch 10/64 loss: 0.22835427522659302
Batch 11/64 loss: 0.21743744611740112
Batch 12/64 loss: 0.20664095878601074
Batch 13/64 loss: 0.22022676467895508
Batch 14/64 loss: 0.2163705825805664
Batch 15/64 loss: 0.21695488691329956
Batch 16/64 loss: 0.2166263461112976
Batch 17/64 loss: 0.21653401851654053
Batch 18/64 loss: 0.22489160299301147
Batch 19/64 loss: 0.22420454025268555
Batch 20/64 loss: 0.23051059246063232
Batch 21/64 loss: 0.21200567483901978
Batch 22/64 loss: 0.22341597080230713
Batch 23/64 loss: 0.2149723768234253
Batch 24/64 loss: 0.2114396095275879
Batch 25/64 loss: 0.21891939640045166
Batch 26/64 loss: 0.21082818508148193
Batch 27/64 loss: 0.21798312664031982
Batch 28/64 loss: 0.224648118019104
Batch 29/64 loss: 0.22457432746887207
Batch 30/64 loss: 0.21552658081054688
Batch 31/64 loss: 0.2185678482055664
Batch 32/64 loss: 0.21738308668136597
Batch 33/64 loss: 0.20942866802215576
Batch 34/64 loss: 0.22681009769439697
Batch 35/64 loss: 0.23102045059204102
Batch 36/64 loss: 0.2148730754852295
Batch 37/64 loss: 0.2175481915473938
Batch 38/64 loss: 0.20873069763183594
Batch 39/64 loss: 0.21484637260437012
Batch 40/64 loss: 0.21491175889968872
Batch 41/64 loss: 0.2088022232055664
Batch 42/64 loss: 0.21058285236358643
Batch 43/64 loss: 0.21876060962677002
Batch 44/64 loss: 0.2110985517501831
Batch 45/64 loss: 0.22105610370635986
Batch 46/64 loss: 0.22474229335784912
Batch 47/64 loss: 0.21149420738220215
Batch 48/64 loss: 0.21490049362182617
Batch 49/64 loss: 0.20880144834518433
Batch 50/64 loss: 0.22141975164413452
Batch 51/64 loss: 0.21833699941635132
Batch 52/64 loss: 0.21360641717910767
Batch 53/64 loss: 0.21478497982025146
Batch 54/64 loss: 0.2059410810470581
Batch 55/64 loss: 0.21759319305419922
Batch 56/64 loss: 0.21956342458724976
Batch 57/64 loss: 0.21840965747833252
Batch 58/64 loss: 0.21761846542358398
Batch 59/64 loss: 0.21923744678497314
Batch 60/64 loss: 0.21467459201812744
Batch 61/64 loss: 0.2114166021347046
Batch 62/64 loss: 0.21475034952163696
Batch 63/64 loss: 0.21878504753112793
Batch 64/64 loss: 0.22135961055755615
Epoch 331  Train loss: 0.21732859471265006  Val loss: 0.26958434176199214
Epoch 332
-------------------------------
Batch 1/64 loss: 0.21987056732177734
Batch 2/64 loss: 0.21149808168411255
Batch 3/64 loss: 0.226118803024292
Batch 4/64 loss: 0.21600085496902466
Batch 5/64 loss: 0.2151792049407959
Batch 6/64 loss: 0.2175997495651245
Batch 7/64 loss: 0.210585355758667
Batch 8/64 loss: 0.220473051071167
Batch 9/64 loss: 0.21329724788665771
Batch 10/64 loss: 0.22015762329101562
Batch 11/64 loss: 0.2194463014602661
Batch 12/64 loss: 0.21552592515945435
Batch 13/64 loss: 0.22612309455871582
Batch 14/64 loss: 0.2157740592956543
Batch 15/64 loss: 0.22250986099243164
Batch 16/64 loss: 0.21387499570846558
Batch 17/64 loss: 0.2121192216873169
Batch 18/64 loss: 0.22315967082977295
Batch 19/64 loss: 0.22203636169433594
Batch 20/64 loss: 0.21895360946655273
Batch 21/64 loss: 0.21608781814575195
Batch 22/64 loss: 0.22104918956756592
Batch 23/64 loss: 0.21646344661712646
Batch 24/64 loss: 0.233656644821167
Batch 25/64 loss: 0.216549813747406
Batch 26/64 loss: 0.21931976079940796
Batch 27/64 loss: 0.22273564338684082
Batch 28/64 loss: 0.22159069776535034
Batch 29/64 loss: 0.2190004587173462
Batch 30/64 loss: 0.22587168216705322
Batch 31/64 loss: 0.22227877378463745
Batch 32/64 loss: 0.22030818462371826
Batch 33/64 loss: 0.21134233474731445
Batch 34/64 loss: 0.21319401264190674
Batch 35/64 loss: 0.21561264991760254
Batch 36/64 loss: 0.21743202209472656
Batch 37/64 loss: 0.22402739524841309
Batch 38/64 loss: 0.22134047746658325
Batch 39/64 loss: 0.21349680423736572
Batch 40/64 loss: 0.2201932668685913
Batch 41/64 loss: 0.2140871286392212
Batch 42/64 loss: 0.23067378997802734
Batch 43/64 loss: 0.21357494592666626
Batch 44/64 loss: 0.23062264919281006
Batch 45/64 loss: 0.22040623426437378
Batch 46/64 loss: 0.2115565538406372
Batch 47/64 loss: 0.21997994184494019
Batch 48/64 loss: 0.2229800820350647
Batch 49/64 loss: 0.21926891803741455
Batch 50/64 loss: 0.22509384155273438
Batch 51/64 loss: 0.21801817417144775
Batch 52/64 loss: 0.21636253595352173
Batch 53/64 loss: 0.2282201647758484
Batch 54/64 loss: 0.21974539756774902
Batch 55/64 loss: 0.21725553274154663
Batch 56/64 loss: 0.21984922885894775
Batch 57/64 loss: 0.22332406044006348
Batch 58/64 loss: 0.21356773376464844
Batch 59/64 loss: 0.21380937099456787
Batch 60/64 loss: 0.22652685642242432
Batch 61/64 loss: 0.2170252799987793
Batch 62/64 loss: 0.20836615562438965
Batch 63/64 loss: 0.21723222732543945
Batch 64/64 loss: 0.21488475799560547
Epoch 332  Train loss: 0.2189892563165403  Val loss: 0.2701088536236294
Epoch 333
-------------------------------
Batch 1/64 loss: 0.21806085109710693
Batch 2/64 loss: 0.21218103170394897
Batch 3/64 loss: 0.220312237739563
Batch 4/64 loss: 0.2264757752418518
Batch 5/64 loss: 0.2267298698425293
Batch 6/64 loss: 0.21781325340270996
Batch 7/64 loss: 0.20542609691619873
Batch 8/64 loss: 0.21750664710998535
Batch 9/64 loss: 0.2208462953567505
Batch 10/64 loss: 0.21820056438446045
Batch 11/64 loss: 0.21466279029846191
Batch 12/64 loss: 0.22463083267211914
Batch 13/64 loss: 0.22273552417755127
Batch 14/64 loss: 0.21949082612991333
Batch 15/64 loss: 0.21296387910842896
Batch 16/64 loss: 0.20892536640167236
Batch 17/64 loss: 0.21403127908706665
Batch 18/64 loss: 0.22781962156295776
Batch 19/64 loss: 0.2144639492034912
Batch 20/64 loss: 0.21660149097442627
Batch 21/64 loss: 0.21819359064102173
Batch 22/64 loss: 0.21368682384490967
Batch 23/64 loss: 0.21972590684890747
Batch 24/64 loss: 0.22091251611709595
Batch 25/64 loss: 0.2204296588897705
Batch 26/64 loss: 0.22745907306671143
Batch 27/64 loss: 0.22336602210998535
Batch 28/64 loss: 0.21506386995315552
Batch 29/64 loss: 0.22270727157592773
Batch 30/64 loss: 0.21627604961395264
Batch 31/64 loss: 0.21987247467041016
Batch 32/64 loss: 0.2159598469734192
Batch 33/64 loss: 0.22466862201690674
Batch 34/64 loss: 0.22347962856292725
Batch 35/64 loss: 0.21355211734771729
Batch 36/64 loss: 0.2126803994178772
Batch 37/64 loss: 0.2127823829650879
Batch 38/64 loss: 0.22461557388305664
Batch 39/64 loss: 0.2155725359916687
Batch 40/64 loss: 0.22470331192016602
Batch 41/64 loss: 0.21029037237167358
Batch 42/64 loss: 0.22488272190093994
Batch 43/64 loss: 0.21749478578567505
Batch 44/64 loss: 0.22127676010131836
Batch 45/64 loss: 0.21547430753707886
Batch 46/64 loss: 0.21953165531158447
Batch 47/64 loss: 0.2198140025138855
Batch 48/64 loss: 0.2103096842765808
Batch 49/64 loss: 0.2326928973197937
Batch 50/64 loss: 0.21558761596679688
Batch 51/64 loss: 0.21212053298950195
Batch 52/64 loss: 0.21333765983581543
Batch 53/64 loss: 0.22010517120361328
Batch 54/64 loss: 0.2178301215171814
Batch 55/64 loss: 0.20737236738204956
Batch 56/64 loss: 0.22582018375396729
Batch 57/64 loss: 0.21041393280029297
Batch 58/64 loss: 0.2109311819076538
Batch 59/64 loss: 0.2200843095779419
Batch 60/64 loss: 0.212577223777771
Batch 61/64 loss: 0.23324692249298096
Batch 62/64 loss: 0.21384304761886597
Batch 63/64 loss: 0.2214221954345703
Batch 64/64 loss: 0.21405571699142456
Epoch 333  Train loss: 0.21823666352851717  Val loss: 0.26916194207889516
Epoch 334
-------------------------------
Batch 1/64 loss: 0.20895171165466309
Batch 2/64 loss: 0.22042381763458252
Batch 3/64 loss: 0.23201584815979004
Batch 4/64 loss: 0.21239161491394043
Batch 5/64 loss: 0.2180626392364502
Batch 6/64 loss: 0.22089362144470215
Batch 7/64 loss: 0.21347784996032715
Batch 8/64 loss: 0.22052496671676636
Batch 9/64 loss: 0.21128451824188232
Batch 10/64 loss: 0.2217196822166443
Batch 11/64 loss: 0.21744704246520996
Batch 12/64 loss: 0.2148895263671875
Batch 13/64 loss: 0.21992796659469604
Batch 14/64 loss: 0.2156583070755005
Batch 15/64 loss: 0.22815942764282227
Batch 16/64 loss: 0.22706341743469238
Batch 17/64 loss: 0.2130361795425415
Batch 18/64 loss: 0.21146714687347412
Batch 19/64 loss: 0.21803760528564453
Batch 20/64 loss: 0.22253906726837158
Batch 21/64 loss: 0.21544456481933594
Batch 22/64 loss: 0.21966075897216797
Batch 23/64 loss: 0.22425377368927002
Batch 24/64 loss: 0.21576708555221558
Batch 25/64 loss: 0.2290414571762085
Batch 26/64 loss: 0.2162543535232544
Batch 27/64 loss: 0.21327447891235352
Batch 28/64 loss: 0.22691363096237183
Batch 29/64 loss: 0.21466970443725586
Batch 30/64 loss: 0.22178900241851807
Batch 31/64 loss: 0.20997977256774902
Batch 32/64 loss: 0.21761035919189453
Batch 33/64 loss: 0.21594351530075073
Batch 34/64 loss: 0.21694821119308472
Batch 35/64 loss: 0.21503525972366333
Batch 36/64 loss: 0.21490025520324707
Batch 37/64 loss: 0.222448468208313
Batch 38/64 loss: 0.2273591160774231
Batch 39/64 loss: 0.22394216060638428
Batch 40/64 loss: 0.20960092544555664
Batch 41/64 loss: 0.21312665939331055
Batch 42/64 loss: 0.21333730220794678
Batch 43/64 loss: 0.20641803741455078
Batch 44/64 loss: 0.2220933437347412
Batch 45/64 loss: 0.2191089391708374
Batch 46/64 loss: 0.21430039405822754
Batch 47/64 loss: 0.2388930320739746
Batch 48/64 loss: 0.2132207751274109
Batch 49/64 loss: 0.20918655395507812
Batch 50/64 loss: 0.22007876634597778
Batch 51/64 loss: 0.22614037990570068
Batch 52/64 loss: 0.22559452056884766
Batch 53/64 loss: 0.21754729747772217
Batch 54/64 loss: 0.227888822555542
Batch 55/64 loss: 0.20841354131698608
Batch 56/64 loss: 0.21560150384902954
Batch 57/64 loss: 0.21793758869171143
Batch 58/64 loss: 0.22693192958831787
Batch 59/64 loss: 0.21977925300598145
Batch 60/64 loss: 0.23093640804290771
Batch 61/64 loss: 0.2125566005706787
Batch 62/64 loss: 0.2199992537498474
Batch 63/64 loss: 0.21178442239761353
Batch 64/64 loss: 0.21755796670913696
Epoch 334  Train loss: 0.21855455075993258  Val loss: 0.26943321203448106
Epoch 335
-------------------------------
Batch 1/64 loss: 0.21486544609069824
Batch 2/64 loss: 0.2107214331626892
Batch 3/64 loss: 0.21089833974838257
Batch 4/64 loss: 0.21955585479736328
Batch 5/64 loss: 0.2168474793434143
Batch 6/64 loss: 0.2182559370994568
Batch 7/64 loss: 0.215545654296875
Batch 8/64 loss: 0.21209800243377686
Batch 9/64 loss: 0.2195369005203247
Batch 10/64 loss: 0.21535050868988037
Batch 11/64 loss: 0.21211063861846924
Batch 12/64 loss: 0.21163785457611084
Batch 13/64 loss: 0.21632730960845947
Batch 14/64 loss: 0.21759450435638428
Batch 15/64 loss: 0.22045063972473145
Batch 16/64 loss: 0.225685715675354
Batch 17/64 loss: 0.20932477712631226
Batch 18/64 loss: 0.22195881605148315
Batch 19/64 loss: 0.21603310108184814
Batch 20/64 loss: 0.20636022090911865
Batch 21/64 loss: 0.2236795425415039
Batch 22/64 loss: 0.21272289752960205
Batch 23/64 loss: 0.21475833654403687
Batch 24/64 loss: 0.2121424674987793
Batch 25/64 loss: 0.21845799684524536
Batch 26/64 loss: 0.2216794490814209
Batch 27/64 loss: 0.20768332481384277
Batch 28/64 loss: 0.2212175726890564
Batch 29/64 loss: 0.2249232530593872
Batch 30/64 loss: 0.2099108099937439
Batch 31/64 loss: 0.22115391492843628
Batch 32/64 loss: 0.21041333675384521
Batch 33/64 loss: 0.22109460830688477
Batch 34/64 loss: 0.2064913511276245
Batch 35/64 loss: 0.2151261568069458
Batch 36/64 loss: 0.22292423248291016
Batch 37/64 loss: 0.2276294231414795
Batch 38/64 loss: 0.21520400047302246
Batch 39/64 loss: 0.21347332000732422
Batch 40/64 loss: 0.21847939491271973
Batch 41/64 loss: 0.21645760536193848
Batch 42/64 loss: 0.21721696853637695
Batch 43/64 loss: 0.21444416046142578
Batch 44/64 loss: 0.21347570419311523
Batch 45/64 loss: 0.21521055698394775
Batch 46/64 loss: 0.21282243728637695
Batch 47/64 loss: 0.21571296453475952
Batch 48/64 loss: 0.22437292337417603
Batch 49/64 loss: 0.21548306941986084
Batch 50/64 loss: 0.2218261957168579
Batch 51/64 loss: 0.2144787311553955
Batch 52/64 loss: 0.22904598712921143
Batch 53/64 loss: 0.2290133833885193
Batch 54/64 loss: 0.22846150398254395
Batch 55/64 loss: 0.2134488821029663
Batch 56/64 loss: 0.22536039352416992
Batch 57/64 loss: 0.20899653434753418
Batch 58/64 loss: 0.21907466650009155
Batch 59/64 loss: 0.2137414813041687
Batch 60/64 loss: 0.22693276405334473
Batch 61/64 loss: 0.21962040662765503
Batch 62/64 loss: 0.21164405345916748
Batch 63/64 loss: 0.2175005078315735
Batch 64/64 loss: 0.211664080619812
Epoch 335  Train loss: 0.21699473670884675  Val loss: 0.26915504576004656
Epoch 336
-------------------------------
Batch 1/64 loss: 0.2151503562927246
Batch 2/64 loss: 0.20545297861099243
Batch 3/64 loss: 0.22448885440826416
Batch 4/64 loss: 0.21222913265228271
Batch 5/64 loss: 0.2143077850341797
Batch 6/64 loss: 0.2094777226448059
Batch 7/64 loss: 0.21521294116973877
Batch 8/64 loss: 0.21361500024795532
Batch 9/64 loss: 0.22383356094360352
Batch 10/64 loss: 0.21429532766342163
Batch 11/64 loss: 0.21312975883483887
Batch 12/64 loss: 0.2146059274673462
Batch 13/64 loss: 0.2136441469192505
Batch 14/64 loss: 0.21596956253051758
Batch 15/64 loss: 0.21544218063354492
Batch 16/64 loss: 0.2102144956588745
Batch 17/64 loss: 0.22078800201416016
Batch 18/64 loss: 0.21558690071105957
Batch 19/64 loss: 0.21145188808441162
Batch 20/64 loss: 0.21745002269744873
Batch 21/64 loss: 0.21689963340759277
Batch 22/64 loss: 0.2175208330154419
Batch 23/64 loss: 0.21091699600219727
Batch 24/64 loss: 0.21380609273910522
Batch 25/64 loss: 0.21488606929779053
Batch 26/64 loss: 0.2103763222694397
Batch 27/64 loss: 0.2216733694076538
Batch 28/64 loss: 0.21208739280700684
Batch 29/64 loss: 0.21664917469024658
Batch 30/64 loss: 0.22545450925827026
Batch 31/64 loss: 0.21433699131011963
Batch 32/64 loss: 0.2188434600830078
Batch 33/64 loss: 0.2269279956817627
Batch 34/64 loss: 0.21342015266418457
Batch 35/64 loss: 0.21454328298568726
Batch 36/64 loss: 0.2229403257369995
Batch 37/64 loss: 0.228002667427063
Batch 38/64 loss: 0.20975327491760254
Batch 39/64 loss: 0.21752727031707764
Batch 40/64 loss: 0.21916794776916504
Batch 41/64 loss: 0.229486346244812
Batch 42/64 loss: 0.2196120023727417
Batch 43/64 loss: 0.215287446975708
Batch 44/64 loss: 0.2151550054550171
Batch 45/64 loss: 0.21658706665039062
Batch 46/64 loss: 0.21585625410079956
Batch 47/64 loss: 0.22852909564971924
Batch 48/64 loss: 0.22058773040771484
Batch 49/64 loss: 0.21067571640014648
Batch 50/64 loss: 0.22785413265228271
Batch 51/64 loss: 0.2058391571044922
Batch 52/64 loss: 0.22034680843353271
Batch 53/64 loss: 0.21355241537094116
Batch 54/64 loss: 0.21877533197402954
Batch 55/64 loss: 0.22160422801971436
Batch 56/64 loss: 0.22260117530822754
Batch 57/64 loss: 0.2179269790649414
Batch 58/64 loss: 0.21949201822280884
Batch 59/64 loss: 0.21651631593704224
Batch 60/64 loss: 0.22999978065490723
Batch 61/64 loss: 0.22142374515533447
Batch 62/64 loss: 0.21333789825439453
Batch 63/64 loss: 0.22523367404937744
Batch 64/64 loss: 0.21626240015029907
Epoch 336  Train loss: 0.21726364598554723  Val loss: 0.26904959326347533
Epoch 337
-------------------------------
Batch 1/64 loss: 0.21685796976089478
Batch 2/64 loss: 0.2346460223197937
Batch 3/64 loss: 0.21970826387405396
Batch 4/64 loss: 0.22527086734771729
Batch 5/64 loss: 0.2147204875946045
Batch 6/64 loss: 0.21671783924102783
Batch 7/64 loss: 0.22877264022827148
Batch 8/64 loss: 0.22071242332458496
Batch 9/64 loss: 0.21552056074142456
Batch 10/64 loss: 0.22129732370376587
Batch 11/64 loss: 0.21135586500167847
Batch 12/64 loss: 0.21901178359985352
Batch 13/64 loss: 0.21796441078186035
Batch 14/64 loss: 0.2246410846710205
Batch 15/64 loss: 0.21467870473861694
Batch 16/64 loss: 0.2071824073791504
Batch 17/64 loss: 0.21176815032958984
Batch 18/64 loss: 0.21835863590240479
Batch 19/64 loss: 0.21298015117645264
Batch 20/64 loss: 0.22790145874023438
Batch 21/64 loss: 0.22468209266662598
Batch 22/64 loss: 0.2078486680984497
Batch 23/64 loss: 0.21455705165863037
Batch 24/64 loss: 0.2170417308807373
Batch 25/64 loss: 0.2154841423034668
Batch 26/64 loss: 0.21191084384918213
Batch 27/64 loss: 0.2183856964111328
Batch 28/64 loss: 0.2150070071220398
Batch 29/64 loss: 0.22412681579589844
Batch 30/64 loss: 0.22333043813705444
Batch 31/64 loss: 0.21981096267700195
Batch 32/64 loss: 0.21783864498138428
Batch 33/64 loss: 0.20808744430541992
Batch 34/64 loss: 0.21137505769729614
Batch 35/64 loss: 0.21099519729614258
Batch 36/64 loss: 0.21569228172302246
Batch 37/64 loss: 0.21385538578033447
Batch 38/64 loss: 0.21780133247375488
Batch 39/64 loss: 0.22060120105743408
Batch 40/64 loss: 0.21387624740600586
Batch 41/64 loss: 0.2081202268600464
Batch 42/64 loss: 0.214111328125
Batch 43/64 loss: 0.22129744291305542
Batch 44/64 loss: 0.2130315899848938
Batch 45/64 loss: 0.22866272926330566
Batch 46/64 loss: 0.21900886297225952
Batch 47/64 loss: 0.22803056240081787
Batch 48/64 loss: 0.20924043655395508
Batch 49/64 loss: 0.22348111867904663
Batch 50/64 loss: 0.21374499797821045
Batch 51/64 loss: 0.21347039937973022
Batch 52/64 loss: 0.2177606225013733
Batch 53/64 loss: 0.21487247943878174
Batch 54/64 loss: 0.23534536361694336
Batch 55/64 loss: 0.23357748985290527
Batch 56/64 loss: 0.21826279163360596
Batch 57/64 loss: 0.21766114234924316
Batch 58/64 loss: 0.2125445008277893
Batch 59/64 loss: 0.2157498002052307
Batch 60/64 loss: 0.21042025089263916
Batch 61/64 loss: 0.2141703963279724
Batch 62/64 loss: 0.21572524309158325
Batch 63/64 loss: 0.22328585386276245
Batch 64/64 loss: 0.21959757804870605
Epoch 337  Train loss: 0.2178611624474619  Val loss: 0.27015822183635224
Epoch 338
-------------------------------
Batch 1/64 loss: 0.21181488037109375
Batch 2/64 loss: 0.21286094188690186
Batch 3/64 loss: 0.23270082473754883
Batch 4/64 loss: 0.20163023471832275
Batch 5/64 loss: 0.21977299451828003
Batch 6/64 loss: 0.21457260847091675
Batch 7/64 loss: 0.23248273134231567
Batch 8/64 loss: 0.21848726272583008
Batch 9/64 loss: 0.22533559799194336
Batch 10/64 loss: 0.2113226056098938
Batch 11/64 loss: 0.2087780237197876
Batch 12/64 loss: 0.21878516674041748
Batch 13/64 loss: 0.21742022037506104
Batch 14/64 loss: 0.20630425214767456
Batch 15/64 loss: 0.21264111995697021
Batch 16/64 loss: 0.20868325233459473
Batch 17/64 loss: 0.2196146845817566
Batch 18/64 loss: 0.21583646535873413
Batch 19/64 loss: 0.21579843759536743
Batch 20/64 loss: 0.20965814590454102
Batch 21/64 loss: 0.21525615453720093
Batch 22/64 loss: 0.22516047954559326
Batch 23/64 loss: 0.210843026638031
Batch 24/64 loss: 0.21424639225006104
Batch 25/64 loss: 0.20863193273544312
Batch 26/64 loss: 0.22348731756210327
Batch 27/64 loss: 0.21875673532485962
Batch 28/64 loss: 0.21502995491027832
Batch 29/64 loss: 0.21352392435073853
Batch 30/64 loss: 0.23193126916885376
Batch 31/64 loss: 0.21492832899093628
Batch 32/64 loss: 0.22231066226959229
Batch 33/64 loss: 0.21573346853256226
Batch 34/64 loss: 0.21705520153045654
Batch 35/64 loss: 0.20876657962799072
Batch 36/64 loss: 0.2176417112350464
Batch 37/64 loss: 0.22885751724243164
Batch 38/64 loss: 0.21695387363433838
Batch 39/64 loss: 0.22058439254760742
Batch 40/64 loss: 0.21992385387420654
Batch 41/64 loss: 0.21576213836669922
Batch 42/64 loss: 0.22566992044448853
Batch 43/64 loss: 0.21975356340408325
Batch 44/64 loss: 0.21707916259765625
Batch 45/64 loss: 0.2166517972946167
Batch 46/64 loss: 0.2229061722755432
Batch 47/64 loss: 0.2194349765777588
Batch 48/64 loss: 0.2102411985397339
Batch 49/64 loss: 0.21574163436889648
Batch 50/64 loss: 0.2118566632270813
Batch 51/64 loss: 0.21638238430023193
Batch 52/64 loss: 0.21689677238464355
Batch 53/64 loss: 0.20902550220489502
Batch 54/64 loss: 0.21613001823425293
Batch 55/64 loss: 0.2130010724067688
Batch 56/64 loss: 0.21882688999176025
Batch 57/64 loss: 0.2092229723930359
Batch 58/64 loss: 0.2165050506591797
Batch 59/64 loss: 0.22649157047271729
Batch 60/64 loss: 0.21525460481643677
Batch 61/64 loss: 0.21280550956726074
Batch 62/64 loss: 0.21303069591522217
Batch 63/64 loss: 0.21600091457366943
Batch 64/64 loss: 0.2184666395187378
Epoch 338  Train loss: 0.21666893164316814  Val loss: 0.26971180127658384
Epoch 339
-------------------------------
Batch 1/64 loss: 0.2219371199607849
Batch 2/64 loss: 0.21558690071105957
Batch 3/64 loss: 0.20737028121948242
Batch 4/64 loss: 0.21561962366104126
Batch 5/64 loss: 0.2202746868133545
Batch 6/64 loss: 0.2112652063369751
Batch 7/64 loss: 0.23098796606063843
Batch 8/64 loss: 0.21511662006378174
Batch 9/64 loss: 0.21333742141723633
Batch 10/64 loss: 0.2147982120513916
Batch 11/64 loss: 0.22145307064056396
Batch 12/64 loss: 0.21856766939163208
Batch 13/64 loss: 0.22118514776229858
Batch 14/64 loss: 0.21122020483016968
Batch 15/64 loss: 0.2220923900604248
Batch 16/64 loss: 0.22245430946350098
Batch 17/64 loss: 0.220007061958313
Batch 18/64 loss: 0.21226412057876587
Batch 19/64 loss: 0.215600848197937
Batch 20/64 loss: 0.22940731048583984
Batch 21/64 loss: 0.20980370044708252
Batch 22/64 loss: 0.20943868160247803
Batch 23/64 loss: 0.2163439393043518
Batch 24/64 loss: 0.20793598890304565
Batch 25/64 loss: 0.21818006038665771
Batch 26/64 loss: 0.22056901454925537
Batch 27/64 loss: 0.22476840019226074
Batch 28/64 loss: 0.21483898162841797
Batch 29/64 loss: 0.21943926811218262
Batch 30/64 loss: 0.2146013379096985
Batch 31/64 loss: 0.21182221174240112
Batch 32/64 loss: 0.22747492790222168
Batch 33/64 loss: 0.21376729011535645
Batch 34/64 loss: 0.21933221817016602
Batch 35/64 loss: 0.2220827341079712
Batch 36/64 loss: 0.21458882093429565
Batch 37/64 loss: 0.21308672428131104
Batch 38/64 loss: 0.22762489318847656
Batch 39/64 loss: 0.20914006233215332
Batch 40/64 loss: 0.21927368640899658
Batch 41/64 loss: 0.22477751970291138
Batch 42/64 loss: 0.21893006563186646
Batch 43/64 loss: 0.21029090881347656
Batch 44/64 loss: 0.22337019443511963
Batch 45/64 loss: 0.2229636311531067
Batch 46/64 loss: 0.2224903106689453
Batch 47/64 loss: 0.21619796752929688
Batch 48/64 loss: 0.22040367126464844
Batch 49/64 loss: 0.21825778484344482
Batch 50/64 loss: 0.21783387660980225
Batch 51/64 loss: 0.21303653717041016
Batch 52/64 loss: 0.21681243181228638
Batch 53/64 loss: 0.21301639080047607
Batch 54/64 loss: 0.21534079313278198
Batch 55/64 loss: 0.22931069135665894
Batch 56/64 loss: 0.21761095523834229
Batch 57/64 loss: 0.21518129110336304
Batch 58/64 loss: 0.2138434648513794
Batch 59/64 loss: 0.22197496891021729
Batch 60/64 loss: 0.21814745664596558
Batch 61/64 loss: 0.22318816184997559
Batch 62/64 loss: 0.21345967054367065
Batch 63/64 loss: 0.20831531286239624
Batch 64/64 loss: 0.21255582571029663
Epoch 339  Train loss: 0.21755027513878017  Val loss: 0.2693417889555705
Epoch 340
-------------------------------
Batch 1/64 loss: 0.21801424026489258
Batch 2/64 loss: 0.2112831473350525
Batch 3/64 loss: 0.22089147567749023
Batch 4/64 loss: 0.22023457288742065
Batch 5/64 loss: 0.21447539329528809
Batch 6/64 loss: 0.2275012731552124
Batch 7/64 loss: 0.2222280502319336
Batch 8/64 loss: 0.2141200304031372
Batch 9/64 loss: 0.22278165817260742
Batch 10/64 loss: 0.23216652870178223
Batch 11/64 loss: 0.22432786226272583
Batch 12/64 loss: 0.21256542205810547
Batch 13/64 loss: 0.2157890796661377
Batch 14/64 loss: 0.21874451637268066
Batch 15/64 loss: 0.21138155460357666
Batch 16/64 loss: 0.21071112155914307
Batch 17/64 loss: 0.21862339973449707
Batch 18/64 loss: 0.21043461561203003
Batch 19/64 loss: 0.2116391658782959
Batch 20/64 loss: 0.21804380416870117
Batch 21/64 loss: 0.2218778133392334
Batch 22/64 loss: 0.21706295013427734
Batch 23/64 loss: 0.21418678760528564
Batch 24/64 loss: 0.22241359949111938
Batch 25/64 loss: 0.22113758325576782
Batch 26/64 loss: 0.21996855735778809
Batch 27/64 loss: 0.21731996536254883
Batch 28/64 loss: 0.20943832397460938
Batch 29/64 loss: 0.21957474946975708
Batch 30/64 loss: 0.23760414123535156
Batch 31/64 loss: 0.21745705604553223
Batch 32/64 loss: 0.22080963850021362
Batch 33/64 loss: 0.21183371543884277
Batch 34/64 loss: 0.21394741535186768
Batch 35/64 loss: 0.21464604139328003
Batch 36/64 loss: 0.21781456470489502
Batch 37/64 loss: 0.21758908033370972
Batch 38/64 loss: 0.2150193452835083
Batch 39/64 loss: 0.2265108823776245
Batch 40/64 loss: 0.21242249011993408
Batch 41/64 loss: 0.21527719497680664
Batch 42/64 loss: 0.22091645002365112
Batch 43/64 loss: 0.21514356136322021
Batch 44/64 loss: 0.21388810873031616
Batch 45/64 loss: 0.2128048539161682
Batch 46/64 loss: 0.21328818798065186
Batch 47/64 loss: 0.22071605920791626
Batch 48/64 loss: 0.21334773302078247
Batch 49/64 loss: 0.21481597423553467
Batch 50/64 loss: 0.219002366065979
Batch 51/64 loss: 0.21833252906799316
Batch 52/64 loss: 0.21513468027114868
Batch 53/64 loss: 0.21947836875915527
Batch 54/64 loss: 0.2228519320487976
Batch 55/64 loss: 0.21650290489196777
Batch 56/64 loss: 0.20829427242279053
Batch 57/64 loss: 0.21622836589813232
Batch 58/64 loss: 0.21559303998947144
Batch 59/64 loss: 0.22022944688796997
Batch 60/64 loss: 0.21502214670181274
Batch 61/64 loss: 0.2115321159362793
Batch 62/64 loss: 0.21739983558654785
Batch 63/64 loss: 0.21831536293029785
Batch 64/64 loss: 0.21045076847076416
Epoch 340  Train loss: 0.2173575714522717  Val loss: 0.26927077483475415
Epoch 341
-------------------------------
Batch 1/64 loss: 0.22665953636169434
Batch 2/64 loss: 0.21316742897033691
Batch 3/64 loss: 0.2081586718559265
Batch 4/64 loss: 0.21266132593154907
Batch 5/64 loss: 0.20940297842025757
Batch 6/64 loss: 0.2113131880760193
Batch 7/64 loss: 0.22116684913635254
Batch 8/64 loss: 0.22505921125411987
Batch 9/64 loss: 0.21140801906585693
Batch 10/64 loss: 0.2119513750076294
Batch 11/64 loss: 0.22381412982940674
Batch 12/64 loss: 0.2158362865447998
Batch 13/64 loss: 0.22364521026611328
Batch 14/64 loss: 0.22444689273834229
Batch 15/64 loss: 0.21367156505584717
Batch 16/64 loss: 0.21639132499694824
Batch 17/64 loss: 0.21945035457611084
Batch 18/64 loss: 0.2180849313735962
Batch 19/64 loss: 0.22578352689743042
Batch 20/64 loss: 0.21334236860275269
Batch 21/64 loss: 0.22070443630218506
Batch 22/64 loss: 0.21335673332214355
Batch 23/64 loss: 0.21945178508758545
Batch 24/64 loss: 0.21320462226867676
Batch 25/64 loss: 0.22100383043289185
Batch 26/64 loss: 0.22584491968154907
Batch 27/64 loss: 0.22426927089691162
Batch 28/64 loss: 0.21082663536071777
Batch 29/64 loss: 0.22098028659820557
Batch 30/64 loss: 0.21206367015838623
Batch 31/64 loss: 0.21570944786071777
Batch 32/64 loss: 0.21433526277542114
Batch 33/64 loss: 0.23030227422714233
Batch 34/64 loss: 0.21416276693344116
Batch 35/64 loss: 0.21341454982757568
Batch 36/64 loss: 0.2130643129348755
Batch 37/64 loss: 0.22632509469985962
Batch 38/64 loss: 0.21163642406463623
Batch 39/64 loss: 0.2146240472793579
Batch 40/64 loss: 0.21430253982543945
Batch 41/64 loss: 0.2166193723678589
Batch 42/64 loss: 0.20980429649353027
Batch 43/64 loss: 0.21366852521896362
Batch 44/64 loss: 0.21521294116973877
Batch 45/64 loss: 0.2176721692085266
Batch 46/64 loss: 0.22318309545516968
Batch 47/64 loss: 0.2148963212966919
Batch 48/64 loss: 0.21610796451568604
Batch 49/64 loss: 0.2182772159576416
Batch 50/64 loss: 0.20415520668029785
Batch 51/64 loss: 0.2139257788658142
Batch 52/64 loss: 0.22030413150787354
Batch 53/64 loss: 0.2372366189956665
Batch 54/64 loss: 0.21110785007476807
Batch 55/64 loss: 0.20993995666503906
Batch 56/64 loss: 0.218919038772583
Batch 57/64 loss: 0.22036969661712646
Batch 58/64 loss: 0.21551549434661865
Batch 59/64 loss: 0.21669107675552368
Batch 60/64 loss: 0.22610557079315186
Batch 61/64 loss: 0.20912617444992065
Batch 62/64 loss: 0.2114856243133545
Batch 63/64 loss: 0.21163666248321533
Batch 64/64 loss: 0.21747100353240967
Epoch 341  Train loss: 0.21694215092004515  Val loss: 0.26889200145026665
Epoch 342
-------------------------------
Batch 1/64 loss: 0.21738731861114502
Batch 2/64 loss: 0.2184828519821167
Batch 3/64 loss: 0.2136632204055786
Batch 4/64 loss: 0.2180943489074707
Batch 5/64 loss: 0.22290503978729248
Batch 6/64 loss: 0.21023023128509521
Batch 7/64 loss: 0.21171307563781738
Batch 8/64 loss: 0.21715116500854492
Batch 9/64 loss: 0.21497559547424316
Batch 10/64 loss: 0.21232974529266357
Batch 11/64 loss: 0.22445356845855713
Batch 12/64 loss: 0.21036243438720703
Batch 13/64 loss: 0.21560192108154297
Batch 14/64 loss: 0.22743505239486694
Batch 15/64 loss: 0.22399377822875977
Batch 16/64 loss: 0.21556711196899414
Batch 17/64 loss: 0.21731030941009521
Batch 18/64 loss: 0.22720706462860107
Batch 19/64 loss: 0.2092609405517578
Batch 20/64 loss: 0.2176525592803955
Batch 21/64 loss: 0.22563707828521729
Batch 22/64 loss: 0.2279982566833496
Batch 23/64 loss: 0.21380329132080078
Batch 24/64 loss: 0.20794856548309326
Batch 25/64 loss: 0.212646484375
Batch 26/64 loss: 0.21836966276168823
Batch 27/64 loss: 0.21289145946502686
Batch 28/64 loss: 0.20938795804977417
Batch 29/64 loss: 0.22472602128982544
Batch 30/64 loss: 0.20742249488830566
Batch 31/64 loss: 0.21596980094909668
Batch 32/64 loss: 0.21507477760314941
Batch 33/64 loss: 0.22151917219161987
Batch 34/64 loss: 0.20642822980880737
Batch 35/64 loss: 0.20712292194366455
Batch 36/64 loss: 0.2092365026473999
Batch 37/64 loss: 0.22139745950698853
Batch 38/64 loss: 0.21546953916549683
Batch 39/64 loss: 0.2079935073852539
Batch 40/64 loss: 0.2198108434677124
Batch 41/64 loss: 0.21929466724395752
Batch 42/64 loss: 0.22124791145324707
Batch 43/64 loss: 0.21319377422332764
Batch 44/64 loss: 0.2144451141357422
Batch 45/64 loss: 0.21410131454467773
Batch 46/64 loss: 0.22012650966644287
Batch 47/64 loss: 0.20686155557632446
Batch 48/64 loss: 0.2153470516204834
Batch 49/64 loss: 0.21796107292175293
Batch 50/64 loss: 0.21717500686645508
Batch 51/64 loss: 0.2119135856628418
Batch 52/64 loss: 0.2137843370437622
Batch 53/64 loss: 0.21624362468719482
Batch 54/64 loss: 0.21846282482147217
Batch 55/64 loss: 0.21141064167022705
Batch 56/64 loss: 0.21247828006744385
Batch 57/64 loss: 0.2177896499633789
Batch 58/64 loss: 0.21373623609542847
Batch 59/64 loss: 0.23282349109649658
Batch 60/64 loss: 0.22113728523254395
Batch 61/64 loss: 0.20849251747131348
Batch 62/64 loss: 0.21286660432815552
Batch 63/64 loss: 0.22174608707427979
Batch 64/64 loss: 0.21487241983413696
Epoch 342  Train loss: 0.21616352656308344  Val loss: 0.26908789692875446
Epoch 343
-------------------------------
Batch 1/64 loss: 0.21411621570587158
Batch 2/64 loss: 0.22884440422058105
Batch 3/64 loss: 0.22599440813064575
Batch 4/64 loss: 0.2361459732055664
Batch 5/64 loss: 0.214569091796875
Batch 6/64 loss: 0.21220272779464722
Batch 7/64 loss: 0.21032917499542236
Batch 8/64 loss: 0.217215895652771
Batch 9/64 loss: 0.21911579370498657
Batch 10/64 loss: 0.20550930500030518
Batch 11/64 loss: 0.21839481592178345
Batch 12/64 loss: 0.21832013130187988
Batch 13/64 loss: 0.20979905128479004
Batch 14/64 loss: 0.21059560775756836
Batch 15/64 loss: 0.22526562213897705
Batch 16/64 loss: 0.21639806032180786
Batch 17/64 loss: 0.213975727558136
Batch 18/64 loss: 0.2134581208229065
Batch 19/64 loss: 0.21190714836120605
Batch 20/64 loss: 0.21200644969940186
Batch 21/64 loss: 0.22205495834350586
Batch 22/64 loss: 0.2110099196434021
Batch 23/64 loss: 0.2112267017364502
Batch 24/64 loss: 0.2061539888381958
Batch 25/64 loss: 0.2087768316268921
Batch 26/64 loss: 0.20990538597106934
Batch 27/64 loss: 0.21945536136627197
Batch 28/64 loss: 0.20451593399047852
Batch 29/64 loss: 0.21629774570465088
Batch 30/64 loss: 0.20672011375427246
Batch 31/64 loss: 0.20898908376693726
Batch 32/64 loss: 0.2174004316329956
Batch 33/64 loss: 0.22094285488128662
Batch 34/64 loss: 0.21715635061264038
Batch 35/64 loss: 0.23609793186187744
Batch 36/64 loss: 0.21548092365264893
Batch 37/64 loss: 0.2129001021385193
Batch 38/64 loss: 0.219429612159729
Batch 39/64 loss: 0.21202510595321655
Batch 40/64 loss: 0.2150370478630066
Batch 41/64 loss: 0.22317898273468018
Batch 42/64 loss: 0.21618717908859253
Batch 43/64 loss: 0.21349632740020752
Batch 44/64 loss: 0.2155991792678833
Batch 45/64 loss: 0.21972882747650146
Batch 46/64 loss: 0.22313213348388672
Batch 47/64 loss: 0.2116178274154663
Batch 48/64 loss: 0.225949227809906
Batch 49/64 loss: 0.21066057682037354
Batch 50/64 loss: 0.214602530002594
Batch 51/64 loss: 0.22297406196594238
Batch 52/64 loss: 0.21539688110351562
Batch 53/64 loss: 0.22013312578201294
Batch 54/64 loss: 0.217190682888031
Batch 55/64 loss: 0.22448468208312988
Batch 56/64 loss: 0.2191755771636963
Batch 57/64 loss: 0.22146886587142944
Batch 58/64 loss: 0.20914340019226074
Batch 59/64 loss: 0.21062874794006348
Batch 60/64 loss: 0.22068560123443604
Batch 61/64 loss: 0.2131582498550415
Batch 62/64 loss: 0.20733559131622314
Batch 63/64 loss: 0.2187952995300293
Batch 64/64 loss: 0.21518218517303467
Epoch 343  Train loss: 0.216185887187135  Val loss: 0.2695639252253005
Epoch 344
-------------------------------
Batch 1/64 loss: 0.21618330478668213
Batch 2/64 loss: 0.20871561765670776
Batch 3/64 loss: 0.2184889316558838
Batch 4/64 loss: 0.22463583946228027
Batch 5/64 loss: 0.22354716062545776
Batch 6/64 loss: 0.21847915649414062
Batch 7/64 loss: 0.2193988561630249
Batch 8/64 loss: 0.21433883905410767
Batch 9/64 loss: 0.21993446350097656
Batch 10/64 loss: 0.21389317512512207
Batch 11/64 loss: 0.21374499797821045
Batch 12/64 loss: 0.21245288848876953
Batch 13/64 loss: 0.21173179149627686
Batch 14/64 loss: 0.21370750665664673
Batch 15/64 loss: 0.21473801136016846
Batch 16/64 loss: 0.2126026749610901
Batch 17/64 loss: 0.21622323989868164
Batch 18/64 loss: 0.213248610496521
Batch 19/64 loss: 0.20397770404815674
Batch 20/64 loss: 0.20933175086975098
Batch 21/64 loss: 0.21294927597045898
Batch 22/64 loss: 0.21894025802612305
Batch 23/64 loss: 0.21436792612075806
Batch 24/64 loss: 0.21804994344711304
Batch 25/64 loss: 0.2145121693611145
Batch 26/64 loss: 0.21300220489501953
Batch 27/64 loss: 0.2144622802734375
Batch 28/64 loss: 0.21233129501342773
Batch 29/64 loss: 0.2153347134590149
Batch 30/64 loss: 0.2039804458618164
Batch 31/64 loss: 0.21557921171188354
Batch 32/64 loss: 0.22692584991455078
Batch 33/64 loss: 0.2127963900566101
Batch 34/64 loss: 0.21387720108032227
Batch 35/64 loss: 0.2178260087966919
Batch 36/64 loss: 0.21413898468017578
Batch 37/64 loss: 0.2087804079055786
Batch 38/64 loss: 0.20438766479492188
Batch 39/64 loss: 0.21392691135406494
Batch 40/64 loss: 0.21965110301971436
Batch 41/64 loss: 0.22304260730743408
Batch 42/64 loss: 0.20705962181091309
Batch 43/64 loss: 0.20897436141967773
Batch 44/64 loss: 0.2103734016418457
Batch 45/64 loss: 0.22724121809005737
Batch 46/64 loss: 0.223649263381958
Batch 47/64 loss: 0.2242577075958252
Batch 48/64 loss: 0.20849567651748657
Batch 49/64 loss: 0.2222827672958374
Batch 50/64 loss: 0.20799535512924194
Batch 51/64 loss: 0.2161794900894165
Batch 52/64 loss: 0.22554421424865723
Batch 53/64 loss: 0.2098817229270935
Batch 54/64 loss: 0.23111259937286377
Batch 55/64 loss: 0.21609842777252197
Batch 56/64 loss: 0.2159244418144226
Batch 57/64 loss: 0.2133007049560547
Batch 58/64 loss: 0.20563781261444092
Batch 59/64 loss: 0.21912014484405518
Batch 60/64 loss: 0.212175190448761
Batch 61/64 loss: 0.217360258102417
Batch 62/64 loss: 0.21958863735198975
Batch 63/64 loss: 0.21910345554351807
Batch 64/64 loss: 0.22056889533996582
Epoch 344  Train loss: 0.21545130224788892  Val loss: 0.26859339856609854
Saving best model, epoch: 344
Epoch 345
-------------------------------
Batch 1/64 loss: 0.2115699052810669
Batch 2/64 loss: 0.21152794361114502
Batch 3/64 loss: 0.2163832187652588
Batch 4/64 loss: 0.20477259159088135
Batch 5/64 loss: 0.2232007384300232
Batch 6/64 loss: 0.21456480026245117
Batch 7/64 loss: 0.21949946880340576
Batch 8/64 loss: 0.21727502346038818
Batch 9/64 loss: 0.2092888355255127
Batch 10/64 loss: 0.21862685680389404
Batch 11/64 loss: 0.20928966999053955
Batch 12/64 loss: 0.21507704257965088
Batch 13/64 loss: 0.215348482131958
Batch 14/64 loss: 0.21929341554641724
Batch 15/64 loss: 0.21516180038452148
Batch 16/64 loss: 0.2139207124710083
Batch 17/64 loss: 0.21498894691467285
Batch 18/64 loss: 0.20943212509155273
Batch 19/64 loss: 0.2082499861717224
Batch 20/64 loss: 0.21775245666503906
Batch 21/64 loss: 0.224159836769104
Batch 22/64 loss: 0.2236238718032837
Batch 23/64 loss: 0.20761477947235107
Batch 24/64 loss: 0.21141624450683594
Batch 25/64 loss: 0.2228912115097046
Batch 26/64 loss: 0.21447831392288208
Batch 27/64 loss: 0.21180450916290283
Batch 28/64 loss: 0.21922987699508667
Batch 29/64 loss: 0.2230280637741089
Batch 30/64 loss: 0.21851462125778198
Batch 31/64 loss: 0.21420276165008545
Batch 32/64 loss: 0.21720588207244873
Batch 33/64 loss: 0.2174168825149536
Batch 34/64 loss: 0.2200695276260376
Batch 35/64 loss: 0.21651160717010498
Batch 36/64 loss: 0.21920526027679443
Batch 37/64 loss: 0.21193158626556396
Batch 38/64 loss: 0.21083271503448486
Batch 39/64 loss: 0.21455836296081543
Batch 40/64 loss: 0.21913224458694458
Batch 41/64 loss: 0.22219061851501465
Batch 42/64 loss: 0.21297341585159302
Batch 43/64 loss: 0.2210875153541565
Batch 44/64 loss: 0.2149447798728943
Batch 45/64 loss: 0.2201913595199585
Batch 46/64 loss: 0.2234324812889099
Batch 47/64 loss: 0.2034832239151001
Batch 48/64 loss: 0.21439474821090698
Batch 49/64 loss: 0.20748543739318848
Batch 50/64 loss: 0.2151249647140503
Batch 51/64 loss: 0.21540415287017822
Batch 52/64 loss: 0.22336578369140625
Batch 53/64 loss: 0.21384072303771973
Batch 54/64 loss: 0.20941197872161865
Batch 55/64 loss: 0.217515766620636
Batch 56/64 loss: 0.23046940565109253
Batch 57/64 loss: 0.213326096534729
Batch 58/64 loss: 0.217055082321167
Batch 59/64 loss: 0.2222691774368286
Batch 60/64 loss: 0.2157219648361206
Batch 61/64 loss: 0.22125554084777832
Batch 62/64 loss: 0.21881502866744995
Batch 63/64 loss: 0.22198069095611572
Batch 64/64 loss: 0.21201884746551514
Epoch 345  Train loss: 0.21612245101554722  Val loss: 0.269868167200449
Epoch 346
-------------------------------
Batch 1/64 loss: 0.22392094135284424
Batch 2/64 loss: 0.21171241998672485
Batch 3/64 loss: 0.20821601152420044
Batch 4/64 loss: 0.221541166305542
Batch 5/64 loss: 0.22664475440979004
Batch 6/64 loss: 0.22574913501739502
Batch 7/64 loss: 0.21697068214416504
Batch 8/64 loss: 0.20610511302947998
Batch 9/64 loss: 0.22957050800323486
Batch 10/64 loss: 0.2198171615600586
Batch 11/64 loss: 0.2104036808013916
Batch 12/64 loss: 0.21076053380966187
Batch 13/64 loss: 0.21040886640548706
Batch 14/64 loss: 0.21692496538162231
Batch 15/64 loss: 0.21740520000457764
Batch 16/64 loss: 0.20882445573806763
Batch 17/64 loss: 0.2194119691848755
Batch 18/64 loss: 0.21499300003051758
Batch 19/64 loss: 0.21151041984558105
Batch 20/64 loss: 0.21201324462890625
Batch 21/64 loss: 0.2149261236190796
Batch 22/64 loss: 0.22125977277755737
Batch 23/64 loss: 0.20473164319992065
Batch 24/64 loss: 0.22618502378463745
Batch 25/64 loss: 0.2219526767730713
Batch 26/64 loss: 0.21823424100875854
Batch 27/64 loss: 0.21795892715454102
Batch 28/64 loss: 0.2200537919998169
Batch 29/64 loss: 0.216191828250885
Batch 30/64 loss: 0.21564549207687378
Batch 31/64 loss: 0.21319139003753662
Batch 32/64 loss: 0.2089306116104126
Batch 33/64 loss: 0.2162841558456421
Batch 34/64 loss: 0.21792840957641602
Batch 35/64 loss: 0.2125353217124939
Batch 36/64 loss: 0.21909630298614502
Batch 37/64 loss: 0.22080695629119873
Batch 38/64 loss: 0.2129582166671753
Batch 39/64 loss: 0.21187639236450195
Batch 40/64 loss: 0.21333622932434082
Batch 41/64 loss: 0.2086637020111084
Batch 42/64 loss: 0.2241743803024292
Batch 43/64 loss: 0.2132759690284729
Batch 44/64 loss: 0.2105315923690796
Batch 45/64 loss: 0.21091067790985107
Batch 46/64 loss: 0.20782744884490967
Batch 47/64 loss: 0.22479796409606934
Batch 48/64 loss: 0.2149261236190796
Batch 49/64 loss: 0.2025841474533081
Batch 50/64 loss: 0.2168177366256714
Batch 51/64 loss: 0.20789247751235962
Batch 52/64 loss: 0.21463054418563843
Batch 53/64 loss: 0.22569990158081055
Batch 54/64 loss: 0.2281617522239685
Batch 55/64 loss: 0.2188042402267456
Batch 56/64 loss: 0.22124534845352173
Batch 57/64 loss: 0.2132587432861328
Batch 58/64 loss: 0.21220910549163818
Batch 59/64 loss: 0.21296894550323486
Batch 60/64 loss: 0.21247899532318115
Batch 61/64 loss: 0.21681004762649536
Batch 62/64 loss: 0.21955519914627075
Batch 63/64 loss: 0.2021803855895996
Batch 64/64 loss: 0.2125939130783081
Epoch 346  Train loss: 0.21563668391283822  Val loss: 0.2692379935090894
Epoch 347
-------------------------------
Batch 1/64 loss: 0.21269500255584717
Batch 2/64 loss: 0.23604434728622437
Batch 3/64 loss: 0.2182682752609253
Batch 4/64 loss: 0.2101346254348755
Batch 5/64 loss: 0.20718520879745483
Batch 6/64 loss: 0.20624887943267822
Batch 7/64 loss: 0.22029799222946167
Batch 8/64 loss: 0.21663939952850342
Batch 9/64 loss: 0.21271014213562012
Batch 10/64 loss: 0.21337538957595825
Batch 11/64 loss: 0.21912503242492676
Batch 12/64 loss: 0.206853985786438
Batch 13/64 loss: 0.21115809679031372
Batch 14/64 loss: 0.21482563018798828
Batch 15/64 loss: 0.2352634072303772
Batch 16/64 loss: 0.21374499797821045
Batch 17/64 loss: 0.2131595015525818
Batch 18/64 loss: 0.21679019927978516
Batch 19/64 loss: 0.21912729740142822
Batch 20/64 loss: 0.21418797969818115
Batch 21/64 loss: 0.21226990222930908
Batch 22/64 loss: 0.20923113822937012
Batch 23/64 loss: 0.21189028024673462
Batch 24/64 loss: 0.2173505425453186
Batch 25/64 loss: 0.22236967086791992
Batch 26/64 loss: 0.2159440517425537
Batch 27/64 loss: 0.22187280654907227
Batch 28/64 loss: 0.20925140380859375
Batch 29/64 loss: 0.2175503969192505
Batch 30/64 loss: 0.22136294841766357
Batch 31/64 loss: 0.214596688747406
Batch 32/64 loss: 0.2113950252532959
Batch 33/64 loss: 0.21404868364334106
Batch 34/64 loss: 0.2220546007156372
Batch 35/64 loss: 0.21741962432861328
Batch 36/64 loss: 0.2211739420890808
Batch 37/64 loss: 0.21944725513458252
Batch 38/64 loss: 0.2279009222984314
Batch 39/64 loss: 0.2152920365333557
Batch 40/64 loss: 0.2209598422050476
Batch 41/64 loss: 0.2199702262878418
Batch 42/64 loss: 0.21632152795791626
Batch 43/64 loss: 0.21278059482574463
Batch 44/64 loss: 0.21131432056427002
Batch 45/64 loss: 0.20872658491134644
Batch 46/64 loss: 0.22164583206176758
Batch 47/64 loss: 0.2183123230934143
Batch 48/64 loss: 0.2119746208190918
Batch 49/64 loss: 0.21649932861328125
Batch 50/64 loss: 0.2139192819595337
Batch 51/64 loss: 0.22808772325515747
Batch 52/64 loss: 0.21178275346755981
Batch 53/64 loss: 0.21223074197769165
Batch 54/64 loss: 0.22568166255950928
Batch 55/64 loss: 0.2141590118408203
Batch 56/64 loss: 0.22195982933044434
Batch 57/64 loss: 0.21546721458435059
Batch 58/64 loss: 0.21829891204833984
Batch 59/64 loss: 0.21577012538909912
Batch 60/64 loss: 0.20968616008758545
Batch 61/64 loss: 0.21098536252975464
Batch 62/64 loss: 0.22152799367904663
Batch 63/64 loss: 0.2142655849456787
Batch 64/64 loss: 0.21844851970672607
Epoch 347  Train loss: 0.21641445113163368  Val loss: 0.2693424554624918
Epoch 348
-------------------------------
Batch 1/64 loss: 0.2131040096282959
Batch 2/64 loss: 0.21083557605743408
Batch 3/64 loss: 0.2128593921661377
Batch 4/64 loss: 0.2097967267036438
Batch 5/64 loss: 0.23285847902297974
Batch 6/64 loss: 0.2079930305480957
Batch 7/64 loss: 0.22026973962783813
Batch 8/64 loss: 0.21708190441131592
Batch 9/64 loss: 0.21951311826705933
Batch 10/64 loss: 0.21739935874938965
Batch 11/64 loss: 0.22025686502456665
Batch 12/64 loss: 0.21657752990722656
Batch 13/64 loss: 0.21258795261383057
Batch 14/64 loss: 0.20976239442825317
Batch 15/64 loss: 0.21245694160461426
Batch 16/64 loss: 0.20506340265274048
Batch 17/64 loss: 0.216502845287323
Batch 18/64 loss: 0.21483063697814941
Batch 19/64 loss: 0.21212244033813477
Batch 20/64 loss: 0.2161475419998169
Batch 21/64 loss: 0.20568633079528809
Batch 22/64 loss: 0.2097644805908203
Batch 23/64 loss: 0.21734869480133057
Batch 24/64 loss: 0.21671104431152344
Batch 25/64 loss: 0.22136425971984863
Batch 26/64 loss: 0.21156388521194458
Batch 27/64 loss: 0.2169036865234375
Batch 28/64 loss: 0.21452045440673828
Batch 29/64 loss: 0.21190202236175537
Batch 30/64 loss: 0.21605777740478516
Batch 31/64 loss: 0.21916550397872925
Batch 32/64 loss: 0.20477354526519775
Batch 33/64 loss: 0.2173902988433838
Batch 34/64 loss: 0.22340452671051025
Batch 35/64 loss: 0.21361863613128662
Batch 36/64 loss: 0.21312212944030762
Batch 37/64 loss: 0.21043556928634644
Batch 38/64 loss: 0.21148526668548584
Batch 39/64 loss: 0.20427554845809937
Batch 40/64 loss: 0.2171648144721985
Batch 41/64 loss: 0.20993995666503906
Batch 42/64 loss: 0.20513951778411865
Batch 43/64 loss: 0.20822608470916748
Batch 44/64 loss: 0.2198629379272461
Batch 45/64 loss: 0.22337961196899414
Batch 46/64 loss: 0.20617449283599854
Batch 47/64 loss: 0.21468663215637207
Batch 48/64 loss: 0.21109700202941895
Batch 49/64 loss: 0.21065664291381836
Batch 50/64 loss: 0.21424192190170288
Batch 51/64 loss: 0.21494871377944946
Batch 52/64 loss: 0.21528613567352295
Batch 53/64 loss: 0.22026598453521729
Batch 54/64 loss: 0.213731050491333
Batch 55/64 loss: 0.20580828189849854
Batch 56/64 loss: 0.2143462896347046
Batch 57/64 loss: 0.21074771881103516
Batch 58/64 loss: 0.21924346685409546
Batch 59/64 loss: 0.22302794456481934
Batch 60/64 loss: 0.22130835056304932
Batch 61/64 loss: 0.21934020519256592
Batch 62/64 loss: 0.22823357582092285
Batch 63/64 loss: 0.21247470378875732
Batch 64/64 loss: 0.21373587846755981
Epoch 348  Train loss: 0.2145434900826099  Val loss: 0.2690047742574895
Epoch 349
-------------------------------
Batch 1/64 loss: 0.20736289024353027
Batch 2/64 loss: 0.2225879430770874
Batch 3/64 loss: 0.21997129917144775
Batch 4/64 loss: 0.21764427423477173
Batch 5/64 loss: 0.20679032802581787
Batch 6/64 loss: 0.2352524995803833
Batch 7/64 loss: 0.21139448881149292
Batch 8/64 loss: 0.2190074920654297
Batch 9/64 loss: 0.2193511724472046
Batch 10/64 loss: 0.21317970752716064
Batch 11/64 loss: 0.21192634105682373
Batch 12/64 loss: 0.21126538515090942
Batch 13/64 loss: 0.22183650732040405
Batch 14/64 loss: 0.22058475017547607
Batch 15/64 loss: 0.21577727794647217
Batch 16/64 loss: 0.20696771144866943
Batch 17/64 loss: 0.21521764993667603
Batch 18/64 loss: 0.22207969427108765
Batch 19/64 loss: 0.2127920389175415
Batch 20/64 loss: 0.21497619152069092
Batch 21/64 loss: 0.21334338188171387
Batch 22/64 loss: 0.21802157163619995
Batch 23/64 loss: 0.2244250774383545
Batch 24/64 loss: 0.2244468331336975
Batch 25/64 loss: 0.21408218145370483
Batch 26/64 loss: 0.204950213432312
Batch 27/64 loss: 0.21793413162231445
Batch 28/64 loss: 0.2233370542526245
Batch 29/64 loss: 0.21106219291687012
Batch 30/64 loss: 0.21791177988052368
Batch 31/64 loss: 0.21231204271316528
Batch 32/64 loss: 0.2180885672569275
Batch 33/64 loss: 0.20811784267425537
Batch 34/64 loss: 0.21254539489746094
Batch 35/64 loss: 0.21251970529556274
Batch 36/64 loss: 0.2150588035583496
Batch 37/64 loss: 0.20254456996917725
Batch 38/64 loss: 0.21090221405029297
Batch 39/64 loss: 0.2199620008468628
Batch 40/64 loss: 0.2209610939025879
Batch 41/64 loss: 0.2158876657485962
Batch 42/64 loss: 0.21261215209960938
Batch 43/64 loss: 0.21821379661560059
Batch 44/64 loss: 0.2192860245704651
Batch 45/64 loss: 0.2149566411972046
Batch 46/64 loss: 0.2305784821510315
Batch 47/64 loss: 0.20754504203796387
Batch 48/64 loss: 0.21560204029083252
Batch 49/64 loss: 0.21316170692443848
Batch 50/64 loss: 0.22281867265701294
Batch 51/64 loss: 0.21770620346069336
Batch 52/64 loss: 0.20774245262145996
Batch 53/64 loss: 0.22851550579071045
Batch 54/64 loss: 0.2160879373550415
Batch 55/64 loss: 0.21826648712158203
Batch 56/64 loss: 0.22486138343811035
Batch 57/64 loss: 0.21652376651763916
Batch 58/64 loss: 0.21005964279174805
Batch 59/64 loss: 0.2188422679901123
Batch 60/64 loss: 0.2196033000946045
Batch 61/64 loss: 0.211825430393219
Batch 62/64 loss: 0.21050405502319336
Batch 63/64 loss: 0.20817923545837402
Batch 64/64 loss: 0.212940514087677
Epoch 349  Train loss: 0.21596200115540448  Val loss: 0.27010843311388466
Epoch 350
-------------------------------
Batch 1/64 loss: 0.20633059740066528
Batch 2/64 loss: 0.2256380319595337
Batch 3/64 loss: 0.21859025955200195
Batch 4/64 loss: 0.20266205072402954
Batch 5/64 loss: 0.2055026888847351
Batch 6/64 loss: 0.23212403059005737
Batch 7/64 loss: 0.22275269031524658
Batch 8/64 loss: 0.20993024110794067
Batch 9/64 loss: 0.20901882648468018
Batch 10/64 loss: 0.21293604373931885
Batch 11/64 loss: 0.21187639236450195
Batch 12/64 loss: 0.2112642526626587
Batch 13/64 loss: 0.21613484621047974
Batch 14/64 loss: 0.21606630086898804
Batch 15/64 loss: 0.2277226448059082
Batch 16/64 loss: 0.2187422513961792
Batch 17/64 loss: 0.21850180625915527
Batch 18/64 loss: 0.21140873432159424
Batch 19/64 loss: 0.2195148468017578
Batch 20/64 loss: 0.21678662300109863
Batch 21/64 loss: 0.21132707595825195
Batch 22/64 loss: 0.22098249197006226
Batch 23/64 loss: 0.2179933786392212
Batch 24/64 loss: 0.21865803003311157
Batch 25/64 loss: 0.21120214462280273
Batch 26/64 loss: 0.21396732330322266
Batch 27/64 loss: 0.21269357204437256
Batch 28/64 loss: 0.2144864797592163
Batch 29/64 loss: 0.21850812435150146
Batch 30/64 loss: 0.20329159498214722
Batch 31/64 loss: 0.21766555309295654
Batch 32/64 loss: 0.21837806701660156
Batch 33/64 loss: 0.21203452348709106
Batch 34/64 loss: 0.22195088863372803
Batch 35/64 loss: 0.21027016639709473
Batch 36/64 loss: 0.21381020545959473
Batch 37/64 loss: 0.20992743968963623
Batch 38/64 loss: 0.20926213264465332
Batch 39/64 loss: 0.21132349967956543
Batch 40/64 loss: 0.20663845539093018
Batch 41/64 loss: 0.2144479751586914
Batch 42/64 loss: 0.21343547105789185
Batch 43/64 loss: 0.21766376495361328
Batch 44/64 loss: 0.21103614568710327
Batch 45/64 loss: 0.21657997369766235
Batch 46/64 loss: 0.21764135360717773
Batch 47/64 loss: 0.20981281995773315
Batch 48/64 loss: 0.2328876256942749
Batch 49/64 loss: 0.21838611364364624
Batch 50/64 loss: 0.21584469079971313
Batch 51/64 loss: 0.20903873443603516
Batch 52/64 loss: 0.2200116515159607
Batch 53/64 loss: 0.22377890348434448
Batch 54/64 loss: 0.21645617485046387
Batch 55/64 loss: 0.21751081943511963
Batch 56/64 loss: 0.21590232849121094
Batch 57/64 loss: 0.21648788452148438
Batch 58/64 loss: 0.21470963954925537
Batch 59/64 loss: 0.21902549266815186
Batch 60/64 loss: 0.21026962995529175
Batch 61/64 loss: 0.22076594829559326
Batch 62/64 loss: 0.202301025390625
Batch 63/64 loss: 0.22114264965057373
Batch 64/64 loss: 0.21776866912841797
Epoch 350  Train loss: 0.21531511568555645  Val loss: 0.27006071601127024
Epoch 351
-------------------------------
Batch 1/64 loss: 0.20743215084075928
Batch 2/64 loss: 0.2105984091758728
Batch 3/64 loss: 0.2233675718307495
Batch 4/64 loss: 0.21668124198913574
Batch 5/64 loss: 0.20904541015625
Batch 6/64 loss: 0.21853840351104736
Batch 7/64 loss: 0.21640658378601074
Batch 8/64 loss: 0.21082472801208496
Batch 9/64 loss: 0.20855247974395752
Batch 10/64 loss: 0.20662754774093628
Batch 11/64 loss: 0.2149982452392578
Batch 12/64 loss: 0.21288621425628662
Batch 13/64 loss: 0.20987212657928467
Batch 14/64 loss: 0.2183336615562439
Batch 15/64 loss: 0.20950686931610107
Batch 16/64 loss: 0.21659260988235474
Batch 17/64 loss: 0.20859724283218384
Batch 18/64 loss: 0.21190166473388672
Batch 19/64 loss: 0.22082465887069702
Batch 20/64 loss: 0.2244563102722168
Batch 21/64 loss: 0.21661168336868286
Batch 22/64 loss: 0.21279633045196533
Batch 23/64 loss: 0.21029096841812134
Batch 24/64 loss: 0.2232428789138794
Batch 25/64 loss: 0.2029350996017456
Batch 26/64 loss: 0.2073206901550293
Batch 27/64 loss: 0.2164163589477539
Batch 28/64 loss: 0.2102344036102295
Batch 29/64 loss: 0.21699905395507812
Batch 30/64 loss: 0.20795047283172607
Batch 31/64 loss: 0.20974016189575195
Batch 32/64 loss: 0.2147301435470581
Batch 33/64 loss: 0.21171873807907104
Batch 34/64 loss: 0.2119351625442505
Batch 35/64 loss: 0.22095990180969238
Batch 36/64 loss: 0.23282921314239502
Batch 37/64 loss: 0.21485555171966553
Batch 38/64 loss: 0.2144099473953247
Batch 39/64 loss: 0.2072134017944336
Batch 40/64 loss: 0.21014350652694702
Batch 41/64 loss: 0.2174229621887207
Batch 42/64 loss: 0.2199934720993042
Batch 43/64 loss: 0.21914976835250854
Batch 44/64 loss: 0.21051859855651855
Batch 45/64 loss: 0.22308117151260376
Batch 46/64 loss: 0.2206035852432251
Batch 47/64 loss: 0.20904570817947388
Batch 48/64 loss: 0.2109973430633545
Batch 49/64 loss: 0.21244966983795166
Batch 50/64 loss: 0.21723949909210205
Batch 51/64 loss: 0.21608078479766846
Batch 52/64 loss: 0.21607494354248047
Batch 53/64 loss: 0.20815718173980713
Batch 54/64 loss: 0.21236759424209595
Batch 55/64 loss: 0.21640390157699585
Batch 56/64 loss: 0.2182086706161499
Batch 57/64 loss: 0.21251672506332397
Batch 58/64 loss: 0.21951687335968018
Batch 59/64 loss: 0.20977675914764404
Batch 60/64 loss: 0.21110749244689941
Batch 61/64 loss: 0.22957879304885864
Batch 62/64 loss: 0.21085244417190552
Batch 63/64 loss: 0.22321629524230957
Batch 64/64 loss: 0.21090608835220337
Epoch 351  Train loss: 0.2144614525869781  Val loss: 0.2686724529643239
Epoch 352
-------------------------------
Batch 1/64 loss: 0.2190314531326294
Batch 2/64 loss: 0.21370446681976318
Batch 3/64 loss: 0.21882081031799316
Batch 4/64 loss: 0.22191983461380005
Batch 5/64 loss: 0.21306753158569336
Batch 6/64 loss: 0.21367865800857544
Batch 7/64 loss: 0.21460014581680298
Batch 8/64 loss: 0.21247810125350952
Batch 9/64 loss: 0.21767932176589966
Batch 10/64 loss: 0.20374655723571777
Batch 11/64 loss: 0.22492146492004395
Batch 12/64 loss: 0.21139580011367798
Batch 13/64 loss: 0.215110182762146
Batch 14/64 loss: 0.22047722339630127
Batch 15/64 loss: 0.20611584186553955
Batch 16/64 loss: 0.20634305477142334
Batch 17/64 loss: 0.21617257595062256
Batch 18/64 loss: 0.21431738138198853
Batch 19/64 loss: 0.22575771808624268
Batch 20/64 loss: 0.2120227813720703
Batch 21/64 loss: 0.21789413690567017
Batch 22/64 loss: 0.210221529006958
Batch 23/64 loss: 0.21929073333740234
Batch 24/64 loss: 0.2130337953567505
Batch 25/64 loss: 0.21138978004455566
Batch 26/64 loss: 0.21661603450775146
Batch 27/64 loss: 0.21030986309051514
Batch 28/64 loss: 0.2103334665298462
Batch 29/64 loss: 0.21154457330703735
Batch 30/64 loss: 0.21816271543502808
Batch 31/64 loss: 0.21461784839630127
Batch 32/64 loss: 0.21100306510925293
Batch 33/64 loss: 0.20455050468444824
Batch 34/64 loss: 0.2234160304069519
Batch 35/64 loss: 0.21234500408172607
Batch 36/64 loss: 0.2172147035598755
Batch 37/64 loss: 0.22253906726837158
Batch 38/64 loss: 0.21808326244354248
Batch 39/64 loss: 0.22182857990264893
Batch 40/64 loss: 0.2084941864013672
Batch 41/64 loss: 0.21714210510253906
Batch 42/64 loss: 0.21723437309265137
Batch 43/64 loss: 0.21923381090164185
Batch 44/64 loss: 0.22345787286758423
Batch 45/64 loss: 0.2121971845626831
Batch 46/64 loss: 0.22116613388061523
Batch 47/64 loss: 0.21471673250198364
Batch 48/64 loss: 0.21915608644485474
Batch 49/64 loss: 0.21212238073349
Batch 50/64 loss: 0.21522247791290283
Batch 51/64 loss: 0.2278810739517212
Batch 52/64 loss: 0.21713745594024658
Batch 53/64 loss: 0.21807825565338135
Batch 54/64 loss: 0.22381490468978882
Batch 55/64 loss: 0.213392972946167
Batch 56/64 loss: 0.2155243158340454
Batch 57/64 loss: 0.21507060527801514
Batch 58/64 loss: 0.21646571159362793
Batch 59/64 loss: 0.2201775312423706
Batch 60/64 loss: 0.22398245334625244
Batch 61/64 loss: 0.20974403619766235
Batch 62/64 loss: 0.22174477577209473
Batch 63/64 loss: 0.21341514587402344
Batch 64/64 loss: 0.21044456958770752
Epoch 352  Train loss: 0.21584567228953044  Val loss: 0.26841580417148025
Saving best model, epoch: 352
Epoch 353
-------------------------------
Batch 1/64 loss: 0.216788649559021
Batch 2/64 loss: 0.2135772705078125
Batch 3/64 loss: 0.20796561241149902
Batch 4/64 loss: 0.2249043583869934
Batch 5/64 loss: 0.20709621906280518
Batch 6/64 loss: 0.2124413251876831
Batch 7/64 loss: 0.216871440410614
Batch 8/64 loss: 0.22432774305343628
Batch 9/64 loss: 0.22447055578231812
Batch 10/64 loss: 0.21579843759536743
Batch 11/64 loss: 0.21905237436294556
Batch 12/64 loss: 0.23171472549438477
Batch 13/64 loss: 0.22006666660308838
Batch 14/64 loss: 0.20728659629821777
Batch 15/64 loss: 0.22651875019073486
Batch 16/64 loss: 0.20333290100097656
Batch 17/64 loss: 0.22199225425720215
Batch 18/64 loss: 0.20498573780059814
Batch 19/64 loss: 0.21910196542739868
Batch 20/64 loss: 0.21107780933380127
Batch 21/64 loss: 0.21059393882751465
Batch 22/64 loss: 0.202417254447937
Batch 23/64 loss: 0.2164972424507141
Batch 24/64 loss: 0.21402859687805176
Batch 25/64 loss: 0.21581488847732544
Batch 26/64 loss: 0.21708238124847412
Batch 27/64 loss: 0.21657073497772217
Batch 28/64 loss: 0.20906919240951538
Batch 29/64 loss: 0.20546376705169678
Batch 30/64 loss: 0.2127758264541626
Batch 31/64 loss: 0.2047882080078125
Batch 32/64 loss: 0.2136058807373047
Batch 33/64 loss: 0.21032249927520752
Batch 34/64 loss: 0.2202305793762207
Batch 35/64 loss: 0.20712298154830933
Batch 36/64 loss: 0.20216822624206543
Batch 37/64 loss: 0.22480952739715576
Batch 38/64 loss: 0.21336781978607178
Batch 39/64 loss: 0.20828235149383545
Batch 40/64 loss: 0.21946382522583008
Batch 41/64 loss: 0.21442413330078125
Batch 42/64 loss: 0.20564734935760498
Batch 43/64 loss: 0.21777987480163574
Batch 44/64 loss: 0.22185558080673218
Batch 45/64 loss: 0.21945655345916748
Batch 46/64 loss: 0.21630507707595825
Batch 47/64 loss: 0.21675264835357666
Batch 48/64 loss: 0.21852433681488037
Batch 49/64 loss: 0.20616185665130615
Batch 50/64 loss: 0.2194209098815918
Batch 51/64 loss: 0.20224475860595703
Batch 52/64 loss: 0.22095859050750732
Batch 53/64 loss: 0.21462476253509521
Batch 54/64 loss: 0.21701359748840332
Batch 55/64 loss: 0.21731293201446533
Batch 56/64 loss: 0.22173398733139038
Batch 57/64 loss: 0.22128689289093018
Batch 58/64 loss: 0.21967697143554688
Batch 59/64 loss: 0.21505820751190186
Batch 60/64 loss: 0.2064252495765686
Batch 61/64 loss: 0.21848064661026
Batch 62/64 loss: 0.2123502492904663
Batch 63/64 loss: 0.22711634635925293
Batch 64/64 loss: 0.21603631973266602
Epoch 353  Train loss: 0.21500369988235773  Val loss: 0.2686995898735073
Epoch 354
-------------------------------
Batch 1/64 loss: 0.21138596534729004
Batch 2/64 loss: 0.206335186958313
Batch 3/64 loss: 0.20800042152404785
Batch 4/64 loss: 0.20769870281219482
Batch 5/64 loss: 0.20973026752471924
Batch 6/64 loss: 0.2164781093597412
Batch 7/64 loss: 0.20554083585739136
Batch 8/64 loss: 0.20894265174865723
Batch 9/64 loss: 0.21126842498779297
Batch 10/64 loss: 0.2092909812927246
Batch 11/64 loss: 0.21753448247909546
Batch 12/64 loss: 0.22221404314041138
Batch 13/64 loss: 0.2093508243560791
Batch 14/64 loss: 0.21610677242279053
Batch 15/64 loss: 0.21459650993347168
Batch 16/64 loss: 0.21237587928771973
Batch 17/64 loss: 0.21560800075531006
Batch 18/64 loss: 0.21602725982666016
Batch 19/64 loss: 0.22222721576690674
Batch 20/64 loss: 0.204021155834198
Batch 21/64 loss: 0.21940350532531738
Batch 22/64 loss: 0.2156306505203247
Batch 23/64 loss: 0.22071146965026855
Batch 24/64 loss: 0.21478259563446045
Batch 25/64 loss: 0.21650075912475586
Batch 26/64 loss: 0.22510480880737305
Batch 27/64 loss: 0.21014058589935303
Batch 28/64 loss: 0.21536916494369507
Batch 29/64 loss: 0.20925617218017578
Batch 30/64 loss: 0.21803468465805054
Batch 31/64 loss: 0.21495592594146729
Batch 32/64 loss: 0.21063625812530518
Batch 33/64 loss: 0.20893335342407227
Batch 34/64 loss: 0.21732115745544434
Batch 35/64 loss: 0.21210980415344238
Batch 36/64 loss: 0.21280288696289062
Batch 37/64 loss: 0.22882592678070068
Batch 38/64 loss: 0.22577989101409912
Batch 39/64 loss: 0.21526896953582764
Batch 40/64 loss: 0.22957557439804077
Batch 41/64 loss: 0.21944117546081543
Batch 42/64 loss: 0.21100127696990967
Batch 43/64 loss: 0.21053707599639893
Batch 44/64 loss: 0.2223806381225586
Batch 45/64 loss: 0.20851051807403564
Batch 46/64 loss: 0.20930767059326172
Batch 47/64 loss: 0.21852493286132812
Batch 48/64 loss: 0.21057045459747314
Batch 49/64 loss: 0.20204132795333862
Batch 50/64 loss: 0.20585358142852783
Batch 51/64 loss: 0.21795928478240967
Batch 52/64 loss: 0.22254455089569092
Batch 53/64 loss: 0.20907801389694214
Batch 54/64 loss: 0.21813160181045532
Batch 55/64 loss: 0.2087729573249817
Batch 56/64 loss: 0.20757800340652466
Batch 57/64 loss: 0.22114473581314087
Batch 58/64 loss: 0.21557247638702393
Batch 59/64 loss: 0.21613085269927979
Batch 60/64 loss: 0.2295042872428894
Batch 61/64 loss: 0.21276962757110596
Batch 62/64 loss: 0.21403932571411133
Batch 63/64 loss: 0.20916247367858887
Batch 64/64 loss: 0.21658855676651
Epoch 354  Train loss: 0.2144137426918628  Val loss: 0.2683669705571178
Saving best model, epoch: 354
Epoch 355
-------------------------------
Batch 1/64 loss: 0.2088932991027832
Batch 2/64 loss: 0.20390218496322632
Batch 3/64 loss: 0.21330559253692627
Batch 4/64 loss: 0.21646064519882202
Batch 5/64 loss: 0.21593022346496582
Batch 6/64 loss: 0.20999515056610107
Batch 7/64 loss: 0.2118396759033203
Batch 8/64 loss: 0.2105422019958496
Batch 9/64 loss: 0.21213746070861816
Batch 10/64 loss: 0.21170198917388916
Batch 11/64 loss: 0.2124689817428589
Batch 12/64 loss: 0.2279178500175476
Batch 13/64 loss: 0.20121949911117554
Batch 14/64 loss: 0.2152615189552307
Batch 15/64 loss: 0.21940720081329346
Batch 16/64 loss: 0.21245241165161133
Batch 17/64 loss: 0.2131829857826233
Batch 18/64 loss: 0.21635878086090088
Batch 19/64 loss: 0.21486103534698486
Batch 20/64 loss: 0.2179321050643921
Batch 21/64 loss: 0.2196977138519287
Batch 22/64 loss: 0.20493751764297485
Batch 23/64 loss: 0.2051001787185669
Batch 24/64 loss: 0.21440207958221436
Batch 25/64 loss: 0.20732158422470093
Batch 26/64 loss: 0.2144986391067505
Batch 27/64 loss: 0.21606969833374023
Batch 28/64 loss: 0.20932269096374512
Batch 29/64 loss: 0.21193373203277588
Batch 30/64 loss: 0.2134827971458435
Batch 31/64 loss: 0.22811448574066162
Batch 32/64 loss: 0.2036832571029663
Batch 33/64 loss: 0.21570736169815063
Batch 34/64 loss: 0.21750891208648682
Batch 35/64 loss: 0.21359026432037354
Batch 36/64 loss: 0.21871554851531982
Batch 37/64 loss: 0.22080016136169434
Batch 38/64 loss: 0.2153714895248413
Batch 39/64 loss: 0.22150498628616333
Batch 40/64 loss: 0.2170429825782776
Batch 41/64 loss: 0.21019703149795532
Batch 42/64 loss: 0.21406608819961548
Batch 43/64 loss: 0.22583383321762085
Batch 44/64 loss: 0.21570205688476562
Batch 45/64 loss: 0.20898473262786865
Batch 46/64 loss: 0.21408820152282715
Batch 47/64 loss: 0.2173178791999817
Batch 48/64 loss: 0.21665775775909424
Batch 49/64 loss: 0.21338975429534912
Batch 50/64 loss: 0.21063435077667236
Batch 51/64 loss: 0.21671950817108154
Batch 52/64 loss: 0.21522611379623413
Batch 53/64 loss: 0.22920548915863037
Batch 54/64 loss: 0.22248351573944092
Batch 55/64 loss: 0.2097465991973877
Batch 56/64 loss: 0.2181391716003418
Batch 57/64 loss: 0.215620756149292
Batch 58/64 loss: 0.20485371351242065
Batch 59/64 loss: 0.21877837181091309
Batch 60/64 loss: 0.23639845848083496
Batch 61/64 loss: 0.21916615962982178
Batch 62/64 loss: 0.21613764762878418
Batch 63/64 loss: 0.20987939834594727
Batch 64/64 loss: 0.2090303897857666
Epoch 355  Train loss: 0.2147541373383765  Val loss: 0.2688332411022121
Epoch 356
-------------------------------
Batch 1/64 loss: 0.21333014965057373
Batch 2/64 loss: 0.20812344551086426
Batch 3/64 loss: 0.20874518156051636
Batch 4/64 loss: 0.21462392807006836
Batch 5/64 loss: 0.21683967113494873
Batch 6/64 loss: 0.2072315812110901
Batch 7/64 loss: 0.20799654722213745
Batch 8/64 loss: 0.22360330820083618
Batch 9/64 loss: 0.2143152952194214
Batch 10/64 loss: 0.21844297647476196
Batch 11/64 loss: 0.21063566207885742
Batch 12/64 loss: 0.21625667810440063
Batch 13/64 loss: 0.21577727794647217
Batch 14/64 loss: 0.2169795036315918
Batch 15/64 loss: 0.21251440048217773
Batch 16/64 loss: 0.21244990825653076
Batch 17/64 loss: 0.2056533694267273
Batch 18/64 loss: 0.2160097360610962
Batch 19/64 loss: 0.22623944282531738
Batch 20/64 loss: 0.20260226726531982
Batch 21/64 loss: 0.21030199527740479
Batch 22/64 loss: 0.2173653244972229
Batch 23/64 loss: 0.2133210301399231
Batch 24/64 loss: 0.2050950527191162
Batch 25/64 loss: 0.2011568546295166
Batch 26/64 loss: 0.21988117694854736
Batch 27/64 loss: 0.2254381775856018
Batch 28/64 loss: 0.20889627933502197
Batch 29/64 loss: 0.2044076919555664
Batch 30/64 loss: 0.2154495120048523
Batch 31/64 loss: 0.22767162322998047
Batch 32/64 loss: 0.23026907444000244
Batch 33/64 loss: 0.22135907411575317
Batch 34/64 loss: 0.20573079586029053
Batch 35/64 loss: 0.20394766330718994
Batch 36/64 loss: 0.22415614128112793
Batch 37/64 loss: 0.2156221866607666
Batch 38/64 loss: 0.2166651487350464
Batch 39/64 loss: 0.21794694662094116
Batch 40/64 loss: 0.21410787105560303
Batch 41/64 loss: 0.21217560768127441
Batch 42/64 loss: 0.20778793096542358
Batch 43/64 loss: 0.20155763626098633
Batch 44/64 loss: 0.21184176206588745
Batch 45/64 loss: 0.2132580280303955
Batch 46/64 loss: 0.21884071826934814
Batch 47/64 loss: 0.21438288688659668
Batch 48/64 loss: 0.20195066928863525
Batch 49/64 loss: 0.20787352323532104
Batch 50/64 loss: 0.21517866849899292
Batch 51/64 loss: 0.2131749987602234
Batch 52/64 loss: 0.21667730808258057
Batch 53/64 loss: 0.2143571376800537
Batch 54/64 loss: 0.20719420909881592
Batch 55/64 loss: 0.21232718229293823
Batch 56/64 loss: 0.22192132472991943
Batch 57/64 loss: 0.20655834674835205
Batch 58/64 loss: 0.20490503311157227
Batch 59/64 loss: 0.21922099590301514
Batch 60/64 loss: 0.20981299877166748
Batch 61/64 loss: 0.22028672695159912
Batch 62/64 loss: 0.22526651620864868
Batch 63/64 loss: 0.21898984909057617
Batch 64/64 loss: 0.21728312969207764
Epoch 356  Train loss: 0.21373588010376576  Val loss: 0.2686025565842173
Epoch 357
-------------------------------
Batch 1/64 loss: 0.20388972759246826
Batch 2/64 loss: 0.20919382572174072
Batch 3/64 loss: 0.21541595458984375
Batch 4/64 loss: 0.21452081203460693
Batch 5/64 loss: 0.20848029851913452
Batch 6/64 loss: 0.20557951927185059
Batch 7/64 loss: 0.20663094520568848
Batch 8/64 loss: 0.2100505828857422
Batch 9/64 loss: 0.2386157512664795
Batch 10/64 loss: 0.20504790544509888
Batch 11/64 loss: 0.2118549346923828
Batch 12/64 loss: 0.20538896322250366
Batch 13/64 loss: 0.22004663944244385
Batch 14/64 loss: 0.2121049165725708
Batch 15/64 loss: 0.21233582496643066
Batch 16/64 loss: 0.22369372844696045
Batch 17/64 loss: 0.21953338384628296
Batch 18/64 loss: 0.20822381973266602
Batch 19/64 loss: 0.2113795280456543
Batch 20/64 loss: 0.20827925205230713
Batch 21/64 loss: 0.20507115125656128
Batch 22/64 loss: 0.21314620971679688
Batch 23/64 loss: 0.2175966501235962
Batch 24/64 loss: 0.20584970712661743
Batch 25/64 loss: 0.22025549411773682
Batch 26/64 loss: 0.2164936065673828
Batch 27/64 loss: 0.21297889947891235
Batch 28/64 loss: 0.21717053651809692
Batch 29/64 loss: 0.2123795747756958
Batch 30/64 loss: 0.21882295608520508
Batch 31/64 loss: 0.21398425102233887
Batch 32/64 loss: 0.21446996927261353
Batch 33/64 loss: 0.2040419578552246
Batch 34/64 loss: 0.22064638137817383
Batch 35/64 loss: 0.22309404611587524
Batch 36/64 loss: 0.20755410194396973
Batch 37/64 loss: 0.21528828144073486
Batch 38/64 loss: 0.20872926712036133
Batch 39/64 loss: 0.219740629196167
Batch 40/64 loss: 0.21981596946716309
Batch 41/64 loss: 0.20804065465927124
Batch 42/64 loss: 0.2144472599029541
Batch 43/64 loss: 0.21568834781646729
Batch 44/64 loss: 0.20981645584106445
Batch 45/64 loss: 0.21196216344833374
Batch 46/64 loss: 0.21982181072235107
Batch 47/64 loss: 0.20746934413909912
Batch 48/64 loss: 0.21339154243469238
Batch 49/64 loss: 0.2117842435836792
Batch 50/64 loss: 0.2230679988861084
Batch 51/64 loss: 0.2235475778579712
Batch 52/64 loss: 0.20938152074813843
Batch 53/64 loss: 0.2157226800918579
Batch 54/64 loss: 0.2257784605026245
Batch 55/64 loss: 0.21251481771469116
Batch 56/64 loss: 0.2309894561767578
Batch 57/64 loss: 0.21587598323822021
Batch 58/64 loss: 0.21873915195465088
Batch 59/64 loss: 0.2110384702682495
Batch 60/64 loss: 0.2167266607284546
Batch 61/64 loss: 0.21183204650878906
Batch 62/64 loss: 0.2208082675933838
Batch 63/64 loss: 0.21119654178619385
Batch 64/64 loss: 0.21209579706192017
Epoch 357  Train loss: 0.21421347856521605  Val loss: 0.2692538876713756
Epoch 358
-------------------------------
Batch 1/64 loss: 0.21135032176971436
Batch 2/64 loss: 0.216217041015625
Batch 3/64 loss: 0.21856999397277832
Batch 4/64 loss: 0.2023392915725708
Batch 5/64 loss: 0.20596885681152344
Batch 6/64 loss: 0.2027188539505005
Batch 7/64 loss: 0.21571552753448486
Batch 8/64 loss: 0.2121676206588745
Batch 9/64 loss: 0.2126917839050293
Batch 10/64 loss: 0.2090131640434265
Batch 11/64 loss: 0.21246206760406494
Batch 12/64 loss: 0.21475553512573242
Batch 13/64 loss: 0.20918893814086914
Batch 14/64 loss: 0.20942926406860352
Batch 15/64 loss: 0.20941126346588135
Batch 16/64 loss: 0.20685136318206787
Batch 17/64 loss: 0.21318411827087402
Batch 18/64 loss: 0.20778989791870117
Batch 19/64 loss: 0.21595966815948486
Batch 20/64 loss: 0.21256041526794434
Batch 21/64 loss: 0.21850228309631348
Batch 22/64 loss: 0.2146756649017334
Batch 23/64 loss: 0.22121894359588623
Batch 24/64 loss: 0.21237075328826904
Batch 25/64 loss: 0.2155095338821411
Batch 26/64 loss: 0.20870184898376465
Batch 27/64 loss: 0.2109275460243225
Batch 28/64 loss: 0.21598398685455322
Batch 29/64 loss: 0.2210984230041504
Batch 30/64 loss: 0.21843111515045166
Batch 31/64 loss: 0.22036808729171753
Batch 32/64 loss: 0.21709811687469482
Batch 33/64 loss: 0.2149820327758789
Batch 34/64 loss: 0.21284443140029907
Batch 35/64 loss: 0.20758575201034546
Batch 36/64 loss: 0.22031855583190918
Batch 37/64 loss: 0.21835827827453613
Batch 38/64 loss: 0.2060718536376953
Batch 39/64 loss: 0.20972943305969238
Batch 40/64 loss: 0.22705203294754028
Batch 41/64 loss: 0.21286475658416748
Batch 42/64 loss: 0.21707046031951904
Batch 43/64 loss: 0.21648812294006348
Batch 44/64 loss: 0.21846282482147217
Batch 45/64 loss: 0.21496981382369995
Batch 46/64 loss: 0.2184830904006958
Batch 47/64 loss: 0.2115699052810669
Batch 48/64 loss: 0.20602083206176758
Batch 49/64 loss: 0.21442866325378418
Batch 50/64 loss: 0.21147441864013672
Batch 51/64 loss: 0.20918303728103638
Batch 52/64 loss: 0.22400230169296265
Batch 53/64 loss: 0.225044846534729
Batch 54/64 loss: 0.2217540740966797
Batch 55/64 loss: 0.21098685264587402
Batch 56/64 loss: 0.2175840139389038
Batch 57/64 loss: 0.2107928991317749
Batch 58/64 loss: 0.2120569944381714
Batch 59/64 loss: 0.22193247079849243
Batch 60/64 loss: 0.20949894189834595
Batch 61/64 loss: 0.21139663457870483
Batch 62/64 loss: 0.2102421522140503
Batch 63/64 loss: 0.2124636173248291
Batch 64/64 loss: 0.21442878246307373
Epoch 358  Train loss: 0.21380026620977066  Val loss: 0.26842732855544466
Epoch 359
-------------------------------
Batch 1/64 loss: 0.2068508267402649
Batch 2/64 loss: 0.215124249458313
Batch 3/64 loss: 0.22171765565872192
Batch 4/64 loss: 0.20856869220733643
Batch 5/64 loss: 0.2073644995689392
Batch 6/64 loss: 0.20639419555664062
Batch 7/64 loss: 0.2022647261619568
Batch 8/64 loss: 0.20963400602340698
Batch 9/64 loss: 0.21325886249542236
Batch 10/64 loss: 0.2148028016090393
Batch 11/64 loss: 0.20748305320739746
Batch 12/64 loss: 0.20323294401168823
Batch 13/64 loss: 0.20980942249298096
Batch 14/64 loss: 0.20534491539001465
Batch 15/64 loss: 0.21197718381881714
Batch 16/64 loss: 0.22043311595916748
Batch 17/64 loss: 0.21022266149520874
Batch 18/64 loss: 0.2086334228515625
Batch 19/64 loss: 0.2128535509109497
Batch 20/64 loss: 0.21910154819488525
Batch 21/64 loss: 0.2091009020805359
Batch 22/64 loss: 0.20004016160964966
Batch 23/64 loss: 0.21635276079177856
Batch 24/64 loss: 0.2089613676071167
Batch 25/64 loss: 0.21541523933410645
Batch 26/64 loss: 0.22623306512832642
Batch 27/64 loss: 0.20826560258865356
Batch 28/64 loss: 0.2145366668701172
Batch 29/64 loss: 0.21220111846923828
Batch 30/64 loss: 0.21372747421264648
Batch 31/64 loss: 0.2112148404121399
Batch 32/64 loss: 0.21542692184448242
Batch 33/64 loss: 0.21070975065231323
Batch 34/64 loss: 0.21394270658493042
Batch 35/64 loss: 0.21174514293670654
Batch 36/64 loss: 0.20773398876190186
Batch 37/64 loss: 0.22726213932037354
Batch 38/64 loss: 0.20881348848342896
Batch 39/64 loss: 0.21350592374801636
Batch 40/64 loss: 0.21244579553604126
Batch 41/64 loss: 0.21657240390777588
Batch 42/64 loss: 0.21779078245162964
Batch 43/64 loss: 0.2120545506477356
Batch 44/64 loss: 0.20447075366973877
Batch 45/64 loss: 0.2132313847541809
Batch 46/64 loss: 0.20229172706604004
Batch 47/64 loss: 0.20750737190246582
Batch 48/64 loss: 0.21586209535598755
Batch 49/64 loss: 0.21097302436828613
Batch 50/64 loss: 0.2141033411026001
Batch 51/64 loss: 0.20866930484771729
Batch 52/64 loss: 0.2210407257080078
Batch 53/64 loss: 0.20943129062652588
Batch 54/64 loss: 0.21789926290512085
Batch 55/64 loss: 0.21807849407196045
Batch 56/64 loss: 0.2194921374320984
Batch 57/64 loss: 0.21018332242965698
Batch 58/64 loss: 0.20598232746124268
Batch 59/64 loss: 0.22086280584335327
Batch 60/64 loss: 0.2173582911491394
Batch 61/64 loss: 0.2238931655883789
Batch 62/64 loss: 0.2088083028793335
Batch 63/64 loss: 0.22080594301223755
Batch 64/64 loss: 0.21863198280334473
Epoch 359  Train loss: 0.21261245783637553  Val loss: 0.26955242337230145
Epoch 360
-------------------------------
Batch 1/64 loss: 0.20936226844787598
Batch 2/64 loss: 0.21323764324188232
Batch 3/64 loss: 0.21536791324615479
Batch 4/64 loss: 0.21288806200027466
Batch 5/64 loss: 0.21782994270324707
Batch 6/64 loss: 0.20924818515777588
Batch 7/64 loss: 0.2163448929786682
Batch 8/64 loss: 0.21258962154388428
Batch 9/64 loss: 0.20867663621902466
Batch 10/64 loss: 0.21335643529891968
Batch 11/64 loss: 0.2067018747329712
Batch 12/64 loss: 0.22078728675842285
Batch 13/64 loss: 0.2161310911178589
Batch 14/64 loss: 0.20773756504058838
Batch 15/64 loss: 0.20961624383926392
Batch 16/64 loss: 0.2099437713623047
Batch 17/64 loss: 0.22613167762756348
Batch 18/64 loss: 0.21506214141845703
Batch 19/64 loss: 0.20053434371948242
Batch 20/64 loss: 0.20625817775726318
Batch 21/64 loss: 0.2129504680633545
Batch 22/64 loss: 0.2332298755645752
Batch 23/64 loss: 0.21002691984176636
Batch 24/64 loss: 0.21952325105667114
Batch 25/64 loss: 0.21908318996429443
Batch 26/64 loss: 0.2061138153076172
Batch 27/64 loss: 0.22221088409423828
Batch 28/64 loss: 0.21022212505340576
Batch 29/64 loss: 0.21112215518951416
Batch 30/64 loss: 0.22942066192626953
Batch 31/64 loss: 0.21345388889312744
Batch 32/64 loss: 0.20901024341583252
Batch 33/64 loss: 0.2030787467956543
Batch 34/64 loss: 0.20850765705108643
Batch 35/64 loss: 0.22631961107254028
Batch 36/64 loss: 0.22046518325805664
Batch 37/64 loss: 0.22175133228302002
Batch 38/64 loss: 0.22305023670196533
Batch 39/64 loss: 0.22200536727905273
Batch 40/64 loss: 0.20700955390930176
Batch 41/64 loss: 0.2135155200958252
Batch 42/64 loss: 0.21793603897094727
Batch 43/64 loss: 0.21468693017959595
Batch 44/64 loss: 0.21201837062835693
Batch 45/64 loss: 0.2112882137298584
Batch 46/64 loss: 0.2148369550704956
Batch 47/64 loss: 0.20895349979400635
Batch 48/64 loss: 0.2088766098022461
Batch 49/64 loss: 0.20347929000854492
Batch 50/64 loss: 0.21762287616729736
Batch 51/64 loss: 0.21009016036987305
Batch 52/64 loss: 0.21063232421875
Batch 53/64 loss: 0.2090778350830078
Batch 54/64 loss: 0.2078685164451599
Batch 55/64 loss: 0.22317910194396973
Batch 56/64 loss: 0.2145182490348816
Batch 57/64 loss: 0.21981346607208252
Batch 58/64 loss: 0.21205711364746094
Batch 59/64 loss: 0.20883113145828247
Batch 60/64 loss: 0.20897674560546875
Batch 61/64 loss: 0.20847129821777344
Batch 62/64 loss: 0.20415419340133667
Batch 63/64 loss: 0.2122952938079834
Batch 64/64 loss: 0.21730709075927734
Epoch 360  Train loss: 0.21352974106283748  Val loss: 0.27023448239487063
Epoch 361
-------------------------------
Batch 1/64 loss: 0.20700442790985107
Batch 2/64 loss: 0.21126067638397217
Batch 3/64 loss: 0.20911121368408203
Batch 4/64 loss: 0.20352184772491455
Batch 5/64 loss: 0.21996551752090454
Batch 6/64 loss: 0.22250664234161377
Batch 7/64 loss: 0.21186405420303345
Batch 8/64 loss: 0.22149014472961426
Batch 9/64 loss: 0.20937883853912354
Batch 10/64 loss: 0.206162691116333
Batch 11/64 loss: 0.2189045548439026
Batch 12/64 loss: 0.20851171016693115
Batch 13/64 loss: 0.21901541948318481
Batch 14/64 loss: 0.20960038900375366
Batch 15/64 loss: 0.21161502599716187
Batch 16/64 loss: 0.20518100261688232
Batch 17/64 loss: 0.20358729362487793
Batch 18/64 loss: 0.21064138412475586
Batch 19/64 loss: 0.21187293529510498
Batch 20/64 loss: 0.21156728267669678
Batch 21/64 loss: 0.2204742431640625
Batch 22/64 loss: 0.21618330478668213
Batch 23/64 loss: 0.21095895767211914
Batch 24/64 loss: 0.22134816646575928
Batch 25/64 loss: 0.2099379301071167
Batch 26/64 loss: 0.2099711298942566
Batch 27/64 loss: 0.21709859371185303
Batch 28/64 loss: 0.21029269695281982
Batch 29/64 loss: 0.2111448049545288
Batch 30/64 loss: 0.21587252616882324
Batch 31/64 loss: 0.21848487854003906
Batch 32/64 loss: 0.20676511526107788
Batch 33/64 loss: 0.21186524629592896
Batch 34/64 loss: 0.21191412210464478
Batch 35/64 loss: 0.21785736083984375
Batch 36/64 loss: 0.20946532487869263
Batch 37/64 loss: 0.2177792191505432
Batch 38/64 loss: 0.22329604625701904
Batch 39/64 loss: 0.2088412046432495
Batch 40/64 loss: 0.21228057146072388
Batch 41/64 loss: 0.21750736236572266
Batch 42/64 loss: 0.21334707736968994
Batch 43/64 loss: 0.21521687507629395
Batch 44/64 loss: 0.21442490816116333
Batch 45/64 loss: 0.2144409418106079
Batch 46/64 loss: 0.21572667360305786
Batch 47/64 loss: 0.21868395805358887
Batch 48/64 loss: 0.21047067642211914
Batch 49/64 loss: 0.21513783931732178
Batch 50/64 loss: 0.2132977843284607
Batch 51/64 loss: 0.21307086944580078
Batch 52/64 loss: 0.21560609340667725
Batch 53/64 loss: 0.20923566818237305
Batch 54/64 loss: 0.21880018711090088
Batch 55/64 loss: 0.21226775646209717
Batch 56/64 loss: 0.2160886526107788
Batch 57/64 loss: 0.21405702829360962
Batch 58/64 loss: 0.21382391452789307
Batch 59/64 loss: 0.21623778343200684
Batch 60/64 loss: 0.21662837266921997
Batch 61/64 loss: 0.20373302698135376
Batch 62/64 loss: 0.21056455373764038
Batch 63/64 loss: 0.220414936542511
Batch 64/64 loss: 0.20484459400177002
Epoch 361  Train loss: 0.21328644518758735  Val loss: 0.2685029543552202
Epoch 362
-------------------------------
Batch 1/64 loss: 0.21961092948913574
Batch 2/64 loss: 0.20408058166503906
Batch 3/64 loss: 0.20603644847869873
Batch 4/64 loss: 0.21079808473587036
Batch 5/64 loss: 0.20907974243164062
Batch 6/64 loss: 0.21247315406799316
Batch 7/64 loss: 0.2174893617630005
Batch 8/64 loss: 0.221868097782135
Batch 9/64 loss: 0.20718348026275635
Batch 10/64 loss: 0.20583343505859375
Batch 11/64 loss: 0.20516341924667358
Batch 12/64 loss: 0.20886123180389404
Batch 13/64 loss: 0.20783460140228271
Batch 14/64 loss: 0.20767104625701904
Batch 15/64 loss: 0.2159101963043213
Batch 16/64 loss: 0.20938396453857422
Batch 17/64 loss: 0.21802937984466553
Batch 18/64 loss: 0.21844828128814697
Batch 19/64 loss: 0.20412588119506836
Batch 20/64 loss: 0.2184290885925293
Batch 21/64 loss: 0.21038967370986938
Batch 22/64 loss: 0.21107351779937744
Batch 23/64 loss: 0.21244871616363525
Batch 24/64 loss: 0.2112497091293335
Batch 25/64 loss: 0.22264283895492554
Batch 26/64 loss: 0.21645283699035645
Batch 27/64 loss: 0.20001369714736938
Batch 28/64 loss: 0.2082066535949707
Batch 29/64 loss: 0.20823168754577637
Batch 30/64 loss: 0.20379936695098877
Batch 31/64 loss: 0.2126307487487793
Batch 32/64 loss: 0.2269582748413086
Batch 33/64 loss: 0.21350467205047607
Batch 34/64 loss: 0.2067440152168274
Batch 35/64 loss: 0.2123204469680786
Batch 36/64 loss: 0.21900254487991333
Batch 37/64 loss: 0.20756769180297852
Batch 38/64 loss: 0.21770769357681274
Batch 39/64 loss: 0.2201911211013794
Batch 40/64 loss: 0.20304524898529053
Batch 41/64 loss: 0.21536844968795776
Batch 42/64 loss: 0.22602730989456177
Batch 43/64 loss: 0.21652477979660034
Batch 44/64 loss: 0.20479965209960938
Batch 45/64 loss: 0.21356618404388428
Batch 46/64 loss: 0.20852434635162354
Batch 47/64 loss: 0.22618556022644043
Batch 48/64 loss: 0.2072468400001526
Batch 49/64 loss: 0.21577274799346924
Batch 50/64 loss: 0.2136031985282898
Batch 51/64 loss: 0.2074366807937622
Batch 52/64 loss: 0.22155416011810303
Batch 53/64 loss: 0.21424216032028198
Batch 54/64 loss: 0.2222278118133545
Batch 55/64 loss: 0.2072824239730835
Batch 56/64 loss: 0.2317143678665161
Batch 57/64 loss: 0.2236461043357849
Batch 58/64 loss: 0.21863269805908203
Batch 59/64 loss: 0.21066462993621826
Batch 60/64 loss: 0.21509069204330444
Batch 61/64 loss: 0.21105384826660156
Batch 62/64 loss: 0.2114027738571167
Batch 63/64 loss: 0.21107912063598633
Batch 64/64 loss: 0.21778041124343872
Epoch 362  Train loss: 0.21316821037554273  Val loss: 0.26921279385327473
Epoch 363
-------------------------------
Batch 1/64 loss: 0.21962761878967285
Batch 2/64 loss: 0.20332247018814087
Batch 3/64 loss: 0.2067210078239441
Batch 4/64 loss: 0.2265775203704834
Batch 5/64 loss: 0.2108757495880127
Batch 6/64 loss: 0.21081805229187012
Batch 7/64 loss: 0.21426188945770264
Batch 8/64 loss: 0.20640414953231812
Batch 9/64 loss: 0.21000182628631592
Batch 10/64 loss: 0.20430004596710205
Batch 11/64 loss: 0.2098153829574585
Batch 12/64 loss: 0.21041053533554077
Batch 13/64 loss: 0.2024887204170227
Batch 14/64 loss: 0.22131848335266113
Batch 15/64 loss: 0.21175283193588257
Batch 16/64 loss: 0.2221534252166748
Batch 17/64 loss: 0.21219861507415771
Batch 18/64 loss: 0.2026829719543457
Batch 19/64 loss: 0.21484911441802979
Batch 20/64 loss: 0.21631503105163574
Batch 21/64 loss: 0.2091435194015503
Batch 22/64 loss: 0.20184695720672607
Batch 23/64 loss: 0.2162494659423828
Batch 24/64 loss: 0.21180510520935059
Batch 25/64 loss: 0.20699191093444824
Batch 26/64 loss: 0.2069208025932312
Batch 27/64 loss: 0.22561979293823242
Batch 28/64 loss: 0.21497702598571777
Batch 29/64 loss: 0.21165108680725098
Batch 30/64 loss: 0.22105032205581665
Batch 31/64 loss: 0.21737897396087646
Batch 32/64 loss: 0.20991075038909912
Batch 33/64 loss: 0.20939964056015015
Batch 34/64 loss: 0.20899879932403564
Batch 35/64 loss: 0.22318100929260254
Batch 36/64 loss: 0.21152091026306152
Batch 37/64 loss: 0.2045983076095581
Batch 38/64 loss: 0.2036793828010559
Batch 39/64 loss: 0.21581172943115234
Batch 40/64 loss: 0.20729845762252808
Batch 41/64 loss: 0.21732330322265625
Batch 42/64 loss: 0.21735715866088867
Batch 43/64 loss: 0.22042489051818848
Batch 44/64 loss: 0.22529995441436768
Batch 45/64 loss: 0.22607684135437012
Batch 46/64 loss: 0.2151566743850708
Batch 47/64 loss: 0.21500563621520996
Batch 48/64 loss: 0.21151793003082275
Batch 49/64 loss: 0.20829522609710693
Batch 50/64 loss: 0.20338398218154907
Batch 51/64 loss: 0.21124154329299927
Batch 52/64 loss: 0.21954131126403809
Batch 53/64 loss: 0.205624520778656
Batch 54/64 loss: 0.20715409517288208
Batch 55/64 loss: 0.20922863483428955
Batch 56/64 loss: 0.20437979698181152
Batch 57/64 loss: 0.20650428533554077
Batch 58/64 loss: 0.2141997218132019
Batch 59/64 loss: 0.2271137833595276
Batch 60/64 loss: 0.21547740697860718
Batch 61/64 loss: 0.21245187520980835
Batch 62/64 loss: 0.21662676334381104
Batch 63/64 loss: 0.21431970596313477
Batch 64/64 loss: 0.21472668647766113
Epoch 363  Train loss: 0.21270085409575817  Val loss: 0.26892646338112164
Epoch 364
-------------------------------
Batch 1/64 loss: 0.19937008619308472
Batch 2/64 loss: 0.21250253915786743
Batch 3/64 loss: 0.21327710151672363
Batch 4/64 loss: 0.2173384428024292
Batch 5/64 loss: 0.20816248655319214
Batch 6/64 loss: 0.21850597858428955
Batch 7/64 loss: 0.2143244743347168
Batch 8/64 loss: 0.2061312198638916
Batch 9/64 loss: 0.2126157283782959
Batch 10/64 loss: 0.22324281930923462
Batch 11/64 loss: 0.21633344888687134
Batch 12/64 loss: 0.2106919288635254
Batch 13/64 loss: 0.21503996849060059
Batch 14/64 loss: 0.2152789831161499
Batch 15/64 loss: 0.21046042442321777
Batch 16/64 loss: 0.21027100086212158
Batch 17/64 loss: 0.21031665802001953
Batch 18/64 loss: 0.20482969284057617
Batch 19/64 loss: 0.20774602890014648
Batch 20/64 loss: 0.2051393985748291
Batch 21/64 loss: 0.2136768102645874
Batch 22/64 loss: 0.20867425203323364
Batch 23/64 loss: 0.22506994009017944
Batch 24/64 loss: 0.21117424964904785
Batch 25/64 loss: 0.2184804081916809
Batch 26/64 loss: 0.20393478870391846
Batch 27/64 loss: 0.21685504913330078
Batch 28/64 loss: 0.21083182096481323
Batch 29/64 loss: 0.2083491086959839
Batch 30/64 loss: 0.20673048496246338
Batch 31/64 loss: 0.20847946405410767
Batch 32/64 loss: 0.20443940162658691
Batch 33/64 loss: 0.21958482265472412
Batch 34/64 loss: 0.21718430519104004
Batch 35/64 loss: 0.2141435146331787
Batch 36/64 loss: 0.21257245540618896
Batch 37/64 loss: 0.21249693632125854
Batch 38/64 loss: 0.2089862823486328
Batch 39/64 loss: 0.21757376194000244
Batch 40/64 loss: 0.203829824924469
Batch 41/64 loss: 0.20748937129974365
Batch 42/64 loss: 0.21383118629455566
Batch 43/64 loss: 0.21461808681488037
Batch 44/64 loss: 0.22135484218597412
Batch 45/64 loss: 0.2032397985458374
Batch 46/64 loss: 0.2125486135482788
Batch 47/64 loss: 0.20217853784561157
Batch 48/64 loss: 0.21264255046844482
Batch 49/64 loss: 0.21036779880523682
Batch 50/64 loss: 0.2132992148399353
Batch 51/64 loss: 0.21279489994049072
Batch 52/64 loss: 0.21095454692840576
Batch 53/64 loss: 0.19811362028121948
Batch 54/64 loss: 0.21769332885742188
Batch 55/64 loss: 0.21265649795532227
Batch 56/64 loss: 0.212208092212677
Batch 57/64 loss: 0.20920473337173462
Batch 58/64 loss: 0.21039754152297974
Batch 59/64 loss: 0.21334302425384521
Batch 60/64 loss: 0.20608699321746826
Batch 61/64 loss: 0.22670447826385498
Batch 62/64 loss: 0.23538053035736084
Batch 63/64 loss: 0.21566319465637207
Batch 64/64 loss: 0.20644265413284302
Epoch 364  Train loss: 0.21211371865927003  Val loss: 0.26814539735669535
Saving best model, epoch: 364
Epoch 365
-------------------------------
Batch 1/64 loss: 0.21605736017227173
Batch 2/64 loss: 0.2104036808013916
Batch 3/64 loss: 0.20701611042022705
Batch 4/64 loss: 0.21361565589904785
Batch 5/64 loss: 0.20500540733337402
Batch 6/64 loss: 0.2226729393005371
Batch 7/64 loss: 0.21596157550811768
Batch 8/64 loss: 0.2091938853263855
Batch 9/64 loss: 0.21289008855819702
Batch 10/64 loss: 0.20649433135986328
Batch 11/64 loss: 0.2141932249069214
Batch 12/64 loss: 0.21237397193908691
Batch 13/64 loss: 0.2147255539894104
Batch 14/64 loss: 0.21116042137145996
Batch 15/64 loss: 0.21129077672958374
Batch 16/64 loss: 0.21475565433502197
Batch 17/64 loss: 0.20581543445587158
Batch 18/64 loss: 0.21351146697998047
Batch 19/64 loss: 0.22243058681488037
Batch 20/64 loss: 0.21477794647216797
Batch 21/64 loss: 0.2052895426750183
Batch 22/64 loss: 0.21799063682556152
Batch 23/64 loss: 0.20990294218063354
Batch 24/64 loss: 0.21449893712997437
Batch 25/64 loss: 0.2040804624557495
Batch 26/64 loss: 0.2166815996170044
Batch 27/64 loss: 0.21368873119354248
Batch 28/64 loss: 0.21350646018981934
Batch 29/64 loss: 0.21782565116882324
Batch 30/64 loss: 0.21813809871673584
Batch 31/64 loss: 0.2212820053100586
Batch 32/64 loss: 0.2034238576889038
Batch 33/64 loss: 0.217201828956604
Batch 34/64 loss: 0.20366036891937256
Batch 35/64 loss: 0.21578919887542725
Batch 36/64 loss: 0.21553432941436768
Batch 37/64 loss: 0.2077493667602539
Batch 38/64 loss: 0.2149519920349121
Batch 39/64 loss: 0.224195659160614
Batch 40/64 loss: 0.2175276279449463
Batch 41/64 loss: 0.2204500436782837
Batch 42/64 loss: 0.20858490467071533
Batch 43/64 loss: 0.20777595043182373
Batch 44/64 loss: 0.21218383312225342
Batch 45/64 loss: 0.20760464668273926
Batch 46/64 loss: 0.20444053411483765
Batch 47/64 loss: 0.21342432498931885
Batch 48/64 loss: 0.2097543478012085
Batch 49/64 loss: 0.20041465759277344
Batch 50/64 loss: 0.21419119834899902
Batch 51/64 loss: 0.20737141370773315
Batch 52/64 loss: 0.2088497281074524
Batch 53/64 loss: 0.21336674690246582
Batch 54/64 loss: 0.21520471572875977
Batch 55/64 loss: 0.21077090501785278
Batch 56/64 loss: 0.21775418519973755
Batch 57/64 loss: 0.20789504051208496
Batch 58/64 loss: 0.20937949419021606
Batch 59/64 loss: 0.20795726776123047
Batch 60/64 loss: 0.209522545337677
Batch 61/64 loss: 0.2114207148551941
Batch 62/64 loss: 0.20590758323669434
Batch 63/64 loss: 0.21860045194625854
Batch 64/64 loss: 0.22181832790374756
Epoch 365  Train loss: 0.21233653881970574  Val loss: 0.2694432503988653
Epoch 366
-------------------------------
Batch 1/64 loss: 0.2077469825744629
Batch 2/64 loss: 0.21238893270492554
Batch 3/64 loss: 0.2097259759902954
Batch 4/64 loss: 0.20397448539733887
Batch 5/64 loss: 0.2079169750213623
Batch 6/64 loss: 0.2144639492034912
Batch 7/64 loss: 0.21299868822097778
Batch 8/64 loss: 0.20160013437271118
Batch 9/64 loss: 0.2126401662826538
Batch 10/64 loss: 0.209053635597229
Batch 11/64 loss: 0.21015429496765137
Batch 12/64 loss: 0.21097970008850098
Batch 13/64 loss: 0.2174774408340454
Batch 14/64 loss: 0.21934843063354492
Batch 15/64 loss: 0.2244856357574463
Batch 16/64 loss: 0.20760709047317505
Batch 17/64 loss: 0.20578861236572266
Batch 18/64 loss: 0.2118430733680725
Batch 19/64 loss: 0.22318041324615479
Batch 20/64 loss: 0.20578670501708984
Batch 21/64 loss: 0.2141791582107544
Batch 22/64 loss: 0.21078044176101685
Batch 23/64 loss: 0.20401448011398315
Batch 24/64 loss: 0.20973485708236694
Batch 25/64 loss: 0.22807848453521729
Batch 26/64 loss: 0.21049582958221436
Batch 27/64 loss: 0.2204744815826416
Batch 28/64 loss: 0.20909225940704346
Batch 29/64 loss: 0.21296203136444092
Batch 30/64 loss: 0.19992327690124512
Batch 31/64 loss: 0.22003543376922607
Batch 32/64 loss: 0.2151942253112793
Batch 33/64 loss: 0.21264803409576416
Batch 34/64 loss: 0.2039591670036316
Batch 35/64 loss: 0.2214268445968628
Batch 36/64 loss: 0.2145143747329712
Batch 37/64 loss: 0.20845377445220947
Batch 38/64 loss: 0.20571863651275635
Batch 39/64 loss: 0.21003109216690063
Batch 40/64 loss: 0.21355849504470825
Batch 41/64 loss: 0.21102595329284668
Batch 42/64 loss: 0.21319973468780518
Batch 43/64 loss: 0.2177276611328125
Batch 44/64 loss: 0.21171176433563232
Batch 45/64 loss: 0.2130834460258484
Batch 46/64 loss: 0.210537850856781
Batch 47/64 loss: 0.20753014087677002
Batch 48/64 loss: 0.2085115909576416
Batch 49/64 loss: 0.20494824647903442
Batch 50/64 loss: 0.22048962116241455
Batch 51/64 loss: 0.21353495121002197
Batch 52/64 loss: 0.21556133031845093
Batch 53/64 loss: 0.21543514728546143
Batch 54/64 loss: 0.195442795753479
Batch 55/64 loss: 0.2176356315612793
Batch 56/64 loss: 0.21171921491622925
Batch 57/64 loss: 0.21007680892944336
Batch 58/64 loss: 0.214866042137146
Batch 59/64 loss: 0.20070874691009521
Batch 60/64 loss: 0.2191748023033142
Batch 61/64 loss: 0.21903598308563232
Batch 62/64 loss: 0.22541040182113647
Batch 63/64 loss: 0.22269999980926514
Batch 64/64 loss: 0.2131175994873047
Epoch 366  Train loss: 0.2123034159342448  Val loss: 0.2693201813501181
Epoch 367
-------------------------------
Batch 1/64 loss: 0.21098434925079346
Batch 2/64 loss: 0.2134181261062622
Batch 3/64 loss: 0.21233046054840088
Batch 4/64 loss: 0.20677614212036133
Batch 5/64 loss: 0.2161896824836731
Batch 6/64 loss: 0.20886528491973877
Batch 7/64 loss: 0.19801044464111328
Batch 8/64 loss: 0.2148289680480957
Batch 9/64 loss: 0.20457589626312256
Batch 10/64 loss: 0.21141886711120605
Batch 11/64 loss: 0.20921015739440918
Batch 12/64 loss: 0.20528382062911987
Batch 13/64 loss: 0.20293641090393066
Batch 14/64 loss: 0.21908605098724365
Batch 15/64 loss: 0.21458673477172852
Batch 16/64 loss: 0.21541154384613037
Batch 17/64 loss: 0.2027004361152649
Batch 18/64 loss: 0.21517550945281982
Batch 19/64 loss: 0.22122305631637573
Batch 20/64 loss: 0.21638482809066772
Batch 21/64 loss: 0.20297133922576904
Batch 22/64 loss: 0.21314239501953125
Batch 23/64 loss: 0.22622758150100708
Batch 24/64 loss: 0.2103843092918396
Batch 25/64 loss: 0.20226824283599854
Batch 26/64 loss: 0.22002166509628296
Batch 27/64 loss: 0.2042067050933838
Batch 28/64 loss: 0.21086442470550537
Batch 29/64 loss: 0.22273778915405273
Batch 30/64 loss: 0.21150869131088257
Batch 31/64 loss: 0.2037695050239563
Batch 32/64 loss: 0.20841997861862183
Batch 33/64 loss: 0.21119260787963867
Batch 34/64 loss: 0.21181058883666992
Batch 35/64 loss: 0.21649062633514404
Batch 36/64 loss: 0.2100011110305786
Batch 37/64 loss: 0.21912544965744019
Batch 38/64 loss: 0.20296120643615723
Batch 39/64 loss: 0.21281099319458008
Batch 40/64 loss: 0.21665161848068237
Batch 41/64 loss: 0.2080315351486206
Batch 42/64 loss: 0.21276652812957764
Batch 43/64 loss: 0.20866882801055908
Batch 44/64 loss: 0.2058950662612915
Batch 45/64 loss: 0.21023279428482056
Batch 46/64 loss: 0.20611464977264404
Batch 47/64 loss: 0.20595192909240723
Batch 48/64 loss: 0.2070898413658142
Batch 49/64 loss: 0.2106143832206726
Batch 50/64 loss: 0.20665335655212402
Batch 51/64 loss: 0.21653985977172852
Batch 52/64 loss: 0.2085973024368286
Batch 53/64 loss: 0.2167973518371582
Batch 54/64 loss: 0.21901828050613403
Batch 55/64 loss: 0.22014594078063965
Batch 56/64 loss: 0.2110985517501831
Batch 57/64 loss: 0.20370608568191528
Batch 58/64 loss: 0.2156381607055664
Batch 59/64 loss: 0.21296381950378418
Batch 60/64 loss: 0.21837007999420166
Batch 61/64 loss: 0.21456611156463623
Batch 62/64 loss: 0.2057463526725769
Batch 63/64 loss: 0.21707934141159058
Batch 64/64 loss: 0.21344947814941406
Epoch 367  Train loss: 0.2114405781615014  Val loss: 0.2695370683145687
Epoch 368
-------------------------------
Batch 1/64 loss: 0.2078583836555481
Batch 2/64 loss: 0.20531749725341797
Batch 3/64 loss: 0.22258102893829346
Batch 4/64 loss: 0.2017812728881836
Batch 5/64 loss: 0.2027248740196228
Batch 6/64 loss: 0.21488916873931885
Batch 7/64 loss: 0.21242761611938477
Batch 8/64 loss: 0.2077503204345703
Batch 9/64 loss: 0.22389209270477295
Batch 10/64 loss: 0.2122039794921875
Batch 11/64 loss: 0.20994096994400024
Batch 12/64 loss: 0.21376991271972656
Batch 13/64 loss: 0.21088922023773193
Batch 14/64 loss: 0.2021334171295166
Batch 15/64 loss: 0.21293026208877563
Batch 16/64 loss: 0.20445561408996582
Batch 17/64 loss: 0.21125996112823486
Batch 18/64 loss: 0.21763944625854492
Batch 19/64 loss: 0.20947372913360596
Batch 20/64 loss: 0.20961064100265503
Batch 21/64 loss: 0.21111297607421875
Batch 22/64 loss: 0.2222278118133545
Batch 23/64 loss: 0.228729248046875
Batch 24/64 loss: 0.21600359678268433
Batch 25/64 loss: 0.203094482421875
Batch 26/64 loss: 0.21400082111358643
Batch 27/64 loss: 0.20771574974060059
Batch 28/64 loss: 0.20867764949798584
Batch 29/64 loss: 0.21366143226623535
Batch 30/64 loss: 0.20935535430908203
Batch 31/64 loss: 0.21538972854614258
Batch 32/64 loss: 0.21923261880874634
Batch 33/64 loss: 0.21063882112503052
Batch 34/64 loss: 0.2076970934867859
Batch 35/64 loss: 0.21612465381622314
Batch 36/64 loss: 0.20347970724105835
Batch 37/64 loss: 0.21137773990631104
Batch 38/64 loss: 0.20688194036483765
Batch 39/64 loss: 0.20068252086639404
Batch 40/64 loss: 0.20915299654006958
Batch 41/64 loss: 0.2166157364845276
Batch 42/64 loss: 0.20462465286254883
Batch 43/64 loss: 0.21291637420654297
Batch 44/64 loss: 0.2264663577079773
Batch 45/64 loss: 0.20902138948440552
Batch 46/64 loss: 0.21408039331436157
Batch 47/64 loss: 0.2191675901412964
Batch 48/64 loss: 0.22206860780715942
Batch 49/64 loss: 0.22001540660858154
Batch 50/64 loss: 0.21704614162445068
Batch 51/64 loss: 0.21656018495559692
Batch 52/64 loss: 0.20582187175750732
Batch 53/64 loss: 0.21729183197021484
Batch 54/64 loss: 0.21373915672302246
Batch 55/64 loss: 0.2072635293006897
Batch 56/64 loss: 0.21266567707061768
Batch 57/64 loss: 0.21051108837127686
Batch 58/64 loss: 0.2102295160293579
Batch 59/64 loss: 0.20513242483139038
Batch 60/64 loss: 0.21266061067581177
Batch 61/64 loss: 0.20316100120544434
Batch 62/64 loss: 0.20424067974090576
Batch 63/64 loss: 0.2264770269393921
Batch 64/64 loss: 0.20898795127868652
Epoch 368  Train loss: 0.21197309120028626  Val loss: 0.269977458154213
Epoch 369
-------------------------------
Batch 1/64 loss: 0.21387594938278198
Batch 2/64 loss: 0.21655702590942383
Batch 3/64 loss: 0.20709228515625
Batch 4/64 loss: 0.21221071481704712
Batch 5/64 loss: 0.20759046077728271
Batch 6/64 loss: 0.20959174633026123
Batch 7/64 loss: 0.2068629264831543
Batch 8/64 loss: 0.21509969234466553
Batch 9/64 loss: 0.2082463502883911
Batch 10/64 loss: 0.20895326137542725
Batch 11/64 loss: 0.2036287784576416
Batch 12/64 loss: 0.22302758693695068
Batch 13/64 loss: 0.2065443992614746
Batch 14/64 loss: 0.21565675735473633
Batch 15/64 loss: 0.2085866928100586
Batch 16/64 loss: 0.20765936374664307
Batch 17/64 loss: 0.21861803531646729
Batch 18/64 loss: 0.21463370323181152
Batch 19/64 loss: 0.2155231237411499
Batch 20/64 loss: 0.21022963523864746
Batch 21/64 loss: 0.2214752435684204
Batch 22/64 loss: 0.2134842872619629
Batch 23/64 loss: 0.22185546159744263
Batch 24/64 loss: 0.20367592573165894
Batch 25/64 loss: 0.20903337001800537
Batch 26/64 loss: 0.23333382606506348
Batch 27/64 loss: 0.2227238416671753
Batch 28/64 loss: 0.20759832859039307
Batch 29/64 loss: 0.2114032506942749
Batch 30/64 loss: 0.21032065153121948
Batch 31/64 loss: 0.20987451076507568
Batch 32/64 loss: 0.21237808465957642
Batch 33/64 loss: 0.21715033054351807
Batch 34/64 loss: 0.2055354118347168
Batch 35/64 loss: 0.2190253734588623
Batch 36/64 loss: 0.2127983570098877
Batch 37/64 loss: 0.1991438865661621
Batch 38/64 loss: 0.20752590894699097
Batch 39/64 loss: 0.20920014381408691
Batch 40/64 loss: 0.20568811893463135
Batch 41/64 loss: 0.20286202430725098
Batch 42/64 loss: 0.21564418077468872
Batch 43/64 loss: 0.20748662948608398
Batch 44/64 loss: 0.21455347537994385
Batch 45/64 loss: 0.21239793300628662
Batch 46/64 loss: 0.2169402837753296
Batch 47/64 loss: 0.2093486785888672
Batch 48/64 loss: 0.21326524019241333
Batch 49/64 loss: 0.21611922979354858
Batch 50/64 loss: 0.22411704063415527
Batch 51/64 loss: 0.20996952056884766
Batch 52/64 loss: 0.2096313238143921
Batch 53/64 loss: 0.21726185083389282
Batch 54/64 loss: 0.20831668376922607
Batch 55/64 loss: 0.2184697389602661
Batch 56/64 loss: 0.20664262771606445
Batch 57/64 loss: 0.2093733549118042
Batch 58/64 loss: 0.20732128620147705
Batch 59/64 loss: 0.2109520435333252
Batch 60/64 loss: 0.2246735692024231
Batch 61/64 loss: 0.20461797714233398
Batch 62/64 loss: 0.23303192853927612
Batch 63/64 loss: 0.21739637851715088
Batch 64/64 loss: 0.21049237251281738
Epoch 369  Train loss: 0.21257529539220474  Val loss: 0.26920799598661077
Epoch 370
-------------------------------
Batch 1/64 loss: 0.2003086805343628
Batch 2/64 loss: 0.22012019157409668
Batch 3/64 loss: 0.21811574697494507
Batch 4/64 loss: 0.21557193994522095
Batch 5/64 loss: 0.21419095993041992
Batch 6/64 loss: 0.22072166204452515
Batch 7/64 loss: 0.2125910520553589
Batch 8/64 loss: 0.21945226192474365
Batch 9/64 loss: 0.2111365795135498
Batch 10/64 loss: 0.2151275873184204
Batch 11/64 loss: 0.2041289210319519
Batch 12/64 loss: 0.21274429559707642
Batch 13/64 loss: 0.20022892951965332
Batch 14/64 loss: 0.2041669487953186
Batch 15/64 loss: 0.21232235431671143
Batch 16/64 loss: 0.20868980884552002
Batch 17/64 loss: 0.2107621431350708
Batch 18/64 loss: 0.2099919319152832
Batch 19/64 loss: 0.20811867713928223
Batch 20/64 loss: 0.20885074138641357
Batch 21/64 loss: 0.20945948362350464
Batch 22/64 loss: 0.21024972200393677
Batch 23/64 loss: 0.2141265869140625
Batch 24/64 loss: 0.22601079940795898
Batch 25/64 loss: 0.21305620670318604
Batch 26/64 loss: 0.19790077209472656
Batch 27/64 loss: 0.21193170547485352
Batch 28/64 loss: 0.20216333866119385
Batch 29/64 loss: 0.21772617101669312
Batch 30/64 loss: 0.20155483484268188
Batch 31/64 loss: 0.21602261066436768
Batch 32/64 loss: 0.21299254894256592
Batch 33/64 loss: 0.20066016912460327
Batch 34/64 loss: 0.21844279766082764
Batch 35/64 loss: 0.220211923122406
Batch 36/64 loss: 0.21658849716186523
Batch 37/64 loss: 0.21570777893066406
Batch 38/64 loss: 0.20626628398895264
Batch 39/64 loss: 0.20784467458724976
Batch 40/64 loss: 0.2068246603012085
Batch 41/64 loss: 0.21245813369750977
Batch 42/64 loss: 0.20310711860656738
Batch 43/64 loss: 0.21202468872070312
Batch 44/64 loss: 0.2131679654121399
Batch 45/64 loss: 0.2158651351928711
Batch 46/64 loss: 0.21363484859466553
Batch 47/64 loss: 0.2231506109237671
Batch 48/64 loss: 0.2132948637008667
Batch 49/64 loss: 0.2219969630241394
Batch 50/64 loss: 0.20799100399017334
Batch 51/64 loss: 0.2058427333831787
Batch 52/64 loss: 0.2028970718383789
Batch 53/64 loss: 0.20781314373016357
Batch 54/64 loss: 0.20961368083953857
Batch 55/64 loss: 0.21422922611236572
Batch 56/64 loss: 0.21809422969818115
Batch 57/64 loss: 0.21725422143936157
Batch 58/64 loss: 0.2173750400543213
Batch 59/64 loss: 0.20138591527938843
Batch 60/64 loss: 0.21337217092514038
Batch 61/64 loss: 0.21455568075180054
Batch 62/64 loss: 0.21582192182540894
Batch 63/64 loss: 0.20649343729019165
Batch 64/64 loss: 0.21327900886535645
Epoch 370  Train loss: 0.21167814965341605  Val loss: 0.2687921151262788
Epoch 371
-------------------------------
Batch 1/64 loss: 0.21399855613708496
Batch 2/64 loss: 0.20651370286941528
Batch 3/64 loss: 0.21450889110565186
Batch 4/64 loss: 0.20254582166671753
Batch 5/64 loss: 0.21422147750854492
Batch 6/64 loss: 0.2071012258529663
Batch 7/64 loss: 0.21231591701507568
Batch 8/64 loss: 0.21353483200073242
Batch 9/64 loss: 0.20476210117340088
Batch 10/64 loss: 0.2053924798965454
Batch 11/64 loss: 0.2154923677444458
Batch 12/64 loss: 0.21450680494308472
Batch 13/64 loss: 0.20944929122924805
Batch 14/64 loss: 0.21727120876312256
Batch 15/64 loss: 0.20679384469985962
Batch 16/64 loss: 0.19859308004379272
Batch 17/64 loss: 0.2101038694381714
Batch 18/64 loss: 0.21912789344787598
Batch 19/64 loss: 0.20767927169799805
Batch 20/64 loss: 0.22370314598083496
Batch 21/64 loss: 0.21002453565597534
Batch 22/64 loss: 0.2046336531639099
Batch 23/64 loss: 0.20932495594024658
Batch 24/64 loss: 0.21077197790145874
Batch 25/64 loss: 0.2104218602180481
Batch 26/64 loss: 0.20039737224578857
Batch 27/64 loss: 0.20711266994476318
Batch 28/64 loss: 0.21896988153457642
Batch 29/64 loss: 0.20501798391342163
Batch 30/64 loss: 0.2137967348098755
Batch 31/64 loss: 0.20821857452392578
Batch 32/64 loss: 0.21443450450897217
Batch 33/64 loss: 0.21066099405288696
Batch 34/64 loss: 0.20310795307159424
Batch 35/64 loss: 0.20822083950042725
Batch 36/64 loss: 0.20895493030548096
Batch 37/64 loss: 0.21837949752807617
Batch 38/64 loss: 0.21549808979034424
Batch 39/64 loss: 0.2055513858795166
Batch 40/64 loss: 0.21640551090240479
Batch 41/64 loss: 0.2139958143234253
Batch 42/64 loss: 0.21328186988830566
Batch 43/64 loss: 0.2052849531173706
Batch 44/64 loss: 0.20923161506652832
Batch 45/64 loss: 0.20193040370941162
Batch 46/64 loss: 0.21792978048324585
Batch 47/64 loss: 0.21628093719482422
Batch 48/64 loss: 0.20146846771240234
Batch 49/64 loss: 0.20235788822174072
Batch 50/64 loss: 0.21484780311584473
Batch 51/64 loss: 0.20350486040115356
Batch 52/64 loss: 0.2125692367553711
Batch 53/64 loss: 0.21461302042007446
Batch 54/64 loss: 0.21849489212036133
Batch 55/64 loss: 0.21137160062789917
Batch 56/64 loss: 0.21991902589797974
Batch 57/64 loss: 0.22234845161437988
Batch 58/64 loss: 0.21917498111724854
Batch 59/64 loss: 0.21384978294372559
Batch 60/64 loss: 0.21127742528915405
Batch 61/64 loss: 0.21382498741149902
Batch 62/64 loss: 0.22004950046539307
Batch 63/64 loss: 0.2171328067779541
Batch 64/64 loss: 0.21359020471572876
Epoch 371  Train loss: 0.2113325874010722  Val loss: 0.26988929817357016
Epoch 372
-------------------------------
Batch 1/64 loss: 0.20816051959991455
Batch 2/64 loss: 0.2194284200668335
Batch 3/64 loss: 0.2036566138267517
Batch 4/64 loss: 0.21522706747055054
Batch 5/64 loss: 0.21342617273330688
Batch 6/64 loss: 0.22307932376861572
Batch 7/64 loss: 0.21165865659713745
Batch 8/64 loss: 0.2204587459564209
Batch 9/64 loss: 0.2098454236984253
Batch 10/64 loss: 0.2193087339401245
Batch 11/64 loss: 0.2163848876953125
Batch 12/64 loss: 0.2073049545288086
Batch 13/64 loss: 0.2174438238143921
Batch 14/64 loss: 0.20871829986572266
Batch 15/64 loss: 0.21375757455825806
Batch 16/64 loss: 0.23075759410858154
Batch 17/64 loss: 0.2213987112045288
Batch 18/64 loss: 0.20649635791778564
Batch 19/64 loss: 0.2155577540397644
Batch 20/64 loss: 0.2093234658241272
Batch 21/64 loss: 0.2053847312927246
Batch 22/64 loss: 0.20272445678710938
Batch 23/64 loss: 0.21411848068237305
Batch 24/64 loss: 0.21612274646759033
Batch 25/64 loss: 0.2080165147781372
Batch 26/64 loss: 0.21004116535186768
Batch 27/64 loss: 0.20613545179367065
Batch 28/64 loss: 0.20817923545837402
Batch 29/64 loss: 0.2195899486541748
Batch 30/64 loss: 0.20801281929016113
Batch 31/64 loss: 0.2165987491607666
Batch 32/64 loss: 0.21012091636657715
Batch 33/64 loss: 0.20534133911132812
Batch 34/64 loss: 0.22066521644592285
Batch 35/64 loss: 0.21202969551086426
Batch 36/64 loss: 0.2120528221130371
Batch 37/64 loss: 0.20381253957748413
Batch 38/64 loss: 0.20767652988433838
Batch 39/64 loss: 0.20218491554260254
Batch 40/64 loss: 0.21327483654022217
Batch 41/64 loss: 0.20421355962753296
Batch 42/64 loss: 0.20644867420196533
Batch 43/64 loss: 0.20653045177459717
Batch 44/64 loss: 0.21313214302062988
Batch 45/64 loss: 0.20669424533843994
Batch 46/64 loss: 0.20555579662322998
Batch 47/64 loss: 0.2101045846939087
Batch 48/64 loss: 0.21107232570648193
Batch 49/64 loss: 0.2116662859916687
Batch 50/64 loss: 0.21866661310195923
Batch 51/64 loss: 0.2123318910598755
Batch 52/64 loss: 0.21453481912612915
Batch 53/64 loss: 0.20298147201538086
Batch 54/64 loss: 0.20851945877075195
Batch 55/64 loss: 0.2158411741256714
Batch 56/64 loss: 0.20897150039672852
Batch 57/64 loss: 0.20939505100250244
Batch 58/64 loss: 0.2068401575088501
Batch 59/64 loss: 0.2107006311416626
Batch 60/64 loss: 0.21205663681030273
Batch 61/64 loss: 0.204708993434906
Batch 62/64 loss: 0.21285748481750488
Batch 63/64 loss: 0.21754610538482666
Batch 64/64 loss: 0.2214147448539734
Epoch 372  Train loss: 0.2116220757073047  Val loss: 0.2691644188464712
Epoch 373
-------------------------------
Batch 1/64 loss: 0.2292124629020691
Batch 2/64 loss: 0.20043885707855225
Batch 3/64 loss: 0.20222049951553345
Batch 4/64 loss: 0.20951128005981445
Batch 5/64 loss: 0.21249639987945557
Batch 6/64 loss: 0.21748709678649902
Batch 7/64 loss: 0.21507447957992554
Batch 8/64 loss: 0.20418024063110352
Batch 9/64 loss: 0.20761513710021973
Batch 10/64 loss: 0.20756548643112183
Batch 11/64 loss: 0.20315086841583252
Batch 12/64 loss: 0.21120190620422363
Batch 13/64 loss: 0.20883744955062866
Batch 14/64 loss: 0.21070659160614014
Batch 15/64 loss: 0.22601318359375
Batch 16/64 loss: 0.20544880628585815
Batch 17/64 loss: 0.20725679397583008
Batch 18/64 loss: 0.2207251787185669
Batch 19/64 loss: 0.2112608551979065
Batch 20/64 loss: 0.21535974740982056
Batch 21/64 loss: 0.2144327163696289
Batch 22/64 loss: 0.21645402908325195
Batch 23/64 loss: 0.21223485469818115
Batch 24/64 loss: 0.21364492177963257
Batch 25/64 loss: 0.20891427993774414
Batch 26/64 loss: 0.2157527208328247
Batch 27/64 loss: 0.20616745948791504
Batch 28/64 loss: 0.21481746435165405
Batch 29/64 loss: 0.1975216269493103
Batch 30/64 loss: 0.2028983235359192
Batch 31/64 loss: 0.20459187030792236
Batch 32/64 loss: 0.210121750831604
Batch 33/64 loss: 0.2102196216583252
Batch 34/64 loss: 0.217728853225708
Batch 35/64 loss: 0.20404982566833496
Batch 36/64 loss: 0.21254026889801025
Batch 37/64 loss: 0.2118358612060547
Batch 38/64 loss: 0.22265350818634033
Batch 39/64 loss: 0.20450836420059204
Batch 40/64 loss: 0.2107061743736267
Batch 41/64 loss: 0.2101457118988037
Batch 42/64 loss: 0.20674937963485718
Batch 43/64 loss: 0.20843487977981567
Batch 44/64 loss: 0.20368272066116333
Batch 45/64 loss: 0.20596468448638916
Batch 46/64 loss: 0.20711541175842285
Batch 47/64 loss: 0.20319586992263794
Batch 48/64 loss: 0.21420830488204956
Batch 49/64 loss: 0.20884668827056885
Batch 50/64 loss: 0.21233844757080078
Batch 51/64 loss: 0.20192503929138184
Batch 52/64 loss: 0.20581215620040894
Batch 53/64 loss: 0.2114351987838745
Batch 54/64 loss: 0.20528805255889893
Batch 55/64 loss: 0.2201554775238037
Batch 56/64 loss: 0.21234965324401855
Batch 57/64 loss: 0.20922446250915527
Batch 58/64 loss: 0.21462035179138184
Batch 59/64 loss: 0.21747958660125732
Batch 60/64 loss: 0.21105623245239258
Batch 61/64 loss: 0.21419167518615723
Batch 62/64 loss: 0.21490448713302612
Batch 63/64 loss: 0.21248388290405273
Batch 64/64 loss: 0.22063946723937988
Epoch 373  Train loss: 0.21073954152125937  Val loss: 0.2688447843302566
Epoch 374
-------------------------------
Batch 1/64 loss: 0.20379185676574707
Batch 2/64 loss: 0.21371793746948242
Batch 3/64 loss: 0.2133493423461914
Batch 4/64 loss: 0.1974528431892395
Batch 5/64 loss: 0.20213031768798828
Batch 6/64 loss: 0.1999661922454834
Batch 7/64 loss: 0.21740204095840454
Batch 8/64 loss: 0.20846819877624512
Batch 9/64 loss: 0.21038097143173218
Batch 10/64 loss: 0.219079852104187
Batch 11/64 loss: 0.2096238136291504
Batch 12/64 loss: 0.2149617075920105
Batch 13/64 loss: 0.21603399515151978
Batch 14/64 loss: 0.21421295404434204
Batch 15/64 loss: 0.21167314052581787
Batch 16/64 loss: 0.20469290018081665
Batch 17/64 loss: 0.20888912677764893
Batch 18/64 loss: 0.22047960758209229
Batch 19/64 loss: 0.21128594875335693
Batch 20/64 loss: 0.20057135820388794
Batch 21/64 loss: 0.20370566844940186
Batch 22/64 loss: 0.20968115329742432
Batch 23/64 loss: 0.20511233806610107
Batch 24/64 loss: 0.209436297416687
Batch 25/64 loss: 0.20639634132385254
Batch 26/64 loss: 0.204689621925354
Batch 27/64 loss: 0.20927470922470093
Batch 28/64 loss: 0.20665597915649414
Batch 29/64 loss: 0.2129918336868286
Batch 30/64 loss: 0.20078802108764648
Batch 31/64 loss: 0.21375393867492676
Batch 32/64 loss: 0.20946216583251953
Batch 33/64 loss: 0.22324836254119873
Batch 34/64 loss: 0.21070897579193115
Batch 35/64 loss: 0.2108520269393921
Batch 36/64 loss: 0.20863807201385498
Batch 37/64 loss: 0.21885496377944946
Batch 38/64 loss: 0.21205002069473267
Batch 39/64 loss: 0.21149879693984985
Batch 40/64 loss: 0.20755809545516968
Batch 41/64 loss: 0.2219017744064331
Batch 42/64 loss: 0.21577906608581543
Batch 43/64 loss: 0.20304644107818604
Batch 44/64 loss: 0.21922051906585693
Batch 45/64 loss: 0.20797181129455566
Batch 46/64 loss: 0.20785772800445557
Batch 47/64 loss: 0.21695923805236816
Batch 48/64 loss: 0.20403456687927246
Batch 49/64 loss: 0.20337837934494019
Batch 50/64 loss: 0.21346861124038696
Batch 51/64 loss: 0.21157819032669067
Batch 52/64 loss: 0.2084587812423706
Batch 53/64 loss: 0.20878630876541138
Batch 54/64 loss: 0.19678735733032227
Batch 55/64 loss: 0.21112823486328125
Batch 56/64 loss: 0.20768487453460693
Batch 57/64 loss: 0.21098864078521729
Batch 58/64 loss: 0.21484363079071045
Batch 59/64 loss: 0.22892731428146362
Batch 60/64 loss: 0.2134491205215454
Batch 61/64 loss: 0.2125917673110962
Batch 62/64 loss: 0.21197259426116943
Batch 63/64 loss: 0.21196818351745605
Batch 64/64 loss: 0.21753168106079102
Epoch 374  Train loss: 0.2105012295292873  Val loss: 0.2689229393333094
Epoch 375
-------------------------------
Batch 1/64 loss: 0.20512115955352783
Batch 2/64 loss: 0.2064727544784546
Batch 3/64 loss: 0.21434855461120605
Batch 4/64 loss: 0.2060689926147461
Batch 5/64 loss: 0.224933922290802
Batch 6/64 loss: 0.2143191695213318
Batch 7/64 loss: 0.21153998374938965
Batch 8/64 loss: 0.2135435938835144
Batch 9/64 loss: 0.20764124393463135
Batch 10/64 loss: 0.21078526973724365
Batch 11/64 loss: 0.20828676223754883
Batch 12/64 loss: 0.21120238304138184
Batch 13/64 loss: 0.21073675155639648
Batch 14/64 loss: 0.2005298137664795
Batch 15/64 loss: 0.21598905324935913
Batch 16/64 loss: 0.20714223384857178
Batch 17/64 loss: 0.21401631832122803
Batch 18/64 loss: 0.20355916023254395
Batch 19/64 loss: 0.2100468873977661
Batch 20/64 loss: 0.20647990703582764
Batch 21/64 loss: 0.207253098487854
Batch 22/64 loss: 0.21757006645202637
Batch 23/64 loss: 0.21049022674560547
Batch 24/64 loss: 0.21578943729400635
Batch 25/64 loss: 0.21407777070999146
Batch 26/64 loss: 0.20617061853408813
Batch 27/64 loss: 0.20408576726913452
Batch 28/64 loss: 0.20546114444732666
Batch 29/64 loss: 0.20990359783172607
Batch 30/64 loss: 0.2097926139831543
Batch 31/64 loss: 0.2075667381286621
Batch 32/64 loss: 0.21716153621673584
Batch 33/64 loss: 0.20948636531829834
Batch 34/64 loss: 0.21111518144607544
Batch 35/64 loss: 0.20966219902038574
Batch 36/64 loss: 0.21391797065734863
Batch 37/64 loss: 0.209284245967865
Batch 38/64 loss: 0.20479917526245117
Batch 39/64 loss: 0.22093093395233154
Batch 40/64 loss: 0.21013933420181274
Batch 41/64 loss: 0.21462780237197876
Batch 42/64 loss: 0.20301294326782227
Batch 43/64 loss: 0.2113194465637207
Batch 44/64 loss: 0.21566390991210938
Batch 45/64 loss: 0.20602643489837646
Batch 46/64 loss: 0.2098676562309265
Batch 47/64 loss: 0.20252031087875366
Batch 48/64 loss: 0.20524054765701294
Batch 49/64 loss: 0.2212713360786438
Batch 50/64 loss: 0.22129571437835693
Batch 51/64 loss: 0.20856553316116333
Batch 52/64 loss: 0.20809286832809448
Batch 53/64 loss: 0.21702611446380615
Batch 54/64 loss: 0.20423376560211182
Batch 55/64 loss: 0.20964336395263672
Batch 56/64 loss: 0.20099788904190063
Batch 57/64 loss: 0.20292675495147705
Batch 58/64 loss: 0.21846604347229004
Batch 59/64 loss: 0.2151569128036499
Batch 60/64 loss: 0.21798741817474365
Batch 61/64 loss: 0.20887964963912964
Batch 62/64 loss: 0.21169817447662354
Batch 63/64 loss: 0.2029956579208374
Batch 64/64 loss: 0.21278619766235352
Epoch 375  Train loss: 0.21042396601508645  Val loss: 0.26866875501842435
Epoch 376
-------------------------------
Batch 1/64 loss: 0.2078491449356079
Batch 2/64 loss: 0.20632702112197876
Batch 3/64 loss: 0.20545709133148193
Batch 4/64 loss: 0.20955359935760498
Batch 5/64 loss: 0.23417848348617554
Batch 6/64 loss: 0.21124482154846191
Batch 7/64 loss: 0.20540481805801392
Batch 8/64 loss: 0.21074146032333374
Batch 9/64 loss: 0.20773619413375854
Batch 10/64 loss: 0.2032914161682129
Batch 11/64 loss: 0.21926164627075195
Batch 12/64 loss: 0.2041422724723816
Batch 13/64 loss: 0.2127993106842041
Batch 14/64 loss: 0.21722078323364258
Batch 15/64 loss: 0.22078049182891846
Batch 16/64 loss: 0.20215928554534912
Batch 17/64 loss: 0.20668518543243408
Batch 18/64 loss: 0.20320183038711548
Batch 19/64 loss: 0.19671154022216797
Batch 20/64 loss: 0.20532482862472534
Batch 21/64 loss: 0.20868408679962158
Batch 22/64 loss: 0.2054462432861328
Batch 23/64 loss: 0.21144509315490723
Batch 24/64 loss: 0.20208024978637695
Batch 25/64 loss: 0.2168288230895996
Batch 26/64 loss: 0.2102879285812378
Batch 27/64 loss: 0.20649349689483643
Batch 28/64 loss: 0.20899808406829834
Batch 29/64 loss: 0.2204188108444214
Batch 30/64 loss: 0.21282756328582764
Batch 31/64 loss: 0.20725464820861816
Batch 32/64 loss: 0.21059823036193848
Batch 33/64 loss: 0.20299512147903442
Batch 34/64 loss: 0.19589656591415405
Batch 35/64 loss: 0.2080180048942566
Batch 36/64 loss: 0.2115984559059143
Batch 37/64 loss: 0.2104194164276123
Batch 38/64 loss: 0.22110587358474731
Batch 39/64 loss: 0.2096419334411621
Batch 40/64 loss: 0.20490771532058716
Batch 41/64 loss: 0.21142816543579102
Batch 42/64 loss: 0.20774471759796143
Batch 43/64 loss: 0.21371102333068848
Batch 44/64 loss: 0.21227943897247314
Batch 45/64 loss: 0.2038317322731018
Batch 46/64 loss: 0.2026163935661316
Batch 47/64 loss: 0.20728176832199097
Batch 48/64 loss: 0.22880953550338745
Batch 49/64 loss: 0.2153029441833496
Batch 50/64 loss: 0.20980656147003174
Batch 51/64 loss: 0.20983195304870605
Batch 52/64 loss: 0.20419913530349731
Batch 53/64 loss: 0.2187213897705078
Batch 54/64 loss: 0.2217143177986145
Batch 55/64 loss: 0.20709657669067383
Batch 56/64 loss: 0.20687854290008545
Batch 57/64 loss: 0.21266353130340576
Batch 58/64 loss: 0.2198631763458252
Batch 59/64 loss: 0.2113599181175232
Batch 60/64 loss: 0.21626412868499756
Batch 61/64 loss: 0.20602965354919434
Batch 62/64 loss: 0.20914697647094727
Batch 63/64 loss: 0.20997965335845947
Batch 64/64 loss: 0.2128514051437378
Epoch 376  Train loss: 0.21023086052314907  Val loss: 0.2698537686846101
Epoch 377
-------------------------------
Batch 1/64 loss: 0.20743340253829956
Batch 2/64 loss: 0.20674371719360352
Batch 3/64 loss: 0.20383816957473755
Batch 4/64 loss: 0.21113181114196777
Batch 5/64 loss: 0.2029847502708435
Batch 6/64 loss: 0.2065352201461792
Batch 7/64 loss: 0.23007166385650635
Batch 8/64 loss: 0.20182329416275024
Batch 9/64 loss: 0.20097988843917847
Batch 10/64 loss: 0.20643532276153564
Batch 11/64 loss: 0.2143188714981079
Batch 12/64 loss: 0.21984273195266724
Batch 13/64 loss: 0.21298623085021973
Batch 14/64 loss: 0.2187788486480713
Batch 15/64 loss: 0.20839661359786987
Batch 16/64 loss: 0.21031957864761353
Batch 17/64 loss: 0.20467257499694824
Batch 18/64 loss: 0.2110046148300171
Batch 19/64 loss: 0.20732790231704712
Batch 20/64 loss: 0.2130587100982666
Batch 21/64 loss: 0.2125675082206726
Batch 22/64 loss: 0.2104572057723999
Batch 23/64 loss: 0.2086833119392395
Batch 24/64 loss: 0.21494853496551514
Batch 25/64 loss: 0.20760679244995117
Batch 26/64 loss: 0.20725494623184204
Batch 27/64 loss: 0.20713090896606445
Batch 28/64 loss: 0.2314528226852417
Batch 29/64 loss: 0.20130449533462524
Batch 30/64 loss: 0.20396393537521362
Batch 31/64 loss: 0.21133726835250854
Batch 32/64 loss: 0.21777081489562988
Batch 33/64 loss: 0.20780402421951294
Batch 34/64 loss: 0.22536492347717285
Batch 35/64 loss: 0.2252124547958374
Batch 36/64 loss: 0.21083903312683105
Batch 37/64 loss: 0.2161998748779297
Batch 38/64 loss: 0.21372246742248535
Batch 39/64 loss: 0.2060350775718689
Batch 40/64 loss: 0.20677077770233154
Batch 41/64 loss: 0.20330488681793213
Batch 42/64 loss: 0.2067553997039795
Batch 43/64 loss: 0.2090989351272583
Batch 44/64 loss: 0.2046244740486145
Batch 45/64 loss: 0.20769000053405762
Batch 46/64 loss: 0.2124180793762207
Batch 47/64 loss: 0.20784121751785278
Batch 48/64 loss: 0.20334595441818237
Batch 49/64 loss: 0.20008862018585205
Batch 50/64 loss: 0.2051713466644287
Batch 51/64 loss: 0.21445631980895996
Batch 52/64 loss: 0.21542751789093018
Batch 53/64 loss: 0.20480108261108398
Batch 54/64 loss: 0.21025270223617554
Batch 55/64 loss: 0.20532143115997314
Batch 56/64 loss: 0.2116362452507019
Batch 57/64 loss: 0.2076696753501892
Batch 58/64 loss: 0.21383583545684814
Batch 59/64 loss: 0.2049834132194519
Batch 60/64 loss: 0.20749711990356445
Batch 61/64 loss: 0.20741426944732666
Batch 62/64 loss: 0.20654237270355225
Batch 63/64 loss: 0.2075793743133545
Batch 64/64 loss: 0.2047460675239563
Epoch 377  Train loss: 0.2098263046320747  Val loss: 0.26958133101053666
Epoch 378
-------------------------------
Batch 1/64 loss: 0.20856261253356934
Batch 2/64 loss: 0.209614098072052
Batch 3/64 loss: 0.1972615122795105
Batch 4/64 loss: 0.20772457122802734
Batch 5/64 loss: 0.21006488800048828
Batch 6/64 loss: 0.21062368154525757
Batch 7/64 loss: 0.2094448208808899
Batch 8/64 loss: 0.2094329595565796
Batch 9/64 loss: 0.20885759592056274
Batch 10/64 loss: 0.2080286145210266
Batch 11/64 loss: 0.21302354335784912
Batch 12/64 loss: 0.21262800693511963
Batch 13/64 loss: 0.19977396726608276
Batch 14/64 loss: 0.2139338254928589
Batch 15/64 loss: 0.21971362829208374
Batch 16/64 loss: 0.21281027793884277
Batch 17/64 loss: 0.21943962574005127
Batch 18/64 loss: 0.2165135145187378
Batch 19/64 loss: 0.21157217025756836
Batch 20/64 loss: 0.20750784873962402
Batch 21/64 loss: 0.22338151931762695
Batch 22/64 loss: 0.2067352533340454
Batch 23/64 loss: 0.20414608716964722
Batch 24/64 loss: 0.2120896577835083
Batch 25/64 loss: 0.20135778188705444
Batch 26/64 loss: 0.20824062824249268
Batch 27/64 loss: 0.2060430645942688
Batch 28/64 loss: 0.2070322036743164
Batch 29/64 loss: 0.22110038995742798
Batch 30/64 loss: 0.21220088005065918
Batch 31/64 loss: 0.20923709869384766
Batch 32/64 loss: 0.21473824977874756
Batch 33/64 loss: 0.21348536014556885
Batch 34/64 loss: 0.21521741151809692
Batch 35/64 loss: 0.21048104763031006
Batch 36/64 loss: 0.21214312314987183
Batch 37/64 loss: 0.21045362949371338
Batch 38/64 loss: 0.21012461185455322
Batch 39/64 loss: 0.21596872806549072
Batch 40/64 loss: 0.21012437343597412
Batch 41/64 loss: 0.21571791172027588
Batch 42/64 loss: 0.20735961198806763
Batch 43/64 loss: 0.2180449366569519
Batch 44/64 loss: 0.2052324414253235
Batch 45/64 loss: 0.21342962980270386
Batch 46/64 loss: 0.2037861943244934
Batch 47/64 loss: 0.20815426111221313
Batch 48/64 loss: 0.21071374416351318
Batch 49/64 loss: 0.20906853675842285
Batch 50/64 loss: 0.20909744501113892
Batch 51/64 loss: 0.21141505241394043
Batch 52/64 loss: 0.2061561942100525
Batch 53/64 loss: 0.20444345474243164
Batch 54/64 loss: 0.21326303482055664
Batch 55/64 loss: 0.20132672786712646
Batch 56/64 loss: 0.2077881097793579
Batch 57/64 loss: 0.2120652198791504
Batch 58/64 loss: 0.20426881313323975
Batch 59/64 loss: 0.2156553864479065
Batch 60/64 loss: 0.20285749435424805
Batch 61/64 loss: 0.20961785316467285
Batch 62/64 loss: 0.213905930519104
Batch 63/64 loss: 0.20318400859832764
Batch 64/64 loss: 0.20526587963104248
Epoch 378  Train loss: 0.2100601453407138  Val loss: 0.2696289291086885
Epoch 379
-------------------------------
Batch 1/64 loss: 0.2068924903869629
Batch 2/64 loss: 0.20064115524291992
Batch 3/64 loss: 0.2039545178413391
Batch 4/64 loss: 0.21111106872558594
Batch 5/64 loss: 0.2166997790336609
Batch 6/64 loss: 0.2044467329978943
Batch 7/64 loss: 0.21217215061187744
Batch 8/64 loss: 0.20152997970581055
Batch 9/64 loss: 0.20477938652038574
Batch 10/64 loss: 0.21188855171203613
Batch 11/64 loss: 0.207677960395813
Batch 12/64 loss: 0.2040308713912964
Batch 13/64 loss: 0.2012137770652771
Batch 14/64 loss: 0.21207982301712036
Batch 15/64 loss: 0.2057511806488037
Batch 16/64 loss: 0.2097606658935547
Batch 17/64 loss: 0.20022308826446533
Batch 18/64 loss: 0.20719105005264282
Batch 19/64 loss: 0.2059403657913208
Batch 20/64 loss: 0.21447980403900146
Batch 21/64 loss: 0.19981324672698975
Batch 22/64 loss: 0.2160036563873291
Batch 23/64 loss: 0.20769739151000977
Batch 24/64 loss: 0.20151782035827637
Batch 25/64 loss: 0.20973223447799683
Batch 26/64 loss: 0.22044110298156738
Batch 27/64 loss: 0.1994805932044983
Batch 28/64 loss: 0.22342348098754883
Batch 29/64 loss: 0.21856164932250977
Batch 30/64 loss: 0.20672130584716797
Batch 31/64 loss: 0.21932685375213623
Batch 32/64 loss: 0.21814972162246704
Batch 33/64 loss: 0.22341954708099365
Batch 34/64 loss: 0.20779669284820557
Batch 35/64 loss: 0.20848232507705688
Batch 36/64 loss: 0.2010173797607422
Batch 37/64 loss: 0.20590293407440186
Batch 38/64 loss: 0.21168935298919678
Batch 39/64 loss: 0.2221299409866333
Batch 40/64 loss: 0.20206570625305176
Batch 41/64 loss: 0.21589207649230957
Batch 42/64 loss: 0.20956122875213623
Batch 43/64 loss: 0.20853763818740845
Batch 44/64 loss: 0.19756227731704712
Batch 45/64 loss: 0.2121754288673401
Batch 46/64 loss: 0.21073472499847412
Batch 47/64 loss: 0.21598249673843384
Batch 48/64 loss: 0.20476937294006348
Batch 49/64 loss: 0.20631146430969238
Batch 50/64 loss: 0.2212505340576172
Batch 51/64 loss: 0.20250153541564941
Batch 52/64 loss: 0.22294199466705322
Batch 53/64 loss: 0.21713286638259888
Batch 54/64 loss: 0.2123699188232422
Batch 55/64 loss: 0.21247804164886475
Batch 56/64 loss: 0.2105225920677185
Batch 57/64 loss: 0.2068420648574829
Batch 58/64 loss: 0.2093513011932373
Batch 59/64 loss: 0.21733522415161133
Batch 60/64 loss: 0.21393287181854248
Batch 61/64 loss: 0.21383130550384521
Batch 62/64 loss: 0.21196389198303223
Batch 63/64 loss: 0.20755398273468018
Batch 64/64 loss: 0.20423686504364014
Epoch 379  Train loss: 0.20989097754160563  Val loss: 0.27028422257334916
Epoch 380
-------------------------------
Batch 1/64 loss: 0.2088862657546997
Batch 2/64 loss: 0.22207915782928467
Batch 3/64 loss: 0.20871376991271973
Batch 4/64 loss: 0.21861052513122559
Batch 5/64 loss: 0.20388329029083252
Batch 6/64 loss: 0.2104838490486145
Batch 7/64 loss: 0.21685171127319336
Batch 8/64 loss: 0.2018338441848755
Batch 9/64 loss: 0.21158039569854736
Batch 10/64 loss: 0.21312081813812256
Batch 11/64 loss: 0.21119731664657593
Batch 12/64 loss: 0.2065407633781433
Batch 13/64 loss: 0.20828485488891602
Batch 14/64 loss: 0.20197755098342896
Batch 15/64 loss: 0.20477372407913208
Batch 16/64 loss: 0.21304666996002197
Batch 17/64 loss: 0.21116113662719727
Batch 18/64 loss: 0.20714330673217773
Batch 19/64 loss: 0.20371174812316895
Batch 20/64 loss: 0.21431416273117065
Batch 21/64 loss: 0.20517903566360474
Batch 22/64 loss: 0.2090725302696228
Batch 23/64 loss: 0.2138323187828064
Batch 24/64 loss: 0.22260254621505737
Batch 25/64 loss: 0.20538759231567383
Batch 26/64 loss: 0.2021327018737793
Batch 27/64 loss: 0.21194487810134888
Batch 28/64 loss: 0.20779478549957275
Batch 29/64 loss: 0.20046353340148926
Batch 30/64 loss: 0.2157067060470581
Batch 31/64 loss: 0.20587193965911865
Batch 32/64 loss: 0.20612460374832153
Batch 33/64 loss: 0.20992636680603027
Batch 34/64 loss: 0.22333747148513794
Batch 35/64 loss: 0.21302509307861328
Batch 36/64 loss: 0.20652318000793457
Batch 37/64 loss: 0.20737206935882568
Batch 38/64 loss: 0.2096872329711914
Batch 39/64 loss: 0.21274960041046143
Batch 40/64 loss: 0.2129717469215393
Batch 41/64 loss: 0.21272623538970947
Batch 42/64 loss: 0.20237278938293457
Batch 43/64 loss: 0.21046775579452515
Batch 44/64 loss: 0.2118443250656128
Batch 45/64 loss: 0.20666980743408203
Batch 46/64 loss: 0.2144508957862854
Batch 47/64 loss: 0.2058318853378296
Batch 48/64 loss: 0.20556426048278809
Batch 49/64 loss: 0.2019510269165039
Batch 50/64 loss: 0.20247316360473633
Batch 51/64 loss: 0.20174312591552734
Batch 52/64 loss: 0.21908926963806152
Batch 53/64 loss: 0.20790916681289673
Batch 54/64 loss: 0.20390576124191284
Batch 55/64 loss: 0.20779180526733398
Batch 56/64 loss: 0.2122889757156372
Batch 57/64 loss: 0.2020413875579834
Batch 58/64 loss: 0.2080007791519165
Batch 59/64 loss: 0.21221017837524414
Batch 60/64 loss: 0.21208548545837402
Batch 61/64 loss: 0.211523175239563
Batch 62/64 loss: 0.21429628133773804
Batch 63/64 loss: 0.20047205686569214
Batch 64/64 loss: 0.2146112322807312
Epoch 380  Train loss: 0.209389314698238  Val loss: 0.26961512745860516
Epoch 381
-------------------------------
Batch 1/64 loss: 0.21296733617782593
Batch 2/64 loss: 0.20762228965759277
Batch 3/64 loss: 0.2015542984008789
Batch 4/64 loss: 0.21941328048706055
Batch 5/64 loss: 0.19937318563461304
Batch 6/64 loss: 0.19938206672668457
Batch 7/64 loss: 0.21666985750198364
Batch 8/64 loss: 0.2093890905380249
Batch 9/64 loss: 0.2058669924736023
Batch 10/64 loss: 0.20331841707229614
Batch 11/64 loss: 0.20275747776031494
Batch 12/64 loss: 0.2155962586402893
Batch 13/64 loss: 0.20302778482437134
Batch 14/64 loss: 0.22041380405426025
Batch 15/64 loss: 0.21468514204025269
Batch 16/64 loss: 0.20896518230438232
Batch 17/64 loss: 0.20948320627212524
Batch 18/64 loss: 0.2039508819580078
Batch 19/64 loss: 0.21137630939483643
Batch 20/64 loss: 0.21632027626037598
Batch 21/64 loss: 0.20069777965545654
Batch 22/64 loss: 0.19888436794281006
Batch 23/64 loss: 0.20440822839736938
Batch 24/64 loss: 0.21059006452560425
Batch 25/64 loss: 0.21199816465377808
Batch 26/64 loss: 0.20684999227523804
Batch 27/64 loss: 0.21769863367080688
Batch 28/64 loss: 0.21603357791900635
Batch 29/64 loss: 0.20578879117965698
Batch 30/64 loss: 0.2150648832321167
Batch 31/64 loss: 0.21649813652038574
Batch 32/64 loss: 0.21233367919921875
Batch 33/64 loss: 0.21134376525878906
Batch 34/64 loss: 0.2061326503753662
Batch 35/64 loss: 0.21289384365081787
Batch 36/64 loss: 0.20798760652542114
Batch 37/64 loss: 0.2082030177116394
Batch 38/64 loss: 0.21152979135513306
Batch 39/64 loss: 0.2050420641899109
Batch 40/64 loss: 0.21102428436279297
Batch 41/64 loss: 0.20491206645965576
Batch 42/64 loss: 0.20253193378448486
Batch 43/64 loss: 0.21051794290542603
Batch 44/64 loss: 0.19844460487365723
Batch 45/64 loss: 0.21431469917297363
Batch 46/64 loss: 0.21384501457214355
Batch 47/64 loss: 0.2065640091896057
Batch 48/64 loss: 0.21637046337127686
Batch 49/64 loss: 0.21284818649291992
Batch 50/64 loss: 0.20913159847259521
Batch 51/64 loss: 0.20377856492996216
Batch 52/64 loss: 0.2088468074798584
Batch 53/64 loss: 0.2093554139137268
Batch 54/64 loss: 0.2260265350341797
Batch 55/64 loss: 0.1995481252670288
Batch 56/64 loss: 0.20623540878295898
Batch 57/64 loss: 0.20496046543121338
Batch 58/64 loss: 0.2064279317855835
Batch 59/64 loss: 0.2123199701309204
Batch 60/64 loss: 0.20796847343444824
Batch 61/64 loss: 0.2145099639892578
Batch 62/64 loss: 0.21714496612548828
Batch 63/64 loss: 0.20605474710464478
Batch 64/64 loss: 0.21608507633209229
Epoch 381  Train loss: 0.20937816722720276  Val loss: 0.2685137221084018
Epoch 382
-------------------------------
Batch 1/64 loss: 0.2154056429862976
Batch 2/64 loss: 0.19943302869796753
Batch 3/64 loss: 0.2128610610961914
Batch 4/64 loss: 0.21007263660430908
Batch 5/64 loss: 0.21548229455947876
Batch 6/64 loss: 0.2000299096107483
Batch 7/64 loss: 0.20550036430358887
Batch 8/64 loss: 0.21472567319869995
Batch 9/64 loss: 0.20872825384140015
Batch 10/64 loss: 0.20526963472366333
Batch 11/64 loss: 0.20757079124450684
Batch 12/64 loss: 0.1982508897781372
Batch 13/64 loss: 0.20300859212875366
Batch 14/64 loss: 0.20371860265731812
Batch 15/64 loss: 0.20466488599777222
Batch 16/64 loss: 0.20380425453186035
Batch 17/64 loss: 0.20369809865951538
Batch 18/64 loss: 0.19793552160263062
Batch 19/64 loss: 0.21271347999572754
Batch 20/64 loss: 0.20733606815338135
Batch 21/64 loss: 0.20552349090576172
Batch 22/64 loss: 0.2088562250137329
Batch 23/64 loss: 0.21397340297698975
Batch 24/64 loss: 0.2050248384475708
Batch 25/64 loss: 0.21615701913833618
Batch 26/64 loss: 0.21128928661346436
Batch 27/64 loss: 0.21249181032180786
Batch 28/64 loss: 0.19987577199935913
Batch 29/64 loss: 0.2099817991256714
Batch 30/64 loss: 0.20290613174438477
Batch 31/64 loss: 0.19801902770996094
Batch 32/64 loss: 0.22416722774505615
Batch 33/64 loss: 0.20165115594863892
Batch 34/64 loss: 0.1998603343963623
Batch 35/64 loss: 0.20707714557647705
Batch 36/64 loss: 0.21359217166900635
Batch 37/64 loss: 0.20260024070739746
Batch 38/64 loss: 0.21037018299102783
Batch 39/64 loss: 0.21458488702774048
Batch 40/64 loss: 0.20584702491760254
Batch 41/64 loss: 0.19951850175857544
Batch 42/64 loss: 0.22435927391052246
Batch 43/64 loss: 0.21150755882263184
Batch 44/64 loss: 0.20877081155776978
Batch 45/64 loss: 0.22130954265594482
Batch 46/64 loss: 0.21464383602142334
Batch 47/64 loss: 0.20511996746063232
Batch 48/64 loss: 0.21125847101211548
Batch 49/64 loss: 0.2128582000732422
Batch 50/64 loss: 0.20543062686920166
Batch 51/64 loss: 0.21596217155456543
Batch 52/64 loss: 0.20244944095611572
Batch 53/64 loss: 0.2128063440322876
Batch 54/64 loss: 0.2135745882987976
Batch 55/64 loss: 0.2194918394088745
Batch 56/64 loss: 0.2096729278564453
Batch 57/64 loss: 0.21503454446792603
Batch 58/64 loss: 0.20743167400360107
Batch 59/64 loss: 0.21748828887939453
Batch 60/64 loss: 0.20452988147735596
Batch 61/64 loss: 0.21088528633117676
Batch 62/64 loss: 0.2089766263961792
Batch 63/64 loss: 0.21120846271514893
Batch 64/64 loss: 0.20841312408447266
Epoch 382  Train loss: 0.2088573736302993  Val loss: 0.26880369686179145
Epoch 383
-------------------------------
Batch 1/64 loss: 0.2046840786933899
Batch 2/64 loss: 0.20782804489135742
Batch 3/64 loss: 0.20987337827682495
Batch 4/64 loss: 0.2144879698753357
Batch 5/64 loss: 0.20620697736740112
Batch 6/64 loss: 0.2012048363685608
Batch 7/64 loss: 0.19818168878555298
Batch 8/64 loss: 0.19659322500228882
Batch 9/64 loss: 0.20452988147735596
Batch 10/64 loss: 0.20424515008926392
Batch 11/64 loss: 0.20431846380233765
Batch 12/64 loss: 0.20364832878112793
Batch 13/64 loss: 0.20797908306121826
Batch 14/64 loss: 0.202012836933136
Batch 15/64 loss: 0.20018523931503296
Batch 16/64 loss: 0.21469908952713013
Batch 17/64 loss: 0.20043087005615234
Batch 18/64 loss: 0.2228074073791504
Batch 19/64 loss: 0.2062242031097412
Batch 20/64 loss: 0.20991814136505127
Batch 21/64 loss: 0.20186597108840942
Batch 22/64 loss: 0.20799517631530762
Batch 23/64 loss: 0.20419955253601074
Batch 24/64 loss: 0.2062552571296692
Batch 25/64 loss: 0.2183927297592163
Batch 26/64 loss: 0.20805060863494873
Batch 27/64 loss: 0.20261895656585693
Batch 28/64 loss: 0.20442920923233032
Batch 29/64 loss: 0.2093542218208313
Batch 30/64 loss: 0.2065563201904297
Batch 31/64 loss: 0.19733518362045288
Batch 32/64 loss: 0.21506667137145996
Batch 33/64 loss: 0.21881002187728882
Batch 34/64 loss: 0.2069169282913208
Batch 35/64 loss: 0.20902568101882935
Batch 36/64 loss: 0.21132463216781616
Batch 37/64 loss: 0.2257392406463623
Batch 38/64 loss: 0.20180654525756836
Batch 39/64 loss: 0.2084054946899414
Batch 40/64 loss: 0.20313793420791626
Batch 41/64 loss: 0.21284091472625732
Batch 42/64 loss: 0.22035038471221924
Batch 43/64 loss: 0.21066272258758545
Batch 44/64 loss: 0.2113603949546814
Batch 45/64 loss: 0.2113955020904541
Batch 46/64 loss: 0.20770478248596191
Batch 47/64 loss: 0.21879315376281738
Batch 48/64 loss: 0.21677470207214355
Batch 49/64 loss: 0.21754276752471924
Batch 50/64 loss: 0.21673548221588135
Batch 51/64 loss: 0.20534002780914307
Batch 52/64 loss: 0.21415483951568604
Batch 53/64 loss: 0.21101760864257812
Batch 54/64 loss: 0.20476514101028442
Batch 55/64 loss: 0.19823771715164185
Batch 56/64 loss: 0.20856404304504395
Batch 57/64 loss: 0.21116876602172852
Batch 58/64 loss: 0.2087879180908203
Batch 59/64 loss: 0.21688556671142578
Batch 60/64 loss: 0.21536386013031006
Batch 61/64 loss: 0.20802277326583862
Batch 62/64 loss: 0.21552002429962158
Batch 63/64 loss: 0.22028684616088867
Batch 64/64 loss: 0.21511828899383545
Epoch 383  Train loss: 0.20911309625588212  Val loss: 0.2684347299775717
Epoch 384
-------------------------------
Batch 1/64 loss: 0.20453357696533203
Batch 2/64 loss: 0.20640993118286133
Batch 3/64 loss: 0.20683038234710693
Batch 4/64 loss: 0.20625483989715576
Batch 5/64 loss: 0.2069646716117859
Batch 6/64 loss: 0.2061671018600464
Batch 7/64 loss: 0.20117026567459106
Batch 8/64 loss: 0.21209347248077393
Batch 9/64 loss: 0.20533859729766846
Batch 10/64 loss: 0.2050355076789856
Batch 11/64 loss: 0.21420812606811523
Batch 12/64 loss: 0.21679329872131348
Batch 13/64 loss: 0.20367908477783203
Batch 14/64 loss: 0.20000404119491577
Batch 15/64 loss: 0.20246386528015137
Batch 16/64 loss: 0.20805728435516357
Batch 17/64 loss: 0.21329808235168457
Batch 18/64 loss: 0.19987589120864868
Batch 19/64 loss: 0.22436797618865967
Batch 20/64 loss: 0.20651280879974365
Batch 21/64 loss: 0.20970827341079712
Batch 22/64 loss: 0.210882306098938
Batch 23/64 loss: 0.20702779293060303
Batch 24/64 loss: 0.21441763639450073
Batch 25/64 loss: 0.21573811769485474
Batch 26/64 loss: 0.21173900365829468
Batch 27/64 loss: 0.2107275128364563
Batch 28/64 loss: 0.21015125513076782
Batch 29/64 loss: 0.21400654315948486
Batch 30/64 loss: 0.20239347219467163
Batch 31/64 loss: 0.20138627290725708
Batch 32/64 loss: 0.21871542930603027
Batch 33/64 loss: 0.21206563711166382
Batch 34/64 loss: 0.21379423141479492
Batch 35/64 loss: 0.21013712882995605
Batch 36/64 loss: 0.21573889255523682
Batch 37/64 loss: 0.20863372087478638
Batch 38/64 loss: 0.20958298444747925
Batch 39/64 loss: 0.21481388807296753
Batch 40/64 loss: 0.20171862840652466
Batch 41/64 loss: 0.20946919918060303
Batch 42/64 loss: 0.21699535846710205
Batch 43/64 loss: 0.20651757717132568
Batch 44/64 loss: 0.21544533967971802
Batch 45/64 loss: 0.19654875993728638
Batch 46/64 loss: 0.20838922262191772
Batch 47/64 loss: 0.2144068479537964
Batch 48/64 loss: 0.21007460355758667
Batch 49/64 loss: 0.21005725860595703
Batch 50/64 loss: 0.2115790843963623
Batch 51/64 loss: 0.20604026317596436
Batch 52/64 loss: 0.21199440956115723
Batch 53/64 loss: 0.20427066087722778
Batch 54/64 loss: 0.21385973691940308
Batch 55/64 loss: 0.21538007259368896
Batch 56/64 loss: 0.21515095233917236
Batch 57/64 loss: 0.20736801624298096
Batch 58/64 loss: 0.22097402811050415
Batch 59/64 loss: 0.207602858543396
Batch 60/64 loss: 0.21264362335205078
Batch 61/64 loss: 0.20436590909957886
Batch 62/64 loss: 0.20369106531143188
Batch 63/64 loss: 0.2103922963142395
Batch 64/64 loss: 0.21407568454742432
Epoch 384  Train loss: 0.20952488534590777  Val loss: 0.27024893498502645
Epoch 385
-------------------------------
Batch 1/64 loss: 0.2171992063522339
Batch 2/64 loss: 0.20625394582748413
Batch 3/64 loss: 0.20487767457962036
Batch 4/64 loss: 0.21164047718048096
Batch 5/64 loss: 0.2102733850479126
Batch 6/64 loss: 0.20043671131134033
Batch 7/64 loss: 0.2046511173248291
Batch 8/64 loss: 0.20584911108016968
Batch 9/64 loss: 0.20464849472045898
Batch 10/64 loss: 0.21775078773498535
Batch 11/64 loss: 0.2254962921142578
Batch 12/64 loss: 0.2121340036392212
Batch 13/64 loss: 0.19970732927322388
Batch 14/64 loss: 0.21303081512451172
Batch 15/64 loss: 0.20949530601501465
Batch 16/64 loss: 0.22324764728546143
Batch 17/64 loss: 0.2059900164604187
Batch 18/64 loss: 0.20517897605895996
Batch 19/64 loss: 0.21511507034301758
Batch 20/64 loss: 0.21027439832687378
Batch 21/64 loss: 0.20292246341705322
Batch 22/64 loss: 0.2039889693260193
Batch 23/64 loss: 0.2103557586669922
Batch 24/64 loss: 0.202886700630188
Batch 25/64 loss: 0.2180180549621582
Batch 26/64 loss: 0.2097684144973755
Batch 27/64 loss: 0.20404595136642456
Batch 28/64 loss: 0.20347076654434204
Batch 29/64 loss: 0.20907050371170044
Batch 30/64 loss: 0.21036571264266968
Batch 31/64 loss: 0.2092728614807129
Batch 32/64 loss: 0.20847147703170776
Batch 33/64 loss: 0.21256786584854126
Batch 34/64 loss: 0.2069033980369568
Batch 35/64 loss: 0.21221935749053955
Batch 36/64 loss: 0.21308356523513794
Batch 37/64 loss: 0.20910519361495972
Batch 38/64 loss: 0.2027425765991211
Batch 39/64 loss: 0.20521855354309082
Batch 40/64 loss: 0.22595971822738647
Batch 41/64 loss: 0.2150278091430664
Batch 42/64 loss: 0.20737498998641968
Batch 43/64 loss: 0.21033227443695068
Batch 44/64 loss: 0.20638269186019897
Batch 45/64 loss: 0.20485585927963257
Batch 46/64 loss: 0.19866502285003662
Batch 47/64 loss: 0.2056230902671814
Batch 48/64 loss: 0.20539283752441406
Batch 49/64 loss: 0.21620213985443115
Batch 50/64 loss: 0.21667581796646118
Batch 51/64 loss: 0.20705509185791016
Batch 52/64 loss: 0.2064957618713379
Batch 53/64 loss: 0.20111405849456787
Batch 54/64 loss: 0.19584554433822632
Batch 55/64 loss: 0.20830309391021729
Batch 56/64 loss: 0.20280194282531738
Batch 57/64 loss: 0.20323973894119263
Batch 58/64 loss: 0.2135937213897705
Batch 59/64 loss: 0.20727360248565674
Batch 60/64 loss: 0.2129957675933838
Batch 61/64 loss: 0.22048604488372803
Batch 62/64 loss: 0.20527797937393188
Batch 63/64 loss: 0.20846712589263916
Batch 64/64 loss: 0.2024129033088684
Epoch 385  Train loss: 0.20886243628520593  Val loss: 0.26916113813308506
Epoch 386
-------------------------------
Batch 1/64 loss: 0.20699286460876465
Batch 2/64 loss: 0.20391583442687988
Batch 3/64 loss: 0.20812159776687622
Batch 4/64 loss: 0.20731592178344727
Batch 5/64 loss: 0.21275973320007324
Batch 6/64 loss: 0.19765979051589966
Batch 7/64 loss: 0.21525263786315918
Batch 8/64 loss: 0.20058578252792358
Batch 9/64 loss: 0.21192914247512817
Batch 10/64 loss: 0.21856915950775146
Batch 11/64 loss: 0.20889264345169067
Batch 12/64 loss: 0.2026289701461792
Batch 13/64 loss: 0.20021331310272217
Batch 14/64 loss: 0.20941811800003052
Batch 15/64 loss: 0.20536571741104126
Batch 16/64 loss: 0.20275664329528809
Batch 17/64 loss: 0.20997679233551025
Batch 18/64 loss: 0.2181066870689392
Batch 19/64 loss: 0.20142000913619995
Batch 20/64 loss: 0.21018165349960327
Batch 21/64 loss: 0.21231937408447266
Batch 22/64 loss: 0.20724976062774658
Batch 23/64 loss: 0.2088766098022461
Batch 24/64 loss: 0.20578229427337646
Batch 25/64 loss: 0.202492356300354
Batch 26/64 loss: 0.20191103219985962
Batch 27/64 loss: 0.20934617519378662
Batch 28/64 loss: 0.21266931295394897
Batch 29/64 loss: 0.20908427238464355
Batch 30/64 loss: 0.20503997802734375
Batch 31/64 loss: 0.21535253524780273
Batch 32/64 loss: 0.21315008401870728
Batch 33/64 loss: 0.20378005504608154
Batch 34/64 loss: 0.21908342838287354
Batch 35/64 loss: 0.2030019760131836
Batch 36/64 loss: 0.2087240219116211
Batch 37/64 loss: 0.20950531959533691
Batch 38/64 loss: 0.21022963523864746
Batch 39/64 loss: 0.20870256423950195
Batch 40/64 loss: 0.2053753137588501
Batch 41/64 loss: 0.21271663904190063
Batch 42/64 loss: 0.20765787363052368
Batch 43/64 loss: 0.2125387191772461
Batch 44/64 loss: 0.21821212768554688
Batch 45/64 loss: 0.2074216604232788
Batch 46/64 loss: 0.21962875127792358
Batch 47/64 loss: 0.21813178062438965
Batch 48/64 loss: 0.20784735679626465
Batch 49/64 loss: 0.21167659759521484
Batch 50/64 loss: 0.21021544933319092
Batch 51/64 loss: 0.21070289611816406
Batch 52/64 loss: 0.2196846604347229
Batch 53/64 loss: 0.20856451988220215
Batch 54/64 loss: 0.21380150318145752
Batch 55/64 loss: 0.20113211870193481
Batch 56/64 loss: 0.21369117498397827
Batch 57/64 loss: 0.20907533168792725
Batch 58/64 loss: 0.20897150039672852
Batch 59/64 loss: 0.20444226264953613
Batch 60/64 loss: 0.19981449842453003
Batch 61/64 loss: 0.20181185007095337
Batch 62/64 loss: 0.20265138149261475
Batch 63/64 loss: 0.21123701333999634
Batch 64/64 loss: 0.21558266878128052
Epoch 386  Train loss: 0.20889496125426946  Val loss: 0.2686850586297995
Epoch 387
-------------------------------
Batch 1/64 loss: 0.20691752433776855
Batch 2/64 loss: 0.19689422845840454
Batch 3/64 loss: 0.20862138271331787
Batch 4/64 loss: 0.19915151596069336
Batch 5/64 loss: 0.20910441875457764
Batch 6/64 loss: 0.2041110396385193
Batch 7/64 loss: 0.2067837119102478
Batch 8/64 loss: 0.2136896848678589
Batch 9/64 loss: 0.19672727584838867
Batch 10/64 loss: 0.2170494794845581
Batch 11/64 loss: 0.2088046669960022
Batch 12/64 loss: 0.2052801251411438
Batch 13/64 loss: 0.20641303062438965
Batch 14/64 loss: 0.21571147441864014
Batch 15/64 loss: 0.2104203701019287
Batch 16/64 loss: 0.21117019653320312
Batch 17/64 loss: 0.20533335208892822
Batch 18/64 loss: 0.21077477931976318
Batch 19/64 loss: 0.20312929153442383
Batch 20/64 loss: 0.20601487159729004
Batch 21/64 loss: 0.2135707139968872
Batch 22/64 loss: 0.20401060581207275
Batch 23/64 loss: 0.21347343921661377
Batch 24/64 loss: 0.21317678689956665
Batch 25/64 loss: 0.21059578657150269
Batch 26/64 loss: 0.20405268669128418
Batch 27/64 loss: 0.20565831661224365
Batch 28/64 loss: 0.20151287317276
Batch 29/64 loss: 0.21224451065063477
Batch 30/64 loss: 0.2162015438079834
Batch 31/64 loss: 0.22096925973892212
Batch 32/64 loss: 0.20003658533096313
Batch 33/64 loss: 0.213201642036438
Batch 34/64 loss: 0.20742177963256836
Batch 35/64 loss: 0.20627963542938232
Batch 36/64 loss: 0.20905077457427979
Batch 37/64 loss: 0.20242911577224731
Batch 38/64 loss: 0.21389973163604736
Batch 39/64 loss: 0.20754486322402954
Batch 40/64 loss: 0.20940911769866943
Batch 41/64 loss: 0.21134114265441895
Batch 42/64 loss: 0.20516812801361084
Batch 43/64 loss: 0.21739548444747925
Batch 44/64 loss: 0.19541895389556885
Batch 45/64 loss: 0.209048330783844
Batch 46/64 loss: 0.20266997814178467
Batch 47/64 loss: 0.2087889313697815
Batch 48/64 loss: 0.20734667778015137
Batch 49/64 loss: 0.20286113023757935
Batch 50/64 loss: 0.2076934576034546
Batch 51/64 loss: 0.2048933506011963
Batch 52/64 loss: 0.2156432867050171
Batch 53/64 loss: 0.20818960666656494
Batch 54/64 loss: 0.2058083415031433
Batch 55/64 loss: 0.21489059925079346
Batch 56/64 loss: 0.21159029006958008
Batch 57/64 loss: 0.21644634008407593
Batch 58/64 loss: 0.22325211763381958
Batch 59/64 loss: 0.20135009288787842
Batch 60/64 loss: 0.2081129550933838
Batch 61/64 loss: 0.20282673835754395
Batch 62/64 loss: 0.1997840404510498
Batch 63/64 loss: 0.20551073551177979
Batch 64/64 loss: 0.21389007568359375
Epoch 387  Train loss: 0.20820847773084453  Val loss: 0.2686672378651465
Epoch 388
-------------------------------
Batch 1/64 loss: 0.2125692367553711
Batch 2/64 loss: 0.20349544286727905
Batch 3/64 loss: 0.20238709449768066
Batch 4/64 loss: 0.20098835229873657
Batch 5/64 loss: 0.19695281982421875
Batch 6/64 loss: 0.21361494064331055
Batch 7/64 loss: 0.21191823482513428
Batch 8/64 loss: 0.20270103216171265
Batch 9/64 loss: 0.20894169807434082
Batch 10/64 loss: 0.20709025859832764
Batch 11/64 loss: 0.20594912767410278
Batch 12/64 loss: 0.21032291650772095
Batch 13/64 loss: 0.19400286674499512
Batch 14/64 loss: 0.2106034755706787
Batch 15/64 loss: 0.21449601650238037
Batch 16/64 loss: 0.1940784454345703
Batch 17/64 loss: 0.21948623657226562
Batch 18/64 loss: 0.20110589265823364
Batch 19/64 loss: 0.21454614400863647
Batch 20/64 loss: 0.20346570014953613
Batch 21/64 loss: 0.2177433967590332
Batch 22/64 loss: 0.21170145273208618
Batch 23/64 loss: 0.20526838302612305
Batch 24/64 loss: 0.21152132749557495
Batch 25/64 loss: 0.20804810523986816
Batch 26/64 loss: 0.1975088119506836
Batch 27/64 loss: 0.20529961585998535
Batch 28/64 loss: 0.20595747232437134
Batch 29/64 loss: 0.20600903034210205
Batch 30/64 loss: 0.2178502082824707
Batch 31/64 loss: 0.2084077000617981
Batch 32/64 loss: 0.21744275093078613
Batch 33/64 loss: 0.2016468048095703
Batch 34/64 loss: 0.2021886110305786
Batch 35/64 loss: 0.2117847204208374
Batch 36/64 loss: 0.21320509910583496
Batch 37/64 loss: 0.2205069661140442
Batch 38/64 loss: 0.21432793140411377
Batch 39/64 loss: 0.2084364891052246
Batch 40/64 loss: 0.21017563343048096
Batch 41/64 loss: 0.21250379085540771
Batch 42/64 loss: 0.20800256729125977
Batch 43/64 loss: 0.20874398946762085
Batch 44/64 loss: 0.20064866542816162
Batch 45/64 loss: 0.22035270929336548
Batch 46/64 loss: 0.21712040901184082
Batch 47/64 loss: 0.21219807863235474
Batch 48/64 loss: 0.2082117795944214
Batch 49/64 loss: 0.20432555675506592
Batch 50/64 loss: 0.21804583072662354
Batch 51/64 loss: 0.2214900255203247
Batch 52/64 loss: 0.20405077934265137
Batch 53/64 loss: 0.21217167377471924
Batch 54/64 loss: 0.21198606491088867
Batch 55/64 loss: 0.20428365468978882
Batch 56/64 loss: 0.20487356185913086
Batch 57/64 loss: 0.20675361156463623
Batch 58/64 loss: 0.20850592851638794
Batch 59/64 loss: 0.20836615562438965
Batch 60/64 loss: 0.21546918153762817
Batch 61/64 loss: 0.20959234237670898
Batch 62/64 loss: 0.20760774612426758
Batch 63/64 loss: 0.20845365524291992
Batch 64/64 loss: 0.20790749788284302
Epoch 388  Train loss: 0.20883819332309797  Val loss: 0.26884365983025726
Epoch 389
-------------------------------
Batch 1/64 loss: 0.20657509565353394
Batch 2/64 loss: 0.2061290144920349
Batch 3/64 loss: 0.20758163928985596
Batch 4/64 loss: 0.2039315104484558
Batch 5/64 loss: 0.2049715518951416
Batch 6/64 loss: 0.2087613344192505
Batch 7/64 loss: 0.2192203402519226
Batch 8/64 loss: 0.21259468793869019
Batch 9/64 loss: 0.20368582010269165
Batch 10/64 loss: 0.20759260654449463
Batch 11/64 loss: 0.20931750535964966
Batch 12/64 loss: 0.21032875776290894
Batch 13/64 loss: 0.21865272521972656
Batch 14/64 loss: 0.21083283424377441
Batch 15/64 loss: 0.20567065477371216
Batch 16/64 loss: 0.22103524208068848
Batch 17/64 loss: 0.20940232276916504
Batch 18/64 loss: 0.20895510911941528
Batch 19/64 loss: 0.2028023600578308
Batch 20/64 loss: 0.20785516500473022
Batch 21/64 loss: 0.2060520052909851
Batch 22/64 loss: 0.2130511999130249
Batch 23/64 loss: 0.21636724472045898
Batch 24/64 loss: 0.21521919965744019
Batch 25/64 loss: 0.20602214336395264
Batch 26/64 loss: 0.20074039697647095
Batch 27/64 loss: 0.20618438720703125
Batch 28/64 loss: 0.20245295763015747
Batch 29/64 loss: 0.2261584997177124
Batch 30/64 loss: 0.21511656045913696
Batch 31/64 loss: 0.20480167865753174
Batch 32/64 loss: 0.20039236545562744
Batch 33/64 loss: 0.2115737795829773
Batch 34/64 loss: 0.20506179332733154
Batch 35/64 loss: 0.20470982789993286
Batch 36/64 loss: 0.20801126956939697
Batch 37/64 loss: 0.20567631721496582
Batch 38/64 loss: 0.19790560007095337
Batch 39/64 loss: 0.2061331868171692
Batch 40/64 loss: 0.20994329452514648
Batch 41/64 loss: 0.21060693264007568
Batch 42/64 loss: 0.2092704176902771
Batch 43/64 loss: 0.20492511987686157
Batch 44/64 loss: 0.2115182876586914
Batch 45/64 loss: 0.19953685998916626
Batch 46/64 loss: 0.20203429460525513
Batch 47/64 loss: 0.214918851852417
Batch 48/64 loss: 0.2032778263092041
Batch 49/64 loss: 0.21021240949630737
Batch 50/64 loss: 0.203385591506958
Batch 51/64 loss: 0.219140887260437
Batch 52/64 loss: 0.2046911120414734
Batch 53/64 loss: 0.214532732963562
Batch 54/64 loss: 0.20343327522277832
Batch 55/64 loss: 0.2091686725616455
Batch 56/64 loss: 0.2150338888168335
Batch 57/64 loss: 0.20467060804367065
Batch 58/64 loss: 0.2081812620162964
Batch 59/64 loss: 0.20601356029510498
Batch 60/64 loss: 0.20962578058242798
Batch 61/64 loss: 0.2078925371170044
Batch 62/64 loss: 0.2065407633781433
Batch 63/64 loss: 0.2051541805267334
Batch 64/64 loss: 0.2050366997718811
Epoch 389  Train loss: 0.20839236647474998  Val loss: 0.269067961940241
Epoch 390
-------------------------------
Batch 1/64 loss: 0.21338415145874023
Batch 2/64 loss: 0.20816338062286377
Batch 3/64 loss: 0.2249976396560669
Batch 4/64 loss: 0.20868974924087524
Batch 5/64 loss: 0.21104907989501953
Batch 6/64 loss: 0.2049849033355713
Batch 7/64 loss: 0.199273943901062
Batch 8/64 loss: 0.21312814950942993
Batch 9/64 loss: 0.20808935165405273
Batch 10/64 loss: 0.21322613954544067
Batch 11/64 loss: 0.20886069536209106
Batch 12/64 loss: 0.206706702709198
Batch 13/64 loss: 0.20306450128555298
Batch 14/64 loss: 0.2080446481704712
Batch 15/64 loss: 0.19949859380722046
Batch 16/64 loss: 0.21215641498565674
Batch 17/64 loss: 0.20251798629760742
Batch 18/64 loss: 0.20278894901275635
Batch 19/64 loss: 0.21788132190704346
Batch 20/64 loss: 0.21566563844680786
Batch 21/64 loss: 0.2134544849395752
Batch 22/64 loss: 0.2047739028930664
Batch 23/64 loss: 0.20247042179107666
Batch 24/64 loss: 0.1993159055709839
Batch 25/64 loss: 0.21076440811157227
Batch 26/64 loss: 0.21229350566864014
Batch 27/64 loss: 0.21460330486297607
Batch 28/64 loss: 0.20955711603164673
Batch 29/64 loss: 0.21830511093139648
Batch 30/64 loss: 0.2027273178100586
Batch 31/64 loss: 0.211342453956604
Batch 32/64 loss: 0.20994281768798828
Batch 33/64 loss: 0.20981240272521973
Batch 34/64 loss: 0.20627212524414062
Batch 35/64 loss: 0.1971217393875122
Batch 36/64 loss: 0.21128547191619873
Batch 37/64 loss: 0.205998957157135
Batch 38/64 loss: 0.21478652954101562
Batch 39/64 loss: 0.2025049924850464
Batch 40/64 loss: 0.20280992984771729
Batch 41/64 loss: 0.21112841367721558
Batch 42/64 loss: 0.1951557993888855
Batch 43/64 loss: 0.20975029468536377
Batch 44/64 loss: 0.20530009269714355
Batch 45/64 loss: 0.20677530765533447
Batch 46/64 loss: 0.20241886377334595
Batch 47/64 loss: 0.21060967445373535
Batch 48/64 loss: 0.212272047996521
Batch 49/64 loss: 0.2116803526878357
Batch 50/64 loss: 0.21038377285003662
Batch 51/64 loss: 0.2065502405166626
Batch 52/64 loss: 0.20812058448791504
Batch 53/64 loss: 0.2089909315109253
Batch 54/64 loss: 0.2028484344482422
Batch 55/64 loss: 0.20030897855758667
Batch 56/64 loss: 0.20129048824310303
Batch 57/64 loss: 0.2128204107284546
Batch 58/64 loss: 0.21211671829223633
Batch 59/64 loss: 0.2096928358078003
Batch 60/64 loss: 0.21401256322860718
Batch 61/64 loss: 0.20372521877288818
Batch 62/64 loss: 0.2097407579421997
Batch 63/64 loss: 0.20343011617660522
Batch 64/64 loss: 0.20761197805404663
Epoch 390  Train loss: 0.2081121054350161  Val loss: 0.26922658239443276
Epoch 391
-------------------------------
Batch 1/64 loss: 0.2000502347946167
Batch 2/64 loss: 0.20048940181732178
Batch 3/64 loss: 0.20233166217803955
Batch 4/64 loss: 0.199085533618927
Batch 5/64 loss: 0.21648705005645752
Batch 6/64 loss: 0.197845458984375
Batch 7/64 loss: 0.20188862085342407
Batch 8/64 loss: 0.21162420511245728
Batch 9/64 loss: 0.20090723037719727
Batch 10/64 loss: 0.20860612392425537
Batch 11/64 loss: 0.20325583219528198
Batch 12/64 loss: 0.20229452848434448
Batch 13/64 loss: 0.209835946559906
Batch 14/64 loss: 0.21268463134765625
Batch 15/64 loss: 0.20315062999725342
Batch 16/64 loss: 0.21859443187713623
Batch 17/64 loss: 0.2006649374961853
Batch 18/64 loss: 0.20985448360443115
Batch 19/64 loss: 0.20295482873916626
Batch 20/64 loss: 0.2177419662475586
Batch 21/64 loss: 0.20177453756332397
Batch 22/64 loss: 0.2007858157157898
Batch 23/64 loss: 0.20094799995422363
Batch 24/64 loss: 0.20524930953979492
Batch 25/64 loss: 0.20310819149017334
Batch 26/64 loss: 0.21422576904296875
Batch 27/64 loss: 0.2187771201133728
Batch 28/64 loss: 0.20967882871627808
Batch 29/64 loss: 0.2194768190383911
Batch 30/64 loss: 0.20879501104354858
Batch 31/64 loss: 0.20038235187530518
Batch 32/64 loss: 0.20016753673553467
Batch 33/64 loss: 0.2035313844680786
Batch 34/64 loss: 0.2051798701286316
Batch 35/64 loss: 0.20277631282806396
Batch 36/64 loss: 0.21884292364120483
Batch 37/64 loss: 0.20221108198165894
Batch 38/64 loss: 0.20128637552261353
Batch 39/64 loss: 0.2151707410812378
Batch 40/64 loss: 0.20813590288162231
Batch 41/64 loss: 0.20578259229660034
Batch 42/64 loss: 0.20199590921401978
Batch 43/64 loss: 0.1994878649711609
Batch 44/64 loss: 0.19537150859832764
Batch 45/64 loss: 0.21125447750091553
Batch 46/64 loss: 0.19902890920639038
Batch 47/64 loss: 0.21557694673538208
Batch 48/64 loss: 0.20477032661437988
Batch 49/64 loss: 0.2204880714416504
Batch 50/64 loss: 0.2156786322593689
Batch 51/64 loss: 0.2032843828201294
Batch 52/64 loss: 0.207594633102417
Batch 53/64 loss: 0.20589888095855713
Batch 54/64 loss: 0.22164034843444824
Batch 55/64 loss: 0.21386635303497314
Batch 56/64 loss: 0.21377503871917725
Batch 57/64 loss: 0.21877121925354004
Batch 58/64 loss: 0.2084101438522339
Batch 59/64 loss: 0.20776045322418213
Batch 60/64 loss: 0.20512568950653076
Batch 61/64 loss: 0.21035873889923096
Batch 62/64 loss: 0.20752876996994019
Batch 63/64 loss: 0.21595704555511475
Batch 64/64 loss: 0.20834624767303467
Epoch 391  Train loss: 0.20747479597727458  Val loss: 0.26918143709910286
Epoch 392
-------------------------------
Batch 1/64 loss: 0.21002131700515747
Batch 2/64 loss: 0.20602232217788696
Batch 3/64 loss: 0.21116483211517334
Batch 4/64 loss: 0.20591795444488525
Batch 5/64 loss: 0.20301419496536255
Batch 6/64 loss: 0.2143670916557312
Batch 7/64 loss: 0.20748305320739746
Batch 8/64 loss: 0.2029128074645996
Batch 9/64 loss: 0.22136354446411133
Batch 10/64 loss: 0.21338379383087158
Batch 11/64 loss: 0.20522284507751465
Batch 12/64 loss: 0.21621990203857422
Batch 13/64 loss: 0.21261608600616455
Batch 14/64 loss: 0.21010732650756836
Batch 15/64 loss: 0.21389877796173096
Batch 16/64 loss: 0.20329022407531738
Batch 17/64 loss: 0.21210438013076782
Batch 18/64 loss: 0.20849239826202393
Batch 19/64 loss: 0.2088305950164795
Batch 20/64 loss: 0.20265495777130127
Batch 21/64 loss: 0.22819042205810547
Batch 22/64 loss: 0.20163458585739136
Batch 23/64 loss: 0.20917177200317383
Batch 24/64 loss: 0.20296597480773926
Batch 25/64 loss: 0.20623326301574707
Batch 26/64 loss: 0.20848941802978516
Batch 27/64 loss: 0.2177143692970276
Batch 28/64 loss: 0.20648705959320068
Batch 29/64 loss: 0.20370304584503174
Batch 30/64 loss: 0.20234036445617676
Batch 31/64 loss: 0.20850688219070435
Batch 32/64 loss: 0.2146446704864502
Batch 33/64 loss: 0.20419543981552124
Batch 34/64 loss: 0.19549918174743652
Batch 35/64 loss: 0.20218569040298462
Batch 36/64 loss: 0.21119403839111328
Batch 37/64 loss: 0.2030726671218872
Batch 38/64 loss: 0.2093045711517334
Batch 39/64 loss: 0.20431172847747803
Batch 40/64 loss: 0.20910614728927612
Batch 41/64 loss: 0.2057729959487915
Batch 42/64 loss: 0.19697558879852295
Batch 43/64 loss: 0.2074068784713745
Batch 44/64 loss: 0.2060861587524414
Batch 45/64 loss: 0.20821964740753174
Batch 46/64 loss: 0.1971137523651123
Batch 47/64 loss: 0.2112128734588623
Batch 48/64 loss: 0.1996437907218933
Batch 49/64 loss: 0.20265859365463257
Batch 50/64 loss: 0.19769668579101562
Batch 51/64 loss: 0.21572214365005493
Batch 52/64 loss: 0.22178781032562256
Batch 53/64 loss: 0.21103441715240479
Batch 54/64 loss: 0.21317684650421143
Batch 55/64 loss: 0.20364636182785034
Batch 56/64 loss: 0.20435398817062378
Batch 57/64 loss: 0.21431803703308105
Batch 58/64 loss: 0.21463555097579956
Batch 59/64 loss: 0.21491199731826782
Batch 60/64 loss: 0.20815229415893555
Batch 61/64 loss: 0.21482443809509277
Batch 62/64 loss: 0.21389174461364746
Batch 63/64 loss: 0.21163809299468994
Batch 64/64 loss: 0.20143699645996094
Epoch 392  Train loss: 0.20837644128238453  Val loss: 0.2698150021104059
Epoch 393
-------------------------------
Batch 1/64 loss: 0.21608245372772217
Batch 2/64 loss: 0.20628607273101807
Batch 3/64 loss: 0.2045607566833496
Batch 4/64 loss: 0.21222233772277832
Batch 5/64 loss: 0.20782238245010376
Batch 6/64 loss: 0.2064201831817627
Batch 7/64 loss: 0.19923114776611328
Batch 8/64 loss: 0.20456725358963013
Batch 9/64 loss: 0.19759511947631836
Batch 10/64 loss: 0.19839388132095337
Batch 11/64 loss: 0.20630693435668945
Batch 12/64 loss: 0.20508641004562378
Batch 13/64 loss: 0.21149271726608276
Batch 14/64 loss: 0.20894843339920044
Batch 15/64 loss: 0.20551365613937378
Batch 16/64 loss: 0.19761323928833008
Batch 17/64 loss: 0.20286047458648682
Batch 18/64 loss: 0.2054511308670044
Batch 19/64 loss: 0.20379680395126343
Batch 20/64 loss: 0.2219865322113037
Batch 21/64 loss: 0.2022770643234253
Batch 22/64 loss: 0.20625537633895874
Batch 23/64 loss: 0.22000885009765625
Batch 24/64 loss: 0.21219879388809204
Batch 25/64 loss: 0.21080827713012695
Batch 26/64 loss: 0.21183091402053833
Batch 27/64 loss: 0.20115768909454346
Batch 28/64 loss: 0.2039341926574707
Batch 29/64 loss: 0.20510751008987427
Batch 30/64 loss: 0.21022045612335205
Batch 31/64 loss: 0.21799564361572266
Batch 32/64 loss: 0.2125605344772339
Batch 33/64 loss: 0.209459125995636
Batch 34/64 loss: 0.20705080032348633
Batch 35/64 loss: 0.206992506980896
Batch 36/64 loss: 0.2005298137664795
Batch 37/64 loss: 0.20423322916030884
Batch 38/64 loss: 0.20524334907531738
Batch 39/64 loss: 0.20024222135543823
Batch 40/64 loss: 0.21314775943756104
Batch 41/64 loss: 0.2109299898147583
Batch 42/64 loss: 0.21248656511306763
Batch 43/64 loss: 0.21918028593063354
Batch 44/64 loss: 0.20494425296783447
Batch 45/64 loss: 0.20288211107254028
Batch 46/64 loss: 0.21024024486541748
Batch 47/64 loss: 0.2175324559211731
Batch 48/64 loss: 0.20864415168762207
Batch 49/64 loss: 0.20259428024291992
Batch 50/64 loss: 0.2084977626800537
Batch 51/64 loss: 0.2149360179901123
Batch 52/64 loss: 0.21877670288085938
Batch 53/64 loss: 0.21095043420791626
Batch 54/64 loss: 0.21230852603912354
Batch 55/64 loss: 0.2120455503463745
Batch 56/64 loss: 0.2098972201347351
Batch 57/64 loss: 0.2016206979751587
Batch 58/64 loss: 0.20014643669128418
Batch 59/64 loss: 0.20616042613983154
Batch 60/64 loss: 0.2120269536972046
Batch 61/64 loss: 0.20554155111312866
Batch 62/64 loss: 0.20246905088424683
Batch 63/64 loss: 0.19937783479690552
Batch 64/64 loss: 0.21587562561035156
Epoch 393  Train loss: 0.20783667844884535  Val loss: 0.2697921354336427
Epoch 394
-------------------------------
Batch 1/64 loss: 0.20056259632110596
Batch 2/64 loss: 0.2227860689163208
Batch 3/64 loss: 0.21159636974334717
Batch 4/64 loss: 0.20911836624145508
Batch 5/64 loss: 0.21195918321609497
Batch 6/64 loss: 0.20234709978103638
Batch 7/64 loss: 0.21441364288330078
Batch 8/64 loss: 0.20412158966064453
Batch 9/64 loss: 0.20774292945861816
Batch 10/64 loss: 0.21270036697387695
Batch 11/64 loss: 0.20713281631469727
Batch 12/64 loss: 0.20319843292236328
Batch 13/64 loss: 0.20122510194778442
Batch 14/64 loss: 0.19781482219696045
Batch 15/64 loss: 0.20327311754226685
Batch 16/64 loss: 0.20584100484848022
Batch 17/64 loss: 0.21118873357772827
Batch 18/64 loss: 0.19712960720062256
Batch 19/64 loss: 0.20886635780334473
Batch 20/64 loss: 0.20637035369873047
Batch 21/64 loss: 0.21380025148391724
Batch 22/64 loss: 0.21598899364471436
Batch 23/64 loss: 0.2083764672279358
Batch 24/64 loss: 0.20628052949905396
Batch 25/64 loss: 0.20080184936523438
Batch 26/64 loss: 0.20251739025115967
Batch 27/64 loss: 0.2109735608100891
Batch 28/64 loss: 0.21745967864990234
Batch 29/64 loss: 0.2117326855659485
Batch 30/64 loss: 0.20500999689102173
Batch 31/64 loss: 0.20038849115371704
Batch 32/64 loss: 0.21016287803649902
Batch 33/64 loss: 0.20194202661514282
Batch 34/64 loss: 0.2012627124786377
Batch 35/64 loss: 0.2035006284713745
Batch 36/64 loss: 0.20066142082214355
Batch 37/64 loss: 0.19507664442062378
Batch 38/64 loss: 0.20580655336380005
Batch 39/64 loss: 0.20026975870132446
Batch 40/64 loss: 0.2080014944076538
Batch 41/64 loss: 0.21653491258621216
Batch 42/64 loss: 0.20965003967285156
Batch 43/64 loss: 0.20204883813858032
Batch 44/64 loss: 0.20877045392990112
Batch 45/64 loss: 0.2102823257446289
Batch 46/64 loss: 0.2093544602394104
Batch 47/64 loss: 0.20626914501190186
Batch 48/64 loss: 0.21406668424606323
Batch 49/64 loss: 0.20432257652282715
Batch 50/64 loss: 0.2127305269241333
Batch 51/64 loss: 0.20853197574615479
Batch 52/64 loss: 0.20383453369140625
Batch 53/64 loss: 0.2170746922492981
Batch 54/64 loss: 0.21794790029525757
Batch 55/64 loss: 0.20455163717269897
Batch 56/64 loss: 0.21076321601867676
Batch 57/64 loss: 0.20176798105239868
Batch 58/64 loss: 0.20310115814208984
Batch 59/64 loss: 0.20628726482391357
Batch 60/64 loss: 0.21907830238342285
Batch 61/64 loss: 0.2193911075592041
Batch 62/64 loss: 0.2191462516784668
Batch 63/64 loss: 0.20868241786956787
Batch 64/64 loss: 0.2195502519607544
Epoch 394  Train loss: 0.2079726064906401  Val loss: 0.270001793030611
Epoch 395
-------------------------------
Batch 1/64 loss: 0.2086430788040161
Batch 2/64 loss: 0.20653420686721802
Batch 3/64 loss: 0.19671308994293213
Batch 4/64 loss: 0.2114940881729126
Batch 5/64 loss: 0.19918310642242432
Batch 6/64 loss: 0.20687580108642578
Batch 7/64 loss: 0.21732020378112793
Batch 8/64 loss: 0.2075839638710022
Batch 9/64 loss: 0.2033771276473999
Batch 10/64 loss: 0.2122148871421814
Batch 11/64 loss: 0.2109159231185913
Batch 12/64 loss: 0.21601855754852295
Batch 13/64 loss: 0.21054816246032715
Batch 14/64 loss: 0.20499873161315918
Batch 15/64 loss: 0.19973111152648926
Batch 16/64 loss: 0.20841163396835327
Batch 17/64 loss: 0.20240962505340576
Batch 18/64 loss: 0.2140331268310547
Batch 19/64 loss: 0.2145524024963379
Batch 20/64 loss: 0.20199072360992432
Batch 21/64 loss: 0.2117295265197754
Batch 22/64 loss: 0.218369722366333
Batch 23/64 loss: 0.2029837965965271
Batch 24/64 loss: 0.20839262008666992
Batch 25/64 loss: 0.21377122402191162
Batch 26/64 loss: 0.22230291366577148
Batch 27/64 loss: 0.20901215076446533
Batch 28/64 loss: 0.2120600938796997
Batch 29/64 loss: 0.20986419916152954
Batch 30/64 loss: 0.210060715675354
Batch 31/64 loss: 0.2108897566795349
Batch 32/64 loss: 0.20975971221923828
Batch 33/64 loss: 0.20486128330230713
Batch 34/64 loss: 0.2113417387008667
Batch 35/64 loss: 0.2136610746383667
Batch 36/64 loss: 0.19817709922790527
Batch 37/64 loss: 0.20395487546920776
Batch 38/64 loss: 0.2209855318069458
Batch 39/64 loss: 0.20432013273239136
Batch 40/64 loss: 0.20480364561080933
Batch 41/64 loss: 0.1983354687690735
Batch 42/64 loss: 0.20804989337921143
Batch 43/64 loss: 0.21205860376358032
Batch 44/64 loss: 0.21637940406799316
Batch 45/64 loss: 0.21533620357513428
Batch 46/64 loss: 0.2029637098312378
Batch 47/64 loss: 0.21685552597045898
Batch 48/64 loss: 0.20607209205627441
Batch 49/64 loss: 0.2071150541305542
Batch 50/64 loss: 0.19899976253509521
Batch 51/64 loss: 0.2075662612915039
Batch 52/64 loss: 0.21254634857177734
Batch 53/64 loss: 0.20476365089416504
Batch 54/64 loss: 0.20982861518859863
Batch 55/64 loss: 0.19736623764038086
Batch 56/64 loss: 0.19946318864822388
Batch 57/64 loss: 0.20814168453216553
Batch 58/64 loss: 0.21851098537445068
Batch 59/64 loss: 0.20676302909851074
Batch 60/64 loss: 0.22326940298080444
Batch 61/64 loss: 0.20932769775390625
Batch 62/64 loss: 0.20110952854156494
Batch 63/64 loss: 0.2017260193824768
Batch 64/64 loss: 0.207719624042511
Epoch 395  Train loss: 0.20852061884075987  Val loss: 0.26913768134985594
Epoch 396
-------------------------------
Batch 1/64 loss: 0.20345324277877808
Batch 2/64 loss: 0.1979154348373413
Batch 3/64 loss: 0.20420384407043457
Batch 4/64 loss: 0.19804245233535767
Batch 5/64 loss: 0.2007402777671814
Batch 6/64 loss: 0.2100679874420166
Batch 7/64 loss: 0.20241552591323853
Batch 8/64 loss: 0.2063876986503601
Batch 9/64 loss: 0.20877504348754883
Batch 10/64 loss: 0.2026461958885193
Batch 11/64 loss: 0.21638011932373047
Batch 12/64 loss: 0.2159956693649292
Batch 13/64 loss: 0.20539897680282593
Batch 14/64 loss: 0.21131408214569092
Batch 15/64 loss: 0.20478123426437378
Batch 16/64 loss: 0.20488345623016357
Batch 17/64 loss: 0.20934617519378662
Batch 18/64 loss: 0.20518016815185547
Batch 19/64 loss: 0.20112216472625732
Batch 20/64 loss: 0.21023595333099365
Batch 21/64 loss: 0.21119755506515503
Batch 22/64 loss: 0.201663076877594
Batch 23/64 loss: 0.20793771743774414
Batch 24/64 loss: 0.21024876832962036
Batch 25/64 loss: 0.2123848795890808
Batch 26/64 loss: 0.20451092720031738
Batch 27/64 loss: 0.20489084720611572
Batch 28/64 loss: 0.20421665906906128
Batch 29/64 loss: 0.20732879638671875
Batch 30/64 loss: 0.2097802758216858
Batch 31/64 loss: 0.20444327592849731
Batch 32/64 loss: 0.20702803134918213
Batch 33/64 loss: 0.203321635723114
Batch 34/64 loss: 0.20957183837890625
Batch 35/64 loss: 0.20706117153167725
Batch 36/64 loss: 0.2059425711631775
Batch 37/64 loss: 0.20435261726379395
Batch 38/64 loss: 0.20721375942230225
Batch 39/64 loss: 0.20755648612976074
Batch 40/64 loss: 0.21869617700576782
Batch 41/64 loss: 0.20725131034851074
Batch 42/64 loss: 0.19844722747802734
Batch 43/64 loss: 0.20714586973190308
Batch 44/64 loss: 0.19989854097366333
Batch 45/64 loss: 0.2007773518562317
Batch 46/64 loss: 0.2076793909072876
Batch 47/64 loss: 0.2042441964149475
Batch 48/64 loss: 0.20271259546279907
Batch 49/64 loss: 0.20439153909683228
Batch 50/64 loss: 0.19981497526168823
Batch 51/64 loss: 0.21992892026901245
Batch 52/64 loss: 0.21422499418258667
Batch 53/64 loss: 0.20235776901245117
Batch 54/64 loss: 0.20933425426483154
Batch 55/64 loss: 0.20781534910202026
Batch 56/64 loss: 0.2095729112625122
Batch 57/64 loss: 0.20831674337387085
Batch 58/64 loss: 0.21990835666656494
Batch 59/64 loss: 0.20840495824813843
Batch 60/64 loss: 0.21198928356170654
Batch 61/64 loss: 0.20866817235946655
Batch 62/64 loss: 0.2038317322731018
Batch 63/64 loss: 0.215232253074646
Batch 64/64 loss: 0.2007802128791809
Epoch 396  Train loss: 0.206920260775323  Val loss: 0.2684111144534501
Epoch 397
-------------------------------
Batch 1/64 loss: 0.2003418207168579
Batch 2/64 loss: 0.20232290029525757
Batch 3/64 loss: 0.20095205307006836
Batch 4/64 loss: 0.20235341787338257
Batch 5/64 loss: 0.20478206872940063
Batch 6/64 loss: 0.2065231204032898
Batch 7/64 loss: 0.20464849472045898
Batch 8/64 loss: 0.1938667893409729
Batch 9/64 loss: 0.2095123529434204
Batch 10/64 loss: 0.20987987518310547
Batch 11/64 loss: 0.20719057321548462
Batch 12/64 loss: 0.2035580277442932
Batch 13/64 loss: 0.19891995191574097
Batch 14/64 loss: 0.20706218481063843
Batch 15/64 loss: 0.20717167854309082
Batch 16/64 loss: 0.20515012741088867
Batch 17/64 loss: 0.21383142471313477
Batch 18/64 loss: 0.20720064640045166
Batch 19/64 loss: 0.19828832149505615
Batch 20/64 loss: 0.20253890752792358
Batch 21/64 loss: 0.20857280492782593
Batch 22/64 loss: 0.2058933973312378
Batch 23/64 loss: 0.21001660823822021
Batch 24/64 loss: 0.20794260501861572
Batch 25/64 loss: 0.19898974895477295
Batch 26/64 loss: 0.19426500797271729
Batch 27/64 loss: 0.20282822847366333
Batch 28/64 loss: 0.1981450319290161
Batch 29/64 loss: 0.2007044553756714
Batch 30/64 loss: 0.2083355188369751
Batch 31/64 loss: 0.19377577304840088
Batch 32/64 loss: 0.21163558959960938
Batch 33/64 loss: 0.2045954465866089
Batch 34/64 loss: 0.21425998210906982
Batch 35/64 loss: 0.19897735118865967
Batch 36/64 loss: 0.20638930797576904
Batch 37/64 loss: 0.2133868932723999
Batch 38/64 loss: 0.20644289255142212
Batch 39/64 loss: 0.20111000537872314
Batch 40/64 loss: 0.20764029026031494
Batch 41/64 loss: 0.20088577270507812
Batch 42/64 loss: 0.21258288621902466
Batch 43/64 loss: 0.21073859930038452
Batch 44/64 loss: 0.20253092050552368
Batch 45/64 loss: 0.21574175357818604
Batch 46/64 loss: 0.20368742942810059
Batch 47/64 loss: 0.20612961053848267
Batch 48/64 loss: 0.21307086944580078
Batch 49/64 loss: 0.20299965143203735
Batch 50/64 loss: 0.21490705013275146
Batch 51/64 loss: 0.20741820335388184
Batch 52/64 loss: 0.20594793558120728
Batch 53/64 loss: 0.2040339708328247
Batch 54/64 loss: 0.20259714126586914
Batch 55/64 loss: 0.20111095905303955
Batch 56/64 loss: 0.2104332447052002
Batch 57/64 loss: 0.20127475261688232
Batch 58/64 loss: 0.2147308588027954
Batch 59/64 loss: 0.2103358507156372
Batch 60/64 loss: 0.21166318655014038
Batch 61/64 loss: 0.21288633346557617
Batch 62/64 loss: 0.20633339881896973
Batch 63/64 loss: 0.20924162864685059
Batch 64/64 loss: 0.20841872692108154
Epoch 397  Train loss: 0.2057662388857673  Val loss: 0.26916611297024073
Epoch 398
-------------------------------
Batch 1/64 loss: 0.21584147214889526
Batch 2/64 loss: 0.20252633094787598
Batch 3/64 loss: 0.20264041423797607
Batch 4/64 loss: 0.20293575525283813
Batch 5/64 loss: 0.22222524881362915
Batch 6/64 loss: 0.21837669610977173
Batch 7/64 loss: 0.20375919342041016
Batch 8/64 loss: 0.20634669065475464
Batch 9/64 loss: 0.20514577627182007
Batch 10/64 loss: 0.21031510829925537
Batch 11/64 loss: 0.21307623386383057
Batch 12/64 loss: 0.2034773826599121
Batch 13/64 loss: 0.20582640171051025
Batch 14/64 loss: 0.19515705108642578
Batch 15/64 loss: 0.20437443256378174
Batch 16/64 loss: 0.1976493000984192
Batch 17/64 loss: 0.20718854665756226
Batch 18/64 loss: 0.21438920497894287
Batch 19/64 loss: 0.21446096897125244
Batch 20/64 loss: 0.20862102508544922
Batch 21/64 loss: 0.21473294496536255
Batch 22/64 loss: 0.2000725269317627
Batch 23/64 loss: 0.1956723928451538
Batch 24/64 loss: 0.21221327781677246
Batch 25/64 loss: 0.211500346660614
Batch 26/64 loss: 0.20747315883636475
Batch 27/64 loss: 0.21144342422485352
Batch 28/64 loss: 0.1985456943511963
Batch 29/64 loss: 0.2113932967185974
Batch 30/64 loss: 0.20549553632736206
Batch 31/64 loss: 0.20758897066116333
Batch 32/64 loss: 0.19617325067520142
Batch 33/64 loss: 0.1978689432144165
Batch 34/64 loss: 0.2044960856437683
Batch 35/64 loss: 0.20663982629776
Batch 36/64 loss: 0.21010786294937134
Batch 37/64 loss: 0.2074701189994812
Batch 38/64 loss: 0.20831990242004395
Batch 39/64 loss: 0.20644670724868774
Batch 40/64 loss: 0.20746368169784546
Batch 41/64 loss: 0.20936083793640137
Batch 42/64 loss: 0.20141226053237915
Batch 43/64 loss: 0.20785903930664062
Batch 44/64 loss: 0.20830368995666504
Batch 45/64 loss: 0.19821113348007202
Batch 46/64 loss: 0.20636814832687378
Batch 47/64 loss: 0.20015019178390503
Batch 48/64 loss: 0.20660150051116943
Batch 49/64 loss: 0.20531725883483887
Batch 50/64 loss: 0.2126176357269287
Batch 51/64 loss: 0.19927626848220825
Batch 52/64 loss: 0.19355571269989014
Batch 53/64 loss: 0.21457970142364502
Batch 54/64 loss: 0.20650577545166016
Batch 55/64 loss: 0.211564302444458
Batch 56/64 loss: 0.19622504711151123
Batch 57/64 loss: 0.21111172437667847
Batch 58/64 loss: 0.2106989622116089
Batch 59/64 loss: 0.21687066555023193
Batch 60/64 loss: 0.20315766334533691
Batch 61/64 loss: 0.2031610608100891
Batch 62/64 loss: 0.20606714487075806
Batch 63/64 loss: 0.2177639603614807
Batch 64/64 loss: 0.2205045223236084
Epoch 398  Train loss: 0.20686383153878007  Val loss: 0.26944603317791654
Epoch 399
-------------------------------
Batch 1/64 loss: 0.19964295625686646
Batch 2/64 loss: 0.20897817611694336
Batch 3/64 loss: 0.21277010440826416
Batch 4/64 loss: 0.1946069598197937
Batch 5/64 loss: 0.20223850011825562
Batch 6/64 loss: 0.20433813333511353
Batch 7/64 loss: 0.2048858404159546
Batch 8/64 loss: 0.2079761028289795
Batch 9/64 loss: 0.19073426723480225
Batch 10/64 loss: 0.213157057762146
Batch 11/64 loss: 0.20746272802352905
Batch 12/64 loss: 0.20612037181854248
Batch 13/64 loss: 0.20598983764648438
Batch 14/64 loss: 0.20883411169052124
Batch 15/64 loss: 0.20103299617767334
Batch 16/64 loss: 0.21602123975753784
Batch 17/64 loss: 0.20688307285308838
Batch 18/64 loss: 0.2183762788772583
Batch 19/64 loss: 0.20160555839538574
Batch 20/64 loss: 0.211389422416687
Batch 21/64 loss: 0.21233981847763062
Batch 22/64 loss: 0.20734888315200806
Batch 23/64 loss: 0.2157285213470459
Batch 24/64 loss: 0.1988300085067749
Batch 25/64 loss: 0.21468901634216309
Batch 26/64 loss: 0.20673424005508423
Batch 27/64 loss: 0.20607060194015503
Batch 28/64 loss: 0.20175111293792725
Batch 29/64 loss: 0.19547635316848755
Batch 30/64 loss: 0.20742475986480713
Batch 31/64 loss: 0.21477097272872925
Batch 32/64 loss: 0.20514315366744995
Batch 33/64 loss: 0.20647579431533813
Batch 34/64 loss: 0.1948046088218689
Batch 35/64 loss: 0.19662433862686157
Batch 36/64 loss: 0.20185959339141846
Batch 37/64 loss: 0.2091502547264099
Batch 38/64 loss: 0.1956678032875061
Batch 39/64 loss: 0.20533204078674316
Batch 40/64 loss: 0.21870076656341553
Batch 41/64 loss: 0.20639723539352417
Batch 42/64 loss: 0.2127581238746643
Batch 43/64 loss: 0.2069035768508911
Batch 44/64 loss: 0.20298200845718384
Batch 45/64 loss: 0.20674383640289307
Batch 46/64 loss: 0.21167749166488647
Batch 47/64 loss: 0.20021837949752808
Batch 48/64 loss: 0.20176106691360474
Batch 49/64 loss: 0.20092427730560303
Batch 50/64 loss: 0.20690208673477173
Batch 51/64 loss: 0.20806801319122314
Batch 52/64 loss: 0.19664466381072998
Batch 53/64 loss: 0.2115243673324585
Batch 54/64 loss: 0.20565736293792725
Batch 55/64 loss: 0.20043373107910156
Batch 56/64 loss: 0.21510684490203857
Batch 57/64 loss: 0.19662469625473022
Batch 58/64 loss: 0.20818626880645752
Batch 59/64 loss: 0.2106536626815796
Batch 60/64 loss: 0.21412992477416992
Batch 61/64 loss: 0.2113550305366516
Batch 62/64 loss: 0.1996082067489624
Batch 63/64 loss: 0.20651847124099731
Batch 64/64 loss: 0.20560413599014282
Epoch 399  Train loss: 0.2060227260870092  Val loss: 0.2689345866134486
Epoch 400
-------------------------------
Batch 1/64 loss: 0.20713704824447632
Batch 2/64 loss: 0.2027721405029297
Batch 3/64 loss: 0.2018657922744751
Batch 4/64 loss: 0.19139015674591064
Batch 5/64 loss: 0.20285189151763916
Batch 6/64 loss: 0.20196187496185303
Batch 7/64 loss: 0.20564264059066772
Batch 8/64 loss: 0.19980227947235107
Batch 9/64 loss: 0.20703935623168945
Batch 10/64 loss: 0.2077394723892212
Batch 11/64 loss: 0.20123302936553955
Batch 12/64 loss: 0.20865607261657715
Batch 13/64 loss: 0.20420968532562256
Batch 14/64 loss: 0.2047024369239807
Batch 15/64 loss: 0.21230876445770264
Batch 16/64 loss: 0.1964426040649414
Batch 17/64 loss: 0.2190508246421814
Batch 18/64 loss: 0.20393610000610352
Batch 19/64 loss: 0.20948457717895508
Batch 20/64 loss: 0.20393604040145874
Batch 21/64 loss: 0.20080900192260742
Batch 22/64 loss: 0.20883333683013916
Batch 23/64 loss: 0.20425349473953247
Batch 24/64 loss: 0.21578866243362427
Batch 25/64 loss: 0.20286023616790771
Batch 26/64 loss: 0.21444106101989746
Batch 27/64 loss: 0.2169877290725708
Batch 28/64 loss: 0.21652978658676147
Batch 29/64 loss: 0.22050172090530396
Batch 30/64 loss: 0.20408880710601807
Batch 31/64 loss: 0.2065853476524353
Batch 32/64 loss: 0.2072746753692627
Batch 33/64 loss: 0.2084646224975586
Batch 34/64 loss: 0.21029990911483765
Batch 35/64 loss: 0.2140897512435913
Batch 36/64 loss: 0.2122601866722107
Batch 37/64 loss: 0.22468626499176025
Batch 38/64 loss: 0.2103583812713623
Batch 39/64 loss: 0.21427148580551147
Batch 40/64 loss: 0.21009421348571777
Batch 41/64 loss: 0.2132784128189087
Batch 42/64 loss: 0.20820164680480957
Batch 43/64 loss: 0.20749306678771973
Batch 44/64 loss: 0.2030775547027588
Batch 45/64 loss: 0.21093392372131348
Batch 46/64 loss: 0.20664095878601074
Batch 47/64 loss: 0.1983758807182312
Batch 48/64 loss: 0.1979236602783203
Batch 49/64 loss: 0.22053056955337524
Batch 50/64 loss: 0.203863263130188
Batch 51/64 loss: 0.196264386177063
Batch 52/64 loss: 0.2063535451889038
Batch 53/64 loss: 0.2077498435974121
Batch 54/64 loss: 0.2027883529663086
Batch 55/64 loss: 0.20642775297164917
Batch 56/64 loss: 0.1992701292037964
Batch 57/64 loss: 0.2090975046157837
Batch 58/64 loss: 0.2062063217163086
Batch 59/64 loss: 0.19796431064605713
Batch 60/64 loss: 0.20120155811309814
Batch 61/64 loss: 0.19727063179016113
Batch 62/64 loss: 0.20974647998809814
Batch 63/64 loss: 0.20803576707839966
Batch 64/64 loss: 0.20759952068328857
Epoch 400  Train loss: 0.20690253528894162  Val loss: 0.2688956502376963
Epoch 401
-------------------------------
Batch 1/64 loss: 0.21772539615631104
Batch 2/64 loss: 0.2010607123374939
Batch 3/64 loss: 0.2130831480026245
Batch 4/64 loss: 0.20099741220474243
Batch 5/64 loss: 0.19908297061920166
Batch 6/64 loss: 0.200616717338562
Batch 7/64 loss: 0.22261065244674683
Batch 8/64 loss: 0.19526338577270508
Batch 9/64 loss: 0.2001183032989502
Batch 10/64 loss: 0.2103632688522339
Batch 11/64 loss: 0.20533955097198486
Batch 12/64 loss: 0.21313953399658203
Batch 13/64 loss: 0.20669567584991455
Batch 14/64 loss: 0.20704925060272217
Batch 15/64 loss: 0.20422488451004028
Batch 16/64 loss: 0.20543336868286133
Batch 17/64 loss: 0.21292346715927124
Batch 18/64 loss: 0.19765043258666992
Batch 19/64 loss: 0.21241360902786255
Batch 20/64 loss: 0.2137589454650879
Batch 21/64 loss: 0.1968936324119568
Batch 22/64 loss: 0.2129582166671753
Batch 23/64 loss: 0.20423638820648193
Batch 24/64 loss: 0.2132328748703003
Batch 25/64 loss: 0.20061194896697998
Batch 26/64 loss: 0.19730299711227417
Batch 27/64 loss: 0.2092684507369995
Batch 28/64 loss: 0.19661366939544678
Batch 29/64 loss: 0.20560866594314575
Batch 30/64 loss: 0.2116754651069641
Batch 31/64 loss: 0.2063075304031372
Batch 32/64 loss: 0.20973849296569824
Batch 33/64 loss: 0.20675086975097656
Batch 34/64 loss: 0.19838488101959229
Batch 35/64 loss: 0.22590190172195435
Batch 36/64 loss: 0.21162927150726318
Batch 37/64 loss: 0.20577359199523926
Batch 38/64 loss: 0.21157753467559814
Batch 39/64 loss: 0.21390914916992188
Batch 40/64 loss: 0.21070599555969238
Batch 41/64 loss: 0.21293067932128906
Batch 42/64 loss: 0.21098947525024414
Batch 43/64 loss: 0.2070600390434265
Batch 44/64 loss: 0.20601630210876465
Batch 45/64 loss: 0.21177655458450317
Batch 46/64 loss: 0.21050608158111572
Batch 47/64 loss: 0.20203828811645508
Batch 48/64 loss: 0.19833242893218994
Batch 49/64 loss: 0.21020996570587158
Batch 50/64 loss: 0.206051766872406
Batch 51/64 loss: 0.20537179708480835
Batch 52/64 loss: 0.20330315828323364
Batch 53/64 loss: 0.20227539539337158
Batch 54/64 loss: 0.2072235345840454
Batch 55/64 loss: 0.20810836553573608
Batch 56/64 loss: 0.2143998146057129
Batch 57/64 loss: 0.2058280110359192
Batch 58/64 loss: 0.20373576879501343
Batch 59/64 loss: 0.20087707042694092
Batch 60/64 loss: 0.20324158668518066
Batch 61/64 loss: 0.20907151699066162
Batch 62/64 loss: 0.2109541893005371
Batch 63/64 loss: 0.20303523540496826
Batch 64/64 loss: 0.20798420906066895
Epoch 401  Train loss: 0.20702678269031002  Val loss: 0.2698603030742239
Epoch 402
-------------------------------
Batch 1/64 loss: 0.20834004878997803
Batch 2/64 loss: 0.22598040103912354
Batch 3/64 loss: 0.20378774404525757
Batch 4/64 loss: 0.20822679996490479
Batch 5/64 loss: 0.20704305171966553
Batch 6/64 loss: 0.20517313480377197
Batch 7/64 loss: 0.19318056106567383
Batch 8/64 loss: 0.20197463035583496
Batch 9/64 loss: 0.21081757545471191
Batch 10/64 loss: 0.20062559843063354
Batch 11/64 loss: 0.1979656219482422
Batch 12/64 loss: 0.1981627345085144
Batch 13/64 loss: 0.21577244997024536
Batch 14/64 loss: 0.19883489608764648
Batch 15/64 loss: 0.19720613956451416
Batch 16/64 loss: 0.20601695775985718
Batch 17/64 loss: 0.21380925178527832
Batch 18/64 loss: 0.2041938304901123
Batch 19/64 loss: 0.20823806524276733
Batch 20/64 loss: 0.20929551124572754
Batch 21/64 loss: 0.20172125101089478
Batch 22/64 loss: 0.20789086818695068
Batch 23/64 loss: 0.1968691349029541
Batch 24/64 loss: 0.20005404949188232
Batch 25/64 loss: 0.20664167404174805
Batch 26/64 loss: 0.20930230617523193
Batch 27/64 loss: 0.2120746374130249
Batch 28/64 loss: 0.20510518550872803
Batch 29/64 loss: 0.21884429454803467
Batch 30/64 loss: 0.19730091094970703
Batch 31/64 loss: 0.21184319257736206
Batch 32/64 loss: 0.19510704278945923
Batch 33/64 loss: 0.1994093656539917
Batch 34/64 loss: 0.19869381189346313
Batch 35/64 loss: 0.20177757740020752
Batch 36/64 loss: 0.21224260330200195
Batch 37/64 loss: 0.200025737285614
Batch 38/64 loss: 0.2137366533279419
Batch 39/64 loss: 0.20494723320007324
Batch 40/64 loss: 0.20670586824417114
Batch 41/64 loss: 0.20563381910324097
Batch 42/64 loss: 0.2088148593902588
Batch 43/64 loss: 0.20638203620910645
Batch 44/64 loss: 0.2181132435798645
Batch 45/64 loss: 0.20542800426483154
Batch 46/64 loss: 0.20492005348205566
Batch 47/64 loss: 0.2081344723701477
Batch 48/64 loss: 0.2099146842956543
Batch 49/64 loss: 0.2114783525466919
Batch 50/64 loss: 0.2097298502922058
Batch 51/64 loss: 0.20353972911834717
Batch 52/64 loss: 0.20819401741027832
Batch 53/64 loss: 0.21166253089904785
Batch 54/64 loss: 0.20352864265441895
Batch 55/64 loss: 0.21497631072998047
Batch 56/64 loss: 0.20801806449890137
Batch 57/64 loss: 0.20069068670272827
Batch 58/64 loss: 0.1942172646522522
Batch 59/64 loss: 0.20568758249282837
Batch 60/64 loss: 0.21100175380706787
Batch 61/64 loss: 0.20982760190963745
Batch 62/64 loss: 0.21489417552947998
Batch 63/64 loss: 0.20892071723937988
Batch 64/64 loss: 0.20755648612976074
Epoch 402  Train loss: 0.2063421838423785  Val loss: 0.2700760827441396
Epoch 403
-------------------------------
Batch 1/64 loss: 0.2000102996826172
Batch 2/64 loss: 0.19597166776657104
Batch 3/64 loss: 0.2164139747619629
Batch 4/64 loss: 0.2123975157737732
Batch 5/64 loss: 0.20551210641860962
Batch 6/64 loss: 0.20690381526947021
Batch 7/64 loss: 0.20089417695999146
Batch 8/64 loss: 0.21282464265823364
Batch 9/64 loss: 0.21221613883972168
Batch 10/64 loss: 0.20525848865509033
Batch 11/64 loss: 0.2021898627281189
Batch 12/64 loss: 0.21095657348632812
Batch 13/64 loss: 0.2126513123512268
Batch 14/64 loss: 0.198769211769104
Batch 15/64 loss: 0.21149790287017822
Batch 16/64 loss: 0.20124411582946777
Batch 17/64 loss: 0.20297002792358398
Batch 18/64 loss: 0.20204496383666992
Batch 19/64 loss: 0.22095423936843872
Batch 20/64 loss: 0.2111114263534546
Batch 21/64 loss: 0.2087523341178894
Batch 22/64 loss: 0.21334272623062134
Batch 23/64 loss: 0.20222222805023193
Batch 24/64 loss: 0.20176982879638672
Batch 25/64 loss: 0.20515871047973633
Batch 26/64 loss: 0.20251089334487915
Batch 27/64 loss: 0.20210802555084229
Batch 28/64 loss: 0.2088046669960022
Batch 29/64 loss: 0.20541870594024658
Batch 30/64 loss: 0.21557092666625977
Batch 31/64 loss: 0.20820176601409912
Batch 32/64 loss: 0.19497781991958618
Batch 33/64 loss: 0.2181965708732605
Batch 34/64 loss: 0.21698403358459473
Batch 35/64 loss: 0.19861429929733276
Batch 36/64 loss: 0.2093585729598999
Batch 37/64 loss: 0.2072352170944214
Batch 38/64 loss: 0.21069639921188354
Batch 39/64 loss: 0.20825743675231934
Batch 40/64 loss: 0.20243418216705322
Batch 41/64 loss: 0.20750844478607178
Batch 42/64 loss: 0.20172512531280518
Batch 43/64 loss: 0.2097642421722412
Batch 44/64 loss: 0.20513993501663208
Batch 45/64 loss: 0.2028406262397766
Batch 46/64 loss: 0.20146912336349487
Batch 47/64 loss: 0.20272725820541382
Batch 48/64 loss: 0.1972702145576477
Batch 49/64 loss: 0.20664554834365845
Batch 50/64 loss: 0.20308619737625122
Batch 51/64 loss: 0.2098037600517273
Batch 52/64 loss: 0.21700197458267212
Batch 53/64 loss: 0.2003435492515564
Batch 54/64 loss: 0.19753867387771606
Batch 55/64 loss: 0.20734721422195435
Batch 56/64 loss: 0.21093404293060303
Batch 57/64 loss: 0.21205413341522217
Batch 58/64 loss: 0.20489448308944702
Batch 59/64 loss: 0.19405901432037354
Batch 60/64 loss: 0.20723450183868408
Batch 61/64 loss: 0.19650346040725708
Batch 62/64 loss: 0.20546692609786987
Batch 63/64 loss: 0.21269583702087402
Batch 64/64 loss: 0.19848203659057617
Epoch 403  Train loss: 0.20621684111800848  Val loss: 0.26861857773921743
Epoch 404
-------------------------------
Batch 1/64 loss: 0.2030315399169922
Batch 2/64 loss: 0.2052748203277588
Batch 3/64 loss: 0.19522899389266968
Batch 4/64 loss: 0.20334476232528687
Batch 5/64 loss: 0.19680297374725342
Batch 6/64 loss: 0.19916892051696777
Batch 7/64 loss: 0.20522910356521606
Batch 8/64 loss: 0.2109782099723816
Batch 9/64 loss: 0.19720739126205444
Batch 10/64 loss: 0.20435386896133423
Batch 11/64 loss: 0.22963714599609375
Batch 12/64 loss: 0.21430319547653198
Batch 13/64 loss: 0.2109534740447998
Batch 14/64 loss: 0.20676791667938232
Batch 15/64 loss: 0.20765376091003418
Batch 16/64 loss: 0.19812381267547607
Batch 17/64 loss: 0.20381546020507812
Batch 18/64 loss: 0.20857751369476318
Batch 19/64 loss: 0.21242421865463257
Batch 20/64 loss: 0.2027685046195984
Batch 21/64 loss: 0.20423203706741333
Batch 22/64 loss: 0.20872557163238525
Batch 23/64 loss: 0.21278882026672363
Batch 24/64 loss: 0.20424991846084595
Batch 25/64 loss: 0.20418864488601685
Batch 26/64 loss: 0.20478272438049316
Batch 27/64 loss: 0.20014548301696777
Batch 28/64 loss: 0.20352691411972046
Batch 29/64 loss: 0.2031393051147461
Batch 30/64 loss: 0.20903432369232178
Batch 31/64 loss: 0.20294171571731567
Batch 32/64 loss: 0.20638883113861084
Batch 33/64 loss: 0.21379685401916504
Batch 34/64 loss: 0.20240288972854614
Batch 35/64 loss: 0.19355809688568115
Batch 36/64 loss: 0.19765275716781616
Batch 37/64 loss: 0.21920472383499146
Batch 38/64 loss: 0.20436811447143555
Batch 39/64 loss: 0.20193153619766235
Batch 40/64 loss: 0.20139002799987793
Batch 41/64 loss: 0.1979021430015564
Batch 42/64 loss: 0.21100366115570068
Batch 43/64 loss: 0.20546066761016846
Batch 44/64 loss: 0.19772207736968994
Batch 45/64 loss: 0.20743322372436523
Batch 46/64 loss: 0.20438063144683838
Batch 47/64 loss: 0.19819313287734985
Batch 48/64 loss: 0.20100289583206177
Batch 49/64 loss: 0.21388471126556396
Batch 50/64 loss: 0.20383524894714355
Batch 51/64 loss: 0.2128819227218628
Batch 52/64 loss: 0.21271604299545288
Batch 53/64 loss: 0.21042972803115845
Batch 54/64 loss: 0.19667983055114746
Batch 55/64 loss: 0.2033289670944214
Batch 56/64 loss: 0.21775418519973755
Batch 57/64 loss: 0.2073441743850708
Batch 58/64 loss: 0.2042805552482605
Batch 59/64 loss: 0.20828098058700562
Batch 60/64 loss: 0.20393246412277222
Batch 61/64 loss: 0.21265363693237305
Batch 62/64 loss: 0.21140319108963013
Batch 63/64 loss: 0.20454484224319458
Batch 64/64 loss: 0.20442426204681396
Epoch 404  Train loss: 0.20571705079546163  Val loss: 0.27021755139852305
Epoch 405
-------------------------------
Batch 1/64 loss: 0.20684224367141724
Batch 2/64 loss: 0.20600086450576782
Batch 3/64 loss: 0.2038804292678833
Batch 4/64 loss: 0.20212489366531372
Batch 5/64 loss: 0.2105458378791809
Batch 6/64 loss: 0.2007218599319458
Batch 7/64 loss: 0.20336008071899414
Batch 8/64 loss: 0.20143431425094604
Batch 9/64 loss: 0.21112829446792603
Batch 10/64 loss: 0.19880622625350952
Batch 11/64 loss: 0.20709306001663208
Batch 12/64 loss: 0.21364891529083252
Batch 13/64 loss: 0.19889837503433228
Batch 14/64 loss: 0.20235472917556763
Batch 15/64 loss: 0.2065984606742859
Batch 16/64 loss: 0.20621728897094727
Batch 17/64 loss: 0.20362603664398193
Batch 18/64 loss: 0.2056390643119812
Batch 19/64 loss: 0.20218414068222046
Batch 20/64 loss: 0.2124401330947876
Batch 21/64 loss: 0.20177650451660156
Batch 22/64 loss: 0.1983623504638672
Batch 23/64 loss: 0.20830190181732178
Batch 24/64 loss: 0.20303285121917725
Batch 25/64 loss: 0.20662450790405273
Batch 26/64 loss: 0.22155314683914185
Batch 27/64 loss: 0.20314055681228638
Batch 28/64 loss: 0.20126211643218994
Batch 29/64 loss: 0.20868921279907227
Batch 30/64 loss: 0.20001763105392456
Batch 31/64 loss: 0.21123117208480835
Batch 32/64 loss: 0.21465468406677246
Batch 33/64 loss: 0.20359379053115845
Batch 34/64 loss: 0.1944293975830078
Batch 35/64 loss: 0.20306295156478882
Batch 36/64 loss: 0.20587986707687378
Batch 37/64 loss: 0.2201513648033142
Batch 38/64 loss: 0.21286523342132568
Batch 39/64 loss: 0.19935673475265503
Batch 40/64 loss: 0.20367783308029175
Batch 41/64 loss: 0.21153050661087036
Batch 42/64 loss: 0.2024354338645935
Batch 43/64 loss: 0.19961678981781006
Batch 44/64 loss: 0.19855475425720215
Batch 45/64 loss: 0.204609215259552
Batch 46/64 loss: 0.19775426387786865
Batch 47/64 loss: 0.20816856622695923
Batch 48/64 loss: 0.20747601985931396
Batch 49/64 loss: 0.20711243152618408
Batch 50/64 loss: 0.20622366666793823
Batch 51/64 loss: 0.21325308084487915
Batch 52/64 loss: 0.20650756359100342
Batch 53/64 loss: 0.2066020965576172
Batch 54/64 loss: 0.2016330361366272
Batch 55/64 loss: 0.2075856328010559
Batch 56/64 loss: 0.2122088074684143
Batch 57/64 loss: 0.20342105627059937
Batch 58/64 loss: 0.19916701316833496
Batch 59/64 loss: 0.21527528762817383
Batch 60/64 loss: 0.19968336820602417
Batch 61/64 loss: 0.222540020942688
Batch 62/64 loss: 0.20379871129989624
Batch 63/64 loss: 0.20719873905181885
Batch 64/64 loss: 0.20263320207595825
Epoch 405  Train loss: 0.20579670620899573  Val loss: 0.2690443312589246
Epoch 406
-------------------------------
Batch 1/64 loss: 0.21760320663452148
Batch 2/64 loss: 0.20557641983032227
Batch 3/64 loss: 0.20626938343048096
Batch 4/64 loss: 0.20491647720336914
Batch 5/64 loss: 0.2062927484512329
Batch 6/64 loss: 0.20555627346038818
Batch 7/64 loss: 0.20338821411132812
Batch 8/64 loss: 0.20834505558013916
Batch 9/64 loss: 0.1996856927871704
Batch 10/64 loss: 0.21228277683258057
Batch 11/64 loss: 0.19369953870773315
Batch 12/64 loss: 0.20971298217773438
Batch 13/64 loss: 0.20370018482208252
Batch 14/64 loss: 0.19963932037353516
Batch 15/64 loss: 0.2138100266456604
Batch 16/64 loss: 0.194024920463562
Batch 17/64 loss: 0.2029135823249817
Batch 18/64 loss: 0.21296405792236328
Batch 19/64 loss: 0.1990397572517395
Batch 20/64 loss: 0.1993080973625183
Batch 21/64 loss: 0.20367544889450073
Batch 22/64 loss: 0.20845472812652588
Batch 23/64 loss: 0.20275473594665527
Batch 24/64 loss: 0.2023112177848816
Batch 25/64 loss: 0.21149557828903198
Batch 26/64 loss: 0.20738667249679565
Batch 27/64 loss: 0.2085755467414856
Batch 28/64 loss: 0.20090138912200928
Batch 29/64 loss: 0.20052063465118408
Batch 30/64 loss: 0.19568848609924316
Batch 31/64 loss: 0.214544415473938
Batch 32/64 loss: 0.2166527509689331
Batch 33/64 loss: 0.20632898807525635
Batch 34/64 loss: 0.21245920658111572
Batch 35/64 loss: 0.21186381578445435
Batch 36/64 loss: 0.20435720682144165
Batch 37/64 loss: 0.2091655731201172
Batch 38/64 loss: 0.20238620042800903
Batch 39/64 loss: 0.20715218782424927
Batch 40/64 loss: 0.21143996715545654
Batch 41/64 loss: 0.19326269626617432
Batch 42/64 loss: 0.2063673734664917
Batch 43/64 loss: 0.205224871635437
Batch 44/64 loss: 0.20675551891326904
Batch 45/64 loss: 0.20266211032867432
Batch 46/64 loss: 0.21705502271652222
Batch 47/64 loss: 0.1991141438484192
Batch 48/64 loss: 0.20809614658355713
Batch 49/64 loss: 0.20633304119110107
Batch 50/64 loss: 0.20245683193206787
Batch 51/64 loss: 0.20245331525802612
Batch 52/64 loss: 0.2155318260192871
Batch 53/64 loss: 0.2120230793952942
Batch 54/64 loss: 0.19837015867233276
Batch 55/64 loss: 0.20336133241653442
Batch 56/64 loss: 0.20935827493667603
Batch 57/64 loss: 0.20355230569839478
Batch 58/64 loss: 0.20412039756774902
Batch 59/64 loss: 0.20154935121536255
Batch 60/64 loss: 0.21196043491363525
Batch 61/64 loss: 0.20972973108291626
Batch 62/64 loss: 0.2080898880958557
Batch 63/64 loss: 0.21350979804992676
Batch 64/64 loss: 0.20605498552322388
Epoch 406  Train loss: 0.2059972134290957  Val loss: 0.2688411027705137
Epoch 407
-------------------------------
Batch 1/64 loss: 0.20754027366638184
Batch 2/64 loss: 0.20076429843902588
Batch 3/64 loss: 0.19652432203292847
Batch 4/64 loss: 0.20712685585021973
Batch 5/64 loss: 0.20312833786010742
Batch 6/64 loss: 0.20972752571105957
Batch 7/64 loss: 0.2083503007888794
Batch 8/64 loss: 0.19979077577590942
Batch 9/64 loss: 0.19958221912384033
Batch 10/64 loss: 0.20878612995147705
Batch 11/64 loss: 0.21158242225646973
Batch 12/64 loss: 0.20750635862350464
Batch 13/64 loss: 0.207081139087677
Batch 14/64 loss: 0.21244579553604126
Batch 15/64 loss: 0.20380884408950806
Batch 16/64 loss: 0.20792627334594727
Batch 17/64 loss: 0.2040722370147705
Batch 18/64 loss: 0.20714497566223145
Batch 19/64 loss: 0.20095229148864746
Batch 20/64 loss: 0.20564544200897217
Batch 21/64 loss: 0.20287805795669556
Batch 22/64 loss: 0.2082100510597229
Batch 23/64 loss: 0.2052595615386963
Batch 24/64 loss: 0.2066199779510498
Batch 25/64 loss: 0.21272355318069458
Batch 26/64 loss: 0.1959947943687439
Batch 27/64 loss: 0.21318161487579346
Batch 28/64 loss: 0.2143130898475647
Batch 29/64 loss: 0.20806491374969482
Batch 30/64 loss: 0.21575742959976196
Batch 31/64 loss: 0.21291017532348633
Batch 32/64 loss: 0.20587408542633057
Batch 33/64 loss: 0.21256375312805176
Batch 34/64 loss: 0.20229017734527588
Batch 35/64 loss: 0.2071598768234253
Batch 36/64 loss: 0.2083694338798523
Batch 37/64 loss: 0.20679330825805664
Batch 38/64 loss: 0.20939195156097412
Batch 39/64 loss: 0.20930325984954834
Batch 40/64 loss: 0.20794016122817993
Batch 41/64 loss: 0.20241105556488037
Batch 42/64 loss: 0.2090071439743042
Batch 43/64 loss: 0.19840312004089355
Batch 44/64 loss: 0.20264816284179688
Batch 45/64 loss: 0.20507919788360596
Batch 46/64 loss: 0.2020207643508911
Batch 47/64 loss: 0.21034765243530273
Batch 48/64 loss: 0.20590198040008545
Batch 49/64 loss: 0.20074808597564697
Batch 50/64 loss: 0.20718598365783691
Batch 51/64 loss: 0.20593130588531494
Batch 52/64 loss: 0.2063579559326172
Batch 53/64 loss: 0.20456814765930176
Batch 54/64 loss: 0.20997190475463867
Batch 55/64 loss: 0.20819240808486938
Batch 56/64 loss: 0.21185541152954102
Batch 57/64 loss: 0.2093667984008789
Batch 58/64 loss: 0.20668989419937134
Batch 59/64 loss: 0.2080014944076538
Batch 60/64 loss: 0.21098411083221436
Batch 61/64 loss: 0.21604537963867188
Batch 62/64 loss: 0.2057499885559082
Batch 63/64 loss: 0.21050333976745605
Batch 64/64 loss: 0.20876365900039673
Epoch 407  Train loss: 0.20689615805943806  Val loss: 0.2703899964434175
Epoch 408
-------------------------------
Batch 1/64 loss: 0.20843565464019775
Batch 2/64 loss: 0.2200140357017517
Batch 3/64 loss: 0.20816123485565186
Batch 4/64 loss: 0.2024170160293579
Batch 5/64 loss: 0.21220433712005615
Batch 6/64 loss: 0.21307897567749023
Batch 7/64 loss: 0.19728463888168335
Batch 8/64 loss: 0.2081940770149231
Batch 9/64 loss: 0.2086174488067627
Batch 10/64 loss: 0.2028980255126953
Batch 11/64 loss: 0.20183348655700684
Batch 12/64 loss: 0.19960856437683105
Batch 13/64 loss: 0.2001345157623291
Batch 14/64 loss: 0.20881879329681396
Batch 15/64 loss: 0.21247804164886475
Batch 16/64 loss: 0.19876903295516968
Batch 17/64 loss: 0.20457983016967773
Batch 18/64 loss: 0.2067556381225586
Batch 19/64 loss: 0.20332568883895874
Batch 20/64 loss: 0.20896631479263306
Batch 21/64 loss: 0.20621788501739502
Batch 22/64 loss: 0.19694089889526367
Batch 23/64 loss: 0.19911819696426392
Batch 24/64 loss: 0.21087110042572021
Batch 25/64 loss: 0.2027909755706787
Batch 26/64 loss: 0.20015889406204224
Batch 27/64 loss: 0.19879847764968872
Batch 28/64 loss: 0.20252597332000732
Batch 29/64 loss: 0.20603615045547485
Batch 30/64 loss: 0.20100677013397217
Batch 31/64 loss: 0.21663236618041992
Batch 32/64 loss: 0.20346665382385254
Batch 33/64 loss: 0.19511640071868896
Batch 34/64 loss: 0.20552408695220947
Batch 35/64 loss: 0.19800841808319092
Batch 36/64 loss: 0.20244622230529785
Batch 37/64 loss: 0.19689983129501343
Batch 38/64 loss: 0.2047557830810547
Batch 39/64 loss: 0.1988268494606018
Batch 40/64 loss: 0.21849161386489868
Batch 41/64 loss: 0.20580130815505981
Batch 42/64 loss: 0.2136499285697937
Batch 43/64 loss: 0.2087332010269165
Batch 44/64 loss: 0.2214505672454834
Batch 45/64 loss: 0.19892871379852295
Batch 46/64 loss: 0.20239931344985962
Batch 47/64 loss: 0.20245474576950073
Batch 48/64 loss: 0.20396852493286133
Batch 49/64 loss: 0.2094862461090088
Batch 50/64 loss: 0.2053380012512207
Batch 51/64 loss: 0.2243424654006958
Batch 52/64 loss: 0.21014618873596191
Batch 53/64 loss: 0.2197551727294922
Batch 54/64 loss: 0.2112579345703125
Batch 55/64 loss: 0.21922904253005981
Batch 56/64 loss: 0.2149754762649536
Batch 57/64 loss: 0.21025580167770386
Batch 58/64 loss: 0.20635956525802612
Batch 59/64 loss: 0.20546793937683105
Batch 60/64 loss: 0.20908582210540771
Batch 61/64 loss: 0.20272910594940186
Batch 62/64 loss: 0.22101998329162598
Batch 63/64 loss: 0.20041215419769287
Batch 64/64 loss: 0.21432161331176758
Epoch 408  Train loss: 0.20673250684551164  Val loss: 0.26942676490115136
Epoch 409
-------------------------------
Batch 1/64 loss: 0.2111918330192566
Batch 2/64 loss: 0.2011866569519043
Batch 3/64 loss: 0.20463788509368896
Batch 4/64 loss: 0.19447380304336548
Batch 5/64 loss: 0.21319741010665894
Batch 6/64 loss: 0.20334696769714355
Batch 7/64 loss: 0.1964145302772522
Batch 8/64 loss: 0.20939350128173828
Batch 9/64 loss: 0.21210235357284546
Batch 10/64 loss: 0.20075923204421997
Batch 11/64 loss: 0.20397770404815674
Batch 12/64 loss: 0.2001330852508545
Batch 13/64 loss: 0.21001219749450684
Batch 14/64 loss: 0.21901941299438477
Batch 15/64 loss: 0.2044721245765686
Batch 16/64 loss: 0.1960776448249817
Batch 17/64 loss: 0.20434832572937012
Batch 18/64 loss: 0.2054939866065979
Batch 19/64 loss: 0.21341699361801147
Batch 20/64 loss: 0.19892889261245728
Batch 21/64 loss: 0.20791077613830566
Batch 22/64 loss: 0.19911932945251465
Batch 23/64 loss: 0.19002634286880493
Batch 24/64 loss: 0.2116236686706543
Batch 25/64 loss: 0.2136034369468689
Batch 26/64 loss: 0.20480841398239136
Batch 27/64 loss: 0.2043370008468628
Batch 28/64 loss: 0.21383392810821533
Batch 29/64 loss: 0.20136654376983643
Batch 30/64 loss: 0.20623779296875
Batch 31/64 loss: 0.2134413719177246
Batch 32/64 loss: 0.20551085472106934
Batch 33/64 loss: 0.19861364364624023
Batch 34/64 loss: 0.20736169815063477
Batch 35/64 loss: 0.2003711462020874
Batch 36/64 loss: 0.20426702499389648
Batch 37/64 loss: 0.197973370552063
Batch 38/64 loss: 0.19504129886627197
Batch 39/64 loss: 0.20098280906677246
Batch 40/64 loss: 0.20563358068466187
Batch 41/64 loss: 0.1979549527168274
Batch 42/64 loss: 0.20744800567626953
Batch 43/64 loss: 0.2134513258934021
Batch 44/64 loss: 0.20542550086975098
Batch 45/64 loss: 0.19718897342681885
Batch 46/64 loss: 0.22162485122680664
Batch 47/64 loss: 0.1947069764137268
Batch 48/64 loss: 0.2051609754562378
Batch 49/64 loss: 0.20012587308883667
Batch 50/64 loss: 0.2073425054550171
Batch 51/64 loss: 0.2061152458190918
Batch 52/64 loss: 0.19845646619796753
Batch 53/64 loss: 0.2062305212020874
Batch 54/64 loss: 0.20796096324920654
Batch 55/64 loss: 0.20538723468780518
Batch 56/64 loss: 0.19849276542663574
Batch 57/64 loss: 0.20576149225234985
Batch 58/64 loss: 0.21002960205078125
Batch 59/64 loss: 0.21315181255340576
Batch 60/64 loss: 0.2046489119529724
Batch 61/64 loss: 0.20747888088226318
Batch 62/64 loss: 0.20844119787216187
Batch 63/64 loss: 0.20800083875656128
Batch 64/64 loss: 0.2259073257446289
Epoch 409  Train loss: 0.20524964613073013  Val loss: 0.2691371528963043
Epoch 410
-------------------------------
Batch 1/64 loss: 0.19593852758407593
Batch 2/64 loss: 0.20081138610839844
Batch 3/64 loss: 0.20698165893554688
Batch 4/64 loss: 0.2032374143600464
Batch 5/64 loss: 0.198327898979187
Batch 6/64 loss: 0.20026564598083496
Batch 7/64 loss: 0.20046091079711914
Batch 8/64 loss: 0.21364831924438477
Batch 9/64 loss: 0.20075666904449463
Batch 10/64 loss: 0.20983409881591797
Batch 11/64 loss: 0.19823896884918213
Batch 12/64 loss: 0.2102653980255127
Batch 13/64 loss: 0.20774316787719727
Batch 14/64 loss: 0.2175983190536499
Batch 15/64 loss: 0.19934505224227905
Batch 16/64 loss: 0.2047836184501648
Batch 17/64 loss: 0.21037518978118896
Batch 18/64 loss: 0.2019389271736145
Batch 19/64 loss: 0.195442795753479
Batch 20/64 loss: 0.20028501749038696
Batch 21/64 loss: 0.19922423362731934
Batch 22/64 loss: 0.20133137702941895
Batch 23/64 loss: 0.20356154441833496
Batch 24/64 loss: 0.20774710178375244
Batch 25/64 loss: 0.2074122428894043
Batch 26/64 loss: 0.20898258686065674
Batch 27/64 loss: 0.2082187533378601
Batch 28/64 loss: 0.2015504240989685
Batch 29/64 loss: 0.20586419105529785
Batch 30/64 loss: 0.21170282363891602
Batch 31/64 loss: 0.2033938765525818
Batch 32/64 loss: 0.19840645790100098
Batch 33/64 loss: 0.2017834186553955
Batch 34/64 loss: 0.20794916152954102
Batch 35/64 loss: 0.19627660512924194
Batch 36/64 loss: 0.20453280210494995
Batch 37/64 loss: 0.19897425174713135
Batch 38/64 loss: 0.2106029987335205
Batch 39/64 loss: 0.20586919784545898
Batch 40/64 loss: 0.20824158191680908
Batch 41/64 loss: 0.2070523500442505
Batch 42/64 loss: 0.2109004259109497
Batch 43/64 loss: 0.20950692892074585
Batch 44/64 loss: 0.2089025378227234
Batch 45/64 loss: 0.20155513286590576
Batch 46/64 loss: 0.21256566047668457
Batch 47/64 loss: 0.20313525199890137
Batch 48/64 loss: 0.2008395791053772
Batch 49/64 loss: 0.21264147758483887
Batch 50/64 loss: 0.2090398669242859
Batch 51/64 loss: 0.21224892139434814
Batch 52/64 loss: 0.20963835716247559
Batch 53/64 loss: 0.19779479503631592
Batch 54/64 loss: 0.20035672187805176
Batch 55/64 loss: 0.21180462837219238
Batch 56/64 loss: 0.21590054035186768
Batch 57/64 loss: 0.19918227195739746
Batch 58/64 loss: 0.20162612199783325
Batch 59/64 loss: 0.20142900943756104
Batch 60/64 loss: 0.20169270038604736
Batch 61/64 loss: 0.20885026454925537
Batch 62/64 loss: 0.20701485872268677
Batch 63/64 loss: 0.21000146865844727
Batch 64/64 loss: 0.20569109916687012
Epoch 410  Train loss: 0.20511141664841595  Val loss: 0.27076878109338764
Epoch 411
-------------------------------
Batch 1/64 loss: 0.208304762840271
Batch 2/64 loss: 0.19539767503738403
Batch 3/64 loss: 0.19872045516967773
Batch 4/64 loss: 0.20431578159332275
Batch 5/64 loss: 0.19870918989181519
Batch 6/64 loss: 0.21266138553619385
Batch 7/64 loss: 0.19961988925933838
Batch 8/64 loss: 0.194053053855896
Batch 9/64 loss: 0.20269477367401123
Batch 10/64 loss: 0.200666606426239
Batch 11/64 loss: 0.20096170902252197
Batch 12/64 loss: 0.20175039768218994
Batch 13/64 loss: 0.20205652713775635
Batch 14/64 loss: 0.2149808406829834
Batch 15/64 loss: 0.20547902584075928
Batch 16/64 loss: 0.20614618062973022
Batch 17/64 loss: 0.21393942832946777
Batch 18/64 loss: 0.2033451795578003
Batch 19/64 loss: 0.20559316873550415
Batch 20/64 loss: 0.20632213354110718
Batch 21/64 loss: 0.20559823513031006
Batch 22/64 loss: 0.21139109134674072
Batch 23/64 loss: 0.2017683982849121
Batch 24/64 loss: 0.20422148704528809
Batch 25/64 loss: 0.2078796625137329
Batch 26/64 loss: 0.20050907135009766
Batch 27/64 loss: 0.20165252685546875
Batch 28/64 loss: 0.20384418964385986
Batch 29/64 loss: 0.20991814136505127
Batch 30/64 loss: 0.2017805576324463
Batch 31/64 loss: 0.20872998237609863
Batch 32/64 loss: 0.2017076015472412
Batch 33/64 loss: 0.19557178020477295
Batch 34/64 loss: 0.21110022068023682
Batch 35/64 loss: 0.2025941014289856
Batch 36/64 loss: 0.20459699630737305
Batch 37/64 loss: 0.21026957035064697
Batch 38/64 loss: 0.209894597530365
Batch 39/64 loss: 0.21487706899642944
Batch 40/64 loss: 0.20520764589309692
Batch 41/64 loss: 0.20117896795272827
Batch 42/64 loss: 0.21177327632904053
Batch 43/64 loss: 0.2058345079421997
Batch 44/64 loss: 0.2035731077194214
Batch 45/64 loss: 0.22407859563827515
Batch 46/64 loss: 0.2017202377319336
Batch 47/64 loss: 0.2012750506401062
Batch 48/64 loss: 0.20358270406723022
Batch 49/64 loss: 0.1933654546737671
Batch 50/64 loss: 0.20297563076019287
Batch 51/64 loss: 0.2041689157485962
Batch 52/64 loss: 0.2240762710571289
Batch 53/64 loss: 0.2010917067527771
Batch 54/64 loss: 0.20748049020767212
Batch 55/64 loss: 0.20192664861679077
Batch 56/64 loss: 0.20499199628829956
Batch 57/64 loss: 0.20388299226760864
Batch 58/64 loss: 0.21129769086837769
Batch 59/64 loss: 0.19688892364501953
Batch 60/64 loss: 0.20787584781646729
Batch 61/64 loss: 0.20532286167144775
Batch 62/64 loss: 0.2017500400543213
Batch 63/64 loss: 0.20443493127822876
Batch 64/64 loss: 0.205020010471344
Epoch 411  Train loss: 0.20497479134914923  Val loss: 0.26916339573581605
Epoch 412
-------------------------------
Batch 1/64 loss: 0.19773060083389282
Batch 2/64 loss: 0.20356225967407227
Batch 3/64 loss: 0.20432090759277344
Batch 4/64 loss: 0.20325660705566406
Batch 5/64 loss: 0.20309823751449585
Batch 6/64 loss: 0.20580923557281494
Batch 7/64 loss: 0.20508050918579102
Batch 8/64 loss: 0.1955849528312683
Batch 9/64 loss: 0.20064842700958252
Batch 10/64 loss: 0.21494972705841064
Batch 11/64 loss: 0.213431715965271
Batch 12/64 loss: 0.20122480392456055
Batch 13/64 loss: 0.1998063325881958
Batch 14/64 loss: 0.2121037244796753
Batch 15/64 loss: 0.1992928385734558
Batch 16/64 loss: 0.209300696849823
Batch 17/64 loss: 0.19779133796691895
Batch 18/64 loss: 0.2170735001564026
Batch 19/64 loss: 0.2104283571243286
Batch 20/64 loss: 0.20414990186691284
Batch 21/64 loss: 0.21251583099365234
Batch 22/64 loss: 0.20441633462905884
Batch 23/64 loss: 0.20775431394577026
Batch 24/64 loss: 0.21367359161376953
Batch 25/64 loss: 0.20274686813354492
Batch 26/64 loss: 0.20096343755722046
Batch 27/64 loss: 0.21196353435516357
Batch 28/64 loss: 0.20605671405792236
Batch 29/64 loss: 0.1970565915107727
Batch 30/64 loss: 0.20385634899139404
Batch 31/64 loss: 0.2001742720603943
Batch 32/64 loss: 0.20648324489593506
Batch 33/64 loss: 0.20749425888061523
Batch 34/64 loss: 0.20260965824127197
Batch 35/64 loss: 0.2077183723449707
Batch 36/64 loss: 0.20900285243988037
Batch 37/64 loss: 0.2079024314880371
Batch 38/64 loss: 0.20003682374954224
Batch 39/64 loss: 0.19834548234939575
Batch 40/64 loss: 0.2004116177558899
Batch 41/64 loss: 0.18841570615768433
Batch 42/64 loss: 0.20187830924987793
Batch 43/64 loss: 0.1962795853614807
Batch 44/64 loss: 0.2022877335548401
Batch 45/64 loss: 0.1971636414527893
Batch 46/64 loss: 0.20410704612731934
Batch 47/64 loss: 0.20064783096313477
Batch 48/64 loss: 0.21444392204284668
Batch 49/64 loss: 0.19868016242980957
Batch 50/64 loss: 0.202644944190979
Batch 51/64 loss: 0.20754992961883545
Batch 52/64 loss: 0.1976831555366516
Batch 53/64 loss: 0.20205283164978027
Batch 54/64 loss: 0.2018687129020691
Batch 55/64 loss: 0.204126238822937
Batch 56/64 loss: 0.2037171721458435
Batch 57/64 loss: 0.2079528570175171
Batch 58/64 loss: 0.1992403268814087
Batch 59/64 loss: 0.20206791162490845
Batch 60/64 loss: 0.21156376600265503
Batch 61/64 loss: 0.2119767665863037
Batch 62/64 loss: 0.20956414937973022
Batch 63/64 loss: 0.2044968605041504
Batch 64/64 loss: 0.20706337690353394
Epoch 412  Train loss: 0.20432210739921122  Val loss: 0.26933858341367795
Epoch 413
-------------------------------
Batch 1/64 loss: 0.20070940256118774
Batch 2/64 loss: 0.20725637674331665
Batch 3/64 loss: 0.20949727296829224
Batch 4/64 loss: 0.19553637504577637
Batch 5/64 loss: 0.20483696460723877
Batch 6/64 loss: 0.20612478256225586
Batch 7/64 loss: 0.20637869834899902
Batch 8/64 loss: 0.19903963804244995
Batch 9/64 loss: 0.21865743398666382
Batch 10/64 loss: 0.20424270629882812
Batch 11/64 loss: 0.19676446914672852
Batch 12/64 loss: 0.20394128561019897
Batch 13/64 loss: 0.2130107879638672
Batch 14/64 loss: 0.21539652347564697
Batch 15/64 loss: 0.19938230514526367
Batch 16/64 loss: 0.20319288969039917
Batch 17/64 loss: 0.20400941371917725
Batch 18/64 loss: 0.19470500946044922
Batch 19/64 loss: 0.19906693696975708
Batch 20/64 loss: 0.19947010278701782
Batch 21/64 loss: 0.20590752363204956
Batch 22/64 loss: 0.1983562707901001
Batch 23/64 loss: 0.20353710651397705
Batch 24/64 loss: 0.2066946029663086
Batch 25/64 loss: 0.20562946796417236
Batch 26/64 loss: 0.20719224214553833
Batch 27/64 loss: 0.2086787223815918
Batch 28/64 loss: 0.2002134919166565
Batch 29/64 loss: 0.1976550817489624
Batch 30/64 loss: 0.1922021508216858
Batch 31/64 loss: 0.20786333084106445
Batch 32/64 loss: 0.20263832807540894
Batch 33/64 loss: 0.21207600831985474
Batch 34/64 loss: 0.21682727336883545
Batch 35/64 loss: 0.2163097858428955
Batch 36/64 loss: 0.2021782398223877
Batch 37/64 loss: 0.2140895128250122
Batch 38/64 loss: 0.1997891664505005
Batch 39/64 loss: 0.20940172672271729
Batch 40/64 loss: 0.20481497049331665
Batch 41/64 loss: 0.19635885953903198
Batch 42/64 loss: 0.20316779613494873
Batch 43/64 loss: 0.20335686206817627
Batch 44/64 loss: 0.20939743518829346
Batch 45/64 loss: 0.20214545726776123
Batch 46/64 loss: 0.20935344696044922
Batch 47/64 loss: 0.1980481743812561
Batch 48/64 loss: 0.20832663774490356
Batch 49/64 loss: 0.20658230781555176
Batch 50/64 loss: 0.20038801431655884
Batch 51/64 loss: 0.20999956130981445
Batch 52/64 loss: 0.21287453174591064
Batch 53/64 loss: 0.20929062366485596
Batch 54/64 loss: 0.2060723900794983
Batch 55/64 loss: 0.20488691329956055
Batch 56/64 loss: 0.20528137683868408
Batch 57/64 loss: 0.2104625105857849
Batch 58/64 loss: 0.20535123348236084
Batch 59/64 loss: 0.20199322700500488
Batch 60/64 loss: 0.2100389003753662
Batch 61/64 loss: 0.20926618576049805
Batch 62/64 loss: 0.20351052284240723
Batch 63/64 loss: 0.19817030429840088
Batch 64/64 loss: 0.2079988718032837
Epoch 413  Train loss: 0.20507602831896612  Val loss: 0.2686563664695242
Epoch 414
-------------------------------
Batch 1/64 loss: 0.19852817058563232
Batch 2/64 loss: 0.2074202299118042
Batch 3/64 loss: 0.20285391807556152
Batch 4/64 loss: 0.20154893398284912
Batch 5/64 loss: 0.19924867153167725
Batch 6/64 loss: 0.20214158296585083
Batch 7/64 loss: 0.1978815197944641
Batch 8/64 loss: 0.21062153577804565
Batch 9/64 loss: 0.20494794845581055
Batch 10/64 loss: 0.20960229635238647
Batch 11/64 loss: 0.20496779680252075
Batch 12/64 loss: 0.20551174879074097
Batch 13/64 loss: 0.20024603605270386
Batch 14/64 loss: 0.20978671312332153
Batch 15/64 loss: 0.1967582106590271
Batch 16/64 loss: 0.2093241810798645
Batch 17/64 loss: 0.19852548837661743
Batch 18/64 loss: 0.2089707851409912
Batch 19/64 loss: 0.2014859914779663
Batch 20/64 loss: 0.20729124546051025
Batch 21/64 loss: 0.20352721214294434
Batch 22/64 loss: 0.2049095630645752
Batch 23/64 loss: 0.1991216540336609
Batch 24/64 loss: 0.1970512866973877
Batch 25/64 loss: 0.196158766746521
Batch 26/64 loss: 0.19956421852111816
Batch 27/64 loss: 0.20304381847381592
Batch 28/64 loss: 0.19969427585601807
Batch 29/64 loss: 0.20981156826019287
Batch 30/64 loss: 0.20961660146713257
Batch 31/64 loss: 0.2002110481262207
Batch 32/64 loss: 0.19581294059753418
Batch 33/64 loss: 0.20228368043899536
Batch 34/64 loss: 0.20242691040039062
Batch 35/64 loss: 0.1990770697593689
Batch 36/64 loss: 0.20852017402648926
Batch 37/64 loss: 0.19364166259765625
Batch 38/64 loss: 0.2016383409500122
Batch 39/64 loss: 0.1996648907661438
Batch 40/64 loss: 0.2024955153465271
Batch 41/64 loss: 0.20163768529891968
Batch 42/64 loss: 0.20428282022476196
Batch 43/64 loss: 0.20614385604858398
Batch 44/64 loss: 0.20462769269943237
Batch 45/64 loss: 0.19696968793869019
Batch 46/64 loss: 0.2096739411354065
Batch 47/64 loss: 0.2156585454940796
Batch 48/64 loss: 0.20404595136642456
Batch 49/64 loss: 0.20752614736557007
Batch 50/64 loss: 0.2020588517189026
Batch 51/64 loss: 0.21188825368881226
Batch 52/64 loss: 0.20877742767333984
Batch 53/64 loss: 0.20015209913253784
Batch 54/64 loss: 0.22232109308242798
Batch 55/64 loss: 0.19865792989730835
Batch 56/64 loss: 0.20603585243225098
Batch 57/64 loss: 0.1992751955986023
Batch 58/64 loss: 0.194677472114563
Batch 59/64 loss: 0.2014073133468628
Batch 60/64 loss: 0.21234607696533203
Batch 61/64 loss: 0.21150600910186768
Batch 62/64 loss: 0.200087308883667
Batch 63/64 loss: 0.2113524079322815
Batch 64/64 loss: 0.19824111461639404
Epoch 414  Train loss: 0.2036976416905721  Val loss: 0.2691112170924026
Epoch 415
-------------------------------
Batch 1/64 loss: 0.20419007539749146
Batch 2/64 loss: 0.20787286758422852
Batch 3/64 loss: 0.20572614669799805
Batch 4/64 loss: 0.203110933303833
Batch 5/64 loss: 0.19731616973876953
Batch 6/64 loss: 0.2157515287399292
Batch 7/64 loss: 0.2106403112411499
Batch 8/64 loss: 0.2082124948501587
Batch 9/64 loss: 0.19715964794158936
Batch 10/64 loss: 0.20705866813659668
Batch 11/64 loss: 0.2039473056793213
Batch 12/64 loss: 0.1950310468673706
Batch 13/64 loss: 0.20087182521820068
Batch 14/64 loss: 0.19780224561691284
Batch 15/64 loss: 0.21075648069381714
Batch 16/64 loss: 0.19482451677322388
Batch 17/64 loss: 0.20079535245895386
Batch 18/64 loss: 0.20868873596191406
Batch 19/64 loss: 0.20669740438461304
Batch 20/64 loss: 0.21039605140686035
Batch 21/64 loss: 0.20489782094955444
Batch 22/64 loss: 0.21122539043426514
Batch 23/64 loss: 0.20846658945083618
Batch 24/64 loss: 0.20759987831115723
Batch 25/64 loss: 0.2083643078804016
Batch 26/64 loss: 0.1982901692390442
Batch 27/64 loss: 0.20701098442077637
Batch 28/64 loss: 0.20629239082336426
Batch 29/64 loss: 0.20044296979904175
Batch 30/64 loss: 0.1969081163406372
Batch 31/64 loss: 0.1993129849433899
Batch 32/64 loss: 0.1978468894958496
Batch 33/64 loss: 0.2030472755432129
Batch 34/64 loss: 0.20440888404846191
Batch 35/64 loss: 0.1960071325302124
Batch 36/64 loss: 0.21093225479125977
Batch 37/64 loss: 0.20527750253677368
Batch 38/64 loss: 0.19815146923065186
Batch 39/64 loss: 0.20994627475738525
Batch 40/64 loss: 0.20569086074829102
Batch 41/64 loss: 0.20100277662277222
Batch 42/64 loss: 0.19531303644180298
Batch 43/64 loss: 0.21455389261245728
Batch 44/64 loss: 0.21137350797653198
Batch 45/64 loss: 0.19589585065841675
Batch 46/64 loss: 0.21171993017196655
Batch 47/64 loss: 0.20342612266540527
Batch 48/64 loss: 0.20871353149414062
Batch 49/64 loss: 0.20170122385025024
Batch 50/64 loss: 0.2082357406616211
Batch 51/64 loss: 0.20568931102752686
Batch 52/64 loss: 0.20550626516342163
Batch 53/64 loss: 0.2018444538116455
Batch 54/64 loss: 0.20393997430801392
Batch 55/64 loss: 0.205885112285614
Batch 56/64 loss: 0.20867979526519775
Batch 57/64 loss: 0.20042723417282104
Batch 58/64 loss: 0.20007622241973877
Batch 59/64 loss: 0.20910108089447021
Batch 60/64 loss: 0.2084904909133911
Batch 61/64 loss: 0.21863257884979248
Batch 62/64 loss: 0.2110133171081543
Batch 63/64 loss: 0.20201104879379272
Batch 64/64 loss: 0.20009028911590576
Epoch 415  Train loss: 0.20471012031330782  Val loss: 0.2688581050466426
Epoch 416
-------------------------------
Batch 1/64 loss: 0.20550554990768433
Batch 2/64 loss: 0.20177102088928223
Batch 3/64 loss: 0.19740474224090576
Batch 4/64 loss: 0.20238125324249268
Batch 5/64 loss: 0.19724422693252563
Batch 6/64 loss: 0.21649909019470215
Batch 7/64 loss: 0.19702881574630737
Batch 8/64 loss: 0.2019575834274292
Batch 9/64 loss: 0.20709526538848877
Batch 10/64 loss: 0.2083144187927246
Batch 11/64 loss: 0.20668351650238037
Batch 12/64 loss: 0.2004895806312561
Batch 13/64 loss: 0.19608527421951294
Batch 14/64 loss: 0.1996825933456421
Batch 15/64 loss: 0.19692063331604004
Batch 16/64 loss: 0.1996556520462036
Batch 17/64 loss: 0.1959717869758606
Batch 18/64 loss: 0.20199155807495117
Batch 19/64 loss: 0.20762360095977783
Batch 20/64 loss: 0.19716882705688477
Batch 21/64 loss: 0.19968938827514648
Batch 22/64 loss: 0.19952815771102905
Batch 23/64 loss: 0.20710504055023193
Batch 24/64 loss: 0.21557050943374634
Batch 25/64 loss: 0.1989980936050415
Batch 26/64 loss: 0.20954155921936035
Batch 27/64 loss: 0.21244961023330688
Batch 28/64 loss: 0.20050716400146484
Batch 29/64 loss: 0.20639687776565552
Batch 30/64 loss: 0.20523607730865479
Batch 31/64 loss: 0.19990801811218262
Batch 32/64 loss: 0.19809406995773315
Batch 33/64 loss: 0.21137571334838867
Batch 34/64 loss: 0.19408196210861206
Batch 35/64 loss: 0.21109259128570557
Batch 36/64 loss: 0.20130592584609985
Batch 37/64 loss: 0.20277905464172363
Batch 38/64 loss: 0.20218360424041748
Batch 39/64 loss: 0.20492100715637207
Batch 40/64 loss: 0.20334595441818237
Batch 41/64 loss: 0.21487963199615479
Batch 42/64 loss: 0.20893943309783936
Batch 43/64 loss: 0.2137293815612793
Batch 44/64 loss: 0.19949853420257568
Batch 45/64 loss: 0.20431113243103027
Batch 46/64 loss: 0.20803302526474
Batch 47/64 loss: 0.20858466625213623
Batch 48/64 loss: 0.19585514068603516
Batch 49/64 loss: 0.2012028694152832
Batch 50/64 loss: 0.19967126846313477
Batch 51/64 loss: 0.2080087661743164
Batch 52/64 loss: 0.20261722803115845
Batch 53/64 loss: 0.20871567726135254
Batch 54/64 loss: 0.21076786518096924
Batch 55/64 loss: 0.2091009020805359
Batch 56/64 loss: 0.19318616390228271
Batch 57/64 loss: 0.2127460241317749
Batch 58/64 loss: 0.1986241340637207
Batch 59/64 loss: 0.21764904260635376
Batch 60/64 loss: 0.20651626586914062
Batch 61/64 loss: 0.2123105525970459
Batch 62/64 loss: 0.2181936502456665
Batch 63/64 loss: 0.20784515142440796
Batch 64/64 loss: 0.20660817623138428
Epoch 416  Train loss: 0.20451024326623654  Val loss: 0.2699317264393023
Epoch 417
-------------------------------
Batch 1/64 loss: 0.2115471363067627
Batch 2/64 loss: 0.2005772590637207
Batch 3/64 loss: 0.2133249044418335
Batch 4/64 loss: 0.19098389148712158
Batch 5/64 loss: 0.2049010992050171
Batch 6/64 loss: 0.20480716228485107
Batch 7/64 loss: 0.2010725736618042
Batch 8/64 loss: 0.21426904201507568
Batch 9/64 loss: 0.20678895711898804
Batch 10/64 loss: 0.2021578550338745
Batch 11/64 loss: 0.20335692167282104
Batch 12/64 loss: 0.19801199436187744
Batch 13/64 loss: 0.2055613398551941
Batch 14/64 loss: 0.20065701007843018
Batch 15/64 loss: 0.20239555835723877
Batch 16/64 loss: 0.1999465823173523
Batch 17/64 loss: 0.2014119029045105
Batch 18/64 loss: 0.2026647925376892
Batch 19/64 loss: 0.1957114338874817
Batch 20/64 loss: 0.2096397876739502
Batch 21/64 loss: 0.20267081260681152
Batch 22/64 loss: 0.20191508531570435
Batch 23/64 loss: 0.20811164379119873
Batch 24/64 loss: 0.2044970989227295
Batch 25/64 loss: 0.21379053592681885
Batch 26/64 loss: 0.21225285530090332
Batch 27/64 loss: 0.19986742734909058
Batch 28/64 loss: 0.19682669639587402
Batch 29/64 loss: 0.20114827156066895
Batch 30/64 loss: 0.1990957260131836
Batch 31/64 loss: 0.21318918466567993
Batch 32/64 loss: 0.2064816951751709
Batch 33/64 loss: 0.2003873586654663
Batch 34/64 loss: 0.2078770399093628
Batch 35/64 loss: 0.19685673713684082
Batch 36/64 loss: 0.20440655946731567
Batch 37/64 loss: 0.2016783356666565
Batch 38/64 loss: 0.19761526584625244
Batch 39/64 loss: 0.20286309719085693
Batch 40/64 loss: 0.21974605321884155
Batch 41/64 loss: 0.198350191116333
Batch 42/64 loss: 0.20330703258514404
Batch 43/64 loss: 0.2090703845024109
Batch 44/64 loss: 0.20929646492004395
Batch 45/64 loss: 0.19864290952682495
Batch 46/64 loss: 0.20682376623153687
Batch 47/64 loss: 0.21543443202972412
Batch 48/64 loss: 0.20356732606887817
Batch 49/64 loss: 0.1992180347442627
Batch 50/64 loss: 0.20298445224761963
Batch 51/64 loss: 0.19953113794326782
Batch 52/64 loss: 0.19781726598739624
Batch 53/64 loss: 0.21631497144699097
Batch 54/64 loss: 0.20082378387451172
Batch 55/64 loss: 0.20285844802856445
Batch 56/64 loss: 0.1906079649925232
Batch 57/64 loss: 0.20700103044509888
Batch 58/64 loss: 0.20797061920166016
Batch 59/64 loss: 0.20215755701065063
Batch 60/64 loss: 0.2058398723602295
Batch 61/64 loss: 0.20725566148757935
Batch 62/64 loss: 0.21541154384613037
Batch 63/64 loss: 0.19799154996871948
Batch 64/64 loss: 0.21806049346923828
Epoch 417  Train loss: 0.20428057184406356  Val loss: 0.2701472666665041
Epoch 418
-------------------------------
Batch 1/64 loss: 0.19961810111999512
Batch 2/64 loss: 0.20161360502243042
Batch 3/64 loss: 0.20414245128631592
Batch 4/64 loss: 0.19823187589645386
Batch 5/64 loss: 0.20725888013839722
Batch 6/64 loss: 0.19939541816711426
Batch 7/64 loss: 0.20568394660949707
Batch 8/64 loss: 0.20004308223724365
Batch 9/64 loss: 0.19271022081375122
Batch 10/64 loss: 0.2025313377380371
Batch 11/64 loss: 0.20613116025924683
Batch 12/64 loss: 0.20721447467803955
Batch 13/64 loss: 0.19793498516082764
Batch 14/64 loss: 0.20099127292633057
Batch 15/64 loss: 0.2026529312133789
Batch 16/64 loss: 0.19630712270736694
Batch 17/64 loss: 0.2021414041519165
Batch 18/64 loss: 0.20579898357391357
Batch 19/64 loss: 0.19842791557312012
Batch 20/64 loss: 0.19651168584823608
Batch 21/64 loss: 0.20602047443389893
Batch 22/64 loss: 0.20155245065689087
Batch 23/64 loss: 0.20235294103622437
Batch 24/64 loss: 0.19981282949447632
Batch 25/64 loss: 0.20309269428253174
Batch 26/64 loss: 0.21571213006973267
Batch 27/64 loss: 0.19828486442565918
Batch 28/64 loss: 0.1948947310447693
Batch 29/64 loss: 0.19875532388687134
Batch 30/64 loss: 0.2012895941734314
Batch 31/64 loss: 0.20885759592056274
Batch 32/64 loss: 0.20222055912017822
Batch 33/64 loss: 0.20225435495376587
Batch 34/64 loss: 0.20780420303344727
Batch 35/64 loss: 0.20624488592147827
Batch 36/64 loss: 0.20368105173110962
Batch 37/64 loss: 0.2100207805633545
Batch 38/64 loss: 0.20086348056793213
Batch 39/64 loss: 0.20678842067718506
Batch 40/64 loss: 0.20534050464630127
Batch 41/64 loss: 0.21232223510742188
Batch 42/64 loss: 0.20594912767410278
Batch 43/64 loss: 0.22097355127334595
Batch 44/64 loss: 0.2176167368888855
Batch 45/64 loss: 0.2083587646484375
Batch 46/64 loss: 0.2086493968963623
Batch 47/64 loss: 0.19805151224136353
Batch 48/64 loss: 0.20681136846542358
Batch 49/64 loss: 0.2041580080986023
Batch 50/64 loss: 0.20257914066314697
Batch 51/64 loss: 0.2051106095314026
Batch 52/64 loss: 0.19773530960083008
Batch 53/64 loss: 0.2008642554283142
Batch 54/64 loss: 0.2074122428894043
Batch 55/64 loss: 0.2044246792793274
Batch 56/64 loss: 0.1999930739402771
Batch 57/64 loss: 0.20530211925506592
Batch 58/64 loss: 0.19823408126831055
Batch 59/64 loss: 0.19588011503219604
Batch 60/64 loss: 0.20872783660888672
Batch 61/64 loss: 0.20167064666748047
Batch 62/64 loss: 0.21772921085357666
Batch 63/64 loss: 0.2081977128982544
Batch 64/64 loss: 0.20776766538619995
Epoch 418  Train loss: 0.2038237209413566  Val loss: 0.27001890734708595
Epoch 419
-------------------------------
Batch 1/64 loss: 0.20672202110290527
Batch 2/64 loss: 0.19679361581802368
Batch 3/64 loss: 0.20183473825454712
Batch 4/64 loss: 0.20816200971603394
Batch 5/64 loss: 0.19652140140533447
Batch 6/64 loss: 0.20231032371520996
Batch 7/64 loss: 0.2069186568260193
Batch 8/64 loss: 0.19574522972106934
Batch 9/64 loss: 0.2093414068222046
Batch 10/64 loss: 0.21106278896331787
Batch 11/64 loss: 0.2069535255432129
Batch 12/64 loss: 0.20124423503875732
Batch 13/64 loss: 0.19621604681015015
Batch 14/64 loss: 0.20891642570495605
Batch 15/64 loss: 0.1975175142288208
Batch 16/64 loss: 0.19855022430419922
Batch 17/64 loss: 0.20816516876220703
Batch 18/64 loss: 0.21367859840393066
Batch 19/64 loss: 0.2016802430152893
Batch 20/64 loss: 0.18837374448776245
Batch 21/64 loss: 0.19823205471038818
Batch 22/64 loss: 0.1995890736579895
Batch 23/64 loss: 0.2029377818107605
Batch 24/64 loss: 0.2091081738471985
Batch 25/64 loss: 0.2077828049659729
Batch 26/64 loss: 0.19695794582366943
Batch 27/64 loss: 0.1942623257637024
Batch 28/64 loss: 0.20676273107528687
Batch 29/64 loss: 0.208077073097229
Batch 30/64 loss: 0.19974642992019653
Batch 31/64 loss: 0.2049831748008728
Batch 32/64 loss: 0.19418299198150635
Batch 33/64 loss: 0.2134227752685547
Batch 34/64 loss: 0.1995943784713745
Batch 35/64 loss: 0.19940698146820068
Batch 36/64 loss: 0.20654159784317017
Batch 37/64 loss: 0.194466233253479
Batch 38/64 loss: 0.19795429706573486
Batch 39/64 loss: 0.2052660584449768
Batch 40/64 loss: 0.20291149616241455
Batch 41/64 loss: 0.20574069023132324
Batch 42/64 loss: 0.2075853943824768
Batch 43/64 loss: 0.2035772204399109
Batch 44/64 loss: 0.20517253875732422
Batch 45/64 loss: 0.2181820273399353
Batch 46/64 loss: 0.2169284224510193
Batch 47/64 loss: 0.20574551820755005
Batch 48/64 loss: 0.20308202505111694
Batch 49/64 loss: 0.20909428596496582
Batch 50/64 loss: 0.19225472211837769
Batch 51/64 loss: 0.19972479343414307
Batch 52/64 loss: 0.1917138695716858
Batch 53/64 loss: 0.21130377054214478
Batch 54/64 loss: 0.19843178987503052
Batch 55/64 loss: 0.2087801694869995
Batch 56/64 loss: 0.21023404598236084
Batch 57/64 loss: 0.19943314790725708
Batch 58/64 loss: 0.20543545484542847
Batch 59/64 loss: 0.20995306968688965
Batch 60/64 loss: 0.20414555072784424
Batch 61/64 loss: 0.19924622774124146
Batch 62/64 loss: 0.2061542272567749
Batch 63/64 loss: 0.20629453659057617
Batch 64/64 loss: 0.21138596534729004
Epoch 419  Train loss: 0.20353956503026627  Val loss: 0.26982964396067094
Epoch 420
-------------------------------
Batch 1/64 loss: 0.20950734615325928
Batch 2/64 loss: 0.20214200019836426
Batch 3/64 loss: 0.2039940357208252
Batch 4/64 loss: 0.21271926164627075
Batch 5/64 loss: 0.20402491092681885
Batch 6/64 loss: 0.21650272607803345
Batch 7/64 loss: 0.20728075504302979
Batch 8/64 loss: 0.21844160556793213
Batch 9/64 loss: 0.20926940441131592
Batch 10/64 loss: 0.21018218994140625
Batch 11/64 loss: 0.2007126808166504
Batch 12/64 loss: 0.20004606246948242
Batch 13/64 loss: 0.19852638244628906
Batch 14/64 loss: 0.20173364877700806
Batch 15/64 loss: 0.20679986476898193
Batch 16/64 loss: 0.20734524726867676
Batch 17/64 loss: 0.20279741287231445
Batch 18/64 loss: 0.21954190731048584
Batch 19/64 loss: 0.2079753279685974
Batch 20/64 loss: 0.218275785446167
Batch 21/64 loss: 0.22018909454345703
Batch 22/64 loss: 0.21495693922042847
Batch 23/64 loss: 0.2041361927986145
Batch 24/64 loss: 0.20171892642974854
Batch 25/64 loss: 0.19330167770385742
Batch 26/64 loss: 0.20784074068069458
Batch 27/64 loss: 0.19704681634902954
Batch 28/64 loss: 0.19975215196609497
Batch 29/64 loss: 0.2002553939819336
Batch 30/64 loss: 0.20885992050170898
Batch 31/64 loss: 0.20812082290649414
Batch 32/64 loss: 0.19749760627746582
Batch 33/64 loss: 0.1938871145248413
Batch 34/64 loss: 0.19514036178588867
Batch 35/64 loss: 0.19572031497955322
Batch 36/64 loss: 0.1992242932319641
Batch 37/64 loss: 0.19919276237487793
Batch 38/64 loss: 0.2065487504005432
Batch 39/64 loss: 0.1967117190361023
Batch 40/64 loss: 0.19895505905151367
Batch 41/64 loss: 0.21797579526901245
Batch 42/64 loss: 0.20514702796936035
Batch 43/64 loss: 0.20508116483688354
Batch 44/64 loss: 0.20917129516601562
Batch 45/64 loss: 0.19598954916000366
Batch 46/64 loss: 0.19592201709747314
Batch 47/64 loss: 0.2071375846862793
Batch 48/64 loss: 0.19873309135437012
Batch 49/64 loss: 0.19778424501419067
Batch 50/64 loss: 0.2082287073135376
Batch 51/64 loss: 0.20628643035888672
Batch 52/64 loss: 0.2125781774520874
Batch 53/64 loss: 0.2019292712211609
Batch 54/64 loss: 0.20107895135879517
Batch 55/64 loss: 0.2069453001022339
Batch 56/64 loss: 0.19818460941314697
Batch 57/64 loss: 0.2045835256576538
Batch 58/64 loss: 0.20114028453826904
Batch 59/64 loss: 0.19769662618637085
Batch 60/64 loss: 0.20342475175857544
Batch 61/64 loss: 0.19791293144226074
Batch 62/64 loss: 0.2077684998512268
Batch 63/64 loss: 0.20811128616333008
Batch 64/64 loss: 0.20983344316482544
Epoch 420  Train loss: 0.20459704188739553  Val loss: 0.2695236888128458
Epoch 421
-------------------------------
Batch 1/64 loss: 0.20345664024353027
Batch 2/64 loss: 0.20061075687408447
Batch 3/64 loss: 0.1969699263572693
Batch 4/64 loss: 0.1977565884590149
Batch 5/64 loss: 0.20517849922180176
Batch 6/64 loss: 0.19409066438674927
Batch 7/64 loss: 0.20285660028457642
Batch 8/64 loss: 0.20231842994689941
Batch 9/64 loss: 0.19619262218475342
Batch 10/64 loss: 0.2103956937789917
Batch 11/64 loss: 0.21156328916549683
Batch 12/64 loss: 0.21403074264526367
Batch 13/64 loss: 0.20397424697875977
Batch 14/64 loss: 0.20521235466003418
Batch 15/64 loss: 0.20175904035568237
Batch 16/64 loss: 0.19795620441436768
Batch 17/64 loss: 0.20044410228729248
Batch 18/64 loss: 0.20164024829864502
Batch 19/64 loss: 0.20835882425308228
Batch 20/64 loss: 0.20321667194366455
Batch 21/64 loss: 0.20403122901916504
Batch 22/64 loss: 0.19974052906036377
Batch 23/64 loss: 0.19368577003479004
Batch 24/64 loss: 0.21428561210632324
Batch 25/64 loss: 0.2158946394920349
Batch 26/64 loss: 0.1949595808982849
Batch 27/64 loss: 0.2066417932510376
Batch 28/64 loss: 0.21304833889007568
Batch 29/64 loss: 0.200583815574646
Batch 30/64 loss: 0.20323097705841064
Batch 31/64 loss: 0.20072489976882935
Batch 32/64 loss: 0.19912874698638916
Batch 33/64 loss: 0.20136916637420654
Batch 34/64 loss: 0.2091144323348999
Batch 35/64 loss: 0.21313989162445068
Batch 36/64 loss: 0.20134270191192627
Batch 37/64 loss: 0.20756810903549194
Batch 38/64 loss: 0.20507854223251343
Batch 39/64 loss: 0.20410585403442383
Batch 40/64 loss: 0.21237540245056152
Batch 41/64 loss: 0.20692580938339233
Batch 42/64 loss: 0.2091032862663269
Batch 43/64 loss: 0.20588946342468262
Batch 44/64 loss: 0.21322554349899292
Batch 45/64 loss: 0.2125949263572693
Batch 46/64 loss: 0.2102949023246765
Batch 47/64 loss: 0.21637362241744995
Batch 48/64 loss: 0.19142121076583862
Batch 49/64 loss: 0.20422261953353882
Batch 50/64 loss: 0.20193970203399658
Batch 51/64 loss: 0.22188591957092285
Batch 52/64 loss: 0.22633767127990723
Batch 53/64 loss: 0.20767545700073242
Batch 54/64 loss: 0.21461939811706543
Batch 55/64 loss: 0.21287858486175537
Batch 56/64 loss: 0.20810145139694214
Batch 57/64 loss: 0.20773810148239136
Batch 58/64 loss: 0.206409752368927
Batch 59/64 loss: 0.20139676332473755
Batch 60/64 loss: 0.19984674453735352
Batch 61/64 loss: 0.2074446678161621
Batch 62/64 loss: 0.19977736473083496
Batch 63/64 loss: 0.1997464895248413
Batch 64/64 loss: 0.1977710723876953
Epoch 421  Train loss: 0.2053679989833458  Val loss: 0.26979911532189016
Epoch 422
-------------------------------
Batch 1/64 loss: 0.20174330472946167
Batch 2/64 loss: 0.20312929153442383
Batch 3/64 loss: 0.2003149390220642
Batch 4/64 loss: 0.19802135229110718
Batch 5/64 loss: 0.2168734073638916
Batch 6/64 loss: 0.21156024932861328
Batch 7/64 loss: 0.20541739463806152
Batch 8/64 loss: 0.18980062007904053
Batch 9/64 loss: 0.20103085041046143
Batch 10/64 loss: 0.20146477222442627
Batch 11/64 loss: 0.19634604454040527
Batch 12/64 loss: 0.2035045623779297
Batch 13/64 loss: 0.21089696884155273
Batch 14/64 loss: 0.19524723291397095
Batch 15/64 loss: 0.19529467821121216
Batch 16/64 loss: 0.20338326692581177
Batch 17/64 loss: 0.20895075798034668
Batch 18/64 loss: 0.20490223169326782
Batch 19/64 loss: 0.19947785139083862
Batch 20/64 loss: 0.2004077434539795
Batch 21/64 loss: 0.20836007595062256
Batch 22/64 loss: 0.21538937091827393
Batch 23/64 loss: 0.20394325256347656
Batch 24/64 loss: 0.1972029209136963
Batch 25/64 loss: 0.2003592848777771
Batch 26/64 loss: 0.19374299049377441
Batch 27/64 loss: 0.1974620819091797
Batch 28/64 loss: 0.20965898036956787
Batch 29/64 loss: 0.203549325466156
Batch 30/64 loss: 0.1986703872680664
Batch 31/64 loss: 0.19526314735412598
Batch 32/64 loss: 0.19835656881332397
Batch 33/64 loss: 0.19815707206726074
Batch 34/64 loss: 0.20913589000701904
Batch 35/64 loss: 0.2015601396560669
Batch 36/64 loss: 0.2138286828994751
Batch 37/64 loss: 0.2006995677947998
Batch 38/64 loss: 0.20713132619857788
Batch 39/64 loss: 0.2037278413772583
Batch 40/64 loss: 0.20394593477249146
Batch 41/64 loss: 0.20621109008789062
Batch 42/64 loss: 0.20997130870819092
Batch 43/64 loss: 0.20684516429901123
Batch 44/64 loss: 0.21700870990753174
Batch 45/64 loss: 0.2099367380142212
Batch 46/64 loss: 0.21215999126434326
Batch 47/64 loss: 0.20940566062927246
Batch 48/64 loss: 0.2098768949508667
Batch 49/64 loss: 0.22140133380889893
Batch 50/64 loss: 0.2087111473083496
Batch 51/64 loss: 0.20405185222625732
Batch 52/64 loss: 0.2142857313156128
Batch 53/64 loss: 0.20969462394714355
Batch 54/64 loss: 0.19547820091247559
Batch 55/64 loss: 0.19974642992019653
Batch 56/64 loss: 0.20069009065628052
Batch 57/64 loss: 0.20806044340133667
Batch 58/64 loss: 0.2054213285446167
Batch 59/64 loss: 0.2022269368171692
Batch 60/64 loss: 0.19924116134643555
Batch 61/64 loss: 0.20953285694122314
Batch 62/64 loss: 0.2112964391708374
Batch 63/64 loss: 0.19725555181503296
Batch 64/64 loss: 0.21908259391784668
Epoch 422  Train loss: 0.20456053322436762  Val loss: 0.26913956698683117
Epoch 423
-------------------------------
Batch 1/64 loss: 0.2010149359703064
Batch 2/64 loss: 0.21013659238815308
Batch 3/64 loss: 0.20324909687042236
Batch 4/64 loss: 0.2027137279510498
Batch 5/64 loss: 0.19782191514968872
Batch 6/64 loss: 0.20709383487701416
Batch 7/64 loss: 0.20073086023330688
Batch 8/64 loss: 0.20506715774536133
Batch 9/64 loss: 0.2019302248954773
Batch 10/64 loss: 0.21063929796218872
Batch 11/64 loss: 0.2039555311203003
Batch 12/64 loss: 0.21335899829864502
Batch 13/64 loss: 0.19817179441452026
Batch 14/64 loss: 0.1961456537246704
Batch 15/64 loss: 0.1961042881011963
Batch 16/64 loss: 0.2040330171585083
Batch 17/64 loss: 0.20852643251419067
Batch 18/64 loss: 0.2067367434501648
Batch 19/64 loss: 0.19832110404968262
Batch 20/64 loss: 0.2032550573348999
Batch 21/64 loss: 0.19479507207870483
Batch 22/64 loss: 0.19910156726837158
Batch 23/64 loss: 0.20482778549194336
Batch 24/64 loss: 0.2035565972328186
Batch 25/64 loss: 0.21128880977630615
Batch 26/64 loss: 0.20290857553482056
Batch 27/64 loss: 0.19974899291992188
Batch 28/64 loss: 0.19994795322418213
Batch 29/64 loss: 0.21075773239135742
Batch 30/64 loss: 0.20751523971557617
Batch 31/64 loss: 0.20340698957443237
Batch 32/64 loss: 0.20913779735565186
Batch 33/64 loss: 0.2037186622619629
Batch 34/64 loss: 0.2040269374847412
Batch 35/64 loss: 0.20297372341156006
Batch 36/64 loss: 0.19944512844085693
Batch 37/64 loss: 0.20054805278778076
Batch 38/64 loss: 0.2134760618209839
Batch 39/64 loss: 0.19539999961853027
Batch 40/64 loss: 0.20202386379241943
Batch 41/64 loss: 0.19785618782043457
Batch 42/64 loss: 0.2068711519241333
Batch 43/64 loss: 0.19995403289794922
Batch 44/64 loss: 0.1989254355430603
Batch 45/64 loss: 0.19831007719039917
Batch 46/64 loss: 0.19998353719711304
Batch 47/64 loss: 0.19694113731384277
Batch 48/64 loss: 0.20105445384979248
Batch 49/64 loss: 0.19449901580810547
Batch 50/64 loss: 0.20782411098480225
Batch 51/64 loss: 0.1948375701904297
Batch 52/64 loss: 0.2124958634376526
Batch 53/64 loss: 0.20544171333312988
Batch 54/64 loss: 0.21418994665145874
Batch 55/64 loss: 0.20227748155593872
Batch 56/64 loss: 0.19682061672210693
Batch 57/64 loss: 0.21347105503082275
Batch 58/64 loss: 0.20620423555374146
Batch 59/64 loss: 0.1954030990600586
Batch 60/64 loss: 0.2156611680984497
Batch 61/64 loss: 0.20544201135635376
Batch 62/64 loss: 0.21386224031448364
Batch 63/64 loss: 0.20540481805801392
Batch 64/64 loss: 0.1977483034133911
Epoch 423  Train loss: 0.20344555284462723  Val loss: 0.26974648708330395
Epoch 424
-------------------------------
Batch 1/64 loss: 0.20012563467025757
Batch 2/64 loss: 0.20004844665527344
Batch 3/64 loss: 0.20524579286575317
Batch 4/64 loss: 0.2104337215423584
Batch 5/64 loss: 0.21073698997497559
Batch 6/64 loss: 0.2143293023109436
Batch 7/64 loss: 0.20373916625976562
Batch 8/64 loss: 0.19525384902954102
Batch 9/64 loss: 0.19856131076812744
Batch 10/64 loss: 0.20478534698486328
Batch 11/64 loss: 0.19687557220458984
Batch 12/64 loss: 0.2006080150604248
Batch 13/64 loss: 0.21036005020141602
Batch 14/64 loss: 0.20764541625976562
Batch 15/64 loss: 0.21006393432617188
Batch 16/64 loss: 0.2035452127456665
Batch 17/64 loss: 0.21633630990982056
Batch 18/64 loss: 0.20280098915100098
Batch 19/64 loss: 0.2025204300880432
Batch 20/64 loss: 0.1996176838874817
Batch 21/64 loss: 0.20087844133377075
Batch 22/64 loss: 0.21592557430267334
Batch 23/64 loss: 0.19567185640335083
Batch 24/64 loss: 0.20459306240081787
Batch 25/64 loss: 0.20447081327438354
Batch 26/64 loss: 0.19190877676010132
Batch 27/64 loss: 0.2032368779182434
Batch 28/64 loss: 0.19968438148498535
Batch 29/64 loss: 0.20316076278686523
Batch 30/64 loss: 0.20113462209701538
Batch 31/64 loss: 0.2168506383895874
Batch 32/64 loss: 0.1930963397026062
Batch 33/64 loss: 0.2062433362007141
Batch 34/64 loss: 0.20065385103225708
Batch 35/64 loss: 0.20360243320465088
Batch 36/64 loss: 0.2077779769897461
Batch 37/64 loss: 0.20426428318023682
Batch 38/64 loss: 0.19569528102874756
Batch 39/64 loss: 0.20732581615447998
Batch 40/64 loss: 0.2061774730682373
Batch 41/64 loss: 0.1991405487060547
Batch 42/64 loss: 0.20013338327407837
Batch 43/64 loss: 0.1959376335144043
Batch 44/64 loss: 0.197934091091156
Batch 45/64 loss: 0.19935429096221924
Batch 46/64 loss: 0.2114475965499878
Batch 47/64 loss: 0.20374733209609985
Batch 48/64 loss: 0.1994093656539917
Batch 49/64 loss: 0.20277059078216553
Batch 50/64 loss: 0.20316410064697266
Batch 51/64 loss: 0.19561874866485596
Batch 52/64 loss: 0.19739919900894165
Batch 53/64 loss: 0.20895874500274658
Batch 54/64 loss: 0.20130425691604614
Batch 55/64 loss: 0.20940423011779785
Batch 56/64 loss: 0.21041333675384521
Batch 57/64 loss: 0.2036881446838379
Batch 58/64 loss: 0.205061674118042
Batch 59/64 loss: 0.1986507773399353
Batch 60/64 loss: 0.19280898571014404
Batch 61/64 loss: 0.20119881629943848
Batch 62/64 loss: 0.21189796924591064
Batch 63/64 loss: 0.19703340530395508
Batch 64/64 loss: 0.19430196285247803
Epoch 424  Train loss: 0.20310885438732074  Val loss: 0.26960766315460205
Epoch 425
-------------------------------
Batch 1/64 loss: 0.20568954944610596
Batch 2/64 loss: 0.21017730236053467
Batch 3/64 loss: 0.19781076908111572
Batch 4/64 loss: 0.21144843101501465
Batch 5/64 loss: 0.19573408365249634
Batch 6/64 loss: 0.2105116844177246
Batch 7/64 loss: 0.21396219730377197
Batch 8/64 loss: 0.20505398511886597
Batch 9/64 loss: 0.20269775390625
Batch 10/64 loss: 0.21263599395751953
Batch 11/64 loss: 0.20846468210220337
Batch 12/64 loss: 0.19181859493255615
Batch 13/64 loss: 0.19977760314941406
Batch 14/64 loss: 0.1965961456298828
Batch 15/64 loss: 0.21883702278137207
Batch 16/64 loss: 0.20462048053741455
Batch 17/64 loss: 0.19590705633163452
Batch 18/64 loss: 0.203985333442688
Batch 19/64 loss: 0.21048599481582642
Batch 20/64 loss: 0.19928789138793945
Batch 21/64 loss: 0.19848549365997314
Batch 22/64 loss: 0.19144654273986816
Batch 23/64 loss: 0.20410078763961792
Batch 24/64 loss: 0.19935619831085205
Batch 25/64 loss: 0.19615238904953003
Batch 26/64 loss: 0.20258021354675293
Batch 27/64 loss: 0.1999627947807312
Batch 28/64 loss: 0.210288405418396
Batch 29/64 loss: 0.2093719244003296
Batch 30/64 loss: 0.19910401105880737
Batch 31/64 loss: 0.21707230806350708
Batch 32/64 loss: 0.20575302839279175
Batch 33/64 loss: 0.213445782661438
Batch 34/64 loss: 0.204187273979187
Batch 35/64 loss: 0.19740831851959229
Batch 36/64 loss: 0.1974930763244629
Batch 37/64 loss: 0.20164120197296143
Batch 38/64 loss: 0.20596951246261597
Batch 39/64 loss: 0.20316195487976074
Batch 40/64 loss: 0.2067754864692688
Batch 41/64 loss: 0.1934630274772644
Batch 42/64 loss: 0.19561177492141724
Batch 43/64 loss: 0.2007489800453186
Batch 44/64 loss: 0.20257866382598877
Batch 45/64 loss: 0.20288598537445068
Batch 46/64 loss: 0.21612238883972168
Batch 47/64 loss: 0.20756679773330688
Batch 48/64 loss: 0.20256471633911133
Batch 49/64 loss: 0.20233410596847534
Batch 50/64 loss: 0.1990795135498047
Batch 51/64 loss: 0.20758742094039917
Batch 52/64 loss: 0.20482385158538818
Batch 53/64 loss: 0.200545072555542
Batch 54/64 loss: 0.19776558876037598
Batch 55/64 loss: 0.20773601531982422
Batch 56/64 loss: 0.19802093505859375
Batch 57/64 loss: 0.19581657648086548
Batch 58/64 loss: 0.19840604066848755
Batch 59/64 loss: 0.1943507194519043
Batch 60/64 loss: 0.19985944032669067
Batch 61/64 loss: 0.19872421026229858
Batch 62/64 loss: 0.20475709438323975
Batch 63/64 loss: 0.2008618712425232
Batch 64/64 loss: 0.21361464262008667
Epoch 425  Train loss: 0.20316362404355817  Val loss: 0.26944734960077554
Epoch 426
-------------------------------
Batch 1/64 loss: 0.203885018825531
Batch 2/64 loss: 0.2032608985900879
Batch 3/64 loss: 0.20879679918289185
Batch 4/64 loss: 0.19519466161727905
Batch 5/64 loss: 0.19678038358688354
Batch 6/64 loss: 0.2102944254875183
Batch 7/64 loss: 0.19408941268920898
Batch 8/64 loss: 0.21218866109848022
Batch 9/64 loss: 0.1999390721321106
Batch 10/64 loss: 0.19733256101608276
Batch 11/64 loss: 0.2008202075958252
Batch 12/64 loss: 0.1994417905807495
Batch 13/64 loss: 0.20315980911254883
Batch 14/64 loss: 0.18706810474395752
Batch 15/64 loss: 0.19902324676513672
Batch 16/64 loss: 0.20570820569992065
Batch 17/64 loss: 0.20063728094100952
Batch 18/64 loss: 0.19477009773254395
Batch 19/64 loss: 0.2088865041732788
Batch 20/64 loss: 0.19973844289779663
Batch 21/64 loss: 0.19624823331832886
Batch 22/64 loss: 0.2096261978149414
Batch 23/64 loss: 0.20757168531417847
Batch 24/64 loss: 0.2092834711074829
Batch 25/64 loss: 0.1953563094139099
Batch 26/64 loss: 0.20454370975494385
Batch 27/64 loss: 0.2006193995475769
Batch 28/64 loss: 0.19459378719329834
Batch 29/64 loss: 0.19898110628128052
Batch 30/64 loss: 0.19541782140731812
Batch 31/64 loss: 0.2031097412109375
Batch 32/64 loss: 0.19233578443527222
Batch 33/64 loss: 0.20203542709350586
Batch 34/64 loss: 0.19443249702453613
Batch 35/64 loss: 0.1964704990386963
Batch 36/64 loss: 0.20748037099838257
Batch 37/64 loss: 0.21568036079406738
Batch 38/64 loss: 0.20295608043670654
Batch 39/64 loss: 0.20556038618087769
Batch 40/64 loss: 0.20750558376312256
Batch 41/64 loss: 0.20087754726409912
Batch 42/64 loss: 0.20241284370422363
Batch 43/64 loss: 0.20153993368148804
Batch 44/64 loss: 0.2016851305961609
Batch 45/64 loss: 0.20050770044326782
Batch 46/64 loss: 0.19967496395111084
Batch 47/64 loss: 0.1995389461517334
Batch 48/64 loss: 0.20335757732391357
Batch 49/64 loss: 0.20227771997451782
Batch 50/64 loss: 0.2027302384376526
Batch 51/64 loss: 0.2001798152923584
Batch 52/64 loss: 0.20401960611343384
Batch 53/64 loss: 0.20755881071090698
Batch 54/64 loss: 0.21255600452423096
Batch 55/64 loss: 0.21073323488235474
Batch 56/64 loss: 0.20754456520080566
Batch 57/64 loss: 0.20818471908569336
Batch 58/64 loss: 0.20793837308883667
Batch 59/64 loss: 0.2038697600364685
Batch 60/64 loss: 0.20107007026672363
Batch 61/64 loss: 0.2017662525177002
Batch 62/64 loss: 0.20438718795776367
Batch 63/64 loss: 0.21069997549057007
Batch 64/64 loss: 0.20200997591018677
Epoch 426  Train loss: 0.202469686199637  Val loss: 0.26990558232638434
Epoch 427
-------------------------------
Batch 1/64 loss: 0.1945844292640686
Batch 2/64 loss: 0.21309566497802734
Batch 3/64 loss: 0.20194435119628906
Batch 4/64 loss: 0.20286303758621216
Batch 5/64 loss: 0.1918770670890808
Batch 6/64 loss: 0.19418764114379883
Batch 7/64 loss: 0.20682907104492188
Batch 8/64 loss: 0.1993703842163086
Batch 9/64 loss: 0.2000163197517395
Batch 10/64 loss: 0.19725829362869263
Batch 11/64 loss: 0.21179109811782837
Batch 12/64 loss: 0.19837379455566406
Batch 13/64 loss: 0.2062772512435913
Batch 14/64 loss: 0.19918221235275269
Batch 15/64 loss: 0.21136730909347534
Batch 16/64 loss: 0.1980609893798828
Batch 17/64 loss: 0.191298246383667
Batch 18/64 loss: 0.19251763820648193
Batch 19/64 loss: 0.1851254105567932
Batch 20/64 loss: 0.20247632265090942
Batch 21/64 loss: 0.1999797224998474
Batch 22/64 loss: 0.20289885997772217
Batch 23/64 loss: 0.1903073787689209
Batch 24/64 loss: 0.2104935646057129
Batch 25/64 loss: 0.19751358032226562
Batch 26/64 loss: 0.21609348058700562
Batch 27/64 loss: 0.19460082054138184
Batch 28/64 loss: 0.1936708688735962
Batch 29/64 loss: 0.20527702569961548
Batch 30/64 loss: 0.21167176961898804
Batch 31/64 loss: 0.203374445438385
Batch 32/64 loss: 0.20144832134246826
Batch 33/64 loss: 0.20569735765457153
Batch 34/64 loss: 0.19713914394378662
Batch 35/64 loss: 0.19246560335159302
Batch 36/64 loss: 0.1981613039970398
Batch 37/64 loss: 0.19704169034957886
Batch 38/64 loss: 0.19720208644866943
Batch 39/64 loss: 0.20206815004348755
Batch 40/64 loss: 0.2030864953994751
Batch 41/64 loss: 0.20659804344177246
Batch 42/64 loss: 0.2067955732345581
Batch 43/64 loss: 0.20192956924438477
Batch 44/64 loss: 0.19416594505310059
Batch 45/64 loss: 0.20415282249450684
Batch 46/64 loss: 0.19569754600524902
Batch 47/64 loss: 0.20648449659347534
Batch 48/64 loss: 0.20915764570236206
Batch 49/64 loss: 0.20907574892044067
Batch 50/64 loss: 0.20520144701004028
Batch 51/64 loss: 0.20194292068481445
Batch 52/64 loss: 0.20053869485855103
Batch 53/64 loss: 0.19800281524658203
Batch 54/64 loss: 0.19546091556549072
Batch 55/64 loss: 0.2056170105934143
Batch 56/64 loss: 0.21400868892669678
Batch 57/64 loss: 0.21616625785827637
Batch 58/64 loss: 0.21800732612609863
Batch 59/64 loss: 0.206939697265625
Batch 60/64 loss: 0.20268821716308594
Batch 61/64 loss: 0.2062314748764038
Batch 62/64 loss: 0.2003888487815857
Batch 63/64 loss: 0.20042717456817627
Batch 64/64 loss: 0.1967376470565796
Epoch 427  Train loss: 0.20191247556723801  Val loss: 0.269039106942534
Epoch 428
-------------------------------
Batch 1/64 loss: 0.21256405115127563
Batch 2/64 loss: 0.193057119846344
Batch 3/64 loss: 0.1975163221359253
Batch 4/64 loss: 0.20536911487579346
Batch 5/64 loss: 0.1945757269859314
Batch 6/64 loss: 0.20913439989089966
Batch 7/64 loss: 0.1984769105911255
Batch 8/64 loss: 0.1944652795791626
Batch 9/64 loss: 0.1992034912109375
Batch 10/64 loss: 0.20720237493515015
Batch 11/64 loss: 0.19169527292251587
Batch 12/64 loss: 0.19639766216278076
Batch 13/64 loss: 0.19728052616119385
Batch 14/64 loss: 0.20041996240615845
Batch 15/64 loss: 0.20080715417861938
Batch 16/64 loss: 0.1934574842453003
Batch 17/64 loss: 0.19698739051818848
Batch 18/64 loss: 0.1980351209640503
Batch 19/64 loss: 0.1944723129272461
Batch 20/64 loss: 0.19543874263763428
Batch 21/64 loss: 0.202284574508667
Batch 22/64 loss: 0.2107408046722412
Batch 23/64 loss: 0.18958473205566406
Batch 24/64 loss: 0.19891715049743652
Batch 25/64 loss: 0.20715445280075073
Batch 26/64 loss: 0.19251608848571777
Batch 27/64 loss: 0.20119774341583252
Batch 28/64 loss: 0.1963314414024353
Batch 29/64 loss: 0.1929314136505127
Batch 30/64 loss: 0.20591861009597778
Batch 31/64 loss: 0.21644508838653564
Batch 32/64 loss: 0.20241934061050415
Batch 33/64 loss: 0.19789886474609375
Batch 34/64 loss: 0.20935475826263428
Batch 35/64 loss: 0.20093822479248047
Batch 36/64 loss: 0.20689809322357178
Batch 37/64 loss: 0.20935630798339844
Batch 38/64 loss: 0.20392918586730957
Batch 39/64 loss: 0.20257794857025146
Batch 40/64 loss: 0.20389604568481445
Batch 41/64 loss: 0.1987769603729248
Batch 42/64 loss: 0.20736432075500488
Batch 43/64 loss: 0.20335161685943604
Batch 44/64 loss: 0.1994096040725708
Batch 45/64 loss: 0.2093152403831482
Batch 46/64 loss: 0.21120238304138184
Batch 47/64 loss: 0.21055752038955688
Batch 48/64 loss: 0.2002752423286438
Batch 49/64 loss: 0.2101069688796997
Batch 50/64 loss: 0.20471370220184326
Batch 51/64 loss: 0.21265745162963867
Batch 52/64 loss: 0.20639121532440186
Batch 53/64 loss: 0.21044838428497314
Batch 54/64 loss: 0.20816069841384888
Batch 55/64 loss: 0.20529025793075562
Batch 56/64 loss: 0.19179147481918335
Batch 57/64 loss: 0.20419734716415405
Batch 58/64 loss: 0.20603621006011963
Batch 59/64 loss: 0.20400583744049072
Batch 60/64 loss: 0.20906710624694824
Batch 61/64 loss: 0.21427381038665771
Batch 62/64 loss: 0.20341098308563232
Batch 63/64 loss: 0.19486403465270996
Batch 64/64 loss: 0.2070176601409912
Epoch 428  Train loss: 0.2024906495038201  Val loss: 0.26896482685587253
Epoch 429
-------------------------------
Batch 1/64 loss: 0.19995850324630737
Batch 2/64 loss: 0.19912385940551758
Batch 3/64 loss: 0.2095513939857483
Batch 4/64 loss: 0.19229227304458618
Batch 5/64 loss: 0.19684183597564697
Batch 6/64 loss: 0.20844745635986328
Batch 7/64 loss: 0.19962680339813232
Batch 8/64 loss: 0.2073296308517456
Batch 9/64 loss: 0.2001878023147583
Batch 10/64 loss: 0.19455629587173462
Batch 11/64 loss: 0.20434153079986572
Batch 12/64 loss: 0.2089000940322876
Batch 13/64 loss: 0.20207178592681885
Batch 14/64 loss: 0.21487635374069214
Batch 15/64 loss: 0.2147618532180786
Batch 16/64 loss: 0.19502198696136475
Batch 17/64 loss: 0.21240496635437012
Batch 18/64 loss: 0.19645482301712036
Batch 19/64 loss: 0.202301025390625
Batch 20/64 loss: 0.19621527194976807
Batch 21/64 loss: 0.20684552192687988
Batch 22/64 loss: 0.20032250881195068
Batch 23/64 loss: 0.19905173778533936
Batch 24/64 loss: 0.1985321044921875
Batch 25/64 loss: 0.2005215883255005
Batch 26/64 loss: 0.20781850814819336
Batch 27/64 loss: 0.1953858733177185
Batch 28/64 loss: 0.21013468503952026
Batch 29/64 loss: 0.20154941082000732
Batch 30/64 loss: 0.20604902505874634
Batch 31/64 loss: 0.20415186882019043
Batch 32/64 loss: 0.20202594995498657
Batch 33/64 loss: 0.1904977560043335
Batch 34/64 loss: 0.2017562985420227
Batch 35/64 loss: 0.19951635599136353
Batch 36/64 loss: 0.2044142484664917
Batch 37/64 loss: 0.19149237871170044
Batch 38/64 loss: 0.20006126165390015
Batch 39/64 loss: 0.20865345001220703
Batch 40/64 loss: 0.20112138986587524
Batch 41/64 loss: 0.21688354015350342
Batch 42/64 loss: 0.20348209142684937
Batch 43/64 loss: 0.19989603757858276
Batch 44/64 loss: 0.19405889511108398
Batch 45/64 loss: 0.207646906375885
Batch 46/64 loss: 0.22049373388290405
Batch 47/64 loss: 0.19889283180236816
Batch 48/64 loss: 0.20076143741607666
Batch 49/64 loss: 0.20546883344650269
Batch 50/64 loss: 0.19447416067123413
Batch 51/64 loss: 0.19614720344543457
Batch 52/64 loss: 0.1956074833869934
Batch 53/64 loss: 0.19723278284072876
Batch 54/64 loss: 0.20136868953704834
Batch 55/64 loss: 0.21454083919525146
Batch 56/64 loss: 0.19721627235412598
Batch 57/64 loss: 0.20596373081207275
Batch 58/64 loss: 0.2003995180130005
Batch 59/64 loss: 0.19965672492980957
Batch 60/64 loss: 0.19587326049804688
Batch 61/64 loss: 0.2070409655570984
Batch 62/64 loss: 0.19091296195983887
Batch 63/64 loss: 0.2060871720314026
Batch 64/64 loss: 0.20827734470367432
Epoch 429  Train loss: 0.20221931840859209  Val loss: 0.2698208067015684
Epoch 430
-------------------------------
Batch 1/64 loss: 0.19780051708221436
Batch 2/64 loss: 0.18842029571533203
Batch 3/64 loss: 0.21006876230239868
Batch 4/64 loss: 0.20603644847869873
Batch 5/64 loss: 0.1855030655860901
Batch 6/64 loss: 0.20838475227355957
Batch 7/64 loss: 0.21856915950775146
Batch 8/64 loss: 0.1937406063079834
Batch 9/64 loss: 0.19533699750900269
Batch 10/64 loss: 0.20416373014450073
Batch 11/64 loss: 0.1895432472229004
Batch 12/64 loss: 0.19806194305419922
Batch 13/64 loss: 0.20190894603729248
Batch 14/64 loss: 0.2098621129989624
Batch 15/64 loss: 0.20830285549163818
Batch 16/64 loss: 0.20042383670806885
Batch 17/64 loss: 0.2066974639892578
Batch 18/64 loss: 0.20100992918014526
Batch 19/64 loss: 0.1922573447227478
Batch 20/64 loss: 0.20237702131271362
Batch 21/64 loss: 0.20173412561416626
Batch 22/64 loss: 0.20833301544189453
Batch 23/64 loss: 0.1946057677268982
Batch 24/64 loss: 0.21822422742843628
Batch 25/64 loss: 0.19557899236679077
Batch 26/64 loss: 0.19682222604751587
Batch 27/64 loss: 0.20067214965820312
Batch 28/64 loss: 0.19861358404159546
Batch 29/64 loss: 0.2004486322402954
Batch 30/64 loss: 0.20995211601257324
Batch 31/64 loss: 0.1991896629333496
Batch 32/64 loss: 0.19936418533325195
Batch 33/64 loss: 0.1920430064201355
Batch 34/64 loss: 0.2000446319580078
Batch 35/64 loss: 0.20255303382873535
Batch 36/64 loss: 0.2052655816078186
Batch 37/64 loss: 0.19146490097045898
Batch 38/64 loss: 0.2201526165008545
Batch 39/64 loss: 0.20213043689727783
Batch 40/64 loss: 0.1975160837173462
Batch 41/64 loss: 0.20416367053985596
Batch 42/64 loss: 0.2087520956993103
Batch 43/64 loss: 0.1996852159500122
Batch 44/64 loss: 0.20708173513412476
Batch 45/64 loss: 0.1977488398551941
Batch 46/64 loss: 0.20709943771362305
Batch 47/64 loss: 0.19345176219940186
Batch 48/64 loss: 0.1976202130317688
Batch 49/64 loss: 0.20301318168640137
Batch 50/64 loss: 0.1999441385269165
Batch 51/64 loss: 0.20066910982131958
Batch 52/64 loss: 0.19715583324432373
Batch 53/64 loss: 0.20683050155639648
Batch 54/64 loss: 0.2112342119216919
Batch 55/64 loss: 0.20661062002182007
Batch 56/64 loss: 0.21216702461242676
Batch 57/64 loss: 0.1993943452835083
Batch 58/64 loss: 0.21474164724349976
Batch 59/64 loss: 0.20616531372070312
Batch 60/64 loss: 0.20050585269927979
Batch 61/64 loss: 0.2057664394378662
Batch 62/64 loss: 0.20451712608337402
Batch 63/64 loss: 0.20358705520629883
Batch 64/64 loss: 0.1931900978088379
Epoch 430  Train loss: 0.20213295618693033  Val loss: 0.2695644667877774
Epoch 431
-------------------------------
Batch 1/64 loss: 0.20874887704849243
Batch 2/64 loss: 0.20085811614990234
Batch 3/64 loss: 0.19886010885238647
Batch 4/64 loss: 0.19369566440582275
Batch 5/64 loss: 0.2046668529510498
Batch 6/64 loss: 0.19644850492477417
Batch 7/64 loss: 0.21856999397277832
Batch 8/64 loss: 0.19303864240646362
Batch 9/64 loss: 0.20047062635421753
Batch 10/64 loss: 0.197554349899292
Batch 11/64 loss: 0.20125079154968262
Batch 12/64 loss: 0.1910800337791443
Batch 13/64 loss: 0.20564258098602295
Batch 14/64 loss: 0.21033835411071777
Batch 15/64 loss: 0.20187276601791382
Batch 16/64 loss: 0.20189452171325684
Batch 17/64 loss: 0.22751152515411377
Batch 18/64 loss: 0.20526665449142456
Batch 19/64 loss: 0.20295560359954834
Batch 20/64 loss: 0.19584888219833374
Batch 21/64 loss: 0.20005226135253906
Batch 22/64 loss: 0.1907978057861328
Batch 23/64 loss: 0.19938504695892334
Batch 24/64 loss: 0.19985860586166382
Batch 25/64 loss: 0.20517510175704956
Batch 26/64 loss: 0.2032334804534912
Batch 27/64 loss: 0.19129717350006104
Batch 28/64 loss: 0.20163887739181519
Batch 29/64 loss: 0.20246684551239014
Batch 30/64 loss: 0.19949185848236084
Batch 31/64 loss: 0.18938392400741577
Batch 32/64 loss: 0.20761585235595703
Batch 33/64 loss: 0.20471900701522827
Batch 34/64 loss: 0.20309382677078247
Batch 35/64 loss: 0.2140546441078186
Batch 36/64 loss: 0.2080620527267456
Batch 37/64 loss: 0.19681501388549805
Batch 38/64 loss: 0.20967251062393188
Batch 39/64 loss: 0.20008474588394165
Batch 40/64 loss: 0.2080797553062439
Batch 41/64 loss: 0.1982688307762146
Batch 42/64 loss: 0.19663900136947632
Batch 43/64 loss: 0.20275527238845825
Batch 44/64 loss: 0.2099875807762146
Batch 45/64 loss: 0.19928359985351562
Batch 46/64 loss: 0.20804810523986816
Batch 47/64 loss: 0.19323670864105225
Batch 48/64 loss: 0.2028512954711914
Batch 49/64 loss: 0.20259422063827515
Batch 50/64 loss: 0.2065855860710144
Batch 51/64 loss: 0.20516586303710938
Batch 52/64 loss: 0.20110249519348145
Batch 53/64 loss: 0.20013773441314697
Batch 54/64 loss: 0.20302700996398926
Batch 55/64 loss: 0.20151352882385254
Batch 56/64 loss: 0.21881508827209473
Batch 57/64 loss: 0.2063344120979309
Batch 58/64 loss: 0.19959640502929688
Batch 59/64 loss: 0.20254021883010864
Batch 60/64 loss: 0.1952366828918457
Batch 61/64 loss: 0.19760358333587646
Batch 62/64 loss: 0.21099650859832764
Batch 63/64 loss: 0.20262491703033447
Batch 64/64 loss: 0.2055797576904297
Epoch 431  Train loss: 0.20252049109515022  Val loss: 0.27013843247980596
Epoch 432
-------------------------------
Batch 1/64 loss: 0.21010112762451172
Batch 2/64 loss: 0.1969444751739502
Batch 3/64 loss: 0.19084441661834717
Batch 4/64 loss: 0.20397299528121948
Batch 5/64 loss: 0.21373021602630615
Batch 6/64 loss: 0.20378273725509644
Batch 7/64 loss: 0.20525598526000977
Batch 8/64 loss: 0.19740241765975952
Batch 9/64 loss: 0.2044905424118042
Batch 10/64 loss: 0.20344936847686768
Batch 11/64 loss: 0.2023078203201294
Batch 12/64 loss: 0.1969749927520752
Batch 13/64 loss: 0.20123803615570068
Batch 14/64 loss: 0.2051129937171936
Batch 15/64 loss: 0.19447851181030273
Batch 16/64 loss: 0.20284998416900635
Batch 17/64 loss: 0.20395010709762573
Batch 18/64 loss: 0.2045843005180359
Batch 19/64 loss: 0.21332871913909912
Batch 20/64 loss: 0.19663578271865845
Batch 21/64 loss: 0.19130313396453857
Batch 22/64 loss: 0.20484423637390137
Batch 23/64 loss: 0.1973639726638794
Batch 24/64 loss: 0.21483737230300903
Batch 25/64 loss: 0.20056509971618652
Batch 26/64 loss: 0.19542229175567627
Batch 27/64 loss: 0.1941138505935669
Batch 28/64 loss: 0.20992720127105713
Batch 29/64 loss: 0.20141631364822388
Batch 30/64 loss: 0.2042403221130371
Batch 31/64 loss: 0.20692598819732666
Batch 32/64 loss: 0.19158798456192017
Batch 33/64 loss: 0.19774460792541504
Batch 34/64 loss: 0.20048928260803223
Batch 35/64 loss: 0.194194495677948
Batch 36/64 loss: 0.2118532657623291
Batch 37/64 loss: 0.20662212371826172
Batch 38/64 loss: 0.2041286826133728
Batch 39/64 loss: 0.20417457818984985
Batch 40/64 loss: 0.20165270566940308
Batch 41/64 loss: 0.20136809349060059
Batch 42/64 loss: 0.20290321111679077
Batch 43/64 loss: 0.20301580429077148
Batch 44/64 loss: 0.21144378185272217
Batch 45/64 loss: 0.20560413599014282
Batch 46/64 loss: 0.20761728286743164
Batch 47/64 loss: 0.19987982511520386
Batch 48/64 loss: 0.21060538291931152
Batch 49/64 loss: 0.19821208715438843
Batch 50/64 loss: 0.20216864347457886
Batch 51/64 loss: 0.1993502974510193
Batch 52/64 loss: 0.19444239139556885
Batch 53/64 loss: 0.20090341567993164
Batch 54/64 loss: 0.20129776000976562
Batch 55/64 loss: 0.2060670256614685
Batch 56/64 loss: 0.20192646980285645
Batch 57/64 loss: 0.19847363233566284
Batch 58/64 loss: 0.19353336095809937
Batch 59/64 loss: 0.20099729299545288
Batch 60/64 loss: 0.2066553831100464
Batch 61/64 loss: 0.19699591398239136
Batch 62/64 loss: 0.18870019912719727
Batch 63/64 loss: 0.20382285118103027
Batch 64/64 loss: 0.20575833320617676
Epoch 432  Train loss: 0.2019630750020345  Val loss: 0.2706512169739635
Epoch 433
-------------------------------
Batch 1/64 loss: 0.20228362083435059
Batch 2/64 loss: 0.193526029586792
Batch 3/64 loss: 0.19568252563476562
Batch 4/64 loss: 0.19776862859725952
Batch 5/64 loss: 0.20746123790740967
Batch 6/64 loss: 0.18779540061950684
Batch 7/64 loss: 0.20941901206970215
Batch 8/64 loss: 0.20965981483459473
Batch 9/64 loss: 0.2011023759841919
Batch 10/64 loss: 0.20149868726730347
Batch 11/64 loss: 0.20655477046966553
Batch 12/64 loss: 0.1910858154296875
Batch 13/64 loss: 0.19402509927749634
Batch 14/64 loss: 0.19368672370910645
Batch 15/64 loss: 0.20718997716903687
Batch 16/64 loss: 0.20181262493133545
Batch 17/64 loss: 0.19569718837738037
Batch 18/64 loss: 0.20003139972686768
Batch 19/64 loss: 0.19186532497406006
Batch 20/64 loss: 0.19573700428009033
Batch 21/64 loss: 0.1994726061820984
Batch 22/64 loss: 0.20377159118652344
Batch 23/64 loss: 0.20955193042755127
Batch 24/64 loss: 0.20092451572418213
Batch 25/64 loss: 0.20719170570373535
Batch 26/64 loss: 0.2021327018737793
Batch 27/64 loss: 0.20058226585388184
Batch 28/64 loss: 0.20144641399383545
Batch 29/64 loss: 0.19520896673202515
Batch 30/64 loss: 0.2014210820198059
Batch 31/64 loss: 0.20685696601867676
Batch 32/64 loss: 0.2073272466659546
Batch 33/64 loss: 0.19742029905319214
Batch 34/64 loss: 0.2062070369720459
Batch 35/64 loss: 0.19556784629821777
Batch 36/64 loss: 0.20331662893295288
Batch 37/64 loss: 0.19577062129974365
Batch 38/64 loss: 0.19843578338623047
Batch 39/64 loss: 0.20226675271987915
Batch 40/64 loss: 0.19445109367370605
Batch 41/64 loss: 0.19802320003509521
Batch 42/64 loss: 0.20669788122177124
Batch 43/64 loss: 0.20205271244049072
Batch 44/64 loss: 0.19918334484100342
Batch 45/64 loss: 0.2016434669494629
Batch 46/64 loss: 0.20471525192260742
Batch 47/64 loss: 0.19729465246200562
Batch 48/64 loss: 0.2012573480606079
Batch 49/64 loss: 0.2070223093032837
Batch 50/64 loss: 0.21193701028823853
Batch 51/64 loss: 0.19824641942977905
Batch 52/64 loss: 0.20848733186721802
Batch 53/64 loss: 0.20944803953170776
Batch 54/64 loss: 0.20522600412368774
Batch 55/64 loss: 0.20561516284942627
Batch 56/64 loss: 0.2132834792137146
Batch 57/64 loss: 0.1950398087501526
Batch 58/64 loss: 0.19845396280288696
Batch 59/64 loss: 0.2069488763809204
Batch 60/64 loss: 0.20518416166305542
Batch 61/64 loss: 0.206337571144104
Batch 62/64 loss: 0.2090308666229248
Batch 63/64 loss: 0.20222985744476318
Batch 64/64 loss: 0.2188895344734192
Epoch 433  Train loss: 0.20189385390749165  Val loss: 0.26985989423961576
Epoch 434
-------------------------------
Batch 1/64 loss: 0.19673413038253784
Batch 2/64 loss: 0.19889897108078003
Batch 3/64 loss: 0.19136905670166016
Batch 4/64 loss: 0.19805371761322021
Batch 5/64 loss: 0.1983521580696106
Batch 6/64 loss: 0.19546377658843994
Batch 7/64 loss: 0.2140464186668396
Batch 8/64 loss: 0.20552140474319458
Batch 9/64 loss: 0.1977548599243164
Batch 10/64 loss: 0.2075558304786682
Batch 11/64 loss: 0.19898182153701782
Batch 12/64 loss: 0.2091907262802124
Batch 13/64 loss: 0.19521194696426392
Batch 14/64 loss: 0.19553649425506592
Batch 15/64 loss: 0.2027689814567566
Batch 16/64 loss: 0.2084299921989441
Batch 17/64 loss: 0.19849586486816406
Batch 18/64 loss: 0.2009732723236084
Batch 19/64 loss: 0.18925714492797852
Batch 20/64 loss: 0.19639801979064941
Batch 21/64 loss: 0.19326400756835938
Batch 22/64 loss: 0.19883763790130615
Batch 23/64 loss: 0.1977781057357788
Batch 24/64 loss: 0.21432220935821533
Batch 25/64 loss: 0.2003059983253479
Batch 26/64 loss: 0.2084745168685913
Batch 27/64 loss: 0.21779727935791016
Batch 28/64 loss: 0.1995481252670288
Batch 29/64 loss: 0.22265124320983887
Batch 30/64 loss: 0.1969836950302124
Batch 31/64 loss: 0.19512492418289185
Batch 32/64 loss: 0.209183931350708
Batch 33/64 loss: 0.1975926160812378
Batch 34/64 loss: 0.20611560344696045
Batch 35/64 loss: 0.19583404064178467
Batch 36/64 loss: 0.2046704888343811
Batch 37/64 loss: 0.1992841362953186
Batch 38/64 loss: 0.1981523633003235
Batch 39/64 loss: 0.21679985523223877
Batch 40/64 loss: 0.19891875982284546
Batch 41/64 loss: 0.20321249961853027
Batch 42/64 loss: 0.1985405683517456
Batch 43/64 loss: 0.20036637783050537
Batch 44/64 loss: 0.20031648874282837
Batch 45/64 loss: 0.2057400941848755
Batch 46/64 loss: 0.19644570350646973
Batch 47/64 loss: 0.20535778999328613
Batch 48/64 loss: 0.1981600522994995
Batch 49/64 loss: 0.19805270433425903
Batch 50/64 loss: 0.1987287402153015
Batch 51/64 loss: 0.20531445741653442
Batch 52/64 loss: 0.20568984746932983
Batch 53/64 loss: 0.19627869129180908
Batch 54/64 loss: 0.19806957244873047
Batch 55/64 loss: 0.19512665271759033
Batch 56/64 loss: 0.2062091827392578
Batch 57/64 loss: 0.20132982730865479
Batch 58/64 loss: 0.22335094213485718
Batch 59/64 loss: 0.19704079627990723
Batch 60/64 loss: 0.20068567991256714
Batch 61/64 loss: 0.20303523540496826
Batch 62/64 loss: 0.19983667135238647
Batch 63/64 loss: 0.21705323457717896
Batch 64/64 loss: 0.20505183935165405
Epoch 434  Train loss: 0.20201356574600818  Val loss: 0.26989571622147185
Epoch 435
-------------------------------
Batch 1/64 loss: 0.19316303730010986
Batch 2/64 loss: 0.20752274990081787
Batch 3/64 loss: 0.19058483839035034
Batch 4/64 loss: 0.20507633686065674
Batch 5/64 loss: 0.19373846054077148
Batch 6/64 loss: 0.20965123176574707
Batch 7/64 loss: 0.20668935775756836
Batch 8/64 loss: 0.20998597145080566
Batch 9/64 loss: 0.19552022218704224
Batch 10/64 loss: 0.20403671264648438
Batch 11/64 loss: 0.20006859302520752
Batch 12/64 loss: 0.21018964052200317
Batch 13/64 loss: 0.19447678327560425
Batch 14/64 loss: 0.20610564947128296
Batch 15/64 loss: 0.19534868001937866
Batch 16/64 loss: 0.20845115184783936
Batch 17/64 loss: 0.19677388668060303
Batch 18/64 loss: 0.19995999336242676
Batch 19/64 loss: 0.19903117418289185
Batch 20/64 loss: 0.20058107376098633
Batch 21/64 loss: 0.19670867919921875
Batch 22/64 loss: 0.20706522464752197
Batch 23/64 loss: 0.2011420726776123
Batch 24/64 loss: 0.1963266134262085
Batch 25/64 loss: 0.20413392782211304
Batch 26/64 loss: 0.1952836513519287
Batch 27/64 loss: 0.1995047926902771
Batch 28/64 loss: 0.2045266032218933
Batch 29/64 loss: 0.19079095125198364
Batch 30/64 loss: 0.20298349857330322
Batch 31/64 loss: 0.2103467583656311
Batch 32/64 loss: 0.19788086414337158
Batch 33/64 loss: 0.20299267768859863
Batch 34/64 loss: 0.19293707609176636
Batch 35/64 loss: 0.20332050323486328
Batch 36/64 loss: 0.20187777280807495
Batch 37/64 loss: 0.19442373514175415
Batch 38/64 loss: 0.2082497477531433
Batch 39/64 loss: 0.19301754236221313
Batch 40/64 loss: 0.1919957399368286
Batch 41/64 loss: 0.197562575340271
Batch 42/64 loss: 0.2012042999267578
Batch 43/64 loss: 0.20408183336257935
Batch 44/64 loss: 0.21095091104507446
Batch 45/64 loss: 0.19836479425430298
Batch 46/64 loss: 0.2026105523109436
Batch 47/64 loss: 0.21319341659545898
Batch 48/64 loss: 0.20075905323028564
Batch 49/64 loss: 0.21149682998657227
Batch 50/64 loss: 0.2039508819580078
Batch 51/64 loss: 0.20383048057556152
Batch 52/64 loss: 0.21132469177246094
Batch 53/64 loss: 0.20495015382766724
Batch 54/64 loss: 0.2199944257736206
Batch 55/64 loss: 0.19968533515930176
Batch 56/64 loss: 0.1981448531150818
Batch 57/64 loss: 0.20322322845458984
Batch 58/64 loss: 0.19796514511108398
Batch 59/64 loss: 0.20247626304626465
Batch 60/64 loss: 0.19503718614578247
Batch 61/64 loss: 0.19803690910339355
Batch 62/64 loss: 0.2004261016845703
Batch 63/64 loss: 0.21231937408447266
Batch 64/64 loss: 0.2006453275680542
Epoch 435  Train loss: 0.2017966630412083  Val loss: 0.270438932266432
Epoch 436
-------------------------------
Batch 1/64 loss: 0.19959568977355957
Batch 2/64 loss: 0.19929122924804688
Batch 3/64 loss: 0.18652236461639404
Batch 4/64 loss: 0.19621682167053223
Batch 5/64 loss: 0.20086801052093506
Batch 6/64 loss: 0.20400702953338623
Batch 7/64 loss: 0.1975620985031128
Batch 8/64 loss: 0.19688421487808228
Batch 9/64 loss: 0.19731390476226807
Batch 10/64 loss: 0.20594793558120728
Batch 11/64 loss: 0.21149969100952148
Batch 12/64 loss: 0.2072685956954956
Batch 13/64 loss: 0.19270318746566772
Batch 14/64 loss: 0.19840556383132935
Batch 15/64 loss: 0.1934053897857666
Batch 16/64 loss: 0.20189136266708374
Batch 17/64 loss: 0.22217226028442383
Batch 18/64 loss: 0.21832013130187988
Batch 19/64 loss: 0.19493132829666138
Batch 20/64 loss: 0.19504547119140625
Batch 21/64 loss: 0.1967877745628357
Batch 22/64 loss: 0.20425254106521606
Batch 23/64 loss: 0.19869476556777954
Batch 24/64 loss: 0.20129096508026123
Batch 25/64 loss: 0.1916654109954834
Batch 26/64 loss: 0.2022339105606079
Batch 27/64 loss: 0.2057873010635376
Batch 28/64 loss: 0.20401817560195923
Batch 29/64 loss: 0.20161950588226318
Batch 30/64 loss: 0.19329607486724854
Batch 31/64 loss: 0.20338565111160278
Batch 32/64 loss: 0.19763720035552979
Batch 33/64 loss: 0.1999184489250183
Batch 34/64 loss: 0.20525044202804565
Batch 35/64 loss: 0.19905823469161987
Batch 36/64 loss: 0.21187710762023926
Batch 37/64 loss: 0.1999186873435974
Batch 38/64 loss: 0.2055894136428833
Batch 39/64 loss: 0.20591187477111816
Batch 40/64 loss: 0.20570147037506104
Batch 41/64 loss: 0.19698011875152588
Batch 42/64 loss: 0.19848161935806274
Batch 43/64 loss: 0.19644808769226074
Batch 44/64 loss: 0.20215058326721191
Batch 45/64 loss: 0.2076956033706665
Batch 46/64 loss: 0.20232713222503662
Batch 47/64 loss: 0.18822866678237915
Batch 48/64 loss: 0.20093560218811035
Batch 49/64 loss: 0.1985490322113037
Batch 50/64 loss: 0.19754838943481445
Batch 51/64 loss: 0.20415353775024414
Batch 52/64 loss: 0.20288145542144775
Batch 53/64 loss: 0.20047569274902344
Batch 54/64 loss: 0.20856869220733643
Batch 55/64 loss: 0.20038527250289917
Batch 56/64 loss: 0.19881248474121094
Batch 57/64 loss: 0.19931113719940186
Batch 58/64 loss: 0.20035505294799805
Batch 59/64 loss: 0.19755297899246216
Batch 60/64 loss: 0.2108122706413269
Batch 61/64 loss: 0.20010018348693848
Batch 62/64 loss: 0.20600831508636475
Batch 63/64 loss: 0.21279895305633545
Batch 64/64 loss: 0.19457638263702393
Epoch 436  Train loss: 0.2012743589924831  Val loss: 0.270009784764031
Epoch 437
-------------------------------
Batch 1/64 loss: 0.20037364959716797
Batch 2/64 loss: 0.19531571865081787
Batch 3/64 loss: 0.19788676500320435
Batch 4/64 loss: 0.1953730583190918
Batch 5/64 loss: 0.19807326793670654
Batch 6/64 loss: 0.18946123123168945
Batch 7/64 loss: 0.20126104354858398
Batch 8/64 loss: 0.19890499114990234
Batch 9/64 loss: 0.20660507678985596
Batch 10/64 loss: 0.2010331153869629
Batch 11/64 loss: 0.19434738159179688
Batch 12/64 loss: 0.19111746549606323
Batch 13/64 loss: 0.19565153121948242
Batch 14/64 loss: 0.20158463716506958
Batch 15/64 loss: 0.2012643814086914
Batch 16/64 loss: 0.19519269466400146
Batch 17/64 loss: 0.2038787603378296
Batch 18/64 loss: 0.19762074947357178
Batch 19/64 loss: 0.20659667253494263
Batch 20/64 loss: 0.19532877206802368
Batch 21/64 loss: 0.20288962125778198
Batch 22/64 loss: 0.20612692832946777
Batch 23/64 loss: 0.21259474754333496
Batch 24/64 loss: 0.19518429040908813
Batch 25/64 loss: 0.19508713483810425
Batch 26/64 loss: 0.212935209274292
Batch 27/64 loss: 0.20992153882980347
Batch 28/64 loss: 0.20086044073104858
Batch 29/64 loss: 0.212998628616333
Batch 30/64 loss: 0.2068617343902588
Batch 31/64 loss: 0.19888460636138916
Batch 32/64 loss: 0.20886313915252686
Batch 33/64 loss: 0.2021040916442871
Batch 34/64 loss: 0.19894593954086304
Batch 35/64 loss: 0.19256871938705444
Batch 36/64 loss: 0.1929134726524353
Batch 37/64 loss: 0.1968153715133667
Batch 38/64 loss: 0.20894145965576172
Batch 39/64 loss: 0.2056664228439331
Batch 40/64 loss: 0.1976780891418457
Batch 41/64 loss: 0.2031494379043579
Batch 42/64 loss: 0.1965886354446411
Batch 43/64 loss: 0.197792649269104
Batch 44/64 loss: 0.1992858648300171
Batch 45/64 loss: 0.1981896162033081
Batch 46/64 loss: 0.20491808652877808
Batch 47/64 loss: 0.2091590166091919
Batch 48/64 loss: 0.19697481393814087
Batch 49/64 loss: 0.20466077327728271
Batch 50/64 loss: 0.21153932809829712
Batch 51/64 loss: 0.20495635271072388
Batch 52/64 loss: 0.20343536138534546
Batch 53/64 loss: 0.19920307397842407
Batch 54/64 loss: 0.2062193751335144
Batch 55/64 loss: 0.2114417552947998
Batch 56/64 loss: 0.205330491065979
Batch 57/64 loss: 0.20429521799087524
Batch 58/64 loss: 0.20019280910491943
Batch 59/64 loss: 0.20234346389770508
Batch 60/64 loss: 0.2080249786376953
Batch 61/64 loss: 0.20350176095962524
Batch 62/64 loss: 0.20640403032302856
Batch 63/64 loss: 0.199049174785614
Batch 64/64 loss: 0.1960621476173401
Epoch 437  Train loss: 0.20155945455326754  Val loss: 0.2698919564178309
Epoch 438
-------------------------------
Batch 1/64 loss: 0.20547783374786377
Batch 2/64 loss: 0.19337928295135498
Batch 3/64 loss: 0.1976587176322937
Batch 4/64 loss: 0.2028876543045044
Batch 5/64 loss: 0.1967962384223938
Batch 6/64 loss: 0.1930742859840393
Batch 7/64 loss: 0.194915771484375
Batch 8/64 loss: 0.19747000932693481
Batch 9/64 loss: 0.1981651782989502
Batch 10/64 loss: 0.19878482818603516
Batch 11/64 loss: 0.20969903469085693
Batch 12/64 loss: 0.20093649625778198
Batch 13/64 loss: 0.20898044109344482
Batch 14/64 loss: 0.20221680402755737
Batch 15/64 loss: 0.2119775414466858
Batch 16/64 loss: 0.19972378015518188
Batch 17/64 loss: 0.20799744129180908
Batch 18/64 loss: 0.20737290382385254
Batch 19/64 loss: 0.20308107137680054
Batch 20/64 loss: 0.19208455085754395
Batch 21/64 loss: 0.19738692045211792
Batch 22/64 loss: 0.21022498607635498
Batch 23/64 loss: 0.19458091259002686
Batch 24/64 loss: 0.2068842649459839
Batch 25/64 loss: 0.19822287559509277
Batch 26/64 loss: 0.20526450872421265
Batch 27/64 loss: 0.2016391158103943
Batch 28/64 loss: 0.19534820318222046
Batch 29/64 loss: 0.20072555541992188
Batch 30/64 loss: 0.20170843601226807
Batch 31/64 loss: 0.19563454389572144
Batch 32/64 loss: 0.19930589199066162
Batch 33/64 loss: 0.19730490446090698
Batch 34/64 loss: 0.2051103115081787
Batch 35/64 loss: 0.20312660932540894
Batch 36/64 loss: 0.19580978155136108
Batch 37/64 loss: 0.20479166507720947
Batch 38/64 loss: 0.19664627313613892
Batch 39/64 loss: 0.2012847661972046
Batch 40/64 loss: 0.20118045806884766
Batch 41/64 loss: 0.19876253604888916
Batch 42/64 loss: 0.20363974571228027
Batch 43/64 loss: 0.2005765438079834
Batch 44/64 loss: 0.2005903720855713
Batch 45/64 loss: 0.19274699687957764
Batch 46/64 loss: 0.19439095258712769
Batch 47/64 loss: 0.1984717845916748
Batch 48/64 loss: 0.2016318440437317
Batch 49/64 loss: 0.19740724563598633
Batch 50/64 loss: 0.20288366079330444
Batch 51/64 loss: 0.19931215047836304
Batch 52/64 loss: 0.2131308913230896
Batch 53/64 loss: 0.19976389408111572
Batch 54/64 loss: 0.1984742283821106
Batch 55/64 loss: 0.21388399600982666
Batch 56/64 loss: 0.19830334186553955
Batch 57/64 loss: 0.20436418056488037
Batch 58/64 loss: 0.2086348533630371
Batch 59/64 loss: 0.20219862461090088
Batch 60/64 loss: 0.20039516687393188
Batch 61/64 loss: 0.2041257619857788
Batch 62/64 loss: 0.20593410730361938
Batch 63/64 loss: 0.205818772315979
Batch 64/64 loss: 0.21246302127838135
Epoch 438  Train loss: 0.20140627084993848  Val loss: 0.26970306090063245
Epoch 439
-------------------------------
Batch 1/64 loss: 0.2035272717475891
Batch 2/64 loss: 0.2153700590133667
Batch 3/64 loss: 0.20260381698608398
Batch 4/64 loss: 0.20775854587554932
Batch 5/64 loss: 0.20039641857147217
Batch 6/64 loss: 0.19422101974487305
Batch 7/64 loss: 0.20341980457305908
Batch 8/64 loss: 0.19801491498947144
Batch 9/64 loss: 0.20130670070648193
Batch 10/64 loss: 0.19192087650299072
Batch 11/64 loss: 0.1917610764503479
Batch 12/64 loss: 0.19830775260925293
Batch 13/64 loss: 0.1890500783920288
Batch 14/64 loss: 0.20465075969696045
Batch 15/64 loss: 0.20162475109100342
Batch 16/64 loss: 0.2069748044013977
Batch 17/64 loss: 0.19994091987609863
Batch 18/64 loss: 0.20438170433044434
Batch 19/64 loss: 0.19509637355804443
Batch 20/64 loss: 0.21333694458007812
Batch 21/64 loss: 0.19756782054901123
Batch 22/64 loss: 0.19900596141815186
Batch 23/64 loss: 0.2041657567024231
Batch 24/64 loss: 0.20406180620193481
Batch 25/64 loss: 0.20031899213790894
Batch 26/64 loss: 0.19991862773895264
Batch 27/64 loss: 0.20135152339935303
Batch 28/64 loss: 0.19635480642318726
Batch 29/64 loss: 0.20161479711532593
Batch 30/64 loss: 0.20144671201705933
Batch 31/64 loss: 0.2021191120147705
Batch 32/64 loss: 0.20023179054260254
Batch 33/64 loss: 0.19288724660873413
Batch 34/64 loss: 0.20347195863723755
Batch 35/64 loss: 0.19532448053359985
Batch 36/64 loss: 0.1915673017501831
Batch 37/64 loss: 0.1957871913909912
Batch 38/64 loss: 0.20191174745559692
Batch 39/64 loss: 0.19056737422943115
Batch 40/64 loss: 0.21345174312591553
Batch 41/64 loss: 0.19907736778259277
Batch 42/64 loss: 0.19527673721313477
Batch 43/64 loss: 0.2001538872718811
Batch 44/64 loss: 0.1959446668624878
Batch 45/64 loss: 0.19784677028656006
Batch 46/64 loss: 0.20564091205596924
Batch 47/64 loss: 0.20027238130569458
Batch 48/64 loss: 0.2051371932029724
Batch 49/64 loss: 0.20193719863891602
Batch 50/64 loss: 0.2028796672821045
Batch 51/64 loss: 0.20773077011108398
Batch 52/64 loss: 0.1900511384010315
Batch 53/64 loss: 0.19999903440475464
Batch 54/64 loss: 0.18998652696609497
Batch 55/64 loss: 0.19691836833953857
Batch 56/64 loss: 0.20069986581802368
Batch 57/64 loss: 0.20459610223770142
Batch 58/64 loss: 0.19589000940322876
Batch 59/64 loss: 0.20158731937408447
Batch 60/64 loss: 0.20186477899551392
Batch 61/64 loss: 0.19821053743362427
Batch 62/64 loss: 0.20405423641204834
Batch 63/64 loss: 0.20321351289749146
Batch 64/64 loss: 0.1962934136390686
Epoch 439  Train loss: 0.20020361390768313  Val loss: 0.2694709442325474
Epoch 440
-------------------------------
Batch 1/64 loss: 0.20434534549713135
Batch 2/64 loss: 0.18873977661132812
Batch 3/64 loss: 0.1963176727294922
Batch 4/64 loss: 0.200422465801239
Batch 5/64 loss: 0.1942753791809082
Batch 6/64 loss: 0.19721120595932007
Batch 7/64 loss: 0.20219933986663818
Batch 8/64 loss: 0.2065906524658203
Batch 9/64 loss: 0.199415385723114
Batch 10/64 loss: 0.19465363025665283
Batch 11/64 loss: 0.2053852081298828
Batch 12/64 loss: 0.20239228010177612
Batch 13/64 loss: 0.20295941829681396
Batch 14/64 loss: 0.18876057863235474
Batch 15/64 loss: 0.20028233528137207
Batch 16/64 loss: 0.1995624303817749
Batch 17/64 loss: 0.19150590896606445
Batch 18/64 loss: 0.19373750686645508
Batch 19/64 loss: 0.19428551197052002
Batch 20/64 loss: 0.1955980658531189
Batch 21/64 loss: 0.20104873180389404
Batch 22/64 loss: 0.19955289363861084
Batch 23/64 loss: 0.19323581457138062
Batch 24/64 loss: 0.21075361967086792
Batch 25/64 loss: 0.1945871114730835
Batch 26/64 loss: 0.19875657558441162
Batch 27/64 loss: 0.2107304334640503
Batch 28/64 loss: 0.19485729932785034
Batch 29/64 loss: 0.20486605167388916
Batch 30/64 loss: 0.20866906642913818
Batch 31/64 loss: 0.2080715298652649
Batch 32/64 loss: 0.2036830186843872
Batch 33/64 loss: 0.20457863807678223
Batch 34/64 loss: 0.2000529170036316
Batch 35/64 loss: 0.19199275970458984
Batch 36/64 loss: 0.20918571949005127
Batch 37/64 loss: 0.193578839302063
Batch 38/64 loss: 0.2030612826347351
Batch 39/64 loss: 0.19151759147644043
Batch 40/64 loss: 0.19632583856582642
Batch 41/64 loss: 0.19932037591934204
Batch 42/64 loss: 0.20464175939559937
Batch 43/64 loss: 0.19848722219467163
Batch 44/64 loss: 0.20501989126205444
Batch 45/64 loss: 0.1878875494003296
Batch 46/64 loss: 0.20093822479248047
Batch 47/64 loss: 0.2126954197883606
Batch 48/64 loss: 0.19997715950012207
Batch 49/64 loss: 0.19028478860855103
Batch 50/64 loss: 0.2007521390914917
Batch 51/64 loss: 0.201005220413208
Batch 52/64 loss: 0.19938063621520996
Batch 53/64 loss: 0.2154407501220703
Batch 54/64 loss: 0.19560867547988892
Batch 55/64 loss: 0.1971515417098999
Batch 56/64 loss: 0.19723010063171387
Batch 57/64 loss: 0.20132410526275635
Batch 58/64 loss: 0.20792245864868164
Batch 59/64 loss: 0.19720113277435303
Batch 60/64 loss: 0.19912761449813843
Batch 61/64 loss: 0.2028341293334961
Batch 62/64 loss: 0.20459610223770142
Batch 63/64 loss: 0.19779622554779053
Batch 64/64 loss: 0.19783025979995728
Epoch 440  Train loss: 0.1998861450774997  Val loss: 0.2694298106780167
Epoch 441
-------------------------------
Batch 1/64 loss: 0.19776254892349243
Batch 2/64 loss: 0.20086067914962769
Batch 3/64 loss: 0.19800245761871338
Batch 4/64 loss: 0.20304113626480103
Batch 5/64 loss: 0.20510882139205933
Batch 6/64 loss: 0.19628256559371948
Batch 7/64 loss: 0.1958490014076233
Batch 8/64 loss: 0.20770567655563354
Batch 9/64 loss: 0.2071373462677002
Batch 10/64 loss: 0.19637227058410645
Batch 11/64 loss: 0.19074082374572754
Batch 12/64 loss: 0.19713616371154785
Batch 13/64 loss: 0.21294474601745605
Batch 14/64 loss: 0.19855839014053345
Batch 15/64 loss: 0.19951319694519043
Batch 16/64 loss: 0.19779562950134277
Batch 17/64 loss: 0.193470299243927
Batch 18/64 loss: 0.19833767414093018
Batch 19/64 loss: 0.19811558723449707
Batch 20/64 loss: 0.2008676528930664
Batch 21/64 loss: 0.2053954005241394
Batch 22/64 loss: 0.19920098781585693
Batch 23/64 loss: 0.20424211025238037
Batch 24/64 loss: 0.20201164484024048
Batch 25/64 loss: 0.1944987177848816
Batch 26/64 loss: 0.19811803102493286
Batch 27/64 loss: 0.19714176654815674
Batch 28/64 loss: 0.21277010440826416
Batch 29/64 loss: 0.20535248517990112
Batch 30/64 loss: 0.20241671800613403
Batch 31/64 loss: 0.21224665641784668
Batch 32/64 loss: 0.19091707468032837
Batch 33/64 loss: 0.19956886768341064
Batch 34/64 loss: 0.195542573928833
Batch 35/64 loss: 0.18828117847442627
Batch 36/64 loss: 0.20387810468673706
Batch 37/64 loss: 0.19808191061019897
Batch 38/64 loss: 0.19747525453567505
Batch 39/64 loss: 0.19477367401123047
Batch 40/64 loss: 0.19435620307922363
Batch 41/64 loss: 0.20069414377212524
Batch 42/64 loss: 0.20249402523040771
Batch 43/64 loss: 0.20929032564163208
Batch 44/64 loss: 0.20940089225769043
Batch 45/64 loss: 0.20314091444015503
Batch 46/64 loss: 0.19819611310958862
Batch 47/64 loss: 0.19343101978302002
Batch 48/64 loss: 0.20398426055908203
Batch 49/64 loss: 0.21483361721038818
Batch 50/64 loss: 0.19804561138153076
Batch 51/64 loss: 0.19598370790481567
Batch 52/64 loss: 0.21379101276397705
Batch 53/64 loss: 0.21190190315246582
Batch 54/64 loss: 0.19745194911956787
Batch 55/64 loss: 0.20516610145568848
Batch 56/64 loss: 0.20102226734161377
Batch 57/64 loss: 0.19216442108154297
Batch 58/64 loss: 0.20113533735275269
Batch 59/64 loss: 0.20511364936828613
Batch 60/64 loss: 0.19627535343170166
Batch 61/64 loss: 0.2046254277229309
Batch 62/64 loss: 0.1991555094718933
Batch 63/64 loss: 0.2074025273323059
Batch 64/64 loss: 0.19481688737869263
Epoch 441  Train loss: 0.20082642961950864  Val loss: 0.2692070179378864
Epoch 442
-------------------------------
Batch 1/64 loss: 0.1972021460533142
Batch 2/64 loss: 0.20174288749694824
Batch 3/64 loss: 0.1967395544052124
Batch 4/64 loss: 0.19112849235534668
Batch 5/64 loss: 0.19741201400756836
Batch 6/64 loss: 0.19777143001556396
Batch 7/64 loss: 0.19319623708724976
Batch 8/64 loss: 0.19295352697372437
Batch 9/64 loss: 0.1981348991394043
Batch 10/64 loss: 0.20558393001556396
Batch 11/64 loss: 0.18887054920196533
Batch 12/64 loss: 0.21918487548828125
Batch 13/64 loss: 0.20833975076675415
Batch 14/64 loss: 0.20756244659423828
Batch 15/64 loss: 0.20534002780914307
Batch 16/64 loss: 0.21126866340637207
Batch 17/64 loss: 0.20017898082733154
Batch 18/64 loss: 0.19393277168273926
Batch 19/64 loss: 0.19398844242095947
Batch 20/64 loss: 0.20977407693862915
Batch 21/64 loss: 0.19935983419418335
Batch 22/64 loss: 0.19101017713546753
Batch 23/64 loss: 0.2037668228149414
Batch 24/64 loss: 0.20548725128173828
Batch 25/64 loss: 0.20539450645446777
Batch 26/64 loss: 0.19442182779312134
Batch 27/64 loss: 0.19329404830932617
Batch 28/64 loss: 0.20684653520584106
Batch 29/64 loss: 0.20133554935455322
Batch 30/64 loss: 0.20458656549453735
Batch 31/64 loss: 0.2046605944633484
Batch 32/64 loss: 0.19221580028533936
Batch 33/64 loss: 0.20107245445251465
Batch 34/64 loss: 0.19225019216537476
Batch 35/64 loss: 0.20560985803604126
Batch 36/64 loss: 0.20338821411132812
Batch 37/64 loss: 0.20920902490615845
Batch 38/64 loss: 0.21787911653518677
Batch 39/64 loss: 0.20104444026947021
Batch 40/64 loss: 0.20176732540130615
Batch 41/64 loss: 0.2000492811203003
Batch 42/64 loss: 0.19640803337097168
Batch 43/64 loss: 0.19948440790176392
Batch 44/64 loss: 0.19637566804885864
Batch 45/64 loss: 0.19819581508636475
Batch 46/64 loss: 0.1982567310333252
Batch 47/64 loss: 0.20127397775650024
Batch 48/64 loss: 0.19434064626693726
Batch 49/64 loss: 0.19701611995697021
Batch 50/64 loss: 0.20379436016082764
Batch 51/64 loss: 0.20098507404327393
Batch 52/64 loss: 0.20533812046051025
Batch 53/64 loss: 0.19674181938171387
Batch 54/64 loss: 0.19713622331619263
Batch 55/64 loss: 0.2048320174217224
Batch 56/64 loss: 0.2063501477241516
Batch 57/64 loss: 0.20271772146224976
Batch 58/64 loss: 0.1990354061126709
Batch 59/64 loss: 0.19455623626708984
Batch 60/64 loss: 0.20339959859848022
Batch 61/64 loss: 0.2087770700454712
Batch 62/64 loss: 0.20443904399871826
Batch 63/64 loss: 0.19672417640686035
Batch 64/64 loss: 0.22174161672592163
Epoch 442  Train loss: 0.20105787842881445  Val loss: 0.2709188342504075
Epoch 443
-------------------------------
Batch 1/64 loss: 0.20797795057296753
Batch 2/64 loss: 0.1936635971069336
Batch 3/64 loss: 0.19591766595840454
Batch 4/64 loss: 0.19709569215774536
Batch 5/64 loss: 0.19464337825775146
Batch 6/64 loss: 0.19224929809570312
Batch 7/64 loss: 0.19925600290298462
Batch 8/64 loss: 0.19439208507537842
Batch 9/64 loss: 0.18971467018127441
Batch 10/64 loss: 0.19253087043762207
Batch 11/64 loss: 0.198275625705719
Batch 12/64 loss: 0.18971151113510132
Batch 13/64 loss: 0.19910955429077148
Batch 14/64 loss: 0.2033771276473999
Batch 15/64 loss: 0.187946617603302
Batch 16/64 loss: 0.19113671779632568
Batch 17/64 loss: 0.20718896389007568
Batch 18/64 loss: 0.2137414813041687
Batch 19/64 loss: 0.19885724782943726
Batch 20/64 loss: 0.19117093086242676
Batch 21/64 loss: 0.19715142250061035
Batch 22/64 loss: 0.20641928911209106
Batch 23/64 loss: 0.20464468002319336
Batch 24/64 loss: 0.19808757305145264
Batch 25/64 loss: 0.20930808782577515
Batch 26/64 loss: 0.21090465784072876
Batch 27/64 loss: 0.20442086458206177
Batch 28/64 loss: 0.19690412282943726
Batch 29/64 loss: 0.20907264947891235
Batch 30/64 loss: 0.2087026834487915
Batch 31/64 loss: 0.2053012251853943
Batch 32/64 loss: 0.1996859312057495
Batch 33/64 loss: 0.2109386920928955
Batch 34/64 loss: 0.1977149248123169
Batch 35/64 loss: 0.19813239574432373
Batch 36/64 loss: 0.19247764348983765
Batch 37/64 loss: 0.1902429461479187
Batch 38/64 loss: 0.21032726764678955
Batch 39/64 loss: 0.20625853538513184
Batch 40/64 loss: 0.204196035861969
Batch 41/64 loss: 0.19683730602264404
Batch 42/64 loss: 0.19402742385864258
Batch 43/64 loss: 0.202400803565979
Batch 44/64 loss: 0.194597065448761
Batch 45/64 loss: 0.1937815546989441
Batch 46/64 loss: 0.2038966417312622
Batch 47/64 loss: 0.2033674120903015
Batch 48/64 loss: 0.20328986644744873
Batch 49/64 loss: 0.19264644384384155
Batch 50/64 loss: 0.19744449853897095
Batch 51/64 loss: 0.20633459091186523
Batch 52/64 loss: 0.2117060422897339
Batch 53/64 loss: 0.214821457862854
Batch 54/64 loss: 0.20620155334472656
Batch 55/64 loss: 0.20837020874023438
Batch 56/64 loss: 0.20684361457824707
Batch 57/64 loss: 0.19684600830078125
Batch 58/64 loss: 0.19615709781646729
Batch 59/64 loss: 0.20005011558532715
Batch 60/64 loss: 0.2043834924697876
Batch 61/64 loss: 0.19483286142349243
Batch 62/64 loss: 0.19649124145507812
Batch 63/64 loss: 0.19844478368759155
Batch 64/64 loss: 0.19339144229888916
Epoch 443  Train loss: 0.20027708680021997  Val loss: 0.2699821091599481
Epoch 444
-------------------------------
Batch 1/64 loss: 0.19405698776245117
Batch 2/64 loss: 0.20234555006027222
Batch 3/64 loss: 0.19839680194854736
Batch 4/64 loss: 0.20149189233779907
Batch 5/64 loss: 0.21300125122070312
Batch 6/64 loss: 0.20241641998291016
Batch 7/64 loss: 0.20375388860702515
Batch 8/64 loss: 0.1991405487060547
Batch 9/64 loss: 0.1991930603981018
Batch 10/64 loss: 0.20070183277130127
Batch 11/64 loss: 0.18888503313064575
Batch 12/64 loss: 0.20890522003173828
Batch 13/64 loss: 0.21100127696990967
Batch 14/64 loss: 0.2022038698196411
Batch 15/64 loss: 0.19663220643997192
Batch 16/64 loss: 0.1878507137298584
Batch 17/64 loss: 0.20194655656814575
Batch 18/64 loss: 0.1939437985420227
Batch 19/64 loss: 0.19680887460708618
Batch 20/64 loss: 0.19248133897781372
Batch 21/64 loss: 0.20107674598693848
Batch 22/64 loss: 0.20012110471725464
Batch 23/64 loss: 0.19423043727874756
Batch 24/64 loss: 0.2014167308807373
Batch 25/64 loss: 0.19975697994232178
Batch 26/64 loss: 0.20701688528060913
Batch 27/64 loss: 0.18948912620544434
Batch 28/64 loss: 0.1986958384513855
Batch 29/64 loss: 0.2072068452835083
Batch 30/64 loss: 0.20727574825286865
Batch 31/64 loss: 0.2008402943611145
Batch 32/64 loss: 0.1945154070854187
Batch 33/64 loss: 0.206343412399292
Batch 34/64 loss: 0.20014750957489014
Batch 35/64 loss: 0.19676947593688965
Batch 36/64 loss: 0.20367205142974854
Batch 37/64 loss: 0.18924570083618164
Batch 38/64 loss: 0.19020581245422363
Batch 39/64 loss: 0.21233141422271729
Batch 40/64 loss: 0.1919623613357544
Batch 41/64 loss: 0.20795327425003052
Batch 42/64 loss: 0.19729077816009521
Batch 43/64 loss: 0.20341455936431885
Batch 44/64 loss: 0.21268486976623535
Batch 45/64 loss: 0.19605720043182373
Batch 46/64 loss: 0.20720994472503662
Batch 47/64 loss: 0.19993948936462402
Batch 48/64 loss: 0.19764816761016846
Batch 49/64 loss: 0.20209038257598877
Batch 50/64 loss: 0.19623154401779175
Batch 51/64 loss: 0.19946777820587158
Batch 52/64 loss: 0.1959744095802307
Batch 53/64 loss: 0.20794302225112915
Batch 54/64 loss: 0.20692932605743408
Batch 55/64 loss: 0.20536363124847412
Batch 56/64 loss: 0.19876688718795776
Batch 57/64 loss: 0.22269386053085327
Batch 58/64 loss: 0.20401108264923096
Batch 59/64 loss: 0.20172011852264404
Batch 60/64 loss: 0.20788973569869995
Batch 61/64 loss: 0.2006523609161377
Batch 62/64 loss: 0.19975066184997559
Batch 63/64 loss: 0.1981636881828308
Batch 64/64 loss: 0.19382834434509277
Epoch 444  Train loss: 0.20082658879897175  Val loss: 0.2694069315068091
Epoch 445
-------------------------------
Batch 1/64 loss: 0.20600605010986328
Batch 2/64 loss: 0.19977569580078125
Batch 3/64 loss: 0.20273667573928833
Batch 4/64 loss: 0.18894469738006592
Batch 5/64 loss: 0.19490277767181396
Batch 6/64 loss: 0.20455849170684814
Batch 7/64 loss: 0.20641016960144043
Batch 8/64 loss: 0.2042219638824463
Batch 9/64 loss: 0.19167464971542358
Batch 10/64 loss: 0.19687044620513916
Batch 11/64 loss: 0.19302970170974731
Batch 12/64 loss: 0.19417256116867065
Batch 13/64 loss: 0.203768789768219
Batch 14/64 loss: 0.2098100185394287
Batch 15/64 loss: 0.20049870014190674
Batch 16/64 loss: 0.20426589250564575
Batch 17/64 loss: 0.19838440418243408
Batch 18/64 loss: 0.21224862337112427
Batch 19/64 loss: 0.2009487748146057
Batch 20/64 loss: 0.19990652799606323
Batch 21/64 loss: 0.2014775276184082
Batch 22/64 loss: 0.21563351154327393
Batch 23/64 loss: 0.21472299098968506
Batch 24/64 loss: 0.2017536759376526
Batch 25/64 loss: 0.19814765453338623
Batch 26/64 loss: 0.19553202390670776
Batch 27/64 loss: 0.19229966402053833
Batch 28/64 loss: 0.20116335153579712
Batch 29/64 loss: 0.20468264818191528
Batch 30/64 loss: 0.20709621906280518
Batch 31/64 loss: 0.1927306056022644
Batch 32/64 loss: 0.19241362810134888
Batch 33/64 loss: 0.2033247947692871
Batch 34/64 loss: 0.20257049798965454
Batch 35/64 loss: 0.19494450092315674
Batch 36/64 loss: 0.19546210765838623
Batch 37/64 loss: 0.19798576831817627
Batch 38/64 loss: 0.20158469676971436
Batch 39/64 loss: 0.2079765796661377
Batch 40/64 loss: 0.20570874214172363
Batch 41/64 loss: 0.21290522813796997
Batch 42/64 loss: 0.2044445276260376
Batch 43/64 loss: 0.1931241750717163
Batch 44/64 loss: 0.20409035682678223
Batch 45/64 loss: 0.20855408906936646
Batch 46/64 loss: 0.20386481285095215
Batch 47/64 loss: 0.21505427360534668
Batch 48/64 loss: 0.20786654949188232
Batch 49/64 loss: 0.2062530517578125
Batch 50/64 loss: 0.2031095027923584
Batch 51/64 loss: 0.20141476392745972
Batch 52/64 loss: 0.2050594687461853
Batch 53/64 loss: 0.19870060682296753
Batch 54/64 loss: 0.21350187063217163
Batch 55/64 loss: 0.19699645042419434
Batch 56/64 loss: 0.19800657033920288
Batch 57/64 loss: 0.19600427150726318
Batch 58/64 loss: 0.19853323698043823
Batch 59/64 loss: 0.19571250677108765
Batch 60/64 loss: 0.21039748191833496
Batch 61/64 loss: 0.21635740995407104
Batch 62/64 loss: 0.20321327447891235
Batch 63/64 loss: 0.1945013403892517
Batch 64/64 loss: 0.2062857747077942
Epoch 445  Train loss: 0.20208199141072292  Val loss: 0.26941807388849687
Epoch 446
-------------------------------
Batch 1/64 loss: 0.19870465993881226
Batch 2/64 loss: 0.19411903619766235
Batch 3/64 loss: 0.1982414722442627
Batch 4/64 loss: 0.19032859802246094
Batch 5/64 loss: 0.19736164808273315
Batch 6/64 loss: 0.19471395015716553
Batch 7/64 loss: 0.18939703702926636
Batch 8/64 loss: 0.19445621967315674
Batch 9/64 loss: 0.19462764263153076
Batch 10/64 loss: 0.2042759656906128
Batch 11/64 loss: 0.20190399885177612
Batch 12/64 loss: 0.19447505474090576
Batch 13/64 loss: 0.19261473417282104
Batch 14/64 loss: 0.19819796085357666
Batch 15/64 loss: 0.19394516944885254
Batch 16/64 loss: 0.19803911447525024
Batch 17/64 loss: 0.20477837324142456
Batch 18/64 loss: 0.1976996660232544
Batch 19/64 loss: 0.20222938060760498
Batch 20/64 loss: 0.20272129774093628
Batch 21/64 loss: 0.18814855813980103
Batch 22/64 loss: 0.2019175887107849
Batch 23/64 loss: 0.2021266222000122
Batch 24/64 loss: 0.20422935485839844
Batch 25/64 loss: 0.19599926471710205
Batch 26/64 loss: 0.20062947273254395
Batch 27/64 loss: 0.209586501121521
Batch 28/64 loss: 0.20033550262451172
Batch 29/64 loss: 0.1910761594772339
Batch 30/64 loss: 0.19757765531539917
Batch 31/64 loss: 0.20535486936569214
Batch 32/64 loss: 0.20163416862487793
Batch 33/64 loss: 0.2028772234916687
Batch 34/64 loss: 0.20547425746917725
Batch 35/64 loss: 0.20130205154418945
Batch 36/64 loss: 0.20191973447799683
Batch 37/64 loss: 0.2114800214767456
Batch 38/64 loss: 0.20839989185333252
Batch 39/64 loss: 0.1980530023574829
Batch 40/64 loss: 0.21333038806915283
Batch 41/64 loss: 0.19818460941314697
Batch 42/64 loss: 0.19936591386795044
Batch 43/64 loss: 0.21961861848831177
Batch 44/64 loss: 0.19493597745895386
Batch 45/64 loss: 0.21697449684143066
Batch 46/64 loss: 0.20896422863006592
Batch 47/64 loss: 0.20751911401748657
Batch 48/64 loss: 0.1993468999862671
Batch 49/64 loss: 0.20496386289596558
Batch 50/64 loss: 0.21644127368927002
Batch 51/64 loss: 0.2085965871810913
Batch 52/64 loss: 0.19676345586776733
Batch 53/64 loss: 0.2098848819732666
Batch 54/64 loss: 0.2057453989982605
Batch 55/64 loss: 0.206487774848938
Batch 56/64 loss: 0.19995713233947754
Batch 57/64 loss: 0.20493745803833008
Batch 58/64 loss: 0.20216357707977295
Batch 59/64 loss: 0.20958727598190308
Batch 60/64 loss: 0.20348519086837769
Batch 61/64 loss: 0.19662326574325562
Batch 62/64 loss: 0.19719505310058594
Batch 63/64 loss: 0.202103853225708
Batch 64/64 loss: 0.21370917558670044
Epoch 446  Train loss: 0.20163782040278116  Val loss: 0.26893779461326467
Epoch 447
-------------------------------
Batch 1/64 loss: 0.20007789134979248
Batch 2/64 loss: 0.20434969663619995
Batch 3/64 loss: 0.19950318336486816
Batch 4/64 loss: 0.19945645332336426
Batch 5/64 loss: 0.19948983192443848
Batch 6/64 loss: 0.19443386793136597
Batch 7/64 loss: 0.19136786460876465
Batch 8/64 loss: 0.19697004556655884
Batch 9/64 loss: 0.19652950763702393
Batch 10/64 loss: 0.2055603265762329
Batch 11/64 loss: 0.20266127586364746
Batch 12/64 loss: 0.2150048017501831
Batch 13/64 loss: 0.19818323850631714
Batch 14/64 loss: 0.20551997423171997
Batch 15/64 loss: 0.21354854106903076
Batch 16/64 loss: 0.2040920853614807
Batch 17/64 loss: 0.2022826075553894
Batch 18/64 loss: 0.202853262424469
Batch 19/64 loss: 0.19386082887649536
Batch 20/64 loss: 0.18878483772277832
Batch 21/64 loss: 0.19187819957733154
Batch 22/64 loss: 0.19407004117965698
Batch 23/64 loss: 0.20261847972869873
Batch 24/64 loss: 0.201979398727417
Batch 25/64 loss: 0.18774253129959106
Batch 26/64 loss: 0.19650983810424805
Batch 27/64 loss: 0.1940082311630249
Batch 28/64 loss: 0.21684598922729492
Batch 29/64 loss: 0.20595932006835938
Batch 30/64 loss: 0.19487601518630981
Batch 31/64 loss: 0.1934589147567749
Batch 32/64 loss: 0.20457398891448975
Batch 33/64 loss: 0.20265352725982666
Batch 34/64 loss: 0.19556736946105957
Batch 35/64 loss: 0.20749688148498535
Batch 36/64 loss: 0.1913515329360962
Batch 37/64 loss: 0.19223445653915405
Batch 38/64 loss: 0.20074081420898438
Batch 39/64 loss: 0.21328383684158325
Batch 40/64 loss: 0.20204579830169678
Batch 41/64 loss: 0.19485771656036377
Batch 42/64 loss: 0.2018275260925293
Batch 43/64 loss: 0.19803690910339355
Batch 44/64 loss: 0.20118188858032227
Batch 45/64 loss: 0.19988608360290527
Batch 46/64 loss: 0.1994515061378479
Batch 47/64 loss: 0.19933342933654785
Batch 48/64 loss: 0.2004084587097168
Batch 49/64 loss: 0.19396376609802246
Batch 50/64 loss: 0.19614410400390625
Batch 51/64 loss: 0.19358617067337036
Batch 52/64 loss: 0.19120287895202637
Batch 53/64 loss: 0.2103557586669922
Batch 54/64 loss: 0.19701385498046875
Batch 55/64 loss: 0.19488251209259033
Batch 56/64 loss: 0.18559879064559937
Batch 57/64 loss: 0.19337159395217896
Batch 58/64 loss: 0.20110058784484863
Batch 59/64 loss: 0.20818477869033813
Batch 60/64 loss: 0.19667106866836548
Batch 61/64 loss: 0.2070598602294922
Batch 62/64 loss: 0.19989043474197388
Batch 63/64 loss: 0.19500219821929932
Batch 64/64 loss: 0.19618266820907593
Epoch 447  Train loss: 0.19938155552920173  Val loss: 0.2694754485821806
Epoch 448
-------------------------------
Batch 1/64 loss: 0.20018810033798218
Batch 2/64 loss: 0.19175082445144653
Batch 3/64 loss: 0.19562631845474243
Batch 4/64 loss: 0.19048231840133667
Batch 5/64 loss: 0.19893914461135864
Batch 6/64 loss: 0.1955377459526062
Batch 7/64 loss: 0.20986193418502808
Batch 8/64 loss: 0.20321035385131836
Batch 9/64 loss: 0.20166510343551636
Batch 10/64 loss: 0.19849276542663574
Batch 11/64 loss: 0.1993710994720459
Batch 12/64 loss: 0.2070336937904358
Batch 13/64 loss: 0.2011011838912964
Batch 14/64 loss: 0.19866615533828735
Batch 15/64 loss: 0.18821221590042114
Batch 16/64 loss: 0.19700342416763306
Batch 17/64 loss: 0.20195811986923218
Batch 18/64 loss: 0.19384682178497314
Batch 19/64 loss: 0.191536545753479
Batch 20/64 loss: 0.2039623260498047
Batch 21/64 loss: 0.1887120008468628
Batch 22/64 loss: 0.2063899040222168
Batch 23/64 loss: 0.19867843389511108
Batch 24/64 loss: 0.2020125389099121
Batch 25/64 loss: 0.19092142581939697
Batch 26/64 loss: 0.20150351524353027
Batch 27/64 loss: 0.21007084846496582
Batch 28/64 loss: 0.19740915298461914
Batch 29/64 loss: 0.19135618209838867
Batch 30/64 loss: 0.20691609382629395
Batch 31/64 loss: 0.2013719081878662
Batch 32/64 loss: 0.19444537162780762
Batch 33/64 loss: 0.19611036777496338
Batch 34/64 loss: 0.19688892364501953
Batch 35/64 loss: 0.1923980712890625
Batch 36/64 loss: 0.1969735026359558
Batch 37/64 loss: 0.20535492897033691
Batch 38/64 loss: 0.19799339771270752
Batch 39/64 loss: 0.2042466402053833
Batch 40/64 loss: 0.2042894959449768
Batch 41/64 loss: 0.19599652290344238
Batch 42/64 loss: 0.21707528829574585
Batch 43/64 loss: 0.19361287355422974
Batch 44/64 loss: 0.20038026571273804
Batch 45/64 loss: 0.20780706405639648
Batch 46/64 loss: 0.20039153099060059
Batch 47/64 loss: 0.202786386013031
Batch 48/64 loss: 0.19854074716567993
Batch 49/64 loss: 0.19550848007202148
Batch 50/64 loss: 0.19001531600952148
Batch 51/64 loss: 0.19717532396316528
Batch 52/64 loss: 0.19826412200927734
Batch 53/64 loss: 0.19611316919326782
Batch 54/64 loss: 0.20505350828170776
Batch 55/64 loss: 0.21578747034072876
Batch 56/64 loss: 0.1962730884552002
Batch 57/64 loss: 0.20284003019332886
Batch 58/64 loss: 0.19348132610321045
Batch 59/64 loss: 0.21582698822021484
Batch 60/64 loss: 0.20661354064941406
Batch 61/64 loss: 0.1960868239402771
Batch 62/64 loss: 0.19883286952972412
Batch 63/64 loss: 0.196788489818573
Batch 64/64 loss: 0.19350677728652954
Epoch 448  Train loss: 0.19951168953203688  Val loss: 0.26978099325678195
Epoch 449
-------------------------------
Batch 1/64 loss: 0.1944562792778015
Batch 2/64 loss: 0.19278812408447266
Batch 3/64 loss: 0.19931954145431519
Batch 4/64 loss: 0.20235002040863037
Batch 5/64 loss: 0.19138628244400024
Batch 6/64 loss: 0.19682782888412476
Batch 7/64 loss: 0.19511747360229492
Batch 8/64 loss: 0.19534289836883545
Batch 9/64 loss: 0.19262558221817017
Batch 10/64 loss: 0.19636797904968262
Batch 11/64 loss: 0.19595026969909668
Batch 12/64 loss: 0.20026308298110962
Batch 13/64 loss: 0.20515060424804688
Batch 14/64 loss: 0.1997806429862976
Batch 15/64 loss: 0.1971713900566101
Batch 16/64 loss: 0.19042319059371948
Batch 17/64 loss: 0.2119448184967041
Batch 18/64 loss: 0.18979144096374512
Batch 19/64 loss: 0.20068442821502686
Batch 20/64 loss: 0.2051956057548523
Batch 21/64 loss: 0.2129826545715332
Batch 22/64 loss: 0.19869697093963623
Batch 23/64 loss: 0.20636820793151855
Batch 24/64 loss: 0.19324660301208496
Batch 25/64 loss: 0.19929730892181396
Batch 26/64 loss: 0.20939379930496216
Batch 27/64 loss: 0.1991536021232605
Batch 28/64 loss: 0.21021735668182373
Batch 29/64 loss: 0.20603084564208984
Batch 30/64 loss: 0.19740045070648193
Batch 31/64 loss: 0.2158294916152954
Batch 32/64 loss: 0.1996290683746338
Batch 33/64 loss: 0.19260436296463013
Batch 34/64 loss: 0.19770663976669312
Batch 35/64 loss: 0.2115248441696167
Batch 36/64 loss: 0.20277118682861328
Batch 37/64 loss: 0.1966787576675415
Batch 38/64 loss: 0.19396543502807617
Batch 39/64 loss: 0.20028269290924072
Batch 40/64 loss: 0.20274925231933594
Batch 41/64 loss: 0.1998438835144043
Batch 42/64 loss: 0.20789659023284912
Batch 43/64 loss: 0.1969107985496521
Batch 44/64 loss: 0.20352691411972046
Batch 45/64 loss: 0.19396573305130005
Batch 46/64 loss: 0.20124781131744385
Batch 47/64 loss: 0.19078850746154785
Batch 48/64 loss: 0.20212453603744507
Batch 49/64 loss: 0.19822591543197632
Batch 50/64 loss: 0.20293307304382324
Batch 51/64 loss: 0.19810205698013306
Batch 52/64 loss: 0.19931334257125854
Batch 53/64 loss: 0.21803796291351318
Batch 54/64 loss: 0.1994834542274475
Batch 55/64 loss: 0.20878565311431885
Batch 56/64 loss: 0.20805102586746216
Batch 57/64 loss: 0.1968541145324707
Batch 58/64 loss: 0.19540536403656006
Batch 59/64 loss: 0.1958369016647339
Batch 60/64 loss: 0.20694059133529663
Batch 61/64 loss: 0.19464492797851562
Batch 62/64 loss: 0.1950100064277649
Batch 63/64 loss: 0.19513005018234253
Batch 64/64 loss: 0.21158170700073242
Epoch 449  Train loss: 0.20027000015857174  Val loss: 0.27065648737641956
Epoch 450
-------------------------------
Batch 1/64 loss: 0.20152956247329712
Batch 2/64 loss: 0.2027938961982727
Batch 3/64 loss: 0.21025437116622925
Batch 4/64 loss: 0.21003609895706177
Batch 5/64 loss: 0.20062255859375
Batch 6/64 loss: 0.2041538953781128
Batch 7/64 loss: 0.19346177577972412
Batch 8/64 loss: 0.20213979482650757
Batch 9/64 loss: 0.19681286811828613
Batch 10/64 loss: 0.19677037000656128
Batch 11/64 loss: 0.18761450052261353
Batch 12/64 loss: 0.19992530345916748
Batch 13/64 loss: 0.1989126205444336
Batch 14/64 loss: 0.19333434104919434
Batch 15/64 loss: 0.1972028613090515
Batch 16/64 loss: 0.2023388147354126
Batch 17/64 loss: 0.19864517450332642
Batch 18/64 loss: 0.20790278911590576
Batch 19/64 loss: 0.19329220056533813
Batch 20/64 loss: 0.19606506824493408
Batch 21/64 loss: 0.20097565650939941
Batch 22/64 loss: 0.20177119970321655
Batch 23/64 loss: 0.20773398876190186
Batch 24/64 loss: 0.2003157138824463
Batch 25/64 loss: 0.2070012092590332
Batch 26/64 loss: 0.2060038447380066
Batch 27/64 loss: 0.19433337450027466
Batch 28/64 loss: 0.2083956003189087
Batch 29/64 loss: 0.20226716995239258
Batch 30/64 loss: 0.1963498592376709
Batch 31/64 loss: 0.1967676877975464
Batch 32/64 loss: 0.20742905139923096
Batch 33/64 loss: 0.19954442977905273
Batch 34/64 loss: 0.19532382488250732
Batch 35/64 loss: 0.2051222324371338
Batch 36/64 loss: 0.19397443532943726
Batch 37/64 loss: 0.21141648292541504
Batch 38/64 loss: 0.19995146989822388
Batch 39/64 loss: 0.20172011852264404
Batch 40/64 loss: 0.1919446587562561
Batch 41/64 loss: 0.1993727684020996
Batch 42/64 loss: 0.19936931133270264
Batch 43/64 loss: 0.19664329290390015
Batch 44/64 loss: 0.1928127408027649
Batch 45/64 loss: 0.19700270891189575
Batch 46/64 loss: 0.20169305801391602
Batch 47/64 loss: 0.19958555698394775
Batch 48/64 loss: 0.2040700912475586
Batch 49/64 loss: 0.19381558895111084
Batch 50/64 loss: 0.19733673334121704
Batch 51/64 loss: 0.20046740770339966
Batch 52/64 loss: 0.19850927591323853
Batch 53/64 loss: 0.20406019687652588
Batch 54/64 loss: 0.19764405488967896
Batch 55/64 loss: 0.2027859091758728
Batch 56/64 loss: 0.18652403354644775
Batch 57/64 loss: 0.19837450981140137
Batch 58/64 loss: 0.2025873064994812
Batch 59/64 loss: 0.19918382167816162
Batch 60/64 loss: 0.19125044345855713
Batch 61/64 loss: 0.1947784423828125
Batch 62/64 loss: 0.19340193271636963
Batch 63/64 loss: 0.20238858461380005
Batch 64/64 loss: 0.21785622835159302
Epoch 450  Train loss: 0.19983060102836758  Val loss: 0.2699615478105971
Epoch 451
-------------------------------
Batch 1/64 loss: 0.1994362473487854
Batch 2/64 loss: 0.2050185203552246
Batch 3/64 loss: 0.199596107006073
Batch 4/64 loss: 0.2067098617553711
Batch 5/64 loss: 0.2019350528717041
Batch 6/64 loss: 0.19623881578445435
Batch 7/64 loss: 0.19154125452041626
Batch 8/64 loss: 0.20070302486419678
Batch 9/64 loss: 0.20673871040344238
Batch 10/64 loss: 0.19809776544570923
Batch 11/64 loss: 0.19449257850646973
Batch 12/64 loss: 0.20084154605865479
Batch 13/64 loss: 0.20566201210021973
Batch 14/64 loss: 0.19736593961715698
Batch 15/64 loss: 0.2130110263824463
Batch 16/64 loss: 0.1999129056930542
Batch 17/64 loss: 0.19434046745300293
Batch 18/64 loss: 0.19270598888397217
Batch 19/64 loss: 0.19523119926452637
Batch 20/64 loss: 0.19132357835769653
Batch 21/64 loss: 0.19785189628601074
Batch 22/64 loss: 0.1965930461883545
Batch 23/64 loss: 0.20954573154449463
Batch 24/64 loss: 0.18852007389068604
Batch 25/64 loss: 0.19021540880203247
Batch 26/64 loss: 0.20091009140014648
Batch 27/64 loss: 0.19276827573776245
Batch 28/64 loss: 0.1928582787513733
Batch 29/64 loss: 0.19683748483657837
Batch 30/64 loss: 0.20635414123535156
Batch 31/64 loss: 0.1981220245361328
Batch 32/64 loss: 0.19756245613098145
Batch 33/64 loss: 0.19272208213806152
Batch 34/64 loss: 0.19722187519073486
Batch 35/64 loss: 0.19414550065994263
Batch 36/64 loss: 0.2073456048965454
Batch 37/64 loss: 0.20012390613555908
Batch 38/64 loss: 0.19021600484848022
Batch 39/64 loss: 0.19730663299560547
Batch 40/64 loss: 0.2004467248916626
Batch 41/64 loss: 0.19820231199264526
Batch 42/64 loss: 0.20558840036392212
Batch 43/64 loss: 0.20322328805923462
Batch 44/64 loss: 0.19897139072418213
Batch 45/64 loss: 0.1973186731338501
Batch 46/64 loss: 0.1983581781387329
Batch 47/64 loss: 0.20203912258148193
Batch 48/64 loss: 0.20395702123641968
Batch 49/64 loss: 0.19808119535446167
Batch 50/64 loss: 0.19978278875350952
Batch 51/64 loss: 0.19706696271896362
Batch 52/64 loss: 0.1990814208984375
Batch 53/64 loss: 0.190598726272583
Batch 54/64 loss: 0.19231128692626953
Batch 55/64 loss: 0.20347505807876587
Batch 56/64 loss: 0.20807647705078125
Batch 57/64 loss: 0.1980922818183899
Batch 58/64 loss: 0.19226813316345215
Batch 59/64 loss: 0.2037755250930786
Batch 60/64 loss: 0.20463162660598755
Batch 61/64 loss: 0.19316667318344116
Batch 62/64 loss: 0.19398248195648193
Batch 63/64 loss: 0.2121046781539917
Batch 64/64 loss: 0.20316791534423828
Epoch 451  Train loss: 0.19898195266723634  Val loss: 0.2696911358751382
Epoch 452
-------------------------------
Batch 1/64 loss: 0.20389008522033691
Batch 2/64 loss: 0.2077992558479309
Batch 3/64 loss: 0.19407612085342407
Batch 4/64 loss: 0.19178736209869385
Batch 5/64 loss: 0.20248943567276
Batch 6/64 loss: 0.2012311816215515
Batch 7/64 loss: 0.20755618810653687
Batch 8/64 loss: 0.21011579036712646
Batch 9/64 loss: 0.19287258386611938
Batch 10/64 loss: 0.20468783378601074
Batch 11/64 loss: 0.20013737678527832
Batch 12/64 loss: 0.21031415462493896
Batch 13/64 loss: 0.19349336624145508
Batch 14/64 loss: 0.19561338424682617
Batch 15/64 loss: 0.19757920503616333
Batch 16/64 loss: 0.20274657011032104
Batch 17/64 loss: 0.1997796893119812
Batch 18/64 loss: 0.1981068253517151
Batch 19/64 loss: 0.19400697946548462
Batch 20/64 loss: 0.2083650827407837
Batch 21/64 loss: 0.20053237676620483
Batch 22/64 loss: 0.19737082719802856
Batch 23/64 loss: 0.19803154468536377
Batch 24/64 loss: 0.20026445388793945
Batch 25/64 loss: 0.19682329893112183
Batch 26/64 loss: 0.21017253398895264
Batch 27/64 loss: 0.2035384178161621
Batch 28/64 loss: 0.19928622245788574
Batch 29/64 loss: 0.19511735439300537
Batch 30/64 loss: 0.1897464394569397
Batch 31/64 loss: 0.19480586051940918
Batch 32/64 loss: 0.2088230848312378
Batch 33/64 loss: 0.2075134515762329
Batch 34/64 loss: 0.2073332667350769
Batch 35/64 loss: 0.19314885139465332
Batch 36/64 loss: 0.2019115686416626
Batch 37/64 loss: 0.20328783988952637
Batch 38/64 loss: 0.19171571731567383
Batch 39/64 loss: 0.19569551944732666
Batch 40/64 loss: 0.197442889213562
Batch 41/64 loss: 0.19763654470443726
Batch 42/64 loss: 0.20138567686080933
Batch 43/64 loss: 0.21275591850280762
Batch 44/64 loss: 0.21205973625183105
Batch 45/64 loss: 0.20407110452651978
Batch 46/64 loss: 0.19313710927963257
Batch 47/64 loss: 0.1984541416168213
Batch 48/64 loss: 0.1989092230796814
Batch 49/64 loss: 0.19475585222244263
Batch 50/64 loss: 0.20054197311401367
Batch 51/64 loss: 0.21041786670684814
Batch 52/64 loss: 0.20285308361053467
Batch 53/64 loss: 0.20294249057769775
Batch 54/64 loss: 0.19980382919311523
Batch 55/64 loss: 0.20191502571105957
Batch 56/64 loss: 0.19386744499206543
Batch 57/64 loss: 0.19592773914337158
Batch 58/64 loss: 0.19401854276657104
Batch 59/64 loss: 0.20610642433166504
Batch 60/64 loss: 0.19855618476867676
Batch 61/64 loss: 0.18980169296264648
Batch 62/64 loss: 0.19358229637145996
Batch 63/64 loss: 0.20276391506195068
Batch 64/64 loss: 0.2111334204673767
Epoch 452  Train loss: 0.20037370779935051  Val loss: 0.2703582728441638
Epoch 453
-------------------------------
Batch 1/64 loss: 0.20324277877807617
Batch 2/64 loss: 0.20732438564300537
Batch 3/64 loss: 0.20030206441879272
Batch 4/64 loss: 0.1904466152191162
Batch 5/64 loss: 0.19590532779693604
Batch 6/64 loss: 0.20526492595672607
Batch 7/64 loss: 0.19475817680358887
Batch 8/64 loss: 0.19406336545944214
Batch 9/64 loss: 0.19578874111175537
Batch 10/64 loss: 0.19254201650619507
Batch 11/64 loss: 0.2000645399093628
Batch 12/64 loss: 0.2017432451248169
Batch 13/64 loss: 0.1975346803665161
Batch 14/64 loss: 0.18947505950927734
Batch 15/64 loss: 0.21375876665115356
Batch 16/64 loss: 0.20076847076416016
Batch 17/64 loss: 0.2029792070388794
Batch 18/64 loss: 0.20276188850402832
Batch 19/64 loss: 0.1958075761795044
Batch 20/64 loss: 0.19813799858093262
Batch 21/64 loss: 0.20677149295806885
Batch 22/64 loss: 0.19747668504714966
Batch 23/64 loss: 0.20381766557693481
Batch 24/64 loss: 0.2047654390335083
Batch 25/64 loss: 0.20610469579696655
Batch 26/64 loss: 0.19344335794448853
Batch 27/64 loss: 0.19398951530456543
Batch 28/64 loss: 0.2042938470840454
Batch 29/64 loss: 0.19489312171936035
Batch 30/64 loss: 0.20105081796646118
Batch 31/64 loss: 0.19586706161499023
Batch 32/64 loss: 0.19783151149749756
Batch 33/64 loss: 0.20325815677642822
Batch 34/64 loss: 0.19938182830810547
Batch 35/64 loss: 0.21424484252929688
Batch 36/64 loss: 0.19445854425430298
Batch 37/64 loss: 0.20583146810531616
Batch 38/64 loss: 0.1982583999633789
Batch 39/64 loss: 0.1955086588859558
Batch 40/64 loss: 0.20787566900253296
Batch 41/64 loss: 0.21342110633850098
Batch 42/64 loss: 0.1986944079399109
Batch 43/64 loss: 0.19418293237686157
Batch 44/64 loss: 0.1954207420349121
Batch 45/64 loss: 0.196918785572052
Batch 46/64 loss: 0.20537960529327393
Batch 47/64 loss: 0.1960989236831665
Batch 48/64 loss: 0.2041630744934082
Batch 49/64 loss: 0.1942453384399414
Batch 50/64 loss: 0.19610166549682617
Batch 51/64 loss: 0.20083355903625488
Batch 52/64 loss: 0.19643628597259521
Batch 53/64 loss: 0.19624853134155273
Batch 54/64 loss: 0.19749987125396729
Batch 55/64 loss: 0.1892714500427246
Batch 56/64 loss: 0.20158910751342773
Batch 57/64 loss: 0.2064175009727478
Batch 58/64 loss: 0.20141881704330444
Batch 59/64 loss: 0.20019078254699707
Batch 60/64 loss: 0.18990743160247803
Batch 61/64 loss: 0.19959652423858643
Batch 62/64 loss: 0.19639599323272705
Batch 63/64 loss: 0.20393890142440796
Batch 64/64 loss: 0.191320538520813
Epoch 453  Train loss: 0.19952398982702518  Val loss: 0.26878038181881725
Epoch 454
-------------------------------
Batch 1/64 loss: 0.19357365369796753
Batch 2/64 loss: 0.20828068256378174
Batch 3/64 loss: 0.20235157012939453
Batch 4/64 loss: 0.19298946857452393
Batch 5/64 loss: 0.19072586297988892
Batch 6/64 loss: 0.2019168734550476
Batch 7/64 loss: 0.19708359241485596
Batch 8/64 loss: 0.19278645515441895
Batch 9/64 loss: 0.19166821241378784
Batch 10/64 loss: 0.19514590501785278
Batch 11/64 loss: 0.19395709037780762
Batch 12/64 loss: 0.18962061405181885
Batch 13/64 loss: 0.19626998901367188
Batch 14/64 loss: 0.1981717348098755
Batch 15/64 loss: 0.18726950883865356
Batch 16/64 loss: 0.18771350383758545
Batch 17/64 loss: 0.19876772165298462
Batch 18/64 loss: 0.19356638193130493
Batch 19/64 loss: 0.20041823387145996
Batch 20/64 loss: 0.1966339349746704
Batch 21/64 loss: 0.20114672183990479
Batch 22/64 loss: 0.1949533224105835
Batch 23/64 loss: 0.20268476009368896
Batch 24/64 loss: 0.19399744272232056
Batch 25/64 loss: 0.19365018606185913
Batch 26/64 loss: 0.19669795036315918
Batch 27/64 loss: 0.1979861855506897
Batch 28/64 loss: 0.20048052072525024
Batch 29/64 loss: 0.2133171558380127
Batch 30/64 loss: 0.20945733785629272
Batch 31/64 loss: 0.19884264469146729
Batch 32/64 loss: 0.201543927192688
Batch 33/64 loss: 0.20525193214416504
Batch 34/64 loss: 0.20391839742660522
Batch 35/64 loss: 0.19427376985549927
Batch 36/64 loss: 0.2020111083984375
Batch 37/64 loss: 0.1946016550064087
Batch 38/64 loss: 0.195520281791687
Batch 39/64 loss: 0.20804989337921143
Batch 40/64 loss: 0.19671577215194702
Batch 41/64 loss: 0.1918119192123413
Batch 42/64 loss: 0.20453643798828125
Batch 43/64 loss: 0.1899874210357666
Batch 44/64 loss: 0.19689321517944336
Batch 45/64 loss: 0.19541430473327637
Batch 46/64 loss: 0.19601863622665405
Batch 47/64 loss: 0.1930081844329834
Batch 48/64 loss: 0.20777279138565063
Batch 49/64 loss: 0.18973910808563232
Batch 50/64 loss: 0.2019106149673462
Batch 51/64 loss: 0.19566529989242554
Batch 52/64 loss: 0.2004219889640808
Batch 53/64 loss: 0.2018401026725769
Batch 54/64 loss: 0.20446574687957764
Batch 55/64 loss: 0.1985929012298584
Batch 56/64 loss: 0.19413471221923828
Batch 57/64 loss: 0.19625109434127808
Batch 58/64 loss: 0.20326048135757446
Batch 59/64 loss: 0.18974220752716064
Batch 60/64 loss: 0.19998395442962646
Batch 61/64 loss: 0.1996532678604126
Batch 62/64 loss: 0.19690537452697754
Batch 63/64 loss: 0.21499711275100708
Batch 64/64 loss: 0.20336967706680298
Epoch 454  Train loss: 0.1981105269170275  Val loss: 0.27017675970018523
Epoch 455
-------------------------------
Batch 1/64 loss: 0.18899333477020264
Batch 2/64 loss: 0.19307178258895874
Batch 3/64 loss: 0.19645440578460693
Batch 4/64 loss: 0.19490528106689453
Batch 5/64 loss: 0.19464588165283203
Batch 6/64 loss: 0.20004582405090332
Batch 7/64 loss: 0.18965047597885132
Batch 8/64 loss: 0.1964903473854065
Batch 9/64 loss: 0.20043760538101196
Batch 10/64 loss: 0.19922351837158203
Batch 11/64 loss: 0.18636339902877808
Batch 12/64 loss: 0.19890403747558594
Batch 13/64 loss: 0.1922023892402649
Batch 14/64 loss: 0.20220041275024414
Batch 15/64 loss: 0.20605027675628662
Batch 16/64 loss: 0.1956005096435547
Batch 17/64 loss: 0.20231246948242188
Batch 18/64 loss: 0.19176769256591797
Batch 19/64 loss: 0.1974526047706604
Batch 20/64 loss: 0.2003554105758667
Batch 21/64 loss: 0.1963908076286316
Batch 22/64 loss: 0.19770610332489014
Batch 23/64 loss: 0.19031143188476562
Batch 24/64 loss: 0.20095586776733398
Batch 25/64 loss: 0.201898455619812
Batch 26/64 loss: 0.19058048725128174
Batch 27/64 loss: 0.1956002116203308
Batch 28/64 loss: 0.20064979791641235
Batch 29/64 loss: 0.19899797439575195
Batch 30/64 loss: 0.20823180675506592
Batch 31/64 loss: 0.2030555009841919
Batch 32/64 loss: 0.20139622688293457
Batch 33/64 loss: 0.20674443244934082
Batch 34/64 loss: 0.19641423225402832
Batch 35/64 loss: 0.19687509536743164
Batch 36/64 loss: 0.18694055080413818
Batch 37/64 loss: 0.19759541749954224
Batch 38/64 loss: 0.19567477703094482
Batch 39/64 loss: 0.20233410596847534
Batch 40/64 loss: 0.1989595890045166
Batch 41/64 loss: 0.19502663612365723
Batch 42/64 loss: 0.19689631462097168
Batch 43/64 loss: 0.1945764422416687
Batch 44/64 loss: 0.19102692604064941
Batch 45/64 loss: 0.20029497146606445
Batch 46/64 loss: 0.19539666175842285
Batch 47/64 loss: 0.19822585582733154
Batch 48/64 loss: 0.19555401802062988
Batch 49/64 loss: 0.221724271774292
Batch 50/64 loss: 0.19401216506958008
Batch 51/64 loss: 0.19892513751983643
Batch 52/64 loss: 0.195076584815979
Batch 53/64 loss: 0.20210152864456177
Batch 54/64 loss: 0.2020311951637268
Batch 55/64 loss: 0.19931894540786743
Batch 56/64 loss: 0.21058928966522217
Batch 57/64 loss: 0.1992911696434021
Batch 58/64 loss: 0.20147454738616943
Batch 59/64 loss: 0.2077694535255432
Batch 60/64 loss: 0.2195899486541748
Batch 61/64 loss: 0.20383679866790771
Batch 62/64 loss: 0.19659841060638428
Batch 63/64 loss: 0.1950235366821289
Batch 64/64 loss: 0.21387803554534912
Epoch 455  Train loss: 0.19873270380730723  Val loss: 0.27043722216615973
Epoch 456
-------------------------------
Batch 1/64 loss: 0.19377738237380981
Batch 2/64 loss: 0.20020335912704468
Batch 3/64 loss: 0.2077641487121582
Batch 4/64 loss: 0.20358020067214966
Batch 5/64 loss: 0.2066662311553955
Batch 6/64 loss: 0.19758057594299316
Batch 7/64 loss: 0.18923908472061157
Batch 8/64 loss: 0.20132970809936523
Batch 9/64 loss: 0.1941847801208496
Batch 10/64 loss: 0.20668327808380127
Batch 11/64 loss: 0.2117459774017334
Batch 12/64 loss: 0.2054169774055481
Batch 13/64 loss: 0.1997242569923401
Batch 14/64 loss: 0.1985122561454773
Batch 15/64 loss: 0.19214493036270142
Batch 16/64 loss: 0.205733060836792
Batch 17/64 loss: 0.19786083698272705
Batch 18/64 loss: 0.1990509033203125
Batch 19/64 loss: 0.19760620594024658
Batch 20/64 loss: 0.19432884454727173
Batch 21/64 loss: 0.21336042881011963
Batch 22/64 loss: 0.20664829015731812
Batch 23/64 loss: 0.19795989990234375
Batch 24/64 loss: 0.19656729698181152
Batch 25/64 loss: 0.1962786316871643
Batch 26/64 loss: 0.1982337236404419
Batch 27/64 loss: 0.19260239601135254
Batch 28/64 loss: 0.18958640098571777
Batch 29/64 loss: 0.20052683353424072
Batch 30/64 loss: 0.20179378986358643
Batch 31/64 loss: 0.19683045148849487
Batch 32/64 loss: 0.1899198293685913
Batch 33/64 loss: 0.20632684230804443
Batch 34/64 loss: 0.19560998678207397
Batch 35/64 loss: 0.20042574405670166
Batch 36/64 loss: 0.1967247724533081
Batch 37/64 loss: 0.20457535982131958
Batch 38/64 loss: 0.19169270992279053
Batch 39/64 loss: 0.18928450345993042
Batch 40/64 loss: 0.20220232009887695
Batch 41/64 loss: 0.20292484760284424
Batch 42/64 loss: 0.1953076720237732
Batch 43/64 loss: 0.1884027123451233
Batch 44/64 loss: 0.1933881640434265
Batch 45/64 loss: 0.1931859254837036
Batch 46/64 loss: 0.20329022407531738
Batch 47/64 loss: 0.203741192817688
Batch 48/64 loss: 0.20625770092010498
Batch 49/64 loss: 0.1976454257965088
Batch 50/64 loss: 0.2135353684425354
Batch 51/64 loss: 0.19574272632598877
Batch 52/64 loss: 0.19813019037246704
Batch 53/64 loss: 0.19306623935699463
Batch 54/64 loss: 0.19661939144134521
Batch 55/64 loss: 0.19709312915802002
Batch 56/64 loss: 0.19404852390289307
Batch 57/64 loss: 0.2036534547805786
Batch 58/64 loss: 0.20465683937072754
Batch 59/64 loss: 0.20542967319488525
Batch 60/64 loss: 0.2038860321044922
Batch 61/64 loss: 0.20195496082305908
Batch 62/64 loss: 0.19732540845870972
Batch 63/64 loss: 0.19707876443862915
Batch 64/64 loss: 0.22126764059066772
Epoch 456  Train loss: 0.19957017267451566  Val loss: 0.27068968040426983
Epoch 457
-------------------------------
Batch 1/64 loss: 0.20142197608947754
Batch 2/64 loss: 0.1948033571243286
Batch 3/64 loss: 0.21008330583572388
Batch 4/64 loss: 0.20681607723236084
Batch 5/64 loss: 0.21084153652191162
Batch 6/64 loss: 0.20284324884414673
Batch 7/64 loss: 0.20164448022842407
Batch 8/64 loss: 0.19792026281356812
Batch 9/64 loss: 0.19247967004776
Batch 10/64 loss: 0.19363528490066528
Batch 11/64 loss: 0.18322080373764038
Batch 12/64 loss: 0.1990441083908081
Batch 13/64 loss: 0.19571280479431152
Batch 14/64 loss: 0.19699591398239136
Batch 15/64 loss: 0.1933923363685608
Batch 16/64 loss: 0.2043028473854065
Batch 17/64 loss: 0.19542312622070312
Batch 18/64 loss: 0.20611649751663208
Batch 19/64 loss: 0.19318830966949463
Batch 20/64 loss: 0.2001911997795105
Batch 21/64 loss: 0.20478087663650513
Batch 22/64 loss: 0.20287197828292847
Batch 23/64 loss: 0.20095336437225342
Batch 24/64 loss: 0.19992858171463013
Batch 25/64 loss: 0.19533616304397583
Batch 26/64 loss: 0.19501656293869019
Batch 27/64 loss: 0.19370996952056885
Batch 28/64 loss: 0.19352781772613525
Batch 29/64 loss: 0.20046770572662354
Batch 30/64 loss: 0.19945645332336426
Batch 31/64 loss: 0.18970847129821777
Batch 32/64 loss: 0.18911516666412354
Batch 33/64 loss: 0.21430909633636475
Batch 34/64 loss: 0.19342321157455444
Batch 35/64 loss: 0.19478917121887207
Batch 36/64 loss: 0.20455652475357056
Batch 37/64 loss: 0.19887959957122803
Batch 38/64 loss: 0.20271366834640503
Batch 39/64 loss: 0.20422035455703735
Batch 40/64 loss: 0.1967446208000183
Batch 41/64 loss: 0.1928824782371521
Batch 42/64 loss: 0.21069121360778809
Batch 43/64 loss: 0.19454938173294067
Batch 44/64 loss: 0.20153886079788208
Batch 45/64 loss: 0.19502276182174683
Batch 46/64 loss: 0.1946730613708496
Batch 47/64 loss: 0.19763875007629395
Batch 48/64 loss: 0.19098687171936035
Batch 49/64 loss: 0.19656622409820557
Batch 50/64 loss: 0.21743643283843994
Batch 51/64 loss: 0.20338976383209229
Batch 52/64 loss: 0.19691896438598633
Batch 53/64 loss: 0.1954430341720581
Batch 54/64 loss: 0.19925183057785034
Batch 55/64 loss: 0.1905798316001892
Batch 56/64 loss: 0.19449597597122192
Batch 57/64 loss: 0.1974967122077942
Batch 58/64 loss: 0.20459645986557007
Batch 59/64 loss: 0.20746654272079468
Batch 60/64 loss: 0.19997811317443848
Batch 61/64 loss: 0.19360429048538208
Batch 62/64 loss: 0.20843243598937988
Batch 63/64 loss: 0.19861489534378052
Batch 64/64 loss: 0.20911723375320435
Epoch 457  Train loss: 0.19911653831893322  Val loss: 0.26941398410862666
Epoch 458
-------------------------------
Batch 1/64 loss: 0.18420803546905518
Batch 2/64 loss: 0.1943911910057068
Batch 3/64 loss: 0.2005598545074463
Batch 4/64 loss: 0.20294040441513062
Batch 5/64 loss: 0.1936478614807129
Batch 6/64 loss: 0.1933438777923584
Batch 7/64 loss: 0.19713503122329712
Batch 8/64 loss: 0.20562821626663208
Batch 9/64 loss: 0.1982412338256836
Batch 10/64 loss: 0.19480085372924805
Batch 11/64 loss: 0.19496703147888184
Batch 12/64 loss: 0.20235878229141235
Batch 13/64 loss: 0.19295579195022583
Batch 14/64 loss: 0.1991896629333496
Batch 15/64 loss: 0.1941230297088623
Batch 16/64 loss: 0.19323033094406128
Batch 17/64 loss: 0.20347750186920166
Batch 18/64 loss: 0.20749318599700928
Batch 19/64 loss: 0.19270479679107666
Batch 20/64 loss: 0.1934574842453003
Batch 21/64 loss: 0.19400465488433838
Batch 22/64 loss: 0.19759738445281982
Batch 23/64 loss: 0.1865772008895874
Batch 24/64 loss: 0.19018810987472534
Batch 25/64 loss: 0.19330543279647827
Batch 26/64 loss: 0.19507694244384766
Batch 27/64 loss: 0.21726000308990479
Batch 28/64 loss: 0.2072489857673645
Batch 29/64 loss: 0.20583122968673706
Batch 30/64 loss: 0.2026827335357666
Batch 31/64 loss: 0.1964881420135498
Batch 32/64 loss: 0.19752758741378784
Batch 33/64 loss: 0.1987665295600891
Batch 34/64 loss: 0.19171655178070068
Batch 35/64 loss: 0.1890125274658203
Batch 36/64 loss: 0.20089280605316162
Batch 37/64 loss: 0.20709383487701416
Batch 38/64 loss: 0.20539015531539917
Batch 39/64 loss: 0.1985018253326416
Batch 40/64 loss: 0.20378613471984863
Batch 41/64 loss: 0.1972191333770752
Batch 42/64 loss: 0.19860684871673584
Batch 43/64 loss: 0.19765913486480713
Batch 44/64 loss: 0.19074654579162598
Batch 45/64 loss: 0.1990746259689331
Batch 46/64 loss: 0.20498621463775635
Batch 47/64 loss: 0.19703209400177002
Batch 48/64 loss: 0.20467489957809448
Batch 49/64 loss: 0.20669424533843994
Batch 50/64 loss: 0.20125800371170044
Batch 51/64 loss: 0.20946991443634033
Batch 52/64 loss: 0.1967545747756958
Batch 53/64 loss: 0.19423311948776245
Batch 54/64 loss: 0.19827008247375488
Batch 55/64 loss: 0.21269023418426514
Batch 56/64 loss: 0.19574737548828125
Batch 57/64 loss: 0.20677906274795532
Batch 58/64 loss: 0.19653946161270142
Batch 59/64 loss: 0.2114109992980957
Batch 60/64 loss: 0.19809377193450928
Batch 61/64 loss: 0.19546139240264893
Batch 62/64 loss: 0.20584219694137573
Batch 63/64 loss: 0.20683610439300537
Batch 64/64 loss: 0.19666290283203125
Epoch 458  Train loss: 0.19908047283397  Val loss: 0.2692348346677433
Epoch 459
-------------------------------
Batch 1/64 loss: 0.19885706901550293
Batch 2/64 loss: 0.19459861516952515
Batch 3/64 loss: 0.19895851612091064
Batch 4/64 loss: 0.19712555408477783
Batch 5/64 loss: 0.1909252405166626
Batch 6/64 loss: 0.1915242075920105
Batch 7/64 loss: 0.1969425082206726
Batch 8/64 loss: 0.20053791999816895
Batch 9/64 loss: 0.19626456499099731
Batch 10/64 loss: 0.18975824117660522
Batch 11/64 loss: 0.1942996382713318
Batch 12/64 loss: 0.18817496299743652
Batch 13/64 loss: 0.19844049215316772
Batch 14/64 loss: 0.20059698820114136
Batch 15/64 loss: 0.19233578443527222
Batch 16/64 loss: 0.19956666231155396
Batch 17/64 loss: 0.20114123821258545
Batch 18/64 loss: 0.20372599363327026
Batch 19/64 loss: 0.20723259449005127
Batch 20/64 loss: 0.1943933367729187
Batch 21/64 loss: 0.2073880434036255
Batch 22/64 loss: 0.19024109840393066
Batch 23/64 loss: 0.192604660987854
Batch 24/64 loss: 0.1918230652809143
Batch 25/64 loss: 0.19358384609222412
Batch 26/64 loss: 0.19350993633270264
Batch 27/64 loss: 0.196388840675354
Batch 28/64 loss: 0.20761680603027344
Batch 29/64 loss: 0.19505196809768677
Batch 30/64 loss: 0.19509410858154297
Batch 31/64 loss: 0.19886565208435059
Batch 32/64 loss: 0.20224285125732422
Batch 33/64 loss: 0.1959938406944275
Batch 34/64 loss: 0.19664794206619263
Batch 35/64 loss: 0.1936073899269104
Batch 36/64 loss: 0.19449055194854736
Batch 37/64 loss: 0.21817731857299805
Batch 38/64 loss: 0.19074594974517822
Batch 39/64 loss: 0.20673274993896484
Batch 40/64 loss: 0.18915057182312012
Batch 41/64 loss: 0.19866490364074707
Batch 42/64 loss: 0.19286853075027466
Batch 43/64 loss: 0.19149446487426758
Batch 44/64 loss: 0.19382762908935547
Batch 45/64 loss: 0.19482558965682983
Batch 46/64 loss: 0.21650707721710205
Batch 47/64 loss: 0.19088035821914673
Batch 48/64 loss: 0.20327544212341309
Batch 49/64 loss: 0.19823306798934937
Batch 50/64 loss: 0.1988527774810791
Batch 51/64 loss: 0.2005062699317932
Batch 52/64 loss: 0.19776320457458496
Batch 53/64 loss: 0.20029854774475098
Batch 54/64 loss: 0.1991126537322998
Batch 55/64 loss: 0.20455002784729004
Batch 56/64 loss: 0.18881100416183472
Batch 57/64 loss: 0.19426220655441284
Batch 58/64 loss: 0.2088642120361328
Batch 59/64 loss: 0.20341873168945312
Batch 60/64 loss: 0.19295352697372437
Batch 61/64 loss: 0.20329445600509644
Batch 62/64 loss: 0.21585023403167725
Batch 63/64 loss: 0.1960633397102356
Batch 64/64 loss: 0.19282567501068115
Epoch 459  Train loss: 0.1978847816878674  Val loss: 0.2705694985963225
Epoch 460
-------------------------------
Batch 1/64 loss: 0.20774424076080322
Batch 2/64 loss: 0.1938982605934143
Batch 3/64 loss: 0.19734680652618408
Batch 4/64 loss: 0.21091318130493164
Batch 5/64 loss: 0.1919872760772705
Batch 6/64 loss: 0.1927003264427185
Batch 7/64 loss: 0.19640350341796875
Batch 8/64 loss: 0.19579297304153442
Batch 9/64 loss: 0.19791722297668457
Batch 10/64 loss: 0.19896459579467773
Batch 11/64 loss: 0.20259779691696167
Batch 12/64 loss: 0.19876331090927124
Batch 13/64 loss: 0.2121495008468628
Batch 14/64 loss: 0.18777936697006226
Batch 15/64 loss: 0.19171446561813354
Batch 16/64 loss: 0.20239073038101196
Batch 17/64 loss: 0.19160008430480957
Batch 18/64 loss: 0.19391822814941406
Batch 19/64 loss: 0.19348323345184326
Batch 20/64 loss: 0.1972408890724182
Batch 21/64 loss: 0.2003575563430786
Batch 22/64 loss: 0.19521713256835938
Batch 23/64 loss: 0.18804514408111572
Batch 24/64 loss: 0.2027353048324585
Batch 25/64 loss: 0.20390450954437256
Batch 26/64 loss: 0.19919699430465698
Batch 27/64 loss: 0.20544719696044922
Batch 28/64 loss: 0.19385963678359985
Batch 29/64 loss: 0.20066750049591064
Batch 30/64 loss: 0.19803351163864136
Batch 31/64 loss: 0.1996293067932129
Batch 32/64 loss: 0.2081395387649536
Batch 33/64 loss: 0.19725453853607178
Batch 34/64 loss: 0.1966627836227417
Batch 35/64 loss: 0.19887399673461914
Batch 36/64 loss: 0.19124865531921387
Batch 37/64 loss: 0.20461124181747437
Batch 38/64 loss: 0.20255470275878906
Batch 39/64 loss: 0.1999645233154297
Batch 40/64 loss: 0.21092522144317627
Batch 41/64 loss: 0.1993771195411682
Batch 42/64 loss: 0.21155869960784912
Batch 43/64 loss: 0.1966872215270996
Batch 44/64 loss: 0.1973644495010376
Batch 45/64 loss: 0.19729948043823242
Batch 46/64 loss: 0.20064020156860352
Batch 47/64 loss: 0.19549715518951416
Batch 48/64 loss: 0.2119152545928955
Batch 49/64 loss: 0.19007253646850586
Batch 50/64 loss: 0.208032488822937
Batch 51/64 loss: 0.198436439037323
Batch 52/64 loss: 0.18985790014266968
Batch 53/64 loss: 0.20474177598953247
Batch 54/64 loss: 0.19871419668197632
Batch 55/64 loss: 0.20254957675933838
Batch 56/64 loss: 0.19593596458435059
Batch 57/64 loss: 0.19755274057388306
Batch 58/64 loss: 0.19753777980804443
Batch 59/64 loss: 0.19400060176849365
Batch 60/64 loss: 0.21184009313583374
Batch 61/64 loss: 0.1914997696876526
Batch 62/64 loss: 0.20032215118408203
Batch 63/64 loss: 0.19811087846755981
Batch 64/64 loss: 0.2052215337753296
Epoch 460  Train loss: 0.19915444102941776  Val loss: 0.2707289690823899
Epoch 461
-------------------------------
Batch 1/64 loss: 0.1921074390411377
Batch 2/64 loss: 0.19287407398223877
Batch 3/64 loss: 0.19725549221038818
Batch 4/64 loss: 0.19154512882232666
Batch 5/64 loss: 0.19474667310714722
Batch 6/64 loss: 0.1907547116279602
Batch 7/64 loss: 0.198064386844635
Batch 8/64 loss: 0.19457471370697021
Batch 9/64 loss: 0.20263171195983887
Batch 10/64 loss: 0.18960142135620117
Batch 11/64 loss: 0.1965276598930359
Batch 12/64 loss: 0.19449567794799805
Batch 13/64 loss: 0.18838375806808472
Batch 14/64 loss: 0.19398486614227295
Batch 15/64 loss: 0.194959819316864
Batch 16/64 loss: 0.1843816041946411
Batch 17/64 loss: 0.20158207416534424
Batch 18/64 loss: 0.19234716892242432
Batch 19/64 loss: 0.18890643119812012
Batch 20/64 loss: 0.19915533065795898
Batch 21/64 loss: 0.19645732641220093
Batch 22/64 loss: 0.18734747171401978
Batch 23/64 loss: 0.1949317455291748
Batch 24/64 loss: 0.19696557521820068
Batch 25/64 loss: 0.19558292627334595
Batch 26/64 loss: 0.19761979579925537
Batch 27/64 loss: 0.19782555103302002
Batch 28/64 loss: 0.19628727436065674
Batch 29/64 loss: 0.20525294542312622
Batch 30/64 loss: 0.20816123485565186
Batch 31/64 loss: 0.1970171332359314
Batch 32/64 loss: 0.192335844039917
Batch 33/64 loss: 0.1941690444946289
Batch 34/64 loss: 0.2095240354537964
Batch 35/64 loss: 0.20318901538848877
Batch 36/64 loss: 0.19726264476776123
Batch 37/64 loss: 0.20645976066589355
Batch 38/64 loss: 0.19244897365570068
Batch 39/64 loss: 0.1970641016960144
Batch 40/64 loss: 0.1964343786239624
Batch 41/64 loss: 0.19792968034744263
Batch 42/64 loss: 0.20050716400146484
Batch 43/64 loss: 0.19099807739257812
Batch 44/64 loss: 0.1985439658164978
Batch 45/64 loss: 0.196708083152771
Batch 46/64 loss: 0.19456833600997925
Batch 47/64 loss: 0.2134646773338318
Batch 48/64 loss: 0.19883352518081665
Batch 49/64 loss: 0.20225459337234497
Batch 50/64 loss: 0.20387816429138184
Batch 51/64 loss: 0.21332651376724243
Batch 52/64 loss: 0.19686222076416016
Batch 53/64 loss: 0.19530856609344482
Batch 54/64 loss: 0.19710403680801392
Batch 55/64 loss: 0.200392484664917
Batch 56/64 loss: 0.2064725160598755
Batch 57/64 loss: 0.20658481121063232
Batch 58/64 loss: 0.20109617710113525
Batch 59/64 loss: 0.19231754541397095
Batch 60/64 loss: 0.19897353649139404
Batch 61/64 loss: 0.19764739274978638
Batch 62/64 loss: 0.19639909267425537
Batch 63/64 loss: 0.20930373668670654
Batch 64/64 loss: 0.1949167251586914
Epoch 461  Train loss: 0.1975981076558431  Val loss: 0.2697001859494501
Epoch 462
-------------------------------
Batch 1/64 loss: 0.19596171379089355
Batch 2/64 loss: 0.1972915530204773
Batch 3/64 loss: 0.19375497102737427
Batch 4/64 loss: 0.19412165880203247
Batch 5/64 loss: 0.19191700220108032
Batch 6/64 loss: 0.1939374804496765
Batch 7/64 loss: 0.20287084579467773
Batch 8/64 loss: 0.19577425718307495
Batch 9/64 loss: 0.19088244438171387
Batch 10/64 loss: 0.18847018480300903
Batch 11/64 loss: 0.1982797384262085
Batch 12/64 loss: 0.19276899099349976
Batch 13/64 loss: 0.20513486862182617
Batch 14/64 loss: 0.19066780805587769
Batch 15/64 loss: 0.20077449083328247
Batch 16/64 loss: 0.1965213418006897
Batch 17/64 loss: 0.2171156406402588
Batch 18/64 loss: 0.20332670211791992
Batch 19/64 loss: 0.19803184270858765
Batch 20/64 loss: 0.19648611545562744
Batch 21/64 loss: 0.210682213306427
Batch 22/64 loss: 0.19266241788864136
Batch 23/64 loss: 0.21575599908828735
Batch 24/64 loss: 0.19817310571670532
Batch 25/64 loss: 0.21185070276260376
Batch 26/64 loss: 0.1960369348526001
Batch 27/64 loss: 0.2000928521156311
Batch 28/64 loss: 0.20034033060073853
Batch 29/64 loss: 0.1946062445640564
Batch 30/64 loss: 0.19663071632385254
Batch 31/64 loss: 0.20466965436935425
Batch 32/64 loss: 0.1899317502975464
Batch 33/64 loss: 0.19731974601745605
Batch 34/64 loss: 0.2018069624900818
Batch 35/64 loss: 0.19400262832641602
Batch 36/64 loss: 0.1927558183670044
Batch 37/64 loss: 0.19825130701065063
Batch 38/64 loss: 0.20373892784118652
Batch 39/64 loss: 0.20633375644683838
Batch 40/64 loss: 0.19970595836639404
Batch 41/64 loss: 0.20119166374206543
Batch 42/64 loss: 0.1888372302055359
Batch 43/64 loss: 0.2093139886856079
Batch 44/64 loss: 0.1959620714187622
Batch 45/64 loss: 0.20420438051223755
Batch 46/64 loss: 0.20131802558898926
Batch 47/64 loss: 0.20722031593322754
Batch 48/64 loss: 0.20853334665298462
Batch 49/64 loss: 0.1916409730911255
Batch 50/64 loss: 0.19313490390777588
Batch 51/64 loss: 0.19206035137176514
Batch 52/64 loss: 0.19700974225997925
Batch 53/64 loss: 0.20505297183990479
Batch 54/64 loss: 0.1976146697998047
Batch 55/64 loss: 0.1895291805267334
Batch 56/64 loss: 0.19211620092391968
Batch 57/64 loss: 0.19539237022399902
Batch 58/64 loss: 0.19614672660827637
Batch 59/64 loss: 0.19694340229034424
Batch 60/64 loss: 0.19288575649261475
Batch 61/64 loss: 0.19491201639175415
Batch 62/64 loss: 0.20309966802597046
Batch 63/64 loss: 0.19617021083831787
Batch 64/64 loss: 0.20204687118530273
Epoch 462  Train loss: 0.1984511842914656  Val loss: 0.27168376871810335
Epoch 463
-------------------------------
Batch 1/64 loss: 0.20113718509674072
Batch 2/64 loss: 0.20036286115646362
Batch 3/64 loss: 0.1946740746498108
Batch 4/64 loss: 0.19241374731063843
Batch 5/64 loss: 0.19138062000274658
Batch 6/64 loss: 0.19442176818847656
Batch 7/64 loss: 0.20256441831588745
Batch 8/64 loss: 0.19218355417251587
Batch 9/64 loss: 0.19169247150421143
Batch 10/64 loss: 0.19086313247680664
Batch 11/64 loss: 0.19971424341201782
Batch 12/64 loss: 0.19158625602722168
Batch 13/64 loss: 0.20290261507034302
Batch 14/64 loss: 0.20482951402664185
Batch 15/64 loss: 0.20309627056121826
Batch 16/64 loss: 0.1962827444076538
Batch 17/64 loss: 0.1989186406135559
Batch 18/64 loss: 0.19436907768249512
Batch 19/64 loss: 0.20444315671920776
Batch 20/64 loss: 0.18848079442977905
Batch 21/64 loss: 0.20211470127105713
Batch 22/64 loss: 0.2011067271232605
Batch 23/64 loss: 0.20239412784576416
Batch 24/64 loss: 0.2077891230583191
Batch 25/64 loss: 0.19580090045928955
Batch 26/64 loss: 0.19760257005691528
Batch 27/64 loss: 0.20048093795776367
Batch 28/64 loss: 0.19651001691818237
Batch 29/64 loss: 0.19697892665863037
Batch 30/64 loss: 0.20563584566116333
Batch 31/64 loss: 0.19302314519882202
Batch 32/64 loss: 0.1888527274131775
Batch 33/64 loss: 0.19969415664672852
Batch 34/64 loss: 0.1917487382888794
Batch 35/64 loss: 0.19568198919296265
Batch 36/64 loss: 0.20337891578674316
Batch 37/64 loss: 0.19352096319198608
Batch 38/64 loss: 0.2125539779663086
Batch 39/64 loss: 0.19664937257766724
Batch 40/64 loss: 0.19579970836639404
Batch 41/64 loss: 0.19872188568115234
Batch 42/64 loss: 0.19714808464050293
Batch 43/64 loss: 0.19447803497314453
Batch 44/64 loss: 0.19741010665893555
Batch 45/64 loss: 0.1929231882095337
Batch 46/64 loss: 0.19028699398040771
Batch 47/64 loss: 0.19523370265960693
Batch 48/64 loss: 0.20495182275772095
Batch 49/64 loss: 0.20123910903930664
Batch 50/64 loss: 0.201687753200531
Batch 51/64 loss: 0.1963101029396057
Batch 52/64 loss: 0.19511640071868896
Batch 53/64 loss: 0.19970136880874634
Batch 54/64 loss: 0.21031564474105835
Batch 55/64 loss: 0.19050270318984985
Batch 56/64 loss: 0.19267141819000244
Batch 57/64 loss: 0.21345412731170654
Batch 58/64 loss: 0.20063376426696777
Batch 59/64 loss: 0.19021588563919067
Batch 60/64 loss: 0.20248305797576904
Batch 61/64 loss: 0.21157437562942505
Batch 62/64 loss: 0.19970905780792236
Batch 63/64 loss: 0.18619686365127563
Batch 64/64 loss: 0.1969054937362671
Epoch 463  Train loss: 0.19802791043823842  Val loss: 0.269967545553581
Epoch 464
-------------------------------
Batch 1/64 loss: 0.19684606790542603
Batch 2/64 loss: 0.187294602394104
Batch 3/64 loss: 0.20303523540496826
Batch 4/64 loss: 0.19761621952056885
Batch 5/64 loss: 0.20624321699142456
Batch 6/64 loss: 0.2115047574043274
Batch 7/64 loss: 0.19195443391799927
Batch 8/64 loss: 0.21060335636138916
Batch 9/64 loss: 0.2015833854675293
Batch 10/64 loss: 0.1902306079864502
Batch 11/64 loss: 0.194158136844635
Batch 12/64 loss: 0.19969505071640015
Batch 13/64 loss: 0.19039905071258545
Batch 14/64 loss: 0.2108137011528015
Batch 15/64 loss: 0.20644491910934448
Batch 16/64 loss: 0.20254743099212646
Batch 17/64 loss: 0.19378018379211426
Batch 18/64 loss: 0.19679349660873413
Batch 19/64 loss: 0.1957969069480896
Batch 20/64 loss: 0.18986225128173828
Batch 21/64 loss: 0.2006382942199707
Batch 22/64 loss: 0.1951858401298523
Batch 23/64 loss: 0.19082170724868774
Batch 24/64 loss: 0.19546878337860107
Batch 25/64 loss: 0.2034512758255005
Batch 26/64 loss: 0.19122815132141113
Batch 27/64 loss: 0.20836412906646729
Batch 28/64 loss: 0.1914839744567871
Batch 29/64 loss: 0.20091426372528076
Batch 30/64 loss: 0.1881258487701416
Batch 31/64 loss: 0.18814468383789062
Batch 32/64 loss: 0.19457340240478516
Batch 33/64 loss: 0.19365191459655762
Batch 34/64 loss: 0.20004653930664062
Batch 35/64 loss: 0.1918492317199707
Batch 36/64 loss: 0.20281445980072021
Batch 37/64 loss: 0.19312894344329834
Batch 38/64 loss: 0.19101864099502563
Batch 39/64 loss: 0.20347166061401367
Batch 40/64 loss: 0.2059960961341858
Batch 41/64 loss: 0.19665658473968506
Batch 42/64 loss: 0.18655234575271606
Batch 43/64 loss: 0.20312291383743286
Batch 44/64 loss: 0.2007988691329956
Batch 45/64 loss: 0.20870935916900635
Batch 46/64 loss: 0.20461714267730713
Batch 47/64 loss: 0.1985124945640564
Batch 48/64 loss: 0.19943976402282715
Batch 49/64 loss: 0.20407068729400635
Batch 50/64 loss: 0.19908368587493896
Batch 51/64 loss: 0.19889581203460693
Batch 52/64 loss: 0.20147067308425903
Batch 53/64 loss: 0.19744610786437988
Batch 54/64 loss: 0.1945139765739441
Batch 55/64 loss: 0.20387673377990723
Batch 56/64 loss: 0.20000344514846802
Batch 57/64 loss: 0.1903771162033081
Batch 58/64 loss: 0.19657987356185913
Batch 59/64 loss: 0.1999559998512268
Batch 60/64 loss: 0.1933000683784485
Batch 61/64 loss: 0.1901291012763977
Batch 62/64 loss: 0.1983690857887268
Batch 63/64 loss: 0.19618886709213257
Batch 64/64 loss: 0.21593356132507324
Epoch 464  Train loss: 0.19815218401890175  Val loss: 0.26944539944330853
Epoch 465
-------------------------------
Batch 1/64 loss: 0.195320725440979
Batch 2/64 loss: 0.19173097610473633
Batch 3/64 loss: 0.19221216440200806
Batch 4/64 loss: 0.19190269708633423
Batch 5/64 loss: 0.20015931129455566
Batch 6/64 loss: 0.19206219911575317
Batch 7/64 loss: 0.18878579139709473
Batch 8/64 loss: 0.18456381559371948
Batch 9/64 loss: 0.19332778453826904
Batch 10/64 loss: 0.18278807401657104
Batch 11/64 loss: 0.21044105291366577
Batch 12/64 loss: 0.19732940196990967
Batch 13/64 loss: 0.19325125217437744
Batch 14/64 loss: 0.19540995359420776
Batch 15/64 loss: 0.1973678469657898
Batch 16/64 loss: 0.20197314023971558
Batch 17/64 loss: 0.19139361381530762
Batch 18/64 loss: 0.2022114396095276
Batch 19/64 loss: 0.19251549243927002
Batch 20/64 loss: 0.19931894540786743
Batch 21/64 loss: 0.20695346593856812
Batch 22/64 loss: 0.19884955883026123
Batch 23/64 loss: 0.21229779720306396
Batch 24/64 loss: 0.1886698603630066
Batch 25/64 loss: 0.20720654726028442
Batch 26/64 loss: 0.19883108139038086
Batch 27/64 loss: 0.20124965906143188
Batch 28/64 loss: 0.20091402530670166
Batch 29/64 loss: 0.19002968072891235
Batch 30/64 loss: 0.19786357879638672
Batch 31/64 loss: 0.19213885068893433
Batch 32/64 loss: 0.1961146593093872
Batch 33/64 loss: 0.19067621231079102
Batch 34/64 loss: 0.20386260747909546
Batch 35/64 loss: 0.19428914785385132
Batch 36/64 loss: 0.20014673471450806
Batch 37/64 loss: 0.19614917039871216
Batch 38/64 loss: 0.19977355003356934
Batch 39/64 loss: 0.20379650592803955
Batch 40/64 loss: 0.1945023536682129
Batch 41/64 loss: 0.1970679759979248
Batch 42/64 loss: 0.203921377658844
Batch 43/64 loss: 0.19878274202346802
Batch 44/64 loss: 0.19841474294662476
Batch 45/64 loss: 0.19704389572143555
Batch 46/64 loss: 0.1949215531349182
Batch 47/64 loss: 0.1958293318748474
Batch 48/64 loss: 0.20266014337539673
Batch 49/64 loss: 0.2079792022705078
Batch 50/64 loss: 0.19366759061813354
Batch 51/64 loss: 0.20589250326156616
Batch 52/64 loss: 0.18774843215942383
Batch 53/64 loss: 0.20099300146102905
Batch 54/64 loss: 0.19496405124664307
Batch 55/64 loss: 0.20055145025253296
Batch 56/64 loss: 0.19794458150863647
Batch 57/64 loss: 0.19684135913848877
Batch 58/64 loss: 0.2059118151664734
Batch 59/64 loss: 0.20399802923202515
Batch 60/64 loss: 0.20414334535598755
Batch 61/64 loss: 0.1966453194618225
Batch 62/64 loss: 0.20637381076812744
Batch 63/64 loss: 0.1973753571510315
Batch 64/64 loss: 0.20815783739089966
Epoch 465  Train loss: 0.197869344552358  Val loss: 0.2702943819904655
Epoch 466
-------------------------------
Batch 1/64 loss: 0.19745343923568726
Batch 2/64 loss: 0.190118670463562
Batch 3/64 loss: 0.19833755493164062
Batch 4/64 loss: 0.19567811489105225
Batch 5/64 loss: 0.1940726637840271
Batch 6/64 loss: 0.19375473260879517
Batch 7/64 loss: 0.19527143239974976
Batch 8/64 loss: 0.19198226928710938
Batch 9/64 loss: 0.19732975959777832
Batch 10/64 loss: 0.20157277584075928
Batch 11/64 loss: 0.20530688762664795
Batch 12/64 loss: 0.18795061111450195
Batch 13/64 loss: 0.19061124324798584
Batch 14/64 loss: 0.19060122966766357
Batch 15/64 loss: 0.20785248279571533
Batch 16/64 loss: 0.20972460508346558
Batch 17/64 loss: 0.20520305633544922
Batch 18/64 loss: 0.1909809112548828
Batch 19/64 loss: 0.18828696012496948
Batch 20/64 loss: 0.19327741861343384
Batch 21/64 loss: 0.19371867179870605
Batch 22/64 loss: 0.19034945964813232
Batch 23/64 loss: 0.19375091791152954
Batch 24/64 loss: 0.19022971391677856
Batch 25/64 loss: 0.1976402997970581
Batch 26/64 loss: 0.20943224430084229
Batch 27/64 loss: 0.19877898693084717
Batch 28/64 loss: 0.19456720352172852
Batch 29/64 loss: 0.18545293807983398
Batch 30/64 loss: 0.18688470125198364
Batch 31/64 loss: 0.19546997547149658
Batch 32/64 loss: 0.197912335395813
Batch 33/64 loss: 0.19871318340301514
Batch 34/64 loss: 0.1854393482208252
Batch 35/64 loss: 0.1920662522315979
Batch 36/64 loss: 0.19985461235046387
Batch 37/64 loss: 0.19066733121871948
Batch 38/64 loss: 0.19766950607299805
Batch 39/64 loss: 0.1949704885482788
Batch 40/64 loss: 0.1978522539138794
Batch 41/64 loss: 0.20494580268859863
Batch 42/64 loss: 0.1955246925354004
Batch 43/64 loss: 0.19788187742233276
Batch 44/64 loss: 0.18800204992294312
Batch 45/64 loss: 0.1931077241897583
Batch 46/64 loss: 0.19249963760375977
Batch 47/64 loss: 0.19192618131637573
Batch 48/64 loss: 0.20536738634109497
Batch 49/64 loss: 0.2108781337738037
Batch 50/64 loss: 0.2016192078590393
Batch 51/64 loss: 0.2026544213294983
Batch 52/64 loss: 0.19509810209274292
Batch 53/64 loss: 0.1913834810256958
Batch 54/64 loss: 0.21522700786590576
Batch 55/64 loss: 0.19385117292404175
Batch 56/64 loss: 0.19381487369537354
Batch 57/64 loss: 0.2035406231880188
Batch 58/64 loss: 0.19277840852737427
Batch 59/64 loss: 0.20650756359100342
Batch 60/64 loss: 0.19984281063079834
Batch 61/64 loss: 0.19009840488433838
Batch 62/64 loss: 0.20932888984680176
Batch 63/64 loss: 0.20841413736343384
Batch 64/64 loss: 0.20233964920043945
Epoch 466  Train loss: 0.19690720894757438  Val loss: 0.2698043023597744
Epoch 467
-------------------------------
Batch 1/64 loss: 0.20096564292907715
Batch 2/64 loss: 0.18720602989196777
Batch 3/64 loss: 0.19337397813796997
Batch 4/64 loss: 0.19017314910888672
Batch 5/64 loss: 0.196405291557312
Batch 6/64 loss: 0.19486701488494873
Batch 7/64 loss: 0.19899272918701172
Batch 8/64 loss: 0.19231528043746948
Batch 9/64 loss: 0.18376928567886353
Batch 10/64 loss: 0.1908334493637085
Batch 11/64 loss: 0.19656360149383545
Batch 12/64 loss: 0.19306260347366333
Batch 13/64 loss: 0.1967325210571289
Batch 14/64 loss: 0.20853298902511597
Batch 15/64 loss: 0.1916852593421936
Batch 16/64 loss: 0.18721342086791992
Batch 17/64 loss: 0.2003539800643921
Batch 18/64 loss: 0.19743800163269043
Batch 19/64 loss: 0.19775038957595825
Batch 20/64 loss: 0.20009362697601318
Batch 21/64 loss: 0.1902472972869873
Batch 22/64 loss: 0.19340121746063232
Batch 23/64 loss: 0.19318848848342896
Batch 24/64 loss: 0.19947880506515503
Batch 25/64 loss: 0.20270979404449463
Batch 26/64 loss: 0.19529050588607788
Batch 27/64 loss: 0.19959378242492676
Batch 28/64 loss: 0.19261610507965088
Batch 29/64 loss: 0.20015370845794678
Batch 30/64 loss: 0.20643550157546997
Batch 31/64 loss: 0.20794332027435303
Batch 32/64 loss: 0.20029282569885254
Batch 33/64 loss: 0.18971508741378784
Batch 34/64 loss: 0.1965673565864563
Batch 35/64 loss: 0.1971341371536255
Batch 36/64 loss: 0.2022290825843811
Batch 37/64 loss: 0.19360852241516113
Batch 38/64 loss: 0.191575825214386
Batch 39/64 loss: 0.19095951318740845
Batch 40/64 loss: 0.21508818864822388
Batch 41/64 loss: 0.21094930171966553
Batch 42/64 loss: 0.18493640422821045
Batch 43/64 loss: 0.18916338682174683
Batch 44/64 loss: 0.1919339895248413
Batch 45/64 loss: 0.20361101627349854
Batch 46/64 loss: 0.20211684703826904
Batch 47/64 loss: 0.19854694604873657
Batch 48/64 loss: 0.20185136795043945
Batch 49/64 loss: 0.20055055618286133
Batch 50/64 loss: 0.21355336904525757
Batch 51/64 loss: 0.20212745666503906
Batch 52/64 loss: 0.19910484552383423
Batch 53/64 loss: 0.20344054698944092
Batch 54/64 loss: 0.19075429439544678
Batch 55/64 loss: 0.2017863392829895
Batch 56/64 loss: 0.20410555601119995
Batch 57/64 loss: 0.1924692988395691
Batch 58/64 loss: 0.18634402751922607
Batch 59/64 loss: 0.1996942162513733
Batch 60/64 loss: 0.20016682147979736
Batch 61/64 loss: 0.20440274477005005
Batch 62/64 loss: 0.194815993309021
Batch 63/64 loss: 0.1948920488357544
Batch 64/64 loss: 0.19996070861816406
Epoch 467  Train loss: 0.19729953279682233  Val loss: 0.27024216340579527
Epoch 468
-------------------------------
Batch 1/64 loss: 0.19246286153793335
Batch 2/64 loss: 0.19310206174850464
Batch 3/64 loss: 0.20411771535873413
Batch 4/64 loss: 0.19601333141326904
Batch 5/64 loss: 0.19570589065551758
Batch 6/64 loss: 0.2114199995994568
Batch 7/64 loss: 0.19709265232086182
Batch 8/64 loss: 0.18498307466506958
Batch 9/64 loss: 0.19174712896347046
Batch 10/64 loss: 0.1983553171157837
Batch 11/64 loss: 0.19160360097885132
Batch 12/64 loss: 0.19979214668273926
Batch 13/64 loss: 0.18884843587875366
Batch 14/64 loss: 0.18705201148986816
Batch 15/64 loss: 0.20546621084213257
Batch 16/64 loss: 0.20422512292861938
Batch 17/64 loss: 0.204318106174469
Batch 18/64 loss: 0.19386380910873413
Batch 19/64 loss: 0.20548832416534424
Batch 20/64 loss: 0.20101237297058105
Batch 21/64 loss: 0.19819331169128418
Batch 22/64 loss: 0.19793576002120972
Batch 23/64 loss: 0.20178478956222534
Batch 24/64 loss: 0.19654130935668945
Batch 25/64 loss: 0.19737029075622559
Batch 26/64 loss: 0.2008543610572815
Batch 27/64 loss: 0.19811677932739258
Batch 28/64 loss: 0.20647591352462769
Batch 29/64 loss: 0.1966923475265503
Batch 30/64 loss: 0.19517308473587036
Batch 31/64 loss: 0.20697230100631714
Batch 32/64 loss: 0.1869613528251648
Batch 33/64 loss: 0.19287419319152832
Batch 34/64 loss: 0.19875866174697876
Batch 35/64 loss: 0.19465011358261108
Batch 36/64 loss: 0.20052754878997803
Batch 37/64 loss: 0.19374632835388184
Batch 38/64 loss: 0.1917286515235901
Batch 39/64 loss: 0.18830657005310059
Batch 40/64 loss: 0.19881105422973633
Batch 41/64 loss: 0.19365650415420532
Batch 42/64 loss: 0.19505560398101807
Batch 43/64 loss: 0.20203757286071777
Batch 44/64 loss: 0.19434863328933716
Batch 45/64 loss: 0.19439435005187988
Batch 46/64 loss: 0.19828474521636963
Batch 47/64 loss: 0.20809268951416016
Batch 48/64 loss: 0.1990976333618164
Batch 49/64 loss: 0.1985214352607727
Batch 50/64 loss: 0.20088720321655273
Batch 51/64 loss: 0.21039831638336182
Batch 52/64 loss: 0.19983124732971191
Batch 53/64 loss: 0.20135855674743652
Batch 54/64 loss: 0.19432157278060913
Batch 55/64 loss: 0.2002938985824585
Batch 56/64 loss: 0.19815689325332642
Batch 57/64 loss: 0.19316786527633667
Batch 58/64 loss: 0.20349335670471191
Batch 59/64 loss: 0.19330018758773804
Batch 60/64 loss: 0.20178675651550293
Batch 61/64 loss: 0.2016998529434204
Batch 62/64 loss: 0.19073057174682617
Batch 63/64 loss: 0.19339650869369507
Batch 64/64 loss: 0.1936095952987671
Epoch 468  Train loss: 0.19765747528450162  Val loss: 0.27072929127519485
Epoch 469
-------------------------------
Batch 1/64 loss: 0.20497238636016846
Batch 2/64 loss: 0.1976526379585266
Batch 3/64 loss: 0.196586012840271
Batch 4/64 loss: 0.19430774450302124
Batch 5/64 loss: 0.19700485467910767
Batch 6/64 loss: 0.19433915615081787
Batch 7/64 loss: 0.19159644842147827
Batch 8/64 loss: 0.19098901748657227
Batch 9/64 loss: 0.1896507740020752
Batch 10/64 loss: 0.20220321416854858
Batch 11/64 loss: 0.19188058376312256
Batch 12/64 loss: 0.2016882300376892
Batch 13/64 loss: 0.2005351185798645
Batch 14/64 loss: 0.1920756697654724
Batch 15/64 loss: 0.19584321975708008
Batch 16/64 loss: 0.1937769651412964
Batch 17/64 loss: 0.1871170997619629
Batch 18/64 loss: 0.19924938678741455
Batch 19/64 loss: 0.19110941886901855
Batch 20/64 loss: 0.19613736867904663
Batch 21/64 loss: 0.2035231590270996
Batch 22/64 loss: 0.19935834407806396
Batch 23/64 loss: 0.19881689548492432
Batch 24/64 loss: 0.19466936588287354
Batch 25/64 loss: 0.20032072067260742
Batch 26/64 loss: 0.20285773277282715
Batch 27/64 loss: 0.18832683563232422
Batch 28/64 loss: 0.1954771876335144
Batch 29/64 loss: 0.19729453325271606
Batch 30/64 loss: 0.20689570903778076
Batch 31/64 loss: 0.19703400135040283
Batch 32/64 loss: 0.20739257335662842
Batch 33/64 loss: 0.19601857662200928
Batch 34/64 loss: 0.20692801475524902
Batch 35/64 loss: 0.19277912378311157
Batch 36/64 loss: 0.2021675705909729
Batch 37/64 loss: 0.203313410282135
Batch 38/64 loss: 0.1905251145362854
Batch 39/64 loss: 0.19622427225112915
Batch 40/64 loss: 0.19816666841506958
Batch 41/64 loss: 0.19770312309265137
Batch 42/64 loss: 0.19847780466079712
Batch 43/64 loss: 0.1969897747039795
Batch 44/64 loss: 0.19765037298202515
Batch 45/64 loss: 0.19516170024871826
Batch 46/64 loss: 0.2150881290435791
Batch 47/64 loss: 0.19848638772964478
Batch 48/64 loss: 0.20005154609680176
Batch 49/64 loss: 0.2007749080657959
Batch 50/64 loss: 0.1905355453491211
Batch 51/64 loss: 0.19454973936080933
Batch 52/64 loss: 0.1903696060180664
Batch 53/64 loss: 0.20606380701065063
Batch 54/64 loss: 0.20370852947235107
Batch 55/64 loss: 0.19422459602355957
Batch 56/64 loss: 0.1937236189842224
Batch 57/64 loss: 0.20415353775024414
Batch 58/64 loss: 0.19094979763031006
Batch 59/64 loss: 0.20331668853759766
Batch 60/64 loss: 0.1986737847328186
Batch 61/64 loss: 0.203441321849823
Batch 62/64 loss: 0.19824647903442383
Batch 63/64 loss: 0.2057858109474182
Batch 64/64 loss: 0.19433510303497314
Epoch 469  Train loss: 0.19781463613697126  Val loss: 0.2704117640187241
Epoch 470
-------------------------------
Batch 1/64 loss: 0.2156674861907959
Batch 2/64 loss: 0.19337379932403564
Batch 3/64 loss: 0.1987432837486267
Batch 4/64 loss: 0.19172567129135132
Batch 5/64 loss: 0.19070613384246826
Batch 6/64 loss: 0.20064103603363037
Batch 7/64 loss: 0.18753105401992798
Batch 8/64 loss: 0.19130253791809082
Batch 9/64 loss: 0.18675678968429565
Batch 10/64 loss: 0.19374191761016846
Batch 11/64 loss: 0.1888027787208557
Batch 12/64 loss: 0.19020438194274902
Batch 13/64 loss: 0.19787126779556274
Batch 14/64 loss: 0.1985653042793274
Batch 15/64 loss: 0.1987534761428833
Batch 16/64 loss: 0.19860053062438965
Batch 17/64 loss: 0.2024531364440918
Batch 18/64 loss: 0.2010607123374939
Batch 19/64 loss: 0.19888508319854736
Batch 20/64 loss: 0.2000255584716797
Batch 21/64 loss: 0.2009846568107605
Batch 22/64 loss: 0.19330525398254395
Batch 23/64 loss: 0.1918802261352539
Batch 24/64 loss: 0.19161498546600342
Batch 25/64 loss: 0.1889132857322693
Batch 26/64 loss: 0.1928158402442932
Batch 27/64 loss: 0.2093380093574524
Batch 28/64 loss: 0.19266963005065918
Batch 29/64 loss: 0.20162123441696167
Batch 30/64 loss: 0.19574379920959473
Batch 31/64 loss: 0.19862306118011475
Batch 32/64 loss: 0.20112895965576172
Batch 33/64 loss: 0.20563393831253052
Batch 34/64 loss: 0.19151413440704346
Batch 35/64 loss: 0.1847640872001648
Batch 36/64 loss: 0.2009374499320984
Batch 37/64 loss: 0.21892249584197998
Batch 38/64 loss: 0.19613391160964966
Batch 39/64 loss: 0.1976061463356018
Batch 40/64 loss: 0.20004981756210327
Batch 41/64 loss: 0.20528525114059448
Batch 42/64 loss: 0.19713491201400757
Batch 43/64 loss: 0.19418084621429443
Batch 44/64 loss: 0.18442124128341675
Batch 45/64 loss: 0.22140419483184814
Batch 46/64 loss: 0.1971803903579712
Batch 47/64 loss: 0.2001456618309021
Batch 48/64 loss: 0.19732850790023804
Batch 49/64 loss: 0.19268405437469482
Batch 50/64 loss: 0.19650673866271973
Batch 51/64 loss: 0.19783848524093628
Batch 52/64 loss: 0.1957693099975586
Batch 53/64 loss: 0.1940729022026062
Batch 54/64 loss: 0.1996665596961975
Batch 55/64 loss: 0.20740610361099243
Batch 56/64 loss: 0.20444178581237793
Batch 57/64 loss: 0.19683867692947388
Batch 58/64 loss: 0.19707751274108887
Batch 59/64 loss: 0.20341706275939941
Batch 60/64 loss: 0.20702636241912842
Batch 61/64 loss: 0.20642542839050293
Batch 62/64 loss: 0.19691568613052368
Batch 63/64 loss: 0.20003360509872437
Batch 64/64 loss: 0.19644784927368164
Epoch 470  Train loss: 0.19796313772014543  Val loss: 0.26974943454322947
Epoch 471
-------------------------------
Batch 1/64 loss: 0.19113308191299438
Batch 2/64 loss: 0.20522677898406982
Batch 3/64 loss: 0.19360709190368652
Batch 4/64 loss: 0.20173686742782593
Batch 5/64 loss: 0.18892443180084229
Batch 6/64 loss: 0.19438660144805908
Batch 7/64 loss: 0.19158726930618286
Batch 8/64 loss: 0.206290602684021
Batch 9/64 loss: 0.19983810186386108
Batch 10/64 loss: 0.18672966957092285
Batch 11/64 loss: 0.1948840618133545
Batch 12/64 loss: 0.19474023580551147
Batch 13/64 loss: 0.18749815225601196
Batch 14/64 loss: 0.1989864706993103
Batch 15/64 loss: 0.20887857675552368
Batch 16/64 loss: 0.19183939695358276
Batch 17/64 loss: 0.18487030267715454
Batch 18/64 loss: 0.19427704811096191
Batch 19/64 loss: 0.19896745681762695
Batch 20/64 loss: 0.19629859924316406
Batch 21/64 loss: 0.20555412769317627
Batch 22/64 loss: 0.2017810344696045
Batch 23/64 loss: 0.1912517547607422
Batch 24/64 loss: 0.18962353467941284
Batch 25/64 loss: 0.20835787057876587
Batch 26/64 loss: 0.18958747386932373
Batch 27/64 loss: 0.19808465242385864
Batch 28/64 loss: 0.20616573095321655
Batch 29/64 loss: 0.19381844997406006
Batch 30/64 loss: 0.19219589233398438
Batch 31/64 loss: 0.20833933353424072
Batch 32/64 loss: 0.18920296430587769
Batch 33/64 loss: 0.19369953870773315
Batch 34/64 loss: 0.2035970687866211
Batch 35/64 loss: 0.1956925392150879
Batch 36/64 loss: 0.1937536597251892
Batch 37/64 loss: 0.194521963596344
Batch 38/64 loss: 0.19343578815460205
Batch 39/64 loss: 0.20190316438674927
Batch 40/64 loss: 0.19273942708969116
Batch 41/64 loss: 0.19738143682479858
Batch 42/64 loss: 0.20545142889022827
Batch 43/64 loss: 0.19385075569152832
Batch 44/64 loss: 0.20590269565582275
Batch 45/64 loss: 0.1938685178756714
Batch 46/64 loss: 0.2006741166114807
Batch 47/64 loss: 0.19860482215881348
Batch 48/64 loss: 0.2006450891494751
Batch 49/64 loss: 0.1967204213142395
Batch 50/64 loss: 0.19555425643920898
Batch 51/64 loss: 0.19509422779083252
Batch 52/64 loss: 0.20662999153137207
Batch 53/64 loss: 0.19296795129776
Batch 54/64 loss: 0.1921842098236084
Batch 55/64 loss: 0.1928551197052002
Batch 56/64 loss: 0.2040235996246338
Batch 57/64 loss: 0.20044708251953125
Batch 58/64 loss: 0.19872236251831055
Batch 59/64 loss: 0.1976090669631958
Batch 60/64 loss: 0.19427895545959473
Batch 61/64 loss: 0.2046545147895813
Batch 62/64 loss: 0.2036435604095459
Batch 63/64 loss: 0.19941669702529907
Batch 64/64 loss: 0.2007521390914917
Epoch 471  Train loss: 0.19726669414370668  Val loss: 0.27028648140504186
Epoch 472
-------------------------------
Batch 1/64 loss: 0.18891054391860962
Batch 2/64 loss: 0.20228326320648193
Batch 3/64 loss: 0.1893123984336853
Batch 4/64 loss: 0.2069820761680603
Batch 5/64 loss: 0.19416218996047974
Batch 6/64 loss: 0.19672727584838867
Batch 7/64 loss: 0.19220274686813354
Batch 8/64 loss: 0.19769835472106934
Batch 9/64 loss: 0.20076227188110352
Batch 10/64 loss: 0.19147098064422607
Batch 11/64 loss: 0.2094430923461914
Batch 12/64 loss: 0.1896253228187561
Batch 13/64 loss: 0.19870012998580933
Batch 14/64 loss: 0.1901613473892212
Batch 15/64 loss: 0.19428890943527222
Batch 16/64 loss: 0.1972476840019226
Batch 17/64 loss: 0.19068080186843872
Batch 18/64 loss: 0.19690877199172974
Batch 19/64 loss: 0.19144850969314575
Batch 20/64 loss: 0.19424676895141602
Batch 21/64 loss: 0.1886594295501709
Batch 22/64 loss: 0.20927554368972778
Batch 23/64 loss: 0.1973678469657898
Batch 24/64 loss: 0.18743973970413208
Batch 25/64 loss: 0.19468843936920166
Batch 26/64 loss: 0.1944788694381714
Batch 27/64 loss: 0.20044398307800293
Batch 28/64 loss: 0.19316160678863525
Batch 29/64 loss: 0.19339501857757568
Batch 30/64 loss: 0.20023691654205322
Batch 31/64 loss: 0.19371432065963745
Batch 32/64 loss: 0.20388376712799072
Batch 33/64 loss: 0.19654548168182373
Batch 34/64 loss: 0.2000707983970642
Batch 35/64 loss: 0.19118386507034302
Batch 36/64 loss: 0.2002347707748413
Batch 37/64 loss: 0.19505763053894043
Batch 38/64 loss: 0.1982487440109253
Batch 39/64 loss: 0.2018742561340332
Batch 40/64 loss: 0.20728957653045654
Batch 41/64 loss: 0.1971772313117981
Batch 42/64 loss: 0.1951943039894104
Batch 43/64 loss: 0.19738256931304932
Batch 44/64 loss: 0.19524389505386353
Batch 45/64 loss: 0.1929348111152649
Batch 46/64 loss: 0.19699060916900635
Batch 47/64 loss: 0.1909000277519226
Batch 48/64 loss: 0.20924663543701172
Batch 49/64 loss: 0.19280868768692017
Batch 50/64 loss: 0.20151716470718384
Batch 51/64 loss: 0.20312833786010742
Batch 52/64 loss: 0.184515118598938
Batch 53/64 loss: 0.2017880082130432
Batch 54/64 loss: 0.18711203336715698
Batch 55/64 loss: 0.19617599248886108
Batch 56/64 loss: 0.1991536021232605
Batch 57/64 loss: 0.19651257991790771
Batch 58/64 loss: 0.19092512130737305
Batch 59/64 loss: 0.1909499168395996
Batch 60/64 loss: 0.20386481285095215
Batch 61/64 loss: 0.19927763938903809
Batch 62/64 loss: 0.19463837146759033
Batch 63/64 loss: 0.1896016001701355
Batch 64/64 loss: 0.19356966018676758
Epoch 472  Train loss: 0.19627812329460592  Val loss: 0.2701411112067626
Epoch 473
-------------------------------
Batch 1/64 loss: 0.18723595142364502
Batch 2/64 loss: 0.20030993223190308
Batch 3/64 loss: 0.18130791187286377
Batch 4/64 loss: 0.20196807384490967
Batch 5/64 loss: 0.2023613452911377
Batch 6/64 loss: 0.19123965501785278
Batch 7/64 loss: 0.19393765926361084
Batch 8/64 loss: 0.19343608617782593
Batch 9/64 loss: 0.1961560845375061
Batch 10/64 loss: 0.18984752893447876
Batch 11/64 loss: 0.18432772159576416
Batch 12/64 loss: 0.19326001405715942
Batch 13/64 loss: 0.18928813934326172
Batch 14/64 loss: 0.18624001741409302
Batch 15/64 loss: 0.1967703104019165
Batch 16/64 loss: 0.19587892293930054
Batch 17/64 loss: 0.19073164463043213
Batch 18/64 loss: 0.19764363765716553
Batch 19/64 loss: 0.19662153720855713
Batch 20/64 loss: 0.20474869012832642
Batch 21/64 loss: 0.1975368857383728
Batch 22/64 loss: 0.1919812560081482
Batch 23/64 loss: 0.19858324527740479
Batch 24/64 loss: 0.2009960412979126
Batch 25/64 loss: 0.19660168886184692
Batch 26/64 loss: 0.207319974899292
Batch 27/64 loss: 0.19296890497207642
Batch 28/64 loss: 0.19336241483688354
Batch 29/64 loss: 0.1966087818145752
Batch 30/64 loss: 0.20786535739898682
Batch 31/64 loss: 0.19648420810699463
Batch 32/64 loss: 0.18804198503494263
Batch 33/64 loss: 0.19442909955978394
Batch 34/64 loss: 0.19471514225006104
Batch 35/64 loss: 0.20583832263946533
Batch 36/64 loss: 0.1905604600906372
Batch 37/64 loss: 0.18328940868377686
Batch 38/64 loss: 0.1917668581008911
Batch 39/64 loss: 0.1985117793083191
Batch 40/64 loss: 0.19131743907928467
Batch 41/64 loss: 0.19467926025390625
Batch 42/64 loss: 0.19378143548965454
Batch 43/64 loss: 0.2034485936164856
Batch 44/64 loss: 0.19431042671203613
Batch 45/64 loss: 0.19551116228103638
Batch 46/64 loss: 0.19590485095977783
Batch 47/64 loss: 0.21022582054138184
Batch 48/64 loss: 0.20300310850143433
Batch 49/64 loss: 0.1925266981124878
Batch 50/64 loss: 0.19270461797714233
Batch 51/64 loss: 0.207871675491333
Batch 52/64 loss: 0.2011464238166809
Batch 53/64 loss: 0.19916623830795288
Batch 54/64 loss: 0.20215368270874023
Batch 55/64 loss: 0.20469766855239868
Batch 56/64 loss: 0.19120287895202637
Batch 57/64 loss: 0.20597004890441895
Batch 58/64 loss: 0.20494407415390015
Batch 59/64 loss: 0.19067078828811646
Batch 60/64 loss: 0.19532722234725952
Batch 61/64 loss: 0.20109283924102783
Batch 62/64 loss: 0.1929556131362915
Batch 63/64 loss: 0.20779883861541748
Batch 64/64 loss: 0.1910400390625
Epoch 473  Train loss: 0.19633669198728076  Val loss: 0.26997099975540056
Epoch 474
-------------------------------
Batch 1/64 loss: 0.19389289617538452
Batch 2/64 loss: 0.19086593389511108
Batch 3/64 loss: 0.20027047395706177
Batch 4/64 loss: 0.196743905544281
Batch 5/64 loss: 0.1930016279220581
Batch 6/64 loss: 0.18762409687042236
Batch 7/64 loss: 0.2098839282989502
Batch 8/64 loss: 0.1894087791442871
Batch 9/64 loss: 0.2099456787109375
Batch 10/64 loss: 0.1993657946586609
Batch 11/64 loss: 0.19457608461380005
Batch 12/64 loss: 0.2006213665008545
Batch 13/64 loss: 0.19327282905578613
Batch 14/64 loss: 0.20545107126235962
Batch 15/64 loss: 0.19382202625274658
Batch 16/64 loss: 0.19673079252243042
Batch 17/64 loss: 0.19396138191223145
Batch 18/64 loss: 0.1910872459411621
Batch 19/64 loss: 0.19210195541381836
Batch 20/64 loss: 0.19216620922088623
Batch 21/64 loss: 0.19914543628692627
Batch 22/64 loss: 0.19148463010787964
Batch 23/64 loss: 0.19597917795181274
Batch 24/64 loss: 0.18933969736099243
Batch 25/64 loss: 0.19932454824447632
Batch 26/64 loss: 0.19114458560943604
Batch 27/64 loss: 0.19304239749908447
Batch 28/64 loss: 0.192676842212677
Batch 29/64 loss: 0.19005894660949707
Batch 30/64 loss: 0.20669883489608765
Batch 31/64 loss: 0.1974172592163086
Batch 32/64 loss: 0.20509397983551025
Batch 33/64 loss: 0.19050228595733643
Batch 34/64 loss: 0.18760329484939575
Batch 35/64 loss: 0.19850611686706543
Batch 36/64 loss: 0.19859230518341064
Batch 37/64 loss: 0.20407426357269287
Batch 38/64 loss: 0.1861422061920166
Batch 39/64 loss: 0.1937047243118286
Batch 40/64 loss: 0.19088101387023926
Batch 41/64 loss: 0.1969098448753357
Batch 42/64 loss: 0.19732677936553955
Batch 43/64 loss: 0.19389814138412476
Batch 44/64 loss: 0.20019280910491943
Batch 45/64 loss: 0.20775294303894043
Batch 46/64 loss: 0.1960243582725525
Batch 47/64 loss: 0.18720722198486328
Batch 48/64 loss: 0.2032163143157959
Batch 49/64 loss: 0.19203788042068481
Batch 50/64 loss: 0.19064807891845703
Batch 51/64 loss: 0.19864022731781006
Batch 52/64 loss: 0.19343268871307373
Batch 53/64 loss: 0.20305824279785156
Batch 54/64 loss: 0.19643950462341309
Batch 55/64 loss: 0.2013593316078186
Batch 56/64 loss: 0.19614559412002563
Batch 57/64 loss: 0.18416017293930054
Batch 58/64 loss: 0.1985769271850586
Batch 59/64 loss: 0.18700295686721802
Batch 60/64 loss: 0.19875788688659668
Batch 61/64 loss: 0.18997502326965332
Batch 62/64 loss: 0.20533382892608643
Batch 63/64 loss: 0.20478177070617676
Batch 64/64 loss: 0.19371575117111206
Epoch 474  Train loss: 0.19599014847886329  Val loss: 0.2694343281365752
Epoch 475
-------------------------------
Batch 1/64 loss: 0.19696533679962158
Batch 2/64 loss: 0.1923593282699585
Batch 3/64 loss: 0.20385348796844482
Batch 4/64 loss: 0.18999862670898438
Batch 5/64 loss: 0.20080149173736572
Batch 6/64 loss: 0.19831222295761108
Batch 7/64 loss: 0.1934836506843567
Batch 8/64 loss: 0.19646179676055908
Batch 9/64 loss: 0.20134323835372925
Batch 10/64 loss: 0.1908046007156372
Batch 11/64 loss: 0.18638694286346436
Batch 12/64 loss: 0.19668853282928467
Batch 13/64 loss: 0.19956421852111816
Batch 14/64 loss: 0.18983852863311768
Batch 15/64 loss: 0.19161051511764526
Batch 16/64 loss: 0.19115722179412842
Batch 17/64 loss: 0.1961665153503418
Batch 18/64 loss: 0.1893710494041443
Batch 19/64 loss: 0.18567156791687012
Batch 20/64 loss: 0.1914360523223877
Batch 21/64 loss: 0.19485890865325928
Batch 22/64 loss: 0.19443005323410034
Batch 23/64 loss: 0.19651108980178833
Batch 24/64 loss: 0.20175719261169434
Batch 25/64 loss: 0.19007140398025513
Batch 26/64 loss: 0.19463670253753662
Batch 27/64 loss: 0.1989971399307251
Batch 28/64 loss: 0.1927815079689026
Batch 29/64 loss: 0.1975998878479004
Batch 30/64 loss: 0.20413058996200562
Batch 31/64 loss: 0.1869434118270874
Batch 32/64 loss: 0.1968669891357422
Batch 33/64 loss: 0.20332098007202148
Batch 34/64 loss: 0.19057011604309082
Batch 35/64 loss: 0.19945263862609863
Batch 36/64 loss: 0.1892021894454956
Batch 37/64 loss: 0.19424939155578613
Batch 38/64 loss: 0.19951140880584717
Batch 39/64 loss: 0.20045512914657593
Batch 40/64 loss: 0.20347458124160767
Batch 41/64 loss: 0.1949547529220581
Batch 42/64 loss: 0.19788408279418945
Batch 43/64 loss: 0.18577909469604492
Batch 44/64 loss: 0.20505094528198242
Batch 45/64 loss: 0.19244009256362915
Batch 46/64 loss: 0.19396817684173584
Batch 47/64 loss: 0.19437867403030396
Batch 48/64 loss: 0.1964946985244751
Batch 49/64 loss: 0.19037455320358276
Batch 50/64 loss: 0.1937776803970337
Batch 51/64 loss: 0.20115000009536743
Batch 52/64 loss: 0.1856827735900879
Batch 53/64 loss: 0.1931653618812561
Batch 54/64 loss: 0.1942186951637268
Batch 55/64 loss: 0.20351099967956543
Batch 56/64 loss: 0.1945464015007019
Batch 57/64 loss: 0.19367611408233643
Batch 58/64 loss: 0.19144022464752197
Batch 59/64 loss: 0.1963210105895996
Batch 60/64 loss: 0.19946390390396118
Batch 61/64 loss: 0.19646412134170532
Batch 62/64 loss: 0.20864027738571167
Batch 63/64 loss: 0.2131199836730957
Batch 64/64 loss: 0.20557820796966553
Epoch 475  Train loss: 0.19580835314357983  Val loss: 0.2694233315916815
Epoch 476
-------------------------------
Batch 1/64 loss: 0.20017147064208984
Batch 2/64 loss: 0.18974995613098145
Batch 3/64 loss: 0.19767272472381592
Batch 4/64 loss: 0.19914406538009644
Batch 5/64 loss: 0.19660896062850952
Batch 6/64 loss: 0.2003922462463379
Batch 7/64 loss: 0.18794745206832886
Batch 8/64 loss: 0.18824219703674316
Batch 9/64 loss: 0.20288962125778198
Batch 10/64 loss: 0.187286376953125
Batch 11/64 loss: 0.19282793998718262
Batch 12/64 loss: 0.18592238426208496
Batch 13/64 loss: 0.19334077835083008
Batch 14/64 loss: 0.19445455074310303
Batch 15/64 loss: 0.1983044147491455
Batch 16/64 loss: 0.19414865970611572
Batch 17/64 loss: 0.19879108667373657
Batch 18/64 loss: 0.18691807985305786
Batch 19/64 loss: 0.1960616111755371
Batch 20/64 loss: 0.18951398134231567
Batch 21/64 loss: 0.1986669898033142
Batch 22/64 loss: 0.19195419549942017
Batch 23/64 loss: 0.19637465476989746
Batch 24/64 loss: 0.18683230876922607
Batch 25/64 loss: 0.19245409965515137
Batch 26/64 loss: 0.19476741552352905
Batch 27/64 loss: 0.19408780336380005
Batch 28/64 loss: 0.20246481895446777
Batch 29/64 loss: 0.20474624633789062
Batch 30/64 loss: 0.19021642208099365
Batch 31/64 loss: 0.1985589861869812
Batch 32/64 loss: 0.1985100507736206
Batch 33/64 loss: 0.20392680168151855
Batch 34/64 loss: 0.20508325099945068
Batch 35/64 loss: 0.20155638456344604
Batch 36/64 loss: 0.18555015325546265
Batch 37/64 loss: 0.2008577585220337
Batch 38/64 loss: 0.2016887068748474
Batch 39/64 loss: 0.20163077116012573
Batch 40/64 loss: 0.19585680961608887
Batch 41/64 loss: 0.19580990076065063
Batch 42/64 loss: 0.20384663343429565
Batch 43/64 loss: 0.18726801872253418
Batch 44/64 loss: 0.1867903470993042
Batch 45/64 loss: 0.1941995620727539
Batch 46/64 loss: 0.20970028638839722
Batch 47/64 loss: 0.19229602813720703
Batch 48/64 loss: 0.20232778787612915
Batch 49/64 loss: 0.197351336479187
Batch 50/64 loss: 0.19358378648757935
Batch 51/64 loss: 0.18737822771072388
Batch 52/64 loss: 0.2006772756576538
Batch 53/64 loss: 0.19590920209884644
Batch 54/64 loss: 0.19789928197860718
Batch 55/64 loss: 0.19948220252990723
Batch 56/64 loss: 0.1913447380065918
Batch 57/64 loss: 0.2055414915084839
Batch 58/64 loss: 0.20443445444107056
Batch 59/64 loss: 0.20254164934158325
Batch 60/64 loss: 0.18636095523834229
Batch 61/64 loss: 0.19109368324279785
Batch 62/64 loss: 0.1928737759590149
Batch 63/64 loss: 0.19623219966888428
Batch 64/64 loss: 0.19992518424987793
Epoch 476  Train loss: 0.1959381944992963  Val loss: 0.2700682272206467
Epoch 477
-------------------------------
Batch 1/64 loss: 0.19571751356124878
Batch 2/64 loss: 0.2009270191192627
Batch 3/64 loss: 0.20097756385803223
Batch 4/64 loss: 0.1939564347267151
Batch 5/64 loss: 0.19121849536895752
Batch 6/64 loss: 0.19108229875564575
Batch 7/64 loss: 0.20720642805099487
Batch 8/64 loss: 0.21148264408111572
Batch 9/64 loss: 0.19715571403503418
Batch 10/64 loss: 0.19484418630599976
Batch 11/64 loss: 0.195576012134552
Batch 12/64 loss: 0.19601720571517944
Batch 13/64 loss: 0.20121610164642334
Batch 14/64 loss: 0.19516205787658691
Batch 15/64 loss: 0.19892048835754395
Batch 16/64 loss: 0.19629281759262085
Batch 17/64 loss: 0.19224470853805542
Batch 18/64 loss: 0.19100630283355713
Batch 19/64 loss: 0.1917322278022766
Batch 20/64 loss: 0.1937989592552185
Batch 21/64 loss: 0.18692845106124878
Batch 22/64 loss: 0.1894007921218872
Batch 23/64 loss: 0.19710451364517212
Batch 24/64 loss: 0.18713873624801636
Batch 25/64 loss: 0.19267868995666504
Batch 26/64 loss: 0.18736517429351807
Batch 27/64 loss: 0.19252514839172363
Batch 28/64 loss: 0.1909315586090088
Batch 29/64 loss: 0.19807332754135132
Batch 30/64 loss: 0.20492225885391235
Batch 31/64 loss: 0.19682514667510986
Batch 32/64 loss: 0.19174814224243164
Batch 33/64 loss: 0.18740922212600708
Batch 34/64 loss: 0.19618141651153564
Batch 35/64 loss: 0.20411986112594604
Batch 36/64 loss: 0.1884203553199768
Batch 37/64 loss: 0.19880497455596924
Batch 38/64 loss: 0.19473892450332642
Batch 39/64 loss: 0.19539427757263184
Batch 40/64 loss: 0.21179401874542236
Batch 41/64 loss: 0.18278586864471436
Batch 42/64 loss: 0.19411951303482056
Batch 43/64 loss: 0.19946825504302979
Batch 44/64 loss: 0.20099693536758423
Batch 45/64 loss: 0.21136724948883057
Batch 46/64 loss: 0.1922990083694458
Batch 47/64 loss: 0.18875235319137573
Batch 48/64 loss: 0.200494647026062
Batch 49/64 loss: 0.19005495309829712
Batch 50/64 loss: 0.20556586980819702
Batch 51/64 loss: 0.19200515747070312
Batch 52/64 loss: 0.20596414804458618
Batch 53/64 loss: 0.2043170928955078
Batch 54/64 loss: 0.19889169931411743
Batch 55/64 loss: 0.19208502769470215
Batch 56/64 loss: 0.19560956954956055
Batch 57/64 loss: 0.20308613777160645
Batch 58/64 loss: 0.19820648431777954
Batch 59/64 loss: 0.19753295183181763
Batch 60/64 loss: 0.19203591346740723
Batch 61/64 loss: 0.1972019076347351
Batch 62/64 loss: 0.1930912733078003
Batch 63/64 loss: 0.19884830713272095
Batch 64/64 loss: 0.1890852451324463
Epoch 477  Train loss: 0.1961668145422842  Val loss: 0.2701260941135105
Epoch 478
-------------------------------
Batch 1/64 loss: 0.19763600826263428
Batch 2/64 loss: 0.19640827178955078
Batch 3/64 loss: 0.1797540783882141
Batch 4/64 loss: 0.19727683067321777
Batch 5/64 loss: 0.1943913698196411
Batch 6/64 loss: 0.20531857013702393
Batch 7/64 loss: 0.19688105583190918
Batch 8/64 loss: 0.19060158729553223
Batch 9/64 loss: 0.19414979219436646
Batch 10/64 loss: 0.19056475162506104
Batch 11/64 loss: 0.18612051010131836
Batch 12/64 loss: 0.1851484775543213
Batch 13/64 loss: 0.19908511638641357
Batch 14/64 loss: 0.19747191667556763
Batch 15/64 loss: 0.18945038318634033
Batch 16/64 loss: 0.1931239366531372
Batch 17/64 loss: 0.19270986318588257
Batch 18/64 loss: 0.20006203651428223
Batch 19/64 loss: 0.1893177032470703
Batch 20/64 loss: 0.19447380304336548
Batch 21/64 loss: 0.19206106662750244
Batch 22/64 loss: 0.196597158908844
Batch 23/64 loss: 0.20067143440246582
Batch 24/64 loss: 0.1887339949607849
Batch 25/64 loss: 0.18766242265701294
Batch 26/64 loss: 0.1974341869354248
Batch 27/64 loss: 0.1899416446685791
Batch 28/64 loss: 0.19548356533050537
Batch 29/64 loss: 0.19484245777130127
Batch 30/64 loss: 0.1961432695388794
Batch 31/64 loss: 0.20149177312850952
Batch 32/64 loss: 0.18784266710281372
Batch 33/64 loss: 0.1993933916091919
Batch 34/64 loss: 0.19078755378723145
Batch 35/64 loss: 0.20314985513687134
Batch 36/64 loss: 0.21097427606582642
Batch 37/64 loss: 0.2030758261680603
Batch 38/64 loss: 0.1939350962638855
Batch 39/64 loss: 0.19266152381896973
Batch 40/64 loss: 0.1952444314956665
Batch 41/64 loss: 0.2157527208328247
Batch 42/64 loss: 0.20048826932907104
Batch 43/64 loss: 0.1921873688697815
Batch 44/64 loss: 0.19217979907989502
Batch 45/64 loss: 0.1915711760520935
Batch 46/64 loss: 0.19770324230194092
Batch 47/64 loss: 0.20303022861480713
Batch 48/64 loss: 0.20655733346939087
Batch 49/64 loss: 0.1939626932144165
Batch 50/64 loss: 0.18854433298110962
Batch 51/64 loss: 0.19593042135238647
Batch 52/64 loss: 0.19190925359725952
Batch 53/64 loss: 0.2028043270111084
Batch 54/64 loss: 0.1982938051223755
Batch 55/64 loss: 0.19996333122253418
Batch 56/64 loss: 0.18633276224136353
Batch 57/64 loss: 0.1913137435913086
Batch 58/64 loss: 0.1912757158279419
Batch 59/64 loss: 0.20658040046691895
Batch 60/64 loss: 0.1934158205986023
Batch 61/64 loss: 0.20902109146118164
Batch 62/64 loss: 0.19865870475769043
Batch 63/64 loss: 0.20129156112670898
Batch 64/64 loss: 0.19347494840621948
Epoch 478  Train loss: 0.1957952623273812  Val loss: 0.271126131011858
Epoch 479
-------------------------------
Batch 1/64 loss: 0.19222640991210938
Batch 2/64 loss: 0.20459258556365967
Batch 3/64 loss: 0.19696664810180664
Batch 4/64 loss: 0.19562816619873047
Batch 5/64 loss: 0.19500583410263062
Batch 6/64 loss: 0.20367860794067383
Batch 7/64 loss: 0.203102707862854
Batch 8/64 loss: 0.19474077224731445
Batch 9/64 loss: 0.19382506608963013
Batch 10/64 loss: 0.2213631272315979
Batch 11/64 loss: 0.19917672872543335
Batch 12/64 loss: 0.20450329780578613
Batch 13/64 loss: 0.1996508240699768
Batch 14/64 loss: 0.19206511974334717
Batch 15/64 loss: 0.19488900899887085
Batch 16/64 loss: 0.1916242241859436
Batch 17/64 loss: 0.1981225609779358
Batch 18/64 loss: 0.19308042526245117
Batch 19/64 loss: 0.19914358854293823
Batch 20/64 loss: 0.19451433420181274
Batch 21/64 loss: 0.1943298578262329
Batch 22/64 loss: 0.1905902624130249
Batch 23/64 loss: 0.19090557098388672
Batch 24/64 loss: 0.19022142887115479
Batch 25/64 loss: 0.1966192126274109
Batch 26/64 loss: 0.18505781888961792
Batch 27/64 loss: 0.1912384033203125
Batch 28/64 loss: 0.19523602724075317
Batch 29/64 loss: 0.19171512126922607
Batch 30/64 loss: 0.19460833072662354
Batch 31/64 loss: 0.19849729537963867
Batch 32/64 loss: 0.19819259643554688
Batch 33/64 loss: 0.19925951957702637
Batch 34/64 loss: 0.1932927370071411
Batch 35/64 loss: 0.1938733458518982
Batch 36/64 loss: 0.19136273860931396
Batch 37/64 loss: 0.20836448669433594
Batch 38/64 loss: 0.19478535652160645
Batch 39/64 loss: 0.1869686245918274
Batch 40/64 loss: 0.18767249584197998
Batch 41/64 loss: 0.198727548122406
Batch 42/64 loss: 0.192099928855896
Batch 43/64 loss: 0.19953566789627075
Batch 44/64 loss: 0.1933349370956421
Batch 45/64 loss: 0.19359970092773438
Batch 46/64 loss: 0.19910168647766113
Batch 47/64 loss: 0.20041990280151367
Batch 48/64 loss: 0.203513503074646
Batch 49/64 loss: 0.1964816451072693
Batch 50/64 loss: 0.19584870338439941
Batch 51/64 loss: 0.19377785921096802
Batch 52/64 loss: 0.19270002841949463
Batch 53/64 loss: 0.19489896297454834
Batch 54/64 loss: 0.20379608869552612
Batch 55/64 loss: 0.1937330961227417
Batch 56/64 loss: 0.19406795501708984
Batch 57/64 loss: 0.19110780954360962
Batch 58/64 loss: 0.19043505191802979
Batch 59/64 loss: 0.1989852786064148
Batch 60/64 loss: 0.19267070293426514
Batch 61/64 loss: 0.19811981916427612
Batch 62/64 loss: 0.20139086246490479
Batch 63/64 loss: 0.20380622148513794
Batch 64/64 loss: 0.20609116554260254
Epoch 479  Train loss: 0.1963515702415915  Val loss: 0.2692167474232179
Epoch 480
-------------------------------
Batch 1/64 loss: 0.20033663511276245
Batch 2/64 loss: 0.1955801248550415
Batch 3/64 loss: 0.18762433528900146
Batch 4/64 loss: 0.2016608715057373
Batch 5/64 loss: 0.19663172960281372
Batch 6/64 loss: 0.18712151050567627
Batch 7/64 loss: 0.19963252544403076
Batch 8/64 loss: 0.18825018405914307
Batch 9/64 loss: 0.18477654457092285
Batch 10/64 loss: 0.1852448582649231
Batch 11/64 loss: 0.19065535068511963
Batch 12/64 loss: 0.19443845748901367
Batch 13/64 loss: 0.19667208194732666
Batch 14/64 loss: 0.19008153676986694
Batch 15/64 loss: 0.19002431631088257
Batch 16/64 loss: 0.19541573524475098
Batch 17/64 loss: 0.18784213066101074
Batch 18/64 loss: 0.19424140453338623
Batch 19/64 loss: 0.1980276107788086
Batch 20/64 loss: 0.20062744617462158
Batch 21/64 loss: 0.19526392221450806
Batch 22/64 loss: 0.19172197580337524
Batch 23/64 loss: 0.20340144634246826
Batch 24/64 loss: 0.18702983856201172
Batch 25/64 loss: 0.2074805498123169
Batch 26/64 loss: 0.18921691179275513
Batch 27/64 loss: 0.2048075795173645
Batch 28/64 loss: 0.194655179977417
Batch 29/64 loss: 0.18730270862579346
Batch 30/64 loss: 0.1914842128753662
Batch 31/64 loss: 0.18690848350524902
Batch 32/64 loss: 0.19980084896087646
Batch 33/64 loss: 0.18622130155563354
Batch 34/64 loss: 0.19181883335113525
Batch 35/64 loss: 0.1932697296142578
Batch 36/64 loss: 0.1987975835800171
Batch 37/64 loss: 0.19832241535186768
Batch 38/64 loss: 0.20474773645401
Batch 39/64 loss: 0.18845397233963013
Batch 40/64 loss: 0.19976913928985596
Batch 41/64 loss: 0.2168123722076416
Batch 42/64 loss: 0.20677530765533447
Batch 43/64 loss: 0.19589149951934814
Batch 44/64 loss: 0.1996409296989441
Batch 45/64 loss: 0.18897897005081177
Batch 46/64 loss: 0.1868312954902649
Batch 47/64 loss: 0.20390868186950684
Batch 48/64 loss: 0.20591211318969727
Batch 49/64 loss: 0.21012014150619507
Batch 50/64 loss: 0.200292706489563
Batch 51/64 loss: 0.193243145942688
Batch 52/64 loss: 0.20027494430541992
Batch 53/64 loss: 0.20162075757980347
Batch 54/64 loss: 0.20199954509735107
Batch 55/64 loss: 0.1930803656578064
Batch 56/64 loss: 0.19234585762023926
Batch 57/64 loss: 0.19549423456192017
Batch 58/64 loss: 0.19562631845474243
Batch 59/64 loss: 0.19945216178894043
Batch 60/64 loss: 0.19440972805023193
Batch 61/64 loss: 0.19238734245300293
Batch 62/64 loss: 0.19255435466766357
Batch 63/64 loss: 0.20504719018936157
Batch 64/64 loss: 0.18337726593017578
Epoch 480  Train loss: 0.19569557133842916  Val loss: 0.2699770480906431
Epoch 481
-------------------------------
Batch 1/64 loss: 0.19666194915771484
Batch 2/64 loss: 0.19155681133270264
Batch 3/64 loss: 0.19823437929153442
Batch 4/64 loss: 0.19816094636917114
Batch 5/64 loss: 0.19176971912384033
Batch 6/64 loss: 0.1975768804550171
Batch 7/64 loss: 0.187910258769989
Batch 8/64 loss: 0.192521333694458
Batch 9/64 loss: 0.18515050411224365
Batch 10/64 loss: 0.1924700140953064
Batch 11/64 loss: 0.18606358766555786
Batch 12/64 loss: 0.20189112424850464
Batch 13/64 loss: 0.1866050362586975
Batch 14/64 loss: 0.1891036033630371
Batch 15/64 loss: 0.19574683904647827
Batch 16/64 loss: 0.18941718339920044
Batch 17/64 loss: 0.1855844259262085
Batch 18/64 loss: 0.1889140009880066
Batch 19/64 loss: 0.18947887420654297
Batch 20/64 loss: 0.19314920902252197
Batch 21/64 loss: 0.20563513040542603
Batch 22/64 loss: 0.1990358829498291
Batch 23/64 loss: 0.19057190418243408
Batch 24/64 loss: 0.1923128366470337
Batch 25/64 loss: 0.19359660148620605
Batch 26/64 loss: 0.1947728395462036
Batch 27/64 loss: 0.18703484535217285
Batch 28/64 loss: 0.18506604433059692
Batch 29/64 loss: 0.19531255960464478
Batch 30/64 loss: 0.198974609375
Batch 31/64 loss: 0.20243823528289795
Batch 32/64 loss: 0.20427167415618896
Batch 33/64 loss: 0.2061213254928589
Batch 34/64 loss: 0.19669806957244873
Batch 35/64 loss: 0.19866549968719482
Batch 36/64 loss: 0.19770216941833496
Batch 37/64 loss: 0.18675541877746582
Batch 38/64 loss: 0.199532151222229
Batch 39/64 loss: 0.19479089975357056
Batch 40/64 loss: 0.1932855248451233
Batch 41/64 loss: 0.18794316053390503
Batch 42/64 loss: 0.18722277879714966
Batch 43/64 loss: 0.19144004583358765
Batch 44/64 loss: 0.1869823932647705
Batch 45/64 loss: 0.20781469345092773
Batch 46/64 loss: 0.20624881982803345
Batch 47/64 loss: 0.19930773973464966
Batch 48/64 loss: 0.19475054740905762
Batch 49/64 loss: 0.18832862377166748
Batch 50/64 loss: 0.2017354965209961
Batch 51/64 loss: 0.1911027431488037
Batch 52/64 loss: 0.19734209775924683
Batch 53/64 loss: 0.1950710415840149
Batch 54/64 loss: 0.19462990760803223
Batch 55/64 loss: 0.1966477632522583
Batch 56/64 loss: 0.205100417137146
Batch 57/64 loss: 0.19596326351165771
Batch 58/64 loss: 0.19587016105651855
Batch 59/64 loss: 0.19315379858016968
Batch 60/64 loss: 0.1942673921585083
Batch 61/64 loss: 0.19367897510528564
Batch 62/64 loss: 0.20156031847000122
Batch 63/64 loss: 0.19532769918441772
Batch 64/64 loss: 0.20747393369674683
Epoch 481  Train loss: 0.19478645067588957  Val loss: 0.26996227617525975
Epoch 482
-------------------------------
Batch 1/64 loss: 0.19850444793701172
Batch 2/64 loss: 0.18782895803451538
Batch 3/64 loss: 0.20489519834518433
Batch 4/64 loss: 0.1891632080078125
Batch 5/64 loss: 0.19855427742004395
Batch 6/64 loss: 0.20398902893066406
Batch 7/64 loss: 0.19387751817703247
Batch 8/64 loss: 0.1937631368637085
Batch 9/64 loss: 0.20593422651290894
Batch 10/64 loss: 0.18711239099502563
Batch 11/64 loss: 0.19116806983947754
Batch 12/64 loss: 0.19070082902908325
Batch 13/64 loss: 0.19931447505950928
Batch 14/64 loss: 0.19716709852218628
Batch 15/64 loss: 0.20172131061553955
Batch 16/64 loss: 0.1920751929283142
Batch 17/64 loss: 0.19767749309539795
Batch 18/64 loss: 0.1899491548538208
Batch 19/64 loss: 0.18862181901931763
Batch 20/64 loss: 0.19410234689712524
Batch 21/64 loss: 0.19941765069961548
Batch 22/64 loss: 0.18938082456588745
Batch 23/64 loss: 0.19034433364868164
Batch 24/64 loss: 0.2000364065170288
Batch 25/64 loss: 0.18775689601898193
Batch 26/64 loss: 0.20189112424850464
Batch 27/64 loss: 0.19152086973190308
Batch 28/64 loss: 0.19425439834594727
Batch 29/64 loss: 0.19054800271987915
Batch 30/64 loss: 0.20052003860473633
Batch 31/64 loss: 0.18873560428619385
Batch 32/64 loss: 0.19533556699752808
Batch 33/64 loss: 0.1877843141555786
Batch 34/64 loss: 0.20024651288986206
Batch 35/64 loss: 0.20420032739639282
Batch 36/64 loss: 0.1965814232826233
Batch 37/64 loss: 0.19167309999465942
Batch 38/64 loss: 0.19219475984573364
Batch 39/64 loss: 0.19019395112991333
Batch 40/64 loss: 0.20335745811462402
Batch 41/64 loss: 0.19261431694030762
Batch 42/64 loss: 0.1847386360168457
Batch 43/64 loss: 0.20423686504364014
Batch 44/64 loss: 0.20391231775283813
Batch 45/64 loss: 0.19375455379486084
Batch 46/64 loss: 0.19110071659088135
Batch 47/64 loss: 0.19566547870635986
Batch 48/64 loss: 0.20579111576080322
Batch 49/64 loss: 0.20541775226593018
Batch 50/64 loss: 0.18724721670150757
Batch 51/64 loss: 0.1896304488182068
Batch 52/64 loss: 0.18737375736236572
Batch 53/64 loss: 0.19832247495651245
Batch 54/64 loss: 0.19383329153060913
Batch 55/64 loss: 0.18832647800445557
Batch 56/64 loss: 0.19727754592895508
Batch 57/64 loss: 0.21167641878128052
Batch 58/64 loss: 0.19522053003311157
Batch 59/64 loss: 0.19692254066467285
Batch 60/64 loss: 0.1968085765838623
Batch 61/64 loss: 0.1943076252937317
Batch 62/64 loss: 0.18895697593688965
Batch 63/64 loss: 0.2094150185585022
Batch 64/64 loss: 0.207891047000885
Epoch 482  Train loss: 0.19561666951459997  Val loss: 0.27031419797451633
Epoch 483
-------------------------------
Batch 1/64 loss: 0.1946316361427307
Batch 2/64 loss: 0.18620753288269043
Batch 3/64 loss: 0.20087730884552002
Batch 4/64 loss: 0.18690472841262817
Batch 5/64 loss: 0.18546611070632935
Batch 6/64 loss: 0.19013267755508423
Batch 7/64 loss: 0.18986403942108154
Batch 8/64 loss: 0.19456130266189575
Batch 9/64 loss: 0.1929665207862854
Batch 10/64 loss: 0.19487619400024414
Batch 11/64 loss: 0.1878332495689392
Batch 12/64 loss: 0.193558931350708
Batch 13/64 loss: 0.1834702491760254
Batch 14/64 loss: 0.19855880737304688
Batch 15/64 loss: 0.20383328199386597
Batch 16/64 loss: 0.20472931861877441
Batch 17/64 loss: 0.1909031867980957
Batch 18/64 loss: 0.19226282835006714
Batch 19/64 loss: 0.19784653186798096
Batch 20/64 loss: 0.1989133358001709
Batch 21/64 loss: 0.19307869672775269
Batch 22/64 loss: 0.19130778312683105
Batch 23/64 loss: 0.1983860731124878
Batch 24/64 loss: 0.19900083541870117
Batch 25/64 loss: 0.1992194652557373
Batch 26/64 loss: 0.1947321891784668
Batch 27/64 loss: 0.2023029327392578
Batch 28/64 loss: 0.18736445903778076
Batch 29/64 loss: 0.20099526643753052
Batch 30/64 loss: 0.19157660007476807
Batch 31/64 loss: 0.19261515140533447
Batch 32/64 loss: 0.197404682636261
Batch 33/64 loss: 0.19296181201934814
Batch 34/64 loss: 0.19385486841201782
Batch 35/64 loss: 0.20132756233215332
Batch 36/64 loss: 0.18842840194702148
Batch 37/64 loss: 0.19948554039001465
Batch 38/64 loss: 0.19039905071258545
Batch 39/64 loss: 0.19291406869888306
Batch 40/64 loss: 0.196094810962677
Batch 41/64 loss: 0.20063865184783936
Batch 42/64 loss: 0.20201003551483154
Batch 43/64 loss: 0.19900941848754883
Batch 44/64 loss: 0.18196803331375122
Batch 45/64 loss: 0.2002880573272705
Batch 46/64 loss: 0.19838947057724
Batch 47/64 loss: 0.1901932954788208
Batch 48/64 loss: 0.1949024796485901
Batch 49/64 loss: 0.1855641007423401
Batch 50/64 loss: 0.20301198959350586
Batch 51/64 loss: 0.1891213059425354
Batch 52/64 loss: 0.19067442417144775
Batch 53/64 loss: 0.20048093795776367
Batch 54/64 loss: 0.19635391235351562
Batch 55/64 loss: 0.1942451000213623
Batch 56/64 loss: 0.20265954732894897
Batch 57/64 loss: 0.19272381067276
Batch 58/64 loss: 0.20963799953460693
Batch 59/64 loss: 0.1931803822517395
Batch 60/64 loss: 0.20431816577911377
Batch 61/64 loss: 0.19743084907531738
Batch 62/64 loss: 0.18791884183883667
Batch 63/64 loss: 0.19352740049362183
Batch 64/64 loss: 0.19092023372650146
Epoch 483  Train loss: 0.19487508091272093  Val loss: 0.2706794607680278
Epoch 484
-------------------------------
Batch 1/64 loss: 0.20806509256362915
Batch 2/64 loss: 0.18903756141662598
Batch 3/64 loss: 0.1877116560935974
Batch 4/64 loss: 0.1960282325744629
Batch 5/64 loss: 0.18662619590759277
Batch 6/64 loss: 0.1903921365737915
Batch 7/64 loss: 0.19694668054580688
Batch 8/64 loss: 0.19215744733810425
Batch 9/64 loss: 0.1845780611038208
Batch 10/64 loss: 0.1896325945854187
Batch 11/64 loss: 0.197981059551239
Batch 12/64 loss: 0.19907617568969727
Batch 13/64 loss: 0.18461394309997559
Batch 14/64 loss: 0.1856124997138977
Batch 15/64 loss: 0.1958690881729126
Batch 16/64 loss: 0.20346546173095703
Batch 17/64 loss: 0.20164263248443604
Batch 18/64 loss: 0.19365906715393066
Batch 19/64 loss: 0.18396133184432983
Batch 20/64 loss: 0.20858126878738403
Batch 21/64 loss: 0.18598181009292603
Batch 22/64 loss: 0.19450092315673828
Batch 23/64 loss: 0.19808006286621094
Batch 24/64 loss: 0.2019559144973755
Batch 25/64 loss: 0.19600170850753784
Batch 26/64 loss: 0.1966569423675537
Batch 27/64 loss: 0.20270538330078125
Batch 28/64 loss: 0.19116657972335815
Batch 29/64 loss: 0.19813305139541626
Batch 30/64 loss: 0.19086378812789917
Batch 31/64 loss: 0.19051635265350342
Batch 32/64 loss: 0.20816749334335327
Batch 33/64 loss: 0.18357616662979126
Batch 34/64 loss: 0.20089322328567505
Batch 35/64 loss: 0.19215399026870728
Batch 36/64 loss: 0.18661576509475708
Batch 37/64 loss: 0.19500946998596191
Batch 38/64 loss: 0.19310808181762695
Batch 39/64 loss: 0.19266831874847412
Batch 40/64 loss: 0.19165164232254028
Batch 41/64 loss: 0.1962825059890747
Batch 42/64 loss: 0.1882544755935669
Batch 43/64 loss: 0.20344412326812744
Batch 44/64 loss: 0.19775325059890747
Batch 45/64 loss: 0.1906588077545166
Batch 46/64 loss: 0.2067497968673706
Batch 47/64 loss: 0.19616961479187012
Batch 48/64 loss: 0.20166200399398804
Batch 49/64 loss: 0.2023242712020874
Batch 50/64 loss: 0.19530391693115234
Batch 51/64 loss: 0.19208139181137085
Batch 52/64 loss: 0.1966075301170349
Batch 53/64 loss: 0.1962307095527649
Batch 54/64 loss: 0.19801533222198486
Batch 55/64 loss: 0.20632648468017578
Batch 56/64 loss: 0.19844579696655273
Batch 57/64 loss: 0.20558315515518188
Batch 58/64 loss: 0.1925768256187439
Batch 59/64 loss: 0.19546157121658325
Batch 60/64 loss: 0.19392341375350952
Batch 61/64 loss: 0.19096606969833374
Batch 62/64 loss: 0.19574964046478271
Batch 63/64 loss: 0.21082675457000732
Batch 64/64 loss: 0.19660115242004395
Epoch 484  Train loss: 0.19552773587843952  Val loss: 0.27072557202729164
Epoch 485
-------------------------------
Batch 1/64 loss: 0.20710551738739014
Batch 2/64 loss: 0.18214881420135498
Batch 3/64 loss: 0.18476593494415283
Batch 4/64 loss: 0.20232230424880981
Batch 5/64 loss: 0.19497185945510864
Batch 6/64 loss: 0.19840145111083984
Batch 7/64 loss: 0.2020692229270935
Batch 8/64 loss: 0.2024276852607727
Batch 9/64 loss: 0.19058752059936523
Batch 10/64 loss: 0.20388555526733398
Batch 11/64 loss: 0.1991276741027832
Batch 12/64 loss: 0.192643940448761
Batch 13/64 loss: 0.1902901530265808
Batch 14/64 loss: 0.20105302333831787
Batch 15/64 loss: 0.19084322452545166
Batch 16/64 loss: 0.19549578428268433
Batch 17/64 loss: 0.1927291750907898
Batch 18/64 loss: 0.19678884744644165
Batch 19/64 loss: 0.19746476411819458
Batch 20/64 loss: 0.19347059726715088
Batch 21/64 loss: 0.19115585088729858
Batch 22/64 loss: 0.19726616144180298
Batch 23/64 loss: 0.1979312300682068
Batch 24/64 loss: 0.1947411298751831
Batch 25/64 loss: 0.19927799701690674
Batch 26/64 loss: 0.18916434049606323
Batch 27/64 loss: 0.19968700408935547
Batch 28/64 loss: 0.1912841796875
Batch 29/64 loss: 0.19536662101745605
Batch 30/64 loss: 0.2043299674987793
Batch 31/64 loss: 0.19549059867858887
Batch 32/64 loss: 0.20054638385772705
Batch 33/64 loss: 0.19493722915649414
Batch 34/64 loss: 0.18113267421722412
Batch 35/64 loss: 0.19977515935897827
Batch 36/64 loss: 0.195903480052948
Batch 37/64 loss: 0.19916534423828125
Batch 38/64 loss: 0.1911168098449707
Batch 39/64 loss: 0.1946195363998413
Batch 40/64 loss: 0.20632988214492798
Batch 41/64 loss: 0.19776707887649536
Batch 42/64 loss: 0.192499041557312
Batch 43/64 loss: 0.19999796152114868
Batch 44/64 loss: 0.1970294713973999
Batch 45/64 loss: 0.18528753519058228
Batch 46/64 loss: 0.19624298810958862
Batch 47/64 loss: 0.19429397583007812
Batch 48/64 loss: 0.19145137071609497
Batch 49/64 loss: 0.18664580583572388
Batch 50/64 loss: 0.18761307001113892
Batch 51/64 loss: 0.19073450565338135
Batch 52/64 loss: 0.19445985555648804
Batch 53/64 loss: 0.19601625204086304
Batch 54/64 loss: 0.19304370880126953
Batch 55/64 loss: 0.20249032974243164
Batch 56/64 loss: 0.20173108577728271
Batch 57/64 loss: 0.19742196798324585
Batch 58/64 loss: 0.18994158506393433
Batch 59/64 loss: 0.19320780038833618
Batch 60/64 loss: 0.19234555959701538
Batch 61/64 loss: 0.19635432958602905
Batch 62/64 loss: 0.20870494842529297
Batch 63/64 loss: 0.18700158596038818
Batch 64/64 loss: 0.2064676284790039
Epoch 485  Train loss: 0.19552858296562645  Val loss: 0.26978274596106144
Epoch 486
-------------------------------
Batch 1/64 loss: 0.1957109570503235
Batch 2/64 loss: 0.2047417163848877
Batch 3/64 loss: 0.19168853759765625
Batch 4/64 loss: 0.19219458103179932
Batch 5/64 loss: 0.19091343879699707
Batch 6/64 loss: 0.1819014549255371
Batch 7/64 loss: 0.19759124517440796
Batch 8/64 loss: 0.1995142698287964
Batch 9/64 loss: 0.18441855907440186
Batch 10/64 loss: 0.1852283477783203
Batch 11/64 loss: 0.18968844413757324
Batch 12/64 loss: 0.19486618041992188
Batch 13/64 loss: 0.1985378861427307
Batch 14/64 loss: 0.18458378314971924
Batch 15/64 loss: 0.1972910761833191
Batch 16/64 loss: 0.2020776867866516
Batch 17/64 loss: 0.1943349838256836
Batch 18/64 loss: 0.18471962213516235
Batch 19/64 loss: 0.18268483877182007
Batch 20/64 loss: 0.1966668963432312
Batch 21/64 loss: 0.19355130195617676
Batch 22/64 loss: 0.19185423851013184
Batch 23/64 loss: 0.19551855325698853
Batch 24/64 loss: 0.1965619921684265
Batch 25/64 loss: 0.18363666534423828
Batch 26/64 loss: 0.19080811738967896
Batch 27/64 loss: 0.1861857771873474
Batch 28/64 loss: 0.19574296474456787
Batch 29/64 loss: 0.19520819187164307
Batch 30/64 loss: 0.20773005485534668
Batch 31/64 loss: 0.1929926872253418
Batch 32/64 loss: 0.21116411685943604
Batch 33/64 loss: 0.1914985179901123
Batch 34/64 loss: 0.19904428720474243
Batch 35/64 loss: 0.19932329654693604
Batch 36/64 loss: 0.1938232183456421
Batch 37/64 loss: 0.19577014446258545
Batch 38/64 loss: 0.2092374563217163
Batch 39/64 loss: 0.19749665260314941
Batch 40/64 loss: 0.19763898849487305
Batch 41/64 loss: 0.19055414199829102
Batch 42/64 loss: 0.19315636157989502
Batch 43/64 loss: 0.1984386444091797
Batch 44/64 loss: 0.19706672430038452
Batch 45/64 loss: 0.19954627752304077
Batch 46/64 loss: 0.18803703784942627
Batch 47/64 loss: 0.18698441982269287
Batch 48/64 loss: 0.19330668449401855
Batch 49/64 loss: 0.19515061378479004
Batch 50/64 loss: 0.1857396960258484
Batch 51/64 loss: 0.18678748607635498
Batch 52/64 loss: 0.18753451108932495
Batch 53/64 loss: 0.19265878200531006
Batch 54/64 loss: 0.19286519289016724
Batch 55/64 loss: 0.1986742615699768
Batch 56/64 loss: 0.20385628938674927
Batch 57/64 loss: 0.19522738456726074
Batch 58/64 loss: 0.19335895776748657
Batch 59/64 loss: 0.20631879568099976
Batch 60/64 loss: 0.18909287452697754
Batch 61/64 loss: 0.19554150104522705
Batch 62/64 loss: 0.20059293508529663
Batch 63/64 loss: 0.19380754232406616
Batch 64/64 loss: 0.1972966194152832
Epoch 486  Train loss: 0.1942966479881137  Val loss: 0.2710078567573705
Epoch 487
-------------------------------
Batch 1/64 loss: 0.19773662090301514
Batch 2/64 loss: 0.19495195150375366
Batch 3/64 loss: 0.18590813875198364
Batch 4/64 loss: 0.19186723232269287
Batch 5/64 loss: 0.19370627403259277
Batch 6/64 loss: 0.18289053440093994
Batch 7/64 loss: 0.19382303953170776
Batch 8/64 loss: 0.19031071662902832
Batch 9/64 loss: 0.189811110496521
Batch 10/64 loss: 0.1802625060081482
Batch 11/64 loss: 0.19222354888916016
Batch 12/64 loss: 0.1940210461616516
Batch 13/64 loss: 0.1993158459663391
Batch 14/64 loss: 0.19380944967269897
Batch 15/64 loss: 0.18519490957260132
Batch 16/64 loss: 0.18905603885650635
Batch 17/64 loss: 0.20284128189086914
Batch 18/64 loss: 0.19520175457000732
Batch 19/64 loss: 0.19356632232666016
Batch 20/64 loss: 0.18917608261108398
Batch 21/64 loss: 0.18958568572998047
Batch 22/64 loss: 0.19447267055511475
Batch 23/64 loss: 0.19729310274124146
Batch 24/64 loss: 0.20532923936843872
Batch 25/64 loss: 0.1877148151397705
Batch 26/64 loss: 0.2154374122619629
Batch 27/64 loss: 0.20100128650665283
Batch 28/64 loss: 0.19711005687713623
Batch 29/64 loss: 0.1988765001296997
Batch 30/64 loss: 0.18690794706344604
Batch 31/64 loss: 0.2023468017578125
Batch 32/64 loss: 0.20094341039657593
Batch 33/64 loss: 0.20066916942596436
Batch 34/64 loss: 0.1997271180152893
Batch 35/64 loss: 0.19835299253463745
Batch 36/64 loss: 0.20448172092437744
Batch 37/64 loss: 0.1914592981338501
Batch 38/64 loss: 0.19366717338562012
Batch 39/64 loss: 0.19666659832000732
Batch 40/64 loss: 0.1872018575668335
Batch 41/64 loss: 0.18303346633911133
Batch 42/64 loss: 0.20052576065063477
Batch 43/64 loss: 0.20323193073272705
Batch 44/64 loss: 0.1948750615119934
Batch 45/64 loss: 0.19706034660339355
Batch 46/64 loss: 0.18867141008377075
Batch 47/64 loss: 0.19337451457977295
Batch 48/64 loss: 0.20151197910308838
Batch 49/64 loss: 0.18994450569152832
Batch 50/64 loss: 0.1941605806350708
Batch 51/64 loss: 0.18901419639587402
Batch 52/64 loss: 0.1985630989074707
Batch 53/64 loss: 0.1923811435699463
Batch 54/64 loss: 0.18917489051818848
Batch 55/64 loss: 0.2129349708557129
Batch 56/64 loss: 0.19063681364059448
Batch 57/64 loss: 0.20537543296813965
Batch 58/64 loss: 0.2039685845375061
Batch 59/64 loss: 0.19580119848251343
Batch 60/64 loss: 0.19182157516479492
Batch 61/64 loss: 0.19818222522735596
Batch 62/64 loss: 0.196455180644989
Batch 63/64 loss: 0.18696457147598267
Batch 64/64 loss: 0.19191819429397583
Epoch 487  Train loss: 0.19492582503487083  Val loss: 0.27118297295062405
Epoch 488
-------------------------------
Batch 1/64 loss: 0.20000457763671875
Batch 2/64 loss: 0.19554650783538818
Batch 3/64 loss: 0.1958199143409729
Batch 4/64 loss: 0.19311612844467163
Batch 5/64 loss: 0.1956106424331665
Batch 6/64 loss: 0.19574475288391113
Batch 7/64 loss: 0.2046530842781067
Batch 8/64 loss: 0.1897212266921997
Batch 9/64 loss: 0.1953940987586975
Batch 10/64 loss: 0.193634033203125
Batch 11/64 loss: 0.20704567432403564
Batch 12/64 loss: 0.1868872046470642
Batch 13/64 loss: 0.1933138370513916
Batch 14/64 loss: 0.19826096296310425
Batch 15/64 loss: 0.1964920163154602
Batch 16/64 loss: 0.18319040536880493
Batch 17/64 loss: 0.19198501110076904
Batch 18/64 loss: 0.19313055276870728
Batch 19/64 loss: 0.18624341487884521
Batch 20/64 loss: 0.21528702974319458
Batch 21/64 loss: 0.19791173934936523
Batch 22/64 loss: 0.1866949200630188
Batch 23/64 loss: 0.18805861473083496
Batch 24/64 loss: 0.18560528755187988
Batch 25/64 loss: 0.19765883684158325
Batch 26/64 loss: 0.20205432176589966
Batch 27/64 loss: 0.20096921920776367
Batch 28/64 loss: 0.19563406705856323
Batch 29/64 loss: 0.19718730449676514
Batch 30/64 loss: 0.18766289949417114
Batch 31/64 loss: 0.1957758665084839
Batch 32/64 loss: 0.200367271900177
Batch 33/64 loss: 0.20578038692474365
Batch 34/64 loss: 0.1952396035194397
Batch 35/64 loss: 0.19824069738388062
Batch 36/64 loss: 0.19888442754745483
Batch 37/64 loss: 0.18525099754333496
Batch 38/64 loss: 0.20661985874176025
Batch 39/64 loss: 0.19770920276641846
Batch 40/64 loss: 0.20126622915267944
Batch 41/64 loss: 0.20420563220977783
Batch 42/64 loss: 0.19810211658477783
Batch 43/64 loss: 0.2029551863670349
Batch 44/64 loss: 0.19839566946029663
Batch 45/64 loss: 0.19487696886062622
Batch 46/64 loss: 0.18929773569107056
Batch 47/64 loss: 0.19761896133422852
Batch 48/64 loss: 0.1985570192337036
Batch 49/64 loss: 0.200283944606781
Batch 50/64 loss: 0.19925200939178467
Batch 51/64 loss: 0.19764065742492676
Batch 52/64 loss: 0.19077014923095703
Batch 53/64 loss: 0.20585846900939941
Batch 54/64 loss: 0.19243067502975464
Batch 55/64 loss: 0.1901455521583557
Batch 56/64 loss: 0.18671512603759766
Batch 57/64 loss: 0.20018965005874634
Batch 58/64 loss: 0.18871992826461792
Batch 59/64 loss: 0.19169306755065918
Batch 60/64 loss: 0.19996577501296997
Batch 61/64 loss: 0.19640618562698364
Batch 62/64 loss: 0.1834762692451477
Batch 63/64 loss: 0.20509761571884155
Batch 64/64 loss: 0.1944562792778015
Epoch 488  Train loss: 0.1959866572828854  Val loss: 0.271952007234711
Epoch 489
-------------------------------
Batch 1/64 loss: 0.19916439056396484
Batch 2/64 loss: 0.18747574090957642
Batch 3/64 loss: 0.19344854354858398
Batch 4/64 loss: 0.19077050685882568
Batch 5/64 loss: 0.1882188320159912
Batch 6/64 loss: 0.19403135776519775
Batch 7/64 loss: 0.19012391567230225
Batch 8/64 loss: 0.20775914192199707
Batch 9/64 loss: 0.20004069805145264
Batch 10/64 loss: 0.20181965827941895
Batch 11/64 loss: 0.1899893879890442
Batch 12/64 loss: 0.18841934204101562
Batch 13/64 loss: 0.1961381435394287
Batch 14/64 loss: 0.20312941074371338
Batch 15/64 loss: 0.18958812952041626
Batch 16/64 loss: 0.18469351530075073
Batch 17/64 loss: 0.20804286003112793
Batch 18/64 loss: 0.19022607803344727
Batch 19/64 loss: 0.1967991590499878
Batch 20/64 loss: 0.1891416311264038
Batch 21/64 loss: 0.18847662210464478
Batch 22/64 loss: 0.2120734453201294
Batch 23/64 loss: 0.194277822971344
Batch 24/64 loss: 0.19704753160476685
Batch 25/64 loss: 0.19539988040924072
Batch 26/64 loss: 0.19218474626541138
Batch 27/64 loss: 0.2032446265220642
Batch 28/64 loss: 0.1938258409500122
Batch 29/64 loss: 0.18607670068740845
Batch 30/64 loss: 0.19149738550186157
Batch 31/64 loss: 0.1936638355255127
Batch 32/64 loss: 0.18711644411087036
Batch 33/64 loss: 0.19538789987564087
Batch 34/64 loss: 0.19583183526992798
Batch 35/64 loss: 0.1855837106704712
Batch 36/64 loss: 0.1962745189666748
Batch 37/64 loss: 0.19329065084457397
Batch 38/64 loss: 0.19333434104919434
Batch 39/64 loss: 0.20502126216888428
Batch 40/64 loss: 0.19306093454360962
Batch 41/64 loss: 0.19027221202850342
Batch 42/64 loss: 0.19472014904022217
Batch 43/64 loss: 0.18870234489440918
Batch 44/64 loss: 0.1910327672958374
Batch 45/64 loss: 0.18610310554504395
Batch 46/64 loss: 0.20256978273391724
Batch 47/64 loss: 0.19617736339569092
Batch 48/64 loss: 0.20061975717544556
Batch 49/64 loss: 0.20373648405075073
Batch 50/64 loss: 0.19354665279388428
Batch 51/64 loss: 0.18479126691818237
Batch 52/64 loss: 0.19233715534210205
Batch 53/64 loss: 0.19007426500320435
Batch 54/64 loss: 0.20357120037078857
Batch 55/64 loss: 0.1922125220298767
Batch 56/64 loss: 0.18859106302261353
Batch 57/64 loss: 0.19154691696166992
Batch 58/64 loss: 0.1904839277267456
Batch 59/64 loss: 0.20148539543151855
Batch 60/64 loss: 0.20305591821670532
Batch 61/64 loss: 0.19194722175598145
Batch 62/64 loss: 0.19569969177246094
Batch 63/64 loss: 0.19409257173538208
Batch 64/64 loss: 0.19941920042037964
Epoch 489  Train loss: 0.19448822923735076  Val loss: 0.269778798945581
Epoch 490
-------------------------------
Batch 1/64 loss: 0.18738436698913574
Batch 2/64 loss: 0.18946897983551025
Batch 3/64 loss: 0.1865672469139099
Batch 4/64 loss: 0.19396787881851196
Batch 5/64 loss: 0.18959856033325195
Batch 6/64 loss: 0.19390839338302612
Batch 7/64 loss: 0.19015389680862427
Batch 8/64 loss: 0.1893814206123352
Batch 9/64 loss: 0.19623112678527832
Batch 10/64 loss: 0.1936388611793518
Batch 11/64 loss: 0.19578051567077637
Batch 12/64 loss: 0.19478130340576172
Batch 13/64 loss: 0.19363832473754883
Batch 14/64 loss: 0.19616079330444336
Batch 15/64 loss: 0.2035500407218933
Batch 16/64 loss: 0.19525736570358276
Batch 17/64 loss: 0.19155919551849365
Batch 18/64 loss: 0.1859913468360901
Batch 19/64 loss: 0.2120201587677002
Batch 20/64 loss: 0.20540201663970947
Batch 21/64 loss: 0.19931161403656006
Batch 22/64 loss: 0.1898096799850464
Batch 23/64 loss: 0.1992400884628296
Batch 24/64 loss: 0.20265960693359375
Batch 25/64 loss: 0.20456451177597046
Batch 26/64 loss: 0.20464283227920532
Batch 27/64 loss: 0.18351590633392334
Batch 28/64 loss: 0.19358336925506592
Batch 29/64 loss: 0.19758296012878418
Batch 30/64 loss: 0.19421792030334473
Batch 31/64 loss: 0.20201575756072998
Batch 32/64 loss: 0.1926289200782776
Batch 33/64 loss: 0.19437909126281738
Batch 34/64 loss: 0.19800204038619995
Batch 35/64 loss: 0.20055335760116577
Batch 36/64 loss: 0.19555306434631348
Batch 37/64 loss: 0.18695521354675293
Batch 38/64 loss: 0.19077444076538086
Batch 39/64 loss: 0.19334197044372559
Batch 40/64 loss: 0.1939030885696411
Batch 41/64 loss: 0.19588446617126465
Batch 42/64 loss: 0.19480031728744507
Batch 43/64 loss: 0.19160842895507812
Batch 44/64 loss: 0.19408559799194336
Batch 45/64 loss: 0.1888638734817505
Batch 46/64 loss: 0.2008911371231079
Batch 47/64 loss: 0.18212342262268066
Batch 48/64 loss: 0.18907731771469116
Batch 49/64 loss: 0.18730872869491577
Batch 50/64 loss: 0.18908905982971191
Batch 51/64 loss: 0.19099175930023193
Batch 52/64 loss: 0.1922740340232849
Batch 53/64 loss: 0.1928476095199585
Batch 54/64 loss: 0.18683743476867676
Batch 55/64 loss: 0.1940617561340332
Batch 56/64 loss: 0.19712358713150024
Batch 57/64 loss: 0.1863347887992859
Batch 58/64 loss: 0.1938183307647705
Batch 59/64 loss: 0.19268399477005005
Batch 60/64 loss: 0.1901228427886963
Batch 61/64 loss: 0.19537806510925293
Batch 62/64 loss: 0.19484245777130127
Batch 63/64 loss: 0.18748515844345093
Batch 64/64 loss: 0.20354413986206055
Epoch 490  Train loss: 0.19392736472335517  Val loss: 0.27100699156829994
Epoch 491
-------------------------------
Batch 1/64 loss: 0.19299983978271484
Batch 2/64 loss: 0.19577175378799438
Batch 3/64 loss: 0.18996191024780273
Batch 4/64 loss: 0.20114964246749878
Batch 5/64 loss: 0.18782669305801392
Batch 6/64 loss: 0.19223880767822266
Batch 7/64 loss: 0.19845139980316162
Batch 8/64 loss: 0.19271069765090942
Batch 9/64 loss: 0.18975830078125
Batch 10/64 loss: 0.19938325881958008
Batch 11/64 loss: 0.20352280139923096
Batch 12/64 loss: 0.20572853088378906
Batch 13/64 loss: 0.20007359981536865
Batch 14/64 loss: 0.1993030309677124
Batch 15/64 loss: 0.18490862846374512
Batch 16/64 loss: 0.19970130920410156
Batch 17/64 loss: 0.19376415014266968
Batch 18/64 loss: 0.19779044389724731
Batch 19/64 loss: 0.18907225131988525
Batch 20/64 loss: 0.20174700021743774
Batch 21/64 loss: 0.19630151987075806
Batch 22/64 loss: 0.19663381576538086
Batch 23/64 loss: 0.1915619969367981
Batch 24/64 loss: 0.1946014165878296
Batch 25/64 loss: 0.190293550491333
Batch 26/64 loss: 0.18777835369110107
Batch 27/64 loss: 0.21050095558166504
Batch 28/64 loss: 0.19628357887268066
Batch 29/64 loss: 0.18380367755889893
Batch 30/64 loss: 0.18650203943252563
Batch 31/64 loss: 0.1875094771385193
Batch 32/64 loss: 0.202337384223938
Batch 33/64 loss: 0.19016814231872559
Batch 34/64 loss: 0.18624091148376465
Batch 35/64 loss: 0.19727134704589844
Batch 36/64 loss: 0.1881500482559204
Batch 37/64 loss: 0.19381791353225708
Batch 38/64 loss: 0.18795162439346313
Batch 39/64 loss: 0.20058178901672363
Batch 40/64 loss: 0.1959511637687683
Batch 41/64 loss: 0.1963403820991516
Batch 42/64 loss: 0.18793612718582153
Batch 43/64 loss: 0.20166033506393433
Batch 44/64 loss: 0.19502991437911987
Batch 45/64 loss: 0.19989091157913208
Batch 46/64 loss: 0.18769431114196777
Batch 47/64 loss: 0.18980872631072998
Batch 48/64 loss: 0.18983137607574463
Batch 49/64 loss: 0.20460134744644165
Batch 50/64 loss: 0.18987315893173218
Batch 51/64 loss: 0.18624025583267212
Batch 52/64 loss: 0.18437016010284424
Batch 53/64 loss: 0.18427956104278564
Batch 54/64 loss: 0.1990424394607544
Batch 55/64 loss: 0.18805599212646484
Batch 56/64 loss: 0.19555699825286865
Batch 57/64 loss: 0.18676608800888062
Batch 58/64 loss: 0.20324403047561646
Batch 59/64 loss: 0.201371431350708
Batch 60/64 loss: 0.2002285122871399
Batch 61/64 loss: 0.2043946385383606
Batch 62/64 loss: 0.19834595918655396
Batch 63/64 loss: 0.19516301155090332
Batch 64/64 loss: 0.19127529859542847
Epoch 491  Train loss: 0.19440450037226958  Val loss: 0.26986648761939347
Epoch 492
-------------------------------
Batch 1/64 loss: 0.18757152557373047
Batch 2/64 loss: 0.1910409927368164
Batch 3/64 loss: 0.1858229637145996
Batch 4/64 loss: 0.1945827603340149
Batch 5/64 loss: 0.19300448894500732
Batch 6/64 loss: 0.19981306791305542
Batch 7/64 loss: 0.20315420627593994
Batch 8/64 loss: 0.20285427570343018
Batch 9/64 loss: 0.1920880675315857
Batch 10/64 loss: 0.19399863481521606
Batch 11/64 loss: 0.2009434700012207
Batch 12/64 loss: 0.21593433618545532
Batch 13/64 loss: 0.20404064655303955
Batch 14/64 loss: 0.21091896295547485
Batch 15/64 loss: 0.18890732526779175
Batch 16/64 loss: 0.18765473365783691
Batch 17/64 loss: 0.18670731782913208
Batch 18/64 loss: 0.18867850303649902
Batch 19/64 loss: 0.20643287897109985
Batch 20/64 loss: 0.2083960771560669
Batch 21/64 loss: 0.187045156955719
Batch 22/64 loss: 0.19009774923324585
Batch 23/64 loss: 0.1920371651649475
Batch 24/64 loss: 0.19543790817260742
Batch 25/64 loss: 0.18843960762023926
Batch 26/64 loss: 0.19747745990753174
Batch 27/64 loss: 0.196302592754364
Batch 28/64 loss: 0.1933814287185669
Batch 29/64 loss: 0.19253045320510864
Batch 30/64 loss: 0.19657105207443237
Batch 31/64 loss: 0.19379031658172607
Batch 32/64 loss: 0.19227272272109985
Batch 33/64 loss: 0.19137489795684814
Batch 34/64 loss: 0.19988548755645752
Batch 35/64 loss: 0.18531525135040283
Batch 36/64 loss: 0.19094973802566528
Batch 37/64 loss: 0.18969404697418213
Batch 38/64 loss: 0.19419825077056885
Batch 39/64 loss: 0.19433695077896118
Batch 40/64 loss: 0.19934892654418945
Batch 41/64 loss: 0.19244122505187988
Batch 42/64 loss: 0.19700467586517334
Batch 43/64 loss: 0.18373245000839233
Batch 44/64 loss: 0.1998615860939026
Batch 45/64 loss: 0.18537259101867676
Batch 46/64 loss: 0.19646209478378296
Batch 47/64 loss: 0.19577181339263916
Batch 48/64 loss: 0.2103579044342041
Batch 49/64 loss: 0.1947568655014038
Batch 50/64 loss: 0.19942313432693481
Batch 51/64 loss: 0.20265865325927734
Batch 52/64 loss: 0.18610870838165283
Batch 53/64 loss: 0.1907942295074463
Batch 54/64 loss: 0.19775772094726562
Batch 55/64 loss: 0.1955167055130005
Batch 56/64 loss: 0.19667303562164307
Batch 57/64 loss: 0.19163072109222412
Batch 58/64 loss: 0.19842910766601562
Batch 59/64 loss: 0.20736634731292725
Batch 60/64 loss: 0.19627368450164795
Batch 61/64 loss: 0.2000930905342102
Batch 62/64 loss: 0.19615131616592407
Batch 63/64 loss: 0.1872793436050415
Batch 64/64 loss: 0.1986006498336792
Epoch 492  Train loss: 0.19535529239504945  Val loss: 0.2698075505056742
Epoch 493
-------------------------------
Batch 1/64 loss: 0.19378173351287842
Batch 2/64 loss: 0.1838001012802124
Batch 3/64 loss: 0.19033879041671753
Batch 4/64 loss: 0.18685781955718994
Batch 5/64 loss: 0.1937205195426941
Batch 6/64 loss: 0.19955646991729736
Batch 7/64 loss: 0.18771690130233765
Batch 8/64 loss: 0.18976199626922607
Batch 9/64 loss: 0.19657093286514282
Batch 10/64 loss: 0.18836158514022827
Batch 11/64 loss: 0.1870477795600891
Batch 12/64 loss: 0.19697672128677368
Batch 13/64 loss: 0.19148188829421997
Batch 14/64 loss: 0.20557630062103271
Batch 15/64 loss: 0.19227617979049683
Batch 16/64 loss: 0.19611483812332153
Batch 17/64 loss: 0.19335663318634033
Batch 18/64 loss: 0.18639421463012695
Batch 19/64 loss: 0.18790525197982788
Batch 20/64 loss: 0.19148904085159302
Batch 21/64 loss: 0.19232267141342163
Batch 22/64 loss: 0.19114011526107788
Batch 23/64 loss: 0.1903114914894104
Batch 24/64 loss: 0.1934492588043213
Batch 25/64 loss: 0.19803202152252197
Batch 26/64 loss: 0.196244478225708
Batch 27/64 loss: 0.18544161319732666
Batch 28/64 loss: 0.20511943101882935
Batch 29/64 loss: 0.18932652473449707
Batch 30/64 loss: 0.19632017612457275
Batch 31/64 loss: 0.18942642211914062
Batch 32/64 loss: 0.19005870819091797
Batch 33/64 loss: 0.20457154512405396
Batch 34/64 loss: 0.19550496339797974
Batch 35/64 loss: 0.19888794422149658
Batch 36/64 loss: 0.19546830654144287
Batch 37/64 loss: 0.2049006223678589
Batch 38/64 loss: 0.20087969303131104
Batch 39/64 loss: 0.2014608383178711
Batch 40/64 loss: 0.19642746448516846
Batch 41/64 loss: 0.20080184936523438
Batch 42/64 loss: 0.18787306547164917
Batch 43/64 loss: 0.19564008712768555
Batch 44/64 loss: 0.19462907314300537
Batch 45/64 loss: 0.19727587699890137
Batch 46/64 loss: 0.1996639370918274
Batch 47/64 loss: 0.1890076994895935
Batch 48/64 loss: 0.19706684350967407
Batch 49/64 loss: 0.18332988023757935
Batch 50/64 loss: 0.20015406608581543
Batch 51/64 loss: 0.1925719976425171
Batch 52/64 loss: 0.20410645008087158
Batch 53/64 loss: 0.1947590708732605
Batch 54/64 loss: 0.1965201497077942
Batch 55/64 loss: 0.19750076532363892
Batch 56/64 loss: 0.1938406229019165
Batch 57/64 loss: 0.19750982522964478
Batch 58/64 loss: 0.2041536569595337
Batch 59/64 loss: 0.18993395566940308
Batch 60/64 loss: 0.20693552494049072
Batch 61/64 loss: 0.19923514127731323
Batch 62/64 loss: 0.19201505184173584
Batch 63/64 loss: 0.19099867343902588
Batch 64/64 loss: 0.19033032655715942
Epoch 493  Train loss: 0.1945513881889044  Val loss: 0.26968442123780134
Epoch 494
-------------------------------
Batch 1/64 loss: 0.21155154705047607
Batch 2/64 loss: 0.1988866925239563
Batch 3/64 loss: 0.19213098287582397
Batch 4/64 loss: 0.194799542427063
Batch 5/64 loss: 0.18740803003311157
Batch 6/64 loss: 0.19616705179214478
Batch 7/64 loss: 0.20122146606445312
Batch 8/64 loss: 0.19226908683776855
Batch 9/64 loss: 0.1841561198234558
Batch 10/64 loss: 0.19285708665847778
Batch 11/64 loss: 0.1907382607460022
Batch 12/64 loss: 0.20159709453582764
Batch 13/64 loss: 0.19345885515213013
Batch 14/64 loss: 0.1979292631149292
Batch 15/64 loss: 0.19752204418182373
Batch 16/64 loss: 0.18994247913360596
Batch 17/64 loss: 0.19363993406295776
Batch 18/64 loss: 0.206304132938385
Batch 19/64 loss: 0.1933460831642151
Batch 20/64 loss: 0.19583487510681152
Batch 21/64 loss: 0.1868341565132141
Batch 22/64 loss: 0.1993180513381958
Batch 23/64 loss: 0.20426559448242188
Batch 24/64 loss: 0.20110493898391724
Batch 25/64 loss: 0.19968265295028687
Batch 26/64 loss: 0.2044270634651184
Batch 27/64 loss: 0.20890027284622192
Batch 28/64 loss: 0.20615100860595703
Batch 29/64 loss: 0.1980074644088745
Batch 30/64 loss: 0.19325172901153564
Batch 31/64 loss: 0.19830405712127686
Batch 32/64 loss: 0.18836915493011475
Batch 33/64 loss: 0.19515210390090942
Batch 34/64 loss: 0.19375395774841309
Batch 35/64 loss: 0.19360870122909546
Batch 36/64 loss: 0.1826232671737671
Batch 37/64 loss: 0.1866370439529419
Batch 38/64 loss: 0.1948786973953247
Batch 39/64 loss: 0.1882171630859375
Batch 40/64 loss: 0.2012590765953064
Batch 41/64 loss: 0.19804108142852783
Batch 42/64 loss: 0.18761968612670898
Batch 43/64 loss: 0.19845306873321533
Batch 44/64 loss: 0.185094952583313
Batch 45/64 loss: 0.20249301195144653
Batch 46/64 loss: 0.19902479648590088
Batch 47/64 loss: 0.20217365026474
Batch 48/64 loss: 0.1971505880355835
Batch 49/64 loss: 0.1938621997833252
Batch 50/64 loss: 0.18790817260742188
Batch 51/64 loss: 0.19294780492782593
Batch 52/64 loss: 0.19247108697891235
Batch 53/64 loss: 0.19041097164154053
Batch 54/64 loss: 0.1907973289489746
Batch 55/64 loss: 0.18559658527374268
Batch 56/64 loss: 0.20856118202209473
Batch 57/64 loss: 0.19143295288085938
Batch 58/64 loss: 0.18958193063735962
Batch 59/64 loss: 0.18699228763580322
Batch 60/64 loss: 0.20635485649108887
Batch 61/64 loss: 0.19201815128326416
Batch 62/64 loss: 0.18794721364974976
Batch 63/64 loss: 0.19214767217636108
Batch 64/64 loss: 0.1906871199607849
Epoch 494  Train loss: 0.19511534676832312  Val loss: 0.27002430248915943
Epoch 495
-------------------------------
Batch 1/64 loss: 0.20284253358840942
Batch 2/64 loss: 0.19003844261169434
Batch 3/64 loss: 0.18879365921020508
Batch 4/64 loss: 0.19966864585876465
Batch 5/64 loss: 0.183327317237854
Batch 6/64 loss: 0.18889617919921875
Batch 7/64 loss: 0.18851196765899658
Batch 8/64 loss: 0.18316799402236938
Batch 9/64 loss: 0.18293923139572144
Batch 10/64 loss: 0.18820786476135254
Batch 11/64 loss: 0.19052404165267944
Batch 12/64 loss: 0.19557321071624756
Batch 13/64 loss: 0.183732807636261
Batch 14/64 loss: 0.19395941495895386
Batch 15/64 loss: 0.19938606023788452
Batch 16/64 loss: 0.2014164924621582
Batch 17/64 loss: 0.20052450895309448
Batch 18/64 loss: 0.192976713180542
Batch 19/64 loss: 0.1878800392150879
Batch 20/64 loss: 0.19426298141479492
Batch 21/64 loss: 0.2041083574295044
Batch 22/64 loss: 0.18570423126220703
Batch 23/64 loss: 0.2015305757522583
Batch 24/64 loss: 0.19704890251159668
Batch 25/64 loss: 0.1958460807800293
Batch 26/64 loss: 0.1946263313293457
Batch 27/64 loss: 0.19701021909713745
Batch 28/64 loss: 0.2005460262298584
Batch 29/64 loss: 0.19825005531311035
Batch 30/64 loss: 0.1948615312576294
Batch 31/64 loss: 0.20643675327301025
Batch 32/64 loss: 0.1957472562789917
Batch 33/64 loss: 0.1896141767501831
Batch 34/64 loss: 0.189042329788208
Batch 35/64 loss: 0.19007015228271484
Batch 36/64 loss: 0.18199652433395386
Batch 37/64 loss: 0.1872444748878479
Batch 38/64 loss: 0.19118839502334595
Batch 39/64 loss: 0.194940447807312
Batch 40/64 loss: 0.18452149629592896
Batch 41/64 loss: 0.20465296506881714
Batch 42/64 loss: 0.18135970830917358
Batch 43/64 loss: 0.18342351913452148
Batch 44/64 loss: 0.1988908052444458
Batch 45/64 loss: 0.19600439071655273
Batch 46/64 loss: 0.1873384714126587
Batch 47/64 loss: 0.19968372583389282
Batch 48/64 loss: 0.19498366117477417
Batch 49/64 loss: 0.19409751892089844
Batch 50/64 loss: 0.19459187984466553
Batch 51/64 loss: 0.1963362693786621
Batch 52/64 loss: 0.20803946256637573
Batch 53/64 loss: 0.1954282522201538
Batch 54/64 loss: 0.19689911603927612
Batch 55/64 loss: 0.1893216371536255
Batch 56/64 loss: 0.18471777439117432
Batch 57/64 loss: 0.20414692163467407
Batch 58/64 loss: 0.1903730034828186
Batch 59/64 loss: 0.19664275646209717
Batch 60/64 loss: 0.20098716020584106
Batch 61/64 loss: 0.1919236183166504
Batch 62/64 loss: 0.19607925415039062
Batch 63/64 loss: 0.20616936683654785
Batch 64/64 loss: 0.2047024965286255
Epoch 495  Train loss: 0.19392286328708425  Val loss: 0.2703567522088277
Epoch 496
-------------------------------
Batch 1/64 loss: 0.1906004548072815
Batch 2/64 loss: 0.1913626790046692
Batch 3/64 loss: 0.19707190990447998
Batch 4/64 loss: 0.19666355848312378
Batch 5/64 loss: 0.19569116830825806
Batch 6/64 loss: 0.19597256183624268
Batch 7/64 loss: 0.18946677446365356
Batch 8/64 loss: 0.18908202648162842
Batch 9/64 loss: 0.1902148723602295
Batch 10/64 loss: 0.191353440284729
Batch 11/64 loss: 0.18769872188568115
Batch 12/64 loss: 0.20043504238128662
Batch 13/64 loss: 0.19494974613189697
Batch 14/64 loss: 0.1913825273513794
Batch 15/64 loss: 0.18728476762771606
Batch 16/64 loss: 0.2017592191696167
Batch 17/64 loss: 0.19184011220932007
Batch 18/64 loss: 0.1912752389907837
Batch 19/64 loss: 0.1899746060371399
Batch 20/64 loss: 0.1964339017868042
Batch 21/64 loss: 0.1854637861251831
Batch 22/64 loss: 0.19256186485290527
Batch 23/64 loss: 0.1860237717628479
Batch 24/64 loss: 0.19275903701782227
Batch 25/64 loss: 0.1918674111366272
Batch 26/64 loss: 0.20165711641311646
Batch 27/64 loss: 0.20167326927185059
Batch 28/64 loss: 0.195051908493042
Batch 29/64 loss: 0.18528586626052856
Batch 30/64 loss: 0.19566476345062256
Batch 31/64 loss: 0.20955681800842285
Batch 32/64 loss: 0.1908555030822754
Batch 33/64 loss: 0.20316338539123535
Batch 34/64 loss: 0.19026952981948853
Batch 35/64 loss: 0.2030867338180542
Batch 36/64 loss: 0.19456177949905396
Batch 37/64 loss: 0.19904851913452148
Batch 38/64 loss: 0.1929125189781189
Batch 39/64 loss: 0.19519823789596558
Batch 40/64 loss: 0.20352047681808472
Batch 41/64 loss: 0.19244974851608276
Batch 42/64 loss: 0.20070111751556396
Batch 43/64 loss: 0.20498764514923096
Batch 44/64 loss: 0.19731509685516357
Batch 45/64 loss: 0.19004547595977783
Batch 46/64 loss: 0.19070202112197876
Batch 47/64 loss: 0.20871847867965698
Batch 48/64 loss: 0.20297271013259888
Batch 49/64 loss: 0.18774187564849854
Batch 50/64 loss: 0.18795424699783325
Batch 51/64 loss: 0.1958184838294983
Batch 52/64 loss: 0.20365798473358154
Batch 53/64 loss: 0.20546269416809082
Batch 54/64 loss: 0.19805598258972168
Batch 55/64 loss: 0.19553112983703613
Batch 56/64 loss: 0.19732248783111572
Batch 57/64 loss: 0.19801825284957886
Batch 58/64 loss: 0.19523018598556519
Batch 59/64 loss: 0.1997816562652588
Batch 60/64 loss: 0.1945279836654663
Batch 61/64 loss: 0.18819499015808105
Batch 62/64 loss: 0.21244585514068604
Batch 63/64 loss: 0.1910630464553833
Batch 64/64 loss: 0.1860278844833374
Epoch 496  Train loss: 0.19527710886562571  Val loss: 0.2694768625026716
Epoch 497
-------------------------------
Batch 1/64 loss: 0.1873847246170044
Batch 2/64 loss: 0.19049352407455444
Batch 3/64 loss: 0.18989253044128418
Batch 4/64 loss: 0.18933439254760742
Batch 5/64 loss: 0.19873815774917603
Batch 6/64 loss: 0.191986083984375
Batch 7/64 loss: 0.20637786388397217
Batch 8/64 loss: 0.19517886638641357
Batch 9/64 loss: 0.19446831941604614
Batch 10/64 loss: 0.19412529468536377
Batch 11/64 loss: 0.18479913473129272
Batch 12/64 loss: 0.1889810562133789
Batch 13/64 loss: 0.19534099102020264
Batch 14/64 loss: 0.1866740584373474
Batch 15/64 loss: 0.1861392855644226
Batch 16/64 loss: 0.19807809591293335
Batch 17/64 loss: 0.18877959251403809
Batch 18/64 loss: 0.19349539279937744
Batch 19/64 loss: 0.19090235233306885
Batch 20/64 loss: 0.18408143520355225
Batch 21/64 loss: 0.1999359130859375
Batch 22/64 loss: 0.19112706184387207
Batch 23/64 loss: 0.1915287971496582
Batch 24/64 loss: 0.1870383620262146
Batch 25/64 loss: 0.1953800916671753
Batch 26/64 loss: 0.18346410989761353
Batch 27/64 loss: 0.19661980867385864
Batch 28/64 loss: 0.1935364007949829
Batch 29/64 loss: 0.19754821062088013
Batch 30/64 loss: 0.19898062944412231
Batch 31/64 loss: 0.20212900638580322
Batch 32/64 loss: 0.18917489051818848
Batch 33/64 loss: 0.1908394694328308
Batch 34/64 loss: 0.20059704780578613
Batch 35/64 loss: 0.1958135962486267
Batch 36/64 loss: 0.18844908475875854
Batch 37/64 loss: 0.19107824563980103
Batch 38/64 loss: 0.18185627460479736
Batch 39/64 loss: 0.1948639154434204
Batch 40/64 loss: 0.18883728981018066
Batch 41/64 loss: 0.19512593746185303
Batch 42/64 loss: 0.1982010006904602
Batch 43/64 loss: 0.20032131671905518
Batch 44/64 loss: 0.1923113465309143
Batch 45/64 loss: 0.1829770803451538
Batch 46/64 loss: 0.19444262981414795
Batch 47/64 loss: 0.19102704524993896
Batch 48/64 loss: 0.18592888116836548
Batch 49/64 loss: 0.18445533514022827
Batch 50/64 loss: 0.1887052059173584
Batch 51/64 loss: 0.20194262266159058
Batch 52/64 loss: 0.19613438844680786
Batch 53/64 loss: 0.1878604292869568
Batch 54/64 loss: 0.1992008090019226
Batch 55/64 loss: 0.19878655672073364
Batch 56/64 loss: 0.19216638803482056
Batch 57/64 loss: 0.19348174333572388
Batch 58/64 loss: 0.17947930097579956
Batch 59/64 loss: 0.21140092611312866
Batch 60/64 loss: 0.18987232446670532
Batch 61/64 loss: 0.19470477104187012
Batch 62/64 loss: 0.185560941696167
Batch 63/64 loss: 0.19774770736694336
Batch 64/64 loss: 0.19930726289749146
Epoch 497  Train loss: 0.19271159990161074  Val loss: 0.2706586259746879
Epoch 498
-------------------------------
Batch 1/64 loss: 0.18325096368789673
Batch 2/64 loss: 0.19135677814483643
Batch 3/64 loss: 0.18521833419799805
Batch 4/64 loss: 0.18767237663269043
Batch 5/64 loss: 0.18639063835144043
Batch 6/64 loss: 0.19428688287734985
Batch 7/64 loss: 0.19426435232162476
Batch 8/64 loss: 0.18824243545532227
Batch 9/64 loss: 0.19703775644302368
Batch 10/64 loss: 0.18851256370544434
Batch 11/64 loss: 0.18855607509613037
Batch 12/64 loss: 0.1823630928993225
Batch 13/64 loss: 0.18764877319335938
Batch 14/64 loss: 0.1890643835067749
Batch 15/64 loss: 0.18428373336791992
Batch 16/64 loss: 0.19974148273468018
Batch 17/64 loss: 0.2005913257598877
Batch 18/64 loss: 0.19632643461227417
Batch 19/64 loss: 0.2013629674911499
Batch 20/64 loss: 0.18673837184906006
Batch 21/64 loss: 0.1927781105041504
Batch 22/64 loss: 0.1942758560180664
Batch 23/64 loss: 0.1995624303817749
Batch 24/64 loss: 0.19041961431503296
Batch 25/64 loss: 0.19132471084594727
Batch 26/64 loss: 0.18938839435577393
Batch 27/64 loss: 0.19007235765457153
Batch 28/64 loss: 0.18826818466186523
Batch 29/64 loss: 0.19947338104248047
Batch 30/64 loss: 0.1839173436164856
Batch 31/64 loss: 0.18721544742584229
Batch 32/64 loss: 0.19161343574523926
Batch 33/64 loss: 0.18957525491714478
Batch 34/64 loss: 0.19523608684539795
Batch 35/64 loss: 0.19668549299240112
Batch 36/64 loss: 0.2054937481880188
Batch 37/64 loss: 0.19485723972320557
Batch 38/64 loss: 0.19601202011108398
Batch 39/64 loss: 0.19607585668563843
Batch 40/64 loss: 0.19110196828842163
Batch 41/64 loss: 0.19357919692993164
Batch 42/64 loss: 0.19275325536727905
Batch 43/64 loss: 0.20140957832336426
Batch 44/64 loss: 0.19691050052642822
Batch 45/64 loss: 0.18724572658538818
Batch 46/64 loss: 0.18813949823379517
Batch 47/64 loss: 0.18437904119491577
Batch 48/64 loss: 0.18861055374145508
Batch 49/64 loss: 0.1880946159362793
Batch 50/64 loss: 0.19620060920715332
Batch 51/64 loss: 0.1882781982421875
Batch 52/64 loss: 0.20278406143188477
Batch 53/64 loss: 0.19353234767913818
Batch 54/64 loss: 0.18960726261138916
Batch 55/64 loss: 0.19833511114120483
Batch 56/64 loss: 0.19571328163146973
Batch 57/64 loss: 0.18765145540237427
Batch 58/64 loss: 0.19901221990585327
Batch 59/64 loss: 0.206096351146698
Batch 60/64 loss: 0.18362897634506226
Batch 61/64 loss: 0.19730472564697266
Batch 62/64 loss: 0.1910935640335083
Batch 63/64 loss: 0.20201945304870605
Batch 64/64 loss: 0.18511343002319336
Epoch 498  Train loss: 0.19243092256433825  Val loss: 0.27192374603035524
Epoch 499
-------------------------------
Batch 1/64 loss: 0.1910557746887207
Batch 2/64 loss: 0.209588885307312
Batch 3/64 loss: 0.1895052194595337
Batch 4/64 loss: 0.19268256425857544
Batch 5/64 loss: 0.18824177980422974
Batch 6/64 loss: 0.19249266386032104
Batch 7/64 loss: 0.18963158130645752
Batch 8/64 loss: 0.19072985649108887
Batch 9/64 loss: 0.19628280401229858
Batch 10/64 loss: 0.2075120210647583
Batch 11/64 loss: 0.19089782238006592
Batch 12/64 loss: 0.1900044083595276
Batch 13/64 loss: 0.20751303434371948
Batch 14/64 loss: 0.19544416666030884
Batch 15/64 loss: 0.19931697845458984
Batch 16/64 loss: 0.1986817717552185
Batch 17/64 loss: 0.18053853511810303
Batch 18/64 loss: 0.18122339248657227
Batch 19/64 loss: 0.1851329803466797
Batch 20/64 loss: 0.19966399669647217
Batch 21/64 loss: 0.1840801239013672
Batch 22/64 loss: 0.192795991897583
Batch 23/64 loss: 0.19683796167373657
Batch 24/64 loss: 0.18635499477386475
Batch 25/64 loss: 0.18207871913909912
Batch 26/64 loss: 0.19013357162475586
Batch 27/64 loss: 0.19056475162506104
Batch 28/64 loss: 0.1880732774734497
Batch 29/64 loss: 0.19746661186218262
Batch 30/64 loss: 0.19186162948608398
Batch 31/64 loss: 0.19889026880264282
Batch 32/64 loss: 0.19061541557312012
Batch 33/64 loss: 0.19869959354400635
Batch 34/64 loss: 0.18971073627471924
Batch 35/64 loss: 0.19757455587387085
Batch 36/64 loss: 0.19188374280929565
Batch 37/64 loss: 0.20029711723327637
Batch 38/64 loss: 0.19510161876678467
Batch 39/64 loss: 0.19055473804473877
Batch 40/64 loss: 0.1917428970336914
Batch 41/64 loss: 0.19943493604660034
Batch 42/64 loss: 0.18725663423538208
Batch 43/64 loss: 0.18784403800964355
Batch 44/64 loss: 0.2024206519126892
Batch 45/64 loss: 0.19143718481063843
Batch 46/64 loss: 0.18797969818115234
Batch 47/64 loss: 0.19053035974502563
Batch 48/64 loss: 0.19943004846572876
Batch 49/64 loss: 0.18853187561035156
Batch 50/64 loss: 0.19035053253173828
Batch 51/64 loss: 0.19846510887145996
Batch 52/64 loss: 0.18774378299713135
Batch 53/64 loss: 0.18764668703079224
Batch 54/64 loss: 0.18999958038330078
Batch 55/64 loss: 0.21172213554382324
Batch 56/64 loss: 0.2012616991996765
Batch 57/64 loss: 0.1943598985671997
Batch 58/64 loss: 0.18709027767181396
Batch 59/64 loss: 0.18831568956375122
Batch 60/64 loss: 0.18732404708862305
Batch 61/64 loss: 0.20096272230148315
Batch 62/64 loss: 0.19433021545410156
Batch 63/64 loss: 0.18868595361709595
Batch 64/64 loss: 0.19916963577270508
Epoch 499  Train loss: 0.19316014963037828  Val loss: 0.2705950327345596
Epoch 500
-------------------------------
Batch 1/64 loss: 0.18707388639450073
Batch 2/64 loss: 0.18510794639587402
Batch 3/64 loss: 0.1949371099472046
Batch 4/64 loss: 0.19412106275558472
Batch 5/64 loss: 0.19203871488571167
Batch 6/64 loss: 0.18790829181671143
Batch 7/64 loss: 0.19533371925354004
Batch 8/64 loss: 0.19174593687057495
Batch 9/64 loss: 0.1941835880279541
Batch 10/64 loss: 0.19431668519973755
Batch 11/64 loss: 0.187486469745636
Batch 12/64 loss: 0.19730401039123535
Batch 13/64 loss: 0.19515657424926758
Batch 14/64 loss: 0.1957932710647583
Batch 15/64 loss: 0.1936776041984558
Batch 16/64 loss: 0.2033366560935974
Batch 17/64 loss: 0.19946569204330444
Batch 18/64 loss: 0.19243603944778442
Batch 19/64 loss: 0.19845938682556152
Batch 20/64 loss: 0.19337677955627441
Batch 21/64 loss: 0.19698452949523926
Batch 22/64 loss: 0.19862240552902222
Batch 23/64 loss: 0.19221192598342896
Batch 24/64 loss: 0.1880304217338562
Batch 25/64 loss: 0.19401651620864868
Batch 26/64 loss: 0.20312780141830444
Batch 27/64 loss: 0.19665110111236572
Batch 28/64 loss: 0.19437885284423828
Batch 29/64 loss: 0.18852853775024414
Batch 30/64 loss: 0.19363117218017578
Batch 31/64 loss: 0.1870937943458557
Batch 32/64 loss: 0.19175505638122559
Batch 33/64 loss: 0.19382357597351074
Batch 34/64 loss: 0.18228161334991455
Batch 35/64 loss: 0.18106335401535034
Batch 36/64 loss: 0.18849211931228638
Batch 37/64 loss: 0.19674694538116455
Batch 38/64 loss: 0.188839852809906
Batch 39/64 loss: 0.19508308172225952
Batch 40/64 loss: 0.19161081314086914
Batch 41/64 loss: 0.18947112560272217
Batch 42/64 loss: 0.19854474067687988
Batch 43/64 loss: 0.18914157152175903
Batch 44/64 loss: 0.19481170177459717
Batch 45/64 loss: 0.1924094557762146
Batch 46/64 loss: 0.20079189538955688
Batch 47/64 loss: 0.19433176517486572
Batch 48/64 loss: 0.20058351755142212
Batch 49/64 loss: 0.19599497318267822
Batch 50/64 loss: 0.1951720118522644
Batch 51/64 loss: 0.196136474609375
Batch 52/64 loss: 0.19232600927352905
Batch 53/64 loss: 0.1902199387550354
Batch 54/64 loss: 0.1810322403907776
Batch 55/64 loss: 0.18666040897369385
Batch 56/64 loss: 0.19596827030181885
Batch 57/64 loss: 0.1933736801147461
Batch 58/64 loss: 0.1915212869644165
Batch 59/64 loss: 0.18960881233215332
Batch 60/64 loss: 0.20205658674240112
Batch 61/64 loss: 0.1987476348876953
Batch 62/64 loss: 0.20412486791610718
Batch 63/64 loss: 0.18882203102111816
Batch 64/64 loss: 0.18802911043167114
Epoch 500  Train loss: 0.19324087418761907  Val loss: 0.270841535833693
SLIC undersegmentation error: 0.054052233676975946
SLIC inter-cluster variation: 0.02397972047789259
SLIC number of superpixels: 162588
SLIC superpixels per image: 558.7216494845361
Model loaded
Test metrics:
0.26444359251723665 0.17987353951890037 10.182599761501061 tensor(0.0911, dtype=torch.float64) 0.4205229669907335 1.6733377934038405 70253
Inference time: 0.004826750542290022 seconds
Relabeled undersegmentation error: 0.08603986254295529
Relabeled inter-cluster variation: 0.04389919412799431
Relabeled mean superpixels count: 403.9828178694158
Original mean superpixels count: 241.42268041237114
Done!
Job id: 422844
Job id: 423607
