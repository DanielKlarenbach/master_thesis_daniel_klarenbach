Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 4.6982035636901855
Batch 2/64 loss: 4.688803672790527
Batch 3/64 loss: 4.680059909820557
Batch 4/64 loss: 4.669508934020996
Batch 5/64 loss: 4.661187648773193
Batch 6/64 loss: 4.662114143371582
Batch 7/64 loss: 4.651062965393066
Batch 8/64 loss: 4.651322841644287
Batch 9/64 loss: 4.653759479522705
Batch 10/64 loss: 4.6488847732543945
Batch 11/64 loss: 4.651543140411377
Batch 12/64 loss: 4.647117614746094
Batch 13/64 loss: 4.645403861999512
Batch 14/64 loss: 4.646731853485107
Batch 15/64 loss: 4.645540714263916
Batch 16/64 loss: 4.645981311798096
Batch 17/64 loss: 4.64393424987793
Batch 18/64 loss: 4.6437296867370605
Batch 19/64 loss: 4.6441545486450195
Batch 20/64 loss: 4.643606662750244
Batch 21/64 loss: 4.643460273742676
Batch 22/64 loss: 4.643373012542725
Batch 23/64 loss: 4.64262580871582
Batch 24/64 loss: 4.6422834396362305
Batch 25/64 loss: 4.643185138702393
Batch 26/64 loss: 4.642233848571777
Batch 27/64 loss: 4.64226770401001
Batch 28/64 loss: 4.64220666885376
Batch 29/64 loss: 4.642037391662598
Batch 30/64 loss: 4.642033576965332
Batch 31/64 loss: 4.641785621643066
Batch 32/64 loss: 4.641817569732666
Batch 33/64 loss: 4.642003536224365
Batch 34/64 loss: 4.6416239738464355
Batch 35/64 loss: 4.641810894012451
Batch 36/64 loss: 4.641721725463867
Batch 37/64 loss: 4.641700267791748
Batch 38/64 loss: 4.641867160797119
Batch 39/64 loss: 4.641917705535889
Batch 40/64 loss: 4.6415581703186035
Batch 41/64 loss: 4.641660213470459
Batch 42/64 loss: 4.641561508178711
Batch 43/64 loss: 4.641622066497803
Batch 44/64 loss: 4.641808986663818
Batch 45/64 loss: 4.64152717590332
Batch 46/64 loss: 4.64152717590332
Batch 47/64 loss: 4.641413688659668
Batch 48/64 loss: 4.641488552093506
Batch 49/64 loss: 4.641481399536133
Batch 50/64 loss: 4.641341209411621
Batch 51/64 loss: 4.641458034515381
Batch 52/64 loss: 4.641349792480469
Batch 53/64 loss: 4.641360759735107
Batch 54/64 loss: 4.641304969787598
Batch 55/64 loss: 4.6413774490356445
Batch 56/64 loss: 4.641299724578857
Batch 57/64 loss: 4.641324043273926
Batch 58/64 loss: 4.641335487365723
Batch 59/64 loss: 4.64137601852417
Batch 60/64 loss: 4.641213893890381
Batch 61/64 loss: 4.641293525695801
Batch 62/64 loss: 4.641360759735107
Batch 63/64 loss: 4.641361236572266
Batch 64/64 loss: 3.8779962062835693
Epoch 1  Train loss: 4.63729427281548  Val loss: 4.609523313152012
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 4.641261577606201
Batch 2/64 loss: 4.6412577629089355
Batch 3/64 loss: 4.641272068023682
Batch 4/64 loss: 4.641197204589844
Batch 5/64 loss: 4.641158103942871
Batch 6/64 loss: 4.641166687011719
Batch 7/64 loss: 4.641226768493652
Batch 8/64 loss: 4.641190528869629
Batch 9/64 loss: 4.641122341156006
Batch 10/64 loss: 4.641112804412842
Batch 11/64 loss: 4.641112327575684
Batch 12/64 loss: 4.641112804412842
Batch 13/64 loss: 4.641116619110107
Batch 14/64 loss: 4.64120626449585
Batch 15/64 loss: 4.641053676605225
Batch 16/64 loss: 4.641120910644531
Batch 17/64 loss: 4.641026020050049
Batch 18/64 loss: 4.641005039215088
Batch 19/64 loss: 4.6410064697265625
Batch 20/64 loss: 4.640988349914551
Batch 21/64 loss: 4.641018390655518
Batch 22/64 loss: 4.640968322753906
Batch 23/64 loss: 4.640887260437012
Batch 24/64 loss: 4.64088249206543
Batch 25/64 loss: 4.640932559967041
Batch 26/64 loss: 4.640870094299316
Batch 27/64 loss: 4.640850067138672
Batch 28/64 loss: 4.640812397003174
Batch 29/64 loss: 4.640811920166016
Batch 30/64 loss: 4.640745639801025
Batch 31/64 loss: 4.640806674957275
Batch 32/64 loss: 4.640693664550781
Batch 33/64 loss: 4.640711784362793
Batch 34/64 loss: 4.64063024520874
Batch 35/64 loss: 4.640511989593506
Batch 36/64 loss: 4.640672206878662
Batch 37/64 loss: 4.640537738800049
Batch 38/64 loss: 4.640800952911377
Batch 39/64 loss: 4.640305042266846
Batch 40/64 loss: 4.640341758728027
Batch 41/64 loss: 4.6405158042907715
Batch 42/64 loss: 4.640201091766357
Batch 43/64 loss: 4.640108108520508
Batch 44/64 loss: 4.640085220336914
Batch 45/64 loss: 4.640685558319092
Batch 46/64 loss: 4.6398820877075195
Batch 47/64 loss: 4.640133380889893
Batch 48/64 loss: 4.640110969543457
Batch 49/64 loss: 4.639987468719482
Batch 50/64 loss: 4.6410627365112305
Batch 51/64 loss: 4.640081405639648
Batch 52/64 loss: 4.642972946166992
Batch 53/64 loss: 4.641570568084717
Batch 54/64 loss: 4.639902591705322
Batch 55/64 loss: 4.6397271156311035
Batch 56/64 loss: 4.63957405090332
Batch 57/64 loss: 4.640049457550049
Batch 58/64 loss: 4.640848159790039
Batch 59/64 loss: 4.640087127685547
Batch 60/64 loss: 4.63947868347168
Batch 61/64 loss: 4.639440536499023
Batch 62/64 loss: 4.639808177947998
Batch 63/64 loss: 4.6390533447265625
Batch 64/64 loss: 3.8733620643615723
Epoch 2  Train loss: 4.631653234070423  Val loss: 4.613053866268433
Epoch 3
-------------------------------
Batch 1/64 loss: 4.638749122619629
Batch 2/64 loss: 4.639682292938232
Batch 3/64 loss: 4.638944625854492
Batch 4/64 loss: 4.638181209564209
Batch 5/64 loss: 4.639345645904541
Batch 6/64 loss: 4.637758255004883
Batch 7/64 loss: 4.638519763946533
Batch 8/64 loss: 4.637937068939209
Batch 9/64 loss: 4.639765739440918
Batch 10/64 loss: 4.638579368591309
Batch 11/64 loss: 4.639612197875977
Batch 12/64 loss: 4.639440059661865
Batch 13/64 loss: 4.639209270477295
Batch 14/64 loss: 4.640282154083252
Batch 15/64 loss: 4.638934135437012
Batch 16/64 loss: 4.640384674072266
Batch 17/64 loss: 4.638115882873535
Batch 18/64 loss: 4.636890888214111
Batch 19/64 loss: 4.63773775100708
Batch 20/64 loss: 4.637929439544678
Batch 21/64 loss: 4.637666702270508
Batch 22/64 loss: 4.635513782501221
Batch 23/64 loss: 4.639334678649902
Batch 24/64 loss: 4.637864589691162
Batch 25/64 loss: 4.637255668640137
Batch 26/64 loss: 4.638497829437256
Batch 27/64 loss: 4.638453960418701
Batch 28/64 loss: 4.636960983276367
Batch 29/64 loss: 4.6360907554626465
Batch 30/64 loss: 4.636577606201172
Batch 31/64 loss: 4.636012554168701
Batch 32/64 loss: 4.635273456573486
Batch 33/64 loss: 4.635580539703369
Batch 34/64 loss: 4.633825302124023
Batch 35/64 loss: 4.634593486785889
Batch 36/64 loss: 4.6344990730285645
Batch 37/64 loss: 4.6345720291137695
Batch 38/64 loss: 4.635287284851074
Batch 39/64 loss: 4.634220123291016
Batch 40/64 loss: 4.6346516609191895
Batch 41/64 loss: 4.632533550262451
Batch 42/64 loss: 4.633870601654053
Batch 43/64 loss: 4.6374101638793945
Batch 44/64 loss: 4.633005619049072
Batch 45/64 loss: 4.634945392608643
Batch 46/64 loss: 4.633344650268555
Batch 47/64 loss: 4.634171485900879
Batch 48/64 loss: 4.634032726287842
Batch 49/64 loss: 4.632316589355469
Batch 50/64 loss: 4.634214401245117
Batch 51/64 loss: 4.6316986083984375
Batch 52/64 loss: 4.632973670959473
Batch 53/64 loss: 4.634451389312744
Batch 54/64 loss: 4.632648468017578
Batch 55/64 loss: 4.631295204162598
Batch 56/64 loss: 4.634695529937744
Batch 57/64 loss: 4.635089874267578
Batch 58/64 loss: 4.631986618041992
Batch 59/64 loss: 4.632252216339111
Batch 60/64 loss: 4.630415439605713
Batch 61/64 loss: 4.632943630218506
Batch 62/64 loss: 4.635053634643555
Batch 63/64 loss: 4.635263919830322
Batch 64/64 loss: 3.867111921310425
Epoch 3  Train loss: 4.626975355896295  Val loss: 4.604494867865572
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 4.636875152587891
Batch 2/64 loss: 4.6363205909729
Batch 3/64 loss: 4.6356587409973145
Batch 4/64 loss: 4.637233734130859
Batch 5/64 loss: 4.635362148284912
Batch 6/64 loss: 4.633269786834717
Batch 7/64 loss: 4.63038444519043
Batch 8/64 loss: 4.63775634765625
Batch 9/64 loss: 4.629156112670898
Batch 10/64 loss: 4.6309309005737305
Batch 11/64 loss: 4.632662296295166
Batch 12/64 loss: 4.631666660308838
Batch 13/64 loss: 4.6295928955078125
Batch 14/64 loss: 4.632987976074219
Batch 15/64 loss: 4.629157066345215
Batch 16/64 loss: 4.630478382110596
Batch 17/64 loss: 4.63156795501709
Batch 18/64 loss: 4.6306471824646
Batch 19/64 loss: 4.62985372543335
Batch 20/64 loss: 4.631346702575684
Batch 21/64 loss: 4.6325860023498535
Batch 22/64 loss: 4.631231784820557
Batch 23/64 loss: 4.631818771362305
Batch 24/64 loss: 4.630380630493164
Batch 25/64 loss: 4.62929105758667
Batch 26/64 loss: 4.629888534545898
Batch 27/64 loss: 4.628849506378174
Batch 28/64 loss: 4.631475925445557
Batch 29/64 loss: 4.630338191986084
Batch 30/64 loss: 4.629153728485107
Batch 31/64 loss: 4.629873752593994
Batch 32/64 loss: 4.630759239196777
Batch 33/64 loss: 4.629516124725342
Batch 34/64 loss: 4.628482341766357
Batch 35/64 loss: 4.627040386199951
Batch 36/64 loss: 4.628037929534912
Batch 37/64 loss: 4.627746105194092
Batch 38/64 loss: 4.626604080200195
Batch 39/64 loss: 4.628144264221191
Batch 40/64 loss: 4.62899923324585
Batch 41/64 loss: 4.627150535583496
Batch 42/64 loss: 4.6249518394470215
Batch 43/64 loss: 4.626832008361816
Batch 44/64 loss: 4.626152038574219
Batch 45/64 loss: 4.6281208992004395
Batch 46/64 loss: 4.6249470710754395
Batch 47/64 loss: 4.62543249130249
Batch 48/64 loss: 4.629302978515625
Batch 49/64 loss: 4.628265380859375
Batch 50/64 loss: 4.6251678466796875
Batch 51/64 loss: 4.629885673522949
Batch 52/64 loss: 4.629369735717773
Batch 53/64 loss: 4.625713348388672
Batch 54/64 loss: 4.626150131225586
Batch 55/64 loss: 4.62647008895874
Batch 56/64 loss: 4.627132892608643
Batch 57/64 loss: 4.6298346519470215
Batch 58/64 loss: 4.624563217163086
Batch 59/64 loss: 4.626665115356445
Batch 60/64 loss: 4.6251020431518555
Batch 61/64 loss: 4.62897253036499
Batch 62/64 loss: 4.626425266265869
Batch 63/64 loss: 4.626460552215576
Batch 64/64 loss: 3.8534982204437256
Epoch 4  Train loss: 4.620428523830339  Val loss: 4.596882437512637
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 4.630640983581543
Batch 2/64 loss: 4.625664234161377
Batch 3/64 loss: 4.626400947570801
Batch 4/64 loss: 4.62753438949585
Batch 5/64 loss: 4.626100063323975
Batch 6/64 loss: 4.626757621765137
Batch 7/64 loss: 4.628432273864746
Batch 8/64 loss: 4.625550746917725
Batch 9/64 loss: 4.6261677742004395
Batch 10/64 loss: 4.625930309295654
Batch 11/64 loss: 4.625811576843262
Batch 12/64 loss: 4.626250267028809
Batch 13/64 loss: 4.624645233154297
Batch 14/64 loss: 4.622472763061523
Batch 15/64 loss: 4.622919082641602
Batch 16/64 loss: 4.624835014343262
Batch 17/64 loss: 4.6243367195129395
Batch 18/64 loss: 4.624750137329102
Batch 19/64 loss: 4.631424903869629
Batch 20/64 loss: 4.625407695770264
Batch 21/64 loss: 4.628352165222168
Batch 22/64 loss: 4.624120712280273
Batch 23/64 loss: 4.625739097595215
Batch 24/64 loss: 4.6238532066345215
Batch 25/64 loss: 4.6265740394592285
Batch 26/64 loss: 4.627029895782471
Batch 27/64 loss: 4.627665996551514
Batch 28/64 loss: 4.625917434692383
Batch 29/64 loss: 4.624520778656006
Batch 30/64 loss: 4.624551773071289
Batch 31/64 loss: 4.632721424102783
Batch 32/64 loss: 4.628134250640869
Batch 33/64 loss: 4.624048709869385
Batch 34/64 loss: 4.623898983001709
Batch 35/64 loss: 4.623545169830322
Batch 36/64 loss: 4.624781608581543
Batch 37/64 loss: 4.624688625335693
Batch 38/64 loss: 4.6236419677734375
Batch 39/64 loss: 4.624896049499512
Batch 40/64 loss: 4.622274875640869
Batch 41/64 loss: 4.621924877166748
Batch 42/64 loss: 4.620733261108398
Batch 43/64 loss: 4.621154308319092
Batch 44/64 loss: 4.624403476715088
Batch 45/64 loss: 4.619900226593018
Batch 46/64 loss: 4.62007999420166
Batch 47/64 loss: 4.631783485412598
Batch 48/64 loss: 4.627704620361328
Batch 49/64 loss: 4.628227233886719
Batch 50/64 loss: 4.625234603881836
Batch 51/64 loss: 4.621155261993408
Batch 52/64 loss: 4.626467227935791
Batch 53/64 loss: 4.620868682861328
Batch 54/64 loss: 4.623819351196289
Batch 55/64 loss: 4.6261138916015625
Batch 56/64 loss: 4.627488136291504
Batch 57/64 loss: 4.623011112213135
Batch 58/64 loss: 4.624675750732422
Batch 59/64 loss: 4.623383045196533
Batch 60/64 loss: 4.624630451202393
Batch 61/64 loss: 4.622889995574951
Batch 62/64 loss: 4.625014781951904
Batch 63/64 loss: 4.62307071685791
Batch 64/64 loss: 3.8471696376800537
Epoch 5  Train loss: 4.616032960368138  Val loss: 4.604057057616637
Epoch 6
-------------------------------
Batch 1/64 loss: 4.628505706787109
Batch 2/64 loss: 4.624815464019775
Batch 3/64 loss: 4.623527526855469
Batch 4/64 loss: 4.623208999633789
Batch 5/64 loss: 4.62540340423584
Batch 6/64 loss: 4.624264240264893
Batch 7/64 loss: 4.620594024658203
Batch 8/64 loss: 4.62309455871582
Batch 9/64 loss: 4.620079040527344
Batch 10/64 loss: 4.622888565063477
Batch 11/64 loss: 4.6230998039245605
Batch 12/64 loss: 4.622229099273682
Batch 13/64 loss: 4.621054172515869
Batch 14/64 loss: 4.623702049255371
Batch 15/64 loss: 4.621579170227051
Batch 16/64 loss: 4.617588996887207
Batch 17/64 loss: 4.623517036437988
Batch 18/64 loss: 4.621721267700195
Batch 19/64 loss: 4.623098373413086
Batch 20/64 loss: 4.620429515838623
Batch 21/64 loss: 4.618095397949219
Batch 22/64 loss: 4.627930641174316
Batch 23/64 loss: 4.622345447540283
Batch 24/64 loss: 4.6188764572143555
Batch 25/64 loss: 4.621574878692627
Batch 26/64 loss: 4.622697353363037
Batch 27/64 loss: 4.622505187988281
Batch 28/64 loss: 4.6224870681762695
Batch 29/64 loss: 4.62477970123291
Batch 30/64 loss: 4.623596668243408
Batch 31/64 loss: 4.6310014724731445
Batch 32/64 loss: 4.626862525939941
Batch 33/64 loss: 4.624807834625244
Batch 34/64 loss: 4.629336833953857
Batch 35/64 loss: 4.626895904541016
Batch 36/64 loss: 4.6210761070251465
Batch 37/64 loss: 4.624958038330078
Batch 38/64 loss: 4.623902797698975
Batch 39/64 loss: 4.620035171508789
Batch 40/64 loss: 4.626269817352295
Batch 41/64 loss: 4.6229987144470215
Batch 42/64 loss: 4.626084804534912
Batch 43/64 loss: 4.62089204788208
Batch 44/64 loss: 4.6195068359375
Batch 45/64 loss: 4.623501300811768
Batch 46/64 loss: 4.621866703033447
Batch 47/64 loss: 4.621859550476074
Batch 48/64 loss: 4.619853973388672
Batch 49/64 loss: 4.6172308921813965
Batch 50/64 loss: 4.620686054229736
Batch 51/64 loss: 4.622491836547852
Batch 52/64 loss: 4.621544361114502
Batch 53/64 loss: 4.620820045471191
Batch 54/64 loss: 4.620481967926025
Batch 55/64 loss: 4.6189799308776855
Batch 56/64 loss: 4.621516227722168
Batch 57/64 loss: 4.623170375823975
Batch 58/64 loss: 4.620963096618652
Batch 59/64 loss: 4.619799613952637
Batch 60/64 loss: 4.62490177154541
Batch 61/64 loss: 4.623720645904541
Batch 62/64 loss: 4.618728160858154
Batch 63/64 loss: 4.624491214752197
Batch 64/64 loss: 3.839815378189087
Epoch 6  Train loss: 4.613496282053929  Val loss: 4.601489845829731
Epoch 7
-------------------------------
Batch 1/64 loss: 4.626237392425537
Batch 2/64 loss: 4.616815090179443
Batch 3/64 loss: 4.621387958526611
Batch 4/64 loss: 4.621413707733154
Batch 5/64 loss: 4.625354290008545
Batch 6/64 loss: 4.621137619018555
Batch 7/64 loss: 4.623830795288086
Batch 8/64 loss: 4.619486331939697
Batch 9/64 loss: 4.627380847930908
Batch 10/64 loss: 4.6288323402404785
Batch 11/64 loss: 4.6228532791137695
Batch 12/64 loss: 4.623836517333984
Batch 13/64 loss: 4.622814178466797
Batch 14/64 loss: 4.62186861038208
Batch 15/64 loss: 4.626564979553223
Batch 16/64 loss: 4.620761394500732
Batch 17/64 loss: 4.623079299926758
Batch 18/64 loss: 4.6252241134643555
Batch 19/64 loss: 4.620508670806885
Batch 20/64 loss: 4.6250691413879395
Batch 21/64 loss: 4.620352745056152
Batch 22/64 loss: 4.620624542236328
Batch 23/64 loss: 4.624924659729004
Batch 24/64 loss: 4.624670028686523
Batch 25/64 loss: 4.624502658843994
Batch 26/64 loss: 4.62658166885376
Batch 27/64 loss: 4.619941711425781
Batch 28/64 loss: 4.628327369689941
Batch 29/64 loss: 4.620678901672363
Batch 30/64 loss: 4.622135162353516
Batch 31/64 loss: 4.619614601135254
Batch 32/64 loss: 4.623123645782471
Batch 33/64 loss: 4.624432563781738
Batch 34/64 loss: 4.620119094848633
Batch 35/64 loss: 4.620742321014404
Batch 36/64 loss: 4.617684841156006
Batch 37/64 loss: 4.617785453796387
Batch 38/64 loss: 4.621340751647949
Batch 39/64 loss: 4.621173858642578
Batch 40/64 loss: 4.619052886962891
Batch 41/64 loss: 4.619692325592041
Batch 42/64 loss: 4.62205696105957
Batch 43/64 loss: 4.619903087615967
Batch 44/64 loss: 4.619236469268799
Batch 45/64 loss: 4.623308181762695
Batch 46/64 loss: 4.61860990524292
Batch 47/64 loss: 4.62199592590332
Batch 48/64 loss: 4.618048667907715
Batch 49/64 loss: 4.6209397315979
Batch 50/64 loss: 4.624658107757568
Batch 51/64 loss: 4.62065315246582
Batch 52/64 loss: 4.6184401512146
Batch 53/64 loss: 4.616689205169678
Batch 54/64 loss: 4.628626346588135
Batch 55/64 loss: 4.625399112701416
Batch 56/64 loss: 4.619915008544922
Batch 57/64 loss: 4.622529983520508
Batch 58/64 loss: 4.6190996170043945
Batch 59/64 loss: 4.624817848205566
Batch 60/64 loss: 4.6248393058776855
Batch 61/64 loss: 4.626349925994873
Batch 62/64 loss: 4.620372772216797
Batch 63/64 loss: 4.620111465454102
Batch 64/64 loss: 3.8414762020111084
Epoch 7  Train loss: 4.613014375462251  Val loss: 4.5881060873929576
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 4.622012138366699
Batch 2/64 loss: 4.625710964202881
Batch 3/64 loss: 4.620480537414551
Batch 4/64 loss: 4.623401165008545
Batch 5/64 loss: 4.6182146072387695
Batch 6/64 loss: 4.622069835662842
Batch 7/64 loss: 4.6165361404418945
Batch 8/64 loss: 4.6220221519470215
Batch 9/64 loss: 4.618215084075928
Batch 10/64 loss: 4.617757320404053
Batch 11/64 loss: 4.618713855743408
Batch 12/64 loss: 4.624453067779541
Batch 13/64 loss: 4.623706817626953
Batch 14/64 loss: 4.625222682952881
Batch 15/64 loss: 4.620193004608154
Batch 16/64 loss: 4.615105628967285
Batch 17/64 loss: 4.618015289306641
Batch 18/64 loss: 4.6156463623046875
Batch 19/64 loss: 4.6165771484375
Batch 20/64 loss: 4.617136001586914
Batch 21/64 loss: 4.618783473968506
Batch 22/64 loss: 4.618549823760986
Batch 23/64 loss: 4.617964744567871
Batch 24/64 loss: 4.616391658782959
Batch 25/64 loss: 4.62000846862793
Batch 26/64 loss: 4.620375633239746
Batch 27/64 loss: 4.620205879211426
Batch 28/64 loss: 4.629177570343018
Batch 29/64 loss: 4.6227126121521
Batch 30/64 loss: 4.614109516143799
Batch 31/64 loss: 4.6205339431762695
Batch 32/64 loss: 4.6270647048950195
Batch 33/64 loss: 4.618235111236572
Batch 34/64 loss: 4.62397575378418
Batch 35/64 loss: 4.623445987701416
Batch 36/64 loss: 4.6225690841674805
Batch 37/64 loss: 4.623181343078613
Batch 38/64 loss: 4.619666576385498
Batch 39/64 loss: 4.631142616271973
Batch 40/64 loss: 4.630620956420898
Batch 41/64 loss: 4.620551109313965
Batch 42/64 loss: 4.61715030670166
Batch 43/64 loss: 4.626133918762207
Batch 44/64 loss: 4.623216152191162
Batch 45/64 loss: 4.62330961227417
Batch 46/64 loss: 4.616339206695557
Batch 47/64 loss: 4.62339448928833
Batch 48/64 loss: 4.624984264373779
Batch 49/64 loss: 4.626890659332275
Batch 50/64 loss: 4.6224284172058105
Batch 51/64 loss: 4.622035503387451
Batch 52/64 loss: 4.618375301361084
Batch 53/64 loss: 4.622402191162109
Batch 54/64 loss: 4.623845100402832
Batch 55/64 loss: 4.6229143142700195
Batch 56/64 loss: 4.613333702087402
Batch 57/64 loss: 4.625113487243652
Batch 58/64 loss: 4.622037887573242
Batch 59/64 loss: 4.617538928985596
Batch 60/64 loss: 4.6224589347839355
Batch 61/64 loss: 4.616267204284668
Batch 62/64 loss: 4.619638919830322
Batch 63/64 loss: 4.6218366622924805
Batch 64/64 loss: 3.826674699783325
Epoch 8  Train loss: 4.6117977656570135  Val loss: 4.609235638195706
Epoch 9
-------------------------------
Batch 1/64 loss: 4.637340545654297
Batch 2/64 loss: 4.6220831871032715
Batch 3/64 loss: 4.626015663146973
Batch 4/64 loss: 4.631127834320068
Batch 5/64 loss: 4.623858451843262
Batch 6/64 loss: 4.6233296394348145
Batch 7/64 loss: 4.621870040893555
Batch 8/64 loss: 4.620119571685791
Batch 9/64 loss: 4.621741771697998
Batch 10/64 loss: 4.635316848754883
Batch 11/64 loss: 4.619486331939697
Batch 12/64 loss: 4.615565776824951
Batch 13/64 loss: 4.618101596832275
Batch 14/64 loss: 4.623896598815918
Batch 15/64 loss: 4.615900993347168
Batch 16/64 loss: 4.618793487548828
Batch 17/64 loss: 4.620367527008057
Batch 18/64 loss: 4.621716499328613
Batch 19/64 loss: 4.613813400268555
Batch 20/64 loss: 4.617928504943848
Batch 21/64 loss: 4.621339797973633
Batch 22/64 loss: 4.620472431182861
Batch 23/64 loss: 4.614410877227783
Batch 24/64 loss: 4.619096755981445
Batch 25/64 loss: 4.615203380584717
Batch 26/64 loss: 4.623746395111084
Batch 27/64 loss: 4.616910934448242
Batch 28/64 loss: 4.613763809204102
Batch 29/64 loss: 4.613508701324463
Batch 30/64 loss: 4.612304210662842
Batch 31/64 loss: 4.615708827972412
Batch 32/64 loss: 4.610406398773193
Batch 33/64 loss: 4.613491535186768
Batch 34/64 loss: 4.605511665344238
Batch 35/64 loss: 4.630032062530518
Batch 36/64 loss: 4.627191543579102
Batch 37/64 loss: 4.616554260253906
Batch 38/64 loss: 4.611886978149414
Batch 39/64 loss: 4.627760410308838
Batch 40/64 loss: 4.621586799621582
Batch 41/64 loss: 4.620327472686768
Batch 42/64 loss: 4.632157802581787
Batch 43/64 loss: 4.619344711303711
Batch 44/64 loss: 4.6249871253967285
Batch 45/64 loss: 4.623780727386475
Batch 46/64 loss: 4.613245964050293
Batch 47/64 loss: 4.621811866760254
Batch 48/64 loss: 4.619592189788818
Batch 49/64 loss: 4.616576671600342
Batch 50/64 loss: 4.6216721534729
Batch 51/64 loss: 4.61778450012207
Batch 52/64 loss: 4.620693683624268
Batch 53/64 loss: 4.622081756591797
Batch 54/64 loss: 4.6189446449279785
Batch 55/64 loss: 4.608520984649658
Batch 56/64 loss: 4.617592811584473
Batch 57/64 loss: 4.616116523742676
Batch 58/64 loss: 4.614560604095459
Batch 59/64 loss: 4.615991592407227
Batch 60/64 loss: 4.6229166984558105
Batch 61/64 loss: 4.633419990539551
Batch 62/64 loss: 4.620568752288818
Batch 63/64 loss: 4.620987415313721
Batch 64/64 loss: 3.8520712852478027
Epoch 9  Train loss: 4.611011641633277  Val loss: 4.593195130734919
Epoch 10
-------------------------------
Batch 1/64 loss: 4.632853031158447
Batch 2/64 loss: 4.6245598793029785
Batch 3/64 loss: 4.624992370605469
Batch 4/64 loss: 4.628386497497559
Batch 5/64 loss: 4.616940975189209
Batch 6/64 loss: 4.621363162994385
Batch 7/64 loss: 4.626436233520508
Batch 8/64 loss: 4.613807678222656
Batch 9/64 loss: 4.628624439239502
Batch 10/64 loss: 4.619563102722168
Batch 11/64 loss: 4.623344421386719
Batch 12/64 loss: 4.6268181800842285
Batch 13/64 loss: 4.6136298179626465
Batch 14/64 loss: 4.628185272216797
Batch 15/64 loss: 4.628307819366455
Batch 16/64 loss: 4.61213493347168
Batch 17/64 loss: 4.6176347732543945
Batch 18/64 loss: 4.628835678100586
Batch 19/64 loss: 4.6264142990112305
Batch 20/64 loss: 4.622804641723633
Batch 21/64 loss: 4.613288879394531
Batch 22/64 loss: 4.621851444244385
Batch 23/64 loss: 4.6179327964782715
Batch 24/64 loss: 4.632136821746826
Batch 25/64 loss: 4.620193958282471
Batch 26/64 loss: 4.621295928955078
Batch 27/64 loss: 4.622481346130371
Batch 28/64 loss: 4.6278557777404785
Batch 29/64 loss: 4.631894588470459
Batch 30/64 loss: 4.622756481170654
Batch 31/64 loss: 4.6233673095703125
Batch 32/64 loss: 4.640110969543457
Batch 33/64 loss: 4.624838352203369
Batch 34/64 loss: 4.617592811584473
Batch 35/64 loss: 4.6271891593933105
Batch 36/64 loss: 4.634877681732178
Batch 37/64 loss: 4.61505126953125
Batch 38/64 loss: 4.6196465492248535
Batch 39/64 loss: 4.618358135223389
Batch 40/64 loss: 4.617106914520264
Batch 41/64 loss: 4.624475002288818
Batch 42/64 loss: 4.620357513427734
Batch 43/64 loss: 4.620521068572998
Batch 44/64 loss: 4.620678901672363
Batch 45/64 loss: 4.614119529724121
Batch 46/64 loss: 4.619845867156982
Batch 47/64 loss: 4.60978364944458
Batch 48/64 loss: 4.62587308883667
Batch 49/64 loss: 4.605173110961914
Batch 50/64 loss: 4.619556903839111
Batch 51/64 loss: 4.637182712554932
Batch 52/64 loss: 4.6130170822143555
Batch 53/64 loss: 4.620436668395996
Batch 54/64 loss: 4.62721586227417
Batch 55/64 loss: 4.61837911605835
Batch 56/64 loss: 4.620701789855957
Batch 57/64 loss: 4.614459037780762
Batch 58/64 loss: 4.61036491394043
Batch 59/64 loss: 4.605746269226074
Batch 60/64 loss: 4.625455379486084
Batch 61/64 loss: 4.611562728881836
Batch 62/64 loss: 4.613289833068848
Batch 63/64 loss: 4.62587308883667
Batch 64/64 loss: 3.8203186988830566
Epoch 10  Train loss: 4.612153294507195  Val loss: 4.598445541670232
Epoch 11
-------------------------------
Batch 1/64 loss: 4.613763332366943
Batch 2/64 loss: 4.616724967956543
Batch 3/64 loss: 4.6301727294921875
Batch 4/64 loss: 4.609281063079834
Batch 5/64 loss: 4.613680839538574
Batch 6/64 loss: 4.6089863777160645
Batch 7/64 loss: 4.624021530151367
Batch 8/64 loss: 4.6331071853637695
Batch 9/64 loss: 4.612761497497559
Batch 10/64 loss: 4.623889446258545
Batch 11/64 loss: 4.615132808685303
Batch 12/64 loss: 4.621164321899414
Batch 13/64 loss: 4.623849391937256
Batch 14/64 loss: 4.624486446380615
Batch 15/64 loss: 4.614345073699951
Batch 16/64 loss: 4.627531051635742
Batch 17/64 loss: 4.627410888671875
Batch 18/64 loss: 4.628615856170654
Batch 19/64 loss: 4.618807315826416
Batch 20/64 loss: 4.616211891174316
Batch 21/64 loss: 4.627897262573242
Batch 22/64 loss: 4.621109485626221
Batch 23/64 loss: 4.6186065673828125
Batch 24/64 loss: 4.620459079742432
Batch 25/64 loss: 4.615758895874023
Batch 26/64 loss: 4.615406513214111
Batch 27/64 loss: 4.610021114349365
Batch 28/64 loss: 4.616458892822266
Batch 29/64 loss: 4.608407497406006
Batch 30/64 loss: 4.618973731994629
Batch 31/64 loss: 4.621730327606201
Batch 32/64 loss: 4.615823745727539
Batch 33/64 loss: 4.6299052238464355
Batch 34/64 loss: 4.618494987487793
Batch 35/64 loss: 4.609650611877441
Batch 36/64 loss: 4.6293416023254395
Batch 37/64 loss: 4.611328601837158
Batch 38/64 loss: 4.604114532470703
Batch 39/64 loss: 4.614571571350098
Batch 40/64 loss: 4.6191277503967285
Batch 41/64 loss: 4.622183322906494
Batch 42/64 loss: 4.615328311920166
Batch 43/64 loss: 4.616815567016602
Batch 44/64 loss: 4.621397018432617
Batch 45/64 loss: 4.625833511352539
Batch 46/64 loss: 4.613912582397461
Batch 47/64 loss: 4.6235809326171875
Batch 48/64 loss: 4.615612983703613
Batch 49/64 loss: 4.6157636642456055
Batch 50/64 loss: 4.6221771240234375
Batch 51/64 loss: 4.616244792938232
Batch 52/64 loss: 4.60939884185791
Batch 53/64 loss: 4.60438346862793
Batch 54/64 loss: 4.596210956573486
Batch 55/64 loss: 4.635452747344971
Batch 56/64 loss: 4.61403751373291
Batch 57/64 loss: 4.620361328125
Batch 58/64 loss: 4.606075763702393
Batch 59/64 loss: 4.606858253479004
Batch 60/64 loss: 4.605686664581299
Batch 61/64 loss: 4.621584892272949
Batch 62/64 loss: 4.614769458770752
Batch 63/64 loss: 4.627396583557129
Batch 64/64 loss: 3.802607536315918
Epoch 11  Train loss: 4.608222022711062  Val loss: 4.590813626538437
Epoch 12
-------------------------------
Batch 1/64 loss: 4.613938808441162
Batch 2/64 loss: 4.608844757080078
Batch 3/64 loss: 4.605062007904053
Batch 4/64 loss: 4.605576515197754
Batch 5/64 loss: 4.609261512756348
Batch 6/64 loss: 4.610614776611328
Batch 7/64 loss: 4.611022472381592
Batch 8/64 loss: 4.617231845855713
Batch 9/64 loss: 4.615091323852539
Batch 10/64 loss: 4.606103897094727
Batch 11/64 loss: 4.611047267913818
Batch 12/64 loss: 4.616301536560059
Batch 13/64 loss: 4.607571601867676
Batch 14/64 loss: 4.611456394195557
Batch 15/64 loss: 4.613760471343994
Batch 16/64 loss: 4.612534999847412
Batch 17/64 loss: 4.609936237335205
Batch 18/64 loss: 4.617014408111572
Batch 19/64 loss: 4.598811626434326
Batch 20/64 loss: 4.6101861000061035
Batch 21/64 loss: 4.606532573699951
Batch 22/64 loss: 4.61426305770874
Batch 23/64 loss: 4.628039360046387
Batch 24/64 loss: 4.614487648010254
Batch 25/64 loss: 4.6044158935546875
Batch 26/64 loss: 4.600701808929443
Batch 27/64 loss: 4.625648021697998
Batch 28/64 loss: 4.603942394256592
Batch 29/64 loss: 4.610412120819092
Batch 30/64 loss: 4.62022590637207
Batch 31/64 loss: 4.630765914916992
Batch 32/64 loss: 4.631592750549316
Batch 33/64 loss: 4.615262031555176
Batch 34/64 loss: 4.620933532714844
Batch 35/64 loss: 4.614025115966797
Batch 36/64 loss: 4.615898132324219
Batch 37/64 loss: 4.611268997192383
Batch 38/64 loss: 4.619202613830566
Batch 39/64 loss: 4.600550174713135
Batch 40/64 loss: 4.603149890899658
Batch 41/64 loss: 4.620066165924072
Batch 42/64 loss: 4.612003326416016
Batch 43/64 loss: 4.604315280914307
Batch 44/64 loss: 4.602665424346924
Batch 45/64 loss: 4.597839832305908
Batch 46/64 loss: 4.623376846313477
Batch 47/64 loss: 4.618322372436523
Batch 48/64 loss: 4.610565662384033
Batch 49/64 loss: 4.588629245758057
Batch 50/64 loss: 4.610667705535889
Batch 51/64 loss: 4.6061224937438965
Batch 52/64 loss: 4.612288951873779
Batch 53/64 loss: 4.6122517585754395
Batch 54/64 loss: 4.606573581695557
Batch 55/64 loss: 4.605313301086426
Batch 56/64 loss: 4.603527545928955
Batch 57/64 loss: 4.60879373550415
Batch 58/64 loss: 4.645215034484863
Batch 59/64 loss: 4.602553367614746
Batch 60/64 loss: 4.621659278869629
Batch 61/64 loss: 4.601031303405762
Batch 62/64 loss: 4.597227096557617
Batch 63/64 loss: 4.6107635498046875
Batch 64/64 loss: 3.788698196411133
Epoch 12  Train loss: 4.601819341322955  Val loss: 4.588288126532564
Epoch 13
-------------------------------
Batch 1/64 loss: 4.596753120422363
Batch 2/64 loss: 4.610151767730713
Batch 3/64 loss: 4.603333950042725
Batch 4/64 loss: 4.607769012451172
Batch 5/64 loss: 4.620497226715088
Batch 6/64 loss: 4.614830493927002
Batch 7/64 loss: 4.619657516479492
Batch 8/64 loss: 4.638896942138672
Batch 9/64 loss: 4.633718490600586
Batch 10/64 loss: 4.654980182647705
Batch 11/64 loss: 4.630438804626465
Batch 12/64 loss: 4.627093315124512
Batch 13/64 loss: 4.632946968078613
Batch 14/64 loss: 4.629910469055176
Batch 15/64 loss: 4.626152038574219
Batch 16/64 loss: 4.640021324157715
Batch 17/64 loss: 4.634716033935547
Batch 18/64 loss: 4.6234636306762695
Batch 19/64 loss: 4.6402692794799805
Batch 20/64 loss: 4.627800941467285
Batch 21/64 loss: 4.6351799964904785
Batch 22/64 loss: 4.62312126159668
Batch 23/64 loss: 4.631895065307617
Batch 24/64 loss: 4.625027179718018
Batch 25/64 loss: 4.627499580383301
Batch 26/64 loss: 4.635743141174316
Batch 27/64 loss: 4.6391682624816895
Batch 28/64 loss: 4.632318496704102
Batch 29/64 loss: 4.619524955749512
Batch 30/64 loss: 4.654176235198975
Batch 31/64 loss: 4.641628742218018
Batch 32/64 loss: 4.629610538482666
Batch 33/64 loss: 4.639128684997559
Batch 34/64 loss: 4.6214070320129395
Batch 35/64 loss: 4.643929958343506
Batch 36/64 loss: 4.639926433563232
Batch 37/64 loss: 4.633553981781006
Batch 38/64 loss: 4.632360458374023
Batch 39/64 loss: 4.6256866455078125
Batch 40/64 loss: 4.625296115875244
Batch 41/64 loss: 4.649150848388672
Batch 42/64 loss: 4.631654262542725
Batch 43/64 loss: 4.644236087799072
Batch 44/64 loss: 4.623232841491699
Batch 45/64 loss: 4.632785320281982
Batch 46/64 loss: 4.636958599090576
Batch 47/64 loss: 4.628028392791748
Batch 48/64 loss: 4.62746000289917
Batch 49/64 loss: 4.623293876647949
Batch 50/64 loss: 4.62337064743042
Batch 51/64 loss: 4.620061874389648
Batch 52/64 loss: 4.613147735595703
Batch 53/64 loss: 4.6273908615112305
Batch 54/64 loss: 4.6164398193359375
Batch 55/64 loss: 4.629242897033691
Batch 56/64 loss: 4.610481262207031
Batch 57/64 loss: 4.6252241134643555
Batch 58/64 loss: 4.621053218841553
Batch 59/64 loss: 4.614582061767578
Batch 60/64 loss: 4.613331317901611
Batch 61/64 loss: 4.616135120391846
Batch 62/64 loss: 4.611541271209717
Batch 63/64 loss: 4.6216888427734375
Batch 64/64 loss: 3.8035945892333984
Epoch 13  Train loss: 4.617768964580461  Val loss: 4.592867769326541
Epoch 14
-------------------------------
Batch 1/64 loss: 4.618005275726318
Batch 2/64 loss: 4.611726760864258
Batch 3/64 loss: 4.62555456161499
Batch 4/64 loss: 4.616462230682373
Batch 5/64 loss: 4.612183094024658
Batch 6/64 loss: 4.618162155151367
Batch 7/64 loss: 4.615428447723389
Batch 8/64 loss: 4.615734577178955
Batch 9/64 loss: 4.607460021972656
Batch 10/64 loss: 4.617600917816162
Batch 11/64 loss: 4.600655555725098
Batch 12/64 loss: 4.599830627441406
Batch 13/64 loss: 4.616871356964111
Batch 14/64 loss: 4.609041213989258
Batch 15/64 loss: 4.609769344329834
Batch 16/64 loss: 4.604892730712891
Batch 17/64 loss: 4.601118087768555
Batch 18/64 loss: 4.620937824249268
Batch 19/64 loss: 4.63496732711792
Batch 20/64 loss: 4.610988140106201
Batch 21/64 loss: 4.596404552459717
Batch 22/64 loss: 4.603799343109131
Batch 23/64 loss: 4.616979122161865
Batch 24/64 loss: 4.611061096191406
Batch 25/64 loss: 4.604351997375488
Batch 26/64 loss: 4.624752998352051
Batch 27/64 loss: 4.600410461425781
Batch 28/64 loss: 4.609915256500244
Batch 29/64 loss: 4.603484630584717
Batch 30/64 loss: 4.601259708404541
Batch 31/64 loss: 4.616488456726074
Batch 32/64 loss: 4.614492416381836
Batch 33/64 loss: 4.601139068603516
Batch 34/64 loss: 4.602590560913086
Batch 35/64 loss: 4.621548652648926
Batch 36/64 loss: 4.597477436065674
Batch 37/64 loss: 4.584507465362549
Batch 38/64 loss: 4.603298664093018
Batch 39/64 loss: 4.634943962097168
Batch 40/64 loss: 4.593458652496338
Batch 41/64 loss: 4.600590229034424
Batch 42/64 loss: 4.587812423706055
Batch 43/64 loss: 4.589291572570801
Batch 44/64 loss: 4.6051788330078125
Batch 45/64 loss: 4.606447696685791
Batch 46/64 loss: 4.6111159324646
Batch 47/64 loss: 4.606302738189697
Batch 48/64 loss: 4.6022629737854
Batch 49/64 loss: 4.593758583068848
Batch 50/64 loss: 4.591525554656982
Batch 51/64 loss: 4.613234043121338
Batch 52/64 loss: 4.588988304138184
Batch 53/64 loss: 4.605698108673096
Batch 54/64 loss: 4.590031147003174
Batch 55/64 loss: 4.602841377258301
Batch 56/64 loss: 4.619585037231445
Batch 57/64 loss: 4.593514442443848
Batch 58/64 loss: 4.584589958190918
Batch 59/64 loss: 4.607208728790283
Batch 60/64 loss: 4.582136631011963
Batch 61/64 loss: 4.594702243804932
Batch 62/64 loss: 4.610905647277832
Batch 63/64 loss: 4.625479698181152
Batch 64/64 loss: 3.7811551094055176
Epoch 14  Train loss: 4.597001144932766  Val loss: 4.569656875330148
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: 4.596395015716553
Batch 2/64 loss: 4.592960834503174
Batch 3/64 loss: 4.609057903289795
Batch 4/64 loss: 4.599158763885498
Batch 5/64 loss: 4.6077470779418945
Batch 6/64 loss: 4.615494251251221
Batch 7/64 loss: 4.605824947357178
Batch 8/64 loss: 4.595197677612305
Batch 9/64 loss: 4.596318244934082
Batch 10/64 loss: 4.596686363220215
Batch 11/64 loss: 4.591336727142334
Batch 12/64 loss: 4.58054780960083
Batch 13/64 loss: 4.595761299133301
Batch 14/64 loss: 4.595853805541992
Batch 15/64 loss: 4.595244407653809
Batch 16/64 loss: 4.586272716522217
Batch 17/64 loss: 4.5832295417785645
Batch 18/64 loss: 4.608422756195068
Batch 19/64 loss: 4.590445518493652
Batch 20/64 loss: 4.588412761688232
Batch 21/64 loss: 4.604640960693359
Batch 22/64 loss: 4.593537330627441
Batch 23/64 loss: 4.597708225250244
Batch 24/64 loss: 4.597611427307129
Batch 25/64 loss: 4.593357086181641
Batch 26/64 loss: 4.596330642700195
Batch 27/64 loss: 4.596726417541504
Batch 28/64 loss: 4.603519916534424
Batch 29/64 loss: 4.601181983947754
Batch 30/64 loss: 4.607641696929932
Batch 31/64 loss: 4.612084865570068
Batch 32/64 loss: 4.591485023498535
Batch 33/64 loss: 4.590267181396484
Batch 34/64 loss: 4.591560363769531
Batch 35/64 loss: 4.589655876159668
Batch 36/64 loss: 4.59964656829834
Batch 37/64 loss: 4.591021537780762
Batch 38/64 loss: 4.605308532714844
Batch 39/64 loss: 4.615265369415283
Batch 40/64 loss: 4.593532085418701
Batch 41/64 loss: 4.601290225982666
Batch 42/64 loss: 4.597212791442871
Batch 43/64 loss: 4.609963417053223
Batch 44/64 loss: 4.599081516265869
Batch 45/64 loss: 4.5901994705200195
Batch 46/64 loss: 4.595531940460205
Batch 47/64 loss: 4.618391990661621
Batch 48/64 loss: 4.623650074005127
Batch 49/64 loss: 4.607524394989014
Batch 50/64 loss: 4.619533538818359
Batch 51/64 loss: 4.621912002563477
Batch 52/64 loss: 4.5994873046875
Batch 53/64 loss: 4.609686374664307
Batch 54/64 loss: 4.605204105377197
Batch 55/64 loss: 4.602125644683838
Batch 56/64 loss: 4.5882062911987305
Batch 57/64 loss: 4.601400852203369
Batch 58/64 loss: 4.589585304260254
Batch 59/64 loss: 4.591425895690918
Batch 60/64 loss: 4.609621524810791
Batch 61/64 loss: 4.60382080078125
Batch 62/64 loss: 4.581875324249268
Batch 63/64 loss: 4.581215858459473
Batch 64/64 loss: 3.762502670288086
Epoch 15  Train loss: 4.589369022144991  Val loss: 4.585828604976745
Epoch 16
-------------------------------
Batch 1/64 loss: 4.591977119445801
Batch 2/64 loss: 4.619609832763672
Batch 3/64 loss: 4.606395244598389
Batch 4/64 loss: 4.577643871307373
Batch 5/64 loss: 4.599491596221924
Batch 6/64 loss: 4.615800380706787
Batch 7/64 loss: 4.593439102172852
Batch 8/64 loss: 4.594577789306641
Batch 9/64 loss: 4.592203617095947
Batch 10/64 loss: 4.590615749359131
Batch 11/64 loss: 4.598860263824463
Batch 12/64 loss: 4.601005554199219
Batch 13/64 loss: 4.605712413787842
Batch 14/64 loss: 4.587698936462402
Batch 15/64 loss: 4.581808567047119
Batch 16/64 loss: 4.607202053070068
Batch 17/64 loss: 4.6135478019714355
Batch 18/64 loss: 4.594024181365967
Batch 19/64 loss: 4.5968217849731445
Batch 20/64 loss: 4.597528457641602
Batch 21/64 loss: 4.619582653045654
Batch 22/64 loss: 4.587860584259033
Batch 23/64 loss: 4.592407703399658
Batch 24/64 loss: 4.597001075744629
Batch 25/64 loss: 4.582148551940918
Batch 26/64 loss: 4.599925518035889
Batch 27/64 loss: 4.584042072296143
Batch 28/64 loss: 4.586251258850098
Batch 29/64 loss: 4.582549571990967
Batch 30/64 loss: 4.594389915466309
Batch 31/64 loss: 4.579755783081055
Batch 32/64 loss: 4.597168922424316
Batch 33/64 loss: 4.576273441314697
Batch 34/64 loss: 4.594695091247559
Batch 35/64 loss: 4.606583118438721
Batch 36/64 loss: 4.592077255249023
Batch 37/64 loss: 4.6186723709106445
Batch 38/64 loss: 4.606245517730713
Batch 39/64 loss: 4.594944953918457
Batch 40/64 loss: 4.586710453033447
Batch 41/64 loss: 4.595036506652832
Batch 42/64 loss: 4.5930399894714355
Batch 43/64 loss: 4.619365692138672
Batch 44/64 loss: 4.590962886810303
Batch 45/64 loss: 4.586849689483643
Batch 46/64 loss: 4.58289098739624
Batch 47/64 loss: 4.592363357543945
Batch 48/64 loss: 4.59372615814209
Batch 49/64 loss: 4.589888572692871
Batch 50/64 loss: 4.588438510894775
Batch 51/64 loss: 4.586878776550293
Batch 52/64 loss: 4.598914623260498
Batch 53/64 loss: 4.575978755950928
Batch 54/64 loss: 4.595202922821045
Batch 55/64 loss: 4.5847039222717285
Batch 56/64 loss: 4.587759971618652
Batch 57/64 loss: 4.575584411621094
Batch 58/64 loss: 4.6103739738464355
Batch 59/64 loss: 4.584733963012695
Batch 60/64 loss: 4.587525367736816
Batch 61/64 loss: 4.568338394165039
Batch 62/64 loss: 4.60126256942749
Batch 63/64 loss: 4.595871925354004
Batch 64/64 loss: 3.739377021789551
Epoch 16  Train loss: 4.584085879606359  Val loss: 4.569403785610526
Saving best model, epoch: 16
Epoch 17
-------------------------------
Batch 1/64 loss: 4.593680381774902
Batch 2/64 loss: 4.574712753295898
Batch 3/64 loss: 4.6085591316223145
Batch 4/64 loss: 4.574553966522217
Batch 5/64 loss: 4.587635517120361
Batch 6/64 loss: 4.59598445892334
Batch 7/64 loss: 4.600816249847412
Batch 8/64 loss: 4.592634201049805
Batch 9/64 loss: 4.592658042907715
Batch 10/64 loss: 4.610376834869385
Batch 11/64 loss: 4.59084939956665
Batch 12/64 loss: 4.597844123840332
Batch 13/64 loss: 4.598165512084961
Batch 14/64 loss: 4.598859786987305
Batch 15/64 loss: 4.597033977508545
Batch 16/64 loss: 4.595499515533447
Batch 17/64 loss: 4.6049933433532715
Batch 18/64 loss: 4.598957538604736
Batch 19/64 loss: 4.59544038772583
Batch 20/64 loss: 4.599369049072266
Batch 21/64 loss: 4.577497482299805
Batch 22/64 loss: 4.596393585205078
Batch 23/64 loss: 4.5971856117248535
Batch 24/64 loss: 4.588987350463867
Batch 25/64 loss: 4.615242958068848
Batch 26/64 loss: 4.585065841674805
Batch 27/64 loss: 4.597141742706299
Batch 28/64 loss: 4.594728469848633
Batch 29/64 loss: 4.601065635681152
Batch 30/64 loss: 4.611574172973633
Batch 31/64 loss: 4.584557056427002
Batch 32/64 loss: 4.600949764251709
Batch 33/64 loss: 4.581348419189453
Batch 34/64 loss: 4.60103702545166
Batch 35/64 loss: 4.59602165222168
Batch 36/64 loss: 4.6213579177856445
Batch 37/64 loss: 4.580629348754883
Batch 38/64 loss: 4.584848403930664
Batch 39/64 loss: 4.597894191741943
Batch 40/64 loss: 4.583835601806641
Batch 41/64 loss: 4.577845573425293
Batch 42/64 loss: 4.591983795166016
Batch 43/64 loss: 4.582900524139404
Batch 44/64 loss: 4.60956335067749
Batch 45/64 loss: 4.57289981842041
Batch 46/64 loss: 4.582437515258789
Batch 47/64 loss: 4.592966079711914
Batch 48/64 loss: 4.601223468780518
Batch 49/64 loss: 4.575632095336914
Batch 50/64 loss: 4.575584888458252
Batch 51/64 loss: 4.587069511413574
Batch 52/64 loss: 4.5905351638793945
Batch 53/64 loss: 4.6025590896606445
Batch 54/64 loss: 4.589188575744629
Batch 55/64 loss: 4.604498863220215
Batch 56/64 loss: 4.5860137939453125
Batch 57/64 loss: 4.586370944976807
Batch 58/64 loss: 4.605836868286133
Batch 59/64 loss: 4.607506275177002
Batch 60/64 loss: 4.590630054473877
Batch 61/64 loss: 4.567901611328125
Batch 62/64 loss: 4.601992130279541
Batch 63/64 loss: 4.577248573303223
Batch 64/64 loss: 3.781515121459961
Epoch 17  Train loss: 4.583568804871803  Val loss: 4.62733183898467
Epoch 18
-------------------------------
Batch 1/64 loss: 4.5803046226501465
Batch 2/64 loss: 4.597912788391113
Batch 3/64 loss: 4.602258205413818
Batch 4/64 loss: 4.622770309448242
Batch 5/64 loss: 4.599690914154053
Batch 6/64 loss: 4.623872756958008
Batch 7/64 loss: 4.593783855438232
Batch 8/64 loss: 4.596645355224609
Batch 9/64 loss: 4.62399959564209
Batch 10/64 loss: 4.586804389953613
Batch 11/64 loss: 4.594004154205322
Batch 12/64 loss: 4.597442150115967
Batch 13/64 loss: 4.595059871673584
Batch 14/64 loss: 4.595269680023193
Batch 15/64 loss: 4.635875225067139
Batch 16/64 loss: 4.601297378540039
Batch 17/64 loss: 4.5841288566589355
Batch 18/64 loss: 4.583306789398193
Batch 19/64 loss: 4.585197448730469
Batch 20/64 loss: 4.589179515838623
Batch 21/64 loss: 4.6187520027160645
Batch 22/64 loss: 4.599610328674316
Batch 23/64 loss: 4.587255001068115
Batch 24/64 loss: 4.593912601470947
Batch 25/64 loss: 4.58641242980957
Batch 26/64 loss: 4.5906901359558105
Batch 27/64 loss: 4.617011070251465
Batch 28/64 loss: 4.58527135848999
Batch 29/64 loss: 4.592268466949463
Batch 30/64 loss: 4.601424694061279
Batch 31/64 loss: 4.604591369628906
Batch 32/64 loss: 4.589920520782471
Batch 33/64 loss: 4.583093166351318
Batch 34/64 loss: 4.600814342498779
Batch 35/64 loss: 4.587941646575928
Batch 36/64 loss: 4.587202072143555
Batch 37/64 loss: 4.58278226852417
Batch 38/64 loss: 4.593791961669922
Batch 39/64 loss: 4.593095779418945
Batch 40/64 loss: 4.604240894317627
Batch 41/64 loss: 4.584046363830566
Batch 42/64 loss: 4.584130764007568
Batch 43/64 loss: 4.596263408660889
Batch 44/64 loss: 4.596130847930908
Batch 45/64 loss: 4.605775356292725
Batch 46/64 loss: 4.589741230010986
Batch 47/64 loss: 4.599780559539795
Batch 48/64 loss: 4.596400737762451
Batch 49/64 loss: 4.605098724365234
Batch 50/64 loss: 4.588078022003174
Batch 51/64 loss: 4.596922397613525
Batch 52/64 loss: 4.621057987213135
Batch 53/64 loss: 4.5786261558532715
Batch 54/64 loss: 4.597340106964111
Batch 55/64 loss: 4.613645076751709
Batch 56/64 loss: 4.579967975616455
Batch 57/64 loss: 4.5902204513549805
Batch 58/64 loss: 4.600246906280518
Batch 59/64 loss: 4.6059064865112305
Batch 60/64 loss: 4.606293201446533
Batch 61/64 loss: 4.586122512817383
Batch 62/64 loss: 4.5835771560668945
Batch 63/64 loss: 4.600207328796387
Batch 64/64 loss: 3.721299409866333
Epoch 18  Train loss: 4.586438279058419  Val loss: 4.594364553382716
Epoch 19
-------------------------------
Batch 1/64 loss: 4.588598728179932
Batch 2/64 loss: 4.601747512817383
Batch 3/64 loss: 4.622505187988281
Batch 4/64 loss: 4.595916271209717
Batch 5/64 loss: 4.579150676727295
Batch 6/64 loss: 4.631404399871826
Batch 7/64 loss: 4.58542537689209
Batch 8/64 loss: 4.5810699462890625
Batch 9/64 loss: 4.605215549468994
Batch 10/64 loss: 4.599203109741211
Batch 11/64 loss: 4.603637218475342
Batch 12/64 loss: 4.596054553985596
Batch 13/64 loss: 4.611456394195557
Batch 14/64 loss: 4.583306312561035
Batch 15/64 loss: 4.602756977081299
Batch 16/64 loss: 4.60048246383667
Batch 17/64 loss: 4.577779769897461
Batch 18/64 loss: 4.594812393188477
Batch 19/64 loss: 4.568710803985596
Batch 20/64 loss: 4.6150898933410645
Batch 21/64 loss: 4.5857744216918945
Batch 22/64 loss: 4.588425636291504
Batch 23/64 loss: 4.574552536010742
Batch 24/64 loss: 4.609253406524658
Batch 25/64 loss: 4.608674049377441
Batch 26/64 loss: 4.5829267501831055
Batch 27/64 loss: 4.559374809265137
Batch 28/64 loss: 4.592705249786377
Batch 29/64 loss: 4.572994709014893
Batch 30/64 loss: 4.581439971923828
Batch 31/64 loss: 4.584373474121094
Batch 32/64 loss: 4.568271636962891
Batch 33/64 loss: 4.580255508422852
Batch 34/64 loss: 4.574905872344971
Batch 35/64 loss: 4.59230375289917
Batch 36/64 loss: 4.570126056671143
Batch 37/64 loss: 4.587751388549805
Batch 38/64 loss: 4.593829154968262
Batch 39/64 loss: 4.577999114990234
Batch 40/64 loss: 4.58981990814209
Batch 41/64 loss: 4.610294342041016
Batch 42/64 loss: 4.558470726013184
Batch 43/64 loss: 4.543940544128418
Batch 44/64 loss: 4.565888404846191
Batch 45/64 loss: 4.564682483673096
Batch 46/64 loss: 4.555166244506836
Batch 47/64 loss: 4.578455448150635
Batch 48/64 loss: 4.576533794403076
Batch 49/64 loss: 4.597440719604492
Batch 50/64 loss: 4.57246732711792
Batch 51/64 loss: 4.58353328704834
Batch 52/64 loss: 4.563671588897705
Batch 53/64 loss: 4.557919979095459
Batch 54/64 loss: 4.5631256103515625
Batch 55/64 loss: 4.6038970947265625
Batch 56/64 loss: 4.591536045074463
Batch 57/64 loss: 4.564305305480957
Batch 58/64 loss: 4.578936576843262
Batch 59/64 loss: 4.686459064483643
Batch 60/64 loss: 4.573034286499023
Batch 61/64 loss: 4.606548309326172
Batch 62/64 loss: 4.613485813140869
Batch 63/64 loss: 4.569911003112793
Batch 64/64 loss: 3.7142648696899414
Epoch 19  Train loss: 4.5770271937052405  Val loss: 4.562823661209381
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 4.59575891494751
Batch 2/64 loss: 4.573216438293457
Batch 3/64 loss: 4.580231666564941
Batch 4/64 loss: 4.600227355957031
Batch 5/64 loss: 4.603014945983887
Batch 6/64 loss: 4.585724353790283
Batch 7/64 loss: 4.5895891189575195
Batch 8/64 loss: 4.582153797149658
Batch 9/64 loss: 4.583306312561035
Batch 10/64 loss: 4.580404758453369
Batch 11/64 loss: 4.607244968414307
Batch 12/64 loss: 4.592637062072754
Batch 13/64 loss: 4.59192419052124
Batch 14/64 loss: 4.599923610687256
Batch 15/64 loss: 4.573840618133545
Batch 16/64 loss: 4.580183029174805
Batch 17/64 loss: 4.575112342834473
Batch 18/64 loss: 4.569767475128174
Batch 19/64 loss: 4.574421405792236
Batch 20/64 loss: 4.568636894226074
Batch 21/64 loss: 4.573826789855957
Batch 22/64 loss: 4.608581066131592
Batch 23/64 loss: 4.579554557800293
Batch 24/64 loss: 4.571083068847656
Batch 25/64 loss: 4.565931797027588
Batch 26/64 loss: 4.5778350830078125
Batch 27/64 loss: 4.57241678237915
Batch 28/64 loss: 4.562110424041748
Batch 29/64 loss: 4.5958123207092285
Batch 30/64 loss: 4.583646774291992
Batch 31/64 loss: 4.588644981384277
Batch 32/64 loss: 4.571107387542725
Batch 33/64 loss: 4.573611736297607
Batch 34/64 loss: 4.580639839172363
Batch 35/64 loss: 4.607624530792236
Batch 36/64 loss: 4.580993175506592
Batch 37/64 loss: 4.588576316833496
Batch 38/64 loss: 4.5858564376831055
Batch 39/64 loss: 4.59199857711792
Batch 40/64 loss: 4.592611789703369
Batch 41/64 loss: 4.563364028930664
Batch 42/64 loss: 4.571171760559082
Batch 43/64 loss: 4.590214729309082
Batch 44/64 loss: 4.5772199630737305
Batch 45/64 loss: 4.565295219421387
Batch 46/64 loss: 4.560694217681885
Batch 47/64 loss: 4.560800075531006
Batch 48/64 loss: 4.582355499267578
Batch 49/64 loss: 4.569980144500732
Batch 50/64 loss: 4.570738792419434
Batch 51/64 loss: 4.570474147796631
Batch 52/64 loss: 4.576910018920898
Batch 53/64 loss: 4.567606449127197
Batch 54/64 loss: 4.588334083557129
Batch 55/64 loss: 4.545456409454346
Batch 56/64 loss: 4.572137832641602
Batch 57/64 loss: 4.6288580894470215
Batch 58/64 loss: 4.57820987701416
Batch 59/64 loss: 4.592733860015869
Batch 60/64 loss: 4.572388172149658
Batch 61/64 loss: 4.580499649047852
Batch 62/64 loss: 4.567677021026611
Batch 63/64 loss: 4.594335556030273
Batch 64/64 loss: 3.7260794639587402
Epoch 20  Train loss: 4.571008594363343  Val loss: 4.552963982537849
Saving best model, epoch: 20
Epoch 21
-------------------------------
Batch 1/64 loss: 4.5568060874938965
Batch 2/64 loss: 4.583003997802734
Batch 3/64 loss: 4.590618133544922
Batch 4/64 loss: 4.565005302429199
Batch 5/64 loss: 4.554864406585693
Batch 6/64 loss: 4.559551239013672
Batch 7/64 loss: 4.572410583496094
Batch 8/64 loss: 4.567132949829102
Batch 9/64 loss: 4.569092750549316
Batch 10/64 loss: 4.551828861236572
Batch 11/64 loss: 4.579593181610107
Batch 12/64 loss: 4.550728797912598
Batch 13/64 loss: 4.543313980102539
Batch 14/64 loss: 4.571675777435303
Batch 15/64 loss: 4.566810607910156
Batch 16/64 loss: 4.547848224639893
Batch 17/64 loss: 4.564976215362549
Batch 18/64 loss: 4.5491108894348145
Batch 19/64 loss: 4.561100482940674
Batch 20/64 loss: 4.564820289611816
Batch 21/64 loss: 4.563500881195068
Batch 22/64 loss: 4.546926975250244
Batch 23/64 loss: 4.544876575469971
Batch 24/64 loss: 4.572260856628418
Batch 25/64 loss: 4.567038059234619
Batch 26/64 loss: 4.570531368255615
Batch 27/64 loss: 4.637988567352295
Batch 28/64 loss: 4.605447769165039
Batch 29/64 loss: 4.579998016357422
Batch 30/64 loss: 4.559294700622559
Batch 31/64 loss: 4.584468841552734
Batch 32/64 loss: 4.59113073348999
Batch 33/64 loss: 4.581121444702148
Batch 34/64 loss: 4.59409761428833
Batch 35/64 loss: 4.574462413787842
Batch 36/64 loss: 4.566032409667969
Batch 37/64 loss: 4.578744888305664
Batch 38/64 loss: 4.567398548126221
Batch 39/64 loss: 4.575231552124023
Batch 40/64 loss: 4.565071105957031
Batch 41/64 loss: 4.560643196105957
Batch 42/64 loss: 4.560647964477539
Batch 43/64 loss: 4.553905963897705
Batch 44/64 loss: 4.57912015914917
Batch 45/64 loss: 4.550192832946777
Batch 46/64 loss: 4.593092918395996
Batch 47/64 loss: 4.541861534118652
Batch 48/64 loss: 4.542776107788086
Batch 49/64 loss: 4.559506416320801
Batch 50/64 loss: 4.597754001617432
Batch 51/64 loss: 4.54705810546875
Batch 52/64 loss: 4.553986549377441
Batch 53/64 loss: 4.566644191741943
Batch 54/64 loss: 4.60274600982666
Batch 55/64 loss: 4.59559440612793
Batch 56/64 loss: 4.550149440765381
Batch 57/64 loss: 4.583645343780518
Batch 58/64 loss: 4.547589302062988
Batch 59/64 loss: 4.552040100097656
Batch 60/64 loss: 4.5679168701171875
Batch 61/64 loss: 4.555664539337158
Batch 62/64 loss: 4.598204612731934
Batch 63/64 loss: 4.546996593475342
Batch 64/64 loss: 3.680041551589966
Epoch 21  Train loss: 4.55786171613955  Val loss: 4.540758806815262
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 4.53582239151001
Batch 2/64 loss: 4.552300453186035
Batch 3/64 loss: 4.544668197631836
Batch 4/64 loss: 4.542943000793457
Batch 5/64 loss: 4.551225662231445
Batch 6/64 loss: 4.56557035446167
Batch 7/64 loss: 4.549792766571045
Batch 8/64 loss: 4.536460876464844
Batch 9/64 loss: 4.539046287536621
Batch 10/64 loss: 4.574881076812744
Batch 11/64 loss: 4.593329906463623
Batch 12/64 loss: 4.556550979614258
Batch 13/64 loss: 4.5460968017578125
Batch 14/64 loss: 4.5516533851623535
Batch 15/64 loss: 4.543150901794434
Batch 16/64 loss: 4.569720268249512
Batch 17/64 loss: 4.574405193328857
Batch 18/64 loss: 4.540993690490723
Batch 19/64 loss: 4.544662952423096
Batch 20/64 loss: 4.53306245803833
Batch 21/64 loss: 4.557059288024902
Batch 22/64 loss: 4.5399980545043945
Batch 23/64 loss: 4.552789688110352
Batch 24/64 loss: 4.517116546630859
Batch 25/64 loss: 4.539990425109863
Batch 26/64 loss: 4.54265832901001
Batch 27/64 loss: 4.578346252441406
Batch 28/64 loss: 4.581759452819824
Batch 29/64 loss: 4.508465766906738
Batch 30/64 loss: 4.522324562072754
Batch 31/64 loss: 4.557983875274658
Batch 32/64 loss: 4.548696994781494
Batch 33/64 loss: 4.543328762054443
Batch 34/64 loss: 4.542550086975098
Batch 35/64 loss: 4.555135250091553
Batch 36/64 loss: 4.548775672912598
Batch 37/64 loss: 4.5889387130737305
Batch 38/64 loss: 4.543548583984375
Batch 39/64 loss: 4.577158451080322
Batch 40/64 loss: 4.548169136047363
Batch 41/64 loss: 4.575037002563477
Batch 42/64 loss: 4.569155216217041
Batch 43/64 loss: 4.594729423522949
Batch 44/64 loss: 4.544963359832764
Batch 45/64 loss: 4.570446968078613
Batch 46/64 loss: 4.565526008605957
Batch 47/64 loss: 4.545339107513428
Batch 48/64 loss: 4.552242279052734
Batch 49/64 loss: 4.534672260284424
Batch 50/64 loss: 4.550833225250244
Batch 51/64 loss: 4.554869651794434
Batch 52/64 loss: 4.552815914154053
Batch 53/64 loss: 4.535449504852295
Batch 54/64 loss: 4.572680473327637
Batch 55/64 loss: 4.534843921661377
Batch 56/64 loss: 4.515334129333496
Batch 57/64 loss: 4.550291061401367
Batch 58/64 loss: 4.562144756317139
Batch 59/64 loss: 4.573872089385986
Batch 60/64 loss: 4.545821666717529
Batch 61/64 loss: 4.530917644500732
Batch 62/64 loss: 4.5188398361206055
Batch 63/64 loss: 4.545682430267334
Batch 64/64 loss: 3.640742063522339
Epoch 22  Train loss: 4.540677583918852  Val loss: 4.528039516861906
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: 4.542500972747803
Batch 2/64 loss: 4.575868129730225
Batch 3/64 loss: 4.530145645141602
Batch 4/64 loss: 4.530817985534668
Batch 5/64 loss: 4.5142412185668945
Batch 6/64 loss: 4.537543296813965
Batch 7/64 loss: 4.554993629455566
Batch 8/64 loss: 4.516741752624512
Batch 9/64 loss: 4.517658233642578
Batch 10/64 loss: 4.539215564727783
Batch 11/64 loss: 4.52520751953125
Batch 12/64 loss: 4.522843360900879
Batch 13/64 loss: 4.5450005531311035
Batch 14/64 loss: 4.537517547607422
Batch 15/64 loss: 4.497591495513916
Batch 16/64 loss: 4.527832508087158
Batch 17/64 loss: 4.5365424156188965
Batch 18/64 loss: 4.511839866638184
Batch 19/64 loss: 4.502560615539551
Batch 20/64 loss: 4.532998085021973
Batch 21/64 loss: 4.555609226226807
Batch 22/64 loss: 4.583872318267822
Batch 23/64 loss: 4.541142463684082
Batch 24/64 loss: 4.517391204833984
Batch 25/64 loss: 4.542492389678955
Batch 26/64 loss: 4.496492385864258
Batch 27/64 loss: 4.540287494659424
Batch 28/64 loss: 4.5476555824279785
Batch 29/64 loss: 4.534918308258057
Batch 30/64 loss: 4.558262348175049
Batch 31/64 loss: 4.543709754943848
Batch 32/64 loss: 4.50868034362793
Batch 33/64 loss: 4.5621256828308105
Batch 34/64 loss: 4.52114200592041
Batch 35/64 loss: 4.518901348114014
Batch 36/64 loss: 4.521203994750977
Batch 37/64 loss: 4.5493879318237305
Batch 38/64 loss: 4.5636420249938965
Batch 39/64 loss: 4.518590927124023
Batch 40/64 loss: 4.518269062042236
Batch 41/64 loss: 4.506206512451172
Batch 42/64 loss: 4.550361156463623
Batch 43/64 loss: 4.55285120010376
Batch 44/64 loss: 4.511989116668701
Batch 45/64 loss: 4.519484996795654
Batch 46/64 loss: 4.546877384185791
Batch 47/64 loss: 4.558025360107422
Batch 48/64 loss: 4.572831153869629
Batch 49/64 loss: 4.551388263702393
Batch 50/64 loss: 4.5086493492126465
Batch 51/64 loss: 4.546479225158691
Batch 52/64 loss: 4.53645133972168
Batch 53/64 loss: 4.521117210388184
Batch 54/64 loss: 4.53018045425415
Batch 55/64 loss: 4.535046577453613
Batch 56/64 loss: 4.532057762145996
Batch 57/64 loss: 4.504651069641113
Batch 58/64 loss: 4.504573345184326
Batch 59/64 loss: 4.545391082763672
Batch 60/64 loss: 4.529520511627197
Batch 61/64 loss: 4.543476581573486
Batch 62/64 loss: 4.5589518547058105
Batch 63/64 loss: 4.538849353790283
Batch 64/64 loss: 3.598881483078003
Epoch 23  Train loss: 4.5231060261819875  Val loss: 4.539723018600359
Epoch 24
-------------------------------
Batch 1/64 loss: 4.582782745361328
Batch 2/64 loss: 4.5120110511779785
Batch 3/64 loss: 4.497706890106201
Batch 4/64 loss: 4.566253185272217
Batch 5/64 loss: 4.538212776184082
Batch 6/64 loss: 4.525901794433594
Batch 7/64 loss: 4.5562744140625
Batch 8/64 loss: 4.518149375915527
Batch 9/64 loss: 4.52372932434082
Batch 10/64 loss: 4.499624729156494
Batch 11/64 loss: 4.528121471405029
Batch 12/64 loss: 4.516143321990967
Batch 13/64 loss: 4.496294021606445
Batch 14/64 loss: 4.52462100982666
Batch 15/64 loss: 4.498122692108154
Batch 16/64 loss: 4.558489799499512
Batch 17/64 loss: 4.527231216430664
Batch 18/64 loss: 4.509057521820068
Batch 19/64 loss: 4.48862361907959
Batch 20/64 loss: 4.498105049133301
Batch 21/64 loss: 4.513918876647949
Batch 22/64 loss: 4.532108306884766
Batch 23/64 loss: 4.539676189422607
Batch 24/64 loss: 4.496837139129639
Batch 25/64 loss: 4.530665397644043
Batch 26/64 loss: 4.523619174957275
Batch 27/64 loss: 4.495792865753174
Batch 28/64 loss: 4.5003509521484375
Batch 29/64 loss: 4.521539688110352
Batch 30/64 loss: 4.501584053039551
Batch 31/64 loss: 4.50704288482666
Batch 32/64 loss: 4.503922462463379
Batch 33/64 loss: 4.4854841232299805
Batch 34/64 loss: 4.536534309387207
Batch 35/64 loss: 4.5331292152404785
Batch 36/64 loss: 4.504373550415039
Batch 37/64 loss: 4.5164337158203125
Batch 38/64 loss: 4.530460357666016
Batch 39/64 loss: 4.496171951293945
Batch 40/64 loss: 4.507652759552002
Batch 41/64 loss: 4.4982757568359375
Batch 42/64 loss: 4.497652530670166
Batch 43/64 loss: 4.495168209075928
Batch 44/64 loss: 4.5344061851501465
Batch 45/64 loss: 4.490368843078613
Batch 46/64 loss: 4.4914703369140625
Batch 47/64 loss: 4.529827117919922
Batch 48/64 loss: 4.525240421295166
Batch 49/64 loss: 4.518093585968018
Batch 50/64 loss: 4.517280578613281
Batch 51/64 loss: 4.490517616271973
Batch 52/64 loss: 4.490170478820801
Batch 53/64 loss: 4.506234645843506
Batch 54/64 loss: 4.505334377288818
Batch 55/64 loss: 4.53071403503418
Batch 56/64 loss: 4.498894691467285
Batch 57/64 loss: 4.570903778076172
Batch 58/64 loss: 4.469946384429932
Batch 59/64 loss: 4.527913570404053
Batch 60/64 loss: 4.516240119934082
Batch 61/64 loss: 4.548017501831055
Batch 62/64 loss: 4.496537685394287
Batch 63/64 loss: 4.494607925415039
Batch 64/64 loss: 3.5721607208251953
Epoch 24  Train loss: 4.504559857237573  Val loss: 4.503332040154238
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 4.497618198394775
Batch 2/64 loss: 4.504745960235596
Batch 3/64 loss: 4.505899429321289
Batch 4/64 loss: 4.576771259307861
Batch 5/64 loss: 4.531220436096191
Batch 6/64 loss: 4.488491535186768
Batch 7/64 loss: 4.521145820617676
Batch 8/64 loss: 4.553701400756836
Batch 9/64 loss: 4.470731735229492
Batch 10/64 loss: 4.481658458709717
Batch 11/64 loss: 4.518944263458252
Batch 12/64 loss: 4.516462802886963
Batch 13/64 loss: 4.533327579498291
Batch 14/64 loss: 4.489773273468018
Batch 15/64 loss: 4.5196075439453125
Batch 16/64 loss: 4.473624229431152
Batch 17/64 loss: 4.476124286651611
Batch 18/64 loss: 4.47360897064209
Batch 19/64 loss: 4.519042015075684
Batch 20/64 loss: 4.4915876388549805
Batch 21/64 loss: 4.546512126922607
Batch 22/64 loss: 4.475879192352295
Batch 23/64 loss: 4.530384063720703
Batch 24/64 loss: 4.505314826965332
Batch 25/64 loss: 4.520059108734131
Batch 26/64 loss: 4.51882266998291
Batch 27/64 loss: 4.516767978668213
Batch 28/64 loss: 4.4794440269470215
Batch 29/64 loss: 4.5359296798706055
Batch 30/64 loss: 4.492217540740967
Batch 31/64 loss: 4.4907660484313965
Batch 32/64 loss: 4.509582996368408
Batch 33/64 loss: 4.515386581420898
Batch 34/64 loss: 4.492833137512207
Batch 35/64 loss: 4.498415470123291
Batch 36/64 loss: 4.487796783447266
Batch 37/64 loss: 4.4899468421936035
Batch 38/64 loss: 4.50693941116333
Batch 39/64 loss: 4.529630184173584
Batch 40/64 loss: 4.551462650299072
Batch 41/64 loss: 4.491857051849365
Batch 42/64 loss: 4.448660373687744
Batch 43/64 loss: 4.495054244995117
Batch 44/64 loss: 4.484267711639404
Batch 45/64 loss: 4.488752841949463
Batch 46/64 loss: 4.481734752655029
Batch 47/64 loss: 4.506560325622559
Batch 48/64 loss: 4.527738094329834
Batch 49/64 loss: 4.497731685638428
Batch 50/64 loss: 4.443622589111328
Batch 51/64 loss: 4.4696149826049805
Batch 52/64 loss: 4.477272987365723
Batch 53/64 loss: 4.502540588378906
Batch 54/64 loss: 4.448367595672607
Batch 55/64 loss: 4.481869220733643
Batch 56/64 loss: 4.530108451843262
Batch 57/64 loss: 4.4930419921875
Batch 58/64 loss: 4.496711730957031
Batch 59/64 loss: 4.479923248291016
Batch 60/64 loss: 4.503403663635254
Batch 61/64 loss: 4.478697299957275
Batch 62/64 loss: 4.447852611541748
Batch 63/64 loss: 4.469789981842041
Batch 64/64 loss: 3.465400457382202
Epoch 25  Train loss: 4.487567098467958  Val loss: 4.460371549186838
Saving best model, epoch: 25
Epoch 26
-------------------------------
Batch 1/64 loss: 4.475556373596191
Batch 2/64 loss: 4.471831798553467
Batch 3/64 loss: 4.461956024169922
Batch 4/64 loss: 4.528803825378418
Batch 5/64 loss: 4.488601207733154
Batch 6/64 loss: 4.452877521514893
Batch 7/64 loss: 4.478837013244629
Batch 8/64 loss: 4.470053195953369
Batch 9/64 loss: 4.455560684204102
Batch 10/64 loss: 4.566705703735352
Batch 11/64 loss: 4.446936130523682
Batch 12/64 loss: 4.464651107788086
Batch 13/64 loss: 4.472900390625
Batch 14/64 loss: 4.482369899749756
Batch 15/64 loss: 4.446226119995117
Batch 16/64 loss: 4.483214378356934
Batch 17/64 loss: 4.4784650802612305
Batch 18/64 loss: 4.461999893188477
Batch 19/64 loss: 4.515928268432617
Batch 20/64 loss: 4.4362311363220215
Batch 21/64 loss: 4.474690914154053
Batch 22/64 loss: 4.515896797180176
Batch 23/64 loss: 4.453498840332031
Batch 24/64 loss: 4.459958076477051
Batch 25/64 loss: 4.4506354331970215
Batch 26/64 loss: 4.449244022369385
Batch 27/64 loss: 4.497429847717285
Batch 28/64 loss: 4.437958717346191
Batch 29/64 loss: 4.489717960357666
Batch 30/64 loss: 4.45841646194458
Batch 31/64 loss: 4.466255187988281
Batch 32/64 loss: 4.447420120239258
Batch 33/64 loss: 4.460865020751953
Batch 34/64 loss: 4.519873142242432
Batch 35/64 loss: 4.488046169281006
Batch 36/64 loss: 4.427536964416504
Batch 37/64 loss: 4.449393272399902
Batch 38/64 loss: 4.4854254722595215
Batch 39/64 loss: 4.437237739562988
Batch 40/64 loss: 4.469781875610352
Batch 41/64 loss: 4.463374614715576
Batch 42/64 loss: 4.491793632507324
Batch 43/64 loss: 4.438407897949219
Batch 44/64 loss: 4.467564582824707
Batch 45/64 loss: 4.465729236602783
Batch 46/64 loss: 4.438915252685547
Batch 47/64 loss: 4.4310431480407715
Batch 48/64 loss: 4.465130805969238
Batch 49/64 loss: 4.437077522277832
Batch 50/64 loss: 4.501410484313965
Batch 51/64 loss: 4.49647331237793
Batch 52/64 loss: 4.474910736083984
Batch 53/64 loss: 4.456185817718506
Batch 54/64 loss: 4.494762897491455
Batch 55/64 loss: 4.508869171142578
Batch 56/64 loss: 4.471322536468506
Batch 57/64 loss: 4.482466220855713
Batch 58/64 loss: 4.456732273101807
Batch 59/64 loss: 4.440855503082275
Batch 60/64 loss: 4.5101423263549805
Batch 61/64 loss: 4.485069274902344
Batch 62/64 loss: 4.475346565246582
Batch 63/64 loss: 4.462985038757324
Batch 64/64 loss: 3.464431047439575
Epoch 26  Train loss: 4.4595118419796815  Val loss: 4.4501824936096614
Saving best model, epoch: 26
Epoch 27
-------------------------------
Batch 1/64 loss: 4.456995487213135
Batch 2/64 loss: 4.462812423706055
Batch 3/64 loss: 4.440265655517578
Batch 4/64 loss: 4.451565265655518
Batch 5/64 loss: 4.617082118988037
Batch 6/64 loss: 4.511047840118408
Batch 7/64 loss: 4.403918266296387
Batch 8/64 loss: 4.474267482757568
Batch 9/64 loss: 4.488222599029541
Batch 10/64 loss: 4.452961444854736
Batch 11/64 loss: 4.481769561767578
Batch 12/64 loss: 4.4638166427612305
Batch 13/64 loss: 4.5387678146362305
Batch 14/64 loss: 4.420541286468506
Batch 15/64 loss: 4.4583282470703125
Batch 16/64 loss: 4.455539226531982
Batch 17/64 loss: 4.483624458312988
Batch 18/64 loss: 4.46721076965332
Batch 19/64 loss: 4.547964572906494
Batch 20/64 loss: 4.489012241363525
Batch 21/64 loss: 4.451971054077148
Batch 22/64 loss: 4.4822163581848145
Batch 23/64 loss: 4.488304138183594
Batch 24/64 loss: 4.451558589935303
Batch 25/64 loss: 4.434894561767578
Batch 26/64 loss: 4.480373859405518
Batch 27/64 loss: 4.475430965423584
Batch 28/64 loss: 4.449173927307129
Batch 29/64 loss: 4.457910537719727
Batch 30/64 loss: 4.419938564300537
Batch 31/64 loss: 4.456238746643066
Batch 32/64 loss: 4.48246431350708
Batch 33/64 loss: 4.4804229736328125
Batch 34/64 loss: 4.429420471191406
Batch 35/64 loss: 4.445810317993164
Batch 36/64 loss: 4.498204231262207
Batch 37/64 loss: 4.4451775550842285
Batch 38/64 loss: 4.489133358001709
Batch 39/64 loss: 4.440576553344727
Batch 40/64 loss: 4.487335205078125
Batch 41/64 loss: 4.478992462158203
Batch 42/64 loss: 4.437881946563721
Batch 43/64 loss: 4.453330993652344
Batch 44/64 loss: 4.454568862915039
Batch 45/64 loss: 4.447347164154053
Batch 46/64 loss: 4.421650409698486
Batch 47/64 loss: 4.460855960845947
Batch 48/64 loss: 4.47281551361084
Batch 49/64 loss: 4.510793685913086
Batch 50/64 loss: 4.438976287841797
Batch 51/64 loss: 4.435247421264648
Batch 52/64 loss: 4.493459701538086
Batch 53/64 loss: 4.480612277984619
Batch 54/64 loss: 4.441952228546143
Batch 55/64 loss: 4.480741024017334
Batch 56/64 loss: 4.458119869232178
Batch 57/64 loss: 4.396264553070068
Batch 58/64 loss: 4.441336154937744
Batch 59/64 loss: 4.467216491699219
Batch 60/64 loss: 4.438392639160156
Batch 61/64 loss: 4.425846099853516
Batch 62/64 loss: 4.465681552886963
Batch 63/64 loss: 4.452447891235352
Batch 64/64 loss: 3.3367133140563965
Epoch 27  Train loss: 4.451283699858422  Val loss: 4.439763176482158
Saving best model, epoch: 27
Epoch 28
-------------------------------
Batch 1/64 loss: 4.39908504486084
Batch 2/64 loss: 4.403615474700928
Batch 3/64 loss: 4.430928707122803
Batch 4/64 loss: 4.497220993041992
Batch 5/64 loss: 4.427726745605469
Batch 6/64 loss: 4.49785041809082
Batch 7/64 loss: 4.442793369293213
Batch 8/64 loss: 4.4152913093566895
Batch 9/64 loss: 4.454971790313721
Batch 10/64 loss: 4.432116985321045
Batch 11/64 loss: 4.456995964050293
Batch 12/64 loss: 4.39907169342041
Batch 13/64 loss: 4.421512603759766
Batch 14/64 loss: 4.460635185241699
Batch 15/64 loss: 4.416054725646973
Batch 16/64 loss: 4.448014259338379
Batch 17/64 loss: 4.44796085357666
Batch 18/64 loss: 4.403491973876953
Batch 19/64 loss: 4.427883148193359
Batch 20/64 loss: 4.430243492126465
Batch 21/64 loss: 4.45594596862793
Batch 22/64 loss: 4.430159091949463
Batch 23/64 loss: 4.468709945678711
Batch 24/64 loss: 4.421995639801025
Batch 25/64 loss: 4.3802571296691895
Batch 26/64 loss: 4.440404891967773
Batch 27/64 loss: 4.416725158691406
Batch 28/64 loss: 4.467518329620361
Batch 29/64 loss: 4.465540885925293
Batch 30/64 loss: 4.4282379150390625
Batch 31/64 loss: 4.4683074951171875
Batch 32/64 loss: 4.419579982757568
Batch 33/64 loss: 4.439786434173584
Batch 34/64 loss: 4.405710697174072
Batch 35/64 loss: 4.443751811981201
Batch 36/64 loss: 4.412448406219482
Batch 37/64 loss: 4.452733516693115
Batch 38/64 loss: 4.432384967803955
Batch 39/64 loss: 4.480228424072266
Batch 40/64 loss: 4.438020706176758
Batch 41/64 loss: 4.416892051696777
Batch 42/64 loss: 4.423915863037109
Batch 43/64 loss: 4.446595191955566
Batch 44/64 loss: 4.418175220489502
Batch 45/64 loss: 4.454646110534668
Batch 46/64 loss: 4.3514790534973145
Batch 47/64 loss: 4.408215045928955
Batch 48/64 loss: 4.4611430168151855
Batch 49/64 loss: 4.399734973907471
Batch 50/64 loss: 4.397229194641113
Batch 51/64 loss: 4.416296482086182
Batch 52/64 loss: 4.445404052734375
Batch 53/64 loss: 4.3857011795043945
Batch 54/64 loss: 4.464278221130371
Batch 55/64 loss: 4.424862384796143
Batch 56/64 loss: 4.429839134216309
Batch 57/64 loss: 4.437505722045898
Batch 58/64 loss: 4.442358493804932
Batch 59/64 loss: 4.429195404052734
Batch 60/64 loss: 4.432237148284912
Batch 61/64 loss: 4.397452354431152
Batch 62/64 loss: 4.430709362030029
Batch 63/64 loss: 4.38544225692749
Batch 64/64 loss: 3.323075771331787
Epoch 28  Train loss: 4.418408264833338  Val loss: 4.390255801866145
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: 4.4198832511901855
Batch 2/64 loss: 4.395967483520508
Batch 3/64 loss: 4.371479511260986
Batch 4/64 loss: 4.467639446258545
Batch 5/64 loss: 4.4456868171691895
Batch 6/64 loss: 4.445699691772461
Batch 7/64 loss: 4.446157455444336
Batch 8/64 loss: 4.436326503753662
Batch 9/64 loss: 4.387266159057617
Batch 10/64 loss: 4.397274971008301
Batch 11/64 loss: 4.376468658447266
Batch 12/64 loss: 4.446538925170898
Batch 13/64 loss: 4.4158935546875
Batch 14/64 loss: 4.47586727142334
Batch 15/64 loss: 4.4264936447143555
Batch 16/64 loss: 4.427175521850586
Batch 17/64 loss: 4.369479179382324
Batch 18/64 loss: 4.422207832336426
Batch 19/64 loss: 4.404978275299072
Batch 20/64 loss: 4.4433465003967285
Batch 21/64 loss: 4.456131935119629
Batch 22/64 loss: 4.417760848999023
Batch 23/64 loss: 4.448646068572998
Batch 24/64 loss: 4.4119133949279785
Batch 25/64 loss: 4.430487632751465
Batch 26/64 loss: 4.389493465423584
Batch 27/64 loss: 4.442860126495361
Batch 28/64 loss: 4.413791656494141
Batch 29/64 loss: 4.433544635772705
Batch 30/64 loss: 4.44287633895874
Batch 31/64 loss: 4.427911281585693
Batch 32/64 loss: 4.393924236297607
Batch 33/64 loss: 4.400222301483154
Batch 34/64 loss: 4.37653923034668
Batch 35/64 loss: 4.3691229820251465
Batch 36/64 loss: 4.426414966583252
Batch 37/64 loss: 4.351328372955322
Batch 38/64 loss: 4.373249053955078
Batch 39/64 loss: 4.458971977233887
Batch 40/64 loss: 4.457984447479248
Batch 41/64 loss: 4.406511306762695
Batch 42/64 loss: 4.358968257904053
Batch 43/64 loss: 4.371504306793213
Batch 44/64 loss: 4.4081268310546875
Batch 45/64 loss: 4.388723850250244
Batch 46/64 loss: 4.389895439147949
Batch 47/64 loss: 4.37294864654541
Batch 48/64 loss: 4.340580463409424
Batch 49/64 loss: 4.408987998962402
Batch 50/64 loss: 4.410338401794434
Batch 51/64 loss: 4.351173400878906
Batch 52/64 loss: 4.370462417602539
Batch 53/64 loss: 4.372217178344727
Batch 54/64 loss: 4.370911598205566
Batch 55/64 loss: 4.330663204193115
Batch 56/64 loss: 4.514333724975586
Batch 57/64 loss: 4.420159339904785
Batch 58/64 loss: 4.394057750701904
Batch 59/64 loss: 4.4087748527526855
Batch 60/64 loss: 4.38092041015625
Batch 61/64 loss: 4.370760440826416
Batch 62/64 loss: 4.3495330810546875
Batch 63/64 loss: 4.384747505187988
Batch 64/64 loss: 3.3769052028656006
Epoch 29  Train loss: 4.39455662615159  Val loss: 4.393001023846393
Epoch 30
-------------------------------
Batch 1/64 loss: 4.435635089874268
Batch 2/64 loss: 4.38680362701416
Batch 3/64 loss: 4.327054023742676
Batch 4/64 loss: 4.404641151428223
Batch 5/64 loss: 4.3456807136535645
Batch 6/64 loss: 4.407142162322998
Batch 7/64 loss: 4.367602825164795
Batch 8/64 loss: 4.394329071044922
Batch 9/64 loss: 4.368129253387451
Batch 10/64 loss: 4.424134254455566
Batch 11/64 loss: 4.39557409286499
Batch 12/64 loss: 4.454730987548828
Batch 13/64 loss: 4.42869758605957
Batch 14/64 loss: 4.412010669708252
Batch 15/64 loss: 4.404196739196777
Batch 16/64 loss: 4.408787727355957
Batch 17/64 loss: 4.416402816772461
Batch 18/64 loss: 4.41699743270874
Batch 19/64 loss: 4.420238494873047
Batch 20/64 loss: 4.340347766876221
Batch 21/64 loss: 4.405434608459473
Batch 22/64 loss: 4.374256134033203
Batch 23/64 loss: 4.352422714233398
Batch 24/64 loss: 4.353029251098633
Batch 25/64 loss: 4.361865520477295
Batch 26/64 loss: 4.357213973999023
Batch 27/64 loss: 4.37113094329834
Batch 28/64 loss: 4.39130163192749
Batch 29/64 loss: 4.384311676025391
Batch 30/64 loss: 4.425743579864502
Batch 31/64 loss: 4.41530704498291
Batch 32/64 loss: 4.379839897155762
Batch 33/64 loss: 4.354518890380859
Batch 34/64 loss: 4.377312660217285
Batch 35/64 loss: 4.332708835601807
Batch 36/64 loss: 4.3970947265625
Batch 37/64 loss: 4.357447624206543
Batch 38/64 loss: 4.355998516082764
Batch 39/64 loss: 4.4730305671691895
Batch 40/64 loss: 4.391092777252197
Batch 41/64 loss: 4.406734943389893
Batch 42/64 loss: 4.389867782592773
Batch 43/64 loss: 4.359167575836182
Batch 44/64 loss: 4.427537441253662
Batch 45/64 loss: 4.419013023376465
Batch 46/64 loss: 4.374705791473389
Batch 47/64 loss: 4.362960338592529
Batch 48/64 loss: 4.428729057312012
Batch 49/64 loss: 4.408215045928955
Batch 50/64 loss: 4.424890041351318
Batch 51/64 loss: 4.397703170776367
Batch 52/64 loss: 4.397432327270508
Batch 53/64 loss: 4.373824596405029
Batch 54/64 loss: 4.428513050079346
Batch 55/64 loss: 4.339563369750977
Batch 56/64 loss: 4.3452630043029785
Batch 57/64 loss: 4.405196189880371
Batch 58/64 loss: 4.416490077972412
Batch 59/64 loss: 4.401915550231934
Batch 60/64 loss: 4.381376266479492
Batch 61/64 loss: 4.337937355041504
Batch 62/64 loss: 4.493993282318115
Batch 63/64 loss: 4.428028106689453
Batch 64/64 loss: 3.2769274711608887
Epoch 30  Train loss: 4.379246290992288  Val loss: 4.46010837276367
Epoch 31
-------------------------------
Batch 1/64 loss: 4.458395957946777
Batch 2/64 loss: 4.497373104095459
Batch 3/64 loss: 4.444925308227539
Batch 4/64 loss: 4.3953857421875
Batch 5/64 loss: 4.5098347663879395
Batch 6/64 loss: 4.430333137512207
Batch 7/64 loss: 4.453277111053467
Batch 8/64 loss: 4.355508804321289
Batch 9/64 loss: 4.4819841384887695
Batch 10/64 loss: 4.386113166809082
Batch 11/64 loss: 4.409426689147949
Batch 12/64 loss: 4.376110553741455
Batch 13/64 loss: 4.430713653564453
Batch 14/64 loss: 4.3619771003723145
Batch 15/64 loss: 4.423793315887451
Batch 16/64 loss: 4.461665153503418
Batch 17/64 loss: 4.417029857635498
Batch 18/64 loss: 4.32358980178833
Batch 19/64 loss: 4.431402683258057
Batch 20/64 loss: 4.4141387939453125
Batch 21/64 loss: 4.357949256896973
Batch 22/64 loss: 4.355311870574951
Batch 23/64 loss: 4.419322967529297
Batch 24/64 loss: 4.395693302154541
Batch 25/64 loss: 4.387959003448486
Batch 26/64 loss: 4.377645492553711
Batch 27/64 loss: 4.339447021484375
Batch 28/64 loss: 4.340838432312012
Batch 29/64 loss: 4.401750564575195
Batch 30/64 loss: 4.349862098693848
Batch 31/64 loss: 4.335930824279785
Batch 32/64 loss: 4.3650407791137695
Batch 33/64 loss: 4.3390212059021
Batch 34/64 loss: 4.309259414672852
Batch 35/64 loss: 4.306028366088867
Batch 36/64 loss: 4.386002540588379
Batch 37/64 loss: 4.367799758911133
Batch 38/64 loss: 4.291422367095947
Batch 39/64 loss: 4.339656829833984
Batch 40/64 loss: 4.376810073852539
Batch 41/64 loss: 4.314578533172607
Batch 42/64 loss: 4.381865501403809
Batch 43/64 loss: 4.335357666015625
Batch 44/64 loss: 4.391989231109619
Batch 45/64 loss: 4.351839065551758
Batch 46/64 loss: 4.378793716430664
Batch 47/64 loss: 4.352364540100098
Batch 48/64 loss: 4.296673774719238
Batch 49/64 loss: 4.376377582550049
Batch 50/64 loss: 4.329968452453613
Batch 51/64 loss: 4.287197113037109
Batch 52/64 loss: 4.297366142272949
Batch 53/64 loss: 4.310627460479736
Batch 54/64 loss: 4.313607215881348
Batch 55/64 loss: 4.328151702880859
Batch 56/64 loss: 4.436165809631348
Batch 57/64 loss: 4.315284729003906
Batch 58/64 loss: 4.285336017608643
Batch 59/64 loss: 4.309173583984375
Batch 60/64 loss: 4.289153099060059
Batch 61/64 loss: 4.2989888191223145
Batch 62/64 loss: 4.274622917175293
Batch 63/64 loss: 4.348222255706787
Batch 64/64 loss: 3.0447816848754883
Epoch 31  Train loss: 4.35283172083836  Val loss: 4.342820378922925
Saving best model, epoch: 31
Epoch 32
-------------------------------
Batch 1/64 loss: 4.326085090637207
Batch 2/64 loss: 4.283246994018555
Batch 3/64 loss: 4.307719707489014
Batch 4/64 loss: 4.330245018005371
Batch 5/64 loss: 4.185707092285156
Batch 6/64 loss: 4.274850845336914
Batch 7/64 loss: 4.291928291320801
Batch 8/64 loss: 4.33380126953125
Batch 9/64 loss: 4.280646800994873
Batch 10/64 loss: 4.29953670501709
Batch 11/64 loss: 4.30726957321167
Batch 12/64 loss: 4.227027893066406
Batch 13/64 loss: 4.37821102142334
Batch 14/64 loss: 4.322052955627441
Batch 15/64 loss: 4.259237289428711
Batch 16/64 loss: 4.299410343170166
Batch 17/64 loss: 4.281492710113525
Batch 18/64 loss: 4.321202278137207
Batch 19/64 loss: 4.282158851623535
Batch 20/64 loss: 4.2220964431762695
Batch 21/64 loss: 4.243497848510742
Batch 22/64 loss: 4.2629218101501465
Batch 23/64 loss: 4.282055377960205
Batch 24/64 loss: 4.294299125671387
Batch 25/64 loss: 4.341594696044922
Batch 26/64 loss: 4.303472518920898
Batch 27/64 loss: 4.286339282989502
Batch 28/64 loss: 4.215007781982422
Batch 29/64 loss: 4.237616062164307
Batch 30/64 loss: 4.275691032409668
Batch 31/64 loss: 4.227140426635742
Batch 32/64 loss: 4.258497714996338
Batch 33/64 loss: 4.201467514038086
Batch 34/64 loss: 4.311461448669434
Batch 35/64 loss: 4.331157684326172
Batch 36/64 loss: 4.338401794433594
Batch 37/64 loss: 4.364634990692139
Batch 38/64 loss: 4.20773983001709
Batch 39/64 loss: 4.341507911682129
Batch 40/64 loss: 4.322585105895996
Batch 41/64 loss: 4.305379390716553
Batch 42/64 loss: 4.3537750244140625
Batch 43/64 loss: 4.2718281745910645
Batch 44/64 loss: 4.269801139831543
Batch 45/64 loss: 4.365694999694824
Batch 46/64 loss: 4.284667491912842
Batch 47/64 loss: 4.298740386962891
Batch 48/64 loss: 4.311992168426514
Batch 49/64 loss: 4.299614429473877
Batch 50/64 loss: 4.2632856369018555
Batch 51/64 loss: 4.304526329040527
Batch 52/64 loss: 4.360136032104492
Batch 53/64 loss: 4.337792873382568
Batch 54/64 loss: 4.279177665710449
Batch 55/64 loss: 4.325113296508789
Batch 56/64 loss: 4.26946496963501
Batch 57/64 loss: 4.3037919998168945
Batch 58/64 loss: 4.237926006317139
Batch 59/64 loss: 4.2739081382751465
Batch 60/64 loss: 4.359463214874268
Batch 61/64 loss: 4.283786296844482
Batch 62/64 loss: 4.313094139099121
Batch 63/64 loss: 4.2655181884765625
Batch 64/64 loss: 2.945709466934204
Epoch 32  Train loss: 4.276216113333609  Val loss: 4.288390494703837
Saving best model, epoch: 32
Epoch 33
-------------------------------
Batch 1/64 loss: 4.251886367797852
Batch 2/64 loss: 4.353861331939697
Batch 3/64 loss: 4.311850547790527
Batch 4/64 loss: 4.262511730194092
Batch 5/64 loss: 4.227999210357666
Batch 6/64 loss: 4.23482608795166
Batch 7/64 loss: 4.19966983795166
Batch 8/64 loss: 4.334406852722168
Batch 9/64 loss: 4.295107364654541
Batch 10/64 loss: 4.243748664855957
Batch 11/64 loss: 4.344526290893555
Batch 12/64 loss: 4.275881290435791
Batch 13/64 loss: 4.216656684875488
Batch 14/64 loss: 4.330334186553955
Batch 15/64 loss: 4.242670059204102
Batch 16/64 loss: 4.292612552642822
Batch 17/64 loss: 4.342485427856445
Batch 18/64 loss: 4.286864280700684
Batch 19/64 loss: 4.2486066818237305
Batch 20/64 loss: 4.2307257652282715
Batch 21/64 loss: 4.269094944000244
Batch 22/64 loss: 4.228488922119141
Batch 23/64 loss: 4.297882080078125
Batch 24/64 loss: 4.162856101989746
Batch 25/64 loss: 4.321049690246582
Batch 26/64 loss: 4.29982328414917
Batch 27/64 loss: 4.252044677734375
Batch 28/64 loss: 4.3039870262146
Batch 29/64 loss: 4.218959331512451
Batch 30/64 loss: 4.324033737182617
Batch 31/64 loss: 4.241223335266113
Batch 32/64 loss: 4.2816548347473145
Batch 33/64 loss: 4.262763977050781
Batch 34/64 loss: 4.240730285644531
Batch 35/64 loss: 4.274679660797119
Batch 36/64 loss: 4.283434867858887
Batch 37/64 loss: 4.255891799926758
Batch 38/64 loss: 4.206768989562988
Batch 39/64 loss: 4.2397942543029785
Batch 40/64 loss: 4.267614841461182
Batch 41/64 loss: 4.245116710662842
Batch 42/64 loss: 4.275561809539795
Batch 43/64 loss: 4.252729892730713
Batch 44/64 loss: 4.2523980140686035
Batch 45/64 loss: 4.243801593780518
Batch 46/64 loss: 4.175171375274658
Batch 47/64 loss: 4.317750453948975
Batch 48/64 loss: 4.22695779800415
Batch 49/64 loss: 4.227764129638672
Batch 50/64 loss: 4.215756893157959
Batch 51/64 loss: 4.24462890625
Batch 52/64 loss: 4.321605205535889
Batch 53/64 loss: 4.220674991607666
Batch 54/64 loss: 4.24233341217041
Batch 55/64 loss: 4.224827766418457
Batch 56/64 loss: 4.212203025817871
Batch 57/64 loss: 4.272928237915039
Batch 58/64 loss: 4.215863227844238
Batch 59/64 loss: 4.203367233276367
Batch 60/64 loss: 4.2058024406433105
Batch 61/64 loss: 4.218178749084473
Batch 62/64 loss: 4.164259433746338
Batch 63/64 loss: 4.284985065460205
Batch 64/64 loss: 2.7881927490234375
Epoch 33  Train loss: 4.240248137829351  Val loss: 4.278771311966414
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: 4.195642948150635
Batch 2/64 loss: 4.147587776184082
Batch 3/64 loss: 4.33192777633667
Batch 4/64 loss: 4.237913131713867
Batch 5/64 loss: 4.2182793617248535
Batch 6/64 loss: 4.20665979385376
Batch 7/64 loss: 4.190191745758057
Batch 8/64 loss: 4.251467227935791
Batch 9/64 loss: 4.265605926513672
Batch 10/64 loss: 4.241126537322998
Batch 11/64 loss: 4.33985710144043
Batch 12/64 loss: 4.209362506866455
Batch 13/64 loss: 4.280827522277832
Batch 14/64 loss: 4.258639812469482
Batch 15/64 loss: 4.272414684295654
Batch 16/64 loss: 4.443458080291748
Batch 17/64 loss: 4.258825302124023
Batch 18/64 loss: 4.331160545349121
Batch 19/64 loss: 4.318181037902832
Batch 20/64 loss: 4.212068557739258
Batch 21/64 loss: 4.293464660644531
Batch 22/64 loss: 4.311784744262695
Batch 23/64 loss: 4.229387283325195
Batch 24/64 loss: 4.297633171081543
Batch 25/64 loss: 4.220909118652344
Batch 26/64 loss: 4.241491317749023
Batch 27/64 loss: 4.277509689331055
Batch 28/64 loss: 4.222495079040527
Batch 29/64 loss: 4.216782569885254
Batch 30/64 loss: 4.271883964538574
Batch 31/64 loss: 4.1551713943481445
Batch 32/64 loss: 4.167934417724609
Batch 33/64 loss: 4.220081329345703
Batch 34/64 loss: 4.168992519378662
Batch 35/64 loss: 4.091865062713623
Batch 36/64 loss: 4.1488752365112305
Batch 37/64 loss: 4.214261054992676
Batch 38/64 loss: 4.259503364562988
Batch 39/64 loss: 4.208364963531494
Batch 40/64 loss: 4.183030128479004
Batch 41/64 loss: 4.304487228393555
Batch 42/64 loss: 4.188440799713135
Batch 43/64 loss: 4.153824329376221
Batch 44/64 loss: 4.214431285858154
Batch 45/64 loss: 4.1722092628479
Batch 46/64 loss: 4.184232234954834
Batch 47/64 loss: 4.195273399353027
Batch 48/64 loss: 4.204097270965576
Batch 49/64 loss: 4.168031692504883
Batch 50/64 loss: 4.238317012786865
Batch 51/64 loss: 4.2321014404296875
Batch 52/64 loss: 4.1868157386779785
Batch 53/64 loss: 4.196512222290039
Batch 54/64 loss: 4.167585849761963
Batch 55/64 loss: 4.22108793258667
Batch 56/64 loss: 4.149913787841797
Batch 57/64 loss: 4.15931510925293
Batch 58/64 loss: 4.232754707336426
Batch 59/64 loss: 4.249212265014648
Batch 60/64 loss: 4.215804576873779
Batch 61/64 loss: 4.177512168884277
Batch 62/64 loss: 4.147608280181885
Batch 63/64 loss: 4.16292667388916
Batch 64/64 loss: 2.7435059547424316
Epoch 34  Train loss: 4.206944991093056  Val loss: 4.2286521806749695
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: 4.25055456161499
Batch 2/64 loss: 4.228466033935547
Batch 3/64 loss: 4.147256851196289
Batch 4/64 loss: 4.17003059387207
Batch 5/64 loss: 4.2188825607299805
Batch 6/64 loss: 4.184387683868408
Batch 7/64 loss: 4.097875118255615
Batch 8/64 loss: 4.279869079589844
Batch 9/64 loss: 4.185578346252441
Batch 10/64 loss: 4.275609016418457
Batch 11/64 loss: 4.215048789978027
Batch 12/64 loss: 4.280825614929199
Batch 13/64 loss: 4.147474765777588
Batch 14/64 loss: 4.225655555725098
Batch 15/64 loss: 4.187544345855713
Batch 16/64 loss: 4.29115104675293
Batch 17/64 loss: 4.2114386558532715
Batch 18/64 loss: 4.186759948730469
Batch 19/64 loss: 4.184465408325195
Batch 20/64 loss: 4.206233978271484
Batch 21/64 loss: 4.193812847137451
Batch 22/64 loss: 4.230035781860352
Batch 23/64 loss: 4.1707353591918945
Batch 24/64 loss: 4.1639180183410645
Batch 25/64 loss: 4.150635719299316
Batch 26/64 loss: 4.246817588806152
Batch 27/64 loss: 4.180555820465088
Batch 28/64 loss: 4.18153190612793
Batch 29/64 loss: 4.152585506439209
Batch 30/64 loss: 4.164599895477295
Batch 31/64 loss: 4.156863212585449
Batch 32/64 loss: 4.139876842498779
Batch 33/64 loss: 4.159681797027588
Batch 34/64 loss: 4.211421012878418
Batch 35/64 loss: 4.185734748840332
Batch 36/64 loss: 4.172269344329834
Batch 37/64 loss: 4.234264373779297
Batch 38/64 loss: 4.193431854248047
Batch 39/64 loss: 4.234591007232666
Batch 40/64 loss: 4.1019768714904785
Batch 41/64 loss: 4.146930694580078
Batch 42/64 loss: 4.098588466644287
Batch 43/64 loss: 4.179516792297363
Batch 44/64 loss: 4.15825891494751
Batch 45/64 loss: 4.228756427764893
Batch 46/64 loss: 4.143719673156738
Batch 47/64 loss: 4.22248649597168
Batch 48/64 loss: 4.161649703979492
Batch 49/64 loss: 4.142125129699707
Batch 50/64 loss: 4.185603618621826
Batch 51/64 loss: 4.197841644287109
Batch 52/64 loss: 4.0855584144592285
Batch 53/64 loss: 4.11764669418335
Batch 54/64 loss: 4.157933235168457
Batch 55/64 loss: 4.173299312591553
Batch 56/64 loss: 4.1227240562438965
Batch 57/64 loss: 4.1708760261535645
Batch 58/64 loss: 4.181737899780273
Batch 59/64 loss: 4.137821197509766
Batch 60/64 loss: 4.109482288360596
Batch 61/64 loss: 4.128461837768555
Batch 62/64 loss: 4.086511611938477
Batch 63/64 loss: 4.152115821838379
Batch 64/64 loss: 2.6683425903320312
Epoch 35  Train loss: 4.161432946897021  Val loss: 4.231631223278766
Epoch 36
-------------------------------
Batch 1/64 loss: 4.069807052612305
Batch 2/64 loss: 4.133852005004883
Batch 3/64 loss: 4.086083889007568
Batch 4/64 loss: 4.07783317565918
Batch 5/64 loss: 4.13243293762207
Batch 6/64 loss: 4.067968845367432
Batch 7/64 loss: 4.201572418212891
Batch 8/64 loss: 4.1307220458984375
Batch 9/64 loss: 4.124272346496582
Batch 10/64 loss: 4.105612754821777
Batch 11/64 loss: 4.106614589691162
Batch 12/64 loss: 4.113801956176758
Batch 13/64 loss: 4.119234085083008
Batch 14/64 loss: 4.18574333190918
Batch 15/64 loss: 4.144494533538818
Batch 16/64 loss: 4.128884315490723
Batch 17/64 loss: 4.282003402709961
Batch 18/64 loss: 4.091516971588135
Batch 19/64 loss: 4.121400356292725
Batch 20/64 loss: 4.114652633666992
Batch 21/64 loss: 4.104346752166748
Batch 22/64 loss: 4.242626190185547
Batch 23/64 loss: 4.080958366394043
Batch 24/64 loss: 4.428234577178955
Batch 25/64 loss: 4.2563700675964355
Batch 26/64 loss: 4.248080253601074
Batch 27/64 loss: 4.196676254272461
Batch 28/64 loss: 4.1884050369262695
Batch 29/64 loss: 4.175075054168701
Batch 30/64 loss: 4.192108631134033
Batch 31/64 loss: 4.149343490600586
Batch 32/64 loss: 4.158146858215332
Batch 33/64 loss: 4.2202911376953125
Batch 34/64 loss: 4.256920337677002
Batch 35/64 loss: 4.086495399475098
Batch 36/64 loss: 4.2028703689575195
Batch 37/64 loss: 4.2201008796691895
Batch 38/64 loss: 4.146399974822998
Batch 39/64 loss: 4.085534572601318
Batch 40/64 loss: 4.168488502502441
Batch 41/64 loss: 4.116334915161133
Batch 42/64 loss: 4.109552383422852
Batch 43/64 loss: 4.1481709480285645
Batch 44/64 loss: 4.123003959655762
Batch 45/64 loss: 4.2010087966918945
Batch 46/64 loss: 4.167514324188232
Batch 47/64 loss: 4.1440324783325195
Batch 48/64 loss: 4.000130653381348
Batch 49/64 loss: 4.207462787628174
Batch 50/64 loss: 4.1728620529174805
Batch 51/64 loss: 4.2045674324035645
Batch 52/64 loss: 4.0966315269470215
Batch 53/64 loss: 4.070315837860107
Batch 54/64 loss: 4.089476585388184
Batch 55/64 loss: 4.024008750915527
Batch 56/64 loss: 4.043117523193359
Batch 57/64 loss: 4.04417085647583
Batch 58/64 loss: 4.0503106117248535
Batch 59/64 loss: 4.052950859069824
Batch 60/64 loss: 4.1386613845825195
Batch 61/64 loss: 4.012516498565674
Batch 62/64 loss: 4.173721790313721
Batch 63/64 loss: 4.057611465454102
Batch 64/64 loss: 2.5568082332611084
Epoch 36  Train loss: 4.120968109018662  Val loss: 4.099145050311007
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 4.022154808044434
Batch 2/64 loss: 4.021945953369141
Batch 3/64 loss: 4.218722343444824
Batch 4/64 loss: 4.03425407409668
Batch 5/64 loss: 4.093316078186035
Batch 6/64 loss: 4.184520721435547
Batch 7/64 loss: 4.041008472442627
Batch 8/64 loss: 4.060829162597656
Batch 9/64 loss: 4.139462947845459
Batch 10/64 loss: 4.173801898956299
Batch 11/64 loss: 4.143221378326416
Batch 12/64 loss: 4.05673885345459
Batch 13/64 loss: 4.161128520965576
Batch 14/64 loss: 4.0267109870910645
Batch 15/64 loss: 4.084275245666504
Batch 16/64 loss: 4.102298736572266
Batch 17/64 loss: 4.109353065490723
Batch 18/64 loss: 4.118715763092041
Batch 19/64 loss: 4.1334428787231445
Batch 20/64 loss: 4.212193965911865
Batch 21/64 loss: 4.069941520690918
Batch 22/64 loss: 4.167316913604736
Batch 23/64 loss: 4.094184875488281
Batch 24/64 loss: 4.003145217895508
Batch 25/64 loss: 4.112906455993652
Batch 26/64 loss: 4.043430328369141
Batch 27/64 loss: 4.104783058166504
Batch 28/64 loss: 4.063083171844482
Batch 29/64 loss: 4.066465377807617
Batch 30/64 loss: 4.104668617248535
Batch 31/64 loss: 4.124238014221191
Batch 32/64 loss: 4.112620830535889
Batch 33/64 loss: 4.090717315673828
Batch 34/64 loss: 4.138571739196777
Batch 35/64 loss: 4.080443382263184
Batch 36/64 loss: 4.032883167266846
Batch 37/64 loss: 4.043642044067383
Batch 38/64 loss: 4.212170124053955
Batch 39/64 loss: 4.126018524169922
Batch 40/64 loss: 4.170291900634766
Batch 41/64 loss: 4.18569278717041
Batch 42/64 loss: 4.11574649810791
Batch 43/64 loss: 4.085290908813477
Batch 44/64 loss: 3.9971697330474854
Batch 45/64 loss: 4.0794878005981445
Batch 46/64 loss: 4.130407810211182
Batch 47/64 loss: 4.106005668640137
Batch 48/64 loss: 4.176103591918945
Batch 49/64 loss: 4.016359806060791
Batch 50/64 loss: 4.1078972816467285
Batch 51/64 loss: 4.087423801422119
Batch 52/64 loss: 3.9485926628112793
Batch 53/64 loss: 4.072690963745117
Batch 54/64 loss: 4.184188365936279
Batch 55/64 loss: 4.019830703735352
Batch 56/64 loss: 3.9955453872680664
Batch 57/64 loss: 4.06346321105957
Batch 58/64 loss: 4.059728622436523
Batch 59/64 loss: 4.133214473724365
Batch 60/64 loss: 4.133847236633301
Batch 61/64 loss: 4.017246246337891
Batch 62/64 loss: 4.17645263671875
Batch 63/64 loss: 4.080216407775879
Batch 64/64 loss: 2.4906606674194336
Epoch 37  Train loss: 4.0774935928045535  Val loss: 4.123528065960022
Epoch 38
-------------------------------
Batch 1/64 loss: 4.024025917053223
Batch 2/64 loss: 4.067683219909668
Batch 3/64 loss: 3.9753544330596924
Batch 4/64 loss: 4.066763401031494
Batch 5/64 loss: 4.035511016845703
Batch 6/64 loss: 4.116729736328125
Batch 7/64 loss: 4.039560317993164
Batch 8/64 loss: 4.1353325843811035
Batch 9/64 loss: 4.050851821899414
Batch 10/64 loss: 4.056549072265625
Batch 11/64 loss: 4.103899002075195
Batch 12/64 loss: 3.989457607269287
Batch 13/64 loss: 4.083606243133545
Batch 14/64 loss: 4.015008926391602
Batch 15/64 loss: 4.017663955688477
Batch 16/64 loss: 4.097410678863525
Batch 17/64 loss: 4.002848148345947
Batch 18/64 loss: 4.205538272857666
Batch 19/64 loss: 4.120160102844238
Batch 20/64 loss: 4.089792251586914
Batch 21/64 loss: 4.091828346252441
Batch 22/64 loss: 4.1601643562316895
Batch 23/64 loss: 4.0490264892578125
Batch 24/64 loss: 4.0681376457214355
Batch 25/64 loss: 4.100679874420166
Batch 26/64 loss: 4.010243892669678
Batch 27/64 loss: 4.108945846557617
Batch 28/64 loss: 4.114777565002441
Batch 29/64 loss: 4.025494575500488
Batch 30/64 loss: 4.031838417053223
Batch 31/64 loss: 3.950145721435547
Batch 32/64 loss: 4.000555038452148
Batch 33/64 loss: 4.040517807006836
Batch 34/64 loss: 3.994385004043579
Batch 35/64 loss: 3.987748622894287
Batch 36/64 loss: 4.128904342651367
Batch 37/64 loss: 4.030922889709473
Batch 38/64 loss: 4.051092147827148
Batch 39/64 loss: 4.086629867553711
Batch 40/64 loss: 3.991762161254883
Batch 41/64 loss: 4.056632995605469
Batch 42/64 loss: 4.094862937927246
Batch 43/64 loss: 4.017815589904785
Batch 44/64 loss: 4.000050067901611
Batch 45/64 loss: 4.049404621124268
Batch 46/64 loss: 4.069628715515137
Batch 47/64 loss: 3.99726939201355
Batch 48/64 loss: 4.072918891906738
Batch 49/64 loss: 4.004392147064209
Batch 50/64 loss: 4.014949798583984
Batch 51/64 loss: 4.049001216888428
Batch 52/64 loss: 4.129429340362549
Batch 53/64 loss: 4.0924177169799805
Batch 54/64 loss: 4.024276256561279
Batch 55/64 loss: 4.104574203491211
Batch 56/64 loss: 4.072159290313721
Batch 57/64 loss: 4.024318695068359
Batch 58/64 loss: 4.0422515869140625
Batch 59/64 loss: 3.9642231464385986
Batch 60/64 loss: 4.136765480041504
Batch 61/64 loss: 4.010247230529785
Batch 62/64 loss: 4.126916885375977
Batch 63/64 loss: 4.007539749145508
Batch 64/64 loss: 2.358069658279419
Epoch 38  Train loss: 4.035265027775484  Val loss: 4.004362807650747
Saving best model, epoch: 38
Epoch 39
-------------------------------
Batch 1/64 loss: 3.9591031074523926
Batch 2/64 loss: 4.066368103027344
Batch 3/64 loss: 3.8652076721191406
Batch 4/64 loss: 3.977935314178467
Batch 5/64 loss: 4.099660396575928
Batch 6/64 loss: 4.061490535736084
Batch 7/64 loss: 4.022863388061523
Batch 8/64 loss: 4.064723968505859
Batch 9/64 loss: 4.007490158081055
Batch 10/64 loss: 4.015850067138672
Batch 11/64 loss: 3.8960816860198975
Batch 12/64 loss: 4.020596027374268
Batch 13/64 loss: 4.017526626586914
Batch 14/64 loss: 4.022760391235352
Batch 15/64 loss: 4.159427642822266
Batch 16/64 loss: 4.0426836013793945
Batch 17/64 loss: 4.0431108474731445
Batch 18/64 loss: 4.001753330230713
Batch 19/64 loss: 4.079376220703125
Batch 20/64 loss: 3.978440284729004
Batch 21/64 loss: 4.002249717712402
Batch 22/64 loss: 3.924665689468384
Batch 23/64 loss: 4.037900447845459
Batch 24/64 loss: 3.9370522499084473
Batch 25/64 loss: 4.016576290130615
Batch 26/64 loss: 3.958515167236328
Batch 27/64 loss: 4.056065559387207
Batch 28/64 loss: 3.966187000274658
Batch 29/64 loss: 3.9931480884552
Batch 30/64 loss: 4.036961555480957
Batch 31/64 loss: 3.9225614070892334
Batch 32/64 loss: 3.945908546447754
Batch 33/64 loss: 3.9876909255981445
Batch 34/64 loss: 3.985100269317627
Batch 35/64 loss: 3.958289623260498
Batch 36/64 loss: 3.9058287143707275
Batch 37/64 loss: 4.071977615356445
Batch 38/64 loss: 4.052313804626465
Batch 39/64 loss: 3.9301342964172363
Batch 40/64 loss: 3.9916844367980957
Batch 41/64 loss: 3.9379539489746094
Batch 42/64 loss: 4.038807392120361
Batch 43/64 loss: 3.9153826236724854
Batch 44/64 loss: 3.909761428833008
Batch 45/64 loss: 3.9792988300323486
Batch 46/64 loss: 3.9799628257751465
Batch 47/64 loss: 4.041685104370117
Batch 48/64 loss: 4.00101375579834
Batch 49/64 loss: 3.9846067428588867
Batch 50/64 loss: 4.0441694259643555
Batch 51/64 loss: 3.9866466522216797
Batch 52/64 loss: 3.8915905952453613
Batch 53/64 loss: 4.019432067871094
Batch 54/64 loss: 3.8946173191070557
Batch 55/64 loss: 3.923901081085205
Batch 56/64 loss: 4.025453567504883
Batch 57/64 loss: 3.8360888957977295
Batch 58/64 loss: 3.989515542984009
Batch 59/64 loss: 3.9874348640441895
Batch 60/64 loss: 3.82824969291687
Batch 61/64 loss: 3.86824631690979
Batch 62/64 loss: 3.9074935913085938
Batch 63/64 loss: 4.11630916595459
Batch 64/64 loss: 2.1803030967712402
Epoch 39  Train loss: 3.965899757310456  Val loss: 3.9838071229941248
Saving best model, epoch: 39
Epoch 40
-------------------------------
Batch 1/64 loss: 3.902421712875366
Batch 2/64 loss: 3.995575189590454
Batch 3/64 loss: 3.9196770191192627
Batch 4/64 loss: 3.9224443435668945
Batch 5/64 loss: 3.996796131134033
Batch 6/64 loss: 3.9658517837524414
Batch 7/64 loss: 4.102603912353516
Batch 8/64 loss: 3.8784875869750977
Batch 9/64 loss: 4.060850143432617
Batch 10/64 loss: 3.9887638092041016
Batch 11/64 loss: 3.8706538677215576
Batch 12/64 loss: 3.9378750324249268
Batch 13/64 loss: 3.9453229904174805
Batch 14/64 loss: 3.8615806102752686
Batch 15/64 loss: 3.795806407928467
Batch 16/64 loss: 4.026491641998291
Batch 17/64 loss: 3.9331984519958496
Batch 18/64 loss: 3.9424002170562744
Batch 19/64 loss: 4.010613441467285
Batch 20/64 loss: 3.922903299331665
Batch 21/64 loss: 3.9267773628234863
Batch 22/64 loss: 3.961087703704834
Batch 23/64 loss: 4.040142059326172
Batch 24/64 loss: 3.8616573810577393
Batch 25/64 loss: 3.857630968093872
Batch 26/64 loss: 3.8085877895355225
Batch 27/64 loss: 4.0019683837890625
Batch 28/64 loss: 3.7822554111480713
Batch 29/64 loss: 3.9136950969696045
Batch 30/64 loss: 3.83431339263916
Batch 31/64 loss: 3.860814094543457
Batch 32/64 loss: 3.982393980026245
Batch 33/64 loss: 3.893019676208496
Batch 34/64 loss: 3.861093282699585
Batch 35/64 loss: 3.877178192138672
Batch 36/64 loss: 3.8644862174987793
Batch 37/64 loss: 3.8542020320892334
Batch 38/64 loss: 3.9456186294555664
Batch 39/64 loss: 3.8972361087799072
Batch 40/64 loss: 3.878178358078003
Batch 41/64 loss: 3.800359010696411
Batch 42/64 loss: 3.926105260848999
Batch 43/64 loss: 3.9794673919677734
Batch 44/64 loss: 3.9235177040100098
Batch 45/64 loss: 3.9530324935913086
Batch 46/64 loss: 3.9228413105010986
Batch 47/64 loss: 4.025629997253418
Batch 48/64 loss: 3.9168765544891357
Batch 49/64 loss: 3.8685169219970703
Batch 50/64 loss: 4.019097328186035
Batch 51/64 loss: 3.8863775730133057
Batch 52/64 loss: 3.9934279918670654
Batch 53/64 loss: 3.8415520191192627
Batch 54/64 loss: 3.9713006019592285
Batch 55/64 loss: 3.9638893604278564
Batch 56/64 loss: 3.9001028537750244
Batch 57/64 loss: 3.964369535446167
Batch 58/64 loss: 3.82902193069458
Batch 59/64 loss: 3.920088291168213
Batch 60/64 loss: 3.9466969966888428
Batch 61/64 loss: 3.8100719451904297
Batch 62/64 loss: 3.757066249847412
Batch 63/64 loss: 3.861962080001831
Batch 64/64 loss: 1.931051254272461
Epoch 40  Train loss: 3.8950951146144495  Val loss: 3.8778165476428685
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: 3.862074375152588
Batch 2/64 loss: 3.9176294803619385
Batch 3/64 loss: 4.090786933898926
Batch 4/64 loss: 3.8658528327941895
Batch 5/64 loss: 3.7835922241210938
Batch 6/64 loss: 3.855342149734497
Batch 7/64 loss: 3.8838436603546143
Batch 8/64 loss: 3.76861572265625
Batch 9/64 loss: 3.8052594661712646
Batch 10/64 loss: 3.8024587631225586
Batch 11/64 loss: 3.753561496734619
Batch 12/64 loss: 3.8172802925109863
Batch 13/64 loss: 3.977238655090332
Batch 14/64 loss: 3.879505157470703
Batch 15/64 loss: 3.760960340499878
Batch 16/64 loss: 3.850438117980957
Batch 17/64 loss: 3.8452680110931396
Batch 18/64 loss: 3.836306571960449
Batch 19/64 loss: 3.916276454925537
Batch 20/64 loss: 3.930079698562622
Batch 21/64 loss: 3.8523361682891846
Batch 22/64 loss: 3.842329978942871
Batch 23/64 loss: 3.897421360015869
Batch 24/64 loss: 3.837167739868164
Batch 25/64 loss: 3.802075147628784
Batch 26/64 loss: 3.828796148300171
Batch 27/64 loss: 3.827903985977173
Batch 28/64 loss: 3.854715347290039
Batch 29/64 loss: 3.906019926071167
Batch 30/64 loss: 3.8874239921569824
Batch 31/64 loss: 3.7924420833587646
Batch 32/64 loss: 3.7759757041931152
Batch 33/64 loss: 3.8725671768188477
Batch 34/64 loss: 3.8289682865142822
Batch 35/64 loss: 3.8967549800872803
Batch 36/64 loss: 3.8100461959838867
Batch 37/64 loss: 3.8337597846984863
Batch 38/64 loss: 3.8776659965515137
Batch 39/64 loss: 3.8064756393432617
Batch 40/64 loss: 3.920419692993164
Batch 41/64 loss: 3.7647626399993896
Batch 42/64 loss: 3.7340919971466064
Batch 43/64 loss: 3.7923691272735596
Batch 44/64 loss: 3.8749382495880127
Batch 45/64 loss: 3.882683038711548
Batch 46/64 loss: 3.8401448726654053
Batch 47/64 loss: 3.8728647232055664
Batch 48/64 loss: 4.027571201324463
Batch 49/64 loss: 3.8194897174835205
Batch 50/64 loss: 3.9745657444000244
Batch 51/64 loss: 3.7887167930603027
Batch 52/64 loss: 3.6672370433807373
Batch 53/64 loss: 3.9379117488861084
Batch 54/64 loss: 3.859067440032959
Batch 55/64 loss: 3.863281488418579
Batch 56/64 loss: 3.856442451477051
Batch 57/64 loss: 3.9213716983795166
Batch 58/64 loss: 3.961719274520874
Batch 59/64 loss: 3.7346668243408203
Batch 60/64 loss: 3.834757089614868
Batch 61/64 loss: 3.8498244285583496
Batch 62/64 loss: 3.7117767333984375
Batch 63/64 loss: 4.033452033996582
Batch 64/64 loss: 1.7542545795440674
Epoch 41  Train loss: 3.828596596624337  Val loss: 3.8198450553867827
Saving best model, epoch: 41
Epoch 42
-------------------------------
Batch 1/64 loss: 3.784480571746826
Batch 2/64 loss: 3.9063899517059326
Batch 3/64 loss: 3.7861454486846924
Batch 4/64 loss: 3.799077272415161
Batch 5/64 loss: 3.801053524017334
Batch 6/64 loss: 3.781485080718994
Batch 7/64 loss: 3.8188681602478027
Batch 8/64 loss: 3.840878486633301
Batch 9/64 loss: 3.8717026710510254
Batch 10/64 loss: 3.8279027938842773
Batch 11/64 loss: 3.9002320766448975
Batch 12/64 loss: 3.830141067504883
Batch 13/64 loss: 3.8995087146759033
Batch 14/64 loss: 3.889187812805176
Batch 15/64 loss: 4.035298824310303
Batch 16/64 loss: 3.7940025329589844
Batch 17/64 loss: 3.7549686431884766
Batch 18/64 loss: 3.826416015625
Batch 19/64 loss: 3.8409252166748047
Batch 20/64 loss: 3.8486058712005615
Batch 21/64 loss: 3.8331174850463867
Batch 22/64 loss: 3.9141061305999756
Batch 23/64 loss: 4.006537437438965
Batch 24/64 loss: 3.7882580757141113
Batch 25/64 loss: 3.9086239337921143
Batch 26/64 loss: 3.821485996246338
Batch 27/64 loss: 3.7778308391571045
Batch 28/64 loss: 3.845489501953125
Batch 29/64 loss: 3.862194061279297
Batch 30/64 loss: 3.783073902130127
Batch 31/64 loss: 3.840348958969116
Batch 32/64 loss: 3.8014204502105713
Batch 33/64 loss: 3.738294839859009
Batch 34/64 loss: 3.7237677574157715
Batch 35/64 loss: 3.8461296558380127
Batch 36/64 loss: 3.858375072479248
Batch 37/64 loss: 3.7379117012023926
Batch 38/64 loss: 3.8274776935577393
Batch 39/64 loss: 3.7714593410491943
Batch 40/64 loss: 3.7486608028411865
Batch 41/64 loss: 3.7631003856658936
Batch 42/64 loss: 3.6513702869415283
Batch 43/64 loss: 3.793454885482788
Batch 44/64 loss: 3.9739017486572266
Batch 45/64 loss: 3.7668120861053467
Batch 46/64 loss: 3.738128662109375
Batch 47/64 loss: 3.7513389587402344
Batch 48/64 loss: 4.0878753662109375
Batch 49/64 loss: 3.690115451812744
Batch 50/64 loss: 3.9123787879943848
Batch 51/64 loss: 3.859844446182251
Batch 52/64 loss: 3.927659749984741
Batch 53/64 loss: 3.7218880653381348
Batch 54/64 loss: 3.7696616649627686
Batch 55/64 loss: 3.9077632427215576
Batch 56/64 loss: 3.7579023838043213
Batch 57/64 loss: 3.719067335128784
Batch 58/64 loss: 3.6829686164855957
Batch 59/64 loss: 3.8427605628967285
Batch 60/64 loss: 3.8533220291137695
Batch 61/64 loss: 3.781707763671875
Batch 62/64 loss: 3.757086992263794
Batch 63/64 loss: 3.737565755844116
Batch 64/64 loss: 1.9402565956115723
Epoch 42  Train loss: 3.7988188556596345  Val loss: 3.73888365427653
Saving best model, epoch: 42
Epoch 43
-------------------------------
Batch 1/64 loss: 3.755246162414551
Batch 2/64 loss: 3.7153780460357666
Batch 3/64 loss: 3.735543727874756
Batch 4/64 loss: 3.7863426208496094
Batch 5/64 loss: 3.731822967529297
Batch 6/64 loss: 3.8599681854248047
Batch 7/64 loss: 3.634579658508301
Batch 8/64 loss: 3.788041353225708
Batch 9/64 loss: 3.7287192344665527
Batch 10/64 loss: 3.731149911880493
Batch 11/64 loss: 3.814410924911499
Batch 12/64 loss: 3.66860294342041
Batch 13/64 loss: 3.791567087173462
Batch 14/64 loss: 3.783254623413086
Batch 15/64 loss: 3.8542587757110596
Batch 16/64 loss: 3.8827970027923584
Batch 17/64 loss: 3.8075971603393555
Batch 18/64 loss: 3.7271623611450195
Batch 19/64 loss: 3.7475967407226562
Batch 20/64 loss: 3.7015461921691895
Batch 21/64 loss: 3.688657760620117
Batch 22/64 loss: 3.729764699935913
Batch 23/64 loss: 3.804265260696411
Batch 24/64 loss: 3.8724441528320312
Batch 25/64 loss: 3.737489700317383
Batch 26/64 loss: 3.7147655487060547
Batch 27/64 loss: 3.8495259284973145
Batch 28/64 loss: 3.639728546142578
Batch 29/64 loss: 3.6359963417053223
Batch 30/64 loss: 3.670335054397583
Batch 31/64 loss: 3.814680814743042
Batch 32/64 loss: 3.660086154937744
Batch 33/64 loss: 3.69830060005188
Batch 34/64 loss: 3.853929281234741
Batch 35/64 loss: 3.6838672161102295
Batch 36/64 loss: 3.5974392890930176
Batch 37/64 loss: 3.7658731937408447
Batch 38/64 loss: 3.6960978507995605
Batch 39/64 loss: 3.7241454124450684
Batch 40/64 loss: 3.7345130443573
Batch 41/64 loss: 3.7095601558685303
Batch 42/64 loss: 3.7161059379577637
Batch 43/64 loss: 3.611546516418457
Batch 44/64 loss: 3.6485650539398193
Batch 45/64 loss: 3.7457237243652344
Batch 46/64 loss: 3.677868604660034
Batch 47/64 loss: 3.7305402755737305
Batch 48/64 loss: 3.7294721603393555
Batch 49/64 loss: 3.690870523452759
Batch 50/64 loss: 3.579242706298828
Batch 51/64 loss: 3.6822407245635986
Batch 52/64 loss: 3.8224503993988037
Batch 53/64 loss: 3.807286024093628
Batch 54/64 loss: 3.6573667526245117
Batch 55/64 loss: 3.8296940326690674
Batch 56/64 loss: 3.7452890872955322
Batch 57/64 loss: 3.769425630569458
Batch 58/64 loss: 3.7845826148986816
Batch 59/64 loss: 3.6405344009399414
Batch 60/64 loss: 3.706923723220825
Batch 61/64 loss: 3.665905714035034
Batch 62/64 loss: 3.7449889183044434
Batch 63/64 loss: 3.7611775398254395
Batch 64/64 loss: 2.0656964778900146
Epoch 43  Train loss: 3.7148882370369107  Val loss: 3.698921229831132
Saving best model, epoch: 43
Epoch 44
-------------------------------
Batch 1/64 loss: 3.725707530975342
Batch 2/64 loss: 3.7944436073303223
Batch 3/64 loss: 3.6542699337005615
Batch 4/64 loss: 3.7028701305389404
Batch 5/64 loss: 3.7106528282165527
Batch 6/64 loss: 3.684026002883911
Batch 7/64 loss: 3.7344892024993896
Batch 8/64 loss: 3.646371841430664
Batch 9/64 loss: 3.704822301864624
Batch 10/64 loss: 3.6808855533599854
Batch 11/64 loss: 3.6510074138641357
Batch 12/64 loss: 3.594775676727295
Batch 13/64 loss: 3.731592893600464
Batch 14/64 loss: 3.679744005203247
Batch 15/64 loss: 3.706491470336914
Batch 16/64 loss: 3.7365126609802246
Batch 17/64 loss: 3.624598503112793
Batch 18/64 loss: 3.695042371749878
Batch 19/64 loss: 3.5712499618530273
Batch 20/64 loss: 3.663752555847168
Batch 21/64 loss: 3.5354790687561035
Batch 22/64 loss: 3.6392688751220703
Batch 23/64 loss: 3.7548606395721436
Batch 24/64 loss: 3.7150180339813232
Batch 25/64 loss: 3.774559736251831
Batch 26/64 loss: 3.5682637691497803
Batch 27/64 loss: 3.63688325881958
Batch 28/64 loss: 3.8963358402252197
Batch 29/64 loss: 3.599879741668701
Batch 30/64 loss: 3.760810136795044
Batch 31/64 loss: 3.7419867515563965
Batch 32/64 loss: 3.642223596572876
Batch 33/64 loss: 3.6791646480560303
Batch 34/64 loss: 3.710922956466675
Batch 35/64 loss: 3.5459532737731934
Batch 36/64 loss: 3.7895619869232178
Batch 37/64 loss: 3.648568630218506
Batch 38/64 loss: 3.8338396549224854
Batch 39/64 loss: 3.827939987182617
Batch 40/64 loss: 3.5940630435943604
Batch 41/64 loss: 3.8266561031341553
Batch 42/64 loss: 3.7123308181762695
Batch 43/64 loss: 3.7450075149536133
Batch 44/64 loss: 3.670043706893921
Batch 45/64 loss: 3.5994162559509277
Batch 46/64 loss: 3.65535044670105
Batch 47/64 loss: 3.6469078063964844
Batch 48/64 loss: 3.681995153427124
Batch 49/64 loss: 3.612302541732788
Batch 50/64 loss: 3.5974764823913574
Batch 51/64 loss: 3.7074477672576904
Batch 52/64 loss: 3.7952494621276855
Batch 53/64 loss: 3.7580931186676025
Batch 54/64 loss: 3.6885361671447754
Batch 55/64 loss: 3.9774975776672363
Batch 56/64 loss: 3.837311267852783
Batch 57/64 loss: 3.689204216003418
Batch 58/64 loss: 3.857491970062256
Batch 59/64 loss: 3.657945394515991
Batch 60/64 loss: 3.771944522857666
Batch 61/64 loss: 3.675107955932617
Batch 62/64 loss: 3.7521865367889404
Batch 63/64 loss: 3.673515558242798
Batch 64/64 loss: 2.2145678997039795
Epoch 44  Train loss: 3.683746421103384  Val loss: 3.6663077377371773
Saving best model, epoch: 44
Epoch 45
-------------------------------
Batch 1/64 loss: 3.576090097427368
Batch 2/64 loss: 3.6242854595184326
Batch 3/64 loss: 3.731804609298706
Batch 4/64 loss: 3.688380718231201
Batch 5/64 loss: 3.762014150619507
Batch 6/64 loss: 3.6813066005706787
Batch 7/64 loss: 3.687380313873291
Batch 8/64 loss: 3.5914905071258545
Batch 9/64 loss: 3.5366714000701904
Batch 10/64 loss: 3.7638943195343018
Batch 11/64 loss: 3.714942693710327
Batch 12/64 loss: 3.6995112895965576
Batch 13/64 loss: 3.817925214767456
Batch 14/64 loss: 3.721419095993042
Batch 15/64 loss: 3.8285443782806396
Batch 16/64 loss: 3.5690040588378906
Batch 17/64 loss: 3.6390912532806396
Batch 18/64 loss: 3.6629598140716553
Batch 19/64 loss: 3.5827271938323975
Batch 20/64 loss: 3.555983543395996
Batch 21/64 loss: 3.61885142326355
Batch 22/64 loss: 3.5977869033813477
Batch 23/64 loss: 3.741715431213379
Batch 24/64 loss: 3.7860500812530518
Batch 25/64 loss: 3.564284086227417
Batch 26/64 loss: 3.779956579208374
Batch 27/64 loss: 3.6074814796447754
Batch 28/64 loss: 3.5865061283111572
Batch 29/64 loss: 3.6096739768981934
Batch 30/64 loss: 3.678623676300049
Batch 31/64 loss: 3.654648542404175
Batch 32/64 loss: 3.663712739944458
Batch 33/64 loss: 3.762468099594116
Batch 34/64 loss: 3.6839566230773926
Batch 35/64 loss: 3.840491771697998
Batch 36/64 loss: 3.482677459716797
Batch 37/64 loss: 3.6523165702819824
Batch 38/64 loss: 3.573909282684326
Batch 39/64 loss: 3.613682746887207
Batch 40/64 loss: 3.5375218391418457
Batch 41/64 loss: 3.7196998596191406
Batch 42/64 loss: 3.4878084659576416
Batch 43/64 loss: 3.4964630603790283
Batch 44/64 loss: 3.4441730976104736
Batch 45/64 loss: 3.611388921737671
Batch 46/64 loss: 3.4757726192474365
Batch 47/64 loss: 3.6776227951049805
Batch 48/64 loss: 3.640838861465454
Batch 49/64 loss: 3.52299165725708
Batch 50/64 loss: 3.516575574874878
Batch 51/64 loss: 3.6591529846191406
Batch 52/64 loss: 3.618718385696411
Batch 53/64 loss: 3.5154829025268555
Batch 54/64 loss: 3.6350769996643066
Batch 55/64 loss: 3.538226366043091
Batch 56/64 loss: 3.766822576522827
Batch 57/64 loss: 3.6144208908081055
Batch 58/64 loss: 3.7441117763519287
Batch 59/64 loss: 3.6028048992156982
Batch 60/64 loss: 3.7387914657592773
Batch 61/64 loss: 3.6518242359161377
Batch 62/64 loss: 3.576054096221924
Batch 63/64 loss: 3.5658304691314697
Batch 64/64 loss: 1.5231778621673584
Epoch 45  Train loss: 3.6146631923376344  Val loss: 3.6298876890202156
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: 3.512077569961548
Batch 2/64 loss: 3.7087225914001465
Batch 3/64 loss: 3.5195930004119873
Batch 4/64 loss: 3.5751638412475586
Batch 5/64 loss: 3.7306272983551025
Batch 6/64 loss: 3.6377532482147217
Batch 7/64 loss: 3.668867588043213
Batch 8/64 loss: 3.501279354095459
Batch 9/64 loss: 3.685845136642456
Batch 10/64 loss: 3.610316038131714
Batch 11/64 loss: 3.629598617553711
Batch 12/64 loss: 3.4620521068573
Batch 13/64 loss: 3.629473924636841
Batch 14/64 loss: 3.62886118888855
Batch 15/64 loss: 3.5258357524871826
Batch 16/64 loss: 3.5392422676086426
Batch 17/64 loss: 3.5586514472961426
Batch 18/64 loss: 3.7085418701171875
Batch 19/64 loss: 3.505911350250244
Batch 20/64 loss: 3.688960075378418
Batch 21/64 loss: 3.522094488143921
Batch 22/64 loss: 3.5473830699920654
Batch 23/64 loss: 3.6333231925964355
Batch 24/64 loss: 3.649061918258667
Batch 25/64 loss: 3.51631498336792
Batch 26/64 loss: 3.6049017906188965
Batch 27/64 loss: 3.5597128868103027
Batch 28/64 loss: 3.581295967102051
Batch 29/64 loss: 3.5413074493408203
Batch 30/64 loss: 3.8005359172821045
Batch 31/64 loss: 3.5737533569335938
Batch 32/64 loss: 3.6098098754882812
Batch 33/64 loss: 3.5734994411468506
Batch 34/64 loss: 3.4914915561676025
Batch 35/64 loss: 3.688859701156616
Batch 36/64 loss: 3.466115951538086
Batch 37/64 loss: 3.840799331665039
Batch 38/64 loss: 3.686979055404663
Batch 39/64 loss: 3.6680748462677
Batch 40/64 loss: 3.6414008140563965
Batch 41/64 loss: 3.6853315830230713
Batch 42/64 loss: 3.4936089515686035
Batch 43/64 loss: 3.5682260990142822
Batch 44/64 loss: 3.55026912689209
Batch 45/64 loss: 3.5260062217712402
Batch 46/64 loss: 3.685246467590332
Batch 47/64 loss: 3.584995746612549
Batch 48/64 loss: 3.684504747390747
Batch 49/64 loss: 3.626417636871338
Batch 50/64 loss: 3.5192413330078125
Batch 51/64 loss: 3.608830213546753
Batch 52/64 loss: 3.558823585510254
Batch 53/64 loss: 3.6168835163116455
Batch 54/64 loss: 3.5311665534973145
Batch 55/64 loss: 3.4292993545532227
Batch 56/64 loss: 3.4173030853271484
Batch 57/64 loss: 3.5927999019622803
Batch 58/64 loss: 3.40809965133667
Batch 59/64 loss: 3.496398687362671
Batch 60/64 loss: 3.5324010848999023
Batch 61/64 loss: 3.5604703426361084
Batch 62/64 loss: 3.6613216400146484
Batch 63/64 loss: 3.632901906967163
Batch 64/64 loss: 1.5489811897277832
Epoch 46  Train loss: 3.566374481425566  Val loss: 3.527486063770412
Saving best model, epoch: 46
Epoch 47
-------------------------------
Batch 1/64 loss: 3.5684900283813477
Batch 2/64 loss: 3.4500625133514404
Batch 3/64 loss: 3.5155279636383057
Batch 4/64 loss: 3.5781633853912354
Batch 5/64 loss: 3.4499638080596924
Batch 6/64 loss: 3.4895293712615967
Batch 7/64 loss: 3.560335874557495
Batch 8/64 loss: 3.558156728744507
Batch 9/64 loss: 3.552083969116211
Batch 10/64 loss: 3.65558123588562
Batch 11/64 loss: 3.487382173538208
Batch 12/64 loss: 3.5247228145599365
Batch 13/64 loss: 3.5423800945281982
Batch 14/64 loss: 3.637721061706543
Batch 15/64 loss: 3.543735980987549
Batch 16/64 loss: 3.614353656768799
Batch 17/64 loss: 3.5026962757110596
Batch 18/64 loss: 3.457822561264038
Batch 19/64 loss: 3.483898878097534
Batch 20/64 loss: 3.6205081939697266
Batch 21/64 loss: 3.435378074645996
Batch 22/64 loss: 3.540633201599121
Batch 23/64 loss: 3.464646339416504
Batch 24/64 loss: 3.4863784313201904
Batch 25/64 loss: 3.438504695892334
Batch 26/64 loss: 3.463757038116455
Batch 27/64 loss: 3.5068862438201904
Batch 28/64 loss: 3.3750863075256348
Batch 29/64 loss: 3.403938055038452
Batch 30/64 loss: 3.5364017486572266
Batch 31/64 loss: 3.4154844284057617
Batch 32/64 loss: 3.527796506881714
Batch 33/64 loss: 3.534506320953369
Batch 34/64 loss: 3.639414072036743
Batch 35/64 loss: 3.5507965087890625
Batch 36/64 loss: 3.4306910037994385
Batch 37/64 loss: 3.754981279373169
Batch 38/64 loss: 3.5398592948913574
Batch 39/64 loss: 3.708143949508667
Batch 40/64 loss: 3.3862762451171875
Batch 41/64 loss: 3.586223840713501
Batch 42/64 loss: 3.556816339492798
Batch 43/64 loss: 3.5989949703216553
Batch 44/64 loss: 3.7225217819213867
Batch 45/64 loss: 3.4334065914154053
Batch 46/64 loss: 3.557637929916382
Batch 47/64 loss: 3.6572964191436768
Batch 48/64 loss: 3.536351203918457
Batch 49/64 loss: 3.583847761154175
Batch 50/64 loss: 3.581263542175293
Batch 51/64 loss: 3.522869825363159
Batch 52/64 loss: 3.6123008728027344
Batch 53/64 loss: 3.7200851440429688
Batch 54/64 loss: 3.5205819606781006
Batch 55/64 loss: 3.4468088150024414
Batch 56/64 loss: 3.50962233543396
Batch 57/64 loss: 3.687941312789917
Batch 58/64 loss: 3.385666847229004
Batch 59/64 loss: 3.58902645111084
Batch 60/64 loss: 3.665916681289673
Batch 61/64 loss: 3.3842899799346924
Batch 62/64 loss: 3.6446499824523926
Batch 63/64 loss: 3.467344284057617
Batch 64/64 loss: 1.3785414695739746
Epoch 47  Train loss: 3.512753682978013  Val loss: 3.456939127027374
Saving best model, epoch: 47
Epoch 48
-------------------------------
Batch 1/64 loss: 3.525148868560791
Batch 2/64 loss: 3.403904676437378
Batch 3/64 loss: 3.638824462890625
Batch 4/64 loss: 3.490633010864258
Batch 5/64 loss: 3.4561078548431396
Batch 6/64 loss: 3.768752098083496
Batch 7/64 loss: 3.4395573139190674
Batch 8/64 loss: 3.3725104331970215
Batch 9/64 loss: 3.517787456512451
Batch 10/64 loss: 3.775308609008789
Batch 11/64 loss: 3.4742188453674316
Batch 12/64 loss: 3.4905619621276855
Batch 13/64 loss: 3.687025308609009
Batch 14/64 loss: 3.476532459259033
Batch 15/64 loss: 3.3890042304992676
Batch 16/64 loss: 3.501215934753418
Batch 17/64 loss: 3.4949920177459717
Batch 18/64 loss: 3.564662218093872
Batch 19/64 loss: 3.5852432250976562
Batch 20/64 loss: 3.3901917934417725
Batch 21/64 loss: 3.6806492805480957
Batch 22/64 loss: 3.4150753021240234
Batch 23/64 loss: 3.528250217437744
Batch 24/64 loss: 3.5161919593811035
Batch 25/64 loss: 3.4577927589416504
Batch 26/64 loss: 3.5336294174194336
Batch 27/64 loss: 3.3458666801452637
Batch 28/64 loss: 3.4861721992492676
Batch 29/64 loss: 3.346181631088257
Batch 30/64 loss: 3.5373575687408447
Batch 31/64 loss: 3.4007718563079834
Batch 32/64 loss: 3.5306379795074463
Batch 33/64 loss: 3.4927661418914795
Batch 34/64 loss: 3.3373048305511475
Batch 35/64 loss: 3.339233875274658
Batch 36/64 loss: 3.3897764682769775
Batch 37/64 loss: 3.4584693908691406
Batch 38/64 loss: 3.450375556945801
Batch 39/64 loss: 3.492466449737549
Batch 40/64 loss: 3.47234845161438
Batch 41/64 loss: 3.4244275093078613
Batch 42/64 loss: 3.44748854637146
Batch 43/64 loss: 3.4256389141082764
Batch 44/64 loss: 3.5634877681732178
Batch 45/64 loss: 3.42907452583313
Batch 46/64 loss: 3.430973768234253
Batch 47/64 loss: 3.378445863723755
Batch 48/64 loss: 3.361583709716797
Batch 49/64 loss: 3.3073627948760986
Batch 50/64 loss: 3.51631236076355
Batch 51/64 loss: 3.350083351135254
Batch 52/64 loss: 3.436196804046631
Batch 53/64 loss: 3.55440354347229
Batch 54/64 loss: 3.349196195602417
Batch 55/64 loss: 3.5946784019470215
Batch 56/64 loss: 3.454315423965454
Batch 57/64 loss: 3.5027120113372803
Batch 58/64 loss: 3.4424452781677246
Batch 59/64 loss: 3.5168092250823975
Batch 60/64 loss: 3.4960572719573975
Batch 61/64 loss: 3.342426061630249
Batch 62/64 loss: 3.388432264328003
Batch 63/64 loss: 3.257559061050415
Batch 64/64 loss: 1.2158856391906738
Epoch 48  Train loss: 3.4436945204641303  Val loss: 3.3701619675888637
Saving best model, epoch: 48
Epoch 49
-------------------------------
Batch 1/64 loss: 3.601680278778076
Batch 2/64 loss: 3.469810962677002
Batch 3/64 loss: 3.487035036087036
Batch 4/64 loss: 3.363584041595459
Batch 5/64 loss: 3.336491584777832
Batch 6/64 loss: 3.5903468132019043
Batch 7/64 loss: 3.26165771484375
Batch 8/64 loss: 3.359589099884033
Batch 9/64 loss: 3.4861958026885986
Batch 10/64 loss: 3.4165687561035156
Batch 11/64 loss: 3.4342803955078125
Batch 12/64 loss: 3.535874843597412
Batch 13/64 loss: 3.5734245777130127
Batch 14/64 loss: 3.5666182041168213
Batch 15/64 loss: 3.472443103790283
Batch 16/64 loss: 3.4967753887176514
Batch 17/64 loss: 3.530273199081421
Batch 18/64 loss: 3.4852163791656494
Batch 19/64 loss: 3.3293941020965576
Batch 20/64 loss: 3.4907193183898926
Batch 21/64 loss: 3.415665626525879
Batch 22/64 loss: 3.3385565280914307
Batch 23/64 loss: 3.527883291244507
Batch 24/64 loss: 3.411275863647461
Batch 25/64 loss: 3.4520726203918457
Batch 26/64 loss: 3.360337257385254
Batch 27/64 loss: 3.4522197246551514
Batch 28/64 loss: 3.4636447429656982
Batch 29/64 loss: 3.5633747577667236
Batch 30/64 loss: 3.5156233310699463
Batch 31/64 loss: 3.4461987018585205
Batch 32/64 loss: 3.6047022342681885
Batch 33/64 loss: 3.558551073074341
Batch 34/64 loss: 3.4651498794555664
Batch 35/64 loss: 3.4895429611206055
Batch 36/64 loss: 3.3992953300476074
Batch 37/64 loss: 3.5378730297088623
Batch 38/64 loss: 3.504666805267334
Batch 39/64 loss: 3.429666757583618
Batch 40/64 loss: 3.462819814682007
Batch 41/64 loss: 3.4493606090545654
Batch 42/64 loss: 3.415224552154541
Batch 43/64 loss: 3.43559193611145
Batch 44/64 loss: 3.5919792652130127
Batch 45/64 loss: 3.4831955432891846
Batch 46/64 loss: 3.5339794158935547
Batch 47/64 loss: 3.4035804271698
Batch 48/64 loss: 3.610018491744995
Batch 49/64 loss: 3.5118329524993896
Batch 50/64 loss: 3.4721038341522217
Batch 51/64 loss: 3.645905017852783
Batch 52/64 loss: 3.4245450496673584
Batch 53/64 loss: 3.434648036956787
Batch 54/64 loss: 3.5604488849639893
Batch 55/64 loss: 3.3421926498413086
Batch 56/64 loss: 3.4654178619384766
Batch 57/64 loss: 3.5652713775634766
Batch 58/64 loss: 3.5440690517425537
Batch 59/64 loss: 3.5127713680267334
Batch 60/64 loss: 3.5057637691497803
Batch 61/64 loss: 3.426649570465088
Batch 62/64 loss: 3.4439988136291504
Batch 63/64 loss: 3.3675050735473633
Batch 64/64 loss: 1.648693561553955
Epoch 49  Train loss: 3.4520733122732126  Val loss: 3.3618130307017324
Saving best model, epoch: 49
Epoch 50
-------------------------------
Batch 1/64 loss: 3.4737460613250732
Batch 2/64 loss: 3.4114487171173096
Batch 3/64 loss: 3.469214677810669
Batch 4/64 loss: 3.40010929107666
Batch 5/64 loss: 3.459442377090454
Batch 6/64 loss: 3.3680343627929688
Batch 7/64 loss: 3.3783693313598633
Batch 8/64 loss: 3.297983169555664
Batch 9/64 loss: 3.4321954250335693
Batch 10/64 loss: 3.3607804775238037
Batch 11/64 loss: 3.4393837451934814
Batch 12/64 loss: 3.4419493675231934
Batch 13/64 loss: 3.55007004737854
Batch 14/64 loss: 3.3211236000061035
Batch 15/64 loss: 3.5414040088653564
Batch 16/64 loss: 3.551955461502075
Batch 17/64 loss: 3.3612868785858154
Batch 18/64 loss: 3.3736536502838135
Batch 19/64 loss: 3.435213088989258
Batch 20/64 loss: 3.397810220718384
Batch 21/64 loss: 3.4152207374572754
Batch 22/64 loss: 3.482578754425049
Batch 23/64 loss: 3.6332240104675293
Batch 24/64 loss: 3.3188278675079346
Batch 25/64 loss: 3.4650256633758545
Batch 26/64 loss: 3.632786512374878
Batch 27/64 loss: 3.367208242416382
Batch 28/64 loss: 3.585667610168457
Batch 29/64 loss: 3.3824830055236816
Batch 30/64 loss: 3.5771186351776123
Batch 31/64 loss: 3.562361001968384
Batch 32/64 loss: 3.495621919631958
Batch 33/64 loss: 3.3742308616638184
Batch 34/64 loss: 3.3557188510894775
Batch 35/64 loss: 3.4559824466705322
Batch 36/64 loss: 3.5310285091400146
Batch 37/64 loss: 3.3735320568084717
Batch 38/64 loss: 3.484884262084961
Batch 39/64 loss: 3.431567430496216
Batch 40/64 loss: 3.3524327278137207
Batch 41/64 loss: 3.4618773460388184
Batch 42/64 loss: 3.421586036682129
Batch 43/64 loss: 3.557399272918701
Batch 44/64 loss: 3.4085748195648193
Batch 45/64 loss: 3.6746103763580322
Batch 46/64 loss: 3.339886426925659
Batch 47/64 loss: 3.5633082389831543
Batch 48/64 loss: 3.549687147140503
Batch 49/64 loss: 3.44452166557312
Batch 50/64 loss: 3.305079221725464
Batch 51/64 loss: 3.4632723331451416
Batch 52/64 loss: 3.3191685676574707
Batch 53/64 loss: 3.3610048294067383
Batch 54/64 loss: 3.4834554195404053
Batch 55/64 loss: 3.3766090869903564
Batch 56/64 loss: 3.2940514087677
Batch 57/64 loss: 3.376194477081299
Batch 58/64 loss: 3.389738082885742
Batch 59/64 loss: 3.249854564666748
Batch 60/64 loss: 3.286221504211426
Batch 61/64 loss: 3.3955440521240234
Batch 62/64 loss: 3.3581442832946777
Batch 63/64 loss: 3.322683811187744
Batch 64/64 loss: 0.8638882637023926
Epoch 50  Train loss: 3.400675517437505  Val loss: 3.2806734661875723
Saving best model, epoch: 50
Epoch 51
-------------------------------
Batch 1/64 loss: 3.256354570388794
Batch 2/64 loss: 3.289191246032715
Batch 3/64 loss: 3.3586838245391846
Batch 4/64 loss: 3.363590717315674
Batch 5/64 loss: 3.352961301803589
Batch 6/64 loss: 3.350369691848755
Batch 7/64 loss: 3.2734158039093018
Batch 8/64 loss: 3.333486318588257
Batch 9/64 loss: 3.571010112762451
Batch 10/64 loss: 3.3882553577423096
Batch 11/64 loss: 3.382850170135498
Batch 12/64 loss: 3.4047274589538574
Batch 13/64 loss: 3.248267650604248
Batch 14/64 loss: 3.335663318634033
Batch 15/64 loss: 3.386596202850342
Batch 16/64 loss: 3.4623231887817383
Batch 17/64 loss: 3.5663254261016846
Batch 18/64 loss: 3.4233570098876953
Batch 19/64 loss: 3.4784889221191406
Batch 20/64 loss: 3.402486562728882
Batch 21/64 loss: 3.4705235958099365
Batch 22/64 loss: 3.281851053237915
Batch 23/64 loss: 3.4686975479125977
Batch 24/64 loss: 3.3548641204833984
Batch 25/64 loss: 3.4167733192443848
Batch 26/64 loss: 3.4191815853118896
Batch 27/64 loss: 3.443824529647827
Batch 28/64 loss: 3.296398401260376
Batch 29/64 loss: 3.329357385635376
Batch 30/64 loss: 3.187242031097412
Batch 31/64 loss: 3.2996838092803955
Batch 32/64 loss: 3.3194944858551025
Batch 33/64 loss: 3.391371726989746
Batch 34/64 loss: 3.3063695430755615
Batch 35/64 loss: 3.415354013442993
Batch 36/64 loss: 3.370586395263672
Batch 37/64 loss: 3.2517738342285156
Batch 38/64 loss: 3.2544052600860596
Batch 39/64 loss: 3.234050750732422
Batch 40/64 loss: 3.271878719329834
Batch 41/64 loss: 3.3256638050079346
Batch 42/64 loss: 3.4111053943634033
Batch 43/64 loss: 3.416257858276367
Batch 44/64 loss: 3.194173574447632
Batch 45/64 loss: 3.2933707237243652
Batch 46/64 loss: 3.3579511642456055
Batch 47/64 loss: 3.3502674102783203
Batch 48/64 loss: 3.7101030349731445
Batch 49/64 loss: 3.4383468627929688
Batch 50/64 loss: 3.4344067573547363
Batch 51/64 loss: 3.5871763229370117
Batch 52/64 loss: 3.3183951377868652
Batch 53/64 loss: 3.830754280090332
Batch 54/64 loss: 3.484562635421753
Batch 55/64 loss: 3.4732258319854736
Batch 56/64 loss: 3.544931173324585
Batch 57/64 loss: 3.4311392307281494
Batch 58/64 loss: 3.4807121753692627
Batch 59/64 loss: 3.7690398693084717
Batch 60/64 loss: 3.5216116905212402
Batch 61/64 loss: 3.6875455379486084
Batch 62/64 loss: 3.4287161827087402
Batch 63/64 loss: 3.490962505340576
Batch 64/64 loss: 1.2380714416503906
Epoch 51  Train loss: 3.377585250256108  Val loss: 3.471464042401396
Epoch 52
-------------------------------
Batch 1/64 loss: 3.425384283065796
Batch 2/64 loss: 3.3317244052886963
Batch 3/64 loss: 3.751227855682373
Batch 4/64 loss: 3.4682939052581787
Batch 5/64 loss: 3.6852612495422363
Batch 6/64 loss: 3.4306204319000244
Batch 7/64 loss: 3.4606637954711914
Batch 8/64 loss: 3.4791853427886963
Batch 9/64 loss: 3.3961822986602783
Batch 10/64 loss: 3.4219815731048584
Batch 11/64 loss: 3.2476232051849365
Batch 12/64 loss: 3.3593320846557617
Batch 13/64 loss: 3.365859031677246
Batch 14/64 loss: 3.3527016639709473
Batch 15/64 loss: 3.528223752975464
Batch 16/64 loss: 3.2705068588256836
Batch 17/64 loss: 3.430476427078247
Batch 18/64 loss: 3.4437808990478516
Batch 19/64 loss: 3.3334507942199707
Batch 20/64 loss: 3.3018856048583984
Batch 21/64 loss: 3.2262260913848877
Batch 22/64 loss: 3.339412212371826
Batch 23/64 loss: 3.461271047592163
Batch 24/64 loss: 3.1997880935668945
Batch 25/64 loss: 3.4368743896484375
Batch 26/64 loss: 3.2746639251708984
Batch 27/64 loss: 3.190295457839966
Batch 28/64 loss: 3.383676528930664
Batch 29/64 loss: 3.267185926437378
Batch 30/64 loss: 3.2150697708129883
Batch 31/64 loss: 3.5610764026641846
Batch 32/64 loss: 3.4917993545532227
Batch 33/64 loss: 3.421642303466797
Batch 34/64 loss: 3.2595009803771973
Batch 35/64 loss: 3.2522621154785156
Batch 36/64 loss: 3.0756382942199707
Batch 37/64 loss: 3.447603702545166
Batch 38/64 loss: 3.327144145965576
Batch 39/64 loss: 3.281440019607544
Batch 40/64 loss: 3.293145179748535
Batch 41/64 loss: 3.3345704078674316
Batch 42/64 loss: 3.30694580078125
Batch 43/64 loss: 3.3512966632843018
Batch 44/64 loss: 3.2871451377868652
Batch 45/64 loss: 3.256211280822754
Batch 46/64 loss: 3.2676026821136475
Batch 47/64 loss: 3.2582027912139893
Batch 48/64 loss: 3.407579183578491
Batch 49/64 loss: 3.242713689804077
Batch 50/64 loss: 3.3594958782196045
Batch 51/64 loss: 3.4078285694122314
Batch 52/64 loss: 3.4198355674743652
Batch 53/64 loss: 3.2540528774261475
Batch 54/64 loss: 3.3853535652160645
Batch 55/64 loss: 3.2066826820373535
Batch 56/64 loss: 3.362227439880371
Batch 57/64 loss: 3.274414300918579
Batch 58/64 loss: 3.3086764812469482
Batch 59/64 loss: 3.215167999267578
Batch 60/64 loss: 3.1875503063201904
Batch 61/64 loss: 3.2619528770446777
Batch 62/64 loss: 3.338210105895996
Batch 63/64 loss: 3.318042278289795
Batch 64/64 loss: 0.9051408767700195
Epoch 52  Train loss: 3.318912872613645  Val loss: 3.2008163969950987
Saving best model, epoch: 52
Epoch 53
-------------------------------
Batch 1/64 loss: 3.372746706008911
Batch 2/64 loss: 3.25192928314209
Batch 3/64 loss: 3.1379480361938477
Batch 4/64 loss: 3.123910427093506
Batch 5/64 loss: 3.3451762199401855
Batch 6/64 loss: 3.3786563873291016
Batch 7/64 loss: 3.336505651473999
Batch 8/64 loss: 3.31514310836792
Batch 9/64 loss: 3.3287549018859863
Batch 10/64 loss: 3.3924612998962402
Batch 11/64 loss: 3.402116298675537
Batch 12/64 loss: 3.225426435470581
Batch 13/64 loss: 3.1675074100494385
Batch 14/64 loss: 3.2165510654449463
Batch 15/64 loss: 3.2522573471069336
Batch 16/64 loss: 3.230637311935425
Batch 17/64 loss: 3.2880606651306152
Batch 18/64 loss: 3.308312177658081
Batch 19/64 loss: 3.2040278911590576
Batch 20/64 loss: 3.364407777786255
Batch 21/64 loss: 3.3033835887908936
Batch 22/64 loss: 3.2997689247131348
Batch 23/64 loss: 3.341432571411133
Batch 24/64 loss: 3.2890665531158447
Batch 25/64 loss: 3.3501970767974854
Batch 26/64 loss: 3.2376248836517334
Batch 27/64 loss: 3.2741169929504395
Batch 28/64 loss: 3.217015266418457
Batch 29/64 loss: 3.237516164779663
Batch 30/64 loss: 3.274103879928589
Batch 31/64 loss: 3.3835654258728027
Batch 32/64 loss: 3.4632740020751953
Batch 33/64 loss: 3.2060089111328125
Batch 34/64 loss: 3.316922187805176
Batch 35/64 loss: 3.5048978328704834
Batch 36/64 loss: 3.242293357849121
Batch 37/64 loss: 3.2120680809020996
Batch 38/64 loss: 3.2464945316314697
Batch 39/64 loss: 3.4490749835968018
Batch 40/64 loss: 3.389824867248535
Batch 41/64 loss: 3.461216449737549
Batch 42/64 loss: 3.4467458724975586
Batch 43/64 loss: 3.2644290924072266
Batch 44/64 loss: 3.3490970134735107
Batch 45/64 loss: 3.2694814205169678
Batch 46/64 loss: 3.263153553009033
Batch 47/64 loss: 3.317146062850952
Batch 48/64 loss: 3.4595091342926025
Batch 49/64 loss: 3.4343278408050537
Batch 50/64 loss: 3.299853801727295
Batch 51/64 loss: 3.2684433460235596
Batch 52/64 loss: 3.2945384979248047
Batch 53/64 loss: 3.299551248550415
Batch 54/64 loss: 3.4023423194885254
Batch 55/64 loss: 3.319302558898926
Batch 56/64 loss: 3.3298051357269287
Batch 57/64 loss: 3.3598058223724365
Batch 58/64 loss: 3.2592482566833496
Batch 59/64 loss: 3.4089667797088623
Batch 60/64 loss: 3.177410125732422
Batch 61/64 loss: 3.2534966468811035
Batch 62/64 loss: 3.2977285385131836
Batch 63/64 loss: 3.295518398284912
Batch 64/64 loss: 0.8990373611450195
Epoch 53  Train loss: 3.2797895281922584  Val loss: 3.208740444117805
Epoch 54
-------------------------------
Batch 1/64 loss: 3.2247982025146484
Batch 2/64 loss: 3.416743040084839
Batch 3/64 loss: 3.4220826625823975
Batch 4/64 loss: 3.3191518783569336
Batch 5/64 loss: 3.2944793701171875
Batch 6/64 loss: 3.362724781036377
Batch 7/64 loss: 3.3274521827697754
Batch 8/64 loss: 3.4495389461517334
Batch 9/64 loss: 3.6065428256988525
Batch 10/64 loss: 3.1635165214538574
Batch 11/64 loss: 3.3688883781433105
Batch 12/64 loss: 3.247265338897705
Batch 13/64 loss: 3.330223798751831
Batch 14/64 loss: 3.2204477787017822
Batch 15/64 loss: 3.18225359916687
Batch 16/64 loss: 3.2244505882263184
Batch 17/64 loss: 3.309075355529785
Batch 18/64 loss: 3.3536570072174072
Batch 19/64 loss: 3.286114454269409
Batch 20/64 loss: 3.232776641845703
Batch 21/64 loss: 3.295214891433716
Batch 22/64 loss: 3.2230935096740723
Batch 23/64 loss: 3.2624971866607666
Batch 24/64 loss: 3.282254219055176
Batch 25/64 loss: 3.146024703979492
Batch 26/64 loss: 3.264406204223633
Batch 27/64 loss: 3.15901517868042
Batch 28/64 loss: 3.4704508781433105
Batch 29/64 loss: 3.190528154373169
Batch 30/64 loss: 3.2784717082977295
Batch 31/64 loss: 3.1757216453552246
Batch 32/64 loss: 3.3110663890838623
Batch 33/64 loss: 3.2073440551757812
Batch 34/64 loss: 3.608315944671631
Batch 35/64 loss: 3.3186702728271484
Batch 36/64 loss: 3.315901756286621
Batch 37/64 loss: 3.3854401111602783
Batch 38/64 loss: 3.2865943908691406
Batch 39/64 loss: 3.1338963508605957
Batch 40/64 loss: 3.2905218601226807
Batch 41/64 loss: 3.3498048782348633
Batch 42/64 loss: 3.3243513107299805
Batch 43/64 loss: 3.385375499725342
Batch 44/64 loss: 3.1852540969848633
Batch 45/64 loss: 3.3101720809936523
Batch 46/64 loss: 3.5115838050842285
Batch 47/64 loss: 3.2997429370880127
Batch 48/64 loss: 3.5066001415252686
Batch 49/64 loss: 3.1987249851226807
Batch 50/64 loss: 3.277879476547241
Batch 51/64 loss: 3.28429913520813
Batch 52/64 loss: 3.16995906829834
Batch 53/64 loss: 3.2318930625915527
Batch 54/64 loss: 3.229586601257324
Batch 55/64 loss: 3.4688987731933594
Batch 56/64 loss: 3.145528554916382
Batch 57/64 loss: 3.1796483993530273
Batch 58/64 loss: 3.2798571586608887
Batch 59/64 loss: 3.3412468433380127
Batch 60/64 loss: 3.189882516860962
Batch 61/64 loss: 3.2887465953826904
Batch 62/64 loss: 3.3360533714294434
Batch 63/64 loss: 3.2223637104034424
Batch 64/64 loss: 0.9203047752380371
Epoch 54  Train loss: 3.268318342695049  Val loss: 3.1978053718907726
Saving best model, epoch: 54
Epoch 55
-------------------------------
Batch 1/64 loss: 3.261315107345581
Batch 2/64 loss: 3.34159779548645
Batch 3/64 loss: 3.120854377746582
Batch 4/64 loss: 3.2402162551879883
Batch 5/64 loss: 3.1519322395324707
Batch 6/64 loss: 3.3034017086029053
Batch 7/64 loss: 3.175023317337036
Batch 8/64 loss: 3.405836582183838
Batch 9/64 loss: 3.467707395553589
Batch 10/64 loss: 3.155106544494629
Batch 11/64 loss: 3.4552531242370605
Batch 12/64 loss: 3.090740919113159
Batch 13/64 loss: 3.384371519088745
Batch 14/64 loss: 3.233896017074585
Batch 15/64 loss: 3.262901544570923
Batch 16/64 loss: 3.3205413818359375
Batch 17/64 loss: 3.3276119232177734
Batch 18/64 loss: 3.25931715965271
Batch 19/64 loss: 3.2763445377349854
Batch 20/64 loss: 3.184452772140503
Batch 21/64 loss: 3.3327667713165283
Batch 22/64 loss: 3.1363942623138428
Batch 23/64 loss: 3.265846014022827
Batch 24/64 loss: 3.3159899711608887
Batch 25/64 loss: 3.5237720012664795
Batch 26/64 loss: 3.269467830657959
Batch 27/64 loss: 3.2961299419403076
Batch 28/64 loss: 3.229405641555786
Batch 29/64 loss: 3.292097806930542
Batch 30/64 loss: 3.0211474895477295
Batch 31/64 loss: 3.2859902381896973
Batch 32/64 loss: 3.1273746490478516
Batch 33/64 loss: 3.3039636611938477
Batch 34/64 loss: 3.4364027976989746
Batch 35/64 loss: 3.318681240081787
Batch 36/64 loss: 3.4670047760009766
Batch 37/64 loss: 3.2855641841888428
Batch 38/64 loss: 3.4076311588287354
Batch 39/64 loss: 3.241877317428589
Batch 40/64 loss: 3.2216644287109375
Batch 41/64 loss: 3.2672300338745117
Batch 42/64 loss: 3.2097108364105225
Batch 43/64 loss: 3.3276147842407227
Batch 44/64 loss: 3.0659239292144775
Batch 45/64 loss: 3.187753677368164
Batch 46/64 loss: 3.218973159790039
Batch 47/64 loss: 3.3604345321655273
Batch 48/64 loss: 3.3986105918884277
Batch 49/64 loss: 3.2106149196624756
Batch 50/64 loss: 3.2469608783721924
Batch 51/64 loss: 3.241626262664795
Batch 52/64 loss: 3.1729066371917725
Batch 53/64 loss: 3.2421023845672607
Batch 54/64 loss: 3.2017903327941895
Batch 55/64 loss: 3.3674049377441406
Batch 56/64 loss: 3.4271559715270996
Batch 57/64 loss: 3.223142147064209
Batch 58/64 loss: 3.316692352294922
Batch 59/64 loss: 3.3363378047943115
Batch 60/64 loss: 3.30242657661438
Batch 61/64 loss: 3.187915802001953
Batch 62/64 loss: 3.3135135173797607
Batch 63/64 loss: 3.2374885082244873
Batch 64/64 loss: 0.8785929679870605
Epoch 55  Train loss: 3.245817564048019  Val loss: 3.2655430397217216
Epoch 56
-------------------------------
Batch 1/64 loss: 3.4305901527404785
Batch 2/64 loss: 3.6606905460357666
Batch 3/64 loss: 3.1641738414764404
Batch 4/64 loss: 3.238365411758423
Batch 5/64 loss: 3.2778584957122803
Batch 6/64 loss: 3.4307501316070557
Batch 7/64 loss: 3.4015591144561768
Batch 8/64 loss: 3.3374977111816406
Batch 9/64 loss: 3.387577772140503
Batch 10/64 loss: 3.274625778198242
Batch 11/64 loss: 3.091508150100708
Batch 12/64 loss: 3.1668620109558105
Batch 13/64 loss: 3.260979413986206
Batch 14/64 loss: 3.184720516204834
Batch 15/64 loss: 3.3918380737304688
Batch 16/64 loss: 3.162368059158325
Batch 17/64 loss: 3.261096715927124
Batch 18/64 loss: 3.2817370891571045
Batch 19/64 loss: 3.261882781982422
Batch 20/64 loss: 3.10776424407959
Batch 21/64 loss: 3.1991448402404785
Batch 22/64 loss: 3.135209083557129
Batch 23/64 loss: 3.192063570022583
Batch 24/64 loss: 3.2573699951171875
Batch 25/64 loss: 3.1222453117370605
Batch 26/64 loss: 3.213777542114258
Batch 27/64 loss: 3.161383628845215
Batch 28/64 loss: 3.068756580352783
Batch 29/64 loss: 3.2849740982055664
Batch 30/64 loss: 3.151157855987549
Batch 31/64 loss: 3.1587796211242676
Batch 32/64 loss: 3.1588170528411865
Batch 33/64 loss: 3.2035703659057617
Batch 34/64 loss: 3.2088913917541504
Batch 35/64 loss: 3.123709201812744
Batch 36/64 loss: 3.3368923664093018
Batch 37/64 loss: 3.0861613750457764
Batch 38/64 loss: 3.3329715728759766
Batch 39/64 loss: 3.158832550048828
Batch 40/64 loss: 3.338820695877075
Batch 41/64 loss: 3.1876583099365234
Batch 42/64 loss: 3.133024215698242
Batch 43/64 loss: 3.109440803527832
Batch 44/64 loss: 3.1155948638916016
Batch 45/64 loss: 3.1500086784362793
Batch 46/64 loss: 3.205393075942993
Batch 47/64 loss: 3.220024585723877
Batch 48/64 loss: 3.486734390258789
Batch 49/64 loss: 3.1869044303894043
Batch 50/64 loss: 3.1777870655059814
Batch 51/64 loss: 3.635669231414795
Batch 52/64 loss: 3.117412805557251
Batch 53/64 loss: 3.1972877979278564
Batch 54/64 loss: 3.272488832473755
Batch 55/64 loss: 3.1773955821990967
Batch 56/64 loss: 3.140749931335449
Batch 57/64 loss: 3.2964038848876953
Batch 58/64 loss: 3.065040349960327
Batch 59/64 loss: 3.074063539505005
Batch 60/64 loss: 3.1079254150390625
Batch 61/64 loss: 3.0948033332824707
Batch 62/64 loss: 3.2266621589660645
Batch 63/64 loss: 3.0979831218719482
Batch 64/64 loss: 0.5811657905578613
Epoch 56  Train loss: 3.193416556190042  Val loss: 3.066585711187513
Saving best model, epoch: 56
Epoch 57
-------------------------------
Batch 1/64 loss: 3.1366772651672363
Batch 2/64 loss: 3.124826431274414
Batch 3/64 loss: 3.2323379516601562
Batch 4/64 loss: 3.076657772064209
Batch 5/64 loss: 3.2163467407226562
Batch 6/64 loss: 3.3442673683166504
Batch 7/64 loss: 3.1154513359069824
Batch 8/64 loss: 3.2859740257263184
Batch 9/64 loss: 3.172919273376465
Batch 10/64 loss: 3.3381991386413574
Batch 11/64 loss: 3.160848617553711
Batch 12/64 loss: 3.087808609008789
Batch 13/64 loss: 3.117802143096924
Batch 14/64 loss: 3.0756354331970215
Batch 15/64 loss: 3.1899447441101074
Batch 16/64 loss: 3.0515127182006836
Batch 17/64 loss: 3.022002696990967
Batch 18/64 loss: 3.1382250785827637
Batch 19/64 loss: 3.352827548980713
Batch 20/64 loss: 3.196074962615967
Batch 21/64 loss: 3.421604633331299
Batch 22/64 loss: 3.046093463897705
Batch 23/64 loss: 3.2011704444885254
Batch 24/64 loss: 3.183485507965088
Batch 25/64 loss: 3.1629815101623535
Batch 26/64 loss: 3.1307902336120605
Batch 27/64 loss: 2.9417600631713867
Batch 28/64 loss: 3.103849411010742
Batch 29/64 loss: 3.0642871856689453
Batch 30/64 loss: 3.179494857788086
Batch 31/64 loss: 3.180102825164795
Batch 32/64 loss: 3.2675588130950928
Batch 33/64 loss: 3.237475872039795
Batch 34/64 loss: 3.086693525314331
Batch 35/64 loss: 3.0701704025268555
Batch 36/64 loss: 3.106119155883789
Batch 37/64 loss: 3.142815113067627
Batch 38/64 loss: 3.149949073791504
Batch 39/64 loss: 3.290626287460327
Batch 40/64 loss: 2.9746527671813965
Batch 41/64 loss: 3.2027125358581543
Batch 42/64 loss: 3.19012188911438
Batch 43/64 loss: 3.1964542865753174
Batch 44/64 loss: 3.1638951301574707
Batch 45/64 loss: 3.061312198638916
Batch 46/64 loss: 3.0564498901367188
Batch 47/64 loss: 3.2301888465881348
Batch 48/64 loss: 3.1185057163238525
Batch 49/64 loss: 3.117039203643799
Batch 50/64 loss: 3.0076041221618652
Batch 51/64 loss: 3.0464935302734375
Batch 52/64 loss: 3.18168044090271
Batch 53/64 loss: 3.171574115753174
Batch 54/64 loss: 3.3890693187713623
Batch 55/64 loss: 3.191967487335205
Batch 56/64 loss: 3.0728797912597656
Batch 57/64 loss: 3.45621919631958
Batch 58/64 loss: 3.096177101135254
Batch 59/64 loss: 3.1681525707244873
Batch 60/64 loss: 3.3204174041748047
Batch 61/64 loss: 3.157022476196289
Batch 62/64 loss: 3.106532573699951
Batch 63/64 loss: 3.120366334915161
Batch 64/64 loss: 0.7248106002807617
Epoch 57  Train loss: 3.1332465115715475  Val loss: 3.011436416521105
Saving best model, epoch: 57
Epoch 58
-------------------------------
Batch 1/64 loss: 3.199176788330078
Batch 2/64 loss: 3.0373711585998535
Batch 3/64 loss: 2.9600982666015625
Batch 4/64 loss: 2.913632869720459
Batch 5/64 loss: 3.1459670066833496
Batch 6/64 loss: 3.2631943225860596
Batch 7/64 loss: 3.540273666381836
Batch 8/64 loss: 3.327136993408203
Batch 9/64 loss: 3.1540188789367676
Batch 10/64 loss: 3.1297097206115723
Batch 11/64 loss: 2.983051300048828
Batch 12/64 loss: 3.482839584350586
Batch 13/64 loss: 3.087339401245117
Batch 14/64 loss: 3.104278564453125
Batch 15/64 loss: 3.0680594444274902
Batch 16/64 loss: 3.0952160358428955
Batch 17/64 loss: 3.0964388847351074
Batch 18/64 loss: 3.234537363052368
Batch 19/64 loss: 3.125791072845459
Batch 20/64 loss: 2.9664406776428223
Batch 21/64 loss: 3.096573829650879
Batch 22/64 loss: 3.069793462753296
Batch 23/64 loss: 2.9914722442626953
Batch 24/64 loss: 3.3161919116973877
Batch 25/64 loss: 3.148432970046997
Batch 26/64 loss: 3.0628085136413574
Batch 27/64 loss: 3.0711731910705566
Batch 28/64 loss: 3.022304058074951
Batch 29/64 loss: 3.1327545642852783
Batch 30/64 loss: 3.2984297275543213
Batch 31/64 loss: 3.3158347606658936
Batch 32/64 loss: 3.0122461318969727
Batch 33/64 loss: 3.0114550590515137
Batch 34/64 loss: 3.021169900894165
Batch 35/64 loss: 3.015550374984741
Batch 36/64 loss: 3.181549549102783
Batch 37/64 loss: 3.3353171348571777
Batch 38/64 loss: 3.0214972496032715
Batch 39/64 loss: 3.1540322303771973
Batch 40/64 loss: 3.024916648864746
Batch 41/64 loss: 3.0766401290893555
Batch 42/64 loss: 3.074873924255371
Batch 43/64 loss: 3.1386027336120605
Batch 44/64 loss: 3.164186954498291
Batch 45/64 loss: 3.069699764251709
Batch 46/64 loss: 3.0169267654418945
Batch 47/64 loss: 3.3462655544281006
Batch 48/64 loss: 3.3575005531311035
Batch 49/64 loss: 3.1232614517211914
Batch 50/64 loss: 3.150073528289795
Batch 51/64 loss: 3.126509666442871
Batch 52/64 loss: 2.986482620239258
Batch 53/64 loss: 2.919203758239746
Batch 54/64 loss: 2.929576873779297
Batch 55/64 loss: 3.1137614250183105
Batch 56/64 loss: 3.0839877128601074
Batch 57/64 loss: 3.226637363433838
Batch 58/64 loss: 3.2551164627075195
Batch 59/64 loss: 2.9488329887390137
Batch 60/64 loss: 3.0520758628845215
Batch 61/64 loss: 3.1760520935058594
Batch 62/64 loss: 3.2339367866516113
Batch 63/64 loss: 3.1019606590270996
Batch 64/64 loss: 0.6387591361999512
Epoch 58  Train loss: 3.09598918428608  Val loss: 3.009747383930429
Saving best model, epoch: 58
Epoch 59
-------------------------------
Batch 1/64 loss: 3.1022157669067383
Batch 2/64 loss: 3.2356276512145996
Batch 3/64 loss: 3.2369678020477295
Batch 4/64 loss: 3.0868306159973145
Batch 5/64 loss: 3.390819549560547
Batch 6/64 loss: 3.12326717376709
Batch 7/64 loss: 3.132235050201416
Batch 8/64 loss: 3.0007195472717285
Batch 9/64 loss: 3.1655049324035645
Batch 10/64 loss: 3.150280475616455
Batch 11/64 loss: 2.9086523056030273
Batch 12/64 loss: 2.977161407470703
Batch 13/64 loss: 3.2494444847106934
Batch 14/64 loss: 2.969363212585449
Batch 15/64 loss: 2.945115566253662
Batch 16/64 loss: 3.1095638275146484
Batch 17/64 loss: 3.0491085052490234
Batch 18/64 loss: 2.980008602142334
Batch 19/64 loss: 3.119279384613037
Batch 20/64 loss: 2.918025016784668
Batch 21/64 loss: 2.9886908531188965
Batch 22/64 loss: 2.983792304992676
Batch 23/64 loss: 3.0592217445373535
Batch 24/64 loss: 3.4503650665283203
Batch 25/64 loss: 3.060634136199951
Batch 26/64 loss: 2.9927802085876465
Batch 27/64 loss: 3.0621633529663086
Batch 28/64 loss: 3.1762754917144775
Batch 29/64 loss: 2.9622750282287598
Batch 30/64 loss: 2.963067054748535
Batch 31/64 loss: 2.8881125450134277
Batch 32/64 loss: 3.1082468032836914
Batch 33/64 loss: 3.0297489166259766
Batch 34/64 loss: 2.9654836654663086
Batch 35/64 loss: 3.0555953979492188
Batch 36/64 loss: 3.2661056518554688
Batch 37/64 loss: 3.0083417892456055
Batch 38/64 loss: 3.256653070449829
Batch 39/64 loss: 2.864480972290039
Batch 40/64 loss: 3.182192802429199
Batch 41/64 loss: 2.9410500526428223
Batch 42/64 loss: 3.047959804534912
Batch 43/64 loss: 3.007887840270996
Batch 44/64 loss: 3.1636672019958496
Batch 45/64 loss: 3.3305459022521973
Batch 46/64 loss: 3.1921749114990234
Batch 47/64 loss: 3.2103514671325684
Batch 48/64 loss: 2.9692559242248535
Batch 49/64 loss: 2.897148609161377
Batch 50/64 loss: 3.098853826522827
Batch 51/64 loss: 2.9826908111572266
Batch 52/64 loss: 3.1597423553466797
Batch 53/64 loss: 3.055285930633545
Batch 54/64 loss: 3.0148544311523438
Batch 55/64 loss: 3.0183377265930176
Batch 56/64 loss: 3.1779963970184326
Batch 57/64 loss: 3.015204429626465
Batch 58/64 loss: 3.1345326900482178
Batch 59/64 loss: 3.2253637313842773
Batch 60/64 loss: 3.2001242637634277
Batch 61/64 loss: 3.0941076278686523
Batch 62/64 loss: 3.166083812713623
Batch 63/64 loss: 3.232412815093994
Batch 64/64 loss: 0.5353469848632812
Epoch 59  Train loss: 3.057436243693034  Val loss: 3.033048767404458
Epoch 60
-------------------------------
Batch 1/64 loss: 2.9453916549682617
Batch 2/64 loss: 3.187021255493164
Batch 3/64 loss: 3.1631040573120117
Batch 4/64 loss: 3.092097282409668
Batch 5/64 loss: 3.0352835655212402
Batch 6/64 loss: 3.1683387756347656
Batch 7/64 loss: 3.072388172149658
Batch 8/64 loss: 3.2262802124023438
Batch 9/64 loss: 3.2506790161132812
Batch 10/64 loss: 3.0228629112243652
Batch 11/64 loss: 2.917140483856201
Batch 12/64 loss: 2.846196174621582
Batch 13/64 loss: 3.0733566284179688
Batch 14/64 loss: 3.210200309753418
Batch 15/64 loss: 3.132570743560791
Batch 16/64 loss: 3.0685739517211914
Batch 17/64 loss: 3.003058910369873
Batch 18/64 loss: 3.1882169246673584
Batch 19/64 loss: 3.054394483566284
Batch 20/64 loss: 3.099337577819824
Batch 21/64 loss: 3.1323370933532715
Batch 22/64 loss: 3.0244741439819336
Batch 23/64 loss: 2.996121406555176
Batch 24/64 loss: 3.126042604446411
Batch 25/64 loss: 3.114908456802368
Batch 26/64 loss: 3.1333189010620117
Batch 27/64 loss: 3.162238121032715
Batch 28/64 loss: 2.9044957160949707
Batch 29/64 loss: 2.9861249923706055
Batch 30/64 loss: 3.5120861530303955
Batch 31/64 loss: 3.1554198265075684
Batch 32/64 loss: 3.082094669342041
Batch 33/64 loss: 3.10821533203125
Batch 34/64 loss: 2.949958324432373
Batch 35/64 loss: 2.965644359588623
Batch 36/64 loss: 2.960364818572998
Batch 37/64 loss: 3.0421040058135986
Batch 38/64 loss: 3.1097590923309326
Batch 39/64 loss: 2.966291904449463
Batch 40/64 loss: 3.055525779724121
Batch 41/64 loss: 3.1552648544311523
Batch 42/64 loss: 3.068235397338867
Batch 43/64 loss: 3.065462827682495
Batch 44/64 loss: 3.1216254234313965
Batch 45/64 loss: 3.196995496749878
Batch 46/64 loss: 3.0062403678894043
Batch 47/64 loss: 3.1230809688568115
Batch 48/64 loss: 3.248922109603882
Batch 49/64 loss: 3.1601226329803467
Batch 50/64 loss: 3.084757089614868
Batch 51/64 loss: 3.0211377143859863
Batch 52/64 loss: 3.1224894523620605
Batch 53/64 loss: 3.041578769683838
Batch 54/64 loss: 3.0276780128479004
Batch 55/64 loss: 2.893644332885742
Batch 56/64 loss: 3.0089521408081055
Batch 57/64 loss: 2.997056484222412
Batch 58/64 loss: 3.1174893379211426
Batch 59/64 loss: 2.808256149291992
Batch 60/64 loss: 2.9717488288879395
Batch 61/64 loss: 2.9492650032043457
Batch 62/64 loss: 3.0360641479492188
Batch 63/64 loss: 3.010709285736084
Batch 64/64 loss: 0.5485467910766602
Epoch 60  Train loss: 3.0414463641596776  Val loss: 2.842478768522387
Saving best model, epoch: 60
Epoch 61
-------------------------------
Batch 1/64 loss: 2.920131206512451
Batch 2/64 loss: 3.121140480041504
Batch 3/64 loss: 2.9732847213745117
Batch 4/64 loss: 3.174222469329834
Batch 5/64 loss: 3.0130562782287598
Batch 6/64 loss: 2.9881911277770996
Batch 7/64 loss: 2.9878640174865723
Batch 8/64 loss: 3.0576910972595215
Batch 9/64 loss: 3.1533045768737793
Batch 10/64 loss: 2.887662410736084
Batch 11/64 loss: 3.014237880706787
Batch 12/64 loss: 3.11967134475708
Batch 13/64 loss: 2.997555732727051
Batch 14/64 loss: 3.0454797744750977
Batch 15/64 loss: 3.100790500640869
Batch 16/64 loss: 3.1028976440429688
Batch 17/64 loss: 3.015103816986084
Batch 18/64 loss: 2.8415780067443848
Batch 19/64 loss: 2.9234681129455566
Batch 20/64 loss: 3.1242594718933105
Batch 21/64 loss: 2.8394875526428223
Batch 22/64 loss: 2.9622020721435547
Batch 23/64 loss: 2.9424214363098145
Batch 24/64 loss: 3.0356621742248535
Batch 25/64 loss: 3.1161160469055176
Batch 26/64 loss: 2.912139415740967
Batch 27/64 loss: 2.9225001335144043
Batch 28/64 loss: 2.90814208984375
Batch 29/64 loss: 2.977088451385498
Batch 30/64 loss: 2.978292465209961
Batch 31/64 loss: 2.8902387619018555
Batch 32/64 loss: 3.1389551162719727
Batch 33/64 loss: 2.9624853134155273
Batch 34/64 loss: 2.7487082481384277
Batch 35/64 loss: 3.0413570404052734
Batch 36/64 loss: 2.981494426727295
Batch 37/64 loss: 3.0029454231262207
Batch 38/64 loss: 2.9595680236816406
Batch 39/64 loss: 2.8544883728027344
Batch 40/64 loss: 2.930159568786621
Batch 41/64 loss: 2.9714436531066895
Batch 42/64 loss: 3.1906533241271973
Batch 43/64 loss: 2.925045967102051
Batch 44/64 loss: 2.917079448699951
Batch 45/64 loss: 2.8387670516967773
Batch 46/64 loss: 3.051820755004883
Batch 47/64 loss: 2.830559253692627
Batch 48/64 loss: 2.8595938682556152
Batch 49/64 loss: 2.9035277366638184
Batch 50/64 loss: 2.9197330474853516
Batch 51/64 loss: 2.932476043701172
Batch 52/64 loss: 2.937130928039551
Batch 53/64 loss: 3.0295557975769043
Batch 54/64 loss: 3.2393598556518555
Batch 55/64 loss: 2.932410717010498
Batch 56/64 loss: 2.817622184753418
Batch 57/64 loss: 2.7829136848449707
Batch 58/64 loss: 2.8439674377441406
Batch 59/64 loss: 2.8068952560424805
Batch 60/64 loss: 3.011448860168457
Batch 61/64 loss: 3.012218475341797
Batch 62/64 loss: 2.881418228149414
Batch 63/64 loss: 3.0551400184631348
Batch 64/64 loss: 0.27233123779296875
Epoch 61  Train loss: 2.942134475708008  Val loss: 2.751544559124819
Saving best model, epoch: 61
Epoch 62
-------------------------------
Batch 1/64 loss: 2.9133095741271973
Batch 2/64 loss: 2.845820426940918
Batch 3/64 loss: 2.945491313934326
Batch 4/64 loss: 3.045863151550293
Batch 5/64 loss: 2.9842257499694824
Batch 6/64 loss: 3.0729289054870605
Batch 7/64 loss: 2.9755263328552246
Batch 8/64 loss: 2.938692569732666
Batch 9/64 loss: 3.1823949813842773
Batch 10/64 loss: 2.9422831535339355
Batch 11/64 loss: 2.8486180305480957
Batch 12/64 loss: 2.890618324279785
Batch 13/64 loss: 3.1897835731506348
Batch 14/64 loss: 2.898444175720215
Batch 15/64 loss: 2.9652256965637207
Batch 16/64 loss: 3.1306138038635254
Batch 17/64 loss: 2.9250993728637695
Batch 18/64 loss: 2.7798399925231934
Batch 19/64 loss: 2.9512228965759277
Batch 20/64 loss: 3.0232062339782715
Batch 21/64 loss: 2.979224681854248
Batch 22/64 loss: 2.9650325775146484
Batch 23/64 loss: 2.9188876152038574
Batch 24/64 loss: 3.019467353820801
Batch 25/64 loss: 2.8243041038513184
Batch 26/64 loss: 2.816835880279541
Batch 27/64 loss: 3.002870559692383
Batch 28/64 loss: 2.897700786590576
Batch 29/64 loss: 2.8236608505249023
Batch 30/64 loss: 2.898524761199951
Batch 31/64 loss: 2.9913530349731445
Batch 32/64 loss: 2.826749801635742
Batch 33/64 loss: 3.0259504318237305
Batch 34/64 loss: 2.8723931312561035
Batch 35/64 loss: 2.9128684997558594
Batch 36/64 loss: 2.8116064071655273
Batch 37/64 loss: 2.7407002449035645
Batch 38/64 loss: 2.8403491973876953
Batch 39/64 loss: 2.8432822227478027
Batch 40/64 loss: 3.031198024749756
Batch 41/64 loss: 3.028054714202881
Batch 42/64 loss: 2.9611639976501465
Batch 43/64 loss: 2.898627758026123
Batch 44/64 loss: 2.7470602989196777
Batch 45/64 loss: 2.7526278495788574
Batch 46/64 loss: 3.011326789855957
Batch 47/64 loss: 2.9138407707214355
Batch 48/64 loss: 2.896549701690674
Batch 49/64 loss: 3.0305838584899902
Batch 50/64 loss: 2.903562545776367
Batch 51/64 loss: 3.074186325073242
Batch 52/64 loss: 2.7892398834228516
Batch 53/64 loss: 2.8538293838500977
Batch 54/64 loss: 2.8747315406799316
Batch 55/64 loss: 2.789985179901123
Batch 56/64 loss: 3.0972414016723633
Batch 57/64 loss: 2.8597846031188965
Batch 58/64 loss: 2.96053409576416
Batch 59/64 loss: 2.924567222595215
Batch 60/64 loss: 2.93900203704834
Batch 61/64 loss: 3.0523056983947754
Batch 62/64 loss: 2.92378568649292
Batch 63/64 loss: 2.7677483558654785
Batch 64/64 loss: 0.18416690826416016
Epoch 62  Train loss: 2.8969511106902477  Val loss: 2.7152207758008817
Saving best model, epoch: 62
Epoch 63
-------------------------------
Batch 1/64 loss: 3.1036458015441895
Batch 2/64 loss: 3.187532424926758
Batch 3/64 loss: 3.108412265777588
Batch 4/64 loss: 3.127347946166992
Batch 5/64 loss: 3.083385467529297
Batch 6/64 loss: 2.7326693534851074
Batch 7/64 loss: 2.9186925888061523
Batch 8/64 loss: 3.1146702766418457
Batch 9/64 loss: 3.000265598297119
Batch 10/64 loss: 3.038966178894043
Batch 11/64 loss: 2.8893017768859863
Batch 12/64 loss: 2.924757957458496
Batch 13/64 loss: 2.8403825759887695
Batch 14/64 loss: 2.8303818702697754
Batch 15/64 loss: 2.7966341972351074
Batch 16/64 loss: 2.9350156784057617
Batch 17/64 loss: 2.8407273292541504
Batch 18/64 loss: 2.942239284515381
Batch 19/64 loss: 2.7259645462036133
Batch 20/64 loss: 2.9664392471313477
Batch 21/64 loss: 2.7739644050598145
Batch 22/64 loss: 2.808529853820801
Batch 23/64 loss: 2.8710904121398926
Batch 24/64 loss: 3.203545093536377
Batch 25/64 loss: 3.028759479522705
Batch 26/64 loss: 2.8237032890319824
Batch 27/64 loss: 2.9085216522216797
Batch 28/64 loss: 2.8758883476257324
Batch 29/64 loss: 2.902165412902832
Batch 30/64 loss: 2.97503662109375
Batch 31/64 loss: 2.9853053092956543
Batch 32/64 loss: 2.8023409843444824
Batch 33/64 loss: 2.970384120941162
Batch 34/64 loss: 2.9718708992004395
Batch 35/64 loss: 2.7300028800964355
Batch 36/64 loss: 2.825462818145752
Batch 37/64 loss: 3.049142360687256
Batch 38/64 loss: 2.8634204864501953
Batch 39/64 loss: 2.865556240081787
Batch 40/64 loss: 2.9065322875976562
Batch 41/64 loss: 2.7435507774353027
Batch 42/64 loss: 2.912996292114258
Batch 43/64 loss: 3.1958065032958984
Batch 44/64 loss: 2.986635208129883
Batch 45/64 loss: 2.799288272857666
Batch 46/64 loss: 2.854799270629883
Batch 47/64 loss: 2.920189380645752
Batch 48/64 loss: 2.881686210632324
Batch 49/64 loss: 3.0315747261047363
Batch 50/64 loss: 2.8380441665649414
Batch 51/64 loss: 2.7283315658569336
Batch 52/64 loss: 2.7628908157348633
Batch 53/64 loss: 2.765657901763916
Batch 54/64 loss: 2.9165196418762207
Batch 55/64 loss: 2.769113063812256
Batch 56/64 loss: 2.906611442565918
Batch 57/64 loss: 2.917994499206543
Batch 58/64 loss: 2.785923957824707
Batch 59/64 loss: 2.8349356651306152
Batch 60/64 loss: 2.735365867614746
Batch 61/64 loss: 2.931246280670166
Batch 62/64 loss: 2.9721503257751465
Batch 63/64 loss: 2.919588088989258
Batch 64/64 loss: 0.2158184051513672
Epoch 63  Train loss: 2.8787673576205384  Val loss: 2.7353243155987403
Epoch 64
-------------------------------
Batch 1/64 loss: 2.8772454261779785
Batch 2/64 loss: 2.90623140335083
Batch 3/64 loss: 2.8210058212280273
Batch 4/64 loss: 2.7360448837280273
Batch 5/64 loss: 3.0798540115356445
Batch 6/64 loss: 2.886575222015381
Batch 7/64 loss: 2.7431182861328125
Batch 8/64 loss: 2.6515402793884277
Batch 9/64 loss: 2.9743757247924805
Batch 10/64 loss: 2.9545674324035645
Batch 11/64 loss: 2.822538375854492
Batch 12/64 loss: 2.7011947631835938
Batch 13/64 loss: 2.868771553039551
Batch 14/64 loss: 2.954342842102051
Batch 15/64 loss: 2.86263370513916
Batch 16/64 loss: 2.8299217224121094
Batch 17/64 loss: 2.8033018112182617
Batch 18/64 loss: 3.113868236541748
Batch 19/64 loss: 2.7576417922973633
Batch 20/64 loss: 2.9080705642700195
Batch 21/64 loss: 2.909799575805664
Batch 22/64 loss: 2.7997183799743652
Batch 23/64 loss: 2.807607650756836
Batch 24/64 loss: 3.180373191833496
Batch 25/64 loss: 2.926877975463867
Batch 26/64 loss: 2.8615474700927734
Batch 27/64 loss: 3.073512077331543
Batch 28/64 loss: 2.827042579650879
Batch 29/64 loss: 3.0701794624328613
Batch 30/64 loss: 2.9126882553100586
Batch 31/64 loss: 2.8023300170898438
Batch 32/64 loss: 2.888669013977051
Batch 33/64 loss: 2.6884212493896484
Batch 34/64 loss: 2.660527229309082
Batch 35/64 loss: 2.883687973022461
Batch 36/64 loss: 2.7864952087402344
Batch 37/64 loss: 2.811840534210205
Batch 38/64 loss: 2.775871753692627
Batch 39/64 loss: 2.752289295196533
Batch 40/64 loss: 2.814974784851074
Batch 41/64 loss: 2.966940402984619
Batch 42/64 loss: 2.8960156440734863
Batch 43/64 loss: 2.6789650917053223
Batch 44/64 loss: 2.8744091987609863
Batch 45/64 loss: 2.726944923400879
Batch 46/64 loss: 3.0979886054992676
Batch 47/64 loss: 3.007213592529297
Batch 48/64 loss: 2.848977565765381
Batch 49/64 loss: 2.836678981781006
Batch 50/64 loss: 2.769702911376953
Batch 51/64 loss: 2.7797484397888184
Batch 52/64 loss: 2.754354476928711
Batch 53/64 loss: 2.9601235389709473
Batch 54/64 loss: 2.784325122833252
Batch 55/64 loss: 2.6320323944091797
Batch 56/64 loss: 2.861450672149658
Batch 57/64 loss: 2.7812600135803223
Batch 58/64 loss: 2.8225879669189453
Batch 59/64 loss: 2.7672767639160156
Batch 60/64 loss: 2.727105140686035
Batch 61/64 loss: 2.6334357261657715
Batch 62/64 loss: 2.900484561920166
Batch 63/64 loss: 2.9039268493652344
Batch 64/64 loss: 0.35013389587402344
Epoch 64  Train loss: 2.8197936712526808  Val loss: 2.7230756766198017
Epoch 65
-------------------------------
Batch 1/64 loss: 2.95582914352417
Batch 2/64 loss: 2.843618392944336
Batch 3/64 loss: 2.914952278137207
Batch 4/64 loss: 2.7725272178649902
Batch 5/64 loss: 2.806309700012207
Batch 6/64 loss: 2.6987786293029785
Batch 7/64 loss: 2.808863639831543
Batch 8/64 loss: 2.7934842109680176
Batch 9/64 loss: 2.790768623352051
Batch 10/64 loss: 2.8148980140686035
Batch 11/64 loss: 2.7870097160339355
Batch 12/64 loss: 2.829223155975342
Batch 13/64 loss: 2.8602466583251953
Batch 14/64 loss: 2.8109049797058105
Batch 15/64 loss: 2.9145450592041016
Batch 16/64 loss: 2.7170324325561523
Batch 17/64 loss: 2.637442111968994
Batch 18/64 loss: 2.749368190765381
Batch 19/64 loss: 2.985891819000244
Batch 20/64 loss: 2.7096595764160156
Batch 21/64 loss: 2.7152371406555176
Batch 22/64 loss: 2.7110657691955566
Batch 23/64 loss: 2.9036436080932617
Batch 24/64 loss: 2.7330751419067383
Batch 25/64 loss: 2.735382080078125
Batch 26/64 loss: 2.771176815032959
Batch 27/64 loss: 3.0647926330566406
Batch 28/64 loss: 2.9317221641540527
Batch 29/64 loss: 2.790799140930176
Batch 30/64 loss: 2.822772979736328
Batch 31/64 loss: 2.853531837463379
Batch 32/64 loss: 2.761786937713623
Batch 33/64 loss: 2.7308521270751953
Batch 34/64 loss: 2.7800450325012207
Batch 35/64 loss: 2.7314977645874023
Batch 36/64 loss: 2.9139342308044434
Batch 37/64 loss: 2.8951010704040527
Batch 38/64 loss: 2.750214099884033
Batch 39/64 loss: 2.7976608276367188
Batch 40/64 loss: 2.7668137550354004
Batch 41/64 loss: 2.7479248046875
Batch 42/64 loss: 2.978156089782715
Batch 43/64 loss: 2.58951997756958
Batch 44/64 loss: 2.9909005165100098
Batch 45/64 loss: 2.6972150802612305
Batch 46/64 loss: 2.7761950492858887
Batch 47/64 loss: 2.9031925201416016
Batch 48/64 loss: 2.7391252517700195
Batch 49/64 loss: 2.7909226417541504
Batch 50/64 loss: 2.731234073638916
Batch 51/64 loss: 2.70692777633667
Batch 52/64 loss: 2.6446237564086914
Batch 53/64 loss: 2.785510540008545
Batch 54/64 loss: 2.8702120780944824
Batch 55/64 loss: 2.613914966583252
Batch 56/64 loss: 2.7941994667053223
Batch 57/64 loss: 2.953744888305664
Batch 58/64 loss: 2.895939826965332
Batch 59/64 loss: 2.8789262771606445
Batch 60/64 loss: 2.7820076942443848
Batch 61/64 loss: 2.845991611480713
Batch 62/64 loss: 2.8399972915649414
Batch 63/64 loss: 2.9940690994262695
Batch 64/64 loss: 0.16281843185424805
Epoch 65  Train loss: 2.7770199813094796  Val loss: 2.8162239507301567
Epoch 66
-------------------------------
Batch 1/64 loss: 2.729398727416992
Batch 2/64 loss: 2.8453521728515625
Batch 3/64 loss: 2.7511696815490723
Batch 4/64 loss: 2.736166477203369
Batch 5/64 loss: 2.8136110305786133
Batch 6/64 loss: 2.8222975730895996
Batch 7/64 loss: 2.7611312866210938
Batch 8/64 loss: 2.877951145172119
Batch 9/64 loss: 3.1337080001831055
Batch 10/64 loss: 2.6479687690734863
Batch 11/64 loss: 2.88181734085083
Batch 12/64 loss: 2.806011199951172
Batch 13/64 loss: 2.8743557929992676
Batch 14/64 loss: 3.0617446899414062
Batch 15/64 loss: 2.812044620513916
Batch 16/64 loss: 2.8191184997558594
Batch 17/64 loss: 2.855172634124756
Batch 18/64 loss: 2.6104578971862793
Batch 19/64 loss: 2.87520170211792
Batch 20/64 loss: 2.654796600341797
Batch 21/64 loss: 2.9271650314331055
Batch 22/64 loss: 2.7755165100097656
Batch 23/64 loss: 2.8014254570007324
Batch 24/64 loss: 2.8363399505615234
Batch 25/64 loss: 2.6768507957458496
Batch 26/64 loss: 2.7672581672668457
Batch 27/64 loss: 2.6286158561706543
Batch 28/64 loss: 2.742583751678467
Batch 29/64 loss: 2.5482354164123535
Batch 30/64 loss: 2.851315975189209
Batch 31/64 loss: 2.94235897064209
Batch 32/64 loss: 2.7442870140075684
Batch 33/64 loss: 2.5501270294189453
Batch 34/64 loss: 2.914750099182129
Batch 35/64 loss: 2.725759983062744
Batch 36/64 loss: 2.8327879905700684
Batch 37/64 loss: 2.630293846130371
Batch 38/64 loss: 2.885312557220459
Batch 39/64 loss: 2.8452506065368652
Batch 40/64 loss: 2.970059394836426
Batch 41/64 loss: 2.7064623832702637
Batch 42/64 loss: 2.70933198928833
Batch 43/64 loss: 2.8311991691589355
Batch 44/64 loss: 2.817563056945801
Batch 45/64 loss: 2.6057357788085938
Batch 46/64 loss: 2.796555519104004
Batch 47/64 loss: 2.8527488708496094
Batch 48/64 loss: 2.6214871406555176
Batch 49/64 loss: 2.8171310424804688
Batch 50/64 loss: 2.6255812644958496
Batch 51/64 loss: 2.730708122253418
Batch 52/64 loss: 2.5893850326538086
Batch 53/64 loss: 2.5623888969421387
Batch 54/64 loss: 2.637089729309082
Batch 55/64 loss: 2.7872753143310547
Batch 56/64 loss: 2.754892349243164
Batch 57/64 loss: 2.8442630767822266
Batch 58/64 loss: 2.692037582397461
Batch 59/64 loss: 2.682705879211426
Batch 60/64 loss: 2.7814440727233887
Batch 61/64 loss: 2.860708713531494
Batch 62/64 loss: 2.684535503387451
Batch 63/64 loss: 2.8846826553344727
Batch 64/64 loss: 0.09888124465942383
Epoch 66  Train loss: 2.7437779501372694  Val loss: 2.6158085262652526
Saving best model, epoch: 66
Epoch 67
-------------------------------
Batch 1/64 loss: 2.607694625854492
Batch 2/64 loss: 2.7077341079711914
Batch 3/64 loss: 2.7773847579956055
Batch 4/64 loss: 2.703935146331787
Batch 5/64 loss: 2.725050449371338
Batch 6/64 loss: 2.8344082832336426
Batch 7/64 loss: 2.7561984062194824
Batch 8/64 loss: 2.836793899536133
Batch 9/64 loss: 2.7451252937316895
Batch 10/64 loss: 2.938018321990967
Batch 11/64 loss: 2.7073121070861816
Batch 12/64 loss: 2.716090202331543
Batch 13/64 loss: 2.8187222480773926
Batch 14/64 loss: 2.556999683380127
Batch 15/64 loss: 2.5908403396606445
Batch 16/64 loss: 2.6452670097351074
Batch 17/64 loss: 2.779829978942871
Batch 18/64 loss: 2.681037425994873
Batch 19/64 loss: 2.865938663482666
Batch 20/64 loss: 2.6409049034118652
Batch 21/64 loss: 2.810525894165039
Batch 22/64 loss: 2.5781235694885254
Batch 23/64 loss: 2.7759342193603516
Batch 24/64 loss: 2.628170967102051
Batch 25/64 loss: 2.772282600402832
Batch 26/64 loss: 2.7302465438842773
Batch 27/64 loss: 2.594320774078369
Batch 28/64 loss: 2.695221424102783
Batch 29/64 loss: 2.734306812286377
Batch 30/64 loss: 2.7792716026306152
Batch 31/64 loss: 2.6615166664123535
Batch 32/64 loss: 2.756011962890625
Batch 33/64 loss: 2.6672115325927734
Batch 34/64 loss: 2.686262607574463
Batch 35/64 loss: 2.7657947540283203
Batch 36/64 loss: 2.7332396507263184
Batch 37/64 loss: 2.7314372062683105
Batch 38/64 loss: 2.6354899406433105
Batch 39/64 loss: 2.709536075592041
Batch 40/64 loss: 2.711439609527588
Batch 41/64 loss: 2.8700366020202637
Batch 42/64 loss: 2.680194854736328
Batch 43/64 loss: 2.656679630279541
Batch 44/64 loss: 2.8948802947998047
Batch 45/64 loss: 2.6280598640441895
Batch 46/64 loss: 2.8112897872924805
Batch 47/64 loss: 2.7306461334228516
Batch 48/64 loss: 2.644481658935547
Batch 49/64 loss: 2.7846784591674805
Batch 50/64 loss: 2.6792664527893066
Batch 51/64 loss: 2.6836156845092773
Batch 52/64 loss: 2.737027168273926
Batch 53/64 loss: 2.6977391242980957
Batch 54/64 loss: 2.7396020889282227
Batch 55/64 loss: 2.5661048889160156
Batch 56/64 loss: 2.654996871948242
Batch 57/64 loss: 2.919800281524658
Batch 58/64 loss: 2.681722640991211
Batch 59/64 loss: 2.6932311058044434
Batch 60/64 loss: 2.7449913024902344
Batch 61/64 loss: 2.667142391204834
Batch 62/64 loss: 2.7043137550354004
Batch 63/64 loss: 2.7868566513061523
Batch 64/64 loss: 0.14734172821044922
Epoch 67  Train loss: 2.691129321678012  Val loss: 2.519915584026743
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: 2.676474094390869
Batch 2/64 loss: 2.87117338180542
Batch 3/64 loss: 2.63346004486084
Batch 4/64 loss: 2.8109307289123535
Batch 5/64 loss: 2.8371224403381348
Batch 6/64 loss: 2.746321201324463
Batch 7/64 loss: 2.768521785736084
Batch 8/64 loss: 2.6289420127868652
Batch 9/64 loss: 2.7000551223754883
Batch 10/64 loss: 2.8388280868530273
Batch 11/64 loss: 2.633368492126465
Batch 12/64 loss: 2.7432045936584473
Batch 13/64 loss: 2.7893614768981934
Batch 14/64 loss: 2.585289478302002
Batch 15/64 loss: 2.7882819175720215
Batch 16/64 loss: 2.9738821983337402
Batch 17/64 loss: 2.4952707290649414
Batch 18/64 loss: 2.82041072845459
Batch 19/64 loss: 2.732266902923584
Batch 20/64 loss: 2.527524948120117
Batch 21/64 loss: 2.880105495452881
Batch 22/64 loss: 3.2640953063964844
Batch 23/64 loss: 2.8363375663757324
Batch 24/64 loss: 2.8138718605041504
Batch 25/64 loss: 2.6177940368652344
Batch 26/64 loss: 2.681410789489746
Batch 27/64 loss: 2.706088066101074
Batch 28/64 loss: 2.650839328765869
Batch 29/64 loss: 2.6788434982299805
Batch 30/64 loss: 2.5877742767333984
Batch 31/64 loss: 2.5772337913513184
Batch 32/64 loss: 2.87692928314209
Batch 33/64 loss: 2.5887222290039062
Batch 34/64 loss: 2.676055431365967
Batch 35/64 loss: 2.6815929412841797
Batch 36/64 loss: 2.6377148628234863
Batch 37/64 loss: 2.682398796081543
Batch 38/64 loss: 2.7145371437072754
Batch 39/64 loss: 2.586942672729492
Batch 40/64 loss: 2.5108642578125
Batch 41/64 loss: 2.6342034339904785
Batch 42/64 loss: 2.5190625190734863
Batch 43/64 loss: 2.8051881790161133
Batch 44/64 loss: 2.5599803924560547
Batch 45/64 loss: 2.6967854499816895
Batch 46/64 loss: 2.507516860961914
Batch 47/64 loss: 2.609079360961914
Batch 48/64 loss: 2.7519521713256836
Batch 49/64 loss: 2.6962075233459473
Batch 50/64 loss: 2.5710787773132324
Batch 51/64 loss: 2.6162853240966797
Batch 52/64 loss: 2.726134777069092
Batch 53/64 loss: 2.7248706817626953
Batch 54/64 loss: 2.659933567047119
Batch 55/64 loss: 2.4947757720947266
Batch 56/64 loss: 2.613348960876465
Batch 57/64 loss: 2.660201072692871
Batch 58/64 loss: 2.545346736907959
Batch 59/64 loss: 2.7221503257751465
Batch 60/64 loss: 2.680680274963379
Batch 61/64 loss: 2.9419212341308594
Batch 62/64 loss: 2.567582607269287
Batch 63/64 loss: 2.75997257232666
Batch 64/64 loss: -0.24235296249389648
Epoch 68  Train loss: 2.662483699648988  Val loss: 2.4968739539077602
Saving best model, epoch: 68
Epoch 69
-------------------------------
Batch 1/64 loss: 2.6789655685424805
Batch 2/64 loss: 2.8540215492248535
Batch 3/64 loss: 2.624661922454834
Batch 4/64 loss: 2.6483349800109863
Batch 5/64 loss: 2.6906843185424805
Batch 6/64 loss: 2.5649499893188477
Batch 7/64 loss: 2.6322293281555176
Batch 8/64 loss: 2.674774169921875
Batch 9/64 loss: 2.758584976196289
Batch 10/64 loss: 2.863832473754883
Batch 11/64 loss: 2.6746296882629395
Batch 12/64 loss: 2.6120619773864746
Batch 13/64 loss: 2.6715354919433594
Batch 14/64 loss: 2.4638471603393555
Batch 15/64 loss: 2.597320556640625
Batch 16/64 loss: 2.6299071311950684
Batch 17/64 loss: 2.492724895477295
Batch 18/64 loss: 2.525254249572754
Batch 19/64 loss: 2.8656249046325684
Batch 20/64 loss: 2.6045870780944824
Batch 21/64 loss: 2.733872890472412
Batch 22/64 loss: 2.655606269836426
Batch 23/64 loss: 2.7013564109802246
Batch 24/64 loss: 2.593536376953125
Batch 25/64 loss: 2.670179843902588
Batch 26/64 loss: 2.655303955078125
Batch 27/64 loss: 2.6291232109069824
Batch 28/64 loss: 2.5192136764526367
Batch 29/64 loss: 2.7274537086486816
Batch 30/64 loss: 2.7727184295654297
Batch 31/64 loss: 2.6118717193603516
Batch 32/64 loss: 2.577770233154297
Batch 33/64 loss: 2.7590179443359375
Batch 34/64 loss: 2.6450719833374023
Batch 35/64 loss: 2.6424384117126465
Batch 36/64 loss: 2.762341022491455
Batch 37/64 loss: 2.618655204772949
Batch 38/64 loss: 2.537078380584717
Batch 39/64 loss: 2.610501289367676
Batch 40/64 loss: 2.5966405868530273
Batch 41/64 loss: 2.4334468841552734
Batch 42/64 loss: 2.674722194671631
Batch 43/64 loss: 2.6118574142456055
Batch 44/64 loss: 2.504363536834717
Batch 45/64 loss: 2.6731619834899902
Batch 46/64 loss: 2.504021644592285
Batch 47/64 loss: 2.6873855590820312
Batch 48/64 loss: 2.7101311683654785
Batch 49/64 loss: 2.8040785789489746
Batch 50/64 loss: 2.5352230072021484
Batch 51/64 loss: 2.462559223175049
Batch 52/64 loss: 2.7921700477600098
Batch 53/64 loss: 2.7703099250793457
Batch 54/64 loss: 2.7102208137512207
Batch 55/64 loss: 2.611670970916748
Batch 56/64 loss: 2.7536635398864746
Batch 57/64 loss: 2.8779077529907227
Batch 58/64 loss: 2.643812656402588
Batch 59/64 loss: 2.5519676208496094
Batch 60/64 loss: 2.561586856842041
Batch 61/64 loss: 2.9918761253356934
Batch 62/64 loss: 2.7812976837158203
Batch 63/64 loss: 2.607056140899658
Batch 64/64 loss: -0.31767702102661133
Epoch 69  Train loss: 2.6221885101467954  Val loss: 2.5121344471305505
Epoch 70
-------------------------------
Batch 1/64 loss: 2.737137794494629
Batch 2/64 loss: 2.5420889854431152
Batch 3/64 loss: 2.633028984069824
Batch 4/64 loss: 2.689486026763916
Batch 5/64 loss: 2.7263059616088867
Batch 6/64 loss: 2.7745513916015625
Batch 7/64 loss: 2.6735901832580566
Batch 8/64 loss: 2.6564688682556152
Batch 9/64 loss: 2.752323627471924
Batch 10/64 loss: 2.6569581031799316
Batch 11/64 loss: 2.692864418029785
Batch 12/64 loss: 2.4763832092285156
Batch 13/64 loss: 2.8002285957336426
Batch 14/64 loss: 2.7977538108825684
Batch 15/64 loss: 2.687422752380371
Batch 16/64 loss: 2.6578469276428223
Batch 17/64 loss: 2.7978830337524414
Batch 18/64 loss: 2.586005210876465
Batch 19/64 loss: 2.484586715698242
Batch 20/64 loss: 2.7366814613342285
Batch 21/64 loss: 2.574841022491455
Batch 22/64 loss: 2.639941692352295
Batch 23/64 loss: 2.607186794281006
Batch 24/64 loss: 2.7695627212524414
Batch 25/64 loss: 2.54404878616333
Batch 26/64 loss: 2.9377694129943848
Batch 27/64 loss: 2.5524730682373047
Batch 28/64 loss: 2.531036853790283
Batch 29/64 loss: 2.464991569519043
Batch 30/64 loss: 2.6093578338623047
Batch 31/64 loss: 2.5103025436401367
Batch 32/64 loss: 2.838712692260742
Batch 33/64 loss: 2.838895320892334
Batch 34/64 loss: 2.7317423820495605
Batch 35/64 loss: 2.570805072784424
Batch 36/64 loss: 2.9373021125793457
Batch 37/64 loss: 2.5439534187316895
Batch 38/64 loss: 2.638805389404297
Batch 39/64 loss: 2.624713897705078
Batch 40/64 loss: 3.0199384689331055
Batch 41/64 loss: 2.6748299598693848
Batch 42/64 loss: 2.4763450622558594
Batch 43/64 loss: 2.611907958984375
Batch 44/64 loss: 2.7312073707580566
Batch 45/64 loss: 2.493164539337158
Batch 46/64 loss: 2.4849843978881836
Batch 47/64 loss: 2.7517929077148438
Batch 48/64 loss: 2.4294447898864746
Batch 49/64 loss: 2.7301745414733887
Batch 50/64 loss: 2.8939576148986816
Batch 51/64 loss: 2.628775119781494
Batch 52/64 loss: 2.6877012252807617
Batch 53/64 loss: 2.6226329803466797
Batch 54/64 loss: 2.6827263832092285
Batch 55/64 loss: 2.722743034362793
Batch 56/64 loss: 2.770263195037842
Batch 57/64 loss: 2.6528334617614746
Batch 58/64 loss: 2.6838793754577637
Batch 59/64 loss: 2.801008701324463
Batch 60/64 loss: 2.6647424697875977
Batch 61/64 loss: 2.499497413635254
Batch 62/64 loss: 2.7793831825256348
Batch 63/64 loss: 2.5596189498901367
Batch 64/64 loss: 0.18844366073608398
Epoch 70  Train loss: 2.638759599947462  Val loss: 2.4360713499927846
Saving best model, epoch: 70
Epoch 71
-------------------------------
Batch 1/64 loss: 2.5405635833740234
Batch 2/64 loss: 2.668018341064453
Batch 3/64 loss: 2.667813777923584
Batch 4/64 loss: 2.679452419281006
Batch 5/64 loss: 2.6469831466674805
Batch 6/64 loss: 2.577054500579834
Batch 7/64 loss: 2.3954644203186035
Batch 8/64 loss: 2.6706676483154297
Batch 9/64 loss: 2.5121145248413086
Batch 10/64 loss: 2.4047741889953613
Batch 11/64 loss: 2.8479905128479004
Batch 12/64 loss: 2.503387451171875
Batch 13/64 loss: 2.458895206451416
Batch 14/64 loss: 2.743636131286621
Batch 15/64 loss: 2.720644474029541
Batch 16/64 loss: 2.701383113861084
Batch 17/64 loss: 2.5746469497680664
Batch 18/64 loss: 2.585827350616455
Batch 19/64 loss: 2.471440315246582
Batch 20/64 loss: 2.771519660949707
Batch 21/64 loss: 2.409796714782715
Batch 22/64 loss: 2.6919779777526855
Batch 23/64 loss: 2.5281600952148438
Batch 24/64 loss: 2.6434149742126465
Batch 25/64 loss: 2.5119857788085938
Batch 26/64 loss: 2.578503131866455
Batch 27/64 loss: 2.5299229621887207
Batch 28/64 loss: 2.5896568298339844
Batch 29/64 loss: 2.4720449447631836
Batch 30/64 loss: 2.7056751251220703
Batch 31/64 loss: 2.623417854309082
Batch 32/64 loss: 2.6544041633605957
Batch 33/64 loss: 2.5613369941711426
Batch 34/64 loss: 2.5322670936584473
Batch 35/64 loss: 2.555251121520996
Batch 36/64 loss: 2.467963218688965
Batch 37/64 loss: 2.467212677001953
Batch 38/64 loss: 3.0933260917663574
Batch 39/64 loss: 2.5065197944641113
Batch 40/64 loss: 2.521834373474121
Batch 41/64 loss: 2.7338085174560547
Batch 42/64 loss: 2.2958455085754395
Batch 43/64 loss: 2.5584230422973633
Batch 44/64 loss: 2.7859678268432617
Batch 45/64 loss: 2.4378676414489746
Batch 46/64 loss: 2.5517024993896484
Batch 47/64 loss: 2.6820669174194336
Batch 48/64 loss: 2.4434685707092285
Batch 49/64 loss: 2.520761013031006
Batch 50/64 loss: 2.5972914695739746
Batch 51/64 loss: 2.4705114364624023
Batch 52/64 loss: 2.523421287536621
Batch 53/64 loss: 2.7682838439941406
Batch 54/64 loss: 2.5152668952941895
Batch 55/64 loss: 2.5826196670532227
Batch 56/64 loss: 2.665109634399414
Batch 57/64 loss: 2.6270618438720703
Batch 58/64 loss: 2.608299732208252
Batch 59/64 loss: 2.312582492828369
Batch 60/64 loss: 2.641742706298828
Batch 61/64 loss: 2.4976067543029785
Batch 62/64 loss: 2.7194032669067383
Batch 63/64 loss: 2.6197304725646973
Batch 64/64 loss: -0.43274879455566406
Epoch 71  Train loss: 2.550921271829044  Val loss: 2.4312376304180763
Saving best model, epoch: 71
Epoch 72
-------------------------------
Batch 1/64 loss: 2.6727919578552246
Batch 2/64 loss: 2.496432304382324
Batch 3/64 loss: 2.643488883972168
Batch 4/64 loss: 2.5236854553222656
Batch 5/64 loss: 2.462158679962158
Batch 6/64 loss: 2.6665453910827637
Batch 7/64 loss: 2.4294657707214355
Batch 8/64 loss: 2.427929401397705
Batch 9/64 loss: 2.5409154891967773
Batch 10/64 loss: 2.5145444869995117
Batch 11/64 loss: 2.4434380531311035
Batch 12/64 loss: 2.6515588760375977
Batch 13/64 loss: 2.6064810752868652
Batch 14/64 loss: 2.739185333251953
Batch 15/64 loss: 2.472820281982422
Batch 16/64 loss: 2.4759697914123535
Batch 17/64 loss: 2.788229465484619
Batch 18/64 loss: 2.677433490753174
Batch 19/64 loss: 2.740147113800049
Batch 20/64 loss: 2.7857728004455566
Batch 21/64 loss: 2.5161476135253906
Batch 22/64 loss: 2.5877957344055176
Batch 23/64 loss: 2.466395854949951
Batch 24/64 loss: 2.5415477752685547
Batch 25/64 loss: 2.5684094429016113
Batch 26/64 loss: 2.7699599266052246
Batch 27/64 loss: 2.424980640411377
Batch 28/64 loss: 2.559333324432373
Batch 29/64 loss: 2.5540575981140137
Batch 30/64 loss: 2.931631565093994
Batch 31/64 loss: 2.591254234313965
Batch 32/64 loss: 2.5724124908447266
Batch 33/64 loss: 2.4909496307373047
Batch 34/64 loss: 2.619502544403076
Batch 35/64 loss: 2.783339500427246
Batch 36/64 loss: 2.986745834350586
Batch 37/64 loss: 2.5692930221557617
Batch 38/64 loss: 2.6084847450256348
Batch 39/64 loss: 2.580270290374756
Batch 40/64 loss: 2.6434192657470703
Batch 41/64 loss: 2.4496335983276367
Batch 42/64 loss: 2.560698986053467
Batch 43/64 loss: 2.608922004699707
Batch 44/64 loss: 2.4595165252685547
Batch 45/64 loss: 2.6649184226989746
Batch 46/64 loss: 2.5104808807373047
Batch 47/64 loss: 2.613420009613037
Batch 48/64 loss: 2.5511417388916016
Batch 49/64 loss: 2.5069799423217773
Batch 50/64 loss: 2.726778984069824
Batch 51/64 loss: 2.665727138519287
Batch 52/64 loss: 2.4760332107543945
Batch 53/64 loss: 2.729006290435791
Batch 54/64 loss: 2.5540614128112793
Batch 55/64 loss: 2.4990477561950684
Batch 56/64 loss: 2.5983314514160156
Batch 57/64 loss: 2.5022053718566895
Batch 58/64 loss: 2.4550156593322754
Batch 59/64 loss: 2.3510589599609375
Batch 60/64 loss: 2.5718021392822266
Batch 61/64 loss: 2.6531267166137695
Batch 62/64 loss: 2.5361642837524414
Batch 63/64 loss: 2.654597282409668
Batch 64/64 loss: -0.2500882148742676
Epoch 72  Train loss: 2.554290631238152  Val loss: 2.3428468736995947
Saving best model, epoch: 72
Epoch 73
-------------------------------
Batch 1/64 loss: 2.7038159370422363
Batch 2/64 loss: 2.6527857780456543
Batch 3/64 loss: 2.5144262313842773
Batch 4/64 loss: 2.4757533073425293
Batch 5/64 loss: 2.493563652038574
Batch 6/64 loss: 2.5768442153930664
Batch 7/64 loss: 2.4737157821655273
Batch 8/64 loss: 2.4140939712524414
Batch 9/64 loss: 2.696167469024658
Batch 10/64 loss: 2.6426429748535156
Batch 11/64 loss: 2.583008289337158
Batch 12/64 loss: 2.408874988555908
Batch 13/64 loss: 2.390578269958496
Batch 14/64 loss: 2.4372549057006836
Batch 15/64 loss: 2.5070648193359375
Batch 16/64 loss: 2.5983352661132812
Batch 17/64 loss: 2.5752477645874023
Batch 18/64 loss: 2.5841856002807617
Batch 19/64 loss: 2.550058364868164
Batch 20/64 loss: 2.4165396690368652
Batch 21/64 loss: 2.616809844970703
Batch 22/64 loss: 2.6261940002441406
Batch 23/64 loss: 2.795072555541992
Batch 24/64 loss: 2.6367921829223633
Batch 25/64 loss: 2.55350399017334
Batch 26/64 loss: 2.5585074424743652
Batch 27/64 loss: 2.287083625793457
Batch 28/64 loss: 2.4943575859069824
Batch 29/64 loss: 2.555844306945801
Batch 30/64 loss: 2.5893678665161133
Batch 31/64 loss: 2.540158271789551
Batch 32/64 loss: 2.3992648124694824
Batch 33/64 loss: 2.350862979888916
Batch 34/64 loss: 2.545006275177002
Batch 35/64 loss: 2.3342370986938477
Batch 36/64 loss: 2.4174551963806152
Batch 37/64 loss: 2.362879753112793
Batch 38/64 loss: 2.4897842407226562
Batch 39/64 loss: 2.3780441284179688
Batch 40/64 loss: 2.4531030654907227
Batch 41/64 loss: 2.2429537773132324
Batch 42/64 loss: 2.553219795227051
Batch 43/64 loss: 2.5431323051452637
Batch 44/64 loss: 2.4234743118286133
Batch 45/64 loss: 2.3402915000915527
Batch 46/64 loss: 2.678450107574463
Batch 47/64 loss: 2.2762250900268555
Batch 48/64 loss: 2.573427200317383
Batch 49/64 loss: 2.536895275115967
Batch 50/64 loss: 2.4389171600341797
Batch 51/64 loss: 2.34389066696167
Batch 52/64 loss: 2.381671905517578
Batch 53/64 loss: 2.418292999267578
Batch 54/64 loss: 2.516683578491211
Batch 55/64 loss: 2.329925537109375
Batch 56/64 loss: 2.439929962158203
Batch 57/64 loss: 2.4227700233459473
Batch 58/64 loss: 2.460174560546875
Batch 59/64 loss: 2.3565335273742676
Batch 60/64 loss: 2.4430384635925293
Batch 61/64 loss: 2.660501003265381
Batch 62/64 loss: 2.458815097808838
Batch 63/64 loss: 2.437256336212158
Batch 64/64 loss: -0.3029966354370117
Epoch 73  Train loss: 2.4584864186305624  Val loss: 2.3490556277769947
Epoch 74
-------------------------------
Batch 1/64 loss: 2.4287734031677246
Batch 2/64 loss: 2.774378776550293
Batch 3/64 loss: 2.4861831665039062
Batch 4/64 loss: 2.373826503753662
Batch 5/64 loss: 2.2890186309814453
Batch 6/64 loss: 2.4514365196228027
Batch 7/64 loss: 2.5467896461486816
Batch 8/64 loss: 2.331709861755371
Batch 9/64 loss: 2.605687141418457
Batch 10/64 loss: 2.7187023162841797
Batch 11/64 loss: 2.4381871223449707
Batch 12/64 loss: 2.5379371643066406
Batch 13/64 loss: 2.4510960578918457
Batch 14/64 loss: 2.3645644187927246
Batch 15/64 loss: 2.3894095420837402
Batch 16/64 loss: 2.4065370559692383
Batch 17/64 loss: 2.3580164909362793
Batch 18/64 loss: 2.459664821624756
Batch 19/64 loss: 2.6867904663085938
Batch 20/64 loss: 2.4845457077026367
Batch 21/64 loss: 2.367361545562744
Batch 22/64 loss: 2.2970118522644043
Batch 23/64 loss: 2.3752493858337402
Batch 24/64 loss: 2.4714479446411133
Batch 25/64 loss: 2.328855514526367
Batch 26/64 loss: 2.8112072944641113
Batch 27/64 loss: 2.727637767791748
Batch 28/64 loss: 2.4046998023986816
Batch 29/64 loss: 2.4693236351013184
Batch 30/64 loss: 2.3888731002807617
Batch 31/64 loss: 2.445967674255371
Batch 32/64 loss: 2.4768314361572266
Batch 33/64 loss: 2.5594100952148438
Batch 34/64 loss: 2.459836006164551
Batch 35/64 loss: 2.603875160217285
Batch 36/64 loss: 2.4846487045288086
Batch 37/64 loss: 2.457418441772461
Batch 38/64 loss: 2.5517029762268066
Batch 39/64 loss: 2.551326274871826
Batch 40/64 loss: 2.4716882705688477
Batch 41/64 loss: 2.584280014038086
Batch 42/64 loss: 2.4744019508361816
Batch 43/64 loss: 2.365788459777832
Batch 44/64 loss: 2.313131809234619
Batch 45/64 loss: 2.6020989418029785
Batch 46/64 loss: 2.492844581604004
Batch 47/64 loss: 2.508824348449707
Batch 48/64 loss: 2.842801570892334
Batch 49/64 loss: 2.851053237915039
Batch 50/64 loss: 2.60984468460083
Batch 51/64 loss: 2.4653143882751465
Batch 52/64 loss: 2.523481845855713
Batch 53/64 loss: 2.310516357421875
Batch 54/64 loss: 2.444056987762451
Batch 55/64 loss: 2.3952255249023438
Batch 56/64 loss: 2.513242721557617
Batch 57/64 loss: 2.68927001953125
Batch 58/64 loss: 2.4441895484924316
Batch 59/64 loss: 2.474541664123535
Batch 60/64 loss: 2.365994930267334
Batch 61/64 loss: 2.4270973205566406
Batch 62/64 loss: 2.3779478073120117
Batch 63/64 loss: 2.4680070877075195
Batch 64/64 loss: -0.3888859748840332
Epoch 74  Train loss: 2.4555281414705163  Val loss: 2.3361558357055245
Saving best model, epoch: 74
Epoch 75
-------------------------------
Batch 1/64 loss: 2.4707040786743164
Batch 2/64 loss: 2.712522029876709
Batch 3/64 loss: 2.3862686157226562
Batch 4/64 loss: 2.5172338485717773
Batch 5/64 loss: 2.570596694946289
Batch 6/64 loss: 2.8641529083251953
Batch 7/64 loss: 2.462617874145508
Batch 8/64 loss: 2.3486275672912598
Batch 9/64 loss: 2.765773296356201
Batch 10/64 loss: 2.662106513977051
Batch 11/64 loss: 2.489161491394043
Batch 12/64 loss: 2.4446725845336914
Batch 13/64 loss: 2.4953160285949707
Batch 14/64 loss: 2.603818416595459
Batch 15/64 loss: 2.607494831085205
Batch 16/64 loss: 2.6830129623413086
Batch 17/64 loss: 2.5680360794067383
Batch 18/64 loss: 2.4203124046325684
Batch 19/64 loss: 2.4229588508605957
Batch 20/64 loss: 2.491209030151367
Batch 21/64 loss: 2.3056297302246094
Batch 22/64 loss: 2.6899733543395996
Batch 23/64 loss: 2.782085418701172
Batch 24/64 loss: 2.7384238243103027
Batch 25/64 loss: 2.304330825805664
Batch 26/64 loss: 2.754762649536133
Batch 27/64 loss: 2.805851936340332
Batch 28/64 loss: 2.654776096343994
Batch 29/64 loss: 2.6161184310913086
Batch 30/64 loss: 2.4586663246154785
Batch 31/64 loss: 2.8448257446289062
Batch 32/64 loss: 2.4808359146118164
Batch 33/64 loss: 2.3284568786621094
Batch 34/64 loss: 2.608248710632324
Batch 35/64 loss: 2.6641335487365723
Batch 36/64 loss: 2.4031753540039062
Batch 37/64 loss: 2.367392063140869
Batch 38/64 loss: 2.548879623413086
Batch 39/64 loss: 2.736043930053711
Batch 40/64 loss: 2.597203254699707
Batch 41/64 loss: 2.4641313552856445
Batch 42/64 loss: 2.515237808227539
Batch 43/64 loss: 2.293795108795166
Batch 44/64 loss: 2.468977451324463
Batch 45/64 loss: 2.591053009033203
Batch 46/64 loss: 2.4579195976257324
Batch 47/64 loss: 2.273099899291992
Batch 48/64 loss: 2.229950428009033
Batch 49/64 loss: 2.331005573272705
Batch 50/64 loss: 2.35911226272583
Batch 51/64 loss: 2.3281517028808594
Batch 52/64 loss: 2.4531750679016113
Batch 53/64 loss: 2.5091614723205566
Batch 54/64 loss: 2.3349380493164062
Batch 55/64 loss: 2.496232032775879
Batch 56/64 loss: 2.428555965423584
Batch 57/64 loss: 2.4355807304382324
Batch 58/64 loss: 2.3475170135498047
Batch 59/64 loss: 2.428920269012451
Batch 60/64 loss: 2.586669445037842
Batch 61/64 loss: 2.5268874168395996
Batch 62/64 loss: 2.4819955825805664
Batch 63/64 loss: 2.57171630859375
Batch 64/64 loss: -0.5608954429626465
Epoch 75  Train loss: 2.481090536304549  Val loss: 2.2305583298411156
Saving best model, epoch: 75
Epoch 76
-------------------------------
Batch 1/64 loss: 2.4059062004089355
Batch 2/64 loss: 2.3944945335388184
Batch 3/64 loss: 2.4865546226501465
Batch 4/64 loss: 2.162855625152588
Batch 5/64 loss: 2.409788131713867
Batch 6/64 loss: 2.384160041809082
Batch 7/64 loss: 2.5937695503234863
Batch 8/64 loss: 2.3332438468933105
Batch 9/64 loss: 2.576058864593506
Batch 10/64 loss: 2.4092202186584473
Batch 11/64 loss: 2.5147523880004883
Batch 12/64 loss: 2.3308544158935547
Batch 13/64 loss: 2.517063617706299
Batch 14/64 loss: 2.5353636741638184
Batch 15/64 loss: 2.5253772735595703
Batch 16/64 loss: 2.7692055702209473
Batch 17/64 loss: 2.4190468788146973
Batch 18/64 loss: 2.4354658126831055
Batch 19/64 loss: 2.499063491821289
Batch 20/64 loss: 2.440227508544922
Batch 21/64 loss: 2.4546146392822266
Batch 22/64 loss: 2.4524126052856445
Batch 23/64 loss: 2.3275809288024902
Batch 24/64 loss: 2.3697094917297363
Batch 25/64 loss: 2.5213470458984375
Batch 26/64 loss: 2.640900135040283
Batch 27/64 loss: 2.3978476524353027
Batch 28/64 loss: 2.2863845825195312
Batch 29/64 loss: 2.730259418487549
Batch 30/64 loss: 2.741387367248535
Batch 31/64 loss: 2.3842644691467285
Batch 32/64 loss: 2.327030658721924
Batch 33/64 loss: 2.5043067932128906
Batch 34/64 loss: 2.4894895553588867
Batch 35/64 loss: 2.5924572944641113
Batch 36/64 loss: 2.248002052307129
Batch 37/64 loss: 2.3900489807128906
Batch 38/64 loss: 2.405031681060791
Batch 39/64 loss: 2.542264461517334
Batch 40/64 loss: 2.4296517372131348
Batch 41/64 loss: 2.6001710891723633
Batch 42/64 loss: 2.4377031326293945
Batch 43/64 loss: 2.5521202087402344
Batch 44/64 loss: 2.470986843109131
Batch 45/64 loss: 2.297140598297119
Batch 46/64 loss: 2.448129653930664
Batch 47/64 loss: 2.369558334350586
Batch 48/64 loss: 2.438037395477295
Batch 49/64 loss: 2.3930654525756836
Batch 50/64 loss: 2.385504722595215
Batch 51/64 loss: 2.61960506439209
Batch 52/64 loss: 2.2658863067626953
Batch 53/64 loss: 2.2181968688964844
Batch 54/64 loss: 2.3731331825256348
Batch 55/64 loss: 2.311807632446289
Batch 56/64 loss: 2.4953250885009766
Batch 57/64 loss: 2.4498653411865234
Batch 58/64 loss: 2.339531898498535
Batch 59/64 loss: 2.4361228942871094
Batch 60/64 loss: 2.1998701095581055
Batch 61/64 loss: 2.9033374786376953
Batch 62/64 loss: 2.1843647956848145
Batch 63/64 loss: 2.2363944053649902
Batch 64/64 loss: -0.41169309616088867
Epoch 76  Train loss: 2.4077576861662022  Val loss: 2.1913837026484644
Saving best model, epoch: 76
Epoch 77
-------------------------------
Batch 1/64 loss: 2.3963546752929688
Batch 2/64 loss: 2.42930269241333
Batch 3/64 loss: 2.3248510360717773
Batch 4/64 loss: 2.363405704498291
Batch 5/64 loss: 2.584122657775879
Batch 6/64 loss: 2.425266742706299
Batch 7/64 loss: 2.2938766479492188
Batch 8/64 loss: 2.3530807495117188
Batch 9/64 loss: 2.3992862701416016
Batch 10/64 loss: 2.3523411750793457
Batch 11/64 loss: 2.6666078567504883
Batch 12/64 loss: 2.560142993927002
Batch 13/64 loss: 2.4571666717529297
Batch 14/64 loss: 2.4023051261901855
Batch 15/64 loss: 2.504349708557129
Batch 16/64 loss: 2.299055576324463
Batch 17/64 loss: 2.45686674118042
Batch 18/64 loss: 2.6047606468200684
Batch 19/64 loss: 2.4190673828125
Batch 20/64 loss: 2.5877604484558105
Batch 21/64 loss: 2.2889113426208496
Batch 22/64 loss: 2.718069553375244
Batch 23/64 loss: 2.584751605987549
Batch 24/64 loss: 2.50068998336792
Batch 25/64 loss: 2.349172592163086
Batch 26/64 loss: 2.6611433029174805
Batch 27/64 loss: 2.411141872406006
Batch 28/64 loss: 2.3747658729553223
Batch 29/64 loss: 2.340348720550537
Batch 30/64 loss: 2.1811914443969727
Batch 31/64 loss: 2.413294792175293
Batch 32/64 loss: 2.4994473457336426
Batch 33/64 loss: 2.2839250564575195
Batch 34/64 loss: 2.305454730987549
Batch 35/64 loss: 2.3695836067199707
Batch 36/64 loss: 2.449521064758301
Batch 37/64 loss: 2.646068572998047
Batch 38/64 loss: 2.331456184387207
Batch 39/64 loss: 2.416623115539551
Batch 40/64 loss: 2.242884635925293
Batch 41/64 loss: 2.2984938621520996
Batch 42/64 loss: 2.340705394744873
Batch 43/64 loss: 2.255295753479004
Batch 44/64 loss: 2.674445152282715
Batch 45/64 loss: 2.2521252632141113
Batch 46/64 loss: 2.619424343109131
Batch 47/64 loss: 2.334402561187744
Batch 48/64 loss: 2.3663644790649414
Batch 49/64 loss: 2.60595703125
Batch 50/64 loss: 2.3764209747314453
Batch 51/64 loss: 2.58980655670166
Batch 52/64 loss: 2.4705872535705566
Batch 53/64 loss: 2.224719524383545
Batch 54/64 loss: 2.3082876205444336
Batch 55/64 loss: 2.286571502685547
Batch 56/64 loss: 2.4523167610168457
Batch 57/64 loss: 2.396911144256592
Batch 58/64 loss: 2.416877269744873
Batch 59/64 loss: 2.345329761505127
Batch 60/64 loss: 2.4076318740844727
Batch 61/64 loss: 2.3454971313476562
Batch 62/64 loss: 2.1907758712768555
Batch 63/64 loss: 2.3438267707824707
Batch 64/64 loss: -0.7384982109069824
Epoch 77  Train loss: 2.3779971309736663  Val loss: 2.2469256751725766
Epoch 78
-------------------------------
Batch 1/64 loss: 2.4394173622131348
Batch 2/64 loss: 2.972686290740967
Batch 3/64 loss: 2.436260223388672
Batch 4/64 loss: 2.6754255294799805
Batch 5/64 loss: 2.4178600311279297
Batch 6/64 loss: 2.530031204223633
Batch 7/64 loss: 2.400534152984619
Batch 8/64 loss: 2.4006905555725098
Batch 9/64 loss: 2.4767942428588867
Batch 10/64 loss: 2.3879294395446777
Batch 11/64 loss: 2.639899730682373
Batch 12/64 loss: 2.4689183235168457
Batch 13/64 loss: 2.2044506072998047
Batch 14/64 loss: 2.271716594696045
Batch 15/64 loss: 2.214308738708496
Batch 16/64 loss: 2.336365222930908
Batch 17/64 loss: 2.432537078857422
Batch 18/64 loss: 2.162177562713623
Batch 19/64 loss: 2.29673433303833
Batch 20/64 loss: 2.6725997924804688
Batch 21/64 loss: 2.349778652191162
Batch 22/64 loss: 2.4928174018859863
Batch 23/64 loss: 2.416451930999756
Batch 24/64 loss: 2.6992416381835938
Batch 25/64 loss: 2.4388585090637207
Batch 26/64 loss: 2.2759389877319336
Batch 27/64 loss: 2.7818026542663574
Batch 28/64 loss: 2.2735843658447266
Batch 29/64 loss: 2.5603318214416504
Batch 30/64 loss: 2.38690185546875
Batch 31/64 loss: 2.3260393142700195
Batch 32/64 loss: 2.9469752311706543
Batch 33/64 loss: 2.3295974731445312
Batch 34/64 loss: 2.6803812980651855
Batch 35/64 loss: 2.6068272590637207
Batch 36/64 loss: 2.587360382080078
Batch 37/64 loss: 2.737964630126953
Batch 38/64 loss: 2.6220293045043945
Batch 39/64 loss: 2.6986756324768066
Batch 40/64 loss: 2.5222249031066895
Batch 41/64 loss: 2.786515235900879
Batch 42/64 loss: 2.5537567138671875
Batch 43/64 loss: 2.557666301727295
Batch 44/64 loss: 2.4734106063842773
Batch 45/64 loss: 2.640005588531494
Batch 46/64 loss: 2.347850799560547
Batch 47/64 loss: 2.6647257804870605
Batch 48/64 loss: 2.3137621879577637
Batch 49/64 loss: 2.5359864234924316
Batch 50/64 loss: 2.4401397705078125
Batch 51/64 loss: 2.4714736938476562
Batch 52/64 loss: 2.4509153366088867
Batch 53/64 loss: 2.4101157188415527
Batch 54/64 loss: 2.641385555267334
Batch 55/64 loss: 2.3955464363098145
Batch 56/64 loss: 2.6459264755249023
Batch 57/64 loss: 2.3327107429504395
Batch 58/64 loss: 2.504563331604004
Batch 59/64 loss: 2.339993476867676
Batch 60/64 loss: 2.421786308288574
Batch 61/64 loss: 2.5654735565185547
Batch 62/64 loss: 2.3299074172973633
Batch 63/64 loss: 2.721466064453125
Batch 64/64 loss: -0.5614290237426758
Epoch 78  Train loss: 2.457962855170755  Val loss: 2.312871310309446
Epoch 79
-------------------------------
Batch 1/64 loss: 2.3635168075561523
Batch 2/64 loss: 2.254910469055176
Batch 3/64 loss: 2.5594711303710938
Batch 4/64 loss: 2.2798776626586914
Batch 5/64 loss: 2.3948426246643066
Batch 6/64 loss: 2.369525909423828
Batch 7/64 loss: 2.389185905456543
Batch 8/64 loss: 2.373716354370117
Batch 9/64 loss: 2.5051369667053223
Batch 10/64 loss: 2.2934885025024414
Batch 11/64 loss: 2.4032201766967773
Batch 12/64 loss: 2.5009918212890625
Batch 13/64 loss: 2.3388071060180664
Batch 14/64 loss: 2.4934911727905273
Batch 15/64 loss: 2.531369209289551
Batch 16/64 loss: 2.3710851669311523
Batch 17/64 loss: 2.6196389198303223
Batch 18/64 loss: 2.3909401893615723
Batch 19/64 loss: 2.7477474212646484
Batch 20/64 loss: 2.540642261505127
Batch 21/64 loss: 2.331660270690918
Batch 22/64 loss: 2.337463855743408
Batch 23/64 loss: 2.525989055633545
Batch 24/64 loss: 2.2585225105285645
Batch 25/64 loss: 2.7022953033447266
Batch 26/64 loss: 2.446719169616699
Batch 27/64 loss: 2.3031420707702637
Batch 28/64 loss: 2.378988742828369
Batch 29/64 loss: 2.425811290740967
Batch 30/64 loss: 2.5013628005981445
Batch 31/64 loss: 2.5242223739624023
Batch 32/64 loss: 2.718278408050537
Batch 33/64 loss: 2.4526185989379883
Batch 34/64 loss: 2.274702548980713
Batch 35/64 loss: 2.4320263862609863
Batch 36/64 loss: 2.548679828643799
Batch 37/64 loss: 2.437570571899414
Batch 38/64 loss: 3.119912624359131
Batch 39/64 loss: 2.5434412956237793
Batch 40/64 loss: 2.5041708946228027
Batch 41/64 loss: 2.5845866203308105
Batch 42/64 loss: 2.694716453552246
Batch 43/64 loss: 2.2898664474487305
Batch 44/64 loss: 2.3530526161193848
Batch 45/64 loss: 2.718351364135742
Batch 46/64 loss: 2.266207218170166
Batch 47/64 loss: 2.3276572227478027
Batch 48/64 loss: 2.5507121086120605
Batch 49/64 loss: 2.597688674926758
Batch 50/64 loss: 2.2870588302612305
Batch 51/64 loss: 2.3698487281799316
Batch 52/64 loss: 2.2314095497131348
Batch 53/64 loss: 2.671358108520508
Batch 54/64 loss: 2.29771089553833
Batch 55/64 loss: 2.410684585571289
Batch 56/64 loss: 2.478008270263672
Batch 57/64 loss: 2.496471405029297
Batch 58/64 loss: 2.2168684005737305
Batch 59/64 loss: 2.323336601257324
Batch 60/64 loss: 2.843557357788086
Batch 61/64 loss: 2.3247733116149902
Batch 62/64 loss: 2.5311474800109863
Batch 63/64 loss: 2.1039481163024902
Batch 64/64 loss: -0.8438510894775391
Epoch 79  Train loss: 2.412946140064913  Val loss: 2.2133593084066594
Epoch 80
-------------------------------
Batch 1/64 loss: 2.5493569374084473
Batch 2/64 loss: 2.7259058952331543
Batch 3/64 loss: 2.345637798309326
Batch 4/64 loss: 2.4245924949645996
Batch 5/64 loss: 2.4764513969421387
Batch 6/64 loss: 2.396205425262451
Batch 7/64 loss: 2.5101051330566406
Batch 8/64 loss: 2.2846245765686035
Batch 9/64 loss: 2.4521961212158203
Batch 10/64 loss: 2.215968132019043
Batch 11/64 loss: 2.512178421020508
Batch 12/64 loss: 2.162184715270996
Batch 13/64 loss: 2.8398776054382324
Batch 14/64 loss: 2.587825298309326
Batch 15/64 loss: 2.2974348068237305
Batch 16/64 loss: 2.442516326904297
Batch 17/64 loss: 2.234865188598633
Batch 18/64 loss: 2.3718185424804688
Batch 19/64 loss: 2.8392577171325684
Batch 20/64 loss: 2.6192846298217773
Batch 21/64 loss: 2.4614362716674805
Batch 22/64 loss: 2.5413336753845215
Batch 23/64 loss: 2.2866172790527344
Batch 24/64 loss: 2.2026424407958984
Batch 25/64 loss: 2.6090736389160156
Batch 26/64 loss: 2.4644765853881836
Batch 27/64 loss: 2.455051898956299
Batch 28/64 loss: 2.37550687789917
Batch 29/64 loss: 2.3666257858276367
Batch 30/64 loss: 2.3638734817504883
Batch 31/64 loss: 2.320659637451172
Batch 32/64 loss: 2.232956886291504
Batch 33/64 loss: 2.484281539916992
Batch 34/64 loss: 2.4407763481140137
Batch 35/64 loss: 2.573352813720703
Batch 36/64 loss: 2.0507640838623047
Batch 37/64 loss: 2.4023146629333496
Batch 38/64 loss: 2.3988680839538574
Batch 39/64 loss: 2.2723779678344727
Batch 40/64 loss: 2.4439730644226074
Batch 41/64 loss: 2.250782012939453
Batch 42/64 loss: 2.3382930755615234
Batch 43/64 loss: 2.332462787628174
Batch 44/64 loss: 2.3317503929138184
Batch 45/64 loss: 2.443781852722168
Batch 46/64 loss: 2.6002612113952637
Batch 47/64 loss: 2.3292393684387207
Batch 48/64 loss: 2.4534544944763184
Batch 49/64 loss: 2.5050315856933594
Batch 50/64 loss: 2.675307273864746
Batch 51/64 loss: 2.4778032302856445
Batch 52/64 loss: 2.516054630279541
Batch 53/64 loss: 2.169182300567627
Batch 54/64 loss: 2.4478940963745117
Batch 55/64 loss: 2.3368020057678223
Batch 56/64 loss: 2.4950170516967773
Batch 57/64 loss: 2.4460206031799316
Batch 58/64 loss: 2.2740888595581055
Batch 59/64 loss: 2.5492982864379883
Batch 60/64 loss: 2.21958589553833
Batch 61/64 loss: 2.4442849159240723
Batch 62/64 loss: 2.337923526763916
Batch 63/64 loss: 2.3294215202331543
Batch 64/64 loss: -0.35201358795166016
Epoch 80  Train loss: 2.3854898976344687  Val loss: 2.226017240806134
Epoch 81
-------------------------------
Batch 1/64 loss: 2.224853038787842
Batch 2/64 loss: 2.408574104309082
Batch 3/64 loss: 2.4376220703125
Batch 4/64 loss: 2.605100631713867
Batch 5/64 loss: 2.377431869506836
Batch 6/64 loss: 2.4122185707092285
Batch 7/64 loss: 2.3317980766296387
Batch 8/64 loss: 2.3636550903320312
Batch 9/64 loss: 2.555755615234375
Batch 10/64 loss: 2.4371676445007324
Batch 11/64 loss: 2.383312702178955
Batch 12/64 loss: 2.4222216606140137
Batch 13/64 loss: 2.5106639862060547
Batch 14/64 loss: 2.205103874206543
Batch 15/64 loss: 2.39668607711792
Batch 16/64 loss: 2.482733726501465
Batch 17/64 loss: 2.318838596343994
Batch 18/64 loss: 2.248011589050293
Batch 19/64 loss: 2.230302333831787
Batch 20/64 loss: 2.355987071990967
Batch 21/64 loss: 2.2223801612854004
Batch 22/64 loss: 2.2751922607421875
Batch 23/64 loss: 2.7017507553100586
Batch 24/64 loss: 2.2984790802001953
Batch 25/64 loss: 2.2686524391174316
Batch 26/64 loss: 2.4291510581970215
Batch 27/64 loss: 2.2284746170043945
Batch 28/64 loss: 2.4130873680114746
Batch 29/64 loss: 2.3611087799072266
Batch 30/64 loss: 2.4010887145996094
Batch 31/64 loss: 2.3388466835021973
Batch 32/64 loss: 2.2564587593078613
Batch 33/64 loss: 2.32273006439209
Batch 34/64 loss: 2.2933688163757324
Batch 35/64 loss: 2.5071425437927246
Batch 36/64 loss: 2.525546073913574
Batch 37/64 loss: 2.4238505363464355
Batch 38/64 loss: 2.48630428314209
Batch 39/64 loss: 2.1953840255737305
Batch 40/64 loss: 2.630096435546875
Batch 41/64 loss: 2.2320127487182617
Batch 42/64 loss: 2.3297643661499023
Batch 43/64 loss: 2.3849425315856934
Batch 44/64 loss: 2.196606159210205
Batch 45/64 loss: 2.3265013694763184
Batch 46/64 loss: 2.4373040199279785
Batch 47/64 loss: 2.3246254920959473
Batch 48/64 loss: 2.229369640350342
Batch 49/64 loss: 2.443436622619629
Batch 50/64 loss: 2.208561897277832
Batch 51/64 loss: 2.1129798889160156
Batch 52/64 loss: 2.3270130157470703
Batch 53/64 loss: 2.486391544342041
Batch 54/64 loss: 2.348580837249756
Batch 55/64 loss: 2.3759665489196777
Batch 56/64 loss: 2.450181007385254
Batch 57/64 loss: 2.0757060050964355
Batch 58/64 loss: 2.518860340118408
Batch 59/64 loss: 2.213892936706543
Batch 60/64 loss: 2.271055221557617
Batch 61/64 loss: 2.3781023025512695
Batch 62/64 loss: 2.620521068572998
Batch 63/64 loss: 2.205994129180908
Batch 64/64 loss: -0.9230799674987793
Epoch 81  Train loss: 2.323030454972211  Val loss: 2.1766021112396134
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: 2.1817498207092285
Batch 2/64 loss: 2.2692384719848633
Batch 3/64 loss: 2.263108253479004
Batch 4/64 loss: 2.64711332321167
Batch 5/64 loss: 2.4974045753479004
Batch 6/64 loss: 2.4619150161743164
Batch 7/64 loss: 2.2522988319396973
Batch 8/64 loss: 2.2471423149108887
Batch 9/64 loss: 2.21903657913208
Batch 10/64 loss: 2.4223427772521973
Batch 11/64 loss: 2.3982644081115723
Batch 12/64 loss: 2.2663631439208984
Batch 13/64 loss: 2.228555679321289
Batch 14/64 loss: 2.529541492462158
Batch 15/64 loss: 2.4601831436157227
Batch 16/64 loss: 2.160031318664551
Batch 17/64 loss: 2.3663039207458496
Batch 18/64 loss: 2.3400464057922363
Batch 19/64 loss: 2.269347667694092
Batch 20/64 loss: 2.3544058799743652
Batch 21/64 loss: 2.426220417022705
Batch 22/64 loss: 2.4895238876342773
Batch 23/64 loss: 2.278125286102295
Batch 24/64 loss: 2.125652313232422
Batch 25/64 loss: 2.2976789474487305
Batch 26/64 loss: 2.2896804809570312
Batch 27/64 loss: 2.2344093322753906
Batch 28/64 loss: 2.1053619384765625
Batch 29/64 loss: 2.3695545196533203
Batch 30/64 loss: 2.1342239379882812
Batch 31/64 loss: 2.486036777496338
Batch 32/64 loss: 2.412459373474121
Batch 33/64 loss: 2.3410964012145996
Batch 34/64 loss: 2.296229839324951
Batch 35/64 loss: 2.06618070602417
Batch 36/64 loss: 2.3971567153930664
Batch 37/64 loss: 2.3939061164855957
Batch 38/64 loss: 2.177140235900879
Batch 39/64 loss: 2.151125431060791
Batch 40/64 loss: 2.130814552307129
Batch 41/64 loss: 2.0862464904785156
Batch 42/64 loss: 2.5339550971984863
Batch 43/64 loss: 2.266915798187256
Batch 44/64 loss: 2.1773457527160645
Batch 45/64 loss: 2.3069019317626953
Batch 46/64 loss: 2.2241902351379395
Batch 47/64 loss: 2.1319808959960938
Batch 48/64 loss: 2.2819790840148926
Batch 49/64 loss: 2.1670331954956055
Batch 50/64 loss: 2.0905542373657227
Batch 51/64 loss: 2.3608107566833496
Batch 52/64 loss: 2.446653366088867
Batch 53/64 loss: 2.1618146896362305
Batch 54/64 loss: 2.3724045753479004
Batch 55/64 loss: 2.1309609413146973
Batch 56/64 loss: 2.287482261657715
Batch 57/64 loss: 2.2120862007141113
Batch 58/64 loss: 2.233835220336914
Batch 59/64 loss: 2.309035301208496
Batch 60/64 loss: 2.1104912757873535
Batch 61/64 loss: 2.062798023223877
Batch 62/64 loss: 2.163862705230713
Batch 63/64 loss: 2.2825393676757812
Batch 64/64 loss: -0.5936636924743652
Epoch 82  Train loss: 2.2493113704756196  Val loss: 2.0897240917297575
Saving best model, epoch: 82
Epoch 83
-------------------------------
Batch 1/64 loss: 2.274930000305176
Batch 2/64 loss: 2.261908531188965
Batch 3/64 loss: 2.233349323272705
Batch 4/64 loss: 2.453739643096924
Batch 5/64 loss: 2.124521255493164
Batch 6/64 loss: 2.066382884979248
Batch 7/64 loss: 2.1451239585876465
Batch 8/64 loss: 2.099186420440674
Batch 9/64 loss: 2.329817771911621
Batch 10/64 loss: 2.36287260055542
Batch 11/64 loss: 2.271352767944336
Batch 12/64 loss: 2.2227768898010254
Batch 13/64 loss: 2.276667594909668
Batch 14/64 loss: 2.108903408050537
Batch 15/64 loss: 2.208894729614258
Batch 16/64 loss: 2.382706642150879
Batch 17/64 loss: 2.224112033843994
Batch 18/64 loss: 2.2496700286865234
Batch 19/64 loss: 2.118229389190674
Batch 20/64 loss: 2.075806140899658
Batch 21/64 loss: 2.1142334938049316
Batch 22/64 loss: 2.7403292655944824
Batch 23/64 loss: 2.413635730743408
Batch 24/64 loss: 2.5032191276550293
Batch 25/64 loss: 2.218189239501953
Batch 26/64 loss: 2.200310230255127
Batch 27/64 loss: 2.039916515350342
Batch 28/64 loss: 2.354043483734131
Batch 29/64 loss: 2.573749542236328
Batch 30/64 loss: 2.31838321685791
Batch 31/64 loss: 2.2164039611816406
Batch 32/64 loss: 2.385733127593994
Batch 33/64 loss: 2.2960925102233887
Batch 34/64 loss: 2.3346128463745117
Batch 35/64 loss: 2.216585159301758
Batch 36/64 loss: 2.0628743171691895
Batch 37/64 loss: 2.3795180320739746
Batch 38/64 loss: 2.155022144317627
Batch 39/64 loss: 2.363994598388672
Batch 40/64 loss: 2.367830276489258
Batch 41/64 loss: 2.357633113861084
Batch 42/64 loss: 2.2508673667907715
Batch 43/64 loss: 2.2295055389404297
Batch 44/64 loss: 2.4088354110717773
Batch 45/64 loss: 2.3284358978271484
Batch 46/64 loss: 2.409979820251465
Batch 47/64 loss: 2.149562358856201
Batch 48/64 loss: 2.2767539024353027
Batch 49/64 loss: 2.457869529724121
Batch 50/64 loss: 2.2484078407287598
Batch 51/64 loss: 2.1665024757385254
Batch 52/64 loss: 2.1350650787353516
Batch 53/64 loss: 2.147785186767578
Batch 54/64 loss: 2.1636948585510254
Batch 55/64 loss: 2.4178881645202637
Batch 56/64 loss: 2.1941914558410645
Batch 57/64 loss: 2.2055716514587402
Batch 58/64 loss: 2.474557399749756
Batch 59/64 loss: 2.4526162147521973
Batch 60/64 loss: 2.431424140930176
Batch 61/64 loss: 2.570882797241211
Batch 62/64 loss: 2.360330104827881
Batch 63/64 loss: 2.4235315322875977
Batch 64/64 loss: -0.658808708190918
Epoch 83  Train loss: 2.251190810110055  Val loss: 2.2146797311265036
Epoch 84
-------------------------------
Batch 1/64 loss: 2.2069220542907715
Batch 2/64 loss: 2.334146499633789
Batch 3/64 loss: 2.3964486122131348
Batch 4/64 loss: 2.319303512573242
Batch 5/64 loss: 2.29848575592041
Batch 6/64 loss: 2.3007278442382812
Batch 7/64 loss: 2.1905875205993652
Batch 8/64 loss: 2.1854472160339355
Batch 9/64 loss: 2.6102309226989746
Batch 10/64 loss: 2.271785259246826
Batch 11/64 loss: 2.1211838722229004
Batch 12/64 loss: 2.156853675842285
Batch 13/64 loss: 2.4958882331848145
Batch 14/64 loss: 2.191262722015381
Batch 15/64 loss: 2.672353744506836
Batch 16/64 loss: 2.3522071838378906
Batch 17/64 loss: 2.389721393585205
Batch 18/64 loss: 2.196974754333496
Batch 19/64 loss: 2.209947109222412
Batch 20/64 loss: 2.246084690093994
Batch 21/64 loss: 2.3568577766418457
Batch 22/64 loss: 2.1450862884521484
Batch 23/64 loss: 2.17295503616333
Batch 24/64 loss: 2.3328733444213867
Batch 25/64 loss: 2.412027359008789
Batch 26/64 loss: 2.0694565773010254
Batch 27/64 loss: 2.1831607818603516
Batch 28/64 loss: 2.291801929473877
Batch 29/64 loss: 2.2171053886413574
Batch 30/64 loss: 2.1291375160217285
Batch 31/64 loss: 2.2748265266418457
Batch 32/64 loss: 2.46927547454834
Batch 33/64 loss: 2.154938220977783
Batch 34/64 loss: 2.312539577484131
Batch 35/64 loss: 2.310638427734375
Batch 36/64 loss: 2.3616738319396973
Batch 37/64 loss: 2.223444938659668
Batch 38/64 loss: 2.1553030014038086
Batch 39/64 loss: 2.3702807426452637
Batch 40/64 loss: 2.1754708290100098
Batch 41/64 loss: 2.033783435821533
Batch 42/64 loss: 2.055453300476074
Batch 43/64 loss: 2.330170154571533
Batch 44/64 loss: 2.2674975395202637
Batch 45/64 loss: 2.2829642295837402
Batch 46/64 loss: 2.290480613708496
Batch 47/64 loss: 2.3334717750549316
Batch 48/64 loss: 2.2532830238342285
Batch 49/64 loss: 2.151522159576416
Batch 50/64 loss: 2.076693534851074
Batch 51/64 loss: 2.1675586700439453
Batch 52/64 loss: 2.3079404830932617
Batch 53/64 loss: 2.3215789794921875
Batch 54/64 loss: 2.2252073287963867
Batch 55/64 loss: 2.1356868743896484
Batch 56/64 loss: 2.1890859603881836
Batch 57/64 loss: 2.176865577697754
Batch 58/64 loss: 1.9967637062072754
Batch 59/64 loss: 2.023210048675537
Batch 60/64 loss: 2.077451705932617
Batch 61/64 loss: 2.2356204986572266
Batch 62/64 loss: 2.262474536895752
Batch 63/64 loss: 2.2195382118225098
Batch 64/64 loss: -0.4972801208496094
Epoch 84  Train loss: 2.2165766024122053  Val loss: 2.0573035957887003
Saving best model, epoch: 84
Epoch 85
-------------------------------
Batch 1/64 loss: 2.0830206871032715
Batch 2/64 loss: 2.1513781547546387
Batch 3/64 loss: 2.2013444900512695
Batch 4/64 loss: 2.2087693214416504
Batch 5/64 loss: 2.2847046852111816
Batch 6/64 loss: 2.2931652069091797
Batch 7/64 loss: 2.6224312782287598
Batch 8/64 loss: 2.417970657348633
Batch 9/64 loss: 2.1395649909973145
Batch 10/64 loss: 2.3191475868225098
Batch 11/64 loss: 2.231748104095459
Batch 12/64 loss: 2.4158167839050293
Batch 13/64 loss: 2.3241658210754395
Batch 14/64 loss: 2.334977626800537
Batch 15/64 loss: 2.0622506141662598
Batch 16/64 loss: 2.3867573738098145
Batch 17/64 loss: 2.197307586669922
Batch 18/64 loss: 2.2361936569213867
Batch 19/64 loss: 2.134549617767334
Batch 20/64 loss: 2.0682730674743652
Batch 21/64 loss: 2.1893105506896973
Batch 22/64 loss: 2.0212602615356445
Batch 23/64 loss: 2.2518553733825684
Batch 24/64 loss: 2.584643840789795
Batch 25/64 loss: 2.217129707336426
Batch 26/64 loss: 2.40181303024292
Batch 27/64 loss: 2.0371785163879395
Batch 28/64 loss: 2.107217311859131
Batch 29/64 loss: 2.2893900871276855
Batch 30/64 loss: 2.260362148284912
Batch 31/64 loss: 2.335200309753418
Batch 32/64 loss: 2.217759132385254
Batch 33/64 loss: 2.362740993499756
Batch 34/64 loss: 2.142526149749756
Batch 35/64 loss: 2.2493491172790527
Batch 36/64 loss: 2.5021791458129883
Batch 37/64 loss: 2.154489040374756
Batch 38/64 loss: 2.2180838584899902
Batch 39/64 loss: 2.155928134918213
Batch 40/64 loss: 2.089451789855957
Batch 41/64 loss: 2.3040013313293457
Batch 42/64 loss: 2.1227197647094727
Batch 43/64 loss: 2.08502197265625
Batch 44/64 loss: 1.952336311340332
Batch 45/64 loss: 2.1789774894714355
Batch 46/64 loss: 2.0423169136047363
Batch 47/64 loss: 2.1715731620788574
Batch 48/64 loss: 2.4952306747436523
Batch 49/64 loss: 1.9860692024230957
Batch 50/64 loss: 2.152188301086426
Batch 51/64 loss: 2.0637564659118652
Batch 52/64 loss: 2.1492867469787598
Batch 53/64 loss: 1.9616179466247559
Batch 54/64 loss: 2.0353760719299316
Batch 55/64 loss: 2.188267707824707
Batch 56/64 loss: 2.1008949279785156
Batch 57/64 loss: 2.4451990127563477
Batch 58/64 loss: 2.216090679168701
Batch 59/64 loss: 2.121973991394043
Batch 60/64 loss: 2.008613109588623
Batch 61/64 loss: 2.1656041145324707
Batch 62/64 loss: 2.3553295135498047
Batch 63/64 loss: 2.157782554626465
Batch 64/64 loss: -0.9202375411987305
Epoch 85  Train loss: 2.175238519556382  Val loss: 1.9296237906229865
Saving best model, epoch: 85
Epoch 86
-------------------------------
Batch 1/64 loss: 2.0588560104370117
Batch 2/64 loss: 2.204306125640869
Batch 3/64 loss: 2.049569606781006
Batch 4/64 loss: 2.3321967124938965
Batch 5/64 loss: 2.132533073425293
Batch 6/64 loss: 2.117264747619629
Batch 7/64 loss: 2.2091526985168457
Batch 8/64 loss: 2.0183801651000977
Batch 9/64 loss: 2.102342128753662
Batch 10/64 loss: 2.241628646850586
Batch 11/64 loss: 2.1171889305114746
Batch 12/64 loss: 2.188476085662842
Batch 13/64 loss: 2.383248805999756
Batch 14/64 loss: 1.986734390258789
Batch 15/64 loss: 2.035503387451172
Batch 16/64 loss: 2.3022685050964355
Batch 17/64 loss: 2.208787441253662
Batch 18/64 loss: 2.3928709030151367
Batch 19/64 loss: 2.2984390258789062
Batch 20/64 loss: 2.1518964767456055
Batch 21/64 loss: 2.226424217224121
Batch 22/64 loss: 2.0550999641418457
Batch 23/64 loss: 2.069967746734619
Batch 24/64 loss: 1.981285572052002
Batch 25/64 loss: 2.110685348510742
Batch 26/64 loss: 2.1689419746398926
Batch 27/64 loss: 2.149808406829834
Batch 28/64 loss: 2.061161994934082
Batch 29/64 loss: 2.344789981842041
Batch 30/64 loss: 2.330996513366699
Batch 31/64 loss: 2.1474618911743164
Batch 32/64 loss: 2.1105804443359375
Batch 33/64 loss: 2.1837024688720703
Batch 34/64 loss: 2.501432418823242
Batch 35/64 loss: 2.2468485832214355
Batch 36/64 loss: 2.3928422927856445
Batch 37/64 loss: 2.1967239379882812
Batch 38/64 loss: 2.2330236434936523
Batch 39/64 loss: 2.0095887184143066
Batch 40/64 loss: 2.0662102699279785
Batch 41/64 loss: 2.32681941986084
Batch 42/64 loss: 2.4117860794067383
Batch 43/64 loss: 2.175851821899414
Batch 44/64 loss: 2.0940442085266113
Batch 45/64 loss: 2.0268187522888184
Batch 46/64 loss: 2.9170703887939453
Batch 47/64 loss: 2.080726146697998
Batch 48/64 loss: 2.5909175872802734
Batch 49/64 loss: 2.398622512817383
Batch 50/64 loss: 2.2080330848693848
Batch 51/64 loss: 2.2050223350524902
Batch 52/64 loss: 2.200291633605957
Batch 53/64 loss: 2.1564087867736816
Batch 54/64 loss: 2.1737613677978516
Batch 55/64 loss: 2.4212417602539062
Batch 56/64 loss: 2.195484161376953
Batch 57/64 loss: 2.344379425048828
Batch 58/64 loss: 2.2507128715515137
Batch 59/64 loss: 2.0765328407287598
Batch 60/64 loss: 2.086111068725586
Batch 61/64 loss: 2.3024139404296875
Batch 62/64 loss: 2.174069404602051
Batch 63/64 loss: 2.128993511199951
Batch 64/64 loss: -0.874809741973877
Epoch 86  Train loss: 2.171125114665312  Val loss: 2.0492055047418654
Epoch 87
-------------------------------
Batch 1/64 loss: 2.4884610176086426
Batch 2/64 loss: 2.112175464630127
Batch 3/64 loss: 2.1973671913146973
Batch 4/64 loss: 2.1253671646118164
Batch 5/64 loss: 2.1727333068847656
Batch 6/64 loss: 2.162844181060791
Batch 7/64 loss: 2.3228206634521484
Batch 8/64 loss: 2.270881175994873
Batch 9/64 loss: 2.1264147758483887
Batch 10/64 loss: 2.299283504486084
Batch 11/64 loss: 2.038823127746582
Batch 12/64 loss: 2.2784857749938965
Batch 13/64 loss: 2.2137246131896973
Batch 14/64 loss: 2.1439261436462402
Batch 15/64 loss: 2.179558277130127
Batch 16/64 loss: 2.088648796081543
Batch 17/64 loss: 2.01762056350708
Batch 18/64 loss: 2.1076579093933105
Batch 19/64 loss: 2.0502448081970215
Batch 20/64 loss: 2.210998058319092
Batch 21/64 loss: 2.170797824859619
Batch 22/64 loss: 2.2032532691955566
Batch 23/64 loss: 2.071499824523926
Batch 24/64 loss: 2.0767831802368164
Batch 25/64 loss: 2.3310251235961914
Batch 26/64 loss: 2.0774312019348145
Batch 27/64 loss: 2.316070079803467
Batch 28/64 loss: 2.249704360961914
Batch 29/64 loss: 2.1366143226623535
Batch 30/64 loss: 2.150635242462158
Batch 31/64 loss: 2.0666003227233887
Batch 32/64 loss: 2.436781883239746
Batch 33/64 loss: 2.3517489433288574
Batch 34/64 loss: 2.3260250091552734
Batch 35/64 loss: 2.1941962242126465
Batch 36/64 loss: 2.2177977561950684
Batch 37/64 loss: 2.229067325592041
Batch 38/64 loss: 2.038790702819824
Batch 39/64 loss: 2.120643138885498
Batch 40/64 loss: 2.2192673683166504
Batch 41/64 loss: 2.090348243713379
Batch 42/64 loss: 2.248462200164795
Batch 43/64 loss: 2.5195159912109375
Batch 44/64 loss: 2.343698024749756
Batch 45/64 loss: 2.1286368370056152
Batch 46/64 loss: 2.1216959953308105
Batch 47/64 loss: 2.0902810096740723
Batch 48/64 loss: 1.993901252746582
Batch 49/64 loss: 2.03519344329834
Batch 50/64 loss: 2.374873638153076
Batch 51/64 loss: 2.1396751403808594
Batch 52/64 loss: 2.085371971130371
Batch 53/64 loss: 1.980421543121338
Batch 54/64 loss: 2.3089447021484375
Batch 55/64 loss: 2.209951400756836
Batch 56/64 loss: 2.015064239501953
Batch 57/64 loss: 2.0680065155029297
Batch 58/64 loss: 2.2022128105163574
Batch 59/64 loss: 2.124211311340332
Batch 60/64 loss: 2.107649803161621
Batch 61/64 loss: 2.1081838607788086
Batch 62/64 loss: 2.0941295623779297
Batch 63/64 loss: 2.48399019241333
Batch 64/64 loss: -0.917050838470459
Epoch 87  Train loss: 2.145559234245151  Val loss: 1.955165489432738
Epoch 88
-------------------------------
Batch 1/64 loss: 2.230123519897461
Batch 2/64 loss: 2.2435994148254395
Batch 3/64 loss: 1.983874797821045
Batch 4/64 loss: 2.1129846572875977
Batch 5/64 loss: 2.226374626159668
Batch 6/64 loss: 2.100830554962158
Batch 7/64 loss: 2.216721534729004
Batch 8/64 loss: 2.19279146194458
Batch 9/64 loss: 2.189105987548828
Batch 10/64 loss: 2.1620731353759766
Batch 11/64 loss: 2.073399066925049
Batch 12/64 loss: 1.906506061553955
Batch 13/64 loss: 2.158503532409668
Batch 14/64 loss: 2.2392163276672363
Batch 15/64 loss: 2.1068434715270996
Batch 16/64 loss: 2.2819814682006836
Batch 17/64 loss: 2.153594970703125
Batch 18/64 loss: 2.3267455101013184
Batch 19/64 loss: 2.2693467140197754
Batch 20/64 loss: 2.0652999877929688
Batch 21/64 loss: 2.0253281593322754
Batch 22/64 loss: 2.0372180938720703
Batch 23/64 loss: 2.267378807067871
Batch 24/64 loss: 2.114226818084717
Batch 25/64 loss: 2.2355122566223145
Batch 26/64 loss: 2.084256172180176
Batch 27/64 loss: 2.196244716644287
Batch 28/64 loss: 2.513381004333496
Batch 29/64 loss: 2.288435459136963
Batch 30/64 loss: 2.2785468101501465
Batch 31/64 loss: 2.128312110900879
Batch 32/64 loss: 2.048671245574951
Batch 33/64 loss: 2.0430521965026855
Batch 34/64 loss: 2.1487464904785156
Batch 35/64 loss: 2.0843968391418457
Batch 36/64 loss: 2.1119704246520996
Batch 37/64 loss: 2.1356329917907715
Batch 38/64 loss: 2.2347617149353027
Batch 39/64 loss: 2.0380282402038574
Batch 40/64 loss: 2.3607282638549805
Batch 41/64 loss: 2.302927017211914
Batch 42/64 loss: 2.266704559326172
Batch 43/64 loss: 2.06624174118042
Batch 44/64 loss: 2.3316969871520996
Batch 45/64 loss: 2.268167018890381
Batch 46/64 loss: 2.043588638305664
Batch 47/64 loss: 2.08400821685791
Batch 48/64 loss: 2.077970027923584
Batch 49/64 loss: 2.0816378593444824
Batch 50/64 loss: 2.0364012718200684
Batch 51/64 loss: 2.001154899597168
Batch 52/64 loss: 2.1254758834838867
Batch 53/64 loss: 2.3225064277648926
Batch 54/64 loss: 2.178809642791748
Batch 55/64 loss: 2.0474348068237305
Batch 56/64 loss: 1.9483895301818848
Batch 57/64 loss: 2.0721211433410645
Batch 58/64 loss: 2.2352042198181152
Batch 59/64 loss: 2.3853302001953125
Batch 60/64 loss: 2.2905702590942383
Batch 61/64 loss: 2.0743837356567383
Batch 62/64 loss: 2.1947197914123535
Batch 63/64 loss: 2.0745315551757812
Batch 64/64 loss: -0.6830134391784668
Epoch 88  Train loss: 2.1272542897392723  Val loss: 2.008521411017454
Epoch 89
-------------------------------
Batch 1/64 loss: 2.0927486419677734
Batch 2/64 loss: 2.1811513900756836
Batch 3/64 loss: 2.1506142616271973
Batch 4/64 loss: 2.0715889930725098
Batch 5/64 loss: 2.207785129547119
Batch 6/64 loss: 2.250263214111328
Batch 7/64 loss: 1.9867496490478516
Batch 8/64 loss: 2.3266377449035645
Batch 9/64 loss: 2.170393466949463
Batch 10/64 loss: 2.143846035003662
Batch 11/64 loss: 2.063803195953369
Batch 12/64 loss: 2.262113571166992
Batch 13/64 loss: 2.3740453720092773
Batch 14/64 loss: 2.0925445556640625
Batch 15/64 loss: 1.9774160385131836
Batch 16/64 loss: 2.119727611541748
Batch 17/64 loss: 2.031153678894043
Batch 18/64 loss: 2.17795991897583
Batch 19/64 loss: 2.0415940284729004
Batch 20/64 loss: 2.0870485305786133
Batch 21/64 loss: 2.4334030151367188
Batch 22/64 loss: 2.2052178382873535
Batch 23/64 loss: 1.952448844909668
Batch 24/64 loss: 1.990466594696045
Batch 25/64 loss: 2.1629090309143066
Batch 26/64 loss: 2.118839740753174
Batch 27/64 loss: 2.2299370765686035
Batch 28/64 loss: 1.9968619346618652
Batch 29/64 loss: 2.1075053215026855
Batch 30/64 loss: 1.9986066818237305
Batch 31/64 loss: 2.023050308227539
Batch 32/64 loss: 2.349945068359375
Batch 33/64 loss: 1.998445987701416
Batch 34/64 loss: 1.9753613471984863
Batch 35/64 loss: 2.0044260025024414
Batch 36/64 loss: 2.064586639404297
Batch 37/64 loss: 2.217355728149414
Batch 38/64 loss: 2.186648368835449
Batch 39/64 loss: 2.0464253425598145
Batch 40/64 loss: 2.1023664474487305
Batch 41/64 loss: 2.2067465782165527
Batch 42/64 loss: 2.24385404586792
Batch 43/64 loss: 2.011932849884033
Batch 44/64 loss: 2.3416824340820312
Batch 45/64 loss: 2.1001434326171875
Batch 46/64 loss: 2.2049880027770996
Batch 47/64 loss: 2.1976962089538574
Batch 48/64 loss: 2.0564565658569336
Batch 49/64 loss: 2.277012348175049
Batch 50/64 loss: 2.1752686500549316
Batch 51/64 loss: 2.263491153717041
Batch 52/64 loss: 1.9746956825256348
Batch 53/64 loss: 2.22507905960083
Batch 54/64 loss: 2.155198097229004
Batch 55/64 loss: 2.304788589477539
Batch 56/64 loss: 1.9606623649597168
Batch 57/64 loss: 1.9740924835205078
Batch 58/64 loss: 2.054625988006592
Batch 59/64 loss: 1.9901909828186035
Batch 60/64 loss: 2.0165600776672363
Batch 61/64 loss: 2.3048171997070312
Batch 62/64 loss: 1.9973788261413574
Batch 63/64 loss: 2.1151251792907715
Batch 64/64 loss: -0.862696647644043
Epoch 89  Train loss: 2.09379539863736  Val loss: 1.8946436983613215
Saving best model, epoch: 89
Epoch 90
-------------------------------
Batch 1/64 loss: 2.0977673530578613
Batch 2/64 loss: 2.1168651580810547
Batch 3/64 loss: 2.0885982513427734
Batch 4/64 loss: 2.0601062774658203
Batch 5/64 loss: 2.212817668914795
Batch 6/64 loss: 2.200995922088623
Batch 7/64 loss: 2.4429707527160645
Batch 8/64 loss: 1.9496560096740723
Batch 9/64 loss: 2.2103447914123535
Batch 10/64 loss: 2.1801228523254395
Batch 11/64 loss: 2.0461692810058594
Batch 12/64 loss: 2.114495277404785
Batch 13/64 loss: 2.2884249687194824
Batch 14/64 loss: 2.1476101875305176
Batch 15/64 loss: 2.0279293060302734
Batch 16/64 loss: 2.2188401222229004
Batch 17/64 loss: 2.2272276878356934
Batch 18/64 loss: 2.1060032844543457
Batch 19/64 loss: 2.0450844764709473
Batch 20/64 loss: 2.1183905601501465
Batch 21/64 loss: 2.0846409797668457
Batch 22/64 loss: 2.2316017150878906
Batch 23/64 loss: 1.982508659362793
Batch 24/64 loss: 2.154323101043701
Batch 25/64 loss: 2.0466394424438477
Batch 26/64 loss: 2.2079238891601562
Batch 27/64 loss: 1.9897255897521973
Batch 28/64 loss: 2.06404972076416
Batch 29/64 loss: 2.1216769218444824
Batch 30/64 loss: 2.147519111633301
Batch 31/64 loss: 2.0128345489501953
Batch 32/64 loss: 2.3707633018493652
Batch 33/64 loss: 2.0443572998046875
Batch 34/64 loss: 2.2153048515319824
Batch 35/64 loss: 2.1370410919189453
Batch 36/64 loss: 2.1333508491516113
Batch 37/64 loss: 2.2275238037109375
Batch 38/64 loss: 2.221158504486084
Batch 39/64 loss: 2.1845078468322754
Batch 40/64 loss: 1.940171718597412
Batch 41/64 loss: 2.135744571685791
Batch 42/64 loss: 1.9901256561279297
Batch 43/64 loss: 2.1083950996398926
Batch 44/64 loss: 2.12943172454834
Batch 45/64 loss: 2.142549514770508
Batch 46/64 loss: 2.367283821105957
Batch 47/64 loss: 1.937574863433838
Batch 48/64 loss: 2.4693427085876465
Batch 49/64 loss: 2.141991138458252
Batch 50/64 loss: 2.0525107383728027
Batch 51/64 loss: 2.074531078338623
Batch 52/64 loss: 2.026421546936035
Batch 53/64 loss: 1.9770841598510742
Batch 54/64 loss: 2.1163620948791504
Batch 55/64 loss: 2.0028185844421387
Batch 56/64 loss: 2.0912365913391113
Batch 57/64 loss: 2.1544313430786133
Batch 58/64 loss: 2.2662768363952637
Batch 59/64 loss: 1.8951406478881836
Batch 60/64 loss: 1.9244565963745117
Batch 61/64 loss: 2.164125442504883
Batch 62/64 loss: 2.113337993621826
Batch 63/64 loss: 1.9928951263427734
Batch 64/64 loss: -0.9295544624328613
Epoch 90  Train loss: 2.086195218329336  Val loss: 1.9181339552312373
Epoch 91
-------------------------------
Batch 1/64 loss: 2.076172351837158
Batch 2/64 loss: 2.079885482788086
Batch 3/64 loss: 1.9292449951171875
Batch 4/64 loss: 2.033665657043457
Batch 5/64 loss: 2.0262317657470703
Batch 6/64 loss: 2.097412586212158
Batch 7/64 loss: 1.8783283233642578
Batch 8/64 loss: 1.9704818725585938
Batch 9/64 loss: 1.996387004852295
Batch 10/64 loss: 2.193875312805176
Batch 11/64 loss: 1.995957374572754
Batch 12/64 loss: 1.8926396369934082
Batch 13/64 loss: 2.1418304443359375
Batch 14/64 loss: 2.110898971557617
Batch 15/64 loss: 1.953096866607666
Batch 16/64 loss: 2.095090389251709
Batch 17/64 loss: 2.188769817352295
Batch 18/64 loss: 2.161952495574951
Batch 19/64 loss: 2.1294217109680176
Batch 20/64 loss: 2.2617626190185547
Batch 21/64 loss: 2.1438841819763184
Batch 22/64 loss: 2.0912351608276367
Batch 23/64 loss: 2.212036609649658
Batch 24/64 loss: 1.8622174263000488
Batch 25/64 loss: 1.947782039642334
Batch 26/64 loss: 1.9764723777770996
Batch 27/64 loss: 1.9684805870056152
Batch 28/64 loss: 2.0609188079833984
Batch 29/64 loss: 1.960202693939209
Batch 30/64 loss: 2.1407909393310547
Batch 31/64 loss: 2.259521007537842
Batch 32/64 loss: 2.2009634971618652
Batch 33/64 loss: 2.118347644805908
Batch 34/64 loss: 2.0356836318969727
Batch 35/64 loss: 2.081582546234131
Batch 36/64 loss: 1.8470125198364258
Batch 37/64 loss: 2.094451427459717
Batch 38/64 loss: 1.9502854347229004
Batch 39/64 loss: 2.1301889419555664
Batch 40/64 loss: 1.9723114967346191
Batch 41/64 loss: 2.0079808235168457
Batch 42/64 loss: 2.139714241027832
Batch 43/64 loss: 2.214015007019043
Batch 44/64 loss: 1.9806194305419922
Batch 45/64 loss: 1.980961799621582
Batch 46/64 loss: 1.9619512557983398
Batch 47/64 loss: 2.065370559692383
Batch 48/64 loss: 2.023928165435791
Batch 49/64 loss: 1.9120306968688965
Batch 50/64 loss: 2.1541781425476074
Batch 51/64 loss: 2.0511984825134277
Batch 52/64 loss: 2.191222667694092
Batch 53/64 loss: 2.248054027557373
Batch 54/64 loss: 2.1506404876708984
Batch 55/64 loss: 2.0479259490966797
Batch 56/64 loss: 1.9560399055480957
Batch 57/64 loss: 2.1037449836730957
Batch 58/64 loss: 2.010538101196289
Batch 59/64 loss: 1.9823684692382812
Batch 60/64 loss: 2.208634853363037
Batch 61/64 loss: 2.1725082397460938
Batch 62/64 loss: 1.9904136657714844
Batch 63/64 loss: 2.0157337188720703
Batch 64/64 loss: -1.1404366493225098
Epoch 91  Train loss: 2.0232458170722514  Val loss: 1.8563508954654444
Saving best model, epoch: 91
Epoch 92
-------------------------------
Batch 1/64 loss: 2.0587496757507324
Batch 2/64 loss: 2.011134147644043
Batch 3/64 loss: 2.1076059341430664
Batch 4/64 loss: 1.9469537734985352
Batch 5/64 loss: 1.9738731384277344
Batch 6/64 loss: 1.9061946868896484
Batch 7/64 loss: 1.8260173797607422
Batch 8/64 loss: 2.346048355102539
Batch 9/64 loss: 2.003419876098633
Batch 10/64 loss: 2.001946449279785
Batch 11/64 loss: 2.077852249145508
Batch 12/64 loss: 2.2209930419921875
Batch 13/64 loss: 1.9447484016418457
Batch 14/64 loss: 2.0843286514282227
Batch 15/64 loss: 2.030533790588379
Batch 16/64 loss: 2.0877532958984375
Batch 17/64 loss: 1.9094486236572266
Batch 18/64 loss: 2.0812363624572754
Batch 19/64 loss: 2.1472344398498535
Batch 20/64 loss: 1.9835600852966309
Batch 21/64 loss: 1.9570884704589844
Batch 22/64 loss: 1.9523100852966309
Batch 23/64 loss: 1.994180679321289
Batch 24/64 loss: 2.033543586730957
Batch 25/64 loss: 1.9676852226257324
Batch 26/64 loss: 2.214008331298828
Batch 27/64 loss: 1.9715681076049805
Batch 28/64 loss: 2.156900405883789
Batch 29/64 loss: 2.927950382232666
Batch 30/64 loss: 2.186279773712158
Batch 31/64 loss: 1.953871726989746
Batch 32/64 loss: 2.2209272384643555
Batch 33/64 loss: 2.038691997528076
Batch 34/64 loss: 2.3228039741516113
Batch 35/64 loss: 2.1857523918151855
Batch 36/64 loss: 2.3776683807373047
Batch 37/64 loss: 2.5220837593078613
Batch 38/64 loss: 2.370842933654785
Batch 39/64 loss: 2.3390936851501465
Batch 40/64 loss: 2.1861791610717773
Batch 41/64 loss: 2.4262189865112305
Batch 42/64 loss: 2.1492486000061035
Batch 43/64 loss: 2.144473075866699
Batch 44/64 loss: 2.188631057739258
Batch 45/64 loss: 2.4729199409484863
Batch 46/64 loss: 2.3027377128601074
Batch 47/64 loss: 2.3803844451904297
Batch 48/64 loss: 2.606626510620117
Batch 49/64 loss: 2.5553760528564453
Batch 50/64 loss: 2.370659351348877
Batch 51/64 loss: 2.476696491241455
Batch 52/64 loss: 2.358199119567871
Batch 53/64 loss: 2.054675579071045
Batch 54/64 loss: 2.005575180053711
Batch 55/64 loss: 2.156594753265381
Batch 56/64 loss: 2.200577735900879
Batch 57/64 loss: 2.8294811248779297
Batch 58/64 loss: 2.27125883102417
Batch 59/64 loss: 2.4554800987243652
Batch 60/64 loss: 2.642620086669922
Batch 61/64 loss: 2.336184501647949
Batch 62/64 loss: 2.1354899406433105
Batch 63/64 loss: 2.229848861694336
Batch 64/64 loss: -0.6593689918518066
Epoch 92  Train loss: 2.162894022698496  Val loss: 2.2032156482185283
Epoch 93
-------------------------------
Batch 1/64 loss: 2.1524205207824707
Batch 2/64 loss: 2.3066248893737793
Batch 3/64 loss: 2.110447406768799
Batch 4/64 loss: 2.2513742446899414
Batch 5/64 loss: 2.1781649589538574
Batch 6/64 loss: 2.4513282775878906
Batch 7/64 loss: 2.3156752586364746
Batch 8/64 loss: 2.116395950317383
Batch 9/64 loss: 2.354179859161377
Batch 10/64 loss: 3.143763542175293
Batch 11/64 loss: 2.501476287841797
Batch 12/64 loss: 2.546658515930176
Batch 13/64 loss: 2.2582287788391113
Batch 14/64 loss: 2.6751151084899902
Batch 15/64 loss: 2.066441535949707
Batch 16/64 loss: 2.2487921714782715
Batch 17/64 loss: 2.156656265258789
Batch 18/64 loss: 2.1989550590515137
Batch 19/64 loss: 2.1170105934143066
Batch 20/64 loss: 2.052863121032715
Batch 21/64 loss: 2.317824363708496
Batch 22/64 loss: 2.283740997314453
Batch 23/64 loss: 2.240969657897949
Batch 24/64 loss: 2.128570079803467
Batch 25/64 loss: 2.3364901542663574
Batch 26/64 loss: 2.163684844970703
Batch 27/64 loss: 2.1355690956115723
Batch 28/64 loss: 2.873140335083008
Batch 29/64 loss: 2.335794448852539
Batch 30/64 loss: 2.010807514190674
Batch 31/64 loss: 2.0993361473083496
Batch 32/64 loss: 2.2794556617736816
Batch 33/64 loss: 2.9538216590881348
Batch 34/64 loss: 1.9987573623657227
Batch 35/64 loss: 2.3482370376586914
Batch 36/64 loss: 2.103607177734375
Batch 37/64 loss: 2.3298754692077637
Batch 38/64 loss: 2.1050515174865723
Batch 39/64 loss: 2.222410202026367
Batch 40/64 loss: 2.294003486633301
Batch 41/64 loss: 2.1144819259643555
Batch 42/64 loss: 2.1356143951416016
Batch 43/64 loss: 2.199779510498047
Batch 44/64 loss: 2.3901009559631348
Batch 45/64 loss: 2.3263907432556152
Batch 46/64 loss: 2.1669297218322754
Batch 47/64 loss: 2.0722780227661133
Batch 48/64 loss: 2.180898666381836
Batch 49/64 loss: 2.2394232749938965
Batch 50/64 loss: 2.5271220207214355
Batch 51/64 loss: 2.220757007598877
Batch 52/64 loss: 2.2218241691589355
Batch 53/64 loss: 2.162254810333252
Batch 54/64 loss: 2.2224717140197754
Batch 55/64 loss: 1.9831280708312988
Batch 56/64 loss: 2.245473861694336
Batch 57/64 loss: 2.01937198638916
Batch 58/64 loss: 2.0262675285339355
Batch 59/64 loss: 2.0321412086486816
Batch 60/64 loss: 2.0898494720458984
Batch 61/64 loss: 2.2835254669189453
Batch 62/64 loss: 2.0558881759643555
Batch 63/64 loss: 2.1561079025268555
Batch 64/64 loss: -0.8993830680847168
Epoch 93  Train loss: 2.214294319526822  Val loss: 2.024582086150179
Epoch 94
-------------------------------
Batch 1/64 loss: 2.306990623474121
Batch 2/64 loss: 2.3091893196105957
Batch 3/64 loss: 2.557743549346924
Batch 4/64 loss: 2.3679938316345215
Batch 5/64 loss: 2.132613182067871
Batch 6/64 loss: 2.160482883453369
Batch 7/64 loss: 2.1062498092651367
Batch 8/64 loss: 2.221592903137207
Batch 9/64 loss: 2.129277229309082
Batch 10/64 loss: 1.9929776191711426
Batch 11/64 loss: 2.17287015914917
Batch 12/64 loss: 2.042422294616699
Batch 13/64 loss: 2.1089515686035156
Batch 14/64 loss: 2.236682891845703
Batch 15/64 loss: 2.24124813079834
Batch 16/64 loss: 2.107454299926758
Batch 17/64 loss: 2.0056843757629395
Batch 18/64 loss: 1.9575977325439453
Batch 19/64 loss: 2.415170669555664
Batch 20/64 loss: 2.289334774017334
Batch 21/64 loss: 2.1487045288085938
Batch 22/64 loss: 1.99546480178833
Batch 23/64 loss: 2.3305892944335938
Batch 24/64 loss: 2.054405689239502
Batch 25/64 loss: 2.1298646926879883
Batch 26/64 loss: 2.025442123413086
Batch 27/64 loss: 2.179777145385742
Batch 28/64 loss: 2.088019847869873
Batch 29/64 loss: 1.9557580947875977
Batch 30/64 loss: 1.9373555183410645
Batch 31/64 loss: 1.9685821533203125
Batch 32/64 loss: 2.012132167816162
Batch 33/64 loss: 1.9023284912109375
Batch 34/64 loss: 2.1370363235473633
Batch 35/64 loss: 1.8514533042907715
Batch 36/64 loss: 2.172913074493408
Batch 37/64 loss: 2.0947351455688477
Batch 38/64 loss: 1.9661493301391602
Batch 39/64 loss: 2.1512136459350586
Batch 40/64 loss: 1.9523425102233887
Batch 41/64 loss: 1.9798741340637207
Batch 42/64 loss: 1.9342994689941406
Batch 43/64 loss: 2.0057015419006348
Batch 44/64 loss: 2.053405284881592
Batch 45/64 loss: 2.0544028282165527
Batch 46/64 loss: 2.4672746658325195
Batch 47/64 loss: 2.253228187561035
Batch 48/64 loss: 2.3637304306030273
Batch 49/64 loss: 2.0785436630249023
Batch 50/64 loss: 1.9965424537658691
Batch 51/64 loss: 2.1079635620117188
Batch 52/64 loss: 2.0406055450439453
Batch 53/64 loss: 2.066359519958496
Batch 54/64 loss: 2.53262996673584
Batch 55/64 loss: 2.1744227409362793
Batch 56/64 loss: 2.057711601257324
Batch 57/64 loss: 2.0933732986450195
Batch 58/64 loss: 1.984227180480957
Batch 59/64 loss: 2.171868324279785
Batch 60/64 loss: 2.320209503173828
Batch 61/64 loss: 2.0476036071777344
Batch 62/64 loss: 2.233956813812256
Batch 63/64 loss: 2.1638593673706055
Batch 64/64 loss: -0.9717545509338379
Epoch 94  Train loss: 2.092074878543031  Val loss: 1.9068392527472113
Epoch 95
-------------------------------
Batch 1/64 loss: 2.0256128311157227
Batch 2/64 loss: 2.1408238410949707
Batch 3/64 loss: 2.09375
Batch 4/64 loss: 2.029021739959717
Batch 5/64 loss: 2.2891998291015625
Batch 6/64 loss: 1.9175710678100586
Batch 7/64 loss: 2.014346122741699
Batch 8/64 loss: 2.3547043800354004
Batch 9/64 loss: 2.1940131187438965
Batch 10/64 loss: 1.9967045783996582
Batch 11/64 loss: 2.0337772369384766
Batch 12/64 loss: 2.069276809692383
Batch 13/64 loss: 2.0315237045288086
Batch 14/64 loss: 2.002842426300049
Batch 15/64 loss: 2.0176053047180176
Batch 16/64 loss: 1.915229320526123
Batch 17/64 loss: 2.0600762367248535
Batch 18/64 loss: 2.1659021377563477
Batch 19/64 loss: 2.188021183013916
Batch 20/64 loss: 2.1092615127563477
Batch 21/64 loss: 2.1679654121398926
Batch 22/64 loss: 2.238576889038086
Batch 23/64 loss: 2.3610358238220215
Batch 24/64 loss: 2.2630205154418945
Batch 25/64 loss: 1.8729114532470703
Batch 26/64 loss: 2.075976848602295
Batch 27/64 loss: 2.1348109245300293
Batch 28/64 loss: 2.2241268157958984
Batch 29/64 loss: 2.0977768898010254
Batch 30/64 loss: 2.055748462677002
Batch 31/64 loss: 2.1103157997131348
Batch 32/64 loss: 2.1804375648498535
Batch 33/64 loss: 2.005446434020996
Batch 34/64 loss: 1.9570908546447754
Batch 35/64 loss: 2.0588221549987793
Batch 36/64 loss: 1.9124011993408203
Batch 37/64 loss: 2.0254077911376953
Batch 38/64 loss: 2.2386484146118164
Batch 39/64 loss: 2.1077675819396973
Batch 40/64 loss: 2.049449920654297
Batch 41/64 loss: 2.007993698120117
Batch 42/64 loss: 2.0058846473693848
Batch 43/64 loss: 2.045867443084717
Batch 44/64 loss: 2.1841540336608887
Batch 45/64 loss: 2.279205799102783
Batch 46/64 loss: 2.082411766052246
Batch 47/64 loss: 2.049023151397705
Batch 48/64 loss: 2.0134143829345703
Batch 49/64 loss: 2.004241466522217
Batch 50/64 loss: 2.152484893798828
Batch 51/64 loss: 1.8300914764404297
Batch 52/64 loss: 1.9883537292480469
Batch 53/64 loss: 2.3154983520507812
Batch 54/64 loss: 2.028195858001709
Batch 55/64 loss: 2.022995948791504
Batch 56/64 loss: 1.8264241218566895
Batch 57/64 loss: 1.933197021484375
Batch 58/64 loss: 1.821958065032959
Batch 59/64 loss: 1.9739670753479004
Batch 60/64 loss: 1.9392127990722656
Batch 61/64 loss: 1.8439640998840332
Batch 62/64 loss: 2.0748987197875977
Batch 63/64 loss: 1.8203668594360352
Batch 64/64 loss: -1.0868120193481445
Epoch 95  Train loss: 2.0269129023832435  Val loss: 1.8252088933466226
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: 1.854794979095459
Batch 2/64 loss: 1.9738073348999023
Batch 3/64 loss: 1.9117422103881836
Batch 4/64 loss: 2.0076451301574707
Batch 5/64 loss: 2.106236457824707
Batch 6/64 loss: 2.0425515174865723
Batch 7/64 loss: 2.16373872756958
Batch 8/64 loss: 2.1212000846862793
Batch 9/64 loss: 2.077085018157959
Batch 10/64 loss: 2.177285671234131
Batch 11/64 loss: 2.3382034301757812
Batch 12/64 loss: 1.9903535842895508
Batch 13/64 loss: 2.1683945655822754
Batch 14/64 loss: 1.9532203674316406
Batch 15/64 loss: 2.2393412590026855
Batch 16/64 loss: 1.9515652656555176
Batch 17/64 loss: 2.149372100830078
Batch 18/64 loss: 2.110081672668457
Batch 19/64 loss: 2.098785400390625
Batch 20/64 loss: 2.1931071281433105
Batch 21/64 loss: 1.9307661056518555
Batch 22/64 loss: 1.9166245460510254
Batch 23/64 loss: 2.169191360473633
Batch 24/64 loss: 1.9130682945251465
Batch 25/64 loss: 1.9131355285644531
Batch 26/64 loss: 1.9999518394470215
Batch 27/64 loss: 1.9366235733032227
Batch 28/64 loss: 1.9647445678710938
Batch 29/64 loss: 2.0696187019348145
Batch 30/64 loss: 1.8622279167175293
Batch 31/64 loss: 2.103177070617676
Batch 32/64 loss: 1.9392948150634766
Batch 33/64 loss: 2.0133471488952637
Batch 34/64 loss: 1.8766427040100098
Batch 35/64 loss: 2.0748825073242188
Batch 36/64 loss: 1.897965431213379
Batch 37/64 loss: 2.0962677001953125
Batch 38/64 loss: 2.254756450653076
Batch 39/64 loss: 2.2641868591308594
Batch 40/64 loss: 2.0043578147888184
Batch 41/64 loss: 1.9196696281433105
Batch 42/64 loss: 1.9563345909118652
Batch 43/64 loss: 1.9433879852294922
Batch 44/64 loss: 1.8983101844787598
Batch 45/64 loss: 1.900383472442627
Batch 46/64 loss: 2.0853629112243652
Batch 47/64 loss: 2.060483932495117
Batch 48/64 loss: 2.053539752960205
Batch 49/64 loss: 2.1017489433288574
Batch 50/64 loss: 1.8988661766052246
Batch 51/64 loss: 2.0662832260131836
Batch 52/64 loss: 2.032794952392578
Batch 53/64 loss: 2.319976329803467
Batch 54/64 loss: 1.9602313041687012
Batch 55/64 loss: 2.0757641792297363
Batch 56/64 loss: 2.2056713104248047
Batch 57/64 loss: 1.959568977355957
Batch 58/64 loss: 2.1960206031799316
Batch 59/64 loss: 2.007192611694336
Batch 60/64 loss: 2.2962489128112793
Batch 61/64 loss: 2.1964569091796875
Batch 62/64 loss: 2.2341742515563965
Batch 63/64 loss: 2.061429500579834
Batch 64/64 loss: -1.1951336860656738
Epoch 96  Train loss: 2.0135355799805885  Val loss: 1.8362557650431734
Epoch 97
-------------------------------
Batch 1/64 loss: 2.1262803077697754
Batch 2/64 loss: 2.0138349533081055
Batch 3/64 loss: 1.9450130462646484
Batch 4/64 loss: 2.1017355918884277
Batch 5/64 loss: 2.3226566314697266
Batch 6/64 loss: 1.956991195678711
Batch 7/64 loss: 2.1965231895446777
Batch 8/64 loss: 1.9597992897033691
Batch 9/64 loss: 1.978104591369629
Batch 10/64 loss: 2.016417980194092
Batch 11/64 loss: 1.9977831840515137
Batch 12/64 loss: 1.835996150970459
Batch 13/64 loss: 2.1129941940307617
Batch 14/64 loss: 1.9552416801452637
Batch 15/64 loss: 2.116866111755371
Batch 16/64 loss: 1.9761338233947754
Batch 17/64 loss: 1.9989705085754395
Batch 18/64 loss: 2.0427422523498535
Batch 19/64 loss: 2.5429043769836426
Batch 20/64 loss: 2.0460548400878906
Batch 21/64 loss: 2.0022759437561035
Batch 22/64 loss: 2.118992805480957
Batch 23/64 loss: 2.001008987426758
Batch 24/64 loss: 2.143218517303467
Batch 25/64 loss: 1.9077887535095215
Batch 26/64 loss: 1.8733906745910645
Batch 27/64 loss: 2.2543859481811523
Batch 28/64 loss: 2.2295899391174316
Batch 29/64 loss: 2.013516426086426
Batch 30/64 loss: 2.179182529449463
Batch 31/64 loss: 2.0279946327209473
Batch 32/64 loss: 2.2044386863708496
Batch 33/64 loss: 2.1113362312316895
Batch 34/64 loss: 1.9697623252868652
Batch 35/64 loss: 2.0322976112365723
Batch 36/64 loss: 1.9921016693115234
Batch 37/64 loss: 1.9283618927001953
Batch 38/64 loss: 1.8330655097961426
Batch 39/64 loss: 2.05873966217041
Batch 40/64 loss: 2.1286206245422363
Batch 41/64 loss: 1.9810500144958496
Batch 42/64 loss: 2.0732340812683105
Batch 43/64 loss: 1.9558687210083008
Batch 44/64 loss: 1.9281997680664062
Batch 45/64 loss: 1.9648075103759766
Batch 46/64 loss: 1.8431415557861328
Batch 47/64 loss: 2.141104221343994
Batch 48/64 loss: 2.0172529220581055
Batch 49/64 loss: 1.8490939140319824
Batch 50/64 loss: 1.9879136085510254
Batch 51/64 loss: 2.1494011878967285
Batch 52/64 loss: 2.176377773284912
Batch 53/64 loss: 1.8784632682800293
Batch 54/64 loss: 1.7936387062072754
Batch 55/64 loss: 2.0056819915771484
Batch 56/64 loss: 2.0212602615356445
Batch 57/64 loss: 1.9601593017578125
Batch 58/64 loss: 1.861727237701416
Batch 59/64 loss: 1.8842625617980957
Batch 60/64 loss: 1.888624668121338
Batch 61/64 loss: 1.8519539833068848
Batch 62/64 loss: 1.916419506072998
Batch 63/64 loss: 1.9659805297851562
Batch 64/64 loss: -1.2072467803955078
Epoch 97  Train loss: 1.9834242428050322  Val loss: 1.81870053478123
Saving best model, epoch: 97
Epoch 98
-------------------------------
Batch 1/64 loss: 1.9975872039794922
Batch 2/64 loss: 2.1081371307373047
Batch 3/64 loss: 2.0237460136413574
Batch 4/64 loss: 2.0322279930114746
Batch 5/64 loss: 1.9543704986572266
Batch 6/64 loss: 1.8962926864624023
Batch 7/64 loss: 2.2804551124572754
Batch 8/64 loss: 2.0491628646850586
Batch 9/64 loss: 1.9943928718566895
Batch 10/64 loss: 2.1013078689575195
Batch 11/64 loss: 1.9784069061279297
Batch 12/64 loss: 1.8903403282165527
Batch 13/64 loss: 1.887000560760498
Batch 14/64 loss: 2.026547908782959
Batch 15/64 loss: 1.921950340270996
Batch 16/64 loss: 1.9236130714416504
Batch 17/64 loss: 2.143465995788574
Batch 18/64 loss: 2.0641207695007324
Batch 19/64 loss: 2.1151461601257324
Batch 20/64 loss: 1.9482598304748535
Batch 21/64 loss: 2.125730037689209
Batch 22/64 loss: 1.9942774772644043
Batch 23/64 loss: 2.098703384399414
Batch 24/64 loss: 1.9664945602416992
Batch 25/64 loss: 1.9987268447875977
Batch 26/64 loss: 2.012136936187744
Batch 27/64 loss: 2.015892505645752
Batch 28/64 loss: 2.1205368041992188
Batch 29/64 loss: 2.4582362174987793
Batch 30/64 loss: 1.906428337097168
Batch 31/64 loss: 2.053250312805176
Batch 32/64 loss: 1.9001140594482422
Batch 33/64 loss: 1.9885435104370117
Batch 34/64 loss: 2.1076154708862305
Batch 35/64 loss: 1.9307808876037598
Batch 36/64 loss: 1.9837298393249512
Batch 37/64 loss: 2.0207419395446777
Batch 38/64 loss: 1.9250240325927734
Batch 39/64 loss: 1.9057292938232422
Batch 40/64 loss: 2.053380012512207
Batch 41/64 loss: 1.8742117881774902
Batch 42/64 loss: 2.189138889312744
Batch 43/64 loss: 2.0028228759765625
Batch 44/64 loss: 2.0825915336608887
Batch 45/64 loss: 2.0571165084838867
Batch 46/64 loss: 2.025768280029297
Batch 47/64 loss: 1.9606389999389648
Batch 48/64 loss: 1.735651969909668
Batch 49/64 loss: 1.9589171409606934
Batch 50/64 loss: 2.1821084022521973
Batch 51/64 loss: 1.970067024230957
Batch 52/64 loss: 2.0409111976623535
Batch 53/64 loss: 1.8449559211730957
Batch 54/64 loss: 2.2101564407348633
Batch 55/64 loss: 2.0307230949401855
Batch 56/64 loss: 2.0352745056152344
Batch 57/64 loss: 1.8299527168273926
Batch 58/64 loss: 1.9791264533996582
Batch 59/64 loss: 2.0269341468811035
Batch 60/64 loss: 2.2555503845214844
Batch 61/64 loss: 1.8016672134399414
Batch 62/64 loss: 1.9199433326721191
Batch 63/64 loss: 1.9575634002685547
Batch 64/64 loss: -1.171583652496338
Epoch 98  Train loss: 1.976403279398002  Val loss: 1.7597669096746804
Saving best model, epoch: 98
Epoch 99
-------------------------------
Batch 1/64 loss: 2.0310568809509277
Batch 2/64 loss: 1.7241010665893555
Batch 3/64 loss: 1.9566597938537598
Batch 4/64 loss: 1.8736214637756348
Batch 5/64 loss: 2.012157440185547
Batch 6/64 loss: 1.9560737609863281
Batch 7/64 loss: 2.000000476837158
Batch 8/64 loss: 1.760293960571289
Batch 9/64 loss: 1.9969110488891602
Batch 10/64 loss: 1.9380979537963867
Batch 11/64 loss: 2.0873584747314453
Batch 12/64 loss: 2.0222043991088867
Batch 13/64 loss: 1.850843906402588
Batch 14/64 loss: 2.000401020050049
Batch 15/64 loss: 1.8099312782287598
Batch 16/64 loss: 1.8600993156433105
Batch 17/64 loss: 2.101461887359619
Batch 18/64 loss: 1.897409439086914
Batch 19/64 loss: 2.0537023544311523
Batch 20/64 loss: 1.9716196060180664
Batch 21/64 loss: 1.9624300003051758
Batch 22/64 loss: 1.9235706329345703
Batch 23/64 loss: 1.8916082382202148
Batch 24/64 loss: 2.0622267723083496
Batch 25/64 loss: 1.8874526023864746
Batch 26/64 loss: 1.9651665687561035
Batch 27/64 loss: 2.01023530960083
Batch 28/64 loss: 1.9672222137451172
Batch 29/64 loss: 2.0028018951416016
Batch 30/64 loss: 2.0132479667663574
Batch 31/64 loss: 2.0715928077697754
Batch 32/64 loss: 1.8297786712646484
Batch 33/64 loss: 1.9222493171691895
Batch 34/64 loss: 1.8568429946899414
Batch 35/64 loss: 1.9156899452209473
Batch 36/64 loss: 2.042482852935791
Batch 37/64 loss: 1.8535242080688477
Batch 38/64 loss: 2.292278289794922
Batch 39/64 loss: 1.9203829765319824
Batch 40/64 loss: 1.8543415069580078
Batch 41/64 loss: 1.9815187454223633
Batch 42/64 loss: 1.8598299026489258
Batch 43/64 loss: 1.935795783996582
Batch 44/64 loss: 1.8882064819335938
Batch 45/64 loss: 1.9256305694580078
Batch 46/64 loss: 1.8777318000793457
Batch 47/64 loss: 2.062650203704834
Batch 48/64 loss: 1.8737082481384277
Batch 49/64 loss: 1.9986538887023926
Batch 50/64 loss: 1.8940491676330566
Batch 51/64 loss: 1.9361419677734375
Batch 52/64 loss: 1.9265265464782715
Batch 53/64 loss: 1.9349632263183594
Batch 54/64 loss: 1.8385133743286133
Batch 55/64 loss: 1.8455047607421875
Batch 56/64 loss: 2.1404662132263184
Batch 57/64 loss: 1.9691472053527832
Batch 58/64 loss: 2.0764122009277344
Batch 59/64 loss: 1.8160300254821777
Batch 60/64 loss: 2.166079521179199
Batch 61/64 loss: 1.8010916709899902
Batch 62/64 loss: 1.9475297927856445
Batch 63/64 loss: 1.9131245613098145
Batch 64/64 loss: -1.447713851928711
Epoch 99  Train loss: 1.9085906159644033  Val loss: 1.6852686577236529
Saving best model, epoch: 99
Epoch 100
-------------------------------
Batch 1/64 loss: 2.102694034576416
Batch 2/64 loss: 1.7970857620239258
Batch 3/64 loss: 1.9306745529174805
Batch 4/64 loss: 2.007293224334717
Batch 5/64 loss: 2.1950879096984863
Batch 6/64 loss: 2.0241761207580566
Batch 7/64 loss: 1.9432897567749023
Batch 8/64 loss: 1.881582260131836
Batch 9/64 loss: 1.8776493072509766
Batch 10/64 loss: 2.0438733100891113
Batch 11/64 loss: 1.9001960754394531
Batch 12/64 loss: 1.811612606048584
Batch 13/64 loss: 2.1931285858154297
Batch 14/64 loss: 1.8742337226867676
Batch 15/64 loss: 2.068159580230713
Batch 16/64 loss: 1.9058480262756348
Batch 17/64 loss: 1.9098577499389648
Batch 18/64 loss: 2.0028553009033203
Batch 19/64 loss: 2.0652337074279785
Batch 20/64 loss: 1.9199333190917969
Batch 21/64 loss: 1.824045181274414
Batch 22/64 loss: 1.9516010284423828
Batch 23/64 loss: 1.943197250366211
Batch 24/64 loss: 1.8734130859375
Batch 25/64 loss: 1.800255298614502
Batch 26/64 loss: 2.027958393096924
Batch 27/64 loss: 1.8226966857910156
Batch 28/64 loss: 1.893310546875
Batch 29/64 loss: 1.7511978149414062
Batch 30/64 loss: 1.933276653289795
Batch 31/64 loss: 1.9921445846557617
Batch 32/64 loss: 1.902420997619629
Batch 33/64 loss: 1.9357085227966309
Batch 34/64 loss: 1.8724346160888672
Batch 35/64 loss: 1.849186897277832
Batch 36/64 loss: 2.061955451965332
Batch 37/64 loss: 2.050083637237549
Batch 38/64 loss: 1.9683489799499512
Batch 39/64 loss: 2.172558307647705
Batch 40/64 loss: 2.0452961921691895
Batch 41/64 loss: 1.897963047027588
Batch 42/64 loss: 2.1079044342041016
Batch 43/64 loss: 1.9177393913269043
Batch 44/64 loss: 2.1352052688598633
Batch 45/64 loss: 2.121835708618164
Batch 46/64 loss: 1.911928653717041
Batch 47/64 loss: 1.9320435523986816
Batch 48/64 loss: 1.929518699645996
Batch 49/64 loss: 2.121361255645752
Batch 50/64 loss: 1.90093994140625
Batch 51/64 loss: 1.8959555625915527
Batch 52/64 loss: 1.9911575317382812
Batch 53/64 loss: 1.9960427284240723
Batch 54/64 loss: 2.0285792350769043
Batch 55/64 loss: 1.853696346282959
Batch 56/64 loss: 2.029141902923584
Batch 57/64 loss: 1.9715075492858887
Batch 58/64 loss: 2.116260051727295
Batch 59/64 loss: 2.108003616333008
Batch 60/64 loss: 2.0140914916992188
Batch 61/64 loss: 2.090176582336426
Batch 62/64 loss: 2.037323474884033
Batch 63/64 loss: 2.0870394706726074
Batch 64/64 loss: -1.0726613998413086
Epoch 100  Train loss: 1.9375133252611347  Val loss: 1.7400007870598757
Epoch 101
-------------------------------
Batch 1/64 loss: 1.9372882843017578
Batch 2/64 loss: 1.9317712783813477
Batch 3/64 loss: 1.8723564147949219
Batch 4/64 loss: 1.927661418914795
Batch 5/64 loss: 1.8429136276245117
Batch 6/64 loss: 1.9326801300048828
Batch 7/64 loss: 2.0579657554626465
Batch 8/64 loss: 2.1202821731567383
Batch 9/64 loss: 1.9896302223205566
Batch 10/64 loss: 1.907081127166748
Batch 11/64 loss: 1.8331665992736816
Batch 12/64 loss: 1.976914405822754
Batch 13/64 loss: 1.952183723449707
Batch 14/64 loss: 2.251798629760742
Batch 15/64 loss: 2.0113377571105957
Batch 16/64 loss: 2.026336669921875
Batch 17/64 loss: 1.9215645790100098
Batch 18/64 loss: 2.1268062591552734
Batch 19/64 loss: 2.1955223083496094
Batch 20/64 loss: 1.9555034637451172
Batch 21/64 loss: 1.9853501319885254
Batch 22/64 loss: 2.118713855743408
Batch 23/64 loss: 1.8183526992797852
Batch 24/64 loss: 2.1174769401550293
Batch 25/64 loss: 2.137788772583008
Batch 26/64 loss: 2.0005745887756348
Batch 27/64 loss: 1.911642074584961
Batch 28/64 loss: 1.9314823150634766
Batch 29/64 loss: 1.8138689994812012
Batch 30/64 loss: 1.864354133605957
Batch 31/64 loss: 1.9423136711120605
Batch 32/64 loss: 1.9933128356933594
Batch 33/64 loss: 2.0499677658081055
Batch 34/64 loss: 2.011197566986084
Batch 35/64 loss: 1.8539834022521973
Batch 36/64 loss: 2.099839687347412
Batch 37/64 loss: 2.184202194213867
Batch 38/64 loss: 2.0807132720947266
Batch 39/64 loss: 2.0723986625671387
Batch 40/64 loss: 1.9362316131591797
Batch 41/64 loss: 1.9099206924438477
Batch 42/64 loss: 1.9276361465454102
Batch 43/64 loss: 2.0164995193481445
Batch 44/64 loss: 1.862152099609375
Batch 45/64 loss: 2.11251163482666
Batch 46/64 loss: 2.0720157623291016
Batch 47/64 loss: 2.1161208152770996
Batch 48/64 loss: 2.0650410652160645
Batch 49/64 loss: 1.8646550178527832
Batch 50/64 loss: 1.7878165245056152
Batch 51/64 loss: 1.9812755584716797
Batch 52/64 loss: 1.8814873695373535
Batch 53/64 loss: 1.9488186836242676
Batch 54/64 loss: 2.1446471214294434
Batch 55/64 loss: 1.9778027534484863
Batch 56/64 loss: 1.9818081855773926
Batch 57/64 loss: 1.9727411270141602
Batch 58/64 loss: 1.8106303215026855
Batch 59/64 loss: 1.9116735458374023
Batch 60/64 loss: 1.9087858200073242
Batch 61/64 loss: 1.8273077011108398
Batch 62/64 loss: 1.8951458930969238
Batch 63/64 loss: 2.0068740844726562
Batch 64/64 loss: -1.1272592544555664
Epoch 101  Train loss: 1.942469851175944  Val loss: 1.7686214840289243
Epoch 102
-------------------------------
Batch 1/64 loss: 1.8172659873962402
Batch 2/64 loss: 1.9690961837768555
Batch 3/64 loss: 1.9469609260559082
Batch 4/64 loss: 1.8557243347167969
Batch 5/64 loss: 2.409492015838623
Batch 6/64 loss: 1.9673118591308594
Batch 7/64 loss: 1.997802734375
Batch 8/64 loss: 1.9748597145080566
Batch 9/64 loss: 1.9845905303955078
Batch 10/64 loss: 2.083432197570801
Batch 11/64 loss: 2.2123827934265137
Batch 12/64 loss: 2.213822841644287
Batch 13/64 loss: 2.168639659881592
Batch 14/64 loss: 1.8987417221069336
Batch 15/64 loss: 1.8809185028076172
Batch 16/64 loss: 1.95367431640625
Batch 17/64 loss: 2.0327229499816895
Batch 18/64 loss: 2.0007400512695312
Batch 19/64 loss: 1.815955638885498
Batch 20/64 loss: 2.2649617195129395
Batch 21/64 loss: 2.221007823944092
Batch 22/64 loss: 1.9919195175170898
Batch 23/64 loss: 1.9366579055786133
Batch 24/64 loss: 2.2329893112182617
Batch 25/64 loss: 1.9668707847595215
Batch 26/64 loss: 1.9712638854980469
Batch 27/64 loss: 2.2204508781433105
Batch 28/64 loss: 1.9311280250549316
Batch 29/64 loss: 1.953378677368164
Batch 30/64 loss: 1.9176764488220215
Batch 31/64 loss: 2.097151756286621
Batch 32/64 loss: 2.193359851837158
Batch 33/64 loss: 1.9045329093933105
Batch 34/64 loss: 1.9290714263916016
Batch 35/64 loss: 1.7579898834228516
Batch 36/64 loss: 1.8646764755249023
Batch 37/64 loss: 1.9685578346252441
Batch 38/64 loss: 1.9952592849731445
Batch 39/64 loss: 1.9673128128051758
Batch 40/64 loss: 2.0771355628967285
Batch 41/64 loss: 2.0353775024414062
Batch 42/64 loss: 2.4139342308044434
Batch 43/64 loss: 2.173914909362793
Batch 44/64 loss: 1.937084674835205
Batch 45/64 loss: 1.8548150062561035
Batch 46/64 loss: 2.1177663803100586
Batch 47/64 loss: 2.1769542694091797
Batch 48/64 loss: 2.2688803672790527
Batch 49/64 loss: 2.159916400909424
Batch 50/64 loss: 1.9086637496948242
Batch 51/64 loss: 1.9900012016296387
Batch 52/64 loss: 1.8662066459655762
Batch 53/64 loss: 2.0383949279785156
Batch 54/64 loss: 1.9745330810546875
Batch 55/64 loss: 1.9774723052978516
Batch 56/64 loss: 2.097653865814209
Batch 57/64 loss: 2.056316375732422
Batch 58/64 loss: 2.088801383972168
Batch 59/64 loss: 2.1871495246887207
Batch 60/64 loss: 2.0703892707824707
Batch 61/64 loss: 1.9102253913879395
Batch 62/64 loss: 2.180233955383301
Batch 63/64 loss: 1.8422584533691406
Batch 64/64 loss: -1.1824936866760254
Epoch 102  Train loss: 1.9919617465898103  Val loss: 1.8791966389134986
Epoch 103
-------------------------------
Batch 1/64 loss: 2.28043794631958
Batch 2/64 loss: 2.114589214324951
Batch 3/64 loss: 2.0529727935791016
Batch 4/64 loss: 1.9033622741699219
Batch 5/64 loss: 1.981400489807129
Batch 6/64 loss: 1.9257793426513672
Batch 7/64 loss: 2.0379724502563477
Batch 8/64 loss: 2.13700532913208
Batch 9/64 loss: 2.0349884033203125
Batch 10/64 loss: 2.0258517265319824
Batch 11/64 loss: 2.122887134552002
Batch 12/64 loss: 2.108689308166504
Batch 13/64 loss: 2.0596261024475098
Batch 14/64 loss: 2.191287040710449
Batch 15/64 loss: 1.993001937866211
Batch 16/64 loss: 1.9544892311096191
Batch 17/64 loss: 1.8857450485229492
Batch 18/64 loss: 2.2171969413757324
Batch 19/64 loss: 2.0084290504455566
Batch 20/64 loss: 2.0106730461120605
Batch 21/64 loss: 1.864452838897705
Batch 22/64 loss: 1.9917678833007812
Batch 23/64 loss: 2.112452507019043
Batch 24/64 loss: 1.964543342590332
Batch 25/64 loss: 1.9919843673706055
Batch 26/64 loss: 2.1948771476745605
Batch 27/64 loss: 1.911428451538086
Batch 28/64 loss: 1.9831476211547852
Batch 29/64 loss: 1.989959716796875
Batch 30/64 loss: 1.910210132598877
Batch 31/64 loss: 1.999898910522461
Batch 32/64 loss: 1.900747299194336
Batch 33/64 loss: 1.991945743560791
Batch 34/64 loss: 1.9531922340393066
Batch 35/64 loss: 1.9062113761901855
Batch 36/64 loss: 1.9889779090881348
Batch 37/64 loss: 1.9154052734375
Batch 38/64 loss: 2.065371036529541
Batch 39/64 loss: 1.9584922790527344
Batch 40/64 loss: 1.8948111534118652
Batch 41/64 loss: 1.961958408355713
Batch 42/64 loss: 1.9164752960205078
Batch 43/64 loss: 1.882911205291748
Batch 44/64 loss: 2.080094814300537
Batch 45/64 loss: 1.902662754058838
Batch 46/64 loss: 1.9524650573730469
Batch 47/64 loss: 1.9547419548034668
Batch 48/64 loss: 2.0380611419677734
Batch 49/64 loss: 1.94105863571167
Batch 50/64 loss: 1.8853960037231445
Batch 51/64 loss: 1.930182933807373
Batch 52/64 loss: 1.9202380180358887
Batch 53/64 loss: 1.8041877746582031
Batch 54/64 loss: 1.8208818435668945
Batch 55/64 loss: 1.9196505546569824
Batch 56/64 loss: 2.123032569885254
Batch 57/64 loss: 2.2273974418640137
Batch 58/64 loss: 2.0717954635620117
Batch 59/64 loss: 1.8863263130187988
Batch 60/64 loss: 1.89198637008667
Batch 61/64 loss: 2.0140113830566406
Batch 62/64 loss: 1.790548324584961
Batch 63/64 loss: 2.0007753372192383
Batch 64/64 loss: -1.3199729919433594
Epoch 103  Train loss: 1.9523626963297527  Val loss: 1.7892163397929923
Epoch 104
-------------------------------
Batch 1/64 loss: 2.1044840812683105
Batch 2/64 loss: 2.113396644592285
Batch 3/64 loss: 1.928330421447754
Batch 4/64 loss: 1.8779606819152832
Batch 5/64 loss: 2.0554141998291016
Batch 6/64 loss: 1.9993767738342285
Batch 7/64 loss: 1.9880762100219727
Batch 8/64 loss: 2.2553811073303223
Batch 9/64 loss: 2.004179000854492
Batch 10/64 loss: 1.9673686027526855
Batch 11/64 loss: 1.9698266983032227
Batch 12/64 loss: 2.105412006378174
Batch 13/64 loss: 1.9143857955932617
Batch 14/64 loss: 1.8473501205444336
Batch 15/64 loss: 2.0525784492492676
Batch 16/64 loss: 1.8781108856201172
Batch 17/64 loss: 1.9795150756835938
Batch 18/64 loss: 1.8706212043762207
Batch 19/64 loss: 1.7916436195373535
Batch 20/64 loss: 1.8013052940368652
Batch 21/64 loss: 1.787768840789795
Batch 22/64 loss: 1.8395590782165527
Batch 23/64 loss: 1.9244871139526367
Batch 24/64 loss: 1.874791145324707
Batch 25/64 loss: 2.040958881378174
Batch 26/64 loss: 2.0500845909118652
Batch 27/64 loss: 1.8407378196716309
Batch 28/64 loss: 2.139216423034668
Batch 29/64 loss: 1.8531627655029297
Batch 30/64 loss: 1.9697456359863281
Batch 31/64 loss: 1.9266624450683594
Batch 32/64 loss: 2.061631679534912
Batch 33/64 loss: 1.9878368377685547
Batch 34/64 loss: 2.170863628387451
Batch 35/64 loss: 2.073549270629883
Batch 36/64 loss: 1.915520191192627
Batch 37/64 loss: 1.8038983345031738
Batch 38/64 loss: 2.1503210067749023
Batch 39/64 loss: 1.8352727890014648
Batch 40/64 loss: 2.039947032928467
Batch 41/64 loss: 1.978198528289795
Batch 42/64 loss: 1.9910359382629395
Batch 43/64 loss: 2.0606789588928223
Batch 44/64 loss: 1.9702701568603516
Batch 45/64 loss: 1.875464916229248
Batch 46/64 loss: 1.9092397689819336
Batch 47/64 loss: 1.8686676025390625
Batch 48/64 loss: 1.873093605041504
Batch 49/64 loss: 1.866727352142334
Batch 50/64 loss: 1.9111018180847168
Batch 51/64 loss: 1.8432106971740723
Batch 52/64 loss: 1.8484926223754883
Batch 53/64 loss: 1.8326077461242676
Batch 54/64 loss: 1.9996452331542969
Batch 55/64 loss: 2.074626922607422
Batch 56/64 loss: 1.7902441024780273
Batch 57/64 loss: 1.8229289054870605
Batch 58/64 loss: 1.7261090278625488
Batch 59/64 loss: 1.9361772537231445
Batch 60/64 loss: 1.850369930267334
Batch 61/64 loss: 1.866659164428711
Batch 62/64 loss: 2.168097496032715
Batch 63/64 loss: 1.8261990547180176
Batch 64/64 loss: -1.3411412239074707
Epoch 104  Train loss: 1.9086231100792979  Val loss: 1.7224436297859114
Epoch 105
-------------------------------
Batch 1/64 loss: 1.898625373840332
Batch 2/64 loss: 1.7936153411865234
Batch 3/64 loss: 1.9917588233947754
Batch 4/64 loss: 1.868624210357666
Batch 5/64 loss: 2.419625759124756
Batch 6/64 loss: 1.8331146240234375
Batch 7/64 loss: 1.714789867401123
Batch 8/64 loss: 1.791250228881836
Batch 9/64 loss: 1.9258084297180176
Batch 10/64 loss: 1.922499656677246
Batch 11/64 loss: 2.012396812438965
Batch 12/64 loss: 2.184267520904541
Batch 13/64 loss: 2.101243019104004
Batch 14/64 loss: 1.8909964561462402
Batch 15/64 loss: 1.9323368072509766
Batch 16/64 loss: 1.9295439720153809
Batch 17/64 loss: 1.7586312294006348
Batch 18/64 loss: 1.8342185020446777
Batch 19/64 loss: 1.8084540367126465
Batch 20/64 loss: 1.920384407043457
Batch 21/64 loss: 1.871121883392334
Batch 22/64 loss: 1.8321008682250977
Batch 23/64 loss: 2.0474658012390137
Batch 24/64 loss: 1.8641963005065918
Batch 25/64 loss: 2.05283784866333
Batch 26/64 loss: 2.191725730895996
Batch 27/64 loss: 1.9409403800964355
Batch 28/64 loss: 1.805659294128418
Batch 29/64 loss: 1.953237533569336
Batch 30/64 loss: 1.8677949905395508
Batch 31/64 loss: 2.0867462158203125
Batch 32/64 loss: 1.8826141357421875
Batch 33/64 loss: 1.7152013778686523
Batch 34/64 loss: 2.052131175994873
Batch 35/64 loss: 1.7381458282470703
Batch 36/64 loss: 2.005068778991699
Batch 37/64 loss: 1.8144941329956055
Batch 38/64 loss: 1.8798580169677734
Batch 39/64 loss: 1.9555106163024902
Batch 40/64 loss: 2.2126569747924805
Batch 41/64 loss: 1.8848791122436523
Batch 42/64 loss: 2.173366069793701
Batch 43/64 loss: 1.741269588470459
Batch 44/64 loss: 1.8967580795288086
Batch 45/64 loss: 1.8954944610595703
Batch 46/64 loss: 1.9149041175842285
Batch 47/64 loss: 1.9300141334533691
Batch 48/64 loss: 1.8187861442565918
Batch 49/64 loss: 2.068403720855713
Batch 50/64 loss: 1.9056034088134766
Batch 51/64 loss: 2.1224141120910645
Batch 52/64 loss: 1.9599699974060059
Batch 53/64 loss: 2.082545280456543
Batch 54/64 loss: 1.8683276176452637
Batch 55/64 loss: 1.9997754096984863
Batch 56/64 loss: 1.8198604583740234
Batch 57/64 loss: 2.0353689193725586
Batch 58/64 loss: 2.0039572715759277
Batch 59/64 loss: 1.8591928482055664
Batch 60/64 loss: 2.3461780548095703
Batch 61/64 loss: 1.8547577857971191
Batch 62/64 loss: 1.758559226989746
Batch 63/64 loss: 2.0115718841552734
Batch 64/64 loss: -1.1201181411743164
Epoch 105  Train loss: 1.9045264636769015  Val loss: 1.7780139831333226
Epoch 106
-------------------------------
Batch 1/64 loss: 1.9030489921569824
Batch 2/64 loss: 2.1310272216796875
Batch 3/64 loss: 1.9730019569396973
Batch 4/64 loss: 2.013826370239258
Batch 5/64 loss: 1.9326581954956055
Batch 6/64 loss: 1.9909543991088867
Batch 7/64 loss: 1.8721561431884766
Batch 8/64 loss: 2.195657730102539
Batch 9/64 loss: 1.8500046730041504
Batch 10/64 loss: 2.192643165588379
Batch 11/64 loss: 2.0361618995666504
Batch 12/64 loss: 1.9117927551269531
Batch 13/64 loss: 1.8042755126953125
Batch 14/64 loss: 2.0340003967285156
Batch 15/64 loss: 1.8081893920898438
Batch 16/64 loss: 1.8778586387634277
Batch 17/64 loss: 2.132624626159668
Batch 18/64 loss: 2.015474319458008
Batch 19/64 loss: 2.0156397819519043
Batch 20/64 loss: 1.8748211860656738
Batch 21/64 loss: 2.0040130615234375
Batch 22/64 loss: 1.936178207397461
Batch 23/64 loss: 1.953568458557129
Batch 24/64 loss: 1.8982939720153809
Batch 25/64 loss: 1.8434267044067383
Batch 26/64 loss: 1.922121524810791
Batch 27/64 loss: 1.9287033081054688
Batch 28/64 loss: 2.1053380966186523
Batch 29/64 loss: 1.8631558418273926
Batch 30/64 loss: 1.948399543762207
Batch 31/64 loss: 1.919022560119629
Batch 32/64 loss: 1.8561716079711914
Batch 33/64 loss: 1.8481659889221191
Batch 34/64 loss: 1.8123373985290527
Batch 35/64 loss: 1.790726661682129
Batch 36/64 loss: 1.9584565162658691
Batch 37/64 loss: 2.0532450675964355
Batch 38/64 loss: 2.160675048828125
Batch 39/64 loss: 1.979423999786377
Batch 40/64 loss: 1.8340086936950684
Batch 41/64 loss: 1.812917709350586
Batch 42/64 loss: 2.140367031097412
Batch 43/64 loss: 2.0040531158447266
Batch 44/64 loss: 2.178793430328369
Batch 45/64 loss: 1.8551483154296875
Batch 46/64 loss: 1.8837504386901855
Batch 47/64 loss: 1.9140868186950684
Batch 48/64 loss: 1.7632946968078613
Batch 49/64 loss: 2.15841007232666
Batch 50/64 loss: 2.0179576873779297
Batch 51/64 loss: 1.9060087203979492
Batch 52/64 loss: 1.9558796882629395
Batch 53/64 loss: 1.8270106315612793
Batch 54/64 loss: 2.0438995361328125
Batch 55/64 loss: 2.0548863410949707
Batch 56/64 loss: 1.9539270401000977
Batch 57/64 loss: 2.0573272705078125
Batch 58/64 loss: 1.8338828086853027
Batch 59/64 loss: 1.903210163116455
Batch 60/64 loss: 1.9400649070739746
Batch 61/64 loss: 1.778397560119629
Batch 62/64 loss: 1.975344181060791
Batch 63/64 loss: 1.7752017974853516
Batch 64/64 loss: -1.3171062469482422
Epoch 106  Train loss: 1.9125841552135991  Val loss: 1.7028113492985362
Epoch 107
-------------------------------
Batch 1/64 loss: 2.0055198669433594
Batch 2/64 loss: 2.3429698944091797
Batch 3/64 loss: 1.9004368782043457
Batch 4/64 loss: 2.0122761726379395
Batch 5/64 loss: 2.164384365081787
Batch 6/64 loss: 1.849961757659912
Batch 7/64 loss: 2.133453369140625
Batch 8/64 loss: 1.8331894874572754
Batch 9/64 loss: 1.7853283882141113
Batch 10/64 loss: 2.0470166206359863
Batch 11/64 loss: 1.8682208061218262
Batch 12/64 loss: 2.0779404640197754
Batch 13/64 loss: 1.9173994064331055
Batch 14/64 loss: 2.2764501571655273
Batch 15/64 loss: 2.057223320007324
Batch 16/64 loss: 1.9745092391967773
Batch 17/64 loss: 1.9742603302001953
Batch 18/64 loss: 1.9357514381408691
Batch 19/64 loss: 2.0339345932006836
Batch 20/64 loss: 1.8824124336242676
Batch 21/64 loss: 1.9726824760437012
Batch 22/64 loss: 2.1468701362609863
Batch 23/64 loss: 1.8619961738586426
Batch 24/64 loss: 2.064802646636963
Batch 25/64 loss: 1.8817672729492188
Batch 26/64 loss: 1.9555869102478027
Batch 27/64 loss: 1.99249267578125
Batch 28/64 loss: 2.0085902214050293
Batch 29/64 loss: 2.148919105529785
Batch 30/64 loss: 1.9352669715881348
Batch 31/64 loss: 2.0062618255615234
Batch 32/64 loss: 2.078279495239258
Batch 33/64 loss: 2.102719783782959
Batch 34/64 loss: 1.9392542839050293
Batch 35/64 loss: 1.9731144905090332
Batch 36/64 loss: 1.961395263671875
Batch 37/64 loss: 2.004328727722168
Batch 38/64 loss: 1.7781686782836914
Batch 39/64 loss: 2.0777945518493652
Batch 40/64 loss: 2.0302987098693848
Batch 41/64 loss: 1.7999954223632812
Batch 42/64 loss: 2.0667576789855957
Batch 43/64 loss: 1.8632378578186035
Batch 44/64 loss: 2.083677291870117
Batch 45/64 loss: 1.9999265670776367
Batch 46/64 loss: 1.9606518745422363
Batch 47/64 loss: 2.1285133361816406
Batch 48/64 loss: 2.096550941467285
Batch 49/64 loss: 1.9333720207214355
Batch 50/64 loss: 1.9972524642944336
Batch 51/64 loss: 2.3386473655700684
Batch 52/64 loss: 1.835749626159668
Batch 53/64 loss: 1.942091464996338
Batch 54/64 loss: 1.8737807273864746
Batch 55/64 loss: 2.016146659851074
Batch 56/64 loss: 2.158572196960449
Batch 57/64 loss: 1.9648685455322266
Batch 58/64 loss: 2.008026123046875
Batch 59/64 loss: 1.823507308959961
Batch 60/64 loss: 1.8460378646850586
Batch 61/64 loss: 1.992149829864502
Batch 62/64 loss: 1.8535189628601074
Batch 63/64 loss: 1.8024134635925293
Batch 64/64 loss: -1.1794500350952148
Epoch 107  Train loss: 1.952848430708343  Val loss: 1.8252759586085159
Epoch 108
-------------------------------
Batch 1/64 loss: 2.067441940307617
Batch 2/64 loss: 2.0384039878845215
Batch 3/64 loss: 2.027649402618408
Batch 4/64 loss: 2.0084586143493652
Batch 5/64 loss: 2.3772459030151367
Batch 6/64 loss: 2.055807590484619
Batch 7/64 loss: 2.189208507537842
Batch 8/64 loss: 1.9904274940490723
Batch 9/64 loss: 2.015964984893799
Batch 10/64 loss: 2.182506561279297
Batch 11/64 loss: 1.9602108001708984
Batch 12/64 loss: 2.1782631874084473
Batch 13/64 loss: 2.1170711517333984
Batch 14/64 loss: 2.132215976715088
Batch 15/64 loss: 2.0717291831970215
Batch 16/64 loss: 2.016110420227051
Batch 17/64 loss: 2.002408981323242
Batch 18/64 loss: 1.9393067359924316
Batch 19/64 loss: 2.122344493865967
Batch 20/64 loss: 1.8803348541259766
Batch 21/64 loss: 1.7518954277038574
Batch 22/64 loss: 2.018494129180908
Batch 23/64 loss: 1.8305277824401855
Batch 24/64 loss: 2.1453046798706055
Batch 25/64 loss: 2.039547920227051
Batch 26/64 loss: 2.1071414947509766
Batch 27/64 loss: 1.8942499160766602
Batch 28/64 loss: 1.9130964279174805
Batch 29/64 loss: 1.9562182426452637
Batch 30/64 loss: 1.973008155822754
Batch 31/64 loss: 1.9124231338500977
Batch 32/64 loss: 1.894848346710205
Batch 33/64 loss: 1.9069743156433105
Batch 34/64 loss: 1.8521137237548828
Batch 35/64 loss: 1.9738373756408691
Batch 36/64 loss: 1.9477338790893555
Batch 37/64 loss: 2.256852626800537
Batch 38/64 loss: 1.8130860328674316
Batch 39/64 loss: 2.1183524131774902
Batch 40/64 loss: 2.002190113067627
Batch 41/64 loss: 2.173710346221924
Batch 42/64 loss: 1.8520488739013672
Batch 43/64 loss: 1.9898805618286133
Batch 44/64 loss: 1.7928543090820312
Batch 45/64 loss: 2.078284740447998
Batch 46/64 loss: 2.01204252243042
Batch 47/64 loss: 1.858978271484375
Batch 48/64 loss: 1.8794875144958496
Batch 49/64 loss: 1.9135017395019531
Batch 50/64 loss: 1.7850852012634277
Batch 51/64 loss: 2.1500024795532227
Batch 52/64 loss: 1.8458576202392578
Batch 53/64 loss: 1.822913646697998
Batch 54/64 loss: 1.9125471115112305
Batch 55/64 loss: 1.7799358367919922
Batch 56/64 loss: 1.9730405807495117
Batch 57/64 loss: 1.8948464393615723
Batch 58/64 loss: 1.9728412628173828
Batch 59/64 loss: 1.9513769149780273
Batch 60/64 loss: 2.0404233932495117
Batch 61/64 loss: 1.809255599975586
Batch 62/64 loss: 1.891355037689209
Batch 63/64 loss: 1.8907184600830078
Batch 64/64 loss: -1.3347187042236328
Epoch 108  Train loss: 1.944328726974188  Val loss: 1.6838419216195333
Saving best model, epoch: 108
Epoch 109
-------------------------------
Batch 1/64 loss: 1.8453497886657715
Batch 2/64 loss: 2.1383471488952637
Batch 3/64 loss: 2.049619197845459
Batch 4/64 loss: 2.0653533935546875
Batch 5/64 loss: 1.875941276550293
Batch 6/64 loss: 1.8066658973693848
Batch 7/64 loss: 2.050576686859131
Batch 8/64 loss: 1.9259462356567383
Batch 9/64 loss: 1.7888092994689941
Batch 10/64 loss: 1.8012666702270508
Batch 11/64 loss: 1.8314080238342285
Batch 12/64 loss: 1.783797264099121
Batch 13/64 loss: 1.8765287399291992
Batch 14/64 loss: 1.7883286476135254
Batch 15/64 loss: 1.6644320487976074
Batch 16/64 loss: 1.7235350608825684
Batch 17/64 loss: 1.7372899055480957
Batch 18/64 loss: 1.794630527496338
Batch 19/64 loss: 1.8508000373840332
Batch 20/64 loss: 1.985323429107666
Batch 21/64 loss: 1.734184741973877
Batch 22/64 loss: 1.9722399711608887
Batch 23/64 loss: 1.8962821960449219
Batch 24/64 loss: 2.0320677757263184
Batch 25/64 loss: 1.8803248405456543
Batch 26/64 loss: 2.0191292762756348
Batch 27/64 loss: 1.8643083572387695
Batch 28/64 loss: 1.9768953323364258
Batch 29/64 loss: 2.0609331130981445
Batch 30/64 loss: 1.884291172027588
Batch 31/64 loss: 2.128448963165283
Batch 32/64 loss: 1.8481755256652832
Batch 33/64 loss: 1.862839698791504
Batch 34/64 loss: 1.7622122764587402
Batch 35/64 loss: 1.9488801956176758
Batch 36/64 loss: 1.9604005813598633
Batch 37/64 loss: 2.004011631011963
Batch 38/64 loss: 1.9019012451171875
Batch 39/64 loss: 2.015932083129883
Batch 40/64 loss: 2.1622700691223145
Batch 41/64 loss: 1.7981157302856445
Batch 42/64 loss: 2.1127514839172363
Batch 43/64 loss: 1.9187560081481934
Batch 44/64 loss: 1.8440427780151367
Batch 45/64 loss: 2.0980663299560547
Batch 46/64 loss: 1.9633727073669434
Batch 47/64 loss: 2.4510602951049805
Batch 48/64 loss: 2.0776209831237793
Batch 49/64 loss: 1.973841667175293
Batch 50/64 loss: 1.717780590057373
Batch 51/64 loss: 1.9787020683288574
Batch 52/64 loss: 2.0473499298095703
Batch 53/64 loss: 2.0043716430664062
Batch 54/64 loss: 1.9847288131713867
Batch 55/64 loss: 1.7780094146728516
Batch 56/64 loss: 1.923189640045166
Batch 57/64 loss: 1.7658615112304688
Batch 58/64 loss: 1.909451961517334
Batch 59/64 loss: 2.0342307090759277
Batch 60/64 loss: 1.9671273231506348
Batch 61/64 loss: 1.9075851440429688
Batch 62/64 loss: 1.8572382926940918
Batch 63/64 loss: 1.9437603950500488
Batch 64/64 loss: -1.063023567199707
Epoch 109  Train loss: 1.891128252066818  Val loss: 1.678527261792999
Saving best model, epoch: 109
Epoch 110
-------------------------------
Batch 1/64 loss: 1.9677009582519531
Batch 2/64 loss: 1.8791909217834473
Batch 3/64 loss: 1.7626299858093262
Batch 4/64 loss: 1.8041572570800781
Batch 5/64 loss: 1.8164772987365723
Batch 6/64 loss: 1.7740979194641113
Batch 7/64 loss: 2.0188097953796387
Batch 8/64 loss: 1.9960479736328125
Batch 9/64 loss: 2.0026512145996094
Batch 10/64 loss: 1.8233189582824707
Batch 11/64 loss: 1.974621295928955
Batch 12/64 loss: 1.9101581573486328
Batch 13/64 loss: 2.0526394844055176
Batch 14/64 loss: 1.8931641578674316
Batch 15/64 loss: 1.9244890213012695
Batch 16/64 loss: 1.7974276542663574
Batch 17/64 loss: 2.0655717849731445
Batch 18/64 loss: 2.087283134460449
Batch 19/64 loss: 1.9919371604919434
Batch 20/64 loss: 1.9959430694580078
Batch 21/64 loss: 1.9683995246887207
Batch 22/64 loss: 2.1418776512145996
Batch 23/64 loss: 2.2006750106811523
Batch 24/64 loss: 2.2558746337890625
Batch 25/64 loss: 2.286179542541504
Batch 26/64 loss: 1.8141894340515137
Batch 27/64 loss: 1.8180079460144043
Batch 28/64 loss: 2.4851183891296387
Batch 29/64 loss: 1.8680472373962402
Batch 30/64 loss: 2.0731639862060547
Batch 31/64 loss: 1.9899072647094727
Batch 32/64 loss: 2.084583282470703
Batch 33/64 loss: 1.886502742767334
Batch 34/64 loss: 2.386713981628418
Batch 35/64 loss: 2.0141563415527344
Batch 36/64 loss: 1.9339537620544434
Batch 37/64 loss: 2.1888389587402344
Batch 38/64 loss: 2.0937347412109375
Batch 39/64 loss: 1.916837215423584
Batch 40/64 loss: 2.1743054389953613
Batch 41/64 loss: 1.945892333984375
Batch 42/64 loss: 1.978111743927002
Batch 43/64 loss: 1.8842544555664062
Batch 44/64 loss: 1.9925966262817383
Batch 45/64 loss: 1.8344359397888184
Batch 46/64 loss: 1.9198827743530273
Batch 47/64 loss: 1.9955201148986816
Batch 48/64 loss: 1.8807473182678223
Batch 49/64 loss: 2.0347137451171875
Batch 50/64 loss: 1.993910312652588
Batch 51/64 loss: 2.002899646759033
Batch 52/64 loss: 1.886085033416748
Batch 53/64 loss: 1.8301091194152832
Batch 54/64 loss: 1.999406337738037
Batch 55/64 loss: 1.904839038848877
Batch 56/64 loss: 1.9568748474121094
Batch 57/64 loss: 1.9923949241638184
Batch 58/64 loss: 1.9184226989746094
Batch 59/64 loss: 2.068333625793457
Batch 60/64 loss: 1.914332389831543
Batch 61/64 loss: 1.9380512237548828
Batch 62/64 loss: 2.087649345397949
Batch 63/64 loss: 1.7998623847961426
Batch 64/64 loss: -0.8308310508728027
Epoch 110  Train loss: 1.9491072467729158  Val loss: 1.7239218118674158
Epoch 111
-------------------------------
Batch 1/64 loss: 1.8896594047546387
Batch 2/64 loss: 2.158905506134033
Batch 3/64 loss: 2.0762338638305664
Batch 4/64 loss: 1.889059066772461
Batch 5/64 loss: 2.010406494140625
Batch 6/64 loss: 1.8469533920288086
Batch 7/64 loss: 1.8831028938293457
Batch 8/64 loss: 2.043182849884033
Batch 9/64 loss: 1.9854798316955566
Batch 10/64 loss: 2.09149169921875
Batch 11/64 loss: 2.2417430877685547
Batch 12/64 loss: 2.048764228820801
Batch 13/64 loss: 2.0112314224243164
Batch 14/64 loss: 2.047118663787842
Batch 15/64 loss: 1.843277931213379
Batch 16/64 loss: 1.9439377784729004
Batch 17/64 loss: 1.8791913986206055
Batch 18/64 loss: 1.8717937469482422
Batch 19/64 loss: 1.7471423149108887
Batch 20/64 loss: 1.9107728004455566
Batch 21/64 loss: 2.089897632598877
Batch 22/64 loss: 2.1507039070129395
Batch 23/64 loss: 2.186832904815674
Batch 24/64 loss: 1.7715601921081543
Batch 25/64 loss: 2.0104174613952637
Batch 26/64 loss: 1.9995155334472656
Batch 27/64 loss: 1.8018851280212402
Batch 28/64 loss: 1.9974322319030762
Batch 29/64 loss: 1.9229040145874023
Batch 30/64 loss: 1.9750404357910156
Batch 31/64 loss: 1.8927016258239746
Batch 32/64 loss: 1.905733585357666
Batch 33/64 loss: 2.0170278549194336
Batch 34/64 loss: 1.8945655822753906
Batch 35/64 loss: 1.798452377319336
Batch 36/64 loss: 1.8876328468322754
Batch 37/64 loss: 2.0340046882629395
Batch 38/64 loss: 1.754662036895752
Batch 39/64 loss: 1.8359899520874023
Batch 40/64 loss: 2.064429759979248
Batch 41/64 loss: 1.890181541442871
Batch 42/64 loss: 1.9091682434082031
Batch 43/64 loss: 1.9088091850280762
Batch 44/64 loss: 1.8864374160766602
Batch 45/64 loss: 1.817667007446289
Batch 46/64 loss: 1.7961082458496094
Batch 47/64 loss: 2.075888156890869
Batch 48/64 loss: 1.8895020484924316
Batch 49/64 loss: 2.2253055572509766
Batch 50/64 loss: 1.95420503616333
Batch 51/64 loss: 1.9284777641296387
Batch 52/64 loss: 1.8990478515625
Batch 53/64 loss: 2.322842597961426
Batch 54/64 loss: 1.952437400817871
Batch 55/64 loss: 1.9348697662353516
Batch 56/64 loss: 2.004960536956787
Batch 57/64 loss: 1.9979195594787598
Batch 58/64 loss: 1.9047508239746094
Batch 59/64 loss: 2.0313172340393066
Batch 60/64 loss: 2.0301365852355957
Batch 61/64 loss: 2.015194892883301
Batch 62/64 loss: 1.8315668106079102
Batch 63/64 loss: 2.056743621826172
Batch 64/64 loss: -1.0737590789794922
Epoch 111  Train loss: 1.9273577521829044  Val loss: 1.7572252922451372
Epoch 112
-------------------------------
Batch 1/64 loss: 1.9112467765808105
Batch 2/64 loss: 2.243253707885742
Batch 3/64 loss: 2.208807945251465
Batch 4/64 loss: 1.9406399726867676
Batch 5/64 loss: 2.048229694366455
Batch 6/64 loss: 1.9068331718444824
Batch 7/64 loss: 1.843325138092041
Batch 8/64 loss: 2.1417489051818848
Batch 9/64 loss: 2.0523529052734375
Batch 10/64 loss: 1.8537278175354004
Batch 11/64 loss: 1.9447731971740723
Batch 12/64 loss: 1.9876246452331543
Batch 13/64 loss: 1.8592305183410645
Batch 14/64 loss: 1.7672638893127441
Batch 15/64 loss: 1.848252296447754
Batch 16/64 loss: 1.935957431793213
Batch 17/64 loss: 1.9144959449768066
Batch 18/64 loss: 1.7613205909729004
Batch 19/64 loss: 1.8685383796691895
Batch 20/64 loss: 1.8103256225585938
Batch 21/64 loss: 1.6229543685913086
Batch 22/64 loss: 2.080292224884033
Batch 23/64 loss: 1.772000789642334
Batch 24/64 loss: 1.8720183372497559
Batch 25/64 loss: 1.8953585624694824
Batch 26/64 loss: 1.8823518753051758
Batch 27/64 loss: 1.758530616760254
Batch 28/64 loss: 1.857346534729004
Batch 29/64 loss: 1.8361701965332031
Batch 30/64 loss: 1.8842453956604004
Batch 31/64 loss: 1.7779359817504883
Batch 32/64 loss: 1.7369623184204102
Batch 33/64 loss: 1.804028034210205
Batch 34/64 loss: 2.060164451599121
Batch 35/64 loss: 1.9072065353393555
Batch 36/64 loss: 1.9026265144348145
Batch 37/64 loss: 2.1114144325256348
Batch 38/64 loss: 1.8175840377807617
Batch 39/64 loss: 1.829482078552246
Batch 40/64 loss: 1.8546175956726074
Batch 41/64 loss: 1.8518719673156738
Batch 42/64 loss: 1.8874197006225586
Batch 43/64 loss: 1.8263373374938965
Batch 44/64 loss: 1.9759135246276855
Batch 45/64 loss: 1.8441672325134277
Batch 46/64 loss: 1.9047937393188477
Batch 47/64 loss: 1.6477560997009277
Batch 48/64 loss: 2.0330262184143066
Batch 49/64 loss: 1.954765796661377
Batch 50/64 loss: 1.9382634162902832
Batch 51/64 loss: 2.0482840538024902
Batch 52/64 loss: 1.8176054954528809
Batch 53/64 loss: 1.9704794883728027
Batch 54/64 loss: 1.7776713371276855
Batch 55/64 loss: 2.3017969131469727
Batch 56/64 loss: 1.8842315673828125
Batch 57/64 loss: 2.016406536102295
Batch 58/64 loss: 2.1000237464904785
Batch 59/64 loss: 1.7567481994628906
Batch 60/64 loss: 2.005070209503174
Batch 61/64 loss: 1.8526420593261719
Batch 62/64 loss: 1.9409685134887695
Batch 63/64 loss: 1.876166820526123
Batch 64/64 loss: -1.3774452209472656
Epoch 112  Train loss: 1.871224556717218  Val loss: 1.7312925476388834
Epoch 113
-------------------------------
Batch 1/64 loss: 1.9164519309997559
Batch 2/64 loss: 2.1154637336730957
Batch 3/64 loss: 1.7636480331420898
Batch 4/64 loss: 1.9741005897521973
Batch 5/64 loss: 1.868722915649414
Batch 6/64 loss: 1.9867172241210938
Batch 7/64 loss: 1.804102897644043
Batch 8/64 loss: 2.1639552116394043
Batch 9/64 loss: 2.02188777923584
Batch 10/64 loss: 2.043250560760498
Batch 11/64 loss: 1.8509268760681152
Batch 12/64 loss: 2.0760812759399414
Batch 13/64 loss: 2.080615997314453
Batch 14/64 loss: 1.905466079711914
Batch 15/64 loss: 1.9707980155944824
Batch 16/64 loss: 1.9797606468200684
Batch 17/64 loss: 1.8956952095031738
Batch 18/64 loss: 2.2245097160339355
Batch 19/64 loss: 1.8353281021118164
Batch 20/64 loss: 1.961876392364502
Batch 21/64 loss: 1.8275737762451172
Batch 22/64 loss: 1.7860946655273438
Batch 23/64 loss: 2.025498867034912
Batch 24/64 loss: 2.0110268592834473
Batch 25/64 loss: 1.9011411666870117
Batch 26/64 loss: 1.989795207977295
Batch 27/64 loss: 1.918050765991211
Batch 28/64 loss: 1.9789924621582031
Batch 29/64 loss: 1.888540267944336
Batch 30/64 loss: 2.0200576782226562
Batch 31/64 loss: 2.117912769317627
Batch 32/64 loss: 1.7450814247131348
Batch 33/64 loss: 1.993889331817627
Batch 34/64 loss: 1.7996950149536133
Batch 35/64 loss: 1.774162769317627
Batch 36/64 loss: 1.8688793182373047
Batch 37/64 loss: 1.9293489456176758
Batch 38/64 loss: 1.7785348892211914
Batch 39/64 loss: 2.0305776596069336
Batch 40/64 loss: 2.0393600463867188
Batch 41/64 loss: 2.1770691871643066
Batch 42/64 loss: 2.0669803619384766
Batch 43/64 loss: 1.8227882385253906
Batch 44/64 loss: 1.7815589904785156
Batch 45/64 loss: 1.9643158912658691
Batch 46/64 loss: 2.034118175506592
Batch 47/64 loss: 1.7581677436828613
Batch 48/64 loss: 1.7131609916687012
Batch 49/64 loss: 1.857241153717041
Batch 50/64 loss: 1.9114503860473633
Batch 51/64 loss: 2.028493881225586
Batch 52/64 loss: 1.7620630264282227
Batch 53/64 loss: 2.118239402770996
Batch 54/64 loss: 2.1660475730895996
Batch 55/64 loss: 1.895479679107666
Batch 56/64 loss: 1.976672649383545
Batch 57/64 loss: 1.9504914283752441
Batch 58/64 loss: 1.860816478729248
Batch 59/64 loss: 2.037153720855713
Batch 60/64 loss: 2.0385355949401855
Batch 61/64 loss: 1.9366226196289062
Batch 62/64 loss: 2.2349495887756348
Batch 63/64 loss: 2.074845790863037
Batch 64/64 loss: -1.178016185760498
Epoch 113  Train loss: 1.9160364468892415  Val loss: 1.74401897417311
Epoch 114
-------------------------------
Batch 1/64 loss: 1.89888334274292
Batch 2/64 loss: 1.9059677124023438
Batch 3/64 loss: 1.9804668426513672
Batch 4/64 loss: 2.162323474884033
Batch 5/64 loss: 1.940152645111084
Batch 6/64 loss: 1.8493142127990723
Batch 7/64 loss: 2.0313053131103516
Batch 8/64 loss: 2.0173592567443848
Batch 9/64 loss: 1.8672842979431152
Batch 10/64 loss: 1.8360347747802734
Batch 11/64 loss: 1.8354501724243164
Batch 12/64 loss: 1.7874760627746582
Batch 13/64 loss: 1.8323917388916016
Batch 14/64 loss: 1.966562271118164
Batch 15/64 loss: 1.8981890678405762
Batch 16/64 loss: 1.8583855628967285
Batch 17/64 loss: 1.8623223304748535
Batch 18/64 loss: 1.910304069519043
Batch 19/64 loss: 2.064138889312744
Batch 20/64 loss: 1.9442024230957031
Batch 21/64 loss: 1.999345302581787
Batch 22/64 loss: 1.9165596961975098
Batch 23/64 loss: 1.7784862518310547
Batch 24/64 loss: 1.8912034034729004
Batch 25/64 loss: 2.0859317779541016
Batch 26/64 loss: 1.9150333404541016
Batch 27/64 loss: 1.9397773742675781
Batch 28/64 loss: 1.8609752655029297
Batch 29/64 loss: 1.8822145462036133
Batch 30/64 loss: 1.9616203308105469
Batch 31/64 loss: 1.9449443817138672
Batch 32/64 loss: 2.0931081771850586
Batch 33/64 loss: 1.772496223449707
Batch 34/64 loss: 2.2234888076782227
Batch 35/64 loss: 1.769301414489746
Batch 36/64 loss: 1.869577407836914
Batch 37/64 loss: 1.9705348014831543
Batch 38/64 loss: 1.7656264305114746
Batch 39/64 loss: 1.8447766304016113
Batch 40/64 loss: 2.2633094787597656
Batch 41/64 loss: 1.8586840629577637
Batch 42/64 loss: 1.9401211738586426
Batch 43/64 loss: 1.9171361923217773
Batch 44/64 loss: 1.9774670600891113
Batch 45/64 loss: 1.8666071891784668
Batch 46/64 loss: 1.9976577758789062
Batch 47/64 loss: 1.9296998977661133
Batch 48/64 loss: 1.7879338264465332
Batch 49/64 loss: 2.0615782737731934
Batch 50/64 loss: 1.8749504089355469
Batch 51/64 loss: 1.912243366241455
Batch 52/64 loss: 2.343137741088867
Batch 53/64 loss: 1.9183573722839355
Batch 54/64 loss: 1.8149399757385254
Batch 55/64 loss: 2.023141384124756
Batch 56/64 loss: 1.76873779296875
Batch 57/64 loss: 2.2726192474365234
Batch 58/64 loss: 1.8976850509643555
Batch 59/64 loss: 1.7380762100219727
Batch 60/64 loss: 1.8383049964904785
Batch 61/64 loss: 2.2330093383789062
Batch 62/64 loss: 1.882378101348877
Batch 63/64 loss: 2.005187511444092
Batch 64/64 loss: -1.2231621742248535
Epoch 114  Train loss: 1.9002212991901473  Val loss: 1.7336363579399396
Epoch 115
-------------------------------
Batch 1/64 loss: 1.8827433586120605
Batch 2/64 loss: 1.9515800476074219
Batch 3/64 loss: 1.83317232131958
Batch 4/64 loss: 1.8581123352050781
Batch 5/64 loss: 1.8633537292480469
Batch 6/64 loss: 1.7705998420715332
Batch 7/64 loss: 1.8421711921691895
Batch 8/64 loss: 1.9680280685424805
Batch 9/64 loss: 2.067328929901123
Batch 10/64 loss: 1.8989152908325195
Batch 11/64 loss: 1.8313517570495605
Batch 12/64 loss: 1.8554387092590332
Batch 13/64 loss: 1.8687257766723633
Batch 14/64 loss: 1.8644704818725586
Batch 15/64 loss: 1.9745283126831055
Batch 16/64 loss: 1.887946605682373
Batch 17/64 loss: 1.7593684196472168
Batch 18/64 loss: 1.9127349853515625
Batch 19/64 loss: 1.851008415222168
Batch 20/64 loss: 1.839411735534668
Batch 21/64 loss: 1.9139509201049805
Batch 22/64 loss: 1.816953182220459
Batch 23/64 loss: 2.104846477508545
Batch 24/64 loss: 1.6331777572631836
Batch 25/64 loss: 1.9074311256408691
Batch 26/64 loss: 1.8025054931640625
Batch 27/64 loss: 1.8814454078674316
Batch 28/64 loss: 1.9207487106323242
Batch 29/64 loss: 1.9174365997314453
Batch 30/64 loss: 1.8703298568725586
Batch 31/64 loss: 2.0574870109558105
Batch 32/64 loss: 1.8295621871948242
Batch 33/64 loss: 1.8530936241149902
Batch 34/64 loss: 2.0031418800354004
Batch 35/64 loss: 1.7625079154968262
Batch 36/64 loss: 1.8313231468200684
Batch 37/64 loss: 1.9787497520446777
Batch 38/64 loss: 2.0998892784118652
Batch 39/64 loss: 1.8006935119628906
Batch 40/64 loss: 1.8285512924194336
Batch 41/64 loss: 1.9031977653503418
Batch 42/64 loss: 1.7977347373962402
Batch 43/64 loss: 1.8541412353515625
Batch 44/64 loss: 1.8468775749206543
Batch 45/64 loss: 1.8781771659851074
Batch 46/64 loss: 2.132272720336914
Batch 47/64 loss: 1.822275161743164
Batch 48/64 loss: 2.0317983627319336
Batch 49/64 loss: 1.7928767204284668
Batch 50/64 loss: 2.2194151878356934
Batch 51/64 loss: 1.9596209526062012
Batch 52/64 loss: 1.8165655136108398
Batch 53/64 loss: 2.071439266204834
Batch 54/64 loss: 1.9689722061157227
Batch 55/64 loss: 1.8421730995178223
Batch 56/64 loss: 1.9655098915100098
Batch 57/64 loss: 1.818415641784668
Batch 58/64 loss: 2.1228079795837402
Batch 59/64 loss: 1.784820556640625
Batch 60/64 loss: 2.023192882537842
Batch 61/64 loss: 2.0316176414489746
Batch 62/64 loss: 1.8635859489440918
Batch 63/64 loss: 1.8119845390319824
Batch 64/64 loss: -1.4271798133850098
Epoch 115  Train loss: 1.861708287631764  Val loss: 1.703348258106979
Epoch 116
-------------------------------
Batch 1/64 loss: 1.8792734146118164
Batch 2/64 loss: 1.8650379180908203
Batch 3/64 loss: 1.8175997734069824
Batch 4/64 loss: 1.737563133239746
Batch 5/64 loss: 2.137421131134033
Batch 6/64 loss: 2.0300426483154297
Batch 7/64 loss: 1.8855609893798828
Batch 8/64 loss: 1.9993906021118164
Batch 9/64 loss: 1.7642598152160645
Batch 10/64 loss: 1.955711841583252
Batch 11/64 loss: 1.8082075119018555
Batch 12/64 loss: 2.0736865997314453
Batch 13/64 loss: 2.057957649230957
Batch 14/64 loss: 1.7628169059753418
Batch 15/64 loss: 1.8749604225158691
Batch 16/64 loss: 1.7269234657287598
Batch 17/64 loss: 1.9120383262634277
Batch 18/64 loss: 1.7497076988220215
Batch 19/64 loss: 1.951096534729004
Batch 20/64 loss: 2.3410611152648926
Batch 21/64 loss: 1.8438153266906738
Batch 22/64 loss: 1.9197425842285156
Batch 23/64 loss: 1.9416584968566895
Batch 24/64 loss: 1.8044381141662598
Batch 25/64 loss: 1.9217090606689453
Batch 26/64 loss: 1.9444141387939453
Batch 27/64 loss: 1.7401275634765625
Batch 28/64 loss: 1.798473834991455
Batch 29/64 loss: 1.9192771911621094
Batch 30/64 loss: 1.7621417045593262
Batch 31/64 loss: 1.8817205429077148
Batch 32/64 loss: 1.7607941627502441
Batch 33/64 loss: 1.8920350074768066
Batch 34/64 loss: 1.7794032096862793
Batch 35/64 loss: 1.9653329849243164
Batch 36/64 loss: 1.8540186882019043
Batch 37/64 loss: 1.9714808464050293
Batch 38/64 loss: 1.850684642791748
Batch 39/64 loss: 1.8564300537109375
Batch 40/64 loss: 1.8207430839538574
Batch 41/64 loss: 1.9227643013000488
Batch 42/64 loss: 1.8621201515197754
Batch 43/64 loss: 1.744913101196289
Batch 44/64 loss: 1.757359504699707
Batch 45/64 loss: 1.8389496803283691
Batch 46/64 loss: 1.8962411880493164
Batch 47/64 loss: 1.9577202796936035
Batch 48/64 loss: 1.9573731422424316
Batch 49/64 loss: 1.8433752059936523
Batch 50/64 loss: 1.9789562225341797
Batch 51/64 loss: 2.012998580932617
Batch 52/64 loss: 1.706202507019043
Batch 53/64 loss: 1.7172574996948242
Batch 54/64 loss: 1.786102294921875
Batch 55/64 loss: 2.026736259460449
Batch 56/64 loss: 1.9041166305541992
Batch 57/64 loss: 1.821159839630127
Batch 58/64 loss: 1.7551169395446777
Batch 59/64 loss: 1.8312592506408691
Batch 60/64 loss: 1.8764710426330566
Batch 61/64 loss: 1.8250479698181152
Batch 62/64 loss: 1.9318480491638184
Batch 63/64 loss: 1.8740458488464355
Batch 64/64 loss: -1.3658161163330078
Epoch 116  Train loss: 1.8409808962952856  Val loss: 1.6210915083737718
Saving best model, epoch: 116
Epoch 117
-------------------------------
Batch 1/64 loss: 1.8104238510131836
Batch 2/64 loss: 1.6470141410827637
Batch 3/64 loss: 1.7486042976379395
Batch 4/64 loss: 1.838338851928711
Batch 5/64 loss: 1.8899426460266113
Batch 6/64 loss: 1.967127799987793
Batch 7/64 loss: 1.713705062866211
Batch 8/64 loss: 1.7192330360412598
Batch 9/64 loss: 1.9765987396240234
Batch 10/64 loss: 1.911355972290039
Batch 11/64 loss: 1.8033485412597656
Batch 12/64 loss: 1.703169345855713
Batch 13/64 loss: 1.8447351455688477
Batch 14/64 loss: 1.6718683242797852
Batch 15/64 loss: 1.867548942565918
Batch 16/64 loss: 1.7743425369262695
Batch 17/64 loss: 1.9571313858032227
Batch 18/64 loss: 1.8207015991210938
Batch 19/64 loss: 1.8892793655395508
Batch 20/64 loss: 1.807279109954834
Batch 21/64 loss: 1.772937297821045
Batch 22/64 loss: 1.8488283157348633
Batch 23/64 loss: 1.7090935707092285
Batch 24/64 loss: 1.8856115341186523
Batch 25/64 loss: 1.969555377960205
Batch 26/64 loss: 1.6019110679626465
Batch 27/64 loss: 1.7894482612609863
Batch 28/64 loss: 1.9780197143554688
Batch 29/64 loss: 1.7328500747680664
Batch 30/64 loss: 2.0843453407287598
Batch 31/64 loss: 1.8405866622924805
Batch 32/64 loss: 2.025212287902832
Batch 33/64 loss: 1.9265074729919434
Batch 34/64 loss: 2.113462448120117
Batch 35/64 loss: 1.9025731086730957
Batch 36/64 loss: 1.7932653427124023
Batch 37/64 loss: 2.074535369873047
Batch 38/64 loss: 1.946120262145996
Batch 39/64 loss: 1.8591017723083496
Batch 40/64 loss: 1.8393173217773438
Batch 41/64 loss: 1.880192756652832
Batch 42/64 loss: 2.1254982948303223
Batch 43/64 loss: 1.70033597946167
Batch 44/64 loss: 1.7256598472595215
Batch 45/64 loss: 1.8342041969299316
Batch 46/64 loss: 1.944000244140625
Batch 47/64 loss: 1.8572916984558105
Batch 48/64 loss: 1.8809318542480469
Batch 49/64 loss: 1.8965730667114258
Batch 50/64 loss: 1.7126870155334473
Batch 51/64 loss: 1.9458932876586914
Batch 52/64 loss: 2.027604103088379
Batch 53/64 loss: 1.8736515045166016
Batch 54/64 loss: 1.8059444427490234
Batch 55/64 loss: 1.8795490264892578
Batch 56/64 loss: 1.8176016807556152
Batch 57/64 loss: 1.7467498779296875
Batch 58/64 loss: 1.8925127983093262
Batch 59/64 loss: 1.7300701141357422
Batch 60/64 loss: 1.9258060455322266
Batch 61/64 loss: 1.7941207885742188
Batch 62/64 loss: 1.991091251373291
Batch 63/64 loss: 1.8019871711730957
Batch 64/64 loss: -1.353142261505127
Epoch 117  Train loss: 1.8169432415681728  Val loss: 1.6021544662947507
Saving best model, epoch: 117
Epoch 118
-------------------------------
Batch 1/64 loss: 1.8690986633300781
Batch 2/64 loss: 1.766484260559082
Batch 3/64 loss: 1.8961567878723145
Batch 4/64 loss: 1.8583073616027832
Batch 5/64 loss: 1.72556734085083
Batch 6/64 loss: 2.117550849914551
Batch 7/64 loss: 1.9958133697509766
Batch 8/64 loss: 2.043506622314453
Batch 9/64 loss: 1.796647071838379
Batch 10/64 loss: 1.8535022735595703
Batch 11/64 loss: 2.0499963760375977
Batch 12/64 loss: 1.9988288879394531
Batch 13/64 loss: 1.9733786582946777
Batch 14/64 loss: 1.9533495903015137
Batch 15/64 loss: 1.8574647903442383
Batch 16/64 loss: 1.7661232948303223
Batch 17/64 loss: 1.8856925964355469
Batch 18/64 loss: 1.980900764465332
Batch 19/64 loss: 1.882127285003662
Batch 20/64 loss: 1.9010429382324219
Batch 21/64 loss: 1.904353141784668
Batch 22/64 loss: 1.833634376525879
Batch 23/64 loss: 1.8971600532531738
Batch 24/64 loss: 2.160069465637207
Batch 25/64 loss: 1.7086801528930664
Batch 26/64 loss: 1.883002758026123
Batch 27/64 loss: 1.7016034126281738
Batch 28/64 loss: 1.9536199569702148
Batch 29/64 loss: 1.8830642700195312
Batch 30/64 loss: 1.8724660873413086
Batch 31/64 loss: 1.9616684913635254
Batch 32/64 loss: 1.9315824508666992
Batch 33/64 loss: 1.7601327896118164
Batch 34/64 loss: 1.6948819160461426
Batch 35/64 loss: 1.8101873397827148
Batch 36/64 loss: 1.9989738464355469
Batch 37/64 loss: 1.9007763862609863
Batch 38/64 loss: 1.8690681457519531
Batch 39/64 loss: 1.8743786811828613
Batch 40/64 loss: 1.7990732192993164
Batch 41/64 loss: 1.8180670738220215
Batch 42/64 loss: 1.7861723899841309
Batch 43/64 loss: 1.7951102256774902
Batch 44/64 loss: 1.7914776802062988
Batch 45/64 loss: 1.837399959564209
Batch 46/64 loss: 1.8602590560913086
Batch 47/64 loss: 1.7757186889648438
Batch 48/64 loss: 1.9361248016357422
Batch 49/64 loss: 1.894352912902832
Batch 50/64 loss: 1.7837605476379395
Batch 51/64 loss: 2.004281997680664
Batch 52/64 loss: 1.8272771835327148
Batch 53/64 loss: 1.870051383972168
Batch 54/64 loss: 1.9086322784423828
Batch 55/64 loss: 1.8083925247192383
Batch 56/64 loss: 1.8200945854187012
Batch 57/64 loss: 1.751852035522461
Batch 58/64 loss: 1.7169318199157715
Batch 59/64 loss: 1.8344612121582031
Batch 60/64 loss: 1.7895622253417969
Batch 61/64 loss: 1.873192310333252
Batch 62/64 loss: 1.7765092849731445
Batch 63/64 loss: 1.709714412689209
Batch 64/64 loss: -1.4906063079833984
Epoch 118  Train loss: 1.826217389574238  Val loss: 1.6377927773596905
Epoch 119
-------------------------------
Batch 1/64 loss: 1.9667553901672363
Batch 2/64 loss: 1.8582525253295898
Batch 3/64 loss: 1.795659065246582
Batch 4/64 loss: 1.7104887962341309
Batch 5/64 loss: 2.1249613761901855
Batch 6/64 loss: 1.819188117980957
Batch 7/64 loss: 1.8814024925231934
Batch 8/64 loss: 1.7030329704284668
Batch 9/64 loss: 1.710172176361084
Batch 10/64 loss: 1.9762086868286133
Batch 11/64 loss: 1.8345122337341309
Batch 12/64 loss: 1.74489164352417
Batch 13/64 loss: 1.7269229888916016
Batch 14/64 loss: 1.8161687850952148
Batch 15/64 loss: 1.8977470397949219
Batch 16/64 loss: 1.96173095703125
Batch 17/64 loss: 1.7989907264709473
Batch 18/64 loss: 2.032045364379883
Batch 19/64 loss: 1.8773698806762695
Batch 20/64 loss: 1.8766193389892578
Batch 21/64 loss: 1.7004656791687012
Batch 22/64 loss: 1.9360642433166504
Batch 23/64 loss: 1.8358001708984375
Batch 24/64 loss: 1.7096161842346191
Batch 25/64 loss: 1.792984962463379
Batch 26/64 loss: 1.6558279991149902
Batch 27/64 loss: 1.9143481254577637
Batch 28/64 loss: 1.8485407829284668
Batch 29/64 loss: 1.9741911888122559
Batch 30/64 loss: 1.8156790733337402
Batch 31/64 loss: 1.8523855209350586
Batch 32/64 loss: 1.8751826286315918
Batch 33/64 loss: 1.9675707817077637
Batch 34/64 loss: 2.046578884124756
Batch 35/64 loss: 1.7966527938842773
Batch 36/64 loss: 2.041642189025879
Batch 37/64 loss: 1.8870244026184082
Batch 38/64 loss: 1.730445384979248
Batch 39/64 loss: 1.837472915649414
Batch 40/64 loss: 1.7563166618347168
Batch 41/64 loss: 1.837958812713623
Batch 42/64 loss: 1.7857699394226074
Batch 43/64 loss: 1.7114152908325195
Batch 44/64 loss: 1.716893196105957
Batch 45/64 loss: 1.7258367538452148
Batch 46/64 loss: 1.808711051940918
Batch 47/64 loss: 1.86122465133667
Batch 48/64 loss: 2.0994181632995605
Batch 49/64 loss: 1.866004467010498
Batch 50/64 loss: 1.9092836380004883
Batch 51/64 loss: 2.034203052520752
Batch 52/64 loss: 2.1655869483947754
Batch 53/64 loss: 1.9392695426940918
Batch 54/64 loss: 1.7479252815246582
Batch 55/64 loss: 1.751479148864746
Batch 56/64 loss: 1.8134827613830566
Batch 57/64 loss: 2.0006752014160156
Batch 58/64 loss: 2.0684361457824707
Batch 59/64 loss: 1.8027939796447754
Batch 60/64 loss: 1.7301740646362305
Batch 61/64 loss: 1.9037957191467285
Batch 62/64 loss: 1.9378013610839844
Batch 63/64 loss: 1.8590521812438965
Batch 64/64 loss: -1.6669321060180664
Epoch 119  Train loss: 1.8182729945463292  Val loss: 1.6018460198366355
Saving best model, epoch: 119
Epoch 120
-------------------------------
Batch 1/64 loss: 1.898137092590332
Batch 2/64 loss: 1.820925235748291
Batch 3/64 loss: 1.8606204986572266
Batch 4/64 loss: 1.949106216430664
Batch 5/64 loss: 1.7713627815246582
Batch 6/64 loss: 1.8235511779785156
Batch 7/64 loss: 1.8647985458374023
Batch 8/64 loss: 1.804152011871338
Batch 9/64 loss: 1.8627662658691406
Batch 10/64 loss: 1.7911877632141113
Batch 11/64 loss: 1.8673677444458008
Batch 12/64 loss: 1.8226709365844727
Batch 13/64 loss: 1.8370442390441895
Batch 14/64 loss: 1.806894302368164
Batch 15/64 loss: 1.8588910102844238
Batch 16/64 loss: 1.862807273864746
Batch 17/64 loss: 1.7916159629821777
Batch 18/64 loss: 1.6522607803344727
Batch 19/64 loss: 1.7220392227172852
Batch 20/64 loss: 1.9080324172973633
Batch 21/64 loss: 1.8643407821655273
Batch 22/64 loss: 1.69938325881958
Batch 23/64 loss: 1.739211082458496
Batch 24/64 loss: 1.998182773590088
Batch 25/64 loss: 1.896531581878662
Batch 26/64 loss: 2.358961582183838
Batch 27/64 loss: 2.024921417236328
Batch 28/64 loss: 1.7999138832092285
Batch 29/64 loss: 1.9258222579956055
Batch 30/64 loss: 1.9949803352355957
Batch 31/64 loss: 2.098527431488037
Batch 32/64 loss: 1.8319568634033203
Batch 33/64 loss: 1.8922200202941895
Batch 34/64 loss: 1.839594841003418
Batch 35/64 loss: 1.8193416595458984
Batch 36/64 loss: 1.6845831871032715
Batch 37/64 loss: 1.8628449440002441
Batch 38/64 loss: 1.6895909309387207
Batch 39/64 loss: 1.7349705696105957
Batch 40/64 loss: 1.8493332862854004
Batch 41/64 loss: 1.7325572967529297
Batch 42/64 loss: 1.7582168579101562
Batch 43/64 loss: 1.962390422821045
Batch 44/64 loss: 1.7066025733947754
Batch 45/64 loss: 1.9589810371398926
Batch 46/64 loss: 1.6975340843200684
Batch 47/64 loss: 1.7768950462341309
Batch 48/64 loss: 1.8234386444091797
Batch 49/64 loss: 1.8898882865905762
Batch 50/64 loss: 1.7435102462768555
Batch 51/64 loss: 1.7151517868041992
Batch 52/64 loss: 1.8168601989746094
Batch 53/64 loss: 2.087156295776367
Batch 54/64 loss: 1.7515583038330078
Batch 55/64 loss: 2.0614967346191406
Batch 56/64 loss: 1.7914695739746094
Batch 57/64 loss: 1.9554810523986816
Batch 58/64 loss: 1.8507404327392578
Batch 59/64 loss: 1.8333134651184082
Batch 60/64 loss: 1.8003621101379395
Batch 61/64 loss: 1.8460922241210938
Batch 62/64 loss: 1.8569130897521973
Batch 63/64 loss: 1.828061580657959
Batch 64/64 loss: -1.444533348083496
Epoch 120  Train loss: 1.80929749806722  Val loss: 1.6191631002524465
Epoch 121
-------------------------------
Batch 1/64 loss: 1.8796873092651367
Batch 2/64 loss: 1.9245080947875977
Batch 3/64 loss: 1.8577189445495605
Batch 4/64 loss: 1.805732250213623
Batch 5/64 loss: 1.7617897987365723
Batch 6/64 loss: 1.8811025619506836
Batch 7/64 loss: 2.023946762084961
Batch 8/64 loss: 1.7356324195861816
Batch 9/64 loss: 1.7669968605041504
Batch 10/64 loss: 1.9013981819152832
Batch 11/64 loss: 2.0897722244262695
Batch 12/64 loss: 1.7738142013549805
Batch 13/64 loss: 1.740654468536377
Batch 14/64 loss: 1.8706650733947754
Batch 15/64 loss: 1.8846492767333984
Batch 16/64 loss: 1.7908244132995605
Batch 17/64 loss: 1.819230079650879
Batch 18/64 loss: 1.87593412399292
Batch 19/64 loss: 1.8574872016906738
Batch 20/64 loss: 1.7973299026489258
Batch 21/64 loss: 2.040621280670166
Batch 22/64 loss: 1.8573222160339355
Batch 23/64 loss: 1.8674755096435547
Batch 24/64 loss: 1.807840347290039
Batch 25/64 loss: 1.8186626434326172
Batch 26/64 loss: 1.8014369010925293
Batch 27/64 loss: 1.8328123092651367
Batch 28/64 loss: 1.795544147491455
Batch 29/64 loss: 1.863786220550537
Batch 30/64 loss: 1.7357854843139648
Batch 31/64 loss: 1.861149787902832
Batch 32/64 loss: 1.9214749336242676
Batch 33/64 loss: 1.6866583824157715
Batch 34/64 loss: 1.8163657188415527
Batch 35/64 loss: 1.7211179733276367
Batch 36/64 loss: 1.7714548110961914
Batch 37/64 loss: 2.0382184982299805
Batch 38/64 loss: 1.804903507232666
Batch 39/64 loss: 1.722503662109375
Batch 40/64 loss: 1.8489727973937988
Batch 41/64 loss: 1.944767951965332
Batch 42/64 loss: 1.7343034744262695
Batch 43/64 loss: 1.8954167366027832
Batch 44/64 loss: 1.8918681144714355
Batch 45/64 loss: 1.8530807495117188
Batch 46/64 loss: 1.8857231140136719
Batch 47/64 loss: 2.0808849334716797
Batch 48/64 loss: 1.747631549835205
Batch 49/64 loss: 1.7477569580078125
Batch 50/64 loss: 1.7663536071777344
Batch 51/64 loss: 1.8253707885742188
Batch 52/64 loss: 1.8809118270874023
Batch 53/64 loss: 1.7789654731750488
Batch 54/64 loss: 1.9414000511169434
Batch 55/64 loss: 2.0594935417175293
Batch 56/64 loss: 1.7417621612548828
Batch 57/64 loss: 2.01175594329834
Batch 58/64 loss: 1.7437629699707031
Batch 59/64 loss: 1.7897772789001465
Batch 60/64 loss: 1.6809115409851074
Batch 61/64 loss: 1.7451977729797363
Batch 62/64 loss: 1.9450674057006836
Batch 63/64 loss: 1.807203769683838
Batch 64/64 loss: -1.1954946517944336
Epoch 121  Train loss: 1.8079329883351045  Val loss: 1.586220344726982
Saving best model, epoch: 121
Epoch 122
-------------------------------
Batch 1/64 loss: 1.7671332359313965
Batch 2/64 loss: 1.7909975051879883
Batch 3/64 loss: 1.8944950103759766
Batch 4/64 loss: 1.8711585998535156
Batch 5/64 loss: 1.819237232208252
Batch 6/64 loss: 1.875518798828125
Batch 7/64 loss: 1.7650146484375
Batch 8/64 loss: 1.912539005279541
Batch 9/64 loss: 1.754201889038086
Batch 10/64 loss: 1.7895774841308594
Batch 11/64 loss: 1.9126415252685547
Batch 12/64 loss: 1.8504867553710938
Batch 13/64 loss: 1.80751371383667
Batch 14/64 loss: 1.7665858268737793
Batch 15/64 loss: 1.739978313446045
Batch 16/64 loss: 1.7387456893920898
Batch 17/64 loss: 1.7638959884643555
Batch 18/64 loss: 1.845749855041504
Batch 19/64 loss: 1.7142391204833984
Batch 20/64 loss: 1.7583484649658203
Batch 21/64 loss: 1.8378467559814453
Batch 22/64 loss: 1.7801580429077148
Batch 23/64 loss: 1.7934203147888184
Batch 24/64 loss: 1.6703577041625977
Batch 25/64 loss: 1.6831769943237305
Batch 26/64 loss: 1.8483858108520508
Batch 27/64 loss: 1.7632989883422852
Batch 28/64 loss: 1.5981569290161133
Batch 29/64 loss: 1.8212428092956543
Batch 30/64 loss: 1.799241542816162
Batch 31/64 loss: 1.7356014251708984
Batch 32/64 loss: 1.868910312652588
Batch 33/64 loss: 1.750077724456787
Batch 34/64 loss: 1.8541054725646973
Batch 35/64 loss: 1.7608871459960938
Batch 36/64 loss: 1.9082140922546387
Batch 37/64 loss: 1.7477326393127441
Batch 38/64 loss: 1.7799983024597168
Batch 39/64 loss: 1.7527270317077637
Batch 40/64 loss: 1.814511775970459
Batch 41/64 loss: 1.6765713691711426
Batch 42/64 loss: 1.5804452896118164
Batch 43/64 loss: 1.652113914489746
Batch 44/64 loss: 1.8909940719604492
Batch 45/64 loss: 1.7282404899597168
Batch 46/64 loss: 1.6543803215026855
Batch 47/64 loss: 1.7413825988769531
Batch 48/64 loss: 1.8882479667663574
Batch 49/64 loss: 1.813283920288086
Batch 50/64 loss: 1.9593505859375
Batch 51/64 loss: 1.8558416366577148
Batch 52/64 loss: 1.987062931060791
Batch 53/64 loss: 1.790151596069336
Batch 54/64 loss: 2.2102699279785156
Batch 55/64 loss: 1.9032702445983887
Batch 56/64 loss: 2.059985637664795
Batch 57/64 loss: 1.8479785919189453
Batch 58/64 loss: 1.8196749687194824
Batch 59/64 loss: 1.737030029296875
Batch 60/64 loss: 1.8614768981933594
Batch 61/64 loss: 1.8043131828308105
Batch 62/64 loss: 1.9123144149780273
Batch 63/64 loss: 1.941967487335205
Batch 64/64 loss: -1.4876289367675781
Epoch 122  Train loss: 1.7710860682468788  Val loss: 1.6357102279400908
Epoch 123
-------------------------------
Batch 1/64 loss: 1.8032832145690918
Batch 2/64 loss: 1.8744568824768066
Batch 3/64 loss: 1.8379855155944824
Batch 4/64 loss: 1.9236297607421875
Batch 5/64 loss: 1.7772130966186523
Batch 6/64 loss: 1.8181519508361816
Batch 7/64 loss: 1.9667186737060547
Batch 8/64 loss: 1.8810853958129883
Batch 9/64 loss: 1.847700595855713
Batch 10/64 loss: 1.6611394882202148
Batch 11/64 loss: 1.9475116729736328
Batch 12/64 loss: 1.8310470581054688
Batch 13/64 loss: 1.813948631286621
Batch 14/64 loss: 1.7606711387634277
Batch 15/64 loss: 1.6972579956054688
Batch 16/64 loss: 1.7661876678466797
Batch 17/64 loss: 1.890106201171875
Batch 18/64 loss: 1.7908692359924316
Batch 19/64 loss: 1.8603978157043457
Batch 20/64 loss: 1.6946496963500977
Batch 21/64 loss: 1.7719478607177734
Batch 22/64 loss: 1.9554295539855957
Batch 23/64 loss: 1.777346134185791
Batch 24/64 loss: 1.9736051559448242
Batch 25/64 loss: 1.989180564880371
Batch 26/64 loss: 1.9858999252319336
Batch 27/64 loss: 1.8991966247558594
Batch 28/64 loss: 1.9157047271728516
Batch 29/64 loss: 1.753321647644043
Batch 30/64 loss: 1.8823351860046387
Batch 31/64 loss: 1.9645366668701172
Batch 32/64 loss: 1.8125438690185547
Batch 33/64 loss: 1.9295120239257812
Batch 34/64 loss: 1.9554853439331055
Batch 35/64 loss: 1.7979021072387695
Batch 36/64 loss: 1.8698806762695312
Batch 37/64 loss: 1.9238266944885254
Batch 38/64 loss: 2.050574779510498
Batch 39/64 loss: 2.2476978302001953
Batch 40/64 loss: 1.960106372833252
Batch 41/64 loss: 1.834545612335205
Batch 42/64 loss: 1.855543613433838
Batch 43/64 loss: 1.869272232055664
Batch 44/64 loss: 1.785719394683838
Batch 45/64 loss: 1.8117899894714355
Batch 46/64 loss: 1.714869499206543
Batch 47/64 loss: 2.0324225425720215
Batch 48/64 loss: 2.1897506713867188
Batch 49/64 loss: 1.9294004440307617
Batch 50/64 loss: 1.76560640335083
Batch 51/64 loss: 1.9076576232910156
Batch 52/64 loss: 1.9198002815246582
Batch 53/64 loss: 1.797743320465088
Batch 54/64 loss: 1.8156871795654297
Batch 55/64 loss: 1.801999568939209
Batch 56/64 loss: 1.7364377975463867
Batch 57/64 loss: 1.9187402725219727
Batch 58/64 loss: 1.7494430541992188
Batch 59/64 loss: 1.7487268447875977
Batch 60/64 loss: 1.908362865447998
Batch 61/64 loss: 1.839263916015625
Batch 62/64 loss: 1.974134922027588
Batch 63/64 loss: 2.054089069366455
Batch 64/64 loss: -1.452815055847168
Epoch 123  Train loss: 1.8310814315197514  Val loss: 1.6634866970101583
Epoch 124
-------------------------------
Batch 1/64 loss: 2.1624279022216797
Batch 2/64 loss: 1.8636841773986816
Batch 3/64 loss: 1.9679055213928223
Batch 4/64 loss: 1.8393535614013672
Batch 5/64 loss: 1.7114019393920898
Batch 6/64 loss: 1.81089448928833
Batch 7/64 loss: 1.9864907264709473
Batch 8/64 loss: 1.8180537223815918
Batch 9/64 loss: 1.849168300628662
Batch 10/64 loss: 1.9065093994140625
Batch 11/64 loss: 1.700859546661377
Batch 12/64 loss: 1.989290714263916
Batch 13/64 loss: 1.7245774269104004
Batch 14/64 loss: 1.7869267463684082
Batch 15/64 loss: 1.9725651741027832
Batch 16/64 loss: 1.8006415367126465
Batch 17/64 loss: 1.7654962539672852
Batch 18/64 loss: 1.829246997833252
Batch 19/64 loss: 1.92537260055542
Batch 20/64 loss: 1.7957653999328613
Batch 21/64 loss: 1.7197279930114746
Batch 22/64 loss: 1.7744712829589844
Batch 23/64 loss: 2.2219271659851074
Batch 24/64 loss: 1.8027067184448242
Batch 25/64 loss: 1.819122314453125
Batch 26/64 loss: 1.7497611045837402
Batch 27/64 loss: 1.7760505676269531
Batch 28/64 loss: 2.1035380363464355
Batch 29/64 loss: 1.9513864517211914
Batch 30/64 loss: 1.7687182426452637
Batch 31/64 loss: 1.9979887008666992
Batch 32/64 loss: 1.7583990097045898
Batch 33/64 loss: 1.780447006225586
Batch 34/64 loss: 1.8442530632019043
Batch 35/64 loss: 1.684234619140625
Batch 36/64 loss: 2.031301975250244
Batch 37/64 loss: 1.8816123008728027
Batch 38/64 loss: 2.0253405570983887
Batch 39/64 loss: 1.889655590057373
Batch 40/64 loss: 1.9416155815124512
Batch 41/64 loss: 1.8776969909667969
Batch 42/64 loss: 1.7468724250793457
Batch 43/64 loss: 2.013641357421875
Batch 44/64 loss: 1.8214612007141113
Batch 45/64 loss: 1.9468164443969727
Batch 46/64 loss: 1.7796745300292969
Batch 47/64 loss: 1.8755507469177246
Batch 48/64 loss: 2.0324807167053223
Batch 49/64 loss: 1.8572254180908203
Batch 50/64 loss: 2.2517037391662598
Batch 51/64 loss: 1.8664155006408691
Batch 52/64 loss: 1.9282588958740234
Batch 53/64 loss: 1.7665939331054688
Batch 54/64 loss: 1.7878437042236328
Batch 55/64 loss: 2.0302019119262695
Batch 56/64 loss: 1.7614970207214355
Batch 57/64 loss: 1.794184684753418
Batch 58/64 loss: 2.0570545196533203
Batch 59/64 loss: 1.8498525619506836
Batch 60/64 loss: 1.7101550102233887
Batch 61/64 loss: 1.811269760131836
Batch 62/64 loss: 1.8797087669372559
Batch 63/64 loss: 1.9590072631835938
Batch 64/64 loss: -1.473236083984375
Epoch 124  Train loss: 1.8357510660208909  Val loss: 1.6247527722230892
Epoch 125
-------------------------------
Batch 1/64 loss: 1.8953266143798828
Batch 2/64 loss: 1.9099383354187012
Batch 3/64 loss: 1.829951286315918
Batch 4/64 loss: 1.851402759552002
Batch 5/64 loss: 1.8084602355957031
Batch 6/64 loss: 1.7369918823242188
Batch 7/64 loss: 2.0191569328308105
Batch 8/64 loss: 1.723465919494629
Batch 9/64 loss: 1.865614414215088
Batch 10/64 loss: 1.970827579498291
Batch 11/64 loss: 2.012071132659912
Batch 12/64 loss: 1.862377643585205
Batch 13/64 loss: 1.9764599800109863
Batch 14/64 loss: 1.890810489654541
Batch 15/64 loss: 1.861598014831543
Batch 16/64 loss: 1.7398810386657715
Batch 17/64 loss: 1.9006333351135254
Batch 18/64 loss: 1.8268637657165527
Batch 19/64 loss: 1.9580564498901367
Batch 20/64 loss: 1.778892993927002
Batch 21/64 loss: 1.8061327934265137
Batch 22/64 loss: 1.7985529899597168
Batch 23/64 loss: 1.8793845176696777
Batch 24/64 loss: 1.7169251441955566
Batch 25/64 loss: 1.8456645011901855
Batch 26/64 loss: 1.9575181007385254
Batch 27/64 loss: 1.8903279304504395
Batch 28/64 loss: 1.7905173301696777
Batch 29/64 loss: 1.9387249946594238
Batch 30/64 loss: 1.7057733535766602
Batch 31/64 loss: 1.7926263809204102
Batch 32/64 loss: 1.7899532318115234
Batch 33/64 loss: 1.710555076599121
Batch 34/64 loss: 1.7392334938049316
Batch 35/64 loss: 1.9029455184936523
Batch 36/64 loss: 1.8010940551757812
Batch 37/64 loss: 1.7678041458129883
Batch 38/64 loss: 1.8897700309753418
Batch 39/64 loss: 1.921168327331543
Batch 40/64 loss: 1.8337836265563965
Batch 41/64 loss: 2.0040159225463867
Batch 42/64 loss: 1.8065519332885742
Batch 43/64 loss: 1.8940134048461914
Batch 44/64 loss: 1.9261293411254883
Batch 45/64 loss: 1.9187908172607422
Batch 46/64 loss: 2.192399501800537
Batch 47/64 loss: 1.7521800994873047
Batch 48/64 loss: 2.023991107940674
Batch 49/64 loss: 1.9559416770935059
Batch 50/64 loss: 1.8158512115478516
Batch 51/64 loss: 1.953366756439209
Batch 52/64 loss: 2.1150083541870117
Batch 53/64 loss: 1.7601380348205566
Batch 54/64 loss: 1.9279212951660156
Batch 55/64 loss: 2.032388210296631
Batch 56/64 loss: 1.873746395111084
Batch 57/64 loss: 1.952563762664795
Batch 58/64 loss: 1.810102939605713
Batch 59/64 loss: 1.9897794723510742
Batch 60/64 loss: 1.798121452331543
Batch 61/64 loss: 1.8911519050598145
Batch 62/64 loss: 1.9957752227783203
Batch 63/64 loss: 1.8269424438476562
Batch 64/64 loss: -1.4042162895202637
Epoch 125  Train loss: 1.836250123790666  Val loss: 1.6992919109121631
Epoch 126
-------------------------------
Batch 1/64 loss: 1.872823715209961
Batch 2/64 loss: 1.7403955459594727
Batch 3/64 loss: 1.943056583404541
Batch 4/64 loss: 1.9793100357055664
Batch 5/64 loss: 1.8815364837646484
Batch 6/64 loss: 1.803208351135254
Batch 7/64 loss: 1.7658634185791016
Batch 8/64 loss: 1.7375335693359375
Batch 9/64 loss: 1.9205031394958496
Batch 10/64 loss: 1.7776412963867188
Batch 11/64 loss: 1.9213929176330566
Batch 12/64 loss: 2.0913023948669434
Batch 13/64 loss: 1.913424015045166
Batch 14/64 loss: 1.973055362701416
Batch 15/64 loss: 1.838672161102295
Batch 16/64 loss: 1.800905704498291
Batch 17/64 loss: 1.883303165435791
Batch 18/64 loss: 1.7314672470092773
Batch 19/64 loss: 1.8066978454589844
Batch 20/64 loss: 1.9256858825683594
Batch 21/64 loss: 2.0734076499938965
Batch 22/64 loss: 2.0370984077453613
Batch 23/64 loss: 2.2973599433898926
Batch 24/64 loss: 2.149779796600342
Batch 25/64 loss: 1.901400089263916
Batch 26/64 loss: 1.9682865142822266
Batch 27/64 loss: 2.084171772003174
Batch 28/64 loss: 2.088961601257324
Batch 29/64 loss: 1.9945464134216309
Batch 30/64 loss: 1.8116111755371094
Batch 31/64 loss: 1.9908928871154785
Batch 32/64 loss: 2.0394716262817383
Batch 33/64 loss: 2.003142833709717
Batch 34/64 loss: 2.3506417274475098
Batch 35/64 loss: 1.8952374458312988
Batch 36/64 loss: 2.0269980430603027
Batch 37/64 loss: 1.814462661743164
Batch 38/64 loss: 1.935229778289795
Batch 39/64 loss: 1.9409408569335938
Batch 40/64 loss: 2.1866092681884766
Batch 41/64 loss: 1.8843317031860352
Batch 42/64 loss: 1.9600696563720703
Batch 43/64 loss: 1.9073548316955566
Batch 44/64 loss: 2.201139450073242
Batch 45/64 loss: 1.8911957740783691
Batch 46/64 loss: 1.8847241401672363
Batch 47/64 loss: 1.8477263450622559
Batch 48/64 loss: 1.7262077331542969
Batch 49/64 loss: 2.000448703765869
Batch 50/64 loss: 1.8521051406860352
Batch 51/64 loss: 1.8487548828125
Batch 52/64 loss: 1.8160381317138672
Batch 53/64 loss: 1.78875732421875
Batch 54/64 loss: 1.9058775901794434
Batch 55/64 loss: 1.864274501800537
Batch 56/64 loss: 1.7550454139709473
Batch 57/64 loss: 2.145440101623535
Batch 58/64 loss: 2.272205352783203
Batch 59/64 loss: 1.8848671913146973
Batch 60/64 loss: 1.912623405456543
Batch 61/64 loss: 1.8980016708374023
Batch 62/64 loss: 2.0180110931396484
Batch 63/64 loss: 1.6752572059631348
Batch 64/64 loss: -1.2842488288879395
Epoch 126  Train loss: 1.896083138035793  Val loss: 1.6865991218802856
Epoch 127
-------------------------------
Batch 1/64 loss: 1.892961025238037
Batch 2/64 loss: 1.8659305572509766
Batch 3/64 loss: 2.1015968322753906
Batch 4/64 loss: 2.033318042755127
Batch 5/64 loss: 1.7794313430786133
Batch 6/64 loss: 2.141122341156006
Batch 7/64 loss: 1.8873586654663086
Batch 8/64 loss: 1.817652702331543
Batch 9/64 loss: 1.7810344696044922
Batch 10/64 loss: 2.0479259490966797
Batch 11/64 loss: 1.7768511772155762
Batch 12/64 loss: 2.036675453186035
Batch 13/64 loss: 1.8170127868652344
Batch 14/64 loss: 1.656557559967041
Batch 15/64 loss: 1.8642578125
Batch 16/64 loss: 1.819526195526123
Batch 17/64 loss: 1.9217748641967773
Batch 18/64 loss: 1.8344860076904297
Batch 19/64 loss: 1.9801530838012695
Batch 20/64 loss: 1.8017263412475586
Batch 21/64 loss: 2.0411105155944824
Batch 22/64 loss: 2.061368465423584
Batch 23/64 loss: 1.9508161544799805
Batch 24/64 loss: 1.93914794921875
Batch 25/64 loss: 1.7944183349609375
Batch 26/64 loss: 1.8145670890808105
Batch 27/64 loss: 2.019031524658203
Batch 28/64 loss: 1.795712947845459
Batch 29/64 loss: 1.8823914527893066
Batch 30/64 loss: 1.760690689086914
Batch 31/64 loss: 2.0079030990600586
Batch 32/64 loss: 1.8365955352783203
Batch 33/64 loss: 1.9914264678955078
Batch 34/64 loss: 1.924787998199463
Batch 35/64 loss: 2.0201754570007324
Batch 36/64 loss: 1.730849266052246
Batch 37/64 loss: 1.8579201698303223
Batch 38/64 loss: 1.8628487586975098
Batch 39/64 loss: 1.681443214416504
Batch 40/64 loss: 1.6933379173278809
Batch 41/64 loss: 1.8721070289611816
Batch 42/64 loss: 2.106086254119873
Batch 43/64 loss: 2.106532096862793
Batch 44/64 loss: 2.0182571411132812
Batch 45/64 loss: 1.7885518074035645
Batch 46/64 loss: 2.3540163040161133
Batch 47/64 loss: 1.8103041648864746
Batch 48/64 loss: 2.133401870727539
Batch 49/64 loss: 1.7406468391418457
Batch 50/64 loss: 1.765505313873291
Batch 51/64 loss: 1.9452180862426758
Batch 52/64 loss: 1.9403905868530273
Batch 53/64 loss: 2.0971899032592773
Batch 54/64 loss: 2.3963584899902344
Batch 55/64 loss: 2.039144992828369
Batch 56/64 loss: 2.098790168762207
Batch 57/64 loss: 1.8521852493286133
Batch 58/64 loss: 1.954620361328125
Batch 59/64 loss: 2.0110487937927246
Batch 60/64 loss: 2.1030964851379395
Batch 61/64 loss: 1.8931770324707031
Batch 62/64 loss: 2.2064080238342285
Batch 63/64 loss: 1.879678726196289
Batch 64/64 loss: -1.372544288635254
Epoch 127  Train loss: 1.8918777054431393  Val loss: 1.794525336563792
Epoch 128
-------------------------------
Batch 1/64 loss: 2.0520100593566895
Batch 2/64 loss: 2.133131504058838
Batch 3/64 loss: 2.122513771057129
Batch 4/64 loss: 1.8633222579956055
Batch 5/64 loss: 1.8785715103149414
Batch 6/64 loss: 2.181173324584961
Batch 7/64 loss: 1.9110221862792969
Batch 8/64 loss: 1.971837043762207
Batch 9/64 loss: 2.2762198448181152
Batch 10/64 loss: 1.817392349243164
Batch 11/64 loss: 1.879922866821289
Batch 12/64 loss: 2.349208354949951
Batch 13/64 loss: 1.8951516151428223
Batch 14/64 loss: 1.7880005836486816
Batch 15/64 loss: 2.053131580352783
Batch 16/64 loss: 2.0086889266967773
Batch 17/64 loss: 2.0852861404418945
Batch 18/64 loss: 1.7882485389709473
Batch 19/64 loss: 2.014512538909912
Batch 20/64 loss: 1.9347734451293945
Batch 21/64 loss: 1.8818745613098145
Batch 22/64 loss: 2.0119881629943848
Batch 23/64 loss: 2.139129161834717
Batch 24/64 loss: 1.9246745109558105
Batch 25/64 loss: 1.9794063568115234
Batch 26/64 loss: 2.0237340927124023
Batch 27/64 loss: 1.8721208572387695
Batch 28/64 loss: 1.9416589736938477
Batch 29/64 loss: 1.9724650382995605
Batch 30/64 loss: 1.9180426597595215
Batch 31/64 loss: 2.4720988273620605
Batch 32/64 loss: 2.138371467590332
Batch 33/64 loss: 2.266486167907715
Batch 34/64 loss: 1.8864240646362305
Batch 35/64 loss: 1.9654197692871094
Batch 36/64 loss: 2.296947479248047
Batch 37/64 loss: 1.8250155448913574
Batch 38/64 loss: 1.9169650077819824
Batch 39/64 loss: 1.9115643501281738
Batch 40/64 loss: 1.9734044075012207
Batch 41/64 loss: 1.99751615524292
Batch 42/64 loss: 1.901627540588379
Batch 43/64 loss: 1.7844185829162598
Batch 44/64 loss: 1.8041200637817383
Batch 45/64 loss: 1.808243751525879
Batch 46/64 loss: 1.9815764427185059
Batch 47/64 loss: 2.039940357208252
Batch 48/64 loss: 1.9972262382507324
Batch 49/64 loss: 1.8162918090820312
Batch 50/64 loss: 1.766085147857666
Batch 51/64 loss: 1.8012232780456543
Batch 52/64 loss: 1.9779772758483887
Batch 53/64 loss: 1.8155226707458496
Batch 54/64 loss: 1.8659052848815918
Batch 55/64 loss: 1.8831205368041992
Batch 56/64 loss: 1.7719225883483887
Batch 57/64 loss: 2.0480175018310547
Batch 58/64 loss: 2.0162129402160645
Batch 59/64 loss: 1.9860634803771973
Batch 60/64 loss: 1.8275980949401855
Batch 61/64 loss: 1.8897714614868164
Batch 62/64 loss: 2.0886054039001465
Batch 63/64 loss: 1.9430956840515137
Batch 64/64 loss: -1.0700860023498535
Epoch 128  Train loss: 1.9346106304841884  Val loss: 1.718101265504188
Epoch 129
-------------------------------
Batch 1/64 loss: 1.8005094528198242
Batch 2/64 loss: 1.944906234741211
Batch 3/64 loss: 1.7808752059936523
Batch 4/64 loss: 2.012631416320801
Batch 5/64 loss: 2.173651695251465
Batch 6/64 loss: 1.9977812767028809
Batch 7/64 loss: 1.8339366912841797
Batch 8/64 loss: 2.034123420715332
Batch 9/64 loss: 1.996321201324463
Batch 10/64 loss: 1.8264493942260742
Batch 11/64 loss: 1.9718008041381836
Batch 12/64 loss: 1.974794864654541
Batch 13/64 loss: 1.9004268646240234
Batch 14/64 loss: 2.1693153381347656
Batch 15/64 loss: 1.9596729278564453
Batch 16/64 loss: 2.029825210571289
Batch 17/64 loss: 2.08772611618042
Batch 18/64 loss: 2.0362629890441895
Batch 19/64 loss: 1.7486763000488281
Batch 20/64 loss: 1.8502588272094727
Batch 21/64 loss: 1.8826580047607422
Batch 22/64 loss: 1.8680248260498047
Batch 23/64 loss: 1.9175596237182617
Batch 24/64 loss: 1.8630437850952148
Batch 25/64 loss: 1.9040155410766602
Batch 26/64 loss: 1.6839160919189453
Batch 27/64 loss: 1.9139771461486816
Batch 28/64 loss: 1.8082304000854492
Batch 29/64 loss: 1.9767308235168457
Batch 30/64 loss: 1.9109373092651367
Batch 31/64 loss: 1.8490405082702637
Batch 32/64 loss: 2.1180801391601562
Batch 33/64 loss: 1.9210562705993652
Batch 34/64 loss: 1.8748412132263184
Batch 35/64 loss: 2.1973118782043457
Batch 36/64 loss: 1.8211231231689453
Batch 37/64 loss: 2.2979884147644043
Batch 38/64 loss: 1.8470582962036133
Batch 39/64 loss: 2.149578094482422
Batch 40/64 loss: 2.1300806999206543
Batch 41/64 loss: 2.260794162750244
Batch 42/64 loss: 1.9985170364379883
Batch 43/64 loss: 1.8508234024047852
Batch 44/64 loss: 2.17612886428833
Batch 45/64 loss: 1.907620906829834
Batch 46/64 loss: 1.8325624465942383
Batch 47/64 loss: 2.1301026344299316
Batch 48/64 loss: 1.8911781311035156
Batch 49/64 loss: 1.824397087097168
Batch 50/64 loss: 1.7313518524169922
Batch 51/64 loss: 1.877652645111084
Batch 52/64 loss: 1.9291906356811523
Batch 53/64 loss: 2.2022032737731934
Batch 54/64 loss: 1.862380027770996
Batch 55/64 loss: 1.8717222213745117
Batch 56/64 loss: 2.0045242309570312
Batch 57/64 loss: 1.8432064056396484
Batch 58/64 loss: 2.096851348876953
Batch 59/64 loss: 2.220950126647949
Batch 60/64 loss: 1.9276347160339355
Batch 61/64 loss: 1.913884162902832
Batch 62/64 loss: 1.8697929382324219
Batch 63/64 loss: 1.813124656677246
Batch 64/64 loss: -1.4530229568481445
Epoch 129  Train loss: 1.913914119496065  Val loss: 1.7647831644798881
Epoch 130
-------------------------------
Batch 1/64 loss: 1.7972650527954102
Batch 2/64 loss: 2.1714744567871094
Batch 3/64 loss: 1.894944190979004
Batch 4/64 loss: 2.161436080932617
Batch 5/64 loss: 1.9629592895507812
Batch 6/64 loss: 1.9162240028381348
Batch 7/64 loss: 2.2553768157958984
Batch 8/64 loss: 1.8983850479125977
Batch 9/64 loss: 1.9077868461608887
Batch 10/64 loss: 2.002208709716797
Batch 11/64 loss: 1.8515610694885254
Batch 12/64 loss: 1.8443880081176758
Batch 13/64 loss: 1.9451122283935547
Batch 14/64 loss: 1.993232250213623
Batch 15/64 loss: 2.101886749267578
Batch 16/64 loss: 1.7826900482177734
Batch 17/64 loss: 1.915130615234375
Batch 18/64 loss: 1.7623448371887207
Batch 19/64 loss: 1.9345927238464355
Batch 20/64 loss: 1.9293861389160156
Batch 21/64 loss: 1.6991491317749023
Batch 22/64 loss: 1.9606657028198242
Batch 23/64 loss: 1.7668070793151855
Batch 24/64 loss: 1.8416023254394531
Batch 25/64 loss: 2.1681594848632812
Batch 26/64 loss: 1.833125114440918
Batch 27/64 loss: 2.0627598762512207
Batch 28/64 loss: 1.8389830589294434
Batch 29/64 loss: 1.9420280456542969
Batch 30/64 loss: 1.7327313423156738
Batch 31/64 loss: 2.2660374641418457
Batch 32/64 loss: 2.027235984802246
Batch 33/64 loss: 1.837235927581787
Batch 34/64 loss: 2.177028179168701
Batch 35/64 loss: 1.8555750846862793
Batch 36/64 loss: 1.7631511688232422
Batch 37/64 loss: 1.8862123489379883
Batch 38/64 loss: 1.7779655456542969
Batch 39/64 loss: 1.8310942649841309
Batch 40/64 loss: 2.015939712524414
Batch 41/64 loss: 1.9179697036743164
Batch 42/64 loss: 1.9760055541992188
Batch 43/64 loss: 1.9084558486938477
Batch 44/64 loss: 2.461902141571045
Batch 45/64 loss: 1.770035743713379
Batch 46/64 loss: 1.9956936836242676
Batch 47/64 loss: 1.9620614051818848
Batch 48/64 loss: 1.9506335258483887
Batch 49/64 loss: 2.091446876525879
Batch 50/64 loss: 1.8940882682800293
Batch 51/64 loss: 2.0009140968322754
Batch 52/64 loss: 1.8969874382019043
Batch 53/64 loss: 1.8733158111572266
Batch 54/64 loss: 2.338878631591797
Batch 55/64 loss: 1.8816943168640137
Batch 56/64 loss: 1.7591290473937988
Batch 57/64 loss: 1.8425383567810059
Batch 58/64 loss: 1.9481496810913086
Batch 59/64 loss: 1.8565869331359863
Batch 60/64 loss: 2.1637144088745117
Batch 61/64 loss: 1.9047393798828125
Batch 62/64 loss: 2.262075424194336
Batch 63/64 loss: 1.8337841033935547
Batch 64/64 loss: -1.1407132148742676
Epoch 130  Train loss: 1.9128962741178626  Val loss: 1.7489739119801735
Epoch 131
-------------------------------
Batch 1/64 loss: 2.1399612426757812
Batch 2/64 loss: 1.999356746673584
Batch 3/64 loss: 2.037672996520996
Batch 4/64 loss: 2.0425572395324707
Batch 5/64 loss: 1.835233211517334
Batch 6/64 loss: 1.8855586051940918
Batch 7/64 loss: 2.1955385208129883
Batch 8/64 loss: 1.873565673828125
Batch 9/64 loss: 1.9505715370178223
Batch 10/64 loss: 1.989889144897461
Batch 11/64 loss: 2.2899107933044434
Batch 12/64 loss: 2.029505729675293
Batch 13/64 loss: 1.9179506301879883
Batch 14/64 loss: 1.936434268951416
Batch 15/64 loss: 1.7659354209899902
Batch 16/64 loss: 1.8944401741027832
Batch 17/64 loss: 1.8725318908691406
Batch 18/64 loss: 1.77587890625
Batch 19/64 loss: 2.053112506866455
Batch 20/64 loss: 1.8626956939697266
Batch 21/64 loss: 1.870776653289795
Batch 22/64 loss: 1.8446078300476074
Batch 23/64 loss: 1.750370979309082
Batch 24/64 loss: 2.060421943664551
Batch 25/64 loss: 2.007002353668213
Batch 26/64 loss: 1.6972193717956543
Batch 27/64 loss: 2.0641703605651855
Batch 28/64 loss: 2.059467315673828
Batch 29/64 loss: 1.9483652114868164
Batch 30/64 loss: 1.8732891082763672
Batch 31/64 loss: 1.960540771484375
Batch 32/64 loss: 1.8118844032287598
Batch 33/64 loss: 1.9111089706420898
Batch 34/64 loss: 1.8449053764343262
Batch 35/64 loss: 1.7884397506713867
Batch 36/64 loss: 1.874669075012207
Batch 37/64 loss: 1.9844045639038086
Batch 38/64 loss: 1.9998235702514648
Batch 39/64 loss: 2.012366771697998
Batch 40/64 loss: 1.9432024955749512
Batch 41/64 loss: 1.730393886566162
Batch 42/64 loss: 1.8437910079956055
Batch 43/64 loss: 2.015204906463623
Batch 44/64 loss: 1.9219970703125
Batch 45/64 loss: 1.7984724044799805
Batch 46/64 loss: 1.854062557220459
Batch 47/64 loss: 2.057112693786621
Batch 48/64 loss: 2.06583833694458
Batch 49/64 loss: 1.9708161354064941
Batch 50/64 loss: 2.1638998985290527
Batch 51/64 loss: 1.8965377807617188
Batch 52/64 loss: 1.879042148590088
Batch 53/64 loss: 1.954732894897461
Batch 54/64 loss: 1.8250150680541992
Batch 55/64 loss: 1.9176316261291504
Batch 56/64 loss: 2.0088791847229004
Batch 57/64 loss: 1.8339691162109375
Batch 58/64 loss: 1.7947940826416016
Batch 59/64 loss: 1.6720967292785645
Batch 60/64 loss: 1.7605376243591309
Batch 61/64 loss: 1.9513778686523438
Batch 62/64 loss: 1.9427103996276855
Batch 63/64 loss: 1.820429801940918
Batch 64/64 loss: -1.1725411415100098
Epoch 131  Train loss: 1.8894945125953824  Val loss: 1.6678627315665437
Epoch 132
-------------------------------
Batch 1/64 loss: 1.9032726287841797
Batch 2/64 loss: 1.8004426956176758
Batch 3/64 loss: 2.006807327270508
Batch 4/64 loss: 1.7613286972045898
Batch 5/64 loss: 1.7178869247436523
Batch 6/64 loss: 1.9801311492919922
Batch 7/64 loss: 2.0294981002807617
Batch 8/64 loss: 1.885535717010498
Batch 9/64 loss: 1.8281035423278809
Batch 10/64 loss: 1.994046688079834
Batch 11/64 loss: 1.8802366256713867
Batch 12/64 loss: 1.8934593200683594
Batch 13/64 loss: 1.8641767501831055
Batch 14/64 loss: 2.154062271118164
Batch 15/64 loss: 2.0240120887756348
Batch 16/64 loss: 2.0970301628112793
Batch 17/64 loss: 1.9538922309875488
Batch 18/64 loss: 2.116486072540283
Batch 19/64 loss: 1.7730536460876465
Batch 20/64 loss: 2.032726764678955
Batch 21/64 loss: 2.164999485015869
Batch 22/64 loss: 1.8689560890197754
Batch 23/64 loss: 1.9336462020874023
Batch 24/64 loss: 1.823350429534912
Batch 25/64 loss: 1.7470345497131348
Batch 26/64 loss: 1.8578534126281738
Batch 27/64 loss: 1.9916620254516602
Batch 28/64 loss: 1.8479461669921875
Batch 29/64 loss: 2.0112109184265137
Batch 30/64 loss: 1.8657236099243164
Batch 31/64 loss: 1.7357802391052246
Batch 32/64 loss: 1.9256367683410645
Batch 33/64 loss: 1.8261542320251465
Batch 34/64 loss: 1.8505096435546875
Batch 35/64 loss: 1.7233171463012695
Batch 36/64 loss: 1.8943428993225098
Batch 37/64 loss: 1.9511828422546387
Batch 38/64 loss: 1.929830551147461
Batch 39/64 loss: 1.8509464263916016
Batch 40/64 loss: 1.7121691703796387
Batch 41/64 loss: 1.7533679008483887
Batch 42/64 loss: 1.6887450218200684
Batch 43/64 loss: 1.9084057807922363
Batch 44/64 loss: 1.846186637878418
Batch 45/64 loss: 1.8839187622070312
Batch 46/64 loss: 1.8018226623535156
Batch 47/64 loss: 1.9307289123535156
Batch 48/64 loss: 1.729928970336914
Batch 49/64 loss: 2.014841079711914
Batch 50/64 loss: 1.905527114868164
Batch 51/64 loss: 1.7784667015075684
Batch 52/64 loss: 1.8117427825927734
Batch 53/64 loss: 1.8884458541870117
Batch 54/64 loss: 1.7951416969299316
Batch 55/64 loss: 1.8270034790039062
Batch 56/64 loss: 1.8226318359375
Batch 57/64 loss: 1.8091859817504883
Batch 58/64 loss: 1.9239606857299805
Batch 59/64 loss: 1.815727710723877
Batch 60/64 loss: 1.7776427268981934
Batch 61/64 loss: 1.9659004211425781
Batch 62/64 loss: 1.7338862419128418
Batch 63/64 loss: 1.8902530670166016
Batch 64/64 loss: -1.5706052780151367
Epoch 132  Train loss: 1.840532553429697  Val loss: 1.5875538698176748
Epoch 133
-------------------------------
Batch 1/64 loss: 1.9492731094360352
Batch 2/64 loss: 1.7995529174804688
Batch 3/64 loss: 1.865870475769043
Batch 4/64 loss: 1.8713674545288086
Batch 5/64 loss: 1.7550687789916992
Batch 6/64 loss: 1.75966215133667
Batch 7/64 loss: 1.7838711738586426
Batch 8/64 loss: 1.6975173950195312
Batch 9/64 loss: 1.9445586204528809
Batch 10/64 loss: 2.1142444610595703
Batch 11/64 loss: 1.9234504699707031
Batch 12/64 loss: 1.8325576782226562
Batch 13/64 loss: 1.8792057037353516
Batch 14/64 loss: 1.8617191314697266
Batch 15/64 loss: 1.8978209495544434
Batch 16/64 loss: 1.89027738571167
Batch 17/64 loss: 2.0285210609436035
Batch 18/64 loss: 2.110137462615967
Batch 19/64 loss: 2.000650405883789
Batch 20/64 loss: 2.0522804260253906
Batch 21/64 loss: 1.9197282791137695
Batch 22/64 loss: 1.884781837463379
Batch 23/64 loss: 1.8783159255981445
Batch 24/64 loss: 1.8204030990600586
Batch 25/64 loss: 1.7934341430664062
Batch 26/64 loss: 1.7861247062683105
Batch 27/64 loss: 1.877845287322998
Batch 28/64 loss: 1.9157614707946777
Batch 29/64 loss: 2.048279285430908
Batch 30/64 loss: 1.897064208984375
Batch 31/64 loss: 1.8530645370483398
Batch 32/64 loss: 1.8919825553894043
Batch 33/64 loss: 1.6617021560668945
Batch 34/64 loss: 1.811863899230957
Batch 35/64 loss: 2.15386962890625
Batch 36/64 loss: 1.687089443206787
Batch 37/64 loss: 1.7800664901733398
Batch 38/64 loss: 2.097330093383789
Batch 39/64 loss: 1.971651554107666
Batch 40/64 loss: 1.8579607009887695
Batch 41/64 loss: 1.7563276290893555
Batch 42/64 loss: 1.7526073455810547
Batch 43/64 loss: 1.7950758934020996
Batch 44/64 loss: 1.9140901565551758
Batch 45/64 loss: 1.8478360176086426
Batch 46/64 loss: 1.7914772033691406
Batch 47/64 loss: 1.7319488525390625
Batch 48/64 loss: 1.748337745666504
Batch 49/64 loss: 1.9146924018859863
Batch 50/64 loss: 2.011192798614502
Batch 51/64 loss: 1.6443042755126953
Batch 52/64 loss: 1.908189296722412
Batch 53/64 loss: 1.8100104331970215
Batch 54/64 loss: 1.7775273323059082
Batch 55/64 loss: 1.789933204650879
Batch 56/64 loss: 1.791367530822754
Batch 57/64 loss: 1.8363361358642578
Batch 58/64 loss: 1.772587776184082
Batch 59/64 loss: 1.8407378196716309
Batch 60/64 loss: 1.7976408004760742
Batch 61/64 loss: 2.008451461791992
Batch 62/64 loss: 1.9139041900634766
Batch 63/64 loss: 1.8331327438354492
Batch 64/64 loss: -1.2055597305297852
Epoch 133  Train loss: 1.830422992332309  Val loss: 1.6034696782167834
Epoch 134
-------------------------------
Batch 1/64 loss: 1.8186745643615723
Batch 2/64 loss: 1.8262481689453125
Batch 3/64 loss: 1.7603754997253418
Batch 4/64 loss: 1.9732208251953125
Batch 5/64 loss: 1.7637372016906738
Batch 6/64 loss: 1.6714057922363281
Batch 7/64 loss: 1.817037582397461
Batch 8/64 loss: 1.7792115211486816
Batch 9/64 loss: 1.948793888092041
Batch 10/64 loss: 1.6563138961791992
Batch 11/64 loss: 1.723844051361084
Batch 12/64 loss: 1.9230976104736328
Batch 13/64 loss: 1.9686589241027832
Batch 14/64 loss: 1.8779540061950684
Batch 15/64 loss: 1.9134745597839355
Batch 16/64 loss: 1.842480182647705
Batch 17/64 loss: 1.9395828247070312
Batch 18/64 loss: 1.8765597343444824
Batch 19/64 loss: 1.8418560028076172
Batch 20/64 loss: 1.847489356994629
Batch 21/64 loss: 1.7270054817199707
Batch 22/64 loss: 1.8400368690490723
Batch 23/64 loss: 1.8849682807922363
Batch 24/64 loss: 1.759664535522461
Batch 25/64 loss: 2.0694236755371094
Batch 26/64 loss: 1.8338184356689453
Batch 27/64 loss: 1.854444980621338
Batch 28/64 loss: 1.900726318359375
Batch 29/64 loss: 1.7714548110961914
Batch 30/64 loss: 1.7895312309265137
Batch 31/64 loss: 2.0615925788879395
Batch 32/64 loss: 1.8849215507507324
Batch 33/64 loss: 1.7376337051391602
Batch 34/64 loss: 1.7833609580993652
Batch 35/64 loss: 1.8759679794311523
Batch 36/64 loss: 1.7176284790039062
Batch 37/64 loss: 1.675229549407959
Batch 38/64 loss: 1.7650561332702637
Batch 39/64 loss: 1.9343976974487305
Batch 40/64 loss: 1.8448314666748047
Batch 41/64 loss: 1.9809846878051758
Batch 42/64 loss: 2.012817859649658
Batch 43/64 loss: 1.8518810272216797
Batch 44/64 loss: 1.7686691284179688
Batch 45/64 loss: 1.8604440689086914
Batch 46/64 loss: 1.8106560707092285
Batch 47/64 loss: 1.8043804168701172
Batch 48/64 loss: 1.9993963241577148
Batch 49/64 loss: 2.1188855171203613
Batch 50/64 loss: 1.8032493591308594
Batch 51/64 loss: 2.0726046562194824
Batch 52/64 loss: 1.8147196769714355
Batch 53/64 loss: 1.6804475784301758
Batch 54/64 loss: 2.035635471343994
Batch 55/64 loss: 1.7910938262939453
Batch 56/64 loss: 1.8803648948669434
Batch 57/64 loss: 1.7692785263061523
Batch 58/64 loss: 1.7781214714050293
Batch 59/64 loss: 2.428529739379883
Batch 60/64 loss: 1.8831586837768555
Batch 61/64 loss: 1.889315128326416
Batch 62/64 loss: 1.7259001731872559
Batch 63/64 loss: 1.7827668190002441
Batch 64/64 loss: -1.2689719200134277
Epoch 134  Train loss: 1.820757381588805  Val loss: 1.670381867189178
Epoch 135
-------------------------------
Batch 1/64 loss: 1.6777663230895996
Batch 2/64 loss: 2.0324649810791016
Batch 3/64 loss: 1.8880400657653809
Batch 4/64 loss: 1.7787346839904785
Batch 5/64 loss: 1.902437686920166
Batch 6/64 loss: 1.8300647735595703
Batch 7/64 loss: 1.8626179695129395
Batch 8/64 loss: 2.057725429534912
Batch 9/64 loss: 1.877018928527832
Batch 10/64 loss: 2.202017307281494
Batch 11/64 loss: 1.8231067657470703
Batch 12/64 loss: 1.8087787628173828
Batch 13/64 loss: 1.923567771911621
Batch 14/64 loss: 2.0060601234436035
Batch 15/64 loss: 1.9876189231872559
Batch 16/64 loss: 2.1290879249572754
Batch 17/64 loss: 1.805617332458496
Batch 18/64 loss: 1.888761043548584
Batch 19/64 loss: 1.891249656677246
Batch 20/64 loss: 1.8052067756652832
Batch 21/64 loss: 2.0191235542297363
Batch 22/64 loss: 1.9231090545654297
Batch 23/64 loss: 1.9945592880249023
Batch 24/64 loss: 2.0043630599975586
Batch 25/64 loss: 1.8787569999694824
Batch 26/64 loss: 1.993171215057373
Batch 27/64 loss: 1.738469123840332
Batch 28/64 loss: 1.9098801612854004
Batch 29/64 loss: 1.8388500213623047
Batch 30/64 loss: 1.9370779991149902
Batch 31/64 loss: 1.8163862228393555
Batch 32/64 loss: 1.7937126159667969
Batch 33/64 loss: 2.090498447418213
Batch 34/64 loss: 1.8712725639343262
Batch 35/64 loss: 1.9191327095031738
Batch 36/64 loss: 1.879040241241455
Batch 37/64 loss: 2.1502747535705566
Batch 38/64 loss: 1.8246631622314453
Batch 39/64 loss: 1.8350615501403809
Batch 40/64 loss: 1.892223834991455
Batch 41/64 loss: 2.0061559677124023
Batch 42/64 loss: 2.0128703117370605
Batch 43/64 loss: 1.9486613273620605
Batch 44/64 loss: 1.6933717727661133
Batch 45/64 loss: 1.8824210166931152
Batch 46/64 loss: 1.875302791595459
Batch 47/64 loss: 1.9488043785095215
Batch 48/64 loss: 1.8230876922607422
Batch 49/64 loss: 2.0455827713012695
Batch 50/64 loss: 2.0727033615112305
Batch 51/64 loss: 1.8337812423706055
Batch 52/64 loss: 1.899378776550293
Batch 53/64 loss: 2.1586170196533203
Batch 54/64 loss: 2.0051188468933105
Batch 55/64 loss: 2.0586953163146973
Batch 56/64 loss: 1.7402400970458984
Batch 57/64 loss: 1.8691620826721191
Batch 58/64 loss: 2.0924181938171387
Batch 59/64 loss: 1.912013053894043
Batch 60/64 loss: 1.882270336151123
Batch 61/64 loss: 1.7457776069641113
Batch 62/64 loss: 2.1602377891540527
Batch 63/64 loss: 1.9042010307312012
Batch 64/64 loss: -1.5397119522094727
Epoch 135  Train loss: 1.8808417039759018  Val loss: 1.6601827824648303
Epoch 136
-------------------------------
Batch 1/64 loss: 2.0271973609924316
Batch 2/64 loss: 1.8843860626220703
Batch 3/64 loss: 1.8378705978393555
Batch 4/64 loss: 1.8155550956726074
Batch 5/64 loss: 2.125217914581299
Batch 6/64 loss: 2.0906009674072266
Batch 7/64 loss: 1.831425666809082
Batch 8/64 loss: 2.1623764038085938
Batch 9/64 loss: 2.0092787742614746
Batch 10/64 loss: 1.8724112510681152
Batch 11/64 loss: 1.9394941329956055
Batch 12/64 loss: 1.763016700744629
Batch 13/64 loss: 1.7712678909301758
Batch 14/64 loss: 1.9419503211975098
Batch 15/64 loss: 1.7550086975097656
Batch 16/64 loss: 1.7629079818725586
Batch 17/64 loss: 1.8517179489135742
Batch 18/64 loss: 1.924698829650879
Batch 19/64 loss: 1.786308765411377
Batch 20/64 loss: 1.8880701065063477
Batch 21/64 loss: 1.8764009475708008
Batch 22/64 loss: 1.8949179649353027
Batch 23/64 loss: 1.7377815246582031
Batch 24/64 loss: 1.87217378616333
Batch 25/64 loss: 1.9390897750854492
Batch 26/64 loss: 1.6704082489013672
Batch 27/64 loss: 1.8763022422790527
Batch 28/64 loss: 1.806291103363037
Batch 29/64 loss: 1.7698798179626465
Batch 30/64 loss: 1.8925204277038574
Batch 31/64 loss: 1.660639762878418
Batch 32/64 loss: 1.7722125053405762
Batch 33/64 loss: 1.8932480812072754
Batch 34/64 loss: 1.7690753936767578
Batch 35/64 loss: 1.7970199584960938
Batch 36/64 loss: 1.6921558380126953
Batch 37/64 loss: 1.9175114631652832
Batch 38/64 loss: 1.8222708702087402
Batch 39/64 loss: 1.9135336875915527
Batch 40/64 loss: 1.7668490409851074
Batch 41/64 loss: 1.8458986282348633
Batch 42/64 loss: 1.7086219787597656
Batch 43/64 loss: 2.0179319381713867
Batch 44/64 loss: 1.8041391372680664
Batch 45/64 loss: 1.8574209213256836
Batch 46/64 loss: 1.8653316497802734
Batch 47/64 loss: 1.9853591918945312
Batch 48/64 loss: 1.7511200904846191
Batch 49/64 loss: 1.7419700622558594
Batch 50/64 loss: 1.8743066787719727
Batch 51/64 loss: 1.850454330444336
Batch 52/64 loss: 1.9118127822875977
Batch 53/64 loss: 1.8742423057556152
Batch 54/64 loss: 1.7811574935913086
Batch 55/64 loss: 2.0291666984558105
Batch 56/64 loss: 1.7237844467163086
Batch 57/64 loss: 1.7560787200927734
Batch 58/64 loss: 1.8638873100280762
Batch 59/64 loss: 1.8996810913085938
Batch 60/64 loss: 1.7439627647399902
Batch 61/64 loss: 1.902099609375
Batch 62/64 loss: 1.770514965057373
Batch 63/64 loss: 1.8651609420776367
Batch 64/64 loss: -1.3788256645202637
Epoch 136  Train loss: 1.8160161317563523  Val loss: 1.625174329043254
Epoch 137
-------------------------------
Batch 1/64 loss: 1.9308032989501953
Batch 2/64 loss: 1.8277344703674316
Batch 3/64 loss: 1.908090591430664
Batch 4/64 loss: 1.693676471710205
Batch 5/64 loss: 1.9492392539978027
Batch 6/64 loss: 1.7916431427001953
Batch 7/64 loss: 1.8413395881652832
Batch 8/64 loss: 1.7602295875549316
Batch 9/64 loss: 1.949507713317871
Batch 10/64 loss: 1.806140422821045
Batch 11/64 loss: 1.9358696937561035
Batch 12/64 loss: 1.9518609046936035
Batch 13/64 loss: 1.9083538055419922
Batch 14/64 loss: 1.7696518898010254
Batch 15/64 loss: 1.9125075340270996
Batch 16/64 loss: 1.8126850128173828
Batch 17/64 loss: 1.7776479721069336
Batch 18/64 loss: 1.9835505485534668
Batch 19/64 loss: 1.9215044975280762
Batch 20/64 loss: 1.8271327018737793
Batch 21/64 loss: 1.8144893646240234
Batch 22/64 loss: 2.336386203765869
Batch 23/64 loss: 1.7449698448181152
Batch 24/64 loss: 1.8470377922058105
Batch 25/64 loss: 1.7266297340393066
Batch 26/64 loss: 1.9921212196350098
Batch 27/64 loss: 1.7685761451721191
Batch 28/64 loss: 1.6927919387817383
Batch 29/64 loss: 1.8278508186340332
Batch 30/64 loss: 1.937669277191162
Batch 31/64 loss: 1.7259812355041504
Batch 32/64 loss: 1.84246826171875
Batch 33/64 loss: 1.8048572540283203
Batch 34/64 loss: 1.922682762145996
Batch 35/64 loss: 1.6671528816223145
Batch 36/64 loss: 1.888631820678711
Batch 37/64 loss: 1.9784841537475586
Batch 38/64 loss: 1.861734390258789
Batch 39/64 loss: 1.815584659576416
Batch 40/64 loss: 1.857675552368164
Batch 41/64 loss: 1.8685250282287598
Batch 42/64 loss: 1.9065985679626465
Batch 43/64 loss: 1.840754508972168
Batch 44/64 loss: 1.7908968925476074
Batch 45/64 loss: 1.7939205169677734
Batch 46/64 loss: 1.730879306793213
Batch 47/64 loss: 1.8070549964904785
Batch 48/64 loss: 1.866358757019043
Batch 49/64 loss: 2.2927656173706055
Batch 50/64 loss: 2.2206034660339355
Batch 51/64 loss: 2.092193126678467
Batch 52/64 loss: 2.1329312324523926
Batch 53/64 loss: 2.1390485763549805
Batch 54/64 loss: 2.237301826477051
Batch 55/64 loss: 1.7526373863220215
Batch 56/64 loss: 2.0473670959472656
Batch 57/64 loss: 1.8851714134216309
Batch 58/64 loss: 1.8820366859436035
Batch 59/64 loss: 1.7346649169921875
Batch 60/64 loss: 2.081749439239502
Batch 61/64 loss: 1.947746753692627
Batch 62/64 loss: 2.078752040863037
Batch 63/64 loss: 1.843249797821045
Batch 64/64 loss: -1.538576602935791
Epoch 137  Train loss: 1.8530544299705356  Val loss: 1.7207794517176258
Epoch 138
-------------------------------
Batch 1/64 loss: 1.999190330505371
Batch 2/64 loss: 1.8369851112365723
Batch 3/64 loss: 2.2755560874938965
Batch 4/64 loss: 1.9120736122131348
Batch 5/64 loss: 1.8668794631958008
Batch 6/64 loss: 2.4542417526245117
Batch 7/64 loss: 1.9728813171386719
Batch 8/64 loss: 2.2147088050842285
Batch 9/64 loss: 2.1241250038146973
Batch 10/64 loss: 1.8378667831420898
Batch 11/64 loss: 1.877138614654541
Batch 12/64 loss: 2.4357357025146484
Batch 13/64 loss: 1.941962718963623
Batch 14/64 loss: 2.025019645690918
Batch 15/64 loss: 1.8982033729553223
Batch 16/64 loss: 2.095468044281006
Batch 17/64 loss: 2.0233120918273926
Batch 18/64 loss: 1.7825288772583008
Batch 19/64 loss: 2.0477304458618164
Batch 20/64 loss: 1.9187941551208496
Batch 21/64 loss: 1.8860774040222168
Batch 22/64 loss: 1.779606819152832
Batch 23/64 loss: 1.9237480163574219
Batch 24/64 loss: 1.8954353332519531
Batch 25/64 loss: 2.0001983642578125
Batch 26/64 loss: 1.8660545349121094
Batch 27/64 loss: 1.94057035446167
Batch 28/64 loss: 1.8027820587158203
Batch 29/64 loss: 1.6873254776000977
Batch 30/64 loss: 2.045344352722168
Batch 31/64 loss: 2.1534042358398438
Batch 32/64 loss: 2.0197958946228027
Batch 33/64 loss: 1.7942891120910645
Batch 34/64 loss: 1.8134851455688477
Batch 35/64 loss: 1.7310986518859863
Batch 36/64 loss: 1.885937213897705
Batch 37/64 loss: 1.7700867652893066
Batch 38/64 loss: 1.8886137008666992
Batch 39/64 loss: 2.0633091926574707
Batch 40/64 loss: 1.9513945579528809
Batch 41/64 loss: 1.6999692916870117
Batch 42/64 loss: 1.9158310890197754
Batch 43/64 loss: 1.8106284141540527
Batch 44/64 loss: 1.8724594116210938
Batch 45/64 loss: 1.7732863426208496
Batch 46/64 loss: 1.8342065811157227
Batch 47/64 loss: 1.767265796661377
Batch 48/64 loss: 1.9656662940979004
Batch 49/64 loss: 1.8344402313232422
Batch 50/64 loss: 1.6512947082519531
Batch 51/64 loss: 1.8766164779663086
Batch 52/64 loss: 1.9250445365905762
Batch 53/64 loss: 1.7290587425231934
Batch 54/64 loss: 1.8511433601379395
Batch 55/64 loss: 1.6746478080749512
Batch 56/64 loss: 1.7652597427368164
Batch 57/64 loss: 1.9117774963378906
Batch 58/64 loss: 1.8124208450317383
Batch 59/64 loss: 1.9800758361816406
Batch 60/64 loss: 1.9069442749023438
Batch 61/64 loss: 1.8388261795043945
Batch 62/64 loss: 1.9064760208129883
Batch 63/64 loss: 1.6486473083496094
Batch 64/64 loss: -1.2603554725646973
Epoch 138  Train loss: 1.873657714619356  Val loss: 1.5707788762358046
Saving best model, epoch: 138
Epoch 139
-------------------------------
Batch 1/64 loss: 1.7604084014892578
Batch 2/64 loss: 2.037184715270996
Batch 3/64 loss: 2.0290145874023438
Batch 4/64 loss: 1.8083796501159668
Batch 5/64 loss: 2.0237951278686523
Batch 6/64 loss: 1.742781639099121
Batch 7/64 loss: 1.8458023071289062
Batch 8/64 loss: 1.9011869430541992
Batch 9/64 loss: 1.721921443939209
Batch 10/64 loss: 1.915712833404541
Batch 11/64 loss: 1.7720460891723633
Batch 12/64 loss: 1.7631092071533203
Batch 13/64 loss: 1.8994460105895996
Batch 14/64 loss: 1.9234309196472168
Batch 15/64 loss: 1.830432415008545
Batch 16/64 loss: 1.8404531478881836
Batch 17/64 loss: 1.9344611167907715
Batch 18/64 loss: 1.7807011604309082
Batch 19/64 loss: 1.8687057495117188
Batch 20/64 loss: 1.9016594886779785
Batch 21/64 loss: 1.8834047317504883
Batch 22/64 loss: 1.8281970024108887
Batch 23/64 loss: 1.8525032997131348
Batch 24/64 loss: 1.8546772003173828
Batch 25/64 loss: 2.0146851539611816
Batch 26/64 loss: 1.985948085784912
Batch 27/64 loss: 1.9593896865844727
Batch 28/64 loss: 1.7141375541687012
Batch 29/64 loss: 1.8635540008544922
Batch 30/64 loss: 1.7918834686279297
Batch 31/64 loss: 1.9091687202453613
Batch 32/64 loss: 2.1024036407470703
Batch 33/64 loss: 1.7053661346435547
Batch 34/64 loss: 1.816788673400879
Batch 35/64 loss: 2.0075106620788574
Batch 36/64 loss: 1.7317862510681152
Batch 37/64 loss: 1.9503211975097656
Batch 38/64 loss: 1.8876261711120605
Batch 39/64 loss: 1.872746467590332
Batch 40/64 loss: 1.7679643630981445
Batch 41/64 loss: 1.7808198928833008
Batch 42/64 loss: 1.8100829124450684
Batch 43/64 loss: 1.8516583442687988
Batch 44/64 loss: 2.1204781532287598
Batch 45/64 loss: 1.9312472343444824
Batch 46/64 loss: 2.1064577102661133
Batch 47/64 loss: 1.901270866394043
Batch 48/64 loss: 1.858863353729248
Batch 49/64 loss: 1.7781219482421875
Batch 50/64 loss: 1.878366470336914
Batch 51/64 loss: 2.428421974182129
Batch 52/64 loss: 1.7952003479003906
Batch 53/64 loss: 1.9356074333190918
Batch 54/64 loss: 1.755767822265625
Batch 55/64 loss: 1.7715325355529785
Batch 56/64 loss: 1.9426589012145996
Batch 57/64 loss: 1.8155546188354492
Batch 58/64 loss: 1.8165454864501953
Batch 59/64 loss: 1.8096590042114258
Batch 60/64 loss: 1.8205170631408691
Batch 61/64 loss: 1.9378647804260254
Batch 62/64 loss: 1.8895010948181152
Batch 63/64 loss: 1.7795109748840332
Batch 64/64 loss: -1.1063761711120605
Epoch 139  Train loss: 1.842927407283409  Val loss: 1.622084116198353
Epoch 140
-------------------------------
Batch 1/64 loss: 2.0294923782348633
Batch 2/64 loss: 1.8857316970825195
Batch 3/64 loss: 2.2094783782958984
Batch 4/64 loss: 1.799849510192871
Batch 5/64 loss: 2.0000953674316406
Batch 6/64 loss: 2.0099563598632812
Batch 7/64 loss: 1.9365739822387695
Batch 8/64 loss: 1.8274893760681152
Batch 9/64 loss: 1.9280424118041992
Batch 10/64 loss: 1.9390535354614258
Batch 11/64 loss: 2.17470121383667
Batch 12/64 loss: 1.8665456771850586
Batch 13/64 loss: 1.9011712074279785
Batch 14/64 loss: 1.8970417976379395
Batch 15/64 loss: 1.9146275520324707
Batch 16/64 loss: 1.8499746322631836
Batch 17/64 loss: 1.958089828491211
Batch 18/64 loss: 1.7464971542358398
Batch 19/64 loss: 2.0105671882629395
Batch 20/64 loss: 2.076085090637207
Batch 21/64 loss: 1.8471941947937012
Batch 22/64 loss: 1.907707691192627
Batch 23/64 loss: 1.8813061714172363
Batch 24/64 loss: 1.9302353858947754
Batch 25/64 loss: 1.913747787475586
Batch 26/64 loss: 1.9613747596740723
Batch 27/64 loss: 1.831526756286621
Batch 28/64 loss: 1.8561921119689941
Batch 29/64 loss: 1.7746539115905762
Batch 30/64 loss: 1.810755729675293
Batch 31/64 loss: 1.99946928024292
Batch 32/64 loss: 2.009244441986084
Batch 33/64 loss: 1.9033632278442383
Batch 34/64 loss: 1.847555160522461
Batch 35/64 loss: 1.780740737915039
Batch 36/64 loss: 1.9171795845031738
Batch 37/64 loss: 1.8100647926330566
Batch 38/64 loss: 2.0560460090637207
Batch 39/64 loss: 1.7104387283325195
Batch 40/64 loss: 1.7471613883972168
Batch 41/64 loss: 1.9316377639770508
Batch 42/64 loss: 1.9393105506896973
Batch 43/64 loss: 1.904144287109375
Batch 44/64 loss: 1.7299036979675293
Batch 45/64 loss: 1.6881608963012695
Batch 46/64 loss: 1.9287776947021484
Batch 47/64 loss: 1.7699079513549805
Batch 48/64 loss: 1.9887042045593262
Batch 49/64 loss: 1.978846549987793
Batch 50/64 loss: 1.8689169883728027
Batch 51/64 loss: 1.9474353790283203
Batch 52/64 loss: 1.7394156455993652
Batch 53/64 loss: 1.7911906242370605
Batch 54/64 loss: 1.7860407829284668
Batch 55/64 loss: 1.934044361114502
Batch 56/64 loss: 1.8397531509399414
Batch 57/64 loss: 1.983809471130371
Batch 58/64 loss: 1.896902084350586
Batch 59/64 loss: 1.6984601020812988
Batch 60/64 loss: 1.7863054275512695
Batch 61/64 loss: 1.707143783569336
Batch 62/64 loss: 1.7164678573608398
Batch 63/64 loss: 1.8043084144592285
Batch 64/64 loss: -1.495377540588379
Epoch 140  Train loss: 1.8461972816317689  Val loss: 1.6288028271337556
Epoch 141
-------------------------------
Batch 1/64 loss: 1.765315055847168
Batch 2/64 loss: 1.8895740509033203
Batch 3/64 loss: 1.7825636863708496
Batch 4/64 loss: 1.7741212844848633
Batch 5/64 loss: 2.055119514465332
Batch 6/64 loss: 1.8978328704833984
Batch 7/64 loss: 1.8656940460205078
Batch 8/64 loss: 2.1375160217285156
Batch 9/64 loss: 1.7384247779846191
Batch 10/64 loss: 1.9264044761657715
Batch 11/64 loss: 1.844395637512207
Batch 12/64 loss: 1.794450283050537
Batch 13/64 loss: 1.9182243347167969
Batch 14/64 loss: 1.87282133102417
Batch 15/64 loss: 1.8813271522521973
Batch 16/64 loss: 1.8645234107971191
Batch 17/64 loss: 1.764312744140625
Batch 18/64 loss: 1.7834711074829102
Batch 19/64 loss: 1.9693293571472168
Batch 20/64 loss: 1.7941679954528809
Batch 21/64 loss: 1.8523292541503906
Batch 22/64 loss: 1.9031124114990234
Batch 23/64 loss: 2.062854766845703
Batch 24/64 loss: 2.0126724243164062
Batch 25/64 loss: 1.8102631568908691
Batch 26/64 loss: 1.7957158088684082
Batch 27/64 loss: 2.1109819412231445
Batch 28/64 loss: 1.9396514892578125
Batch 29/64 loss: 2.0377068519592285
Batch 30/64 loss: 1.8413491249084473
Batch 31/64 loss: 1.7218480110168457
Batch 32/64 loss: 1.9110822677612305
Batch 33/64 loss: 1.8140864372253418
Batch 34/64 loss: 1.815803050994873
Batch 35/64 loss: 2.143871784210205
Batch 36/64 loss: 1.7779240608215332
Batch 37/64 loss: 1.7711710929870605
Batch 38/64 loss: 1.919848918914795
Batch 39/64 loss: 2.0027170181274414
Batch 40/64 loss: 1.8048043251037598
Batch 41/64 loss: 2.0288476943969727
Batch 42/64 loss: 2.1874442100524902
Batch 43/64 loss: 1.8088035583496094
Batch 44/64 loss: 1.9226655960083008
Batch 45/64 loss: 2.022113800048828
Batch 46/64 loss: 1.7144737243652344
Batch 47/64 loss: 1.8828482627868652
Batch 48/64 loss: 1.7856040000915527
Batch 49/64 loss: 1.8254528045654297
Batch 50/64 loss: 2.043612480163574
Batch 51/64 loss: 1.877645492553711
Batch 52/64 loss: 1.8304433822631836
Batch 53/64 loss: 1.8279118537902832
Batch 54/64 loss: 1.763279914855957
Batch 55/64 loss: 1.720041275024414
Batch 56/64 loss: 1.745500087738037
Batch 57/64 loss: 1.760972499847412
Batch 58/64 loss: 1.811936855316162
Batch 59/64 loss: 1.8099913597106934
Batch 60/64 loss: 1.7322206497192383
Batch 61/64 loss: 1.7560853958129883
Batch 62/64 loss: 1.8471503257751465
Batch 63/64 loss: 1.8273754119873047
Batch 64/64 loss: -1.3679146766662598
Epoch 141  Train loss: 1.8333469484366622  Val loss: 1.548457935503668
Saving best model, epoch: 141
Epoch 142
-------------------------------
Batch 1/64 loss: 1.7335658073425293
Batch 2/64 loss: 1.916482925415039
Batch 3/64 loss: 1.8050589561462402
Batch 4/64 loss: 1.8638300895690918
Batch 5/64 loss: 1.718592643737793
Batch 6/64 loss: 1.9051523208618164
Batch 7/64 loss: 1.8296236991882324
Batch 8/64 loss: 1.8738126754760742
Batch 9/64 loss: 1.7533273696899414
Batch 10/64 loss: 1.8301348686218262
Batch 11/64 loss: 1.7523956298828125
Batch 12/64 loss: 1.877516269683838
Batch 13/64 loss: 1.8871726989746094
Batch 14/64 loss: 1.8929486274719238
Batch 15/64 loss: 1.768618106842041
Batch 16/64 loss: 1.995302677154541
Batch 17/64 loss: 1.9986886978149414
Batch 18/64 loss: 1.8646697998046875
Batch 19/64 loss: 1.7393836975097656
Batch 20/64 loss: 1.6515064239501953
Batch 21/64 loss: 1.640049934387207
Batch 22/64 loss: 1.716294765472412
Batch 23/64 loss: 1.6978659629821777
Batch 24/64 loss: 1.8919930458068848
Batch 25/64 loss: 1.8439698219299316
Batch 26/64 loss: 1.8311562538146973
Batch 27/64 loss: 1.745157241821289
Batch 28/64 loss: 1.861288070678711
Batch 29/64 loss: 1.6826910972595215
Batch 30/64 loss: 1.961334228515625
Batch 31/64 loss: 1.8176789283752441
Batch 32/64 loss: 1.9459528923034668
Batch 33/64 loss: 1.8678646087646484
Batch 34/64 loss: 2.1536731719970703
Batch 35/64 loss: 1.7728500366210938
Batch 36/64 loss: 1.8361058235168457
Batch 37/64 loss: 1.725170612335205
Batch 38/64 loss: 1.7570338249206543
Batch 39/64 loss: 1.94842529296875
Batch 40/64 loss: 1.8350377082824707
Batch 41/64 loss: 2.0248827934265137
Batch 42/64 loss: 1.9299263954162598
Batch 43/64 loss: 1.9787864685058594
Batch 44/64 loss: 1.783003807067871
Batch 45/64 loss: 2.0070343017578125
Batch 46/64 loss: 1.912118911743164
Batch 47/64 loss: 1.7683334350585938
Batch 48/64 loss: 1.8544507026672363
Batch 49/64 loss: 1.7035341262817383
Batch 50/64 loss: 1.8243098258972168
Batch 51/64 loss: 1.6901135444641113
Batch 52/64 loss: 1.7557086944580078
Batch 53/64 loss: 1.8363847732543945
Batch 54/64 loss: 1.8958420753479004
Batch 55/64 loss: 1.987809658050537
Batch 56/64 loss: 1.9032812118530273
Batch 57/64 loss: 1.7975859642028809
Batch 58/64 loss: 1.8553457260131836
Batch 59/64 loss: 1.7507762908935547
Batch 60/64 loss: 1.777364730834961
Batch 61/64 loss: 1.8529200553894043
Batch 62/64 loss: 1.8590259552001953
Batch 63/64 loss: 1.7901897430419922
Batch 64/64 loss: -1.4352436065673828
Epoch 142  Train loss: 1.7984576281379252  Val loss: 1.6941213902738905
Epoch 143
-------------------------------
Batch 1/64 loss: 1.8817977905273438
Batch 2/64 loss: 1.8898534774780273
Batch 3/64 loss: 1.8698596954345703
Batch 4/64 loss: 1.7614412307739258
Batch 5/64 loss: 1.9344978332519531
Batch 6/64 loss: 1.8658957481384277
Batch 7/64 loss: 2.003530979156494
Batch 8/64 loss: 1.9655675888061523
Batch 9/64 loss: 1.8753108978271484
Batch 10/64 loss: 1.8089103698730469
Batch 11/64 loss: 1.9485578536987305
Batch 12/64 loss: 2.8740968704223633
Batch 13/64 loss: 2.203794479370117
Batch 14/64 loss: 2.0640134811401367
Batch 15/64 loss: 2.053351879119873
Batch 16/64 loss: 1.871516227722168
Batch 17/64 loss: 2.215907096862793
Batch 18/64 loss: 1.7826557159423828
Batch 19/64 loss: 1.8909988403320312
Batch 20/64 loss: 1.70989990234375
Batch 21/64 loss: 1.9053912162780762
Batch 22/64 loss: 2.067671298980713
Batch 23/64 loss: 2.0341086387634277
Batch 24/64 loss: 2.1058144569396973
Batch 25/64 loss: 1.8771028518676758
Batch 26/64 loss: 1.8128066062927246
Batch 27/64 loss: 1.932323932647705
Batch 28/64 loss: 1.8175110816955566
Batch 29/64 loss: 1.8543763160705566
Batch 30/64 loss: 2.008420944213867
Batch 31/64 loss: 1.889078140258789
Batch 32/64 loss: 1.751558780670166
Batch 33/64 loss: 1.8523650169372559
Batch 34/64 loss: 1.7809867858886719
Batch 35/64 loss: 1.9470977783203125
Batch 36/64 loss: 1.869422435760498
Batch 37/64 loss: 1.7751412391662598
Batch 38/64 loss: 1.9099125862121582
Batch 39/64 loss: 2.000068187713623
Batch 40/64 loss: 1.9690723419189453
Batch 41/64 loss: 1.839773178100586
Batch 42/64 loss: 2.021312713623047
Batch 43/64 loss: 1.795283317565918
Batch 44/64 loss: 1.9787354469299316
Batch 45/64 loss: 1.7964367866516113
Batch 46/64 loss: 1.8804926872253418
Batch 47/64 loss: 1.8660778999328613
Batch 48/64 loss: 1.9223198890686035
Batch 49/64 loss: 1.9357614517211914
Batch 50/64 loss: 1.9987821578979492
Batch 51/64 loss: 1.8701038360595703
Batch 52/64 loss: 1.7473840713500977
Batch 53/64 loss: 1.7590627670288086
Batch 54/64 loss: 1.8459444046020508
Batch 55/64 loss: 1.8472099304199219
Batch 56/64 loss: 1.8561534881591797
Batch 57/64 loss: 1.7220039367675781
Batch 58/64 loss: 1.8279404640197754
Batch 59/64 loss: 1.819016456604004
Batch 60/64 loss: 1.8934788703918457
Batch 61/64 loss: 1.794084072113037
Batch 62/64 loss: 1.7952346801757812
Batch 63/64 loss: 1.713888168334961
Batch 64/64 loss: -1.4324302673339844
Epoch 143  Train loss: 1.8679819069656671  Val loss: 1.6508768284853381
Epoch 144
-------------------------------
Batch 1/64 loss: 2.0161914825439453
Batch 2/64 loss: 1.7788028717041016
Batch 3/64 loss: 2.1566052436828613
Batch 4/64 loss: 1.9613776206970215
Batch 5/64 loss: 1.8097515106201172
Batch 6/64 loss: 1.9516291618347168
Batch 7/64 loss: 1.8831119537353516
Batch 8/64 loss: 1.9043512344360352
Batch 9/64 loss: 1.983008861541748
Batch 10/64 loss: 1.7509794235229492
Batch 11/64 loss: 1.996964931488037
Batch 12/64 loss: 1.8913674354553223
Batch 13/64 loss: 1.832077980041504
Batch 14/64 loss: 2.140829563140869
Batch 15/64 loss: 1.9160008430480957
Batch 16/64 loss: 2.0245347023010254
Batch 17/64 loss: 1.8599352836608887
Batch 18/64 loss: 1.8389244079589844
Batch 19/64 loss: 2.010806083679199
Batch 20/64 loss: 1.883382797241211
Batch 21/64 loss: 1.7514362335205078
Batch 22/64 loss: 1.7764592170715332
Batch 23/64 loss: 2.2194409370422363
Batch 24/64 loss: 1.8269424438476562
Batch 25/64 loss: 1.9143261909484863
Batch 26/64 loss: 2.2949695587158203
Batch 27/64 loss: 1.803046703338623
Batch 28/64 loss: 1.9139976501464844
Batch 29/64 loss: 1.7003507614135742
Batch 30/64 loss: 1.9388809204101562
Batch 31/64 loss: 1.8239383697509766
Batch 32/64 loss: 1.7360243797302246
Batch 33/64 loss: 1.8303070068359375
Batch 34/64 loss: 1.7134461402893066
Batch 35/64 loss: 1.8433547019958496
Batch 36/64 loss: 1.8333168029785156
Batch 37/64 loss: 1.8931684494018555
Batch 38/64 loss: 1.7750182151794434
Batch 39/64 loss: 1.8952102661132812
Batch 40/64 loss: 1.7331209182739258
Batch 41/64 loss: 1.6343989372253418
Batch 42/64 loss: 1.931753158569336
Batch 43/64 loss: 1.862523078918457
Batch 44/64 loss: 1.9492912292480469
Batch 45/64 loss: 1.6930112838745117
Batch 46/64 loss: 1.8696355819702148
Batch 47/64 loss: 1.7380423545837402
Batch 48/64 loss: 1.8134374618530273
Batch 49/64 loss: 1.825777530670166
Batch 50/64 loss: 1.832963466644287
Batch 51/64 loss: 1.9434709548950195
Batch 52/64 loss: 1.8063812255859375
Batch 53/64 loss: 1.9201226234436035
Batch 54/64 loss: 1.9358158111572266
Batch 55/64 loss: 1.6803374290466309
Batch 56/64 loss: 1.992300033569336
Batch 57/64 loss: 1.8248977661132812
Batch 58/64 loss: 1.8019709587097168
Batch 59/64 loss: 2.016221046447754
Batch 60/64 loss: 1.826333999633789
Batch 61/64 loss: 1.670302391052246
Batch 62/64 loss: 1.9353055953979492
Batch 63/64 loss: 1.6748895645141602
Batch 64/64 loss: -1.6087613105773926
Epoch 144  Train loss: 1.8318431648553586  Val loss: 1.6003256073522405
Epoch 145
-------------------------------
Batch 1/64 loss: 1.8708248138427734
Batch 2/64 loss: 1.968604564666748
Batch 3/64 loss: 1.8099913597106934
Batch 4/64 loss: 1.885857105255127
Batch 5/64 loss: 1.7595505714416504
Batch 6/64 loss: 1.6129140853881836
Batch 7/64 loss: 1.7297415733337402
Batch 8/64 loss: 1.9553627967834473
Batch 9/64 loss: 1.622828483581543
Batch 10/64 loss: 1.6970429420471191
Batch 11/64 loss: 1.6580042839050293
Batch 12/64 loss: 1.6676793098449707
Batch 13/64 loss: 1.7700014114379883
Batch 14/64 loss: 1.7396965026855469
Batch 15/64 loss: 1.8814811706542969
Batch 16/64 loss: 1.7933006286621094
Batch 17/64 loss: 1.9186458587646484
Batch 18/64 loss: 1.9580864906311035
Batch 19/64 loss: 1.6820459365844727
Batch 20/64 loss: 1.6867036819458008
Batch 21/64 loss: 1.7409815788269043
Batch 22/64 loss: 1.9826745986938477
Batch 23/64 loss: 1.9106941223144531
Batch 24/64 loss: 1.878908634185791
Batch 25/64 loss: 1.7544317245483398
Batch 26/64 loss: 1.9700055122375488
Batch 27/64 loss: 1.7394952774047852
Batch 28/64 loss: 1.7567048072814941
Batch 29/64 loss: 1.8507461547851562
Batch 30/64 loss: 1.8691673278808594
Batch 31/64 loss: 1.7919607162475586
Batch 32/64 loss: 1.8856048583984375
Batch 33/64 loss: 1.7243647575378418
Batch 34/64 loss: 1.6716070175170898
Batch 35/64 loss: 1.8168301582336426
Batch 36/64 loss: 1.841094970703125
Batch 37/64 loss: 1.8804492950439453
Batch 38/64 loss: 1.9578337669372559
Batch 39/64 loss: 1.899393081665039
Batch 40/64 loss: 1.8728923797607422
Batch 41/64 loss: 1.9035534858703613
Batch 42/64 loss: 1.8571429252624512
Batch 43/64 loss: 1.76751708984375
Batch 44/64 loss: 1.937103271484375
Batch 45/64 loss: 1.778280258178711
Batch 46/64 loss: 1.747504711151123
Batch 47/64 loss: 1.8924083709716797
Batch 48/64 loss: 1.9441404342651367
Batch 49/64 loss: 1.8158187866210938
Batch 50/64 loss: 1.841982364654541
Batch 51/64 loss: 1.880422592163086
Batch 52/64 loss: 1.7465920448303223
Batch 53/64 loss: 1.8514046669006348
Batch 54/64 loss: 1.7831354141235352
Batch 55/64 loss: 1.9717044830322266
Batch 56/64 loss: 1.7870407104492188
Batch 57/64 loss: 1.8546099662780762
Batch 58/64 loss: 2.060892105102539
Batch 59/64 loss: 2.16925048828125
Batch 60/64 loss: 1.9993653297424316
Batch 61/64 loss: 1.8396496772766113
Batch 62/64 loss: 1.8119926452636719
Batch 63/64 loss: 1.902200698852539
Batch 64/64 loss: -1.2719950675964355
Epoch 145  Train loss: 1.7984928710787904  Val loss: 1.6182862770106785
Epoch 146
-------------------------------
Batch 1/64 loss: 1.84553861618042
Batch 2/64 loss: 1.7913398742675781
Batch 3/64 loss: 2.0088791847229004
Batch 4/64 loss: 1.8313169479370117
Batch 5/64 loss: 2.0500102043151855
Batch 6/64 loss: 1.8426737785339355
Batch 7/64 loss: 1.7197656631469727
Batch 8/64 loss: 1.8815793991088867
Batch 9/64 loss: 1.8205394744873047
Batch 10/64 loss: 1.8798365592956543
Batch 11/64 loss: 1.775538444519043
Batch 12/64 loss: 1.7599396705627441
Batch 13/64 loss: 1.732863426208496
Batch 14/64 loss: 1.7106542587280273
Batch 15/64 loss: 2.013296127319336
Batch 16/64 loss: 2.317363739013672
Batch 17/64 loss: 2.158297061920166
Batch 18/64 loss: 2.0122909545898438
Batch 19/64 loss: 1.7295751571655273
Batch 20/64 loss: 1.7006220817565918
Batch 21/64 loss: 1.9552106857299805
Batch 22/64 loss: 1.8242568969726562
Batch 23/64 loss: 2.0132431983947754
Batch 24/64 loss: 1.9651250839233398
Batch 25/64 loss: 1.764479160308838
Batch 26/64 loss: 1.797579288482666
Batch 27/64 loss: 1.7967205047607422
Batch 28/64 loss: 1.9721784591674805
Batch 29/64 loss: 1.8499469757080078
Batch 30/64 loss: 1.776899814605713
Batch 31/64 loss: 1.8316082954406738
Batch 32/64 loss: 1.6891732215881348
Batch 33/64 loss: 1.952263355255127
Batch 34/64 loss: 1.9506683349609375
Batch 35/64 loss: 2.0088367462158203
Batch 36/64 loss: 2.0222830772399902
Batch 37/64 loss: 1.8597826957702637
Batch 38/64 loss: 1.818333625793457
Batch 39/64 loss: 1.8302173614501953
Batch 40/64 loss: 1.7173967361450195
Batch 41/64 loss: 1.7174124717712402
Batch 42/64 loss: 1.8329615592956543
Batch 43/64 loss: 1.7710175514221191
Batch 44/64 loss: 1.81752347946167
Batch 45/64 loss: 1.675765037536621
Batch 46/64 loss: 1.711550235748291
Batch 47/64 loss: 2.0983457565307617
Batch 48/64 loss: 1.7787647247314453
Batch 49/64 loss: 1.772993564605713
Batch 50/64 loss: 1.7684125900268555
Batch 51/64 loss: 1.7635893821716309
Batch 52/64 loss: 1.798306941986084
Batch 53/64 loss: 1.851224422454834
Batch 54/64 loss: 1.9615211486816406
Batch 55/64 loss: 1.8834104537963867
Batch 56/64 loss: 1.8241333961486816
Batch 57/64 loss: 2.0842208862304688
Batch 58/64 loss: 1.7825894355773926
Batch 59/64 loss: 1.8691706657409668
Batch 60/64 loss: 1.7717151641845703
Batch 61/64 loss: 1.9333252906799316
Batch 62/64 loss: 1.7915682792663574
Batch 63/64 loss: 1.7164998054504395
Batch 64/64 loss: -1.5421934127807617
Epoch 146  Train loss: 1.8164313933428595  Val loss: 1.6110016537695815
Epoch 147
-------------------------------
Batch 1/64 loss: 1.8681201934814453
Batch 2/64 loss: 1.6723065376281738
Batch 3/64 loss: 1.7305569648742676
Batch 4/64 loss: 1.9174094200134277
Batch 5/64 loss: 1.8347225189208984
Batch 6/64 loss: 1.923635482788086
Batch 7/64 loss: 1.8848843574523926
Batch 8/64 loss: 1.9260988235473633
Batch 9/64 loss: 1.8901429176330566
Batch 10/64 loss: 1.815025806427002
Batch 11/64 loss: 1.7773594856262207
Batch 12/64 loss: 1.7389516830444336
Batch 13/64 loss: 1.9712862968444824
Batch 14/64 loss: 1.8071479797363281
Batch 15/64 loss: 1.8509564399719238
Batch 16/64 loss: 1.8133740425109863
Batch 17/64 loss: 1.6759600639343262
Batch 18/64 loss: 1.682396411895752
Batch 19/64 loss: 1.888643741607666
Batch 20/64 loss: 1.7354931831359863
Batch 21/64 loss: 1.7299914360046387
Batch 22/64 loss: 1.676447868347168
Batch 23/64 loss: 1.7512454986572266
Batch 24/64 loss: 2.253767967224121
Batch 25/64 loss: 1.8564186096191406
Batch 26/64 loss: 1.7564191818237305
Batch 27/64 loss: 1.8182225227355957
Batch 28/64 loss: 1.8527836799621582
Batch 29/64 loss: 1.7757492065429688
Batch 30/64 loss: 1.6813082695007324
Batch 31/64 loss: 1.840959072113037
Batch 32/64 loss: 1.7574048042297363
Batch 33/64 loss: 1.9736099243164062
Batch 34/64 loss: 1.710324764251709
Batch 35/64 loss: 1.7351951599121094
Batch 36/64 loss: 1.8282876014709473
Batch 37/64 loss: 1.7263975143432617
Batch 38/64 loss: 1.8901996612548828
Batch 39/64 loss: 1.774820327758789
Batch 40/64 loss: 1.7428712844848633
Batch 41/64 loss: 1.7946701049804688
Batch 42/64 loss: 1.7521824836730957
Batch 43/64 loss: 1.8258051872253418
Batch 44/64 loss: 1.953000545501709
Batch 45/64 loss: 1.8577380180358887
Batch 46/64 loss: 1.8417024612426758
Batch 47/64 loss: 1.8775320053100586
Batch 48/64 loss: 1.7410192489624023
Batch 49/64 loss: 1.669321060180664
Batch 50/64 loss: 1.663299560546875
Batch 51/64 loss: 1.8256969451904297
Batch 52/64 loss: 1.8219242095947266
Batch 53/64 loss: 1.9772319793701172
Batch 54/64 loss: 1.8045668601989746
Batch 55/64 loss: 1.6804800033569336
Batch 56/64 loss: 1.8812074661254883
Batch 57/64 loss: 1.8443679809570312
Batch 58/64 loss: 1.7909207344055176
Batch 59/64 loss: 1.6483092308044434
Batch 60/64 loss: 1.8063688278198242
Batch 61/64 loss: 1.7330527305603027
Batch 62/64 loss: 1.906050205230713
Batch 63/64 loss: 1.83355712890625
Batch 64/64 loss: -1.6083741188049316
Epoch 147  Train loss: 1.770362683838489  Val loss: 1.5082226389462186
Saving best model, epoch: 147
Epoch 148
-------------------------------
Batch 1/64 loss: 1.7430691719055176
Batch 2/64 loss: 1.86798095703125
Batch 3/64 loss: 1.6719226837158203
Batch 4/64 loss: 1.884871006011963
Batch 5/64 loss: 1.7950043678283691
Batch 6/64 loss: 1.80269193649292
Batch 7/64 loss: 1.725590705871582
Batch 8/64 loss: 1.8016085624694824
Batch 9/64 loss: 1.642549991607666
Batch 10/64 loss: 1.7336969375610352
Batch 11/64 loss: 1.727426528930664
Batch 12/64 loss: 1.7548046112060547
Batch 13/64 loss: 1.8157763481140137
Batch 14/64 loss: 1.8733816146850586
Batch 15/64 loss: 1.8803949356079102
Batch 16/64 loss: 1.7256293296813965
Batch 17/64 loss: 1.8017597198486328
Batch 18/64 loss: 1.8099589347839355
Batch 19/64 loss: 1.705803394317627
Batch 20/64 loss: 1.7831215858459473
Batch 21/64 loss: 1.743105411529541
Batch 22/64 loss: 1.7574939727783203
Batch 23/64 loss: 1.7068185806274414
Batch 24/64 loss: 1.8316936492919922
Batch 25/64 loss: 1.749664306640625
Batch 26/64 loss: 1.759575366973877
Batch 27/64 loss: 1.7754631042480469
Batch 28/64 loss: 1.7249741554260254
Batch 29/64 loss: 1.782893180847168
Batch 30/64 loss: 1.7018213272094727
Batch 31/64 loss: 1.7707605361938477
Batch 32/64 loss: 1.701451301574707
Batch 33/64 loss: 1.6791362762451172
Batch 34/64 loss: 1.7011675834655762
Batch 35/64 loss: 1.7201175689697266
Batch 36/64 loss: 1.8978705406188965
Batch 37/64 loss: 1.857053279876709
Batch 38/64 loss: 1.705878734588623
Batch 39/64 loss: 1.8211979866027832
Batch 40/64 loss: 1.6526899337768555
Batch 41/64 loss: 1.9547138214111328
Batch 42/64 loss: 1.7497763633728027
Batch 43/64 loss: 1.9623475074768066
Batch 44/64 loss: 1.6969666481018066
Batch 45/64 loss: 1.750579833984375
Batch 46/64 loss: 1.712747573852539
Batch 47/64 loss: 2.0625
Batch 48/64 loss: 2.0265417098999023
Batch 49/64 loss: 1.82381010055542
Batch 50/64 loss: 1.8159422874450684
Batch 51/64 loss: 1.7791266441345215
Batch 52/64 loss: 1.7388734817504883
Batch 53/64 loss: 1.65800142288208
Batch 54/64 loss: 1.9203424453735352
Batch 55/64 loss: 1.7345495223999023
Batch 56/64 loss: 1.6660833358764648
Batch 57/64 loss: 1.9681992530822754
Batch 58/64 loss: 1.9218759536743164
Batch 59/64 loss: 1.913520336151123
Batch 60/64 loss: 1.7765231132507324
Batch 61/64 loss: 1.7472820281982422
Batch 62/64 loss: 1.8451719284057617
Batch 63/64 loss: 1.8906970024108887
Batch 64/64 loss: -1.5039677619934082
Epoch 148  Train loss: 1.7502128096187817  Val loss: 1.570031805136769
Epoch 149
-------------------------------
Batch 1/64 loss: 1.7777762413024902
Batch 2/64 loss: 1.7782435417175293
Batch 3/64 loss: 1.708899974822998
Batch 4/64 loss: 1.7887201309204102
Batch 5/64 loss: 1.7412452697753906
Batch 6/64 loss: 1.7135357856750488
Batch 7/64 loss: 1.7808198928833008
Batch 8/64 loss: 1.695054054260254
Batch 9/64 loss: 1.9521141052246094
Batch 10/64 loss: 1.9823899269104004
Batch 11/64 loss: 1.9097223281860352
Batch 12/64 loss: 1.7604904174804688
Batch 13/64 loss: 1.7596492767333984
Batch 14/64 loss: 1.948336124420166
Batch 15/64 loss: 2.014130115509033
Batch 16/64 loss: 1.8562736511230469
Batch 17/64 loss: 1.7885308265686035
Batch 18/64 loss: 1.7984929084777832
Batch 19/64 loss: 1.845724105834961
Batch 20/64 loss: 1.9241328239440918
Batch 21/64 loss: 1.758204460144043
Batch 22/64 loss: 1.8214154243469238
Batch 23/64 loss: 1.6295232772827148
Batch 24/64 loss: 1.8196496963500977
Batch 25/64 loss: 1.8004159927368164
Batch 26/64 loss: 1.8339834213256836
Batch 27/64 loss: 1.7442216873168945
Batch 28/64 loss: 1.8002204895019531
Batch 29/64 loss: 1.8837614059448242
Batch 30/64 loss: 1.7932524681091309
Batch 31/64 loss: 1.7391180992126465
Batch 32/64 loss: 1.9953150749206543
Batch 33/64 loss: 1.9550175666809082
Batch 34/64 loss: 1.7021794319152832
Batch 35/64 loss: 1.811978816986084
Batch 36/64 loss: 1.638267993927002
Batch 37/64 loss: 1.710474967956543
Batch 38/64 loss: 1.753713607788086
Batch 39/64 loss: 1.7664508819580078
Batch 40/64 loss: 1.7842211723327637
Batch 41/64 loss: 1.8761849403381348
Batch 42/64 loss: 1.7960844039916992
Batch 43/64 loss: 1.959083080291748
Batch 44/64 loss: 1.8153939247131348
Batch 45/64 loss: 1.872307300567627
Batch 46/64 loss: 1.71453857421875
Batch 47/64 loss: 1.7679963111877441
Batch 48/64 loss: 1.8947696685791016
Batch 49/64 loss: 1.8520359992980957
Batch 50/64 loss: 1.9082756042480469
Batch 51/64 loss: 1.831127643585205
Batch 52/64 loss: 1.8028697967529297
Batch 53/64 loss: 1.790539264678955
Batch 54/64 loss: 1.72283935546875
Batch 55/64 loss: 1.729903221130371
Batch 56/64 loss: 1.7104649543762207
Batch 57/64 loss: 1.9464726448059082
Batch 58/64 loss: 2.0017552375793457
Batch 59/64 loss: 1.7343330383300781
Batch 60/64 loss: 1.700063705444336
Batch 61/64 loss: 2.146516799926758
Batch 62/64 loss: 1.8114194869995117
Batch 63/64 loss: 1.8361754417419434
Batch 64/64 loss: -1.5481758117675781
Epoch 149  Train loss: 1.7776578192617378  Val loss: 1.5690675191453232
Epoch 150
-------------------------------
Batch 1/64 loss: 1.7104167938232422
Batch 2/64 loss: 1.6829838752746582
Batch 3/64 loss: 1.767822265625
Batch 4/64 loss: 1.889915943145752
Batch 5/64 loss: 2.0428123474121094
Batch 6/64 loss: 1.6672945022583008
Batch 7/64 loss: 1.774080753326416
Batch 8/64 loss: 1.8609213829040527
Batch 9/64 loss: 1.8198800086975098
Batch 10/64 loss: 1.9664044380187988
Batch 11/64 loss: 1.7778496742248535
Batch 12/64 loss: 1.656209945678711
Batch 13/64 loss: 1.8653759956359863
Batch 14/64 loss: 1.6995611190795898
Batch 15/64 loss: 1.9381890296936035
Batch 16/64 loss: 1.679865837097168
Batch 17/64 loss: 1.9905524253845215
Batch 18/64 loss: 1.881866455078125
Batch 19/64 loss: 1.7830119132995605
Batch 20/64 loss: 2.2082252502441406
Batch 21/64 loss: 2.115910530090332
Batch 22/64 loss: 1.9627890586853027
Batch 23/64 loss: 1.804863452911377
Batch 24/64 loss: 1.8727688789367676
Batch 25/64 loss: 1.8043036460876465
Batch 26/64 loss: 1.8434686660766602
Batch 27/64 loss: 1.7419228553771973
Batch 28/64 loss: 1.857017993927002
Batch 29/64 loss: 1.7666611671447754
Batch 30/64 loss: 1.7902531623840332
Batch 31/64 loss: 2.070322036743164
Batch 32/64 loss: 1.7319893836975098
Batch 33/64 loss: 2.120852470397949
Batch 34/64 loss: 1.7809977531433105
Batch 35/64 loss: 1.8461523056030273
Batch 36/64 loss: 1.8325104713439941
Batch 37/64 loss: 1.6778459548950195
Batch 38/64 loss: 1.7248320579528809
Batch 39/64 loss: 1.6707115173339844
Batch 40/64 loss: 1.7426409721374512
Batch 41/64 loss: 1.8494110107421875
Batch 42/64 loss: 1.756927490234375
Batch 43/64 loss: 1.731764316558838
Batch 44/64 loss: 1.81972074508667
Batch 45/64 loss: 1.8335785865783691
Batch 46/64 loss: 1.7887811660766602
Batch 47/64 loss: 1.821897029876709
Batch 48/64 loss: 1.8507380485534668
Batch 49/64 loss: 1.801093578338623
Batch 50/64 loss: 1.8952131271362305
Batch 51/64 loss: 1.880408763885498
Batch 52/64 loss: 1.6869282722473145
Batch 53/64 loss: 1.8424310684204102
Batch 54/64 loss: 1.7448124885559082
Batch 55/64 loss: 1.6232032775878906
Batch 56/64 loss: 1.6371574401855469
Batch 57/64 loss: 1.7145981788635254
Batch 58/64 loss: 1.7216973304748535
Batch 59/64 loss: 1.792311191558838
Batch 60/64 loss: 1.6872625350952148
Batch 61/64 loss: 1.911085605621338
Batch 62/64 loss: 1.6722869873046875
Batch 63/64 loss: 1.9661383628845215
Batch 64/64 loss: -1.4218854904174805
Epoch 150  Train loss: 1.7785895964678595  Val loss: 1.5732984378985113
Epoch 151
-------------------------------
Batch 1/64 loss: 1.6660056114196777
Batch 2/64 loss: 1.8453984260559082
Batch 3/64 loss: 2.067200183868408
Batch 4/64 loss: 1.9738507270812988
Batch 5/64 loss: 1.780116081237793
Batch 6/64 loss: 1.7866649627685547
Batch 7/64 loss: 1.8106780052185059
Batch 8/64 loss: 1.5751056671142578
Batch 9/64 loss: 1.6845240592956543
Batch 10/64 loss: 1.654249668121338
Batch 11/64 loss: 1.7597603797912598
Batch 12/64 loss: 1.870682716369629
Batch 13/64 loss: 1.868506908416748
Batch 14/64 loss: 1.8628196716308594
Batch 15/64 loss: 1.9073262214660645
Batch 16/64 loss: 1.7607483863830566
Batch 17/64 loss: 1.8208398818969727
Batch 18/64 loss: 1.9649744033813477
Batch 19/64 loss: 1.8162035942077637
Batch 20/64 loss: 1.8089518547058105
Batch 21/64 loss: 1.9017014503479004
Batch 22/64 loss: 1.9389433860778809
Batch 23/64 loss: 1.9305305480957031
Batch 24/64 loss: 1.79365873336792
Batch 25/64 loss: 1.7860918045043945
Batch 26/64 loss: 1.7348546981811523
Batch 27/64 loss: 1.8555965423583984
Batch 28/64 loss: 1.9414567947387695
Batch 29/64 loss: 1.752610206604004
Batch 30/64 loss: 1.7640786170959473
Batch 31/64 loss: 1.7450141906738281
Batch 32/64 loss: 1.8544549942016602
Batch 33/64 loss: 1.817464828491211
Batch 34/64 loss: 1.787961483001709
Batch 35/64 loss: 1.7439823150634766
Batch 36/64 loss: 1.9431777000427246
Batch 37/64 loss: 1.714742660522461
Batch 38/64 loss: 1.8022947311401367
Batch 39/64 loss: 1.7865605354309082
Batch 40/64 loss: 1.7972745895385742
Batch 41/64 loss: 2.0374884605407715
Batch 42/64 loss: 1.7805242538452148
Batch 43/64 loss: 1.8069186210632324
Batch 44/64 loss: 1.731989860534668
Batch 45/64 loss: 1.9869122505187988
Batch 46/64 loss: 1.718700885772705
Batch 47/64 loss: 1.7033357620239258
Batch 48/64 loss: 1.936957836151123
Batch 49/64 loss: 1.8198003768920898
Batch 50/64 loss: 1.6855368614196777
Batch 51/64 loss: 1.7814898490905762
Batch 52/64 loss: 1.7493395805358887
Batch 53/64 loss: 1.9501018524169922
Batch 54/64 loss: 1.8620805740356445
Batch 55/64 loss: 1.8129901885986328
Batch 56/64 loss: 1.6300978660583496
Batch 57/64 loss: 1.6756706237792969
Batch 58/64 loss: 1.773024559020996
Batch 59/64 loss: 1.6705074310302734
Batch 60/64 loss: 1.6328701972961426
Batch 61/64 loss: 1.738215446472168
Batch 62/64 loss: 2.087902545928955
Batch 63/64 loss: 1.799799919128418
Batch 64/64 loss: -1.4653348922729492
Epoch 151  Train loss: 1.7717696133781882  Val loss: 1.5189196072083568
Epoch 152
-------------------------------
Batch 1/64 loss: 1.809697151184082
Batch 2/64 loss: 1.8298940658569336
Batch 3/64 loss: 1.7628517150878906
Batch 4/64 loss: 1.671393871307373
Batch 5/64 loss: 1.7778840065002441
Batch 6/64 loss: 1.8258519172668457
Batch 7/64 loss: 1.729294776916504
Batch 8/64 loss: 1.7159795761108398
Batch 9/64 loss: 2.16788387298584
Batch 10/64 loss: 1.873415470123291
Batch 11/64 loss: 1.7214531898498535
Batch 12/64 loss: 1.7210659980773926
Batch 13/64 loss: 1.8030662536621094
Batch 14/64 loss: 1.7939414978027344
Batch 15/64 loss: 1.7645153999328613
Batch 16/64 loss: 1.7340173721313477
Batch 17/64 loss: 1.8004155158996582
Batch 18/64 loss: 1.76104736328125
Batch 19/64 loss: 1.9016814231872559
Batch 20/64 loss: 1.9616661071777344
Batch 21/64 loss: 1.810567855834961
Batch 22/64 loss: 1.8071913719177246
Batch 23/64 loss: 1.7330036163330078
Batch 24/64 loss: 1.741590976715088
Batch 25/64 loss: 1.8143882751464844
Batch 26/64 loss: 1.8733110427856445
Batch 27/64 loss: 2.01893949508667
Batch 28/64 loss: 1.6682219505310059
Batch 29/64 loss: 2.167398452758789
Batch 30/64 loss: 1.8911128044128418
Batch 31/64 loss: 1.7349767684936523
Batch 32/64 loss: 1.675384521484375
Batch 33/64 loss: 1.8460850715637207
Batch 34/64 loss: 1.688868522644043
Batch 35/64 loss: 1.7446203231811523
Batch 36/64 loss: 1.7699298858642578
Batch 37/64 loss: 1.7831578254699707
Batch 38/64 loss: 1.7461786270141602
Batch 39/64 loss: 1.8271551132202148
Batch 40/64 loss: 1.8095006942749023
Batch 41/64 loss: 1.6745333671569824
Batch 42/64 loss: 1.7014694213867188
Batch 43/64 loss: 1.651839256286621
Batch 44/64 loss: 1.6384916305541992
Batch 45/64 loss: 1.8561763763427734
Batch 46/64 loss: 1.6444802284240723
Batch 47/64 loss: 1.9976081848144531
Batch 48/64 loss: 1.8013849258422852
Batch 49/64 loss: 1.7389788627624512
Batch 50/64 loss: 1.6668777465820312
Batch 51/64 loss: 1.7811236381530762
Batch 52/64 loss: 1.568608283996582
Batch 53/64 loss: 1.7941036224365234
Batch 54/64 loss: 1.891294002532959
Batch 55/64 loss: 1.8501191139221191
Batch 56/64 loss: 1.8588752746582031
Batch 57/64 loss: 2.0174713134765625
Batch 58/64 loss: 1.7626276016235352
Batch 59/64 loss: 1.7875289916992188
Batch 60/64 loss: 1.9198684692382812
Batch 61/64 loss: 1.8857026100158691
Batch 62/64 loss: 1.7928767204284668
Batch 63/64 loss: 1.7227468490600586
Batch 64/64 loss: -1.5997276306152344
Epoch 152  Train loss: 1.758173968745213  Val loss: 1.5271502229356275
Epoch 153
-------------------------------
Batch 1/64 loss: 1.8632607460021973
Batch 2/64 loss: 2.0210185050964355
Batch 3/64 loss: 1.8023395538330078
Batch 4/64 loss: 1.8091917037963867
Batch 5/64 loss: 1.8051457405090332
Batch 6/64 loss: 1.713362216949463
Batch 7/64 loss: 1.9588203430175781
Batch 8/64 loss: 1.6978936195373535
Batch 9/64 loss: 1.8088388442993164
Batch 10/64 loss: 1.830705165863037
Batch 11/64 loss: 1.648637294769287
Batch 12/64 loss: 1.8142375946044922
Batch 13/64 loss: 2.2995705604553223
Batch 14/64 loss: 1.7826323509216309
Batch 15/64 loss: 1.9023876190185547
Batch 16/64 loss: 1.7993412017822266
Batch 17/64 loss: 2.1755971908569336
Batch 18/64 loss: 1.7278318405151367
Batch 19/64 loss: 1.6416096687316895
Batch 20/64 loss: 1.798814296722412
Batch 21/64 loss: 1.7644219398498535
Batch 22/64 loss: 1.7679986953735352
Batch 23/64 loss: 1.7251567840576172
Batch 24/64 loss: 1.9016032218933105
Batch 25/64 loss: 1.769383430480957
Batch 26/64 loss: 2.0279054641723633
Batch 27/64 loss: 1.7578911781311035
Batch 28/64 loss: 1.6944451332092285
Batch 29/64 loss: 1.9414787292480469
Batch 30/64 loss: 1.8055753707885742
Batch 31/64 loss: 1.7645354270935059
Batch 32/64 loss: 1.6765518188476562
Batch 33/64 loss: 1.7728943824768066
Batch 34/64 loss: 1.8059120178222656
Batch 35/64 loss: 1.8332104682922363
Batch 36/64 loss: 1.6942338943481445
Batch 37/64 loss: 1.7320141792297363
Batch 38/64 loss: 1.690699577331543
Batch 39/64 loss: 1.691728115081787
Batch 40/64 loss: 1.7401199340820312
Batch 41/64 loss: 1.7726893424987793
Batch 42/64 loss: 1.737910270690918
Batch 43/64 loss: 1.7190847396850586
Batch 44/64 loss: 1.8183207511901855
Batch 45/64 loss: 1.7694973945617676
Batch 46/64 loss: 1.6402392387390137
Batch 47/64 loss: 1.608015537261963
Batch 48/64 loss: 1.8371648788452148
Batch 49/64 loss: 1.6275529861450195
Batch 50/64 loss: 1.6476831436157227
Batch 51/64 loss: 1.7775135040283203
Batch 52/64 loss: 1.7406129837036133
Batch 53/64 loss: 1.803128719329834
Batch 54/64 loss: 1.70805025100708
Batch 55/64 loss: 1.871452808380127
Batch 56/64 loss: 2.0937576293945312
Batch 57/64 loss: 1.8729095458984375
Batch 58/64 loss: 1.70269775390625
Batch 59/64 loss: 1.6864824295043945
Batch 60/64 loss: 1.715315341949463
Batch 61/64 loss: 1.7487125396728516
Batch 62/64 loss: 1.843717098236084
Batch 63/64 loss: 1.969569206237793
Batch 64/64 loss: -1.5975346565246582
Epoch 153  Train loss: 1.7564380066067564  Val loss: 1.484081910647887
Saving best model, epoch: 153
Epoch 154
-------------------------------
Batch 1/64 loss: 1.6963019371032715
Batch 2/64 loss: 1.7122831344604492
Batch 3/64 loss: 1.6529531478881836
Batch 4/64 loss: 1.7396411895751953
Batch 5/64 loss: 1.8172259330749512
Batch 6/64 loss: 1.6381573677062988
Batch 7/64 loss: 1.8428683280944824
Batch 8/64 loss: 1.6996512413024902
Batch 9/64 loss: 1.7298274040222168
Batch 10/64 loss: 1.7336196899414062
Batch 11/64 loss: 1.910736083984375
Batch 12/64 loss: 1.747992992401123
Batch 13/64 loss: 1.8822212219238281
Batch 14/64 loss: 1.787703037261963
Batch 15/64 loss: 1.719527244567871
Batch 16/64 loss: 1.8437271118164062
Batch 17/64 loss: 1.6601533889770508
Batch 18/64 loss: 1.6504864692687988
Batch 19/64 loss: 1.7375154495239258
Batch 20/64 loss: 1.7657699584960938
Batch 21/64 loss: 1.8979434967041016
Batch 22/64 loss: 1.8006834983825684
Batch 23/64 loss: 1.6748709678649902
Batch 24/64 loss: 1.8067841529846191
Batch 25/64 loss: 1.6269946098327637
Batch 26/64 loss: 1.763859748840332
Batch 27/64 loss: 1.7565851211547852
Batch 28/64 loss: 1.7473254203796387
Batch 29/64 loss: 1.9207029342651367
Batch 30/64 loss: 2.036290168762207
Batch 31/64 loss: 1.7086739540100098
Batch 32/64 loss: 1.8700079917907715
Batch 33/64 loss: 1.649716854095459
Batch 34/64 loss: 1.903951644897461
Batch 35/64 loss: 1.8938846588134766
Batch 36/64 loss: 1.5797972679138184
Batch 37/64 loss: 1.8620681762695312
Batch 38/64 loss: 1.7444658279418945
Batch 39/64 loss: 1.7236924171447754
Batch 40/64 loss: 2.007779121398926
Batch 41/64 loss: 1.6959924697875977
Batch 42/64 loss: 1.8401126861572266
Batch 43/64 loss: 1.7233901023864746
Batch 44/64 loss: 1.7883644104003906
Batch 45/64 loss: 1.9999651908874512
Batch 46/64 loss: 1.8510770797729492
Batch 47/64 loss: 1.7746996879577637
Batch 48/64 loss: 1.8052291870117188
Batch 49/64 loss: 1.720261573791504
Batch 50/64 loss: 1.9256505966186523
Batch 51/64 loss: 1.78363037109375
Batch 52/64 loss: 2.038926601409912
Batch 53/64 loss: 1.7182235717773438
Batch 54/64 loss: 1.927666187286377
Batch 55/64 loss: 1.685682773590088
Batch 56/64 loss: 1.8277597427368164
Batch 57/64 loss: 1.7294411659240723
Batch 58/64 loss: 1.6766629219055176
Batch 59/64 loss: 1.8021602630615234
Batch 60/64 loss: 1.7095389366149902
Batch 61/64 loss: 1.826307773590088
Batch 62/64 loss: 1.8079628944396973
Batch 63/64 loss: 1.6733322143554688
Batch 64/64 loss: -1.5160446166992188
Epoch 154  Train loss: 1.7433638479195388  Val loss: 1.5098858403995685
Epoch 155
-------------------------------
Batch 1/64 loss: 1.8244752883911133
Batch 2/64 loss: 2.0131287574768066
Batch 3/64 loss: 1.9961094856262207
Batch 4/64 loss: 1.6259374618530273
Batch 5/64 loss: 1.8770866394042969
Batch 6/64 loss: 1.6824126243591309
Batch 7/64 loss: 1.6930418014526367
Batch 8/64 loss: 1.7488760948181152
Batch 9/64 loss: 1.7297635078430176
Batch 10/64 loss: 1.8319892883300781
Batch 11/64 loss: 1.7477631568908691
Batch 12/64 loss: 1.747347354888916
Batch 13/64 loss: 1.7592778205871582
Batch 14/64 loss: 1.875349998474121
Batch 15/64 loss: 1.8076825141906738
Batch 16/64 loss: 1.804832935333252
Batch 17/64 loss: 1.769996166229248
Batch 18/64 loss: 1.687760829925537
Batch 19/64 loss: 1.7789263725280762
Batch 20/64 loss: 1.8424148559570312
Batch 21/64 loss: 1.769155502319336
Batch 22/64 loss: 1.7453351020812988
Batch 23/64 loss: 1.7336220741271973
Batch 24/64 loss: 1.6506714820861816
Batch 25/64 loss: 1.680795669555664
Batch 26/64 loss: 1.7429919242858887
Batch 27/64 loss: 1.7765331268310547
Batch 28/64 loss: 1.8459901809692383
Batch 29/64 loss: 1.856863021850586
Batch 30/64 loss: 1.7860760688781738
Batch 31/64 loss: 1.7945365905761719
Batch 32/64 loss: 1.7686967849731445
Batch 33/64 loss: 1.9358539581298828
Batch 34/64 loss: 1.824770450592041
Batch 35/64 loss: 1.8768939971923828
Batch 36/64 loss: 2.2325472831726074
Batch 37/64 loss: 1.8825101852416992
Batch 38/64 loss: 1.9849853515625
Batch 39/64 loss: 1.8660192489624023
Batch 40/64 loss: 1.845400333404541
Batch 41/64 loss: 1.8253064155578613
Batch 42/64 loss: 1.9489893913269043
Batch 43/64 loss: 1.963423728942871
Batch 44/64 loss: 1.7814521789550781
Batch 45/64 loss: 1.917722225189209
Batch 46/64 loss: 1.7658071517944336
Batch 47/64 loss: 1.8686857223510742
Batch 48/64 loss: 1.9727578163146973
Batch 49/64 loss: 1.9113531112670898
Batch 50/64 loss: 1.7490878105163574
Batch 51/64 loss: 1.8214168548583984
Batch 52/64 loss: 1.778902530670166
Batch 53/64 loss: 1.7547588348388672
Batch 54/64 loss: 1.9239773750305176
Batch 55/64 loss: 1.8294425010681152
Batch 56/64 loss: 2.271994113922119
Batch 57/64 loss: 1.8463325500488281
Batch 58/64 loss: 1.915116310119629
Batch 59/64 loss: 1.9512734413146973
Batch 60/64 loss: 1.633352279663086
Batch 61/64 loss: 1.715761661529541
Batch 62/64 loss: 1.7696666717529297
Batch 63/64 loss: 1.886782169342041
Batch 64/64 loss: -0.9529962539672852
Epoch 155  Train loss: 1.7965966579960841  Val loss: 1.6762949035749404
Epoch 156
-------------------------------
Batch 1/64 loss: 1.8082489967346191
Batch 2/64 loss: 1.8876953125
Batch 3/64 loss: 1.7689805030822754
Batch 4/64 loss: 1.7355284690856934
Batch 5/64 loss: 1.9955196380615234
Batch 6/64 loss: 1.9747943878173828
Batch 7/64 loss: 1.8757762908935547
Batch 8/64 loss: 1.9060935974121094
Batch 9/64 loss: 1.7296171188354492
Batch 10/64 loss: 1.810103416442871
Batch 11/64 loss: 1.8268485069274902
Batch 12/64 loss: 1.9728245735168457
Batch 13/64 loss: 1.9455294609069824
Batch 14/64 loss: 1.9469761848449707
Batch 15/64 loss: 1.9790902137756348
Batch 16/64 loss: 1.7836084365844727
Batch 17/64 loss: 1.7537531852722168
Batch 18/64 loss: 1.7590303421020508
Batch 19/64 loss: 2.187636375427246
Batch 20/64 loss: 1.7619538307189941
Batch 21/64 loss: 1.8927946090698242
Batch 22/64 loss: 1.9531521797180176
Batch 23/64 loss: 2.054900646209717
Batch 24/64 loss: 1.8534908294677734
Batch 25/64 loss: 1.7100062370300293
Batch 26/64 loss: 1.7342143058776855
Batch 27/64 loss: 1.81925630569458
Batch 28/64 loss: 1.9699912071228027
Batch 29/64 loss: 2.0322165489196777
Batch 30/64 loss: 1.7607455253601074
Batch 31/64 loss: 1.8784027099609375
Batch 32/64 loss: 1.7193331718444824
Batch 33/64 loss: 2.077922821044922
Batch 34/64 loss: 2.1878933906555176
Batch 35/64 loss: 1.7679367065429688
Batch 36/64 loss: 1.639967918395996
Batch 37/64 loss: 1.5737719535827637
Batch 38/64 loss: 1.7906675338745117
Batch 39/64 loss: 1.8101692199707031
Batch 40/64 loss: 1.689915657043457
Batch 41/64 loss: 1.762779712677002
Batch 42/64 loss: 1.7267589569091797
Batch 43/64 loss: 1.6309432983398438
Batch 44/64 loss: 1.9699392318725586
Batch 45/64 loss: 1.7513995170593262
Batch 46/64 loss: 1.6196341514587402
Batch 47/64 loss: 1.6637544631958008
Batch 48/64 loss: 1.7569003105163574
Batch 49/64 loss: 1.8240370750427246
Batch 50/64 loss: 1.6121668815612793
Batch 51/64 loss: 1.7140932083129883
Batch 52/64 loss: 1.7354769706726074
Batch 53/64 loss: 1.9322538375854492
Batch 54/64 loss: 1.8140292167663574
Batch 55/64 loss: 1.8516664505004883
Batch 56/64 loss: 1.6905136108398438
Batch 57/64 loss: 1.6548256874084473
Batch 58/64 loss: 1.7480225563049316
Batch 59/64 loss: 1.8626785278320312
Batch 60/64 loss: 1.7157378196716309
Batch 61/64 loss: 1.7018914222717285
Batch 62/64 loss: 1.7406296730041504
Batch 63/64 loss: 1.9022555351257324
Batch 64/64 loss: -1.488081932067871
Epoch 156  Train loss: 1.7818460389679553  Val loss: 1.5526666280739905
Epoch 157
-------------------------------
Batch 1/64 loss: 1.5899558067321777
Batch 2/64 loss: 1.6323094367980957
Batch 3/64 loss: 1.9179115295410156
Batch 4/64 loss: 1.7144498825073242
Batch 5/64 loss: 1.857870101928711
Batch 6/64 loss: 1.7226142883300781
Batch 7/64 loss: 1.8506011962890625
Batch 8/64 loss: 1.7087807655334473
Batch 9/64 loss: 1.7416772842407227
Batch 10/64 loss: 1.6315722465515137
Batch 11/64 loss: 1.8574094772338867
Batch 12/64 loss: 1.6595172882080078
Batch 13/64 loss: 1.7890515327453613
Batch 14/64 loss: 1.7339324951171875
Batch 15/64 loss: 1.7373247146606445
Batch 16/64 loss: 1.8243675231933594
Batch 17/64 loss: 1.8958206176757812
Batch 18/64 loss: 1.8665108680725098
Batch 19/64 loss: 1.944991111755371
Batch 20/64 loss: 1.623520851135254
Batch 21/64 loss: 1.8329682350158691
Batch 22/64 loss: 1.678541660308838
Batch 23/64 loss: 1.7310528755187988
Batch 24/64 loss: 1.7129793167114258
Batch 25/64 loss: 1.691145420074463
Batch 26/64 loss: 1.8015727996826172
Batch 27/64 loss: 1.9200010299682617
Batch 28/64 loss: 1.8034534454345703
Batch 29/64 loss: 1.835726261138916
Batch 30/64 loss: 1.8530120849609375
Batch 31/64 loss: 1.75787353515625
Batch 32/64 loss: 1.9461727142333984
Batch 33/64 loss: 1.7223262786865234
Batch 34/64 loss: 1.9877347946166992
Batch 35/64 loss: 1.777475357055664
Batch 36/64 loss: 1.7801198959350586
Batch 37/64 loss: 1.637594223022461
Batch 38/64 loss: 1.8187108039855957
Batch 39/64 loss: 1.8402514457702637
Batch 40/64 loss: 1.922882080078125
Batch 41/64 loss: 1.6191859245300293
Batch 42/64 loss: 1.8695082664489746
Batch 43/64 loss: 1.8536205291748047
Batch 44/64 loss: 1.716672420501709
Batch 45/64 loss: 1.9346747398376465
Batch 46/64 loss: 1.836472988128662
Batch 47/64 loss: 1.862452507019043
Batch 48/64 loss: 1.88533353805542
Batch 49/64 loss: 1.8562469482421875
Batch 50/64 loss: 1.8544740676879883
Batch 51/64 loss: 1.909806728363037
Batch 52/64 loss: 1.8495092391967773
Batch 53/64 loss: 1.9486427307128906
Batch 54/64 loss: 1.8265228271484375
Batch 55/64 loss: 1.7366447448730469
Batch 56/64 loss: 1.7603445053100586
Batch 57/64 loss: 1.8158397674560547
Batch 58/64 loss: 1.9623465538024902
Batch 59/64 loss: 1.909022331237793
Batch 60/64 loss: 1.8696579933166504
Batch 61/64 loss: 1.8731780052185059
Batch 62/64 loss: 2.022571086883545
Batch 63/64 loss: 1.793065071105957
Batch 64/64 loss: -1.4813251495361328
Epoch 157  Train loss: 1.7695150263169233  Val loss: 1.5578090169585448
Epoch 158
-------------------------------
Batch 1/64 loss: 1.8504881858825684
Batch 2/64 loss: 1.8231353759765625
Batch 3/64 loss: 1.6303696632385254
Batch 4/64 loss: 1.7468891143798828
Batch 5/64 loss: 1.8823819160461426
Batch 6/64 loss: 1.8696856498718262
Batch 7/64 loss: 1.7717037200927734
Batch 8/64 loss: 1.9069814682006836
Batch 9/64 loss: 1.8140220642089844
Batch 10/64 loss: 2.0289177894592285
Batch 11/64 loss: 1.7578134536743164
Batch 12/64 loss: 1.6223454475402832
Batch 13/64 loss: 1.7648558616638184
Batch 14/64 loss: 1.6806278228759766
Batch 15/64 loss: 1.736445426940918
Batch 16/64 loss: 1.8186473846435547
Batch 17/64 loss: 1.790156364440918
Batch 18/64 loss: 1.7213335037231445
Batch 19/64 loss: 1.597921371459961
Batch 20/64 loss: 1.6768898963928223
Batch 21/64 loss: 1.8358068466186523
Batch 22/64 loss: 1.7245469093322754
Batch 23/64 loss: 1.809126377105713
Batch 24/64 loss: 1.9153046607971191
Batch 25/64 loss: 1.8382363319396973
Batch 26/64 loss: 1.8810820579528809
Batch 27/64 loss: 1.743079662322998
Batch 28/64 loss: 1.699388027191162
Batch 29/64 loss: 1.8714122772216797
Batch 30/64 loss: 1.709484577178955
Batch 31/64 loss: 1.8550958633422852
Batch 32/64 loss: 1.8377928733825684
Batch 33/64 loss: 1.871342658996582
Batch 34/64 loss: 1.663853645324707
Batch 35/64 loss: 1.96575927734375
Batch 36/64 loss: 1.8866047859191895
Batch 37/64 loss: 1.7533326148986816
Batch 38/64 loss: 1.7184209823608398
Batch 39/64 loss: 1.8443307876586914
Batch 40/64 loss: 1.757093906402588
Batch 41/64 loss: 1.7232275009155273
Batch 42/64 loss: 1.8083248138427734
Batch 43/64 loss: 2.033968448638916
Batch 44/64 loss: 1.732490062713623
Batch 45/64 loss: 1.8879165649414062
Batch 46/64 loss: 1.6423425674438477
Batch 47/64 loss: 1.7383599281311035
Batch 48/64 loss: 1.5713820457458496
Batch 49/64 loss: 1.8924260139465332
Batch 50/64 loss: 1.8838672637939453
Batch 51/64 loss: 1.81451416015625
Batch 52/64 loss: 1.7700080871582031
Batch 53/64 loss: 1.7314391136169434
Batch 54/64 loss: 1.7049870491027832
Batch 55/64 loss: 1.7035012245178223
Batch 56/64 loss: 1.6296906471252441
Batch 57/64 loss: 1.6407856941223145
Batch 58/64 loss: 1.9099421501159668
Batch 59/64 loss: 1.8013439178466797
Batch 60/64 loss: 1.768754005432129
Batch 61/64 loss: 1.6979460716247559
Batch 62/64 loss: 1.8415307998657227
Batch 63/64 loss: 1.7543063163757324
Batch 64/64 loss: -1.572746753692627
Epoch 158  Train loss: 1.7439404076220943  Val loss: 1.4985399475622014
Epoch 159
-------------------------------
Batch 1/64 loss: 1.7566285133361816
Batch 2/64 loss: 1.872133731842041
Batch 3/64 loss: 1.994884967803955
Batch 4/64 loss: 2.1797618865966797
Batch 5/64 loss: 1.6938023567199707
Batch 6/64 loss: 1.7150464057922363
Batch 7/64 loss: 1.5678439140319824
Batch 8/64 loss: 1.7777600288391113
Batch 9/64 loss: 1.802201271057129
Batch 10/64 loss: 1.7665581703186035
Batch 11/64 loss: 1.7033042907714844
Batch 12/64 loss: 2.145808696746826
Batch 13/64 loss: 1.7886862754821777
Batch 14/64 loss: 1.9606952667236328
Batch 15/64 loss: 1.7065372467041016
Batch 16/64 loss: 1.8763771057128906
Batch 17/64 loss: 1.8176045417785645
Batch 18/64 loss: 1.7574172019958496
Batch 19/64 loss: 1.6891603469848633
Batch 20/64 loss: 1.7817153930664062
Batch 21/64 loss: 1.7198238372802734
Batch 22/64 loss: 1.718989372253418
Batch 23/64 loss: 1.8796629905700684
Batch 24/64 loss: 1.93644380569458
Batch 25/64 loss: 1.815239429473877
Batch 26/64 loss: 1.65629243850708
Batch 27/64 loss: 1.849782943725586
Batch 28/64 loss: 1.8840336799621582
Batch 29/64 loss: 1.7863993644714355
Batch 30/64 loss: 1.7970781326293945
Batch 31/64 loss: 1.8437366485595703
Batch 32/64 loss: 1.8126106262207031
Batch 33/64 loss: 1.869126796722412
Batch 34/64 loss: 1.6469721794128418
Batch 35/64 loss: 1.6639776229858398
Batch 36/64 loss: 1.8288383483886719
Batch 37/64 loss: 1.7238130569458008
Batch 38/64 loss: 1.7599611282348633
Batch 39/64 loss: 1.82149076461792
Batch 40/64 loss: 1.7307772636413574
Batch 41/64 loss: 1.8225555419921875
Batch 42/64 loss: 1.756028652191162
Batch 43/64 loss: 1.6234593391418457
Batch 44/64 loss: 1.7157588005065918
Batch 45/64 loss: 1.8766570091247559
Batch 46/64 loss: 1.9370384216308594
Batch 47/64 loss: 1.8860154151916504
Batch 48/64 loss: 2.020146369934082
Batch 49/64 loss: 1.9422073364257812
Batch 50/64 loss: 2.0367870330810547
Batch 51/64 loss: 1.7437119483947754
Batch 52/64 loss: 1.6902093887329102
Batch 53/64 loss: 1.7644729614257812
Batch 54/64 loss: 1.917189598083496
Batch 55/64 loss: 1.7964515686035156
Batch 56/64 loss: 1.8159403800964355
Batch 57/64 loss: 2.058894157409668
Batch 58/64 loss: 2.071549892425537
Batch 59/64 loss: 2.0672216415405273
Batch 60/64 loss: 1.8701958656311035
Batch 61/64 loss: 1.9093728065490723
Batch 62/64 loss: 1.805586338043213
Batch 63/64 loss: 1.8354473114013672
Batch 64/64 loss: -1.4933948516845703
Epoch 159  Train loss: 1.7873228185317096  Val loss: 1.5960203085568352
Epoch 160
-------------------------------
Batch 1/64 loss: 1.772585391998291
Batch 2/64 loss: 1.664896011352539
Batch 3/64 loss: 1.9696826934814453
Batch 4/64 loss: 2.0088114738464355
Batch 5/64 loss: 1.8035368919372559
Batch 6/64 loss: 1.815007209777832
Batch 7/64 loss: 1.7968788146972656
Batch 8/64 loss: 1.8861770629882812
Batch 9/64 loss: 1.8805556297302246
Batch 10/64 loss: 1.7117133140563965
Batch 11/64 loss: 1.9814567565917969
Batch 12/64 loss: 1.8042397499084473
Batch 13/64 loss: 1.586507797241211
Batch 14/64 loss: 1.729743480682373
Batch 15/64 loss: 1.711435317993164
Batch 16/64 loss: 1.732316493988037
Batch 17/64 loss: 1.7010083198547363
Batch 18/64 loss: 1.7129979133605957
Batch 19/64 loss: 1.7706642150878906
Batch 20/64 loss: 1.7149090766906738
Batch 21/64 loss: 1.9957923889160156
Batch 22/64 loss: 1.7177820205688477
Batch 23/64 loss: 1.7517752647399902
Batch 24/64 loss: 1.9554486274719238
Batch 25/64 loss: 2.086963653564453
Batch 26/64 loss: 1.7005729675292969
Batch 27/64 loss: 1.8992233276367188
Batch 28/64 loss: 1.746936321258545
Batch 29/64 loss: 1.7705726623535156
Batch 30/64 loss: 1.8536696434020996
Batch 31/64 loss: 1.7040519714355469
Batch 32/64 loss: 1.8744230270385742
Batch 33/64 loss: 1.85174560546875
Batch 34/64 loss: 1.9204707145690918
Batch 35/64 loss: 1.7311716079711914
Batch 36/64 loss: 1.9672904014587402
Batch 37/64 loss: 1.743952751159668
Batch 38/64 loss: 1.7584967613220215
Batch 39/64 loss: 1.7693772315979004
Batch 40/64 loss: 1.747474193572998
Batch 41/64 loss: 1.7143778800964355
Batch 42/64 loss: 1.9809660911560059
Batch 43/64 loss: 1.8045802116394043
Batch 44/64 loss: 2.0002670288085938
Batch 45/64 loss: 1.7000670433044434
Batch 46/64 loss: 1.7423686981201172
Batch 47/64 loss: 1.9297151565551758
Batch 48/64 loss: 1.7147736549377441
Batch 49/64 loss: 1.982254981994629
Batch 50/64 loss: 1.7424430847167969
Batch 51/64 loss: 1.843949317932129
Batch 52/64 loss: 1.8020119667053223
Batch 53/64 loss: 1.8537659645080566
Batch 54/64 loss: 2.0139212608337402
Batch 55/64 loss: 1.85325288772583
Batch 56/64 loss: 1.7895803451538086
Batch 57/64 loss: 1.70550537109375
Batch 58/64 loss: 1.7861981391906738
Batch 59/64 loss: 1.842881202697754
Batch 60/64 loss: 1.771446704864502
Batch 61/64 loss: 1.700963020324707
Batch 62/64 loss: 1.7438511848449707
Batch 63/64 loss: 1.7937626838684082
Batch 64/64 loss: -1.2988781929016113
Epoch 160  Train loss: 1.7747617254070207  Val loss: 1.517371318594287
Epoch 161
-------------------------------
Batch 1/64 loss: 1.9116473197937012
Batch 2/64 loss: 1.7931904792785645
Batch 3/64 loss: 1.7885046005249023
Batch 4/64 loss: 2.0008978843688965
Batch 5/64 loss: 1.6953153610229492
Batch 6/64 loss: 1.7674098014831543
Batch 7/64 loss: 1.731241226196289
Batch 8/64 loss: 1.672337532043457
Batch 9/64 loss: 1.7281608581542969
Batch 10/64 loss: 1.781221866607666
Batch 11/64 loss: 1.800858974456787
Batch 12/64 loss: 1.6322250366210938
Batch 13/64 loss: 1.8830533027648926
Batch 14/64 loss: 1.8782353401184082
Batch 15/64 loss: 1.853158950805664
Batch 16/64 loss: 1.7946100234985352
Batch 17/64 loss: 1.7584376335144043
Batch 18/64 loss: 1.7202868461608887
Batch 19/64 loss: 1.9627203941345215
Batch 20/64 loss: 1.7628173828125
Batch 21/64 loss: 1.8328123092651367
Batch 22/64 loss: 1.973832607269287
Batch 23/64 loss: 1.9532771110534668
Batch 24/64 loss: 1.8521976470947266
Batch 25/64 loss: 1.8148088455200195
Batch 26/64 loss: 1.8729114532470703
Batch 27/64 loss: 1.9193038940429688
Batch 28/64 loss: 1.8325819969177246
Batch 29/64 loss: 1.6585445404052734
Batch 30/64 loss: 1.8950614929199219
Batch 31/64 loss: 1.7757086753845215
Batch 32/64 loss: 1.7729740142822266
Batch 33/64 loss: 1.7669029235839844
Batch 34/64 loss: 1.7357354164123535
Batch 35/64 loss: 1.7040777206420898
Batch 36/64 loss: 1.7575445175170898
Batch 37/64 loss: 1.9975690841674805
Batch 38/64 loss: 1.7672834396362305
Batch 39/64 loss: 1.8068218231201172
Batch 40/64 loss: 1.7779316902160645
Batch 41/64 loss: 1.7756695747375488
Batch 42/64 loss: 1.8173484802246094
Batch 43/64 loss: 1.9088621139526367
Batch 44/64 loss: 1.8955798149108887
Batch 45/64 loss: 1.7739639282226562
Batch 46/64 loss: 1.6920342445373535
Batch 47/64 loss: 1.780390739440918
Batch 48/64 loss: 1.773773193359375
Batch 49/64 loss: 1.6989798545837402
Batch 50/64 loss: 1.700223445892334
Batch 51/64 loss: 1.6503267288208008
Batch 52/64 loss: 1.7326483726501465
Batch 53/64 loss: 1.6586294174194336
Batch 54/64 loss: 1.9053244590759277
Batch 55/64 loss: 1.7442450523376465
Batch 56/64 loss: 1.8299288749694824
Batch 57/64 loss: 1.7137932777404785
Batch 58/64 loss: 1.672459602355957
Batch 59/64 loss: 1.6108765602111816
Batch 60/64 loss: 1.7678594589233398
Batch 61/64 loss: 1.7720451354980469
Batch 62/64 loss: 1.648195743560791
Batch 63/64 loss: 1.8211755752563477
Batch 64/64 loss: -1.63230562210083
Epoch 161  Train loss: 1.7490873168496524  Val loss: 1.5513294259297479
Epoch 162
-------------------------------
Batch 1/64 loss: 1.6065316200256348
Batch 2/64 loss: 1.7685585021972656
Batch 3/64 loss: 1.7602415084838867
Batch 4/64 loss: 1.8753623962402344
Batch 5/64 loss: 1.7414336204528809
Batch 6/64 loss: 1.6864886283874512
Batch 7/64 loss: 1.8878178596496582
Batch 8/64 loss: 1.7656183242797852
Batch 9/64 loss: 1.669649600982666
Batch 10/64 loss: 1.7561683654785156
Batch 11/64 loss: 1.7218670845031738
Batch 12/64 loss: 1.747457504272461
Batch 13/64 loss: 2.0523200035095215
Batch 14/64 loss: 1.694303035736084
Batch 15/64 loss: 1.8006086349487305
Batch 16/64 loss: 1.7710943222045898
Batch 17/64 loss: 1.8141908645629883
Batch 18/64 loss: 1.7583365440368652
Batch 19/64 loss: 1.6892671585083008
Batch 20/64 loss: 1.7482891082763672
Batch 21/64 loss: 1.722330093383789
Batch 22/64 loss: 1.682180404663086
Batch 23/64 loss: 1.9954042434692383
Batch 24/64 loss: 1.6882519721984863
Batch 25/64 loss: 1.768488883972168
Batch 26/64 loss: 1.727623462677002
Batch 27/64 loss: 1.935638427734375
Batch 28/64 loss: 1.6898398399353027
Batch 29/64 loss: 1.9323244094848633
Batch 30/64 loss: 1.8491716384887695
Batch 31/64 loss: 1.8486580848693848
Batch 32/64 loss: 1.9017314910888672
Batch 33/64 loss: 1.9498872756958008
Batch 34/64 loss: 1.949080467224121
Batch 35/64 loss: 1.9776973724365234
Batch 36/64 loss: 1.868210792541504
Batch 37/64 loss: 1.875734806060791
Batch 38/64 loss: 1.7933087348937988
Batch 39/64 loss: 1.7144341468811035
Batch 40/64 loss: 1.8884224891662598
Batch 41/64 loss: 1.8171906471252441
Batch 42/64 loss: 1.6810078620910645
Batch 43/64 loss: 1.7752094268798828
Batch 44/64 loss: 1.6274027824401855
Batch 45/64 loss: 1.8123807907104492
Batch 46/64 loss: 1.7381834983825684
Batch 47/64 loss: 1.7708797454833984
Batch 48/64 loss: 1.791783332824707
Batch 49/64 loss: 1.7109375
Batch 50/64 loss: 1.902151107788086
Batch 51/64 loss: 2.02565336227417
Batch 52/64 loss: 2.038114070892334
Batch 53/64 loss: 1.7120661735534668
Batch 54/64 loss: 1.7497034072875977
Batch 55/64 loss: 1.9683375358581543
Batch 56/64 loss: 1.6407933235168457
Batch 57/64 loss: 1.7802462577819824
Batch 58/64 loss: 1.6640386581420898
Batch 59/64 loss: 1.7816996574401855
Batch 60/64 loss: 1.8239531517028809
Batch 61/64 loss: 1.8195934295654297
Batch 62/64 loss: 1.735605239868164
Batch 63/64 loss: 1.7972888946533203
Batch 64/64 loss: -1.4572649002075195
Epoch 162  Train loss: 1.7591418808581782  Val loss: 1.5322469730967099
Epoch 163
-------------------------------
Batch 1/64 loss: 1.7056221961975098
Batch 2/64 loss: 1.710526466369629
Batch 3/64 loss: 1.8672356605529785
Batch 4/64 loss: 1.7689018249511719
Batch 5/64 loss: 1.6730108261108398
Batch 6/64 loss: 1.7839579582214355
Batch 7/64 loss: 1.7611608505249023
Batch 8/64 loss: 1.645763874053955
Batch 9/64 loss: 1.7716517448425293
Batch 10/64 loss: 1.7056074142456055
Batch 11/64 loss: 1.8240108489990234
Batch 12/64 loss: 1.7784337997436523
Batch 13/64 loss: 1.8062787055969238
Batch 14/64 loss: 1.79791259765625
Batch 15/64 loss: 1.9225282669067383
Batch 16/64 loss: 1.754539966583252
Batch 17/64 loss: 1.861487865447998
Batch 18/64 loss: 1.9178504943847656
Batch 19/64 loss: 1.8900208473205566
Batch 20/64 loss: 1.711564064025879
Batch 21/64 loss: 1.7198309898376465
Batch 22/64 loss: 1.7919230461120605
Batch 23/64 loss: 1.7310690879821777
Batch 24/64 loss: 2.1649909019470215
Batch 25/64 loss: 1.7056279182434082
Batch 26/64 loss: 1.729628562927246
Batch 27/64 loss: 1.9484758377075195
Batch 28/64 loss: 1.8174495697021484
Batch 29/64 loss: 2.12375545501709
Batch 30/64 loss: 1.8469500541687012
Batch 31/64 loss: 2.0394654273986816
Batch 32/64 loss: 2.0149850845336914
Batch 33/64 loss: 1.7487187385559082
Batch 34/64 loss: 1.7274417877197266
Batch 35/64 loss: 2.0027756690979004
Batch 36/64 loss: 1.7841510772705078
Batch 37/64 loss: 1.7000198364257812
Batch 38/64 loss: 1.8738369941711426
Batch 39/64 loss: 1.835770606994629
Batch 40/64 loss: 1.8985872268676758
Batch 41/64 loss: 1.6892390251159668
Batch 42/64 loss: 1.7131619453430176
Batch 43/64 loss: 1.7833662033081055
Batch 44/64 loss: 1.9976158142089844
Batch 45/64 loss: 1.938976764678955
Batch 46/64 loss: 1.8516731262207031
Batch 47/64 loss: 1.7510838508605957
Batch 48/64 loss: 1.8932180404663086
Batch 49/64 loss: 1.6551966667175293
Batch 50/64 loss: 2.002257823944092
Batch 51/64 loss: 1.8934869766235352
Batch 52/64 loss: 1.7855377197265625
Batch 53/64 loss: 1.7468814849853516
Batch 54/64 loss: 1.8748278617858887
Batch 55/64 loss: 1.9008851051330566
Batch 56/64 loss: 1.8500938415527344
Batch 57/64 loss: 1.6943964958190918
Batch 58/64 loss: 1.7896265983581543
Batch 59/64 loss: 1.8826241493225098
Batch 60/64 loss: 1.6771206855773926
Batch 61/64 loss: 1.7725977897644043
Batch 62/64 loss: 1.7803544998168945
Batch 63/64 loss: 1.7823057174682617
Batch 64/64 loss: -1.646745204925537
Epoch 163  Train loss: 1.7778037557414934  Val loss: 1.528432826405948
Epoch 164
-------------------------------
Batch 1/64 loss: 1.589705467224121
Batch 2/64 loss: 1.7598810195922852
Batch 3/64 loss: 1.6941618919372559
Batch 4/64 loss: 1.7100205421447754
Batch 5/64 loss: 1.8723154067993164
Batch 6/64 loss: 1.7424964904785156
Batch 7/64 loss: 1.7686080932617188
Batch 8/64 loss: 1.6399178504943848
Batch 9/64 loss: 1.8881783485412598
Batch 10/64 loss: 1.8196897506713867
Batch 11/64 loss: 1.7776093482971191
Batch 12/64 loss: 1.754094123840332
Batch 13/64 loss: 1.8544697761535645
Batch 14/64 loss: 1.8533806800842285
Batch 15/64 loss: 1.7939801216125488
Batch 16/64 loss: 1.7117195129394531
Batch 17/64 loss: 1.8218955993652344
Batch 18/64 loss: 1.7679877281188965
Batch 19/64 loss: 1.859633445739746
Batch 20/64 loss: 1.8782167434692383
Batch 21/64 loss: 1.8620262145996094
Batch 22/64 loss: 1.8280911445617676
Batch 23/64 loss: 1.8188867568969727
Batch 24/64 loss: 1.8812155723571777
Batch 25/64 loss: 1.7395477294921875
Batch 26/64 loss: 1.794754981994629
Batch 27/64 loss: 1.622614860534668
Batch 28/64 loss: 1.9010825157165527
Batch 29/64 loss: 1.794731616973877
Batch 30/64 loss: 1.8828315734863281
Batch 31/64 loss: 1.8856658935546875
Batch 32/64 loss: 1.789074420928955
Batch 33/64 loss: 1.7526326179504395
Batch 34/64 loss: 1.7722325325012207
Batch 35/64 loss: 1.628005027770996
Batch 36/64 loss: 1.8224248886108398
Batch 37/64 loss: 1.6836204528808594
Batch 38/64 loss: 2.0170559883117676
Batch 39/64 loss: 1.8528251647949219
Batch 40/64 loss: 1.772676944732666
Batch 41/64 loss: 1.7945656776428223
Batch 42/64 loss: 1.9003181457519531
Batch 43/64 loss: 1.7215518951416016
Batch 44/64 loss: 1.8888297080993652
Batch 45/64 loss: 1.9083304405212402
Batch 46/64 loss: 1.6537280082702637
Batch 47/64 loss: 1.777967929840088
Batch 48/64 loss: 1.7663259506225586
Batch 49/64 loss: 1.950810432434082
Batch 50/64 loss: 1.6952109336853027
Batch 51/64 loss: 1.743241786956787
Batch 52/64 loss: 1.66420316696167
Batch 53/64 loss: 1.7100048065185547
Batch 54/64 loss: 1.815727710723877
Batch 55/64 loss: 1.6618013381958008
Batch 56/64 loss: 1.6820878982543945
Batch 57/64 loss: 1.6419625282287598
Batch 58/64 loss: 1.61553955078125
Batch 59/64 loss: 1.728184700012207
Batch 60/64 loss: 1.7498879432678223
Batch 61/64 loss: 1.6554145812988281
Batch 62/64 loss: 1.7225604057312012
Batch 63/64 loss: 1.7467303276062012
Batch 64/64 loss: -1.6456217765808105
Epoch 164  Train loss: 1.7352271117416083  Val loss: 1.5009790400868839
Epoch 165
-------------------------------
Batch 1/64 loss: 1.7817769050598145
Batch 2/64 loss: 1.7334022521972656
Batch 3/64 loss: 1.7308216094970703
Batch 4/64 loss: 1.8508682250976562
Batch 5/64 loss: 1.7136507034301758
Batch 6/64 loss: 1.7880640029907227
Batch 7/64 loss: 1.6397347450256348
Batch 8/64 loss: 1.692777156829834
Batch 9/64 loss: 1.7621350288391113
Batch 10/64 loss: 1.959608554840088
Batch 11/64 loss: 1.6711559295654297
Batch 12/64 loss: 1.8719568252563477
Batch 13/64 loss: 1.7453398704528809
Batch 14/64 loss: 1.7880172729492188
Batch 15/64 loss: 1.993485927581787
Batch 16/64 loss: 1.8524880409240723
Batch 17/64 loss: 1.8007111549377441
Batch 18/64 loss: 1.6877140998840332
Batch 19/64 loss: 1.813427448272705
Batch 20/64 loss: 1.7734503746032715
Batch 21/64 loss: 1.6783466339111328
Batch 22/64 loss: 2.03366756439209
Batch 23/64 loss: 1.6672639846801758
Batch 24/64 loss: 1.6830682754516602
Batch 25/64 loss: 1.8532867431640625
Batch 26/64 loss: 1.8909282684326172
Batch 27/64 loss: 1.7721171379089355
Batch 28/64 loss: 1.7667808532714844
Batch 29/64 loss: 1.7095823287963867
Batch 30/64 loss: 1.6921682357788086
Batch 31/64 loss: 1.5634164810180664
Batch 32/64 loss: 1.769474983215332
Batch 33/64 loss: 1.7915692329406738
Batch 34/64 loss: 1.7102508544921875
Batch 35/64 loss: 1.8649067878723145
Batch 36/64 loss: 1.8558197021484375
Batch 37/64 loss: 1.840193748474121
Batch 38/64 loss: 1.7464203834533691
Batch 39/64 loss: 1.849039077758789
Batch 40/64 loss: 1.9932737350463867
Batch 41/64 loss: 1.7780165672302246
Batch 42/64 loss: 2.0150303840637207
Batch 43/64 loss: 1.9131803512573242
Batch 44/64 loss: 1.8680658340454102
Batch 45/64 loss: 1.7632150650024414
Batch 46/64 loss: 1.904104232788086
Batch 47/64 loss: 1.9071221351623535
Batch 48/64 loss: 1.8242087364196777
Batch 49/64 loss: 1.8357658386230469
Batch 50/64 loss: 1.990396499633789
Batch 51/64 loss: 1.891552448272705
Batch 52/64 loss: 1.7793498039245605
Batch 53/64 loss: 1.6851954460144043
Batch 54/64 loss: 2.0143051147460938
Batch 55/64 loss: 1.7925796508789062
Batch 56/64 loss: 1.78265380859375
Batch 57/64 loss: 1.679490566253662
Batch 58/64 loss: 1.924311637878418
Batch 59/64 loss: 1.7302346229553223
Batch 60/64 loss: 1.7370562553405762
Batch 61/64 loss: 1.6462087631225586
Batch 62/64 loss: 1.9239516258239746
Batch 63/64 loss: 1.8428606986999512
Batch 64/64 loss: -1.4767560958862305
Epoch 165  Train loss: 1.7647600024354224  Val loss: 1.5857856593181177
Epoch 166
-------------------------------
Batch 1/64 loss: 1.8511056900024414
Batch 2/64 loss: 1.7969532012939453
Batch 3/64 loss: 1.9228262901306152
Batch 4/64 loss: 2.0107650756835938
Batch 5/64 loss: 1.8150863647460938
Batch 6/64 loss: 1.7696123123168945
Batch 7/64 loss: 1.6784629821777344
Batch 8/64 loss: 1.7849740982055664
Batch 9/64 loss: 1.7669281959533691
Batch 10/64 loss: 1.8963680267333984
Batch 11/64 loss: 2.04359769821167
Batch 12/64 loss: 1.9465909004211426
Batch 13/64 loss: 1.8208999633789062
Batch 14/64 loss: 2.0700173377990723
Batch 15/64 loss: 2.103631019592285
Batch 16/64 loss: 1.844839096069336
Batch 17/64 loss: 1.643578052520752
Batch 18/64 loss: 1.9406719207763672
Batch 19/64 loss: 1.8686237335205078
Batch 20/64 loss: 1.7121548652648926
Batch 21/64 loss: 2.036929130554199
Batch 22/64 loss: 1.8849587440490723
Batch 23/64 loss: 2.0193257331848145
Batch 24/64 loss: 1.9201135635375977
Batch 25/64 loss: 1.904160976409912
Batch 26/64 loss: 1.981992244720459
Batch 27/64 loss: 1.8567419052124023
Batch 28/64 loss: 1.8734631538391113
Batch 29/64 loss: 1.9174370765686035
Batch 30/64 loss: 1.8374695777893066
Batch 31/64 loss: 1.691943645477295
Batch 32/64 loss: 1.825120449066162
Batch 33/64 loss: 1.901059627532959
Batch 34/64 loss: 2.084033489227295
Batch 35/64 loss: 2.13214111328125
Batch 36/64 loss: 1.6511359214782715
Batch 37/64 loss: 1.7918710708618164
Batch 38/64 loss: 1.8316192626953125
Batch 39/64 loss: 1.68381929397583
Batch 40/64 loss: 1.7975711822509766
Batch 41/64 loss: 1.7337851524353027
Batch 42/64 loss: 1.79130220413208
Batch 43/64 loss: 1.8701443672180176
Batch 44/64 loss: 1.8944215774536133
Batch 45/64 loss: 1.7599029541015625
Batch 46/64 loss: 1.8736824989318848
Batch 47/64 loss: 1.6884231567382812
Batch 48/64 loss: 1.776273250579834
Batch 49/64 loss: 1.786816120147705
Batch 50/64 loss: 1.8020992279052734
Batch 51/64 loss: 1.8199963569641113
Batch 52/64 loss: 1.9997692108154297
Batch 53/64 loss: 1.7868494987487793
Batch 54/64 loss: 1.9073963165283203
Batch 55/64 loss: 1.7732577323913574
Batch 56/64 loss: 1.8396339416503906
Batch 57/64 loss: 1.6953511238098145
Batch 58/64 loss: 1.8601055145263672
Batch 59/64 loss: 1.915013313293457
Batch 60/64 loss: 1.7210793495178223
Batch 61/64 loss: 1.9613184928894043
Batch 62/64 loss: 1.8145689964294434
Batch 63/64 loss: 1.9395270347595215
Batch 64/64 loss: -1.2904181480407715
Epoch 166  Train loss: 1.8188783963521322  Val loss: 1.7235459855331998
Epoch 167
-------------------------------
Batch 1/64 loss: 1.753011703491211
Batch 2/64 loss: 1.8138532638549805
Batch 3/64 loss: 1.9985113143920898
Batch 4/64 loss: 1.7581992149353027
Batch 5/64 loss: 1.822777271270752
Batch 6/64 loss: 1.9164581298828125
Batch 7/64 loss: 2.0301623344421387
Batch 8/64 loss: 1.8038640022277832
Batch 9/64 loss: 1.8916516304016113
Batch 10/64 loss: 1.864121913909912
Batch 11/64 loss: 1.7637529373168945
Batch 12/64 loss: 1.8738913536071777
Batch 13/64 loss: 1.7432279586791992
Batch 14/64 loss: 1.7957954406738281
Batch 15/64 loss: 2.176342487335205
Batch 16/64 loss: 2.0325822830200195
Batch 17/64 loss: 1.7844562530517578
Batch 18/64 loss: 1.9549803733825684
Batch 19/64 loss: 1.8762717247009277
Batch 20/64 loss: 1.8567066192626953
Batch 21/64 loss: 1.8140006065368652
Batch 22/64 loss: 1.8279995918273926
Batch 23/64 loss: 1.7711091041564941
Batch 24/64 loss: 1.765364170074463
Batch 25/64 loss: 1.8347625732421875
Batch 26/64 loss: 1.986219882965088
Batch 27/64 loss: 1.787106990814209
Batch 28/64 loss: 2.0619516372680664
Batch 29/64 loss: 1.8404693603515625
Batch 30/64 loss: 1.9707655906677246
Batch 31/64 loss: 2.0110926628112793
Batch 32/64 loss: 1.8767247200012207
Batch 33/64 loss: 1.7016034126281738
Batch 34/64 loss: 1.8312735557556152
Batch 35/64 loss: 1.8681721687316895
Batch 36/64 loss: 1.969846248626709
Batch 37/64 loss: 1.84785795211792
Batch 38/64 loss: 1.9778428077697754
Batch 39/64 loss: 1.8083996772766113
Batch 40/64 loss: 1.76633882522583
Batch 41/64 loss: 1.7010254859924316
Batch 42/64 loss: 2.028273105621338
Batch 43/64 loss: 1.7546768188476562
Batch 44/64 loss: 1.723954677581787
Batch 45/64 loss: 1.8391952514648438
Batch 46/64 loss: 1.8565101623535156
Batch 47/64 loss: 1.9146580696105957
Batch 48/64 loss: 2.0029091835021973
Batch 49/64 loss: 1.7047886848449707
Batch 50/64 loss: 1.6312298774719238
Batch 51/64 loss: 1.8032140731811523
Batch 52/64 loss: 1.741163730621338
Batch 53/64 loss: 1.6343731880187988
Batch 54/64 loss: 1.7558302879333496
Batch 55/64 loss: 1.9309306144714355
Batch 56/64 loss: 1.6837396621704102
Batch 57/64 loss: 1.7585487365722656
Batch 58/64 loss: 1.8682284355163574
Batch 59/64 loss: 1.7411713600158691
Batch 60/64 loss: 1.741363525390625
Batch 61/64 loss: 1.7996296882629395
Batch 62/64 loss: 1.749692440032959
Batch 63/64 loss: 2.1923646926879883
Batch 64/64 loss: -1.4994659423828125
Epoch 167  Train loss: 1.8080375222598806  Val loss: 1.6135632885280753
Epoch 168
-------------------------------
Batch 1/64 loss: 1.6800665855407715
Batch 2/64 loss: 1.8893046379089355
Batch 3/64 loss: 1.9646105766296387
Batch 4/64 loss: 1.7637343406677246
Batch 5/64 loss: 1.7459063529968262
Batch 6/64 loss: 1.999845027923584
Batch 7/64 loss: 1.8817577362060547
Batch 8/64 loss: 1.7137508392333984
Batch 9/64 loss: 1.8892388343811035
Batch 10/64 loss: 1.9707765579223633
Batch 11/64 loss: 1.920485496520996
Batch 12/64 loss: 1.6706514358520508
Batch 13/64 loss: 1.9183907508850098
Batch 14/64 loss: 1.7130932807922363
Batch 15/64 loss: 1.8421730995178223
Batch 16/64 loss: 1.8200788497924805
Batch 17/64 loss: 1.799839973449707
Batch 18/64 loss: 1.9279451370239258
Batch 19/64 loss: 1.7741012573242188
Batch 20/64 loss: 1.663133144378662
Batch 21/64 loss: 1.842653751373291
Batch 22/64 loss: 1.8528990745544434
Batch 23/64 loss: 1.6701703071594238
Batch 24/64 loss: 1.7310032844543457
Batch 25/64 loss: 1.9284815788269043
Batch 26/64 loss: 1.6285223960876465
Batch 27/64 loss: 1.7629075050354004
Batch 28/64 loss: 1.6688027381896973
Batch 29/64 loss: 1.6232662200927734
Batch 30/64 loss: 1.7281489372253418
Batch 31/64 loss: 1.9730782508850098
Batch 32/64 loss: 1.7487215995788574
Batch 33/64 loss: 1.7299985885620117
Batch 34/64 loss: 1.7076802253723145
Batch 35/64 loss: 1.777270793914795
Batch 36/64 loss: 1.7786531448364258
Batch 37/64 loss: 1.7201495170593262
Batch 38/64 loss: 1.918868064880371
Batch 39/64 loss: 1.5612521171569824
Batch 40/64 loss: 1.7129616737365723
Batch 41/64 loss: 1.7412152290344238
Batch 42/64 loss: 1.7020916938781738
Batch 43/64 loss: 1.7546172142028809
Batch 44/64 loss: 1.718177318572998
Batch 45/64 loss: 1.6657791137695312
Batch 46/64 loss: 1.825963020324707
Batch 47/64 loss: 1.8543167114257812
Batch 48/64 loss: 1.8483734130859375
Batch 49/64 loss: 1.7954115867614746
Batch 50/64 loss: 1.8033313751220703
Batch 51/64 loss: 1.6661834716796875
Batch 52/64 loss: 1.7728347778320312
Batch 53/64 loss: 1.82952880859375
Batch 54/64 loss: 1.8160319328308105
Batch 55/64 loss: 1.8971314430236816
Batch 56/64 loss: 1.6706037521362305
Batch 57/64 loss: 1.766237735748291
Batch 58/64 loss: 1.714423656463623
Batch 59/64 loss: 1.6702604293823242
Batch 60/64 loss: 1.7445130348205566
Batch 61/64 loss: 1.788560390472412
Batch 62/64 loss: 1.880232334136963
Batch 63/64 loss: 1.825016975402832
Batch 64/64 loss: -1.5188250541687012
Epoch 168  Train loss: 1.7447229852863386  Val loss: 1.5302635402613898
Epoch 169
-------------------------------
Batch 1/64 loss: 1.7038793563842773
Batch 2/64 loss: 1.8287644386291504
Batch 3/64 loss: 1.688185214996338
Batch 4/64 loss: 1.8112411499023438
Batch 5/64 loss: 1.64518404006958
Batch 6/64 loss: 1.7333507537841797
Batch 7/64 loss: 1.8118171691894531
Batch 8/64 loss: 1.6781535148620605
Batch 9/64 loss: 2.019179344177246
Batch 10/64 loss: 1.934643268585205
Batch 11/64 loss: 1.7138700485229492
Batch 12/64 loss: 1.792097568511963
Batch 13/64 loss: 1.8265151977539062
Batch 14/64 loss: 1.7424678802490234
Batch 15/64 loss: 1.7735395431518555
Batch 16/64 loss: 1.720757007598877
Batch 17/64 loss: 2.0586118698120117
Batch 18/64 loss: 1.5869622230529785
Batch 19/64 loss: 1.700645923614502
Batch 20/64 loss: 1.7636871337890625
Batch 21/64 loss: 1.8058109283447266
Batch 22/64 loss: 1.9238462448120117
Batch 23/64 loss: 1.6748175621032715
Batch 24/64 loss: 1.861252784729004
Batch 25/64 loss: 1.926419734954834
Batch 26/64 loss: 1.72691011428833
Batch 27/64 loss: 1.665550708770752
Batch 28/64 loss: 1.7012672424316406
Batch 29/64 loss: 1.8328642845153809
Batch 30/64 loss: 1.7902584075927734
Batch 31/64 loss: 1.8310637474060059
Batch 32/64 loss: 1.6962246894836426
Batch 33/64 loss: 1.834578037261963
Batch 34/64 loss: 1.689842700958252
Batch 35/64 loss: 1.6462903022766113
Batch 36/64 loss: 1.832777976989746
Batch 37/64 loss: 1.876713752746582
Batch 38/64 loss: 1.7065739631652832
Batch 39/64 loss: 1.796949863433838
Batch 40/64 loss: 1.6584763526916504
Batch 41/64 loss: 1.6574206352233887
Batch 42/64 loss: 1.8145408630371094
Batch 43/64 loss: 1.790700912475586
Batch 44/64 loss: 1.6053409576416016
Batch 45/64 loss: 1.878988265991211
Batch 46/64 loss: 1.8109641075134277
Batch 47/64 loss: 1.7116584777832031
Batch 48/64 loss: 1.6616902351379395
Batch 49/64 loss: 1.5972223281860352
Batch 50/64 loss: 1.785240650177002
Batch 51/64 loss: 1.8727035522460938
Batch 52/64 loss: 1.7711052894592285
Batch 53/64 loss: 1.717698574066162
Batch 54/64 loss: 1.7158870697021484
Batch 55/64 loss: 1.8826484680175781
Batch 56/64 loss: 1.7110390663146973
Batch 57/64 loss: 1.744760513305664
Batch 58/64 loss: 1.641876220703125
Batch 59/64 loss: 1.8876442909240723
Batch 60/64 loss: 1.8576741218566895
Batch 61/64 loss: 1.6710758209228516
Batch 62/64 loss: 1.8709297180175781
Batch 63/64 loss: 1.7650647163391113
Batch 64/64 loss: -1.5477004051208496
Epoch 169  Train loss: 1.72980614269481  Val loss: 1.5301059971969972
Epoch 170
-------------------------------
Batch 1/64 loss: 1.6823444366455078
Batch 2/64 loss: 1.7682242393493652
Batch 3/64 loss: 1.865035057067871
Batch 4/64 loss: 1.7503299713134766
Batch 5/64 loss: 1.6374640464782715
Batch 6/64 loss: 1.820814609527588
Batch 7/64 loss: 1.6419353485107422
Batch 8/64 loss: 1.6681971549987793
Batch 9/64 loss: 1.7206192016601562
Batch 10/64 loss: 1.8128724098205566
Batch 11/64 loss: 1.7003302574157715
Batch 12/64 loss: 1.7479028701782227
Batch 13/64 loss: 1.7243351936340332
Batch 14/64 loss: 2.028212547302246
Batch 15/64 loss: 1.8422017097473145
Batch 16/64 loss: 1.745628833770752
Batch 17/64 loss: 1.7520051002502441
Batch 18/64 loss: 1.7920446395874023
Batch 19/64 loss: 1.7267870903015137
Batch 20/64 loss: 1.6151938438415527
Batch 21/64 loss: 1.6762313842773438
Batch 22/64 loss: 1.7792744636535645
Batch 23/64 loss: 1.8466582298278809
Batch 24/64 loss: 1.7045931816101074
Batch 25/64 loss: 1.6583433151245117
Batch 26/64 loss: 1.5682520866394043
Batch 27/64 loss: 1.8210563659667969
Batch 28/64 loss: 1.7215275764465332
Batch 29/64 loss: 1.961761474609375
Batch 30/64 loss: 1.7056679725646973
Batch 31/64 loss: 1.6963458061218262
Batch 32/64 loss: 1.6968884468078613
Batch 33/64 loss: 1.655348777770996
Batch 34/64 loss: 1.924410343170166
Batch 35/64 loss: 1.6702828407287598
Batch 36/64 loss: 1.7817673683166504
Batch 37/64 loss: 1.795910358428955
Batch 38/64 loss: 1.7856817245483398
Batch 39/64 loss: 1.6849570274353027
Batch 40/64 loss: 1.879460334777832
Batch 41/64 loss: 1.6394567489624023
Batch 42/64 loss: 1.7506089210510254
Batch 43/64 loss: 1.8257408142089844
Batch 44/64 loss: 2.0194177627563477
Batch 45/64 loss: 1.8327279090881348
Batch 46/64 loss: 2.107304573059082
Batch 47/64 loss: 1.8282904624938965
Batch 48/64 loss: 1.9160799980163574
Batch 49/64 loss: 1.8273954391479492
Batch 50/64 loss: 1.8728995323181152
Batch 51/64 loss: 1.9071826934814453
Batch 52/64 loss: 1.671278953552246
Batch 53/64 loss: 1.5397224426269531
Batch 54/64 loss: 1.6464009284973145
Batch 55/64 loss: 1.8760266304016113
Batch 56/64 loss: 1.8996853828430176
Batch 57/64 loss: 1.7019786834716797
Batch 58/64 loss: 1.8749794960021973
Batch 59/64 loss: 1.8047819137573242
Batch 60/64 loss: 1.6783947944641113
Batch 61/64 loss: 1.8068866729736328
Batch 62/64 loss: 1.746511459350586
Batch 63/64 loss: 1.8142194747924805
Batch 64/64 loss: -1.4996075630187988
Epoch 170  Train loss: 1.7336496259651932  Val loss: 1.4704134898497068
Saving best model, epoch: 170
Epoch 171
-------------------------------
Batch 1/64 loss: 1.7477221488952637
Batch 2/64 loss: 1.7283191680908203
Batch 3/64 loss: 1.7923932075500488
Batch 4/64 loss: 1.8039312362670898
Batch 5/64 loss: 1.6134557723999023
Batch 6/64 loss: 1.6629414558410645
Batch 7/64 loss: 1.6412382125854492
Batch 8/64 loss: 1.6366987228393555
Batch 9/64 loss: 1.616452693939209
Batch 10/64 loss: 1.6416664123535156
Batch 11/64 loss: 1.6739192008972168
Batch 12/64 loss: 1.583641529083252
Batch 13/64 loss: 1.7413358688354492
Batch 14/64 loss: 1.6820430755615234
Batch 15/64 loss: 1.7062182426452637
Batch 16/64 loss: 1.7116508483886719
Batch 17/64 loss: 2.137083053588867
Batch 18/64 loss: 1.7741103172302246
Batch 19/64 loss: 1.6511344909667969
Batch 20/64 loss: 1.7981104850769043
Batch 21/64 loss: 1.7218422889709473
Batch 22/64 loss: 1.8864636421203613
Batch 23/64 loss: 1.6442618370056152
Batch 24/64 loss: 1.6799631118774414
Batch 25/64 loss: 1.8276491165161133
Batch 26/64 loss: 1.755138874053955
Batch 27/64 loss: 1.6949963569641113
Batch 28/64 loss: 1.755833625793457
Batch 29/64 loss: 1.6834120750427246
Batch 30/64 loss: 1.7857813835144043
Batch 31/64 loss: 1.6249117851257324
Batch 32/64 loss: 2.075666904449463
Batch 33/64 loss: 1.9106364250183105
Batch 34/64 loss: 1.7150850296020508
Batch 35/64 loss: 1.7202444076538086
Batch 36/64 loss: 1.7020254135131836
Batch 37/64 loss: 1.9291205406188965
Batch 38/64 loss: 1.908921718597412
Batch 39/64 loss: 1.715686321258545
Batch 40/64 loss: 1.7211318016052246
Batch 41/64 loss: 1.7697091102600098
Batch 42/64 loss: 1.6484589576721191
Batch 43/64 loss: 1.8003349304199219
Batch 44/64 loss: 1.8251519203186035
Batch 45/64 loss: 1.7296013832092285
Batch 46/64 loss: 1.9042034149169922
Batch 47/64 loss: 1.8038249015808105
Batch 48/64 loss: 1.8391575813293457
Batch 49/64 loss: 1.9782896041870117
Batch 50/64 loss: 1.8156156539916992
Batch 51/64 loss: 2.0493459701538086
Batch 52/64 loss: 1.6922760009765625
Batch 53/64 loss: 1.8767027854919434
Batch 54/64 loss: 1.9418087005615234
Batch 55/64 loss: 1.914370059967041
Batch 56/64 loss: 1.7646517753601074
Batch 57/64 loss: 1.975728988647461
Batch 58/64 loss: 2.090780258178711
Batch 59/64 loss: 1.9316191673278809
Batch 60/64 loss: 1.7743639945983887
Batch 61/64 loss: 1.8427886962890625
Batch 62/64 loss: 1.709388256072998
Batch 63/64 loss: 1.7372169494628906
Batch 64/64 loss: -1.5610284805297852
Epoch 171  Train loss: 1.7419208863202262  Val loss: 1.6405541528131544
Epoch 172
-------------------------------
Batch 1/64 loss: 1.7702603340148926
Batch 2/64 loss: 1.6744751930236816
Batch 3/64 loss: 1.9337801933288574
Batch 4/64 loss: 1.7336344718933105
Batch 5/64 loss: 1.7791218757629395
Batch 6/64 loss: 1.868095874786377
Batch 7/64 loss: 1.946579933166504
Batch 8/64 loss: 1.9344706535339355
Batch 9/64 loss: 1.8724899291992188
Batch 10/64 loss: 1.837130069732666
Batch 11/64 loss: 1.8229355812072754
Batch 12/64 loss: 1.9128823280334473
Batch 13/64 loss: 1.7537870407104492
Batch 14/64 loss: 1.596662998199463
Batch 15/64 loss: 1.57692289352417
Batch 16/64 loss: 1.8005471229553223
Batch 17/64 loss: 1.7691855430603027
Batch 18/64 loss: 1.8505024909973145
Batch 19/64 loss: 2.019894599914551
Batch 20/64 loss: 1.8896379470825195
Batch 21/64 loss: 1.8765277862548828
Batch 22/64 loss: 1.8438663482666016
Batch 23/64 loss: 1.7611165046691895
Batch 24/64 loss: 1.7047715187072754
Batch 25/64 loss: 1.8741455078125
Batch 26/64 loss: 1.7505688667297363
Batch 27/64 loss: 1.9127707481384277
Batch 28/64 loss: 1.6641006469726562
Batch 29/64 loss: 1.8855724334716797
Batch 30/64 loss: 1.6411657333374023
Batch 31/64 loss: 1.7564444541931152
Batch 32/64 loss: 1.730966567993164
Batch 33/64 loss: 2.0884885787963867
Batch 34/64 loss: 2.0607080459594727
Batch 35/64 loss: 1.7303566932678223
Batch 36/64 loss: 1.6006412506103516
Batch 37/64 loss: 1.7325968742370605
Batch 38/64 loss: 1.7197279930114746
Batch 39/64 loss: 1.752608299255371
Batch 40/64 loss: 1.9048190116882324
Batch 41/64 loss: 1.7812132835388184
Batch 42/64 loss: 1.9523301124572754
Batch 43/64 loss: 1.7025542259216309
Batch 44/64 loss: 1.921072006225586
Batch 45/64 loss: 1.7798047065734863
Batch 46/64 loss: 1.9149103164672852
Batch 47/64 loss: 1.7518787384033203
Batch 48/64 loss: 1.7435460090637207
Batch 49/64 loss: 1.9297800064086914
Batch 50/64 loss: 1.8630619049072266
Batch 51/64 loss: 1.8561902046203613
Batch 52/64 loss: 1.6782011985778809
Batch 53/64 loss: 1.9880666732788086
Batch 54/64 loss: 1.722724437713623
Batch 55/64 loss: 1.704099178314209
Batch 56/64 loss: 1.6493782997131348
Batch 57/64 loss: 2.2902960777282715
Batch 58/64 loss: 1.7025141716003418
Batch 59/64 loss: 1.8424863815307617
Batch 60/64 loss: 1.9200119972229004
Batch 61/64 loss: 1.8950800895690918
Batch 62/64 loss: 1.68994140625
Batch 63/64 loss: 1.73936128616333
Batch 64/64 loss: -1.4824318885803223
Epoch 172  Train loss: 1.7763394467970903  Val loss: 1.523917135913757
Epoch 173
-------------------------------
Batch 1/64 loss: 1.7671566009521484
Batch 2/64 loss: 1.951225757598877
Batch 3/64 loss: 2.075923442840576
Batch 4/64 loss: 1.8407878875732422
Batch 5/64 loss: 2.141782760620117
Batch 6/64 loss: 1.7125096321105957
Batch 7/64 loss: 1.754915714263916
Batch 8/64 loss: 1.738112449645996
Batch 9/64 loss: 1.6732254028320312
Batch 10/64 loss: 1.7370357513427734
Batch 11/64 loss: 1.7377290725708008
Batch 12/64 loss: 2.3438382148742676
Batch 13/64 loss: 1.5864992141723633
Batch 14/64 loss: 1.775866985321045
Batch 15/64 loss: 1.7331128120422363
Batch 16/64 loss: 1.663154125213623
Batch 17/64 loss: 1.6644444465637207
Batch 18/64 loss: 1.760319709777832
Batch 19/64 loss: 1.9038653373718262
Batch 20/64 loss: 1.7363710403442383
Batch 21/64 loss: 1.7820611000061035
Batch 22/64 loss: 1.6905264854431152
Batch 23/64 loss: 1.8090300559997559
Batch 24/64 loss: 1.8876214027404785
Batch 25/64 loss: 1.8596487045288086
Batch 26/64 loss: 1.794579029083252
Batch 27/64 loss: 1.8858184814453125
Batch 28/64 loss: 1.7135357856750488
Batch 29/64 loss: 1.6706299781799316
Batch 30/64 loss: 1.8337483406066895
Batch 31/64 loss: 1.744058609008789
Batch 32/64 loss: 1.793339729309082
Batch 33/64 loss: 1.7956652641296387
Batch 34/64 loss: 1.8334722518920898
Batch 35/64 loss: 1.740006923675537
Batch 36/64 loss: 1.925910472869873
Batch 37/64 loss: 1.599790096282959
Batch 38/64 loss: 1.8124499320983887
Batch 39/64 loss: 2.0429491996765137
Batch 40/64 loss: 1.7187209129333496
Batch 41/64 loss: 1.9265074729919434
Batch 42/64 loss: 1.738985538482666
Batch 43/64 loss: 1.833071231842041
Batch 44/64 loss: 1.8802123069763184
Batch 45/64 loss: 1.8831048011779785
Batch 46/64 loss: 1.7882542610168457
Batch 47/64 loss: 1.629603385925293
Batch 48/64 loss: 1.7184433937072754
Batch 49/64 loss: 1.631556510925293
Batch 50/64 loss: 1.9556775093078613
Batch 51/64 loss: 1.8148880004882812
Batch 52/64 loss: 1.9121308326721191
Batch 53/64 loss: 1.923905372619629
Batch 54/64 loss: 1.7798676490783691
Batch 55/64 loss: 1.8373327255249023
Batch 56/64 loss: 1.803487777709961
Batch 57/64 loss: 2.0709500312805176
Batch 58/64 loss: 1.9438490867614746
Batch 59/64 loss: 1.7209320068359375
Batch 60/64 loss: 1.9060101509094238
Batch 61/64 loss: 1.792959213256836
Batch 62/64 loss: 1.779350757598877
Batch 63/64 loss: 1.7067103385925293
Batch 64/64 loss: -1.5902009010314941
Epoch 173  Train loss: 1.7728090791141287  Val loss: 1.5490814549816434
Epoch 174
-------------------------------
Batch 1/64 loss: 1.7032322883605957
Batch 2/64 loss: 2.0355234146118164
Batch 3/64 loss: 1.7860474586486816
Batch 4/64 loss: 1.9159245491027832
Batch 5/64 loss: 1.8922309875488281
Batch 6/64 loss: 1.8996262550354004
Batch 7/64 loss: 1.795525074005127
Batch 8/64 loss: 2.0995612144470215
Batch 9/64 loss: 1.69789457321167
Batch 10/64 loss: 1.9108238220214844
Batch 11/64 loss: 1.6452736854553223
Batch 12/64 loss: 1.8181815147399902
Batch 13/64 loss: 1.7285327911376953
Batch 14/64 loss: 1.6825084686279297
Batch 15/64 loss: 2.0071659088134766
Batch 16/64 loss: 1.808462142944336
Batch 17/64 loss: 1.817981243133545
Batch 18/64 loss: 1.9136290550231934
Batch 19/64 loss: 1.681201457977295
Batch 20/64 loss: 1.8792991638183594
Batch 21/64 loss: 1.824854850769043
Batch 22/64 loss: 1.674180507659912
Batch 23/64 loss: 1.9034829139709473
Batch 24/64 loss: 1.8233013153076172
Batch 25/64 loss: 1.7780795097351074
Batch 26/64 loss: 1.678168773651123
Batch 27/64 loss: 1.9020195007324219
Batch 28/64 loss: 1.6304569244384766
Batch 29/64 loss: 1.6966071128845215
Batch 30/64 loss: 1.7429819107055664
Batch 31/64 loss: 1.6599373817443848
Batch 32/64 loss: 1.701897144317627
Batch 33/64 loss: 1.8614258766174316
Batch 34/64 loss: 1.8539443016052246
Batch 35/64 loss: 1.7614645957946777
Batch 36/64 loss: 1.7403674125671387
Batch 37/64 loss: 1.7641620635986328
Batch 38/64 loss: 1.765120506286621
Batch 39/64 loss: 1.7682123184204102
Batch 40/64 loss: 1.774083137512207
Batch 41/64 loss: 1.906954288482666
Batch 42/64 loss: 1.789179801940918
Batch 43/64 loss: 2.1288223266601562
Batch 44/64 loss: 1.7793083190917969
Batch 45/64 loss: 1.6092004776000977
Batch 46/64 loss: 1.701200008392334
Batch 47/64 loss: 1.8262710571289062
Batch 48/64 loss: 1.6351609230041504
Batch 49/64 loss: 1.6420488357543945
Batch 50/64 loss: 1.7991905212402344
Batch 51/64 loss: 1.6889047622680664
Batch 52/64 loss: 1.6469006538391113
Batch 53/64 loss: 1.6307721138000488
Batch 54/64 loss: 1.6650090217590332
Batch 55/64 loss: 1.715383529663086
Batch 56/64 loss: 1.7875547409057617
Batch 57/64 loss: 1.7654404640197754
Batch 58/64 loss: 1.7323393821716309
Batch 59/64 loss: 1.6981134414672852
Batch 60/64 loss: 1.721536636352539
Batch 61/64 loss: 1.7136468887329102
Batch 62/64 loss: 1.7621850967407227
Batch 63/64 loss: 1.672210693359375
Batch 64/64 loss: -1.5947136878967285
Epoch 174  Train loss: 1.7387399505166445  Val loss: 1.4765030313603247
Epoch 175
-------------------------------
Batch 1/64 loss: 1.818739891052246
Batch 2/64 loss: 1.6433472633361816
Batch 3/64 loss: 1.7386770248413086
Batch 4/64 loss: 1.711794376373291
Batch 5/64 loss: 1.7255778312683105
Batch 6/64 loss: 1.8394055366516113
Batch 7/64 loss: 1.6834611892700195
Batch 8/64 loss: 1.7739858627319336
Batch 9/64 loss: 1.7295374870300293
Batch 10/64 loss: 1.6759066581726074
Batch 11/64 loss: 1.6949081420898438
Batch 12/64 loss: 1.8109402656555176
Batch 13/64 loss: 1.7572908401489258
Batch 14/64 loss: 1.6556973457336426
Batch 15/64 loss: 1.8751630783081055
Batch 16/64 loss: 1.7288012504577637
Batch 17/64 loss: 1.8033771514892578
Batch 18/64 loss: 1.7482709884643555
Batch 19/64 loss: 2.4138669967651367
Batch 20/64 loss: 1.9450502395629883
Batch 21/64 loss: 1.9302010536193848
Batch 22/64 loss: 1.9455633163452148
Batch 23/64 loss: 1.7757601737976074
Batch 24/64 loss: 1.8749504089355469
Batch 25/64 loss: 1.821603775024414
Batch 26/64 loss: 1.7336888313293457
Batch 27/64 loss: 1.7630577087402344
Batch 28/64 loss: 1.6751537322998047
Batch 29/64 loss: 1.7325100898742676
Batch 30/64 loss: 1.8778505325317383
Batch 31/64 loss: 2.00645112991333
Batch 32/64 loss: 1.7840228080749512
Batch 33/64 loss: 1.7368354797363281
Batch 34/64 loss: 1.731715202331543
Batch 35/64 loss: 1.8696184158325195
Batch 36/64 loss: 1.8552074432373047
Batch 37/64 loss: 1.7851362228393555
Batch 38/64 loss: 1.958646297454834
Batch 39/64 loss: 1.8084373474121094
Batch 40/64 loss: 1.731156826019287
Batch 41/64 loss: 1.856205940246582
Batch 42/64 loss: 1.6547369956970215
Batch 43/64 loss: 1.7238082885742188
Batch 44/64 loss: 1.7644248008728027
Batch 45/64 loss: 1.9289050102233887
Batch 46/64 loss: 1.8946118354797363
Batch 47/64 loss: 1.653266429901123
Batch 48/64 loss: 1.9596471786499023
Batch 49/64 loss: 1.7388453483581543
Batch 50/64 loss: 1.6527013778686523
Batch 51/64 loss: 1.7208194732666016
Batch 52/64 loss: 1.7784662246704102
Batch 53/64 loss: 1.7937493324279785
Batch 54/64 loss: 1.8268795013427734
Batch 55/64 loss: 1.7159490585327148
Batch 56/64 loss: 1.7573418617248535
Batch 57/64 loss: 1.742340087890625
Batch 58/64 loss: 1.702770709991455
Batch 59/64 loss: 1.7821478843688965
Batch 60/64 loss: 1.8856134414672852
Batch 61/64 loss: 1.913590908050537
Batch 62/64 loss: 1.7691473960876465
Batch 63/64 loss: 1.5844926834106445
Batch 64/64 loss: -1.604346752166748
Epoch 175  Train loss: 1.753232437956567  Val loss: 1.5454414144824051
Epoch 176
-------------------------------
Batch 1/64 loss: 1.9695773124694824
Batch 2/64 loss: 1.9543776512145996
Batch 3/64 loss: 1.798828125
Batch 4/64 loss: 1.7471275329589844
Batch 5/64 loss: 1.7389812469482422
Batch 6/64 loss: 1.700871467590332
Batch 7/64 loss: 1.735762596130371
Batch 8/64 loss: 1.682075023651123
Batch 9/64 loss: 1.7510967254638672
Batch 10/64 loss: 1.7295222282409668
Batch 11/64 loss: 1.735668659210205
Batch 12/64 loss: 1.712073802947998
Batch 13/64 loss: 2.0321102142333984
Batch 14/64 loss: 1.7112817764282227
Batch 15/64 loss: 1.871811866760254
Batch 16/64 loss: 1.719743251800537
Batch 17/64 loss: 1.8688430786132812
Batch 18/64 loss: 1.7694315910339355
Batch 19/64 loss: 1.645981788635254
Batch 20/64 loss: 1.720405101776123
Batch 21/64 loss: 1.9246792793273926
Batch 22/64 loss: 1.9526443481445312
Batch 23/64 loss: 1.9434256553649902
Batch 24/64 loss: 1.7284836769104004
Batch 25/64 loss: 1.726550579071045
Batch 26/64 loss: 1.8005824089050293
Batch 27/64 loss: 1.7829275131225586
Batch 28/64 loss: 2.0704216957092285
Batch 29/64 loss: 1.7997856140136719
Batch 30/64 loss: 1.7276501655578613
Batch 31/64 loss: 1.6641597747802734
Batch 32/64 loss: 1.720141887664795
Batch 33/64 loss: 1.8266043663024902
Batch 34/64 loss: 1.680234432220459
Batch 35/64 loss: 2.19813871383667
Batch 36/64 loss: 1.7533397674560547
Batch 37/64 loss: 1.824659824371338
Batch 38/64 loss: 1.6976232528686523
Batch 39/64 loss: 1.7448029518127441
Batch 40/64 loss: 1.7750096321105957
Batch 41/64 loss: 1.8732752799987793
Batch 42/64 loss: 1.9983916282653809
Batch 43/64 loss: 1.880678653717041
Batch 44/64 loss: 1.8965635299682617
Batch 45/64 loss: 1.822099208831787
Batch 46/64 loss: 1.947129249572754
Batch 47/64 loss: 1.7274971008300781
Batch 48/64 loss: 1.7749199867248535
Batch 49/64 loss: 1.7847046852111816
Batch 50/64 loss: 1.8689961433410645
Batch 51/64 loss: 1.9511528015136719
Batch 52/64 loss: 1.877377986907959
Batch 53/64 loss: 1.9697837829589844
Batch 54/64 loss: 1.7069048881530762
Batch 55/64 loss: 1.7712793350219727
Batch 56/64 loss: 1.741884708404541
Batch 57/64 loss: 1.6253504753112793
Batch 58/64 loss: 1.8567595481872559
Batch 59/64 loss: 1.8191900253295898
Batch 60/64 loss: 1.742358684539795
Batch 61/64 loss: 2.0236716270446777
Batch 62/64 loss: 1.7938098907470703
Batch 63/64 loss: 1.9047036170959473
Batch 64/64 loss: -1.684575080871582
Epoch 176  Train loss: 1.7730586369832357  Val loss: 1.5666081929944224
Epoch 177
-------------------------------
Batch 1/64 loss: 1.827545166015625
Batch 2/64 loss: 1.7772727012634277
Batch 3/64 loss: 1.7811675071716309
Batch 4/64 loss: 1.9400830268859863
Batch 5/64 loss: 2.0278778076171875
Batch 6/64 loss: 1.8005104064941406
Batch 7/64 loss: 1.7660603523254395
Batch 8/64 loss: 1.6654791831970215
Batch 9/64 loss: 1.857649803161621
Batch 10/64 loss: 1.8802156448364258
Batch 11/64 loss: 1.7623333930969238
Batch 12/64 loss: 2.020681858062744
Batch 13/64 loss: 1.671837329864502
Batch 14/64 loss: 1.7712860107421875
Batch 15/64 loss: 1.996427059173584
Batch 16/64 loss: 1.8493175506591797
Batch 17/64 loss: 1.6843323707580566
Batch 18/64 loss: 1.8060226440429688
Batch 19/64 loss: 1.9247641563415527
Batch 20/64 loss: 1.8665218353271484
Batch 21/64 loss: 1.859384536743164
Batch 22/64 loss: 1.8211231231689453
Batch 23/64 loss: 1.8715763092041016
Batch 24/64 loss: 1.7676424980163574
Batch 25/64 loss: 1.8279318809509277
Batch 26/64 loss: 1.7430949211120605
Batch 27/64 loss: 1.7734274864196777
Batch 28/64 loss: 1.781148910522461
Batch 29/64 loss: 1.9507102966308594
Batch 30/64 loss: 1.8050661087036133
Batch 31/64 loss: 1.8178329467773438
Batch 32/64 loss: 1.8071823120117188
Batch 33/64 loss: 1.7465500831604004
Batch 34/64 loss: 1.9465947151184082
Batch 35/64 loss: 1.6993937492370605
Batch 36/64 loss: 1.9018430709838867
Batch 37/64 loss: 1.9751391410827637
Batch 38/64 loss: 1.8537259101867676
Batch 39/64 loss: 1.815232276916504
Batch 40/64 loss: 1.8159465789794922
Batch 41/64 loss: 1.7048215866088867
Batch 42/64 loss: 1.7525405883789062
Batch 43/64 loss: 1.9361214637756348
Batch 44/64 loss: 1.815025806427002
Batch 45/64 loss: 1.7606945037841797
Batch 46/64 loss: 1.717282772064209
Batch 47/64 loss: 1.869856357574463
Batch 48/64 loss: 2.21395206451416
Batch 49/64 loss: 1.986109733581543
Batch 50/64 loss: 1.77496337890625
Batch 51/64 loss: 1.7967400550842285
Batch 52/64 loss: 1.905106544494629
Batch 53/64 loss: 1.9089617729187012
Batch 54/64 loss: 1.9802861213684082
Batch 55/64 loss: 2.3916778564453125
Batch 56/64 loss: 1.9896445274353027
Batch 57/64 loss: 2.011270523071289
Batch 58/64 loss: 1.8685035705566406
Batch 59/64 loss: 1.8757834434509277
Batch 60/64 loss: 1.9778971672058105
Batch 61/64 loss: 1.959348201751709
Batch 62/64 loss: 1.927213191986084
Batch 63/64 loss: 1.8484077453613281
Batch 64/64 loss: -0.9208974838256836
Epoch 177  Train loss: 1.8280700945386699  Val loss: 1.707609884517709
Epoch 178
-------------------------------
Batch 1/64 loss: 2.077272415161133
Batch 2/64 loss: 1.7196660041809082
Batch 3/64 loss: 1.9526071548461914
Batch 4/64 loss: 1.9840764999389648
Batch 5/64 loss: 1.9224371910095215
Batch 6/64 loss: 1.7609295845031738
Batch 7/64 loss: 1.7942276000976562
Batch 8/64 loss: 1.8531928062438965
Batch 9/64 loss: 2.0279359817504883
Batch 10/64 loss: 1.8513054847717285
Batch 11/64 loss: 1.9293718338012695
Batch 12/64 loss: 1.9020309448242188
Batch 13/64 loss: 1.8363337516784668
Batch 14/64 loss: 2.1187844276428223
Batch 15/64 loss: 1.8534421920776367
Batch 16/64 loss: 1.7849655151367188
Batch 17/64 loss: 1.8279480934143066
Batch 18/64 loss: 1.8328123092651367
Batch 19/64 loss: 2.3507471084594727
Batch 20/64 loss: 1.8129940032958984
Batch 21/64 loss: 1.9255566596984863
Batch 22/64 loss: 1.9040513038635254
Batch 23/64 loss: 1.823859691619873
Batch 24/64 loss: 1.9348735809326172
Batch 25/64 loss: 1.7803783416748047
Batch 26/64 loss: 1.8191003799438477
Batch 27/64 loss: 1.768446922302246
Batch 28/64 loss: 2.156280040740967
Batch 29/64 loss: 2.2335128784179688
Batch 30/64 loss: 1.8195104598999023
Batch 31/64 loss: 1.9621634483337402
Batch 32/64 loss: 1.736875057220459
Batch 33/64 loss: 1.7894816398620605
Batch 34/64 loss: 2.0135726928710938
Batch 35/64 loss: 2.518319606781006
Batch 36/64 loss: 1.8931841850280762
Batch 37/64 loss: 2.016225814819336
Batch 38/64 loss: 1.9080586433410645
Batch 39/64 loss: 1.7072877883911133
Batch 40/64 loss: 1.9431405067443848
Batch 41/64 loss: 2.0228304862976074
Batch 42/64 loss: 1.8790202140808105
Batch 43/64 loss: 1.9442410469055176
Batch 44/64 loss: 2.1615819931030273
Batch 45/64 loss: 1.8280673027038574
Batch 46/64 loss: 1.97951078414917
Batch 47/64 loss: 1.829904556274414
Batch 48/64 loss: 1.879404067993164
Batch 49/64 loss: 1.8320550918579102
Batch 50/64 loss: 1.9178094863891602
Batch 51/64 loss: 1.8045940399169922
Batch 52/64 loss: 2.3608617782592773
Batch 53/64 loss: 1.943406581878662
Batch 54/64 loss: 2.364778995513916
Batch 55/64 loss: 1.880666732788086
Batch 56/64 loss: 2.0413808822631836
Batch 57/64 loss: 1.9023447036743164
Batch 58/64 loss: 1.823997974395752
Batch 59/64 loss: 2.417065143585205
Batch 60/64 loss: 1.7724385261535645
Batch 61/64 loss: 1.8386335372924805
Batch 62/64 loss: 1.998579502105713
Batch 63/64 loss: 1.9848766326904297
Batch 64/64 loss: -1.6052055358886719
Epoch 178  Train loss: 1.8988408855363434  Val loss: 1.756375624142152
Epoch 179
-------------------------------
Batch 1/64 loss: 1.7589707374572754
Batch 2/64 loss: 2.203148365020752
Batch 3/64 loss: 1.9409112930297852
Batch 4/64 loss: 1.8490238189697266
Batch 5/64 loss: 1.7346243858337402
Batch 6/64 loss: 1.802199363708496
Batch 7/64 loss: 2.0726776123046875
Batch 8/64 loss: 1.9108333587646484
Batch 9/64 loss: 2.7157034873962402
Batch 10/64 loss: 1.9291210174560547
Batch 11/64 loss: 2.3981313705444336
Batch 12/64 loss: 2.0815467834472656
Batch 13/64 loss: 1.7954931259155273
Batch 14/64 loss: 1.7886590957641602
Batch 15/64 loss: 1.8046455383300781
Batch 16/64 loss: 1.7839841842651367
Batch 17/64 loss: 1.9783782958984375
Batch 18/64 loss: 1.9883050918579102
Batch 19/64 loss: 2.3040199279785156
Batch 20/64 loss: 1.9699645042419434
Batch 21/64 loss: 2.1921210289001465
Batch 22/64 loss: 2.3100223541259766
Batch 23/64 loss: 1.9387621879577637
Batch 24/64 loss: 2.290006160736084
Batch 25/64 loss: 1.906416893005371
Batch 26/64 loss: 2.1792397499084473
Batch 27/64 loss: 2.0017566680908203
Batch 28/64 loss: 2.1318531036376953
Batch 29/64 loss: 2.1719894409179688
Batch 30/64 loss: 2.3136558532714844
Batch 31/64 loss: 2.2033772468566895
Batch 32/64 loss: 2.376859664916992
Batch 33/64 loss: 1.845191478729248
Batch 34/64 loss: 2.9432387351989746
Batch 35/64 loss: 5.009495735168457
Batch 36/64 loss: 2.018637180328369
Batch 37/64 loss: 2.1261725425720215
Batch 38/64 loss: 2.1789865493774414
Batch 39/64 loss: 2.402170181274414
Batch 40/64 loss: 4.739562511444092
Batch 41/64 loss: 2.7716665267944336
Batch 42/64 loss: 2.0754661560058594
Batch 43/64 loss: 2.0974197387695312
Batch 44/64 loss: 2.1947946548461914
Batch 45/64 loss: 2.045163154602051
Batch 46/64 loss: 3.640658378601074
Batch 47/64 loss: 2.048839569091797
Batch 48/64 loss: 2.0566396713256836
Batch 49/64 loss: 2.0750932693481445
Batch 50/64 loss: 2.0135574340820312
Batch 51/64 loss: 2.109633445739746
Batch 52/64 loss: 2.037753105163574
Batch 53/64 loss: 1.9754571914672852
Batch 54/64 loss: 2.3449316024780273
Batch 55/64 loss: 2.0461339950561523
Batch 56/64 loss: 2.117480754852295
Batch 57/64 loss: 2.328990936279297
Batch 58/64 loss: 3.4312353134155273
Batch 59/64 loss: 2.0961475372314453
Batch 60/64 loss: 3.5880303382873535
Batch 61/64 loss: 2.1341543197631836
Batch 62/64 loss: 2.5879993438720703
Batch 63/64 loss: 2.4689455032348633
Batch 64/64 loss: -0.20683002471923828
Epoch 179  Train loss: 2.246602761511709  Val loss: 2.8709366002033665
Epoch 180
-------------------------------
Batch 1/64 loss: 2.714071273803711
Batch 2/64 loss: 2.674534320831299
Batch 3/64 loss: 2.6896939277648926
Batch 4/64 loss: 2.73779296875
Batch 5/64 loss: 4.877522945404053
Batch 6/64 loss: 3.0178613662719727
Batch 7/64 loss: 3.1954188346862793
Batch 8/64 loss: 3.417478084564209
Batch 9/64 loss: 3.16033935546875
Batch 10/64 loss: 3.5239810943603516
Batch 11/64 loss: 3.076810359954834
Batch 12/64 loss: 3.449653148651123
Batch 13/64 loss: 3.2693376541137695
Batch 14/64 loss: 2.852414131164551
Batch 15/64 loss: 7.366652488708496
Batch 16/64 loss: 3.4265594482421875
Batch 17/64 loss: 4.872992515563965
Batch 18/64 loss: 3.420225143432617
Batch 19/64 loss: 3.595700263977051
Batch 20/64 loss: 4.084071636199951
Batch 21/64 loss: 3.0755319595336914
Batch 22/64 loss: 3.91861629486084
Batch 23/64 loss: 3.091233730316162
Batch 24/64 loss: 3.5270276069641113
Batch 25/64 loss: 3.2247490882873535
Batch 26/64 loss: 2.977254867553711
Batch 27/64 loss: 2.7372617721557617
Batch 28/64 loss: 3.007270336151123
Batch 29/64 loss: 2.8894829750061035
Batch 30/64 loss: 3.262498378753662
Batch 31/64 loss: 2.9395313262939453
Batch 32/64 loss: 2.9012880325317383
Batch 33/64 loss: 2.8830223083496094
Batch 34/64 loss: 3.2199807167053223
Batch 35/64 loss: 2.5671887397766113
Batch 36/64 loss: 2.6701865196228027
Batch 37/64 loss: 2.4878320693969727
Batch 38/64 loss: 5.313732624053955
Batch 39/64 loss: 2.640791416168213
Batch 40/64 loss: 3.8027749061584473
Batch 41/64 loss: 5.491275787353516
Batch 42/64 loss: 3.1950817108154297
Batch 43/64 loss: 3.750251293182373
Batch 44/64 loss: 2.733591079711914
Batch 45/64 loss: 2.62795352935791
Batch 46/64 loss: 2.6126608848571777
Batch 47/64 loss: 3.4009594917297363
Batch 48/64 loss: 2.401841640472412
Batch 49/64 loss: 3.340397357940674
Batch 50/64 loss: 2.254258632659912
Batch 51/64 loss: 2.436939239501953
Batch 52/64 loss: 4.950368881225586
Batch 53/64 loss: 2.3720145225524902
Batch 54/64 loss: 2.449631690979004
Batch 55/64 loss: 2.544936180114746
Batch 56/64 loss: 2.6732940673828125
Batch 57/64 loss: 2.3050832748413086
Batch 58/64 loss: 2.469285011291504
Batch 59/64 loss: 2.1987252235412598
Batch 60/64 loss: 2.9961066246032715
Batch 61/64 loss: 2.626415252685547
Batch 62/64 loss: 2.2140884399414062
Batch 63/64 loss: 2.343721866607666
Batch 64/64 loss: -1.2193775177001953
Epoch 180  Train loss: 3.1377994537353517  Val loss: 2.1824333872582087
Epoch 181
-------------------------------
Batch 1/64 loss: 2.1864099502563477
Batch 2/64 loss: 4.652419090270996
Batch 3/64 loss: 2.330477714538574
Batch 4/64 loss: 3.031761646270752
Batch 5/64 loss: 2.6394362449645996
Batch 6/64 loss: 2.299257278442383
Batch 7/64 loss: 2.3255953788757324
Batch 8/64 loss: 2.276519298553467
Batch 9/64 loss: 2.291635036468506
Batch 10/64 loss: 2.373852252960205
Batch 11/64 loss: 2.245267868041992
Batch 12/64 loss: 2.5625157356262207
Batch 13/64 loss: 2.2261061668395996
Batch 14/64 loss: 2.1619815826416016
Batch 15/64 loss: 2.4470396041870117
Batch 16/64 loss: 2.3300509452819824
Batch 17/64 loss: 2.1517906188964844
Batch 18/64 loss: 2.394606113433838
Batch 19/64 loss: 2.5990004539489746
Batch 20/64 loss: 2.761237621307373
Batch 21/64 loss: 2.5314650535583496
Batch 22/64 loss: 2.2692131996154785
Batch 23/64 loss: 2.1330552101135254
Batch 24/64 loss: 3.516284942626953
Batch 25/64 loss: 2.409482479095459
Batch 26/64 loss: 2.0856199264526367
Batch 27/64 loss: 2.1458263397216797
Batch 28/64 loss: 2.153430461883545
Batch 29/64 loss: 2.1099767684936523
Batch 30/64 loss: 3.4132280349731445
Batch 31/64 loss: 1.9949803352355957
Batch 32/64 loss: 2.8821539878845215
Batch 33/64 loss: 2.183457374572754
Batch 34/64 loss: 2.1020541191101074
Batch 35/64 loss: 2.124908924102783
Batch 36/64 loss: 2.2879953384399414
Batch 37/64 loss: 2.285153865814209
Batch 38/64 loss: 2.240480899810791
Batch 39/64 loss: 2.4473958015441895
Batch 40/64 loss: 2.451383590698242
Batch 41/64 loss: 2.0184755325317383
Batch 42/64 loss: 2.2530131340026855
Batch 43/64 loss: 2.4553298950195312
Batch 44/64 loss: 2.1208009719848633
Batch 45/64 loss: 2.1413516998291016
Batch 46/64 loss: 5.171904563903809
Batch 47/64 loss: 2.431816577911377
Batch 48/64 loss: 2.5020551681518555
Batch 49/64 loss: 2.397512912750244
Batch 50/64 loss: 2.006964683532715
Batch 51/64 loss: 2.0243401527404785
Batch 52/64 loss: 3.638688564300537
Batch 53/64 loss: 2.109412670135498
Batch 54/64 loss: 2.1420745849609375
Batch 55/64 loss: 1.9085216522216797
Batch 56/64 loss: 2.117640495300293
Batch 57/64 loss: 4.792893409729004
Batch 58/64 loss: 2.0718588829040527
Batch 59/64 loss: 2.406864643096924
Batch 60/64 loss: 1.9648680686950684
Batch 61/64 loss: 2.274059772491455
Batch 62/64 loss: 2.1068382263183594
Batch 63/64 loss: 2.1800012588500977
Batch 64/64 loss: -1.4233207702636719
Epoch 181  Train loss: 2.419204771752451  Val loss: 1.9015419950190278
Epoch 182
-------------------------------
Batch 1/64 loss: 1.9664034843444824
Batch 2/64 loss: 2.441152572631836
Batch 3/64 loss: 2.0010390281677246
Batch 4/64 loss: 1.980764389038086
Batch 5/64 loss: 2.0876126289367676
Batch 6/64 loss: 2.263453960418701
Batch 7/64 loss: 2.1807098388671875
Batch 8/64 loss: 2.9134044647216797
Batch 9/64 loss: 2.7536983489990234
Batch 10/64 loss: 2.0635781288146973
Batch 11/64 loss: 2.35115909576416
Batch 12/64 loss: 2.3432579040527344
Batch 13/64 loss: 2.4780354499816895
Batch 14/64 loss: 5.28704309463501
Batch 15/64 loss: 2.4349141120910645
Batch 16/64 loss: 5.671728610992432
Batch 17/64 loss: 2.922152042388916
Batch 18/64 loss: 3.5605525970458984
Batch 19/64 loss: 2.86910343170166
Batch 20/64 loss: 3.5035691261291504
Batch 21/64 loss: 2.2603259086608887
Batch 22/64 loss: 2.3959879875183105
Batch 23/64 loss: 2.476182460784912
Batch 24/64 loss: 2.5387587547302246
Batch 25/64 loss: 2.3122873306274414
Batch 26/64 loss: 2.55397891998291
Batch 27/64 loss: 2.3106985092163086
Batch 28/64 loss: 3.176867961883545
Batch 29/64 loss: 2.552790641784668
Batch 30/64 loss: 4.491111755371094
Batch 31/64 loss: 2.0984034538269043
Batch 32/64 loss: 2.346522331237793
Batch 33/64 loss: 2.8923397064208984
Batch 34/64 loss: 2.7098326683044434
Batch 35/64 loss: 2.6087088584899902
Batch 36/64 loss: 3.0653815269470215
Batch 37/64 loss: 2.551422119140625
Batch 38/64 loss: 2.2451353073120117
Batch 39/64 loss: 2.10369873046875
Batch 40/64 loss: 2.079258441925049
Batch 41/64 loss: 5.091136932373047
Batch 42/64 loss: 2.036952495574951
Batch 43/64 loss: 2.2124686241149902
Batch 44/64 loss: 2.166426181793213
Batch 45/64 loss: 2.468234062194824
Batch 46/64 loss: 2.1654796600341797
Batch 47/64 loss: 2.0774340629577637
Batch 48/64 loss: 1.934157371520996
Batch 49/64 loss: 2.3424720764160156
Batch 50/64 loss: 2.3540048599243164
Batch 51/64 loss: 1.9903841018676758
Batch 52/64 loss: 2.0673184394836426
Batch 53/64 loss: 2.6331686973571777
Batch 54/64 loss: 2.000105381011963
Batch 55/64 loss: 2.1551976203918457
Batch 56/64 loss: 2.1217103004455566
Batch 57/64 loss: 2.0253825187683105
Batch 58/64 loss: 2.0216522216796875
Batch 59/64 loss: 2.0377278327941895
Batch 60/64 loss: 2.0884151458740234
Batch 61/64 loss: 2.075718879699707
Batch 62/64 loss: 4.3885297775268555
Batch 63/64 loss: 2.737429618835449
Batch 64/64 loss: -1.2639684677124023
Epoch 182  Train loss: 2.5425342148425534  Val loss: 1.8726348352596112
Epoch 183
-------------------------------
Batch 1/64 loss: 2.43621826171875
Batch 2/64 loss: 2.5431909561157227
Batch 3/64 loss: 2.1164469718933105
Batch 4/64 loss: 2.1251840591430664
Batch 5/64 loss: 2.11472225189209
Batch 6/64 loss: 2.1650400161743164
Batch 7/64 loss: 2.037492275238037
Batch 8/64 loss: 2.319031238555908
Batch 9/64 loss: 2.012061595916748
Batch 10/64 loss: 1.970472812652588
Batch 11/64 loss: 3.497981071472168
Batch 12/64 loss: 2.1010375022888184
Batch 13/64 loss: 3.1330699920654297
Batch 14/64 loss: 2.0190725326538086
Batch 15/64 loss: 2.0579285621643066
Batch 16/64 loss: 2.140209674835205
Batch 17/64 loss: 2.0101804733276367
Batch 18/64 loss: 2.038431167602539
Batch 19/64 loss: 2.0884222984313965
Batch 20/64 loss: 2.104020595550537
Batch 21/64 loss: 2.3836679458618164
Batch 22/64 loss: 4.290120601654053
Batch 23/64 loss: 1.855909824371338
Batch 24/64 loss: 1.90771484375
Batch 25/64 loss: 2.081996440887451
Batch 26/64 loss: 4.880667686462402
Batch 27/64 loss: 1.945326805114746
Batch 28/64 loss: 2.0427637100219727
Batch 29/64 loss: 2.1162571907043457
Batch 30/64 loss: 2.1188673973083496
Batch 31/64 loss: 2.6947531700134277
Batch 32/64 loss: 2.128070831298828
Batch 33/64 loss: 2.394967555999756
Batch 34/64 loss: 2.372811794281006
Batch 35/64 loss: 2.0291709899902344
Batch 36/64 loss: 2.06337833404541
Batch 37/64 loss: 2.124208927154541
Batch 38/64 loss: 2.1413588523864746
Batch 39/64 loss: 3.000089168548584
Batch 40/64 loss: 2.0846681594848633
Batch 41/64 loss: 2.165968418121338
Batch 42/64 loss: 1.8777852058410645
Batch 43/64 loss: 1.9077367782592773
Batch 44/64 loss: 2.0208306312561035
Batch 45/64 loss: 2.0023412704467773
Batch 46/64 loss: 2.032898426055908
Batch 47/64 loss: 2.013291358947754
Batch 48/64 loss: 2.1225695610046387
Batch 49/64 loss: 3.391493797302246
Batch 50/64 loss: 2.0230283737182617
Batch 51/64 loss: 2.082587718963623
Batch 52/64 loss: 2.1614537239074707
Batch 53/64 loss: 2.037569522857666
Batch 54/64 loss: 2.3260364532470703
Batch 55/64 loss: 2.149883270263672
Batch 56/64 loss: 2.0357556343078613
Batch 57/64 loss: 2.037745475769043
Batch 58/64 loss: 4.843011856079102
Batch 59/64 loss: 1.9624485969543457
Batch 60/64 loss: 2.0757274627685547
Batch 61/64 loss: 2.0148749351501465
Batch 62/64 loss: 2.2132930755615234
Batch 63/64 loss: 2.0724563598632812
Batch 64/64 loss: -0.9954919815063477
Epoch 183  Train loss: 2.2668416228948853  Val loss: 1.870206242984103
Epoch 184
-------------------------------
Batch 1/64 loss: 2.3285274505615234
Batch 2/64 loss: 2.583275318145752
Batch 3/64 loss: 2.1393914222717285
Batch 4/64 loss: 2.204267978668213
Batch 5/64 loss: 2.1251587867736816
Batch 6/64 loss: 2.3624820709228516
Batch 7/64 loss: 1.9495224952697754
Batch 8/64 loss: 1.9314932823181152
Batch 9/64 loss: 2.508938789367676
Batch 10/64 loss: 2.0098962783813477
Batch 11/64 loss: 2.1577038764953613
Batch 12/64 loss: 2.4638562202453613
Batch 13/64 loss: 2.0116357803344727
Batch 14/64 loss: 1.9963045120239258
Batch 15/64 loss: 2.1286449432373047
Batch 16/64 loss: 2.1169004440307617
Batch 17/64 loss: 4.6132659912109375
Batch 18/64 loss: 1.9073591232299805
Batch 19/64 loss: 2.049767017364502
Batch 20/64 loss: 2.228329658508301
Batch 21/64 loss: 2.3339829444885254
Batch 22/64 loss: 2.318495750427246
Batch 23/64 loss: 2.111922264099121
Batch 24/64 loss: 1.8853416442871094
Batch 25/64 loss: 1.9223999977111816
Batch 26/64 loss: 2.8444886207580566
Batch 27/64 loss: 1.933304786682129
Batch 28/64 loss: 2.3224587440490723
Batch 29/64 loss: 1.8790178298950195
Batch 30/64 loss: 2.19248104095459
Batch 31/64 loss: 2.0522212982177734
Batch 32/64 loss: 6.268743991851807
Batch 33/64 loss: 1.9888334274291992
Batch 34/64 loss: 2.3481674194335938
Batch 35/64 loss: 4.305229663848877
Batch 36/64 loss: 2.0602617263793945
Batch 37/64 loss: 2.0902509689331055
Batch 38/64 loss: 2.0380821228027344
Batch 39/64 loss: 1.9993791580200195
Batch 40/64 loss: 3.148374080657959
Batch 41/64 loss: 1.960540771484375
Batch 42/64 loss: 2.199549674987793
Batch 43/64 loss: 1.966353416442871
Batch 44/64 loss: 2.0367507934570312
Batch 45/64 loss: 2.072688579559326
Batch 46/64 loss: 1.9058380126953125
Batch 47/64 loss: 3.184231758117676
Batch 48/64 loss: 2.0135793685913086
Batch 49/64 loss: 2.1806082725524902
Batch 50/64 loss: 2.056650161743164
Batch 51/64 loss: 2.2174320220947266
Batch 52/64 loss: 1.9352984428405762
Batch 53/64 loss: 1.9047565460205078
Batch 54/64 loss: 2.228921890258789
Batch 55/64 loss: 2.782041072845459
Batch 56/64 loss: 1.9143924713134766
Batch 57/64 loss: 1.8767151832580566
Batch 58/64 loss: 2.2775912284851074
Batch 59/64 loss: 2.168699264526367
Batch 60/64 loss: 1.9732012748718262
Batch 61/64 loss: 1.9596552848815918
Batch 62/64 loss: 1.9970970153808594
Batch 63/64 loss: 2.0594606399536133
Batch 64/64 loss: -1.5003538131713867
Epoch 184  Train loss: 2.2526579875572055  Val loss: 1.776912335268001
Epoch 185
-------------------------------
Batch 1/64 loss: 1.787477970123291
Batch 2/64 loss: 1.8771486282348633
Batch 3/64 loss: 1.8757562637329102
Batch 4/64 loss: 2.596336841583252
Batch 5/64 loss: 2.7085013389587402
Batch 6/64 loss: 1.9968647956848145
Batch 7/64 loss: 2.0732579231262207
Batch 8/64 loss: 2.197612762451172
Batch 9/64 loss: 1.930312156677246
Batch 10/64 loss: 1.9541869163513184
Batch 11/64 loss: 2.2236266136169434
Batch 12/64 loss: 2.306001663208008
Batch 13/64 loss: 2.0104808807373047
Batch 14/64 loss: 2.034608840942383
Batch 15/64 loss: 2.095008373260498
Batch 16/64 loss: 2.0234885215759277
Batch 17/64 loss: 1.9834108352661133
Batch 18/64 loss: 2.196352481842041
Batch 19/64 loss: 1.964963436126709
Batch 20/64 loss: 1.949472427368164
Batch 21/64 loss: 1.9697847366333008
Batch 22/64 loss: 2.3133926391601562
Batch 23/64 loss: 2.086402416229248
Batch 24/64 loss: 2.205562114715576
Batch 25/64 loss: 1.9032397270202637
Batch 26/64 loss: 4.897839546203613
Batch 27/64 loss: 1.953580379486084
Batch 28/64 loss: 4.313039779663086
Batch 29/64 loss: 1.9022903442382812
Batch 30/64 loss: 1.9331140518188477
Batch 31/64 loss: 2.09462833404541
Batch 32/64 loss: 2.9230117797851562
Batch 33/64 loss: 1.8766217231750488
Batch 34/64 loss: 4.914601802825928
Batch 35/64 loss: 1.7463345527648926
Batch 36/64 loss: 2.161520481109619
Batch 37/64 loss: 2.039853572845459
Batch 38/64 loss: 1.8691911697387695
Batch 39/64 loss: 2.1541857719421387
Batch 40/64 loss: 2.2103452682495117
Batch 41/64 loss: 1.92718505859375
Batch 42/64 loss: 2.0523033142089844
Batch 43/64 loss: 2.112476348876953
Batch 44/64 loss: 2.1432442665100098
Batch 45/64 loss: 1.8010358810424805
Batch 46/64 loss: 1.8954815864562988
Batch 47/64 loss: 1.8434481620788574
Batch 48/64 loss: 1.989738941192627
Batch 49/64 loss: 1.902994155883789
Batch 50/64 loss: 2.19598388671875
Batch 51/64 loss: 2.0070905685424805
Batch 52/64 loss: 1.9872984886169434
Batch 53/64 loss: 1.8760957717895508
Batch 54/64 loss: 1.9670724868774414
Batch 55/64 loss: 2.9927268028259277
Batch 56/64 loss: 1.895998477935791
Batch 57/64 loss: 1.856522560119629
Batch 58/64 loss: 1.8806991577148438
Batch 59/64 loss: 1.9987750053405762
Batch 60/64 loss: 2.3353452682495117
Batch 61/64 loss: 1.8801093101501465
Batch 62/64 loss: 3.3790969848632812
Batch 63/64 loss: 2.1333770751953125
Batch 64/64 loss: -1.4883689880371094
Epoch 185  Train loss: 2.1677056106866575  Val loss: 1.722812836112845
Epoch 186
-------------------------------
Batch 1/64 loss: 1.8970303535461426
Batch 2/64 loss: 2.0217294692993164
Batch 3/64 loss: 1.9630827903747559
Batch 4/64 loss: 2.1826791763305664
Batch 5/64 loss: 5.005837440490723
Batch 6/64 loss: 2.01090145111084
Batch 7/64 loss: 1.991459846496582
Batch 8/64 loss: 1.882833480834961
Batch 9/64 loss: 3.267087459564209
Batch 10/64 loss: 1.8874540328979492
Batch 11/64 loss: 2.6176228523254395
Batch 12/64 loss: 1.891739845275879
Batch 13/64 loss: 2.1588797569274902
Batch 14/64 loss: 1.9366955757141113
Batch 15/64 loss: 2.5433297157287598
Batch 16/64 loss: 1.8922901153564453
Batch 17/64 loss: 1.967529296875
Batch 18/64 loss: 2.2405338287353516
Batch 19/64 loss: 1.9866390228271484
Batch 20/64 loss: 1.8120970726013184
Batch 21/64 loss: 2.3424320220947266
Batch 22/64 loss: 1.9154143333435059
Batch 23/64 loss: 1.918161392211914
Batch 24/64 loss: 1.9378504753112793
Batch 25/64 loss: 2.0170578956604004
Batch 26/64 loss: 1.7418994903564453
Batch 27/64 loss: 2.1362171173095703
Batch 28/64 loss: 2.103699207305908
Batch 29/64 loss: 2.2171006202697754
Batch 30/64 loss: 2.461120128631592
Batch 31/64 loss: 3.2777271270751953
Batch 32/64 loss: 4.408734321594238
Batch 33/64 loss: 1.9799599647521973
Batch 34/64 loss: 1.9625587463378906
Batch 35/64 loss: 1.8513436317443848
Batch 36/64 loss: 2.406515598297119
Batch 37/64 loss: 1.851454257965088
Batch 38/64 loss: 1.9013023376464844
Batch 39/64 loss: 1.90855073928833
Batch 40/64 loss: 2.4238715171813965
Batch 41/64 loss: 1.857161521911621
Batch 42/64 loss: 2.946959972381592
Batch 43/64 loss: 1.8700737953186035
Batch 44/64 loss: 1.853111743927002
Batch 45/64 loss: 1.9506120681762695
Batch 46/64 loss: 4.268218517303467
Batch 47/64 loss: 1.8792214393615723
Batch 48/64 loss: 2.1125283241271973
Batch 49/64 loss: 2.132509231567383
Batch 50/64 loss: 1.910599708557129
Batch 51/64 loss: 2.089419364929199
Batch 52/64 loss: 2.114954948425293
Batch 53/64 loss: 1.898493766784668
Batch 54/64 loss: 2.1285643577575684
Batch 55/64 loss: 2.0724453926086426
Batch 56/64 loss: 1.8877825736999512
Batch 57/64 loss: 2.527289390563965
Batch 58/64 loss: 1.8999156951904297
Batch 59/64 loss: 1.9556074142456055
Batch 60/64 loss: 2.000473976135254
Batch 61/64 loss: 2.199643135070801
Batch 62/64 loss: 1.9072155952453613
Batch 63/64 loss: 1.8858728408813477
Batch 64/64 loss: -1.5516281127929688
Epoch 186  Train loss: 2.1663588579963236  Val loss: 1.7413741829469032
Epoch 187
-------------------------------
Batch 1/64 loss: 1.8817243576049805
Batch 2/64 loss: 2.218186855316162
Batch 3/64 loss: 1.8319826126098633
Batch 4/64 loss: 1.9449248313903809
Batch 5/64 loss: 1.9298367500305176
Batch 6/64 loss: 1.9648480415344238
Batch 7/64 loss: 1.8588085174560547
Batch 8/64 loss: 1.8827424049377441
Batch 9/64 loss: 1.979301929473877
Batch 10/64 loss: 1.9884767532348633
Batch 11/64 loss: 1.9321322441101074
Batch 12/64 loss: 1.957282543182373
Batch 13/64 loss: 1.89085054397583
Batch 14/64 loss: 2.052496910095215
Batch 15/64 loss: 2.111457347869873
Batch 16/64 loss: 2.2204861640930176
Batch 17/64 loss: 1.8356084823608398
Batch 18/64 loss: 1.8972325325012207
Batch 19/64 loss: 2.360565185546875
Batch 20/64 loss: 2.183523654937744
Batch 21/64 loss: 2.0143165588378906
Batch 22/64 loss: 1.9780364036560059
Batch 23/64 loss: 2.0454611778259277
Batch 24/64 loss: 2.1946325302124023
Batch 25/64 loss: 2.1691250801086426
Batch 26/64 loss: 5.1924591064453125
Batch 27/64 loss: 2.3039112091064453
Batch 28/64 loss: 3.304838180541992
Batch 29/64 loss: 1.9818005561828613
Batch 30/64 loss: 2.331806182861328
Batch 31/64 loss: 2.01448917388916
Batch 32/64 loss: 2.066315174102783
Batch 33/64 loss: 3.541891574859619
Batch 34/64 loss: 1.97041654586792
Batch 35/64 loss: 3.737359046936035
Batch 36/64 loss: 2.2955222129821777
Batch 37/64 loss: 2.050416946411133
Batch 38/64 loss: 1.9901118278503418
Batch 39/64 loss: 2.1737923622131348
Batch 40/64 loss: 2.740447998046875
Batch 41/64 loss: 1.9773311614990234
Batch 42/64 loss: 2.432981491088867
Batch 43/64 loss: 2.367959499359131
Batch 44/64 loss: 2.4029970169067383
Batch 45/64 loss: 2.350832939147949
Batch 46/64 loss: 2.8099746704101562
Batch 47/64 loss: 2.483900547027588
Batch 48/64 loss: 2.3443641662597656
Batch 49/64 loss: 5.0513129234313965
Batch 50/64 loss: 2.170179843902588
Batch 51/64 loss: 2.4112467765808105
Batch 52/64 loss: 2.019521713256836
Batch 53/64 loss: 2.6971840858459473
Batch 54/64 loss: 2.241210460662842
Batch 55/64 loss: 2.7033886909484863
Batch 56/64 loss: 2.1412272453308105
Batch 57/64 loss: 2.259122848510742
Batch 58/64 loss: 2.696281909942627
Batch 59/64 loss: 4.987735748291016
Batch 60/64 loss: 4.140170097351074
Batch 61/64 loss: 2.0797433853149414
Batch 62/64 loss: 2.1588058471679688
Batch 63/64 loss: 2.0988149642944336
Batch 64/64 loss: -0.5744256973266602
Epoch 187  Train loss: 2.36258960424685  Val loss: 2.1093820722652055
Epoch 188
-------------------------------
Batch 1/64 loss: 2.0526628494262695
Batch 2/64 loss: 2.277235984802246
Batch 3/64 loss: 2.6564903259277344
Batch 4/64 loss: 3.8117103576660156
Batch 5/64 loss: 3.1404991149902344
Batch 6/64 loss: 2.038968563079834
Batch 7/64 loss: 2.177578926086426
Batch 8/64 loss: 2.531426429748535
Batch 9/64 loss: 1.986738681793213
Batch 10/64 loss: 2.2437362670898438
Batch 11/64 loss: 2.167403221130371
Batch 12/64 loss: 2.2516989707946777
Batch 13/64 loss: 2.502049446105957
Batch 14/64 loss: 1.9654607772827148
Batch 15/64 loss: 1.9582290649414062
Batch 16/64 loss: 2.1422505378723145
Batch 17/64 loss: 2.3070945739746094
Batch 18/64 loss: 2.4242467880249023
Batch 19/64 loss: 1.9325709342956543
Batch 20/64 loss: 2.0382142066955566
Batch 21/64 loss: 1.892514705657959
Batch 22/64 loss: 2.213521957397461
Batch 23/64 loss: 3.039440631866455
Batch 24/64 loss: 1.9428563117980957
Batch 25/64 loss: 1.927628517150879
Batch 26/64 loss: 1.9443445205688477
Batch 27/64 loss: 2.115877628326416
Batch 28/64 loss: 2.168485641479492
Batch 29/64 loss: 3.281190872192383
Batch 30/64 loss: 2.2590527534484863
Batch 31/64 loss: 2.029684066772461
Batch 32/64 loss: 1.945734977722168
Batch 33/64 loss: 2.118156909942627
Batch 34/64 loss: 2.2370829582214355
Batch 35/64 loss: 1.8846511840820312
Batch 36/64 loss: 4.615749835968018
Batch 37/64 loss: 2.7145895957946777
Batch 38/64 loss: 1.9507794380187988
Batch 39/64 loss: 1.9772119522094727
Batch 40/64 loss: 2.0600318908691406
Batch 41/64 loss: 1.8721675872802734
Batch 42/64 loss: 1.8926210403442383
Batch 43/64 loss: 1.8726916313171387
Batch 44/64 loss: 2.008535385131836
Batch 45/64 loss: 2.044724464416504
Batch 46/64 loss: 1.841902732849121
Batch 47/64 loss: 1.9407687187194824
Batch 48/64 loss: 2.2659831047058105
Batch 49/64 loss: 2.319305896759033
Batch 50/64 loss: 2.030117988586426
Batch 51/64 loss: 2.507236957550049
Batch 52/64 loss: 2.02766752243042
Batch 53/64 loss: 2.4768595695495605
Batch 54/64 loss: 1.936166763305664
Batch 55/64 loss: 2.0560684204101562
Batch 56/64 loss: 1.940845012664795
Batch 57/64 loss: 2.0569205284118652
Batch 58/64 loss: 1.9722347259521484
Batch 59/64 loss: 4.8686323165893555
Batch 60/64 loss: 4.534713268280029
Batch 61/64 loss: 1.961817741394043
Batch 62/64 loss: 2.2361631393432617
Batch 63/64 loss: 2.500217914581299
Batch 64/64 loss: -1.4124908447265625
Epoch 188  Train loss: 2.274977986952838  Val loss: 1.7897335786590052
Epoch 189
-------------------------------
Batch 1/64 loss: 2.286545753479004
Batch 2/64 loss: 3.089315891265869
Batch 3/64 loss: 2.1345949172973633
Batch 4/64 loss: 2.556854248046875
Batch 5/64 loss: 1.9832019805908203
Batch 6/64 loss: 2.022955894470215
Batch 7/64 loss: 2.037051200866699
Batch 8/64 loss: 1.9289112091064453
Batch 9/64 loss: 2.067537784576416
Batch 10/64 loss: 2.0675883293151855
Batch 11/64 loss: 1.8017120361328125
Batch 12/64 loss: 1.8078298568725586
Batch 13/64 loss: 2.063490390777588
Batch 14/64 loss: 4.448905944824219
Batch 15/64 loss: 2.090646743774414
Batch 16/64 loss: 1.8721494674682617
Batch 17/64 loss: 1.8441615104675293
Batch 18/64 loss: 2.1315765380859375
Batch 19/64 loss: 2.1085381507873535
Batch 20/64 loss: 1.974764347076416
Batch 21/64 loss: 1.957611083984375
Batch 22/64 loss: 1.8345069885253906
Batch 23/64 loss: 2.344578266143799
Batch 24/64 loss: 1.999560832977295
Batch 25/64 loss: 2.041297435760498
Batch 26/64 loss: 2.023033618927002
Batch 27/64 loss: 2.0316333770751953
Batch 28/64 loss: 2.9947423934936523
Batch 29/64 loss: 2.189546585083008
Batch 30/64 loss: 3.4167985916137695
Batch 31/64 loss: 2.852050304412842
Batch 32/64 loss: 2.119764804840088
Batch 33/64 loss: 1.8774523735046387
Batch 34/64 loss: 1.849754810333252
Batch 35/64 loss: 1.8671293258666992
Batch 36/64 loss: 1.946782112121582
Batch 37/64 loss: 2.656728744506836
Batch 38/64 loss: 1.9070625305175781
Batch 39/64 loss: 2.0583224296569824
Batch 40/64 loss: 2.0253853797912598
Batch 41/64 loss: 2.568593978881836
Batch 42/64 loss: 2.0493383407592773
Batch 43/64 loss: 2.091501235961914
Batch 44/64 loss: 1.9799375534057617
Batch 45/64 loss: 1.8430871963500977
Batch 46/64 loss: 1.9456167221069336
Batch 47/64 loss: 1.89164400100708
Batch 48/64 loss: 2.0314435958862305
Batch 49/64 loss: 2.008444309234619
Batch 50/64 loss: 1.9961566925048828
Batch 51/64 loss: 1.983086109161377
Batch 52/64 loss: 2.178239345550537
Batch 53/64 loss: 2.416504383087158
Batch 54/64 loss: 2.261880397796631
Batch 55/64 loss: 1.9376416206359863
Batch 56/64 loss: 2.148862361907959
Batch 57/64 loss: 2.2190303802490234
Batch 58/64 loss: 2.123589038848877
Batch 59/64 loss: 4.82136344909668
Batch 60/64 loss: 2.027510643005371
Batch 61/64 loss: 4.201492786407471
Batch 62/64 loss: 2.004350185394287
Batch 63/64 loss: 1.9108481407165527
Batch 64/64 loss: -1.3012371063232422
Epoch 189  Train loss: 2.1957068050608917  Val loss: 1.745733477405666
Epoch 190
-------------------------------
Batch 1/64 loss: 2.3662514686584473
Batch 2/64 loss: 1.8377070426940918
Batch 3/64 loss: 2.570469379425049
Batch 4/64 loss: 1.9673213958740234
Batch 5/64 loss: 1.9740076065063477
Batch 6/64 loss: 2.341541290283203
Batch 7/64 loss: 1.8683819770812988
Batch 8/64 loss: 1.874272346496582
Batch 9/64 loss: 1.8853669166564941
Batch 10/64 loss: 2.222926139831543
Batch 11/64 loss: 2.1303744316101074
Batch 12/64 loss: 1.9747486114501953
Batch 13/64 loss: 2.1455631256103516
Batch 14/64 loss: 2.1175646781921387
Batch 15/64 loss: 2.1317949295043945
Batch 16/64 loss: 2.027574062347412
Batch 17/64 loss: 1.9642891883850098
Batch 18/64 loss: 1.8965692520141602
Batch 19/64 loss: 1.8479361534118652
Batch 20/64 loss: 1.8109159469604492
Batch 21/64 loss: 1.9378137588500977
Batch 22/64 loss: 1.8631610870361328
Batch 23/64 loss: 1.9408116340637207
Batch 24/64 loss: 2.1569976806640625
Batch 25/64 loss: 1.8884363174438477
Batch 26/64 loss: 1.9976634979248047
Batch 27/64 loss: 2.1994104385375977
Batch 28/64 loss: 1.955336093902588
Batch 29/64 loss: 1.9757013320922852
Batch 30/64 loss: 2.060814380645752
Batch 31/64 loss: 1.8788456916809082
Batch 32/64 loss: 1.9632787704467773
Batch 33/64 loss: 2.0139427185058594
Batch 34/64 loss: 1.7649226188659668
Batch 35/64 loss: 2.0418643951416016
Batch 36/64 loss: 1.9175939559936523
Batch 37/64 loss: 1.9920029640197754
Batch 38/64 loss: 2.344226837158203
Batch 39/64 loss: 1.8840527534484863
Batch 40/64 loss: 3.351954936981201
Batch 41/64 loss: 1.9048042297363281
Batch 42/64 loss: 4.4342427253723145
Batch 43/64 loss: 1.9012455940246582
Batch 44/64 loss: 2.5880789756774902
Batch 45/64 loss: 1.8495030403137207
Batch 46/64 loss: 2.0009870529174805
Batch 47/64 loss: 2.0955615043640137
Batch 48/64 loss: 2.325223922729492
Batch 49/64 loss: 2.0116829872131348
Batch 50/64 loss: 2.373891830444336
Batch 51/64 loss: 1.9869356155395508
Batch 52/64 loss: 4.890492916107178
Batch 53/64 loss: 1.8127927780151367
Batch 54/64 loss: 2.0234856605529785
Batch 55/64 loss: 4.429986953735352
Batch 56/64 loss: 3.0237717628479004
Batch 57/64 loss: 1.8009915351867676
Batch 58/64 loss: 2.0018739700317383
Batch 59/64 loss: 3.3965134620666504
Batch 60/64 loss: 2.3229637145996094
Batch 61/64 loss: 1.8222827911376953
Batch 62/64 loss: 1.9865765571594238
Batch 63/64 loss: 2.2461633682250977
Batch 64/64 loss: -1.0955734252929688
Epoch 190  Train loss: 2.172435775457644  Val loss: 1.7506814937001651
Epoch 191
-------------------------------
Batch 1/64 loss: 1.7339134216308594
Batch 2/64 loss: 2.089466094970703
Batch 3/64 loss: 2.156033992767334
Batch 4/64 loss: 2.07027006149292
Batch 5/64 loss: 2.0998611450195312
Batch 6/64 loss: 2.4888839721679688
Batch 7/64 loss: 1.863687515258789
Batch 8/64 loss: 1.7903156280517578
Batch 9/64 loss: 4.387555122375488
Batch 10/64 loss: 1.8246212005615234
Batch 11/64 loss: 2.7000489234924316
Batch 12/64 loss: 1.9876556396484375
Batch 13/64 loss: 2.025362968444824
Batch 14/64 loss: 2.232666492462158
Batch 15/64 loss: 1.863450527191162
Batch 16/64 loss: 1.9941010475158691
Batch 17/64 loss: 1.9103355407714844
Batch 18/64 loss: 1.988095760345459
Batch 19/64 loss: 1.9185614585876465
Batch 20/64 loss: 1.9748377799987793
Batch 21/64 loss: 2.084639549255371
Batch 22/64 loss: 2.139390468597412
Batch 23/64 loss: 2.002863883972168
Batch 24/64 loss: 2.2708349227905273
Batch 25/64 loss: 1.861454963684082
Batch 26/64 loss: 2.098189353942871
Batch 27/64 loss: 2.0722498893737793
Batch 28/64 loss: 2.0632081031799316
Batch 29/64 loss: 2.597266674041748
Batch 30/64 loss: 1.8922233581542969
Batch 31/64 loss: 3.592010498046875
Batch 32/64 loss: 2.4865713119506836
Batch 33/64 loss: 1.9488940238952637
Batch 34/64 loss: 1.9008078575134277
Batch 35/64 loss: 5.834163188934326
Batch 36/64 loss: 2.262434482574463
Batch 37/64 loss: 1.9781031608581543
Batch 38/64 loss: 1.9193835258483887
Batch 39/64 loss: 2.2976861000061035
Batch 40/64 loss: 1.9365262985229492
Batch 41/64 loss: 2.2359089851379395
Batch 42/64 loss: 1.9298462867736816
Batch 43/64 loss: 1.9988651275634766
Batch 44/64 loss: 2.112668514251709
Batch 45/64 loss: 1.9293317794799805
Batch 46/64 loss: 1.995152473449707
Batch 47/64 loss: 2.009429454803467
Batch 48/64 loss: 1.9876761436462402
Batch 49/64 loss: 1.9319448471069336
Batch 50/64 loss: 1.920975685119629
Batch 51/64 loss: 2.1052913665771484
Batch 52/64 loss: 1.9085025787353516
Batch 53/64 loss: 1.9022235870361328
Batch 54/64 loss: 2.1695022583007812
Batch 55/64 loss: 1.9488110542297363
Batch 56/64 loss: 2.6589274406433105
Batch 57/64 loss: 2.3568472862243652
Batch 58/64 loss: 2.0379414558410645
Batch 59/64 loss: 1.804288387298584
Batch 60/64 loss: 1.7019824981689453
Batch 61/64 loss: 4.2206034660339355
Batch 62/64 loss: 2.162902355194092
Batch 63/64 loss: 1.8113794326782227
Batch 64/64 loss: -1.4114255905151367
Epoch 191  Train loss: 2.166604849871467  Val loss: 1.7354926931899028
Epoch 192
-------------------------------
Batch 1/64 loss: 2.085418701171875
Batch 2/64 loss: 1.902679443359375
Batch 3/64 loss: 1.8301939964294434
Batch 4/64 loss: 2.1013646125793457
Batch 5/64 loss: 3.0426573753356934
Batch 6/64 loss: 2.189647674560547
Batch 7/64 loss: 2.293442726135254
Batch 8/64 loss: 2.4028353691101074
Batch 9/64 loss: 1.8271660804748535
Batch 10/64 loss: 1.885423183441162
Batch 11/64 loss: 2.014768600463867
Batch 12/64 loss: 2.0081562995910645
Batch 13/64 loss: 2.6942028999328613
Batch 14/64 loss: 1.8252038955688477
Batch 15/64 loss: 2.0849380493164062
Batch 16/64 loss: 1.9477839469909668
Batch 17/64 loss: 1.8709511756896973
Batch 18/64 loss: 1.8228912353515625
Batch 19/64 loss: 1.9035453796386719
Batch 20/64 loss: 2.102324962615967
Batch 21/64 loss: 1.925461769104004
Batch 22/64 loss: 1.934934139251709
Batch 23/64 loss: 2.2652816772460938
Batch 24/64 loss: 1.9191694259643555
Batch 25/64 loss: 2.5332508087158203
Batch 26/64 loss: 1.907332420349121
Batch 27/64 loss: 2.0695457458496094
Batch 28/64 loss: 1.8487582206726074
Batch 29/64 loss: 1.8918423652648926
Batch 30/64 loss: 1.8310503959655762
Batch 31/64 loss: 4.116852283477783
Batch 32/64 loss: 1.8161253929138184
Batch 33/64 loss: 4.582784652709961
Batch 34/64 loss: 2.593101978302002
Batch 35/64 loss: 2.734386920928955
Batch 36/64 loss: 2.255856990814209
Batch 37/64 loss: 2.5921621322631836
Batch 38/64 loss: 2.344529151916504
Batch 39/64 loss: 4.829346179962158
Batch 40/64 loss: 2.7673559188842773
Batch 41/64 loss: 4.792057514190674
Batch 42/64 loss: 4.127167701721191
Batch 43/64 loss: 3.5399880409240723
Batch 44/64 loss: 3.426723003387451
Batch 45/64 loss: 2.6175546646118164
Batch 46/64 loss: 2.870234966278076
Batch 47/64 loss: 2.2860465049743652
Batch 48/64 loss: 3.055142402648926
Batch 49/64 loss: 3.055046558380127
Batch 50/64 loss: 3.8196864128112793
Batch 51/64 loss: 3.0120835304260254
Batch 52/64 loss: 2.8996591567993164
Batch 53/64 loss: 2.642220973968506
Batch 54/64 loss: 2.668412685394287
Batch 55/64 loss: 5.385964870452881
Batch 56/64 loss: 2.3470025062561035
Batch 57/64 loss: 2.210568428039551
Batch 58/64 loss: 3.4595532417297363
Batch 59/64 loss: 2.2910642623901367
Batch 60/64 loss: 2.5552682876586914
Batch 61/64 loss: 2.5468058586120605
Batch 62/64 loss: 2.498952865600586
Batch 63/64 loss: 2.8630876541137695
Batch 64/64 loss: -1.1093769073486328
Epoch 192  Train loss: 2.552674252379174  Val loss: 2.369085934563601
Epoch 193
-------------------------------
Batch 1/64 loss: 2.2488160133361816
Batch 2/64 loss: 2.477663516998291
Batch 3/64 loss: 3.6974716186523438
Batch 4/64 loss: 2.1507906913757324
Batch 5/64 loss: 2.430629253387451
Batch 6/64 loss: 2.1903209686279297
Batch 7/64 loss: 2.6507511138916016
Batch 8/64 loss: 2.4160070419311523
Batch 9/64 loss: 2.017759323120117
Batch 10/64 loss: 2.240896701812744
Batch 11/64 loss: 2.5655312538146973
Batch 12/64 loss: 2.4434432983398438
Batch 13/64 loss: 5.105837821960449
Batch 14/64 loss: 5.284548759460449
Batch 15/64 loss: 2.210702419281006
Batch 16/64 loss: 1.971419334411621
Batch 17/64 loss: 3.0239815711975098
Batch 18/64 loss: 2.4682464599609375
Batch 19/64 loss: 2.169135570526123
Batch 20/64 loss: 2.1296443939208984
Batch 21/64 loss: 2.3189239501953125
Batch 22/64 loss: 2.1389737129211426
Batch 23/64 loss: 2.0056662559509277
Batch 24/64 loss: 2.4129233360290527
Batch 25/64 loss: 2.158989906311035
Batch 26/64 loss: 2.2371110916137695
Batch 27/64 loss: 2.091320037841797
Batch 28/64 loss: 2.3571529388427734
Batch 29/64 loss: 2.0497536659240723
Batch 30/64 loss: 2.14205265045166
Batch 31/64 loss: 3.7593894004821777
Batch 32/64 loss: 2.2038135528564453
Batch 33/64 loss: 2.350982189178467
Batch 34/64 loss: 2.218801975250244
Batch 35/64 loss: 2.658095359802246
Batch 36/64 loss: 3.0651025772094727
Batch 37/64 loss: 2.1454992294311523
Batch 38/64 loss: 2.5833678245544434
Batch 39/64 loss: 2.0654683113098145
Batch 40/64 loss: 2.170889377593994
Batch 41/64 loss: 2.1776609420776367
Batch 42/64 loss: 2.107192039489746
Batch 43/64 loss: 2.072974681854248
Batch 44/64 loss: 2.512531280517578
Batch 45/64 loss: 2.2810330390930176
Batch 46/64 loss: 2.0292606353759766
Batch 47/64 loss: 1.9490022659301758
Batch 48/64 loss: 2.209077835083008
Batch 49/64 loss: 2.4320249557495117
Batch 50/64 loss: 2.5056376457214355
Batch 51/64 loss: 2.6856470108032227
Batch 52/64 loss: 2.0105419158935547
Batch 53/64 loss: 2.0918731689453125
Batch 54/64 loss: 2.2079734802246094
Batch 55/64 loss: 1.8899312019348145
Batch 56/64 loss: 2.063577651977539
Batch 57/64 loss: 2.4634594917297363
Batch 58/64 loss: 2.0386219024658203
Batch 59/64 loss: 4.104244709014893
Batch 60/64 loss: 2.167294979095459
Batch 61/64 loss: 2.1763057708740234
Batch 62/64 loss: 2.042487621307373
Batch 63/64 loss: 1.8896641731262207
Batch 64/64 loss: -1.2141237258911133
Epoch 193  Train loss: 2.3878478442921356  Val loss: 1.8410118994434266
Epoch 194
-------------------------------
Batch 1/64 loss: 1.9982805252075195
Batch 2/64 loss: 4.9996747970581055
Batch 3/64 loss: 1.885000228881836
Batch 4/64 loss: 2.142449378967285
Batch 5/64 loss: 2.2250633239746094
Batch 6/64 loss: 2.0464253425598145
Batch 7/64 loss: 1.8590998649597168
Batch 8/64 loss: 1.8658266067504883
Batch 9/64 loss: 2.0945663452148438
Batch 10/64 loss: 1.9100613594055176
Batch 11/64 loss: 5.1864094734191895
Batch 12/64 loss: 3.194058895111084
Batch 13/64 loss: 2.818660259246826
Batch 14/64 loss: 2.021747589111328
Batch 15/64 loss: 1.996286392211914
Batch 16/64 loss: 2.1813158988952637
Batch 17/64 loss: 1.954742431640625
Batch 18/64 loss: 2.1472983360290527
Batch 19/64 loss: 2.1594367027282715
Batch 20/64 loss: 2.149406909942627
Batch 21/64 loss: 1.972414493560791
Batch 22/64 loss: 2.047852039337158
Batch 23/64 loss: 2.384127140045166
Batch 24/64 loss: 2.6359081268310547
Batch 25/64 loss: 2.011298179626465
Batch 26/64 loss: 2.6059088706970215
Batch 27/64 loss: 4.090256214141846
Batch 28/64 loss: 2.295743942260742
Batch 29/64 loss: 2.082493305206299
Batch 30/64 loss: 2.4889492988586426
Batch 31/64 loss: 2.123945713043213
Batch 32/64 loss: 2.280156135559082
Batch 33/64 loss: 2.4266953468322754
Batch 34/64 loss: 2.219870090484619
Batch 35/64 loss: 2.059164047241211
Batch 36/64 loss: 2.1055006980895996
Batch 37/64 loss: 2.071065902709961
Batch 38/64 loss: 2.3345351219177246
Batch 39/64 loss: 3.024916648864746
Batch 40/64 loss: 3.1095070838928223
Batch 41/64 loss: 2.365540027618408
Batch 42/64 loss: 2.5334701538085938
Batch 43/64 loss: 2.4348530769348145
Batch 44/64 loss: 2.3023319244384766
Batch 45/64 loss: 2.4492125511169434
Batch 46/64 loss: 2.1498913764953613
Batch 47/64 loss: 2.8897299766540527
Batch 48/64 loss: 2.028775215148926
Batch 49/64 loss: 2.156431198120117
Batch 50/64 loss: 2.247180938720703
Batch 51/64 loss: 2.095215320587158
Batch 52/64 loss: 3.985102653503418
Batch 53/64 loss: 2.2720675468444824
Batch 54/64 loss: 4.745588779449463
Batch 55/64 loss: 2.2125844955444336
Batch 56/64 loss: 2.0225391387939453
Batch 57/64 loss: 2.3931827545166016
Batch 58/64 loss: 2.070695400238037
Batch 59/64 loss: 2.292799949645996
Batch 60/64 loss: 2.53194522857666
Batch 61/64 loss: 2.248687744140625
Batch 62/64 loss: 2.348238468170166
Batch 63/64 loss: 2.2140307426452637
Batch 64/64 loss: -1.4180421829223633
Epoch 194  Train loss: 2.402081287608427  Val loss: 1.91102073774305
Epoch 195
-------------------------------
Batch 1/64 loss: 2.6836981773376465
Batch 2/64 loss: 4.269448280334473
Batch 3/64 loss: 2.0312490463256836
Batch 4/64 loss: 2.340627670288086
Batch 5/64 loss: 2.8643836975097656
Batch 6/64 loss: 2.2261099815368652
Batch 7/64 loss: 1.9695672988891602
Batch 8/64 loss: 4.208802700042725
Batch 9/64 loss: 2.0785131454467773
Batch 10/64 loss: 2.559511661529541
Batch 11/64 loss: 2.3026161193847656
Batch 12/64 loss: 2.0422120094299316
Batch 13/64 loss: 1.8063879013061523
Batch 14/64 loss: 1.9484925270080566
Batch 15/64 loss: 1.8892574310302734
Batch 16/64 loss: 2.0751771926879883
Batch 17/64 loss: 1.9652557373046875
Batch 18/64 loss: 2.110933780670166
Batch 19/64 loss: 2.5223097801208496
Batch 20/64 loss: 2.2360477447509766
Batch 21/64 loss: 2.1501870155334473
Batch 22/64 loss: 4.96655797958374
Batch 23/64 loss: 2.4003195762634277
Batch 24/64 loss: 1.9727911949157715
Batch 25/64 loss: 1.9978532791137695
Batch 26/64 loss: 2.420773983001709
Batch 27/64 loss: 2.240176200866699
Batch 28/64 loss: 2.3111066818237305
Batch 29/64 loss: 3.1121249198913574
Batch 30/64 loss: 1.9002480506896973
Batch 31/64 loss: 1.8675341606140137
Batch 32/64 loss: 2.3187198638916016
Batch 33/64 loss: 2.0666632652282715
Batch 34/64 loss: 2.66825532913208
Batch 35/64 loss: 1.9451065063476562
Batch 36/64 loss: 1.8839120864868164
Batch 37/64 loss: 2.4091687202453613
Batch 38/64 loss: 1.896430492401123
Batch 39/64 loss: 1.8535919189453125
Batch 40/64 loss: 2.111457347869873
Batch 41/64 loss: 2.071352005004883
Batch 42/64 loss: 2.099571704864502
Batch 43/64 loss: 1.960373878479004
Batch 44/64 loss: 2.5203561782836914
Batch 45/64 loss: 1.9533195495605469
Batch 46/64 loss: 2.121878147125244
Batch 47/64 loss: 1.8056526184082031
Batch 48/64 loss: 2.022919178009033
Batch 49/64 loss: 1.8711581230163574
Batch 50/64 loss: 2.130962371826172
Batch 51/64 loss: 1.8919925689697266
Batch 52/64 loss: 2.134300708770752
Batch 53/64 loss: 4.481637477874756
Batch 54/64 loss: 2.0833911895751953
Batch 55/64 loss: 1.8842711448669434
Batch 56/64 loss: 1.9447498321533203
Batch 57/64 loss: 1.8600316047668457
Batch 58/64 loss: 1.8237848281860352
Batch 59/64 loss: 1.91542387008667
Batch 60/64 loss: 2.038733959197998
Batch 61/64 loss: 1.9863595962524414
Batch 62/64 loss: 1.9838619232177734
Batch 63/64 loss: 2.0367250442504883
Batch 64/64 loss: -1.5024347305297852
Epoch 195  Train loss: 2.2293264613432044  Val loss: 1.6821909376845736
Epoch 196
-------------------------------
Batch 1/64 loss: 2.3615565299987793
Batch 2/64 loss: 1.9673104286193848
Batch 3/64 loss: 1.9077787399291992
Batch 4/64 loss: 1.805147647857666
Batch 5/64 loss: 1.8364386558532715
Batch 6/64 loss: 2.5191831588745117
Batch 7/64 loss: 1.7929024696350098
Batch 8/64 loss: 1.8734993934631348
Batch 9/64 loss: 1.879216194152832
Batch 10/64 loss: 2.1542530059814453
Batch 11/64 loss: 2.5088539123535156
Batch 12/64 loss: 2.1055474281311035
Batch 13/64 loss: 1.8493866920471191
Batch 14/64 loss: 1.9235687255859375
Batch 15/64 loss: 2.356759548187256
Batch 16/64 loss: 1.9631562232971191
Batch 17/64 loss: 1.9889912605285645
Batch 18/64 loss: 1.8501105308532715
Batch 19/64 loss: 2.1028823852539062
Batch 20/64 loss: 2.2562241554260254
Batch 21/64 loss: 1.7513031959533691
Batch 22/64 loss: 1.8746743202209473
Batch 23/64 loss: 2.2735648155212402
Batch 24/64 loss: 1.8970098495483398
Batch 25/64 loss: 2.0189666748046875
Batch 26/64 loss: 2.060957431793213
Batch 27/64 loss: 2.217837333679199
Batch 28/64 loss: 1.8600788116455078
Batch 29/64 loss: 1.8472962379455566
Batch 30/64 loss: 1.9379396438598633
Batch 31/64 loss: 1.874107837677002
Batch 32/64 loss: 1.868128776550293
Batch 33/64 loss: 2.0296711921691895
Batch 34/64 loss: 1.8753776550292969
Batch 35/64 loss: 1.8932771682739258
Batch 36/64 loss: 1.8116354942321777
Batch 37/64 loss: 1.9120512008666992
Batch 38/64 loss: 1.9755496978759766
Batch 39/64 loss: 1.9295287132263184
Batch 40/64 loss: 1.9304184913635254
Batch 41/64 loss: 2.0016398429870605
Batch 42/64 loss: 1.9542608261108398
Batch 43/64 loss: 1.8756999969482422
Batch 44/64 loss: 4.4046735763549805
Batch 45/64 loss: 1.7544903755187988
Batch 46/64 loss: 1.7298808097839355
Batch 47/64 loss: 2.2084598541259766
Batch 48/64 loss: 5.699057579040527
Batch 49/64 loss: 4.404414176940918
Batch 50/64 loss: 3.008359909057617
Batch 51/64 loss: 1.9983153343200684
Batch 52/64 loss: 1.8751864433288574
Batch 53/64 loss: 1.773303508758545
Batch 54/64 loss: 2.2516345977783203
Batch 55/64 loss: 1.7658381462097168
Batch 56/64 loss: 2.129575252532959
Batch 57/64 loss: 3.297366142272949
Batch 58/64 loss: 1.951228141784668
Batch 59/64 loss: 2.0618104934692383
Batch 60/64 loss: 2.3967676162719727
Batch 61/64 loss: 2.0440454483032227
Batch 62/64 loss: 1.9746246337890625
Batch 63/64 loss: 2.0604467391967773
Batch 64/64 loss: -1.392019271850586
Epoch 196  Train loss: 2.124222848929611  Val loss: 1.702259692949118
Epoch 197
-------------------------------
Batch 1/64 loss: 2.1755661964416504
Batch 2/64 loss: 2.0623536109924316
Batch 3/64 loss: 2.401221752166748
Batch 4/64 loss: 1.9468936920166016
Batch 5/64 loss: 1.8955588340759277
Batch 6/64 loss: 2.1052489280700684
Batch 7/64 loss: 1.9011859893798828
Batch 8/64 loss: 1.832059383392334
Batch 9/64 loss: 1.8219413757324219
Batch 10/64 loss: 2.0926990509033203
Batch 11/64 loss: 2.087562084197998
Batch 12/64 loss: 1.8565406799316406
Batch 13/64 loss: 1.9627699851989746
Batch 14/64 loss: 4.697819709777832
Batch 15/64 loss: 2.095768928527832
Batch 16/64 loss: 2.3126730918884277
Batch 17/64 loss: 1.9243378639221191
Batch 18/64 loss: 2.159923553466797
Batch 19/64 loss: 2.0877938270568848
Batch 20/64 loss: 1.8514127731323242
Batch 21/64 loss: 1.8310623168945312
Batch 22/64 loss: 2.0899834632873535
Batch 23/64 loss: 2.0191268920898438
Batch 24/64 loss: 2.123016357421875
Batch 25/64 loss: 1.971588134765625
Batch 26/64 loss: 2.0158257484436035
Batch 27/64 loss: 1.9336061477661133
Batch 28/64 loss: 2.098221778869629
Batch 29/64 loss: 2.496753215789795
Batch 30/64 loss: 1.7927050590515137
Batch 31/64 loss: 1.7858881950378418
Batch 32/64 loss: 3.1009387969970703
Batch 33/64 loss: 2.0796070098876953
Batch 34/64 loss: 1.882129192352295
Batch 35/64 loss: 1.853926658630371
Batch 36/64 loss: 2.002692222595215
Batch 37/64 loss: 2.0344972610473633
Batch 38/64 loss: 1.764641284942627
Batch 39/64 loss: 2.103034019470215
Batch 40/64 loss: 2.149016857147217
Batch 41/64 loss: 2.8049426078796387
Batch 42/64 loss: 1.7475614547729492
Batch 43/64 loss: 2.147860527038574
Batch 44/64 loss: 4.738875389099121
Batch 45/64 loss: 1.8762578964233398
Batch 46/64 loss: 1.8182010650634766
Batch 47/64 loss: 1.8226661682128906
Batch 48/64 loss: 4.943664073944092
Batch 49/64 loss: 2.0402626991271973
Batch 50/64 loss: 2.19893741607666
Batch 51/64 loss: 1.7775335311889648
Batch 52/64 loss: 3.129228115081787
Batch 53/64 loss: 1.8284287452697754
Batch 54/64 loss: 1.9666061401367188
Batch 55/64 loss: 1.8785409927368164
Batch 56/64 loss: 1.9223260879516602
Batch 57/64 loss: 1.912184238433838
Batch 58/64 loss: 2.020049571990967
Batch 59/64 loss: 1.8644542694091797
Batch 60/64 loss: 1.8715415000915527
Batch 61/64 loss: 1.9122958183288574
Batch 62/64 loss: 1.9413299560546875
Batch 63/64 loss: 2.218386173248291
Batch 64/64 loss: -1.1967382431030273
Epoch 197  Train loss: 2.1315164341646082  Val loss: 1.6673017219989161
Epoch 198
-------------------------------
Batch 1/64 loss: 1.8465795516967773
Batch 2/64 loss: 2.0708680152893066
Batch 3/64 loss: 2.0967659950256348
Batch 4/64 loss: 2.0461220741271973
Batch 5/64 loss: 2.0129213333129883
Batch 6/64 loss: 2.059572219848633
Batch 7/64 loss: 1.9314970970153809
Batch 8/64 loss: 2.001953601837158
Batch 9/64 loss: 1.9538779258728027
Batch 10/64 loss: 1.9294500350952148
Batch 11/64 loss: 1.9791698455810547
Batch 12/64 loss: 1.9604082107543945
Batch 13/64 loss: 2.098045825958252
Batch 14/64 loss: 1.8374266624450684
Batch 15/64 loss: 1.801215648651123
Batch 16/64 loss: 1.9218897819519043
Batch 17/64 loss: 2.477022647857666
Batch 18/64 loss: 2.0242257118225098
Batch 19/64 loss: 1.9478259086608887
Batch 20/64 loss: 2.0023107528686523
Batch 21/64 loss: 2.6004467010498047
Batch 22/64 loss: 1.8640227317810059
Batch 23/64 loss: 1.9570698738098145
Batch 24/64 loss: 2.1930665969848633
Batch 25/64 loss: 1.9354305267333984
Batch 26/64 loss: 2.204127788543701
Batch 27/64 loss: 2.08254337310791
Batch 28/64 loss: 1.8849844932556152
Batch 29/64 loss: 1.8493094444274902
Batch 30/64 loss: 2.391225814819336
Batch 31/64 loss: 4.332739353179932
Batch 32/64 loss: 5.704054832458496
Batch 33/64 loss: 1.8048386573791504
Batch 34/64 loss: 1.865889549255371
Batch 35/64 loss: 1.8917789459228516
Batch 36/64 loss: 1.9138684272766113
Batch 37/64 loss: 1.9941787719726562
Batch 38/64 loss: 1.855422019958496
Batch 39/64 loss: 4.124838352203369
Batch 40/64 loss: 1.9652085304260254
Batch 41/64 loss: 1.8898253440856934
Batch 42/64 loss: 1.9214286804199219
Batch 43/64 loss: 1.86820650100708
Batch 44/64 loss: 2.087739944458008
Batch 45/64 loss: 1.8359670639038086
Batch 46/64 loss: 1.983609676361084
Batch 47/64 loss: 2.0806264877319336
Batch 48/64 loss: 1.8977093696594238
Batch 49/64 loss: 1.8318877220153809
Batch 50/64 loss: 3.0688719749450684
Batch 51/64 loss: 2.5629167556762695
Batch 52/64 loss: 1.7695817947387695
Batch 53/64 loss: 1.9284067153930664
Batch 54/64 loss: 1.894810676574707
Batch 55/64 loss: 3.0962815284729004
Batch 56/64 loss: 2.027120590209961
Batch 57/64 loss: 1.905829906463623
Batch 58/64 loss: 2.041187286376953
Batch 59/64 loss: 2.12892484664917
Batch 60/64 loss: 1.941737174987793
Batch 61/64 loss: 1.943007469177246
Batch 62/64 loss: 1.7198996543884277
Batch 63/64 loss: 1.8462467193603516
Batch 64/64 loss: -1.4713144302368164
Epoch 198  Train loss: 2.1110985363230985  Val loss: 1.619531834658069
Epoch 199
-------------------------------
Batch 1/64 loss: 1.817227840423584
Batch 2/64 loss: 1.9618120193481445
Batch 3/64 loss: 1.949319839477539
Batch 4/64 loss: 3.248666286468506
Batch 5/64 loss: 1.8520069122314453
Batch 6/64 loss: 1.9458274841308594
Batch 7/64 loss: 1.820716381072998
Batch 8/64 loss: 1.9003853797912598
Batch 9/64 loss: 2.1135406494140625
Batch 10/64 loss: 2.135396957397461
Batch 11/64 loss: 1.8828954696655273
Batch 12/64 loss: 1.9020438194274902
Batch 13/64 loss: 2.1411876678466797
Batch 14/64 loss: 1.9338421821594238
Batch 15/64 loss: 1.8833742141723633
Batch 16/64 loss: 2.411113739013672
Batch 17/64 loss: 1.7652029991149902
Batch 18/64 loss: 1.765547752380371
Batch 19/64 loss: 1.7656598091125488
Batch 20/64 loss: 1.6762199401855469
Batch 21/64 loss: 1.7937054634094238
Batch 22/64 loss: 3.222299575805664
Batch 23/64 loss: 1.7405428886413574
Batch 24/64 loss: 2.0128493309020996
Batch 25/64 loss: 1.8214659690856934
Batch 26/64 loss: 1.8271818161010742
Batch 27/64 loss: 1.8160605430603027
Batch 28/64 loss: 4.880251884460449
Batch 29/64 loss: 1.788651466369629
Batch 30/64 loss: 1.8725881576538086
Batch 31/64 loss: 1.877995491027832
Batch 32/64 loss: 4.272417068481445
Batch 33/64 loss: 1.9425811767578125
Batch 34/64 loss: 2.0123424530029297
Batch 35/64 loss: 1.918320655822754
Batch 36/64 loss: 1.8026671409606934
Batch 37/64 loss: 1.958202838897705
Batch 38/64 loss: 1.8981680870056152
Batch 39/64 loss: 2.1448302268981934
Batch 40/64 loss: 2.500471591949463
Batch 41/64 loss: 1.8770055770874023
Batch 42/64 loss: 1.9608173370361328
Batch 43/64 loss: 1.9671268463134766
Batch 44/64 loss: 2.029280185699463
Batch 45/64 loss: 4.225503444671631
Batch 46/64 loss: 2.031090259552002
Batch 47/64 loss: 1.994269847869873
Batch 48/64 loss: 2.5516629219055176
Batch 49/64 loss: 1.9614324569702148
Batch 50/64 loss: 2.4482860565185547
Batch 51/64 loss: 2.2073497772216797
Batch 52/64 loss: 1.8319463729858398
Batch 53/64 loss: 2.053338050842285
Batch 54/64 loss: 1.8905119895935059
Batch 55/64 loss: 1.9064316749572754
Batch 56/64 loss: 2.2224888801574707
Batch 57/64 loss: 1.9631409645080566
Batch 58/64 loss: 1.82993745803833
Batch 59/64 loss: 2.0113649368286133
Batch 60/64 loss: 1.7914700508117676
Batch 61/64 loss: 2.341494083404541
Batch 62/64 loss: 2.1126089096069336
Batch 63/64 loss: 1.9003276824951172
Batch 64/64 loss: -0.6063117980957031
Epoch 199  Train loss: 2.096152675853056  Val loss: 1.7202240134432554
Epoch 200
-------------------------------
Batch 1/64 loss: 1.91825532913208
Batch 2/64 loss: 4.7709221839904785
Batch 3/64 loss: 1.9250035285949707
Batch 4/64 loss: 2.2290334701538086
Batch 5/64 loss: 1.8312630653381348
Batch 6/64 loss: 2.1286659240722656
Batch 7/64 loss: 1.7979516983032227
Batch 8/64 loss: 1.8410162925720215
Batch 9/64 loss: 1.948094367980957
Batch 10/64 loss: 1.949038028717041
Batch 11/64 loss: 1.9890837669372559
Batch 12/64 loss: 1.9310779571533203
Batch 13/64 loss: 2.014657497406006
Batch 14/64 loss: 3.2676191329956055
Batch 15/64 loss: 2.0109477043151855
Batch 16/64 loss: 2.038496494293213
Batch 17/64 loss: 1.9352335929870605
Batch 18/64 loss: 1.9094786643981934
Batch 19/64 loss: 2.018360137939453
Batch 20/64 loss: 1.8172383308410645
Batch 21/64 loss: 1.9331932067871094
Batch 22/64 loss: 2.1724443435668945
Batch 23/64 loss: 2.27939510345459
Batch 24/64 loss: 1.7810301780700684
Batch 25/64 loss: 1.8604321479797363
Batch 26/64 loss: 2.039095401763916
Batch 27/64 loss: 1.937295913696289
Batch 28/64 loss: 2.0464959144592285
Batch 29/64 loss: 1.8849353790283203
Batch 30/64 loss: 1.8650169372558594
Batch 31/64 loss: 1.7658934593200684
Batch 32/64 loss: 2.047438144683838
Batch 33/64 loss: 1.8446440696716309
Batch 34/64 loss: 2.0954227447509766
Batch 35/64 loss: 3.1738858222961426
Batch 36/64 loss: 1.9094982147216797
Batch 37/64 loss: 2.811178207397461
Batch 38/64 loss: 1.9720826148986816
Batch 39/64 loss: 1.9236793518066406
Batch 40/64 loss: 1.924893856048584
Batch 41/64 loss: 1.8731331825256348
Batch 42/64 loss: 2.652702808380127
Batch 43/64 loss: 1.928764820098877
Batch 44/64 loss: 1.881861686706543
Batch 45/64 loss: 2.3496103286743164
Batch 46/64 loss: 4.287900924682617
Batch 47/64 loss: 1.7654738426208496
Batch 48/64 loss: 1.914344310760498
Batch 49/64 loss: 2.1467885971069336
Batch 50/64 loss: 1.8570513725280762
Batch 51/64 loss: 1.7852044105529785
Batch 52/64 loss: 1.911919116973877
Batch 53/64 loss: 1.9850239753723145
Batch 54/64 loss: 2.4076242446899414
Batch 55/64 loss: 1.987095832824707
Batch 56/64 loss: 2.664393901824951
Batch 57/64 loss: 1.882157325744629
Batch 58/64 loss: 2.0613741874694824
Batch 59/64 loss: 2.2122321128845215
Batch 60/64 loss: 1.847238540649414
Batch 61/64 loss: 1.8869900703430176
Batch 62/64 loss: 1.9849424362182617
Batch 63/64 loss: 4.089117050170898
Batch 64/64 loss: -1.546457290649414
Epoch 200  Train loss: 2.113607690848556  Val loss: 1.6915649663132082
Epoch 201
-------------------------------
Batch 1/64 loss: 4.3751444816589355
Batch 2/64 loss: 4.869427680969238
Batch 3/64 loss: 2.177241802215576
Batch 4/64 loss: 1.9297847747802734
Batch 5/64 loss: 1.8070378303527832
Batch 6/64 loss: 1.985217571258545
Batch 7/64 loss: 1.7908978462219238
Batch 8/64 loss: 1.9588146209716797
Batch 9/64 loss: 1.8617024421691895
Batch 10/64 loss: 1.7404756546020508
Batch 11/64 loss: 2.18502140045166
Batch 12/64 loss: 3.2808775901794434
Batch 13/64 loss: 2.0340166091918945
Batch 14/64 loss: 1.9753170013427734
Batch 15/64 loss: 1.8857917785644531
Batch 16/64 loss: 2.1493754386901855
Batch 17/64 loss: 2.086862087249756
Batch 18/64 loss: 1.8004069328308105
Batch 19/64 loss: 1.913316249847412
Batch 20/64 loss: 1.9131135940551758
Batch 21/64 loss: 1.8013639450073242
Batch 22/64 loss: 2.18937349319458
Batch 23/64 loss: 1.8507094383239746
Batch 24/64 loss: 2.242842197418213
Batch 25/64 loss: 2.074892520904541
Batch 26/64 loss: 1.9203267097473145
Batch 27/64 loss: 2.0417895317077637
Batch 28/64 loss: 1.9255638122558594
Batch 29/64 loss: 1.928788185119629
Batch 30/64 loss: 2.9314236640930176
Batch 31/64 loss: 1.9467921257019043
Batch 32/64 loss: 2.224402904510498
Batch 33/64 loss: 2.2652978897094727
Batch 34/64 loss: 4.219294548034668
Batch 35/64 loss: 1.8987212181091309
Batch 36/64 loss: 1.8261752128601074
Batch 37/64 loss: 2.573650360107422
Batch 38/64 loss: 1.9941368103027344
Batch 39/64 loss: 2.060985565185547
Batch 40/64 loss: 1.7875070571899414
Batch 41/64 loss: 1.955286979675293
Batch 42/64 loss: 2.03875732421875
Batch 43/64 loss: 1.9606738090515137
Batch 44/64 loss: 2.269503116607666
Batch 45/64 loss: 1.9558262825012207
Batch 46/64 loss: 1.8430628776550293
Batch 47/64 loss: 2.446446418762207
Batch 48/64 loss: 1.929825782775879
Batch 49/64 loss: 1.9148545265197754
Batch 50/64 loss: 1.8412690162658691
Batch 51/64 loss: 1.7786030769348145
Batch 52/64 loss: 1.802316665649414
Batch 53/64 loss: 1.9313716888427734
Batch 54/64 loss: 2.0313687324523926
Batch 55/64 loss: 2.627326488494873
Batch 56/64 loss: 1.8557677268981934
Batch 57/64 loss: 2.2343530654907227
Batch 58/64 loss: 2.673463821411133
Batch 59/64 loss: 2.5375404357910156
Batch 60/64 loss: 2.214205741882324
Batch 61/64 loss: 2.129526138305664
Batch 62/64 loss: 2.534754753112793
Batch 63/64 loss: 2.4604086875915527
Batch 64/64 loss: -0.9658098220825195
Epoch 201  Train loss: 2.159467237135943  Val loss: 2.7485785533472433
Epoch 202
-------------------------------
Batch 1/64 loss: 2.841918468475342
Batch 2/64 loss: 3.4195594787597656
Batch 3/64 loss: 5.200980186462402
Batch 4/64 loss: 2.2353596687316895
Batch 5/64 loss: 2.7347893714904785
Batch 6/64 loss: 3.0460309982299805
Batch 7/64 loss: 2.0881547927856445
Batch 8/64 loss: 2.524791717529297
Batch 9/64 loss: 2.197727680206299
Batch 10/64 loss: 3.4702491760253906
Batch 11/64 loss: 2.381579875946045
Batch 12/64 loss: 2.5551886558532715
Batch 13/64 loss: 2.1011219024658203
Batch 14/64 loss: 2.2717084884643555
Batch 15/64 loss: 2.198072910308838
Batch 16/64 loss: 2.1696958541870117
Batch 17/64 loss: 2.030910015106201
Batch 18/64 loss: 1.9286866188049316
Batch 19/64 loss: 2.058596134185791
Batch 20/64 loss: 2.3234777450561523
Batch 21/64 loss: 2.242774486541748
Batch 22/64 loss: 2.073544979095459
Batch 23/64 loss: 2.550605297088623
Batch 24/64 loss: 2.0351128578186035
Batch 25/64 loss: 2.098299980163574
Batch 26/64 loss: 2.1354665756225586
Batch 27/64 loss: 2.1222567558288574
Batch 28/64 loss: 2.9787755012512207
Batch 29/64 loss: 2.0674920082092285
Batch 30/64 loss: 2.0464906692504883
Batch 31/64 loss: 2.0982699394226074
Batch 32/64 loss: 2.010934352874756
Batch 33/64 loss: 1.9420242309570312
Batch 34/64 loss: 2.5551652908325195
Batch 35/64 loss: 2.2852210998535156
Batch 36/64 loss: 1.9630756378173828
Batch 37/64 loss: 2.3591346740722656
Batch 38/64 loss: 2.5722827911376953
Batch 39/64 loss: 2.213766574859619
Batch 40/64 loss: 1.8582024574279785
Batch 41/64 loss: 2.141800880432129
Batch 42/64 loss: 1.9383158683776855
Batch 43/64 loss: 1.9397950172424316
Batch 44/64 loss: 2.0090107917785645
Batch 45/64 loss: 1.988050937652588
Batch 46/64 loss: 1.8482398986816406
Batch 47/64 loss: 2.9170823097229004
Batch 48/64 loss: 2.450324058532715
Batch 49/64 loss: 1.891782283782959
Batch 50/64 loss: 1.9851584434509277
Batch 51/64 loss: 2.136223793029785
Batch 52/64 loss: 1.9016971588134766
Batch 53/64 loss: 4.061490058898926
Batch 54/64 loss: 1.8852057456970215
Batch 55/64 loss: 1.8931593894958496
Batch 56/64 loss: 1.9726743698120117
Batch 57/64 loss: 4.232947826385498
Batch 58/64 loss: 1.9967637062072754
Batch 59/64 loss: 1.8792672157287598
Batch 60/64 loss: 1.8037314414978027
Batch 61/64 loss: 2.095895767211914
Batch 62/64 loss: 1.847078800201416
Batch 63/64 loss: 2.0838699340820312
Batch 64/64 loss: -0.15160846710205078
Epoch 202  Train loss: 2.3023271411072974  Val loss: 1.7219493512025814
Epoch 203
-------------------------------
Batch 1/64 loss: 4.385677337646484
Batch 2/64 loss: 1.7707905769348145
Batch 3/64 loss: 2.1641621589660645
Batch 4/64 loss: 1.7883505821228027
Batch 5/64 loss: 1.8761897087097168
Batch 6/64 loss: 1.8754386901855469
Batch 7/64 loss: 2.39430570602417
Batch 8/64 loss: 2.1103596687316895
Batch 9/64 loss: 2.026460647583008
Batch 10/64 loss: 2.122239112854004
Batch 11/64 loss: 1.9506831169128418
Batch 12/64 loss: 2.7379212379455566
Batch 13/64 loss: 4.825811386108398
Batch 14/64 loss: 1.8752269744873047
Batch 15/64 loss: 1.9530596733093262
Batch 16/64 loss: 2.0039191246032715
Batch 17/64 loss: 2.1692628860473633
Batch 18/64 loss: 1.794412612915039
Batch 19/64 loss: 2.075986385345459
Batch 20/64 loss: 1.8282065391540527
Batch 21/64 loss: 1.887270450592041
Batch 22/64 loss: 1.8219852447509766
Batch 23/64 loss: 2.0383529663085938
Batch 24/64 loss: 1.7966713905334473
Batch 25/64 loss: 1.81512451171875
Batch 26/64 loss: 1.9533381462097168
Batch 27/64 loss: 1.8516244888305664
Batch 28/64 loss: 1.958519458770752
Batch 29/64 loss: 1.7863373756408691
Batch 30/64 loss: 1.9519171714782715
Batch 31/64 loss: 2.2618937492370605
Batch 32/64 loss: 2.0402116775512695
Batch 33/64 loss: 2.4119362831115723
Batch 34/64 loss: 1.8325409889221191
Batch 35/64 loss: 2.9684348106384277
Batch 36/64 loss: 2.927218437194824
Batch 37/64 loss: 1.8409347534179688
Batch 38/64 loss: 1.8329424858093262
Batch 39/64 loss: 1.8501439094543457
Batch 40/64 loss: 1.8086366653442383
Batch 41/64 loss: 1.7122769355773926
Batch 42/64 loss: 2.060868263244629
Batch 43/64 loss: 2.7823281288146973
Batch 44/64 loss: 1.8855476379394531
Batch 45/64 loss: 2.1600985527038574
Batch 46/64 loss: 2.0576934814453125
Batch 47/64 loss: 1.9404754638671875
Batch 48/64 loss: 1.9996528625488281
Batch 49/64 loss: 2.038743019104004
Batch 50/64 loss: 2.2957005500793457
Batch 51/64 loss: 2.0446181297302246
Batch 52/64 loss: 1.8393158912658691
Batch 53/64 loss: 1.8384218215942383
Batch 54/64 loss: 1.8015332221984863
Batch 55/64 loss: 4.015890121459961
Batch 56/64 loss: 2.064818859100342
Batch 57/64 loss: 1.8437070846557617
Batch 58/64 loss: 2.361314296722412
Batch 59/64 loss: 1.902146816253662
Batch 60/64 loss: 2.067655563354492
Batch 61/64 loss: 1.8272151947021484
Batch 62/64 loss: 1.9247140884399414
Batch 63/64 loss: 1.9996261596679688
Batch 64/64 loss: -1.3773860931396484
Epoch 203  Train loss: 2.0987579869289026  Val loss: 1.6455675236547935
Epoch 204
-------------------------------
Batch 1/64 loss: 1.9668335914611816
Batch 2/64 loss: 1.9633402824401855
Batch 3/64 loss: 2.0596232414245605
Batch 4/64 loss: 3.6275649070739746
Batch 5/64 loss: 1.887063980102539
Batch 6/64 loss: 5.027306079864502
Batch 7/64 loss: 1.8265948295593262
Batch 8/64 loss: 1.79433012008667
Batch 9/64 loss: 1.8419795036315918
Batch 10/64 loss: 1.748058795928955
Batch 11/64 loss: 2.0605955123901367
Batch 12/64 loss: 3.2536606788635254
Batch 13/64 loss: 2.9952945709228516
Batch 14/64 loss: 1.897529125213623
Batch 15/64 loss: 1.8598594665527344
Batch 16/64 loss: 1.8165483474731445
Batch 17/64 loss: 1.8977837562561035
Batch 18/64 loss: 2.229975700378418
Batch 19/64 loss: 1.7561798095703125
Batch 20/64 loss: 1.7096519470214844
Batch 21/64 loss: 1.7944226264953613
Batch 22/64 loss: 4.271755218505859
Batch 23/64 loss: 1.7875537872314453
Batch 24/64 loss: 1.9730372428894043
Batch 25/64 loss: 1.8562874794006348
Batch 26/64 loss: 1.984208106994629
Batch 27/64 loss: 1.8112883567810059
Batch 28/64 loss: 1.938014030456543
Batch 29/64 loss: 1.871635913848877
Batch 30/64 loss: 2.132338523864746
Batch 31/64 loss: 1.8338689804077148
Batch 32/64 loss: 1.9674897193908691
Batch 33/64 loss: 1.7218523025512695
Batch 34/64 loss: 1.731048583984375
Batch 35/64 loss: 1.7981314659118652
Batch 36/64 loss: 1.8025169372558594
Batch 37/64 loss: 1.7890992164611816
Batch 38/64 loss: 2.037506103515625
Batch 39/64 loss: 1.693967342376709
Batch 40/64 loss: 2.013861656188965
Batch 41/64 loss: 1.9970974922180176
Batch 42/64 loss: 2.1383070945739746
Batch 43/64 loss: 2.1164121627807617
Batch 44/64 loss: 2.060556411743164
Batch 45/64 loss: 2.2778100967407227
Batch 46/64 loss: 3.994182586669922
Batch 47/64 loss: 1.8786239624023438
Batch 48/64 loss: 1.8180737495422363
Batch 49/64 loss: 1.882270336151123
Batch 50/64 loss: 1.9002599716186523
Batch 51/64 loss: 1.874891757965088
Batch 52/64 loss: 1.8401575088500977
Batch 53/64 loss: 1.850536823272705
Batch 54/64 loss: 1.9947361946105957
Batch 55/64 loss: 1.9419679641723633
Batch 56/64 loss: 1.7175421714782715
Batch 57/64 loss: 2.3727917671203613
Batch 58/64 loss: 2.3652334213256836
Batch 59/64 loss: 1.75156831741333
Batch 60/64 loss: 2.0322113037109375
Batch 61/64 loss: 1.754955768585205
Batch 62/64 loss: 1.9345459938049316
Batch 63/64 loss: 1.8331589698791504
Batch 64/64 loss: -1.5863170623779297
Epoch 204  Train loss: 2.0575343038521563  Val loss: 1.6998595142692225
Epoch 205
-------------------------------
Batch 1/64 loss: 1.9450492858886719
Batch 2/64 loss: 1.7556090354919434
Batch 3/64 loss: 1.8707785606384277
Batch 4/64 loss: 1.98099946975708
Batch 5/64 loss: 1.8069753646850586
Batch 6/64 loss: 1.8756804466247559
Batch 7/64 loss: 1.8097939491271973
Batch 8/64 loss: 3.378283977508545
Batch 9/64 loss: 1.8038992881774902
Batch 10/64 loss: 2.237384796142578
Batch 11/64 loss: 1.8930864334106445
Batch 12/64 loss: 2.018627643585205
Batch 13/64 loss: 3.8528542518615723
Batch 14/64 loss: 1.9737491607666016
Batch 15/64 loss: 2.0058884620666504
Batch 16/64 loss: 1.8184318542480469
Batch 17/64 loss: 1.9512214660644531
Batch 18/64 loss: 1.9059405326843262
Batch 19/64 loss: 2.331343650817871
Batch 20/64 loss: 1.9394912719726562
Batch 21/64 loss: 1.7893023490905762
Batch 22/64 loss: 1.770462989807129
Batch 23/64 loss: 1.699380874633789
Batch 24/64 loss: 1.8088946342468262
Batch 25/64 loss: 1.9166412353515625
Batch 26/64 loss: 1.7081871032714844
Batch 27/64 loss: 1.9126043319702148
Batch 28/64 loss: 1.807769775390625
Batch 29/64 loss: 1.8982744216918945
Batch 30/64 loss: 2.19000244140625
Batch 31/64 loss: 2.2305235862731934
Batch 32/64 loss: 1.862419605255127
Batch 33/64 loss: 1.8996868133544922
Batch 34/64 loss: 1.8269081115722656
Batch 35/64 loss: 1.838449478149414
Batch 36/64 loss: 2.0661392211914062
Batch 37/64 loss: 2.8128557205200195
Batch 38/64 loss: 1.9166245460510254
Batch 39/64 loss: 1.6708359718322754
Batch 40/64 loss: 2.149655342102051
Batch 41/64 loss: 1.6523656845092773
Batch 42/64 loss: 2.0128350257873535
Batch 43/64 loss: 4.241446018218994
Batch 44/64 loss: 2.7695860862731934
Batch 45/64 loss: 1.963789463043213
Batch 46/64 loss: 1.7426776885986328
Batch 47/64 loss: 1.9799246788024902
Batch 48/64 loss: 1.8180665969848633
Batch 49/64 loss: 1.9138274192810059
Batch 50/64 loss: 5.5965166091918945
Batch 51/64 loss: 1.8989453315734863
Batch 52/64 loss: 1.9016838073730469
Batch 53/64 loss: 2.5484652519226074
Batch 54/64 loss: 1.913339614868164
Batch 55/64 loss: 1.7985835075378418
Batch 56/64 loss: 1.8252606391906738
Batch 57/64 loss: 1.880331039428711
Batch 58/64 loss: 2.029731273651123
Batch 59/64 loss: 2.3068933486938477
Batch 60/64 loss: 1.792762279510498
Batch 61/64 loss: 1.8495750427246094
Batch 62/64 loss: 1.9099974632263184
Batch 63/64 loss: 1.8021864891052246
Batch 64/64 loss: -1.3799285888671875
Epoch 205  Train loss: 2.0556008058435777  Val loss: 1.6152621659216602
Epoch 206
-------------------------------
Batch 1/64 loss: 1.9740114212036133
Batch 2/64 loss: 1.8644113540649414
Batch 3/64 loss: 2.9387550354003906
Batch 4/64 loss: 1.8406834602355957
Batch 5/64 loss: 1.789921760559082
Batch 6/64 loss: 2.0633530616760254
Batch 7/64 loss: 1.769556999206543
Batch 8/64 loss: 1.8304071426391602
Batch 9/64 loss: 2.2264857292175293
Batch 10/64 loss: 1.9238567352294922
Batch 11/64 loss: 2.4755115509033203
Batch 12/64 loss: 1.925264835357666
Batch 13/64 loss: 1.848043441772461
Batch 14/64 loss: 1.8830900192260742
Batch 15/64 loss: 1.7155537605285645
Batch 16/64 loss: 1.9283604621887207
Batch 17/64 loss: 2.195713520050049
Batch 18/64 loss: 1.8083806037902832
Batch 19/64 loss: 1.9416513442993164
Batch 20/64 loss: 2.008688449859619
Batch 21/64 loss: 1.8843445777893066
Batch 22/64 loss: 2.0733394622802734
Batch 23/64 loss: 1.900064468383789
Batch 24/64 loss: 2.1512441635131836
Batch 25/64 loss: 1.8074026107788086
Batch 26/64 loss: 1.8044734001159668
Batch 27/64 loss: 2.229520797729492
Batch 28/64 loss: 2.241452693939209
Batch 29/64 loss: 2.0074729919433594
Batch 30/64 loss: 1.8736004829406738
Batch 31/64 loss: 1.8486075401306152
Batch 32/64 loss: 2.4015331268310547
Batch 33/64 loss: 1.8705458641052246
Batch 34/64 loss: 1.9355883598327637
Batch 35/64 loss: 1.8364315032958984
Batch 36/64 loss: 1.743880271911621
Batch 37/64 loss: 1.6971468925476074
Batch 38/64 loss: 2.634768486022949
Batch 39/64 loss: 3.5418787002563477
Batch 40/64 loss: 2.15922212600708
Batch 41/64 loss: 3.549297332763672
Batch 42/64 loss: 2.533344268798828
Batch 43/64 loss: 2.623279571533203
Batch 44/64 loss: 2.4408140182495117
Batch 45/64 loss: 5.438487529754639
Batch 46/64 loss: 2.4523162841796875
Batch 47/64 loss: 3.161741256713867
Batch 48/64 loss: 2.517284870147705
Batch 49/64 loss: 3.4778594970703125
Batch 50/64 loss: 2.7792959213256836
Batch 51/64 loss: 2.738171100616455
Batch 52/64 loss: 2.5784506797790527
Batch 53/64 loss: 3.34964656829834
Batch 54/64 loss: 2.875666618347168
Batch 55/64 loss: 3.820406913757324
Batch 56/64 loss: 2.4283671379089355
Batch 57/64 loss: 5.001510143280029
Batch 58/64 loss: 2.114781379699707
Batch 59/64 loss: 2.5026817321777344
Batch 60/64 loss: 6.43614387512207
Batch 61/64 loss: 2.43678617477417
Batch 62/64 loss: 2.3775887489318848
Batch 63/64 loss: 2.3856616020202637
Batch 64/64 loss: -0.3786611557006836
Epoch 206  Train loss: 2.4051734363331514  Val loss: 3.745750112631886
Epoch 207
-------------------------------
Batch 1/64 loss: 2.4605536460876465
Batch 2/64 loss: 3.2725062370300293
Batch 3/64 loss: 5.710690975189209
Batch 4/64 loss: 2.2253713607788086
Batch 5/64 loss: 2.30118465423584
Batch 6/64 loss: 2.8070807456970215
Batch 7/64 loss: 5.61482048034668
Batch 8/64 loss: 2.3729629516601562
Batch 9/64 loss: 2.915012836456299
Batch 10/64 loss: 3.4961295127868652
Batch 11/64 loss: 2.48032808303833
Batch 12/64 loss: 2.1528100967407227
Batch 13/64 loss: 2.29449462890625
Batch 14/64 loss: 2.0983362197875977
Batch 15/64 loss: 2.8680810928344727
Batch 16/64 loss: 2.2225122451782227
Batch 17/64 loss: 2.460235595703125
Batch 18/64 loss: 2.932555675506592
Batch 19/64 loss: 2.18060302734375
Batch 20/64 loss: 2.3690953254699707
Batch 21/64 loss: 2.4196200370788574
Batch 22/64 loss: 2.3441572189331055
Batch 23/64 loss: 2.2621212005615234
Batch 24/64 loss: 1.9307537078857422
Batch 25/64 loss: 2.1945090293884277
Batch 26/64 loss: 2.049891948699951
Batch 27/64 loss: 2.213932991027832
Batch 28/64 loss: 1.8886032104492188
Batch 29/64 loss: 2.1934776306152344
Batch 30/64 loss: 2.430971622467041
Batch 31/64 loss: 2.0318312644958496
Batch 32/64 loss: 2.0619606971740723
Batch 33/64 loss: 2.4076967239379883
Batch 34/64 loss: 1.8852472305297852
Batch 35/64 loss: 1.9322762489318848
Batch 36/64 loss: 2.0416550636291504
Batch 37/64 loss: 1.9050912857055664
Batch 38/64 loss: 1.9691009521484375
Batch 39/64 loss: 2.0859298706054688
Batch 40/64 loss: 2.270504951477051
Batch 41/64 loss: 1.8452692031860352
Batch 42/64 loss: 2.4066433906555176
Batch 43/64 loss: 3.649035930633545
Batch 44/64 loss: 2.1807870864868164
Batch 45/64 loss: 1.8854694366455078
Batch 46/64 loss: 1.8903846740722656
Batch 47/64 loss: 2.594963550567627
Batch 48/64 loss: 5.124863624572754
Batch 49/64 loss: 1.898226261138916
Batch 50/64 loss: 1.8736424446105957
Batch 51/64 loss: 1.7692742347717285
Batch 52/64 loss: 1.9108967781066895
Batch 53/64 loss: 2.069547653198242
Batch 54/64 loss: 1.9374499320983887
Batch 55/64 loss: 2.2685599327087402
Batch 56/64 loss: 2.3302040100097656
Batch 57/64 loss: 2.087210178375244
Batch 58/64 loss: 2.8916635513305664
Batch 59/64 loss: 4.524826526641846
Batch 60/64 loss: 2.2173705101013184
Batch 61/64 loss: 1.9729304313659668
Batch 62/64 loss: 2.2124791145324707
Batch 63/64 loss: 1.885859489440918
Batch 64/64 loss: -1.593876838684082
Epoch 207  Train loss: 2.4154799779256186  Val loss: 1.9004354444156397
Epoch 208
-------------------------------
Batch 1/64 loss: 1.922290325164795
Batch 2/64 loss: 1.8514208793640137
Batch 3/64 loss: 2.5418872833251953
Batch 4/64 loss: 2.62838077545166
Batch 5/64 loss: 1.8630146980285645
Batch 6/64 loss: 1.9956245422363281
Batch 7/64 loss: 2.0467214584350586
Batch 8/64 loss: 1.927558422088623
Batch 9/64 loss: 1.8604764938354492
Batch 10/64 loss: 2.558028221130371
Batch 11/64 loss: 2.0952916145324707
Batch 12/64 loss: 1.9060473442077637
Batch 13/64 loss: 2.145049571990967
Batch 14/64 loss: 3.4324417114257812
Batch 15/64 loss: 2.9673686027526855
Batch 16/64 loss: 2.0195999145507812
Batch 17/64 loss: 1.9368939399719238
Batch 18/64 loss: 1.9031286239624023
Batch 19/64 loss: 2.0145182609558105
Batch 20/64 loss: 1.9644889831542969
Batch 21/64 loss: 1.9594264030456543
Batch 22/64 loss: 1.9250144958496094
Batch 23/64 loss: 1.9132614135742188
Batch 24/64 loss: 2.0781469345092773
Batch 25/64 loss: 2.537449836730957
Batch 26/64 loss: 1.8011651039123535
Batch 27/64 loss: 2.0832691192626953
Batch 28/64 loss: 1.7549524307250977
Batch 29/64 loss: 1.8945269584655762
Batch 30/64 loss: 4.352810859680176
Batch 31/64 loss: 1.864114761352539
Batch 32/64 loss: 1.840914249420166
Batch 33/64 loss: 1.8854069709777832
Batch 34/64 loss: 1.795539379119873
Batch 35/64 loss: 1.9516234397888184
Batch 36/64 loss: 2.557511806488037
Batch 37/64 loss: 2.0417604446411133
Batch 38/64 loss: 2.1560893058776855
Batch 39/64 loss: 2.042379379272461
Batch 40/64 loss: 3.282639980316162
Batch 41/64 loss: 1.9254517555236816
Batch 42/64 loss: 1.7483344078063965
Batch 43/64 loss: 1.9406309127807617
Batch 44/64 loss: 2.0949039459228516
Batch 45/64 loss: 1.9156737327575684
Batch 46/64 loss: 1.9192476272583008
Batch 47/64 loss: 1.8086037635803223
Batch 48/64 loss: 1.8362045288085938
Batch 49/64 loss: 1.789445400238037
Batch 50/64 loss: 1.8888401985168457
Batch 51/64 loss: 1.9385299682617188
Batch 52/64 loss: 1.7444300651550293
Batch 53/64 loss: 1.7337532043457031
Batch 54/64 loss: 1.8845124244689941
Batch 55/64 loss: 1.8812499046325684
Batch 56/64 loss: 1.7822694778442383
Batch 57/64 loss: 3.961550235748291
Batch 58/64 loss: 2.087332248687744
Batch 59/64 loss: 2.1471357345581055
Batch 60/64 loss: 2.1304264068603516
Batch 61/64 loss: 2.3492555618286133
Batch 62/64 loss: 2.6831765174865723
Batch 63/64 loss: 5.787292003631592
Batch 64/64 loss: 2.679044723510742
Epoch 208  Train loss: 2.2005610746495865  Val loss: 4.197841985119167
Epoch 209
-------------------------------
Batch 1/64 loss: 2.650360107421875
Batch 2/64 loss: 2.475757598876953
Batch 3/64 loss: 2.629645824432373
Batch 4/64 loss: 5.320476055145264
Batch 5/64 loss: 3.248671054840088
Batch 6/64 loss: 2.6410012245178223
Batch 7/64 loss: 3.0688772201538086
Batch 8/64 loss: 3.417769432067871
Batch 9/64 loss: 2.5539236068725586
Batch 10/64 loss: 3.5735769271850586
Batch 11/64 loss: 3.417357921600342
Batch 12/64 loss: 2.318307399749756
Batch 13/64 loss: 2.390472888946533
Batch 14/64 loss: 2.472527503967285
Batch 15/64 loss: 2.3846726417541504
Batch 16/64 loss: 2.4419236183166504
Batch 17/64 loss: 5.839321136474609
Batch 18/64 loss: 2.5921826362609863
Batch 19/64 loss: 2.2151193618774414
Batch 20/64 loss: 2.394002914428711
Batch 21/64 loss: 2.2908568382263184
Batch 22/64 loss: 2.9187350273132324
Batch 23/64 loss: 2.621246814727783
Batch 24/64 loss: 2.3124470710754395
Batch 25/64 loss: 2.5541577339172363
Batch 26/64 loss: 2.360384941101074
Batch 27/64 loss: 2.2786660194396973
Batch 28/64 loss: 2.114474296569824
Batch 29/64 loss: 2.135374069213867
Batch 30/64 loss: 2.0835609436035156
Batch 31/64 loss: 3.8126044273376465
Batch 32/64 loss: 2.0648093223571777
Batch 33/64 loss: 2.288191795349121
Batch 34/64 loss: 2.2375540733337402
Batch 35/64 loss: 2.1022400856018066
Batch 36/64 loss: 2.076061248779297
Batch 37/64 loss: 2.4580535888671875
Batch 38/64 loss: 2.5061163902282715
Batch 39/64 loss: 2.1128153800964355
Batch 40/64 loss: 2.076765537261963
Batch 41/64 loss: 2.2414045333862305
Batch 42/64 loss: 5.189679145812988
Batch 43/64 loss: 4.193624973297119
Batch 44/64 loss: 2.1582560539245605
Batch 45/64 loss: 1.8761811256408691
Batch 46/64 loss: 3.467866897583008
Batch 47/64 loss: 2.2325477600097656
Batch 48/64 loss: 2.550950527191162
Batch 49/64 loss: 2.06742000579834
Batch 50/64 loss: 2.5199642181396484
Batch 51/64 loss: 3.1588854789733887
Batch 52/64 loss: 2.5756216049194336
Batch 53/64 loss: 2.2346901893615723
Batch 54/64 loss: 2.1033835411071777
Batch 55/64 loss: 2.828685760498047
Batch 56/64 loss: 2.4564685821533203
Batch 57/64 loss: 2.4335098266601562
Batch 58/64 loss: 2.3175950050354004
Batch 59/64 loss: 2.229783535003662
Batch 60/64 loss: 2.642627716064453
Batch 61/64 loss: 2.2763757705688477
Batch 62/64 loss: 1.9419069290161133
Batch 63/64 loss: 3.037107467651367
Batch 64/64 loss: -1.3455915451049805
Epoch 209  Train loss: 2.6223749908746457  Val loss: 1.893335925754403
Epoch 210
-------------------------------
Batch 1/64 loss: 2.3942246437072754
Batch 2/64 loss: 4.571154594421387
Batch 3/64 loss: 1.9827485084533691
Batch 4/64 loss: 2.878014087677002
Batch 5/64 loss: 1.939117431640625
Batch 6/64 loss: 2.0169129371643066
Batch 7/64 loss: 1.9651217460632324
Batch 8/64 loss: 2.065279960632324
Batch 9/64 loss: 1.8454203605651855
Batch 10/64 loss: 3.442476749420166
Batch 11/64 loss: 2.062002182006836
Batch 12/64 loss: 1.94850492477417
Batch 13/64 loss: 1.9132723808288574
Batch 14/64 loss: 2.513317108154297
Batch 15/64 loss: 2.063344955444336
Batch 16/64 loss: 1.9418296813964844
Batch 17/64 loss: 1.8967881202697754
Batch 18/64 loss: 1.9428014755249023
Batch 19/64 loss: 1.9289908409118652
Batch 20/64 loss: 1.9515509605407715
Batch 21/64 loss: 2.1396865844726562
Batch 22/64 loss: 1.892256736755371
Batch 23/64 loss: 1.9475908279418945
Batch 24/64 loss: 1.7956805229187012
Batch 25/64 loss: 2.090467929840088
Batch 26/64 loss: 2.2687931060791016
Batch 27/64 loss: 3.403831958770752
Batch 28/64 loss: 1.970865249633789
Batch 29/64 loss: 2.00343656539917
Batch 30/64 loss: 2.283267021179199
Batch 31/64 loss: 1.8882803916931152
Batch 32/64 loss: 2.785407066345215
Batch 33/64 loss: 2.064438819885254
Batch 34/64 loss: 1.9215588569641113
Batch 35/64 loss: 4.228079319000244
Batch 36/64 loss: 1.7910242080688477
Batch 37/64 loss: 1.900620460510254
Batch 38/64 loss: 1.9248003959655762
Batch 39/64 loss: 1.8917269706726074
Batch 40/64 loss: 1.8365607261657715
Batch 41/64 loss: 2.165764808654785
Batch 42/64 loss: 2.5930490493774414
Batch 43/64 loss: 1.7459468841552734
Batch 44/64 loss: 2.03554630279541
Batch 45/64 loss: 2.1655960083007812
Batch 46/64 loss: 1.8132929801940918
Batch 47/64 loss: 1.9361286163330078
Batch 48/64 loss: 1.9117684364318848
Batch 49/64 loss: 2.5215816497802734
Batch 50/64 loss: 1.957848072052002
Batch 51/64 loss: 1.7390427589416504
Batch 52/64 loss: 2.144658088684082
Batch 53/64 loss: 2.0264062881469727
Batch 54/64 loss: 1.7057914733886719
Batch 55/64 loss: 1.8804054260253906
Batch 56/64 loss: 2.206818103790283
Batch 57/64 loss: 1.9517321586608887
Batch 58/64 loss: 1.8500361442565918
Batch 59/64 loss: 1.9693660736083984
Batch 60/64 loss: 1.8510804176330566
Batch 61/64 loss: 2.689903736114502
Batch 62/64 loss: 4.771312236785889
Batch 63/64 loss: 2.3806567192077637
Batch 64/64 loss: -1.6584758758544922
Epoch 210  Train loss: 2.1656646728515625  Val loss: 1.6666150699366409
Epoch 211
-------------------------------
Batch 1/64 loss: 1.9494414329528809
Batch 2/64 loss: 1.8202776908874512
Batch 3/64 loss: 1.8941526412963867
Batch 4/64 loss: 1.943807601928711
Batch 5/64 loss: 2.1258115768432617
Batch 6/64 loss: 4.081891059875488
Batch 7/64 loss: 1.9546356201171875
Batch 8/64 loss: 5.317023277282715
Batch 9/64 loss: 4.425701141357422
Batch 10/64 loss: 2.8160881996154785
Batch 11/64 loss: 2.6423254013061523
Batch 12/64 loss: 2.032458782196045
Batch 13/64 loss: 1.879697322845459
Batch 14/64 loss: 1.8824262619018555
Batch 15/64 loss: 1.9838180541992188
Batch 16/64 loss: 1.9381275177001953
Batch 17/64 loss: 2.183962345123291
Batch 18/64 loss: 1.920546531677246
Batch 19/64 loss: 2.3538804054260254
Batch 20/64 loss: 3.32358980178833
Batch 21/64 loss: 1.7315349578857422
Batch 22/64 loss: 2.2100272178649902
Batch 23/64 loss: 1.9454894065856934
Batch 24/64 loss: 2.501488208770752
Batch 25/64 loss: 1.8201346397399902
Batch 26/64 loss: 2.025871753692627
Batch 27/64 loss: 1.8533992767333984
Batch 28/64 loss: 1.813194751739502
Batch 29/64 loss: 2.265857219696045
Batch 30/64 loss: 1.763932228088379
Batch 31/64 loss: 2.08687686920166
Batch 32/64 loss: 1.9865169525146484
Batch 33/64 loss: 1.9956693649291992
Batch 34/64 loss: 2.0482444763183594
Batch 35/64 loss: 1.7592105865478516
Batch 36/64 loss: 1.8170075416564941
Batch 37/64 loss: 1.870908260345459
Batch 38/64 loss: 1.969322681427002
Batch 39/64 loss: 1.7432990074157715
Batch 40/64 loss: 2.202731132507324
Batch 41/64 loss: 2.046358585357666
Batch 42/64 loss: 1.949683666229248
Batch 43/64 loss: 2.0171022415161133
Batch 44/64 loss: 2.279242515563965
Batch 45/64 loss: 1.821732521057129
Batch 46/64 loss: 2.25996732711792
Batch 47/64 loss: 2.033806324005127
Batch 48/64 loss: 1.7979660034179688
Batch 49/64 loss: 1.8602533340454102
Batch 50/64 loss: 2.1425232887268066
Batch 51/64 loss: 1.893782615661621
Batch 52/64 loss: 1.8362488746643066
Batch 53/64 loss: 2.4173293113708496
Batch 54/64 loss: 1.8038253784179688
Batch 55/64 loss: 1.8386592864990234
Batch 56/64 loss: 1.91377592086792
Batch 57/64 loss: 1.8484430313110352
Batch 58/64 loss: 1.6750001907348633
Batch 59/64 loss: 1.7737703323364258
Batch 60/64 loss: 1.8278865814208984
Batch 61/64 loss: 1.8382554054260254
Batch 62/64 loss: 1.855940341949463
Batch 63/64 loss: 1.8674640655517578
Batch 64/64 loss: -0.25407886505126953
Epoch 211  Train loss: 2.106491563834396  Val loss: 1.6272735988970883
Epoch 212
-------------------------------
Batch 1/64 loss: 2.1852564811706543
Batch 2/64 loss: 1.7552061080932617
Batch 3/64 loss: 4.410830020904541
Batch 4/64 loss: 1.9468164443969727
Batch 5/64 loss: 1.7667322158813477
Batch 6/64 loss: 1.8997740745544434
Batch 7/64 loss: 2.5500659942626953
Batch 8/64 loss: 1.7719850540161133
Batch 9/64 loss: 4.9195780754089355
Batch 10/64 loss: 3.980891704559326
Batch 11/64 loss: 2.204195022583008
Batch 12/64 loss: 2.0245532989501953
Batch 13/64 loss: 1.7808308601379395
Batch 14/64 loss: 2.206902027130127
Batch 15/64 loss: 1.90494966506958
Batch 16/64 loss: 1.748239517211914
Batch 17/64 loss: 1.9341259002685547
Batch 18/64 loss: 1.9558887481689453
Batch 19/64 loss: 1.9365196228027344
Batch 20/64 loss: 3.160062313079834
Batch 21/64 loss: 1.8396472930908203
Batch 22/64 loss: 2.1030426025390625
Batch 23/64 loss: 1.857287883758545
Batch 24/64 loss: 2.0091023445129395
Batch 25/64 loss: 1.780181884765625
Batch 26/64 loss: 1.8060293197631836
Batch 27/64 loss: 2.772141456604004
Batch 28/64 loss: 1.7300548553466797
Batch 29/64 loss: 2.0411367416381836
Batch 30/64 loss: 1.8325247764587402
Batch 31/64 loss: 1.7287931442260742
Batch 32/64 loss: 2.1324377059936523
Batch 33/64 loss: 2.302438735961914
Batch 34/64 loss: 1.8337416648864746
Batch 35/64 loss: 2.158224582672119
Batch 36/64 loss: 2.0011768341064453
Batch 37/64 loss: 2.024289131164551
Batch 38/64 loss: 1.792229175567627
Batch 39/64 loss: 1.8539600372314453
Batch 40/64 loss: 3.255913257598877
Batch 41/64 loss: 1.7907299995422363
Batch 42/64 loss: 1.992931842803955
Batch 43/64 loss: 1.8611087799072266
Batch 44/64 loss: 1.7832331657409668
Batch 45/64 loss: 1.864851474761963
Batch 46/64 loss: 1.767927646636963
Batch 47/64 loss: 1.8563990592956543
Batch 48/64 loss: 1.8679718971252441
Batch 49/64 loss: 1.7326340675354004
Batch 50/64 loss: 2.6237096786499023
Batch 51/64 loss: 1.8293190002441406
Batch 52/64 loss: 2.005516529083252
Batch 53/64 loss: 1.8107833862304688
Batch 54/64 loss: 1.8746938705444336
Batch 55/64 loss: 1.84759521484375
Batch 56/64 loss: 2.0617876052856445
Batch 57/64 loss: 1.8443818092346191
Batch 58/64 loss: 1.8433904647827148
Batch 59/64 loss: 2.3013076782226562
Batch 60/64 loss: 1.8917279243469238
Batch 61/64 loss: 1.8710026741027832
Batch 62/64 loss: 1.8625645637512207
Batch 63/64 loss: 2.1090612411499023
Batch 64/64 loss: -1.6623363494873047
Epoch 212  Train loss: 2.069735433541092  Val loss: 1.5931145710633792
Epoch 213
-------------------------------
Batch 1/64 loss: 2.0233359336853027
Batch 2/64 loss: 2.191129684448242
Batch 3/64 loss: 1.826941967010498
Batch 4/64 loss: 1.9479999542236328
Batch 5/64 loss: 1.832620620727539
Batch 6/64 loss: 1.7624578475952148
Batch 7/64 loss: 1.8027896881103516
Batch 8/64 loss: 2.0114364624023438
Batch 9/64 loss: 1.8409886360168457
Batch 10/64 loss: 2.1259279251098633
Batch 11/64 loss: 1.7200813293457031
Batch 12/64 loss: 1.9595832824707031
Batch 13/64 loss: 2.6107234954833984
Batch 14/64 loss: 1.7998476028442383
Batch 15/64 loss: 1.8020849227905273
Batch 16/64 loss: 1.871476650238037
Batch 17/64 loss: 1.7910399436950684
Batch 18/64 loss: 2.1503162384033203
Batch 19/64 loss: 1.8419585227966309
Batch 20/64 loss: 1.8547611236572266
Batch 21/64 loss: 4.425080299377441
Batch 22/64 loss: 1.856837272644043
Batch 23/64 loss: 1.8730525970458984
Batch 24/64 loss: 2.123767375946045
Batch 25/64 loss: 1.9897971153259277
Batch 26/64 loss: 1.73701810836792
Batch 27/64 loss: 1.829620361328125
Batch 28/64 loss: 2.1977481842041016
Batch 29/64 loss: 1.7904629707336426
Batch 30/64 loss: 2.0463156700134277
Batch 31/64 loss: 1.775611400604248
Batch 32/64 loss: 4.825845241546631
Batch 33/64 loss: 1.84102201461792
Batch 34/64 loss: 3.0383925437927246
Batch 35/64 loss: 2.0791540145874023
Batch 36/64 loss: 1.7550873756408691
Batch 37/64 loss: 2.2661900520324707
Batch 38/64 loss: 2.0508995056152344
Batch 39/64 loss: 1.975947380065918
Batch 40/64 loss: 2.234623908996582
Batch 41/64 loss: 1.8640484809875488
Batch 42/64 loss: 1.9477272033691406
Batch 43/64 loss: 2.128396987915039
Batch 44/64 loss: 2.14125919342041
Batch 45/64 loss: 1.913222312927246
Batch 46/64 loss: 2.075789451599121
Batch 47/64 loss: 2.245572566986084
Batch 48/64 loss: 1.8248372077941895
Batch 49/64 loss: 3.8035316467285156
Batch 50/64 loss: 2.3600950241088867
Batch 51/64 loss: 1.9046893119812012
Batch 52/64 loss: 1.8215155601501465
Batch 53/64 loss: 2.0357861518859863
Batch 54/64 loss: 1.9350013732910156
Batch 55/64 loss: 2.0362329483032227
Batch 56/64 loss: 1.9299664497375488
Batch 57/64 loss: 1.9415078163146973
Batch 58/64 loss: 1.8043465614318848
Batch 59/64 loss: 2.9286298751831055
Batch 60/64 loss: 1.8115911483764648
Batch 61/64 loss: 1.9838037490844727
Batch 62/64 loss: 1.8423004150390625
Batch 63/64 loss: 4.044998645782471
Batch 64/64 loss: -1.427947998046875
Epoch 213  Train loss: 2.097786106782801  Val loss: 1.64133594945534
Epoch 214
-------------------------------
Batch 1/64 loss: 1.7747087478637695
Batch 2/64 loss: 2.0117135047912598
Batch 3/64 loss: 2.9171972274780273
Batch 4/64 loss: 2.013731002807617
Batch 5/64 loss: 1.8910307884216309
Batch 6/64 loss: 1.8603496551513672
Batch 7/64 loss: 1.817946434020996
Batch 8/64 loss: 1.9336867332458496
Batch 9/64 loss: 1.7784476280212402
Batch 10/64 loss: 1.9881291389465332
Batch 11/64 loss: 1.7711639404296875
Batch 12/64 loss: 1.7287588119506836
Batch 13/64 loss: 1.9000897407531738
Batch 14/64 loss: 1.957773208618164
Batch 15/64 loss: 1.7809782028198242
Batch 16/64 loss: 2.8666443824768066
Batch 17/64 loss: 1.8098258972167969
Batch 18/64 loss: 2.1284356117248535
Batch 19/64 loss: 1.8259310722351074
Batch 20/64 loss: 1.936133861541748
Batch 21/64 loss: 1.7700223922729492
Batch 22/64 loss: 1.9667620658874512
Batch 23/64 loss: 1.9014225006103516
Batch 24/64 loss: 1.8012681007385254
Batch 25/64 loss: 2.1122183799743652
Batch 26/64 loss: 2.385610580444336
Batch 27/64 loss: 1.7533988952636719
Batch 28/64 loss: 3.1157736778259277
Batch 29/64 loss: 1.9350814819335938
Batch 30/64 loss: 1.8955907821655273
Batch 31/64 loss: 1.7442684173583984
Batch 32/64 loss: 1.7409157752990723
Batch 33/64 loss: 1.9126238822937012
Batch 34/64 loss: 1.8998279571533203
Batch 35/64 loss: 2.524362087249756
Batch 36/64 loss: 1.767728328704834
Batch 37/64 loss: 1.9751996994018555
Batch 38/64 loss: 1.8801016807556152
Batch 39/64 loss: 1.813798427581787
Batch 40/64 loss: 2.5655150413513184
Batch 41/64 loss: 1.8142590522766113
Batch 42/64 loss: 1.7944064140319824
Batch 43/64 loss: 1.8629016876220703
Batch 44/64 loss: 4.9303364753723145
Batch 45/64 loss: 1.9734034538269043
Batch 46/64 loss: 2.013123035430908
Batch 47/64 loss: 1.9662013053894043
Batch 48/64 loss: 2.413236141204834
Batch 49/64 loss: 4.340851306915283
Batch 50/64 loss: 1.8667659759521484
Batch 51/64 loss: 1.9295940399169922
Batch 52/64 loss: 2.1818084716796875
Batch 53/64 loss: 1.9864158630371094
Batch 54/64 loss: 1.8251595497131348
Batch 55/64 loss: 3.9979538917541504
Batch 56/64 loss: 1.739689826965332
Batch 57/64 loss: 1.9221620559692383
Batch 58/64 loss: 1.8946113586425781
Batch 59/64 loss: 2.0359110832214355
Batch 60/64 loss: 1.992966651916504
Batch 61/64 loss: 1.993361473083496
Batch 62/64 loss: 1.875746250152588
Batch 63/64 loss: 1.8067889213562012
Batch 64/64 loss: -1.7017898559570312
Epoch 214  Train loss: 2.0554584727567784  Val loss: 1.61148808010665
Epoch 215
-------------------------------
Batch 1/64 loss: 1.8161087036132812
Batch 2/64 loss: 1.8367853164672852
Batch 3/64 loss: 4.737078666687012
Batch 4/64 loss: 1.8553214073181152
Batch 5/64 loss: 1.6551289558410645
Batch 6/64 loss: 1.821310043334961
Batch 7/64 loss: 1.7999496459960938
Batch 8/64 loss: 1.952441692352295
Batch 9/64 loss: 2.001114845275879
Batch 10/64 loss: 1.8705010414123535
Batch 11/64 loss: 1.8104572296142578
Batch 12/64 loss: 2.668609142303467
Batch 13/64 loss: 1.813772201538086
Batch 14/64 loss: 1.7510933876037598
Batch 15/64 loss: 1.744384765625
Batch 16/64 loss: 1.758347988128662
Batch 17/64 loss: 1.6953368186950684
Batch 18/64 loss: 1.7925176620483398
Batch 19/64 loss: 1.706315517425537
Batch 20/64 loss: 1.9741196632385254
Batch 21/64 loss: 2.2038373947143555
Batch 22/64 loss: 2.4633560180664062
Batch 23/64 loss: 2.876163959503174
Batch 24/64 loss: 1.7135138511657715
Batch 25/64 loss: 1.897932529449463
Batch 26/64 loss: 1.7497172355651855
Batch 27/64 loss: 1.8411250114440918
Batch 28/64 loss: 1.863354206085205
Batch 29/64 loss: 4.322998523712158
Batch 30/64 loss: 1.7217612266540527
Batch 31/64 loss: 2.384127140045166
Batch 32/64 loss: 2.1315464973449707
Batch 33/64 loss: 1.9288582801818848
Batch 34/64 loss: 1.82084321975708
Batch 35/64 loss: 3.0633230209350586
Batch 36/64 loss: 1.9954042434692383
Batch 37/64 loss: 1.9819135665893555
Batch 38/64 loss: 1.8764925003051758
Batch 39/64 loss: 2.0457592010498047
Batch 40/64 loss: 2.3048362731933594
Batch 41/64 loss: 1.8260784149169922
Batch 42/64 loss: 2.091167449951172
Batch 43/64 loss: 2.307802200317383
Batch 44/64 loss: 4.428623199462891
Batch 45/64 loss: 1.972808837890625
Batch 46/64 loss: 1.9241409301757812
Batch 47/64 loss: 1.901360034942627
Batch 48/64 loss: 2.0906643867492676
Batch 49/64 loss: 1.9862260818481445
Batch 50/64 loss: 1.8640861511230469
Batch 51/64 loss: 1.8793106079101562
Batch 52/64 loss: 2.649533748626709
Batch 53/64 loss: 1.9839186668395996
Batch 54/64 loss: 2.06740140914917
Batch 55/64 loss: 1.8185606002807617
Batch 56/64 loss: 2.0391392707824707
Batch 57/64 loss: 1.8259248733520508
Batch 58/64 loss: 2.0565342903137207
Batch 59/64 loss: 1.9538936614990234
Batch 60/64 loss: 3.2339272499084473
Batch 61/64 loss: 1.9747228622436523
Batch 62/64 loss: 1.8299226760864258
Batch 63/64 loss: 1.809067726135254
Batch 64/64 loss: -1.5320405960083008
Epoch 215  Train loss: 2.0802093094470453  Val loss: 1.8012440343902694
Epoch 216
-------------------------------
Batch 1/64 loss: 1.767862319946289
Batch 2/64 loss: 1.9107074737548828
Batch 3/64 loss: 3.1123790740966797
Batch 4/64 loss: 1.8765568733215332
Batch 5/64 loss: 1.7773289680480957
Batch 6/64 loss: 1.8327131271362305
Batch 7/64 loss: 1.7276554107666016
Batch 8/64 loss: 2.0018935203552246
Batch 9/64 loss: 2.149010181427002
Batch 10/64 loss: 2.109757423400879
Batch 11/64 loss: 1.970308780670166
Batch 12/64 loss: 1.7856755256652832
Batch 13/64 loss: 1.9184436798095703
Batch 14/64 loss: 2.096907615661621
Batch 15/64 loss: 2.1141982078552246
Batch 16/64 loss: 2.482848644256592
Batch 17/64 loss: 2.88914155960083
Batch 18/64 loss: 2.9404702186584473
Batch 19/64 loss: 1.954495906829834
Batch 20/64 loss: 4.350067615509033
Batch 21/64 loss: 2.1668787002563477
Batch 22/64 loss: 2.3576459884643555
Batch 23/64 loss: 2.6888694763183594
Batch 24/64 loss: 3.164318084716797
Batch 25/64 loss: 4.141656398773193
Batch 26/64 loss: 3.23148250579834
Batch 27/64 loss: 5.913081169128418
Batch 28/64 loss: 2.8644886016845703
Batch 29/64 loss: 3.006608486175537
Batch 30/64 loss: 3.244675636291504
Batch 31/64 loss: 5.533787727355957
Batch 32/64 loss: 3.693358898162842
Batch 33/64 loss: 2.902343273162842
Batch 34/64 loss: 3.3111720085144043
Batch 35/64 loss: 5.322506904602051
Batch 36/64 loss: 3.777463912963867
Batch 37/64 loss: 3.0774850845336914
Batch 38/64 loss: 2.7132744789123535
Batch 39/64 loss: 2.937798500061035
Batch 40/64 loss: 3.578084945678711
Batch 41/64 loss: 4.2069411277771
Batch 42/64 loss: 2.8770179748535156
Batch 43/64 loss: 2.7003064155578613
Batch 44/64 loss: 3.447476387023926
Batch 45/64 loss: 2.940314292907715
Batch 46/64 loss: 2.8691859245300293
Batch 47/64 loss: 2.7149171829223633
Batch 48/64 loss: 2.643693447113037
Batch 49/64 loss: 2.745302200317383
Batch 50/64 loss: 2.6536903381347656
Batch 51/64 loss: 2.591256618499756
Batch 52/64 loss: 2.855736255645752
Batch 53/64 loss: 2.873408317565918
Batch 54/64 loss: 3.3344573974609375
Batch 55/64 loss: 2.6645498275756836
Batch 56/64 loss: 2.5728626251220703
Batch 57/64 loss: 2.736143112182617
Batch 58/64 loss: 2.7567973136901855
Batch 59/64 loss: 5.091293811798096
Batch 60/64 loss: 2.3947811126708984
Batch 61/64 loss: 2.544041633605957
Batch 62/64 loss: 2.4241652488708496
Batch 63/64 loss: 2.6801300048828125
Batch 64/64 loss: -1.1032886505126953
Epoch 216  Train loss: 2.8374338037827433  Val loss: 2.533227186432409
Epoch 217
-------------------------------
Batch 1/64 loss: 3.025754928588867
Batch 2/64 loss: 2.1998777389526367
Batch 3/64 loss: 2.6686768531799316
Batch 4/64 loss: 2.724940776824951
Batch 5/64 loss: 3.670701026916504
Batch 6/64 loss: 2.7391533851623535
Batch 7/64 loss: 3.62144136428833
Batch 8/64 loss: 2.359325408935547
Batch 9/64 loss: 2.3900651931762695
Batch 10/64 loss: 3.404428482055664
Batch 11/64 loss: 2.308259963989258
Batch 12/64 loss: 2.2974658012390137
Batch 13/64 loss: 2.5640687942504883
Batch 14/64 loss: 2.2692580223083496
Batch 15/64 loss: 2.0592851638793945
Batch 16/64 loss: 2.337817668914795
Batch 17/64 loss: 2.1597752571105957
Batch 18/64 loss: 2.1202354431152344
Batch 19/64 loss: 2.180764675140381
Batch 20/64 loss: 2.5123653411865234
Batch 21/64 loss: 2.1568174362182617
Batch 22/64 loss: 1.9131832122802734
Batch 23/64 loss: 4.40773344039917
Batch 24/64 loss: 2.318840980529785
Batch 25/64 loss: 2.233732223510742
Batch 26/64 loss: 2.1686959266662598
Batch 27/64 loss: 2.076197624206543
Batch 28/64 loss: 2.4342756271362305
Batch 29/64 loss: 2.147251605987549
Batch 30/64 loss: 2.3152103424072266
Batch 31/64 loss: 2.0300064086914062
Batch 32/64 loss: 2.462033748626709
Batch 33/64 loss: 2.156918525695801
Batch 34/64 loss: 2.2392396926879883
Batch 35/64 loss: 1.9777593612670898
Batch 36/64 loss: 4.949104309082031
Batch 37/64 loss: 2.224888324737549
Batch 38/64 loss: 2.0520896911621094
Batch 39/64 loss: 2.9270825386047363
Batch 40/64 loss: 2.131804943084717
Batch 41/64 loss: 2.184305191040039
Batch 42/64 loss: 2.139537811279297
Batch 43/64 loss: 2.0777158737182617
Batch 44/64 loss: 2.642131805419922
Batch 45/64 loss: 2.193556308746338
Batch 46/64 loss: 2.232841968536377
Batch 47/64 loss: 2.2482285499572754
Batch 48/64 loss: 2.4614205360412598
Batch 49/64 loss: 2.232407569885254
Batch 50/64 loss: 2.136880397796631
Batch 51/64 loss: 1.9965686798095703
Batch 52/64 loss: 3.214082717895508
Batch 53/64 loss: 2.0331625938415527
Batch 54/64 loss: 2.5776968002319336
Batch 55/64 loss: 2.0098495483398438
Batch 56/64 loss: 1.8836159706115723
Batch 57/64 loss: 2.4773964881896973
Batch 58/64 loss: 2.026355266571045
Batch 59/64 loss: 4.486368179321289
Batch 60/64 loss: 2.3241052627563477
Batch 61/64 loss: 1.854764461517334
Batch 62/64 loss: 2.025127410888672
Batch 63/64 loss: 2.174981117248535
Batch 64/64 loss: -1.1838808059692383
Epoch 217  Train loss: 2.410693602468453  Val loss: 1.8301259201416855
Epoch 218
-------------------------------
Batch 1/64 loss: 2.1955385208129883
Batch 2/64 loss: 1.9361748695373535
Batch 3/64 loss: 2.056553363800049
Batch 4/64 loss: 2.4507012367248535
Batch 5/64 loss: 2.089664936065674
Batch 6/64 loss: 2.0069990158081055
Batch 7/64 loss: 2.0248546600341797
Batch 8/64 loss: 1.9318599700927734
Batch 9/64 loss: 4.578431129455566
Batch 10/64 loss: 2.104982852935791
Batch 11/64 loss: 2.296874523162842
Batch 12/64 loss: 2.028012275695801
Batch 13/64 loss: 2.0388031005859375
Batch 14/64 loss: 1.9290227890014648
Batch 15/64 loss: 1.9468564987182617
Batch 16/64 loss: 2.58144474029541
Batch 17/64 loss: 2.1350440979003906
Batch 18/64 loss: 2.771254539489746
Batch 19/64 loss: 3.4080042839050293
Batch 20/64 loss: 2.0028324127197266
Batch 21/64 loss: 2.086116313934326
Batch 22/64 loss: 1.9026050567626953
Batch 23/64 loss: 2.2679662704467773
Batch 24/64 loss: 2.4401373863220215
Batch 25/64 loss: 2.264094829559326
Batch 26/64 loss: 1.8835492134094238
Batch 27/64 loss: 2.2722702026367188
Batch 28/64 loss: 2.195645809173584
Batch 29/64 loss: 1.9204721450805664
Batch 30/64 loss: 2.2479395866394043
Batch 31/64 loss: 1.998868465423584
Batch 32/64 loss: 2.1331095695495605
Batch 33/64 loss: 2.380866050720215
Batch 34/64 loss: 2.0458626747131348
Batch 35/64 loss: 1.987377643585205
Batch 36/64 loss: 1.9824481010437012
Batch 37/64 loss: 1.9472942352294922
Batch 38/64 loss: 1.8484764099121094
Batch 39/64 loss: 1.9461474418640137
Batch 40/64 loss: 1.962198257446289
Batch 41/64 loss: 1.83799409866333
Batch 42/64 loss: 1.828904628753662
Batch 43/64 loss: 1.8621058464050293
Batch 44/64 loss: 2.2958688735961914
Batch 45/64 loss: 2.063129425048828
Batch 46/64 loss: 2.011655330657959
Batch 47/64 loss: 4.774537086486816
Batch 48/64 loss: 2.3528623580932617
Batch 49/64 loss: 2.1755285263061523
Batch 50/64 loss: 2.044224262237549
Batch 51/64 loss: 4.174437522888184
Batch 52/64 loss: 1.9945859909057617
Batch 53/64 loss: 3.08366060256958
Batch 54/64 loss: 1.8788414001464844
Batch 55/64 loss: 1.9880518913269043
Batch 56/64 loss: 1.8828892707824707
Batch 57/64 loss: 1.8956918716430664
Batch 58/64 loss: 1.8512182235717773
Batch 59/64 loss: 2.0015182495117188
Batch 60/64 loss: 1.9548239707946777
Batch 61/64 loss: 1.9359989166259766
Batch 62/64 loss: 1.894869327545166
Batch 63/64 loss: 1.822866439819336
Batch 64/64 loss: -0.3278684616088867
Epoch 218  Train loss: 2.1896112666410557  Val loss: 1.686864879123124
Epoch 219
-------------------------------
Batch 1/64 loss: 1.8715453147888184
Batch 2/64 loss: 1.8699445724487305
Batch 3/64 loss: 1.8768935203552246
Batch 4/64 loss: 1.7949333190917969
Batch 5/64 loss: 1.989025592803955
Batch 6/64 loss: 2.093719959259033
Batch 7/64 loss: 1.8957209587097168
Batch 8/64 loss: 1.9251737594604492
Batch 9/64 loss: 2.0101985931396484
Batch 10/64 loss: 1.9281549453735352
Batch 11/64 loss: 2.626260280609131
Batch 12/64 loss: 4.303555488586426
Batch 13/64 loss: 2.057185649871826
Batch 14/64 loss: 2.9403152465820312
Batch 15/64 loss: 1.9533309936523438
Batch 16/64 loss: 1.8377156257629395
Batch 17/64 loss: 2.155853271484375
Batch 18/64 loss: 1.8393640518188477
Batch 19/64 loss: 2.293606758117676
Batch 20/64 loss: 2.0274734497070312
Batch 21/64 loss: 1.8985986709594727
Batch 22/64 loss: 2.047928810119629
Batch 23/64 loss: 2.056443691253662
Batch 24/64 loss: 2.5418920516967773
Batch 25/64 loss: 2.1312575340270996
Batch 26/64 loss: 1.853506088256836
Batch 27/64 loss: 1.8473615646362305
Batch 28/64 loss: 2.0039305686950684
Batch 29/64 loss: 1.9577364921569824
Batch 30/64 loss: 1.8828353881835938
Batch 31/64 loss: 1.8881964683532715
Batch 32/64 loss: 1.8942012786865234
Batch 33/64 loss: 1.9420857429504395
Batch 34/64 loss: 2.098404884338379
Batch 35/64 loss: 2.1282286643981934
Batch 36/64 loss: 1.7578535079956055
Batch 37/64 loss: 1.965144157409668
Batch 38/64 loss: 4.340554237365723
Batch 39/64 loss: 3.3627991676330566
Batch 40/64 loss: 2.8634700775146484
Batch 41/64 loss: 2.2809205055236816
Batch 42/64 loss: 2.283407688140869
Batch 43/64 loss: 3.2808923721313477
Batch 44/64 loss: 2.3477091789245605
Batch 45/64 loss: 2.490190029144287
Batch 46/64 loss: 2.3943276405334473
Batch 47/64 loss: 3.1257028579711914
Batch 48/64 loss: 2.5509347915649414
Batch 49/64 loss: 3.056718349456787
Batch 50/64 loss: 2.9841904640197754
Batch 51/64 loss: 2.771462917327881
Batch 52/64 loss: 3.2819290161132812
Batch 53/64 loss: 2.3895249366760254
Batch 54/64 loss: 5.66696834564209
Batch 55/64 loss: 2.1980843544006348
Batch 56/64 loss: 2.314232349395752
Batch 57/64 loss: 2.4602251052856445
Batch 58/64 loss: 2.1955862045288086
Batch 59/64 loss: 2.8715901374816895
Batch 60/64 loss: 2.224911689758301
Batch 61/64 loss: 3.329246997833252
Batch 62/64 loss: 2.5209994316101074
Batch 63/64 loss: 2.4899168014526367
Batch 64/64 loss: -1.031416893005371
Epoch 219  Train loss: 2.360604076759488  Val loss: 2.2452186112551344
Epoch 220
-------------------------------
Batch 1/64 loss: 2.8264694213867188
Batch 2/64 loss: 5.305639743804932
Batch 3/64 loss: 2.505990505218506
Batch 4/64 loss: 2.1037192344665527
Batch 5/64 loss: 2.2353382110595703
Batch 6/64 loss: 2.8919453620910645
Batch 7/64 loss: 2.0839462280273438
Batch 8/64 loss: 3.1215672492980957
Batch 9/64 loss: 2.494086742401123
Batch 10/64 loss: 2.3567209243774414
Batch 11/64 loss: 2.4139208793640137
Batch 12/64 loss: 2.206679344177246
Batch 13/64 loss: 2.2170491218566895
Batch 14/64 loss: 2.0856432914733887
Batch 15/64 loss: 2.47520112991333
Batch 16/64 loss: 2.238101005554199
Batch 17/64 loss: 4.420280933380127
Batch 18/64 loss: 2.6727685928344727
Batch 19/64 loss: 2.340023994445801
Batch 20/64 loss: 1.9222822189331055
Batch 21/64 loss: 2.7106680870056152
Batch 22/64 loss: 1.9667510986328125
Batch 23/64 loss: 2.1397876739501953
Batch 24/64 loss: 2.099116802215576
Batch 25/64 loss: 2.087165355682373
Batch 26/64 loss: 2.1817784309387207
Batch 27/64 loss: 2.144650459289551
Batch 28/64 loss: 1.90592622756958
Batch 29/64 loss: 1.9344863891601562
Batch 30/64 loss: 1.942396640777588
Batch 31/64 loss: 2.3271656036376953
Batch 32/64 loss: 1.9898505210876465
Batch 33/64 loss: 1.9900336265563965
Batch 34/64 loss: 1.9376039505004883
Batch 35/64 loss: 4.563087463378906
Batch 36/64 loss: 1.970334529876709
Batch 37/64 loss: 1.9485821723937988
Batch 38/64 loss: 2.7738566398620605
Batch 39/64 loss: 1.8980932235717773
Batch 40/64 loss: 2.101210117340088
Batch 41/64 loss: 2.030268669128418
Batch 42/64 loss: 2.307692527770996
Batch 43/64 loss: 1.9792242050170898
Batch 44/64 loss: 3.0452346801757812
Batch 45/64 loss: 1.9369029998779297
Batch 46/64 loss: 2.458953380584717
Batch 47/64 loss: 1.951298713684082
Batch 48/64 loss: 2.0094261169433594
Batch 49/64 loss: 2.0204086303710938
Batch 50/64 loss: 2.0573720932006836
Batch 51/64 loss: 2.426858901977539
Batch 52/64 loss: 1.978529453277588
Batch 53/64 loss: 3.058065891265869
Batch 54/64 loss: 2.0142922401428223
Batch 55/64 loss: 2.106440544128418
Batch 56/64 loss: 2.1539669036865234
Batch 57/64 loss: 2.0072927474975586
Batch 58/64 loss: 1.9543194770812988
Batch 59/64 loss: 1.9618020057678223
Batch 60/64 loss: 3.028742790222168
Batch 61/64 loss: 1.7936787605285645
Batch 62/64 loss: 2.243340015411377
Batch 63/64 loss: 3.4232544898986816
Batch 64/64 loss: -1.4462461471557617
Epoch 220  Train loss: 2.327727070976706  Val loss: 1.7949394671777679
Epoch 221
-------------------------------
Batch 1/64 loss: 2.07511568069458
Batch 2/64 loss: 1.8157296180725098
Batch 3/64 loss: 2.0208563804626465
Batch 4/64 loss: 2.311455726623535
Batch 5/64 loss: 1.9674992561340332
Batch 6/64 loss: 2.1056151390075684
Batch 7/64 loss: 1.896557331085205
Batch 8/64 loss: 4.896553039550781
Batch 9/64 loss: 1.8778657913208008
Batch 10/64 loss: 2.0921149253845215
Batch 11/64 loss: 2.6983513832092285
Batch 12/64 loss: 1.896772861480713
Batch 13/64 loss: 2.0907363891601562
Batch 14/64 loss: 2.5526232719421387
Batch 15/64 loss: 1.9430317878723145
Batch 16/64 loss: 1.9421191215515137
Batch 17/64 loss: 2.6404032707214355
Batch 18/64 loss: 1.8877501487731934
Batch 19/64 loss: 1.8459367752075195
Batch 20/64 loss: 1.9755759239196777
Batch 21/64 loss: 1.9761452674865723
Batch 22/64 loss: 1.8199801445007324
Batch 23/64 loss: 1.8782172203063965
Batch 24/64 loss: 2.1812334060668945
Batch 25/64 loss: 2.0715789794921875
Batch 26/64 loss: 2.612387180328369
Batch 27/64 loss: 2.553856372833252
Batch 28/64 loss: 2.4698586463928223
Batch 29/64 loss: 1.7838282585144043
Batch 30/64 loss: 1.736659049987793
Batch 31/64 loss: 1.7709341049194336
Batch 32/64 loss: 2.189756393432617
Batch 33/64 loss: 2.018998146057129
Batch 34/64 loss: 1.9170522689819336
Batch 35/64 loss: 1.864159107208252
Batch 36/64 loss: 4.348845481872559
Batch 37/64 loss: 2.1360769271850586
Batch 38/64 loss: 2.0970349311828613
Batch 39/64 loss: 1.9608359336853027
Batch 40/64 loss: 1.873361587524414
Batch 41/64 loss: 1.8529071807861328
Batch 42/64 loss: 1.9597134590148926
Batch 43/64 loss: 2.1617331504821777
Batch 44/64 loss: 1.830172061920166
Batch 45/64 loss: 1.8923287391662598
Batch 46/64 loss: 2.0006937980651855
Batch 47/64 loss: 1.8636994361877441
Batch 48/64 loss: 1.8891234397888184
Batch 49/64 loss: 2.0204968452453613
Batch 50/64 loss: 1.7813591957092285
Batch 51/64 loss: 1.8107075691223145
Batch 52/64 loss: 1.8863105773925781
Batch 53/64 loss: 2.0207104682922363
Batch 54/64 loss: 2.3337583541870117
Batch 55/64 loss: 1.9432053565979004
Batch 56/64 loss: 2.1412014961242676
Batch 57/64 loss: 4.211339473724365
Batch 58/64 loss: 2.108238697052002
Batch 59/64 loss: 1.9676456451416016
Batch 60/64 loss: 2.0864696502685547
Batch 61/64 loss: 2.1196770668029785
Batch 62/64 loss: 2.09376859664917
Batch 63/64 loss: 1.8695502281188965
Batch 64/64 loss: 1.1440458297729492
Epoch 221  Train loss: 2.141118558247884  Val loss: 1.6958860285913002
Epoch 222
-------------------------------
Batch 1/64 loss: 1.7969036102294922
Batch 2/64 loss: 1.964670181274414
Batch 3/64 loss: 1.686302661895752
Batch 4/64 loss: 1.852247714996338
Batch 5/64 loss: 1.9498295783996582
Batch 6/64 loss: 2.9515223503112793
Batch 7/64 loss: 2.0952248573303223
Batch 8/64 loss: 2.0481982231140137
Batch 9/64 loss: 2.3598008155822754
Batch 10/64 loss: 1.8344316482543945
Batch 11/64 loss: 1.877596378326416
Batch 12/64 loss: 4.81960391998291
Batch 13/64 loss: 2.0145511627197266
Batch 14/64 loss: 1.894500732421875
Batch 15/64 loss: 1.8073649406433105
Batch 16/64 loss: 1.8191218376159668
Batch 17/64 loss: 2.1444406509399414
Batch 18/64 loss: 1.9748649597167969
Batch 19/64 loss: 1.9272122383117676
Batch 20/64 loss: 1.9369144439697266
Batch 21/64 loss: 1.914057731628418
Batch 22/64 loss: 1.9730463027954102
Batch 23/64 loss: 1.9276456832885742
Batch 24/64 loss: 2.0110015869140625
Batch 25/64 loss: 1.8685622215270996
Batch 26/64 loss: 2.1249303817749023
Batch 27/64 loss: 2.5313925743103027
Batch 28/64 loss: 1.8800621032714844
Batch 29/64 loss: 3.088670253753662
Batch 30/64 loss: 2.0453805923461914
Batch 31/64 loss: 2.062826633453369
Batch 32/64 loss: 1.9958195686340332
Batch 33/64 loss: 2.116302967071533
Batch 34/64 loss: 1.9574155807495117
Batch 35/64 loss: 1.8643689155578613
Batch 36/64 loss: 1.827120304107666
Batch 37/64 loss: 2.1522507667541504
Batch 38/64 loss: 1.7621560096740723
Batch 39/64 loss: 1.865522861480713
Batch 40/64 loss: 2.161560535430908
Batch 41/64 loss: 1.9309673309326172
Batch 42/64 loss: 1.779548168182373
Batch 43/64 loss: 1.7789273262023926
Batch 44/64 loss: 2.0399060249328613
Batch 45/64 loss: 1.7606191635131836
Batch 46/64 loss: 3.115321636199951
Batch 47/64 loss: 1.8408689498901367
Batch 48/64 loss: 1.8548245429992676
Batch 49/64 loss: 1.9377155303955078
Batch 50/64 loss: 1.9734406471252441
Batch 51/64 loss: 1.930819034576416
Batch 52/64 loss: 2.5824942588806152
Batch 53/64 loss: 1.8778138160705566
Batch 54/64 loss: 1.875166893005371
Batch 55/64 loss: 4.227463722229004
Batch 56/64 loss: 2.0661182403564453
Batch 57/64 loss: 1.8871970176696777
Batch 58/64 loss: 2.1072797775268555
Batch 59/64 loss: 4.221423149108887
Batch 60/64 loss: 1.8591856956481934
Batch 61/64 loss: 1.9335551261901855
Batch 62/64 loss: 2.346935749053955
Batch 63/64 loss: 2.0207085609436035
Batch 64/64 loss: -1.509552001953125
Epoch 222  Train loss: 2.0972789465212354  Val loss: 1.69204565094099
Epoch 223
-------------------------------
Batch 1/64 loss: 1.8822107315063477
Batch 2/64 loss: 1.8691844940185547
Batch 3/64 loss: 1.8453950881958008
Batch 4/64 loss: 1.8423371315002441
Batch 5/64 loss: 1.8163866996765137
Batch 6/64 loss: 1.8572916984558105
Batch 7/64 loss: 2.1912717819213867
Batch 8/64 loss: 1.7582321166992188
Batch 9/64 loss: 2.1735548973083496
Batch 10/64 loss: 1.7888975143432617
Batch 11/64 loss: 1.8133010864257812
Batch 12/64 loss: 1.9913949966430664
Batch 13/64 loss: 2.091282367706299
Batch 14/64 loss: 4.005125522613525
Batch 15/64 loss: 1.7506918907165527
Batch 16/64 loss: 2.039133071899414
Batch 17/64 loss: 1.9786152839660645
Batch 18/64 loss: 1.8908815383911133
Batch 19/64 loss: 2.3335671424865723
Batch 20/64 loss: 1.9847164154052734
Batch 21/64 loss: 2.0306577682495117
Batch 22/64 loss: 2.029965877532959
Batch 23/64 loss: 1.860032558441162
Batch 24/64 loss: 1.971348762512207
Batch 25/64 loss: 2.1089091300964355
Batch 26/64 loss: 1.8285117149353027
Batch 27/64 loss: 1.8492541313171387
Batch 28/64 loss: 1.9869976043701172
Batch 29/64 loss: 1.9178876876831055
Batch 30/64 loss: 2.081963062286377
Batch 31/64 loss: 2.41815185546875
Batch 32/64 loss: 1.9940009117126465
Batch 33/64 loss: 1.915696620941162
Batch 34/64 loss: 1.7850704193115234
Batch 35/64 loss: 4.781818389892578
Batch 36/64 loss: 2.521118640899658
Batch 37/64 loss: 2.078138828277588
Batch 38/64 loss: 2.1356606483459473
Batch 39/64 loss: 1.9071931838989258
Batch 40/64 loss: 1.849602222442627
Batch 41/64 loss: 2.730928421020508
Batch 42/64 loss: 1.8023381233215332
Batch 43/64 loss: 1.8350615501403809
Batch 44/64 loss: 2.912095069885254
Batch 45/64 loss: 1.9066543579101562
Batch 46/64 loss: 2.0241546630859375
Batch 47/64 loss: 1.9776849746704102
Batch 48/64 loss: 1.6629815101623535
Batch 49/64 loss: 2.047184944152832
Batch 50/64 loss: 1.9155912399291992
Batch 51/64 loss: 1.9564218521118164
Batch 52/64 loss: 1.7619857788085938
Batch 53/64 loss: 3.1147618293762207
Batch 54/64 loss: 1.7461857795715332
Batch 55/64 loss: 2.1381664276123047
Batch 56/64 loss: 1.7330999374389648
Batch 57/64 loss: 1.844080924987793
Batch 58/64 loss: 1.894545078277588
Batch 59/64 loss: 2.020376682281494
Batch 60/64 loss: 1.833829402923584
Batch 61/64 loss: 4.514224052429199
Batch 62/64 loss: 1.9023103713989258
Batch 63/64 loss: 2.1672492027282715
Batch 64/64 loss: -1.6223363876342773
Epoch 223  Train loss: 2.073421354854808  Val loss: 1.647217465430191
Epoch 224
-------------------------------
Batch 1/64 loss: 1.8108453750610352
Batch 2/64 loss: 1.8238348960876465
Batch 3/64 loss: 1.816328525543213
Batch 4/64 loss: 1.8780217170715332
Batch 5/64 loss: 1.829702377319336
Batch 6/64 loss: 4.9524245262146
Batch 7/64 loss: 2.050501823425293
Batch 8/64 loss: 1.8101506233215332
Batch 9/64 loss: 2.9770607948303223
Batch 10/64 loss: 2.012193202972412
Batch 11/64 loss: 1.9750676155090332
Batch 12/64 loss: 2.2147293090820312
Batch 13/64 loss: 1.8791308403015137
Batch 14/64 loss: 1.9048190116882324
Batch 15/64 loss: 1.9409451484680176
Batch 16/64 loss: 1.8845863342285156
Batch 17/64 loss: 2.010868549346924
Batch 18/64 loss: 1.9922833442687988
Batch 19/64 loss: 2.0040969848632812
Batch 20/64 loss: 2.4774694442749023
Batch 21/64 loss: 1.8250155448913574
Batch 22/64 loss: 1.961446762084961
Batch 23/64 loss: 1.9028100967407227
Batch 24/64 loss: 4.890199184417725
Batch 25/64 loss: 1.849541187286377
Batch 26/64 loss: 1.908128261566162
Batch 27/64 loss: 1.7784624099731445
Batch 28/64 loss: 1.8139739036560059
Batch 29/64 loss: 2.1232433319091797
Batch 30/64 loss: 1.9127211570739746
Batch 31/64 loss: 1.80851411819458
Batch 32/64 loss: 2.4908370971679688
Batch 33/64 loss: 2.1472268104553223
Batch 34/64 loss: 2.1736249923706055
Batch 35/64 loss: 1.8034753799438477
Batch 36/64 loss: 1.9013152122497559
Batch 37/64 loss: 1.8123445510864258
Batch 38/64 loss: 2.2557921409606934
Batch 39/64 loss: 1.8364691734313965
Batch 40/64 loss: 1.7732772827148438
Batch 41/64 loss: 2.038330078125
Batch 42/64 loss: 2.3666577339172363
Batch 43/64 loss: 2.1818795204162598
Batch 44/64 loss: 4.2323317527771
Batch 45/64 loss: 1.8540759086608887
Batch 46/64 loss: 1.74306058883667
Batch 47/64 loss: 1.7269096374511719
Batch 48/64 loss: 1.744685173034668
Batch 49/64 loss: 1.9464526176452637
Batch 50/64 loss: 1.8916277885437012
Batch 51/64 loss: 1.7756891250610352
Batch 52/64 loss: 3.059399127960205
Batch 53/64 loss: 2.575491428375244
Batch 54/64 loss: 1.9818997383117676
Batch 55/64 loss: 1.7912993431091309
Batch 56/64 loss: 1.8105497360229492
Batch 57/64 loss: 1.774146556854248
Batch 58/64 loss: 1.9007282257080078
Batch 59/64 loss: 2.1676907539367676
Batch 60/64 loss: 1.7816166877746582
Batch 61/64 loss: 1.8837108612060547
Batch 62/64 loss: 2.0736613273620605
Batch 63/64 loss: 1.8755121231079102
Batch 64/64 loss: -1.479696273803711
Epoch 224  Train loss: 2.0749978458180145  Val loss: 1.6609375681664116
Epoch 225
-------------------------------
Batch 1/64 loss: 1.7360525131225586
Batch 2/64 loss: 2.0301923751831055
Batch 3/64 loss: 1.7493371963500977
Batch 4/64 loss: 2.4562621116638184
Batch 5/64 loss: 1.847240924835205
Batch 6/64 loss: 1.7759027481079102
Batch 7/64 loss: 1.9192190170288086
Batch 8/64 loss: 1.7559022903442383
Batch 9/64 loss: 1.812950611114502
Batch 10/64 loss: 2.0906500816345215
Batch 11/64 loss: 1.9554686546325684
Batch 12/64 loss: 1.996124267578125
Batch 13/64 loss: 1.9019217491149902
Batch 14/64 loss: 4.237035751342773
Batch 15/64 loss: 1.841264247894287
Batch 16/64 loss: 1.9517483711242676
Batch 17/64 loss: 1.8125152587890625
Batch 18/64 loss: 3.07077693939209
Batch 19/64 loss: 1.7655444145202637
Batch 20/64 loss: 1.8799419403076172
Batch 21/64 loss: 1.8532724380493164
Batch 22/64 loss: 2.2136731147766113
Batch 23/64 loss: 1.9530582427978516
Batch 24/64 loss: 4.99083137512207
Batch 25/64 loss: 1.83320951461792
Batch 26/64 loss: 2.055914878845215
Batch 27/64 loss: 2.4443612098693848
Batch 28/64 loss: 2.63478946685791
Batch 29/64 loss: 2.627063274383545
Batch 30/64 loss: 2.754547595977783
Batch 31/64 loss: 5.777740955352783
Batch 32/64 loss: 2.7767834663391113
Batch 33/64 loss: 2.670197010040283
Batch 34/64 loss: 2.387131690979004
Batch 35/64 loss: 3.0377941131591797
Batch 36/64 loss: 4.910671234130859
Batch 37/64 loss: 2.7341179847717285
Batch 38/64 loss: 7.165446758270264
Batch 39/64 loss: 2.350254535675049
Batch 40/64 loss: 2.6254186630249023
Batch 41/64 loss: 3.478123664855957
Batch 42/64 loss: 3.3446974754333496
Batch 43/64 loss: 2.9340624809265137
Batch 44/64 loss: 2.3652920722961426
Batch 45/64 loss: 3.0442862510681152
Batch 46/64 loss: 2.578493595123291
Batch 47/64 loss: 2.5268912315368652
Batch 48/64 loss: 3.140798568725586
Batch 49/64 loss: 2.3382930755615234
Batch 50/64 loss: 3.8650684356689453
Batch 51/64 loss: 2.41275691986084
Batch 52/64 loss: 2.9946885108947754
Batch 53/64 loss: 2.317809581756592
Batch 54/64 loss: 3.506202220916748
Batch 55/64 loss: 2.911954402923584
Batch 56/64 loss: 2.2023792266845703
Batch 57/64 loss: 2.6887125968933105
Batch 58/64 loss: 2.615640640258789
Batch 59/64 loss: 2.22444486618042
Batch 60/64 loss: 2.437168598175049
Batch 61/64 loss: 2.2639684677124023
Batch 62/64 loss: 2.4049062728881836
Batch 63/64 loss: 2.2370166778564453
Batch 64/64 loss: -1.2024164199829102
Epoch 225  Train loss: 2.59316349029541  Val loss: 2.3961911611130966
Epoch 226
-------------------------------
Batch 1/64 loss: 2.228517532348633
Batch 2/64 loss: 2.532780647277832
Batch 3/64 loss: 2.9353294372558594
Batch 4/64 loss: 2.310471534729004
Batch 5/64 loss: 2.065701484680176
Batch 6/64 loss: 2.9056057929992676
Batch 7/64 loss: 2.1814217567443848
Batch 8/64 loss: 3.0531115531921387
Batch 9/64 loss: 2.3613686561584473
Batch 10/64 loss: 1.9294228553771973
Batch 11/64 loss: 3.491703987121582
Batch 12/64 loss: 2.143054485321045
Batch 13/64 loss: 2.016061782836914
Batch 14/64 loss: 2.243105411529541
Batch 15/64 loss: 1.985546588897705
Batch 16/64 loss: 2.2926130294799805
Batch 17/64 loss: 2.368832588195801
Batch 18/64 loss: 2.219792366027832
Batch 19/64 loss: 2.136758327484131
Batch 20/64 loss: 1.9511008262634277
Batch 21/64 loss: 2.1347060203552246
Batch 22/64 loss: 2.005296230316162
Batch 23/64 loss: 2.576402187347412
Batch 24/64 loss: 1.9863872528076172
Batch 25/64 loss: 2.3710274696350098
Batch 26/64 loss: 2.7968688011169434
Batch 27/64 loss: 1.974125862121582
Batch 28/64 loss: 1.9822869300842285
Batch 29/64 loss: 2.1748428344726562
Batch 30/64 loss: 2.0781092643737793
Batch 31/64 loss: 2.1118593215942383
Batch 32/64 loss: 2.4553604125976562
Batch 33/64 loss: 2.261624813079834
Batch 34/64 loss: 2.102386474609375
Batch 35/64 loss: 2.200550079345703
Batch 36/64 loss: 2.121856689453125
Batch 37/64 loss: 2.6429953575134277
Batch 38/64 loss: 1.8930463790893555
Batch 39/64 loss: 2.0318007469177246
Batch 40/64 loss: 2.019806385040283
Batch 41/64 loss: 1.972139835357666
Batch 42/64 loss: 1.997807502746582
Batch 43/64 loss: 4.377318382263184
Batch 44/64 loss: 2.197359561920166
Batch 45/64 loss: 1.9074110984802246
Batch 46/64 loss: 2.251582622528076
Batch 47/64 loss: 2.5997543334960938
Batch 48/64 loss: 1.866865634918213
Batch 49/64 loss: 2.1796841621398926
Batch 50/64 loss: 1.8682775497436523
Batch 51/64 loss: 1.914529800415039
Batch 52/64 loss: 2.0272393226623535
Batch 53/64 loss: 4.952324867248535
Batch 54/64 loss: 1.919614315032959
Batch 55/64 loss: 2.8948163986206055
Batch 56/64 loss: 4.197457313537598
Batch 57/64 loss: 1.8881778717041016
Batch 58/64 loss: 2.0973973274230957
Batch 59/64 loss: 2.0409021377563477
Batch 60/64 loss: 2.233830451965332
Batch 61/64 loss: 2.675198554992676
Batch 62/64 loss: 1.9994773864746094
Batch 63/64 loss: 3.4558072090148926
Batch 64/64 loss: -1.1691875457763672
Epoch 226  Train loss: 2.3201838923435587  Val loss: 1.9453089868080164
Epoch 227
-------------------------------
Batch 1/64 loss: 1.8577752113342285
Batch 2/64 loss: 1.8096604347229004
Batch 3/64 loss: 2.309825897216797
Batch 4/64 loss: 1.8434066772460938
Batch 5/64 loss: 2.301539421081543
Batch 6/64 loss: 1.8532962799072266
Batch 7/64 loss: 2.6197257041931152
Batch 8/64 loss: 2.0942115783691406
Batch 9/64 loss: 4.151389122009277
Batch 10/64 loss: 2.273289203643799
Batch 11/64 loss: 2.8939785957336426
Batch 12/64 loss: 4.090755939483643
Batch 13/64 loss: 1.993494987487793
Batch 14/64 loss: 1.874361515045166
Batch 15/64 loss: 1.9181103706359863
Batch 16/64 loss: 1.855271816253662
Batch 17/64 loss: 1.9588813781738281
Batch 18/64 loss: 2.0267152786254883
Batch 19/64 loss: 1.822402000427246
Batch 20/64 loss: 2.2368955612182617
Batch 21/64 loss: 1.8934788703918457
Batch 22/64 loss: 2.0263328552246094
Batch 23/64 loss: 1.8487396240234375
Batch 24/64 loss: 2.242203712463379
Batch 25/64 loss: 2.077448844909668
Batch 26/64 loss: 2.0152430534362793
Batch 27/64 loss: 2.069455146789551
Batch 28/64 loss: 2.1893177032470703
Batch 29/64 loss: 1.9766368865966797
Batch 30/64 loss: 1.8525958061218262
Batch 31/64 loss: 1.9611458778381348
Batch 32/64 loss: 2.013679027557373
Batch 33/64 loss: 1.974757194519043
Batch 34/64 loss: 2.1597251892089844
Batch 35/64 loss: 5.066877841949463
Batch 36/64 loss: 1.8628907203674316
Batch 37/64 loss: 2.52337646484375
Batch 38/64 loss: 2.1432485580444336
Batch 39/64 loss: 1.9877519607543945
Batch 40/64 loss: 2.286144733428955
Batch 41/64 loss: 2.109137535095215
Batch 42/64 loss: 1.8622875213623047
Batch 43/64 loss: 1.9747896194458008
Batch 44/64 loss: 2.2411246299743652
Batch 45/64 loss: 2.2377991676330566
Batch 46/64 loss: 1.9297723770141602
Batch 47/64 loss: 4.3598551750183105
Batch 48/64 loss: 2.7973384857177734
Batch 49/64 loss: 1.8919110298156738
Batch 50/64 loss: 1.9919791221618652
Batch 51/64 loss: 1.9300537109375
Batch 52/64 loss: 2.577413558959961
Batch 53/64 loss: 2.007960319519043
Batch 54/64 loss: 2.2142786979675293
Batch 55/64 loss: 2.251852035522461
Batch 56/64 loss: 1.966423511505127
Batch 57/64 loss: 2.9879560470581055
Batch 58/64 loss: 3.30012845993042
Batch 59/64 loss: 3.067923069000244
Batch 60/64 loss: 2.890665054321289
Batch 61/64 loss: 2.1993579864501953
Batch 62/64 loss: 2.193777084350586
Batch 63/64 loss: 2.035338878631592
Batch 64/64 loss: 0.021623611450195312
Epoch 227  Train loss: 2.2743745542040057  Val loss: 2.4940075431902384
Epoch 228
-------------------------------
Batch 1/64 loss: 2.5949501991271973
Batch 2/64 loss: 3.3268375396728516
Batch 3/64 loss: 3.4225988388061523
Batch 4/64 loss: 2.0062971115112305
Batch 5/64 loss: 3.777409553527832
Batch 6/64 loss: 1.949587345123291
Batch 7/64 loss: 2.014875888824463
Batch 8/64 loss: 1.9580273628234863
Batch 9/64 loss: 2.1630735397338867
Batch 10/64 loss: 1.9458518028259277
Batch 11/64 loss: 1.9900712966918945
Batch 12/64 loss: 2.2027788162231445
Batch 13/64 loss: 2.3108386993408203
Batch 14/64 loss: 2.1531295776367188
Batch 15/64 loss: 4.913201332092285
Batch 16/64 loss: 3.3450136184692383
Batch 17/64 loss: 2.131157875061035
Batch 18/64 loss: 2.5060362815856934
Batch 19/64 loss: 2.064931869506836
Batch 20/64 loss: 3.226661205291748
Batch 21/64 loss: 1.7778558731079102
Batch 22/64 loss: 2.271491527557373
Batch 23/64 loss: 2.3777379989624023
Batch 24/64 loss: 2.157529354095459
Batch 25/64 loss: 2.6417622566223145
Batch 26/64 loss: 2.880115509033203
Batch 27/64 loss: 2.102293014526367
Batch 28/64 loss: 2.6816763877868652
Batch 29/64 loss: 2.2786569595336914
Batch 30/64 loss: 2.2019057273864746
Batch 31/64 loss: 3.125291347503662
Batch 32/64 loss: 2.259089946746826
Batch 33/64 loss: 2.4623146057128906
Batch 34/64 loss: 2.403503894805908
Batch 35/64 loss: 2.533280372619629
Batch 36/64 loss: 2.7226200103759766
Batch 37/64 loss: 5.398508071899414
Batch 38/64 loss: 4.350649356842041
Batch 39/64 loss: 2.3154220581054688
Batch 40/64 loss: 3.6503682136535645
Batch 41/64 loss: 2.089735984802246
Batch 42/64 loss: 2.5754380226135254
Batch 43/64 loss: 2.0439743995666504
Batch 44/64 loss: 2.907564163208008
Batch 45/64 loss: 2.008309841156006
Batch 46/64 loss: 4.7052106857299805
Batch 47/64 loss: 2.052361011505127
Batch 48/64 loss: 2.352659225463867
Batch 49/64 loss: 2.210996150970459
Batch 50/64 loss: 2.848170280456543
Batch 51/64 loss: 2.146696090698242
Batch 52/64 loss: 2.512028217315674
Batch 53/64 loss: 2.115212917327881
Batch 54/64 loss: 2.339824676513672
Batch 55/64 loss: 1.9415788650512695
Batch 56/64 loss: 2.051595687866211
Batch 57/64 loss: 2.104799747467041
Batch 58/64 loss: 2.3083744049072266
Batch 59/64 loss: 2.444782257080078
Batch 60/64 loss: 1.8982558250427246
Batch 61/64 loss: 1.8467216491699219
Batch 62/64 loss: 2.0782313346862793
Batch 63/64 loss: 2.0806374549865723
Batch 64/64 loss: -1.1298236846923828
Epoch 228  Train loss: 2.5005677391501036  Val loss: 1.8659858179256268
Epoch 229
-------------------------------
Batch 1/64 loss: 1.999758243560791
Batch 2/64 loss: 2.4166884422302246
Batch 3/64 loss: 2.4596405029296875
Batch 4/64 loss: 1.7857427597045898
Batch 5/64 loss: 1.952399730682373
Batch 6/64 loss: 2.9086856842041016
Batch 7/64 loss: 1.9729533195495605
Batch 8/64 loss: 1.99699068069458
Batch 9/64 loss: 2.260324001312256
Batch 10/64 loss: 2.051365375518799
Batch 11/64 loss: 5.150825023651123
Batch 12/64 loss: 4.062239646911621
Batch 13/64 loss: 1.8684325218200684
Batch 14/64 loss: 1.8246874809265137
Batch 15/64 loss: 1.765878677368164
Batch 16/64 loss: 4.448669910430908
Batch 17/64 loss: 2.9458231925964355
Batch 18/64 loss: 2.2295289039611816
Batch 19/64 loss: 1.9569377899169922
Batch 20/64 loss: 1.932373046875
Batch 21/64 loss: 2.2416882514953613
Batch 22/64 loss: 1.8087987899780273
Batch 23/64 loss: 1.9684391021728516
Batch 24/64 loss: 1.814375877380371
Batch 25/64 loss: 1.979691505432129
Batch 26/64 loss: 1.9920248985290527
Batch 27/64 loss: 2.00692081451416
Batch 28/64 loss: 1.9730143547058105
Batch 29/64 loss: 1.8749299049377441
Batch 30/64 loss: 1.9584336280822754
Batch 31/64 loss: 1.8567633628845215
Batch 32/64 loss: 2.1155762672424316
Batch 33/64 loss: 3.1941137313842773
Batch 34/64 loss: 1.8288531303405762
Batch 35/64 loss: 2.1805200576782227
Batch 36/64 loss: 1.9703431129455566
Batch 37/64 loss: 1.9515986442565918
Batch 38/64 loss: 2.0991077423095703
Batch 39/64 loss: 1.9006423950195312
Batch 40/64 loss: 2.0490951538085938
Batch 41/64 loss: 1.951629638671875
Batch 42/64 loss: 1.925908088684082
Batch 43/64 loss: 2.0452523231506348
Batch 44/64 loss: 3.7376084327697754
Batch 45/64 loss: 1.9557385444641113
Batch 46/64 loss: 2.075589179992676
Batch 47/64 loss: 1.9362573623657227
Batch 48/64 loss: 1.8637208938598633
Batch 49/64 loss: 1.9237213134765625
Batch 50/64 loss: 3.5083017349243164
Batch 51/64 loss: 2.135462760925293
Batch 52/64 loss: 2.0912814140319824
Batch 53/64 loss: 1.9763293266296387
Batch 54/64 loss: 1.8524518013000488
Batch 55/64 loss: 1.933168888092041
Batch 56/64 loss: 1.7817788124084473
Batch 57/64 loss: 2.1754446029663086
Batch 58/64 loss: 1.9435033798217773
Batch 59/64 loss: 2.2032699584960938
Batch 60/64 loss: 2.113523006439209
Batch 61/64 loss: 1.9995880126953125
Batch 62/64 loss: 2.6516270637512207
Batch 63/64 loss: 1.9407167434692383
Batch 64/64 loss: -1.5253772735595703
Epoch 229  Train loss: 2.1856112311868108  Val loss: 1.8712526432836998
Epoch 230
-------------------------------
Batch 1/64 loss: 1.9025592803955078
Batch 2/64 loss: 2.7811007499694824
Batch 3/64 loss: 2.209962844848633
Batch 4/64 loss: 2.290128231048584
Batch 5/64 loss: 2.0671563148498535
Batch 6/64 loss: 1.834752082824707
Batch 7/64 loss: 3.057164192199707
Batch 8/64 loss: 1.8448266983032227
Batch 9/64 loss: 1.970489501953125
Batch 10/64 loss: 1.9513859748840332
Batch 11/64 loss: 2.359835147857666
Batch 12/64 loss: 5.207653999328613
Batch 13/64 loss: 1.8519153594970703
Batch 14/64 loss: 6.231783390045166
Batch 15/64 loss: 1.9598369598388672
Batch 16/64 loss: 2.047274589538574
Batch 17/64 loss: 2.0409154891967773
Batch 18/64 loss: 1.6982784271240234
Batch 19/64 loss: 1.8675894737243652
Batch 20/64 loss: 2.0331788063049316
Batch 21/64 loss: 2.2119851112365723
Batch 22/64 loss: 2.0409693717956543
Batch 23/64 loss: 1.942366600036621
Batch 24/64 loss: 2.113523483276367
Batch 25/64 loss: 1.8947772979736328
Batch 26/64 loss: 2.8408946990966797
Batch 27/64 loss: 1.8602313995361328
Batch 28/64 loss: 2.3716049194335938
Batch 29/64 loss: 1.8269329071044922
Batch 30/64 loss: 1.9935288429260254
Batch 31/64 loss: 1.8512153625488281
Batch 32/64 loss: 2.028724193572998
Batch 33/64 loss: 2.0703115463256836
Batch 34/64 loss: 1.9110617637634277
Batch 35/64 loss: 1.8127837181091309
Batch 36/64 loss: 1.7660818099975586
Batch 37/64 loss: 1.792856216430664
Batch 38/64 loss: 2.0734286308288574
Batch 39/64 loss: 1.80625581741333
Batch 40/64 loss: 1.9082880020141602
Batch 41/64 loss: 2.0299816131591797
Batch 42/64 loss: 1.899033546447754
Batch 43/64 loss: 2.187824249267578
Batch 44/64 loss: 2.1889700889587402
Batch 45/64 loss: 1.7972283363342285
Batch 46/64 loss: 2.2538418769836426
Batch 47/64 loss: 3.0054874420166016
Batch 48/64 loss: 1.8063960075378418
Batch 49/64 loss: 1.7979950904846191
Batch 50/64 loss: 2.647305488586426
Batch 51/64 loss: 1.9210658073425293
Batch 52/64 loss: 1.8839435577392578
Batch 53/64 loss: 1.9733357429504395
Batch 54/64 loss: 1.7352290153503418
Batch 55/64 loss: 1.813826560974121
Batch 56/64 loss: 1.9705772399902344
Batch 57/64 loss: 1.785841941833496
Batch 58/64 loss: 1.858199119567871
Batch 59/64 loss: 1.7637715339660645
Batch 60/64 loss: 1.745866298675537
Batch 61/64 loss: 2.089378833770752
Batch 62/64 loss: 1.990194320678711
Batch 63/64 loss: 1.8455605506896973
Batch 64/64 loss: -1.6229467391967773
Epoch 230  Train loss: 2.1035177006441006  Val loss: 1.7132260627353315
Epoch 231
-------------------------------
Batch 1/64 loss: 4.663373947143555
Batch 2/64 loss: 5.140722751617432
Batch 3/64 loss: 2.0803189277648926
Batch 4/64 loss: 2.651918411254883
Batch 5/64 loss: 1.8665637969970703
Batch 6/64 loss: 1.895681381225586
Batch 7/64 loss: 1.8906240463256836
Batch 8/64 loss: 1.928356647491455
Batch 9/64 loss: 1.741330623626709
Batch 10/64 loss: 1.8106307983398438
Batch 11/64 loss: 2.5662522315979004
Batch 12/64 loss: 1.796034812927246
Batch 13/64 loss: 2.036379337310791
Batch 14/64 loss: 2.01530122756958
Batch 15/64 loss: 1.8049798011779785
Batch 16/64 loss: 1.7219390869140625
Batch 17/64 loss: 3.8965377807617188
Batch 18/64 loss: 2.153815746307373
Batch 19/64 loss: 1.7993264198303223
Batch 20/64 loss: 2.09527587890625
Batch 21/64 loss: 3.0443077087402344
Batch 22/64 loss: 1.7830696105957031
Batch 23/64 loss: 2.014392852783203
Batch 24/64 loss: 1.74210786819458
Batch 25/64 loss: 1.8893070220947266
Batch 26/64 loss: 1.847928524017334
Batch 27/64 loss: 2.0892014503479004
Batch 28/64 loss: 1.9588279724121094
Batch 29/64 loss: 1.9095282554626465
Batch 30/64 loss: 2.021035671234131
Batch 31/64 loss: 1.904348373413086
Batch 32/64 loss: 2.0277299880981445
Batch 33/64 loss: 1.8267602920532227
Batch 34/64 loss: 2.6460771560668945
Batch 35/64 loss: 2.4812369346618652
Batch 36/64 loss: 2.4900755882263184
Batch 37/64 loss: 1.7685823440551758
Batch 38/64 loss: 2.00199031829834
Batch 39/64 loss: 1.7589621543884277
Batch 40/64 loss: 1.749474048614502
Batch 41/64 loss: 1.9481797218322754
Batch 42/64 loss: 1.8477973937988281
Batch 43/64 loss: 1.8902206420898438
Batch 44/64 loss: 1.7893743515014648
Batch 45/64 loss: 1.8784904479980469
Batch 46/64 loss: 1.8506278991699219
Batch 47/64 loss: 2.478238105773926
Batch 48/64 loss: 1.6961755752563477
Batch 49/64 loss: 1.9976868629455566
Batch 50/64 loss: 1.8822755813598633
Batch 51/64 loss: 1.9078369140625
Batch 52/64 loss: 1.97434663772583
Batch 53/64 loss: 2.1950340270996094
Batch 54/64 loss: 1.9813823699951172
Batch 55/64 loss: 1.7977218627929688
Batch 56/64 loss: 1.868542194366455
Batch 57/64 loss: 1.7802629470825195
Batch 58/64 loss: 1.9211583137512207
Batch 59/64 loss: 1.7522788047790527
Batch 60/64 loss: 1.7314186096191406
Batch 61/64 loss: 1.7412843704223633
Batch 62/64 loss: 1.834632396697998
Batch 63/64 loss: 2.608826160430908
Batch 64/64 loss: -1.6253395080566406
Epoch 231  Train loss: 2.0650211035036574  Val loss: 1.7494650640848166
Epoch 232
-------------------------------
Batch 1/64 loss: 1.7679238319396973
Batch 2/64 loss: 1.8817152976989746
Batch 3/64 loss: 1.77178955078125
Batch 4/64 loss: 1.7126574516296387
Batch 5/64 loss: 1.7784805297851562
Batch 6/64 loss: 1.8789138793945312
Batch 7/64 loss: 2.1516318321228027
Batch 8/64 loss: 4.314929485321045
Batch 9/64 loss: 1.9133353233337402
Batch 10/64 loss: 4.068300247192383
Batch 11/64 loss: 1.8683934211730957
Batch 12/64 loss: 1.9244112968444824
Batch 13/64 loss: 1.7129817008972168
Batch 14/64 loss: 1.8072166442871094
Batch 15/64 loss: 2.8401670455932617
Batch 16/64 loss: 2.0119099617004395
Batch 17/64 loss: 1.9611964225769043
Batch 18/64 loss: 1.6425251960754395
Batch 19/64 loss: 2.9387707710266113
Batch 20/64 loss: 1.8502445220947266
Batch 21/64 loss: 2.110807418823242
Batch 22/64 loss: 2.206017017364502
Batch 23/64 loss: 2.3786978721618652
Batch 24/64 loss: 2.1288580894470215
Batch 25/64 loss: 1.7719645500183105
Batch 26/64 loss: 1.7893452644348145
Batch 27/64 loss: 1.9306387901306152
Batch 28/64 loss: 2.165191173553467
Batch 29/64 loss: 1.7094449996948242
Batch 30/64 loss: 3.2673912048339844
Batch 31/64 loss: 1.8187122344970703
Batch 32/64 loss: 1.973179817199707
Batch 33/64 loss: 2.0218300819396973
Batch 34/64 loss: 1.905078411102295
Batch 35/64 loss: 2.1320457458496094
Batch 36/64 loss: 1.780336856842041
Batch 37/64 loss: 3.251277446746826
Batch 38/64 loss: 2.526081085205078
Batch 39/64 loss: 1.737619400024414
Batch 40/64 loss: 1.8211822509765625
Batch 41/64 loss: 1.8673219680786133
Batch 42/64 loss: 1.9682559967041016
Batch 43/64 loss: 1.9934649467468262
Batch 44/64 loss: 1.9086723327636719
Batch 45/64 loss: 2.079014778137207
Batch 46/64 loss: 2.749838352203369
Batch 47/64 loss: 1.6840577125549316
Batch 48/64 loss: 1.689732551574707
Batch 49/64 loss: 1.8641738891601562
Batch 50/64 loss: 1.8933963775634766
Batch 51/64 loss: 1.8540539741516113
Batch 52/64 loss: 1.7654056549072266
Batch 53/64 loss: 2.0921835899353027
Batch 54/64 loss: 1.9956402778625488
Batch 55/64 loss: 5.057646751403809
Batch 56/64 loss: 1.8140692710876465
Batch 57/64 loss: 1.8743577003479004
Batch 58/64 loss: 1.7521061897277832
Batch 59/64 loss: 1.8659639358520508
Batch 60/64 loss: 2.057023525238037
Batch 61/64 loss: 1.8161616325378418
Batch 62/64 loss: 2.6126556396484375
Batch 63/64 loss: 2.2523860931396484
Batch 64/64 loss: -1.747237205505371
Epoch 232  Train loss: 2.092868225247252  Val loss: 1.6102586333284672
Epoch 233
-------------------------------
Batch 1/64 loss: 1.7327790260314941
Batch 2/64 loss: 2.0739340782165527
Batch 3/64 loss: 2.000535011291504
Batch 4/64 loss: 1.8586196899414062
Batch 5/64 loss: 1.8019232749938965
Batch 6/64 loss: 1.9850807189941406
Batch 7/64 loss: 1.9918179512023926
Batch 8/64 loss: 1.7732577323913574
Batch 9/64 loss: 2.3523058891296387
Batch 10/64 loss: 1.7167701721191406
Batch 11/64 loss: 1.7824316024780273
Batch 12/64 loss: 1.6564087867736816
Batch 13/64 loss: 1.8934597969055176
Batch 14/64 loss: 1.6641478538513184
Batch 15/64 loss: 1.974095344543457
Batch 16/64 loss: 1.8144841194152832
Batch 17/64 loss: 2.01686954498291
Batch 18/64 loss: 6.4278483390808105
Batch 19/64 loss: 2.733539581298828
Batch 20/64 loss: 1.7662882804870605
Batch 21/64 loss: 4.167206764221191
Batch 22/64 loss: 1.7626099586486816
Batch 23/64 loss: 1.6937341690063477
Batch 24/64 loss: 1.863278865814209
Batch 25/64 loss: 1.8385353088378906
Batch 26/64 loss: 1.720658779144287
Batch 27/64 loss: 1.746109962463379
Batch 28/64 loss: 2.080745220184326
Batch 29/64 loss: 1.9488120079040527
Batch 30/64 loss: 1.7533597946166992
Batch 31/64 loss: 1.7317028045654297
Batch 32/64 loss: 2.426551342010498
Batch 33/64 loss: 1.9325027465820312
Batch 34/64 loss: 1.8239026069641113
Batch 35/64 loss: 1.8605561256408691
Batch 36/64 loss: 1.7055625915527344
Batch 37/64 loss: 1.7109322547912598
Batch 38/64 loss: 1.937556266784668
Batch 39/64 loss: 1.8631010055541992
Batch 40/64 loss: 1.7415857315063477
Batch 41/64 loss: 1.8960742950439453
Batch 42/64 loss: 1.7271976470947266
Batch 43/64 loss: 1.7210912704467773
Batch 44/64 loss: 1.7094779014587402
Batch 45/64 loss: 1.6725654602050781
Batch 46/64 loss: 2.0956621170043945
Batch 47/64 loss: 1.7130632400512695
Batch 48/64 loss: 1.6785893440246582
Batch 49/64 loss: 2.135462760925293
Batch 50/64 loss: 1.8368849754333496
Batch 51/64 loss: 1.747169017791748
Batch 52/64 loss: 2.152064323425293
Batch 53/64 loss: 1.9602622985839844
Batch 54/64 loss: 2.040745258331299
Batch 55/64 loss: 1.845411777496338
Batch 56/64 loss: 1.8202004432678223
Batch 57/64 loss: 2.1031899452209473
Batch 58/64 loss: 2.4983444213867188
Batch 59/64 loss: 2.7101025581359863
Batch 60/64 loss: 2.087575912475586
Batch 61/64 loss: 1.8626279830932617
Batch 62/64 loss: 2.183624744415283
Batch 63/64 loss: 2.108844757080078
Batch 64/64 loss: 0.3729696273803711
Epoch 233  Train loss: 2.0064558552760703  Val loss: 1.6450616764448762
Epoch 234
-------------------------------
Batch 1/64 loss: 1.8698787689208984
Batch 2/64 loss: 2.7200045585632324
Batch 3/64 loss: 1.9476304054260254
Batch 4/64 loss: 1.833327293395996
Batch 5/64 loss: 1.868828296661377
Batch 6/64 loss: 1.7688922882080078
Batch 7/64 loss: 1.8292503356933594
Batch 8/64 loss: 1.9590296745300293
Batch 9/64 loss: 1.8992829322814941
Batch 10/64 loss: 3.1390180587768555
Batch 11/64 loss: 1.877509593963623
Batch 12/64 loss: 1.9721064567565918
Batch 13/64 loss: 1.88374662399292
Batch 14/64 loss: 1.8413090705871582
Batch 15/64 loss: 1.9667143821716309
Batch 16/64 loss: 1.9194307327270508
Batch 17/64 loss: 2.125560760498047
Batch 18/64 loss: 1.8893537521362305
Batch 19/64 loss: 1.897862434387207
Batch 20/64 loss: 2.0547757148742676
Batch 21/64 loss: 1.8710074424743652
Batch 22/64 loss: 2.0151004791259766
Batch 23/64 loss: 1.7380924224853516
Batch 24/64 loss: 1.7415275573730469
Batch 25/64 loss: 1.7546072006225586
Batch 26/64 loss: 3.7490234375
Batch 27/64 loss: 1.8702168464660645
Batch 28/64 loss: 1.9073777198791504
Batch 29/64 loss: 2.183925151824951
Batch 30/64 loss: 1.7445759773254395
Batch 31/64 loss: 1.9626984596252441
Batch 32/64 loss: 2.0335588455200195
Batch 33/64 loss: 1.736811637878418
Batch 34/64 loss: 1.7630729675292969
Batch 35/64 loss: 1.7750954627990723
Batch 36/64 loss: 2.895656108856201
Batch 37/64 loss: 1.6910829544067383
Batch 38/64 loss: 2.1452808380126953
Batch 39/64 loss: 1.8215532302856445
Batch 40/64 loss: 1.996354103088379
Batch 41/64 loss: 1.7595267295837402
Batch 42/64 loss: 1.8340344429016113
Batch 43/64 loss: 1.722257137298584
Batch 44/64 loss: 1.85508394241333
Batch 45/64 loss: 1.9745755195617676
Batch 46/64 loss: 2.0279927253723145
Batch 47/64 loss: 4.275589942932129
Batch 48/64 loss: 2.109889030456543
Batch 49/64 loss: 1.8846874237060547
Batch 50/64 loss: 1.7153849601745605
Batch 51/64 loss: 1.9208793640136719
Batch 52/64 loss: 1.6741514205932617
Batch 53/64 loss: 1.8446569442749023
Batch 54/64 loss: 2.251105785369873
Batch 55/64 loss: 2.6644463539123535
Batch 56/64 loss: 4.848280906677246
Batch 57/64 loss: 1.6859931945800781
Batch 58/64 loss: 2.025547504425049
Batch 59/64 loss: 1.7470216751098633
Batch 60/64 loss: 1.8112835884094238
Batch 61/64 loss: 1.822138786315918
Batch 62/64 loss: 1.763317584991455
Batch 63/64 loss: 1.7741961479187012
Batch 64/64 loss: -1.5390377044677734
Epoch 234  Train loss: 2.0156532362395643  Val loss: 1.5811519819436615
Epoch 235
-------------------------------
Batch 1/64 loss: 4.1909613609313965
Batch 2/64 loss: 1.8809900283813477
Batch 3/64 loss: 2.2258505821228027
Batch 4/64 loss: 2.2387986183166504
Batch 5/64 loss: 4.259461402893066
Batch 6/64 loss: 1.6926321983337402
Batch 7/64 loss: 2.6458678245544434
Batch 8/64 loss: 1.8271164894104004
Batch 9/64 loss: 1.7960224151611328
Batch 10/64 loss: 1.6965155601501465
Batch 11/64 loss: 1.6907076835632324
Batch 12/64 loss: 2.8513264656066895
Batch 13/64 loss: 1.9197607040405273
Batch 14/64 loss: 2.050022602081299
Batch 15/64 loss: 1.8672223091125488
Batch 16/64 loss: 2.09305477142334
Batch 17/64 loss: 1.9016375541687012
Batch 18/64 loss: 1.8365788459777832
Batch 19/64 loss: 1.8369112014770508
Batch 20/64 loss: 1.7580828666687012
Batch 21/64 loss: 1.6878705024719238
Batch 22/64 loss: 1.7815136909484863
Batch 23/64 loss: 2.3403549194335938
Batch 24/64 loss: 1.7437491416931152
Batch 25/64 loss: 1.9534173011779785
Batch 26/64 loss: 2.0802106857299805
Batch 27/64 loss: 1.6069750785827637
Batch 28/64 loss: 1.7152423858642578
Batch 29/64 loss: 2.0242700576782227
Batch 30/64 loss: 1.6716251373291016
Batch 31/64 loss: 1.7591466903686523
Batch 32/64 loss: 1.7840828895568848
Batch 33/64 loss: 1.7297921180725098
Batch 34/64 loss: 1.6709232330322266
Batch 35/64 loss: 1.7064733505249023
Batch 36/64 loss: 1.9464421272277832
Batch 37/64 loss: 1.8814177513122559
Batch 38/64 loss: 1.908552646636963
Batch 39/64 loss: 1.6628737449645996
Batch 40/64 loss: 1.8629140853881836
Batch 41/64 loss: 2.0003294944763184
Batch 42/64 loss: 1.7375273704528809
Batch 43/64 loss: 1.8294448852539062
Batch 44/64 loss: 1.9302282333374023
Batch 45/64 loss: 2.431140899658203
Batch 46/64 loss: 1.7272849082946777
Batch 47/64 loss: 2.0044174194335938
Batch 48/64 loss: 1.692246437072754
Batch 49/64 loss: 1.7819786071777344
Batch 50/64 loss: 2.8235034942626953
Batch 51/64 loss: 1.8389396667480469
Batch 52/64 loss: 1.7426700592041016
Batch 53/64 loss: 1.663867473602295
Batch 54/64 loss: 4.827112197875977
Batch 55/64 loss: 1.7852911949157715
Batch 56/64 loss: 1.9253926277160645
Batch 57/64 loss: 1.7592248916625977
Batch 58/64 loss: 1.7119665145874023
Batch 59/64 loss: 1.785512924194336
Batch 60/64 loss: 1.7315654754638672
Batch 61/64 loss: 1.859421730041504
Batch 62/64 loss: 1.6839680671691895
Batch 63/64 loss: 1.964935302734375
Batch 64/64 loss: -1.4867782592773438
Epoch 235  Train loss: 1.974905963972503  Val loss: 1.5612251701223891
Epoch 236
-------------------------------
Batch 1/64 loss: 1.7699503898620605
Batch 2/64 loss: 1.7901501655578613
Batch 3/64 loss: 1.7468109130859375
Batch 4/64 loss: 3.7966365814208984
Batch 5/64 loss: 1.7620043754577637
Batch 6/64 loss: 2.501530170440674
Batch 7/64 loss: 1.8870964050292969
Batch 8/64 loss: 2.034604549407959
Batch 9/64 loss: 1.7670044898986816
Batch 10/64 loss: 1.6901583671569824
Batch 11/64 loss: 1.6313486099243164
Batch 12/64 loss: 1.9168758392333984
Batch 13/64 loss: 1.903085708618164
Batch 14/64 loss: 1.8952264785766602
Batch 15/64 loss: 2.4147090911865234
Batch 16/64 loss: 1.748711109161377
Batch 17/64 loss: 1.7735505104064941
Batch 18/64 loss: 1.8477635383605957
Batch 19/64 loss: 2.0145678520202637
Batch 20/64 loss: 1.8769631385803223
Batch 21/64 loss: 1.7149434089660645
Batch 22/64 loss: 5.782440662384033
Batch 23/64 loss: 1.7311859130859375
Batch 24/64 loss: 1.7800145149230957
Batch 25/64 loss: 1.6844940185546875
Batch 26/64 loss: 1.891737937927246
Batch 27/64 loss: 1.7694964408874512
Batch 28/64 loss: 1.743884563446045
Batch 29/64 loss: 1.8690214157104492
Batch 30/64 loss: 4.226195812225342
Batch 31/64 loss: 2.176619529724121
Batch 32/64 loss: 2.0291638374328613
Batch 33/64 loss: 1.7383975982666016
Batch 34/64 loss: 2.427074432373047
Batch 35/64 loss: 1.6545052528381348
Batch 36/64 loss: 1.7849493026733398
Batch 37/64 loss: 2.009753704071045
Batch 38/64 loss: 1.673363208770752
Batch 39/64 loss: 1.7635555267333984
Batch 40/64 loss: 1.7056536674499512
Batch 41/64 loss: 2.1381025314331055
Batch 42/64 loss: 1.8446917533874512
Batch 43/64 loss: 2.652961254119873
Batch 44/64 loss: 1.810777187347412
Batch 45/64 loss: 1.7396702766418457
Batch 46/64 loss: 1.6182036399841309
Batch 47/64 loss: 1.661893367767334
Batch 48/64 loss: 1.7993707656860352
Batch 49/64 loss: 1.64152193069458
Batch 50/64 loss: 1.6420917510986328
Batch 51/64 loss: 1.6443982124328613
Batch 52/64 loss: 1.7047758102416992
Batch 53/64 loss: 1.985520362854004
Batch 54/64 loss: 1.8867030143737793
Batch 55/64 loss: 1.7889995574951172
Batch 56/64 loss: 1.9019346237182617
Batch 57/64 loss: 1.6914091110229492
Batch 58/64 loss: 1.979365348815918
Batch 59/64 loss: 1.6826324462890625
Batch 60/64 loss: 1.9635887145996094
Batch 61/64 loss: 1.725295066833496
Batch 62/64 loss: 1.6466460227966309
Batch 63/64 loss: 1.9473671913146973
Batch 64/64 loss: -1.6705636978149414
Epoch 236  Train loss: 1.9414932737163468  Val loss: 1.519891273524753
Epoch 237
-------------------------------
Batch 1/64 loss: 1.9618659019470215
Batch 2/64 loss: 1.7147393226623535
Batch 3/64 loss: 1.962113380432129
Batch 4/64 loss: 2.013908863067627
Batch 5/64 loss: 1.7216119766235352
Batch 6/64 loss: 2.5903759002685547
Batch 7/64 loss: 1.7843236923217773
Batch 8/64 loss: 1.7875852584838867
Batch 9/64 loss: 1.7397918701171875
Batch 10/64 loss: 1.8501849174499512
Batch 11/64 loss: 1.7428312301635742
Batch 12/64 loss: 1.7273774147033691
Batch 13/64 loss: 1.81467866897583
Batch 14/64 loss: 1.7744574546813965
Batch 15/64 loss: 2.3651957511901855
Batch 16/64 loss: 1.6908388137817383
Batch 17/64 loss: 1.829136848449707
Batch 18/64 loss: 2.0836782455444336
Batch 19/64 loss: 1.7399063110351562
Batch 20/64 loss: 4.147363185882568
Batch 21/64 loss: 1.665600299835205
Batch 22/64 loss: 2.715364456176758
Batch 23/64 loss: 1.859361171722412
Batch 24/64 loss: 2.0130043029785156
Batch 25/64 loss: 1.8126068115234375
Batch 26/64 loss: 1.7327461242675781
Batch 27/64 loss: 1.7823386192321777
Batch 28/64 loss: 1.8577814102172852
Batch 29/64 loss: 2.1589102745056152
Batch 30/64 loss: 1.7278070449829102
Batch 31/64 loss: 1.8185644149780273
Batch 32/64 loss: 1.7789273262023926
Batch 33/64 loss: 1.6368298530578613
Batch 34/64 loss: 1.7411303520202637
Batch 35/64 loss: 2.086287498474121
Batch 36/64 loss: 2.3539819717407227
Batch 37/64 loss: 1.6865663528442383
Batch 38/64 loss: 1.6872038841247559
Batch 39/64 loss: 1.5770492553710938
Batch 40/64 loss: 3.949990749359131
Batch 41/64 loss: 1.7275962829589844
Batch 42/64 loss: 3.1372299194335938
Batch 43/64 loss: 1.8712735176086426
Batch 44/64 loss: 1.8390326499938965
Batch 45/64 loss: 5.390934467315674
Batch 46/64 loss: 1.83143949508667
Batch 47/64 loss: 1.7341594696044922
Batch 48/64 loss: 1.7920432090759277
Batch 49/64 loss: 1.7588043212890625
Batch 50/64 loss: 1.8726391792297363
Batch 51/64 loss: 2.011031150817871
Batch 52/64 loss: 1.9686493873596191
Batch 53/64 loss: 1.97119140625
Batch 54/64 loss: 1.6085014343261719
Batch 55/64 loss: 1.8837924003601074
Batch 56/64 loss: 1.7311062812805176
Batch 57/64 loss: 1.7684898376464844
Batch 58/64 loss: 1.7933416366577148
Batch 59/64 loss: 1.7509188652038574
Batch 60/64 loss: 1.7826414108276367
Batch 61/64 loss: 1.87750244140625
Batch 62/64 loss: 2.657222270965576
Batch 63/64 loss: 1.7911171913146973
Batch 64/64 loss: -1.6452398300170898
Epoch 237  Train loss: 1.9764822829003428  Val loss: 1.5509967476231945
Epoch 238
-------------------------------
Batch 1/64 loss: 2.2004122734069824
Batch 2/64 loss: 1.706434726715088
Batch 3/64 loss: 1.9653801918029785
Batch 4/64 loss: 2.9628024101257324
Batch 5/64 loss: 1.8572092056274414
Batch 6/64 loss: 1.8508696556091309
Batch 7/64 loss: 2.0291008949279785
Batch 8/64 loss: 1.6846637725830078
Batch 9/64 loss: 1.6757779121398926
Batch 10/64 loss: 1.710909366607666
Batch 11/64 loss: 1.767530918121338
Batch 12/64 loss: 1.7137532234191895
Batch 13/64 loss: 2.4421586990356445
Batch 14/64 loss: 1.6936588287353516
Batch 15/64 loss: 2.1260275840759277
Batch 16/64 loss: 2.6359658241271973
Batch 17/64 loss: 2.0581226348876953
Batch 18/64 loss: 1.7352380752563477
Batch 19/64 loss: 1.7573943138122559
Batch 20/64 loss: 1.8565640449523926
Batch 21/64 loss: 1.814781665802002
Batch 22/64 loss: 1.972799301147461
Batch 23/64 loss: 1.8943977355957031
Batch 24/64 loss: 1.8205418586730957
Batch 25/64 loss: 1.764892578125
Batch 26/64 loss: 3.217257499694824
Batch 27/64 loss: 2.8012290000915527
Batch 28/64 loss: 2.0252037048339844
Batch 29/64 loss: 1.6834092140197754
Batch 30/64 loss: 1.764749526977539
Batch 31/64 loss: 1.631126880645752
Batch 32/64 loss: 1.7537055015563965
Batch 33/64 loss: 1.8031673431396484
Batch 34/64 loss: 1.8147449493408203
Batch 35/64 loss: 1.6026806831359863
Batch 36/64 loss: 1.8109846115112305
Batch 37/64 loss: 1.6640105247497559
Batch 38/64 loss: 1.7621631622314453
Batch 39/64 loss: 1.9034762382507324
Batch 40/64 loss: 1.877619743347168
Batch 41/64 loss: 1.8771629333496094
Batch 42/64 loss: 1.8047809600830078
Batch 43/64 loss: 5.485784530639648
Batch 44/64 loss: 1.7387304306030273
Batch 45/64 loss: 1.7760047912597656
Batch 46/64 loss: 1.7455096244812012
Batch 47/64 loss: 1.856658935546875
Batch 48/64 loss: 1.706641674041748
Batch 49/64 loss: 1.7049221992492676
Batch 50/64 loss: 1.7389535903930664
Batch 51/64 loss: 1.8239316940307617
Batch 52/64 loss: 2.0360655784606934
Batch 53/64 loss: 4.211080074310303
Batch 54/64 loss: 1.7981624603271484
Batch 55/64 loss: 1.7560882568359375
Batch 56/64 loss: 1.8305230140686035
Batch 57/64 loss: 2.00704288482666
Batch 58/64 loss: 1.756721019744873
Batch 59/64 loss: 1.9997782707214355
Batch 60/64 loss: 1.7864398956298828
Batch 61/64 loss: 2.125436782836914
Batch 62/64 loss: 1.808427333831787
Batch 63/64 loss: 3.911159038543701
Batch 64/64 loss: -1.314718246459961
Epoch 238  Train loss: 1.9939275853774128  Val loss: 1.5650031230703663
Epoch 239
-------------------------------
Batch 1/64 loss: 1.838183879852295
Batch 2/64 loss: 1.686422348022461
Batch 3/64 loss: 1.7823991775512695
Batch 4/64 loss: 1.737870693206787
Batch 5/64 loss: 1.755171775817871
Batch 6/64 loss: 1.7168688774108887
Batch 7/64 loss: 2.4305615425109863
Batch 8/64 loss: 1.9981465339660645
Batch 9/64 loss: 1.9172430038452148
Batch 10/64 loss: 1.7866854667663574
Batch 11/64 loss: 2.174604892730713
Batch 12/64 loss: 1.6637654304504395
Batch 13/64 loss: 2.003434658050537
Batch 14/64 loss: 1.7526254653930664
Batch 15/64 loss: 1.7255744934082031
Batch 16/64 loss: 1.746108055114746
Batch 17/64 loss: 1.7652597427368164
Batch 18/64 loss: 1.9275288581848145
Batch 19/64 loss: 1.870814323425293
Batch 20/64 loss: 1.7752156257629395
Batch 21/64 loss: 1.849562168121338
Batch 22/64 loss: 4.177748680114746
Batch 23/64 loss: 2.1011929512023926
Batch 24/64 loss: 1.8398818969726562
Batch 25/64 loss: 2.037172794342041
Batch 26/64 loss: 1.9419960975646973
Batch 27/64 loss: 1.9985027313232422
Batch 28/64 loss: 1.7145671844482422
Batch 29/64 loss: 1.850156307220459
Batch 30/64 loss: 1.833085536956787
Batch 31/64 loss: 1.659437656402588
Batch 32/64 loss: 1.714306354522705
Batch 33/64 loss: 3.7447080612182617
Batch 34/64 loss: 1.7792773246765137
Batch 35/64 loss: 2.4251132011413574
Batch 36/64 loss: 1.8200163841247559
Batch 37/64 loss: 1.9077177047729492
Batch 38/64 loss: 1.7793059349060059
Batch 39/64 loss: 1.843160629272461
Batch 40/64 loss: 1.7112531661987305
Batch 41/64 loss: 2.0193395614624023
Batch 42/64 loss: 1.927933692932129
Batch 43/64 loss: 1.8292512893676758
Batch 44/64 loss: 1.9704389572143555
Batch 45/64 loss: 2.173765182495117
Batch 46/64 loss: 1.8158164024353027
Batch 47/64 loss: 1.7649321556091309
Batch 48/64 loss: 2.1500611305236816
Batch 49/64 loss: 3.1025891304016113
Batch 50/64 loss: 1.751389980316162
Batch 51/64 loss: 4.683248996734619
Batch 52/64 loss: 1.5867705345153809
Batch 53/64 loss: 2.104705810546875
Batch 54/64 loss: 1.7589154243469238
Batch 55/64 loss: 1.73521089553833
Batch 56/64 loss: 1.9384832382202148
Batch 57/64 loss: 2.164142608642578
Batch 58/64 loss: 1.7050514221191406
Batch 59/64 loss: 2.0500783920288086
Batch 60/64 loss: 1.9723849296569824
Batch 61/64 loss: 4.021318435668945
Batch 62/64 loss: 1.6622061729431152
Batch 63/64 loss: 1.5744762420654297
Batch 64/64 loss: -1.5934782028198242
Epoch 239  Train loss: 1.9929419536216586  Val loss: 1.5219788174448963
Epoch 240
-------------------------------
Batch 1/64 loss: 1.8512611389160156
Batch 2/64 loss: 1.8457508087158203
Batch 3/64 loss: 1.9023046493530273
Batch 4/64 loss: 1.6945996284484863
Batch 5/64 loss: 2.7979230880737305
Batch 6/64 loss: 1.710996150970459
Batch 7/64 loss: 1.909761905670166
Batch 8/64 loss: 1.6787347793579102
Batch 9/64 loss: 1.8961763381958008
Batch 10/64 loss: 1.8305091857910156
Batch 11/64 loss: 2.1908955574035645
Batch 12/64 loss: 1.6633710861206055
Batch 13/64 loss: 2.508841037750244
Batch 14/64 loss: 1.7944746017456055
Batch 15/64 loss: 2.0119271278381348
Batch 16/64 loss: 1.750589370727539
Batch 17/64 loss: 1.779322624206543
Batch 18/64 loss: 1.6824545860290527
Batch 19/64 loss: 1.736764907836914
Batch 20/64 loss: 1.848069190979004
Batch 21/64 loss: 1.7625536918640137
Batch 22/64 loss: 1.7326960563659668
Batch 23/64 loss: 2.1414966583251953
Batch 24/64 loss: 2.9171366691589355
Batch 25/64 loss: 1.914555549621582
Batch 26/64 loss: 1.8034558296203613
Batch 27/64 loss: 1.8065671920776367
Batch 28/64 loss: 1.805171012878418
Batch 29/64 loss: 1.7516231536865234
Batch 30/64 loss: 1.8271684646606445
Batch 31/64 loss: 1.9394145011901855
Batch 32/64 loss: 2.154127597808838
Batch 33/64 loss: 4.601650714874268
Batch 34/64 loss: 1.8031511306762695
Batch 35/64 loss: 1.9042167663574219
Batch 36/64 loss: 1.7193870544433594
Batch 37/64 loss: 2.015882968902588
Batch 38/64 loss: 1.7434015274047852
Batch 39/64 loss: 1.6688737869262695
Batch 40/64 loss: 1.8033957481384277
Batch 41/64 loss: 1.731630802154541
Batch 42/64 loss: 1.6737937927246094
Batch 43/64 loss: 1.8355259895324707
Batch 44/64 loss: 1.725599765777588
Batch 45/64 loss: 4.221063137054443
Batch 46/64 loss: 1.812164306640625
Batch 47/64 loss: 1.8088626861572266
Batch 48/64 loss: 4.217355251312256
Batch 49/64 loss: 1.7416276931762695
Batch 50/64 loss: 1.669424057006836
Batch 51/64 loss: 2.006852149963379
Batch 52/64 loss: 2.1376519203186035
Batch 53/64 loss: 1.8390192985534668
Batch 54/64 loss: 1.8735899925231934
Batch 55/64 loss: 1.7413883209228516
Batch 56/64 loss: 1.7161893844604492
Batch 57/64 loss: 1.6972689628601074
Batch 58/64 loss: 1.8620433807373047
Batch 59/64 loss: 1.9628658294677734
Batch 60/64 loss: 1.750856876373291
Batch 61/64 loss: 1.6676025390625
Batch 62/64 loss: 1.774979591369629
Batch 63/64 loss: 1.7146153450012207
Batch 64/64 loss: -0.5446243286132812
Epoch 240  Train loss: 1.9556730457380707  Val loss: 1.5059020445518887
Epoch 241
-------------------------------
Batch 1/64 loss: 2.1234569549560547
Batch 2/64 loss: 1.8369150161743164
Batch 3/64 loss: 1.9840569496154785
Batch 4/64 loss: 1.785224437713623
Batch 5/64 loss: 1.8361382484436035
Batch 6/64 loss: 1.7622394561767578
Batch 7/64 loss: 1.7368359565734863
Batch 8/64 loss: 1.7635416984558105
Batch 9/64 loss: 1.681586742401123
Batch 10/64 loss: 1.6253280639648438
Batch 11/64 loss: 2.3016929626464844
Batch 12/64 loss: 1.824692726135254
Batch 13/64 loss: 1.6959280967712402
Batch 14/64 loss: 1.8479232788085938
Batch 15/64 loss: 1.8858532905578613
Batch 16/64 loss: 1.8632760047912598
Batch 17/64 loss: 6.807142734527588
Batch 18/64 loss: 2.010049343109131
Batch 19/64 loss: 2.9822030067443848
Batch 20/64 loss: 1.697218894958496
Batch 21/64 loss: 1.8567004203796387
Batch 22/64 loss: 1.6368346214294434
Batch 23/64 loss: 1.6788792610168457
Batch 24/64 loss: 1.6797218322753906
Batch 25/64 loss: 1.7319908142089844
Batch 26/64 loss: 1.7057437896728516
Batch 27/64 loss: 1.7076311111450195
Batch 28/64 loss: 2.422207832336426
Batch 29/64 loss: 1.6623830795288086
Batch 30/64 loss: 1.7281146049499512
Batch 31/64 loss: 1.617793083190918
Batch 32/64 loss: 1.7837166786193848
Batch 33/64 loss: 1.7499175071716309
Batch 34/64 loss: 1.8135299682617188
Batch 35/64 loss: 2.2795462608337402
Batch 36/64 loss: 1.7980575561523438
Batch 37/64 loss: 1.684748649597168
Batch 38/64 loss: 1.6811285018920898
Batch 39/64 loss: 1.6998910903930664
Batch 40/64 loss: 4.331169605255127
Batch 41/64 loss: 1.7711949348449707
Batch 42/64 loss: 1.8709845542907715
Batch 43/64 loss: 1.94569730758667
Batch 44/64 loss: 1.789381504058838
Batch 45/64 loss: 1.9546294212341309
Batch 46/64 loss: 1.754148006439209
Batch 47/64 loss: 2.732776165008545
Batch 48/64 loss: 1.8451237678527832
Batch 49/64 loss: 1.8253402709960938
Batch 50/64 loss: 1.927290439605713
Batch 51/64 loss: 1.676621437072754
Batch 52/64 loss: 1.720627784729004
Batch 53/64 loss: 1.6348576545715332
Batch 54/64 loss: 1.8155369758605957
Batch 55/64 loss: 1.668004035949707
Batch 56/64 loss: 1.7382111549377441
Batch 57/64 loss: 1.660590648651123
Batch 58/64 loss: 1.8595075607299805
Batch 59/64 loss: 1.7286648750305176
Batch 60/64 loss: 1.6956162452697754
Batch 61/64 loss: 2.054805278778076
Batch 62/64 loss: 1.9220070838928223
Batch 63/64 loss: 2.3026833534240723
Batch 64/64 loss: -1.7199106216430664
Epoch 241  Train loss: 1.9279274921791225  Val loss: 1.5478570944664813
Epoch 242
-------------------------------
Batch 1/64 loss: 1.899113655090332
Batch 2/64 loss: 2.175142765045166
Batch 3/64 loss: 1.9500732421875
Batch 4/64 loss: 1.7703289985656738
Batch 5/64 loss: 1.782106876373291
Batch 6/64 loss: 1.707864761352539
Batch 7/64 loss: 1.7677230834960938
Batch 8/64 loss: 2.019392967224121
Batch 9/64 loss: 2.9124464988708496
Batch 10/64 loss: 2.7273917198181152
Batch 11/64 loss: 1.7911548614501953
Batch 12/64 loss: 1.7675867080688477
Batch 13/64 loss: 1.7576122283935547
Batch 14/64 loss: 1.8721933364868164
Batch 15/64 loss: 1.9439191818237305
Batch 16/64 loss: 1.8781380653381348
Batch 17/64 loss: 2.104832649230957
Batch 18/64 loss: 1.7862930297851562
Batch 19/64 loss: 2.0169453620910645
Batch 20/64 loss: 1.7722182273864746
Batch 21/64 loss: 1.858999252319336
Batch 22/64 loss: 1.8688173294067383
Batch 23/64 loss: 1.8195710182189941
Batch 24/64 loss: 1.9183883666992188
Batch 25/64 loss: 1.74853515625
Batch 26/64 loss: 1.8713054656982422
Batch 27/64 loss: 1.9373507499694824
Batch 28/64 loss: 1.598924160003662
Batch 29/64 loss: 3.8618927001953125
Batch 30/64 loss: 3.2075295448303223
Batch 31/64 loss: 2.2611846923828125
Batch 32/64 loss: 1.7058982849121094
Batch 33/64 loss: 1.718287467956543
Batch 34/64 loss: 4.690094947814941
Batch 35/64 loss: 1.6806249618530273
Batch 36/64 loss: 1.6767778396606445
Batch 37/64 loss: 1.8991494178771973
Batch 38/64 loss: 2.067107677459717
Batch 39/64 loss: 1.9366846084594727
Batch 40/64 loss: 1.959726333618164
Batch 41/64 loss: 1.999281883239746
Batch 42/64 loss: 1.6338791847229004
Batch 43/64 loss: 4.062117099761963
Batch 44/64 loss: 1.8953757286071777
Batch 45/64 loss: 2.055868148803711
Batch 46/64 loss: 2.432018280029297
Batch 47/64 loss: 2.0027780532836914
Batch 48/64 loss: 1.7636871337890625
Batch 49/64 loss: 1.7593598365783691
Batch 50/64 loss: 1.8562726974487305
Batch 51/64 loss: 1.8310904502868652
Batch 52/64 loss: 1.9426393508911133
Batch 53/64 loss: 1.885286808013916
Batch 54/64 loss: 1.814743995666504
Batch 55/64 loss: 1.7078771591186523
Batch 56/64 loss: 1.860464096069336
Batch 57/64 loss: 1.7737746238708496
Batch 58/64 loss: 1.7542591094970703
Batch 59/64 loss: 1.703369140625
Batch 60/64 loss: 1.8147473335266113
Batch 61/64 loss: 1.6851320266723633
Batch 62/64 loss: 1.8950304985046387
Batch 63/64 loss: 1.9209628105163574
Batch 64/64 loss: -1.3915386199951172
Epoch 242  Train loss: 1.9873833675010533  Val loss: 1.5631985221941447
Epoch 243
-------------------------------
Batch 1/64 loss: 1.91340970993042
Batch 2/64 loss: 1.7155299186706543
Batch 3/64 loss: 1.8603086471557617
Batch 4/64 loss: 1.7597246170043945
Batch 5/64 loss: 1.7426776885986328
Batch 6/64 loss: 1.8092989921569824
Batch 7/64 loss: 1.8885254859924316
Batch 8/64 loss: 1.890120029449463
Batch 9/64 loss: 1.748425006866455
Batch 10/64 loss: 1.6932172775268555
Batch 11/64 loss: 2.1180806159973145
Batch 12/64 loss: 1.778247356414795
Batch 13/64 loss: 1.8658418655395508
Batch 14/64 loss: 1.932511806488037
Batch 15/64 loss: 1.7578649520874023
Batch 16/64 loss: 2.8026537895202637
Batch 17/64 loss: 1.8199782371520996
Batch 18/64 loss: 1.8209304809570312
Batch 19/64 loss: 1.6808032989501953
Batch 20/64 loss: 1.9811210632324219
Batch 21/64 loss: 1.9104437828063965
Batch 22/64 loss: 3.8596043586730957
Batch 23/64 loss: 1.7503662109375
Batch 24/64 loss: 2.9636945724487305
Batch 25/64 loss: 1.8100790977478027
Batch 26/64 loss: 1.748490333557129
Batch 27/64 loss: 1.6823835372924805
Batch 28/64 loss: 2.5554938316345215
Batch 29/64 loss: 2.1189236640930176
Batch 30/64 loss: 2.143571376800537
Batch 31/64 loss: 1.7610297203063965
Batch 32/64 loss: 1.7036056518554688
Batch 33/64 loss: 4.644561290740967
Batch 34/64 loss: 3.080166816711426
Batch 35/64 loss: 2.7359018325805664
Batch 36/64 loss: 1.7591190338134766
Batch 37/64 loss: 1.6455702781677246
Batch 38/64 loss: 1.9182329177856445
Batch 39/64 loss: 2.1344614028930664
Batch 40/64 loss: 1.811490535736084
Batch 41/64 loss: 1.8983497619628906
Batch 42/64 loss: 1.68619966506958
Batch 43/64 loss: 1.7621865272521973
Batch 44/64 loss: 1.9507641792297363
Batch 45/64 loss: 1.9106898307800293
Batch 46/64 loss: 1.9987530708312988
Batch 47/64 loss: 2.05610990524292
Batch 48/64 loss: 1.8941917419433594
Batch 49/64 loss: 1.7714223861694336
Batch 50/64 loss: 2.0085086822509766
Batch 51/64 loss: 1.6292243003845215
Batch 52/64 loss: 4.292032718658447
Batch 53/64 loss: 1.8001289367675781
Batch 54/64 loss: 2.023571014404297
Batch 55/64 loss: 1.8801250457763672
Batch 56/64 loss: 1.7682981491088867
Batch 57/64 loss: 1.8974895477294922
Batch 58/64 loss: 1.9452052116394043
Batch 59/64 loss: 2.290846824645996
Batch 60/64 loss: 1.8083033561706543
Batch 61/64 loss: 2.1819491386413574
Batch 62/64 loss: 1.8654775619506836
Batch 63/64 loss: 1.741015911102295
Batch 64/64 loss: -1.5169095993041992
Epoch 243  Train loss: 2.011601919286391  Val loss: 1.5735020195085978
Epoch 244
-------------------------------
Batch 1/64 loss: 1.8269057273864746
Batch 2/64 loss: 1.9506745338439941
Batch 3/64 loss: 1.7943286895751953
Batch 4/64 loss: 1.7410011291503906
Batch 5/64 loss: 1.9393806457519531
Batch 6/64 loss: 1.7129087448120117
Batch 7/64 loss: 1.6257319450378418
Batch 8/64 loss: 1.8278179168701172
Batch 9/64 loss: 1.7609820365905762
Batch 10/64 loss: 1.8635177612304688
Batch 11/64 loss: 1.784195899963379
Batch 12/64 loss: 1.8415331840515137
Batch 13/64 loss: 4.2517924308776855
Batch 14/64 loss: 1.688624382019043
Batch 15/64 loss: 1.8135461807250977
Batch 16/64 loss: 1.7163844108581543
Batch 17/64 loss: 1.7772698402404785
Batch 18/64 loss: 1.700669765472412
Batch 19/64 loss: 1.9010629653930664
Batch 20/64 loss: 1.76116943359375
Batch 21/64 loss: 2.022562026977539
Batch 22/64 loss: 1.7672767639160156
Batch 23/64 loss: 1.8187780380249023
Batch 24/64 loss: 1.857527256011963
Batch 25/64 loss: 1.6496520042419434
Batch 26/64 loss: 2.6953940391540527
Batch 27/64 loss: 1.6412930488586426
Batch 28/64 loss: 1.8615679740905762
Batch 29/64 loss: 2.6249184608459473
Batch 30/64 loss: 1.844031810760498
Batch 31/64 loss: 1.8861727714538574
Batch 32/64 loss: 1.7285957336425781
Batch 33/64 loss: 1.7179226875305176
Batch 34/64 loss: 1.7900395393371582
Batch 35/64 loss: 2.0177340507507324
Batch 36/64 loss: 1.78822660446167
Batch 37/64 loss: 4.646810054779053
Batch 38/64 loss: 4.972389221191406
Batch 39/64 loss: 1.692741870880127
Batch 40/64 loss: 1.8987317085266113
Batch 41/64 loss: 1.7948012351989746
Batch 42/64 loss: 1.972912311553955
Batch 43/64 loss: 2.012019157409668
Batch 44/64 loss: 1.8274779319763184
Batch 45/64 loss: 2.274015426635742
Batch 46/64 loss: 1.7707157135009766
Batch 47/64 loss: 1.7193427085876465
Batch 48/64 loss: 1.7941827774047852
Batch 49/64 loss: 1.780646800994873
Batch 50/64 loss: 2.5575079917907715
Batch 51/64 loss: 3.2514748573303223
Batch 52/64 loss: 2.049593925476074
Batch 53/64 loss: 1.9335989952087402
Batch 54/64 loss: 1.7200593948364258
Batch 55/64 loss: 1.792287826538086
Batch 56/64 loss: 1.8173809051513672
Batch 57/64 loss: 2.1800432205200195
Batch 58/64 loss: 2.030384063720703
Batch 59/64 loss: 1.8919448852539062
Batch 60/64 loss: 1.9329476356506348
Batch 61/64 loss: 1.98176908493042
Batch 62/64 loss: 1.7690472602844238
Batch 63/64 loss: 1.853245735168457
Batch 64/64 loss: -1.5792455673217773
Epoch 244  Train loss: 1.9878404542511585  Val loss: 1.5289227724894625
Epoch 245
-------------------------------
Batch 1/64 loss: 1.7860784530639648
Batch 2/64 loss: 1.8560233116149902
Batch 3/64 loss: 2.6439080238342285
Batch 4/64 loss: 1.596717357635498
Batch 5/64 loss: 1.7369179725646973
Batch 6/64 loss: 2.0416951179504395
Batch 7/64 loss: 1.7223401069641113
Batch 8/64 loss: 1.7631621360778809
Batch 9/64 loss: 1.7381787300109863
Batch 10/64 loss: 1.7306208610534668
Batch 11/64 loss: 1.8632593154907227
Batch 12/64 loss: 2.1226963996887207
Batch 13/64 loss: 2.116086959838867
Batch 14/64 loss: 1.661027431488037
Batch 15/64 loss: 1.8681650161743164
Batch 16/64 loss: 3.308840274810791
Batch 17/64 loss: 2.2782726287841797
Batch 18/64 loss: 1.8049087524414062
Batch 19/64 loss: 1.7768325805664062
Batch 20/64 loss: 1.7933659553527832
Batch 21/64 loss: 4.629868984222412
Batch 22/64 loss: 1.830256462097168
Batch 23/64 loss: 1.7389039993286133
Batch 24/64 loss: 1.7036066055297852
Batch 25/64 loss: 1.8015775680541992
Batch 26/64 loss: 1.7767300605773926
Batch 27/64 loss: 1.8270721435546875
Batch 28/64 loss: 1.8020811080932617
Batch 29/64 loss: 1.8180451393127441
Batch 30/64 loss: 1.71815824508667
Batch 31/64 loss: 1.9871840476989746
Batch 32/64 loss: 1.681577205657959
Batch 33/64 loss: 5.061715126037598
Batch 34/64 loss: 1.6906323432922363
Batch 35/64 loss: 1.9579529762268066
Batch 36/64 loss: 1.736790657043457
Batch 37/64 loss: 2.3356590270996094
Batch 38/64 loss: 1.7416229248046875
Batch 39/64 loss: 2.062770366668701
Batch 40/64 loss: 2.83198881149292
Batch 41/64 loss: 1.913762092590332
Batch 42/64 loss: 1.6938133239746094
Batch 43/64 loss: 1.770937442779541
Batch 44/64 loss: 1.9717698097229004
Batch 45/64 loss: 1.9065637588500977
Batch 46/64 loss: 1.8517303466796875
Batch 47/64 loss: 2.270730495452881
Batch 48/64 loss: 1.7456140518188477
Batch 49/64 loss: 2.051628589630127
Batch 50/64 loss: 1.687385082244873
Batch 51/64 loss: 1.889298915863037
Batch 52/64 loss: 2.0920400619506836
Batch 53/64 loss: 1.8060393333435059
Batch 54/64 loss: 3.97359037399292
Batch 55/64 loss: 1.7876882553100586
Batch 56/64 loss: 1.7929439544677734
Batch 57/64 loss: 1.9014854431152344
Batch 58/64 loss: 1.8359298706054688
Batch 59/64 loss: 1.8078322410583496
Batch 60/64 loss: 1.956233024597168
Batch 61/64 loss: 1.7264108657836914
Batch 62/64 loss: 1.6651725769042969
Batch 63/64 loss: 1.9599885940551758
Batch 64/64 loss: -1.6094017028808594
Epoch 245  Train loss: 1.9889384849398744  Val loss: 1.691137340060624
Epoch 246
-------------------------------
Batch 1/64 loss: 2.2120604515075684
Batch 2/64 loss: 1.956557273864746
Batch 3/64 loss: 1.7418532371520996
Batch 4/64 loss: 1.7772388458251953
Batch 5/64 loss: 1.9715023040771484
Batch 6/64 loss: 1.8531899452209473
Batch 7/64 loss: 1.9587998390197754
Batch 8/64 loss: 1.726773738861084
Batch 9/64 loss: 1.8830299377441406
Batch 10/64 loss: 1.744448184967041
Batch 11/64 loss: 1.8637747764587402
Batch 12/64 loss: 3.8378348350524902
Batch 13/64 loss: 2.395941734313965
Batch 14/64 loss: 1.7980947494506836
Batch 15/64 loss: 5.062829494476318
Batch 16/64 loss: 1.8193020820617676
Batch 17/64 loss: 2.4769744873046875
Batch 18/64 loss: 1.774704933166504
Batch 19/64 loss: 1.7872896194458008
Batch 20/64 loss: 1.9751300811767578
Batch 21/64 loss: 2.707167148590088
Batch 22/64 loss: 3.1737241744995117
Batch 23/64 loss: 2.307063579559326
Batch 24/64 loss: 1.718916416168213
Batch 25/64 loss: 1.7381205558776855
Batch 26/64 loss: 1.7253732681274414
Batch 27/64 loss: 2.0144519805908203
Batch 28/64 loss: 1.7011175155639648
Batch 29/64 loss: 2.112424373626709
Batch 30/64 loss: 1.8603897094726562
Batch 31/64 loss: 1.8108315467834473
Batch 32/64 loss: 1.706423282623291
Batch 33/64 loss: 1.9793920516967773
Batch 34/64 loss: 1.9918522834777832
Batch 35/64 loss: 1.8997087478637695
Batch 36/64 loss: 1.7174434661865234
Batch 37/64 loss: 2.6334357261657715
Batch 38/64 loss: 1.869009017944336
Batch 39/64 loss: 1.9046082496643066
Batch 40/64 loss: 1.7548842430114746
Batch 41/64 loss: 1.804898738861084
Batch 42/64 loss: 1.960798740386963
Batch 43/64 loss: 3.0371780395507812
Batch 44/64 loss: 1.8246979713439941
Batch 45/64 loss: 2.018714427947998
Batch 46/64 loss: 1.767019271850586
Batch 47/64 loss: 1.713399887084961
Batch 48/64 loss: 1.7248787879943848
Batch 49/64 loss: 4.00038480758667
Batch 50/64 loss: 1.6457695960998535
Batch 51/64 loss: 1.794511318206787
Batch 52/64 loss: 1.6925835609436035
Batch 53/64 loss: 1.648360252380371
Batch 54/64 loss: 1.5883464813232422
Batch 55/64 loss: 4.202683925628662
Batch 56/64 loss: 2.044062614440918
Batch 57/64 loss: 2.1310253143310547
Batch 58/64 loss: 2.2326183319091797
Batch 59/64 loss: 1.6226081848144531
Batch 60/64 loss: 1.7391180992126465
Batch 61/64 loss: 1.6361284255981445
Batch 62/64 loss: 1.9440436363220215
Batch 63/64 loss: 2.2969565391540527
Batch 64/64 loss: -1.593658447265625
Epoch 246  Train loss: 2.05206605499866  Val loss: 1.5115025510493012
Epoch 247
-------------------------------
Batch 1/64 loss: 1.8183207511901855
Batch 2/64 loss: 1.917353630065918
Batch 3/64 loss: 1.8692998886108398
Batch 4/64 loss: 1.7462434768676758
Batch 5/64 loss: 2.5401182174682617
Batch 6/64 loss: 6.6218085289001465
Batch 7/64 loss: 1.6798105239868164
Batch 8/64 loss: 1.6840710639953613
Batch 9/64 loss: 1.8054022789001465
Batch 10/64 loss: 1.6526098251342773
Batch 11/64 loss: 1.8341236114501953
Batch 12/64 loss: 1.97175931930542
Batch 13/64 loss: 1.842759609222412
Batch 14/64 loss: 1.9732179641723633
Batch 15/64 loss: 1.9052305221557617
Batch 16/64 loss: 1.696058750152588
Batch 17/64 loss: 1.747119426727295
Batch 18/64 loss: 1.7192864418029785
Batch 19/64 loss: 2.1266069412231445
Batch 20/64 loss: 1.787710189819336
Batch 21/64 loss: 2.0269789695739746
Batch 22/64 loss: 2.1055660247802734
Batch 23/64 loss: 1.809863567352295
Batch 24/64 loss: 1.6352219581604004
Batch 25/64 loss: 1.9705662727355957
Batch 26/64 loss: 3.3554534912109375
Batch 27/64 loss: 1.7393808364868164
Batch 28/64 loss: 2.820827007293701
Batch 29/64 loss: 1.7054777145385742
Batch 30/64 loss: 1.8981451988220215
Batch 31/64 loss: 1.8785648345947266
Batch 32/64 loss: 1.7656936645507812
Batch 33/64 loss: 1.707509994506836
Batch 34/64 loss: 1.9014487266540527
Batch 35/64 loss: 1.6065726280212402
Batch 36/64 loss: 1.858896255493164
Batch 37/64 loss: 1.9252047538757324
Batch 38/64 loss: 1.731877326965332
Batch 39/64 loss: 1.7193994522094727
Batch 40/64 loss: 1.760754108428955
Batch 41/64 loss: 1.684128761291504
Batch 42/64 loss: 1.7437806129455566
Batch 43/64 loss: 1.7494878768920898
Batch 44/64 loss: 3.1670002937316895
Batch 45/64 loss: 1.6312780380249023
Batch 46/64 loss: 1.818760871887207
Batch 47/64 loss: 1.7437410354614258
Batch 48/64 loss: 1.6724553108215332
Batch 49/64 loss: 1.6015582084655762
Batch 50/64 loss: 1.9808216094970703
Batch 51/64 loss: 1.7121872901916504
Batch 52/64 loss: 1.7533178329467773
Batch 53/64 loss: 1.7882084846496582
Batch 54/64 loss: 1.7158799171447754
Batch 55/64 loss: 1.7845959663391113
Batch 56/64 loss: 1.6664199829101562
Batch 57/64 loss: 1.669466495513916
Batch 58/64 loss: 1.7541155815124512
Batch 59/64 loss: 1.6277413368225098
Batch 60/64 loss: 2.0033202171325684
Batch 61/64 loss: 1.7171669006347656
Batch 62/64 loss: 2.030526638031006
Batch 63/64 loss: 1.7606539726257324
Batch 64/64 loss: 0.49659252166748047
Epoch 247  Train loss: 1.9295901392020431  Val loss: 1.649730852789076
Epoch 248
-------------------------------
Batch 1/64 loss: 1.7252388000488281
Batch 2/64 loss: 4.5839996337890625
Batch 3/64 loss: 1.8837623596191406
Batch 4/64 loss: 1.860537052154541
Batch 5/64 loss: 1.910658359527588
Batch 6/64 loss: 1.987441062927246
Batch 7/64 loss: 2.4834952354431152
Batch 8/64 loss: 2.443448543548584
Batch 9/64 loss: 3.865973472595215
Batch 10/64 loss: 1.9335894584655762
Batch 11/64 loss: 2.0983471870422363
Batch 12/64 loss: 2.1404290199279785
Batch 13/64 loss: 1.954695701599121
Batch 14/64 loss: 2.0098094940185547
Batch 15/64 loss: 1.8732094764709473
Batch 16/64 loss: 2.146346092224121
Batch 17/64 loss: 2.047854423522949
Batch 18/64 loss: 2.457073211669922
Batch 19/64 loss: 2.972878932952881
Batch 20/64 loss: 2.146493434906006
Batch 21/64 loss: 3.221984386444092
Batch 22/64 loss: 4.587032794952393
Batch 23/64 loss: 2.0637593269348145
Batch 24/64 loss: 2.1684975624084473
Batch 25/64 loss: 1.9997940063476562
Batch 26/64 loss: 2.0461926460266113
Batch 27/64 loss: 1.9920315742492676
Batch 28/64 loss: 2.2123146057128906
Batch 29/64 loss: 1.8783082962036133
Batch 30/64 loss: 2.2114644050598145
Batch 31/64 loss: 2.378261089324951
Batch 32/64 loss: 1.9428553581237793
Batch 33/64 loss: 1.9236960411071777
Batch 34/64 loss: 3.0310449600219727
Batch 35/64 loss: 2.090786933898926
Batch 36/64 loss: 2.440619468688965
Batch 37/64 loss: 1.8683834075927734
Batch 38/64 loss: 2.079127788543701
Batch 39/64 loss: 2.028008460998535
Batch 40/64 loss: 2.9767069816589355
Batch 41/64 loss: 2.1991143226623535
Batch 42/64 loss: 3.3350415229797363
Batch 43/64 loss: 4.266664028167725
Batch 44/64 loss: 1.9645729064941406
Batch 45/64 loss: 3.5717577934265137
Batch 46/64 loss: 3.5692262649536133
Batch 47/64 loss: 2.447606086730957
Batch 48/64 loss: 2.2304768562316895
Batch 49/64 loss: 2.859715461730957
Batch 50/64 loss: 1.9964747428894043
Batch 51/64 loss: 5.1124186515808105
Batch 52/64 loss: 3.816657543182373
Batch 53/64 loss: 2.485286235809326
Batch 54/64 loss: 2.1368050575256348
Batch 55/64 loss: 2.214463233947754
Batch 56/64 loss: 2.221522808074951
Batch 57/64 loss: 1.9445557594299316
Batch 58/64 loss: 2.9541988372802734
Batch 59/64 loss: 2.6565003395080566
Batch 60/64 loss: 2.10172700881958
Batch 61/64 loss: 3.8372697830200195
Batch 62/64 loss: 2.129950523376465
Batch 63/64 loss: 2.0985774993896484
Batch 64/64 loss: -1.139699935913086
Epoch 248  Train loss: 2.4621483821494907  Val loss: 2.0056466826868222
Epoch 249
-------------------------------
Batch 1/64 loss: 1.8746280670166016
Batch 2/64 loss: 1.8653779029846191
Batch 3/64 loss: 1.8619589805603027
Batch 4/64 loss: 2.8134050369262695
Batch 5/64 loss: 2.0553698539733887
Batch 6/64 loss: 2.516453266143799
Batch 7/64 loss: 2.0016770362854004
Batch 8/64 loss: 2.5737271308898926
Batch 9/64 loss: 2.058577537536621
Batch 10/64 loss: 2.421844959259033
Batch 11/64 loss: 2.5869436264038086
Batch 12/64 loss: 1.8753223419189453
Batch 13/64 loss: 2.133500099182129
Batch 14/64 loss: 2.5430421829223633
Batch 15/64 loss: 1.8127455711364746
Batch 16/64 loss: 2.0777387619018555
Batch 17/64 loss: 2.011608600616455
Batch 18/64 loss: 1.9855775833129883
Batch 19/64 loss: 2.2237367630004883
Batch 20/64 loss: 3.735957622528076
Batch 21/64 loss: 1.8678832054138184
Batch 22/64 loss: 2.199143409729004
Batch 23/64 loss: 2.021951198577881
Batch 24/64 loss: 2.295206069946289
Batch 25/64 loss: 2.023162841796875
Batch 26/64 loss: 2.4054036140441895
Batch 27/64 loss: 2.2446446418762207
Batch 28/64 loss: 1.903979778289795
Batch 29/64 loss: 1.8456392288208008
Batch 30/64 loss: 3.0947632789611816
Batch 31/64 loss: 2.329780101776123
Batch 32/64 loss: 2.073479175567627
Batch 33/64 loss: 2.21420955657959
Batch 34/64 loss: 2.172513484954834
Batch 35/64 loss: 1.911386489868164
Batch 36/64 loss: 2.166858196258545
Batch 37/64 loss: 1.996744155883789
Batch 38/64 loss: 1.804194450378418
Batch 39/64 loss: 1.9000091552734375
Batch 40/64 loss: 1.8141913414001465
Batch 41/64 loss: 1.7915759086608887
Batch 42/64 loss: 2.0242743492126465
Batch 43/64 loss: 1.8279671669006348
Batch 44/64 loss: 1.83815336227417
Batch 45/64 loss: 1.7197589874267578
Batch 46/64 loss: 2.833244800567627
Batch 47/64 loss: 1.7731599807739258
Batch 48/64 loss: 3.1145877838134766
Batch 49/64 loss: 4.161909580230713
Batch 50/64 loss: 1.7377958297729492
Batch 51/64 loss: 2.090104103088379
Batch 52/64 loss: 4.897525787353516
Batch 53/64 loss: 1.780510425567627
Batch 54/64 loss: 2.0722336769104004
Batch 55/64 loss: 4.372591018676758
Batch 56/64 loss: 1.8529558181762695
Batch 57/64 loss: 1.9227752685546875
Batch 58/64 loss: 1.711616039276123
Batch 59/64 loss: 2.489943027496338
Batch 60/64 loss: 1.880795955657959
Batch 61/64 loss: 1.8498635292053223
Batch 62/64 loss: 1.8387579917907715
Batch 63/64 loss: 1.91987943649292
Batch 64/64 loss: -1.5334138870239258
Epoch 249  Train loss: 2.1908432268628886  Val loss: 1.693090563377564
Epoch 250
-------------------------------
Batch 1/64 loss: 5.136105537414551
Batch 2/64 loss: 1.854933261871338
Batch 3/64 loss: 1.8604755401611328
Batch 4/64 loss: 1.742095947265625
Batch 5/64 loss: 2.1686673164367676
Batch 6/64 loss: 2.0313291549682617
Batch 7/64 loss: 2.006953239440918
Batch 8/64 loss: 2.148134231567383
Batch 9/64 loss: 2.0136499404907227
Batch 10/64 loss: 2.274643898010254
Batch 11/64 loss: 1.7945094108581543
Batch 12/64 loss: 1.805924892425537
Batch 13/64 loss: 1.7262821197509766
Batch 14/64 loss: 1.8476881980895996
Batch 15/64 loss: 1.7254042625427246
Batch 16/64 loss: 1.8014321327209473
Batch 17/64 loss: 2.0882883071899414
Batch 18/64 loss: 1.615732192993164
Batch 19/64 loss: 2.0116796493530273
Batch 20/64 loss: 2.944845676422119
Batch 21/64 loss: 2.067842483520508
Batch 22/64 loss: 1.6790194511413574
Batch 23/64 loss: 1.7929954528808594
Batch 24/64 loss: 2.031643867492676
Batch 25/64 loss: 2.7681760787963867
Batch 26/64 loss: 2.009255886077881
Batch 27/64 loss: 1.7064709663391113
Batch 28/64 loss: 2.507913589477539
Batch 29/64 loss: 1.92708158493042
Batch 30/64 loss: 1.6784844398498535
Batch 31/64 loss: 1.6688013076782227
Batch 32/64 loss: 1.7265009880065918
Batch 33/64 loss: 4.199159622192383
Batch 34/64 loss: 1.7389154434204102
Batch 35/64 loss: 1.7315526008605957
Batch 36/64 loss: 1.782569408416748
Batch 37/64 loss: 2.1957225799560547
Batch 38/64 loss: 1.7682175636291504
Batch 39/64 loss: 1.8248820304870605
Batch 40/64 loss: 1.958733081817627
Batch 41/64 loss: 1.9245905876159668
Batch 42/64 loss: 1.8188872337341309
Batch 43/64 loss: 2.583770751953125
Batch 44/64 loss: 3.275822639465332
Batch 45/64 loss: 1.9264121055603027
Batch 46/64 loss: 1.9887580871582031
Batch 47/64 loss: 2.13462495803833
Batch 48/64 loss: 2.0322651863098145
Batch 49/64 loss: 1.8726024627685547
Batch 50/64 loss: 1.759018898010254
Batch 51/64 loss: 1.8159875869750977
Batch 52/64 loss: 1.807507038116455
Batch 53/64 loss: 1.7999944686889648
Batch 54/64 loss: 1.7028799057006836
Batch 55/64 loss: 1.977917194366455
Batch 56/64 loss: 1.8771657943725586
Batch 57/64 loss: 2.0049591064453125
Batch 58/64 loss: 2.2657833099365234
Batch 59/64 loss: 1.9867157936096191
Batch 60/64 loss: 4.2141618728637695
Batch 61/64 loss: 1.687565803527832
Batch 62/64 loss: 1.7752532958984375
Batch 63/64 loss: 1.6130385398864746
Batch 64/64 loss: -1.5200586318969727
Epoch 250  Train loss: 2.0402878742592008  Val loss: 1.6103255675011074
Epoch 251
-------------------------------
Batch 1/64 loss: 2.0610294342041016
Batch 2/64 loss: 1.6809349060058594
Batch 3/64 loss: 1.829035758972168
Batch 4/64 loss: 2.9141764640808105
Batch 5/64 loss: 2.149115562438965
Batch 6/64 loss: 1.9287562370300293
Batch 7/64 loss: 1.9464325904846191
Batch 8/64 loss: 1.9948997497558594
Batch 9/64 loss: 2.9298667907714844
Batch 10/64 loss: 1.7509002685546875
Batch 11/64 loss: 2.023221492767334
Batch 12/64 loss: 1.6598405838012695
Batch 13/64 loss: 2.1048507690429688
Batch 14/64 loss: 1.795511245727539
Batch 15/64 loss: 1.6770944595336914
Batch 16/64 loss: 1.955613136291504
Batch 17/64 loss: 1.722649097442627
Batch 18/64 loss: 1.915268898010254
Batch 19/64 loss: 1.6150708198547363
Batch 20/64 loss: 2.0649232864379883
Batch 21/64 loss: 1.7228460311889648
Batch 22/64 loss: 1.8329362869262695
Batch 23/64 loss: 1.7530879974365234
Batch 24/64 loss: 1.7845559120178223
Batch 25/64 loss: 1.8806495666503906
Batch 26/64 loss: 1.793750286102295
Batch 27/64 loss: 1.8516616821289062
Batch 28/64 loss: 1.8060059547424316
Batch 29/64 loss: 1.908522605895996
Batch 30/64 loss: 3.0841097831726074
Batch 31/64 loss: 1.8393545150756836
Batch 32/64 loss: 1.7802858352661133
Batch 33/64 loss: 1.9937310218811035
Batch 34/64 loss: 2.0859808921813965
Batch 35/64 loss: 1.7398838996887207
Batch 36/64 loss: 1.8396515846252441
Batch 37/64 loss: 2.519319534301758
Batch 38/64 loss: 4.372594833374023
Batch 39/64 loss: 1.865990161895752
Batch 40/64 loss: 1.7951955795288086
Batch 41/64 loss: 1.986642837524414
Batch 42/64 loss: 1.8522453308105469
Batch 43/64 loss: 1.845029354095459
Batch 44/64 loss: 1.791762351989746
Batch 45/64 loss: 2.124239444732666
Batch 46/64 loss: 1.8142180442810059
Batch 47/64 loss: 2.022510051727295
Batch 48/64 loss: 1.9023118019104004
Batch 49/64 loss: 2.3710575103759766
Batch 50/64 loss: 1.784712791442871
Batch 51/64 loss: 4.733914852142334
Batch 52/64 loss: 2.361072063446045
Batch 53/64 loss: 1.942300796508789
Batch 54/64 loss: 2.042207717895508
Batch 55/64 loss: 1.7785143852233887
Batch 56/64 loss: 1.7168965339660645
Batch 57/64 loss: 1.7432703971862793
Batch 58/64 loss: 3.894443988800049
Batch 59/64 loss: 1.7279844284057617
Batch 60/64 loss: 1.949751377105713
Batch 61/64 loss: 1.6212959289550781
Batch 62/64 loss: 2.5211291313171387
Batch 63/64 loss: 1.8154964447021484
Batch 64/64 loss: -1.6920099258422852
Epoch 251  Train loss: 2.0242087158502318  Val loss: 1.681165138061104
Epoch 252
-------------------------------
Batch 1/64 loss: 1.7579622268676758
Batch 2/64 loss: 1.7832207679748535
Batch 3/64 loss: 1.7467989921569824
Batch 4/64 loss: 2.0640368461608887
Batch 5/64 loss: 2.77272891998291
Batch 6/64 loss: 3.9412007331848145
Batch 7/64 loss: 1.7842292785644531
Batch 8/64 loss: 1.9049334526062012
Batch 9/64 loss: 1.9202346801757812
Batch 10/64 loss: 1.9876651763916016
Batch 11/64 loss: 1.7266874313354492
Batch 12/64 loss: 1.674975872039795
Batch 13/64 loss: 1.944441795349121
Batch 14/64 loss: 2.1036715507507324
Batch 15/64 loss: 1.7949881553649902
Batch 16/64 loss: 1.7072548866271973
Batch 17/64 loss: 5.1722517013549805
Batch 18/64 loss: 1.9669084548950195
Batch 19/64 loss: 2.116936206817627
Batch 20/64 loss: 2.1197333335876465
Batch 21/64 loss: 1.8116283416748047
Batch 22/64 loss: 1.8780708312988281
Batch 23/64 loss: 2.0870070457458496
Batch 24/64 loss: 1.8427910804748535
Batch 25/64 loss: 2.0647058486938477
Batch 26/64 loss: 1.7085633277893066
Batch 27/64 loss: 2.0706019401550293
Batch 28/64 loss: 2.220858573913574
Batch 29/64 loss: 1.8657450675964355
Batch 30/64 loss: 1.7225837707519531
Batch 31/64 loss: 1.9183287620544434
Batch 32/64 loss: 2.1189961433410645
Batch 33/64 loss: 4.170598983764648
Batch 34/64 loss: 1.7632765769958496
Batch 35/64 loss: 1.997633934020996
Batch 36/64 loss: 2.0208301544189453
Batch 37/64 loss: 1.8256235122680664
Batch 38/64 loss: 1.776893138885498
Batch 39/64 loss: 1.707414150238037
Batch 40/64 loss: 2.022491931915283
Batch 41/64 loss: 1.7785797119140625
Batch 42/64 loss: 2.5395312309265137
Batch 43/64 loss: 1.9355320930480957
Batch 44/64 loss: 1.7775025367736816
Batch 45/64 loss: 1.709129810333252
Batch 46/64 loss: 1.7198491096496582
Batch 47/64 loss: 2.1013035774230957
Batch 48/64 loss: 1.8192715644836426
Batch 49/64 loss: 1.8560166358947754
Batch 50/64 loss: 1.6538739204406738
Batch 51/64 loss: 1.6857471466064453
Batch 52/64 loss: 2.1477818489074707
Batch 53/64 loss: 1.8243193626403809
Batch 54/64 loss: 1.7750754356384277
Batch 55/64 loss: 3.11538028717041
Batch 56/64 loss: 1.7352042198181152
Batch 57/64 loss: 3.005932331085205
Batch 58/64 loss: 1.8238143920898438
Batch 59/64 loss: 2.0156397819519043
Batch 60/64 loss: 1.920823097229004
Batch 61/64 loss: 2.3529882431030273
Batch 62/64 loss: 1.968614101409912
Batch 63/64 loss: 1.7386016845703125
Batch 64/64 loss: -1.5844135284423828
Epoch 252  Train loss: 2.029767930273916  Val loss: 1.5536185982301063
Epoch 253
-------------------------------
Batch 1/64 loss: 1.7249274253845215
Batch 2/64 loss: 2.2372679710388184
Batch 3/64 loss: 1.7926630973815918
Batch 4/64 loss: 2.6942148208618164
Batch 5/64 loss: 3.9289679527282715
Batch 6/64 loss: 2.0247483253479004
Batch 7/64 loss: 1.837313175201416
Batch 8/64 loss: 1.7668099403381348
Batch 9/64 loss: 1.6758537292480469
Batch 10/64 loss: 4.452732086181641
Batch 11/64 loss: 1.7893304824829102
Batch 12/64 loss: 1.6095528602600098
Batch 13/64 loss: 1.9117255210876465
Batch 14/64 loss: 2.283562660217285
Batch 15/64 loss: 1.6327214241027832
Batch 16/64 loss: 1.96390962600708
Batch 17/64 loss: 4.881047248840332
Batch 18/64 loss: 1.7493853569030762
Batch 19/64 loss: 1.7683863639831543
Batch 20/64 loss: 2.851919174194336
Batch 21/64 loss: 1.883434772491455
Batch 22/64 loss: 1.656519889831543
Batch 23/64 loss: 2.832277297973633
Batch 24/64 loss: 1.9591822624206543
Batch 25/64 loss: 1.7631583213806152
Batch 26/64 loss: 1.6966314315795898
Batch 27/64 loss: 2.339740753173828
Batch 28/64 loss: 1.6681079864501953
Batch 29/64 loss: 1.8586196899414062
Batch 30/64 loss: 1.8261661529541016
Batch 31/64 loss: 1.743276596069336
Batch 32/64 loss: 1.8048501014709473
Batch 33/64 loss: 1.7276649475097656
Batch 34/64 loss: 1.7575716972351074
Batch 35/64 loss: 1.8519482612609863
Batch 36/64 loss: 1.7750649452209473
Batch 37/64 loss: 1.8839426040649414
Batch 38/64 loss: 1.7341046333312988
Batch 39/64 loss: 1.6976752281188965
Batch 40/64 loss: 2.2733898162841797
Batch 41/64 loss: 1.7548575401306152
Batch 42/64 loss: 1.8172211647033691
Batch 43/64 loss: 1.7509827613830566
Batch 44/64 loss: 1.6685028076171875
Batch 45/64 loss: 1.7725849151611328
Batch 46/64 loss: 1.951179027557373
Batch 47/64 loss: 2.0456466674804688
Batch 48/64 loss: 2.5181565284729004
Batch 49/64 loss: 1.6889677047729492
Batch 50/64 loss: 1.7248797416687012
Batch 51/64 loss: 1.8635368347167969
Batch 52/64 loss: 1.6808714866638184
Batch 53/64 loss: 2.1126046180725098
Batch 54/64 loss: 1.7809596061706543
Batch 55/64 loss: 1.7286624908447266
Batch 56/64 loss: 1.7439203262329102
Batch 57/64 loss: 1.7772817611694336
Batch 58/64 loss: 1.9401741027832031
Batch 59/64 loss: 1.7749710083007812
Batch 60/64 loss: 1.765246868133545
Batch 61/64 loss: 1.8584861755371094
Batch 62/64 loss: 1.9033665657043457
Batch 63/64 loss: 1.830876350402832
Batch 64/64 loss: -1.7004632949829102
Epoch 253  Train loss: 1.9684542151058422  Val loss: 1.5206591157159446
Epoch 254
-------------------------------
Batch 1/64 loss: 1.7761249542236328
Batch 2/64 loss: 4.263922214508057
Batch 3/64 loss: 1.7563090324401855
Batch 4/64 loss: 2.886610507965088
Batch 5/64 loss: 1.6918768882751465
Batch 6/64 loss: 2.9163618087768555
Batch 7/64 loss: 1.7151260375976562
Batch 8/64 loss: 1.7256875038146973
Batch 9/64 loss: 1.6662969589233398
Batch 10/64 loss: 1.56756591796875
Batch 11/64 loss: 1.7606964111328125
Batch 12/64 loss: 1.7474684715270996
Batch 13/64 loss: 1.782175064086914
Batch 14/64 loss: 1.8962159156799316
Batch 15/64 loss: 1.6885042190551758
Batch 16/64 loss: 2.074842929840088
Batch 17/64 loss: 4.533908843994141
Batch 18/64 loss: 2.0541696548461914
Batch 19/64 loss: 1.8641304969787598
Batch 20/64 loss: 2.0701870918273926
Batch 21/64 loss: 1.8091130256652832
Batch 22/64 loss: 1.7834162712097168
Batch 23/64 loss: 1.9363932609558105
Batch 24/64 loss: 2.2380809783935547
Batch 25/64 loss: 1.8773307800292969
Batch 26/64 loss: 1.9068703651428223
Batch 27/64 loss: 1.762925624847412
Batch 28/64 loss: 1.8705945014953613
Batch 29/64 loss: 2.001038074493408
Batch 30/64 loss: 1.8554272651672363
Batch 31/64 loss: 2.315401077270508
Batch 32/64 loss: 1.7677712440490723
Batch 33/64 loss: 2.4507288932800293
Batch 34/64 loss: 1.906052589416504
Batch 35/64 loss: 1.7173237800598145
Batch 36/64 loss: 1.9671306610107422
Batch 37/64 loss: 1.709291934967041
Batch 38/64 loss: 1.8743486404418945
Batch 39/64 loss: 1.7523913383483887
Batch 40/64 loss: 1.8483381271362305
Batch 41/64 loss: 4.064469337463379
Batch 42/64 loss: 1.6728715896606445
Batch 43/64 loss: 1.8887581825256348
Batch 44/64 loss: 1.8818707466125488
Batch 45/64 loss: 1.874767780303955
Batch 46/64 loss: 2.5592594146728516
Batch 47/64 loss: 1.8113079071044922
Batch 48/64 loss: 1.7010135650634766
Batch 49/64 loss: 1.8854517936706543
Batch 50/64 loss: 1.823143482208252
Batch 51/64 loss: 1.702904224395752
Batch 52/64 loss: 1.7266488075256348
Batch 53/64 loss: 2.2451963424682617
Batch 54/64 loss: 1.8561382293701172
Batch 55/64 loss: 1.8314132690429688
Batch 56/64 loss: 1.6419672966003418
Batch 57/64 loss: 1.8836822509765625
Batch 58/64 loss: 2.1771178245544434
Batch 59/64 loss: 2.05733585357666
Batch 60/64 loss: 1.7996711730957031
Batch 61/64 loss: 1.6781401634216309
Batch 62/64 loss: 1.72560453414917
Batch 63/64 loss: 2.505753517150879
Batch 64/64 loss: -1.7650203704833984
Epoch 254  Train loss: 1.9836685704249961  Val loss: 1.5901795613397027
Epoch 255
-------------------------------
Batch 1/64 loss: 1.7884478569030762
Batch 2/64 loss: 1.7837390899658203
Batch 3/64 loss: 1.7557311058044434
Batch 4/64 loss: 2.5186500549316406
Batch 5/64 loss: 1.9135475158691406
Batch 6/64 loss: 1.9518842697143555
Batch 7/64 loss: 1.9403891563415527
Batch 8/64 loss: 1.7212529182434082
Batch 9/64 loss: 4.161056041717529
Batch 10/64 loss: 1.7311859130859375
Batch 11/64 loss: 1.7652010917663574
Batch 12/64 loss: 1.6535100936889648
Batch 13/64 loss: 1.7836337089538574
Batch 14/64 loss: 1.7514095306396484
Batch 15/64 loss: 1.865170955657959
Batch 16/64 loss: 1.7405304908752441
Batch 17/64 loss: 1.9435396194458008
Batch 18/64 loss: 4.1318254470825195
Batch 19/64 loss: 1.7478008270263672
Batch 20/64 loss: 1.8329663276672363
Batch 21/64 loss: 4.698723793029785
Batch 22/64 loss: 1.9177422523498535
Batch 23/64 loss: 2.130486011505127
Batch 24/64 loss: 1.758479118347168
Batch 25/64 loss: 2.053272247314453
Batch 26/64 loss: 1.7505741119384766
Batch 27/64 loss: 1.8604435920715332
Batch 28/64 loss: 1.8730626106262207
Batch 29/64 loss: 2.8550515174865723
Batch 30/64 loss: 2.1593594551086426
Batch 31/64 loss: 1.8301162719726562
Batch 32/64 loss: 1.631589412689209
Batch 33/64 loss: 3.3813023567199707
Batch 34/64 loss: 1.7749929428100586
Batch 35/64 loss: 1.9859347343444824
Batch 36/64 loss: 1.8200669288635254
Batch 37/64 loss: 2.5501537322998047
Batch 38/64 loss: 1.804281234741211
Batch 39/64 loss: 1.6784887313842773
Batch 40/64 loss: 1.9260058403015137
Batch 41/64 loss: 1.765455722808838
Batch 42/64 loss: 1.8763771057128906
Batch 43/64 loss: 1.8489251136779785
Batch 44/64 loss: 1.8921785354614258
Batch 45/64 loss: 1.8343615531921387
Batch 46/64 loss: 1.862830638885498
Batch 47/64 loss: 1.742018699645996
Batch 48/64 loss: 1.8416438102722168
Batch 49/64 loss: 1.6837124824523926
Batch 50/64 loss: 1.79819917678833
Batch 51/64 loss: 2.7677035331726074
Batch 52/64 loss: 1.7541155815124512
Batch 53/64 loss: 1.7903132438659668
Batch 54/64 loss: 1.6842665672302246
Batch 55/64 loss: 1.7134671211242676
Batch 56/64 loss: 1.767531394958496
Batch 57/64 loss: 1.9609594345092773
Batch 58/64 loss: 2.0196571350097656
Batch 59/64 loss: 1.7308921813964844
Batch 60/64 loss: 1.950223445892334
Batch 61/64 loss: 1.774125576019287
Batch 62/64 loss: 1.6644983291625977
Batch 63/64 loss: 1.6532707214355469
Batch 64/64 loss: -1.6613340377807617
Epoch 255  Train loss: 1.9772913801903818  Val loss: 1.5890508173257625
Epoch 256
-------------------------------
Batch 1/64 loss: 1.688115119934082
Batch 2/64 loss: 2.030831813812256
Batch 3/64 loss: 1.851914882659912
Batch 4/64 loss: 1.7443394660949707
Batch 5/64 loss: 1.6854948997497559
Batch 6/64 loss: 2.2322440147399902
Batch 7/64 loss: 1.9745688438415527
Batch 8/64 loss: 1.640368938446045
Batch 9/64 loss: 1.9154047966003418
Batch 10/64 loss: 1.789987564086914
Batch 11/64 loss: 1.7137351036071777
Batch 12/64 loss: 4.68490743637085
Batch 13/64 loss: 1.6768670082092285
Batch 14/64 loss: 1.6776843070983887
Batch 15/64 loss: 1.7616982460021973
Batch 16/64 loss: 1.922114372253418
Batch 17/64 loss: 1.6505780220031738
Batch 18/64 loss: 1.8627171516418457
Batch 19/64 loss: 1.7091174125671387
Batch 20/64 loss: 1.7063055038452148
Batch 21/64 loss: 1.864201545715332
Batch 22/64 loss: 1.7008366584777832
Batch 23/64 loss: 2.978090286254883
Batch 24/64 loss: 2.1746320724487305
Batch 25/64 loss: 1.7723207473754883
Batch 26/64 loss: 2.923642635345459
Batch 27/64 loss: 1.647172451019287
Batch 28/64 loss: 1.8129558563232422
Batch 29/64 loss: 2.0187973976135254
Batch 30/64 loss: 1.9135894775390625
Batch 31/64 loss: 1.67344331741333
Batch 32/64 loss: 1.7414703369140625
Batch 33/64 loss: 1.8062443733215332
Batch 34/64 loss: 2.295668601989746
Batch 35/64 loss: 2.00551176071167
Batch 36/64 loss: 1.8313560485839844
Batch 37/64 loss: 2.0141563415527344
Batch 38/64 loss: 1.925858974456787
Batch 39/64 loss: 1.7584643363952637
Batch 40/64 loss: 1.659583568572998
Batch 41/64 loss: 2.3234105110168457
Batch 42/64 loss: 2.7579445838928223
Batch 43/64 loss: 2.5848989486694336
Batch 44/64 loss: 1.807455062866211
Batch 45/64 loss: 1.7593927383422852
Batch 46/64 loss: 1.712782859802246
Batch 47/64 loss: 1.8176569938659668
Batch 48/64 loss: 1.7632999420166016
Batch 49/64 loss: 1.987330436706543
Batch 50/64 loss: 1.8830809593200684
Batch 51/64 loss: 3.010249614715576
Batch 52/64 loss: 1.7353882789611816
Batch 53/64 loss: 2.0038938522338867
Batch 54/64 loss: 1.90757417678833
Batch 55/64 loss: 1.7907028198242188
Batch 56/64 loss: 2.233635425567627
Batch 57/64 loss: 4.344539642333984
Batch 58/64 loss: 2.15708065032959
Batch 59/64 loss: 1.9510698318481445
Batch 60/64 loss: 2.23709774017334
Batch 61/64 loss: 2.0567994117736816
Batch 62/64 loss: 1.799145221710205
Batch 63/64 loss: 2.1778621673583984
Batch 64/64 loss: -1.632124900817871
Epoch 256  Train loss: 1.9923951354681277  Val loss: 1.9303386006568306
Epoch 257
-------------------------------
Batch 1/64 loss: 1.893777847290039
Batch 2/64 loss: 2.0197577476501465
Batch 3/64 loss: 2.4701528549194336
Batch 4/64 loss: 1.810605525970459
Batch 5/64 loss: 2.6324892044067383
Batch 6/64 loss: 1.988368034362793
Batch 7/64 loss: 1.990738868713379
Batch 8/64 loss: 2.104952812194824
Batch 9/64 loss: 1.8694138526916504
Batch 10/64 loss: 3.094156265258789
Batch 11/64 loss: 1.9157204627990723
Batch 12/64 loss: 2.00441312789917
Batch 13/64 loss: 1.941274642944336
Batch 14/64 loss: 1.8837389945983887
Batch 15/64 loss: 2.2682933807373047
Batch 16/64 loss: 4.306054592132568
Batch 17/64 loss: 1.9242863655090332
Batch 18/64 loss: 1.9924201965332031
Batch 19/64 loss: 2.7271337509155273
Batch 20/64 loss: 1.9103503227233887
Batch 21/64 loss: 1.9460773468017578
Batch 22/64 loss: 2.073486804962158
Batch 23/64 loss: 1.8205080032348633
Batch 24/64 loss: 1.6768560409545898
Batch 25/64 loss: 1.874955654144287
Batch 26/64 loss: 1.675628662109375
Batch 27/64 loss: 1.881235122680664
Batch 28/64 loss: 1.6436243057250977
Batch 29/64 loss: 2.2705135345458984
Batch 30/64 loss: 1.8013453483581543
Batch 31/64 loss: 1.9597382545471191
Batch 32/64 loss: 1.716470718383789
Batch 33/64 loss: 1.873610019683838
Batch 34/64 loss: 2.158346176147461
Batch 35/64 loss: 3.3324942588806152
Batch 36/64 loss: 2.2677674293518066
Batch 37/64 loss: 1.763535499572754
Batch 38/64 loss: 2.2052688598632812
Batch 39/64 loss: 1.994338035583496
Batch 40/64 loss: 1.8538756370544434
Batch 41/64 loss: 1.7942266464233398
Batch 42/64 loss: 1.7866430282592773
Batch 43/64 loss: 1.753303050994873
Batch 44/64 loss: 1.7592525482177734
Batch 45/64 loss: 2.63314151763916
Batch 46/64 loss: 5.204038619995117
Batch 47/64 loss: 1.7368526458740234
Batch 48/64 loss: 2.2953286170959473
Batch 49/64 loss: 2.925987720489502
Batch 50/64 loss: 1.9580268859863281
Batch 51/64 loss: 1.8559627532958984
Batch 52/64 loss: 1.8281383514404297
Batch 53/64 loss: 2.123399257659912
Batch 54/64 loss: 1.7732090950012207
Batch 55/64 loss: 4.93090295791626
Batch 56/64 loss: 1.8364782333374023
Batch 57/64 loss: 1.8963475227355957
Batch 58/64 loss: 1.7672152519226074
Batch 59/64 loss: 1.968160629272461
Batch 60/64 loss: 2.202632427215576
Batch 61/64 loss: 1.7979297637939453
Batch 62/64 loss: 1.734856128692627
Batch 63/64 loss: 1.7633075714111328
Batch 64/64 loss: -1.8155622482299805
Epoch 257  Train loss: 2.1098265741385664  Val loss: 1.6047242482503254
Epoch 258
-------------------------------
Batch 1/64 loss: 2.5203027725219727
Batch 2/64 loss: 1.763822078704834
Batch 3/64 loss: 1.7178096771240234
Batch 4/64 loss: 2.3069047927856445
Batch 5/64 loss: 1.8679652214050293
Batch 6/64 loss: 2.3332152366638184
Batch 7/64 loss: 2.4887890815734863
Batch 8/64 loss: 4.535453796386719
Batch 9/64 loss: 1.8560442924499512
Batch 10/64 loss: 2.8512697219848633
Batch 11/64 loss: 2.0225791931152344
Batch 12/64 loss: 1.6962103843688965
Batch 13/64 loss: 1.707343578338623
Batch 14/64 loss: 1.9732913970947266
Batch 15/64 loss: 1.7708024978637695
Batch 16/64 loss: 1.7415614128112793
Batch 17/64 loss: 1.7878665924072266
Batch 18/64 loss: 1.855541706085205
Batch 19/64 loss: 4.782642841339111
Batch 20/64 loss: 2.207249164581299
Batch 21/64 loss: 1.5829920768737793
Batch 22/64 loss: 2.036468029022217
Batch 23/64 loss: 1.6794838905334473
Batch 24/64 loss: 1.7247838973999023
Batch 25/64 loss: 1.787121295928955
Batch 26/64 loss: 1.8278069496154785
Batch 27/64 loss: 1.9926104545593262
Batch 28/64 loss: 1.7242765426635742
Batch 29/64 loss: 2.1475114822387695
Batch 30/64 loss: 3.211894989013672
Batch 31/64 loss: 2.0290136337280273
Batch 32/64 loss: 1.637895107269287
Batch 33/64 loss: 4.157351970672607
Batch 34/64 loss: 1.6957674026489258
Batch 35/64 loss: 2.120817184448242
Batch 36/64 loss: 1.6771888732910156
Batch 37/64 loss: 1.6749162673950195
Batch 38/64 loss: 2.6167101860046387
Batch 39/64 loss: 1.7841110229492188
Batch 40/64 loss: 1.6380062103271484
Batch 41/64 loss: 2.0205278396606445
Batch 42/64 loss: 1.7115612030029297
Batch 43/64 loss: 1.759413719177246
Batch 44/64 loss: 1.7507400512695312
Batch 45/64 loss: 1.7428984642028809
Batch 46/64 loss: 1.6663827896118164
Batch 47/64 loss: 2.016648292541504
Batch 48/64 loss: 1.8010544776916504
Batch 49/64 loss: 1.7659845352172852
Batch 50/64 loss: 2.4416370391845703
Batch 51/64 loss: 1.7687506675720215
Batch 52/64 loss: 2.110161781311035
Batch 53/64 loss: 1.827127456665039
Batch 54/64 loss: 1.7920594215393066
Batch 55/64 loss: 1.680619239807129
Batch 56/64 loss: 1.629106044769287
Batch 57/64 loss: 1.778515338897705
Batch 58/64 loss: 2.874011993408203
Batch 59/64 loss: 1.744710922241211
Batch 60/64 loss: 1.813310146331787
Batch 61/64 loss: 1.8185372352600098
Batch 62/64 loss: 1.8082146644592285
Batch 63/64 loss: 1.753772258758545
Batch 64/64 loss: -1.774825096130371
Epoch 258  Train loss: 2.0122042300654392  Val loss: 1.5571217749946307
Epoch 259
-------------------------------
Batch 1/64 loss: 1.7956104278564453
Batch 2/64 loss: 4.300872325897217
Batch 3/64 loss: 2.6751556396484375
Batch 4/64 loss: 1.9629411697387695
Batch 5/64 loss: 1.8082795143127441
Batch 6/64 loss: 1.7895550727844238
Batch 7/64 loss: 1.7622385025024414
Batch 8/64 loss: 1.6679248809814453
Batch 9/64 loss: 2.4308271408081055
Batch 10/64 loss: 1.726830005645752
Batch 11/64 loss: 2.234251022338867
Batch 12/64 loss: 1.9469823837280273
Batch 13/64 loss: 1.7599091529846191
Batch 14/64 loss: 1.8539695739746094
Batch 15/64 loss: 1.7106900215148926
Batch 16/64 loss: 1.7596282958984375
Batch 17/64 loss: 1.8202390670776367
Batch 18/64 loss: 1.778611183166504
Batch 19/64 loss: 1.7184600830078125
Batch 20/64 loss: 2.4301509857177734
Batch 21/64 loss: 5.090281009674072
Batch 22/64 loss: 1.852076530456543
Batch 23/64 loss: 1.6267895698547363
Batch 24/64 loss: 1.7505488395690918
Batch 25/64 loss: 2.2728028297424316
Batch 26/64 loss: 1.869603157043457
Batch 27/64 loss: 1.7359809875488281
Batch 28/64 loss: 1.8570966720581055
Batch 29/64 loss: 1.8372993469238281
Batch 30/64 loss: 2.2620177268981934
Batch 31/64 loss: 1.762514591217041
Batch 32/64 loss: 1.9365534782409668
Batch 33/64 loss: 1.9886054992675781
Batch 34/64 loss: 1.7052216529846191
Batch 35/64 loss: 1.8642477989196777
Batch 36/64 loss: 2.9361987113952637
Batch 37/64 loss: 1.5929198265075684
Batch 38/64 loss: 1.8596124649047852
Batch 39/64 loss: 2.01541805267334
Batch 40/64 loss: 2.0509862899780273
Batch 41/64 loss: 2.780240058898926
Batch 42/64 loss: 1.7815942764282227
Batch 43/64 loss: 1.9978361129760742
Batch 44/64 loss: 2.0065622329711914
Batch 45/64 loss: 1.7950186729431152
Batch 46/64 loss: 1.7770953178405762
Batch 47/64 loss: 2.567694664001465
Batch 48/64 loss: 1.946340560913086
Batch 49/64 loss: 1.6867661476135254
Batch 50/64 loss: 1.7692184448242188
Batch 51/64 loss: 4.8864827156066895
Batch 52/64 loss: 1.7949714660644531
Batch 53/64 loss: 1.729872703552246
Batch 54/64 loss: 1.6825904846191406
Batch 55/64 loss: 1.6984491348266602
Batch 56/64 loss: 1.7513909339904785
Batch 57/64 loss: 1.9799747467041016
Batch 58/64 loss: 1.9837069511413574
Batch 59/64 loss: 1.9755511283874512
Batch 60/64 loss: 1.9704065322875977
Batch 61/64 loss: 1.833662509918213
Batch 62/64 loss: 1.674208641052246
Batch 63/64 loss: 1.7417068481445312
Batch 64/64 loss: -1.6483840942382812
Epoch 259  Train loss: 2.0137247796152153  Val loss: 1.5371838336957688
Epoch 260
-------------------------------
Batch 1/64 loss: 1.7055144309997559
Batch 2/64 loss: 1.9698095321655273
Batch 3/64 loss: 1.8213882446289062
Batch 4/64 loss: 1.657057762145996
Batch 5/64 loss: 1.7740230560302734
Batch 6/64 loss: 1.6938977241516113
Batch 7/64 loss: 1.8873066902160645
Batch 8/64 loss: 2.9921326637268066
Batch 9/64 loss: 1.9553766250610352
Batch 10/64 loss: 1.8143548965454102
Batch 11/64 loss: 2.0371437072753906
Batch 12/64 loss: 1.7686500549316406
Batch 13/64 loss: 1.8066530227661133
Batch 14/64 loss: 1.7094974517822266
Batch 15/64 loss: 1.7729477882385254
Batch 16/64 loss: 1.8058476448059082
Batch 17/64 loss: 1.7317471504211426
Batch 18/64 loss: 1.7070598602294922
Batch 19/64 loss: 1.8635492324829102
Batch 20/64 loss: 2.1005043983459473
Batch 21/64 loss: 1.667668342590332
Batch 22/64 loss: 1.7863168716430664
Batch 23/64 loss: 1.8242087364196777
Batch 24/64 loss: 1.8025569915771484
Batch 25/64 loss: 1.8668999671936035
Batch 26/64 loss: 1.906721591949463
Batch 27/64 loss: 1.7190184593200684
Batch 28/64 loss: 1.881704330444336
Batch 29/64 loss: 1.944791316986084
Batch 30/64 loss: 1.763747215270996
Batch 31/64 loss: 1.8223061561584473
Batch 32/64 loss: 1.7358112335205078
Batch 33/64 loss: 1.7951011657714844
Batch 34/64 loss: 2.9725351333618164
Batch 35/64 loss: 1.8996219635009766
Batch 36/64 loss: 1.8284788131713867
Batch 37/64 loss: 3.8776917457580566
Batch 38/64 loss: 2.5571389198303223
Batch 39/64 loss: 1.809922218322754
Batch 40/64 loss: 1.7607717514038086
Batch 41/64 loss: 2.318790912628174
Batch 42/64 loss: 1.9984021186828613
Batch 43/64 loss: 1.9808001518249512
Batch 44/64 loss: 1.7365503311157227
Batch 45/64 loss: 1.7784266471862793
Batch 46/64 loss: 2.139638900756836
Batch 47/64 loss: 1.6889333724975586
Batch 48/64 loss: 1.8432612419128418
Batch 49/64 loss: 1.796328067779541
Batch 50/64 loss: 1.831984043121338
Batch 51/64 loss: 4.27222204208374
Batch 52/64 loss: 1.7480230331420898
Batch 53/64 loss: 1.8231334686279297
Batch 54/64 loss: 1.9733233451843262
Batch 55/64 loss: 1.7720484733581543
Batch 56/64 loss: 4.8187456130981445
Batch 57/64 loss: 1.7676057815551758
Batch 58/64 loss: 1.7798023223876953
Batch 59/64 loss: 1.8076186180114746
Batch 60/64 loss: 2.1089625358581543
Batch 61/64 loss: 1.7027158737182617
Batch 62/64 loss: 3.0166168212890625
Batch 63/64 loss: 1.7491588592529297
Batch 64/64 loss: -1.6150503158569336
Epoch 260  Train loss: 1.9770867403815775  Val loss: 1.5219163009800862
Epoch 261
-------------------------------
Batch 1/64 loss: 1.7613258361816406
Batch 2/64 loss: 1.7387752532958984
Batch 3/64 loss: 1.7571234703063965
Batch 4/64 loss: 1.7827658653259277
Batch 5/64 loss: 1.7871522903442383
Batch 6/64 loss: 1.78997802734375
Batch 7/64 loss: 1.8642334938049316
Batch 8/64 loss: 1.7999210357666016
Batch 9/64 loss: 2.5006542205810547
Batch 10/64 loss: 1.742302417755127
Batch 11/64 loss: 2.1400389671325684
Batch 12/64 loss: 1.7428197860717773
Batch 13/64 loss: 1.7660603523254395
Batch 14/64 loss: 1.8086872100830078
Batch 15/64 loss: 1.753349781036377
Batch 16/64 loss: 1.8712310791015625
Batch 17/64 loss: 1.9374160766601562
Batch 18/64 loss: 1.8576350212097168
Batch 19/64 loss: 1.6948323249816895
Batch 20/64 loss: 2.083773136138916
Batch 21/64 loss: 1.6917009353637695
Batch 22/64 loss: 1.7536334991455078
Batch 23/64 loss: 3.067744255065918
Batch 24/64 loss: 1.788078784942627
Batch 25/64 loss: 2.2488961219787598
Batch 26/64 loss: 2.0727477073669434
Batch 27/64 loss: 2.0150508880615234
Batch 28/64 loss: 1.7832975387573242
Batch 29/64 loss: 1.614020824432373
Batch 30/64 loss: 1.8603310585021973
Batch 31/64 loss: 1.7649235725402832
Batch 32/64 loss: 1.7414112091064453
Batch 33/64 loss: 2.611510753631592
Batch 34/64 loss: 1.7695937156677246
Batch 35/64 loss: 1.733116626739502
Batch 36/64 loss: 4.3754706382751465
Batch 37/64 loss: 1.8420982360839844
Batch 38/64 loss: 3.915055751800537
Batch 39/64 loss: 2.6380691528320312
Batch 40/64 loss: 1.725259780883789
Batch 41/64 loss: 1.7419285774230957
Batch 42/64 loss: 1.83528470993042
Batch 43/64 loss: 1.807664394378662
Batch 44/64 loss: 1.8431401252746582
Batch 45/64 loss: 1.6984167098999023
Batch 46/64 loss: 1.7246170043945312
Batch 47/64 loss: 1.8111162185668945
Batch 48/64 loss: 1.7671570777893066
Batch 49/64 loss: 4.774726390838623
Batch 50/64 loss: 1.7695536613464355
Batch 51/64 loss: 1.647348403930664
Batch 52/64 loss: 1.728360652923584
Batch 53/64 loss: 1.742417812347412
Batch 54/64 loss: 1.8488035202026367
Batch 55/64 loss: 1.8193397521972656
Batch 56/64 loss: 1.7951302528381348
Batch 57/64 loss: 1.6918730735778809
Batch 58/64 loss: 1.7805657386779785
Batch 59/64 loss: 1.875056266784668
Batch 60/64 loss: 2.745044708251953
Batch 61/64 loss: 2.046853542327881
Batch 62/64 loss: 1.8610467910766602
Batch 63/64 loss: 1.8242669105529785
Batch 64/64 loss: -1.7247200012207031
Epoch 261  Train loss: 1.962011905744964  Val loss: 1.548921945578454
Epoch 262
-------------------------------
Batch 1/64 loss: 1.7539138793945312
Batch 2/64 loss: 1.7383899688720703
Batch 3/64 loss: 1.663774013519287
Batch 4/64 loss: 1.735107421875
Batch 5/64 loss: 1.9520373344421387
Batch 6/64 loss: 1.8187966346740723
Batch 7/64 loss: 2.001068115234375
Batch 8/64 loss: 1.7109179496765137
Batch 9/64 loss: 1.713151454925537
Batch 10/64 loss: 1.823221206665039
Batch 11/64 loss: 1.7819757461547852
Batch 12/64 loss: 1.6517233848571777
Batch 13/64 loss: 1.7311534881591797
Batch 14/64 loss: 1.798393726348877
Batch 15/64 loss: 2.7581186294555664
Batch 16/64 loss: 1.6895551681518555
Batch 17/64 loss: 1.8002209663391113
Batch 18/64 loss: 1.8552665710449219
Batch 19/64 loss: 2.367603302001953
Batch 20/64 loss: 1.7106518745422363
Batch 21/64 loss: 1.7665939331054688
Batch 22/64 loss: 1.982771396636963
Batch 23/64 loss: 2.3026342391967773
Batch 24/64 loss: 1.5546112060546875
Batch 25/64 loss: 2.0009756088256836
Batch 26/64 loss: 1.7893457412719727
Batch 27/64 loss: 1.9188203811645508
Batch 28/64 loss: 2.022078037261963
Batch 29/64 loss: 1.8917856216430664
Batch 30/64 loss: 1.6437196731567383
Batch 31/64 loss: 1.721153736114502
Batch 32/64 loss: 1.855320930480957
Batch 33/64 loss: 1.991396427154541
Batch 34/64 loss: 1.753943920135498
Batch 35/64 loss: 4.050767421722412
Batch 36/64 loss: 1.7474331855773926
Batch 37/64 loss: 1.7613763809204102
Batch 38/64 loss: 1.7305874824523926
Batch 39/64 loss: 1.7108635902404785
Batch 40/64 loss: 1.8680996894836426
Batch 41/64 loss: 1.8032331466674805
Batch 42/64 loss: 1.669234275817871
Batch 43/64 loss: 1.8981432914733887
Batch 44/64 loss: 1.6978116035461426
Batch 45/64 loss: 1.8183550834655762
Batch 46/64 loss: 1.8367648124694824
Batch 47/64 loss: 1.8422765731811523
Batch 48/64 loss: 1.7893433570861816
Batch 49/64 loss: 1.6479134559631348
Batch 50/64 loss: 2.8832859992980957
Batch 51/64 loss: 1.984459400177002
Batch 52/64 loss: 4.928542613983154
Batch 53/64 loss: 1.7435822486877441
Batch 54/64 loss: 2.171320915222168
Batch 55/64 loss: 1.6248703002929688
Batch 56/64 loss: 1.8624095916748047
Batch 57/64 loss: 2.48748779296875
Batch 58/64 loss: 1.7810473442077637
Batch 59/64 loss: 4.1551008224487305
Batch 60/64 loss: 1.8386249542236328
Batch 61/64 loss: 1.6897087097167969
Batch 62/64 loss: 1.9398431777954102
Batch 63/64 loss: 1.741870403289795
Batch 64/64 loss: -1.6945953369140625
Epoch 262  Train loss: 1.9401349460377413  Val loss: 1.589590944375369
Epoch 263
-------------------------------
Batch 1/64 loss: 1.9582395553588867
Batch 2/64 loss: 1.66090726852417
Batch 3/64 loss: 1.7294158935546875
Batch 4/64 loss: 2.0811166763305664
Batch 5/64 loss: 2.358983039855957
Batch 6/64 loss: 1.8391437530517578
Batch 7/64 loss: 1.7535600662231445
Batch 8/64 loss: 1.7138123512268066
Batch 9/64 loss: 1.7375402450561523
Batch 10/64 loss: 4.011053562164307
Batch 11/64 loss: 1.8773694038391113
Batch 12/64 loss: 2.022883415222168
Batch 13/64 loss: 1.8515524864196777
Batch 14/64 loss: 1.9995923042297363
Batch 15/64 loss: 2.655350685119629
Batch 16/64 loss: 1.822805404663086
Batch 17/64 loss: 2.3591156005859375
Batch 18/64 loss: 1.9779644012451172
Batch 19/64 loss: 1.823784351348877
Batch 20/64 loss: 2.070958137512207
Batch 21/64 loss: 2.2985615730285645
Batch 22/64 loss: 1.7283382415771484
Batch 23/64 loss: 4.134527683258057
Batch 24/64 loss: 1.7165513038635254
Batch 25/64 loss: 2.2041563987731934
Batch 26/64 loss: 1.7395458221435547
Batch 27/64 loss: 1.9020423889160156
Batch 28/64 loss: 1.884683609008789
Batch 29/64 loss: 1.9393291473388672
Batch 30/64 loss: 1.8188867568969727
Batch 31/64 loss: 1.7298312187194824
Batch 32/64 loss: 1.9281907081604004
Batch 33/64 loss: 1.6486883163452148
Batch 34/64 loss: 1.7372655868530273
Batch 35/64 loss: 1.8961048126220703
Batch 36/64 loss: 1.7819104194641113
Batch 37/64 loss: 2.291436195373535
Batch 38/64 loss: 1.8305583000183105
Batch 39/64 loss: 1.9442644119262695
Batch 40/64 loss: 1.9751949310302734
Batch 41/64 loss: 4.577147960662842
Batch 42/64 loss: 1.9787073135375977
Batch 43/64 loss: 1.6918392181396484
Batch 44/64 loss: 2.025195598602295
Batch 45/64 loss: 2.781663417816162
Batch 46/64 loss: 1.913576602935791
Batch 47/64 loss: 2.7413015365600586
Batch 48/64 loss: 1.7289624214172363
Batch 49/64 loss: 2.064910888671875
Batch 50/64 loss: 1.653214454650879
Batch 51/64 loss: 1.9221253395080566
Batch 52/64 loss: 1.6988439559936523
Batch 53/64 loss: 1.6865849494934082
Batch 54/64 loss: 1.9503521919250488
Batch 55/64 loss: 1.6352777481079102
Batch 56/64 loss: 1.9382085800170898
Batch 57/64 loss: 1.8446950912475586
Batch 58/64 loss: 1.7299952507019043
Batch 59/64 loss: 1.8658690452575684
Batch 60/64 loss: 1.629826545715332
Batch 61/64 loss: 1.8037972450256348
Batch 62/64 loss: 1.8725957870483398
Batch 63/64 loss: 1.8049182891845703
Batch 64/64 loss: -1.6336488723754883
Epoch 263  Train loss: 1.9882288502711876  Val loss: 1.5214086971741771
Epoch 264
-------------------------------
Batch 1/64 loss: 1.7497568130493164
Batch 2/64 loss: 1.8452377319335938
Batch 3/64 loss: 1.6843104362487793
Batch 4/64 loss: 1.8370208740234375
Batch 5/64 loss: 1.6343512535095215
Batch 6/64 loss: 2.6380414962768555
Batch 7/64 loss: 1.9413318634033203
Batch 8/64 loss: 2.0743141174316406
Batch 9/64 loss: 1.7175025939941406
Batch 10/64 loss: 1.7339763641357422
Batch 11/64 loss: 1.7867746353149414
Batch 12/64 loss: 1.8851547241210938
Batch 13/64 loss: 1.9512648582458496
Batch 14/64 loss: 3.8486971855163574
Batch 15/64 loss: 1.9206137657165527
Batch 16/64 loss: 1.966287612915039
Batch 17/64 loss: 2.1007843017578125
Batch 18/64 loss: 1.6306710243225098
Batch 19/64 loss: 1.813187599182129
Batch 20/64 loss: 1.729907512664795
Batch 21/64 loss: 2.284945487976074
Batch 22/64 loss: 1.860112190246582
Batch 23/64 loss: 1.6614408493041992
Batch 24/64 loss: 1.7075843811035156
Batch 25/64 loss: 1.7022314071655273
Batch 26/64 loss: 1.8817181587219238
Batch 27/64 loss: 1.8590502738952637
Batch 28/64 loss: 1.887732982635498
Batch 29/64 loss: 4.699100494384766
Batch 30/64 loss: 1.9250383377075195
Batch 31/64 loss: 1.895951747894287
Batch 32/64 loss: 1.6698870658874512
Batch 33/64 loss: 1.7178969383239746
Batch 34/64 loss: 1.749405860900879
Batch 35/64 loss: 1.8705568313598633
Batch 36/64 loss: 1.7434215545654297
Batch 37/64 loss: 1.694183349609375
Batch 38/64 loss: 2.227151870727539
Batch 39/64 loss: 1.7975192070007324
Batch 40/64 loss: 1.8643126487731934
Batch 41/64 loss: 4.3354902267456055
Batch 42/64 loss: 1.6787891387939453
Batch 43/64 loss: 2.0632944107055664
Batch 44/64 loss: 1.7610902786254883
Batch 45/64 loss: 2.586207389831543
Batch 46/64 loss: 1.7182812690734863
Batch 47/64 loss: 1.7612743377685547
Batch 48/64 loss: 1.9866347312927246
Batch 49/64 loss: 1.6035957336425781
Batch 50/64 loss: 1.6585431098937988
Batch 51/64 loss: 2.2705583572387695
Batch 52/64 loss: 1.751448631286621
Batch 53/64 loss: 1.8299059867858887
Batch 54/64 loss: 1.683915138244629
Batch 55/64 loss: 1.7714061737060547
Batch 56/64 loss: 2.8567795753479004
Batch 57/64 loss: 2.0609612464904785
Batch 58/64 loss: 1.7984418869018555
Batch 59/64 loss: 2.4151835441589355
Batch 60/64 loss: 1.7972841262817383
Batch 61/64 loss: 1.854548454284668
Batch 62/64 loss: 1.9197278022766113
Batch 63/64 loss: 1.7653284072875977
Batch 64/64 loss: -1.0918340682983398
Epoch 264  Train loss: 1.9654626322727577  Val loss: 1.5743650062796997
Epoch 265
-------------------------------
Batch 1/64 loss: 2.37001895904541
Batch 2/64 loss: 4.168200492858887
Batch 3/64 loss: 1.8338394165039062
Batch 4/64 loss: 1.7402992248535156
Batch 5/64 loss: 1.815971851348877
Batch 6/64 loss: 1.9474444389343262
Batch 7/64 loss: 2.507232189178467
Batch 8/64 loss: 1.6428446769714355
Batch 9/64 loss: 1.7870969772338867
Batch 10/64 loss: 4.5583319664001465
Batch 11/64 loss: 1.8925046920776367
Batch 12/64 loss: 1.9931674003601074
Batch 13/64 loss: 1.7034850120544434
Batch 14/64 loss: 1.7603626251220703
Batch 15/64 loss: 1.8650670051574707
Batch 16/64 loss: 1.8974919319152832
Batch 17/64 loss: 1.7053518295288086
Batch 18/64 loss: 1.7540321350097656
Batch 19/64 loss: 1.952817440032959
Batch 20/64 loss: 1.679548740386963
Batch 21/64 loss: 1.6764163970947266
Batch 22/64 loss: 1.7408843040466309
Batch 23/64 loss: 2.28446102142334
Batch 24/64 loss: 2.495108127593994
Batch 25/64 loss: 1.890702247619629
Batch 26/64 loss: 1.8792595863342285
Batch 27/64 loss: 2.8014330863952637
Batch 28/64 loss: 1.749952793121338
Batch 29/64 loss: 2.108372211456299
Batch 30/64 loss: 1.6915388107299805
Batch 31/64 loss: 1.65803861618042
Batch 32/64 loss: 1.7335195541381836
Batch 33/64 loss: 1.7175683975219727
Batch 34/64 loss: 1.800560474395752
Batch 35/64 loss: 1.6680707931518555
Batch 36/64 loss: 1.878035068511963
Batch 37/64 loss: 1.659390926361084
Batch 38/64 loss: 2.38564395904541
Batch 39/64 loss: 1.855010986328125
Batch 40/64 loss: 1.9925403594970703
Batch 41/64 loss: 1.9926676750183105
Batch 42/64 loss: 2.355903148651123
Batch 43/64 loss: 3.774301052093506
Batch 44/64 loss: 3.3765368461608887
Batch 45/64 loss: 2.3028922080993652
Batch 46/64 loss: 2.6269054412841797
Batch 47/64 loss: 2.6474852561950684
Batch 48/64 loss: 2.7080321311950684
Batch 49/64 loss: 2.6551647186279297
Batch 50/64 loss: 4.300487041473389
Batch 51/64 loss: 2.9909911155700684
Batch 52/64 loss: 2.023787021636963
Batch 53/64 loss: 2.6959824562072754
Batch 54/64 loss: 5.785337924957275
Batch 55/64 loss: 2.357715606689453
Batch 56/64 loss: 2.684072971343994
Batch 57/64 loss: 3.5735549926757812
Batch 58/64 loss: 3.1161742210388184
Batch 59/64 loss: 2.15681791305542
Batch 60/64 loss: 2.938542366027832
Batch 61/64 loss: 2.4128003120422363
Batch 62/64 loss: 2.6824493408203125
Batch 63/64 loss: 2.2746753692626953
Batch 64/64 loss: -0.8994407653808594
Epoch 265  Train loss: 2.3058872671688304  Val loss: 2.6576579641230738
Epoch 266
-------------------------------
Batch 1/64 loss: 3.237901210784912
Batch 2/64 loss: 2.535459041595459
Batch 3/64 loss: 5.041077613830566
Batch 4/64 loss: 2.297332763671875
Batch 5/64 loss: 2.854912757873535
Batch 6/64 loss: 2.8695931434631348
Batch 7/64 loss: 2.545677661895752
Batch 8/64 loss: 2.1844868659973145
Batch 9/64 loss: 3.535055160522461
Batch 10/64 loss: 5.026423931121826
Batch 11/64 loss: 2.111269474029541
Batch 12/64 loss: 2.0524277687072754
Batch 13/64 loss: 2.411489963531494
Batch 14/64 loss: 2.3444018363952637
Batch 15/64 loss: 2.1730966567993164
Batch 16/64 loss: 1.8704438209533691
Batch 17/64 loss: 2.033900260925293
Batch 18/64 loss: 2.130725860595703
Batch 19/64 loss: 3.5942230224609375
Batch 20/64 loss: 3.040717124938965
Batch 21/64 loss: 2.422133445739746
Batch 22/64 loss: 1.823735237121582
Batch 23/64 loss: 4.177548885345459
Batch 24/64 loss: 2.0190815925598145
Batch 25/64 loss: 2.2806239128112793
Batch 26/64 loss: 2.151503086090088
Batch 27/64 loss: 2.303384304046631
Batch 28/64 loss: 2.5088672637939453
Batch 29/64 loss: 2.3140511512756348
Batch 30/64 loss: 1.9231061935424805
Batch 31/64 loss: 1.9012346267700195
Batch 32/64 loss: 2.783902645111084
Batch 33/64 loss: 2.0943336486816406
Batch 34/64 loss: 2.041100025177002
Batch 35/64 loss: 1.991605281829834
Batch 36/64 loss: 1.855165958404541
Batch 37/64 loss: 2.106505870819092
Batch 38/64 loss: 2.172579288482666
Batch 39/64 loss: 2.0637660026550293
Batch 40/64 loss: 1.8553080558776855
Batch 41/64 loss: 3.9938745498657227
Batch 42/64 loss: 2.378645896911621
Batch 43/64 loss: 1.74723482131958
Batch 44/64 loss: 1.9195680618286133
Batch 45/64 loss: 2.166635513305664
Batch 46/64 loss: 4.440666675567627
Batch 47/64 loss: 1.9294114112854004
Batch 48/64 loss: 1.865567684173584
Batch 49/64 loss: 2.97346830368042
Batch 50/64 loss: 1.8868379592895508
Batch 51/64 loss: 1.9279966354370117
Batch 52/64 loss: 1.9392709732055664
Batch 53/64 loss: 1.7717151641845703
Batch 54/64 loss: 1.6870994567871094
Batch 55/64 loss: 1.8802366256713867
Batch 56/64 loss: 1.8463592529296875
Batch 57/64 loss: 2.027433395385742
Batch 58/64 loss: 1.8355302810668945
Batch 59/64 loss: 2.7361669540405273
Batch 60/64 loss: 1.7826032638549805
Batch 61/64 loss: 2.1434693336486816
Batch 62/64 loss: 1.8361783027648926
Batch 63/64 loss: 1.796034812927246
Batch 64/64 loss: -1.4713811874389648
Epoch 266  Train loss: 2.3543313232122682  Val loss: 1.7984573849288048
Epoch 267
-------------------------------
Batch 1/64 loss: 1.8862419128417969
Batch 2/64 loss: 1.8148870468139648
Batch 3/64 loss: 2.2799692153930664
Batch 4/64 loss: 1.7799839973449707
Batch 5/64 loss: 2.1400704383850098
Batch 6/64 loss: 1.7703313827514648
Batch 7/64 loss: 1.9324913024902344
Batch 8/64 loss: 2.7930049896240234
Batch 9/64 loss: 1.760119915008545
Batch 10/64 loss: 2.8945560455322266
Batch 11/64 loss: 1.8212928771972656
Batch 12/64 loss: 1.8230514526367188
Batch 13/64 loss: 1.896627426147461
Batch 14/64 loss: 2.09590482711792
Batch 15/64 loss: 2.9700584411621094
Batch 16/64 loss: 1.8811736106872559
Batch 17/64 loss: 1.9450697898864746
Batch 18/64 loss: 1.763235092163086
Batch 19/64 loss: 2.004007339477539
Batch 20/64 loss: 1.776747703552246
Batch 21/64 loss: 2.163100242614746
Batch 22/64 loss: 1.7838058471679688
Batch 23/64 loss: 1.737309455871582
Batch 24/64 loss: 1.9334936141967773
Batch 25/64 loss: 1.7961459159851074
Batch 26/64 loss: 2.020421028137207
Batch 27/64 loss: 2.287137031555176
Batch 28/64 loss: 1.8193235397338867
Batch 29/64 loss: 5.2863569259643555
Batch 30/64 loss: 1.8425626754760742
Batch 31/64 loss: 1.8680434226989746
Batch 32/64 loss: 2.0286707878112793
Batch 33/64 loss: 2.5664405822753906
Batch 34/64 loss: 1.7815189361572266
Batch 35/64 loss: 2.0413174629211426
Batch 36/64 loss: 1.8219289779663086
Batch 37/64 loss: 2.0336413383483887
Batch 38/64 loss: 2.399172306060791
Batch 39/64 loss: 2.100414752960205
Batch 40/64 loss: 1.7820062637329102
Batch 41/64 loss: 1.8322181701660156
Batch 42/64 loss: 2.432957172393799
Batch 43/64 loss: 2.2179064750671387
Batch 44/64 loss: 1.8012819290161133
Batch 45/64 loss: 1.8178205490112305
Batch 46/64 loss: 2.551215648651123
Batch 47/64 loss: 1.7843871116638184
Batch 48/64 loss: 1.8577113151550293
Batch 49/64 loss: 2.084517002105713
Batch 50/64 loss: 4.3218536376953125
Batch 51/64 loss: 1.7749180793762207
Batch 52/64 loss: 4.096857070922852
Batch 53/64 loss: 1.9753761291503906
Batch 54/64 loss: 1.973862648010254
Batch 55/64 loss: 1.8196730613708496
Batch 56/64 loss: 2.040444850921631
Batch 57/64 loss: 2.6808009147644043
Batch 58/64 loss: 1.958643913269043
Batch 59/64 loss: 1.7249035835266113
Batch 60/64 loss: 1.7956137657165527
Batch 61/64 loss: 1.98569917678833
Batch 62/64 loss: 1.7652587890625
Batch 63/64 loss: 1.8927531242370605
Batch 64/64 loss: -1.6468610763549805
Epoch 267  Train loss: 2.0874221839156806  Val loss: 1.6780638875010907
Epoch 268
-------------------------------
Batch 1/64 loss: 2.582611083984375
Batch 2/64 loss: 1.8461308479309082
Batch 3/64 loss: 2.0919437408447266
Batch 4/64 loss: 1.9489192962646484
Batch 5/64 loss: 1.7248549461364746
Batch 6/64 loss: 1.806236743927002
Batch 7/64 loss: 1.8242688179016113
Batch 8/64 loss: 1.784226417541504
Batch 9/64 loss: 1.8540077209472656
Batch 10/64 loss: 2.417105197906494
Batch 11/64 loss: 1.7601675987243652
Batch 12/64 loss: 1.7094430923461914
Batch 13/64 loss: 1.8406882286071777
Batch 14/64 loss: 1.8670554161071777
Batch 15/64 loss: 4.1512770652771
Batch 16/64 loss: 1.8056635856628418
Batch 17/64 loss: 1.7137870788574219
Batch 18/64 loss: 1.8394184112548828
Batch 19/64 loss: 2.0469346046447754
Batch 20/64 loss: 1.9146714210510254
Batch 21/64 loss: 1.690413475036621
Batch 22/64 loss: 1.9186358451843262
Batch 23/64 loss: 1.8584613800048828
Batch 24/64 loss: 1.842268466949463
Batch 25/64 loss: 1.667593002319336
Batch 26/64 loss: 1.7772884368896484
Batch 27/64 loss: 1.8194880485534668
Batch 28/64 loss: 1.9870100021362305
Batch 29/64 loss: 1.6982083320617676
Batch 30/64 loss: 1.99479341506958
Batch 31/64 loss: 1.7477507591247559
Batch 32/64 loss: 1.8157496452331543
Batch 33/64 loss: 1.652848720550537
Batch 34/64 loss: 1.913590908050537
Batch 35/64 loss: 1.789797306060791
Batch 36/64 loss: 1.9013285636901855
Batch 37/64 loss: 1.9480228424072266
Batch 38/64 loss: 2.1336355209350586
Batch 39/64 loss: 1.8497099876403809
Batch 40/64 loss: 1.9545507431030273
Batch 41/64 loss: 1.9208483695983887
Batch 42/64 loss: 1.8916692733764648
Batch 43/64 loss: 1.8288674354553223
Batch 44/64 loss: 1.7488775253295898
Batch 45/64 loss: 2.4835634231567383
Batch 46/64 loss: 1.7585039138793945
Batch 47/64 loss: 1.728797435760498
Batch 48/64 loss: 6.539259910583496
Batch 49/64 loss: 1.7524709701538086
Batch 50/64 loss: 1.7779297828674316
Batch 51/64 loss: 1.7199163436889648
Batch 52/64 loss: 1.704568862915039
Batch 53/64 loss: 1.9946608543395996
Batch 54/64 loss: 1.7478275299072266
Batch 55/64 loss: 1.8356232643127441
Batch 56/64 loss: 1.7115478515625
Batch 57/64 loss: 2.2238097190856934
Batch 58/64 loss: 2.0060219764709473
Batch 59/64 loss: 3.9450936317443848
Batch 60/64 loss: 1.9148750305175781
Batch 61/64 loss: 3.0751419067382812
Batch 62/64 loss: 2.1115150451660156
Batch 63/64 loss: 1.7569031715393066
Batch 64/64 loss: -1.6253604888916016
Epoch 268  Train loss: 1.9992130129945045  Val loss: 1.5985608576089656
Epoch 269
-------------------------------
Batch 1/64 loss: 1.82942533493042
Batch 2/64 loss: 1.8783068656921387
Batch 3/64 loss: 1.8538894653320312
Batch 4/64 loss: 1.977386474609375
Batch 5/64 loss: 1.6584272384643555
Batch 6/64 loss: 1.6877803802490234
Batch 7/64 loss: 2.0319418907165527
Batch 8/64 loss: 1.82249116897583
Batch 9/64 loss: 1.7493200302124023
Batch 10/64 loss: 1.7522969245910645
Batch 11/64 loss: 1.669060230255127
Batch 12/64 loss: 1.6652603149414062
Batch 13/64 loss: 1.977552890777588
Batch 14/64 loss: 3.566394805908203
Batch 15/64 loss: 2.010509967803955
Batch 16/64 loss: 2.333169460296631
Batch 17/64 loss: 2.3379573822021484
Batch 18/64 loss: 2.2687292098999023
Batch 19/64 loss: 3.0092177391052246
Batch 20/64 loss: 2.566211223602295
Batch 21/64 loss: 3.691875457763672
Batch 22/64 loss: 2.854095935821533
Batch 23/64 loss: 2.5612940788269043
Batch 24/64 loss: 3.1758875846862793
Batch 25/64 loss: 2.6563687324523926
Batch 26/64 loss: 3.727097511291504
Batch 27/64 loss: 2.653160572052002
Batch 28/64 loss: 2.6919713020324707
Batch 29/64 loss: 2.908285617828369
Batch 30/64 loss: 2.412938117980957
Batch 31/64 loss: 3.978787899017334
Batch 32/64 loss: 2.9799771308898926
Batch 33/64 loss: 3.9586663246154785
Batch 34/64 loss: 2.4452576637268066
Batch 35/64 loss: 2.3747072219848633
Batch 36/64 loss: 2.7454285621643066
Batch 37/64 loss: 2.983854293823242
Batch 38/64 loss: 2.444777488708496
Batch 39/64 loss: 2.116881847381592
Batch 40/64 loss: 2.7614874839782715
Batch 41/64 loss: 2.687490463256836
Batch 42/64 loss: 2.813364028930664
Batch 43/64 loss: 2.3633880615234375
Batch 44/64 loss: 2.49397611618042
Batch 45/64 loss: 2.171182632446289
Batch 46/64 loss: 2.4001259803771973
Batch 47/64 loss: 2.170314311981201
Batch 48/64 loss: 2.16641902923584
Batch 49/64 loss: 2.824268341064453
Batch 50/64 loss: 3.035632610321045
Batch 51/64 loss: 2.0222835540771484
Batch 52/64 loss: 2.395390510559082
Batch 53/64 loss: 4.638350963592529
Batch 54/64 loss: 2.6033501625061035
Batch 55/64 loss: 2.349822998046875
Batch 56/64 loss: 5.244811534881592
Batch 57/64 loss: 3.3951268196105957
Batch 58/64 loss: 3.032332420349121
Batch 59/64 loss: 2.025639533996582
Batch 60/64 loss: 2.1106858253479004
Batch 61/64 loss: 2.1808667182922363
Batch 62/64 loss: 2.365428924560547
Batch 63/64 loss: 2.252425193786621
Batch 64/64 loss: -1.1818838119506836
Epoch 269  Train loss: 2.519598332573386  Val loss: 2.0758927466533437
Epoch 270
-------------------------------
Batch 1/64 loss: 2.0004448890686035
Batch 2/64 loss: 2.7054662704467773
Batch 3/64 loss: 3.6577811241149902
Batch 4/64 loss: 1.8982353210449219
Batch 5/64 loss: 2.473940849304199
Batch 6/64 loss: 1.9472074508666992
Batch 7/64 loss: 2.5191378593444824
Batch 8/64 loss: 1.9875836372375488
Batch 9/64 loss: 2.383316993713379
Batch 10/64 loss: 1.9857988357543945
Batch 11/64 loss: 2.027912139892578
Batch 12/64 loss: 2.184922695159912
Batch 13/64 loss: 1.9498686790466309
Batch 14/64 loss: 1.900301456451416
Batch 15/64 loss: 2.077056884765625
Batch 16/64 loss: 1.983532428741455
Batch 17/64 loss: 1.9884848594665527
Batch 18/64 loss: 1.9915118217468262
Batch 19/64 loss: 1.7999820709228516
Batch 20/64 loss: 2.1399130821228027
Batch 21/64 loss: 2.063411235809326
Batch 22/64 loss: 1.9662084579467773
Batch 23/64 loss: 1.8821163177490234
Batch 24/64 loss: 2.0028529167175293
Batch 25/64 loss: 2.2913146018981934
Batch 26/64 loss: 1.983187198638916
Batch 27/64 loss: 4.1715006828308105
Batch 28/64 loss: 2.1831064224243164
Batch 29/64 loss: 2.200631618499756
Batch 30/64 loss: 2.30133056640625
Batch 31/64 loss: 3.100236415863037
Batch 32/64 loss: 2.121072769165039
Batch 33/64 loss: 2.0407347679138184
Batch 34/64 loss: 2.116213798522949
Batch 35/64 loss: 1.9036297798156738
Batch 36/64 loss: 1.890946388244629
Batch 37/64 loss: 2.1577835083007812
Batch 38/64 loss: 1.9559545516967773
Batch 39/64 loss: 2.4180502891540527
Batch 40/64 loss: 2.0355725288391113
Batch 41/64 loss: 1.966324806213379
Batch 42/64 loss: 2.202882766723633
Batch 43/64 loss: 1.8915901184082031
Batch 44/64 loss: 1.9253416061401367
Batch 45/64 loss: 2.655752658843994
Batch 46/64 loss: 3.0171403884887695
Batch 47/64 loss: 1.943962574005127
Batch 48/64 loss: 1.7500901222229004
Batch 49/64 loss: 1.9042291641235352
Batch 50/64 loss: 2.1627726554870605
Batch 51/64 loss: 2.3358969688415527
Batch 52/64 loss: 2.097931385040283
Batch 53/64 loss: 1.9291033744812012
Batch 54/64 loss: 4.269796848297119
Batch 55/64 loss: 2.237485408782959
Batch 56/64 loss: 1.8771190643310547
Batch 57/64 loss: 1.8493924140930176
Batch 58/64 loss: 5.3535475730896
Batch 59/64 loss: 1.9439644813537598
Batch 60/64 loss: 2.017971992492676
Batch 61/64 loss: 1.8623170852661133
Batch 62/64 loss: 1.8967280387878418
Batch 63/64 loss: 1.8067560195922852
Batch 64/64 loss: -1.1087541580200195
Epoch 270  Train loss: 2.2032123303880877  Val loss: 1.6405407096102476
Epoch 271
-------------------------------
Batch 1/64 loss: 1.8978796005249023
Batch 2/64 loss: 1.7510762214660645
Batch 3/64 loss: 2.152918815612793
Batch 4/64 loss: 2.4489879608154297
Batch 5/64 loss: 2.6566853523254395
Batch 6/64 loss: 1.9284920692443848
Batch 7/64 loss: 2.063019275665283
Batch 8/64 loss: 1.80509614944458
Batch 9/64 loss: 1.7885289192199707
Batch 10/64 loss: 3.0752553939819336
Batch 11/64 loss: 1.8971443176269531
Batch 12/64 loss: 1.9400439262390137
Batch 13/64 loss: 1.7392292022705078
Batch 14/64 loss: 2.3999314308166504
Batch 15/64 loss: 2.1172776222229004
Batch 16/64 loss: 1.8917121887207031
Batch 17/64 loss: 1.7892704010009766
Batch 18/64 loss: 1.9752559661865234
Batch 19/64 loss: 2.462385654449463
Batch 20/64 loss: 1.9978241920471191
Batch 21/64 loss: 1.709911823272705
Batch 22/64 loss: 4.008193016052246
Batch 23/64 loss: 2.0307044982910156
Batch 24/64 loss: 1.7868595123291016
Batch 25/64 loss: 2.0382018089294434
Batch 26/64 loss: 1.8504929542541504
Batch 27/64 loss: 2.026216983795166
Batch 28/64 loss: 1.938368797302246
Batch 29/64 loss: 2.0961642265319824
Batch 30/64 loss: 1.8230853080749512
Batch 31/64 loss: 1.9431605339050293
Batch 32/64 loss: 6.65119743347168
Batch 33/64 loss: 1.8309974670410156
Batch 34/64 loss: 1.8713741302490234
Batch 35/64 loss: 1.9138355255126953
Batch 36/64 loss: 1.9794011116027832
Batch 37/64 loss: 1.8857994079589844
Batch 38/64 loss: 1.987940788269043
Batch 39/64 loss: 1.8130311965942383
Batch 40/64 loss: 2.156444549560547
Batch 41/64 loss: 1.8484911918640137
Batch 42/64 loss: 1.6957573890686035
Batch 43/64 loss: 1.888634204864502
Batch 44/64 loss: 3.1836071014404297
Batch 45/64 loss: 1.7311434745788574
Batch 46/64 loss: 1.8245434761047363
Batch 47/64 loss: 1.7490696907043457
Batch 48/64 loss: 1.8719401359558105
Batch 49/64 loss: 2.2609777450561523
Batch 50/64 loss: 1.8596034049987793
Batch 51/64 loss: 1.769606590270996
Batch 52/64 loss: 2.055602550506592
Batch 53/64 loss: 1.6758456230163574
Batch 54/64 loss: 1.834902286529541
Batch 55/64 loss: 1.9191298484802246
Batch 56/64 loss: 2.0381455421447754
Batch 57/64 loss: 1.7577409744262695
Batch 58/64 loss: 1.803725242614746
Batch 59/64 loss: 1.8407602310180664
Batch 60/64 loss: 1.9097814559936523
Batch 61/64 loss: 1.8459196090698242
Batch 62/64 loss: 2.0893497467041016
Batch 63/64 loss: 2.0350022315979004
Batch 64/64 loss: -1.663717269897461
Epoch 271  Train loss: 2.044876667097503  Val loss: 1.5910642499366576
Epoch 272
-------------------------------
Batch 1/64 loss: 1.9092116355895996
Batch 2/64 loss: 1.9445219039916992
Batch 3/64 loss: 1.9771618843078613
Batch 4/64 loss: 1.985391616821289
Batch 5/64 loss: 1.8738360404968262
Batch 6/64 loss: 1.8256945610046387
Batch 7/64 loss: 1.8082304000854492
Batch 8/64 loss: 4.95224666595459
Batch 9/64 loss: 1.7824134826660156
Batch 10/64 loss: 4.165719032287598
Batch 11/64 loss: 1.8999443054199219
Batch 12/64 loss: 1.7729511260986328
Batch 13/64 loss: 1.7889342308044434
Batch 14/64 loss: 1.7817177772521973
Batch 15/64 loss: 1.829906940460205
Batch 16/64 loss: 2.84346866607666
Batch 17/64 loss: 1.8931326866149902
Batch 18/64 loss: 2.18760347366333
Batch 19/64 loss: 1.7471442222595215
Batch 20/64 loss: 1.6721091270446777
Batch 21/64 loss: 1.8239622116088867
Batch 22/64 loss: 1.802565097808838
Batch 23/64 loss: 1.6953320503234863
Batch 24/64 loss: 1.7039752006530762
Batch 25/64 loss: 2.0799598693847656
Batch 26/64 loss: 1.7271037101745605
Batch 27/64 loss: 3.0392160415649414
Batch 28/64 loss: 1.7536144256591797
Batch 29/64 loss: 1.8559021949768066
Batch 30/64 loss: 1.8802947998046875
Batch 31/64 loss: 4.07098388671875
Batch 32/64 loss: 1.8028388023376465
Batch 33/64 loss: 1.723060131072998
Batch 34/64 loss: 1.892735481262207
Batch 35/64 loss: 1.6594300270080566
Batch 36/64 loss: 1.7855424880981445
Batch 37/64 loss: 2.513874053955078
Batch 38/64 loss: 1.8287510871887207
Batch 39/64 loss: 2.1038527488708496
Batch 40/64 loss: 2.40336275100708
Batch 41/64 loss: 2.273505687713623
Batch 42/64 loss: 1.7479267120361328
Batch 43/64 loss: 1.911008358001709
Batch 44/64 loss: 3.020287036895752
Batch 45/64 loss: 1.7951593399047852
Batch 46/64 loss: 1.8456573486328125
Batch 47/64 loss: 1.7367196083068848
Batch 48/64 loss: 1.9281902313232422
Batch 49/64 loss: 1.8852043151855469
Batch 50/64 loss: 1.8864951133728027
Batch 51/64 loss: 1.7626514434814453
Batch 52/64 loss: 1.600881576538086
Batch 53/64 loss: 1.6788101196289062
Batch 54/64 loss: 1.7228193283081055
Batch 55/64 loss: 2.0020689964294434
Batch 56/64 loss: 1.6982512474060059
Batch 57/64 loss: 1.6627345085144043
Batch 58/64 loss: 1.722785472869873
Batch 59/64 loss: 1.749185562133789
Batch 60/64 loss: 2.5137791633605957
Batch 61/64 loss: 1.8210339546203613
Batch 62/64 loss: 1.8205089569091797
Batch 63/64 loss: 1.9910240173339844
Batch 64/64 loss: -1.7551441192626953
Epoch 272  Train loss: 1.9960474799661074  Val loss: 1.529556051562332
Epoch 273
-------------------------------
Batch 1/64 loss: 1.6699705123901367
Batch 2/64 loss: 2.0143322944641113
Batch 3/64 loss: 1.8551292419433594
Batch 4/64 loss: 1.7859525680541992
Batch 5/64 loss: 4.131505012512207
Batch 6/64 loss: 2.33444881439209
Batch 7/64 loss: 2.329486846923828
Batch 8/64 loss: 1.8395195007324219
Batch 9/64 loss: 2.4819998741149902
Batch 10/64 loss: 1.9121313095092773
Batch 11/64 loss: 2.0789794921875
Batch 12/64 loss: 2.108048439025879
Batch 13/64 loss: 1.7973337173461914
Batch 14/64 loss: 2.214219570159912
Batch 15/64 loss: 2.0387659072875977
Batch 16/64 loss: 1.9905362129211426
Batch 17/64 loss: 2.153428077697754
Batch 18/64 loss: 2.8822579383850098
Batch 19/64 loss: 1.9149198532104492
Batch 20/64 loss: 2.575322151184082
Batch 21/64 loss: 1.9213995933532715
Batch 22/64 loss: 2.022002696990967
Batch 23/64 loss: 1.8524322509765625
Batch 24/64 loss: 3.3013768196105957
Batch 25/64 loss: 2.0672121047973633
Batch 26/64 loss: 3.1527442932128906
Batch 27/64 loss: 1.9714603424072266
Batch 28/64 loss: 2.017730712890625
Batch 29/64 loss: 1.7966523170471191
Batch 30/64 loss: 2.098515510559082
Batch 31/64 loss: 2.281524181365967
Batch 32/64 loss: 1.8484315872192383
Batch 33/64 loss: 1.8924012184143066
Batch 34/64 loss: 4.118213653564453
Batch 35/64 loss: 1.8199152946472168
Batch 36/64 loss: 1.7987418174743652
Batch 37/64 loss: 1.7477855682373047
Batch 38/64 loss: 1.8689074516296387
Batch 39/64 loss: 1.728766918182373
Batch 40/64 loss: 1.7214250564575195
Batch 41/64 loss: 2.0205283164978027
Batch 42/64 loss: 3.274791717529297
Batch 43/64 loss: 1.8461756706237793
Batch 44/64 loss: 1.8572945594787598
Batch 45/64 loss: 1.8746953010559082
Batch 46/64 loss: 1.777785301208496
Batch 47/64 loss: 1.845022201538086
Batch 48/64 loss: 2.103024482727051
Batch 49/64 loss: 1.931593894958496
Batch 50/64 loss: 1.730760097503662
Batch 51/64 loss: 2.235139846801758
Batch 52/64 loss: 1.9899048805236816
Batch 53/64 loss: 1.7307806015014648
Batch 54/64 loss: 1.8391857147216797
Batch 55/64 loss: 1.782674789428711
Batch 56/64 loss: 1.824091911315918
Batch 57/64 loss: 4.971378326416016
Batch 58/64 loss: 1.9862079620361328
Batch 59/64 loss: 2.2010340690612793
Batch 60/64 loss: 1.67179536819458
Batch 61/64 loss: 1.9234933853149414
Batch 62/64 loss: 1.9136271476745605
Batch 63/64 loss: 1.7980308532714844
Batch 64/64 loss: -1.6811437606811523
Epoch 273  Train loss: 2.1020248674878887  Val loss: 1.6384759031210567
Epoch 274
-------------------------------
Batch 1/64 loss: 4.576637268066406
Batch 2/64 loss: 1.9737558364868164
Batch 3/64 loss: 1.8752059936523438
Batch 4/64 loss: 1.8007078170776367
Batch 5/64 loss: 1.7488336563110352
Batch 6/64 loss: 4.179814338684082
Batch 7/64 loss: 1.6564645767211914
Batch 8/64 loss: 1.7278451919555664
Batch 9/64 loss: 1.9321503639221191
Batch 10/64 loss: 1.8324570655822754
Batch 11/64 loss: 2.0406785011291504
Batch 12/64 loss: 1.695937156677246
Batch 13/64 loss: 2.5376129150390625
Batch 14/64 loss: 2.6957502365112305
Batch 15/64 loss: 1.7207865715026855
Batch 16/64 loss: 2.0009617805480957
Batch 17/64 loss: 2.1658143997192383
Batch 18/64 loss: 1.6546497344970703
Batch 19/64 loss: 2.060920238494873
Batch 20/64 loss: 2.9444851875305176
Batch 21/64 loss: 1.871772289276123
Batch 22/64 loss: 1.9046330451965332
Batch 23/64 loss: 1.8937273025512695
Batch 24/64 loss: 1.7892932891845703
Batch 25/64 loss: 2.19162654876709
Batch 26/64 loss: 4.870083332061768
Batch 27/64 loss: 1.6446609497070312
Batch 28/64 loss: 1.7429852485656738
Batch 29/64 loss: 1.7442207336425781
Batch 30/64 loss: 1.820889949798584
Batch 31/64 loss: 2.0413713455200195
Batch 32/64 loss: 1.8504056930541992
Batch 33/64 loss: 1.7974681854248047
Batch 34/64 loss: 1.840153694152832
Batch 35/64 loss: 1.8932876586914062
Batch 36/64 loss: 1.8602485656738281
Batch 37/64 loss: 1.71040678024292
Batch 38/64 loss: 1.7147717475891113
Batch 39/64 loss: 1.824789047241211
Batch 40/64 loss: 1.6103711128234863
Batch 41/64 loss: 1.7471137046813965
Batch 42/64 loss: 2.1445984840393066
Batch 43/64 loss: 2.2018303871154785
Batch 44/64 loss: 1.7961068153381348
Batch 45/64 loss: 1.7337384223937988
Batch 46/64 loss: 1.7789196968078613
Batch 47/64 loss: 1.8662309646606445
Batch 48/64 loss: 1.9497556686401367
Batch 49/64 loss: 1.825852870941162
Batch 50/64 loss: 1.771347999572754
Batch 51/64 loss: 1.665088176727295
Batch 52/64 loss: 1.7821283340454102
Batch 53/64 loss: 1.8426885604858398
Batch 54/64 loss: 2.077340602874756
Batch 55/64 loss: 1.8009071350097656
Batch 56/64 loss: 3.1011152267456055
Batch 57/64 loss: 1.765885353088379
Batch 58/64 loss: 1.7629332542419434
Batch 59/64 loss: 1.9117884635925293
Batch 60/64 loss: 1.819791316986084
Batch 61/64 loss: 1.8467974662780762
Batch 62/64 loss: 1.7643303871154785
Batch 63/64 loss: 1.7849669456481934
Batch 64/64 loss: -0.3376731872558594
Epoch 274  Train loss: 2.0066923403272443  Val loss: 1.5646231739791399
Epoch 275
-------------------------------
Batch 1/64 loss: 1.7108840942382812
Batch 2/64 loss: 1.837329387664795
Batch 3/64 loss: 2.282351016998291
Batch 4/64 loss: 2.6490349769592285
Batch 5/64 loss: 1.9957237243652344
Batch 6/64 loss: 1.7253003120422363
Batch 7/64 loss: 1.7692866325378418
Batch 8/64 loss: 1.6667265892028809
Batch 9/64 loss: 1.8505544662475586
Batch 10/64 loss: 1.922348976135254
Batch 11/64 loss: 1.9339632987976074
Batch 12/64 loss: 4.389056205749512
Batch 13/64 loss: 1.7525053024291992
Batch 14/64 loss: 2.0245604515075684
Batch 15/64 loss: 1.8739333152770996
Batch 16/64 loss: 1.7457966804504395
Batch 17/64 loss: 1.7475967407226562
Batch 18/64 loss: 2.0474119186401367
Batch 19/64 loss: 1.7733006477355957
Batch 20/64 loss: 2.503568649291992
Batch 21/64 loss: 2.795760154724121
Batch 22/64 loss: 1.768028736114502
Batch 23/64 loss: 1.6730008125305176
Batch 24/64 loss: 1.8903627395629883
Batch 25/64 loss: 1.7121515274047852
Batch 26/64 loss: 2.001746654510498
Batch 27/64 loss: 1.7690558433532715
Batch 28/64 loss: 1.7296690940856934
Batch 29/64 loss: 1.8069043159484863
Batch 30/64 loss: 1.6204009056091309
Batch 31/64 loss: 4.753966331481934
Batch 32/64 loss: 1.652297019958496
Batch 33/64 loss: 1.882415771484375
Batch 34/64 loss: 4.030772686004639
Batch 35/64 loss: 1.7720913887023926
Batch 36/64 loss: 1.760777473449707
Batch 37/64 loss: 1.8116025924682617
Batch 38/64 loss: 1.7386722564697266
Batch 39/64 loss: 1.6989188194274902
Batch 40/64 loss: 1.7844738960266113
Batch 41/64 loss: 1.7916369438171387
Batch 42/64 loss: 1.656752586364746
Batch 43/64 loss: 1.8145098686218262
Batch 44/64 loss: 1.8059616088867188
Batch 45/64 loss: 1.976752758026123
Batch 46/64 loss: 1.7342524528503418
Batch 47/64 loss: 1.707627773284912
Batch 48/64 loss: 2.850351333618164
Batch 49/64 loss: 1.897231101989746
Batch 50/64 loss: 1.8403668403625488
Batch 51/64 loss: 1.7111482620239258
Batch 52/64 loss: 2.046379566192627
Batch 53/64 loss: 1.9824943542480469
Batch 54/64 loss: 2.3139142990112305
Batch 55/64 loss: 1.7430305480957031
Batch 56/64 loss: 1.7096991539001465
Batch 57/64 loss: 1.827244758605957
Batch 58/64 loss: 2.1108055114746094
Batch 59/64 loss: 1.6724238395690918
Batch 60/64 loss: 2.495670795440674
Batch 61/64 loss: 1.941544532775879
Batch 62/64 loss: 1.8430585861206055
Batch 63/64 loss: 1.720409870147705
Batch 64/64 loss: -1.4906902313232422
Epoch 275  Train loss: 1.9753655227960325  Val loss: 1.6432447007431608
Epoch 276
-------------------------------
Batch 1/64 loss: 1.7895784378051758
Batch 2/64 loss: 1.8398122787475586
Batch 3/64 loss: 2.6566014289855957
Batch 4/64 loss: 1.9854211807250977
Batch 5/64 loss: 1.6453003883361816
Batch 6/64 loss: 1.733959674835205
Batch 7/64 loss: 1.7187132835388184
Batch 8/64 loss: 1.788902759552002
Batch 9/64 loss: 1.8886117935180664
Batch 10/64 loss: 1.9887099266052246
Batch 11/64 loss: 1.7949237823486328
Batch 12/64 loss: 2.037466526031494
Batch 13/64 loss: 1.8097004890441895
Batch 14/64 loss: 4.30122184753418
Batch 15/64 loss: 1.851959228515625
Batch 16/64 loss: 1.9498405456542969
Batch 17/64 loss: 1.7412877082824707
Batch 18/64 loss: 1.9733242988586426
Batch 19/64 loss: 1.7122960090637207
Batch 20/64 loss: 1.7157073020935059
Batch 21/64 loss: 1.7738709449768066
Batch 22/64 loss: 1.792325496673584
Batch 23/64 loss: 1.9410109519958496
Batch 24/64 loss: 1.8971543312072754
Batch 25/64 loss: 1.8646650314331055
Batch 26/64 loss: 2.0117287635803223
Batch 27/64 loss: 1.8369393348693848
Batch 28/64 loss: 1.643092155456543
Batch 29/64 loss: 1.708155632019043
Batch 30/64 loss: 2.1017231941223145
Batch 31/64 loss: 1.7567071914672852
Batch 32/64 loss: 1.7554378509521484
Batch 33/64 loss: 1.6851344108581543
Batch 34/64 loss: 1.7299747467041016
Batch 35/64 loss: 2.3943352699279785
Batch 36/64 loss: 2.299917221069336
Batch 37/64 loss: 2.096928119659424
Batch 38/64 loss: 5.7096781730651855
Batch 39/64 loss: 1.8173203468322754
Batch 40/64 loss: 1.8046064376831055
Batch 41/64 loss: 2.009615421295166
Batch 42/64 loss: 3.9147276878356934
Batch 43/64 loss: 2.0064644813537598
Batch 44/64 loss: 2.9560956954956055
Batch 45/64 loss: 1.7335925102233887
Batch 46/64 loss: 1.82735013961792
Batch 47/64 loss: 1.7529654502868652
Batch 48/64 loss: 1.7329845428466797
Batch 49/64 loss: 1.9193882942199707
Batch 50/64 loss: 1.869368553161621
Batch 51/64 loss: 1.837432861328125
Batch 52/64 loss: 2.804016590118408
Batch 53/64 loss: 1.8068313598632812
Batch 54/64 loss: 1.7029528617858887
Batch 55/64 loss: 1.5822639465332031
Batch 56/64 loss: 1.7097058296203613
Batch 57/64 loss: 1.742241382598877
Batch 58/64 loss: 2.2429089546203613
Batch 59/64 loss: 1.9241280555725098
Batch 60/64 loss: 2.0927581787109375
Batch 61/64 loss: 1.7122769355773926
Batch 62/64 loss: 1.8078007698059082
Batch 63/64 loss: 2.085285186767578
Batch 64/64 loss: -1.7147579193115234
Epoch 276  Train loss: 1.9926452038334865  Val loss: 1.6161601535233436
Epoch 277
-------------------------------
Batch 1/64 loss: 2.523683547973633
Batch 2/64 loss: 1.8381872177124023
Batch 3/64 loss: 1.778010368347168
Batch 4/64 loss: 1.6620783805847168
Batch 5/64 loss: 1.8926239013671875
Batch 6/64 loss: 2.1514687538146973
Batch 7/64 loss: 1.6888866424560547
Batch 8/64 loss: 1.877479076385498
Batch 9/64 loss: 1.9085650444030762
Batch 10/64 loss: 2.5195088386535645
Batch 11/64 loss: 1.6657800674438477
Batch 12/64 loss: 1.8487358093261719
Batch 13/64 loss: 1.8713164329528809
Batch 14/64 loss: 1.6395492553710938
Batch 15/64 loss: 1.8168201446533203
Batch 16/64 loss: 1.7056689262390137
Batch 17/64 loss: 2.0256028175354004
Batch 18/64 loss: 1.7975468635559082
Batch 19/64 loss: 1.9935126304626465
Batch 20/64 loss: 1.9186558723449707
Batch 21/64 loss: 1.7814106941223145
Batch 22/64 loss: 3.729051113128662
Batch 23/64 loss: 1.9943451881408691
Batch 24/64 loss: 1.7986679077148438
Batch 25/64 loss: 1.7714314460754395
Batch 26/64 loss: 1.6848196983337402
Batch 27/64 loss: 1.6936359405517578
Batch 28/64 loss: 1.8587932586669922
Batch 29/64 loss: 1.8145885467529297
Batch 30/64 loss: 2.0158281326293945
Batch 31/64 loss: 1.8072175979614258
Batch 32/64 loss: 1.8977103233337402
Batch 33/64 loss: 1.8577442169189453
Batch 34/64 loss: 1.706831932067871
Batch 35/64 loss: 2.0039100646972656
Batch 36/64 loss: 2.04433012008667
Batch 37/64 loss: 1.7509241104125977
Batch 38/64 loss: 1.7643895149230957
Batch 39/64 loss: 3.9771203994750977
Batch 40/64 loss: 2.131175994873047
Batch 41/64 loss: 1.681300163269043
Batch 42/64 loss: 1.8046951293945312
Batch 43/64 loss: 2.1480584144592285
Batch 44/64 loss: 1.6792826652526855
Batch 45/64 loss: 1.9757061004638672
Batch 46/64 loss: 2.0144596099853516
Batch 47/64 loss: 1.7793407440185547
Batch 48/64 loss: 1.9914684295654297
Batch 49/64 loss: 5.220638751983643
Batch 50/64 loss: 2.074286937713623
Batch 51/64 loss: 1.8302927017211914
Batch 52/64 loss: 1.6942682266235352
Batch 53/64 loss: 1.710914134979248
Batch 54/64 loss: 1.8237791061401367
Batch 55/64 loss: 4.930483818054199
Batch 56/64 loss: 1.9567956924438477
Batch 57/64 loss: 1.8240861892700195
Batch 58/64 loss: 1.8909687995910645
Batch 59/64 loss: 1.7204399108886719
Batch 60/64 loss: 2.130453109741211
Batch 61/64 loss: 1.8044538497924805
Batch 62/64 loss: 1.9846792221069336
Batch 63/64 loss: 1.9178099632263184
Batch 64/64 loss: -1.6558771133422852
Epoch 277  Train loss: 2.000852715735342  Val loss: 1.6086040378845845
Epoch 278
-------------------------------
Batch 1/64 loss: 1.7624387741088867
Batch 2/64 loss: 1.6400585174560547
Batch 3/64 loss: 1.8507652282714844
Batch 4/64 loss: 2.504312038421631
Batch 5/64 loss: 1.886631965637207
Batch 6/64 loss: 1.8048968315124512
Batch 7/64 loss: 2.1012001037597656
Batch 8/64 loss: 1.9203062057495117
Batch 9/64 loss: 1.8620491027832031
Batch 10/64 loss: 2.939291477203369
Batch 11/64 loss: 1.933596134185791
Batch 12/64 loss: 1.8910961151123047
Batch 13/64 loss: 3.7570204734802246
Batch 14/64 loss: 1.852994441986084
Batch 15/64 loss: 1.8279390335083008
Batch 16/64 loss: 2.446213722229004
Batch 17/64 loss: 1.7759613990783691
Batch 18/64 loss: 1.7206377983093262
Batch 19/64 loss: 1.6496458053588867
Batch 20/64 loss: 2.120894432067871
Batch 21/64 loss: 1.6466879844665527
Batch 22/64 loss: 1.8485369682312012
Batch 23/64 loss: 1.8779544830322266
Batch 24/64 loss: 1.6936721801757812
Batch 25/64 loss: 2.044490337371826
Batch 26/64 loss: 2.002995014190674
Batch 27/64 loss: 2.743527412414551
Batch 28/64 loss: 2.1116867065429688
Batch 29/64 loss: 1.706540584564209
Batch 30/64 loss: 1.638458251953125
Batch 31/64 loss: 4.672971725463867
Batch 32/64 loss: 1.6847319602966309
Batch 33/64 loss: 1.865067481994629
Batch 34/64 loss: 4.377768039703369
Batch 35/64 loss: 1.795149803161621
Batch 36/64 loss: 1.8551206588745117
Batch 37/64 loss: 1.7099175453186035
Batch 38/64 loss: 1.8681325912475586
Batch 39/64 loss: 2.0436716079711914
Batch 40/64 loss: 1.660135269165039
Batch 41/64 loss: 1.7374606132507324
Batch 42/64 loss: 1.8082666397094727
Batch 43/64 loss: 1.6628684997558594
Batch 44/64 loss: 1.84598970413208
Batch 45/64 loss: 1.6595349311828613
Batch 46/64 loss: 1.8773193359375
Batch 47/64 loss: 1.96744966506958
Batch 48/64 loss: 1.9992613792419434
Batch 49/64 loss: 1.7615318298339844
Batch 50/64 loss: 1.6757426261901855
Batch 51/64 loss: 1.7488703727722168
Batch 52/64 loss: 1.8549656867980957
Batch 53/64 loss: 1.8414530754089355
Batch 54/64 loss: 1.811678409576416
Batch 55/64 loss: 1.795450210571289
Batch 56/64 loss: 1.781843662261963
Batch 57/64 loss: 1.7328495979309082
Batch 58/64 loss: 1.9026408195495605
Batch 59/64 loss: 1.8491182327270508
Batch 60/64 loss: 2.5422377586364746
Batch 61/64 loss: 1.7914257049560547
Batch 62/64 loss: 1.6515727043151855
Batch 63/64 loss: 1.8488764762878418
Batch 64/64 loss: -1.8268852233886719
Epoch 278  Train loss: 1.9587985917633655  Val loss: 1.5265885317038834
Epoch 279
-------------------------------
Batch 1/64 loss: 1.6799826622009277
Batch 2/64 loss: 3.857952117919922
Batch 3/64 loss: 1.722579002380371
Batch 4/64 loss: 1.792497158050537
Batch 5/64 loss: 1.7844562530517578
Batch 6/64 loss: 1.6707792282104492
Batch 7/64 loss: 1.653982162475586
Batch 8/64 loss: 4.244640827178955
Batch 9/64 loss: 1.7705202102661133
Batch 10/64 loss: 1.6491703987121582
Batch 11/64 loss: 1.7371001243591309
Batch 12/64 loss: 2.2396187782287598
Batch 13/64 loss: 1.8341941833496094
Batch 14/64 loss: 1.620004653930664
Batch 15/64 loss: 1.7999262809753418
Batch 16/64 loss: 1.8118562698364258
Batch 17/64 loss: 1.9831256866455078
Batch 18/64 loss: 1.7544336318969727
Batch 19/64 loss: 1.7843432426452637
Batch 20/64 loss: 2.02793025970459
Batch 21/64 loss: 1.8475403785705566
Batch 22/64 loss: 1.8179659843444824
Batch 23/64 loss: 1.7322750091552734
Batch 24/64 loss: 1.8768296241760254
Batch 25/64 loss: 1.7101163864135742
Batch 26/64 loss: 1.9217720031738281
Batch 27/64 loss: 1.7615294456481934
Batch 28/64 loss: 2.262218952178955
Batch 29/64 loss: 1.76513671875
Batch 30/64 loss: 1.821824550628662
Batch 31/64 loss: 1.849219799041748
Batch 32/64 loss: 1.8382987976074219
Batch 33/64 loss: 2.3576650619506836
Batch 34/64 loss: 1.7944812774658203
Batch 35/64 loss: 2.215878486633301
Batch 36/64 loss: 2.9712347984313965
Batch 37/64 loss: 1.7229037284851074
Batch 38/64 loss: 1.6933140754699707
Batch 39/64 loss: 2.5513157844543457
Batch 40/64 loss: 1.6548066139221191
Batch 41/64 loss: 1.9117798805236816
Batch 42/64 loss: 1.70601224899292
Batch 43/64 loss: 1.7504572868347168
Batch 44/64 loss: 2.592806816101074
Batch 45/64 loss: 1.7742390632629395
Batch 46/64 loss: 1.6622028350830078
Batch 47/64 loss: 1.9966411590576172
Batch 48/64 loss: 1.697497844696045
Batch 49/64 loss: 1.822519302368164
Batch 50/64 loss: 1.7476844787597656
Batch 51/64 loss: 1.698275089263916
Batch 52/64 loss: 1.8093390464782715
Batch 53/64 loss: 1.6338977813720703
Batch 54/64 loss: 1.8202929496765137
Batch 55/64 loss: 1.6740245819091797
Batch 56/64 loss: 1.915907382965088
Batch 57/64 loss: 1.684427261352539
Batch 58/64 loss: 1.9092564582824707
Batch 59/64 loss: 1.779770851135254
Batch 60/64 loss: 1.7073750495910645
Batch 61/64 loss: 1.6823673248291016
Batch 62/64 loss: 1.783888339996338
Batch 63/64 loss: 5.443938255310059
Batch 64/64 loss: -1.585153579711914
Epoch 279  Train loss: 1.9388416739071117  Val loss: 1.578895555738731
Epoch 280
-------------------------------
Batch 1/64 loss: 1.9576449394226074
Batch 2/64 loss: 1.670541763305664
Batch 3/64 loss: 1.7266755104064941
Batch 4/64 loss: 1.8898425102233887
Batch 5/64 loss: 1.8028020858764648
Batch 6/64 loss: 1.9133315086364746
Batch 7/64 loss: 1.9042277336120605
Batch 8/64 loss: 4.8011579513549805
Batch 9/64 loss: 1.7182002067565918
Batch 10/64 loss: 1.6532506942749023
Batch 11/64 loss: 1.957077980041504
Batch 12/64 loss: 1.793520450592041
Batch 13/64 loss: 1.749250888824463
Batch 14/64 loss: 1.9228816032409668
Batch 15/64 loss: 1.7626953125
Batch 16/64 loss: 1.7162938117980957
Batch 17/64 loss: 1.7650275230407715
Batch 18/64 loss: 1.828561782836914
Batch 19/64 loss: 1.7424144744873047
Batch 20/64 loss: 1.6816511154174805
Batch 21/64 loss: 3.9538097381591797
Batch 22/64 loss: 3.253425121307373
Batch 23/64 loss: 1.7116284370422363
Batch 24/64 loss: 2.1273393630981445
Batch 25/64 loss: 2.1441192626953125
Batch 26/64 loss: 1.9496498107910156
Batch 27/64 loss: 2.231100559234619
Batch 28/64 loss: 2.022922992706299
Batch 29/64 loss: 1.679830551147461
Batch 30/64 loss: 2.4212403297424316
Batch 31/64 loss: 1.7107315063476562
Batch 32/64 loss: 1.9347171783447266
Batch 33/64 loss: 1.8648786544799805
Batch 34/64 loss: 4.245534896850586
Batch 35/64 loss: 1.7599492073059082
Batch 36/64 loss: 1.9607462882995605
Batch 37/64 loss: 1.6845097541809082
Batch 38/64 loss: 1.739023208618164
Batch 39/64 loss: 1.8143310546875
Batch 40/64 loss: 2.193660259246826
Batch 41/64 loss: 1.7434701919555664
Batch 42/64 loss: 1.7585158348083496
Batch 43/64 loss: 1.8934926986694336
Batch 44/64 loss: 1.7950186729431152
Batch 45/64 loss: 1.8118667602539062
Batch 46/64 loss: 1.7093396186828613
Batch 47/64 loss: 2.042076587677002
Batch 48/64 loss: 1.6797313690185547
Batch 49/64 loss: 1.6435480117797852
Batch 50/64 loss: 1.6836037635803223
Batch 51/64 loss: 2.18900728225708
Batch 52/64 loss: 2.003824234008789
Batch 53/64 loss: 3.551379680633545
Batch 54/64 loss: 1.7459230422973633
Batch 55/64 loss: 1.9722332954406738
Batch 56/64 loss: 1.8875713348388672
Batch 57/64 loss: 2.6010751724243164
Batch 58/64 loss: 1.7143568992614746
Batch 59/64 loss: 1.814882755279541
Batch 60/64 loss: 1.856947898864746
Batch 61/64 loss: 1.772414207458496
Batch 62/64 loss: 1.7080307006835938
Batch 63/64 loss: 1.8116507530212402
Batch 64/64 loss: -1.7912673950195312
Epoch 280  Train loss: 1.982850325341318  Val loss: 1.5717770815714938
Epoch 281
-------------------------------
Batch 1/64 loss: 2.1826462745666504
Batch 2/64 loss: 2.1537771224975586
Batch 3/64 loss: 2.1534223556518555
Batch 4/64 loss: 1.7362256050109863
Batch 5/64 loss: 1.834834098815918
Batch 6/64 loss: 1.810765266418457
Batch 7/64 loss: 1.721273422241211
Batch 8/64 loss: 1.9677143096923828
Batch 9/64 loss: 1.8897337913513184
Batch 10/64 loss: 1.7337760925292969
Batch 11/64 loss: 1.8242077827453613
Batch 12/64 loss: 1.9924349784851074
Batch 13/64 loss: 1.654895305633545
Batch 14/64 loss: 1.6643218994140625
Batch 15/64 loss: 2.065433979034424
Batch 16/64 loss: 1.8497228622436523
Batch 17/64 loss: 2.476229190826416
Batch 18/64 loss: 1.8228683471679688
Batch 19/64 loss: 1.7465286254882812
Batch 20/64 loss: 1.7950725555419922
Batch 21/64 loss: 4.87833309173584
Batch 22/64 loss: 1.6810636520385742
Batch 23/64 loss: 1.7267427444458008
Batch 24/64 loss: 2.401789665222168
Batch 25/64 loss: 1.7073745727539062
Batch 26/64 loss: 1.893195629119873
Batch 27/64 loss: 1.7234077453613281
Batch 28/64 loss: 2.0185184478759766
Batch 29/64 loss: 1.8221240043640137
Batch 30/64 loss: 1.6818552017211914
Batch 31/64 loss: 1.7380337715148926
Batch 32/64 loss: 1.6354150772094727
Batch 33/64 loss: 1.8363165855407715
Batch 34/64 loss: 1.7476654052734375
Batch 35/64 loss: 3.1472768783569336
Batch 36/64 loss: 1.956162452697754
Batch 37/64 loss: 1.7623882293701172
Batch 38/64 loss: 1.7333741188049316
Batch 39/64 loss: 3.946043014526367
Batch 40/64 loss: 1.6786141395568848
Batch 41/64 loss: 4.199551105499268
Batch 42/64 loss: 1.8334598541259766
Batch 43/64 loss: 1.703967571258545
Batch 44/64 loss: 1.8580255508422852
Batch 45/64 loss: 3.2056140899658203
Batch 46/64 loss: 1.8461041450500488
Batch 47/64 loss: 1.5968923568725586
Batch 48/64 loss: 1.9187817573547363
Batch 49/64 loss: 1.6728219985961914
Batch 50/64 loss: 1.8880410194396973
Batch 51/64 loss: 1.7843570709228516
Batch 52/64 loss: 1.7569961547851562
Batch 53/64 loss: 1.778228759765625
Batch 54/64 loss: 1.6897964477539062
Batch 55/64 loss: 1.8224148750305176
Batch 56/64 loss: 1.906911849975586
Batch 57/64 loss: 1.648198127746582
Batch 58/64 loss: 1.8015031814575195
Batch 59/64 loss: 1.5754027366638184
Batch 60/64 loss: 1.7303767204284668
Batch 61/64 loss: 1.788797378540039
Batch 62/64 loss: 1.690192699432373
Batch 63/64 loss: 2.641359806060791
Batch 64/64 loss: -1.730422019958496
Epoch 281  Train loss: 1.9581420711442536  Val loss: 1.475231262416774
Epoch 282
-------------------------------
Batch 1/64 loss: 1.743945598602295
Batch 2/64 loss: 1.880396842956543
Batch 3/64 loss: 1.699256420135498
Batch 4/64 loss: 1.681370735168457
Batch 5/64 loss: 4.238372802734375
Batch 6/64 loss: 1.7929892539978027
Batch 7/64 loss: 1.7032337188720703
Batch 8/64 loss: 2.0598349571228027
Batch 9/64 loss: 1.791858196258545
Batch 10/64 loss: 1.811790943145752
Batch 11/64 loss: 1.5786385536193848
Batch 12/64 loss: 1.7082295417785645
Batch 13/64 loss: 1.9354233741760254
Batch 14/64 loss: 1.6993050575256348
Batch 15/64 loss: 1.6569533348083496
Batch 16/64 loss: 1.592885971069336
Batch 17/64 loss: 2.3481826782226562
Batch 18/64 loss: 2.6701736450195312
Batch 19/64 loss: 1.7175569534301758
Batch 20/64 loss: 1.7795982360839844
Batch 21/64 loss: 1.835744857788086
Batch 22/64 loss: 1.673572063446045
Batch 23/64 loss: 4.146183490753174
Batch 24/64 loss: 1.653538703918457
Batch 25/64 loss: 1.68757963180542
Batch 26/64 loss: 1.764735221862793
Batch 27/64 loss: 2.3405542373657227
Batch 28/64 loss: 1.653733730316162
Batch 29/64 loss: 1.6453056335449219
Batch 30/64 loss: 1.8183889389038086
Batch 31/64 loss: 1.7277684211730957
Batch 32/64 loss: 1.8554048538208008
Batch 33/64 loss: 1.708406925201416
Batch 34/64 loss: 1.749253749847412
Batch 35/64 loss: 1.690666675567627
Batch 36/64 loss: 1.6955928802490234
Batch 37/64 loss: 1.7853245735168457
Batch 38/64 loss: 1.7147693634033203
Batch 39/64 loss: 1.634007453918457
Batch 40/64 loss: 1.850616455078125
Batch 41/64 loss: 1.7587971687316895
Batch 42/64 loss: 1.7928924560546875
Batch 43/64 loss: 1.7136249542236328
Batch 44/64 loss: 2.8943281173706055
Batch 45/64 loss: 1.6904349327087402
Batch 46/64 loss: 1.7222375869750977
Batch 47/64 loss: 1.7608661651611328
Batch 48/64 loss: 1.8220572471618652
Batch 49/64 loss: 2.109463691711426
Batch 50/64 loss: 1.957226276397705
Batch 51/64 loss: 2.7356343269348145
Batch 52/64 loss: 1.763451099395752
Batch 53/64 loss: 1.6471757888793945
Batch 54/64 loss: 4.628942966461182
Batch 55/64 loss: 1.6547083854675293
Batch 56/64 loss: 1.8242087364196777
Batch 57/64 loss: 1.6896629333496094
Batch 58/64 loss: 1.618734359741211
Batch 59/64 loss: 1.7759308815002441
Batch 60/64 loss: 1.6827082633972168
Batch 61/64 loss: 1.754587173461914
Batch 62/64 loss: 1.5765113830566406
Batch 63/64 loss: 2.350052833557129
Batch 64/64 loss: -1.6595287322998047
Epoch 282  Train loss: 1.904325268315334  Val loss: 1.4615024160273706
Saving best model, epoch: 282
Epoch 283
-------------------------------
Batch 1/64 loss: 1.6835618019104004
Batch 2/64 loss: 1.7878427505493164
Batch 3/64 loss: 1.8046746253967285
Batch 4/64 loss: 1.7235870361328125
Batch 5/64 loss: 1.70414400100708
Batch 6/64 loss: 2.6654272079467773
Batch 7/64 loss: 1.74245023727417
Batch 8/64 loss: 1.611234188079834
Batch 9/64 loss: 1.67222261428833
Batch 10/64 loss: 1.8749089241027832
Batch 11/64 loss: 4.137242317199707
Batch 12/64 loss: 4.6189069747924805
Batch 13/64 loss: 1.838862419128418
Batch 14/64 loss: 1.6672611236572266
Batch 15/64 loss: 2.0000863075256348
Batch 16/64 loss: 1.8005924224853516
Batch 17/64 loss: 1.738473892211914
Batch 18/64 loss: 1.55340576171875
Batch 19/64 loss: 1.7252779006958008
Batch 20/64 loss: 1.7766032218933105
Batch 21/64 loss: 1.6248865127563477
Batch 22/64 loss: 1.9827475547790527
Batch 23/64 loss: 1.6822967529296875
Batch 24/64 loss: 1.8927278518676758
Batch 25/64 loss: 1.833174228668213
Batch 26/64 loss: 1.6813054084777832
Batch 27/64 loss: 1.9680609703063965
Batch 28/64 loss: 1.8228583335876465
Batch 29/64 loss: 1.823737621307373
Batch 30/64 loss: 1.6919431686401367
Batch 31/64 loss: 1.7448949813842773
Batch 32/64 loss: 1.744680404663086
Batch 33/64 loss: 1.7961711883544922
Batch 34/64 loss: 2.3888068199157715
Batch 35/64 loss: 2.408674716949463
Batch 36/64 loss: 1.5821433067321777
Batch 37/64 loss: 1.7057957649230957
Batch 38/64 loss: 2.0311264991760254
Batch 39/64 loss: 1.7962818145751953
Batch 40/64 loss: 1.8934249877929688
Batch 41/64 loss: 2.165170669555664
Batch 42/64 loss: 1.9767370223999023
Batch 43/64 loss: 1.7014694213867188
Batch 44/64 loss: 1.8057470321655273
Batch 45/64 loss: 2.0183849334716797
Batch 46/64 loss: 1.7895727157592773
Batch 47/64 loss: 1.7039828300476074
Batch 48/64 loss: 1.719362735748291
Batch 49/64 loss: 2.6824402809143066
Batch 50/64 loss: 1.6366491317749023
Batch 51/64 loss: 1.801584243774414
Batch 52/64 loss: 1.8816332817077637
Batch 53/64 loss: 1.8607378005981445
Batch 54/64 loss: 3.8415818214416504
Batch 55/64 loss: 1.7443108558654785
Batch 56/64 loss: 3.033700942993164
Batch 57/64 loss: 1.6405839920043945
Batch 58/64 loss: 1.6569452285766602
Batch 59/64 loss: 1.799201488494873
Batch 60/64 loss: 1.619178295135498
Batch 61/64 loss: 1.9090003967285156
Batch 62/64 loss: 1.672605037689209
Batch 63/64 loss: 2.094827175140381
Batch 64/64 loss: -1.8336811065673828
Epoch 283  Train loss: 1.923178841085995  Val loss: 1.531692478664962
Epoch 284
-------------------------------
Batch 1/64 loss: 1.6761016845703125
Batch 2/64 loss: 1.6291909217834473
Batch 3/64 loss: 2.0513787269592285
Batch 4/64 loss: 1.8176507949829102
Batch 5/64 loss: 1.836606502532959
Batch 6/64 loss: 1.7067022323608398
Batch 7/64 loss: 1.8877592086791992
Batch 8/64 loss: 1.6937756538391113
Batch 9/64 loss: 1.6721162796020508
Batch 10/64 loss: 1.7254366874694824
Batch 11/64 loss: 1.7059807777404785
Batch 12/64 loss: 1.6960949897766113
Batch 13/64 loss: 1.6984548568725586
Batch 14/64 loss: 1.8951616287231445
Batch 15/64 loss: 1.7367734909057617
Batch 16/64 loss: 1.7411742210388184
Batch 17/64 loss: 1.5998449325561523
Batch 18/64 loss: 1.704967975616455
Batch 19/64 loss: 2.8273024559020996
Batch 20/64 loss: 1.667264461517334
Batch 21/64 loss: 1.7903776168823242
Batch 22/64 loss: 1.6516356468200684
Batch 23/64 loss: 2.104708194732666
Batch 24/64 loss: 1.7620601654052734
Batch 25/64 loss: 1.8017258644104004
Batch 26/64 loss: 1.7392067909240723
Batch 27/64 loss: 1.8659782409667969
Batch 28/64 loss: 2.37337064743042
Batch 29/64 loss: 1.6680960655212402
Batch 30/64 loss: 1.6611332893371582
Batch 31/64 loss: 1.7311367988586426
Batch 32/64 loss: 1.858957290649414
Batch 33/64 loss: 1.7434310913085938
Batch 34/64 loss: 1.7698407173156738
Batch 35/64 loss: 2.850640296936035
Batch 36/64 loss: 1.696134090423584
Batch 37/64 loss: 1.6478490829467773
Batch 38/64 loss: 4.114236354827881
Batch 39/64 loss: 1.882645606994629
Batch 40/64 loss: 1.7483515739440918
Batch 41/64 loss: 4.674901485443115
Batch 42/64 loss: 1.7048163414001465
Batch 43/64 loss: 2.0074715614318848
Batch 44/64 loss: 1.9924988746643066
Batch 45/64 loss: 1.6727595329284668
Batch 46/64 loss: 2.491899013519287
Batch 47/64 loss: 1.599454402923584
Batch 48/64 loss: 1.983391284942627
Batch 49/64 loss: 1.8304643630981445
Batch 50/64 loss: 2.363583564758301
Batch 51/64 loss: 1.9011774063110352
Batch 52/64 loss: 1.8169636726379395
Batch 53/64 loss: 1.833216667175293
Batch 54/64 loss: 1.8893208503723145
Batch 55/64 loss: 1.7709112167358398
Batch 56/64 loss: 1.8228979110717773
Batch 57/64 loss: 2.582827091217041
Batch 58/64 loss: 2.0717625617980957
Batch 59/64 loss: 3.880401611328125
Batch 60/64 loss: 1.8537230491638184
Batch 61/64 loss: 1.6669893264770508
Batch 62/64 loss: 1.7233686447143555
Batch 63/64 loss: 1.9245896339416504
Batch 64/64 loss: -1.804152488708496
Epoch 284  Train loss: 1.931569091946471  Val loss: 1.5445329069681593
Epoch 285
-------------------------------
Batch 1/64 loss: 1.7528138160705566
Batch 2/64 loss: 1.755296230316162
Batch 3/64 loss: 2.7027387619018555
Batch 4/64 loss: 1.694922924041748
Batch 5/64 loss: 1.6470136642456055
Batch 6/64 loss: 3.7843947410583496
Batch 7/64 loss: 4.1409912109375
Batch 8/64 loss: 1.6296310424804688
Batch 9/64 loss: 1.6573104858398438
Batch 10/64 loss: 1.8436636924743652
Batch 11/64 loss: 1.7453546524047852
Batch 12/64 loss: 1.7250347137451172
Batch 13/64 loss: 1.6426658630371094
Batch 14/64 loss: 1.676072597503662
Batch 15/64 loss: 1.7919578552246094
Batch 16/64 loss: 2.0307669639587402
Batch 17/64 loss: 1.7950763702392578
Batch 18/64 loss: 1.8094701766967773
Batch 19/64 loss: 1.667747974395752
Batch 20/64 loss: 1.7802772521972656
Batch 21/64 loss: 1.7930150032043457
Batch 22/64 loss: 2.809880256652832
Batch 23/64 loss: 2.022006034851074
Batch 24/64 loss: 1.7811837196350098
Batch 25/64 loss: 1.7445573806762695
Batch 26/64 loss: 1.8111395835876465
Batch 27/64 loss: 3.2567057609558105
Batch 28/64 loss: 2.0024728775024414
Batch 29/64 loss: 1.7237896919250488
Batch 30/64 loss: 1.7223200798034668
Batch 31/64 loss: 1.8072233200073242
Batch 32/64 loss: 4.68486213684082
Batch 33/64 loss: 1.6097493171691895
Batch 34/64 loss: 1.8270668983459473
Batch 35/64 loss: 1.8360962867736816
Batch 36/64 loss: 1.9017047882080078
Batch 37/64 loss: 2.1026649475097656
Batch 38/64 loss: 1.5683612823486328
Batch 39/64 loss: 1.8707103729248047
Batch 40/64 loss: 1.6836109161376953
Batch 41/64 loss: 1.8419365882873535
Batch 42/64 loss: 1.845984935760498
Batch 43/64 loss: 1.646749496459961
Batch 44/64 loss: 2.4195103645324707
Batch 45/64 loss: 1.676910400390625
Batch 46/64 loss: 1.6442065238952637
Batch 47/64 loss: 1.7385978698730469
Batch 48/64 loss: 1.7693915367126465
Batch 49/64 loss: 1.9247617721557617
Batch 50/64 loss: 1.9540767669677734
Batch 51/64 loss: 1.8738884925842285
Batch 52/64 loss: 1.6322298049926758
Batch 53/64 loss: 1.7570991516113281
Batch 54/64 loss: 1.8654441833496094
Batch 55/64 loss: 2.3948588371276855
Batch 56/64 loss: 1.7396125793457031
Batch 57/64 loss: 1.6219816207885742
Batch 58/64 loss: 1.6313905715942383
Batch 59/64 loss: 1.711815357208252
Batch 60/64 loss: 1.8050179481506348
Batch 61/64 loss: 1.772939682006836
Batch 62/64 loss: 1.7684712409973145
Batch 63/64 loss: 1.6972432136535645
Batch 64/64 loss: -1.6940279006958008
Epoch 285  Train loss: 1.9183673671647614  Val loss: 1.5131574283350784
Epoch 286
-------------------------------
Batch 1/64 loss: 2.6964526176452637
Batch 2/64 loss: 1.6311745643615723
Batch 3/64 loss: 1.957902431488037
Batch 4/64 loss: 2.818955898284912
Batch 5/64 loss: 1.7292213439941406
Batch 6/64 loss: 2.464639663696289
Batch 7/64 loss: 1.7725043296813965
Batch 8/64 loss: 1.710176944732666
Batch 9/64 loss: 1.589597225189209
Batch 10/64 loss: 1.6919126510620117
Batch 11/64 loss: 1.707568645477295
Batch 12/64 loss: 2.021218776702881
Batch 13/64 loss: 1.8814692497253418
Batch 14/64 loss: 1.7502317428588867
Batch 15/64 loss: 1.753255844116211
Batch 16/64 loss: 1.711857795715332
Batch 17/64 loss: 1.7033557891845703
Batch 18/64 loss: 1.8036937713623047
Batch 19/64 loss: 1.8822541236877441
Batch 20/64 loss: 1.6500744819641113
Batch 21/64 loss: 1.7438163757324219
Batch 22/64 loss: 1.909287452697754
Batch 23/64 loss: 1.7086596488952637
Batch 24/64 loss: 1.797952651977539
Batch 25/64 loss: 1.6750688552856445
Batch 26/64 loss: 1.7436208724975586
Batch 27/64 loss: 1.6402359008789062
Batch 28/64 loss: 1.9512581825256348
Batch 29/64 loss: 1.6857366561889648
Batch 30/64 loss: 1.8687849044799805
Batch 31/64 loss: 1.7475800514221191
Batch 32/64 loss: 2.3518991470336914
Batch 33/64 loss: 1.778184413909912
Batch 34/64 loss: 1.640754222869873
Batch 35/64 loss: 2.0313167572021484
Batch 36/64 loss: 1.8231391906738281
Batch 37/64 loss: 2.355746269226074
Batch 38/64 loss: 1.8184494972229004
Batch 39/64 loss: 2.5219521522521973
Batch 40/64 loss: 1.9162273406982422
Batch 41/64 loss: 1.9108872413635254
Batch 42/64 loss: 1.7440438270568848
Batch 43/64 loss: 1.648848056793213
Batch 44/64 loss: 1.887108325958252
Batch 45/64 loss: 1.6582393646240234
Batch 46/64 loss: 3.7619986534118652
Batch 47/64 loss: 1.6962342262268066
Batch 48/64 loss: 1.598811149597168
Batch 49/64 loss: 1.9238176345825195
Batch 50/64 loss: 1.7866291999816895
Batch 51/64 loss: 4.001336574554443
Batch 52/64 loss: 1.6238398551940918
Batch 53/64 loss: 1.779618263244629
Batch 54/64 loss: 1.6748723983764648
Batch 55/64 loss: 1.9410090446472168
Batch 56/64 loss: 1.818519115447998
Batch 57/64 loss: 4.825972557067871
Batch 58/64 loss: 1.623016357421875
Batch 59/64 loss: 2.0163187980651855
Batch 60/64 loss: 1.698486328125
Batch 61/64 loss: 2.039238452911377
Batch 62/64 loss: 1.7804040908813477
Batch 63/64 loss: 1.743217945098877
Batch 64/64 loss: -1.671121597290039
Epoch 286  Train loss: 1.9226088579963236  Val loss: 1.513470967610677
Epoch 287
-------------------------------
Batch 1/64 loss: 1.9805588722229004
Batch 2/64 loss: 2.729130268096924
Batch 3/64 loss: 1.6319403648376465
Batch 4/64 loss: 1.6956977844238281
Batch 5/64 loss: 1.8347358703613281
Batch 6/64 loss: 1.8619179725646973
Batch 7/64 loss: 1.9162578582763672
Batch 8/64 loss: 1.7059807777404785
Batch 9/64 loss: 1.822089672088623
Batch 10/64 loss: 1.6443161964416504
Batch 11/64 loss: 1.769300937652588
Batch 12/64 loss: 1.6372079849243164
Batch 13/64 loss: 1.7822809219360352
Batch 14/64 loss: 1.7265958786010742
Batch 15/64 loss: 1.6162829399108887
Batch 16/64 loss: 1.8104567527770996
Batch 17/64 loss: 1.995920181274414
Batch 18/64 loss: 1.8213725090026855
Batch 19/64 loss: 1.701521873474121
Batch 20/64 loss: 2.3672547340393066
Batch 21/64 loss: 1.7173480987548828
Batch 22/64 loss: 1.9870834350585938
Batch 23/64 loss: 1.6006603240966797
Batch 24/64 loss: 1.752049446105957
Batch 25/64 loss: 1.733964443206787
Batch 26/64 loss: 3.7315125465393066
Batch 27/64 loss: 1.6701664924621582
Batch 28/64 loss: 1.978743553161621
Batch 29/64 loss: 1.6367897987365723
Batch 30/64 loss: 1.6419610977172852
Batch 31/64 loss: 1.7575531005859375
Batch 32/64 loss: 1.8083610534667969
Batch 33/64 loss: 2.099405288696289
Batch 34/64 loss: 4.107722759246826
Batch 35/64 loss: 1.6711368560791016
Batch 36/64 loss: 2.5558838844299316
Batch 37/64 loss: 1.9934601783752441
Batch 38/64 loss: 1.6644964218139648
Batch 39/64 loss: 1.7003669738769531
Batch 40/64 loss: 1.6319832801818848
Batch 41/64 loss: 1.648399829864502
Batch 42/64 loss: 1.811866283416748
Batch 43/64 loss: 1.8948068618774414
Batch 44/64 loss: 1.6191792488098145
Batch 45/64 loss: 1.7412056922912598
Batch 46/64 loss: 1.7769570350646973
Batch 47/64 loss: 1.6082720756530762
Batch 48/64 loss: 2.3040080070495605
Batch 49/64 loss: 5.058435440063477
Batch 50/64 loss: 1.588524341583252
Batch 51/64 loss: 1.8841753005981445
Batch 52/64 loss: 2.9246678352355957
Batch 53/64 loss: 1.6994667053222656
Batch 54/64 loss: 1.6938776969909668
Batch 55/64 loss: 1.6594419479370117
Batch 56/64 loss: 1.7156109809875488
Batch 57/64 loss: 1.830005168914795
Batch 58/64 loss: 1.8901796340942383
Batch 59/64 loss: 1.7252483367919922
Batch 60/64 loss: 1.7596402168273926
Batch 61/64 loss: 1.7510504722595215
Batch 62/64 loss: 1.8086419105529785
Batch 63/64 loss: 1.850468635559082
Batch 64/64 loss: -1.8054122924804688
Epoch 287  Train loss: 1.904024154064702  Val loss: 1.4944402425969179
Epoch 288
-------------------------------
Batch 1/64 loss: 1.5677289962768555
Batch 2/64 loss: 4.65915584564209
Batch 3/64 loss: 2.277472496032715
Batch 4/64 loss: 1.704298496246338
Batch 5/64 loss: 1.757237434387207
Batch 6/64 loss: 1.6386008262634277
Batch 7/64 loss: 1.8460774421691895
Batch 8/64 loss: 1.6843557357788086
Batch 9/64 loss: 2.332216739654541
Batch 10/64 loss: 1.923342227935791
Batch 11/64 loss: 2.739558696746826
Batch 12/64 loss: 1.6020140647888184
Batch 13/64 loss: 1.6466293334960938
Batch 14/64 loss: 1.6911311149597168
Batch 15/64 loss: 1.7054486274719238
Batch 16/64 loss: 1.9853367805480957
Batch 17/64 loss: 1.7989501953125
Batch 18/64 loss: 1.7763323783874512
Batch 19/64 loss: 1.7401609420776367
Batch 20/64 loss: 2.0745797157287598
Batch 21/64 loss: 1.663233757019043
Batch 22/64 loss: 2.324158191680908
Batch 23/64 loss: 1.7831273078918457
Batch 24/64 loss: 1.8710079193115234
Batch 25/64 loss: 1.7217354774475098
Batch 26/64 loss: 1.77227783203125
Batch 27/64 loss: 1.7658486366271973
Batch 28/64 loss: 3.851419448852539
Batch 29/64 loss: 1.7879972457885742
Batch 30/64 loss: 1.6794886589050293
Batch 31/64 loss: 1.8995871543884277
Batch 32/64 loss: 2.513953685760498
Batch 33/64 loss: 1.6293020248413086
Batch 34/64 loss: 4.125319004058838
Batch 35/64 loss: 1.852797031402588
Batch 36/64 loss: 1.6761083602905273
Batch 37/64 loss: 1.8225274085998535
Batch 38/64 loss: 1.6551613807678223
Batch 39/64 loss: 1.6228065490722656
Batch 40/64 loss: 1.8730640411376953
Batch 41/64 loss: 2.9604859352111816
Batch 42/64 loss: 1.6494083404541016
Batch 43/64 loss: 1.8029170036315918
Batch 44/64 loss: 1.583916187286377
Batch 45/64 loss: 1.61761474609375
Batch 46/64 loss: 1.8278865814208984
Batch 47/64 loss: 1.6486821174621582
Batch 48/64 loss: 1.627490520477295
Batch 49/64 loss: 1.7736144065856934
Batch 50/64 loss: 1.6655263900756836
Batch 51/64 loss: 1.7531676292419434
Batch 52/64 loss: 1.6914758682250977
Batch 53/64 loss: 2.1985912322998047
Batch 54/64 loss: 1.7918734550476074
Batch 55/64 loss: 1.684628963470459
Batch 56/64 loss: 1.8081626892089844
Batch 57/64 loss: 1.5759563446044922
Batch 58/64 loss: 1.7847309112548828
Batch 59/64 loss: 1.812830924987793
Batch 60/64 loss: 1.6805357933044434
Batch 61/64 loss: 1.6830940246582031
Batch 62/64 loss: 1.5841522216796875
Batch 63/64 loss: 1.6019587516784668
Batch 64/64 loss: -1.7046146392822266
Epoch 288  Train loss: 1.8913221845439836  Val loss: 1.4825458854334461
Epoch 289
-------------------------------
Batch 1/64 loss: 1.5102229118347168
Batch 2/64 loss: 1.6141119003295898
Batch 3/64 loss: 1.6836824417114258
Batch 4/64 loss: 1.4902300834655762
Batch 5/64 loss: 1.6492266654968262
Batch 6/64 loss: 1.5571322441101074
Batch 7/64 loss: 3.2773752212524414
Batch 8/64 loss: 1.6546292304992676
Batch 9/64 loss: 1.9654269218444824
Batch 10/64 loss: 1.6306943893432617
Batch 11/64 loss: 5.323733806610107
Batch 12/64 loss: 1.728719711303711
Batch 13/64 loss: 1.9078292846679688
Batch 14/64 loss: 1.8112940788269043
Batch 15/64 loss: 1.765139102935791
Batch 16/64 loss: 1.7948722839355469
Batch 17/64 loss: 1.7665624618530273
Batch 18/64 loss: 1.7506160736083984
Batch 19/64 loss: 1.8221187591552734
Batch 20/64 loss: 2.1597061157226562
Batch 21/64 loss: 3.87764310836792
Batch 22/64 loss: 1.9454708099365234
Batch 23/64 loss: 1.6900396347045898
Batch 24/64 loss: 1.6638555526733398
Batch 25/64 loss: 2.199828624725342
Batch 26/64 loss: 1.629580020904541
Batch 27/64 loss: 2.321173667907715
Batch 28/64 loss: 1.7647724151611328
Batch 29/64 loss: 1.6748499870300293
Batch 30/64 loss: 1.656078815460205
Batch 31/64 loss: 1.6890172958374023
Batch 32/64 loss: 1.6539344787597656
Batch 33/64 loss: 1.6805596351623535
Batch 34/64 loss: 1.6771554946899414
Batch 35/64 loss: 1.6647734642028809
Batch 36/64 loss: 1.672774314880371
Batch 37/64 loss: 1.7173080444335938
Batch 38/64 loss: 1.7047109603881836
Batch 39/64 loss: 1.630305290222168
Batch 40/64 loss: 1.6126155853271484
Batch 41/64 loss: 1.6780123710632324
Batch 42/64 loss: 2.0560526847839355
Batch 43/64 loss: 1.9108023643493652
Batch 44/64 loss: 2.0074963569641113
Batch 45/64 loss: 1.6403083801269531
Batch 46/64 loss: 1.6582822799682617
Batch 47/64 loss: 1.73773193359375
Batch 48/64 loss: 1.6334400177001953
Batch 49/64 loss: 2.608321189880371
Batch 50/64 loss: 4.432185649871826
Batch 51/64 loss: 2.461615562438965
Batch 52/64 loss: 1.9568791389465332
Batch 53/64 loss: 1.8076000213623047
Batch 54/64 loss: 1.5878844261169434
Batch 55/64 loss: 2.646216869354248
Batch 56/64 loss: 1.7567195892333984
Batch 57/64 loss: 1.6433286666870117
Batch 58/64 loss: 1.673762321472168
Batch 59/64 loss: 2.0572409629821777
Batch 60/64 loss: 1.5515093803405762
Batch 61/64 loss: 1.657477855682373
Batch 62/64 loss: 1.8675060272216797
Batch 63/64 loss: 1.6666831970214844
Batch 64/64 loss: -1.8372249603271484
Epoch 289  Train loss: 1.902884853587431  Val loss: 1.5258606324081159
Epoch 290
-------------------------------
Batch 1/64 loss: 1.64640474319458
Batch 2/64 loss: 1.8008933067321777
Batch 3/64 loss: 1.9023361206054688
Batch 4/64 loss: 1.7302041053771973
Batch 5/64 loss: 1.6931161880493164
Batch 6/64 loss: 1.9631762504577637
Batch 7/64 loss: 1.6772360801696777
Batch 8/64 loss: 4.208412170410156
Batch 9/64 loss: 1.7488980293273926
Batch 10/64 loss: 1.7214698791503906
Batch 11/64 loss: 1.7718310356140137
Batch 12/64 loss: 1.7447514533996582
Batch 13/64 loss: 1.9008798599243164
Batch 14/64 loss: 1.5973734855651855
Batch 15/64 loss: 1.6062211990356445
Batch 16/64 loss: 1.905013084411621
Batch 17/64 loss: 1.7844281196594238
Batch 18/64 loss: 1.7131924629211426
Batch 19/64 loss: 1.7808918952941895
Batch 20/64 loss: 2.195014476776123
Batch 21/64 loss: 1.8572964668273926
Batch 22/64 loss: 2.0925674438476562
Batch 23/64 loss: 1.8664283752441406
Batch 24/64 loss: 1.585904598236084
Batch 25/64 loss: 2.626476764678955
Batch 26/64 loss: 1.6425161361694336
Batch 27/64 loss: 1.6355056762695312
Batch 28/64 loss: 1.7395586967468262
Batch 29/64 loss: 1.7795443534851074
Batch 30/64 loss: 1.819746971130371
Batch 31/64 loss: 2.0398917198181152
Batch 32/64 loss: 2.290090560913086
Batch 33/64 loss: 2.9490485191345215
Batch 34/64 loss: 1.7796216011047363
Batch 35/64 loss: 1.9028310775756836
Batch 36/64 loss: 1.7176270484924316
Batch 37/64 loss: 2.1088857650756836
Batch 38/64 loss: 1.9307351112365723
Batch 39/64 loss: 2.62302303314209
Batch 40/64 loss: 1.9329566955566406
Batch 41/64 loss: 1.9954395294189453
Batch 42/64 loss: 1.6478180885314941
Batch 43/64 loss: 1.8640813827514648
Batch 44/64 loss: 4.7567219734191895
Batch 45/64 loss: 1.7059898376464844
Batch 46/64 loss: 1.827770709991455
Batch 47/64 loss: 1.6298012733459473
Batch 48/64 loss: 1.7117581367492676
Batch 49/64 loss: 3.5168490409851074
Batch 50/64 loss: 1.79984712600708
Batch 51/64 loss: 2.145007610321045
Batch 52/64 loss: 1.7360029220581055
Batch 53/64 loss: 1.672861099243164
Batch 54/64 loss: 2.204664707183838
Batch 55/64 loss: 1.7731413841247559
Batch 56/64 loss: 2.9366507530212402
Batch 57/64 loss: 1.8142099380493164
Batch 58/64 loss: 1.8301219940185547
Batch 59/64 loss: 2.1976118087768555
Batch 60/64 loss: 1.7806577682495117
Batch 61/64 loss: 1.735276699066162
Batch 62/64 loss: 1.8416862487792969
Batch 63/64 loss: 1.823681354522705
Batch 64/64 loss: 0.5031156539916992
Epoch 290  Train loss: 1.981756685294357  Val loss: 1.6131375171884228
Epoch 291
-------------------------------
Batch 1/64 loss: 3.8164448738098145
Batch 2/64 loss: 2.078639507293701
Batch 3/64 loss: 2.0502753257751465
Batch 4/64 loss: 2.8286876678466797
Batch 5/64 loss: 1.6179604530334473
Batch 6/64 loss: 2.4416775703430176
Batch 7/64 loss: 2.746339797973633
Batch 8/64 loss: 1.8993358612060547
Batch 9/64 loss: 1.6721210479736328
Batch 10/64 loss: 4.373009204864502
Batch 11/64 loss: 1.8804187774658203
Batch 12/64 loss: 1.7722692489624023
Batch 13/64 loss: 1.7305121421813965
Batch 14/64 loss: 1.6800904273986816
Batch 15/64 loss: 1.6115703582763672
Batch 16/64 loss: 2.0197057723999023
Batch 17/64 loss: 1.7642083168029785
Batch 18/64 loss: 1.7865676879882812
Batch 19/64 loss: 1.9782147407531738
Batch 20/64 loss: 1.797506332397461
Batch 21/64 loss: 1.717432975769043
Batch 22/64 loss: 1.7356514930725098
Batch 23/64 loss: 1.983896255493164
Batch 24/64 loss: 1.8063359260559082
Batch 25/64 loss: 1.7841715812683105
Batch 26/64 loss: 1.7078032493591309
Batch 27/64 loss: 1.6840004920959473
Batch 28/64 loss: 1.7770538330078125
Batch 29/64 loss: 1.8244585990905762
Batch 30/64 loss: 1.7949204444885254
Batch 31/64 loss: 2.725095748901367
Batch 32/64 loss: 1.8970274925231934
Batch 33/64 loss: 1.9990572929382324
Batch 34/64 loss: 1.8105473518371582
Batch 35/64 loss: 1.7259211540222168
Batch 36/64 loss: 1.7384843826293945
Batch 37/64 loss: 1.7068166732788086
Batch 38/64 loss: 1.7734694480895996
Batch 39/64 loss: 1.6433920860290527
Batch 40/64 loss: 1.82096529006958
Batch 41/64 loss: 1.6632180213928223
Batch 42/64 loss: 1.6491594314575195
Batch 43/64 loss: 1.813936710357666
Batch 44/64 loss: 2.258354663848877
Batch 45/64 loss: 1.6277766227722168
Batch 46/64 loss: 1.77229642868042
Batch 47/64 loss: 1.9294328689575195
Batch 48/64 loss: 1.852494716644287
Batch 49/64 loss: 1.970536708831787
Batch 50/64 loss: 1.6113924980163574
Batch 51/64 loss: 1.8208403587341309
Batch 52/64 loss: 1.6006155014038086
Batch 53/64 loss: 1.837615966796875
Batch 54/64 loss: 1.7287812232971191
Batch 55/64 loss: 4.766587734222412
Batch 56/64 loss: 1.695772647857666
Batch 57/64 loss: 1.5761985778808594
Batch 58/64 loss: 1.6415300369262695
Batch 59/64 loss: 1.8681979179382324
Batch 60/64 loss: 1.838705062866211
Batch 61/64 loss: 2.9269185066223145
Batch 62/64 loss: 1.724370002746582
Batch 63/64 loss: 1.748283863067627
Batch 64/64 loss: -1.6726350784301758
Epoch 291  Train loss: 1.943068182702158  Val loss: 1.4796283761250604
Epoch 292
-------------------------------
Batch 1/64 loss: 2.782015800476074
Batch 2/64 loss: 2.264035224914551
Batch 3/64 loss: 1.7508435249328613
Batch 4/64 loss: 1.7256388664245605
Batch 5/64 loss: 1.8876090049743652
Batch 6/64 loss: 1.6732521057128906
Batch 7/64 loss: 1.6380319595336914
Batch 8/64 loss: 1.8839569091796875
Batch 9/64 loss: 1.6552329063415527
Batch 10/64 loss: 1.6991291046142578
Batch 11/64 loss: 1.6508007049560547
Batch 12/64 loss: 1.813218116760254
Batch 13/64 loss: 1.895911693572998
Batch 14/64 loss: 1.7408699989318848
Batch 15/64 loss: 1.6881680488586426
Batch 16/64 loss: 1.538942813873291
Batch 17/64 loss: 1.7272496223449707
Batch 18/64 loss: 1.6738128662109375
Batch 19/64 loss: 2.122448444366455
Batch 20/64 loss: 2.8690991401672363
Batch 21/64 loss: 1.751701831817627
Batch 22/64 loss: 1.6514196395874023
Batch 23/64 loss: 4.237100124359131
Batch 24/64 loss: 1.897629737854004
Batch 25/64 loss: 4.61496114730835
Batch 26/64 loss: 1.850409984588623
Batch 27/64 loss: 1.7124547958374023
Batch 28/64 loss: 1.7624564170837402
Batch 29/64 loss: 1.726792812347412
Batch 30/64 loss: 1.6991815567016602
Batch 31/64 loss: 1.5483369827270508
Batch 32/64 loss: 1.9491243362426758
Batch 33/64 loss: 1.616713047027588
Batch 34/64 loss: 1.7772917747497559
Batch 35/64 loss: 1.7534852027893066
Batch 36/64 loss: 1.8597517013549805
Batch 37/64 loss: 2.4046216011047363
Batch 38/64 loss: 1.71812105178833
Batch 39/64 loss: 1.8894190788269043
Batch 40/64 loss: 2.3816986083984375
Batch 41/64 loss: 1.9744806289672852
Batch 42/64 loss: 1.9054851531982422
Batch 43/64 loss: 1.8727502822875977
Batch 44/64 loss: 1.642624855041504
Batch 45/64 loss: 1.6904706954956055
Batch 46/64 loss: 1.689298152923584
Batch 47/64 loss: 1.7443041801452637
Batch 48/64 loss: 1.6753439903259277
Batch 49/64 loss: 1.7068109512329102
Batch 50/64 loss: 1.9995341300964355
Batch 51/64 loss: 1.655752182006836
Batch 52/64 loss: 1.6667742729187012
Batch 53/64 loss: 1.84625244140625
Batch 54/64 loss: 1.9041991233825684
Batch 55/64 loss: 1.6914091110229492
Batch 56/64 loss: 2.7250452041625977
Batch 57/64 loss: 3.956979274749756
Batch 58/64 loss: 1.7518901824951172
Batch 59/64 loss: 1.6710944175720215
Batch 60/64 loss: 1.8134469985961914
Batch 61/64 loss: 1.5944938659667969
Batch 62/64 loss: 1.9015941619873047
Batch 63/64 loss: 1.6431798934936523
Batch 64/64 loss: -1.6677398681640625
Epoch 292  Train loss: 1.9130250594195197  Val loss: 1.4984939942245221
Epoch 293
-------------------------------
Batch 1/64 loss: 1.6781220436096191
Batch 2/64 loss: 1.6615538597106934
Batch 3/64 loss: 1.6155791282653809
Batch 4/64 loss: 1.721609115600586
Batch 5/64 loss: 1.8633818626403809
Batch 6/64 loss: 1.7078495025634766
Batch 7/64 loss: 1.7990078926086426
Batch 8/64 loss: 1.7731847763061523
Batch 9/64 loss: 1.714038372039795
Batch 10/64 loss: 1.8621416091918945
Batch 11/64 loss: 1.764627456665039
Batch 12/64 loss: 1.5838508605957031
Batch 13/64 loss: 1.8749842643737793
Batch 14/64 loss: 1.9746828079223633
Batch 15/64 loss: 1.7694263458251953
Batch 16/64 loss: 1.6859617233276367
Batch 17/64 loss: 1.819580078125
Batch 18/64 loss: 1.6737627983093262
Batch 19/64 loss: 1.7424407005310059
Batch 20/64 loss: 1.690462589263916
Batch 21/64 loss: 1.7605695724487305
Batch 22/64 loss: 1.8009343147277832
Batch 23/64 loss: 2.4568324089050293
Batch 24/64 loss: 1.7625484466552734
Batch 25/64 loss: 2.055194854736328
Batch 26/64 loss: 1.760481834411621
Batch 27/64 loss: 1.6846122741699219
Batch 28/64 loss: 2.058460235595703
Batch 29/64 loss: 4.184200286865234
Batch 30/64 loss: 2.0377821922302246
Batch 31/64 loss: 1.674609661102295
Batch 32/64 loss: 3.8993310928344727
Batch 33/64 loss: 1.6228713989257812
Batch 34/64 loss: 4.623306751251221
Batch 35/64 loss: 3.144090175628662
Batch 36/64 loss: 1.7423396110534668
Batch 37/64 loss: 1.6746368408203125
Batch 38/64 loss: 1.794145107269287
Batch 39/64 loss: 1.688950538635254
Batch 40/64 loss: 3.0783591270446777
Batch 41/64 loss: 1.7875614166259766
Batch 42/64 loss: 2.969111919403076
Batch 43/64 loss: 1.7749176025390625
Batch 44/64 loss: 1.6655817031860352
Batch 45/64 loss: 1.663886547088623
Batch 46/64 loss: 1.6580634117126465
Batch 47/64 loss: 1.893357753753662
Batch 48/64 loss: 1.7737345695495605
Batch 49/64 loss: 1.6534056663513184
Batch 50/64 loss: 2.6080408096313477
Batch 51/64 loss: 1.9966936111450195
Batch 52/64 loss: 1.7642607688903809
Batch 53/64 loss: 1.769946575164795
Batch 54/64 loss: 1.8384828567504883
Batch 55/64 loss: 1.6855292320251465
Batch 56/64 loss: 1.7895054817199707
Batch 57/64 loss: 2.2032012939453125
Batch 58/64 loss: 1.639845848083496
Batch 59/64 loss: 1.5986056327819824
Batch 60/64 loss: 1.7620644569396973
Batch 61/64 loss: 1.8782806396484375
Batch 62/64 loss: 1.6782917976379395
Batch 63/64 loss: 1.5949382781982422
Batch 64/64 loss: -1.7547340393066406
Epoch 293  Train loss: 1.9264590095071232  Val loss: 1.5043970219458092
Epoch 294
-------------------------------
Batch 1/64 loss: 1.9743103981018066
Batch 2/64 loss: 4.100639343261719
Batch 3/64 loss: 1.6095008850097656
Batch 4/64 loss: 1.9981937408447266
Batch 5/64 loss: 1.8000259399414062
Batch 6/64 loss: 2.2356367111206055
Batch 7/64 loss: 1.8018107414245605
Batch 8/64 loss: 1.875905990600586
Batch 9/64 loss: 2.2115345001220703
Batch 10/64 loss: 2.123791217803955
Batch 11/64 loss: 2.5834298133850098
Batch 12/64 loss: 3.019482135772705
Batch 13/64 loss: 2.022698402404785
Batch 14/64 loss: 3.559957504272461
Batch 15/64 loss: 2.4921135902404785
Batch 16/64 loss: 2.6499414443969727
Batch 17/64 loss: 2.6982293128967285
Batch 18/64 loss: 3.2489757537841797
Batch 19/64 loss: 2.6636829376220703
Batch 20/64 loss: 2.3591179847717285
Batch 21/64 loss: 2.1481785774230957
Batch 22/64 loss: 1.994950771331787
Batch 23/64 loss: 2.219144344329834
Batch 24/64 loss: 2.265258312225342
Batch 25/64 loss: 2.1641769409179688
Batch 26/64 loss: 2.742250442504883
Batch 27/64 loss: 2.443795680999756
Batch 28/64 loss: 5.870311737060547
Batch 29/64 loss: 2.8803625106811523
Batch 30/64 loss: 2.331063747406006
Batch 31/64 loss: 2.9692444801330566
Batch 32/64 loss: 1.9716124534606934
Batch 33/64 loss: 2.156230926513672
Batch 34/64 loss: 3.431816577911377
Batch 35/64 loss: 3.119140625
Batch 36/64 loss: 2.0431270599365234
Batch 37/64 loss: 4.4208855628967285
Batch 38/64 loss: 2.6304802894592285
Batch 39/64 loss: 2.938544273376465
Batch 40/64 loss: 2.1642637252807617
Batch 41/64 loss: 2.370547294616699
Batch 42/64 loss: 2.351590156555176
Batch 43/64 loss: 2.5006794929504395
Batch 44/64 loss: 2.274623394012451
Batch 45/64 loss: 2.0060410499572754
Batch 46/64 loss: 2.9896488189697266
Batch 47/64 loss: 2.0936193466186523
Batch 48/64 loss: 3.4215750694274902
Batch 49/64 loss: 2.2642974853515625
Batch 50/64 loss: 2.081801414489746
Batch 51/64 loss: 1.8982534408569336
Batch 52/64 loss: 1.9294486045837402
Batch 53/64 loss: 2.370513439178467
Batch 54/64 loss: 2.0423598289489746
Batch 55/64 loss: 2.0930538177490234
Batch 56/64 loss: 1.9037442207336426
Batch 57/64 loss: 2.6986122131347656
Batch 58/64 loss: 3.3986239433288574
Batch 59/64 loss: 2.1402549743652344
Batch 60/64 loss: 2.3551430702209473
Batch 61/64 loss: 2.0789060592651367
Batch 62/64 loss: 1.7867693901062012
Batch 63/64 loss: 2.8563480377197266
Batch 64/64 loss: -1.1147756576538086
Epoch 294  Train loss: 2.4628108267690623  Val loss: 1.9397714818056506
Epoch 295
-------------------------------
Batch 1/64 loss: 2.031454563140869
Batch 2/64 loss: 2.062572479248047
Batch 3/64 loss: 3.209014892578125
Batch 4/64 loss: 2.124606132507324
Batch 5/64 loss: 4.440981388092041
Batch 6/64 loss: 1.8661603927612305
Batch 7/64 loss: 1.8810844421386719
Batch 8/64 loss: 2.19981050491333
Batch 9/64 loss: 1.954690933227539
Batch 10/64 loss: 1.972172737121582
Batch 11/64 loss: 2.168030261993408
Batch 12/64 loss: 4.060856819152832
Batch 13/64 loss: 2.314377784729004
Batch 14/64 loss: 1.732480525970459
Batch 15/64 loss: 2.284970283508301
Batch 16/64 loss: 3.0704879760742188
Batch 17/64 loss: 1.857710361480713
Batch 18/64 loss: 1.822160243988037
Batch 19/64 loss: 1.8965377807617188
Batch 20/64 loss: 2.2332205772399902
Batch 21/64 loss: 2.1003265380859375
Batch 22/64 loss: 1.9267964363098145
Batch 23/64 loss: 2.2073278427124023
Batch 24/64 loss: 2.2166061401367188
Batch 25/64 loss: 2.7656030654907227
Batch 26/64 loss: 1.8831443786621094
Batch 27/64 loss: 1.7311897277832031
Batch 28/64 loss: 2.7810287475585938
Batch 29/64 loss: 1.7702960968017578
Batch 30/64 loss: 1.9401803016662598
Batch 31/64 loss: 2.181671142578125
Batch 32/64 loss: 2.111571788787842
Batch 33/64 loss: 1.8042025566101074
Batch 34/64 loss: 1.7343993186950684
Batch 35/64 loss: 2.301030158996582
Batch 36/64 loss: 1.847661018371582
Batch 37/64 loss: 1.9765586853027344
Batch 38/64 loss: 2.368490219116211
Batch 39/64 loss: 1.7603859901428223
Batch 40/64 loss: 2.6995396614074707
Batch 41/64 loss: 1.8434524536132812
Batch 42/64 loss: 1.9004740715026855
Batch 43/64 loss: 1.9298458099365234
Batch 44/64 loss: 1.9789371490478516
Batch 45/64 loss: 2.434903144836426
Batch 46/64 loss: 2.0866146087646484
Batch 47/64 loss: 1.7965879440307617
Batch 48/64 loss: 1.755826473236084
Batch 49/64 loss: 4.747772216796875
Batch 50/64 loss: 1.918100357055664
Batch 51/64 loss: 2.101736545562744
Batch 52/64 loss: 2.1707944869995117
Batch 53/64 loss: 1.7809648513793945
Batch 54/64 loss: 1.7602596282958984
Batch 55/64 loss: 3.0013208389282227
Batch 56/64 loss: 1.8922104835510254
Batch 57/64 loss: 1.8618240356445312
Batch 58/64 loss: 1.819483757019043
Batch 59/64 loss: 1.7944355010986328
Batch 60/64 loss: 1.818307876586914
Batch 61/64 loss: 1.815903663635254
Batch 62/64 loss: 2.1577367782592773
Batch 63/64 loss: 1.7973742485046387
Batch 64/64 loss: -1.6174964904785156
Epoch 295  Train loss: 2.137147222780714  Val loss: 1.6643152400800043
Epoch 296
-------------------------------
Batch 1/64 loss: 1.8019566535949707
Batch 2/64 loss: 1.9752798080444336
Batch 3/64 loss: 2.1598291397094727
Batch 4/64 loss: 2.2279276847839355
Batch 5/64 loss: 1.7932181358337402
Batch 6/64 loss: 1.791883945465088
Batch 7/64 loss: 1.8253107070922852
Batch 8/64 loss: 1.9530010223388672
Batch 9/64 loss: 1.7503843307495117
Batch 10/64 loss: 3.9732141494750977
Batch 11/64 loss: 1.9102773666381836
Batch 12/64 loss: 2.0304627418518066
Batch 13/64 loss: 2.6945137977600098
Batch 14/64 loss: 2.4890308380126953
Batch 15/64 loss: 2.2732229232788086
Batch 16/64 loss: 1.7527365684509277
Batch 17/64 loss: 2.2484078407287598
Batch 18/64 loss: 2.0907979011535645
Batch 19/64 loss: 1.8728175163269043
Batch 20/64 loss: 1.9218831062316895
Batch 21/64 loss: 1.7632989883422852
Batch 22/64 loss: 1.7875704765319824
Batch 23/64 loss: 1.8013124465942383
Batch 24/64 loss: 1.7780733108520508
Batch 25/64 loss: 1.9645805358886719
Batch 26/64 loss: 4.340267181396484
Batch 27/64 loss: 1.7913117408752441
Batch 28/64 loss: 2.3906631469726562
Batch 29/64 loss: 1.7722430229187012
Batch 30/64 loss: 1.7527961730957031
Batch 31/64 loss: 4.714268684387207
Batch 32/64 loss: 1.6724767684936523
Batch 33/64 loss: 1.9062809944152832
Batch 34/64 loss: 2.0483012199401855
Batch 35/64 loss: 1.8300080299377441
Batch 36/64 loss: 1.893205165863037
Batch 37/64 loss: 1.9373345375061035
Batch 38/64 loss: 1.8262720108032227
Batch 39/64 loss: 1.8827929496765137
Batch 40/64 loss: 1.6569223403930664
Batch 41/64 loss: 2.328556537628174
Batch 42/64 loss: 1.7646183967590332
Batch 43/64 loss: 1.7730226516723633
Batch 44/64 loss: 1.7168941497802734
Batch 45/64 loss: 2.050065517425537
Batch 46/64 loss: 3.7550220489501953
Batch 47/64 loss: 1.8763351440429688
Batch 48/64 loss: 1.7703471183776855
Batch 49/64 loss: 1.7486329078674316
Batch 50/64 loss: 1.906571388244629
Batch 51/64 loss: 1.6846518516540527
Batch 52/64 loss: 1.8630757331848145
Batch 53/64 loss: 1.9669785499572754
Batch 54/64 loss: 2.0182251930236816
Batch 55/64 loss: 1.795130729675293
Batch 56/64 loss: 1.749506950378418
Batch 57/64 loss: 1.6785202026367188
Batch 58/64 loss: 1.8422174453735352
Batch 59/64 loss: 1.6985621452331543
Batch 60/64 loss: 1.7857232093811035
Batch 61/64 loss: 2.0141167640686035
Batch 62/64 loss: 1.7167024612426758
Batch 63/64 loss: 1.6857595443725586
Batch 64/64 loss: -1.5743303298950195
Epoch 296  Train loss: 2.0086999967986463  Val loss: 1.5446963490489423
Epoch 297
-------------------------------
Batch 1/64 loss: 1.8612937927246094
Batch 2/64 loss: 1.9371371269226074
Batch 3/64 loss: 2.7072677612304688
Batch 4/64 loss: 1.705047607421875
Batch 5/64 loss: 1.9304676055908203
Batch 6/64 loss: 1.8288369178771973
Batch 7/64 loss: 2.6518564224243164
Batch 8/64 loss: 4.663776397705078
Batch 9/64 loss: 1.7612814903259277
Batch 10/64 loss: 1.6801657676696777
Batch 11/64 loss: 1.8262381553649902
Batch 12/64 loss: 1.6663107872009277
Batch 13/64 loss: 1.882051944732666
Batch 14/64 loss: 1.722181797027588
Batch 15/64 loss: 1.8692903518676758
Batch 16/64 loss: 1.6665029525756836
Batch 17/64 loss: 1.786128044128418
Batch 18/64 loss: 1.6239161491394043
Batch 19/64 loss: 2.603606700897217
Batch 20/64 loss: 1.7627229690551758
Batch 21/64 loss: 1.7469544410705566
Batch 22/64 loss: 4.817178249359131
Batch 23/64 loss: 1.7515721321105957
Batch 24/64 loss: 1.624497413635254
Batch 25/64 loss: 1.8878498077392578
Batch 26/64 loss: 1.874577522277832
Batch 27/64 loss: 1.9139199256896973
Batch 28/64 loss: 1.7612528800964355
Batch 29/64 loss: 1.7312202453613281
Batch 30/64 loss: 1.7846083641052246
Batch 31/64 loss: 1.8064146041870117
Batch 32/64 loss: 1.769345760345459
Batch 33/64 loss: 1.8260431289672852
Batch 34/64 loss: 1.8439135551452637
Batch 35/64 loss: 4.346002578735352
Batch 36/64 loss: 1.63545560836792
Batch 37/64 loss: 1.9567289352416992
Batch 38/64 loss: 1.9286727905273438
Batch 39/64 loss: 2.3427186012268066
Batch 40/64 loss: 1.9939484596252441
Batch 41/64 loss: 1.8503260612487793
Batch 42/64 loss: 2.0979247093200684
Batch 43/64 loss: 1.770559310913086
Batch 44/64 loss: 2.122270107269287
Batch 45/64 loss: 1.6949634552001953
Batch 46/64 loss: 2.1610493659973145
Batch 47/64 loss: 1.7791099548339844
Batch 48/64 loss: 1.7142448425292969
Batch 49/64 loss: 1.8247485160827637
Batch 50/64 loss: 2.015160083770752
Batch 51/64 loss: 1.816312313079834
Batch 52/64 loss: 1.8734970092773438
Batch 53/64 loss: 2.047342300415039
Batch 54/64 loss: 1.7585721015930176
Batch 55/64 loss: 2.1181387901306152
Batch 56/64 loss: 1.6861872673034668
Batch 57/64 loss: 1.790541648864746
Batch 58/64 loss: 1.8912839889526367
Batch 59/64 loss: 1.8486700057983398
Batch 60/64 loss: 2.1219840049743652
Batch 61/64 loss: 1.9122376441955566
Batch 62/64 loss: 1.786290168762207
Batch 63/64 loss: 1.7272891998291016
Batch 64/64 loss: -1.414280891418457
Epoch 297  Train loss: 1.973756045921176  Val loss: 1.5652851222716655
Epoch 298
-------------------------------
Batch 1/64 loss: 2.0293588638305664
Batch 2/64 loss: 1.8362069129943848
Batch 3/64 loss: 1.7521705627441406
Batch 4/64 loss: 2.6538233757019043
Batch 5/64 loss: 1.7975172996520996
Batch 6/64 loss: 1.9505786895751953
Batch 7/64 loss: 1.8101897239685059
Batch 8/64 loss: 1.8114304542541504
Batch 9/64 loss: 4.631608486175537
Batch 10/64 loss: 1.8072843551635742
Batch 11/64 loss: 2.8438057899475098
Batch 12/64 loss: 1.7667484283447266
Batch 13/64 loss: 2.1836509704589844
Batch 14/64 loss: 1.9325852394104004
Batch 15/64 loss: 1.9024276733398438
Batch 16/64 loss: 1.8612756729125977
Batch 17/64 loss: 1.938105583190918
Batch 18/64 loss: 1.8414993286132812
Batch 19/64 loss: 1.8143959045410156
Batch 20/64 loss: 1.7416372299194336
Batch 21/64 loss: 1.8027114868164062
Batch 22/64 loss: 1.9106502532958984
Batch 23/64 loss: 1.7708168029785156
Batch 24/64 loss: 1.8502368927001953
Batch 25/64 loss: 1.8510808944702148
Batch 26/64 loss: 1.8048977851867676
Batch 27/64 loss: 1.6844592094421387
Batch 28/64 loss: 1.8653669357299805
Batch 29/64 loss: 1.8314709663391113
Batch 30/64 loss: 1.7153987884521484
Batch 31/64 loss: 1.7291293144226074
Batch 32/64 loss: 2.892451286315918
Batch 33/64 loss: 1.7018108367919922
Batch 34/64 loss: 1.6678037643432617
Batch 35/64 loss: 1.8899312019348145
Batch 36/64 loss: 1.777451992034912
Batch 37/64 loss: 2.0686254501342773
Batch 38/64 loss: 2.0843844413757324
Batch 39/64 loss: 1.7164955139160156
Batch 40/64 loss: 1.947751522064209
Batch 41/64 loss: 1.6210370063781738
Batch 42/64 loss: 4.212670803070068
Batch 43/64 loss: 2.0138020515441895
Batch 44/64 loss: 1.9896464347839355
Batch 45/64 loss: 1.9170684814453125
Batch 46/64 loss: 3.96889066696167
Batch 47/64 loss: 1.7521858215332031
Batch 48/64 loss: 1.8027544021606445
Batch 49/64 loss: 1.7638015747070312
Batch 50/64 loss: 1.8908143043518066
Batch 51/64 loss: 1.7171401977539062
Batch 52/64 loss: 2.338717460632324
Batch 53/64 loss: 1.6879348754882812
Batch 54/64 loss: 1.9848346710205078
Batch 55/64 loss: 1.7188353538513184
Batch 56/64 loss: 1.8041186332702637
Batch 57/64 loss: 1.6331119537353516
Batch 58/64 loss: 1.7941670417785645
Batch 59/64 loss: 1.9204740524291992
Batch 60/64 loss: 1.7983016967773438
Batch 61/64 loss: 2.140286922454834
Batch 62/64 loss: 1.8085827827453613
Batch 63/64 loss: 1.7362980842590332
Batch 64/64 loss: -1.0421247482299805
Epoch 298  Train loss: 1.9718134524775486  Val loss: 1.533178794834622
Epoch 299
-------------------------------
Batch 1/64 loss: 2.285390853881836
Batch 2/64 loss: 2.4140992164611816
Batch 3/64 loss: 1.8038239479064941
Batch 4/64 loss: 1.7283663749694824
Batch 5/64 loss: 1.7738194465637207
Batch 6/64 loss: 1.7511653900146484
Batch 7/64 loss: 1.9064054489135742
Batch 8/64 loss: 1.6306800842285156
Batch 9/64 loss: 1.865063190460205
Batch 10/64 loss: 1.7522401809692383
Batch 11/64 loss: 1.9074702262878418
Batch 12/64 loss: 1.7501554489135742
Batch 13/64 loss: 2.149782180786133
Batch 14/64 loss: 1.7013516426086426
Batch 15/64 loss: 1.661306381225586
Batch 16/64 loss: 2.152675151824951
Batch 17/64 loss: 2.014495372772217
Batch 18/64 loss: 1.8377785682678223
Batch 19/64 loss: 1.6232242584228516
Batch 20/64 loss: 1.6614141464233398
Batch 21/64 loss: 1.7468342781066895
Batch 22/64 loss: 1.820511817932129
Batch 23/64 loss: 1.6234502792358398
Batch 24/64 loss: 1.8374152183532715
Batch 25/64 loss: 1.7004690170288086
Batch 26/64 loss: 1.7312211990356445
Batch 27/64 loss: 4.674110412597656
Batch 28/64 loss: 1.8227863311767578
Batch 29/64 loss: 1.8593902587890625
Batch 30/64 loss: 1.7696013450622559
Batch 31/64 loss: 1.7455267906188965
Batch 32/64 loss: 1.7208714485168457
Batch 33/64 loss: 1.7589516639709473
Batch 34/64 loss: 1.7814455032348633
Batch 35/64 loss: 1.7051291465759277
Batch 36/64 loss: 1.9265155792236328
Batch 37/64 loss: 1.8144288063049316
Batch 38/64 loss: 1.8273544311523438
Batch 39/64 loss: 1.7310528755187988
Batch 40/64 loss: 1.8059234619140625
Batch 41/64 loss: 2.2047247886657715
Batch 42/64 loss: 2.952672004699707
Batch 43/64 loss: 1.7554941177368164
Batch 44/64 loss: 2.5079774856567383
Batch 45/64 loss: 1.7971253395080566
Batch 46/64 loss: 1.8329882621765137
Batch 47/64 loss: 1.7998461723327637
Batch 48/64 loss: 4.150491714477539
Batch 49/64 loss: 1.8024721145629883
Batch 50/64 loss: 3.0759215354919434
Batch 51/64 loss: 1.8829660415649414
Batch 52/64 loss: 1.7641167640686035
Batch 53/64 loss: 1.8675365447998047
Batch 54/64 loss: 1.779745101928711
Batch 55/64 loss: 1.7618012428283691
Batch 56/64 loss: 1.759857177734375
Batch 57/64 loss: 1.7921342849731445
Batch 58/64 loss: 1.9078874588012695
Batch 59/64 loss: 1.8919973373413086
Batch 60/64 loss: 1.7825613021850586
Batch 61/64 loss: 1.758704662322998
Batch 62/64 loss: 4.286623954772949
Batch 63/64 loss: 1.7565836906433105
Batch 64/64 loss: -1.6476984024047852
Epoch 299  Train loss: 1.9515318066466087  Val loss: 1.55943940677184
Epoch 300
-------------------------------
Batch 1/64 loss: 3.078282356262207
Batch 2/64 loss: 1.7112503051757812
Batch 3/64 loss: 1.9031944274902344
Batch 4/64 loss: 1.7563023567199707
Batch 5/64 loss: 1.842841625213623
Batch 6/64 loss: 4.524003505706787
Batch 7/64 loss: 4.260737419128418
Batch 8/64 loss: 1.6571474075317383
Batch 9/64 loss: 1.8146047592163086
Batch 10/64 loss: 1.7761878967285156
Batch 11/64 loss: 1.6645879745483398
Batch 12/64 loss: 2.2134885787963867
Batch 13/64 loss: 4.653452396392822
Batch 14/64 loss: 1.8658275604248047
Batch 15/64 loss: 3.0166401863098145
Batch 16/64 loss: 2.041797637939453
Batch 17/64 loss: 1.9471845626831055
Batch 18/64 loss: 1.8766980171203613
Batch 19/64 loss: 1.7167515754699707
Batch 20/64 loss: 1.853567123413086
Batch 21/64 loss: 2.361433506011963
Batch 22/64 loss: 1.7810087203979492
Batch 23/64 loss: 1.7046093940734863
Batch 24/64 loss: 1.7752604484558105
Batch 25/64 loss: 1.6698269844055176
Batch 26/64 loss: 1.9933857917785645
Batch 27/64 loss: 1.9303359985351562
Batch 28/64 loss: 2.0401062965393066
Batch 29/64 loss: 1.663219928741455
Batch 30/64 loss: 1.7261710166931152
Batch 31/64 loss: 1.6689324378967285
Batch 32/64 loss: 1.7517733573913574
Batch 33/64 loss: 1.970005989074707
Batch 34/64 loss: 1.7385320663452148
Batch 35/64 loss: 1.7849617004394531
Batch 36/64 loss: 2.2002673149108887
Batch 37/64 loss: 1.6176137924194336
Batch 38/64 loss: 1.6768226623535156
Batch 39/64 loss: 1.8469176292419434
Batch 40/64 loss: 2.097055435180664
Batch 41/64 loss: 1.7207679748535156
Batch 42/64 loss: 3.0417633056640625
Batch 43/64 loss: 1.8246631622314453
Batch 44/64 loss: 1.6523985862731934
Batch 45/64 loss: 1.8373117446899414
Batch 46/64 loss: 1.734910488128662
Batch 47/64 loss: 1.8289518356323242
Batch 48/64 loss: 1.8410282135009766
Batch 49/64 loss: 1.688326358795166
Batch 50/64 loss: 1.642199993133545
Batch 51/64 loss: 1.665600299835205
Batch 52/64 loss: 1.9643588066101074
Batch 53/64 loss: 2.044369697570801
Batch 54/64 loss: 1.7286906242370605
Batch 55/64 loss: 1.6568927764892578
Batch 56/64 loss: 1.980353832244873
Batch 57/64 loss: 1.8093419075012207
Batch 58/64 loss: 1.7697792053222656
Batch 59/64 loss: 1.9370646476745605
Batch 60/64 loss: 1.76133394241333
Batch 61/64 loss: 1.9504103660583496
Batch 62/64 loss: 1.7644662857055664
Batch 63/64 loss: 1.7096633911132812
Batch 64/64 loss: -1.5903797149658203
Epoch 300  Train loss: 1.9691709929821537  Val loss: 1.5023035790092756
Epoch 301
-------------------------------
Batch 1/64 loss: 1.7133512496948242
Batch 2/64 loss: 1.642733097076416
Batch 3/64 loss: 2.368854522705078
Batch 4/64 loss: 1.6166887283325195
Batch 5/64 loss: 1.888617992401123
Batch 6/64 loss: 1.7709498405456543
Batch 7/64 loss: 1.7394614219665527
Batch 8/64 loss: 3.8649072647094727
Batch 9/64 loss: 1.598391056060791
Batch 10/64 loss: 1.8075079917907715
Batch 11/64 loss: 1.8217272758483887
Batch 12/64 loss: 1.6664485931396484
Batch 13/64 loss: 4.153451919555664
Batch 14/64 loss: 1.8967208862304688
Batch 15/64 loss: 1.7874760627746582
Batch 16/64 loss: 1.806185245513916
Batch 17/64 loss: 1.6529841423034668
Batch 18/64 loss: 1.805068016052246
Batch 19/64 loss: 2.041111946105957
Batch 20/64 loss: 1.9570684432983398
Batch 21/64 loss: 1.828744888305664
Batch 22/64 loss: 1.6863150596618652
Batch 23/64 loss: 1.6885323524475098
Batch 24/64 loss: 2.3647546768188477
Batch 25/64 loss: 2.095982551574707
Batch 26/64 loss: 1.8656864166259766
Batch 27/64 loss: 1.7965574264526367
Batch 28/64 loss: 1.9875969886779785
Batch 29/64 loss: 2.004085063934326
Batch 30/64 loss: 1.8119640350341797
Batch 31/64 loss: 1.9572367668151855
Batch 32/64 loss: 1.7690110206604004
Batch 33/64 loss: 2.3364124298095703
Batch 34/64 loss: 1.7498393058776855
Batch 35/64 loss: 1.6770281791687012
Batch 36/64 loss: 1.996131420135498
Batch 37/64 loss: 1.8271503448486328
Batch 38/64 loss: 1.9685792922973633
Batch 39/64 loss: 1.724125862121582
Batch 40/64 loss: 1.812495231628418
Batch 41/64 loss: 1.8403043746948242
Batch 42/64 loss: 1.7490110397338867
Batch 43/64 loss: 2.55073881149292
Batch 44/64 loss: 1.6280417442321777
Batch 45/64 loss: 1.5832548141479492
Batch 46/64 loss: 1.7567815780639648
Batch 47/64 loss: 2.831155300140381
Batch 48/64 loss: 1.7791461944580078
Batch 49/64 loss: 1.7036056518554688
Batch 50/64 loss: 1.9987297058105469
Batch 51/64 loss: 1.840916633605957
Batch 52/64 loss: 4.593669414520264
Batch 53/64 loss: 1.6627321243286133
Batch 54/64 loss: 1.837085247039795
Batch 55/64 loss: 2.0357918739318848
Batch 56/64 loss: 1.721447467803955
Batch 57/64 loss: 2.7833399772644043
Batch 58/64 loss: 2.2300190925598145
Batch 59/64 loss: 2.1126513481140137
Batch 60/64 loss: 1.7275290489196777
Batch 61/64 loss: 1.803147315979004
Batch 62/64 loss: 1.8341422080993652
Batch 63/64 loss: 2.148928642272949
Batch 64/64 loss: -1.7393264770507812
Epoch 301  Train loss: 1.9607154472201478  Val loss: 1.6032202809127336
Epoch 302
-------------------------------
Batch 1/64 loss: 1.998295783996582
Batch 2/64 loss: 4.719058513641357
Batch 3/64 loss: 1.6849098205566406
Batch 4/64 loss: 1.9331684112548828
Batch 5/64 loss: 1.7476439476013184
Batch 6/64 loss: 1.8951363563537598
Batch 7/64 loss: 1.8672924041748047
Batch 8/64 loss: 1.7030701637268066
Batch 9/64 loss: 1.6972360610961914
Batch 10/64 loss: 1.7595186233520508
Batch 11/64 loss: 1.7043218612670898
Batch 12/64 loss: 1.8928966522216797
Batch 13/64 loss: 1.8568124771118164
Batch 14/64 loss: 1.8427014350891113
Batch 15/64 loss: 1.6415786743164062
Batch 16/64 loss: 4.006866931915283
Batch 17/64 loss: 1.8090815544128418
Batch 18/64 loss: 1.6882710456848145
Batch 19/64 loss: 1.96467924118042
Batch 20/64 loss: 3.0701727867126465
Batch 21/64 loss: 1.752089500427246
Batch 22/64 loss: 1.7739896774291992
Batch 23/64 loss: 2.1524643898010254
Batch 24/64 loss: 4.420119762420654
Batch 25/64 loss: 1.7400741577148438
Batch 26/64 loss: 1.6668343544006348
Batch 27/64 loss: 1.6876816749572754
Batch 28/64 loss: 1.8262152671813965
Batch 29/64 loss: 1.7963356971740723
Batch 30/64 loss: 1.6650714874267578
Batch 31/64 loss: 1.689842700958252
Batch 32/64 loss: 2.51420259475708
Batch 33/64 loss: 1.7404308319091797
Batch 34/64 loss: 2.7891087532043457
Batch 35/64 loss: 2.0389461517333984
Batch 36/64 loss: 1.7759575843811035
Batch 37/64 loss: 1.672900676727295
Batch 38/64 loss: 2.2125778198242188
Batch 39/64 loss: 1.8903989791870117
Batch 40/64 loss: 2.643141746520996
Batch 41/64 loss: 1.739830493927002
Batch 42/64 loss: 1.6834239959716797
Batch 43/64 loss: 1.6919841766357422
Batch 44/64 loss: 1.7620134353637695
Batch 45/64 loss: 1.8739047050476074
Batch 46/64 loss: 1.7355008125305176
Batch 47/64 loss: 1.8428611755371094
Batch 48/64 loss: 1.64509916305542
Batch 49/64 loss: 1.7487998008728027
Batch 50/64 loss: 1.730278491973877
Batch 51/64 loss: 1.7823295593261719
Batch 52/64 loss: 1.7501206398010254
Batch 53/64 loss: 1.8746538162231445
Batch 54/64 loss: 1.7864885330200195
Batch 55/64 loss: 1.6505317687988281
Batch 56/64 loss: 1.9699673652648926
Batch 57/64 loss: 1.8424749374389648
Batch 58/64 loss: 1.962873935699463
Batch 59/64 loss: 2.801767349243164
Batch 60/64 loss: 1.7766766548156738
Batch 61/64 loss: 1.7224640846252441
Batch 62/64 loss: 2.0882320404052734
Batch 63/64 loss: 1.919428825378418
Batch 64/64 loss: -1.8683910369873047
Epoch 302  Train loss: 1.959396220188515  Val loss: 1.5019645428739463
Epoch 303
-------------------------------
Batch 1/64 loss: 1.7080063819885254
Batch 2/64 loss: 4.645729064941406
Batch 3/64 loss: 1.6574735641479492
Batch 4/64 loss: 1.9243831634521484
Batch 5/64 loss: 1.721360206604004
Batch 6/64 loss: 1.637068748474121
Batch 7/64 loss: 1.6839103698730469
Batch 8/64 loss: 2.6807613372802734
Batch 9/64 loss: 1.8670907020568848
Batch 10/64 loss: 1.7874207496643066
Batch 11/64 loss: 1.8636856079101562
Batch 12/64 loss: 1.7680435180664062
Batch 13/64 loss: 4.051303863525391
Batch 14/64 loss: 1.6723217964172363
Batch 15/64 loss: 1.7472138404846191
Batch 16/64 loss: 2.8130908012390137
Batch 17/64 loss: 1.7762703895568848
Batch 18/64 loss: 1.8498826026916504
Batch 19/64 loss: 1.7288217544555664
Batch 20/64 loss: 1.8011422157287598
Batch 21/64 loss: 1.6823859214782715
Batch 22/64 loss: 1.6944408416748047
Batch 23/64 loss: 1.793539047241211
Batch 24/64 loss: 1.659069538116455
Batch 25/64 loss: 2.6255311965942383
Batch 26/64 loss: 1.6991448402404785
Batch 27/64 loss: 1.5852546691894531
Batch 28/64 loss: 1.7161321640014648
Batch 29/64 loss: 1.9906806945800781
Batch 30/64 loss: 1.8241214752197266
Batch 31/64 loss: 1.7942461967468262
Batch 32/64 loss: 1.7857260704040527
Batch 33/64 loss: 2.8435354232788086
Batch 34/64 loss: 1.7169790267944336
Batch 35/64 loss: 4.008219242095947
Batch 36/64 loss: 1.6325998306274414
Batch 37/64 loss: 1.5895237922668457
Batch 38/64 loss: 1.6793007850646973
Batch 39/64 loss: 1.811826229095459
Batch 40/64 loss: 1.6826238632202148
Batch 41/64 loss: 1.7393698692321777
Batch 42/64 loss: 1.853139877319336
Batch 43/64 loss: 1.643526554107666
Batch 44/64 loss: 1.741074562072754
Batch 45/64 loss: 1.68397855758667
Batch 46/64 loss: 2.38572359085083
Batch 47/64 loss: 1.8255295753479004
Batch 48/64 loss: 1.7517046928405762
Batch 49/64 loss: 1.6888508796691895
Batch 50/64 loss: 1.7192983627319336
Batch 51/64 loss: 2.3450613021850586
Batch 52/64 loss: 1.8155088424682617
Batch 53/64 loss: 1.7076478004455566
Batch 54/64 loss: 1.7593541145324707
Batch 55/64 loss: 1.6838388442993164
Batch 56/64 loss: 1.8697619438171387
Batch 57/64 loss: 1.892202377319336
Batch 58/64 loss: 1.6005406379699707
Batch 59/64 loss: 2.4332356452941895
Batch 60/64 loss: 1.7467002868652344
Batch 61/64 loss: 1.7394671440124512
Batch 62/64 loss: 2.220226287841797
Batch 63/64 loss: 1.811750888824463
Batch 64/64 loss: -1.4368295669555664
Epoch 303  Train loss: 1.9259565802181469  Val loss: 1.611942972923882
Epoch 304
-------------------------------
Batch 1/64 loss: 1.7607269287109375
Batch 2/64 loss: 1.9543185234069824
Batch 3/64 loss: 1.6655359268188477
Batch 4/64 loss: 1.6544885635375977
Batch 5/64 loss: 1.7507343292236328
Batch 6/64 loss: 1.9334683418273926
Batch 7/64 loss: 1.9258337020874023
Batch 8/64 loss: 1.9559249877929688
Batch 9/64 loss: 2.023782253265381
Batch 10/64 loss: 1.990889072418213
Batch 11/64 loss: 2.387784481048584
Batch 12/64 loss: 1.8296494483947754
Batch 13/64 loss: 4.6398749351501465
Batch 14/64 loss: 2.1970419883728027
Batch 15/64 loss: 1.7742881774902344
Batch 16/64 loss: 2.5114455223083496
Batch 17/64 loss: 1.8855810165405273
Batch 18/64 loss: 1.7661914825439453
Batch 19/64 loss: 1.669116497039795
Batch 20/64 loss: 1.7803459167480469
Batch 21/64 loss: 1.714271068572998
Batch 22/64 loss: 2.1974220275878906
Batch 23/64 loss: 2.1689095497131348
Batch 24/64 loss: 1.7684545516967773
Batch 25/64 loss: 1.758958339691162
Batch 26/64 loss: 2.0044760704040527
Batch 27/64 loss: 1.8517403602600098
Batch 28/64 loss: 1.759328842163086
Batch 29/64 loss: 1.8814501762390137
Batch 30/64 loss: 1.8088784217834473
Batch 31/64 loss: 1.6742467880249023
Batch 32/64 loss: 2.41757869720459
Batch 33/64 loss: 1.8133325576782227
Batch 34/64 loss: 1.771815299987793
Batch 35/64 loss: 3.82169771194458
Batch 36/64 loss: 1.7696728706359863
Batch 37/64 loss: 1.9780282974243164
Batch 38/64 loss: 2.065526008605957
Batch 39/64 loss: 2.668363094329834
Batch 40/64 loss: 3.4300127029418945
Batch 41/64 loss: 2.297724723815918
Batch 42/64 loss: 2.505113124847412
Batch 43/64 loss: 2.3956689834594727
Batch 44/64 loss: 2.374061107635498
Batch 45/64 loss: 6.019326210021973
Batch 46/64 loss: 3.2288055419921875
Batch 47/64 loss: 2.244466781616211
Batch 48/64 loss: 2.0765132904052734
Batch 49/64 loss: 2.9609270095825195
Batch 50/64 loss: 2.2061409950256348
Batch 51/64 loss: 2.3851876258850098
Batch 52/64 loss: 2.9448089599609375
Batch 53/64 loss: 2.083556652069092
Batch 54/64 loss: 2.1104745864868164
Batch 55/64 loss: 2.564542293548584
Batch 56/64 loss: 2.436919689178467
Batch 57/64 loss: 2.2828917503356934
Batch 58/64 loss: 3.0666327476501465
Batch 59/64 loss: 3.2013115882873535
Batch 60/64 loss: 2.4411420822143555
Batch 61/64 loss: 2.2482070922851562
Batch 62/64 loss: 1.936408519744873
Batch 63/64 loss: 2.1566286087036133
Batch 64/64 loss: -1.1839771270751953
Epoch 304  Train loss: 2.2378143160950903  Val loss: 2.17876439569742
Epoch 305
-------------------------------
Batch 1/64 loss: 2.2859344482421875
Batch 2/64 loss: 2.192270278930664
Batch 3/64 loss: 2.1946640014648438
Batch 4/64 loss: 2.1450767517089844
Batch 5/64 loss: 2.250277519226074
Batch 6/64 loss: 2.0784010887145996
Batch 7/64 loss: 2.1331992149353027
Batch 8/64 loss: 1.9859919548034668
Batch 9/64 loss: 2.428374767303467
Batch 10/64 loss: 2.2645740509033203
Batch 11/64 loss: 2.6406965255737305
Batch 12/64 loss: 2.746530055999756
Batch 13/64 loss: 2.108835220336914
Batch 14/64 loss: 2.2276439666748047
Batch 15/64 loss: 4.781645774841309
Batch 16/64 loss: 2.416663646697998
Batch 17/64 loss: 4.621863842010498
Batch 18/64 loss: 3.024439811706543
Batch 19/64 loss: 1.801063060760498
Batch 20/64 loss: 2.03291654586792
Batch 21/64 loss: 2.179381847381592
Batch 22/64 loss: 2.2808985710144043
Batch 23/64 loss: 2.104203701019287
Batch 24/64 loss: 1.900461196899414
Batch 25/64 loss: 2.04734468460083
Batch 26/64 loss: 2.0620765686035156
Batch 27/64 loss: 2.077645778656006
Batch 28/64 loss: 2.1881985664367676
Batch 29/64 loss: 1.8912482261657715
Batch 30/64 loss: 1.9356040954589844
Batch 31/64 loss: 2.1744494438171387
Batch 32/64 loss: 1.9348359107971191
Batch 33/64 loss: 2.2478079795837402
Batch 34/64 loss: 3.385481357574463
Batch 35/64 loss: 2.2330856323242188
Batch 36/64 loss: 2.1100573539733887
Batch 37/64 loss: 1.9686918258666992
Batch 38/64 loss: 2.1139674186706543
Batch 39/64 loss: 1.8322796821594238
Batch 40/64 loss: 1.8463759422302246
Batch 41/64 loss: 1.9239554405212402
Batch 42/64 loss: 2.2096567153930664
Batch 43/64 loss: 1.859513759613037
Batch 44/64 loss: 1.9958992004394531
Batch 45/64 loss: 1.854994773864746
Batch 46/64 loss: 2.0024094581604004
Batch 47/64 loss: 2.4884657859802246
Batch 48/64 loss: 1.7789902687072754
Batch 49/64 loss: 1.8294634819030762
Batch 50/64 loss: 2.93135929107666
Batch 51/64 loss: 2.191781997680664
Batch 52/64 loss: 1.9832520484924316
Batch 53/64 loss: 1.782761573791504
Batch 54/64 loss: 1.7876396179199219
Batch 55/64 loss: 2.1183619499206543
Batch 56/64 loss: 2.0816421508789062
Batch 57/64 loss: 1.7740402221679688
Batch 58/64 loss: 1.7897758483886719
Batch 59/64 loss: 1.8042898178100586
Batch 60/64 loss: 1.7890853881835938
Batch 61/64 loss: 4.682565689086914
Batch 62/64 loss: 2.0416646003723145
Batch 63/64 loss: 1.8585076332092285
Batch 64/64 loss: -1.2429533004760742
Epoch 305  Train loss: 2.203968941931631  Val loss: 1.640440675401196
Epoch 306
-------------------------------
Batch 1/64 loss: 2.1571974754333496
Batch 2/64 loss: 2.3200855255126953
Batch 3/64 loss: 1.8673381805419922
Batch 4/64 loss: 1.745424747467041
Batch 5/64 loss: 1.7550039291381836
Batch 6/64 loss: 1.7395071983337402
Batch 7/64 loss: 2.01602840423584
Batch 8/64 loss: 4.0313191413879395
Batch 9/64 loss: 1.689824104309082
Batch 10/64 loss: 1.804419994354248
Batch 11/64 loss: 2.6344780921936035
Batch 12/64 loss: 1.8659319877624512
Batch 13/64 loss: 1.8821449279785156
Batch 14/64 loss: 1.843675136566162
Batch 15/64 loss: 2.073031425476074
Batch 16/64 loss: 2.005174160003662
Batch 17/64 loss: 2.3063297271728516
Batch 18/64 loss: 1.8524513244628906
Batch 19/64 loss: 1.8765625953674316
Batch 20/64 loss: 2.014310836791992
Batch 21/64 loss: 1.6961030960083008
Batch 22/64 loss: 1.8244047164916992
Batch 23/64 loss: 2.0838427543640137
Batch 24/64 loss: 2.8908424377441406
Batch 25/64 loss: 2.140167713165283
Batch 26/64 loss: 2.1223220825195312
Batch 27/64 loss: 1.8293342590332031
Batch 28/64 loss: 1.8571586608886719
Batch 29/64 loss: 1.7818846702575684
Batch 30/64 loss: 1.6796884536743164
Batch 31/64 loss: 1.800156593322754
Batch 32/64 loss: 1.8506689071655273
Batch 33/64 loss: 1.7391338348388672
Batch 34/64 loss: 1.892538070678711
Batch 35/64 loss: 1.6878209114074707
Batch 36/64 loss: 2.8342080116271973
Batch 37/64 loss: 2.066312789916992
Batch 38/64 loss: 1.9286489486694336
Batch 39/64 loss: 2.0948610305786133
Batch 40/64 loss: 1.768782138824463
Batch 41/64 loss: 1.784287929534912
Batch 42/64 loss: 1.9786734580993652
Batch 43/64 loss: 1.816450595855713
Batch 44/64 loss: 1.912980556488037
Batch 45/64 loss: 2.0562191009521484
Batch 46/64 loss: 1.937398910522461
Batch 47/64 loss: 1.838660717010498
Batch 48/64 loss: 1.716890811920166
Batch 49/64 loss: 1.7994003295898438
Batch 50/64 loss: 2.1258091926574707
Batch 51/64 loss: 1.7815523147583008
Batch 52/64 loss: 2.206361770629883
Batch 53/64 loss: 1.9937667846679688
Batch 54/64 loss: 1.7422857284545898
Batch 55/64 loss: 2.9453468322753906
Batch 56/64 loss: 1.7860679626464844
Batch 57/64 loss: 1.9936962127685547
Batch 58/64 loss: 5.056434154510498
Batch 59/64 loss: 1.84849214553833
Batch 60/64 loss: 1.6945486068725586
Batch 61/64 loss: 1.8857364654541016
Batch 62/64 loss: 4.208189964294434
Batch 63/64 loss: 2.3610405921936035
Batch 64/64 loss: -1.202712059020996
Epoch 306  Train loss: 2.04890001708386  Val loss: 1.6356672437739945
Epoch 307
-------------------------------
Batch 1/64 loss: 1.8949275016784668
Batch 2/64 loss: 1.8445591926574707
Batch 3/64 loss: 1.8725738525390625
Batch 4/64 loss: 1.943084716796875
Batch 5/64 loss: 1.8302226066589355
Batch 6/64 loss: 1.8228826522827148
Batch 7/64 loss: 1.7551460266113281
Batch 8/64 loss: 2.550419330596924
Batch 9/64 loss: 1.6474533081054688
Batch 10/64 loss: 1.7373547554016113
Batch 11/64 loss: 1.737236499786377
Batch 12/64 loss: 1.808253288269043
Batch 13/64 loss: 4.082469463348389
Batch 14/64 loss: 2.0031518936157227
Batch 15/64 loss: 1.8475971221923828
Batch 16/64 loss: 2.4699811935424805
Batch 17/64 loss: 1.6785516738891602
Batch 18/64 loss: 2.1108169555664062
Batch 19/64 loss: 1.9621143341064453
Batch 20/64 loss: 2.0994906425476074
Batch 21/64 loss: 1.6811366081237793
Batch 22/64 loss: 1.9522972106933594
Batch 23/64 loss: 1.7970595359802246
Batch 24/64 loss: 2.127817153930664
Batch 25/64 loss: 1.8367619514465332
Batch 26/64 loss: 2.8306431770324707
Batch 27/64 loss: 1.7060565948486328
Batch 28/64 loss: 1.9330925941467285
Batch 29/64 loss: 1.9217867851257324
Batch 30/64 loss: 1.894148349761963
Batch 31/64 loss: 1.7204680442810059
Batch 32/64 loss: 1.9452366828918457
Batch 33/64 loss: 4.748621940612793
Batch 34/64 loss: 1.9223952293395996
Batch 35/64 loss: 1.9752230644226074
Batch 36/64 loss: 4.0554046630859375
Batch 37/64 loss: 3.04020357131958
Batch 38/64 loss: 1.8114027976989746
Batch 39/64 loss: 1.9098458290100098
Batch 40/64 loss: 1.867088794708252
Batch 41/64 loss: 2.092194080352783
Batch 42/64 loss: 2.126645565032959
Batch 43/64 loss: 1.7874674797058105
Batch 44/64 loss: 1.7826848030090332
Batch 45/64 loss: 1.8914427757263184
Batch 46/64 loss: 1.8906664848327637
Batch 47/64 loss: 1.7249088287353516
Batch 48/64 loss: 1.713207721710205
Batch 49/64 loss: 2.0143256187438965
Batch 50/64 loss: 1.719329833984375
Batch 51/64 loss: 2.044154644012451
Batch 52/64 loss: 1.8986377716064453
Batch 53/64 loss: 1.9140396118164062
Batch 54/64 loss: 1.7780580520629883
Batch 55/64 loss: 1.7752337455749512
Batch 56/64 loss: 1.8985371589660645
Batch 57/64 loss: 2.544893741607666
Batch 58/64 loss: 1.9839911460876465
Batch 59/64 loss: 1.7395343780517578
Batch 60/64 loss: 1.9540023803710938
Batch 61/64 loss: 1.677330493927002
Batch 62/64 loss: 1.8704004287719727
Batch 63/64 loss: 2.2876696586608887
Batch 64/64 loss: -1.7385263442993164
Epoch 307  Train loss: 2.0106735566083125  Val loss: 1.5302419367524767
Epoch 308
-------------------------------
Batch 1/64 loss: 2.0569639205932617
Batch 2/64 loss: 1.8328862190246582
Batch 3/64 loss: 2.9744911193847656
Batch 4/64 loss: 1.716928482055664
Batch 5/64 loss: 1.847224235534668
Batch 6/64 loss: 1.8759407997131348
Batch 7/64 loss: 1.8810229301452637
Batch 8/64 loss: 1.733199119567871
Batch 9/64 loss: 1.91939115524292
Batch 10/64 loss: 1.755669116973877
Batch 11/64 loss: 1.7035789489746094
Batch 12/64 loss: 1.6851191520690918
Batch 13/64 loss: 1.6633062362670898
Batch 14/64 loss: 4.759932518005371
Batch 15/64 loss: 1.8559865951538086
Batch 16/64 loss: 1.9396324157714844
Batch 17/64 loss: 1.798886775970459
Batch 18/64 loss: 1.943540096282959
Batch 19/64 loss: 1.7419013977050781
Batch 20/64 loss: 1.8823881149291992
Batch 21/64 loss: 1.8587961196899414
Batch 22/64 loss: 1.7659831047058105
Batch 23/64 loss: 2.7788095474243164
Batch 24/64 loss: 1.7836976051330566
Batch 25/64 loss: 1.7115840911865234
Batch 26/64 loss: 2.1880459785461426
Batch 27/64 loss: 1.6224656105041504
Batch 28/64 loss: 1.607461929321289
Batch 29/64 loss: 1.8716793060302734
Batch 30/64 loss: 1.7486891746520996
Batch 31/64 loss: 1.760350227355957
Batch 32/64 loss: 1.711620807647705
Batch 33/64 loss: 1.6634631156921387
Batch 34/64 loss: 1.7411746978759766
Batch 35/64 loss: 1.7507386207580566
Batch 36/64 loss: 2.585806369781494
Batch 37/64 loss: 1.8371005058288574
Batch 38/64 loss: 1.6334991455078125
Batch 39/64 loss: 1.8095283508300781
Batch 40/64 loss: 2.371690273284912
Batch 41/64 loss: 1.6695284843444824
Batch 42/64 loss: 2.526704788208008
Batch 43/64 loss: 4.076261520385742
Batch 44/64 loss: 1.9909882545471191
Batch 45/64 loss: 1.621706485748291
Batch 46/64 loss: 1.7358965873718262
Batch 47/64 loss: 1.6192684173583984
Batch 48/64 loss: 1.6738719940185547
Batch 49/64 loss: 1.9001951217651367
Batch 50/64 loss: 2.400625228881836
Batch 51/64 loss: 1.7304139137268066
Batch 52/64 loss: 1.682560920715332
Batch 53/64 loss: 1.9143028259277344
Batch 54/64 loss: 1.7401471138000488
Batch 55/64 loss: 1.8270974159240723
Batch 56/64 loss: 2.0570831298828125
Batch 57/64 loss: 1.8008012771606445
Batch 58/64 loss: 2.2685256004333496
Batch 59/64 loss: 2.0931849479675293
Batch 60/64 loss: 1.6943130493164062
Batch 61/64 loss: 1.8924751281738281
Batch 62/64 loss: 1.839470386505127
Batch 63/64 loss: 4.322411060333252
Batch 64/64 loss: -1.5701332092285156
Epoch 308  Train loss: 1.9650260027717141  Val loss: 1.5243599619652397
Epoch 309
-------------------------------
Batch 1/64 loss: 1.7175378799438477
Batch 2/64 loss: 1.7173304557800293
Batch 3/64 loss: 1.653648853302002
Batch 4/64 loss: 1.9155082702636719
Batch 5/64 loss: 1.9174895286560059
Batch 6/64 loss: 1.8527235984802246
Batch 7/64 loss: 1.6820592880249023
Batch 8/64 loss: 2.8625149726867676
Batch 9/64 loss: 1.8484067916870117
Batch 10/64 loss: 1.8176426887512207
Batch 11/64 loss: 2.088898181915283
Batch 12/64 loss: 1.7160205841064453
Batch 13/64 loss: 1.6705727577209473
Batch 14/64 loss: 1.810685634613037
Batch 15/64 loss: 1.6307969093322754
Batch 16/64 loss: 2.6405673027038574
Batch 17/64 loss: 1.8240747451782227
Batch 18/64 loss: 1.8726420402526855
Batch 19/64 loss: 1.7601318359375
Batch 20/64 loss: 2.0468978881835938
Batch 21/64 loss: 1.9574475288391113
Batch 22/64 loss: 1.7829504013061523
Batch 23/64 loss: 1.741915225982666
Batch 24/64 loss: 3.1986212730407715
Batch 25/64 loss: 1.7454900741577148
Batch 26/64 loss: 1.8847041130065918
Batch 27/64 loss: 1.7953248023986816
Batch 28/64 loss: 1.7566871643066406
Batch 29/64 loss: 1.962374210357666
Batch 30/64 loss: 4.061354637145996
Batch 31/64 loss: 2.353084087371826
Batch 32/64 loss: 1.6326146125793457
Batch 33/64 loss: 1.64664888381958
Batch 34/64 loss: 1.7244296073913574
Batch 35/64 loss: 1.744110107421875
Batch 36/64 loss: 1.7455682754516602
Batch 37/64 loss: 1.650355339050293
Batch 38/64 loss: 2.4031362533569336
Batch 39/64 loss: 1.6360392570495605
Batch 40/64 loss: 1.792440414428711
Batch 41/64 loss: 1.6834335327148438
Batch 42/64 loss: 1.6993770599365234
Batch 43/64 loss: 2.0761704444885254
Batch 44/64 loss: 1.8894405364990234
Batch 45/64 loss: 4.804994106292725
Batch 46/64 loss: 1.6065692901611328
Batch 47/64 loss: 1.7444987297058105
Batch 48/64 loss: 1.7536578178405762
Batch 49/64 loss: 4.415426731109619
Batch 50/64 loss: 1.7517142295837402
Batch 51/64 loss: 2.0600099563598633
Batch 52/64 loss: 1.8685460090637207
Batch 53/64 loss: 1.7358813285827637
Batch 54/64 loss: 1.7697210311889648
Batch 55/64 loss: 1.8642611503601074
Batch 56/64 loss: 1.6748080253601074
Batch 57/64 loss: 1.6724967956542969
Batch 58/64 loss: 1.9194560050964355
Batch 59/64 loss: 2.0996804237365723
Batch 60/64 loss: 1.793985366821289
Batch 61/64 loss: 1.915609359741211
Batch 62/64 loss: 2.266023635864258
Batch 63/64 loss: 1.6258039474487305
Batch 64/64 loss: -1.738870620727539
Epoch 309  Train loss: 1.9552762199850644  Val loss: 1.5700904479141498
Epoch 310
-------------------------------
Batch 1/64 loss: 1.915609359741211
Batch 2/64 loss: 2.1498117446899414
Batch 3/64 loss: 1.7810783386230469
Batch 4/64 loss: 1.9749650955200195
Batch 5/64 loss: 1.7678966522216797
Batch 6/64 loss: 4.884042263031006
Batch 7/64 loss: 1.9596538543701172
Batch 8/64 loss: 1.7217926979064941
Batch 9/64 loss: 1.65816068649292
Batch 10/64 loss: 1.8128414154052734
Batch 11/64 loss: 2.067582130432129
Batch 12/64 loss: 2.2787413597106934
Batch 13/64 loss: 1.6993165016174316
Batch 14/64 loss: 2.125781536102295
Batch 15/64 loss: 1.6817512512207031
Batch 16/64 loss: 1.7572221755981445
Batch 17/64 loss: 1.7544341087341309
Batch 18/64 loss: 2.060861587524414
Batch 19/64 loss: 1.7388358116149902
Batch 20/64 loss: 3.1424622535705566
Batch 21/64 loss: 3.261040210723877
Batch 22/64 loss: 1.7926521301269531
Batch 23/64 loss: 1.9271435737609863
Batch 24/64 loss: 4.98604679107666
Batch 25/64 loss: 1.8640856742858887
Batch 26/64 loss: 1.6729340553283691
Batch 27/64 loss: 1.7207140922546387
Batch 28/64 loss: 1.9305229187011719
Batch 29/64 loss: 1.7675504684448242
Batch 30/64 loss: 1.672027587890625
Batch 31/64 loss: 2.0628585815429688
Batch 32/64 loss: 1.8181772232055664
Batch 33/64 loss: 2.1443748474121094
Batch 34/64 loss: 1.8815422058105469
Batch 35/64 loss: 1.6440339088439941
Batch 36/64 loss: 1.7353949546813965
Batch 37/64 loss: 1.7629108428955078
Batch 38/64 loss: 1.6640982627868652
Batch 39/64 loss: 1.7751245498657227
Batch 40/64 loss: 1.8262128829956055
Batch 41/64 loss: 1.8480744361877441
Batch 42/64 loss: 1.7275090217590332
Batch 43/64 loss: 4.315302848815918
Batch 44/64 loss: 1.8754305839538574
Batch 45/64 loss: 1.793013095855713
Batch 46/64 loss: 1.6918177604675293
Batch 47/64 loss: 1.7127747535705566
Batch 48/64 loss: 1.842602252960205
Batch 49/64 loss: 1.7646498680114746
Batch 50/64 loss: 1.915480136871338
Batch 51/64 loss: 1.8722314834594727
Batch 52/64 loss: 1.7561883926391602
Batch 53/64 loss: 1.898038387298584
Batch 54/64 loss: 1.9665050506591797
Batch 55/64 loss: 1.6978816986083984
Batch 56/64 loss: 1.8259201049804688
Batch 57/64 loss: 1.6953563690185547
Batch 58/64 loss: 1.792398452758789
Batch 59/64 loss: 1.6851720809936523
Batch 60/64 loss: 1.8555068969726562
Batch 61/64 loss: 1.9584665298461914
Batch 62/64 loss: 1.666964054107666
Batch 63/64 loss: 2.586162567138672
Batch 64/64 loss: -1.5043840408325195
Epoch 310  Train loss: 1.9836462020874024  Val loss: 1.5779690496700327
Epoch 311
-------------------------------
Batch 1/64 loss: 1.7163405418395996
Batch 2/64 loss: 1.673013687133789
Batch 3/64 loss: 1.8088688850402832
Batch 4/64 loss: 1.8572092056274414
Batch 5/64 loss: 2.7239341735839844
Batch 6/64 loss: 1.9612441062927246
Batch 7/64 loss: 4.681568622589111
Batch 8/64 loss: 1.731797695159912
Batch 9/64 loss: 1.8238096237182617
Batch 10/64 loss: 1.7971806526184082
Batch 11/64 loss: 2.459423065185547
Batch 12/64 loss: 1.9870877265930176
Batch 13/64 loss: 1.8735675811767578
Batch 14/64 loss: 1.7910027503967285
Batch 15/64 loss: 1.778883457183838
Batch 16/64 loss: 1.8541488647460938
Batch 17/64 loss: 1.7523102760314941
Batch 18/64 loss: 1.7034111022949219
Batch 19/64 loss: 1.8567276000976562
Batch 20/64 loss: 1.838493824005127
Batch 21/64 loss: 3.932476043701172
Batch 22/64 loss: 1.7267751693725586
Batch 23/64 loss: 1.765317440032959
Batch 24/64 loss: 3.2809548377990723
Batch 25/64 loss: 1.822253704071045
Batch 26/64 loss: 2.1670007705688477
Batch 27/64 loss: 1.7644901275634766
Batch 28/64 loss: 1.6633596420288086
Batch 29/64 loss: 3.046565532684326
Batch 30/64 loss: 1.6735382080078125
Batch 31/64 loss: 1.8814468383789062
Batch 32/64 loss: 1.599172592163086
Batch 33/64 loss: 1.7747783660888672
Batch 34/64 loss: 1.7484984397888184
Batch 35/64 loss: 1.8225469589233398
Batch 36/64 loss: 1.9436168670654297
Batch 37/64 loss: 2.0580315589904785
Batch 38/64 loss: 1.7684788703918457
Batch 39/64 loss: 1.7030038833618164
Batch 40/64 loss: 1.7215657234191895
Batch 41/64 loss: 4.304440498352051
Batch 42/64 loss: 1.6485185623168945
Batch 43/64 loss: 1.9054417610168457
Batch 44/64 loss: 1.7980527877807617
Batch 45/64 loss: 1.9756417274475098
Batch 46/64 loss: 1.6288785934448242
Batch 47/64 loss: 2.774683952331543
Batch 48/64 loss: 1.7353086471557617
Batch 49/64 loss: 2.038400650024414
Batch 50/64 loss: 1.7543396949768066
Batch 51/64 loss: 1.989417552947998
Batch 52/64 loss: 2.0941100120544434
Batch 53/64 loss: 1.8292274475097656
Batch 54/64 loss: 1.8574104309082031
Batch 55/64 loss: 1.9177165031433105
Batch 56/64 loss: 1.7626805305480957
Batch 57/64 loss: 1.8907103538513184
Batch 58/64 loss: 2.00486421585083
Batch 59/64 loss: 1.737288475036621
Batch 60/64 loss: 1.8437824249267578
Batch 61/64 loss: 1.6841545104980469
Batch 62/64 loss: 1.730362892150879
Batch 63/64 loss: 1.8125195503234863
Batch 64/64 loss: -1.6440277099609375
Epoch 311  Train loss: 1.9767658981622434  Val loss: 1.5858420932415835
Epoch 312
-------------------------------
Batch 1/64 loss: 1.7061347961425781
Batch 2/64 loss: 1.791102409362793
Batch 3/64 loss: 1.852010726928711
Batch 4/64 loss: 1.636579990386963
Batch 5/64 loss: 1.6532211303710938
Batch 6/64 loss: 1.7443947792053223
Batch 7/64 loss: 1.7884459495544434
Batch 8/64 loss: 1.6871404647827148
Batch 9/64 loss: 1.6937828063964844
Batch 10/64 loss: 2.089038372039795
Batch 11/64 loss: 2.014249324798584
Batch 12/64 loss: 1.6078920364379883
Batch 13/64 loss: 1.928138256072998
Batch 14/64 loss: 1.891247272491455
Batch 15/64 loss: 2.0898489952087402
Batch 16/64 loss: 1.8700289726257324
Batch 17/64 loss: 1.6758756637573242
Batch 18/64 loss: 1.7735085487365723
Batch 19/64 loss: 2.03108549118042
Batch 20/64 loss: 1.644937515258789
Batch 21/64 loss: 1.7917675971984863
Batch 22/64 loss: 1.8917961120605469
Batch 23/64 loss: 2.5313920974731445
Batch 24/64 loss: 4.0972394943237305
Batch 25/64 loss: 1.6577668190002441
Batch 26/64 loss: 1.7101783752441406
Batch 27/64 loss: 1.8329801559448242
Batch 28/64 loss: 2.1062254905700684
Batch 29/64 loss: 1.8140654563903809
Batch 30/64 loss: 1.7329678535461426
Batch 31/64 loss: 1.9088988304138184
Batch 32/64 loss: 1.7665557861328125
Batch 33/64 loss: 1.651310920715332
Batch 34/64 loss: 2.1686549186706543
Batch 35/64 loss: 2.954833507537842
Batch 36/64 loss: 1.8227381706237793
Batch 37/64 loss: 1.7937736511230469
Batch 38/64 loss: 4.724496841430664
Batch 39/64 loss: 1.7081990242004395
Batch 40/64 loss: 1.7360639572143555
Batch 41/64 loss: 4.238077640533447
Batch 42/64 loss: 1.8408403396606445
Batch 43/64 loss: 2.1576972007751465
Batch 44/64 loss: 1.8357954025268555
Batch 45/64 loss: 1.6555604934692383
Batch 46/64 loss: 1.8041558265686035
Batch 47/64 loss: 1.7124090194702148
Batch 48/64 loss: 2.0365805625915527
Batch 49/64 loss: 1.7876825332641602
Batch 50/64 loss: 1.7656183242797852
Batch 51/64 loss: 2.01231050491333
Batch 52/64 loss: 1.8209609985351562
Batch 53/64 loss: 1.7280220985412598
Batch 54/64 loss: 2.682347297668457
Batch 55/64 loss: 1.706833839416504
Batch 56/64 loss: 2.4769673347473145
Batch 57/64 loss: 1.6990752220153809
Batch 58/64 loss: 1.9673161506652832
Batch 59/64 loss: 1.8955330848693848
Batch 60/64 loss: 1.8093986511230469
Batch 61/64 loss: 1.8085293769836426
Batch 62/64 loss: 1.9403562545776367
Batch 63/64 loss: 1.9307994842529297
Batch 64/64 loss: -0.37421131134033203
Epoch 312  Train loss: 1.9702396505019244  Val loss: 1.6067629417602958
Epoch 313
-------------------------------
Batch 1/64 loss: 1.7998948097229004
Batch 2/64 loss: 1.9331636428833008
Batch 3/64 loss: 2.3090076446533203
Batch 4/64 loss: 1.9355688095092773
Batch 5/64 loss: 2.2322206497192383
Batch 6/64 loss: 1.9236454963684082
Batch 7/64 loss: 2.3317413330078125
Batch 8/64 loss: 1.8798465728759766
Batch 9/64 loss: 1.8755593299865723
Batch 10/64 loss: 1.897376537322998
Batch 11/64 loss: 2.463747978210449
Batch 12/64 loss: 2.388094425201416
Batch 13/64 loss: 1.9358744621276855
Batch 14/64 loss: 1.7881865501403809
Batch 15/64 loss: 1.8922052383422852
Batch 16/64 loss: 2.3822011947631836
Batch 17/64 loss: 2.0342559814453125
Batch 18/64 loss: 1.7621216773986816
Batch 19/64 loss: 2.047830581665039
Batch 20/64 loss: 1.6969141960144043
Batch 21/64 loss: 1.7379727363586426
Batch 22/64 loss: 1.7904272079467773
Batch 23/64 loss: 1.7820959091186523
Batch 24/64 loss: 1.8888306617736816
Batch 25/64 loss: 1.9420900344848633
Batch 26/64 loss: 1.840684413909912
Batch 27/64 loss: 1.8735265731811523
Batch 28/64 loss: 1.9621844291687012
Batch 29/64 loss: 2.0414929389953613
Batch 30/64 loss: 1.717515468597412
Batch 31/64 loss: 2.336824893951416
Batch 32/64 loss: 1.8487277030944824
Batch 33/64 loss: 1.9168553352355957
Batch 34/64 loss: 1.7408227920532227
Batch 35/64 loss: 1.7746524810791016
Batch 36/64 loss: 1.8806705474853516
Batch 37/64 loss: 1.8445944786071777
Batch 38/64 loss: 1.8914222717285156
Batch 39/64 loss: 2.5309696197509766
Batch 40/64 loss: 1.782003402709961
Batch 41/64 loss: 1.829155445098877
Batch 42/64 loss: 2.588545799255371
Batch 43/64 loss: 1.8107233047485352
Batch 44/64 loss: 3.1281919479370117
Batch 45/64 loss: 1.6971735954284668
Batch 46/64 loss: 1.7579307556152344
Batch 47/64 loss: 1.8095965385437012
Batch 48/64 loss: 4.915454387664795
Batch 49/64 loss: 1.755483627319336
Batch 50/64 loss: 1.8861126899719238
Batch 51/64 loss: 1.7213129997253418
Batch 52/64 loss: 2.020275592803955
Batch 53/64 loss: 2.012864112854004
Batch 54/64 loss: 2.0605034828186035
Batch 55/64 loss: 2.1058506965637207
Batch 56/64 loss: 2.1486706733703613
Batch 57/64 loss: 1.9999327659606934
Batch 58/64 loss: 2.000494956970215
Batch 59/64 loss: 3.640775203704834
Batch 60/64 loss: 2.1451239585876465
Batch 61/64 loss: 3.3076515197753906
Batch 62/64 loss: 4.856240749359131
Batch 63/64 loss: 2.9329628944396973
Batch 64/64 loss: -0.3056354522705078
Epoch 313  Train loss: 2.110362699920056  Val loss: 6.64997643539586
Epoch 314
-------------------------------
Batch 1/64 loss: 3.075901508331299
Batch 2/64 loss: 3.6825003623962402
Batch 3/64 loss: 3.350677490234375
Batch 4/64 loss: 2.8989734649658203
Batch 5/64 loss: 3.681251049041748
Batch 6/64 loss: 4.598979473114014
Batch 7/64 loss: 4.080969333648682
Batch 8/64 loss: 3.8687286376953125
Batch 9/64 loss: 3.3117880821228027
Batch 10/64 loss: 3.6120777130126953
Batch 11/64 loss: 4.160973072052002
Batch 12/64 loss: 3.4414563179016113
Batch 13/64 loss: 3.2223620414733887
Batch 14/64 loss: 4.177392482757568
Batch 15/64 loss: 3.4400954246520996
Batch 16/64 loss: 3.4388375282287598
Batch 17/64 loss: 3.362992763519287
Batch 18/64 loss: 2.9280195236206055
Batch 19/64 loss: 3.254993438720703
Batch 20/64 loss: 3.666130542755127
Batch 21/64 loss: 3.4985222816467285
Batch 22/64 loss: 3.246706008911133
Batch 23/64 loss: 3.0898947715759277
Batch 24/64 loss: 3.5579380989074707
Batch 25/64 loss: 4.049740791320801
Batch 26/64 loss: 3.729792594909668
Batch 27/64 loss: 2.8233747482299805
Batch 28/64 loss: 3.071824073791504
Batch 29/64 loss: 2.665250778198242
Batch 30/64 loss: 2.829512596130371
Batch 31/64 loss: 2.891974925994873
Batch 32/64 loss: 3.0494766235351562
Batch 33/64 loss: 4.382485389709473
Batch 34/64 loss: 2.868520736694336
Batch 35/64 loss: 2.4468793869018555
Batch 36/64 loss: 2.5816879272460938
Batch 37/64 loss: 5.24602746963501
Batch 38/64 loss: 3.5459818840026855
Batch 39/64 loss: 2.476189136505127
Batch 40/64 loss: 2.6835718154907227
Batch 41/64 loss: 3.396421432495117
Batch 42/64 loss: 2.4635562896728516
Batch 43/64 loss: 2.724170207977295
Batch 44/64 loss: 3.7217917442321777
Batch 45/64 loss: 2.295339584350586
Batch 46/64 loss: 2.4305124282836914
Batch 47/64 loss: 3.0488319396972656
Batch 48/64 loss: 3.400604724884033
Batch 49/64 loss: 2.20937442779541
Batch 50/64 loss: 2.7756409645080566
Batch 51/64 loss: 2.630030632019043
Batch 52/64 loss: 2.4760355949401855
Batch 53/64 loss: 2.496391773223877
Batch 54/64 loss: 2.606189727783203
Batch 55/64 loss: 3.4807028770446777
Batch 56/64 loss: 4.765560150146484
Batch 57/64 loss: 5.401890754699707
Batch 58/64 loss: 2.2797694206237793
Batch 59/64 loss: 2.401731014251709
Batch 60/64 loss: 2.279212474822998
Batch 61/64 loss: 2.4636902809143066
Batch 62/64 loss: 2.3335094451904297
Batch 63/64 loss: 2.2866406440734863
Batch 64/64 loss: -1.1249370574951172
Epoch 314  Train loss: 3.161009380864162  Val loss: 2.0962755458871114
Epoch 315
-------------------------------
Batch 1/64 loss: 2.3423190116882324
Batch 2/64 loss: 2.2995524406433105
Batch 3/64 loss: 2.125389575958252
Batch 4/64 loss: 2.3420653343200684
Batch 5/64 loss: 2.6749792098999023
Batch 6/64 loss: 2.3904457092285156
Batch 7/64 loss: 2.2768754959106445
Batch 8/64 loss: 2.2963290214538574
Batch 9/64 loss: 2.2108583450317383
Batch 10/64 loss: 2.6188621520996094
Batch 11/64 loss: 2.777148723602295
Batch 12/64 loss: 2.5793652534484863
Batch 13/64 loss: 2.071160316467285
Batch 14/64 loss: 2.406208038330078
Batch 15/64 loss: 2.287916660308838
Batch 16/64 loss: 2.4372501373291016
Batch 17/64 loss: 2.384655475616455
Batch 18/64 loss: 2.0938239097595215
Batch 19/64 loss: 4.869296073913574
Batch 20/64 loss: 3.4492249488830566
Batch 21/64 loss: 5.169618129730225
Batch 22/64 loss: 3.1906309127807617
Batch 23/64 loss: 2.1062088012695312
Batch 24/64 loss: 2.4564852714538574
Batch 25/64 loss: 2.6193161010742188
Batch 26/64 loss: 2.1135034561157227
Batch 27/64 loss: 2.14406681060791
Batch 28/64 loss: 2.0818428993225098
Batch 29/64 loss: 2.135118007659912
Batch 30/64 loss: 2.272757053375244
Batch 31/64 loss: 4.398707389831543
Batch 32/64 loss: 2.133563995361328
Batch 33/64 loss: 2.709718704223633
Batch 34/64 loss: 2.2416863441467285
Batch 35/64 loss: 2.084249973297119
Batch 36/64 loss: 2.1001219749450684
Batch 37/64 loss: 1.9763784408569336
Batch 38/64 loss: 2.223295211791992
Batch 39/64 loss: 2.307682514190674
Batch 40/64 loss: 2.0836071968078613
Batch 41/64 loss: 2.0280346870422363
Batch 42/64 loss: 2.168868064880371
Batch 43/64 loss: 1.974825382232666
Batch 44/64 loss: 2.4053397178649902
Batch 45/64 loss: 2.0390515327453613
Batch 46/64 loss: 2.785445213317871
Batch 47/64 loss: 2.911095142364502
Batch 48/64 loss: 2.359140396118164
Batch 49/64 loss: 1.981523036956787
Batch 50/64 loss: 2.1266112327575684
Batch 51/64 loss: 2.232576370239258
Batch 52/64 loss: 2.1920957565307617
Batch 53/64 loss: 1.9344663619995117
Batch 54/64 loss: 2.4975767135620117
Batch 55/64 loss: 2.024287700653076
Batch 56/64 loss: 2.020267963409424
Batch 57/64 loss: 2.0152735710144043
Batch 58/64 loss: 2.045806884765625
Batch 59/64 loss: 2.0394277572631836
Batch 60/64 loss: 2.073080539703369
Batch 61/64 loss: 2.0765976905822754
Batch 62/64 loss: 2.115736961364746
Batch 63/64 loss: 2.203373432159424
Batch 64/64 loss: -1.4103565216064453
Epoch 315  Train loss: 2.363529721428366  Val loss: 1.8399072103074325
Epoch 316
-------------------------------
Batch 1/64 loss: 1.8501744270324707
Batch 2/64 loss: 2.6868996620178223
Batch 3/64 loss: 1.9657692909240723
Batch 4/64 loss: 1.8655238151550293
Batch 5/64 loss: 1.8954277038574219
Batch 6/64 loss: 2.0783042907714844
Batch 7/64 loss: 2.379171371459961
Batch 8/64 loss: 2.0629196166992188
Batch 9/64 loss: 2.013087749481201
Batch 10/64 loss: 1.8359341621398926
Batch 11/64 loss: 2.046294689178467
Batch 12/64 loss: 2.1699719429016113
Batch 13/64 loss: 2.235032081604004
Batch 14/64 loss: 4.922710418701172
Batch 15/64 loss: 1.8956141471862793
Batch 16/64 loss: 2.134554386138916
Batch 17/64 loss: 2.382767677307129
Batch 18/64 loss: 2.011052131652832
Batch 19/64 loss: 1.9264822006225586
Batch 20/64 loss: 2.0097603797912598
Batch 21/64 loss: 2.0166831016540527
Batch 22/64 loss: 2.3702173233032227
Batch 23/64 loss: 2.228667736053467
Batch 24/64 loss: 2.0852389335632324
Batch 25/64 loss: 2.789304733276367
Batch 26/64 loss: 3.405545711517334
Batch 27/64 loss: 1.9196414947509766
Batch 28/64 loss: 1.9169960021972656
Batch 29/64 loss: 1.9993720054626465
Batch 30/64 loss: 2.155120372772217
Batch 31/64 loss: 1.792898178100586
Batch 32/64 loss: 1.968855381011963
Batch 33/64 loss: 2.097146511077881
Batch 34/64 loss: 3.054931640625
Batch 35/64 loss: 2.050168514251709
Batch 36/64 loss: 2.2143449783325195
Batch 37/64 loss: 1.8256278038024902
Batch 38/64 loss: 1.9862480163574219
Batch 39/64 loss: 1.8757033348083496
Batch 40/64 loss: 1.8778085708618164
Batch 41/64 loss: 1.8498039245605469
Batch 42/64 loss: 2.081552028656006
Batch 43/64 loss: 1.9851460456848145
Batch 44/64 loss: 1.8441801071166992
Batch 45/64 loss: 2.125636577606201
Batch 46/64 loss: 2.3725337982177734
Batch 47/64 loss: 1.8736138343811035
Batch 48/64 loss: 2.250244140625
Batch 49/64 loss: 1.937910556793213
Batch 50/64 loss: 3.0178141593933105
Batch 51/64 loss: 2.0142745971679688
Batch 52/64 loss: 6.073089599609375
Batch 53/64 loss: 1.882120132446289
Batch 54/64 loss: 1.8915209770202637
Batch 55/64 loss: 1.918105125427246
Batch 56/64 loss: 1.9702529907226562
Batch 57/64 loss: 1.8670668601989746
Batch 58/64 loss: 1.8803162574768066
Batch 59/64 loss: 1.8955302238464355
Batch 60/64 loss: 2.200277805328369
Batch 61/64 loss: 2.0194530487060547
Batch 62/64 loss: 2.179286479949951
Batch 63/64 loss: 1.9193620681762695
Batch 64/64 loss: -1.0801458358764648
Epoch 316  Train loss: 2.1684228149114873  Val loss: 1.6874024564867576
Epoch 317
-------------------------------
Batch 1/64 loss: 1.8321595191955566
Batch 2/64 loss: 1.8769721984863281
Batch 3/64 loss: 2.197462558746338
Batch 4/64 loss: 2.2197837829589844
Batch 5/64 loss: 2.069108009338379
Batch 6/64 loss: 2.0310020446777344
Batch 7/64 loss: 2.018700122833252
Batch 8/64 loss: 1.9425811767578125
Batch 9/64 loss: 1.8020806312561035
Batch 10/64 loss: 1.809704303741455
Batch 11/64 loss: 1.8926477432250977
Batch 12/64 loss: 2.1094489097595215
Batch 13/64 loss: 2.5083651542663574
Batch 14/64 loss: 2.0349950790405273
Batch 15/64 loss: 2.025073528289795
Batch 16/64 loss: 1.8140130043029785
Batch 17/64 loss: 1.8849129676818848
Batch 18/64 loss: 2.2638025283813477
Batch 19/64 loss: 1.9184012413024902
Batch 20/64 loss: 2.018179416656494
Batch 21/64 loss: 1.8640742301940918
Batch 22/64 loss: 2.017207145690918
Batch 23/64 loss: 1.713125228881836
Batch 24/64 loss: 1.8716516494750977
Batch 25/64 loss: 1.8980703353881836
Batch 26/64 loss: 2.246396064758301
Batch 27/64 loss: 1.7252812385559082
Batch 28/64 loss: 2.1599268913269043
Batch 29/64 loss: 2.843876838684082
Batch 30/64 loss: 1.9249563217163086
Batch 31/64 loss: 1.9189348220825195
Batch 32/64 loss: 1.9004631042480469
Batch 33/64 loss: 1.7661018371582031
Batch 34/64 loss: 1.7539305686950684
Batch 35/64 loss: 2.0996017456054688
Batch 36/64 loss: 3.9660186767578125
Batch 37/64 loss: 2.088994026184082
Batch 38/64 loss: 1.7462973594665527
Batch 39/64 loss: 2.2980170249938965
Batch 40/64 loss: 1.9322638511657715
Batch 41/64 loss: 1.954545021057129
Batch 42/64 loss: 1.875138282775879
Batch 43/64 loss: 2.1826539039611816
Batch 44/64 loss: 1.9059653282165527
Batch 45/64 loss: 1.982837200164795
Batch 46/64 loss: 1.9584946632385254
Batch 47/64 loss: 1.8456158638000488
Batch 48/64 loss: 4.231276512145996
Batch 49/64 loss: 2.338372230529785
Batch 50/64 loss: 4.767484188079834
Batch 51/64 loss: 1.9077577590942383
Batch 52/64 loss: 3.0319857597351074
Batch 53/64 loss: 1.7063908576965332
Batch 54/64 loss: 1.734848976135254
Batch 55/64 loss: 1.8277873992919922
Batch 56/64 loss: 1.8246445655822754
Batch 57/64 loss: 2.9221339225769043
Batch 58/64 loss: 1.988847255706787
Batch 59/64 loss: 1.8491802215576172
Batch 60/64 loss: 2.9311881065368652
Batch 61/64 loss: 1.9439220428466797
Batch 62/64 loss: 1.9706177711486816
Batch 63/64 loss: 2.1598706245422363
Batch 64/64 loss: -1.527665138244629
Epoch 317  Train loss: 2.097261058582979  Val loss: 1.6588262577646786
Epoch 318
-------------------------------
Batch 1/64 loss: 1.7996206283569336
Batch 2/64 loss: 1.8476462364196777
Batch 3/64 loss: 1.7439532279968262
Batch 4/64 loss: 2.1266064643859863
Batch 5/64 loss: 1.9025721549987793
Batch 6/64 loss: 1.9713997840881348
Batch 7/64 loss: 1.9877386093139648
Batch 8/64 loss: 1.8267316818237305
Batch 9/64 loss: 1.907280445098877
Batch 10/64 loss: 1.8074440956115723
Batch 11/64 loss: 1.7800664901733398
Batch 12/64 loss: 1.9062261581420898
Batch 13/64 loss: 4.801876544952393
Batch 14/64 loss: 2.05275297164917
Batch 15/64 loss: 2.258111000061035
Batch 16/64 loss: 2.110734462738037
Batch 17/64 loss: 1.8764338493347168
Batch 18/64 loss: 1.9537591934204102
Batch 19/64 loss: 1.8454389572143555
Batch 20/64 loss: 1.876584529876709
Batch 21/64 loss: 2.7933077812194824
Batch 22/64 loss: 1.8572206497192383
Batch 23/64 loss: 1.973935604095459
Batch 24/64 loss: 1.8944306373596191
Batch 25/64 loss: 1.9760723114013672
Batch 26/64 loss: 1.924330234527588
Batch 27/64 loss: 1.8114275932312012
Batch 28/64 loss: 1.9146108627319336
Batch 29/64 loss: 1.924609661102295
Batch 30/64 loss: 1.8670411109924316
Batch 31/64 loss: 1.862377643585205
Batch 32/64 loss: 5.065258026123047
Batch 33/64 loss: 3.0033535957336426
Batch 34/64 loss: 1.9355440139770508
Batch 35/64 loss: 1.8826918601989746
Batch 36/64 loss: 2.6353769302368164
Batch 37/64 loss: 2.314260959625244
Batch 38/64 loss: 1.9604063034057617
Batch 39/64 loss: 1.8448076248168945
Batch 40/64 loss: 1.9636569023132324
Batch 41/64 loss: 2.05654239654541
Batch 42/64 loss: 3.893331527709961
Batch 43/64 loss: 1.802659511566162
Batch 44/64 loss: 2.5808205604553223
Batch 45/64 loss: 1.9732751846313477
Batch 46/64 loss: 2.16961669921875
Batch 47/64 loss: 1.8283233642578125
Batch 48/64 loss: 2.061497211456299
Batch 49/64 loss: 2.4238901138305664
Batch 50/64 loss: 1.7865872383117676
Batch 51/64 loss: 1.8663372993469238
Batch 52/64 loss: 1.790468692779541
Batch 53/64 loss: 2.097334384918213
Batch 54/64 loss: 1.8950738906860352
Batch 55/64 loss: 2.015920639038086
Batch 56/64 loss: 1.8143601417541504
Batch 57/64 loss: 1.7932758331298828
Batch 58/64 loss: 1.7782464027404785
Batch 59/64 loss: 1.8848247528076172
Batch 60/64 loss: 1.9738154411315918
Batch 61/64 loss: 1.8164372444152832
Batch 62/64 loss: 1.8644580841064453
Batch 63/64 loss: 1.7762222290039062
Batch 64/64 loss: -1.5431289672851562
Epoch 318  Train loss: 2.0639007044773474  Val loss: 1.6362577353146477
Epoch 319
-------------------------------
Batch 1/64 loss: 4.729831695556641
Batch 2/64 loss: 1.9141392707824707
Batch 3/64 loss: 2.1754651069641113
Batch 4/64 loss: 1.9993042945861816
Batch 5/64 loss: 1.7437505722045898
Batch 6/64 loss: 1.7871627807617188
Batch 7/64 loss: 2.7510743141174316
Batch 8/64 loss: 2.751821517944336
Batch 9/64 loss: 1.7558364868164062
Batch 10/64 loss: 2.1361374855041504
Batch 11/64 loss: 1.8465356826782227
Batch 12/64 loss: 1.895120620727539
Batch 13/64 loss: 1.8785786628723145
Batch 14/64 loss: 1.8599376678466797
Batch 15/64 loss: 1.9029855728149414
Batch 16/64 loss: 1.8776350021362305
Batch 17/64 loss: 1.832695484161377
Batch 18/64 loss: 1.9099488258361816
Batch 19/64 loss: 1.8239383697509766
Batch 20/64 loss: 1.8073835372924805
Batch 21/64 loss: 1.8370332717895508
Batch 22/64 loss: 1.9367809295654297
Batch 23/64 loss: 1.8897652626037598
Batch 24/64 loss: 1.8568115234375
Batch 25/64 loss: 2.092317581176758
Batch 26/64 loss: 1.7536802291870117
Batch 27/64 loss: 1.8891596794128418
Batch 28/64 loss: 1.811495304107666
Batch 29/64 loss: 1.775986671447754
Batch 30/64 loss: 3.1856017112731934
Batch 31/64 loss: 1.771772861480713
Batch 32/64 loss: 1.976015567779541
Batch 33/64 loss: 1.8092761039733887
Batch 34/64 loss: 1.8341269493103027
Batch 35/64 loss: 1.8862824440002441
Batch 36/64 loss: 2.014641761779785
Batch 37/64 loss: 1.7549786567687988
Batch 38/64 loss: 1.9092726707458496
Batch 39/64 loss: 1.9246859550476074
Batch 40/64 loss: 2.160750389099121
Batch 41/64 loss: 2.0452027320861816
Batch 42/64 loss: 1.6611099243164062
Batch 43/64 loss: 1.7549357414245605
Batch 44/64 loss: 1.9911456108093262
Batch 45/64 loss: 2.0267319679260254
Batch 46/64 loss: 1.961817741394043
Batch 47/64 loss: 1.7455077171325684
Batch 48/64 loss: 1.8361754417419434
Batch 49/64 loss: 2.075129508972168
Batch 50/64 loss: 2.0771994590759277
Batch 51/64 loss: 1.9832267761230469
Batch 52/64 loss: 2.3616251945495605
Batch 53/64 loss: 2.040595531463623
Batch 54/64 loss: 2.1259822845458984
Batch 55/64 loss: 1.9515109062194824
Batch 56/64 loss: 4.35769510269165
Batch 57/64 loss: 2.797389030456543
Batch 58/64 loss: 1.7624139785766602
Batch 59/64 loss: 2.4542078971862793
Batch 60/64 loss: 3.9595484733581543
Batch 61/64 loss: 1.674642562866211
Batch 62/64 loss: 1.9344353675842285
Batch 63/64 loss: 1.7763442993164062
Batch 64/64 loss: -1.034977912902832
Epoch 319  Train loss: 2.0553420908310835  Val loss: 1.7066715804162305
Epoch 320
-------------------------------
Batch 1/64 loss: 4.748178005218506
Batch 2/64 loss: 2.108560562133789
Batch 3/64 loss: 2.1244330406188965
Batch 4/64 loss: 1.7642998695373535
Batch 5/64 loss: 1.7823634147644043
Batch 6/64 loss: 1.7770328521728516
Batch 7/64 loss: 1.9134316444396973
Batch 8/64 loss: 1.8255062103271484
Batch 9/64 loss: 2.0907278060913086
Batch 10/64 loss: 1.9033236503601074
Batch 11/64 loss: 2.2530436515808105
Batch 12/64 loss: 1.9886369705200195
Batch 13/64 loss: 2.8968071937561035
Batch 14/64 loss: 1.7555184364318848
Batch 15/64 loss: 1.809880256652832
Batch 16/64 loss: 1.9151573181152344
Batch 17/64 loss: 3.9360299110412598
Batch 18/64 loss: 2.406580924987793
Batch 19/64 loss: 1.9682106971740723
Batch 20/64 loss: 1.8812313079833984
Batch 21/64 loss: 1.9438610076904297
Batch 22/64 loss: 1.894698143005371
Batch 23/64 loss: 1.7605342864990234
Batch 24/64 loss: 2.125171184539795
Batch 25/64 loss: 1.7230544090270996
Batch 26/64 loss: 1.958949089050293
Batch 27/64 loss: 2.00589656829834
Batch 28/64 loss: 2.7205634117126465
Batch 29/64 loss: 1.9213109016418457
Batch 30/64 loss: 1.719757080078125
Batch 31/64 loss: 1.8848319053649902
Batch 32/64 loss: 1.9013590812683105
Batch 33/64 loss: 2.858462333679199
Batch 34/64 loss: 2.910851001739502
Batch 35/64 loss: 1.8535232543945312
Batch 36/64 loss: 1.786773681640625
Batch 37/64 loss: 2.0295987129211426
Batch 38/64 loss: 1.8074898719787598
Batch 39/64 loss: 2.0533647537231445
Batch 40/64 loss: 1.8892412185668945
Batch 41/64 loss: 1.7124662399291992
Batch 42/64 loss: 1.7921252250671387
Batch 43/64 loss: 1.9315824508666992
Batch 44/64 loss: 1.8608717918395996
Batch 45/64 loss: 2.128994941711426
Batch 46/64 loss: 1.889420509338379
Batch 47/64 loss: 1.7861647605895996
Batch 48/64 loss: 1.8036084175109863
Batch 49/64 loss: 1.776090145111084
Batch 50/64 loss: 1.8586487770080566
Batch 51/64 loss: 4.468666076660156
Batch 52/64 loss: 1.7574005126953125
Batch 53/64 loss: 1.8856759071350098
Batch 54/64 loss: 1.7879176139831543
Batch 55/64 loss: 1.736964225769043
Batch 56/64 loss: 1.8076839447021484
Batch 57/64 loss: 1.790628433227539
Batch 58/64 loss: 1.7983818054199219
Batch 59/64 loss: 2.3834967613220215
Batch 60/64 loss: 1.9971938133239746
Batch 61/64 loss: 2.06198787689209
Batch 62/64 loss: 1.6889009475708008
Batch 63/64 loss: 1.7162084579467773
Batch 64/64 loss: -1.7171506881713867
Epoch 320  Train loss: 2.035003329258339  Val loss: 1.5675774144962482
Epoch 321
-------------------------------
Batch 1/64 loss: 1.66945219039917
Batch 2/64 loss: 1.8567008972167969
Batch 3/64 loss: 2.0819754600524902
Batch 4/64 loss: 1.8232150077819824
Batch 5/64 loss: 1.886148452758789
Batch 6/64 loss: 2.0359621047973633
Batch 7/64 loss: 1.7959017753601074
Batch 8/64 loss: 2.136436939239502
Batch 9/64 loss: 3.030764579772949
Batch 10/64 loss: 1.8252954483032227
Batch 11/64 loss: 2.2242560386657715
Batch 12/64 loss: 1.9271578788757324
Batch 13/64 loss: 1.7753324508666992
Batch 14/64 loss: 1.8603386878967285
Batch 15/64 loss: 2.0843400955200195
Batch 16/64 loss: 2.544005870819092
Batch 17/64 loss: 2.0475215911865234
Batch 18/64 loss: 1.9374184608459473
Batch 19/64 loss: 1.7694640159606934
Batch 20/64 loss: 1.675635814666748
Batch 21/64 loss: 1.8592286109924316
Batch 22/64 loss: 1.9229817390441895
Batch 23/64 loss: 1.813971996307373
Batch 24/64 loss: 2.0549511909484863
Batch 25/64 loss: 1.7091569900512695
Batch 26/64 loss: 1.7940044403076172
Batch 27/64 loss: 2.8735475540161133
Batch 28/64 loss: 1.8782525062561035
Batch 29/64 loss: 1.6948580741882324
Batch 30/64 loss: 1.86085844039917
Batch 31/64 loss: 3.919703483581543
Batch 32/64 loss: 1.913071632385254
Batch 33/64 loss: 2.039041519165039
Batch 34/64 loss: 1.838089942932129
Batch 35/64 loss: 1.6753368377685547
Batch 36/64 loss: 1.887556552886963
Batch 37/64 loss: 3.2845263481140137
Batch 38/64 loss: 1.8129043579101562
Batch 39/64 loss: 1.891648292541504
Batch 40/64 loss: 1.849562644958496
Batch 41/64 loss: 1.7017788887023926
Batch 42/64 loss: 1.7740440368652344
Batch 43/64 loss: 2.3282246589660645
Batch 44/64 loss: 1.8934249877929688
Batch 45/64 loss: 1.7160205841064453
Batch 46/64 loss: 1.8270654678344727
Batch 47/64 loss: 1.6818199157714844
Batch 48/64 loss: 1.7775382995605469
Batch 49/64 loss: 1.7110114097595215
Batch 50/64 loss: 1.949246883392334
Batch 51/64 loss: 1.769052505493164
Batch 52/64 loss: 1.935232162475586
Batch 53/64 loss: 1.6669692993164062
Batch 54/64 loss: 1.7350044250488281
Batch 55/64 loss: 2.0521368980407715
Batch 56/64 loss: 1.7774925231933594
Batch 57/64 loss: 1.8057599067687988
Batch 58/64 loss: 4.011922836303711
Batch 59/64 loss: 1.7339630126953125
Batch 60/64 loss: 4.704202175140381
Batch 61/64 loss: 2.0654287338256836
Batch 62/64 loss: 2.441068172454834
Batch 63/64 loss: 1.716874122619629
Batch 64/64 loss: -1.3313417434692383
Epoch 321  Train loss: 2.013134941400266  Val loss: 2.6603788526607133
Epoch 322
-------------------------------
Batch 1/64 loss: 2.6807408332824707
Batch 2/64 loss: 2.3392844200134277
Batch 3/64 loss: 2.2853331565856934
Batch 4/64 loss: 2.737699031829834
Batch 5/64 loss: 1.96486234664917
Batch 6/64 loss: 2.0316076278686523
Batch 7/64 loss: 3.26210880279541
Batch 8/64 loss: 2.163595676422119
Batch 9/64 loss: 2.1563520431518555
Batch 10/64 loss: 2.2627291679382324
Batch 11/64 loss: 2.78702449798584
Batch 12/64 loss: 2.0108742713928223
Batch 13/64 loss: 2.0828280448913574
Batch 14/64 loss: 2.1345181465148926
Batch 15/64 loss: 2.2167177200317383
Batch 16/64 loss: 1.981462001800537
Batch 17/64 loss: 2.119908332824707
Batch 18/64 loss: 3.1758780479431152
Batch 19/64 loss: 2.099949359893799
Batch 20/64 loss: 2.0074057579040527
Batch 21/64 loss: 2.2594966888427734
Batch 22/64 loss: 2.0359973907470703
Batch 23/64 loss: 2.123119354248047
Batch 24/64 loss: 1.9171648025512695
Batch 25/64 loss: 1.8525004386901855
Batch 26/64 loss: 2.2204833030700684
Batch 27/64 loss: 2.1166000366210938
Batch 28/64 loss: 1.8808627128601074
Batch 29/64 loss: 2.679591178894043
Batch 30/64 loss: 2.025618553161621
Batch 31/64 loss: 1.9158868789672852
Batch 32/64 loss: 1.9406156539916992
Batch 33/64 loss: 2.2762999534606934
Batch 34/64 loss: 4.194818019866943
Batch 35/64 loss: 1.8769655227661133
Batch 36/64 loss: 1.9598989486694336
Batch 37/64 loss: 2.0628561973571777
Batch 38/64 loss: 3.2887701988220215
Batch 39/64 loss: 2.3272957801818848
Batch 40/64 loss: 2.0181427001953125
Batch 41/64 loss: 1.9599204063415527
Batch 42/64 loss: 2.0383520126342773
Batch 43/64 loss: 4.1603875160217285
Batch 44/64 loss: 2.192018508911133
Batch 45/64 loss: 2.0688490867614746
Batch 46/64 loss: 1.8500666618347168
Batch 47/64 loss: 1.799623966217041
Batch 48/64 loss: 1.8945932388305664
Batch 49/64 loss: 2.0442328453063965
Batch 50/64 loss: 1.7388343811035156
Batch 51/64 loss: 1.8583793640136719
Batch 52/64 loss: 1.8129992485046387
Batch 53/64 loss: 2.1478676795959473
Batch 54/64 loss: 2.236558437347412
Batch 55/64 loss: 1.8297414779663086
Batch 56/64 loss: 2.1148428916931152
Batch 57/64 loss: 1.916818618774414
Batch 58/64 loss: 3.164933204650879
Batch 59/64 loss: 1.9437475204467773
Batch 60/64 loss: 2.031978130340576
Batch 61/64 loss: 1.8336296081542969
Batch 62/64 loss: 5.017519474029541
Batch 63/64 loss: 2.0071802139282227
Batch 64/64 loss: -1.6910572052001953
Epoch 322  Train loss: 2.225390512803022  Val loss: 1.7020885559291774
Epoch 323
-------------------------------
Batch 1/64 loss: 2.381552219390869
Batch 2/64 loss: 1.847853183746338
Batch 3/64 loss: 1.819725513458252
Batch 4/64 loss: 1.863664150238037
Batch 5/64 loss: 3.167440414428711
Batch 6/64 loss: 1.7766332626342773
Batch 7/64 loss: 1.8951373100280762
Batch 8/64 loss: 1.946444034576416
Batch 9/64 loss: 1.7581710815429688
Batch 10/64 loss: 1.8346548080444336
Batch 11/64 loss: 1.8878626823425293
Batch 12/64 loss: 2.195467472076416
Batch 13/64 loss: 1.9161090850830078
Batch 14/64 loss: 2.014970302581787
Batch 15/64 loss: 4.49099588394165
Batch 16/64 loss: 1.983750820159912
Batch 17/64 loss: 4.447010040283203
Batch 18/64 loss: 3.9672460556030273
Batch 19/64 loss: 2.664508819580078
Batch 20/64 loss: 1.8698177337646484
Batch 21/64 loss: 2.172496795654297
Batch 22/64 loss: 3.677338123321533
Batch 23/64 loss: 2.1776881217956543
Batch 24/64 loss: 2.571556568145752
Batch 25/64 loss: 2.5764198303222656
Batch 26/64 loss: 2.361288070678711
Batch 27/64 loss: 2.5880579948425293
Batch 28/64 loss: 2.664797306060791
Batch 29/64 loss: 2.0222415924072266
Batch 30/64 loss: 1.9902753829956055
Batch 31/64 loss: 3.0656685829162598
Batch 32/64 loss: 3.075193405151367
Batch 33/64 loss: 2.8585071563720703
Batch 34/64 loss: 2.9476351737976074
Batch 35/64 loss: 4.256695747375488
Batch 36/64 loss: 2.535048484802246
Batch 37/64 loss: 2.7698702812194824
Batch 38/64 loss: 2.0467586517333984
Batch 39/64 loss: 3.310868263244629
Batch 40/64 loss: 3.1488165855407715
Batch 41/64 loss: 2.0944371223449707
Batch 42/64 loss: 2.784782886505127
Batch 43/64 loss: 2.7036118507385254
Batch 44/64 loss: 3.6836676597595215
Batch 45/64 loss: 7.281105995178223
Batch 46/64 loss: 2.592639446258545
Batch 47/64 loss: 2.2147164344787598
Batch 48/64 loss: 2.011291980743408
Batch 49/64 loss: 2.7673044204711914
Batch 50/64 loss: 2.8531556129455566
Batch 51/64 loss: 2.01432466506958
Batch 52/64 loss: 2.570925712585449
Batch 53/64 loss: 1.8395466804504395
Batch 54/64 loss: 1.770860195159912
Batch 55/64 loss: 4.050143241882324
Batch 56/64 loss: 3.0687551498413086
Batch 57/64 loss: 2.931852340698242
Batch 58/64 loss: 2.455386161804199
Batch 59/64 loss: 3.232579231262207
Batch 60/64 loss: 2.141541004180908
Batch 61/64 loss: 2.008741855621338
Batch 62/64 loss: 2.1845293045043945
Batch 63/64 loss: 1.9774079322814941
Batch 64/64 loss: -1.4492549896240234
Epoch 323  Train loss: 2.5834133746577246  Val loss: 1.999724961638041
Epoch 324
-------------------------------
Batch 1/64 loss: 2.0298876762390137
Batch 2/64 loss: 2.84816312789917
Batch 3/64 loss: 2.3629255294799805
Batch 4/64 loss: 2.4246506690979004
Batch 5/64 loss: 2.7789649963378906
Batch 6/64 loss: 2.05568790435791
Batch 7/64 loss: 2.266726493835449
Batch 8/64 loss: 1.953989028930664
Batch 9/64 loss: 1.9116220474243164
Batch 10/64 loss: 2.0125412940979004
Batch 11/64 loss: 2.153778076171875
Batch 12/64 loss: 1.9332351684570312
Batch 13/64 loss: 2.069803237915039
Batch 14/64 loss: 2.159895420074463
Batch 15/64 loss: 1.9148550033569336
Batch 16/64 loss: 1.98626708984375
Batch 17/64 loss: 1.8343777656555176
Batch 18/64 loss: 2.0539002418518066
Batch 19/64 loss: 3.924581527709961
Batch 20/64 loss: 2.0890960693359375
Batch 21/64 loss: 2.8666176795959473
Batch 22/64 loss: 2.2708382606506348
Batch 23/64 loss: 1.9609308242797852
Batch 24/64 loss: 2.006667137145996
Batch 25/64 loss: 1.968092441558838
Batch 26/64 loss: 2.0044240951538086
Batch 27/64 loss: 1.8640875816345215
Batch 28/64 loss: 4.48382043838501
Batch 29/64 loss: 1.9477343559265137
Batch 30/64 loss: 1.7773356437683105
Batch 31/64 loss: 2.095299243927002
Batch 32/64 loss: 2.209052085876465
Batch 33/64 loss: 2.3514647483825684
Batch 34/64 loss: 1.920372486114502
Batch 35/64 loss: 1.7338953018188477
Batch 36/64 loss: 1.9194612503051758
Batch 37/64 loss: 2.456864356994629
Batch 38/64 loss: 1.9820351600646973
Batch 39/64 loss: 2.5668582916259766
Batch 40/64 loss: 1.846717357635498
Batch 41/64 loss: 2.718278408050537
Batch 42/64 loss: 1.7044825553894043
Batch 43/64 loss: 1.9395942687988281
Batch 44/64 loss: 1.8743972778320312
Batch 45/64 loss: 1.9132161140441895
Batch 46/64 loss: 1.7443299293518066
Batch 47/64 loss: 3.1773924827575684
Batch 48/64 loss: 2.1406378746032715
Batch 49/64 loss: 2.7161011695861816
Batch 50/64 loss: 1.954277515411377
Batch 51/64 loss: 2.030263900756836
Batch 52/64 loss: 1.7750988006591797
Batch 53/64 loss: 2.0181126594543457
Batch 54/64 loss: 2.0568113327026367
Batch 55/64 loss: 1.76422119140625
Batch 56/64 loss: 1.8101000785827637
Batch 57/64 loss: 2.2078967094421387
Batch 58/64 loss: 1.725998878479004
Batch 59/64 loss: 1.7109875679016113
Batch 60/64 loss: 5.010783672332764
Batch 61/64 loss: 2.0121355056762695
Batch 62/64 loss: 2.144486904144287
Batch 63/64 loss: 3.888925552368164
Batch 64/64 loss: -1.7849798202514648
Epoch 324  Train loss: 2.1913303936229034  Val loss: 1.7037357448302592
Epoch 325
-------------------------------
Batch 1/64 loss: 2.366116523742676
Batch 2/64 loss: 1.995713233947754
Batch 3/64 loss: 1.8402118682861328
Batch 4/64 loss: 1.6547913551330566
Batch 5/64 loss: 1.726914405822754
Batch 6/64 loss: 1.8605356216430664
Batch 7/64 loss: 2.093961715698242
Batch 8/64 loss: 2.547323226928711
Batch 9/64 loss: 4.120165824890137
Batch 10/64 loss: 1.9282984733581543
Batch 11/64 loss: 2.0552115440368652
Batch 12/64 loss: 1.8924460411071777
Batch 13/64 loss: 2.1707277297973633
Batch 14/64 loss: 1.722879409790039
Batch 15/64 loss: 2.150810718536377
Batch 16/64 loss: 1.8760795593261719
Batch 17/64 loss: 2.918074131011963
Batch 18/64 loss: 1.7823901176452637
Batch 19/64 loss: 1.8073606491088867
Batch 20/64 loss: 1.7459187507629395
Batch 21/64 loss: 1.9678988456726074
Batch 22/64 loss: 1.7093582153320312
Batch 23/64 loss: 2.650672435760498
Batch 24/64 loss: 3.8987503051757812
Batch 25/64 loss: 1.8001618385314941
Batch 26/64 loss: 2.2820863723754883
Batch 27/64 loss: 2.453449249267578
Batch 28/64 loss: 1.9173369407653809
Batch 29/64 loss: 2.0528554916381836
Batch 30/64 loss: 2.1581320762634277
Batch 31/64 loss: 3.054887294769287
Batch 32/64 loss: 2.195577621459961
Batch 33/64 loss: 2.6593785285949707
Batch 34/64 loss: 2.6431632041931152
Batch 35/64 loss: 2.9491891860961914
Batch 36/64 loss: 2.1394200325012207
Batch 37/64 loss: 2.280684471130371
Batch 38/64 loss: 2.224196434020996
Batch 39/64 loss: 2.2476119995117188
Batch 40/64 loss: 2.3635950088500977
Batch 41/64 loss: 2.330648899078369
Batch 42/64 loss: 2.404733657836914
Batch 43/64 loss: 2.41264009475708
Batch 44/64 loss: 2.8127222061157227
Batch 45/64 loss: 3.2681031227111816
Batch 46/64 loss: 2.2022242546081543
Batch 47/64 loss: 2.233215808868408
Batch 48/64 loss: 3.4851913452148438
Batch 49/64 loss: 2.4199843406677246
Batch 50/64 loss: 2.1521849632263184
Batch 51/64 loss: 2.142892360687256
Batch 52/64 loss: 2.308784008026123
Batch 53/64 loss: 2.125251293182373
Batch 54/64 loss: 2.2270002365112305
Batch 55/64 loss: 2.031874656677246
Batch 56/64 loss: 2.1959152221679688
Batch 57/64 loss: 5.16764497756958
Batch 58/64 loss: 2.2866177558898926
Batch 59/64 loss: 2.1537575721740723
Batch 60/64 loss: 2.200742721557617
Batch 61/64 loss: 2.3501205444335938
Batch 62/64 loss: 2.260194778442383
Batch 63/64 loss: 2.277259349822998
Batch 64/64 loss: -1.2040586471557617
Epoch 325  Train loss: 2.2972705354877547  Val loss: 2.171868812587253
Epoch 326
-------------------------------
Batch 1/64 loss: 2.303028106689453
Batch 2/64 loss: 1.8871941566467285
Batch 3/64 loss: 2.0834879875183105
Batch 4/64 loss: 2.076659679412842
Batch 5/64 loss: 5.143909454345703
Batch 6/64 loss: 2.0212607383728027
Batch 7/64 loss: 2.2006893157958984
Batch 8/64 loss: 2.2246737480163574
Batch 9/64 loss: 2.758467197418213
Batch 10/64 loss: 1.892859935760498
Batch 11/64 loss: 2.166226387023926
Batch 12/64 loss: 1.9518046379089355
Batch 13/64 loss: 1.959764003753662
Batch 14/64 loss: 3.6825437545776367
Batch 15/64 loss: 2.5443811416625977
Batch 16/64 loss: 2.150324821472168
Batch 17/64 loss: 1.901583194732666
Batch 18/64 loss: 5.477547645568848
Batch 19/64 loss: 2.1888785362243652
Batch 20/64 loss: 4.26140832901001
Batch 21/64 loss: 1.986466407775879
Batch 22/64 loss: 2.0158071517944336
Batch 23/64 loss: 1.9384040832519531
Batch 24/64 loss: 2.177031993865967
Batch 25/64 loss: 2.564931869506836
Batch 26/64 loss: 1.8592534065246582
Batch 27/64 loss: 2.186662197113037
Batch 28/64 loss: 1.8324260711669922
Batch 29/64 loss: 2.147350311279297
Batch 30/64 loss: 2.15193510055542
Batch 31/64 loss: 2.120656967163086
Batch 32/64 loss: 1.8160743713378906
Batch 33/64 loss: 1.9122858047485352
Batch 34/64 loss: 1.983673095703125
Batch 35/64 loss: 2.6594200134277344
Batch 36/64 loss: 1.8987140655517578
Batch 37/64 loss: 2.017829418182373
Batch 38/64 loss: 2.268634796142578
Batch 39/64 loss: 2.080564498901367
Batch 40/64 loss: 2.951882839202881
Batch 41/64 loss: 2.0739927291870117
Batch 42/64 loss: 1.976179599761963
Batch 43/64 loss: 1.7671594619750977
Batch 44/64 loss: 3.0892796516418457
Batch 45/64 loss: 2.1599316596984863
Batch 46/64 loss: 2.3885722160339355
Batch 47/64 loss: 1.7623906135559082
Batch 48/64 loss: 1.8330512046813965
Batch 49/64 loss: 2.045405864715576
Batch 50/64 loss: 2.333864212036133
Batch 51/64 loss: 1.7410893440246582
Batch 52/64 loss: 1.7603168487548828
Batch 53/64 loss: 1.8737964630126953
Batch 54/64 loss: 1.7578425407409668
Batch 55/64 loss: 2.007093906402588
Batch 56/64 loss: 2.0736093521118164
Batch 57/64 loss: 1.8219528198242188
Batch 58/64 loss: 2.10203218460083
Batch 59/64 loss: 1.9193005561828613
Batch 60/64 loss: 1.9430251121520996
Batch 61/64 loss: 1.7009243965148926
Batch 62/64 loss: 2.2899551391601562
Batch 63/64 loss: 1.7012362480163574
Batch 64/64 loss: -1.655324935913086
Epoch 326  Train loss: 2.201211069144455  Val loss: 1.6899388500095642
Epoch 327
-------------------------------
Batch 1/64 loss: 1.8209376335144043
Batch 2/64 loss: 2.3190488815307617
Batch 3/64 loss: 2.2240114212036133
Batch 4/64 loss: 1.696516990661621
Batch 5/64 loss: 2.8559741973876953
Batch 6/64 loss: 1.7758078575134277
Batch 7/64 loss: 1.811617374420166
Batch 8/64 loss: 1.8200984001159668
Batch 9/64 loss: 1.8351383209228516
Batch 10/64 loss: 2.231754779815674
Batch 11/64 loss: 2.158017158508301
Batch 12/64 loss: 3.054035186767578
Batch 13/64 loss: 1.9557924270629883
Batch 14/64 loss: 2.154369354248047
Batch 15/64 loss: 1.8042969703674316
Batch 16/64 loss: 4.915574073791504
Batch 17/64 loss: 1.7089381217956543
Batch 18/64 loss: 1.8526062965393066
Batch 19/64 loss: 1.7881650924682617
Batch 20/64 loss: 2.0621137619018555
Batch 21/64 loss: 1.9830594062805176
Batch 22/64 loss: 1.7252659797668457
Batch 23/64 loss: 1.8692030906677246
Batch 24/64 loss: 1.7830586433410645
Batch 25/64 loss: 1.6533913612365723
Batch 26/64 loss: 3.416055202484131
Batch 27/64 loss: 2.070977210998535
Batch 28/64 loss: 1.898209571838379
Batch 29/64 loss: 1.8592801094055176
Batch 30/64 loss: 1.849632740020752
Batch 31/64 loss: 2.1742591857910156
Batch 32/64 loss: 1.8040146827697754
Batch 33/64 loss: 2.0275697708129883
Batch 34/64 loss: 1.8497605323791504
Batch 35/64 loss: 2.148658275604248
Batch 36/64 loss: 1.847135066986084
Batch 37/64 loss: 1.7938847541809082
Batch 38/64 loss: 1.7495217323303223
Batch 39/64 loss: 3.1489548683166504
Batch 40/64 loss: 1.9105725288391113
Batch 41/64 loss: 1.939857006072998
Batch 42/64 loss: 1.6895318031311035
Batch 43/64 loss: 1.9217114448547363
Batch 44/64 loss: 1.972144603729248
Batch 45/64 loss: 2.114063262939453
Batch 46/64 loss: 1.8175463676452637
Batch 47/64 loss: 1.9004950523376465
Batch 48/64 loss: 1.8265690803527832
Batch 49/64 loss: 1.6860957145690918
Batch 50/64 loss: 2.1151905059814453
Batch 51/64 loss: 1.8838486671447754
Batch 52/64 loss: 1.8689522743225098
Batch 53/64 loss: 1.9672274589538574
Batch 54/64 loss: 1.811997413635254
Batch 55/64 loss: 1.7357902526855469
Batch 56/64 loss: 4.182103633880615
Batch 57/64 loss: 1.7078661918640137
Batch 58/64 loss: 2.139477252960205
Batch 59/64 loss: 4.037779331207275
Batch 60/64 loss: 1.9966363906860352
Batch 61/64 loss: 1.8046903610229492
Batch 62/64 loss: 1.6904230117797852
Batch 63/64 loss: 1.9371657371520996
Batch 64/64 loss: -1.7577733993530273
Epoch 327  Train loss: 2.0523311652389227  Val loss: 1.5811301686919432
Epoch 328
-------------------------------
Batch 1/64 loss: 1.7592840194702148
Batch 2/64 loss: 1.638092041015625
Batch 3/64 loss: 1.7543230056762695
Batch 4/64 loss: 1.9072976112365723
Batch 5/64 loss: 2.1397743225097656
Batch 6/64 loss: 2.058145523071289
Batch 7/64 loss: 2.8593521118164062
Batch 8/64 loss: 1.8362689018249512
Batch 9/64 loss: 1.8655776977539062
Batch 10/64 loss: 1.7735905647277832
Batch 11/64 loss: 3.3508405685424805
Batch 12/64 loss: 1.7501616477966309
Batch 13/64 loss: 1.8883624076843262
Batch 14/64 loss: 1.7864813804626465
Batch 15/64 loss: 1.744588851928711
Batch 16/64 loss: 1.7502388954162598
Batch 17/64 loss: 1.739095687866211
Batch 18/64 loss: 1.9152641296386719
Batch 19/64 loss: 1.815870761871338
Batch 20/64 loss: 1.8748283386230469
Batch 21/64 loss: 1.825779914855957
Batch 22/64 loss: 1.9390168190002441
Batch 23/64 loss: 1.6929144859313965
Batch 24/64 loss: 1.7706170082092285
Batch 25/64 loss: 4.900115489959717
Batch 26/64 loss: 1.790140151977539
Batch 27/64 loss: 2.64072847366333
Batch 28/64 loss: 2.147928237915039
Batch 29/64 loss: 1.9048075675964355
Batch 30/64 loss: 3.0623483657836914
Batch 31/64 loss: 1.9037580490112305
Batch 32/64 loss: 1.7889351844787598
Batch 33/64 loss: 1.7309684753417969
Batch 34/64 loss: 1.79799222946167
Batch 35/64 loss: 1.7871942520141602
Batch 36/64 loss: 2.0277891159057617
Batch 37/64 loss: 1.6073789596557617
Batch 38/64 loss: 1.8073229789733887
Batch 39/64 loss: 1.8673138618469238
Batch 40/64 loss: 1.7879648208618164
Batch 41/64 loss: 1.8585400581359863
Batch 42/64 loss: 1.7140259742736816
Batch 43/64 loss: 1.8451595306396484
Batch 44/64 loss: 1.8626527786254883
Batch 45/64 loss: 2.057523250579834
Batch 46/64 loss: 1.8820819854736328
Batch 47/64 loss: 1.9512429237365723
Batch 48/64 loss: 3.863372802734375
Batch 49/64 loss: 2.1551952362060547
Batch 50/64 loss: 2.659529209136963
Batch 51/64 loss: 2.0841846466064453
Batch 52/64 loss: 1.7239761352539062
Batch 53/64 loss: 1.7674684524536133
Batch 54/64 loss: 1.6532564163208008
Batch 55/64 loss: 1.7777910232543945
Batch 56/64 loss: 1.7097792625427246
Batch 57/64 loss: 4.095770359039307
Batch 58/64 loss: 1.8231439590454102
Batch 59/64 loss: 1.7412800788879395
Batch 60/64 loss: 1.7772417068481445
Batch 61/64 loss: 1.682680606842041
Batch 62/64 loss: 1.7530407905578613
Batch 63/64 loss: 2.1033053398132324
Batch 64/64 loss: -1.5896539688110352
Epoch 328  Train loss: 1.997465960184733  Val loss: 1.593238017813037
Epoch 329
-------------------------------
Batch 1/64 loss: 3.047729015350342
Batch 2/64 loss: 1.833195686340332
Batch 3/64 loss: 1.8973054885864258
Batch 4/64 loss: 1.793628215789795
Batch 5/64 loss: 2.097487449645996
Batch 6/64 loss: 1.7363696098327637
Batch 7/64 loss: 1.949389934539795
Batch 8/64 loss: 1.8927116394042969
Batch 9/64 loss: 1.8917436599731445
Batch 10/64 loss: 1.8499455451965332
Batch 11/64 loss: 3.31072998046875
Batch 12/64 loss: 1.8343095779418945
Batch 13/64 loss: 1.749281883239746
Batch 14/64 loss: 2.96622896194458
Batch 15/64 loss: 1.7623624801635742
Batch 16/64 loss: 1.6158084869384766
Batch 17/64 loss: 2.073115825653076
Batch 18/64 loss: 1.8679633140563965
Batch 19/64 loss: 2.1426286697387695
Batch 20/64 loss: 1.765089511871338
Batch 21/64 loss: 1.707228183746338
Batch 22/64 loss: 1.9254870414733887
Batch 23/64 loss: 1.8112506866455078
Batch 24/64 loss: 1.7493228912353516
Batch 25/64 loss: 1.7830429077148438
Batch 26/64 loss: 1.7455968856811523
Batch 27/64 loss: 1.7748231887817383
Batch 28/64 loss: 2.1353187561035156
Batch 29/64 loss: 1.8254318237304688
Batch 30/64 loss: 1.773005485534668
Batch 31/64 loss: 2.212695598602295
Batch 32/64 loss: 3.7625246047973633
Batch 33/64 loss: 1.7356147766113281
Batch 34/64 loss: 1.8331336975097656
Batch 35/64 loss: 1.9030709266662598
Batch 36/64 loss: 1.710446834564209
Batch 37/64 loss: 2.27396297454834
Batch 38/64 loss: 1.65285062789917
Batch 39/64 loss: 1.8307595252990723
Batch 40/64 loss: 1.5911240577697754
Batch 41/64 loss: 1.740175724029541
Batch 42/64 loss: 2.0856900215148926
Batch 43/64 loss: 1.5908703804016113
Batch 44/64 loss: 1.6204400062561035
Batch 45/64 loss: 1.7062764167785645
Batch 46/64 loss: 1.7635111808776855
Batch 47/64 loss: 1.6673927307128906
Batch 48/64 loss: 1.8069214820861816
Batch 49/64 loss: 1.863825798034668
Batch 50/64 loss: 3.237745761871338
Batch 51/64 loss: 1.6307730674743652
Batch 52/64 loss: 2.000556468963623
Batch 53/64 loss: 1.815253734588623
Batch 54/64 loss: 1.849785327911377
Batch 55/64 loss: 1.7364482879638672
Batch 56/64 loss: 1.8997077941894531
Batch 57/64 loss: 4.637669563293457
Batch 58/64 loss: 1.9045300483703613
Batch 59/64 loss: 1.6591782569885254
Batch 60/64 loss: 1.9840312004089355
Batch 61/64 loss: 2.4743480682373047
Batch 62/64 loss: 2.6004886627197266
Batch 63/64 loss: 1.78471040725708
Batch 64/64 loss: -1.4568586349487305
Epoch 329  Train loss: 1.973041612961713  Val loss: 1.5234309979730456
Epoch 330
-------------------------------
Batch 1/64 loss: 1.8853631019592285
Batch 2/64 loss: 1.8283238410949707
Batch 3/64 loss: 1.9141716957092285
Batch 4/64 loss: 1.9021329879760742
Batch 5/64 loss: 1.758554458618164
Batch 6/64 loss: 1.8234224319458008
Batch 7/64 loss: 1.8337059020996094
Batch 8/64 loss: 1.8624863624572754
Batch 9/64 loss: 4.133864879608154
Batch 10/64 loss: 1.7233591079711914
Batch 11/64 loss: 2.0029678344726562
Batch 12/64 loss: 1.9205341339111328
Batch 13/64 loss: 2.84187650680542
Batch 14/64 loss: 1.9063239097595215
Batch 15/64 loss: 1.9617486000061035
Batch 16/64 loss: 1.6329898834228516
Batch 17/64 loss: 2.243619441986084
Batch 18/64 loss: 1.717029094696045
Batch 19/64 loss: 1.7523894309997559
Batch 20/64 loss: 1.6472277641296387
Batch 21/64 loss: 1.911449909210205
Batch 22/64 loss: 3.892286777496338
Batch 23/64 loss: 1.8078808784484863
Batch 24/64 loss: 1.7413649559020996
Batch 25/64 loss: 2.754157543182373
Batch 26/64 loss: 1.7242331504821777
Batch 27/64 loss: 1.6323800086975098
Batch 28/64 loss: 1.7058091163635254
Batch 29/64 loss: 1.817514419555664
Batch 30/64 loss: 1.6697468757629395
Batch 31/64 loss: 1.8955302238464355
Batch 32/64 loss: 2.075735569000244
Batch 33/64 loss: 2.767538547515869
Batch 34/64 loss: 1.7863149642944336
Batch 35/64 loss: 1.7607035636901855
Batch 36/64 loss: 1.7666635513305664
Batch 37/64 loss: 1.6498618125915527
Batch 38/64 loss: 1.8260960578918457
Batch 39/64 loss: 1.7091875076293945
Batch 40/64 loss: 1.5725188255310059
Batch 41/64 loss: 1.7124419212341309
Batch 42/64 loss: 2.069192409515381
Batch 43/64 loss: 1.8240456581115723
Batch 44/64 loss: 1.743398666381836
Batch 45/64 loss: 1.7507719993591309
Batch 46/64 loss: 2.0463924407958984
Batch 47/64 loss: 1.7536449432373047
Batch 48/64 loss: 1.7794337272644043
Batch 49/64 loss: 1.6988015174865723
Batch 50/64 loss: 1.6601004600524902
Batch 51/64 loss: 1.650599479675293
Batch 52/64 loss: 1.8864164352416992
Batch 53/64 loss: 1.7273521423339844
Batch 54/64 loss: 4.685201168060303
Batch 55/64 loss: 1.6099815368652344
Batch 56/64 loss: 1.7849822044372559
Batch 57/64 loss: 1.6626472473144531
Batch 58/64 loss: 1.6539244651794434
Batch 59/64 loss: 2.285168170928955
Batch 60/64 loss: 1.59476900100708
Batch 61/64 loss: 1.800736427307129
Batch 62/64 loss: 2.4775586128234863
Batch 63/64 loss: 1.742497444152832
Batch 64/64 loss: -1.046473503112793
Epoch 330  Train loss: 1.9384198992860084  Val loss: 1.5338396288684963
Epoch 331
-------------------------------
Batch 1/64 loss: 1.8149518966674805
Batch 2/64 loss: 1.8362021446228027
Batch 3/64 loss: 1.7685441970825195
Batch 4/64 loss: 2.077167510986328
Batch 5/64 loss: 1.6981110572814941
Batch 6/64 loss: 1.7983355522155762
Batch 7/64 loss: 1.8776488304138184
Batch 8/64 loss: 1.644944667816162
Batch 9/64 loss: 1.9820408821105957
Batch 10/64 loss: 2.2792458534240723
Batch 11/64 loss: 4.64059591293335
Batch 12/64 loss: 3.9379167556762695
Batch 13/64 loss: 1.8323745727539062
Batch 14/64 loss: 1.7783541679382324
Batch 15/64 loss: 2.5777926445007324
Batch 16/64 loss: 1.6289067268371582
Batch 17/64 loss: 1.9854912757873535
Batch 18/64 loss: 1.8115849494934082
Batch 19/64 loss: 2.994288921356201
Batch 20/64 loss: 1.8391199111938477
Batch 21/64 loss: 1.939568042755127
Batch 22/64 loss: 1.8646035194396973
Batch 23/64 loss: 1.792475700378418
Batch 24/64 loss: 1.7658162117004395
Batch 25/64 loss: 1.6318016052246094
Batch 26/64 loss: 1.6649694442749023
Batch 27/64 loss: 1.8711447715759277
Batch 28/64 loss: 1.7529182434082031
Batch 29/64 loss: 1.775468349456787
Batch 30/64 loss: 1.8850221633911133
Batch 31/64 loss: 1.6502485275268555
Batch 32/64 loss: 1.7328062057495117
Batch 33/64 loss: 2.2943310737609863
Batch 34/64 loss: 1.708287239074707
Batch 35/64 loss: 2.134087562561035
Batch 36/64 loss: 1.842648983001709
Batch 37/64 loss: 1.652742862701416
Batch 38/64 loss: 1.854912281036377
Batch 39/64 loss: 1.6696147918701172
Batch 40/64 loss: 1.7730317115783691
Batch 41/64 loss: 1.8302702903747559
Batch 42/64 loss: 1.7654519081115723
Batch 43/64 loss: 1.7273974418640137
Batch 44/64 loss: 1.9404630661010742
Batch 45/64 loss: 1.9804697036743164
Batch 46/64 loss: 1.6927289962768555
Batch 47/64 loss: 1.8692030906677246
Batch 48/64 loss: 1.7348847389221191
Batch 49/64 loss: 1.7086362838745117
Batch 50/64 loss: 1.5667710304260254
Batch 51/64 loss: 3.056497097015381
Batch 52/64 loss: 4.346883773803711
Batch 53/64 loss: 1.916707992553711
Batch 54/64 loss: 1.743729591369629
Batch 55/64 loss: 1.8030691146850586
Batch 56/64 loss: 1.7861981391906738
Batch 57/64 loss: 1.8046879768371582
Batch 58/64 loss: 1.9639782905578613
Batch 59/64 loss: 1.676070213317871
Batch 60/64 loss: 1.5884876251220703
Batch 61/64 loss: 1.7765398025512695
Batch 62/64 loss: 1.8329906463623047
Batch 63/64 loss: 1.5819087028503418
Batch 64/64 loss: -1.7984285354614258
Epoch 331  Train loss: 1.9357697542975931  Val loss: 1.4733574070881323
Epoch 332
-------------------------------
Batch 1/64 loss: 1.7014427185058594
Batch 2/64 loss: 1.6338262557983398
Batch 3/64 loss: 1.6668663024902344
Batch 4/64 loss: 1.6688976287841797
Batch 5/64 loss: 1.7328767776489258
Batch 6/64 loss: 2.2607436180114746
Batch 7/64 loss: 1.697608470916748
Batch 8/64 loss: 1.6316051483154297
Batch 9/64 loss: 1.7973461151123047
Batch 10/64 loss: 2.7251319885253906
Batch 11/64 loss: 1.7557692527770996
Batch 12/64 loss: 1.7950568199157715
Batch 13/64 loss: 1.679901123046875
Batch 14/64 loss: 1.9192767143249512
Batch 15/64 loss: 1.6185626983642578
Batch 16/64 loss: 2.0018081665039062
Batch 17/64 loss: 1.7411980628967285
Batch 18/64 loss: 2.1193532943725586
Batch 19/64 loss: 1.9493212699890137
Batch 20/64 loss: 2.9459409713745117
Batch 21/64 loss: 1.6173324584960938
Batch 22/64 loss: 1.811370849609375
Batch 23/64 loss: 1.8145074844360352
Batch 24/64 loss: 2.008901596069336
Batch 25/64 loss: 1.7037644386291504
Batch 26/64 loss: 1.7577242851257324
Batch 27/64 loss: 1.720846176147461
Batch 28/64 loss: 1.9085197448730469
Batch 29/64 loss: 1.7123165130615234
Batch 30/64 loss: 3.5888237953186035
Batch 31/64 loss: 1.6463007926940918
Batch 32/64 loss: 1.8405075073242188
Batch 33/64 loss: 2.115212917327881
Batch 34/64 loss: 1.822256088256836
Batch 35/64 loss: 1.9391822814941406
Batch 36/64 loss: 2.0390377044677734
Batch 37/64 loss: 1.9276633262634277
Batch 38/64 loss: 4.305427074432373
Batch 39/64 loss: 2.3500466346740723
Batch 40/64 loss: 1.9725117683410645
Batch 41/64 loss: 1.7717642784118652
Batch 42/64 loss: 2.6953344345092773
Batch 43/64 loss: 2.1043262481689453
Batch 44/64 loss: 2.699441909790039
Batch 45/64 loss: 2.067625045776367
Batch 46/64 loss: 1.9957585334777832
Batch 47/64 loss: 1.8046765327453613
Batch 48/64 loss: 2.0107898712158203
Batch 49/64 loss: 1.8721437454223633
Batch 50/64 loss: 1.8388824462890625
Batch 51/64 loss: 2.0563430786132812
Batch 52/64 loss: 3.2253098487854004
Batch 53/64 loss: 1.966583251953125
Batch 54/64 loss: 4.888740539550781
Batch 55/64 loss: 2.0397677421569824
Batch 56/64 loss: 1.7362384796142578
Batch 57/64 loss: 1.6412372589111328
Batch 58/64 loss: 2.216586112976074
Batch 59/64 loss: 1.7410764694213867
Batch 60/64 loss: 1.832132339477539
Batch 61/64 loss: 2.326380729675293
Batch 62/64 loss: 2.74006986618042
Batch 63/64 loss: 1.9299955368041992
Batch 64/64 loss: -1.5709333419799805
Epoch 332  Train loss: 2.034004566716213  Val loss: 1.8274129756127846
Epoch 333
-------------------------------
Batch 1/64 loss: 1.7432494163513184
Batch 2/64 loss: 3.114600658416748
Batch 3/64 loss: 2.26621675491333
Batch 4/64 loss: 2.031674385070801
Batch 5/64 loss: 2.2262048721313477
Batch 6/64 loss: 2.9109020233154297
Batch 7/64 loss: 2.012417793273926
Batch 8/64 loss: 1.7519960403442383
Batch 9/64 loss: 1.781165599822998
Batch 10/64 loss: 2.1631760597229004
Batch 11/64 loss: 1.7374000549316406
Batch 12/64 loss: 4.8024444580078125
Batch 13/64 loss: 1.7440881729125977
Batch 14/64 loss: 1.7630548477172852
Batch 15/64 loss: 1.778611183166504
Batch 16/64 loss: 1.766188144683838
Batch 17/64 loss: 2.1209306716918945
Batch 18/64 loss: 1.7176580429077148
Batch 19/64 loss: 1.8135967254638672
Batch 20/64 loss: 3.0718135833740234
Batch 21/64 loss: 1.738368034362793
Batch 22/64 loss: 1.746253490447998
Batch 23/64 loss: 1.6346874237060547
Batch 24/64 loss: 1.8460192680358887
Batch 25/64 loss: 3.540910243988037
Batch 26/64 loss: 1.8855738639831543
Batch 27/64 loss: 2.0674891471862793
Batch 28/64 loss: 2.2378406524658203
Batch 29/64 loss: 3.8305506706237793
Batch 30/64 loss: 1.67112398147583
Batch 31/64 loss: 1.9127378463745117
Batch 32/64 loss: 1.9219727516174316
Batch 33/64 loss: 1.843879222869873
Batch 34/64 loss: 1.841529369354248
Batch 35/64 loss: 1.7578577995300293
Batch 36/64 loss: 2.2246646881103516
Batch 37/64 loss: 1.9521832466125488
Batch 38/64 loss: 2.028698444366455
Batch 39/64 loss: 1.7439289093017578
Batch 40/64 loss: 1.9760560989379883
Batch 41/64 loss: 1.7183523178100586
Batch 42/64 loss: 1.6499428749084473
Batch 43/64 loss: 1.8142790794372559
Batch 44/64 loss: 1.739051342010498
Batch 45/64 loss: 1.8938446044921875
Batch 46/64 loss: 1.721601963043213
Batch 47/64 loss: 1.7827367782592773
Batch 48/64 loss: 2.3273730278015137
Batch 49/64 loss: 2.1818723678588867
Batch 50/64 loss: 1.6525721549987793
Batch 51/64 loss: 1.8012094497680664
Batch 52/64 loss: 1.6075382232666016
Batch 53/64 loss: 1.6616511344909668
Batch 54/64 loss: 1.7551169395446777
Batch 55/64 loss: 2.0278186798095703
Batch 56/64 loss: 1.7131876945495605
Batch 57/64 loss: 1.8837156295776367
Batch 58/64 loss: 1.7390375137329102
Batch 59/64 loss: 1.667823314666748
Batch 60/64 loss: 1.7452940940856934
Batch 61/64 loss: 1.8619999885559082
Batch 62/64 loss: 4.695627689361572
Batch 63/64 loss: 1.902167797088623
Batch 64/64 loss: -1.644291877746582
Epoch 333  Train loss: 2.0240048689000747  Val loss: 1.5162001934248148
Epoch 334
-------------------------------
Batch 1/64 loss: 1.5501422882080078
Batch 2/64 loss: 1.853726863861084
Batch 3/64 loss: 1.6378889083862305
Batch 4/64 loss: 1.620887279510498
Batch 5/64 loss: 2.004063129425049
Batch 6/64 loss: 2.952523708343506
Batch 7/64 loss: 1.6799540519714355
Batch 8/64 loss: 1.9429097175598145
Batch 9/64 loss: 1.6177282333374023
Batch 10/64 loss: 2.031904697418213
Batch 11/64 loss: 2.2772645950317383
Batch 12/64 loss: 1.7018475532531738
Batch 13/64 loss: 1.6271677017211914
Batch 14/64 loss: 1.7460460662841797
Batch 15/64 loss: 1.666839599609375
Batch 16/64 loss: 2.377769947052002
Batch 17/64 loss: 1.7430524826049805
Batch 18/64 loss: 1.749185562133789
Batch 19/64 loss: 1.7563281059265137
Batch 20/64 loss: 1.7110400199890137
Batch 21/64 loss: 1.829150676727295
Batch 22/64 loss: 1.6669893264770508
Batch 23/64 loss: 1.7531466484069824
Batch 24/64 loss: 1.7044696807861328
Batch 25/64 loss: 4.6345906257629395
Batch 26/64 loss: 1.6032624244689941
Batch 27/64 loss: 1.728261947631836
Batch 28/64 loss: 2.013759136199951
Batch 29/64 loss: 1.6093430519104004
Batch 30/64 loss: 1.8362045288085938
Batch 31/64 loss: 1.667191505432129
Batch 32/64 loss: 1.817166805267334
Batch 33/64 loss: 1.6797986030578613
Batch 34/64 loss: 1.884495735168457
Batch 35/64 loss: 1.720191478729248
Batch 36/64 loss: 1.8487434387207031
Batch 37/64 loss: 1.7941865921020508
Batch 38/64 loss: 1.719313144683838
Batch 39/64 loss: 1.6310911178588867
Batch 40/64 loss: 1.614689826965332
Batch 41/64 loss: 2.8806958198547363
Batch 42/64 loss: 1.8279647827148438
Batch 43/64 loss: 1.7699642181396484
Batch 44/64 loss: 1.748856544494629
Batch 45/64 loss: 1.565744400024414
Batch 46/64 loss: 1.6559157371520996
Batch 47/64 loss: 1.6480183601379395
Batch 48/64 loss: 2.3185625076293945
Batch 49/64 loss: 1.7427010536193848
Batch 50/64 loss: 1.7838115692138672
Batch 51/64 loss: 2.624544143676758
Batch 52/64 loss: 3.7296271324157715
Batch 53/64 loss: 1.7355499267578125
Batch 54/64 loss: 1.7644305229187012
Batch 55/64 loss: 1.7873225212097168
Batch 56/64 loss: 2.209327220916748
Batch 57/64 loss: 1.8852410316467285
Batch 58/64 loss: 1.6862616539001465
Batch 59/64 loss: 1.8400826454162598
Batch 60/64 loss: 4.2960591316223145
Batch 61/64 loss: 1.888298511505127
Batch 62/64 loss: 2.202934741973877
Batch 63/64 loss: 2.092482566833496
Batch 64/64 loss: -1.7239503860473633
Epoch 334  Train loss: 1.9199333452710918  Val loss: 1.4857892695161485
Epoch 335
-------------------------------
Batch 1/64 loss: 1.810716152191162
Batch 2/64 loss: 1.6155414581298828
Batch 3/64 loss: 1.6182799339294434
Batch 4/64 loss: 1.734377384185791
Batch 5/64 loss: 2.8748483657836914
Batch 6/64 loss: 1.8897018432617188
Batch 7/64 loss: 1.6508502960205078
Batch 8/64 loss: 1.6480803489685059
Batch 9/64 loss: 1.7778401374816895
Batch 10/64 loss: 1.6598272323608398
Batch 11/64 loss: 1.7368803024291992
Batch 12/64 loss: 1.6953420639038086
Batch 13/64 loss: 1.6825523376464844
Batch 14/64 loss: 1.7217483520507812
Batch 15/64 loss: 1.5973258018493652
Batch 16/64 loss: 1.7041511535644531
Batch 17/64 loss: 1.6746807098388672
Batch 18/64 loss: 1.9228854179382324
Batch 19/64 loss: 1.8453540802001953
Batch 20/64 loss: 1.779222011566162
Batch 21/64 loss: 1.8679265975952148
Batch 22/64 loss: 1.6050987243652344
Batch 23/64 loss: 1.919724941253662
Batch 24/64 loss: 2.286996364593506
Batch 25/64 loss: 1.7641372680664062
Batch 26/64 loss: 1.879490852355957
Batch 27/64 loss: 1.8080673217773438
Batch 28/64 loss: 1.6665329933166504
Batch 29/64 loss: 4.865406036376953
Batch 30/64 loss: 1.6557917594909668
Batch 31/64 loss: 1.6738953590393066
Batch 32/64 loss: 1.6985397338867188
Batch 33/64 loss: 2.4106788635253906
Batch 34/64 loss: 2.798464775085449
Batch 35/64 loss: 1.9413814544677734
Batch 36/64 loss: 1.637995719909668
Batch 37/64 loss: 1.6080574989318848
Batch 38/64 loss: 1.8111472129821777
Batch 39/64 loss: 2.0051393508911133
Batch 40/64 loss: 4.098761081695557
Batch 41/64 loss: 2.470378875732422
Batch 42/64 loss: 2.149433135986328
Batch 43/64 loss: 1.6076312065124512
Batch 44/64 loss: 1.8890471458435059
Batch 45/64 loss: 1.8964934349060059
Batch 46/64 loss: 1.7008261680603027
Batch 47/64 loss: 1.752730369567871
Batch 48/64 loss: 1.8025493621826172
Batch 49/64 loss: 2.038501739501953
Batch 50/64 loss: 1.646871566772461
Batch 51/64 loss: 1.7079248428344727
Batch 52/64 loss: 1.6146998405456543
Batch 53/64 loss: 1.6614952087402344
Batch 54/64 loss: 1.6144638061523438
Batch 55/64 loss: 1.6118097305297852
Batch 56/64 loss: 1.7189340591430664
Batch 57/64 loss: 2.116024971008301
Batch 58/64 loss: 1.6932778358459473
Batch 59/64 loss: 1.8740382194519043
Batch 60/64 loss: 1.5980377197265625
Batch 61/64 loss: 1.570439338684082
Batch 62/64 loss: 3.699918270111084
Batch 63/64 loss: 1.9938774108886719
Batch 64/64 loss: -1.8365097045898438
Epoch 335  Train loss: 1.8932621376187193  Val loss: 1.4682578253991825
Epoch 336
-------------------------------
Batch 1/64 loss: 1.63057279586792
Batch 2/64 loss: 2.1458444595336914
Batch 3/64 loss: 1.7568707466125488
Batch 4/64 loss: 3.8424696922302246
Batch 5/64 loss: 2.6414670944213867
Batch 6/64 loss: 1.873589038848877
Batch 7/64 loss: 1.9116501808166504
Batch 8/64 loss: 1.8232951164245605
Batch 9/64 loss: 1.7253832817077637
Batch 10/64 loss: 1.744746208190918
Batch 11/64 loss: 1.7083792686462402
Batch 12/64 loss: 1.9125666618347168
Batch 13/64 loss: 1.7627878189086914
Batch 14/64 loss: 1.7638683319091797
Batch 15/64 loss: 1.5802545547485352
Batch 16/64 loss: 1.8449530601501465
Batch 17/64 loss: 2.417081356048584
Batch 18/64 loss: 1.739311695098877
Batch 19/64 loss: 1.8728575706481934
Batch 20/64 loss: 1.72957181930542
Batch 21/64 loss: 2.7876458168029785
Batch 22/64 loss: 1.9041457176208496
Batch 23/64 loss: 2.5378198623657227
Batch 24/64 loss: 1.6962790489196777
Batch 25/64 loss: 1.5999879837036133
Batch 26/64 loss: 1.7645015716552734
Batch 27/64 loss: 1.9006257057189941
Batch 28/64 loss: 1.6914730072021484
Batch 29/64 loss: 1.8937106132507324
Batch 30/64 loss: 1.7264866828918457
Batch 31/64 loss: 1.559783935546875
Batch 32/64 loss: 1.779731273651123
Batch 33/64 loss: 1.7955875396728516
Batch 34/64 loss: 1.5845541954040527
Batch 35/64 loss: 1.7390546798706055
Batch 36/64 loss: 1.6195993423461914
Batch 37/64 loss: 1.6925272941589355
Batch 38/64 loss: 1.9223809242248535
Batch 39/64 loss: 1.8071298599243164
Batch 40/64 loss: 4.625863075256348
Batch 41/64 loss: 1.6595282554626465
Batch 42/64 loss: 1.881342887878418
Batch 43/64 loss: 1.6652865409851074
Batch 44/64 loss: 1.8327345848083496
Batch 45/64 loss: 1.7074828147888184
Batch 46/64 loss: 1.8070297241210938
Batch 47/64 loss: 3.1005311012268066
Batch 48/64 loss: 1.8092303276062012
Batch 49/64 loss: 1.682870864868164
Batch 50/64 loss: 4.159701347351074
Batch 51/64 loss: 1.7602696418762207
Batch 52/64 loss: 1.644681453704834
Batch 53/64 loss: 1.7701530456542969
Batch 54/64 loss: 1.6727328300476074
Batch 55/64 loss: 1.723991870880127
Batch 56/64 loss: 1.9254918098449707
Batch 57/64 loss: 1.691183090209961
Batch 58/64 loss: 1.787576675415039
Batch 59/64 loss: 1.648545265197754
Batch 60/64 loss: 1.6049485206604004
Batch 61/64 loss: 1.6373157501220703
Batch 62/64 loss: 1.5819406509399414
Batch 63/64 loss: 1.7957425117492676
Batch 64/64 loss: -1.835139274597168
Epoch 336  Train loss: 1.901652799868116  Val loss: 1.5022452574005651
Epoch 337
-------------------------------
Batch 1/64 loss: 1.8326172828674316
Batch 2/64 loss: 4.5920491218566895
Batch 3/64 loss: 1.6681146621704102
Batch 4/64 loss: 1.6515989303588867
Batch 5/64 loss: 1.8751153945922852
Batch 6/64 loss: 2.315329074859619
Batch 7/64 loss: 1.7853517532348633
Batch 8/64 loss: 2.924283981323242
Batch 9/64 loss: 2.025334358215332
Batch 10/64 loss: 1.6517257690429688
Batch 11/64 loss: 1.7049369812011719
Batch 12/64 loss: 1.7028388977050781
Batch 13/64 loss: 2.087099552154541
Batch 14/64 loss: 1.6184992790222168
Batch 15/64 loss: 1.7592592239379883
Batch 16/64 loss: 1.7776093482971191
Batch 17/64 loss: 2.641791820526123
Batch 18/64 loss: 1.8968138694763184
Batch 19/64 loss: 2.3282899856567383
Batch 20/64 loss: 1.6130623817443848
Batch 21/64 loss: 1.698934555053711
Batch 22/64 loss: 1.8437089920043945
Batch 23/64 loss: 1.7566494941711426
Batch 24/64 loss: 4.490994930267334
Batch 25/64 loss: 1.6541404724121094
Batch 26/64 loss: 1.780808925628662
Batch 27/64 loss: 1.600471019744873
Batch 28/64 loss: 1.6506943702697754
Batch 29/64 loss: 1.9085893630981445
Batch 30/64 loss: 1.7293777465820312
Batch 31/64 loss: 1.6994514465332031
Batch 32/64 loss: 1.6785669326782227
Batch 33/64 loss: 1.691694736480713
Batch 34/64 loss: 1.7970666885375977
Batch 35/64 loss: 1.6180448532104492
Batch 36/64 loss: 1.6407570838928223
Batch 37/64 loss: 1.5742931365966797
Batch 38/64 loss: 1.7604241371154785
Batch 39/64 loss: 1.7606754302978516
Batch 40/64 loss: 1.7455816268920898
Batch 41/64 loss: 1.9018363952636719
Batch 42/64 loss: 1.8056097030639648
Batch 43/64 loss: 1.7317166328430176
Batch 44/64 loss: 1.9102959632873535
Batch 45/64 loss: 1.7366023063659668
Batch 46/64 loss: 1.6059927940368652
Batch 47/64 loss: 1.6331729888916016
Batch 48/64 loss: 1.6990618705749512
Batch 49/64 loss: 1.7232871055603027
Batch 50/64 loss: 2.2176356315612793
Batch 51/64 loss: 4.0345683097839355
Batch 52/64 loss: 1.7831840515136719
Batch 53/64 loss: 1.6626076698303223
Batch 54/64 loss: 1.602126121520996
Batch 55/64 loss: 1.9100546836853027
Batch 56/64 loss: 1.6113147735595703
Batch 57/64 loss: 1.7539520263671875
Batch 58/64 loss: 2.034121513366699
Batch 59/64 loss: 1.683626651763916
Batch 60/64 loss: 1.6572422981262207
Batch 61/64 loss: 1.9908785820007324
Batch 62/64 loss: 1.6281604766845703
Batch 63/64 loss: 1.5568561553955078
Batch 64/64 loss: -1.8082351684570312
Epoch 337  Train loss: 1.8831431519751456  Val loss: 1.429415961721099
Saving best model, epoch: 337
Epoch 338
-------------------------------
Batch 1/64 loss: 1.7857327461242676
Batch 2/64 loss: 1.7108020782470703
Batch 3/64 loss: 1.7006444931030273
Batch 4/64 loss: 1.6250267028808594
Batch 5/64 loss: 2.455559253692627
Batch 6/64 loss: 1.6978034973144531
Batch 7/64 loss: 1.7482428550720215
Batch 8/64 loss: 2.7139010429382324
Batch 9/64 loss: 1.8520574569702148
Batch 10/64 loss: 2.2881546020507812
Batch 11/64 loss: 1.6347284317016602
Batch 12/64 loss: 1.870920181274414
Batch 13/64 loss: 1.6669120788574219
Batch 14/64 loss: 1.6230816841125488
Batch 15/64 loss: 1.6271862983703613
Batch 16/64 loss: 1.6084132194519043
Batch 17/64 loss: 1.8317131996154785
Batch 18/64 loss: 1.5799450874328613
Batch 19/64 loss: 1.8035001754760742
Batch 20/64 loss: 4.009994029998779
Batch 21/64 loss: 1.615499496459961
Batch 22/64 loss: 1.8906135559082031
Batch 23/64 loss: 1.784318447113037
Batch 24/64 loss: 1.899651050567627
Batch 25/64 loss: 1.8549814224243164
Batch 26/64 loss: 1.7656912803649902
Batch 27/64 loss: 1.58591890335083
Batch 28/64 loss: 2.0086774826049805
Batch 29/64 loss: 1.9381723403930664
Batch 30/64 loss: 1.7100958824157715
Batch 31/64 loss: 1.735903263092041
Batch 32/64 loss: 1.7044734954833984
Batch 33/64 loss: 4.091226577758789
Batch 34/64 loss: 2.029325008392334
Batch 35/64 loss: 1.8272762298583984
Batch 36/64 loss: 1.7550086975097656
Batch 37/64 loss: 1.7264037132263184
Batch 38/64 loss: 1.5738253593444824
Batch 39/64 loss: 1.7055048942565918
Batch 40/64 loss: 1.638650894165039
Batch 41/64 loss: 1.8885841369628906
Batch 42/64 loss: 1.6946463584899902
Batch 43/64 loss: 1.640207290649414
Batch 44/64 loss: 1.6465959548950195
Batch 45/64 loss: 1.6390314102172852
Batch 46/64 loss: 1.6605496406555176
Batch 47/64 loss: 1.62669038772583
Batch 48/64 loss: 1.8698277473449707
Batch 49/64 loss: 3.0938587188720703
Batch 50/64 loss: 4.695732116699219
Batch 51/64 loss: 1.674703598022461
Batch 52/64 loss: 1.6512622833251953
Batch 53/64 loss: 2.0099544525146484
Batch 54/64 loss: 2.163654327392578
Batch 55/64 loss: 1.6292433738708496
Batch 56/64 loss: 1.6271867752075195
Batch 57/64 loss: 1.9985003471374512
Batch 58/64 loss: 1.7504358291625977
Batch 59/64 loss: 1.6390094757080078
Batch 60/64 loss: 2.577544689178467
Batch 61/64 loss: 1.61836576461792
Batch 62/64 loss: 1.5923376083374023
Batch 63/64 loss: 2.0469346046447754
Batch 64/64 loss: -1.4771814346313477
Epoch 338  Train loss: 1.8980785556868012  Val loss: 1.450417102407344
Epoch 339
-------------------------------
Batch 1/64 loss: 2.224215030670166
Batch 2/64 loss: 2.721421718597412
Batch 3/64 loss: 4.600718975067139
Batch 4/64 loss: 1.7313566207885742
Batch 5/64 loss: 2.111307144165039
Batch 6/64 loss: 1.72468900680542
Batch 7/64 loss: 2.6244096755981445
Batch 8/64 loss: 1.8145623207092285
Batch 9/64 loss: 1.6635279655456543
Batch 10/64 loss: 3.8004212379455566
Batch 11/64 loss: 1.8040242195129395
Batch 12/64 loss: 1.709150791168213
Batch 13/64 loss: 1.8544111251831055
Batch 14/64 loss: 1.7724194526672363
Batch 15/64 loss: 1.6715750694274902
Batch 16/64 loss: 1.7311339378356934
Batch 17/64 loss: 1.6454143524169922
Batch 18/64 loss: 1.713134765625
Batch 19/64 loss: 1.6668548583984375
Batch 20/64 loss: 1.6352009773254395
Batch 21/64 loss: 1.716447353363037
Batch 22/64 loss: 1.9560790061950684
Batch 23/64 loss: 1.848435878753662
Batch 24/64 loss: 1.7424578666687012
Batch 25/64 loss: 1.5947051048278809
Batch 26/64 loss: 1.5859274864196777
Batch 27/64 loss: 1.7493705749511719
Batch 28/64 loss: 1.979787826538086
Batch 29/64 loss: 1.6017265319824219
Batch 30/64 loss: 1.632174015045166
Batch 31/64 loss: 2.2081313133239746
Batch 32/64 loss: 1.630941390991211
Batch 33/64 loss: 1.6651983261108398
Batch 34/64 loss: 1.6294875144958496
Batch 35/64 loss: 1.5628409385681152
Batch 36/64 loss: 1.5949630737304688
Batch 37/64 loss: 1.7234711647033691
Batch 38/64 loss: 2.29750394821167
Batch 39/64 loss: 1.5984506607055664
Batch 40/64 loss: 1.7805867195129395
Batch 41/64 loss: 1.6806721687316895
Batch 42/64 loss: 1.6987853050231934
Batch 43/64 loss: 1.9606895446777344
Batch 44/64 loss: 2.8851332664489746
Batch 45/64 loss: 1.6661109924316406
Batch 46/64 loss: 1.6690053939819336
Batch 47/64 loss: 4.1169633865356445
Batch 48/64 loss: 1.7586522102355957
Batch 49/64 loss: 1.761270523071289
Batch 50/64 loss: 1.7633862495422363
Batch 51/64 loss: 1.8143854141235352
Batch 52/64 loss: 1.5702180862426758
Batch 53/64 loss: 1.7535319328308105
Batch 54/64 loss: 1.6518917083740234
Batch 55/64 loss: 1.8075661659240723
Batch 56/64 loss: 1.6687145233154297
Batch 57/64 loss: 1.8392248153686523
Batch 58/64 loss: 1.722940444946289
Batch 59/64 loss: 1.7738323211669922
Batch 60/64 loss: 1.7078008651733398
Batch 61/64 loss: 1.7401776313781738
Batch 62/64 loss: 1.6557064056396484
Batch 63/64 loss: 1.7108793258666992
Batch 64/64 loss: -1.5673770904541016
Epoch 339  Train loss: 1.8748335969214347  Val loss: 1.48104479550496
Epoch 340
-------------------------------
Batch 1/64 loss: 1.8030767440795898
Batch 2/64 loss: 3.7225780487060547
Batch 3/64 loss: 1.8035659790039062
Batch 4/64 loss: 1.5662603378295898
Batch 5/64 loss: 1.9366536140441895
Batch 6/64 loss: 1.7886195182800293
Batch 7/64 loss: 1.8596577644348145
Batch 8/64 loss: 3.042659282684326
Batch 9/64 loss: 2.2654852867126465
Batch 10/64 loss: 1.8376855850219727
Batch 11/64 loss: 1.6906490325927734
Batch 12/64 loss: 1.7307219505310059
Batch 13/64 loss: 1.6122350692749023
Batch 14/64 loss: 1.9318313598632812
Batch 15/64 loss: 1.6470766067504883
Batch 16/64 loss: 1.6817750930786133
Batch 17/64 loss: 1.659348487854004
Batch 18/64 loss: 1.681291103363037
Batch 19/64 loss: 1.7283134460449219
Batch 20/64 loss: 1.6750860214233398
Batch 21/64 loss: 1.628950595855713
Batch 22/64 loss: 1.788454532623291
Batch 23/64 loss: 1.6362605094909668
Batch 24/64 loss: 1.6535053253173828
Batch 25/64 loss: 1.5646772384643555
Batch 26/64 loss: 1.8598918914794922
Batch 27/64 loss: 1.7180061340332031
Batch 28/64 loss: 2.663682460784912
Batch 29/64 loss: 1.76385498046875
Batch 30/64 loss: 1.5712451934814453
Batch 31/64 loss: 1.6638216972351074
Batch 32/64 loss: 4.487556457519531
Batch 33/64 loss: 2.023716926574707
Batch 34/64 loss: 1.8043389320373535
Batch 35/64 loss: 1.7223620414733887
Batch 36/64 loss: 1.9699015617370605
Batch 37/64 loss: 1.6194796562194824
Batch 38/64 loss: 1.7556161880493164
Batch 39/64 loss: 3.1527929306030273
Batch 40/64 loss: 1.6271238327026367
Batch 41/64 loss: 1.721388816833496
Batch 42/64 loss: 1.6775822639465332
Batch 43/64 loss: 1.8581600189208984
Batch 44/64 loss: 1.8351902961730957
Batch 45/64 loss: 1.8652844429016113
Batch 46/64 loss: 1.6857099533081055
Batch 47/64 loss: 1.6138644218444824
Batch 48/64 loss: 1.676455020904541
Batch 49/64 loss: 1.6302666664123535
Batch 50/64 loss: 1.9484457969665527
Batch 51/64 loss: 1.7735896110534668
Batch 52/64 loss: 1.5935754776000977
Batch 53/64 loss: 1.8686366081237793
Batch 54/64 loss: 4.136883735656738
Batch 55/64 loss: 1.7597298622131348
Batch 56/64 loss: 2.2159481048583984
Batch 57/64 loss: 1.6759843826293945
Batch 58/64 loss: 1.8517279624938965
Batch 59/64 loss: 1.7694993019104004
Batch 60/64 loss: 1.6576080322265625
Batch 61/64 loss: 1.6179375648498535
Batch 62/64 loss: 1.8715534210205078
Batch 63/64 loss: 1.765456199645996
Batch 64/64 loss: -1.853348731994629
Epoch 340  Train loss: 1.8826709934309418  Val loss: 1.4919068772358584
Epoch 341
-------------------------------
Batch 1/64 loss: 1.6694121360778809
Batch 2/64 loss: 1.6907391548156738
Batch 3/64 loss: 2.5618820190429688
Batch 4/64 loss: 1.6691198348999023
Batch 5/64 loss: 1.9057130813598633
Batch 6/64 loss: 1.7711176872253418
Batch 7/64 loss: 1.6107330322265625
Batch 8/64 loss: 1.6869702339172363
Batch 9/64 loss: 1.6747698783874512
Batch 10/64 loss: 1.590585708618164
Batch 11/64 loss: 1.5438408851623535
Batch 12/64 loss: 1.715815544128418
Batch 13/64 loss: 4.623683929443359
Batch 14/64 loss: 1.652735710144043
Batch 15/64 loss: 1.787501335144043
Batch 16/64 loss: 1.5870509147644043
Batch 17/64 loss: 1.6232290267944336
Batch 18/64 loss: 4.207130432128906
Batch 19/64 loss: 1.7176909446716309
Batch 20/64 loss: 1.7761998176574707
Batch 21/64 loss: 1.7339000701904297
Batch 22/64 loss: 1.7100143432617188
Batch 23/64 loss: 2.0123257637023926
Batch 24/64 loss: 1.8989982604980469
Batch 25/64 loss: 1.5337162017822266
Batch 26/64 loss: 2.130948066711426
Batch 27/64 loss: 1.6862311363220215
Batch 28/64 loss: 1.6379890441894531
Batch 29/64 loss: 1.7645177841186523
Batch 30/64 loss: 1.953554630279541
Batch 31/64 loss: 1.7443199157714844
Batch 32/64 loss: 2.6961569786071777
Batch 33/64 loss: 1.7508654594421387
Batch 34/64 loss: 2.040492534637451
Batch 35/64 loss: 1.6336841583251953
Batch 36/64 loss: 1.5936737060546875
Batch 37/64 loss: 1.6860218048095703
Batch 38/64 loss: 1.7192282676696777
Batch 39/64 loss: 1.7959566116333008
Batch 40/64 loss: 2.1502251625061035
Batch 41/64 loss: 1.869802474975586
Batch 42/64 loss: 2.749396324157715
Batch 43/64 loss: 1.7021536827087402
Batch 44/64 loss: 1.6463098526000977
Batch 45/64 loss: 1.6034679412841797
Batch 46/64 loss: 2.2911882400512695
Batch 47/64 loss: 1.5937366485595703
Batch 48/64 loss: 1.653843879699707
Batch 49/64 loss: 1.7902932167053223
Batch 50/64 loss: 4.019716739654541
Batch 51/64 loss: 1.7035551071166992
Batch 52/64 loss: 1.565971851348877
Batch 53/64 loss: 1.644711971282959
Batch 54/64 loss: 1.7645726203918457
Batch 55/64 loss: 1.7731738090515137
Batch 56/64 loss: 1.7165298461914062
Batch 57/64 loss: 1.717015266418457
Batch 58/64 loss: 1.598705768585205
Batch 59/64 loss: 1.6393656730651855
Batch 60/64 loss: 1.9776315689086914
Batch 61/64 loss: 1.7002387046813965
Batch 62/64 loss: 1.6235342025756836
Batch 63/64 loss: 1.878671646118164
Batch 64/64 loss: -1.9783344268798828
Epoch 341  Train loss: 1.8616247438916973  Val loss: 1.4142348954767705
Saving best model, epoch: 341
Epoch 342
-------------------------------
Batch 1/64 loss: 2.1882896423339844
Batch 2/64 loss: 2.043301582336426
Batch 3/64 loss: 1.7257122993469238
Batch 4/64 loss: 1.6992816925048828
Batch 5/64 loss: 1.7054247856140137
Batch 6/64 loss: 1.9439644813537598
Batch 7/64 loss: 1.722142219543457
Batch 8/64 loss: 1.7966837882995605
Batch 9/64 loss: 1.6971993446350098
Batch 10/64 loss: 2.7474923133850098
Batch 11/64 loss: 1.7481403350830078
Batch 12/64 loss: 1.7713265419006348
Batch 13/64 loss: 1.720409870147705
Batch 14/64 loss: 1.8322577476501465
Batch 15/64 loss: 1.709427833557129
Batch 16/64 loss: 1.636190414428711
Batch 17/64 loss: 1.663346767425537
Batch 18/64 loss: 1.6993370056152344
Batch 19/64 loss: 1.563521385192871
Batch 20/64 loss: 1.7844510078430176
Batch 21/64 loss: 1.5930747985839844
Batch 22/64 loss: 1.5965285301208496
Batch 23/64 loss: 1.7196273803710938
Batch 24/64 loss: 2.6726436614990234
Batch 25/64 loss: 1.6535735130310059
Batch 26/64 loss: 1.7491645812988281
Batch 27/64 loss: 1.6164779663085938
Batch 28/64 loss: 1.6381635665893555
Batch 29/64 loss: 4.675995826721191
Batch 30/64 loss: 1.953824520111084
Batch 31/64 loss: 1.5975332260131836
Batch 32/64 loss: 3.961183547973633
Batch 33/64 loss: 3.8511223793029785
Batch 34/64 loss: 1.5817303657531738
Batch 35/64 loss: 1.6002306938171387
Batch 36/64 loss: 1.6928205490112305
Batch 37/64 loss: 1.800140380859375
Batch 38/64 loss: 1.7321395874023438
Batch 39/64 loss: 1.7178397178649902
Batch 40/64 loss: 1.8475961685180664
Batch 41/64 loss: 2.468811511993408
Batch 42/64 loss: 1.605513095855713
Batch 43/64 loss: 1.6320862770080566
Batch 44/64 loss: 1.919661045074463
Batch 45/64 loss: 1.5727019309997559
Batch 46/64 loss: 1.8540582656860352
Batch 47/64 loss: 1.7545299530029297
Batch 48/64 loss: 1.6485223770141602
Batch 49/64 loss: 1.6797475814819336
Batch 50/64 loss: 1.624908447265625
Batch 51/64 loss: 1.7549028396606445
Batch 52/64 loss: 1.828108310699463
Batch 53/64 loss: 1.6600284576416016
Batch 54/64 loss: 1.6242108345031738
Batch 55/64 loss: 1.6193084716796875
Batch 56/64 loss: 1.5793962478637695
Batch 57/64 loss: 2.602695941925049
Batch 58/64 loss: 1.7264890670776367
Batch 59/64 loss: 1.6628637313842773
Batch 60/64 loss: 2.7687454223632812
Batch 61/64 loss: 1.6013011932373047
Batch 62/64 loss: 1.7590465545654297
Batch 63/64 loss: 1.8428006172180176
Batch 64/64 loss: -1.887497901916504
Epoch 342  Train loss: 1.8670451257743088  Val loss: 1.4819530605040874
Epoch 343
-------------------------------
Batch 1/64 loss: 2.4857125282287598
Batch 2/64 loss: 1.7402229309082031
Batch 3/64 loss: 1.7416605949401855
Batch 4/64 loss: 2.1779069900512695
Batch 5/64 loss: 1.8588542938232422
Batch 6/64 loss: 1.659616470336914
Batch 7/64 loss: 1.7019143104553223
Batch 8/64 loss: 1.9224700927734375
Batch 9/64 loss: 1.9363751411437988
Batch 10/64 loss: 1.5227203369140625
Batch 11/64 loss: 1.6321301460266113
Batch 12/64 loss: 1.8496484756469727
Batch 13/64 loss: 1.809964656829834
Batch 14/64 loss: 1.7773418426513672
Batch 15/64 loss: 1.7935481071472168
Batch 16/64 loss: 1.674642562866211
Batch 17/64 loss: 1.7761526107788086
Batch 18/64 loss: 1.6875958442687988
Batch 19/64 loss: 1.6767516136169434
Batch 20/64 loss: 1.774061679840088
Batch 21/64 loss: 1.6887083053588867
Batch 22/64 loss: 1.62367582321167
Batch 23/64 loss: 1.6012725830078125
Batch 24/64 loss: 2.374152183532715
Batch 25/64 loss: 1.5818490982055664
Batch 26/64 loss: 1.6790742874145508
Batch 27/64 loss: 1.740096092224121
Batch 28/64 loss: 1.6202449798583984
Batch 29/64 loss: 1.8249011039733887
Batch 30/64 loss: 1.6863207817077637
Batch 31/64 loss: 1.6809496879577637
Batch 32/64 loss: 2.043548583984375
Batch 33/64 loss: 1.697981834411621
Batch 34/64 loss: 1.7852940559387207
Batch 35/64 loss: 1.753946304321289
Batch 36/64 loss: 1.64326810836792
Batch 37/64 loss: 1.6564550399780273
Batch 38/64 loss: 1.750326156616211
Batch 39/64 loss: 1.896310806274414
Batch 40/64 loss: 1.7441725730895996
Batch 41/64 loss: 1.7836995124816895
Batch 42/64 loss: 1.8603334426879883
Batch 43/64 loss: 1.7270493507385254
Batch 44/64 loss: 2.0068721771240234
Batch 45/64 loss: 1.7573976516723633
Batch 46/64 loss: 2.383453845977783
Batch 47/64 loss: 1.6350088119506836
Batch 48/64 loss: 1.7304177284240723
Batch 49/64 loss: 1.8372807502746582
Batch 50/64 loss: 1.6055946350097656
Batch 51/64 loss: 4.553488731384277
Batch 52/64 loss: 3.8657498359680176
Batch 53/64 loss: 2.0030465126037598
Batch 54/64 loss: 2.9059090614318848
Batch 55/64 loss: 1.7181873321533203
Batch 56/64 loss: 1.890204906463623
Batch 57/64 loss: 1.7483038902282715
Batch 58/64 loss: 1.909013271331787
Batch 59/64 loss: 1.7132010459899902
Batch 60/64 loss: 3.8521833419799805
Batch 61/64 loss: 1.6942949295043945
Batch 62/64 loss: 1.763779640197754
Batch 63/64 loss: 4.157495498657227
Batch 64/64 loss: -1.7100791931152344
Epoch 343  Train loss: 1.9151568020091336  Val loss: 1.4943994476213487
Epoch 344
-------------------------------
Batch 1/64 loss: 1.7589988708496094
Batch 2/64 loss: 1.7861862182617188
Batch 3/64 loss: 1.8624415397644043
Batch 4/64 loss: 2.364657402038574
Batch 5/64 loss: 1.7069921493530273
Batch 6/64 loss: 1.6039557456970215
Batch 7/64 loss: 4.264420509338379
Batch 8/64 loss: 4.580759048461914
Batch 9/64 loss: 2.320340156555176
Batch 10/64 loss: 1.7971620559692383
Batch 11/64 loss: 1.8169846534729004
Batch 12/64 loss: 1.684600830078125
Batch 13/64 loss: 1.6353058815002441
Batch 14/64 loss: 1.8096075057983398
Batch 15/64 loss: 1.9223437309265137
Batch 16/64 loss: 1.780839443206787
Batch 17/64 loss: 1.7797455787658691
Batch 18/64 loss: 1.689885139465332
Batch 19/64 loss: 1.8952951431274414
Batch 20/64 loss: 1.811744213104248
Batch 21/64 loss: 2.05545711517334
Batch 22/64 loss: 1.812424659729004
Batch 23/64 loss: 1.886629581451416
Batch 24/64 loss: 1.7286477088928223
Batch 25/64 loss: 2.4447059631347656
Batch 26/64 loss: 2.3976964950561523
Batch 27/64 loss: 2.0064334869384766
Batch 28/64 loss: 1.8047800064086914
Batch 29/64 loss: 1.9207191467285156
Batch 30/64 loss: 2.075222969055176
Batch 31/64 loss: 1.7993130683898926
Batch 32/64 loss: 1.7462153434753418
Batch 33/64 loss: 1.6807122230529785
Batch 34/64 loss: 1.7949447631835938
Batch 35/64 loss: 1.8094806671142578
Batch 36/64 loss: 3.333761692047119
Batch 37/64 loss: 1.7696824073791504
Batch 38/64 loss: 2.1788783073425293
Batch 39/64 loss: 1.6672005653381348
Batch 40/64 loss: 1.7135562896728516
Batch 41/64 loss: 2.8754196166992188
Batch 42/64 loss: 1.920903205871582
Batch 43/64 loss: 1.8718714714050293
Batch 44/64 loss: 1.6599407196044922
Batch 45/64 loss: 1.8076634407043457
Batch 46/64 loss: 1.772712230682373
Batch 47/64 loss: 4.145156383514404
Batch 48/64 loss: 1.8229060173034668
Batch 49/64 loss: 2.0601511001586914
Batch 50/64 loss: 1.8164448738098145
Batch 51/64 loss: 1.9487652778625488
Batch 52/64 loss: 1.958794116973877
Batch 53/64 loss: 1.842796802520752
Batch 54/64 loss: 1.7302618026733398
Batch 55/64 loss: 1.9298720359802246
Batch 56/64 loss: 1.9064059257507324
Batch 57/64 loss: 1.7774100303649902
Batch 58/64 loss: 1.9025368690490723
Batch 59/64 loss: 2.86641788482666
Batch 60/64 loss: 1.7452068328857422
Batch 61/64 loss: 1.813342571258545
Batch 62/64 loss: 1.7529082298278809
Batch 63/64 loss: 1.7375173568725586
Batch 64/64 loss: -1.748307228088379
Epoch 344  Train loss: 1.989849453346402  Val loss: 1.5386997498187822
Epoch 345
-------------------------------
Batch 1/64 loss: 1.9819765090942383
Batch 2/64 loss: 1.6514091491699219
Batch 3/64 loss: 1.714531421661377
Batch 4/64 loss: 4.8048295974731445
Batch 5/64 loss: 1.6567511558532715
Batch 6/64 loss: 1.6957511901855469
Batch 7/64 loss: 1.731318473815918
Batch 8/64 loss: 1.7659201622009277
Batch 9/64 loss: 1.7212343215942383
Batch 10/64 loss: 1.7149982452392578
Batch 11/64 loss: 1.9207415580749512
Batch 12/64 loss: 2.9145407676696777
Batch 13/64 loss: 1.6023955345153809
Batch 14/64 loss: 1.9637432098388672
Batch 15/64 loss: 1.801711082458496
Batch 16/64 loss: 2.851154327392578
Batch 17/64 loss: 1.642812728881836
Batch 18/64 loss: 1.6213974952697754
Batch 19/64 loss: 1.6290912628173828
Batch 20/64 loss: 1.774580955505371
Batch 21/64 loss: 1.7205705642700195
Batch 22/64 loss: 1.6095080375671387
Batch 23/64 loss: 1.8109917640686035
Batch 24/64 loss: 1.635423183441162
Batch 25/64 loss: 2.2715320587158203
Batch 26/64 loss: 2.323594570159912
Batch 27/64 loss: 1.6711349487304688
Batch 28/64 loss: 1.9677238464355469
Batch 29/64 loss: 1.8250741958618164
Batch 30/64 loss: 1.9940619468688965
Batch 31/64 loss: 1.78765869140625
Batch 32/64 loss: 1.7016816139221191
Batch 33/64 loss: 1.8257169723510742
Batch 34/64 loss: 1.7154736518859863
Batch 35/64 loss: 1.9762582778930664
Batch 36/64 loss: 4.130991458892822
Batch 37/64 loss: 1.9328746795654297
Batch 38/64 loss: 2.9171018600463867
Batch 39/64 loss: 1.9817638397216797
Batch 40/64 loss: 2.227658271789551
Batch 41/64 loss: 1.7238240242004395
Batch 42/64 loss: 3.8269948959350586
Batch 43/64 loss: 1.7038636207580566
Batch 44/64 loss: 1.8206777572631836
Batch 45/64 loss: 1.761629581451416
Batch 46/64 loss: 1.9873361587524414
Batch 47/64 loss: 1.631446361541748
Batch 48/64 loss: 1.6731925010681152
Batch 49/64 loss: 2.2786831855773926
Batch 50/64 loss: 1.5906376838684082
Batch 51/64 loss: 1.7104716300964355
Batch 52/64 loss: 1.750593662261963
Batch 53/64 loss: 1.8596506118774414
Batch 54/64 loss: 1.9533190727233887
Batch 55/64 loss: 1.9545588493347168
Batch 56/64 loss: 1.7114434242248535
Batch 57/64 loss: 1.6650705337524414
Batch 58/64 loss: 2.055574417114258
Batch 59/64 loss: 1.7916507720947266
Batch 60/64 loss: 1.8457026481628418
Batch 61/64 loss: 1.6887612342834473
Batch 62/64 loss: 1.605916976928711
Batch 63/64 loss: 1.8632869720458984
Batch 64/64 loss: -1.8471946716308594
Epoch 345  Train loss: 1.9334364573160807  Val loss: 1.5015252758956856
Epoch 346
-------------------------------
Batch 1/64 loss: 2.4853968620300293
Batch 2/64 loss: 1.762770652770996
Batch 3/64 loss: 1.9252371788024902
Batch 4/64 loss: 1.6783790588378906
Batch 5/64 loss: 1.7077178955078125
Batch 6/64 loss: 1.779855728149414
Batch 7/64 loss: 1.5714144706726074
Batch 8/64 loss: 1.7141499519348145
Batch 9/64 loss: 1.8757596015930176
Batch 10/64 loss: 1.7083477973937988
Batch 11/64 loss: 1.6786775588989258
Batch 12/64 loss: 1.6352100372314453
Batch 13/64 loss: 1.5712203979492188
Batch 14/64 loss: 4.11162805557251
Batch 15/64 loss: 1.6276321411132812
Batch 16/64 loss: 1.8155527114868164
Batch 17/64 loss: 1.7820672988891602
Batch 18/64 loss: 2.036921977996826
Batch 19/64 loss: 1.6634783744812012
Batch 20/64 loss: 1.7578010559082031
Batch 21/64 loss: 1.7801342010498047
Batch 22/64 loss: 1.9445300102233887
Batch 23/64 loss: 1.6582164764404297
Batch 24/64 loss: 2.019423007965088
Batch 25/64 loss: 1.6782870292663574
Batch 26/64 loss: 1.8185687065124512
Batch 27/64 loss: 2.698031425476074
Batch 28/64 loss: 1.6857571601867676
Batch 29/64 loss: 1.9074044227600098
Batch 30/64 loss: 1.8583016395568848
Batch 31/64 loss: 1.6840400695800781
Batch 32/64 loss: 2.893249988555908
Batch 33/64 loss: 1.5861053466796875
Batch 34/64 loss: 1.7431550025939941
Batch 35/64 loss: 2.8613076210021973
Batch 36/64 loss: 1.782580852508545
Batch 37/64 loss: 1.6829586029052734
Batch 38/64 loss: 3.997128486633301
Batch 39/64 loss: 1.7373261451721191
Batch 40/64 loss: 1.6009202003479004
Batch 41/64 loss: 1.967947006225586
Batch 42/64 loss: 1.8686976432800293
Batch 43/64 loss: 1.7815632820129395
Batch 44/64 loss: 1.65230131149292
Batch 45/64 loss: 1.6986870765686035
Batch 46/64 loss: 1.5875458717346191
Batch 47/64 loss: 2.166567802429199
Batch 48/64 loss: 2.249142646789551
Batch 49/64 loss: 1.662200927734375
Batch 50/64 loss: 4.582383155822754
Batch 51/64 loss: 1.6058969497680664
Batch 52/64 loss: 1.8443760871887207
Batch 53/64 loss: 1.5676965713500977
Batch 54/64 loss: 1.7984390258789062
Batch 55/64 loss: 1.9474115371704102
Batch 56/64 loss: 2.0004897117614746
Batch 57/64 loss: 1.6612920761108398
Batch 58/64 loss: 1.9169921875
Batch 59/64 loss: 1.9161133766174316
Batch 60/64 loss: 1.7925853729248047
Batch 61/64 loss: 1.6458678245544434
Batch 62/64 loss: 1.661177158355713
Batch 63/64 loss: 1.6853418350219727
Batch 64/64 loss: -1.6763830184936523
Epoch 346  Train loss: 1.9060403823852539  Val loss: 1.4740487193733556
Epoch 347
-------------------------------
Batch 1/64 loss: 1.7418408393859863
Batch 2/64 loss: 1.7252912521362305
Batch 3/64 loss: 1.716844081878662
Batch 4/64 loss: 1.6739506721496582
Batch 5/64 loss: 1.691359519958496
Batch 6/64 loss: 1.7153935432434082
Batch 7/64 loss: 1.580169677734375
Batch 8/64 loss: 1.901242733001709
Batch 9/64 loss: 2.2548890113830566
Batch 10/64 loss: 2.6647539138793945
Batch 11/64 loss: 1.6802024841308594
Batch 12/64 loss: 1.7643351554870605
Batch 13/64 loss: 1.7109885215759277
Batch 14/64 loss: 4.653514385223389
Batch 15/64 loss: 1.8009414672851562
Batch 16/64 loss: 1.7831883430480957
Batch 17/64 loss: 1.7829790115356445
Batch 18/64 loss: 1.6178498268127441
Batch 19/64 loss: 1.7591743469238281
Batch 20/64 loss: 2.171271800994873
Batch 21/64 loss: 2.1992897987365723
Batch 22/64 loss: 1.6253981590270996
Batch 23/64 loss: 1.9305920600891113
Batch 24/64 loss: 1.7940964698791504
Batch 25/64 loss: 1.663954734802246
Batch 26/64 loss: 1.682030200958252
Batch 27/64 loss: 1.6206626892089844
Batch 28/64 loss: 1.7927570343017578
Batch 29/64 loss: 2.102566719055176
Batch 30/64 loss: 1.8642735481262207
Batch 31/64 loss: 2.016611099243164
Batch 32/64 loss: 1.691080093383789
Batch 33/64 loss: 1.8458037376403809
Batch 34/64 loss: 1.9416589736938477
Batch 35/64 loss: 1.8324570655822754
Batch 36/64 loss: 1.687042236328125
Batch 37/64 loss: 1.7372846603393555
Batch 38/64 loss: 1.842756748199463
Batch 39/64 loss: 1.8710765838623047
Batch 40/64 loss: 1.6748509407043457
Batch 41/64 loss: 1.5991997718811035
Batch 42/64 loss: 2.3660712242126465
Batch 43/64 loss: 2.833859920501709
Batch 44/64 loss: 1.6947822570800781
Batch 45/64 loss: 4.1892523765563965
Batch 46/64 loss: 1.6773004531860352
Batch 47/64 loss: 1.670546054840088
Batch 48/64 loss: 2.063131332397461
Batch 49/64 loss: 1.720808982849121
Batch 50/64 loss: 2.550997734069824
Batch 51/64 loss: 1.7306833267211914
Batch 52/64 loss: 1.8969225883483887
Batch 53/64 loss: 1.802259922027588
Batch 54/64 loss: 1.7539877891540527
Batch 55/64 loss: 3.7287068367004395
Batch 56/64 loss: 1.7562847137451172
Batch 57/64 loss: 1.7797179222106934
Batch 58/64 loss: 1.6863856315612793
Batch 59/64 loss: 1.6856083869934082
Batch 60/64 loss: 1.5796170234680176
Batch 61/64 loss: 1.867971420288086
Batch 62/64 loss: 1.7653303146362305
Batch 63/64 loss: 2.1513772010803223
Batch 64/64 loss: -1.767115592956543
Epoch 347  Train loss: 1.9142257353838752  Val loss: 1.4694376811129122
Epoch 348
-------------------------------
Batch 1/64 loss: 1.797867774963379
Batch 2/64 loss: 2.102750301361084
Batch 3/64 loss: 1.7708220481872559
Batch 4/64 loss: 1.8030085563659668
Batch 5/64 loss: 1.7460322380065918
Batch 6/64 loss: 1.683253288269043
Batch 7/64 loss: 1.7989592552185059
Batch 8/64 loss: 3.1244192123413086
Batch 9/64 loss: 1.8601036071777344
Batch 10/64 loss: 1.9867057800292969
Batch 11/64 loss: 2.1109371185302734
Batch 12/64 loss: 2.1816601753234863
Batch 13/64 loss: 2.2612767219543457
Batch 14/64 loss: 2.1036229133605957
Batch 15/64 loss: 2.1293811798095703
Batch 16/64 loss: 2.305866241455078
Batch 17/64 loss: 2.1844091415405273
Batch 18/64 loss: 2.3391990661621094
Batch 19/64 loss: 2.555891513824463
Batch 20/64 loss: 2.4463443756103516
Batch 21/64 loss: 2.261962413787842
Batch 22/64 loss: 2.064612865447998
Batch 23/64 loss: 2.5059595108032227
Batch 24/64 loss: 2.100706100463867
Batch 25/64 loss: 2.4264235496520996
Batch 26/64 loss: 3.5730080604553223
Batch 27/64 loss: 2.174866199493408
Batch 28/64 loss: 2.202914237976074
Batch 29/64 loss: 2.352443218231201
Batch 30/64 loss: 1.9898972511291504
Batch 31/64 loss: 2.347115993499756
Batch 32/64 loss: 2.305535316467285
Batch 33/64 loss: 2.118777275085449
Batch 34/64 loss: 2.0402565002441406
Batch 35/64 loss: 2.171708106994629
Batch 36/64 loss: 2.0388989448547363
Batch 37/64 loss: 2.8900327682495117
Batch 38/64 loss: 4.424947738647461
Batch 39/64 loss: 2.221930980682373
Batch 40/64 loss: 1.9646949768066406
Batch 41/64 loss: 2.225827693939209
Batch 42/64 loss: 2.0101470947265625
Batch 43/64 loss: 2.6316871643066406
Batch 44/64 loss: 2.1575675010681152
Batch 45/64 loss: 2.156324863433838
Batch 46/64 loss: 2.7453765869140625
Batch 47/64 loss: 1.9293885231018066
Batch 48/64 loss: 2.1308436393737793
Batch 49/64 loss: 3.0769171714782715
Batch 50/64 loss: 1.7972941398620605
Batch 51/64 loss: 2.449493885040283
Batch 52/64 loss: 1.7692136764526367
Batch 53/64 loss: 2.0211410522460938
Batch 54/64 loss: 1.8950457572937012
Batch 55/64 loss: 2.678577423095703
Batch 56/64 loss: 1.9317641258239746
Batch 57/64 loss: 1.9785351753234863
Batch 58/64 loss: 2.3231663703918457
Batch 59/64 loss: 1.8116278648376465
Batch 60/64 loss: 2.004849910736084
Batch 61/64 loss: 1.9078049659729004
Batch 62/64 loss: 1.9828314781188965
Batch 63/64 loss: 5.085892677307129
Batch 64/64 loss: -1.6586389541625977
Epoch 348  Train loss: 2.226298698724485  Val loss: 1.669397498324155
Epoch 349
-------------------------------
Batch 1/64 loss: 2.548694133758545
Batch 2/64 loss: 1.8136115074157715
Batch 3/64 loss: 1.8783674240112305
Batch 4/64 loss: 1.8569846153259277
Batch 5/64 loss: 1.9480528831481934
Batch 6/64 loss: 1.730602741241455
Batch 7/64 loss: 1.8049044609069824
Batch 8/64 loss: 1.7836298942565918
Batch 9/64 loss: 1.889237403869629
Batch 10/64 loss: 1.8052048683166504
Batch 11/64 loss: 1.8228178024291992
Batch 12/64 loss: 1.7952775955200195
Batch 13/64 loss: 2.1377768516540527
Batch 14/64 loss: 1.9027900695800781
Batch 15/64 loss: 1.7495484352111816
Batch 16/64 loss: 1.8577094078063965
Batch 17/64 loss: 1.892012119293213
Batch 18/64 loss: 1.83652925491333
Batch 19/64 loss: 1.6756095886230469
Batch 20/64 loss: 1.6956090927124023
Batch 21/64 loss: 1.816807746887207
Batch 22/64 loss: 1.8399219512939453
Batch 23/64 loss: 1.970268726348877
Batch 24/64 loss: 1.9045696258544922
Batch 25/64 loss: 2.238621234893799
Batch 26/64 loss: 1.6851420402526855
Batch 27/64 loss: 1.9784388542175293
Batch 28/64 loss: 1.8151664733886719
Batch 29/64 loss: 2.604623317718506
Batch 30/64 loss: 2.007352828979492
Batch 31/64 loss: 2.3163514137268066
Batch 32/64 loss: 1.734766960144043
Batch 33/64 loss: 1.7059440612792969
Batch 34/64 loss: 3.0343194007873535
Batch 35/64 loss: 2.108132839202881
Batch 36/64 loss: 2.062659740447998
Batch 37/64 loss: 4.667064666748047
Batch 38/64 loss: 3.2577967643737793
Batch 39/64 loss: 1.8329286575317383
Batch 40/64 loss: 1.8408613204956055
Batch 41/64 loss: 2.337353229522705
Batch 42/64 loss: 2.884183406829834
Batch 43/64 loss: 1.6950478553771973
Batch 44/64 loss: 4.022245407104492
Batch 45/64 loss: 2.049527168273926
Batch 46/64 loss: 2.1558728218078613
Batch 47/64 loss: 1.7769460678100586
Batch 48/64 loss: 1.6912622451782227
Batch 49/64 loss: 2.201272964477539
Batch 50/64 loss: 2.990302562713623
Batch 51/64 loss: 1.7542734146118164
Batch 52/64 loss: 1.8306403160095215
Batch 53/64 loss: 2.036161422729492
Batch 54/64 loss: 1.8694415092468262
Batch 55/64 loss: 1.76005220413208
Batch 56/64 loss: 1.706486701965332
Batch 57/64 loss: 2.046072483062744
Batch 58/64 loss: 4.271090984344482
Batch 59/64 loss: 1.8108644485473633
Batch 60/64 loss: 1.8658146858215332
Batch 61/64 loss: 1.7043476104736328
Batch 62/64 loss: 1.787914752960205
Batch 63/64 loss: 1.651576042175293
Batch 64/64 loss: -1.620584487915039
Epoch 349  Train loss: 2.047529736687155  Val loss: 1.5362447627221596
Epoch 350
-------------------------------
Batch 1/64 loss: 1.7390408515930176
Batch 2/64 loss: 1.760756015777588
Batch 3/64 loss: 1.761927604675293
Batch 4/64 loss: 1.7839016914367676
Batch 5/64 loss: 1.733931064605713
Batch 6/64 loss: 1.8240957260131836
Batch 7/64 loss: 1.9114718437194824
Batch 8/64 loss: 1.8048429489135742
Batch 9/64 loss: 2.278106212615967
Batch 10/64 loss: 1.868344783782959
Batch 11/64 loss: 6.421747207641602
Batch 12/64 loss: 1.6628398895263672
Batch 13/64 loss: 2.8907361030578613
Batch 14/64 loss: 1.7524418830871582
Batch 15/64 loss: 4.2957940101623535
Batch 16/64 loss: 1.6512889862060547
Batch 17/64 loss: 1.908846378326416
Batch 18/64 loss: 1.6395196914672852
Batch 19/64 loss: 2.1645092964172363
Batch 20/64 loss: 1.6740026473999023
Batch 21/64 loss: 1.7739753723144531
Batch 22/64 loss: 1.696925163269043
Batch 23/64 loss: 1.7134709358215332
Batch 24/64 loss: 1.7962803840637207
Batch 25/64 loss: 1.9070367813110352
Batch 26/64 loss: 1.9082074165344238
Batch 27/64 loss: 1.996675968170166
Batch 28/64 loss: 1.748288631439209
Batch 29/64 loss: 2.1617517471313477
Batch 30/64 loss: 1.6962871551513672
Batch 31/64 loss: 1.8767342567443848
Batch 32/64 loss: 1.6945381164550781
Batch 33/64 loss: 1.7308125495910645
Batch 34/64 loss: 1.7233376502990723
Batch 35/64 loss: 1.747459888458252
Batch 36/64 loss: 1.9144229888916016
Batch 37/64 loss: 1.5764689445495605
Batch 38/64 loss: 2.202587127685547
Batch 39/64 loss: 1.7480134963989258
Batch 40/64 loss: 3.044948101043701
Batch 41/64 loss: 1.8555126190185547
Batch 42/64 loss: 2.014458656311035
Batch 43/64 loss: 1.8866701126098633
Batch 44/64 loss: 1.7261486053466797
Batch 45/64 loss: 3.3659915924072266
Batch 46/64 loss: 1.701948642730713
Batch 47/64 loss: 1.8974676132202148
Batch 48/64 loss: 1.8745784759521484
Batch 49/64 loss: 2.0244526863098145
Batch 50/64 loss: 1.9760818481445312
Batch 51/64 loss: 2.383131504058838
Batch 52/64 loss: 1.82188081741333
Batch 53/64 loss: 1.6755890846252441
Batch 54/64 loss: 2.048490524291992
Batch 55/64 loss: 2.1206283569335938
Batch 56/64 loss: 1.7142109870910645
Batch 57/64 loss: 1.838754653930664
Batch 58/64 loss: 2.029635429382324
Batch 59/64 loss: 1.9864392280578613
Batch 60/64 loss: 1.8476743698120117
Batch 61/64 loss: 1.9655771255493164
Batch 62/64 loss: 1.8003458976745605
Batch 63/64 loss: 1.8748631477355957
Batch 64/64 loss: -1.7452678680419922
Epoch 350  Train loss: 1.9813011543423522  Val loss: 1.5102947929880464
Epoch 351
-------------------------------
Batch 1/64 loss: 2.172593593597412
Batch 2/64 loss: 1.920511245727539
Batch 3/64 loss: 2.2674684524536133
Batch 4/64 loss: 1.7617030143737793
Batch 5/64 loss: 1.6677007675170898
Batch 6/64 loss: 1.8605074882507324
Batch 7/64 loss: 1.7385058403015137
Batch 8/64 loss: 1.6800565719604492
Batch 9/64 loss: 1.8987946510314941
Batch 10/64 loss: 1.6095938682556152
Batch 11/64 loss: 4.083588123321533
Batch 12/64 loss: 1.763227939605713
Batch 13/64 loss: 1.7522764205932617
Batch 14/64 loss: 2.0067458152770996
Batch 15/64 loss: 1.9111218452453613
Batch 16/64 loss: 1.7479534149169922
Batch 17/64 loss: 1.7226271629333496
Batch 18/64 loss: 1.8188042640686035
Batch 19/64 loss: 1.6100525856018066
Batch 20/64 loss: 1.694148063659668
Batch 21/64 loss: 1.702989101409912
Batch 22/64 loss: 1.5928840637207031
Batch 23/64 loss: 1.6953468322753906
Batch 24/64 loss: 1.647449016571045
Batch 25/64 loss: 1.7355871200561523
Batch 26/64 loss: 1.7775702476501465
Batch 27/64 loss: 1.7373027801513672
Batch 28/64 loss: 1.7999401092529297
Batch 29/64 loss: 1.6797680854797363
Batch 30/64 loss: 1.7437615394592285
Batch 31/64 loss: 2.451855182647705
Batch 32/64 loss: 1.9390358924865723
Batch 33/64 loss: 2.0996909141540527
Batch 34/64 loss: 1.8563323020935059
Batch 35/64 loss: 1.664736270904541
Batch 36/64 loss: 2.018484592437744
Batch 37/64 loss: 1.685814380645752
Batch 38/64 loss: 1.6898088455200195
Batch 39/64 loss: 1.6740097999572754
Batch 40/64 loss: 5.592052459716797
Batch 41/64 loss: 1.6931428909301758
Batch 42/64 loss: 1.6814489364624023
Batch 43/64 loss: 1.7991142272949219
Batch 44/64 loss: 1.6141910552978516
Batch 45/64 loss: 1.6972336769104004
Batch 46/64 loss: 1.6249918937683105
Batch 47/64 loss: 1.6777892112731934
Batch 48/64 loss: 2.517453670501709
Batch 49/64 loss: 1.6750216484069824
Batch 50/64 loss: 1.7289581298828125
Batch 51/64 loss: 1.5792350769042969
Batch 52/64 loss: 1.7603826522827148
Batch 53/64 loss: 1.7703680992126465
Batch 54/64 loss: 2.0649709701538086
Batch 55/64 loss: 1.6702899932861328
Batch 56/64 loss: 3.9226179122924805
Batch 57/64 loss: 1.7869172096252441
Batch 58/64 loss: 1.8736963272094727
Batch 59/64 loss: 2.0207509994506836
Batch 60/64 loss: 4.082904815673828
Batch 61/64 loss: 1.6071443557739258
Batch 62/64 loss: 1.8614354133605957
Batch 63/64 loss: 1.7735304832458496
Batch 64/64 loss: -1.6630001068115234
Epoch 351  Train loss: 1.9248429840686274  Val loss: 1.5004977196762241
Epoch 352
-------------------------------
Batch 1/64 loss: 1.7526750564575195
Batch 2/64 loss: 1.8202672004699707
Batch 3/64 loss: 1.759099006652832
Batch 4/64 loss: 1.6485233306884766
Batch 5/64 loss: 1.7919750213623047
Batch 6/64 loss: 1.6843171119689941
Batch 7/64 loss: 1.6679906845092773
Batch 8/64 loss: 1.694221019744873
Batch 9/64 loss: 1.6048345565795898
Batch 10/64 loss: 1.99763822555542
Batch 11/64 loss: 1.7391548156738281
Batch 12/64 loss: 1.5215411186218262
Batch 13/64 loss: 1.6085171699523926
Batch 14/64 loss: 1.6487407684326172
Batch 15/64 loss: 1.6997485160827637
Batch 16/64 loss: 1.7897343635559082
Batch 17/64 loss: 1.6067595481872559
Batch 18/64 loss: 1.7658743858337402
Batch 19/64 loss: 2.0076303482055664
Batch 20/64 loss: 1.7255973815917969
Batch 21/64 loss: 1.6868667602539062
Batch 22/64 loss: 1.9561967849731445
Batch 23/64 loss: 1.6520485877990723
Batch 24/64 loss: 2.346095085144043
Batch 25/64 loss: 1.6852574348449707
Batch 26/64 loss: 1.607330322265625
Batch 27/64 loss: 1.8838129043579102
Batch 28/64 loss: 1.6389846801757812
Batch 29/64 loss: 1.7426767349243164
Batch 30/64 loss: 1.6408848762512207
Batch 31/64 loss: 2.010634422302246
Batch 32/64 loss: 1.5932397842407227
Batch 33/64 loss: 1.692692756652832
Batch 34/64 loss: 1.7751612663269043
Batch 35/64 loss: 3.048218250274658
Batch 36/64 loss: 1.7081646919250488
Batch 37/64 loss: 1.6932988166809082
Batch 38/64 loss: 2.312556266784668
Batch 39/64 loss: 1.6690168380737305
Batch 40/64 loss: 1.9188613891601562
Batch 41/64 loss: 1.6583528518676758
Batch 42/64 loss: 1.743973731994629
Batch 43/64 loss: 2.1250123977661133
Batch 44/64 loss: 1.7233538627624512
Batch 45/64 loss: 1.7987580299377441
Batch 46/64 loss: 1.7941641807556152
Batch 47/64 loss: 4.101615905761719
Batch 48/64 loss: 4.67381477355957
Batch 49/64 loss: 1.8065762519836426
Batch 50/64 loss: 1.9045305252075195
Batch 51/64 loss: 1.665046215057373
Batch 52/64 loss: 1.8034648895263672
Batch 53/64 loss: 3.7543063163757324
Batch 54/64 loss: 2.627991199493408
Batch 55/64 loss: 2.344381809234619
Batch 56/64 loss: 1.921818733215332
Batch 57/64 loss: 1.6262907981872559
Batch 58/64 loss: 1.6897244453430176
Batch 59/64 loss: 1.8699169158935547
Batch 60/64 loss: 2.729647159576416
Batch 61/64 loss: 1.8057494163513184
Batch 62/64 loss: 1.6634092330932617
Batch 63/64 loss: 1.793473243713379
Batch 64/64 loss: -1.627614974975586
Epoch 352  Train loss: 1.9011999990425859  Val loss: 1.5026424578375013
Epoch 353
-------------------------------
Batch 1/64 loss: 1.7378864288330078
Batch 2/64 loss: 1.8644294738769531
Batch 3/64 loss: 1.6862478256225586
Batch 4/64 loss: 1.7936697006225586
Batch 5/64 loss: 1.7318921089172363
Batch 6/64 loss: 1.6941571235656738
Batch 7/64 loss: 1.703683853149414
Batch 8/64 loss: 2.247905731201172
Batch 9/64 loss: 1.7610459327697754
Batch 10/64 loss: 1.5909242630004883
Batch 11/64 loss: 1.7748732566833496
Batch 12/64 loss: 1.7524518966674805
Batch 13/64 loss: 1.6451187133789062
Batch 14/64 loss: 1.8842754364013672
Batch 15/64 loss: 1.8091011047363281
Batch 16/64 loss: 1.7208008766174316
Batch 17/64 loss: 1.6317644119262695
Batch 18/64 loss: 1.7521929740905762
Batch 19/64 loss: 1.7025604248046875
Batch 20/64 loss: 1.8260760307312012
Batch 21/64 loss: 1.6351590156555176
Batch 22/64 loss: 1.8954954147338867
Batch 23/64 loss: 1.7404074668884277
Batch 24/64 loss: 2.1248106956481934
Batch 25/64 loss: 1.8056793212890625
Batch 26/64 loss: 1.8328614234924316
Batch 27/64 loss: 1.6387557983398438
Batch 28/64 loss: 2.3138246536254883
Batch 29/64 loss: 1.7677135467529297
Batch 30/64 loss: 4.162715435028076
Batch 31/64 loss: 1.7449216842651367
Batch 32/64 loss: 1.5919265747070312
Batch 33/64 loss: 1.7585539817810059
Batch 34/64 loss: 1.7703824043273926
Batch 35/64 loss: 1.7336745262145996
Batch 36/64 loss: 1.529191017150879
Batch 37/64 loss: 1.772737979888916
Batch 38/64 loss: 4.1347126960754395
Batch 39/64 loss: 1.6300697326660156
Batch 40/64 loss: 1.7250256538391113
Batch 41/64 loss: 1.9165778160095215
Batch 42/64 loss: 1.8630309104919434
Batch 43/64 loss: 2.6658153533935547
Batch 44/64 loss: 1.6936454772949219
Batch 45/64 loss: 1.7091498374938965
Batch 46/64 loss: 1.6639413833618164
Batch 47/64 loss: 1.9893770217895508
Batch 48/64 loss: 1.5990009307861328
Batch 49/64 loss: 1.6247663497924805
Batch 50/64 loss: 1.6657037734985352
Batch 51/64 loss: 4.606856346130371
Batch 52/64 loss: 1.9135560989379883
Batch 53/64 loss: 1.571530818939209
Batch 54/64 loss: 2.576821804046631
Batch 55/64 loss: 1.8799314498901367
Batch 56/64 loss: 1.9043049812316895
Batch 57/64 loss: 1.6140289306640625
Batch 58/64 loss: 1.579057216644287
Batch 59/64 loss: 2.886751651763916
Batch 60/64 loss: 2.159335136413574
Batch 61/64 loss: 2.252742290496826
Batch 62/64 loss: 1.6918845176696777
Batch 63/64 loss: 1.6190071105957031
Batch 64/64 loss: -1.876063346862793
Epoch 353  Train loss: 1.8958344515632182  Val loss: 1.4391816522657257
Epoch 354
-------------------------------
Batch 1/64 loss: 1.7710609436035156
Batch 2/64 loss: 1.6344056129455566
Batch 3/64 loss: 1.6056981086730957
Batch 4/64 loss: 1.6589250564575195
Batch 5/64 loss: 1.7988662719726562
Batch 6/64 loss: 1.696436882019043
Batch 7/64 loss: 2.575428009033203
Batch 8/64 loss: 1.676065444946289
Batch 9/64 loss: 1.768488883972168
Batch 10/64 loss: 1.6500344276428223
Batch 11/64 loss: 1.7159152030944824
Batch 12/64 loss: 1.712202548980713
Batch 13/64 loss: 4.014877796173096
Batch 14/64 loss: 1.616565227508545
Batch 15/64 loss: 2.3412294387817383
Batch 16/64 loss: 1.908442497253418
Batch 17/64 loss: 1.971348762512207
Batch 18/64 loss: 4.1578450202941895
Batch 19/64 loss: 1.889181137084961
Batch 20/64 loss: 1.5548133850097656
Batch 21/64 loss: 1.9899120330810547
Batch 22/64 loss: 1.634439468383789
Batch 23/64 loss: 1.8265018463134766
Batch 24/64 loss: 1.8740735054016113
Batch 25/64 loss: 4.651784896850586
Batch 26/64 loss: 1.8314094543457031
Batch 27/64 loss: 1.6862192153930664
Batch 28/64 loss: 2.257136344909668
Batch 29/64 loss: 1.9251046180725098
Batch 30/64 loss: 1.6021385192871094
Batch 31/64 loss: 1.6746435165405273
Batch 32/64 loss: 1.8319482803344727
Batch 33/64 loss: 1.8354859352111816
Batch 34/64 loss: 1.6626324653625488
Batch 35/64 loss: 1.7187280654907227
Batch 36/64 loss: 1.6263012886047363
Batch 37/64 loss: 1.9184036254882812
Batch 38/64 loss: 1.7878599166870117
Batch 39/64 loss: 1.8136944770812988
Batch 40/64 loss: 2.0636343955993652
Batch 41/64 loss: 1.591623306274414
Batch 42/64 loss: 1.8183388710021973
Batch 43/64 loss: 1.6851658821105957
Batch 44/64 loss: 1.7805719375610352
Batch 45/64 loss: 1.8278484344482422
Batch 46/64 loss: 1.8215084075927734
Batch 47/64 loss: 2.794483184814453
Batch 48/64 loss: 1.7504639625549316
Batch 49/64 loss: 1.848649501800537
Batch 50/64 loss: 1.7210068702697754
Batch 51/64 loss: 1.7189087867736816
Batch 52/64 loss: 1.7264809608459473
Batch 53/64 loss: 1.669480323791504
Batch 54/64 loss: 1.7640604972839355
Batch 55/64 loss: 1.729182243347168
Batch 56/64 loss: 1.7280216217041016
Batch 57/64 loss: 1.7784428596496582
Batch 58/64 loss: 2.917099952697754
Batch 59/64 loss: 1.954010009765625
Batch 60/64 loss: 2.105281352996826
Batch 61/64 loss: 1.8243346214294434
Batch 62/64 loss: 1.7285666465759277
Batch 63/64 loss: 1.8754792213439941
Batch 64/64 loss: -1.399928092956543
Epoch 354  Train loss: 1.9143364064833697  Val loss: 1.460435074219589
Epoch 355
-------------------------------
Batch 1/64 loss: 1.7067432403564453
Batch 2/64 loss: 1.6141581535339355
Batch 3/64 loss: 1.7594757080078125
Batch 4/64 loss: 1.8085098266601562
Batch 5/64 loss: 1.9518036842346191
Batch 6/64 loss: 1.6696977615356445
Batch 7/64 loss: 1.7517461776733398
Batch 8/64 loss: 1.7729434967041016
Batch 9/64 loss: 1.646528720855713
Batch 10/64 loss: 1.5794496536254883
Batch 11/64 loss: 1.8316073417663574
Batch 12/64 loss: 1.6571044921875
Batch 13/64 loss: 1.705526351928711
Batch 14/64 loss: 1.5433030128479004
Batch 15/64 loss: 1.7321276664733887
Batch 16/64 loss: 1.7769694328308105
Batch 17/64 loss: 1.8209724426269531
Batch 18/64 loss: 2.0537123680114746
Batch 19/64 loss: 1.678741455078125
Batch 20/64 loss: 1.6787796020507812
Batch 21/64 loss: 1.6547727584838867
Batch 22/64 loss: 1.9500823020935059
Batch 23/64 loss: 1.5727648735046387
Batch 24/64 loss: 2.9607086181640625
Batch 25/64 loss: 1.753760814666748
Batch 26/64 loss: 2.2801437377929688
Batch 27/64 loss: 1.5945792198181152
Batch 28/64 loss: 1.8014049530029297
Batch 29/64 loss: 1.756152629852295
Batch 30/64 loss: 1.8461475372314453
Batch 31/64 loss: 1.6767921447753906
Batch 32/64 loss: 3.7497129440307617
Batch 33/64 loss: 1.6075315475463867
Batch 34/64 loss: 1.6212677955627441
Batch 35/64 loss: 2.106562614440918
Batch 36/64 loss: 1.8771734237670898
Batch 37/64 loss: 1.819993495941162
Batch 38/64 loss: 1.6807827949523926
Batch 39/64 loss: 1.8491778373718262
Batch 40/64 loss: 1.6310534477233887
Batch 41/64 loss: 1.7330808639526367
Batch 42/64 loss: 1.7697415351867676
Batch 43/64 loss: 1.6577987670898438
Batch 44/64 loss: 1.7598357200622559
Batch 45/64 loss: 1.7727446556091309
Batch 46/64 loss: 4.024966239929199
Batch 47/64 loss: 1.509986400604248
Batch 48/64 loss: 1.6017365455627441
Batch 49/64 loss: 2.2006278038024902
Batch 50/64 loss: 1.7909517288208008
Batch 51/64 loss: 3.151668071746826
Batch 52/64 loss: 1.6209163665771484
Batch 53/64 loss: 2.522794246673584
Batch 54/64 loss: 1.6731934547424316
Batch 55/64 loss: 1.7304697036743164
Batch 56/64 loss: 1.6528797149658203
Batch 57/64 loss: 1.8142390251159668
Batch 58/64 loss: 1.6346750259399414
Batch 59/64 loss: 1.695131778717041
Batch 60/64 loss: 1.8202366828918457
Batch 61/64 loss: 2.581150531768799
Batch 62/64 loss: 1.6660785675048828
Batch 63/64 loss: 1.6384410858154297
Batch 64/64 loss: 1.6011323928833008
Epoch 355  Train loss: 1.8785044688804478  Val loss: 1.4514981037153
Epoch 356
-------------------------------
Batch 1/64 loss: 1.704371452331543
Batch 2/64 loss: 1.5926575660705566
Batch 3/64 loss: 1.8171367645263672
Batch 4/64 loss: 1.7180609703063965
Batch 5/64 loss: 1.6781086921691895
Batch 6/64 loss: 1.6431827545166016
Batch 7/64 loss: 1.5704607963562012
Batch 8/64 loss: 1.7827119827270508
Batch 9/64 loss: 2.0091962814331055
Batch 10/64 loss: 1.6341462135314941
Batch 11/64 loss: 1.680708885192871
Batch 12/64 loss: 1.7080936431884766
Batch 13/64 loss: 2.3935546875
Batch 14/64 loss: 1.5734996795654297
Batch 15/64 loss: 1.7021193504333496
Batch 16/64 loss: 1.6304931640625
Batch 17/64 loss: 1.7619009017944336
Batch 18/64 loss: 2.4793505668640137
Batch 19/64 loss: 1.644214153289795
Batch 20/64 loss: 1.7041029930114746
Batch 21/64 loss: 1.6693100929260254
Batch 22/64 loss: 1.7425322532653809
Batch 23/64 loss: 1.7157378196716309
Batch 24/64 loss: 2.282423973083496
Batch 25/64 loss: 1.7760334014892578
Batch 26/64 loss: 2.8555331230163574
Batch 27/64 loss: 1.724909782409668
Batch 28/64 loss: 1.7452073097229004
Batch 29/64 loss: 2.0070133209228516
Batch 30/64 loss: 1.6924095153808594
Batch 31/64 loss: 2.173485279083252
Batch 32/64 loss: 1.754298210144043
Batch 33/64 loss: 1.744157314300537
Batch 34/64 loss: 1.647064208984375
Batch 35/64 loss: 1.7224011421203613
Batch 36/64 loss: 2.035914897918701
Batch 37/64 loss: 2.6253256797790527
Batch 38/64 loss: 1.6785669326782227
Batch 39/64 loss: 1.8833346366882324
Batch 40/64 loss: 1.861490249633789
Batch 41/64 loss: 2.018512725830078
Batch 42/64 loss: 1.5963826179504395
Batch 43/64 loss: 2.2403764724731445
Batch 44/64 loss: 2.1776413917541504
Batch 45/64 loss: 1.7389097213745117
Batch 46/64 loss: 1.868161678314209
Batch 47/64 loss: 1.9087896347045898
Batch 48/64 loss: 1.7976980209350586
Batch 49/64 loss: 1.69630765914917
Batch 50/64 loss: 1.7964200973510742
Batch 51/64 loss: 1.9467120170593262
Batch 52/64 loss: 1.561964988708496
Batch 53/64 loss: 1.866194725036621
Batch 54/64 loss: 2.1980223655700684
Batch 55/64 loss: 2.854678153991699
Batch 56/64 loss: 3.9323887825012207
Batch 57/64 loss: 1.7886314392089844
Batch 58/64 loss: 1.7190098762512207
Batch 59/64 loss: 1.741037368774414
Batch 60/64 loss: 1.6862502098083496
Batch 61/64 loss: 4.73867654800415
Batch 62/64 loss: 4.17991828918457
Batch 63/64 loss: 1.7061562538146973
Batch 64/64 loss: -1.7864179611206055
Epoch 356  Train loss: 1.9323019326901902  Val loss: 1.467700866489476
Epoch 357
-------------------------------
Batch 1/64 loss: 1.6628403663635254
Batch 2/64 loss: 1.797027587890625
Batch 3/64 loss: 1.6962852478027344
Batch 4/64 loss: 4.00581693649292
Batch 5/64 loss: 1.7432265281677246
Batch 6/64 loss: 1.6557512283325195
Batch 7/64 loss: 1.7875442504882812
Batch 8/64 loss: 1.7365241050720215
Batch 9/64 loss: 1.7681002616882324
Batch 10/64 loss: 1.7637720108032227
Batch 11/64 loss: 1.7604889869689941
Batch 12/64 loss: 1.7294349670410156
Batch 13/64 loss: 1.5617175102233887
Batch 14/64 loss: 2.1038436889648438
Batch 15/64 loss: 2.917388439178467
Batch 16/64 loss: 2.923090934753418
Batch 17/64 loss: 1.7633724212646484
Batch 18/64 loss: 1.629666805267334
Batch 19/64 loss: 1.8309149742126465
Batch 20/64 loss: 2.673581123352051
Batch 21/64 loss: 1.9629278182983398
Batch 22/64 loss: 1.6470322608947754
Batch 23/64 loss: 1.76149320602417
Batch 24/64 loss: 1.938021183013916
Batch 25/64 loss: 1.5857930183410645
Batch 26/64 loss: 1.680577278137207
Batch 27/64 loss: 1.600761890411377
Batch 28/64 loss: 1.7435030937194824
Batch 29/64 loss: 1.8006095886230469
Batch 30/64 loss: 1.5648894309997559
Batch 31/64 loss: 1.565147876739502
Batch 32/64 loss: 1.8202872276306152
Batch 33/64 loss: 1.6307644844055176
Batch 34/64 loss: 1.7854514122009277
Batch 35/64 loss: 1.87385892868042
Batch 36/64 loss: 1.6266579627990723
Batch 37/64 loss: 1.7502198219299316
Batch 38/64 loss: 1.6601653099060059
Batch 39/64 loss: 1.6776189804077148
Batch 40/64 loss: 1.749157428741455
Batch 41/64 loss: 1.8108000755310059
Batch 42/64 loss: 1.684950828552246
Batch 43/64 loss: 1.7314600944519043
Batch 44/64 loss: 1.7305808067321777
Batch 45/64 loss: 2.818983554840088
Batch 46/64 loss: 2.278388500213623
Batch 47/64 loss: 2.200444221496582
Batch 48/64 loss: 1.7924394607543945
Batch 49/64 loss: 1.788996696472168
Batch 50/64 loss: 1.878190040588379
Batch 51/64 loss: 1.6683940887451172
Batch 52/64 loss: 4.535539627075195
Batch 53/64 loss: 1.8792428970336914
Batch 54/64 loss: 1.6303181648254395
Batch 55/64 loss: 3.877467155456543
Batch 56/64 loss: 1.9734463691711426
Batch 57/64 loss: 1.750746726989746
Batch 58/64 loss: 1.9644889831542969
Batch 59/64 loss: 1.7964200973510742
Batch 60/64 loss: 1.7444515228271484
Batch 61/64 loss: 1.6466951370239258
Batch 62/64 loss: 1.7050771713256836
Batch 63/64 loss: 1.6630277633666992
Batch 64/64 loss: -1.7543792724609375
Epoch 357  Train loss: 1.900707327150831  Val loss: 1.4564919225948374
Epoch 358
-------------------------------
Batch 1/64 loss: 1.8244619369506836
Batch 2/64 loss: 1.786829948425293
Batch 3/64 loss: 1.6671676635742188
Batch 4/64 loss: 1.8767051696777344
Batch 5/64 loss: 1.7461647987365723
Batch 6/64 loss: 1.626518726348877
Batch 7/64 loss: 1.7082085609436035
Batch 8/64 loss: 1.9033479690551758
Batch 9/64 loss: 1.5942511558532715
Batch 10/64 loss: 1.817690372467041
Batch 11/64 loss: 1.6627225875854492
Batch 12/64 loss: 2.819617748260498
Batch 13/64 loss: 1.8016233444213867
Batch 14/64 loss: 1.7080121040344238
Batch 15/64 loss: 1.623422622680664
Batch 16/64 loss: 1.6912293434143066
Batch 17/64 loss: 1.6115097999572754
Batch 18/64 loss: 1.737783432006836
Batch 19/64 loss: 1.823622703552246
Batch 20/64 loss: 1.6169447898864746
Batch 21/64 loss: 1.7780165672302246
Batch 22/64 loss: 2.0924453735351562
Batch 23/64 loss: 1.7867097854614258
Batch 24/64 loss: 1.640587329864502
Batch 25/64 loss: 1.7188849449157715
Batch 26/64 loss: 1.8457469940185547
Batch 27/64 loss: 2.0536856651306152
Batch 28/64 loss: 1.9621148109436035
Batch 29/64 loss: 1.5491580963134766
Batch 30/64 loss: 1.5455398559570312
Batch 31/64 loss: 4.117411136627197
Batch 32/64 loss: 1.7021751403808594
Batch 33/64 loss: 1.6146745681762695
Batch 34/64 loss: 1.8679518699645996
Batch 35/64 loss: 2.3355627059936523
Batch 36/64 loss: 1.6903328895568848
Batch 37/64 loss: 1.654017448425293
Batch 38/64 loss: 1.8926019668579102
Batch 39/64 loss: 2.7287683486938477
Batch 40/64 loss: 3.8193726539611816
Batch 41/64 loss: 1.6385178565979004
Batch 42/64 loss: 1.6976251602172852
Batch 43/64 loss: 1.6844820976257324
Batch 44/64 loss: 1.6898674964904785
Batch 45/64 loss: 1.8713703155517578
Batch 46/64 loss: 1.6188459396362305
Batch 47/64 loss: 2.4883337020874023
Batch 48/64 loss: 1.7762045860290527
Batch 49/64 loss: 1.694507122039795
Batch 50/64 loss: 1.7415590286254883
Batch 51/64 loss: 1.7362351417541504
Batch 52/64 loss: 1.7285947799682617
Batch 53/64 loss: 1.6690702438354492
Batch 54/64 loss: 1.6957197189331055
Batch 55/64 loss: 1.5425896644592285
Batch 56/64 loss: 1.7113900184631348
Batch 57/64 loss: 1.6638174057006836
Batch 58/64 loss: 1.800455093383789
Batch 59/64 loss: 2.7697057723999023
Batch 60/64 loss: 2.8377699851989746
Batch 61/64 loss: 1.6199603080749512
Batch 62/64 loss: 1.6941685676574707
Batch 63/64 loss: 4.580057144165039
Batch 64/64 loss: -1.624119758605957
Epoch 358  Train loss: 1.8945309844671512  Val loss: 1.4301634981869833
Epoch 359
-------------------------------
Batch 1/64 loss: 2.800778865814209
Batch 2/64 loss: 2.0528244972229004
Batch 3/64 loss: 4.602662086486816
Batch 4/64 loss: 1.7794771194458008
Batch 5/64 loss: 1.66264009475708
Batch 6/64 loss: 1.6418466567993164
Batch 7/64 loss: 1.655022144317627
Batch 8/64 loss: 1.6204242706298828
Batch 9/64 loss: 1.556981086730957
Batch 10/64 loss: 1.6733708381652832
Batch 11/64 loss: 1.659186840057373
Batch 12/64 loss: 2.8112525939941406
Batch 13/64 loss: 1.8276500701904297
Batch 14/64 loss: 1.642275333404541
Batch 15/64 loss: 2.2903952598571777
Batch 16/64 loss: 1.9861431121826172
Batch 17/64 loss: 1.6917757987976074
Batch 18/64 loss: 2.2737202644348145
Batch 19/64 loss: 1.516493797302246
Batch 20/64 loss: 1.7196898460388184
Batch 21/64 loss: 1.8625726699829102
Batch 22/64 loss: 1.7259154319763184
Batch 23/64 loss: 1.6261940002441406
Batch 24/64 loss: 1.7115788459777832
Batch 25/64 loss: 1.8533673286437988
Batch 26/64 loss: 1.779867172241211
Batch 27/64 loss: 1.6219472885131836
Batch 28/64 loss: 1.648085117340088
Batch 29/64 loss: 1.6472201347351074
Batch 30/64 loss: 1.6618547439575195
Batch 31/64 loss: 4.060581207275391
Batch 32/64 loss: 1.5736217498779297
Batch 33/64 loss: 1.641435146331787
Batch 34/64 loss: 1.631803035736084
Batch 35/64 loss: 1.7069768905639648
Batch 36/64 loss: 1.6716251373291016
Batch 37/64 loss: 1.8551373481750488
Batch 38/64 loss: 1.8492751121520996
Batch 39/64 loss: 1.8525104522705078
Batch 40/64 loss: 1.5977020263671875
Batch 41/64 loss: 1.5416655540466309
Batch 42/64 loss: 1.6963090896606445
Batch 43/64 loss: 1.6208090782165527
Batch 44/64 loss: 1.7253718376159668
Batch 45/64 loss: 1.6906013488769531
Batch 46/64 loss: 2.767120838165283
Batch 47/64 loss: 1.852729320526123
Batch 48/64 loss: 1.6455073356628418
Batch 49/64 loss: 1.6279616355895996
Batch 50/64 loss: 1.7933578491210938
Batch 51/64 loss: 2.284458637237549
Batch 52/64 loss: 1.686903476715088
Batch 53/64 loss: 1.6360440254211426
Batch 54/64 loss: 1.6798419952392578
Batch 55/64 loss: 1.673497200012207
Batch 56/64 loss: 1.5568857192993164
Batch 57/64 loss: 1.747574806213379
Batch 58/64 loss: 1.7842621803283691
Batch 59/64 loss: 3.830838203430176
Batch 60/64 loss: 1.5858674049377441
Batch 61/64 loss: 1.652660846710205
Batch 62/64 loss: 1.6491470336914062
Batch 63/64 loss: 1.6009488105773926
Batch 64/64 loss: -1.5414037704467773
Epoch 359  Train loss: 1.854403024561265  Val loss: 1.4130396629936506
Saving best model, epoch: 359
Epoch 360
-------------------------------
Batch 1/64 loss: 1.5647611618041992
Batch 2/64 loss: 1.5736846923828125
Batch 3/64 loss: 1.7835707664489746
Batch 4/64 loss: 1.7208948135375977
Batch 5/64 loss: 1.6557765007019043
Batch 6/64 loss: 1.7193431854248047
Batch 7/64 loss: 1.8396167755126953
Batch 8/64 loss: 2.1764988899230957
Batch 9/64 loss: 1.7305293083190918
Batch 10/64 loss: 1.798926830291748
Batch 11/64 loss: 1.7612824440002441
Batch 12/64 loss: 1.7293243408203125
Batch 13/64 loss: 1.6780061721801758
Batch 14/64 loss: 1.8616652488708496
Batch 15/64 loss: 3.971104145050049
Batch 16/64 loss: 1.7568063735961914
Batch 17/64 loss: 1.9166226387023926
Batch 18/64 loss: 1.71803617477417
Batch 19/64 loss: 1.7816495895385742
Batch 20/64 loss: 2.2863359451293945
Batch 21/64 loss: 1.7604413032531738
Batch 22/64 loss: 2.042044162750244
Batch 23/64 loss: 1.9839019775390625
Batch 24/64 loss: 1.9839634895324707
Batch 25/64 loss: 1.702476978302002
Batch 26/64 loss: 1.7274861335754395
Batch 27/64 loss: 1.6732177734375
Batch 28/64 loss: 2.3074841499328613
Batch 29/64 loss: 1.7497224807739258
Batch 30/64 loss: 2.6129045486450195
Batch 31/64 loss: 1.573692798614502
Batch 32/64 loss: 2.732748508453369
Batch 33/64 loss: 1.6602630615234375
Batch 34/64 loss: 1.6647238731384277
Batch 35/64 loss: 1.6558003425598145
Batch 36/64 loss: 1.7830915451049805
Batch 37/64 loss: 4.647370338439941
Batch 38/64 loss: 1.5958118438720703
Batch 39/64 loss: 1.5722789764404297
Batch 40/64 loss: 1.8887686729431152
Batch 41/64 loss: 1.7160873413085938
Batch 42/64 loss: 1.6525893211364746
Batch 43/64 loss: 1.6894049644470215
Batch 44/64 loss: 1.842177391052246
Batch 45/64 loss: 1.7182302474975586
Batch 46/64 loss: 3.921170711517334
Batch 47/64 loss: 1.6931910514831543
Batch 48/64 loss: 1.7568974494934082
Batch 49/64 loss: 2.2017154693603516
Batch 50/64 loss: 1.6678194999694824
Batch 51/64 loss: 1.6857843399047852
Batch 52/64 loss: 2.99873685836792
Batch 53/64 loss: 1.8361945152282715
Batch 54/64 loss: 1.5874361991882324
Batch 55/64 loss: 1.5814862251281738
Batch 56/64 loss: 1.7561249732971191
Batch 57/64 loss: 1.6149182319641113
Batch 58/64 loss: 1.730635166168213
Batch 59/64 loss: 1.7489590644836426
Batch 60/64 loss: 1.7827372550964355
Batch 61/64 loss: 1.7395453453063965
Batch 62/64 loss: 1.9255595207214355
Batch 63/64 loss: 1.6397767066955566
Batch 64/64 loss: -1.7995996475219727
Epoch 360  Train loss: 1.8898840324551451  Val loss: 1.4696276949853013
Epoch 361
-------------------------------
Batch 1/64 loss: 1.5996589660644531
Batch 2/64 loss: 1.8005123138427734
Batch 3/64 loss: 2.494781017303467
Batch 4/64 loss: 1.7017765045166016
Batch 5/64 loss: 1.5778074264526367
Batch 6/64 loss: 1.5296258926391602
Batch 7/64 loss: 2.8390626907348633
Batch 8/64 loss: 4.590672016143799
Batch 9/64 loss: 1.722090721130371
Batch 10/64 loss: 1.7897744178771973
Batch 11/64 loss: 1.6552982330322266
Batch 12/64 loss: 2.839366912841797
Batch 13/64 loss: 3.7430200576782227
Batch 14/64 loss: 1.7940301895141602
Batch 15/64 loss: 1.7141361236572266
Batch 16/64 loss: 1.7033953666687012
Batch 17/64 loss: 1.7543210983276367
Batch 18/64 loss: 1.7035698890686035
Batch 19/64 loss: 1.6382479667663574
Batch 20/64 loss: 1.9351067543029785
Batch 21/64 loss: 1.7386488914489746
Batch 22/64 loss: 1.8084759712219238
Batch 23/64 loss: 1.6196022033691406
Batch 24/64 loss: 1.72041654586792
Batch 25/64 loss: 2.224234104156494
Batch 26/64 loss: 1.6434998512268066
Batch 27/64 loss: 1.885066032409668
Batch 28/64 loss: 1.7488970756530762
Batch 29/64 loss: 3.9790782928466797
Batch 30/64 loss: 1.943948745727539
Batch 31/64 loss: 1.6555852890014648
Batch 32/64 loss: 1.685305118560791
Batch 33/64 loss: 2.007384777069092
Batch 34/64 loss: 1.7629857063293457
Batch 35/64 loss: 1.7769699096679688
Batch 36/64 loss: 1.7465224266052246
Batch 37/64 loss: 1.766469955444336
Batch 38/64 loss: 1.793764591217041
Batch 39/64 loss: 1.6143412590026855
Batch 40/64 loss: 1.878805160522461
Batch 41/64 loss: 1.7149572372436523
Batch 42/64 loss: 1.7266030311584473
Batch 43/64 loss: 1.6353073120117188
Batch 44/64 loss: 1.6291613578796387
Batch 45/64 loss: 1.650998592376709
Batch 46/64 loss: 1.7001795768737793
Batch 47/64 loss: 1.8973231315612793
Batch 48/64 loss: 1.9490132331848145
Batch 49/64 loss: 1.697765827178955
Batch 50/64 loss: 2.137317657470703
Batch 51/64 loss: 1.6962947845458984
Batch 52/64 loss: 1.584545612335205
Batch 53/64 loss: 1.7091522216796875
Batch 54/64 loss: 1.6810259819030762
Batch 55/64 loss: 2.4418931007385254
Batch 56/64 loss: 1.6773667335510254
Batch 57/64 loss: 1.7359862327575684
Batch 58/64 loss: 1.5752577781677246
Batch 59/64 loss: 1.7046232223510742
Batch 60/64 loss: 1.6553473472595215
Batch 61/64 loss: 2.0237655639648438
Batch 62/64 loss: 1.6147751808166504
Batch 63/64 loss: 1.760653018951416
Batch 64/64 loss: -1.758326530456543
Epoch 361  Train loss: 1.8730482400632371  Val loss: 1.4156246381936615
Epoch 362
-------------------------------
Batch 1/64 loss: 1.6326093673706055
Batch 2/64 loss: 1.692678451538086
Batch 3/64 loss: 1.6456284523010254
Batch 4/64 loss: 1.725759506225586
Batch 5/64 loss: 1.760061264038086
Batch 6/64 loss: 1.7250690460205078
Batch 7/64 loss: 1.6224117279052734
Batch 8/64 loss: 1.6665306091308594
Batch 9/64 loss: 2.06754207611084
Batch 10/64 loss: 1.7115254402160645
Batch 11/64 loss: 1.5609216690063477
Batch 12/64 loss: 2.00689697265625
Batch 13/64 loss: 1.6711711883544922
Batch 14/64 loss: 4.643725395202637
Batch 15/64 loss: 1.5874228477478027
Batch 16/64 loss: 1.6840553283691406
Batch 17/64 loss: 1.690727710723877
Batch 18/64 loss: 1.8701567649841309
Batch 19/64 loss: 1.7143187522888184
Batch 20/64 loss: 1.744114875793457
Batch 21/64 loss: 1.7048215866088867
Batch 22/64 loss: 1.7374062538146973
Batch 23/64 loss: 1.7552728652954102
Batch 24/64 loss: 1.650047779083252
Batch 25/64 loss: 1.6179537773132324
Batch 26/64 loss: 3.770339012145996
Batch 27/64 loss: 1.6430926322937012
Batch 28/64 loss: 1.881063461303711
Batch 29/64 loss: 1.6224498748779297
Batch 30/64 loss: 2.6662473678588867
Batch 31/64 loss: 1.5914478302001953
Batch 32/64 loss: 1.6326260566711426
Batch 33/64 loss: 1.5712761878967285
Batch 34/64 loss: 2.460784912109375
Batch 35/64 loss: 1.585906982421875
Batch 36/64 loss: 1.6232061386108398
Batch 37/64 loss: 1.6370830535888672
Batch 38/64 loss: 1.6865849494934082
Batch 39/64 loss: 1.8267664909362793
Batch 40/64 loss: 1.6337966918945312
Batch 41/64 loss: 1.8042855262756348
Batch 42/64 loss: 2.498701572418213
Batch 43/64 loss: 4.0360283851623535
Batch 44/64 loss: 1.706284523010254
Batch 45/64 loss: 1.6415104866027832
Batch 46/64 loss: 1.7249608039855957
Batch 47/64 loss: 1.6862125396728516
Batch 48/64 loss: 1.71061372756958
Batch 49/64 loss: 1.679837703704834
Batch 50/64 loss: 1.657160758972168
Batch 51/64 loss: 2.820775032043457
Batch 52/64 loss: 1.6688599586486816
Batch 53/64 loss: 1.898460865020752
Batch 54/64 loss: 1.6425585746765137
Batch 55/64 loss: 1.5853476524353027
Batch 56/64 loss: 1.899355411529541
Batch 57/64 loss: 1.682528018951416
Batch 58/64 loss: 1.710343837738037
Batch 59/64 loss: 1.761497974395752
Batch 60/64 loss: 2.0109872817993164
Batch 61/64 loss: 2.258782386779785
Batch 62/64 loss: 1.6436285972595215
Batch 63/64 loss: 2.2160959243774414
Batch 64/64 loss: -1.800013542175293
Epoch 362  Train loss: 1.8559420978321748  Val loss: 1.4303271631194963
Epoch 363
-------------------------------
Batch 1/64 loss: 1.643402099609375
Batch 2/64 loss: 1.6867427825927734
Batch 3/64 loss: 1.6191630363464355
Batch 4/64 loss: 1.674825668334961
Batch 5/64 loss: 3.7561540603637695
Batch 6/64 loss: 1.5711889266967773
Batch 7/64 loss: 1.683624267578125
Batch 8/64 loss: 1.6983642578125
Batch 9/64 loss: 1.7532696723937988
Batch 10/64 loss: 1.6370749473571777
Batch 11/64 loss: 4.550936222076416
Batch 12/64 loss: 1.5942258834838867
Batch 13/64 loss: 1.6350855827331543
Batch 14/64 loss: 1.7591948509216309
Batch 15/64 loss: 1.6420783996582031
Batch 16/64 loss: 1.7698817253112793
Batch 17/64 loss: 1.8218493461608887
Batch 18/64 loss: 1.691694736480713
Batch 19/64 loss: 1.8262605667114258
Batch 20/64 loss: 1.7237548828125
Batch 21/64 loss: 1.7978801727294922
Batch 22/64 loss: 1.693939208984375
Batch 23/64 loss: 1.7310371398925781
Batch 24/64 loss: 2.289015769958496
Batch 25/64 loss: 1.7546296119689941
Batch 26/64 loss: 1.6327853202819824
Batch 27/64 loss: 1.7226228713989258
Batch 28/64 loss: 1.6648988723754883
Batch 29/64 loss: 1.5951766967773438
Batch 30/64 loss: 1.5975337028503418
Batch 31/64 loss: 1.7499136924743652
Batch 32/64 loss: 2.626535415649414
Batch 33/64 loss: 1.7497944831848145
Batch 34/64 loss: 1.5070977210998535
Batch 35/64 loss: 1.5957136154174805
Batch 36/64 loss: 2.189404010772705
Batch 37/64 loss: 2.2638635635375977
Batch 38/64 loss: 2.9925460815429688
Batch 39/64 loss: 1.6762385368347168
Batch 40/64 loss: 1.599897861480713
Batch 41/64 loss: 1.8295655250549316
Batch 42/64 loss: 1.5245938301086426
Batch 43/64 loss: 1.6721196174621582
Batch 44/64 loss: 1.884488582611084
Batch 45/64 loss: 1.5348143577575684
Batch 46/64 loss: 1.715552806854248
Batch 47/64 loss: 1.643239974975586
Batch 48/64 loss: 1.629854679107666
Batch 49/64 loss: 2.819485664367676
Batch 50/64 loss: 2.213136672973633
Batch 51/64 loss: 1.6719274520874023
Batch 52/64 loss: 3.9455738067626953
Batch 53/64 loss: 1.6512041091918945
Batch 54/64 loss: 1.679502010345459
Batch 55/64 loss: 1.6500134468078613
Batch 56/64 loss: 1.7962803840637207
Batch 57/64 loss: 1.5538854598999023
Batch 58/64 loss: 1.6902475357055664
Batch 59/64 loss: 1.599710464477539
Batch 60/64 loss: 1.6581788063049316
Batch 61/64 loss: 1.7066826820373535
Batch 62/64 loss: 1.6637368202209473
Batch 63/64 loss: 2.0432801246643066
Batch 64/64 loss: -1.8732671737670898
Epoch 363  Train loss: 1.8437869913437788  Val loss: 1.4018563863747717
Saving best model, epoch: 363
Epoch 364
-------------------------------
Batch 1/64 loss: 1.5909194946289062
Batch 2/64 loss: 1.5525026321411133
Batch 3/64 loss: 1.6962409019470215
Batch 4/64 loss: 2.1986589431762695
Batch 5/64 loss: 1.775620460510254
Batch 6/64 loss: 2.05712890625
Batch 7/64 loss: 2.793393135070801
Batch 8/64 loss: 1.7632880210876465
Batch 9/64 loss: 1.5669703483581543
Batch 10/64 loss: 1.7350482940673828
Batch 11/64 loss: 1.743776798248291
Batch 12/64 loss: 1.6888337135314941
Batch 13/64 loss: 1.658574104309082
Batch 14/64 loss: 1.7152986526489258
Batch 15/64 loss: 1.7327704429626465
Batch 16/64 loss: 2.08781099319458
Batch 17/64 loss: 1.8291683197021484
Batch 18/64 loss: 1.7202138900756836
Batch 19/64 loss: 1.750448226928711
Batch 20/64 loss: 1.8042244911193848
Batch 21/64 loss: 1.5636677742004395
Batch 22/64 loss: 1.774116039276123
Batch 23/64 loss: 1.7573442459106445
Batch 24/64 loss: 1.6941790580749512
Batch 25/64 loss: 4.596935272216797
Batch 26/64 loss: 2.7589263916015625
Batch 27/64 loss: 1.583144187927246
Batch 28/64 loss: 4.215600967407227
Batch 29/64 loss: 1.97222900390625
Batch 30/64 loss: 1.6249275207519531
Batch 31/64 loss: 2.0540995597839355
Batch 32/64 loss: 1.7417969703674316
Batch 33/64 loss: 1.661691665649414
Batch 34/64 loss: 1.6468162536621094
Batch 35/64 loss: 1.7669320106506348
Batch 36/64 loss: 2.098388195037842
Batch 37/64 loss: 1.6184053421020508
Batch 38/64 loss: 1.9005498886108398
Batch 39/64 loss: 1.8126282691955566
Batch 40/64 loss: 1.771543025970459
Batch 41/64 loss: 1.6713528633117676
Batch 42/64 loss: 1.7819137573242188
Batch 43/64 loss: 1.8682689666748047
Batch 44/64 loss: 1.6817030906677246
Batch 45/64 loss: 1.7633814811706543
Batch 46/64 loss: 1.6254901885986328
Batch 47/64 loss: 1.7151527404785156
Batch 48/64 loss: 1.7136383056640625
Batch 49/64 loss: 1.7667322158813477
Batch 50/64 loss: 1.6948981285095215
Batch 51/64 loss: 1.6070442199707031
Batch 52/64 loss: 4.134973526000977
Batch 53/64 loss: 2.6318540573120117
Batch 54/64 loss: 1.7886743545532227
Batch 55/64 loss: 1.7883639335632324
Batch 56/64 loss: 1.7823691368103027
Batch 57/64 loss: 1.6851301193237305
Batch 58/64 loss: 1.6591143608093262
Batch 59/64 loss: 1.8438854217529297
Batch 60/64 loss: 1.7186784744262695
Batch 61/64 loss: 2.0482797622680664
Batch 62/64 loss: 1.969482421875
Batch 63/64 loss: 2.480721950531006
Batch 64/64 loss: -1.8918609619140625
Epoch 364  Train loss: 1.8992473751890893  Val loss: 1.465752080543754
Epoch 365
-------------------------------
Batch 1/64 loss: 1.7865819931030273
Batch 2/64 loss: 1.8225021362304688
Batch 3/64 loss: 1.6721253395080566
Batch 4/64 loss: 2.0309386253356934
Batch 5/64 loss: 1.8432769775390625
Batch 6/64 loss: 1.721144676208496
Batch 7/64 loss: 1.9114265441894531
Batch 8/64 loss: 1.6501708030700684
Batch 9/64 loss: 1.6690707206726074
Batch 10/64 loss: 1.8985872268676758
Batch 11/64 loss: 1.6622586250305176
Batch 12/64 loss: 1.7267236709594727
Batch 13/64 loss: 1.8561158180236816
Batch 14/64 loss: 1.8961758613586426
Batch 15/64 loss: 1.6619958877563477
Batch 16/64 loss: 1.9283452033996582
Batch 17/64 loss: 1.75441312789917
Batch 18/64 loss: 1.6500277519226074
Batch 19/64 loss: 1.740889072418213
Batch 20/64 loss: 4.045384883880615
Batch 21/64 loss: 1.636049747467041
Batch 22/64 loss: 2.0745773315429688
Batch 23/64 loss: 1.6684565544128418
Batch 24/64 loss: 1.6697001457214355
Batch 25/64 loss: 4.359298229217529
Batch 26/64 loss: 1.560297966003418
Batch 27/64 loss: 1.6563849449157715
Batch 28/64 loss: 1.6733860969543457
Batch 29/64 loss: 1.6909122467041016
Batch 30/64 loss: 1.8037500381469727
Batch 31/64 loss: 1.7223634719848633
Batch 32/64 loss: 1.713836669921875
Batch 33/64 loss: 2.333120346069336
Batch 34/64 loss: 2.769129753112793
Batch 35/64 loss: 4.5976104736328125
Batch 36/64 loss: 1.7333059310913086
Batch 37/64 loss: 1.7518901824951172
Batch 38/64 loss: 1.7038931846618652
Batch 39/64 loss: 1.6772632598876953
Batch 40/64 loss: 1.5893616676330566
Batch 41/64 loss: 1.6262469291687012
Batch 42/64 loss: 1.7502951622009277
Batch 43/64 loss: 1.7015876770019531
Batch 44/64 loss: 1.7668542861938477
Batch 45/64 loss: 1.5647063255310059
Batch 46/64 loss: 1.752119541168213
Batch 47/64 loss: 1.6590771675109863
Batch 48/64 loss: 1.6769742965698242
Batch 49/64 loss: 1.6708006858825684
Batch 50/64 loss: 1.6219215393066406
Batch 51/64 loss: 1.7923579216003418
Batch 52/64 loss: 1.7718214988708496
Batch 53/64 loss: 1.5845751762390137
Batch 54/64 loss: 1.590712070465088
Batch 55/64 loss: 1.82358980178833
Batch 56/64 loss: 4.884964942932129
Batch 57/64 loss: 2.2203588485717773
Batch 58/64 loss: 2.08571720123291
Batch 59/64 loss: 1.9675335884094238
Batch 60/64 loss: 1.874133586883545
Batch 61/64 loss: 1.6981658935546875
Batch 62/64 loss: 2.029323101043701
Batch 63/64 loss: 1.6416759490966797
Batch 64/64 loss: -1.8022680282592773
Epoch 365  Train loss: 1.9092792997173234  Val loss: 1.4207465050556405
Epoch 366
-------------------------------
Batch 1/64 loss: 1.6321024894714355
Batch 2/64 loss: 2.0048828125
Batch 3/64 loss: 2.327815055847168
Batch 4/64 loss: 1.4925289154052734
Batch 5/64 loss: 1.565737247467041
Batch 6/64 loss: 1.7476286888122559
Batch 7/64 loss: 1.5659732818603516
Batch 8/64 loss: 1.5193567276000977
Batch 9/64 loss: 1.6684355735778809
Batch 10/64 loss: 1.7011299133300781
Batch 11/64 loss: 1.5854072570800781
Batch 12/64 loss: 4.573822498321533
Batch 13/64 loss: 1.6404023170471191
Batch 14/64 loss: 1.7916574478149414
Batch 15/64 loss: 1.554943561553955
Batch 16/64 loss: 1.7636356353759766
Batch 17/64 loss: 1.6313972473144531
Batch 18/64 loss: 2.786707878112793
Batch 19/64 loss: 1.683145523071289
Batch 20/64 loss: 1.6344680786132812
Batch 21/64 loss: 1.8557333946228027
Batch 22/64 loss: 1.7156119346618652
Batch 23/64 loss: 1.8512802124023438
Batch 24/64 loss: 1.67551851272583
Batch 25/64 loss: 1.819535255432129
Batch 26/64 loss: 1.8258028030395508
Batch 27/64 loss: 1.811978816986084
Batch 28/64 loss: 3.1747937202453613
Batch 29/64 loss: 1.7336411476135254
Batch 30/64 loss: 1.8520517349243164
Batch 31/64 loss: 1.8695101737976074
Batch 32/64 loss: 1.6324119567871094
Batch 33/64 loss: 1.535346508026123
Batch 34/64 loss: 1.5999946594238281
Batch 35/64 loss: 1.8363614082336426
Batch 36/64 loss: 1.6944947242736816
Batch 37/64 loss: 1.8408727645874023
Batch 38/64 loss: 1.858393669128418
Batch 39/64 loss: 1.7926864624023438
Batch 40/64 loss: 4.336759567260742
Batch 41/64 loss: 1.704148292541504
Batch 42/64 loss: 1.804417610168457
Batch 43/64 loss: 1.8369088172912598
Batch 44/64 loss: 1.7381138801574707
Batch 45/64 loss: 1.601111888885498
Batch 46/64 loss: 1.5772991180419922
Batch 47/64 loss: 1.7805438041687012
Batch 48/64 loss: 1.7556519508361816
Batch 49/64 loss: 1.6163859367370605
Batch 50/64 loss: 1.8247294425964355
Batch 51/64 loss: 1.7775826454162598
Batch 52/64 loss: 1.797440528869629
Batch 53/64 loss: 1.79718017578125
Batch 54/64 loss: 2.012610912322998
Batch 55/64 loss: 3.774280071258545
Batch 56/64 loss: 1.623642921447754
Batch 57/64 loss: 2.4664573669433594
Batch 58/64 loss: 2.730715751647949
Batch 59/64 loss: 1.8824806213378906
Batch 60/64 loss: 1.9925284385681152
Batch 61/64 loss: 1.8393254280090332
Batch 62/64 loss: 1.7822089195251465
Batch 63/64 loss: 1.7894501686096191
Batch 64/64 loss: -1.8879852294921875
Epoch 366  Train loss: 1.8866381701301127  Val loss: 1.5211058941084086
Epoch 367
-------------------------------
Batch 1/64 loss: 1.7013435363769531
Batch 2/64 loss: 1.6265158653259277
Batch 3/64 loss: 1.8896474838256836
Batch 4/64 loss: 1.6600298881530762
Batch 5/64 loss: 1.757436752319336
Batch 6/64 loss: 1.67905855178833
Batch 7/64 loss: 2.192641258239746
Batch 8/64 loss: 1.7664389610290527
Batch 9/64 loss: 1.6996536254882812
Batch 10/64 loss: 2.2427101135253906
Batch 11/64 loss: 1.7242789268493652
Batch 12/64 loss: 1.632199764251709
Batch 13/64 loss: 1.8167076110839844
Batch 14/64 loss: 1.80055570602417
Batch 15/64 loss: 1.880831241607666
Batch 16/64 loss: 1.80293607711792
Batch 17/64 loss: 5.3620123863220215
Batch 18/64 loss: 1.8407292366027832
Batch 19/64 loss: 3.875131607055664
Batch 20/64 loss: 1.7773675918579102
Batch 21/64 loss: 1.7463350296020508
Batch 22/64 loss: 1.738372802734375
Batch 23/64 loss: 1.6211533546447754
Batch 24/64 loss: 1.8405108451843262
Batch 25/64 loss: 3.1078896522521973
Batch 26/64 loss: 2.1838855743408203
Batch 27/64 loss: 2.7498321533203125
Batch 28/64 loss: 1.6237926483154297
Batch 29/64 loss: 1.5721759796142578
Batch 30/64 loss: 4.29202127456665
Batch 31/64 loss: 1.8714118003845215
Batch 32/64 loss: 1.85272216796875
Batch 33/64 loss: 1.720993995666504
Batch 34/64 loss: 1.6787567138671875
Batch 35/64 loss: 1.694127082824707
Batch 36/64 loss: 1.686103343963623
Batch 37/64 loss: 1.7705769538879395
Batch 38/64 loss: 2.100505828857422
Batch 39/64 loss: 1.7023253440856934
Batch 40/64 loss: 2.0581860542297363
Batch 41/64 loss: 2.01185941696167
Batch 42/64 loss: 1.8820228576660156
Batch 43/64 loss: 1.8019280433654785
Batch 44/64 loss: 1.8937392234802246
Batch 45/64 loss: 2.6427340507507324
Batch 46/64 loss: 1.789891242980957
Batch 47/64 loss: 2.1362314224243164
Batch 48/64 loss: 1.9142184257507324
Batch 49/64 loss: 1.7124214172363281
Batch 50/64 loss: 1.7250733375549316
Batch 51/64 loss: 1.732205867767334
Batch 52/64 loss: 1.7912988662719727
Batch 53/64 loss: 1.773876667022705
Batch 54/64 loss: 1.8053364753723145
Batch 55/64 loss: 1.7011656761169434
Batch 56/64 loss: 1.865534782409668
Batch 57/64 loss: 2.086282253265381
Batch 58/64 loss: 1.7425413131713867
Batch 59/64 loss: 1.9094548225402832
Batch 60/64 loss: 1.781898021697998
Batch 61/64 loss: 1.8170127868652344
Batch 62/64 loss: 1.7480359077453613
Batch 63/64 loss: 1.7421326637268066
Batch 64/64 loss: -1.722452163696289
Epoch 367  Train loss: 1.9459601757573146  Val loss: 1.6166509910137792
Epoch 368
-------------------------------
Batch 1/64 loss: 2.57706356048584
Batch 2/64 loss: 2.134242534637451
Batch 3/64 loss: 2.045836925506592
Batch 4/64 loss: 2.3720650672912598
Batch 5/64 loss: 1.8789191246032715
Batch 6/64 loss: 1.9088902473449707
Batch 7/64 loss: 1.758944034576416
Batch 8/64 loss: 1.7950162887573242
Batch 9/64 loss: 2.8258590698242188
Batch 10/64 loss: 4.170558452606201
Batch 11/64 loss: 1.8663749694824219
Batch 12/64 loss: 1.9104952812194824
Batch 13/64 loss: 1.8744072914123535
Batch 14/64 loss: 1.900865077972412
Batch 15/64 loss: 1.8213210105895996
Batch 16/64 loss: 2.2985548973083496
Batch 17/64 loss: 3.8638906478881836
Batch 18/64 loss: 1.7584648132324219
Batch 19/64 loss: 1.8260040283203125
Batch 20/64 loss: 1.7384142875671387
Batch 21/64 loss: 1.8869428634643555
Batch 22/64 loss: 1.7187175750732422
Batch 23/64 loss: 1.9360241889953613
Batch 24/64 loss: 1.6252923011779785
Batch 25/64 loss: 1.7165508270263672
Batch 26/64 loss: 2.018202781677246
Batch 27/64 loss: 1.6067390441894531
Batch 28/64 loss: 1.7330665588378906
Batch 29/64 loss: 1.920121192932129
Batch 30/64 loss: 1.9224448204040527
Batch 31/64 loss: 1.8268699645996094
Batch 32/64 loss: 2.9685258865356445
Batch 33/64 loss: 2.0799155235290527
Batch 34/64 loss: 2.0553102493286133
Batch 35/64 loss: 2.504134178161621
Batch 36/64 loss: 1.7616362571716309
Batch 37/64 loss: 2.3508262634277344
Batch 38/64 loss: 1.9574322700500488
Batch 39/64 loss: 2.5528388023376465
Batch 40/64 loss: 2.019711494445801
Batch 41/64 loss: 1.9688186645507812
Batch 42/64 loss: 1.9636139869689941
Batch 43/64 loss: 2.1480860710144043
Batch 44/64 loss: 1.9570379257202148
Batch 45/64 loss: 1.8285727500915527
Batch 46/64 loss: 2.06596040725708
Batch 47/64 loss: 2.486809253692627
Batch 48/64 loss: 1.934554100036621
Batch 49/64 loss: 1.7945570945739746
Batch 50/64 loss: 1.805511474609375
Batch 51/64 loss: 1.872039794921875
Batch 52/64 loss: 2.199648857116699
Batch 53/64 loss: 1.9934577941894531
Batch 54/64 loss: 2.0725784301757812
Batch 55/64 loss: 2.2811946868896484
Batch 56/64 loss: 3.0575437545776367
Batch 57/64 loss: 1.7822904586791992
Batch 58/64 loss: 4.7801642417907715
Batch 59/64 loss: 1.8594279289245605
Batch 60/64 loss: 2.089137554168701
Batch 61/64 loss: 2.074862480163574
Batch 62/64 loss: 2.0742859840393066
Batch 63/64 loss: 1.786816120147705
Batch 64/64 loss: -1.6438570022583008
Epoch 368  Train loss: 2.088338317123114  Val loss: 1.7684440743882222
Epoch 369
-------------------------------
Batch 1/64 loss: 1.8637542724609375
Batch 2/64 loss: 1.7746758460998535
Batch 3/64 loss: 1.840714931488037
Batch 4/64 loss: 3.725154399871826
Batch 5/64 loss: 1.963120937347412
Batch 6/64 loss: 1.958177089691162
Batch 7/64 loss: 1.967771053314209
Batch 8/64 loss: 1.7474207878112793
Batch 9/64 loss: 2.046358585357666
Batch 10/64 loss: 2.0856680870056152
Batch 11/64 loss: 1.9367966651916504
Batch 12/64 loss: 1.8352155685424805
Batch 13/64 loss: 1.7447724342346191
Batch 14/64 loss: 2.0939626693725586
Batch 15/64 loss: 2.1188478469848633
Batch 16/64 loss: 1.7839608192443848
Batch 17/64 loss: 1.6080718040466309
Batch 18/64 loss: 1.7270078659057617
Batch 19/64 loss: 1.71675443649292
Batch 20/64 loss: 1.7155423164367676
Batch 21/64 loss: 1.7893943786621094
Batch 22/64 loss: 2.129758358001709
Batch 23/64 loss: 1.8966412544250488
Batch 24/64 loss: 3.9024176597595215
Batch 25/64 loss: 4.776762008666992
Batch 26/64 loss: 1.854966163635254
Batch 27/64 loss: 1.7983856201171875
Batch 28/64 loss: 1.641469955444336
Batch 29/64 loss: 1.8976187705993652
Batch 30/64 loss: 1.8334803581237793
Batch 31/64 loss: 1.7574687004089355
Batch 32/64 loss: 1.786745548248291
Batch 33/64 loss: 1.7077579498291016
Batch 34/64 loss: 1.7822442054748535
Batch 35/64 loss: 1.8268308639526367
Batch 36/64 loss: 4.324331760406494
Batch 37/64 loss: 2.090519428253174
Batch 38/64 loss: 1.7472810745239258
Batch 39/64 loss: 1.7511720657348633
Batch 40/64 loss: 1.6493549346923828
Batch 41/64 loss: 1.75938081741333
Batch 42/64 loss: 2.1422266960144043
Batch 43/64 loss: 1.7214875221252441
Batch 44/64 loss: 1.8188676834106445
Batch 45/64 loss: 1.7357006072998047
Batch 46/64 loss: 1.6081132888793945
Batch 47/64 loss: 1.7282662391662598
Batch 48/64 loss: 2.9564199447631836
Batch 49/64 loss: 1.5978045463562012
Batch 50/64 loss: 1.7476930618286133
Batch 51/64 loss: 1.7503089904785156
Batch 52/64 loss: 1.7308197021484375
Batch 53/64 loss: 1.8269572257995605
Batch 54/64 loss: 1.7981510162353516
Batch 55/64 loss: 1.7451205253601074
Batch 56/64 loss: 2.184917449951172
Batch 57/64 loss: 3.1503143310546875
Batch 58/64 loss: 1.6610541343688965
Batch 59/64 loss: 1.6881966590881348
Batch 60/64 loss: 1.7960495948791504
Batch 61/64 loss: 1.8720240592956543
Batch 62/64 loss: 1.8031792640686035
Batch 63/64 loss: 1.6645746231079102
Batch 64/64 loss: -1.7401094436645508
Epoch 369  Train loss: 1.9667591431561637  Val loss: 1.569705596084857
Epoch 370
-------------------------------
Batch 1/64 loss: 1.7079567909240723
Batch 2/64 loss: 1.8449459075927734
Batch 3/64 loss: 1.9135489463806152
Batch 4/64 loss: 1.75679349899292
Batch 5/64 loss: 1.8055973052978516
Batch 6/64 loss: 1.7270927429199219
Batch 7/64 loss: 1.7406964302062988
Batch 8/64 loss: 1.7074508666992188
Batch 9/64 loss: 1.9114246368408203
Batch 10/64 loss: 1.69893217086792
Batch 11/64 loss: 1.888392448425293
Batch 12/64 loss: 1.8164148330688477
Batch 13/64 loss: 1.7946929931640625
Batch 14/64 loss: 1.8741083145141602
Batch 15/64 loss: 1.7188076972961426
Batch 16/64 loss: 2.4700570106506348
Batch 17/64 loss: 1.8031020164489746
Batch 18/64 loss: 2.028231143951416
Batch 19/64 loss: 1.8632278442382812
Batch 20/64 loss: 2.029613494873047
Batch 21/64 loss: 1.6445612907409668
Batch 22/64 loss: 1.8743157386779785
Batch 23/64 loss: 1.9319825172424316
Batch 24/64 loss: 1.7605977058410645
Batch 25/64 loss: 4.264250755310059
Batch 26/64 loss: 1.7845993041992188
Batch 27/64 loss: 1.8150348663330078
Batch 28/64 loss: 1.7188820838928223
Batch 29/64 loss: 1.7347559928894043
Batch 30/64 loss: 2.8411202430725098
Batch 31/64 loss: 1.6738739013671875
Batch 32/64 loss: 1.7255120277404785
Batch 33/64 loss: 1.7435994148254395
Batch 34/64 loss: 1.7170772552490234
Batch 35/64 loss: 1.6751594543457031
Batch 36/64 loss: 1.7710814476013184
Batch 37/64 loss: 1.9039678573608398
Batch 38/64 loss: 1.6068782806396484
Batch 39/64 loss: 1.749971866607666
Batch 40/64 loss: 1.585524082183838
Batch 41/64 loss: 1.5953469276428223
Batch 42/64 loss: 1.6747775077819824
Batch 43/64 loss: 1.5333404541015625
Batch 44/64 loss: 1.7148385047912598
Batch 45/64 loss: 2.282726287841797
Batch 46/64 loss: 2.6070146560668945
Batch 47/64 loss: 3.71987247467041
Batch 48/64 loss: 1.7972493171691895
Batch 49/64 loss: 1.6985554695129395
Batch 50/64 loss: 1.649670124053955
Batch 51/64 loss: 1.6692423820495605
Batch 52/64 loss: 1.991685390472412
Batch 53/64 loss: 1.9038453102111816
Batch 54/64 loss: 1.694730281829834
Batch 55/64 loss: 1.7007708549499512
Batch 56/64 loss: 1.7864465713500977
Batch 57/64 loss: 2.233485221862793
Batch 58/64 loss: 5.607617378234863
Batch 59/64 loss: 1.7395620346069336
Batch 60/64 loss: 1.807931900024414
Batch 61/64 loss: 1.9596071243286133
Batch 62/64 loss: 2.0542101860046387
Batch 63/64 loss: 1.67695951461792
Batch 64/64 loss: -1.679098129272461
Epoch 370  Train loss: 1.9210038503011069  Val loss: 1.494356896049788
Epoch 371
-------------------------------
Batch 1/64 loss: 1.7166485786437988
Batch 2/64 loss: 3.762478828430176
Batch 3/64 loss: 1.691244125366211
Batch 4/64 loss: 1.7598023414611816
Batch 5/64 loss: 1.8613319396972656
Batch 6/64 loss: 1.6596155166625977
Batch 7/64 loss: 1.7366809844970703
Batch 8/64 loss: 1.6665434837341309
Batch 9/64 loss: 1.83964204788208
Batch 10/64 loss: 1.6266884803771973
Batch 11/64 loss: 1.7246403694152832
Batch 12/64 loss: 1.8791346549987793
Batch 13/64 loss: 1.6976227760314941
Batch 14/64 loss: 1.7348170280456543
Batch 15/64 loss: 1.7975373268127441
Batch 16/64 loss: 1.6721038818359375
Batch 17/64 loss: 1.6798348426818848
Batch 18/64 loss: 2.013763904571533
Batch 19/64 loss: 1.654984951019287
Batch 20/64 loss: 1.8378028869628906
Batch 21/64 loss: 1.8264827728271484
Batch 22/64 loss: 1.6828079223632812
Batch 23/64 loss: 1.785630702972412
Batch 24/64 loss: 1.8424854278564453
Batch 25/64 loss: 2.9080214500427246
Batch 26/64 loss: 1.7206840515136719
Batch 27/64 loss: 2.487785816192627
Batch 28/64 loss: 1.7455639839172363
Batch 29/64 loss: 1.7734193801879883
Batch 30/64 loss: 1.7993097305297852
Batch 31/64 loss: 1.8593482971191406
Batch 32/64 loss: 1.6305131912231445
Batch 33/64 loss: 1.7773075103759766
Batch 34/64 loss: 1.5964484214782715
Batch 35/64 loss: 1.6310820579528809
Batch 36/64 loss: 1.8344993591308594
Batch 37/64 loss: 1.9424662590026855
Batch 38/64 loss: 1.7291302680969238
Batch 39/64 loss: 1.6467547416687012
Batch 40/64 loss: 2.4173455238342285
Batch 41/64 loss: 1.6712040901184082
Batch 42/64 loss: 1.6797237396240234
Batch 43/64 loss: 1.7836737632751465
Batch 44/64 loss: 3.044600009918213
Batch 45/64 loss: 2.061781406402588
Batch 46/64 loss: 1.7605161666870117
Batch 47/64 loss: 1.6965641975402832
Batch 48/64 loss: 1.8821196556091309
Batch 49/64 loss: 1.6114563941955566
Batch 50/64 loss: 1.9521422386169434
Batch 51/64 loss: 4.6339898109436035
Batch 52/64 loss: 1.7455720901489258
Batch 53/64 loss: 1.789121150970459
Batch 54/64 loss: 2.0746850967407227
Batch 55/64 loss: 1.7273635864257812
Batch 56/64 loss: 2.05869197845459
Batch 57/64 loss: 2.0379347801208496
Batch 58/64 loss: 1.684934139251709
Batch 59/64 loss: 1.737417221069336
Batch 60/64 loss: 1.6406440734863281
Batch 61/64 loss: 1.94215726852417
Batch 62/64 loss: 2.7352495193481445
Batch 63/64 loss: 4.082784652709961
Batch 64/64 loss: -1.6140155792236328
Epoch 371  Train loss: 1.921157979030235  Val loss: 1.4554116029509974
Epoch 372
-------------------------------
Batch 1/64 loss: 1.7479138374328613
Batch 2/64 loss: 1.6071972846984863
Batch 3/64 loss: 1.5483479499816895
Batch 4/64 loss: 1.6799354553222656
Batch 5/64 loss: 1.6674137115478516
Batch 6/64 loss: 1.6371726989746094
Batch 7/64 loss: 1.725860595703125
Batch 8/64 loss: 1.6670045852661133
Batch 9/64 loss: 2.5351486206054688
Batch 10/64 loss: 1.5967302322387695
Batch 11/64 loss: 1.7222671508789062
Batch 12/64 loss: 1.7083492279052734
Batch 13/64 loss: 1.6835341453552246
Batch 14/64 loss: 1.9494438171386719
Batch 15/64 loss: 1.8727669715881348
Batch 16/64 loss: 2.001636505126953
Batch 17/64 loss: 1.66502046585083
Batch 18/64 loss: 1.8192949295043945
Batch 19/64 loss: 2.621464729309082
Batch 20/64 loss: 1.6591415405273438
Batch 21/64 loss: 1.934619426727295
Batch 22/64 loss: 1.727379322052002
Batch 23/64 loss: 1.7081365585327148
Batch 24/64 loss: 1.7916665077209473
Batch 25/64 loss: 1.9161920547485352
Batch 26/64 loss: 2.172107219696045
Batch 27/64 loss: 1.791290283203125
Batch 28/64 loss: 2.001997470855713
Batch 29/64 loss: 1.7532410621643066
Batch 30/64 loss: 1.755089282989502
Batch 31/64 loss: 1.692124366760254
Batch 32/64 loss: 1.659630298614502
Batch 33/64 loss: 1.9340834617614746
Batch 34/64 loss: 1.6954994201660156
Batch 35/64 loss: 1.753066062927246
Batch 36/64 loss: 1.6797480583190918
Batch 37/64 loss: 1.6503286361694336
Batch 38/64 loss: 1.7078337669372559
Batch 39/64 loss: 1.7471656799316406
Batch 40/64 loss: 4.652652263641357
Batch 41/64 loss: 1.5657720565795898
Batch 42/64 loss: 2.919981002807617
Batch 43/64 loss: 1.6428275108337402
Batch 44/64 loss: 1.948667049407959
Batch 45/64 loss: 2.0749878883361816
Batch 46/64 loss: 1.725522518157959
Batch 47/64 loss: 1.9986538887023926
Batch 48/64 loss: 3.073223114013672
Batch 49/64 loss: 4.203511714935303
Batch 50/64 loss: 2.0656795501708984
Batch 51/64 loss: 1.7766013145446777
Batch 52/64 loss: 1.740828514099121
Batch 53/64 loss: 1.7373690605163574
Batch 54/64 loss: 1.6912574768066406
Batch 55/64 loss: 1.5935673713684082
Batch 56/64 loss: 1.8846044540405273
Batch 57/64 loss: 1.74924898147583
Batch 58/64 loss: 4.3677659034729
Batch 59/64 loss: 1.628396987915039
Batch 60/64 loss: 1.701612949371338
Batch 61/64 loss: 1.739029884338379
Batch 62/64 loss: 1.7076430320739746
Batch 63/64 loss: 1.626694679260254
Batch 64/64 loss: -1.7381019592285156
Epoch 372  Train loss: 1.9090096641989316  Val loss: 1.4598164509252174
Epoch 373
-------------------------------
Batch 1/64 loss: 1.6746454238891602
Batch 2/64 loss: 1.8807668685913086
Batch 3/64 loss: 1.6939592361450195
Batch 4/64 loss: 1.6154069900512695
Batch 5/64 loss: 2.0045251846313477
Batch 6/64 loss: 1.6497116088867188
Batch 7/64 loss: 1.8115100860595703
Batch 8/64 loss: 1.9531807899475098
Batch 9/64 loss: 2.012237071990967
Batch 10/64 loss: 1.9201865196228027
Batch 11/64 loss: 1.732865810394287
Batch 12/64 loss: 5.141473770141602
Batch 13/64 loss: 1.6376304626464844
Batch 14/64 loss: 1.7771077156066895
Batch 15/64 loss: 2.5883936882019043
Batch 16/64 loss: 1.8671464920043945
Batch 17/64 loss: 1.7124462127685547
Batch 18/64 loss: 1.7203660011291504
Batch 19/64 loss: 1.7076406478881836
Batch 20/64 loss: 1.8056159019470215
Batch 21/64 loss: 1.7700648307800293
Batch 22/64 loss: 1.6333799362182617
Batch 23/64 loss: 2.5404090881347656
Batch 24/64 loss: 1.6927227973937988
Batch 25/64 loss: 1.8705825805664062
Batch 26/64 loss: 1.765859603881836
Batch 27/64 loss: 1.7919120788574219
Batch 28/64 loss: 2.030301570892334
Batch 29/64 loss: 1.6268243789672852
Batch 30/64 loss: 1.7261066436767578
Batch 31/64 loss: 1.7946267127990723
Batch 32/64 loss: 1.6963934898376465
Batch 33/64 loss: 1.7183079719543457
Batch 34/64 loss: 2.593191623687744
Batch 35/64 loss: 1.66351318359375
Batch 36/64 loss: 2.9579453468322754
Batch 37/64 loss: 1.906702995300293
Batch 38/64 loss: 1.681286334991455
Batch 39/64 loss: 2.859221935272217
Batch 40/64 loss: 1.616039752960205
Batch 41/64 loss: 1.633531093597412
Batch 42/64 loss: 1.6653776168823242
Batch 43/64 loss: 1.6555862426757812
Batch 44/64 loss: 1.9269466400146484
Batch 45/64 loss: 3.874298572540283
Batch 46/64 loss: 1.654008388519287
Batch 47/64 loss: 1.9403843879699707
Batch 48/64 loss: 1.7073235511779785
Batch 49/64 loss: 1.7871417999267578
Batch 50/64 loss: 1.8190946578979492
Batch 51/64 loss: 1.5701894760131836
Batch 52/64 loss: 1.759150505065918
Batch 53/64 loss: 1.7253074645996094
Batch 54/64 loss: 1.9526972770690918
Batch 55/64 loss: 1.8011717796325684
Batch 56/64 loss: 2.20023775100708
Batch 57/64 loss: 4.060792446136475
Batch 58/64 loss: 1.8964691162109375
Batch 59/64 loss: 1.901658535003662
Batch 60/64 loss: 1.6686782836914062
Batch 61/64 loss: 1.6328668594360352
Batch 62/64 loss: 1.683633804321289
Batch 63/64 loss: 1.7839388847351074
Batch 64/64 loss: -1.7880058288574219
Epoch 373  Train loss: 1.9263010212019378  Val loss: 1.451626610510128
Epoch 374
-------------------------------
Batch 1/64 loss: 1.7712059020996094
Batch 2/64 loss: 1.6486425399780273
Batch 3/64 loss: 1.8523836135864258
Batch 4/64 loss: 1.7127223014831543
Batch 5/64 loss: 1.7782244682312012
Batch 6/64 loss: 1.6831979751586914
Batch 7/64 loss: 1.6517524719238281
Batch 8/64 loss: 1.7702622413635254
Batch 9/64 loss: 3.8314108848571777
Batch 10/64 loss: 1.6420526504516602
Batch 11/64 loss: 1.8107008934020996
Batch 12/64 loss: 1.7939143180847168
Batch 13/64 loss: 1.753026008605957
Batch 14/64 loss: 2.7977733612060547
Batch 15/64 loss: 4.081830024719238
Batch 16/64 loss: 1.6289162635803223
Batch 17/64 loss: 1.604353904724121
Batch 18/64 loss: 1.6574387550354004
Batch 19/64 loss: 1.8143248558044434
Batch 20/64 loss: 1.6426482200622559
Batch 21/64 loss: 1.8432559967041016
Batch 22/64 loss: 1.6598625183105469
Batch 23/64 loss: 1.6100192070007324
Batch 24/64 loss: 1.9368586540222168
Batch 25/64 loss: 1.6908621788024902
Batch 26/64 loss: 1.763627052307129
Batch 27/64 loss: 1.6764965057373047
Batch 28/64 loss: 1.6617579460144043
Batch 29/64 loss: 1.8036928176879883
Batch 30/64 loss: 1.7689924240112305
Batch 31/64 loss: 1.5856809616088867
Batch 32/64 loss: 1.8594913482666016
Batch 33/64 loss: 1.7029228210449219
Batch 34/64 loss: 1.7601065635681152
Batch 35/64 loss: 4.6650004386901855
Batch 36/64 loss: 1.6137728691101074
Batch 37/64 loss: 2.131822109222412
Batch 38/64 loss: 1.9414453506469727
Batch 39/64 loss: 1.720198631286621
Batch 40/64 loss: 1.6054883003234863
Batch 41/64 loss: 1.5570168495178223
Batch 42/64 loss: 1.6446151733398438
Batch 43/64 loss: 1.6998090744018555
Batch 44/64 loss: 1.6470317840576172
Batch 45/64 loss: 1.7893013954162598
Batch 46/64 loss: 1.6941843032836914
Batch 47/64 loss: 2.8002548217773438
Batch 48/64 loss: 1.7171473503112793
Batch 49/64 loss: 2.9900364875793457
Batch 50/64 loss: 2.4396886825561523
Batch 51/64 loss: 1.6754379272460938
Batch 52/64 loss: 1.6115365028381348
Batch 53/64 loss: 1.64497709274292
Batch 54/64 loss: 1.6624412536621094
Batch 55/64 loss: 1.9063892364501953
Batch 56/64 loss: 2.131807804107666
Batch 57/64 loss: 1.9242939949035645
Batch 58/64 loss: 2.6980767250061035
Batch 59/64 loss: 2.0317907333374023
Batch 60/64 loss: 1.7377996444702148
Batch 61/64 loss: 1.7856659889221191
Batch 62/64 loss: 1.9380946159362793
Batch 63/64 loss: 1.732862949371338
Batch 64/64 loss: -1.5031023025512695
Epoch 374  Train loss: 1.9021344315771964  Val loss: 1.509006513353066
Epoch 375
-------------------------------
Batch 1/64 loss: 1.8073320388793945
Batch 2/64 loss: 1.885695457458496
Batch 3/64 loss: 1.7361345291137695
Batch 4/64 loss: 2.079890251159668
Batch 5/64 loss: 1.772547721862793
Batch 6/64 loss: 1.7949085235595703
Batch 7/64 loss: 2.725794792175293
Batch 8/64 loss: 1.6976284980773926
Batch 9/64 loss: 1.6821861267089844
Batch 10/64 loss: 2.565646171569824
Batch 11/64 loss: 1.7619686126708984
Batch 12/64 loss: 2.009065628051758
Batch 13/64 loss: 1.9175338745117188
Batch 14/64 loss: 1.7351646423339844
Batch 15/64 loss: 1.7701821327209473
Batch 16/64 loss: 2.3100523948669434
Batch 17/64 loss: 1.6669235229492188
Batch 18/64 loss: 1.7609190940856934
Batch 19/64 loss: 1.6584091186523438
Batch 20/64 loss: 1.9993209838867188
Batch 21/64 loss: 1.6856780052185059
Batch 22/64 loss: 1.6587262153625488
Batch 23/64 loss: 1.6091222763061523
Batch 24/64 loss: 1.8587980270385742
Batch 25/64 loss: 1.6786003112792969
Batch 26/64 loss: 1.9043474197387695
Batch 27/64 loss: 1.9156904220581055
Batch 28/64 loss: 3.997708320617676
Batch 29/64 loss: 1.9453644752502441
Batch 30/64 loss: 1.7183918952941895
Batch 31/64 loss: 1.864954948425293
Batch 32/64 loss: 1.8157596588134766
Batch 33/64 loss: 1.6705164909362793
Batch 34/64 loss: 4.081775188446045
Batch 35/64 loss: 1.8676838874816895
Batch 36/64 loss: 1.8236780166625977
Batch 37/64 loss: 1.8380155563354492
Batch 38/64 loss: 1.6795158386230469
Batch 39/64 loss: 1.9044184684753418
Batch 40/64 loss: 1.6621112823486328
Batch 41/64 loss: 2.1667208671569824
Batch 42/64 loss: 1.7094712257385254
Batch 43/64 loss: 2.0059947967529297
Batch 44/64 loss: 1.60685396194458
Batch 45/64 loss: 1.915665626525879
Batch 46/64 loss: 1.85776948928833
Batch 47/64 loss: 1.6871404647827148
Batch 48/64 loss: 1.7494115829467773
Batch 49/64 loss: 2.0237107276916504
Batch 50/64 loss: 1.6719326972961426
Batch 51/64 loss: 2.884202480316162
Batch 52/64 loss: 2.532878875732422
Batch 53/64 loss: 1.661024570465088
Batch 54/64 loss: 1.6552624702453613
Batch 55/64 loss: 1.7999629974365234
Batch 56/64 loss: 4.885725975036621
Batch 57/64 loss: 1.747786045074463
Batch 58/64 loss: 1.7062649726867676
Batch 59/64 loss: 1.5870227813720703
Batch 60/64 loss: 2.104370594024658
Batch 61/64 loss: 1.6163363456726074
Batch 62/64 loss: 1.8113203048706055
Batch 63/64 loss: 2.4226064682006836
Batch 64/64 loss: -1.816025733947754
Epoch 375  Train loss: 1.9445580837773342  Val loss: 1.4855367129610986
Epoch 376
-------------------------------
Batch 1/64 loss: 1.8157668113708496
Batch 2/64 loss: 1.9319806098937988
Batch 3/64 loss: 1.9276738166809082
Batch 4/64 loss: 1.6716008186340332
Batch 5/64 loss: 1.762019157409668
Batch 6/64 loss: 1.6864023208618164
Batch 7/64 loss: 2.4858455657958984
Batch 8/64 loss: 1.7515501976013184
Batch 9/64 loss: 1.8633575439453125
Batch 10/64 loss: 1.8397588729858398
Batch 11/64 loss: 1.551370620727539
Batch 12/64 loss: 1.7777013778686523
Batch 13/64 loss: 1.8429460525512695
Batch 14/64 loss: 1.8830595016479492
Batch 15/64 loss: 1.6689138412475586
Batch 16/64 loss: 2.8283286094665527
Batch 17/64 loss: 1.5512194633483887
Batch 18/64 loss: 4.106578826904297
Batch 19/64 loss: 1.7984533309936523
Batch 20/64 loss: 1.9576034545898438
Batch 21/64 loss: 1.6665430068969727
Batch 22/64 loss: 1.719836711883545
Batch 23/64 loss: 1.5178627967834473
Batch 24/64 loss: 3.9234132766723633
Batch 25/64 loss: 1.7142868041992188
Batch 26/64 loss: 2.050628185272217
Batch 27/64 loss: 1.5877175331115723
Batch 28/64 loss: 1.5348711013793945
Batch 29/64 loss: 1.59210205078125
Batch 30/64 loss: 1.677464485168457
Batch 31/64 loss: 1.605700969696045
Batch 32/64 loss: 1.7542510032653809
Batch 33/64 loss: 2.255110263824463
Batch 34/64 loss: 1.6327991485595703
Batch 35/64 loss: 1.7682223320007324
Batch 36/64 loss: 1.9718742370605469
Batch 37/64 loss: 1.6468439102172852
Batch 38/64 loss: 1.6215462684631348
Batch 39/64 loss: 1.5596532821655273
Batch 40/64 loss: 2.3133535385131836
Batch 41/64 loss: 1.7747769355773926
Batch 42/64 loss: 1.7590713500976562
Batch 43/64 loss: 1.6605682373046875
Batch 44/64 loss: 1.8406996726989746
Batch 45/64 loss: 1.8421730995178223
Batch 46/64 loss: 1.6241273880004883
Batch 47/64 loss: 2.8696398735046387
Batch 48/64 loss: 1.9047369956970215
Batch 49/64 loss: 1.612372875213623
Batch 50/64 loss: 1.8130097389221191
Batch 51/64 loss: 1.646787166595459
Batch 52/64 loss: 4.637917995452881
Batch 53/64 loss: 1.5473852157592773
Batch 54/64 loss: 1.6381454467773438
Batch 55/64 loss: 1.603696346282959
Batch 56/64 loss: 1.7667179107666016
Batch 57/64 loss: 1.605151653289795
Batch 58/64 loss: 1.8544025421142578
Batch 59/64 loss: 1.6846084594726562
Batch 60/64 loss: 2.050414562225342
Batch 61/64 loss: 1.9873242378234863
Batch 62/64 loss: 1.6859712600708008
Batch 63/64 loss: 1.6473627090454102
Batch 64/64 loss: -1.2900829315185547
Epoch 376  Train loss: 1.8808739007688036  Val loss: 1.442669386716233
Epoch 377
-------------------------------
Batch 1/64 loss: 1.8440732955932617
Batch 2/64 loss: 1.6794404983520508
Batch 3/64 loss: 1.9002656936645508
Batch 4/64 loss: 1.7936067581176758
Batch 5/64 loss: 1.7416834831237793
Batch 6/64 loss: 1.662808895111084
Batch 7/64 loss: 4.034492015838623
Batch 8/64 loss: 1.7052431106567383
Batch 9/64 loss: 1.9028620719909668
Batch 10/64 loss: 2.033604145050049
Batch 11/64 loss: 1.666839599609375
Batch 12/64 loss: 1.7018227577209473
Batch 13/64 loss: 1.7459139823913574
Batch 14/64 loss: 1.934434413909912
Batch 15/64 loss: 2.0423154830932617
Batch 16/64 loss: 1.7068719863891602
Batch 17/64 loss: 1.852126121520996
Batch 18/64 loss: 1.632824420928955
Batch 19/64 loss: 1.613790512084961
Batch 20/64 loss: 1.7828588485717773
Batch 21/64 loss: 4.586747646331787
Batch 22/64 loss: 1.7005958557128906
Batch 23/64 loss: 1.8815479278564453
Batch 24/64 loss: 1.6288485527038574
Batch 25/64 loss: 2.30972957611084
Batch 26/64 loss: 1.6178746223449707
Batch 27/64 loss: 1.69704008102417
Batch 28/64 loss: 1.6416349411010742
Batch 29/64 loss: 1.6345953941345215
Batch 30/64 loss: 1.6822457313537598
Batch 31/64 loss: 1.6336369514465332
Batch 32/64 loss: 1.7692980766296387
Batch 33/64 loss: 1.6232085227966309
Batch 34/64 loss: 1.960205078125
Batch 35/64 loss: 1.7770256996154785
Batch 36/64 loss: 2.696455955505371
Batch 37/64 loss: 1.6136884689331055
Batch 38/64 loss: 1.5865063667297363
Batch 39/64 loss: 1.7053437232971191
Batch 40/64 loss: 1.7706737518310547
Batch 41/64 loss: 1.633432388305664
Batch 42/64 loss: 1.9811859130859375
Batch 43/64 loss: 1.9065508842468262
Batch 44/64 loss: 1.692899227142334
Batch 45/64 loss: 1.6383261680603027
Batch 46/64 loss: 2.849721908569336
Batch 47/64 loss: 1.5259838104248047
Batch 48/64 loss: 1.7313909530639648
Batch 49/64 loss: 1.7264885902404785
Batch 50/64 loss: 3.3436903953552246
Batch 51/64 loss: 1.6316328048706055
Batch 52/64 loss: 1.7158832550048828
Batch 53/64 loss: 1.7240171432495117
Batch 54/64 loss: 1.740990161895752
Batch 55/64 loss: 1.718954086303711
Batch 56/64 loss: 1.7756690979003906
Batch 57/64 loss: 3.836186408996582
Batch 58/64 loss: 1.5812535285949707
Batch 59/64 loss: 1.738980770111084
Batch 60/64 loss: 1.8078784942626953
Batch 61/64 loss: 2.1581778526306152
Batch 62/64 loss: 1.9312982559204102
Batch 63/64 loss: 1.6589784622192383
Batch 64/64 loss: -1.4936037063598633
Epoch 377  Train loss: 1.8890062556547278  Val loss: 1.4716578218125806
Epoch 378
-------------------------------
Batch 1/64 loss: 1.731490135192871
Batch 2/64 loss: 2.8213701248168945
Batch 3/64 loss: 1.6760764122009277
Batch 4/64 loss: 1.6417579650878906
Batch 5/64 loss: 1.6116671562194824
Batch 6/64 loss: 1.836474895477295
Batch 7/64 loss: 1.6860556602478027
Batch 8/64 loss: 1.6889853477478027
Batch 9/64 loss: 2.108656883239746
Batch 10/64 loss: 1.747213363647461
Batch 11/64 loss: 1.9200806617736816
Batch 12/64 loss: 1.6571102142333984
Batch 13/64 loss: 1.6972570419311523
Batch 14/64 loss: 2.975501537322998
Batch 15/64 loss: 1.9020957946777344
Batch 16/64 loss: 1.7832236289978027
Batch 17/64 loss: 1.744920253753662
Batch 18/64 loss: 1.7978978157043457
Batch 19/64 loss: 3.9146299362182617
Batch 20/64 loss: 1.6148309707641602
Batch 21/64 loss: 1.9469351768493652
Batch 22/64 loss: 1.7720189094543457
Batch 23/64 loss: 1.6851906776428223
Batch 24/64 loss: 2.147340774536133
Batch 25/64 loss: 1.6865582466125488
Batch 26/64 loss: 1.7104573249816895
Batch 27/64 loss: 1.65720796585083
Batch 28/64 loss: 1.7252001762390137
Batch 29/64 loss: 5.105729579925537
Batch 30/64 loss: 2.986055374145508
Batch 31/64 loss: 1.9023423194885254
Batch 32/64 loss: 2.092283248901367
Batch 33/64 loss: 2.2981414794921875
Batch 34/64 loss: 2.025822639465332
Batch 35/64 loss: 1.760847568511963
Batch 36/64 loss: 1.856247901916504
Batch 37/64 loss: 1.7796945571899414
Batch 38/64 loss: 1.8301949501037598
Batch 39/64 loss: 1.9226980209350586
Batch 40/64 loss: 5.927806854248047
Batch 41/64 loss: 1.9454569816589355
Batch 42/64 loss: 1.8809704780578613
Batch 43/64 loss: 1.997084617614746
Batch 44/64 loss: 1.9586148262023926
Batch 45/64 loss: 1.9518890380859375
Batch 46/64 loss: 2.796131134033203
Batch 47/64 loss: 2.052669048309326
Batch 48/64 loss: 2.005922794342041
Batch 49/64 loss: 2.0224180221557617
Batch 50/64 loss: 2.093705654144287
Batch 51/64 loss: 2.0593180656433105
Batch 52/64 loss: 1.9401941299438477
Batch 53/64 loss: 2.0229763984680176
Batch 54/64 loss: 2.475003242492676
Batch 55/64 loss: 2.6173534393310547
Batch 56/64 loss: 1.9199252128601074
Batch 57/64 loss: 3.0484771728515625
Batch 58/64 loss: 2.749556541442871
Batch 59/64 loss: 2.204329013824463
Batch 60/64 loss: 1.7397394180297852
Batch 61/64 loss: 1.765955924987793
Batch 62/64 loss: 1.8120079040527344
Batch 63/64 loss: 1.8796467781066895
Batch 64/64 loss: -1.6245269775390625
Epoch 378  Train loss: 2.0877963944977407  Val loss: 1.750577454714431
Epoch 379
-------------------------------
Batch 1/64 loss: 1.8554949760437012
Batch 2/64 loss: 1.9117212295532227
Batch 3/64 loss: 1.8942975997924805
Batch 4/64 loss: 2.9956679344177246
Batch 5/64 loss: 2.008068084716797
Batch 6/64 loss: 1.8099403381347656
Batch 7/64 loss: 4.153971195220947
Batch 8/64 loss: 1.9286308288574219
Batch 9/64 loss: 2.0036840438842773
Batch 10/64 loss: 1.7218213081359863
Batch 11/64 loss: 1.7532258033752441
Batch 12/64 loss: 1.7347092628479004
Batch 13/64 loss: 1.701246738433838
Batch 14/64 loss: 2.4356093406677246
Batch 15/64 loss: 1.9157981872558594
Batch 16/64 loss: 1.7720608711242676
Batch 17/64 loss: 1.9802370071411133
Batch 18/64 loss: 2.053894519805908
Batch 19/64 loss: 1.681565761566162
Batch 20/64 loss: 1.6820902824401855
Batch 21/64 loss: 1.9462170600891113
Batch 22/64 loss: 2.7758522033691406
Batch 23/64 loss: 2.4480490684509277
Batch 24/64 loss: 1.792595386505127
Batch 25/64 loss: 1.8070907592773438
Batch 26/64 loss: 2.4795212745666504
Batch 27/64 loss: 1.9333853721618652
Batch 28/64 loss: 1.9639496803283691
Batch 29/64 loss: 1.9699535369873047
Batch 30/64 loss: 1.830787181854248
Batch 31/64 loss: 1.9656982421875
Batch 32/64 loss: 1.7997212409973145
Batch 33/64 loss: 1.7564802169799805
Batch 34/64 loss: 1.7499380111694336
Batch 35/64 loss: 2.0093512535095215
Batch 36/64 loss: 1.8622784614562988
Batch 37/64 loss: 1.8156466484069824
Batch 38/64 loss: 1.707669734954834
Batch 39/64 loss: 3.3035435676574707
Batch 40/64 loss: 1.8048615455627441
Batch 41/64 loss: 4.953750133514404
Batch 42/64 loss: 1.6987652778625488
Batch 43/64 loss: 1.6863789558410645
Batch 44/64 loss: 1.787679672241211
Batch 45/64 loss: 1.8923301696777344
Batch 46/64 loss: 2.010634422302246
Batch 47/64 loss: 1.7532901763916016
Batch 48/64 loss: 4.554787635803223
Batch 49/64 loss: 1.8411445617675781
Batch 50/64 loss: 2.415769577026367
Batch 51/64 loss: 1.82004976272583
Batch 52/64 loss: 1.7260942459106445
Batch 53/64 loss: 2.0727009773254395
Batch 54/64 loss: 1.6816625595092773
Batch 55/64 loss: 1.7413549423217773
Batch 56/64 loss: 1.8908839225769043
Batch 57/64 loss: 1.9105749130249023
Batch 58/64 loss: 2.438387870788574
Batch 59/64 loss: 1.7744650840759277
Batch 60/64 loss: 1.8754549026489258
Batch 61/64 loss: 1.7008261680603027
Batch 62/64 loss: 1.8559837341308594
Batch 63/64 loss: 1.911078929901123
Batch 64/64 loss: -1.326704978942871
Epoch 379  Train loss: 2.034750519546808  Val loss: 1.6380082815373476
Epoch 380
-------------------------------
Batch 1/64 loss: 1.827986717224121
Batch 2/64 loss: 1.7839345932006836
Batch 3/64 loss: 1.7513227462768555
Batch 4/64 loss: 1.7534174919128418
Batch 5/64 loss: 1.7484040260314941
Batch 6/64 loss: 1.855480670928955
Batch 7/64 loss: 1.875636100769043
Batch 8/64 loss: 1.758080005645752
Batch 9/64 loss: 1.9048995971679688
Batch 10/64 loss: 1.6975998878479004
Batch 11/64 loss: 4.366769313812256
Batch 12/64 loss: 1.7470369338989258
Batch 13/64 loss: 1.6755266189575195
Batch 14/64 loss: 1.7777457237243652
Batch 15/64 loss: 1.836622714996338
Batch 16/64 loss: 1.7270278930664062
Batch 17/64 loss: 1.8015270233154297
Batch 18/64 loss: 2.0066866874694824
Batch 19/64 loss: 1.9141674041748047
Batch 20/64 loss: 1.6937499046325684
Batch 21/64 loss: 1.8471102714538574
Batch 22/64 loss: 2.1252574920654297
Batch 23/64 loss: 1.7284927368164062
Batch 24/64 loss: 4.678962230682373
Batch 25/64 loss: 4.2040791511535645
Batch 26/64 loss: 2.6087985038757324
Batch 27/64 loss: 1.961562156677246
Batch 28/64 loss: 1.7660441398620605
Batch 29/64 loss: 1.9396562576293945
Batch 30/64 loss: 1.7962441444396973
Batch 31/64 loss: 2.1505279541015625
Batch 32/64 loss: 1.841609001159668
Batch 33/64 loss: 1.6883597373962402
Batch 34/64 loss: 1.7467355728149414
Batch 35/64 loss: 2.5512328147888184
Batch 36/64 loss: 1.6260757446289062
Batch 37/64 loss: 1.6692557334899902
Batch 38/64 loss: 1.9517288208007812
Batch 39/64 loss: 1.7486686706542969
Batch 40/64 loss: 1.829906940460205
Batch 41/64 loss: 2.0100998878479004
Batch 42/64 loss: 1.684621810913086
Batch 43/64 loss: 1.5996356010437012
Batch 44/64 loss: 2.8324151039123535
Batch 45/64 loss: 1.647512435913086
Batch 46/64 loss: 1.696497917175293
Batch 47/64 loss: 1.7228317260742188
Batch 48/64 loss: 1.72877836227417
Batch 49/64 loss: 1.777601718902588
Batch 50/64 loss: 1.7251100540161133
Batch 51/64 loss: 2.4506211280822754
Batch 52/64 loss: 1.8537287712097168
Batch 53/64 loss: 1.8843140602111816
Batch 54/64 loss: 1.8639249801635742
Batch 55/64 loss: 1.9576935768127441
Batch 56/64 loss: 1.7590594291687012
Batch 57/64 loss: 1.7591495513916016
Batch 58/64 loss: 2.9732160568237305
Batch 59/64 loss: 1.9878501892089844
Batch 60/64 loss: 1.753983497619629
Batch 61/64 loss: 1.8955097198486328
Batch 62/64 loss: 1.7268929481506348
Batch 63/64 loss: 1.9497771263122559
Batch 64/64 loss: -1.0652532577514648
Epoch 380  Train loss: 1.967150052388509  Val loss: 1.499438020371899
Epoch 381
-------------------------------
Batch 1/64 loss: 1.750960350036621
Batch 2/64 loss: 1.8527326583862305
Batch 3/64 loss: 1.9538698196411133
Batch 4/64 loss: 1.8555192947387695
Batch 5/64 loss: 1.6425056457519531
Batch 6/64 loss: 1.651604175567627
Batch 7/64 loss: 1.8258461952209473
Batch 8/64 loss: 1.8330812454223633
Batch 9/64 loss: 1.7550992965698242
Batch 10/64 loss: 1.706758975982666
Batch 11/64 loss: 2.0001940727233887
Batch 12/64 loss: 2.09498929977417
Batch 13/64 loss: 1.8357019424438477
Batch 14/64 loss: 1.7040295600891113
Batch 15/64 loss: 1.93208646774292
Batch 16/64 loss: 2.328145980834961
Batch 17/64 loss: 1.956965446472168
Batch 18/64 loss: 5.580573081970215
Batch 19/64 loss: 1.9683141708374023
Batch 20/64 loss: 1.7612080574035645
Batch 21/64 loss: 1.800185203552246
Batch 22/64 loss: 1.7361578941345215
Batch 23/64 loss: 1.7258224487304688
Batch 24/64 loss: 1.895216941833496
Batch 25/64 loss: 3.615027904510498
Batch 26/64 loss: 1.7502775192260742
Batch 27/64 loss: 1.7195587158203125
Batch 28/64 loss: 3.7526235580444336
Batch 29/64 loss: 1.654252529144287
Batch 30/64 loss: 1.7819018363952637
Batch 31/64 loss: 1.650547981262207
Batch 32/64 loss: 1.6642255783081055
Batch 33/64 loss: 1.6513500213623047
Batch 34/64 loss: 1.7745661735534668
Batch 35/64 loss: 1.7067508697509766
Batch 36/64 loss: 1.684305191040039
Batch 37/64 loss: 1.6395673751831055
Batch 38/64 loss: 1.70521879196167
Batch 39/64 loss: 2.3057894706726074
Batch 40/64 loss: 1.7996530532836914
Batch 41/64 loss: 1.7646808624267578
Batch 42/64 loss: 2.3044357299804688
Batch 43/64 loss: 1.8737173080444336
Batch 44/64 loss: 1.6200165748596191
Batch 45/64 loss: 1.7719521522521973
Batch 46/64 loss: 4.998928070068359
Batch 47/64 loss: 1.8248863220214844
Batch 48/64 loss: 1.6363329887390137
Batch 49/64 loss: 1.965071678161621
Batch 50/64 loss: 1.7576017379760742
Batch 51/64 loss: 1.8324003219604492
Batch 52/64 loss: 1.720895767211914
Batch 53/64 loss: 1.7214655876159668
Batch 54/64 loss: 1.7005186080932617
Batch 55/64 loss: 1.7933268547058105
Batch 56/64 loss: 1.9483485221862793
Batch 57/64 loss: 2.0207529067993164
Batch 58/64 loss: 1.7009854316711426
Batch 59/64 loss: 1.7369985580444336
Batch 60/64 loss: 1.654891014099121
Batch 61/64 loss: 1.8120121955871582
Batch 62/64 loss: 1.7239155769348145
Batch 63/64 loss: 1.7975029945373535
Batch 64/64 loss: -1.7132291793823242
Epoch 381  Train loss: 1.935684716467764  Val loss: 1.4623319881478536
Epoch 382
-------------------------------
Batch 1/64 loss: 2.0728445053100586
Batch 2/64 loss: 2.692166805267334
Batch 3/64 loss: 1.780959129333496
Batch 4/64 loss: 1.6908903121948242
Batch 5/64 loss: 1.6481266021728516
Batch 6/64 loss: 1.7245774269104004
Batch 7/64 loss: 1.7794122695922852
Batch 8/64 loss: 1.6074647903442383
Batch 9/64 loss: 1.6945624351501465
Batch 10/64 loss: 2.9699268341064453
Batch 11/64 loss: 1.8102116584777832
Batch 12/64 loss: 1.9005804061889648
Batch 13/64 loss: 1.9219112396240234
Batch 14/64 loss: 1.8714756965637207
Batch 15/64 loss: 1.8120174407958984
Batch 16/64 loss: 1.7188920974731445
Batch 17/64 loss: 2.869964599609375
Batch 18/64 loss: 1.7144250869750977
Batch 19/64 loss: 1.8856267929077148
Batch 20/64 loss: 1.7106389999389648
Batch 21/64 loss: 1.7029743194580078
Batch 22/64 loss: 1.797459602355957
Batch 23/64 loss: 1.7581725120544434
Batch 24/64 loss: 1.9413905143737793
Batch 25/64 loss: 1.7823247909545898
Batch 26/64 loss: 6.907962799072266
Batch 27/64 loss: 1.786180019378662
Batch 28/64 loss: 2.0362234115600586
Batch 29/64 loss: 1.8057737350463867
Batch 30/64 loss: 1.9264841079711914
Batch 31/64 loss: 1.7111725807189941
Batch 32/64 loss: 3.8615989685058594
Batch 33/64 loss: 1.6977276802062988
Batch 34/64 loss: 1.7167572975158691
Batch 35/64 loss: 1.9656286239624023
Batch 36/64 loss: 1.7022809982299805
Batch 37/64 loss: 1.7479920387268066
Batch 38/64 loss: 1.683824062347412
Batch 39/64 loss: 1.7877044677734375
Batch 40/64 loss: 1.6795330047607422
Batch 41/64 loss: 1.826024055480957
Batch 42/64 loss: 1.7265958786010742
Batch 43/64 loss: 1.678551197052002
Batch 44/64 loss: 1.6835365295410156
Batch 45/64 loss: 1.8772807121276855
Batch 46/64 loss: 1.7428827285766602
Batch 47/64 loss: 1.744344711303711
Batch 48/64 loss: 1.9384145736694336
Batch 49/64 loss: 1.730299949645996
Batch 50/64 loss: 1.7909083366394043
Batch 51/64 loss: 1.723404884338379
Batch 52/64 loss: 1.720472812652588
Batch 53/64 loss: 1.8484210968017578
Batch 54/64 loss: 1.7759928703308105
Batch 55/64 loss: 2.389479637145996
Batch 56/64 loss: 2.2171835899353027
Batch 57/64 loss: 1.8086662292480469
Batch 58/64 loss: 1.7610955238342285
Batch 59/64 loss: 2.106398105621338
Batch 60/64 loss: 1.948960304260254
Batch 61/64 loss: 1.987278938293457
Batch 62/64 loss: 1.8016786575317383
Batch 63/64 loss: 1.8467392921447754
Batch 64/64 loss: -1.769200325012207
Epoch 382  Train loss: 1.9329184476067038  Val loss: 1.5472003897440803
Epoch 383
-------------------------------
Batch 1/64 loss: 1.724778175354004
Batch 2/64 loss: 1.7107458114624023
Batch 3/64 loss: 1.8189811706542969
Batch 4/64 loss: 1.7573223114013672
Batch 5/64 loss: 2.1218924522399902
Batch 6/64 loss: 1.9105825424194336
Batch 7/64 loss: 1.7156562805175781
Batch 8/64 loss: 1.7716798782348633
Batch 9/64 loss: 1.8527107238769531
Batch 10/64 loss: 1.647000789642334
Batch 11/64 loss: 2.220334529876709
Batch 12/64 loss: 1.7502245903015137
Batch 13/64 loss: 1.6728630065917969
Batch 14/64 loss: 1.9190988540649414
Batch 15/64 loss: 1.8134632110595703
Batch 16/64 loss: 1.6908378601074219
Batch 17/64 loss: 1.6472949981689453
Batch 18/64 loss: 1.755518913269043
Batch 19/64 loss: 1.707862377166748
Batch 20/64 loss: 1.716853141784668
Batch 21/64 loss: 1.7963852882385254
Batch 22/64 loss: 2.689866542816162
Batch 23/64 loss: 1.6579890251159668
Batch 24/64 loss: 1.817267894744873
Batch 25/64 loss: 1.762965202331543
Batch 26/64 loss: 1.6297683715820312
Batch 27/64 loss: 2.063833236694336
Batch 28/64 loss: 1.52215576171875
Batch 29/64 loss: 4.141101360321045
Batch 30/64 loss: 1.8595685958862305
Batch 31/64 loss: 1.9736137390136719
Batch 32/64 loss: 1.7381339073181152
Batch 33/64 loss: 1.7257952690124512
Batch 34/64 loss: 1.6964678764343262
Batch 35/64 loss: 1.6887173652648926
Batch 36/64 loss: 3.1011295318603516
Batch 37/64 loss: 1.762253761291504
Batch 38/64 loss: 1.8123364448547363
Batch 39/64 loss: 1.8123116493225098
Batch 40/64 loss: 1.7665257453918457
Batch 41/64 loss: 2.79020357131958
Batch 42/64 loss: 2.0183815956115723
Batch 43/64 loss: 1.9835996627807617
Batch 44/64 loss: 3.7768068313598633
Batch 45/64 loss: 1.9171018600463867
Batch 46/64 loss: 2.080415725708008
Batch 47/64 loss: 2.5398998260498047
Batch 48/64 loss: 3.188632011413574
Batch 49/64 loss: 1.926656723022461
Batch 50/64 loss: 5.216091632843018
Batch 51/64 loss: 2.38816499710083
Batch 52/64 loss: 2.0501861572265625
Batch 53/64 loss: 4.183960914611816
Batch 54/64 loss: 2.3978590965270996
Batch 55/64 loss: 2.234574317932129
Batch 56/64 loss: 2.184964179992676
Batch 57/64 loss: 2.554853916168213
Batch 58/64 loss: 2.238650321960449
Batch 59/64 loss: 3.13680362701416
Batch 60/64 loss: 2.2631678581237793
Batch 61/64 loss: 2.003814220428467
Batch 62/64 loss: 2.060380458831787
Batch 63/64 loss: 2.5970940589904785
Batch 64/64 loss: -0.06685829162597656
Epoch 383  Train loss: 2.1274667926863127  Val loss: 2.1240958446489575
Epoch 384
-------------------------------
Batch 1/64 loss: 2.200252056121826
Batch 2/64 loss: 2.2071709632873535
Batch 3/64 loss: 3.915572166442871
Batch 4/64 loss: 2.4616856575012207
Batch 5/64 loss: 2.1878762245178223
Batch 6/64 loss: 1.985445499420166
Batch 7/64 loss: 3.0201563835144043
Batch 8/64 loss: 1.957578182220459
Batch 9/64 loss: 1.8390841484069824
Batch 10/64 loss: 2.365391731262207
Batch 11/64 loss: 2.2885079383850098
Batch 12/64 loss: 3.5431642532348633
Batch 13/64 loss: 2.385411262512207
Batch 14/64 loss: 1.9592084884643555
Batch 15/64 loss: 2.0129637718200684
Batch 16/64 loss: 1.9675378799438477
Batch 17/64 loss: 2.3564019203186035
Batch 18/64 loss: 2.423250198364258
Batch 19/64 loss: 1.9075980186462402
Batch 20/64 loss: 2.3695755004882812
Batch 21/64 loss: 1.7799630165100098
Batch 22/64 loss: 4.60999870300293
Batch 23/64 loss: 2.020538806915283
Batch 24/64 loss: 2.4747557640075684
Batch 25/64 loss: 2.014036178588867
Batch 26/64 loss: 1.8157238960266113
Batch 27/64 loss: 2.2864890098571777
Batch 28/64 loss: 2.0740647315979004
Batch 29/64 loss: 1.9146180152893066
Batch 30/64 loss: 2.4223456382751465
Batch 31/64 loss: 2.078090190887451
Batch 32/64 loss: 2.2415099143981934
Batch 33/64 loss: 2.2812962532043457
Batch 34/64 loss: 2.0197315216064453
Batch 35/64 loss: 1.9685802459716797
Batch 36/64 loss: 2.442354679107666
Batch 37/64 loss: 2.1157846450805664
Batch 38/64 loss: 2.049773693084717
Batch 39/64 loss: 1.8969497680664062
Batch 40/64 loss: 1.839322566986084
Batch 41/64 loss: 2.327983856201172
Batch 42/64 loss: 4.880331516265869
Batch 43/64 loss: 4.256662845611572
Batch 44/64 loss: 1.924093246459961
Batch 45/64 loss: 1.8557591438293457
Batch 46/64 loss: 2.5597567558288574
Batch 47/64 loss: 2.0909643173217773
Batch 48/64 loss: 2.2660140991210938
Batch 49/64 loss: 2.137638568878174
Batch 50/64 loss: 2.0238571166992188
Batch 51/64 loss: 1.9760122299194336
Batch 52/64 loss: 1.8996367454528809
Batch 53/64 loss: 2.590468406677246
Batch 54/64 loss: 2.556704521179199
Batch 55/64 loss: 1.8146843910217285
Batch 56/64 loss: 2.975491523742676
Batch 57/64 loss: 1.9781618118286133
Batch 58/64 loss: 2.1215996742248535
Batch 59/64 loss: 1.9005637168884277
Batch 60/64 loss: 2.503389358520508
Batch 61/64 loss: 1.8003201484680176
Batch 62/64 loss: 1.7071495056152344
Batch 63/64 loss: 2.1854195594787598
Batch 64/64 loss: -1.434138298034668
Epoch 384  Train loss: 2.273832452063467  Val loss: 1.6701496163594354
Epoch 385
-------------------------------
Batch 1/64 loss: 2.814732074737549
Batch 2/64 loss: 1.7649760246276855
Batch 3/64 loss: 4.227881908416748
Batch 4/64 loss: 1.84904146194458
Batch 5/64 loss: 2.3347058296203613
Batch 6/64 loss: 1.7593059539794922
Batch 7/64 loss: 2.9046568870544434
Batch 8/64 loss: 1.881615161895752
Batch 9/64 loss: 4.223144054412842
Batch 10/64 loss: 1.7290067672729492
Batch 11/64 loss: 1.9183907508850098
Batch 12/64 loss: 1.7529120445251465
Batch 13/64 loss: 1.8666772842407227
Batch 14/64 loss: 1.9462132453918457
Batch 15/64 loss: 3.2050700187683105
Batch 16/64 loss: 2.716114044189453
Batch 17/64 loss: 2.144258975982666
Batch 18/64 loss: 2.415924072265625
Batch 19/64 loss: 1.901979923248291
Batch 20/64 loss: 2.4004712104797363
Batch 21/64 loss: 1.999000072479248
Batch 22/64 loss: 2.106903076171875
Batch 23/64 loss: 1.9554052352905273
Batch 24/64 loss: 1.7680020332336426
Batch 25/64 loss: 1.7680954933166504
Batch 26/64 loss: 5.221390247344971
Batch 27/64 loss: 1.8336129188537598
Batch 28/64 loss: 2.6546554565429688
Batch 29/64 loss: 2.014641284942627
Batch 30/64 loss: 1.7100930213928223
Batch 31/64 loss: 1.9601984024047852
Batch 32/64 loss: 1.7358441352844238
Batch 33/64 loss: 1.9178261756896973
Batch 34/64 loss: 1.8851971626281738
Batch 35/64 loss: 1.9876961708068848
Batch 36/64 loss: 1.8212175369262695
Batch 37/64 loss: 2.064199924468994
Batch 38/64 loss: 1.8282976150512695
Batch 39/64 loss: 1.8741827011108398
Batch 40/64 loss: 1.8978495597839355
Batch 41/64 loss: 1.7741332054138184
Batch 42/64 loss: 2.122105598449707
Batch 43/64 loss: 2.485517978668213
Batch 44/64 loss: 2.0580644607543945
Batch 45/64 loss: 1.7713594436645508
Batch 46/64 loss: 2.1029248237609863
Batch 47/64 loss: 1.6872782707214355
Batch 48/64 loss: 2.325289726257324
Batch 49/64 loss: 1.6652922630310059
Batch 50/64 loss: 1.9163708686828613
Batch 51/64 loss: 2.4465136528015137
Batch 52/64 loss: 1.9231901168823242
Batch 53/64 loss: 1.828134536743164
Batch 54/64 loss: 1.725752830505371
Batch 55/64 loss: 1.8776774406433105
Batch 56/64 loss: 1.6622614860534668
Batch 57/64 loss: 2.034605026245117
Batch 58/64 loss: 1.9813423156738281
Batch 59/64 loss: 2.442760467529297
Batch 60/64 loss: 1.6764826774597168
Batch 61/64 loss: 1.7830309867858887
Batch 62/64 loss: 1.8272695541381836
Batch 63/64 loss: 1.9497261047363281
Batch 64/64 loss: -1.7885684967041016
Epoch 385  Train loss: 2.09391440597235  Val loss: 1.6325189780533518
Epoch 386
-------------------------------
Batch 1/64 loss: 2.3638558387756348
Batch 2/64 loss: 1.7127351760864258
Batch 3/64 loss: 1.812248706817627
Batch 4/64 loss: 1.683847427368164
Batch 5/64 loss: 1.7465801239013672
Batch 6/64 loss: 2.3255653381347656
Batch 7/64 loss: 1.694967269897461
Batch 8/64 loss: 2.106834888458252
Batch 9/64 loss: 1.752302646636963
Batch 10/64 loss: 1.718606948852539
Batch 11/64 loss: 1.8381919860839844
Batch 12/64 loss: 1.8196287155151367
Batch 13/64 loss: 1.8382248878479004
Batch 14/64 loss: 1.7237205505371094
Batch 15/64 loss: 1.9383602142333984
Batch 16/64 loss: 1.8995285034179688
Batch 17/64 loss: 1.7361726760864258
Batch 18/64 loss: 2.698577880859375
Batch 19/64 loss: 1.819575309753418
Batch 20/64 loss: 4.214634418487549
Batch 21/64 loss: 1.7768182754516602
Batch 22/64 loss: 1.965747356414795
Batch 23/64 loss: 1.7521004676818848
Batch 24/64 loss: 2.124972343444824
Batch 25/64 loss: 1.742629051208496
Batch 26/64 loss: 1.77327299118042
Batch 27/64 loss: 1.7573442459106445
Batch 28/64 loss: 1.9159417152404785
Batch 29/64 loss: 2.438056468963623
Batch 30/64 loss: 2.0603995323181152
Batch 31/64 loss: 1.9414663314819336
Batch 32/64 loss: 1.9730262756347656
Batch 33/64 loss: 1.9723577499389648
Batch 34/64 loss: 1.7712998390197754
Batch 35/64 loss: 1.8788442611694336
Batch 36/64 loss: 2.0454797744750977
Batch 37/64 loss: 1.8218164443969727
Batch 38/64 loss: 2.4295454025268555
Batch 39/64 loss: 1.6633453369140625
Batch 40/64 loss: 2.1577939987182617
Batch 41/64 loss: 1.8797268867492676
Batch 42/64 loss: 1.8626184463500977
Batch 43/64 loss: 1.7722840309143066
Batch 44/64 loss: 2.018980026245117
Batch 45/64 loss: 1.694417953491211
Batch 46/64 loss: 1.6471819877624512
Batch 47/64 loss: 1.9280753135681152
Batch 48/64 loss: 1.8783073425292969
Batch 49/64 loss: 1.8037309646606445
Batch 50/64 loss: 1.9993534088134766
Batch 51/64 loss: 1.7821521759033203
Batch 52/64 loss: 2.0632786750793457
Batch 53/64 loss: 1.836141586303711
Batch 54/64 loss: 1.799476146697998
Batch 55/64 loss: 1.6769022941589355
Batch 56/64 loss: 2.9718732833862305
Batch 57/64 loss: 1.822556972503662
Batch 58/64 loss: 2.046259880065918
Batch 59/64 loss: 4.655044078826904
Batch 60/64 loss: 1.6600093841552734
Batch 61/64 loss: 3.1485724449157715
Batch 62/64 loss: 1.8475098609924316
Batch 63/64 loss: 3.794182777404785
Batch 64/64 loss: -1.4628610610961914
Epoch 386  Train loss: 2.0062416862039005  Val loss: 1.5143346622637457
Epoch 387
-------------------------------
Batch 1/64 loss: 1.869248390197754
Batch 2/64 loss: 2.234975814819336
Batch 3/64 loss: 1.6984176635742188
Batch 4/64 loss: 1.7445058822631836
Batch 5/64 loss: 1.7956371307373047
Batch 6/64 loss: 1.6782045364379883
Batch 7/64 loss: 1.8048768043518066
Batch 8/64 loss: 1.8078017234802246
Batch 9/64 loss: 1.7820348739624023
Batch 10/64 loss: 1.8679914474487305
Batch 11/64 loss: 1.6414790153503418
Batch 12/64 loss: 1.6430134773254395
Batch 13/64 loss: 1.6829028129577637
Batch 14/64 loss: 1.6888904571533203
Batch 15/64 loss: 1.8481659889221191
Batch 16/64 loss: 1.8556671142578125
Batch 17/64 loss: 1.6799139976501465
Batch 18/64 loss: 2.0277938842773438
Batch 19/64 loss: 1.6774258613586426
Batch 20/64 loss: 1.6785740852355957
Batch 21/64 loss: 3.4933338165283203
Batch 22/64 loss: 1.657559871673584
Batch 23/64 loss: 1.8818893432617188
Batch 24/64 loss: 2.758270740509033
Batch 25/64 loss: 2.3501181602478027
Batch 26/64 loss: 1.725168228149414
Batch 27/64 loss: 2.027986526489258
Batch 28/64 loss: 1.6453495025634766
Batch 29/64 loss: 1.780306339263916
Batch 30/64 loss: 1.935340404510498
Batch 31/64 loss: 1.7884478569030762
Batch 32/64 loss: 5.056553363800049
Batch 33/64 loss: 1.7560205459594727
Batch 34/64 loss: 1.6808018684387207
Batch 35/64 loss: 1.7522525787353516
Batch 36/64 loss: 1.8275022506713867
Batch 37/64 loss: 1.962911605834961
Batch 38/64 loss: 2.0623726844787598
Batch 39/64 loss: 1.9191007614135742
Batch 40/64 loss: 2.670567035675049
Batch 41/64 loss: 1.6493802070617676
Batch 42/64 loss: 1.9765996932983398
Batch 43/64 loss: 1.9774236679077148
Batch 44/64 loss: 1.907689094543457
Batch 45/64 loss: 1.8254494667053223
Batch 46/64 loss: 1.804609775543213
Batch 47/64 loss: 1.7013754844665527
Batch 48/64 loss: 1.9456210136413574
Batch 49/64 loss: 1.638498306274414
Batch 50/64 loss: 1.8632802963256836
Batch 51/64 loss: 1.7322406768798828
Batch 52/64 loss: 1.755699634552002
Batch 53/64 loss: 4.02813720703125
Batch 54/64 loss: 1.8127551078796387
Batch 55/64 loss: 2.293607711791992
Batch 56/64 loss: 1.814645767211914
Batch 57/64 loss: 1.7637677192687988
Batch 58/64 loss: 2.328518867492676
Batch 59/64 loss: 1.895705223083496
Batch 60/64 loss: 1.9055442810058594
Batch 61/64 loss: 1.692995548248291
Batch 62/64 loss: 1.9227800369262695
Batch 63/64 loss: 4.593092441558838
Batch 64/64 loss: -1.3020095825195312
Epoch 387  Train loss: 1.9810554429596545  Val loss: 1.5076063359316272
Epoch 388
-------------------------------
Batch 1/64 loss: 1.8741602897644043
Batch 2/64 loss: 1.893782138824463
Batch 3/64 loss: 1.687093734741211
Batch 4/64 loss: 1.6660428047180176
Batch 5/64 loss: 3.170027732849121
Batch 6/64 loss: 2.2961506843566895
Batch 7/64 loss: 1.589475154876709
Batch 8/64 loss: 1.9499411582946777
Batch 9/64 loss: 1.6633882522583008
Batch 10/64 loss: 1.7367949485778809
Batch 11/64 loss: 1.7444543838500977
Batch 12/64 loss: 1.7614784240722656
Batch 13/64 loss: 1.9160523414611816
Batch 14/64 loss: 1.6987323760986328
Batch 15/64 loss: 2.049748420715332
Batch 16/64 loss: 2.035182476043701
Batch 17/64 loss: 2.0971522331237793
Batch 18/64 loss: 1.7634882926940918
Batch 19/64 loss: 1.776681900024414
Batch 20/64 loss: 4.0671796798706055
Batch 21/64 loss: 1.7544760704040527
Batch 22/64 loss: 1.972663402557373
Batch 23/64 loss: 1.879554271697998
Batch 24/64 loss: 2.982903480529785
Batch 25/64 loss: 2.0220580101013184
Batch 26/64 loss: 1.63865327835083
Batch 27/64 loss: 2.240461826324463
Batch 28/64 loss: 1.7591314315795898
Batch 29/64 loss: 5.550908088684082
Batch 30/64 loss: 1.7888860702514648
Batch 31/64 loss: 1.8104166984558105
Batch 32/64 loss: 1.8632383346557617
Batch 33/64 loss: 1.7338056564331055
Batch 34/64 loss: 1.753377914428711
Batch 35/64 loss: 1.7406859397888184
Batch 36/64 loss: 1.6653294563293457
Batch 37/64 loss: 1.6604270935058594
Batch 38/64 loss: 2.0058064460754395
Batch 39/64 loss: 2.2590932846069336
Batch 40/64 loss: 1.8781390190124512
Batch 41/64 loss: 1.8420357704162598
Batch 42/64 loss: 1.7182888984680176
Batch 43/64 loss: 1.6635775566101074
Batch 44/64 loss: 3.219836711883545
Batch 45/64 loss: 1.6418356895446777
Batch 46/64 loss: 1.854914665222168
Batch 47/64 loss: 1.8105964660644531
Batch 48/64 loss: 1.8369922637939453
Batch 49/64 loss: 1.7360706329345703
Batch 50/64 loss: 1.8063735961914062
Batch 51/64 loss: 1.7970499992370605
Batch 52/64 loss: 1.6992650032043457
Batch 53/64 loss: 1.6886811256408691
Batch 54/64 loss: 1.6276040077209473
Batch 55/64 loss: 1.8524894714355469
Batch 56/64 loss: 1.6159553527832031
Batch 57/64 loss: 4.065530776977539
Batch 58/64 loss: 1.6876134872436523
Batch 59/64 loss: 1.9838504791259766
Batch 60/64 loss: 1.559126377105713
Batch 61/64 loss: 1.7347674369812012
Batch 62/64 loss: 1.735743522644043
Batch 63/64 loss: 1.9146122932434082
Batch 64/64 loss: -1.7208366394042969
Epoch 388  Train loss: 1.9639091342103248  Val loss: 1.5301785092173572
Epoch 389
-------------------------------
Batch 1/64 loss: 1.9346041679382324
Batch 2/64 loss: 1.991053581237793
Batch 3/64 loss: 1.6444716453552246
Batch 4/64 loss: 1.8213834762573242
Batch 5/64 loss: 1.6070313453674316
Batch 6/64 loss: 1.8805389404296875
Batch 7/64 loss: 1.6207804679870605
Batch 8/64 loss: 1.7788805961608887
Batch 9/64 loss: 1.6086511611938477
Batch 10/64 loss: 1.843893051147461
Batch 11/64 loss: 2.276632785797119
Batch 12/64 loss: 1.8205714225769043
Batch 13/64 loss: 1.8074440956115723
Batch 14/64 loss: 1.7323055267333984
Batch 15/64 loss: 2.722374439239502
Batch 16/64 loss: 4.152737617492676
Batch 17/64 loss: 2.8918771743774414
Batch 18/64 loss: 1.7690362930297852
Batch 19/64 loss: 1.833888053894043
Batch 20/64 loss: 1.6605849266052246
Batch 21/64 loss: 1.7443666458129883
Batch 22/64 loss: 1.6165108680725098
Batch 23/64 loss: 1.841390609741211
Batch 24/64 loss: 1.7882237434387207
Batch 25/64 loss: 1.7523951530456543
Batch 26/64 loss: 2.035466194152832
Batch 27/64 loss: 1.6514520645141602
Batch 28/64 loss: 1.6809239387512207
Batch 29/64 loss: 1.6481318473815918
Batch 30/64 loss: 1.7970056533813477
Batch 31/64 loss: 1.8962554931640625
Batch 32/64 loss: 1.797285556793213
Batch 33/64 loss: 1.7820796966552734
Batch 34/64 loss: 4.996035099029541
Batch 35/64 loss: 1.8055009841918945
Batch 36/64 loss: 1.8126201629638672
Batch 37/64 loss: 1.7206721305847168
Batch 38/64 loss: 1.6353020668029785
Batch 39/64 loss: 1.6617298126220703
Batch 40/64 loss: 1.8776884078979492
Batch 41/64 loss: 1.8904738426208496
Batch 42/64 loss: 1.6585750579833984
Batch 43/64 loss: 1.7332420349121094
Batch 44/64 loss: 1.7749757766723633
Batch 45/64 loss: 1.7675395011901855
Batch 46/64 loss: 2.955939292907715
Batch 47/64 loss: 1.8833060264587402
Batch 48/64 loss: 1.734642505645752
Batch 49/64 loss: 1.8241791725158691
Batch 50/64 loss: 1.7633872032165527
Batch 51/64 loss: 1.7778406143188477
Batch 52/64 loss: 1.5814542770385742
Batch 53/64 loss: 1.99261474609375
Batch 54/64 loss: 1.6563405990600586
Batch 55/64 loss: 1.6961393356323242
Batch 56/64 loss: 1.826209545135498
Batch 57/64 loss: 1.7045707702636719
Batch 58/64 loss: 1.736443042755127
Batch 59/64 loss: 2.3031387329101562
Batch 60/64 loss: 1.779444694519043
Batch 61/64 loss: 2.6634697914123535
Batch 62/64 loss: 3.920527935028076
Batch 63/64 loss: 1.8570117950439453
Batch 64/64 loss: -1.7930774688720703
Epoch 389  Train loss: 1.930610746495864  Val loss: 1.4627525749075454
Epoch 390
-------------------------------
Batch 1/64 loss: 1.6806540489196777
Batch 2/64 loss: 1.6855077743530273
Batch 3/64 loss: 1.8947882652282715
Batch 4/64 loss: 2.549717426300049
Batch 5/64 loss: 1.6085567474365234
Batch 6/64 loss: 4.687507152557373
Batch 7/64 loss: 1.7882647514343262
Batch 8/64 loss: 1.7631735801696777
Batch 9/64 loss: 1.6252408027648926
Batch 10/64 loss: 1.8483190536499023
Batch 11/64 loss: 1.6724858283996582
Batch 12/64 loss: 1.6993823051452637
Batch 13/64 loss: 2.0721988677978516
Batch 14/64 loss: 1.7352561950683594
Batch 15/64 loss: 1.717264175415039
Batch 16/64 loss: 1.6727056503295898
Batch 17/64 loss: 2.8556036949157715
Batch 18/64 loss: 1.6755585670471191
Batch 19/64 loss: 1.8145942687988281
Batch 20/64 loss: 1.9244251251220703
Batch 21/64 loss: 4.682492733001709
Batch 22/64 loss: 1.6049342155456543
Batch 23/64 loss: 1.784942626953125
Batch 24/64 loss: 1.6840977668762207
Batch 25/64 loss: 1.706441879272461
Batch 26/64 loss: 1.670778751373291
Batch 27/64 loss: 1.6401395797729492
Batch 28/64 loss: 1.7853569984436035
Batch 29/64 loss: 2.062112808227539
Batch 30/64 loss: 1.840489387512207
Batch 31/64 loss: 2.067999839782715
Batch 32/64 loss: 1.8253507614135742
Batch 33/64 loss: 1.6341605186462402
Batch 34/64 loss: 1.537431240081787
Batch 35/64 loss: 2.7926340103149414
Batch 36/64 loss: 3.80775785446167
Batch 37/64 loss: 1.8250737190246582
Batch 38/64 loss: 1.6803879737854004
Batch 39/64 loss: 1.688443660736084
Batch 40/64 loss: 1.8112444877624512
Batch 41/64 loss: 1.6456055641174316
Batch 42/64 loss: 1.7500176429748535
Batch 43/64 loss: 2.07395601272583
Batch 44/64 loss: 1.7940268516540527
Batch 45/64 loss: 1.6896476745605469
Batch 46/64 loss: 2.4131622314453125
Batch 47/64 loss: 1.5895352363586426
Batch 48/64 loss: 1.9117097854614258
Batch 49/64 loss: 1.8468732833862305
Batch 50/64 loss: 1.7560029029846191
Batch 51/64 loss: 1.810448169708252
Batch 52/64 loss: 2.0288753509521484
Batch 53/64 loss: 2.033759593963623
Batch 54/64 loss: 1.661731243133545
Batch 55/64 loss: 1.7467436790466309
Batch 56/64 loss: 2.1433377265930176
Batch 57/64 loss: 2.021310806274414
Batch 58/64 loss: 1.7014422416687012
Batch 59/64 loss: 1.7547545433044434
Batch 60/64 loss: 1.760256290435791
Batch 61/64 loss: 1.6569385528564453
Batch 62/64 loss: 1.716522216796875
Batch 63/64 loss: 1.769911289215088
Batch 64/64 loss: -1.4101457595825195
Epoch 390  Train loss: 1.9187832888434915  Val loss: 1.456991215342099
Epoch 391
-------------------------------
Batch 1/64 loss: 1.7067017555236816
Batch 2/64 loss: 1.8003740310668945
Batch 3/64 loss: 4.062432765960693
Batch 4/64 loss: 1.7445836067199707
Batch 5/64 loss: 1.6878747940063477
Batch 6/64 loss: 1.741572380065918
Batch 7/64 loss: 1.8428168296813965
Batch 8/64 loss: 2.010930061340332
Batch 9/64 loss: 1.8061881065368652
Batch 10/64 loss: 1.655336856842041
Batch 11/64 loss: 1.5945286750793457
Batch 12/64 loss: 4.573049068450928
Batch 13/64 loss: 2.56868314743042
Batch 14/64 loss: 1.6541147232055664
Batch 15/64 loss: 1.812075138092041
Batch 16/64 loss: 1.7438240051269531
Batch 17/64 loss: 1.8778553009033203
Batch 18/64 loss: 1.6350197792053223
Batch 19/64 loss: 1.7467732429504395
Batch 20/64 loss: 1.6033196449279785
Batch 21/64 loss: 1.6788945198059082
Batch 22/64 loss: 4.227801322937012
Batch 23/64 loss: 1.670264720916748
Batch 24/64 loss: 1.937293529510498
Batch 25/64 loss: 2.1035842895507812
Batch 26/64 loss: 2.2148561477661133
Batch 27/64 loss: 1.8901643753051758
Batch 28/64 loss: 1.8338546752929688
Batch 29/64 loss: 1.6148905754089355
Batch 30/64 loss: 1.7565088272094727
Batch 31/64 loss: 1.9616351127624512
Batch 32/64 loss: 1.8508539199829102
Batch 33/64 loss: 1.7313213348388672
Batch 34/64 loss: 1.7167158126831055
Batch 35/64 loss: 1.839406967163086
Batch 36/64 loss: 1.8475279808044434
Batch 37/64 loss: 2.0997071266174316
Batch 38/64 loss: 1.6517601013183594
Batch 39/64 loss: 1.698953628540039
Batch 40/64 loss: 1.72263765335083
Batch 41/64 loss: 1.8818397521972656
Batch 42/64 loss: 2.356842517852783
Batch 43/64 loss: 2.1006503105163574
Batch 44/64 loss: 1.9771366119384766
Batch 45/64 loss: 1.8706717491149902
Batch 46/64 loss: 1.8115200996398926
Batch 47/64 loss: 1.736931324005127
Batch 48/64 loss: 1.718017578125
Batch 49/64 loss: 1.8477988243103027
Batch 50/64 loss: 1.7400474548339844
Batch 51/64 loss: 3.326997756958008
Batch 52/64 loss: 1.903867244720459
Batch 53/64 loss: 1.8290705680847168
Batch 54/64 loss: 1.8468279838562012
Batch 55/64 loss: 1.7350564002990723
Batch 56/64 loss: 1.9640240669250488
Batch 57/64 loss: 2.423819065093994
Batch 58/64 loss: 1.7413840293884277
Batch 59/64 loss: 1.6861133575439453
Batch 60/64 loss: 3.0064139366149902
Batch 61/64 loss: 1.8370466232299805
Batch 62/64 loss: 1.785665512084961
Batch 63/64 loss: 1.8838872909545898
Batch 64/64 loss: -1.6907997131347656
Epoch 391  Train loss: 1.9554543813069662  Val loss: 1.4871702358075434
Epoch 392
-------------------------------
Batch 1/64 loss: 1.6775522232055664
Batch 2/64 loss: 1.6559758186340332
Batch 3/64 loss: 1.8363447189331055
Batch 4/64 loss: 1.747878074645996
Batch 5/64 loss: 1.7706379890441895
Batch 6/64 loss: 2.4840049743652344
Batch 7/64 loss: 1.8744282722473145
Batch 8/64 loss: 1.802511215209961
Batch 9/64 loss: 2.215425968170166
Batch 10/64 loss: 4.699991703033447
Batch 11/64 loss: 1.7718329429626465
Batch 12/64 loss: 1.7307024002075195
Batch 13/64 loss: 1.7477450370788574
Batch 14/64 loss: 1.8712410926818848
Batch 15/64 loss: 1.7013335227966309
Batch 16/64 loss: 1.7935576438903809
Batch 17/64 loss: 1.9585094451904297
Batch 18/64 loss: 1.760021686553955
Batch 19/64 loss: 1.6503572463989258
Batch 20/64 loss: 1.780318260192871
Batch 21/64 loss: 1.8083181381225586
Batch 22/64 loss: 1.6758222579956055
Batch 23/64 loss: 1.7098402976989746
Batch 24/64 loss: 1.8679389953613281
Batch 25/64 loss: 1.7413382530212402
Batch 26/64 loss: 2.7681002616882324
Batch 27/64 loss: 1.8118677139282227
Batch 28/64 loss: 2.491236686706543
Batch 29/64 loss: 3.8294482231140137
Batch 30/64 loss: 1.9068636894226074
Batch 31/64 loss: 1.696528434753418
Batch 32/64 loss: 1.99530029296875
Batch 33/64 loss: 1.7140183448791504
Batch 34/64 loss: 1.8033604621887207
Batch 35/64 loss: 1.7709484100341797
Batch 36/64 loss: 1.635749340057373
Batch 37/64 loss: 1.7738943099975586
Batch 38/64 loss: 2.647515296936035
Batch 39/64 loss: 1.7523341178894043
Batch 40/64 loss: 2.0676941871643066
Batch 41/64 loss: 1.93157958984375
Batch 42/64 loss: 1.6524004936218262
Batch 43/64 loss: 1.5992064476013184
Batch 44/64 loss: 1.8056001663208008
Batch 45/64 loss: 1.8044185638427734
Batch 46/64 loss: 1.63771390914917
Batch 47/64 loss: 1.6472549438476562
Batch 48/64 loss: 4.066559314727783
Batch 49/64 loss: 1.998812198638916
Batch 50/64 loss: 1.9259214401245117
Batch 51/64 loss: 1.7997260093688965
Batch 52/64 loss: 1.7597126960754395
Batch 53/64 loss: 1.850771427154541
Batch 54/64 loss: 2.416464328765869
Batch 55/64 loss: 1.736088752746582
Batch 56/64 loss: 1.8123259544372559
Batch 57/64 loss: 1.741623878479004
Batch 58/64 loss: 2.031607151031494
Batch 59/64 loss: 1.9926066398620605
Batch 60/64 loss: 1.6124916076660156
Batch 61/64 loss: 1.6694836616516113
Batch 62/64 loss: 2.0190558433532715
Batch 63/64 loss: 1.582000732421875
Batch 64/64 loss: -1.7785415649414062
Epoch 392  Train loss: 1.9256158043356504  Val loss: 1.4592072595026075
Epoch 393
-------------------------------
Batch 1/64 loss: 1.665844440460205
Batch 2/64 loss: 1.9757838249206543
Batch 3/64 loss: 1.6293611526489258
Batch 4/64 loss: 1.946528434753418
Batch 5/64 loss: 1.774430751800537
Batch 6/64 loss: 4.110559463500977
Batch 7/64 loss: 1.5960516929626465
Batch 8/64 loss: 2.585340976715088
Batch 9/64 loss: 1.662071704864502
Batch 10/64 loss: 1.6295833587646484
Batch 11/64 loss: 2.7088403701782227
Batch 12/64 loss: 1.7307100296020508
Batch 13/64 loss: 1.7193799018859863
Batch 14/64 loss: 2.042898178100586
Batch 15/64 loss: 1.785895824432373
Batch 16/64 loss: 2.7665247917175293
Batch 17/64 loss: 1.8679347038269043
Batch 18/64 loss: 1.7398676872253418
Batch 19/64 loss: 1.9182796478271484
Batch 20/64 loss: 1.7242546081542969
Batch 21/64 loss: 1.5959539413452148
Batch 22/64 loss: 1.7904281616210938
Batch 23/64 loss: 1.6184639930725098
Batch 24/64 loss: 1.7463922500610352
Batch 25/64 loss: 1.685689926147461
Batch 26/64 loss: 1.7881884574890137
Batch 27/64 loss: 1.6783990859985352
Batch 28/64 loss: 1.632260799407959
Batch 29/64 loss: 1.7717633247375488
Batch 30/64 loss: 1.6798930168151855
Batch 31/64 loss: 1.6971354484558105
Batch 32/64 loss: 1.6069674491882324
Batch 33/64 loss: 1.6627016067504883
Batch 34/64 loss: 1.8692283630371094
Batch 35/64 loss: 1.6499924659729004
Batch 36/64 loss: 1.6832218170166016
Batch 37/64 loss: 1.568037986755371
Batch 38/64 loss: 2.693081855773926
Batch 39/64 loss: 1.6470575332641602
Batch 40/64 loss: 1.6408376693725586
Batch 41/64 loss: 1.8131699562072754
Batch 42/64 loss: 1.6494030952453613
Batch 43/64 loss: 1.5815863609313965
Batch 44/64 loss: 2.398681163787842
Batch 45/64 loss: 1.6691913604736328
Batch 46/64 loss: 4.011368274688721
Batch 47/64 loss: 4.93404483795166
Batch 48/64 loss: 1.7523937225341797
Batch 49/64 loss: 1.7016777992248535
Batch 50/64 loss: 1.7434492111206055
Batch 51/64 loss: 1.871091365814209
Batch 52/64 loss: 1.7741694450378418
Batch 53/64 loss: 1.6570320129394531
Batch 54/64 loss: 1.9558486938476562
Batch 55/64 loss: 1.6872024536132812
Batch 56/64 loss: 1.7512836456298828
Batch 57/64 loss: 1.8104462623596191
Batch 58/64 loss: 2.0014829635620117
Batch 59/64 loss: 1.6014471054077148
Batch 60/64 loss: 1.776054859161377
Batch 61/64 loss: 1.7794547080993652
Batch 62/64 loss: 1.6654720306396484
Batch 63/64 loss: 1.7267098426818848
Batch 64/64 loss: -1.716568946838379
Epoch 393  Train loss: 1.8872324887443992  Val loss: 1.4499487205059667
Epoch 394
-------------------------------
Batch 1/64 loss: 1.6591768264770508
Batch 2/64 loss: 1.8081436157226562
Batch 3/64 loss: 1.80997896194458
Batch 4/64 loss: 1.7936396598815918
Batch 5/64 loss: 1.599447250366211
Batch 6/64 loss: 1.6794323921203613
Batch 7/64 loss: 1.7673053741455078
Batch 8/64 loss: 1.680006504058838
Batch 9/64 loss: 1.640693187713623
Batch 10/64 loss: 1.622683048248291
Batch 11/64 loss: 1.66023588180542
Batch 12/64 loss: 1.5624346733093262
Batch 13/64 loss: 1.7402644157409668
Batch 14/64 loss: 1.7740473747253418
Batch 15/64 loss: 4.63980770111084
Batch 16/64 loss: 2.032378673553467
Batch 17/64 loss: 4.154989719390869
Batch 18/64 loss: 1.73026704788208
Batch 19/64 loss: 1.858335018157959
Batch 20/64 loss: 1.727933406829834
Batch 21/64 loss: 2.0504512786865234
Batch 22/64 loss: 2.411220073699951
Batch 23/64 loss: 1.626208782196045
Batch 24/64 loss: 1.6217713356018066
Batch 25/64 loss: 1.7570438385009766
Batch 26/64 loss: 1.8049263954162598
Batch 27/64 loss: 1.8174400329589844
Batch 28/64 loss: 3.7440195083618164
Batch 29/64 loss: 1.7190337181091309
Batch 30/64 loss: 1.8029394149780273
Batch 31/64 loss: 1.7378077507019043
Batch 32/64 loss: 2.0961251258850098
Batch 33/64 loss: 1.7431364059448242
Batch 34/64 loss: 2.822364330291748
Batch 35/64 loss: 1.9419283866882324
Batch 36/64 loss: 1.8306078910827637
Batch 37/64 loss: 1.7935805320739746
Batch 38/64 loss: 1.8695769309997559
Batch 39/64 loss: 2.6205949783325195
Batch 40/64 loss: 1.6791558265686035
Batch 41/64 loss: 2.3345084190368652
Batch 42/64 loss: 1.7955269813537598
Batch 43/64 loss: 1.7496967315673828
Batch 44/64 loss: 2.079113483428955
Batch 45/64 loss: 1.9083871841430664
Batch 46/64 loss: 1.9387249946594238
Batch 47/64 loss: 2.100424289703369
Batch 48/64 loss: 1.9708032608032227
Batch 49/64 loss: 1.8630366325378418
Batch 50/64 loss: 1.8724102973937988
Batch 51/64 loss: 1.6613235473632812
Batch 52/64 loss: 1.893630027770996
Batch 53/64 loss: 1.7047972679138184
Batch 54/64 loss: 1.770503044128418
Batch 55/64 loss: 2.847489356994629
Batch 56/64 loss: 1.6301298141479492
Batch 57/64 loss: 1.7307391166687012
Batch 58/64 loss: 1.6092863082885742
Batch 59/64 loss: 1.8454012870788574
Batch 60/64 loss: 1.7041010856628418
Batch 61/64 loss: 1.7157325744628906
Batch 62/64 loss: 1.8455924987792969
Batch 63/64 loss: 1.818610668182373
Batch 64/64 loss: -1.717696189880371
Epoch 394  Train loss: 1.9220836078419405  Val loss: 1.4576420341570353
Epoch 395
-------------------------------
Batch 1/64 loss: 1.7084007263183594
Batch 2/64 loss: 4.752758026123047
Batch 3/64 loss: 1.9996423721313477
Batch 4/64 loss: 1.680978775024414
Batch 5/64 loss: 1.6982831954956055
Batch 6/64 loss: 1.9023594856262207
Batch 7/64 loss: 1.7290496826171875
Batch 8/64 loss: 1.8767156600952148
Batch 9/64 loss: 1.6580710411071777
Batch 10/64 loss: 1.9237117767333984
Batch 11/64 loss: 1.7583904266357422
Batch 12/64 loss: 1.7444214820861816
Batch 13/64 loss: 4.2846360206604
Batch 14/64 loss: 1.8181719779968262
Batch 15/64 loss: 1.7919926643371582
Batch 16/64 loss: 1.8910160064697266
Batch 17/64 loss: 1.8012561798095703
Batch 18/64 loss: 1.8152384757995605
Batch 19/64 loss: 1.7503271102905273
Batch 20/64 loss: 1.7688865661621094
Batch 21/64 loss: 1.8296399116516113
Batch 22/64 loss: 1.9861278533935547
Batch 23/64 loss: 1.8678851127624512
Batch 24/64 loss: 1.7588391304016113
Batch 25/64 loss: 1.7793364524841309
Batch 26/64 loss: 1.6023540496826172
Batch 27/64 loss: 1.844006061553955
Batch 28/64 loss: 2.764065742492676
Batch 29/64 loss: 1.6426687240600586
Batch 30/64 loss: 1.6929535865783691
Batch 31/64 loss: 2.399439811706543
Batch 32/64 loss: 1.6682424545288086
Batch 33/64 loss: 1.6219158172607422
Batch 34/64 loss: 1.679783821105957
Batch 35/64 loss: 3.846412181854248
Batch 36/64 loss: 1.7753734588623047
Batch 37/64 loss: 1.666006088256836
Batch 38/64 loss: 1.7305827140808105
Batch 39/64 loss: 2.8853440284729004
Batch 40/64 loss: 1.642702579498291
Batch 41/64 loss: 1.6261177062988281
Batch 42/64 loss: 1.7362146377563477
Batch 43/64 loss: 1.7539081573486328
Batch 44/64 loss: 1.6652154922485352
Batch 45/64 loss: 1.8596844673156738
Batch 46/64 loss: 1.8367705345153809
Batch 47/64 loss: 1.6118731498718262
Batch 48/64 loss: 1.8229427337646484
Batch 49/64 loss: 2.014986991882324
Batch 50/64 loss: 2.0560193061828613
Batch 51/64 loss: 1.6944985389709473
Batch 52/64 loss: 2.2353615760803223
Batch 53/64 loss: 1.537663459777832
Batch 54/64 loss: 1.984567642211914
Batch 55/64 loss: 1.796037197113037
Batch 56/64 loss: 1.727787971496582
Batch 57/64 loss: 1.8482232093811035
Batch 58/64 loss: 1.820594310760498
Batch 59/64 loss: 1.7282028198242188
Batch 60/64 loss: 1.9744148254394531
Batch 61/64 loss: 2.6376562118530273
Batch 62/64 loss: 1.7484450340270996
Batch 63/64 loss: 1.6578187942504883
Batch 64/64 loss: -1.1587200164794922
Epoch 395  Train loss: 1.9222580704034544  Val loss: 1.468441645304362
Epoch 396
-------------------------------
Batch 1/64 loss: 2.4138450622558594
Batch 2/64 loss: 1.7286548614501953
Batch 3/64 loss: 1.6613621711730957
Batch 4/64 loss: 1.7259612083435059
Batch 5/64 loss: 1.6912970542907715
Batch 6/64 loss: 1.6089463233947754
Batch 7/64 loss: 1.7115960121154785
Batch 8/64 loss: 2.0930404663085938
Batch 9/64 loss: 1.9096360206604004
Batch 10/64 loss: 1.7585296630859375
Batch 11/64 loss: 1.8301458358764648
Batch 12/64 loss: 1.8086366653442383
Batch 13/64 loss: 1.654036045074463
Batch 14/64 loss: 4.2984137535095215
Batch 15/64 loss: 1.6771678924560547
Batch 16/64 loss: 1.624800682067871
Batch 17/64 loss: 1.893378734588623
Batch 18/64 loss: 1.578277587890625
Batch 19/64 loss: 2.0870871543884277
Batch 20/64 loss: 1.625565528869629
Batch 21/64 loss: 1.90706205368042
Batch 22/64 loss: 1.5776829719543457
Batch 23/64 loss: 1.6565117835998535
Batch 24/64 loss: 1.7613162994384766
Batch 25/64 loss: 3.868800163269043
Batch 26/64 loss: 1.7836852073669434
Batch 27/64 loss: 1.6362156867980957
Batch 28/64 loss: 1.7490448951721191
Batch 29/64 loss: 1.601025104522705
Batch 30/64 loss: 1.7459697723388672
Batch 31/64 loss: 1.617772102355957
Batch 32/64 loss: 1.6617364883422852
Batch 33/64 loss: 2.0658578872680664
Batch 34/64 loss: 2.367982864379883
Batch 35/64 loss: 1.6990680694580078
Batch 36/64 loss: 1.9413275718688965
Batch 37/64 loss: 2.8176321983337402
Batch 38/64 loss: 1.6595940589904785
Batch 39/64 loss: 2.093400001525879
Batch 40/64 loss: 2.0445003509521484
Batch 41/64 loss: 2.061373710632324
Batch 42/64 loss: 2.264164924621582
Batch 43/64 loss: 1.743537425994873
Batch 44/64 loss: 1.6360440254211426
Batch 45/64 loss: 1.905217170715332
Batch 46/64 loss: 1.678908348083496
Batch 47/64 loss: 2.26816987991333
Batch 48/64 loss: 1.612168788909912
Batch 49/64 loss: 1.762953281402588
Batch 50/64 loss: 1.6786537170410156
Batch 51/64 loss: 1.5678038597106934
Batch 52/64 loss: 2.6140737533569336
Batch 53/64 loss: 1.7795038223266602
Batch 54/64 loss: 1.912229061126709
Batch 55/64 loss: 1.9180035591125488
Batch 56/64 loss: 1.9453282356262207
Batch 57/64 loss: 1.641209602355957
Batch 58/64 loss: 1.759805679321289
Batch 59/64 loss: 1.7532901763916016
Batch 60/64 loss: 1.840205192565918
Batch 61/64 loss: 4.91896915435791
Batch 62/64 loss: 1.5346941947937012
Batch 63/64 loss: 2.7900753021240234
Batch 64/64 loss: -1.6575632095336914
Epoch 396  Train loss: 1.9290945053100585  Val loss: 1.5244173266224026
Epoch 397
-------------------------------
Batch 1/64 loss: 1.9062271118164062
Batch 2/64 loss: 1.962562084197998
Batch 3/64 loss: 2.7382874488830566
Batch 4/64 loss: 1.8374881744384766
Batch 5/64 loss: 1.6754679679870605
Batch 6/64 loss: 1.694188117980957
Batch 7/64 loss: 1.660862922668457
Batch 8/64 loss: 3.041851043701172
Batch 9/64 loss: 1.911797046661377
Batch 10/64 loss: 1.6977777481079102
Batch 11/64 loss: 1.8610897064208984
Batch 12/64 loss: 1.638056755065918
Batch 13/64 loss: 2.1405882835388184
Batch 14/64 loss: 2.790498733520508
Batch 15/64 loss: 1.8145484924316406
Batch 16/64 loss: 1.8121047019958496
Batch 17/64 loss: 2.2545924186706543
Batch 18/64 loss: 1.8933959007263184
Batch 19/64 loss: 1.694587230682373
Batch 20/64 loss: 2.072567939758301
Batch 21/64 loss: 1.6582703590393066
Batch 22/64 loss: 2.0051093101501465
Batch 23/64 loss: 1.9865875244140625
Batch 24/64 loss: 1.8564033508300781
Batch 25/64 loss: 1.8232536315917969
Batch 26/64 loss: 1.9108061790466309
Batch 27/64 loss: 1.635641098022461
Batch 28/64 loss: 1.669360637664795
Batch 29/64 loss: 1.760730266571045
Batch 30/64 loss: 1.81681489944458
Batch 31/64 loss: 1.8150558471679688
Batch 32/64 loss: 1.7360901832580566
Batch 33/64 loss: 1.9956579208374023
Batch 34/64 loss: 1.7257156372070312
Batch 35/64 loss: 1.7106404304504395
Batch 36/64 loss: 3.2600107192993164
Batch 37/64 loss: 1.8299651145935059
Batch 38/64 loss: 1.6191248893737793
Batch 39/64 loss: 1.6008296012878418
Batch 40/64 loss: 1.5973129272460938
Batch 41/64 loss: 1.9490318298339844
Batch 42/64 loss: 1.7810487747192383
Batch 43/64 loss: 4.119648456573486
Batch 44/64 loss: 1.706099033355713
Batch 45/64 loss: 2.027698516845703
Batch 46/64 loss: 2.063534736633301
Batch 47/64 loss: 1.9799199104309082
Batch 48/64 loss: 1.9491276741027832
Batch 49/64 loss: 1.651515007019043
Batch 50/64 loss: 1.566084861755371
Batch 51/64 loss: 1.9470982551574707
Batch 52/64 loss: 1.805631160736084
Batch 53/64 loss: 1.6355247497558594
Batch 54/64 loss: 1.721911907196045
Batch 55/64 loss: 1.7137441635131836
Batch 56/64 loss: 2.0553603172302246
Batch 57/64 loss: 3.7801623344421387
Batch 58/64 loss: 1.7299447059631348
Batch 59/64 loss: 1.7366862297058105
Batch 60/64 loss: 1.919003963470459
Batch 61/64 loss: 4.626445770263672
Batch 62/64 loss: 1.7047367095947266
Batch 63/64 loss: 1.7368922233581543
Batch 64/64 loss: -1.800374984741211
Epoch 397  Train loss: 1.9555841632917816  Val loss: 1.4113387143898666
Epoch 398
-------------------------------
Batch 1/64 loss: 1.72011137008667
Batch 2/64 loss: 1.800468921661377
Batch 3/64 loss: 1.773780345916748
Batch 4/64 loss: 1.621138572692871
Batch 5/64 loss: 1.6309943199157715
Batch 6/64 loss: 1.571721076965332
Batch 7/64 loss: 1.6099300384521484
Batch 8/64 loss: 1.5905652046203613
Batch 9/64 loss: 1.7103562355041504
Batch 10/64 loss: 1.6913599967956543
Batch 11/64 loss: 1.7514843940734863
Batch 12/64 loss: 1.7711753845214844
Batch 13/64 loss: 1.8062200546264648
Batch 14/64 loss: 1.9124341011047363
Batch 15/64 loss: 2.803579330444336
Batch 16/64 loss: 1.7615737915039062
Batch 17/64 loss: 1.7234010696411133
Batch 18/64 loss: 1.6394166946411133
Batch 19/64 loss: 3.8889694213867188
Batch 20/64 loss: 1.7984662055969238
Batch 21/64 loss: 4.177089691162109
Batch 22/64 loss: 1.9792695045471191
Batch 23/64 loss: 1.6268558502197266
Batch 24/64 loss: 1.7223682403564453
Batch 25/64 loss: 1.9612984657287598
Batch 26/64 loss: 1.6802301406860352
Batch 27/64 loss: 1.6623401641845703
Batch 28/64 loss: 2.295175075531006
Batch 29/64 loss: 1.9073305130004883
Batch 30/64 loss: 1.9274845123291016
Batch 31/64 loss: 1.62410306930542
Batch 32/64 loss: 1.7270994186401367
Batch 33/64 loss: 1.5695719718933105
Batch 34/64 loss: 1.748671054840088
Batch 35/64 loss: 4.82520866394043
Batch 36/64 loss: 1.750849723815918
Batch 37/64 loss: 1.7018909454345703
Batch 38/64 loss: 2.4695420265197754
Batch 39/64 loss: 1.6937990188598633
Batch 40/64 loss: 1.838493824005127
Batch 41/64 loss: 3.4421772956848145
Batch 42/64 loss: 1.7995119094848633
Batch 43/64 loss: 2.6993207931518555
Batch 44/64 loss: 2.3085341453552246
Batch 45/64 loss: 1.8487935066223145
Batch 46/64 loss: 1.9400529861450195
Batch 47/64 loss: 1.9537758827209473
Batch 48/64 loss: 1.8876614570617676
Batch 49/64 loss: 2.071561813354492
Batch 50/64 loss: 2.180428981781006
Batch 51/64 loss: 2.379721164703369
Batch 52/64 loss: 2.171553611755371
Batch 53/64 loss: 3.4803338050842285
Batch 54/64 loss: 3.448098659515381
Batch 55/64 loss: 1.9666633605957031
Batch 56/64 loss: 2.9935216903686523
Batch 57/64 loss: 2.5550942420959473
Batch 58/64 loss: 2.2435951232910156
Batch 59/64 loss: 1.7721366882324219
Batch 60/64 loss: 1.9164190292358398
Batch 61/64 loss: 1.9447975158691406
Batch 62/64 loss: 2.957522392272949
Batch 63/64 loss: 2.1237926483154297
Batch 64/64 loss: -1.1266279220581055
Epoch 398  Train loss: 2.081661430059695  Val loss: 1.7900472162515437
Epoch 399
-------------------------------
Batch 1/64 loss: 2.076322078704834
Batch 2/64 loss: 2.039536476135254
Batch 3/64 loss: 2.039985179901123
Batch 4/64 loss: 1.9327783584594727
Batch 5/64 loss: 1.958798885345459
Batch 6/64 loss: 1.951718807220459
Batch 7/64 loss: 1.8781747817993164
Batch 8/64 loss: 1.7853245735168457
Batch 9/64 loss: 4.474570274353027
Batch 10/64 loss: 1.8751745223999023
Batch 11/64 loss: 2.0732431411743164
Batch 12/64 loss: 2.3458805084228516
Batch 13/64 loss: 2.345473289489746
Batch 14/64 loss: 2.894838333129883
Batch 15/64 loss: 1.8777494430541992
Batch 16/64 loss: 1.7208499908447266
Batch 17/64 loss: 1.6702580451965332
Batch 18/64 loss: 1.8273415565490723
Batch 19/64 loss: 1.758531093597412
Batch 20/64 loss: 1.7446250915527344
Batch 21/64 loss: 1.8138227462768555
Batch 22/64 loss: 1.6934547424316406
Batch 23/64 loss: 2.312617778778076
Batch 24/64 loss: 1.709543228149414
Batch 25/64 loss: 1.7568631172180176
Batch 26/64 loss: 2.4542407989501953
Batch 27/64 loss: 2.1919031143188477
Batch 28/64 loss: 2.817809581756592
Batch 29/64 loss: 1.975193977355957
Batch 30/64 loss: 1.7861227989196777
Batch 31/64 loss: 1.740664005279541
Batch 32/64 loss: 1.8071870803833008
Batch 33/64 loss: 1.821981430053711
Batch 34/64 loss: 1.8347220420837402
Batch 35/64 loss: 1.9092211723327637
Batch 36/64 loss: 1.6661019325256348
Batch 37/64 loss: 5.14757776260376
Batch 38/64 loss: 1.7239165306091309
Batch 39/64 loss: 2.8676204681396484
Batch 40/64 loss: 1.8952727317810059
Batch 41/64 loss: 1.8165960311889648
Batch 42/64 loss: 1.8586158752441406
Batch 43/64 loss: 1.660036563873291
Batch 44/64 loss: 1.7406964302062988
Batch 45/64 loss: 1.8987226486206055
Batch 46/64 loss: 1.6901111602783203
Batch 47/64 loss: 1.9649910926818848
Batch 48/64 loss: 1.8181877136230469
Batch 49/64 loss: 1.7481708526611328
Batch 50/64 loss: 1.7147111892700195
Batch 51/64 loss: 1.9616656303405762
Batch 52/64 loss: 1.6263303756713867
Batch 53/64 loss: 1.7960848808288574
Batch 54/64 loss: 1.6984601020812988
Batch 55/64 loss: 2.0081496238708496
Batch 56/64 loss: 2.413146495819092
Batch 57/64 loss: 1.894406795501709
Batch 58/64 loss: 1.6894621849060059
Batch 59/64 loss: 1.9269599914550781
Batch 60/64 loss: 1.7341852188110352
Batch 61/64 loss: 1.7488675117492676
Batch 62/64 loss: 1.8209776878356934
Batch 63/64 loss: 4.374695777893066
Batch 64/64 loss: -1.864069938659668
Epoch 399  Train loss: 2.0141676996268476  Val loss: 1.4568140613254403
Epoch 400
-------------------------------
Batch 1/64 loss: 1.8726181983947754
Batch 2/64 loss: 1.68894624710083
Batch 3/64 loss: 2.7344837188720703
Batch 4/64 loss: 1.8560266494750977
Batch 5/64 loss: 1.63911771774292
Batch 6/64 loss: 1.7433171272277832
Batch 7/64 loss: 1.6559815406799316
Batch 8/64 loss: 1.569666862487793
Batch 9/64 loss: 1.779313564300537
Batch 10/64 loss: 1.7073173522949219
Batch 11/64 loss: 1.7974443435668945
Batch 12/64 loss: 2.4415173530578613
Batch 13/64 loss: 1.6783719062805176
Batch 14/64 loss: 1.8401103019714355
Batch 15/64 loss: 1.7355270385742188
Batch 16/64 loss: 1.6531643867492676
Batch 17/64 loss: 1.7441291809082031
Batch 18/64 loss: 5.014557361602783
Batch 19/64 loss: 1.7923431396484375
Batch 20/64 loss: 1.641897201538086
Batch 21/64 loss: 1.7488698959350586
Batch 22/64 loss: 1.8296661376953125
Batch 23/64 loss: 1.7598719596862793
Batch 24/64 loss: 2.5100202560424805
Batch 25/64 loss: 2.4878292083740234
Batch 26/64 loss: 2.019713878631592
Batch 27/64 loss: 1.7068424224853516
Batch 28/64 loss: 1.70595121383667
Batch 29/64 loss: 1.6324615478515625
Batch 30/64 loss: 1.7265214920043945
Batch 31/64 loss: 1.7613372802734375
Batch 32/64 loss: 2.2026214599609375
Batch 33/64 loss: 1.7910070419311523
Batch 34/64 loss: 1.989138126373291
Batch 35/64 loss: 1.6585664749145508
Batch 36/64 loss: 1.6799931526184082
Batch 37/64 loss: 4.64674711227417
Batch 38/64 loss: 1.621072769165039
Batch 39/64 loss: 1.9907941818237305
Batch 40/64 loss: 1.7319035530090332
Batch 41/64 loss: 1.6830158233642578
Batch 42/64 loss: 1.795921802520752
Batch 43/64 loss: 2.049269199371338
Batch 44/64 loss: 1.6916494369506836
Batch 45/64 loss: 1.700467586517334
Batch 46/64 loss: 1.6701059341430664
Batch 47/64 loss: 1.664309024810791
Batch 48/64 loss: 1.7762336730957031
Batch 49/64 loss: 1.5771126747131348
Batch 50/64 loss: 1.7475166320800781
Batch 51/64 loss: 1.628077507019043
Batch 52/64 loss: 1.6510233879089355
Batch 53/64 loss: 1.8249778747558594
Batch 54/64 loss: 1.633112907409668
Batch 55/64 loss: 1.5952916145324707
Batch 56/64 loss: 1.7222800254821777
Batch 57/64 loss: 1.6996116638183594
Batch 58/64 loss: 1.7312111854553223
Batch 59/64 loss: 1.7703471183776855
Batch 60/64 loss: 2.0529446601867676
Batch 61/64 loss: 3.8336539268493652
Batch 62/64 loss: 1.5830717086791992
Batch 63/64 loss: 1.6389713287353516
Batch 64/64 loss: -1.8725290298461914
Epoch 400  Train loss: 1.8839617299098594  Val loss: 1.3933829605784203
Saving best model, epoch: 400
Epoch 401
-------------------------------
Batch 1/64 loss: 1.7937273979187012
Batch 2/64 loss: 1.7366209030151367
Batch 3/64 loss: 1.560750961303711
Batch 4/64 loss: 1.7944016456604004
Batch 5/64 loss: 1.6735520362854004
Batch 6/64 loss: 1.6121668815612793
Batch 7/64 loss: 1.6676840782165527
Batch 8/64 loss: 1.7518548965454102
Batch 9/64 loss: 1.8706016540527344
Batch 10/64 loss: 1.5992660522460938
Batch 11/64 loss: 1.7070879936218262
Batch 12/64 loss: 1.6148982048034668
Batch 13/64 loss: 4.034789562225342
Batch 14/64 loss: 1.6025629043579102
Batch 15/64 loss: 1.664827823638916
Batch 16/64 loss: 1.6467127799987793
Batch 17/64 loss: 1.7310190200805664
Batch 18/64 loss: 1.9025306701660156
Batch 19/64 loss: 1.5320625305175781
Batch 20/64 loss: 1.8569650650024414
Batch 21/64 loss: 1.6145410537719727
Batch 22/64 loss: 1.6096811294555664
Batch 23/64 loss: 2.285656452178955
Batch 24/64 loss: 5.55692720413208
Batch 25/64 loss: 1.6699700355529785
Batch 26/64 loss: 1.6987862586975098
Batch 27/64 loss: 2.0758376121520996
Batch 28/64 loss: 2.4071574211120605
Batch 29/64 loss: 2.7498412132263184
Batch 30/64 loss: 1.6405348777770996
Batch 31/64 loss: 1.7152676582336426
Batch 32/64 loss: 1.7035083770751953
Batch 33/64 loss: 1.621757984161377
Batch 34/64 loss: 2.4154419898986816
Batch 35/64 loss: 1.5981502532958984
Batch 36/64 loss: 1.663682460784912
Batch 37/64 loss: 1.5660104751586914
Batch 38/64 loss: 1.6829299926757812
Batch 39/64 loss: 1.663414478302002
Batch 40/64 loss: 1.8125381469726562
Batch 41/64 loss: 1.5686712265014648
Batch 42/64 loss: 1.7018179893493652
Batch 43/64 loss: 1.682866096496582
Batch 44/64 loss: 1.9421520233154297
Batch 45/64 loss: 1.618760108947754
Batch 46/64 loss: 1.623365879058838
Batch 47/64 loss: 1.983086109161377
Batch 48/64 loss: 1.6188983917236328
Batch 49/64 loss: 1.9636378288269043
Batch 50/64 loss: 1.5584235191345215
Batch 51/64 loss: 2.0174803733825684
Batch 52/64 loss: 1.6360154151916504
Batch 53/64 loss: 1.6380763053894043
Batch 54/64 loss: 1.7136421203613281
Batch 55/64 loss: 1.6059794425964355
Batch 56/64 loss: 2.0721516609191895
Batch 57/64 loss: 1.7624549865722656
Batch 58/64 loss: 3.9124221801757812
Batch 59/64 loss: 1.6190400123596191
Batch 60/64 loss: 1.8648204803466797
Batch 61/64 loss: 1.5158400535583496
Batch 62/64 loss: 1.750460147857666
Batch 63/64 loss: 1.7649974822998047
Batch 64/64 loss: -1.7993392944335938
Epoch 401  Train loss: 1.8492748784083946  Val loss: 1.4811263985650236
Epoch 402
-------------------------------
Batch 1/64 loss: 1.7663216590881348
Batch 2/64 loss: 1.7665762901306152
Batch 3/64 loss: 1.7152228355407715
Batch 4/64 loss: 1.786299705505371
Batch 5/64 loss: 5.268917560577393
Batch 6/64 loss: 1.6912803649902344
Batch 7/64 loss: 1.7299895286560059
Batch 8/64 loss: 1.753779411315918
Batch 9/64 loss: 3.925506591796875
Batch 10/64 loss: 1.8974289894104004
Batch 11/64 loss: 1.703293800354004
Batch 12/64 loss: 1.946706771850586
Batch 13/64 loss: 2.170653820037842
Batch 14/64 loss: 1.8167657852172852
Batch 15/64 loss: 2.8277363777160645
Batch 16/64 loss: 2.5771102905273438
Batch 17/64 loss: 1.9560513496398926
Batch 18/64 loss: 1.870908260345459
Batch 19/64 loss: 3.6398677825927734
Batch 20/64 loss: 2.4990530014038086
Batch 21/64 loss: 1.94520902633667
Batch 22/64 loss: 2.267427921295166
Batch 23/64 loss: 2.9073195457458496
Batch 24/64 loss: 4.752164363861084
Batch 25/64 loss: 2.2440648078918457
Batch 26/64 loss: 2.1675047874450684
Batch 27/64 loss: 1.769503116607666
Batch 28/64 loss: 1.9099183082580566
Batch 29/64 loss: 2.258110523223877
Batch 30/64 loss: 3.1190810203552246
Batch 31/64 loss: 1.7534418106079102
Batch 32/64 loss: 2.595709800720215
Batch 33/64 loss: 2.3864502906799316
Batch 34/64 loss: 2.1010236740112305
Batch 35/64 loss: 1.785494327545166
Batch 36/64 loss: 1.8239660263061523
Batch 37/64 loss: 1.929722785949707
Batch 38/64 loss: 1.833526611328125
Batch 39/64 loss: 2.996628761291504
Batch 40/64 loss: 1.7923765182495117
Batch 41/64 loss: 1.7746505737304688
Batch 42/64 loss: 1.8866949081420898
Batch 43/64 loss: 1.785264492034912
Batch 44/64 loss: 2.0637454986572266
Batch 45/64 loss: 1.8502559661865234
Batch 46/64 loss: 1.6303038597106934
Batch 47/64 loss: 1.781999111175537
Batch 48/64 loss: 1.883821964263916
Batch 49/64 loss: 2.174833297729492
Batch 50/64 loss: 1.8945255279541016
Batch 51/64 loss: 1.7140212059020996
Batch 52/64 loss: 1.7876553535461426
Batch 53/64 loss: 1.8426637649536133
Batch 54/64 loss: 1.8436837196350098
Batch 55/64 loss: 1.9202547073364258
Batch 56/64 loss: 1.6845059394836426
Batch 57/64 loss: 1.7330474853515625
Batch 58/64 loss: 1.8902063369750977
Batch 59/64 loss: 1.8032455444335938
Batch 60/64 loss: 1.8386783599853516
Batch 61/64 loss: 1.6038546562194824
Batch 62/64 loss: 2.06376314163208
Batch 63/64 loss: 1.7405285835266113
Batch 64/64 loss: -1.7345876693725586
Epoch 402  Train loss: 2.0947353325638116  Val loss: 1.4905798082908814
Epoch 403
-------------------------------
Batch 1/64 loss: 1.720569133758545
Batch 2/64 loss: 1.7427244186401367
Batch 3/64 loss: 1.8192567825317383
Batch 4/64 loss: 1.5927424430847168
Batch 5/64 loss: 1.7521953582763672
Batch 6/64 loss: 1.8487467765808105
Batch 7/64 loss: 2.012162685394287
Batch 8/64 loss: 1.7175555229187012
Batch 9/64 loss: 1.684427261352539
Batch 10/64 loss: 1.8119268417358398
Batch 11/64 loss: 4.198000907897949
Batch 12/64 loss: 1.657224178314209
Batch 13/64 loss: 1.671581745147705
Batch 14/64 loss: 1.9625482559204102
Batch 15/64 loss: 1.7588577270507812
Batch 16/64 loss: 1.76408052444458
Batch 17/64 loss: 1.6331000328063965
Batch 18/64 loss: 1.9671850204467773
Batch 19/64 loss: 1.741100788116455
Batch 20/64 loss: 1.9485712051391602
Batch 21/64 loss: 1.5928325653076172
Batch 22/64 loss: 1.7006440162658691
Batch 23/64 loss: 1.7712440490722656
Batch 24/64 loss: 1.704061508178711
Batch 25/64 loss: 2.2649755477905273
Batch 26/64 loss: 1.5507259368896484
Batch 27/64 loss: 1.8093867301940918
Batch 28/64 loss: 1.6655244827270508
Batch 29/64 loss: 1.7083549499511719
Batch 30/64 loss: 2.016535758972168
Batch 31/64 loss: 1.6546669006347656
Batch 32/64 loss: 1.756861686706543
Batch 33/64 loss: 1.7021327018737793
Batch 34/64 loss: 1.6969075202941895
Batch 35/64 loss: 1.7933130264282227
Batch 36/64 loss: 1.6954174041748047
Batch 37/64 loss: 1.9332537651062012
Batch 38/64 loss: 1.8192343711853027
Batch 39/64 loss: 1.664781093597412
Batch 40/64 loss: 2.041165828704834
Batch 41/64 loss: 1.6476469039916992
Batch 42/64 loss: 2.0374627113342285
Batch 43/64 loss: 1.7429800033569336
Batch 44/64 loss: 1.7275843620300293
Batch 45/64 loss: 1.9545559883117676
Batch 46/64 loss: 5.132375240325928
Batch 47/64 loss: 5.132031440734863
Batch 48/64 loss: 1.657496452331543
Batch 49/64 loss: 1.5479960441589355
Batch 50/64 loss: 1.761857509613037
Batch 51/64 loss: 1.9643006324768066
Batch 52/64 loss: 1.7468795776367188
Batch 53/64 loss: 2.5486984252929688
Batch 54/64 loss: 1.9169864654541016
Batch 55/64 loss: 1.9812674522399902
Batch 56/64 loss: 1.5726032257080078
Batch 57/64 loss: 3.1229310035705566
Batch 58/64 loss: 2.497715950012207
Batch 59/64 loss: 1.7852349281311035
Batch 60/64 loss: 1.7746968269348145
Batch 61/64 loss: 1.795194149017334
Batch 62/64 loss: 1.7045254707336426
Batch 63/64 loss: 1.8277592658996582
Batch 64/64 loss: -1.7338428497314453
Epoch 403  Train loss: 1.9266976524801815  Val loss: 1.448161869114617
Epoch 404
-------------------------------
Batch 1/64 loss: 1.7298226356506348
Batch 2/64 loss: 1.688891887664795
Batch 3/64 loss: 1.812636375427246
Batch 4/64 loss: 1.9311103820800781
Batch 5/64 loss: 1.6273393630981445
Batch 6/64 loss: 1.7110881805419922
Batch 7/64 loss: 4.4360480308532715
Batch 8/64 loss: 1.8320684432983398
Batch 9/64 loss: 1.7450833320617676
Batch 10/64 loss: 1.7826671600341797
Batch 11/64 loss: 2.461622714996338
Batch 12/64 loss: 1.7679328918457031
Batch 13/64 loss: 2.325040340423584
Batch 14/64 loss: 1.848231315612793
Batch 15/64 loss: 1.6004505157470703
Batch 16/64 loss: 1.7099709510803223
Batch 17/64 loss: 1.7386412620544434
Batch 18/64 loss: 1.7321500778198242
Batch 19/64 loss: 1.8516778945922852
Batch 20/64 loss: 1.6220502853393555
Batch 21/64 loss: 4.765364170074463
Batch 22/64 loss: 1.7750177383422852
Batch 23/64 loss: 1.6572537422180176
Batch 24/64 loss: 1.6626577377319336
Batch 25/64 loss: 1.7131423950195312
Batch 26/64 loss: 1.7990140914916992
Batch 27/64 loss: 1.6199331283569336
Batch 28/64 loss: 1.6120223999023438
Batch 29/64 loss: 1.8828253746032715
Batch 30/64 loss: 2.017937183380127
Batch 31/64 loss: 1.658623218536377
Batch 32/64 loss: 1.593106746673584
Batch 33/64 loss: 2.9365010261535645
Batch 34/64 loss: 1.886767864227295
Batch 35/64 loss: 1.6977729797363281
Batch 36/64 loss: 1.596787452697754
Batch 37/64 loss: 1.8026576042175293
Batch 38/64 loss: 1.6722402572631836
Batch 39/64 loss: 1.6596155166625977
Batch 40/64 loss: 1.7161974906921387
Batch 41/64 loss: 2.8491201400756836
Batch 42/64 loss: 1.608203411102295
Batch 43/64 loss: 3.7324328422546387
Batch 44/64 loss: 1.6855683326721191
Batch 45/64 loss: 1.9176344871520996
Batch 46/64 loss: 2.3044028282165527
Batch 47/64 loss: 1.6344928741455078
Batch 48/64 loss: 1.7451438903808594
Batch 49/64 loss: 2.5861353874206543
Batch 50/64 loss: 1.8404560089111328
Batch 51/64 loss: 1.766890525817871
Batch 52/64 loss: 1.6219334602355957
Batch 53/64 loss: 1.6728143692016602
Batch 54/64 loss: 1.6544933319091797
Batch 55/64 loss: 1.5947818756103516
Batch 56/64 loss: 1.715005874633789
Batch 57/64 loss: 1.7161140441894531
Batch 58/64 loss: 1.9541006088256836
Batch 59/64 loss: 1.775421142578125
Batch 60/64 loss: 1.8741068840026855
Batch 61/64 loss: 1.5239219665527344
Batch 62/64 loss: 1.7180557250976562
Batch 63/64 loss: 1.7278695106506348
Batch 64/64 loss: -1.6104793548583984
Epoch 404  Train loss: 1.893195328057981  Val loss: 1.4224600251187984
Epoch 405
-------------------------------
Batch 1/64 loss: 1.556713581085205
Batch 2/64 loss: 2.9989237785339355
Batch 3/64 loss: 1.7142972946166992
Batch 4/64 loss: 2.014491081237793
Batch 5/64 loss: 1.8952579498291016
Batch 6/64 loss: 4.00549840927124
Batch 7/64 loss: 2.1133837699890137
Batch 8/64 loss: 1.6994867324829102
Batch 9/64 loss: 1.7755417823791504
Batch 10/64 loss: 1.8124480247497559
Batch 11/64 loss: 1.8981142044067383
Batch 12/64 loss: 1.8069162368774414
Batch 13/64 loss: 2.0622401237487793
Batch 14/64 loss: 2.237283706665039
Batch 15/64 loss: 1.790837287902832
Batch 16/64 loss: 1.7065982818603516
Batch 17/64 loss: 2.4885125160217285
Batch 18/64 loss: 1.8106427192687988
Batch 19/64 loss: 1.6302709579467773
Batch 20/64 loss: 1.5996928215026855
Batch 21/64 loss: 1.62245512008667
Batch 22/64 loss: 1.785080909729004
Batch 23/64 loss: 2.746166229248047
Batch 24/64 loss: 1.8539695739746094
Batch 25/64 loss: 1.5751519203186035
Batch 26/64 loss: 1.9018096923828125
Batch 27/64 loss: 1.6407561302185059
Batch 28/64 loss: 1.6537203788757324
Batch 29/64 loss: 1.5476326942443848
Batch 30/64 loss: 1.6150097846984863
Batch 31/64 loss: 1.7207350730895996
Batch 32/64 loss: 1.6928362846374512
Batch 33/64 loss: 1.7020273208618164
Batch 34/64 loss: 1.7486991882324219
Batch 35/64 loss: 1.8110036849975586
Batch 36/64 loss: 1.6262550354003906
Batch 37/64 loss: 1.6851277351379395
Batch 38/64 loss: 1.6756210327148438
Batch 39/64 loss: 1.7826552391052246
Batch 40/64 loss: 1.6191339492797852
Batch 41/64 loss: 1.670100212097168
Batch 42/64 loss: 3.8402514457702637
Batch 43/64 loss: 1.7513036727905273
Batch 44/64 loss: 1.7121357917785645
Batch 45/64 loss: 1.7584114074707031
Batch 46/64 loss: 1.7316689491271973
Batch 47/64 loss: 2.1451330184936523
Batch 48/64 loss: 1.6244993209838867
Batch 49/64 loss: 1.8884224891662598
Batch 50/64 loss: 1.6703300476074219
Batch 51/64 loss: 1.680985450744629
Batch 52/64 loss: 2.302476406097412
Batch 53/64 loss: 1.572524070739746
Batch 54/64 loss: 1.9502248764038086
Batch 55/64 loss: 1.7021903991699219
Batch 56/64 loss: 1.7253403663635254
Batch 57/64 loss: 1.674868106842041
Batch 58/64 loss: 1.5720109939575195
Batch 59/64 loss: 1.7213730812072754
Batch 60/64 loss: 1.6387534141540527
Batch 61/64 loss: 1.5266895294189453
Batch 62/64 loss: 1.5612831115722656
Batch 63/64 loss: 4.541476726531982
Batch 64/64 loss: -1.7569150924682617
Epoch 405  Train loss: 1.8708668989293715  Val loss: 1.4054332352995462
Epoch 406
-------------------------------
Batch 1/64 loss: 1.5581340789794922
Batch 2/64 loss: 1.81988525390625
Batch 3/64 loss: 1.7143864631652832
Batch 4/64 loss: 4.033721446990967
Batch 5/64 loss: 1.6677756309509277
Batch 6/64 loss: 1.7690939903259277
Batch 7/64 loss: 1.7482056617736816
Batch 8/64 loss: 1.6159453392028809
Batch 9/64 loss: 3.7279701232910156
Batch 10/64 loss: 1.6866140365600586
Batch 11/64 loss: 3.8605966567993164
Batch 12/64 loss: 1.8013596534729004
Batch 13/64 loss: 2.365569591522217
Batch 14/64 loss: 3.0605010986328125
Batch 15/64 loss: 4.157104969024658
Batch 16/64 loss: 2.758902072906494
Batch 17/64 loss: 3.5781922340393066
Batch 18/64 loss: 3.476137638092041
Batch 19/64 loss: 2.6678013801574707
Batch 20/64 loss: 3.64739990234375
Batch 21/64 loss: 3.0369038581848145
Batch 22/64 loss: 3.0465030670166016
Batch 23/64 loss: 3.5269651412963867
Batch 24/64 loss: 3.120201587677002
Batch 25/64 loss: 2.7640089988708496
Batch 26/64 loss: 3.5316200256347656
Batch 27/64 loss: 2.6956729888916016
Batch 28/64 loss: 2.720026969909668
Batch 29/64 loss: 2.7767539024353027
Batch 30/64 loss: 3.3704113960266113
Batch 31/64 loss: 2.718418598175049
Batch 32/64 loss: 2.731907844543457
Batch 33/64 loss: 2.9714317321777344
Batch 34/64 loss: 3.2834835052490234
Batch 35/64 loss: 2.6080198287963867
Batch 36/64 loss: 2.2900643348693848
Batch 37/64 loss: 2.6322555541992188
Batch 38/64 loss: 2.489027976989746
Batch 39/64 loss: 2.543036937713623
Batch 40/64 loss: 2.932155132293701
Batch 41/64 loss: 2.5975756645202637
Batch 42/64 loss: 2.686532497406006
Batch 43/64 loss: 2.961909770965576
Batch 44/64 loss: 2.964399814605713
Batch 45/64 loss: 3.060133457183838
Batch 46/64 loss: 2.7440314292907715
Batch 47/64 loss: 2.8714957237243652
Batch 48/64 loss: 2.43637752532959
Batch 49/64 loss: 2.340132713317871
Batch 50/64 loss: 2.3593688011169434
Batch 51/64 loss: 2.5546951293945312
Batch 52/64 loss: 2.4385247230529785
Batch 53/64 loss: 3.173560619354248
Batch 54/64 loss: 2.596923351287842
Batch 55/64 loss: 2.6655545234680176
Batch 56/64 loss: 2.464865207672119
Batch 57/64 loss: 2.680379867553711
Batch 58/64 loss: 2.2916102409362793
Batch 59/64 loss: 4.7713623046875
Batch 60/64 loss: 2.3851442337036133
Batch 61/64 loss: 2.441533088684082
Batch 62/64 loss: 2.43508243560791
Batch 63/64 loss: 2.0194625854492188
Batch 64/64 loss: -1.3960866928100586
Epoch 406  Train loss: 2.6885922712438246  Val loss: 1.975911065065574
Epoch 407
-------------------------------
Batch 1/64 loss: 2.1232171058654785
Batch 2/64 loss: 2.891435146331787
Batch 3/64 loss: 2.1960511207580566
Batch 4/64 loss: 2.704087257385254
Batch 5/64 loss: 2.1939191818237305
Batch 6/64 loss: 2.157653331756592
Batch 7/64 loss: 2.0041604042053223
Batch 8/64 loss: 2.095102310180664
Batch 9/64 loss: 2.3343892097473145
Batch 10/64 loss: 2.048090934753418
Batch 11/64 loss: 3.488795757293701
Batch 12/64 loss: 4.167594909667969
Batch 13/64 loss: 2.4186367988586426
Batch 14/64 loss: 2.0581297874450684
Batch 15/64 loss: 2.8418426513671875
Batch 16/64 loss: 1.8622446060180664
Batch 17/64 loss: 1.9487614631652832
Batch 18/64 loss: 3.0728793144226074
Batch 19/64 loss: 2.0219593048095703
Batch 20/64 loss: 1.874117374420166
Batch 21/64 loss: 1.840550422668457
Batch 22/64 loss: 2.1552624702453613
Batch 23/64 loss: 2.5024046897888184
Batch 24/64 loss: 1.876976490020752
Batch 25/64 loss: 2.0119452476501465
Batch 26/64 loss: 2.561150550842285
Batch 27/64 loss: 1.9823241233825684
Batch 28/64 loss: 2.641634941101074
Batch 29/64 loss: 2.050044536590576
Batch 30/64 loss: 4.583153247833252
Batch 31/64 loss: 2.026297092437744
Batch 32/64 loss: 1.9946770668029785
Batch 33/64 loss: 1.9469356536865234
Batch 34/64 loss: 1.8698468208312988
Batch 35/64 loss: 2.1476712226867676
Batch 36/64 loss: 2.2447056770324707
Batch 37/64 loss: 1.9048089981079102
Batch 38/64 loss: 2.1315574645996094
Batch 39/64 loss: 2.026392936706543
Batch 40/64 loss: 2.0338034629821777
Batch 41/64 loss: 5.084737777709961
Batch 42/64 loss: 1.884335994720459
Batch 43/64 loss: 1.8718791007995605
Batch 44/64 loss: 2.0356998443603516
Batch 45/64 loss: 2.180257797241211
Batch 46/64 loss: 2.269221782684326
Batch 47/64 loss: 1.830380916595459
Batch 48/64 loss: 1.8356285095214844
Batch 49/64 loss: 2.3346614837646484
Batch 50/64 loss: 1.9306931495666504
Batch 51/64 loss: 1.8598031997680664
Batch 52/64 loss: 2.068859100341797
Batch 53/64 loss: 1.7968549728393555
Batch 54/64 loss: 1.8415980339050293
Batch 55/64 loss: 1.7758126258850098
Batch 56/64 loss: 1.6881699562072754
Batch 57/64 loss: 1.8657970428466797
Batch 58/64 loss: 1.9804573059082031
Batch 59/64 loss: 1.8749699592590332
Batch 60/64 loss: 1.8409552574157715
Batch 61/64 loss: 2.2954506874084473
Batch 62/64 loss: 1.8964200019836426
Batch 63/64 loss: 1.760873794555664
Batch 64/64 loss: -1.4852075576782227
Epoch 407  Train loss: 2.1917619406008253  Val loss: 1.5929829050175512
Epoch 408
-------------------------------
Batch 1/64 loss: 2.464592456817627
Batch 2/64 loss: 2.149564266204834
Batch 3/64 loss: 2.237516403198242
Batch 4/64 loss: 1.8647527694702148
Batch 5/64 loss: 5.1845831871032715
Batch 6/64 loss: 2.062056541442871
Batch 7/64 loss: 1.774641990661621
Batch 8/64 loss: 1.8340554237365723
Batch 9/64 loss: 1.9188570976257324
Batch 10/64 loss: 1.8025751113891602
Batch 11/64 loss: 2.011308193206787
Batch 12/64 loss: 1.932079792022705
Batch 13/64 loss: 1.865809440612793
Batch 14/64 loss: 1.9114928245544434
Batch 15/64 loss: 1.8612232208251953
Batch 16/64 loss: 1.7095050811767578
Batch 17/64 loss: 1.918522834777832
Batch 18/64 loss: 4.82266902923584
Batch 19/64 loss: 1.7347602844238281
Batch 20/64 loss: 1.7314233779907227
Batch 21/64 loss: 1.889418601989746
Batch 22/64 loss: 2.0557656288146973
Batch 23/64 loss: 1.9360861778259277
Batch 24/64 loss: 1.831653118133545
Batch 25/64 loss: 1.9014978408813477
Batch 26/64 loss: 2.0982918739318848
Batch 27/64 loss: 1.804375171661377
Batch 28/64 loss: 1.727121353149414
Batch 29/64 loss: 2.7815608978271484
Batch 30/64 loss: 2.028993606567383
Batch 31/64 loss: 1.7598328590393066
Batch 32/64 loss: 1.9413037300109863
Batch 33/64 loss: 1.812819004058838
Batch 34/64 loss: 3.129067897796631
Batch 35/64 loss: 1.9493966102600098
Batch 36/64 loss: 2.0562543869018555
Batch 37/64 loss: 1.8932113647460938
Batch 38/64 loss: 1.9495124816894531
Batch 39/64 loss: 1.7447028160095215
Batch 40/64 loss: 2.024993419647217
Batch 41/64 loss: 2.217479705810547
Batch 42/64 loss: 1.8874502182006836
Batch 43/64 loss: 1.8243403434753418
Batch 44/64 loss: 2.016653060913086
Batch 45/64 loss: 1.8287572860717773
Batch 46/64 loss: 1.8397808074951172
Batch 47/64 loss: 2.308797836303711
Batch 48/64 loss: 1.9292283058166504
Batch 49/64 loss: 1.7980690002441406
Batch 50/64 loss: 1.8345999717712402
Batch 51/64 loss: 2.433504104614258
Batch 52/64 loss: 1.7786221504211426
Batch 53/64 loss: 1.8386039733886719
Batch 54/64 loss: 1.869781494140625
Batch 55/64 loss: 3.1544179916381836
Batch 56/64 loss: 3.912024974822998
Batch 57/64 loss: 1.7833552360534668
Batch 58/64 loss: 1.7533655166625977
Batch 59/64 loss: 1.857569694519043
Batch 60/64 loss: 1.8782224655151367
Batch 61/64 loss: 2.066584587097168
Batch 62/64 loss: 1.7976388931274414
Batch 63/64 loss: 1.654395580291748
Batch 64/64 loss: -1.6535682678222656
Epoch 408  Train loss: 2.0569555319991766  Val loss: 1.6200973143692279
Epoch 409
-------------------------------
Batch 1/64 loss: 1.8006806373596191
Batch 2/64 loss: 1.7382946014404297
Batch 3/64 loss: 2.483875274658203
Batch 4/64 loss: 2.878788471221924
Batch 5/64 loss: 1.8429698944091797
Batch 6/64 loss: 1.909421443939209
Batch 7/64 loss: 1.9929776191711426
Batch 8/64 loss: 1.8806381225585938
Batch 9/64 loss: 1.781775951385498
Batch 10/64 loss: 1.6678781509399414
Batch 11/64 loss: 2.7636218070983887
Batch 12/64 loss: 1.988126277923584
Batch 13/64 loss: 2.2143940925598145
Batch 14/64 loss: 1.8771653175354004
Batch 15/64 loss: 1.7457456588745117
Batch 16/64 loss: 1.7116336822509766
Batch 17/64 loss: 1.8324575424194336
Batch 18/64 loss: 2.0871753692626953
Batch 19/64 loss: 1.867067813873291
Batch 20/64 loss: 1.6778717041015625
Batch 21/64 loss: 1.8731541633605957
Batch 22/64 loss: 1.7796239852905273
Batch 23/64 loss: 2.8713340759277344
Batch 24/64 loss: 2.138424873352051
Batch 25/64 loss: 1.808243751525879
Batch 26/64 loss: 1.8136711120605469
Batch 27/64 loss: 1.7739982604980469
Batch 28/64 loss: 2.1754326820373535
Batch 29/64 loss: 1.742283821105957
Batch 30/64 loss: 4.80825662612915
Batch 31/64 loss: 1.9223437309265137
Batch 32/64 loss: 1.6893439292907715
Batch 33/64 loss: 1.82659912109375
Batch 34/64 loss: 1.6681632995605469
Batch 35/64 loss: 4.339048385620117
Batch 36/64 loss: 1.6153006553649902
Batch 37/64 loss: 1.7701635360717773
Batch 38/64 loss: 2.0032200813293457
Batch 39/64 loss: 1.7391071319580078
Batch 40/64 loss: 1.8231148719787598
Batch 41/64 loss: 1.8595409393310547
Batch 42/64 loss: 1.7926459312438965
Batch 43/64 loss: 1.8100957870483398
Batch 44/64 loss: 1.9851365089416504
Batch 45/64 loss: 1.9190587997436523
Batch 46/64 loss: 1.9462995529174805
Batch 47/64 loss: 1.8492774963378906
Batch 48/64 loss: 1.8464574813842773
Batch 49/64 loss: 1.7432465553283691
Batch 50/64 loss: 1.8085064888000488
Batch 51/64 loss: 2.857177734375
Batch 52/64 loss: 1.889298439025879
Batch 53/64 loss: 1.8731145858764648
Batch 54/64 loss: 1.6453909873962402
Batch 55/64 loss: 1.682009220123291
Batch 56/64 loss: 1.720383644104004
Batch 57/64 loss: 1.9114751815795898
Batch 58/64 loss: 4.013422966003418
Batch 59/64 loss: 1.6960206031799316
Batch 60/64 loss: 1.634544849395752
Batch 61/64 loss: 2.137937068939209
Batch 62/64 loss: 1.7838530540466309
Batch 63/64 loss: 1.8414287567138672
Batch 64/64 loss: -1.5284194946289062
Epoch 409  Train loss: 1.9925238515816484  Val loss: 1.4863156453031034
Epoch 410
-------------------------------
Batch 1/64 loss: 1.6865167617797852
Batch 2/64 loss: 1.764686107635498
Batch 3/64 loss: 1.9982986450195312
Batch 4/64 loss: 1.9203863143920898
Batch 5/64 loss: 2.6739182472229004
Batch 6/64 loss: 1.725259780883789
Batch 7/64 loss: 1.5538172721862793
Batch 8/64 loss: 1.773712158203125
Batch 9/64 loss: 1.9439759254455566
Batch 10/64 loss: 1.7098264694213867
Batch 11/64 loss: 1.761106014251709
Batch 12/64 loss: 1.6808662414550781
Batch 13/64 loss: 1.7037672996520996
Batch 14/64 loss: 1.7922759056091309
Batch 15/64 loss: 2.877617359161377
Batch 16/64 loss: 1.801041603088379
Batch 17/64 loss: 1.6963777542114258
Batch 18/64 loss: 2.0000720024108887
Batch 19/64 loss: 1.7483553886413574
Batch 20/64 loss: 1.7212677001953125
Batch 21/64 loss: 1.7460837364196777
Batch 22/64 loss: 1.795912742614746
Batch 23/64 loss: 1.6450581550598145
Batch 24/64 loss: 1.7376995086669922
Batch 25/64 loss: 2.0301361083984375
Batch 26/64 loss: 1.7089314460754395
Batch 27/64 loss: 1.805689811706543
Batch 28/64 loss: 1.7913341522216797
Batch 29/64 loss: 1.835080623626709
Batch 30/64 loss: 1.6474905014038086
Batch 31/64 loss: 2.25982666015625
Batch 32/64 loss: 1.7383947372436523
Batch 33/64 loss: 1.6926822662353516
Batch 34/64 loss: 1.9142417907714844
Batch 35/64 loss: 1.7247867584228516
Batch 36/64 loss: 1.6755132675170898
Batch 37/64 loss: 1.9778761863708496
Batch 38/64 loss: 1.681816577911377
Batch 39/64 loss: 2.0992088317871094
Batch 40/64 loss: 1.6327719688415527
Batch 41/64 loss: 1.815312385559082
Batch 42/64 loss: 4.388063907623291
Batch 43/64 loss: 1.746922492980957
Batch 44/64 loss: 1.6754045486450195
Batch 45/64 loss: 1.6466431617736816
Batch 46/64 loss: 1.8040175437927246
Batch 47/64 loss: 1.6954107284545898
Batch 48/64 loss: 1.7788519859313965
Batch 49/64 loss: 1.7071895599365234
Batch 50/64 loss: 1.6984291076660156
Batch 51/64 loss: 4.44600248336792
Batch 52/64 loss: 1.6834168434143066
Batch 53/64 loss: 1.9858708381652832
Batch 54/64 loss: 4.694335460662842
Batch 55/64 loss: 1.9237136840820312
Batch 56/64 loss: 1.728686809539795
Batch 57/64 loss: 1.746835708618164
Batch 58/64 loss: 2.2103633880615234
Batch 59/64 loss: 3.10160493850708
Batch 60/64 loss: 1.963066577911377
Batch 61/64 loss: 1.7093758583068848
Batch 62/64 loss: 1.6997089385986328
Batch 63/64 loss: 1.8408198356628418
Batch 64/64 loss: -1.818404197692871
Epoch 410  Train loss: 1.9294105791578107  Val loss: 1.4743562416522364
Epoch 411
-------------------------------
Batch 1/64 loss: 1.6678190231323242
Batch 2/64 loss: 1.8315882682800293
Batch 3/64 loss: 4.798147201538086
Batch 4/64 loss: 1.657210350036621
Batch 5/64 loss: 1.8678011894226074
Batch 6/64 loss: 1.5895614624023438
Batch 7/64 loss: 1.6812243461608887
Batch 8/64 loss: 1.7195887565612793
Batch 9/64 loss: 1.6975998878479004
Batch 10/64 loss: 1.7827143669128418
Batch 11/64 loss: 1.7682209014892578
Batch 12/64 loss: 1.6434402465820312
Batch 13/64 loss: 1.8619017601013184
Batch 14/64 loss: 1.6997528076171875
Batch 15/64 loss: 1.7970051765441895
Batch 16/64 loss: 1.6865463256835938
Batch 17/64 loss: 1.8550410270690918
Batch 18/64 loss: 1.724522590637207
Batch 19/64 loss: 1.8228764533996582
Batch 20/64 loss: 1.6674580574035645
Batch 21/64 loss: 1.6892590522766113
Batch 22/64 loss: 4.317983150482178
Batch 23/64 loss: 2.4003472328186035
Batch 24/64 loss: 1.6991205215454102
Batch 25/64 loss: 2.066249370574951
Batch 26/64 loss: 1.71766996383667
Batch 27/64 loss: 3.5965328216552734
Batch 28/64 loss: 2.047947883605957
Batch 29/64 loss: 1.6210789680480957
Batch 30/64 loss: 1.668680191040039
Batch 31/64 loss: 3.8525924682617188
Batch 32/64 loss: 1.8283805847167969
Batch 33/64 loss: 1.618044376373291
Batch 34/64 loss: 1.701718807220459
Batch 35/64 loss: 1.7579078674316406
Batch 36/64 loss: 1.8860969543457031
Batch 37/64 loss: 1.650373935699463
Batch 38/64 loss: 2.06685209274292
Batch 39/64 loss: 1.7643251419067383
Batch 40/64 loss: 1.7167811393737793
Batch 41/64 loss: 1.7629938125610352
Batch 42/64 loss: 1.8347702026367188
Batch 43/64 loss: 2.0754470825195312
Batch 44/64 loss: 1.8223180770874023
Batch 45/64 loss: 1.681610107421875
Batch 46/64 loss: 1.6926789283752441
Batch 47/64 loss: 1.6051087379455566
Batch 48/64 loss: 1.9743051528930664
Batch 49/64 loss: 1.6780834197998047
Batch 50/64 loss: 1.7434954643249512
Batch 51/64 loss: 1.7824249267578125
Batch 52/64 loss: 1.6439666748046875
Batch 53/64 loss: 1.6232795715332031
Batch 54/64 loss: 2.9110612869262695
Batch 55/64 loss: 1.6844964027404785
Batch 56/64 loss: 1.6509437561035156
Batch 57/64 loss: 1.8625526428222656
Batch 58/64 loss: 1.7300195693969727
Batch 59/64 loss: 1.8625564575195312
Batch 60/64 loss: 1.618283748626709
Batch 61/64 loss: 1.6285347938537598
Batch 62/64 loss: 1.8296713829040527
Batch 63/64 loss: 2.6419239044189453
Batch 64/64 loss: -1.7961673736572266
Epoch 411  Train loss: 1.9055900124942555  Val loss: 1.5026551210593522
Epoch 412
-------------------------------
Batch 1/64 loss: 1.7550315856933594
Batch 2/64 loss: 1.8392300605773926
Batch 3/64 loss: 1.7053289413452148
Batch 4/64 loss: 2.390368938446045
Batch 5/64 loss: 1.6906671524047852
Batch 6/64 loss: 1.6267967224121094
Batch 7/64 loss: 1.803999423980713
Batch 8/64 loss: 3.829169750213623
Batch 9/64 loss: 1.8227524757385254
Batch 10/64 loss: 4.511804103851318
Batch 11/64 loss: 1.5717792510986328
Batch 12/64 loss: 1.9932847023010254
Batch 13/64 loss: 1.6876516342163086
Batch 14/64 loss: 1.731642246246338
Batch 15/64 loss: 1.596334457397461
Batch 16/64 loss: 1.683335304260254
Batch 17/64 loss: 4.665829181671143
Batch 18/64 loss: 1.7960267066955566
Batch 19/64 loss: 1.6675949096679688
Batch 20/64 loss: 1.7927141189575195
Batch 21/64 loss: 1.7583365440368652
Batch 22/64 loss: 1.8303327560424805
Batch 23/64 loss: 1.6630258560180664
Batch 24/64 loss: 1.6455583572387695
Batch 25/64 loss: 1.5540790557861328
Batch 26/64 loss: 2.904973030090332
Batch 27/64 loss: 1.7090377807617188
Batch 28/64 loss: 1.6771259307861328
Batch 29/64 loss: 1.8141112327575684
Batch 30/64 loss: 1.642897605895996
Batch 31/64 loss: 1.9615225791931152
Batch 32/64 loss: 1.7038216590881348
Batch 33/64 loss: 1.5898652076721191
Batch 34/64 loss: 1.776702880859375
Batch 35/64 loss: 1.7115473747253418
Batch 36/64 loss: 1.714799404144287
Batch 37/64 loss: 1.7268424034118652
Batch 38/64 loss: 2.3884754180908203
Batch 39/64 loss: 1.7813448905944824
Batch 40/64 loss: 2.1439294815063477
Batch 41/64 loss: 2.738931179046631
Batch 42/64 loss: 1.70866060256958
Batch 43/64 loss: 1.5540213584899902
Batch 44/64 loss: 1.6594228744506836
Batch 45/64 loss: 1.660996913909912
Batch 46/64 loss: 1.7152228355407715
Batch 47/64 loss: 2.0697431564331055
Batch 48/64 loss: 1.7679352760314941
Batch 49/64 loss: 1.7492952346801758
Batch 50/64 loss: 1.6947026252746582
Batch 51/64 loss: 1.7502565383911133
Batch 52/64 loss: 1.6270432472229004
Batch 53/64 loss: 1.7624835968017578
Batch 54/64 loss: 1.794611930847168
Batch 55/64 loss: 1.6511530876159668
Batch 56/64 loss: 1.855435848236084
Batch 57/64 loss: 1.6686787605285645
Batch 58/64 loss: 1.6354179382324219
Batch 59/64 loss: 2.7073678970336914
Batch 60/64 loss: 2.0636534690856934
Batch 61/64 loss: 1.881885051727295
Batch 62/64 loss: 1.8249754905700684
Batch 63/64 loss: 1.571413516998291
Batch 64/64 loss: -1.7005586624145508
Epoch 412  Train loss: 1.89329506743188  Val loss: 1.449723063465656
Epoch 413
-------------------------------
Batch 1/64 loss: 1.6370291709899902
Batch 2/64 loss: 1.640113353729248
Batch 3/64 loss: 1.717139720916748
Batch 4/64 loss: 1.6923980712890625
Batch 5/64 loss: 1.662595272064209
Batch 6/64 loss: 1.6581950187683105
Batch 7/64 loss: 1.6642379760742188
Batch 8/64 loss: 2.9310522079467773
Batch 9/64 loss: 1.6878762245178223
Batch 10/64 loss: 1.7571916580200195
Batch 11/64 loss: 1.7475438117980957
Batch 12/64 loss: 1.8482294082641602
Batch 13/64 loss: 4.135695934295654
Batch 14/64 loss: 1.6970529556274414
Batch 15/64 loss: 1.765233039855957
Batch 16/64 loss: 1.8339080810546875
Batch 17/64 loss: 1.7115483283996582
Batch 18/64 loss: 2.4765543937683105
Batch 19/64 loss: 1.6997547149658203
Batch 20/64 loss: 4.6159749031066895
Batch 21/64 loss: 1.641446590423584
Batch 22/64 loss: 1.687222957611084
Batch 23/64 loss: 1.769362449645996
Batch 24/64 loss: 2.2448019981384277
Batch 25/64 loss: 1.8071413040161133
Batch 26/64 loss: 1.654615879058838
Batch 27/64 loss: 1.6255402565002441
Batch 28/64 loss: 1.7768306732177734
Batch 29/64 loss: 2.060713768005371
Batch 30/64 loss: 1.6971244812011719
Batch 31/64 loss: 1.8003268241882324
Batch 32/64 loss: 1.8467869758605957
Batch 33/64 loss: 2.0696091651916504
Batch 34/64 loss: 1.6977496147155762
Batch 35/64 loss: 1.9434490203857422
Batch 36/64 loss: 1.6207671165466309
Batch 37/64 loss: 1.7858467102050781
Batch 38/64 loss: 2.680333137512207
Batch 39/64 loss: 1.6758456230163574
Batch 40/64 loss: 1.7225914001464844
Batch 41/64 loss: 1.6314330101013184
Batch 42/64 loss: 2.1123504638671875
Batch 43/64 loss: 1.6947064399719238
Batch 44/64 loss: 1.573957920074463
Batch 45/64 loss: 2.062288284301758
Batch 46/64 loss: 2.0008726119995117
Batch 47/64 loss: 1.5729928016662598
Batch 48/64 loss: 1.764906883239746
Batch 49/64 loss: 1.7182106971740723
Batch 50/64 loss: 1.674001693725586
Batch 51/64 loss: 1.6372365951538086
Batch 52/64 loss: 1.8758440017700195
Batch 53/64 loss: 1.700770378112793
Batch 54/64 loss: 1.6588201522827148
Batch 55/64 loss: 1.6523408889770508
Batch 56/64 loss: 2.292363166809082
Batch 57/64 loss: 1.6038155555725098
Batch 58/64 loss: 1.6853008270263672
Batch 59/64 loss: 3.953436851501465
Batch 60/64 loss: 1.562791347503662
Batch 61/64 loss: 1.670450210571289
Batch 62/64 loss: 1.7238001823425293
Batch 63/64 loss: 1.5915684700012207
Batch 64/64 loss: -1.7775650024414062
Epoch 413  Train loss: 1.8740159352620442  Val loss: 1.4459917914007128
Epoch 414
-------------------------------
Batch 1/64 loss: 1.6105246543884277
Batch 2/64 loss: 1.6731877326965332
Batch 3/64 loss: 1.6054906845092773
Batch 4/64 loss: 1.8439912796020508
Batch 5/64 loss: 1.8654956817626953
Batch 6/64 loss: 2.052694320678711
Batch 7/64 loss: 1.8022432327270508
Batch 8/64 loss: 3.073098659515381
Batch 9/64 loss: 1.674781322479248
Batch 10/64 loss: 1.8010306358337402
Batch 11/64 loss: 1.6604952812194824
Batch 12/64 loss: 1.8308181762695312
Batch 13/64 loss: 1.7352561950683594
Batch 14/64 loss: 1.586324691772461
Batch 15/64 loss: 1.695814609527588
Batch 16/64 loss: 1.8351426124572754
Batch 17/64 loss: 1.7499027252197266
Batch 18/64 loss: 1.7267975807189941
Batch 19/64 loss: 1.6296100616455078
Batch 20/64 loss: 1.6453328132629395
Batch 21/64 loss: 1.6033854484558105
Batch 22/64 loss: 1.6302838325500488
Batch 23/64 loss: 1.606825828552246
Batch 24/64 loss: 1.6026105880737305
Batch 25/64 loss: 2.58510160446167
Batch 26/64 loss: 2.0311012268066406
Batch 27/64 loss: 1.7144999504089355
Batch 28/64 loss: 1.6884593963623047
Batch 29/64 loss: 1.872711181640625
Batch 30/64 loss: 1.6763882637023926
Batch 31/64 loss: 4.395934104919434
Batch 32/64 loss: 2.2554550170898438
Batch 33/64 loss: 1.786252498626709
Batch 34/64 loss: 1.5517778396606445
Batch 35/64 loss: 1.654491901397705
Batch 36/64 loss: 1.7199583053588867
Batch 37/64 loss: 1.6780571937561035
Batch 38/64 loss: 1.8264813423156738
Batch 39/64 loss: 1.5740275382995605
Batch 40/64 loss: 1.7558627128601074
Batch 41/64 loss: 1.747267246246338
Batch 42/64 loss: 1.796168327331543
Batch 43/64 loss: 1.5918965339660645
Batch 44/64 loss: 1.8413562774658203
Batch 45/64 loss: 1.720052719116211
Batch 46/64 loss: 1.6790342330932617
Batch 47/64 loss: 1.6046762466430664
Batch 48/64 loss: 1.743962287902832
Batch 49/64 loss: 1.9202008247375488
Batch 50/64 loss: 4.239872932434082
Batch 51/64 loss: 1.665689468383789
Batch 52/64 loss: 1.6901464462280273
Batch 53/64 loss: 1.5938000679016113
Batch 54/64 loss: 4.533508777618408
Batch 55/64 loss: 2.710280418395996
Batch 56/64 loss: 1.7479357719421387
Batch 57/64 loss: 1.5758700370788574
Batch 58/64 loss: 1.717961311340332
Batch 59/64 loss: 1.67582368850708
Batch 60/64 loss: 2.3285303115844727
Batch 61/64 loss: 1.6636524200439453
Batch 62/64 loss: 1.8128809928894043
Batch 63/64 loss: 1.6490936279296875
Batch 64/64 loss: -1.7794876098632812
Epoch 414  Train loss: 1.8701606900084253  Val loss: 1.4385771866106905
Epoch 415
-------------------------------
Batch 1/64 loss: 2.024069309234619
Batch 2/64 loss: 1.6103515625
Batch 3/64 loss: 1.8533763885498047
Batch 4/64 loss: 1.8487906455993652
Batch 5/64 loss: 1.7807440757751465
Batch 6/64 loss: 2.7395496368408203
Batch 7/64 loss: 1.65586519241333
Batch 8/64 loss: 1.715470314025879
Batch 9/64 loss: 1.7395200729370117
Batch 10/64 loss: 1.607780933380127
Batch 11/64 loss: 5.0653228759765625
Batch 12/64 loss: 3.795736312866211
Batch 13/64 loss: 1.9203248023986816
Batch 14/64 loss: 1.7327804565429688
Batch 15/64 loss: 1.8081560134887695
Batch 16/64 loss: 2.5384511947631836
Batch 17/64 loss: 1.6981902122497559
Batch 18/64 loss: 4.570169925689697
Batch 19/64 loss: 1.9877948760986328
Batch 20/64 loss: 1.6685094833374023
Batch 21/64 loss: 1.7223734855651855
Batch 22/64 loss: 1.909646987915039
Batch 23/64 loss: 1.6062955856323242
Batch 24/64 loss: 1.9590530395507812
Batch 25/64 loss: 2.3496923446655273
Batch 26/64 loss: 1.546241283416748
Batch 27/64 loss: 1.7901215553283691
Batch 28/64 loss: 1.697268009185791
Batch 29/64 loss: 1.6051387786865234
Batch 30/64 loss: 1.748335838317871
Batch 31/64 loss: 1.6498770713806152
Batch 32/64 loss: 1.8210015296936035
Batch 33/64 loss: 1.6178321838378906
Batch 34/64 loss: 2.695035457611084
Batch 35/64 loss: 1.750037670135498
Batch 36/64 loss: 1.6729698181152344
Batch 37/64 loss: 1.6824870109558105
Batch 38/64 loss: 1.7502331733703613
Batch 39/64 loss: 1.9199624061584473
Batch 40/64 loss: 1.9511656761169434
Batch 41/64 loss: 1.5922245979309082
Batch 42/64 loss: 1.7607841491699219
Batch 43/64 loss: 1.6383147239685059
Batch 44/64 loss: 1.6768403053283691
Batch 45/64 loss: 1.564589023590088
Batch 46/64 loss: 1.723790168762207
Batch 47/64 loss: 1.5919256210327148
Batch 48/64 loss: 1.5946059226989746
Batch 49/64 loss: 1.6429939270019531
Batch 50/64 loss: 1.8542594909667969
Batch 51/64 loss: 1.6497492790222168
Batch 52/64 loss: 1.7819151878356934
Batch 53/64 loss: 1.5709271430969238
Batch 54/64 loss: 1.835958480834961
Batch 55/64 loss: 1.771000862121582
Batch 56/64 loss: 1.7095460891723633
Batch 57/64 loss: 1.597649097442627
Batch 58/64 loss: 1.9136805534362793
Batch 59/64 loss: 1.681480884552002
Batch 60/64 loss: 1.6620745658874512
Batch 61/64 loss: 1.6745519638061523
Batch 62/64 loss: 1.7505788803100586
Batch 63/64 loss: 1.5345892906188965
Batch 64/64 loss: -1.8281803131103516
Epoch 415  Train loss: 1.8699391084558823  Val loss: 1.3878876073253934
Saving best model, epoch: 415
Epoch 416
-------------------------------
Batch 1/64 loss: 2.2414984703063965
Batch 2/64 loss: 1.624007225036621
Batch 3/64 loss: 1.9957427978515625
Batch 4/64 loss: 1.6168107986450195
Batch 5/64 loss: 1.970933437347412
Batch 6/64 loss: 1.98565673828125
Batch 7/64 loss: 1.5570721626281738
Batch 8/64 loss: 1.828110694885254
Batch 9/64 loss: 1.605771541595459
Batch 10/64 loss: 1.679847240447998
Batch 11/64 loss: 1.6021404266357422
Batch 12/64 loss: 1.8306598663330078
Batch 13/64 loss: 1.6321721076965332
Batch 14/64 loss: 1.5630183219909668
Batch 15/64 loss: 1.5999722480773926
Batch 16/64 loss: 1.6654572486877441
Batch 17/64 loss: 1.544064998626709
Batch 18/64 loss: 1.9179668426513672
Batch 19/64 loss: 1.7256813049316406
Batch 20/64 loss: 1.6006951332092285
Batch 21/64 loss: 2.597475528717041
Batch 22/64 loss: 1.6621313095092773
Batch 23/64 loss: 4.267389297485352
Batch 24/64 loss: 1.5982732772827148
Batch 25/64 loss: 2.975249767303467
Batch 26/64 loss: 2.101316452026367
Batch 27/64 loss: 1.6900911331176758
Batch 28/64 loss: 2.314995765686035
Batch 29/64 loss: 1.5902576446533203
Batch 30/64 loss: 1.8189640045166016
Batch 31/64 loss: 1.6750264167785645
Batch 32/64 loss: 5.489680767059326
Batch 33/64 loss: 1.588240146636963
Batch 34/64 loss: 1.8690385818481445
Batch 35/64 loss: 1.8159503936767578
Batch 36/64 loss: 1.5913195610046387
Batch 37/64 loss: 1.727156162261963
Batch 38/64 loss: 1.588864803314209
Batch 39/64 loss: 2.3257999420166016
Batch 40/64 loss: 1.623244285583496
Batch 41/64 loss: 3.7110185623168945
Batch 42/64 loss: 1.6273274421691895
Batch 43/64 loss: 1.6509156227111816
Batch 44/64 loss: 1.617093563079834
Batch 45/64 loss: 1.6241464614868164
Batch 46/64 loss: 1.6755146980285645
Batch 47/64 loss: 1.6282706260681152
Batch 48/64 loss: 1.7204790115356445
Batch 49/64 loss: 1.6847214698791504
Batch 50/64 loss: 1.7677111625671387
Batch 51/64 loss: 1.6471023559570312
Batch 52/64 loss: 1.7100186347961426
Batch 53/64 loss: 1.6835684776306152
Batch 54/64 loss: 1.56254243850708
Batch 55/64 loss: 1.6389617919921875
Batch 56/64 loss: 1.5918569564819336
Batch 57/64 loss: 1.6273117065429688
Batch 58/64 loss: 1.7307171821594238
Batch 59/64 loss: 1.6419296264648438
Batch 60/64 loss: 1.607612133026123
Batch 61/64 loss: 1.722093105316162
Batch 62/64 loss: 1.5255274772644043
Batch 63/64 loss: 1.5980987548828125
Batch 64/64 loss: -1.8573789596557617
Epoch 416  Train loss: 1.8399882335288853  Val loss: 1.3755895345891054
Saving best model, epoch: 416
Epoch 417
-------------------------------
Batch 1/64 loss: 1.5859465599060059
Batch 2/64 loss: 1.5978689193725586
Batch 3/64 loss: 1.6175971031188965
Batch 4/64 loss: 1.6961145401000977
Batch 5/64 loss: 1.8427457809448242
Batch 6/64 loss: 1.6373968124389648
Batch 7/64 loss: 1.6973471641540527
Batch 8/64 loss: 1.650071144104004
Batch 9/64 loss: 2.8836398124694824
Batch 10/64 loss: 1.9732956886291504
Batch 11/64 loss: 1.6850051879882812
Batch 12/64 loss: 1.7671499252319336
Batch 13/64 loss: 1.5877046585083008
Batch 14/64 loss: 1.6140131950378418
Batch 15/64 loss: 1.6309380531311035
Batch 16/64 loss: 1.4933676719665527
Batch 17/64 loss: 4.434170246124268
Batch 18/64 loss: 2.0351600646972656
Batch 19/64 loss: 1.7277255058288574
Batch 20/64 loss: 1.7240328788757324
Batch 21/64 loss: 2.312708854675293
Batch 22/64 loss: 1.7814750671386719
Batch 23/64 loss: 4.2754645347595215
Batch 24/64 loss: 2.7716917991638184
Batch 25/64 loss: 3.2955498695373535
Batch 26/64 loss: 2.163966655731201
Batch 27/64 loss: 2.6623449325561523
Batch 28/64 loss: 2.2887983322143555
Batch 29/64 loss: 2.3983263969421387
Batch 30/64 loss: 4.516274452209473
Batch 31/64 loss: 1.9527997970581055
Batch 32/64 loss: 2.9636287689208984
Batch 33/64 loss: 2.5500245094299316
Batch 34/64 loss: 2.1397552490234375
Batch 35/64 loss: 2.928046226501465
Batch 36/64 loss: 2.568955421447754
Batch 37/64 loss: 5.512110233306885
Batch 38/64 loss: 1.8755507469177246
Batch 39/64 loss: 2.5989532470703125
Batch 40/64 loss: 3.4715142250061035
Batch 41/64 loss: 2.6541433334350586
Batch 42/64 loss: 1.9703192710876465
Batch 43/64 loss: 2.2004470825195312
Batch 44/64 loss: 2.2762999534606934
Batch 45/64 loss: 2.252640724182129
Batch 46/64 loss: 2.213186740875244
Batch 47/64 loss: 2.8478078842163086
Batch 48/64 loss: 2.294708251953125
Batch 49/64 loss: 2.402949333190918
Batch 50/64 loss: 2.813405990600586
Batch 51/64 loss: 2.8600854873657227
Batch 52/64 loss: 2.0484461784362793
Batch 53/64 loss: 2.2151408195495605
Batch 54/64 loss: 2.3658251762390137
Batch 55/64 loss: 2.390458106994629
Batch 56/64 loss: 3.9879231452941895
Batch 57/64 loss: 1.9863953590393066
Batch 58/64 loss: 1.9922618865966797
Batch 59/64 loss: 2.129672050476074
Batch 60/64 loss: 2.6149606704711914
Batch 61/64 loss: 1.736466884613037
Batch 62/64 loss: 2.3185787200927734
Batch 63/64 loss: 2.1541528701782227
Batch 64/64 loss: -1.742340087890625
Epoch 417  Train loss: 2.326725507250019  Val loss: 1.984136325796855
Epoch 418
-------------------------------
Batch 1/64 loss: 2.063488483428955
Batch 2/64 loss: 1.925316333770752
Batch 3/64 loss: 1.781625747680664
Batch 4/64 loss: 1.967216968536377
Batch 5/64 loss: 1.9724411964416504
Batch 6/64 loss: 1.7490348815917969
Batch 7/64 loss: 2.9667253494262695
Batch 8/64 loss: 4.2757744789123535
Batch 9/64 loss: 1.9634852409362793
Batch 10/64 loss: 2.1821584701538086
Batch 11/64 loss: 2.150149345397949
Batch 12/64 loss: 1.6860027313232422
Batch 13/64 loss: 2.213315010070801
Batch 14/64 loss: 3.9921441078186035
Batch 15/64 loss: 2.313398838043213
Batch 16/64 loss: 1.6554555892944336
Batch 17/64 loss: 1.7746987342834473
Batch 18/64 loss: 3.2066731452941895
Batch 19/64 loss: 2.457301139831543
Batch 20/64 loss: 1.8995633125305176
Batch 21/64 loss: 2.5751914978027344
Batch 22/64 loss: 2.9862279891967773
Batch 23/64 loss: 5.020116806030273
Batch 24/64 loss: 2.446164131164551
Batch 25/64 loss: 1.753248691558838
Batch 26/64 loss: 2.0184149742126465
Batch 27/64 loss: 2.0175657272338867
Batch 28/64 loss: 1.9753828048706055
Batch 29/64 loss: 1.757077693939209
Batch 30/64 loss: 2.296171188354492
Batch 31/64 loss: 1.9244155883789062
Batch 32/64 loss: 1.800558090209961
Batch 33/64 loss: 1.8606886863708496
Batch 34/64 loss: 2.334836483001709
Batch 35/64 loss: 1.7550468444824219
Batch 36/64 loss: 2.828040599822998
Batch 37/64 loss: 1.7249813079833984
Batch 38/64 loss: 2.7245216369628906
Batch 39/64 loss: 1.964531421661377
Batch 40/64 loss: 1.873328685760498
Batch 41/64 loss: 2.0394372940063477
Batch 42/64 loss: 2.4165329933166504
Batch 43/64 loss: 1.8650517463684082
Batch 44/64 loss: 1.7085070610046387
Batch 45/64 loss: 1.8174195289611816
Batch 46/64 loss: 2.6736807823181152
Batch 47/64 loss: 2.548455238342285
Batch 48/64 loss: 1.7036538124084473
Batch 49/64 loss: 1.764768123626709
Batch 50/64 loss: 1.7116889953613281
Batch 51/64 loss: 1.6716079711914062
Batch 52/64 loss: 1.7446026802062988
Batch 53/64 loss: 2.0883960723876953
Batch 54/64 loss: 1.7241029739379883
Batch 55/64 loss: 1.9334497451782227
Batch 56/64 loss: 1.816826343536377
Batch 57/64 loss: 1.7372856140136719
Batch 58/64 loss: 2.1110754013061523
Batch 59/64 loss: 2.458467483520508
Batch 60/64 loss: 2.1079230308532715
Batch 61/64 loss: 1.6662073135375977
Batch 62/64 loss: 1.9297780990600586
Batch 63/64 loss: 1.9257855415344238
Batch 64/64 loss: -0.8802337646484375
Epoch 418  Train loss: 2.1386197408040366  Val loss: 1.5962825526076903
Epoch 419
-------------------------------
Batch 1/64 loss: 2.06107234954834
Batch 2/64 loss: 1.8142504692077637
Batch 3/64 loss: 1.6347546577453613
Batch 4/64 loss: 1.8813881874084473
Batch 5/64 loss: 1.8169431686401367
Batch 6/64 loss: 1.661055564880371
Batch 7/64 loss: 1.6807050704956055
Batch 8/64 loss: 1.5812592506408691
Batch 9/64 loss: 1.725538730621338
Batch 10/64 loss: 1.7348089218139648
Batch 11/64 loss: 1.9969277381896973
Batch 12/64 loss: 2.0460729598999023
Batch 13/64 loss: 1.62791109085083
Batch 14/64 loss: 1.7372841835021973
Batch 15/64 loss: 2.172900676727295
Batch 16/64 loss: 1.6856374740600586
Batch 17/64 loss: 1.7602005004882812
Batch 18/64 loss: 1.6660847663879395
Batch 19/64 loss: 4.799799919128418
Batch 20/64 loss: 1.8560471534729004
Batch 21/64 loss: 1.7688798904418945
Batch 22/64 loss: 1.78010892868042
Batch 23/64 loss: 3.043649673461914
Batch 24/64 loss: 2.451108932495117
Batch 25/64 loss: 1.7611908912658691
Batch 26/64 loss: 1.6559081077575684
Batch 27/64 loss: 1.8272342681884766
Batch 28/64 loss: 1.7797203063964844
Batch 29/64 loss: 3.70181941986084
Batch 30/64 loss: 1.623154640197754
Batch 31/64 loss: 1.7571911811828613
Batch 32/64 loss: 2.161207675933838
Batch 33/64 loss: 1.7964177131652832
Batch 34/64 loss: 1.7384600639343262
Batch 35/64 loss: 1.6992287635803223
Batch 36/64 loss: 1.7359113693237305
Batch 37/64 loss: 1.971956729888916
Batch 38/64 loss: 1.8104944229125977
Batch 39/64 loss: 4.445009231567383
Batch 40/64 loss: 2.4194650650024414
Batch 41/64 loss: 1.7650189399719238
Batch 42/64 loss: 2.4921531677246094
Batch 43/64 loss: 1.6975865364074707
Batch 44/64 loss: 1.798628330230713
Batch 45/64 loss: 1.8324847221374512
Batch 46/64 loss: 1.7370305061340332
Batch 47/64 loss: 2.0538525581359863
Batch 48/64 loss: 1.9898056983947754
Batch 49/64 loss: 1.823976993560791
Batch 50/64 loss: 1.6763896942138672
Batch 51/64 loss: 1.8078818321228027
Batch 52/64 loss: 2.997105121612549
Batch 53/64 loss: 2.0129833221435547
Batch 54/64 loss: 1.8123769760131836
Batch 55/64 loss: 2.1120710372924805
Batch 56/64 loss: 1.763411521911621
Batch 57/64 loss: 1.7478055953979492
Batch 58/64 loss: 1.7128357887268066
Batch 59/64 loss: 2.1465158462524414
Batch 60/64 loss: 1.927863597869873
Batch 61/64 loss: 2.0938005447387695
Batch 62/64 loss: 1.701028823852539
Batch 63/64 loss: 1.6327404975891113
Batch 64/64 loss: -1.786661148071289
Epoch 419  Train loss: 1.9586527356914445  Val loss: 1.5118083363955783
Epoch 420
-------------------------------
Batch 1/64 loss: 1.7312908172607422
Batch 2/64 loss: 2.029531478881836
Batch 3/64 loss: 1.6714253425598145
Batch 4/64 loss: 2.0817532539367676
Batch 5/64 loss: 1.8207178115844727
Batch 6/64 loss: 2.6798462867736816
Batch 7/64 loss: 1.7563486099243164
Batch 8/64 loss: 1.7028989791870117
Batch 9/64 loss: 1.7211012840270996
Batch 10/64 loss: 1.8217101097106934
Batch 11/64 loss: 1.8243818283081055
Batch 12/64 loss: 1.7527036666870117
Batch 13/64 loss: 2.2489376068115234
Batch 14/64 loss: 1.7903552055358887
Batch 15/64 loss: 1.6991791725158691
Batch 16/64 loss: 1.8404860496520996
Batch 17/64 loss: 1.6728153228759766
Batch 18/64 loss: 1.745008945465088
Batch 19/64 loss: 1.607304573059082
Batch 20/64 loss: 1.7200846672058105
Batch 21/64 loss: 1.8852019309997559
Batch 22/64 loss: 2.312537670135498
Batch 23/64 loss: 1.848463535308838
Batch 24/64 loss: 2.616678237915039
Batch 25/64 loss: 1.6791043281555176
Batch 26/64 loss: 1.7725868225097656
Batch 27/64 loss: 1.949070930480957
Batch 28/64 loss: 1.783897876739502
Batch 29/64 loss: 1.7064270973205566
Batch 30/64 loss: 1.8088006973266602
Batch 31/64 loss: 3.982463836669922
Batch 32/64 loss: 4.323565483093262
Batch 33/64 loss: 1.6944589614868164
Batch 34/64 loss: 1.9147367477416992
Batch 35/64 loss: 1.699540615081787
Batch 36/64 loss: 4.765195369720459
Batch 37/64 loss: 1.7442235946655273
Batch 38/64 loss: 1.8932275772094727
Batch 39/64 loss: 1.7127323150634766
Batch 40/64 loss: 1.8686408996582031
Batch 41/64 loss: 1.6909995079040527
Batch 42/64 loss: 1.622136116027832
Batch 43/64 loss: 1.5675692558288574
Batch 44/64 loss: 1.5525012016296387
Batch 45/64 loss: 2.5475664138793945
Batch 46/64 loss: 1.6402678489685059
Batch 47/64 loss: 1.816176414489746
Batch 48/64 loss: 1.918562889099121
Batch 49/64 loss: 1.666520118713379
Batch 50/64 loss: 1.9150161743164062
Batch 51/64 loss: 1.9234638214111328
Batch 52/64 loss: 2.8992395401000977
Batch 53/64 loss: 2.042757034301758
Batch 54/64 loss: 1.9008116722106934
Batch 55/64 loss: 2.1451358795166016
Batch 56/64 loss: 1.7264189720153809
Batch 57/64 loss: 2.0626626014709473
Batch 58/64 loss: 1.5790348052978516
Batch 59/64 loss: 1.731644630432129
Batch 60/64 loss: 1.7013530731201172
Batch 61/64 loss: 1.6977534294128418
Batch 62/64 loss: 1.739417552947998
Batch 63/64 loss: 1.6864123344421387
Batch 64/64 loss: -1.7577590942382812
Epoch 420  Train loss: 1.9346594118604472  Val loss: 1.5127414165903204
Epoch 421
-------------------------------
Batch 1/64 loss: 1.7331409454345703
Batch 2/64 loss: 4.237799644470215
Batch 3/64 loss: 1.5933876037597656
Batch 4/64 loss: 1.8714141845703125
Batch 5/64 loss: 4.143248558044434
Batch 6/64 loss: 2.403750419616699
Batch 7/64 loss: 1.7942848205566406
Batch 8/64 loss: 2.0497493743896484
Batch 9/64 loss: 2.209164619445801
Batch 10/64 loss: 1.7019243240356445
Batch 11/64 loss: 4.647224426269531
Batch 12/64 loss: 1.745262622833252
Batch 13/64 loss: 1.838430404663086
Batch 14/64 loss: 1.6428146362304688
Batch 15/64 loss: 1.7191901206970215
Batch 16/64 loss: 1.895775318145752
Batch 17/64 loss: 1.8211450576782227
Batch 18/64 loss: 1.6460075378417969
Batch 19/64 loss: 1.7188220024108887
Batch 20/64 loss: 1.7332544326782227
Batch 21/64 loss: 1.8244071006774902
Batch 22/64 loss: 1.6953163146972656
Batch 23/64 loss: 1.9827675819396973
Batch 24/64 loss: 1.735372543334961
Batch 25/64 loss: 1.7252087593078613
Batch 26/64 loss: 2.108520984649658
Batch 27/64 loss: 1.7082524299621582
Batch 28/64 loss: 1.6074161529541016
Batch 29/64 loss: 1.6537237167358398
Batch 30/64 loss: 1.7595100402832031
Batch 31/64 loss: 1.8104972839355469
Batch 32/64 loss: 1.692746639251709
Batch 33/64 loss: 1.5790448188781738
Batch 34/64 loss: 2.216733455657959
Batch 35/64 loss: 2.9172143936157227
Batch 36/64 loss: 1.6336922645568848
Batch 37/64 loss: 1.8290209770202637
Batch 38/64 loss: 1.7480969429016113
Batch 39/64 loss: 1.8447465896606445
Batch 40/64 loss: 1.6512508392333984
Batch 41/64 loss: 1.617741584777832
Batch 42/64 loss: 1.6187553405761719
Batch 43/64 loss: 1.6564674377441406
Batch 44/64 loss: 1.803694725036621
Batch 45/64 loss: 1.6518120765686035
Batch 46/64 loss: 1.8945865631103516
Batch 47/64 loss: 1.5730547904968262
Batch 48/64 loss: 1.6889996528625488
Batch 49/64 loss: 1.6885552406311035
Batch 50/64 loss: 1.7628002166748047
Batch 51/64 loss: 1.742161750793457
Batch 52/64 loss: 2.5501275062561035
Batch 53/64 loss: 1.7238316535949707
Batch 54/64 loss: 2.7652244567871094
Batch 55/64 loss: 1.7971200942993164
Batch 56/64 loss: 1.7987923622131348
Batch 57/64 loss: 1.5898585319519043
Batch 58/64 loss: 1.7728838920593262
Batch 59/64 loss: 1.7170181274414062
Batch 60/64 loss: 1.735525131225586
Batch 61/64 loss: 1.771921157836914
Batch 62/64 loss: 1.8920235633850098
Batch 63/64 loss: 1.8745336532592773
Batch 64/64 loss: -1.548971176147461
Epoch 421  Train loss: 1.9042367374195772  Val loss: 1.4856788661471756
Epoch 422
-------------------------------
Batch 1/64 loss: 1.6529698371887207
Batch 2/64 loss: 1.6483087539672852
Batch 3/64 loss: 1.8077116012573242
Batch 4/64 loss: 1.6595268249511719
Batch 5/64 loss: 4.178972244262695
Batch 6/64 loss: 1.8410677909851074
Batch 7/64 loss: 1.7236557006835938
Batch 8/64 loss: 1.6034116744995117
Batch 9/64 loss: 1.667428970336914
Batch 10/64 loss: 1.9114151000976562
Batch 11/64 loss: 1.7914457321166992
Batch 12/64 loss: 1.6275529861450195
Batch 13/64 loss: 2.006147861480713
Batch 14/64 loss: 1.73736572265625
Batch 15/64 loss: 2.2935171127319336
Batch 16/64 loss: 1.6938672065734863
Batch 17/64 loss: 1.889094352722168
Batch 18/64 loss: 1.7095117568969727
Batch 19/64 loss: 1.8015341758728027
Batch 20/64 loss: 4.896152019500732
Batch 21/64 loss: 1.7277436256408691
Batch 22/64 loss: 1.9459352493286133
Batch 23/64 loss: 2.053353786468506
Batch 24/64 loss: 1.7588615417480469
Batch 25/64 loss: 1.586543083190918
Batch 26/64 loss: 1.7653284072875977
Batch 27/64 loss: 1.716993808746338
Batch 28/64 loss: 1.6894574165344238
Batch 29/64 loss: 1.7542648315429688
Batch 30/64 loss: 1.7562947273254395
Batch 31/64 loss: 1.797314167022705
Batch 32/64 loss: 1.8170580863952637
Batch 33/64 loss: 2.78695011138916
Batch 34/64 loss: 1.7030234336853027
Batch 35/64 loss: 1.7896413803100586
Batch 36/64 loss: 1.8684754371643066
Batch 37/64 loss: 2.5648980140686035
Batch 38/64 loss: 1.6586170196533203
Batch 39/64 loss: 1.7540836334228516
Batch 40/64 loss: 1.9015116691589355
Batch 41/64 loss: 1.6718831062316895
Batch 42/64 loss: 1.8191161155700684
Batch 43/64 loss: 1.571629524230957
Batch 44/64 loss: 1.7250456809997559
Batch 45/64 loss: 1.7287096977233887
Batch 46/64 loss: 3.7309017181396484
Batch 47/64 loss: 1.8542218208312988
Batch 48/64 loss: 1.6550664901733398
Batch 49/64 loss: 1.6479854583740234
Batch 50/64 loss: 1.7757587432861328
Batch 51/64 loss: 1.8408575057983398
Batch 52/64 loss: 2.0666751861572266
Batch 53/64 loss: 1.5802431106567383
Batch 54/64 loss: 1.6259002685546875
Batch 55/64 loss: 1.6832637786865234
Batch 56/64 loss: 1.7223272323608398
Batch 57/64 loss: 2.2201709747314453
Batch 58/64 loss: 2.8805160522460938
Batch 59/64 loss: 2.622199058532715
Batch 60/64 loss: 1.9507484436035156
Batch 61/64 loss: 1.967268466949463
Batch 62/64 loss: 1.483705997467041
Batch 63/64 loss: 2.4776291847229004
Batch 64/64 loss: -1.8890295028686523
Epoch 422  Train loss: 1.9203460132374484  Val loss: 1.3913910462684238
Epoch 423
-------------------------------
Batch 1/64 loss: 1.8091607093811035
Batch 2/64 loss: 1.5991830825805664
Batch 3/64 loss: 2.7985920906066895
Batch 4/64 loss: 4.073997974395752
Batch 5/64 loss: 1.7633967399597168
Batch 6/64 loss: 1.6867694854736328
Batch 7/64 loss: 1.667463779449463
Batch 8/64 loss: 1.7270970344543457
Batch 9/64 loss: 1.7464327812194824
Batch 10/64 loss: 1.9734687805175781
Batch 11/64 loss: 3.132032871246338
Batch 12/64 loss: 1.5946335792541504
Batch 13/64 loss: 1.9068050384521484
Batch 14/64 loss: 1.9771156311035156
Batch 15/64 loss: 1.9231305122375488
Batch 16/64 loss: 1.848623275756836
Batch 17/64 loss: 1.63163423538208
Batch 18/64 loss: 1.890920639038086
Batch 19/64 loss: 1.6459174156188965
Batch 20/64 loss: 1.7059898376464844
Batch 21/64 loss: 1.7081174850463867
Batch 22/64 loss: 1.6576666831970215
Batch 23/64 loss: 1.6909561157226562
Batch 24/64 loss: 1.5576272010803223
Batch 25/64 loss: 1.7243223190307617
Batch 26/64 loss: 1.663456916809082
Batch 27/64 loss: 1.5658869743347168
Batch 28/64 loss: 1.6445903778076172
Batch 29/64 loss: 1.802961826324463
Batch 30/64 loss: 1.6615047454833984
Batch 31/64 loss: 1.8634843826293945
Batch 32/64 loss: 2.005953788757324
Batch 33/64 loss: 1.6478238105773926
Batch 34/64 loss: 1.7380685806274414
Batch 35/64 loss: 1.6573081016540527
Batch 36/64 loss: 1.7056360244750977
Batch 37/64 loss: 1.6917400360107422
Batch 38/64 loss: 1.8219332695007324
Batch 39/64 loss: 1.6420702934265137
Batch 40/64 loss: 1.6634502410888672
Batch 41/64 loss: 1.7734975814819336
Batch 42/64 loss: 2.0327916145324707
Batch 43/64 loss: 1.6768608093261719
Batch 44/64 loss: 1.624922275543213
Batch 45/64 loss: 1.534041404724121
Batch 46/64 loss: 1.6391329765319824
Batch 47/64 loss: 1.6153178215026855
Batch 48/64 loss: 1.6871562004089355
Batch 49/64 loss: 2.1229043006896973
Batch 50/64 loss: 1.7307190895080566
Batch 51/64 loss: 2.814079761505127
Batch 52/64 loss: 1.7317156791687012
Batch 53/64 loss: 1.7302379608154297
Batch 54/64 loss: 1.7162256240844727
Batch 55/64 loss: 3.9772067070007324
Batch 56/64 loss: 1.6448698043823242
Batch 57/64 loss: 2.558647632598877
Batch 58/64 loss: 1.7360568046569824
Batch 59/64 loss: 1.5904617309570312
Batch 60/64 loss: 1.6773605346679688
Batch 61/64 loss: 1.798055648803711
Batch 62/64 loss: 1.7364063262939453
Batch 63/64 loss: 4.602609634399414
Batch 64/64 loss: -1.7339773178100586
Epoch 423  Train loss: 1.8771406996483897  Val loss: 1.3916441009626357
Epoch 424
-------------------------------
Batch 1/64 loss: 1.6199312210083008
Batch 2/64 loss: 1.649190902709961
Batch 3/64 loss: 1.7628731727600098
Batch 4/64 loss: 1.8098468780517578
Batch 5/64 loss: 1.5666770935058594
Batch 6/64 loss: 1.9815726280212402
Batch 7/64 loss: 3.6811728477478027
Batch 8/64 loss: 1.593066692352295
Batch 9/64 loss: 1.739931583404541
Batch 10/64 loss: 1.6595540046691895
Batch 11/64 loss: 1.6113405227661133
Batch 12/64 loss: 1.7472357749938965
Batch 13/64 loss: 1.692857265472412
Batch 14/64 loss: 1.5883870124816895
Batch 15/64 loss: 1.7627005577087402
Batch 16/64 loss: 2.7964529991149902
Batch 17/64 loss: 1.5756335258483887
Batch 18/64 loss: 2.214625358581543
Batch 19/64 loss: 1.9795598983764648
Batch 20/64 loss: 1.7013392448425293
Batch 21/64 loss: 1.7564306259155273
Batch 22/64 loss: 2.7033748626708984
Batch 23/64 loss: 1.9689006805419922
Batch 24/64 loss: 2.1564064025878906
Batch 25/64 loss: 1.6531062126159668
Batch 26/64 loss: 1.7951750755310059
Batch 27/64 loss: 1.8791203498840332
Batch 28/64 loss: 1.771528720855713
Batch 29/64 loss: 1.7893996238708496
Batch 30/64 loss: 1.5879497528076172
Batch 31/64 loss: 1.6417264938354492
Batch 32/64 loss: 1.6026191711425781
Batch 33/64 loss: 1.6584296226501465
Batch 34/64 loss: 1.6363019943237305
Batch 35/64 loss: 3.393721103668213
Batch 36/64 loss: 4.706334590911865
Batch 37/64 loss: 1.8538603782653809
Batch 38/64 loss: 1.6383566856384277
Batch 39/64 loss: 1.715461254119873
Batch 40/64 loss: 1.6212658882141113
Batch 41/64 loss: 1.6395955085754395
Batch 42/64 loss: 1.6856584548950195
Batch 43/64 loss: 1.7257146835327148
Batch 44/64 loss: 1.7391366958618164
Batch 45/64 loss: 2.230679988861084
Batch 46/64 loss: 1.7157564163208008
Batch 47/64 loss: 1.751920223236084
Batch 48/64 loss: 1.698556900024414
Batch 49/64 loss: 1.570803165435791
Batch 50/64 loss: 4.214723587036133
Batch 51/64 loss: 1.6789274215698242
Batch 52/64 loss: 1.6879420280456543
Batch 53/64 loss: 1.7529349327087402
Batch 54/64 loss: 1.6653738021850586
Batch 55/64 loss: 1.7339887619018555
Batch 56/64 loss: 1.6124672889709473
Batch 57/64 loss: 1.7667818069458008
Batch 58/64 loss: 1.9543452262878418
Batch 59/64 loss: 1.9408884048461914
Batch 60/64 loss: 1.8859410285949707
Batch 61/64 loss: 1.6423425674438477
Batch 62/64 loss: 1.7344131469726562
Batch 63/64 loss: 1.7612910270690918
Batch 64/64 loss: -1.8829832077026367
Epoch 424  Train loss: 1.8767272837021771  Val loss: 1.432342031157713
Epoch 425
-------------------------------
Batch 1/64 loss: 1.928882122039795
Batch 2/64 loss: 1.7903904914855957
Batch 3/64 loss: 1.8165497779846191
Batch 4/64 loss: 5.024020671844482
Batch 5/64 loss: 2.138549327850342
Batch 6/64 loss: 1.770050048828125
Batch 7/64 loss: 1.7952470779418945
Batch 8/64 loss: 1.6832842826843262
Batch 9/64 loss: 2.811786651611328
Batch 10/64 loss: 1.640324592590332
Batch 11/64 loss: 1.5973854064941406
Batch 12/64 loss: 1.6584453582763672
Batch 13/64 loss: 2.5101027488708496
Batch 14/64 loss: 1.8866748809814453
Batch 15/64 loss: 1.691713809967041
Batch 16/64 loss: 1.5802421569824219
Batch 17/64 loss: 2.535900592803955
Batch 18/64 loss: 1.588179588317871
Batch 19/64 loss: 1.809953212738037
Batch 20/64 loss: 1.7270960807800293
Batch 21/64 loss: 4.227016925811768
Batch 22/64 loss: 1.6111135482788086
Batch 23/64 loss: 1.7177939414978027
Batch 24/64 loss: 1.7592220306396484
Batch 25/64 loss: 1.8094325065612793
Batch 26/64 loss: 1.5599913597106934
Batch 27/64 loss: 1.811659336090088
Batch 28/64 loss: 1.8410425186157227
Batch 29/64 loss: 1.8807430267333984
Batch 30/64 loss: 1.709024429321289
Batch 31/64 loss: 1.5658483505249023
Batch 32/64 loss: 1.516331672668457
Batch 33/64 loss: 1.7554669380187988
Batch 34/64 loss: 1.7288107872009277
Batch 35/64 loss: 1.6138801574707031
Batch 36/64 loss: 1.8056840896606445
Batch 37/64 loss: 1.746222972869873
Batch 38/64 loss: 1.583561897277832
Batch 39/64 loss: 1.5981144905090332
Batch 40/64 loss: 2.0424375534057617
Batch 41/64 loss: 1.7823009490966797
Batch 42/64 loss: 1.6931495666503906
Batch 43/64 loss: 2.8309788703918457
Batch 44/64 loss: 1.62158203125
Batch 45/64 loss: 1.7481160163879395
Batch 46/64 loss: 1.6105918884277344
Batch 47/64 loss: 2.0267715454101562
Batch 48/64 loss: 1.6109628677368164
Batch 49/64 loss: 1.5933971405029297
Batch 50/64 loss: 1.6475090980529785
Batch 51/64 loss: 1.6475353240966797
Batch 52/64 loss: 1.9392504692077637
Batch 53/64 loss: 2.176041603088379
Batch 54/64 loss: 3.922244071960449
Batch 55/64 loss: 1.627793788909912
Batch 56/64 loss: 1.8779325485229492
Batch 57/64 loss: 1.6990575790405273
Batch 58/64 loss: 2.025055408477783
Batch 59/64 loss: 1.8329505920410156
Batch 60/64 loss: 1.7155227661132812
Batch 61/64 loss: 1.6026630401611328
Batch 62/64 loss: 1.7802410125732422
Batch 63/64 loss: 2.0317158699035645
Batch 64/64 loss: -1.8042373657226562
Epoch 425  Train loss: 1.8911115833357268  Val loss: 1.4660176673705636
Epoch 426
-------------------------------
Batch 1/64 loss: 1.812251091003418
Batch 2/64 loss: 1.676417350769043
Batch 3/64 loss: 1.9744105339050293
Batch 4/64 loss: 1.679694652557373
Batch 5/64 loss: 1.697481632232666
Batch 6/64 loss: 1.5374188423156738
Batch 7/64 loss: 2.3522777557373047
Batch 8/64 loss: 1.674558162689209
Batch 9/64 loss: 4.87409782409668
Batch 10/64 loss: 1.5192294120788574
Batch 11/64 loss: 2.0198211669921875
Batch 12/64 loss: 1.664088249206543
Batch 13/64 loss: 1.7319011688232422
Batch 14/64 loss: 1.6817874908447266
Batch 15/64 loss: 2.7439937591552734
Batch 16/64 loss: 1.6089844703674316
Batch 17/64 loss: 1.608741283416748
Batch 18/64 loss: 1.7431321144104004
Batch 19/64 loss: 1.7321577072143555
Batch 20/64 loss: 1.8803482055664062
Batch 21/64 loss: 1.7318439483642578
Batch 22/64 loss: 1.9998908042907715
Batch 23/64 loss: 1.8324809074401855
Batch 24/64 loss: 1.6743688583374023
Batch 25/64 loss: 4.6200127601623535
Batch 26/64 loss: 2.2651147842407227
Batch 27/64 loss: 1.6311230659484863
Batch 28/64 loss: 1.858872413635254
Batch 29/64 loss: 1.6278929710388184
Batch 30/64 loss: 1.757126808166504
Batch 31/64 loss: 1.8539705276489258
Batch 32/64 loss: 1.7111163139343262
Batch 33/64 loss: 1.7748126983642578
Batch 34/64 loss: 1.8078947067260742
Batch 35/64 loss: 4.000600337982178
Batch 36/64 loss: 1.6055502891540527
Batch 37/64 loss: 1.757723331451416
Batch 38/64 loss: 2.8260741233825684
Batch 39/64 loss: 2.2884364128112793
Batch 40/64 loss: 1.6734228134155273
Batch 41/64 loss: 1.759730339050293
Batch 42/64 loss: 1.8914804458618164
Batch 43/64 loss: 1.6007919311523438
Batch 44/64 loss: 1.7249422073364258
Batch 45/64 loss: 1.5700631141662598
Batch 46/64 loss: 1.7032051086425781
Batch 47/64 loss: 1.6305475234985352
Batch 48/64 loss: 1.5713305473327637
Batch 49/64 loss: 1.5785646438598633
Batch 50/64 loss: 1.8127140998840332
Batch 51/64 loss: 2.0727596282958984
Batch 52/64 loss: 1.9290480613708496
Batch 53/64 loss: 1.68949556350708
Batch 54/64 loss: 1.7384018898010254
Batch 55/64 loss: 1.802807331085205
Batch 56/64 loss: 1.8334074020385742
Batch 57/64 loss: 1.6007928848266602
Batch 58/64 loss: 1.836277961730957
Batch 59/64 loss: 1.7239012718200684
Batch 60/64 loss: 1.6044893264770508
Batch 61/64 loss: 2.000122547149658
Batch 62/64 loss: 1.6060724258422852
Batch 63/64 loss: 1.6285929679870605
Batch 64/64 loss: -1.8914265632629395
Epoch 426  Train loss: 1.882385741963106  Val loss: 1.4978804571931714
Epoch 427
-------------------------------
Batch 1/64 loss: 1.6400952339172363
Batch 2/64 loss: 1.666254997253418
Batch 3/64 loss: 2.1499948501586914
Batch 4/64 loss: 1.8111400604248047
Batch 5/64 loss: 1.762467861175537
Batch 6/64 loss: 1.950240135192871
Batch 7/64 loss: 1.6408305168151855
Batch 8/64 loss: 2.046459197998047
Batch 9/64 loss: 1.6362004280090332
Batch 10/64 loss: 2.170985221862793
Batch 11/64 loss: 2.4246912002563477
Batch 12/64 loss: 1.8804678916931152
Batch 13/64 loss: 1.6587138175964355
Batch 14/64 loss: 1.756143569946289
Batch 15/64 loss: 1.6624021530151367
Batch 16/64 loss: 1.8403525352478027
Batch 17/64 loss: 2.654867649078369
Batch 18/64 loss: 3.830813407897949
Batch 19/64 loss: 1.8127918243408203
Batch 20/64 loss: 1.657872200012207
Batch 21/64 loss: 1.6088461875915527
Batch 22/64 loss: 2.622053623199463
Batch 23/64 loss: 1.6755170822143555
Batch 24/64 loss: 1.7460246086120605
Batch 25/64 loss: 2.0394649505615234
Batch 26/64 loss: 1.5378203392028809
Batch 27/64 loss: 2.859714984893799
Batch 28/64 loss: 1.6337366104125977
Batch 29/64 loss: 1.6071181297302246
Batch 30/64 loss: 1.6072726249694824
Batch 31/64 loss: 4.141942977905273
Batch 32/64 loss: 1.6533493995666504
Batch 33/64 loss: 2.36806583404541
Batch 34/64 loss: 1.6676621437072754
Batch 35/64 loss: 1.6764311790466309
Batch 36/64 loss: 1.663278579711914
Batch 37/64 loss: 1.5691776275634766
Batch 38/64 loss: 1.5751023292541504
Batch 39/64 loss: 2.3111114501953125
Batch 40/64 loss: 1.7853636741638184
Batch 41/64 loss: 1.7001862525939941
Batch 42/64 loss: 2.2441530227661133
Batch 43/64 loss: 1.647740364074707
Batch 44/64 loss: 4.533925533294678
Batch 45/64 loss: 1.9910297393798828
Batch 46/64 loss: 1.7025761604309082
Batch 47/64 loss: 1.7956619262695312
Batch 48/64 loss: 1.586472511291504
Batch 49/64 loss: 1.5870413780212402
Batch 50/64 loss: 1.6035356521606445
Batch 51/64 loss: 1.807115077972412
Batch 52/64 loss: 1.6420502662658691
Batch 53/64 loss: 1.9933280944824219
Batch 54/64 loss: 1.548853874206543
Batch 55/64 loss: 1.724484920501709
Batch 56/64 loss: 1.6188344955444336
Batch 57/64 loss: 1.8133115768432617
Batch 58/64 loss: 1.9919867515563965
Batch 59/64 loss: 1.637502670288086
Batch 60/64 loss: 1.6540336608886719
Batch 61/64 loss: 1.777245044708252
Batch 62/64 loss: 1.6460719108581543
Batch 63/64 loss: 1.6887378692626953
Batch 64/64 loss: -1.892704963684082
Epoch 427  Train loss: 1.8904970842249254  Val loss: 1.3644365264787706
Saving best model, epoch: 427
Epoch 428
-------------------------------
Batch 1/64 loss: 2.2518324851989746
Batch 2/64 loss: 1.5848021507263184
Batch 3/64 loss: 1.839165210723877
Batch 4/64 loss: 1.8739047050476074
Batch 5/64 loss: 4.128598690032959
Batch 6/64 loss: 1.741405963897705
Batch 7/64 loss: 2.0605320930480957
Batch 8/64 loss: 1.6427645683288574
Batch 9/64 loss: 1.6204800605773926
Batch 10/64 loss: 1.9357690811157227
Batch 11/64 loss: 1.5482640266418457
Batch 12/64 loss: 1.920607089996338
Batch 13/64 loss: 1.6642498970031738
Batch 14/64 loss: 1.581552505493164
Batch 15/64 loss: 1.5482335090637207
Batch 16/64 loss: 1.89021635055542
Batch 17/64 loss: 1.7427978515625
Batch 18/64 loss: 1.600416660308838
Batch 19/64 loss: 1.682116985321045
Batch 20/64 loss: 1.7128381729125977
Batch 21/64 loss: 1.6645941734313965
Batch 22/64 loss: 2.2803406715393066
Batch 23/64 loss: 1.560053825378418
Batch 24/64 loss: 3.681140422821045
Batch 25/64 loss: 1.6609973907470703
Batch 26/64 loss: 3.0794167518615723
Batch 27/64 loss: 1.712845802307129
Batch 28/64 loss: 2.788872718811035
Batch 29/64 loss: 1.7323923110961914
Batch 30/64 loss: 2.524552345275879
Batch 31/64 loss: 1.6389741897583008
Batch 32/64 loss: 1.6094632148742676
Batch 33/64 loss: 1.6654419898986816
Batch 34/64 loss: 1.8463435173034668
Batch 35/64 loss: 1.8891239166259766
Batch 36/64 loss: 1.5545825958251953
Batch 37/64 loss: 1.511551856994629
Batch 38/64 loss: 2.383148670196533
Batch 39/64 loss: 1.698045253753662
Batch 40/64 loss: 1.6744379997253418
Batch 41/64 loss: 4.771609783172607
Batch 42/64 loss: 1.5982542037963867
Batch 43/64 loss: 1.5267457962036133
Batch 44/64 loss: 1.8009181022644043
Batch 45/64 loss: 1.6375536918640137
Batch 46/64 loss: 1.6875638961791992
Batch 47/64 loss: 1.615757942199707
Batch 48/64 loss: 1.683117389678955
Batch 49/64 loss: 1.643326759338379
Batch 50/64 loss: 1.7642312049865723
Batch 51/64 loss: 1.6221776008605957
Batch 52/64 loss: 1.5931596755981445
Batch 53/64 loss: 1.8106341361999512
Batch 54/64 loss: 1.539041519165039
Batch 55/64 loss: 1.9604802131652832
Batch 56/64 loss: 1.9130744934082031
Batch 57/64 loss: 1.658155918121338
Batch 58/64 loss: 1.6626200675964355
Batch 59/64 loss: 1.7572288513183594
Batch 60/64 loss: 1.6125078201293945
Batch 61/64 loss: 1.6722869873046875
Batch 62/64 loss: 1.6290225982666016
Batch 63/64 loss: 1.705521583557129
Batch 64/64 loss: -1.781111717224121
Epoch 428  Train loss: 1.8549964568194222  Val loss: 1.4040116772209246
Epoch 429
-------------------------------
Batch 1/64 loss: 1.7247190475463867
Batch 2/64 loss: 1.6493415832519531
Batch 3/64 loss: 1.7702603340148926
Batch 4/64 loss: 2.229045867919922
Batch 5/64 loss: 1.613265037536621
Batch 6/64 loss: 1.5105509757995605
Batch 7/64 loss: 1.5902867317199707
Batch 8/64 loss: 1.6641969680786133
Batch 9/64 loss: 4.124460697174072
Batch 10/64 loss: 1.674551010131836
Batch 11/64 loss: 1.609121322631836
Batch 12/64 loss: 1.5651512145996094
Batch 13/64 loss: 1.510200023651123
Batch 14/64 loss: 2.943233013153076
Batch 15/64 loss: 1.7267227172851562
Batch 16/64 loss: 1.6638898849487305
Batch 17/64 loss: 2.8449783325195312
Batch 18/64 loss: 1.684586524963379
Batch 19/64 loss: 3.6414222717285156
Batch 20/64 loss: 1.5733957290649414
Batch 21/64 loss: 1.8193292617797852
Batch 22/64 loss: 1.6590523719787598
Batch 23/64 loss: 1.8454699516296387
Batch 24/64 loss: 1.626244068145752
Batch 25/64 loss: 1.7919187545776367
Batch 26/64 loss: 1.6361193656921387
Batch 27/64 loss: 1.9318385124206543
Batch 28/64 loss: 1.7082195281982422
Batch 29/64 loss: 2.1549010276794434
Batch 30/64 loss: 1.7166967391967773
Batch 31/64 loss: 1.5151138305664062
Batch 32/64 loss: 1.6245574951171875
Batch 33/64 loss: 1.6496520042419434
Batch 34/64 loss: 2.3149752616882324
Batch 35/64 loss: 4.722475051879883
Batch 36/64 loss: 1.65128755569458
Batch 37/64 loss: 2.027129650115967
Batch 38/64 loss: 1.6653389930725098
Batch 39/64 loss: 1.671339988708496
Batch 40/64 loss: 1.6745686531066895
Batch 41/64 loss: 1.969245433807373
Batch 42/64 loss: 1.6375279426574707
Batch 43/64 loss: 1.7949204444885254
Batch 44/64 loss: 1.837846279144287
Batch 45/64 loss: 1.593780517578125
Batch 46/64 loss: 1.6007766723632812
Batch 47/64 loss: 1.6773433685302734
Batch 48/64 loss: 1.6786603927612305
Batch 49/64 loss: 1.684434413909912
Batch 50/64 loss: 1.6375083923339844
Batch 51/64 loss: 1.7188591957092285
Batch 52/64 loss: 1.614394187927246
Batch 53/64 loss: 1.6001038551330566
Batch 54/64 loss: 2.545567035675049
Batch 55/64 loss: 2.2367687225341797
Batch 56/64 loss: 1.5600943565368652
Batch 57/64 loss: 1.9038934707641602
Batch 58/64 loss: 1.7288031578063965
Batch 59/64 loss: 1.595360279083252
Batch 60/64 loss: 1.7260851860046387
Batch 61/64 loss: 2.05703067779541
Batch 62/64 loss: 1.727524757385254
Batch 63/64 loss: 1.6818113327026367
Batch 64/64 loss: -1.8075199127197266
Epoch 429  Train loss: 1.8536832547655293  Val loss: 1.4245978942032123
Epoch 430
-------------------------------
Batch 1/64 loss: 1.610713005065918
Batch 2/64 loss: 1.7758588790893555
Batch 3/64 loss: 2.0877685546875
Batch 4/64 loss: 1.7584381103515625
Batch 5/64 loss: 1.7031173706054688
Batch 6/64 loss: 1.717454433441162
Batch 7/64 loss: 2.2258052825927734
Batch 8/64 loss: 1.6817851066589355
Batch 9/64 loss: 2.6743087768554688
Batch 10/64 loss: 1.694075584411621
Batch 11/64 loss: 1.7853341102600098
Batch 12/64 loss: 1.5613207817077637
Batch 13/64 loss: 1.677126407623291
Batch 14/64 loss: 1.6104254722595215
Batch 15/64 loss: 3.796903610229492
Batch 16/64 loss: 2.39860200881958
Batch 17/64 loss: 1.6689691543579102
Batch 18/64 loss: 1.5740776062011719
Batch 19/64 loss: 1.9295172691345215
Batch 20/64 loss: 1.6201930046081543
Batch 21/64 loss: 1.5555353164672852
Batch 22/64 loss: 1.7890625
Batch 23/64 loss: 1.6712064743041992
Batch 24/64 loss: 1.5896296501159668
Batch 25/64 loss: 1.8226318359375
Batch 26/64 loss: 2.455864906311035
Batch 27/64 loss: 1.5712499618530273
Batch 28/64 loss: 1.5832881927490234
Batch 29/64 loss: 1.633455753326416
Batch 30/64 loss: 1.6935968399047852
Batch 31/64 loss: 1.6049251556396484
Batch 32/64 loss: 1.6449179649353027
Batch 33/64 loss: 1.571878433227539
Batch 34/64 loss: 1.6151628494262695
Batch 35/64 loss: 1.676252841949463
Batch 36/64 loss: 1.5472326278686523
Batch 37/64 loss: 2.1479415893554688
Batch 38/64 loss: 1.7346692085266113
Batch 39/64 loss: 4.896032333374023
Batch 40/64 loss: 1.7760238647460938
Batch 41/64 loss: 1.7088861465454102
Batch 42/64 loss: 1.5664596557617188
Batch 43/64 loss: 1.702326774597168
Batch 44/64 loss: 1.81642484664917
Batch 45/64 loss: 1.547767162322998
Batch 46/64 loss: 1.5780515670776367
Batch 47/64 loss: 1.6706171035766602
Batch 48/64 loss: 1.8146743774414062
Batch 49/64 loss: 1.90972900390625
Batch 50/64 loss: 1.739525318145752
Batch 51/64 loss: 1.7376108169555664
Batch 52/64 loss: 1.7621245384216309
Batch 53/64 loss: 1.7696247100830078
Batch 54/64 loss: 1.6156139373779297
Batch 55/64 loss: 4.943812370300293
Batch 56/64 loss: 1.544151782989502
Batch 57/64 loss: 1.901383876800537
Batch 58/64 loss: 1.7830424308776855
Batch 59/64 loss: 1.7925772666931152
Batch 60/64 loss: 1.6901593208312988
Batch 61/64 loss: 1.711507797241211
Batch 62/64 loss: 1.671177864074707
Batch 63/64 loss: 1.5188226699829102
Batch 64/64 loss: -1.8150291442871094
Epoch 430  Train loss: 1.8394847421085134  Val loss: 1.4039669757856126
Epoch 431
-------------------------------
Batch 1/64 loss: 1.569767951965332
Batch 2/64 loss: 1.7556734085083008
Batch 3/64 loss: 2.774089813232422
Batch 4/64 loss: 1.9814162254333496
Batch 5/64 loss: 1.6649913787841797
Batch 6/64 loss: 3.7777414321899414
Batch 7/64 loss: 2.7145705223083496
Batch 8/64 loss: 1.7697300910949707
Batch 9/64 loss: 1.6214966773986816
Batch 10/64 loss: 1.6771416664123535
Batch 11/64 loss: 1.5205168724060059
Batch 12/64 loss: 1.9167604446411133
Batch 13/64 loss: 1.5128273963928223
Batch 14/64 loss: 1.8348298072814941
Batch 15/64 loss: 1.6486091613769531
Batch 16/64 loss: 2.4555411338806152
Batch 17/64 loss: 1.5436806678771973
Batch 18/64 loss: 1.696439266204834
Batch 19/64 loss: 1.5906543731689453
Batch 20/64 loss: 1.5324387550354004
Batch 21/64 loss: 1.8873324394226074
Batch 22/64 loss: 1.7665224075317383
Batch 23/64 loss: 1.5781736373901367
Batch 24/64 loss: 1.7826008796691895
Batch 25/64 loss: 1.7603960037231445
Batch 26/64 loss: 2.0437326431274414
Batch 27/64 loss: 1.6326608657836914
Batch 28/64 loss: 1.45280122756958
Batch 29/64 loss: 1.7220993041992188
Batch 30/64 loss: 4.136348247528076
Batch 31/64 loss: 2.3577213287353516
Batch 32/64 loss: 1.6584711074829102
Batch 33/64 loss: 1.6782746315002441
Batch 34/64 loss: 1.933784008026123
Batch 35/64 loss: 1.9048457145690918
Batch 36/64 loss: 1.630971908569336
Batch 37/64 loss: 1.6196227073669434
Batch 38/64 loss: 1.803140640258789
Batch 39/64 loss: 1.7633605003356934
Batch 40/64 loss: 1.606947898864746
Batch 41/64 loss: 1.7019295692443848
Batch 42/64 loss: 1.7646565437316895
Batch 43/64 loss: 1.9908466339111328
Batch 44/64 loss: 2.0398592948913574
Batch 45/64 loss: 1.678062915802002
Batch 46/64 loss: 1.6310811042785645
Batch 47/64 loss: 1.5486674308776855
Batch 48/64 loss: 1.6811957359313965
Batch 49/64 loss: 1.721947193145752
Batch 50/64 loss: 1.7588372230529785
Batch 51/64 loss: 1.7409110069274902
Batch 52/64 loss: 4.610023498535156
Batch 53/64 loss: 1.8839244842529297
Batch 54/64 loss: 1.7483758926391602
Batch 55/64 loss: 1.6016321182250977
Batch 56/64 loss: 1.704099178314209
Batch 57/64 loss: 1.5602984428405762
Batch 58/64 loss: 1.5812458992004395
Batch 59/64 loss: 1.4734554290771484
Batch 60/64 loss: 1.5984001159667969
Batch 61/64 loss: 1.693068504333496
Batch 62/64 loss: 2.4643845558166504
Batch 63/64 loss: 1.573702335357666
Batch 64/64 loss: -1.6986055374145508
Epoch 431  Train loss: 1.847143154518277  Val loss: 1.4947063275628893
Epoch 432
-------------------------------
Batch 1/64 loss: 4.6725640296936035
Batch 2/64 loss: 1.6504158973693848
Batch 3/64 loss: 1.7422447204589844
Batch 4/64 loss: 1.705885410308838
Batch 5/64 loss: 1.8753252029418945
Batch 6/64 loss: 1.692357063293457
Batch 7/64 loss: 1.7043581008911133
Batch 8/64 loss: 1.6425328254699707
Batch 9/64 loss: 1.61268949508667
Batch 10/64 loss: 1.5207629203796387
Batch 11/64 loss: 1.5614347457885742
Batch 12/64 loss: 1.628591537475586
Batch 13/64 loss: 1.6624865531921387
Batch 14/64 loss: 1.75376558303833
Batch 15/64 loss: 1.7801051139831543
Batch 16/64 loss: 1.7493410110473633
Batch 17/64 loss: 1.6903882026672363
Batch 18/64 loss: 1.6315350532531738
Batch 19/64 loss: 1.6926798820495605
Batch 20/64 loss: 1.6244869232177734
Batch 21/64 loss: 1.5286369323730469
Batch 22/64 loss: 1.5687313079833984
Batch 23/64 loss: 1.5586447715759277
Batch 24/64 loss: 1.7383947372436523
Batch 25/64 loss: 1.6064090728759766
Batch 26/64 loss: 1.674476146697998
Batch 27/64 loss: 1.6602563858032227
Batch 28/64 loss: 2.014068603515625
Batch 29/64 loss: 1.6614255905151367
Batch 30/64 loss: 1.6686968803405762
Batch 31/64 loss: 1.7392945289611816
Batch 32/64 loss: 1.5837059020996094
Batch 33/64 loss: 4.0144243240356445
Batch 34/64 loss: 2.537818431854248
Batch 35/64 loss: 1.5258655548095703
Batch 36/64 loss: 1.859177589416504
Batch 37/64 loss: 1.9364595413208008
Batch 38/64 loss: 2.452754020690918
Batch 39/64 loss: 1.8853092193603516
Batch 40/64 loss: 1.9805521965026855
Batch 41/64 loss: 1.5678801536560059
Batch 42/64 loss: 4.087377071380615
Batch 43/64 loss: 1.6292805671691895
Batch 44/64 loss: 1.704012393951416
Batch 45/64 loss: 1.5842361450195312
Batch 46/64 loss: 1.6552562713623047
Batch 47/64 loss: 1.5663328170776367
Batch 48/64 loss: 1.660140037536621
Batch 49/64 loss: 1.5640807151794434
Batch 50/64 loss: 1.599405288696289
Batch 51/64 loss: 1.715430736541748
Batch 52/64 loss: 1.5737981796264648
Batch 53/64 loss: 1.6621174812316895
Batch 54/64 loss: 2.8177132606506348
Batch 55/64 loss: 1.6505475044250488
Batch 56/64 loss: 1.5015106201171875
Batch 57/64 loss: 1.7354693412780762
Batch 58/64 loss: 1.723947525024414
Batch 59/64 loss: 1.6543235778808594
Batch 60/64 loss: 2.8135247230529785
Batch 61/64 loss: 2.4213881492614746
Batch 62/64 loss: 2.1497182846069336
Batch 63/64 loss: 1.6318678855895996
Batch 64/64 loss: -1.795802116394043
Epoch 432  Train loss: 1.8370440651388729  Val loss: 1.4597750660480093
Epoch 433
-------------------------------
Batch 1/64 loss: 1.7118024826049805
Batch 2/64 loss: 1.6725754737854004
Batch 3/64 loss: 1.802492618560791
Batch 4/64 loss: 1.6547741889953613
Batch 5/64 loss: 2.1964311599731445
Batch 6/64 loss: 1.4774904251098633
Batch 7/64 loss: 1.6413655281066895
Batch 8/64 loss: 1.6287775039672852
Batch 9/64 loss: 1.5692253112792969
Batch 10/64 loss: 1.6471118927001953
Batch 11/64 loss: 2.002096652984619
Batch 12/64 loss: 3.957401752471924
Batch 13/64 loss: 1.6759181022644043
Batch 14/64 loss: 1.6550250053405762
Batch 15/64 loss: 1.7160863876342773
Batch 16/64 loss: 1.612630844116211
Batch 17/64 loss: 1.8142085075378418
Batch 18/64 loss: 1.7621574401855469
Batch 19/64 loss: 2.184206962585449
Batch 20/64 loss: 1.696021556854248
Batch 21/64 loss: 2.7488746643066406
Batch 22/64 loss: 1.7336325645446777
Batch 23/64 loss: 1.741506576538086
Batch 24/64 loss: 1.6718497276306152
Batch 25/64 loss: 2.1847729682922363
Batch 26/64 loss: 4.647889614105225
Batch 27/64 loss: 1.7066001892089844
Batch 28/64 loss: 1.5972471237182617
Batch 29/64 loss: 1.9172048568725586
Batch 30/64 loss: 1.6222939491271973
Batch 31/64 loss: 1.6089096069335938
Batch 32/64 loss: 1.8250336647033691
Batch 33/64 loss: 1.826256275177002
Batch 34/64 loss: 1.5701913833618164
Batch 35/64 loss: 2.5712809562683105
Batch 36/64 loss: 1.7017183303833008
Batch 37/64 loss: 1.6957721710205078
Batch 38/64 loss: 1.5978717803955078
Batch 39/64 loss: 1.8332414627075195
Batch 40/64 loss: 1.9160447120666504
Batch 41/64 loss: 1.6337852478027344
Batch 42/64 loss: 1.7300057411193848
Batch 43/64 loss: 1.7285728454589844
Batch 44/64 loss: 1.8517370223999023
Batch 45/64 loss: 2.0221500396728516
Batch 46/64 loss: 1.7493634223937988
Batch 47/64 loss: 1.6463661193847656
Batch 48/64 loss: 1.783163070678711
Batch 49/64 loss: 1.9263339042663574
Batch 50/64 loss: 1.8552865982055664
Batch 51/64 loss: 1.6040987968444824
Batch 52/64 loss: 1.822476863861084
Batch 53/64 loss: 3.6851401329040527
Batch 54/64 loss: 2.117554187774658
Batch 55/64 loss: 2.4187960624694824
Batch 56/64 loss: 1.7561674118041992
Batch 57/64 loss: 1.7532563209533691
Batch 58/64 loss: 1.6061558723449707
Batch 59/64 loss: 1.7588801383972168
Batch 60/64 loss: 1.6652469635009766
Batch 61/64 loss: 1.7079238891601562
Batch 62/64 loss: 2.765432834625244
Batch 63/64 loss: 1.6795926094055176
Batch 64/64 loss: -1.7987957000732422
Epoch 433  Train loss: 1.8778726540359796  Val loss: 1.4364176091459608
Epoch 434
-------------------------------
Batch 1/64 loss: 1.77586030960083
Batch 2/64 loss: 1.6918792724609375
Batch 3/64 loss: 1.5889678001403809
Batch 4/64 loss: 1.6916003227233887
Batch 5/64 loss: 1.8756351470947266
Batch 6/64 loss: 1.7235617637634277
Batch 7/64 loss: 1.6362733840942383
Batch 8/64 loss: 1.6373491287231445
Batch 9/64 loss: 1.6518688201904297
Batch 10/64 loss: 1.7260112762451172
Batch 11/64 loss: 2.646134853363037
Batch 12/64 loss: 1.6471986770629883
Batch 13/64 loss: 1.559544563293457
Batch 14/64 loss: 1.7083616256713867
Batch 15/64 loss: 1.6112360954284668
Batch 16/64 loss: 1.7232880592346191
Batch 17/64 loss: 4.946870803833008
Batch 18/64 loss: 2.139824390411377
Batch 19/64 loss: 1.5476207733154297
Batch 20/64 loss: 4.61120080947876
Batch 21/64 loss: 1.578406810760498
Batch 22/64 loss: 1.643080711364746
Batch 23/64 loss: 1.7674450874328613
Batch 24/64 loss: 1.7184629440307617
Batch 25/64 loss: 3.245818614959717
Batch 26/64 loss: 1.8619050979614258
Batch 27/64 loss: 1.8582429885864258
Batch 28/64 loss: 1.7456440925598145
Batch 29/64 loss: 1.6279749870300293
Batch 30/64 loss: 2.2710633277893066
Batch 31/64 loss: 2.939998149871826
Batch 32/64 loss: 1.581827163696289
Batch 33/64 loss: 1.687830924987793
Batch 34/64 loss: 1.4752740859985352
Batch 35/64 loss: 1.6831049919128418
Batch 36/64 loss: 1.6493120193481445
Batch 37/64 loss: 2.030355930328369
Batch 38/64 loss: 1.5577034950256348
Batch 39/64 loss: 1.7181591987609863
Batch 40/64 loss: 1.6775398254394531
Batch 41/64 loss: 1.8744468688964844
Batch 42/64 loss: 1.709284782409668
Batch 43/64 loss: 3.6951651573181152
Batch 44/64 loss: 1.6402363777160645
Batch 45/64 loss: 1.6050386428833008
Batch 46/64 loss: 1.9021058082580566
Batch 47/64 loss: 1.6443800926208496
Batch 48/64 loss: 1.9090161323547363
Batch 49/64 loss: 1.6204814910888672
Batch 50/64 loss: 1.810410976409912
Batch 51/64 loss: 1.5774521827697754
Batch 52/64 loss: 1.6226563453674316
Batch 53/64 loss: 1.9418244361877441
Batch 54/64 loss: 1.5647025108337402
Batch 55/64 loss: 1.7089223861694336
Batch 56/64 loss: 1.88228178024292
Batch 57/64 loss: 1.657048225402832
Batch 58/64 loss: 1.7395262718200684
Batch 59/64 loss: 1.6236987113952637
Batch 60/64 loss: 1.6393651962280273
Batch 61/64 loss: 1.7053256034851074
Batch 62/64 loss: 1.6941628456115723
Batch 63/64 loss: 1.6479196548461914
Batch 64/64 loss: -1.8844871520996094
Epoch 434  Train loss: 1.85822000690535  Val loss: 1.4027272778278363
Epoch 435
-------------------------------
Batch 1/64 loss: 1.7649025917053223
Batch 2/64 loss: 1.5260963439941406
Batch 3/64 loss: 1.8054842948913574
Batch 4/64 loss: 1.8255581855773926
Batch 5/64 loss: 1.725264072418213
Batch 6/64 loss: 1.70452880859375
Batch 7/64 loss: 1.590519905090332
Batch 8/64 loss: 1.7333478927612305
Batch 9/64 loss: 2.207775592803955
Batch 10/64 loss: 1.611948013305664
Batch 11/64 loss: 1.5948286056518555
Batch 12/64 loss: 1.6778783798217773
Batch 13/64 loss: 1.9699344635009766
Batch 14/64 loss: 1.7721400260925293
Batch 15/64 loss: 1.5860443115234375
Batch 16/64 loss: 1.8245205879211426
Batch 17/64 loss: 1.6670165061950684
Batch 18/64 loss: 1.8082103729248047
Batch 19/64 loss: 1.568392276763916
Batch 20/64 loss: 1.5424251556396484
Batch 21/64 loss: 1.6896281242370605
Batch 22/64 loss: 1.5903277397155762
Batch 23/64 loss: 4.498823642730713
Batch 24/64 loss: 1.740471363067627
Batch 25/64 loss: 2.4135351181030273
Batch 26/64 loss: 1.5112524032592773
Batch 27/64 loss: 1.6638293266296387
Batch 28/64 loss: 1.750837802886963
Batch 29/64 loss: 2.7196297645568848
Batch 30/64 loss: 1.743257999420166
Batch 31/64 loss: 1.6497373580932617
Batch 32/64 loss: 1.6922321319580078
Batch 33/64 loss: 1.7299504280090332
Batch 34/64 loss: 1.7617855072021484
Batch 35/64 loss: 1.9072699546813965
Batch 36/64 loss: 1.7345976829528809
Batch 37/64 loss: 1.9564967155456543
Batch 38/64 loss: 1.619554042816162
Batch 39/64 loss: 1.5902948379516602
Batch 40/64 loss: 3.9321279525756836
Batch 41/64 loss: 1.636000633239746
Batch 42/64 loss: 1.6115703582763672
Batch 43/64 loss: 1.7789411544799805
Batch 44/64 loss: 1.7309141159057617
Batch 45/64 loss: 2.794412136077881
Batch 46/64 loss: 1.6549272537231445
Batch 47/64 loss: 1.7257728576660156
Batch 48/64 loss: 1.7143621444702148
Batch 49/64 loss: 1.9255166053771973
Batch 50/64 loss: 1.5837488174438477
Batch 51/64 loss: 1.6512436866760254
Batch 52/64 loss: 4.3901143074035645
Batch 53/64 loss: 1.6233763694763184
Batch 54/64 loss: 1.5709338188171387
Batch 55/64 loss: 2.0037050247192383
Batch 56/64 loss: 1.5841150283813477
Batch 57/64 loss: 1.613710880279541
Batch 58/64 loss: 1.6024518013000488
Batch 59/64 loss: 1.7188878059387207
Batch 60/64 loss: 1.5684409141540527
Batch 61/64 loss: 1.639014720916748
Batch 62/64 loss: 1.7314157485961914
Batch 63/64 loss: 1.5425972938537598
Batch 64/64 loss: -1.991285800933838
Epoch 435  Train loss: 1.8243947515300676  Val loss: 1.362275271071601
Saving best model, epoch: 435
Epoch 436
-------------------------------
Batch 1/64 loss: 1.6265459060668945
Batch 2/64 loss: 1.6473159790039062
Batch 3/64 loss: 1.7869701385498047
Batch 4/64 loss: 1.5804557800292969
Batch 5/64 loss: 1.9992213249206543
Batch 6/64 loss: 1.6941208839416504
Batch 7/64 loss: 1.7395896911621094
Batch 8/64 loss: 1.9350237846374512
Batch 9/64 loss: 1.636317253112793
Batch 10/64 loss: 2.8309850692749023
Batch 11/64 loss: 3.785407066345215
Batch 12/64 loss: 1.6053438186645508
Batch 13/64 loss: 1.549119472503662
Batch 14/64 loss: 1.5326905250549316
Batch 15/64 loss: 1.5860366821289062
Batch 16/64 loss: 1.549079418182373
Batch 17/64 loss: 1.8220901489257812
Batch 18/64 loss: 1.5451598167419434
Batch 19/64 loss: 2.377932071685791
Batch 20/64 loss: 1.7226448059082031
Batch 21/64 loss: 1.6881904602050781
Batch 22/64 loss: 1.72147798538208
Batch 23/64 loss: 1.6877174377441406
Batch 24/64 loss: 1.8140816688537598
Batch 25/64 loss: 1.5010342597961426
Batch 26/64 loss: 2.324496269226074
Batch 27/64 loss: 2.447572708129883
Batch 28/64 loss: 1.5747737884521484
Batch 29/64 loss: 1.6155552864074707
Batch 30/64 loss: 2.451840877532959
Batch 31/64 loss: 1.6169209480285645
Batch 32/64 loss: 1.6279687881469727
Batch 33/64 loss: 1.656702995300293
Batch 34/64 loss: 1.5851683616638184
Batch 35/64 loss: 1.5704526901245117
Batch 36/64 loss: 1.6629929542541504
Batch 37/64 loss: 3.9349632263183594
Batch 38/64 loss: 1.7736449241638184
Batch 39/64 loss: 1.5934906005859375
Batch 40/64 loss: 1.6141014099121094
Batch 41/64 loss: 1.5486550331115723
Batch 42/64 loss: 1.654130458831787
Batch 43/64 loss: 1.6693177223205566
Batch 44/64 loss: 1.599919319152832
Batch 45/64 loss: 1.593761920928955
Batch 46/64 loss: 1.7849035263061523
Batch 47/64 loss: 1.5596909523010254
Batch 48/64 loss: 5.43735933303833
Batch 49/64 loss: 1.8254899978637695
Batch 50/64 loss: 1.6322174072265625
Batch 51/64 loss: 1.717750072479248
Batch 52/64 loss: 1.560819149017334
Batch 53/64 loss: 1.7081007957458496
Batch 54/64 loss: 1.7151141166687012
Batch 55/64 loss: 1.5874199867248535
Batch 56/64 loss: 1.5697274208068848
Batch 57/64 loss: 1.6833839416503906
Batch 58/64 loss: 1.569051742553711
Batch 59/64 loss: 1.7736411094665527
Batch 60/64 loss: 1.7190117835998535
Batch 61/64 loss: 1.569066047668457
Batch 62/64 loss: 1.5125923156738281
Batch 63/64 loss: 1.7466468811035156
Batch 64/64 loss: -1.821868896484375
Epoch 436  Train loss: 1.8099853590422985  Val loss: 1.357996190126819
Saving best model, epoch: 436
Epoch 437
-------------------------------
Batch 1/64 loss: 1.6301636695861816
Batch 2/64 loss: 1.7959256172180176
Batch 3/64 loss: 1.6511902809143066
Batch 4/64 loss: 1.7317500114440918
Batch 5/64 loss: 1.5441718101501465
Batch 6/64 loss: 1.6383700370788574
Batch 7/64 loss: 1.9131793975830078
Batch 8/64 loss: 3.6693921089172363
Batch 9/64 loss: 1.5742216110229492
Batch 10/64 loss: 1.6701693534851074
Batch 11/64 loss: 4.0437140464782715
Batch 12/64 loss: 1.537841796875
Batch 13/64 loss: 1.5606675148010254
Batch 14/64 loss: 1.566648006439209
Batch 15/64 loss: 1.4869747161865234
Batch 16/64 loss: 1.720625877380371
Batch 17/64 loss: 1.5109786987304688
Batch 18/64 loss: 1.569563865661621
Batch 19/64 loss: 1.5879263877868652
Batch 20/64 loss: 1.6282768249511719
Batch 21/64 loss: 1.5953927040100098
Batch 22/64 loss: 1.5564360618591309
Batch 23/64 loss: 2.6785764694213867
Batch 24/64 loss: 1.5408077239990234
Batch 25/64 loss: 4.44398832321167
Batch 26/64 loss: 1.519010066986084
Batch 27/64 loss: 1.6861968040466309
Batch 28/64 loss: 1.6385841369628906
Batch 29/64 loss: 1.5310420989990234
Batch 30/64 loss: 2.211209297180176
Batch 31/64 loss: 2.431612968444824
Batch 32/64 loss: 1.536219596862793
Batch 33/64 loss: 2.047010898590088
Batch 34/64 loss: 1.7724928855895996
Batch 35/64 loss: 1.5524072647094727
Batch 36/64 loss: 1.4426379203796387
Batch 37/64 loss: 1.5521769523620605
Batch 38/64 loss: 1.7466721534729004
Batch 39/64 loss: 1.4996695518493652
Batch 40/64 loss: 1.591324806213379
Batch 41/64 loss: 2.2354769706726074
Batch 42/64 loss: 1.6785693168640137
Batch 43/64 loss: 1.5498480796813965
Batch 44/64 loss: 1.571805477142334
Batch 45/64 loss: 1.613898754119873
Batch 46/64 loss: 1.595095157623291
Batch 47/64 loss: 1.5403318405151367
Batch 48/64 loss: 1.7243738174438477
Batch 49/64 loss: 1.7434067726135254
Batch 50/64 loss: 2.2045273780822754
Batch 51/64 loss: 1.7559099197387695
Batch 52/64 loss: 1.5838627815246582
Batch 53/64 loss: 1.7104482650756836
Batch 54/64 loss: 2.0094823837280273
Batch 55/64 loss: 2.8217878341674805
Batch 56/64 loss: 1.650223731994629
Batch 57/64 loss: 1.5121369361877441
Batch 58/64 loss: 1.7224817276000977
Batch 59/64 loss: 1.7891812324523926
Batch 60/64 loss: 1.7998003959655762
Batch 61/64 loss: 1.5081567764282227
Batch 62/64 loss: 2.0510711669921875
Batch 63/64 loss: 1.579305648803711
Batch 64/64 loss: -1.8950719833374023
Epoch 437  Train loss: 1.7903544893451766  Val loss: 1.3450774491038109
Saving best model, epoch: 437
Epoch 438
-------------------------------
Batch 1/64 loss: 1.6810040473937988
Batch 2/64 loss: 1.6970062255859375
Batch 3/64 loss: 1.5501775741577148
Batch 4/64 loss: 1.5966014862060547
Batch 5/64 loss: 1.5861396789550781
Batch 6/64 loss: 1.4774246215820312
Batch 7/64 loss: 1.7050681114196777
Batch 8/64 loss: 1.6275672912597656
Batch 9/64 loss: 1.683588981628418
Batch 10/64 loss: 1.4992289543151855
Batch 11/64 loss: 3.6429014205932617
Batch 12/64 loss: 1.544222354888916
Batch 13/64 loss: 1.4807085990905762
Batch 14/64 loss: 1.688157081604004
Batch 15/64 loss: 1.5612010955810547
Batch 16/64 loss: 1.6382265090942383
Batch 17/64 loss: 4.169170379638672
Batch 18/64 loss: 1.5372357368469238
Batch 19/64 loss: 2.1248908042907715
Batch 20/64 loss: 4.484421253204346
Batch 21/64 loss: 1.662519931793213
Batch 22/64 loss: 1.6519131660461426
Batch 23/64 loss: 1.5492372512817383
Batch 24/64 loss: 1.515270709991455
Batch 25/64 loss: 1.6450982093811035
Batch 26/64 loss: 1.5771360397338867
Batch 27/64 loss: 1.6198534965515137
Batch 28/64 loss: 1.548067569732666
Batch 29/64 loss: 1.5273675918579102
Batch 30/64 loss: 2.6722970008850098
Batch 31/64 loss: 1.5573034286499023
Batch 32/64 loss: 1.6308622360229492
Batch 33/64 loss: 2.532550811767578
Batch 34/64 loss: 1.6157822608947754
Batch 35/64 loss: 1.5679116249084473
Batch 36/64 loss: 1.5110969543457031
Batch 37/64 loss: 1.6400227546691895
Batch 38/64 loss: 1.5533623695373535
Batch 39/64 loss: 1.6475954055786133
Batch 40/64 loss: 2.350320816040039
Batch 41/64 loss: 2.7829360961914062
Batch 42/64 loss: 1.5392560958862305
Batch 43/64 loss: 1.810257911682129
Batch 44/64 loss: 1.5207204818725586
Batch 45/64 loss: 1.5702438354492188
Batch 46/64 loss: 1.6471996307373047
Batch 47/64 loss: 1.5770606994628906
Batch 48/64 loss: 1.5505189895629883
Batch 49/64 loss: 1.5563530921936035
Batch 50/64 loss: 1.5730586051940918
Batch 51/64 loss: 1.6402864456176758
Batch 52/64 loss: 2.188015937805176
Batch 53/64 loss: 1.6111221313476562
Batch 54/64 loss: 1.7450871467590332
Batch 55/64 loss: 1.5308647155761719
Batch 56/64 loss: 1.6808409690856934
Batch 57/64 loss: 2.0308680534362793
Batch 58/64 loss: 1.7710418701171875
Batch 59/64 loss: 1.6234517097473145
Batch 60/64 loss: 1.57893705368042
Batch 61/64 loss: 1.614769458770752
Batch 62/64 loss: 2.0986452102661133
Batch 63/64 loss: 1.474057674407959
Batch 64/64 loss: -1.9742388725280762
Epoch 438  Train loss: 1.7691831607444615  Val loss: 1.3414223398949272
Saving best model, epoch: 438
Epoch 439
-------------------------------
Batch 1/64 loss: 2.695150852203369
Batch 2/64 loss: 1.6238727569580078
Batch 3/64 loss: 1.7141170501708984
Batch 4/64 loss: 1.6933064460754395
Batch 5/64 loss: 1.9774384498596191
Batch 6/64 loss: 1.469653606414795
Batch 7/64 loss: 1.5502290725708008
Batch 8/64 loss: 1.5957789421081543
Batch 9/64 loss: 1.5237741470336914
Batch 10/64 loss: 1.5386323928833008
Batch 11/64 loss: 1.7791705131530762
Batch 12/64 loss: 1.6650099754333496
Batch 13/64 loss: 1.6400628089904785
Batch 14/64 loss: 1.5683012008666992
Batch 15/64 loss: 2.4572553634643555
Batch 16/64 loss: 1.7091803550720215
Batch 17/64 loss: 1.5461134910583496
Batch 18/64 loss: 1.624556064605713
Batch 19/64 loss: 1.5786852836608887
Batch 20/64 loss: 1.627671718597412
Batch 21/64 loss: 1.7055082321166992
Batch 22/64 loss: 1.7038979530334473
Batch 23/64 loss: 1.6770405769348145
Batch 24/64 loss: 1.552886962890625
Batch 25/64 loss: 1.6940679550170898
Batch 26/64 loss: 2.010070323944092
Batch 27/64 loss: 1.5095982551574707
Batch 28/64 loss: 1.921884536743164
Batch 29/64 loss: 1.8507399559020996
Batch 30/64 loss: 2.7717623710632324
Batch 31/64 loss: 1.6632585525512695
Batch 32/64 loss: 1.5844306945800781
Batch 33/64 loss: 1.7652511596679688
Batch 34/64 loss: 1.6975812911987305
Batch 35/64 loss: 1.619882583618164
Batch 36/64 loss: 2.8021955490112305
Batch 37/64 loss: 1.5551042556762695
Batch 38/64 loss: 1.6447834968566895
Batch 39/64 loss: 1.7554678916931152
Batch 40/64 loss: 1.6481475830078125
Batch 41/64 loss: 1.4797239303588867
Batch 42/64 loss: 1.6595401763916016
Batch 43/64 loss: 1.6329331398010254
Batch 44/64 loss: 1.5860595703125
Batch 45/64 loss: 4.629486560821533
Batch 46/64 loss: 1.5261225700378418
Batch 47/64 loss: 1.615572452545166
Batch 48/64 loss: 1.6827268600463867
Batch 49/64 loss: 1.6219186782836914
Batch 50/64 loss: 1.588918685913086
Batch 51/64 loss: 1.5298309326171875
Batch 52/64 loss: 1.5786871910095215
Batch 53/64 loss: 1.5187087059020996
Batch 54/64 loss: 1.6123733520507812
Batch 55/64 loss: 3.632327079772949
Batch 56/64 loss: 4.422373294830322
Batch 57/64 loss: 1.8767642974853516
Batch 58/64 loss: 1.725006103515625
Batch 59/64 loss: 1.7956781387329102
Batch 60/64 loss: 1.6302833557128906
Batch 61/64 loss: 1.5662317276000977
Batch 62/64 loss: 1.6226625442504883
Batch 63/64 loss: 1.5641608238220215
Batch 64/64 loss: -1.7851667404174805
Epoch 439  Train loss: 1.7956193849152209  Val loss: 1.4028242183305144
Epoch 440
-------------------------------
Batch 1/64 loss: 1.8042850494384766
Batch 2/64 loss: 1.6152257919311523
Batch 3/64 loss: 1.5366778373718262
Batch 4/64 loss: 2.5023422241210938
Batch 5/64 loss: 1.596135139465332
Batch 6/64 loss: 1.5712027549743652
Batch 7/64 loss: 2.51755952835083
Batch 8/64 loss: 1.9854683876037598
Batch 9/64 loss: 1.5649800300598145
Batch 10/64 loss: 1.6186127662658691
Batch 11/64 loss: 1.694791316986084
Batch 12/64 loss: 1.867253303527832
Batch 13/64 loss: 1.6556529998779297
Batch 14/64 loss: 2.0050458908081055
Batch 15/64 loss: 1.55855131149292
Batch 16/64 loss: 1.626856803894043
Batch 17/64 loss: 1.7006235122680664
Batch 18/64 loss: 1.5107455253601074
Batch 19/64 loss: 1.6902127265930176
Batch 20/64 loss: 1.6129555702209473
Batch 21/64 loss: 1.474194049835205
Batch 22/64 loss: 1.629979133605957
Batch 23/64 loss: 1.5281343460083008
Batch 24/64 loss: 1.5434536933898926
Batch 25/64 loss: 1.638214111328125
Batch 26/64 loss: 1.6278791427612305
Batch 27/64 loss: 1.7300896644592285
Batch 28/64 loss: 1.6752080917358398
Batch 29/64 loss: 1.550783634185791
Batch 30/64 loss: 1.7869324684143066
Batch 31/64 loss: 1.5242323875427246
Batch 32/64 loss: 1.6203813552856445
Batch 33/64 loss: 1.5911164283752441
Batch 34/64 loss: 1.6557869911193848
Batch 35/64 loss: 1.7687411308288574
Batch 36/64 loss: 1.6185998916625977
Batch 37/64 loss: 2.227283477783203
Batch 38/64 loss: 4.533535003662109
Batch 39/64 loss: 1.5542826652526855
Batch 40/64 loss: 1.6264386177062988
Batch 41/64 loss: 3.1691012382507324
Batch 42/64 loss: 1.5289554595947266
Batch 43/64 loss: 3.797205924987793
Batch 44/64 loss: 1.5563116073608398
Batch 45/64 loss: 1.6390800476074219
Batch 46/64 loss: 1.7004337310791016
Batch 47/64 loss: 1.5980925559997559
Batch 48/64 loss: 1.8251466751098633
Batch 49/64 loss: 1.5142545700073242
Batch 50/64 loss: 1.5966577529907227
Batch 51/64 loss: 2.104097843170166
Batch 52/64 loss: 1.6012053489685059
Batch 53/64 loss: 1.5722670555114746
Batch 54/64 loss: 4.014692783355713
Batch 55/64 loss: 1.5843234062194824
Batch 56/64 loss: 1.9801836013793945
Batch 57/64 loss: 1.542586326599121
Batch 58/64 loss: 1.6022663116455078
Batch 59/64 loss: 1.6907029151916504
Batch 60/64 loss: 1.7732768058776855
Batch 61/64 loss: 2.300543785095215
Batch 62/64 loss: 1.5996222496032715
Batch 63/64 loss: 1.5970244407653809
Batch 64/64 loss: -1.7770462036132812
Epoch 440  Train loss: 1.7991481182621976  Val loss: 1.430730865583387
Epoch 441
-------------------------------
Batch 1/64 loss: 1.5312328338623047
Batch 2/64 loss: 1.5185279846191406
Batch 3/64 loss: 2.216005802154541
Batch 4/64 loss: 1.8636603355407715
Batch 5/64 loss: 2.149733543395996
Batch 6/64 loss: 2.2032790184020996
Batch 7/64 loss: 1.8244380950927734
Batch 8/64 loss: 1.9795494079589844
Batch 9/64 loss: 2.1032567024230957
Batch 10/64 loss: 1.666654109954834
Batch 11/64 loss: 1.6340370178222656
Batch 12/64 loss: 1.5549302101135254
Batch 13/64 loss: 1.6516780853271484
Batch 14/64 loss: 1.6013412475585938
Batch 15/64 loss: 1.5703892707824707
Batch 16/64 loss: 1.6249361038208008
Batch 17/64 loss: 3.767387866973877
Batch 18/64 loss: 1.7291812896728516
Batch 19/64 loss: 1.6362133026123047
Batch 20/64 loss: 2.4744982719421387
Batch 21/64 loss: 1.6025686264038086
Batch 22/64 loss: 1.6006431579589844
Batch 23/64 loss: 1.6784605979919434
Batch 24/64 loss: 1.5976629257202148
Batch 25/64 loss: 1.698838233947754
Batch 26/64 loss: 2.739241600036621
Batch 27/64 loss: 1.4826254844665527
Batch 28/64 loss: 2.0145812034606934
Batch 29/64 loss: 4.571370601654053
Batch 30/64 loss: 1.6119575500488281
Batch 31/64 loss: 1.535510540008545
Batch 32/64 loss: 1.5080976486206055
Batch 33/64 loss: 1.6823792457580566
Batch 34/64 loss: 1.6031570434570312
Batch 35/64 loss: 1.7590765953063965
Batch 36/64 loss: 1.614349365234375
Batch 37/64 loss: 1.538022518157959
Batch 38/64 loss: 2.6784591674804688
Batch 39/64 loss: 1.7395758628845215
Batch 40/64 loss: 1.6751112937927246
Batch 41/64 loss: 1.7646775245666504
Batch 42/64 loss: 1.5493402481079102
Batch 43/64 loss: 1.6727771759033203
Batch 44/64 loss: 1.585289478302002
Batch 45/64 loss: 1.5402274131774902
Batch 46/64 loss: 1.74430513381958
Batch 47/64 loss: 1.6512484550476074
Batch 48/64 loss: 1.6044635772705078
Batch 49/64 loss: 1.8271064758300781
Batch 50/64 loss: 4.006349086761475
Batch 51/64 loss: 1.6214890480041504
Batch 52/64 loss: 1.8181180953979492
Batch 53/64 loss: 1.6970696449279785
Batch 54/64 loss: 1.7884492874145508
Batch 55/64 loss: 1.829732894897461
Batch 56/64 loss: 1.6617298126220703
Batch 57/64 loss: 1.610321044921875
Batch 58/64 loss: 1.5093164443969727
Batch 59/64 loss: 1.491466999053955
Batch 60/64 loss: 1.6564531326293945
Batch 61/64 loss: 1.6351990699768066
Batch 62/64 loss: 1.6967802047729492
Batch 63/64 loss: 1.6345787048339844
Batch 64/64 loss: -1.9448394775390625
Epoch 441  Train loss: 1.8097330055984797  Val loss: 1.362061097449863
Epoch 442
-------------------------------
Batch 1/64 loss: 1.977816104888916
Batch 2/64 loss: 1.5298705101013184
Batch 3/64 loss: 1.5638465881347656
Batch 4/64 loss: 1.4956212043762207
Batch 5/64 loss: 1.6120672225952148
Batch 6/64 loss: 2.1245527267456055
Batch 7/64 loss: 1.7356681823730469
Batch 8/64 loss: 1.582097053527832
Batch 9/64 loss: 1.4988141059875488
Batch 10/64 loss: 1.6529512405395508
Batch 11/64 loss: 1.5605134963989258
Batch 12/64 loss: 1.5127978324890137
Batch 13/64 loss: 1.5605783462524414
Batch 14/64 loss: 1.9334793090820312
Batch 15/64 loss: 2.257132053375244
Batch 16/64 loss: 1.6559467315673828
Batch 17/64 loss: 1.6279420852661133
Batch 18/64 loss: 1.5843586921691895
Batch 19/64 loss: 1.6815695762634277
Batch 20/64 loss: 1.6124911308288574
Batch 21/64 loss: 1.8417744636535645
Batch 22/64 loss: 1.6476492881774902
Batch 23/64 loss: 1.5431809425354004
Batch 24/64 loss: 1.651308536529541
Batch 25/64 loss: 1.6860342025756836
Batch 26/64 loss: 1.5800127983093262
Batch 27/64 loss: 1.7778387069702148
Batch 28/64 loss: 1.6274285316467285
Batch 29/64 loss: 1.9550819396972656
Batch 30/64 loss: 1.6615219116210938
Batch 31/64 loss: 1.544827938079834
Batch 32/64 loss: 1.8330178260803223
Batch 33/64 loss: 1.666801929473877
Batch 34/64 loss: 2.607203483581543
Batch 35/64 loss: 1.5188922882080078
Batch 36/64 loss: 1.76123046875
Batch 37/64 loss: 1.5489726066589355
Batch 38/64 loss: 1.5876655578613281
Batch 39/64 loss: 1.6291913986206055
Batch 40/64 loss: 2.734334945678711
Batch 41/64 loss: 1.6709418296813965
Batch 42/64 loss: 2.056997776031494
Batch 43/64 loss: 4.563739776611328
Batch 44/64 loss: 2.042637348175049
Batch 45/64 loss: 1.5741782188415527
Batch 46/64 loss: 1.7249507904052734
Batch 47/64 loss: 1.5822029113769531
Batch 48/64 loss: 1.535789966583252
Batch 49/64 loss: 1.7826595306396484
Batch 50/64 loss: 1.5472021102905273
Batch 51/64 loss: 3.765183925628662
Batch 52/64 loss: 2.3845558166503906
Batch 53/64 loss: 1.5584707260131836
Batch 54/64 loss: 1.8441638946533203
Batch 55/64 loss: 1.5999550819396973
Batch 56/64 loss: 1.5618367195129395
Batch 57/64 loss: 4.079349040985107
Batch 58/64 loss: 1.8301563262939453
Batch 59/64 loss: 1.7042136192321777
Batch 60/64 loss: 1.5399541854858398
Batch 61/64 loss: 1.594759464263916
Batch 62/64 loss: 2.5908236503601074
Batch 63/64 loss: 1.6687145233154297
Batch 64/64 loss: -1.8174333572387695
Epoch 442  Train loss: 1.8134030772190468  Val loss: 1.3607086496254832
Epoch 443
-------------------------------
Batch 1/64 loss: 1.8473782539367676
Batch 2/64 loss: 1.636345386505127
Batch 3/64 loss: 1.6445765495300293
Batch 4/64 loss: 1.6088552474975586
Batch 5/64 loss: 1.5477685928344727
Batch 6/64 loss: 1.663881778717041
Batch 7/64 loss: 1.7101407051086426
Batch 8/64 loss: 1.4535102844238281
Batch 9/64 loss: 1.691359519958496
Batch 10/64 loss: 4.199367523193359
Batch 11/64 loss: 1.7425918579101562
Batch 12/64 loss: 1.617985725402832
Batch 13/64 loss: 1.7442240715026855
Batch 14/64 loss: 1.5668859481811523
Batch 15/64 loss: 1.5764927864074707
Batch 16/64 loss: 1.590254306793213
Batch 17/64 loss: 4.619595050811768
Batch 18/64 loss: 1.6727700233459473
Batch 19/64 loss: 1.5941152572631836
Batch 20/64 loss: 1.5928940773010254
Batch 21/64 loss: 1.6262273788452148
Batch 22/64 loss: 1.5043582916259766
Batch 23/64 loss: 1.618598461151123
Batch 24/64 loss: 1.5844383239746094
Batch 25/64 loss: 3.1927342414855957
Batch 26/64 loss: 1.5955891609191895
Batch 27/64 loss: 1.7769560813903809
Batch 28/64 loss: 3.632265090942383
Batch 29/64 loss: 1.6866474151611328
Batch 30/64 loss: 1.6838288307189941
Batch 31/64 loss: 1.695237636566162
Batch 32/64 loss: 1.7189850807189941
Batch 33/64 loss: 1.5250916481018066
Batch 34/64 loss: 1.690706729888916
Batch 35/64 loss: 2.165454864501953
Batch 36/64 loss: 1.6700544357299805
Batch 37/64 loss: 1.5421299934387207
Batch 38/64 loss: 1.6264252662658691
Batch 39/64 loss: 1.606313705444336
Batch 40/64 loss: 1.6979904174804688
Batch 41/64 loss: 1.5806059837341309
Batch 42/64 loss: 1.5350770950317383
Batch 43/64 loss: 1.400838851928711
Batch 44/64 loss: 1.8972702026367188
Batch 45/64 loss: 1.722933292388916
Batch 46/64 loss: 1.6165623664855957
Batch 47/64 loss: 1.558403491973877
Batch 48/64 loss: 1.6245827674865723
Batch 49/64 loss: 1.577418327331543
Batch 50/64 loss: 1.8128914833068848
Batch 51/64 loss: 1.745185375213623
Batch 52/64 loss: 1.9359068870544434
Batch 53/64 loss: 2.501199245452881
Batch 54/64 loss: 1.5281963348388672
Batch 55/64 loss: 1.9782166481018066
Batch 56/64 loss: 1.5171785354614258
Batch 57/64 loss: 1.4973344802856445
Batch 58/64 loss: 1.5537824630737305
Batch 59/64 loss: 1.5704145431518555
Batch 60/64 loss: 1.6182060241699219
Batch 61/64 loss: 1.9935979843139648
Batch 62/64 loss: 2.6812314987182617
Batch 63/64 loss: 1.5921015739440918
Batch 64/64 loss: -1.9933271408081055
Epoch 443  Train loss: 1.7836104486502853  Val loss: 1.3600071910320688
Epoch 444
-------------------------------
Batch 1/64 loss: 1.887988567352295
Batch 2/64 loss: 1.5456767082214355
Batch 3/64 loss: 1.9981813430786133
Batch 4/64 loss: 1.5620765686035156
Batch 5/64 loss: 1.5040712356567383
Batch 6/64 loss: 2.7571229934692383
Batch 7/64 loss: 2.4304656982421875
Batch 8/64 loss: 1.501852035522461
Batch 9/64 loss: 1.6280779838562012
Batch 10/64 loss: 1.6851677894592285
Batch 11/64 loss: 4.422751426696777
Batch 12/64 loss: 1.5290632247924805
Batch 13/64 loss: 1.5173959732055664
Batch 14/64 loss: 1.631761074066162
Batch 15/64 loss: 1.5977392196655273
Batch 16/64 loss: 2.0430898666381836
Batch 17/64 loss: 1.8159151077270508
Batch 18/64 loss: 1.7111663818359375
Batch 19/64 loss: 1.6477937698364258
Batch 20/64 loss: 1.6330466270446777
Batch 21/64 loss: 1.6169929504394531
Batch 22/64 loss: 1.5470457077026367
Batch 23/64 loss: 1.679898738861084
Batch 24/64 loss: 1.6377215385437012
Batch 25/64 loss: 1.7665977478027344
Batch 26/64 loss: 1.549262523651123
Batch 27/64 loss: 1.63569974899292
Batch 28/64 loss: 1.5767955780029297
Batch 29/64 loss: 2.820455551147461
Batch 30/64 loss: 4.138254642486572
Batch 31/64 loss: 1.6290760040283203
Batch 32/64 loss: 1.9021081924438477
Batch 33/64 loss: 1.5573525428771973
Batch 34/64 loss: 1.5617380142211914
Batch 35/64 loss: 1.6030797958374023
Batch 36/64 loss: 1.5379252433776855
Batch 37/64 loss: 1.544912338256836
Batch 38/64 loss: 1.5962281227111816
Batch 39/64 loss: 1.6152772903442383
Batch 40/64 loss: 1.5119209289550781
Batch 41/64 loss: 1.5941143035888672
Batch 42/64 loss: 1.704634189605713
Batch 43/64 loss: 2.083237648010254
Batch 44/64 loss: 1.5949673652648926
Batch 45/64 loss: 1.6898150444030762
Batch 46/64 loss: 1.5554571151733398
Batch 47/64 loss: 1.6928095817565918
Batch 48/64 loss: 1.5980615615844727
Batch 49/64 loss: 1.6068930625915527
Batch 50/64 loss: 1.6561298370361328
Batch 51/64 loss: 1.6164708137512207
Batch 52/64 loss: 2.238250732421875
Batch 53/64 loss: 1.6079750061035156
Batch 54/64 loss: 1.4992337226867676
Batch 55/64 loss: 1.597362995147705
Batch 56/64 loss: 1.647542953491211
Batch 57/64 loss: 1.559053897857666
Batch 58/64 loss: 4.536449432373047
Batch 59/64 loss: 1.5454363822937012
Batch 60/64 loss: 1.9134087562561035
Batch 61/64 loss: 1.5514192581176758
Batch 62/64 loss: 1.5733470916748047
Batch 63/64 loss: 1.734053611755371
Batch 64/64 loss: -1.8757953643798828
Epoch 444  Train loss: 1.7893023472206264  Val loss: 1.3222431300841655
Saving best model, epoch: 444
Epoch 445
-------------------------------
Batch 1/64 loss: 1.523226261138916
Batch 2/64 loss: 1.5722665786743164
Batch 3/64 loss: 1.7897233963012695
Batch 4/64 loss: 1.5505285263061523
Batch 5/64 loss: 1.5682005882263184
Batch 6/64 loss: 1.5725903511047363
Batch 7/64 loss: 1.7292513847351074
Batch 8/64 loss: 1.560577392578125
Batch 9/64 loss: 1.5840883255004883
Batch 10/64 loss: 1.504122257232666
Batch 11/64 loss: 1.5145721435546875
Batch 12/64 loss: 1.5291128158569336
Batch 13/64 loss: 1.5668234825134277
Batch 14/64 loss: 1.5743451118469238
Batch 15/64 loss: 1.6594300270080566
Batch 16/64 loss: 1.47349214553833
Batch 17/64 loss: 1.7691988945007324
Batch 18/64 loss: 1.6018271446228027
Batch 19/64 loss: 1.845731258392334
Batch 20/64 loss: 1.6157054901123047
Batch 21/64 loss: 1.521923542022705
Batch 22/64 loss: 4.212298393249512
Batch 23/64 loss: 1.689049243927002
Batch 24/64 loss: 2.7002601623535156
Batch 25/64 loss: 1.728912353515625
Batch 26/64 loss: 1.547882080078125
Batch 27/64 loss: 1.6778411865234375
Batch 28/64 loss: 1.534296989440918
Batch 29/64 loss: 1.6033267974853516
Batch 30/64 loss: 1.762606143951416
Batch 31/64 loss: 1.5695066452026367
Batch 32/64 loss: 2.331864356994629
Batch 33/64 loss: 5.1881303787231445
Batch 34/64 loss: 1.5707879066467285
Batch 35/64 loss: 1.7183027267456055
Batch 36/64 loss: 1.64072847366333
Batch 37/64 loss: 1.5827059745788574
Batch 38/64 loss: 1.6716923713684082
Batch 39/64 loss: 1.5682077407836914
Batch 40/64 loss: 3.3518896102905273
Batch 41/64 loss: 1.570681095123291
Batch 42/64 loss: 1.6124238967895508
Batch 43/64 loss: 1.8764781951904297
Batch 44/64 loss: 1.6923670768737793
Batch 45/64 loss: 1.5106968879699707
Batch 46/64 loss: 1.6860599517822266
Batch 47/64 loss: 1.6968979835510254
Batch 48/64 loss: 1.856163501739502
Batch 49/64 loss: 1.6401896476745605
Batch 50/64 loss: 2.3327059745788574
Batch 51/64 loss: 1.6350688934326172
Batch 52/64 loss: 1.9084248542785645
Batch 53/64 loss: 1.7230925559997559
Batch 54/64 loss: 2.016848087310791
Batch 55/64 loss: 1.5935840606689453
Batch 56/64 loss: 1.7049174308776855
Batch 57/64 loss: 1.6034293174743652
Batch 58/64 loss: 1.5812530517578125
Batch 59/64 loss: 4.048244476318359
Batch 60/64 loss: 1.7765274047851562
Batch 61/64 loss: 1.622288703918457
Batch 62/64 loss: 1.583707332611084
Batch 63/64 loss: 1.7506604194641113
Batch 64/64 loss: -1.807978630065918
Epoch 445  Train loss: 1.803039270288804  Val loss: 1.4073091618383873
Epoch 446
-------------------------------
Batch 1/64 loss: 1.6160340309143066
Batch 2/64 loss: 2.0337982177734375
Batch 3/64 loss: 1.7537550926208496
Batch 4/64 loss: 1.6551780700683594
Batch 5/64 loss: 1.6851153373718262
Batch 6/64 loss: 1.5775861740112305
Batch 7/64 loss: 1.6969261169433594
Batch 8/64 loss: 1.7379107475280762
Batch 9/64 loss: 2.2641077041625977
Batch 10/64 loss: 2.1051435470581055
Batch 11/64 loss: 1.599778652191162
Batch 12/64 loss: 2.0174546241760254
Batch 13/64 loss: 1.8135395050048828
Batch 14/64 loss: 1.6137022972106934
Batch 15/64 loss: 1.8845534324645996
Batch 16/64 loss: 5.0919189453125
Batch 17/64 loss: 1.7181711196899414
Batch 18/64 loss: 1.725313663482666
Batch 19/64 loss: 1.5507454872131348
Batch 20/64 loss: 1.6943955421447754
Batch 21/64 loss: 1.6442818641662598
Batch 22/64 loss: 1.652153491973877
Batch 23/64 loss: 1.582993507385254
Batch 24/64 loss: 1.6311640739440918
Batch 25/64 loss: 1.8156981468200684
Batch 26/64 loss: 1.7153406143188477
Batch 27/64 loss: 1.6014657020568848
Batch 28/64 loss: 1.5581769943237305
Batch 29/64 loss: 1.90858793258667
Batch 30/64 loss: 1.5871248245239258
Batch 31/64 loss: 1.6077642440795898
Batch 32/64 loss: 1.6146836280822754
Batch 33/64 loss: 2.8968868255615234
Batch 34/64 loss: 1.5194387435913086
Batch 35/64 loss: 2.019127368927002
Batch 36/64 loss: 3.9902939796447754
Batch 37/64 loss: 1.6766581535339355
Batch 38/64 loss: 1.596611499786377
Batch 39/64 loss: 1.5766797065734863
Batch 40/64 loss: 1.5153322219848633
Batch 41/64 loss: 1.616805076599121
Batch 42/64 loss: 1.725076675415039
Batch 43/64 loss: 1.6187453269958496
Batch 44/64 loss: 1.5135741233825684
Batch 45/64 loss: 1.5003581047058105
Batch 46/64 loss: 1.6426663398742676
Batch 47/64 loss: 2.1661438941955566
Batch 48/64 loss: 1.6311092376708984
Batch 49/64 loss: 1.506791114807129
Batch 50/64 loss: 1.740316390991211
Batch 51/64 loss: 1.6805849075317383
Batch 52/64 loss: 1.5983781814575195
Batch 53/64 loss: 2.7111873626708984
Batch 54/64 loss: 1.5923104286193848
Batch 55/64 loss: 3.1102523803710938
Batch 56/64 loss: 1.7016401290893555
Batch 57/64 loss: 1.7018952369689941
Batch 58/64 loss: 3.890496253967285
Batch 59/64 loss: 1.821275234222412
Batch 60/64 loss: 1.7873668670654297
Batch 61/64 loss: 1.8193111419677734
Batch 62/64 loss: 1.727269172668457
Batch 63/64 loss: 1.861605167388916
Batch 64/64 loss: -1.656057357788086
Epoch 446  Train loss: 1.8504895303763595  Val loss: 1.7685649255706681
Epoch 447
-------------------------------
Batch 1/64 loss: 1.6860947608947754
Batch 2/64 loss: 1.719313144683838
Batch 3/64 loss: 1.8131675720214844
Batch 4/64 loss: 1.7716827392578125
Batch 5/64 loss: 1.7232379913330078
Batch 6/64 loss: 1.643162727355957
Batch 7/64 loss: 1.81512451171875
Batch 8/64 loss: 1.6649317741394043
Batch 9/64 loss: 1.7060084342956543
Batch 10/64 loss: 1.7238450050354004
Batch 11/64 loss: 1.848294734954834
Batch 12/64 loss: 1.8775410652160645
Batch 13/64 loss: 1.7415986061096191
Batch 14/64 loss: 1.6628608703613281
Batch 15/64 loss: 2.743504524230957
Batch 16/64 loss: 4.245078086853027
Batch 17/64 loss: 1.7480425834655762
Batch 18/64 loss: 1.6436009407043457
Batch 19/64 loss: 1.6739444732666016
Batch 20/64 loss: 1.628957748413086
Batch 21/64 loss: 1.7873249053955078
Batch 22/64 loss: 1.818833351135254
Batch 23/64 loss: 1.797715663909912
Batch 24/64 loss: 1.707075595855713
Batch 25/64 loss: 1.783165454864502
Batch 26/64 loss: 1.714585781097412
Batch 27/64 loss: 1.6653728485107422
Batch 28/64 loss: 1.6716570854187012
Batch 29/64 loss: 2.0858259201049805
Batch 30/64 loss: 1.6161932945251465
Batch 31/64 loss: 1.652115821838379
Batch 32/64 loss: 2.131145477294922
Batch 33/64 loss: 2.0401296615600586
Batch 34/64 loss: 1.7300810813903809
Batch 35/64 loss: 1.6807317733764648
Batch 36/64 loss: 1.7144112586975098
Batch 37/64 loss: 1.9227514266967773
Batch 38/64 loss: 1.7158279418945312
Batch 39/64 loss: 1.9570884704589844
Batch 40/64 loss: 1.5901365280151367
Batch 41/64 loss: 1.6683540344238281
Batch 42/64 loss: 2.236865520477295
Batch 43/64 loss: 1.6439695358276367
Batch 44/64 loss: 1.66367769241333
Batch 45/64 loss: 2.1114563941955566
Batch 46/64 loss: 1.7733049392700195
Batch 47/64 loss: 1.5476574897766113
Batch 48/64 loss: 1.5942416191101074
Batch 49/64 loss: 3.643101215362549
Batch 50/64 loss: 1.9075188636779785
Batch 51/64 loss: 3.7269134521484375
Batch 52/64 loss: 1.6901273727416992
Batch 53/64 loss: 1.6667232513427734
Batch 54/64 loss: 1.6128087043762207
Batch 55/64 loss: 2.355134963989258
Batch 56/64 loss: 1.8356537818908691
Batch 57/64 loss: 1.6336655616760254
Batch 58/64 loss: 1.9508190155029297
Batch 59/64 loss: 1.8709745407104492
Batch 60/64 loss: 1.7779135704040527
Batch 61/64 loss: 4.963598728179932
Batch 62/64 loss: 1.8925743103027344
Batch 63/64 loss: 1.680074691772461
Batch 64/64 loss: -1.6631298065185547
Epoch 447  Train loss: 1.8990108789182176  Val loss: 1.7346992099408023
Epoch 448
-------------------------------
Batch 1/64 loss: 1.6377720832824707
Batch 2/64 loss: 3.9289355278015137
Batch 3/64 loss: 1.6996502876281738
Batch 4/64 loss: 1.6224408149719238
Batch 5/64 loss: 1.8128318786621094
Batch 6/64 loss: 1.760693073272705
Batch 7/64 loss: 1.8344836235046387
Batch 8/64 loss: 1.8150181770324707
Batch 9/64 loss: 1.6045570373535156
Batch 10/64 loss: 1.7658038139343262
Batch 11/64 loss: 1.7711796760559082
Batch 12/64 loss: 1.8141698837280273
Batch 13/64 loss: 1.921663761138916
Batch 14/64 loss: 1.9608287811279297
Batch 15/64 loss: 1.6173529624938965
Batch 16/64 loss: 1.7181973457336426
Batch 17/64 loss: 1.6676735877990723
Batch 18/64 loss: 1.5753779411315918
Batch 19/64 loss: 1.7605085372924805
Batch 20/64 loss: 1.6161184310913086
Batch 21/64 loss: 1.618546962738037
Batch 22/64 loss: 1.7103829383850098
Batch 23/64 loss: 2.5599546432495117
Batch 24/64 loss: 1.8509364128112793
Batch 25/64 loss: 1.72271728515625
Batch 26/64 loss: 1.7539892196655273
Batch 27/64 loss: 2.3499884605407715
Batch 28/64 loss: 1.612442970275879
Batch 29/64 loss: 1.7595024108886719
Batch 30/64 loss: 1.7695612907409668
Batch 31/64 loss: 1.9756083488464355
Batch 32/64 loss: 2.8926072120666504
Batch 33/64 loss: 2.7879724502563477
Batch 34/64 loss: 4.159488201141357
Batch 35/64 loss: 1.7516651153564453
Batch 36/64 loss: 1.5812053680419922
Batch 37/64 loss: 2.4683799743652344
Batch 38/64 loss: 1.8089914321899414
Batch 39/64 loss: 1.992051601409912
Batch 40/64 loss: 1.6970129013061523
Batch 41/64 loss: 2.246906280517578
Batch 42/64 loss: 1.740776538848877
Batch 43/64 loss: 2.0088815689086914
Batch 44/64 loss: 1.7399067878723145
Batch 45/64 loss: 4.636329174041748
Batch 46/64 loss: 1.9804773330688477
Batch 47/64 loss: 1.7711238861083984
Batch 48/64 loss: 2.1260299682617188
Batch 49/64 loss: 1.6371374130249023
Batch 50/64 loss: 1.9647903442382812
Batch 51/64 loss: 1.6201510429382324
Batch 52/64 loss: 1.5718135833740234
Batch 53/64 loss: 1.6524715423583984
Batch 54/64 loss: 1.9821605682373047
Batch 55/64 loss: 1.7741193771362305
Batch 56/64 loss: 1.689375400543213
Batch 57/64 loss: 1.5844221115112305
Batch 58/64 loss: 1.8629355430603027
Batch 59/64 loss: 1.917943000793457
Batch 60/64 loss: 1.7033209800720215
Batch 61/64 loss: 1.7705941200256348
Batch 62/64 loss: 1.5323538780212402
Batch 63/64 loss: 1.7960867881774902
Batch 64/64 loss: -1.549489974975586
Epoch 448  Train loss: 1.9117843478333716  Val loss: 1.4145926380485194
Epoch 449
-------------------------------
Batch 1/64 loss: 1.935628890991211
Batch 2/64 loss: 1.6050162315368652
Batch 3/64 loss: 1.8536396026611328
Batch 4/64 loss: 3.831936836242676
Batch 5/64 loss: 1.5688591003417969
Batch 6/64 loss: 1.7102160453796387
Batch 7/64 loss: 1.5905942916870117
Batch 8/64 loss: 1.5988516807556152
Batch 9/64 loss: 2.2351274490356445
Batch 10/64 loss: 1.5843491554260254
Batch 11/64 loss: 1.6538605690002441
Batch 12/64 loss: 1.8654069900512695
Batch 13/64 loss: 1.6065583229064941
Batch 14/64 loss: 1.9643487930297852
Batch 15/64 loss: 4.6299896240234375
Batch 16/64 loss: 1.727574348449707
Batch 17/64 loss: 2.007988452911377
Batch 18/64 loss: 1.5509529113769531
Batch 19/64 loss: 2.5320868492126465
Batch 20/64 loss: 1.877504825592041
Batch 21/64 loss: 1.913297176361084
Batch 22/64 loss: 1.6956758499145508
Batch 23/64 loss: 1.620349407196045
Batch 24/64 loss: 1.849130630493164
Batch 25/64 loss: 2.0327205657958984
Batch 26/64 loss: 1.6885590553283691
Batch 27/64 loss: 1.7873926162719727
Batch 28/64 loss: 1.756605625152588
Batch 29/64 loss: 1.6019501686096191
Batch 30/64 loss: 1.7078132629394531
Batch 31/64 loss: 1.6406707763671875
Batch 32/64 loss: 2.856755256652832
Batch 33/64 loss: 1.5685100555419922
Batch 34/64 loss: 1.8893795013427734
Batch 35/64 loss: 1.813586711883545
Batch 36/64 loss: 1.5732421875
Batch 37/64 loss: 1.831850528717041
Batch 38/64 loss: 1.894594669342041
Batch 39/64 loss: 1.6970014572143555
Batch 40/64 loss: 1.8185906410217285
Batch 41/64 loss: 1.5802521705627441
Batch 42/64 loss: 2.2611775398254395
Batch 43/64 loss: 1.7061781883239746
Batch 44/64 loss: 1.7152423858642578
Batch 45/64 loss: 1.7494983673095703
Batch 46/64 loss: 2.834649085998535
Batch 47/64 loss: 1.5531578063964844
Batch 48/64 loss: 1.8185739517211914
Batch 49/64 loss: 1.8988227844238281
Batch 50/64 loss: 1.8749513626098633
Batch 51/64 loss: 1.7974600791931152
Batch 52/64 loss: 1.6172394752502441
Batch 53/64 loss: 1.7737770080566406
Batch 54/64 loss: 4.0929059982299805
Batch 55/64 loss: 1.682337760925293
Batch 56/64 loss: 1.6729941368103027
Batch 57/64 loss: 1.5590143203735352
Batch 58/64 loss: 1.6668219566345215
Batch 59/64 loss: 1.6307768821716309
Batch 60/64 loss: 1.5666298866271973
Batch 61/64 loss: 1.550096035003662
Batch 62/64 loss: 1.6786775588989258
Batch 63/64 loss: 1.828991413116455
Batch 64/64 loss: -1.9126567840576172
Epoch 449  Train loss: 1.8642180498908547  Val loss: 1.4099211807513155
Epoch 450
-------------------------------
Batch 1/64 loss: 1.6715517044067383
Batch 2/64 loss: 1.5840606689453125
Batch 3/64 loss: 1.7907719612121582
Batch 4/64 loss: 1.8012418746948242
Batch 5/64 loss: 1.561549186706543
Batch 6/64 loss: 1.8636770248413086
Batch 7/64 loss: 2.7333579063415527
Batch 8/64 loss: 1.6997151374816895
Batch 9/64 loss: 1.6066370010375977
Batch 10/64 loss: 2.96781587600708
Batch 11/64 loss: 1.5834717750549316
Batch 12/64 loss: 1.605980396270752
Batch 13/64 loss: 1.6273417472839355
Batch 14/64 loss: 1.721789836883545
Batch 15/64 loss: 1.6799030303955078
Batch 16/64 loss: 1.5608391761779785
Batch 17/64 loss: 1.7381377220153809
Batch 18/64 loss: 1.7120914459228516
Batch 19/64 loss: 1.705686092376709
Batch 20/64 loss: 1.8953890800476074
Batch 21/64 loss: 1.8262743949890137
Batch 22/64 loss: 1.659822940826416
Batch 23/64 loss: 1.8028063774108887
Batch 24/64 loss: 3.8473105430603027
Batch 25/64 loss: 1.5649094581604004
Batch 26/64 loss: 1.5356254577636719
Batch 27/64 loss: 1.6910743713378906
Batch 28/64 loss: 1.5878586769104004
Batch 29/64 loss: 1.912485122680664
Batch 30/64 loss: 2.056393623352051
Batch 31/64 loss: 1.7471733093261719
Batch 32/64 loss: 1.527052879333496
Batch 33/64 loss: 1.8596816062927246
Batch 34/64 loss: 1.6140789985656738
Batch 35/64 loss: 1.7482194900512695
Batch 36/64 loss: 1.5061264038085938
Batch 37/64 loss: 1.821390151977539
Batch 38/64 loss: 1.6193056106567383
Batch 39/64 loss: 1.5842022895812988
Batch 40/64 loss: 1.6734232902526855
Batch 41/64 loss: 1.868767261505127
Batch 42/64 loss: 1.9639554023742676
Batch 43/64 loss: 1.7038288116455078
Batch 44/64 loss: 1.6365408897399902
Batch 45/64 loss: 1.60835599899292
Batch 46/64 loss: 4.599820613861084
Batch 47/64 loss: 1.6876459121704102
Batch 48/64 loss: 1.7427678108215332
Batch 49/64 loss: 4.021801948547363
Batch 50/64 loss: 1.6297969818115234
Batch 51/64 loss: 1.8072714805603027
Batch 52/64 loss: 2.451894760131836
Batch 53/64 loss: 1.8842740058898926
Batch 54/64 loss: 1.6561102867126465
Batch 55/64 loss: 1.7246594429016113
Batch 56/64 loss: 1.9182038307189941
Batch 57/64 loss: 1.9265732765197754
Batch 58/64 loss: 1.748504638671875
Batch 59/64 loss: 2.071070671081543
Batch 60/64 loss: 1.6080079078674316
Batch 61/64 loss: 1.8931670188903809
Batch 62/64 loss: 1.7092094421386719
Batch 63/64 loss: 2.601961612701416
Batch 64/64 loss: -1.8931159973144531
Epoch 450  Train loss: 1.8563227709601908  Val loss: 1.4326012994825226
Epoch 451
-------------------------------
Batch 1/64 loss: 1.7416691780090332
Batch 2/64 loss: 1.8678827285766602
Batch 3/64 loss: 1.62788724899292
Batch 4/64 loss: 1.554114818572998
Batch 5/64 loss: 1.6828203201293945
Batch 6/64 loss: 1.785287857055664
Batch 7/64 loss: 1.6717453002929688
Batch 8/64 loss: 1.6329479217529297
Batch 9/64 loss: 1.6730256080627441
Batch 10/64 loss: 1.5589852333068848
Batch 11/64 loss: 1.7503232955932617
Batch 12/64 loss: 1.6234869956970215
Batch 13/64 loss: 1.6432881355285645
Batch 14/64 loss: 1.6493568420410156
Batch 15/64 loss: 1.761636734008789
Batch 16/64 loss: 1.5763754844665527
Batch 17/64 loss: 1.7019071578979492
Batch 18/64 loss: 1.7285776138305664
Batch 19/64 loss: 1.7591848373413086
Batch 20/64 loss: 1.715919017791748
Batch 21/64 loss: 1.8847947120666504
Batch 22/64 loss: 1.7795891761779785
Batch 23/64 loss: 1.960331916809082
Batch 24/64 loss: 1.7602415084838867
Batch 25/64 loss: 1.739091396331787
Batch 26/64 loss: 2.6777596473693848
Batch 27/64 loss: 1.9817218780517578
Batch 28/64 loss: 4.600088119506836
Batch 29/64 loss: 1.5724549293518066
Batch 30/64 loss: 1.4929404258728027
Batch 31/64 loss: 1.5482268333435059
Batch 32/64 loss: 1.7262959480285645
Batch 33/64 loss: 1.7397632598876953
Batch 34/64 loss: 1.6527538299560547
Batch 35/64 loss: 3.1289615631103516
Batch 36/64 loss: 2.0002522468566895
Batch 37/64 loss: 1.600860595703125
Batch 38/64 loss: 1.6212239265441895
Batch 39/64 loss: 1.6065006256103516
Batch 40/64 loss: 1.6658740043640137
Batch 41/64 loss: 4.705099105834961
Batch 42/64 loss: 1.5676460266113281
Batch 43/64 loss: 1.7205896377563477
Batch 44/64 loss: 1.8336753845214844
Batch 45/64 loss: 1.5673556327819824
Batch 46/64 loss: 1.5843825340270996
Batch 47/64 loss: 1.6762800216674805
Batch 48/64 loss: 1.922846794128418
Batch 49/64 loss: 1.5371761322021484
Batch 50/64 loss: 1.5462908744812012
Batch 51/64 loss: 1.6618375778198242
Batch 52/64 loss: 1.7145366668701172
Batch 53/64 loss: 1.7220449447631836
Batch 54/64 loss: 1.5975756645202637
Batch 55/64 loss: 1.6083288192749023
Batch 56/64 loss: 4.131227493286133
Batch 57/64 loss: 1.5895018577575684
Batch 58/64 loss: 1.642982006072998
Batch 59/64 loss: 1.7783927917480469
Batch 60/64 loss: 1.6814212799072266
Batch 61/64 loss: 2.2147369384765625
Batch 62/64 loss: 1.6075801849365234
Batch 63/64 loss: 1.555093765258789
Batch 64/64 loss: -1.9392452239990234
Epoch 451  Train loss: 1.8220912484561695  Val loss: 1.4257786937595642
Epoch 452
-------------------------------
Batch 1/64 loss: 1.9685783386230469
Batch 2/64 loss: 1.6452999114990234
Batch 3/64 loss: 1.5786190032958984
Batch 4/64 loss: 1.7111468315124512
Batch 5/64 loss: 1.7426152229309082
Batch 6/64 loss: 1.9128551483154297
Batch 7/64 loss: 1.685708999633789
Batch 8/64 loss: 1.7167673110961914
Batch 9/64 loss: 1.6262874603271484
Batch 10/64 loss: 2.071950912475586
Batch 11/64 loss: 1.7016596794128418
Batch 12/64 loss: 1.8206000328063965
Batch 13/64 loss: 2.2430577278137207
Batch 14/64 loss: 1.5806431770324707
Batch 15/64 loss: 1.874460220336914
Batch 16/64 loss: 1.5277628898620605
Batch 17/64 loss: 1.7931079864501953
Batch 18/64 loss: 1.49638032913208
Batch 19/64 loss: 4.532540798187256
Batch 20/64 loss: 1.6580467224121094
Batch 21/64 loss: 1.596144199371338
Batch 22/64 loss: 1.6552138328552246
Batch 23/64 loss: 2.1535072326660156
Batch 24/64 loss: 1.7065320014953613
Batch 25/64 loss: 1.5602941513061523
Batch 26/64 loss: 1.6819257736206055
Batch 27/64 loss: 1.7327041625976562
Batch 28/64 loss: 1.5591731071472168
Batch 29/64 loss: 1.571056842803955
Batch 30/64 loss: 1.6386590003967285
Batch 31/64 loss: 1.5316758155822754
Batch 32/64 loss: 1.6082749366760254
Batch 33/64 loss: 1.5817217826843262
Batch 34/64 loss: 3.9454684257507324
Batch 35/64 loss: 1.5098795890808105
Batch 36/64 loss: 1.7538042068481445
Batch 37/64 loss: 1.6780214309692383
Batch 38/64 loss: 1.5908403396606445
Batch 39/64 loss: 1.645442008972168
Batch 40/64 loss: 1.5831847190856934
Batch 41/64 loss: 1.6953063011169434
Batch 42/64 loss: 1.6137127876281738
Batch 43/64 loss: 1.6239652633666992
Batch 44/64 loss: 2.846013069152832
Batch 45/64 loss: 1.9678668975830078
Batch 46/64 loss: 1.5574984550476074
Batch 47/64 loss: 1.645017147064209
Batch 48/64 loss: 1.5480079650878906
Batch 49/64 loss: 1.952530860900879
Batch 50/64 loss: 1.5219488143920898
Batch 51/64 loss: 1.4947443008422852
Batch 52/64 loss: 1.5648951530456543
Batch 53/64 loss: 1.9914851188659668
Batch 54/64 loss: 1.5672354698181152
Batch 55/64 loss: 2.704834461212158
Batch 56/64 loss: 3.8054652214050293
Batch 57/64 loss: 1.5146350860595703
Batch 58/64 loss: 1.6168971061706543
Batch 59/64 loss: 1.7713375091552734
Batch 60/64 loss: 1.5062751770019531
Batch 61/64 loss: 2.3264570236206055
Batch 62/64 loss: 1.5481295585632324
Batch 63/64 loss: 1.903151035308838
Batch 64/64 loss: -1.951430320739746
Epoch 452  Train loss: 1.8038501851698931  Val loss: 1.3574019101067507
Epoch 453
-------------------------------
Batch 1/64 loss: 1.628394603729248
Batch 2/64 loss: 1.5669856071472168
Batch 3/64 loss: 1.573021411895752
Batch 4/64 loss: 1.673232078552246
Batch 5/64 loss: 1.5855021476745605
Batch 6/64 loss: 1.4607949256896973
Batch 7/64 loss: 1.7105636596679688
Batch 8/64 loss: 1.5845003128051758
Batch 9/64 loss: 1.8089179992675781
Batch 10/64 loss: 1.5280084609985352
Batch 11/64 loss: 1.7983455657958984
Batch 12/64 loss: 1.6312718391418457
Batch 13/64 loss: 1.7242989540100098
Batch 14/64 loss: 1.7380409240722656
Batch 15/64 loss: 1.584174633026123
Batch 16/64 loss: 1.559952735900879
Batch 17/64 loss: 2.1823034286499023
Batch 18/64 loss: 1.6624293327331543
Batch 19/64 loss: 2.287623882293701
Batch 20/64 loss: 1.5651497840881348
Batch 21/64 loss: 1.614206314086914
Batch 22/64 loss: 1.646878719329834
Batch 23/64 loss: 1.6367511749267578
Batch 24/64 loss: 1.654076099395752
Batch 25/64 loss: 1.6087274551391602
Batch 26/64 loss: 1.909501552581787
Batch 27/64 loss: 1.8290696144104004
Batch 28/64 loss: 1.642808437347412
Batch 29/64 loss: 1.6753630638122559
Batch 30/64 loss: 1.5336976051330566
Batch 31/64 loss: 2.521517276763916
Batch 32/64 loss: 1.586658000946045
Batch 33/64 loss: 1.6868624687194824
Batch 34/64 loss: 1.4883818626403809
Batch 35/64 loss: 1.655080795288086
Batch 36/64 loss: 4.934442043304443
Batch 37/64 loss: 1.5280218124389648
Batch 38/64 loss: 1.6278753280639648
Batch 39/64 loss: 1.5862445831298828
Batch 40/64 loss: 4.922873020172119
Batch 41/64 loss: 1.657280445098877
Batch 42/64 loss: 2.6026105880737305
Batch 43/64 loss: 1.7000598907470703
Batch 44/64 loss: 1.5706820487976074
Batch 45/64 loss: 1.787428379058838
Batch 46/64 loss: 1.542140007019043
Batch 47/64 loss: 1.5724306106567383
Batch 48/64 loss: 1.7615270614624023
Batch 49/64 loss: 1.5844683647155762
Batch 50/64 loss: 1.6449980735778809
Batch 51/64 loss: 1.574519157409668
Batch 52/64 loss: 1.540238380432129
Batch 53/64 loss: 1.537717342376709
Batch 54/64 loss: 1.5764708518981934
Batch 55/64 loss: 1.6384148597717285
Batch 56/64 loss: 1.6153230667114258
Batch 57/64 loss: 1.66558837890625
Batch 58/64 loss: 1.6074562072753906
Batch 59/64 loss: 2.0374789237976074
Batch 60/64 loss: 4.009470462799072
Batch 61/64 loss: 1.5564565658569336
Batch 62/64 loss: 1.6834301948547363
Batch 63/64 loss: 1.5393800735473633
Batch 64/64 loss: -1.8752756118774414
Epoch 453  Train loss: 1.7841829449522728  Val loss: 1.3553424586135496
Epoch 454
-------------------------------
Batch 1/64 loss: 1.5237078666687012
Batch 2/64 loss: 3.103353977203369
Batch 3/64 loss: 1.5856356620788574
Batch 4/64 loss: 1.5058660507202148
Batch 5/64 loss: 1.6226143836975098
Batch 6/64 loss: 1.5605511665344238
Batch 7/64 loss: 1.7251496315002441
Batch 8/64 loss: 1.566270351409912
Batch 9/64 loss: 1.692944049835205
Batch 10/64 loss: 1.5169987678527832
Batch 11/64 loss: 1.5908503532409668
Batch 12/64 loss: 1.6773757934570312
Batch 13/64 loss: 1.4972620010375977
Batch 14/64 loss: 1.5541496276855469
Batch 15/64 loss: 1.4690570831298828
Batch 16/64 loss: 1.4637703895568848
Batch 17/64 loss: 1.5867900848388672
Batch 18/64 loss: 1.556070327758789
Batch 19/64 loss: 1.5030779838562012
Batch 20/64 loss: 1.7313838005065918
Batch 21/64 loss: 1.6962890625
Batch 22/64 loss: 1.633936882019043
Batch 23/64 loss: 1.5298619270324707
Batch 24/64 loss: 1.7551050186157227
Batch 25/64 loss: 1.7054505348205566
Batch 26/64 loss: 3.9416117668151855
Batch 27/64 loss: 1.721269130706787
Batch 28/64 loss: 4.619082450866699
Batch 29/64 loss: 2.829397201538086
Batch 30/64 loss: 1.6021389961242676
Batch 31/64 loss: 1.6661477088928223
Batch 32/64 loss: 1.586545467376709
Batch 33/64 loss: 1.6609678268432617
Batch 34/64 loss: 1.5313806533813477
Batch 35/64 loss: 1.66864013671875
Batch 36/64 loss: 1.5091543197631836
Batch 37/64 loss: 1.612389087677002
Batch 38/64 loss: 2.341360092163086
Batch 39/64 loss: 2.1639723777770996
Batch 40/64 loss: 1.7593917846679688
Batch 41/64 loss: 1.5213532447814941
Batch 42/64 loss: 1.666121482849121
Batch 43/64 loss: 1.5404620170593262
Batch 44/64 loss: 1.5789241790771484
Batch 45/64 loss: 2.44205379486084
Batch 46/64 loss: 1.7808194160461426
Batch 47/64 loss: 2.405547618865967
Batch 48/64 loss: 1.589376449584961
Batch 49/64 loss: 1.7265090942382812
Batch 50/64 loss: 1.906167984008789
Batch 51/64 loss: 1.715467929840088
Batch 52/64 loss: 1.6936941146850586
Batch 53/64 loss: 1.6373372077941895
Batch 54/64 loss: 1.697634220123291
Batch 55/64 loss: 1.601534366607666
Batch 56/64 loss: 2.3958845138549805
Batch 57/64 loss: 3.701864719390869
Batch 58/64 loss: 1.523056983947754
Batch 59/64 loss: 1.7003846168518066
Batch 60/64 loss: 1.6069955825805664
Batch 61/64 loss: 1.71681547164917
Batch 62/64 loss: 1.648770809173584
Batch 63/64 loss: 1.5612850189208984
Batch 64/64 loss: -1.9322471618652344
Epoch 454  Train loss: 1.7956995646158853  Val loss: 1.3886571274590247
Epoch 455
-------------------------------
Batch 1/64 loss: 1.8421387672424316
Batch 2/64 loss: 1.8571710586547852
Batch 3/64 loss: 1.8179011344909668
Batch 4/64 loss: 1.5871052742004395
Batch 5/64 loss: 1.7510786056518555
Batch 6/64 loss: 1.7781386375427246
Batch 7/64 loss: 1.6514949798583984
Batch 8/64 loss: 1.6113309860229492
Batch 9/64 loss: 1.540268898010254
Batch 10/64 loss: 1.8758206367492676
Batch 11/64 loss: 1.7022662162780762
Batch 12/64 loss: 2.6039657592773438
Batch 13/64 loss: 1.6214337348937988
Batch 14/64 loss: 1.660222053527832
Batch 15/64 loss: 1.7619123458862305
Batch 16/64 loss: 1.5811347961425781
Batch 17/64 loss: 1.7175841331481934
Batch 18/64 loss: 1.6462178230285645
Batch 19/64 loss: 1.7170743942260742
Batch 20/64 loss: 4.16806697845459
Batch 21/64 loss: 1.5539569854736328
Batch 22/64 loss: 1.789982795715332
Batch 23/64 loss: 1.888493537902832
Batch 24/64 loss: 1.6758980751037598
Batch 25/64 loss: 1.6219267845153809
Batch 26/64 loss: 1.6329116821289062
Batch 27/64 loss: 1.772775650024414
Batch 28/64 loss: 1.6032695770263672
Batch 29/64 loss: 2.3572473526000977
Batch 30/64 loss: 1.6713933944702148
Batch 31/64 loss: 1.567446231842041
Batch 32/64 loss: 1.6444525718688965
Batch 33/64 loss: 1.5798983573913574
Batch 34/64 loss: 1.738579273223877
Batch 35/64 loss: 1.642235279083252
Batch 36/64 loss: 1.6225080490112305
Batch 37/64 loss: 1.5639290809631348
Batch 38/64 loss: 6.805355548858643
Batch 39/64 loss: 1.6674537658691406
Batch 40/64 loss: 1.6889209747314453
Batch 41/64 loss: 1.5091967582702637
Batch 42/64 loss: 1.585479736328125
Batch 43/64 loss: 1.5851454734802246
Batch 44/64 loss: 1.5429234504699707
Batch 45/64 loss: 1.6323699951171875
Batch 46/64 loss: 2.254314422607422
Batch 47/64 loss: 1.6470351219177246
Batch 48/64 loss: 1.7642083168029785
Batch 49/64 loss: 1.6551251411437988
Batch 50/64 loss: 1.5873241424560547
Batch 51/64 loss: 1.580380916595459
Batch 52/64 loss: 1.9786829948425293
Batch 53/64 loss: 1.7762045860290527
Batch 54/64 loss: 1.6136431694030762
Batch 55/64 loss: 1.8946232795715332
Batch 56/64 loss: 1.9335107803344727
Batch 57/64 loss: 2.376791477203369
Batch 58/64 loss: 1.7085018157958984
Batch 59/64 loss: 1.7202463150024414
Batch 60/64 loss: 1.6709017753601074
Batch 61/64 loss: 1.5691947937011719
Batch 62/64 loss: 1.6743550300598145
Batch 63/64 loss: 2.7552995681762695
Batch 64/64 loss: -1.7215385437011719
Epoch 455  Train loss: 1.8243963503370098  Val loss: 1.371650302533022
Epoch 456
-------------------------------
Batch 1/64 loss: 1.7598352432250977
Batch 2/64 loss: 1.5674057006835938
Batch 3/64 loss: 1.579716682434082
Batch 4/64 loss: 1.6853418350219727
Batch 5/64 loss: 1.559445858001709
Batch 6/64 loss: 1.525890827178955
Batch 7/64 loss: 1.9210968017578125
Batch 8/64 loss: 1.6470541954040527
Batch 9/64 loss: 4.8024983406066895
Batch 10/64 loss: 1.5938301086425781
Batch 11/64 loss: 1.7627439498901367
Batch 12/64 loss: 1.57847261428833
Batch 13/64 loss: 1.7678346633911133
Batch 14/64 loss: 1.754429817199707
Batch 15/64 loss: 1.821599006652832
Batch 16/64 loss: 1.776843547821045
Batch 17/64 loss: 1.6510095596313477
Batch 18/64 loss: 1.756678581237793
Batch 19/64 loss: 3.67079496383667
Batch 20/64 loss: 2.8210864067077637
Batch 21/64 loss: 1.530205249786377
Batch 22/64 loss: 2.704768180847168
Batch 23/64 loss: 2.706292152404785
Batch 24/64 loss: 1.8036670684814453
Batch 25/64 loss: 1.6824989318847656
Batch 26/64 loss: 1.6099286079406738
Batch 27/64 loss: 1.5926432609558105
Batch 28/64 loss: 1.7028069496154785
Batch 29/64 loss: 1.6396245956420898
Batch 30/64 loss: 1.7738347053527832
Batch 31/64 loss: 1.4968714714050293
Batch 32/64 loss: 1.5412631034851074
Batch 33/64 loss: 1.5263867378234863
Batch 34/64 loss: 1.6716809272766113
Batch 35/64 loss: 1.7175097465515137
Batch 36/64 loss: 1.765674114227295
Batch 37/64 loss: 1.6467432975769043
Batch 38/64 loss: 1.6335291862487793
Batch 39/64 loss: 1.6826376914978027
Batch 40/64 loss: 1.7090167999267578
Batch 41/64 loss: 2.555478096008301
Batch 42/64 loss: 1.6102313995361328
Batch 43/64 loss: 1.5695829391479492
Batch 44/64 loss: 1.5940899848937988
Batch 45/64 loss: 1.6659116744995117
Batch 46/64 loss: 1.6762490272521973
Batch 47/64 loss: 2.397125720977783
Batch 48/64 loss: 1.5121345520019531
Batch 49/64 loss: 1.6487808227539062
Batch 50/64 loss: 1.6429853439331055
Batch 51/64 loss: 4.570268630981445
Batch 52/64 loss: 1.6174883842468262
Batch 53/64 loss: 1.5653495788574219
Batch 54/64 loss: 1.6174359321594238
Batch 55/64 loss: 1.5540060997009277
Batch 56/64 loss: 1.5427322387695312
Batch 57/64 loss: 1.629957675933838
Batch 58/64 loss: 1.592576503753662
Batch 59/64 loss: 1.5732636451721191
Batch 60/64 loss: 1.5638060569763184
Batch 61/64 loss: 1.6452999114990234
Batch 62/64 loss: 1.665459156036377
Batch 63/64 loss: 1.8050122261047363
Batch 64/64 loss: -1.9881491661071777
Epoch 456  Train loss: 1.8112204738691742  Val loss: 1.3773100548183794
Epoch 457
-------------------------------
Batch 1/64 loss: 4.658893585205078
Batch 2/64 loss: 1.816366195678711
Batch 3/64 loss: 1.5886955261230469
Batch 4/64 loss: 1.6920995712280273
Batch 5/64 loss: 1.7832260131835938
Batch 6/64 loss: 1.5131287574768066
Batch 7/64 loss: 1.6392712593078613
Batch 8/64 loss: 1.7108550071716309
Batch 9/64 loss: 1.5277099609375
Batch 10/64 loss: 1.5152201652526855
Batch 11/64 loss: 1.5061607360839844
Batch 12/64 loss: 1.5289101600646973
Batch 13/64 loss: 1.6058311462402344
Batch 14/64 loss: 2.475914478302002
Batch 15/64 loss: 1.6084365844726562
Batch 16/64 loss: 1.5346159934997559
Batch 17/64 loss: 1.8609676361083984
Batch 18/64 loss: 1.6473307609558105
Batch 19/64 loss: 1.6877532005310059
Batch 20/64 loss: 1.679460048675537
Batch 21/64 loss: 1.6104555130004883
Batch 22/64 loss: 1.6147208213806152
Batch 23/64 loss: 3.9644651412963867
Batch 24/64 loss: 1.601668357849121
Batch 25/64 loss: 3.8689022064208984
Batch 26/64 loss: 1.6599221229553223
Batch 27/64 loss: 1.6441302299499512
Batch 28/64 loss: 1.657482624053955
Batch 29/64 loss: 1.6563677787780762
Batch 30/64 loss: 1.5830068588256836
Batch 31/64 loss: 1.634902000427246
Batch 32/64 loss: 1.5697498321533203
Batch 33/64 loss: 1.927706241607666
Batch 34/64 loss: 1.7618117332458496
Batch 35/64 loss: 1.7305316925048828
Batch 36/64 loss: 1.679245948791504
Batch 37/64 loss: 1.6426377296447754
Batch 38/64 loss: 1.5914640426635742
Batch 39/64 loss: 1.5805168151855469
Batch 40/64 loss: 1.5596308708190918
Batch 41/64 loss: 1.632591724395752
Batch 42/64 loss: 1.688859462738037
Batch 43/64 loss: 1.6822919845581055
Batch 44/64 loss: 1.6758060455322266
Batch 45/64 loss: 1.7532715797424316
Batch 46/64 loss: 1.6326370239257812
Batch 47/64 loss: 1.567850112915039
Batch 48/64 loss: 1.675147533416748
Batch 49/64 loss: 1.9382481575012207
Batch 50/64 loss: 1.7833023071289062
Batch 51/64 loss: 1.6929607391357422
Batch 52/64 loss: 2.8109374046325684
Batch 53/64 loss: 1.4851479530334473
Batch 54/64 loss: 1.6124138832092285
Batch 55/64 loss: 1.8526525497436523
Batch 56/64 loss: 1.592918872833252
Batch 57/64 loss: 2.7331066131591797
Batch 58/64 loss: 1.7304234504699707
Batch 59/64 loss: 1.6052870750427246
Batch 60/64 loss: 1.621239185333252
Batch 61/64 loss: 1.6678667068481445
Batch 62/64 loss: 1.8290681838989258
Batch 63/64 loss: 2.4329066276550293
Batch 64/64 loss: -1.890822410583496
Epoch 457  Train loss: 1.7944938622268976  Val loss: 1.364947381298157
Epoch 458
-------------------------------
Batch 1/64 loss: 1.581221103668213
Batch 2/64 loss: 1.6994853019714355
Batch 3/64 loss: 1.4993672370910645
Batch 4/64 loss: 1.6138949394226074
Batch 5/64 loss: 1.5615220069885254
Batch 6/64 loss: 1.8188567161560059
Batch 7/64 loss: 1.639059066772461
Batch 8/64 loss: 1.599229335784912
Batch 9/64 loss: 1.6028685569763184
Batch 10/64 loss: 4.552711486816406
Batch 11/64 loss: 1.744389533996582
Batch 12/64 loss: 1.623033046722412
Batch 13/64 loss: 1.540656566619873
Batch 14/64 loss: 2.2163891792297363
Batch 15/64 loss: 1.5079078674316406
Batch 16/64 loss: 1.6940679550170898
Batch 17/64 loss: 1.5884690284729004
Batch 18/64 loss: 2.085970878601074
Batch 19/64 loss: 1.635655403137207
Batch 20/64 loss: 1.6722426414489746
Batch 21/64 loss: 1.5744547843933105
Batch 22/64 loss: 2.689361572265625
Batch 23/64 loss: 1.5448613166809082
Batch 24/64 loss: 1.645948886871338
Batch 25/64 loss: 1.6795244216918945
Batch 26/64 loss: 1.6714248657226562
Batch 27/64 loss: 1.6700382232666016
Batch 28/64 loss: 2.218681812286377
Batch 29/64 loss: 1.5717344284057617
Batch 30/64 loss: 1.545957088470459
Batch 31/64 loss: 1.5966200828552246
Batch 32/64 loss: 1.865954875946045
Batch 33/64 loss: 1.7837820053100586
Batch 34/64 loss: 2.1472363471984863
Batch 35/64 loss: 1.6300249099731445
Batch 36/64 loss: 1.611128330230713
Batch 37/64 loss: 1.6149907112121582
Batch 38/64 loss: 1.5732536315917969
Batch 39/64 loss: 1.991715431213379
Batch 40/64 loss: 1.6130414009094238
Batch 41/64 loss: 4.5898308753967285
Batch 42/64 loss: 1.643937110900879
Batch 43/64 loss: 1.692596435546875
Batch 44/64 loss: 1.5683650970458984
Batch 45/64 loss: 1.9157066345214844
Batch 46/64 loss: 3.6751575469970703
Batch 47/64 loss: 1.7169137001037598
Batch 48/64 loss: 1.625136375427246
Batch 49/64 loss: 1.6465959548950195
Batch 50/64 loss: 1.5421056747436523
Batch 51/64 loss: 1.5090889930725098
Batch 52/64 loss: 1.6877036094665527
Batch 53/64 loss: 1.7013673782348633
Batch 54/64 loss: 1.5150647163391113
Batch 55/64 loss: 1.5507292747497559
Batch 56/64 loss: 1.9925756454467773
Batch 57/64 loss: 1.6515765190124512
Batch 58/64 loss: 1.5188961029052734
Batch 59/64 loss: 2.5798492431640625
Batch 60/64 loss: 1.7002501487731934
Batch 61/64 loss: 1.605942726135254
Batch 62/64 loss: 1.568979263305664
Batch 63/64 loss: 1.9843974113464355
Batch 64/64 loss: -1.7992172241210938
Epoch 458  Train loss: 1.796864101933498  Val loss: 1.3430915386816071
Epoch 459
-------------------------------
Batch 1/64 loss: 2.68582820892334
Batch 2/64 loss: 1.672041893005371
Batch 3/64 loss: 1.5574946403503418
Batch 4/64 loss: 1.4987072944641113
Batch 5/64 loss: 1.7328343391418457
Batch 6/64 loss: 1.603261947631836
Batch 7/64 loss: 1.605252742767334
Batch 8/64 loss: 1.5514049530029297
Batch 9/64 loss: 1.70997953414917
Batch 10/64 loss: 1.5787358283996582
Batch 11/64 loss: 1.5731415748596191
Batch 12/64 loss: 2.7248334884643555
Batch 13/64 loss: 1.6492547988891602
Batch 14/64 loss: 1.6438655853271484
Batch 15/64 loss: 1.8289122581481934
Batch 16/64 loss: 3.968125820159912
Batch 17/64 loss: 3.6478614807128906
Batch 18/64 loss: 1.6713790893554688
Batch 19/64 loss: 2.2097549438476562
Batch 20/64 loss: 1.7160000801086426
Batch 21/64 loss: 1.6574091911315918
Batch 22/64 loss: 1.615264892578125
Batch 23/64 loss: 1.5644259452819824
Batch 24/64 loss: 1.6361150741577148
Batch 25/64 loss: 1.6398248672485352
Batch 26/64 loss: 2.0152058601379395
Batch 27/64 loss: 2.030364513397217
Batch 28/64 loss: 1.6393465995788574
Batch 29/64 loss: 1.542374610900879
Batch 30/64 loss: 2.1224451065063477
Batch 31/64 loss: 1.6442842483520508
Batch 32/64 loss: 1.7237772941589355
Batch 33/64 loss: 1.6088752746582031
Batch 34/64 loss: 1.7193007469177246
Batch 35/64 loss: 1.6489591598510742
Batch 36/64 loss: 1.6476492881774902
Batch 37/64 loss: 1.6287522315979004
Batch 38/64 loss: 1.6277966499328613
Batch 39/64 loss: 2.416717052459717
Batch 40/64 loss: 1.877035140991211
Batch 41/64 loss: 1.7132787704467773
Batch 42/64 loss: 1.6220378875732422
Batch 43/64 loss: 1.579465389251709
Batch 44/64 loss: 1.525650978088379
Batch 45/64 loss: 1.6630454063415527
Batch 46/64 loss: 1.7928314208984375
Batch 47/64 loss: 1.9107298851013184
Batch 48/64 loss: 1.9129986763000488
Batch 49/64 loss: 1.9227519035339355
Batch 50/64 loss: 1.6844897270202637
Batch 51/64 loss: 1.5640268325805664
Batch 52/64 loss: 1.7635445594787598
Batch 53/64 loss: 1.6221084594726562
Batch 54/64 loss: 1.8243846893310547
Batch 55/64 loss: 1.740480899810791
Batch 56/64 loss: 1.8289098739624023
Batch 57/64 loss: 1.793271541595459
Batch 58/64 loss: 1.6093692779541016
Batch 59/64 loss: 1.7310199737548828
Batch 60/64 loss: 1.6163315773010254
Batch 61/64 loss: 1.6627235412597656
Batch 62/64 loss: 4.5958685874938965
Batch 63/64 loss: 1.7498607635498047
Batch 64/64 loss: -1.9508647918701172
Epoch 459  Train loss: 1.816480412202723  Val loss: 1.4069897104374731
Epoch 460
-------------------------------
Batch 1/64 loss: 1.5643377304077148
Batch 2/64 loss: 3.9691929817199707
Batch 3/64 loss: 1.629918098449707
Batch 4/64 loss: 2.232034683227539
Batch 5/64 loss: 1.678581714630127
Batch 6/64 loss: 1.7417263984680176
Batch 7/64 loss: 1.6268653869628906
Batch 8/64 loss: 1.5805244445800781
Batch 9/64 loss: 3.7888293266296387
Batch 10/64 loss: 1.7143406867980957
Batch 11/64 loss: 2.792853832244873
Batch 12/64 loss: 1.7263031005859375
Batch 13/64 loss: 1.7343978881835938
Batch 14/64 loss: 1.5984272956848145
Batch 15/64 loss: 1.7571892738342285
Batch 16/64 loss: 1.7031688690185547
Batch 17/64 loss: 1.614100456237793
Batch 18/64 loss: 1.6257905960083008
Batch 19/64 loss: 1.5927400588989258
Batch 20/64 loss: 1.6669425964355469
Batch 21/64 loss: 1.638709545135498
Batch 22/64 loss: 1.7002458572387695
Batch 23/64 loss: 1.697615146636963
Batch 24/64 loss: 1.6620144844055176
Batch 25/64 loss: 1.8537359237670898
Batch 26/64 loss: 1.5103874206542969
Batch 27/64 loss: 1.7110443115234375
Batch 28/64 loss: 1.6508660316467285
Batch 29/64 loss: 1.7816166877746582
Batch 30/64 loss: 1.5078372955322266
Batch 31/64 loss: 1.879539966583252
Batch 32/64 loss: 1.711343765258789
Batch 33/64 loss: 2.3707566261291504
Batch 34/64 loss: 1.516263484954834
Batch 35/64 loss: 1.9142136573791504
Batch 36/64 loss: 1.6904563903808594
Batch 37/64 loss: 1.6725082397460938
Batch 38/64 loss: 1.5615434646606445
Batch 39/64 loss: 2.828179359436035
Batch 40/64 loss: 1.8127293586730957
Batch 41/64 loss: 1.525190830230713
Batch 42/64 loss: 1.8085346221923828
Batch 43/64 loss: 1.9828429222106934
Batch 44/64 loss: 1.5653915405273438
Batch 45/64 loss: 1.5688457489013672
Batch 46/64 loss: 1.618271827697754
Batch 47/64 loss: 2.464616298675537
Batch 48/64 loss: 1.6194167137145996
Batch 49/64 loss: 1.6169977188110352
Batch 50/64 loss: 4.536905765533447
Batch 51/64 loss: 1.6267967224121094
Batch 52/64 loss: 1.6822619438171387
Batch 53/64 loss: 1.663741111755371
Batch 54/64 loss: 1.915999412536621
Batch 55/64 loss: 1.8932576179504395
Batch 56/64 loss: 1.813222885131836
Batch 57/64 loss: 1.6746768951416016
Batch 58/64 loss: 1.590998649597168
Batch 59/64 loss: 1.7199997901916504
Batch 60/64 loss: 1.62388277053833
Batch 61/64 loss: 1.6120281219482422
Batch 62/64 loss: 1.6789021492004395
Batch 63/64 loss: 1.6030468940734863
Batch 64/64 loss: -1.7352533340454102
Epoch 460  Train loss: 1.821400178647509  Val loss: 1.3888013518553008
Epoch 461
-------------------------------
Batch 1/64 loss: 1.5739731788635254
Batch 2/64 loss: 1.5595331192016602
Batch 3/64 loss: 1.560354232788086
Batch 4/64 loss: 1.5151495933532715
Batch 5/64 loss: 1.6433286666870117
Batch 6/64 loss: 1.6685090065002441
Batch 7/64 loss: 1.6036405563354492
Batch 8/64 loss: 1.6183266639709473
Batch 9/64 loss: 1.615396499633789
Batch 10/64 loss: 1.5687003135681152
Batch 11/64 loss: 1.6578311920166016
Batch 12/64 loss: 1.6988539695739746
Batch 13/64 loss: 1.6645264625549316
Batch 14/64 loss: 1.7468323707580566
Batch 15/64 loss: 1.5024070739746094
Batch 16/64 loss: 1.704272747039795
Batch 17/64 loss: 1.6401128768920898
Batch 18/64 loss: 1.7274565696716309
Batch 19/64 loss: 1.5252456665039062
Batch 20/64 loss: 1.8095803260803223
Batch 21/64 loss: 1.6302428245544434
Batch 22/64 loss: 1.7455883026123047
Batch 23/64 loss: 1.6668081283569336
Batch 24/64 loss: 3.9817490577697754
Batch 25/64 loss: 1.7087712287902832
Batch 26/64 loss: 4.658056735992432
Batch 27/64 loss: 1.8682303428649902
Batch 28/64 loss: 1.6418237686157227
Batch 29/64 loss: 2.7920732498168945
Batch 30/64 loss: 1.788285732269287
Batch 31/64 loss: 2.9971752166748047
Batch 32/64 loss: 1.7081060409545898
Batch 33/64 loss: 1.5771851539611816
Batch 34/64 loss: 1.7073111534118652
Batch 35/64 loss: 1.5653119087219238
Batch 36/64 loss: 3.0571069717407227
Batch 37/64 loss: 1.858414649963379
Batch 38/64 loss: 1.6402616500854492
Batch 39/64 loss: 1.5905704498291016
Batch 40/64 loss: 1.669306755065918
Batch 41/64 loss: 1.9288249015808105
Batch 42/64 loss: 1.7963871955871582
Batch 43/64 loss: 1.5303568840026855
Batch 44/64 loss: 1.757981300354004
Batch 45/64 loss: 1.5413188934326172
Batch 46/64 loss: 1.7123332023620605
Batch 47/64 loss: 3.8535547256469727
Batch 48/64 loss: 1.958054542541504
Batch 49/64 loss: 1.9589428901672363
Batch 50/64 loss: 1.6500310897827148
Batch 51/64 loss: 1.8947839736938477
Batch 52/64 loss: 2.07669734954834
Batch 53/64 loss: 1.7624115943908691
Batch 54/64 loss: 1.7918758392333984
Batch 55/64 loss: 2.0457711219787598
Batch 56/64 loss: 1.8803653717041016
Batch 57/64 loss: 1.829521656036377
Batch 58/64 loss: 1.6675825119018555
Batch 59/64 loss: 1.7403674125671387
Batch 60/64 loss: 2.2090911865234375
Batch 61/64 loss: 1.812647819519043
Batch 62/64 loss: 1.9424853324890137
Batch 63/64 loss: 1.838162899017334
Batch 64/64 loss: -1.8119888305664062
Epoch 461  Train loss: 1.8553249957514744  Val loss: 1.5734824872098838
Epoch 462
-------------------------------
Batch 1/64 loss: 2.0509257316589355
Batch 2/64 loss: 3.2921180725097656
Batch 3/64 loss: 2.8946805000305176
Batch 4/64 loss: 2.387423515319824
Batch 5/64 loss: 1.8497443199157715
Batch 6/64 loss: 1.8242053985595703
Batch 7/64 loss: 2.0329537391662598
Batch 8/64 loss: 1.716494083404541
Batch 9/64 loss: 1.7477045059204102
Batch 10/64 loss: 3.8823933601379395
Batch 11/64 loss: 3.033039093017578
Batch 12/64 loss: 1.865492820739746
Batch 13/64 loss: 1.7069931030273438
Batch 14/64 loss: 1.8134889602661133
Batch 15/64 loss: 1.7208786010742188
Batch 16/64 loss: 1.6359200477600098
Batch 17/64 loss: 1.865992546081543
Batch 18/64 loss: 1.884223461151123
Batch 19/64 loss: 1.8865966796875
Batch 20/64 loss: 1.6271090507507324
Batch 21/64 loss: 1.8515586853027344
Batch 22/64 loss: 1.7404141426086426
Batch 23/64 loss: 1.9528379440307617
Batch 24/64 loss: 1.8530559539794922
Batch 25/64 loss: 2.028653144836426
Batch 26/64 loss: 1.751176357269287
Batch 27/64 loss: 2.4002838134765625
Batch 28/64 loss: 1.6966700553894043
Batch 29/64 loss: 1.817176342010498
Batch 30/64 loss: 1.687718391418457
Batch 31/64 loss: 1.778841495513916
Batch 32/64 loss: 1.8919386863708496
Batch 33/64 loss: 2.3619680404663086
Batch 34/64 loss: 1.652897834777832
Batch 35/64 loss: 1.5569591522216797
Batch 36/64 loss: 1.9739909172058105
Batch 37/64 loss: 1.596257209777832
Batch 38/64 loss: 2.356421947479248
Batch 39/64 loss: 1.8078389167785645
Batch 40/64 loss: 1.717369556427002
Batch 41/64 loss: 2.241124153137207
Batch 42/64 loss: 4.325470447540283
Batch 43/64 loss: 1.6384387016296387
Batch 44/64 loss: 2.338738441467285
Batch 45/64 loss: 4.848176002502441
Batch 46/64 loss: 1.7953786849975586
Batch 47/64 loss: 1.754626750946045
Batch 48/64 loss: 1.7437925338745117
Batch 49/64 loss: 1.605058193206787
Batch 50/64 loss: 1.6975884437561035
Batch 51/64 loss: 2.267760753631592
Batch 52/64 loss: 1.8963532447814941
Batch 53/64 loss: 2.0027546882629395
Batch 54/64 loss: 1.7437758445739746
Batch 55/64 loss: 1.8131904602050781
Batch 56/64 loss: 1.7022738456726074
Batch 57/64 loss: 2.0185389518737793
Batch 58/64 loss: 1.66656494140625
Batch 59/64 loss: 1.7138762474060059
Batch 60/64 loss: 1.5983672142028809
Batch 61/64 loss: 1.7602043151855469
Batch 62/64 loss: 1.8256349563598633
Batch 63/64 loss: 1.6716437339782715
Batch 64/64 loss: -1.6568536758422852
Epoch 462  Train loss: 1.986181921117446  Val loss: 1.4376364114767908
Epoch 463
-------------------------------
Batch 1/64 loss: 1.5826606750488281
Batch 2/64 loss: 1.688882827758789
Batch 3/64 loss: 1.5604853630065918
Batch 4/64 loss: 1.71699857711792
Batch 5/64 loss: 1.6540002822875977
Batch 6/64 loss: 2.619900703430176
Batch 7/64 loss: 1.6001472473144531
Batch 8/64 loss: 1.6502904891967773
Batch 9/64 loss: 1.6129913330078125
Batch 10/64 loss: 1.8102269172668457
Batch 11/64 loss: 1.6976103782653809
Batch 12/64 loss: 1.7338371276855469
Batch 13/64 loss: 1.7455449104309082
Batch 14/64 loss: 1.5790653228759766
Batch 15/64 loss: 1.8186421394348145
Batch 16/64 loss: 1.8470101356506348
Batch 17/64 loss: 2.017838478088379
Batch 18/64 loss: 1.885530948638916
Batch 19/64 loss: 1.8296055793762207
Batch 20/64 loss: 1.7332572937011719
Batch 21/64 loss: 1.648869514465332
Batch 22/64 loss: 1.7032136917114258
Batch 23/64 loss: 1.8747539520263672
Batch 24/64 loss: 1.6303071975708008
Batch 25/64 loss: 1.6840877532958984
Batch 26/64 loss: 1.822166919708252
Batch 27/64 loss: 1.5872654914855957
Batch 28/64 loss: 1.644120216369629
Batch 29/64 loss: 1.7614355087280273
Batch 30/64 loss: 2.3381829261779785
Batch 31/64 loss: 2.312136173248291
Batch 32/64 loss: 1.661158561706543
Batch 33/64 loss: 1.592081069946289
Batch 34/64 loss: 1.888843059539795
Batch 35/64 loss: 1.56254243850708
Batch 36/64 loss: 1.6965270042419434
Batch 37/64 loss: 1.656604290008545
Batch 38/64 loss: 1.6622061729431152
Batch 39/64 loss: 1.5808734893798828
Batch 40/64 loss: 4.706673622131348
Batch 41/64 loss: 1.791013240814209
Batch 42/64 loss: 3.822524070739746
Batch 43/64 loss: 1.8168754577636719
Batch 44/64 loss: 2.6772680282592773
Batch 45/64 loss: 1.710127353668213
Batch 46/64 loss: 1.7131190299987793
Batch 47/64 loss: 1.6728630065917969
Batch 48/64 loss: 1.7960033416748047
Batch 49/64 loss: 1.9594335556030273
Batch 50/64 loss: 1.7535462379455566
Batch 51/64 loss: 2.7533884048461914
Batch 52/64 loss: 2.2212018966674805
Batch 53/64 loss: 1.7717065811157227
Batch 54/64 loss: 1.8694429397583008
Batch 55/64 loss: 1.7336273193359375
Batch 56/64 loss: 1.611802101135254
Batch 57/64 loss: 4.1764817237854
Batch 58/64 loss: 1.6665220260620117
Batch 59/64 loss: 1.7163915634155273
Batch 60/64 loss: 1.6993765830993652
Batch 61/64 loss: 1.7445464134216309
Batch 62/64 loss: 1.764256477355957
Batch 63/64 loss: 1.6893229484558105
Batch 64/64 loss: -1.7854928970336914
Epoch 463  Train loss: 1.8696517084159103  Val loss: 1.3978037358968938
Epoch 464
-------------------------------
Batch 1/64 loss: 4.2910475730896
Batch 2/64 loss: 1.5668950080871582
Batch 3/64 loss: 2.171928882598877
Batch 4/64 loss: 2.426236152648926
Batch 5/64 loss: 1.6172070503234863
Batch 6/64 loss: 1.6717290878295898
Batch 7/64 loss: 1.5566887855529785
Batch 8/64 loss: 2.350933074951172
Batch 9/64 loss: 1.6556882858276367
Batch 10/64 loss: 1.6159782409667969
Batch 11/64 loss: 1.6102938652038574
Batch 12/64 loss: 1.6422157287597656
Batch 13/64 loss: 1.708362102508545
Batch 14/64 loss: 1.748241901397705
Batch 15/64 loss: 1.910996913909912
Batch 16/64 loss: 1.534332275390625
Batch 17/64 loss: 1.8465142250061035
Batch 18/64 loss: 1.5923848152160645
Batch 19/64 loss: 1.787611484527588
Batch 20/64 loss: 1.8965497016906738
Batch 21/64 loss: 1.7119240760803223
Batch 22/64 loss: 1.629673957824707
Batch 23/64 loss: 2.5703539848327637
Batch 24/64 loss: 1.577085018157959
Batch 25/64 loss: 1.8116636276245117
Batch 26/64 loss: 1.7214512825012207
Batch 27/64 loss: 1.5676517486572266
Batch 28/64 loss: 1.6342997550964355
Batch 29/64 loss: 1.781827449798584
Batch 30/64 loss: 1.870129108428955
Batch 31/64 loss: 1.560330867767334
Batch 32/64 loss: 2.3540759086608887
Batch 33/64 loss: 1.8648533821105957
Batch 34/64 loss: 1.8526372909545898
Batch 35/64 loss: 4.53212833404541
Batch 36/64 loss: 1.6162362098693848
Batch 37/64 loss: 2.6029462814331055
Batch 38/64 loss: 1.4881134033203125
Batch 39/64 loss: 1.663599967956543
Batch 40/64 loss: 1.7541160583496094
Batch 41/64 loss: 2.693812370300293
Batch 42/64 loss: 1.5867338180541992
Batch 43/64 loss: 1.7385997772216797
Batch 44/64 loss: 1.681459903717041
Batch 45/64 loss: 3.761793613433838
Batch 46/64 loss: 1.7986884117126465
Batch 47/64 loss: 2.009701728820801
Batch 48/64 loss: 1.7534265518188477
Batch 49/64 loss: 1.6481857299804688
Batch 50/64 loss: 1.614027500152588
Batch 51/64 loss: 1.7067980766296387
Batch 52/64 loss: 1.631753921508789
Batch 53/64 loss: 1.9597620964050293
Batch 54/64 loss: 1.7396907806396484
Batch 55/64 loss: 1.6521005630493164
Batch 56/64 loss: 1.6174979209899902
Batch 57/64 loss: 1.8273353576660156
Batch 58/64 loss: 1.6472740173339844
Batch 59/64 loss: 1.6285090446472168
Batch 60/64 loss: 1.5628609657287598
Batch 61/64 loss: 1.630727767944336
Batch 62/64 loss: 1.8123688697814941
Batch 63/64 loss: 1.7825655937194824
Batch 64/64 loss: -1.8167524337768555
Epoch 464  Train loss: 1.858667339998133  Val loss: 1.3982923055432506
Epoch 465
-------------------------------
Batch 1/64 loss: 1.9185266494750977
Batch 2/64 loss: 1.6705665588378906
Batch 3/64 loss: 1.7421245574951172
Batch 4/64 loss: 1.7255287170410156
Batch 5/64 loss: 1.8137497901916504
Batch 6/64 loss: 1.6676907539367676
Batch 7/64 loss: 1.6398615837097168
Batch 8/64 loss: 2.3101515769958496
Batch 9/64 loss: 1.9767065048217773
Batch 10/64 loss: 1.7717790603637695
Batch 11/64 loss: 1.6039953231811523
Batch 12/64 loss: 1.619039535522461
Batch 13/64 loss: 1.9001250267028809
Batch 14/64 loss: 1.5427193641662598
Batch 15/64 loss: 1.6367416381835938
Batch 16/64 loss: 1.6059918403625488
Batch 17/64 loss: 2.022282123565674
Batch 18/64 loss: 1.8897266387939453
Batch 19/64 loss: 1.6195755004882812
Batch 20/64 loss: 1.552083969116211
Batch 21/64 loss: 1.7347850799560547
Batch 22/64 loss: 1.5516023635864258
Batch 23/64 loss: 1.6556243896484375
Batch 24/64 loss: 2.8794617652893066
Batch 25/64 loss: 1.62105131149292
Batch 26/64 loss: 1.6861810684204102
Batch 27/64 loss: 1.648634910583496
Batch 28/64 loss: 1.9723539352416992
Batch 29/64 loss: 1.8065204620361328
Batch 30/64 loss: 1.8384490013122559
Batch 31/64 loss: 1.6825852394104004
Batch 32/64 loss: 1.7367539405822754
Batch 33/64 loss: 2.0600337982177734
Batch 34/64 loss: 1.79514741897583
Batch 35/64 loss: 2.52333402633667
Batch 36/64 loss: 2.009326934814453
Batch 37/64 loss: 1.5353569984436035
Batch 38/64 loss: 1.62701416015625
Batch 39/64 loss: 1.8319153785705566
Batch 40/64 loss: 1.7120890617370605
Batch 41/64 loss: 1.7474756240844727
Batch 42/64 loss: 1.6902799606323242
Batch 43/64 loss: 1.699038028717041
Batch 44/64 loss: 1.598351001739502
Batch 45/64 loss: 1.965240478515625
Batch 46/64 loss: 1.7212390899658203
Batch 47/64 loss: 1.6534652709960938
Batch 48/64 loss: 1.78193998336792
Batch 49/64 loss: 1.6058859825134277
Batch 50/64 loss: 1.6865458488464355
Batch 51/64 loss: 4.095186233520508
Batch 52/64 loss: 1.6434564590454102
Batch 53/64 loss: 1.639289379119873
Batch 54/64 loss: 1.5743980407714844
Batch 55/64 loss: 1.790663242340088
Batch 56/64 loss: 1.5877223014831543
Batch 57/64 loss: 5.287238597869873
Batch 58/64 loss: 2.0426464080810547
Batch 59/64 loss: 1.5804271697998047
Batch 60/64 loss: 4.118536949157715
Batch 61/64 loss: 3.073153018951416
Batch 62/64 loss: 1.6006112098693848
Batch 63/64 loss: 1.6414108276367188
Batch 64/64 loss: -1.8446836471557617
Epoch 465  Train loss: 1.875731393402698  Val loss: 1.4210825654649244
Epoch 466
-------------------------------
Batch 1/64 loss: 2.0894675254821777
Batch 2/64 loss: 1.6732587814331055
Batch 3/64 loss: 1.5575284957885742
Batch 4/64 loss: 1.8213858604431152
Batch 5/64 loss: 1.7783970832824707
Batch 6/64 loss: 1.5958561897277832
Batch 7/64 loss: 1.6391549110412598
Batch 8/64 loss: 1.7434616088867188
Batch 9/64 loss: 1.6973261833190918
Batch 10/64 loss: 1.5866875648498535
Batch 11/64 loss: 1.6892881393432617
Batch 12/64 loss: 1.707169532775879
Batch 13/64 loss: 1.5449395179748535
Batch 14/64 loss: 1.9912095069885254
Batch 15/64 loss: 4.081222057342529
Batch 16/64 loss: 1.539362907409668
Batch 17/64 loss: 2.897090435028076
Batch 18/64 loss: 1.6632390022277832
Batch 19/64 loss: 1.7021055221557617
Batch 20/64 loss: 3.0288681983947754
Batch 21/64 loss: 1.6595854759216309
Batch 22/64 loss: 2.1669116020202637
Batch 23/64 loss: 1.7146778106689453
Batch 24/64 loss: 2.51224946975708
Batch 25/64 loss: 1.7125329971313477
Batch 26/64 loss: 2.278902053833008
Batch 27/64 loss: 1.565253734588623
Batch 28/64 loss: 1.6714601516723633
Batch 29/64 loss: 1.5833768844604492
Batch 30/64 loss: 1.8998260498046875
Batch 31/64 loss: 1.9455227851867676
Batch 32/64 loss: 1.750166416168213
Batch 33/64 loss: 1.563539981842041
Batch 34/64 loss: 3.8007946014404297
Batch 35/64 loss: 1.6042537689208984
Batch 36/64 loss: 1.5986847877502441
Batch 37/64 loss: 1.643918514251709
Batch 38/64 loss: 1.7628421783447266
Batch 39/64 loss: 1.5226383209228516
Batch 40/64 loss: 1.5442290306091309
Batch 41/64 loss: 1.7353277206420898
Batch 42/64 loss: 1.5581746101379395
Batch 43/64 loss: 1.5964279174804688
Batch 44/64 loss: 2.100949764251709
Batch 45/64 loss: 1.510983943939209
Batch 46/64 loss: 1.6235570907592773
Batch 47/64 loss: 1.6548571586608887
Batch 48/64 loss: 1.7628216743469238
Batch 49/64 loss: 4.518413543701172
Batch 50/64 loss: 1.8595366477966309
Batch 51/64 loss: 2.299067497253418
Batch 52/64 loss: 1.5279669761657715
Batch 53/64 loss: 1.5165748596191406
Batch 54/64 loss: 1.6077523231506348
Batch 55/64 loss: 1.5011143684387207
Batch 56/64 loss: 1.7939066886901855
Batch 57/64 loss: 1.644704818725586
Batch 58/64 loss: 1.516775131225586
Batch 59/64 loss: 1.7127842903137207
Batch 60/64 loss: 1.7819948196411133
Batch 61/64 loss: 1.544365406036377
Batch 62/64 loss: 1.7451119422912598
Batch 63/64 loss: 1.6498932838439941
Batch 64/64 loss: -1.667313575744629
Epoch 466  Train loss: 1.835936673482259  Val loss: 1.3814603667898275
Epoch 467
-------------------------------
Batch 1/64 loss: 1.525038719177246
Batch 2/64 loss: 1.5538296699523926
Batch 3/64 loss: 1.6169953346252441
Batch 4/64 loss: 2.811678886413574
Batch 5/64 loss: 1.7477946281433105
Batch 6/64 loss: 1.9268412590026855
Batch 7/64 loss: 1.5715880393981934
Batch 8/64 loss: 2.213393211364746
Batch 9/64 loss: 1.7103643417358398
Batch 10/64 loss: 1.6166019439697266
Batch 11/64 loss: 1.6623668670654297
Batch 12/64 loss: 1.6494240760803223
Batch 13/64 loss: 1.577993392944336
Batch 14/64 loss: 1.7273650169372559
Batch 15/64 loss: 1.6844491958618164
Batch 16/64 loss: 2.560826301574707
Batch 17/64 loss: 1.9344005584716797
Batch 18/64 loss: 4.0189127922058105
Batch 19/64 loss: 1.606328010559082
Batch 20/64 loss: 2.0784292221069336
Batch 21/64 loss: 1.5899357795715332
Batch 22/64 loss: 1.7075247764587402
Batch 23/64 loss: 1.6433906555175781
Batch 24/64 loss: 1.6161513328552246
Batch 25/64 loss: 2.092834949493408
Batch 26/64 loss: 1.6760497093200684
Batch 27/64 loss: 1.5435185432434082
Batch 28/64 loss: 1.6631946563720703
Batch 29/64 loss: 1.5403976440429688
Batch 30/64 loss: 1.7590055465698242
Batch 31/64 loss: 1.5175137519836426
Batch 32/64 loss: 1.5999336242675781
Batch 33/64 loss: 1.6176114082336426
Batch 34/64 loss: 1.6236352920532227
Batch 35/64 loss: 2.0010056495666504
Batch 36/64 loss: 1.500533103942871
Batch 37/64 loss: 1.5680475234985352
Batch 38/64 loss: 1.740495204925537
Batch 39/64 loss: 1.8448066711425781
Batch 40/64 loss: 1.6182966232299805
Batch 41/64 loss: 1.655003547668457
Batch 42/64 loss: 1.8368926048278809
Batch 43/64 loss: 2.671518325805664
Batch 44/64 loss: 1.610288143157959
Batch 45/64 loss: 2.9505233764648438
Batch 46/64 loss: 1.950882911682129
Batch 47/64 loss: 1.9153919219970703
Batch 48/64 loss: 4.674098968505859
Batch 49/64 loss: 1.667323112487793
Batch 50/64 loss: 1.5895299911499023
Batch 51/64 loss: 1.5842976570129395
Batch 52/64 loss: 3.7509069442749023
Batch 53/64 loss: 1.7288484573364258
Batch 54/64 loss: 1.561323642730713
Batch 55/64 loss: 1.6251740455627441
Batch 56/64 loss: 1.4780192375183105
Batch 57/64 loss: 1.6704087257385254
Batch 58/64 loss: 1.6063518524169922
Batch 59/64 loss: 1.5608768463134766
Batch 60/64 loss: 1.6981010437011719
Batch 61/64 loss: 1.746523380279541
Batch 62/64 loss: 1.534146785736084
Batch 63/64 loss: 1.785940170288086
Batch 64/64 loss: -1.917459487915039
Epoch 467  Train loss: 1.8301612704407935  Val loss: 1.333609446627168
Epoch 468
-------------------------------
Batch 1/64 loss: 1.512498378753662
Batch 2/64 loss: 1.7167391777038574
Batch 3/64 loss: 1.556596279144287
Batch 4/64 loss: 1.7100849151611328
Batch 5/64 loss: 1.6112079620361328
Batch 6/64 loss: 1.7502880096435547
Batch 7/64 loss: 2.3432536125183105
Batch 8/64 loss: 1.6945204734802246
Batch 9/64 loss: 1.6040563583374023
Batch 10/64 loss: 1.598238468170166
Batch 11/64 loss: 1.6092500686645508
Batch 12/64 loss: 1.7752819061279297
Batch 13/64 loss: 1.5144410133361816
Batch 14/64 loss: 1.6302618980407715
Batch 15/64 loss: 1.6780672073364258
Batch 16/64 loss: 2.018764019012451
Batch 17/64 loss: 1.6374483108520508
Batch 18/64 loss: 1.7749261856079102
Batch 19/64 loss: 1.6047134399414062
Batch 20/64 loss: 3.9906506538391113
Batch 21/64 loss: 1.7584176063537598
Batch 22/64 loss: 1.5397276878356934
Batch 23/64 loss: 1.857619285583496
Batch 24/64 loss: 1.6116266250610352
Batch 25/64 loss: 1.7238430976867676
Batch 26/64 loss: 1.4971766471862793
Batch 27/64 loss: 1.6029996871948242
Batch 28/64 loss: 1.5749831199645996
Batch 29/64 loss: 2.806380271911621
Batch 30/64 loss: 1.5267972946166992
Batch 31/64 loss: 1.6051344871520996
Batch 32/64 loss: 1.970524787902832
Batch 33/64 loss: 1.65285062789917
Batch 34/64 loss: 1.5624909400939941
Batch 35/64 loss: 1.7466564178466797
Batch 36/64 loss: 1.5472955703735352
Batch 37/64 loss: 1.5966682434082031
Batch 38/64 loss: 1.9640264511108398
Batch 39/64 loss: 1.5317802429199219
Batch 40/64 loss: 1.618710994720459
Batch 41/64 loss: 1.5987434387207031
Batch 42/64 loss: 2.1516528129577637
Batch 43/64 loss: 1.6598544120788574
Batch 44/64 loss: 1.6334967613220215
Batch 45/64 loss: 1.661086082458496
Batch 46/64 loss: 1.6072821617126465
Batch 47/64 loss: 1.5662713050842285
Batch 48/64 loss: 1.5584440231323242
Batch 49/64 loss: 1.662264347076416
Batch 50/64 loss: 3.6158809661865234
Batch 51/64 loss: 4.6043243408203125
Batch 52/64 loss: 1.6037321090698242
Batch 53/64 loss: 1.6161503791809082
Batch 54/64 loss: 1.571629524230957
Batch 55/64 loss: 1.597318172454834
Batch 56/64 loss: 1.6229372024536133
Batch 57/64 loss: 1.7304515838623047
Batch 58/64 loss: 2.2633213996887207
Batch 59/64 loss: 1.6924314498901367
Batch 60/64 loss: 1.68735933303833
Batch 61/64 loss: 2.444100856781006
Batch 62/64 loss: 1.5564289093017578
Batch 63/64 loss: 2.7751007080078125
Batch 64/64 loss: -1.6770458221435547
Epoch 468  Train loss: 1.8015604131362017  Val loss: 1.3407691352555842
Epoch 469
-------------------------------
Batch 1/64 loss: 1.8662562370300293
Batch 2/64 loss: 1.8162031173706055
Batch 3/64 loss: 1.7297396659851074
Batch 4/64 loss: 1.5948753356933594
Batch 5/64 loss: 1.6434054374694824
Batch 6/64 loss: 1.5894489288330078
Batch 7/64 loss: 1.652782917022705
Batch 8/64 loss: 1.6001362800598145
Batch 9/64 loss: 1.5278515815734863
Batch 10/64 loss: 4.392427444458008
Batch 11/64 loss: 1.6687917709350586
Batch 12/64 loss: 1.9080758094787598
Batch 13/64 loss: 1.6644830703735352
Batch 14/64 loss: 1.8046040534973145
Batch 15/64 loss: 1.6732382774353027
Batch 16/64 loss: 1.56282377243042
Batch 17/64 loss: 1.9176568984985352
Batch 18/64 loss: 1.5569496154785156
Batch 19/64 loss: 2.3056468963623047
Batch 20/64 loss: 1.579854965209961
Batch 21/64 loss: 1.6577873229980469
Batch 22/64 loss: 1.636375904083252
Batch 23/64 loss: 1.5438861846923828
Batch 24/64 loss: 3.56402587890625
Batch 25/64 loss: 1.6715741157531738
Batch 26/64 loss: 1.758100986480713
Batch 27/64 loss: 2.5938048362731934
Batch 28/64 loss: 1.668717861175537
Batch 29/64 loss: 2.325230598449707
Batch 30/64 loss: 1.9941935539245605
Batch 31/64 loss: 1.7236299514770508
Batch 32/64 loss: 1.5500898361206055
Batch 33/64 loss: 2.029698371887207
Batch 34/64 loss: 1.7688612937927246
Batch 35/64 loss: 2.9325671195983887
Batch 36/64 loss: 1.6884970664978027
Batch 37/64 loss: 1.7297539710998535
Batch 38/64 loss: 1.6863112449645996
Batch 39/64 loss: 1.8861160278320312
Batch 40/64 loss: 1.8358569145202637
Batch 41/64 loss: 1.7040214538574219
Batch 42/64 loss: 1.721010684967041
Batch 43/64 loss: 1.7008976936340332
Batch 44/64 loss: 1.5704693794250488
Batch 45/64 loss: 2.6020684242248535
Batch 46/64 loss: 1.743438720703125
Batch 47/64 loss: 1.7356419563293457
Batch 48/64 loss: 2.538785457611084
Batch 49/64 loss: 1.7783799171447754
Batch 50/64 loss: 2.4745664596557617
Batch 51/64 loss: 1.7316594123840332
Batch 52/64 loss: 1.6694755554199219
Batch 53/64 loss: 4.650775909423828
Batch 54/64 loss: 1.7225074768066406
Batch 55/64 loss: 1.6403594017028809
Batch 56/64 loss: 2.8361663818359375
Batch 57/64 loss: 1.5807733535766602
Batch 58/64 loss: 1.5622949600219727
Batch 59/64 loss: 1.6503453254699707
Batch 60/64 loss: 1.7477998733520508
Batch 61/64 loss: 1.6093378067016602
Batch 62/64 loss: 1.691906452178955
Batch 63/64 loss: 1.6523423194885254
Batch 64/64 loss: -1.8604459762573242
Epoch 469  Train loss: 1.885804251128552  Val loss: 1.4316131224746966
Epoch 470
-------------------------------
Batch 1/64 loss: 1.6269989013671875
Batch 2/64 loss: 1.5326552391052246
Batch 3/64 loss: 1.7063584327697754
Batch 4/64 loss: 1.6870970726013184
Batch 5/64 loss: 4.5184645652771
Batch 6/64 loss: 1.7014837265014648
Batch 7/64 loss: 1.5479121208190918
Batch 8/64 loss: 1.669672966003418
Batch 9/64 loss: 1.646932601928711
Batch 10/64 loss: 1.6396293640136719
Batch 11/64 loss: 1.717379093170166
Batch 12/64 loss: 1.719459056854248
Batch 13/64 loss: 1.7291183471679688
Batch 14/64 loss: 1.6556038856506348
Batch 15/64 loss: 1.6133337020874023
Batch 16/64 loss: 1.7493648529052734
Batch 17/64 loss: 1.6295342445373535
Batch 18/64 loss: 1.6647944450378418
Batch 19/64 loss: 1.5885710716247559
Batch 20/64 loss: 1.7187647819519043
Batch 21/64 loss: 1.8060755729675293
Batch 22/64 loss: 1.9651503562927246
Batch 23/64 loss: 2.152589797973633
Batch 24/64 loss: 1.6676831245422363
Batch 25/64 loss: 1.521629810333252
Batch 26/64 loss: 1.9070014953613281
Batch 27/64 loss: 1.532505989074707
Batch 28/64 loss: 3.981905937194824
Batch 29/64 loss: 2.0550622940063477
Batch 30/64 loss: 1.6061339378356934
Batch 31/64 loss: 2.1325535774230957
Batch 32/64 loss: 4.780923366546631
Batch 33/64 loss: 1.6681041717529297
Batch 34/64 loss: 1.951880931854248
Batch 35/64 loss: 2.1733145713806152
Batch 36/64 loss: 1.6974120140075684
Batch 37/64 loss: 1.683548927307129
Batch 38/64 loss: 1.6738405227661133
Batch 39/64 loss: 1.6468677520751953
Batch 40/64 loss: 2.903172492980957
Batch 41/64 loss: 1.8737735748291016
Batch 42/64 loss: 1.485241413116455
Batch 43/64 loss: 1.664292812347412
Batch 44/64 loss: 2.0420966148376465
Batch 45/64 loss: 1.710014820098877
Batch 46/64 loss: 1.7734966278076172
Batch 47/64 loss: 2.5872154235839844
Batch 48/64 loss: 1.6897525787353516
Batch 49/64 loss: 1.6877198219299316
Batch 50/64 loss: 2.6889867782592773
Batch 51/64 loss: 1.8051252365112305
Batch 52/64 loss: 1.7903132438659668
Batch 53/64 loss: 2.074038028717041
Batch 54/64 loss: 2.5641937255859375
Batch 55/64 loss: 1.965883731842041
Batch 56/64 loss: 1.6946539878845215
Batch 57/64 loss: 1.593332290649414
Batch 58/64 loss: 1.7337260246276855
Batch 59/64 loss: 1.6702046394348145
Batch 60/64 loss: 1.6838350296020508
Batch 61/64 loss: 1.6530308723449707
Batch 62/64 loss: 1.5600576400756836
Batch 63/64 loss: 1.5758800506591797
Batch 64/64 loss: -1.9119338989257812
Epoch 470  Train loss: 1.8777003867953432  Val loss: 1.3828279685318674
Epoch 471
-------------------------------
Batch 1/64 loss: 1.6888689994812012
Batch 2/64 loss: 1.6476125717163086
Batch 3/64 loss: 1.5363507270812988
Batch 4/64 loss: 1.541123390197754
Batch 5/64 loss: 1.6511635780334473
Batch 6/64 loss: 1.7384214401245117
Batch 7/64 loss: 1.641268253326416
Batch 8/64 loss: 1.9892520904541016
Batch 9/64 loss: 2.039273738861084
Batch 10/64 loss: 1.6462883949279785
Batch 11/64 loss: 1.5753517150878906
Batch 12/64 loss: 1.6468515396118164
Batch 13/64 loss: 1.7134857177734375
Batch 14/64 loss: 1.6292219161987305
Batch 15/64 loss: 1.5824437141418457
Batch 16/64 loss: 1.6891169548034668
Batch 17/64 loss: 1.8011250495910645
Batch 18/64 loss: 1.798201084136963
Batch 19/64 loss: 2.359055519104004
Batch 20/64 loss: 2.9525718688964844
Batch 21/64 loss: 1.7969999313354492
Batch 22/64 loss: 1.8714618682861328
Batch 23/64 loss: 1.6278629302978516
Batch 24/64 loss: 1.8952927589416504
Batch 25/64 loss: 4.764638423919678
Batch 26/64 loss: 1.6388206481933594
Batch 27/64 loss: 1.7917084693908691
Batch 28/64 loss: 2.635314464569092
Batch 29/64 loss: 1.8513994216918945
Batch 30/64 loss: 1.6375908851623535
Batch 31/64 loss: 1.9787535667419434
Batch 32/64 loss: 1.5751399993896484
Batch 33/64 loss: 1.694694995880127
Batch 34/64 loss: 1.6297574043273926
Batch 35/64 loss: 1.6607246398925781
Batch 36/64 loss: 1.8206391334533691
Batch 37/64 loss: 1.6672334671020508
Batch 38/64 loss: 1.4683175086975098
Batch 39/64 loss: 1.6671652793884277
Batch 40/64 loss: 1.673004150390625
Batch 41/64 loss: 1.6318745613098145
Batch 42/64 loss: 1.9034318923950195
Batch 43/64 loss: 2.5646848678588867
Batch 44/64 loss: 1.6748924255371094
Batch 45/64 loss: 1.6134490966796875
Batch 46/64 loss: 5.78155517578125
Batch 47/64 loss: 1.601618766784668
Batch 48/64 loss: 1.6982698440551758
Batch 49/64 loss: 1.7780866622924805
Batch 50/64 loss: 1.5829620361328125
Batch 51/64 loss: 1.6844100952148438
Batch 52/64 loss: 1.5629081726074219
Batch 53/64 loss: 1.5292878150939941
Batch 54/64 loss: 1.471517562866211
Batch 55/64 loss: 2.8702688217163086
Batch 56/64 loss: 1.7634592056274414
Batch 57/64 loss: 1.6490731239318848
Batch 58/64 loss: 1.7960357666015625
Batch 59/64 loss: 1.7093486785888672
Batch 60/64 loss: 2.075404167175293
Batch 61/64 loss: 1.9704484939575195
Batch 62/64 loss: 1.6980738639831543
Batch 63/64 loss: 1.5516009330749512
Batch 64/64 loss: -1.8515424728393555
Epoch 471  Train loss: 1.8507854648664885  Val loss: 1.4107632194597697
Epoch 472
-------------------------------
Batch 1/64 loss: 1.657210350036621
Batch 2/64 loss: 1.8040132522583008
Batch 3/64 loss: 1.6913962364196777
Batch 4/64 loss: 1.8133597373962402
Batch 5/64 loss: 1.9133243560791016
Batch 6/64 loss: 2.166718006134033
Batch 7/64 loss: 1.721203327178955
Batch 8/64 loss: 1.636474609375
Batch 9/64 loss: 2.098571300506592
Batch 10/64 loss: 1.7443857192993164
Batch 11/64 loss: 1.9432635307312012
Batch 12/64 loss: 1.700098991394043
Batch 13/64 loss: 2.341585636138916
Batch 14/64 loss: 1.8210554122924805
Batch 15/64 loss: 2.562378406524658
Batch 16/64 loss: 1.7189602851867676
Batch 17/64 loss: 1.856210708618164
Batch 18/64 loss: 1.6849160194396973
Batch 19/64 loss: 2.053926467895508
Batch 20/64 loss: 2.1957197189331055
Batch 21/64 loss: 1.9084792137145996
Batch 22/64 loss: 2.100034236907959
Batch 23/64 loss: 1.8556275367736816
Batch 24/64 loss: 1.682152271270752
Batch 25/64 loss: 1.6474571228027344
Batch 26/64 loss: 2.663268566131592
Batch 27/64 loss: 1.9918632507324219
Batch 28/64 loss: 1.662768840789795
Batch 29/64 loss: 1.8139805793762207
Batch 30/64 loss: 1.7601637840270996
Batch 31/64 loss: 1.6776447296142578
Batch 32/64 loss: 2.221406936645508
Batch 33/64 loss: 1.5280871391296387
Batch 34/64 loss: 2.815730094909668
Batch 35/64 loss: 1.6166343688964844
Batch 36/64 loss: 1.5849976539611816
Batch 37/64 loss: 1.8794126510620117
Batch 38/64 loss: 1.648477554321289
Batch 39/64 loss: 1.7648415565490723
Batch 40/64 loss: 1.6255698204040527
Batch 41/64 loss: 4.02094841003418
Batch 42/64 loss: 1.550769329071045
Batch 43/64 loss: 1.9184937477111816
Batch 44/64 loss: 1.525174617767334
Batch 45/64 loss: 1.6489696502685547
Batch 46/64 loss: 3.9425911903381348
Batch 47/64 loss: 1.6282052993774414
Batch 48/64 loss: 1.5624279975891113
Batch 49/64 loss: 3.068854808807373
Batch 50/64 loss: 1.72021484375
Batch 51/64 loss: 1.7133946418762207
Batch 52/64 loss: 1.7648215293884277
Batch 53/64 loss: 1.7206101417541504
Batch 54/64 loss: 1.6592025756835938
Batch 55/64 loss: 1.6761016845703125
Batch 56/64 loss: 4.635328769683838
Batch 57/64 loss: 1.7508597373962402
Batch 58/64 loss: 1.6345157623291016
Batch 59/64 loss: 1.6674308776855469
Batch 60/64 loss: 1.595381259918213
Batch 61/64 loss: 1.8022189140319824
Batch 62/64 loss: 1.673013687133789
Batch 63/64 loss: 1.8914456367492676
Batch 64/64 loss: -1.7305383682250977
Epoch 472  Train loss: 1.914453981436935  Val loss: 1.4448768641940506
Epoch 473
-------------------------------
Batch 1/64 loss: 4.6449174880981445
Batch 2/64 loss: 1.6384897232055664
Batch 3/64 loss: 1.8768887519836426
Batch 4/64 loss: 1.669325351715088
Batch 5/64 loss: 1.7230634689331055
Batch 6/64 loss: 1.6973085403442383
Batch 7/64 loss: 1.607424259185791
Batch 8/64 loss: 1.8281021118164062
Batch 9/64 loss: 1.6567044258117676
Batch 10/64 loss: 2.282927989959717
Batch 11/64 loss: 1.6715335845947266
Batch 12/64 loss: 1.932140827178955
Batch 13/64 loss: 1.9833784103393555
Batch 14/64 loss: 1.6729860305786133
Batch 15/64 loss: 2.5241518020629883
Batch 16/64 loss: 1.6114225387573242
Batch 17/64 loss: 1.5588774681091309
Batch 18/64 loss: 1.6137304306030273
Batch 19/64 loss: 1.9819684028625488
Batch 20/64 loss: 1.6964831352233887
Batch 21/64 loss: 1.8532500267028809
Batch 22/64 loss: 5.246755123138428
Batch 23/64 loss: 1.6124205589294434
Batch 24/64 loss: 1.9045429229736328
Batch 25/64 loss: 1.851548194885254
Batch 26/64 loss: 1.558962345123291
Batch 27/64 loss: 1.6396546363830566
Batch 28/64 loss: 1.549135684967041
Batch 29/64 loss: 1.843233585357666
Batch 30/64 loss: 1.679044246673584
Batch 31/64 loss: 2.1399683952331543
Batch 32/64 loss: 1.6031928062438965
Batch 33/64 loss: 1.5972294807434082
Batch 34/64 loss: 2.019054889678955
Batch 35/64 loss: 1.6693038940429688
Batch 36/64 loss: 2.843277931213379
Batch 37/64 loss: 1.6654658317565918
Batch 38/64 loss: 1.5065836906433105
Batch 39/64 loss: 1.6224136352539062
Batch 40/64 loss: 1.5958342552185059
Batch 41/64 loss: 1.5701179504394531
Batch 42/64 loss: 1.623857021331787
Batch 43/64 loss: 1.7316641807556152
Batch 44/64 loss: 1.6593480110168457
Batch 45/64 loss: 1.6620254516601562
Batch 46/64 loss: 1.5740342140197754
Batch 47/64 loss: 2.407796859741211
Batch 48/64 loss: 1.6425561904907227
Batch 49/64 loss: 1.7410211563110352
Batch 50/64 loss: 1.5936617851257324
Batch 51/64 loss: 1.7208013534545898
Batch 52/64 loss: 1.921971321105957
Batch 53/64 loss: 1.5920672416687012
Batch 54/64 loss: 3.713869571685791
Batch 55/64 loss: 2.0189762115478516
Batch 56/64 loss: 1.615896224975586
Batch 57/64 loss: 1.6092381477355957
Batch 58/64 loss: 2.237001419067383
Batch 59/64 loss: 1.6269288063049316
Batch 60/64 loss: 1.6622085571289062
Batch 61/64 loss: 1.7208662033081055
Batch 62/64 loss: 1.4714694023132324
Batch 63/64 loss: 1.5315122604370117
Batch 64/64 loss: -1.9351091384887695
Epoch 473  Train loss: 1.8520824245378082  Val loss: 1.4063500735358274
Epoch 474
-------------------------------
Batch 1/64 loss: 2.877033233642578
Batch 2/64 loss: 1.7831664085388184
Batch 3/64 loss: 1.656099796295166
Batch 4/64 loss: 1.6333503723144531
Batch 5/64 loss: 4.566990852355957
Batch 6/64 loss: 1.7200918197631836
Batch 7/64 loss: 5.759120464324951
Batch 8/64 loss: 1.592604160308838
Batch 9/64 loss: 1.6271209716796875
Batch 10/64 loss: 1.574190616607666
Batch 11/64 loss: 1.9159598350524902
Batch 12/64 loss: 1.6502690315246582
Batch 13/64 loss: 1.7605867385864258
Batch 14/64 loss: 1.6394290924072266
Batch 15/64 loss: 2.9206442832946777
Batch 16/64 loss: 1.560534954071045
Batch 17/64 loss: 1.8880977630615234
Batch 18/64 loss: 1.626237392425537
Batch 19/64 loss: 1.6150479316711426
Batch 20/64 loss: 1.947390079498291
Batch 21/64 loss: 1.6042499542236328
Batch 22/64 loss: 1.570446491241455
Batch 23/64 loss: 1.7013649940490723
Batch 24/64 loss: 1.744269847869873
Batch 25/64 loss: 1.692131519317627
Batch 26/64 loss: 1.9232592582702637
Batch 27/64 loss: 1.7763705253601074
Batch 28/64 loss: 1.5975337028503418
Batch 29/64 loss: 1.6737275123596191
Batch 30/64 loss: 1.7272348403930664
Batch 31/64 loss: 1.6407995223999023
Batch 32/64 loss: 1.628354549407959
Batch 33/64 loss: 1.6350932121276855
Batch 34/64 loss: 1.6870980262756348
Batch 35/64 loss: 1.618640422821045
Batch 36/64 loss: 1.8460259437561035
Batch 37/64 loss: 1.6482725143432617
Batch 38/64 loss: 1.5771398544311523
Batch 39/64 loss: 1.898526668548584
Batch 40/64 loss: 1.7861895561218262
Batch 41/64 loss: 2.5730538368225098
Batch 42/64 loss: 1.738966464996338
Batch 43/64 loss: 1.6280651092529297
Batch 44/64 loss: 1.7256431579589844
Batch 45/64 loss: 1.7931313514709473
Batch 46/64 loss: 1.6248078346252441
Batch 47/64 loss: 1.5970029830932617
Batch 48/64 loss: 1.919813632965088
Batch 49/64 loss: 2.843710422515869
Batch 50/64 loss: 1.6512813568115234
Batch 51/64 loss: 2.147854804992676
Batch 52/64 loss: 1.6450285911560059
Batch 53/64 loss: 1.8247437477111816
Batch 54/64 loss: 1.7686538696289062
Batch 55/64 loss: 1.6837706565856934
Batch 56/64 loss: 1.5840959548950195
Batch 57/64 loss: 1.6541399955749512
Batch 58/64 loss: 1.6507835388183594
Batch 59/64 loss: 1.6007771492004395
Batch 60/64 loss: 1.5909290313720703
Batch 61/64 loss: 1.576002597808838
Batch 62/64 loss: 1.7078685760498047
Batch 63/64 loss: 1.6920280456542969
Batch 64/64 loss: -1.8163251876831055
Epoch 474  Train loss: 1.837656526004567  Val loss: 1.4470178925294648
Epoch 475
-------------------------------
Batch 1/64 loss: 1.5394287109375
Batch 2/64 loss: 1.629716396331787
Batch 3/64 loss: 1.7758636474609375
Batch 4/64 loss: 1.5891156196594238
Batch 5/64 loss: 2.0209717750549316
Batch 6/64 loss: 1.6022353172302246
Batch 7/64 loss: 1.6463184356689453
Batch 8/64 loss: 1.7517046928405762
Batch 9/64 loss: 1.6303973197937012
Batch 10/64 loss: 1.6219305992126465
Batch 11/64 loss: 1.6942553520202637
Batch 12/64 loss: 1.715522289276123
Batch 13/64 loss: 1.5624680519104004
Batch 14/64 loss: 1.702894687652588
Batch 15/64 loss: 2.888087749481201
Batch 16/64 loss: 1.8081307411193848
Batch 17/64 loss: 1.8307456970214844
Batch 18/64 loss: 4.808411598205566
Batch 19/64 loss: 1.702868938446045
Batch 20/64 loss: 1.7239723205566406
Batch 21/64 loss: 1.5660576820373535
Batch 22/64 loss: 2.102318286895752
Batch 23/64 loss: 1.645148754119873
Batch 24/64 loss: 1.5632009506225586
Batch 25/64 loss: 1.5632662773132324
Batch 26/64 loss: 2.2722268104553223
Batch 27/64 loss: 1.5664796829223633
Batch 28/64 loss: 2.237640857696533
Batch 29/64 loss: 1.724743366241455
Batch 30/64 loss: 1.6722540855407715
Batch 31/64 loss: 1.6483988761901855
Batch 32/64 loss: 1.6358470916748047
Batch 33/64 loss: 1.6309242248535156
Batch 34/64 loss: 1.7414140701293945
Batch 35/64 loss: 3.8590831756591797
Batch 36/64 loss: 1.653101921081543
Batch 37/64 loss: 1.5836668014526367
Batch 38/64 loss: 1.558079719543457
Batch 39/64 loss: 1.5808253288269043
Batch 40/64 loss: 1.600477695465088
Batch 41/64 loss: 1.632014274597168
Batch 42/64 loss: 2.088776111602783
Batch 43/64 loss: 1.7626023292541504
Batch 44/64 loss: 1.62955904006958
Batch 45/64 loss: 1.5471653938293457
Batch 46/64 loss: 2.5224928855895996
Batch 47/64 loss: 1.527881145477295
Batch 48/64 loss: 1.674485683441162
Batch 49/64 loss: 1.7550811767578125
Batch 50/64 loss: 2.0137429237365723
Batch 51/64 loss: 1.6568450927734375
Batch 52/64 loss: 1.6168861389160156
Batch 53/64 loss: 1.9096527099609375
Batch 54/64 loss: 1.9588651657104492
Batch 55/64 loss: 1.8622360229492188
Batch 56/64 loss: 1.6777291297912598
Batch 57/64 loss: 4.151763916015625
Batch 58/64 loss: 1.6410479545593262
Batch 59/64 loss: 1.8403472900390625
Batch 60/64 loss: 1.7356109619140625
Batch 61/64 loss: 1.640355110168457
Batch 62/64 loss: 1.7430620193481445
Batch 63/64 loss: 1.5608954429626465
Batch 64/64 loss: -0.6468267440795898
Epoch 475  Train loss: 1.840222328784419  Val loss: 1.4221539317127765
Epoch 476
-------------------------------
Batch 1/64 loss: 1.529191017150879
Batch 2/64 loss: 1.986429214477539
Batch 3/64 loss: 1.6292648315429688
Batch 4/64 loss: 1.9154376983642578
Batch 5/64 loss: 1.6549172401428223
Batch 6/64 loss: 1.6594386100769043
Batch 7/64 loss: 1.827545166015625
Batch 8/64 loss: 1.7164607048034668
Batch 9/64 loss: 1.826150894165039
Batch 10/64 loss: 1.6390352249145508
Batch 11/64 loss: 1.625089168548584
Batch 12/64 loss: 1.842416763305664
Batch 13/64 loss: 1.510976791381836
Batch 14/64 loss: 1.5849504470825195
Batch 15/64 loss: 2.5323634147644043
Batch 16/64 loss: 1.7576065063476562
Batch 17/64 loss: 1.5230426788330078
Batch 18/64 loss: 1.6437692642211914
Batch 19/64 loss: 1.5944104194641113
Batch 20/64 loss: 1.5836873054504395
Batch 21/64 loss: 1.7448725700378418
Batch 22/64 loss: 1.9458680152893066
Batch 23/64 loss: 4.518688678741455
Batch 24/64 loss: 1.661226749420166
Batch 25/64 loss: 1.7714929580688477
Batch 26/64 loss: 1.8309741020202637
Batch 27/64 loss: 1.8560962677001953
Batch 28/64 loss: 2.63018798828125
Batch 29/64 loss: 1.725234031677246
Batch 30/64 loss: 1.549501895904541
Batch 31/64 loss: 1.8497495651245117
Batch 32/64 loss: 1.6644973754882812
Batch 33/64 loss: 1.6708555221557617
Batch 34/64 loss: 1.596954345703125
Batch 35/64 loss: 1.7568635940551758
Batch 36/64 loss: 1.6969666481018066
Batch 37/64 loss: 1.6809349060058594
Batch 38/64 loss: 1.7311315536499023
Batch 39/64 loss: 1.786607265472412
Batch 40/64 loss: 1.6979055404663086
Batch 41/64 loss: 1.5330514907836914
Batch 42/64 loss: 1.5339412689208984
Batch 43/64 loss: 1.7431344985961914
Batch 44/64 loss: 1.6482253074645996
Batch 45/64 loss: 1.7058043479919434
Batch 46/64 loss: 1.9756364822387695
Batch 47/64 loss: 4.175097942352295
Batch 48/64 loss: 3.75594425201416
Batch 49/64 loss: 1.9123992919921875
Batch 50/64 loss: 1.8717832565307617
Batch 51/64 loss: 1.576075553894043
Batch 52/64 loss: 1.5156636238098145
Batch 53/64 loss: 1.5785880088806152
Batch 54/64 loss: 1.7465453147888184
Batch 55/64 loss: 1.6985454559326172
Batch 56/64 loss: 2.568274974822998
Batch 57/64 loss: 1.6124882698059082
Batch 58/64 loss: 1.6955342292785645
Batch 59/64 loss: 1.6840171813964844
Batch 60/64 loss: 1.7328929901123047
Batch 61/64 loss: 1.664900779724121
Batch 62/64 loss: 2.2649850845336914
Batch 63/64 loss: 2.7228646278381348
Batch 64/64 loss: -1.8946819305419922
Epoch 476  Train loss: 1.8422615799249387  Val loss: 1.4181325591306915
Epoch 477
-------------------------------
Batch 1/64 loss: 4.11649227142334
Batch 2/64 loss: 1.734178066253662
Batch 3/64 loss: 2.3574538230895996
Batch 4/64 loss: 1.6522269248962402
Batch 5/64 loss: 1.8557372093200684
Batch 6/64 loss: 1.6572842597961426
Batch 7/64 loss: 1.7222380638122559
Batch 8/64 loss: 1.632455825805664
Batch 9/64 loss: 1.9129366874694824
Batch 10/64 loss: 1.550222396850586
Batch 11/64 loss: 1.5303049087524414
Batch 12/64 loss: 1.84242582321167
Batch 13/64 loss: 1.7511305809020996
Batch 14/64 loss: 1.7277541160583496
Batch 15/64 loss: 2.446798324584961
Batch 16/64 loss: 1.746077060699463
Batch 17/64 loss: 1.7001852989196777
Batch 18/64 loss: 1.695054054260254
Batch 19/64 loss: 4.157412528991699
Batch 20/64 loss: 1.7559394836425781
Batch 21/64 loss: 1.669497013092041
Batch 22/64 loss: 1.5869669914245605
Batch 23/64 loss: 1.5609521865844727
Batch 24/64 loss: 1.9325175285339355
Batch 25/64 loss: 1.5838799476623535
Batch 26/64 loss: 1.5857763290405273
Batch 27/64 loss: 1.7950959205627441
Batch 28/64 loss: 1.6701078414916992
Batch 29/64 loss: 1.6516199111938477
Batch 30/64 loss: 1.6301846504211426
Batch 31/64 loss: 1.5597243309020996
Batch 32/64 loss: 1.6140251159667969
Batch 33/64 loss: 1.6602725982666016
Batch 34/64 loss: 2.704897880554199
Batch 35/64 loss: 1.5885920524597168
Batch 36/64 loss: 1.6391925811767578
Batch 37/64 loss: 1.6907615661621094
Batch 38/64 loss: 2.3361997604370117
Batch 39/64 loss: 1.602560043334961
Batch 40/64 loss: 1.5326900482177734
Batch 41/64 loss: 1.6278815269470215
Batch 42/64 loss: 1.6104888916015625
Batch 43/64 loss: 4.71859073638916
Batch 44/64 loss: 1.7028813362121582
Batch 45/64 loss: 1.6109747886657715
Batch 46/64 loss: 1.63380765914917
Batch 47/64 loss: 1.9503250122070312
Batch 48/64 loss: 1.6386394500732422
Batch 49/64 loss: 1.5787644386291504
Batch 50/64 loss: 1.5767264366149902
Batch 51/64 loss: 1.5971126556396484
Batch 52/64 loss: 1.6229662895202637
Batch 53/64 loss: 1.5637106895446777
Batch 54/64 loss: 1.7580928802490234
Batch 55/64 loss: 1.663088321685791
Batch 56/64 loss: 1.9596529006958008
Batch 57/64 loss: 1.6131677627563477
Batch 58/64 loss: 1.8275485038757324
Batch 59/64 loss: 1.7216830253601074
Batch 60/64 loss: 1.767113208770752
Batch 61/64 loss: 1.540271282196045
Batch 62/64 loss: 2.527378559112549
Batch 63/64 loss: 1.5882587432861328
Batch 64/64 loss: -1.0771675109863281
Epoch 477  Train loss: 1.8310756309359681  Val loss: 1.3939050628557237
Epoch 478
-------------------------------
Batch 1/64 loss: 2.1670737266540527
Batch 2/64 loss: 3.987459659576416
Batch 3/64 loss: 1.668928623199463
Batch 4/64 loss: 2.4371390342712402
Batch 5/64 loss: 1.7199220657348633
Batch 6/64 loss: 1.4728970527648926
Batch 7/64 loss: 1.622056484222412
Batch 8/64 loss: 2.7583069801330566
Batch 9/64 loss: 1.540341854095459
Batch 10/64 loss: 1.7523903846740723
Batch 11/64 loss: 1.5758190155029297
Batch 12/64 loss: 1.9439654350280762
Batch 13/64 loss: 1.6450080871582031
Batch 14/64 loss: 1.7281885147094727
Batch 15/64 loss: 1.5196824073791504
Batch 16/64 loss: 1.6446309089660645
Batch 17/64 loss: 4.531597137451172
Batch 18/64 loss: 1.9297189712524414
Batch 19/64 loss: 1.5694031715393066
Batch 20/64 loss: 1.6047253608703613
Batch 21/64 loss: 3.776735305786133
Batch 22/64 loss: 1.569343090057373
Batch 23/64 loss: 1.6113743782043457
Batch 24/64 loss: 1.8314251899719238
Batch 25/64 loss: 1.6998090744018555
Batch 26/64 loss: 1.5854005813598633
Batch 27/64 loss: 1.6299867630004883
Batch 28/64 loss: 1.6613445281982422
Batch 29/64 loss: 1.5214662551879883
Batch 30/64 loss: 1.625349521636963
Batch 31/64 loss: 2.2221336364746094
Batch 32/64 loss: 1.8843584060668945
Batch 33/64 loss: 1.661031723022461
Batch 34/64 loss: 1.6122713088989258
Batch 35/64 loss: 1.645003318786621
Batch 36/64 loss: 1.9586009979248047
Batch 37/64 loss: 2.292470932006836
Batch 38/64 loss: 1.715609073638916
Batch 39/64 loss: 1.5559039115905762
Batch 40/64 loss: 1.6513605117797852
Batch 41/64 loss: 1.6153569221496582
Batch 42/64 loss: 1.6565723419189453
Batch 43/64 loss: 1.707399845123291
Batch 44/64 loss: 1.6574249267578125
Batch 45/64 loss: 1.6228084564208984
Batch 46/64 loss: 1.706007957458496
Batch 47/64 loss: 1.6271586418151855
Batch 48/64 loss: 1.6065568923950195
Batch 49/64 loss: 1.7479286193847656
Batch 50/64 loss: 1.733475685119629
Batch 51/64 loss: 1.6415519714355469
Batch 52/64 loss: 1.6894211769104004
Batch 53/64 loss: 1.7588677406311035
Batch 54/64 loss: 1.518355369567871
Batch 55/64 loss: 1.5968074798583984
Batch 56/64 loss: 1.5964422225952148
Batch 57/64 loss: 3.951183795928955
Batch 58/64 loss: 1.8293256759643555
Batch 59/64 loss: 1.5638065338134766
Batch 60/64 loss: 1.547074317932129
Batch 61/64 loss: 1.775702953338623
Batch 62/64 loss: 1.5641112327575684
Batch 63/64 loss: 1.563270092010498
Batch 64/64 loss: -1.7966384887695312
Epoch 478  Train loss: 1.8268135743982652  Val loss: 1.3711200727220254
Epoch 479
-------------------------------
Batch 1/64 loss: 1.6212806701660156
Batch 2/64 loss: 1.5414342880249023
Batch 3/64 loss: 4.519754886627197
Batch 4/64 loss: 2.4785757064819336
Batch 5/64 loss: 1.6056742668151855
Batch 6/64 loss: 1.6493053436279297
Batch 7/64 loss: 1.5862445831298828
Batch 8/64 loss: 1.7971420288085938
Batch 9/64 loss: 1.65277099609375
Batch 10/64 loss: 1.662369728088379
Batch 11/64 loss: 1.927760124206543
Batch 12/64 loss: 1.6488194465637207
Batch 13/64 loss: 1.6265463829040527
Batch 14/64 loss: 1.6429734230041504
Batch 15/64 loss: 1.743429183959961
Batch 16/64 loss: 1.6329584121704102
Batch 17/64 loss: 1.6264958381652832
Batch 18/64 loss: 1.682157039642334
Batch 19/64 loss: 3.8225693702697754
Batch 20/64 loss: 1.6690964698791504
Batch 21/64 loss: 1.7313365936279297
Batch 22/64 loss: 1.7850556373596191
Batch 23/64 loss: 4.025750160217285
Batch 24/64 loss: 1.935133457183838
Batch 25/64 loss: 2.0889124870300293
Batch 26/64 loss: 1.6328082084655762
Batch 27/64 loss: 1.6377897262573242
Batch 28/64 loss: 1.7006573677062988
Batch 29/64 loss: 1.7237272262573242
Batch 30/64 loss: 1.6654167175292969
Batch 31/64 loss: 1.6437568664550781
Batch 32/64 loss: 2.1025967597961426
Batch 33/64 loss: 1.6803317070007324
Batch 34/64 loss: 1.7072572708129883
Batch 35/64 loss: 1.644805908203125
Batch 36/64 loss: 2.208099365234375
Batch 37/64 loss: 1.7179880142211914
Batch 38/64 loss: 1.7501506805419922
Batch 39/64 loss: 1.7923269271850586
Batch 40/64 loss: 1.7969250679016113
Batch 41/64 loss: 1.5493683815002441
Batch 42/64 loss: 1.7356891632080078
Batch 43/64 loss: 1.7505340576171875
Batch 44/64 loss: 1.6269688606262207
Batch 45/64 loss: 1.6710872650146484
Batch 46/64 loss: 1.5564112663269043
Batch 47/64 loss: 2.5530877113342285
Batch 48/64 loss: 1.5307064056396484
Batch 49/64 loss: 1.74224853515625
Batch 50/64 loss: 1.8274173736572266
Batch 51/64 loss: 1.733565330505371
Batch 52/64 loss: 1.6689138412475586
Batch 53/64 loss: 1.740816593170166
Batch 54/64 loss: 1.860581874847412
Batch 55/64 loss: 1.6766223907470703
Batch 56/64 loss: 1.5788555145263672
Batch 57/64 loss: 1.7974867820739746
Batch 58/64 loss: 1.6799116134643555
Batch 59/64 loss: 1.5858263969421387
Batch 60/64 loss: 1.673924446105957
Batch 61/64 loss: 1.7497310638427734
Batch 62/64 loss: 1.6472563743591309
Batch 63/64 loss: 1.5150113105773926
Batch 64/64 loss: 0.4983091354370117
Epoch 479  Train loss: 1.8342578626146504  Val loss: 1.3884896347203206
Epoch 480
-------------------------------
Batch 1/64 loss: 1.6332321166992188
Batch 2/64 loss: 1.7301020622253418
Batch 3/64 loss: 1.5490050315856934
Batch 4/64 loss: 1.8004980087280273
Batch 5/64 loss: 2.065615177154541
Batch 6/64 loss: 1.6242046356201172
Batch 7/64 loss: 1.5799074172973633
Batch 8/64 loss: 1.6116399765014648
Batch 9/64 loss: 1.5865931510925293
Batch 10/64 loss: 3.772965908050537
Batch 11/64 loss: 1.5489425659179688
Batch 12/64 loss: 1.519796371459961
Batch 13/64 loss: 2.506911277770996
Batch 14/64 loss: 1.5744361877441406
Batch 15/64 loss: 1.8146586418151855
Batch 16/64 loss: 1.5859813690185547
Batch 17/64 loss: 1.733060359954834
Batch 18/64 loss: 1.7197332382202148
Batch 19/64 loss: 1.6827473640441895
Batch 20/64 loss: 2.397636890411377
Batch 21/64 loss: 1.8891587257385254
Batch 22/64 loss: 2.3659019470214844
Batch 23/64 loss: 1.5928292274475098
Batch 24/64 loss: 1.509305477142334
Batch 25/64 loss: 1.5646653175354004
Batch 26/64 loss: 1.788482666015625
Batch 27/64 loss: 1.640352725982666
Batch 28/64 loss: 1.6243629455566406
Batch 29/64 loss: 1.6845860481262207
Batch 30/64 loss: 1.755256175994873
Batch 31/64 loss: 1.7138371467590332
Batch 32/64 loss: 1.8356008529663086
Batch 33/64 loss: 1.9002699851989746
Batch 34/64 loss: 4.050022125244141
Batch 35/64 loss: 1.6075162887573242
Batch 36/64 loss: 1.700789451599121
Batch 37/64 loss: 1.7710328102111816
Batch 38/64 loss: 2.916092872619629
Batch 39/64 loss: 2.002002239227295
Batch 40/64 loss: 1.6549639701843262
Batch 41/64 loss: 1.650667667388916
Batch 42/64 loss: 1.5962028503417969
Batch 43/64 loss: 2.0229382514953613
Batch 44/64 loss: 1.966942310333252
Batch 45/64 loss: 1.635441780090332
Batch 46/64 loss: 1.582115650177002
Batch 47/64 loss: 1.6635394096374512
Batch 48/64 loss: 1.62176513671875
Batch 49/64 loss: 2.2262072563171387
Batch 50/64 loss: 1.732431411743164
Batch 51/64 loss: 1.7236971855163574
Batch 52/64 loss: 2.9640212059020996
Batch 53/64 loss: 1.7145991325378418
Batch 54/64 loss: 1.776970386505127
Batch 55/64 loss: 1.6544432640075684
Batch 56/64 loss: 1.6765060424804688
Batch 57/64 loss: 1.793774127960205
Batch 58/64 loss: 1.705634593963623
Batch 59/64 loss: 1.6137995719909668
Batch 60/64 loss: 4.550439357757568
Batch 61/64 loss: 1.8114304542541504
Batch 62/64 loss: 1.6694765090942383
Batch 63/64 loss: 1.519178867340088
Batch 64/64 loss: -1.6727409362792969
Epoch 480  Train loss: 1.8544684466193704  Val loss: 1.4475419611455649
Epoch 481
-------------------------------
Batch 1/64 loss: 1.6479315757751465
Batch 2/64 loss: 1.5924983024597168
Batch 3/64 loss: 1.8195509910583496
Batch 4/64 loss: 1.5685772895812988
Batch 5/64 loss: 1.7649664878845215
Batch 6/64 loss: 1.6049532890319824
Batch 7/64 loss: 1.8464465141296387
Batch 8/64 loss: 1.6600966453552246
Batch 9/64 loss: 1.8572535514831543
Batch 10/64 loss: 1.594419002532959
Batch 11/64 loss: 1.7951879501342773
Batch 12/64 loss: 4.6097235679626465
Batch 13/64 loss: 1.5961270332336426
Batch 14/64 loss: 1.6628332138061523
Batch 15/64 loss: 2.8723721504211426
Batch 16/64 loss: 1.691272258758545
Batch 17/64 loss: 2.3580431938171387
Batch 18/64 loss: 1.6864523887634277
Batch 19/64 loss: 1.6550426483154297
Batch 20/64 loss: 1.7369604110717773
Batch 21/64 loss: 1.6717705726623535
Batch 22/64 loss: 1.5226478576660156
Batch 23/64 loss: 1.8261666297912598
Batch 24/64 loss: 2.417595386505127
Batch 25/64 loss: 1.659900188446045
Batch 26/64 loss: 1.5572409629821777
Batch 27/64 loss: 1.8513531684875488
Batch 28/64 loss: 1.6464133262634277
Batch 29/64 loss: 1.672868251800537
Batch 30/64 loss: 1.667370319366455
Batch 31/64 loss: 2.634951591491699
Batch 32/64 loss: 1.742269515991211
Batch 33/64 loss: 2.097787380218506
Batch 34/64 loss: 1.5657711029052734
Batch 35/64 loss: 1.642749309539795
Batch 36/64 loss: 1.6751933097839355
Batch 37/64 loss: 2.795508861541748
Batch 38/64 loss: 2.094240665435791
Batch 39/64 loss: 1.640303134918213
Batch 40/64 loss: 1.6883525848388672
Batch 41/64 loss: 1.6023874282836914
Batch 42/64 loss: 3.910137176513672
Batch 43/64 loss: 1.6373634338378906
Batch 44/64 loss: 3.909158706665039
Batch 45/64 loss: 1.820411205291748
Batch 46/64 loss: 1.5843009948730469
Batch 47/64 loss: 1.559779167175293
Batch 48/64 loss: 1.6507902145385742
Batch 49/64 loss: 2.399352550506592
Batch 50/64 loss: 1.8308138847351074
Batch 51/64 loss: 1.6148066520690918
Batch 52/64 loss: 1.847132682800293
Batch 53/64 loss: 1.6152071952819824
Batch 54/64 loss: 1.781529426574707
Batch 55/64 loss: 1.729123592376709
Batch 56/64 loss: 1.6313114166259766
Batch 57/64 loss: 1.7900476455688477
Batch 58/64 loss: 1.6570172309875488
Batch 59/64 loss: 1.5811142921447754
Batch 60/64 loss: 1.7201447486877441
Batch 61/64 loss: 1.705777645111084
Batch 62/64 loss: 1.666576862335205
Batch 63/64 loss: 1.6161670684814453
Batch 64/64 loss: -1.9511127471923828
Epoch 481  Train loss: 1.8523651646632775  Val loss: 1.4102708482250725
Epoch 482
-------------------------------
Batch 1/64 loss: 3.7640419006347656
Batch 2/64 loss: 1.7277183532714844
Batch 3/64 loss: 1.7636752128601074
Batch 4/64 loss: 1.485461711883545
Batch 5/64 loss: 1.8850622177124023
Batch 6/64 loss: 1.517829418182373
Batch 7/64 loss: 4.506430625915527
Batch 8/64 loss: 1.6050868034362793
Batch 9/64 loss: 1.6509408950805664
Batch 10/64 loss: 1.6076736450195312
Batch 11/64 loss: 1.6246204376220703
Batch 12/64 loss: 1.745002269744873
Batch 13/64 loss: 1.6291108131408691
Batch 14/64 loss: 1.7194476127624512
Batch 15/64 loss: 2.724821090698242
Batch 16/64 loss: 1.6766095161437988
Batch 17/64 loss: 2.0186452865600586
Batch 18/64 loss: 2.120184898376465
Batch 19/64 loss: 1.7012019157409668
Batch 20/64 loss: 1.5431594848632812
Batch 21/64 loss: 1.6221070289611816
Batch 22/64 loss: 1.513875961303711
Batch 23/64 loss: 1.6530909538269043
Batch 24/64 loss: 1.5513153076171875
Batch 25/64 loss: 1.573014259338379
Batch 26/64 loss: 1.5600829124450684
Batch 27/64 loss: 1.6723389625549316
Batch 28/64 loss: 1.8795204162597656
Batch 29/64 loss: 3.9397778511047363
Batch 30/64 loss: 1.5937128067016602
Batch 31/64 loss: 1.7954959869384766
Batch 32/64 loss: 1.7420530319213867
Batch 33/64 loss: 1.6556305885314941
Batch 34/64 loss: 1.6313824653625488
Batch 35/64 loss: 1.6330795288085938
Batch 36/64 loss: 1.6909966468811035
Batch 37/64 loss: 2.4169211387634277
Batch 38/64 loss: 1.5807843208312988
Batch 39/64 loss: 1.7441143989562988
Batch 40/64 loss: 1.735487461090088
Batch 41/64 loss: 1.5563430786132812
Batch 42/64 loss: 1.6863179206848145
Batch 43/64 loss: 1.761125087738037
Batch 44/64 loss: 1.7293462753295898
Batch 45/64 loss: 1.694139003753662
Batch 46/64 loss: 1.69970703125
Batch 47/64 loss: 1.4844059944152832
Batch 48/64 loss: 1.6903982162475586
Batch 49/64 loss: 1.6507577896118164
Batch 50/64 loss: 1.6224756240844727
Batch 51/64 loss: 1.575148105621338
Batch 52/64 loss: 1.779869556427002
Batch 53/64 loss: 3.0501956939697266
Batch 54/64 loss: 2.5961694717407227
Batch 55/64 loss: 1.571843147277832
Batch 56/64 loss: 1.6611003875732422
Batch 57/64 loss: 1.6654834747314453
Batch 58/64 loss: 1.5461406707763672
Batch 59/64 loss: 2.0959506034851074
Batch 60/64 loss: 1.645430088043213
Batch 61/64 loss: 1.9701037406921387
Batch 62/64 loss: 1.5851178169250488
Batch 63/64 loss: 1.8016233444213867
Batch 64/64 loss: -1.8202123641967773
Epoch 482  Train loss: 1.8189104154998181  Val loss: 1.4171959788528914
Epoch 483
-------------------------------
Batch 1/64 loss: 1.601356029510498
Batch 2/64 loss: 1.5502300262451172
Batch 3/64 loss: 1.7394828796386719
Batch 4/64 loss: 1.536435604095459
Batch 5/64 loss: 1.6658716201782227
Batch 6/64 loss: 1.6062722206115723
Batch 7/64 loss: 1.7771449089050293
Batch 8/64 loss: 1.8178658485412598
Batch 9/64 loss: 1.9131965637207031
Batch 10/64 loss: 1.718231201171875
Batch 11/64 loss: 1.6308650970458984
Batch 12/64 loss: 1.5789995193481445
Batch 13/64 loss: 1.8137445449829102
Batch 14/64 loss: 1.7539916038513184
Batch 15/64 loss: 3.8215537071228027
Batch 16/64 loss: 1.5998024940490723
Batch 17/64 loss: 1.5073399543762207
Batch 18/64 loss: 1.6767539978027344
Batch 19/64 loss: 1.8862438201904297
Batch 20/64 loss: 1.5602283477783203
Batch 21/64 loss: 1.7224726676940918
Batch 22/64 loss: 1.606712818145752
Batch 23/64 loss: 2.105099678039551
Batch 24/64 loss: 1.650979995727539
Batch 25/64 loss: 2.2770166397094727
Batch 26/64 loss: 1.5951390266418457
Batch 27/64 loss: 1.7024331092834473
Batch 28/64 loss: 1.8452391624450684
Batch 29/64 loss: 1.6537232398986816
Batch 30/64 loss: 1.6029987335205078
Batch 31/64 loss: 1.7427306175231934
Batch 32/64 loss: 1.6610674858093262
Batch 33/64 loss: 1.7132821083068848
Batch 34/64 loss: 1.5335330963134766
Batch 35/64 loss: 1.6650300025939941
Batch 36/64 loss: 1.632617473602295
Batch 37/64 loss: 1.5011720657348633
Batch 38/64 loss: 1.948317050933838
Batch 39/64 loss: 2.7479729652404785
Batch 40/64 loss: 1.5681204795837402
Batch 41/64 loss: 1.6708989143371582
Batch 42/64 loss: 1.5914416313171387
Batch 43/64 loss: 1.7124347686767578
Batch 44/64 loss: 2.0011825561523438
Batch 45/64 loss: 1.4728965759277344
Batch 46/64 loss: 1.5981216430664062
Batch 47/64 loss: 1.6488194465637207
Batch 48/64 loss: 1.6494488716125488
Batch 49/64 loss: 2.044795513153076
Batch 50/64 loss: 1.6043791770935059
Batch 51/64 loss: 1.5430092811584473
Batch 52/64 loss: 1.6029763221740723
Batch 53/64 loss: 3.977205753326416
Batch 54/64 loss: 5.371799468994141
Batch 55/64 loss: 1.815455436706543
Batch 56/64 loss: 1.6212577819824219
Batch 57/64 loss: 1.5732460021972656
Batch 58/64 loss: 1.8138432502746582
Batch 59/64 loss: 1.8480525016784668
Batch 60/64 loss: 1.8760032653808594
Batch 61/64 loss: 2.999422073364258
Batch 62/64 loss: 1.557478427886963
Batch 63/64 loss: 1.5976533889770508
Batch 64/64 loss: -1.5974674224853516
Epoch 483  Train loss: 1.8231370963302314  Val loss: 1.362375698548412
Epoch 484
-------------------------------
Batch 1/64 loss: 1.6575398445129395
Batch 2/64 loss: 4.631229877471924
Batch 3/64 loss: 3.782444953918457
Batch 4/64 loss: 2.6334662437438965
Batch 5/64 loss: 1.5684194564819336
Batch 6/64 loss: 1.5200715065002441
Batch 7/64 loss: 1.62453031539917
Batch 8/64 loss: 1.7284183502197266
Batch 9/64 loss: 1.6511459350585938
Batch 10/64 loss: 1.7020206451416016
Batch 11/64 loss: 1.5370941162109375
Batch 12/64 loss: 2.0599451065063477
Batch 13/64 loss: 1.8016080856323242
Batch 14/64 loss: 1.814765453338623
Batch 15/64 loss: 2.434926986694336
Batch 16/64 loss: 1.5353574752807617
Batch 17/64 loss: 1.629692554473877
Batch 18/64 loss: 1.662442684173584
Batch 19/64 loss: 1.68442964553833
Batch 20/64 loss: 2.1212244033813477
Batch 21/64 loss: 1.6468911170959473
Batch 22/64 loss: 1.5698270797729492
Batch 23/64 loss: 2.990577220916748
Batch 24/64 loss: 1.6740822792053223
Batch 25/64 loss: 1.5959973335266113
Batch 26/64 loss: 1.6109271049499512
Batch 27/64 loss: 1.6728458404541016
Batch 28/64 loss: 2.4033150672912598
Batch 29/64 loss: 1.6128735542297363
Batch 30/64 loss: 1.741239070892334
Batch 31/64 loss: 1.762974739074707
Batch 32/64 loss: 1.691545009613037
Batch 33/64 loss: 2.5553956031799316
Batch 34/64 loss: 1.6527724266052246
Batch 35/64 loss: 1.5653696060180664
Batch 36/64 loss: 1.5841593742370605
Batch 37/64 loss: 1.6925134658813477
Batch 38/64 loss: 1.598400592803955
Batch 39/64 loss: 1.5973310470581055
Batch 40/64 loss: 1.771806240081787
Batch 41/64 loss: 1.636308193206787
Batch 42/64 loss: 1.6602215766906738
Batch 43/64 loss: 1.6742334365844727
Batch 44/64 loss: 1.551098346710205
Batch 45/64 loss: 1.5882792472839355
Batch 46/64 loss: 1.549731731414795
Batch 47/64 loss: 2.2060837745666504
Batch 48/64 loss: 1.992478370666504
Batch 49/64 loss: 1.852332592010498
Batch 50/64 loss: 1.934483528137207
Batch 51/64 loss: 1.6177902221679688
Batch 52/64 loss: 2.0585427284240723
Batch 53/64 loss: 1.727564811706543
Batch 54/64 loss: 1.794663906097412
Batch 55/64 loss: 1.7279553413391113
Batch 56/64 loss: 1.8521943092346191
Batch 57/64 loss: 2.054348945617676
Batch 58/64 loss: 1.8992815017700195
Batch 59/64 loss: 1.9265408515930176
Batch 60/64 loss: 4.443121433258057
Batch 61/64 loss: 1.9903364181518555
Batch 62/64 loss: 1.7848124504089355
Batch 63/64 loss: 2.066012382507324
Batch 64/64 loss: -1.647883415222168
Epoch 484  Train loss: 1.8842999364815507  Val loss: 1.7961862963909137
Epoch 485
-------------------------------
Batch 1/64 loss: 3.891012668609619
Batch 2/64 loss: 1.8622307777404785
Batch 3/64 loss: 2.0590643882751465
Batch 4/64 loss: 1.6919913291931152
Batch 5/64 loss: 2.0130882263183594
Batch 6/64 loss: 1.9801974296569824
Batch 7/64 loss: 1.759537696838379
Batch 8/64 loss: 1.8971457481384277
Batch 9/64 loss: 1.7880916595458984
Batch 10/64 loss: 2.1194019317626953
Batch 11/64 loss: 2.079461097717285
Batch 12/64 loss: 1.723677635192871
Batch 13/64 loss: 1.6126065254211426
Batch 14/64 loss: 1.5903749465942383
Batch 15/64 loss: 2.0733227729797363
Batch 16/64 loss: 1.6990489959716797
Batch 17/64 loss: 1.6553783416748047
Batch 18/64 loss: 1.7258539199829102
Batch 19/64 loss: 2.3336682319641113
Batch 20/64 loss: 1.6364655494689941
Batch 21/64 loss: 1.847184658050537
Batch 22/64 loss: 1.594533920288086
Batch 23/64 loss: 1.644460678100586
Batch 24/64 loss: 1.615056037902832
Batch 25/64 loss: 1.689958095550537
Batch 26/64 loss: 1.7580041885375977
Batch 27/64 loss: 1.6522626876831055
Batch 28/64 loss: 4.174521446228027
Batch 29/64 loss: 1.8329439163208008
Batch 30/64 loss: 2.6100540161132812
Batch 31/64 loss: 1.9495916366577148
Batch 32/64 loss: 1.8076071739196777
Batch 33/64 loss: 1.6982779502868652
Batch 34/64 loss: 1.751518726348877
Batch 35/64 loss: 2.782287120819092
Batch 36/64 loss: 1.608133316040039
Batch 37/64 loss: 2.769458770751953
Batch 38/64 loss: 1.6964035034179688
Batch 39/64 loss: 1.6404151916503906
Batch 40/64 loss: 1.7357673645019531
Batch 41/64 loss: 1.605687141418457
Batch 42/64 loss: 1.626208782196045
Batch 43/64 loss: 1.6505231857299805
Batch 44/64 loss: 1.6842808723449707
Batch 45/64 loss: 1.5749025344848633
Batch 46/64 loss: 1.8642621040344238
Batch 47/64 loss: 4.6810407638549805
Batch 48/64 loss: 1.5879859924316406
Batch 49/64 loss: 1.649522304534912
Batch 50/64 loss: 1.6235032081604004
Batch 51/64 loss: 1.6969618797302246
Batch 52/64 loss: 1.6920862197875977
Batch 53/64 loss: 1.675999641418457
Batch 54/64 loss: 1.6009669303894043
Batch 55/64 loss: 1.6295523643493652
Batch 56/64 loss: 2.1727232933044434
Batch 57/64 loss: 1.5973296165466309
Batch 58/64 loss: 1.8743791580200195
Batch 59/64 loss: 1.572655200958252
Batch 60/64 loss: 1.7059087753295898
Batch 61/64 loss: 1.734034538269043
Batch 62/64 loss: 3.9693241119384766
Batch 63/64 loss: 1.809131145477295
Batch 64/64 loss: -1.9016036987304688
Epoch 485  Train loss: 1.9122012119667202  Val loss: 1.4103038958257825
Epoch 486
-------------------------------
Batch 1/64 loss: 1.9430980682373047
Batch 2/64 loss: 1.7615303993225098
Batch 3/64 loss: 2.0552353858947754
Batch 4/64 loss: 1.6947269439697266
Batch 5/64 loss: 4.230080604553223
Batch 6/64 loss: 2.475705623626709
Batch 7/64 loss: 1.5385398864746094
Batch 8/64 loss: 1.5291557312011719
Batch 9/64 loss: 1.5778374671936035
Batch 10/64 loss: 1.6551265716552734
Batch 11/64 loss: 1.8506569862365723
Batch 12/64 loss: 1.7146072387695312
Batch 13/64 loss: 2.7137389183044434
Batch 14/64 loss: 2.040134906768799
Batch 15/64 loss: 1.6190237998962402
Batch 16/64 loss: 1.5612621307373047
Batch 17/64 loss: 1.668034553527832
Batch 18/64 loss: 1.710106372833252
Batch 19/64 loss: 1.7202773094177246
Batch 20/64 loss: 1.6383862495422363
Batch 21/64 loss: 1.5280089378356934
Batch 22/64 loss: 1.7106800079345703
Batch 23/64 loss: 2.7922263145446777
Batch 24/64 loss: 1.9669761657714844
Batch 25/64 loss: 1.7598652839660645
Batch 26/64 loss: 1.9444785118103027
Batch 27/64 loss: 1.6705169677734375
Batch 28/64 loss: 1.5539417266845703
Batch 29/64 loss: 1.5911011695861816
Batch 30/64 loss: 1.6095376014709473
Batch 31/64 loss: 2.0095434188842773
Batch 32/64 loss: 1.7193865776062012
Batch 33/64 loss: 2.5251712799072266
Batch 34/64 loss: 1.817150592803955
Batch 35/64 loss: 1.5973458290100098
Batch 36/64 loss: 1.6653871536254883
Batch 37/64 loss: 4.776639461517334
Batch 38/64 loss: 4.047431468963623
Batch 39/64 loss: 1.7268257141113281
Batch 40/64 loss: 1.8436684608459473
Batch 41/64 loss: 1.6287651062011719
Batch 42/64 loss: 1.6624584197998047
Batch 43/64 loss: 2.683408737182617
Batch 44/64 loss: 1.5749993324279785
Batch 45/64 loss: 1.6453757286071777
Batch 46/64 loss: 1.7361254692077637
Batch 47/64 loss: 1.780418872833252
Batch 48/64 loss: 1.6761059761047363
Batch 49/64 loss: 1.561251163482666
Batch 50/64 loss: 1.6327128410339355
Batch 51/64 loss: 1.7851643562316895
Batch 52/64 loss: 1.732039451599121
Batch 53/64 loss: 1.6118474006652832
Batch 54/64 loss: 1.5816326141357422
Batch 55/64 loss: 1.5826220512390137
Batch 56/64 loss: 1.7085824012756348
Batch 57/64 loss: 1.596259593963623
Batch 58/64 loss: 1.719205379486084
Batch 59/64 loss: 1.6429572105407715
Batch 60/64 loss: 1.6612873077392578
Batch 61/64 loss: 1.6744365692138672
Batch 62/64 loss: 1.7016210556030273
Batch 63/64 loss: 1.548201084136963
Batch 64/64 loss: -1.8698978424072266
Epoch 486  Train loss: 1.855344353470148  Val loss: 1.4382942435667687
Epoch 487
-------------------------------
Batch 1/64 loss: 1.5852065086364746
Batch 2/64 loss: 1.715601921081543
Batch 3/64 loss: 1.9553942680358887
Batch 4/64 loss: 1.6700215339660645
Batch 5/64 loss: 1.8800053596496582
Batch 6/64 loss: 1.9764456748962402
Batch 7/64 loss: 1.6572632789611816
Batch 8/64 loss: 2.366014003753662
Batch 9/64 loss: 2.879307270050049
Batch 10/64 loss: 1.7504844665527344
Batch 11/64 loss: 1.8576998710632324
Batch 12/64 loss: 1.7529106140136719
Batch 13/64 loss: 1.6979031562805176
Batch 14/64 loss: 1.6374988555908203
Batch 15/64 loss: 1.7671542167663574
Batch 16/64 loss: 1.685814380645752
Batch 17/64 loss: 1.7947158813476562
Batch 18/64 loss: 2.6562438011169434
Batch 19/64 loss: 1.7370071411132812
Batch 20/64 loss: 1.8641433715820312
Batch 21/64 loss: 1.6792573928833008
Batch 22/64 loss: 1.7078571319580078
Batch 23/64 loss: 2.4276247024536133
Batch 24/64 loss: 2.253110885620117
Batch 25/64 loss: 2.6446661949157715
Batch 26/64 loss: 1.9202871322631836
Batch 27/64 loss: 2.2536396980285645
Batch 28/64 loss: 2.9461312294006348
Batch 29/64 loss: 1.981473445892334
Batch 30/64 loss: 2.6803321838378906
Batch 31/64 loss: 5.357249736785889
Batch 32/64 loss: 2.3225975036621094
Batch 33/64 loss: 2.283982276916504
Batch 34/64 loss: 1.801952838897705
Batch 35/64 loss: 4.339487552642822
Batch 36/64 loss: 1.9478540420532227
Batch 37/64 loss: 2.354759693145752
Batch 38/64 loss: 1.8332891464233398
Batch 39/64 loss: 1.7043805122375488
Batch 40/64 loss: 2.211432456970215
Batch 41/64 loss: 1.8654427528381348
Batch 42/64 loss: 2.0751757621765137
Batch 43/64 loss: 2.1357431411743164
Batch 44/64 loss: 1.905515193939209
Batch 45/64 loss: 1.9058170318603516
Batch 46/64 loss: 2.9248952865600586
Batch 47/64 loss: 2.107975959777832
Batch 48/64 loss: 1.9296832084655762
Batch 49/64 loss: 1.9990315437316895
Batch 50/64 loss: 3.0791821479797363
Batch 51/64 loss: 1.844376564025879
Batch 52/64 loss: 1.6914358139038086
Batch 53/64 loss: 2.2619094848632812
Batch 54/64 loss: 1.9635562896728516
Batch 55/64 loss: 1.884361743927002
Batch 56/64 loss: 1.8701739311218262
Batch 57/64 loss: 1.88810396194458
Batch 58/64 loss: 1.720386028289795
Batch 59/64 loss: 3.986997127532959
Batch 60/64 loss: 1.8295965194702148
Batch 61/64 loss: 2.0149712562561035
Batch 62/64 loss: 1.8068900108337402
Batch 63/64 loss: 1.7856378555297852
Batch 64/64 loss: -1.7275276184082031
Epoch 487  Train loss: 2.097559438967237  Val loss: 1.7118581136067708
Epoch 488
-------------------------------
Batch 1/64 loss: 1.9387011528015137
Batch 2/64 loss: 1.948781967163086
Batch 3/64 loss: 1.7401652336120605
Batch 4/64 loss: 1.8065738677978516
Batch 5/64 loss: 1.9982056617736816
Batch 6/64 loss: 1.6688294410705566
Batch 7/64 loss: 1.8953094482421875
Batch 8/64 loss: 2.7411036491394043
Batch 9/64 loss: 1.794621467590332
Batch 10/64 loss: 1.956953525543213
Batch 11/64 loss: 1.8409137725830078
Batch 12/64 loss: 1.7429847717285156
Batch 13/64 loss: 4.455867767333984
Batch 14/64 loss: 2.1919798851013184
Batch 15/64 loss: 1.851944923400879
Batch 16/64 loss: 1.8035578727722168
Batch 17/64 loss: 2.7589597702026367
Batch 18/64 loss: 1.8865103721618652
Batch 19/64 loss: 1.7030243873596191
Batch 20/64 loss: 1.765824794769287
Batch 21/64 loss: 3.844463348388672
Batch 22/64 loss: 1.7777271270751953
Batch 23/64 loss: 1.8889307975769043
Batch 24/64 loss: 2.4229793548583984
Batch 25/64 loss: 2.0834531784057617
Batch 26/64 loss: 2.450636386871338
Batch 27/64 loss: 1.7461299896240234
Batch 28/64 loss: 1.9985404014587402
Batch 29/64 loss: 1.836169719696045
Batch 30/64 loss: 1.6792521476745605
Batch 31/64 loss: 1.649186134338379
Batch 32/64 loss: 1.7054052352905273
Batch 33/64 loss: 1.79608154296875
Batch 34/64 loss: 1.8443183898925781
Batch 35/64 loss: 2.167421340942383
Batch 36/64 loss: 1.7220301628112793
Batch 37/64 loss: 1.7105884552001953
Batch 38/64 loss: 1.8577322959899902
Batch 39/64 loss: 1.6921329498291016
Batch 40/64 loss: 1.6783838272094727
Batch 41/64 loss: 1.7220721244812012
Batch 42/64 loss: 2.683147430419922
Batch 43/64 loss: 1.9206647872924805
Batch 44/64 loss: 1.639026165008545
Batch 45/64 loss: 1.8215389251708984
Batch 46/64 loss: 1.6902709007263184
Batch 47/64 loss: 1.9155020713806152
Batch 48/64 loss: 2.2007617950439453
Batch 49/64 loss: 4.773730754852295
Batch 50/64 loss: 1.7926087379455566
Batch 51/64 loss: 1.5995173454284668
Batch 52/64 loss: 1.5949616432189941
Batch 53/64 loss: 2.5122170448303223
Batch 54/64 loss: 1.7884645462036133
Batch 55/64 loss: 1.8015971183776855
Batch 56/64 loss: 2.3190083503723145
Batch 57/64 loss: 1.689356803894043
Batch 58/64 loss: 1.6302847862243652
Batch 59/64 loss: 1.974888801574707
Batch 60/64 loss: 1.8119745254516602
Batch 61/64 loss: 1.644937515258789
Batch 62/64 loss: 1.7618365287780762
Batch 63/64 loss: 2.012887954711914
Batch 64/64 loss: -1.7300605773925781
Epoch 488  Train loss: 1.9771935332055186  Val loss: 1.5005669741286445
Epoch 489
-------------------------------
Batch 1/64 loss: 1.7433466911315918
Batch 2/64 loss: 1.7234292030334473
Batch 3/64 loss: 1.6361808776855469
Batch 4/64 loss: 1.7539663314819336
Batch 5/64 loss: 1.5666027069091797
Batch 6/64 loss: 2.5007691383361816
Batch 7/64 loss: 4.715383052825928
Batch 8/64 loss: 1.701761245727539
Batch 9/64 loss: 1.8737883567810059
Batch 10/64 loss: 1.9027843475341797
Batch 11/64 loss: 1.752324104309082
Batch 12/64 loss: 2.0875186920166016
Batch 13/64 loss: 1.9481902122497559
Batch 14/64 loss: 1.6870713233947754
Batch 15/64 loss: 1.6822271347045898
Batch 16/64 loss: 1.7294225692749023
Batch 17/64 loss: 1.6558194160461426
Batch 18/64 loss: 1.7158722877502441
Batch 19/64 loss: 1.6913065910339355
Batch 20/64 loss: 2.048293113708496
Batch 21/64 loss: 4.289938449859619
Batch 22/64 loss: 1.7406277656555176
Batch 23/64 loss: 2.3476734161376953
Batch 24/64 loss: 1.5664854049682617
Batch 25/64 loss: 1.756330966949463
Batch 26/64 loss: 1.9223623275756836
Batch 27/64 loss: 1.613081455230713
Batch 28/64 loss: 1.9463319778442383
Batch 29/64 loss: 1.8125338554382324
Batch 30/64 loss: 1.7250046730041504
Batch 31/64 loss: 1.6905431747436523
Batch 32/64 loss: 1.9934272766113281
Batch 33/64 loss: 1.7040753364562988
Batch 34/64 loss: 1.8871965408325195
Batch 35/64 loss: 1.6080141067504883
Batch 36/64 loss: 2.7714366912841797
Batch 37/64 loss: 1.8489594459533691
Batch 38/64 loss: 3.7989120483398438
Batch 39/64 loss: 1.7251548767089844
Batch 40/64 loss: 1.713698387145996
Batch 41/64 loss: 1.6968798637390137
Batch 42/64 loss: 1.801361083984375
Batch 43/64 loss: 1.9562678337097168
Batch 44/64 loss: 1.7767033576965332
Batch 45/64 loss: 1.6360268592834473
Batch 46/64 loss: 1.9256176948547363
Batch 47/64 loss: 1.679314136505127
Batch 48/64 loss: 1.6639676094055176
Batch 49/64 loss: 1.6371259689331055
Batch 50/64 loss: 2.7793149948120117
Batch 51/64 loss: 1.8182320594787598
Batch 52/64 loss: 2.3053579330444336
Batch 53/64 loss: 1.7994651794433594
Batch 54/64 loss: 1.7865099906921387
Batch 55/64 loss: 1.6277384757995605
Batch 56/64 loss: 1.9081969261169434
Batch 57/64 loss: 1.6204357147216797
Batch 58/64 loss: 1.8615474700927734
Batch 59/64 loss: 1.742347240447998
Batch 60/64 loss: 1.737776279449463
Batch 61/64 loss: 1.9901528358459473
Batch 62/64 loss: 2.470309257507324
Batch 63/64 loss: 1.9206280708312988
Batch 64/64 loss: -1.7095050811767578
Epoch 489  Train loss: 1.9205802917480468  Val loss: 1.4611158469288619
Epoch 490
-------------------------------
Batch 1/64 loss: 1.6652836799621582
Batch 2/64 loss: 1.626509189605713
Batch 3/64 loss: 2.7483930587768555
Batch 4/64 loss: 2.6225128173828125
Batch 5/64 loss: 2.2396140098571777
Batch 6/64 loss: 1.7423491477966309
Batch 7/64 loss: 1.770707130432129
Batch 8/64 loss: 2.6049413681030273
Batch 9/64 loss: 1.7774806022644043
Batch 10/64 loss: 1.696685791015625
Batch 11/64 loss: 1.5832819938659668
Batch 12/64 loss: 1.6831450462341309
Batch 13/64 loss: 1.7113618850708008
Batch 14/64 loss: 1.6432585716247559
Batch 15/64 loss: 1.6737985610961914
Batch 16/64 loss: 1.6742725372314453
Batch 17/64 loss: 1.9609174728393555
Batch 18/64 loss: 1.6162924766540527
Batch 19/64 loss: 1.5675163269042969
Batch 20/64 loss: 1.6152901649475098
Batch 21/64 loss: 2.210939884185791
Batch 22/64 loss: 1.8318791389465332
Batch 23/64 loss: 1.750779151916504
Batch 24/64 loss: 1.834611415863037
Batch 25/64 loss: 1.5582284927368164
Batch 26/64 loss: 1.592698097229004
Batch 27/64 loss: 1.87615966796875
Batch 28/64 loss: 1.8649821281433105
Batch 29/64 loss: 1.7266731262207031
Batch 30/64 loss: 1.6255154609680176
Batch 31/64 loss: 3.6855597496032715
Batch 32/64 loss: 1.589181900024414
Batch 33/64 loss: 1.671877384185791
Batch 34/64 loss: 2.7257285118103027
Batch 35/64 loss: 1.7898664474487305
Batch 36/64 loss: 2.0706138610839844
Batch 37/64 loss: 1.6968178749084473
Batch 38/64 loss: 1.6188206672668457
Batch 39/64 loss: 1.6650481224060059
Batch 40/64 loss: 1.9953927993774414
Batch 41/64 loss: 4.660006523132324
Batch 42/64 loss: 1.788238525390625
Batch 43/64 loss: 1.924008846282959
Batch 44/64 loss: 1.8400907516479492
Batch 45/64 loss: 1.7976865768432617
Batch 46/64 loss: 1.6243653297424316
Batch 47/64 loss: 1.5710153579711914
Batch 48/64 loss: 1.7399015426635742
Batch 49/64 loss: 1.784069538116455
Batch 50/64 loss: 4.065555572509766
Batch 51/64 loss: 1.65462064743042
Batch 52/64 loss: 1.7306151390075684
Batch 53/64 loss: 1.6983027458190918
Batch 54/64 loss: 1.7863669395446777
Batch 55/64 loss: 1.645228385925293
Batch 56/64 loss: 1.7347102165222168
Batch 57/64 loss: 1.67496919631958
Batch 58/64 loss: 1.646684169769287
Batch 59/64 loss: 1.6107091903686523
Batch 60/64 loss: 1.6872992515563965
Batch 61/64 loss: 1.9240288734436035
Batch 62/64 loss: 1.612037181854248
Batch 63/64 loss: 1.5678191184997559
Batch 64/64 loss: -1.9436635971069336
Epoch 490  Train loss: 1.8653422374351352  Val loss: 1.4061735094208079
Epoch 491
-------------------------------
Batch 1/64 loss: 3.982116222381592
Batch 2/64 loss: 2.3568549156188965
Batch 3/64 loss: 1.581070899963379
Batch 4/64 loss: 1.6412911415100098
Batch 5/64 loss: 1.5890073776245117
Batch 6/64 loss: 1.620631217956543
Batch 7/64 loss: 1.6801996231079102
Batch 8/64 loss: 1.6329269409179688
Batch 9/64 loss: 1.671879768371582
Batch 10/64 loss: 1.6365046501159668
Batch 11/64 loss: 2.898223876953125
Batch 12/64 loss: 1.610461711883545
Batch 13/64 loss: 1.576284408569336
Batch 14/64 loss: 1.5763654708862305
Batch 15/64 loss: 1.6297650337219238
Batch 16/64 loss: 1.7110023498535156
Batch 17/64 loss: 1.5708646774291992
Batch 18/64 loss: 1.5808706283569336
Batch 19/64 loss: 1.731968879699707
Batch 20/64 loss: 1.6956143379211426
Batch 21/64 loss: 1.6269512176513672
Batch 22/64 loss: 1.6140928268432617
Batch 23/64 loss: 1.647132396697998
Batch 24/64 loss: 1.6785078048706055
Batch 25/64 loss: 1.6203136444091797
Batch 26/64 loss: 3.696378231048584
Batch 27/64 loss: 1.868110179901123
Batch 28/64 loss: 1.5892481803894043
Batch 29/64 loss: 1.6004223823547363
Batch 30/64 loss: 1.722738265991211
Batch 31/64 loss: 1.6289215087890625
Batch 32/64 loss: 2.443737030029297
Batch 33/64 loss: 1.483564853668213
Batch 34/64 loss: 1.5019030570983887
Batch 35/64 loss: 1.578066349029541
Batch 36/64 loss: 1.7859325408935547
Batch 37/64 loss: 1.7187047004699707
Batch 38/64 loss: 1.6495280265808105
Batch 39/64 loss: 1.720181941986084
Batch 40/64 loss: 1.5719990730285645
Batch 41/64 loss: 1.6099939346313477
Batch 42/64 loss: 1.6351752281188965
Batch 43/64 loss: 1.9247488975524902
Batch 44/64 loss: 1.6628742218017578
Batch 45/64 loss: 1.740842342376709
Batch 46/64 loss: 1.9126520156860352
Batch 47/64 loss: 1.8206815719604492
Batch 48/64 loss: 1.6220250129699707
Batch 49/64 loss: 1.7453632354736328
Batch 50/64 loss: 1.6376914978027344
Batch 51/64 loss: 3.165553569793701
Batch 52/64 loss: 1.6880698204040527
Batch 53/64 loss: 1.7640175819396973
Batch 54/64 loss: 4.644298553466797
Batch 55/64 loss: 2.6175012588500977
Batch 56/64 loss: 1.8664569854736328
Batch 57/64 loss: 1.8787531852722168
Batch 58/64 loss: 1.6096105575561523
Batch 59/64 loss: 1.69645357131958
Batch 60/64 loss: 1.5922541618347168
Batch 61/64 loss: 2.383054733276367
Batch 62/64 loss: 1.6576108932495117
Batch 63/64 loss: 1.6975107192993164
Batch 64/64 loss: -1.8679332733154297
Epoch 491  Train loss: 1.8336091284658396  Val loss: 1.419627763151713
Epoch 492
-------------------------------
Batch 1/64 loss: 1.734178066253662
Batch 2/64 loss: 1.635246753692627
Batch 3/64 loss: 1.6693410873413086
Batch 4/64 loss: 2.692462921142578
Batch 5/64 loss: 1.7394323348999023
Batch 6/64 loss: 1.7513761520385742
Batch 7/64 loss: 1.9784150123596191
Batch 8/64 loss: 1.9023466110229492
Batch 9/64 loss: 1.6943345069885254
Batch 10/64 loss: 1.5658559799194336
Batch 11/64 loss: 1.6935629844665527
Batch 12/64 loss: 1.63438081741333
Batch 13/64 loss: 1.743764877319336
Batch 14/64 loss: 1.6757049560546875
Batch 15/64 loss: 3.9268412590026855
Batch 16/64 loss: 4.859073162078857
Batch 17/64 loss: 1.6678094863891602
Batch 18/64 loss: 1.8399405479431152
Batch 19/64 loss: 1.6963677406311035
Batch 20/64 loss: 1.7880401611328125
Batch 21/64 loss: 1.7954010963439941
Batch 22/64 loss: 1.6395645141601562
Batch 23/64 loss: 1.7464313507080078
Batch 24/64 loss: 1.7534284591674805
Batch 25/64 loss: 1.7427711486816406
Batch 26/64 loss: 1.648500919342041
Batch 27/64 loss: 1.690373420715332
Batch 28/64 loss: 1.615644931793213
Batch 29/64 loss: 1.7575993537902832
Batch 30/64 loss: 1.6841645240783691
Batch 31/64 loss: 1.666585922241211
Batch 32/64 loss: 1.6033248901367188
Batch 33/64 loss: 1.5728421211242676
Batch 34/64 loss: 1.5980315208435059
Batch 35/64 loss: 1.7309622764587402
Batch 36/64 loss: 1.6734647750854492
Batch 37/64 loss: 1.7377042770385742
Batch 38/64 loss: 2.0090174674987793
Batch 39/64 loss: 2.5297908782958984
Batch 40/64 loss: 1.7657246589660645
Batch 41/64 loss: 1.7437901496887207
Batch 42/64 loss: 1.68353271484375
Batch 43/64 loss: 1.6467275619506836
Batch 44/64 loss: 1.6353693008422852
Batch 45/64 loss: 1.6423492431640625
Batch 46/64 loss: 1.8831167221069336
Batch 47/64 loss: 2.388123035430908
Batch 48/64 loss: 1.7180218696594238
Batch 49/64 loss: 2.071892261505127
Batch 50/64 loss: 1.5331377983093262
Batch 51/64 loss: 1.7783355712890625
Batch 52/64 loss: 1.612685203552246
Batch 53/64 loss: 1.6280598640441895
Batch 54/64 loss: 1.512181282043457
Batch 55/64 loss: 2.047722339630127
Batch 56/64 loss: 1.7085261344909668
Batch 57/64 loss: 1.5405621528625488
Batch 58/64 loss: 1.639298439025879
Batch 59/64 loss: 1.7331733703613281
Batch 60/64 loss: 1.7988700866699219
Batch 61/64 loss: 3.9799375534057617
Batch 62/64 loss: 2.534707546234131
Batch 63/64 loss: 1.6531133651733398
Batch 64/64 loss: -1.2998723983764648
Epoch 492  Train loss: 1.850794246149998  Val loss: 1.3933127098476763
Epoch 493
-------------------------------
Batch 1/64 loss: 1.619135856628418
Batch 2/64 loss: 2.4811758995056152
Batch 3/64 loss: 1.7465381622314453
Batch 4/64 loss: 2.806643486022949
Batch 5/64 loss: 1.8873023986816406
Batch 6/64 loss: 1.6021857261657715
Batch 7/64 loss: 2.009644031524658
Batch 8/64 loss: 1.692258358001709
Batch 9/64 loss: 1.6563239097595215
Batch 10/64 loss: 1.7799715995788574
Batch 11/64 loss: 1.6923813819885254
Batch 12/64 loss: 1.7334604263305664
Batch 13/64 loss: 1.8994369506835938
Batch 14/64 loss: 1.5957822799682617
Batch 15/64 loss: 1.6048359870910645
Batch 16/64 loss: 2.606750011444092
Batch 17/64 loss: 1.7067556381225586
Batch 18/64 loss: 1.8414430618286133
Batch 19/64 loss: 1.7141461372375488
Batch 20/64 loss: 1.9058632850646973
Batch 21/64 loss: 1.5150465965270996
Batch 22/64 loss: 1.8186874389648438
Batch 23/64 loss: 1.79801607131958
Batch 24/64 loss: 1.7124505043029785
Batch 25/64 loss: 1.7668867111206055
Batch 26/64 loss: 4.585115909576416
Batch 27/64 loss: 1.7378273010253906
Batch 28/64 loss: 1.6671404838562012
Batch 29/64 loss: 1.5387158393859863
Batch 30/64 loss: 1.6515445709228516
Batch 31/64 loss: 1.7094388008117676
Batch 32/64 loss: 1.616128921508789
Batch 33/64 loss: 1.67246675491333
Batch 34/64 loss: 1.616525650024414
Batch 35/64 loss: 2.8021979331970215
Batch 36/64 loss: 1.6780099868774414
Batch 37/64 loss: 1.695009708404541
Batch 38/64 loss: 1.6600236892700195
Batch 39/64 loss: 1.5407018661499023
Batch 40/64 loss: 1.7372565269470215
Batch 41/64 loss: 3.693587303161621
Batch 42/64 loss: 2.357257843017578
Batch 43/64 loss: 1.8714203834533691
Batch 44/64 loss: 1.619781494140625
Batch 45/64 loss: 1.5915942192077637
Batch 46/64 loss: 1.8923163414001465
Batch 47/64 loss: 1.6969985961914062
Batch 48/64 loss: 1.8679699897766113
Batch 49/64 loss: 1.627957820892334
Batch 50/64 loss: 1.566065788269043
Batch 51/64 loss: 1.9111108779907227
Batch 52/64 loss: 1.5845141410827637
Batch 53/64 loss: 1.6343293190002441
Batch 54/64 loss: 3.979801654815674
Batch 55/64 loss: 1.5419931411743164
Batch 56/64 loss: 1.5406718254089355
Batch 57/64 loss: 1.598149299621582
Batch 58/64 loss: 1.621352195739746
Batch 59/64 loss: 1.5657458305358887
Batch 60/64 loss: 1.5921788215637207
Batch 61/64 loss: 1.6818351745605469
Batch 62/64 loss: 1.8043437004089355
Batch 63/64 loss: 1.5652642250061035
Batch 64/64 loss: -1.5218124389648438
Epoch 493  Train loss: 1.8410369648652918  Val loss: 1.3957471683672613
Epoch 494
-------------------------------
Batch 1/64 loss: 1.5454907417297363
Batch 2/64 loss: 1.783158779144287
Batch 3/64 loss: 1.5612635612487793
Batch 4/64 loss: 1.5274968147277832
Batch 5/64 loss: 1.7149715423583984
Batch 6/64 loss: 1.8904361724853516
Batch 7/64 loss: 1.6432905197143555
Batch 8/64 loss: 1.609044075012207
Batch 9/64 loss: 1.6553692817687988
Batch 10/64 loss: 1.7156038284301758
Batch 11/64 loss: 1.5677146911621094
Batch 12/64 loss: 4.3709492683410645
Batch 13/64 loss: 1.6632475852966309
Batch 14/64 loss: 1.8328685760498047
Batch 15/64 loss: 1.7214455604553223
Batch 16/64 loss: 1.718210220336914
Batch 17/64 loss: 1.6807570457458496
Batch 18/64 loss: 2.7244644165039062
Batch 19/64 loss: 1.9653172492980957
Batch 20/64 loss: 1.8982648849487305
Batch 21/64 loss: 1.8244032859802246
Batch 22/64 loss: 1.563913345336914
Batch 23/64 loss: 1.6610593795776367
Batch 24/64 loss: 1.605072021484375
Batch 25/64 loss: 1.645735740661621
Batch 26/64 loss: 3.9623827934265137
Batch 27/64 loss: 1.6148762702941895
Batch 28/64 loss: 1.7109107971191406
Batch 29/64 loss: 1.6553187370300293
Batch 30/64 loss: 1.5996499061584473
Batch 31/64 loss: 1.6289968490600586
Batch 32/64 loss: 1.5991039276123047
Batch 33/64 loss: 1.7121567726135254
Batch 34/64 loss: 2.736326217651367
Batch 35/64 loss: 4.697160243988037
Batch 36/64 loss: 1.9046664237976074
Batch 37/64 loss: 1.7226958274841309
Batch 38/64 loss: 2.0888819694519043
Batch 39/64 loss: 1.6948604583740234
Batch 40/64 loss: 1.604689598083496
Batch 41/64 loss: 2.2921218872070312
Batch 42/64 loss: 1.5513253211975098
Batch 43/64 loss: 1.92799711227417
Batch 44/64 loss: 1.6639790534973145
Batch 45/64 loss: 1.7539730072021484
Batch 46/64 loss: 2.124147415161133
Batch 47/64 loss: 1.7446231842041016
Batch 48/64 loss: 1.6726937294006348
Batch 49/64 loss: 1.6521172523498535
Batch 50/64 loss: 1.701181411743164
Batch 51/64 loss: 1.7201061248779297
Batch 52/64 loss: 1.8768854141235352
Batch 53/64 loss: 1.6462979316711426
Batch 54/64 loss: 1.5913352966308594
Batch 55/64 loss: 2.2293148040771484
Batch 56/64 loss: 1.503415584564209
Batch 57/64 loss: 1.6068425178527832
Batch 58/64 loss: 1.6181721687316895
Batch 59/64 loss: 1.6761360168457031
Batch 60/64 loss: 1.7163047790527344
Batch 61/64 loss: 1.9877276420593262
Batch 62/64 loss: 2.782398223876953
Batch 63/64 loss: 1.8113493919372559
Batch 64/64 loss: -1.9912910461425781
Epoch 494  Train loss: 1.856928664562749  Val loss: 1.4034870973567373
Epoch 495
-------------------------------
Batch 1/64 loss: 1.6592588424682617
Batch 2/64 loss: 1.6999740600585938
Batch 3/64 loss: 1.8202228546142578
Batch 4/64 loss: 2.7710795402526855
Batch 5/64 loss: 1.69307279586792
Batch 6/64 loss: 1.6868000030517578
Batch 7/64 loss: 1.654770851135254
Batch 8/64 loss: 1.869642734527588
Batch 9/64 loss: 1.6157450675964355
Batch 10/64 loss: 1.678380012512207
Batch 11/64 loss: 2.7480788230895996
Batch 12/64 loss: 2.2349514961242676
Batch 13/64 loss: 1.6885099411010742
Batch 14/64 loss: 1.8712329864501953
Batch 15/64 loss: 1.699049472808838
Batch 16/64 loss: 2.0488247871398926
Batch 17/64 loss: 1.903592586517334
Batch 18/64 loss: 1.681142807006836
Batch 19/64 loss: 1.7207989692687988
Batch 20/64 loss: 1.7340164184570312
Batch 21/64 loss: 1.8958930969238281
Batch 22/64 loss: 1.7558975219726562
Batch 23/64 loss: 1.6927638053894043
Batch 24/64 loss: 1.8560686111450195
Batch 25/64 loss: 2.4203453063964844
Batch 26/64 loss: 2.303098201751709
Batch 27/64 loss: 1.717484951019287
Batch 28/64 loss: 1.717604160308838
Batch 29/64 loss: 1.6073007583618164
Batch 30/64 loss: 1.641767978668213
Batch 31/64 loss: 1.6342086791992188
Batch 32/64 loss: 1.8427982330322266
Batch 33/64 loss: 1.6344490051269531
Batch 34/64 loss: 1.728456974029541
Batch 35/64 loss: 1.594672679901123
Batch 36/64 loss: 1.754429817199707
Batch 37/64 loss: 1.5892071723937988
Batch 38/64 loss: 1.8358979225158691
Batch 39/64 loss: 1.8495697975158691
Batch 40/64 loss: 1.6984186172485352
Batch 41/64 loss: 1.5835504531860352
Batch 42/64 loss: 1.7188448905944824
Batch 43/64 loss: 1.641805648803711
Batch 44/64 loss: 1.655024528503418
Batch 45/64 loss: 1.7060694694519043
Batch 46/64 loss: 1.6337738037109375
Batch 47/64 loss: 1.580336093902588
Batch 48/64 loss: 1.6643400192260742
Batch 49/64 loss: 1.6320276260375977
Batch 50/64 loss: 1.6419267654418945
Batch 51/64 loss: 1.8684234619140625
Batch 52/64 loss: 1.7718849182128906
Batch 53/64 loss: 1.7894625663757324
Batch 54/64 loss: 4.226161479949951
Batch 55/64 loss: 1.6412177085876465
Batch 56/64 loss: 1.6340279579162598
Batch 57/64 loss: 1.657073974609375
Batch 58/64 loss: 2.755002498626709
Batch 59/64 loss: 1.9777436256408691
Batch 60/64 loss: 1.6481976509094238
Batch 61/64 loss: 1.7168192863464355
Batch 62/64 loss: 3.7486166954040527
Batch 63/64 loss: 4.558866024017334
Batch 64/64 loss: -1.7991180419921875
Epoch 495  Train loss: 1.8721778346043008  Val loss: 1.3948611623233127
Epoch 496
-------------------------------
Batch 1/64 loss: 1.751638412475586
Batch 2/64 loss: 1.5696229934692383
Batch 3/64 loss: 1.8669276237487793
Batch 4/64 loss: 1.570340633392334
Batch 5/64 loss: 2.705122947692871
Batch 6/64 loss: 1.909348964691162
Batch 7/64 loss: 1.6451020240783691
Batch 8/64 loss: 1.6961045265197754
Batch 9/64 loss: 1.6970815658569336
Batch 10/64 loss: 1.6384491920471191
Batch 11/64 loss: 1.7390971183776855
Batch 12/64 loss: 1.6150093078613281
Batch 13/64 loss: 1.668391227722168
Batch 14/64 loss: 1.6714754104614258
Batch 15/64 loss: 1.662851333618164
Batch 16/64 loss: 2.2633814811706543
Batch 17/64 loss: 1.6231799125671387
Batch 18/64 loss: 1.6183791160583496
Batch 19/64 loss: 1.6139287948608398
Batch 20/64 loss: 1.7053675651550293
Batch 21/64 loss: 3.833448886871338
Batch 22/64 loss: 2.4693922996520996
Batch 23/64 loss: 1.717045783996582
Batch 24/64 loss: 1.6830415725708008
Batch 25/64 loss: 2.2516722679138184
Batch 26/64 loss: 1.6461338996887207
Batch 27/64 loss: 2.0734682083129883
Batch 28/64 loss: 1.5504441261291504
Batch 29/64 loss: 1.7412381172180176
Batch 30/64 loss: 3.997744083404541
Batch 31/64 loss: 1.687037467956543
Batch 32/64 loss: 1.6898536682128906
Batch 33/64 loss: 1.6547441482543945
Batch 34/64 loss: 1.6889848709106445
Batch 35/64 loss: 1.6789374351501465
Batch 36/64 loss: 1.7268800735473633
Batch 37/64 loss: 1.9782958030700684
Batch 38/64 loss: 1.7255001068115234
Batch 39/64 loss: 2.02555513381958
Batch 40/64 loss: 1.683751106262207
Batch 41/64 loss: 1.6204724311828613
Batch 42/64 loss: 1.5902628898620605
Batch 43/64 loss: 1.6282501220703125
Batch 44/64 loss: 1.6703152656555176
Batch 45/64 loss: 1.7841358184814453
Batch 46/64 loss: 1.8974285125732422
Batch 47/64 loss: 1.9647321701049805
Batch 48/64 loss: 1.8282976150512695
Batch 49/64 loss: 4.713437557220459
Batch 50/64 loss: 1.7334470748901367
Batch 51/64 loss: 2.7555623054504395
Batch 52/64 loss: 1.7507691383361816
Batch 53/64 loss: 1.7541718482971191
Batch 54/64 loss: 2.112150192260742
Batch 55/64 loss: 1.6563515663146973
Batch 56/64 loss: 1.6851840019226074
Batch 57/64 loss: 1.6660361289978027
Batch 58/64 loss: 1.7111539840698242
Batch 59/64 loss: 1.5604000091552734
Batch 60/64 loss: 1.633568286895752
Batch 61/64 loss: 2.2980833053588867
Batch 62/64 loss: 1.8976750373840332
Batch 63/64 loss: 1.6207947731018066
Batch 64/64 loss: -1.9242191314697266
Epoch 496  Train loss: 1.8638978023155064  Val loss: 1.412737279413492
Epoch 497
-------------------------------
Batch 1/64 loss: 1.5793867111206055
Batch 2/64 loss: 1.6206908226013184
Batch 3/64 loss: 1.7180089950561523
Batch 4/64 loss: 1.6215033531188965
Batch 5/64 loss: 1.8299269676208496
Batch 6/64 loss: 1.61683988571167
Batch 7/64 loss: 1.5509428977966309
Batch 8/64 loss: 3.1037044525146484
Batch 9/64 loss: 1.9070258140563965
Batch 10/64 loss: 1.8707985877990723
Batch 11/64 loss: 1.6607041358947754
Batch 12/64 loss: 1.6475930213928223
Batch 13/64 loss: 1.6159539222717285
Batch 14/64 loss: 1.7299985885620117
Batch 15/64 loss: 4.652298450469971
Batch 16/64 loss: 1.7118206024169922
Batch 17/64 loss: 1.9772148132324219
Batch 18/64 loss: 1.8531603813171387
Batch 19/64 loss: 1.5864944458007812
Batch 20/64 loss: 1.5632538795471191
Batch 21/64 loss: 2.027207851409912
Batch 22/64 loss: 1.6136713027954102
Batch 23/64 loss: 1.7826557159423828
Batch 24/64 loss: 1.7292280197143555
Batch 25/64 loss: 1.6466569900512695
Batch 26/64 loss: 3.958463668823242
Batch 27/64 loss: 1.5819077491760254
Batch 28/64 loss: 1.696986198425293
Batch 29/64 loss: 1.613438606262207
Batch 30/64 loss: 1.660348892211914
Batch 31/64 loss: 2.1783714294433594
Batch 32/64 loss: 1.7340779304504395
Batch 33/64 loss: 2.305527687072754
Batch 34/64 loss: 1.933438777923584
Batch 35/64 loss: 1.7928595542907715
Batch 36/64 loss: 1.4971098899841309
Batch 37/64 loss: 1.9430170059204102
Batch 38/64 loss: 2.3485851287841797
Batch 39/64 loss: 1.5244793891906738
Batch 40/64 loss: 1.5370898246765137
Batch 41/64 loss: 1.7445859909057617
Batch 42/64 loss: 1.6977014541625977
Batch 43/64 loss: 1.9483046531677246
Batch 44/64 loss: 1.5535755157470703
Batch 45/64 loss: 1.5718531608581543
Batch 46/64 loss: 1.6595454216003418
Batch 47/64 loss: 1.6949429512023926
Batch 48/64 loss: 1.741495132446289
Batch 49/64 loss: 1.7206144332885742
Batch 50/64 loss: 3.778116226196289
Batch 51/64 loss: 1.490701675415039
Batch 52/64 loss: 1.8117527961730957
Batch 53/64 loss: 1.6033806800842285
Batch 54/64 loss: 2.7930917739868164
Batch 55/64 loss: 1.6819343566894531
Batch 56/64 loss: 1.6964607238769531
Batch 57/64 loss: 1.560882568359375
Batch 58/64 loss: 1.6843576431274414
Batch 59/64 loss: 1.7166404724121094
Batch 60/64 loss: 1.8868074417114258
Batch 61/64 loss: 1.590223789215088
Batch 62/64 loss: 1.6766314506530762
Batch 63/64 loss: 2.03493070602417
Batch 64/64 loss: -1.7854461669921875
Epoch 497  Train loss: 1.8434806075750614  Val loss: 1.4561542891145163
Epoch 498
-------------------------------
Batch 1/64 loss: 1.6951708793640137
Batch 2/64 loss: 2.184919834136963
Batch 3/64 loss: 1.632680892944336
Batch 4/64 loss: 5.205998420715332
Batch 5/64 loss: 2.0478763580322266
Batch 6/64 loss: 2.0711207389831543
Batch 7/64 loss: 1.7119364738464355
Batch 8/64 loss: 1.760556697845459
Batch 9/64 loss: 1.6801538467407227
Batch 10/64 loss: 1.6137371063232422
Batch 11/64 loss: 1.7872028350830078
Batch 12/64 loss: 1.759960651397705
Batch 13/64 loss: 1.6758699417114258
Batch 14/64 loss: 1.8470487594604492
Batch 15/64 loss: 1.6568903923034668
Batch 16/64 loss: 1.7334928512573242
Batch 17/64 loss: 1.911041259765625
Batch 18/64 loss: 1.7684102058410645
Batch 19/64 loss: 2.316567897796631
Batch 20/64 loss: 1.7183289527893066
Batch 21/64 loss: 1.7579231262207031
Batch 22/64 loss: 1.6252713203430176
Batch 23/64 loss: 1.715888500213623
Batch 24/64 loss: 1.62003755569458
Batch 25/64 loss: 1.6539411544799805
Batch 26/64 loss: 1.777925968170166
Batch 27/64 loss: 1.621164321899414
Batch 28/64 loss: 1.6838068962097168
Batch 29/64 loss: 1.759955883026123
Batch 30/64 loss: 1.7645606994628906
Batch 31/64 loss: 1.7546138763427734
Batch 32/64 loss: 4.6367950439453125
Batch 33/64 loss: 1.5927143096923828
Batch 34/64 loss: 1.7444071769714355
Batch 35/64 loss: 1.627917766571045
Batch 36/64 loss: 1.743492603302002
Batch 37/64 loss: 1.718177318572998
Batch 38/64 loss: 1.745236873626709
Batch 39/64 loss: 3.180492877960205
Batch 40/64 loss: 1.6325688362121582
Batch 41/64 loss: 1.9761309623718262
Batch 42/64 loss: 1.5684967041015625
Batch 43/64 loss: 1.6232647895812988
Batch 44/64 loss: 1.669252872467041
Batch 45/64 loss: 1.5598745346069336
Batch 46/64 loss: 1.7425446510314941
Batch 47/64 loss: 3.8192968368530273
Batch 48/64 loss: 1.649702548980713
Batch 49/64 loss: 1.6547784805297852
Batch 50/64 loss: 1.6779661178588867
Batch 51/64 loss: 1.5011167526245117
Batch 52/64 loss: 2.263631820678711
Batch 53/64 loss: 1.6842985153198242
Batch 54/64 loss: 1.6117753982543945
Batch 55/64 loss: 1.540942668914795
Batch 56/64 loss: 2.3671460151672363
Batch 57/64 loss: 1.5331554412841797
Batch 58/64 loss: 1.5859766006469727
Batch 59/64 loss: 1.6416583061218262
Batch 60/64 loss: 1.9372711181640625
Batch 61/64 loss: 1.7152471542358398
Batch 62/64 loss: 1.5466985702514648
Batch 63/64 loss: 1.7449641227722168
Batch 64/64 loss: -1.625452995300293
Epoch 498  Train loss: 1.859324836730957  Val loss: 1.404975458518746
Epoch 499
-------------------------------
Batch 1/64 loss: 1.796701431274414
Batch 2/64 loss: 1.5332956314086914
Batch 3/64 loss: 1.560680866241455
Batch 4/64 loss: 1.544790267944336
Batch 5/64 loss: 1.6215434074401855
Batch 6/64 loss: 1.78192138671875
Batch 7/64 loss: 1.603616714477539
Batch 8/64 loss: 1.829113483428955
Batch 9/64 loss: 3.8991031646728516
Batch 10/64 loss: 2.4277515411376953
Batch 11/64 loss: 1.9664297103881836
Batch 12/64 loss: 2.8066701889038086
Batch 13/64 loss: 1.7050657272338867
Batch 14/64 loss: 3.413947582244873
Batch 15/64 loss: 1.9816746711730957
Batch 16/64 loss: 1.7633628845214844
Batch 17/64 loss: 1.6117653846740723
Batch 18/64 loss: 2.170422077178955
Batch 19/64 loss: 2.008297920227051
Batch 20/64 loss: 1.6322383880615234
Batch 21/64 loss: 1.8397278785705566
Batch 22/64 loss: 1.7797298431396484
Batch 23/64 loss: 1.6768383979797363
Batch 24/64 loss: 1.565610408782959
Batch 25/64 loss: 1.63484525680542
Batch 26/64 loss: 1.5744457244873047
Batch 27/64 loss: 1.6770873069763184
Batch 28/64 loss: 4.054025650024414
Batch 29/64 loss: 1.5979514122009277
Batch 30/64 loss: 1.6155343055725098
Batch 31/64 loss: 1.661055564880371
Batch 32/64 loss: 2.090885639190674
Batch 33/64 loss: 1.7575325965881348
Batch 34/64 loss: 1.8057031631469727
Batch 35/64 loss: 1.9517884254455566
Batch 36/64 loss: 1.9870572090148926
Batch 37/64 loss: 2.6171178817749023
Batch 38/64 loss: 1.7799487113952637
Batch 39/64 loss: 1.6611671447753906
Batch 40/64 loss: 1.6266555786132812
Batch 41/64 loss: 1.791959285736084
Batch 42/64 loss: 2.0377883911132812
Batch 43/64 loss: 1.8243188858032227
Batch 44/64 loss: 1.7606539726257324
Batch 45/64 loss: 1.8333072662353516
Batch 46/64 loss: 2.0946531295776367
Batch 47/64 loss: 1.9002981185913086
Batch 48/64 loss: 1.706071376800537
Batch 49/64 loss: 1.6447515487670898
Batch 50/64 loss: 1.7885527610778809
Batch 51/64 loss: 1.6025171279907227
Batch 52/64 loss: 1.650132656097412
Batch 53/64 loss: 1.5846962928771973
Batch 54/64 loss: 4.779650688171387
Batch 55/64 loss: 1.8326458930969238
Batch 56/64 loss: 1.6078457832336426
Batch 57/64 loss: 1.7260479927062988
Batch 58/64 loss: 1.8837523460388184
Batch 59/64 loss: 1.5980830192565918
Batch 60/64 loss: 1.724484920501709
Batch 61/64 loss: 1.7636876106262207
Batch 62/64 loss: 1.7077317237854004
Batch 63/64 loss: 1.6507973670959473
Batch 64/64 loss: -1.776515007019043
Epoch 499  Train loss: 1.8945120381373985  Val loss: 1.449974872811963
Epoch 500
-------------------------------
Batch 1/64 loss: 1.7203102111816406
Batch 2/64 loss: 4.202439785003662
Batch 3/64 loss: 1.887655258178711
Batch 4/64 loss: 1.6006717681884766
Batch 5/64 loss: 1.6915702819824219
Batch 6/64 loss: 1.7037787437438965
Batch 7/64 loss: 2.0954384803771973
Batch 8/64 loss: 1.605931282043457
Batch 9/64 loss: 1.5477852821350098
Batch 10/64 loss: 1.8587932586669922
Batch 11/64 loss: 1.593461036682129
Batch 12/64 loss: 1.8537988662719727
Batch 13/64 loss: 2.038508892059326
Batch 14/64 loss: 1.707993507385254
Batch 15/64 loss: 1.6070070266723633
Batch 16/64 loss: 2.584012985229492
Batch 17/64 loss: 1.6196227073669434
Batch 18/64 loss: 1.8923659324645996
Batch 19/64 loss: 1.5637249946594238
Batch 20/64 loss: 1.6593012809753418
Batch 21/64 loss: 2.0447897911071777
Batch 22/64 loss: 2.3844785690307617
Batch 23/64 loss: 1.5819993019104004
Batch 24/64 loss: 2.6549901962280273
Batch 25/64 loss: 1.5924859046936035
Batch 26/64 loss: 1.6373810768127441
Batch 27/64 loss: 2.8855152130126953
Batch 28/64 loss: 1.5721979141235352
Batch 29/64 loss: 1.6635780334472656
Batch 30/64 loss: 1.70637845993042
Batch 31/64 loss: 1.54056978225708
Batch 32/64 loss: 1.5825519561767578
Batch 33/64 loss: 1.659590721130371
Batch 34/64 loss: 1.6276826858520508
Batch 35/64 loss: 1.7352957725524902
Batch 36/64 loss: 1.5619902610778809
Batch 37/64 loss: 1.7498784065246582
Batch 38/64 loss: 1.818110466003418
Batch 39/64 loss: 1.5739450454711914
Batch 40/64 loss: 1.7254033088684082
Batch 41/64 loss: 1.5693883895874023
Batch 42/64 loss: 1.695615291595459
Batch 43/64 loss: 1.7559714317321777
Batch 44/64 loss: 1.695404052734375
Batch 45/64 loss: 1.6022858619689941
Batch 46/64 loss: 2.1171603202819824
Batch 47/64 loss: 2.3839144706726074
Batch 48/64 loss: 1.5359697341918945
Batch 49/64 loss: 1.7520151138305664
Batch 50/64 loss: 1.850632667541504
Batch 51/64 loss: 3.86403751373291
Batch 52/64 loss: 2.0443148612976074
Batch 53/64 loss: 1.5764656066894531
Batch 54/64 loss: 4.576695442199707
Batch 55/64 loss: 1.7094831466674805
Batch 56/64 loss: 2.2073588371276855
Batch 57/64 loss: 1.8975319862365723
Batch 58/64 loss: 1.6092262268066406
Batch 59/64 loss: 1.9175915718078613
Batch 60/64 loss: 1.882422924041748
Batch 61/64 loss: 1.6464800834655762
Batch 62/64 loss: 1.7346768379211426
Batch 63/64 loss: 1.5387296676635742
Batch 64/64 loss: -1.7985973358154297
Epoch 500  Train loss: 1.868978956633923  Val loss: 1.409479894998557
SLIC undersegmentation error: 0.054052233676975946
SLIC inter-cluster variation: 0.02397972047789259
SLIC number of superpixels: 162588
SLIC superpixels per image: 558.7216494845361
Model loaded
Test metrics:
0.8365761930590233 0.25648522336769763 6.250145928369834 tensor(0.1077, dtype=torch.float64) 0.5232440594249447 1.9781571101357662 78149
Inference time: 0.004313457462795821 seconds
Relabeled undersegmentation error: 0.06995189003436424
Relabeled inter-cluster variation: 0.03531384057575293
Relabeled mean superpixels count: 531.2405498281787
Original mean superpixels count: 268.5635738831615
Done!
Job id: 489836
Job id: 492290
