Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 0.47064363956451416
Batch 2/64 loss: 0.4019315838813782
Batch 3/64 loss: 0.3895425796508789
Batch 4/64 loss: 0.38725847005844116
Batch 5/64 loss: 0.38326340913772583
Batch 6/64 loss: 0.3829934597015381
Batch 7/64 loss: 0.3831331133842468
Batch 8/64 loss: 0.38284003734588623
Batch 9/64 loss: 0.38109517097473145
Batch 10/64 loss: 0.38087600469589233
Batch 11/64 loss: 0.38030946254730225
Batch 12/64 loss: 0.3796607255935669
Batch 13/64 loss: 0.3802838921546936
Batch 14/64 loss: 0.37996846437454224
Batch 15/64 loss: 0.3784799575805664
Batch 16/64 loss: 0.37932389974594116
Batch 17/64 loss: 0.37978601455688477
Batch 18/64 loss: 0.37802183628082275
Batch 19/64 loss: 0.37793898582458496
Batch 20/64 loss: 0.37821173667907715
Batch 21/64 loss: 0.3773422837257385
Batch 22/64 loss: 0.3786535859107971
Batch 23/64 loss: 0.3779521584510803
Batch 24/64 loss: 0.3772960901260376
Batch 25/64 loss: 0.3767944574356079
Batch 26/64 loss: 0.3761644959449768
Batch 27/64 loss: 0.3771705627441406
Batch 28/64 loss: 0.3765483498573303
Batch 29/64 loss: 0.37716883420944214
Batch 30/64 loss: 0.37679946422576904
Batch 31/64 loss: 0.37568914890289307
Batch 32/64 loss: 0.3755400776863098
Batch 33/64 loss: 0.37822532653808594
Batch 34/64 loss: 0.3771418333053589
Batch 35/64 loss: 0.3770129680633545
Batch 36/64 loss: 0.37484681606292725
Batch 37/64 loss: 0.3756776452064514
Batch 38/64 loss: 0.37707316875457764
Batch 39/64 loss: 0.3755272626876831
Batch 40/64 loss: 0.37543320655822754
Batch 41/64 loss: 0.3758140802383423
Batch 42/64 loss: 0.37454503774642944
Batch 43/64 loss: 0.3745192885398865
Batch 44/64 loss: 0.3741379976272583
Batch 45/64 loss: 0.3752567172050476
Batch 46/64 loss: 0.3738420009613037
Batch 47/64 loss: 0.37524867057800293
Batch 48/64 loss: 0.3752063512802124
Batch 49/64 loss: 0.37489771842956543
Batch 50/64 loss: 0.3751552104949951
Batch 51/64 loss: 0.37257444858551025
Batch 52/64 loss: 0.37174689769744873
Batch 53/64 loss: 0.37392282485961914
Batch 54/64 loss: 0.3706963062286377
Batch 55/64 loss: 0.37254202365875244
Batch 56/64 loss: 0.3741663098335266
Batch 57/64 loss: 0.37377530336380005
Batch 58/64 loss: 0.3728073239326477
Batch 59/64 loss: 0.37226593494415283
Batch 60/64 loss: 0.37234747409820557
Batch 61/64 loss: 0.37253105640411377
Batch 62/64 loss: 0.3716663718223572
Batch 63/64 loss: 0.37205827236175537
Batch 64/64 loss: 0.37212246656417847
Epoch 1  Train loss: 0.37867350040697584  Val loss: 0.3744960134381691
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 0.3720378279685974
Batch 2/64 loss: 0.3745896816253662
Batch 3/64 loss: 0.371776819229126
Batch 4/64 loss: 0.3721922039985657
Batch 5/64 loss: 0.3715130686759949
Batch 6/64 loss: 0.3713831305503845
Batch 7/64 loss: 0.3708914518356323
Batch 8/64 loss: 0.3711310625076294
Batch 9/64 loss: 0.36946535110473633
Batch 10/64 loss: 0.3684656620025635
Batch 11/64 loss: 0.3705716133117676
Batch 12/64 loss: 0.37270796298980713
Batch 13/64 loss: 0.37041521072387695
Batch 14/64 loss: 0.37063121795654297
Batch 15/64 loss: 0.3700054883956909
Batch 16/64 loss: 0.368921160697937
Batch 17/64 loss: 0.3691675662994385
Batch 18/64 loss: 0.36924517154693604
Batch 19/64 loss: 0.3699883818626404
Batch 20/64 loss: 0.3688775300979614
Batch 21/64 loss: 0.3674255609512329
Batch 22/64 loss: 0.36854755878448486
Batch 23/64 loss: 0.3684910535812378
Batch 24/64 loss: 0.370794415473938
Batch 25/64 loss: 0.36895501613616943
Batch 26/64 loss: 0.36804401874542236
Batch 27/64 loss: 0.36873453855514526
Batch 28/64 loss: 0.3660733699798584
Batch 29/64 loss: 0.36914539337158203
Batch 30/64 loss: 0.3680495023727417
Batch 31/64 loss: 0.3701537847518921
Batch 32/64 loss: 0.3667854070663452
Batch 33/64 loss: 0.3670463562011719
Batch 34/64 loss: 0.36843955516815186
Batch 35/64 loss: 0.369035005569458
Batch 36/64 loss: 0.3682054281234741
Batch 37/64 loss: 0.3670908808708191
Batch 38/64 loss: 0.37011992931365967
Batch 39/64 loss: 0.369775652885437
Batch 40/64 loss: 0.3667367696762085
Batch 41/64 loss: 0.3670397996902466
Batch 42/64 loss: 0.36477482318878174
Batch 43/64 loss: 0.3673042058944702
Batch 44/64 loss: 0.3668479919433594
Batch 45/64 loss: 0.3696969151496887
Batch 46/64 loss: 0.3664463758468628
Batch 47/64 loss: 0.3663643002510071
Batch 48/64 loss: 0.36822664737701416
Batch 49/64 loss: 0.3673085570335388
Batch 50/64 loss: 0.36767327785491943
Batch 51/64 loss: 0.3664688467979431
Batch 52/64 loss: 0.3683054447174072
Batch 53/64 loss: 0.3659316301345825
Batch 54/64 loss: 0.3691636323928833
Batch 55/64 loss: 0.368014395236969
Batch 56/64 loss: 0.36511528491973877
Batch 57/64 loss: 0.36741650104522705
Batch 58/64 loss: 0.3657788038253784
Batch 59/64 loss: 0.36558473110198975
Batch 60/64 loss: 0.368274986743927
Batch 61/64 loss: 0.364668071269989
Batch 62/64 loss: 0.36515116691589355
Batch 63/64 loss: 0.36697816848754883
Batch 64/64 loss: 0.36562228202819824
Epoch 2  Train loss: 0.3685392632203944  Val loss: 0.3673772838517153
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 0.3671908378601074
Batch 2/64 loss: 0.36789941787719727
Batch 3/64 loss: 0.36720359325408936
Batch 4/64 loss: 0.36455237865448
Batch 5/64 loss: 0.3677845001220703
Batch 6/64 loss: 0.3666391372680664
Batch 7/64 loss: 0.36427247524261475
Batch 8/64 loss: 0.36600154638290405
Batch 9/64 loss: 0.3641185760498047
Batch 10/64 loss: 0.36300116777420044
Batch 11/64 loss: 0.36478710174560547
Batch 12/64 loss: 0.36868035793304443
Batch 13/64 loss: 0.36671900749206543
Batch 14/64 loss: 0.36568546295166016
Batch 15/64 loss: 0.36596643924713135
Batch 16/64 loss: 0.36325669288635254
Batch 17/64 loss: 0.36314308643341064
Batch 18/64 loss: 0.36553072929382324
Batch 19/64 loss: 0.36535215377807617
Batch 20/64 loss: 0.3668927550315857
Batch 21/64 loss: 0.360442578792572
Batch 22/64 loss: 0.36689674854278564
Batch 23/64 loss: 0.363283634185791
Batch 24/64 loss: 0.3647274374961853
Batch 25/64 loss: 0.3656272292137146
Batch 26/64 loss: 0.36510419845581055
Batch 27/64 loss: 0.36488044261932373
Batch 28/64 loss: 0.3651018738746643
Batch 29/64 loss: 0.36430954933166504
Batch 30/64 loss: 0.36562836170196533
Batch 31/64 loss: 0.3639090061187744
Batch 32/64 loss: 0.3627265691757202
Batch 33/64 loss: 0.36305415630340576
Batch 34/64 loss: 0.3679664134979248
Batch 35/64 loss: 0.3634762167930603
Batch 36/64 loss: 0.36410707235336304
Batch 37/64 loss: 0.36263424158096313
Batch 38/64 loss: 0.36337512731552124
Batch 39/64 loss: 0.36233651638031006
Batch 40/64 loss: 0.36335289478302
Batch 41/64 loss: 0.36101430654525757
Batch 42/64 loss: 0.3632012605667114
Batch 43/64 loss: 0.3614872097969055
Batch 44/64 loss: 0.36415404081344604
Batch 45/64 loss: 0.36535876989364624
Batch 46/64 loss: 0.36435937881469727
Batch 47/64 loss: 0.36272263526916504
Batch 48/64 loss: 0.3629882335662842
Batch 49/64 loss: 0.36431777477264404
Batch 50/64 loss: 0.36363232135772705
Batch 51/64 loss: 0.3642098903656006
Batch 52/64 loss: 0.3654320240020752
Batch 53/64 loss: 0.36695629358291626
Batch 54/64 loss: 0.36266088485717773
Batch 55/64 loss: 0.35860002040863037
Batch 56/64 loss: 0.3624570369720459
Batch 57/64 loss: 0.3637181520462036
Batch 58/64 loss: 0.363714337348938
Batch 59/64 loss: 0.3632221221923828
Batch 60/64 loss: 0.36338895559310913
Batch 61/64 loss: 0.3612496852874756
Batch 62/64 loss: 0.36749470233917236
Batch 63/64 loss: 0.36297500133514404
Batch 64/64 loss: 0.364473819732666
Epoch 3  Train loss: 0.3643966758952421  Val loss: 0.3636350768947929
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 0.36339277029037476
Batch 2/64 loss: 0.3636817932128906
Batch 3/64 loss: 0.36061155796051025
Batch 4/64 loss: 0.3609262704849243
Batch 5/64 loss: 0.36320316791534424
Batch 6/64 loss: 0.3592577576637268
Batch 7/64 loss: 0.3615766763687134
Batch 8/64 loss: 0.3603801727294922
Batch 9/64 loss: 0.3628053665161133
Batch 10/64 loss: 0.3602571487426758
Batch 11/64 loss: 0.36323797702789307
Batch 12/64 loss: 0.36504065990448
Batch 13/64 loss: 0.3576834201812744
Batch 14/64 loss: 0.3587825894355774
Batch 15/64 loss: 0.360044002532959
Batch 16/64 loss: 0.3610323667526245
Batch 17/64 loss: 0.3624042868614197
Batch 18/64 loss: 0.3639872074127197
Batch 19/64 loss: 0.3633202314376831
Batch 20/64 loss: 0.3627065420150757
Batch 21/64 loss: 0.359561562538147
Batch 22/64 loss: 0.36104750633239746
Batch 23/64 loss: 0.36433863639831543
Batch 24/64 loss: 0.361614465713501
Batch 25/64 loss: 0.3613048791885376
Batch 26/64 loss: 0.36306339502334595
Batch 27/64 loss: 0.3626279830932617
Batch 28/64 loss: 0.36125636100769043
Batch 29/64 loss: 0.36315757036209106
Batch 30/64 loss: 0.3608269691467285
Batch 31/64 loss: 0.35839903354644775
Batch 32/64 loss: 0.36260658502578735
Batch 33/64 loss: 0.36234450340270996
Batch 34/64 loss: 0.36178749799728394
Batch 35/64 loss: 0.36073052883148193
Batch 36/64 loss: 0.36268502473831177
Batch 37/64 loss: 0.36100274324417114
Batch 38/64 loss: 0.36215370893478394
Batch 39/64 loss: 0.3642835021018982
Batch 40/64 loss: 0.36168134212493896
Batch 41/64 loss: 0.36078864336013794
Batch 42/64 loss: 0.3587855100631714
Batch 43/64 loss: 0.3610439896583557
Batch 44/64 loss: 0.3600574731826782
Batch 45/64 loss: 0.3647971749305725
Batch 46/64 loss: 0.3613765835762024
Batch 47/64 loss: 0.3630799651145935
Batch 48/64 loss: 0.36241090297698975
Batch 49/64 loss: 0.36356115341186523
Batch 50/64 loss: 0.35859864950180054
Batch 51/64 loss: 0.3622591495513916
Batch 52/64 loss: 0.360231876373291
Batch 53/64 loss: 0.3614891767501831
Batch 54/64 loss: 0.3599886894226074
Batch 55/64 loss: 0.35850703716278076
Batch 56/64 loss: 0.3600082993507385
Batch 57/64 loss: 0.36124151945114136
Batch 58/64 loss: 0.36036646366119385
Batch 59/64 loss: 0.36180973052978516
Batch 60/64 loss: 0.356204628944397
Batch 61/64 loss: 0.3610551357269287
Batch 62/64 loss: 0.3599131107330322
Batch 63/64 loss: 0.36035585403442383
Batch 64/64 loss: 0.3618626594543457
Epoch 4  Train loss: 0.3614138584510953  Val loss: 0.3616228390395437
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 0.3617534041404724
Batch 2/64 loss: 0.3608447313308716
Batch 3/64 loss: 0.3621412515640259
Batch 4/64 loss: 0.3610932230949402
Batch 5/64 loss: 0.3580225110054016
Batch 6/64 loss: 0.3601541519165039
Batch 7/64 loss: 0.358325719833374
Batch 8/64 loss: 0.3605436086654663
Batch 9/64 loss: 0.3575648069381714
Batch 10/64 loss: 0.360252320766449
Batch 11/64 loss: 0.3598504066467285
Batch 12/64 loss: 0.3592298626899719
Batch 13/64 loss: 0.3622027635574341
Batch 14/64 loss: 0.35996222496032715
Batch 15/64 loss: 0.3603525757789612
Batch 16/64 loss: 0.35825252532958984
Batch 17/64 loss: 0.3579777479171753
Batch 18/64 loss: 0.3614729046821594
Batch 19/64 loss: 0.3595846891403198
Batch 20/64 loss: 0.35969412326812744
Batch 21/64 loss: 0.357970654964447
Batch 22/64 loss: 0.35791611671447754
Batch 23/64 loss: 0.36612051725387573
Batch 24/64 loss: 0.35960865020751953
Batch 25/64 loss: 0.3558751344680786
Batch 26/64 loss: 0.36150801181793213
Batch 27/64 loss: 0.36237823963165283
Batch 28/64 loss: 0.35976970195770264
Batch 29/64 loss: 0.3570602536201477
Batch 30/64 loss: 0.3542114496231079
Batch 31/64 loss: 0.358279824256897
Batch 32/64 loss: 0.35632431507110596
Batch 33/64 loss: 0.35943830013275146
Batch 34/64 loss: 0.35506415367126465
Batch 35/64 loss: 0.36250483989715576
Batch 36/64 loss: 0.3578522205352783
Batch 37/64 loss: 0.36225831508636475
Batch 38/64 loss: 0.3580667972564697
Batch 39/64 loss: 0.35523563623428345
Batch 40/64 loss: 0.36073148250579834
Batch 41/64 loss: 0.35428404808044434
Batch 42/64 loss: 0.3582451343536377
Batch 43/64 loss: 0.3600647449493408
Batch 44/64 loss: 0.35839998722076416
Batch 45/64 loss: 0.35895293951034546
Batch 46/64 loss: 0.3603980541229248
Batch 47/64 loss: 0.35758888721466064
Batch 48/64 loss: 0.35772961378097534
Batch 49/64 loss: 0.3594260811805725
Batch 50/64 loss: 0.36011362075805664
Batch 51/64 loss: 0.36300235986709595
Batch 52/64 loss: 0.35933005809783936
Batch 53/64 loss: 0.3587072491645813
Batch 54/64 loss: 0.3567342758178711
Batch 55/64 loss: 0.3633251190185547
Batch 56/64 loss: 0.36047452688217163
Batch 57/64 loss: 0.3584355115890503
Batch 58/64 loss: 0.35663938522338867
Batch 59/64 loss: 0.35923564434051514
Batch 60/64 loss: 0.36082524061203003
Batch 61/64 loss: 0.3592812418937683
Batch 62/64 loss: 0.35996079444885254
Batch 63/64 loss: 0.36254769563674927
Batch 64/64 loss: 0.35619020462036133
Epoch 5  Train loss: 0.3593458044762705  Val loss: 0.36032656255046935
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 0.35857802629470825
Batch 2/64 loss: 0.3573415279388428
Batch 3/64 loss: 0.3631647825241089
Batch 4/64 loss: 0.3605687618255615
Batch 5/64 loss: 0.35691070556640625
Batch 6/64 loss: 0.35693514347076416
Batch 7/64 loss: 0.35591191053390503
Batch 8/64 loss: 0.3568049669265747
Batch 9/64 loss: 0.3596982955932617
Batch 10/64 loss: 0.35992932319641113
Batch 11/64 loss: 0.35945940017700195
Batch 12/64 loss: 0.35857558250427246
Batch 13/64 loss: 0.36024051904678345
Batch 14/64 loss: 0.3596513271331787
Batch 15/64 loss: 0.3598034977912903
Batch 16/64 loss: 0.3595147132873535
Batch 17/64 loss: 0.35696661472320557
Batch 18/64 loss: 0.3605685830116272
Batch 19/64 loss: 0.35904639959335327
Batch 20/64 loss: 0.3571690320968628
Batch 21/64 loss: 0.3576345443725586
Batch 22/64 loss: 0.3562411069869995
Batch 23/64 loss: 0.3607509136199951
Batch 24/64 loss: 0.3571500778198242
Batch 25/64 loss: 0.35882461071014404
Batch 26/64 loss: 0.35867488384246826
Batch 27/64 loss: 0.36165010929107666
Batch 28/64 loss: 0.35965871810913086
Batch 29/64 loss: 0.354900062084198
Batch 30/64 loss: 0.3597549796104431
Batch 31/64 loss: 0.35748910903930664
Batch 32/64 loss: 0.3589801788330078
Batch 33/64 loss: 0.35970544815063477
Batch 34/64 loss: 0.3574105501174927
Batch 35/64 loss: 0.358026921749115
Batch 36/64 loss: 0.3585408926010132
Batch 37/64 loss: 0.35574591159820557
Batch 38/64 loss: 0.3596435785293579
Batch 39/64 loss: 0.3622334599494934
Batch 40/64 loss: 0.356714129447937
Batch 41/64 loss: 0.35764652490615845
Batch 42/64 loss: 0.35778945684432983
Batch 43/64 loss: 0.35867786407470703
Batch 44/64 loss: 0.35786354541778564
Batch 45/64 loss: 0.3552401065826416
Batch 46/64 loss: 0.36003488302230835
Batch 47/64 loss: 0.35674864053726196
Batch 48/64 loss: 0.35872066020965576
Batch 49/64 loss: 0.3556585907936096
Batch 50/64 loss: 0.35790956020355225
Batch 51/64 loss: 0.3516462445259094
Batch 52/64 loss: 0.3583946228027344
Batch 53/64 loss: 0.35641539096832275
Batch 54/64 loss: 0.35793256759643555
Batch 55/64 loss: 0.3591625690460205
Batch 56/64 loss: 0.3569456934928894
Batch 57/64 loss: 0.3525179624557495
Batch 58/64 loss: 0.35326600074768066
Batch 59/64 loss: 0.3584561347961426
Batch 60/64 loss: 0.3558981418609619
Batch 61/64 loss: 0.358465313911438
Batch 62/64 loss: 0.35312366485595703
Batch 63/64 loss: 0.3598123788833618
Batch 64/64 loss: 0.3531895875930786
Epoch 6  Train loss: 0.35795745896358117  Val loss: 0.3584714587201777
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.36043643951416016
Batch 2/64 loss: 0.35491180419921875
Batch 3/64 loss: 0.35577940940856934
Batch 4/64 loss: 0.3605281114578247
Batch 5/64 loss: 0.35699188709259033
Batch 6/64 loss: 0.35665953159332275
Batch 7/64 loss: 0.3555675148963928
Batch 8/64 loss: 0.35270464420318604
Batch 9/64 loss: 0.3589058518409729
Batch 10/64 loss: 0.3566315174102783
Batch 11/64 loss: 0.35729771852493286
Batch 12/64 loss: 0.35510993003845215
Batch 13/64 loss: 0.3563893437385559
Batch 14/64 loss: 0.35338103771209717
Batch 15/64 loss: 0.3566085696220398
Batch 16/64 loss: 0.35566699504852295
Batch 17/64 loss: 0.3584907054901123
Batch 18/64 loss: 0.356967568397522
Batch 19/64 loss: 0.3558560609817505
Batch 20/64 loss: 0.35414743423461914
Batch 21/64 loss: 0.35224050283432007
Batch 22/64 loss: 0.35615622997283936
Batch 23/64 loss: 0.3566943407058716
Batch 24/64 loss: 0.3537869453430176
Batch 25/64 loss: 0.3545260429382324
Batch 26/64 loss: 0.3575870990753174
Batch 27/64 loss: 0.3548152446746826
Batch 28/64 loss: 0.3555108308792114
Batch 29/64 loss: 0.3556774854660034
Batch 30/64 loss: 0.3538883924484253
Batch 31/64 loss: 0.35429632663726807
Batch 32/64 loss: 0.3538207411766052
Batch 33/64 loss: 0.35851526260375977
Batch 34/64 loss: 0.3531097173690796
Batch 35/64 loss: 0.3587110638618469
Batch 36/64 loss: 0.35385406017303467
Batch 37/64 loss: 0.35472893714904785
Batch 38/64 loss: 0.3589244484901428
Batch 39/64 loss: 0.3566257953643799
Batch 40/64 loss: 0.3545030951499939
Batch 41/64 loss: 0.3580402135848999
Batch 42/64 loss: 0.35474932193756104
Batch 43/64 loss: 0.3599857687950134
Batch 44/64 loss: 0.3548314571380615
Batch 45/64 loss: 0.3556708097457886
Batch 46/64 loss: 0.35565507411956787
Batch 47/64 loss: 0.3610365390777588
Batch 48/64 loss: 0.3578106760978699
Batch 49/64 loss: 0.35675787925720215
Batch 50/64 loss: 0.35533154010772705
Batch 51/64 loss: 0.3558521270751953
Batch 52/64 loss: 0.3526967167854309
Batch 53/64 loss: 0.35403019189834595
Batch 54/64 loss: 0.35617566108703613
Batch 55/64 loss: 0.35922157764434814
Batch 56/64 loss: 0.3571138381958008
Batch 57/64 loss: 0.35829854011535645
Batch 58/64 loss: 0.3582162857055664
Batch 59/64 loss: 0.35750865936279297
Batch 60/64 loss: 0.35560065507888794
Batch 61/64 loss: 0.35623276233673096
Batch 62/64 loss: 0.35657548904418945
Batch 63/64 loss: 0.35641777515411377
Batch 64/64 loss: 0.3556711673736572
Epoch 7  Train loss: 0.3561971383936265  Val loss: 0.35786846986750964
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 0.3558066487312317
Batch 2/64 loss: 0.3540956974029541
Batch 3/64 loss: 0.356350302696228
Batch 4/64 loss: 0.3550281524658203
Batch 5/64 loss: 0.35896235704421997
Batch 6/64 loss: 0.3543909192085266
Batch 7/64 loss: 0.3574777841567993
Batch 8/64 loss: 0.3600785732269287
Batch 9/64 loss: 0.3535078763961792
Batch 10/64 loss: 0.35773617029190063
Batch 11/64 loss: 0.35599029064178467
Batch 12/64 loss: 0.3522219657897949
Batch 13/64 loss: 0.35669803619384766
Batch 14/64 loss: 0.3580183982849121
Batch 15/64 loss: 0.35536569356918335
Batch 16/64 loss: 0.3618483543395996
Batch 17/64 loss: 0.35431140661239624
Batch 18/64 loss: 0.35878145694732666
Batch 19/64 loss: 0.3562058210372925
Batch 20/64 loss: 0.3574022054672241
Batch 21/64 loss: 0.3536580204963684
Batch 22/64 loss: 0.35468703508377075
Batch 23/64 loss: 0.3568962812423706
Batch 24/64 loss: 0.35877054929733276
Batch 25/64 loss: 0.3565877676010132
Batch 26/64 loss: 0.35469961166381836
Batch 27/64 loss: 0.3571430444717407
Batch 28/64 loss: 0.3526376485824585
Batch 29/64 loss: 0.3540905714035034
Batch 30/64 loss: 0.3549250364303589
Batch 31/64 loss: 0.35502195358276367
Batch 32/64 loss: 0.3590301275253296
Batch 33/64 loss: 0.35378772020339966
Batch 34/64 loss: 0.35429346561431885
Batch 35/64 loss: 0.35582393407821655
Batch 36/64 loss: 0.35601091384887695
Batch 37/64 loss: 0.34965288639068604
Batch 38/64 loss: 0.35456883907318115
Batch 39/64 loss: 0.35412001609802246
Batch 40/64 loss: 0.3557940721511841
Batch 41/64 loss: 0.35580873489379883
Batch 42/64 loss: 0.35401302576065063
Batch 43/64 loss: 0.3583526611328125
Batch 44/64 loss: 0.35940873622894287
Batch 45/64 loss: 0.35719799995422363
Batch 46/64 loss: 0.3553016185760498
Batch 47/64 loss: 0.3531075716018677
Batch 48/64 loss: 0.35686492919921875
Batch 49/64 loss: 0.35189592838287354
Batch 50/64 loss: 0.3571457862854004
Batch 51/64 loss: 0.35057830810546875
Batch 52/64 loss: 0.3544434905052185
Batch 53/64 loss: 0.35167473554611206
Batch 54/64 loss: 0.35452497005462646
Batch 55/64 loss: 0.35578298568725586
Batch 56/64 loss: 0.35546326637268066
Batch 57/64 loss: 0.35273683071136475
Batch 58/64 loss: 0.3539143204689026
Batch 59/64 loss: 0.35319197177886963
Batch 60/64 loss: 0.35687869787216187
Batch 61/64 loss: 0.350319504737854
Batch 62/64 loss: 0.3530569076538086
Batch 63/64 loss: 0.350533127784729
Batch 64/64 loss: 0.34685105085372925
Epoch 8  Train loss: 0.35521273729847924  Val loss: 0.3554190647151462
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 0.3515593409538269
Batch 2/64 loss: 0.35511136054992676
Batch 3/64 loss: 0.34974491596221924
Batch 4/64 loss: 0.35156357288360596
Batch 5/64 loss: 0.35402363538742065
Batch 6/64 loss: 0.35408419370651245
Batch 7/64 loss: 0.3493044376373291
Batch 8/64 loss: 0.35450541973114014
Batch 9/64 loss: 0.35120683908462524
Batch 10/64 loss: 0.35585302114486694
Batch 11/64 loss: 0.35127556324005127
Batch 12/64 loss: 0.3496600389480591
Batch 13/64 loss: 0.35341089963912964
Batch 14/64 loss: 0.3560904264450073
Batch 15/64 loss: 0.35487842559814453
Batch 16/64 loss: 0.35219717025756836
Batch 17/64 loss: 0.3525369167327881
Batch 18/64 loss: 0.3538309335708618
Batch 19/64 loss: 0.3545829653739929
Batch 20/64 loss: 0.35710740089416504
Batch 21/64 loss: 0.35674232244491577
Batch 22/64 loss: 0.35432684421539307
Batch 23/64 loss: 0.3512417674064636
Batch 24/64 loss: 0.3539011478424072
Batch 25/64 loss: 0.35508275032043457
Batch 26/64 loss: 0.3534409999847412
Batch 27/64 loss: 0.3518507480621338
Batch 28/64 loss: 0.35871708393096924
Batch 29/64 loss: 0.3515526056289673
Batch 30/64 loss: 0.35095494985580444
Batch 31/64 loss: 0.3563424348831177
Batch 32/64 loss: 0.35436558723449707
Batch 33/64 loss: 0.3574221730232239
Batch 34/64 loss: 0.35767948627471924
Batch 35/64 loss: 0.35711467266082764
Batch 36/64 loss: 0.35201382637023926
Batch 37/64 loss: 0.35125601291656494
Batch 38/64 loss: 0.3568362593650818
Batch 39/64 loss: 0.35318535566329956
Batch 40/64 loss: 0.3522759675979614
Batch 41/64 loss: 0.3544437885284424
Batch 42/64 loss: 0.35689640045166016
Batch 43/64 loss: 0.355155348777771
Batch 44/64 loss: 0.3534162640571594
Batch 45/64 loss: 0.35159164667129517
Batch 46/64 loss: 0.35783469676971436
Batch 47/64 loss: 0.3541387915611267
Batch 48/64 loss: 0.3537115454673767
Batch 49/64 loss: 0.3580811023712158
Batch 50/64 loss: 0.3512752056121826
Batch 51/64 loss: 0.3510485887527466
Batch 52/64 loss: 0.35261327028274536
Batch 53/64 loss: 0.35531824827194214
Batch 54/64 loss: 0.35064613819122314
Batch 55/64 loss: 0.352824330329895
Batch 56/64 loss: 0.35151368379592896
Batch 57/64 loss: 0.35425055027008057
Batch 58/64 loss: 0.352911114692688
Batch 59/64 loss: 0.3519139289855957
Batch 60/64 loss: 0.3494546413421631
Batch 61/64 loss: 0.35203784704208374
Batch 62/64 loss: 0.3530008792877197
Batch 63/64 loss: 0.3521239161491394
Batch 64/64 loss: 0.3577197194099426
Epoch 9  Train loss: 0.3536207402453703  Val loss: 0.3545677397668976
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: 0.35550206899642944
Batch 2/64 loss: 0.35178518295288086
Batch 3/64 loss: 0.3547089695930481
Batch 4/64 loss: 0.35343897342681885
Batch 5/64 loss: 0.3519555330276489
Batch 6/64 loss: 0.3557950258255005
Batch 7/64 loss: 0.3509594202041626
Batch 8/64 loss: 0.3541107177734375
Batch 9/64 loss: 0.3540269136428833
Batch 10/64 loss: 0.35177671909332275
Batch 11/64 loss: 0.35922396183013916
Batch 12/64 loss: 0.35193556547164917
Batch 13/64 loss: 0.3542914390563965
Batch 14/64 loss: 0.3501312732696533
Batch 15/64 loss: 0.35311031341552734
Batch 16/64 loss: 0.35123705863952637
Batch 17/64 loss: 0.3519936203956604
Batch 18/64 loss: 0.3508366346359253
Batch 19/64 loss: 0.35157644748687744
Batch 20/64 loss: 0.3505845069885254
Batch 21/64 loss: 0.3554288148880005
Batch 22/64 loss: 0.3500899076461792
Batch 23/64 loss: 0.3554026484489441
Batch 24/64 loss: 0.35557711124420166
Batch 25/64 loss: 0.3515658974647522
Batch 26/64 loss: 0.3522080183029175
Batch 27/64 loss: 0.3565865755081177
Batch 28/64 loss: 0.35256052017211914
Batch 29/64 loss: 0.34987080097198486
Batch 30/64 loss: 0.3507491946220398
Batch 31/64 loss: 0.35095643997192383
Batch 32/64 loss: 0.3522888422012329
Batch 33/64 loss: 0.35147207975387573
Batch 34/64 loss: 0.3512709140777588
Batch 35/64 loss: 0.3553314208984375
Batch 36/64 loss: 0.35117244720458984
Batch 37/64 loss: 0.35332489013671875
Batch 38/64 loss: 0.35590124130249023
Batch 39/64 loss: 0.3527523875236511
Batch 40/64 loss: 0.3549036979675293
Batch 41/64 loss: 0.3539239168167114
Batch 42/64 loss: 0.3526982069015503
Batch 43/64 loss: 0.34948694705963135
Batch 44/64 loss: 0.3545339107513428
Batch 45/64 loss: 0.35120463371276855
Batch 46/64 loss: 0.3513275384902954
Batch 47/64 loss: 0.3490704298019409
Batch 48/64 loss: 0.35384154319763184
Batch 49/64 loss: 0.35521066188812256
Batch 50/64 loss: 0.3529130220413208
Batch 51/64 loss: 0.3495457172393799
Batch 52/64 loss: 0.3515152335166931
Batch 53/64 loss: 0.3538944721221924
Batch 54/64 loss: 0.34941595792770386
Batch 55/64 loss: 0.35164159536361694
Batch 56/64 loss: 0.34948503971099854
Batch 57/64 loss: 0.34715867042541504
Batch 58/64 loss: 0.3476187586784363
Batch 59/64 loss: 0.3492540121078491
Batch 60/64 loss: 0.35746335983276367
Batch 61/64 loss: 0.35072654485702515
Batch 62/64 loss: 0.34916526079177856
Batch 63/64 loss: 0.34796154499053955
Batch 64/64 loss: 0.34850913286209106
Epoch 10  Train loss: 0.35229541998283537  Val loss: 0.3533356775532883
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: 0.3492799997329712
Batch 2/64 loss: 0.35514581203460693
Batch 3/64 loss: 0.35260164737701416
Batch 4/64 loss: 0.35118967294692993
Batch 5/64 loss: 0.35340237617492676
Batch 6/64 loss: 0.3530825972557068
Batch 7/64 loss: 0.35365450382232666
Batch 8/64 loss: 0.3543403744697571
Batch 9/64 loss: 0.3504505157470703
Batch 10/64 loss: 0.35151368379592896
Batch 11/64 loss: 0.35579198598861694
Batch 12/64 loss: 0.35083693265914917
Batch 13/64 loss: 0.3483976125717163
Batch 14/64 loss: 0.3520684242248535
Batch 15/64 loss: 0.3557129502296448
Batch 16/64 loss: 0.3500215411186218
Batch 17/64 loss: 0.349032461643219
Batch 18/64 loss: 0.35465288162231445
Batch 19/64 loss: 0.34855639934539795
Batch 20/64 loss: 0.35079771280288696
Batch 21/64 loss: 0.35164326429367065
Batch 22/64 loss: 0.35152125358581543
Batch 23/64 loss: 0.34876251220703125
Batch 24/64 loss: 0.3518807888031006
Batch 25/64 loss: 0.3537675142288208
Batch 26/64 loss: 0.35098326206207275
Batch 27/64 loss: 0.3500016927719116
Batch 28/64 loss: 0.3469465970993042
Batch 29/64 loss: 0.3513776659965515
Batch 30/64 loss: 0.3474782705307007
Batch 31/64 loss: 0.35170668363571167
Batch 32/64 loss: 0.35042208433151245
Batch 33/64 loss: 0.34912562370300293
Batch 34/64 loss: 0.34571099281311035
Batch 35/64 loss: 0.3521236181259155
Batch 36/64 loss: 0.3480045795440674
Batch 37/64 loss: 0.34733474254608154
Batch 38/64 loss: 0.3496931791305542
Batch 39/64 loss: 0.349859356880188
Batch 40/64 loss: 0.34867918491363525
Batch 41/64 loss: 0.3486011028289795
Batch 42/64 loss: 0.34655308723449707
Batch 43/64 loss: 0.35237205028533936
Batch 44/64 loss: 0.3522888422012329
Batch 45/64 loss: 0.34927546977996826
Batch 46/64 loss: 0.3564484715461731
Batch 47/64 loss: 0.3469197750091553
Batch 48/64 loss: 0.3543546199798584
Batch 49/64 loss: 0.3485969305038452
Batch 50/64 loss: 0.35072827339172363
Batch 51/64 loss: 0.35414397716522217
Batch 52/64 loss: 0.3485245108604431
Batch 53/64 loss: 0.35062479972839355
Batch 54/64 loss: 0.35380327701568604
Batch 55/64 loss: 0.34827351570129395
Batch 56/64 loss: 0.3507425785064697
Batch 57/64 loss: 0.349889874458313
Batch 58/64 loss: 0.3533480167388916
Batch 59/64 loss: 0.353983998298645
Batch 60/64 loss: 0.3525059223175049
Batch 61/64 loss: 0.3567054271697998
Batch 62/64 loss: 0.35007739067077637
Batch 63/64 loss: 0.3492870330810547
Batch 64/64 loss: 0.3515512943267822
Epoch 11  Train loss: 0.3510472998899572  Val loss: 0.3541921950697489
Epoch 12
-------------------------------
Batch 1/64 loss: 0.35069864988327026
Batch 2/64 loss: 0.3482191562652588
Batch 3/64 loss: 0.35131406784057617
Batch 4/64 loss: 0.35173672437667847
Batch 5/64 loss: 0.34676313400268555
Batch 6/64 loss: 0.3475182056427002
Batch 7/64 loss: 0.35102570056915283
Batch 8/64 loss: 0.3511441946029663
Batch 9/64 loss: 0.35224008560180664
Batch 10/64 loss: 0.3509751558303833
Batch 11/64 loss: 0.35076725482940674
Batch 12/64 loss: 0.350838303565979
Batch 13/64 loss: 0.34320926666259766
Batch 14/64 loss: 0.34903210401535034
Batch 15/64 loss: 0.35180139541625977
Batch 16/64 loss: 0.34895992279052734
Batch 17/64 loss: 0.3532388210296631
Batch 18/64 loss: 0.3500021696090698
Batch 19/64 loss: 0.34479135274887085
Batch 20/64 loss: 0.34807777404785156
Batch 21/64 loss: 0.34806811809539795
Batch 22/64 loss: 0.3507871627807617
Batch 23/64 loss: 0.34979647397994995
Batch 24/64 loss: 0.3452281951904297
Batch 25/64 loss: 0.3549399971961975
Batch 26/64 loss: 0.35072803497314453
Batch 27/64 loss: 0.34583139419555664
Batch 28/64 loss: 0.34890806674957275
Batch 29/64 loss: 0.3457556366920471
Batch 30/64 loss: 0.34388983249664307
Batch 31/64 loss: 0.35073351860046387
Batch 32/64 loss: 0.35059845447540283
Batch 33/64 loss: 0.35104382038116455
Batch 34/64 loss: 0.34736478328704834
Batch 35/64 loss: 0.35208940505981445
Batch 36/64 loss: 0.34718626737594604
Batch 37/64 loss: 0.34817367792129517
Batch 38/64 loss: 0.3464212417602539
Batch 39/64 loss: 0.35163724422454834
Batch 40/64 loss: 0.3536139726638794
Batch 41/64 loss: 0.34880661964416504
Batch 42/64 loss: 0.34406232833862305
Batch 43/64 loss: 0.34661245346069336
Batch 44/64 loss: 0.35023677349090576
Batch 45/64 loss: 0.35092127323150635
Batch 46/64 loss: 0.35074663162231445
Batch 47/64 loss: 0.35267651081085205
Batch 48/64 loss: 0.35212457180023193
Batch 49/64 loss: 0.35033828020095825
Batch 50/64 loss: 0.34952276945114136
Batch 51/64 loss: 0.35366952419281006
Batch 52/64 loss: 0.35070890188217163
Batch 53/64 loss: 0.3503739833831787
Batch 54/64 loss: 0.3519017696380615
Batch 55/64 loss: 0.3558844327926636
Batch 56/64 loss: 0.3505539298057556
Batch 57/64 loss: 0.3459286093711853
Batch 58/64 loss: 0.34839773178100586
Batch 59/64 loss: 0.35267412662506104
Batch 60/64 loss: 0.34879881143569946
Batch 61/64 loss: 0.3523670434951782
Batch 62/64 loss: 0.350344181060791
Batch 63/64 loss: 0.3518971800804138
Batch 64/64 loss: 0.3496931195259094
Epoch 12  Train loss: 0.3497563453281627  Val loss: 0.3525507314917968
Saving best model, epoch: 12
Epoch 13
-------------------------------
Batch 1/64 loss: 0.3451281785964966
Batch 2/64 loss: 0.3498625159263611
Batch 3/64 loss: 0.3517029285430908
Batch 4/64 loss: 0.3500794768333435
Batch 5/64 loss: 0.35129475593566895
Batch 6/64 loss: 0.3538384437561035
Batch 7/64 loss: 0.34656643867492676
Batch 8/64 loss: 0.3508206605911255
Batch 9/64 loss: 0.353202223777771
Batch 10/64 loss: 0.34699034690856934
Batch 11/64 loss: 0.3496028780937195
Batch 12/64 loss: 0.3520656228065491
Batch 13/64 loss: 0.3537740707397461
Batch 14/64 loss: 0.3499053716659546
Batch 15/64 loss: 0.3517966866493225
Batch 16/64 loss: 0.3525088429450989
Batch 17/64 loss: 0.3454440236091614
Batch 18/64 loss: 0.348904550075531
Batch 19/64 loss: 0.34775328636169434
Batch 20/64 loss: 0.35213416814804077
Batch 21/64 loss: 0.3516958951950073
Batch 22/64 loss: 0.34837669134140015
Batch 23/64 loss: 0.34447377920150757
Batch 24/64 loss: 0.34399354457855225
Batch 25/64 loss: 0.34421491622924805
Batch 26/64 loss: 0.3510821461677551
Batch 27/64 loss: 0.3492775559425354
Batch 28/64 loss: 0.3434501886367798
Batch 29/64 loss: 0.34576040506362915
Batch 30/64 loss: 0.3454996347427368
Batch 31/64 loss: 0.34747374057769775
Batch 32/64 loss: 0.35472893714904785
Batch 33/64 loss: 0.34855401515960693
Batch 34/64 loss: 0.3471028804779053
Batch 35/64 loss: 0.35156792402267456
Batch 36/64 loss: 0.3494839668273926
Batch 37/64 loss: 0.3521450161933899
Batch 38/64 loss: 0.34802156686782837
Batch 39/64 loss: 0.35119545459747314
Batch 40/64 loss: 0.34755825996398926
Batch 41/64 loss: 0.3489137887954712
Batch 42/64 loss: 0.34766513109207153
Batch 43/64 loss: 0.3446460962295532
Batch 44/64 loss: 0.34692084789276123
Batch 45/64 loss: 0.3489950895309448
Batch 46/64 loss: 0.3489280343055725
Batch 47/64 loss: 0.3471705913543701
Batch 48/64 loss: 0.35090434551239014
Batch 49/64 loss: 0.3506247401237488
Batch 50/64 loss: 0.3500540256500244
Batch 51/64 loss: 0.3463493585586548
Batch 52/64 loss: 0.35245710611343384
Batch 53/64 loss: 0.3491235375404358
Batch 54/64 loss: 0.35309070348739624
Batch 55/64 loss: 0.3466460704803467
Batch 56/64 loss: 0.3476661443710327
Batch 57/64 loss: 0.3521672487258911
Batch 58/64 loss: 0.34803545475006104
Batch 59/64 loss: 0.35049116611480713
Batch 60/64 loss: 0.3463491201400757
Batch 61/64 loss: 0.3449368476867676
Batch 62/64 loss: 0.34520649909973145
Batch 63/64 loss: 0.351692259311676
Batch 64/64 loss: 0.3478912115097046
Epoch 13  Train loss: 0.34900368007959104  Val loss: 0.3499733312023464
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: 0.34486329555511475
Batch 2/64 loss: 0.3492957353591919
Batch 3/64 loss: 0.34473705291748047
Batch 4/64 loss: 0.34661930799484253
Batch 5/64 loss: 0.3500070571899414
Batch 6/64 loss: 0.34677767753601074
Batch 7/64 loss: 0.35107630491256714
Batch 8/64 loss: 0.3424069881439209
Batch 9/64 loss: 0.34876883029937744
Batch 10/64 loss: 0.34577488899230957
Batch 11/64 loss: 0.34949731826782227
Batch 12/64 loss: 0.34773504734039307
Batch 13/64 loss: 0.3514241576194763
Batch 14/64 loss: 0.3471220135688782
Batch 15/64 loss: 0.3445897102355957
Batch 16/64 loss: 0.34344834089279175
Batch 17/64 loss: 0.3473532199859619
Batch 18/64 loss: 0.34650421142578125
Batch 19/64 loss: 0.34524232149124146
Batch 20/64 loss: 0.3459134101867676
Batch 21/64 loss: 0.34452277421951294
Batch 22/64 loss: 0.3498152494430542
Batch 23/64 loss: 0.3461778163909912
Batch 24/64 loss: 0.3460478186607361
Batch 25/64 loss: 0.3464972972869873
Batch 26/64 loss: 0.3476141095161438
Batch 27/64 loss: 0.3456730842590332
Batch 28/64 loss: 0.346244215965271
Batch 29/64 loss: 0.34739428758621216
Batch 30/64 loss: 0.34636807441711426
Batch 31/64 loss: 0.34554970264434814
Batch 32/64 loss: 0.35467493534088135
Batch 33/64 loss: 0.35089683532714844
Batch 34/64 loss: 0.34819281101226807
Batch 35/64 loss: 0.3467719554901123
Batch 36/64 loss: 0.35559624433517456
Batch 37/64 loss: 0.3436751365661621
Batch 38/64 loss: 0.3427923917770386
Batch 39/64 loss: 0.3515157103538513
Batch 40/64 loss: 0.34570205211639404
Batch 41/64 loss: 0.3520700931549072
Batch 42/64 loss: 0.3464151620864868
Batch 43/64 loss: 0.3475562334060669
Batch 44/64 loss: 0.34874826669692993
Batch 45/64 loss: 0.3451192378997803
Batch 46/64 loss: 0.3491044044494629
Batch 47/64 loss: 0.3473823070526123
Batch 48/64 loss: 0.3420809507369995
Batch 49/64 loss: 0.35020655393600464
Batch 50/64 loss: 0.3461152911186218
Batch 51/64 loss: 0.3373245596885681
Batch 52/64 loss: 0.3463917374610901
Batch 53/64 loss: 0.34831106662750244
Batch 54/64 loss: 0.34884899854660034
Batch 55/64 loss: 0.3522947430610657
Batch 56/64 loss: 0.34320151805877686
Batch 57/64 loss: 0.34820806980133057
Batch 58/64 loss: 0.34480494260787964
Batch 59/64 loss: 0.34547269344329834
Batch 60/64 loss: 0.34885090589523315
Batch 61/64 loss: 0.3497315049171448
Batch 62/64 loss: 0.3473883867263794
Batch 63/64 loss: 0.3492085933685303
Batch 64/64 loss: 0.3438371419906616
Epoch 14  Train loss: 0.34719362305659873  Val loss: 0.3497210183913765
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: 0.3508164882659912
Batch 2/64 loss: 0.3453959822654724
Batch 3/64 loss: 0.34835994243621826
Batch 4/64 loss: 0.3482035994529724
Batch 5/64 loss: 0.3517115116119385
Batch 6/64 loss: 0.3436020016670227
Batch 7/64 loss: 0.3437879681587219
Batch 8/64 loss: 0.34651947021484375
Batch 9/64 loss: 0.3443107008934021
Batch 10/64 loss: 0.3518298268318176
Batch 11/64 loss: 0.34434008598327637
Batch 12/64 loss: 0.35031890869140625
Batch 13/64 loss: 0.3454344868659973
Batch 14/64 loss: 0.3453660011291504
Batch 15/64 loss: 0.345913827419281
Batch 16/64 loss: 0.3477950692176819
Batch 17/64 loss: 0.3454068899154663
Batch 18/64 loss: 0.345788836479187
Batch 19/64 loss: 0.34676891565322876
Batch 20/64 loss: 0.3448694944381714
Batch 21/64 loss: 0.34404098987579346
Batch 22/64 loss: 0.35109055042266846
Batch 23/64 loss: 0.35146594047546387
Batch 24/64 loss: 0.3405865430831909
Batch 25/64 loss: 0.35149675607681274
Batch 26/64 loss: 0.341153085231781
Batch 27/64 loss: 0.3499372601509094
Batch 28/64 loss: 0.34863781929016113
Batch 29/64 loss: 0.34759092330932617
Batch 30/64 loss: 0.34850531816482544
Batch 31/64 loss: 0.34619641304016113
Batch 32/64 loss: 0.3457173705101013
Batch 33/64 loss: 0.34809595346450806
Batch 34/64 loss: 0.3472592830657959
Batch 35/64 loss: 0.344341516494751
Batch 36/64 loss: 0.3459171652793884
Batch 37/64 loss: 0.35248351097106934
Batch 38/64 loss: 0.3445514440536499
Batch 39/64 loss: 0.3486446142196655
Batch 40/64 loss: 0.344843327999115
Batch 41/64 loss: 0.34608960151672363
Batch 42/64 loss: 0.3504791259765625
Batch 43/64 loss: 0.34271240234375
Batch 44/64 loss: 0.3477190136909485
Batch 45/64 loss: 0.34360015392303467
Batch 46/64 loss: 0.3496890664100647
Batch 47/64 loss: 0.3442857265472412
Batch 48/64 loss: 0.3484933376312256
Batch 49/64 loss: 0.34735965728759766
Batch 50/64 loss: 0.3495286703109741
Batch 51/64 loss: 0.3502389192581177
Batch 52/64 loss: 0.3472236394882202
Batch 53/64 loss: 0.3457997441291809
Batch 54/64 loss: 0.3479219675064087
Batch 55/64 loss: 0.34681272506713867
Batch 56/64 loss: 0.3435741066932678
Batch 57/64 loss: 0.34918320178985596
Batch 58/64 loss: 0.3473333716392517
Batch 59/64 loss: 0.3463398218154907
Batch 60/64 loss: 0.3444991111755371
Batch 61/64 loss: 0.3487844467163086
Batch 62/64 loss: 0.34321391582489014
Batch 63/64 loss: 0.3480232357978821
Batch 64/64 loss: 0.34701287746429443
Epoch 15  Train loss: 0.3469531045240514  Val loss: 0.3492576957158616
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: 0.3456119894981384
Batch 2/64 loss: 0.34919267892837524
Batch 3/64 loss: 0.35112810134887695
Batch 4/64 loss: 0.34523487091064453
Batch 5/64 loss: 0.34821784496307373
Batch 6/64 loss: 0.34323716163635254
Batch 7/64 loss: 0.3475622534751892
Batch 8/64 loss: 0.3477746844291687
Batch 9/64 loss: 0.3472663164138794
Batch 10/64 loss: 0.34672147035598755
Batch 11/64 loss: 0.35122716426849365
Batch 12/64 loss: 0.35105347633361816
Batch 13/64 loss: 0.3469046354293823
Batch 14/64 loss: 0.3424229025840759
Batch 15/64 loss: 0.34369099140167236
Batch 16/64 loss: 0.34323650598526
Batch 17/64 loss: 0.34441375732421875
Batch 18/64 loss: 0.3463042378425598
Batch 19/64 loss: 0.3437398672103882
Batch 20/64 loss: 0.3461253046989441
Batch 21/64 loss: 0.3404611349105835
Batch 22/64 loss: 0.3430967330932617
Batch 23/64 loss: 0.34509509801864624
Batch 24/64 loss: 0.3451578617095947
Batch 25/64 loss: 0.34949368238449097
Batch 26/64 loss: 0.34127330780029297
Batch 27/64 loss: 0.3482588529586792
Batch 28/64 loss: 0.34384775161743164
Batch 29/64 loss: 0.3492366671562195
Batch 30/64 loss: 0.3446842432022095
Batch 31/64 loss: 0.34492027759552
Batch 32/64 loss: 0.34562838077545166
Batch 33/64 loss: 0.34884244203567505
Batch 34/64 loss: 0.34998565912246704
Batch 35/64 loss: 0.3464158773422241
Batch 36/64 loss: 0.34856146574020386
Batch 37/64 loss: 0.34473133087158203
Batch 38/64 loss: 0.3476908206939697
Batch 39/64 loss: 0.34787535667419434
Batch 40/64 loss: 0.3482024669647217
Batch 41/64 loss: 0.34589284658432007
Batch 42/64 loss: 0.3451085686683655
Batch 43/64 loss: 0.3438270092010498
Batch 44/64 loss: 0.3457908630371094
Batch 45/64 loss: 0.3465960621833801
Batch 46/64 loss: 0.3402996063232422
Batch 47/64 loss: 0.3509441614151001
Batch 48/64 loss: 0.34599220752716064
Batch 49/64 loss: 0.34609782695770264
Batch 50/64 loss: 0.34570395946502686
Batch 51/64 loss: 0.34586524963378906
Batch 52/64 loss: 0.3422219157218933
Batch 53/64 loss: 0.34452110528945923
Batch 54/64 loss: 0.35039758682250977
Batch 55/64 loss: 0.34201598167419434
Batch 56/64 loss: 0.3395266532897949
Batch 57/64 loss: 0.3490266799926758
Batch 58/64 loss: 0.34530961513519287
Batch 59/64 loss: 0.35058116912841797
Batch 60/64 loss: 0.34939438104629517
Batch 61/64 loss: 0.3406117558479309
Batch 62/64 loss: 0.3452261686325073
Batch 63/64 loss: 0.33987200260162354
Batch 64/64 loss: 0.34931468963623047
Epoch 16  Train loss: 0.3459974120644962  Val loss: 0.3483471282568994
Saving best model, epoch: 16
Epoch 17
-------------------------------
Batch 1/64 loss: 0.3468121290206909
Batch 2/64 loss: 0.34385013580322266
Batch 3/64 loss: 0.34752941131591797
Batch 4/64 loss: 0.34643566608428955
Batch 5/64 loss: 0.345394492149353
Batch 6/64 loss: 0.3456542491912842
Batch 7/64 loss: 0.34189367294311523
Batch 8/64 loss: 0.34435510635375977
Batch 9/64 loss: 0.34736931324005127
Batch 10/64 loss: 0.3428325057029724
Batch 11/64 loss: 0.3457486033439636
Batch 12/64 loss: 0.34527575969696045
Batch 13/64 loss: 0.345874547958374
Batch 14/64 loss: 0.35040485858917236
Batch 15/64 loss: 0.3474101424217224
Batch 16/64 loss: 0.34455323219299316
Batch 17/64 loss: 0.34725451469421387
Batch 18/64 loss: 0.3438819646835327
Batch 19/64 loss: 0.3433094620704651
Batch 20/64 loss: 0.3462061285972595
Batch 21/64 loss: 0.34586989879608154
Batch 22/64 loss: 0.3432401418685913
Batch 23/64 loss: 0.3443226218223572
Batch 24/64 loss: 0.3433265686035156
Batch 25/64 loss: 0.3436068296432495
Batch 26/64 loss: 0.3448876738548279
Batch 27/64 loss: 0.345234215259552
Batch 28/64 loss: 0.34338849782943726
Batch 29/64 loss: 0.34784191846847534
Batch 30/64 loss: 0.34175801277160645
Batch 31/64 loss: 0.3455442190170288
Batch 32/64 loss: 0.34317028522491455
Batch 33/64 loss: 0.3401910662651062
Batch 34/64 loss: 0.3421517014503479
Batch 35/64 loss: 0.3419386148452759
Batch 36/64 loss: 0.34535300731658936
Batch 37/64 loss: 0.34774208068847656
Batch 38/64 loss: 0.343964159488678
Batch 39/64 loss: 0.3437870740890503
Batch 40/64 loss: 0.34379732608795166
Batch 41/64 loss: 0.34594249725341797
Batch 42/64 loss: 0.34161823987960815
Batch 43/64 loss: 0.34084367752075195
Batch 44/64 loss: 0.3454406261444092
Batch 45/64 loss: 0.34147703647613525
Batch 46/64 loss: 0.3452644348144531
Batch 47/64 loss: 0.34585243463516235
Batch 48/64 loss: 0.348923921585083
Batch 49/64 loss: 0.3479928970336914
Batch 50/64 loss: 0.34495824575424194
Batch 51/64 loss: 0.3442338705062866
Batch 52/64 loss: 0.3442099690437317
Batch 53/64 loss: 0.3469465970993042
Batch 54/64 loss: 0.34244823455810547
Batch 55/64 loss: 0.3494250774383545
Batch 56/64 loss: 0.34841668605804443
Batch 57/64 loss: 0.34702563285827637
Batch 58/64 loss: 0.3455345630645752
Batch 59/64 loss: 0.34575986862182617
Batch 60/64 loss: 0.34573888778686523
Batch 61/64 loss: 0.34486109018325806
Batch 62/64 loss: 0.34696102142333984
Batch 63/64 loss: 0.3415334224700928
Batch 64/64 loss: 0.3503227233886719
Epoch 17  Train loss: 0.3450558868109011  Val loss: 0.3472310308738263
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: 0.3489961624145508
Batch 2/64 loss: 0.3412330746650696
Batch 3/64 loss: 0.3438029885292053
Batch 4/64 loss: 0.3447859287261963
Batch 5/64 loss: 0.34560829401016235
Batch 6/64 loss: 0.340049684047699
Batch 7/64 loss: 0.3493632674217224
Batch 8/64 loss: 0.3436119556427002
Batch 9/64 loss: 0.3459976315498352
Batch 10/64 loss: 0.34190261363983154
Batch 11/64 loss: 0.3476688861846924
Batch 12/64 loss: 0.3394065499305725
Batch 13/64 loss: 0.34262704849243164
Batch 14/64 loss: 0.34234946966171265
Batch 15/64 loss: 0.34309089183807373
Batch 16/64 loss: 0.3433745503425598
Batch 17/64 loss: 0.347726047039032
Batch 18/64 loss: 0.34255802631378174
Batch 19/64 loss: 0.3418238162994385
Batch 20/64 loss: 0.34321755170822144
Batch 21/64 loss: 0.3442142605781555
Batch 22/64 loss: 0.34255027770996094
Batch 23/64 loss: 0.34339356422424316
Batch 24/64 loss: 0.34242212772369385
Batch 25/64 loss: 0.3449212312698364
Batch 26/64 loss: 0.3444279432296753
Batch 27/64 loss: 0.34570103883743286
Batch 28/64 loss: 0.34339970350265503
Batch 29/64 loss: 0.34793466329574585
Batch 30/64 loss: 0.3443264961242676
Batch 31/64 loss: 0.34415125846862793
Batch 32/64 loss: 0.3458528518676758
Batch 33/64 loss: 0.3471842408180237
Batch 34/64 loss: 0.3436252474784851
Batch 35/64 loss: 0.3422079086303711
Batch 36/64 loss: 0.34358149766921997
Batch 37/64 loss: 0.3443754315376282
Batch 38/64 loss: 0.3410242199897766
Batch 39/64 loss: 0.35047197341918945
Batch 40/64 loss: 0.3432886600494385
Batch 41/64 loss: 0.35184597969055176
Batch 42/64 loss: 0.3450065851211548
Batch 43/64 loss: 0.34143877029418945
Batch 44/64 loss: 0.3433281183242798
Batch 45/64 loss: 0.3400265574455261
Batch 46/64 loss: 0.33697402477264404
Batch 47/64 loss: 0.34678012132644653
Batch 48/64 loss: 0.3475905656814575
Batch 49/64 loss: 0.3420352339744568
Batch 50/64 loss: 0.33745622634887695
Batch 51/64 loss: 0.34354352951049805
Batch 52/64 loss: 0.3409256935119629
Batch 53/64 loss: 0.34135007858276367
Batch 54/64 loss: 0.3481241464614868
Batch 55/64 loss: 0.34314894676208496
Batch 56/64 loss: 0.34409451484680176
Batch 57/64 loss: 0.343677818775177
Batch 58/64 loss: 0.33925843238830566
Batch 59/64 loss: 0.342490017414093
Batch 60/64 loss: 0.3441060781478882
Batch 61/64 loss: 0.34780633449554443
Batch 62/64 loss: 0.34759706258773804
Batch 63/64 loss: 0.3418593406677246
Batch 64/64 loss: 0.33872801065444946
Epoch 18  Train loss: 0.34388641913731893  Val loss: 0.3472189362516108
Saving best model, epoch: 18
Epoch 19
-------------------------------
Batch 1/64 loss: 0.3433394432067871
Batch 2/64 loss: 0.34634268283843994
Batch 3/64 loss: 0.34310710430145264
Batch 4/64 loss: 0.3423005938529968
Batch 5/64 loss: 0.34530413150787354
Batch 6/64 loss: 0.34619396924972534
Batch 7/64 loss: 0.34435737133026123
Batch 8/64 loss: 0.3386765718460083
Batch 9/64 loss: 0.33665645122528076
Batch 10/64 loss: 0.3441990613937378
Batch 11/64 loss: 0.346782922744751
Batch 12/64 loss: 0.3434077501296997
Batch 13/64 loss: 0.3432541489601135
Batch 14/64 loss: 0.34459519386291504
Batch 15/64 loss: 0.3443130850791931
Batch 16/64 loss: 0.34712648391723633
Batch 17/64 loss: 0.34589892625808716
Batch 18/64 loss: 0.3390495777130127
Batch 19/64 loss: 0.3435755968093872
Batch 20/64 loss: 0.34427589178085327
Batch 21/64 loss: 0.34125280380249023
Batch 22/64 loss: 0.3441768288612366
Batch 23/64 loss: 0.3425028324127197
Batch 24/64 loss: 0.3426307439804077
Batch 25/64 loss: 0.3424729108810425
Batch 26/64 loss: 0.34425896406173706
Batch 27/64 loss: 0.3436824083328247
Batch 28/64 loss: 0.3426446318626404
Batch 29/64 loss: 0.3429969549179077
Batch 30/64 loss: 0.344174325466156
Batch 31/64 loss: 0.3433868885040283
Batch 32/64 loss: 0.3403562307357788
Batch 33/64 loss: 0.3392324447631836
Batch 34/64 loss: 0.34523528814315796
Batch 35/64 loss: 0.34043562412261963
Batch 36/64 loss: 0.3467450737953186
Batch 37/64 loss: 0.34361839294433594
Batch 38/64 loss: 0.34389686584472656
Batch 39/64 loss: 0.3408217430114746
Batch 40/64 loss: 0.34323692321777344
Batch 41/64 loss: 0.3429381847381592
Batch 42/64 loss: 0.34302860498428345
Batch 43/64 loss: 0.34157776832580566
Batch 44/64 loss: 0.34092187881469727
Batch 45/64 loss: 0.34127354621887207
Batch 46/64 loss: 0.3470667600631714
Batch 47/64 loss: 0.3435468077659607
Batch 48/64 loss: 0.3409656286239624
Batch 49/64 loss: 0.3459031581878662
Batch 50/64 loss: 0.34404003620147705
Batch 51/64 loss: 0.3443726897239685
Batch 52/64 loss: 0.34443235397338867
Batch 53/64 loss: 0.33819037675857544
Batch 54/64 loss: 0.3442867398262024
Batch 55/64 loss: 0.3479740619659424
Batch 56/64 loss: 0.34638911485671997
Batch 57/64 loss: 0.3448183536529541
Batch 58/64 loss: 0.3431929349899292
Batch 59/64 loss: 0.3485657572746277
Batch 60/64 loss: 0.34925222396850586
Batch 61/64 loss: 0.3450448513031006
Batch 62/64 loss: 0.34337741136550903
Batch 63/64 loss: 0.3425312042236328
Batch 64/64 loss: 0.3463146686553955
Epoch 19  Train loss: 0.34359125156028597  Val loss: 0.34641207268147944
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 0.34181034564971924
Batch 2/64 loss: 0.33767038583755493
Batch 3/64 loss: 0.34535926580429077
Batch 4/64 loss: 0.34173065423965454
Batch 5/64 loss: 0.34381216764450073
Batch 6/64 loss: 0.3449252247810364
Batch 7/64 loss: 0.3431383967399597
Batch 8/64 loss: 0.34574025869369507
Batch 9/64 loss: 0.3468813896179199
Batch 10/64 loss: 0.3436993360519409
Batch 11/64 loss: 0.34029364585876465
Batch 12/64 loss: 0.3413318991661072
Batch 13/64 loss: 0.3418709635734558
Batch 14/64 loss: 0.3439587950706482
Batch 15/64 loss: 0.33812665939331055
Batch 16/64 loss: 0.3482239246368408
Batch 17/64 loss: 0.3418309688568115
Batch 18/64 loss: 0.3460501432418823
Batch 19/64 loss: 0.3417612314224243
Batch 20/64 loss: 0.34439516067504883
Batch 21/64 loss: 0.34171783924102783
Batch 22/64 loss: 0.3488370180130005
Batch 23/64 loss: 0.3441225290298462
Batch 24/64 loss: 0.34197455644607544
Batch 25/64 loss: 0.3382643461227417
Batch 26/64 loss: 0.3446599245071411
Batch 27/64 loss: 0.3451571464538574
Batch 28/64 loss: 0.34568917751312256
Batch 29/64 loss: 0.34523874521255493
Batch 30/64 loss: 0.34102070331573486
Batch 31/64 loss: 0.34383779764175415
Batch 32/64 loss: 0.3432120084762573
Batch 33/64 loss: 0.34803444147109985
Batch 34/64 loss: 0.34135329723358154
Batch 35/64 loss: 0.34045588970184326
Batch 36/64 loss: 0.34361910820007324
Batch 37/64 loss: 0.3402441143989563
Batch 38/64 loss: 0.34610557556152344
Batch 39/64 loss: 0.3439151644706726
Batch 40/64 loss: 0.342639684677124
Batch 41/64 loss: 0.3435018062591553
Batch 42/64 loss: 0.33902841806411743
Batch 43/64 loss: 0.33698761463165283
Batch 44/64 loss: 0.3413625955581665
Batch 45/64 loss: 0.3428061008453369
Batch 46/64 loss: 0.34232592582702637
Batch 47/64 loss: 0.3464476466178894
Batch 48/64 loss: 0.33999699354171753
Batch 49/64 loss: 0.340273916721344
Batch 50/64 loss: 0.3508980870246887
Batch 51/64 loss: 0.3445587754249573
Batch 52/64 loss: 0.3444250822067261
Batch 53/64 loss: 0.33728134632110596
Batch 54/64 loss: 0.34462517499923706
Batch 55/64 loss: 0.3408912420272827
Batch 56/64 loss: 0.34312164783477783
Batch 57/64 loss: 0.34046435356140137
Batch 58/64 loss: 0.3412524461746216
Batch 59/64 loss: 0.3447340726852417
Batch 60/64 loss: 0.340590238571167
Batch 61/64 loss: 0.3454885482788086
Batch 62/64 loss: 0.3381528854370117
Batch 63/64 loss: 0.34496188163757324
Batch 64/64 loss: 0.34477949142456055
Epoch 20  Train loss: 0.3429877851523605  Val loss: 0.3468197182691384
Epoch 21
-------------------------------
Batch 1/64 loss: 0.345874547958374
Batch 2/64 loss: 0.34495794773101807
Batch 3/64 loss: 0.343578577041626
Batch 4/64 loss: 0.34339457750320435
Batch 5/64 loss: 0.34358465671539307
Batch 6/64 loss: 0.3415820598602295
Batch 7/64 loss: 0.34157437086105347
Batch 8/64 loss: 0.3381405472755432
Batch 9/64 loss: 0.34489524364471436
Batch 10/64 loss: 0.34642893075942993
Batch 11/64 loss: 0.3406022787094116
Batch 12/64 loss: 0.33797645568847656
Batch 13/64 loss: 0.3431025743484497
Batch 14/64 loss: 0.34134143590927124
Batch 15/64 loss: 0.3394109010696411
Batch 16/64 loss: 0.33368486166000366
Batch 17/64 loss: 0.3427048921585083
Batch 18/64 loss: 0.3419731855392456
Batch 19/64 loss: 0.3381485939025879
Batch 20/64 loss: 0.3410496115684509
Batch 21/64 loss: 0.3419051766395569
Batch 22/64 loss: 0.33985984325408936
Batch 23/64 loss: 0.3407766819000244
Batch 24/64 loss: 0.33940863609313965
Batch 25/64 loss: 0.3354649543762207
Batch 26/64 loss: 0.3395240306854248
Batch 27/64 loss: 0.34104490280151367
Batch 28/64 loss: 0.34042859077453613
Batch 29/64 loss: 0.34545278549194336
Batch 30/64 loss: 0.3474041223526001
Batch 31/64 loss: 0.34410107135772705
Batch 32/64 loss: 0.337571918964386
Batch 33/64 loss: 0.33946889638900757
Batch 34/64 loss: 0.34447622299194336
Batch 35/64 loss: 0.3398524522781372
Batch 36/64 loss: 0.3437917232513428
Batch 37/64 loss: 0.3400833010673523
Batch 38/64 loss: 0.345858633518219
Batch 39/64 loss: 0.3353574275970459
Batch 40/64 loss: 0.34470856189727783
Batch 41/64 loss: 0.3386595845222473
Batch 42/64 loss: 0.33847618103027344
Batch 43/64 loss: 0.33904409408569336
Batch 44/64 loss: 0.33664828538894653
Batch 45/64 loss: 0.34664809703826904
Batch 46/64 loss: 0.34276533126831055
Batch 47/64 loss: 0.34030044078826904
Batch 48/64 loss: 0.3458477854728699
Batch 49/64 loss: 0.3419067859649658
Batch 50/64 loss: 0.342431902885437
Batch 51/64 loss: 0.3402310609817505
Batch 52/64 loss: 0.3400214910507202
Batch 53/64 loss: 0.3405801057815552
Batch 54/64 loss: 0.34769272804260254
Batch 55/64 loss: 0.34133005142211914
Batch 56/64 loss: 0.3378310203552246
Batch 57/64 loss: 0.3429003953933716
Batch 58/64 loss: 0.3417055606842041
Batch 59/64 loss: 0.34325945377349854
Batch 60/64 loss: 0.3407360315322876
Batch 61/64 loss: 0.34194469451904297
Batch 62/64 loss: 0.34881049394607544
Batch 63/64 loss: 0.3430293798446655
Batch 64/64 loss: 0.34513169527053833
Epoch 21  Train loss: 0.34168150448331647  Val loss: 0.3451118176335731
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 0.3400993347167969
Batch 2/64 loss: 0.3376811742782593
Batch 3/64 loss: 0.3361440896987915
Batch 4/64 loss: 0.34411513805389404
Batch 5/64 loss: 0.3387451171875
Batch 6/64 loss: 0.3440709114074707
Batch 7/64 loss: 0.3409166932106018
Batch 8/64 loss: 0.34355461597442627
Batch 9/64 loss: 0.3435073494911194
Batch 10/64 loss: 0.34096670150756836
Batch 11/64 loss: 0.3426438570022583
Batch 12/64 loss: 0.3400055170059204
Batch 13/64 loss: 0.3439062833786011
Batch 14/64 loss: 0.34028011560440063
Batch 15/64 loss: 0.34141087532043457
Batch 16/64 loss: 0.33918142318725586
Batch 17/64 loss: 0.3421818017959595
Batch 18/64 loss: 0.34231966733932495
Batch 19/64 loss: 0.3376474380493164
Batch 20/64 loss: 0.33936607837677
Batch 21/64 loss: 0.34426647424697876
Batch 22/64 loss: 0.34319186210632324
Batch 23/64 loss: 0.3403934836387634
Batch 24/64 loss: 0.34472203254699707
Batch 25/64 loss: 0.3419632911682129
Batch 26/64 loss: 0.34668445587158203
Batch 27/64 loss: 0.33912813663482666
Batch 28/64 loss: 0.3414449095726013
Batch 29/64 loss: 0.33750247955322266
Batch 30/64 loss: 0.3409575819969177
Batch 31/64 loss: 0.34028178453445435
Batch 32/64 loss: 0.34319931268692017
Batch 33/64 loss: 0.3392612934112549
Batch 34/64 loss: 0.33752018213272095
Batch 35/64 loss: 0.34158873558044434
Batch 36/64 loss: 0.34268200397491455
Batch 37/64 loss: 0.34488803148269653
Batch 38/64 loss: 0.3399512767791748
Batch 39/64 loss: 0.3402903079986572
Batch 40/64 loss: 0.34254181385040283
Batch 41/64 loss: 0.34392762184143066
Batch 42/64 loss: 0.3367244005203247
Batch 43/64 loss: 0.3418252468109131
Batch 44/64 loss: 0.339130699634552
Batch 45/64 loss: 0.3411310911178589
Batch 46/64 loss: 0.3430514335632324
Batch 47/64 loss: 0.3411945104598999
Batch 48/64 loss: 0.3395235538482666
Batch 49/64 loss: 0.33868610858917236
Batch 50/64 loss: 0.34424734115600586
Batch 51/64 loss: 0.346962571144104
Batch 52/64 loss: 0.33495402336120605
Batch 53/64 loss: 0.34340977668762207
Batch 54/64 loss: 0.34558385610580444
Batch 55/64 loss: 0.33857446908950806
Batch 56/64 loss: 0.3398694396018982
Batch 57/64 loss: 0.3396812677383423
Batch 58/64 loss: 0.33878397941589355
Batch 59/64 loss: 0.3395434617996216
Batch 60/64 loss: 0.3421686887741089
Batch 61/64 loss: 0.3382822871208191
Batch 62/64 loss: 0.3397448658943176
Batch 63/64 loss: 0.344768226146698
Batch 64/64 loss: 0.34121227264404297
Epoch 22  Train loss: 0.34115892952563714  Val loss: 0.345225121966752
Epoch 23
-------------------------------
Batch 1/64 loss: 0.33838868141174316
Batch 2/64 loss: 0.34120893478393555
Batch 3/64 loss: 0.34440159797668457
Batch 4/64 loss: 0.3426138758659363
Batch 5/64 loss: 0.3431522846221924
Batch 6/64 loss: 0.3371328115463257
Batch 7/64 loss: 0.3388214111328125
Batch 8/64 loss: 0.33978450298309326
Batch 9/64 loss: 0.33700835704803467
Batch 10/64 loss: 0.3437401056289673
Batch 11/64 loss: 0.3421682119369507
Batch 12/64 loss: 0.34366822242736816
Batch 13/64 loss: 0.3486536741256714
Batch 14/64 loss: 0.3461652994155884
Batch 15/64 loss: 0.3441513776779175
Batch 16/64 loss: 0.3421744108200073
Batch 17/64 loss: 0.3361690044403076
Batch 18/64 loss: 0.335519015789032
Batch 19/64 loss: 0.3444780111312866
Batch 20/64 loss: 0.3364022970199585
Batch 21/64 loss: 0.3332661986351013
Batch 22/64 loss: 0.336489200592041
Batch 23/64 loss: 0.34030812978744507
Batch 24/64 loss: 0.342800498008728
Batch 25/64 loss: 0.34786349534988403
Batch 26/64 loss: 0.3348449468612671
Batch 27/64 loss: 0.3400561213493347
Batch 28/64 loss: 0.3447904586791992
Batch 29/64 loss: 0.34052056074142456
Batch 30/64 loss: 0.33785808086395264
Batch 31/64 loss: 0.3406994938850403
Batch 32/64 loss: 0.3387628197669983
Batch 33/64 loss: 0.3352322578430176
Batch 34/64 loss: 0.3349350690841675
Batch 35/64 loss: 0.34079086780548096
Batch 36/64 loss: 0.3430991768836975
Batch 37/64 loss: 0.33801716566085815
Batch 38/64 loss: 0.3351256251335144
Batch 39/64 loss: 0.3381856083869934
Batch 40/64 loss: 0.3380448818206787
Batch 41/64 loss: 0.3422219157218933
Batch 42/64 loss: 0.3425487279891968
Batch 43/64 loss: 0.3391186594963074
Batch 44/64 loss: 0.3425908088684082
Batch 45/64 loss: 0.33883774280548096
Batch 46/64 loss: 0.3383415937423706
Batch 47/64 loss: 0.3435978889465332
Batch 48/64 loss: 0.3346989154815674
Batch 49/64 loss: 0.33798933029174805
Batch 50/64 loss: 0.33645397424697876
Batch 51/64 loss: 0.3419605493545532
Batch 52/64 loss: 0.34100615978240967
Batch 53/64 loss: 0.33520233631134033
Batch 54/64 loss: 0.3411909341812134
Batch 55/64 loss: 0.34100615978240967
Batch 56/64 loss: 0.344043493270874
Batch 57/64 loss: 0.341762900352478
Batch 58/64 loss: 0.34187185764312744
Batch 59/64 loss: 0.3376612663269043
Batch 60/64 loss: 0.340317964553833
Batch 61/64 loss: 0.34182167053222656
Batch 62/64 loss: 0.33863353729248047
Batch 63/64 loss: 0.33618873357772827
Batch 64/64 loss: 0.34509384632110596
Epoch 23  Train loss: 0.34016282745436127  Val loss: 0.344410762139612
Saving best model, epoch: 23
Epoch 24
-------------------------------
Batch 1/64 loss: 0.3360949754714966
Batch 2/64 loss: 0.3350253105163574
Batch 3/64 loss: 0.3397817611694336
Batch 4/64 loss: 0.3340659737586975
Batch 5/64 loss: 0.33877885341644287
Batch 6/64 loss: 0.3363776206970215
Batch 7/64 loss: 0.3358497619628906
Batch 8/64 loss: 0.33737409114837646
Batch 9/64 loss: 0.3392585515975952
Batch 10/64 loss: 0.3442419767379761
Batch 11/64 loss: 0.33550941944122314
Batch 12/64 loss: 0.33856046199798584
Batch 13/64 loss: 0.3419063091278076
Batch 14/64 loss: 0.3382907509803772
Batch 15/64 loss: 0.3427544832229614
Batch 16/64 loss: 0.33559226989746094
Batch 17/64 loss: 0.3394387364387512
Batch 18/64 loss: 0.34012675285339355
Batch 19/64 loss: 0.340067982673645
Batch 20/64 loss: 0.33572423458099365
Batch 21/64 loss: 0.33309847116470337
Batch 22/64 loss: 0.33624112606048584
Batch 23/64 loss: 0.3392256498336792
Batch 24/64 loss: 0.33626389503479004
Batch 25/64 loss: 0.3319789171218872
Batch 26/64 loss: 0.3399617671966553
Batch 27/64 loss: 0.3431459665298462
Batch 28/64 loss: 0.3433854579925537
Batch 29/64 loss: 0.34125179052352905
Batch 30/64 loss: 0.3404799699783325
Batch 31/64 loss: 0.34186089038848877
Batch 32/64 loss: 0.3405505418777466
Batch 33/64 loss: 0.3392256498336792
Batch 34/64 loss: 0.33974969387054443
Batch 35/64 loss: 0.33734840154647827
Batch 36/64 loss: 0.3408748507499695
Batch 37/64 loss: 0.340675950050354
Batch 38/64 loss: 0.3369312286376953
Batch 39/64 loss: 0.34053510427474976
Batch 40/64 loss: 0.3435448408126831
Batch 41/64 loss: 0.3373279571533203
Batch 42/64 loss: 0.3381116986274719
Batch 43/64 loss: 0.348724365234375
Batch 44/64 loss: 0.3395802974700928
Batch 45/64 loss: 0.33782827854156494
Batch 46/64 loss: 0.34093040227890015
Batch 47/64 loss: 0.33890342712402344
Batch 48/64 loss: 0.343528687953949
Batch 49/64 loss: 0.33522891998291016
Batch 50/64 loss: 0.340828001499176
Batch 51/64 loss: 0.34204185009002686
Batch 52/64 loss: 0.3405104875564575
Batch 53/64 loss: 0.33772557973861694
Batch 54/64 loss: 0.33817338943481445
Batch 55/64 loss: 0.3397350311279297
Batch 56/64 loss: 0.33765190839767456
Batch 57/64 loss: 0.3413947820663452
Batch 58/64 loss: 0.3373841643333435
Batch 59/64 loss: 0.3442118167877197
Batch 60/64 loss: 0.3374212980270386
Batch 61/64 loss: 0.3418508768081665
Batch 62/64 loss: 0.3368207812309265
Batch 63/64 loss: 0.3376842737197876
Batch 64/64 loss: 0.34002459049224854
Epoch 24  Train loss: 0.3391336024976244  Val loss: 0.34300290145415213
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 0.3377106785774231
Batch 2/64 loss: 0.33640003204345703
Batch 3/64 loss: 0.339253306388855
Batch 4/64 loss: 0.33538055419921875
Batch 5/64 loss: 0.33907389640808105
Batch 6/64 loss: 0.33686721324920654
Batch 7/64 loss: 0.33783602714538574
Batch 8/64 loss: 0.33792048692703247
Batch 9/64 loss: 0.32894259691238403
Batch 10/64 loss: 0.3396334648132324
Batch 11/64 loss: 0.3409370183944702
Batch 12/64 loss: 0.34621989727020264
Batch 13/64 loss: 0.3399711847305298
Batch 14/64 loss: 0.3389331102371216
Batch 15/64 loss: 0.3371464014053345
Batch 16/64 loss: 0.3365154266357422
Batch 17/64 loss: 0.33705276250839233
Batch 18/64 loss: 0.3366714119911194
Batch 19/64 loss: 0.34164345264434814
Batch 20/64 loss: 0.33263564109802246
Batch 21/64 loss: 0.33987826108932495
Batch 22/64 loss: 0.335971474647522
Batch 23/64 loss: 0.3316376209259033
Batch 24/64 loss: 0.3406013250350952
Batch 25/64 loss: 0.33860623836517334
Batch 26/64 loss: 0.3400248885154724
Batch 27/64 loss: 0.34034717082977295
Batch 28/64 loss: 0.344057559967041
Batch 29/64 loss: 0.3360822796821594
Batch 30/64 loss: 0.34257376194000244
Batch 31/64 loss: 0.33864009380340576
Batch 32/64 loss: 0.3405205011367798
Batch 33/64 loss: 0.34110164642333984
Batch 34/64 loss: 0.3350270986557007
Batch 35/64 loss: 0.33895909786224365
Batch 36/64 loss: 0.33697402477264404
Batch 37/64 loss: 0.3383171558380127
Batch 38/64 loss: 0.3337796926498413
Batch 39/64 loss: 0.341330349445343
Batch 40/64 loss: 0.3381669521331787
Batch 41/64 loss: 0.33597028255462646
Batch 42/64 loss: 0.3447916507720947
Batch 43/64 loss: 0.33852505683898926
Batch 44/64 loss: 0.33265233039855957
Batch 45/64 loss: 0.3397846817970276
Batch 46/64 loss: 0.34066450595855713
Batch 47/64 loss: 0.3336212635040283
Batch 48/64 loss: 0.33970963954925537
Batch 49/64 loss: 0.33771324157714844
Batch 50/64 loss: 0.3377148509025574
Batch 51/64 loss: 0.34143269062042236
Batch 52/64 loss: 0.3353605270385742
Batch 53/64 loss: 0.34065598249435425
Batch 54/64 loss: 0.342823326587677
Batch 55/64 loss: 0.33891499042510986
Batch 56/64 loss: 0.34038424491882324
Batch 57/64 loss: 0.34220731258392334
Batch 58/64 loss: 0.3389413356781006
Batch 59/64 loss: 0.3403569459915161
Batch 60/64 loss: 0.3401985168457031
Batch 61/64 loss: 0.3408098816871643
Batch 62/64 loss: 0.3359227180480957
Batch 63/64 loss: 0.3409859538078308
Batch 64/64 loss: 0.3386305570602417
Epoch 25  Train loss: 0.3385640251870249  Val loss: 0.34242873667032037
Saving best model, epoch: 25
Epoch 26
-------------------------------
Batch 1/64 loss: 0.3372504711151123
Batch 2/64 loss: 0.3379822373390198
Batch 3/64 loss: 0.3405606746673584
Batch 4/64 loss: 0.3401247262954712
Batch 5/64 loss: 0.33352231979370117
Batch 6/64 loss: 0.34098780155181885
Batch 7/64 loss: 0.33696043491363525
Batch 8/64 loss: 0.33751821517944336
Batch 9/64 loss: 0.33727461099624634
Batch 10/64 loss: 0.3344036340713501
Batch 11/64 loss: 0.3387698531150818
Batch 12/64 loss: 0.342379629611969
Batch 13/64 loss: 0.3417298197746277
Batch 14/64 loss: 0.3383251428604126
Batch 15/64 loss: 0.33620530366897583
Batch 16/64 loss: 0.34010159969329834
Batch 17/64 loss: 0.3373156189918518
Batch 18/64 loss: 0.33442074060440063
Batch 19/64 loss: 0.34161317348480225
Batch 20/64 loss: 0.3356418013572693
Batch 21/64 loss: 0.33989107608795166
Batch 22/64 loss: 0.3348653316497803
Batch 23/64 loss: 0.33501696586608887
Batch 24/64 loss: 0.34361106157302856
Batch 25/64 loss: 0.3388134241104126
Batch 26/64 loss: 0.33541202545166016
Batch 27/64 loss: 0.338686466217041
Batch 28/64 loss: 0.3397960662841797
Batch 29/64 loss: 0.33628714084625244
Batch 30/64 loss: 0.33882617950439453
Batch 31/64 loss: 0.33798515796661377
Batch 32/64 loss: 0.3340357542037964
Batch 33/64 loss: 0.33625853061676025
Batch 34/64 loss: 0.3415626883506775
Batch 35/64 loss: 0.33876752853393555
Batch 36/64 loss: 0.3363412618637085
Batch 37/64 loss: 0.3350524306297302
Batch 38/64 loss: 0.3405740261077881
Batch 39/64 loss: 0.3419671058654785
Batch 40/64 loss: 0.33342212438583374
Batch 41/64 loss: 0.34071147441864014
Batch 42/64 loss: 0.3343229293823242
Batch 43/64 loss: 0.33403486013412476
Batch 44/64 loss: 0.3347259759902954
Batch 45/64 loss: 0.33603042364120483
Batch 46/64 loss: 0.33849120140075684
Batch 47/64 loss: 0.3402862548828125
Batch 48/64 loss: 0.33809447288513184
Batch 49/64 loss: 0.3402618169784546
Batch 50/64 loss: 0.3350263833999634
Batch 51/64 loss: 0.33609509468078613
Batch 52/64 loss: 0.3357194662094116
Batch 53/64 loss: 0.3328236937522888
Batch 54/64 loss: 0.33880770206451416
Batch 55/64 loss: 0.33826375007629395
Batch 56/64 loss: 0.3375546336174011
Batch 57/64 loss: 0.332939088344574
Batch 58/64 loss: 0.34179937839508057
Batch 59/64 loss: 0.33858662843704224
Batch 60/64 loss: 0.3385459780693054
Batch 61/64 loss: 0.3360673189163208
Batch 62/64 loss: 0.33737438917160034
Batch 63/64 loss: 0.3395621180534363
Batch 64/64 loss: 0.3330662250518799
Epoch 26  Train loss: 0.33766564481398637  Val loss: 0.34326344544125587
Epoch 27
-------------------------------
Batch 1/64 loss: 0.333556592464447
Batch 2/64 loss: 0.3348132371902466
Batch 3/64 loss: 0.337743878364563
Batch 4/64 loss: 0.33486032485961914
Batch 5/64 loss: 0.3350398540496826
Batch 6/64 loss: 0.3426002264022827
Batch 7/64 loss: 0.3378000855445862
Batch 8/64 loss: 0.3409278988838196
Batch 9/64 loss: 0.3380987048149109
Batch 10/64 loss: 0.33939337730407715
Batch 11/64 loss: 0.3377893567085266
Batch 12/64 loss: 0.3395887017250061
Batch 13/64 loss: 0.33786147832870483
Batch 14/64 loss: 0.3359501361846924
Batch 15/64 loss: 0.3365509510040283
Batch 16/64 loss: 0.3384329676628113
Batch 17/64 loss: 0.33804798126220703
Batch 18/64 loss: 0.3416830897331238
Batch 19/64 loss: 0.335050106048584
Batch 20/64 loss: 0.33929651975631714
Batch 21/64 loss: 0.3403952717781067
Batch 22/64 loss: 0.33397769927978516
Batch 23/64 loss: 0.3356768488883972
Batch 24/64 loss: 0.3402128219604492
Batch 25/64 loss: 0.3390350341796875
Batch 26/64 loss: 0.34160375595092773
Batch 27/64 loss: 0.3348293900489807
Batch 28/64 loss: 0.3355952501296997
Batch 29/64 loss: 0.33906710147857666
Batch 30/64 loss: 0.3354882597923279
Batch 31/64 loss: 0.33825063705444336
Batch 32/64 loss: 0.3328537940979004
Batch 33/64 loss: 0.33501946926116943
Batch 34/64 loss: 0.3422343134880066
Batch 35/64 loss: 0.33500856161117554
Batch 36/64 loss: 0.3356173038482666
Batch 37/64 loss: 0.33725249767303467
Batch 38/64 loss: 0.33793187141418457
Batch 39/64 loss: 0.3324134349822998
Batch 40/64 loss: 0.3364199995994568
Batch 41/64 loss: 0.34089863300323486
Batch 42/64 loss: 0.3354705572128296
Batch 43/64 loss: 0.3372800946235657
Batch 44/64 loss: 0.3330546021461487
Batch 45/64 loss: 0.33654916286468506
Batch 46/64 loss: 0.3357178568840027
Batch 47/64 loss: 0.3434337377548218
Batch 48/64 loss: 0.3340297341346741
Batch 49/64 loss: 0.33898109197616577
Batch 50/64 loss: 0.3383704423904419
Batch 51/64 loss: 0.3348933458328247
Batch 52/64 loss: 0.3326437473297119
Batch 53/64 loss: 0.3419896364212036
Batch 54/64 loss: 0.33187317848205566
Batch 55/64 loss: 0.34188294410705566
Batch 56/64 loss: 0.33674317598342896
Batch 57/64 loss: 0.3334944248199463
Batch 58/64 loss: 0.33613085746765137
Batch 59/64 loss: 0.3376983404159546
Batch 60/64 loss: 0.33862990140914917
Batch 61/64 loss: 0.33808648586273193
Batch 62/64 loss: 0.33198094367980957
Batch 63/64 loss: 0.3392130136489868
Batch 64/64 loss: 0.33634334802627563
Epoch 27  Train loss: 0.3371807404592925  Val loss: 0.34137948395050677
Saving best model, epoch: 27
Epoch 28
-------------------------------
Batch 1/64 loss: 0.333940327167511
Batch 2/64 loss: 0.3383573293685913
Batch 3/64 loss: 0.335909366607666
Batch 4/64 loss: 0.33711540699005127
Batch 5/64 loss: 0.3387947082519531
Batch 6/64 loss: 0.33659785985946655
Batch 7/64 loss: 0.33542531728744507
Batch 8/64 loss: 0.33833831548690796
Batch 9/64 loss: 0.3398372530937195
Batch 10/64 loss: 0.3355370759963989
Batch 11/64 loss: 0.3361142873764038
Batch 12/64 loss: 0.33370399475097656
Batch 13/64 loss: 0.33740532398223877
Batch 14/64 loss: 0.3372335433959961
Batch 15/64 loss: 0.3364013433456421
Batch 16/64 loss: 0.3339182138442993
Batch 17/64 loss: 0.3335103392601013
Batch 18/64 loss: 0.3412410020828247
Batch 19/64 loss: 0.33930838108062744
Batch 20/64 loss: 0.33419954776763916
Batch 21/64 loss: 0.33630192279815674
Batch 22/64 loss: 0.3400595188140869
Batch 23/64 loss: 0.3370358943939209
Batch 24/64 loss: 0.33804237842559814
Batch 25/64 loss: 0.3367314338684082
Batch 26/64 loss: 0.3350811004638672
Batch 27/64 loss: 0.3332362771034241
Batch 28/64 loss: 0.33581042289733887
Batch 29/64 loss: 0.3326098918914795
Batch 30/64 loss: 0.33582383394241333
Batch 31/64 loss: 0.33314645290374756
Batch 32/64 loss: 0.33363914489746094
Batch 33/64 loss: 0.338070273399353
Batch 34/64 loss: 0.3345940113067627
Batch 35/64 loss: 0.33373647928237915
Batch 36/64 loss: 0.33456408977508545
Batch 37/64 loss: 0.33945125341415405
Batch 38/64 loss: 0.33692872524261475
Batch 39/64 loss: 0.340496301651001
Batch 40/64 loss: 0.33527863025665283
Batch 41/64 loss: 0.33860790729522705
Batch 42/64 loss: 0.3347797989845276
Batch 43/64 loss: 0.3399495482444763
Batch 44/64 loss: 0.3377060890197754
Batch 45/64 loss: 0.336661696434021
Batch 46/64 loss: 0.33516359329223633
Batch 47/64 loss: 0.33653026819229126
Batch 48/64 loss: 0.3357776403427124
Batch 49/64 loss: 0.33640795946121216
Batch 50/64 loss: 0.33588719367980957
Batch 51/64 loss: 0.33709996938705444
Batch 52/64 loss: 0.34044963121414185
Batch 53/64 loss: 0.3343808650970459
Batch 54/64 loss: 0.33685922622680664
Batch 55/64 loss: 0.33773279190063477
Batch 56/64 loss: 0.336506187915802
Batch 57/64 loss: 0.33436739444732666
Batch 58/64 loss: 0.3388940095901489
Batch 59/64 loss: 0.3403269052505493
Batch 60/64 loss: 0.33709609508514404
Batch 61/64 loss: 0.3369733691215515
Batch 62/64 loss: 0.33793431520462036
Batch 63/64 loss: 0.3376115560531616
Batch 64/64 loss: 0.3355969190597534
Epoch 28  Train loss: 0.33661064587387385  Val loss: 0.34105652058657093
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: 0.33680641651153564
Batch 2/64 loss: 0.33667999505996704
Batch 3/64 loss: 0.3319000005722046
Batch 4/64 loss: 0.33538007736206055
Batch 5/64 loss: 0.3393666744232178
Batch 6/64 loss: 0.33594828844070435
Batch 7/64 loss: 0.3326268792152405
Batch 8/64 loss: 0.33603304624557495
Batch 9/64 loss: 0.33619964122772217
Batch 10/64 loss: 0.3338635563850403
Batch 11/64 loss: 0.3371279835700989
Batch 12/64 loss: 0.33347201347351074
Batch 13/64 loss: 0.335299015045166
Batch 14/64 loss: 0.3370433449745178
Batch 15/64 loss: 0.3357478380203247
Batch 16/64 loss: 0.33371615409851074
Batch 17/64 loss: 0.3346306085586548
Batch 18/64 loss: 0.3377339839935303
Batch 19/64 loss: 0.33752143383026123
Batch 20/64 loss: 0.335452675819397
Batch 21/64 loss: 0.33656954765319824
Batch 22/64 loss: 0.33946263790130615
Batch 23/64 loss: 0.3390754461288452
Batch 24/64 loss: 0.3297293186187744
Batch 25/64 loss: 0.33242619037628174
Batch 26/64 loss: 0.33783841133117676
Batch 27/64 loss: 0.3314741849899292
Batch 28/64 loss: 0.337208092212677
Batch 29/64 loss: 0.33385443687438965
Batch 30/64 loss: 0.34034669399261475
Batch 31/64 loss: 0.3348398208618164
Batch 32/64 loss: 0.3347930312156677
Batch 33/64 loss: 0.33896011114120483
Batch 34/64 loss: 0.33818256855010986
Batch 35/64 loss: 0.33656859397888184
Batch 36/64 loss: 0.3416949510574341
Batch 37/64 loss: 0.33237576484680176
Batch 38/64 loss: 0.3351069688796997
Batch 39/64 loss: 0.33631694316864014
Batch 40/64 loss: 0.3387939929962158
Batch 41/64 loss: 0.3332839012145996
Batch 42/64 loss: 0.33949458599090576
Batch 43/64 loss: 0.336076021194458
Batch 44/64 loss: 0.33572161197662354
Batch 45/64 loss: 0.3334618806838989
Batch 46/64 loss: 0.3374001979827881
Batch 47/64 loss: 0.3360769748687744
Batch 48/64 loss: 0.33728134632110596
Batch 49/64 loss: 0.3338322043418884
Batch 50/64 loss: 0.3308159112930298
Batch 51/64 loss: 0.3406217098236084
Batch 52/64 loss: 0.3372310400009155
Batch 53/64 loss: 0.3343839645385742
Batch 54/64 loss: 0.3407942056655884
Batch 55/64 loss: 0.33595895767211914
Batch 56/64 loss: 0.33540230989456177
Batch 57/64 loss: 0.33585333824157715
Batch 58/64 loss: 0.33616048097610474
Batch 59/64 loss: 0.3388841152191162
Batch 60/64 loss: 0.33594322204589844
Batch 61/64 loss: 0.3428303003311157
Batch 62/64 loss: 0.3339383602142334
Batch 63/64 loss: 0.33102649450302124
Batch 64/64 loss: 0.3324761390686035
Epoch 29  Train loss: 0.33599996192782533  Val loss: 0.3400344221862321
Saving best model, epoch: 29
Epoch 30
-------------------------------
Batch 1/64 loss: 0.33362340927124023
Batch 2/64 loss: 0.33143651485443115
Batch 3/64 loss: 0.33371686935424805
Batch 4/64 loss: 0.33107900619506836
Batch 5/64 loss: 0.3322150707244873
Batch 6/64 loss: 0.3452267646789551
Batch 7/64 loss: 0.3360224962234497
Batch 8/64 loss: 0.33390021324157715
Batch 9/64 loss: 0.3312251567840576
Batch 10/64 loss: 0.3383423686027527
Batch 11/64 loss: 0.3349512815475464
Batch 12/64 loss: 0.3303752541542053
Batch 13/64 loss: 0.33597445487976074
Batch 14/64 loss: 0.3342355489730835
Batch 15/64 loss: 0.3408377170562744
Batch 16/64 loss: 0.33946335315704346
Batch 17/64 loss: 0.32779544591903687
Batch 18/64 loss: 0.3375850319862366
Batch 19/64 loss: 0.3335078954696655
Batch 20/64 loss: 0.3319178819656372
Batch 21/64 loss: 0.3364464044570923
Batch 22/64 loss: 0.33575451374053955
Batch 23/64 loss: 0.33403271436691284
Batch 24/64 loss: 0.33625680208206177
Batch 25/64 loss: 0.32860857248306274
Batch 26/64 loss: 0.3337101340293884
Batch 27/64 loss: 0.33396196365356445
Batch 28/64 loss: 0.3409537076950073
Batch 29/64 loss: 0.33262038230895996
Batch 30/64 loss: 0.33291131258010864
Batch 31/64 loss: 0.33573031425476074
Batch 32/64 loss: 0.3361701965332031
Batch 33/64 loss: 0.33132505416870117
Batch 34/64 loss: 0.3398870825767517
Batch 35/64 loss: 0.3415869474411011
Batch 36/64 loss: 0.3352315425872803
Batch 37/64 loss: 0.3323361873626709
Batch 38/64 loss: 0.34078359603881836
Batch 39/64 loss: 0.3336395025253296
Batch 40/64 loss: 0.3363466262817383
Batch 41/64 loss: 0.3316729664802551
Batch 42/64 loss: 0.3314514756202698
Batch 43/64 loss: 0.3362075090408325
Batch 44/64 loss: 0.3381561040878296
Batch 45/64 loss: 0.3382701873779297
Batch 46/64 loss: 0.33731430768966675
Batch 47/64 loss: 0.3359912633895874
Batch 48/64 loss: 0.33373647928237915
Batch 49/64 loss: 0.33584243059158325
Batch 50/64 loss: 0.33468616008758545
Batch 51/64 loss: 0.33435094356536865
Batch 52/64 loss: 0.3337991237640381
Batch 53/64 loss: 0.33718442916870117
Batch 54/64 loss: 0.33769065141677856
Batch 55/64 loss: 0.3329274654388428
Batch 56/64 loss: 0.3363356590270996
Batch 57/64 loss: 0.3368767499923706
Batch 58/64 loss: 0.33677196502685547
Batch 59/64 loss: 0.3362165689468384
Batch 60/64 loss: 0.3344704508781433
Batch 61/64 loss: 0.3323538899421692
Batch 62/64 loss: 0.33999717235565186
Batch 63/64 loss: 0.34118664264678955
Batch 64/64 loss: 0.33058422803878784
Epoch 30  Train loss: 0.3352651617106269  Val loss: 0.34035672006738144
Epoch 31
-------------------------------
Batch 1/64 loss: 0.3399958610534668
Batch 2/64 loss: 0.3361375331878662
Batch 3/64 loss: 0.3395087718963623
Batch 4/64 loss: 0.33656102418899536
Batch 5/64 loss: 0.33323144912719727
Batch 6/64 loss: 0.3294942378997803
Batch 7/64 loss: 0.3315191864967346
Batch 8/64 loss: 0.33290398120880127
Batch 9/64 loss: 0.33306384086608887
Batch 10/64 loss: 0.33114373683929443
Batch 11/64 loss: 0.3348275423049927
Batch 12/64 loss: 0.33488190174102783
Batch 13/64 loss: 0.33097392320632935
Batch 14/64 loss: 0.3300820589065552
Batch 15/64 loss: 0.3376518487930298
Batch 16/64 loss: 0.3357805013656616
Batch 17/64 loss: 0.3322661519050598
Batch 18/64 loss: 0.3358444571495056
Batch 19/64 loss: 0.33256977796554565
Batch 20/64 loss: 0.3310678005218506
Batch 21/64 loss: 0.33166933059692383
Batch 22/64 loss: 0.3387802839279175
Batch 23/64 loss: 0.338625431060791
Batch 24/64 loss: 0.33850377798080444
Batch 25/64 loss: 0.3417626619338989
Batch 26/64 loss: 0.3415048122406006
Batch 27/64 loss: 0.334533154964447
Batch 28/64 loss: 0.3348274827003479
Batch 29/64 loss: 0.336026668548584
Batch 30/64 loss: 0.3328900933265686
Batch 31/64 loss: 0.3344597816467285
Batch 32/64 loss: 0.33301591873168945
Batch 33/64 loss: 0.32953643798828125
Batch 34/64 loss: 0.3352430462837219
Batch 35/64 loss: 0.33516305685043335
Batch 36/64 loss: 0.33822333812713623
Batch 37/64 loss: 0.33617883920669556
Batch 38/64 loss: 0.3349165916442871
Batch 39/64 loss: 0.33502042293548584
Batch 40/64 loss: 0.3373139500617981
Batch 41/64 loss: 0.33567655086517334
Batch 42/64 loss: 0.3352699279785156
Batch 43/64 loss: 0.3350866436958313
Batch 44/64 loss: 0.34263718128204346
Batch 45/64 loss: 0.33306026458740234
Batch 46/64 loss: 0.33100152015686035
Batch 47/64 loss: 0.328926146030426
Batch 48/64 loss: 0.3346763253211975
Batch 49/64 loss: 0.33281517028808594
Batch 50/64 loss: 0.33294957876205444
Batch 51/64 loss: 0.3349885940551758
Batch 52/64 loss: 0.3405475616455078
Batch 53/64 loss: 0.3364379405975342
Batch 54/64 loss: 0.3301910161972046
Batch 55/64 loss: 0.33773601055145264
Batch 56/64 loss: 0.33134889602661133
Batch 57/64 loss: 0.33401668071746826
Batch 58/64 loss: 0.3335157632827759
Batch 59/64 loss: 0.33670681715011597
Batch 60/64 loss: 0.3327338695526123
Batch 61/64 loss: 0.335216224193573
Batch 62/64 loss: 0.3297725319862366
Batch 63/64 loss: 0.3314884305000305
Batch 64/64 loss: 0.3309318423271179
Epoch 31  Train loss: 0.3346305756007924  Val loss: 0.33914718062607285
Saving best model, epoch: 31
Epoch 32
-------------------------------
Batch 1/64 loss: 0.3315948247909546
Batch 2/64 loss: 0.3336227536201477
Batch 3/64 loss: 0.33265572786331177
Batch 4/64 loss: 0.33186542987823486
Batch 5/64 loss: 0.33312559127807617
Batch 6/64 loss: 0.3332986831665039
Batch 7/64 loss: 0.3348276615142822
Batch 8/64 loss: 0.33492642641067505
Batch 9/64 loss: 0.33097684383392334
Batch 10/64 loss: 0.3347201347351074
Batch 11/64 loss: 0.3346751928329468
Batch 12/64 loss: 0.33748918771743774
Batch 13/64 loss: 0.33297663927078247
Batch 14/64 loss: 0.33394086360931396
Batch 15/64 loss: 0.3308793902397156
Batch 16/64 loss: 0.3335829973220825
Batch 17/64 loss: 0.33703839778900146
Batch 18/64 loss: 0.3382159471511841
Batch 19/64 loss: 0.33411192893981934
Batch 20/64 loss: 0.3331180214881897
Batch 21/64 loss: 0.3295271396636963
Batch 22/64 loss: 0.3380366563796997
Batch 23/64 loss: 0.33107858896255493
Batch 24/64 loss: 0.3350694179534912
Batch 25/64 loss: 0.3361632823944092
Batch 26/64 loss: 0.3343784213066101
Batch 27/64 loss: 0.33103227615356445
Batch 28/64 loss: 0.3302445411682129
Batch 29/64 loss: 0.3356466293334961
Batch 30/64 loss: 0.33399462699890137
Batch 31/64 loss: 0.3363037109375
Batch 32/64 loss: 0.3314012885093689
Batch 33/64 loss: 0.33116817474365234
Batch 34/64 loss: 0.33984649181365967
Batch 35/64 loss: 0.34066498279571533
Batch 36/64 loss: 0.33072853088378906
Batch 37/64 loss: 0.33465856313705444
Batch 38/64 loss: 0.3349953889846802
Batch 39/64 loss: 0.33072274923324585
Batch 40/64 loss: 0.3277180790901184
Batch 41/64 loss: 0.33174562454223633
Batch 42/64 loss: 0.33469271659851074
Batch 43/64 loss: 0.33442223072052
Batch 44/64 loss: 0.33488965034484863
Batch 45/64 loss: 0.33801746368408203
Batch 46/64 loss: 0.3342738151550293
Batch 47/64 loss: 0.33575981855392456
Batch 48/64 loss: 0.33655059337615967
Batch 49/64 loss: 0.3320556879043579
Batch 50/64 loss: 0.33328694105148315
Batch 51/64 loss: 0.33239203691482544
Batch 52/64 loss: 0.3354194164276123
Batch 53/64 loss: 0.3349156379699707
Batch 54/64 loss: 0.33464515209198
Batch 55/64 loss: 0.32981300354003906
Batch 56/64 loss: 0.34159624576568604
Batch 57/64 loss: 0.3371851444244385
Batch 58/64 loss: 0.33409953117370605
Batch 59/64 loss: 0.337066650390625
Batch 60/64 loss: 0.33693528175354004
Batch 61/64 loss: 0.33038562536239624
Batch 62/64 loss: 0.32644450664520264
Batch 63/64 loss: 0.33569765090942383
Batch 64/64 loss: 0.33234483003616333
Epoch 32  Train loss: 0.33400111736035815  Val loss: 0.33902606234927357
Saving best model, epoch: 32
Epoch 33
-------------------------------
Batch 1/64 loss: 0.3293715715408325
Batch 2/64 loss: 0.3319946527481079
Batch 3/64 loss: 0.3382683992385864
Batch 4/64 loss: 0.33140498399734497
Batch 5/64 loss: 0.33347272872924805
Batch 6/64 loss: 0.33677512407302856
Batch 7/64 loss: 0.3357185125350952
Batch 8/64 loss: 0.3276110291481018
Batch 9/64 loss: 0.3320264220237732
Batch 10/64 loss: 0.3349536657333374
Batch 11/64 loss: 0.32902997732162476
Batch 12/64 loss: 0.3351266384124756
Batch 13/64 loss: 0.33564257621765137
Batch 14/64 loss: 0.3322324752807617
Batch 15/64 loss: 0.3256354331970215
Batch 16/64 loss: 0.33711111545562744
Batch 17/64 loss: 0.33204561471939087
Batch 18/64 loss: 0.3361474275588989
Batch 19/64 loss: 0.33178114891052246
Batch 20/64 loss: 0.33289003372192383
Batch 21/64 loss: 0.329764723777771
Batch 22/64 loss: 0.3374534249305725
Batch 23/64 loss: 0.32931292057037354
Batch 24/64 loss: 0.33096325397491455
Batch 25/64 loss: 0.3346896767616272
Batch 26/64 loss: 0.33579742908477783
Batch 27/64 loss: 0.328548789024353
Batch 28/64 loss: 0.33561819791793823
Batch 29/64 loss: 0.32857775688171387
Batch 30/64 loss: 0.3327089548110962
Batch 31/64 loss: 0.33316588401794434
Batch 32/64 loss: 0.3344930410385132
Batch 33/64 loss: 0.33068954944610596
Batch 34/64 loss: 0.33496350049972534
Batch 35/64 loss: 0.33451688289642334
Batch 36/64 loss: 0.32592904567718506
Batch 37/64 loss: 0.3271210193634033
Batch 38/64 loss: 0.33289217948913574
Batch 39/64 loss: 0.3278413414955139
Batch 40/64 loss: 0.3305957317352295
Batch 41/64 loss: 0.33040928840637207
Batch 42/64 loss: 0.3344435691833496
Batch 43/64 loss: 0.32761454582214355
Batch 44/64 loss: 0.3385195732116699
Batch 45/64 loss: 0.3442791700363159
Batch 46/64 loss: 0.33462822437286377
Batch 47/64 loss: 0.3345886468887329
Batch 48/64 loss: 0.3295259475708008
Batch 49/64 loss: 0.33852893114089966
Batch 50/64 loss: 0.33709633350372314
Batch 51/64 loss: 0.33132755756378174
Batch 52/64 loss: 0.33389586210250854
Batch 53/64 loss: 0.3353140950202942
Batch 54/64 loss: 0.3281092643737793
Batch 55/64 loss: 0.33171939849853516
Batch 56/64 loss: 0.3333413600921631
Batch 57/64 loss: 0.33714497089385986
Batch 58/64 loss: 0.3376743793487549
Batch 59/64 loss: 0.33470290899276733
Batch 60/64 loss: 0.3278433680534363
Batch 61/64 loss: 0.33050966262817383
Batch 62/64 loss: 0.33241117000579834
Batch 63/64 loss: 0.3272245526313782
Batch 64/64 loss: 0.3317451477050781
Epoch 33  Train loss: 0.3327771682365268  Val loss: 0.338167262650847
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: 0.32795292139053345
Batch 2/64 loss: 0.3377836346626282
Batch 3/64 loss: 0.3295808434486389
Batch 4/64 loss: 0.3334212899208069
Batch 5/64 loss: 0.3318866491317749
Batch 6/64 loss: 0.33619874715805054
Batch 7/64 loss: 0.33532679080963135
Batch 8/64 loss: 0.333518385887146
Batch 9/64 loss: 0.32600653171539307
Batch 10/64 loss: 0.3304135203361511
Batch 11/64 loss: 0.33489733934402466
Batch 12/64 loss: 0.326961874961853
Batch 13/64 loss: 0.334017276763916
Batch 14/64 loss: 0.3320229649543762
Batch 15/64 loss: 0.3351476192474365
Batch 16/64 loss: 0.33142566680908203
Batch 17/64 loss: 0.33641988039016724
Batch 18/64 loss: 0.33225202560424805
Batch 19/64 loss: 0.33150023221969604
Batch 20/64 loss: 0.33251655101776123
Batch 21/64 loss: 0.3318042755126953
Batch 22/64 loss: 0.33166682720184326
Batch 23/64 loss: 0.33368730545043945
Batch 24/64 loss: 0.3262104392051697
Batch 25/64 loss: 0.3359100818634033
Batch 26/64 loss: 0.32389283180236816
Batch 27/64 loss: 0.33335936069488525
Batch 28/64 loss: 0.3265494704246521
Batch 29/64 loss: 0.333842396736145
Batch 30/64 loss: 0.3318026065826416
Batch 31/64 loss: 0.33573591709136963
Batch 32/64 loss: 0.3317760229110718
Batch 33/64 loss: 0.32996052503585815
Batch 34/64 loss: 0.33703142404556274
Batch 35/64 loss: 0.3349456787109375
Batch 36/64 loss: 0.336106538772583
Batch 37/64 loss: 0.33142805099487305
Batch 38/64 loss: 0.3317447900772095
Batch 39/64 loss: 0.33128637075424194
Batch 40/64 loss: 0.33724743127822876
Batch 41/64 loss: 0.33013951778411865
Batch 42/64 loss: 0.3330737352371216
Batch 43/64 loss: 0.3372466564178467
Batch 44/64 loss: 0.335365891456604
Batch 45/64 loss: 0.3338589072227478
Batch 46/64 loss: 0.3323596715927124
Batch 47/64 loss: 0.32673126459121704
Batch 48/64 loss: 0.327639639377594
Batch 49/64 loss: 0.33366042375564575
Batch 50/64 loss: 0.3341470956802368
Batch 51/64 loss: 0.3304635286331177
Batch 52/64 loss: 0.3320286273956299
Batch 53/64 loss: 0.3316861391067505
Batch 54/64 loss: 0.3303370475769043
Batch 55/64 loss: 0.33212363719940186
Batch 56/64 loss: 0.33242619037628174
Batch 57/64 loss: 0.3248734474182129
Batch 58/64 loss: 0.3325526714324951
Batch 59/64 loss: 0.3280826807022095
Batch 60/64 loss: 0.3368711471557617
Batch 61/64 loss: 0.3338348865509033
Batch 62/64 loss: 0.32835853099823
Batch 63/64 loss: 0.3319047689437866
Batch 64/64 loss: 0.3275819420814514
Epoch 34  Train loss: 0.3320892808484096  Val loss: 0.33702578372562053
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: 0.3325956463813782
Batch 2/64 loss: 0.32771456241607666
Batch 3/64 loss: 0.3303273916244507
Batch 4/64 loss: 0.3222578763961792
Batch 5/64 loss: 0.3327251672744751
Batch 6/64 loss: 0.3373482823371887
Batch 7/64 loss: 0.3311263918876648
Batch 8/64 loss: 0.326343297958374
Batch 9/64 loss: 0.33460676670074463
Batch 10/64 loss: 0.3347926735877991
Batch 11/64 loss: 0.3270421028137207
Batch 12/64 loss: 0.3362572193145752
Batch 13/64 loss: 0.32947778701782227
Batch 14/64 loss: 0.32777106761932373
Batch 15/64 loss: 0.3327430486679077
Batch 16/64 loss: 0.3342364430427551
Batch 17/64 loss: 0.32745838165283203
Batch 18/64 loss: 0.33371084928512573
Batch 19/64 loss: 0.3289673328399658
Batch 20/64 loss: 0.32732462882995605
Batch 21/64 loss: 0.3337000608444214
Batch 22/64 loss: 0.32977038621902466
Batch 23/64 loss: 0.33421802520751953
Batch 24/64 loss: 0.3373427391052246
Batch 25/64 loss: 0.3261203169822693
Batch 26/64 loss: 0.33229583501815796
Batch 27/64 loss: 0.33273863792419434
Batch 28/64 loss: 0.3349781036376953
Batch 29/64 loss: 0.3308061361312866
Batch 30/64 loss: 0.33745646476745605
Batch 31/64 loss: 0.33646535873413086
Batch 32/64 loss: 0.3332872986793518
Batch 33/64 loss: 0.3355690836906433
Batch 34/64 loss: 0.3342010974884033
Batch 35/64 loss: 0.3265420198440552
Batch 36/64 loss: 0.32999515533447266
Batch 37/64 loss: 0.33266693353652954
Batch 38/64 loss: 0.3283092975616455
Batch 39/64 loss: 0.3315281867980957
Batch 40/64 loss: 0.33640265464782715
Batch 41/64 loss: 0.3319586515426636
Batch 42/64 loss: 0.33576345443725586
Batch 43/64 loss: 0.33043932914733887
Batch 44/64 loss: 0.3294495940208435
Batch 45/64 loss: 0.33731329441070557
Batch 46/64 loss: 0.32993465662002563
Batch 47/64 loss: 0.3306758403778076
Batch 48/64 loss: 0.3346875309944153
Batch 49/64 loss: 0.3336350917816162
Batch 50/64 loss: 0.3259168863296509
Batch 51/64 loss: 0.33138132095336914
Batch 52/64 loss: 0.33620119094848633
Batch 53/64 loss: 0.33001041412353516
Batch 54/64 loss: 0.32799386978149414
Batch 55/64 loss: 0.3282737731933594
Batch 56/64 loss: 0.32682013511657715
Batch 57/64 loss: 0.3317652940750122
Batch 58/64 loss: 0.32939666509628296
Batch 59/64 loss: 0.33572226762771606
Batch 60/64 loss: 0.3329784870147705
Batch 61/64 loss: 0.33165091276168823
Batch 62/64 loss: 0.33061426877975464
Batch 63/64 loss: 0.3281313180923462
Batch 64/64 loss: 0.33524930477142334
Epoch 35  Train loss: 0.33162936369578044  Val loss: 0.3376674897891959
Epoch 36
-------------------------------
Batch 1/64 loss: 0.33370232582092285
Batch 2/64 loss: 0.3310072422027588
Batch 3/64 loss: 0.32499682903289795
Batch 4/64 loss: 0.33372414112091064
Batch 5/64 loss: 0.3338519334793091
Batch 6/64 loss: 0.3309530019760132
Batch 7/64 loss: 0.33316218852996826
Batch 8/64 loss: 0.33089327812194824
Batch 9/64 loss: 0.3284369707107544
Batch 10/64 loss: 0.33490848541259766
Batch 11/64 loss: 0.32787126302719116
Batch 12/64 loss: 0.32888364791870117
Batch 13/64 loss: 0.3279486894607544
Batch 14/64 loss: 0.33237576484680176
Batch 15/64 loss: 0.33109933137893677
Batch 16/64 loss: 0.3238793611526489
Batch 17/64 loss: 0.3366173505783081
Batch 18/64 loss: 0.3344222903251648
Batch 19/64 loss: 0.3326411247253418
Batch 20/64 loss: 0.3314116597175598
Batch 21/64 loss: 0.33538442850112915
Batch 22/64 loss: 0.32382404804229736
Batch 23/64 loss: 0.3335492014884949
Batch 24/64 loss: 0.3342212438583374
Batch 25/64 loss: 0.3326992988586426
Batch 26/64 loss: 0.33562350273132324
Batch 27/64 loss: 0.3343087434768677
Batch 28/64 loss: 0.33141177892684937
Batch 29/64 loss: 0.329878568649292
Batch 30/64 loss: 0.3312421441078186
Batch 31/64 loss: 0.33398449420928955
Batch 32/64 loss: 0.328784704208374
Batch 33/64 loss: 0.32548725605010986
Batch 34/64 loss: 0.3300420045852661
Batch 35/64 loss: 0.32850098609924316
Batch 36/64 loss: 0.3272467851638794
Batch 37/64 loss: 0.33369410037994385
Batch 38/64 loss: 0.33535611629486084
Batch 39/64 loss: 0.32725292444229126
Batch 40/64 loss: 0.32404065132141113
Batch 41/64 loss: 0.333848237991333
Batch 42/64 loss: 0.33268821239471436
Batch 43/64 loss: 0.3305252194404602
Batch 44/64 loss: 0.33095067739486694
Batch 45/64 loss: 0.3272159695625305
Batch 46/64 loss: 0.3280070424079895
Batch 47/64 loss: 0.32800865173339844
Batch 48/64 loss: 0.3323746919631958
Batch 49/64 loss: 0.3259696960449219
Batch 50/64 loss: 0.3294687271118164
Batch 51/64 loss: 0.33028507232666016
Batch 52/64 loss: 0.3323158025741577
Batch 53/64 loss: 0.3299073576927185
Batch 54/64 loss: 0.33691829442977905
Batch 55/64 loss: 0.3306671380996704
Batch 56/64 loss: 0.32904934883117676
Batch 57/64 loss: 0.3293050527572632
Batch 58/64 loss: 0.3373526334762573
Batch 59/64 loss: 0.337221622467041
Batch 60/64 loss: 0.32526683807373047
Batch 61/64 loss: 0.32706356048583984
Batch 62/64 loss: 0.3358030915260315
Batch 63/64 loss: 0.32715338468551636
Batch 64/64 loss: 0.3256707787513733
Epoch 36  Train loss: 0.33083826303482056  Val loss: 0.3368904889654048
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 0.32680046558380127
Batch 2/64 loss: 0.33219075202941895
Batch 3/64 loss: 0.3289456367492676
Batch 4/64 loss: 0.33186209201812744
Batch 5/64 loss: 0.32901954650878906
Batch 6/64 loss: 0.3294299840927124
Batch 7/64 loss: 0.3294597864151001
Batch 8/64 loss: 0.329913854598999
Batch 9/64 loss: 0.33315473794937134
Batch 10/64 loss: 0.3300831913948059
Batch 11/64 loss: 0.3341549038887024
Batch 12/64 loss: 0.3289576768875122
Batch 13/64 loss: 0.3337153196334839
Batch 14/64 loss: 0.3313126564025879
Batch 15/64 loss: 0.32916897535324097
Batch 16/64 loss: 0.32738399505615234
Batch 17/64 loss: 0.3284701108932495
Batch 18/64 loss: 0.3401467800140381
Batch 19/64 loss: 0.3269834518432617
Batch 20/64 loss: 0.32834571599960327
Batch 21/64 loss: 0.32734858989715576
Batch 22/64 loss: 0.33587849140167236
Batch 23/64 loss: 0.3265960216522217
Batch 24/64 loss: 0.32820701599121094
Batch 25/64 loss: 0.3345177173614502
Batch 26/64 loss: 0.3281627893447876
Batch 27/64 loss: 0.3282815217971802
Batch 28/64 loss: 0.3262608051300049
Batch 29/64 loss: 0.32737112045288086
Batch 30/64 loss: 0.33386778831481934
Batch 31/64 loss: 0.3271031975746155
Batch 32/64 loss: 0.33232200145721436
Batch 33/64 loss: 0.33215558528900146
Batch 34/64 loss: 0.33444666862487793
Batch 35/64 loss: 0.32865989208221436
Batch 36/64 loss: 0.33224743604660034
Batch 37/64 loss: 0.3265409469604492
Batch 38/64 loss: 0.3329862356185913
Batch 39/64 loss: 0.33023977279663086
Batch 40/64 loss: 0.33189231157302856
Batch 41/64 loss: 0.3286581039428711
Batch 42/64 loss: 0.3341689109802246
Batch 43/64 loss: 0.33098554611206055
Batch 44/64 loss: 0.32737624645233154
Batch 45/64 loss: 0.32378411293029785
Batch 46/64 loss: 0.3274032473564148
Batch 47/64 loss: 0.328230082988739
Batch 48/64 loss: 0.33180761337280273
Batch 49/64 loss: 0.33350586891174316
Batch 50/64 loss: 0.32949298620224
Batch 51/64 loss: 0.3270694613456726
Batch 52/64 loss: 0.3242660164833069
Batch 53/64 loss: 0.3257356882095337
Batch 54/64 loss: 0.33196163177490234
Batch 55/64 loss: 0.3316587805747986
Batch 56/64 loss: 0.32846832275390625
Batch 57/64 loss: 0.3363255262374878
Batch 58/64 loss: 0.33144819736480713
Batch 59/64 loss: 0.3288238048553467
Batch 60/64 loss: 0.3339043855667114
Batch 61/64 loss: 0.32964271306991577
Batch 62/64 loss: 0.33022451400756836
Batch 63/64 loss: 0.33095550537109375
Batch 64/64 loss: 0.32839059829711914
Epoch 37  Train loss: 0.3301455020904541  Val loss: 0.33610757560664434
Saving best model, epoch: 37
Epoch 38
-------------------------------
Batch 1/64 loss: 0.3332098722457886
Batch 2/64 loss: 0.33627164363861084
Batch 3/64 loss: 0.3296198844909668
Batch 4/64 loss: 0.32596760988235474
Batch 5/64 loss: 0.32905566692352295
Batch 6/64 loss: 0.3279423713684082
Batch 7/64 loss: 0.33201169967651367
Batch 8/64 loss: 0.3264930248260498
Batch 9/64 loss: 0.3294164538383484
Batch 10/64 loss: 0.32449787855148315
Batch 11/64 loss: 0.33009493350982666
Batch 12/64 loss: 0.3326941728591919
Batch 13/64 loss: 0.33093029260635376
Batch 14/64 loss: 0.32452845573425293
Batch 15/64 loss: 0.3269798755645752
Batch 16/64 loss: 0.32726073265075684
Batch 17/64 loss: 0.32439112663269043
Batch 18/64 loss: 0.32864248752593994
Batch 19/64 loss: 0.33012855052948
Batch 20/64 loss: 0.3330165147781372
Batch 21/64 loss: 0.33376801013946533
Batch 22/64 loss: 0.3261840343475342
Batch 23/64 loss: 0.3288842439651489
Batch 24/64 loss: 0.3292807340621948
Batch 25/64 loss: 0.3277512192726135
Batch 26/64 loss: 0.3266686201095581
Batch 27/64 loss: 0.31807971000671387
Batch 28/64 loss: 0.32413357496261597
Batch 29/64 loss: 0.3265851140022278
Batch 30/64 loss: 0.33005404472351074
Batch 31/64 loss: 0.32817018032073975
Batch 32/64 loss: 0.32711994647979736
Batch 33/64 loss: 0.3320401906967163
Batch 34/64 loss: 0.330035924911499
Batch 35/64 loss: 0.3214075565338135
Batch 36/64 loss: 0.3271002769470215
Batch 37/64 loss: 0.33060741424560547
Batch 38/64 loss: 0.33047235012054443
Batch 39/64 loss: 0.32767152786254883
Batch 40/64 loss: 0.3301945924758911
Batch 41/64 loss: 0.32951247692108154
Batch 42/64 loss: 0.32633066177368164
Batch 43/64 loss: 0.32368767261505127
Batch 44/64 loss: 0.3316238522529602
Batch 45/64 loss: 0.3284043073654175
Batch 46/64 loss: 0.3307739496231079
Batch 47/64 loss: 0.33142268657684326
Batch 48/64 loss: 0.3277435898780823
Batch 49/64 loss: 0.33212774991989136
Batch 50/64 loss: 0.3247636556625366
Batch 51/64 loss: 0.331958532333374
Batch 52/64 loss: 0.3296656608581543
Batch 53/64 loss: 0.3310866355895996
Batch 54/64 loss: 0.32874298095703125
Batch 55/64 loss: 0.32321131229400635
Batch 56/64 loss: 0.330020010471344
Batch 57/64 loss: 0.33462846279144287
Batch 58/64 loss: 0.3237299919128418
Batch 59/64 loss: 0.33232581615448
Batch 60/64 loss: 0.3276776075363159
Batch 61/64 loss: 0.3254595994949341
Batch 62/64 loss: 0.32836735248565674
Batch 63/64 loss: 0.32609426975250244
Batch 64/64 loss: 0.3246800899505615
Epoch 38  Train loss: 0.3285055908502317  Val loss: 0.3361287489789458
Epoch 39
-------------------------------
Batch 1/64 loss: 0.33057886362075806
Batch 2/64 loss: 0.32303011417388916
Batch 3/64 loss: 0.3334916830062866
Batch 4/64 loss: 0.32309508323669434
Batch 5/64 loss: 0.3295910358428955
Batch 6/64 loss: 0.32870644330978394
Batch 7/64 loss: 0.3279902935028076
Batch 8/64 loss: 0.32644927501678467
Batch 9/64 loss: 0.3328826427459717
Batch 10/64 loss: 0.3282015919685364
Batch 11/64 loss: 0.32680583000183105
Batch 12/64 loss: 0.3264402747154236
Batch 13/64 loss: 0.3274487853050232
Batch 14/64 loss: 0.31982409954071045
Batch 15/64 loss: 0.3279988765716553
Batch 16/64 loss: 0.32419633865356445
Batch 17/64 loss: 0.33083224296569824
Batch 18/64 loss: 0.3301459550857544
Batch 19/64 loss: 0.3247073292732239
Batch 20/64 loss: 0.32699835300445557
Batch 21/64 loss: 0.33036112785339355
Batch 22/64 loss: 0.3296194076538086
Batch 23/64 loss: 0.32686275243759155
Batch 24/64 loss: 0.3270822763442993
Batch 25/64 loss: 0.3235909938812256
Batch 26/64 loss: 0.3309142589569092
Batch 27/64 loss: 0.3303295373916626
Batch 28/64 loss: 0.33127301931381226
Batch 29/64 loss: 0.3196439743041992
Batch 30/64 loss: 0.3258630037307739
Batch 31/64 loss: 0.3259519338607788
Batch 32/64 loss: 0.3298947811126709
Batch 33/64 loss: 0.329581618309021
Batch 34/64 loss: 0.3298267126083374
Batch 35/64 loss: 0.3263593912124634
Batch 36/64 loss: 0.32367026805877686
Batch 37/64 loss: 0.3252837657928467
Batch 38/64 loss: 0.3297569155693054
Batch 39/64 loss: 0.33233165740966797
Batch 40/64 loss: 0.3278304934501648
Batch 41/64 loss: 0.32811617851257324
Batch 42/64 loss: 0.32105904817581177
Batch 43/64 loss: 0.3284585475921631
Batch 44/64 loss: 0.3256385326385498
Batch 45/64 loss: 0.33277344703674316
Batch 46/64 loss: 0.3307475447654724
Batch 47/64 loss: 0.32495051622390747
Batch 48/64 loss: 0.32893240451812744
Batch 49/64 loss: 0.3307429552078247
Batch 50/64 loss: 0.3257097005844116
Batch 51/64 loss: 0.32853376865386963
Batch 52/64 loss: 0.3263435959815979
Batch 53/64 loss: 0.33142465353012085
Batch 54/64 loss: 0.3278474807739258
Batch 55/64 loss: 0.3228766918182373
Batch 56/64 loss: 0.33317577838897705
Batch 57/64 loss: 0.3293658494949341
Batch 58/64 loss: 0.3266866207122803
Batch 59/64 loss: 0.3236119747161865
Batch 60/64 loss: 0.3280766010284424
Batch 61/64 loss: 0.32412785291671753
Batch 62/64 loss: 0.3229982256889343
Batch 63/64 loss: 0.32874929904937744
Batch 64/64 loss: 0.32875555753707886
Epoch 39  Train loss: 0.3275757950894973  Val loss: 0.3336210908349027
Saving best model, epoch: 39
Epoch 40
-------------------------------
Batch 1/64 loss: 0.32441508769989014
Batch 2/64 loss: 0.3267974853515625
Batch 3/64 loss: 0.3274438977241516
Batch 4/64 loss: 0.3223832845687866
Batch 5/64 loss: 0.3294261693954468
Batch 6/64 loss: 0.3298931121826172
Batch 7/64 loss: 0.3223491907119751
Batch 8/64 loss: 0.3243867754936218
Batch 9/64 loss: 0.32788121700286865
Batch 10/64 loss: 0.33045750856399536
Batch 11/64 loss: 0.3307669758796692
Batch 12/64 loss: 0.32452332973480225
Batch 13/64 loss: 0.3243914842605591
Batch 14/64 loss: 0.33176589012145996
Batch 15/64 loss: 0.3244190216064453
Batch 16/64 loss: 0.3262288570404053
Batch 17/64 loss: 0.32695472240448
Batch 18/64 loss: 0.3312123417854309
Batch 19/64 loss: 0.3262569308280945
Batch 20/64 loss: 0.32912635803222656
Batch 21/64 loss: 0.32142651081085205
Batch 22/64 loss: 0.3254014253616333
Batch 23/64 loss: 0.326259970664978
Batch 24/64 loss: 0.3254810571670532
Batch 25/64 loss: 0.33289778232574463
Batch 26/64 loss: 0.3247257471084595
Batch 27/64 loss: 0.3247241973876953
Batch 28/64 loss: 0.32177042961120605
Batch 29/64 loss: 0.32649481296539307
Batch 30/64 loss: 0.32695066928863525
Batch 31/64 loss: 0.32492196559906006
Batch 32/64 loss: 0.32212942838668823
Batch 33/64 loss: 0.3290574550628662
Batch 34/64 loss: 0.32909321784973145
Batch 35/64 loss: 0.32379698753356934
Batch 36/64 loss: 0.3248783349990845
Batch 37/64 loss: 0.3257913589477539
Batch 38/64 loss: 0.32821786403656006
Batch 39/64 loss: 0.3297803997993469
Batch 40/64 loss: 0.33039361238479614
Batch 41/64 loss: 0.3303982615470886
Batch 42/64 loss: 0.32997941970825195
Batch 43/64 loss: 0.3230149745941162
Batch 44/64 loss: 0.32132720947265625
Batch 45/64 loss: 0.3275163173675537
Batch 46/64 loss: 0.33126139640808105
Batch 47/64 loss: 0.3240728974342346
Batch 48/64 loss: 0.3291891813278198
Batch 49/64 loss: 0.32514870166778564
Batch 50/64 loss: 0.32584285736083984
Batch 51/64 loss: 0.3304945230484009
Batch 52/64 loss: 0.32403647899627686
Batch 53/64 loss: 0.32927757501602173
Batch 54/64 loss: 0.3300923705101013
Batch 55/64 loss: 0.3292149305343628
Batch 56/64 loss: 0.32491886615753174
Batch 57/64 loss: 0.3258628845214844
Batch 58/64 loss: 0.3239516019821167
Batch 59/64 loss: 0.3260475993156433
Batch 60/64 loss: 0.3238440752029419
Batch 61/64 loss: 0.33121538162231445
Batch 62/64 loss: 0.33206701278686523
Batch 63/64 loss: 0.3312799334526062
Batch 64/64 loss: 0.3276100158691406
Epoch 40  Train loss: 0.32691819340574974  Val loss: 0.33356814163247334
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: 0.3264322876930237
Batch 2/64 loss: 0.33315080404281616
Batch 3/64 loss: 0.327406108379364
Batch 4/64 loss: 0.3241078853607178
Batch 5/64 loss: 0.328649640083313
Batch 6/64 loss: 0.32706689834594727
Batch 7/64 loss: 0.32838666439056396
Batch 8/64 loss: 0.325603187084198
Batch 9/64 loss: 0.3225322961807251
Batch 10/64 loss: 0.32810527086257935
Batch 11/64 loss: 0.32034581899642944
Batch 12/64 loss: 0.3305398225784302
Batch 13/64 loss: 0.3284536600112915
Batch 14/64 loss: 0.3270655870437622
Batch 15/64 loss: 0.330180287361145
Batch 16/64 loss: 0.3273400068283081
Batch 17/64 loss: 0.33220744132995605
Batch 18/64 loss: 0.32747888565063477
Batch 19/64 loss: 0.3306787610054016
Batch 20/64 loss: 0.32125288248062134
Batch 21/64 loss: 0.3276160955429077
Batch 22/64 loss: 0.32243871688842773
Batch 23/64 loss: 0.3259016275405884
Batch 24/64 loss: 0.32844793796539307
Batch 25/64 loss: 0.32222187519073486
Batch 26/64 loss: 0.33315491676330566
Batch 27/64 loss: 0.3205883502960205
Batch 28/64 loss: 0.32469701766967773
Batch 29/64 loss: 0.32222962379455566
Batch 30/64 loss: 0.33003079891204834
Batch 31/64 loss: 0.3259158730506897
Batch 32/64 loss: 0.32363468408584595
Batch 33/64 loss: 0.3248840570449829
Batch 34/64 loss: 0.32275718450546265
Batch 35/64 loss: 0.3239614963531494
Batch 36/64 loss: 0.3238028883934021
Batch 37/64 loss: 0.3238411545753479
Batch 38/64 loss: 0.3281610608100891
Batch 39/64 loss: 0.32633352279663086
Batch 40/64 loss: 0.31799519062042236
Batch 41/64 loss: 0.3297277092933655
Batch 42/64 loss: 0.3260568380355835
Batch 43/64 loss: 0.3299477696418762
Batch 44/64 loss: 0.32671892642974854
Batch 45/64 loss: 0.32591938972473145
Batch 46/64 loss: 0.32648706436157227
Batch 47/64 loss: 0.3255993127822876
Batch 48/64 loss: 0.3329307436943054
Batch 49/64 loss: 0.32463812828063965
Batch 50/64 loss: 0.3274047374725342
Batch 51/64 loss: 0.3223201036453247
Batch 52/64 loss: 0.32137393951416016
Batch 53/64 loss: 0.3252434730529785
Batch 54/64 loss: 0.32698363065719604
Batch 55/64 loss: 0.3249927759170532
Batch 56/64 loss: 0.32543128728866577
Batch 57/64 loss: 0.31827813386917114
Batch 58/64 loss: 0.3268622159957886
Batch 59/64 loss: 0.32241785526275635
Batch 60/64 loss: 0.325869083404541
Batch 61/64 loss: 0.32040733098983765
Batch 62/64 loss: 0.32144176959991455
Batch 63/64 loss: 0.32072722911834717
Batch 64/64 loss: 0.3260738253593445
Epoch 41  Train loss: 0.32577149938134586  Val loss: 0.3320801682078961
Saving best model, epoch: 41
Epoch 42
-------------------------------
Batch 1/64 loss: 0.322517991065979
Batch 2/64 loss: 0.3290765881538391
Batch 3/64 loss: 0.32742369174957275
Batch 4/64 loss: 0.3257560729980469
Batch 5/64 loss: 0.31951552629470825
Batch 6/64 loss: 0.3236464262008667
Batch 7/64 loss: 0.32154130935668945
Batch 8/64 loss: 0.3238861560821533
Batch 9/64 loss: 0.32022273540496826
Batch 10/64 loss: 0.3311293125152588
Batch 11/64 loss: 0.31542861461639404
Batch 12/64 loss: 0.3220556378364563
Batch 13/64 loss: 0.3247692584991455
Batch 14/64 loss: 0.3193237781524658
Batch 15/64 loss: 0.31940627098083496
Batch 16/64 loss: 0.33008646965026855
Batch 17/64 loss: 0.3256939649581909
Batch 18/64 loss: 0.32379353046417236
Batch 19/64 loss: 0.33088696002960205
Batch 20/64 loss: 0.32493531703948975
Batch 21/64 loss: 0.32145196199417114
Batch 22/64 loss: 0.3234821557998657
Batch 23/64 loss: 0.3244936466217041
Batch 24/64 loss: 0.33162617683410645
Batch 25/64 loss: 0.3226041793823242
Batch 26/64 loss: 0.32842308282852173
Batch 27/64 loss: 0.32636284828186035
Batch 28/64 loss: 0.3236292600631714
Batch 29/64 loss: 0.3247286081314087
Batch 30/64 loss: 0.3240482807159424
Batch 31/64 loss: 0.32218122482299805
Batch 32/64 loss: 0.329659104347229
Batch 33/64 loss: 0.32995909452438354
Batch 34/64 loss: 0.32401925325393677
Batch 35/64 loss: 0.3183286190032959
Batch 36/64 loss: 0.3287452459335327
Batch 37/64 loss: 0.3204135298728943
Batch 38/64 loss: 0.31993865966796875
Batch 39/64 loss: 0.3229635953903198
Batch 40/64 loss: 0.3285377025604248
Batch 41/64 loss: 0.3236389756202698
Batch 42/64 loss: 0.32531988620758057
Batch 43/64 loss: 0.3193432092666626
Batch 44/64 loss: 0.32632386684417725
Batch 45/64 loss: 0.3243199586868286
Batch 46/64 loss: 0.33123779296875
Batch 47/64 loss: 0.3204690217971802
Batch 48/64 loss: 0.3214828372001648
Batch 49/64 loss: 0.3225175142288208
Batch 50/64 loss: 0.3278179168701172
Batch 51/64 loss: 0.32448142766952515
Batch 52/64 loss: 0.3276529312133789
Batch 53/64 loss: 0.3238917589187622
Batch 54/64 loss: 0.3240314722061157
Batch 55/64 loss: 0.32105374336242676
Batch 56/64 loss: 0.31680798530578613
Batch 57/64 loss: 0.3259497880935669
Batch 58/64 loss: 0.323569118976593
Batch 59/64 loss: 0.3227752447128296
Batch 60/64 loss: 0.31933295726776123
Batch 61/64 loss: 0.32426226139068604
Batch 62/64 loss: 0.3184739947319031
Batch 63/64 loss: 0.32702457904815674
Batch 64/64 loss: 0.33088207244873047
Epoch 42  Train loss: 0.32418245708241183  Val loss: 0.33143544606736436
Saving best model, epoch: 42
Epoch 43
-------------------------------
Batch 1/64 loss: 0.31796443462371826
Batch 2/64 loss: 0.3234650492668152
Batch 3/64 loss: 0.31717759370803833
Batch 4/64 loss: 0.31922680139541626
Batch 5/64 loss: 0.3316582441329956
Batch 6/64 loss: 0.3222736120223999
Batch 7/64 loss: 0.32025444507598877
Batch 8/64 loss: 0.32834696769714355
Batch 9/64 loss: 0.32005608081817627
Batch 10/64 loss: 0.318942666053772
Batch 11/64 loss: 0.32362300157546997
Batch 12/64 loss: 0.32154786586761475
Batch 13/64 loss: 0.3285936713218689
Batch 14/64 loss: 0.3268996477127075
Batch 15/64 loss: 0.32493120431900024
Batch 16/64 loss: 0.3208155035972595
Batch 17/64 loss: 0.32532501220703125
Batch 18/64 loss: 0.31713342666625977
Batch 19/64 loss: 0.32458430528640747
Batch 20/64 loss: 0.324709951877594
Batch 21/64 loss: 0.32725000381469727
Batch 22/64 loss: 0.3189486861228943
Batch 23/64 loss: 0.325101375579834
Batch 24/64 loss: 0.3243754506111145
Batch 25/64 loss: 0.3288416862487793
Batch 26/64 loss: 0.3285009264945984
Batch 27/64 loss: 0.32986462116241455
Batch 28/64 loss: 0.3205537796020508
Batch 29/64 loss: 0.32723599672317505
Batch 30/64 loss: 0.32800430059432983
Batch 31/64 loss: 0.3238065242767334
Batch 32/64 loss: 0.32130885124206543
Batch 33/64 loss: 0.32324957847595215
Batch 34/64 loss: 0.33274292945861816
Batch 35/64 loss: 0.32530540227890015
Batch 36/64 loss: 0.31840384006500244
Batch 37/64 loss: 0.31763458251953125
Batch 38/64 loss: 0.3188587427139282
Batch 39/64 loss: 0.3236939311027527
Batch 40/64 loss: 0.324462890625
Batch 41/64 loss: 0.31890732049942017
Batch 42/64 loss: 0.3235340118408203
Batch 43/64 loss: 0.32540392875671387
Batch 44/64 loss: 0.33001863956451416
Batch 45/64 loss: 0.32431572675704956
Batch 46/64 loss: 0.32088083028793335
Batch 47/64 loss: 0.3203366994857788
Batch 48/64 loss: 0.32199984788894653
Batch 49/64 loss: 0.3178216218948364
Batch 50/64 loss: 0.3201104402542114
Batch 51/64 loss: 0.32459384202957153
Batch 52/64 loss: 0.32298707962036133
Batch 53/64 loss: 0.31889915466308594
Batch 54/64 loss: 0.32555556297302246
Batch 55/64 loss: 0.3191559314727783
Batch 56/64 loss: 0.318739116191864
Batch 57/64 loss: 0.31963133811950684
Batch 58/64 loss: 0.31713294982910156
Batch 59/64 loss: 0.32400989532470703
Batch 60/64 loss: 0.32469016313552856
Batch 61/64 loss: 0.32330143451690674
Batch 62/64 loss: 0.323080837726593
Batch 63/64 loss: 0.32619553804397583
Batch 64/64 loss: 0.32517558336257935
Epoch 43  Train loss: 0.3231507009150935  Val loss: 0.33082930042161973
Saving best model, epoch: 43
Epoch 44
-------------------------------
Batch 1/64 loss: 0.3132094144821167
Batch 2/64 loss: 0.32388150691986084
Batch 3/64 loss: 0.3254506587982178
Batch 4/64 loss: 0.32042717933654785
Batch 5/64 loss: 0.3254246711730957
Batch 6/64 loss: 0.32340937852859497
Batch 7/64 loss: 0.3192044496536255
Batch 8/64 loss: 0.31897038221359253
Batch 9/64 loss: 0.3190518021583557
Batch 10/64 loss: 0.31603628396987915
Batch 11/64 loss: 0.3251917362213135
Batch 12/64 loss: 0.32959890365600586
Batch 13/64 loss: 0.3184516429901123
Batch 14/64 loss: 0.3197416067123413
Batch 15/64 loss: 0.32535022497177124
Batch 16/64 loss: 0.3271162509918213
Batch 17/64 loss: 0.32641786336898804
Batch 18/64 loss: 0.32249319553375244
Batch 19/64 loss: 0.3202906847000122
Batch 20/64 loss: 0.3236790895462036
Batch 21/64 loss: 0.3245980739593506
Batch 22/64 loss: 0.322442889213562
Batch 23/64 loss: 0.31737589836120605
Batch 24/64 loss: 0.32055819034576416
Batch 25/64 loss: 0.32027727365493774
Batch 26/64 loss: 0.3238599896430969
Batch 27/64 loss: 0.3181271553039551
Batch 28/64 loss: 0.31875187158584595
Batch 29/64 loss: 0.3221484422683716
Batch 30/64 loss: 0.32370996475219727
Batch 31/64 loss: 0.32443541288375854
Batch 32/64 loss: 0.3226087689399719
Batch 33/64 loss: 0.3316173553466797
Batch 34/64 loss: 0.32529783248901367
Batch 35/64 loss: 0.32346057891845703
Batch 36/64 loss: 0.32574355602264404
Batch 37/64 loss: 0.32773399353027344
Batch 38/64 loss: 0.3222529888153076
Batch 39/64 loss: 0.3179359436035156
Batch 40/64 loss: 0.3257797956466675
Batch 41/64 loss: 0.32037103176116943
Batch 42/64 loss: 0.31825077533721924
Batch 43/64 loss: 0.3215183615684509
Batch 44/64 loss: 0.319252610206604
Batch 45/64 loss: 0.31941771507263184
Batch 46/64 loss: 0.3100346326828003
Batch 47/64 loss: 0.3182086944580078
Batch 48/64 loss: 0.3189805746078491
Batch 49/64 loss: 0.326593279838562
Batch 50/64 loss: 0.32776039838790894
Batch 51/64 loss: 0.32474446296691895
Batch 52/64 loss: 0.31677961349487305
Batch 53/64 loss: 0.3224745988845825
Batch 54/64 loss: 0.31627070903778076
Batch 55/64 loss: 0.32105112075805664
Batch 56/64 loss: 0.3163032531738281
Batch 57/64 loss: 0.32628679275512695
Batch 58/64 loss: 0.3142651915550232
Batch 59/64 loss: 0.321649432182312
Batch 60/64 loss: 0.32432466745376587
Batch 61/64 loss: 0.32033371925354004
Batch 62/64 loss: 0.31917035579681396
Batch 63/64 loss: 0.32762646675109863
Batch 64/64 loss: 0.31274962425231934
Epoch 44  Train loss: 0.3216995070962345  Val loss: 0.3297744534679295
Saving best model, epoch: 44
Epoch 45
-------------------------------
Batch 1/64 loss: 0.32476675510406494
Batch 2/64 loss: 0.31638312339782715
Batch 3/64 loss: 0.31737220287323
Batch 4/64 loss: 0.3246856927871704
Batch 5/64 loss: 0.318276047706604
Batch 6/64 loss: 0.31975919008255005
Batch 7/64 loss: 0.324707567691803
Batch 8/64 loss: 0.31666481494903564
Batch 9/64 loss: 0.3174457550048828
Batch 10/64 loss: 0.3153573274612427
Batch 11/64 loss: 0.324552059173584
Batch 12/64 loss: 0.32233768701553345
Batch 13/64 loss: 0.32521557807922363
Batch 14/64 loss: 0.3181653618812561
Batch 15/64 loss: 0.3225367069244385
Batch 16/64 loss: 0.3198544383049011
Batch 17/64 loss: 0.3173142671585083
Batch 18/64 loss: 0.32179486751556396
Batch 19/64 loss: 0.319410502910614
Batch 20/64 loss: 0.3180350065231323
Batch 21/64 loss: 0.32769376039505005
Batch 22/64 loss: 0.3142714500427246
Batch 23/64 loss: 0.31913304328918457
Batch 24/64 loss: 0.3165431618690491
Batch 25/64 loss: 0.3220475912094116
Batch 26/64 loss: 0.31885313987731934
Batch 27/64 loss: 0.31514161825180054
Batch 28/64 loss: 0.3270000219345093
Batch 29/64 loss: 0.32475745677948
Batch 30/64 loss: 0.3219105005264282
Batch 31/64 loss: 0.32690513134002686
Batch 32/64 loss: 0.3268374800682068
Batch 33/64 loss: 0.3176500201225281
Batch 34/64 loss: 0.3192048668861389
Batch 35/64 loss: 0.3269343376159668
Batch 36/64 loss: 0.31887900829315186
Batch 37/64 loss: 0.325542151927948
Batch 38/64 loss: 0.3195722699165344
Batch 39/64 loss: 0.3253765106201172
Batch 40/64 loss: 0.32208454608917236
Batch 41/64 loss: 0.3212851285934448
Batch 42/64 loss: 0.32035279273986816
Batch 43/64 loss: 0.32656294107437134
Batch 44/64 loss: 0.3174092769622803
Batch 45/64 loss: 0.32410889863967896
Batch 46/64 loss: 0.3209787607192993
Batch 47/64 loss: 0.3239624500274658
Batch 48/64 loss: 0.31703752279281616
Batch 49/64 loss: 0.3187815546989441
Batch 50/64 loss: 0.3175637722015381
Batch 51/64 loss: 0.32470083236694336
Batch 52/64 loss: 0.3250420093536377
Batch 53/64 loss: 0.3242616653442383
Batch 54/64 loss: 0.31690382957458496
Batch 55/64 loss: 0.31434983015060425
Batch 56/64 loss: 0.3174041509628296
Batch 57/64 loss: 0.3166290521621704
Batch 58/64 loss: 0.32239460945129395
Batch 59/64 loss: 0.3231772780418396
Batch 60/64 loss: 0.31838715076446533
Batch 61/64 loss: 0.32833194732666016
Batch 62/64 loss: 0.31985461711883545
Batch 63/64 loss: 0.31877756118774414
Batch 64/64 loss: 0.3253937363624573
Epoch 45  Train loss: 0.32099256398631076  Val loss: 0.32837386065741997
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: 0.32396233081817627
Batch 2/64 loss: 0.31882965564727783
Batch 3/64 loss: 0.3216109275817871
Batch 4/64 loss: 0.31744879484176636
Batch 5/64 loss: 0.32148319482803345
Batch 6/64 loss: 0.317619264125824
Batch 7/64 loss: 0.3162662982940674
Batch 8/64 loss: 0.31858009099960327
Batch 9/64 loss: 0.31425201892852783
Batch 10/64 loss: 0.31337642669677734
Batch 11/64 loss: 0.31587040424346924
Batch 12/64 loss: 0.3211897611618042
Batch 13/64 loss: 0.31509989500045776
Batch 14/64 loss: 0.32024121284484863
Batch 15/64 loss: 0.31717270612716675
Batch 16/64 loss: 0.3173776865005493
Batch 17/64 loss: 0.32240617275238037
Batch 18/64 loss: 0.3212742209434509
Batch 19/64 loss: 0.32387876510620117
Batch 20/64 loss: 0.32071495056152344
Batch 21/64 loss: 0.32366323471069336
Batch 22/64 loss: 0.31943249702453613
Batch 23/64 loss: 0.31703877449035645
Batch 24/64 loss: 0.3199242353439331
Batch 25/64 loss: 0.3144652843475342
Batch 26/64 loss: 0.31356728076934814
Batch 27/64 loss: 0.3156742453575134
Batch 28/64 loss: 0.31104886531829834
Batch 29/64 loss: 0.3206731081008911
Batch 30/64 loss: 0.3207376003265381
Batch 31/64 loss: 0.3238109350204468
Batch 32/64 loss: 0.32009172439575195
Batch 33/64 loss: 0.3232482671737671
Batch 34/64 loss: 0.3200547695159912
Batch 35/64 loss: 0.3242543339729309
Batch 36/64 loss: 0.32101690769195557
Batch 37/64 loss: 0.31461799144744873
Batch 38/64 loss: 0.31774693727493286
Batch 39/64 loss: 0.3152710795402527
Batch 40/64 loss: 0.3239806890487671
Batch 41/64 loss: 0.31471508741378784
Batch 42/64 loss: 0.3249202370643616
Batch 43/64 loss: 0.31451094150543213
Batch 44/64 loss: 0.31491798162460327
Batch 45/64 loss: 0.3158271908760071
Batch 46/64 loss: 0.3172081708908081
Batch 47/64 loss: 0.317168653011322
Batch 48/64 loss: 0.3193410634994507
Batch 49/64 loss: 0.31972736120224
Batch 50/64 loss: 0.31794023513793945
Batch 51/64 loss: 0.32172322273254395
Batch 52/64 loss: 0.3175966143608093
Batch 53/64 loss: 0.3215908408164978
Batch 54/64 loss: 0.3201436996459961
Batch 55/64 loss: 0.3273410201072693
Batch 56/64 loss: 0.31984907388687134
Batch 57/64 loss: 0.3322809338569641
Batch 58/64 loss: 0.32219594717025757
Batch 59/64 loss: 0.32278281450271606
Batch 60/64 loss: 0.31623005867004395
Batch 61/64 loss: 0.32156896591186523
Batch 62/64 loss: 0.3143599033355713
Batch 63/64 loss: 0.32057470083236694
Batch 64/64 loss: 0.31484246253967285
Epoch 46  Train loss: 0.31920972711899703  Val loss: 0.3264175188500447
Saving best model, epoch: 46
Epoch 47
-------------------------------
Batch 1/64 loss: 0.31782686710357666
Batch 2/64 loss: 0.3198239803314209
Batch 3/64 loss: 0.319030225276947
Batch 4/64 loss: 0.3163493871688843
Batch 5/64 loss: 0.3215194344520569
Batch 6/64 loss: 0.30985748767852783
Batch 7/64 loss: 0.31960058212280273
Batch 8/64 loss: 0.31673741340637207
Batch 9/64 loss: 0.3148428797721863
Batch 10/64 loss: 0.31663453578948975
Batch 11/64 loss: 0.31954097747802734
Batch 12/64 loss: 0.3138014078140259
Batch 13/64 loss: 0.31603848934173584
Batch 14/64 loss: 0.3167128562927246
Batch 15/64 loss: 0.3177333474159241
Batch 16/64 loss: 0.307986855506897
Batch 17/64 loss: 0.3160216808319092
Batch 18/64 loss: 0.3167549967765808
Batch 19/64 loss: 0.31843143701553345
Batch 20/64 loss: 0.3223443031311035
Batch 21/64 loss: 0.3165276050567627
Batch 22/64 loss: 0.31723183393478394
Batch 23/64 loss: 0.3226775527000427
Batch 24/64 loss: 0.31335705518722534
Batch 25/64 loss: 0.3216310739517212
Batch 26/64 loss: 0.31903600692749023
Batch 27/64 loss: 0.3114742040634155
Batch 28/64 loss: 0.31421220302581787
Batch 29/64 loss: 0.31755727529525757
Batch 30/64 loss: 0.31855207681655884
Batch 31/64 loss: 0.31663501262664795
Batch 32/64 loss: 0.31655776500701904
Batch 33/64 loss: 0.31474900245666504
Batch 34/64 loss: 0.318231463432312
Batch 35/64 loss: 0.31988608837127686
Batch 36/64 loss: 0.3236476182937622
Batch 37/64 loss: 0.31552475690841675
Batch 38/64 loss: 0.31763511896133423
Batch 39/64 loss: 0.318456768989563
Batch 40/64 loss: 0.31940317153930664
Batch 41/64 loss: 0.3155097961425781
Batch 42/64 loss: 0.3192209005355835
Batch 43/64 loss: 0.3166402578353882
Batch 44/64 loss: 0.311435341835022
Batch 45/64 loss: 0.32083314657211304
Batch 46/64 loss: 0.32234853506088257
Batch 47/64 loss: 0.328788161277771
Batch 48/64 loss: 0.3274010419845581
Batch 49/64 loss: 0.31605589389801025
Batch 50/64 loss: 0.31810009479522705
Batch 51/64 loss: 0.3227272033691406
Batch 52/64 loss: 0.31725525856018066
Batch 53/64 loss: 0.3268679976463318
Batch 54/64 loss: 0.321134090423584
Batch 55/64 loss: 0.33037781715393066
Batch 56/64 loss: 0.321261465549469
Batch 57/64 loss: 0.3171529769897461
Batch 58/64 loss: 0.3223888874053955
Batch 59/64 loss: 0.31691569089889526
Batch 60/64 loss: 0.31751835346221924
Batch 61/64 loss: 0.32128071784973145
Batch 62/64 loss: 0.3211483955383301
Batch 63/64 loss: 0.3205794095993042
Batch 64/64 loss: 0.31588393449783325
Epoch 47  Train loss: 0.31843807346680586  Val loss: 0.32718408681273053
Epoch 48
-------------------------------
Batch 1/64 loss: 0.3204364776611328
Batch 2/64 loss: 0.3212888240814209
Batch 3/64 loss: 0.32270246744155884
Batch 4/64 loss: 0.31271517276763916
Batch 5/64 loss: 0.31937992572784424
Batch 6/64 loss: 0.31685805320739746
Batch 7/64 loss: 0.3149469494819641
Batch 8/64 loss: 0.3212714195251465
Batch 9/64 loss: 0.3144533634185791
Batch 10/64 loss: 0.315893292427063
Batch 11/64 loss: 0.31551265716552734
Batch 12/64 loss: 0.31147563457489014
Batch 13/64 loss: 0.31608593463897705
Batch 14/64 loss: 0.31827718019485474
Batch 15/64 loss: 0.3179202079772949
Batch 16/64 loss: 0.31856220960617065
Batch 17/64 loss: 0.3124834895133972
Batch 18/64 loss: 0.3223723769187927
Batch 19/64 loss: 0.32088160514831543
Batch 20/64 loss: 0.3145119547843933
Batch 21/64 loss: 0.3165827989578247
Batch 22/64 loss: 0.3165042996406555
Batch 23/64 loss: 0.3161720633506775
Batch 24/64 loss: 0.3213340640068054
Batch 25/64 loss: 0.32089608907699585
Batch 26/64 loss: 0.32040518522262573
Batch 27/64 loss: 0.3254786729812622
Batch 28/64 loss: 0.31101077795028687
Batch 29/64 loss: 0.31245505809783936
Batch 30/64 loss: 0.3219938278198242
Batch 31/64 loss: 0.31735414266586304
Batch 32/64 loss: 0.31084543466567993
Batch 33/64 loss: 0.31964313983917236
Batch 34/64 loss: 0.321008563041687
Batch 35/64 loss: 0.3219687342643738
Batch 36/64 loss: 0.3115692138671875
Batch 37/64 loss: 0.31844037771224976
Batch 38/64 loss: 0.3076591491699219
Batch 39/64 loss: 0.31876111030578613
Batch 40/64 loss: 0.3142557740211487
Batch 41/64 loss: 0.3158804178237915
Batch 42/64 loss: 0.31319403648376465
Batch 43/64 loss: 0.3235725164413452
Batch 44/64 loss: 0.318641722202301
Batch 45/64 loss: 0.31509125232696533
Batch 46/64 loss: 0.31978797912597656
Batch 47/64 loss: 0.31281578540802
Batch 48/64 loss: 0.3149433135986328
Batch 49/64 loss: 0.30995213985443115
Batch 50/64 loss: 0.31923365592956543
Batch 51/64 loss: 0.32393914461135864
Batch 52/64 loss: 0.3173069953918457
Batch 53/64 loss: 0.32040393352508545
Batch 54/64 loss: 0.3147055506706238
Batch 55/64 loss: 0.3165052533149719
Batch 56/64 loss: 0.31515252590179443
Batch 57/64 loss: 0.3188668489456177
Batch 58/64 loss: 0.3148244619369507
Batch 59/64 loss: 0.3137662410736084
Batch 60/64 loss: 0.31293314695358276
Batch 61/64 loss: 0.32130444049835205
Batch 62/64 loss: 0.31378495693206787
Batch 63/64 loss: 0.3150806427001953
Batch 64/64 loss: 0.31678658723831177
Epoch 48  Train loss: 0.31704540509803625  Val loss: 0.3270598086704503
Epoch 49
-------------------------------
Batch 1/64 loss: 0.31740862131118774
Batch 2/64 loss: 0.3073423504829407
Batch 3/64 loss: 0.31689584255218506
Batch 4/64 loss: 0.3073180913925171
Batch 5/64 loss: 0.3186922073364258
Batch 6/64 loss: 0.31473779678344727
Batch 7/64 loss: 0.3110593557357788
Batch 8/64 loss: 0.3146219849586487
Batch 9/64 loss: 0.31449514627456665
Batch 10/64 loss: 0.31590092182159424
Batch 11/64 loss: 0.3151789903640747
Batch 12/64 loss: 0.31990522146224976
Batch 13/64 loss: 0.318229079246521
Batch 14/64 loss: 0.31535208225250244
Batch 15/64 loss: 0.3151392936706543
Batch 16/64 loss: 0.31488704681396484
Batch 17/64 loss: 0.31439828872680664
Batch 18/64 loss: 0.3180747628211975
Batch 19/64 loss: 0.31429678201675415
Batch 20/64 loss: 0.31391990184783936
Batch 21/64 loss: 0.3145437240600586
Batch 22/64 loss: 0.3148483633995056
Batch 23/64 loss: 0.317376971244812
Batch 24/64 loss: 0.31454384326934814
Batch 25/64 loss: 0.3155842423439026
Batch 26/64 loss: 0.32003283500671387
Batch 27/64 loss: 0.31016451120376587
Batch 28/64 loss: 0.3087606430053711
Batch 29/64 loss: 0.32023847103118896
Batch 30/64 loss: 0.31689703464508057
Batch 31/64 loss: 0.3211115598678589
Batch 32/64 loss: 0.3266701102256775
Batch 33/64 loss: 0.31520748138427734
Batch 34/64 loss: 0.31742894649505615
Batch 35/64 loss: 0.3224067687988281
Batch 36/64 loss: 0.3179802894592285
Batch 37/64 loss: 0.3202899694442749
Batch 38/64 loss: 0.3097116947174072
Batch 39/64 loss: 0.32096004486083984
Batch 40/64 loss: 0.3177531957626343
Batch 41/64 loss: 0.3137025833129883
Batch 42/64 loss: 0.3125804662704468
Batch 43/64 loss: 0.31809890270233154
Batch 44/64 loss: 0.31200945377349854
Batch 45/64 loss: 0.30988597869873047
Batch 46/64 loss: 0.3178904056549072
Batch 47/64 loss: 0.3138653635978699
Batch 48/64 loss: 0.31773489713668823
Batch 49/64 loss: 0.31786710023880005
Batch 50/64 loss: 0.3145878314971924
Batch 51/64 loss: 0.31727802753448486
Batch 52/64 loss: 0.3172872066497803
Batch 53/64 loss: 0.30881381034851074
Batch 54/64 loss: 0.31524431705474854
Batch 55/64 loss: 0.316816508769989
Batch 56/64 loss: 0.3181039094924927
Batch 57/64 loss: 0.3101215362548828
Batch 58/64 loss: 0.319896936416626
Batch 59/64 loss: 0.3112391233444214
Batch 60/64 loss: 0.3216608762741089
Batch 61/64 loss: 0.31978273391723633
Batch 62/64 loss: 0.31684988737106323
Batch 63/64 loss: 0.3224271535873413
Batch 64/64 loss: 0.31873542070388794
Epoch 49  Train loss: 0.31597115362391753  Val loss: 0.3257956764952014
Saving best model, epoch: 49
Epoch 50
-------------------------------
Batch 1/64 loss: 0.31752651929855347
Batch 2/64 loss: 0.3083970546722412
Batch 3/64 loss: 0.3131754994392395
Batch 4/64 loss: 0.307827353477478
Batch 5/64 loss: 0.3161158561706543
Batch 6/64 loss: 0.3130875825881958
Batch 7/64 loss: 0.3182920813560486
Batch 8/64 loss: 0.3098914623260498
Batch 9/64 loss: 0.31697559356689453
Batch 10/64 loss: 0.3137861490249634
Batch 11/64 loss: 0.32279300689697266
Batch 12/64 loss: 0.31668972969055176
Batch 13/64 loss: 0.32110750675201416
Batch 14/64 loss: 0.3157087564468384
Batch 15/64 loss: 0.3163071870803833
Batch 16/64 loss: 0.3226637840270996
Batch 17/64 loss: 0.31718504428863525
Batch 18/64 loss: 0.314755916595459
Batch 19/64 loss: 0.3192853331565857
Batch 20/64 loss: 0.31574445962905884
Batch 21/64 loss: 0.31772977113723755
Batch 22/64 loss: 0.31374627351760864
Batch 23/64 loss: 0.3126094937324524
Batch 24/64 loss: 0.3092862367630005
Batch 25/64 loss: 0.31492018699645996
Batch 26/64 loss: 0.3143994212150574
Batch 27/64 loss: 0.3127979040145874
Batch 28/64 loss: 0.31006044149398804
Batch 29/64 loss: 0.315443754196167
Batch 30/64 loss: 0.3220409154891968
Batch 31/64 loss: 0.31921303272247314
Batch 32/64 loss: 0.31549638509750366
Batch 33/64 loss: 0.3155086040496826
Batch 34/64 loss: 0.3131129741668701
Batch 35/64 loss: 0.3123719096183777
Batch 36/64 loss: 0.3180011510848999
Batch 37/64 loss: 0.3188997507095337
Batch 38/64 loss: 0.3118475675582886
Batch 39/64 loss: 0.31023311614990234
Batch 40/64 loss: 0.31654709577560425
Batch 41/64 loss: 0.32077109813690186
Batch 42/64 loss: 0.3168913722038269
Batch 43/64 loss: 0.3136955499649048
Batch 44/64 loss: 0.31370341777801514
Batch 45/64 loss: 0.31655222177505493
Batch 46/64 loss: 0.3233345150947571
Batch 47/64 loss: 0.31307893991470337
Batch 48/64 loss: 0.3114473819732666
Batch 49/64 loss: 0.3163038492202759
Batch 50/64 loss: 0.31611281633377075
Batch 51/64 loss: 0.3088461756706238
Batch 52/64 loss: 0.31580251455307007
Batch 53/64 loss: 0.31485986709594727
Batch 54/64 loss: 0.3204677104949951
Batch 55/64 loss: 0.31832027435302734
Batch 56/64 loss: 0.3216940760612488
Batch 57/64 loss: 0.31048470735549927
Batch 58/64 loss: 0.3184909224510193
Batch 59/64 loss: 0.31460005044937134
Batch 60/64 loss: 0.3223801851272583
Batch 61/64 loss: 0.3106936812400818
Batch 62/64 loss: 0.3114511966705322
Batch 63/64 loss: 0.31781136989593506
Batch 64/64 loss: 0.31755244731903076
Epoch 50  Train loss: 0.31556925633374383  Val loss: 0.3241730074292606
Saving best model, epoch: 50
Epoch 51
-------------------------------
Batch 1/64 loss: 0.3086972236633301
Batch 2/64 loss: 0.3165726661682129
Batch 3/64 loss: 0.31598353385925293
Batch 4/64 loss: 0.3139951229095459
Batch 5/64 loss: 0.31145375967025757
Batch 6/64 loss: 0.30617815256118774
Batch 7/64 loss: 0.31789064407348633
Batch 8/64 loss: 0.3175235390663147
Batch 9/64 loss: 0.31412947177886963
Batch 10/64 loss: 0.3057718276977539
Batch 11/64 loss: 0.3085945248603821
Batch 12/64 loss: 0.3141477108001709
Batch 13/64 loss: 0.31178951263427734
Batch 14/64 loss: 0.31132960319519043
Batch 15/64 loss: 0.31003403663635254
Batch 16/64 loss: 0.3195852041244507
Batch 17/64 loss: 0.31004762649536133
Batch 18/64 loss: 0.3193325996398926
Batch 19/64 loss: 0.31980645656585693
Batch 20/64 loss: 0.3138030767440796
Batch 21/64 loss: 0.3084578514099121
Batch 22/64 loss: 0.3159789443016052
Batch 23/64 loss: 0.31807243824005127
Batch 24/64 loss: 0.3112601041793823
Batch 25/64 loss: 0.3186274766921997
Batch 26/64 loss: 0.3121616244316101
Batch 27/64 loss: 0.32282066345214844
Batch 28/64 loss: 0.31728267669677734
Batch 29/64 loss: 0.3162670135498047
Batch 30/64 loss: 0.31726187467575073
Batch 31/64 loss: 0.3113178014755249
Batch 32/64 loss: 0.3131589889526367
Batch 33/64 loss: 0.3145254850387573
Batch 34/64 loss: 0.31302881240844727
Batch 35/64 loss: 0.31361639499664307
Batch 36/64 loss: 0.3179014325141907
Batch 37/64 loss: 0.3147609233856201
Batch 38/64 loss: 0.3105740547180176
Batch 39/64 loss: 0.3144841194152832
Batch 40/64 loss: 0.30573439598083496
Batch 41/64 loss: 0.31817394495010376
Batch 42/64 loss: 0.3197862505912781
Batch 43/64 loss: 0.3174407482147217
Batch 44/64 loss: 0.3139427900314331
Batch 45/64 loss: 0.31109243631362915
Batch 46/64 loss: 0.3109325170516968
Batch 47/64 loss: 0.32069504261016846
Batch 48/64 loss: 0.30713987350463867
Batch 49/64 loss: 0.3210620880126953
Batch 50/64 loss: 0.3146047592163086
Batch 51/64 loss: 0.3092796802520752
Batch 52/64 loss: 0.30830490589141846
Batch 53/64 loss: 0.31793051958084106
Batch 54/64 loss: 0.315631628036499
Batch 55/64 loss: 0.3166145086288452
Batch 56/64 loss: 0.30727696418762207
Batch 57/64 loss: 0.3149687647819519
Batch 58/64 loss: 0.31236791610717773
Batch 59/64 loss: 0.3184795379638672
Batch 60/64 loss: 0.3066641688346863
Batch 61/64 loss: 0.3119097948074341
Batch 62/64 loss: 0.3139249086380005
Batch 63/64 loss: 0.3109755516052246
Batch 64/64 loss: 0.3221668004989624
Epoch 51  Train loss: 0.31395739246817195  Val loss: 0.32329242827556387
Saving best model, epoch: 51
Epoch 52
-------------------------------
Batch 1/64 loss: 0.31100761890411377
Batch 2/64 loss: 0.31302523612976074
Batch 3/64 loss: 0.312261700630188
Batch 4/64 loss: 0.30740654468536377
Batch 5/64 loss: 0.3109879493713379
Batch 6/64 loss: 0.31527477502822876
Batch 7/64 loss: 0.3177270293235779
Batch 8/64 loss: 0.3170173168182373
Batch 9/64 loss: 0.3217952251434326
Batch 10/64 loss: 0.31637513637542725
Batch 11/64 loss: 0.3110382556915283
Batch 12/64 loss: 0.30276966094970703
Batch 13/64 loss: 0.31368088722229004
Batch 14/64 loss: 0.31084275245666504
Batch 15/64 loss: 0.3063136339187622
Batch 16/64 loss: 0.3173714876174927
Batch 17/64 loss: 0.309983491897583
Batch 18/64 loss: 0.3151911497116089
Batch 19/64 loss: 0.308957576751709
Batch 20/64 loss: 0.309955894947052
Batch 21/64 loss: 0.3152538537979126
Batch 22/64 loss: 0.31128817796707153
Batch 23/64 loss: 0.3149104118347168
Batch 24/64 loss: 0.320517897605896
Batch 25/64 loss: 0.3061385750770569
Batch 26/64 loss: 0.3129626512527466
Batch 27/64 loss: 0.3195679783821106
Batch 28/64 loss: 0.31594181060791016
Batch 29/64 loss: 0.3188059329986572
Batch 30/64 loss: 0.3113445043563843
Batch 31/64 loss: 0.30612999200820923
Batch 32/64 loss: 0.3156782388687134
Batch 33/64 loss: 0.30711430311203003
Batch 34/64 loss: 0.31309062242507935
Batch 35/64 loss: 0.30937039852142334
Batch 36/64 loss: 0.30903440713882446
Batch 37/64 loss: 0.3137030005455017
Batch 38/64 loss: 0.3068366050720215
Batch 39/64 loss: 0.3080739974975586
Batch 40/64 loss: 0.31104761362075806
Batch 41/64 loss: 0.3172694444656372
Batch 42/64 loss: 0.3147900104522705
Batch 43/64 loss: 0.3100097179412842
Batch 44/64 loss: 0.3121899366378784
Batch 45/64 loss: 0.3123464584350586
Batch 46/64 loss: 0.31052660942077637
Batch 47/64 loss: 0.31115996837615967
Batch 48/64 loss: 0.3144824504852295
Batch 49/64 loss: 0.32147932052612305
Batch 50/64 loss: 0.30455219745635986
Batch 51/64 loss: 0.31170225143432617
Batch 52/64 loss: 0.30952179431915283
Batch 53/64 loss: 0.31156766414642334
Batch 54/64 loss: 0.3131457567214966
Batch 55/64 loss: 0.31859779357910156
Batch 56/64 loss: 0.31324541568756104
Batch 57/64 loss: 0.31350648403167725
Batch 58/64 loss: 0.31673574447631836
Batch 59/64 loss: 0.3135451674461365
Batch 60/64 loss: 0.31837934255599976
Batch 61/64 loss: 0.3136618733406067
Batch 62/64 loss: 0.31594306230545044
Batch 63/64 loss: 0.31194353103637695
Batch 64/64 loss: 0.31314516067504883
Epoch 52  Train loss: 0.3127992966595818  Val loss: 0.32276056496957733
Saving best model, epoch: 52
Epoch 53
-------------------------------
Batch 1/64 loss: 0.3184400796890259
Batch 2/64 loss: 0.3137272596359253
Batch 3/64 loss: 0.3126262426376343
Batch 4/64 loss: 0.3040804862976074
Batch 5/64 loss: 0.3166518211364746
Batch 6/64 loss: 0.31528472900390625
Batch 7/64 loss: 0.31841498613357544
Batch 8/64 loss: 0.30673646926879883
Batch 9/64 loss: 0.31102967262268066
Batch 10/64 loss: 0.31124675273895264
Batch 11/64 loss: 0.3166327476501465
Batch 12/64 loss: 0.31376153230667114
Batch 13/64 loss: 0.3140428066253662
Batch 14/64 loss: 0.3107699751853943
Batch 15/64 loss: 0.3173799514770508
Batch 16/64 loss: 0.3103523254394531
Batch 17/64 loss: 0.31882548332214355
Batch 18/64 loss: 0.3081350326538086
Batch 19/64 loss: 0.30472612380981445
Batch 20/64 loss: 0.3119368553161621
Batch 21/64 loss: 0.308870792388916
Batch 22/64 loss: 0.32123374938964844
Batch 23/64 loss: 0.31054937839508057
Batch 24/64 loss: 0.31266796588897705
Batch 25/64 loss: 0.3096114993095398
Batch 26/64 loss: 0.31304293870925903
Batch 27/64 loss: 0.31306928396224976
Batch 28/64 loss: 0.3175312280654907
Batch 29/64 loss: 0.3196605443954468
Batch 30/64 loss: 0.31786131858825684
Batch 31/64 loss: 0.3140694499015808
Batch 32/64 loss: 0.30349665880203247
Batch 33/64 loss: 0.31199944019317627
Batch 34/64 loss: 0.31328344345092773
Batch 35/64 loss: 0.3143994212150574
Batch 36/64 loss: 0.31290286779403687
Batch 37/64 loss: 0.3093714118003845
Batch 38/64 loss: 0.30874812602996826
Batch 39/64 loss: 0.31810182332992554
Batch 40/64 loss: 0.31099194288253784
Batch 41/64 loss: 0.3120726943016052
Batch 42/64 loss: 0.3097940683364868
Batch 43/64 loss: 0.3090030550956726
Batch 44/64 loss: 0.3136460781097412
Batch 45/64 loss: 0.3095039129257202
Batch 46/64 loss: 0.3162704110145569
Batch 47/64 loss: 0.3118390440940857
Batch 48/64 loss: 0.3105822801589966
Batch 49/64 loss: 0.3163261413574219
Batch 50/64 loss: 0.30698907375335693
Batch 51/64 loss: 0.31318235397338867
Batch 52/64 loss: 0.3115108013153076
Batch 53/64 loss: 0.3075006604194641
Batch 54/64 loss: 0.3086093068122864
Batch 55/64 loss: 0.31766098737716675
Batch 56/64 loss: 0.30796682834625244
Batch 57/64 loss: 0.3129469156265259
Batch 58/64 loss: 0.3079671859741211
Batch 59/64 loss: 0.3104010820388794
Batch 60/64 loss: 0.3134087920188904
Batch 61/64 loss: 0.3063499927520752
Batch 62/64 loss: 0.31031954288482666
Batch 63/64 loss: 0.310802161693573
Batch 64/64 loss: 0.3076174259185791
Epoch 53  Train loss: 0.3121824479570576  Val loss: 0.3214683639224862
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: 0.3121100068092346
Batch 2/64 loss: 0.30845367908477783
Batch 3/64 loss: 0.3203010559082031
Batch 4/64 loss: 0.3139045238494873
Batch 5/64 loss: 0.31416428089141846
Batch 6/64 loss: 0.3146502375602722
Batch 7/64 loss: 0.3162705898284912
Batch 8/64 loss: 0.30865830183029175
Batch 9/64 loss: 0.3091472387313843
Batch 10/64 loss: 0.3108634948730469
Batch 11/64 loss: 0.3126415014266968
Batch 12/64 loss: 0.3122711777687073
Batch 13/64 loss: 0.3120848536491394
Batch 14/64 loss: 0.3027968406677246
Batch 15/64 loss: 0.3135190010070801
Batch 16/64 loss: 0.3112947940826416
Batch 17/64 loss: 0.3101513385772705
Batch 18/64 loss: 0.30549120903015137
Batch 19/64 loss: 0.316133975982666
Batch 20/64 loss: 0.3085601329803467
Batch 21/64 loss: 0.31420785188674927
Batch 22/64 loss: 0.3068913221359253
Batch 23/64 loss: 0.3125208616256714
Batch 24/64 loss: 0.3068392872810364
Batch 25/64 loss: 0.31384575366973877
Batch 26/64 loss: 0.3144856095314026
Batch 27/64 loss: 0.31046879291534424
Batch 28/64 loss: 0.31088411808013916
Batch 29/64 loss: 0.3127729296684265
Batch 30/64 loss: 0.31049299240112305
Batch 31/64 loss: 0.3077765107154846
Batch 32/64 loss: 0.3100166320800781
Batch 33/64 loss: 0.31616437435150146
Batch 34/64 loss: 0.3167191743850708
Batch 35/64 loss: 0.3102650046348572
Batch 36/64 loss: 0.3133842945098877
Batch 37/64 loss: 0.31221693754196167
Batch 38/64 loss: 0.3076567053794861
Batch 39/64 loss: 0.308013916015625
Batch 40/64 loss: 0.3063812851905823
Batch 41/64 loss: 0.3059350848197937
Batch 42/64 loss: 0.30682122707366943
Batch 43/64 loss: 0.3111841082572937
Batch 44/64 loss: 0.3127116560935974
Batch 45/64 loss: 0.31226831674575806
Batch 46/64 loss: 0.3090633749961853
Batch 47/64 loss: 0.3081067204475403
Batch 48/64 loss: 0.31088942289352417
Batch 49/64 loss: 0.31660377979278564
Batch 50/64 loss: 0.30996572971343994
Batch 51/64 loss: 0.30503010749816895
Batch 52/64 loss: 0.31440871953964233
Batch 53/64 loss: 0.3202487826347351
Batch 54/64 loss: 0.3071938753128052
Batch 55/64 loss: 0.3099521994590759
Batch 56/64 loss: 0.3089102506637573
Batch 57/64 loss: 0.3131445646286011
Batch 58/64 loss: 0.3054083585739136
Batch 59/64 loss: 0.309916615486145
Batch 60/64 loss: 0.3133063316345215
Batch 61/64 loss: 0.3118278980255127
Batch 62/64 loss: 0.3120635747909546
Batch 63/64 loss: 0.3123764991760254
Batch 64/64 loss: 0.30909568071365356
Epoch 54  Train loss: 0.3111314752522637  Val loss: 0.32037514919267895
Saving best model, epoch: 54
Epoch 55
-------------------------------
Batch 1/64 loss: 0.3121914267539978
Batch 2/64 loss: 0.3138759136199951
Batch 3/64 loss: 0.3076193332672119
Batch 4/64 loss: 0.3063035011291504
Batch 5/64 loss: 0.31674301624298096
Batch 6/64 loss: 0.30240190029144287
Batch 7/64 loss: 0.3140922784805298
Batch 8/64 loss: 0.3179926872253418
Batch 9/64 loss: 0.30641400814056396
Batch 10/64 loss: 0.30938291549682617
Batch 11/64 loss: 0.3102494478225708
Batch 12/64 loss: 0.31211185455322266
Batch 13/64 loss: 0.3068246841430664
Batch 14/64 loss: 0.305202841758728
Batch 15/64 loss: 0.311761736869812
Batch 16/64 loss: 0.3074162006378174
Batch 17/64 loss: 0.30467289686203003
Batch 18/64 loss: 0.3052470088005066
Batch 19/64 loss: 0.31770384311676025
Batch 20/64 loss: 0.3023768663406372
Batch 21/64 loss: 0.3177216649055481
Batch 22/64 loss: 0.30574071407318115
Batch 23/64 loss: 0.3131141662597656
Batch 24/64 loss: 0.3091210722923279
Batch 25/64 loss: 0.30649280548095703
Batch 26/64 loss: 0.30751073360443115
Batch 27/64 loss: 0.3113940954208374
Batch 28/64 loss: 0.3122595548629761
Batch 29/64 loss: 0.3132173418998718
Batch 30/64 loss: 0.3066200017929077
Batch 31/64 loss: 0.31136393547058105
Batch 32/64 loss: 0.30105018615722656
Batch 33/64 loss: 0.31264013051986694
Batch 34/64 loss: 0.31599926948547363
Batch 35/64 loss: 0.3114909529685974
Batch 36/64 loss: 0.3065997362136841
Batch 37/64 loss: 0.3081240653991699
Batch 38/64 loss: 0.3068220615386963
Batch 39/64 loss: 0.3187747001647949
Batch 40/64 loss: 0.3155207633972168
Batch 41/64 loss: 0.31444722414016724
Batch 42/64 loss: 0.30409419536590576
Batch 43/64 loss: 0.3080950379371643
Batch 44/64 loss: 0.31037139892578125
Batch 45/64 loss: 0.3100191354751587
Batch 46/64 loss: 0.30519741773605347
Batch 47/64 loss: 0.3086435794830322
Batch 48/64 loss: 0.32227373123168945
Batch 49/64 loss: 0.31122326850891113
Batch 50/64 loss: 0.3119937777519226
Batch 51/64 loss: 0.31028270721435547
Batch 52/64 loss: 0.30953896045684814
Batch 53/64 loss: 0.3160984516143799
Batch 54/64 loss: 0.3079719543457031
Batch 55/64 loss: 0.3118588328361511
Batch 56/64 loss: 0.3103404641151428
Batch 57/64 loss: 0.3083575963973999
Batch 58/64 loss: 0.3119523525238037
Batch 59/64 loss: 0.3064157962799072
Batch 60/64 loss: 0.30620384216308594
Batch 61/64 loss: 0.3078621029853821
Batch 62/64 loss: 0.3120152950286865
Batch 63/64 loss: 0.30054694414138794
Batch 64/64 loss: 0.30918407440185547
Epoch 55  Train loss: 0.30995850095561905  Val loss: 0.32206481326486647
Epoch 56
-------------------------------
Batch 1/64 loss: 0.3049233555793762
Batch 2/64 loss: 0.3112279772758484
Batch 3/64 loss: 0.30382901430130005
Batch 4/64 loss: 0.3050847053527832
Batch 5/64 loss: 0.30819445848464966
Batch 6/64 loss: 0.3041321039199829
Batch 7/64 loss: 0.3063386082649231
Batch 8/64 loss: 0.30330222845077515
Batch 9/64 loss: 0.31199347972869873
Batch 10/64 loss: 0.3140867352485657
Batch 11/64 loss: 0.3081205487251282
Batch 12/64 loss: 0.3112020492553711
Batch 13/64 loss: 0.3065665364265442
Batch 14/64 loss: 0.3051711320877075
Batch 15/64 loss: 0.3065739870071411
Batch 16/64 loss: 0.30169224739074707
Batch 17/64 loss: 0.3114616870880127
Batch 18/64 loss: 0.30565714836120605
Batch 19/64 loss: 0.31815671920776367
Batch 20/64 loss: 0.30556321144104004
Batch 21/64 loss: 0.3111264109611511
Batch 22/64 loss: 0.30527788400650024
Batch 23/64 loss: 0.3193686008453369
Batch 24/64 loss: 0.30993980169296265
Batch 25/64 loss: 0.30624717473983765
Batch 26/64 loss: 0.3144341707229614
Batch 27/64 loss: 0.3095417618751526
Batch 28/64 loss: 0.3088498115539551
Batch 29/64 loss: 0.309658944606781
Batch 30/64 loss: 0.31265854835510254
Batch 31/64 loss: 0.3172491788864136
Batch 32/64 loss: 0.31435149908065796
Batch 33/64 loss: 0.3017258644104004
Batch 34/64 loss: 0.3186761140823364
Batch 35/64 loss: 0.3081347346305847
Batch 36/64 loss: 0.3094594478607178
Batch 37/64 loss: 0.3041236400604248
Batch 38/64 loss: 0.310813307762146
Batch 39/64 loss: 0.3027135133743286
Batch 40/64 loss: 0.30794697999954224
Batch 41/64 loss: 0.31271183490753174
Batch 42/64 loss: 0.3129923343658447
Batch 43/64 loss: 0.3145555257797241
Batch 44/64 loss: 0.313978910446167
Batch 45/64 loss: 0.3152289390563965
Batch 46/64 loss: 0.30083799362182617
Batch 47/64 loss: 0.30986297130584717
Batch 48/64 loss: 0.3047419786453247
Batch 49/64 loss: 0.315429151058197
Batch 50/64 loss: 0.3097410202026367
Batch 51/64 loss: 0.3022482991218567
Batch 52/64 loss: 0.3163890242576599
Batch 53/64 loss: 0.303821861743927
Batch 54/64 loss: 0.30590105056762695
Batch 55/64 loss: 0.31699472665786743
Batch 56/64 loss: 0.31336069107055664
Batch 57/64 loss: 0.3101125955581665
Batch 58/64 loss: 0.30708563327789307
Batch 59/64 loss: 0.3121758699417114
Batch 60/64 loss: 0.31507158279418945
Batch 61/64 loss: 0.31133246421813965
Batch 62/64 loss: 0.3139340877532959
Batch 63/64 loss: 0.3093739151954651
Batch 64/64 loss: 0.31269240379333496
Epoch 56  Train loss: 0.3096153268627092  Val loss: 0.31977317198035643
Saving best model, epoch: 56
Epoch 57
-------------------------------
Batch 1/64 loss: 0.306917667388916
Batch 2/64 loss: 0.3080332279205322
Batch 3/64 loss: 0.3043562173843384
Batch 4/64 loss: 0.30528831481933594
Batch 5/64 loss: 0.3068320155143738
Batch 6/64 loss: 0.31183063983917236
Batch 7/64 loss: 0.30698758363723755
Batch 8/64 loss: 0.3185495138168335
Batch 9/64 loss: 0.31005507707595825
Batch 10/64 loss: 0.31385886669158936
Batch 11/64 loss: 0.3034593462944031
Batch 12/64 loss: 0.3069063425064087
Batch 13/64 loss: 0.312552809715271
Batch 14/64 loss: 0.310691237449646
Batch 15/64 loss: 0.3058284521102905
Batch 16/64 loss: 0.3090554475784302
Batch 17/64 loss: 0.3047456741333008
Batch 18/64 loss: 0.3123898506164551
Batch 19/64 loss: 0.3127526640892029
Batch 20/64 loss: 0.3146215081214905
Batch 21/64 loss: 0.3098219037055969
Batch 22/64 loss: 0.30857908725738525
Batch 23/64 loss: 0.3155772089958191
Batch 24/64 loss: 0.3098388910293579
Batch 25/64 loss: 0.30379581451416016
Batch 26/64 loss: 0.3088485598564148
Batch 27/64 loss: 0.31299078464508057
Batch 28/64 loss: 0.31327301263809204
Batch 29/64 loss: 0.3027002811431885
Batch 30/64 loss: 0.3060486912727356
Batch 31/64 loss: 0.30979591608047485
Batch 32/64 loss: 0.3122870922088623
Batch 33/64 loss: 0.30630654096603394
Batch 34/64 loss: 0.2975764274597168
Batch 35/64 loss: 0.3026268482208252
Batch 36/64 loss: 0.3012862801551819
Batch 37/64 loss: 0.30547207593917847
Batch 38/64 loss: 0.3057600259780884
Batch 39/64 loss: 0.31268805265426636
Batch 40/64 loss: 0.3018161654472351
Batch 41/64 loss: 0.3056989312171936
Batch 42/64 loss: 0.3028108477592468
Batch 43/64 loss: 0.30670225620269775
Batch 44/64 loss: 0.3050575256347656
Batch 45/64 loss: 0.30594050884246826
Batch 46/64 loss: 0.3043145537376404
Batch 47/64 loss: 0.31016963720321655
Batch 48/64 loss: 0.3113859295845032
Batch 49/64 loss: 0.3008731007575989
Batch 50/64 loss: 0.3061469793319702
Batch 51/64 loss: 0.30233442783355713
Batch 52/64 loss: 0.3178473114967346
Batch 53/64 loss: 0.3035891056060791
Batch 54/64 loss: 0.31294745206832886
Batch 55/64 loss: 0.3032127618789673
Batch 56/64 loss: 0.31020402908325195
Batch 57/64 loss: 0.3057903051376343
Batch 58/64 loss: 0.30143582820892334
Batch 59/64 loss: 0.3090716600418091
Batch 60/64 loss: 0.3074002265930176
Batch 61/64 loss: 0.3052835464477539
Batch 62/64 loss: 0.30809950828552246
Batch 63/64 loss: 0.3030693531036377
Batch 64/64 loss: 0.310977041721344
Epoch 57  Train loss: 0.3076928734779358  Val loss: 0.3184965416737848
Saving best model, epoch: 57
Epoch 58
-------------------------------
Batch 1/64 loss: 0.30225205421447754
Batch 2/64 loss: 0.30509698390960693
Batch 3/64 loss: 0.3082464933395386
Batch 4/64 loss: 0.3074668049812317
Batch 5/64 loss: 0.31180906295776367
Batch 6/64 loss: 0.30185121297836304
Batch 7/64 loss: 0.299515962600708
Batch 8/64 loss: 0.2993071675300598
Batch 9/64 loss: 0.3044520616531372
Batch 10/64 loss: 0.306721031665802
Batch 11/64 loss: 0.30438846349716187
Batch 12/64 loss: 0.3139679431915283
Batch 13/64 loss: 0.3048991560935974
Batch 14/64 loss: 0.31740736961364746
Batch 15/64 loss: 0.31119513511657715
Batch 16/64 loss: 0.31284403800964355
Batch 17/64 loss: 0.30799245834350586
Batch 18/64 loss: 0.30374979972839355
Batch 19/64 loss: 0.3066099286079407
Batch 20/64 loss: 0.30750399827957153
Batch 21/64 loss: 0.3024151921272278
Batch 22/64 loss: 0.30748796463012695
Batch 23/64 loss: 0.3117749094963074
Batch 24/64 loss: 0.30877602100372314
Batch 25/64 loss: 0.3030223846435547
Batch 26/64 loss: 0.3089325428009033
Batch 27/64 loss: 0.3059431314468384
Batch 28/64 loss: 0.3163509964942932
Batch 29/64 loss: 0.3123844861984253
Batch 30/64 loss: 0.304662823677063
Batch 31/64 loss: 0.3110086917877197
Batch 32/64 loss: 0.30355262756347656
Batch 33/64 loss: 0.30666011571884155
Batch 34/64 loss: 0.29969239234924316
Batch 35/64 loss: 0.30667412281036377
Batch 36/64 loss: 0.3116692304611206
Batch 37/64 loss: 0.30972975492477417
Batch 38/64 loss: 0.2990477681159973
Batch 39/64 loss: 0.3023214340209961
Batch 40/64 loss: 0.2964210510253906
Batch 41/64 loss: 0.30453723669052124
Batch 42/64 loss: 0.3049144148826599
Batch 43/64 loss: 0.3165167570114136
Batch 44/64 loss: 0.31184375286102295
Batch 45/64 loss: 0.30473530292510986
Batch 46/64 loss: 0.3063621520996094
Batch 47/64 loss: 0.30234408378601074
Batch 48/64 loss: 0.3015182614326477
Batch 49/64 loss: 0.3094034194946289
Batch 50/64 loss: 0.3048221468925476
Batch 51/64 loss: 0.31080150604248047
Batch 52/64 loss: 0.31456422805786133
Batch 53/64 loss: 0.3036489486694336
Batch 54/64 loss: 0.30347347259521484
Batch 55/64 loss: 0.3105320930480957
Batch 56/64 loss: 0.30385148525238037
Batch 57/64 loss: 0.3048856854438782
Batch 58/64 loss: 0.3042224645614624
Batch 59/64 loss: 0.30712056159973145
Batch 60/64 loss: 0.3107006549835205
Batch 61/64 loss: 0.3097744584083557
Batch 62/64 loss: 0.3077840805053711
Batch 63/64 loss: 0.30395907163619995
Batch 64/64 loss: 0.3121005892753601
Epoch 58  Train loss: 0.30685798350502463  Val loss: 0.3176171032014172
Saving best model, epoch: 58
Epoch 59
-------------------------------
Batch 1/64 loss: 0.3119049668312073
Batch 2/64 loss: 0.3061794638633728
Batch 3/64 loss: 0.3040308952331543
Batch 4/64 loss: 0.3042599558830261
Batch 5/64 loss: 0.3125317096710205
Batch 6/64 loss: 0.3045525550842285
Batch 7/64 loss: 0.3113134503364563
Batch 8/64 loss: 0.30335915088653564
Batch 9/64 loss: 0.3043358325958252
Batch 10/64 loss: 0.3050405979156494
Batch 11/64 loss: 0.3041893243789673
Batch 12/64 loss: 0.305411159992218
Batch 13/64 loss: 0.30420446395874023
Batch 14/64 loss: 0.30261242389678955
Batch 15/64 loss: 0.3068016767501831
Batch 16/64 loss: 0.3100753426551819
Batch 17/64 loss: 0.30555784702301025
Batch 18/64 loss: 0.31107521057128906
Batch 19/64 loss: 0.2980480194091797
Batch 20/64 loss: 0.3051919937133789
Batch 21/64 loss: 0.30385130643844604
Batch 22/64 loss: 0.31364619731903076
Batch 23/64 loss: 0.29937219619750977
Batch 24/64 loss: 0.3052123188972473
Batch 25/64 loss: 0.2994735836982727
Batch 26/64 loss: 0.3057224750518799
Batch 27/64 loss: 0.3027009963989258
Batch 28/64 loss: 0.31363552808761597
Batch 29/64 loss: 0.3051992654800415
Batch 30/64 loss: 0.3078984022140503
Batch 31/64 loss: 0.3029332160949707
Batch 32/64 loss: 0.30542463064193726
Batch 33/64 loss: 0.307797372341156
Batch 34/64 loss: 0.3128317594528198
Batch 35/64 loss: 0.3062779903411865
Batch 36/64 loss: 0.31052982807159424
Batch 37/64 loss: 0.3098149299621582
Batch 38/64 loss: 0.3034532070159912
Batch 39/64 loss: 0.30641746520996094
Batch 40/64 loss: 0.30602091550827026
Batch 41/64 loss: 0.30565595626831055
Batch 42/64 loss: 0.31802284717559814
Batch 43/64 loss: 0.3028515577316284
Batch 44/64 loss: 0.3045177459716797
Batch 45/64 loss: 0.3009834289550781
Batch 46/64 loss: 0.30500316619873047
Batch 47/64 loss: 0.30508536100387573
Batch 48/64 loss: 0.30825090408325195
Batch 49/64 loss: 0.3088325262069702
Batch 50/64 loss: 0.29719817638397217
Batch 51/64 loss: 0.3017187714576721
Batch 52/64 loss: 0.31157028675079346
Batch 53/64 loss: 0.3080129623413086
Batch 54/64 loss: 0.29845356941223145
Batch 55/64 loss: 0.31123173236846924
Batch 56/64 loss: 0.30377328395843506
Batch 57/64 loss: 0.3067384958267212
Batch 58/64 loss: 0.306277871131897
Batch 59/64 loss: 0.30392879247665405
Batch 60/64 loss: 0.2998943328857422
Batch 61/64 loss: 0.30731189250946045
Batch 62/64 loss: 0.30615705251693726
Batch 63/64 loss: 0.31031644344329834
Batch 64/64 loss: 0.30549103021621704
Epoch 59  Train loss: 0.30603600085950367  Val loss: 0.3175329119479124
Saving best model, epoch: 59
Epoch 60
-------------------------------
Batch 1/64 loss: 0.31104910373687744
Batch 2/64 loss: 0.3076326251029968
Batch 3/64 loss: 0.3049151301383972
Batch 4/64 loss: 0.3055126667022705
Batch 5/64 loss: 0.30779820680618286
Batch 6/64 loss: 0.3153272867202759
Batch 7/64 loss: 0.31485289335250854
Batch 8/64 loss: 0.3007289171218872
Batch 9/64 loss: 0.30224835872650146
Batch 10/64 loss: 0.30210500955581665
Batch 11/64 loss: 0.30507880449295044
Batch 12/64 loss: 0.3040715456008911
Batch 13/64 loss: 0.3043612241744995
Batch 14/64 loss: 0.303786039352417
Batch 15/64 loss: 0.3076136112213135
Batch 16/64 loss: 0.30483579635620117
Batch 17/64 loss: 0.30952590703964233
Batch 18/64 loss: 0.3010512590408325
Batch 19/64 loss: 0.3026914596557617
Batch 20/64 loss: 0.3027563691139221
Batch 21/64 loss: 0.3126387596130371
Batch 22/64 loss: 0.2988162040710449
Batch 23/64 loss: 0.3035450577735901
Batch 24/64 loss: 0.30799663066864014
Batch 25/64 loss: 0.3114476799964905
Batch 26/64 loss: 0.30828988552093506
Batch 27/64 loss: 0.3051875829696655
Batch 28/64 loss: 0.3074599504470825
Batch 29/64 loss: 0.3021186590194702
Batch 30/64 loss: 0.3082059621810913
Batch 31/64 loss: 0.3023572564125061
Batch 32/64 loss: 0.3104287385940552
Batch 33/64 loss: 0.30212152004241943
Batch 34/64 loss: 0.29661238193511963
Batch 35/64 loss: 0.30091285705566406
Batch 36/64 loss: 0.30362313985824585
Batch 37/64 loss: 0.30240553617477417
Batch 38/64 loss: 0.30656683444976807
Batch 39/64 loss: 0.303663432598114
Batch 40/64 loss: 0.3126770257949829
Batch 41/64 loss: 0.2966032028198242
Batch 42/64 loss: 0.30784785747528076
Batch 43/64 loss: 0.30631881952285767
Batch 44/64 loss: 0.30658411979675293
Batch 45/64 loss: 0.3039940595626831
Batch 46/64 loss: 0.298120379447937
Batch 47/64 loss: 0.30507445335388184
Batch 48/64 loss: 0.2995520830154419
Batch 49/64 loss: 0.3105425238609314
Batch 50/64 loss: 0.3084125518798828
Batch 51/64 loss: 0.30254417657852173
Batch 52/64 loss: 0.3049910068511963
Batch 53/64 loss: 0.30278903245925903
Batch 54/64 loss: 0.2976859211921692
Batch 55/64 loss: 0.30521905422210693
Batch 56/64 loss: 0.3159571886062622
Batch 57/64 loss: 0.30436086654663086
Batch 58/64 loss: 0.3072381019592285
Batch 59/64 loss: 0.3058805465698242
Batch 60/64 loss: 0.30210697650909424
Batch 61/64 loss: 0.2959330677986145
Batch 62/64 loss: 0.31045591831207275
Batch 63/64 loss: 0.3067108392715454
Batch 64/64 loss: 0.30139607191085815
Epoch 60  Train loss: 0.30519195467818017  Val loss: 0.31648605713729594
Saving best model, epoch: 60
Epoch 61
-------------------------------
Batch 1/64 loss: 0.30221986770629883
Batch 2/64 loss: 0.30381524562835693
Batch 3/64 loss: 0.30147063732147217
Batch 4/64 loss: 0.30641770362854004
Batch 5/64 loss: 0.3042854070663452
Batch 6/64 loss: 0.30462467670440674
Batch 7/64 loss: 0.30522215366363525
Batch 8/64 loss: 0.30637258291244507
Batch 9/64 loss: 0.30051326751708984
Batch 10/64 loss: 0.3060290217399597
Batch 11/64 loss: 0.30312418937683105
Batch 12/64 loss: 0.2971940040588379
Batch 13/64 loss: 0.30367815494537354
Batch 14/64 loss: 0.30049288272857666
Batch 15/64 loss: 0.3040505647659302
Batch 16/64 loss: 0.3068481683731079
Batch 17/64 loss: 0.297673761844635
Batch 18/64 loss: 0.2974509000778198
Batch 19/64 loss: 0.31020140647888184
Batch 20/64 loss: 0.30171000957489014
Batch 21/64 loss: 0.30387359857559204
Batch 22/64 loss: 0.29937195777893066
Batch 23/64 loss: 0.3085205554962158
Batch 24/64 loss: 0.29864317178726196
Batch 25/64 loss: 0.30873650312423706
Batch 26/64 loss: 0.2967389225959778
Batch 27/64 loss: 0.3050426244735718
Batch 28/64 loss: 0.3059194087982178
Batch 29/64 loss: 0.30603253841400146
Batch 30/64 loss: 0.30454325675964355
Batch 31/64 loss: 0.30577898025512695
Batch 32/64 loss: 0.303287148475647
Batch 33/64 loss: 0.3150932788848877
Batch 34/64 loss: 0.29991501569747925
Batch 35/64 loss: 0.30558276176452637
Batch 36/64 loss: 0.30577200651168823
Batch 37/64 loss: 0.3133453130722046
Batch 38/64 loss: 0.2993049621582031
Batch 39/64 loss: 0.31594717502593994
Batch 40/64 loss: 0.30149543285369873
Batch 41/64 loss: 0.3045428991317749
Batch 42/64 loss: 0.29954099655151367
Batch 43/64 loss: 0.3026643991470337
Batch 44/64 loss: 0.30054140090942383
Batch 45/64 loss: 0.29973363876342773
Batch 46/64 loss: 0.3067784309387207
Batch 47/64 loss: 0.29805123805999756
Batch 48/64 loss: 0.30710458755493164
Batch 49/64 loss: 0.30079197883605957
Batch 50/64 loss: 0.294608473777771
Batch 51/64 loss: 0.30363738536834717
Batch 52/64 loss: 0.2983858585357666
Batch 53/64 loss: 0.3087162971496582
Batch 54/64 loss: 0.3102312684059143
Batch 55/64 loss: 0.3111478090286255
Batch 56/64 loss: 0.3128514289855957
Batch 57/64 loss: 0.2990485429763794
Batch 58/64 loss: 0.3008905053138733
Batch 59/64 loss: 0.2993322014808655
Batch 60/64 loss: 0.30572688579559326
Batch 61/64 loss: 0.3115999698638916
Batch 62/64 loss: 0.3067052364349365
Batch 63/64 loss: 0.2954576015472412
Batch 64/64 loss: 0.3128390312194824
Epoch 61  Train loss: 0.30398521610334805  Val loss: 0.3165430412259708
Epoch 62
-------------------------------
Batch 1/64 loss: 0.30330580472946167
Batch 2/64 loss: 0.29419195652008057
Batch 3/64 loss: 0.31034576892852783
Batch 4/64 loss: 0.3025919198989868
Batch 5/64 loss: 0.3024606704711914
Batch 6/64 loss: 0.2993323802947998
Batch 7/64 loss: 0.3054419755935669
Batch 8/64 loss: 0.30432313680648804
Batch 9/64 loss: 0.3026350736618042
Batch 10/64 loss: 0.31194007396698
Batch 11/64 loss: 0.30694425106048584
Batch 12/64 loss: 0.3025031089782715
Batch 13/64 loss: 0.30856674909591675
Batch 14/64 loss: 0.2946321964263916
Batch 15/64 loss: 0.3066459894180298
Batch 16/64 loss: 0.2990117073059082
Batch 17/64 loss: 0.297599196434021
Batch 18/64 loss: 0.2966269850730896
Batch 19/64 loss: 0.30549609661102295
Batch 20/64 loss: 0.3021600842475891
Batch 21/64 loss: 0.29886066913604736
Batch 22/64 loss: 0.3094513416290283
Batch 23/64 loss: 0.29940497875213623
Batch 24/64 loss: 0.29933929443359375
Batch 25/64 loss: 0.3056487441062927
Batch 26/64 loss: 0.3079078197479248
Batch 27/64 loss: 0.303452730178833
Batch 28/64 loss: 0.30900096893310547
Batch 29/64 loss: 0.3068876266479492
Batch 30/64 loss: 0.30385565757751465
Batch 31/64 loss: 0.3056257963180542
Batch 32/64 loss: 0.3028103709220886
Batch 33/64 loss: 0.30200767517089844
Batch 34/64 loss: 0.30078959465026855
Batch 35/64 loss: 0.3080241084098816
Batch 36/64 loss: 0.3070875406265259
Batch 37/64 loss: 0.299530029296875
Batch 38/64 loss: 0.30450791120529175
Batch 39/64 loss: 0.2988685965538025
Batch 40/64 loss: 0.3021923303604126
Batch 41/64 loss: 0.3041805624961853
Batch 42/64 loss: 0.3002616763114929
Batch 43/64 loss: 0.3055671453475952
Batch 44/64 loss: 0.30342042446136475
Batch 45/64 loss: 0.30513954162597656
Batch 46/64 loss: 0.30522459745407104
Batch 47/64 loss: 0.29568636417388916
Batch 48/64 loss: 0.3050905466079712
Batch 49/64 loss: 0.30053430795669556
Batch 50/64 loss: 0.2993425130844116
Batch 51/64 loss: 0.30174750089645386
Batch 52/64 loss: 0.3048515319824219
Batch 53/64 loss: 0.30556154251098633
Batch 54/64 loss: 0.3047052025794983
Batch 55/64 loss: 0.30969828367233276
Batch 56/64 loss: 0.3084303140640259
Batch 57/64 loss: 0.3025626540184021
Batch 58/64 loss: 0.29938656091690063
Batch 59/64 loss: 0.304742693901062
Batch 60/64 loss: 0.3036313056945801
Batch 61/64 loss: 0.3197362422943115
Batch 62/64 loss: 0.300065279006958
Batch 63/64 loss: 0.3090308904647827
Batch 64/64 loss: 0.30252283811569214
Epoch 62  Train loss: 0.30364703874962  Val loss: 0.31498035286710024
Saving best model, epoch: 62
Epoch 63
-------------------------------
Batch 1/64 loss: 0.29323863983154297
Batch 2/64 loss: 0.31064552068710327
Batch 3/64 loss: 0.2935999631881714
Batch 4/64 loss: 0.3040880560874939
Batch 5/64 loss: 0.29986417293548584
Batch 6/64 loss: 0.2948143482208252
Batch 7/64 loss: 0.3022935390472412
Batch 8/64 loss: 0.29979991912841797
Batch 9/64 loss: 0.30315089225769043
Batch 10/64 loss: 0.2980513572692871
Batch 11/64 loss: 0.3064494729042053
Batch 12/64 loss: 0.2975435256958008
Batch 13/64 loss: 0.30124586820602417
Batch 14/64 loss: 0.3017539978027344
Batch 15/64 loss: 0.29532766342163086
Batch 16/64 loss: 0.30040740966796875
Batch 17/64 loss: 0.29738783836364746
Batch 18/64 loss: 0.30335426330566406
Batch 19/64 loss: 0.3078591823577881
Batch 20/64 loss: 0.3003537654876709
Batch 21/64 loss: 0.29723936319351196
Batch 22/64 loss: 0.30187785625457764
Batch 23/64 loss: 0.3054192066192627
Batch 24/64 loss: 0.294619083404541
Batch 25/64 loss: 0.30433404445648193
Batch 26/64 loss: 0.3057671785354614
Batch 27/64 loss: 0.3108328580856323
Batch 28/64 loss: 0.30124813318252563
Batch 29/64 loss: 0.29788970947265625
Batch 30/64 loss: 0.30994874238967896
Batch 31/64 loss: 0.3035956025123596
Batch 32/64 loss: 0.30472445487976074
Batch 33/64 loss: 0.302004337310791
Batch 34/64 loss: 0.30199456214904785
Batch 35/64 loss: 0.2976190447807312
Batch 36/64 loss: 0.2925158739089966
Batch 37/64 loss: 0.30258578062057495
Batch 38/64 loss: 0.30328333377838135
Batch 39/64 loss: 0.30391639471054077
Batch 40/64 loss: 0.30123698711395264
Batch 41/64 loss: 0.3062424659729004
Batch 42/64 loss: 0.30568867921829224
Batch 43/64 loss: 0.3037782907485962
Batch 44/64 loss: 0.2988849878311157
Batch 45/64 loss: 0.3108208179473877
Batch 46/64 loss: 0.3012838363647461
Batch 47/64 loss: 0.3045816421508789
Batch 48/64 loss: 0.3028830289840698
Batch 49/64 loss: 0.30504345893859863
Batch 50/64 loss: 0.30456769466400146
Batch 51/64 loss: 0.3011501431465149
Batch 52/64 loss: 0.2998499870300293
Batch 53/64 loss: 0.30065256357192993
Batch 54/64 loss: 0.30391669273376465
Batch 55/64 loss: 0.3009357452392578
Batch 56/64 loss: 0.30353647470474243
Batch 57/64 loss: 0.3062697649002075
Batch 58/64 loss: 0.3057934045791626
Batch 59/64 loss: 0.30077648162841797
Batch 60/64 loss: 0.3018707036972046
Batch 61/64 loss: 0.29947006702423096
Batch 62/64 loss: 0.3083505630493164
Batch 63/64 loss: 0.3082939386367798
Batch 64/64 loss: 0.29869431257247925
Epoch 63  Train loss: 0.3021575546732136  Val loss: 0.3147482892491973
Saving best model, epoch: 63
Epoch 64
-------------------------------
Batch 1/64 loss: 0.30345475673675537
Batch 2/64 loss: 0.2938135266304016
Batch 3/64 loss: 0.3042259216308594
Batch 4/64 loss: 0.29825472831726074
Batch 5/64 loss: 0.2989632487297058
Batch 6/64 loss: 0.2951847314834595
Batch 7/64 loss: 0.29901808500289917
Batch 8/64 loss: 0.30090200901031494
Batch 9/64 loss: 0.30168092250823975
Batch 10/64 loss: 0.29079484939575195
Batch 11/64 loss: 0.293083131313324
Batch 12/64 loss: 0.3037908673286438
Batch 13/64 loss: 0.3067513704299927
Batch 14/64 loss: 0.30111420154571533
Batch 15/64 loss: 0.29490935802459717
Batch 16/64 loss: 0.2995532155036926
Batch 17/64 loss: 0.307866632938385
Batch 18/64 loss: 0.30022186040878296
Batch 19/64 loss: 0.2976412773132324
Batch 20/64 loss: 0.3035801649093628
Batch 21/64 loss: 0.3072777986526489
Batch 22/64 loss: 0.30824756622314453
Batch 23/64 loss: 0.30087363719940186
Batch 24/64 loss: 0.3013995289802551
Batch 25/64 loss: 0.298073947429657
Batch 26/64 loss: 0.2945812940597534
Batch 27/64 loss: 0.304762601852417
Batch 28/64 loss: 0.30044400691986084
Batch 29/64 loss: 0.2966400980949402
Batch 30/64 loss: 0.3002966642379761
Batch 31/64 loss: 0.3020974397659302
Batch 32/64 loss: 0.30160588026046753
Batch 33/64 loss: 0.3038361072540283
Batch 34/64 loss: 0.3047511577606201
Batch 35/64 loss: 0.30407726764678955
Batch 36/64 loss: 0.3011559844017029
Batch 37/64 loss: 0.297046422958374
Batch 38/64 loss: 0.311215877532959
Batch 39/64 loss: 0.2988535165786743
Batch 40/64 loss: 0.2975417971611023
Batch 41/64 loss: 0.30497610569000244
Batch 42/64 loss: 0.30536603927612305
Batch 43/64 loss: 0.2997567057609558
Batch 44/64 loss: 0.30203795433044434
Batch 45/64 loss: 0.3051384687423706
Batch 46/64 loss: 0.2915940284729004
Batch 47/64 loss: 0.3063678741455078
Batch 48/64 loss: 0.29546868801116943
Batch 49/64 loss: 0.3090875744819641
Batch 50/64 loss: 0.2992985248565674
Batch 51/64 loss: 0.29870712757110596
Batch 52/64 loss: 0.3045302629470825
Batch 53/64 loss: 0.305316686630249
Batch 54/64 loss: 0.30448484420776367
Batch 55/64 loss: 0.2994511127471924
Batch 56/64 loss: 0.3038507103919983
Batch 57/64 loss: 0.2994530200958252
Batch 58/64 loss: 0.3041527271270752
Batch 59/64 loss: 0.30064117908477783
Batch 60/64 loss: 0.30860984325408936
Batch 61/64 loss: 0.30908942222595215
Batch 62/64 loss: 0.297796368598938
Batch 63/64 loss: 0.30023401975631714
Batch 64/64 loss: 0.300664484500885
Epoch 64  Train loss: 0.30134103695551556  Val loss: 0.31681831636789326
Epoch 65
-------------------------------
Batch 1/64 loss: 0.2970552444458008
Batch 2/64 loss: 0.30179840326309204
Batch 3/64 loss: 0.29598116874694824
Batch 4/64 loss: 0.2967100143432617
Batch 5/64 loss: 0.30660098791122437
Batch 6/64 loss: 0.3001856803894043
Batch 7/64 loss: 0.30185770988464355
Batch 8/64 loss: 0.30310845375061035
Batch 9/64 loss: 0.2967188358306885
Batch 10/64 loss: 0.2965672016143799
Batch 11/64 loss: 0.3078881502151489
Batch 12/64 loss: 0.302574098110199
Batch 13/64 loss: 0.3018147349357605
Batch 14/64 loss: 0.2974501848220825
Batch 15/64 loss: 0.2956541180610657
Batch 16/64 loss: 0.2997368574142456
Batch 17/64 loss: 0.30599576234817505
Batch 18/64 loss: 0.29572784900665283
Batch 19/64 loss: 0.2905477285385132
Batch 20/64 loss: 0.29804855585098267
Batch 21/64 loss: 0.3051002025604248
Batch 22/64 loss: 0.30515968799591064
Batch 23/64 loss: 0.300936222076416
Batch 24/64 loss: 0.2991625666618347
Batch 25/64 loss: 0.300417959690094
Batch 26/64 loss: 0.29410219192504883
Batch 27/64 loss: 0.3044947385787964
Batch 28/64 loss: 0.2905617952346802
Batch 29/64 loss: 0.29928839206695557
Batch 30/64 loss: 0.29915857315063477
Batch 31/64 loss: 0.305289626121521
Batch 32/64 loss: 0.2992304563522339
Batch 33/64 loss: 0.3102726936340332
Batch 34/64 loss: 0.3018955588340759
Batch 35/64 loss: 0.29730165004730225
Batch 36/64 loss: 0.3017312288284302
Batch 37/64 loss: 0.29785043001174927
Batch 38/64 loss: 0.29843246936798096
Batch 39/64 loss: 0.2957491874694824
Batch 40/64 loss: 0.2967604994773865
Batch 41/64 loss: 0.30290544033050537
Batch 42/64 loss: 0.3088870048522949
Batch 43/64 loss: 0.30475807189941406
Batch 44/64 loss: 0.3042043447494507
Batch 45/64 loss: 0.3021999001502991
Batch 46/64 loss: 0.30206650495529175
Batch 47/64 loss: 0.3108779788017273
Batch 48/64 loss: 0.30022990703582764
Batch 49/64 loss: 0.2996087074279785
Batch 50/64 loss: 0.3030517101287842
Batch 51/64 loss: 0.30429112911224365
Batch 52/64 loss: 0.29839229583740234
Batch 53/64 loss: 0.30392134189605713
Batch 54/64 loss: 0.3057299852371216
Batch 55/64 loss: 0.2990070581436157
Batch 56/64 loss: 0.30020272731781006
Batch 57/64 loss: 0.3003939986228943
Batch 58/64 loss: 0.3001757860183716
Batch 59/64 loss: 0.2982978820800781
Batch 60/64 loss: 0.29274260997772217
Batch 61/64 loss: 0.3002355098724365
Batch 62/64 loss: 0.30174803733825684
Batch 63/64 loss: 0.3010075092315674
Batch 64/64 loss: 0.3045704960823059
Epoch 65  Train loss: 0.30067892051210593  Val loss: 0.3136643824708421
Saving best model, epoch: 65
Epoch 66
-------------------------------
Batch 1/64 loss: 0.298170804977417
Batch 2/64 loss: 0.2951642870903015
Batch 3/64 loss: 0.2971160411834717
Batch 4/64 loss: 0.2967628240585327
Batch 5/64 loss: 0.29863011837005615
Batch 6/64 loss: 0.30609363317489624
Batch 7/64 loss: 0.29987794160842896
Batch 8/64 loss: 0.30282527208328247
Batch 9/64 loss: 0.30441927909851074
Batch 10/64 loss: 0.2948508858680725
Batch 11/64 loss: 0.2988779544830322
Batch 12/64 loss: 0.2974846363067627
Batch 13/64 loss: 0.3023512363433838
Batch 14/64 loss: 0.3010901212692261
Batch 15/64 loss: 0.2997082471847534
Batch 16/64 loss: 0.2922212481498718
Batch 17/64 loss: 0.30315840244293213
Batch 18/64 loss: 0.29604506492614746
Batch 19/64 loss: 0.30837559700012207
Batch 20/64 loss: 0.30188047885894775
Batch 21/64 loss: 0.29530036449432373
Batch 22/64 loss: 0.29461216926574707
Batch 23/64 loss: 0.30444586277008057
Batch 24/64 loss: 0.2969212532043457
Batch 25/64 loss: 0.29334479570388794
Batch 26/64 loss: 0.29885411262512207
Batch 27/64 loss: 0.30303525924682617
Batch 28/64 loss: 0.30365443229675293
Batch 29/64 loss: 0.30216825008392334
Batch 30/64 loss: 0.2978123426437378
Batch 31/64 loss: 0.3045307397842407
Batch 32/64 loss: 0.29714256525039673
Batch 33/64 loss: 0.3007745146751404
Batch 34/64 loss: 0.3086535930633545
Batch 35/64 loss: 0.3009970188140869
Batch 36/64 loss: 0.2946295142173767
Batch 37/64 loss: 0.30427616834640503
Batch 38/64 loss: 0.30256974697113037
Batch 39/64 loss: 0.29208624362945557
Batch 40/64 loss: 0.2931114435195923
Batch 41/64 loss: 0.29417502880096436
Batch 42/64 loss: 0.29934465885162354
Batch 43/64 loss: 0.3013255000114441
Batch 44/64 loss: 0.2989763617515564
Batch 45/64 loss: 0.3021421432495117
Batch 46/64 loss: 0.3098185062408447
Batch 47/64 loss: 0.2917594909667969
Batch 48/64 loss: 0.301333487033844
Batch 49/64 loss: 0.3011183738708496
Batch 50/64 loss: 0.30748021602630615
Batch 51/64 loss: 0.2959586977958679
Batch 52/64 loss: 0.3007747530937195
Batch 53/64 loss: 0.3028739094734192
Batch 54/64 loss: 0.29738032817840576
Batch 55/64 loss: 0.3061451315879822
Batch 56/64 loss: 0.2997863292694092
Batch 57/64 loss: 0.3045530319213867
Batch 58/64 loss: 0.29854774475097656
Batch 59/64 loss: 0.29748278856277466
Batch 60/64 loss: 0.2984883785247803
Batch 61/64 loss: 0.29667407274246216
Batch 62/64 loss: 0.2983938455581665
Batch 63/64 loss: 0.3007924556732178
Batch 64/64 loss: 0.30119574069976807
Epoch 66  Train loss: 0.29984700399286607  Val loss: 0.31468455119640965
Epoch 67
-------------------------------
Batch 1/64 loss: 0.29604339599609375
Batch 2/64 loss: 0.30390727519989014
Batch 3/64 loss: 0.3044605851173401
Batch 4/64 loss: 0.30086684226989746
Batch 5/64 loss: 0.30012047290802
Batch 6/64 loss: 0.29412156343460083
Batch 7/64 loss: 0.30176442861557007
Batch 8/64 loss: 0.29346394538879395
Batch 9/64 loss: 0.30133509635925293
Batch 10/64 loss: 0.2987474203109741
Batch 11/64 loss: 0.30639785528182983
Batch 12/64 loss: 0.2952117919921875
Batch 13/64 loss: 0.29766732454299927
Batch 14/64 loss: 0.29856008291244507
Batch 15/64 loss: 0.29775094985961914
Batch 16/64 loss: 0.3033222556114197
Batch 17/64 loss: 0.2955852746963501
Batch 18/64 loss: 0.29637110233306885
Batch 19/64 loss: 0.2984492778778076
Batch 20/64 loss: 0.29805493354797363
Batch 21/64 loss: 0.30035626888275146
Batch 22/64 loss: 0.2952533960342407
Batch 23/64 loss: 0.30138450860977173
Batch 24/64 loss: 0.29543590545654297
Batch 25/64 loss: 0.2956521511077881
Batch 26/64 loss: 0.3008619546890259
Batch 27/64 loss: 0.30789315700531006
Batch 28/64 loss: 0.29651540517807007
Batch 29/64 loss: 0.2953793406486511
Batch 30/64 loss: 0.30086588859558105
Batch 31/64 loss: 0.30451422929763794
Batch 32/64 loss: 0.30624687671661377
Batch 33/64 loss: 0.29699552059173584
Batch 34/64 loss: 0.2905169725418091
Batch 35/64 loss: 0.3034346103668213
Batch 36/64 loss: 0.29804515838623047
Batch 37/64 loss: 0.2953416109085083
Batch 38/64 loss: 0.2901262044906616
Batch 39/64 loss: 0.2883114814758301
Batch 40/64 loss: 0.2976611852645874
Batch 41/64 loss: 0.2972066402435303
Batch 42/64 loss: 0.293013334274292
Batch 43/64 loss: 0.304951548576355
Batch 44/64 loss: 0.298537015914917
Batch 45/64 loss: 0.29895973205566406
Batch 46/64 loss: 0.2991877794265747
Batch 47/64 loss: 0.29054534435272217
Batch 48/64 loss: 0.30001676082611084
Batch 49/64 loss: 0.3028987646102905
Batch 50/64 loss: 0.29606199264526367
Batch 51/64 loss: 0.2904229760169983
Batch 52/64 loss: 0.2920913100242615
Batch 53/64 loss: 0.309592068195343
Batch 54/64 loss: 0.3001229763031006
Batch 55/64 loss: 0.2930961847305298
Batch 56/64 loss: 0.30636876821517944
Batch 57/64 loss: 0.30523014068603516
Batch 58/64 loss: 0.2981199026107788
Batch 59/64 loss: 0.3005247712135315
Batch 60/64 loss: 0.30387067794799805
Batch 61/64 loss: 0.2981998920440674
Batch 62/64 loss: 0.2977447509765625
Batch 63/64 loss: 0.30159491300582886
Batch 64/64 loss: 0.29760074615478516
Epoch 67  Train loss: 0.29873807851006  Val loss: 0.31404714772791387
Epoch 68
-------------------------------
Batch 1/64 loss: 0.30329012870788574
Batch 2/64 loss: 0.29771482944488525
Batch 3/64 loss: 0.3042362928390503
Batch 4/64 loss: 0.29390859603881836
Batch 5/64 loss: 0.29681921005249023
Batch 6/64 loss: 0.2995182275772095
Batch 7/64 loss: 0.29983454942703247
Batch 8/64 loss: 0.3015108108520508
Batch 9/64 loss: 0.29179513454437256
Batch 10/64 loss: 0.29561465978622437
Batch 11/64 loss: 0.29097098112106323
Batch 12/64 loss: 0.2886123061180115
Batch 13/64 loss: 0.2972433567047119
Batch 14/64 loss: 0.2934321165084839
Batch 15/64 loss: 0.3013404607772827
Batch 16/64 loss: 0.2950468063354492
Batch 17/64 loss: 0.30334746837615967
Batch 18/64 loss: 0.2971113920211792
Batch 19/64 loss: 0.30214130878448486
Batch 20/64 loss: 0.30578649044036865
Batch 21/64 loss: 0.3045424222946167
Batch 22/64 loss: 0.29366356134414673
Batch 23/64 loss: 0.298042893409729
Batch 24/64 loss: 0.30262577533721924
Batch 25/64 loss: 0.2962700128555298
Batch 26/64 loss: 0.29837578535079956
Batch 27/64 loss: 0.291958212852478
Batch 28/64 loss: 0.29522454738616943
Batch 29/64 loss: 0.29535698890686035
Batch 30/64 loss: 0.30233824253082275
Batch 31/64 loss: 0.2962244153022766
Batch 32/64 loss: 0.2948594093322754
Batch 33/64 loss: 0.2901214361190796
Batch 34/64 loss: 0.2957344055175781
Batch 35/64 loss: 0.29809749126434326
Batch 36/64 loss: 0.3010253310203552
Batch 37/64 loss: 0.2986953854560852
Batch 38/64 loss: 0.30435991287231445
Batch 39/64 loss: 0.2982579469680786
Batch 40/64 loss: 0.2959434390068054
Batch 41/64 loss: 0.30637937784194946
Batch 42/64 loss: 0.2982708215713501
Batch 43/64 loss: 0.29980963468551636
Batch 44/64 loss: 0.2949022054672241
Batch 45/64 loss: 0.2903616428375244
Batch 46/64 loss: 0.3024466037750244
Batch 47/64 loss: 0.3002724051475525
Batch 48/64 loss: 0.29723668098449707
Batch 49/64 loss: 0.3020714521408081
Batch 50/64 loss: 0.30132728815078735
Batch 51/64 loss: 0.2931562662124634
Batch 52/64 loss: 0.293013334274292
Batch 53/64 loss: 0.2982812523841858
Batch 54/64 loss: 0.29695218801498413
Batch 55/64 loss: 0.2992531657218933
Batch 56/64 loss: 0.29890894889831543
Batch 57/64 loss: 0.2977988123893738
Batch 58/64 loss: 0.3029170632362366
Batch 59/64 loss: 0.29427415132522583
Batch 60/64 loss: 0.2930756211280823
Batch 61/64 loss: 0.29515719413757324
Batch 62/64 loss: 0.30513978004455566
Batch 63/64 loss: 0.2948061227798462
Batch 64/64 loss: 0.2906269431114197
Epoch 68  Train loss: 0.2978003915618448  Val loss: 0.3129428559562185
Saving best model, epoch: 68
Epoch 69
-------------------------------
Batch 1/64 loss: 0.29987502098083496
Batch 2/64 loss: 0.29050540924072266
Batch 3/64 loss: 0.300015926361084
Batch 4/64 loss: 0.29586261510849
Batch 5/64 loss: 0.2920733094215393
Batch 6/64 loss: 0.29925692081451416
Batch 7/64 loss: 0.2879805564880371
Batch 8/64 loss: 0.2909775376319885
Batch 9/64 loss: 0.29434871673583984
Batch 10/64 loss: 0.296972393989563
Batch 11/64 loss: 0.2956690788269043
Batch 12/64 loss: 0.2912561893463135
Batch 13/64 loss: 0.306351900100708
Batch 14/64 loss: 0.29374241828918457
Batch 15/64 loss: 0.29894793033599854
Batch 16/64 loss: 0.2941305637359619
Batch 17/64 loss: 0.2955576181411743
Batch 18/64 loss: 0.2920180559158325
Batch 19/64 loss: 0.3046715259552002
Batch 20/64 loss: 0.2950589060783386
Batch 21/64 loss: 0.2937144637107849
Batch 22/64 loss: 0.3036726117134094
Batch 23/64 loss: 0.2972019910812378
Batch 24/64 loss: 0.2994558811187744
Batch 25/64 loss: 0.3011661171913147
Batch 26/64 loss: 0.28849172592163086
Batch 27/64 loss: 0.3059878349304199
Batch 28/64 loss: 0.29763662815093994
Batch 29/64 loss: 0.29580825567245483
Batch 30/64 loss: 0.2952839732170105
Batch 31/64 loss: 0.29421675205230713
Batch 32/64 loss: 0.28918784856796265
Batch 33/64 loss: 0.2941545248031616
Batch 34/64 loss: 0.30084967613220215
Batch 35/64 loss: 0.2978634834289551
Batch 36/64 loss: 0.29126274585723877
Batch 37/64 loss: 0.2945460081100464
Batch 38/64 loss: 0.30108487606048584
Batch 39/64 loss: 0.29747307300567627
Batch 40/64 loss: 0.2945747971534729
Batch 41/64 loss: 0.2952392101287842
Batch 42/64 loss: 0.29558253288269043
Batch 43/64 loss: 0.2946333885192871
Batch 44/64 loss: 0.29992765188217163
Batch 45/64 loss: 0.298720121383667
Batch 46/64 loss: 0.3044089078903198
Batch 47/64 loss: 0.29308927059173584
Batch 48/64 loss: 0.2969290018081665
Batch 49/64 loss: 0.29250431060791016
Batch 50/64 loss: 0.3051525354385376
Batch 51/64 loss: 0.3087460994720459
Batch 52/64 loss: 0.2988468408584595
Batch 53/64 loss: 0.30126261711120605
Batch 54/64 loss: 0.30169689655303955
Batch 55/64 loss: 0.29828131198883057
Batch 56/64 loss: 0.2918248176574707
Batch 57/64 loss: 0.2972351312637329
Batch 58/64 loss: 0.29804420471191406
Batch 59/64 loss: 0.2989012598991394
Batch 60/64 loss: 0.2988904118537903
Batch 61/64 loss: 0.29832756519317627
Batch 62/64 loss: 0.2936530113220215
Batch 63/64 loss: 0.3061800003051758
Batch 64/64 loss: 0.299008846282959
Epoch 69  Train loss: 0.29711748384961895  Val loss: 0.31134480381339685
Saving best model, epoch: 69
Epoch 70
-------------------------------
Batch 1/64 loss: 0.2933005690574646
Batch 2/64 loss: 0.2975316643714905
Batch 3/64 loss: 0.29681646823883057
Batch 4/64 loss: 0.29293394088745117
Batch 5/64 loss: 0.3009430170059204
Batch 6/64 loss: 0.3008154630661011
Batch 7/64 loss: 0.2975144386291504
Batch 8/64 loss: 0.2939862012863159
Batch 9/64 loss: 0.2960202693939209
Batch 10/64 loss: 0.2976636290550232
Batch 11/64 loss: 0.2915995121002197
Batch 12/64 loss: 0.30584442615509033
Batch 13/64 loss: 0.29378020763397217
Batch 14/64 loss: 0.2990126609802246
Batch 15/64 loss: 0.3000537157058716
Batch 16/64 loss: 0.2934529781341553
Batch 17/64 loss: 0.28950929641723633
Batch 18/64 loss: 0.29343104362487793
Batch 19/64 loss: 0.2955702543258667
Batch 20/64 loss: 0.29829370975494385
Batch 21/64 loss: 0.2984641194343567
Batch 22/64 loss: 0.2953909635543823
Batch 23/64 loss: 0.3033612370491028
Batch 24/64 loss: 0.2950406074523926
Batch 25/64 loss: 0.29837214946746826
Batch 26/64 loss: 0.2917059659957886
Batch 27/64 loss: 0.29560863971710205
Batch 28/64 loss: 0.3016968369483948
Batch 29/64 loss: 0.2965662479400635
Batch 30/64 loss: 0.28963905572891235
Batch 31/64 loss: 0.2931036353111267
Batch 32/64 loss: 0.2968118190765381
Batch 33/64 loss: 0.30000460147857666
Batch 34/64 loss: 0.29410529136657715
Batch 35/64 loss: 0.29112333059310913
Batch 36/64 loss: 0.30064260959625244
Batch 37/64 loss: 0.29649680852890015
Batch 38/64 loss: 0.29283565282821655
Batch 39/64 loss: 0.3019692897796631
Batch 40/64 loss: 0.2878084182739258
Batch 41/64 loss: 0.29095160961151123
Batch 42/64 loss: 0.2955775260925293
Batch 43/64 loss: 0.29617083072662354
Batch 44/64 loss: 0.2952401638031006
Batch 45/64 loss: 0.3046863079071045
Batch 46/64 loss: 0.2955054044723511
Batch 47/64 loss: 0.29200291633605957
Batch 48/64 loss: 0.3069084882736206
Batch 49/64 loss: 0.29686856269836426
Batch 50/64 loss: 0.29239773750305176
Batch 51/64 loss: 0.29222047328948975
Batch 52/64 loss: 0.30142128467559814
Batch 53/64 loss: 0.2948809862136841
Batch 54/64 loss: 0.2961939573287964
Batch 55/64 loss: 0.2910749316215515
Batch 56/64 loss: 0.2937358617782593
Batch 57/64 loss: 0.29928475618362427
Batch 58/64 loss: 0.293645441532135
Batch 59/64 loss: 0.30158066749572754
Batch 60/64 loss: 0.29935693740844727
Batch 61/64 loss: 0.29548072814941406
Batch 62/64 loss: 0.3026060461997986
Batch 63/64 loss: 0.2953703999519348
Batch 64/64 loss: 0.30411040782928467
Epoch 70  Train loss: 0.29647161680109363  Val loss: 0.3109056390437883
Saving best model, epoch: 70
Epoch 71
-------------------------------
Batch 1/64 loss: 0.2891191244125366
Batch 2/64 loss: 0.2974562644958496
Batch 3/64 loss: 0.29213452339172363
Batch 4/64 loss: 0.28583091497421265
Batch 5/64 loss: 0.29509085416793823
Batch 6/64 loss: 0.294824481010437
Batch 7/64 loss: 0.2986431121826172
Batch 8/64 loss: 0.2960313558578491
Batch 9/64 loss: 0.29896414279937744
Batch 10/64 loss: 0.2969682216644287
Batch 11/64 loss: 0.29639357328414917
Batch 12/64 loss: 0.29709410667419434
Batch 13/64 loss: 0.2939387559890747
Batch 14/64 loss: 0.2968941926956177
Batch 15/64 loss: 0.2917524576187134
Batch 16/64 loss: 0.28644829988479614
Batch 17/64 loss: 0.2957667112350464
Batch 18/64 loss: 0.296600878238678
Batch 19/64 loss: 0.2930558919906616
Batch 20/64 loss: 0.29365968704223633
Batch 21/64 loss: 0.29907166957855225
Batch 22/64 loss: 0.29824578762054443
Batch 23/64 loss: 0.2937673330307007
Batch 24/64 loss: 0.29415905475616455
Batch 25/64 loss: 0.2998422384262085
Batch 26/64 loss: 0.2920480966567993
Batch 27/64 loss: 0.2934578061103821
Batch 28/64 loss: 0.2967106103897095
Batch 29/64 loss: 0.29538607597351074
Batch 30/64 loss: 0.3016144037246704
Batch 31/64 loss: 0.30386996269226074
Batch 32/64 loss: 0.2918027639389038
Batch 33/64 loss: 0.2922389507293701
Batch 34/64 loss: 0.2940605878829956
Batch 35/64 loss: 0.2983875274658203
Batch 36/64 loss: 0.2944682836532593
Batch 37/64 loss: 0.290655255317688
Batch 38/64 loss: 0.28841638565063477
Batch 39/64 loss: 0.30573856830596924
Batch 40/64 loss: 0.2931739091873169
Batch 41/64 loss: 0.29274535179138184
Batch 42/64 loss: 0.2925702929496765
Batch 43/64 loss: 0.2977639436721802
Batch 44/64 loss: 0.29371267557144165
Batch 45/64 loss: 0.3032822608947754
Batch 46/64 loss: 0.29228007793426514
Batch 47/64 loss: 0.2921029329299927
Batch 48/64 loss: 0.2902352809906006
Batch 49/64 loss: 0.30099111795425415
Batch 50/64 loss: 0.2944912910461426
Batch 51/64 loss: 0.2892725467681885
Batch 52/64 loss: 0.29985105991363525
Batch 53/64 loss: 0.28961825370788574
Batch 54/64 loss: 0.297616183757782
Batch 55/64 loss: 0.29584383964538574
Batch 56/64 loss: 0.29971998929977417
Batch 57/64 loss: 0.29650211334228516
Batch 58/64 loss: 0.3038114905357361
Batch 59/64 loss: 0.29132384061813354
Batch 60/64 loss: 0.29967713356018066
Batch 61/64 loss: 0.2943357229232788
Batch 62/64 loss: 0.2891831398010254
Batch 63/64 loss: 0.2934846878051758
Batch 64/64 loss: 0.3056851625442505
Epoch 71  Train loss: 0.29526999090232103  Val loss: 0.3102787483189114
Saving best model, epoch: 71
Epoch 72
-------------------------------
Batch 1/64 loss: 0.29533278942108154
Batch 2/64 loss: 0.29366815090179443
Batch 3/64 loss: 0.2965102195739746
Batch 4/64 loss: 0.29642254114151
Batch 5/64 loss: 0.29358720779418945
Batch 6/64 loss: 0.29901373386383057
Batch 7/64 loss: 0.29381173849105835
Batch 8/64 loss: 0.2931225299835205
Batch 9/64 loss: 0.294471800327301
Batch 10/64 loss: 0.292585551738739
Batch 11/64 loss: 0.2999759316444397
Batch 12/64 loss: 0.29415786266326904
Batch 13/64 loss: 0.2961515784263611
Batch 14/64 loss: 0.2872077226638794
Batch 15/64 loss: 0.2969399690628052
Batch 16/64 loss: 0.3001607656478882
Batch 17/64 loss: 0.29817044734954834
Batch 18/64 loss: 0.2952863574028015
Batch 19/64 loss: 0.2925417423248291
Batch 20/64 loss: 0.29714226722717285
Batch 21/64 loss: 0.2989504337310791
Batch 22/64 loss: 0.2974194884300232
Batch 23/64 loss: 0.2869546413421631
Batch 24/64 loss: 0.30602872371673584
Batch 25/64 loss: 0.3043944239616394
Batch 26/64 loss: 0.2934229373931885
Batch 27/64 loss: 0.2916675806045532
Batch 28/64 loss: 0.28772151470184326
Batch 29/64 loss: 0.29105913639068604
Batch 30/64 loss: 0.29192066192626953
Batch 31/64 loss: 0.29426705837249756
Batch 32/64 loss: 0.2934720516204834
Batch 33/64 loss: 0.2936282157897949
Batch 34/64 loss: 0.29120826721191406
Batch 35/64 loss: 0.3053940534591675
Batch 36/64 loss: 0.2923416495323181
Batch 37/64 loss: 0.3010402321815491
Batch 38/64 loss: 0.3008589744567871
Batch 39/64 loss: 0.2856026887893677
Batch 40/64 loss: 0.29272663593292236
Batch 41/64 loss: 0.2978283166885376
Batch 42/64 loss: 0.3049723505973816
Batch 43/64 loss: 0.29171282052993774
Batch 44/64 loss: 0.28893160820007324
Batch 45/64 loss: 0.2963831424713135
Batch 46/64 loss: 0.2932392954826355
Batch 47/64 loss: 0.29202723503112793
Batch 48/64 loss: 0.29274511337280273
Batch 49/64 loss: 0.2941064238548279
Batch 50/64 loss: 0.29889237880706787
Batch 51/64 loss: 0.29706263542175293
Batch 52/64 loss: 0.2961461544036865
Batch 53/64 loss: 0.2942048907279968
Batch 54/64 loss: 0.29677116870880127
Batch 55/64 loss: 0.3007230758666992
Batch 56/64 loss: 0.296458899974823
Batch 57/64 loss: 0.291622519493103
Batch 58/64 loss: 0.2954890727996826
Batch 59/64 loss: 0.2904682159423828
Batch 60/64 loss: 0.29783719778060913
Batch 61/64 loss: 0.29053205251693726
Batch 62/64 loss: 0.2943781018257141
Batch 63/64 loss: 0.28987860679626465
Batch 64/64 loss: 0.29027092456817627
Epoch 72  Train loss: 0.2950032117320042  Val loss: 0.3097683076596342
Saving best model, epoch: 72
Epoch 73
-------------------------------
Batch 1/64 loss: 0.295793354511261
Batch 2/64 loss: 0.2935810089111328
Batch 3/64 loss: 0.2894439101219177
Batch 4/64 loss: 0.29887640476226807
Batch 5/64 loss: 0.29515016078948975
Batch 6/64 loss: 0.2927383780479431
Batch 7/64 loss: 0.28944891691207886
Batch 8/64 loss: 0.28964465856552124
Batch 9/64 loss: 0.2918581962585449
Batch 10/64 loss: 0.2992106080055237
Batch 11/64 loss: 0.29264456033706665
Batch 12/64 loss: 0.29021894931793213
Batch 13/64 loss: 0.28626692295074463
Batch 14/64 loss: 0.290058434009552
Batch 15/64 loss: 0.2952989339828491
Batch 16/64 loss: 0.29657256603240967
Batch 17/64 loss: 0.29250508546829224
Batch 18/64 loss: 0.2869783639907837
Batch 19/64 loss: 0.29195767641067505
Batch 20/64 loss: 0.2991430163383484
Batch 21/64 loss: 0.29424023628234863
Batch 22/64 loss: 0.2936522960662842
Batch 23/64 loss: 0.30144256353378296
Batch 24/64 loss: 0.2853160500526428
Batch 25/64 loss: 0.2945610284805298
Batch 26/64 loss: 0.29629528522491455
Batch 27/64 loss: 0.28908050060272217
Batch 28/64 loss: 0.2920162081718445
Batch 29/64 loss: 0.30056232213974
Batch 30/64 loss: 0.29170745611190796
Batch 31/64 loss: 0.290751576423645
Batch 32/64 loss: 0.29779529571533203
Batch 33/64 loss: 0.2984662652015686
Batch 34/64 loss: 0.2849687337875366
Batch 35/64 loss: 0.29468047618865967
Batch 36/64 loss: 0.3029100298881531
Batch 37/64 loss: 0.29254233837127686
Batch 38/64 loss: 0.30081790685653687
Batch 39/64 loss: 0.3019252419471741
Batch 40/64 loss: 0.29758936166763306
Batch 41/64 loss: 0.29636549949645996
Batch 42/64 loss: 0.28961706161499023
Batch 43/64 loss: 0.2948892116546631
Batch 44/64 loss: 0.2869139313697815
Batch 45/64 loss: 0.30212700366973877
Batch 46/64 loss: 0.29991334676742554
Batch 47/64 loss: 0.2960188388824463
Batch 48/64 loss: 0.293271005153656
Batch 49/64 loss: 0.28811317682266235
Batch 50/64 loss: 0.2963755130767822
Batch 51/64 loss: 0.2924058437347412
Batch 52/64 loss: 0.28964853286743164
Batch 53/64 loss: 0.28927111625671387
Batch 54/64 loss: 0.2918218970298767
Batch 55/64 loss: 0.2936389446258545
Batch 56/64 loss: 0.306934118270874
Batch 57/64 loss: 0.29845762252807617
Batch 58/64 loss: 0.29651975631713867
Batch 59/64 loss: 0.29012930393218994
Batch 60/64 loss: 0.2973829507827759
Batch 61/64 loss: 0.29936790466308594
Batch 62/64 loss: 0.29613256454467773
Batch 63/64 loss: 0.2950233221054077
Batch 64/64 loss: 0.28611326217651367
Epoch 73  Train loss: 0.2941746618233475  Val loss: 0.30931793025269133
Saving best model, epoch: 73
Epoch 74
-------------------------------
Batch 1/64 loss: 0.2888990044593811
Batch 2/64 loss: 0.29230427742004395
Batch 3/64 loss: 0.297039270401001
Batch 4/64 loss: 0.2879120111465454
Batch 5/64 loss: 0.29128289222717285
Batch 6/64 loss: 0.29588961601257324
Batch 7/64 loss: 0.2935032844543457
Batch 8/64 loss: 0.2919769883155823
Batch 9/64 loss: 0.29752373695373535
Batch 10/64 loss: 0.29209989309310913
Batch 11/64 loss: 0.29782986640930176
Batch 12/64 loss: 0.2942890524864197
Batch 13/64 loss: 0.2950240969657898
Batch 14/64 loss: 0.29566991329193115
Batch 15/64 loss: 0.29763758182525635
Batch 16/64 loss: 0.29668354988098145
Batch 17/64 loss: 0.29551565647125244
Batch 18/64 loss: 0.2873462438583374
Batch 19/64 loss: 0.2939462661743164
Batch 20/64 loss: 0.2917296290397644
Batch 21/64 loss: 0.2896066904067993
Batch 22/64 loss: 0.29180407524108887
Batch 23/64 loss: 0.2895665168762207
Batch 24/64 loss: 0.29820603132247925
Batch 25/64 loss: 0.2895747423171997
Batch 26/64 loss: 0.29127681255340576
Batch 27/64 loss: 0.29066038131713867
Batch 28/64 loss: 0.2921801209449768
Batch 29/64 loss: 0.2948998212814331
Batch 30/64 loss: 0.2880547046661377
Batch 31/64 loss: 0.29200422763824463
Batch 32/64 loss: 0.288277804851532
Batch 33/64 loss: 0.2965761423110962
Batch 34/64 loss: 0.29559171199798584
Batch 35/64 loss: 0.2918192148208618
Batch 36/64 loss: 0.29189854860305786
Batch 37/64 loss: 0.29446154832839966
Batch 38/64 loss: 0.2935972213745117
Batch 39/64 loss: 0.2971489429473877
Batch 40/64 loss: 0.29828232526779175
Batch 41/64 loss: 0.29245418310165405
Batch 42/64 loss: 0.2995372414588928
Batch 43/64 loss: 0.2921435832977295
Batch 44/64 loss: 0.29165029525756836
Batch 45/64 loss: 0.2961326837539673
Batch 46/64 loss: 0.29843103885650635
Batch 47/64 loss: 0.29504549503326416
Batch 48/64 loss: 0.2899045944213867
Batch 49/64 loss: 0.29372596740722656
Batch 50/64 loss: 0.2865840196609497
Batch 51/64 loss: 0.300672709941864
Batch 52/64 loss: 0.2927449345588684
Batch 53/64 loss: 0.2948075532913208
Batch 54/64 loss: 0.28755974769592285
Batch 55/64 loss: 0.29389631748199463
Batch 56/64 loss: 0.28653484582901
Batch 57/64 loss: 0.29579704999923706
Batch 58/64 loss: 0.29358744621276855
Batch 59/64 loss: 0.2933262586593628
Batch 60/64 loss: 0.2946394681930542
Batch 61/64 loss: 0.2985970973968506
Batch 62/64 loss: 0.2877894639968872
Batch 63/64 loss: 0.2929406762123108
Batch 64/64 loss: 0.298694372177124
Epoch 74  Train loss: 0.2933664920283299  Val loss: 0.3096413143311989
Epoch 75
-------------------------------
Batch 1/64 loss: 0.29473596811294556
Batch 2/64 loss: 0.3011622428894043
Batch 3/64 loss: 0.2977299094200134
Batch 4/64 loss: 0.28809547424316406
Batch 5/64 loss: 0.2902899980545044
Batch 6/64 loss: 0.293880820274353
Batch 7/64 loss: 0.2908083200454712
Batch 8/64 loss: 0.28563016653060913
Batch 9/64 loss: 0.29747819900512695
Batch 10/64 loss: 0.2880786657333374
Batch 11/64 loss: 0.2913249731063843
Batch 12/64 loss: 0.28803426027297974
Batch 13/64 loss: 0.2886291742324829
Batch 14/64 loss: 0.2900373935699463
Batch 15/64 loss: 0.29968684911727905
Batch 16/64 loss: 0.2910899519920349
Batch 17/64 loss: 0.29782599210739136
Batch 18/64 loss: 0.29324769973754883
Batch 19/64 loss: 0.29240792989730835
Batch 20/64 loss: 0.29554998874664307
Batch 21/64 loss: 0.28710246086120605
Batch 22/64 loss: 0.29771244525909424
Batch 23/64 loss: 0.2841668725013733
Batch 24/64 loss: 0.2958475351333618
Batch 25/64 loss: 0.2931842803955078
Batch 26/64 loss: 0.29069554805755615
Batch 27/64 loss: 0.2969716787338257
Batch 28/64 loss: 0.285663366317749
Batch 29/64 loss: 0.2925071716308594
Batch 30/64 loss: 0.2874622344970703
Batch 31/64 loss: 0.29222726821899414
Batch 32/64 loss: 0.2957218885421753
Batch 33/64 loss: 0.2916032075881958
Batch 34/64 loss: 0.2921748161315918
Batch 35/64 loss: 0.2935792803764343
Batch 36/64 loss: 0.301278293132782
Batch 37/64 loss: 0.29748213291168213
Batch 38/64 loss: 0.3003033399581909
Batch 39/64 loss: 0.29028165340423584
Batch 40/64 loss: 0.29043710231781006
Batch 41/64 loss: 0.28294265270233154
Batch 42/64 loss: 0.29754388332366943
Batch 43/64 loss: 0.28952717781066895
Batch 44/64 loss: 0.29096633195877075
Batch 45/64 loss: 0.2881357669830322
Batch 46/64 loss: 0.29195547103881836
Batch 47/64 loss: 0.29526859521865845
Batch 48/64 loss: 0.2913461923599243
Batch 49/64 loss: 0.2969776391983032
Batch 50/64 loss: 0.2912874221801758
Batch 51/64 loss: 0.2831369638442993
Batch 52/64 loss: 0.28941643238067627
Batch 53/64 loss: 0.29769766330718994
Batch 54/64 loss: 0.29421305656433105
Batch 55/64 loss: 0.2930522561073303
Batch 56/64 loss: 0.29721736907958984
Batch 57/64 loss: 0.29660648107528687
Batch 58/64 loss: 0.29027801752090454
Batch 59/64 loss: 0.29041165113449097
Batch 60/64 loss: 0.2821369171142578
Batch 61/64 loss: 0.2899845838546753
Batch 62/64 loss: 0.2935194969177246
Batch 63/64 loss: 0.2971777319908142
Batch 64/64 loss: 0.29391658306121826
Epoch 75  Train loss: 0.29244492147483075  Val loss: 0.30838857749893084
Saving best model, epoch: 75
Epoch 76
-------------------------------
Batch 1/64 loss: 0.2977050542831421
Batch 2/64 loss: 0.2914435863494873
Batch 3/64 loss: 0.29570233821868896
Batch 4/64 loss: 0.28958451747894287
Batch 5/64 loss: 0.29405903816223145
Batch 6/64 loss: 0.2878255248069763
Batch 7/64 loss: 0.2878068685531616
Batch 8/64 loss: 0.29194414615631104
Batch 9/64 loss: 0.3007773160934448
Batch 10/64 loss: 0.2911437749862671
Batch 11/64 loss: 0.2862062454223633
Batch 12/64 loss: 0.2891296148300171
Batch 13/64 loss: 0.29472941160202026
Batch 14/64 loss: 0.2952346205711365
Batch 15/64 loss: 0.2895053029060364
Batch 16/64 loss: 0.2882641553878784
Batch 17/64 loss: 0.29347658157348633
Batch 18/64 loss: 0.2920341491699219
Batch 19/64 loss: 0.29483938217163086
Batch 20/64 loss: 0.2900218963623047
Batch 21/64 loss: 0.29055434465408325
Batch 22/64 loss: 0.29704177379608154
Batch 23/64 loss: 0.29541921615600586
Batch 24/64 loss: 0.2885095477104187
Batch 25/64 loss: 0.2921491861343384
Batch 26/64 loss: 0.2877935767173767
Batch 27/64 loss: 0.2853168249130249
Batch 28/64 loss: 0.2938794493675232
Batch 29/64 loss: 0.2975615859031677
Batch 30/64 loss: 0.2941802740097046
Batch 31/64 loss: 0.2934000492095947
Batch 32/64 loss: 0.28531527519226074
Batch 33/64 loss: 0.28838860988616943
Batch 34/64 loss: 0.2903035283088684
Batch 35/64 loss: 0.29189610481262207
Batch 36/64 loss: 0.2946246862411499
Batch 37/64 loss: 0.29463982582092285
Batch 38/64 loss: 0.29337430000305176
Batch 39/64 loss: 0.29247844219207764
Batch 40/64 loss: 0.292682409286499
Batch 41/64 loss: 0.28617680072784424
Batch 42/64 loss: 0.2927654981613159
Batch 43/64 loss: 0.29161232709884644
Batch 44/64 loss: 0.2916554808616638
Batch 45/64 loss: 0.29950594902038574
Batch 46/64 loss: 0.29879724979400635
Batch 47/64 loss: 0.2881890535354614
Batch 48/64 loss: 0.2897014617919922
Batch 49/64 loss: 0.2893836498260498
Batch 50/64 loss: 0.29855382442474365
Batch 51/64 loss: 0.28859782218933105
Batch 52/64 loss: 0.28732800483703613
Batch 53/64 loss: 0.2978247404098511
Batch 54/64 loss: 0.2891106605529785
Batch 55/64 loss: 0.2849215269088745
Batch 56/64 loss: 0.29259347915649414
Batch 57/64 loss: 0.3000195026397705
Batch 58/64 loss: 0.29009389877319336
Batch 59/64 loss: 0.28345155715942383
Batch 60/64 loss: 0.2906920909881592
Batch 61/64 loss: 0.2981142997741699
Batch 62/64 loss: 0.2918586730957031
Batch 63/64 loss: 0.2958338260650635
Batch 64/64 loss: 0.28996241092681885
Epoch 76  Train loss: 0.29200307013941745  Val loss: 0.30809323320683746
Saving best model, epoch: 76
Epoch 77
-------------------------------
Batch 1/64 loss: 0.28819286823272705
Batch 2/64 loss: 0.29198014736175537
Batch 3/64 loss: 0.2932626008987427
Batch 4/64 loss: 0.2895151972770691
Batch 5/64 loss: 0.29041242599487305
Batch 6/64 loss: 0.2942183017730713
Batch 7/64 loss: 0.2915470600128174
Batch 8/64 loss: 0.29595720767974854
Batch 9/64 loss: 0.28942346572875977
Batch 10/64 loss: 0.29359543323516846
Batch 11/64 loss: 0.2956688404083252
Batch 12/64 loss: 0.2873963713645935
Batch 13/64 loss: 0.29643505811691284
Batch 14/64 loss: 0.2864673137664795
Batch 15/64 loss: 0.2893872857093811
Batch 16/64 loss: 0.29021525382995605
Batch 17/64 loss: 0.2881452441215515
Batch 18/64 loss: 0.28828585147857666
Batch 19/64 loss: 0.2913014888763428
Batch 20/64 loss: 0.2872370481491089
Batch 21/64 loss: 0.28495681285858154
Batch 22/64 loss: 0.2887076139450073
Batch 23/64 loss: 0.2879275679588318
Batch 24/64 loss: 0.28994935750961304
Batch 25/64 loss: 0.28756487369537354
Batch 26/64 loss: 0.2867683172225952
Batch 27/64 loss: 0.2879038453102112
Batch 28/64 loss: 0.2943779230117798
Batch 29/64 loss: 0.29917216300964355
Batch 30/64 loss: 0.27953362464904785
Batch 31/64 loss: 0.29208242893218994
Batch 32/64 loss: 0.2888960838317871
Batch 33/64 loss: 0.29130780696868896
Batch 34/64 loss: 0.29350048303604126
Batch 35/64 loss: 0.29099059104919434
Batch 36/64 loss: 0.2897457480430603
Batch 37/64 loss: 0.2899554371833801
Batch 38/64 loss: 0.28450989723205566
Batch 39/64 loss: 0.29142510890960693
Batch 40/64 loss: 0.28392457962036133
Batch 41/64 loss: 0.29838377237319946
Batch 42/64 loss: 0.28791993856430054
Batch 43/64 loss: 0.2867438793182373
Batch 44/64 loss: 0.2942779064178467
Batch 45/64 loss: 0.2889471650123596
Batch 46/64 loss: 0.2941296696662903
Batch 47/64 loss: 0.2869824171066284
Batch 48/64 loss: 0.29273462295532227
Batch 49/64 loss: 0.2893780469894409
Batch 50/64 loss: 0.29851245880126953
Batch 51/64 loss: 0.2927852272987366
Batch 52/64 loss: 0.2888033986091614
Batch 53/64 loss: 0.295609712600708
Batch 54/64 loss: 0.29079270362854004
Batch 55/64 loss: 0.28215014934539795
Batch 56/64 loss: 0.2889813184738159
Batch 57/64 loss: 0.2932807207107544
Batch 58/64 loss: 0.2846733331680298
Batch 59/64 loss: 0.289824903011322
Batch 60/64 loss: 0.2944352626800537
Batch 61/64 loss: 0.3023456335067749
Batch 62/64 loss: 0.3021911382675171
Batch 63/64 loss: 0.2849026918411255
Batch 64/64 loss: 0.30256712436676025
Epoch 77  Train loss: 0.29078519437827316  Val loss: 0.3080311016118813
Saving best model, epoch: 77
Epoch 78
-------------------------------
Batch 1/64 loss: 0.2917765974998474
Batch 2/64 loss: 0.2920283079147339
Batch 3/64 loss: 0.2869061231613159
Batch 4/64 loss: 0.29632192850112915
Batch 5/64 loss: 0.2937096357345581
Batch 6/64 loss: 0.2907533049583435
Batch 7/64 loss: 0.29238003492355347
Batch 8/64 loss: 0.2984039783477783
Batch 9/64 loss: 0.2835885286331177
Batch 10/64 loss: 0.29536664485931396
Batch 11/64 loss: 0.29005908966064453
Batch 12/64 loss: 0.2927699685096741
Batch 13/64 loss: 0.2978519797325134
Batch 14/64 loss: 0.2901310920715332
Batch 15/64 loss: 0.29342448711395264
Batch 16/64 loss: 0.29256880283355713
Batch 17/64 loss: 0.29101574420928955
Batch 18/64 loss: 0.29117435216903687
Batch 19/64 loss: 0.29012298583984375
Batch 20/64 loss: 0.2954865097999573
Batch 21/64 loss: 0.286857545375824
Batch 22/64 loss: 0.28373509645462036
Batch 23/64 loss: 0.28677529096603394
Batch 24/64 loss: 0.28873324394226074
Batch 25/64 loss: 0.2882314920425415
Batch 26/64 loss: 0.2866111993789673
Batch 27/64 loss: 0.2834697365760803
Batch 28/64 loss: 0.29007792472839355
Batch 29/64 loss: 0.2863274812698364
Batch 30/64 loss: 0.2886176109313965
Batch 31/64 loss: 0.2821962833404541
Batch 32/64 loss: 0.28521108627319336
Batch 33/64 loss: 0.28731703758239746
Batch 34/64 loss: 0.2832023501396179
Batch 35/64 loss: 0.286609411239624
Batch 36/64 loss: 0.2942255735397339
Batch 37/64 loss: 0.2918710708618164
Batch 38/64 loss: 0.2869373559951782
Batch 39/64 loss: 0.2901120185852051
Batch 40/64 loss: 0.28812384605407715
Batch 41/64 loss: 0.29352420568466187
Batch 42/64 loss: 0.296159565448761
Batch 43/64 loss: 0.2931952476501465
Batch 44/64 loss: 0.2846771478652954
Batch 45/64 loss: 0.2903748154640198
Batch 46/64 loss: 0.28606146574020386
Batch 47/64 loss: 0.2995908260345459
Batch 48/64 loss: 0.2923160791397095
Batch 49/64 loss: 0.2956284284591675
Batch 50/64 loss: 0.28662818670272827
Batch 51/64 loss: 0.28533220291137695
Batch 52/64 loss: 0.28799331188201904
Batch 53/64 loss: 0.2946122884750366
Batch 54/64 loss: 0.28745633363723755
Batch 55/64 loss: 0.2874690890312195
Batch 56/64 loss: 0.2907618284225464
Batch 57/64 loss: 0.2894700765609741
Batch 58/64 loss: 0.29334771633148193
Batch 59/64 loss: 0.2874869704246521
Batch 60/64 loss: 0.28552788496017456
Batch 61/64 loss: 0.2968069314956665
Batch 62/64 loss: 0.2934498190879822
Batch 63/64 loss: 0.28866106271743774
Batch 64/64 loss: 0.2953551411628723
Epoch 78  Train loss: 0.29018244065490423  Val loss: 0.3070942974582161
Saving best model, epoch: 78
Epoch 79
-------------------------------
Batch 1/64 loss: 0.28785425424575806
Batch 2/64 loss: 0.2828853130340576
Batch 3/64 loss: 0.29338598251342773
Batch 4/64 loss: 0.28819340467453003
Batch 5/64 loss: 0.29099124670028687
Batch 6/64 loss: 0.2952426075935364
Batch 7/64 loss: 0.2847403287887573
Batch 8/64 loss: 0.2818523645401001
Batch 9/64 loss: 0.2947843074798584
Batch 10/64 loss: 0.2989693284034729
Batch 11/64 loss: 0.29230964183807373
Batch 12/64 loss: 0.2861073613166809
Batch 13/64 loss: 0.28755444288253784
Batch 14/64 loss: 0.2857630252838135
Batch 15/64 loss: 0.2953951358795166
Batch 16/64 loss: 0.2861180305480957
Batch 17/64 loss: 0.287208616733551
Batch 18/64 loss: 0.2941312789916992
Batch 19/64 loss: 0.28749793767929077
Batch 20/64 loss: 0.289425253868103
Batch 21/64 loss: 0.29598987102508545
Batch 22/64 loss: 0.28700870275497437
Batch 23/64 loss: 0.28147149085998535
Batch 24/64 loss: 0.2922477722167969
Batch 25/64 loss: 0.29586338996887207
Batch 26/64 loss: 0.2843761444091797
Batch 27/64 loss: 0.29553890228271484
Batch 28/64 loss: 0.2923857569694519
Batch 29/64 loss: 0.3010801076889038
Batch 30/64 loss: 0.28875213861465454
Batch 31/64 loss: 0.28915512561798096
Batch 32/64 loss: 0.28856509923934937
Batch 33/64 loss: 0.2966545820236206
Batch 34/64 loss: 0.29385679960250854
Batch 35/64 loss: 0.2986178398132324
Batch 36/64 loss: 0.2926737666130066
Batch 37/64 loss: 0.29654717445373535
Batch 38/64 loss: 0.2906385660171509
Batch 39/64 loss: 0.2861684560775757
Batch 40/64 loss: 0.2847106456756592
Batch 41/64 loss: 0.2908517122268677
Batch 42/64 loss: 0.2879105806350708
Batch 43/64 loss: 0.2799057960510254
Batch 44/64 loss: 0.28304070234298706
Batch 45/64 loss: 0.2928682565689087
Batch 46/64 loss: 0.2881585955619812
Batch 47/64 loss: 0.29515618085861206
Batch 48/64 loss: 0.283810019493103
Batch 49/64 loss: 0.28852611780166626
Batch 50/64 loss: 0.28793513774871826
Batch 51/64 loss: 0.28893566131591797
Batch 52/64 loss: 0.2845717668533325
Batch 53/64 loss: 0.28019624948501587
Batch 54/64 loss: 0.2873286008834839
Batch 55/64 loss: 0.30046015977859497
Batch 56/64 loss: 0.28582435846328735
Batch 57/64 loss: 0.2879238724708557
Batch 58/64 loss: 0.2846716046333313
Batch 59/64 loss: 0.29733139276504517
Batch 60/64 loss: 0.28516435623168945
Batch 61/64 loss: 0.2890438437461853
Batch 62/64 loss: 0.28648775815963745
Batch 63/64 loss: 0.2901473045349121
Batch 64/64 loss: 0.29194504022598267
Epoch 79  Train loss: 0.28969287848940084  Val loss: 0.30749945235006587
Epoch 80
-------------------------------
Batch 1/64 loss: 0.2933696508407593
Batch 2/64 loss: 0.29214489459991455
Batch 3/64 loss: 0.29578137397766113
Batch 4/64 loss: 0.2919922471046448
Batch 5/64 loss: 0.2884233593940735
Batch 6/64 loss: 0.29281044006347656
Batch 7/64 loss: 0.28673577308654785
Batch 8/64 loss: 0.2921270728111267
Batch 9/64 loss: 0.2847440242767334
Batch 10/64 loss: 0.2864419221878052
Batch 11/64 loss: 0.2928194999694824
Batch 12/64 loss: 0.2869059443473816
Batch 13/64 loss: 0.2916896939277649
Batch 14/64 loss: 0.29262471199035645
Batch 15/64 loss: 0.28757303953170776
Batch 16/64 loss: 0.2950366735458374
Batch 17/64 loss: 0.28894346952438354
Batch 18/64 loss: 0.28544938564300537
Batch 19/64 loss: 0.2864570617675781
Batch 20/64 loss: 0.2911367416381836
Batch 21/64 loss: 0.29126888513565063
Batch 22/64 loss: 0.2898932695388794
Batch 23/64 loss: 0.28728747367858887
Batch 24/64 loss: 0.28657835721969604
Batch 25/64 loss: 0.2811615467071533
Batch 26/64 loss: 0.2880781888961792
Batch 27/64 loss: 0.2858281135559082
Batch 28/64 loss: 0.29705649614334106
Batch 29/64 loss: 0.286859929561615
Batch 30/64 loss: 0.28940844535827637
Batch 31/64 loss: 0.2892810106277466
Batch 32/64 loss: 0.29059576988220215
Batch 33/64 loss: 0.28298795223236084
Batch 34/64 loss: 0.28013086318969727
Batch 35/64 loss: 0.28481388092041016
Batch 36/64 loss: 0.29087358713150024
Batch 37/64 loss: 0.2976427674293518
Batch 38/64 loss: 0.2824171185493469
Batch 39/64 loss: 0.2897226810455322
Batch 40/64 loss: 0.2780546545982361
Batch 41/64 loss: 0.28706008195877075
Batch 42/64 loss: 0.28863441944122314
Batch 43/64 loss: 0.28462696075439453
Batch 44/64 loss: 0.290022611618042
Batch 45/64 loss: 0.28582000732421875
Batch 46/64 loss: 0.28421616554260254
Batch 47/64 loss: 0.28830254077911377
Batch 48/64 loss: 0.29095733165740967
Batch 49/64 loss: 0.28665804862976074
Batch 50/64 loss: 0.2905241847038269
Batch 51/64 loss: 0.28932976722717285
Batch 52/64 loss: 0.2931164503097534
Batch 53/64 loss: 0.28698843717575073
Batch 54/64 loss: 0.28306275606155396
Batch 55/64 loss: 0.2777479887008667
Batch 56/64 loss: 0.2835097908973694
Batch 57/64 loss: 0.2903674244880676
Batch 58/64 loss: 0.2895505428314209
Batch 59/64 loss: 0.2939673662185669
Batch 60/64 loss: 0.2874547839164734
Batch 61/64 loss: 0.28650981187820435
Batch 62/64 loss: 0.29256319999694824
Batch 63/64 loss: 0.28743040561676025
Batch 64/64 loss: 0.2919872999191284
Epoch 80  Train loss: 0.288479365087023  Val loss: 0.30677686565110773
Saving best model, epoch: 80
Epoch 81
-------------------------------
Batch 1/64 loss: 0.28928929567337036
Batch 2/64 loss: 0.29016584157943726
Batch 3/64 loss: 0.27265071868896484
Batch 4/64 loss: 0.28642523288726807
Batch 5/64 loss: 0.2782236933708191
Batch 6/64 loss: 0.2816850543022156
Batch 7/64 loss: 0.2882053852081299
Batch 8/64 loss: 0.29262304306030273
Batch 9/64 loss: 0.292116641998291
Batch 10/64 loss: 0.2901921272277832
Batch 11/64 loss: 0.29104143381118774
Batch 12/64 loss: 0.2872128486633301
Batch 13/64 loss: 0.2906177043914795
Batch 14/64 loss: 0.28225964307785034
Batch 15/64 loss: 0.2859877347946167
Batch 16/64 loss: 0.2954517602920532
Batch 17/64 loss: 0.2799062132835388
Batch 18/64 loss: 0.2774839997291565
Batch 19/64 loss: 0.28520667552948
Batch 20/64 loss: 0.28242528438568115
Batch 21/64 loss: 0.29008233547210693
Batch 22/64 loss: 0.2853550910949707
Batch 23/64 loss: 0.2864423394203186
Batch 24/64 loss: 0.2848357558250427
Batch 25/64 loss: 0.28979551792144775
Batch 26/64 loss: 0.2896205186843872
Batch 27/64 loss: 0.2887413501739502
Batch 28/64 loss: 0.29055851697921753
Batch 29/64 loss: 0.28975462913513184
Batch 30/64 loss: 0.2904180884361267
Batch 31/64 loss: 0.2833903431892395
Batch 32/64 loss: 0.28392916917800903
Batch 33/64 loss: 0.28860437870025635
Batch 34/64 loss: 0.2902735471725464
Batch 35/64 loss: 0.2957555055618286
Batch 36/64 loss: 0.2914217710494995
Batch 37/64 loss: 0.2926533818244934
Batch 38/64 loss: 0.2884119749069214
Batch 39/64 loss: 0.2912414073944092
Batch 40/64 loss: 0.2940722703933716
Batch 41/64 loss: 0.2827540636062622
Batch 42/64 loss: 0.29022401571273804
Batch 43/64 loss: 0.29017436504364014
Batch 44/64 loss: 0.2860952615737915
Batch 45/64 loss: 0.3004816770553589
Batch 46/64 loss: 0.29140567779541016
Batch 47/64 loss: 0.285264253616333
Batch 48/64 loss: 0.29031163454055786
Batch 49/64 loss: 0.2950345277786255
Batch 50/64 loss: 0.29287028312683105
Batch 51/64 loss: 0.2945108413696289
Batch 52/64 loss: 0.28767073154449463
Batch 53/64 loss: 0.2865802049636841
Batch 54/64 loss: 0.2869231104850769
Batch 55/64 loss: 0.29193824529647827
Batch 56/64 loss: 0.2822225093841553
Batch 57/64 loss: 0.28437817096710205
Batch 58/64 loss: 0.28786057233810425
Batch 59/64 loss: 0.29749107360839844
Batch 60/64 loss: 0.2966633439064026
Batch 61/64 loss: 0.2974414825439453
Batch 62/64 loss: 0.28366321325302124
Batch 63/64 loss: 0.29789507389068604
Batch 64/64 loss: 0.2857097387313843
Epoch 81  Train loss: 0.2886065076379215  Val loss: 0.30598366444872827
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: 0.2960934638977051
Batch 2/64 loss: 0.2808588743209839
Batch 3/64 loss: 0.27990520000457764
Batch 4/64 loss: 0.2818787693977356
Batch 5/64 loss: 0.28322362899780273
Batch 6/64 loss: 0.29095780849456787
Batch 7/64 loss: 0.28346192836761475
Batch 8/64 loss: 0.2797677516937256
Batch 9/64 loss: 0.2866772413253784
Batch 10/64 loss: 0.28875136375427246
Batch 11/64 loss: 0.28598475456237793
Batch 12/64 loss: 0.2863224744796753
Batch 13/64 loss: 0.2841075658798218
Batch 14/64 loss: 0.27965790033340454
Batch 15/64 loss: 0.2816126346588135
Batch 16/64 loss: 0.2878148555755615
Batch 17/64 loss: 0.27876853942871094
Batch 18/64 loss: 0.28698933124542236
Batch 19/64 loss: 0.2928612232208252
Batch 20/64 loss: 0.2856902480125427
Batch 21/64 loss: 0.2815822958946228
Batch 22/64 loss: 0.29335784912109375
Batch 23/64 loss: 0.29245853424072266
Batch 24/64 loss: 0.2835851311683655
Batch 25/64 loss: 0.28794145584106445
Batch 26/64 loss: 0.28604280948638916
Batch 27/64 loss: 0.292822003364563
Batch 28/64 loss: 0.29292798042297363
Batch 29/64 loss: 0.2831341028213501
Batch 30/64 loss: 0.2884364724159241
Batch 31/64 loss: 0.2923409342765808
Batch 32/64 loss: 0.2771216630935669
Batch 33/64 loss: 0.284248948097229
Batch 34/64 loss: 0.28797709941864014
Batch 35/64 loss: 0.2852843403816223
Batch 36/64 loss: 0.2804054617881775
Batch 37/64 loss: 0.2984045147895813
Batch 38/64 loss: 0.2867571711540222
Batch 39/64 loss: 0.2947477102279663
Batch 40/64 loss: 0.2912943959236145
Batch 41/64 loss: 0.2808297276496887
Batch 42/64 loss: 0.29152393341064453
Batch 43/64 loss: 0.28909194469451904
Batch 44/64 loss: 0.28756511211395264
Batch 45/64 loss: 0.2877904772758484
Batch 46/64 loss: 0.28980231285095215
Batch 47/64 loss: 0.2928736209869385
Batch 48/64 loss: 0.2912031412124634
Batch 49/64 loss: 0.28683042526245117
Batch 50/64 loss: 0.2884650230407715
Batch 51/64 loss: 0.2947421073913574
Batch 52/64 loss: 0.29125404357910156
Batch 53/64 loss: 0.2853713035583496
Batch 54/64 loss: 0.287253737449646
Batch 55/64 loss: 0.2962552309036255
Batch 56/64 loss: 0.2904949188232422
Batch 57/64 loss: 0.28593915700912476
Batch 58/64 loss: 0.2968544363975525
Batch 59/64 loss: 0.28554069995880127
Batch 60/64 loss: 0.2922133207321167
Batch 61/64 loss: 0.28826677799224854
Batch 62/64 loss: 0.285186767578125
Batch 63/64 loss: 0.28700870275497437
Batch 64/64 loss: 0.2878239154815674
Epoch 82  Train loss: 0.28753696142458446  Val loss: 0.30777980658606563
Epoch 83
-------------------------------
Batch 1/64 loss: 0.2863457202911377
Batch 2/64 loss: 0.27884578704833984
Batch 3/64 loss: 0.285852313041687
Batch 4/64 loss: 0.2753704786300659
Batch 5/64 loss: 0.2864633798599243
Batch 6/64 loss: 0.28969717025756836
Batch 7/64 loss: 0.2851092219352722
Batch 8/64 loss: 0.2831001877784729
Batch 9/64 loss: 0.279849112033844
Batch 10/64 loss: 0.2871236801147461
Batch 11/64 loss: 0.2799454927444458
Batch 12/64 loss: 0.2851588726043701
Batch 13/64 loss: 0.29573237895965576
Batch 14/64 loss: 0.28330016136169434
Batch 15/64 loss: 0.2855328917503357
Batch 16/64 loss: 0.28613221645355225
Batch 17/64 loss: 0.2931942939758301
Batch 18/64 loss: 0.295188844203949
Batch 19/64 loss: 0.29006052017211914
Batch 20/64 loss: 0.29110395908355713
Batch 21/64 loss: 0.29152798652648926
Batch 22/64 loss: 0.28504979610443115
Batch 23/64 loss: 0.2878117561340332
Batch 24/64 loss: 0.29632723331451416
Batch 25/64 loss: 0.2928076386451721
Batch 26/64 loss: 0.2838205099105835
Batch 27/64 loss: 0.2852274179458618
Batch 28/64 loss: 0.28412044048309326
Batch 29/64 loss: 0.28674042224884033
Batch 30/64 loss: 0.28780317306518555
Batch 31/64 loss: 0.28770577907562256
Batch 32/64 loss: 0.28781867027282715
Batch 33/64 loss: 0.2873237133026123
Batch 34/64 loss: 0.2818453311920166
Batch 35/64 loss: 0.2898440957069397
Batch 36/64 loss: 0.2831977605819702
Batch 37/64 loss: 0.2823057174682617
Batch 38/64 loss: 0.2911897897720337
Batch 39/64 loss: 0.2817920446395874
Batch 40/64 loss: 0.2905200719833374
Batch 41/64 loss: 0.2895364761352539
Batch 42/64 loss: 0.2841830253601074
Batch 43/64 loss: 0.2858150005340576
Batch 44/64 loss: 0.287245512008667
Batch 45/64 loss: 0.28009140491485596
Batch 46/64 loss: 0.27921438217163086
Batch 47/64 loss: 0.2892444133758545
Batch 48/64 loss: 0.2887541651725769
Batch 49/64 loss: 0.2868831157684326
Batch 50/64 loss: 0.2887304425239563
Batch 51/64 loss: 0.2801361083984375
Batch 52/64 loss: 0.2850315570831299
Batch 53/64 loss: 0.294192910194397
Batch 54/64 loss: 0.28181546926498413
Batch 55/64 loss: 0.2926461100578308
Batch 56/64 loss: 0.28280091285705566
Batch 57/64 loss: 0.2792574167251587
Batch 58/64 loss: 0.2849111557006836
Batch 59/64 loss: 0.29756927490234375
Batch 60/64 loss: 0.2914496064186096
Batch 61/64 loss: 0.2988849878311157
Batch 62/64 loss: 0.28699779510498047
Batch 63/64 loss: 0.28949689865112305
Batch 64/64 loss: 0.2999036908149719
Epoch 83  Train loss: 0.2870227755284777  Val loss: 0.3068741760712719
Epoch 84
-------------------------------
Batch 1/64 loss: 0.28061020374298096
Batch 2/64 loss: 0.2926288843154907
Batch 3/64 loss: 0.29069364070892334
Batch 4/64 loss: 0.2860485911369324
Batch 5/64 loss: 0.280276894569397
Batch 6/64 loss: 0.2965068817138672
Batch 7/64 loss: 0.2910304069519043
Batch 8/64 loss: 0.29009848833084106
Batch 9/64 loss: 0.28412413597106934
Batch 10/64 loss: 0.27983999252319336
Batch 11/64 loss: 0.2865440249443054
Batch 12/64 loss: 0.2879619598388672
Batch 13/64 loss: 0.2933843731880188
Batch 14/64 loss: 0.2886728048324585
Batch 15/64 loss: 0.28853774070739746
Batch 16/64 loss: 0.2814040184020996
Batch 17/64 loss: 0.29569393396377563
Batch 18/64 loss: 0.2923036813735962
Batch 19/64 loss: 0.2860276699066162
Batch 20/64 loss: 0.2922935485839844
Batch 21/64 loss: 0.2861534357070923
Batch 22/64 loss: 0.2926596403121948
Batch 23/64 loss: 0.2853228449821472
Batch 24/64 loss: 0.28891563415527344
Batch 25/64 loss: 0.29048049449920654
Batch 26/64 loss: 0.2969391345977783
Batch 27/64 loss: 0.29260557889938354
Batch 28/64 loss: 0.2868005633354187
Batch 29/64 loss: 0.2831137776374817
Batch 30/64 loss: 0.28817737102508545
Batch 31/64 loss: 0.28055113554000854
Batch 32/64 loss: 0.2942882180213928
Batch 33/64 loss: 0.2863335609436035
Batch 34/64 loss: 0.2804195284843445
Batch 35/64 loss: 0.29342859983444214
Batch 36/64 loss: 0.28164732456207275
Batch 37/64 loss: 0.28020358085632324
Batch 38/64 loss: 0.28764569759368896
Batch 39/64 loss: 0.281457781791687
Batch 40/64 loss: 0.282828688621521
Batch 41/64 loss: 0.28488683700561523
Batch 42/64 loss: 0.28174227476119995
Batch 43/64 loss: 0.2801923155784607
Batch 44/64 loss: 0.28461718559265137
Batch 45/64 loss: 0.2825471758842468
Batch 46/64 loss: 0.28520500659942627
Batch 47/64 loss: 0.2885916829109192
Batch 48/64 loss: 0.2834164500236511
Batch 49/64 loss: 0.283214807510376
Batch 50/64 loss: 0.28634047508239746
Batch 51/64 loss: 0.2816312313079834
Batch 52/64 loss: 0.2744743824005127
Batch 53/64 loss: 0.2827059030532837
Batch 54/64 loss: 0.2857751250267029
Batch 55/64 loss: 0.28549349308013916
Batch 56/64 loss: 0.2872229814529419
Batch 57/64 loss: 0.28312814235687256
Batch 58/64 loss: 0.2893202304840088
Batch 59/64 loss: 0.2904475927352905
Batch 60/64 loss: 0.28735584020614624
Batch 61/64 loss: 0.28570783138275146
Batch 62/64 loss: 0.2838406562805176
Batch 63/64 loss: 0.2858915328979492
Batch 64/64 loss: 0.2909238338470459
Epoch 84  Train loss: 0.2865348469977285  Val loss: 0.3056066511422908
Saving best model, epoch: 84
Epoch 85
-------------------------------
Batch 1/64 loss: 0.2908363342285156
Batch 2/64 loss: 0.2831013798713684
Batch 3/64 loss: 0.27865827083587646
Batch 4/64 loss: 0.28773975372314453
Batch 5/64 loss: 0.28462982177734375
Batch 6/64 loss: 0.2902395725250244
Batch 7/64 loss: 0.2873423099517822
Batch 8/64 loss: 0.2782711982727051
Batch 9/64 loss: 0.28139758110046387
Batch 10/64 loss: 0.28306859731674194
Batch 11/64 loss: 0.28647834062576294
Batch 12/64 loss: 0.28396958112716675
Batch 13/64 loss: 0.27820974588394165
Batch 14/64 loss: 0.2878330945968628
Batch 15/64 loss: 0.28685665130615234
Batch 16/64 loss: 0.29035699367523193
Batch 17/64 loss: 0.2827211618423462
Batch 18/64 loss: 0.28375792503356934
Batch 19/64 loss: 0.28440749645233154
Batch 20/64 loss: 0.2930558919906616
Batch 21/64 loss: 0.2787743806838989
Batch 22/64 loss: 0.2886059284210205
Batch 23/64 loss: 0.29080235958099365
Batch 24/64 loss: 0.2794041037559509
Batch 25/64 loss: 0.2789919376373291
Batch 26/64 loss: 0.28008049726486206
Batch 27/64 loss: 0.27627986669540405
Batch 28/64 loss: 0.2779143452644348
Batch 29/64 loss: 0.2894684076309204
Batch 30/64 loss: 0.27768611907958984
Batch 31/64 loss: 0.29413723945617676
Batch 32/64 loss: 0.2836802005767822
Batch 33/64 loss: 0.2869248390197754
Batch 34/64 loss: 0.286399781703949
Batch 35/64 loss: 0.28094977140426636
Batch 36/64 loss: 0.29156553745269775
Batch 37/64 loss: 0.2801111936569214
Batch 38/64 loss: 0.2794848680496216
Batch 39/64 loss: 0.2799006700515747
Batch 40/64 loss: 0.28618353605270386
Batch 41/64 loss: 0.2881755232810974
Batch 42/64 loss: 0.28393763303756714
Batch 43/64 loss: 0.28273826837539673
Batch 44/64 loss: 0.2853838801383972
Batch 45/64 loss: 0.2869482636451721
Batch 46/64 loss: 0.2779895067214966
Batch 47/64 loss: 0.28818273544311523
Batch 48/64 loss: 0.29097604751586914
Batch 49/64 loss: 0.2847701907157898
Batch 50/64 loss: 0.2769770622253418
Batch 51/64 loss: 0.2908923625946045
Batch 52/64 loss: 0.2908594608306885
Batch 53/64 loss: 0.28449881076812744
Batch 54/64 loss: 0.29091691970825195
Batch 55/64 loss: 0.2920985221862793
Batch 56/64 loss: 0.28285443782806396
Batch 57/64 loss: 0.2911566495895386
Batch 58/64 loss: 0.29256582260131836
Batch 59/64 loss: 0.29006797075271606
Batch 60/64 loss: 0.28490567207336426
Batch 61/64 loss: 0.27741342782974243
Batch 62/64 loss: 0.28519511222839355
Batch 63/64 loss: 0.2802641987800598
Batch 64/64 loss: 0.28025001287460327
Epoch 85  Train loss: 0.28486640429964255  Val loss: 0.3049867679573007
Saving best model, epoch: 85
Epoch 86
-------------------------------
Batch 1/64 loss: 0.2820829153060913
Batch 2/64 loss: 0.29043757915496826
Batch 3/64 loss: 0.28279364109039307
Batch 4/64 loss: 0.2887767553329468
Batch 5/64 loss: 0.28406214714050293
Batch 6/64 loss: 0.2860051393508911
Batch 7/64 loss: 0.28445178270339966
Batch 8/64 loss: 0.28763628005981445
Batch 9/64 loss: 0.2728199362754822
Batch 10/64 loss: 0.28889578580856323
Batch 11/64 loss: 0.27844130992889404
Batch 12/64 loss: 0.287276029586792
Batch 13/64 loss: 0.2918977737426758
Batch 14/64 loss: 0.27700304985046387
Batch 15/64 loss: 0.2915385365486145
Batch 16/64 loss: 0.28562211990356445
Batch 17/64 loss: 0.2845114469528198
Batch 18/64 loss: 0.2810976505279541
Batch 19/64 loss: 0.2819373607635498
Batch 20/64 loss: 0.28005701303482056
Batch 21/64 loss: 0.29287469387054443
Batch 22/64 loss: 0.28272128105163574
Batch 23/64 loss: 0.29310542345046997
Batch 24/64 loss: 0.2801162004470825
Batch 25/64 loss: 0.28535908460617065
Batch 26/64 loss: 0.2789909839630127
Batch 27/64 loss: 0.2791091203689575
Batch 28/64 loss: 0.289034366607666
Batch 29/64 loss: 0.27670419216156006
Batch 30/64 loss: 0.27858805656433105
Batch 31/64 loss: 0.2951740026473999
Batch 32/64 loss: 0.28878092765808105
Batch 33/64 loss: 0.28898632526397705
Batch 34/64 loss: 0.2846416234970093
Batch 35/64 loss: 0.2835038900375366
Batch 36/64 loss: 0.285003662109375
Batch 37/64 loss: 0.28386199474334717
Batch 38/64 loss: 0.29425859451293945
Batch 39/64 loss: 0.28131306171417236
Batch 40/64 loss: 0.2878039479255676
Batch 41/64 loss: 0.288078248500824
Batch 42/64 loss: 0.2872239351272583
Batch 43/64 loss: 0.29309630393981934
Batch 44/64 loss: 0.2885681390762329
Batch 45/64 loss: 0.2831442356109619
Batch 46/64 loss: 0.2878847122192383
Batch 47/64 loss: 0.27316105365753174
Batch 48/64 loss: 0.2858158349990845
Batch 49/64 loss: 0.28240907192230225
Batch 50/64 loss: 0.28816092014312744
Batch 51/64 loss: 0.28639233112335205
Batch 52/64 loss: 0.28496259450912476
Batch 53/64 loss: 0.28899437189102173
Batch 54/64 loss: 0.28293007612228394
Batch 55/64 loss: 0.28597259521484375
Batch 56/64 loss: 0.27946293354034424
Batch 57/64 loss: 0.29222559928894043
Batch 58/64 loss: 0.2885408401489258
Batch 59/64 loss: 0.2797601819038391
Batch 60/64 loss: 0.28506171703338623
Batch 61/64 loss: 0.2842226028442383
Batch 62/64 loss: 0.28042733669281006
Batch 63/64 loss: 0.2857353687286377
Batch 64/64 loss: 0.28449350595474243
Epoch 86  Train loss: 0.2850647344308741  Val loss: 0.3057663960964819
Epoch 87
-------------------------------
Batch 1/64 loss: 0.2834968566894531
Batch 2/64 loss: 0.29043006896972656
Batch 3/64 loss: 0.2836160659790039
Batch 4/64 loss: 0.28572630882263184
Batch 5/64 loss: 0.2908325791358948
Batch 6/64 loss: 0.2872086763381958
Batch 7/64 loss: 0.28252947330474854
Batch 8/64 loss: 0.2810842990875244
Batch 9/64 loss: 0.29472315311431885
Batch 10/64 loss: 0.29084551334381104
Batch 11/64 loss: 0.28549015522003174
Batch 12/64 loss: 0.27977830171585083
Batch 13/64 loss: 0.2778957486152649
Batch 14/64 loss: 0.2845732569694519
Batch 15/64 loss: 0.27898186445236206
Batch 16/64 loss: 0.28791046142578125
Batch 17/64 loss: 0.2886775732040405
Batch 18/64 loss: 0.2807379961013794
Batch 19/64 loss: 0.281072199344635
Batch 20/64 loss: 0.284604549407959
Batch 21/64 loss: 0.29527735710144043
Batch 22/64 loss: 0.2903369665145874
Batch 23/64 loss: 0.295171320438385
Batch 24/64 loss: 0.2868236303329468
Batch 25/64 loss: 0.27956175804138184
Batch 26/64 loss: 0.28758591413497925
Batch 27/64 loss: 0.28734850883483887
Batch 28/64 loss: 0.2788419723510742
Batch 29/64 loss: 0.2917722463607788
Batch 30/64 loss: 0.2849702835083008
Batch 31/64 loss: 0.28069812059402466
Batch 32/64 loss: 0.27900660037994385
Batch 33/64 loss: 0.28036385774612427
Batch 34/64 loss: 0.2783135175704956
Batch 35/64 loss: 0.28028684854507446
Batch 36/64 loss: 0.28887200355529785
Batch 37/64 loss: 0.2792515158653259
Batch 38/64 loss: 0.28444111347198486
Batch 39/64 loss: 0.28569483757019043
Batch 40/64 loss: 0.2778747081756592
Batch 41/64 loss: 0.2844621539115906
Batch 42/64 loss: 0.29013633728027344
Batch 43/64 loss: 0.28545069694519043
Batch 44/64 loss: 0.28165459632873535
Batch 45/64 loss: 0.27866798639297485
Batch 46/64 loss: 0.2789520025253296
Batch 47/64 loss: 0.28937792778015137
Batch 48/64 loss: 0.28368496894836426
Batch 49/64 loss: 0.27709174156188965
Batch 50/64 loss: 0.281701922416687
Batch 51/64 loss: 0.2911045551300049
Batch 52/64 loss: 0.28624653816223145
Batch 53/64 loss: 0.2870863676071167
Batch 54/64 loss: 0.28248316049575806
Batch 55/64 loss: 0.29355669021606445
Batch 56/64 loss: 0.2789825201034546
Batch 57/64 loss: 0.2789100408554077
Batch 58/64 loss: 0.28740251064300537
Batch 59/64 loss: 0.2955511808395386
Batch 60/64 loss: 0.28288978338241577
Batch 61/64 loss: 0.2858731150627136
Batch 62/64 loss: 0.2870601415634155
Batch 63/64 loss: 0.27735233306884766
Batch 64/64 loss: 0.2828953266143799
Epoch 87  Train loss: 0.2847146501728133  Val loss: 0.3046346101973884
Saving best model, epoch: 87
Epoch 88
-------------------------------
Batch 1/64 loss: 0.28257763385772705
Batch 2/64 loss: 0.27633917331695557
Batch 3/64 loss: 0.2857019901275635
Batch 4/64 loss: 0.278667688369751
Batch 5/64 loss: 0.28328561782836914
Batch 6/64 loss: 0.2831769585609436
Batch 7/64 loss: 0.2835620641708374
Batch 8/64 loss: 0.2873004674911499
Batch 9/64 loss: 0.2793784737586975
Batch 10/64 loss: 0.2837854027748108
Batch 11/64 loss: 0.2859886884689331
Batch 12/64 loss: 0.27410197257995605
Batch 13/64 loss: 0.29714226722717285
Batch 14/64 loss: 0.2736552953720093
Batch 15/64 loss: 0.28487104177474976
Batch 16/64 loss: 0.28561317920684814
Batch 17/64 loss: 0.282529354095459
Batch 18/64 loss: 0.2808505892753601
Batch 19/64 loss: 0.2807081937789917
Batch 20/64 loss: 0.28866076469421387
Batch 21/64 loss: 0.27304625511169434
Batch 22/64 loss: 0.28091132640838623
Batch 23/64 loss: 0.2937934398651123
Batch 24/64 loss: 0.28352606296539307
Batch 25/64 loss: 0.28314685821533203
Batch 26/64 loss: 0.2802661657333374
Batch 27/64 loss: 0.29059112071990967
Batch 28/64 loss: 0.2804415225982666
Batch 29/64 loss: 0.2745792865753174
Batch 30/64 loss: 0.2759150266647339
Batch 31/64 loss: 0.2832087278366089
Batch 32/64 loss: 0.2792259454727173
Batch 33/64 loss: 0.28874069452285767
Batch 34/64 loss: 0.2928798198699951
Batch 35/64 loss: 0.2836132049560547
Batch 36/64 loss: 0.27564340829849243
Batch 37/64 loss: 0.28174757957458496
Batch 38/64 loss: 0.28284192085266113
Batch 39/64 loss: 0.28744053840637207
Batch 40/64 loss: 0.2863938808441162
Batch 41/64 loss: 0.28042304515838623
Batch 42/64 loss: 0.2779695391654968
Batch 43/64 loss: 0.2724739909172058
Batch 44/64 loss: 0.28490883111953735
Batch 45/64 loss: 0.2791704535484314
Batch 46/64 loss: 0.28613317012786865
Batch 47/64 loss: 0.29142916202545166
Batch 48/64 loss: 0.2836519479751587
Batch 49/64 loss: 0.28900623321533203
Batch 50/64 loss: 0.2837374210357666
Batch 51/64 loss: 0.28695404529571533
Batch 52/64 loss: 0.2882620692253113
Batch 53/64 loss: 0.2872591018676758
Batch 54/64 loss: 0.2820618152618408
Batch 55/64 loss: 0.28121912479400635
Batch 56/64 loss: 0.27934741973876953
Batch 57/64 loss: 0.27815282344818115
Batch 58/64 loss: 0.28123635053634644
Batch 59/64 loss: 0.2860572338104248
Batch 60/64 loss: 0.293224036693573
Batch 61/64 loss: 0.2778899669647217
Batch 62/64 loss: 0.28521835803985596
Batch 63/64 loss: 0.29132258892059326
Batch 64/64 loss: 0.2754442095756531
Epoch 88  Train loss: 0.28313006256140916  Val loss: 0.3052436019137143
Epoch 89
-------------------------------
Batch 1/64 loss: 0.27153950929641724
Batch 2/64 loss: 0.2691774368286133
Batch 3/64 loss: 0.2804379463195801
Batch 4/64 loss: 0.2843940258026123
Batch 5/64 loss: 0.28582942485809326
Batch 6/64 loss: 0.2787976861000061
Batch 7/64 loss: 0.2943464517593384
Batch 8/64 loss: 0.2824496030807495
Batch 9/64 loss: 0.28286391496658325
Batch 10/64 loss: 0.2846972346305847
Batch 11/64 loss: 0.28147900104522705
Batch 12/64 loss: 0.2763763666152954
Batch 13/64 loss: 0.29282379150390625
Batch 14/64 loss: 0.27530449628829956
Batch 15/64 loss: 0.27405357360839844
Batch 16/64 loss: 0.2936166524887085
Batch 17/64 loss: 0.29128456115722656
Batch 18/64 loss: 0.2814640998840332
Batch 19/64 loss: 0.28383511304855347
Batch 20/64 loss: 0.27874326705932617
Batch 21/64 loss: 0.2886999845504761
Batch 22/64 loss: 0.29063189029693604
Batch 23/64 loss: 0.28880393505096436
Batch 24/64 loss: 0.2863887548446655
Batch 25/64 loss: 0.2888599634170532
Batch 26/64 loss: 0.28139615058898926
Batch 27/64 loss: 0.2831125259399414
Batch 28/64 loss: 0.28563761711120605
Batch 29/64 loss: 0.28382408618927
Batch 30/64 loss: 0.28597795963287354
Batch 31/64 loss: 0.28363609313964844
Batch 32/64 loss: 0.27927637100219727
Batch 33/64 loss: 0.2841528654098511
Batch 34/64 loss: 0.2878095507621765
Batch 35/64 loss: 0.2831815481185913
Batch 36/64 loss: 0.2850606441497803
Batch 37/64 loss: 0.2770754098892212
Batch 38/64 loss: 0.2779366374015808
Batch 39/64 loss: 0.28874993324279785
Batch 40/64 loss: 0.2848246693611145
Batch 41/64 loss: 0.2922358512878418
Batch 42/64 loss: 0.29143601655960083
Batch 43/64 loss: 0.28148770332336426
Batch 44/64 loss: 0.2806825041770935
Batch 45/64 loss: 0.28508615493774414
Batch 46/64 loss: 0.28681492805480957
Batch 47/64 loss: 0.2777416706085205
Batch 48/64 loss: 0.2821337580680847
Batch 49/64 loss: 0.2888069152832031
Batch 50/64 loss: 0.27297472953796387
Batch 51/64 loss: 0.286218523979187
Batch 52/64 loss: 0.28398048877716064
Batch 53/64 loss: 0.2873353958129883
Batch 54/64 loss: 0.28400957584381104
Batch 55/64 loss: 0.2769124507904053
Batch 56/64 loss: 0.2846792936325073
Batch 57/64 loss: 0.2836993336677551
Batch 58/64 loss: 0.28290772438049316
Batch 59/64 loss: 0.2814815044403076
Batch 60/64 loss: 0.27613234519958496
Batch 61/64 loss: 0.2772763967514038
Batch 62/64 loss: 0.27766597270965576
Batch 63/64 loss: 0.2810870409011841
Batch 64/64 loss: 0.2870544195175171
Epoch 89  Train loss: 0.28324122101652854  Val loss: 0.3044828317829014
Saving best model, epoch: 89
Epoch 90
-------------------------------
Batch 1/64 loss: 0.2753758430480957
Batch 2/64 loss: 0.2787148356437683
Batch 3/64 loss: 0.2750084400177002
Batch 4/64 loss: 0.2841426730155945
Batch 5/64 loss: 0.2784779667854309
Batch 6/64 loss: 0.2850135564804077
Batch 7/64 loss: 0.27581918239593506
Batch 8/64 loss: 0.2804678678512573
Batch 9/64 loss: 0.2798610329627991
Batch 10/64 loss: 0.278897762298584
Batch 11/64 loss: 0.28820914030075073
Batch 12/64 loss: 0.2834094762802124
Batch 13/64 loss: 0.2900710105895996
Batch 14/64 loss: 0.2817841172218323
Batch 15/64 loss: 0.28019869327545166
Batch 16/64 loss: 0.285247266292572
Batch 17/64 loss: 0.28447049856185913
Batch 18/64 loss: 0.27317702770233154
Batch 19/64 loss: 0.28387850522994995
Batch 20/64 loss: 0.2815322279930115
Batch 21/64 loss: 0.28389227390289307
Batch 22/64 loss: 0.29282712936401367
Batch 23/64 loss: 0.2772641181945801
Batch 24/64 loss: 0.29181015491485596
Batch 25/64 loss: 0.28832823038101196
Batch 26/64 loss: 0.28612208366394043
Batch 27/64 loss: 0.28297996520996094
Batch 28/64 loss: 0.28325212001800537
Batch 29/64 loss: 0.2864754796028137
Batch 30/64 loss: 0.28154289722442627
Batch 31/64 loss: 0.2885599136352539
Batch 32/64 loss: 0.2863435745239258
Batch 33/64 loss: 0.2831881642341614
Batch 34/64 loss: 0.28030067682266235
Batch 35/64 loss: 0.2791617512702942
Batch 36/64 loss: 0.28530389070510864
Batch 37/64 loss: 0.2778303623199463
Batch 38/64 loss: 0.28348731994628906
Batch 39/64 loss: 0.2834421992301941
Batch 40/64 loss: 0.2780300974845886
Batch 41/64 loss: 0.2832726240158081
Batch 42/64 loss: 0.2864375114440918
Batch 43/64 loss: 0.2803959846496582
Batch 44/64 loss: 0.2832092046737671
Batch 45/64 loss: 0.29178887605667114
Batch 46/64 loss: 0.280831515789032
Batch 47/64 loss: 0.285144567489624
Batch 48/64 loss: 0.2793501615524292
Batch 49/64 loss: 0.281863272190094
Batch 50/64 loss: 0.2834416627883911
Batch 51/64 loss: 0.2839028239250183
Batch 52/64 loss: 0.281522274017334
Batch 53/64 loss: 0.2811881899833679
Batch 54/64 loss: 0.2780799865722656
Batch 55/64 loss: 0.2840069532394409
Batch 56/64 loss: 0.27122825384140015
Batch 57/64 loss: 0.2759443521499634
Batch 58/64 loss: 0.29298365116119385
Batch 59/64 loss: 0.2801644206047058
Batch 60/64 loss: 0.2840714454650879
Batch 61/64 loss: 0.2718477249145508
Batch 62/64 loss: 0.2743435502052307
Batch 63/64 loss: 0.2815878391265869
Batch 64/64 loss: 0.2797180414199829
Epoch 90  Train loss: 0.2822007043688905  Val loss: 0.30499880236039045
Epoch 91
-------------------------------
Batch 1/64 loss: 0.2797284722328186
Batch 2/64 loss: 0.27355635166168213
Batch 3/64 loss: 0.2780662775039673
Batch 4/64 loss: 0.2774326801300049
Batch 5/64 loss: 0.2835104465484619
Batch 6/64 loss: 0.2841334342956543
Batch 7/64 loss: 0.27627426385879517
Batch 8/64 loss: 0.28313446044921875
Batch 9/64 loss: 0.27756935358047485
Batch 10/64 loss: 0.2767522931098938
Batch 11/64 loss: 0.2794058322906494
Batch 12/64 loss: 0.27769196033477783
Batch 13/64 loss: 0.28611648082733154
Batch 14/64 loss: 0.28228819370269775
Batch 15/64 loss: 0.2757146954536438
Batch 16/64 loss: 0.28318190574645996
Batch 17/64 loss: 0.2757420539855957
Batch 18/64 loss: 0.2855590581893921
Batch 19/64 loss: 0.2791072130203247
Batch 20/64 loss: 0.2802910804748535
Batch 21/64 loss: 0.2815609574317932
Batch 22/64 loss: 0.278148889541626
Batch 23/64 loss: 0.28287625312805176
Batch 24/64 loss: 0.28808242082595825
Batch 25/64 loss: 0.2831861972808838
Batch 26/64 loss: 0.2916741371154785
Batch 27/64 loss: 0.27602243423461914
Batch 28/64 loss: 0.2779353857040405
Batch 29/64 loss: 0.2809068560600281
Batch 30/64 loss: 0.28774380683898926
Batch 31/64 loss: 0.2735137939453125
Batch 32/64 loss: 0.2841743230819702
Batch 33/64 loss: 0.2814781665802002
Batch 34/64 loss: 0.2752198576927185
Batch 35/64 loss: 0.2751780152320862
Batch 36/64 loss: 0.28256726264953613
Batch 37/64 loss: 0.2874460816383362
Batch 38/64 loss: 0.27304065227508545
Batch 39/64 loss: 0.27811503410339355
Batch 40/64 loss: 0.27570903301239014
Batch 41/64 loss: 0.293418288230896
Batch 42/64 loss: 0.27378278970718384
Batch 43/64 loss: 0.2734954357147217
Batch 44/64 loss: 0.28217291831970215
Batch 45/64 loss: 0.29447734355926514
Batch 46/64 loss: 0.28043293952941895
Batch 47/64 loss: 0.28215765953063965
Batch 48/64 loss: 0.2866344451904297
Batch 49/64 loss: 0.2873271107673645
Batch 50/64 loss: 0.2776355743408203
Batch 51/64 loss: 0.2911950349807739
Batch 52/64 loss: 0.27865105867385864
Batch 53/64 loss: 0.27879422903060913
Batch 54/64 loss: 0.2799486517906189
Batch 55/64 loss: 0.29595375061035156
Batch 56/64 loss: 0.2811495065689087
Batch 57/64 loss: 0.28046131134033203
Batch 58/64 loss: 0.283674418926239
Batch 59/64 loss: 0.2871882915496826
Batch 60/64 loss: 0.279369056224823
Batch 61/64 loss: 0.29045724868774414
Batch 62/64 loss: 0.28104478120803833
Batch 63/64 loss: 0.26922762393951416
Batch 64/64 loss: 0.29313623905181885
Epoch 91  Train loss: 0.28138568962321564  Val loss: 0.3040852329575319
Saving best model, epoch: 91
Epoch 92
-------------------------------
Batch 1/64 loss: 0.2779359817504883
Batch 2/64 loss: 0.27911698818206787
Batch 3/64 loss: 0.28743433952331543
Batch 4/64 loss: 0.2819635272026062
Batch 5/64 loss: 0.27690398693084717
Batch 6/64 loss: 0.27907687425613403
Batch 7/64 loss: 0.27798688411712646
Batch 8/64 loss: 0.27748918533325195
Batch 9/64 loss: 0.27913087606430054
Batch 10/64 loss: 0.2857099771499634
Batch 11/64 loss: 0.27680230140686035
Batch 12/64 loss: 0.2785034775733948
Batch 13/64 loss: 0.2748483419418335
Batch 14/64 loss: 0.2776750326156616
Batch 15/64 loss: 0.2880181074142456
Batch 16/64 loss: 0.27636557817459106
Batch 17/64 loss: 0.28333866596221924
Batch 18/64 loss: 0.27942532300949097
Batch 19/64 loss: 0.28194403648376465
Batch 20/64 loss: 0.2761939764022827
Batch 21/64 loss: 0.27141547203063965
Batch 22/64 loss: 0.29137563705444336
Batch 23/64 loss: 0.28840112686157227
Batch 24/64 loss: 0.284152626991272
Batch 25/64 loss: 0.2867586612701416
Batch 26/64 loss: 0.28009670972824097
Batch 27/64 loss: 0.28345292806625366
Batch 28/64 loss: 0.27876925468444824
Batch 29/64 loss: 0.27774953842163086
Batch 30/64 loss: 0.27967923879623413
Batch 31/64 loss: 0.281982958316803
Batch 32/64 loss: 0.27232712507247925
Batch 33/64 loss: 0.2791311740875244
Batch 34/64 loss: 0.2795085906982422
Batch 35/64 loss: 0.28644120693206787
Batch 36/64 loss: 0.2819553017616272
Batch 37/64 loss: 0.2797427177429199
Batch 38/64 loss: 0.278012752532959
Batch 39/64 loss: 0.2766072750091553
Batch 40/64 loss: 0.28307294845581055
Batch 41/64 loss: 0.2836762070655823
Batch 42/64 loss: 0.28043538331985474
Batch 43/64 loss: 0.2864624857902527
Batch 44/64 loss: 0.2792685031890869
Batch 45/64 loss: 0.27878713607788086
Batch 46/64 loss: 0.2726724147796631
Batch 47/64 loss: 0.2808191776275635
Batch 48/64 loss: 0.2825731039047241
Batch 49/64 loss: 0.2830691337585449
Batch 50/64 loss: 0.28204774856567383
Batch 51/64 loss: 0.2794954776763916
Batch 52/64 loss: 0.274509072303772
Batch 53/64 loss: 0.2745119333267212
Batch 54/64 loss: 0.2818872928619385
Batch 55/64 loss: 0.278270423412323
Batch 56/64 loss: 0.2881358861923218
Batch 57/64 loss: 0.28779709339141846
Batch 58/64 loss: 0.28347837924957275
Batch 59/64 loss: 0.2784183621406555
Batch 60/64 loss: 0.2926980257034302
Batch 61/64 loss: 0.28165340423583984
Batch 62/64 loss: 0.28603702783584595
Batch 63/64 loss: 0.2786290645599365
Batch 64/64 loss: 0.28692346811294556
Epoch 92  Train loss: 0.28089446343627633  Val loss: 0.3037615076373123
Saving best model, epoch: 92
Epoch 93
-------------------------------
Batch 1/64 loss: 0.28296828269958496
Batch 2/64 loss: 0.2837637662887573
Batch 3/64 loss: 0.2828472852706909
Batch 4/64 loss: 0.2858123183250427
Batch 5/64 loss: 0.2846378684043884
Batch 6/64 loss: 0.27907514572143555
Batch 7/64 loss: 0.2800987958908081
Batch 8/64 loss: 0.2802712321281433
Batch 9/64 loss: 0.27298736572265625
Batch 10/64 loss: 0.2778497338294983
Batch 11/64 loss: 0.28458458185195923
Batch 12/64 loss: 0.27507174015045166
Batch 13/64 loss: 0.2754777669906616
Batch 14/64 loss: 0.291507363319397
Batch 15/64 loss: 0.28705406188964844
Batch 16/64 loss: 0.2797148823738098
Batch 17/64 loss: 0.28015559911727905
Batch 18/64 loss: 0.27872925996780396
Batch 19/64 loss: 0.2797797918319702
Batch 20/64 loss: 0.2862091064453125
Batch 21/64 loss: 0.2833462953567505
Batch 22/64 loss: 0.2820281982421875
Batch 23/64 loss: 0.28291434049606323
Batch 24/64 loss: 0.27832329273223877
Batch 25/64 loss: 0.2774197459220886
Batch 26/64 loss: 0.2666521668434143
Batch 27/64 loss: 0.28776830434799194
Batch 28/64 loss: 0.2748997211456299
Batch 29/64 loss: 0.2811635136604309
Batch 30/64 loss: 0.2750394344329834
Batch 31/64 loss: 0.28185564279556274
Batch 32/64 loss: 0.27953600883483887
Batch 33/64 loss: 0.2777875065803528
Batch 34/64 loss: 0.2706407308578491
Batch 35/64 loss: 0.28599458932876587
Batch 36/64 loss: 0.2799000144004822
Batch 37/64 loss: 0.2761269807815552
Batch 38/64 loss: 0.26947033405303955
Batch 39/64 loss: 0.2768040895462036
Batch 40/64 loss: 0.2803505063056946
Batch 41/64 loss: 0.2815660238265991
Batch 42/64 loss: 0.2814875841140747
Batch 43/64 loss: 0.2861858010292053
Batch 44/64 loss: 0.2799602150917053
Batch 45/64 loss: 0.27955687046051025
Batch 46/64 loss: 0.2782686948776245
Batch 47/64 loss: 0.2818448543548584
Batch 48/64 loss: 0.2788679599761963
Batch 49/64 loss: 0.2817510962486267
Batch 50/64 loss: 0.2796732187271118
Batch 51/64 loss: 0.27925145626068115
Batch 52/64 loss: 0.2775050401687622
Batch 53/64 loss: 0.28602927923202515
Batch 54/64 loss: 0.28095531463623047
Batch 55/64 loss: 0.2896709442138672
Batch 56/64 loss: 0.27819836139678955
Batch 57/64 loss: 0.27909624576568604
Batch 58/64 loss: 0.28591394424438477
Batch 59/64 loss: 0.284930944442749
Batch 60/64 loss: 0.27406060695648193
Batch 61/64 loss: 0.2827718257904053
Batch 62/64 loss: 0.2829645276069641
Batch 63/64 loss: 0.280737042427063
Batch 64/64 loss: 0.28895437717437744
Epoch 93  Train loss: 0.28054244705274994  Val loss: 0.3036149447316566
Saving best model, epoch: 93
Epoch 94
-------------------------------
Batch 1/64 loss: 0.27833259105682373
Batch 2/64 loss: 0.2838723659515381
Batch 3/64 loss: 0.27197057008743286
Batch 4/64 loss: 0.2773933410644531
Batch 5/64 loss: 0.2813626527786255
Batch 6/64 loss: 0.2771996259689331
Batch 7/64 loss: 0.2824282646179199
Batch 8/64 loss: 0.2718876600265503
Batch 9/64 loss: 0.28272122144699097
Batch 10/64 loss: 0.2771538496017456
Batch 11/64 loss: 0.2764627933502197
Batch 12/64 loss: 0.28062355518341064
Batch 13/64 loss: 0.27806901931762695
Batch 14/64 loss: 0.281883180141449
Batch 15/64 loss: 0.2812240719795227
Batch 16/64 loss: 0.2697286605834961
Batch 17/64 loss: 0.2799428105354309
Batch 18/64 loss: 0.28360575437545776
Batch 19/64 loss: 0.2857096791267395
Batch 20/64 loss: 0.284670352935791
Batch 21/64 loss: 0.2742319107055664
Batch 22/64 loss: 0.2760049104690552
Batch 23/64 loss: 0.2788781523704529
Batch 24/64 loss: 0.2810720205307007
Batch 25/64 loss: 0.2856096029281616
Batch 26/64 loss: 0.27558350563049316
Batch 27/64 loss: 0.28272855281829834
Batch 28/64 loss: 0.28664159774780273
Batch 29/64 loss: 0.283453106880188
Batch 30/64 loss: 0.28186631202697754
Batch 31/64 loss: 0.2850099205970764
Batch 32/64 loss: 0.28004592657089233
Batch 33/64 loss: 0.2782740592956543
Batch 34/64 loss: 0.2789604663848877
Batch 35/64 loss: 0.27951979637145996
Batch 36/64 loss: 0.28139305114746094
Batch 37/64 loss: 0.2803446054458618
Batch 38/64 loss: 0.2804809808731079
Batch 39/64 loss: 0.2725478410720825
Batch 40/64 loss: 0.28899574279785156
Batch 41/64 loss: 0.27350133657455444
Batch 42/64 loss: 0.2878154516220093
Batch 43/64 loss: 0.27417540550231934
Batch 44/64 loss: 0.28851473331451416
Batch 45/64 loss: 0.28633105754852295
Batch 46/64 loss: 0.27635180950164795
Batch 47/64 loss: 0.28119707107543945
Batch 48/64 loss: 0.28180086612701416
Batch 49/64 loss: 0.2782646417617798
Batch 50/64 loss: 0.28078436851501465
Batch 51/64 loss: 0.2867248058319092
Batch 52/64 loss: 0.28096628189086914
Batch 53/64 loss: 0.2736583948135376
Batch 54/64 loss: 0.28319811820983887
Batch 55/64 loss: 0.27887582778930664
Batch 56/64 loss: 0.28124356269836426
Batch 57/64 loss: 0.2722337245941162
Batch 58/64 loss: 0.27795201539993286
Batch 59/64 loss: 0.2837280035018921
Batch 60/64 loss: 0.28265380859375
Batch 61/64 loss: 0.2844206690788269
Batch 62/64 loss: 0.28229033946990967
Batch 63/64 loss: 0.2801303267478943
Batch 64/64 loss: 0.27546000480651855
Epoch 94  Train loss: 0.28017712480881635  Val loss: 0.30307532032740486
Saving best model, epoch: 94
Epoch 95
-------------------------------
Batch 1/64 loss: 0.28568339347839355
Batch 2/64 loss: 0.2886524796485901
Batch 3/64 loss: 0.275368332862854
Batch 4/64 loss: 0.2809339761734009
Batch 5/64 loss: 0.2765880227088928
Batch 6/64 loss: 0.27563172578811646
Batch 7/64 loss: 0.27607518434524536
Batch 8/64 loss: 0.274522066116333
Batch 9/64 loss: 0.2790527939796448
Batch 10/64 loss: 0.27776408195495605
Batch 11/64 loss: 0.2850661873817444
Batch 12/64 loss: 0.2781416177749634
Batch 13/64 loss: 0.27764904499053955
Batch 14/64 loss: 0.271470308303833
Batch 15/64 loss: 0.28045654296875
Batch 16/64 loss: 0.2742651700973511
Batch 17/64 loss: 0.2860602140426636
Batch 18/64 loss: 0.27750855684280396
Batch 19/64 loss: 0.2827240824699402
Batch 20/64 loss: 0.2710447311401367
Batch 21/64 loss: 0.27576714754104614
Batch 22/64 loss: 0.28188276290893555
Batch 23/64 loss: 0.27158212661743164
Batch 24/64 loss: 0.2746313810348511
Batch 25/64 loss: 0.27713584899902344
Batch 26/64 loss: 0.2692534923553467
Batch 27/64 loss: 0.2838681936264038
Batch 28/64 loss: 0.27322137355804443
Batch 29/64 loss: 0.27606838941574097
Batch 30/64 loss: 0.27768880128860474
Batch 31/64 loss: 0.277399480342865
Batch 32/64 loss: 0.27425122261047363
Batch 33/64 loss: 0.2880288362503052
Batch 34/64 loss: 0.27754342555999756
Batch 35/64 loss: 0.2823481559753418
Batch 36/64 loss: 0.2880261540412903
Batch 37/64 loss: 0.28302836418151855
Batch 38/64 loss: 0.27984893321990967
Batch 39/64 loss: 0.27520686388015747
Batch 40/64 loss: 0.2821056842803955
Batch 41/64 loss: 0.2753911018371582
Batch 42/64 loss: 0.273800253868103
Batch 43/64 loss: 0.27499616146087646
Batch 44/64 loss: 0.28250110149383545
Batch 45/64 loss: 0.2766627073287964
Batch 46/64 loss: 0.2708495259284973
Batch 47/64 loss: 0.27487653493881226
Batch 48/64 loss: 0.2738884687423706
Batch 49/64 loss: 0.27272170782089233
Batch 50/64 loss: 0.2813093662261963
Batch 51/64 loss: 0.274619460105896
Batch 52/64 loss: 0.28506964445114136
Batch 53/64 loss: 0.285730242729187
Batch 54/64 loss: 0.2830166816711426
Batch 55/64 loss: 0.27458590269088745
Batch 56/64 loss: 0.27862846851348877
Batch 57/64 loss: 0.28131937980651855
Batch 58/64 loss: 0.28425687551498413
Batch 59/64 loss: 0.275424599647522
Batch 60/64 loss: 0.27880144119262695
Batch 61/64 loss: 0.2752005457878113
Batch 62/64 loss: 0.28085970878601074
Batch 63/64 loss: 0.2798886299133301
Batch 64/64 loss: 0.290388286113739
Epoch 95  Train loss: 0.2785213313850702  Val loss: 0.3021916638534913
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: 0.2804199457168579
Batch 2/64 loss: 0.2740882635116577
Batch 3/64 loss: 0.2741166949272156
Batch 4/64 loss: 0.2689095735549927
Batch 5/64 loss: 0.28226906061172485
Batch 6/64 loss: 0.28296518325805664
Batch 7/64 loss: 0.27935659885406494
Batch 8/64 loss: 0.2775077819824219
Batch 9/64 loss: 0.27501654624938965
Batch 10/64 loss: 0.2793475389480591
Batch 11/64 loss: 0.271581768989563
Batch 12/64 loss: 0.2805103063583374
Batch 13/64 loss: 0.27359747886657715
Batch 14/64 loss: 0.28089797496795654
Batch 15/64 loss: 0.27873438596725464
Batch 16/64 loss: 0.2749024033546448
Batch 17/64 loss: 0.2815037965774536
Batch 18/64 loss: 0.2805286645889282
Batch 19/64 loss: 0.27312278747558594
Batch 20/64 loss: 0.2743845582008362
Batch 21/64 loss: 0.2800719738006592
Batch 22/64 loss: 0.2810746431350708
Batch 23/64 loss: 0.27094829082489014
Batch 24/64 loss: 0.2780604362487793
Batch 25/64 loss: 0.2714865803718567
Batch 26/64 loss: 0.28475314378738403
Batch 27/64 loss: 0.2782670855522156
Batch 28/64 loss: 0.27745532989501953
Batch 29/64 loss: 0.2728499174118042
Batch 30/64 loss: 0.27491825819015503
Batch 31/64 loss: 0.27929097414016724
Batch 32/64 loss: 0.2832450270652771
Batch 33/64 loss: 0.27613186836242676
Batch 34/64 loss: 0.28142404556274414
Batch 35/64 loss: 0.28498566150665283
Batch 36/64 loss: 0.27500396966934204
Batch 37/64 loss: 0.2832190990447998
Batch 38/64 loss: 0.2802223563194275
Batch 39/64 loss: 0.283205509185791
Batch 40/64 loss: 0.27209460735321045
Batch 41/64 loss: 0.2931351661682129
Batch 42/64 loss: 0.27816200256347656
Batch 43/64 loss: 0.2724187970161438
Batch 44/64 loss: 0.28271985054016113
Batch 45/64 loss: 0.278586208820343
Batch 46/64 loss: 0.2724079489707947
Batch 47/64 loss: 0.27497339248657227
Batch 48/64 loss: 0.27685534954071045
Batch 49/64 loss: 0.28238821029663086
Batch 50/64 loss: 0.27642130851745605
Batch 51/64 loss: 0.276261568069458
Batch 52/64 loss: 0.27505457401275635
Batch 53/64 loss: 0.2845919728279114
Batch 54/64 loss: 0.2803531885147095
Batch 55/64 loss: 0.2771798372268677
Batch 56/64 loss: 0.2761467695236206
Batch 57/64 loss: 0.2783934473991394
Batch 58/64 loss: 0.2839495539665222
Batch 59/64 loss: 0.28589969873428345
Batch 60/64 loss: 0.2755850553512573
Batch 61/64 loss: 0.2850227355957031
Batch 62/64 loss: 0.28770482540130615
Batch 63/64 loss: 0.27422821521759033
Batch 64/64 loss: 0.2853638529777527
Epoch 96  Train loss: 0.27850874755896776  Val loss: 0.3035181418726944
Epoch 97
-------------------------------
Batch 1/64 loss: 0.27600979804992676
Batch 2/64 loss: 0.27605175971984863
Batch 3/64 loss: 0.27833449840545654
Batch 4/64 loss: 0.27990418672561646
Batch 5/64 loss: 0.2795729637145996
Batch 6/64 loss: 0.28483808040618896
Batch 7/64 loss: 0.2832794189453125
Batch 8/64 loss: 0.27827227115631104
Batch 9/64 loss: 0.2766474485397339
Batch 10/64 loss: 0.2809060215950012
Batch 11/64 loss: 0.27893054485321045
Batch 12/64 loss: 0.2777770757675171
Batch 13/64 loss: 0.2691352367401123
Batch 14/64 loss: 0.2782905697822571
Batch 15/64 loss: 0.2782245874404907
Batch 16/64 loss: 0.27390623092651367
Batch 17/64 loss: 0.2791774868965149
Batch 18/64 loss: 0.2791163921356201
Batch 19/64 loss: 0.27911674976348877
Batch 20/64 loss: 0.2676147222518921
Batch 21/64 loss: 0.26718389987945557
Batch 22/64 loss: 0.27053236961364746
Batch 23/64 loss: 0.2833743095397949
Batch 24/64 loss: 0.28040367364883423
Batch 25/64 loss: 0.27536821365356445
Batch 26/64 loss: 0.2795880436897278
Batch 27/64 loss: 0.27852582931518555
Batch 28/64 loss: 0.27408456802368164
Batch 29/64 loss: 0.27300095558166504
Batch 30/64 loss: 0.2863534688949585
Batch 31/64 loss: 0.2736275792121887
Batch 32/64 loss: 0.27963030338287354
Batch 33/64 loss: 0.27880966663360596
Batch 34/64 loss: 0.2738990783691406
Batch 35/64 loss: 0.2710998058319092
Batch 36/64 loss: 0.2797638177871704
Batch 37/64 loss: 0.2738306522369385
Batch 38/64 loss: 0.27982097864151
Batch 39/64 loss: 0.2677531838417053
Batch 40/64 loss: 0.27373528480529785
Batch 41/64 loss: 0.27829253673553467
Batch 42/64 loss: 0.27595311403274536
Batch 43/64 loss: 0.29058313369750977
Batch 44/64 loss: 0.2789883613586426
Batch 45/64 loss: 0.28176063299179077
Batch 46/64 loss: 0.2840244174003601
Batch 47/64 loss: 0.2801769971847534
Batch 48/64 loss: 0.2833743095397949
Batch 49/64 loss: 0.28883177042007446
Batch 50/64 loss: 0.2745143175125122
Batch 51/64 loss: 0.27656376361846924
Batch 52/64 loss: 0.27267318964004517
Batch 53/64 loss: 0.2725929617881775
Batch 54/64 loss: 0.28491532802581787
Batch 55/64 loss: 0.28305572271347046
Batch 56/64 loss: 0.2740374803543091
Batch 57/64 loss: 0.27558642625808716
Batch 58/64 loss: 0.27524518966674805
Batch 59/64 loss: 0.2865760326385498
Batch 60/64 loss: 0.2759166955947876
Batch 61/64 loss: 0.2812618613243103
Batch 62/64 loss: 0.28602445125579834
Batch 63/64 loss: 0.2744241952896118
Batch 64/64 loss: 0.28471314907073975
Epoch 97  Train loss: 0.27802979572146547  Val loss: 0.30340193882840605
Epoch 98
-------------------------------
Batch 1/64 loss: 0.2828463315963745
Batch 2/64 loss: 0.27835118770599365
Batch 3/64 loss: 0.27690601348876953
Batch 4/64 loss: 0.2699941396713257
Batch 5/64 loss: 0.2733978033065796
Batch 6/64 loss: 0.2648962736129761
Batch 7/64 loss: 0.2873290181159973
Batch 8/64 loss: 0.27103912830352783
Batch 9/64 loss: 0.2682274580001831
Batch 10/64 loss: 0.279990017414093
Batch 11/64 loss: 0.27275562286376953
Batch 12/64 loss: 0.2779530882835388
Batch 13/64 loss: 0.26454079151153564
Batch 14/64 loss: 0.2690654993057251
Batch 15/64 loss: 0.2797231078147888
Batch 16/64 loss: 0.28127777576446533
Batch 17/64 loss: 0.27944517135620117
Batch 18/64 loss: 0.2823548913002014
Batch 19/64 loss: 0.28022539615631104
Batch 20/64 loss: 0.27878183126449585
Batch 21/64 loss: 0.2804502248764038
Batch 22/64 loss: 0.26703888177871704
Batch 23/64 loss: 0.2802375555038452
Batch 24/64 loss: 0.281629741191864
Batch 25/64 loss: 0.2882797122001648
Batch 26/64 loss: 0.27970415353775024
Batch 27/64 loss: 0.2767358422279358
Batch 28/64 loss: 0.27950161695480347
Batch 29/64 loss: 0.28636324405670166
Batch 30/64 loss: 0.27373987436294556
Batch 31/64 loss: 0.2822633981704712
Batch 32/64 loss: 0.2760024666786194
Batch 33/64 loss: 0.2899355888366699
Batch 34/64 loss: 0.27641773223876953
Batch 35/64 loss: 0.2744055390357971
Batch 36/64 loss: 0.2741900682449341
Batch 37/64 loss: 0.27759021520614624
Batch 38/64 loss: 0.27923154830932617
Batch 39/64 loss: 0.2779631018638611
Batch 40/64 loss: 0.2762334942817688
Batch 41/64 loss: 0.28047382831573486
Batch 42/64 loss: 0.276241660118103
Batch 43/64 loss: 0.26697075366973877
Batch 44/64 loss: 0.2785447835922241
Batch 45/64 loss: 0.2763206362724304
Batch 46/64 loss: 0.2779895067214966
Batch 47/64 loss: 0.28659266233444214
Batch 48/64 loss: 0.28036749362945557
Batch 49/64 loss: 0.2850736379623413
Batch 50/64 loss: 0.26872730255126953
Batch 51/64 loss: 0.28376150131225586
Batch 52/64 loss: 0.27168381214141846
Batch 53/64 loss: 0.26723700761795044
Batch 54/64 loss: 0.27184808254241943
Batch 55/64 loss: 0.2686241865158081
Batch 56/64 loss: 0.2827754616737366
Batch 57/64 loss: 0.2786685824394226
Batch 58/64 loss: 0.27778321504592896
Batch 59/64 loss: 0.28120851516723633
Batch 60/64 loss: 0.27076464891433716
Batch 61/64 loss: 0.2783929109573364
Batch 62/64 loss: 0.270974338054657
Batch 63/64 loss: 0.27503180503845215
Batch 64/64 loss: 0.2888873219490051
Epoch 98  Train loss: 0.27717233522265566  Val loss: 0.30257217826712174
Epoch 99
-------------------------------
Batch 1/64 loss: 0.2808648347854614
Batch 2/64 loss: 0.27218449115753174
Batch 3/64 loss: 0.2680475115776062
Batch 4/64 loss: 0.27922534942626953
Batch 5/64 loss: 0.27038252353668213
Batch 6/64 loss: 0.2843356728553772
Batch 7/64 loss: 0.27739018201828003
Batch 8/64 loss: 0.2751671075820923
Batch 9/64 loss: 0.27570903301239014
Batch 10/64 loss: 0.27208006381988525
Batch 11/64 loss: 0.2761523723602295
Batch 12/64 loss: 0.27194952964782715
Batch 13/64 loss: 0.27776527404785156
Batch 14/64 loss: 0.27371466159820557
Batch 15/64 loss: 0.27661168575286865
Batch 16/64 loss: 0.2749694585800171
Batch 17/64 loss: 0.27722740173339844
Batch 18/64 loss: 0.2724373936653137
Batch 19/64 loss: 0.28505825996398926
Batch 20/64 loss: 0.26824498176574707
Batch 21/64 loss: 0.2731441855430603
Batch 22/64 loss: 0.27385079860687256
Batch 23/64 loss: 0.2821533679962158
Batch 24/64 loss: 0.2778193950653076
Batch 25/64 loss: 0.2735644578933716
Batch 26/64 loss: 0.2774050235748291
Batch 27/64 loss: 0.2721785306930542
Batch 28/64 loss: 0.2790858745574951
Batch 29/64 loss: 0.28083324432373047
Batch 30/64 loss: 0.27661287784576416
Batch 31/64 loss: 0.28660517930984497
Batch 32/64 loss: 0.28367114067077637
Batch 33/64 loss: 0.2780170440673828
Batch 34/64 loss: 0.2711871862411499
Batch 35/64 loss: 0.28239190578460693
Batch 36/64 loss: 0.2743051052093506
Batch 37/64 loss: 0.2788403034210205
Batch 38/64 loss: 0.27422481775283813
Batch 39/64 loss: 0.27491796016693115
Batch 40/64 loss: 0.2719108462333679
Batch 41/64 loss: 0.28595107793807983
Batch 42/64 loss: 0.27399516105651855
Batch 43/64 loss: 0.26973724365234375
Batch 44/64 loss: 0.28348469734191895
Batch 45/64 loss: 0.278231143951416
Batch 46/64 loss: 0.2782464623451233
Batch 47/64 loss: 0.2689671516418457
Batch 48/64 loss: 0.2890270948410034
Batch 49/64 loss: 0.2756919264793396
Batch 50/64 loss: 0.27401673793792725
Batch 51/64 loss: 0.2824517488479614
Batch 52/64 loss: 0.27996230125427246
Batch 53/64 loss: 0.2854156494140625
Batch 54/64 loss: 0.27000170946121216
Batch 55/64 loss: 0.27688002586364746
Batch 56/64 loss: 0.27393120527267456
Batch 57/64 loss: 0.28067100048065186
Batch 58/64 loss: 0.27694302797317505
Batch 59/64 loss: 0.2868025302886963
Batch 60/64 loss: 0.2817906141281128
Batch 61/64 loss: 0.2747316360473633
Batch 62/64 loss: 0.2783212661743164
Batch 63/64 loss: 0.2728930115699768
Batch 64/64 loss: 0.26919829845428467
Epoch 99  Train loss: 0.27689851265327603  Val loss: 0.3024994442143391
Epoch 100
-------------------------------
Batch 1/64 loss: 0.26451361179351807
Batch 2/64 loss: 0.2750554084777832
Batch 3/64 loss: 0.27887648344039917
Batch 4/64 loss: 0.2830545902252197
Batch 5/64 loss: 0.26967155933380127
Batch 6/64 loss: 0.2707475423812866
Batch 7/64 loss: 0.2810453772544861
Batch 8/64 loss: 0.27577173709869385
Batch 9/64 loss: 0.2702525854110718
Batch 10/64 loss: 0.27415943145751953
Batch 11/64 loss: 0.28123271465301514
Batch 12/64 loss: 0.2771746516227722
Batch 13/64 loss: 0.278805136680603
Batch 14/64 loss: 0.2773709297180176
Batch 15/64 loss: 0.2716377377510071
Batch 16/64 loss: 0.27911263704299927
Batch 17/64 loss: 0.2795918583869934
Batch 18/64 loss: 0.27396517992019653
Batch 19/64 loss: 0.2759287357330322
Batch 20/64 loss: 0.2650498151779175
Batch 21/64 loss: 0.2705586552619934
Batch 22/64 loss: 0.27714598178863525
Batch 23/64 loss: 0.28151530027389526
Batch 24/64 loss: 0.27923476696014404
Batch 25/64 loss: 0.27806925773620605
Batch 26/64 loss: 0.2789948582649231
Batch 27/64 loss: 0.2837097644805908
Batch 28/64 loss: 0.2759692668914795
Batch 29/64 loss: 0.2707793116569519
Batch 30/64 loss: 0.2758229374885559
Batch 31/64 loss: 0.28098154067993164
Batch 32/64 loss: 0.2787497043609619
Batch 33/64 loss: 0.2752150297164917
Batch 34/64 loss: 0.2767760753631592
Batch 35/64 loss: 0.2822878360748291
Batch 36/64 loss: 0.2783879041671753
Batch 37/64 loss: 0.2767876386642456
Batch 38/64 loss: 0.2708880305290222
Batch 39/64 loss: 0.274003267288208
Batch 40/64 loss: 0.2748468518257141
Batch 41/64 loss: 0.2689385414123535
Batch 42/64 loss: 0.2756635546684265
Batch 43/64 loss: 0.26963919401168823
Batch 44/64 loss: 0.2722346782684326
Batch 45/64 loss: 0.27264636754989624
Batch 46/64 loss: 0.27284735441207886
Batch 47/64 loss: 0.27502918243408203
Batch 48/64 loss: 0.2765007019042969
Batch 49/64 loss: 0.26361143589019775
Batch 50/64 loss: 0.27953803539276123
Batch 51/64 loss: 0.27813124656677246
Batch 52/64 loss: 0.2779234051704407
Batch 53/64 loss: 0.2760958671569824
Batch 54/64 loss: 0.2794983386993408
Batch 55/64 loss: 0.2736414670944214
Batch 56/64 loss: 0.27849042415618896
Batch 57/64 loss: 0.277244508266449
Batch 58/64 loss: 0.2722892165184021
Batch 59/64 loss: 0.2807164192199707
Batch 60/64 loss: 0.27655887603759766
Batch 61/64 loss: 0.27383941411972046
Batch 62/64 loss: 0.28413569927215576
Batch 63/64 loss: 0.27803611755371094
Batch 64/64 loss: 0.2789098620414734
Epoch 100  Train loss: 0.275861555221034  Val loss: 0.3019438232343221
Saving best model, epoch: 100
Epoch 101
-------------------------------
Batch 1/64 loss: 0.2680550813674927
Batch 2/64 loss: 0.27633213996887207
Batch 3/64 loss: 0.2752535343170166
Batch 4/64 loss: 0.2773776650428772
Batch 5/64 loss: 0.27554774284362793
Batch 6/64 loss: 0.2712833881378174
Batch 7/64 loss: 0.2774023413658142
Batch 8/64 loss: 0.28244030475616455
Batch 9/64 loss: 0.26914429664611816
Batch 10/64 loss: 0.2682270407676697
Batch 11/64 loss: 0.2700308561325073
Batch 12/64 loss: 0.28571969270706177
Batch 13/64 loss: 0.27057427167892456
Batch 14/64 loss: 0.27285856008529663
Batch 15/64 loss: 0.27268922328948975
Batch 16/64 loss: 0.28700506687164307
Batch 17/64 loss: 0.2786281108856201
Batch 18/64 loss: 0.2753608226776123
Batch 19/64 loss: 0.27669090032577515
Batch 20/64 loss: 0.27285730838775635
Batch 21/64 loss: 0.2731844186782837
Batch 22/64 loss: 0.27256327867507935
Batch 23/64 loss: 0.2727651596069336
Batch 24/64 loss: 0.26817625761032104
Batch 25/64 loss: 0.2684314250946045
Batch 26/64 loss: 0.2792750597000122
Batch 27/64 loss: 0.27916866540908813
Batch 28/64 loss: 0.27786123752593994
Batch 29/64 loss: 0.27999305725097656
Batch 30/64 loss: 0.2784927487373352
Batch 31/64 loss: 0.2789403200149536
Batch 32/64 loss: 0.26975351572036743
Batch 33/64 loss: 0.28498703241348267
Batch 34/64 loss: 0.27401018142700195
Batch 35/64 loss: 0.26826906204223633
Batch 36/64 loss: 0.27207863330841064
Batch 37/64 loss: 0.28898608684539795
Batch 38/64 loss: 0.2785987854003906
Batch 39/64 loss: 0.2698286771774292
Batch 40/64 loss: 0.2766723036766052
Batch 41/64 loss: 0.28453201055526733
Batch 42/64 loss: 0.2784682512283325
Batch 43/64 loss: 0.27898097038269043
Batch 44/64 loss: 0.28114187717437744
Batch 45/64 loss: 0.2759639024734497
Batch 46/64 loss: 0.26998335123062134
Batch 47/64 loss: 0.2705315947532654
Batch 48/64 loss: 0.2780735492706299
Batch 49/64 loss: 0.27350395917892456
Batch 50/64 loss: 0.27834171056747437
Batch 51/64 loss: 0.270388126373291
Batch 52/64 loss: 0.28291600942611694
Batch 53/64 loss: 0.27776408195495605
Batch 54/64 loss: 0.26932859420776367
Batch 55/64 loss: 0.27261054515838623
Batch 56/64 loss: 0.281857967376709
Batch 57/64 loss: 0.2873767614364624
Batch 58/64 loss: 0.27487504482269287
Batch 59/64 loss: 0.273157000541687
Batch 60/64 loss: 0.27433347702026367
Batch 61/64 loss: 0.27737343311309814
Batch 62/64 loss: 0.27813857793807983
Batch 63/64 loss: 0.2690500020980835
Batch 64/64 loss: 0.28995704650878906
Epoch 101  Train loss: 0.27594780921936035  Val loss: 0.30121296500831946
Saving best model, epoch: 101
Epoch 102
-------------------------------
Batch 1/64 loss: 0.2753570079803467
Batch 2/64 loss: 0.2738156318664551
Batch 3/64 loss: 0.2706317901611328
Batch 4/64 loss: 0.2692224979400635
Batch 5/64 loss: 0.2774670124053955
Batch 6/64 loss: 0.2747304439544678
Batch 7/64 loss: 0.2698937654495239
Batch 8/64 loss: 0.2679092288017273
Batch 9/64 loss: 0.28287744522094727
Batch 10/64 loss: 0.26925814151763916
Batch 11/64 loss: 0.26833927631378174
Batch 12/64 loss: 0.2773858904838562
Batch 13/64 loss: 0.2765926718711853
Batch 14/64 loss: 0.2778613567352295
Batch 15/64 loss: 0.27988821268081665
Batch 16/64 loss: 0.26739072799682617
Batch 17/64 loss: 0.27082669734954834
Batch 18/64 loss: 0.2753704786300659
Batch 19/64 loss: 0.283702552318573
Batch 20/64 loss: 0.26792430877685547
Batch 21/64 loss: 0.2732832431793213
Batch 22/64 loss: 0.2772020101547241
Batch 23/64 loss: 0.2798902988433838
Batch 24/64 loss: 0.27732402086257935
Batch 25/64 loss: 0.27349168062210083
Batch 26/64 loss: 0.2856733798980713
Batch 27/64 loss: 0.27394986152648926
Batch 28/64 loss: 0.2807999849319458
Batch 29/64 loss: 0.2733519673347473
Batch 30/64 loss: 0.279483437538147
Batch 31/64 loss: 0.26705408096313477
Batch 32/64 loss: 0.2647705078125
Batch 33/64 loss: 0.26899266242980957
Batch 34/64 loss: 0.2868393659591675
Batch 35/64 loss: 0.2718254327774048
Batch 36/64 loss: 0.27871453762054443
Batch 37/64 loss: 0.27806735038757324
Batch 38/64 loss: 0.26940029859542847
Batch 39/64 loss: 0.2791217565536499
Batch 40/64 loss: 0.26854240894317627
Batch 41/64 loss: 0.26735514402389526
Batch 42/64 loss: 0.2749243974685669
Batch 43/64 loss: 0.269071102142334
Batch 44/64 loss: 0.2718700170516968
Batch 45/64 loss: 0.2769124507904053
Batch 46/64 loss: 0.2686960697174072
Batch 47/64 loss: 0.2705685496330261
Batch 48/64 loss: 0.28407466411590576
Batch 49/64 loss: 0.27297747135162354
Batch 50/64 loss: 0.2802976369857788
Batch 51/64 loss: 0.27319812774658203
Batch 52/64 loss: 0.27998918294906616
Batch 53/64 loss: 0.2715551257133484
Batch 54/64 loss: 0.2720973491668701
Batch 55/64 loss: 0.2733736038208008
Batch 56/64 loss: 0.27604782581329346
Batch 57/64 loss: 0.27479827404022217
Batch 58/64 loss: 0.28263646364212036
Batch 59/64 loss: 0.271572470664978
Batch 60/64 loss: 0.278064489364624
Batch 61/64 loss: 0.2677069902420044
Batch 62/64 loss: 0.2830430269241333
Batch 63/64 loss: 0.28588569164276123
Batch 64/64 loss: 0.27246689796447754
Epoch 102  Train loss: 0.2747496427274218  Val loss: 0.30296494501972526
Epoch 103
-------------------------------
Batch 1/64 loss: 0.27462559938430786
Batch 2/64 loss: 0.2733408808708191
Batch 3/64 loss: 0.26869142055511475
Batch 4/64 loss: 0.27019405364990234
Batch 5/64 loss: 0.26836180686950684
Batch 6/64 loss: 0.2664419412612915
Batch 7/64 loss: 0.27297544479370117
Batch 8/64 loss: 0.26446831226348877
Batch 9/64 loss: 0.2775982618331909
Batch 10/64 loss: 0.2766740322113037
Batch 11/64 loss: 0.27271080017089844
Batch 12/64 loss: 0.2799437642097473
Batch 13/64 loss: 0.2796109914779663
Batch 14/64 loss: 0.2617744207382202
Batch 15/64 loss: 0.2730252742767334
Batch 16/64 loss: 0.2863394021987915
Batch 17/64 loss: 0.27051717042922974
Batch 18/64 loss: 0.2728676199913025
Batch 19/64 loss: 0.2770254611968994
Batch 20/64 loss: 0.27665233612060547
Batch 21/64 loss: 0.2735799551010132
Batch 22/64 loss: 0.2714289426803589
Batch 23/64 loss: 0.2766343355178833
Batch 24/64 loss: 0.28741323947906494
Batch 25/64 loss: 0.26742279529571533
Batch 26/64 loss: 0.28001993894577026
Batch 27/64 loss: 0.2755829691886902
Batch 28/64 loss: 0.27178096771240234
Batch 29/64 loss: 0.2719239592552185
Batch 30/64 loss: 0.2676292657852173
Batch 31/64 loss: 0.2694646120071411
Batch 32/64 loss: 0.27796006202697754
Batch 33/64 loss: 0.2784085273742676
Batch 34/64 loss: 0.2767251133918762
Batch 35/64 loss: 0.27188175916671753
Batch 36/64 loss: 0.2759767174720764
Batch 37/64 loss: 0.2723926305770874
Batch 38/64 loss: 0.266445517539978
Batch 39/64 loss: 0.27566850185394287
Batch 40/64 loss: 0.2916748523712158
Batch 41/64 loss: 0.2766401767730713
Batch 42/64 loss: 0.2847166061401367
Batch 43/64 loss: 0.27241504192352295
Batch 44/64 loss: 0.2655918002128601
Batch 45/64 loss: 0.2801121473312378
Batch 46/64 loss: 0.2735288143157959
Batch 47/64 loss: 0.2722240686416626
Batch 48/64 loss: 0.27525854110717773
Batch 49/64 loss: 0.281876802444458
Batch 50/64 loss: 0.2787536382675171
Batch 51/64 loss: 0.2752590775489807
Batch 52/64 loss: 0.27950000762939453
Batch 53/64 loss: 0.2766432762145996
Batch 54/64 loss: 0.2747427225112915
Batch 55/64 loss: 0.2791985273361206
Batch 56/64 loss: 0.2779742479324341
Batch 57/64 loss: 0.2711942195892334
Batch 58/64 loss: 0.2789544463157654
Batch 59/64 loss: 0.27666622400283813
Batch 60/64 loss: 0.2661318778991699
Batch 61/64 loss: 0.2829662561416626
Batch 62/64 loss: 0.27548712491989136
Batch 63/64 loss: 0.27084410190582275
Batch 64/64 loss: 0.2696846127510071
Epoch 103  Train loss: 0.27471053904178094  Val loss: 0.300900970332811
Saving best model, epoch: 103
Epoch 104
-------------------------------
Batch 1/64 loss: 0.27002382278442383
Batch 2/64 loss: 0.27670907974243164
Batch 3/64 loss: 0.27373844385147095
Batch 4/64 loss: 0.2605059742927551
Batch 5/64 loss: 0.2846047282218933
Batch 6/64 loss: 0.2711380124092102
Batch 7/64 loss: 0.27341246604919434
Batch 8/64 loss: 0.27437812089920044
Batch 9/64 loss: 0.2801802158355713
Batch 10/64 loss: 0.2629093527793884
Batch 11/64 loss: 0.2757488489151001
Batch 12/64 loss: 0.2704228162765503
Batch 13/64 loss: 0.2700982689857483
Batch 14/64 loss: 0.2773810625076294
Batch 15/64 loss: 0.2731478810310364
Batch 16/64 loss: 0.27993226051330566
Batch 17/64 loss: 0.26750636100769043
Batch 18/64 loss: 0.26646292209625244
Batch 19/64 loss: 0.2672126293182373
Batch 20/64 loss: 0.2646872401237488
Batch 21/64 loss: 0.28283751010894775
Batch 22/64 loss: 0.271415114402771
Batch 23/64 loss: 0.26991868019104004
Batch 24/64 loss: 0.2762101888656616
Batch 25/64 loss: 0.2651700973510742
Batch 26/64 loss: 0.27584367990493774
Batch 27/64 loss: 0.2629479169845581
Batch 28/64 loss: 0.26899266242980957
Batch 29/64 loss: 0.27253258228302
Batch 30/64 loss: 0.27377867698669434
Batch 31/64 loss: 0.27079522609710693
Batch 32/64 loss: 0.2816835641860962
Batch 33/64 loss: 0.28146791458129883
Batch 34/64 loss: 0.2710866928100586
Batch 35/64 loss: 0.2764340043067932
Batch 36/64 loss: 0.27663344144821167
Batch 37/64 loss: 0.27073848247528076
Batch 38/64 loss: 0.26411932706832886
Batch 39/64 loss: 0.2763495445251465
Batch 40/64 loss: 0.26725077629089355
Batch 41/64 loss: 0.2651550769805908
Batch 42/64 loss: 0.26994067430496216
Batch 43/64 loss: 0.28159481287002563
Batch 44/64 loss: 0.2726669907569885
Batch 45/64 loss: 0.27959322929382324
Batch 46/64 loss: 0.2738648056983948
Batch 47/64 loss: 0.2820388078689575
Batch 48/64 loss: 0.27018749713897705
Batch 49/64 loss: 0.2730438709259033
Batch 50/64 loss: 0.2668730616569519
Batch 51/64 loss: 0.27233123779296875
Batch 52/64 loss: 0.279013991355896
Batch 53/64 loss: 0.27972137928009033
Batch 54/64 loss: 0.27519309520721436
Batch 55/64 loss: 0.2742931842803955
Batch 56/64 loss: 0.2809409499168396
Batch 57/64 loss: 0.279024600982666
Batch 58/64 loss: 0.2678322196006775
Batch 59/64 loss: 0.27953559160232544
Batch 60/64 loss: 0.2772026062011719
Batch 61/64 loss: 0.2766491770744324
Batch 62/64 loss: 0.26993727684020996
Batch 63/64 loss: 0.27153480052948
Batch 64/64 loss: 0.2800896167755127
Epoch 104  Train loss: 0.2733277292812572  Val loss: 0.30125910596749217
Epoch 105
-------------------------------
Batch 1/64 loss: 0.27975142002105713
Batch 2/64 loss: 0.26974546909332275
Batch 3/64 loss: 0.2663213014602661
Batch 4/64 loss: 0.27908897399902344
Batch 5/64 loss: 0.2652655243873596
Batch 6/64 loss: 0.26770836114883423
Batch 7/64 loss: 0.26415812969207764
Batch 8/64 loss: 0.2723584771156311
Batch 9/64 loss: 0.27260416746139526
Batch 10/64 loss: 0.2775920629501343
Batch 11/64 loss: 0.27257609367370605
Batch 12/64 loss: 0.2781578302383423
Batch 13/64 loss: 0.26053154468536377
Batch 14/64 loss: 0.2837737798690796
Batch 15/64 loss: 0.2729097008705139
Batch 16/64 loss: 0.2724043130874634
Batch 17/64 loss: 0.26465147733688354
Batch 18/64 loss: 0.2735586166381836
Batch 19/64 loss: 0.274380087852478
Batch 20/64 loss: 0.2684366703033447
Batch 21/64 loss: 0.277213990688324
Batch 22/64 loss: 0.2709923982620239
Batch 23/64 loss: 0.26786357164382935
Batch 24/64 loss: 0.27606189250946045
Batch 25/64 loss: 0.27319467067718506
Batch 26/64 loss: 0.2710578441619873
Batch 27/64 loss: 0.2802228331565857
Batch 28/64 loss: 0.27642273902893066
Batch 29/64 loss: 0.2844465970993042
Batch 30/64 loss: 0.27047592401504517
Batch 31/64 loss: 0.2838214635848999
Batch 32/64 loss: 0.26709794998168945
Batch 33/64 loss: 0.27511298656463623
Batch 34/64 loss: 0.2632021903991699
Batch 35/64 loss: 0.28210556507110596
Batch 36/64 loss: 0.2763329744338989
Batch 37/64 loss: 0.273837149143219
Batch 38/64 loss: 0.2718609571456909
Batch 39/64 loss: 0.27935469150543213
Batch 40/64 loss: 0.2784988284111023
Batch 41/64 loss: 0.26870179176330566
Batch 42/64 loss: 0.27191925048828125
Batch 43/64 loss: 0.27407556772232056
Batch 44/64 loss: 0.2700076103210449
Batch 45/64 loss: 0.27817749977111816
Batch 46/64 loss: 0.2803518772125244
Batch 47/64 loss: 0.26914411783218384
Batch 48/64 loss: 0.27519798278808594
Batch 49/64 loss: 0.27425122261047363
Batch 50/64 loss: 0.2800283432006836
Batch 51/64 loss: 0.2717147469520569
Batch 52/64 loss: 0.27852070331573486
Batch 53/64 loss: 0.27813804149627686
Batch 54/64 loss: 0.2737235426902771
Batch 55/64 loss: 0.29134464263916016
Batch 56/64 loss: 0.28114259243011475
Batch 57/64 loss: 0.2796189785003662
Batch 58/64 loss: 0.2714446783065796
Batch 59/64 loss: 0.27025628089904785
Batch 60/64 loss: 0.26399803161621094
Batch 61/64 loss: 0.26411736011505127
Batch 62/64 loss: 0.2749589681625366
Batch 63/64 loss: 0.2771505117416382
Batch 64/64 loss: 0.27236664295196533
Epoch 105  Train loss: 0.2738417340259926  Val loss: 0.3009466723478127
Epoch 106
-------------------------------
Batch 1/64 loss: 0.26793861389160156
Batch 2/64 loss: 0.27355313301086426
Batch 3/64 loss: 0.2744380235671997
Batch 4/64 loss: 0.2677195072174072
Batch 5/64 loss: 0.27278584241867065
Batch 6/64 loss: 0.2744194269180298
Batch 7/64 loss: 0.2695631980895996
Batch 8/64 loss: 0.2691000699996948
Batch 9/64 loss: 0.2673162817955017
Batch 10/64 loss: 0.2716482877731323
Batch 11/64 loss: 0.27289605140686035
Batch 12/64 loss: 0.2771102786064148
Batch 13/64 loss: 0.27472585439682007
Batch 14/64 loss: 0.28031373023986816
Batch 15/64 loss: 0.27249813079833984
Batch 16/64 loss: 0.277044415473938
Batch 17/64 loss: 0.2829551696777344
Batch 18/64 loss: 0.26758599281311035
Batch 19/64 loss: 0.2681628465652466
Batch 20/64 loss: 0.261131227016449
Batch 21/64 loss: 0.27525269985198975
Batch 22/64 loss: 0.2679794430732727
Batch 23/64 loss: 0.2677242159843445
Batch 24/64 loss: 0.26613664627075195
Batch 25/64 loss: 0.27043479681015015
Batch 26/64 loss: 0.26859670877456665
Batch 27/64 loss: 0.27155303955078125
Batch 28/64 loss: 0.26772570610046387
Batch 29/64 loss: 0.2695234417915344
Batch 30/64 loss: 0.26781165599823
Batch 31/64 loss: 0.275299072265625
Batch 32/64 loss: 0.2741100788116455
Batch 33/64 loss: 0.27735453844070435
Batch 34/64 loss: 0.28169792890548706
Batch 35/64 loss: 0.2689136266708374
Batch 36/64 loss: 0.27851635217666626
Batch 37/64 loss: 0.2710384130477905
Batch 38/64 loss: 0.2747344970703125
Batch 39/64 loss: 0.27696162462234497
Batch 40/64 loss: 0.26852500438690186
Batch 41/64 loss: 0.2714715003967285
Batch 42/64 loss: 0.2706281542778015
Batch 43/64 loss: 0.2874298691749573
Batch 44/64 loss: 0.2725420594215393
Batch 45/64 loss: 0.28732991218566895
Batch 46/64 loss: 0.27518147230148315
Batch 47/64 loss: 0.27737122774124146
Batch 48/64 loss: 0.27865326404571533
Batch 49/64 loss: 0.26750266551971436
Batch 50/64 loss: 0.271587610244751
Batch 51/64 loss: 0.2691335678100586
Batch 52/64 loss: 0.27357012033462524
Batch 53/64 loss: 0.27176225185394287
Batch 54/64 loss: 0.28431177139282227
Batch 55/64 loss: 0.2746204137802124
Batch 56/64 loss: 0.26505982875823975
Batch 57/64 loss: 0.2668665647506714
Batch 58/64 loss: 0.26834094524383545
Batch 59/64 loss: 0.26901984214782715
Batch 60/64 loss: 0.2731882333755493
Batch 61/64 loss: 0.2693493962287903
Batch 62/64 loss: 0.274000883102417
Batch 63/64 loss: 0.28333866596221924
Batch 64/64 loss: 0.2677510380744934
Epoch 106  Train loss: 0.272719514837452  Val loss: 0.3021311313425962
Epoch 107
-------------------------------
Batch 1/64 loss: 0.28088533878326416
Batch 2/64 loss: 0.2815020680427551
Batch 3/64 loss: 0.261488676071167
Batch 4/64 loss: 0.2653120756149292
Batch 5/64 loss: 0.26948726177215576
Batch 6/64 loss: 0.27661168575286865
Batch 7/64 loss: 0.2672257423400879
Batch 8/64 loss: 0.27314090728759766
Batch 9/64 loss: 0.263882577419281
Batch 10/64 loss: 0.2705835700035095
Batch 11/64 loss: 0.27220284938812256
Batch 12/64 loss: 0.27349746227264404
Batch 13/64 loss: 0.27688348293304443
Batch 14/64 loss: 0.2706160545349121
Batch 15/64 loss: 0.27403926849365234
Batch 16/64 loss: 0.2649385929107666
Batch 17/64 loss: 0.2723003625869751
Batch 18/64 loss: 0.27408403158187866
Batch 19/64 loss: 0.26648128032684326
Batch 20/64 loss: 0.26816749572753906
Batch 21/64 loss: 0.2674093246459961
Batch 22/64 loss: 0.2697743773460388
Batch 23/64 loss: 0.2645754814147949
Batch 24/64 loss: 0.27498865127563477
Batch 25/64 loss: 0.27485179901123047
Batch 26/64 loss: 0.2726525068283081
Batch 27/64 loss: 0.2678072452545166
Batch 28/64 loss: 0.27881157398223877
Batch 29/64 loss: 0.26616811752319336
Batch 30/64 loss: 0.27110522985458374
Batch 31/64 loss: 0.26878273487091064
Batch 32/64 loss: 0.2669332027435303
Batch 33/64 loss: 0.2802921533584595
Batch 34/64 loss: 0.2671440839767456
Batch 35/64 loss: 0.270888090133667
Batch 36/64 loss: 0.2700018286705017
Batch 37/64 loss: 0.2615910768508911
Batch 38/64 loss: 0.28300392627716064
Batch 39/64 loss: 0.26922863721847534
Batch 40/64 loss: 0.27480101585388184
Batch 41/64 loss: 0.26757562160491943
Batch 42/64 loss: 0.27274662256240845
Batch 43/64 loss: 0.26714110374450684
Batch 44/64 loss: 0.27371710538864136
Batch 45/64 loss: 0.27594542503356934
Batch 46/64 loss: 0.2777179479598999
Batch 47/64 loss: 0.2670031189918518
Batch 48/64 loss: 0.2693554162979126
Batch 49/64 loss: 0.2665140628814697
Batch 50/64 loss: 0.27989065647125244
Batch 51/64 loss: 0.2717767357826233
Batch 52/64 loss: 0.26614606380462646
Batch 53/64 loss: 0.27279114723205566
Batch 54/64 loss: 0.2674281597137451
Batch 55/64 loss: 0.27578920125961304
Batch 56/64 loss: 0.27026402950286865
Batch 57/64 loss: 0.26808464527130127
Batch 58/64 loss: 0.26758962869644165
Batch 59/64 loss: 0.2697657346725464
Batch 60/64 loss: 0.2747679352760315
Batch 61/64 loss: 0.2787407636642456
Batch 62/64 loss: 0.2703527808189392
Batch 63/64 loss: 0.27285265922546387
Batch 64/64 loss: 0.2853447198867798
Epoch 107  Train loss: 0.2714055991640278  Val loss: 0.3004781212593682
Saving best model, epoch: 107
Epoch 108
-------------------------------
Batch 1/64 loss: 0.27406764030456543
Batch 2/64 loss: 0.2669013738632202
Batch 3/64 loss: 0.26556289196014404
Batch 4/64 loss: 0.2644270658493042
Batch 5/64 loss: 0.2657751441001892
Batch 6/64 loss: 0.2779707908630371
Batch 7/64 loss: 0.2658032178878784
Batch 8/64 loss: 0.2634248733520508
Batch 9/64 loss: 0.27854621410369873
Batch 10/64 loss: 0.2692965269088745
Batch 11/64 loss: 0.2779574990272522
Batch 12/64 loss: 0.2702754735946655
Batch 13/64 loss: 0.2661738395690918
Batch 14/64 loss: 0.27895212173461914
Batch 15/64 loss: 0.26585686206817627
Batch 16/64 loss: 0.27434277534484863
Batch 17/64 loss: 0.2780529856681824
Batch 18/64 loss: 0.26645827293395996
Batch 19/64 loss: 0.27408385276794434
Batch 20/64 loss: 0.2709346413612366
Batch 21/64 loss: 0.2654576897621155
Batch 22/64 loss: 0.2689507007598877
Batch 23/64 loss: 0.27586764097213745
Batch 24/64 loss: 0.27416884899139404
Batch 25/64 loss: 0.2786217927932739
Batch 26/64 loss: 0.265339732170105
Batch 27/64 loss: 0.27589619159698486
Batch 28/64 loss: 0.26922178268432617
Batch 29/64 loss: 0.28247761726379395
Batch 30/64 loss: 0.2724255323410034
Batch 31/64 loss: 0.2829676866531372
Batch 32/64 loss: 0.2761010527610779
Batch 33/64 loss: 0.26704418659210205
Batch 34/64 loss: 0.27113068103790283
Batch 35/64 loss: 0.279607355594635
Batch 36/64 loss: 0.2649655342102051
Batch 37/64 loss: 0.2730299234390259
Batch 38/64 loss: 0.2755765914916992
Batch 39/64 loss: 0.27718502283096313
Batch 40/64 loss: 0.2697352170944214
Batch 41/64 loss: 0.2760087847709656
Batch 42/64 loss: 0.27453309297561646
Batch 43/64 loss: 0.2667558193206787
Batch 44/64 loss: 0.2738919258117676
Batch 45/64 loss: 0.26738613843917847
Batch 46/64 loss: 0.2595440149307251
Batch 47/64 loss: 0.27223145961761475
Batch 48/64 loss: 0.26444607973098755
Batch 49/64 loss: 0.27247071266174316
Batch 50/64 loss: 0.2672486901283264
Batch 51/64 loss: 0.27267396450042725
Batch 52/64 loss: 0.274763286113739
Batch 53/64 loss: 0.2688745856285095
Batch 54/64 loss: 0.2796207666397095
Batch 55/64 loss: 0.27216869592666626
Batch 56/64 loss: 0.2720215320587158
Batch 57/64 loss: 0.27074986696243286
Batch 58/64 loss: 0.27557265758514404
Batch 59/64 loss: 0.2775474190711975
Batch 60/64 loss: 0.2730746269226074
Batch 61/64 loss: 0.26810598373413086
Batch 62/64 loss: 0.2680196762084961
Batch 63/64 loss: 0.27882879972457886
Batch 64/64 loss: 0.2747238874435425
Epoch 108  Train loss: 0.2718935896368588  Val loss: 0.30039938598154337
Saving best model, epoch: 108
Epoch 109
-------------------------------
Batch 1/64 loss: 0.27360743284225464
Batch 2/64 loss: 0.2654414176940918
Batch 3/64 loss: 0.27265703678131104
Batch 4/64 loss: 0.26395750045776367
Batch 5/64 loss: 0.27198326587677
Batch 6/64 loss: 0.27289044857025146
Batch 7/64 loss: 0.27126193046569824
Batch 8/64 loss: 0.28621554374694824
Batch 9/64 loss: 0.2717767357826233
Batch 10/64 loss: 0.2748277187347412
Batch 11/64 loss: 0.2693953514099121
Batch 12/64 loss: 0.26835405826568604
Batch 13/64 loss: 0.26677167415618896
Batch 14/64 loss: 0.27090221643447876
Batch 15/64 loss: 0.2670302391052246
Batch 16/64 loss: 0.26533520221710205
Batch 17/64 loss: 0.27623677253723145
Batch 18/64 loss: 0.2702460289001465
Batch 19/64 loss: 0.2772812843322754
Batch 20/64 loss: 0.27628517150878906
Batch 21/64 loss: 0.26402950286865234
Batch 22/64 loss: 0.2626941204071045
Batch 23/64 loss: 0.26979100704193115
Batch 24/64 loss: 0.27655863761901855
Batch 25/64 loss: 0.2747562527656555
Batch 26/64 loss: 0.27880585193634033
Batch 27/64 loss: 0.2677866220474243
Batch 28/64 loss: 0.27545106410980225
Batch 29/64 loss: 0.2684037685394287
Batch 30/64 loss: 0.2851024270057678
Batch 31/64 loss: 0.26848000288009644
Batch 32/64 loss: 0.2698037624359131
Batch 33/64 loss: 0.2799440622329712
Batch 34/64 loss: 0.26842397451400757
Batch 35/64 loss: 0.2620363235473633
Batch 36/64 loss: 0.2756224274635315
Batch 37/64 loss: 0.2758776545524597
Batch 38/64 loss: 0.27041614055633545
Batch 39/64 loss: 0.2782354950904846
Batch 40/64 loss: 0.2621392011642456
Batch 41/64 loss: 0.2741960287094116
Batch 42/64 loss: 0.26628124713897705
Batch 43/64 loss: 0.2664794325828552
Batch 44/64 loss: 0.26826924085617065
Batch 45/64 loss: 0.2658942937850952
Batch 46/64 loss: 0.2715030908584595
Batch 47/64 loss: 0.26825714111328125
Batch 48/64 loss: 0.26762890815734863
Batch 49/64 loss: 0.27416324615478516
Batch 50/64 loss: 0.2717745304107666
Batch 51/64 loss: 0.2724575400352478
Batch 52/64 loss: 0.2642303705215454
Batch 53/64 loss: 0.2710764408111572
Batch 54/64 loss: 0.274846613407135
Batch 55/64 loss: 0.270601749420166
Batch 56/64 loss: 0.27756935358047485
Batch 57/64 loss: 0.27507245540618896
Batch 58/64 loss: 0.2652397155761719
Batch 59/64 loss: 0.26962071657180786
Batch 60/64 loss: 0.27498286962509155
Batch 61/64 loss: 0.2641822099685669
Batch 62/64 loss: 0.2720297574996948
Batch 63/64 loss: 0.2727288603782654
Batch 64/64 loss: 0.27698588371276855
Epoch 109  Train loss: 0.2712727930031571  Val loss: 0.298999489377864
Saving best model, epoch: 109
Epoch 110
-------------------------------
Batch 1/64 loss: 0.26466071605682373
Batch 2/64 loss: 0.2729426622390747
Batch 3/64 loss: 0.2662951946258545
Batch 4/64 loss: 0.27066510915756226
Batch 5/64 loss: 0.2672998905181885
Batch 6/64 loss: 0.26720690727233887
Batch 7/64 loss: 0.26877737045288086
Batch 8/64 loss: 0.2743474245071411
Batch 9/64 loss: 0.27472084760665894
Batch 10/64 loss: 0.26827913522720337
Batch 11/64 loss: 0.2718495726585388
Batch 12/64 loss: 0.272369384765625
Batch 13/64 loss: 0.2706564664840698
Batch 14/64 loss: 0.27823638916015625
Batch 15/64 loss: 0.2728644609451294
Batch 16/64 loss: 0.26388704776763916
Batch 17/64 loss: 0.28201329708099365
Batch 18/64 loss: 0.2625904083251953
Batch 19/64 loss: 0.2747079133987427
Batch 20/64 loss: 0.27237653732299805
Batch 21/64 loss: 0.2723051905632019
Batch 22/64 loss: 0.26912665367126465
Batch 23/64 loss: 0.266015887260437
Batch 24/64 loss: 0.2632535696029663
Batch 25/64 loss: 0.2740814685821533
Batch 26/64 loss: 0.27164965867996216
Batch 27/64 loss: 0.267625629901886
Batch 28/64 loss: 0.26797330379486084
Batch 29/64 loss: 0.2677382826805115
Batch 30/64 loss: 0.2745974659919739
Batch 31/64 loss: 0.2642899751663208
Batch 32/64 loss: 0.27228283882141113
Batch 33/64 loss: 0.2728274464607239
Batch 34/64 loss: 0.28367310762405396
Batch 35/64 loss: 0.27139008045196533
Batch 36/64 loss: 0.2700595259666443
Batch 37/64 loss: 0.2697795629501343
Batch 38/64 loss: 0.2662386894226074
Batch 39/64 loss: 0.2726236581802368
Batch 40/64 loss: 0.2695201635360718
Batch 41/64 loss: 0.271453857421875
Batch 42/64 loss: 0.27284204959869385
Batch 43/64 loss: 0.2696128487586975
Batch 44/64 loss: 0.276868999004364
Batch 45/64 loss: 0.26821839809417725
Batch 46/64 loss: 0.2719910144805908
Batch 47/64 loss: 0.268690288066864
Batch 48/64 loss: 0.2785322666168213
Batch 49/64 loss: 0.271385133266449
Batch 50/64 loss: 0.26862800121307373
Batch 51/64 loss: 0.2672309875488281
Batch 52/64 loss: 0.2649812698364258
Batch 53/64 loss: 0.2639450430870056
Batch 54/64 loss: 0.26529258489608765
Batch 55/64 loss: 0.2716381549835205
Batch 56/64 loss: 0.274486243724823
Batch 57/64 loss: 0.2605735659599304
Batch 58/64 loss: 0.2665594816207886
Batch 59/64 loss: 0.27304017543792725
Batch 60/64 loss: 0.267301082611084
Batch 61/64 loss: 0.27086126804351807
Batch 62/64 loss: 0.27017688751220703
Batch 63/64 loss: 0.2709444761276245
Batch 64/64 loss: 0.2700904607772827
Epoch 110  Train loss: 0.27029993440590655  Val loss: 0.29985895906527016
Epoch 111
-------------------------------
Batch 1/64 loss: 0.2628929615020752
Batch 2/64 loss: 0.2674374580383301
Batch 3/64 loss: 0.26337146759033203
Batch 4/64 loss: 0.26572132110595703
Batch 5/64 loss: 0.2706509232521057
Batch 6/64 loss: 0.2653895616531372
Batch 7/64 loss: 0.2659298777580261
Batch 8/64 loss: 0.26421135663986206
Batch 9/64 loss: 0.2750248312950134
Batch 10/64 loss: 0.26699066162109375
Batch 11/64 loss: 0.26549434661865234
Batch 12/64 loss: 0.270710289478302
Batch 13/64 loss: 0.2711848020553589
Batch 14/64 loss: 0.2712358236312866
Batch 15/64 loss: 0.26846903562545776
Batch 16/64 loss: 0.27072322368621826
Batch 17/64 loss: 0.267831027507782
Batch 18/64 loss: 0.2717002034187317
Batch 19/64 loss: 0.26055723428726196
Batch 20/64 loss: 0.27012336254119873
Batch 21/64 loss: 0.2828419804573059
Batch 22/64 loss: 0.277554988861084
Batch 23/64 loss: 0.2722189426422119
Batch 24/64 loss: 0.27359771728515625
Batch 25/64 loss: 0.2688103914260864
Batch 26/64 loss: 0.264060914516449
Batch 27/64 loss: 0.2699531316757202
Batch 28/64 loss: 0.2734287977218628
Batch 29/64 loss: 0.2640655040740967
Batch 30/64 loss: 0.26740562915802
Batch 31/64 loss: 0.2702265977859497
Batch 32/64 loss: 0.27177703380584717
Batch 33/64 loss: 0.25972747802734375
Batch 34/64 loss: 0.271959125995636
Batch 35/64 loss: 0.28000152111053467
Batch 36/64 loss: 0.2799961566925049
Batch 37/64 loss: 0.27220380306243896
Batch 38/64 loss: 0.2624335289001465
Batch 39/64 loss: 0.26825350522994995
Batch 40/64 loss: 0.26724886894226074
Batch 41/64 loss: 0.2711082696914673
Batch 42/64 loss: 0.26954424381256104
Batch 43/64 loss: 0.2697237730026245
Batch 44/64 loss: 0.27073490619659424
Batch 45/64 loss: 0.27393031120300293
Batch 46/64 loss: 0.2696918845176697
Batch 47/64 loss: 0.26691943407058716
Batch 48/64 loss: 0.27794283628463745
Batch 49/64 loss: 0.27875399589538574
Batch 50/64 loss: 0.27120041847229004
Batch 51/64 loss: 0.27425986528396606
Batch 52/64 loss: 0.2772597074508667
Batch 53/64 loss: 0.27021199464797974
Batch 54/64 loss: 0.2772342562675476
Batch 55/64 loss: 0.2657654881477356
Batch 56/64 loss: 0.26709192991256714
Batch 57/64 loss: 0.2655560374259949
Batch 58/64 loss: 0.2653462886810303
Batch 59/64 loss: 0.2800767421722412
Batch 60/64 loss: 0.27632391452789307
Batch 61/64 loss: 0.264718234539032
Batch 62/64 loss: 0.2610850930213928
Batch 63/64 loss: 0.26970338821411133
Batch 64/64 loss: 0.2706807851791382
Epoch 111  Train loss: 0.26997033708235796  Val loss: 0.29861980758581785
Saving best model, epoch: 111
Epoch 112
-------------------------------
Batch 1/64 loss: 0.2666734457015991
Batch 2/64 loss: 0.26897090673446655
Batch 3/64 loss: 0.2729418873786926
Batch 4/64 loss: 0.26407337188720703
Batch 5/64 loss: 0.26700079441070557
Batch 6/64 loss: 0.27474260330200195
Batch 7/64 loss: 0.2694775462150574
Batch 8/64 loss: 0.2668852210044861
Batch 9/64 loss: 0.26513874530792236
Batch 10/64 loss: 0.27021992206573486
Batch 11/64 loss: 0.2716946601867676
Batch 12/64 loss: 0.2650297284126282
Batch 13/64 loss: 0.2664470672607422
Batch 14/64 loss: 0.27631139755249023
Batch 15/64 loss: 0.2685978412628174
Batch 16/64 loss: 0.26714813709259033
Batch 17/64 loss: 0.27253812551498413
Batch 18/64 loss: 0.2718846797943115
Batch 19/64 loss: 0.2752641439437866
Batch 20/64 loss: 0.26993072032928467
Batch 21/64 loss: 0.2650787830352783
Batch 22/64 loss: 0.2601458430290222
Batch 23/64 loss: 0.2698851227760315
Batch 24/64 loss: 0.27307063341140747
Batch 25/64 loss: 0.2724294662475586
Batch 26/64 loss: 0.27043795585632324
Batch 27/64 loss: 0.26544904708862305
Batch 28/64 loss: 0.27245891094207764
Batch 29/64 loss: 0.2612496018409729
Batch 30/64 loss: 0.2763723134994507
Batch 31/64 loss: 0.2679964303970337
Batch 32/64 loss: 0.27589142322540283
Batch 33/64 loss: 0.2695719003677368
Batch 34/64 loss: 0.27895861864089966
Batch 35/64 loss: 0.26969635486602783
Batch 36/64 loss: 0.26877522468566895
Batch 37/64 loss: 0.27481305599212646
Batch 38/64 loss: 0.272094190120697
Batch 39/64 loss: 0.2692665457725525
Batch 40/64 loss: 0.2677239179611206
Batch 41/64 loss: 0.269647479057312
Batch 42/64 loss: 0.2711828351020813
Batch 43/64 loss: 0.2742798328399658
Batch 44/64 loss: 0.2652292847633362
Batch 45/64 loss: 0.26926088333129883
Batch 46/64 loss: 0.26857632398605347
Batch 47/64 loss: 0.27372992038726807
Batch 48/64 loss: 0.26630526781082153
Batch 49/64 loss: 0.2701340317726135
Batch 50/64 loss: 0.28573477268218994
Batch 51/64 loss: 0.2664182186126709
Batch 52/64 loss: 0.2676736116409302
Batch 53/64 loss: 0.2577981948852539
Batch 54/64 loss: 0.2668569087982178
Batch 55/64 loss: 0.27710580825805664
Batch 56/64 loss: 0.265804648399353
Batch 57/64 loss: 0.2699096202850342
Batch 58/64 loss: 0.2624887228012085
Batch 59/64 loss: 0.2601624131202698
Batch 60/64 loss: 0.2666938304901123
Batch 61/64 loss: 0.2604156732559204
Batch 62/64 loss: 0.2702622413635254
Batch 63/64 loss: 0.2701590061187744
Batch 64/64 loss: 0.27886515855789185
Epoch 112  Train loss: 0.26944807347129374  Val loss: 0.29951344384360556
Epoch 113
-------------------------------
Batch 1/64 loss: 0.2711942791938782
Batch 2/64 loss: 0.26572132110595703
Batch 3/64 loss: 0.2775084376335144
Batch 4/64 loss: 0.282726526260376
Batch 5/64 loss: 0.27224743366241455
Batch 6/64 loss: 0.2666449546813965
Batch 7/64 loss: 0.25982218980789185
Batch 8/64 loss: 0.26940739154815674
Batch 9/64 loss: 0.2753725051879883
Batch 10/64 loss: 0.266059935092926
Batch 11/64 loss: 0.27100247144699097
Batch 12/64 loss: 0.26524174213409424
Batch 13/64 loss: 0.2669140100479126
Batch 14/64 loss: 0.2819935083389282
Batch 15/64 loss: 0.27023041248321533
Batch 16/64 loss: 0.26668286323547363
Batch 17/64 loss: 0.2792457342147827
Batch 18/64 loss: 0.2606152296066284
Batch 19/64 loss: 0.26929134130477905
Batch 20/64 loss: 0.26213282346725464
Batch 21/64 loss: 0.2613939642906189
Batch 22/64 loss: 0.2617313861846924
Batch 23/64 loss: 0.26583707332611084
Batch 24/64 loss: 0.2701934576034546
Batch 25/64 loss: 0.27192604541778564
Batch 26/64 loss: 0.26421022415161133
Batch 27/64 loss: 0.26975202560424805
Batch 28/64 loss: 0.2729909420013428
Batch 29/64 loss: 0.271343469619751
Batch 30/64 loss: 0.26772594451904297
Batch 31/64 loss: 0.26232314109802246
Batch 32/64 loss: 0.26463985443115234
Batch 33/64 loss: 0.2650686502456665
Batch 34/64 loss: 0.27120471000671387
Batch 35/64 loss: 0.26673197746276855
Batch 36/64 loss: 0.25899553298950195
Batch 37/64 loss: 0.27085161209106445
Batch 38/64 loss: 0.2687443494796753
Batch 39/64 loss: 0.268001914024353
Batch 40/64 loss: 0.2671952247619629
Batch 41/64 loss: 0.2748260498046875
Batch 42/64 loss: 0.2717055678367615
Batch 43/64 loss: 0.26684248447418213
Batch 44/64 loss: 0.2652825117111206
Batch 45/64 loss: 0.2706791162490845
Batch 46/64 loss: 0.27330565452575684
Batch 47/64 loss: 0.26740479469299316
Batch 48/64 loss: 0.26414287090301514
Batch 49/64 loss: 0.26427823305130005
Batch 50/64 loss: 0.26770031452178955
Batch 51/64 loss: 0.2708296775817871
Batch 52/64 loss: 0.2708313465118408
Batch 53/64 loss: 0.2685232162475586
Batch 54/64 loss: 0.2743123769760132
Batch 55/64 loss: 0.2732580900192261
Batch 56/64 loss: 0.27099359035491943
Batch 57/64 loss: 0.2659130096435547
Batch 58/64 loss: 0.26385629177093506
Batch 59/64 loss: 0.2817831039428711
Batch 60/64 loss: 0.2639271020889282
Batch 61/64 loss: 0.2713225483894348
Batch 62/64 loss: 0.2733943462371826
Batch 63/64 loss: 0.26376819610595703
Batch 64/64 loss: 0.26447445154190063
Epoch 113  Train loss: 0.2688337716401792  Val loss: 0.29985609415060877
Epoch 114
-------------------------------
Batch 1/64 loss: 0.26473766565322876
Batch 2/64 loss: 0.2688565254211426
Batch 3/64 loss: 0.2621570825576782
Batch 4/64 loss: 0.2601897716522217
Batch 5/64 loss: 0.27275073528289795
Batch 6/64 loss: 0.27609384059906006
Batch 7/64 loss: 0.2722139358520508
Batch 8/64 loss: 0.26910245418548584
Batch 9/64 loss: 0.2676756978034973
Batch 10/64 loss: 0.26669251918792725
Batch 11/64 loss: 0.2715141773223877
Batch 12/64 loss: 0.2652820348739624
Batch 13/64 loss: 0.2639504671096802
Batch 14/64 loss: 0.2704876661300659
Batch 15/64 loss: 0.2712066173553467
Batch 16/64 loss: 0.26509761810302734
Batch 17/64 loss: 0.26420384645462036
Batch 18/64 loss: 0.27253782749176025
Batch 19/64 loss: 0.2661951780319214
Batch 20/64 loss: 0.2708146572113037
Batch 21/64 loss: 0.26663893461227417
Batch 22/64 loss: 0.26054954528808594
Batch 23/64 loss: 0.2736404538154602
Batch 24/64 loss: 0.2597411274909973
Batch 25/64 loss: 0.26000094413757324
Batch 26/64 loss: 0.26331549882888794
Batch 27/64 loss: 0.2641473412513733
Batch 28/64 loss: 0.2674039602279663
Batch 29/64 loss: 0.2676106095314026
Batch 30/64 loss: 0.2719091773033142
Batch 31/64 loss: 0.2659940719604492
Batch 32/64 loss: 0.2598165273666382
Batch 33/64 loss: 0.2606738805770874
Batch 34/64 loss: 0.2650279998779297
Batch 35/64 loss: 0.25900542736053467
Batch 36/64 loss: 0.27601420879364014
Batch 37/64 loss: 0.26904261112213135
Batch 38/64 loss: 0.26945436000823975
Batch 39/64 loss: 0.2780524492263794
Batch 40/64 loss: 0.2711673378944397
Batch 41/64 loss: 0.2686331272125244
Batch 42/64 loss: 0.2656034231185913
Batch 43/64 loss: 0.2771846055984497
Batch 44/64 loss: 0.2681666612625122
Batch 45/64 loss: 0.2663488984107971
Batch 46/64 loss: 0.26475757360458374
Batch 47/64 loss: 0.2760354280471802
Batch 48/64 loss: 0.26383447647094727
Batch 49/64 loss: 0.2777421474456787
Batch 50/64 loss: 0.2687857151031494
Batch 51/64 loss: 0.26551520824432373
Batch 52/64 loss: 0.2646327018737793
Batch 53/64 loss: 0.27398550510406494
Batch 54/64 loss: 0.2716502547264099
Batch 55/64 loss: 0.26068538427352905
Batch 56/64 loss: 0.26686131954193115
Batch 57/64 loss: 0.27248072624206543
Batch 58/64 loss: 0.26855921745300293
Batch 59/64 loss: 0.26742470264434814
Batch 60/64 loss: 0.2793487310409546
Batch 61/64 loss: 0.2676807641983032
Batch 62/64 loss: 0.2644474506378174
Batch 63/64 loss: 0.27386486530303955
Batch 64/64 loss: 0.2651759386062622
Epoch 114  Train loss: 0.26798553139555686  Val loss: 0.29907138876079287
Epoch 115
-------------------------------
Batch 1/64 loss: 0.27392566204071045
Batch 2/64 loss: 0.2684464454650879
Batch 3/64 loss: 0.2783120274543762
Batch 4/64 loss: 0.26746666431427
Batch 5/64 loss: 0.268665075302124
Batch 6/64 loss: 0.27733874320983887
Batch 7/64 loss: 0.26488327980041504
Batch 8/64 loss: 0.26842600107192993
Batch 9/64 loss: 0.270679235458374
Batch 10/64 loss: 0.27214211225509644
Batch 11/64 loss: 0.2709103226661682
Batch 12/64 loss: 0.26926422119140625
Batch 13/64 loss: 0.27609169483184814
Batch 14/64 loss: 0.2632030248641968
Batch 15/64 loss: 0.2650712728500366
Batch 16/64 loss: 0.2678050994873047
Batch 17/64 loss: 0.26409733295440674
Batch 18/64 loss: 0.2707868814468384
Batch 19/64 loss: 0.27692651748657227
Batch 20/64 loss: 0.2660375237464905
Batch 21/64 loss: 0.2743138074874878
Batch 22/64 loss: 0.2689707279205322
Batch 23/64 loss: 0.2699927091598511
Batch 24/64 loss: 0.2691720724105835
Batch 25/64 loss: 0.26564687490463257
Batch 26/64 loss: 0.2636391520500183
Batch 27/64 loss: 0.27412211894989014
Batch 28/64 loss: 0.2604539394378662
Batch 29/64 loss: 0.26980483531951904
Batch 30/64 loss: 0.2690390348434448
Batch 31/64 loss: 0.2703695297241211
Batch 32/64 loss: 0.26578712463378906
Batch 33/64 loss: 0.2611178159713745
Batch 34/64 loss: 0.27714812755584717
Batch 35/64 loss: 0.272929847240448
Batch 36/64 loss: 0.2686382532119751
Batch 37/64 loss: 0.2677609920501709
Batch 38/64 loss: 0.27360963821411133
Batch 39/64 loss: 0.2675551772117615
Batch 40/64 loss: 0.2709059715270996
Batch 41/64 loss: 0.27835172414779663
Batch 42/64 loss: 0.2658664584159851
Batch 43/64 loss: 0.2677961587905884
Batch 44/64 loss: 0.272614061832428
Batch 45/64 loss: 0.2724112868309021
Batch 46/64 loss: 0.26709651947021484
Batch 47/64 loss: 0.26949334144592285
Batch 48/64 loss: 0.26864248514175415
Batch 49/64 loss: 0.27699846029281616
Batch 50/64 loss: 0.26294875144958496
Batch 51/64 loss: 0.26078474521636963
Batch 52/64 loss: 0.26015377044677734
Batch 53/64 loss: 0.2719929814338684
Batch 54/64 loss: 0.2717733383178711
Batch 55/64 loss: 0.2550925016403198
Batch 56/64 loss: 0.2641385793685913
Batch 57/64 loss: 0.2765797972679138
Batch 58/64 loss: 0.2715780735015869
Batch 59/64 loss: 0.26367735862731934
Batch 60/64 loss: 0.26790714263916016
Batch 61/64 loss: 0.2669324278831482
Batch 62/64 loss: 0.2611812353134155
Batch 63/64 loss: 0.26998448371887207
Batch 64/64 loss: 0.27260106801986694
Epoch 115  Train loss: 0.2690180921087078  Val loss: 0.2985229219767646
Saving best model, epoch: 115
Epoch 116
-------------------------------
Batch 1/64 loss: 0.2664395570755005
Batch 2/64 loss: 0.2542148232460022
Batch 3/64 loss: 0.26363837718963623
Batch 4/64 loss: 0.2626273036003113
Batch 5/64 loss: 0.2727898955345154
Batch 6/64 loss: 0.2681293487548828
Batch 7/64 loss: 0.2644524574279785
Batch 8/64 loss: 0.26082849502563477
Batch 9/64 loss: 0.2683396339416504
Batch 10/64 loss: 0.2626993656158447
Batch 11/64 loss: 0.26830679178237915
Batch 12/64 loss: 0.2604163885116577
Batch 13/64 loss: 0.26520687341690063
Batch 14/64 loss: 0.2747582197189331
Batch 15/64 loss: 0.25653815269470215
Batch 16/64 loss: 0.25937116146087646
Batch 17/64 loss: 0.2629033327102661
Batch 18/64 loss: 0.26839399337768555
Batch 19/64 loss: 0.2727617025375366
Batch 20/64 loss: 0.2710007429122925
Batch 21/64 loss: 0.26975637674331665
Batch 22/64 loss: 0.2717723250389099
Batch 23/64 loss: 0.2760874032974243
Batch 24/64 loss: 0.2548859119415283
Batch 25/64 loss: 0.2728292942047119
Batch 26/64 loss: 0.2565169930458069
Batch 27/64 loss: 0.26694256067276
Batch 28/64 loss: 0.2653791308403015
Batch 29/64 loss: 0.2655876874923706
Batch 30/64 loss: 0.26614415645599365
Batch 31/64 loss: 0.2584267258644104
Batch 32/64 loss: 0.2664604187011719
Batch 33/64 loss: 0.25867605209350586
Batch 34/64 loss: 0.2613288164138794
Batch 35/64 loss: 0.2626250982284546
Batch 36/64 loss: 0.27099698781967163
Batch 37/64 loss: 0.26392805576324463
Batch 38/64 loss: 0.26466435194015503
Batch 39/64 loss: 0.2738446593284607
Batch 40/64 loss: 0.2712724804878235
Batch 41/64 loss: 0.2644716501235962
Batch 42/64 loss: 0.2657321095466614
Batch 43/64 loss: 0.27175724506378174
Batch 44/64 loss: 0.26973986625671387
Batch 45/64 loss: 0.267727255821228
Batch 46/64 loss: 0.2767817974090576
Batch 47/64 loss: 0.26643240451812744
Batch 48/64 loss: 0.2773553133010864
Batch 49/64 loss: 0.26422786712646484
Batch 50/64 loss: 0.2721560001373291
Batch 51/64 loss: 0.258442223072052
Batch 52/64 loss: 0.26915597915649414
Batch 53/64 loss: 0.2792102098464966
Batch 54/64 loss: 0.26989030838012695
Batch 55/64 loss: 0.2790147066116333
Batch 56/64 loss: 0.2691735029220581
Batch 57/64 loss: 0.26518332958221436
Batch 58/64 loss: 0.25879406929016113
Batch 59/64 loss: 0.27019429206848145
Batch 60/64 loss: 0.27277421951293945
Batch 61/64 loss: 0.2810819745063782
Batch 62/64 loss: 0.2721470594406128
Batch 63/64 loss: 0.26994073390960693
Batch 64/64 loss: 0.2628657817840576
Epoch 116  Train loss: 0.2671447146172617  Val loss: 0.2991741637593692
Epoch 117
-------------------------------
Batch 1/64 loss: 0.25833165645599365
Batch 2/64 loss: 0.2633175849914551
Batch 3/64 loss: 0.26273834705352783
Batch 4/64 loss: 0.2705305814743042
Batch 5/64 loss: 0.26764506101608276
Batch 6/64 loss: 0.2682814598083496
Batch 7/64 loss: 0.2648448944091797
Batch 8/64 loss: 0.26966559886932373
Batch 9/64 loss: 0.26943540573120117
Batch 10/64 loss: 0.271007776260376
Batch 11/64 loss: 0.26484596729278564
Batch 12/64 loss: 0.26660746335983276
Batch 13/64 loss: 0.2734089493751526
Batch 14/64 loss: 0.26105332374572754
Batch 15/64 loss: 0.2669041156768799
Batch 16/64 loss: 0.2636091709136963
Batch 17/64 loss: 0.2689177989959717
Batch 18/64 loss: 0.26832830905914307
Batch 19/64 loss: 0.2653939723968506
Batch 20/64 loss: 0.26731014251708984
Batch 21/64 loss: 0.28047633171081543
Batch 22/64 loss: 0.26404714584350586
Batch 23/64 loss: 0.2564156651496887
Batch 24/64 loss: 0.26443320512771606
Batch 25/64 loss: 0.26283788681030273
Batch 26/64 loss: 0.2636653184890747
Batch 27/64 loss: 0.27804744243621826
Batch 28/64 loss: 0.26394057273864746
Batch 29/64 loss: 0.2643347978591919
Batch 30/64 loss: 0.2733747959136963
Batch 31/64 loss: 0.27150166034698486
Batch 32/64 loss: 0.26678675413131714
Batch 33/64 loss: 0.2664661407470703
Batch 34/64 loss: 0.2672908306121826
Batch 35/64 loss: 0.2700909376144409
Batch 36/64 loss: 0.26692092418670654
Batch 37/64 loss: 0.27085697650909424
Batch 38/64 loss: 0.26675379276275635
Batch 39/64 loss: 0.27153074741363525
Batch 40/64 loss: 0.27301478385925293
Batch 41/64 loss: 0.26966774463653564
Batch 42/64 loss: 0.2603302001953125
Batch 43/64 loss: 0.27031928300857544
Batch 44/64 loss: 0.2676745057106018
Batch 45/64 loss: 0.2630711793899536
Batch 46/64 loss: 0.2692989110946655
Batch 47/64 loss: 0.26235759258270264
Batch 48/64 loss: 0.26435697078704834
Batch 49/64 loss: 0.27052509784698486
Batch 50/64 loss: 0.2697109580039978
Batch 51/64 loss: 0.2654249668121338
Batch 52/64 loss: 0.28321027755737305
Batch 53/64 loss: 0.2637489438056946
Batch 54/64 loss: 0.266990602016449
Batch 55/64 loss: 0.26526951789855957
Batch 56/64 loss: 0.2653905749320984
Batch 57/64 loss: 0.26299232244491577
Batch 58/64 loss: 0.26113563776016235
Batch 59/64 loss: 0.2696153521537781
Batch 60/64 loss: 0.2706197500228882
Batch 61/64 loss: 0.2624366879463196
Batch 62/64 loss: 0.267880916595459
Batch 63/64 loss: 0.2637094259262085
Batch 64/64 loss: 0.2666262984275818
Epoch 117  Train loss: 0.26714778717826393  Val loss: 0.29815916752897176
Saving best model, epoch: 117
Epoch 118
-------------------------------
Batch 1/64 loss: 0.2686128616333008
Batch 2/64 loss: 0.2637801766395569
Batch 3/64 loss: 0.25732946395874023
Batch 4/64 loss: 0.26180195808410645
Batch 5/64 loss: 0.2690487504005432
Batch 6/64 loss: 0.2727593779563904
Batch 7/64 loss: 0.2619205713272095
Batch 8/64 loss: 0.25945985317230225
Batch 9/64 loss: 0.26605701446533203
Batch 10/64 loss: 0.2559775114059448
Batch 11/64 loss: 0.2627962827682495
Batch 12/64 loss: 0.26040351390838623
Batch 13/64 loss: 0.2631964683532715
Batch 14/64 loss: 0.275982141494751
Batch 15/64 loss: 0.2680181860923767
Batch 16/64 loss: 0.2794296145439148
Batch 17/64 loss: 0.26133036613464355
Batch 18/64 loss: 0.2636571526527405
Batch 19/64 loss: 0.27277374267578125
Batch 20/64 loss: 0.2633284330368042
Batch 21/64 loss: 0.2624168395996094
Batch 22/64 loss: 0.2707836627960205
Batch 23/64 loss: 0.266440212726593
Batch 24/64 loss: 0.26888084411621094
Batch 25/64 loss: 0.26462650299072266
Batch 26/64 loss: 0.2650943398475647
Batch 27/64 loss: 0.2636122703552246
Batch 28/64 loss: 0.2733497619628906
Batch 29/64 loss: 0.2654510736465454
Batch 30/64 loss: 0.27520620822906494
Batch 31/64 loss: 0.2765948176383972
Batch 32/64 loss: 0.26373255252838135
Batch 33/64 loss: 0.25678813457489014
Batch 34/64 loss: 0.26368606090545654
Batch 35/64 loss: 0.2660127282142639
Batch 36/64 loss: 0.27099448442459106
Batch 37/64 loss: 0.2591341733932495
Batch 38/64 loss: 0.2655813694000244
Batch 39/64 loss: 0.2616150379180908
Batch 40/64 loss: 0.26616740226745605
Batch 41/64 loss: 0.26823943853378296
Batch 42/64 loss: 0.27228784561157227
Batch 43/64 loss: 0.2695496082305908
Batch 44/64 loss: 0.2687798738479614
Batch 45/64 loss: 0.2673991918563843
Batch 46/64 loss: 0.27114665508270264
Batch 47/64 loss: 0.2640533447265625
Batch 48/64 loss: 0.26371192932128906
Batch 49/64 loss: 0.27286404371261597
Batch 50/64 loss: 0.2724727392196655
Batch 51/64 loss: 0.26357221603393555
Batch 52/64 loss: 0.2625102996826172
Batch 53/64 loss: 0.26707637310028076
Batch 54/64 loss: 0.26296329498291016
Batch 55/64 loss: 0.2610524892807007
Batch 56/64 loss: 0.26960253715515137
Batch 57/64 loss: 0.27698814868927
Batch 58/64 loss: 0.26348650455474854
Batch 59/64 loss: 0.266811728477478
Batch 60/64 loss: 0.263507604598999
Batch 61/64 loss: 0.2754209041595459
Batch 62/64 loss: 0.2602663040161133
Batch 63/64 loss: 0.2682884931564331
Batch 64/64 loss: 0.272816002368927
Epoch 118  Train loss: 0.2665175762830996  Val loss: 0.29872458579204336
Epoch 119
-------------------------------
Batch 1/64 loss: 0.26158785820007324
Batch 2/64 loss: 0.26730847358703613
Batch 3/64 loss: 0.2635812759399414
Batch 4/64 loss: 0.2647123336791992
Batch 5/64 loss: 0.26462554931640625
Batch 6/64 loss: 0.2739187479019165
Batch 7/64 loss: 0.28998637199401855
Batch 8/64 loss: 0.26370108127593994
Batch 9/64 loss: 0.26535093784332275
Batch 10/64 loss: 0.2612038850784302
Batch 11/64 loss: 0.2673017978668213
Batch 12/64 loss: 0.26586997509002686
Batch 13/64 loss: 0.2676997184753418
Batch 14/64 loss: 0.2680586576461792
Batch 15/64 loss: 0.267517626285553
Batch 16/64 loss: 0.26569151878356934
Batch 17/64 loss: 0.26465439796447754
Batch 18/64 loss: 0.27459514141082764
Batch 19/64 loss: 0.26252448558807373
Batch 20/64 loss: 0.26752614974975586
Batch 21/64 loss: 0.273202121257782
Batch 22/64 loss: 0.25914931297302246
Batch 23/64 loss: 0.2683006525039673
Batch 24/64 loss: 0.2750943899154663
Batch 25/64 loss: 0.26357173919677734
Batch 26/64 loss: 0.2641735076904297
Batch 27/64 loss: 0.26276254653930664
Batch 28/64 loss: 0.2776302695274353
Batch 29/64 loss: 0.2609676122665405
Batch 30/64 loss: 0.2684541940689087
Batch 31/64 loss: 0.2602218985557556
Batch 32/64 loss: 0.26683199405670166
Batch 33/64 loss: 0.2601829171180725
Batch 34/64 loss: 0.2697431445121765
Batch 35/64 loss: 0.2683354616165161
Batch 36/64 loss: 0.26649177074432373
Batch 37/64 loss: 0.26960843801498413
Batch 38/64 loss: 0.26437556743621826
Batch 39/64 loss: 0.26987695693969727
Batch 40/64 loss: 0.26444900035858154
Batch 41/64 loss: 0.2635822296142578
Batch 42/64 loss: 0.26648151874542236
Batch 43/64 loss: 0.2623472809791565
Batch 44/64 loss: 0.2583577632904053
Batch 45/64 loss: 0.2596539855003357
Batch 46/64 loss: 0.26886212825775146
Batch 47/64 loss: 0.2637418508529663
Batch 48/64 loss: 0.2583947777748108
Batch 49/64 loss: 0.26954591274261475
Batch 50/64 loss: 0.26337212324142456
Batch 51/64 loss: 0.25947433710098267
Batch 52/64 loss: 0.26375508308410645
Batch 53/64 loss: 0.2641122341156006
Batch 54/64 loss: 0.26255369186401367
Batch 55/64 loss: 0.2662537693977356
Batch 56/64 loss: 0.2665383219718933
Batch 57/64 loss: 0.26394951343536377
Batch 58/64 loss: 0.2564724087715149
Batch 59/64 loss: 0.26322853565216064
Batch 60/64 loss: 0.2598191499710083
Batch 61/64 loss: 0.27986109256744385
Batch 62/64 loss: 0.2603442668914795
Batch 63/64 loss: 0.26674288511276245
Batch 64/64 loss: 0.26295602321624756
Epoch 119  Train loss: 0.26581178599712896  Val loss: 0.2985601138413157
Epoch 120
-------------------------------
Batch 1/64 loss: 0.2687975764274597
Batch 2/64 loss: 0.27251601219177246
Batch 3/64 loss: 0.2753504514694214
Batch 4/64 loss: 0.26304304599761963
Batch 5/64 loss: 0.26640546321868896
Batch 6/64 loss: 0.2619755268096924
Batch 7/64 loss: 0.2682701349258423
Batch 8/64 loss: 0.2658854126930237
Batch 9/64 loss: 0.2625080347061157
Batch 10/64 loss: 0.2642557621002197
Batch 11/64 loss: 0.2560749053955078
Batch 12/64 loss: 0.2683887481689453
Batch 13/64 loss: 0.25714391469955444
Batch 14/64 loss: 0.26164716482162476
Batch 15/64 loss: 0.26807212829589844
Batch 16/64 loss: 0.25522494316101074
Batch 17/64 loss: 0.27410459518432617
Batch 18/64 loss: 0.26141464710235596
Batch 19/64 loss: 0.25806379318237305
Batch 20/64 loss: 0.2625551223754883
Batch 21/64 loss: 0.2685455083847046
Batch 22/64 loss: 0.2688317894935608
Batch 23/64 loss: 0.26450133323669434
Batch 24/64 loss: 0.2635279893875122
Batch 25/64 loss: 0.25833767652511597
Batch 26/64 loss: 0.2635897397994995
Batch 27/64 loss: 0.2630195617675781
Batch 28/64 loss: 0.27817124128341675
Batch 29/64 loss: 0.25451767444610596
Batch 30/64 loss: 0.2625293731689453
Batch 31/64 loss: 0.2611851692199707
Batch 32/64 loss: 0.2795978784561157
Batch 33/64 loss: 0.26789963245391846
Batch 34/64 loss: 0.26391780376434326
Batch 35/64 loss: 0.2664836645126343
Batch 36/64 loss: 0.261637806892395
Batch 37/64 loss: 0.26300913095474243
Batch 38/64 loss: 0.27005863189697266
Batch 39/64 loss: 0.2763466238975525
Batch 40/64 loss: 0.26924628019332886
Batch 41/64 loss: 0.2701641321182251
Batch 42/64 loss: 0.26535284519195557
Batch 43/64 loss: 0.2617430090904236
Batch 44/64 loss: 0.26185446977615356
Batch 45/64 loss: 0.2661933898925781
Batch 46/64 loss: 0.2640482187271118
Batch 47/64 loss: 0.27067315578460693
Batch 48/64 loss: 0.2664138078689575
Batch 49/64 loss: 0.26142847537994385
Batch 50/64 loss: 0.2631686329841614
Batch 51/64 loss: 0.27047085762023926
Batch 52/64 loss: 0.267314076423645
Batch 53/64 loss: 0.26172810792922974
Batch 54/64 loss: 0.262173056602478
Batch 55/64 loss: 0.27204394340515137
Batch 56/64 loss: 0.2614555358886719
Batch 57/64 loss: 0.27301663160324097
Batch 58/64 loss: 0.26844751834869385
Batch 59/64 loss: 0.2734074592590332
Batch 60/64 loss: 0.2733021378517151
Batch 61/64 loss: 0.2704920768737793
Batch 62/64 loss: 0.265228271484375
Batch 63/64 loss: 0.26340359449386597
Batch 64/64 loss: 0.27036142349243164
Epoch 120  Train loss: 0.26592857042948403  Val loss: 0.29939030740678924
Epoch 121
-------------------------------
Batch 1/64 loss: 0.2655900716781616
Batch 2/64 loss: 0.2738707661628723
Batch 3/64 loss: 0.26548492908477783
Batch 4/64 loss: 0.2673197388648987
Batch 5/64 loss: 0.2607966661453247
Batch 6/64 loss: 0.26825255155563354
Batch 7/64 loss: 0.26832228899002075
Batch 8/64 loss: 0.2729945182800293
Batch 9/64 loss: 0.2633627653121948
Batch 10/64 loss: 0.27128589153289795
Batch 11/64 loss: 0.2583967447280884
Batch 12/64 loss: 0.25897032022476196
Batch 13/64 loss: 0.272768497467041
Batch 14/64 loss: 0.255817711353302
Batch 15/64 loss: 0.2614710330963135
Batch 16/64 loss: 0.2636811137199402
Batch 17/64 loss: 0.26365935802459717
Batch 18/64 loss: 0.26341378688812256
Batch 19/64 loss: 0.2661585211753845
Batch 20/64 loss: 0.2667926549911499
Batch 21/64 loss: 0.2629273533821106
Batch 22/64 loss: 0.2688583731651306
Batch 23/64 loss: 0.2622499465942383
Batch 24/64 loss: 0.27232664823532104
Batch 25/64 loss: 0.271426796913147
Batch 26/64 loss: 0.2683885097503662
Batch 27/64 loss: 0.25652825832366943
Batch 28/64 loss: 0.2667720317840576
Batch 29/64 loss: 0.26466941833496094
Batch 30/64 loss: 0.2648220658302307
Batch 31/64 loss: 0.26296311616897583
Batch 32/64 loss: 0.2632029056549072
Batch 33/64 loss: 0.2571061849594116
Batch 34/64 loss: 0.26595187187194824
Batch 35/64 loss: 0.2682263255119324
Batch 36/64 loss: 0.2562858462333679
Batch 37/64 loss: 0.2637207508087158
Batch 38/64 loss: 0.26561057567596436
Batch 39/64 loss: 0.2576620578765869
Batch 40/64 loss: 0.26968371868133545
Batch 41/64 loss: 0.26556479930877686
Batch 42/64 loss: 0.27067452669143677
Batch 43/64 loss: 0.2599966526031494
Batch 44/64 loss: 0.27167123556137085
Batch 45/64 loss: 0.26566648483276367
Batch 46/64 loss: 0.2620847821235657
Batch 47/64 loss: 0.2764265537261963
Batch 48/64 loss: 0.26777827739715576
Batch 49/64 loss: 0.26702654361724854
Batch 50/64 loss: 0.26704204082489014
Batch 51/64 loss: 0.2641497850418091
Batch 52/64 loss: 0.2611353397369385
Batch 53/64 loss: 0.26220178604125977
Batch 54/64 loss: 0.26915812492370605
Batch 55/64 loss: 0.2657139301300049
Batch 56/64 loss: 0.27157092094421387
Batch 57/64 loss: 0.2676796317100525
Batch 58/64 loss: 0.27243244647979736
Batch 59/64 loss: 0.26715946197509766
Batch 60/64 loss: 0.2641076445579529
Batch 61/64 loss: 0.26408839225769043
Batch 62/64 loss: 0.26972126960754395
Batch 63/64 loss: 0.266620934009552
Batch 64/64 loss: 0.26914912462234497
Epoch 121  Train loss: 0.26571491909962075  Val loss: 0.2986702775627477
Epoch 122
-------------------------------
Batch 1/64 loss: 0.2666964530944824
Batch 2/64 loss: 0.26336830854415894
Batch 3/64 loss: 0.27051281929016113
Batch 4/64 loss: 0.2620784044265747
Batch 5/64 loss: 0.26735377311706543
Batch 6/64 loss: 0.26591676473617554
Batch 7/64 loss: 0.26224231719970703
Batch 8/64 loss: 0.25828075408935547
Batch 9/64 loss: 0.26793646812438965
Batch 10/64 loss: 0.27074509859085083
Batch 11/64 loss: 0.25568175315856934
Batch 12/64 loss: 0.26256436109542847
Batch 13/64 loss: 0.27356696128845215
Batch 14/64 loss: 0.25601810216903687
Batch 15/64 loss: 0.26154160499572754
Batch 16/64 loss: 0.27150893211364746
Batch 17/64 loss: 0.26615047454833984
Batch 18/64 loss: 0.25969183444976807
Batch 19/64 loss: 0.2662256956100464
Batch 20/64 loss: 0.26224851608276367
Batch 21/64 loss: 0.2636578679084778
Batch 22/64 loss: 0.26562368869781494
Batch 23/64 loss: 0.2603248953819275
Batch 24/64 loss: 0.25829845666885376
Batch 25/64 loss: 0.2590976357460022
Batch 26/64 loss: 0.2685725688934326
Batch 27/64 loss: 0.25822198390960693
Batch 28/64 loss: 0.25788354873657227
Batch 29/64 loss: 0.26152265071868896
Batch 30/64 loss: 0.2617608904838562
Batch 31/64 loss: 0.2633705735206604
Batch 32/64 loss: 0.25126737356185913
Batch 33/64 loss: 0.27129411697387695
Batch 34/64 loss: 0.2584758996963501
Batch 35/64 loss: 0.2609812617301941
Batch 36/64 loss: 0.2596126198768616
Batch 37/64 loss: 0.2611391544342041
Batch 38/64 loss: 0.2681596279144287
Batch 39/64 loss: 0.25983452796936035
Batch 40/64 loss: 0.2690806984901428
Batch 41/64 loss: 0.2679256200790405
Batch 42/64 loss: 0.2665524482727051
Batch 43/64 loss: 0.2692682147026062
Batch 44/64 loss: 0.26182854175567627
Batch 45/64 loss: 0.26117926836013794
Batch 46/64 loss: 0.25452983379364014
Batch 47/64 loss: 0.2690402865409851
Batch 48/64 loss: 0.27207034826278687
Batch 49/64 loss: 0.2766566872596741
Batch 50/64 loss: 0.2724188566207886
Batch 51/64 loss: 0.2804591655731201
Batch 52/64 loss: 0.26517200469970703
Batch 53/64 loss: 0.26285994052886963
Batch 54/64 loss: 0.2630445957183838
Batch 55/64 loss: 0.2611599564552307
Batch 56/64 loss: 0.267206609249115
Batch 57/64 loss: 0.26397228240966797
Batch 58/64 loss: 0.2674907445907593
Batch 59/64 loss: 0.26432371139526367
Batch 60/64 loss: 0.26803451776504517
Batch 61/64 loss: 0.2734788656234741
Batch 62/64 loss: 0.2605081796646118
Batch 63/64 loss: 0.2587214708328247
Batch 64/64 loss: 0.25434422492980957
Epoch 122  Train loss: 0.26426932951983284  Val loss: 0.2975992902447678
Saving best model, epoch: 122
Epoch 123
-------------------------------
Batch 1/64 loss: 0.2606661915779114
Batch 2/64 loss: 0.25461333990097046
Batch 3/64 loss: 0.26931411027908325
Batch 4/64 loss: 0.25951099395751953
Batch 5/64 loss: 0.27464747428894043
Batch 6/64 loss: 0.267250657081604
Batch 7/64 loss: 0.2732769250869751
Batch 8/64 loss: 0.26085734367370605
Batch 9/64 loss: 0.25856244564056396
Batch 10/64 loss: 0.26690739393234253
Batch 11/64 loss: 0.2628592252731323
Batch 12/64 loss: 0.26302117109298706
Batch 13/64 loss: 0.2639427185058594
Batch 14/64 loss: 0.26652848720550537
Batch 15/64 loss: 0.26290416717529297
Batch 16/64 loss: 0.2648121118545532
Batch 17/64 loss: 0.2574671506881714
Batch 18/64 loss: 0.2697521448135376
Batch 19/64 loss: 0.2555999159812927
Batch 20/64 loss: 0.2625555992126465
Batch 21/64 loss: 0.26760900020599365
Batch 22/64 loss: 0.2586265802383423
Batch 23/64 loss: 0.2588626742362976
Batch 24/64 loss: 0.26243650913238525
Batch 25/64 loss: 0.2669427990913391
Batch 26/64 loss: 0.2606654167175293
Batch 27/64 loss: 0.2759988307952881
Batch 28/64 loss: 0.25887739658355713
Batch 29/64 loss: 0.2561119794845581
Batch 30/64 loss: 0.2619059085845947
Batch 31/64 loss: 0.26237261295318604
Batch 32/64 loss: 0.2626490592956543
Batch 33/64 loss: 0.26890456676483154
Batch 34/64 loss: 0.2661227583885193
Batch 35/64 loss: 0.26569050550460815
Batch 36/64 loss: 0.2703990340232849
Batch 37/64 loss: 0.26145005226135254
Batch 38/64 loss: 0.2595674395561218
Batch 39/64 loss: 0.26609867811203003
Batch 40/64 loss: 0.26527297496795654
Batch 41/64 loss: 0.2704836130142212
Batch 42/64 loss: 0.2687203884124756
Batch 43/64 loss: 0.2649994492530823
Batch 44/64 loss: 0.2661776542663574
Batch 45/64 loss: 0.25468844175338745
Batch 46/64 loss: 0.27503037452697754
Batch 47/64 loss: 0.2665349245071411
Batch 48/64 loss: 0.26342761516571045
Batch 49/64 loss: 0.2624772787094116
Batch 50/64 loss: 0.26501500606536865
Batch 51/64 loss: 0.2677869200706482
Batch 52/64 loss: 0.26550960540771484
Batch 53/64 loss: 0.27591681480407715
Batch 54/64 loss: 0.26553505659103394
Batch 55/64 loss: 0.26443547010421753
Batch 56/64 loss: 0.26682049036026
Batch 57/64 loss: 0.26695722341537476
Batch 58/64 loss: 0.2576587200164795
Batch 59/64 loss: 0.269791841506958
Batch 60/64 loss: 0.2642480134963989
Batch 61/64 loss: 0.2690269947052002
Batch 62/64 loss: 0.26198023557662964
Batch 63/64 loss: 0.2585330009460449
Batch 64/64 loss: 0.26494938135147095
Epoch 123  Train loss: 0.26450323941660864  Val loss: 0.2990666207988647
Epoch 124
-------------------------------
Batch 1/64 loss: 0.25522541999816895
Batch 2/64 loss: 0.2627924084663391
Batch 3/64 loss: 0.2670856714248657
Batch 4/64 loss: 0.268959105014801
Batch 5/64 loss: 0.2590895891189575
Batch 6/64 loss: 0.2646796703338623
Batch 7/64 loss: 0.2590751051902771
Batch 8/64 loss: 0.2650686502456665
Batch 9/64 loss: 0.25788307189941406
Batch 10/64 loss: 0.2606557607650757
Batch 11/64 loss: 0.26881080865859985
Batch 12/64 loss: 0.25492268800735474
Batch 13/64 loss: 0.2691636085510254
Batch 14/64 loss: 0.2567722797393799
Batch 15/64 loss: 0.2665637135505676
Batch 16/64 loss: 0.2621021270751953
Batch 17/64 loss: 0.26205015182495117
Batch 18/64 loss: 0.2587074041366577
Batch 19/64 loss: 0.26698416471481323
Batch 20/64 loss: 0.26440656185150146
Batch 21/64 loss: 0.2561919689178467
Batch 22/64 loss: 0.26996421813964844
Batch 23/64 loss: 0.2690376043319702
Batch 24/64 loss: 0.26132071018218994
Batch 25/64 loss: 0.26502346992492676
Batch 26/64 loss: 0.2708204388618469
Batch 27/64 loss: 0.2737635374069214
Batch 28/64 loss: 0.2622671127319336
Batch 29/64 loss: 0.2560950517654419
Batch 30/64 loss: 0.2561773657798767
Batch 31/64 loss: 0.2598724365234375
Batch 32/64 loss: 0.2643665075302124
Batch 33/64 loss: 0.2612465023994446
Batch 34/64 loss: 0.26195597648620605
Batch 35/64 loss: 0.2732248902320862
Batch 36/64 loss: 0.265006422996521
Batch 37/64 loss: 0.2550269365310669
Batch 38/64 loss: 0.26201748847961426
Batch 39/64 loss: 0.263827919960022
Batch 40/64 loss: 0.26081573963165283
Batch 41/64 loss: 0.26426786184310913
Batch 42/64 loss: 0.27181297540664673
Batch 43/64 loss: 0.2683013081550598
Batch 44/64 loss: 0.27326083183288574
Batch 45/64 loss: 0.2558552026748657
Batch 46/64 loss: 0.26198744773864746
Batch 47/64 loss: 0.26063764095306396
Batch 48/64 loss: 0.27500033378601074
Batch 49/64 loss: 0.25931406021118164
Batch 50/64 loss: 0.2707950472831726
Batch 51/64 loss: 0.26556456089019775
Batch 52/64 loss: 0.26034873723983765
Batch 53/64 loss: 0.26553094387054443
Batch 54/64 loss: 0.2636675238609314
Batch 55/64 loss: 0.2634737491607666
Batch 56/64 loss: 0.27659857273101807
Batch 57/64 loss: 0.2619289755821228
Batch 58/64 loss: 0.2582571506500244
Batch 59/64 loss: 0.26613402366638184
Batch 60/64 loss: 0.26276999711990356
Batch 61/64 loss: 0.2585475444793701
Batch 62/64 loss: 0.26179957389831543
Batch 63/64 loss: 0.25964462757110596
Batch 64/64 loss: 0.26797032356262207
Epoch 124  Train loss: 0.263615634394627  Val loss: 0.2986218171431027
Epoch 125
-------------------------------
Batch 1/64 loss: 0.26138174533843994
Batch 2/64 loss: 0.2630242109298706
Batch 3/64 loss: 0.2685498595237732
Batch 4/64 loss: 0.258756160736084
Batch 5/64 loss: 0.25670552253723145
Batch 6/64 loss: 0.26626384258270264
Batch 7/64 loss: 0.26600682735443115
Batch 8/64 loss: 0.26530921459198
Batch 9/64 loss: 0.259377121925354
Batch 10/64 loss: 0.2619360685348511
Batch 11/64 loss: 0.2633183002471924
Batch 12/64 loss: 0.27055853605270386
Batch 13/64 loss: 0.2669197916984558
Batch 14/64 loss: 0.2593190670013428
Batch 15/64 loss: 0.2675668001174927
Batch 16/64 loss: 0.2634516954421997
Batch 17/64 loss: 0.25676965713500977
Batch 18/64 loss: 0.2592642307281494
Batch 19/64 loss: 0.26496124267578125
Batch 20/64 loss: 0.2656075358390808
Batch 21/64 loss: 0.2572685480117798
Batch 22/64 loss: 0.2682441473007202
Batch 23/64 loss: 0.262085497379303
Batch 24/64 loss: 0.26497721672058105
Batch 25/64 loss: 0.2657064199447632
Batch 26/64 loss: 0.2663846015930176
Batch 27/64 loss: 0.26294922828674316
Batch 28/64 loss: 0.25502103567123413
Batch 29/64 loss: 0.26000797748565674
Batch 30/64 loss: 0.2549697160720825
Batch 31/64 loss: 0.26677560806274414
Batch 32/64 loss: 0.26296377182006836
Batch 33/64 loss: 0.25765901803970337
Batch 34/64 loss: 0.2703373432159424
Batch 35/64 loss: 0.2737526297569275
Batch 36/64 loss: 0.27014172077178955
Batch 37/64 loss: 0.270260751247406
Batch 38/64 loss: 0.26559388637542725
Batch 39/64 loss: 0.26095330715179443
Batch 40/64 loss: 0.26330459117889404
Batch 41/64 loss: 0.27062225341796875
Batch 42/64 loss: 0.2708749771118164
Batch 43/64 loss: 0.2701660394668579
Batch 44/64 loss: 0.25858521461486816
Batch 45/64 loss: 0.26484328508377075
Batch 46/64 loss: 0.256139874458313
Batch 47/64 loss: 0.25524961948394775
Batch 48/64 loss: 0.27895116806030273
Batch 49/64 loss: 0.2562592625617981
Batch 50/64 loss: 0.2665364742279053
Batch 51/64 loss: 0.2616540193557739
Batch 52/64 loss: 0.26240789890289307
Batch 53/64 loss: 0.26711833477020264
Batch 54/64 loss: 0.2671414017677307
Batch 55/64 loss: 0.25819265842437744
Batch 56/64 loss: 0.25808608531951904
Batch 57/64 loss: 0.25783634185791016
Batch 58/64 loss: 0.2690824270248413
Batch 59/64 loss: 0.26256227493286133
Batch 60/64 loss: 0.26427698135375977
Batch 61/64 loss: 0.2610589265823364
Batch 62/64 loss: 0.26312780380249023
Batch 63/64 loss: 0.2559192180633545
Batch 64/64 loss: 0.271282434463501
Epoch 125  Train loss: 0.2636009225658342  Val loss: 0.29734411723015647
Saving best model, epoch: 125
Epoch 126
-------------------------------
Batch 1/64 loss: 0.25655317306518555
Batch 2/64 loss: 0.27911263704299927
Batch 3/64 loss: 0.27428531646728516
Batch 4/64 loss: 0.26064562797546387
Batch 5/64 loss: 0.2643200159072876
Batch 6/64 loss: 0.27192074060440063
Batch 7/64 loss: 0.2628355026245117
Batch 8/64 loss: 0.26240062713623047
Batch 9/64 loss: 0.26057010889053345
Batch 10/64 loss: 0.26480889320373535
Batch 11/64 loss: 0.26708078384399414
Batch 12/64 loss: 0.2600516676902771
Batch 13/64 loss: 0.26165854930877686
Batch 14/64 loss: 0.25455307960510254
Batch 15/64 loss: 0.25686371326446533
Batch 16/64 loss: 0.2692373991012573
Batch 17/64 loss: 0.2642592191696167
Batch 18/64 loss: 0.2603492736816406
Batch 19/64 loss: 0.2627320885658264
Batch 20/64 loss: 0.2679349184036255
Batch 21/64 loss: 0.26064610481262207
Batch 22/64 loss: 0.2683711051940918
Batch 23/64 loss: 0.25462448596954346
Batch 24/64 loss: 0.26462221145629883
Batch 25/64 loss: 0.2656327486038208
Batch 26/64 loss: 0.2656479477882385
Batch 27/64 loss: 0.26026713848114014
Batch 28/64 loss: 0.25769758224487305
Batch 29/64 loss: 0.27041715383529663
Batch 30/64 loss: 0.2590331435203552
Batch 31/64 loss: 0.26054584980010986
Batch 32/64 loss: 0.25774288177490234
Batch 33/64 loss: 0.26753175258636475
Batch 34/64 loss: 0.26429080963134766
Batch 35/64 loss: 0.26103878021240234
Batch 36/64 loss: 0.26210200786590576
Batch 37/64 loss: 0.2636259198188782
Batch 38/64 loss: 0.26496022939682007
Batch 39/64 loss: 0.25999826192855835
Batch 40/64 loss: 0.2641686201095581
Batch 41/64 loss: 0.2647961378097534
Batch 42/64 loss: 0.2567668557167053
Batch 43/64 loss: 0.26437145471572876
Batch 44/64 loss: 0.26852548122406006
Batch 45/64 loss: 0.25723928213119507
Batch 46/64 loss: 0.2596132159233093
Batch 47/64 loss: 0.25694024562835693
Batch 48/64 loss: 0.2677001953125
Batch 49/64 loss: 0.265725314617157
Batch 50/64 loss: 0.2589552402496338
Batch 51/64 loss: 0.2647993564605713
Batch 52/64 loss: 0.2651921510696411
Batch 53/64 loss: 0.26357102394104004
Batch 54/64 loss: 0.2688421607017517
Batch 55/64 loss: 0.26607745885849
Batch 56/64 loss: 0.2620674967765808
Batch 57/64 loss: 0.25739169120788574
Batch 58/64 loss: 0.2612529993057251
Batch 59/64 loss: 0.26109784841537476
Batch 60/64 loss: 0.26085376739501953
Batch 61/64 loss: 0.25932973623275757
Batch 62/64 loss: 0.26339077949523926
Batch 63/64 loss: 0.2656397819519043
Batch 64/64 loss: 0.2611207962036133
Epoch 126  Train loss: 0.2630763661627676  Val loss: 0.29737714598678644
Epoch 127
-------------------------------
Batch 1/64 loss: 0.26152753829956055
Batch 2/64 loss: 0.2621285915374756
Batch 3/64 loss: 0.259161114692688
Batch 4/64 loss: 0.2682991623878479
Batch 5/64 loss: 0.2580982446670532
Batch 6/64 loss: 0.26550161838531494
Batch 7/64 loss: 0.2609367370605469
Batch 8/64 loss: 0.2559201717376709
Batch 9/64 loss: 0.2630906105041504
Batch 10/64 loss: 0.2643495798110962
Batch 11/64 loss: 0.25953733921051025
Batch 12/64 loss: 0.2652953267097473
Batch 13/64 loss: 0.26439762115478516
Batch 14/64 loss: 0.2636241316795349
Batch 15/64 loss: 0.254916250705719
Batch 16/64 loss: 0.2585076689720154
Batch 17/64 loss: 0.26371169090270996
Batch 18/64 loss: 0.26733672618865967
Batch 19/64 loss: 0.25871896743774414
Batch 20/64 loss: 0.2615799307823181
Batch 21/64 loss: 0.2633780241012573
Batch 22/64 loss: 0.263164758682251
Batch 23/64 loss: 0.26191699504852295
Batch 24/64 loss: 0.26402437686920166
Batch 25/64 loss: 0.25673234462738037
Batch 26/64 loss: 0.2657583951950073
Batch 27/64 loss: 0.2678467035293579
Batch 28/64 loss: 0.2593550682067871
Batch 29/64 loss: 0.2618260979652405
Batch 30/64 loss: 0.26000869274139404
Batch 31/64 loss: 0.25801825523376465
Batch 32/64 loss: 0.2569608688354492
Batch 33/64 loss: 0.26982784271240234
Batch 34/64 loss: 0.25645911693573
Batch 35/64 loss: 0.2589137554168701
Batch 36/64 loss: 0.2628238797187805
Batch 37/64 loss: 0.26034843921661377
Batch 38/64 loss: 0.2630462646484375
Batch 39/64 loss: 0.2627466917037964
Batch 40/64 loss: 0.26012492179870605
Batch 41/64 loss: 0.25895094871520996
Batch 42/64 loss: 0.26268935203552246
Batch 43/64 loss: 0.264728307723999
Batch 44/64 loss: 0.2599341869354248
Batch 45/64 loss: 0.25997936725616455
Batch 46/64 loss: 0.25519925355911255
Batch 47/64 loss: 0.2613440155982971
Batch 48/64 loss: 0.26056981086730957
Batch 49/64 loss: 0.25165581703186035
Batch 50/64 loss: 0.2544529438018799
Batch 51/64 loss: 0.25613850355148315
Batch 52/64 loss: 0.2586210370063782
Batch 53/64 loss: 0.2678264379501343
Batch 54/64 loss: 0.26974594593048096
Batch 55/64 loss: 0.262296199798584
Batch 56/64 loss: 0.26151806116104126
Batch 57/64 loss: 0.2664123773574829
Batch 58/64 loss: 0.26208531856536865
Batch 59/64 loss: 0.2610173225402832
Batch 60/64 loss: 0.266180157661438
Batch 61/64 loss: 0.26734399795532227
Batch 62/64 loss: 0.2647358179092407
Batch 63/64 loss: 0.25661998987197876
Batch 64/64 loss: 0.2836792469024658
Epoch 127  Train loss: 0.26184666857999916  Val loss: 0.297626520350217
Epoch 128
-------------------------------
Batch 1/64 loss: 0.2677464485168457
Batch 2/64 loss: 0.2583463191986084
Batch 3/64 loss: 0.2560102343559265
Batch 4/64 loss: 0.2637050747871399
Batch 5/64 loss: 0.2554255723953247
Batch 6/64 loss: 0.26600420475006104
Batch 7/64 loss: 0.25585824251174927
Batch 8/64 loss: 0.27038896083831787
Batch 9/64 loss: 0.2568902373313904
Batch 10/64 loss: 0.26155149936676025
Batch 11/64 loss: 0.2620686888694763
Batch 12/64 loss: 0.2653633952140808
Batch 13/64 loss: 0.25266849994659424
Batch 14/64 loss: 0.2598994970321655
Batch 15/64 loss: 0.2593801021575928
Batch 16/64 loss: 0.2682504653930664
Batch 17/64 loss: 0.2668536305427551
Batch 18/64 loss: 0.2618173360824585
Batch 19/64 loss: 0.2589559555053711
Batch 20/64 loss: 0.2539396286010742
Batch 21/64 loss: 0.25940608978271484
Batch 22/64 loss: 0.25076860189437866
Batch 23/64 loss: 0.2643859386444092
Batch 24/64 loss: 0.26055610179901123
Batch 25/64 loss: 0.25898104906082153
Batch 26/64 loss: 0.254095196723938
Batch 27/64 loss: 0.2634199857711792
Batch 28/64 loss: 0.2633615732192993
Batch 29/64 loss: 0.2580842971801758
Batch 30/64 loss: 0.26391172409057617
Batch 31/64 loss: 0.26397860050201416
Batch 32/64 loss: 0.2635796070098877
Batch 33/64 loss: 0.25362688302993774
Batch 34/64 loss: 0.25593167543411255
Batch 35/64 loss: 0.2683398127555847
Batch 36/64 loss: 0.26174354553222656
Batch 37/64 loss: 0.2527306079864502
Batch 38/64 loss: 0.2593109607696533
Batch 39/64 loss: 0.2593253254890442
Batch 40/64 loss: 0.25808185338974
Batch 41/64 loss: 0.25314199924468994
Batch 42/64 loss: 0.25703269243240356
Batch 43/64 loss: 0.26921844482421875
Batch 44/64 loss: 0.26660627126693726
Batch 45/64 loss: 0.26325803995132446
Batch 46/64 loss: 0.2681756615638733
Batch 47/64 loss: 0.2671513557434082
Batch 48/64 loss: 0.2649763822555542
Batch 49/64 loss: 0.2684866786003113
Batch 50/64 loss: 0.26391148567199707
Batch 51/64 loss: 0.2699977159500122
Batch 52/64 loss: 0.26552915573120117
Batch 53/64 loss: 0.2706753611564636
Batch 54/64 loss: 0.26068031787872314
Batch 55/64 loss: 0.26475954055786133
Batch 56/64 loss: 0.26352471113204956
Batch 57/64 loss: 0.25806474685668945
Batch 58/64 loss: 0.25657153129577637
Batch 59/64 loss: 0.26262253522872925
Batch 60/64 loss: 0.2613708972930908
Batch 61/64 loss: 0.2596588730812073
Batch 62/64 loss: 0.2583658695220947
Batch 63/64 loss: 0.2588968276977539
Batch 64/64 loss: 0.26488977670669556
Epoch 128  Train loss: 0.26142882903416953  Val loss: 0.2989898240033704
Epoch 129
-------------------------------
Batch 1/64 loss: 0.2576857805252075
Batch 2/64 loss: 0.2595808506011963
Batch 3/64 loss: 0.26073408126831055
Batch 4/64 loss: 0.255604088306427
Batch 5/64 loss: 0.2573174834251404
Batch 6/64 loss: 0.26514530181884766
Batch 7/64 loss: 0.26234495639801025
Batch 8/64 loss: 0.2672919034957886
Batch 9/64 loss: 0.27013832330703735
Batch 10/64 loss: 0.25512027740478516
Batch 11/64 loss: 0.268779993057251
Batch 12/64 loss: 0.25198978185653687
Batch 13/64 loss: 0.2566448450088501
Batch 14/64 loss: 0.26210588216781616
Batch 15/64 loss: 0.2637791633605957
Batch 16/64 loss: 0.26513993740081787
Batch 17/64 loss: 0.26618337631225586
Batch 18/64 loss: 0.25986015796661377
Batch 19/64 loss: 0.25694000720977783
Batch 20/64 loss: 0.25840914249420166
Batch 21/64 loss: 0.2596701979637146
Batch 22/64 loss: 0.2620915174484253
Batch 23/64 loss: 0.26082587242126465
Batch 24/64 loss: 0.2642431855201721
Batch 25/64 loss: 0.2657209634780884
Batch 26/64 loss: 0.26363426446914673
Batch 27/64 loss: 0.2600463628768921
Batch 28/64 loss: 0.2570744752883911
Batch 29/64 loss: 0.2587670087814331
Batch 30/64 loss: 0.26683199405670166
Batch 31/64 loss: 0.2583332657814026
Batch 32/64 loss: 0.25097954273223877
Batch 33/64 loss: 0.2601783275604248
Batch 34/64 loss: 0.2656049132347107
Batch 35/64 loss: 0.25209689140319824
Batch 36/64 loss: 0.2583543062210083
Batch 37/64 loss: 0.25482606887817383
Batch 38/64 loss: 0.25506067276000977
Batch 39/64 loss: 0.2565866708755493
Batch 40/64 loss: 0.2530486583709717
Batch 41/64 loss: 0.2539938688278198
Batch 42/64 loss: 0.26711535453796387
Batch 43/64 loss: 0.2557058334350586
Batch 44/64 loss: 0.26515352725982666
Batch 45/64 loss: 0.25496965646743774
Batch 46/64 loss: 0.266507089138031
Batch 47/64 loss: 0.2546963095664978
Batch 48/64 loss: 0.2673443555831909
Batch 49/64 loss: 0.26420074701309204
Batch 50/64 loss: 0.2612416744232178
Batch 51/64 loss: 0.25815075635910034
Batch 52/64 loss: 0.2643061876296997
Batch 53/64 loss: 0.2661120891571045
Batch 54/64 loss: 0.25636088848114014
Batch 55/64 loss: 0.26250386238098145
Batch 56/64 loss: 0.2600719928741455
Batch 57/64 loss: 0.2587754726409912
Batch 58/64 loss: 0.2663530111312866
Batch 59/64 loss: 0.2607678174972534
Batch 60/64 loss: 0.25395840406417847
Batch 61/64 loss: 0.2694684863090515
Batch 62/64 loss: 0.26586461067199707
Batch 63/64 loss: 0.257421612739563
Batch 64/64 loss: 0.2715013027191162
Epoch 129  Train loss: 0.26069709927428003  Val loss: 0.2972993146103272
Saving best model, epoch: 129
Epoch 130
-------------------------------
Batch 1/64 loss: 0.261340856552124
Batch 2/64 loss: 0.2608991265296936
Batch 3/64 loss: 0.2562241554260254
Batch 4/64 loss: 0.26177817583084106
Batch 5/64 loss: 0.255865216255188
Batch 6/64 loss: 0.2679610252380371
Batch 7/64 loss: 0.2640964984893799
Batch 8/64 loss: 0.26769399642944336
Batch 9/64 loss: 0.2525351047515869
Batch 10/64 loss: 0.27651429176330566
Batch 11/64 loss: 0.25495463609695435
Batch 12/64 loss: 0.25967109203338623
Batch 13/64 loss: 0.26457685232162476
Batch 14/64 loss: 0.2589346170425415
Batch 15/64 loss: 0.25615108013153076
Batch 16/64 loss: 0.2546778917312622
Batch 17/64 loss: 0.2774538993835449
Batch 18/64 loss: 0.24921798706054688
Batch 19/64 loss: 0.2582448720932007
Batch 20/64 loss: 0.2636054754257202
Batch 21/64 loss: 0.2573627233505249
Batch 22/64 loss: 0.25879132747650146
Batch 23/64 loss: 0.2608802914619446
Batch 24/64 loss: 0.26196199655532837
Batch 25/64 loss: 0.2620171308517456
Batch 26/64 loss: 0.26159822940826416
Batch 27/64 loss: 0.2554703950881958
Batch 28/64 loss: 0.2607463002204895
Batch 29/64 loss: 0.25046271085739136
Batch 30/64 loss: 0.2585930824279785
Batch 31/64 loss: 0.2651865482330322
Batch 32/64 loss: 0.27155929803848267
Batch 33/64 loss: 0.2600829005241394
Batch 34/64 loss: 0.26396405696868896
Batch 35/64 loss: 0.26111698150634766
Batch 36/64 loss: 0.2630624771118164
Batch 37/64 loss: 0.2593165636062622
Batch 38/64 loss: 0.2574779987335205
Batch 39/64 loss: 0.2688201665878296
Batch 40/64 loss: 0.25459450483322144
Batch 41/64 loss: 0.2508866786956787
Batch 42/64 loss: 0.27335768938064575
Batch 43/64 loss: 0.2585204243659973
Batch 44/64 loss: 0.2644232511520386
Batch 45/64 loss: 0.26290321350097656
Batch 46/64 loss: 0.2644987106323242
Batch 47/64 loss: 0.25965428352355957
Batch 48/64 loss: 0.2599390745162964
Batch 49/64 loss: 0.25509166717529297
Batch 50/64 loss: 0.25977224111557007
Batch 51/64 loss: 0.2652496099472046
Batch 52/64 loss: 0.25621354579925537
Batch 53/64 loss: 0.26040494441986084
Batch 54/64 loss: 0.25719523429870605
Batch 55/64 loss: 0.25125235319137573
Batch 56/64 loss: 0.2573808431625366
Batch 57/64 loss: 0.261616587638855
Batch 58/64 loss: 0.25671595335006714
Batch 59/64 loss: 0.2541919946670532
Batch 60/64 loss: 0.2593933939933777
Batch 61/64 loss: 0.2584323287010193
Batch 62/64 loss: 0.26553934812545776
Batch 63/64 loss: 0.2695903778076172
Batch 64/64 loss: 0.26031118631362915
Epoch 130  Train loss: 0.2605948184050766  Val loss: 0.2978957911946929
Epoch 131
-------------------------------
Batch 1/64 loss: 0.26076817512512207
Batch 2/64 loss: 0.2590080499649048
Batch 3/64 loss: 0.25685179233551025
Batch 4/64 loss: 0.2707937955856323
Batch 5/64 loss: 0.26159071922302246
Batch 6/64 loss: 0.2563602924346924
Batch 7/64 loss: 0.2780717611312866
Batch 8/64 loss: 0.2648484706878662
Batch 9/64 loss: 0.2617853283882141
Batch 10/64 loss: 0.25832152366638184
Batch 11/64 loss: 0.25205695629119873
Batch 12/64 loss: 0.2523091435432434
Batch 13/64 loss: 0.25352078676223755
Batch 14/64 loss: 0.26460355520248413
Batch 15/64 loss: 0.26146286725997925
Batch 16/64 loss: 0.26009923219680786
Batch 17/64 loss: 0.2591668963432312
Batch 18/64 loss: 0.2589801549911499
Batch 19/64 loss: 0.26023781299591064
Batch 20/64 loss: 0.25069665908813477
Batch 21/64 loss: 0.2640916109085083
Batch 22/64 loss: 0.27125096321105957
Batch 23/64 loss: 0.25796830654144287
Batch 24/64 loss: 0.2534558176994324
Batch 25/64 loss: 0.2670491933822632
Batch 26/64 loss: 0.2663201093673706
Batch 27/64 loss: 0.25899988412857056
Batch 28/64 loss: 0.2652367353439331
Batch 29/64 loss: 0.2656950354576111
Batch 30/64 loss: 0.25025928020477295
Batch 31/64 loss: 0.25409185886383057
Batch 32/64 loss: 0.26212477684020996
Batch 33/64 loss: 0.2660309076309204
Batch 34/64 loss: 0.2545771598815918
Batch 35/64 loss: 0.2582956552505493
Batch 36/64 loss: 0.2557692527770996
Batch 37/64 loss: 0.26094186305999756
Batch 38/64 loss: 0.26107609272003174
Batch 39/64 loss: 0.26108741760253906
Batch 40/64 loss: 0.2622191905975342
Batch 41/64 loss: 0.2540857791900635
Batch 42/64 loss: 0.25796836614608765
Batch 43/64 loss: 0.2520034909248352
Batch 44/64 loss: 0.2630019187927246
Batch 45/64 loss: 0.25619012117385864
Batch 46/64 loss: 0.2613203525543213
Batch 47/64 loss: 0.25553011894226074
Batch 48/64 loss: 0.2616928219795227
Batch 49/64 loss: 0.2632765769958496
Batch 50/64 loss: 0.2595541477203369
Batch 51/64 loss: 0.25922149419784546
Batch 52/64 loss: 0.25862860679626465
Batch 53/64 loss: 0.26411211490631104
Batch 54/64 loss: 0.2543880343437195
Batch 55/64 loss: 0.26592832803726196
Batch 56/64 loss: 0.25651758909225464
Batch 57/64 loss: 0.26490169763565063
Batch 58/64 loss: 0.2525902986526489
Batch 59/64 loss: 0.25555962324142456
Batch 60/64 loss: 0.25322067737579346
Batch 61/64 loss: 0.2542152404785156
Batch 62/64 loss: 0.2603030800819397
Batch 63/64 loss: 0.2584516406059265
Batch 64/64 loss: 0.26586228609085083
Epoch 131  Train loss: 0.2597668065744288  Val loss: 0.29725854073193475
Saving best model, epoch: 131
Epoch 132
-------------------------------
Batch 1/64 loss: 0.2666522264480591
Batch 2/64 loss: 0.26003795862197876
Batch 3/64 loss: 0.26007080078125
Batch 4/64 loss: 0.25847136974334717
Batch 5/64 loss: 0.25782454013824463
Batch 6/64 loss: 0.26731300354003906
Batch 7/64 loss: 0.2621619701385498
Batch 8/64 loss: 0.25611233711242676
Batch 9/64 loss: 0.25560176372528076
Batch 10/64 loss: 0.25741082429885864
Batch 11/64 loss: 0.25949883460998535
Batch 12/64 loss: 0.26106154918670654
Batch 13/64 loss: 0.2581663131713867
Batch 14/64 loss: 0.2663727402687073
Batch 15/64 loss: 0.26113009452819824
Batch 16/64 loss: 0.262346088886261
Batch 17/64 loss: 0.26254570484161377
Batch 18/64 loss: 0.2632828950881958
Batch 19/64 loss: 0.258209228515625
Batch 20/64 loss: 0.25226789712905884
Batch 21/64 loss: 0.26660633087158203
Batch 22/64 loss: 0.2659919261932373
Batch 23/64 loss: 0.2687870264053345
Batch 24/64 loss: 0.26143527030944824
Batch 25/64 loss: 0.26212942600250244
Batch 26/64 loss: 0.2588948607444763
Batch 27/64 loss: 0.2590092420578003
Batch 28/64 loss: 0.2551916241645813
Batch 29/64 loss: 0.2607072591781616
Batch 30/64 loss: 0.26788854598999023
Batch 31/64 loss: 0.25759464502334595
Batch 32/64 loss: 0.269372820854187
Batch 33/64 loss: 0.2593989372253418
Batch 34/64 loss: 0.2619534134864807
Batch 35/64 loss: 0.25007784366607666
Batch 36/64 loss: 0.2581530809402466
Batch 37/64 loss: 0.25832217931747437
Batch 38/64 loss: 0.2620609402656555
Batch 39/64 loss: 0.26396167278289795
Batch 40/64 loss: 0.2560458183288574
Batch 41/64 loss: 0.25394129753112793
Batch 42/64 loss: 0.25897443294525146
Batch 43/64 loss: 0.26137733459472656
Batch 44/64 loss: 0.2636711597442627
Batch 45/64 loss: 0.26789724826812744
Batch 46/64 loss: 0.2588902711868286
Batch 47/64 loss: 0.25629478693008423
Batch 48/64 loss: 0.25722193717956543
Batch 49/64 loss: 0.2600586414337158
Batch 50/64 loss: 0.2554330825805664
Batch 51/64 loss: 0.25418031215667725
Batch 52/64 loss: 0.2619885802268982
Batch 53/64 loss: 0.2626881003379822
Batch 54/64 loss: 0.2597227096557617
Batch 55/64 loss: 0.25663959980010986
Batch 56/64 loss: 0.2636861801147461
Batch 57/64 loss: 0.2645587921142578
Batch 58/64 loss: 0.2596069574356079
Batch 59/64 loss: 0.25132834911346436
Batch 60/64 loss: 0.26198315620422363
Batch 61/64 loss: 0.2545267939567566
Batch 62/64 loss: 0.26677900552749634
Batch 63/64 loss: 0.25504589080810547
Batch 64/64 loss: 0.2607458829879761
Epoch 132  Train loss: 0.2602694123399024  Val loss: 0.2966889569030185
Saving best model, epoch: 132
Epoch 133
-------------------------------
Batch 1/64 loss: 0.2601670026779175
Batch 2/64 loss: 0.25312888622283936
Batch 3/64 loss: 0.25700438022613525
Batch 4/64 loss: 0.26086825132369995
Batch 5/64 loss: 0.2577093243598938
Batch 6/64 loss: 0.26896393299102783
Batch 7/64 loss: 0.2651241421699524
Batch 8/64 loss: 0.2514077425003052
Batch 9/64 loss: 0.2591845989227295
Batch 10/64 loss: 0.2570975422859192
Batch 11/64 loss: 0.26645565032958984
Batch 12/64 loss: 0.26248061656951904
Batch 13/64 loss: 0.27188533544540405
Batch 14/64 loss: 0.26732462644577026
Batch 15/64 loss: 0.259458065032959
Batch 16/64 loss: 0.2607001066207886
Batch 17/64 loss: 0.26006680727005005
Batch 18/64 loss: 0.26634132862091064
Batch 19/64 loss: 0.2634657621383667
Batch 20/64 loss: 0.25629234313964844
Batch 21/64 loss: 0.25472986698150635
Batch 22/64 loss: 0.26228415966033936
Batch 23/64 loss: 0.2588980197906494
Batch 24/64 loss: 0.262079119682312
Batch 25/64 loss: 0.2643582820892334
Batch 26/64 loss: 0.25791239738464355
Batch 27/64 loss: 0.24590110778808594
Batch 28/64 loss: 0.26473933458328247
Batch 29/64 loss: 0.2678263187408447
Batch 30/64 loss: 0.2572762966156006
Batch 31/64 loss: 0.2664095163345337
Batch 32/64 loss: 0.265766441822052
Batch 33/64 loss: 0.258935809135437
Batch 34/64 loss: 0.26536935567855835
Batch 35/64 loss: 0.2547762989997864
Batch 36/64 loss: 0.2624136209487915
Batch 37/64 loss: 0.2551853656768799
Batch 38/64 loss: 0.2536364793777466
Batch 39/64 loss: 0.255504846572876
Batch 40/64 loss: 0.25891053676605225
Batch 41/64 loss: 0.25802505016326904
Batch 42/64 loss: 0.264498770236969
Batch 43/64 loss: 0.25414764881134033
Batch 44/64 loss: 0.26354503631591797
Batch 45/64 loss: 0.25739580392837524
Batch 46/64 loss: 0.26161813735961914
Batch 47/64 loss: 0.2621425986289978
Batch 48/64 loss: 0.2624972462654114
Batch 49/64 loss: 0.25871533155441284
Batch 50/64 loss: 0.26104414463043213
Batch 51/64 loss: 0.25909125804901123
Batch 52/64 loss: 0.2586745023727417
Batch 53/64 loss: 0.2522379755973816
Batch 54/64 loss: 0.26401543617248535
Batch 55/64 loss: 0.25958192348480225
Batch 56/64 loss: 0.2505807876586914
Batch 57/64 loss: 0.26700568199157715
Batch 58/64 loss: 0.26450347900390625
Batch 59/64 loss: 0.2571549415588379
Batch 60/64 loss: 0.25449883937835693
Batch 61/64 loss: 0.261600136756897
Batch 62/64 loss: 0.2574753761291504
Batch 63/64 loss: 0.2739083170890808
Batch 64/64 loss: 0.2554802894592285
Epoch 133  Train loss: 0.26029189427693683  Val loss: 0.29676802338603436
Epoch 134
-------------------------------
Batch 1/64 loss: 0.2618948221206665
Batch 2/64 loss: 0.2583906054496765
Batch 3/64 loss: 0.26778972148895264
Batch 4/64 loss: 0.2595052123069763
Batch 5/64 loss: 0.2574656009674072
Batch 6/64 loss: 0.25277817249298096
Batch 7/64 loss: 0.25249749422073364
Batch 8/64 loss: 0.2506304979324341
Batch 9/64 loss: 0.2579103708267212
Batch 10/64 loss: 0.26124805212020874
Batch 11/64 loss: 0.2565903663635254
Batch 12/64 loss: 0.25971341133117676
Batch 13/64 loss: 0.25095826387405396
Batch 14/64 loss: 0.2592231035232544
Batch 15/64 loss: 0.26099860668182373
Batch 16/64 loss: 0.26769202947616577
Batch 17/64 loss: 0.2551279067993164
Batch 18/64 loss: 0.2597273588180542
Batch 19/64 loss: 0.24578124284744263
Batch 20/64 loss: 0.25985652208328247
Batch 21/64 loss: 0.259685754776001
Batch 22/64 loss: 0.2644301652908325
Batch 23/64 loss: 0.25570225715637207
Batch 24/64 loss: 0.2501431703567505
Batch 25/64 loss: 0.25371837615966797
Batch 26/64 loss: 0.2533431053161621
Batch 27/64 loss: 0.2566182017326355
Batch 28/64 loss: 0.2514345645904541
Batch 29/64 loss: 0.2602250576019287
Batch 30/64 loss: 0.26283276081085205
Batch 31/64 loss: 0.2576238512992859
Batch 32/64 loss: 0.25649189949035645
Batch 33/64 loss: 0.26333677768707275
Batch 34/64 loss: 0.25839918851852417
Batch 35/64 loss: 0.2582617998123169
Batch 36/64 loss: 0.26844096183776855
Batch 37/64 loss: 0.2555586099624634
Batch 38/64 loss: 0.2619248628616333
Batch 39/64 loss: 0.25959140062332153
Batch 40/64 loss: 0.2677311301231384
Batch 41/64 loss: 0.25791865587234497
Batch 42/64 loss: 0.26406770944595337
Batch 43/64 loss: 0.25805550813674927
Batch 44/64 loss: 0.26142454147338867
Batch 45/64 loss: 0.2579350471496582
Batch 46/64 loss: 0.2637595534324646
Batch 47/64 loss: 0.26531434059143066
Batch 48/64 loss: 0.26690220832824707
Batch 49/64 loss: 0.24875742197036743
Batch 50/64 loss: 0.2634662389755249
Batch 51/64 loss: 0.25210773944854736
Batch 52/64 loss: 0.26825571060180664
Batch 53/64 loss: 0.256314754486084
Batch 54/64 loss: 0.24818801879882812
Batch 55/64 loss: 0.257114052772522
Batch 56/64 loss: 0.2535533905029297
Batch 57/64 loss: 0.259967565536499
Batch 58/64 loss: 0.2577670216560364
Batch 59/64 loss: 0.26308584213256836
Batch 60/64 loss: 0.26849615573883057
Batch 61/64 loss: 0.26272696256637573
Batch 62/64 loss: 0.25525498390197754
Batch 63/64 loss: 0.26395857334136963
Batch 64/64 loss: 0.26203399896621704
Epoch 134  Train loss: 0.2588578941775303  Val loss: 0.29686792691548664
Epoch 135
-------------------------------
Batch 1/64 loss: 0.2581603527069092
Batch 2/64 loss: 0.2583528757095337
Batch 3/64 loss: 0.263491153717041
Batch 4/64 loss: 0.2592466473579407
Batch 5/64 loss: 0.2501678466796875
Batch 6/64 loss: 0.2553620934486389
Batch 7/64 loss: 0.2517162561416626
Batch 8/64 loss: 0.2654270529747009
Batch 9/64 loss: 0.25667691230773926
Batch 10/64 loss: 0.2570788264274597
Batch 11/64 loss: 0.2468656301498413
Batch 12/64 loss: 0.2640901803970337
Batch 13/64 loss: 0.25872063636779785
Batch 14/64 loss: 0.261966347694397
Batch 15/64 loss: 0.2600628733634949
Batch 16/64 loss: 0.2603362798690796
Batch 17/64 loss: 0.2560141086578369
Batch 18/64 loss: 0.2634121775627136
Batch 19/64 loss: 0.26634883880615234
Batch 20/64 loss: 0.25173336267471313
Batch 21/64 loss: 0.2593703269958496
Batch 22/64 loss: 0.25309401750564575
Batch 23/64 loss: 0.2695462107658386
Batch 24/64 loss: 0.25495755672454834
Batch 25/64 loss: 0.2599588632583618
Batch 26/64 loss: 0.25999945402145386
Batch 27/64 loss: 0.2530333995819092
Batch 28/64 loss: 0.26832854747772217
Batch 29/64 loss: 0.2636427879333496
Batch 30/64 loss: 0.2560223340988159
Batch 31/64 loss: 0.26016098260879517
Batch 32/64 loss: 0.2525486946105957
Batch 33/64 loss: 0.26640450954437256
Batch 34/64 loss: 0.2547088861465454
Batch 35/64 loss: 0.26079660654067993
Batch 36/64 loss: 0.2516865134239197
Batch 37/64 loss: 0.2524174451828003
Batch 38/64 loss: 0.256869375705719
Batch 39/64 loss: 0.2577736973762512
Batch 40/64 loss: 0.26054346561431885
Batch 41/64 loss: 0.26048970222473145
Batch 42/64 loss: 0.2559070587158203
Batch 43/64 loss: 0.27049654722213745
Batch 44/64 loss: 0.2549504041671753
Batch 45/64 loss: 0.2575942277908325
Batch 46/64 loss: 0.2647552490234375
Batch 47/64 loss: 0.25809311866760254
Batch 48/64 loss: 0.2616046667098999
Batch 49/64 loss: 0.25748080015182495
Batch 50/64 loss: 0.2578437924385071
Batch 51/64 loss: 0.2555067539215088
Batch 52/64 loss: 0.25033068656921387
Batch 53/64 loss: 0.2561134099960327
Batch 54/64 loss: 0.2710360884666443
Batch 55/64 loss: 0.2671082019805908
Batch 56/64 loss: 0.24917995929718018
Batch 57/64 loss: 0.26135069131851196
Batch 58/64 loss: 0.2550581097602844
Batch 59/64 loss: 0.25480079650878906
Batch 60/64 loss: 0.2552452087402344
Batch 61/64 loss: 0.2569681406021118
Batch 62/64 loss: 0.2551390528678894
Batch 63/64 loss: 0.2569084167480469
Batch 64/64 loss: 0.24847185611724854
Epoch 135  Train loss: 0.2583122996722951  Val loss: 0.29734820352796837
Epoch 136
-------------------------------
Batch 1/64 loss: 0.257402241230011
Batch 2/64 loss: 0.2595536708831787
Batch 3/64 loss: 0.25501954555511475
Batch 4/64 loss: 0.26293790340423584
Batch 5/64 loss: 0.27391040325164795
Batch 6/64 loss: 0.25790274143218994
Batch 7/64 loss: 0.2619314193725586
Batch 8/64 loss: 0.25077301263809204
Batch 9/64 loss: 0.2602989077568054
Batch 10/64 loss: 0.2590329051017761
Batch 11/64 loss: 0.25999975204467773
Batch 12/64 loss: 0.2605917453765869
Batch 13/64 loss: 0.24998778104782104
Batch 14/64 loss: 0.2579975724220276
Batch 15/64 loss: 0.2593013048171997
Batch 16/64 loss: 0.24980276823043823
Batch 17/64 loss: 0.2470637559890747
Batch 18/64 loss: 0.2528025507926941
Batch 19/64 loss: 0.25666701793670654
Batch 20/64 loss: 0.2532773017883301
Batch 21/64 loss: 0.25332385301589966
Batch 22/64 loss: 0.2624831199645996
Batch 23/64 loss: 0.25701022148132324
Batch 24/64 loss: 0.2486788034439087
Batch 25/64 loss: 0.2524672746658325
Batch 26/64 loss: 0.25053298473358154
Batch 27/64 loss: 0.2567178010940552
Batch 28/64 loss: 0.25731050968170166
Batch 29/64 loss: 0.25670433044433594
Batch 30/64 loss: 0.2534818649291992
Batch 31/64 loss: 0.25536513328552246
Batch 32/64 loss: 0.2524806261062622
Batch 33/64 loss: 0.2600431442260742
Batch 34/64 loss: 0.26613491773605347
Batch 35/64 loss: 0.2499321699142456
Batch 36/64 loss: 0.2574281692504883
Batch 37/64 loss: 0.2578030824661255
Batch 38/64 loss: 0.2620353698730469
Batch 39/64 loss: 0.26102781295776367
Batch 40/64 loss: 0.2599780559539795
Batch 41/64 loss: 0.2533622980117798
Batch 42/64 loss: 0.2595771551132202
Batch 43/64 loss: 0.2473391890525818
Batch 44/64 loss: 0.26633620262145996
Batch 45/64 loss: 0.2630370855331421
Batch 46/64 loss: 0.259752094745636
Batch 47/64 loss: 0.2538524866104126
Batch 48/64 loss: 0.24971896409988403
Batch 49/64 loss: 0.2587662935256958
Batch 50/64 loss: 0.27120739221572876
Batch 51/64 loss: 0.2547636032104492
Batch 52/64 loss: 0.25874924659729004
Batch 53/64 loss: 0.25613605976104736
Batch 54/64 loss: 0.2554752230644226
Batch 55/64 loss: 0.26274073123931885
Batch 56/64 loss: 0.25945353507995605
Batch 57/64 loss: 0.2525308132171631
Batch 58/64 loss: 0.2599858045578003
Batch 59/64 loss: 0.257096529006958
Batch 60/64 loss: 0.2644904851913452
Batch 61/64 loss: 0.2618159055709839
Batch 62/64 loss: 0.2583218812942505
Batch 63/64 loss: 0.2598962187767029
Batch 64/64 loss: 0.2599238157272339
Epoch 136  Train loss: 0.25751437813627953  Val loss: 0.2953797539894524
Saving best model, epoch: 136
Epoch 137
-------------------------------
Batch 1/64 loss: 0.2626572251319885
Batch 2/64 loss: 0.2505655884742737
Batch 3/64 loss: 0.2555738687515259
Batch 4/64 loss: 0.2550860643386841
Batch 5/64 loss: 0.25457054376602173
Batch 6/64 loss: 0.2541131377220154
Batch 7/64 loss: 0.2593923807144165
Batch 8/64 loss: 0.25449705123901367
Batch 9/64 loss: 0.24945324659347534
Batch 10/64 loss: 0.25142914056777954
Batch 11/64 loss: 0.2602722644805908
Batch 12/64 loss: 0.24615514278411865
Batch 13/64 loss: 0.2526308298110962
Batch 14/64 loss: 0.2476375699043274
Batch 15/64 loss: 0.2609974145889282
Batch 16/64 loss: 0.24947547912597656
Batch 17/64 loss: 0.2545244097709656
Batch 18/64 loss: 0.2505127787590027
Batch 19/64 loss: 0.2565481662750244
Batch 20/64 loss: 0.2676302194595337
Batch 21/64 loss: 0.25065523386001587
Batch 22/64 loss: 0.25727003812789917
Batch 23/64 loss: 0.24927139282226562
Batch 24/64 loss: 0.25757157802581787
Batch 25/64 loss: 0.255687952041626
Batch 26/64 loss: 0.25419503450393677
Batch 27/64 loss: 0.2602997422218323
Batch 28/64 loss: 0.2543262243270874
Batch 29/64 loss: 0.26468491554260254
Batch 30/64 loss: 0.2601621150970459
Batch 31/64 loss: 0.2628299593925476
Batch 32/64 loss: 0.2580019235610962
Batch 33/64 loss: 0.26032519340515137
Batch 34/64 loss: 0.2539064884185791
Batch 35/64 loss: 0.25998634099960327
Batch 36/64 loss: 0.25371795892715454
Batch 37/64 loss: 0.2627617120742798
Batch 38/64 loss: 0.26343679428100586
Batch 39/64 loss: 0.2565537095069885
Batch 40/64 loss: 0.25876933336257935
Batch 41/64 loss: 0.25753676891326904
Batch 42/64 loss: 0.25732719898223877
Batch 43/64 loss: 0.2510964274406433
Batch 44/64 loss: 0.24928617477416992
Batch 45/64 loss: 0.263324499130249
Batch 46/64 loss: 0.2625882625579834
Batch 47/64 loss: 0.2587651014328003
Batch 48/64 loss: 0.265494704246521
Batch 49/64 loss: 0.2722393870353699
Batch 50/64 loss: 0.2577904462814331
Batch 51/64 loss: 0.2548719644546509
Batch 52/64 loss: 0.26119887828826904
Batch 53/64 loss: 0.25920218229293823
Batch 54/64 loss: 0.25454598665237427
Batch 55/64 loss: 0.26563727855682373
Batch 56/64 loss: 0.2556830644607544
Batch 57/64 loss: 0.25309664011001587
Batch 58/64 loss: 0.2555065155029297
Batch 59/64 loss: 0.2661799192428589
Batch 60/64 loss: 0.2609611749649048
Batch 61/64 loss: 0.26274538040161133
Batch 62/64 loss: 0.2674033045768738
Batch 63/64 loss: 0.24598872661590576
Batch 64/64 loss: 0.24962115287780762
Epoch 137  Train loss: 0.2571579923816756  Val loss: 0.2965361799571113
Epoch 138
-------------------------------
Batch 1/64 loss: 0.24980545043945312
Batch 2/64 loss: 0.25589245557785034
Batch 3/64 loss: 0.2603084444999695
Batch 4/64 loss: 0.2551637887954712
Batch 5/64 loss: 0.2474919557571411
Batch 6/64 loss: 0.25383293628692627
Batch 7/64 loss: 0.2526904344558716
Batch 8/64 loss: 0.2549586296081543
Batch 9/64 loss: 0.2512037754058838
Batch 10/64 loss: 0.26386094093322754
Batch 11/64 loss: 0.26063716411590576
Batch 12/64 loss: 0.26110637187957764
Batch 13/64 loss: 0.2595215439796448
Batch 14/64 loss: 0.2568129301071167
Batch 15/64 loss: 0.25375229120254517
Batch 16/64 loss: 0.24998807907104492
Batch 17/64 loss: 0.25408148765563965
Batch 18/64 loss: 0.26041650772094727
Batch 19/64 loss: 0.25223106145858765
Batch 20/64 loss: 0.2625526189804077
Batch 21/64 loss: 0.2516329884529114
Batch 22/64 loss: 0.2522023916244507
Batch 23/64 loss: 0.26192569732666016
Batch 24/64 loss: 0.25424230098724365
Batch 25/64 loss: 0.25478339195251465
Batch 26/64 loss: 0.2644963264465332
Batch 27/64 loss: 0.2697750926017761
Batch 28/64 loss: 0.2615875005722046
Batch 29/64 loss: 0.26724469661712646
Batch 30/64 loss: 0.25921130180358887
Batch 31/64 loss: 0.250873327255249
Batch 32/64 loss: 0.25232183933258057
Batch 33/64 loss: 0.2706129550933838
Batch 34/64 loss: 0.25027942657470703
Batch 35/64 loss: 0.2568783760070801
Batch 36/64 loss: 0.2538096308708191
Batch 37/64 loss: 0.24255144596099854
Batch 38/64 loss: 0.25274771451950073
Batch 39/64 loss: 0.2582833766937256
Batch 40/64 loss: 0.26372361183166504
Batch 41/64 loss: 0.2578045725822449
Batch 42/64 loss: 0.26457303762435913
Batch 43/64 loss: 0.26464784145355225
Batch 44/64 loss: 0.25739407539367676
Batch 45/64 loss: 0.24827635288238525
Batch 46/64 loss: 0.2533016800880432
Batch 47/64 loss: 0.25394773483276367
Batch 48/64 loss: 0.2572973370552063
Batch 49/64 loss: 0.2569483518600464
Batch 50/64 loss: 0.257293164730072
Batch 51/64 loss: 0.24934828281402588
Batch 52/64 loss: 0.26241499185562134
Batch 53/64 loss: 0.2612161636352539
Batch 54/64 loss: 0.2637729048728943
Batch 55/64 loss: 0.2590835690498352
Batch 56/64 loss: 0.2573482394218445
Batch 57/64 loss: 0.2581261396408081
Batch 58/64 loss: 0.26029717922210693
Batch 59/64 loss: 0.2622296214103699
Batch 60/64 loss: 0.259549617767334
Batch 61/64 loss: 0.255058228969574
Batch 62/64 loss: 0.25963932275772095
Batch 63/64 loss: 0.25447529554367065
Batch 64/64 loss: 0.2662409543991089
Epoch 138  Train loss: 0.25724261461519726  Val loss: 0.2959792611934885
Epoch 139
-------------------------------
Batch 1/64 loss: 0.24899053573608398
Batch 2/64 loss: 0.2447737455368042
Batch 3/64 loss: 0.2493271827697754
Batch 4/64 loss: 0.24959206581115723
Batch 5/64 loss: 0.263691782951355
Batch 6/64 loss: 0.26025891304016113
Batch 7/64 loss: 0.2575299143791199
Batch 8/64 loss: 0.2606568932533264
Batch 9/64 loss: 0.25852036476135254
Batch 10/64 loss: 0.25487351417541504
Batch 11/64 loss: 0.25291919708251953
Batch 12/64 loss: 0.25565165281295776
Batch 13/64 loss: 0.24883371591567993
Batch 14/64 loss: 0.25419706106185913
Batch 15/64 loss: 0.2627516984939575
Batch 16/64 loss: 0.26010143756866455
Batch 17/64 loss: 0.2560616731643677
Batch 18/64 loss: 0.2533656358718872
Batch 19/64 loss: 0.2528250217437744
Batch 20/64 loss: 0.2633575201034546
Batch 21/64 loss: 0.26057350635528564
Batch 22/64 loss: 0.249237060546875
Batch 23/64 loss: 0.25327539443969727
Batch 24/64 loss: 0.2593449354171753
Batch 25/64 loss: 0.2574805021286011
Batch 26/64 loss: 0.26931244134902954
Batch 27/64 loss: 0.26195549964904785
Batch 28/64 loss: 0.25992804765701294
Batch 29/64 loss: 0.26469874382019043
Batch 30/64 loss: 0.25893813371658325
Batch 31/64 loss: 0.255932092666626
Batch 32/64 loss: 0.2504647970199585
Batch 33/64 loss: 0.25004875659942627
Batch 34/64 loss: 0.258068323135376
Batch 35/64 loss: 0.2503965497016907
Batch 36/64 loss: 0.2602391242980957
Batch 37/64 loss: 0.25282299518585205
Batch 38/64 loss: 0.2580740451812744
Batch 39/64 loss: 0.257815957069397
Batch 40/64 loss: 0.2611590623855591
Batch 41/64 loss: 0.25289201736450195
Batch 42/64 loss: 0.25883549451828003
Batch 43/64 loss: 0.2597191333770752
Batch 44/64 loss: 0.25113463401794434
Batch 45/64 loss: 0.25003963708877563
Batch 46/64 loss: 0.2611793279647827
Batch 47/64 loss: 0.2503768801689148
Batch 48/64 loss: 0.25905001163482666
Batch 49/64 loss: 0.254702091217041
Batch 50/64 loss: 0.2583160400390625
Batch 51/64 loss: 0.24802422523498535
Batch 52/64 loss: 0.25095075368881226
Batch 53/64 loss: 0.2583577632904053
Batch 54/64 loss: 0.24682140350341797
Batch 55/64 loss: 0.2483280897140503
Batch 56/64 loss: 0.25287896394729614
Batch 57/64 loss: 0.2585919499397278
Batch 58/64 loss: 0.24792617559432983
Batch 59/64 loss: 0.24578332901000977
Batch 60/64 loss: 0.25768429040908813
Batch 61/64 loss: 0.25236213207244873
Batch 62/64 loss: 0.2560359835624695
Batch 63/64 loss: 0.25985097885131836
Batch 64/64 loss: 0.2638125419616699
Epoch 139  Train loss: 0.2556195483488195  Val loss: 0.29572580524326597
Epoch 140
-------------------------------
Batch 1/64 loss: 0.2547469139099121
Batch 2/64 loss: 0.2533172369003296
Batch 3/64 loss: 0.24255895614624023
Batch 4/64 loss: 0.2572842836380005
Batch 5/64 loss: 0.25474750995635986
Batch 6/64 loss: 0.25411438941955566
Batch 7/64 loss: 0.2524014711380005
Batch 8/64 loss: 0.26337867975234985
Batch 9/64 loss: 0.26340508460998535
Batch 10/64 loss: 0.25465071201324463
Batch 11/64 loss: 0.2599371671676636
Batch 12/64 loss: 0.2578655481338501
Batch 13/64 loss: 0.2553914189338684
Batch 14/64 loss: 0.24726426601409912
Batch 15/64 loss: 0.2565068006515503
Batch 16/64 loss: 0.26256293058395386
Batch 17/64 loss: 0.2502230405807495
Batch 18/64 loss: 0.2538442611694336
Batch 19/64 loss: 0.25647658109664917
Batch 20/64 loss: 0.2649170160293579
Batch 21/64 loss: 0.26001328229904175
Batch 22/64 loss: 0.2477341890335083
Batch 23/64 loss: 0.2601550817489624
Batch 24/64 loss: 0.2561146020889282
Batch 25/64 loss: 0.2540847659111023
Batch 26/64 loss: 0.2544894218444824
Batch 27/64 loss: 0.25264090299606323
Batch 28/64 loss: 0.2506633996963501
Batch 29/64 loss: 0.25274085998535156
Batch 30/64 loss: 0.24882924556732178
Batch 31/64 loss: 0.26276177167892456
Batch 32/64 loss: 0.2554497718811035
Batch 33/64 loss: 0.2520420551300049
Batch 34/64 loss: 0.2537039518356323
Batch 35/64 loss: 0.2504923343658447
Batch 36/64 loss: 0.26681196689605713
Batch 37/64 loss: 0.2552871108055115
Batch 38/64 loss: 0.2618287205696106
Batch 39/64 loss: 0.25401079654693604
Batch 40/64 loss: 0.2600345015525818
Batch 41/64 loss: 0.26056408882141113
Batch 42/64 loss: 0.25272804498672485
Batch 43/64 loss: 0.26565253734588623
Batch 44/64 loss: 0.2654842138290405
Batch 45/64 loss: 0.25663113594055176
Batch 46/64 loss: 0.24897640943527222
Batch 47/64 loss: 0.25103604793548584
Batch 48/64 loss: 0.2569462060928345
Batch 49/64 loss: 0.25399965047836304
Batch 50/64 loss: 0.2549777030944824
Batch 51/64 loss: 0.26000726222991943
Batch 52/64 loss: 0.26930636167526245
Batch 53/64 loss: 0.25801318883895874
Batch 54/64 loss: 0.25896453857421875
Batch 55/64 loss: 0.2580236792564392
Batch 56/64 loss: 0.26235508918762207
Batch 57/64 loss: 0.2514914274215698
Batch 58/64 loss: 0.2528166174888611
Batch 59/64 loss: 0.2651900053024292
Batch 60/64 loss: 0.2485761046409607
Batch 61/64 loss: 0.2618829607963562
Batch 62/64 loss: 0.2605341672897339
Batch 63/64 loss: 0.25882571935653687
Batch 64/64 loss: 0.24319791793823242
Epoch 140  Train loss: 0.2563272878235462  Val loss: 0.2958128276149842
Epoch 141
-------------------------------
Batch 1/64 loss: 0.25297844409942627
Batch 2/64 loss: 0.2616557478904724
Batch 3/64 loss: 0.2528690695762634
Batch 4/64 loss: 0.24456292390823364
Batch 5/64 loss: 0.25908321142196655
Batch 6/64 loss: 0.2518240213394165
Batch 7/64 loss: 0.26519161462783813
Batch 8/64 loss: 0.25724852085113525
Batch 9/64 loss: 0.2503163814544678
Batch 10/64 loss: 0.26337987184524536
Batch 11/64 loss: 0.2550482749938965
Batch 12/64 loss: 0.2555636167526245
Batch 13/64 loss: 0.2557189464569092
Batch 14/64 loss: 0.25833505392074585
Batch 15/64 loss: 0.263558566570282
Batch 16/64 loss: 0.2501407265663147
Batch 17/64 loss: 0.25884199142456055
Batch 18/64 loss: 0.25837528705596924
Batch 19/64 loss: 0.24777722358703613
Batch 20/64 loss: 0.2710695266723633
Batch 21/64 loss: 0.2648336887359619
Batch 22/64 loss: 0.24571597576141357
Batch 23/64 loss: 0.2581547498703003
Batch 24/64 loss: 0.25736165046691895
Batch 25/64 loss: 0.2633565664291382
Batch 26/64 loss: 0.26200926303863525
Batch 27/64 loss: 0.2561694383621216
Batch 28/64 loss: 0.2525719404220581
Batch 29/64 loss: 0.258262038230896
Batch 30/64 loss: 0.24959158897399902
Batch 31/64 loss: 0.24583077430725098
Batch 32/64 loss: 0.2484745979309082
Batch 33/64 loss: 0.25458824634552
Batch 34/64 loss: 0.26926958560943604
Batch 35/64 loss: 0.25164592266082764
Batch 36/64 loss: 0.254452109336853
Batch 37/64 loss: 0.26669609546661377
Batch 38/64 loss: 0.26136666536331177
Batch 39/64 loss: 0.2552052140235901
Batch 40/64 loss: 0.255771279335022
Batch 41/64 loss: 0.26475316286087036
Batch 42/64 loss: 0.25726866722106934
Batch 43/64 loss: 0.25257962942123413
Batch 44/64 loss: 0.25741106271743774
Batch 45/64 loss: 0.2506239414215088
Batch 46/64 loss: 0.2523679733276367
Batch 47/64 loss: 0.2536012530326843
Batch 48/64 loss: 0.2545311450958252
Batch 49/64 loss: 0.26224517822265625
Batch 50/64 loss: 0.25555360317230225
Batch 51/64 loss: 0.2595491409301758
Batch 52/64 loss: 0.2530674934387207
Batch 53/64 loss: 0.2534639835357666
Batch 54/64 loss: 0.2487836480140686
Batch 55/64 loss: 0.2583034038543701
Batch 56/64 loss: 0.25888919830322266
Batch 57/64 loss: 0.25183868408203125
Batch 58/64 loss: 0.2591913342475891
Batch 59/64 loss: 0.24762141704559326
Batch 60/64 loss: 0.2515941858291626
Batch 61/64 loss: 0.24793899059295654
Batch 62/64 loss: 0.2571526765823364
Batch 63/64 loss: 0.2480083703994751
Batch 64/64 loss: 0.2469029426574707
Epoch 141  Train loss: 0.2557863805808273  Val loss: 0.2958762621142201
Epoch 142
-------------------------------
Batch 1/64 loss: 0.25815343856811523
Batch 2/64 loss: 0.25973832607269287
Batch 3/64 loss: 0.2781245708465576
Batch 4/64 loss: 0.26040565967559814
Batch 5/64 loss: 0.25834178924560547
Batch 6/64 loss: 0.26642167568206787
Batch 7/64 loss: 0.25013184547424316
Batch 8/64 loss: 0.2474576234817505
Batch 9/64 loss: 0.266021728515625
Batch 10/64 loss: 0.25516438484191895
Batch 11/64 loss: 0.2561943531036377
Batch 12/64 loss: 0.25433433055877686
Batch 13/64 loss: 0.24690675735473633
Batch 14/64 loss: 0.2528284788131714
Batch 15/64 loss: 0.2545536160469055
Batch 16/64 loss: 0.24422115087509155
Batch 17/64 loss: 0.25610142946243286
Batch 18/64 loss: 0.251589298248291
Batch 19/64 loss: 0.25122201442718506
Batch 20/64 loss: 0.2487141489982605
Batch 21/64 loss: 0.26153242588043213
Batch 22/64 loss: 0.25562357902526855
Batch 23/64 loss: 0.24700802564620972
Batch 24/64 loss: 0.2611730098724365
Batch 25/64 loss: 0.24996721744537354
Batch 26/64 loss: 0.24896591901779175
Batch 27/64 loss: 0.2548567056655884
Batch 28/64 loss: 0.2593657970428467
Batch 29/64 loss: 0.25598686933517456
Batch 30/64 loss: 0.2493634819984436
Batch 31/64 loss: 0.25193339586257935
Batch 32/64 loss: 0.2528667449951172
Batch 33/64 loss: 0.24956291913986206
Batch 34/64 loss: 0.24682605266571045
Batch 35/64 loss: 0.25864142179489136
Batch 36/64 loss: 0.24799692630767822
Batch 37/64 loss: 0.24980509281158447
Batch 38/64 loss: 0.25663626194000244
Batch 39/64 loss: 0.2502779960632324
Batch 40/64 loss: 0.2512245178222656
Batch 41/64 loss: 0.2502427101135254
Batch 42/64 loss: 0.2539423704147339
Batch 43/64 loss: 0.25413018465042114
Batch 44/64 loss: 0.256136953830719
Batch 45/64 loss: 0.24802231788635254
Batch 46/64 loss: 0.2606167197227478
Batch 47/64 loss: 0.24105465412139893
Batch 48/64 loss: 0.2568477988243103
Batch 49/64 loss: 0.2607194781303406
Batch 50/64 loss: 0.2544584274291992
Batch 51/64 loss: 0.26349568367004395
Batch 52/64 loss: 0.24898922443389893
Batch 53/64 loss: 0.2652798891067505
Batch 54/64 loss: 0.2521931529045105
Batch 55/64 loss: 0.2602834105491638
Batch 56/64 loss: 0.25554198026657104
Batch 57/64 loss: 0.25553542375564575
Batch 58/64 loss: 0.25787317752838135
Batch 59/64 loss: 0.2600864768028259
Batch 60/64 loss: 0.2556498646736145
Batch 61/64 loss: 0.2571502923965454
Batch 62/64 loss: 0.25396502017974854
Batch 63/64 loss: 0.26278382539749146
Batch 64/64 loss: 0.25502872467041016
Epoch 142  Train loss: 0.25494135781830435  Val loss: 0.29689324639507175
Epoch 143
-------------------------------
Batch 1/64 loss: 0.2515925168991089
Batch 2/64 loss: 0.2462366819381714
Batch 3/64 loss: 0.2521666884422302
Batch 4/64 loss: 0.24642395973205566
Batch 5/64 loss: 0.2541494369506836
Batch 6/64 loss: 0.2688448429107666
Batch 7/64 loss: 0.2560727000236511
Batch 8/64 loss: 0.24832820892333984
Batch 9/64 loss: 0.2604118585586548
Batch 10/64 loss: 0.25596368312835693
Batch 11/64 loss: 0.25561702251434326
Batch 12/64 loss: 0.2498881220817566
Batch 13/64 loss: 0.24955099821090698
Batch 14/64 loss: 0.2572697401046753
Batch 15/64 loss: 0.2550581693649292
Batch 16/64 loss: 0.25208306312561035
Batch 17/64 loss: 0.25261974334716797
Batch 18/64 loss: 0.25754672288894653
Batch 19/64 loss: 0.2557286024093628
Batch 20/64 loss: 0.2560824155807495
Batch 21/64 loss: 0.24751359224319458
Batch 22/64 loss: 0.24036121368408203
Batch 23/64 loss: 0.2638587951660156
Batch 24/64 loss: 0.25995373725891113
Batch 25/64 loss: 0.25768613815307617
Batch 26/64 loss: 0.25698208808898926
Batch 27/64 loss: 0.24952518939971924
Batch 28/64 loss: 0.26206761598587036
Batch 29/64 loss: 0.24870681762695312
Batch 30/64 loss: 0.25741130113601685
Batch 31/64 loss: 0.2506154775619507
Batch 32/64 loss: 0.2584078311920166
Batch 33/64 loss: 0.2504057288169861
Batch 34/64 loss: 0.2470989227294922
Batch 35/64 loss: 0.24982905387878418
Batch 36/64 loss: 0.2578163146972656
Batch 37/64 loss: 0.26166975498199463
Batch 38/64 loss: 0.2563815116882324
Batch 39/64 loss: 0.2651495933532715
Batch 40/64 loss: 0.255051851272583
Batch 41/64 loss: 0.25867587327957153
Batch 42/64 loss: 0.2523893117904663
Batch 43/64 loss: 0.2516670227050781
Batch 44/64 loss: 0.25576913356781006
Batch 45/64 loss: 0.24892938137054443
Batch 46/64 loss: 0.24572813510894775
Batch 47/64 loss: 0.259509801864624
Batch 48/64 loss: 0.2576632499694824
Batch 49/64 loss: 0.25236034393310547
Batch 50/64 loss: 0.25039780139923096
Batch 51/64 loss: 0.25444459915161133
Batch 52/64 loss: 0.2635071873664856
Batch 53/64 loss: 0.2509446144104004
Batch 54/64 loss: 0.25051939487457275
Batch 55/64 loss: 0.25663793087005615
Batch 56/64 loss: 0.2560359239578247
Batch 57/64 loss: 0.25947755575180054
Batch 58/64 loss: 0.2544996738433838
Batch 59/64 loss: 0.2541963458061218
Batch 60/64 loss: 0.25742948055267334
Batch 61/64 loss: 0.25388288497924805
Batch 62/64 loss: 0.2594337463378906
Batch 63/64 loss: 0.25356197357177734
Batch 64/64 loss: 0.26007986068725586
Epoch 143  Train loss: 0.2546015524396709  Val loss: 0.29595400254750986
Epoch 144
-------------------------------
Batch 1/64 loss: 0.25248920917510986
Batch 2/64 loss: 0.2632043957710266
Batch 3/64 loss: 0.24960815906524658
Batch 4/64 loss: 0.24967026710510254
Batch 5/64 loss: 0.2571544647216797
Batch 6/64 loss: 0.2528189420700073
Batch 7/64 loss: 0.2553046941757202
Batch 8/64 loss: 0.2540435791015625
Batch 9/64 loss: 0.2542840242385864
Batch 10/64 loss: 0.26319241523742676
Batch 11/64 loss: 0.2474595308303833
Batch 12/64 loss: 0.25445735454559326
Batch 13/64 loss: 0.25819170475006104
Batch 14/64 loss: 0.24665367603302002
Batch 15/64 loss: 0.2525012493133545
Batch 16/64 loss: 0.2686387300491333
Batch 17/64 loss: 0.25681209564208984
Batch 18/64 loss: 0.2507169246673584
Batch 19/64 loss: 0.2507418394088745
Batch 20/64 loss: 0.25888049602508545
Batch 21/64 loss: 0.2511146068572998
Batch 22/64 loss: 0.24404489994049072
Batch 23/64 loss: 0.25848686695098877
Batch 24/64 loss: 0.2519950270652771
Batch 25/64 loss: 0.25741004943847656
Batch 26/64 loss: 0.2552134394645691
Batch 27/64 loss: 0.24802255630493164
Batch 28/64 loss: 0.2493600845336914
Batch 29/64 loss: 0.2518962025642395
Batch 30/64 loss: 0.24611896276474
Batch 31/64 loss: 0.2597123384475708
Batch 32/64 loss: 0.25446242094039917
Batch 33/64 loss: 0.24561214447021484
Batch 34/64 loss: 0.24893438816070557
Batch 35/64 loss: 0.259335458278656
Batch 36/64 loss: 0.25468993186950684
Batch 37/64 loss: 0.2602205276489258
Batch 38/64 loss: 0.2534946799278259
Batch 39/64 loss: 0.2734922170639038
Batch 40/64 loss: 0.2542484402656555
Batch 41/64 loss: 0.2524225115776062
Batch 42/64 loss: 0.2544189691543579
Batch 43/64 loss: 0.26277005672454834
Batch 44/64 loss: 0.25243449211120605
Batch 45/64 loss: 0.25265759229660034
Batch 46/64 loss: 0.25723642110824585
Batch 47/64 loss: 0.25599944591522217
Batch 48/64 loss: 0.24824774265289307
Batch 49/64 loss: 0.2583715319633484
Batch 50/64 loss: 0.25173646211624146
Batch 51/64 loss: 0.2503442168235779
Batch 52/64 loss: 0.2485414743423462
Batch 53/64 loss: 0.2607383728027344
Batch 54/64 loss: 0.2436504364013672
Batch 55/64 loss: 0.25045740604400635
Batch 56/64 loss: 0.2527264356613159
Batch 57/64 loss: 0.2504505515098572
Batch 58/64 loss: 0.26483452320098877
Batch 59/64 loss: 0.25876951217651367
Batch 60/64 loss: 0.2567957639694214
Batch 61/64 loss: 0.24798429012298584
Batch 62/64 loss: 0.25756609439849854
Batch 63/64 loss: 0.2458178997039795
Batch 64/64 loss: 0.2583125829696655
Epoch 144  Train loss: 0.25417091191983693  Val loss: 0.2956827799069513
Epoch 145
-------------------------------
Batch 1/64 loss: 0.25340723991394043
Batch 2/64 loss: 0.25276196002960205
Batch 3/64 loss: 0.24629783630371094
Batch 4/64 loss: 0.25051164627075195
Batch 5/64 loss: 0.2514689564704895
Batch 6/64 loss: 0.2424325942993164
Batch 7/64 loss: 0.25043320655822754
Batch 8/64 loss: 0.25701963901519775
Batch 9/64 loss: 0.2558337450027466
Batch 10/64 loss: 0.2538853883743286
Batch 11/64 loss: 0.24708425998687744
Batch 12/64 loss: 0.24794137477874756
Batch 13/64 loss: 0.26107317209243774
Batch 14/64 loss: 0.25337767601013184
Batch 15/64 loss: 0.26194751262664795
Batch 16/64 loss: 0.26152753829956055
Batch 17/64 loss: 0.25899553298950195
Batch 18/64 loss: 0.25328558683395386
Batch 19/64 loss: 0.2516512870788574
Batch 20/64 loss: 0.25361478328704834
Batch 21/64 loss: 0.26751768589019775
Batch 22/64 loss: 0.24841487407684326
Batch 23/64 loss: 0.2467503547668457
Batch 24/64 loss: 0.24504399299621582
Batch 25/64 loss: 0.26029282808303833
Batch 26/64 loss: 0.2610381841659546
Batch 27/64 loss: 0.24940502643585205
Batch 28/64 loss: 0.2624131441116333
Batch 29/64 loss: 0.24265480041503906
Batch 30/64 loss: 0.25817304849624634
Batch 31/64 loss: 0.2535562515258789
Batch 32/64 loss: 0.24976086616516113
Batch 33/64 loss: 0.2653532028198242
Batch 34/64 loss: 0.2546902894973755
Batch 35/64 loss: 0.25394105911254883
Batch 36/64 loss: 0.2515525817871094
Batch 37/64 loss: 0.2553439736366272
Batch 38/64 loss: 0.25915390253067017
Batch 39/64 loss: 0.26040709018707275
Batch 40/64 loss: 0.25458288192749023
Batch 41/64 loss: 0.2526371479034424
Batch 42/64 loss: 0.2514837384223938
Batch 43/64 loss: 0.2609221339225769
Batch 44/64 loss: 0.25421977043151855
Batch 45/64 loss: 0.25111985206604004
Batch 46/64 loss: 0.2536267042160034
Batch 47/64 loss: 0.25347596406936646
Batch 48/64 loss: 0.24751585721969604
Batch 49/64 loss: 0.25234609842300415
Batch 50/64 loss: 0.24942535161972046
Batch 51/64 loss: 0.2678185701370239
Batch 52/64 loss: 0.2536908984184265
Batch 53/64 loss: 0.2594139575958252
Batch 54/64 loss: 0.24925029277801514
Batch 55/64 loss: 0.25565457344055176
Batch 56/64 loss: 0.26199817657470703
Batch 57/64 loss: 0.2456178069114685
Batch 58/64 loss: 0.25269198417663574
Batch 59/64 loss: 0.2539581060409546
Batch 60/64 loss: 0.2570977210998535
Batch 61/64 loss: 0.2521563768386841
Batch 62/64 loss: 0.25304996967315674
Batch 63/64 loss: 0.25650548934936523
Batch 64/64 loss: 0.25452858209609985
Epoch 145  Train loss: 0.25413599925882674  Val loss: 0.29549288872591
Epoch 146
-------------------------------
Batch 1/64 loss: 0.24619227647781372
Batch 2/64 loss: 0.2573927640914917
Batch 3/64 loss: 0.268943190574646
Batch 4/64 loss: 0.25095951557159424
Batch 5/64 loss: 0.25281262397766113
Batch 6/64 loss: 0.24455112218856812
Batch 7/64 loss: 0.24866712093353271
Batch 8/64 loss: 0.25572502613067627
Batch 9/64 loss: 0.2540830373764038
Batch 10/64 loss: 0.2451048493385315
Batch 11/64 loss: 0.256717324256897
Batch 12/64 loss: 0.2532142400741577
Batch 13/64 loss: 0.25201284885406494
Batch 14/64 loss: 0.2692892551422119
Batch 15/64 loss: 0.2481611967086792
Batch 16/64 loss: 0.2518472671508789
Batch 17/64 loss: 0.2560250759124756
Batch 18/64 loss: 0.25336194038391113
Batch 19/64 loss: 0.2572142481803894
Batch 20/64 loss: 0.24774301052093506
Batch 21/64 loss: 0.2584484815597534
Batch 22/64 loss: 0.25324511528015137
Batch 23/64 loss: 0.2546757459640503
Batch 24/64 loss: 0.2544454336166382
Batch 25/64 loss: 0.24372529983520508
Batch 26/64 loss: 0.2602810263633728
Batch 27/64 loss: 0.25174951553344727
Batch 28/64 loss: 0.23938459157943726
Batch 29/64 loss: 0.257580041885376
Batch 30/64 loss: 0.25124311447143555
Batch 31/64 loss: 0.2528143525123596
Batch 32/64 loss: 0.2545211911201477
Batch 33/64 loss: 0.2443990707397461
Batch 34/64 loss: 0.2576082944869995
Batch 35/64 loss: 0.2501946687698364
Batch 36/64 loss: 0.2517687678337097
Batch 37/64 loss: 0.2612193822860718
Batch 38/64 loss: 0.25240981578826904
Batch 39/64 loss: 0.2483919858932495
Batch 40/64 loss: 0.250325083732605
Batch 41/64 loss: 0.2470548152923584
Batch 42/64 loss: 0.24828702211380005
Batch 43/64 loss: 0.2545034885406494
Batch 44/64 loss: 0.25528430938720703
Batch 45/64 loss: 0.24533617496490479
Batch 46/64 loss: 0.2581288814544678
Batch 47/64 loss: 0.2657071352005005
Batch 48/64 loss: 0.24586999416351318
Batch 49/64 loss: 0.25630199909210205
Batch 50/64 loss: 0.2497117519378662
Batch 51/64 loss: 0.2582050561904907
Batch 52/64 loss: 0.2499067783355713
Batch 53/64 loss: 0.2558826208114624
Batch 54/64 loss: 0.2525184750556946
Batch 55/64 loss: 0.26657557487487793
Batch 56/64 loss: 0.2598379850387573
Batch 57/64 loss: 0.24827176332473755
Batch 58/64 loss: 0.24840641021728516
Batch 59/64 loss: 0.2562476396560669
Batch 60/64 loss: 0.25658535957336426
Batch 61/64 loss: 0.2585480213165283
Batch 62/64 loss: 0.2537243366241455
Batch 63/64 loss: 0.25005102157592773
Batch 64/64 loss: 0.2530158758163452
Epoch 146  Train loss: 0.2533201166227752  Val loss: 0.2953451791989435
Saving best model, epoch: 146
Epoch 147
-------------------------------
Batch 1/64 loss: 0.24329602718353271
Batch 2/64 loss: 0.24985766410827637
Batch 3/64 loss: 0.2526278495788574
Batch 4/64 loss: 0.25050342082977295
Batch 5/64 loss: 0.2587168216705322
Batch 6/64 loss: 0.262808620929718
Batch 7/64 loss: 0.24333763122558594
Batch 8/64 loss: 0.25160133838653564
Batch 9/64 loss: 0.2531329393386841
Batch 10/64 loss: 0.25652050971984863
Batch 11/64 loss: 0.2509653568267822
Batch 12/64 loss: 0.25141334533691406
Batch 13/64 loss: 0.24783772230148315
Batch 14/64 loss: 0.24616080522537231
Batch 15/64 loss: 0.24770402908325195
Batch 16/64 loss: 0.2553824186325073
Batch 17/64 loss: 0.24774408340454102
Batch 18/64 loss: 0.2670360803604126
Batch 19/64 loss: 0.2488834261894226
Batch 20/64 loss: 0.25120389461517334
Batch 21/64 loss: 0.25591570138931274
Batch 22/64 loss: 0.2480698823928833
Batch 23/64 loss: 0.2526542544364929
Batch 24/64 loss: 0.24630874395370483
Batch 25/64 loss: 0.257448673248291
Batch 26/64 loss: 0.2623915672302246
Batch 27/64 loss: 0.2529597878456116
Batch 28/64 loss: 0.25459110736846924
Batch 29/64 loss: 0.2547755241394043
Batch 30/64 loss: 0.25281190872192383
Batch 31/64 loss: 0.26201021671295166
Batch 32/64 loss: 0.25437819957733154
Batch 33/64 loss: 0.25142568349838257
Batch 34/64 loss: 0.2584235668182373
Batch 35/64 loss: 0.24427950382232666
Batch 36/64 loss: 0.2597179412841797
Batch 37/64 loss: 0.2537754774093628
Batch 38/64 loss: 0.2520580291748047
Batch 39/64 loss: 0.26080119609832764
Batch 40/64 loss: 0.2538604736328125
Batch 41/64 loss: 0.24925661087036133
Batch 42/64 loss: 0.25420570373535156
Batch 43/64 loss: 0.24863052368164062
Batch 44/64 loss: 0.25217270851135254
Batch 45/64 loss: 0.25404274463653564
Batch 46/64 loss: 0.2608477473258972
Batch 47/64 loss: 0.24683088064193726
Batch 48/64 loss: 0.2587836980819702
Batch 49/64 loss: 0.251684308052063
Batch 50/64 loss: 0.2524293065071106
Batch 51/64 loss: 0.2507188320159912
Batch 52/64 loss: 0.25571250915527344
Batch 53/64 loss: 0.26728105545043945
Batch 54/64 loss: 0.2552485466003418
Batch 55/64 loss: 0.2559100389480591
Batch 56/64 loss: 0.25275152921676636
Batch 57/64 loss: 0.2499237060546875
Batch 58/64 loss: 0.248884916305542
Batch 59/64 loss: 0.24580711126327515
Batch 60/64 loss: 0.24974364042282104
Batch 61/64 loss: 0.2752370238304138
Batch 62/64 loss: 0.2527174949645996
Batch 63/64 loss: 0.2511885166168213
Batch 64/64 loss: 0.2520480751991272
Epoch 147  Train loss: 0.2534029275763269  Val loss: 0.2951510536301996
Saving best model, epoch: 147
Epoch 148
-------------------------------
Batch 1/64 loss: 0.24562251567840576
Batch 2/64 loss: 0.24817025661468506
Batch 3/64 loss: 0.2507323622703552
Batch 4/64 loss: 0.2435767650604248
Batch 5/64 loss: 0.25449252128601074
Batch 6/64 loss: 0.25520020723342896
Batch 7/64 loss: 0.24993693828582764
Batch 8/64 loss: 0.2639992833137512
Batch 9/64 loss: 0.2533745765686035
Batch 10/64 loss: 0.25209522247314453
Batch 11/64 loss: 0.2479625940322876
Batch 12/64 loss: 0.25421977043151855
Batch 13/64 loss: 0.25097811222076416
Batch 14/64 loss: 0.26755446195602417
Batch 15/64 loss: 0.26190030574798584
Batch 16/64 loss: 0.24271464347839355
Batch 17/64 loss: 0.25968801975250244
Batch 18/64 loss: 0.24692022800445557
Batch 19/64 loss: 0.26279211044311523
Batch 20/64 loss: 0.2564582824707031
Batch 21/64 loss: 0.2470884919166565
Batch 22/64 loss: 0.2530668377876282
Batch 23/64 loss: 0.2509869933128357
Batch 24/64 loss: 0.2537841796875
Batch 25/64 loss: 0.25260114669799805
Batch 26/64 loss: 0.24815446138381958
Batch 27/64 loss: 0.24791944026947021
Batch 28/64 loss: 0.24853557348251343
Batch 29/64 loss: 0.25320959091186523
Batch 30/64 loss: 0.2527165412902832
Batch 31/64 loss: 0.2519347667694092
Batch 32/64 loss: 0.25074589252471924
Batch 33/64 loss: 0.25823938846588135
Batch 34/64 loss: 0.25686389207839966
Batch 35/64 loss: 0.24806952476501465
Batch 36/64 loss: 0.260728657245636
Batch 37/64 loss: 0.256075918674469
Batch 38/64 loss: 0.2432713508605957
Batch 39/64 loss: 0.25589001178741455
Batch 40/64 loss: 0.2570231556892395
Batch 41/64 loss: 0.2582453489303589
Batch 42/64 loss: 0.24521231651306152
Batch 43/64 loss: 0.25803184509277344
Batch 44/64 loss: 0.2553905248641968
Batch 45/64 loss: 0.24397069215774536
Batch 46/64 loss: 0.25329720973968506
Batch 47/64 loss: 0.2530243396759033
Batch 48/64 loss: 0.24991488456726074
Batch 49/64 loss: 0.24717581272125244
Batch 50/64 loss: 0.2472296953201294
Batch 51/64 loss: 0.2530553340911865
Batch 52/64 loss: 0.25315606594085693
Batch 53/64 loss: 0.2585926055908203
Batch 54/64 loss: 0.2624626159667969
Batch 55/64 loss: 0.2543533444404602
Batch 56/64 loss: 0.2485426664352417
Batch 57/64 loss: 0.24527513980865479
Batch 58/64 loss: 0.2503795623779297
Batch 59/64 loss: 0.25105804204940796
Batch 60/64 loss: 0.25332218408584595
Batch 61/64 loss: 0.2521180510520935
Batch 62/64 loss: 0.2593299150466919
Batch 63/64 loss: 0.2503412961959839
Batch 64/64 loss: 0.25895583629608154
Epoch 148  Train loss: 0.2527528056911394  Val loss: 0.29617679405867847
Epoch 149
-------------------------------
Batch 1/64 loss: 0.2473132610321045
Batch 2/64 loss: 0.25756949186325073
Batch 3/64 loss: 0.245810866355896
Batch 4/64 loss: 0.24261093139648438
Batch 5/64 loss: 0.2471165657043457
Batch 6/64 loss: 0.24813902378082275
Batch 7/64 loss: 0.2488611936569214
Batch 8/64 loss: 0.25491005182266235
Batch 9/64 loss: 0.2558246850967407
Batch 10/64 loss: 0.250583291053772
Batch 11/64 loss: 0.2592158317565918
Batch 12/64 loss: 0.24855387210845947
Batch 13/64 loss: 0.2539687156677246
Batch 14/64 loss: 0.25269240140914917
Batch 15/64 loss: 0.2559027075767517
Batch 16/64 loss: 0.24865996837615967
Batch 17/64 loss: 0.24852389097213745
Batch 18/64 loss: 0.25219666957855225
Batch 19/64 loss: 0.24576902389526367
Batch 20/64 loss: 0.25079548358917236
Batch 21/64 loss: 0.2522426247596741
Batch 22/64 loss: 0.25004565715789795
Batch 23/64 loss: 0.245222806930542
Batch 24/64 loss: 0.252504825592041
Batch 25/64 loss: 0.24896711111068726
Batch 26/64 loss: 0.25025737285614014
Batch 27/64 loss: 0.2547886371612549
Batch 28/64 loss: 0.2648047208786011
Batch 29/64 loss: 0.25450778007507324
Batch 30/64 loss: 0.24819016456604004
Batch 31/64 loss: 0.24615180492401123
Batch 32/64 loss: 0.2540832757949829
Batch 33/64 loss: 0.24694859981536865
Batch 34/64 loss: 0.24223506450653076
Batch 35/64 loss: 0.2565338611602783
Batch 36/64 loss: 0.2564210295677185
Batch 37/64 loss: 0.2560536861419678
Batch 38/64 loss: 0.24893659353256226
Batch 39/64 loss: 0.2534061074256897
Batch 40/64 loss: 0.25047218799591064
Batch 41/64 loss: 0.24976956844329834
Batch 42/64 loss: 0.2498924732208252
Batch 43/64 loss: 0.25751376152038574
Batch 44/64 loss: 0.26936787366867065
Batch 45/64 loss: 0.26320672035217285
Batch 46/64 loss: 0.2584952116012573
Batch 47/64 loss: 0.24918687343597412
Batch 48/64 loss: 0.2559010982513428
Batch 49/64 loss: 0.2554442882537842
Batch 50/64 loss: 0.25875282287597656
Batch 51/64 loss: 0.24972492456436157
Batch 52/64 loss: 0.253345787525177
Batch 53/64 loss: 0.2607162594795227
Batch 54/64 loss: 0.253431499004364
Batch 55/64 loss: 0.24407339096069336
Batch 56/64 loss: 0.2613976001739502
Batch 57/64 loss: 0.2494744062423706
Batch 58/64 loss: 0.24574947357177734
Batch 59/64 loss: 0.2546274662017822
Batch 60/64 loss: 0.2542184591293335
Batch 61/64 loss: 0.2569223642349243
Batch 62/64 loss: 0.26200735569000244
Batch 63/64 loss: 0.25037652254104614
Batch 64/64 loss: 0.2596219778060913
Epoch 149  Train loss: 0.2526447768304862  Val loss: 0.2964636695753668
Epoch 150
-------------------------------
Batch 1/64 loss: 0.2505195140838623
Batch 2/64 loss: 0.26308202743530273
Batch 3/64 loss: 0.2543211579322815
Batch 4/64 loss: 0.25605326890945435
Batch 5/64 loss: 0.2544809579849243
Batch 6/64 loss: 0.24655455350875854
Batch 7/64 loss: 0.24553662538528442
Batch 8/64 loss: 0.2417229413986206
Batch 9/64 loss: 0.25413060188293457
Batch 10/64 loss: 0.2505750060081482
Batch 11/64 loss: 0.2553286552429199
Batch 12/64 loss: 0.25374269485473633
Batch 13/64 loss: 0.24874955415725708
Batch 14/64 loss: 0.25632959604263306
Batch 15/64 loss: 0.26094454526901245
Batch 16/64 loss: 0.24655383825302124
Batch 17/64 loss: 0.25167596340179443
Batch 18/64 loss: 0.25969231128692627
Batch 19/64 loss: 0.2515653371810913
Batch 20/64 loss: 0.24891376495361328
Batch 21/64 loss: 0.2549513578414917
Batch 22/64 loss: 0.26088738441467285
Batch 23/64 loss: 0.25111591815948486
Batch 24/64 loss: 0.2512955665588379
Batch 25/64 loss: 0.2490617036819458
Batch 26/64 loss: 0.25713270902633667
Batch 27/64 loss: 0.2495872974395752
Batch 28/64 loss: 0.25743567943573
Batch 29/64 loss: 0.2488497495651245
Batch 30/64 loss: 0.24582910537719727
Batch 31/64 loss: 0.24746334552764893
Batch 32/64 loss: 0.26195359230041504
Batch 33/64 loss: 0.2515449523925781
Batch 34/64 loss: 0.24610662460327148
Batch 35/64 loss: 0.2579782009124756
Batch 36/64 loss: 0.24873119592666626
Batch 37/64 loss: 0.25389188528060913
Batch 38/64 loss: 0.24695098400115967
Batch 39/64 loss: 0.24703121185302734
Batch 40/64 loss: 0.2515442967414856
Batch 41/64 loss: 0.24841582775115967
Batch 42/64 loss: 0.2495945692062378
Batch 43/64 loss: 0.2709805965423584
Batch 44/64 loss: 0.25423330068588257
Batch 45/64 loss: 0.2544729709625244
Batch 46/64 loss: 0.2575889825820923
Batch 47/64 loss: 0.25046420097351074
Batch 48/64 loss: 0.25487637519836426
Batch 49/64 loss: 0.25259196758270264
Batch 50/64 loss: 0.252774715423584
Batch 51/64 loss: 0.24584662914276123
Batch 52/64 loss: 0.24935829639434814
Batch 53/64 loss: 0.24654138088226318
Batch 54/64 loss: 0.24937152862548828
Batch 55/64 loss: 0.2651470899581909
Batch 56/64 loss: 0.2563857436180115
Batch 57/64 loss: 0.24456554651260376
Batch 58/64 loss: 0.24722546339035034
Batch 59/64 loss: 0.2637077569961548
Batch 60/64 loss: 0.255565881729126
Batch 61/64 loss: 0.24911272525787354
Batch 62/64 loss: 0.2493014931678772
Batch 63/64 loss: 0.25136327743530273
Batch 64/64 loss: 0.25525355339050293
Epoch 150  Train loss: 0.25256066135331695  Val loss: 0.2952628672327782
Epoch 151
-------------------------------
Batch 1/64 loss: 0.242775559425354
Batch 2/64 loss: 0.2488471269607544
Batch 3/64 loss: 0.2656157612800598
Batch 4/64 loss: 0.2621435523033142
Batch 5/64 loss: 0.2562723159790039
Batch 6/64 loss: 0.2429255247116089
Batch 7/64 loss: 0.24906325340270996
Batch 8/64 loss: 0.23698967695236206
Batch 9/64 loss: 0.2560293674468994
Batch 10/64 loss: 0.25342023372650146
Batch 11/64 loss: 0.25779974460601807
Batch 12/64 loss: 0.24341320991516113
Batch 13/64 loss: 0.2557194232940674
Batch 14/64 loss: 0.24708229303359985
Batch 15/64 loss: 0.25501734018325806
Batch 16/64 loss: 0.23856866359710693
Batch 17/64 loss: 0.24546325206756592
Batch 18/64 loss: 0.25518667697906494
Batch 19/64 loss: 0.2469828724861145
Batch 20/64 loss: 0.24590253829956055
Batch 21/64 loss: 0.24719715118408203
Batch 22/64 loss: 0.2610889673233032
Batch 23/64 loss: 0.24911350011825562
Batch 24/64 loss: 0.24924278259277344
Batch 25/64 loss: 0.25147581100463867
Batch 26/64 loss: 0.2620788812637329
Batch 27/64 loss: 0.24747693538665771
Batch 28/64 loss: 0.2531895637512207
Batch 29/64 loss: 0.2516646385192871
Batch 30/64 loss: 0.25298792123794556
Batch 31/64 loss: 0.2449079155921936
Batch 32/64 loss: 0.2541017532348633
Batch 33/64 loss: 0.2548048496246338
Batch 34/64 loss: 0.24411463737487793
Batch 35/64 loss: 0.25877106189727783
Batch 36/64 loss: 0.24186170101165771
Batch 37/64 loss: 0.2507004737854004
Batch 38/64 loss: 0.25481748580932617
Batch 39/64 loss: 0.2470220923423767
Batch 40/64 loss: 0.25534510612487793
Batch 41/64 loss: 0.2576136589050293
Batch 42/64 loss: 0.2462249994277954
Batch 43/64 loss: 0.24924975633621216
Batch 44/64 loss: 0.25277936458587646
Batch 45/64 loss: 0.2462506890296936
Batch 46/64 loss: 0.2456938624382019
Batch 47/64 loss: 0.2505894899368286
Batch 48/64 loss: 0.25170624256134033
Batch 49/64 loss: 0.24589413404464722
Batch 50/64 loss: 0.250219464302063
Batch 51/64 loss: 0.2525590658187866
Batch 52/64 loss: 0.2524075508117676
Batch 53/64 loss: 0.2606407403945923
Batch 54/64 loss: 0.25302553176879883
Batch 55/64 loss: 0.24833452701568604
Batch 56/64 loss: 0.25128114223480225
Batch 57/64 loss: 0.24902379512786865
Batch 58/64 loss: 0.2609788179397583
Batch 59/64 loss: 0.2602130174636841
Batch 60/64 loss: 0.25209784507751465
Batch 61/64 loss: 0.26383060216903687
Batch 62/64 loss: 0.2506362199783325
Batch 63/64 loss: 0.2587776780128479
Batch 64/64 loss: 0.26242709159851074
Epoch 151  Train loss: 0.25167106086132573  Val loss: 0.29656830235445214
Epoch 152
-------------------------------
Batch 1/64 loss: 0.24484384059906006
Batch 2/64 loss: 0.2563357353210449
Batch 3/64 loss: 0.2507248520851135
Batch 4/64 loss: 0.25296032428741455
Batch 5/64 loss: 0.2437644600868225
Batch 6/64 loss: 0.2575453519821167
Batch 7/64 loss: 0.25829267501831055
Batch 8/64 loss: 0.2484731674194336
Batch 9/64 loss: 0.254883348941803
Batch 10/64 loss: 0.2497054934501648
Batch 11/64 loss: 0.24996417760849
Batch 12/64 loss: 0.25078803300857544
Batch 13/64 loss: 0.2388601303100586
Batch 14/64 loss: 0.24453496932983398
Batch 15/64 loss: 0.23598849773406982
Batch 16/64 loss: 0.25849902629852295
Batch 17/64 loss: 0.24470388889312744
Batch 18/64 loss: 0.2508091926574707
Batch 19/64 loss: 0.25126373767852783
Batch 20/64 loss: 0.24390780925750732
Batch 21/64 loss: 0.2514634132385254
Batch 22/64 loss: 0.26328444480895996
Batch 23/64 loss: 0.2500631809234619
Batch 24/64 loss: 0.263036847114563
Batch 25/64 loss: 0.2539180517196655
Batch 26/64 loss: 0.24851572513580322
Batch 27/64 loss: 0.25649452209472656
Batch 28/64 loss: 0.25606071949005127
Batch 29/64 loss: 0.248307466506958
Batch 30/64 loss: 0.26024842262268066
Batch 31/64 loss: 0.24669623374938965
Batch 32/64 loss: 0.25320327281951904
Batch 33/64 loss: 0.24918699264526367
Batch 34/64 loss: 0.2546626329421997
Batch 35/64 loss: 0.2443963885307312
Batch 36/64 loss: 0.24269449710845947
Batch 37/64 loss: 0.24433612823486328
Batch 38/64 loss: 0.2540740370750427
Batch 39/64 loss: 0.25814515352249146
Batch 40/64 loss: 0.2484380006790161
Batch 41/64 loss: 0.24474430084228516
Batch 42/64 loss: 0.25022292137145996
Batch 43/64 loss: 0.24446243047714233
Batch 44/64 loss: 0.2488231658935547
Batch 45/64 loss: 0.2546532154083252
Batch 46/64 loss: 0.2563372850418091
Batch 47/64 loss: 0.24490272998809814
Batch 48/64 loss: 0.25421786308288574
Batch 49/64 loss: 0.26730048656463623
Batch 50/64 loss: 0.2537034749984741
Batch 51/64 loss: 0.26751554012298584
Batch 52/64 loss: 0.24911868572235107
Batch 53/64 loss: 0.26212751865386963
Batch 54/64 loss: 0.24601835012435913
Batch 55/64 loss: 0.2640587091445923
Batch 56/64 loss: 0.24990630149841309
Batch 57/64 loss: 0.24854767322540283
Batch 58/64 loss: 0.25337713956832886
Batch 59/64 loss: 0.24849069118499756
Batch 60/64 loss: 0.2493269443511963
Batch 61/64 loss: 0.25475168228149414
Batch 62/64 loss: 0.24166566133499146
Batch 63/64 loss: 0.2580457925796509
Batch 64/64 loss: 0.2527579665184021
Epoch 152  Train loss: 0.2515445000985089  Val loss: 0.2948620952281755
Saving best model, epoch: 152
Epoch 153
-------------------------------
Batch 1/64 loss: 0.2476605772972107
Batch 2/64 loss: 0.24180513620376587
Batch 3/64 loss: 0.24806946516036987
Batch 4/64 loss: 0.25409388542175293
Batch 5/64 loss: 0.24972081184387207
Batch 6/64 loss: 0.2506074905395508
Batch 7/64 loss: 0.24891448020935059
Batch 8/64 loss: 0.2637779116630554
Batch 9/64 loss: 0.2529507279396057
Batch 10/64 loss: 0.24171757698059082
Batch 11/64 loss: 0.2508540153503418
Batch 12/64 loss: 0.2533590793609619
Batch 13/64 loss: 0.253911554813385
Batch 14/64 loss: 0.2402614951133728
Batch 15/64 loss: 0.2463012933731079
Batch 16/64 loss: 0.2447209358215332
Batch 17/64 loss: 0.2537441849708557
Batch 18/64 loss: 0.25093692541122437
Batch 19/64 loss: 0.2466268539428711
Batch 20/64 loss: 0.24441206455230713
Batch 21/64 loss: 0.2447296380996704
Batch 22/64 loss: 0.25101399421691895
Batch 23/64 loss: 0.24822646379470825
Batch 24/64 loss: 0.25791680812835693
Batch 25/64 loss: 0.25109249353408813
Batch 26/64 loss: 0.23916125297546387
Batch 27/64 loss: 0.2501882314682007
Batch 28/64 loss: 0.2538316249847412
Batch 29/64 loss: 0.24460899829864502
Batch 30/64 loss: 0.24833035469055176
Batch 31/64 loss: 0.24335336685180664
Batch 32/64 loss: 0.25978314876556396
Batch 33/64 loss: 0.24664533138275146
Batch 34/64 loss: 0.2561405897140503
Batch 35/64 loss: 0.2519475221633911
Batch 36/64 loss: 0.24498748779296875
Batch 37/64 loss: 0.25183892250061035
Batch 38/64 loss: 0.2399827241897583
Batch 39/64 loss: 0.248437762260437
Batch 40/64 loss: 0.24613910913467407
Batch 41/64 loss: 0.2458205223083496
Batch 42/64 loss: 0.25470513105392456
Batch 43/64 loss: 0.25014787912368774
Batch 44/64 loss: 0.25434207916259766
Batch 45/64 loss: 0.2623084783554077
Batch 46/64 loss: 0.2489643096923828
Batch 47/64 loss: 0.2506103515625
Batch 48/64 loss: 0.25847339630126953
Batch 49/64 loss: 0.2510506510734558
Batch 50/64 loss: 0.2543279528617859
Batch 51/64 loss: 0.2652626633644104
Batch 52/64 loss: 0.24966037273406982
Batch 53/64 loss: 0.2584937810897827
Batch 54/64 loss: 0.250543475151062
Batch 55/64 loss: 0.2528543472290039
Batch 56/64 loss: 0.2588655352592468
Batch 57/64 loss: 0.2506173849105835
Batch 58/64 loss: 0.25059425830841064
Batch 59/64 loss: 0.25561511516571045
Batch 60/64 loss: 0.25173234939575195
Batch 61/64 loss: 0.2479899525642395
Batch 62/64 loss: 0.249406099319458
Batch 63/64 loss: 0.2500939965248108
Batch 64/64 loss: 0.24383121728897095
Epoch 153  Train loss: 0.25048087508070704  Val loss: 0.29495847593877733
Epoch 154
-------------------------------
Batch 1/64 loss: 0.2475811243057251
Batch 2/64 loss: 0.2621593475341797
Batch 3/64 loss: 0.25663572549819946
Batch 4/64 loss: 0.25512492656707764
Batch 5/64 loss: 0.252755343914032
Batch 6/64 loss: 0.24968385696411133
Batch 7/64 loss: 0.2446708083152771
Batch 8/64 loss: 0.2415095567703247
Batch 9/64 loss: 0.2518754005432129
Batch 10/64 loss: 0.2592017650604248
Batch 11/64 loss: 0.24692589044570923
Batch 12/64 loss: 0.24882560968399048
Batch 13/64 loss: 0.24622207880020142
Batch 14/64 loss: 0.2588402032852173
Batch 15/64 loss: 0.24002546072006226
Batch 16/64 loss: 0.2484215497970581
Batch 17/64 loss: 0.26002663373947144
Batch 18/64 loss: 0.24973005056381226
Batch 19/64 loss: 0.2421749234199524
Batch 20/64 loss: 0.2530737519264221
Batch 21/64 loss: 0.25224143266677856
Batch 22/64 loss: 0.24422061443328857
Batch 23/64 loss: 0.25684523582458496
Batch 24/64 loss: 0.25232207775115967
Batch 25/64 loss: 0.245880126953125
Batch 26/64 loss: 0.25739967823028564
Batch 27/64 loss: 0.24304723739624023
Batch 28/64 loss: 0.2513830065727234
Batch 29/64 loss: 0.24921774864196777
Batch 30/64 loss: 0.2476123571395874
Batch 31/64 loss: 0.24638599157333374
Batch 32/64 loss: 0.25602543354034424
Batch 33/64 loss: 0.25116539001464844
Batch 34/64 loss: 0.25144147872924805
Batch 35/64 loss: 0.2560863494873047
Batch 36/64 loss: 0.25085151195526123
Batch 37/64 loss: 0.24954593181610107
Batch 38/64 loss: 0.24466097354888916
Batch 39/64 loss: 0.24028360843658447
Batch 40/64 loss: 0.26095420122146606
Batch 41/64 loss: 0.25743263959884644
Batch 42/64 loss: 0.2488628625869751
Batch 43/64 loss: 0.24600452184677124
Batch 44/64 loss: 0.25438010692596436
Batch 45/64 loss: 0.25265324115753174
Batch 46/64 loss: 0.2459244728088379
Batch 47/64 loss: 0.2457767128944397
Batch 48/64 loss: 0.25280094146728516
Batch 49/64 loss: 0.24971163272857666
Batch 50/64 loss: 0.256869912147522
Batch 51/64 loss: 0.2556576728820801
Batch 52/64 loss: 0.25212931632995605
Batch 53/64 loss: 0.24949294328689575
Batch 54/64 loss: 0.24315446615219116
Batch 55/64 loss: 0.25272566080093384
Batch 56/64 loss: 0.24637675285339355
Batch 57/64 loss: 0.25400280952453613
Batch 58/64 loss: 0.24616581201553345
Batch 59/64 loss: 0.25559771060943604
Batch 60/64 loss: 0.25686943531036377
Batch 61/64 loss: 0.23893141746520996
Batch 62/64 loss: 0.2576155662536621
Batch 63/64 loss: 0.24976933002471924
Batch 64/64 loss: 0.25474774837493896
Epoch 154  Train loss: 0.2507137434155333  Val loss: 0.29609286539333385
Epoch 155
-------------------------------
Batch 1/64 loss: 0.24518799781799316
Batch 2/64 loss: 0.2425309419631958
Batch 3/64 loss: 0.25249171257019043
Batch 4/64 loss: 0.25372314453125
Batch 5/64 loss: 0.2545624375343323
Batch 6/64 loss: 0.24911046028137207
Batch 7/64 loss: 0.2537817358970642
Batch 8/64 loss: 0.24151623249053955
Batch 9/64 loss: 0.2570366859436035
Batch 10/64 loss: 0.24810636043548584
Batch 11/64 loss: 0.2509949803352356
Batch 12/64 loss: 0.25132471323013306
Batch 13/64 loss: 0.2515185475349426
Batch 14/64 loss: 0.25289666652679443
Batch 15/64 loss: 0.2502479553222656
Batch 16/64 loss: 0.2510859966278076
Batch 17/64 loss: 0.24874436855316162
Batch 18/64 loss: 0.2542094588279724
Batch 19/64 loss: 0.25391221046447754
Batch 20/64 loss: 0.2544292211532593
Batch 21/64 loss: 0.2550976276397705
Batch 22/64 loss: 0.24712038040161133
Batch 23/64 loss: 0.2558831572532654
Batch 24/64 loss: 0.2463005781173706
Batch 25/64 loss: 0.25316810607910156
Batch 26/64 loss: 0.24606990814208984
Batch 27/64 loss: 0.2463201880455017
Batch 28/64 loss: 0.257598876953125
Batch 29/64 loss: 0.24767649173736572
Batch 30/64 loss: 0.23998451232910156
Batch 31/64 loss: 0.2490922212600708
Batch 32/64 loss: 0.24700379371643066
Batch 33/64 loss: 0.24377810955047607
Batch 34/64 loss: 0.24259674549102783
Batch 35/64 loss: 0.25371789932250977
Batch 36/64 loss: 0.2511657476425171
Batch 37/64 loss: 0.24651563167572021
Batch 38/64 loss: 0.24781203269958496
Batch 39/64 loss: 0.24838495254516602
Batch 40/64 loss: 0.24328827857971191
Batch 41/64 loss: 0.23908793926239014
Batch 42/64 loss: 0.25135189294815063
Batch 43/64 loss: 0.25240689516067505
Batch 44/64 loss: 0.24247819185256958
Batch 45/64 loss: 0.2612783908843994
Batch 46/64 loss: 0.24631237983703613
Batch 47/64 loss: 0.25009429454803467
Batch 48/64 loss: 0.24961698055267334
Batch 49/64 loss: 0.2565714120864868
Batch 50/64 loss: 0.24522018432617188
Batch 51/64 loss: 0.24926549196243286
Batch 52/64 loss: 0.250103235244751
Batch 53/64 loss: 0.25711894035339355
Batch 54/64 loss: 0.24521994590759277
Batch 55/64 loss: 0.2521493434906006
Batch 56/64 loss: 0.24773752689361572
Batch 57/64 loss: 0.2553219199180603
Batch 58/64 loss: 0.25538432598114014
Batch 59/64 loss: 0.2502334713935852
Batch 60/64 loss: 0.25169622898101807
Batch 61/64 loss: 0.24605035781860352
Batch 62/64 loss: 0.24291610717773438
Batch 63/64 loss: 0.2582184076309204
Batch 64/64 loss: 0.25711679458618164
Epoch 155  Train loss: 0.24995542788038067  Val loss: 0.294886364559947
Epoch 156
-------------------------------
Batch 1/64 loss: 0.24958568811416626
Batch 2/64 loss: 0.2458362579345703
Batch 3/64 loss: 0.24699097871780396
Batch 4/64 loss: 0.25442826747894287
Batch 5/64 loss: 0.2530851364135742
Batch 6/64 loss: 0.251923143863678
Batch 7/64 loss: 0.24459463357925415
Batch 8/64 loss: 0.2511478662490845
Batch 9/64 loss: 0.24780476093292236
Batch 10/64 loss: 0.2530885934829712
Batch 11/64 loss: 0.24833643436431885
Batch 12/64 loss: 0.24933063983917236
Batch 13/64 loss: 0.25060272216796875
Batch 14/64 loss: 0.2447054386138916
Batch 15/64 loss: 0.25672125816345215
Batch 16/64 loss: 0.24491137266159058
Batch 17/64 loss: 0.25059574842453003
Batch 18/64 loss: 0.2454383373260498
Batch 19/64 loss: 0.24790656566619873
Batch 20/64 loss: 0.24404776096343994
Batch 21/64 loss: 0.24616998434066772
Batch 22/64 loss: 0.2697160840034485
Batch 23/64 loss: 0.24945378303527832
Batch 24/64 loss: 0.24493908882141113
Batch 25/64 loss: 0.2511940002441406
Batch 26/64 loss: 0.25008338689804077
Batch 27/64 loss: 0.25211101770401
Batch 28/64 loss: 0.2509124279022217
Batch 29/64 loss: 0.25586748123168945
Batch 30/64 loss: 0.24364721775054932
Batch 31/64 loss: 0.24179291725158691
Batch 32/64 loss: 0.24776804447174072
Batch 33/64 loss: 0.2517355680465698
Batch 34/64 loss: 0.2612263560295105
Batch 35/64 loss: 0.2573535442352295
Batch 36/64 loss: 0.24424946308135986
Batch 37/64 loss: 0.2513991594314575
Batch 38/64 loss: 0.2539101839065552
Batch 39/64 loss: 0.2414180040359497
Batch 40/64 loss: 0.24272489547729492
Batch 41/64 loss: 0.2449871301651001
Batch 42/64 loss: 0.25409913063049316
Batch 43/64 loss: 0.2429189682006836
Batch 44/64 loss: 0.2557294964790344
Batch 45/64 loss: 0.24974846839904785
Batch 46/64 loss: 0.2511489987373352
Batch 47/64 loss: 0.25054728984832764
Batch 48/64 loss: 0.2620697617530823
Batch 49/64 loss: 0.24056851863861084
Batch 50/64 loss: 0.24425017833709717
Batch 51/64 loss: 0.24488329887390137
Batch 52/64 loss: 0.24154728651046753
Batch 53/64 loss: 0.2608455419540405
Batch 54/64 loss: 0.25600725412368774
Batch 55/64 loss: 0.2492656707763672
Batch 56/64 loss: 0.24915874004364014
Batch 57/64 loss: 0.24492144584655762
Batch 58/64 loss: 0.244293212890625
Batch 59/64 loss: 0.2569425702095032
Batch 60/64 loss: 0.24304699897766113
Batch 61/64 loss: 0.251941978931427
Batch 62/64 loss: 0.23710131645202637
Batch 63/64 loss: 0.25122445821762085
Batch 64/64 loss: 0.2462254762649536
Epoch 156  Train loss: 0.24942229074590347  Val loss: 0.2954548191778439
Epoch 157
-------------------------------
Batch 1/64 loss: 0.25009775161743164
Batch 2/64 loss: 0.25672614574432373
Batch 3/64 loss: 0.24884283542633057
Batch 4/64 loss: 0.24925488233566284
Batch 5/64 loss: 0.24696511030197144
Batch 6/64 loss: 0.26741743087768555
Batch 7/64 loss: 0.2534714937210083
Batch 8/64 loss: 0.2462846040725708
Batch 9/64 loss: 0.23815244436264038
Batch 10/64 loss: 0.24411696195602417
Batch 11/64 loss: 0.25222814083099365
Batch 12/64 loss: 0.2467212677001953
Batch 13/64 loss: 0.25279712677001953
Batch 14/64 loss: 0.24195951223373413
Batch 15/64 loss: 0.24402153491973877
Batch 16/64 loss: 0.24089258909225464
Batch 17/64 loss: 0.2473374605178833
Batch 18/64 loss: 0.25423628091812134
Batch 19/64 loss: 0.24381405115127563
Batch 20/64 loss: 0.25889623165130615
Batch 21/64 loss: 0.25118857622146606
Batch 22/64 loss: 0.2544434666633606
Batch 23/64 loss: 0.2489631175994873
Batch 24/64 loss: 0.24974608421325684
Batch 25/64 loss: 0.2450801134109497
Batch 26/64 loss: 0.25853198766708374
Batch 27/64 loss: 0.25464463233947754
Batch 28/64 loss: 0.2498534917831421
Batch 29/64 loss: 0.24898946285247803
Batch 30/64 loss: 0.25026071071624756
Batch 31/64 loss: 0.24801623821258545
Batch 32/64 loss: 0.254155695438385
Batch 33/64 loss: 0.25069522857666016
Batch 34/64 loss: 0.2414836287498474
Batch 35/64 loss: 0.25259387493133545
Batch 36/64 loss: 0.24372506141662598
Batch 37/64 loss: 0.24948745965957642
Batch 38/64 loss: 0.2486119270324707
Batch 39/64 loss: 0.24566835165023804
Batch 40/64 loss: 0.2602578401565552
Batch 41/64 loss: 0.25311005115509033
Batch 42/64 loss: 0.2526834011077881
Batch 43/64 loss: 0.2511199712753296
Batch 44/64 loss: 0.2450878620147705
Batch 45/64 loss: 0.2504228353500366
Batch 46/64 loss: 0.2561943531036377
Batch 47/64 loss: 0.2517421841621399
Batch 48/64 loss: 0.2531822919845581
Batch 49/64 loss: 0.2510682940483093
Batch 50/64 loss: 0.2671389579772949
Batch 51/64 loss: 0.2533993721008301
Batch 52/64 loss: 0.24893319606781006
Batch 53/64 loss: 0.24468815326690674
Batch 54/64 loss: 0.25394946336746216
Batch 55/64 loss: 0.23740756511688232
Batch 56/64 loss: 0.24202632904052734
Batch 57/64 loss: 0.24306917190551758
Batch 58/64 loss: 0.25187039375305176
Batch 59/64 loss: 0.24421298503875732
Batch 60/64 loss: 0.2474239468574524
Batch 61/64 loss: 0.24558162689208984
Batch 62/64 loss: 0.24816280603408813
Batch 63/64 loss: 0.2393442988395691
Batch 64/64 loss: 0.25247013568878174
Epoch 157  Train loss: 0.24959690851323746  Val loss: 0.2945509808989325
Saving best model, epoch: 157
Epoch 158
-------------------------------
Batch 1/64 loss: 0.2473980188369751
Batch 2/64 loss: 0.25421833992004395
Batch 3/64 loss: 0.25144267082214355
Batch 4/64 loss: 0.243705153465271
Batch 5/64 loss: 0.23951351642608643
Batch 6/64 loss: 0.24832165241241455
Batch 7/64 loss: 0.2623708248138428
Batch 8/64 loss: 0.2463223934173584
Batch 9/64 loss: 0.24796581268310547
Batch 10/64 loss: 0.24690645933151245
Batch 11/64 loss: 0.2509191036224365
Batch 12/64 loss: 0.2474697232246399
Batch 13/64 loss: 0.24225574731826782
Batch 14/64 loss: 0.2426910400390625
Batch 15/64 loss: 0.24538767337799072
Batch 16/64 loss: 0.25142234563827515
Batch 17/64 loss: 0.23643916845321655
Batch 18/64 loss: 0.25112152099609375
Batch 19/64 loss: 0.2430763840675354
Batch 20/64 loss: 0.2524804472923279
Batch 21/64 loss: 0.24654722213745117
Batch 22/64 loss: 0.23945832252502441
Batch 23/64 loss: 0.252138614654541
Batch 24/64 loss: 0.2517213225364685
Batch 25/64 loss: 0.25767403841018677
Batch 26/64 loss: 0.258831262588501
Batch 27/64 loss: 0.2510777711868286
Batch 28/64 loss: 0.24114787578582764
Batch 29/64 loss: 0.2601670026779175
Batch 30/64 loss: 0.25349050760269165
Batch 31/64 loss: 0.24569201469421387
Batch 32/64 loss: 0.2511556148529053
Batch 33/64 loss: 0.24613511562347412
Batch 34/64 loss: 0.24080991744995117
Batch 35/64 loss: 0.2422490119934082
Batch 36/64 loss: 0.24509936571121216
Batch 37/64 loss: 0.2419477105140686
Batch 38/64 loss: 0.2609151005744934
Batch 39/64 loss: 0.25246548652648926
Batch 40/64 loss: 0.24418854713439941
Batch 41/64 loss: 0.24920082092285156
Batch 42/64 loss: 0.25259286165237427
Batch 43/64 loss: 0.2449021339416504
Batch 44/64 loss: 0.26030975580215454
Batch 45/64 loss: 0.2388995885848999
Batch 46/64 loss: 0.2438526153564453
Batch 47/64 loss: 0.23829615116119385
Batch 48/64 loss: 0.24957799911499023
Batch 49/64 loss: 0.2592070698738098
Batch 50/64 loss: 0.24715030193328857
Batch 51/64 loss: 0.24636709690093994
Batch 52/64 loss: 0.258833646774292
Batch 53/64 loss: 0.24779963493347168
Batch 54/64 loss: 0.24833285808563232
Batch 55/64 loss: 0.2458052635192871
Batch 56/64 loss: 0.2522314190864563
Batch 57/64 loss: 0.24617350101470947
Batch 58/64 loss: 0.24883782863616943
Batch 59/64 loss: 0.2545838952064514
Batch 60/64 loss: 0.2549072504043579
Batch 61/64 loss: 0.2481778860092163
Batch 62/64 loss: 0.24555575847625732
Batch 63/64 loss: 0.24812018871307373
Batch 64/64 loss: 0.24654912948608398
Epoch 158  Train loss: 0.248611250110701  Val loss: 0.2961535044142471
Epoch 159
-------------------------------
Batch 1/64 loss: 0.256397545337677
Batch 2/64 loss: 0.23702967166900635
Batch 3/64 loss: 0.24441611766815186
Batch 4/64 loss: 0.2509065866470337
Batch 5/64 loss: 0.2502129077911377
Batch 6/64 loss: 0.2483367919921875
Batch 7/64 loss: 0.23765158653259277
Batch 8/64 loss: 0.2448406219482422
Batch 9/64 loss: 0.24492788314819336
Batch 10/64 loss: 0.2564113736152649
Batch 11/64 loss: 0.25497519969940186
Batch 12/64 loss: 0.2587522268295288
Batch 13/64 loss: 0.25313854217529297
Batch 14/64 loss: 0.24500083923339844
Batch 15/64 loss: 0.2534250020980835
Batch 16/64 loss: 0.24574345350265503
Batch 17/64 loss: 0.25630104541778564
Batch 18/64 loss: 0.2515864968299866
Batch 19/64 loss: 0.24486267566680908
Batch 20/64 loss: 0.24463963508605957
Batch 21/64 loss: 0.23906230926513672
Batch 22/64 loss: 0.245550274848938
Batch 23/64 loss: 0.24659961462020874
Batch 24/64 loss: 0.2554135322570801
Batch 25/64 loss: 0.24817782640457153
Batch 26/64 loss: 0.23965424299240112
Batch 27/64 loss: 0.2463756799697876
Batch 28/64 loss: 0.25421208143234253
Batch 29/64 loss: 0.24484789371490479
Batch 30/64 loss: 0.24128246307373047
Batch 31/64 loss: 0.24106526374816895
Batch 32/64 loss: 0.25483810901641846
Batch 33/64 loss: 0.2492348551750183
Batch 34/64 loss: 0.26319509744644165
Batch 35/64 loss: 0.25029104948043823
Batch 36/64 loss: 0.2499985694885254
Batch 37/64 loss: 0.2376270294189453
Batch 38/64 loss: 0.24510908126831055
Batch 39/64 loss: 0.25650912523269653
Batch 40/64 loss: 0.2486029863357544
Batch 41/64 loss: 0.2531124949455261
Batch 42/64 loss: 0.24747395515441895
Batch 43/64 loss: 0.25213706493377686
Batch 44/64 loss: 0.24439454078674316
Batch 45/64 loss: 0.25927650928497314
Batch 46/64 loss: 0.24142825603485107
Batch 47/64 loss: 0.2475946545600891
Batch 48/64 loss: 0.2432911992073059
Batch 49/64 loss: 0.24578338861465454
Batch 50/64 loss: 0.24999165534973145
Batch 51/64 loss: 0.2507917881011963
Batch 52/64 loss: 0.24075567722320557
Batch 53/64 loss: 0.25102460384368896
Batch 54/64 loss: 0.24401390552520752
Batch 55/64 loss: 0.2481967806816101
Batch 56/64 loss: 0.2576894760131836
Batch 57/64 loss: 0.2488410472869873
Batch 58/64 loss: 0.2422851324081421
Batch 59/64 loss: 0.2460341453552246
Batch 60/64 loss: 0.2609049081802368
Batch 61/64 loss: 0.2547813653945923
Batch 62/64 loss: 0.24685072898864746
Batch 63/64 loss: 0.2521970272064209
Batch 64/64 loss: 0.2531658411026001
Epoch 159  Train loss: 0.24872043880761838  Val loss: 0.2946280345474322
Epoch 160
-------------------------------
Batch 1/64 loss: 0.25197863578796387
Batch 2/64 loss: 0.24408042430877686
Batch 3/64 loss: 0.24764251708984375
Batch 4/64 loss: 0.24981868267059326
Batch 5/64 loss: 0.25216811895370483
Batch 6/64 loss: 0.23909831047058105
Batch 7/64 loss: 0.2542297840118408
Batch 8/64 loss: 0.2545583248138428
Batch 9/64 loss: 0.243554949760437
Batch 10/64 loss: 0.24792110919952393
Batch 11/64 loss: 0.2510106563568115
Batch 12/64 loss: 0.24176442623138428
Batch 13/64 loss: 0.2602689266204834
Batch 14/64 loss: 0.24405276775360107
Batch 15/64 loss: 0.24972325563430786
Batch 16/64 loss: 0.2515209913253784
Batch 17/64 loss: 0.2527121305465698
Batch 18/64 loss: 0.238275945186615
Batch 19/64 loss: 0.2529139518737793
Batch 20/64 loss: 0.2523430585861206
Batch 21/64 loss: 0.24354296922683716
Batch 22/64 loss: 0.24706333875656128
Batch 23/64 loss: 0.25112831592559814
Batch 24/64 loss: 0.24918913841247559
Batch 25/64 loss: 0.2495518922805786
Batch 26/64 loss: 0.24616646766662598
Batch 27/64 loss: 0.2517627477645874
Batch 28/64 loss: 0.24953913688659668
Batch 29/64 loss: 0.25092214345932007
Batch 30/64 loss: 0.24922555685043335
Batch 31/64 loss: 0.23901325464248657
Batch 32/64 loss: 0.24944382905960083
Batch 33/64 loss: 0.2524787187576294
Batch 34/64 loss: 0.24857395887374878
Batch 35/64 loss: 0.2518359422683716
Batch 36/64 loss: 0.25364530086517334
Batch 37/64 loss: 0.24998879432678223
Batch 38/64 loss: 0.24137639999389648
Batch 39/64 loss: 0.23801720142364502
Batch 40/64 loss: 0.24529242515563965
Batch 41/64 loss: 0.2494450807571411
Batch 42/64 loss: 0.24176770448684692
Batch 43/64 loss: 0.24816763401031494
Batch 44/64 loss: 0.25413936376571655
Batch 45/64 loss: 0.2544679641723633
Batch 46/64 loss: 0.24571603536605835
Batch 47/64 loss: 0.24704939126968384
Batch 48/64 loss: 0.24891340732574463
Batch 49/64 loss: 0.24830758571624756
Batch 50/64 loss: 0.24764609336853027
Batch 51/64 loss: 0.25294744968414307
Batch 52/64 loss: 0.249952495098114
Batch 53/64 loss: 0.24911820888519287
Batch 54/64 loss: 0.2473766803741455
Batch 55/64 loss: 0.24901843070983887
Batch 56/64 loss: 0.24631834030151367
Batch 57/64 loss: 0.254016637802124
Batch 58/64 loss: 0.24551773071289062
Batch 59/64 loss: 0.24850863218307495
Batch 60/64 loss: 0.24324548244476318
Batch 61/64 loss: 0.24648088216781616
Batch 62/64 loss: 0.242256760597229
Batch 63/64 loss: 0.2458587884902954
Batch 64/64 loss: 0.25137758255004883
Epoch 160  Train loss: 0.24834767790401682  Val loss: 0.2946857496635201
Epoch 161
-------------------------------
Batch 1/64 loss: 0.26278358697891235
Batch 2/64 loss: 0.25350749492645264
Batch 3/64 loss: 0.2578577399253845
Batch 4/64 loss: 0.2490488886833191
Batch 5/64 loss: 0.24776697158813477
Batch 6/64 loss: 0.25250399112701416
Batch 7/64 loss: 0.25366532802581787
Batch 8/64 loss: 0.24163389205932617
Batch 9/64 loss: 0.2472415566444397
Batch 10/64 loss: 0.24474763870239258
Batch 11/64 loss: 0.2529478073120117
Batch 12/64 loss: 0.2482013702392578
Batch 13/64 loss: 0.25228774547576904
Batch 14/64 loss: 0.25581908226013184
Batch 15/64 loss: 0.24679815769195557
Batch 16/64 loss: 0.24103522300720215
Batch 17/64 loss: 0.24784761667251587
Batch 18/64 loss: 0.23839813470840454
Batch 19/64 loss: 0.24322378635406494
Batch 20/64 loss: 0.238459050655365
Batch 21/64 loss: 0.24841392040252686
Batch 22/64 loss: 0.2424222230911255
Batch 23/64 loss: 0.24438607692718506
Batch 24/64 loss: 0.24781197309494019
Batch 25/64 loss: 0.2528831958770752
Batch 26/64 loss: 0.24365520477294922
Batch 27/64 loss: 0.2463434934616089
Batch 28/64 loss: 0.2513444423675537
Batch 29/64 loss: 0.24946898221969604
Batch 30/64 loss: 0.24972069263458252
Batch 31/64 loss: 0.2390347123146057
Batch 32/64 loss: 0.249592125415802
Batch 33/64 loss: 0.247361421585083
Batch 34/64 loss: 0.2538466453552246
Batch 35/64 loss: 0.24246466159820557
Batch 36/64 loss: 0.24133867025375366
Batch 37/64 loss: 0.24823200702667236
Batch 38/64 loss: 0.24303734302520752
Batch 39/64 loss: 0.24624252319335938
Batch 40/64 loss: 0.255257785320282
Batch 41/64 loss: 0.2548622488975525
Batch 42/64 loss: 0.24542009830474854
Batch 43/64 loss: 0.24598896503448486
Batch 44/64 loss: 0.2511199712753296
Batch 45/64 loss: 0.25374817848205566
Batch 46/64 loss: 0.24651968479156494
Batch 47/64 loss: 0.24523329734802246
Batch 48/64 loss: 0.24412477016448975
Batch 49/64 loss: 0.25273561477661133
Batch 50/64 loss: 0.24431025981903076
Batch 51/64 loss: 0.24907135963439941
Batch 52/64 loss: 0.24657607078552246
Batch 53/64 loss: 0.25405651330947876
Batch 54/64 loss: 0.2387326955795288
Batch 55/64 loss: 0.24252450466156006
Batch 56/64 loss: 0.2486933469772339
Batch 57/64 loss: 0.2591817378997803
Batch 58/64 loss: 0.23815393447875977
Batch 59/64 loss: 0.26265692710876465
Batch 60/64 loss: 0.24492955207824707
Batch 61/64 loss: 0.24847155809402466
Batch 62/64 loss: 0.2557348608970642
Batch 63/64 loss: 0.24374902248382568
Batch 64/64 loss: 0.24326086044311523
Epoch 161  Train loss: 0.24812037617552515  Val loss: 0.2944984433986887
Saving best model, epoch: 161
Epoch 162
-------------------------------
Batch 1/64 loss: 0.2445734739303589
Batch 2/64 loss: 0.2360326051712036
Batch 3/64 loss: 0.24118006229400635
Batch 4/64 loss: 0.2512686252593994
Batch 5/64 loss: 0.2416173219680786
Batch 6/64 loss: 0.23075932264328003
Batch 7/64 loss: 0.24582606554031372
Batch 8/64 loss: 0.2471013069152832
Batch 9/64 loss: 0.25128471851348877
Batch 10/64 loss: 0.24469518661499023
Batch 11/64 loss: 0.24485278129577637
Batch 12/64 loss: 0.2455439567565918
Batch 13/64 loss: 0.2468475103378296
Batch 14/64 loss: 0.2544747591018677
Batch 15/64 loss: 0.2391384243965149
Batch 16/64 loss: 0.24675363302230835
Batch 17/64 loss: 0.24251365661621094
Batch 18/64 loss: 0.2463470697402954
Batch 19/64 loss: 0.24302852153778076
Batch 20/64 loss: 0.24017274379730225
Batch 21/64 loss: 0.25344324111938477
Batch 22/64 loss: 0.2402176856994629
Batch 23/64 loss: 0.23892271518707275
Batch 24/64 loss: 0.24892234802246094
Batch 25/64 loss: 0.25138330459594727
Batch 26/64 loss: 0.2530869245529175
Batch 27/64 loss: 0.2514444589614868
Batch 28/64 loss: 0.2498716115951538
Batch 29/64 loss: 0.240778386592865
Batch 30/64 loss: 0.2527240514755249
Batch 31/64 loss: 0.23946619033813477
Batch 32/64 loss: 0.2520572543144226
Batch 33/64 loss: 0.24584996700286865
Batch 34/64 loss: 0.24794405698776245
Batch 35/64 loss: 0.2474668025970459
Batch 36/64 loss: 0.25455570220947266
Batch 37/64 loss: 0.24734795093536377
Batch 38/64 loss: 0.24951982498168945
Batch 39/64 loss: 0.2510794401168823
Batch 40/64 loss: 0.24510598182678223
Batch 41/64 loss: 0.250014066696167
Batch 42/64 loss: 0.2458789348602295
Batch 43/64 loss: 0.24615371227264404
Batch 44/64 loss: 0.2497636079788208
Batch 45/64 loss: 0.24130511283874512
Batch 46/64 loss: 0.2521483898162842
Batch 47/64 loss: 0.25046253204345703
Batch 48/64 loss: 0.243086040019989
Batch 49/64 loss: 0.2511991262435913
Batch 50/64 loss: 0.2593644857406616
Batch 51/64 loss: 0.2521592378616333
Batch 52/64 loss: 0.25325989723205566
Batch 53/64 loss: 0.2544783353805542
Batch 54/64 loss: 0.2523304224014282
Batch 55/64 loss: 0.2524838447570801
Batch 56/64 loss: 0.24367868900299072
Batch 57/64 loss: 0.24919742345809937
Batch 58/64 loss: 0.25315725803375244
Batch 59/64 loss: 0.24467557668685913
Batch 60/64 loss: 0.242026686668396
Batch 61/64 loss: 0.2501295804977417
Batch 62/64 loss: 0.244101881980896
Batch 63/64 loss: 0.2446659803390503
Batch 64/64 loss: 0.24442356824874878
Epoch 162  Train loss: 0.2471253042127572  Val loss: 0.29550598249402654
Epoch 163
-------------------------------
Batch 1/64 loss: 0.23758602142333984
Batch 2/64 loss: 0.25376957654953003
Batch 3/64 loss: 0.2380751371383667
Batch 4/64 loss: 0.24879074096679688
Batch 5/64 loss: 0.2423195242881775
Batch 6/64 loss: 0.24390363693237305
Batch 7/64 loss: 0.25584185123443604
Batch 8/64 loss: 0.25586360692977905
Batch 9/64 loss: 0.25000643730163574
Batch 10/64 loss: 0.2484452724456787
Batch 11/64 loss: 0.2388860583305359
Batch 12/64 loss: 0.24393796920776367
Batch 13/64 loss: 0.24355852603912354
Batch 14/64 loss: 0.24405694007873535
Batch 15/64 loss: 0.24639904499053955
Batch 16/64 loss: 0.24636119604110718
Batch 17/64 loss: 0.2423895001411438
Batch 18/64 loss: 0.2578998804092407
Batch 19/64 loss: 0.24010711908340454
Batch 20/64 loss: 0.24162131547927856
Batch 21/64 loss: 0.2394695281982422
Batch 22/64 loss: 0.24267947673797607
Batch 23/64 loss: 0.2549896836280823
Batch 24/64 loss: 0.24760526418685913
Batch 25/64 loss: 0.24059730768203735
Batch 26/64 loss: 0.23856407403945923
Batch 27/64 loss: 0.23650765419006348
Batch 28/64 loss: 0.25044989585876465
Batch 29/64 loss: 0.2437383532524109
Batch 30/64 loss: 0.25385987758636475
Batch 31/64 loss: 0.24322938919067383
Batch 32/64 loss: 0.24880516529083252
Batch 33/64 loss: 0.25117814540863037
Batch 34/64 loss: 0.2535189390182495
Batch 35/64 loss: 0.24791359901428223
Batch 36/64 loss: 0.2587660551071167
Batch 37/64 loss: 0.2550891041755676
Batch 38/64 loss: 0.2535518407821655
Batch 39/64 loss: 0.23672175407409668
Batch 40/64 loss: 0.253673791885376
Batch 41/64 loss: 0.25162583589553833
Batch 42/64 loss: 0.23990100622177124
Batch 43/64 loss: 0.2458186149597168
Batch 44/64 loss: 0.2441692352294922
Batch 45/64 loss: 0.2440251111984253
Batch 46/64 loss: 0.2560911178588867
Batch 47/64 loss: 0.24692314863204956
Batch 48/64 loss: 0.24633222818374634
Batch 49/64 loss: 0.25215208530426025
Batch 50/64 loss: 0.24836528301239014
Batch 51/64 loss: 0.24214518070220947
Batch 52/64 loss: 0.24732744693756104
Batch 53/64 loss: 0.25492918491363525
Batch 54/64 loss: 0.2515263557434082
Batch 55/64 loss: 0.2543048858642578
Batch 56/64 loss: 0.24065136909484863
Batch 57/64 loss: 0.2383359670639038
Batch 58/64 loss: 0.24668681621551514
Batch 59/64 loss: 0.24919652938842773
Batch 60/64 loss: 0.25053298473358154
Batch 61/64 loss: 0.23916196823120117
Batch 62/64 loss: 0.25161683559417725
Batch 63/64 loss: 0.25257956981658936
Batch 64/64 loss: 0.24208509922027588
Epoch 163  Train loss: 0.24700691512986725  Val loss: 0.294274637994078
Saving best model, epoch: 163
Epoch 164
-------------------------------
Batch 1/64 loss: 0.23214435577392578
Batch 2/64 loss: 0.2517920732498169
Batch 3/64 loss: 0.2559380531311035
Batch 4/64 loss: 0.2441980242729187
Batch 5/64 loss: 0.24086642265319824
Batch 6/64 loss: 0.25372016429901123
Batch 7/64 loss: 0.24633169174194336
Batch 8/64 loss: 0.24196815490722656
Batch 9/64 loss: 0.24452757835388184
Batch 10/64 loss: 0.2547881603240967
Batch 11/64 loss: 0.23844242095947266
Batch 12/64 loss: 0.23227810859680176
Batch 13/64 loss: 0.25139427185058594
Batch 14/64 loss: 0.24068021774291992
Batch 15/64 loss: 0.2409193515777588
Batch 16/64 loss: 0.24449682235717773
Batch 17/64 loss: 0.25394415855407715
Batch 18/64 loss: 0.2416926622390747
Batch 19/64 loss: 0.24716341495513916
Batch 20/64 loss: 0.23611748218536377
Batch 21/64 loss: 0.2394120693206787
Batch 22/64 loss: 0.23813140392303467
Batch 23/64 loss: 0.2569611072540283
Batch 24/64 loss: 0.24336886405944824
Batch 25/64 loss: 0.2568885087966919
Batch 26/64 loss: 0.2488616704940796
Batch 27/64 loss: 0.24814379215240479
Batch 28/64 loss: 0.2528247833251953
Batch 29/64 loss: 0.23911625146865845
Batch 30/64 loss: 0.2444724440574646
Batch 31/64 loss: 0.2495877742767334
Batch 32/64 loss: 0.24735116958618164
Batch 33/64 loss: 0.24309563636779785
Batch 34/64 loss: 0.24365448951721191
Batch 35/64 loss: 0.24296218156814575
Batch 36/64 loss: 0.2535642385482788
Batch 37/64 loss: 0.24913573265075684
Batch 38/64 loss: 0.24554121494293213
Batch 39/64 loss: 0.2505027651786804
Batch 40/64 loss: 0.24953246116638184
Batch 41/64 loss: 0.24806225299835205
Batch 42/64 loss: 0.24785083532333374
Batch 43/64 loss: 0.2472313642501831
Batch 44/64 loss: 0.2441595196723938
Batch 45/64 loss: 0.2456032633781433
Batch 46/64 loss: 0.2423756718635559
Batch 47/64 loss: 0.2429260015487671
Batch 48/64 loss: 0.24110984802246094
Batch 49/64 loss: 0.24509918689727783
Batch 50/64 loss: 0.2543827295303345
Batch 51/64 loss: 0.2572352886199951
Batch 52/64 loss: 0.24706906080245972
Batch 53/64 loss: 0.24384605884552002
Batch 54/64 loss: 0.24766099452972412
Batch 55/64 loss: 0.25241589546203613
Batch 56/64 loss: 0.2505377531051636
Batch 57/64 loss: 0.24752557277679443
Batch 58/64 loss: 0.24187397956848145
Batch 59/64 loss: 0.25645214319229126
Batch 60/64 loss: 0.25317180156707764
Batch 61/64 loss: 0.238355815410614
Batch 62/64 loss: 0.26497137546539307
Batch 63/64 loss: 0.24994289875030518
Batch 64/64 loss: 0.25688105821609497
Epoch 164  Train loss: 0.24688678044898837  Val loss: 0.2949735897103536
Epoch 165
-------------------------------
Batch 1/64 loss: 0.24964070320129395
Batch 2/64 loss: 0.23772919178009033
Batch 3/64 loss: 0.24216824769973755
Batch 4/64 loss: 0.25241273641586304
Batch 5/64 loss: 0.24300044775009155
Batch 6/64 loss: 0.2508623003959656
Batch 7/64 loss: 0.23882359266281128
Batch 8/64 loss: 0.24286621809005737
Batch 9/64 loss: 0.2463451623916626
Batch 10/64 loss: 0.23870331048965454
Batch 11/64 loss: 0.24990177154541016
Batch 12/64 loss: 0.24769294261932373
Batch 13/64 loss: 0.24484241008758545
Batch 14/64 loss: 0.25819337368011475
Batch 15/64 loss: 0.26136255264282227
Batch 16/64 loss: 0.2395455241203308
Batch 17/64 loss: 0.24604034423828125
Batch 18/64 loss: 0.2509293556213379
Batch 19/64 loss: 0.24756169319152832
Batch 20/64 loss: 0.24446308612823486
Batch 21/64 loss: 0.2535359859466553
Batch 22/64 loss: 0.25124669075012207
Batch 23/64 loss: 0.24542337656021118
Batch 24/64 loss: 0.24894970655441284
Batch 25/64 loss: 0.24884408712387085
Batch 26/64 loss: 0.24634277820587158
Batch 27/64 loss: 0.23959970474243164
Batch 28/64 loss: 0.2371639609336853
Batch 29/64 loss: 0.23615658283233643
Batch 30/64 loss: 0.2552626132965088
Batch 31/64 loss: 0.25987309217453003
Batch 32/64 loss: 0.247597336769104
Batch 33/64 loss: 0.23983442783355713
Batch 34/64 loss: 0.23581111431121826
Batch 35/64 loss: 0.2432330846786499
Batch 36/64 loss: 0.24831509590148926
Batch 37/64 loss: 0.24275147914886475
Batch 38/64 loss: 0.24841463565826416
Batch 39/64 loss: 0.24324870109558105
Batch 40/64 loss: 0.23527169227600098
Batch 41/64 loss: 0.25534164905548096
Batch 42/64 loss: 0.24419093132019043
Batch 43/64 loss: 0.23908758163452148
Batch 44/64 loss: 0.24030262231826782
Batch 45/64 loss: 0.24045664072036743
Batch 46/64 loss: 0.23697906732559204
Batch 47/64 loss: 0.25176703929901123
Batch 48/64 loss: 0.24892795085906982
Batch 49/64 loss: 0.24141955375671387
Batch 50/64 loss: 0.24775159358978271
Batch 51/64 loss: 0.24596703052520752
Batch 52/64 loss: 0.24904489517211914
Batch 53/64 loss: 0.2617771625518799
Batch 54/64 loss: 0.2471003532409668
Batch 55/64 loss: 0.24364399909973145
Batch 56/64 loss: 0.2501525282859802
Batch 57/64 loss: 0.23979365825653076
Batch 58/64 loss: 0.24210667610168457
Batch 59/64 loss: 0.24921494722366333
Batch 60/64 loss: 0.2496352195739746
Batch 61/64 loss: 0.2448561191558838
Batch 62/64 loss: 0.2487812042236328
Batch 63/64 loss: 0.25267261266708374
Batch 64/64 loss: 0.24859404563903809
Epoch 165  Train loss: 0.24623337539972043  Val loss: 0.29509424425891995
Epoch 166
-------------------------------
Batch 1/64 loss: 0.24121785163879395
Batch 2/64 loss: 0.244085431098938
Batch 3/64 loss: 0.2526569366455078
Batch 4/64 loss: 0.244590163230896
Batch 5/64 loss: 0.24436134099960327
Batch 6/64 loss: 0.2555956244468689
Batch 7/64 loss: 0.24468016624450684
Batch 8/64 loss: 0.24099040031433105
Batch 9/64 loss: 0.25176870822906494
Batch 10/64 loss: 0.23739421367645264
Batch 11/64 loss: 0.2505950331687927
Batch 12/64 loss: 0.24620211124420166
Batch 13/64 loss: 0.24560928344726562
Batch 14/64 loss: 0.25009679794311523
Batch 15/64 loss: 0.250002920627594
Batch 16/64 loss: 0.23919713497161865
Batch 17/64 loss: 0.25763005018234253
Batch 18/64 loss: 0.2529263496398926
Batch 19/64 loss: 0.24558401107788086
Batch 20/64 loss: 0.24008691310882568
Batch 21/64 loss: 0.24632525444030762
Batch 22/64 loss: 0.2548867464065552
Batch 23/64 loss: 0.2477947473526001
Batch 24/64 loss: 0.24112367630004883
Batch 25/64 loss: 0.25163567066192627
Batch 26/64 loss: 0.24938815832138062
Batch 27/64 loss: 0.2501765489578247
Batch 28/64 loss: 0.24918925762176514
Batch 29/64 loss: 0.2466583251953125
Batch 30/64 loss: 0.24119389057159424
Batch 31/64 loss: 0.2465754747390747
Batch 32/64 loss: 0.2381516695022583
Batch 33/64 loss: 0.246559739112854
Batch 34/64 loss: 0.2594951391220093
Batch 35/64 loss: 0.24449515342712402
Batch 36/64 loss: 0.23895174264907837
Batch 37/64 loss: 0.2419673204421997
Batch 38/64 loss: 0.24763107299804688
Batch 39/64 loss: 0.2392641305923462
Batch 40/64 loss: 0.24927324056625366
Batch 41/64 loss: 0.2336956262588501
Batch 42/64 loss: 0.2441003918647766
Batch 43/64 loss: 0.24459785223007202
Batch 44/64 loss: 0.24992704391479492
Batch 45/64 loss: 0.2547224760055542
Batch 46/64 loss: 0.24366044998168945
Batch 47/64 loss: 0.262090802192688
Batch 48/64 loss: 0.24105042219161987
Batch 49/64 loss: 0.24973106384277344
Batch 50/64 loss: 0.23795223236083984
Batch 51/64 loss: 0.2389131784439087
Batch 52/64 loss: 0.2430882453918457
Batch 53/64 loss: 0.2480330467224121
Batch 54/64 loss: 0.24031126499176025
Batch 55/64 loss: 0.24550676345825195
Batch 56/64 loss: 0.23801714181900024
Batch 57/64 loss: 0.2466524839401245
Batch 58/64 loss: 0.23646080493927002
Batch 59/64 loss: 0.24020403623580933
Batch 60/64 loss: 0.2559971809387207
Batch 61/64 loss: 0.23831170797348022
Batch 62/64 loss: 0.24123895168304443
Batch 63/64 loss: 0.2523311376571655
Batch 64/64 loss: 0.24303799867630005
Epoch 166  Train loss: 0.24588048948961147  Val loss: 0.29400498617146026
Saving best model, epoch: 166
Epoch 167
-------------------------------
Batch 1/64 loss: 0.2521343231201172
Batch 2/64 loss: 0.2327854037284851
Batch 3/64 loss: 0.2362101674079895
Batch 4/64 loss: 0.23461836576461792
Batch 5/64 loss: 0.2342703938484192
Batch 6/64 loss: 0.24770832061767578
Batch 7/64 loss: 0.24239134788513184
Batch 8/64 loss: 0.24162137508392334
Batch 9/64 loss: 0.23845207691192627
Batch 10/64 loss: 0.2402055263519287
Batch 11/64 loss: 0.23807024955749512
Batch 12/64 loss: 0.24755394458770752
Batch 13/64 loss: 0.24940747022628784
Batch 14/64 loss: 0.24086928367614746
Batch 15/64 loss: 0.24531996250152588
Batch 16/64 loss: 0.23456919193267822
Batch 17/64 loss: 0.2504792809486389
Batch 18/64 loss: 0.263727068901062
Batch 19/64 loss: 0.2515789270401001
Batch 20/64 loss: 0.24228239059448242
Batch 21/64 loss: 0.2502845525741577
Batch 22/64 loss: 0.24412870407104492
Batch 23/64 loss: 0.25177860260009766
Batch 24/64 loss: 0.24719375371932983
Batch 25/64 loss: 0.24705076217651367
Batch 26/64 loss: 0.24985581636428833
Batch 27/64 loss: 0.24664771556854248
Batch 28/64 loss: 0.245191752910614
Batch 29/64 loss: 0.2487316131591797
Batch 30/64 loss: 0.24783748388290405
Batch 31/64 loss: 0.2363327145576477
Batch 32/64 loss: 0.2503109574317932
Batch 33/64 loss: 0.24380135536193848
Batch 34/64 loss: 0.2385462522506714
Batch 35/64 loss: 0.240830659866333
Batch 36/64 loss: 0.2452515959739685
Batch 37/64 loss: 0.24505829811096191
Batch 38/64 loss: 0.2541158199310303
Batch 39/64 loss: 0.25012505054473877
Batch 40/64 loss: 0.2483336329460144
Batch 41/64 loss: 0.24991214275360107
Batch 42/64 loss: 0.24819743633270264
Batch 43/64 loss: 0.24419152736663818
Batch 44/64 loss: 0.23803037405014038
Batch 45/64 loss: 0.24206167459487915
Batch 46/64 loss: 0.2610083818435669
Batch 47/64 loss: 0.23756450414657593
Batch 48/64 loss: 0.2441037893295288
Batch 49/64 loss: 0.2510150671005249
Batch 50/64 loss: 0.24673014879226685
Batch 51/64 loss: 0.24961650371551514
Batch 52/64 loss: 0.24373304843902588
Batch 53/64 loss: 0.23658323287963867
Batch 54/64 loss: 0.24499833583831787
Batch 55/64 loss: 0.2564999461174011
Batch 56/64 loss: 0.24284231662750244
Batch 57/64 loss: 0.23816132545471191
Batch 58/64 loss: 0.24974656105041504
Batch 59/64 loss: 0.24440544843673706
Batch 60/64 loss: 0.24215316772460938
Batch 61/64 loss: 0.2478676438331604
Batch 62/64 loss: 0.24493885040283203
Batch 63/64 loss: 0.24093008041381836
Batch 64/64 loss: 0.24350732564926147
Epoch 167  Train loss: 0.24507583005755557  Val loss: 0.29442575174508634
Epoch 168
-------------------------------
Batch 1/64 loss: 0.2354533076286316
Batch 2/64 loss: 0.23672139644622803
Batch 3/64 loss: 0.23722994327545166
Batch 4/64 loss: 0.24320662021636963
Batch 5/64 loss: 0.23719429969787598
Batch 6/64 loss: 0.23464924097061157
Batch 7/64 loss: 0.24107426404953003
Batch 8/64 loss: 0.2397252917289734
Batch 9/64 loss: 0.24643778800964355
Batch 10/64 loss: 0.23723715543746948
Batch 11/64 loss: 0.25082165002822876
Batch 12/64 loss: 0.24696743488311768
Batch 13/64 loss: 0.2511211633682251
Batch 14/64 loss: 0.24224799871444702
Batch 15/64 loss: 0.24620819091796875
Batch 16/64 loss: 0.2474912405014038
Batch 17/64 loss: 0.2456110715866089
Batch 18/64 loss: 0.23831206560134888
Batch 19/64 loss: 0.2504538297653198
Batch 20/64 loss: 0.24766182899475098
Batch 21/64 loss: 0.24465155601501465
Batch 22/64 loss: 0.2429596185684204
Batch 23/64 loss: 0.2450600266456604
Batch 24/64 loss: 0.24002301692962646
Batch 25/64 loss: 0.24753493070602417
Batch 26/64 loss: 0.23890340328216553
Batch 27/64 loss: 0.23695290088653564
Batch 28/64 loss: 0.25172579288482666
Batch 29/64 loss: 0.24566984176635742
Batch 30/64 loss: 0.24763041734695435
Batch 31/64 loss: 0.24730253219604492
Batch 32/64 loss: 0.2538028359413147
Batch 33/64 loss: 0.2407037615776062
Batch 34/64 loss: 0.24761438369750977
Batch 35/64 loss: 0.24187171459197998
Batch 36/64 loss: 0.24220293760299683
Batch 37/64 loss: 0.2560666799545288
Batch 38/64 loss: 0.24176836013793945
Batch 39/64 loss: 0.25714802742004395
Batch 40/64 loss: 0.24274051189422607
Batch 41/64 loss: 0.24630773067474365
Batch 42/64 loss: 0.2377641797065735
Batch 43/64 loss: 0.24662542343139648
Batch 44/64 loss: 0.23792994022369385
Batch 45/64 loss: 0.24314802885055542
Batch 46/64 loss: 0.23949766159057617
Batch 47/64 loss: 0.24334871768951416
Batch 48/64 loss: 0.2517029047012329
Batch 49/64 loss: 0.2665099501609802
Batch 50/64 loss: 0.252132773399353
Batch 51/64 loss: 0.2480558156967163
Batch 52/64 loss: 0.2523202896118164
Batch 53/64 loss: 0.2413315773010254
Batch 54/64 loss: 0.23935449123382568
Batch 55/64 loss: 0.23985981941223145
Batch 56/64 loss: 0.24561625719070435
Batch 57/64 loss: 0.2363814115524292
Batch 58/64 loss: 0.24257254600524902
Batch 59/64 loss: 0.24212431907653809
Batch 60/64 loss: 0.2563934326171875
Batch 61/64 loss: 0.2469506859779358
Batch 62/64 loss: 0.23997712135314941
Batch 63/64 loss: 0.24584925174713135
Batch 64/64 loss: 0.24063700437545776
Epoch 168  Train loss: 0.2445551547349668  Val loss: 0.2955280581290779
Epoch 169
-------------------------------
Batch 1/64 loss: 0.23973840475082397
Batch 2/64 loss: 0.2575291395187378
Batch 3/64 loss: 0.24314457178115845
Batch 4/64 loss: 0.25086772441864014
Batch 5/64 loss: 0.22916734218597412
Batch 6/64 loss: 0.2382563352584839
Batch 7/64 loss: 0.2401794195175171
Batch 8/64 loss: 0.2436385154724121
Batch 9/64 loss: 0.2442774772644043
Batch 10/64 loss: 0.24953174591064453
Batch 11/64 loss: 0.24021613597869873
Batch 12/64 loss: 0.2486221194267273
Batch 13/64 loss: 0.23597967624664307
Batch 14/64 loss: 0.24954140186309814
Batch 15/64 loss: 0.24968373775482178
Batch 16/64 loss: 0.2391906976699829
Batch 17/64 loss: 0.26001477241516113
Batch 18/64 loss: 0.23480308055877686
Batch 19/64 loss: 0.24131566286087036
Batch 20/64 loss: 0.2487506866455078
Batch 21/64 loss: 0.2520402669906616
Batch 22/64 loss: 0.23928427696228027
Batch 23/64 loss: 0.2474767565727234
Batch 24/64 loss: 0.24226486682891846
Batch 25/64 loss: 0.2453552484512329
Batch 26/64 loss: 0.24705296754837036
Batch 27/64 loss: 0.24462443590164185
Batch 28/64 loss: 0.23687541484832764
Batch 29/64 loss: 0.27130281925201416
Batch 30/64 loss: 0.2609679698944092
Batch 31/64 loss: 0.25184422731399536
Batch 32/64 loss: 0.2388211488723755
Batch 33/64 loss: 0.2462012767791748
Batch 34/64 loss: 0.2459734082221985
Batch 35/64 loss: 0.2362987995147705
Batch 36/64 loss: 0.25186026096343994
Batch 37/64 loss: 0.2385188341140747
Batch 38/64 loss: 0.24833941459655762
Batch 39/64 loss: 0.24340951442718506
Batch 40/64 loss: 0.25052642822265625
Batch 41/64 loss: 0.24252235889434814
Batch 42/64 loss: 0.23361170291900635
Batch 43/64 loss: 0.2629140615463257
Batch 44/64 loss: 0.24014419317245483
Batch 45/64 loss: 0.24651271104812622
Batch 46/64 loss: 0.2435207962989807
Batch 47/64 loss: 0.24232661724090576
Batch 48/64 loss: 0.2488541603088379
Batch 49/64 loss: 0.24140071868896484
Batch 50/64 loss: 0.2418919801712036
Batch 51/64 loss: 0.23851436376571655
Batch 52/64 loss: 0.2393970489501953
Batch 53/64 loss: 0.23935997486114502
Batch 54/64 loss: 0.2507771849632263
Batch 55/64 loss: 0.2411537766456604
Batch 56/64 loss: 0.240206778049469
Batch 57/64 loss: 0.24969178438186646
Batch 58/64 loss: 0.24147248268127441
Batch 59/64 loss: 0.2425994873046875
Batch 60/64 loss: 0.24847781658172607
Batch 61/64 loss: 0.23871135711669922
Batch 62/64 loss: 0.2544023394584656
Batch 63/64 loss: 0.25037652254104614
Batch 64/64 loss: 0.24646830558776855
Epoch 169  Train loss: 0.24513221067540786  Val loss: 0.2944932369022435
Epoch 170
-------------------------------
Batch 1/64 loss: 0.24455958604812622
Batch 2/64 loss: 0.24563872814178467
Batch 3/64 loss: 0.25479722023010254
Batch 4/64 loss: 0.2397822141647339
Batch 5/64 loss: 0.24043333530426025
Batch 6/64 loss: 0.25741612911224365
Batch 7/64 loss: 0.24300384521484375
Batch 8/64 loss: 0.24823492765426636
Batch 9/64 loss: 0.25655078887939453
Batch 10/64 loss: 0.2483736276626587
Batch 11/64 loss: 0.24055814743041992
Batch 12/64 loss: 0.24998342990875244
Batch 13/64 loss: 0.24599069356918335
Batch 14/64 loss: 0.24143147468566895
Batch 15/64 loss: 0.24094635248184204
Batch 16/64 loss: 0.23941034078598022
Batch 17/64 loss: 0.24154698848724365
Batch 18/64 loss: 0.2393290400505066
Batch 19/64 loss: 0.24706828594207764
Batch 20/64 loss: 0.2435627579689026
Batch 21/64 loss: 0.2484220266342163
Batch 22/64 loss: 0.255778968334198
Batch 23/64 loss: 0.24310302734375
Batch 24/64 loss: 0.234683096408844
Batch 25/64 loss: 0.2435392141342163
Batch 26/64 loss: 0.24438047409057617
Batch 27/64 loss: 0.23903393745422363
Batch 28/64 loss: 0.24159586429595947
Batch 29/64 loss: 0.2530953884124756
Batch 30/64 loss: 0.23765802383422852
Batch 31/64 loss: 0.24153995513916016
Batch 32/64 loss: 0.25518035888671875
Batch 33/64 loss: 0.2570011615753174
Batch 34/64 loss: 0.23964428901672363
Batch 35/64 loss: 0.22983413934707642
Batch 36/64 loss: 0.2417725920677185
Batch 37/64 loss: 0.23469746112823486
Batch 38/64 loss: 0.24609416723251343
Batch 39/64 loss: 0.2455640435218811
Batch 40/64 loss: 0.2463180422782898
Batch 41/64 loss: 0.24816489219665527
Batch 42/64 loss: 0.2483670711517334
Batch 43/64 loss: 0.24177658557891846
Batch 44/64 loss: 0.24155187606811523
Batch 45/64 loss: 0.24933159351348877
Batch 46/64 loss: 0.25287294387817383
Batch 47/64 loss: 0.2423715591430664
Batch 48/64 loss: 0.2377796173095703
Batch 49/64 loss: 0.23755210638046265
Batch 50/64 loss: 0.24932849407196045
Batch 51/64 loss: 0.2508648633956909
Batch 52/64 loss: 0.24309927225112915
Batch 53/64 loss: 0.24430125951766968
Batch 54/64 loss: 0.2470763921737671
Batch 55/64 loss: 0.2477567195892334
Batch 56/64 loss: 0.24441492557525635
Batch 57/64 loss: 0.2401798963546753
Batch 58/64 loss: 0.24158984422683716
Batch 59/64 loss: 0.2564784288406372
Batch 60/64 loss: 0.24036270380020142
Batch 61/64 loss: 0.24212205410003662
Batch 62/64 loss: 0.2391272783279419
Batch 63/64 loss: 0.2524101734161377
Batch 64/64 loss: 0.24256396293640137
Epoch 170  Train loss: 0.2448369830262427  Val loss: 0.2947802883652887
Epoch 171
-------------------------------
Batch 1/64 loss: 0.24199843406677246
Batch 2/64 loss: 0.2497342824935913
Batch 3/64 loss: 0.23831379413604736
Batch 4/64 loss: 0.24325931072235107
Batch 5/64 loss: 0.2503706216812134
Batch 6/64 loss: 0.24817359447479248
Batch 7/64 loss: 0.24622690677642822
Batch 8/64 loss: 0.24349427223205566
Batch 9/64 loss: 0.2500233054161072
Batch 10/64 loss: 0.24089133739471436
Batch 11/64 loss: 0.24602460861206055
Batch 12/64 loss: 0.24637937545776367
Batch 13/64 loss: 0.24100160598754883
Batch 14/64 loss: 0.24744510650634766
Batch 15/64 loss: 0.24088627099990845
Batch 16/64 loss: 0.2481553554534912
Batch 17/64 loss: 0.23449468612670898
Batch 18/64 loss: 0.235184907913208
Batch 19/64 loss: 0.24749255180358887
Batch 20/64 loss: 0.23994576930999756
Batch 21/64 loss: 0.2481018304824829
Batch 22/64 loss: 0.2493300437927246
Batch 23/64 loss: 0.2426866888999939
Batch 24/64 loss: 0.24405419826507568
Batch 25/64 loss: 0.2582324147224426
Batch 26/64 loss: 0.24734580516815186
Batch 27/64 loss: 0.24384385347366333
Batch 28/64 loss: 0.24606311321258545
Batch 29/64 loss: 0.23865854740142822
Batch 30/64 loss: 0.23429101705551147
Batch 31/64 loss: 0.24477314949035645
Batch 32/64 loss: 0.24982547760009766
Batch 33/64 loss: 0.23604923486709595
Batch 34/64 loss: 0.2514075040817261
Batch 35/64 loss: 0.24378401041030884
Batch 36/64 loss: 0.23881328105926514
Batch 37/64 loss: 0.2414010763168335
Batch 38/64 loss: 0.2388005256652832
Batch 39/64 loss: 0.243702232837677
Batch 40/64 loss: 0.24733543395996094
Batch 41/64 loss: 0.2434903383255005
Batch 42/64 loss: 0.23803138732910156
Batch 43/64 loss: 0.2594138979911804
Batch 44/64 loss: 0.23983705043792725
Batch 45/64 loss: 0.2529325485229492
Batch 46/64 loss: 0.24912917613983154
Batch 47/64 loss: 0.24147439002990723
Batch 48/64 loss: 0.2502550482749939
Batch 49/64 loss: 0.24021852016448975
Batch 50/64 loss: 0.24342435598373413
Batch 51/64 loss: 0.25003939867019653
Batch 52/64 loss: 0.25220412015914917
Batch 53/64 loss: 0.24642086029052734
Batch 54/64 loss: 0.2428135871887207
Batch 55/64 loss: 0.23746979236602783
Batch 56/64 loss: 0.23821783065795898
Batch 57/64 loss: 0.23998582363128662
Batch 58/64 loss: 0.23505020141601562
Batch 59/64 loss: 0.24319052696228027
Batch 60/64 loss: 0.25467419624328613
Batch 61/64 loss: 0.24385905265808105
Batch 62/64 loss: 0.24347329139709473
Batch 63/64 loss: 0.2554887533187866
Batch 64/64 loss: 0.2464231252670288
Epoch 171  Train loss: 0.2446103063284182  Val loss: 0.2941550843904108
Epoch 172
-------------------------------
Batch 1/64 loss: 0.24929630756378174
Batch 2/64 loss: 0.2416730523109436
Batch 3/64 loss: 0.23857229948043823
Batch 4/64 loss: 0.24397021532058716
Batch 5/64 loss: 0.24525952339172363
Batch 6/64 loss: 0.23846596479415894
Batch 7/64 loss: 0.24519062042236328
Batch 8/64 loss: 0.24720942974090576
Batch 9/64 loss: 0.24637073278427124
Batch 10/64 loss: 0.24506139755249023
Batch 11/64 loss: 0.2430497407913208
Batch 12/64 loss: 0.258817195892334
Batch 13/64 loss: 0.23730337619781494
Batch 14/64 loss: 0.23555278778076172
Batch 15/64 loss: 0.24262070655822754
Batch 16/64 loss: 0.24397587776184082
Batch 17/64 loss: 0.24017632007598877
Batch 18/64 loss: 0.24573779106140137
Batch 19/64 loss: 0.24416935443878174
Batch 20/64 loss: 0.24521613121032715
Batch 21/64 loss: 0.2360600233078003
Batch 22/64 loss: 0.24017351865768433
Batch 23/64 loss: 0.24253588914871216
Batch 24/64 loss: 0.2520022988319397
Batch 25/64 loss: 0.24792957305908203
Batch 26/64 loss: 0.2504720687866211
Batch 27/64 loss: 0.24047982692718506
Batch 28/64 loss: 0.24330395460128784
Batch 29/64 loss: 0.24404162168502808
Batch 30/64 loss: 0.25520920753479004
Batch 31/64 loss: 0.24129998683929443
Batch 32/64 loss: 0.24613380432128906
Batch 33/64 loss: 0.24768376350402832
Batch 34/64 loss: 0.2468475103378296
Batch 35/64 loss: 0.2411900758743286
Batch 36/64 loss: 0.2363520860671997
Batch 37/64 loss: 0.2359461784362793
Batch 38/64 loss: 0.24583196640014648
Batch 39/64 loss: 0.2469097375869751
Batch 40/64 loss: 0.25451719760894775
Batch 41/64 loss: 0.23413610458374023
Batch 42/64 loss: 0.24102270603179932
Batch 43/64 loss: 0.2579428553581238
Batch 44/64 loss: 0.2422635555267334
Batch 45/64 loss: 0.2360866665840149
Batch 46/64 loss: 0.24564653635025024
Batch 47/64 loss: 0.24050605297088623
Batch 48/64 loss: 0.24180126190185547
Batch 49/64 loss: 0.2505761384963989
Batch 50/64 loss: 0.23907947540283203
Batch 51/64 loss: 0.24451005458831787
Batch 52/64 loss: 0.2309260368347168
Batch 53/64 loss: 0.25735998153686523
Batch 54/64 loss: 0.23969656229019165
Batch 55/64 loss: 0.24517488479614258
Batch 56/64 loss: 0.238905668258667
Batch 57/64 loss: 0.24064314365386963
Batch 58/64 loss: 0.24768030643463135
Batch 59/64 loss: 0.2386733889579773
Batch 60/64 loss: 0.23564386367797852
Batch 61/64 loss: 0.25101518630981445
Batch 62/64 loss: 0.23670291900634766
Batch 63/64 loss: 0.25240838527679443
Batch 64/64 loss: 0.24491816759109497
Epoch 172  Train loss: 0.24383842313990872  Val loss: 0.29450824416380156
Epoch 173
-------------------------------
Batch 1/64 loss: 0.23934662342071533
Batch 2/64 loss: 0.24705851078033447
Batch 3/64 loss: 0.2411975860595703
Batch 4/64 loss: 0.23618805408477783
Batch 5/64 loss: 0.2469773292541504
Batch 6/64 loss: 0.24503278732299805
Batch 7/64 loss: 0.24303185939788818
Batch 8/64 loss: 0.24881649017333984
Batch 9/64 loss: 0.24949902296066284
Batch 10/64 loss: 0.23736822605133057
Batch 11/64 loss: 0.24435436725616455
Batch 12/64 loss: 0.24781256914138794
Batch 13/64 loss: 0.24472224712371826
Batch 14/64 loss: 0.24882984161376953
Batch 15/64 loss: 0.23761582374572754
Batch 16/64 loss: 0.23780322074890137
Batch 17/64 loss: 0.24278491735458374
Batch 18/64 loss: 0.2366986870765686
Batch 19/64 loss: 0.24061554670333862
Batch 20/64 loss: 0.24363285303115845
Batch 21/64 loss: 0.23346924781799316
Batch 22/64 loss: 0.23536455631256104
Batch 23/64 loss: 0.2531622052192688
Batch 24/64 loss: 0.2419215440750122
Batch 25/64 loss: 0.24682492017745972
Batch 26/64 loss: 0.2526255249977112
Batch 27/64 loss: 0.2529261112213135
Batch 28/64 loss: 0.23953115940093994
Batch 29/64 loss: 0.24403685331344604
Batch 30/64 loss: 0.24106085300445557
Batch 31/64 loss: 0.24811887741088867
Batch 32/64 loss: 0.2513711452484131
Batch 33/64 loss: 0.2432042360305786
Batch 34/64 loss: 0.23944497108459473
Batch 35/64 loss: 0.24994754791259766
Batch 36/64 loss: 0.24585658311843872
Batch 37/64 loss: 0.24264520406723022
Batch 38/64 loss: 0.24099409580230713
Batch 39/64 loss: 0.2384587526321411
Batch 40/64 loss: 0.24640202522277832
Batch 41/64 loss: 0.24242204427719116
Batch 42/64 loss: 0.23344838619232178
Batch 43/64 loss: 0.2421048879623413
Batch 44/64 loss: 0.2440558671951294
Batch 45/64 loss: 0.24327480792999268
Batch 46/64 loss: 0.24227488040924072
Batch 47/64 loss: 0.24712276458740234
Batch 48/64 loss: 0.24674582481384277
Batch 49/64 loss: 0.24172592163085938
Batch 50/64 loss: 0.24549901485443115
Batch 51/64 loss: 0.24203425645828247
Batch 52/64 loss: 0.23716270923614502
Batch 53/64 loss: 0.26060032844543457
Batch 54/64 loss: 0.2373420000076294
Batch 55/64 loss: 0.25094449520111084
Batch 56/64 loss: 0.24324822425842285
Batch 57/64 loss: 0.24598360061645508
Batch 58/64 loss: 0.2456403374671936
Batch 59/64 loss: 0.24138343334197998
Batch 60/64 loss: 0.24430668354034424
Batch 61/64 loss: 0.24203026294708252
Batch 62/64 loss: 0.23653262853622437
Batch 63/64 loss: 0.23883366584777832
Batch 64/64 loss: 0.24746519327163696
Epoch 173  Train loss: 0.2435618650679495  Val loss: 0.294583865662211
Epoch 174
-------------------------------
Batch 1/64 loss: 0.2425142526626587
Batch 2/64 loss: 0.2415398359298706
Batch 3/64 loss: 0.2371675968170166
Batch 4/64 loss: 0.23070091009140015
Batch 5/64 loss: 0.2387133240699768
Batch 6/64 loss: 0.23549211025238037
Batch 7/64 loss: 0.2447371482849121
Batch 8/64 loss: 0.23741930723190308
Batch 9/64 loss: 0.23857468366622925
Batch 10/64 loss: 0.2462506890296936
Batch 11/64 loss: 0.24028068780899048
Batch 12/64 loss: 0.23409318923950195
Batch 13/64 loss: 0.24606728553771973
Batch 14/64 loss: 0.2464005947113037
Batch 15/64 loss: 0.24327635765075684
Batch 16/64 loss: 0.24662840366363525
Batch 17/64 loss: 0.238944411277771
Batch 18/64 loss: 0.2370705008506775
Batch 19/64 loss: 0.24092304706573486
Batch 20/64 loss: 0.2513752579689026
Batch 21/64 loss: 0.2291039228439331
Batch 22/64 loss: 0.24604833126068115
Batch 23/64 loss: 0.25105440616607666
Batch 24/64 loss: 0.2520540952682495
Batch 25/64 loss: 0.23110604286193848
Batch 26/64 loss: 0.24937188625335693
Batch 27/64 loss: 0.23676133155822754
Batch 28/64 loss: 0.24113953113555908
Batch 29/64 loss: 0.23582875728607178
Batch 30/64 loss: 0.2498873472213745
Batch 31/64 loss: 0.24710530042648315
Batch 32/64 loss: 0.25848472118377686
Batch 33/64 loss: 0.24019187688827515
Batch 34/64 loss: 0.25085723400115967
Batch 35/64 loss: 0.2442038655281067
Batch 36/64 loss: 0.240777850151062
Batch 37/64 loss: 0.24525576829910278
Batch 38/64 loss: 0.24168479442596436
Batch 39/64 loss: 0.23937737941741943
Batch 40/64 loss: 0.2349942922592163
Batch 41/64 loss: 0.23671257495880127
Batch 42/64 loss: 0.24540817737579346
Batch 43/64 loss: 0.2536606788635254
Batch 44/64 loss: 0.24322211742401123
Batch 45/64 loss: 0.251764178276062
Batch 46/64 loss: 0.2503763437271118
Batch 47/64 loss: 0.24056267738342285
Batch 48/64 loss: 0.23828279972076416
Batch 49/64 loss: 0.24775516986846924
Batch 50/64 loss: 0.23565489053726196
Batch 51/64 loss: 0.24465250968933105
Batch 52/64 loss: 0.23946213722229004
Batch 53/64 loss: 0.24445843696594238
Batch 54/64 loss: 0.2473018765449524
Batch 55/64 loss: 0.24920666217803955
Batch 56/64 loss: 0.23542022705078125
Batch 57/64 loss: 0.24078017473220825
Batch 58/64 loss: 0.24137485027313232
Batch 59/64 loss: 0.2399386763572693
Batch 60/64 loss: 0.2420210838317871
Batch 61/64 loss: 0.23902714252471924
Batch 62/64 loss: 0.2395763397216797
Batch 63/64 loss: 0.241510808467865
Batch 64/64 loss: 0.24577486515045166
Epoch 174  Train loss: 0.24244580409106087  Val loss: 0.29398552638148934
Saving best model, epoch: 174
Epoch 175
-------------------------------
Batch 1/64 loss: 0.23802679777145386
Batch 2/64 loss: 0.2455354928970337
Batch 3/64 loss: 0.25264930725097656
Batch 4/64 loss: 0.24570244550704956
Batch 5/64 loss: 0.24505341053009033
Batch 6/64 loss: 0.2421029806137085
Batch 7/64 loss: 0.23285448551177979
Batch 8/64 loss: 0.23272085189819336
Batch 9/64 loss: 0.238258957862854
Batch 10/64 loss: 0.24247288703918457
Batch 11/64 loss: 0.25509506464004517
Batch 12/64 loss: 0.24453520774841309
Batch 13/64 loss: 0.24320274591445923
Batch 14/64 loss: 0.23666822910308838
Batch 15/64 loss: 0.2383623719215393
Batch 16/64 loss: 0.2422724962234497
Batch 17/64 loss: 0.2308627963066101
Batch 18/64 loss: 0.24979323148727417
Batch 19/64 loss: 0.23932135105133057
Batch 20/64 loss: 0.24831271171569824
Batch 21/64 loss: 0.24437958002090454
Batch 22/64 loss: 0.24842488765716553
Batch 23/64 loss: 0.23460114002227783
Batch 24/64 loss: 0.24565446376800537
Batch 25/64 loss: 0.24284225702285767
Batch 26/64 loss: 0.23993384838104248
Batch 27/64 loss: 0.2485257387161255
Batch 28/64 loss: 0.23567438125610352
Batch 29/64 loss: 0.229198157787323
Batch 30/64 loss: 0.24059724807739258
Batch 31/64 loss: 0.23880290985107422
Batch 32/64 loss: 0.23943042755126953
Batch 33/64 loss: 0.2465587854385376
Batch 34/64 loss: 0.25190871953964233
Batch 35/64 loss: 0.2469019889831543
Batch 36/64 loss: 0.2390652894973755
Batch 37/64 loss: 0.24317479133605957
Batch 38/64 loss: 0.23886674642562866
Batch 39/64 loss: 0.23833060264587402
Batch 40/64 loss: 0.23944306373596191
Batch 41/64 loss: 0.2515332102775574
Batch 42/64 loss: 0.24220585823059082
Batch 43/64 loss: 0.24728655815124512
Batch 44/64 loss: 0.23650145530700684
Batch 45/64 loss: 0.2497997283935547
Batch 46/64 loss: 0.24700969457626343
Batch 47/64 loss: 0.23754137754440308
Batch 48/64 loss: 0.2395753264427185
Batch 49/64 loss: 0.23825997114181519
Batch 50/64 loss: 0.24739784002304077
Batch 51/64 loss: 0.23955726623535156
Batch 52/64 loss: 0.24723148345947266
Batch 53/64 loss: 0.24615758657455444
Batch 54/64 loss: 0.23188096284866333
Batch 55/64 loss: 0.2495403289794922
Batch 56/64 loss: 0.23925107717514038
Batch 57/64 loss: 0.24297964572906494
Batch 58/64 loss: 0.23715126514434814
Batch 59/64 loss: 0.23799824714660645
Batch 60/64 loss: 0.24035143852233887
Batch 61/64 loss: 0.23760724067687988
Batch 62/64 loss: 0.2456410527229309
Batch 63/64 loss: 0.24563395977020264
Batch 64/64 loss: 0.2458261251449585
Epoch 175  Train loss: 0.24217381991592107  Val loss: 0.2935721263852726
Saving best model, epoch: 175
Epoch 176
-------------------------------
Batch 1/64 loss: 0.23257267475128174
Batch 2/64 loss: 0.23870849609375
Batch 3/64 loss: 0.24363213777542114
Batch 4/64 loss: 0.23650890588760376
Batch 5/64 loss: 0.23336261510849
Batch 6/64 loss: 0.2378920316696167
Batch 7/64 loss: 0.24451971054077148
Batch 8/64 loss: 0.23958545923233032
Batch 9/64 loss: 0.24051129817962646
Batch 10/64 loss: 0.23193955421447754
Batch 11/64 loss: 0.23261624574661255
Batch 12/64 loss: 0.24758470058441162
Batch 13/64 loss: 0.23182564973831177
Batch 14/64 loss: 0.2324591875076294
Batch 15/64 loss: 0.24139750003814697
Batch 16/64 loss: 0.24792635440826416
Batch 17/64 loss: 0.23866760730743408
Batch 18/64 loss: 0.23939818143844604
Batch 19/64 loss: 0.24244683980941772
Batch 20/64 loss: 0.2405085563659668
Batch 21/64 loss: 0.2483518123626709
Batch 22/64 loss: 0.24610495567321777
Batch 23/64 loss: 0.2427600622177124
Batch 24/64 loss: 0.2346208691596985
Batch 25/64 loss: 0.23775631189346313
Batch 26/64 loss: 0.245192289352417
Batch 27/64 loss: 0.24682462215423584
Batch 28/64 loss: 0.24536871910095215
Batch 29/64 loss: 0.23776352405548096
Batch 30/64 loss: 0.24677056074142456
Batch 31/64 loss: 0.24804282188415527
Batch 32/64 loss: 0.2394418716430664
Batch 33/64 loss: 0.24228686094284058
Batch 34/64 loss: 0.234566330909729
Batch 35/64 loss: 0.23948895931243896
Batch 36/64 loss: 0.23210912942886353
Batch 37/64 loss: 0.24023663997650146
Batch 38/64 loss: 0.2571861743927002
Batch 39/64 loss: 0.25340020656585693
Batch 40/64 loss: 0.24435758590698242
Batch 41/64 loss: 0.237518310546875
Batch 42/64 loss: 0.24678301811218262
Batch 43/64 loss: 0.24828171730041504
Batch 44/64 loss: 0.24810409545898438
Batch 45/64 loss: 0.2387528419494629
Batch 46/64 loss: 0.24506163597106934
Batch 47/64 loss: 0.24656832218170166
Batch 48/64 loss: 0.25092172622680664
Batch 49/64 loss: 0.23861801624298096
Batch 50/64 loss: 0.23342669010162354
Batch 51/64 loss: 0.2480962872505188
Batch 52/64 loss: 0.24978917837142944
Batch 53/64 loss: 0.23522847890853882
Batch 54/64 loss: 0.2455233335494995
Batch 55/64 loss: 0.23801612854003906
Batch 56/64 loss: 0.2336719036102295
Batch 57/64 loss: 0.25128626823425293
Batch 58/64 loss: 0.23545736074447632
Batch 59/64 loss: 0.24263274669647217
Batch 60/64 loss: 0.242684006690979
Batch 61/64 loss: 0.24403220415115356
Batch 62/64 loss: 0.23500418663024902
Batch 63/64 loss: 0.24589502811431885
Batch 64/64 loss: 0.23136889934539795
Epoch 176  Train loss: 0.24143645763397217  Val loss: 0.2943199504282057
Epoch 177
-------------------------------
Batch 1/64 loss: 0.22844266891479492
Batch 2/64 loss: 0.23517310619354248
Batch 3/64 loss: 0.23314601182937622
Batch 4/64 loss: 0.2445976734161377
Batch 5/64 loss: 0.2339450716972351
Batch 6/64 loss: 0.2416626214981079
Batch 7/64 loss: 0.23747289180755615
Batch 8/64 loss: 0.25008994340896606
Batch 9/64 loss: 0.23347055912017822
Batch 10/64 loss: 0.24387890100479126
Batch 11/64 loss: 0.2432544231414795
Batch 12/64 loss: 0.2440885305404663
Batch 13/64 loss: 0.2407926321029663
Batch 14/64 loss: 0.2407599687576294
Batch 15/64 loss: 0.23890554904937744
Batch 16/64 loss: 0.23453623056411743
Batch 17/64 loss: 0.23812448978424072
Batch 18/64 loss: 0.2347019910812378
Batch 19/64 loss: 0.2428046464920044
Batch 20/64 loss: 0.23426282405853271
Batch 21/64 loss: 0.23974531888961792
Batch 22/64 loss: 0.23567736148834229
Batch 23/64 loss: 0.2478020191192627
Batch 24/64 loss: 0.24416697025299072
Batch 25/64 loss: 0.24253827333450317
Batch 26/64 loss: 0.24405300617218018
Batch 27/64 loss: 0.2459086775779724
Batch 28/64 loss: 0.23814797401428223
Batch 29/64 loss: 0.2471994161605835
Batch 30/64 loss: 0.24928683042526245
Batch 31/64 loss: 0.24746978282928467
Batch 32/64 loss: 0.24290990829467773
Batch 33/64 loss: 0.23657512664794922
Batch 34/64 loss: 0.23008006811141968
Batch 35/64 loss: 0.24757134914398193
Batch 36/64 loss: 0.23552167415618896
Batch 37/64 loss: 0.24117439985275269
Batch 38/64 loss: 0.2412034273147583
Batch 39/64 loss: 0.24990570545196533
Batch 40/64 loss: 0.24650084972381592
Batch 41/64 loss: 0.2451077699661255
Batch 42/64 loss: 0.2354525327682495
Batch 43/64 loss: 0.2534788250923157
Batch 44/64 loss: 0.24684321880340576
Batch 45/64 loss: 0.2507054805755615
Batch 46/64 loss: 0.23338115215301514
Batch 47/64 loss: 0.245819091796875
Batch 48/64 loss: 0.2354069948196411
Batch 49/64 loss: 0.23911035060882568
Batch 50/64 loss: 0.23562192916870117
Batch 51/64 loss: 0.2495376467704773
Batch 52/64 loss: 0.24135756492614746
Batch 53/64 loss: 0.24408745765686035
Batch 54/64 loss: 0.23932099342346191
Batch 55/64 loss: 0.2381807565689087
Batch 56/64 loss: 0.24900603294372559
Batch 57/64 loss: 0.24026429653167725
Batch 58/64 loss: 0.24955624341964722
Batch 59/64 loss: 0.2586066722869873
Batch 60/64 loss: 0.2464839220046997
Batch 61/64 loss: 0.24241000413894653
Batch 62/64 loss: 0.23212885856628418
Batch 63/64 loss: 0.23270761966705322
Batch 64/64 loss: 0.24373233318328857
Epoch 177  Train loss: 0.24148899667403279  Val loss: 0.2940999910593852
Epoch 178
-------------------------------
Batch 1/64 loss: 0.23781657218933105
Batch 2/64 loss: 0.24668174982070923
Batch 3/64 loss: 0.24602019786834717
Batch 4/64 loss: 0.2535105347633362
Batch 5/64 loss: 0.2484949827194214
Batch 6/64 loss: 0.23811054229736328
Batch 7/64 loss: 0.24168694019317627
Batch 8/64 loss: 0.24144214391708374
Batch 9/64 loss: 0.23621118068695068
Batch 10/64 loss: 0.23622030019760132
Batch 11/64 loss: 0.23786675930023193
Batch 12/64 loss: 0.24357247352600098
Batch 13/64 loss: 0.24134337902069092
Batch 14/64 loss: 0.2359400987625122
Batch 15/64 loss: 0.24504035711288452
Batch 16/64 loss: 0.2324925661087036
Batch 17/64 loss: 0.24303066730499268
Batch 18/64 loss: 0.2522144317626953
Batch 19/64 loss: 0.243738055229187
Batch 20/64 loss: 0.23470526933670044
Batch 21/64 loss: 0.23738718032836914
Batch 22/64 loss: 0.23236900568008423
Batch 23/64 loss: 0.22993946075439453
Batch 24/64 loss: 0.23576438426971436
Batch 25/64 loss: 0.2429860234260559
Batch 26/64 loss: 0.2475336790084839
Batch 27/64 loss: 0.2501099109649658
Batch 28/64 loss: 0.2421470284461975
Batch 29/64 loss: 0.24273383617401123
Batch 30/64 loss: 0.24271142482757568
Batch 31/64 loss: 0.2425844669342041
Batch 32/64 loss: 0.24230659008026123
Batch 33/64 loss: 0.2407139539718628
Batch 34/64 loss: 0.23791950941085815
Batch 35/64 loss: 0.2460108995437622
Batch 36/64 loss: 0.23771357536315918
Batch 37/64 loss: 0.2460460662841797
Batch 38/64 loss: 0.2317107915878296
Batch 39/64 loss: 0.23365473747253418
Batch 40/64 loss: 0.2403736114501953
Batch 41/64 loss: 0.23969244956970215
Batch 42/64 loss: 0.24145424365997314
Batch 43/64 loss: 0.23944789171218872
Batch 44/64 loss: 0.24203366041183472
Batch 45/64 loss: 0.2495211362838745
Batch 46/64 loss: 0.24383652210235596
Batch 47/64 loss: 0.2433323860168457
Batch 48/64 loss: 0.23923420906066895
Batch 49/64 loss: 0.24392056465148926
Batch 50/64 loss: 0.23984527587890625
Batch 51/64 loss: 0.2411041259765625
Batch 52/64 loss: 0.23950058221817017
Batch 53/64 loss: 0.23751795291900635
Batch 54/64 loss: 0.24004137516021729
Batch 55/64 loss: 0.23975545167922974
Batch 56/64 loss: 0.242095947265625
Batch 57/64 loss: 0.2522020936012268
Batch 58/64 loss: 0.2484683394432068
Batch 59/64 loss: 0.24367570877075195
Batch 60/64 loss: 0.23907649517059326
Batch 61/64 loss: 0.23708754777908325
Batch 62/64 loss: 0.2406536340713501
Batch 63/64 loss: 0.2426760196685791
Batch 64/64 loss: 0.2372514009475708
Epoch 178  Train loss: 0.24130145100986256  Val loss: 0.29407148754473816
Epoch 179
-------------------------------
Batch 1/64 loss: 0.23828542232513428
Batch 2/64 loss: 0.23381924629211426
Batch 3/64 loss: 0.23376065492630005
Batch 4/64 loss: 0.24671030044555664
Batch 5/64 loss: 0.23528242111206055
Batch 6/64 loss: 0.23176991939544678
Batch 7/64 loss: 0.24934154748916626
Batch 8/64 loss: 0.24745666980743408
Batch 9/64 loss: 0.2413855791091919
Batch 10/64 loss: 0.24608862400054932
Batch 11/64 loss: 0.23518377542495728
Batch 12/64 loss: 0.2335718870162964
Batch 13/64 loss: 0.24174845218658447
Batch 14/64 loss: 0.2397952675819397
Batch 15/64 loss: 0.24506127834320068
Batch 16/64 loss: 0.2459348440170288
Batch 17/64 loss: 0.2405080795288086
Batch 18/64 loss: 0.2530208230018616
Batch 19/64 loss: 0.23559939861297607
Batch 20/64 loss: 0.2530345916748047
Batch 21/64 loss: 0.2357153296470642
Batch 22/64 loss: 0.24096143245697021
Batch 23/64 loss: 0.24994778633117676
Batch 24/64 loss: 0.23973143100738525
Batch 25/64 loss: 0.23562347888946533
Batch 26/64 loss: 0.2512497901916504
Batch 27/64 loss: 0.2410663366317749
Batch 28/64 loss: 0.2354743480682373
Batch 29/64 loss: 0.2324904203414917
Batch 30/64 loss: 0.2284889817237854
Batch 31/64 loss: 0.23584145307540894
Batch 32/64 loss: 0.2459447979927063
Batch 33/64 loss: 0.24094748497009277
Batch 34/64 loss: 0.23802268505096436
Batch 35/64 loss: 0.23789000511169434
Batch 36/64 loss: 0.2458152174949646
Batch 37/64 loss: 0.25406694412231445
Batch 38/64 loss: 0.23087352514266968
Batch 39/64 loss: 0.24634051322937012
Batch 40/64 loss: 0.23724132776260376
Batch 41/64 loss: 0.22866040468215942
Batch 42/64 loss: 0.23431503772735596
Batch 43/64 loss: 0.25121480226516724
Batch 44/64 loss: 0.2388317584991455
Batch 45/64 loss: 0.24328690767288208
Batch 46/64 loss: 0.24383103847503662
Batch 47/64 loss: 0.242343008518219
Batch 48/64 loss: 0.23985540866851807
Batch 49/64 loss: 0.24289679527282715
Batch 50/64 loss: 0.2472468614578247
Batch 51/64 loss: 0.23962372541427612
Batch 52/64 loss: 0.25062310695648193
Batch 53/64 loss: 0.2556161880493164
Batch 54/64 loss: 0.24810749292373657
Batch 55/64 loss: 0.24819409847259521
Batch 56/64 loss: 0.236261248588562
Batch 57/64 loss: 0.2515733242034912
Batch 58/64 loss: 0.24358761310577393
Batch 59/64 loss: 0.24825751781463623
Batch 60/64 loss: 0.2424352765083313
Batch 61/64 loss: 0.24025499820709229
Batch 62/64 loss: 0.2383512258529663
Batch 63/64 loss: 0.24770379066467285
Batch 64/64 loss: 0.23868858814239502
Epoch 179  Train loss: 0.24177537478652655  Val loss: 0.29418296646006736
Epoch 180
-------------------------------
Batch 1/64 loss: 0.24041712284088135
Batch 2/64 loss: 0.24007517099380493
Batch 3/64 loss: 0.24903470277786255
Batch 4/64 loss: 0.24513888359069824
Batch 5/64 loss: 0.23846971988677979
Batch 6/64 loss: 0.2321513295173645
Batch 7/64 loss: 0.2359246015548706
Batch 8/64 loss: 0.239280104637146
Batch 9/64 loss: 0.23228132724761963
Batch 10/64 loss: 0.24762189388275146
Batch 11/64 loss: 0.23335671424865723
Batch 12/64 loss: 0.24167031049728394
Batch 13/64 loss: 0.23540258407592773
Batch 14/64 loss: 0.24135661125183105
Batch 15/64 loss: 0.23958426713943481
Batch 16/64 loss: 0.2364492416381836
Batch 17/64 loss: 0.24395430088043213
Batch 18/64 loss: 0.23649966716766357
Batch 19/64 loss: 0.23193144798278809
Batch 20/64 loss: 0.24602866172790527
Batch 21/64 loss: 0.24511855840682983
Batch 22/64 loss: 0.23227018117904663
Batch 23/64 loss: 0.24016374349594116
Batch 24/64 loss: 0.23905277252197266
Batch 25/64 loss: 0.24702370166778564
Batch 26/64 loss: 0.23445087671279907
Batch 27/64 loss: 0.236594557762146
Batch 28/64 loss: 0.24499088525772095
Batch 29/64 loss: 0.23903048038482666
Batch 30/64 loss: 0.2364734411239624
Batch 31/64 loss: 0.24455046653747559
Batch 32/64 loss: 0.23257440328598022
Batch 33/64 loss: 0.24528652429580688
Batch 34/64 loss: 0.23332202434539795
Batch 35/64 loss: 0.23471492528915405
Batch 36/64 loss: 0.2426208257675171
Batch 37/64 loss: 0.241074800491333
Batch 38/64 loss: 0.24236607551574707
Batch 39/64 loss: 0.23567616939544678
Batch 40/64 loss: 0.23816728591918945
Batch 41/64 loss: 0.23689550161361694
Batch 42/64 loss: 0.24950289726257324
Batch 43/64 loss: 0.2381143569946289
Batch 44/64 loss: 0.2355184555053711
Batch 45/64 loss: 0.24738669395446777
Batch 46/64 loss: 0.25039350986480713
Batch 47/64 loss: 0.24114227294921875
Batch 48/64 loss: 0.2548043727874756
Batch 49/64 loss: 0.2388216257095337
Batch 50/64 loss: 0.23254632949829102
Batch 51/64 loss: 0.24148297309875488
Batch 52/64 loss: 0.2400299310684204
Batch 53/64 loss: 0.23587417602539062
Batch 54/64 loss: 0.2492685317993164
Batch 55/64 loss: 0.2415541410446167
Batch 56/64 loss: 0.25267207622528076
Batch 57/64 loss: 0.2365208864212036
Batch 58/64 loss: 0.24027276039123535
Batch 59/64 loss: 0.254178524017334
Batch 60/64 loss: 0.2506263256072998
Batch 61/64 loss: 0.24149227142333984
Batch 62/64 loss: 0.24619150161743164
Batch 63/64 loss: 0.23427915573120117
Batch 64/64 loss: 0.24405837059020996
Epoch 180  Train loss: 0.2407021868462656  Val loss: 0.29425640265966196
Epoch 181
-------------------------------
Batch 1/64 loss: 0.23592710494995117
Batch 2/64 loss: 0.2514271140098572
Batch 3/64 loss: 0.23880022764205933
Batch 4/64 loss: 0.2410651445388794
Batch 5/64 loss: 0.24736464023590088
Batch 6/64 loss: 0.23082226514816284
Batch 7/64 loss: 0.23468834161758423
Batch 8/64 loss: 0.23889213800430298
Batch 9/64 loss: 0.2341768741607666
Batch 10/64 loss: 0.2320336103439331
Batch 11/64 loss: 0.24471580982208252
Batch 12/64 loss: 0.24816954135894775
Batch 13/64 loss: 0.24276715517044067
Batch 14/64 loss: 0.243233323097229
Batch 15/64 loss: 0.247697114944458
Batch 16/64 loss: 0.2424607276916504
Batch 17/64 loss: 0.23841285705566406
Batch 18/64 loss: 0.237199068069458
Batch 19/64 loss: 0.24268388748168945
Batch 20/64 loss: 0.23643910884857178
Batch 21/64 loss: 0.2347337007522583
Batch 22/64 loss: 0.24644804000854492
Batch 23/64 loss: 0.2360248565673828
Batch 24/64 loss: 0.24612826108932495
Batch 25/64 loss: 0.23073625564575195
Batch 26/64 loss: 0.2398233413696289
Batch 27/64 loss: 0.23653888702392578
Batch 28/64 loss: 0.2389380931854248
Batch 29/64 loss: 0.23862963914871216
Batch 30/64 loss: 0.24660611152648926
Batch 31/64 loss: 0.24403983354568481
Batch 32/64 loss: 0.2431246042251587
Batch 33/64 loss: 0.23315244913101196
Batch 34/64 loss: 0.24246788024902344
Batch 35/64 loss: 0.23519295454025269
Batch 36/64 loss: 0.2377614974975586
Batch 37/64 loss: 0.24488747119903564
Batch 38/64 loss: 0.24466627836227417
Batch 39/64 loss: 0.23545414209365845
Batch 40/64 loss: 0.24988895654678345
Batch 41/64 loss: 0.24288570880889893
Batch 42/64 loss: 0.24193596839904785
Batch 43/64 loss: 0.2388911247253418
Batch 44/64 loss: 0.24492883682250977
Batch 45/64 loss: 0.24766021966934204
Batch 46/64 loss: 0.2463693618774414
Batch 47/64 loss: 0.23987942934036255
Batch 48/64 loss: 0.2342877984046936
Batch 49/64 loss: 0.23376858234405518
Batch 50/64 loss: 0.24612140655517578
Batch 51/64 loss: 0.23758792877197266
Batch 52/64 loss: 0.2463686466217041
Batch 53/64 loss: 0.2514171600341797
Batch 54/64 loss: 0.24124449491500854
Batch 55/64 loss: 0.23841077089309692
Batch 56/64 loss: 0.24344885349273682
Batch 57/64 loss: 0.24748343229293823
Batch 58/64 loss: 0.2511402368545532
Batch 59/64 loss: 0.2435678243637085
Batch 60/64 loss: 0.24111193418502808
Batch 61/64 loss: 0.23201775550842285
Batch 62/64 loss: 0.2415693998336792
Batch 63/64 loss: 0.2549276351928711
Batch 64/64 loss: 0.24179720878601074
Epoch 181  Train loss: 0.24129555646110984  Val loss: 0.2949794326041572
Epoch 182
-------------------------------
Batch 1/64 loss: 0.23546791076660156
Batch 2/64 loss: 0.23113608360290527
Batch 3/64 loss: 0.2469346523284912
Batch 4/64 loss: 0.24484682083129883
Batch 5/64 loss: 0.24837887287139893
Batch 6/64 loss: 0.24042487144470215
Batch 7/64 loss: 0.23309326171875
Batch 8/64 loss: 0.24566185474395752
Batch 9/64 loss: 0.24666213989257812
Batch 10/64 loss: 0.23030245304107666
Batch 11/64 loss: 0.232940673828125
Batch 12/64 loss: 0.23210179805755615
Batch 13/64 loss: 0.24985253810882568
Batch 14/64 loss: 0.2454860806465149
Batch 15/64 loss: 0.2429126501083374
Batch 16/64 loss: 0.23318380117416382
Batch 17/64 loss: 0.23364436626434326
Batch 18/64 loss: 0.24053925275802612
Batch 19/64 loss: 0.2438310980796814
Batch 20/64 loss: 0.24003106355667114
Batch 21/64 loss: 0.24131572246551514
Batch 22/64 loss: 0.2520209550857544
Batch 23/64 loss: 0.24210822582244873
Batch 24/64 loss: 0.24062269926071167
Batch 25/64 loss: 0.24766838550567627
Batch 26/64 loss: 0.23745691776275635
Batch 27/64 loss: 0.2340596318244934
Batch 28/64 loss: 0.25592321157455444
Batch 29/64 loss: 0.23310726881027222
Batch 30/64 loss: 0.24030447006225586
Batch 31/64 loss: 0.23730158805847168
Batch 32/64 loss: 0.24965399503707886
Batch 33/64 loss: 0.2334638237953186
Batch 34/64 loss: 0.22734206914901733
Batch 35/64 loss: 0.2320777177810669
Batch 36/64 loss: 0.24064290523529053
Batch 37/64 loss: 0.24721550941467285
Batch 38/64 loss: 0.25222015380859375
Batch 39/64 loss: 0.23088914155960083
Batch 40/64 loss: 0.23782533407211304
Batch 41/64 loss: 0.25370538234710693
Batch 42/64 loss: 0.23812156915664673
Batch 43/64 loss: 0.23917388916015625
Batch 44/64 loss: 0.23857581615447998
Batch 45/64 loss: 0.24636828899383545
Batch 46/64 loss: 0.24174726009368896
Batch 47/64 loss: 0.24003726243972778
Batch 48/64 loss: 0.23876333236694336
Batch 49/64 loss: 0.23371624946594238
Batch 50/64 loss: 0.22993707656860352
Batch 51/64 loss: 0.23563247919082642
Batch 52/64 loss: 0.2330576777458191
Batch 53/64 loss: 0.2450326681137085
Batch 54/64 loss: 0.24041521549224854
Batch 55/64 loss: 0.2396618127822876
Batch 56/64 loss: 0.23308318853378296
Batch 57/64 loss: 0.25756126642227173
Batch 58/64 loss: 0.242720365524292
Batch 59/64 loss: 0.2483397126197815
Batch 60/64 loss: 0.23626303672790527
Batch 61/64 loss: 0.2487959861755371
Batch 62/64 loss: 0.2386680245399475
Batch 63/64 loss: 0.24106121063232422
Batch 64/64 loss: 0.24369215965270996
Epoch 182  Train loss: 0.2405311350728951  Val loss: 0.29498471836863516
Epoch 183
-------------------------------
Batch 1/64 loss: 0.23161667585372925
Batch 2/64 loss: 0.23383867740631104
Batch 3/64 loss: 0.23176896572113037
Batch 4/64 loss: 0.24202817678451538
Batch 5/64 loss: 0.24093890190124512
Batch 6/64 loss: 0.2528855800628662
Batch 7/64 loss: 0.23837649822235107
Batch 8/64 loss: 0.23703926801681519
Batch 9/64 loss: 0.24543744325637817
Batch 10/64 loss: 0.2348266839981079
Batch 11/64 loss: 0.24102479219436646
Batch 12/64 loss: 0.22971785068511963
Batch 13/64 loss: 0.24284785985946655
Batch 14/64 loss: 0.23046791553497314
Batch 15/64 loss: 0.23625445365905762
Batch 16/64 loss: 0.25231003761291504
Batch 17/64 loss: 0.23815035820007324
Batch 18/64 loss: 0.22911536693572998
Batch 19/64 loss: 0.24145030975341797
Batch 20/64 loss: 0.23773062229156494
Batch 21/64 loss: 0.2541065216064453
Batch 22/64 loss: 0.23577332496643066
Batch 23/64 loss: 0.24645674228668213
Batch 24/64 loss: 0.24126708507537842
Batch 25/64 loss: 0.23547637462615967
Batch 26/64 loss: 0.2418203353881836
Batch 27/64 loss: 0.24122732877731323
Batch 28/64 loss: 0.2489711046218872
Batch 29/64 loss: 0.2527562379837036
Batch 30/64 loss: 0.2370225191116333
Batch 31/64 loss: 0.24188470840454102
Batch 32/64 loss: 0.23363900184631348
Batch 33/64 loss: 0.24496114253997803
Batch 34/64 loss: 0.2488316297531128
Batch 35/64 loss: 0.24063539505004883
Batch 36/64 loss: 0.23233431577682495
Batch 37/64 loss: 0.24385011196136475
Batch 38/64 loss: 0.2396479845046997
Batch 39/64 loss: 0.23346000909805298
Batch 40/64 loss: 0.24192345142364502
Batch 41/64 loss: 0.23405039310455322
Batch 42/64 loss: 0.23505699634552002
Batch 43/64 loss: 0.24352067708969116
Batch 44/64 loss: 0.24677705764770508
Batch 45/64 loss: 0.24181389808654785
Batch 46/64 loss: 0.24980807304382324
Batch 47/64 loss: 0.23509883880615234
Batch 48/64 loss: 0.23874503374099731
Batch 49/64 loss: 0.24200868606567383
Batch 50/64 loss: 0.24163001775741577
Batch 51/64 loss: 0.24216455221176147
Batch 52/64 loss: 0.24372351169586182
Batch 53/64 loss: 0.24395722150802612
Batch 54/64 loss: 0.2275451421737671
Batch 55/64 loss: 0.2273317575454712
Batch 56/64 loss: 0.24895048141479492
Batch 57/64 loss: 0.23626983165740967
Batch 58/64 loss: 0.24102342128753662
Batch 59/64 loss: 0.24399685859680176
Batch 60/64 loss: 0.24126064777374268
Batch 61/64 loss: 0.24940454959869385
Batch 62/64 loss: 0.23467564582824707
Batch 63/64 loss: 0.2475348711013794
Batch 64/64 loss: 0.24422580003738403
Epoch 183  Train loss: 0.2403668906174454  Val loss: 0.29498371062000184
Epoch 184
-------------------------------
Batch 1/64 loss: 0.24335944652557373
Batch 2/64 loss: 0.24125820398330688
Batch 3/64 loss: 0.24367189407348633
Batch 4/64 loss: 0.2463587522506714
Batch 5/64 loss: 0.2327355146408081
Batch 6/64 loss: 0.24653911590576172
Batch 7/64 loss: 0.23567557334899902
Batch 8/64 loss: 0.24460768699645996
Batch 9/64 loss: 0.24850237369537354
Batch 10/64 loss: 0.23533320426940918
Batch 11/64 loss: 0.23966479301452637
Batch 12/64 loss: 0.25128912925720215
Batch 13/64 loss: 0.2462366819381714
Batch 14/64 loss: 0.2398386001586914
Batch 15/64 loss: 0.24833858013153076
Batch 16/64 loss: 0.23785936832427979
Batch 17/64 loss: 0.23748773336410522
Batch 18/64 loss: 0.2339184284210205
Batch 19/64 loss: 0.24889707565307617
Batch 20/64 loss: 0.23613053560256958
Batch 21/64 loss: 0.24888014793395996
Batch 22/64 loss: 0.248742938041687
Batch 23/64 loss: 0.23557424545288086
Batch 24/64 loss: 0.24333131313323975
Batch 25/64 loss: 0.24143004417419434
Batch 26/64 loss: 0.23674315214157104
Batch 27/64 loss: 0.23512327671051025
Batch 28/64 loss: 0.24373042583465576
Batch 29/64 loss: 0.23551243543624878
Batch 30/64 loss: 0.24245870113372803
Batch 31/64 loss: 0.2307826280593872
Batch 32/64 loss: 0.2366456389427185
Batch 33/64 loss: 0.2331240177154541
Batch 34/64 loss: 0.23384714126586914
Batch 35/64 loss: 0.24687910079956055
Batch 36/64 loss: 0.23691916465759277
Batch 37/64 loss: 0.24028503894805908
Batch 38/64 loss: 0.2395891547203064
Batch 39/64 loss: 0.2523959279060364
Batch 40/64 loss: 0.244273841381073
Batch 41/64 loss: 0.23199832439422607
Batch 42/64 loss: 0.24337482452392578
Batch 43/64 loss: 0.2360762357711792
Batch 44/64 loss: 0.23812061548233032
Batch 45/64 loss: 0.2388368844985962
Batch 46/64 loss: 0.23710763454437256
Batch 47/64 loss: 0.23040270805358887
Batch 48/64 loss: 0.2421191930770874
Batch 49/64 loss: 0.23212683200836182
Batch 50/64 loss: 0.23614072799682617
Batch 51/64 loss: 0.24123167991638184
Batch 52/64 loss: 0.24521023035049438
Batch 53/64 loss: 0.2333822250366211
Batch 54/64 loss: 0.24696767330169678
Batch 55/64 loss: 0.24817991256713867
Batch 56/64 loss: 0.23364877700805664
Batch 57/64 loss: 0.24008870124816895
Batch 58/64 loss: 0.2396748661994934
Batch 59/64 loss: 0.23516476154327393
Batch 60/64 loss: 0.2400839924812317
Batch 61/64 loss: 0.2454150915145874
Batch 62/64 loss: 0.2321251630783081
Batch 63/64 loss: 0.24429106712341309
Batch 64/64 loss: 0.2345905303955078
Epoch 184  Train loss: 0.2401832477719176  Val loss: 0.29414934042802793
Epoch 185
-------------------------------
Batch 1/64 loss: 0.24669361114501953
Batch 2/64 loss: 0.2288060188293457
Batch 3/64 loss: 0.23946213722229004
Batch 4/64 loss: 0.24670004844665527
Batch 5/64 loss: 0.24152064323425293
Batch 6/64 loss: 0.2395777702331543
Batch 7/64 loss: 0.2354273796081543
Batch 8/64 loss: 0.23037457466125488
Batch 9/64 loss: 0.23665666580200195
Batch 10/64 loss: 0.24392235279083252
Batch 11/64 loss: 0.2401658296585083
Batch 12/64 loss: 0.23825585842132568
Batch 13/64 loss: 0.23712515830993652
Batch 14/64 loss: 0.2303401231765747
Batch 15/64 loss: 0.2363133430480957
Batch 16/64 loss: 0.23787611722946167
Batch 17/64 loss: 0.2394312620162964
Batch 18/64 loss: 0.24158978462219238
Batch 19/64 loss: 0.2299267053604126
Batch 20/64 loss: 0.23127871751785278
Batch 21/64 loss: 0.24102634191513062
Batch 22/64 loss: 0.24057167768478394
Batch 23/64 loss: 0.236469566822052
Batch 24/64 loss: 0.23640167713165283
Batch 25/64 loss: 0.24737048149108887
Batch 26/64 loss: 0.2465001344680786
Batch 27/64 loss: 0.2521783113479614
Batch 28/64 loss: 0.24916958808898926
Batch 29/64 loss: 0.2444515824317932
Batch 30/64 loss: 0.24109947681427002
Batch 31/64 loss: 0.2416003942489624
Batch 32/64 loss: 0.243369460105896
Batch 33/64 loss: 0.23707330226898193
Batch 34/64 loss: 0.2365121841430664
Batch 35/64 loss: 0.25266826152801514
Batch 36/64 loss: 0.23797965049743652
Batch 37/64 loss: 0.2389073371887207
Batch 38/64 loss: 0.2525143623352051
Batch 39/64 loss: 0.23132765293121338
Batch 40/64 loss: 0.2312791347503662
Batch 41/64 loss: 0.25081461668014526
Batch 42/64 loss: 0.22711622714996338
Batch 43/64 loss: 0.24330508708953857
Batch 44/64 loss: 0.23601895570755005
Batch 45/64 loss: 0.2411171793937683
Batch 46/64 loss: 0.2630563974380493
Batch 47/64 loss: 0.23727095127105713
Batch 48/64 loss: 0.2412990927696228
Batch 49/64 loss: 0.23493468761444092
Batch 50/64 loss: 0.23162829875946045
Batch 51/64 loss: 0.23507177829742432
Batch 52/64 loss: 0.2379845380783081
Batch 53/64 loss: 0.23720484972000122
Batch 54/64 loss: 0.23313909769058228
Batch 55/64 loss: 0.2449561357498169
Batch 56/64 loss: 0.24710869789123535
Batch 57/64 loss: 0.2377679944038391
Batch 58/64 loss: 0.2510029077529907
Batch 59/64 loss: 0.23832249641418457
Batch 60/64 loss: 0.24887752532958984
Batch 61/64 loss: 0.24425679445266724
Batch 62/64 loss: 0.24098080396652222
Batch 63/64 loss: 0.22655892372131348
Batch 64/64 loss: 0.2344987392425537
Epoch 185  Train loss: 0.23993071013805914  Val loss: 0.2943975759535721
Epoch 186
-------------------------------
Batch 1/64 loss: 0.2537806034088135
Batch 2/64 loss: 0.2392059564590454
Batch 3/64 loss: 0.23471015691757202
Batch 4/64 loss: 0.2341364622116089
Batch 5/64 loss: 0.2381124496459961
Batch 6/64 loss: 0.23564696311950684
Batch 7/64 loss: 0.23646044731140137
Batch 8/64 loss: 0.2323673963546753
Batch 9/64 loss: 0.25330281257629395
Batch 10/64 loss: 0.24392884969711304
Batch 11/64 loss: 0.23668313026428223
Batch 12/64 loss: 0.23403286933898926
Batch 13/64 loss: 0.23731470108032227
Batch 14/64 loss: 0.23884105682373047
Batch 15/64 loss: 0.23024392127990723
Batch 16/64 loss: 0.2370474934577942
Batch 17/64 loss: 0.23780059814453125
Batch 18/64 loss: 0.2513611316680908
Batch 19/64 loss: 0.23585784435272217
Batch 20/64 loss: 0.24288105964660645
Batch 21/64 loss: 0.241058349609375
Batch 22/64 loss: 0.22847825288772583
Batch 23/64 loss: 0.23553192615509033
Batch 24/64 loss: 0.23232680559158325
Batch 25/64 loss: 0.24532437324523926
Batch 26/64 loss: 0.23996973037719727
Batch 27/64 loss: 0.23748433589935303
Batch 28/64 loss: 0.2396484613418579
Batch 29/64 loss: 0.2323523759841919
Batch 30/64 loss: 0.24607789516448975
Batch 31/64 loss: 0.2285400629043579
Batch 32/64 loss: 0.2356647253036499
Batch 33/64 loss: 0.24202978610992432
Batch 34/64 loss: 0.24836599826812744
Batch 35/64 loss: 0.2446715235710144
Batch 36/64 loss: 0.2352120280265808
Batch 37/64 loss: 0.2519957423210144
Batch 38/64 loss: 0.2395726442337036
Batch 39/64 loss: 0.24366754293441772
Batch 40/64 loss: 0.24626797437667847
Batch 41/64 loss: 0.23380738496780396
Batch 42/64 loss: 0.24363309144973755
Batch 43/64 loss: 0.2462310791015625
Batch 44/64 loss: 0.23286861181259155
Batch 45/64 loss: 0.23749011754989624
Batch 46/64 loss: 0.24037706851959229
Batch 47/64 loss: 0.23975765705108643
Batch 48/64 loss: 0.23347347974777222
Batch 49/64 loss: 0.24194276332855225
Batch 50/64 loss: 0.24344730377197266
Batch 51/64 loss: 0.23122358322143555
Batch 52/64 loss: 0.23840641975402832
Batch 53/64 loss: 0.23490560054779053
Batch 54/64 loss: 0.24030548334121704
Batch 55/64 loss: 0.24069994688034058
Batch 56/64 loss: 0.2372831106185913
Batch 57/64 loss: 0.24278056621551514
Batch 58/64 loss: 0.23047494888305664
Batch 59/64 loss: 0.23687744140625
Batch 60/64 loss: 0.24754691123962402
Batch 61/64 loss: 0.23070108890533447
Batch 62/64 loss: 0.23815208673477173
Batch 63/64 loss: 0.24144411087036133
Batch 64/64 loss: 0.22817611694335938
Epoch 186  Train loss: 0.2389477393206428  Val loss: 0.2941014723679454
Epoch 187
-------------------------------
Batch 1/64 loss: 0.23578119277954102
Batch 2/64 loss: 0.23676663637161255
Batch 3/64 loss: 0.22712326049804688
Batch 4/64 loss: 0.238189697265625
Batch 5/64 loss: 0.24131816625595093
Batch 6/64 loss: 0.23721086978912354
Batch 7/64 loss: 0.23123013973236084
Batch 8/64 loss: 0.23144322633743286
Batch 9/64 loss: 0.2395421266555786
Batch 10/64 loss: 0.23745667934417725
Batch 11/64 loss: 0.25099873542785645
Batch 12/64 loss: 0.23904657363891602
Batch 13/64 loss: 0.23683691024780273
Batch 14/64 loss: 0.2331935167312622
Batch 15/64 loss: 0.23955827951431274
Batch 16/64 loss: 0.23543274402618408
Batch 17/64 loss: 0.24264192581176758
Batch 18/64 loss: 0.23552924394607544
Batch 19/64 loss: 0.22879457473754883
Batch 20/64 loss: 0.23855751752853394
Batch 21/64 loss: 0.2423926591873169
Batch 22/64 loss: 0.23289477825164795
Batch 23/64 loss: 0.24630999565124512
Batch 24/64 loss: 0.24685919284820557
Batch 25/64 loss: 0.24312084913253784
Batch 26/64 loss: 0.2288820743560791
Batch 27/64 loss: 0.23211586475372314
Batch 28/64 loss: 0.2406069040298462
Batch 29/64 loss: 0.23444914817810059
Batch 30/64 loss: 0.24821603298187256
Batch 31/64 loss: 0.2354103922843933
Batch 32/64 loss: 0.23860937356948853
Batch 33/64 loss: 0.2513241767883301
Batch 34/64 loss: 0.23990416526794434
Batch 35/64 loss: 0.2326737642288208
Batch 36/64 loss: 0.23034828901290894
Batch 37/64 loss: 0.23537206649780273
Batch 38/64 loss: 0.23828399181365967
Batch 39/64 loss: 0.23062992095947266
Batch 40/64 loss: 0.23236501216888428
Batch 41/64 loss: 0.24038028717041016
Batch 42/64 loss: 0.24223458766937256
Batch 43/64 loss: 0.2359459400177002
Batch 44/64 loss: 0.23467379808425903
Batch 45/64 loss: 0.2277623414993286
Batch 46/64 loss: 0.24056106805801392
Batch 47/64 loss: 0.24358785152435303
Batch 48/64 loss: 0.2386348843574524
Batch 49/64 loss: 0.2287689447402954
Batch 50/64 loss: 0.2434467077255249
Batch 51/64 loss: 0.23604917526245117
Batch 52/64 loss: 0.24032533168792725
Batch 53/64 loss: 0.24440288543701172
Batch 54/64 loss: 0.2429315447807312
Batch 55/64 loss: 0.24787640571594238
Batch 56/64 loss: 0.23394715785980225
Batch 57/64 loss: 0.23758524656295776
Batch 58/64 loss: 0.2381136417388916
Batch 59/64 loss: 0.24477934837341309
Batch 60/64 loss: 0.23767364025115967
Batch 61/64 loss: 0.23493164777755737
Batch 62/64 loss: 0.24620020389556885
Batch 63/64 loss: 0.2406214475631714
Batch 64/64 loss: 0.24071335792541504
Epoch 187  Train loss: 0.23810807489881328  Val loss: 0.29400412118721664
Epoch 188
-------------------------------
Batch 1/64 loss: 0.24087470769882202
Batch 2/64 loss: 0.23752361536026
Batch 3/64 loss: 0.23271793127059937
Batch 4/64 loss: 0.23250049352645874
Batch 5/64 loss: 0.24211269617080688
Batch 6/64 loss: 0.24727928638458252
Batch 7/64 loss: 0.24190330505371094
Batch 8/64 loss: 0.23514652252197266
Batch 9/64 loss: 0.240057110786438
Batch 10/64 loss: 0.2386382818222046
Batch 11/64 loss: 0.24931883811950684
Batch 12/64 loss: 0.23183691501617432
Batch 13/64 loss: 0.23808544874191284
Batch 14/64 loss: 0.23531180620193481
Batch 15/64 loss: 0.23658275604248047
Batch 16/64 loss: 0.24267196655273438
Batch 17/64 loss: 0.23739337921142578
Batch 18/64 loss: 0.23153865337371826
Batch 19/64 loss: 0.23844599723815918
Batch 20/64 loss: 0.23453640937805176
Batch 21/64 loss: 0.23394787311553955
Batch 22/64 loss: 0.2410793900489807
Batch 23/64 loss: 0.23513555526733398
Batch 24/64 loss: 0.24099475145339966
Batch 25/64 loss: 0.23976600170135498
Batch 26/64 loss: 0.23809194564819336
Batch 27/64 loss: 0.24423730373382568
Batch 28/64 loss: 0.2357950210571289
Batch 29/64 loss: 0.24790585041046143
Batch 30/64 loss: 0.24564450979232788
Batch 31/64 loss: 0.2358984351158142
Batch 32/64 loss: 0.25412094593048096
Batch 33/64 loss: 0.24197077751159668
Batch 34/64 loss: 0.2397187352180481
Batch 35/64 loss: 0.23843854665756226
Batch 36/64 loss: 0.2359250783920288
Batch 37/64 loss: 0.2375708818435669
Batch 38/64 loss: 0.24306398630142212
Batch 39/64 loss: 0.2366321086883545
Batch 40/64 loss: 0.22891128063201904
Batch 41/64 loss: 0.2379327416419983
Batch 42/64 loss: 0.24427372217178345
Batch 43/64 loss: 0.2305058240890503
Batch 44/64 loss: 0.23817849159240723
Batch 45/64 loss: 0.24580270051956177
Batch 46/64 loss: 0.24360764026641846
Batch 47/64 loss: 0.23425257205963135
Batch 48/64 loss: 0.23271894454956055
Batch 49/64 loss: 0.24342048168182373
Batch 50/64 loss: 0.24500107765197754
Batch 51/64 loss: 0.2364017367362976
Batch 52/64 loss: 0.23403894901275635
Batch 53/64 loss: 0.247031569480896
Batch 54/64 loss: 0.24163568019866943
Batch 55/64 loss: 0.23685818910598755
Batch 56/64 loss: 0.23475360870361328
Batch 57/64 loss: 0.24273622035980225
Batch 58/64 loss: 0.23371505737304688
Batch 59/64 loss: 0.23734331130981445
Batch 60/64 loss: 0.2467193603515625
Batch 61/64 loss: 0.23335248231887817
Batch 62/64 loss: 0.2282623052597046
Batch 63/64 loss: 0.24401164054870605
Batch 64/64 loss: 0.23207902908325195
Epoch 188  Train loss: 0.23883825376922008  Val loss: 0.2937972000784071
Epoch 189
-------------------------------
Batch 1/64 loss: 0.24029147624969482
Batch 2/64 loss: 0.24557644128799438
Batch 3/64 loss: 0.23464906215667725
Batch 4/64 loss: 0.23672014474868774
Batch 5/64 loss: 0.2436479926109314
Batch 6/64 loss: 0.2371159791946411
Batch 7/64 loss: 0.23869502544403076
Batch 8/64 loss: 0.2413313388824463
Batch 9/64 loss: 0.2350214719772339
Batch 10/64 loss: 0.2347315549850464
Batch 11/64 loss: 0.23871499300003052
Batch 12/64 loss: 0.2408677339553833
Batch 13/64 loss: 0.2372153401374817
Batch 14/64 loss: 0.2265235185623169
Batch 15/64 loss: 0.23193109035491943
Batch 16/64 loss: 0.2343388795852661
Batch 17/64 loss: 0.23514926433563232
Batch 18/64 loss: 0.25324803590774536
Batch 19/64 loss: 0.23821115493774414
Batch 20/64 loss: 0.24101048707962036
Batch 21/64 loss: 0.23451733589172363
Batch 22/64 loss: 0.23036247491836548
Batch 23/64 loss: 0.25380969047546387
Batch 24/64 loss: 0.23439717292785645
Batch 25/64 loss: 0.23521161079406738
Batch 26/64 loss: 0.23602694272994995
Batch 27/64 loss: 0.23708176612854004
Batch 28/64 loss: 0.235337495803833
Batch 29/64 loss: 0.2279808521270752
Batch 30/64 loss: 0.24580073356628418
Batch 31/64 loss: 0.2428048849105835
Batch 32/64 loss: 0.23797720670700073
Batch 33/64 loss: 0.23306679725646973
Batch 34/64 loss: 0.22624999284744263
Batch 35/64 loss: 0.2321261763572693
Batch 36/64 loss: 0.23822784423828125
Batch 37/64 loss: 0.2376551628112793
Batch 38/64 loss: 0.24650955200195312
Batch 39/64 loss: 0.23463380336761475
Batch 40/64 loss: 0.25430136919021606
Batch 41/64 loss: 0.2358863353729248
Batch 42/64 loss: 0.2362903356552124
Batch 43/64 loss: 0.2324708104133606
Batch 44/64 loss: 0.23919671773910522
Batch 45/64 loss: 0.23949098587036133
Batch 46/64 loss: 0.24428415298461914
Batch 47/64 loss: 0.23397481441497803
Batch 48/64 loss: 0.24245160818099976
Batch 49/64 loss: 0.24055135250091553
Batch 50/64 loss: 0.23175150156021118
Batch 51/64 loss: 0.23623865842819214
Batch 52/64 loss: 0.2425987720489502
Batch 53/64 loss: 0.24868202209472656
Batch 54/64 loss: 0.24768322706222534
Batch 55/64 loss: 0.2413768768310547
Batch 56/64 loss: 0.24606990814208984
Batch 57/64 loss: 0.23962390422821045
Batch 58/64 loss: 0.2345619797706604
Batch 59/64 loss: 0.23860573768615723
Batch 60/64 loss: 0.24425894021987915
Batch 61/64 loss: 0.23536115884780884
Batch 62/64 loss: 0.2385108470916748
Batch 63/64 loss: 0.24170488119125366
Batch 64/64 loss: 0.2394644021987915
Epoch 189  Train loss: 0.2385928420459523  Val loss: 0.29464026865680604
Epoch 190
-------------------------------
Batch 1/64 loss: 0.24044382572174072
Batch 2/64 loss: 0.23572152853012085
Batch 3/64 loss: 0.24240875244140625
Batch 4/64 loss: 0.22969943284988403
Batch 5/64 loss: 0.24560391902923584
Batch 6/64 loss: 0.23611927032470703
Batch 7/64 loss: 0.237623929977417
Batch 8/64 loss: 0.2338353395462036
Batch 9/64 loss: 0.2439669966697693
Batch 10/64 loss: 0.23341155052185059
Batch 11/64 loss: 0.2361992597579956
Batch 12/64 loss: 0.2346704602241516
Batch 13/64 loss: 0.24964892864227295
Batch 14/64 loss: 0.2384434938430786
Batch 15/64 loss: 0.23951268196105957
Batch 16/64 loss: 0.2312549352645874
Batch 17/64 loss: 0.238075852394104
Batch 18/64 loss: 0.23971307277679443
Batch 19/64 loss: 0.23683583736419678
Batch 20/64 loss: 0.24033230543136597
Batch 21/64 loss: 0.23730778694152832
Batch 22/64 loss: 0.23538923263549805
Batch 23/64 loss: 0.2447229027748108
Batch 24/64 loss: 0.24879270792007446
Batch 25/64 loss: 0.23709970712661743
Batch 26/64 loss: 0.23134386539459229
Batch 27/64 loss: 0.2322242259979248
Batch 28/64 loss: 0.241779625415802
Batch 29/64 loss: 0.23807454109191895
Batch 30/64 loss: 0.2383771538734436
Batch 31/64 loss: 0.23273003101348877
Batch 32/64 loss: 0.23405444622039795
Batch 33/64 loss: 0.2362762689590454
Batch 34/64 loss: 0.23048686981201172
Batch 35/64 loss: 0.23357295989990234
Batch 36/64 loss: 0.2427213191986084
Batch 37/64 loss: 0.23247569799423218
Batch 38/64 loss: 0.22587871551513672
Batch 39/64 loss: 0.22695845365524292
Batch 40/64 loss: 0.2404993772506714
Batch 41/64 loss: 0.24407553672790527
Batch 42/64 loss: 0.23198318481445312
Batch 43/64 loss: 0.2442060112953186
Batch 44/64 loss: 0.2378382682800293
Batch 45/64 loss: 0.23276174068450928
Batch 46/64 loss: 0.23591983318328857
Batch 47/64 loss: 0.24218899011611938
Batch 48/64 loss: 0.232635498046875
Batch 49/64 loss: 0.2391146421432495
Batch 50/64 loss: 0.2378246784210205
Batch 51/64 loss: 0.24056756496429443
Batch 52/64 loss: 0.24379092454910278
Batch 53/64 loss: 0.2389845848083496
Batch 54/64 loss: 0.2484266757965088
Batch 55/64 loss: 0.23506218194961548
Batch 56/64 loss: 0.2514294981956482
Batch 57/64 loss: 0.24516451358795166
Batch 58/64 loss: 0.24978530406951904
Batch 59/64 loss: 0.24126386642456055
Batch 60/64 loss: 0.24128544330596924
Batch 61/64 loss: 0.2326250672340393
Batch 62/64 loss: 0.22800642251968384
Batch 63/64 loss: 0.23202157020568848
Batch 64/64 loss: 0.24393373727798462
Epoch 190  Train loss: 0.2380266598626679  Val loss: 0.2939523575232201
Epoch 191
-------------------------------
Batch 1/64 loss: 0.23414576053619385
Batch 2/64 loss: 0.23776650428771973
Batch 3/64 loss: 0.2427242398262024
Batch 4/64 loss: 0.23098421096801758
Batch 5/64 loss: 0.23888075351715088
Batch 6/64 loss: 0.2373102307319641
Batch 7/64 loss: 0.22967302799224854
Batch 8/64 loss: 0.23682749271392822
Batch 9/64 loss: 0.23519480228424072
Batch 10/64 loss: 0.23835331201553345
Batch 11/64 loss: 0.23562884330749512
Batch 12/64 loss: 0.24763989448547363
Batch 13/64 loss: 0.2342349886894226
Batch 14/64 loss: 0.24167025089263916
Batch 15/64 loss: 0.24428260326385498
Batch 16/64 loss: 0.2277148962020874
Batch 17/64 loss: 0.23108834028244019
Batch 18/64 loss: 0.23763656616210938
Batch 19/64 loss: 0.2341376543045044
Batch 20/64 loss: 0.23751115798950195
Batch 21/64 loss: 0.23769265413284302
Batch 22/64 loss: 0.23439598083496094
Batch 23/64 loss: 0.2363067865371704
Batch 24/64 loss: 0.2339523434638977
Batch 25/64 loss: 0.2378098964691162
Batch 26/64 loss: 0.23851817846298218
Batch 27/64 loss: 0.23575031757354736
Batch 28/64 loss: 0.23454469442367554
Batch 29/64 loss: 0.24195683002471924
Batch 30/64 loss: 0.23261165618896484
Batch 31/64 loss: 0.23260504007339478
Batch 32/64 loss: 0.24415671825408936
Batch 33/64 loss: 0.2441624402999878
Batch 34/64 loss: 0.25184619426727295
Batch 35/64 loss: 0.23903107643127441
Batch 36/64 loss: 0.24200868606567383
Batch 37/64 loss: 0.22946631908416748
Batch 38/64 loss: 0.25253498554229736
Batch 39/64 loss: 0.24109137058258057
Batch 40/64 loss: 0.23480594158172607
Batch 41/64 loss: 0.2304781675338745
Batch 42/64 loss: 0.24348723888397217
Batch 43/64 loss: 0.23971879482269287
Batch 44/64 loss: 0.23654985427856445
Batch 45/64 loss: 0.23286163806915283
Batch 46/64 loss: 0.23626792430877686
Batch 47/64 loss: 0.22980636358261108
Batch 48/64 loss: 0.24317675828933716
Batch 49/64 loss: 0.23249709606170654
Batch 50/64 loss: 0.24619054794311523
Batch 51/64 loss: 0.23833465576171875
Batch 52/64 loss: 0.23506319522857666
Batch 53/64 loss: 0.25316739082336426
Batch 54/64 loss: 0.24023222923278809
Batch 55/64 loss: 0.23444288969039917
Batch 56/64 loss: 0.23880505561828613
Batch 57/64 loss: 0.23244524002075195
Batch 58/64 loss: 0.23448944091796875
Batch 59/64 loss: 0.24053996801376343
Batch 60/64 loss: 0.22992479801177979
Batch 61/64 loss: 0.24265456199645996
Batch 62/64 loss: 0.23120468854904175
Batch 63/64 loss: 0.23266196250915527
Batch 64/64 loss: 0.2340335249900818
Epoch 191  Train loss: 0.23747732148450965  Val loss: 0.2936742610947783
Epoch 192
-------------------------------
Batch 1/64 loss: 0.23281311988830566
Batch 2/64 loss: 0.22974854707717896
Batch 3/64 loss: 0.23484504222869873
Batch 4/64 loss: 0.2251635193824768
Batch 5/64 loss: 0.23624688386917114
Batch 6/64 loss: 0.2293514609336853
Batch 7/64 loss: 0.24045908451080322
Batch 8/64 loss: 0.24082183837890625
Batch 9/64 loss: 0.24112606048583984
Batch 10/64 loss: 0.23389720916748047
Batch 11/64 loss: 0.23251616954803467
Batch 12/64 loss: 0.2443745732307434
Batch 13/64 loss: 0.2331119179725647
Batch 14/64 loss: 0.22964918613433838
Batch 15/64 loss: 0.23979365825653076
Batch 16/64 loss: 0.24604785442352295
Batch 17/64 loss: 0.2327793836593628
Batch 18/64 loss: 0.23942983150482178
Batch 19/64 loss: 0.2393629550933838
Batch 20/64 loss: 0.2275850772857666
Batch 21/64 loss: 0.23437297344207764
Batch 22/64 loss: 0.23381257057189941
Batch 23/64 loss: 0.23667961359024048
Batch 24/64 loss: 0.238819420337677
Batch 25/64 loss: 0.2369157075881958
Batch 26/64 loss: 0.24054372310638428
Batch 27/64 loss: 0.23921751976013184
Batch 28/64 loss: 0.22806358337402344
Batch 29/64 loss: 0.2368648648262024
Batch 30/64 loss: 0.24544590711593628
Batch 31/64 loss: 0.23131489753723145
Batch 32/64 loss: 0.2362077236175537
Batch 33/64 loss: 0.23578953742980957
Batch 34/64 loss: 0.23333317041397095
Batch 35/64 loss: 0.22885870933532715
Batch 36/64 loss: 0.23758071660995483
Batch 37/64 loss: 0.2455732226371765
Batch 38/64 loss: 0.23596251010894775
Batch 39/64 loss: 0.22790652513504028
Batch 40/64 loss: 0.24419116973876953
Batch 41/64 loss: 0.23078739643096924
Batch 42/64 loss: 0.23646605014801025
Batch 43/64 loss: 0.2360631227493286
Batch 44/64 loss: 0.24032628536224365
Batch 45/64 loss: 0.235213041305542
Batch 46/64 loss: 0.24077767133712769
Batch 47/64 loss: 0.2435663938522339
Batch 48/64 loss: 0.2388671636581421
Batch 49/64 loss: 0.23431849479675293
Batch 50/64 loss: 0.24149179458618164
Batch 51/64 loss: 0.23857301473617554
Batch 52/64 loss: 0.23790061473846436
Batch 53/64 loss: 0.23337525129318237
Batch 54/64 loss: 0.23329579830169678
Batch 55/64 loss: 0.24492311477661133
Batch 56/64 loss: 0.2333509922027588
Batch 57/64 loss: 0.2340213656425476
Batch 58/64 loss: 0.24940729141235352
Batch 59/64 loss: 0.23671948909759521
Batch 60/64 loss: 0.23402512073516846
Batch 61/64 loss: 0.24511146545410156
Batch 62/64 loss: 0.2342258095741272
Batch 63/64 loss: 0.23411768674850464
Batch 64/64 loss: 0.23869121074676514
Epoch 192  Train loss: 0.23658855335385193  Val loss: 0.29420818373100044
Epoch 193
-------------------------------
Batch 1/64 loss: 0.23252099752426147
Batch 2/64 loss: 0.23323571681976318
Batch 3/64 loss: 0.23195481300354004
Batch 4/64 loss: 0.23861688375473022
Batch 5/64 loss: 0.2248222827911377
Batch 6/64 loss: 0.22904008626937866
Batch 7/64 loss: 0.23172813653945923
Batch 8/64 loss: 0.22796845436096191
Batch 9/64 loss: 0.23450732231140137
Batch 10/64 loss: 0.23156136274337769
Batch 11/64 loss: 0.23666119575500488
Batch 12/64 loss: 0.24594390392303467
Batch 13/64 loss: 0.2442408800125122
Batch 14/64 loss: 0.24158203601837158
Batch 15/64 loss: 0.23587095737457275
Batch 16/64 loss: 0.2236168384552002
Batch 17/64 loss: 0.23910772800445557
Batch 18/64 loss: 0.2348530888557434
Batch 19/64 loss: 0.246390700340271
Batch 20/64 loss: 0.23440003395080566
Batch 21/64 loss: 0.23709237575531006
Batch 22/64 loss: 0.22424185276031494
Batch 23/64 loss: 0.2355881929397583
Batch 24/64 loss: 0.23103618621826172
Batch 25/64 loss: 0.22831082344055176
Batch 26/64 loss: 0.23959660530090332
Batch 27/64 loss: 0.23177850246429443
Batch 28/64 loss: 0.2455388307571411
Batch 29/64 loss: 0.24846506118774414
Batch 30/64 loss: 0.24619615077972412
Batch 31/64 loss: 0.23859059810638428
Batch 32/64 loss: 0.23368430137634277
Batch 33/64 loss: 0.23608362674713135
Batch 34/64 loss: 0.23192226886749268
Batch 35/64 loss: 0.24293899536132812
Batch 36/64 loss: 0.2301574945449829
Batch 37/64 loss: 0.2383992075920105
Batch 38/64 loss: 0.2297770380973816
Batch 39/64 loss: 0.2291473150253296
Batch 40/64 loss: 0.24071615934371948
Batch 41/64 loss: 0.24703902006149292
Batch 42/64 loss: 0.23944753408432007
Batch 43/64 loss: 0.23814815282821655
Batch 44/64 loss: 0.2535899877548218
Batch 45/64 loss: 0.24585044384002686
Batch 46/64 loss: 0.23323971033096313
Batch 47/64 loss: 0.23637527227401733
Batch 48/64 loss: 0.23258745670318604
Batch 49/64 loss: 0.23292678594589233
Batch 50/64 loss: 0.23936140537261963
Batch 51/64 loss: 0.24091613292694092
Batch 52/64 loss: 0.2346993088722229
Batch 53/64 loss: 0.23402631282806396
Batch 54/64 loss: 0.24246901273727417
Batch 55/64 loss: 0.2501752972602844
Batch 56/64 loss: 0.2349759340286255
Batch 57/64 loss: 0.23899680376052856
Batch 58/64 loss: 0.23509979248046875
Batch 59/64 loss: 0.2407383918762207
Batch 60/64 loss: 0.23750847578048706
Batch 61/64 loss: 0.225541889667511
Batch 62/64 loss: 0.23877263069152832
Batch 63/64 loss: 0.23371952772140503
Batch 64/64 loss: 0.23868721723556519
Epoch 193  Train loss: 0.2365977364427903  Val loss: 0.2935375165693539
Saving best model, epoch: 193
Epoch 194
-------------------------------
Batch 1/64 loss: 0.22869890928268433
Batch 2/64 loss: 0.23513323068618774
Batch 3/64 loss: 0.24340426921844482
Batch 4/64 loss: 0.23992300033569336
Batch 5/64 loss: 0.2425883412361145
Batch 6/64 loss: 0.23805910348892212
Batch 7/64 loss: 0.23383378982543945
Batch 8/64 loss: 0.23850750923156738
Batch 9/64 loss: 0.2378596067428589
Batch 10/64 loss: 0.23009103536605835
Batch 11/64 loss: 0.2346339225769043
Batch 12/64 loss: 0.23110145330429077
Batch 13/64 loss: 0.23483610153198242
Batch 14/64 loss: 0.24111759662628174
Batch 15/64 loss: 0.2380903959274292
Batch 16/64 loss: 0.23438531160354614
Batch 17/64 loss: 0.2520824670791626
Batch 18/64 loss: 0.23909950256347656
Batch 19/64 loss: 0.2373267412185669
Batch 20/64 loss: 0.23715436458587646
Batch 21/64 loss: 0.22920268774032593
Batch 22/64 loss: 0.23965543508529663
Batch 23/64 loss: 0.2473750114440918
Batch 24/64 loss: 0.2271936535835266
Batch 25/64 loss: 0.24483191967010498
Batch 26/64 loss: 0.23872387409210205
Batch 27/64 loss: 0.23174196481704712
Batch 28/64 loss: 0.23689746856689453
Batch 29/64 loss: 0.24042350053787231
Batch 30/64 loss: 0.23549187183380127
Batch 31/64 loss: 0.23792564868927002
Batch 32/64 loss: 0.23718929290771484
Batch 33/64 loss: 0.23311734199523926
Batch 34/64 loss: 0.2330840826034546
Batch 35/64 loss: 0.23495376110076904
Batch 36/64 loss: 0.2286064624786377
Batch 37/64 loss: 0.23545658588409424
Batch 38/64 loss: 0.23098617792129517
Batch 39/64 loss: 0.23588675260543823
Batch 40/64 loss: 0.23676908016204834
Batch 41/64 loss: 0.23502910137176514
Batch 42/64 loss: 0.22709959745407104
Batch 43/64 loss: 0.2292548418045044
Batch 44/64 loss: 0.23524928092956543
Batch 45/64 loss: 0.22993385791778564
Batch 46/64 loss: 0.23547720909118652
Batch 47/64 loss: 0.23716163635253906
Batch 48/64 loss: 0.23206913471221924
Batch 49/64 loss: 0.2397061586380005
Batch 50/64 loss: 0.237673819065094
Batch 51/64 loss: 0.23542028665542603
Batch 52/64 loss: 0.22642815113067627
Batch 53/64 loss: 0.23502713441848755
Batch 54/64 loss: 0.23465299606323242
Batch 55/64 loss: 0.23253178596496582
Batch 56/64 loss: 0.24820858240127563
Batch 57/64 loss: 0.23671644926071167
Batch 58/64 loss: 0.23156845569610596
Batch 59/64 loss: 0.23115885257720947
Batch 60/64 loss: 0.2369523048400879
Batch 61/64 loss: 0.23098361492156982
Batch 62/64 loss: 0.2519659996032715
Batch 63/64 loss: 0.24358129501342773
Batch 64/64 loss: 0.22731810808181763
Epoch 194  Train loss: 0.2360435820093342  Val loss: 0.2936325212524519
Epoch 195
-------------------------------
Batch 1/64 loss: 0.22470659017562866
Batch 2/64 loss: 0.244209885597229
Batch 3/64 loss: 0.22972321510314941
Batch 4/64 loss: 0.231964111328125
Batch 5/64 loss: 0.22943341732025146
Batch 6/64 loss: 0.2319251298904419
Batch 7/64 loss: 0.23464429378509521
Batch 8/64 loss: 0.2491336464881897
Batch 9/64 loss: 0.2425093650817871
Batch 10/64 loss: 0.2264578938484192
Batch 11/64 loss: 0.2338172197341919
Batch 12/64 loss: 0.22890770435333252
Batch 13/64 loss: 0.24215495586395264
Batch 14/64 loss: 0.24022996425628662
Batch 15/64 loss: 0.2490522861480713
Batch 16/64 loss: 0.23745501041412354
Batch 17/64 loss: 0.23544442653656006
Batch 18/64 loss: 0.23672521114349365
Batch 19/64 loss: 0.23740476369857788
Batch 20/64 loss: 0.24292731285095215
Batch 21/64 loss: 0.22934716939926147
Batch 22/64 loss: 0.23179352283477783
Batch 23/64 loss: 0.24565887451171875
Batch 24/64 loss: 0.24018609523773193
Batch 25/64 loss: 0.23159396648406982
Batch 26/64 loss: 0.24440282583236694
Batch 27/64 loss: 0.23613834381103516
Batch 28/64 loss: 0.23718863725662231
Batch 29/64 loss: 0.24128615856170654
Batch 30/64 loss: 0.22481441497802734
Batch 31/64 loss: 0.23911595344543457
Batch 32/64 loss: 0.24110126495361328
Batch 33/64 loss: 0.237288236618042
Batch 34/64 loss: 0.2306365966796875
Batch 35/64 loss: 0.23186838626861572
Batch 36/64 loss: 0.24755775928497314
Batch 37/64 loss: 0.22709357738494873
Batch 38/64 loss: 0.24025100469589233
Batch 39/64 loss: 0.2412390112876892
Batch 40/64 loss: 0.23602938652038574
Batch 41/64 loss: 0.23059862852096558
Batch 42/64 loss: 0.2349216341972351
Batch 43/64 loss: 0.2300623655319214
Batch 44/64 loss: 0.23295754194259644
Batch 45/64 loss: 0.23612499237060547
Batch 46/64 loss: 0.23737674951553345
Batch 47/64 loss: 0.23866593837738037
Batch 48/64 loss: 0.24491095542907715
Batch 49/64 loss: 0.24075806140899658
Batch 50/64 loss: 0.24087762832641602
Batch 51/64 loss: 0.24049675464630127
Batch 52/64 loss: 0.23748880624771118
Batch 53/64 loss: 0.23761999607086182
Batch 54/64 loss: 0.23759818077087402
Batch 55/64 loss: 0.22907376289367676
Batch 56/64 loss: 0.23785555362701416
Batch 57/64 loss: 0.23479729890823364
Batch 58/64 loss: 0.2341333031654358
Batch 59/64 loss: 0.24383825063705444
Batch 60/64 loss: 0.22709643840789795
Batch 61/64 loss: 0.23656797409057617
Batch 62/64 loss: 0.23282575607299805
Batch 63/64 loss: 0.22812092304229736
Batch 64/64 loss: 0.22737455368041992
Epoch 195  Train loss: 0.23621515292747347  Val loss: 0.29360072698789774
Epoch 196
-------------------------------
Batch 1/64 loss: 0.24231171607971191
Batch 2/64 loss: 0.22666120529174805
Batch 3/64 loss: 0.2265338897705078
Batch 4/64 loss: 0.23083096742630005
Batch 5/64 loss: 0.23746240139007568
Batch 6/64 loss: 0.24915218353271484
Batch 7/64 loss: 0.22765988111495972
Batch 8/64 loss: 0.2306724190711975
Batch 9/64 loss: 0.25296592712402344
Batch 10/64 loss: 0.2325737476348877
Batch 11/64 loss: 0.23402267694473267
Batch 12/64 loss: 0.23937737941741943
Batch 13/64 loss: 0.22750639915466309
Batch 14/64 loss: 0.22802841663360596
Batch 15/64 loss: 0.24031126499176025
Batch 16/64 loss: 0.231758713722229
Batch 17/64 loss: 0.23890167474746704
Batch 18/64 loss: 0.2428739070892334
Batch 19/64 loss: 0.23681658506393433
Batch 20/64 loss: 0.23874390125274658
Batch 21/64 loss: 0.24054831266403198
Batch 22/64 loss: 0.2422460913658142
Batch 23/64 loss: 0.2375398874282837
Batch 24/64 loss: 0.23117130994796753
Batch 25/64 loss: 0.2336825132369995
Batch 26/64 loss: 0.23348468542099
Batch 27/64 loss: 0.23630869388580322
Batch 28/64 loss: 0.2419377565383911
Batch 29/64 loss: 0.2403528094291687
Batch 30/64 loss: 0.2407345175743103
Batch 31/64 loss: 0.24322080612182617
Batch 32/64 loss: 0.23957812786102295
Batch 33/64 loss: 0.23525691032409668
Batch 34/64 loss: 0.22932028770446777
Batch 35/64 loss: 0.2334192395210266
Batch 36/64 loss: 0.23059803247451782
Batch 37/64 loss: 0.23655474185943604
Batch 38/64 loss: 0.23011255264282227
Batch 39/64 loss: 0.23759007453918457
Batch 40/64 loss: 0.2284688949584961
Batch 41/64 loss: 0.23914676904678345
Batch 42/64 loss: 0.22772502899169922
Batch 43/64 loss: 0.23002135753631592
Batch 44/64 loss: 0.23035740852355957
Batch 45/64 loss: 0.22411781549453735
Batch 46/64 loss: 0.24518609046936035
Batch 47/64 loss: 0.2402745485305786
Batch 48/64 loss: 0.2366587519645691
Batch 49/64 loss: 0.24217110872268677
Batch 50/64 loss: 0.236000657081604
Batch 51/64 loss: 0.24338245391845703
Batch 52/64 loss: 0.23410940170288086
Batch 53/64 loss: 0.22838842868804932
Batch 54/64 loss: 0.24593698978424072
Batch 55/64 loss: 0.24039113521575928
Batch 56/64 loss: 0.23359739780426025
Batch 57/64 loss: 0.2286365032196045
Batch 58/64 loss: 0.23779058456420898
Batch 59/64 loss: 0.24305814504623413
Batch 60/64 loss: 0.23585104942321777
Batch 61/64 loss: 0.23506087064743042
Batch 62/64 loss: 0.24336254596710205
Batch 63/64 loss: 0.24036037921905518
Batch 64/64 loss: 0.23843169212341309
Epoch 196  Train loss: 0.2361992265663895  Val loss: 0.29409286267159324
Epoch 197
-------------------------------
Batch 1/64 loss: 0.23468053340911865
Batch 2/64 loss: 0.23521417379379272
Batch 3/64 loss: 0.22980725765228271
Batch 4/64 loss: 0.23059284687042236
Batch 5/64 loss: 0.23022228479385376
Batch 6/64 loss: 0.22632372379302979
Batch 7/64 loss: 0.23022115230560303
Batch 8/64 loss: 0.23415517807006836
Batch 9/64 loss: 0.23607641458511353
Batch 10/64 loss: 0.2276737093925476
Batch 11/64 loss: 0.2333785891532898
Batch 12/64 loss: 0.25416362285614014
Batch 13/64 loss: 0.23931044340133667
Batch 14/64 loss: 0.23537611961364746
Batch 15/64 loss: 0.24176305532455444
Batch 16/64 loss: 0.24207258224487305
Batch 17/64 loss: 0.23846906423568726
Batch 18/64 loss: 0.23275399208068848
Batch 19/64 loss: 0.23538607358932495
Batch 20/64 loss: 0.23245716094970703
Batch 21/64 loss: 0.23196351528167725
Batch 22/64 loss: 0.23078858852386475
Batch 23/64 loss: 0.23942017555236816
Batch 24/64 loss: 0.23704922199249268
Batch 25/64 loss: 0.23596060276031494
Batch 26/64 loss: 0.24527490139007568
Batch 27/64 loss: 0.2383134365081787
Batch 28/64 loss: 0.2273937463760376
Batch 29/64 loss: 0.23520159721374512
Batch 30/64 loss: 0.22308039665222168
Batch 31/64 loss: 0.23166155815124512
Batch 32/64 loss: 0.2272176742553711
Batch 33/64 loss: 0.22820371389389038
Batch 34/64 loss: 0.2285994291305542
Batch 35/64 loss: 0.23448705673217773
Batch 36/64 loss: 0.23378396034240723
Batch 37/64 loss: 0.25177836418151855
Batch 38/64 loss: 0.2263166904449463
Batch 39/64 loss: 0.23016631603240967
Batch 40/64 loss: 0.23984408378601074
Batch 41/64 loss: 0.23374336957931519
Batch 42/64 loss: 0.23888444900512695
Batch 43/64 loss: 0.23067820072174072
Batch 44/64 loss: 0.2312251329421997
Batch 45/64 loss: 0.2384634017944336
Batch 46/64 loss: 0.23638075590133667
Batch 47/64 loss: 0.24301153421401978
Batch 48/64 loss: 0.23311066627502441
Batch 49/64 loss: 0.2455899715423584
Batch 50/64 loss: 0.24637126922607422
Batch 51/64 loss: 0.2333080768585205
Batch 52/64 loss: 0.23372161388397217
Batch 53/64 loss: 0.2447112798690796
Batch 54/64 loss: 0.2403767704963684
Batch 55/64 loss: 0.23916757106781006
Batch 56/64 loss: 0.24136555194854736
Batch 57/64 loss: 0.2374790906906128
Batch 58/64 loss: 0.23683524131774902
Batch 59/64 loss: 0.2310580015182495
Batch 60/64 loss: 0.22611886262893677
Batch 61/64 loss: 0.23651182651519775
Batch 62/64 loss: 0.23017573356628418
Batch 63/64 loss: 0.23857593536376953
Batch 64/64 loss: 0.2423795461654663
Epoch 197  Train loss: 0.23537650155086143  Val loss: 0.29301160799269005
Saving best model, epoch: 197
Epoch 198
-------------------------------
Batch 1/64 loss: 0.23655462265014648
Batch 2/64 loss: 0.23396193981170654
Batch 3/64 loss: 0.237717866897583
Batch 4/64 loss: 0.22529500722885132
Batch 5/64 loss: 0.2345118522644043
Batch 6/64 loss: 0.23706990480422974
Batch 7/64 loss: 0.230552077293396
Batch 8/64 loss: 0.24466818571090698
Batch 9/64 loss: 0.23577237129211426
Batch 10/64 loss: 0.23177087306976318
Batch 11/64 loss: 0.25873661041259766
Batch 12/64 loss: 0.2268216609954834
Batch 13/64 loss: 0.2352374792098999
Batch 14/64 loss: 0.23120397329330444
Batch 15/64 loss: 0.23351752758026123
Batch 16/64 loss: 0.2319798469543457
Batch 17/64 loss: 0.22986090183258057
Batch 18/64 loss: 0.22397136688232422
Batch 19/64 loss: 0.23080897331237793
Batch 20/64 loss: 0.23427170515060425
Batch 21/64 loss: 0.2343839406967163
Batch 22/64 loss: 0.23803746700286865
Batch 23/64 loss: 0.2402288317680359
Batch 24/64 loss: 0.22402960062026978
Batch 25/64 loss: 0.22984158992767334
Batch 26/64 loss: 0.23818016052246094
Batch 27/64 loss: 0.2437208890914917
Batch 28/64 loss: 0.2501973509788513
Batch 29/64 loss: 0.2475908398628235
Batch 30/64 loss: 0.22823107242584229
Batch 31/64 loss: 0.2409871220588684
Batch 32/64 loss: 0.2350529432296753
Batch 33/64 loss: 0.2302303910255432
Batch 34/64 loss: 0.23406898975372314
Batch 35/64 loss: 0.24758267402648926
Batch 36/64 loss: 0.24114739894866943
Batch 37/64 loss: 0.2399437427520752
Batch 38/64 loss: 0.2312774658203125
Batch 39/64 loss: 0.231012761592865
Batch 40/64 loss: 0.23603308200836182
Batch 41/64 loss: 0.22517120838165283
Batch 42/64 loss: 0.23681235313415527
Batch 43/64 loss: 0.24351763725280762
Batch 44/64 loss: 0.2330772876739502
Batch 45/64 loss: 0.23698681592941284
Batch 46/64 loss: 0.23296475410461426
Batch 47/64 loss: 0.23410797119140625
Batch 48/64 loss: 0.23001450300216675
Batch 49/64 loss: 0.23554694652557373
Batch 50/64 loss: 0.24520611763000488
Batch 51/64 loss: 0.2277730107307434
Batch 52/64 loss: 0.22713297605514526
Batch 53/64 loss: 0.23335790634155273
Batch 54/64 loss: 0.2373431921005249
Batch 55/64 loss: 0.2312822937965393
Batch 56/64 loss: 0.23771309852600098
Batch 57/64 loss: 0.2313450574874878
Batch 58/64 loss: 0.22599875926971436
Batch 59/64 loss: 0.23097503185272217
Batch 60/64 loss: 0.23644286394119263
Batch 61/64 loss: 0.23737800121307373
Batch 62/64 loss: 0.2482438087463379
Batch 63/64 loss: 0.23168396949768066
Batch 64/64 loss: 0.2384124994277954
Epoch 198  Train loss: 0.23521487058377732  Val loss: 0.29463889221964834
Epoch 199
-------------------------------
Batch 1/64 loss: 0.24089187383651733
Batch 2/64 loss: 0.23058533668518066
Batch 3/64 loss: 0.23171496391296387
Batch 4/64 loss: 0.2312108874320984
Batch 5/64 loss: 0.23319005966186523
Batch 6/64 loss: 0.23452043533325195
Batch 7/64 loss: 0.23209989070892334
Batch 8/64 loss: 0.23749494552612305
Batch 9/64 loss: 0.24083852767944336
Batch 10/64 loss: 0.2352304458618164
Batch 11/64 loss: 0.23596787452697754
Batch 12/64 loss: 0.2357417345046997
Batch 13/64 loss: 0.22806298732757568
Batch 14/64 loss: 0.23803263902664185
Batch 15/64 loss: 0.23544847965240479
Batch 16/64 loss: 0.23802363872528076
Batch 17/64 loss: 0.2366781234741211
Batch 18/64 loss: 0.23094213008880615
Batch 19/64 loss: 0.24120432138442993
Batch 20/64 loss: 0.23129594326019287
Batch 21/64 loss: 0.22744441032409668
Batch 22/64 loss: 0.2297523021697998
Batch 23/64 loss: 0.22929894924163818
Batch 24/64 loss: 0.24146705865859985
Batch 25/64 loss: 0.22750115394592285
Batch 26/64 loss: 0.2364734411239624
Batch 27/64 loss: 0.2337557077407837
Batch 28/64 loss: 0.2429593801498413
Batch 29/64 loss: 0.2276824712753296
Batch 30/64 loss: 0.23574292659759521
Batch 31/64 loss: 0.2336903214454651
Batch 32/64 loss: 0.24889886379241943
Batch 33/64 loss: 0.22598057985305786
Batch 34/64 loss: 0.23159563541412354
Batch 35/64 loss: 0.24264216423034668
Batch 36/64 loss: 0.22665143013000488
Batch 37/64 loss: 0.24326658248901367
Batch 38/64 loss: 0.23577719926834106
Batch 39/64 loss: 0.23069888353347778
Batch 40/64 loss: 0.23661494255065918
Batch 41/64 loss: 0.23390918970108032
Batch 42/64 loss: 0.2379879355430603
Batch 43/64 loss: 0.23965990543365479
Batch 44/64 loss: 0.22878438234329224
Batch 45/64 loss: 0.2327413558959961
Batch 46/64 loss: 0.23744940757751465
Batch 47/64 loss: 0.2426011562347412
Batch 48/64 loss: 0.23173177242279053
Batch 49/64 loss: 0.23441535234451294
Batch 50/64 loss: 0.23287183046340942
Batch 51/64 loss: 0.2385849952697754
Batch 52/64 loss: 0.2334836721420288
Batch 53/64 loss: 0.23823189735412598
Batch 54/64 loss: 0.22747361660003662
Batch 55/64 loss: 0.2363957166671753
Batch 56/64 loss: 0.2401372194290161
Batch 57/64 loss: 0.228929340839386
Batch 58/64 loss: 0.24258899688720703
Batch 59/64 loss: 0.24554812908172607
Batch 60/64 loss: 0.23527705669403076
Batch 61/64 loss: 0.23157155513763428
Batch 62/64 loss: 0.24741524457931519
Batch 63/64 loss: 0.22633367776870728
Batch 64/64 loss: 0.24393177032470703
Epoch 199  Train loss: 0.23520222551682415  Val loss: 0.29401854223402096
Epoch 200
-------------------------------
Batch 1/64 loss: 0.22978055477142334
Batch 2/64 loss: 0.23491597175598145
Batch 3/64 loss: 0.22718369960784912
Batch 4/64 loss: 0.23167872428894043
Batch 5/64 loss: 0.2313014268875122
Batch 6/64 loss: 0.23917829990386963
Batch 7/64 loss: 0.23540544509887695
Batch 8/64 loss: 0.233384370803833
Batch 9/64 loss: 0.23292338848114014
Batch 10/64 loss: 0.23052763938903809
Batch 11/64 loss: 0.2287454605102539
Batch 12/64 loss: 0.22858262062072754
Batch 13/64 loss: 0.23992252349853516
Batch 14/64 loss: 0.23624825477600098
Batch 15/64 loss: 0.23396581411361694
Batch 16/64 loss: 0.23044520616531372
Batch 17/64 loss: 0.22550183534622192
Batch 18/64 loss: 0.2457517385482788
Batch 19/64 loss: 0.23161005973815918
Batch 20/64 loss: 0.2323446273803711
Batch 21/64 loss: 0.2406734824180603
Batch 22/64 loss: 0.23663437366485596
Batch 23/64 loss: 0.2389378547668457
Batch 24/64 loss: 0.22690469026565552
Batch 25/64 loss: 0.22308361530303955
Batch 26/64 loss: 0.23194611072540283
Batch 27/64 loss: 0.23617267608642578
Batch 28/64 loss: 0.24522614479064941
Batch 29/64 loss: 0.24270260334014893
Batch 30/64 loss: 0.23605459928512573
Batch 31/64 loss: 0.23765051364898682
Batch 32/64 loss: 0.24029171466827393
Batch 33/64 loss: 0.2337867021560669
Batch 34/64 loss: 0.23207098245620728
Batch 35/64 loss: 0.24208056926727295
Batch 36/64 loss: 0.23746538162231445
Batch 37/64 loss: 0.23795264959335327
Batch 38/64 loss: 0.2464471459388733
Batch 39/64 loss: 0.2377234697341919
Batch 40/64 loss: 0.22663253545761108
Batch 41/64 loss: 0.22413349151611328
Batch 42/64 loss: 0.22852420806884766
Batch 43/64 loss: 0.24293076992034912
Batch 44/64 loss: 0.24012333154678345
Batch 45/64 loss: 0.23649168014526367
Batch 46/64 loss: 0.2381504774093628
Batch 47/64 loss: 0.22789084911346436
Batch 48/64 loss: 0.2313011884689331
Batch 49/64 loss: 0.23812651634216309
Batch 50/64 loss: 0.23537123203277588
Batch 51/64 loss: 0.24819457530975342
Batch 52/64 loss: 0.23319971561431885
Batch 53/64 loss: 0.22917616367340088
Batch 54/64 loss: 0.24645745754241943
Batch 55/64 loss: 0.23446238040924072
Batch 56/64 loss: 0.23779559135437012
Batch 57/64 loss: 0.2340637445449829
Batch 58/64 loss: 0.23291373252868652
Batch 59/64 loss: 0.23171448707580566
Batch 60/64 loss: 0.23140478134155273
Batch 61/64 loss: 0.22484302520751953
Batch 62/64 loss: 0.23362982273101807
Batch 63/64 loss: 0.23153740167617798
Batch 64/64 loss: 0.24528390169143677
Epoch 200  Train loss: 0.23476447100732842  Val loss: 0.29340780272926253
Epoch 201
-------------------------------
Batch 1/64 loss: 0.23466217517852783
Batch 2/64 loss: 0.23646306991577148
Batch 3/64 loss: 0.22511309385299683
Batch 4/64 loss: 0.23844695091247559
Batch 5/64 loss: 0.22995340824127197
Batch 6/64 loss: 0.23155534267425537
Batch 7/64 loss: 0.2369455099105835
Batch 8/64 loss: 0.23140621185302734
Batch 9/64 loss: 0.23668557405471802
Batch 10/64 loss: 0.23096996545791626
Batch 11/64 loss: 0.22835344076156616
Batch 12/64 loss: 0.24376845359802246
Batch 13/64 loss: 0.2380809783935547
Batch 14/64 loss: 0.230876624584198
Batch 15/64 loss: 0.23911374807357788
Batch 16/64 loss: 0.24564337730407715
Batch 17/64 loss: 0.2332291603088379
Batch 18/64 loss: 0.23549020290374756
Batch 19/64 loss: 0.23549365997314453
Batch 20/64 loss: 0.22610676288604736
Batch 21/64 loss: 0.23563933372497559
Batch 22/64 loss: 0.23541933298110962
Batch 23/64 loss: 0.22663027048110962
Batch 24/64 loss: 0.22636902332305908
Batch 25/64 loss: 0.2340174913406372
Batch 26/64 loss: 0.22902441024780273
Batch 27/64 loss: 0.24137985706329346
Batch 28/64 loss: 0.22885286808013916
Batch 29/64 loss: 0.23130345344543457
Batch 30/64 loss: 0.2295628786087036
Batch 31/64 loss: 0.23222333192825317
Batch 32/64 loss: 0.23367631435394287
Batch 33/64 loss: 0.23798006772994995
Batch 34/64 loss: 0.24238073825836182
Batch 35/64 loss: 0.22827231884002686
Batch 36/64 loss: 0.2288227081298828
Batch 37/64 loss: 0.23042798042297363
Batch 38/64 loss: 0.2286088466644287
Batch 39/64 loss: 0.22836565971374512
Batch 40/64 loss: 0.2321677803993225
Batch 41/64 loss: 0.23030179738998413
Batch 42/64 loss: 0.23082184791564941
Batch 43/64 loss: 0.25004303455352783
Batch 44/64 loss: 0.22800886631011963
Batch 45/64 loss: 0.23639577627182007
Batch 46/64 loss: 0.23598814010620117
Batch 47/64 loss: 0.23532545566558838
Batch 48/64 loss: 0.23867887258529663
Batch 49/64 loss: 0.24059194326400757
Batch 50/64 loss: 0.2330087423324585
Batch 51/64 loss: 0.23395979404449463
Batch 52/64 loss: 0.23287808895111084
Batch 53/64 loss: 0.24107050895690918
Batch 54/64 loss: 0.22638583183288574
Batch 55/64 loss: 0.2394404411315918
Batch 56/64 loss: 0.24361270666122437
Batch 57/64 loss: 0.2361537218093872
Batch 58/64 loss: 0.2554665803909302
Batch 59/64 loss: 0.23228365182876587
Batch 60/64 loss: 0.23877400159835815
Batch 61/64 loss: 0.23137962818145752
Batch 62/64 loss: 0.2272578477859497
Batch 63/64 loss: 0.2385997772216797
Batch 64/64 loss: 0.24288809299468994
Epoch 201  Train loss: 0.23447961573507273  Val loss: 0.2947149205043963
Epoch 202
-------------------------------
Batch 1/64 loss: 0.23240840435028076
Batch 2/64 loss: 0.22220349311828613
Batch 3/64 loss: 0.2408190369606018
Batch 4/64 loss: 0.23202908039093018
Batch 5/64 loss: 0.23867911100387573
Batch 6/64 loss: 0.2328735589981079
Batch 7/64 loss: 0.22861438989639282
Batch 8/64 loss: 0.23065638542175293
Batch 9/64 loss: 0.23001450300216675
Batch 10/64 loss: 0.23264312744140625
Batch 11/64 loss: 0.23527264595031738
Batch 12/64 loss: 0.2267809510231018
Batch 13/64 loss: 0.24368464946746826
Batch 14/64 loss: 0.22837740182876587
Batch 15/64 loss: 0.23057645559310913
Batch 16/64 loss: 0.23714762926101685
Batch 17/64 loss: 0.22758597135543823
Batch 18/64 loss: 0.225569486618042
Batch 19/64 loss: 0.24201154708862305
Batch 20/64 loss: 0.23722237348556519
Batch 21/64 loss: 0.24161767959594727
Batch 22/64 loss: 0.2364521622657776
Batch 23/64 loss: 0.23552542924880981
Batch 24/64 loss: 0.22655075788497925
Batch 25/64 loss: 0.2277975082397461
Batch 26/64 loss: 0.23857998847961426
Batch 27/64 loss: 0.23875808715820312
Batch 28/64 loss: 0.2333938479423523
Batch 29/64 loss: 0.23260784149169922
Batch 30/64 loss: 0.2450101375579834
Batch 31/64 loss: 0.23317646980285645
Batch 32/64 loss: 0.23837614059448242
Batch 33/64 loss: 0.22753357887268066
Batch 34/64 loss: 0.2354567050933838
Batch 35/64 loss: 0.22921639680862427
Batch 36/64 loss: 0.22741782665252686
Batch 37/64 loss: 0.23987293243408203
Batch 38/64 loss: 0.23190581798553467
Batch 39/64 loss: 0.23590248823165894
Batch 40/64 loss: 0.2386305332183838
Batch 41/64 loss: 0.22416168451309204
Batch 42/64 loss: 0.22886860370635986
Batch 43/64 loss: 0.24180996417999268
Batch 44/64 loss: 0.22904062271118164
Batch 45/64 loss: 0.23520445823669434
Batch 46/64 loss: 0.2332705855369568
Batch 47/64 loss: 0.23443466424942017
Batch 48/64 loss: 0.23061084747314453
Batch 49/64 loss: 0.23356086015701294
Batch 50/64 loss: 0.23396968841552734
Batch 51/64 loss: 0.2535055875778198
Batch 52/64 loss: 0.2427358627319336
Batch 53/64 loss: 0.2298346757888794
Batch 54/64 loss: 0.2380266785621643
Batch 55/64 loss: 0.2463829517364502
Batch 56/64 loss: 0.2367469072341919
Batch 57/64 loss: 0.23045796155929565
Batch 58/64 loss: 0.23134517669677734
Batch 59/64 loss: 0.24616456031799316
Batch 60/64 loss: 0.23025178909301758
Batch 61/64 loss: 0.23145616054534912
Batch 62/64 loss: 0.23045146465301514
Batch 63/64 loss: 0.23176205158233643
Batch 64/64 loss: 0.2341451644897461
Epoch 202  Train loss: 0.23417435627357633  Val loss: 0.2936783516939563
Epoch 203
-------------------------------
Batch 1/64 loss: 0.22781556844711304
Batch 2/64 loss: 0.23004484176635742
Batch 3/64 loss: 0.2303246259689331
Batch 4/64 loss: 0.22863554954528809
Batch 5/64 loss: 0.2380303144454956
Batch 6/64 loss: 0.23177075386047363
Batch 7/64 loss: 0.229217529296875
Batch 8/64 loss: 0.2379065752029419
Batch 9/64 loss: 0.23697853088378906
Batch 10/64 loss: 0.2407236099243164
Batch 11/64 loss: 0.23482167720794678
Batch 12/64 loss: 0.23860478401184082
Batch 13/64 loss: 0.2271813154220581
Batch 14/64 loss: 0.22616994380950928
Batch 15/64 loss: 0.22571218013763428
Batch 16/64 loss: 0.22914552688598633
Batch 17/64 loss: 0.2285946011543274
Batch 18/64 loss: 0.22756612300872803
Batch 19/64 loss: 0.23853516578674316
Batch 20/64 loss: 0.25365716218948364
Batch 21/64 loss: 0.23065060377120972
Batch 22/64 loss: 0.23292797803878784
Batch 23/64 loss: 0.2333214282989502
Batch 24/64 loss: 0.2437295913696289
Batch 25/64 loss: 0.24036800861358643
Batch 26/64 loss: 0.22489333152770996
Batch 27/64 loss: 0.22867047786712646
Batch 28/64 loss: 0.24745190143585205
Batch 29/64 loss: 0.23264575004577637
Batch 30/64 loss: 0.2412317991256714
Batch 31/64 loss: 0.22753828763961792
Batch 32/64 loss: 0.23088228702545166
Batch 33/64 loss: 0.22917842864990234
Batch 34/64 loss: 0.24454987049102783
Batch 35/64 loss: 0.22826218605041504
Batch 36/64 loss: 0.23573321104049683
Batch 37/64 loss: 0.22965574264526367
Batch 38/64 loss: 0.2290503978729248
Batch 39/64 loss: 0.23238420486450195
Batch 40/64 loss: 0.2354699969291687
Batch 41/64 loss: 0.22708511352539062
Batch 42/64 loss: 0.23257219791412354
Batch 43/64 loss: 0.23671627044677734
Batch 44/64 loss: 0.24686574935913086
Batch 45/64 loss: 0.23610985279083252
Batch 46/64 loss: 0.23192310333251953
Batch 47/64 loss: 0.2398817539215088
Batch 48/64 loss: 0.23242485523223877
Batch 49/64 loss: 0.22882115840911865
Batch 50/64 loss: 0.22943687438964844
Batch 51/64 loss: 0.22843259572982788
Batch 52/64 loss: 0.23777079582214355
Batch 53/64 loss: 0.2288529872894287
Batch 54/64 loss: 0.23554742336273193
Batch 55/64 loss: 0.22771751880645752
Batch 56/64 loss: 0.24752873182296753
Batch 57/64 loss: 0.2523028254508972
Batch 58/64 loss: 0.23336297273635864
Batch 59/64 loss: 0.22839081287384033
Batch 60/64 loss: 0.22933036088943481
Batch 61/64 loss: 0.23027563095092773
Batch 62/64 loss: 0.22924470901489258
Batch 63/64 loss: 0.24261689186096191
Batch 64/64 loss: 0.23245632648468018
Epoch 203  Train loss: 0.2338444751851699  Val loss: 0.2944928712861235
Epoch 204
-------------------------------
Batch 1/64 loss: 0.22680389881134033
Batch 2/64 loss: 0.23738038539886475
Batch 3/64 loss: 0.23640602827072144
Batch 4/64 loss: 0.22683101892471313
Batch 5/64 loss: 0.2296345829963684
Batch 6/64 loss: 0.23655319213867188
Batch 7/64 loss: 0.23565673828125
Batch 8/64 loss: 0.24032831192016602
Batch 9/64 loss: 0.23676049709320068
Batch 10/64 loss: 0.23879611492156982
Batch 11/64 loss: 0.2470187544822693
Batch 12/64 loss: 0.23343825340270996
Batch 13/64 loss: 0.23449993133544922
Batch 14/64 loss: 0.23358488082885742
Batch 15/64 loss: 0.23175954818725586
Batch 16/64 loss: 0.2201802134513855
Batch 17/64 loss: 0.2273656129837036
Batch 18/64 loss: 0.22174012660980225
Batch 19/64 loss: 0.22671687602996826
Batch 20/64 loss: 0.2412765622138977
Batch 21/64 loss: 0.24614661931991577
Batch 22/64 loss: 0.23700261116027832
Batch 23/64 loss: 0.2351386547088623
Batch 24/64 loss: 0.23271095752716064
Batch 25/64 loss: 0.2454674243927002
Batch 26/64 loss: 0.2350846529006958
Batch 27/64 loss: 0.2244429588317871
Batch 28/64 loss: 0.23586106300354004
Batch 29/64 loss: 0.23058092594146729
Batch 30/64 loss: 0.22814881801605225
Batch 31/64 loss: 0.23284989595413208
Batch 32/64 loss: 0.23339474201202393
Batch 33/64 loss: 0.23709750175476074
Batch 34/64 loss: 0.2387458086013794
Batch 35/64 loss: 0.2323783040046692
Batch 36/64 loss: 0.23481273651123047
Batch 37/64 loss: 0.23769938945770264
Batch 38/64 loss: 0.231833815574646
Batch 39/64 loss: 0.24149101972579956
Batch 40/64 loss: 0.23269760608673096
Batch 41/64 loss: 0.23375791311264038
Batch 42/64 loss: 0.2306358814239502
Batch 43/64 loss: 0.24459731578826904
Batch 44/64 loss: 0.23585623502731323
Batch 45/64 loss: 0.25031280517578125
Batch 46/64 loss: 0.2308083176612854
Batch 47/64 loss: 0.23733097314834595
Batch 48/64 loss: 0.23338091373443604
Batch 49/64 loss: 0.23248255252838135
Batch 50/64 loss: 0.23397409915924072
Batch 51/64 loss: 0.22994530200958252
Batch 52/64 loss: 0.24654114246368408
Batch 53/64 loss: 0.2342212200164795
Batch 54/64 loss: 0.22613751888275146
Batch 55/64 loss: 0.23225432634353638
Batch 56/64 loss: 0.24124133586883545
Batch 57/64 loss: 0.23283803462982178
Batch 58/64 loss: 0.23618531227111816
Batch 59/64 loss: 0.23365509510040283
Batch 60/64 loss: 0.23752671480178833
Batch 61/64 loss: 0.238811194896698
Batch 62/64 loss: 0.2180720567703247
Batch 63/64 loss: 0.2264062762260437
Batch 64/64 loss: 0.22508299350738525
Epoch 204  Train loss: 0.23422904809316  Val loss: 0.29252827167510986
Saving best model, epoch: 204
Epoch 205
-------------------------------
Batch 1/64 loss: 0.23442959785461426
Batch 2/64 loss: 0.2365795373916626
Batch 3/64 loss: 0.22757381200790405
Batch 4/64 loss: 0.22799986600875854
Batch 5/64 loss: 0.23344075679779053
Batch 6/64 loss: 0.22616815567016602
Batch 7/64 loss: 0.2281132936477661
Batch 8/64 loss: 0.2429978847503662
Batch 9/64 loss: 0.22513443231582642
Batch 10/64 loss: 0.2237706184387207
Batch 11/64 loss: 0.23598361015319824
Batch 12/64 loss: 0.22645330429077148
Batch 13/64 loss: 0.2283405065536499
Batch 14/64 loss: 0.226526141166687
Batch 15/64 loss: 0.23000693321228027
Batch 16/64 loss: 0.23014450073242188
Batch 17/64 loss: 0.24024462699890137
Batch 18/64 loss: 0.2330126166343689
Batch 19/64 loss: 0.2306579351425171
Batch 20/64 loss: 0.2369784116744995
Batch 21/64 loss: 0.2418985366821289
Batch 22/64 loss: 0.22983837127685547
Batch 23/64 loss: 0.2422327995300293
Batch 24/64 loss: 0.23371171951293945
Batch 25/64 loss: 0.2356586456298828
Batch 26/64 loss: 0.23696428537368774
Batch 27/64 loss: 0.22824668884277344
Batch 28/64 loss: 0.23359298706054688
Batch 29/64 loss: 0.2360929250717163
Batch 30/64 loss: 0.23462259769439697
Batch 31/64 loss: 0.22839075326919556
Batch 32/64 loss: 0.22791016101837158
Batch 33/64 loss: 0.23213553428649902
Batch 34/64 loss: 0.2287740707397461
Batch 35/64 loss: 0.23402178287506104
Batch 36/64 loss: 0.23058652877807617
Batch 37/64 loss: 0.24149656295776367
Batch 38/64 loss: 0.2270904779434204
Batch 39/64 loss: 0.2313377857208252
Batch 40/64 loss: 0.23751235008239746
Batch 41/64 loss: 0.24346095323562622
Batch 42/64 loss: 0.23590993881225586
Batch 43/64 loss: 0.2310435175895691
Batch 44/64 loss: 0.24625349044799805
Batch 45/64 loss: 0.22829341888427734
Batch 46/64 loss: 0.24179434776306152
Batch 47/64 loss: 0.24132102727890015
Batch 48/64 loss: 0.24762946367263794
Batch 49/64 loss: 0.2288665771484375
Batch 50/64 loss: 0.24065184593200684
Batch 51/64 loss: 0.23176443576812744
Batch 52/64 loss: 0.22880494594573975
Batch 53/64 loss: 0.23032158613204956
Batch 54/64 loss: 0.24609702825546265
Batch 55/64 loss: 0.2355141043663025
Batch 56/64 loss: 0.22992265224456787
Batch 57/64 loss: 0.22162896394729614
Batch 58/64 loss: 0.23058176040649414
Batch 59/64 loss: 0.23228681087493896
Batch 60/64 loss: 0.2273452877998352
Batch 61/64 loss: 0.2360631823539734
Batch 62/64 loss: 0.23661565780639648
Batch 63/64 loss: 0.23834514617919922
Batch 64/64 loss: 0.23177266120910645
Epoch 205  Train loss: 0.23342772932613598  Val loss: 0.2929326168859947
Epoch 206
-------------------------------
Batch 1/64 loss: 0.2330411672592163
Batch 2/64 loss: 0.23581987619400024
Batch 3/64 loss: 0.23648405075073242
Batch 4/64 loss: 0.2348625659942627
Batch 5/64 loss: 0.23153162002563477
Batch 6/64 loss: 0.2281569242477417
Batch 7/64 loss: 0.2323986291885376
Batch 8/64 loss: 0.22992491722106934
Batch 9/64 loss: 0.2367868423461914
Batch 10/64 loss: 0.23944640159606934
Batch 11/64 loss: 0.2324448823928833
Batch 12/64 loss: 0.235395610332489
Batch 13/64 loss: 0.2281854748725891
Batch 14/64 loss: 0.22805970907211304
Batch 15/64 loss: 0.2298339605331421
Batch 16/64 loss: 0.2259364128112793
Batch 17/64 loss: 0.22468996047973633
Batch 18/64 loss: 0.22940033674240112
Batch 19/64 loss: 0.23429226875305176
Batch 20/64 loss: 0.24105918407440186
Batch 21/64 loss: 0.23092085123062134
Batch 22/64 loss: 0.24227917194366455
Batch 23/64 loss: 0.2377898097038269
Batch 24/64 loss: 0.23485028743743896
Batch 25/64 loss: 0.23108196258544922
Batch 26/64 loss: 0.2257002592086792
Batch 27/64 loss: 0.2339678406715393
Batch 28/64 loss: 0.22977221012115479
Batch 29/64 loss: 0.22992563247680664
Batch 30/64 loss: 0.22536325454711914
Batch 31/64 loss: 0.2434854507446289
Batch 32/64 loss: 0.23331326246261597
Batch 33/64 loss: 0.24248433113098145
Batch 34/64 loss: 0.24949133396148682
Batch 35/64 loss: 0.23487353324890137
Batch 36/64 loss: 0.23934555053710938
Batch 37/64 loss: 0.23307323455810547
Batch 38/64 loss: 0.2362065315246582
Batch 39/64 loss: 0.2406069040298462
Batch 40/64 loss: 0.22877591848373413
Batch 41/64 loss: 0.23156964778900146
Batch 42/64 loss: 0.2357313632965088
Batch 43/64 loss: 0.2307133674621582
Batch 44/64 loss: 0.22941982746124268
Batch 45/64 loss: 0.2265636920928955
Batch 46/64 loss: 0.22708582878112793
Batch 47/64 loss: 0.2286466360092163
Batch 48/64 loss: 0.23649734258651733
Batch 49/64 loss: 0.22960436344146729
Batch 50/64 loss: 0.23286044597625732
Batch 51/64 loss: 0.2328668236732483
Batch 52/64 loss: 0.2343275547027588
Batch 53/64 loss: 0.23089158535003662
Batch 54/64 loss: 0.2534469962120056
Batch 55/64 loss: 0.23845070600509644
Batch 56/64 loss: 0.22521930932998657
Batch 57/64 loss: 0.2388991117477417
Batch 58/64 loss: 0.2307741641998291
Batch 59/64 loss: 0.22302913665771484
Batch 60/64 loss: 0.2304946780204773
Batch 61/64 loss: 0.23331212997436523
Batch 62/64 loss: 0.22718560695648193
Batch 63/64 loss: 0.23266899585723877
Batch 64/64 loss: 0.22658950090408325
Epoch 206  Train loss: 0.2331177970942329  Val loss: 0.2929645104916235
Epoch 207
-------------------------------
Batch 1/64 loss: 0.22207510471343994
Batch 2/64 loss: 0.24288856983184814
Batch 3/64 loss: 0.22861719131469727
Batch 4/64 loss: 0.23064976930618286
Batch 5/64 loss: 0.22922062873840332
Batch 6/64 loss: 0.2264825701713562
Batch 7/64 loss: 0.2231714129447937
Batch 8/64 loss: 0.22756695747375488
Batch 9/64 loss: 0.2311050295829773
Batch 10/64 loss: 0.22704797983169556
Batch 11/64 loss: 0.24269402027130127
Batch 12/64 loss: 0.22309017181396484
Batch 13/64 loss: 0.23288118839263916
Batch 14/64 loss: 0.22721421718597412
Batch 15/64 loss: 0.21871429681777954
Batch 16/64 loss: 0.24322152137756348
Batch 17/64 loss: 0.23022913932800293
Batch 18/64 loss: 0.2333051562309265
Batch 19/64 loss: 0.22368961572647095
Batch 20/64 loss: 0.23436051607131958
Batch 21/64 loss: 0.24950510263442993
Batch 22/64 loss: 0.2217649221420288
Batch 23/64 loss: 0.2289431095123291
Batch 24/64 loss: 0.2427232265472412
Batch 25/64 loss: 0.22888362407684326
Batch 26/64 loss: 0.2241501808166504
Batch 27/64 loss: 0.2361246943473816
Batch 28/64 loss: 0.2199251651763916
Batch 29/64 loss: 0.25053977966308594
Batch 30/64 loss: 0.22783786058425903
Batch 31/64 loss: 0.24454569816589355
Batch 32/64 loss: 0.2254428267478943
Batch 33/64 loss: 0.22999578714370728
Batch 34/64 loss: 0.2297130823135376
Batch 35/64 loss: 0.23544806241989136
Batch 36/64 loss: 0.2364940047264099
Batch 37/64 loss: 0.22434931993484497
Batch 38/64 loss: 0.2289513349533081
Batch 39/64 loss: 0.2388235330581665
Batch 40/64 loss: 0.23262262344360352
Batch 41/64 loss: 0.24219393730163574
Batch 42/64 loss: 0.22316384315490723
Batch 43/64 loss: 0.22919654846191406
Batch 44/64 loss: 0.2393486499786377
Batch 45/64 loss: 0.2333664894104004
Batch 46/64 loss: 0.24737024307250977
Batch 47/64 loss: 0.23561370372772217
Batch 48/64 loss: 0.23134946823120117
Batch 49/64 loss: 0.2335505485534668
Batch 50/64 loss: 0.22814452648162842
Batch 51/64 loss: 0.23398280143737793
Batch 52/64 loss: 0.23125100135803223
Batch 53/64 loss: 0.23666489124298096
Batch 54/64 loss: 0.23280644416809082
Batch 55/64 loss: 0.23367047309875488
Batch 56/64 loss: 0.22758519649505615
Batch 57/64 loss: 0.23272764682769775
Batch 58/64 loss: 0.22899329662322998
Batch 59/64 loss: 0.23917216062545776
Batch 60/64 loss: 0.23590505123138428
Batch 61/64 loss: 0.2313528060913086
Batch 62/64 loss: 0.23185968399047852
Batch 63/64 loss: 0.23810160160064697
Batch 64/64 loss: 0.23750674724578857
Epoch 207  Train loss: 0.23232172657461728  Val loss: 0.29377226219144476
Epoch 208
-------------------------------
Batch 1/64 loss: 0.22798949480056763
Batch 2/64 loss: 0.22832489013671875
Batch 3/64 loss: 0.2229897379875183
Batch 4/64 loss: 0.23529601097106934
Batch 5/64 loss: 0.23174768686294556
Batch 6/64 loss: 0.2257227897644043
Batch 7/64 loss: 0.23444074392318726
Batch 8/64 loss: 0.2309635877609253
Batch 9/64 loss: 0.2422507405281067
Batch 10/64 loss: 0.22485727071762085
Batch 11/64 loss: 0.22538161277770996
Batch 12/64 loss: 0.23537850379943848
Batch 13/64 loss: 0.23313796520233154
Batch 14/64 loss: 0.238366961479187
Batch 15/64 loss: 0.2315598726272583
Batch 16/64 loss: 0.219834566116333
Batch 17/64 loss: 0.23564869165420532
Batch 18/64 loss: 0.22935688495635986
Batch 19/64 loss: 0.22862094640731812
Batch 20/64 loss: 0.23221945762634277
Batch 21/64 loss: 0.2590740919113159
Batch 22/64 loss: 0.24797582626342773
Batch 23/64 loss: 0.23891866207122803
Batch 24/64 loss: 0.238059401512146
Batch 25/64 loss: 0.2297682762145996
Batch 26/64 loss: 0.2436765432357788
Batch 27/64 loss: 0.2314760684967041
Batch 28/64 loss: 0.22641527652740479
Batch 29/64 loss: 0.2377188801765442
Batch 30/64 loss: 0.23020070791244507
Batch 31/64 loss: 0.22889423370361328
Batch 32/64 loss: 0.22839760780334473
Batch 33/64 loss: 0.23056542873382568
Batch 34/64 loss: 0.2303389310836792
Batch 35/64 loss: 0.2247692346572876
Batch 36/64 loss: 0.2287132740020752
Batch 37/64 loss: 0.22388696670532227
Batch 38/64 loss: 0.2334510087966919
Batch 39/64 loss: 0.22428929805755615
Batch 40/64 loss: 0.23682808876037598
Batch 41/64 loss: 0.22580820322036743
Batch 42/64 loss: 0.23210608959197998
Batch 43/64 loss: 0.23703217506408691
Batch 44/64 loss: 0.23954623937606812
Batch 45/64 loss: 0.23608845472335815
Batch 46/64 loss: 0.2368481159210205
Batch 47/64 loss: 0.23483753204345703
Batch 48/64 loss: 0.2303379774093628
Batch 49/64 loss: 0.2444770336151123
Batch 50/64 loss: 0.23350054025650024
Batch 51/64 loss: 0.23600691556930542
Batch 52/64 loss: 0.2290945053100586
Batch 53/64 loss: 0.22390806674957275
Batch 54/64 loss: 0.23399698734283447
Batch 55/64 loss: 0.24638748168945312
Batch 56/64 loss: 0.23680472373962402
Batch 57/64 loss: 0.23651814460754395
Batch 58/64 loss: 0.24118685722351074
Batch 59/64 loss: 0.22629809379577637
Batch 60/64 loss: 0.23980021476745605
Batch 61/64 loss: 0.23219871520996094
Batch 62/64 loss: 0.22845780849456787
Batch 63/64 loss: 0.22919481992721558
Batch 64/64 loss: 0.22651970386505127
Epoch 208  Train loss: 0.23290716386308857  Val loss: 0.29411261106274794
Epoch 209
-------------------------------
Batch 1/64 loss: 0.233168363571167
Batch 2/64 loss: 0.24371099472045898
Batch 3/64 loss: 0.23741883039474487
Batch 4/64 loss: 0.23259717226028442
Batch 5/64 loss: 0.23131537437438965
Batch 6/64 loss: 0.2301335334777832
Batch 7/64 loss: 0.22459781169891357
Batch 8/64 loss: 0.22872304916381836
Batch 9/64 loss: 0.2214198112487793
Batch 10/64 loss: 0.23643475770950317
Batch 11/64 loss: 0.23676037788391113
Batch 12/64 loss: 0.2284584641456604
Batch 13/64 loss: 0.22646063566207886
Batch 14/64 loss: 0.2229222059249878
Batch 15/64 loss: 0.2351895570755005
Batch 16/64 loss: 0.23650634288787842
Batch 17/64 loss: 0.22411686182022095
Batch 18/64 loss: 0.22671103477478027
Batch 19/64 loss: 0.23066651821136475
Batch 20/64 loss: 0.2286696434020996
Batch 21/64 loss: 0.228659987449646
Batch 22/64 loss: 0.2320261001586914
Batch 23/64 loss: 0.22705936431884766
Batch 24/64 loss: 0.2334383726119995
Batch 25/64 loss: 0.22982120513916016
Batch 26/64 loss: 0.22435593605041504
Batch 27/64 loss: 0.24282300472259521
Batch 28/64 loss: 0.24382007122039795
Batch 29/64 loss: 0.22802382707595825
Batch 30/64 loss: 0.22761619091033936
Batch 31/64 loss: 0.23252618312835693
Batch 32/64 loss: 0.23132914304733276
Batch 33/64 loss: 0.23086237907409668
Batch 34/64 loss: 0.23205721378326416
Batch 35/64 loss: 0.2375139594078064
Batch 36/64 loss: 0.23306286334991455
Batch 37/64 loss: 0.22207212448120117
Batch 38/64 loss: 0.24295514822006226
Batch 39/64 loss: 0.22244876623153687
Batch 40/64 loss: 0.23133856058120728
Batch 41/64 loss: 0.23537582159042358
Batch 42/64 loss: 0.2540223002433777
Batch 43/64 loss: 0.22313576936721802
Batch 44/64 loss: 0.22257792949676514
Batch 45/64 loss: 0.2303164005279541
Batch 46/64 loss: 0.23937243223190308
Batch 47/64 loss: 0.22532451152801514
Batch 48/64 loss: 0.2303614616394043
Batch 49/64 loss: 0.22702890634536743
Batch 50/64 loss: 0.2506471872329712
Batch 51/64 loss: 0.23578768968582153
Batch 52/64 loss: 0.22749674320220947
Batch 53/64 loss: 0.2261190414428711
Batch 54/64 loss: 0.23011374473571777
Batch 55/64 loss: 0.2298985719680786
Batch 56/64 loss: 0.2338254451751709
Batch 57/64 loss: 0.22446030378341675
Batch 58/64 loss: 0.2314056158065796
Batch 59/64 loss: 0.23454248905181885
Batch 60/64 loss: 0.23290681838989258
Batch 61/64 loss: 0.22995418310165405
Batch 62/64 loss: 0.25818783044815063
Batch 63/64 loss: 0.22830688953399658
Batch 64/64 loss: 0.24226981401443481
Epoch 209  Train loss: 0.232041759818208  Val loss: 0.293538978829007
Epoch 210
-------------------------------
Batch 1/64 loss: 0.23853105306625366
Batch 2/64 loss: 0.2266436219215393
Batch 3/64 loss: 0.23460233211517334
Batch 4/64 loss: 0.23412227630615234
Batch 5/64 loss: 0.23117387294769287
Batch 6/64 loss: 0.22781896591186523
Batch 7/64 loss: 0.22189867496490479
Batch 8/64 loss: 0.23318302631378174
Batch 9/64 loss: 0.2298756241798401
Batch 10/64 loss: 0.22715044021606445
Batch 11/64 loss: 0.2248990535736084
Batch 12/64 loss: 0.23105335235595703
Batch 13/64 loss: 0.2334432601928711
Batch 14/64 loss: 0.22940969467163086
Batch 15/64 loss: 0.23812109231948853
Batch 16/64 loss: 0.23537927865982056
Batch 17/64 loss: 0.2399601936340332
Batch 18/64 loss: 0.22805219888687134
Batch 19/64 loss: 0.24612176418304443
Batch 20/64 loss: 0.22650384902954102
Batch 21/64 loss: 0.22623419761657715
Batch 22/64 loss: 0.24019360542297363
Batch 23/64 loss: 0.2291731834411621
Batch 24/64 loss: 0.24021118879318237
Batch 25/64 loss: 0.22687840461730957
Batch 26/64 loss: 0.22270262241363525
Batch 27/64 loss: 0.24960124492645264
Batch 28/64 loss: 0.23460471630096436
Batch 29/64 loss: 0.2359369397163391
Batch 30/64 loss: 0.22624588012695312
Batch 31/64 loss: 0.22738409042358398
Batch 32/64 loss: 0.22530609369277954
Batch 33/64 loss: 0.21879231929779053
Batch 34/64 loss: 0.23396283388137817
Batch 35/64 loss: 0.24080157279968262
Batch 36/64 loss: 0.23271781206130981
Batch 37/64 loss: 0.23056823015213013
Batch 38/64 loss: 0.22394222021102905
Batch 39/64 loss: 0.2304213047027588
Batch 40/64 loss: 0.226024329662323
Batch 41/64 loss: 0.22362029552459717
Batch 42/64 loss: 0.2203735113143921
Batch 43/64 loss: 0.23770159482955933
Batch 44/64 loss: 0.23785710334777832
Batch 45/64 loss: 0.24276214838027954
Batch 46/64 loss: 0.23288947343826294
Batch 47/64 loss: 0.2250502109527588
Batch 48/64 loss: 0.23264050483703613
Batch 49/64 loss: 0.23282212018966675
Batch 50/64 loss: 0.23639965057373047
Batch 51/64 loss: 0.23079544305801392
Batch 52/64 loss: 0.23258382081985474
Batch 53/64 loss: 0.23219400644302368
Batch 54/64 loss: 0.23061800003051758
Batch 55/64 loss: 0.2354956865310669
Batch 56/64 loss: 0.23677432537078857
Batch 57/64 loss: 0.23666751384735107
Batch 58/64 loss: 0.2337411642074585
Batch 59/64 loss: 0.2359248399734497
Batch 60/64 loss: 0.21838688850402832
Batch 61/64 loss: 0.22659099102020264
Batch 62/64 loss: 0.2332092523574829
Batch 63/64 loss: 0.2392207384109497
Batch 64/64 loss: 0.22721338272094727
Epoch 210  Train loss: 0.23175491351707309  Val loss: 0.29316510941154766
Epoch 211
-------------------------------
Batch 1/64 loss: 0.22742128372192383
Batch 2/64 loss: 0.22720474004745483
Batch 3/64 loss: 0.23091769218444824
Batch 4/64 loss: 0.23269706964492798
Batch 5/64 loss: 0.22643578052520752
Batch 6/64 loss: 0.24147534370422363
Batch 7/64 loss: 0.234119713306427
Batch 8/64 loss: 0.2362648844718933
Batch 9/64 loss: 0.2275901436805725
Batch 10/64 loss: 0.2295258641242981
Batch 11/64 loss: 0.22170627117156982
Batch 12/64 loss: 0.2236383557319641
Batch 13/64 loss: 0.23747169971466064
Batch 14/64 loss: 0.22781366109848022
Batch 15/64 loss: 0.23038268089294434
Batch 16/64 loss: 0.2338811159133911
Batch 17/64 loss: 0.23261380195617676
Batch 18/64 loss: 0.22492051124572754
Batch 19/64 loss: 0.24153870344161987
Batch 20/64 loss: 0.23192757368087769
Batch 21/64 loss: 0.24107110500335693
Batch 22/64 loss: 0.23488187789916992
Batch 23/64 loss: 0.22327589988708496
Batch 24/64 loss: 0.2236783504486084
Batch 25/64 loss: 0.23589569330215454
Batch 26/64 loss: 0.2216867208480835
Batch 27/64 loss: 0.23621320724487305
Batch 28/64 loss: 0.21954578161239624
Batch 29/64 loss: 0.22556066513061523
Batch 30/64 loss: 0.23127329349517822
Batch 31/64 loss: 0.2406759262084961
Batch 32/64 loss: 0.22730755805969238
Batch 33/64 loss: 0.2258855700492859
Batch 34/64 loss: 0.23418748378753662
Batch 35/64 loss: 0.226878821849823
Batch 36/64 loss: 0.2204188108444214
Batch 37/64 loss: 0.23621141910552979
Batch 38/64 loss: 0.2284119725227356
Batch 39/64 loss: 0.24061328172683716
Batch 40/64 loss: 0.22623968124389648
Batch 41/64 loss: 0.22825759649276733
Batch 42/64 loss: 0.23106443881988525
Batch 43/64 loss: 0.224357008934021
Batch 44/64 loss: 0.23432707786560059
Batch 45/64 loss: 0.24277430772781372
Batch 46/64 loss: 0.22793060541152954
Batch 47/64 loss: 0.23050814867019653
Batch 48/64 loss: 0.23641157150268555
Batch 49/64 loss: 0.22612512111663818
Batch 50/64 loss: 0.23798644542694092
Batch 51/64 loss: 0.2275354266166687
Batch 52/64 loss: 0.23615658283233643
Batch 53/64 loss: 0.24447304010391235
Batch 54/64 loss: 0.22689276933670044
Batch 55/64 loss: 0.2265106439590454
Batch 56/64 loss: 0.23286962509155273
Batch 57/64 loss: 0.23668807744979858
Batch 58/64 loss: 0.23280823230743408
Batch 59/64 loss: 0.2330678105354309
Batch 60/64 loss: 0.24133318662643433
Batch 61/64 loss: 0.23335063457489014
Batch 62/64 loss: 0.22848713397979736
Batch 63/64 loss: 0.2386978268623352
Batch 64/64 loss: 0.24058055877685547
Epoch 211  Train loss: 0.23150601948008817  Val loss: 0.2932503250046694
Epoch 212
-------------------------------
Batch 1/64 loss: 0.23397207260131836
Batch 2/64 loss: 0.2250211238861084
Batch 3/64 loss: 0.23603475093841553
Batch 4/64 loss: 0.2270216941833496
Batch 5/64 loss: 0.23052912950515747
Batch 6/64 loss: 0.22838366031646729
Batch 7/64 loss: 0.2359524369239807
Batch 8/64 loss: 0.23534148931503296
Batch 9/64 loss: 0.23202800750732422
Batch 10/64 loss: 0.22232449054718018
Batch 11/64 loss: 0.24069619178771973
Batch 12/64 loss: 0.2344353199005127
Batch 13/64 loss: 0.2235558032989502
Batch 14/64 loss: 0.23307782411575317
Batch 15/64 loss: 0.23322707414627075
Batch 16/64 loss: 0.23485875129699707
Batch 17/64 loss: 0.22780966758728027
Batch 18/64 loss: 0.2410966157913208
Batch 19/64 loss: 0.22637736797332764
Batch 20/64 loss: 0.23265492916107178
Batch 21/64 loss: 0.2301102876663208
Batch 22/64 loss: 0.238197922706604
Batch 23/64 loss: 0.23426079750061035
Batch 24/64 loss: 0.22109389305114746
Batch 25/64 loss: 0.22948020696640015
Batch 26/64 loss: 0.23301666975021362
Batch 27/64 loss: 0.24791347980499268
Batch 28/64 loss: 0.22626686096191406
Batch 29/64 loss: 0.24045467376708984
Batch 30/64 loss: 0.24137765169143677
Batch 31/64 loss: 0.24417555332183838
Batch 32/64 loss: 0.230241060256958
Batch 33/64 loss: 0.2265796661376953
Batch 34/64 loss: 0.2288019061088562
Batch 35/64 loss: 0.22759956121444702
Batch 36/64 loss: 0.22768950462341309
Batch 37/64 loss: 0.250216007232666
Batch 38/64 loss: 0.2431696057319641
Batch 39/64 loss: 0.22835129499435425
Batch 40/64 loss: 0.23612916469573975
Batch 41/64 loss: 0.23059558868408203
Batch 42/64 loss: 0.23493236303329468
Batch 43/64 loss: 0.2245575189590454
Batch 44/64 loss: 0.21860063076019287
Batch 45/64 loss: 0.23166203498840332
Batch 46/64 loss: 0.22327017784118652
Batch 47/64 loss: 0.22076904773712158
Batch 48/64 loss: 0.2324690818786621
Batch 49/64 loss: 0.23111039400100708
Batch 50/64 loss: 0.22728276252746582
Batch 51/64 loss: 0.22964686155319214
Batch 52/64 loss: 0.2265336513519287
Batch 53/64 loss: 0.23717743158340454
Batch 54/64 loss: 0.2250005006790161
Batch 55/64 loss: 0.22838687896728516
Batch 56/64 loss: 0.2230963110923767
Batch 57/64 loss: 0.23468393087387085
Batch 58/64 loss: 0.23905599117279053
Batch 59/64 loss: 0.2275683879852295
Batch 60/64 loss: 0.23009061813354492
Batch 61/64 loss: 0.22830820083618164
Batch 62/64 loss: 0.23876655101776123
Batch 63/64 loss: 0.234624445438385
Batch 64/64 loss: 0.2388743758201599
Epoch 212  Train loss: 0.23179402842241176  Val loss: 0.2930200865997891
Epoch 213
-------------------------------
Batch 1/64 loss: 0.2388402223587036
Batch 2/64 loss: 0.23107481002807617
Batch 3/64 loss: 0.22677981853485107
Batch 4/64 loss: 0.22967642545700073
Batch 5/64 loss: 0.23670965433120728
Batch 6/64 loss: 0.2287110686302185
Batch 7/64 loss: 0.22671425342559814
Batch 8/64 loss: 0.22269010543823242
Batch 9/64 loss: 0.23105454444885254
Batch 10/64 loss: 0.2279822826385498
Batch 11/64 loss: 0.23491966724395752
Batch 12/64 loss: 0.2451162338256836
Batch 13/64 loss: 0.22978883981704712
Batch 14/64 loss: 0.23768162727355957
Batch 15/64 loss: 0.23286974430084229
Batch 16/64 loss: 0.22997713088989258
Batch 17/64 loss: 0.2237255573272705
Batch 18/64 loss: 0.21715062856674194
Batch 19/64 loss: 0.23048830032348633
Batch 20/64 loss: 0.2285810112953186
Batch 21/64 loss: 0.2403133511543274
Batch 22/64 loss: 0.2300705909729004
Batch 23/64 loss: 0.22439688444137573
Batch 24/64 loss: 0.22536969184875488
Batch 25/64 loss: 0.23114287853240967
Batch 26/64 loss: 0.22937452793121338
Batch 27/64 loss: 0.22537869215011597
Batch 28/64 loss: 0.23676258325576782
Batch 29/64 loss: 0.22634851932525635
Batch 30/64 loss: 0.22122669219970703
Batch 31/64 loss: 0.22774583101272583
Batch 32/64 loss: 0.22734856605529785
Batch 33/64 loss: 0.23305296897888184
Batch 34/64 loss: 0.24331355094909668
Batch 35/64 loss: 0.22664415836334229
Batch 36/64 loss: 0.23754501342773438
Batch 37/64 loss: 0.23277604579925537
Batch 38/64 loss: 0.2329537272453308
Batch 39/64 loss: 0.23466497659683228
Batch 40/64 loss: 0.2289065718650818
Batch 41/64 loss: 0.22882157564163208
Batch 42/64 loss: 0.22964167594909668
Batch 43/64 loss: 0.23656350374221802
Batch 44/64 loss: 0.2325577735900879
Batch 45/64 loss: 0.22490429878234863
Batch 46/64 loss: 0.22443413734436035
Batch 47/64 loss: 0.2300633192062378
Batch 48/64 loss: 0.23220860958099365
Batch 49/64 loss: 0.2355220913887024
Batch 50/64 loss: 0.23465019464492798
Batch 51/64 loss: 0.23292821645736694
Batch 52/64 loss: 0.225638747215271
Batch 53/64 loss: 0.23907208442687988
Batch 54/64 loss: 0.23171836137771606
Batch 55/64 loss: 0.22757339477539062
Batch 56/64 loss: 0.2264847755432129
Batch 57/64 loss: 0.23165631294250488
Batch 58/64 loss: 0.23559856414794922
Batch 59/64 loss: 0.23364925384521484
Batch 60/64 loss: 0.22981411218643188
Batch 61/64 loss: 0.22974395751953125
Batch 62/64 loss: 0.23236119747161865
Batch 63/64 loss: 0.23362314701080322
Batch 64/64 loss: 0.221119225025177
Epoch 213  Train loss: 0.23075978779325299  Val loss: 0.2939199114992856
Epoch 214
-------------------------------
Batch 1/64 loss: 0.22855424880981445
Batch 2/64 loss: 0.2340412735939026
Batch 3/64 loss: 0.22035956382751465
Batch 4/64 loss: 0.23118549585342407
Batch 5/64 loss: 0.23294103145599365
Batch 6/64 loss: 0.22487318515777588
Batch 7/64 loss: 0.22761595249176025
Batch 8/64 loss: 0.23194700479507446
Batch 9/64 loss: 0.22442328929901123
Batch 10/64 loss: 0.23680388927459717
Batch 11/64 loss: 0.23950982093811035
Batch 12/64 loss: 0.2341066598892212
Batch 13/64 loss: 0.22650498151779175
Batch 14/64 loss: 0.23439347743988037
Batch 15/64 loss: 0.22169935703277588
Batch 16/64 loss: 0.22596657276153564
Batch 17/64 loss: 0.22483432292938232
Batch 18/64 loss: 0.2297126054763794
Batch 19/64 loss: 0.24003958702087402
Batch 20/64 loss: 0.23455941677093506
Batch 21/64 loss: 0.22968435287475586
Batch 22/64 loss: 0.22501027584075928
Batch 23/64 loss: 0.23225706815719604
Batch 24/64 loss: 0.22185909748077393
Batch 25/64 loss: 0.2271694540977478
Batch 26/64 loss: 0.22866493463516235
Batch 27/64 loss: 0.22731584310531616
Batch 28/64 loss: 0.22844433784484863
Batch 29/64 loss: 0.22849756479263306
Batch 30/64 loss: 0.23428815603256226
Batch 31/64 loss: 0.22267162799835205
Batch 32/64 loss: 0.2395648956298828
Batch 33/64 loss: 0.22615408897399902
Batch 34/64 loss: 0.23488497734069824
Batch 35/64 loss: 0.22002267837524414
Batch 36/64 loss: 0.22255009412765503
Batch 37/64 loss: 0.23365139961242676
Batch 38/64 loss: 0.2286529541015625
Batch 39/64 loss: 0.22117865085601807
Batch 40/64 loss: 0.2411748766899109
Batch 41/64 loss: 0.22216355800628662
Batch 42/64 loss: 0.2229076623916626
Batch 43/64 loss: 0.2336788773536682
Batch 44/64 loss: 0.2282753586769104
Batch 45/64 loss: 0.2426963448524475
Batch 46/64 loss: 0.23071038722991943
Batch 47/64 loss: 0.24070006608963013
Batch 48/64 loss: 0.23299241065979004
Batch 49/64 loss: 0.2243485450744629
Batch 50/64 loss: 0.22356784343719482
Batch 51/64 loss: 0.2320692539215088
Batch 52/64 loss: 0.22959113121032715
Batch 53/64 loss: 0.23743277788162231
Batch 54/64 loss: 0.23209446668624878
Batch 55/64 loss: 0.23951208591461182
Batch 56/64 loss: 0.23485791683197021
Batch 57/64 loss: 0.22601550817489624
Batch 58/64 loss: 0.23346447944641113
Batch 59/64 loss: 0.23630481958389282
Batch 60/64 loss: 0.23426371812820435
Batch 61/64 loss: 0.23977971076965332
Batch 62/64 loss: 0.23830389976501465
Batch 63/64 loss: 0.2405383586883545
Batch 64/64 loss: 0.23303353786468506
Epoch 214  Train loss: 0.23072648469139548  Val loss: 0.29331703632557926
Epoch 215
-------------------------------
Batch 1/64 loss: 0.22449392080307007
Batch 2/64 loss: 0.2287030816078186
Batch 3/64 loss: 0.2193535566329956
Batch 4/64 loss: 0.23107117414474487
Batch 5/64 loss: 0.2214057445526123
Batch 6/64 loss: 0.2333449125289917
Batch 7/64 loss: 0.2281385064125061
Batch 8/64 loss: 0.22634565830230713
Batch 9/64 loss: 0.23713725805282593
Batch 10/64 loss: 0.2184232473373413
Batch 11/64 loss: 0.22952431440353394
Batch 12/64 loss: 0.21950215101242065
Batch 13/64 loss: 0.23602443933486938
Batch 14/64 loss: 0.2354215383529663
Batch 15/64 loss: 0.23319005966186523
Batch 16/64 loss: 0.2318958044052124
Batch 17/64 loss: 0.22356641292572021
Batch 18/64 loss: 0.22303128242492676
Batch 19/64 loss: 0.24194341897964478
Batch 20/64 loss: 0.23392629623413086
Batch 21/64 loss: 0.24087882041931152
Batch 22/64 loss: 0.2319825291633606
Batch 23/64 loss: 0.22736656665802002
Batch 24/64 loss: 0.22687971591949463
Batch 25/64 loss: 0.2405351996421814
Batch 26/64 loss: 0.2235645055770874
Batch 27/64 loss: 0.23533451557159424
Batch 28/64 loss: 0.23592329025268555
Batch 29/64 loss: 0.22371035814285278
Batch 30/64 loss: 0.2227935791015625
Batch 31/64 loss: 0.24503111839294434
Batch 32/64 loss: 0.22681653499603271
Batch 33/64 loss: 0.22397339344024658
Batch 34/64 loss: 0.22133022546768188
Batch 35/64 loss: 0.2390926480293274
Batch 36/64 loss: 0.22258424758911133
Batch 37/64 loss: 0.2220362424850464
Batch 38/64 loss: 0.22828412055969238
Batch 39/64 loss: 0.23888659477233887
Batch 40/64 loss: 0.22406089305877686
Batch 41/64 loss: 0.23581290245056152
Batch 42/64 loss: 0.2230088710784912
Batch 43/64 loss: 0.22628402709960938
Batch 44/64 loss: 0.24492108821868896
Batch 45/64 loss: 0.22507953643798828
Batch 46/64 loss: 0.22901254892349243
Batch 47/64 loss: 0.2358947992324829
Batch 48/64 loss: 0.22119522094726562
Batch 49/64 loss: 0.24350368976593018
Batch 50/64 loss: 0.22693073749542236
Batch 51/64 loss: 0.2417171597480774
Batch 52/64 loss: 0.22719663381576538
Batch 53/64 loss: 0.2293211817741394
Batch 54/64 loss: 0.23698914051055908
Batch 55/64 loss: 0.2226874828338623
Batch 56/64 loss: 0.23895204067230225
Batch 57/64 loss: 0.2267444133758545
Batch 58/64 loss: 0.23044085502624512
Batch 59/64 loss: 0.22621476650238037
Batch 60/64 loss: 0.22591686248779297
Batch 61/64 loss: 0.23438608646392822
Batch 62/64 loss: 0.23446106910705566
Batch 63/64 loss: 0.22544199228286743
Batch 64/64 loss: 0.22582870721817017
Epoch 215  Train loss: 0.22994498061198815  Val loss: 0.2934719793165672
Epoch 216
-------------------------------
Batch 1/64 loss: 0.2340618371963501
Batch 2/64 loss: 0.23685795068740845
Batch 3/64 loss: 0.23512506484985352
Batch 4/64 loss: 0.22483664751052856
Batch 5/64 loss: 0.2414839267730713
Batch 6/64 loss: 0.22154712677001953
Batch 7/64 loss: 0.22213470935821533
Batch 8/64 loss: 0.2244187593460083
Batch 9/64 loss: 0.23524045944213867
Batch 10/64 loss: 0.22705340385437012
Batch 11/64 loss: 0.23254889249801636
Batch 12/64 loss: 0.22875618934631348
Batch 13/64 loss: 0.22481656074523926
Batch 14/64 loss: 0.2215336561203003
Batch 15/64 loss: 0.22178614139556885
Batch 16/64 loss: 0.2308318018913269
Batch 17/64 loss: 0.22372221946716309
Batch 18/64 loss: 0.23490619659423828
Batch 19/64 loss: 0.22370564937591553
Batch 20/64 loss: 0.23488187789916992
Batch 21/64 loss: 0.23283547163009644
Batch 22/64 loss: 0.22788071632385254
Batch 23/64 loss: 0.22075438499450684
Batch 24/64 loss: 0.22532016038894653
Batch 25/64 loss: 0.2295251488685608
Batch 26/64 loss: 0.2274269461631775
Batch 27/64 loss: 0.2413264513015747
Batch 28/64 loss: 0.22745442390441895
Batch 29/64 loss: 0.23182761669158936
Batch 30/64 loss: 0.23776018619537354
Batch 31/64 loss: 0.21944081783294678
Batch 32/64 loss: 0.2329244613647461
Batch 33/64 loss: 0.22662460803985596
Batch 34/64 loss: 0.2267777919769287
Batch 35/64 loss: 0.22857040166854858
Batch 36/64 loss: 0.22774440050125122
Batch 37/64 loss: 0.23057717084884644
Batch 38/64 loss: 0.2288583517074585
Batch 39/64 loss: 0.23416900634765625
Batch 40/64 loss: 0.2328827977180481
Batch 41/64 loss: 0.22721576690673828
Batch 42/64 loss: 0.23142695426940918
Batch 43/64 loss: 0.24030345678329468
Batch 44/64 loss: 0.22519564628601074
Batch 45/64 loss: 0.23526054620742798
Batch 46/64 loss: 0.23281526565551758
Batch 47/64 loss: 0.2474132776260376
Batch 48/64 loss: 0.22512519359588623
Batch 49/64 loss: 0.2226041555404663
Batch 50/64 loss: 0.2360668182373047
Batch 51/64 loss: 0.2273908257484436
Batch 52/64 loss: 0.22472095489501953
Batch 53/64 loss: 0.23109853267669678
Batch 54/64 loss: 0.23073309659957886
Batch 55/64 loss: 0.22706735134124756
Batch 56/64 loss: 0.23391193151474
Batch 57/64 loss: 0.22488141059875488
Batch 58/64 loss: 0.22551965713500977
Batch 59/64 loss: 0.2252514362335205
Batch 60/64 loss: 0.24215483665466309
Batch 61/64 loss: 0.22626978158950806
Batch 62/64 loss: 0.2249271273612976
Batch 63/64 loss: 0.24139803647994995
Batch 64/64 loss: 0.22903960943222046
Epoch 216  Train loss: 0.2298268572956908  Val loss: 0.29403245346652684
Epoch 217
-------------------------------
Batch 1/64 loss: 0.2338564395904541
Batch 2/64 loss: 0.2257370948791504
Batch 3/64 loss: 0.2331092357635498
Batch 4/64 loss: 0.23040592670440674
Batch 5/64 loss: 0.22589325904846191
Batch 6/64 loss: 0.2274654507637024
Batch 7/64 loss: 0.23093754053115845
Batch 8/64 loss: 0.2202717661857605
Batch 9/64 loss: 0.22524559497833252
Batch 10/64 loss: 0.22392654418945312
Batch 11/64 loss: 0.2252030372619629
Batch 12/64 loss: 0.23590993881225586
Batch 13/64 loss: 0.2305017113685608
Batch 14/64 loss: 0.23136740922927856
Batch 15/64 loss: 0.23428797721862793
Batch 16/64 loss: 0.22552835941314697
Batch 17/64 loss: 0.24057453870773315
Batch 18/64 loss: 0.22436624765396118
Batch 19/64 loss: 0.2296680212020874
Batch 20/64 loss: 0.21896636486053467
Batch 21/64 loss: 0.2292608618736267
Batch 22/64 loss: 0.2346048355102539
Batch 23/64 loss: 0.22387778759002686
Batch 24/64 loss: 0.2279086709022522
Batch 25/64 loss: 0.22867906093597412
Batch 26/64 loss: 0.2293931245803833
Batch 27/64 loss: 0.22331851720809937
Batch 28/64 loss: 0.2235819697380066
Batch 29/64 loss: 0.24352258443832397
Batch 30/64 loss: 0.22723811864852905
Batch 31/64 loss: 0.2308865785598755
Batch 32/64 loss: 0.2295283079147339
Batch 33/64 loss: 0.23640310764312744
Batch 34/64 loss: 0.2300422191619873
Batch 35/64 loss: 0.23188269138336182
Batch 36/64 loss: 0.22154498100280762
Batch 37/64 loss: 0.2314697504043579
Batch 38/64 loss: 0.24099057912826538
Batch 39/64 loss: 0.23528599739074707
Batch 40/64 loss: 0.22733867168426514
Batch 41/64 loss: 0.22265905141830444
Batch 42/64 loss: 0.22703969478607178
Batch 43/64 loss: 0.23483407497406006
Batch 44/64 loss: 0.2319096326828003
Batch 45/64 loss: 0.22341293096542358
Batch 46/64 loss: 0.2379676103591919
Batch 47/64 loss: 0.22497165203094482
Batch 48/64 loss: 0.22612178325653076
Batch 49/64 loss: 0.23230516910552979
Batch 50/64 loss: 0.2313280701637268
Batch 51/64 loss: 0.22049236297607422
Batch 52/64 loss: 0.22217774391174316
Batch 53/64 loss: 0.22134947776794434
Batch 54/64 loss: 0.2350766658782959
Batch 55/64 loss: 0.22515559196472168
Batch 56/64 loss: 0.22099822759628296
Batch 57/64 loss: 0.23197674751281738
Batch 58/64 loss: 0.23846209049224854
Batch 59/64 loss: 0.23446416854858398
Batch 60/64 loss: 0.24375486373901367
Batch 61/64 loss: 0.22866302728652954
Batch 62/64 loss: 0.2301732897758484
Batch 63/64 loss: 0.22240805625915527
Batch 64/64 loss: 0.2270604372024536
Epoch 217  Train loss: 0.2293016185947493  Val loss: 0.29389205544265273
Epoch 218
-------------------------------
Batch 1/64 loss: 0.2391597032546997
Batch 2/64 loss: 0.23309558629989624
Batch 3/64 loss: 0.23263335227966309
Batch 4/64 loss: 0.22928494215011597
Batch 5/64 loss: 0.2271997332572937
Batch 6/64 loss: 0.22016620635986328
Batch 7/64 loss: 0.23298275470733643
Batch 8/64 loss: 0.22419381141662598
Batch 9/64 loss: 0.23373055458068848
Batch 10/64 loss: 0.22969865798950195
Batch 11/64 loss: 0.2277904748916626
Batch 12/64 loss: 0.22731363773345947
Batch 13/64 loss: 0.22293007373809814
Batch 14/64 loss: 0.23827725648880005
Batch 15/64 loss: 0.2296675443649292
Batch 16/64 loss: 0.22542047500610352
Batch 17/64 loss: 0.21804136037826538
Batch 18/64 loss: 0.22380632162094116
Batch 19/64 loss: 0.22519731521606445
Batch 20/64 loss: 0.22574234008789062
Batch 21/64 loss: 0.22515296936035156
Batch 22/64 loss: 0.2293950319290161
Batch 23/64 loss: 0.2277909517288208
Batch 24/64 loss: 0.2213570475578308
Batch 25/64 loss: 0.224770188331604
Batch 26/64 loss: 0.23339170217514038
Batch 27/64 loss: 0.22670137882232666
Batch 28/64 loss: 0.22392189502716064
Batch 29/64 loss: 0.22553324699401855
Batch 30/64 loss: 0.22708964347839355
Batch 31/64 loss: 0.22240716218948364
Batch 32/64 loss: 0.23680150508880615
Batch 33/64 loss: 0.23298704624176025
Batch 34/64 loss: 0.23107731342315674
Batch 35/64 loss: 0.21996808052062988
Batch 36/64 loss: 0.23610591888427734
Batch 37/64 loss: 0.22421586513519287
Batch 38/64 loss: 0.227924644947052
Batch 39/64 loss: 0.22683358192443848
Batch 40/64 loss: 0.22189050912857056
Batch 41/64 loss: 0.23006033897399902
Batch 42/64 loss: 0.22401666641235352
Batch 43/64 loss: 0.23180973529815674
Batch 44/64 loss: 0.22297191619873047
Batch 45/64 loss: 0.2404215931892395
Batch 46/64 loss: 0.25025510787963867
Batch 47/64 loss: 0.22264671325683594
Batch 48/64 loss: 0.22507870197296143
Batch 49/64 loss: 0.23986685276031494
Batch 50/64 loss: 0.24092644453048706
Batch 51/64 loss: 0.2284889817237854
Batch 52/64 loss: 0.23636329174041748
Batch 53/64 loss: 0.22617745399475098
Batch 54/64 loss: 0.23366588354110718
Batch 55/64 loss: 0.23297739028930664
Batch 56/64 loss: 0.2393016815185547
Batch 57/64 loss: 0.2325044870376587
Batch 58/64 loss: 0.23377740383148193
Batch 59/64 loss: 0.22667551040649414
Batch 60/64 loss: 0.23196512460708618
Batch 61/64 loss: 0.22069406509399414
Batch 62/64 loss: 0.2435307502746582
Batch 63/64 loss: 0.2327514886856079
Batch 64/64 loss: 0.23477530479431152
Epoch 218  Train loss: 0.22956324465134564  Val loss: 0.29347530836911545
Epoch 219
-------------------------------
Batch 1/64 loss: 0.22858822345733643
Batch 2/64 loss: 0.22683459520339966
Batch 3/64 loss: 0.21840131282806396
Batch 4/64 loss: 0.22126686573028564
Batch 5/64 loss: 0.22350573539733887
Batch 6/64 loss: 0.23540902137756348
Batch 7/64 loss: 0.22105950117111206
Batch 8/64 loss: 0.22785240411758423
Batch 9/64 loss: 0.232049822807312
Batch 10/64 loss: 0.21676921844482422
Batch 11/64 loss: 0.23465806245803833
Batch 12/64 loss: 0.22299659252166748
Batch 13/64 loss: 0.22937524318695068
Batch 14/64 loss: 0.25129324197769165
Batch 15/64 loss: 0.23401862382888794
Batch 16/64 loss: 0.23410451412200928
Batch 17/64 loss: 0.22566944360733032
Batch 18/64 loss: 0.24626821279525757
Batch 19/64 loss: 0.2226683497428894
Batch 20/64 loss: 0.2255399227142334
Batch 21/64 loss: 0.22744613885879517
Batch 22/64 loss: 0.23061764240264893
Batch 23/64 loss: 0.2264317274093628
Batch 24/64 loss: 0.23641633987426758
Batch 25/64 loss: 0.22665828466415405
Batch 26/64 loss: 0.22529929876327515
Batch 27/64 loss: 0.23575401306152344
Batch 28/64 loss: 0.2320265769958496
Batch 29/64 loss: 0.23253852128982544
Batch 30/64 loss: 0.23306572437286377
Batch 31/64 loss: 0.23000717163085938
Batch 32/64 loss: 0.23465478420257568
Batch 33/64 loss: 0.22203516960144043
Batch 34/64 loss: 0.22772860527038574
Batch 35/64 loss: 0.22424256801605225
Batch 36/64 loss: 0.22861260175704956
Batch 37/64 loss: 0.22150695323944092
Batch 38/64 loss: 0.21699941158294678
Batch 39/64 loss: 0.2415241003036499
Batch 40/64 loss: 0.24799633026123047
Batch 41/64 loss: 0.2320847511291504
Batch 42/64 loss: 0.23959338665008545
Batch 43/64 loss: 0.2323474884033203
Batch 44/64 loss: 0.22436213493347168
Batch 45/64 loss: 0.23043060302734375
Batch 46/64 loss: 0.2294403314590454
Batch 47/64 loss: 0.2358459234237671
Batch 48/64 loss: 0.23080193996429443
Batch 49/64 loss: 0.2423143982887268
Batch 50/64 loss: 0.2319042682647705
Batch 51/64 loss: 0.23316943645477295
Batch 52/64 loss: 0.22466158866882324
Batch 53/64 loss: 0.24265003204345703
Batch 54/64 loss: 0.22915267944335938
Batch 55/64 loss: 0.22306692600250244
Batch 56/64 loss: 0.23055636882781982
Batch 57/64 loss: 0.22827666997909546
Batch 58/64 loss: 0.22938036918640137
Batch 59/64 loss: 0.23360168933868408
Batch 60/64 loss: 0.23282390832901
Batch 61/64 loss: 0.23772335052490234
Batch 62/64 loss: 0.23936575651168823
Batch 63/64 loss: 0.23004090785980225
Batch 64/64 loss: 0.23243820667266846
Epoch 219  Train loss: 0.23055395191791012  Val loss: 0.29396962054406656
Epoch 220
-------------------------------
Batch 1/64 loss: 0.22446441650390625
Batch 2/64 loss: 0.2199518084526062
Batch 3/64 loss: 0.22904115915298462
Batch 4/64 loss: 0.2248222827911377
Batch 5/64 loss: 0.22676336765289307
Batch 6/64 loss: 0.23079776763916016
Batch 7/64 loss: 0.23150861263275146
Batch 8/64 loss: 0.23596906661987305
Batch 9/64 loss: 0.2370154857635498
Batch 10/64 loss: 0.21748507022857666
Batch 11/64 loss: 0.22932565212249756
Batch 12/64 loss: 0.2249000072479248
Batch 13/64 loss: 0.23635905981063843
Batch 14/64 loss: 0.2276403307914734
Batch 15/64 loss: 0.239851713180542
Batch 16/64 loss: 0.22707414627075195
Batch 17/64 loss: 0.2235836386680603
Batch 18/64 loss: 0.22281503677368164
Batch 19/64 loss: 0.23588979244232178
Batch 20/64 loss: 0.22903889417648315
Batch 21/64 loss: 0.23218822479248047
Batch 22/64 loss: 0.22787684202194214
Batch 23/64 loss: 0.2171141505241394
Batch 24/64 loss: 0.23494040966033936
Batch 25/64 loss: 0.2305700182914734
Batch 26/64 loss: 0.2196791172027588
Batch 27/64 loss: 0.2345350980758667
Batch 28/64 loss: 0.23846513032913208
Batch 29/64 loss: 0.22884011268615723
Batch 30/64 loss: 0.21935820579528809
Batch 31/64 loss: 0.22188818454742432
Batch 32/64 loss: 0.23517495393753052
Batch 33/64 loss: 0.2283654808998108
Batch 34/64 loss: 0.22510647773742676
Batch 35/64 loss: 0.23216724395751953
Batch 36/64 loss: 0.22805452346801758
Batch 37/64 loss: 0.2169191837310791
Batch 38/64 loss: 0.23132383823394775
Batch 39/64 loss: 0.23413193225860596
Batch 40/64 loss: 0.2417771816253662
Batch 41/64 loss: 0.2317126989364624
Batch 42/64 loss: 0.22561883926391602
Batch 43/64 loss: 0.23229598999023438
Batch 44/64 loss: 0.22717136144638062
Batch 45/64 loss: 0.22776281833648682
Batch 46/64 loss: 0.23748326301574707
Batch 47/64 loss: 0.23268377780914307
Batch 48/64 loss: 0.22065770626068115
Batch 49/64 loss: 0.24593806266784668
Batch 50/64 loss: 0.21853208541870117
Batch 51/64 loss: 0.23893356323242188
Batch 52/64 loss: 0.22342538833618164
Batch 53/64 loss: 0.2273382544517517
Batch 54/64 loss: 0.22104084491729736
Batch 55/64 loss: 0.2291187047958374
Batch 56/64 loss: 0.22421491146087646
Batch 57/64 loss: 0.23056745529174805
Batch 58/64 loss: 0.23572152853012085
Batch 59/64 loss: 0.23149389028549194
Batch 60/64 loss: 0.22816967964172363
Batch 61/64 loss: 0.23521113395690918
Batch 62/64 loss: 0.23294901847839355
Batch 63/64 loss: 0.22883301973342896
Batch 64/64 loss: 0.23753619194030762
Epoch 220  Train loss: 0.22929881974762562  Val loss: 0.29263266992732834
Epoch 221
-------------------------------
Batch 1/64 loss: 0.2192744016647339
Batch 2/64 loss: 0.22269999980926514
Batch 3/64 loss: 0.21725887060165405
Batch 4/64 loss: 0.22258353233337402
Batch 5/64 loss: 0.21641302108764648
Batch 6/64 loss: 0.23125696182250977
Batch 7/64 loss: 0.2276911735534668
Batch 8/64 loss: 0.2292414903640747
Batch 9/64 loss: 0.22999751567840576
Batch 10/64 loss: 0.2273876667022705
Batch 11/64 loss: 0.22732794284820557
Batch 12/64 loss: 0.2293739914894104
Batch 13/64 loss: 0.22388499975204468
Batch 14/64 loss: 0.2326943278312683
Batch 15/64 loss: 0.22118639945983887
Batch 16/64 loss: 0.23925411701202393
Batch 17/64 loss: 0.22405850887298584
Batch 18/64 loss: 0.23568612337112427
Batch 19/64 loss: 0.2381913661956787
Batch 20/64 loss: 0.23403537273406982
Batch 21/64 loss: 0.22045421600341797
Batch 22/64 loss: 0.22998440265655518
Batch 23/64 loss: 0.22537612915039062
Batch 24/64 loss: 0.21946698427200317
Batch 25/64 loss: 0.23856717348098755
Batch 26/64 loss: 0.23344242572784424
Batch 27/64 loss: 0.23406332731246948
Batch 28/64 loss: 0.21677207946777344
Batch 29/64 loss: 0.22545868158340454
Batch 30/64 loss: 0.2326645851135254
Batch 31/64 loss: 0.22954058647155762
Batch 32/64 loss: 0.23042500019073486
Batch 33/64 loss: 0.2320082187652588
Batch 34/64 loss: 0.21851706504821777
Batch 35/64 loss: 0.2204180359840393
Batch 36/64 loss: 0.2306206226348877
Batch 37/64 loss: 0.22786372900009155
Batch 38/64 loss: 0.22640138864517212
Batch 39/64 loss: 0.22693943977355957
Batch 40/64 loss: 0.23042434453964233
Batch 41/64 loss: 0.2224758267402649
Batch 42/64 loss: 0.22421550750732422
Batch 43/64 loss: 0.2368534803390503
Batch 44/64 loss: 0.2325303554534912
Batch 45/64 loss: 0.23593556880950928
Batch 46/64 loss: 0.22838056087493896
Batch 47/64 loss: 0.22519975900650024
Batch 48/64 loss: 0.2242090106010437
Batch 49/64 loss: 0.23230111598968506
Batch 50/64 loss: 0.22904741764068604
Batch 51/64 loss: 0.2280818223953247
Batch 52/64 loss: 0.23324120044708252
Batch 53/64 loss: 0.24836957454681396
Batch 54/64 loss: 0.23920190334320068
Batch 55/64 loss: 0.2263784408569336
Batch 56/64 loss: 0.22979635000228882
Batch 57/64 loss: 0.23189198970794678
Batch 58/64 loss: 0.23280596733093262
Batch 59/64 loss: 0.2340611219406128
Batch 60/64 loss: 0.22881412506103516
Batch 61/64 loss: 0.22621071338653564
Batch 62/64 loss: 0.23510754108428955
Batch 63/64 loss: 0.22193479537963867
Batch 64/64 loss: 0.22476887702941895
Epoch 221  Train loss: 0.22862003176820045  Val loss: 0.293301639687974
Epoch 222
-------------------------------
Batch 1/64 loss: 0.22317588329315186
Batch 2/64 loss: 0.229509174823761
Batch 3/64 loss: 0.2321408987045288
Batch 4/64 loss: 0.24520647525787354
Batch 5/64 loss: 0.23191428184509277
Batch 6/64 loss: 0.22396349906921387
Batch 7/64 loss: 0.22253131866455078
Batch 8/64 loss: 0.23294931650161743
Batch 9/64 loss: 0.22625255584716797
Batch 10/64 loss: 0.232793390750885
Batch 11/64 loss: 0.22560298442840576
Batch 12/64 loss: 0.21912777423858643
Batch 13/64 loss: 0.22742241621017456
Batch 14/64 loss: 0.23465299606323242
Batch 15/64 loss: 0.23051071166992188
Batch 16/64 loss: 0.22288262844085693
Batch 17/64 loss: 0.23234105110168457
Batch 18/64 loss: 0.22426104545593262
Batch 19/64 loss: 0.21933972835540771
Batch 20/64 loss: 0.22919678688049316
Batch 21/64 loss: 0.2158982753753662
Batch 22/64 loss: 0.2200135588645935
Batch 23/64 loss: 0.21766287088394165
Batch 24/64 loss: 0.22452449798583984
Batch 25/64 loss: 0.239740788936615
Batch 26/64 loss: 0.23087221384048462
Batch 27/64 loss: 0.23562932014465332
Batch 28/64 loss: 0.22637081146240234
Batch 29/64 loss: 0.236577570438385
Batch 30/64 loss: 0.22192645072937012
Batch 31/64 loss: 0.21984219551086426
Batch 32/64 loss: 0.22410011291503906
Batch 33/64 loss: 0.220434308052063
Batch 34/64 loss: 0.23252403736114502
Batch 35/64 loss: 0.23559844493865967
Batch 36/64 loss: 0.2312023639678955
Batch 37/64 loss: 0.22464507818222046
Batch 38/64 loss: 0.23289930820465088
Batch 39/64 loss: 0.23874205350875854
Batch 40/64 loss: 0.2242445945739746
Batch 41/64 loss: 0.22315961122512817
Batch 42/64 loss: 0.22547012567520142
Batch 43/64 loss: 0.225921630859375
Batch 44/64 loss: 0.2382831573486328
Batch 45/64 loss: 0.2248767614364624
Batch 46/64 loss: 0.22427213191986084
Batch 47/64 loss: 0.22990167140960693
Batch 48/64 loss: 0.22922784090042114
Batch 49/64 loss: 0.23037731647491455
Batch 50/64 loss: 0.22710108757019043
Batch 51/64 loss: 0.22542643547058105
Batch 52/64 loss: 0.22883832454681396
Batch 53/64 loss: 0.2374882698059082
Batch 54/64 loss: 0.23605835437774658
Batch 55/64 loss: 0.23304855823516846
Batch 56/64 loss: 0.23585575819015503
Batch 57/64 loss: 0.22899818420410156
Batch 58/64 loss: 0.23558193445205688
Batch 59/64 loss: 0.23446345329284668
Batch 60/64 loss: 0.22282707691192627
Batch 61/64 loss: 0.22798216342926025
Batch 62/64 loss: 0.2330261468887329
Batch 63/64 loss: 0.23213398456573486
Batch 64/64 loss: 0.24040544033050537
Epoch 222  Train loss: 0.22886035816342223  Val loss: 0.292887489820264
Epoch 223
-------------------------------
Batch 1/64 loss: 0.2306807041168213
Batch 2/64 loss: 0.22016221284866333
Batch 3/64 loss: 0.22682958841323853
Batch 4/64 loss: 0.21732980012893677
Batch 5/64 loss: 0.2357010841369629
Batch 6/64 loss: 0.22919398546218872
Batch 7/64 loss: 0.22213590145111084
Batch 8/64 loss: 0.2240503430366516
Batch 9/64 loss: 0.23580515384674072
Batch 10/64 loss: 0.23112303018569946
Batch 11/64 loss: 0.23459118604660034
Batch 12/64 loss: 0.22470802068710327
Batch 13/64 loss: 0.23000288009643555
Batch 14/64 loss: 0.2287786602973938
Batch 15/64 loss: 0.23337888717651367
Batch 16/64 loss: 0.22106081247329712
Batch 17/64 loss: 0.22141528129577637
Batch 18/64 loss: 0.23672717809677124
Batch 19/64 loss: 0.2197052240371704
Batch 20/64 loss: 0.22870945930480957
Batch 21/64 loss: 0.23438525199890137
Batch 22/64 loss: 0.22999143600463867
Batch 23/64 loss: 0.2233656644821167
Batch 24/64 loss: 0.22378981113433838
Batch 25/64 loss: 0.22571641206741333
Batch 26/64 loss: 0.2328750491142273
Batch 27/64 loss: 0.2378963828086853
Batch 28/64 loss: 0.2260538935661316
Batch 29/64 loss: 0.22598087787628174
Batch 30/64 loss: 0.22863519191741943
Batch 31/64 loss: 0.22830140590667725
Batch 32/64 loss: 0.2278003692626953
Batch 33/64 loss: 0.22858965396881104
Batch 34/64 loss: 0.2218388319015503
Batch 35/64 loss: 0.22988641262054443
Batch 36/64 loss: 0.22466939687728882
Batch 37/64 loss: 0.22028321027755737
Batch 38/64 loss: 0.2393813133239746
Batch 39/64 loss: 0.22484302520751953
Batch 40/64 loss: 0.2306841015815735
Batch 41/64 loss: 0.2380772829055786
Batch 42/64 loss: 0.23028349876403809
Batch 43/64 loss: 0.2362445592880249
Batch 44/64 loss: 0.2306385636329651
Batch 45/64 loss: 0.22004663944244385
Batch 46/64 loss: 0.23216032981872559
Batch 47/64 loss: 0.22579431533813477
Batch 48/64 loss: 0.22341394424438477
Batch 49/64 loss: 0.2214459776878357
Batch 50/64 loss: 0.22978436946868896
Batch 51/64 loss: 0.22968357801437378
Batch 52/64 loss: 0.2280009388923645
Batch 53/64 loss: 0.23520219326019287
Batch 54/64 loss: 0.22641468048095703
Batch 55/64 loss: 0.23947632312774658
Batch 56/64 loss: 0.23192226886749268
Batch 57/64 loss: 0.22426795959472656
Batch 58/64 loss: 0.2255690097808838
Batch 59/64 loss: 0.22286248207092285
Batch 60/64 loss: 0.22607958316802979
Batch 61/64 loss: 0.22112929821014404
Batch 62/64 loss: 0.2253153920173645
Batch 63/64 loss: 0.23106735944747925
Batch 64/64 loss: 0.23688948154449463
Epoch 223  Train loss: 0.22822909401912314  Val loss: 0.29353883565496336
Epoch 224
-------------------------------
Batch 1/64 loss: 0.24459588527679443
Batch 2/64 loss: 0.22837257385253906
Batch 3/64 loss: 0.22577351331710815
Batch 4/64 loss: 0.23548662662506104
Batch 5/64 loss: 0.23293673992156982
Batch 6/64 loss: 0.22230494022369385
Batch 7/64 loss: 0.2300659418106079
Batch 8/64 loss: 0.22165679931640625
Batch 9/64 loss: 0.2203446626663208
Batch 10/64 loss: 0.23254990577697754
Batch 11/64 loss: 0.22981441020965576
Batch 12/64 loss: 0.22919154167175293
Batch 13/64 loss: 0.22324228286743164
Batch 14/64 loss: 0.2379070520401001
Batch 15/64 loss: 0.22565561532974243
Batch 16/64 loss: 0.2323143482208252
Batch 17/64 loss: 0.23064780235290527
Batch 18/64 loss: 0.2246665358543396
Batch 19/64 loss: 0.23037773370742798
Batch 20/64 loss: 0.23279708623886108
Batch 21/64 loss: 0.22455179691314697
Batch 22/64 loss: 0.22075533866882324
Batch 23/64 loss: 0.23093724250793457
Batch 24/64 loss: 0.2204188108444214
Batch 25/64 loss: 0.23094946146011353
Batch 26/64 loss: 0.22921884059906006
Batch 27/64 loss: 0.23147177696228027
Batch 28/64 loss: 0.23123180866241455
Batch 29/64 loss: 0.23469150066375732
Batch 30/64 loss: 0.23262536525726318
Batch 31/64 loss: 0.23664534091949463
Batch 32/64 loss: 0.22384309768676758
Batch 33/64 loss: 0.22309762239456177
Batch 34/64 loss: 0.22340214252471924
Batch 35/64 loss: 0.232560396194458
Batch 36/64 loss: 0.23082363605499268
Batch 37/64 loss: 0.2245255708694458
Batch 38/64 loss: 0.23002326488494873
Batch 39/64 loss: 0.21839076280593872
Batch 40/64 loss: 0.22053539752960205
Batch 41/64 loss: 0.2196352481842041
Batch 42/64 loss: 0.23076766729354858
Batch 43/64 loss: 0.22672617435455322
Batch 44/64 loss: 0.22029364109039307
Batch 45/64 loss: 0.22661268711090088
Batch 46/64 loss: 0.22745084762573242
Batch 47/64 loss: 0.233695387840271
Batch 48/64 loss: 0.21946030855178833
Batch 49/64 loss: 0.2371951937675476
Batch 50/64 loss: 0.2289644479751587
Batch 51/64 loss: 0.21688711643218994
Batch 52/64 loss: 0.22304439544677734
Batch 53/64 loss: 0.2255387306213379
Batch 54/64 loss: 0.2200927734375
Batch 55/64 loss: 0.22872817516326904
Batch 56/64 loss: 0.2319622039794922
Batch 57/64 loss: 0.23762297630310059
Batch 58/64 loss: 0.2340640425682068
Batch 59/64 loss: 0.22585856914520264
Batch 60/64 loss: 0.23488450050354004
Batch 61/64 loss: 0.2277016043663025
Batch 62/64 loss: 0.22217965126037598
Batch 63/64 loss: 0.23214304447174072
Batch 64/64 loss: 0.2166622281074524
Epoch 224  Train loss: 0.2280063879256155  Val loss: 0.29338698678000275
Epoch 225
-------------------------------
Batch 1/64 loss: 0.23488891124725342
Batch 2/64 loss: 0.22890859842300415
Batch 3/64 loss: 0.24224042892456055
Batch 4/64 loss: 0.23040366172790527
Batch 5/64 loss: 0.21950143575668335
Batch 6/64 loss: 0.22410106658935547
Batch 7/64 loss: 0.22626566886901855
Batch 8/64 loss: 0.2205137014389038
Batch 9/64 loss: 0.22675561904907227
Batch 10/64 loss: 0.22153687477111816
Batch 11/64 loss: 0.22474133968353271
Batch 12/64 loss: 0.2247854471206665
Batch 13/64 loss: 0.21231764554977417
Batch 14/64 loss: 0.2215561866760254
Batch 15/64 loss: 0.23167097568511963
Batch 16/64 loss: 0.22596919536590576
Batch 17/64 loss: 0.22588157653808594
Batch 18/64 loss: 0.23669934272766113
Batch 19/64 loss: 0.2230404019355774
Batch 20/64 loss: 0.2239208221435547
Batch 21/64 loss: 0.21916937828063965
Batch 22/64 loss: 0.23085731267929077
Batch 23/64 loss: 0.22844380140304565
Batch 24/64 loss: 0.23618090152740479
Batch 25/64 loss: 0.22910082340240479
Batch 26/64 loss: 0.23520201444625854
Batch 27/64 loss: 0.22798311710357666
Batch 28/64 loss: 0.22283291816711426
Batch 29/64 loss: 0.2220911979675293
Batch 30/64 loss: 0.214030921459198
Batch 31/64 loss: 0.22575581073760986
Batch 32/64 loss: 0.21728992462158203
Batch 33/64 loss: 0.21783018112182617
Batch 34/64 loss: 0.23201251029968262
Batch 35/64 loss: 0.2260715365409851
Batch 36/64 loss: 0.23273110389709473
Batch 37/64 loss: 0.22785544395446777
Batch 38/64 loss: 0.23567599058151245
Batch 39/64 loss: 0.23894351720809937
Batch 40/64 loss: 0.2263566255569458
Batch 41/64 loss: 0.22536110877990723
Batch 42/64 loss: 0.22631120681762695
Batch 43/64 loss: 0.2284386157989502
Batch 44/64 loss: 0.21951830387115479
Batch 45/64 loss: 0.22799807786941528
Batch 46/64 loss: 0.23080766201019287
Batch 47/64 loss: 0.23336303234100342
Batch 48/64 loss: 0.23418152332305908
Batch 49/64 loss: 0.2180708646774292
Batch 50/64 loss: 0.22919178009033203
Batch 51/64 loss: 0.21723800897598267
Batch 52/64 loss: 0.2275151014328003
Batch 53/64 loss: 0.2386302947998047
Batch 54/64 loss: 0.2302004098892212
Batch 55/64 loss: 0.2298189401626587
Batch 56/64 loss: 0.22354662418365479
Batch 57/64 loss: 0.24092799425125122
Batch 58/64 loss: 0.2382628321647644
Batch 59/64 loss: 0.22933876514434814
Batch 60/64 loss: 0.22166097164154053
Batch 61/64 loss: 0.2207755446434021
Batch 62/64 loss: 0.2262636423110962
Batch 63/64 loss: 0.2377110719680786
Batch 64/64 loss: 0.22351741790771484
Epoch 225  Train loss: 0.22737073524325502  Val loss: 0.2933926094848266
Epoch 226
-------------------------------
Batch 1/64 loss: 0.22917407751083374
Batch 2/64 loss: 0.22609519958496094
Batch 3/64 loss: 0.23374521732330322
Batch 4/64 loss: 0.2275857925415039
Batch 5/64 loss: 0.22394531965255737
Batch 6/64 loss: 0.22502970695495605
Batch 7/64 loss: 0.22451651096343994
Batch 8/64 loss: 0.23200637102127075
Batch 9/64 loss: 0.22616350650787354
Batch 10/64 loss: 0.23448431491851807
Batch 11/64 loss: 0.22537195682525635
Batch 12/64 loss: 0.22716057300567627
Batch 13/64 loss: 0.22120535373687744
Batch 14/64 loss: 0.2286059856414795
Batch 15/64 loss: 0.21767371892929077
Batch 16/64 loss: 0.22658604383468628
Batch 17/64 loss: 0.2256476879119873
Batch 18/64 loss: 0.2167569398880005
Batch 19/64 loss: 0.2217313051223755
Batch 20/64 loss: 0.2284015417098999
Batch 21/64 loss: 0.22744297981262207
Batch 22/64 loss: 0.22802531719207764
Batch 23/64 loss: 0.21894323825836182
Batch 24/64 loss: 0.23378843069076538
Batch 25/64 loss: 0.2227800488471985
Batch 26/64 loss: 0.22711771726608276
Batch 27/64 loss: 0.22052574157714844
Batch 28/64 loss: 0.22185081243515015
Batch 29/64 loss: 0.23432159423828125
Batch 30/64 loss: 0.23075515031814575
Batch 31/64 loss: 0.2276829481124878
Batch 32/64 loss: 0.22915500402450562
Batch 33/64 loss: 0.22660791873931885
Batch 34/64 loss: 0.2369309663772583
Batch 35/64 loss: 0.22685766220092773
Batch 36/64 loss: 0.2229405641555786
Batch 37/64 loss: 0.23259276151657104
Batch 38/64 loss: 0.23165345191955566
Batch 39/64 loss: 0.21966081857681274
Batch 40/64 loss: 0.23635321855545044
Batch 41/64 loss: 0.22555756568908691
Batch 42/64 loss: 0.22714734077453613
Batch 43/64 loss: 0.2391911745071411
Batch 44/64 loss: 0.2351841926574707
Batch 45/64 loss: 0.22901982069015503
Batch 46/64 loss: 0.2306838035583496
Batch 47/64 loss: 0.22318941354751587
Batch 48/64 loss: 0.21975213289260864
Batch 49/64 loss: 0.22505545616149902
Batch 50/64 loss: 0.2250744104385376
Batch 51/64 loss: 0.23025548458099365
Batch 52/64 loss: 0.22712993621826172
Batch 53/64 loss: 0.2222285270690918
Batch 54/64 loss: 0.22562766075134277
Batch 55/64 loss: 0.23031246662139893
Batch 56/64 loss: 0.22555679082870483
Batch 57/64 loss: 0.23415935039520264
Batch 58/64 loss: 0.23120194673538208
Batch 59/64 loss: 0.23038583993911743
Batch 60/64 loss: 0.23024463653564453
Batch 61/64 loss: 0.2241373062133789
Batch 62/64 loss: 0.23377007246017456
Batch 63/64 loss: 0.23296725749969482
Batch 64/64 loss: 0.228737473487854
Epoch 226  Train loss: 0.22756484957302317  Val loss: 0.2931257129944477
Epoch 227
-------------------------------
Batch 1/64 loss: 0.22934353351593018
Batch 2/64 loss: 0.23113024234771729
Batch 3/64 loss: 0.22072356939315796
Batch 4/64 loss: 0.2310253381729126
Batch 5/64 loss: 0.23376333713531494
Batch 6/64 loss: 0.22810637950897217
Batch 7/64 loss: 0.22484362125396729
Batch 8/64 loss: 0.21324467658996582
Batch 9/64 loss: 0.22179579734802246
Batch 10/64 loss: 0.22287189960479736
Batch 11/64 loss: 0.2229277491569519
Batch 12/64 loss: 0.22766530513763428
Batch 13/64 loss: 0.22953534126281738
Batch 14/64 loss: 0.22945678234100342
Batch 15/64 loss: 0.21906936168670654
Batch 16/64 loss: 0.2197345495223999
Batch 17/64 loss: 0.2234431505203247
Batch 18/64 loss: 0.2263866662979126
Batch 19/64 loss: 0.23112237453460693
Batch 20/64 loss: 0.22481709718704224
Batch 21/64 loss: 0.22440171241760254
Batch 22/64 loss: 0.22800958156585693
Batch 23/64 loss: 0.22515910863876343
Batch 24/64 loss: 0.23016059398651123
Batch 25/64 loss: 0.22219884395599365
Batch 26/64 loss: 0.22446990013122559
Batch 27/64 loss: 0.22910577058792114
Batch 28/64 loss: 0.22671067714691162
Batch 29/64 loss: 0.23188722133636475
Batch 30/64 loss: 0.2242732048034668
Batch 31/64 loss: 0.2396528124809265
Batch 32/64 loss: 0.2340695858001709
Batch 33/64 loss: 0.2277938723564148
Batch 34/64 loss: 0.23431909084320068
Batch 35/64 loss: 0.2311415672302246
Batch 36/64 loss: 0.2342311143875122
Batch 37/64 loss: 0.22609031200408936
Batch 38/64 loss: 0.22383511066436768
Batch 39/64 loss: 0.22790539264678955
Batch 40/64 loss: 0.22883784770965576
Batch 41/64 loss: 0.24307233095169067
Batch 42/64 loss: 0.22768044471740723
Batch 43/64 loss: 0.2163691520690918
Batch 44/64 loss: 0.22936809062957764
Batch 45/64 loss: 0.22640544176101685
Batch 46/64 loss: 0.2302086353302002
Batch 47/64 loss: 0.23255717754364014
Batch 48/64 loss: 0.24393105506896973
Batch 49/64 loss: 0.23230195045471191
Batch 50/64 loss: 0.22708475589752197
Batch 51/64 loss: 0.23682290315628052
Batch 52/64 loss: 0.22435390949249268
Batch 53/64 loss: 0.2227562665939331
Batch 54/64 loss: 0.23142576217651367
Batch 55/64 loss: 0.22416532039642334
Batch 56/64 loss: 0.22346079349517822
Batch 57/64 loss: 0.23956286907196045
Batch 58/64 loss: 0.2285623550415039
Batch 59/64 loss: 0.23293477296829224
Batch 60/64 loss: 0.24157166481018066
Batch 61/64 loss: 0.22130811214447021
Batch 62/64 loss: 0.22970759868621826
Batch 63/64 loss: 0.2348320484161377
Batch 64/64 loss: 0.21833312511444092
Epoch 227  Train loss: 0.22822671918308032  Val loss: 0.29323457729365815
Epoch 228
-------------------------------
Batch 1/64 loss: 0.2196965217590332
Batch 2/64 loss: 0.23571687936782837
Batch 3/64 loss: 0.2225041389465332
Batch 4/64 loss: 0.23191547393798828
Batch 5/64 loss: 0.20879989862442017
Batch 6/64 loss: 0.22261595726013184
Batch 7/64 loss: 0.2227821946144104
Batch 8/64 loss: 0.21748191118240356
Batch 9/64 loss: 0.2218712568283081
Batch 10/64 loss: 0.2212740182876587
Batch 11/64 loss: 0.22559881210327148
Batch 12/64 loss: 0.22850865125656128
Batch 13/64 loss: 0.2217848300933838
Batch 14/64 loss: 0.23461312055587769
Batch 15/64 loss: 0.21818256378173828
Batch 16/64 loss: 0.22041738033294678
Batch 17/64 loss: 0.2253943681716919
Batch 18/64 loss: 0.22994160652160645
Batch 19/64 loss: 0.22994303703308105
Batch 20/64 loss: 0.2349700927734375
Batch 21/64 loss: 0.2301662564277649
Batch 22/64 loss: 0.23936820030212402
Batch 23/64 loss: 0.23609697818756104
Batch 24/64 loss: 0.21761858463287354
Batch 25/64 loss: 0.22435128688812256
Batch 26/64 loss: 0.231370747089386
Batch 27/64 loss: 0.22902464866638184
Batch 28/64 loss: 0.22874635457992554
Batch 29/64 loss: 0.22279083728790283
Batch 30/64 loss: 0.212782621383667
Batch 31/64 loss: 0.23513609170913696
Batch 32/64 loss: 0.22913217544555664
Batch 33/64 loss: 0.23415786027908325
Batch 34/64 loss: 0.22268295288085938
Batch 35/64 loss: 0.22471952438354492
Batch 36/64 loss: 0.22271668910980225
Batch 37/64 loss: 0.22794055938720703
Batch 38/64 loss: 0.2169426679611206
Batch 39/64 loss: 0.23502010107040405
Batch 40/64 loss: 0.22013449668884277
Batch 41/64 loss: 0.2292250394821167
Batch 42/64 loss: 0.23004281520843506
Batch 43/64 loss: 0.226873517036438
Batch 44/64 loss: 0.22669768333435059
Batch 45/64 loss: 0.22250980138778687
Batch 46/64 loss: 0.22314989566802979
Batch 47/64 loss: 0.22795993089675903
Batch 48/64 loss: 0.23240405321121216
Batch 49/64 loss: 0.2297573685646057
Batch 50/64 loss: 0.235415518283844
Batch 51/64 loss: 0.22936075925827026
Batch 52/64 loss: 0.23180007934570312
Batch 53/64 loss: 0.23288434743881226
Batch 54/64 loss: 0.22335904836654663
Batch 55/64 loss: 0.2189089059829712
Batch 56/64 loss: 0.23344767093658447
Batch 57/64 loss: 0.221979558467865
Batch 58/64 loss: 0.22872579097747803
Batch 59/64 loss: 0.23667848110198975
Batch 60/64 loss: 0.2251746654510498
Batch 61/64 loss: 0.23209643363952637
Batch 62/64 loss: 0.2289852499961853
Batch 63/64 loss: 0.23308038711547852
Batch 64/64 loss: 0.233995258808136
Epoch 228  Train loss: 0.2269949144008113  Val loss: 0.2942149671901952
Epoch 229
-------------------------------
Batch 1/64 loss: 0.23599779605865479
Batch 2/64 loss: 0.2235933542251587
Batch 3/64 loss: 0.22147297859191895
Batch 4/64 loss: 0.23173636198043823
Batch 5/64 loss: 0.2158852219581604
Batch 6/64 loss: 0.23777318000793457
Batch 7/64 loss: 0.22047638893127441
Batch 8/64 loss: 0.2318875789642334
Batch 9/64 loss: 0.22554761171340942
Batch 10/64 loss: 0.22096645832061768
Batch 11/64 loss: 0.22474658489227295
Batch 12/64 loss: 0.21993088722229004
Batch 13/64 loss: 0.22077912092208862
Batch 14/64 loss: 0.22789537906646729
Batch 15/64 loss: 0.22535723447799683
Batch 16/64 loss: 0.2334471344947815
Batch 17/64 loss: 0.2223520278930664
Batch 18/64 loss: 0.2225314974784851
Batch 19/64 loss: 0.22373950481414795
Batch 20/64 loss: 0.21896964311599731
Batch 21/64 loss: 0.21320313215255737
Batch 22/64 loss: 0.22154897451400757
Batch 23/64 loss: 0.22114193439483643
Batch 24/64 loss: 0.23133444786071777
Batch 25/64 loss: 0.21400153636932373
Batch 26/64 loss: 0.22796344757080078
Batch 27/64 loss: 0.22029703855514526
Batch 28/64 loss: 0.22444355487823486
Batch 29/64 loss: 0.22929763793945312
Batch 30/64 loss: 0.22988712787628174
Batch 31/64 loss: 0.22281891107559204
Batch 32/64 loss: 0.22911518812179565
Batch 33/64 loss: 0.24313795566558838
Batch 34/64 loss: 0.22811412811279297
Batch 35/64 loss: 0.23281437158584595
Batch 36/64 loss: 0.22885394096374512
Batch 37/64 loss: 0.23127520084381104
Batch 38/64 loss: 0.2257065773010254
Batch 39/64 loss: 0.22787737846374512
Batch 40/64 loss: 0.21693068742752075
Batch 41/64 loss: 0.23651838302612305
Batch 42/64 loss: 0.23850828409194946
Batch 43/64 loss: 0.22413760423660278
Batch 44/64 loss: 0.22400569915771484
Batch 45/64 loss: 0.23653298616409302
Batch 46/64 loss: 0.2233973741531372
Batch 47/64 loss: 0.22273069620132446
Batch 48/64 loss: 0.2236025333404541
Batch 49/64 loss: 0.2156769037246704
Batch 50/64 loss: 0.2229386568069458
Batch 51/64 loss: 0.22305679321289062
Batch 52/64 loss: 0.222267746925354
Batch 53/64 loss: 0.23106294870376587
Batch 54/64 loss: 0.2209237813949585
Batch 55/64 loss: 0.23226022720336914
Batch 56/64 loss: 0.23009324073791504
Batch 57/64 loss: 0.22776013612747192
Batch 58/64 loss: 0.22045373916625977
Batch 59/64 loss: 0.22812986373901367
Batch 60/64 loss: 0.23005104064941406
Batch 61/64 loss: 0.240705668926239
Batch 62/64 loss: 0.22307324409484863
Batch 63/64 loss: 0.22211205959320068
Batch 64/64 loss: 0.22054624557495117
Epoch 229  Train loss: 0.22604326921350815  Val loss: 0.2939689009869631
Epoch 230
-------------------------------
Batch 1/64 loss: 0.2286820411682129
Batch 2/64 loss: 0.21440255641937256
Batch 3/64 loss: 0.22758841514587402
Batch 4/64 loss: 0.2229304313659668
Batch 5/64 loss: 0.22762227058410645
Batch 6/64 loss: 0.2251899242401123
Batch 7/64 loss: 0.2167258858680725
Batch 8/64 loss: 0.2209254503250122
Batch 9/64 loss: 0.22193032503128052
Batch 10/64 loss: 0.22358101606369019
Batch 11/64 loss: 0.23084652423858643
Batch 12/64 loss: 0.23472237586975098
Batch 13/64 loss: 0.2187272310256958
Batch 14/64 loss: 0.2432827353477478
Batch 15/64 loss: 0.22725164890289307
Batch 16/64 loss: 0.2232326865196228
Batch 17/64 loss: 0.22106927633285522
Batch 18/64 loss: 0.22039794921875
Batch 19/64 loss: 0.22355741262435913
Batch 20/64 loss: 0.22662174701690674
Batch 21/64 loss: 0.21836137771606445
Batch 22/64 loss: 0.21613389253616333
Batch 23/64 loss: 0.22353672981262207
Batch 24/64 loss: 0.2160780429840088
Batch 25/64 loss: 0.23072397708892822
Batch 26/64 loss: 0.23235857486724854
Batch 27/64 loss: 0.22116363048553467
Batch 28/64 loss: 0.23646748065948486
Batch 29/64 loss: 0.23015570640563965
Batch 30/64 loss: 0.23102283477783203
Batch 31/64 loss: 0.23248577117919922
Batch 32/64 loss: 0.2290986180305481
Batch 33/64 loss: 0.2281782627105713
Batch 34/64 loss: 0.22113877534866333
Batch 35/64 loss: 0.227655291557312
Batch 36/64 loss: 0.227037250995636
Batch 37/64 loss: 0.24651288986206055
Batch 38/64 loss: 0.21687060594558716
Batch 39/64 loss: 0.232924222946167
Batch 40/64 loss: 0.229425311088562
Batch 41/64 loss: 0.22019827365875244
Batch 42/64 loss: 0.2417137622833252
Batch 43/64 loss: 0.22133564949035645
Batch 44/64 loss: 0.22567343711853027
Batch 45/64 loss: 0.2284718155860901
Batch 46/64 loss: 0.23947817087173462
Batch 47/64 loss: 0.2314043641090393
Batch 48/64 loss: 0.22028982639312744
Batch 49/64 loss: 0.226568341255188
Batch 50/64 loss: 0.22361469268798828
Batch 51/64 loss: 0.22429674863815308
Batch 52/64 loss: 0.23306751251220703
Batch 53/64 loss: 0.22272348403930664
Batch 54/64 loss: 0.23268842697143555
Batch 55/64 loss: 0.23531293869018555
Batch 56/64 loss: 0.23159384727478027
Batch 57/64 loss: 0.22494018077850342
Batch 58/64 loss: 0.2263619303703308
Batch 59/64 loss: 0.22614842653274536
Batch 60/64 loss: 0.22619843482971191
Batch 61/64 loss: 0.23823148012161255
Batch 62/64 loss: 0.22857153415679932
Batch 63/64 loss: 0.22150415182113647
Batch 64/64 loss: 0.21743345260620117
Epoch 230  Train loss: 0.22682477913650811  Val loss: 0.2936906056715451
Epoch 231
-------------------------------
Batch 1/64 loss: 0.22902214527130127
Batch 2/64 loss: 0.22183442115783691
Batch 3/64 loss: 0.22870779037475586
Batch 4/64 loss: 0.22385674715042114
Batch 5/64 loss: 0.2226313352584839
Batch 6/64 loss: 0.2253483533859253
Batch 7/64 loss: 0.2239365577697754
Batch 8/64 loss: 0.22389554977416992
Batch 9/64 loss: 0.22197192907333374
Batch 10/64 loss: 0.2355496883392334
Batch 11/64 loss: 0.2219046950340271
Batch 12/64 loss: 0.21408092975616455
Batch 13/64 loss: 0.22593247890472412
Batch 14/64 loss: 0.23786109685897827
Batch 15/64 loss: 0.22727322578430176
Batch 16/64 loss: 0.24041426181793213
Batch 17/64 loss: 0.23460954427719116
Batch 18/64 loss: 0.22442317008972168
Batch 19/64 loss: 0.2279362678527832
Batch 20/64 loss: 0.22886425256729126
Batch 21/64 loss: 0.21882200241088867
Batch 22/64 loss: 0.23554182052612305
Batch 23/64 loss: 0.22559136152267456
Batch 24/64 loss: 0.21657133102416992
Batch 25/64 loss: 0.22480696439743042
Batch 26/64 loss: 0.22618526220321655
Batch 27/64 loss: 0.22193104028701782
Batch 28/64 loss: 0.2262892723083496
Batch 29/64 loss: 0.22429239749908447
Batch 30/64 loss: 0.2246658205986023
Batch 31/64 loss: 0.22419679164886475
Batch 32/64 loss: 0.22943055629730225
Batch 33/64 loss: 0.2264125943183899
Batch 34/64 loss: 0.22351014614105225
Batch 35/64 loss: 0.22016549110412598
Batch 36/64 loss: 0.22857952117919922
Batch 37/64 loss: 0.23345625400543213
Batch 38/64 loss: 0.21813476085662842
Batch 39/64 loss: 0.22407668828964233
Batch 40/64 loss: 0.2276708483695984
Batch 41/64 loss: 0.22379207611083984
Batch 42/64 loss: 0.22463977336883545
Batch 43/64 loss: 0.21686697006225586
Batch 44/64 loss: 0.2273627519607544
Batch 45/64 loss: 0.21881985664367676
Batch 46/64 loss: 0.2182173728942871
Batch 47/64 loss: 0.22848272323608398
Batch 48/64 loss: 0.21966767311096191
Batch 49/64 loss: 0.22067391872406006
Batch 50/64 loss: 0.23167800903320312
Batch 51/64 loss: 0.2311769723892212
Batch 52/64 loss: 0.23661047220230103
Batch 53/64 loss: 0.23265230655670166
Batch 54/64 loss: 0.22918689250946045
Batch 55/64 loss: 0.22633743286132812
Batch 56/64 loss: 0.22724735736846924
Batch 57/64 loss: 0.21995222568511963
Batch 58/64 loss: 0.22959822416305542
Batch 59/64 loss: 0.23743140697479248
Batch 60/64 loss: 0.21929967403411865
Batch 61/64 loss: 0.23032116889953613
Batch 62/64 loss: 0.2244023084640503
Batch 63/64 loss: 0.2218724489212036
Batch 64/64 loss: 0.22351908683776855
Epoch 231  Train loss: 0.22595003445943196  Val loss: 0.2933866707320066
Epoch 232
-------------------------------
Batch 1/64 loss: 0.23162275552749634
Batch 2/64 loss: 0.22785449028015137
Batch 3/64 loss: 0.2234724760055542
Batch 4/64 loss: 0.2427418828010559
Batch 5/64 loss: 0.22685730457305908
Batch 6/64 loss: 0.23107421398162842
Batch 7/64 loss: 0.22801733016967773
Batch 8/64 loss: 0.2230842113494873
Batch 9/64 loss: 0.22786545753479004
Batch 10/64 loss: 0.22292155027389526
Batch 11/64 loss: 0.22471988201141357
Batch 12/64 loss: 0.2204849123954773
Batch 13/64 loss: 0.22213029861450195
Batch 14/64 loss: 0.23520100116729736
Batch 15/64 loss: 0.21509003639221191
Batch 16/64 loss: 0.22426962852478027
Batch 17/64 loss: 0.22659099102020264
Batch 18/64 loss: 0.21363461017608643
Batch 19/64 loss: 0.23406827449798584
Batch 20/64 loss: 0.22291254997253418
Batch 21/64 loss: 0.22858721017837524
Batch 22/64 loss: 0.21989715099334717
Batch 23/64 loss: 0.22069871425628662
Batch 24/64 loss: 0.23427271842956543
Batch 25/64 loss: 0.2152554988861084
Batch 26/64 loss: 0.22109711170196533
Batch 27/64 loss: 0.22926223278045654
Batch 28/64 loss: 0.21275866031646729
Batch 29/64 loss: 0.22574758529663086
Batch 30/64 loss: 0.22408562898635864
Batch 31/64 loss: 0.22940945625305176
Batch 32/64 loss: 0.22340524196624756
Batch 33/64 loss: 0.2200537919998169
Batch 34/64 loss: 0.2173067331314087
Batch 35/64 loss: 0.22802942991256714
Batch 36/64 loss: 0.24017608165740967
Batch 37/64 loss: 0.2202765941619873
Batch 38/64 loss: 0.21597176790237427
Batch 39/64 loss: 0.23204004764556885
Batch 40/64 loss: 0.22912204265594482
Batch 41/64 loss: 0.23147094249725342
Batch 42/64 loss: 0.2296944260597229
Batch 43/64 loss: 0.22105413675308228
Batch 44/64 loss: 0.22423696517944336
Batch 45/64 loss: 0.2286853790283203
Batch 46/64 loss: 0.2207903265953064
Batch 47/64 loss: 0.2315589189529419
Batch 48/64 loss: 0.2367231249809265
Batch 49/64 loss: 0.23766177892684937
Batch 50/64 loss: 0.22627794742584229
Batch 51/64 loss: 0.22435569763183594
Batch 52/64 loss: 0.2407621145248413
Batch 53/64 loss: 0.22204023599624634
Batch 54/64 loss: 0.22518914937973022
Batch 55/64 loss: 0.23004567623138428
Batch 56/64 loss: 0.22152817249298096
Batch 57/64 loss: 0.21698296070098877
Batch 58/64 loss: 0.2185119390487671
Batch 59/64 loss: 0.21439754962921143
Batch 60/64 loss: 0.22408604621887207
Batch 61/64 loss: 0.2364850640296936
Batch 62/64 loss: 0.21807408332824707
Batch 63/64 loss: 0.22513628005981445
Batch 64/64 loss: 0.22601377964019775
Epoch 232  Train loss: 0.22568355775346943  Val loss: 0.29420864541096375
Epoch 233
-------------------------------
Batch 1/64 loss: 0.22310972213745117
Batch 2/64 loss: 0.2348613142967224
Batch 3/64 loss: 0.22980594635009766
Batch 4/64 loss: 0.21725356578826904
Batch 5/64 loss: 0.22710442543029785
Batch 6/64 loss: 0.22471153736114502
Batch 7/64 loss: 0.22889387607574463
Batch 8/64 loss: 0.21780800819396973
Batch 9/64 loss: 0.2184276580810547
Batch 10/64 loss: 0.21956372261047363
Batch 11/64 loss: 0.2180556058883667
Batch 12/64 loss: 0.21925759315490723
Batch 13/64 loss: 0.22130262851715088
Batch 14/64 loss: 0.2193228006362915
Batch 15/64 loss: 0.21848201751708984
Batch 16/64 loss: 0.22942620515823364
Batch 17/64 loss: 0.22964894771575928
Batch 18/64 loss: 0.22429710626602173
Batch 19/64 loss: 0.2243863344192505
Batch 20/64 loss: 0.23774880170822144
Batch 21/64 loss: 0.23208928108215332
Batch 22/64 loss: 0.22743892669677734
Batch 23/64 loss: 0.2251962423324585
Batch 24/64 loss: 0.23293530941009521
Batch 25/64 loss: 0.22221100330352783
Batch 26/64 loss: 0.2167782187461853
Batch 27/64 loss: 0.23762989044189453
Batch 28/64 loss: 0.21912771463394165
Batch 29/64 loss: 0.230749249458313
Batch 30/64 loss: 0.22961056232452393
Batch 31/64 loss: 0.22690117359161377
Batch 32/64 loss: 0.2330613136291504
Batch 33/64 loss: 0.22532129287719727
Batch 34/64 loss: 0.24340975284576416
Batch 35/64 loss: 0.2242705225944519
Batch 36/64 loss: 0.2267809510231018
Batch 37/64 loss: 0.22524893283843994
Batch 38/64 loss: 0.22134828567504883
Batch 39/64 loss: 0.22456854581832886
Batch 40/64 loss: 0.22059869766235352
Batch 41/64 loss: 0.23086267709732056
Batch 42/64 loss: 0.23124921321868896
Batch 43/64 loss: 0.22619295120239258
Batch 44/64 loss: 0.22700107097625732
Batch 45/64 loss: 0.22479510307312012
Batch 46/64 loss: 0.2291959524154663
Batch 47/64 loss: 0.2376704216003418
Batch 48/64 loss: 0.22810065746307373
Batch 49/64 loss: 0.22269856929779053
Batch 50/64 loss: 0.22591304779052734
Batch 51/64 loss: 0.23381078243255615
Batch 52/64 loss: 0.21652734279632568
Batch 53/64 loss: 0.21514582633972168
Batch 54/64 loss: 0.2224574089050293
Batch 55/64 loss: 0.221765398979187
Batch 56/64 loss: 0.23301613330841064
Batch 57/64 loss: 0.22053146362304688
Batch 58/64 loss: 0.21486377716064453
Batch 59/64 loss: 0.23749399185180664
Batch 60/64 loss: 0.2321745753288269
Batch 61/64 loss: 0.235356867313385
Batch 62/64 loss: 0.22801095247268677
Batch 63/64 loss: 0.22501099109649658
Batch 64/64 loss: 0.2386082410812378
Epoch 233  Train loss: 0.22631443201326856  Val loss: 0.29365247856710375
Epoch 234
-------------------------------
Batch 1/64 loss: 0.23226940631866455
Batch 2/64 loss: 0.22606700658798218
Batch 3/64 loss: 0.2225501537322998
Batch 4/64 loss: 0.22519278526306152
Batch 5/64 loss: 0.216397225856781
Batch 6/64 loss: 0.21696197986602783
Batch 7/64 loss: 0.21858882904052734
Batch 8/64 loss: 0.2267606258392334
Batch 9/64 loss: 0.23229742050170898
Batch 10/64 loss: 0.22971129417419434
Batch 11/64 loss: 0.2274830937385559
Batch 12/64 loss: 0.23116278648376465
Batch 13/64 loss: 0.21726489067077637
Batch 14/64 loss: 0.22048449516296387
Batch 15/64 loss: 0.2134658694267273
Batch 16/64 loss: 0.22952306270599365
Batch 17/64 loss: 0.2216358184814453
Batch 18/64 loss: 0.22603440284729004
Batch 19/64 loss: 0.22764146327972412
Batch 20/64 loss: 0.24393880367279053
Batch 21/64 loss: 0.22804534435272217
Batch 22/64 loss: 0.22561287879943848
Batch 23/64 loss: 0.22520768642425537
Batch 24/64 loss: 0.22322332859039307
Batch 25/64 loss: 0.22765541076660156
Batch 26/64 loss: 0.22651958465576172
Batch 27/64 loss: 0.21602129936218262
Batch 28/64 loss: 0.23083627223968506
Batch 29/64 loss: 0.23122882843017578
Batch 30/64 loss: 0.2212918996810913
Batch 31/64 loss: 0.23214852809906006
Batch 32/64 loss: 0.22131961584091187
Batch 33/64 loss: 0.21489816904067993
Batch 34/64 loss: 0.2347499132156372
Batch 35/64 loss: 0.22420799732208252
Batch 36/64 loss: 0.2311340570449829
Batch 37/64 loss: 0.23047292232513428
Batch 38/64 loss: 0.21949511766433716
Batch 39/64 loss: 0.22636336088180542
Batch 40/64 loss: 0.22281980514526367
Batch 41/64 loss: 0.22599732875823975
Batch 42/64 loss: 0.22879159450531006
Batch 43/64 loss: 0.21007132530212402
Batch 44/64 loss: 0.2286374568939209
Batch 45/64 loss: 0.22292715311050415
Batch 46/64 loss: 0.230299711227417
Batch 47/64 loss: 0.23310160636901855
Batch 48/64 loss: 0.23689615726470947
Batch 49/64 loss: 0.22850120067596436
Batch 50/64 loss: 0.2222970724105835
Batch 51/64 loss: 0.23292768001556396
Batch 52/64 loss: 0.2217862606048584
Batch 53/64 loss: 0.22649484872817993
Batch 54/64 loss: 0.22329449653625488
Batch 55/64 loss: 0.2155081033706665
Batch 56/64 loss: 0.22676610946655273
Batch 57/64 loss: 0.225203275680542
Batch 58/64 loss: 0.2079695463180542
Batch 59/64 loss: 0.2135554552078247
Batch 60/64 loss: 0.24001818895339966
Batch 61/64 loss: 0.2265905737876892
Batch 62/64 loss: 0.22761690616607666
Batch 63/64 loss: 0.2147444486618042
Batch 64/64 loss: 0.2267601490020752
Epoch 234  Train loss: 0.22523529482822793  Val loss: 0.2935374334096089
Epoch 235
-------------------------------
Batch 1/64 loss: 0.2294861078262329
Batch 2/64 loss: 0.2186872959136963
Batch 3/64 loss: 0.22209501266479492
Batch 4/64 loss: 0.22120672464370728
Batch 5/64 loss: 0.21881985664367676
Batch 6/64 loss: 0.23195993900299072
Batch 7/64 loss: 0.21861505508422852
Batch 8/64 loss: 0.22272515296936035
Batch 9/64 loss: 0.21151411533355713
Batch 10/64 loss: 0.22585511207580566
Batch 11/64 loss: 0.22463035583496094
Batch 12/64 loss: 0.22216081619262695
Batch 13/64 loss: 0.22158598899841309
Batch 14/64 loss: 0.21854382753372192
Batch 15/64 loss: 0.21997570991516113
Batch 16/64 loss: 0.21712857484817505
Batch 17/64 loss: 0.22300076484680176
Batch 18/64 loss: 0.23657262325286865
Batch 19/64 loss: 0.23177939653396606
Batch 20/64 loss: 0.22874152660369873
Batch 21/64 loss: 0.22532868385314941
Batch 22/64 loss: 0.23784148693084717
Batch 23/64 loss: 0.23254024982452393
Batch 24/64 loss: 0.23740124702453613
Batch 25/64 loss: 0.22192049026489258
Batch 26/64 loss: 0.2322014570236206
Batch 27/64 loss: 0.2234867811203003
Batch 28/64 loss: 0.22806596755981445
Batch 29/64 loss: 0.2234588861465454
Batch 30/64 loss: 0.22249054908752441
Batch 31/64 loss: 0.219818115234375
Batch 32/64 loss: 0.22262203693389893
Batch 33/64 loss: 0.22952204942703247
Batch 34/64 loss: 0.21770119667053223
Batch 35/64 loss: 0.22989511489868164
Batch 36/64 loss: 0.22279059886932373
Batch 37/64 loss: 0.22473061084747314
Batch 38/64 loss: 0.22304844856262207
Batch 39/64 loss: 0.23412847518920898
Batch 40/64 loss: 0.2314332127571106
Batch 41/64 loss: 0.22279298305511475
Batch 42/64 loss: 0.23536252975463867
Batch 43/64 loss: 0.21774929761886597
Batch 44/64 loss: 0.22356635332107544
Batch 45/64 loss: 0.22378695011138916
Batch 46/64 loss: 0.22159874439239502
Batch 47/64 loss: 0.2549647092819214
Batch 48/64 loss: 0.23067986965179443
Batch 49/64 loss: 0.2200232744216919
Batch 50/64 loss: 0.22449231147766113
Batch 51/64 loss: 0.22628945112228394
Batch 52/64 loss: 0.23353517055511475
Batch 53/64 loss: 0.22219038009643555
Batch 54/64 loss: 0.22184443473815918
Batch 55/64 loss: 0.22679859399795532
Batch 56/64 loss: 0.22347277402877808
Batch 57/64 loss: 0.23631417751312256
Batch 58/64 loss: 0.22852450609207153
Batch 59/64 loss: 0.21874117851257324
Batch 60/64 loss: 0.22553956508636475
Batch 61/64 loss: 0.21938037872314453
Batch 62/64 loss: 0.22695457935333252
Batch 63/64 loss: 0.22519880533218384
Batch 64/64 loss: 0.21926891803741455
Epoch 235  Train loss: 0.22556489916408765  Val loss: 0.2934932704643695
Epoch 236
-------------------------------
Batch 1/64 loss: 0.22197061777114868
Batch 2/64 loss: 0.21467101573944092
Batch 3/64 loss: 0.22727841138839722
Batch 4/64 loss: 0.21585988998413086
Batch 5/64 loss: 0.2252258062362671
Batch 6/64 loss: 0.22594118118286133
Batch 7/64 loss: 0.22147512435913086
Batch 8/64 loss: 0.21745175123214722
Batch 9/64 loss: 0.22315478324890137
Batch 10/64 loss: 0.23630183935165405
Batch 11/64 loss: 0.21401876211166382
Batch 12/64 loss: 0.2188875675201416
Batch 13/64 loss: 0.2391776442527771
Batch 14/64 loss: 0.2282160520553589
Batch 15/64 loss: 0.20915579795837402
Batch 16/64 loss: 0.213157057762146
Batch 17/64 loss: 0.23301804065704346
Batch 18/64 loss: 0.23078972101211548
Batch 19/64 loss: 0.21521788835525513
Batch 20/64 loss: 0.23392289876937866
Batch 21/64 loss: 0.216048002243042
Batch 22/64 loss: 0.21974492073059082
Batch 23/64 loss: 0.21814709901809692
Batch 24/64 loss: 0.23578375577926636
Batch 25/64 loss: 0.23065543174743652
Batch 26/64 loss: 0.2260187864303589
Batch 27/64 loss: 0.22244125604629517
Batch 28/64 loss: 0.2336100935935974
Batch 29/64 loss: 0.22616589069366455
Batch 30/64 loss: 0.2292804718017578
Batch 31/64 loss: 0.22539913654327393
Batch 32/64 loss: 0.21671760082244873
Batch 33/64 loss: 0.21989881992340088
Batch 34/64 loss: 0.23628437519073486
Batch 35/64 loss: 0.21850800514221191
Batch 36/64 loss: 0.22147458791732788
Batch 37/64 loss: 0.2242262363433838
Batch 38/64 loss: 0.22559934854507446
Batch 39/64 loss: 0.2255604863166809
Batch 40/64 loss: 0.21170353889465332
Batch 41/64 loss: 0.22417891025543213
Batch 42/64 loss: 0.2231982946395874
Batch 43/64 loss: 0.23160362243652344
Batch 44/64 loss: 0.22761470079421997
Batch 45/64 loss: 0.22073328495025635
Batch 46/64 loss: 0.2236320972442627
Batch 47/64 loss: 0.22305572032928467
Batch 48/64 loss: 0.2254447340965271
Batch 49/64 loss: 0.22203552722930908
Batch 50/64 loss: 0.21824723482131958
Batch 51/64 loss: 0.2354099154472351
Batch 52/64 loss: 0.22094005346298218
Batch 53/64 loss: 0.22999483346939087
Batch 54/64 loss: 0.22662997245788574
Batch 55/64 loss: 0.2176755666732788
Batch 56/64 loss: 0.21384721994400024
Batch 57/64 loss: 0.23244428634643555
Batch 58/64 loss: 0.23038232326507568
Batch 59/64 loss: 0.2260270118713379
Batch 60/64 loss: 0.22290003299713135
Batch 61/64 loss: 0.2342318892478943
Batch 62/64 loss: 0.2295287847518921
Batch 63/64 loss: 0.22161900997161865
Batch 64/64 loss: 0.21739423274993896
Epoch 236  Train loss: 0.22419733954410928  Val loss: 0.2935925427171373
Epoch 237
-------------------------------
Batch 1/64 loss: 0.22128725051879883
Batch 2/64 loss: 0.22741258144378662
Batch 3/64 loss: 0.22009187936782837
Batch 4/64 loss: 0.2208579182624817
Batch 5/64 loss: 0.22726237773895264
Batch 6/64 loss: 0.2221311330795288
Batch 7/64 loss: 0.22522073984146118
Batch 8/64 loss: 0.22096526622772217
Batch 9/64 loss: 0.2284860610961914
Batch 10/64 loss: 0.22520840167999268
Batch 11/64 loss: 0.22521966695785522
Batch 12/64 loss: 0.2357800006866455
Batch 13/64 loss: 0.22266089916229248
Batch 14/64 loss: 0.22552502155303955
Batch 15/64 loss: 0.22507727146148682
Batch 16/64 loss: 0.2212924361228943
Batch 17/64 loss: 0.2243315577507019
Batch 18/64 loss: 0.214805006980896
Batch 19/64 loss: 0.22315454483032227
Batch 20/64 loss: 0.22772681713104248
Batch 21/64 loss: 0.22768265008926392
Batch 22/64 loss: 0.2099071741104126
Batch 23/64 loss: 0.22444581985473633
Batch 24/64 loss: 0.21581614017486572
Batch 25/64 loss: 0.2122315764427185
Batch 26/64 loss: 0.21731936931610107
Batch 27/64 loss: 0.22105640172958374
Batch 28/64 loss: 0.209328293800354
Batch 29/64 loss: 0.22063350677490234
Batch 30/64 loss: 0.22049164772033691
Batch 31/64 loss: 0.21879661083221436
Batch 32/64 loss: 0.21837204694747925
Batch 33/64 loss: 0.22215408086776733
Batch 34/64 loss: 0.22628796100616455
Batch 35/64 loss: 0.2267051339149475
Batch 36/64 loss: 0.22603893280029297
Batch 37/64 loss: 0.24043172597885132
Batch 38/64 loss: 0.2386610507965088
Batch 39/64 loss: 0.22921758890151978
Batch 40/64 loss: 0.2230657935142517
Batch 41/64 loss: 0.2280287742614746
Batch 42/64 loss: 0.22221851348876953
Batch 43/64 loss: 0.22443431615829468
Batch 44/64 loss: 0.21959072351455688
Batch 45/64 loss: 0.2286924123764038
Batch 46/64 loss: 0.2224186658859253
Batch 47/64 loss: 0.23756206035614014
Batch 48/64 loss: 0.23681533336639404
Batch 49/64 loss: 0.22155487537384033
Batch 50/64 loss: 0.21913748979568481
Batch 51/64 loss: 0.22092634439468384
Batch 52/64 loss: 0.23193752765655518
Batch 53/64 loss: 0.22211968898773193
Batch 54/64 loss: 0.22084593772888184
Batch 55/64 loss: 0.2198779582977295
Batch 56/64 loss: 0.23856955766677856
Batch 57/64 loss: 0.2306789755821228
Batch 58/64 loss: 0.2261403203010559
Batch 59/64 loss: 0.2296532392501831
Batch 60/64 loss: 0.224578857421875
Batch 61/64 loss: 0.22242134809494019
Batch 62/64 loss: 0.22842395305633545
Batch 63/64 loss: 0.21856385469436646
Batch 64/64 loss: 0.2280827760696411
Epoch 237  Train loss: 0.22430420623106115  Val loss: 0.2932608989915487
Epoch 238
-------------------------------
Batch 1/64 loss: 0.22386765480041504
Batch 2/64 loss: 0.2412014603614807
Batch 3/64 loss: 0.22310519218444824
Batch 4/64 loss: 0.2182350754737854
Batch 5/64 loss: 0.2182929515838623
Batch 6/64 loss: 0.22562265396118164
Batch 7/64 loss: 0.21938085556030273
Batch 8/64 loss: 0.22395169734954834
Batch 9/64 loss: 0.22366952896118164
Batch 10/64 loss: 0.21760344505310059
Batch 11/64 loss: 0.2329384684562683
Batch 12/64 loss: 0.22303462028503418
Batch 13/64 loss: 0.23491495847702026
Batch 14/64 loss: 0.2162621021270752
Batch 15/64 loss: 0.22242385149002075
Batch 16/64 loss: 0.22159045934677124
Batch 17/64 loss: 0.22149407863616943
Batch 18/64 loss: 0.22618919610977173
Batch 19/64 loss: 0.22913813591003418
Batch 20/64 loss: 0.22034704685211182
Batch 21/64 loss: 0.2198672890663147
Batch 22/64 loss: 0.21646928787231445
Batch 23/64 loss: 0.23667782545089722
Batch 24/64 loss: 0.22377383708953857
Batch 25/64 loss: 0.23063278198242188
Batch 26/64 loss: 0.23012495040893555
Batch 27/64 loss: 0.22142672538757324
Batch 28/64 loss: 0.2221585512161255
Batch 29/64 loss: 0.240381121635437
Batch 30/64 loss: 0.22891676425933838
Batch 31/64 loss: 0.22960138320922852
Batch 32/64 loss: 0.22427630424499512
Batch 33/64 loss: 0.2275937795639038
Batch 34/64 loss: 0.21249866485595703
Batch 35/64 loss: 0.21455669403076172
Batch 36/64 loss: 0.22623276710510254
Batch 37/64 loss: 0.23238730430603027
Batch 38/64 loss: 0.23129379749298096
Batch 39/64 loss: 0.23768484592437744
Batch 40/64 loss: 0.22034192085266113
Batch 41/64 loss: 0.2097567915916443
Batch 42/64 loss: 0.2320922613143921
Batch 43/64 loss: 0.21644747257232666
Batch 44/64 loss: 0.23174577951431274
Batch 45/64 loss: 0.23516547679901123
Batch 46/64 loss: 0.2349780797958374
Batch 47/64 loss: 0.23215872049331665
Batch 48/64 loss: 0.227361261844635
Batch 49/64 loss: 0.22460651397705078
Batch 50/64 loss: 0.23350751399993896
Batch 51/64 loss: 0.2162470817565918
Batch 52/64 loss: 0.21121960878372192
Batch 53/64 loss: 0.22330069541931152
Batch 54/64 loss: 0.21282559633255005
Batch 55/64 loss: 0.2318176031112671
Batch 56/64 loss: 0.22215938568115234
Batch 57/64 loss: 0.2321763038635254
Batch 58/64 loss: 0.23280686140060425
Batch 59/64 loss: 0.21548092365264893
Batch 60/64 loss: 0.23009157180786133
Batch 61/64 loss: 0.22907650470733643
Batch 62/64 loss: 0.22229695320129395
Batch 63/64 loss: 0.2261521816253662
Batch 64/64 loss: 0.2216528058052063
Epoch 238  Train loss: 0.2252528749260248  Val loss: 0.29297580116802885
Epoch 239
-------------------------------
Batch 1/64 loss: 0.21653831005096436
Batch 2/64 loss: 0.2207738757133484
Batch 3/64 loss: 0.23285186290740967
Batch 4/64 loss: 0.22361969947814941
Batch 5/64 loss: 0.23289620876312256
Batch 6/64 loss: 0.21692121028900146
Batch 7/64 loss: 0.21895074844360352
Batch 8/64 loss: 0.22794252634048462
Batch 9/64 loss: 0.2307673692703247
Batch 10/64 loss: 0.2202235460281372
Batch 11/64 loss: 0.2263963222503662
Batch 12/64 loss: 0.22673821449279785
Batch 13/64 loss: 0.2228250503540039
Batch 14/64 loss: 0.2227877378463745
Batch 15/64 loss: 0.21889078617095947
Batch 16/64 loss: 0.22590261697769165
Batch 17/64 loss: 0.21555691957473755
Batch 18/64 loss: 0.21622538566589355
Batch 19/64 loss: 0.2255016565322876
Batch 20/64 loss: 0.229162335395813
Batch 21/64 loss: 0.23029983043670654
Batch 22/64 loss: 0.22660315036773682
Batch 23/64 loss: 0.2318210005760193
Batch 24/64 loss: 0.2280116081237793
Batch 25/64 loss: 0.22038507461547852
Batch 26/64 loss: 0.22331738471984863
Batch 27/64 loss: 0.23365449905395508
Batch 28/64 loss: 0.23257946968078613
Batch 29/64 loss: 0.24173617362976074
Batch 30/64 loss: 0.23403149843215942
Batch 31/64 loss: 0.2360527515411377
Batch 32/64 loss: 0.21863973140716553
Batch 33/64 loss: 0.22292304039001465
Batch 34/64 loss: 0.2270234227180481
Batch 35/64 loss: 0.21730542182922363
Batch 36/64 loss: 0.22883260250091553
Batch 37/64 loss: 0.21839940547943115
Batch 38/64 loss: 0.21545642614364624
Batch 39/64 loss: 0.21758008003234863
Batch 40/64 loss: 0.23040473461151123
Batch 41/64 loss: 0.21621441841125488
Batch 42/64 loss: 0.21619844436645508
Batch 43/64 loss: 0.21756315231323242
Batch 44/64 loss: 0.2266831398010254
Batch 45/64 loss: 0.2221512794494629
Batch 46/64 loss: 0.2283231019973755
Batch 47/64 loss: 0.228620707988739
Batch 48/64 loss: 0.21657133102416992
Batch 49/64 loss: 0.23021137714385986
Batch 50/64 loss: 0.21559035778045654
Batch 51/64 loss: 0.22016459703445435
Batch 52/64 loss: 0.2210155725479126
Batch 53/64 loss: 0.2326143980026245
Batch 54/64 loss: 0.22365176677703857
Batch 55/64 loss: 0.2182856798171997
Batch 56/64 loss: 0.2144930362701416
Batch 57/64 loss: 0.2418757677078247
Batch 58/64 loss: 0.2317638397216797
Batch 59/64 loss: 0.21155929565429688
Batch 60/64 loss: 0.2406565546989441
Batch 61/64 loss: 0.21763837337493896
Batch 62/64 loss: 0.22924840450286865
Batch 63/64 loss: 0.22540146112442017
Batch 64/64 loss: 0.22030550241470337
Epoch 239  Train loss: 0.22460007644167132  Val loss: 0.29468742903974865
Epoch 240
-------------------------------
Batch 1/64 loss: 0.22857367992401123
Batch 2/64 loss: 0.21876657009124756
Batch 3/64 loss: 0.2233451008796692
Batch 4/64 loss: 0.215734601020813
Batch 5/64 loss: 0.22263073921203613
Batch 6/64 loss: 0.21542412042617798
Batch 7/64 loss: 0.21987587213516235
Batch 8/64 loss: 0.2227368950843811
Batch 9/64 loss: 0.2308979034423828
Batch 10/64 loss: 0.23666644096374512
Batch 11/64 loss: 0.22097474336624146
Batch 12/64 loss: 0.22939586639404297
Batch 13/64 loss: 0.21880483627319336
Batch 14/64 loss: 0.22166657447814941
Batch 15/64 loss: 0.22109496593475342
Batch 16/64 loss: 0.22712266445159912
Batch 17/64 loss: 0.21666979789733887
Batch 18/64 loss: 0.21118402481079102
Batch 19/64 loss: 0.22888630628585815
Batch 20/64 loss: 0.2272319793701172
Batch 21/64 loss: 0.223677396774292
Batch 22/64 loss: 0.21729373931884766
Batch 23/64 loss: 0.22334080934524536
Batch 24/64 loss: 0.2190842628479004
Batch 25/64 loss: 0.21928519010543823
Batch 26/64 loss: 0.21097809076309204
Batch 27/64 loss: 0.22217273712158203
Batch 28/64 loss: 0.21970140933990479
Batch 29/64 loss: 0.22960537672042847
Batch 30/64 loss: 0.23261278867721558
Batch 31/64 loss: 0.22534239292144775
Batch 32/64 loss: 0.2200070023536682
Batch 33/64 loss: 0.22227942943572998
Batch 34/64 loss: 0.2277308702468872
Batch 35/64 loss: 0.21705609560012817
Batch 36/64 loss: 0.22090458869934082
Batch 37/64 loss: 0.22234117984771729
Batch 38/64 loss: 0.2281402349472046
Batch 39/64 loss: 0.22010058164596558
Batch 40/64 loss: 0.22815412282943726
Batch 41/64 loss: 0.21722614765167236
Batch 42/64 loss: 0.22394096851348877
Batch 43/64 loss: 0.22688788175582886
Batch 44/64 loss: 0.22734683752059937
Batch 45/64 loss: 0.21970230340957642
Batch 46/64 loss: 0.22703158855438232
Batch 47/64 loss: 0.22270327806472778
Batch 48/64 loss: 0.22533100843429565
Batch 49/64 loss: 0.22701436281204224
Batch 50/64 loss: 0.2145298719406128
Batch 51/64 loss: 0.22108691930770874
Batch 52/64 loss: 0.23376047611236572
Batch 53/64 loss: 0.21997451782226562
Batch 54/64 loss: 0.22719687223434448
Batch 55/64 loss: 0.2256561517715454
Batch 56/64 loss: 0.23023247718811035
Batch 57/64 loss: 0.2265322208404541
Batch 58/64 loss: 0.22332346439361572
Batch 59/64 loss: 0.23951852321624756
Batch 60/64 loss: 0.23198455572128296
Batch 61/64 loss: 0.2397608757019043
Batch 62/64 loss: 0.22874164581298828
Batch 63/64 loss: 0.22318923473358154
Batch 64/64 loss: 0.2154529094696045
Epoch 240  Train loss: 0.2238706485897887  Val loss: 0.2920910533760831
Saving best model, epoch: 240
Epoch 241
-------------------------------
Batch 1/64 loss: 0.20860642194747925
Batch 2/64 loss: 0.21568822860717773
Batch 3/64 loss: 0.21786844730377197
Batch 4/64 loss: 0.22024905681610107
Batch 5/64 loss: 0.22379201650619507
Batch 6/64 loss: 0.23344898223876953
Batch 7/64 loss: 0.21708452701568604
Batch 8/64 loss: 0.22505545616149902
Batch 9/64 loss: 0.22420066595077515
Batch 10/64 loss: 0.2206730842590332
Batch 11/64 loss: 0.23039400577545166
Batch 12/64 loss: 0.2293184995651245
Batch 13/64 loss: 0.2269374132156372
Batch 14/64 loss: 0.22153031826019287
Batch 15/64 loss: 0.22205591201782227
Batch 16/64 loss: 0.2336139678955078
Batch 17/64 loss: 0.22065383195877075
Batch 18/64 loss: 0.21661633253097534
Batch 19/64 loss: 0.21677088737487793
Batch 20/64 loss: 0.22503089904785156
Batch 21/64 loss: 0.2165294885635376
Batch 22/64 loss: 0.22777915000915527
Batch 23/64 loss: 0.22319245338439941
Batch 24/64 loss: 0.22876310348510742
Batch 25/64 loss: 0.22763323783874512
Batch 26/64 loss: 0.2176302671432495
Batch 27/64 loss: 0.2262892723083496
Batch 28/64 loss: 0.2214248776435852
Batch 29/64 loss: 0.21877598762512207
Batch 30/64 loss: 0.23401212692260742
Batch 31/64 loss: 0.21356111764907837
Batch 32/64 loss: 0.22359877824783325
Batch 33/64 loss: 0.21772676706314087
Batch 34/64 loss: 0.21863579750061035
Batch 35/64 loss: 0.21703392267227173
Batch 36/64 loss: 0.22066879272460938
Batch 37/64 loss: 0.22145414352416992
Batch 38/64 loss: 0.22071558237075806
Batch 39/64 loss: 0.2271742820739746
Batch 40/64 loss: 0.226468026638031
Batch 41/64 loss: 0.2254694700241089
Batch 42/64 loss: 0.2219754457473755
Batch 43/64 loss: 0.2219322919845581
Batch 44/64 loss: 0.22923612594604492
Batch 45/64 loss: 0.21393591165542603
Batch 46/64 loss: 0.2213050127029419
Batch 47/64 loss: 0.22278666496276855
Batch 48/64 loss: 0.2172783613204956
Batch 49/64 loss: 0.23526346683502197
Batch 50/64 loss: 0.22095215320587158
Batch 51/64 loss: 0.2183670997619629
Batch 52/64 loss: 0.22771406173706055
Batch 53/64 loss: 0.22802317142486572
Batch 54/64 loss: 0.23434346914291382
Batch 55/64 loss: 0.2338801622390747
Batch 56/64 loss: 0.23026740550994873
Batch 57/64 loss: 0.22252768278121948
Batch 58/64 loss: 0.23000168800354004
Batch 59/64 loss: 0.21982187032699585
Batch 60/64 loss: 0.23698759078979492
Batch 61/64 loss: 0.21817421913146973
Batch 62/64 loss: 0.23210978507995605
Batch 63/64 loss: 0.2170192003250122
Batch 64/64 loss: 0.23284494876861572
Epoch 241  Train loss: 0.22357117101257923  Val loss: 0.29340783959811495
Epoch 242
-------------------------------
Batch 1/64 loss: 0.22782742977142334
Batch 2/64 loss: 0.21757769584655762
Batch 3/64 loss: 0.22186195850372314
Batch 4/64 loss: 0.21564233303070068
Batch 5/64 loss: 0.2264847755432129
Batch 6/64 loss: 0.22055047750473022
Batch 7/64 loss: 0.2237781286239624
Batch 8/64 loss: 0.23589181900024414
Batch 9/64 loss: 0.229653000831604
Batch 10/64 loss: 0.2234601378440857
Batch 11/64 loss: 0.21718692779541016
Batch 12/64 loss: 0.22033143043518066
Batch 13/64 loss: 0.2421918511390686
Batch 14/64 loss: 0.21720707416534424
Batch 15/64 loss: 0.22439181804656982
Batch 16/64 loss: 0.23082959651947021
Batch 17/64 loss: 0.22055739164352417
Batch 18/64 loss: 0.21979749202728271
Batch 19/64 loss: 0.21590447425842285
Batch 20/64 loss: 0.22872179746627808
Batch 21/64 loss: 0.2164367437362671
Batch 22/64 loss: 0.21912533044815063
Batch 23/64 loss: 0.23202729225158691
Batch 24/64 loss: 0.23576945066452026
Batch 25/64 loss: 0.216424822807312
Batch 26/64 loss: 0.22096818685531616
Batch 27/64 loss: 0.22830301523208618
Batch 28/64 loss: 0.21445852518081665
Batch 29/64 loss: 0.22341740131378174
Batch 30/64 loss: 0.2207481861114502
Batch 31/64 loss: 0.22276020050048828
Batch 32/64 loss: 0.2275959849357605
Batch 33/64 loss: 0.21865969896316528
Batch 34/64 loss: 0.21733880043029785
Batch 35/64 loss: 0.2260846495628357
Batch 36/64 loss: 0.22858524322509766
Batch 37/64 loss: 0.23533248901367188
Batch 38/64 loss: 0.22650134563446045
Batch 39/64 loss: 0.23001158237457275
Batch 40/64 loss: 0.2242000699043274
Batch 41/64 loss: 0.2195807695388794
Batch 42/64 loss: 0.2240452766418457
Batch 43/64 loss: 0.22290384769439697
Batch 44/64 loss: 0.24301910400390625
Batch 45/64 loss: 0.22725975513458252
Batch 46/64 loss: 0.2213747501373291
Batch 47/64 loss: 0.22293031215667725
Batch 48/64 loss: 0.23401963710784912
Batch 49/64 loss: 0.2272655963897705
Batch 50/64 loss: 0.23688215017318726
Batch 51/64 loss: 0.21578717231750488
Batch 52/64 loss: 0.22277843952178955
Batch 53/64 loss: 0.23382937908172607
Batch 54/64 loss: 0.22340333461761475
Batch 55/64 loss: 0.2257881760597229
Batch 56/64 loss: 0.21334010362625122
Batch 57/64 loss: 0.21703940629959106
Batch 58/64 loss: 0.22562628984451294
Batch 59/64 loss: 0.21858298778533936
Batch 60/64 loss: 0.22342920303344727
Batch 61/64 loss: 0.21249210834503174
Batch 62/64 loss: 0.23029857873916626
Batch 63/64 loss: 0.23009717464447021
Batch 64/64 loss: 0.22659087181091309
Epoch 242  Train loss: 0.2244127582101261  Val loss: 0.2931171909640335
Epoch 243
-------------------------------
Batch 1/64 loss: 0.21737706661224365
Batch 2/64 loss: 0.21950209140777588
Batch 3/64 loss: 0.21263402700424194
Batch 4/64 loss: 0.2164008617401123
Batch 5/64 loss: 0.2396373748779297
Batch 6/64 loss: 0.22890055179595947
Batch 7/64 loss: 0.21088415384292603
Batch 8/64 loss: 0.22267842292785645
Batch 9/64 loss: 0.23263537883758545
Batch 10/64 loss: 0.22305357456207275
Batch 11/64 loss: 0.22087836265563965
Batch 12/64 loss: 0.22080421447753906
Batch 13/64 loss: 0.21336615085601807
Batch 14/64 loss: 0.21928906440734863
Batch 15/64 loss: 0.2186131477355957
Batch 16/64 loss: 0.22442126274108887
Batch 17/64 loss: 0.2182038426399231
Batch 18/64 loss: 0.22812575101852417
Batch 19/64 loss: 0.23353898525238037
Batch 20/64 loss: 0.22033679485321045
Batch 21/64 loss: 0.21830123662948608
Batch 22/64 loss: 0.228368878364563
Batch 23/64 loss: 0.22472858428955078
Batch 24/64 loss: 0.22236484289169312
Batch 25/64 loss: 0.22598689794540405
Batch 26/64 loss: 0.22353363037109375
Batch 27/64 loss: 0.22518736124038696
Batch 28/64 loss: 0.2274627685546875
Batch 29/64 loss: 0.2204592227935791
Batch 30/64 loss: 0.215587317943573
Batch 31/64 loss: 0.2270878553390503
Batch 32/64 loss: 0.22342431545257568
Batch 33/64 loss: 0.22053253650665283
Batch 34/64 loss: 0.222822904586792
Batch 35/64 loss: 0.23906707763671875
Batch 36/64 loss: 0.22568637132644653
Batch 37/64 loss: 0.21790480613708496
Batch 38/64 loss: 0.22139394283294678
Batch 39/64 loss: 0.21611088514328003
Batch 40/64 loss: 0.22165298461914062
Batch 41/64 loss: 0.2251855731010437
Batch 42/64 loss: 0.21320319175720215
Batch 43/64 loss: 0.22365224361419678
Batch 44/64 loss: 0.2147504687309265
Batch 45/64 loss: 0.22554564476013184
Batch 46/64 loss: 0.21298003196716309
Batch 47/64 loss: 0.23373383283615112
Batch 48/64 loss: 0.2106528878211975
Batch 49/64 loss: 0.21502584218978882
Batch 50/64 loss: 0.21433484554290771
Batch 51/64 loss: 0.221640944480896
Batch 52/64 loss: 0.2413560152053833
Batch 53/64 loss: 0.22671043872833252
Batch 54/64 loss: 0.22180628776550293
Batch 55/64 loss: 0.21699851751327515
Batch 56/64 loss: 0.22955358028411865
Batch 57/64 loss: 0.2302650809288025
Batch 58/64 loss: 0.2315967082977295
Batch 59/64 loss: 0.2176474928855896
Batch 60/64 loss: 0.23608434200286865
Batch 61/64 loss: 0.22069746255874634
Batch 62/64 loss: 0.21601474285125732
Batch 63/64 loss: 0.226324200630188
Batch 64/64 loss: 0.22272568941116333
Epoch 243  Train loss: 0.22277255128411685  Val loss: 0.29336847226644297
Epoch 244
-------------------------------
Batch 1/64 loss: 0.2291356325149536
Batch 2/64 loss: 0.22867023944854736
Batch 3/64 loss: 0.2139914631843567
Batch 4/64 loss: 0.2282460331916809
Batch 5/64 loss: 0.22339117527008057
Batch 6/64 loss: 0.2174665927886963
Batch 7/64 loss: 0.21864694356918335
Batch 8/64 loss: 0.2207513451576233
Batch 9/64 loss: 0.2230646014213562
Batch 10/64 loss: 0.22028088569641113
Batch 11/64 loss: 0.2178499698638916
Batch 12/64 loss: 0.21934133768081665
Batch 13/64 loss: 0.2159879207611084
Batch 14/64 loss: 0.22496962547302246
Batch 15/64 loss: 0.22141337394714355
Batch 16/64 loss: 0.23207074403762817
Batch 17/64 loss: 0.20985066890716553
Batch 18/64 loss: 0.2279592752456665
Batch 19/64 loss: 0.21917366981506348
Batch 20/64 loss: 0.2332751750946045
Batch 21/64 loss: 0.23426610231399536
Batch 22/64 loss: 0.22489547729492188
Batch 23/64 loss: 0.2187892198562622
Batch 24/64 loss: 0.23313379287719727
Batch 25/64 loss: 0.21644222736358643
Batch 26/64 loss: 0.2229892611503601
Batch 27/64 loss: 0.22246968746185303
Batch 28/64 loss: 0.217659592628479
Batch 29/64 loss: 0.21501362323760986
Batch 30/64 loss: 0.2273784875869751
Batch 31/64 loss: 0.22417086362838745
Batch 32/64 loss: 0.21489745378494263
Batch 33/64 loss: 0.2292114496231079
Batch 34/64 loss: 0.23212772607803345
Batch 35/64 loss: 0.225793719291687
Batch 36/64 loss: 0.22936832904815674
Batch 37/64 loss: 0.23133832216262817
Batch 38/64 loss: 0.21432268619537354
Batch 39/64 loss: 0.22649693489074707
Batch 40/64 loss: 0.22664713859558105
Batch 41/64 loss: 0.2133130431175232
Batch 42/64 loss: 0.2253360152244568
Batch 43/64 loss: 0.2198885679244995
Batch 44/64 loss: 0.21770870685577393
Batch 45/64 loss: 0.23069602251052856
Batch 46/64 loss: 0.21420687437057495
Batch 47/64 loss: 0.21285343170166016
Batch 48/64 loss: 0.22874236106872559
Batch 49/64 loss: 0.22291940450668335
Batch 50/64 loss: 0.23418104648590088
Batch 51/64 loss: 0.22036969661712646
Batch 52/64 loss: 0.22286969423294067
Batch 53/64 loss: 0.21659976243972778
Batch 54/64 loss: 0.23238027095794678
Batch 55/64 loss: 0.21730732917785645
Batch 56/64 loss: 0.22721856832504272
Batch 57/64 loss: 0.21754014492034912
Batch 58/64 loss: 0.22797387838363647
Batch 59/64 loss: 0.22834694385528564
Batch 60/64 loss: 0.21627336740493774
Batch 61/64 loss: 0.22738909721374512
Batch 62/64 loss: 0.23438119888305664
Batch 63/64 loss: 0.2339712381362915
Batch 64/64 loss: 0.22240078449249268
Epoch 244  Train loss: 0.2234073101305494  Val loss: 0.2933723885578798
Epoch 245
-------------------------------
Batch 1/64 loss: 0.21734857559204102
Batch 2/64 loss: 0.22637993097305298
Batch 3/64 loss: 0.23094332218170166
Batch 4/64 loss: 0.2185060977935791
Batch 5/64 loss: 0.21345555782318115
Batch 6/64 loss: 0.2205822467803955
Batch 7/64 loss: 0.22169220447540283
Batch 8/64 loss: 0.2217724323272705
Batch 9/64 loss: 0.2180902361869812
Batch 10/64 loss: 0.21675097942352295
Batch 11/64 loss: 0.22276967763900757
Batch 12/64 loss: 0.21217644214630127
Batch 13/64 loss: 0.2264074683189392
Batch 14/64 loss: 0.2326938509941101
Batch 15/64 loss: 0.2258344292640686
Batch 16/64 loss: 0.22031819820404053
Batch 17/64 loss: 0.2338780164718628
Batch 18/64 loss: 0.22900056838989258
Batch 19/64 loss: 0.2224346399307251
Batch 20/64 loss: 0.23235797882080078
Batch 21/64 loss: 0.22173607349395752
Batch 22/64 loss: 0.21557199954986572
Batch 23/64 loss: 0.2155221700668335
Batch 24/64 loss: 0.22074764966964722
Batch 25/64 loss: 0.22665202617645264
Batch 26/64 loss: 0.2198622226715088
Batch 27/64 loss: 0.22216832637786865
Batch 28/64 loss: 0.22213506698608398
Batch 29/64 loss: 0.23003220558166504
Batch 30/64 loss: 0.22232985496520996
Batch 31/64 loss: 0.2234196662902832
Batch 32/64 loss: 0.23069697618484497
Batch 33/64 loss: 0.22806328535079956
Batch 34/64 loss: 0.24146628379821777
Batch 35/64 loss: 0.22149372100830078
Batch 36/64 loss: 0.2153281569480896
Batch 37/64 loss: 0.2172539234161377
Batch 38/64 loss: 0.2314988374710083
Batch 39/64 loss: 0.23262202739715576
Batch 40/64 loss: 0.223260760307312
Batch 41/64 loss: 0.2182941436767578
Batch 42/64 loss: 0.21507799625396729
Batch 43/64 loss: 0.23110973834991455
Batch 44/64 loss: 0.21463918685913086
Batch 45/64 loss: 0.2398827075958252
Batch 46/64 loss: 0.23003780841827393
Batch 47/64 loss: 0.22759926319122314
Batch 48/64 loss: 0.21198183298110962
Batch 49/64 loss: 0.22208577394485474
Batch 50/64 loss: 0.22205626964569092
Batch 51/64 loss: 0.22404181957244873
Batch 52/64 loss: 0.21754181385040283
Batch 53/64 loss: 0.22761428356170654
Batch 54/64 loss: 0.21307820081710815
Batch 55/64 loss: 0.2294887900352478
Batch 56/64 loss: 0.21730756759643555
Batch 57/64 loss: 0.2220010757446289
Batch 58/64 loss: 0.2323070764541626
Batch 59/64 loss: 0.23023080825805664
Batch 60/64 loss: 0.22869139909744263
Batch 61/64 loss: 0.23408466577529907
Batch 62/64 loss: 0.22210460901260376
Batch 63/64 loss: 0.22064530849456787
Batch 64/64 loss: 0.21384626626968384
Epoch 245  Train loss: 0.22364770080529006  Val loss: 0.29282480949388745
Epoch 246
-------------------------------
Batch 1/64 loss: 0.22289705276489258
Batch 2/64 loss: 0.22606194019317627
Batch 3/64 loss: 0.21582448482513428
Batch 4/64 loss: 0.22585022449493408
Batch 5/64 loss: 0.22097009420394897
Batch 6/64 loss: 0.21908968687057495
Batch 7/64 loss: 0.2155483365058899
Batch 8/64 loss: 0.2279931902885437
Batch 9/64 loss: 0.22122716903686523
Batch 10/64 loss: 0.2164691686630249
Batch 11/64 loss: 0.22454947233200073
Batch 12/64 loss: 0.21486186981201172
Batch 13/64 loss: 0.2241111397743225
Batch 14/64 loss: 0.22142702341079712
Batch 15/64 loss: 0.2323797345161438
Batch 16/64 loss: 0.22548705339431763
Batch 17/64 loss: 0.22266030311584473
Batch 18/64 loss: 0.22331547737121582
Batch 19/64 loss: 0.21651923656463623
Batch 20/64 loss: 0.22041326761245728
Batch 21/64 loss: 0.2219679355621338
Batch 22/64 loss: 0.21767151355743408
Batch 23/64 loss: 0.22845613956451416
Batch 24/64 loss: 0.21539181470870972
Batch 25/64 loss: 0.22438883781433105
Batch 26/64 loss: 0.23149961233139038
Batch 27/64 loss: 0.2231956124305725
Batch 28/64 loss: 0.21817433834075928
Batch 29/64 loss: 0.2186288833618164
Batch 30/64 loss: 0.22098016738891602
Batch 31/64 loss: 0.22868669033050537
Batch 32/64 loss: 0.21781224012374878
Batch 33/64 loss: 0.23373550176620483
Batch 34/64 loss: 0.22855520248413086
Batch 35/64 loss: 0.21360516548156738
Batch 36/64 loss: 0.2202436923980713
Batch 37/64 loss: 0.21660476922988892
Batch 38/64 loss: 0.21491611003875732
Batch 39/64 loss: 0.2262575626373291
Batch 40/64 loss: 0.2249692678451538
Batch 41/64 loss: 0.21343904733657837
Batch 42/64 loss: 0.21500205993652344
Batch 43/64 loss: 0.22500377893447876
Batch 44/64 loss: 0.24337857961654663
Batch 45/64 loss: 0.22484081983566284
Batch 46/64 loss: 0.23116660118103027
Batch 47/64 loss: 0.23326706886291504
Batch 48/64 loss: 0.22243058681488037
Batch 49/64 loss: 0.22329366207122803
Batch 50/64 loss: 0.2198193073272705
Batch 51/64 loss: 0.2215803861618042
Batch 52/64 loss: 0.2170257568359375
Batch 53/64 loss: 0.22322499752044678
Batch 54/64 loss: 0.2223491668701172
Batch 55/64 loss: 0.22743302583694458
Batch 56/64 loss: 0.22631090879440308
Batch 57/64 loss: 0.2316751480102539
Batch 58/64 loss: 0.23378634452819824
Batch 59/64 loss: 0.2242565155029297
Batch 60/64 loss: 0.22633814811706543
Batch 61/64 loss: 0.22293221950531006
Batch 62/64 loss: 0.22856128215789795
Batch 63/64 loss: 0.22696447372436523
Batch 64/64 loss: 0.2282935380935669
Epoch 246  Train loss: 0.22335211015215106  Val loss: 0.2933470776810269
Epoch 247
-------------------------------
Batch 1/64 loss: 0.2154942750930786
Batch 2/64 loss: 0.22322160005569458
Batch 3/64 loss: 0.21353399753570557
Batch 4/64 loss: 0.2224312424659729
Batch 5/64 loss: 0.22143328189849854
Batch 6/64 loss: 0.22359192371368408
Batch 7/64 loss: 0.22418749332427979
Batch 8/64 loss: 0.22648143768310547
Batch 9/64 loss: 0.22073793411254883
Batch 10/64 loss: 0.21638667583465576
Batch 11/64 loss: 0.22711116075515747
Batch 12/64 loss: 0.21954607963562012
Batch 13/64 loss: 0.22259676456451416
Batch 14/64 loss: 0.21933412551879883
Batch 15/64 loss: 0.21579039096832275
Batch 16/64 loss: 0.22908788919448853
Batch 17/64 loss: 0.22111499309539795
Batch 18/64 loss: 0.22525978088378906
Batch 19/64 loss: 0.21211957931518555
Batch 20/64 loss: 0.22394901514053345
Batch 21/64 loss: 0.21803200244903564
Batch 22/64 loss: 0.2164602279663086
Batch 23/64 loss: 0.21129119396209717
Batch 24/64 loss: 0.21860051155090332
Batch 25/64 loss: 0.2253265380859375
Batch 26/64 loss: 0.22148007154464722
Batch 27/64 loss: 0.23168784379959106
Batch 28/64 loss: 0.21312904357910156
Batch 29/64 loss: 0.218009352684021
Batch 30/64 loss: 0.21373116970062256
Batch 31/64 loss: 0.23060786724090576
Batch 32/64 loss: 0.21348047256469727
Batch 33/64 loss: 0.2194393277168274
Batch 34/64 loss: 0.22164255380630493
Batch 35/64 loss: 0.22087323665618896
Batch 36/64 loss: 0.23381805419921875
Batch 37/64 loss: 0.22808873653411865
Batch 38/64 loss: 0.23154574632644653
Batch 39/64 loss: 0.2274637222290039
Batch 40/64 loss: 0.22095704078674316
Batch 41/64 loss: 0.23375076055526733
Batch 42/64 loss: 0.2158605456352234
Batch 43/64 loss: 0.22257697582244873
Batch 44/64 loss: 0.22059166431427002
Batch 45/64 loss: 0.22385525703430176
Batch 46/64 loss: 0.21842992305755615
Batch 47/64 loss: 0.2208646535873413
Batch 48/64 loss: 0.2263413667678833
Batch 49/64 loss: 0.2273731231689453
Batch 50/64 loss: 0.2220403552055359
Batch 51/64 loss: 0.22311055660247803
Batch 52/64 loss: 0.22931957244873047
Batch 53/64 loss: 0.2228628396987915
Batch 54/64 loss: 0.22285819053649902
Batch 55/64 loss: 0.23077607154846191
Batch 56/64 loss: 0.21937215328216553
Batch 57/64 loss: 0.23969924449920654
Batch 58/64 loss: 0.2279776930809021
Batch 59/64 loss: 0.21858304738998413
Batch 60/64 loss: 0.22731149196624756
Batch 61/64 loss: 0.2230626344680786
Batch 62/64 loss: 0.22340941429138184
Batch 63/64 loss: 0.2184227705001831
Batch 64/64 loss: 0.22837138175964355
Epoch 247  Train loss: 0.22256946189730775  Val loss: 0.292725180022905
Epoch 248
-------------------------------
Batch 1/64 loss: 0.23816871643066406
Batch 2/64 loss: 0.2232491374015808
Batch 3/64 loss: 0.22653621435165405
Batch 4/64 loss: 0.21905410289764404
Batch 5/64 loss: 0.2219836711883545
Batch 6/64 loss: 0.22476565837860107
Batch 7/64 loss: 0.21484094858169556
Batch 8/64 loss: 0.2233971357345581
Batch 9/64 loss: 0.21840524673461914
Batch 10/64 loss: 0.23005712032318115
Batch 11/64 loss: 0.22543954849243164
Batch 12/64 loss: 0.21501541137695312
Batch 13/64 loss: 0.21904897689819336
Batch 14/64 loss: 0.22523832321166992
Batch 15/64 loss: 0.21304261684417725
Batch 16/64 loss: 0.22987854480743408
Batch 17/64 loss: 0.21205931901931763
Batch 18/64 loss: 0.23143327236175537
Batch 19/64 loss: 0.22093838453292847
Batch 20/64 loss: 0.2252013087272644
Batch 21/64 loss: 0.21857750415802002
Batch 22/64 loss: 0.22945958375930786
Batch 23/64 loss: 0.22060447931289673
Batch 24/64 loss: 0.22031527757644653
Batch 25/64 loss: 0.22328555583953857
Batch 26/64 loss: 0.2271660566329956
Batch 27/64 loss: 0.22273796796798706
Batch 28/64 loss: 0.23258978128433228
Batch 29/64 loss: 0.21581149101257324
Batch 30/64 loss: 0.22466540336608887
Batch 31/64 loss: 0.2117478847503662
Batch 32/64 loss: 0.22207164764404297
Batch 33/64 loss: 0.2278132438659668
Batch 34/64 loss: 0.22162890434265137
Batch 35/64 loss: 0.21633243560791016
Batch 36/64 loss: 0.23444509506225586
Batch 37/64 loss: 0.22042202949523926
Batch 38/64 loss: 0.23119014501571655
Batch 39/64 loss: 0.2115408182144165
Batch 40/64 loss: 0.2292262315750122
Batch 41/64 loss: 0.22852706909179688
Batch 42/64 loss: 0.22024959325790405
Batch 43/64 loss: 0.21880090236663818
Batch 44/64 loss: 0.2193598747253418
Batch 45/64 loss: 0.219818115234375
Batch 46/64 loss: 0.22632169723510742
Batch 47/64 loss: 0.2317894697189331
Batch 48/64 loss: 0.21245187520980835
Batch 49/64 loss: 0.21250176429748535
Batch 50/64 loss: 0.21229547262191772
Batch 51/64 loss: 0.21336627006530762
Batch 52/64 loss: 0.2134864330291748
Batch 53/64 loss: 0.22060883045196533
Batch 54/64 loss: 0.22071897983551025
Batch 55/64 loss: 0.21357768774032593
Batch 56/64 loss: 0.22690749168395996
Batch 57/64 loss: 0.22459477186203003
Batch 58/64 loss: 0.21125197410583496
Batch 59/64 loss: 0.23003721237182617
Batch 60/64 loss: 0.21953034400939941
Batch 61/64 loss: 0.22523081302642822
Batch 62/64 loss: 0.217867910861969
Batch 63/64 loss: 0.21668672561645508
Batch 64/64 loss: 0.22124695777893066
Epoch 248  Train loss: 0.2218243402593276  Val loss: 0.29348970278841524
Epoch 249
-------------------------------
Batch 1/64 loss: 0.2162603735923767
Batch 2/64 loss: 0.21131455898284912
Batch 3/64 loss: 0.2181694507598877
Batch 4/64 loss: 0.226951003074646
Batch 5/64 loss: 0.22342270612716675
Batch 6/64 loss: 0.23024916648864746
Batch 7/64 loss: 0.2233484983444214
Batch 8/64 loss: 0.22588777542114258
Batch 9/64 loss: 0.21161675453186035
Batch 10/64 loss: 0.22868084907531738
Batch 11/64 loss: 0.22265291213989258
Batch 12/64 loss: 0.22377347946166992
Batch 13/64 loss: 0.21775561571121216
Batch 14/64 loss: 0.22433120012283325
Batch 15/64 loss: 0.22886091470718384
Batch 16/64 loss: 0.21798276901245117
Batch 17/64 loss: 0.22601401805877686
Batch 18/64 loss: 0.2219035029411316
Batch 19/64 loss: 0.22035932540893555
Batch 20/64 loss: 0.21939921379089355
Batch 21/64 loss: 0.2194077968597412
Batch 22/64 loss: 0.2197190523147583
Batch 23/64 loss: 0.2180187702178955
Batch 24/64 loss: 0.21577823162078857
Batch 25/64 loss: 0.223993718624115
Batch 26/64 loss: 0.2169860601425171
Batch 27/64 loss: 0.21703177690505981
Batch 28/64 loss: 0.22241032123565674
Batch 29/64 loss: 0.22182750701904297
Batch 30/64 loss: 0.21642839908599854
Batch 31/64 loss: 0.22629690170288086
Batch 32/64 loss: 0.21833497285842896
Batch 33/64 loss: 0.23238587379455566
Batch 34/64 loss: 0.21091735363006592
Batch 35/64 loss: 0.2322494387626648
Batch 36/64 loss: 0.23505449295043945
Batch 37/64 loss: 0.22429072856903076
Batch 38/64 loss: 0.237352192401886
Batch 39/64 loss: 0.2210252285003662
Batch 40/64 loss: 0.22369205951690674
Batch 41/64 loss: 0.22291111946105957
Batch 42/64 loss: 0.21822088956832886
Batch 43/64 loss: 0.22541701793670654
Batch 44/64 loss: 0.22710728645324707
Batch 45/64 loss: 0.23327022790908813
Batch 46/64 loss: 0.2188507318496704
Batch 47/64 loss: 0.2265775203704834
Batch 48/64 loss: 0.2181868553161621
Batch 49/64 loss: 0.2085120677947998
Batch 50/64 loss: 0.22340434789657593
Batch 51/64 loss: 0.22781968116760254
Batch 52/64 loss: 0.22379374504089355
Batch 53/64 loss: 0.22793126106262207
Batch 54/64 loss: 0.23131364583969116
Batch 55/64 loss: 0.2168189287185669
Batch 56/64 loss: 0.22968637943267822
Batch 57/64 loss: 0.21887338161468506
Batch 58/64 loss: 0.2235034704208374
Batch 59/64 loss: 0.22886210680007935
Batch 60/64 loss: 0.2207498550415039
Batch 61/64 loss: 0.21842169761657715
Batch 62/64 loss: 0.22128379344940186
Batch 63/64 loss: 0.22557789087295532
Batch 64/64 loss: 0.22149032354354858
Epoch 249  Train loss: 0.22267210366679172  Val loss: 0.29458233396621913
Epoch 250
-------------------------------
Batch 1/64 loss: 0.22153019905090332
Batch 2/64 loss: 0.22606319189071655
Batch 3/64 loss: 0.21875929832458496
Batch 4/64 loss: 0.22631949186325073
Batch 5/64 loss: 0.24409222602844238
Batch 6/64 loss: 0.20993101596832275
Batch 7/64 loss: 0.22289645671844482
Batch 8/64 loss: 0.23269027471542358
Batch 9/64 loss: 0.21059352159500122
Batch 10/64 loss: 0.21475863456726074
Batch 11/64 loss: 0.21983182430267334
Batch 12/64 loss: 0.21989691257476807
Batch 13/64 loss: 0.21280723810195923
Batch 14/64 loss: 0.21853762865066528
Batch 15/64 loss: 0.21636801958084106
Batch 16/64 loss: 0.2292768955230713
Batch 17/64 loss: 0.21465343236923218
Batch 18/64 loss: 0.23165005445480347
Batch 19/64 loss: 0.22153425216674805
Batch 20/64 loss: 0.22036778926849365
Batch 21/64 loss: 0.22312963008880615
Batch 22/64 loss: 0.22426646947860718
Batch 23/64 loss: 0.21922051906585693
Batch 24/64 loss: 0.22686320543289185
Batch 25/64 loss: 0.22046244144439697
Batch 26/64 loss: 0.22674310207366943
Batch 27/64 loss: 0.23098421096801758
Batch 28/64 loss: 0.224143385887146
Batch 29/64 loss: 0.22371411323547363
Batch 30/64 loss: 0.22129690647125244
Batch 31/64 loss: 0.2252216339111328
Batch 32/64 loss: 0.21629035472869873
Batch 33/64 loss: 0.21332550048828125
Batch 34/64 loss: 0.2275235652923584
Batch 35/64 loss: 0.23257100582122803
Batch 36/64 loss: 0.22968733310699463
Batch 37/64 loss: 0.2049502730369568
Batch 38/64 loss: 0.22318994998931885
Batch 39/64 loss: 0.22406691312789917
Batch 40/64 loss: 0.21616971492767334
Batch 41/64 loss: 0.22406601905822754
Batch 42/64 loss: 0.21204125881195068
Batch 43/64 loss: 0.2179347276687622
Batch 44/64 loss: 0.22116976976394653
Batch 45/64 loss: 0.2193036675453186
Batch 46/64 loss: 0.2281644344329834
Batch 47/64 loss: 0.2169111967086792
Batch 48/64 loss: 0.22611761093139648
Batch 49/64 loss: 0.227508544921875
Batch 50/64 loss: 0.22458618879318237
Batch 51/64 loss: 0.2239772081375122
Batch 52/64 loss: 0.22775113582611084
Batch 53/64 loss: 0.21016013622283936
Batch 54/64 loss: 0.23402893543243408
Batch 55/64 loss: 0.21129751205444336
Batch 56/64 loss: 0.2311357855796814
Batch 57/64 loss: 0.20810145139694214
Batch 58/64 loss: 0.22535240650177002
Batch 59/64 loss: 0.21791338920593262
Batch 60/64 loss: 0.22097843885421753
Batch 61/64 loss: 0.22144418954849243
Batch 62/64 loss: 0.21551525592803955
Batch 63/64 loss: 0.22787487506866455
Batch 64/64 loss: 0.21960479021072388
Epoch 250  Train loss: 0.22187319713480333  Val loss: 0.29304152419886637
Epoch 251
-------------------------------
Batch 1/64 loss: 0.2204992175102234
Batch 2/64 loss: 0.21740126609802246
Batch 3/64 loss: 0.22380119562149048
Batch 4/64 loss: 0.22298210859298706
Batch 5/64 loss: 0.2335669994354248
Batch 6/64 loss: 0.22054272890090942
Batch 7/64 loss: 0.20989751815795898
Batch 8/64 loss: 0.2161528468132019
Batch 9/64 loss: 0.22158807516098022
Batch 10/64 loss: 0.2239220142364502
Batch 11/64 loss: 0.2168792486190796
Batch 12/64 loss: 0.216294527053833
Batch 13/64 loss: 0.2169075608253479
Batch 14/64 loss: 0.21950209140777588
Batch 15/64 loss: 0.21852773427963257
Batch 16/64 loss: 0.21074622869491577
Batch 17/64 loss: 0.21702134609222412
Batch 18/64 loss: 0.20805829763412476
Batch 19/64 loss: 0.22475826740264893
Batch 20/64 loss: 0.21646928787231445
Batch 21/64 loss: 0.22324919700622559
Batch 22/64 loss: 0.22802340984344482
Batch 23/64 loss: 0.22835427522659302
Batch 24/64 loss: 0.22289955615997314
Batch 25/64 loss: 0.21918904781341553
Batch 26/64 loss: 0.21880334615707397
Batch 27/64 loss: 0.22845089435577393
Batch 28/64 loss: 0.2094743251800537
Batch 29/64 loss: 0.21920287609100342
Batch 30/64 loss: 0.22369718551635742
Batch 31/64 loss: 0.2152577042579651
Batch 32/64 loss: 0.22728514671325684
Batch 33/64 loss: 0.22179162502288818
Batch 34/64 loss: 0.2185155153274536
Batch 35/64 loss: 0.21462154388427734
Batch 36/64 loss: 0.22805023193359375
Batch 37/64 loss: 0.21623694896697998
Batch 38/64 loss: 0.2233993411064148
Batch 39/64 loss: 0.23089063167572021
Batch 40/64 loss: 0.23000174760818481
Batch 41/64 loss: 0.21838176250457764
Batch 42/64 loss: 0.234119713306427
Batch 43/64 loss: 0.21630889177322388
Batch 44/64 loss: 0.21742725372314453
Batch 45/64 loss: 0.22417962551116943
Batch 46/64 loss: 0.2289525270462036
Batch 47/64 loss: 0.21126258373260498
Batch 48/64 loss: 0.22152382135391235
Batch 49/64 loss: 0.21667826175689697
Batch 50/64 loss: 0.22684234380722046
Batch 51/64 loss: 0.21114373207092285
Batch 52/64 loss: 0.23123157024383545
Batch 53/64 loss: 0.22572803497314453
Batch 54/64 loss: 0.2224797010421753
Batch 55/64 loss: 0.22019100189208984
Batch 56/64 loss: 0.2307288646697998
Batch 57/64 loss: 0.2271326780319214
Batch 58/64 loss: 0.22098982334136963
Batch 59/64 loss: 0.23234283924102783
Batch 60/64 loss: 0.2177964448928833
Batch 61/64 loss: 0.21656274795532227
Batch 62/64 loss: 0.22395813465118408
Batch 63/64 loss: 0.22746485471725464
Batch 64/64 loss: 0.2176884412765503
Epoch 251  Train loss: 0.22132716319140266  Val loss: 0.2933074424356939
Epoch 252
-------------------------------
Batch 1/64 loss: 0.21622049808502197
Batch 2/64 loss: 0.21697068214416504
Batch 3/64 loss: 0.21524196863174438
Batch 4/64 loss: 0.21753990650177002
Batch 5/64 loss: 0.22960758209228516
Batch 6/64 loss: 0.22232520580291748
Batch 7/64 loss: 0.21489083766937256
Batch 8/64 loss: 0.22001725435256958
Batch 9/64 loss: 0.22405850887298584
Batch 10/64 loss: 0.20859169960021973
Batch 11/64 loss: 0.24021124839782715
Batch 12/64 loss: 0.22397983074188232
Batch 13/64 loss: 0.21483838558197021
Batch 14/64 loss: 0.21074962615966797
Batch 15/64 loss: 0.2230035662651062
Batch 16/64 loss: 0.2138417363166809
Batch 17/64 loss: 0.2240067720413208
Batch 18/64 loss: 0.21707522869110107
Batch 19/64 loss: 0.22925162315368652
Batch 20/64 loss: 0.2266978621482849
Batch 21/64 loss: 0.22115397453308105
Batch 22/64 loss: 0.20905745029449463
Batch 23/64 loss: 0.2199779748916626
Batch 24/64 loss: 0.21727359294891357
Batch 25/64 loss: 0.21319705247879028
Batch 26/64 loss: 0.21910375356674194
Batch 27/64 loss: 0.22590208053588867
Batch 28/64 loss: 0.21981245279312134
Batch 29/64 loss: 0.21487724781036377
Batch 30/64 loss: 0.22458994388580322
Batch 31/64 loss: 0.21835577487945557
Batch 32/64 loss: 0.23025727272033691
Batch 33/64 loss: 0.21412169933319092
Batch 34/64 loss: 0.2200613021850586
Batch 35/64 loss: 0.22232747077941895
Batch 36/64 loss: 0.21774405241012573
Batch 37/64 loss: 0.21756678819656372
Batch 38/64 loss: 0.223302960395813
Batch 39/64 loss: 0.23217225074768066
Batch 40/64 loss: 0.22475171089172363
Batch 41/64 loss: 0.21348565816879272
Batch 42/64 loss: 0.22786056995391846
Batch 43/64 loss: 0.2353883981704712
Batch 44/64 loss: 0.21642309427261353
Batch 45/64 loss: 0.22432076930999756
Batch 46/64 loss: 0.23175346851348877
Batch 47/64 loss: 0.2186950445175171
Batch 48/64 loss: 0.22329050302505493
Batch 49/64 loss: 0.2271404266357422
Batch 50/64 loss: 0.21007859706878662
Batch 51/64 loss: 0.2195340394973755
Batch 52/64 loss: 0.21880316734313965
Batch 53/64 loss: 0.21696996688842773
Batch 54/64 loss: 0.2199496030807495
Batch 55/64 loss: 0.23650622367858887
Batch 56/64 loss: 0.2334892749786377
Batch 57/64 loss: 0.22393786907196045
Batch 58/64 loss: 0.23100566864013672
Batch 59/64 loss: 0.21560728549957275
Batch 60/64 loss: 0.2167285680770874
Batch 61/64 loss: 0.23173832893371582
Batch 62/64 loss: 0.22130978107452393
Batch 63/64 loss: 0.21783006191253662
Batch 64/64 loss: 0.22610414028167725
Epoch 252  Train loss: 0.22142982436161415  Val loss: 0.2931319933986336
Epoch 253
-------------------------------
Batch 1/64 loss: 0.2095491886138916
Batch 2/64 loss: 0.2136460542678833
Batch 3/64 loss: 0.22355061769485474
Batch 4/64 loss: 0.22581887245178223
Batch 5/64 loss: 0.21487903594970703
Batch 6/64 loss: 0.21246284246444702
Batch 7/64 loss: 0.22960340976715088
Batch 8/64 loss: 0.2139701247215271
Batch 9/64 loss: 0.2189539074897766
Batch 10/64 loss: 0.23199748992919922
Batch 11/64 loss: 0.21292102336883545
Batch 12/64 loss: 0.21082091331481934
Batch 13/64 loss: 0.2204301357269287
Batch 14/64 loss: 0.22433888912200928
Batch 15/64 loss: 0.2259199619293213
Batch 16/64 loss: 0.21857845783233643
Batch 17/64 loss: 0.2166743278503418
Batch 18/64 loss: 0.22455161809921265
Batch 19/64 loss: 0.2137266993522644
Batch 20/64 loss: 0.21915769577026367
Batch 21/64 loss: 0.21986079216003418
Batch 22/64 loss: 0.2141643762588501
Batch 23/64 loss: 0.22665703296661377
Batch 24/64 loss: 0.21183061599731445
Batch 25/64 loss: 0.23318684101104736
Batch 26/64 loss: 0.20801222324371338
Batch 27/64 loss: 0.2160133719444275
Batch 28/64 loss: 0.21598762273788452
Batch 29/64 loss: 0.2321593165397644
Batch 30/64 loss: 0.22286534309387207
Batch 31/64 loss: 0.2231249213218689
Batch 32/64 loss: 0.22046124935150146
Batch 33/64 loss: 0.22040599584579468
Batch 34/64 loss: 0.2301405668258667
Batch 35/64 loss: 0.2200300693511963
Batch 36/64 loss: 0.2236020565032959
Batch 37/64 loss: 0.22414928674697876
Batch 38/64 loss: 0.2196502685546875
Batch 39/64 loss: 0.23456037044525146
Batch 40/64 loss: 0.21798259019851685
Batch 41/64 loss: 0.21199649572372437
Batch 42/64 loss: 0.2111530303955078
Batch 43/64 loss: 0.23095214366912842
Batch 44/64 loss: 0.2082902193069458
Batch 45/64 loss: 0.21986174583435059
Batch 46/64 loss: 0.2194598913192749
Batch 47/64 loss: 0.23306512832641602
Batch 48/64 loss: 0.22500354051589966
Batch 49/64 loss: 0.21478891372680664
Batch 50/64 loss: 0.22199702262878418
Batch 51/64 loss: 0.21997970342636108
Batch 52/64 loss: 0.21587377786636353
Batch 53/64 loss: 0.21209537982940674
Batch 54/64 loss: 0.2087109088897705
Batch 55/64 loss: 0.21810412406921387
Batch 56/64 loss: 0.21273553371429443
Batch 57/64 loss: 0.22639042139053345
Batch 58/64 loss: 0.22246325016021729
Batch 59/64 loss: 0.21934670209884644
Batch 60/64 loss: 0.22074002027511597
Batch 61/64 loss: 0.2149457335472107
Batch 62/64 loss: 0.2224278450012207
Batch 63/64 loss: 0.21791094541549683
Batch 64/64 loss: 0.215157151222229
Epoch 253  Train loss: 0.21970284733117795  Val loss: 0.29332621830845207
Epoch 254
-------------------------------
Batch 1/64 loss: 0.2248978614807129
Batch 2/64 loss: 0.2176647186279297
Batch 3/64 loss: 0.2188396453857422
Batch 4/64 loss: 0.2192552089691162
Batch 5/64 loss: 0.21119362115859985
Batch 6/64 loss: 0.21883738040924072
Batch 7/64 loss: 0.2256627082824707
Batch 8/64 loss: 0.2175123691558838
Batch 9/64 loss: 0.22480762004852295
Batch 10/64 loss: 0.21902626752853394
Batch 11/64 loss: 0.22034764289855957
Batch 12/64 loss: 0.21175003051757812
Batch 13/64 loss: 0.22882550954818726
Batch 14/64 loss: 0.2363494634628296
Batch 15/64 loss: 0.21818697452545166
Batch 16/64 loss: 0.22671401500701904
Batch 17/64 loss: 0.21148908138275146
Batch 18/64 loss: 0.21988201141357422
Batch 19/64 loss: 0.2252870798110962
Batch 20/64 loss: 0.2196056842803955
Batch 21/64 loss: 0.22333049774169922
Batch 22/64 loss: 0.23309999704360962
Batch 23/64 loss: 0.21924227476119995
Batch 24/64 loss: 0.2186908721923828
Batch 25/64 loss: 0.2177203893661499
Batch 26/64 loss: 0.22363096475601196
Batch 27/64 loss: 0.21629458665847778
Batch 28/64 loss: 0.2213173508644104
Batch 29/64 loss: 0.22409677505493164
Batch 30/64 loss: 0.21527111530303955
Batch 31/64 loss: 0.22393447160720825
Batch 32/64 loss: 0.22347009181976318
Batch 33/64 loss: 0.22035104036331177
Batch 34/64 loss: 0.22227871417999268
Batch 35/64 loss: 0.22343915700912476
Batch 36/64 loss: 0.22066372632980347
Batch 37/64 loss: 0.2208549976348877
Batch 38/64 loss: 0.21829813718795776
Batch 39/64 loss: 0.22643083333969116
Batch 40/64 loss: 0.2213207483291626
Batch 41/64 loss: 0.21885359287261963
Batch 42/64 loss: 0.21792900562286377
Batch 43/64 loss: 0.22279459238052368
Batch 44/64 loss: 0.21181917190551758
Batch 45/64 loss: 0.21762245893478394
Batch 46/64 loss: 0.23095130920410156
Batch 47/64 loss: 0.22434532642364502
Batch 48/64 loss: 0.22074288129806519
Batch 49/64 loss: 0.21349257230758667
Batch 50/64 loss: 0.21428650617599487
Batch 51/64 loss: 0.21622729301452637
Batch 52/64 loss: 0.2131863236427307
Batch 53/64 loss: 0.21905964612960815
Batch 54/64 loss: 0.22371745109558105
Batch 55/64 loss: 0.21439510583877563
Batch 56/64 loss: 0.21765410900115967
Batch 57/64 loss: 0.22459173202514648
Batch 58/64 loss: 0.2290281057357788
Batch 59/64 loss: 0.21445000171661377
Batch 60/64 loss: 0.20858442783355713
Batch 61/64 loss: 0.20996826887130737
Batch 62/64 loss: 0.2106102705001831
Batch 63/64 loss: 0.21803313493728638
Batch 64/64 loss: 0.22354447841644287
Epoch 254  Train loss: 0.22007644363478118  Val loss: 0.29330543349288996
Epoch 255
-------------------------------
Batch 1/64 loss: 0.2095867395401001
Batch 2/64 loss: 0.22652912139892578
Batch 3/64 loss: 0.2193666696548462
Batch 4/64 loss: 0.22009259462356567
Batch 5/64 loss: 0.21913188695907593
Batch 6/64 loss: 0.22596144676208496
Batch 7/64 loss: 0.22287517786026
Batch 8/64 loss: 0.21927499771118164
Batch 9/64 loss: 0.21872472763061523
Batch 10/64 loss: 0.22313940525054932
Batch 11/64 loss: 0.21357500553131104
Batch 12/64 loss: 0.21561133861541748
Batch 13/64 loss: 0.2156376838684082
Batch 14/64 loss: 0.20943450927734375
Batch 15/64 loss: 0.21682822704315186
Batch 16/64 loss: 0.23297327756881714
Batch 17/64 loss: 0.22587883472442627
Batch 18/64 loss: 0.23006951808929443
Batch 19/64 loss: 0.2166723608970642
Batch 20/64 loss: 0.21754133701324463
Batch 21/64 loss: 0.21143579483032227
Batch 22/64 loss: 0.22183126211166382
Batch 23/64 loss: 0.21411073207855225
Batch 24/64 loss: 0.21798259019851685
Batch 25/64 loss: 0.22275006771087646
Batch 26/64 loss: 0.22380828857421875
Batch 27/64 loss: 0.22233867645263672
Batch 28/64 loss: 0.2258000373840332
Batch 29/64 loss: 0.21625572443008423
Batch 30/64 loss: 0.22064614295959473
Batch 31/64 loss: 0.22107994556427002
Batch 32/64 loss: 0.21882176399230957
Batch 33/64 loss: 0.22787600755691528
Batch 34/64 loss: 0.22795867919921875
Batch 35/64 loss: 0.21817922592163086
Batch 36/64 loss: 0.22498810291290283
Batch 37/64 loss: 0.22001469135284424
Batch 38/64 loss: 0.2326430082321167
Batch 39/64 loss: 0.21029412746429443
Batch 40/64 loss: 0.22971612215042114
Batch 41/64 loss: 0.2159562110900879
Batch 42/64 loss: 0.21561193466186523
Batch 43/64 loss: 0.22116315364837646
Batch 44/64 loss: 0.22074401378631592
Batch 45/64 loss: 0.2280435562133789
Batch 46/64 loss: 0.21295225620269775
Batch 47/64 loss: 0.22180896997451782
Batch 48/64 loss: 0.21400213241577148
Batch 49/64 loss: 0.22457927465438843
Batch 50/64 loss: 0.2214822769165039
Batch 51/64 loss: 0.23092520236968994
Batch 52/64 loss: 0.2116551399230957
Batch 53/64 loss: 0.2260829210281372
Batch 54/64 loss: 0.2270500659942627
Batch 55/64 loss: 0.21665966510772705
Batch 56/64 loss: 0.2206161618232727
Batch 57/64 loss: 0.21707820892333984
Batch 58/64 loss: 0.22526192665100098
Batch 59/64 loss: 0.22917038202285767
Batch 60/64 loss: 0.2108839750289917
Batch 61/64 loss: 0.22339290380477905
Batch 62/64 loss: 0.21694421768188477
Batch 63/64 loss: 0.2222599983215332
Batch 64/64 loss: 0.2379056215286255
Epoch 255  Train loss: 0.22086571945863612  Val loss: 0.2938264952492468
Epoch 256
-------------------------------
Batch 1/64 loss: 0.21477138996124268
Batch 2/64 loss: 0.21210646629333496
Batch 3/64 loss: 0.2191624641418457
Batch 4/64 loss: 0.21340453624725342
Batch 5/64 loss: 0.21779638528823853
Batch 6/64 loss: 0.21602147817611694
Batch 7/64 loss: 0.21988654136657715
Batch 8/64 loss: 0.2129805088043213
Batch 9/64 loss: 0.21881622076034546
Batch 10/64 loss: 0.2150762677192688
Batch 11/64 loss: 0.21572446823120117
Batch 12/64 loss: 0.21645617485046387
Batch 13/64 loss: 0.21712827682495117
Batch 14/64 loss: 0.23505383729934692
Batch 15/64 loss: 0.21918398141860962
Batch 16/64 loss: 0.20935165882110596
Batch 17/64 loss: 0.22089457511901855
Batch 18/64 loss: 0.22322481870651245
Batch 19/64 loss: 0.2309005856513977
Batch 20/64 loss: 0.2220367193222046
Batch 21/64 loss: 0.21175169944763184
Batch 22/64 loss: 0.22289055585861206
Batch 23/64 loss: 0.2307145595550537
Batch 24/64 loss: 0.21561121940612793
Batch 25/64 loss: 0.2151634693145752
Batch 26/64 loss: 0.21928489208221436
Batch 27/64 loss: 0.22308814525604248
Batch 28/64 loss: 0.21794164180755615
Batch 29/64 loss: 0.2201608419418335
Batch 30/64 loss: 0.2332139015197754
Batch 31/64 loss: 0.2230989933013916
Batch 32/64 loss: 0.22608435153961182
Batch 33/64 loss: 0.21434307098388672
Batch 34/64 loss: 0.22142374515533447
Batch 35/64 loss: 0.21299636363983154
Batch 36/64 loss: 0.22084516286849976
Batch 37/64 loss: 0.21674060821533203
Batch 38/64 loss: 0.23913252353668213
Batch 39/64 loss: 0.21646755933761597
Batch 40/64 loss: 0.23953652381896973
Batch 41/64 loss: 0.21847301721572876
Batch 42/64 loss: 0.210860013961792
Batch 43/64 loss: 0.2373228669166565
Batch 44/64 loss: 0.22824126482009888
Batch 45/64 loss: 0.21774303913116455
Batch 46/64 loss: 0.21905577182769775
Batch 47/64 loss: 0.21047258377075195
Batch 48/64 loss: 0.2317482829093933
Batch 49/64 loss: 0.21839779615402222
Batch 50/64 loss: 0.23354274034500122
Batch 51/64 loss: 0.2162073850631714
Batch 52/64 loss: 0.22546982765197754
Batch 53/64 loss: 0.22026538848876953
Batch 54/64 loss: 0.2249891757965088
Batch 55/64 loss: 0.22705543041229248
Batch 56/64 loss: 0.23166924715042114
Batch 57/64 loss: 0.2165510058403015
Batch 58/64 loss: 0.2164594531059265
Batch 59/64 loss: 0.2102733850479126
Batch 60/64 loss: 0.21280574798583984
Batch 61/64 loss: 0.21989798545837402
Batch 62/64 loss: 0.2324678897857666
Batch 63/64 loss: 0.2185472846031189
Batch 64/64 loss: 0.21644359827041626
Epoch 256  Train loss: 0.22072653279584997  Val loss: 0.29343690659172345
Epoch 257
-------------------------------
Batch 1/64 loss: 0.22586631774902344
Batch 2/64 loss: 0.21274793148040771
Batch 3/64 loss: 0.21381103992462158
Batch 4/64 loss: 0.22808623313903809
Batch 5/64 loss: 0.21624970436096191
Batch 6/64 loss: 0.2061467170715332
Batch 7/64 loss: 0.23023366928100586
Batch 8/64 loss: 0.2290358543395996
Batch 9/64 loss: 0.21604526042938232
Batch 10/64 loss: 0.2141316533088684
Batch 11/64 loss: 0.243305504322052
Batch 12/64 loss: 0.21782708168029785
Batch 13/64 loss: 0.21767407655715942
Batch 14/64 loss: 0.22716009616851807
Batch 15/64 loss: 0.21506166458129883
Batch 16/64 loss: 0.21638286113739014
Batch 17/64 loss: 0.21734273433685303
Batch 18/64 loss: 0.23356854915618896
Batch 19/64 loss: 0.21901214122772217
Batch 20/64 loss: 0.21603012084960938
Batch 21/64 loss: 0.21333354711532593
Batch 22/64 loss: 0.22493112087249756
Batch 23/64 loss: 0.22030633687973022
Batch 24/64 loss: 0.2156175971031189
Batch 25/64 loss: 0.23798143863677979
Batch 26/64 loss: 0.22238969802856445
Batch 27/64 loss: 0.223419189453125
Batch 28/64 loss: 0.22181862592697144
Batch 29/64 loss: 0.22263073921203613
Batch 30/64 loss: 0.22937488555908203
Batch 31/64 loss: 0.22125935554504395
Batch 32/64 loss: 0.22812092304229736
Batch 33/64 loss: 0.2147083282470703
Batch 34/64 loss: 0.21877306699752808
Batch 35/64 loss: 0.22593748569488525
Batch 36/64 loss: 0.22039401531219482
Batch 37/64 loss: 0.23221111297607422
Batch 38/64 loss: 0.22411948442459106
Batch 39/64 loss: 0.21743446588516235
Batch 40/64 loss: 0.2124032974243164
Batch 41/64 loss: 0.2222875952720642
Batch 42/64 loss: 0.21969568729400635
Batch 43/64 loss: 0.22309547662734985
Batch 44/64 loss: 0.21526873111724854
Batch 45/64 loss: 0.22167158126831055
Batch 46/64 loss: 0.21287453174591064
Batch 47/64 loss: 0.21560180187225342
Batch 48/64 loss: 0.2180025577545166
Batch 49/64 loss: 0.22405636310577393
Batch 50/64 loss: 0.21803945302963257
Batch 51/64 loss: 0.2115483283996582
Batch 52/64 loss: 0.22598612308502197
Batch 53/64 loss: 0.2209235429763794
Batch 54/64 loss: 0.21985656023025513
Batch 55/64 loss: 0.21462273597717285
Batch 56/64 loss: 0.21782493591308594
Batch 57/64 loss: 0.21418583393096924
Batch 58/64 loss: 0.21883940696716309
Batch 59/64 loss: 0.2251521348953247
Batch 60/64 loss: 0.21630895137786865
Batch 61/64 loss: 0.21872764825820923
Batch 62/64 loss: 0.21909421682357788
Batch 63/64 loss: 0.20950692892074585
Batch 64/64 loss: 0.21606892347335815
Epoch 257  Train loss: 0.2203624587433011  Val loss: 0.2944845192620844
Epoch 258
-------------------------------
Batch 1/64 loss: 0.2119523286819458
Batch 2/64 loss: 0.20973151922225952
Batch 3/64 loss: 0.21961843967437744
Batch 4/64 loss: 0.2081451416015625
Batch 5/64 loss: 0.22231769561767578
Batch 6/64 loss: 0.21410465240478516
Batch 7/64 loss: 0.2122795581817627
Batch 8/64 loss: 0.22498005628585815
Batch 9/64 loss: 0.2176724076271057
Batch 10/64 loss: 0.2263292670249939
Batch 11/64 loss: 0.2200390100479126
Batch 12/64 loss: 0.21759605407714844
Batch 13/64 loss: 0.21891361474990845
Batch 14/64 loss: 0.22435051202774048
Batch 15/64 loss: 0.22161906957626343
Batch 16/64 loss: 0.21755099296569824
Batch 17/64 loss: 0.21661192178726196
Batch 18/64 loss: 0.21951061487197876
Batch 19/64 loss: 0.21846723556518555
Batch 20/64 loss: 0.21784436702728271
Batch 21/64 loss: 0.23590707778930664
Batch 22/64 loss: 0.2168709635734558
Batch 23/64 loss: 0.22072726488113403
Batch 24/64 loss: 0.2224597930908203
Batch 25/64 loss: 0.22228437662124634
Batch 26/64 loss: 0.2205563187599182
Batch 27/64 loss: 0.21542596817016602
Batch 28/64 loss: 0.23190289735794067
Batch 29/64 loss: 0.21662718057632446
Batch 30/64 loss: 0.21767139434814453
Batch 31/64 loss: 0.22190868854522705
Batch 32/64 loss: 0.21481215953826904
Batch 33/64 loss: 0.22286993265151978
Batch 34/64 loss: 0.2299278974533081
Batch 35/64 loss: 0.2126510739326477
Batch 36/64 loss: 0.22533953189849854
Batch 37/64 loss: 0.2122962474822998
Batch 38/64 loss: 0.2217007875442505
Batch 39/64 loss: 0.21795761585235596
Batch 40/64 loss: 0.21196341514587402
Batch 41/64 loss: 0.21099472045898438
Batch 42/64 loss: 0.21347111463546753
Batch 43/64 loss: 0.21615076065063477
Batch 44/64 loss: 0.21754753589630127
Batch 45/64 loss: 0.21399742364883423
Batch 46/64 loss: 0.21394050121307373
Batch 47/64 loss: 0.2140953540802002
Batch 48/64 loss: 0.2180476188659668
Batch 49/64 loss: 0.2280646562576294
Batch 50/64 loss: 0.21945488452911377
Batch 51/64 loss: 0.22655481100082397
Batch 52/64 loss: 0.22170907258987427
Batch 53/64 loss: 0.21065592765808105
Batch 54/64 loss: 0.21902823448181152
Batch 55/64 loss: 0.22382307052612305
Batch 56/64 loss: 0.22446787357330322
Batch 57/64 loss: 0.23017239570617676
Batch 58/64 loss: 0.22249066829681396
Batch 59/64 loss: 0.23009628057479858
Batch 60/64 loss: 0.22637677192687988
Batch 61/64 loss: 0.22697699069976807
Batch 62/64 loss: 0.21431469917297363
Batch 63/64 loss: 0.22453200817108154
Batch 64/64 loss: 0.23137277364730835
Epoch 258  Train loss: 0.21979589018167234  Val loss: 0.29465403241390214
Epoch 259
-------------------------------
Batch 1/64 loss: 0.2296466827392578
Batch 2/64 loss: 0.21569311618804932
Batch 3/64 loss: 0.22503060102462769
Batch 4/64 loss: 0.2240557074546814
Batch 5/64 loss: 0.2183520793914795
Batch 6/64 loss: 0.2073880434036255
Batch 7/64 loss: 0.21821367740631104
Batch 8/64 loss: 0.22329342365264893
Batch 9/64 loss: 0.21223217248916626
Batch 10/64 loss: 0.21339643001556396
Batch 11/64 loss: 0.2226341962814331
Batch 12/64 loss: 0.20606207847595215
Batch 13/64 loss: 0.22215306758880615
Batch 14/64 loss: 0.2126261591911316
Batch 15/64 loss: 0.2204136848449707
Batch 16/64 loss: 0.21948838233947754
Batch 17/64 loss: 0.22980231046676636
Batch 18/64 loss: 0.21578770875930786
Batch 19/64 loss: 0.2186785340309143
Batch 20/64 loss: 0.22931861877441406
Batch 21/64 loss: 0.2122480869293213
Batch 22/64 loss: 0.21358954906463623
Batch 23/64 loss: 0.22677206993103027
Batch 24/64 loss: 0.21903961896896362
Batch 25/64 loss: 0.2188875675201416
Batch 26/64 loss: 0.22468936443328857
Batch 27/64 loss: 0.22326511144638062
Batch 28/64 loss: 0.22374385595321655
Batch 29/64 loss: 0.2214951515197754
Batch 30/64 loss: 0.23002731800079346
Batch 31/64 loss: 0.21272015571594238
Batch 32/64 loss: 0.21312344074249268
Batch 33/64 loss: 0.21634995937347412
Batch 34/64 loss: 0.21797990798950195
Batch 35/64 loss: 0.21880066394805908
Batch 36/64 loss: 0.2166690230369568
Batch 37/64 loss: 0.22495687007904053
Batch 38/64 loss: 0.21731245517730713
Batch 39/64 loss: 0.2173856496810913
Batch 40/64 loss: 0.21249723434448242
Batch 41/64 loss: 0.20923113822937012
Batch 42/64 loss: 0.20748025178909302
Batch 43/64 loss: 0.22336459159851074
Batch 44/64 loss: 0.23446255922317505
Batch 45/64 loss: 0.21279442310333252
Batch 46/64 loss: 0.21914255619049072
Batch 47/64 loss: 0.228285014629364
Batch 48/64 loss: 0.22036349773406982
Batch 49/64 loss: 0.21524059772491455
Batch 50/64 loss: 0.21704041957855225
Batch 51/64 loss: 0.22173553705215454
Batch 52/64 loss: 0.2112572193145752
Batch 53/64 loss: 0.21430814266204834
Batch 54/64 loss: 0.2148493528366089
Batch 55/64 loss: 0.2101675271987915
Batch 56/64 loss: 0.22676020860671997
Batch 57/64 loss: 0.21660971641540527
Batch 58/64 loss: 0.22637498378753662
Batch 59/64 loss: 0.22340261936187744
Batch 60/64 loss: 0.22371989488601685
Batch 61/64 loss: 0.21305310726165771
Batch 62/64 loss: 0.21910357475280762
Batch 63/64 loss: 0.22085636854171753
Batch 64/64 loss: 0.22734391689300537
Epoch 259  Train loss: 0.21907342695722393  Val loss: 0.2945950404065581
Epoch 260
-------------------------------
Batch 1/64 loss: 0.22078847885131836
Batch 2/64 loss: 0.22361040115356445
Batch 3/64 loss: 0.23075836896896362
Batch 4/64 loss: 0.22765040397644043
Batch 5/64 loss: 0.22095102071762085
Batch 6/64 loss: 0.21961462497711182
Batch 7/64 loss: 0.22254681587219238
Batch 8/64 loss: 0.20798850059509277
Batch 9/64 loss: 0.21684354543685913
Batch 10/64 loss: 0.2227534055709839
Batch 11/64 loss: 0.21248406171798706
Batch 12/64 loss: 0.22944402694702148
Batch 13/64 loss: 0.21753346920013428
Batch 14/64 loss: 0.21647632122039795
Batch 15/64 loss: 0.21467268466949463
Batch 16/64 loss: 0.21628981828689575
Batch 17/64 loss: 0.22014844417572021
Batch 18/64 loss: 0.22349393367767334
Batch 19/64 loss: 0.2190537452697754
Batch 20/64 loss: 0.2178250551223755
Batch 21/64 loss: 0.228559672832489
Batch 22/64 loss: 0.21516680717468262
Batch 23/64 loss: 0.23056375980377197
Batch 24/64 loss: 0.221022367477417
Batch 25/64 loss: 0.22444117069244385
Batch 26/64 loss: 0.212593674659729
Batch 27/64 loss: 0.2276397943496704
Batch 28/64 loss: 0.2290247678756714
Batch 29/64 loss: 0.21853506565093994
Batch 30/64 loss: 0.23050594329833984
Batch 31/64 loss: 0.21262788772583008
Batch 32/64 loss: 0.22076934576034546
Batch 33/64 loss: 0.21745264530181885
Batch 34/64 loss: 0.21897101402282715
Batch 35/64 loss: 0.22934669256210327
Batch 36/64 loss: 0.2194109559059143
Batch 37/64 loss: 0.2233438491821289
Batch 38/64 loss: 0.21829521656036377
Batch 39/64 loss: 0.21393287181854248
Batch 40/64 loss: 0.2152719497680664
Batch 41/64 loss: 0.22803103923797607
Batch 42/64 loss: 0.23097443580627441
Batch 43/64 loss: 0.21303391456604004
Batch 44/64 loss: 0.2163172960281372
Batch 45/64 loss: 0.21516883373260498
Batch 46/64 loss: 0.21653413772583008
Batch 47/64 loss: 0.21460551023483276
Batch 48/64 loss: 0.22513246536254883
Batch 49/64 loss: 0.2189021110534668
Batch 50/64 loss: 0.2202683687210083
Batch 51/64 loss: 0.22062313556671143
Batch 52/64 loss: 0.21289873123168945
Batch 53/64 loss: 0.21047627925872803
Batch 54/64 loss: 0.23837804794311523
Batch 55/64 loss: 0.21783077716827393
Batch 56/64 loss: 0.20972150564193726
Batch 57/64 loss: 0.21588850021362305
Batch 58/64 loss: 0.22087633609771729
Batch 59/64 loss: 0.20726531744003296
Batch 60/64 loss: 0.21590197086334229
Batch 61/64 loss: 0.21765190362930298
Batch 62/64 loss: 0.22645795345306396
Batch 63/64 loss: 0.21421515941619873
Batch 64/64 loss: 0.2255244255065918
Epoch 260  Train loss: 0.21999528828789205  Val loss: 0.29428255988150526
Epoch 261
-------------------------------
Batch 1/64 loss: 0.2177022099494934
Batch 2/64 loss: 0.21914523839950562
Batch 3/64 loss: 0.23024260997772217
Batch 4/64 loss: 0.213128924369812
Batch 5/64 loss: 0.2129049301147461
Batch 6/64 loss: 0.2278207540512085
Batch 7/64 loss: 0.21780908107757568
Batch 8/64 loss: 0.21086496114730835
Batch 9/64 loss: 0.23236775398254395
Batch 10/64 loss: 0.2107924222946167
Batch 11/64 loss: 0.21259373426437378
Batch 12/64 loss: 0.2143235206604004
Batch 13/64 loss: 0.21003806591033936
Batch 14/64 loss: 0.21879351139068604
Batch 15/64 loss: 0.21105599403381348
Batch 16/64 loss: 0.22044599056243896
Batch 17/64 loss: 0.2170330286026001
Batch 18/64 loss: 0.22152072191238403
Batch 19/64 loss: 0.21834546327590942
Batch 20/64 loss: 0.22135215997695923
Batch 21/64 loss: 0.2251296043395996
Batch 22/64 loss: 0.21494758129119873
Batch 23/64 loss: 0.2212831974029541
Batch 24/64 loss: 0.23310577869415283
Batch 25/64 loss: 0.21225690841674805
Batch 26/64 loss: 0.21136856079101562
Batch 27/64 loss: 0.20638692378997803
Batch 28/64 loss: 0.21538209915161133
Batch 29/64 loss: 0.21883893013000488
Batch 30/64 loss: 0.2188485860824585
Batch 31/64 loss: 0.22017979621887207
Batch 32/64 loss: 0.22263085842132568
Batch 33/64 loss: 0.22781813144683838
Batch 34/64 loss: 0.22929894924163818
Batch 35/64 loss: 0.21308565139770508
Batch 36/64 loss: 0.21766602993011475
Batch 37/64 loss: 0.2189388871192932
Batch 38/64 loss: 0.21367228031158447
Batch 39/64 loss: 0.21629208326339722
Batch 40/64 loss: 0.2187156081199646
Batch 41/64 loss: 0.22038769721984863
Batch 42/64 loss: 0.21108698844909668
Batch 43/64 loss: 0.22049522399902344
Batch 44/64 loss: 0.2226393222808838
Batch 45/64 loss: 0.21312320232391357
Batch 46/64 loss: 0.21378207206726074
Batch 47/64 loss: 0.2217261791229248
Batch 48/64 loss: 0.21373873949050903
Batch 49/64 loss: 0.22039473056793213
Batch 50/64 loss: 0.2121884822845459
Batch 51/64 loss: 0.2288861870765686
Batch 52/64 loss: 0.23159193992614746
Batch 53/64 loss: 0.21485072374343872
Batch 54/64 loss: 0.213309645652771
Batch 55/64 loss: 0.22722655534744263
Batch 56/64 loss: 0.22788578271865845
Batch 57/64 loss: 0.2303975224494934
Batch 58/64 loss: 0.23439335823059082
Batch 59/64 loss: 0.22183722257614136
Batch 60/64 loss: 0.22078055143356323
Batch 61/64 loss: 0.2265663743019104
Batch 62/64 loss: 0.2257317304611206
Batch 63/64 loss: 0.22844326496124268
Batch 64/64 loss: 0.21191203594207764
Epoch 261  Train loss: 0.21952196149265066  Val loss: 0.29489133980675664
Epoch 262
-------------------------------
Batch 1/64 loss: 0.219887375831604
Batch 2/64 loss: 0.21218621730804443
Batch 3/64 loss: 0.22347891330718994
Batch 4/64 loss: 0.2241511344909668
Batch 5/64 loss: 0.2214188575744629
Batch 6/64 loss: 0.21152377128601074
Batch 7/64 loss: 0.2195589542388916
Batch 8/64 loss: 0.21821975708007812
Batch 9/64 loss: 0.21755677461624146
Batch 10/64 loss: 0.21441805362701416
Batch 11/64 loss: 0.21092045307159424
Batch 12/64 loss: 0.21840792894363403
Batch 13/64 loss: 0.21636968851089478
Batch 14/64 loss: 0.22160303592681885
Batch 15/64 loss: 0.22178655862808228
Batch 16/64 loss: 0.210820734500885
Batch 17/64 loss: 0.20856022834777832
Batch 18/64 loss: 0.22195857763290405
Batch 19/64 loss: 0.2211647629737854
Batch 20/64 loss: 0.21892821788787842
Batch 21/64 loss: 0.2139626145362854
Batch 22/64 loss: 0.22116899490356445
Batch 23/64 loss: 0.22626620531082153
Batch 24/64 loss: 0.2161160707473755
Batch 25/64 loss: 0.23182553052902222
Batch 26/64 loss: 0.22421354055404663
Batch 27/64 loss: 0.21324479579925537
Batch 28/64 loss: 0.20807021856307983
Batch 29/64 loss: 0.2199465036392212
Batch 30/64 loss: 0.22249656915664673
Batch 31/64 loss: 0.21914100646972656
Batch 32/64 loss: 0.2113100290298462
Batch 33/64 loss: 0.2279638648033142
Batch 34/64 loss: 0.21159547567367554
Batch 35/64 loss: 0.21974480152130127
Batch 36/64 loss: 0.22008246183395386
Batch 37/64 loss: 0.21676450967788696
Batch 38/64 loss: 0.22300934791564941
Batch 39/64 loss: 0.2250915765762329
Batch 40/64 loss: 0.20984655618667603
Batch 41/64 loss: 0.22782772779464722
Batch 42/64 loss: 0.22372311353683472
Batch 43/64 loss: 0.21859204769134521
Batch 44/64 loss: 0.21953487396240234
Batch 45/64 loss: 0.2170756459236145
Batch 46/64 loss: 0.2319135069847107
Batch 47/64 loss: 0.21567726135253906
Batch 48/64 loss: 0.2268497347831726
Batch 49/64 loss: 0.2169364094734192
Batch 50/64 loss: 0.22470158338546753
Batch 51/64 loss: 0.21809136867523193
Batch 52/64 loss: 0.21173697710037231
Batch 53/64 loss: 0.2171410322189331
Batch 54/64 loss: 0.22626614570617676
Batch 55/64 loss: 0.2193000316619873
Batch 56/64 loss: 0.22221362590789795
Batch 57/64 loss: 0.21642935276031494
Batch 58/64 loss: 0.2330641746520996
Batch 59/64 loss: 0.23070484399795532
Batch 60/64 loss: 0.21783673763275146
Batch 61/64 loss: 0.2228420376777649
Batch 62/64 loss: 0.2208157777786255
Batch 63/64 loss: 0.21494340896606445
Batch 64/64 loss: 0.2422810196876526
Epoch 262  Train loss: 0.2197758251545476  Val loss: 0.29285813074341344
Epoch 263
-------------------------------
Batch 1/64 loss: 0.21813952922821045
Batch 2/64 loss: 0.22109484672546387
Batch 3/64 loss: 0.21711039543151855
Batch 4/64 loss: 0.21584850549697876
Batch 5/64 loss: 0.22018015384674072
Batch 6/64 loss: 0.22688603401184082
Batch 7/64 loss: 0.21123474836349487
Batch 8/64 loss: 0.22143959999084473
Batch 9/64 loss: 0.21980994939804077
Batch 10/64 loss: 0.21423858404159546
Batch 11/64 loss: 0.21818053722381592
Batch 12/64 loss: 0.21148282289505005
Batch 13/64 loss: 0.2284775972366333
Batch 14/64 loss: 0.2178267240524292
Batch 15/64 loss: 0.20918285846710205
Batch 16/64 loss: 0.22596800327301025
Batch 17/64 loss: 0.22507649660110474
Batch 18/64 loss: 0.2237299084663391
Batch 19/64 loss: 0.21372604370117188
Batch 20/64 loss: 0.22700560092926025
Batch 21/64 loss: 0.2274329662322998
Batch 22/64 loss: 0.2168099284172058
Batch 23/64 loss: 0.21999776363372803
Batch 24/64 loss: 0.2215968370437622
Batch 25/64 loss: 0.21559375524520874
Batch 26/64 loss: 0.22124028205871582
Batch 27/64 loss: 0.22189724445343018
Batch 28/64 loss: 0.22108608484268188
Batch 29/64 loss: 0.22338110208511353
Batch 30/64 loss: 0.21116769313812256
Batch 31/64 loss: 0.2118862271308899
Batch 32/64 loss: 0.21671712398529053
Batch 33/64 loss: 0.21445703506469727
Batch 34/64 loss: 0.22119230031967163
Batch 35/64 loss: 0.22054660320281982
Batch 36/64 loss: 0.22577118873596191
Batch 37/64 loss: 0.21922814846038818
Batch 38/64 loss: 0.21088147163391113
Batch 39/64 loss: 0.21686041355133057
Batch 40/64 loss: 0.2200990915298462
Batch 41/64 loss: 0.2302565574645996
Batch 42/64 loss: 0.22675389051437378
Batch 43/64 loss: 0.2288978099822998
Batch 44/64 loss: 0.21752136945724487
Batch 45/64 loss: 0.22420811653137207
Batch 46/64 loss: 0.2189733386039734
Batch 47/64 loss: 0.22326338291168213
Batch 48/64 loss: 0.22373104095458984
Batch 49/64 loss: 0.21022027730941772
Batch 50/64 loss: 0.20672345161437988
Batch 51/64 loss: 0.22550612688064575
Batch 52/64 loss: 0.21438735723495483
Batch 53/64 loss: 0.21582704782485962
Batch 54/64 loss: 0.21194785833358765
Batch 55/64 loss: 0.20689868927001953
Batch 56/64 loss: 0.2201746702194214
Batch 57/64 loss: 0.2186068296432495
Batch 58/64 loss: 0.21650630235671997
Batch 59/64 loss: 0.23779141902923584
Batch 60/64 loss: 0.2148374319076538
Batch 61/64 loss: 0.2320549488067627
Batch 62/64 loss: 0.21807605028152466
Batch 63/64 loss: 0.2145252823829651
Batch 64/64 loss: 0.2161475419998169
Epoch 263  Train loss: 0.21936128793978224  Val loss: 0.29340481430394544
Epoch 264
-------------------------------
Batch 1/64 loss: 0.21463799476623535
Batch 2/64 loss: 0.2232474684715271
Batch 3/64 loss: 0.21390926837921143
Batch 4/64 loss: 0.21702229976654053
Batch 5/64 loss: 0.227017343044281
Batch 6/64 loss: 0.21419960260391235
Batch 7/64 loss: 0.2045198678970337
Batch 8/64 loss: 0.21483772993087769
Batch 9/64 loss: 0.21328383684158325
Batch 10/64 loss: 0.2150862216949463
Batch 11/64 loss: 0.23597955703735352
Batch 12/64 loss: 0.21642303466796875
Batch 13/64 loss: 0.22992002964019775
Batch 14/64 loss: 0.21969634294509888
Batch 15/64 loss: 0.22433686256408691
Batch 16/64 loss: 0.21574902534484863
Batch 17/64 loss: 0.22222661972045898
Batch 18/64 loss: 0.21861255168914795
Batch 19/64 loss: 0.20724999904632568
Batch 20/64 loss: 0.21671044826507568
Batch 21/64 loss: 0.22257310152053833
Batch 22/64 loss: 0.2090606689453125
Batch 23/64 loss: 0.21248602867126465
Batch 24/64 loss: 0.21124136447906494
Batch 25/64 loss: 0.22138845920562744
Batch 26/64 loss: 0.2217656970024109
Batch 27/64 loss: 0.21192800998687744
Batch 28/64 loss: 0.21659833192825317
Batch 29/64 loss: 0.2189854383468628
Batch 30/64 loss: 0.21573615074157715
Batch 31/64 loss: 0.2225239872932434
Batch 32/64 loss: 0.2162664532661438
Batch 33/64 loss: 0.2213364839553833
Batch 34/64 loss: 0.22187328338623047
Batch 35/64 loss: 0.21864497661590576
Batch 36/64 loss: 0.21631121635437012
Batch 37/64 loss: 0.215404212474823
Batch 38/64 loss: 0.21560412645339966
Batch 39/64 loss: 0.21651405096054077
Batch 40/64 loss: 0.213018000125885
Batch 41/64 loss: 0.2167649269104004
Batch 42/64 loss: 0.2227463722229004
Batch 43/64 loss: 0.2270892858505249
Batch 44/64 loss: 0.216147780418396
Batch 45/64 loss: 0.2171013355255127
Batch 46/64 loss: 0.21603381633758545
Batch 47/64 loss: 0.22510552406311035
Batch 48/64 loss: 0.21381592750549316
Batch 49/64 loss: 0.2151448130607605
Batch 50/64 loss: 0.2121182084083557
Batch 51/64 loss: 0.219573974609375
Batch 52/64 loss: 0.22305190563201904
Batch 53/64 loss: 0.22306418418884277
Batch 54/64 loss: 0.22237765789031982
Batch 55/64 loss: 0.2248826026916504
Batch 56/64 loss: 0.22108745574951172
Batch 57/64 loss: 0.21721404790878296
Batch 58/64 loss: 0.2132752537727356
Batch 59/64 loss: 0.22929394245147705
Batch 60/64 loss: 0.20813822746276855
Batch 61/64 loss: 0.2169119119644165
Batch 62/64 loss: 0.21882933378219604
Batch 63/64 loss: 0.2203209400177002
Batch 64/64 loss: 0.2258467674255371
Epoch 264  Train loss: 0.21824942196116728  Val loss: 0.2938578292676264
Epoch 265
-------------------------------
Batch 1/64 loss: 0.21261608600616455
Batch 2/64 loss: 0.2212735414505005
Batch 3/64 loss: 0.21203678846359253
Batch 4/64 loss: 0.210746169090271
Batch 5/64 loss: 0.22176826000213623
Batch 6/64 loss: 0.207996666431427
Batch 7/64 loss: 0.21933621168136597
Batch 8/64 loss: 0.2178506851196289
Batch 9/64 loss: 0.2155674695968628
Batch 10/64 loss: 0.20973646640777588
Batch 11/64 loss: 0.21165168285369873
Batch 12/64 loss: 0.2204759120941162
Batch 13/64 loss: 0.23254907131195068
Batch 14/64 loss: 0.215262770652771
Batch 15/64 loss: 0.2230377197265625
Batch 16/64 loss: 0.2163395881652832
Batch 17/64 loss: 0.2186594009399414
Batch 18/64 loss: 0.21359801292419434
Batch 19/64 loss: 0.21744561195373535
Batch 20/64 loss: 0.2188786268234253
Batch 21/64 loss: 0.22550314664840698
Batch 22/64 loss: 0.2192697525024414
Batch 23/64 loss: 0.21359682083129883
Batch 24/64 loss: 0.21343684196472168
Batch 25/64 loss: 0.21573853492736816
Batch 26/64 loss: 0.23177671432495117
Batch 27/64 loss: 0.22964942455291748
Batch 28/64 loss: 0.2235814332962036
Batch 29/64 loss: 0.20332419872283936
Batch 30/64 loss: 0.2148658037185669
Batch 31/64 loss: 0.2297903299331665
Batch 32/64 loss: 0.22528332471847534
Batch 33/64 loss: 0.21338295936584473
Batch 34/64 loss: 0.22533881664276123
Batch 35/64 loss: 0.22174477577209473
Batch 36/64 loss: 0.21428561210632324
Batch 37/64 loss: 0.21652472019195557
Batch 38/64 loss: 0.21578645706176758
Batch 39/64 loss: 0.2164602279663086
Batch 40/64 loss: 0.2133224606513977
Batch 41/64 loss: 0.21953368186950684
Batch 42/64 loss: 0.21911567449569702
Batch 43/64 loss: 0.22748887538909912
Batch 44/64 loss: 0.20833396911621094
Batch 45/64 loss: 0.213406503200531
Batch 46/64 loss: 0.20719492435455322
Batch 47/64 loss: 0.21249693632125854
Batch 48/64 loss: 0.22331809997558594
Batch 49/64 loss: 0.21312618255615234
Batch 50/64 loss: 0.21095585823059082
Batch 51/64 loss: 0.21907305717468262
Batch 52/64 loss: 0.22627776861190796
Batch 53/64 loss: 0.21363884210586548
Batch 54/64 loss: 0.225793719291687
Batch 55/64 loss: 0.22169029712677002
Batch 56/64 loss: 0.24422019720077515
Batch 57/64 loss: 0.2232062816619873
Batch 58/64 loss: 0.216016948223114
Batch 59/64 loss: 0.21373462677001953
Batch 60/64 loss: 0.21505165100097656
Batch 61/64 loss: 0.2181628942489624
Batch 62/64 loss: 0.2209133505821228
Batch 63/64 loss: 0.2196359634399414
Batch 64/64 loss: 0.22701960802078247
Epoch 265  Train loss: 0.21838651147543214  Val loss: 0.2934837189736645
Epoch 266
-------------------------------
Batch 1/64 loss: 0.21293246746063232
Batch 2/64 loss: 0.22713851928710938
Batch 3/64 loss: 0.2228388786315918
Batch 4/64 loss: 0.2184159755706787
Batch 5/64 loss: 0.22641021013259888
Batch 6/64 loss: 0.21256625652313232
Batch 7/64 loss: 0.21804022789001465
Batch 8/64 loss: 0.21096014976501465
Batch 9/64 loss: 0.21519112586975098
Batch 10/64 loss: 0.22097355127334595
Batch 11/64 loss: 0.21802282333374023
Batch 12/64 loss: 0.2144758105278015
Batch 13/64 loss: 0.2190874218940735
Batch 14/64 loss: 0.20930266380310059
Batch 15/64 loss: 0.21614736318588257
Batch 16/64 loss: 0.21877551078796387
Batch 17/64 loss: 0.21727442741394043
Batch 18/64 loss: 0.21817374229431152
Batch 19/64 loss: 0.21461236476898193
Batch 20/64 loss: 0.21220624446868896
Batch 21/64 loss: 0.21625202894210815
Batch 22/64 loss: 0.2160710096359253
Batch 23/64 loss: 0.21259498596191406
Batch 24/64 loss: 0.21468573808670044
Batch 25/64 loss: 0.21618282794952393
Batch 26/64 loss: 0.20438635349273682
Batch 27/64 loss: 0.21961188316345215
Batch 28/64 loss: 0.24146318435668945
Batch 29/64 loss: 0.230057954788208
Batch 30/64 loss: 0.21644890308380127
Batch 31/64 loss: 0.22406458854675293
Batch 32/64 loss: 0.2170339822769165
Batch 33/64 loss: 0.2201547622680664
Batch 34/64 loss: 0.2224375605583191
Batch 35/64 loss: 0.20862984657287598
Batch 36/64 loss: 0.2209409475326538
Batch 37/64 loss: 0.2313326597213745
Batch 38/64 loss: 0.21090388298034668
Batch 39/64 loss: 0.21925830841064453
Batch 40/64 loss: 0.21719235181808472
Batch 41/64 loss: 0.2142171859741211
Batch 42/64 loss: 0.22153258323669434
Batch 43/64 loss: 0.21783244609832764
Batch 44/64 loss: 0.21689796447753906
Batch 45/64 loss: 0.21225476264953613
Batch 46/64 loss: 0.21331924200057983
Batch 47/64 loss: 0.21370947360992432
Batch 48/64 loss: 0.2237999439239502
Batch 49/64 loss: 0.2198147177696228
Batch 50/64 loss: 0.23003268241882324
Batch 51/64 loss: 0.21280020475387573
Batch 52/64 loss: 0.2360924482345581
Batch 53/64 loss: 0.21742796897888184
Batch 54/64 loss: 0.217116117477417
Batch 55/64 loss: 0.22437405586242676
Batch 56/64 loss: 0.21616703271865845
Batch 57/64 loss: 0.2202690839767456
Batch 58/64 loss: 0.22790932655334473
Batch 59/64 loss: 0.20711183547973633
Batch 60/64 loss: 0.21915900707244873
Batch 61/64 loss: 0.2333005666732788
Batch 62/64 loss: 0.22723162174224854
Batch 63/64 loss: 0.22494196891784668
Batch 64/64 loss: 0.21570950746536255
Epoch 266  Train loss: 0.21886029594084797  Val loss: 0.2940085597873963
Epoch 267
-------------------------------
Batch 1/64 loss: 0.21519029140472412
Batch 2/64 loss: 0.21789121627807617
Batch 3/64 loss: 0.22277307510375977
Batch 4/64 loss: 0.21410322189331055
Batch 5/64 loss: 0.21746420860290527
Batch 6/64 loss: 0.21561932563781738
Batch 7/64 loss: 0.2127518653869629
Batch 8/64 loss: 0.2186741828918457
Batch 9/64 loss: 0.22010302543640137
Batch 10/64 loss: 0.22547513246536255
Batch 11/64 loss: 0.21340978145599365
Batch 12/64 loss: 0.22159570455551147
Batch 13/64 loss: 0.22485458850860596
Batch 14/64 loss: 0.2188636064529419
Batch 15/64 loss: 0.21840369701385498
Batch 16/64 loss: 0.21329379081726074
Batch 17/64 loss: 0.2184659242630005
Batch 18/64 loss: 0.22135233879089355
Batch 19/64 loss: 0.21453028917312622
Batch 20/64 loss: 0.21370136737823486
Batch 21/64 loss: 0.21751761436462402
Batch 22/64 loss: 0.22345203161239624
Batch 23/64 loss: 0.22241723537445068
Batch 24/64 loss: 0.21734946966171265
Batch 25/64 loss: 0.21286660432815552
Batch 26/64 loss: 0.20760738849639893
Batch 27/64 loss: 0.21889829635620117
Batch 28/64 loss: 0.2212620973587036
Batch 29/64 loss: 0.21456009149551392
Batch 30/64 loss: 0.21080374717712402
Batch 31/64 loss: 0.21595269441604614
Batch 32/64 loss: 0.22071409225463867
Batch 33/64 loss: 0.2129397988319397
Batch 34/64 loss: 0.2240816354751587
Batch 35/64 loss: 0.21427249908447266
Batch 36/64 loss: 0.2232668399810791
Batch 37/64 loss: 0.2194535732269287
Batch 38/64 loss: 0.20708245038986206
Batch 39/64 loss: 0.2279801368713379
Batch 40/64 loss: 0.21976083517074585
Batch 41/64 loss: 0.22094470262527466
Batch 42/64 loss: 0.2252175211906433
Batch 43/64 loss: 0.2147817611694336
Batch 44/64 loss: 0.21517497301101685
Batch 45/64 loss: 0.22306203842163086
Batch 46/64 loss: 0.21713238954544067
Batch 47/64 loss: 0.22153449058532715
Batch 48/64 loss: 0.21836894750595093
Batch 49/64 loss: 0.21328485012054443
Batch 50/64 loss: 0.21591436862945557
Batch 51/64 loss: 0.20691215991973877
Batch 52/64 loss: 0.22882449626922607
Batch 53/64 loss: 0.2324507236480713
Batch 54/64 loss: 0.21972310543060303
Batch 55/64 loss: 0.22162246704101562
Batch 56/64 loss: 0.2162259817123413
Batch 57/64 loss: 0.22498035430908203
Batch 58/64 loss: 0.21681761741638184
Batch 59/64 loss: 0.2266470193862915
Batch 60/64 loss: 0.21035659313201904
Batch 61/64 loss: 0.21868294477462769
Batch 62/64 loss: 0.22097456455230713
Batch 63/64 loss: 0.22564148902893066
Batch 64/64 loss: 0.20807814598083496
Epoch 267  Train loss: 0.2183857244603774  Val loss: 0.29354047140304984
Epoch 268
-------------------------------
Batch 1/64 loss: 0.21502113342285156
Batch 2/64 loss: 0.2082076072692871
Batch 3/64 loss: 0.20692545175552368
Batch 4/64 loss: 0.20780885219573975
Batch 5/64 loss: 0.21429705619812012
Batch 6/64 loss: 0.21463048458099365
Batch 7/64 loss: 0.22735416889190674
Batch 8/64 loss: 0.21481937170028687
Batch 9/64 loss: 0.21949517726898193
Batch 10/64 loss: 0.23787951469421387
Batch 11/64 loss: 0.2205767035484314
Batch 12/64 loss: 0.21500778198242188
Batch 13/64 loss: 0.21440434455871582
Batch 14/64 loss: 0.21996474266052246
Batch 15/64 loss: 0.2121143341064453
Batch 16/64 loss: 0.2274511456489563
Batch 17/64 loss: 0.2272409200668335
Batch 18/64 loss: 0.22213757038116455
Batch 19/64 loss: 0.22086822986602783
Batch 20/64 loss: 0.21522855758666992
Batch 21/64 loss: 0.2100663185119629
Batch 22/64 loss: 0.2204827070236206
Batch 23/64 loss: 0.2134135365486145
Batch 24/64 loss: 0.22574162483215332
Batch 25/64 loss: 0.2253803014755249
Batch 26/64 loss: 0.22046583890914917
Batch 27/64 loss: 0.21539252996444702
Batch 28/64 loss: 0.21663427352905273
Batch 29/64 loss: 0.2244909405708313
Batch 30/64 loss: 0.22195446491241455
Batch 31/64 loss: 0.23067766427993774
Batch 32/64 loss: 0.20883691310882568
Batch 33/64 loss: 0.22748875617980957
Batch 34/64 loss: 0.22388368844985962
Batch 35/64 loss: 0.21843206882476807
Batch 36/64 loss: 0.22785216569900513
Batch 37/64 loss: 0.21810680627822876
Batch 38/64 loss: 0.21789288520812988
Batch 39/64 loss: 0.21117103099822998
Batch 40/64 loss: 0.22580170631408691
Batch 41/64 loss: 0.22168684005737305
Batch 42/64 loss: 0.22466957569122314
Batch 43/64 loss: 0.21311426162719727
Batch 44/64 loss: 0.22006642818450928
Batch 45/64 loss: 0.218849778175354
Batch 46/64 loss: 0.21107351779937744
Batch 47/64 loss: 0.21636748313903809
Batch 48/64 loss: 0.21991479396820068
Batch 49/64 loss: 0.21336722373962402
Batch 50/64 loss: 0.21594369411468506
Batch 51/64 loss: 0.21313375234603882
Batch 52/64 loss: 0.21088111400604248
Batch 53/64 loss: 0.21590125560760498
Batch 54/64 loss: 0.2074049711227417
Batch 55/64 loss: 0.23006391525268555
Batch 56/64 loss: 0.21611899137496948
Batch 57/64 loss: 0.21703559160232544
Batch 58/64 loss: 0.21523970365524292
Batch 59/64 loss: 0.21352893114089966
Batch 60/64 loss: 0.22467464208602905
Batch 61/64 loss: 0.2197743058204651
Batch 62/64 loss: 0.21653902530670166
Batch 63/64 loss: 0.22315925359725952
Batch 64/64 loss: 0.22176384925842285
Epoch 268  Train loss: 0.21851656951156317  Val loss: 0.29390312101423127
Epoch 269
-------------------------------
Batch 1/64 loss: 0.22134745121002197
Batch 2/64 loss: 0.21618008613586426
Batch 3/64 loss: 0.20989996194839478
Batch 4/64 loss: 0.21661949157714844
Batch 5/64 loss: 0.22019505500793457
Batch 6/64 loss: 0.21820759773254395
Batch 7/64 loss: 0.21573007106781006
Batch 8/64 loss: 0.21780049800872803
Batch 9/64 loss: 0.20428884029388428
Batch 10/64 loss: 0.227561354637146
Batch 11/64 loss: 0.21352332830429077
Batch 12/64 loss: 0.21818524599075317
Batch 13/64 loss: 0.2204393744468689
Batch 14/64 loss: 0.23846662044525146
Batch 15/64 loss: 0.21895134449005127
Batch 16/64 loss: 0.2165660858154297
Batch 17/64 loss: 0.21536701917648315
Batch 18/64 loss: 0.2215096354484558
Batch 19/64 loss: 0.223352313041687
Batch 20/64 loss: 0.20995628833770752
Batch 21/64 loss: 0.21000909805297852
Batch 22/64 loss: 0.22305166721343994
Batch 23/64 loss: 0.21622717380523682
Batch 24/64 loss: 0.23021095991134644
Batch 25/64 loss: 0.2218092679977417
Batch 26/64 loss: 0.21406066417694092
Batch 27/64 loss: 0.2186826467514038
Batch 28/64 loss: 0.21939241886138916
Batch 29/64 loss: 0.21548813581466675
Batch 30/64 loss: 0.21082067489624023
Batch 31/64 loss: 0.22716259956359863
Batch 32/64 loss: 0.22587406635284424
Batch 33/64 loss: 0.22911906242370605
Batch 34/64 loss: 0.21711385250091553
Batch 35/64 loss: 0.20411771535873413
Batch 36/64 loss: 0.21797215938568115
Batch 37/64 loss: 0.20780491828918457
Batch 38/64 loss: 0.22790509462356567
Batch 39/64 loss: 0.2159305214881897
Batch 40/64 loss: 0.2186269760131836
Batch 41/64 loss: 0.2196333408355713
Batch 42/64 loss: 0.21041572093963623
Batch 43/64 loss: 0.21178263425827026
Batch 44/64 loss: 0.22152888774871826
Batch 45/64 loss: 0.21659016609191895
Batch 46/64 loss: 0.220964252948761
Batch 47/64 loss: 0.22590208053588867
Batch 48/64 loss: 0.20827555656433105
Batch 49/64 loss: 0.22770047187805176
Batch 50/64 loss: 0.21583527326583862
Batch 51/64 loss: 0.21762824058532715
Batch 52/64 loss: 0.21763837337493896
Batch 53/64 loss: 0.20949041843414307
Batch 54/64 loss: 0.2202979326248169
Batch 55/64 loss: 0.22211873531341553
Batch 56/64 loss: 0.2230231761932373
Batch 57/64 loss: 0.21283066272735596
Batch 58/64 loss: 0.21903061866760254
Batch 59/64 loss: 0.21303969621658325
Batch 60/64 loss: 0.2260320782661438
Batch 61/64 loss: 0.2176026701927185
Batch 62/64 loss: 0.21869510412216187
Batch 63/64 loss: 0.2224711775779724
Batch 64/64 loss: 0.2076939344406128
Epoch 269  Train loss: 0.21819333422417733  Val loss: 0.29322877454593826
Epoch 270
-------------------------------
Batch 1/64 loss: 0.21862941980361938
Batch 2/64 loss: 0.21744245290756226
Batch 3/64 loss: 0.2117173671722412
Batch 4/64 loss: 0.2247452735900879
Batch 5/64 loss: 0.21721398830413818
Batch 6/64 loss: 0.21755683422088623
Batch 7/64 loss: 0.22455328702926636
Batch 8/64 loss: 0.2108684778213501
Batch 9/64 loss: 0.21131932735443115
Batch 10/64 loss: 0.2161915898323059
Batch 11/64 loss: 0.21718084812164307
Batch 12/64 loss: 0.22317171096801758
Batch 13/64 loss: 0.230446457862854
Batch 14/64 loss: 0.21926665306091309
Batch 15/64 loss: 0.21856766939163208
Batch 16/64 loss: 0.21563827991485596
Batch 17/64 loss: 0.22756695747375488
Batch 18/64 loss: 0.21329134702682495
Batch 19/64 loss: 0.21544575691223145
Batch 20/64 loss: 0.2164807915687561
Batch 21/64 loss: 0.21388423442840576
Batch 22/64 loss: 0.22754299640655518
Batch 23/64 loss: 0.21868044137954712
Batch 24/64 loss: 0.2209385633468628
Batch 25/64 loss: 0.2295466661453247
Batch 26/64 loss: 0.21734988689422607
Batch 27/64 loss: 0.21388530731201172
Batch 28/64 loss: 0.21719038486480713
Batch 29/64 loss: 0.22162795066833496
Batch 30/64 loss: 0.2225123643875122
Batch 31/64 loss: 0.2457408905029297
Batch 32/64 loss: 0.21580100059509277
Batch 33/64 loss: 0.21809148788452148
Batch 34/64 loss: 0.21631580591201782
Batch 35/64 loss: 0.21053224802017212
Batch 36/64 loss: 0.22911834716796875
Batch 37/64 loss: 0.2254939079284668
Batch 38/64 loss: 0.2171175479888916
Batch 39/64 loss: 0.21683156490325928
Batch 40/64 loss: 0.22089159488677979
Batch 41/64 loss: 0.2114168405532837
Batch 42/64 loss: 0.2165437936782837
Batch 43/64 loss: 0.21998119354248047
Batch 44/64 loss: 0.22039103507995605
Batch 45/64 loss: 0.22772371768951416
Batch 46/64 loss: 0.20463955402374268
Batch 47/64 loss: 0.21607625484466553
Batch 48/64 loss: 0.21242034435272217
Batch 49/64 loss: 0.21802562475204468
Batch 50/64 loss: 0.2105981707572937
Batch 51/64 loss: 0.21501398086547852
Batch 52/64 loss: 0.22116351127624512
Batch 53/64 loss: 0.21760010719299316
Batch 54/64 loss: 0.22081613540649414
Batch 55/64 loss: 0.21808505058288574
Batch 56/64 loss: 0.2024133801460266
Batch 57/64 loss: 0.21830880641937256
Batch 58/64 loss: 0.21295082569122314
Batch 59/64 loss: 0.21274256706237793
Batch 60/64 loss: 0.20687580108642578
Batch 61/64 loss: 0.22045397758483887
Batch 62/64 loss: 0.21529841423034668
Batch 63/64 loss: 0.20732879638671875
Batch 64/64 loss: 0.206609845161438
Epoch 270  Train loss: 0.2178543207692165  Val loss: 0.2937809292393452
Epoch 271
-------------------------------
Batch 1/64 loss: 0.22016531229019165
Batch 2/64 loss: 0.22205817699432373
Batch 3/64 loss: 0.21413803100585938
Batch 4/64 loss: 0.21715116500854492
Batch 5/64 loss: 0.21253395080566406
Batch 6/64 loss: 0.22945213317871094
Batch 7/64 loss: 0.21465444564819336
Batch 8/64 loss: 0.21873033046722412
Batch 9/64 loss: 0.20725929737091064
Batch 10/64 loss: 0.20794081687927246
Batch 11/64 loss: 0.21916544437408447
Batch 12/64 loss: 0.21866214275360107
Batch 13/64 loss: 0.21743476390838623
Batch 14/64 loss: 0.21388334035873413
Batch 15/64 loss: 0.2202097773551941
Batch 16/64 loss: 0.21712088584899902
Batch 17/64 loss: 0.20730412006378174
Batch 18/64 loss: 0.21642816066741943
Batch 19/64 loss: 0.2070789933204651
Batch 20/64 loss: 0.21212106943130493
Batch 21/64 loss: 0.21821892261505127
Batch 22/64 loss: 0.21731656789779663
Batch 23/64 loss: 0.2223731279373169
Batch 24/64 loss: 0.21573734283447266
Batch 25/64 loss: 0.21330857276916504
Batch 26/64 loss: 0.22264909744262695
Batch 27/64 loss: 0.21146124601364136
Batch 28/64 loss: 0.23083829879760742
Batch 29/64 loss: 0.21520721912384033
Batch 30/64 loss: 0.21509456634521484
Batch 31/64 loss: 0.21928894519805908
Batch 32/64 loss: 0.22385859489440918
Batch 33/64 loss: 0.21945494413375854
Batch 34/64 loss: 0.20826351642608643
Batch 35/64 loss: 0.21427786350250244
Batch 36/64 loss: 0.21773207187652588
Batch 37/64 loss: 0.21442365646362305
Batch 38/64 loss: 0.21639955043792725
Batch 39/64 loss: 0.23069679737091064
Batch 40/64 loss: 0.2215045690536499
Batch 41/64 loss: 0.20789754390716553
Batch 42/64 loss: 0.212141215801239
Batch 43/64 loss: 0.20927613973617554
Batch 44/64 loss: 0.20719075202941895
Batch 45/64 loss: 0.23218262195587158
Batch 46/64 loss: 0.22323596477508545
Batch 47/64 loss: 0.21304607391357422
Batch 48/64 loss: 0.22143352031707764
Batch 49/64 loss: 0.22447949647903442
Batch 50/64 loss: 0.22437059879302979
Batch 51/64 loss: 0.20858466625213623
Batch 52/64 loss: 0.22324275970458984
Batch 53/64 loss: 0.21944069862365723
Batch 54/64 loss: 0.22728586196899414
Batch 55/64 loss: 0.22320884466171265
Batch 56/64 loss: 0.21811997890472412
Batch 57/64 loss: 0.23512840270996094
Batch 58/64 loss: 0.20191168785095215
Batch 59/64 loss: 0.21142518520355225
Batch 60/64 loss: 0.2135663628578186
Batch 61/64 loss: 0.21487444639205933
Batch 62/64 loss: 0.22226548194885254
Batch 63/64 loss: 0.2345747947692871
Batch 64/64 loss: 0.2174382209777832
Epoch 271  Train loss: 0.21762446422202913  Val loss: 0.29364124770017014
Epoch 272
-------------------------------
Batch 1/64 loss: 0.21979916095733643
Batch 2/64 loss: 0.23336327075958252
Batch 3/64 loss: 0.21244573593139648
Batch 4/64 loss: 0.21583807468414307
Batch 5/64 loss: 0.21636801958084106
Batch 6/64 loss: 0.21320390701293945
Batch 7/64 loss: 0.2166752815246582
Batch 8/64 loss: 0.21453619003295898
Batch 9/64 loss: 0.21796631813049316
Batch 10/64 loss: 0.22501814365386963
Batch 11/64 loss: 0.2130974531173706
Batch 12/64 loss: 0.21846270561218262
Batch 13/64 loss: 0.20626556873321533
Batch 14/64 loss: 0.21410977840423584
Batch 15/64 loss: 0.21039772033691406
Batch 16/64 loss: 0.22745025157928467
Batch 17/64 loss: 0.21971261501312256
Batch 18/64 loss: 0.2144373655319214
Batch 19/64 loss: 0.2149239182472229
Batch 20/64 loss: 0.21532154083251953
Batch 21/64 loss: 0.21843504905700684
Batch 22/64 loss: 0.22571992874145508
Batch 23/64 loss: 0.2213294506072998
Batch 24/64 loss: 0.22240418195724487
Batch 25/64 loss: 0.2188476324081421
Batch 26/64 loss: 0.21264135837554932
Batch 27/64 loss: 0.2227115035057068
Batch 28/64 loss: 0.20863670110702515
Batch 29/64 loss: 0.21542370319366455
Batch 30/64 loss: 0.21680128574371338
Batch 31/64 loss: 0.22162145376205444
Batch 32/64 loss: 0.202720046043396
Batch 33/64 loss: 0.23616528511047363
Batch 34/64 loss: 0.22357714176177979
Batch 35/64 loss: 0.21503007411956787
Batch 36/64 loss: 0.22793084383010864
Batch 37/64 loss: 0.2210162878036499
Batch 38/64 loss: 0.22397774457931519
Batch 39/64 loss: 0.21772831678390503
Batch 40/64 loss: 0.21709990501403809
Batch 41/64 loss: 0.21891087293624878
Batch 42/64 loss: 0.21007007360458374
Batch 43/64 loss: 0.22323310375213623
Batch 44/64 loss: 0.22726845741271973
Batch 45/64 loss: 0.22251105308532715
Batch 46/64 loss: 0.22016215324401855
Batch 47/64 loss: 0.21370387077331543
Batch 48/64 loss: 0.21511602401733398
Batch 49/64 loss: 0.2231353521347046
Batch 50/64 loss: 0.22519832849502563
Batch 51/64 loss: 0.22319746017456055
Batch 52/64 loss: 0.21192437410354614
Batch 53/64 loss: 0.20512831211090088
Batch 54/64 loss: 0.21177923679351807
Batch 55/64 loss: 0.2150287628173828
Batch 56/64 loss: 0.2089020013809204
Batch 57/64 loss: 0.21156823635101318
Batch 58/64 loss: 0.22041654586791992
Batch 59/64 loss: 0.22636723518371582
Batch 60/64 loss: 0.21591460704803467
Batch 61/64 loss: 0.20971179008483887
Batch 62/64 loss: 0.21505260467529297
Batch 63/64 loss: 0.20927393436431885
Batch 64/64 loss: 0.2146090269088745
Epoch 272  Train loss: 0.21762732664744058  Val loss: 0.2949514423858669
Epoch 273
-------------------------------
Batch 1/64 loss: 0.2068617343902588
Batch 2/64 loss: 0.22037053108215332
Batch 3/64 loss: 0.21358108520507812
Batch 4/64 loss: 0.21241354942321777
Batch 5/64 loss: 0.20584559440612793
Batch 6/64 loss: 0.20402860641479492
Batch 7/64 loss: 0.20769059658050537
Batch 8/64 loss: 0.21884560585021973
Batch 9/64 loss: 0.21177911758422852
Batch 10/64 loss: 0.22823894023895264
Batch 11/64 loss: 0.2126319408416748
Batch 12/64 loss: 0.20886850357055664
Batch 13/64 loss: 0.21034055948257446
Batch 14/64 loss: 0.2091681957244873
Batch 15/64 loss: 0.21500277519226074
Batch 16/64 loss: 0.21425390243530273
Batch 17/64 loss: 0.2102656364440918
Batch 18/64 loss: 0.21731752157211304
Batch 19/64 loss: 0.22965240478515625
Batch 20/64 loss: 0.20607984066009521
Batch 21/64 loss: 0.22938483953475952
Batch 22/64 loss: 0.2086249589920044
Batch 23/64 loss: 0.2511880397796631
Batch 24/64 loss: 0.2141326665878296
Batch 25/64 loss: 0.21812474727630615
Batch 26/64 loss: 0.2229710817337036
Batch 27/64 loss: 0.21423912048339844
Batch 28/64 loss: 0.20972377061843872
Batch 29/64 loss: 0.20968633890151978
Batch 30/64 loss: 0.2289872169494629
Batch 31/64 loss: 0.22553139925003052
Batch 32/64 loss: 0.21510565280914307
Batch 33/64 loss: 0.2242528200149536
Batch 34/64 loss: 0.22520387172698975
Batch 35/64 loss: 0.2197001576423645
Batch 36/64 loss: 0.22441363334655762
Batch 37/64 loss: 0.21387732028961182
Batch 38/64 loss: 0.2317192554473877
Batch 39/64 loss: 0.21548426151275635
Batch 40/64 loss: 0.21839022636413574
Batch 41/64 loss: 0.21551072597503662
Batch 42/64 loss: 0.22042018175125122
Batch 43/64 loss: 0.21295607089996338
Batch 44/64 loss: 0.20975100994110107
Batch 45/64 loss: 0.21696293354034424
Batch 46/64 loss: 0.22322386503219604
Batch 47/64 loss: 0.20298677682876587
Batch 48/64 loss: 0.22010552883148193
Batch 49/64 loss: 0.21449977159500122
Batch 50/64 loss: 0.21900200843811035
Batch 51/64 loss: 0.22051113843917847
Batch 52/64 loss: 0.21256422996520996
Batch 53/64 loss: 0.21730995178222656
Batch 54/64 loss: 0.20986467599868774
Batch 55/64 loss: 0.21127063035964966
Batch 56/64 loss: 0.21468448638916016
Batch 57/64 loss: 0.2133808732032776
Batch 58/64 loss: 0.21688580513000488
Batch 59/64 loss: 0.21440279483795166
Batch 60/64 loss: 0.22466164827346802
Batch 61/64 loss: 0.21895605325698853
Batch 62/64 loss: 0.2106316089630127
Batch 63/64 loss: 0.21796923875808716
Batch 64/64 loss: 0.21403425931930542
Epoch 273  Train loss: 0.216517893707051  Val loss: 0.29398699355698943
Epoch 274
-------------------------------
Batch 1/64 loss: 0.20967477560043335
Batch 2/64 loss: 0.231586754322052
Batch 3/64 loss: 0.19724702835083008
Batch 4/64 loss: 0.21697378158569336
Batch 5/64 loss: 0.2229822278022766
Batch 6/64 loss: 0.2151780128479004
Batch 7/64 loss: 0.20706093311309814
Batch 8/64 loss: 0.2222278118133545
Batch 9/64 loss: 0.22208160161972046
Batch 10/64 loss: 0.21948719024658203
Batch 11/64 loss: 0.22164946794509888
Batch 12/64 loss: 0.21453678607940674
Batch 13/64 loss: 0.21406030654907227
Batch 14/64 loss: 0.21505111455917358
Batch 15/64 loss: 0.2079559564590454
Batch 16/64 loss: 0.22279393672943115
Batch 17/64 loss: 0.21221792697906494
Batch 18/64 loss: 0.20768767595291138
Batch 19/64 loss: 0.20965415239334106
Batch 20/64 loss: 0.22079598903656006
Batch 21/64 loss: 0.2182255983352661
Batch 22/64 loss: 0.2189919352531433
Batch 23/64 loss: 0.23424148559570312
Batch 24/64 loss: 0.22192072868347168
Batch 25/64 loss: 0.20606791973114014
Batch 26/64 loss: 0.22486937046051025
Batch 27/64 loss: 0.21989405155181885
Batch 28/64 loss: 0.22273766994476318
Batch 29/64 loss: 0.24012935161590576
Batch 30/64 loss: 0.21215766668319702
Batch 31/64 loss: 0.21384531259536743
Batch 32/64 loss: 0.2141932249069214
Batch 33/64 loss: 0.21196019649505615
Batch 34/64 loss: 0.21296632289886475
Batch 35/64 loss: 0.22921502590179443
Batch 36/64 loss: 0.2122730016708374
Batch 37/64 loss: 0.21620982885360718
Batch 38/64 loss: 0.2201366424560547
Batch 39/64 loss: 0.21003520488739014
Batch 40/64 loss: 0.21287405490875244
Batch 41/64 loss: 0.23478758335113525
Batch 42/64 loss: 0.21148061752319336
Batch 43/64 loss: 0.20941197872161865
Batch 44/64 loss: 0.2163066267967224
Batch 45/64 loss: 0.21757394075393677
Batch 46/64 loss: 0.21360445022583008
Batch 47/64 loss: 0.20848006010055542
Batch 48/64 loss: 0.2287003993988037
Batch 49/64 loss: 0.22404181957244873
Batch 50/64 loss: 0.22611963748931885
Batch 51/64 loss: 0.21766233444213867
Batch 52/64 loss: 0.21762192249298096
Batch 53/64 loss: 0.21452534198760986
Batch 54/64 loss: 0.23049461841583252
Batch 55/64 loss: 0.21320635080337524
Batch 56/64 loss: 0.2152634859085083
Batch 57/64 loss: 0.2115567922592163
Batch 58/64 loss: 0.21680951118469238
Batch 59/64 loss: 0.21022355556488037
Batch 60/64 loss: 0.22084927558898926
Batch 61/64 loss: 0.22797107696533203
Batch 62/64 loss: 0.22438818216323853
Batch 63/64 loss: 0.21819829940795898
Batch 64/64 loss: 0.20833712816238403
Epoch 274  Train loss: 0.21755888204948576  Val loss: 0.29528849149487685
Epoch 275
-------------------------------
Batch 1/64 loss: 0.21216213703155518
Batch 2/64 loss: 0.21290969848632812
Batch 3/64 loss: 0.21116983890533447
Batch 4/64 loss: 0.22198235988616943
Batch 5/64 loss: 0.2172785997390747
Batch 6/64 loss: 0.2088559865951538
Batch 7/64 loss: 0.2220485806465149
Batch 8/64 loss: 0.2250690460205078
Batch 9/64 loss: 0.21941930055618286
Batch 10/64 loss: 0.21333253383636475
Batch 11/64 loss: 0.2236940860748291
Batch 12/64 loss: 0.2158220410346985
Batch 13/64 loss: 0.21335077285766602
Batch 14/64 loss: 0.20855724811553955
Batch 15/64 loss: 0.21172940731048584
Batch 16/64 loss: 0.21117091178894043
Batch 17/64 loss: 0.2124512791633606
Batch 18/64 loss: 0.20844018459320068
Batch 19/64 loss: 0.22316455841064453
Batch 20/64 loss: 0.21269917488098145
Batch 21/64 loss: 0.20972490310668945
Batch 22/64 loss: 0.2171015739440918
Batch 23/64 loss: 0.21487164497375488
Batch 24/64 loss: 0.2183825969696045
Batch 25/64 loss: 0.207410991191864
Batch 26/64 loss: 0.20838427543640137
Batch 27/64 loss: 0.2083580493927002
Batch 28/64 loss: 0.22085773944854736
Batch 29/64 loss: 0.21016275882720947
Batch 30/64 loss: 0.2145557403564453
Batch 31/64 loss: 0.20529305934906006
Batch 32/64 loss: 0.22013342380523682
Batch 33/64 loss: 0.22582614421844482
Batch 34/64 loss: 0.21171188354492188
Batch 35/64 loss: 0.2152760624885559
Batch 36/64 loss: 0.22081422805786133
Batch 37/64 loss: 0.21423488855361938
Batch 38/64 loss: 0.21081018447875977
Batch 39/64 loss: 0.22094541788101196
Batch 40/64 loss: 0.2159733772277832
Batch 41/64 loss: 0.21806859970092773
Batch 42/64 loss: 0.2262563705444336
Batch 43/64 loss: 0.20830786228179932
Batch 44/64 loss: 0.22273552417755127
Batch 45/64 loss: 0.22027850151062012
Batch 46/64 loss: 0.21833938360214233
Batch 47/64 loss: 0.2109755277633667
Batch 48/64 loss: 0.21160125732421875
Batch 49/64 loss: 0.2113763689994812
Batch 50/64 loss: 0.23381483554840088
Batch 51/64 loss: 0.2178410291671753
Batch 52/64 loss: 0.23042428493499756
Batch 53/64 loss: 0.22036659717559814
Batch 54/64 loss: 0.22094082832336426
Batch 55/64 loss: 0.21287024021148682
Batch 56/64 loss: 0.21715998649597168
Batch 57/64 loss: 0.22484898567199707
Batch 58/64 loss: 0.2215350866317749
Batch 59/64 loss: 0.22191566228866577
Batch 60/64 loss: 0.22516632080078125
Batch 61/64 loss: 0.21584784984588623
Batch 62/64 loss: 0.20448243618011475
Batch 63/64 loss: 0.22573697566986084
Batch 64/64 loss: 0.21869397163391113
Epoch 275  Train loss: 0.21648702247470034  Val loss: 0.29360979979800195
Epoch 276
-------------------------------
Batch 1/64 loss: 0.20552855730056763
Batch 2/64 loss: 0.21591585874557495
Batch 3/64 loss: 0.20713192224502563
Batch 4/64 loss: 0.20792198181152344
Batch 5/64 loss: 0.22018122673034668
Batch 6/64 loss: 0.21915006637573242
Batch 7/64 loss: 0.19847655296325684
Batch 8/64 loss: 0.225119948387146
Batch 9/64 loss: 0.21267038583755493
Batch 10/64 loss: 0.20747852325439453
Batch 11/64 loss: 0.21122485399246216
Batch 12/64 loss: 0.2098027467727661
Batch 13/64 loss: 0.21934103965759277
Batch 14/64 loss: 0.23500359058380127
Batch 15/64 loss: 0.21215248107910156
Batch 16/64 loss: 0.22358787059783936
Batch 17/64 loss: 0.20894485712051392
Batch 18/64 loss: 0.22737520933151245
Batch 19/64 loss: 0.2227919101715088
Batch 20/64 loss: 0.2134469747543335
Batch 21/64 loss: 0.22012948989868164
Batch 22/64 loss: 0.2234783172607422
Batch 23/64 loss: 0.2394167184829712
Batch 24/64 loss: 0.21982252597808838
Batch 25/64 loss: 0.22235095500946045
Batch 26/64 loss: 0.20597076416015625
Batch 27/64 loss: 0.2246110439300537
Batch 28/64 loss: 0.21712517738342285
Batch 29/64 loss: 0.21414577960968018
Batch 30/64 loss: 0.21557986736297607
Batch 31/64 loss: 0.21590757369995117
Batch 32/64 loss: 0.20999473333358765
Batch 33/64 loss: 0.23091042041778564
Batch 34/64 loss: 0.21323400735855103
Batch 35/64 loss: 0.21559983491897583
Batch 36/64 loss: 0.22133851051330566
Batch 37/64 loss: 0.20652854442596436
Batch 38/64 loss: 0.2115498185157776
Batch 39/64 loss: 0.20595455169677734
Batch 40/64 loss: 0.2173001766204834
Batch 41/64 loss: 0.20923513174057007
Batch 42/64 loss: 0.2170257568359375
Batch 43/64 loss: 0.20861482620239258
Batch 44/64 loss: 0.21999400854110718
Batch 45/64 loss: 0.21631550788879395
Batch 46/64 loss: 0.2114555835723877
Batch 47/64 loss: 0.21207386255264282
Batch 48/64 loss: 0.2145603895187378
Batch 49/64 loss: 0.2183956503868103
Batch 50/64 loss: 0.21307086944580078
Batch 51/64 loss: 0.22193145751953125
Batch 52/64 loss: 0.20950305461883545
Batch 53/64 loss: 0.21193397045135498
Batch 54/64 loss: 0.2211298942565918
Batch 55/64 loss: 0.2200556993484497
Batch 56/64 loss: 0.2162395715713501
Batch 57/64 loss: 0.21327394247055054
Batch 58/64 loss: 0.23135358095169067
Batch 59/64 loss: 0.21282613277435303
Batch 60/64 loss: 0.21738052368164062
Batch 61/64 loss: 0.2034081220626831
Batch 62/64 loss: 0.2296624779701233
Batch 63/64 loss: 0.22391152381896973
Batch 64/64 loss: 0.2265363335609436
Epoch 276  Train loss: 0.2164305750061484  Val loss: 0.293688207147867
Epoch 277
-------------------------------
Batch 1/64 loss: 0.21900594234466553
Batch 2/64 loss: 0.20904570817947388
Batch 3/64 loss: 0.2193053960800171
Batch 4/64 loss: 0.2088332176208496
Batch 5/64 loss: 0.21016407012939453
Batch 6/64 loss: 0.22067368030548096
Batch 7/64 loss: 0.22236967086791992
Batch 8/64 loss: 0.21786195039749146
Batch 9/64 loss: 0.22071117162704468
Batch 10/64 loss: 0.21733713150024414
Batch 11/64 loss: 0.21147030591964722
Batch 12/64 loss: 0.229211688041687
Batch 13/64 loss: 0.21361017227172852
Batch 14/64 loss: 0.21215945482254028
Batch 15/64 loss: 0.20633089542388916
Batch 16/64 loss: 0.2120915651321411
Batch 17/64 loss: 0.2229442596435547
Batch 18/64 loss: 0.21673762798309326
Batch 19/64 loss: 0.20653682947158813
Batch 20/64 loss: 0.21932822465896606
Batch 21/64 loss: 0.2100200057029724
Batch 22/64 loss: 0.21073585748672485
Batch 23/64 loss: 0.21657633781433105
Batch 24/64 loss: 0.21711909770965576
Batch 25/64 loss: 0.21381711959838867
Batch 26/64 loss: 0.2277970314025879
Batch 27/64 loss: 0.21116620302200317
Batch 28/64 loss: 0.22137892246246338
Batch 29/64 loss: 0.2144729495048523
Batch 30/64 loss: 0.22382962703704834
Batch 31/64 loss: 0.2237311601638794
Batch 32/64 loss: 0.21827590465545654
Batch 33/64 loss: 0.2235507369041443
Batch 34/64 loss: 0.20921730995178223
Batch 35/64 loss: 0.21357464790344238
Batch 36/64 loss: 0.2215663194656372
Batch 37/64 loss: 0.22369730472564697
Batch 38/64 loss: 0.21820473670959473
Batch 39/64 loss: 0.21257752180099487
Batch 40/64 loss: 0.21781694889068604
Batch 41/64 loss: 0.22739553451538086
Batch 42/64 loss: 0.22922062873840332
Batch 43/64 loss: 0.2203000783920288
Batch 44/64 loss: 0.212541401386261
Batch 45/64 loss: 0.21136987209320068
Batch 46/64 loss: 0.22205263376235962
Batch 47/64 loss: 0.20603203773498535
Batch 48/64 loss: 0.22376477718353271
Batch 49/64 loss: 0.2089720368385315
Batch 50/64 loss: 0.2148212194442749
Batch 51/64 loss: 0.22706401348114014
Batch 52/64 loss: 0.22363245487213135
Batch 53/64 loss: 0.2145775556564331
Batch 54/64 loss: 0.22561872005462646
Batch 55/64 loss: 0.2088969349861145
Batch 56/64 loss: 0.21113669872283936
Batch 57/64 loss: 0.20906811952590942
Batch 58/64 loss: 0.23082339763641357
Batch 59/64 loss: 0.21857857704162598
Batch 60/64 loss: 0.2108861804008484
Batch 61/64 loss: 0.21422600746154785
Batch 62/64 loss: 0.21566498279571533
Batch 63/64 loss: 0.22451335191726685
Batch 64/64 loss: 0.22631675004959106
Epoch 277  Train loss: 0.21718822717666625  Val loss: 0.2934985885915068
Epoch 278
-------------------------------
Batch 1/64 loss: 0.21894729137420654
Batch 2/64 loss: 0.20824480056762695
Batch 3/64 loss: 0.20708155632019043
Batch 4/64 loss: 0.2111804485321045
Batch 5/64 loss: 0.21256005764007568
Batch 6/64 loss: 0.2250899076461792
Batch 7/64 loss: 0.20965683460235596
Batch 8/64 loss: 0.20997905731201172
Batch 9/64 loss: 0.2158750295639038
Batch 10/64 loss: 0.22290658950805664
Batch 11/64 loss: 0.20777684450149536
Batch 12/64 loss: 0.21591931581497192
Batch 13/64 loss: 0.21369338035583496
Batch 14/64 loss: 0.22095376253128052
Batch 15/64 loss: 0.21308934688568115
Batch 16/64 loss: 0.2147701382637024
Batch 17/64 loss: 0.21805059909820557
Batch 18/64 loss: 0.22716140747070312
Batch 19/64 loss: 0.2268615961074829
Batch 20/64 loss: 0.21137970685958862
Batch 21/64 loss: 0.20839601755142212
Batch 22/64 loss: 0.2196052074432373
Batch 23/64 loss: 0.21076518297195435
Batch 24/64 loss: 0.21589922904968262
Batch 25/64 loss: 0.21528780460357666
Batch 26/64 loss: 0.23014819622039795
Batch 27/64 loss: 0.20553195476531982
Batch 28/64 loss: 0.2052164077758789
Batch 29/64 loss: 0.20533883571624756
Batch 30/64 loss: 0.21877765655517578
Batch 31/64 loss: 0.21279704570770264
Batch 32/64 loss: 0.20140337944030762
Batch 33/64 loss: 0.2190813422203064
Batch 34/64 loss: 0.21442925930023193
Batch 35/64 loss: 0.21001136302947998
Batch 36/64 loss: 0.22083532810211182
Batch 37/64 loss: 0.22225117683410645
Batch 38/64 loss: 0.22574388980865479
Batch 39/64 loss: 0.21515429019927979
Batch 40/64 loss: 0.23125994205474854
Batch 41/64 loss: 0.2203357219696045
Batch 42/64 loss: 0.21470344066619873
Batch 43/64 loss: 0.21111953258514404
Batch 44/64 loss: 0.20331740379333496
Batch 45/64 loss: 0.20932155847549438
Batch 46/64 loss: 0.2150667905807495
Batch 47/64 loss: 0.22398614883422852
Batch 48/64 loss: 0.22955024242401123
Batch 49/64 loss: 0.20807945728302002
Batch 50/64 loss: 0.20808321237564087
Batch 51/64 loss: 0.22110939025878906
Batch 52/64 loss: 0.2324305772781372
Batch 53/64 loss: 0.21905314922332764
Batch 54/64 loss: 0.232688307762146
Batch 55/64 loss: 0.2213638424873352
Batch 56/64 loss: 0.20775949954986572
Batch 57/64 loss: 0.22189569473266602
Batch 58/64 loss: 0.2196108102798462
Batch 59/64 loss: 0.23547005653381348
Batch 60/64 loss: 0.21553516387939453
Batch 61/64 loss: 0.20673465728759766
Batch 62/64 loss: 0.21987634897232056
Batch 63/64 loss: 0.21693801879882812
Batch 64/64 loss: 0.2282615303993225
Epoch 278  Train loss: 0.21653860947665046  Val loss: 0.2940763894634968
Epoch 279
-------------------------------
Batch 1/64 loss: 0.19777733087539673
Batch 2/64 loss: 0.20835638046264648
Batch 3/64 loss: 0.21393263339996338
Batch 4/64 loss: 0.21684682369232178
Batch 5/64 loss: 0.22167187929153442
Batch 6/64 loss: 0.2163299322128296
Batch 7/64 loss: 0.20867764949798584
Batch 8/64 loss: 0.22300994396209717
Batch 9/64 loss: 0.20930814743041992
Batch 10/64 loss: 0.20598596334457397
Batch 11/64 loss: 0.211997389793396
Batch 12/64 loss: 0.22585755586624146
Batch 13/64 loss: 0.2106320858001709
Batch 14/64 loss: 0.22781354188919067
Batch 15/64 loss: 0.21993803977966309
Batch 16/64 loss: 0.2353147268295288
Batch 17/64 loss: 0.2142188549041748
Batch 18/64 loss: 0.21541118621826172
Batch 19/64 loss: 0.20939308404922485
Batch 20/64 loss: 0.20816242694854736
Batch 21/64 loss: 0.21613693237304688
Batch 22/64 loss: 0.2129141092300415
Batch 23/64 loss: 0.21749955415725708
Batch 24/64 loss: 0.21276110410690308
Batch 25/64 loss: 0.21874165534973145
Batch 26/64 loss: 0.21798396110534668
Batch 27/64 loss: 0.21309411525726318
Batch 28/64 loss: 0.21239960193634033
Batch 29/64 loss: 0.21433532238006592
Batch 30/64 loss: 0.2091660499572754
Batch 31/64 loss: 0.21193218231201172
Batch 32/64 loss: 0.22073006629943848
Batch 33/64 loss: 0.21762621402740479
Batch 34/64 loss: 0.211334228515625
Batch 35/64 loss: 0.2187473177909851
Batch 36/64 loss: 0.218711256980896
Batch 37/64 loss: 0.20849275588989258
Batch 38/64 loss: 0.22341501712799072
Batch 39/64 loss: 0.21506667137145996
Batch 40/64 loss: 0.20731806755065918
Batch 41/64 loss: 0.2139580249786377
Batch 42/64 loss: 0.2186976671218872
Batch 43/64 loss: 0.21314537525177002
Batch 44/64 loss: 0.2162238359451294
Batch 45/64 loss: 0.2228676676750183
Batch 46/64 loss: 0.21583479642868042
Batch 47/64 loss: 0.21772313117980957
Batch 48/64 loss: 0.21656328439712524
Batch 49/64 loss: 0.22377586364746094
Batch 50/64 loss: 0.2100677490234375
Batch 51/64 loss: 0.22775006294250488
Batch 52/64 loss: 0.22476351261138916
Batch 53/64 loss: 0.20615661144256592
Batch 54/64 loss: 0.21415948867797852
Batch 55/64 loss: 0.21232998371124268
Batch 56/64 loss: 0.2224178910255432
Batch 57/64 loss: 0.20830774307250977
Batch 58/64 loss: 0.21992170810699463
Batch 59/64 loss: 0.21382975578308105
Batch 60/64 loss: 0.2216077446937561
Batch 61/64 loss: 0.21394211053848267
Batch 62/64 loss: 0.21470755338668823
Batch 63/64 loss: 0.21633225679397583
Batch 64/64 loss: 0.22691595554351807
Epoch 279  Train loss: 0.2157539222754684  Val loss: 0.2936965618346565
Epoch 280
-------------------------------
Batch 1/64 loss: 0.20748651027679443
Batch 2/64 loss: 0.21843767166137695
Batch 3/64 loss: 0.21166837215423584
Batch 4/64 loss: 0.21494591236114502
Batch 5/64 loss: 0.21143150329589844
Batch 6/64 loss: 0.210840106010437
Batch 7/64 loss: 0.21685397624969482
Batch 8/64 loss: 0.21082067489624023
Batch 9/64 loss: 0.20983600616455078
Batch 10/64 loss: 0.21580535173416138
Batch 11/64 loss: 0.21758460998535156
Batch 12/64 loss: 0.20976555347442627
Batch 13/64 loss: 0.21448063850402832
Batch 14/64 loss: 0.21635496616363525
Batch 15/64 loss: 0.21756696701049805
Batch 16/64 loss: 0.21718454360961914
Batch 17/64 loss: 0.20756471157073975
Batch 18/64 loss: 0.21692758798599243
Batch 19/64 loss: 0.2130565643310547
Batch 20/64 loss: 0.21552038192749023
Batch 21/64 loss: 0.21720349788665771
Batch 22/64 loss: 0.22372674942016602
Batch 23/64 loss: 0.22662591934204102
Batch 24/64 loss: 0.21027040481567383
Batch 25/64 loss: 0.21312463283538818
Batch 26/64 loss: 0.21267634630203247
Batch 27/64 loss: 0.22962093353271484
Batch 28/64 loss: 0.23305249214172363
Batch 29/64 loss: 0.21853786706924438
Batch 30/64 loss: 0.21824872493743896
Batch 31/64 loss: 0.22083312273025513
Batch 32/64 loss: 0.20895922183990479
Batch 33/64 loss: 0.2082364559173584
Batch 34/64 loss: 0.2236347198486328
Batch 35/64 loss: 0.2151467204093933
Batch 36/64 loss: 0.2214663028717041
Batch 37/64 loss: 0.21227610111236572
Batch 38/64 loss: 0.227148175239563
Batch 39/64 loss: 0.21018314361572266
Batch 40/64 loss: 0.20935702323913574
Batch 41/64 loss: 0.21577095985412598
Batch 42/64 loss: 0.22396284341812134
Batch 43/64 loss: 0.22746634483337402
Batch 44/64 loss: 0.20965152978897095
Batch 45/64 loss: 0.20630741119384766
Batch 46/64 loss: 0.2256460189819336
Batch 47/64 loss: 0.21977734565734863
Batch 48/64 loss: 0.22192150354385376
Batch 49/64 loss: 0.20976930856704712
Batch 50/64 loss: 0.21494579315185547
Batch 51/64 loss: 0.21356868743896484
Batch 52/64 loss: 0.22669261693954468
Batch 53/64 loss: 0.21812456846237183
Batch 54/64 loss: 0.20751023292541504
Batch 55/64 loss: 0.2186793088912964
Batch 56/64 loss: 0.2274458408355713
Batch 57/64 loss: 0.23377454280853271
Batch 58/64 loss: 0.2126610279083252
Batch 59/64 loss: 0.2274174690246582
Batch 60/64 loss: 0.21296441555023193
Batch 61/64 loss: 0.20625293254852295
Batch 62/64 loss: 0.2081809639930725
Batch 63/64 loss: 0.21473169326782227
Batch 64/64 loss: 0.21475547552108765
Epoch 280  Train loss: 0.2164509981286292  Val loss: 0.2945471600568581
Epoch 281
-------------------------------
Batch 1/64 loss: 0.23126494884490967
Batch 2/64 loss: 0.21225255727767944
Batch 3/64 loss: 0.2084924578666687
Batch 4/64 loss: 0.21629416942596436
Batch 5/64 loss: 0.21162784099578857
Batch 6/64 loss: 0.2205204963684082
Batch 7/64 loss: 0.22328084707260132
Batch 8/64 loss: 0.22438538074493408
Batch 9/64 loss: 0.22086268663406372
Batch 10/64 loss: 0.2147691249847412
Batch 11/64 loss: 0.21487683057785034
Batch 12/64 loss: 0.2100611925125122
Batch 13/64 loss: 0.2124805450439453
Batch 14/64 loss: 0.21447253227233887
Batch 15/64 loss: 0.21143680810928345
Batch 16/64 loss: 0.21403247117996216
Batch 17/64 loss: 0.21081328392028809
Batch 18/64 loss: 0.20890527963638306
Batch 19/64 loss: 0.20336812734603882
Batch 20/64 loss: 0.22898828983306885
Batch 21/64 loss: 0.22001516819000244
Batch 22/64 loss: 0.2109726071357727
Batch 23/64 loss: 0.21206355094909668
Batch 24/64 loss: 0.21137338876724243
Batch 25/64 loss: 0.2105157971382141
Batch 26/64 loss: 0.22085314989089966
Batch 27/64 loss: 0.2219167947769165
Batch 28/64 loss: 0.21127384901046753
Batch 29/64 loss: 0.22164392471313477
Batch 30/64 loss: 0.2151719331741333
Batch 31/64 loss: 0.20532828569412231
Batch 32/64 loss: 0.2293379306793213
Batch 33/64 loss: 0.21653538942337036
Batch 34/64 loss: 0.2107151746749878
Batch 35/64 loss: 0.21979403495788574
Batch 36/64 loss: 0.2221878170967102
Batch 37/64 loss: 0.21351289749145508
Batch 38/64 loss: 0.21027201414108276
Batch 39/64 loss: 0.21803897619247437
Batch 40/64 loss: 0.2106931209564209
Batch 41/64 loss: 0.2194582223892212
Batch 42/64 loss: 0.2159251570701599
Batch 43/64 loss: 0.21453857421875
Batch 44/64 loss: 0.21738004684448242
Batch 45/64 loss: 0.21633505821228027
Batch 46/64 loss: 0.21201157569885254
Batch 47/64 loss: 0.21689069271087646
Batch 48/64 loss: 0.20653247833251953
Batch 49/64 loss: 0.21012580394744873
Batch 50/64 loss: 0.22507023811340332
Batch 51/64 loss: 0.20745337009429932
Batch 52/64 loss: 0.21020543575286865
Batch 53/64 loss: 0.2163979411125183
Batch 54/64 loss: 0.20640653371810913
Batch 55/64 loss: 0.21797561645507812
Batch 56/64 loss: 0.21454578638076782
Batch 57/64 loss: 0.21726059913635254
Batch 58/64 loss: 0.21794980764389038
Batch 59/64 loss: 0.20653069019317627
Batch 60/64 loss: 0.2191314697265625
Batch 61/64 loss: 0.21961545944213867
Batch 62/64 loss: 0.2012861967086792
Batch 63/64 loss: 0.2221168875694275
Batch 64/64 loss: 0.22484242916107178
Epoch 281  Train loss: 0.2152968962987264  Val loss: 0.2953843521498323
Epoch 282
-------------------------------
Batch 1/64 loss: 0.22781974077224731
Batch 2/64 loss: 0.21272993087768555
Batch 3/64 loss: 0.218300461769104
Batch 4/64 loss: 0.21133792400360107
Batch 5/64 loss: 0.2165919542312622
Batch 6/64 loss: 0.21920859813690186
Batch 7/64 loss: 0.20227080583572388
Batch 8/64 loss: 0.2193654179573059
Batch 9/64 loss: 0.20618677139282227
Batch 10/64 loss: 0.21091437339782715
Batch 11/64 loss: 0.22410798072814941
Batch 12/64 loss: 0.2135072946548462
Batch 13/64 loss: 0.2034873366355896
Batch 14/64 loss: 0.2281007170677185
Batch 15/64 loss: 0.22091913223266602
Batch 16/64 loss: 0.2113896608352661
Batch 17/64 loss: 0.2143380045890808
Batch 18/64 loss: 0.22675204277038574
Batch 19/64 loss: 0.21772122383117676
Batch 20/64 loss: 0.22526812553405762
Batch 21/64 loss: 0.22381937503814697
Batch 22/64 loss: 0.23526954650878906
Batch 23/64 loss: 0.2091277837753296
Batch 24/64 loss: 0.21591246128082275
Batch 25/64 loss: 0.2130969762802124
Batch 26/64 loss: 0.21759891510009766
Batch 27/64 loss: 0.2218419313430786
Batch 28/64 loss: 0.2239929437637329
Batch 29/64 loss: 0.21144139766693115
Batch 30/64 loss: 0.22090423107147217
Batch 31/64 loss: 0.2271348237991333
Batch 32/64 loss: 0.20870637893676758
Batch 33/64 loss: 0.21865564584732056
Batch 34/64 loss: 0.22373849153518677
Batch 35/64 loss: 0.2040715217590332
Batch 36/64 loss: 0.21140450239181519
Batch 37/64 loss: 0.22250699996948242
Batch 38/64 loss: 0.21170568466186523
Batch 39/64 loss: 0.21106719970703125
Batch 40/64 loss: 0.21804940700531006
Batch 41/64 loss: 0.20883482694625854
Batch 42/64 loss: 0.2074899673461914
Batch 43/64 loss: 0.21232318878173828
Batch 44/64 loss: 0.21963942050933838
Batch 45/64 loss: 0.214302659034729
Batch 46/64 loss: 0.21708780527114868
Batch 47/64 loss: 0.21538859605789185
Batch 48/64 loss: 0.21664631366729736
Batch 49/64 loss: 0.20876026153564453
Batch 50/64 loss: 0.2115703821182251
Batch 51/64 loss: 0.21850943565368652
Batch 52/64 loss: 0.21983754634857178
Batch 53/64 loss: 0.2055063247680664
Batch 54/64 loss: 0.21885991096496582
Batch 55/64 loss: 0.2108471393585205
Batch 56/64 loss: 0.21522057056427002
Batch 57/64 loss: 0.21005284786224365
Batch 58/64 loss: 0.21977102756500244
Batch 59/64 loss: 0.2233831286430359
Batch 60/64 loss: 0.21720117330551147
Batch 61/64 loss: 0.20722424983978271
Batch 62/64 loss: 0.21450531482696533
Batch 63/64 loss: 0.222173810005188
Batch 64/64 loss: 0.2224663496017456
Epoch 282  Train loss: 0.2161937157313029  Val loss: 0.2935974544675899
Epoch 283
-------------------------------
Batch 1/64 loss: 0.21619141101837158
Batch 2/64 loss: 0.22657489776611328
Batch 3/64 loss: 0.21147215366363525
Batch 4/64 loss: 0.20664054155349731
Batch 5/64 loss: 0.2226043939590454
Batch 6/64 loss: 0.21514523029327393
Batch 7/64 loss: 0.20725858211517334
Batch 8/64 loss: 0.2197812795639038
Batch 9/64 loss: 0.21486210823059082
Batch 10/64 loss: 0.20535963773727417
Batch 11/64 loss: 0.20703554153442383
Batch 12/64 loss: 0.20921111106872559
Batch 13/64 loss: 0.21572411060333252
Batch 14/64 loss: 0.22977274656295776
Batch 15/64 loss: 0.21120381355285645
Batch 16/64 loss: 0.21660113334655762
Batch 17/64 loss: 0.22256386280059814
Batch 18/64 loss: 0.20839089155197144
Batch 19/64 loss: 0.2125125527381897
Batch 20/64 loss: 0.2135004997253418
Batch 21/64 loss: 0.21513545513153076
Batch 22/64 loss: 0.20647883415222168
Batch 23/64 loss: 0.22072869539260864
Batch 24/64 loss: 0.21618294715881348
Batch 25/64 loss: 0.20912915468215942
Batch 26/64 loss: 0.20753037929534912
Batch 27/64 loss: 0.21712422370910645
Batch 28/64 loss: 0.21482223272323608
Batch 29/64 loss: 0.22895461320877075
Batch 30/64 loss: 0.20548546314239502
Batch 31/64 loss: 0.21019601821899414
Batch 32/64 loss: 0.20296871662139893
Batch 33/64 loss: 0.21016836166381836
Batch 34/64 loss: 0.21169757843017578
Batch 35/64 loss: 0.21114730834960938
Batch 36/64 loss: 0.2236778736114502
Batch 37/64 loss: 0.2151496410369873
Batch 38/64 loss: 0.21487712860107422
Batch 39/64 loss: 0.23251771926879883
Batch 40/64 loss: 0.20708346366882324
Batch 41/64 loss: 0.21519196033477783
Batch 42/64 loss: 0.22202444076538086
Batch 43/64 loss: 0.2170243263244629
Batch 44/64 loss: 0.21442198753356934
Batch 45/64 loss: 0.22155898809432983
Batch 46/64 loss: 0.21073049306869507
Batch 47/64 loss: 0.20799076557159424
Batch 48/64 loss: 0.22186613082885742
Batch 49/64 loss: 0.21235179901123047
Batch 50/64 loss: 0.2277725338935852
Batch 51/64 loss: 0.22386384010314941
Batch 52/64 loss: 0.21122503280639648
Batch 53/64 loss: 0.22815579175949097
Batch 54/64 loss: 0.21373462677001953
Batch 55/64 loss: 0.20879709720611572
Batch 56/64 loss: 0.20916533470153809
Batch 57/64 loss: 0.2078290581703186
Batch 58/64 loss: 0.21278691291809082
Batch 59/64 loss: 0.22844356298446655
Batch 60/64 loss: 0.20757907629013062
Batch 61/64 loss: 0.21335816383361816
Batch 62/64 loss: 0.2147592306137085
Batch 63/64 loss: 0.21246230602264404
Batch 64/64 loss: 0.21666109561920166
Epoch 283  Train loss: 0.21488708374547025  Val loss: 0.29414395245489794
Epoch 284
-------------------------------
Batch 1/64 loss: 0.2075730562210083
Batch 2/64 loss: 0.2107648253440857
Batch 3/64 loss: 0.21275413036346436
Batch 4/64 loss: 0.21156412363052368
Batch 5/64 loss: 0.21198976039886475
Batch 6/64 loss: 0.202500581741333
Batch 7/64 loss: 0.2106601595878601
Batch 8/64 loss: 0.2078433632850647
Batch 9/64 loss: 0.2071666717529297
Batch 10/64 loss: 0.2091800570487976
Batch 11/64 loss: 0.2181401252746582
Batch 12/64 loss: 0.21413081884384155
Batch 13/64 loss: 0.20569145679473877
Batch 14/64 loss: 0.2140064239501953
Batch 15/64 loss: 0.21662259101867676
Batch 16/64 loss: 0.21332985162734985
Batch 17/64 loss: 0.2066364884376526
Batch 18/64 loss: 0.21016967296600342
Batch 19/64 loss: 0.2079176902770996
Batch 20/64 loss: 0.21471399068832397
Batch 21/64 loss: 0.21819555759429932
Batch 22/64 loss: 0.21381711959838867
Batch 23/64 loss: 0.20764750242233276
Batch 24/64 loss: 0.20918726921081543
Batch 25/64 loss: 0.2193155288696289
Batch 26/64 loss: 0.2221207618713379
Batch 27/64 loss: 0.22360342741012573
Batch 28/64 loss: 0.20367932319641113
Batch 29/64 loss: 0.2163071632385254
Batch 30/64 loss: 0.2128610610961914
Batch 31/64 loss: 0.2183520793914795
Batch 32/64 loss: 0.22046184539794922
Batch 33/64 loss: 0.21889030933380127
Batch 34/64 loss: 0.22699815034866333
Batch 35/64 loss: 0.2187991738319397
Batch 36/64 loss: 0.21600234508514404
Batch 37/64 loss: 0.20971262454986572
Batch 38/64 loss: 0.20977675914764404
Batch 39/64 loss: 0.21475809812545776
Batch 40/64 loss: 0.20647847652435303
Batch 41/64 loss: 0.23023313283920288
Batch 42/64 loss: 0.21583521366119385
Batch 43/64 loss: 0.2073662281036377
Batch 44/64 loss: 0.22279560565948486
Batch 45/64 loss: 0.2178102731704712
Batch 46/64 loss: 0.21435123682022095
Batch 47/64 loss: 0.21559500694274902
Batch 48/64 loss: 0.2169182300567627
Batch 49/64 loss: 0.21543669700622559
Batch 50/64 loss: 0.21902835369110107
Batch 51/64 loss: 0.2226628065109253
Batch 52/64 loss: 0.21013367176055908
Batch 53/64 loss: 0.22544646263122559
Batch 54/64 loss: 0.21258997917175293
Batch 55/64 loss: 0.2087586522102356
Batch 56/64 loss: 0.21974629163742065
Batch 57/64 loss: 0.21182703971862793
Batch 58/64 loss: 0.21303153038024902
Batch 59/64 loss: 0.23326528072357178
Batch 60/64 loss: 0.21516716480255127
Batch 61/64 loss: 0.21550869941711426
Batch 62/64 loss: 0.21371698379516602
Batch 63/64 loss: 0.2157689332962036
Batch 64/64 loss: 0.22548604011535645
Epoch 284  Train loss: 0.2146263281504313  Val loss: 0.2950117125134288
Epoch 285
-------------------------------
Batch 1/64 loss: 0.21572673320770264
Batch 2/64 loss: 0.2161616086959839
Batch 3/64 loss: 0.21862316131591797
Batch 4/64 loss: 0.21098828315734863
Batch 5/64 loss: 0.2164219617843628
Batch 6/64 loss: 0.21864455938339233
Batch 7/64 loss: 0.2100479006767273
Batch 8/64 loss: 0.22728979587554932
Batch 9/64 loss: 0.2106245756149292
Batch 10/64 loss: 0.20889031887054443
Batch 11/64 loss: 0.20968914031982422
Batch 12/64 loss: 0.21005511283874512
Batch 13/64 loss: 0.22309339046478271
Batch 14/64 loss: 0.2266017198562622
Batch 15/64 loss: 0.2104901671409607
Batch 16/64 loss: 0.22439348697662354
Batch 17/64 loss: 0.21608948707580566
Batch 18/64 loss: 0.2109154462814331
Batch 19/64 loss: 0.21021413803100586
Batch 20/64 loss: 0.22526860237121582
Batch 21/64 loss: 0.20828378200531006
Batch 22/64 loss: 0.21012699604034424
Batch 23/64 loss: 0.2073671817779541
Batch 24/64 loss: 0.21380740404129028
Batch 25/64 loss: 0.222683846950531
Batch 26/64 loss: 0.2229825258255005
Batch 27/64 loss: 0.22509288787841797
Batch 28/64 loss: 0.20217812061309814
Batch 29/64 loss: 0.2040664553642273
Batch 30/64 loss: 0.20327186584472656
Batch 31/64 loss: 0.21683192253112793
Batch 32/64 loss: 0.2217932939529419
Batch 33/64 loss: 0.21430045366287231
Batch 34/64 loss: 0.21526390314102173
Batch 35/64 loss: 0.2236495018005371
Batch 36/64 loss: 0.22337579727172852
Batch 37/64 loss: 0.2142719030380249
Batch 38/64 loss: 0.21933937072753906
Batch 39/64 loss: 0.2218252420425415
Batch 40/64 loss: 0.21288180351257324
Batch 41/64 loss: 0.20943820476531982
Batch 42/64 loss: 0.2184377908706665
Batch 43/64 loss: 0.215420663356781
Batch 44/64 loss: 0.21207982301712036
Batch 45/64 loss: 0.21561211347579956
Batch 46/64 loss: 0.21723932027816772
Batch 47/64 loss: 0.2216554880142212
Batch 48/64 loss: 0.20592767000198364
Batch 49/64 loss: 0.22141516208648682
Batch 50/64 loss: 0.21780860424041748
Batch 51/64 loss: 0.2123393416404724
Batch 52/64 loss: 0.21203672885894775
Batch 53/64 loss: 0.21379268169403076
Batch 54/64 loss: 0.20815861225128174
Batch 55/64 loss: 0.22242283821105957
Batch 56/64 loss: 0.21037626266479492
Batch 57/64 loss: 0.2215569019317627
Batch 58/64 loss: 0.22585469484329224
Batch 59/64 loss: 0.22940421104431152
Batch 60/64 loss: 0.21013593673706055
Batch 61/64 loss: 0.21391034126281738
Batch 62/64 loss: 0.22028577327728271
Batch 63/64 loss: 0.22047662734985352
Batch 64/64 loss: 0.21890604496002197
Epoch 285  Train loss: 0.2158994380165549  Val loss: 0.2941674497938648
Epoch 286
-------------------------------
Batch 1/64 loss: 0.21312391757965088
Batch 2/64 loss: 0.21679341793060303
Batch 3/64 loss: 0.2047479748725891
Batch 4/64 loss: 0.2140876054763794
Batch 5/64 loss: 0.21111774444580078
Batch 6/64 loss: 0.21978867053985596
Batch 7/64 loss: 0.21397697925567627
Batch 8/64 loss: 0.20511841773986816
Batch 9/64 loss: 0.21951496601104736
Batch 10/64 loss: 0.202825129032135
Batch 11/64 loss: 0.22308754920959473
Batch 12/64 loss: 0.22288286685943604
Batch 13/64 loss: 0.20692598819732666
Batch 14/64 loss: 0.21183371543884277
Batch 15/64 loss: 0.216056227684021
Batch 16/64 loss: 0.20987236499786377
Batch 17/64 loss: 0.19938135147094727
Batch 18/64 loss: 0.2075810432434082
Batch 19/64 loss: 0.23483335971832275
Batch 20/64 loss: 0.217299222946167
Batch 21/64 loss: 0.2172781229019165
Batch 22/64 loss: 0.20291662216186523
Batch 23/64 loss: 0.20321708917617798
Batch 24/64 loss: 0.22342395782470703
Batch 25/64 loss: 0.2081221342086792
Batch 26/64 loss: 0.21991533041000366
Batch 27/64 loss: 0.22543931007385254
Batch 28/64 loss: 0.20968544483184814
Batch 29/64 loss: 0.20973336696624756
Batch 30/64 loss: 0.20389622449874878
Batch 31/64 loss: 0.20545148849487305
Batch 32/64 loss: 0.21166598796844482
Batch 33/64 loss: 0.21932637691497803
Batch 34/64 loss: 0.22407090663909912
Batch 35/64 loss: 0.2112194299697876
Batch 36/64 loss: 0.2113351821899414
Batch 37/64 loss: 0.20869719982147217
Batch 38/64 loss: 0.20773309469223022
Batch 39/64 loss: 0.21441161632537842
Batch 40/64 loss: 0.22110193967819214
Batch 41/64 loss: 0.21295428276062012
Batch 42/64 loss: 0.2289474606513977
Batch 43/64 loss: 0.21300017833709717
Batch 44/64 loss: 0.20704233646392822
Batch 45/64 loss: 0.21789944171905518
Batch 46/64 loss: 0.21073389053344727
Batch 47/64 loss: 0.21790099143981934
Batch 48/64 loss: 0.215348482131958
Batch 49/64 loss: 0.21782469749450684
Batch 50/64 loss: 0.20860308408737183
Batch 51/64 loss: 0.22125858068466187
Batch 52/64 loss: 0.21264612674713135
Batch 53/64 loss: 0.21157586574554443
Batch 54/64 loss: 0.23423320055007935
Batch 55/64 loss: 0.20025551319122314
Batch 56/64 loss: 0.22193175554275513
Batch 57/64 loss: 0.21498912572860718
Batch 58/64 loss: 0.21561604738235474
Batch 59/64 loss: 0.22391188144683838
Batch 60/64 loss: 0.21073931455612183
Batch 61/64 loss: 0.22017115354537964
Batch 62/64 loss: 0.21829617023468018
Batch 63/64 loss: 0.21223866939544678
Batch 64/64 loss: 0.21574890613555908
Epoch 286  Train loss: 0.21426540028815175  Val loss: 0.293427313521146
Epoch 287
-------------------------------
Batch 1/64 loss: 0.2341984510421753
Batch 2/64 loss: 0.20869332551956177
Batch 3/64 loss: 0.20812809467315674
Batch 4/64 loss: 0.20169717073440552
Batch 5/64 loss: 0.2205694317817688
Batch 6/64 loss: 0.20822441577911377
Batch 7/64 loss: 0.20330810546875
Batch 8/64 loss: 0.21095144748687744
Batch 9/64 loss: 0.20349407196044922
Batch 10/64 loss: 0.21421188116073608
Batch 11/64 loss: 0.2197243571281433
Batch 12/64 loss: 0.21968454122543335
Batch 13/64 loss: 0.21206462383270264
Batch 14/64 loss: 0.2204892635345459
Batch 15/64 loss: 0.22992348670959473
Batch 16/64 loss: 0.21847319602966309
Batch 17/64 loss: 0.2183104157447815
Batch 18/64 loss: 0.21945726871490479
Batch 19/64 loss: 0.21510404348373413
Batch 20/64 loss: 0.23067975044250488
Batch 21/64 loss: 0.20363599061965942
Batch 22/64 loss: 0.2256711721420288
Batch 23/64 loss: 0.21043169498443604
Batch 24/64 loss: 0.21415138244628906
Batch 25/64 loss: 0.22045505046844482
Batch 26/64 loss: 0.22304511070251465
Batch 27/64 loss: 0.21407246589660645
Batch 28/64 loss: 0.22244179248809814
Batch 29/64 loss: 0.2146039605140686
Batch 30/64 loss: 0.21598374843597412
Batch 31/64 loss: 0.21037709712982178
Batch 32/64 loss: 0.20434999465942383
Batch 33/64 loss: 0.21939051151275635
Batch 34/64 loss: 0.22679710388183594
Batch 35/64 loss: 0.21089041233062744
Batch 36/64 loss: 0.20873379707336426
Batch 37/64 loss: 0.21608710289001465
Batch 38/64 loss: 0.21480852365493774
Batch 39/64 loss: 0.21812033653259277
Batch 40/64 loss: 0.21428179740905762
Batch 41/64 loss: 0.21990913152694702
Batch 42/64 loss: 0.20832884311676025
Batch 43/64 loss: 0.21496301889419556
Batch 44/64 loss: 0.2069258689880371
Batch 45/64 loss: 0.2064768671989441
Batch 46/64 loss: 0.21378469467163086
Batch 47/64 loss: 0.21933197975158691
Batch 48/64 loss: 0.21563249826431274
Batch 49/64 loss: 0.21233797073364258
Batch 50/64 loss: 0.2187572717666626
Batch 51/64 loss: 0.20796680450439453
Batch 52/64 loss: 0.21497976779937744
Batch 53/64 loss: 0.20128929615020752
Batch 54/64 loss: 0.22532474994659424
Batch 55/64 loss: 0.22029036283493042
Batch 56/64 loss: 0.21715080738067627
Batch 57/64 loss: 0.21814477443695068
Batch 58/64 loss: 0.21931898593902588
Batch 59/64 loss: 0.20889055728912354
Batch 60/64 loss: 0.21821081638336182
Batch 61/64 loss: 0.21558743715286255
Batch 62/64 loss: 0.21277201175689697
Batch 63/64 loss: 0.20665931701660156
Batch 64/64 loss: 0.22398144006729126
Epoch 287  Train loss: 0.21516449100830976  Val loss: 0.2951127241567238
Epoch 288
-------------------------------
Batch 1/64 loss: 0.2159513235092163
Batch 2/64 loss: 0.2131374478340149
Batch 3/64 loss: 0.213567852973938
Batch 4/64 loss: 0.21160882711410522
Batch 5/64 loss: 0.20947372913360596
Batch 6/64 loss: 0.21574366092681885
Batch 7/64 loss: 0.2104315161705017
Batch 8/64 loss: 0.21252304315567017
Batch 9/64 loss: 0.20476514101028442
Batch 10/64 loss: 0.2116302251815796
Batch 11/64 loss: 0.21253538131713867
Batch 12/64 loss: 0.21262633800506592
Batch 13/64 loss: 0.21359658241271973
Batch 14/64 loss: 0.20934152603149414
Batch 15/64 loss: 0.20663917064666748
Batch 16/64 loss: 0.217820942401886
Batch 17/64 loss: 0.20744842290878296
Batch 18/64 loss: 0.20782506465911865
Batch 19/64 loss: 0.21545910835266113
Batch 20/64 loss: 0.22409522533416748
Batch 21/64 loss: 0.21731293201446533
Batch 22/64 loss: 0.2103797197341919
Batch 23/64 loss: 0.21225988864898682
Batch 24/64 loss: 0.2153242826461792
Batch 25/64 loss: 0.20477914810180664
Batch 26/64 loss: 0.2196788787841797
Batch 27/64 loss: 0.20613598823547363
Batch 28/64 loss: 0.2109062671661377
Batch 29/64 loss: 0.2128303050994873
Batch 30/64 loss: 0.2052876353263855
Batch 31/64 loss: 0.21098363399505615
Batch 32/64 loss: 0.21075737476348877
Batch 33/64 loss: 0.20947301387786865
Batch 34/64 loss: 0.21317487955093384
Batch 35/64 loss: 0.21169400215148926
Batch 36/64 loss: 0.20856928825378418
Batch 37/64 loss: 0.20567071437835693
Batch 38/64 loss: 0.21528995037078857
Batch 39/64 loss: 0.21104085445404053
Batch 40/64 loss: 0.21796083450317383
Batch 41/64 loss: 0.21047520637512207
Batch 42/64 loss: 0.214150071144104
Batch 43/64 loss: 0.22569876909255981
Batch 44/64 loss: 0.20525550842285156
Batch 45/64 loss: 0.22947263717651367
Batch 46/64 loss: 0.2111634612083435
Batch 47/64 loss: 0.21273165941238403
Batch 48/64 loss: 0.21582448482513428
Batch 49/64 loss: 0.21611517667770386
Batch 50/64 loss: 0.220944344997406
Batch 51/64 loss: 0.2157840132713318
Batch 52/64 loss: 0.21165251731872559
Batch 53/64 loss: 0.2131410837173462
Batch 54/64 loss: 0.2116018533706665
Batch 55/64 loss: 0.2061251401901245
Batch 56/64 loss: 0.21611738204956055
Batch 57/64 loss: 0.22318249940872192
Batch 58/64 loss: 0.22027587890625
Batch 59/64 loss: 0.21286380290985107
Batch 60/64 loss: 0.22120124101638794
Batch 61/64 loss: 0.21487343311309814
Batch 62/64 loss: 0.21821266412734985
Batch 63/64 loss: 0.22387993335723877
Batch 64/64 loss: 0.23044776916503906
Epoch 288  Train loss: 0.21363621506036495  Val loss: 0.2941720213267402
Epoch 289
-------------------------------
Batch 1/64 loss: 0.21318650245666504
Batch 2/64 loss: 0.2111208438873291
Batch 3/64 loss: 0.21969354152679443
Batch 4/64 loss: 0.21773725748062134
Batch 5/64 loss: 0.21547257900238037
Batch 6/64 loss: 0.21639156341552734
Batch 7/64 loss: 0.2088717818260193
Batch 8/64 loss: 0.23510801792144775
Batch 9/64 loss: 0.22091567516326904
Batch 10/64 loss: 0.21127939224243164
Batch 11/64 loss: 0.21645212173461914
Batch 12/64 loss: 0.20623892545700073
Batch 13/64 loss: 0.215326189994812
Batch 14/64 loss: 0.21015828847885132
Batch 15/64 loss: 0.21240174770355225
Batch 16/64 loss: 0.217678964138031
Batch 17/64 loss: 0.21440547704696655
Batch 18/64 loss: 0.20595204830169678
Batch 19/64 loss: 0.19993388652801514
Batch 20/64 loss: 0.20020806789398193
Batch 21/64 loss: 0.22251510620117188
Batch 22/64 loss: 0.23165678977966309
Batch 23/64 loss: 0.21008694171905518
Batch 24/64 loss: 0.21121668815612793
Batch 25/64 loss: 0.2221347689628601
Batch 26/64 loss: 0.20713472366333008
Batch 27/64 loss: 0.20207983255386353
Batch 28/64 loss: 0.20603537559509277
Batch 29/64 loss: 0.21336984634399414
Batch 30/64 loss: 0.2239115834236145
Batch 31/64 loss: 0.2150755524635315
Batch 32/64 loss: 0.21460622549057007
Batch 33/64 loss: 0.21663439273834229
Batch 34/64 loss: 0.21337890625
Batch 35/64 loss: 0.2061518430709839
Batch 36/64 loss: 0.21949899196624756
Batch 37/64 loss: 0.21994423866271973
Batch 38/64 loss: 0.22094273567199707
Batch 39/64 loss: 0.2153337001800537
Batch 40/64 loss: 0.2118765115737915
Batch 41/64 loss: 0.20863419771194458
Batch 42/64 loss: 0.213187575340271
Batch 43/64 loss: 0.21907544136047363
Batch 44/64 loss: 0.20886772871017456
Batch 45/64 loss: 0.21469277143478394
Batch 46/64 loss: 0.2069615125656128
Batch 47/64 loss: 0.2209622859954834
Batch 48/64 loss: 0.23363983631134033
Batch 49/64 loss: 0.20726144313812256
Batch 50/64 loss: 0.20443511009216309
Batch 51/64 loss: 0.2036150097846985
Batch 52/64 loss: 0.20934981107711792
Batch 53/64 loss: 0.22168177366256714
Batch 54/64 loss: 0.2048792839050293
Batch 55/64 loss: 0.2260352373123169
Batch 56/64 loss: 0.2175503373146057
Batch 57/64 loss: 0.22109651565551758
Batch 58/64 loss: 0.21490734815597534
Batch 59/64 loss: 0.2035989761352539
Batch 60/64 loss: 0.21222913265228271
Batch 61/64 loss: 0.2071397304534912
Batch 62/64 loss: 0.21088731288909912
Batch 63/64 loss: 0.2219301462173462
Batch 64/64 loss: 0.22469687461853027
Epoch 289  Train loss: 0.21416876549814262  Val loss: 0.29330650494270716
Epoch 290
-------------------------------
Batch 1/64 loss: 0.2126157283782959
Batch 2/64 loss: 0.21404564380645752
Batch 3/64 loss: 0.22461366653442383
Batch 4/64 loss: 0.20807194709777832
Batch 5/64 loss: 0.20664751529693604
Batch 6/64 loss: 0.2129133939743042
Batch 7/64 loss: 0.20660710334777832
Batch 8/64 loss: 0.20583128929138184
Batch 9/64 loss: 0.20235538482666016
Batch 10/64 loss: 0.2210538387298584
Batch 11/64 loss: 0.21526610851287842
Batch 12/64 loss: 0.20296823978424072
Batch 13/64 loss: 0.2182140350341797
Batch 14/64 loss: 0.21156257390975952
Batch 15/64 loss: 0.20724785327911377
Batch 16/64 loss: 0.22078019380569458
Batch 17/64 loss: 0.2072771191596985
Batch 18/64 loss: 0.20693516731262207
Batch 19/64 loss: 0.21155834197998047
Batch 20/64 loss: 0.20129740238189697
Batch 21/64 loss: 0.2068766951560974
Batch 22/64 loss: 0.22217702865600586
Batch 23/64 loss: 0.20765960216522217
Batch 24/64 loss: 0.20491892099380493
Batch 25/64 loss: 0.21454977989196777
Batch 26/64 loss: 0.21396279335021973
Batch 27/64 loss: 0.21687376499176025
Batch 28/64 loss: 0.22180479764938354
Batch 29/64 loss: 0.2096763253211975
Batch 30/64 loss: 0.20996898412704468
Batch 31/64 loss: 0.21095269918441772
Batch 32/64 loss: 0.21305382251739502
Batch 33/64 loss: 0.22466599941253662
Batch 34/64 loss: 0.2226930856704712
Batch 35/64 loss: 0.2111535668373108
Batch 36/64 loss: 0.22060948610305786
Batch 37/64 loss: 0.21676743030548096
Batch 38/64 loss: 0.2196817398071289
Batch 39/64 loss: 0.2106035351753235
Batch 40/64 loss: 0.22341597080230713
Batch 41/64 loss: 0.20815539360046387
Batch 42/64 loss: 0.21737957000732422
Batch 43/64 loss: 0.2172074317932129
Batch 44/64 loss: 0.21363979578018188
Batch 45/64 loss: 0.2107851505279541
Batch 46/64 loss: 0.21720707416534424
Batch 47/64 loss: 0.20801234245300293
Batch 48/64 loss: 0.2053409218788147
Batch 49/64 loss: 0.21367818117141724
Batch 50/64 loss: 0.2188076376914978
Batch 51/64 loss: 0.22231853008270264
Batch 52/64 loss: 0.22165316343307495
Batch 53/64 loss: 0.21555203199386597
Batch 54/64 loss: 0.19933712482452393
Batch 55/64 loss: 0.21264076232910156
Batch 56/64 loss: 0.2320491075515747
Batch 57/64 loss: 0.21550190448760986
Batch 58/64 loss: 0.21470248699188232
Batch 59/64 loss: 0.20753908157348633
Batch 60/64 loss: 0.22343695163726807
Batch 61/64 loss: 0.20836222171783447
Batch 62/64 loss: 0.2188456654548645
Batch 63/64 loss: 0.2165130376815796
Batch 64/64 loss: 0.22702044248580933
Epoch 290  Train loss: 0.21378603098439236  Val loss: 0.2945377060637851
Epoch 291
-------------------------------
Batch 1/64 loss: 0.21868032217025757
Batch 2/64 loss: 0.21002066135406494
Batch 3/64 loss: 0.2079145312309265
Batch 4/64 loss: 0.21423029899597168
Batch 5/64 loss: 0.201765239238739
Batch 6/64 loss: 0.2169896364212036
Batch 7/64 loss: 0.2194482684135437
Batch 8/64 loss: 0.2154933214187622
Batch 9/64 loss: 0.2021414041519165
Batch 10/64 loss: 0.21049517393112183
Batch 11/64 loss: 0.23360979557037354
Batch 12/64 loss: 0.2264324426651001
Batch 13/64 loss: 0.2236396074295044
Batch 14/64 loss: 0.21994060277938843
Batch 15/64 loss: 0.22151249647140503
Batch 16/64 loss: 0.20493489503860474
Batch 17/64 loss: 0.2176971435546875
Batch 18/64 loss: 0.21127855777740479
Batch 19/64 loss: 0.21476399898529053
Batch 20/64 loss: 0.2207266092300415
Batch 21/64 loss: 0.2058107852935791
Batch 22/64 loss: 0.21774017810821533
Batch 23/64 loss: 0.21850436925888062
Batch 24/64 loss: 0.21342337131500244
Batch 25/64 loss: 0.2032366394996643
Batch 26/64 loss: 0.20484459400177002
Batch 27/64 loss: 0.20920372009277344
Batch 28/64 loss: 0.2089531421661377
Batch 29/64 loss: 0.21620070934295654
Batch 30/64 loss: 0.21703195571899414
Batch 31/64 loss: 0.21552157402038574
Batch 32/64 loss: 0.21020978689193726
Batch 33/64 loss: 0.22311389446258545
Batch 34/64 loss: 0.2097843885421753
Batch 35/64 loss: 0.20375490188598633
Batch 36/64 loss: 0.2052534818649292
Batch 37/64 loss: 0.21544480323791504
Batch 38/64 loss: 0.2299622893333435
Batch 39/64 loss: 0.2185910940170288
Batch 40/64 loss: 0.21490395069122314
Batch 41/64 loss: 0.2122228741645813
Batch 42/64 loss: 0.21069175004959106
Batch 43/64 loss: 0.2118607759475708
Batch 44/64 loss: 0.2049119472503662
Batch 45/64 loss: 0.21156084537506104
Batch 46/64 loss: 0.21516871452331543
Batch 47/64 loss: 0.21023321151733398
Batch 48/64 loss: 0.2108597755432129
Batch 49/64 loss: 0.2116614580154419
Batch 50/64 loss: 0.21891093254089355
Batch 51/64 loss: 0.21718233823776245
Batch 52/64 loss: 0.20972847938537598
Batch 53/64 loss: 0.2169269323348999
Batch 54/64 loss: 0.21765899658203125
Batch 55/64 loss: 0.20794594287872314
Batch 56/64 loss: 0.21808308362960815
Batch 57/64 loss: 0.21430444717407227
Batch 58/64 loss: 0.2184009552001953
Batch 59/64 loss: 0.2096794843673706
Batch 60/64 loss: 0.22463220357894897
Batch 61/64 loss: 0.2138962745666504
Batch 62/64 loss: 0.21474206447601318
Batch 63/64 loss: 0.2044757604598999
Batch 64/64 loss: 0.21131819486618042
Epoch 291  Train loss: 0.21392051028270348  Val loss: 0.2941587174061647
Epoch 292
-------------------------------
Batch 1/64 loss: 0.20677721500396729
Batch 2/64 loss: 0.2093038558959961
Batch 3/64 loss: 0.20280468463897705
Batch 4/64 loss: 0.2058587670326233
Batch 5/64 loss: 0.20648330450057983
Batch 6/64 loss: 0.21274292469024658
Batch 7/64 loss: 0.21145713329315186
Batch 8/64 loss: 0.21525192260742188
Batch 9/64 loss: 0.23531198501586914
Batch 10/64 loss: 0.21066522598266602
Batch 11/64 loss: 0.21272766590118408
Batch 12/64 loss: 0.21447378396987915
Batch 13/64 loss: 0.2081845998764038
Batch 14/64 loss: 0.2105921506881714
Batch 15/64 loss: 0.20439893007278442
Batch 16/64 loss: 0.21217340230941772
Batch 17/64 loss: 0.20024001598358154
Batch 18/64 loss: 0.20946598052978516
Batch 19/64 loss: 0.21811270713806152
Batch 20/64 loss: 0.22338777780532837
Batch 21/64 loss: 0.20826882123947144
Batch 22/64 loss: 0.22073990106582642
Batch 23/64 loss: 0.21110665798187256
Batch 24/64 loss: 0.21306341886520386
Batch 25/64 loss: 0.21527355909347534
Batch 26/64 loss: 0.22698771953582764
Batch 27/64 loss: 0.21622484922409058
Batch 28/64 loss: 0.2098308801651001
Batch 29/64 loss: 0.2136775255203247
Batch 30/64 loss: 0.22104787826538086
Batch 31/64 loss: 0.20975089073181152
Batch 32/64 loss: 0.20963174104690552
Batch 33/64 loss: 0.22102928161621094
Batch 34/64 loss: 0.2133256196975708
Batch 35/64 loss: 0.21131861209869385
Batch 36/64 loss: 0.22935199737548828
Batch 37/64 loss: 0.21433216333389282
Batch 38/64 loss: 0.21143853664398193
Batch 39/64 loss: 0.2304292917251587
Batch 40/64 loss: 0.2075570821762085
Batch 41/64 loss: 0.21535611152648926
Batch 42/64 loss: 0.22537344694137573
Batch 43/64 loss: 0.21622323989868164
Batch 44/64 loss: 0.20931506156921387
Batch 45/64 loss: 0.23948681354522705
Batch 46/64 loss: 0.20850086212158203
Batch 47/64 loss: 0.21047598123550415
Batch 48/64 loss: 0.2087327241897583
Batch 49/64 loss: 0.20699548721313477
Batch 50/64 loss: 0.20737487077713013
Batch 51/64 loss: 0.21700209379196167
Batch 52/64 loss: 0.2110486626625061
Batch 53/64 loss: 0.21151769161224365
Batch 54/64 loss: 0.20505225658416748
Batch 55/64 loss: 0.2299061417579651
Batch 56/64 loss: 0.2043241262435913
Batch 57/64 loss: 0.2131834626197815
Batch 58/64 loss: 0.21542221307754517
Batch 59/64 loss: 0.21658366918563843
Batch 60/64 loss: 0.21294182538986206
Batch 61/64 loss: 0.21555709838867188
Batch 62/64 loss: 0.22107326984405518
Batch 63/64 loss: 0.2076345682144165
Batch 64/64 loss: 0.22111111879348755
Epoch 292  Train loss: 0.21395632122077193  Val loss: 0.29459929138524427
Epoch 293
-------------------------------
Batch 1/64 loss: 0.20718050003051758
Batch 2/64 loss: 0.21622443199157715
Batch 3/64 loss: 0.21745377779006958
Batch 4/64 loss: 0.20867472887039185
Batch 5/64 loss: 0.2071496844291687
Batch 6/64 loss: 0.20489847660064697
Batch 7/64 loss: 0.21003371477127075
Batch 8/64 loss: 0.2143077850341797
Batch 9/64 loss: 0.21209514141082764
Batch 10/64 loss: 0.22375309467315674
Batch 11/64 loss: 0.2167344093322754
Batch 12/64 loss: 0.2146032452583313
Batch 13/64 loss: 0.2087026834487915
Batch 14/64 loss: 0.21625971794128418
Batch 15/64 loss: 0.2080831527709961
Batch 16/64 loss: 0.2115257978439331
Batch 17/64 loss: 0.2168523073196411
Batch 18/64 loss: 0.20226681232452393
Batch 19/64 loss: 0.21215617656707764
Batch 20/64 loss: 0.20805972814559937
Batch 21/64 loss: 0.20601481199264526
Batch 22/64 loss: 0.2114449143409729
Batch 23/64 loss: 0.20703405141830444
Batch 24/64 loss: 0.20727360248565674
Batch 25/64 loss: 0.22447800636291504
Batch 26/64 loss: 0.20781368017196655
Batch 27/64 loss: 0.21187692880630493
Batch 28/64 loss: 0.23158133029937744
Batch 29/64 loss: 0.20469635725021362
Batch 30/64 loss: 0.21382927894592285
Batch 31/64 loss: 0.2093905210494995
Batch 32/64 loss: 0.21139895915985107
Batch 33/64 loss: 0.22339606285095215
Batch 34/64 loss: 0.23482489585876465
Batch 35/64 loss: 0.21779769659042358
Batch 36/64 loss: 0.21936333179473877
Batch 37/64 loss: 0.224132239818573
Batch 38/64 loss: 0.20967507362365723
Batch 39/64 loss: 0.21814179420471191
Batch 40/64 loss: 0.21651983261108398
Batch 41/64 loss: 0.21938812732696533
Batch 42/64 loss: 0.2112787365913391
Batch 43/64 loss: 0.2080426812171936
Batch 44/64 loss: 0.21403121948242188
Batch 45/64 loss: 0.2377389669418335
Batch 46/64 loss: 0.21027004718780518
Batch 47/64 loss: 0.21417593955993652
Batch 48/64 loss: 0.21190118789672852
Batch 49/64 loss: 0.21519851684570312
Batch 50/64 loss: 0.21287882328033447
Batch 51/64 loss: 0.21586573123931885
Batch 52/64 loss: 0.2044937014579773
Batch 53/64 loss: 0.22143149375915527
Batch 54/64 loss: 0.22005999088287354
Batch 55/64 loss: 0.21813273429870605
Batch 56/64 loss: 0.2130090594291687
Batch 57/64 loss: 0.21717339754104614
Batch 58/64 loss: 0.2123255729675293
Batch 59/64 loss: 0.19918978214263916
Batch 60/64 loss: 0.22384613752365112
Batch 61/64 loss: 0.21261000633239746
Batch 62/64 loss: 0.20135605335235596
Batch 63/64 loss: 0.2112884521484375
Batch 64/64 loss: 0.20980346202850342
Epoch 293  Train loss: 0.21381549320968926  Val loss: 0.29388710702817467
Epoch 294
-------------------------------
Batch 1/64 loss: 0.2146855592727661
Batch 2/64 loss: 0.20066815614700317
Batch 3/64 loss: 0.20700544118881226
Batch 4/64 loss: 0.2261519432067871
Batch 5/64 loss: 0.215894877910614
Batch 6/64 loss: 0.211839497089386
Batch 7/64 loss: 0.20382016897201538
Batch 8/64 loss: 0.20627760887145996
Batch 9/64 loss: 0.2059926986694336
Batch 10/64 loss: 0.21563076972961426
Batch 11/64 loss: 0.22297132015228271
Batch 12/64 loss: 0.207800030708313
Batch 13/64 loss: 0.21799707412719727
Batch 14/64 loss: 0.22013401985168457
Batch 15/64 loss: 0.20194125175476074
Batch 16/64 loss: 0.21540743112564087
Batch 17/64 loss: 0.2105928659439087
Batch 18/64 loss: 0.21880489587783813
Batch 19/64 loss: 0.2106296420097351
Batch 20/64 loss: 0.205191969871521
Batch 21/64 loss: 0.20846271514892578
Batch 22/64 loss: 0.20921224355697632
Batch 23/64 loss: 0.20795053243637085
Batch 24/64 loss: 0.21396148204803467
Batch 25/64 loss: 0.21427738666534424
Batch 26/64 loss: 0.22347521781921387
Batch 27/64 loss: 0.21202409267425537
Batch 28/64 loss: 0.21334397792816162
Batch 29/64 loss: 0.21454107761383057
Batch 30/64 loss: 0.21112394332885742
Batch 31/64 loss: 0.2200840711593628
Batch 32/64 loss: 0.22136247158050537
Batch 33/64 loss: 0.20920294523239136
Batch 34/64 loss: 0.2159334421157837
Batch 35/64 loss: 0.21806257963180542
Batch 36/64 loss: 0.20730692148208618
Batch 37/64 loss: 0.20790302753448486
Batch 38/64 loss: 0.21425461769104004
Batch 39/64 loss: 0.20502829551696777
Batch 40/64 loss: 0.22004938125610352
Batch 41/64 loss: 0.20541679859161377
Batch 42/64 loss: 0.20115500688552856
Batch 43/64 loss: 0.21317505836486816
Batch 44/64 loss: 0.20918655395507812
Batch 45/64 loss: 0.2216368317604065
Batch 46/64 loss: 0.2085726261138916
Batch 47/64 loss: 0.22280657291412354
Batch 48/64 loss: 0.20667821168899536
Batch 49/64 loss: 0.20977449417114258
Batch 50/64 loss: 0.214089035987854
Batch 51/64 loss: 0.23057317733764648
Batch 52/64 loss: 0.21344172954559326
Batch 53/64 loss: 0.2147446870803833
Batch 54/64 loss: 0.20117294788360596
Batch 55/64 loss: 0.20335543155670166
Batch 56/64 loss: 0.204767107963562
Batch 57/64 loss: 0.21495532989501953
Batch 58/64 loss: 0.22287297248840332
Batch 59/64 loss: 0.21024221181869507
Batch 60/64 loss: 0.20805609226226807
Batch 61/64 loss: 0.21617209911346436
Batch 62/64 loss: 0.22641313076019287
Batch 63/64 loss: 0.21793556213378906
Batch 64/64 loss: 0.21125680208206177
Epoch 294  Train loss: 0.21274719869389253  Val loss: 0.2940833351456423
Epoch 295
-------------------------------
Batch 1/64 loss: 0.20222508907318115
Batch 2/64 loss: 0.20358169078826904
Batch 3/64 loss: 0.20085132122039795
Batch 4/64 loss: 0.21965771913528442
Batch 5/64 loss: 0.21802783012390137
Batch 6/64 loss: 0.20895087718963623
Batch 7/64 loss: 0.21886396408081055
Batch 8/64 loss: 0.21070373058319092
Batch 9/64 loss: 0.21199274063110352
Batch 10/64 loss: 0.21330106258392334
Batch 11/64 loss: 0.20665788650512695
Batch 12/64 loss: 0.21151304244995117
Batch 13/64 loss: 0.2040235996246338
Batch 14/64 loss: 0.21586894989013672
Batch 15/64 loss: 0.21564757823944092
Batch 16/64 loss: 0.21268486976623535
Batch 17/64 loss: 0.20987272262573242
Batch 18/64 loss: 0.2092236876487732
Batch 19/64 loss: 0.20792698860168457
Batch 20/64 loss: 0.2051687240600586
Batch 21/64 loss: 0.22012192010879517
Batch 22/64 loss: 0.2218528389930725
Batch 23/64 loss: 0.2014520764350891
Batch 24/64 loss: 0.2083510160446167
Batch 25/64 loss: 0.22375857830047607
Batch 26/64 loss: 0.19800782203674316
Batch 27/64 loss: 0.24339205026626587
Batch 28/64 loss: 0.21281999349594116
Batch 29/64 loss: 0.21131598949432373
Batch 30/64 loss: 0.21077412366867065
Batch 31/64 loss: 0.2121409773826599
Batch 32/64 loss: 0.20586591958999634
Batch 33/64 loss: 0.22701555490493774
Batch 34/64 loss: 0.21250510215759277
Batch 35/64 loss: 0.20656615495681763
Batch 36/64 loss: 0.22252410650253296
Batch 37/64 loss: 0.20762193202972412
Batch 38/64 loss: 0.20279979705810547
Batch 39/64 loss: 0.21118378639221191
Batch 40/64 loss: 0.2142040729522705
Batch 41/64 loss: 0.21653831005096436
Batch 42/64 loss: 0.210471510887146
Batch 43/64 loss: 0.21907776594161987
Batch 44/64 loss: 0.2228325605392456
Batch 45/64 loss: 0.2144775390625
Batch 46/64 loss: 0.21810543537139893
Batch 47/64 loss: 0.20992207527160645
Batch 48/64 loss: 0.2187836766242981
Batch 49/64 loss: 0.20948755741119385
Batch 50/64 loss: 0.2164028286933899
Batch 51/64 loss: 0.2122499942779541
Batch 52/64 loss: 0.21410077810287476
Batch 53/64 loss: 0.20456111431121826
Batch 54/64 loss: 0.2154926061630249
Batch 55/64 loss: 0.21153229475021362
Batch 56/64 loss: 0.20364910364151
Batch 57/64 loss: 0.2110501527786255
Batch 58/64 loss: 0.2087840437889099
Batch 59/64 loss: 0.21171408891677856
Batch 60/64 loss: 0.20747745037078857
Batch 61/64 loss: 0.21417367458343506
Batch 62/64 loss: 0.21158921718597412
Batch 63/64 loss: 0.2085704207420349
Batch 64/64 loss: 0.21399611234664917
Epoch 295  Train loss: 0.21227543798147464  Val loss: 0.29387861510732327
Epoch 296
-------------------------------
Batch 1/64 loss: 0.20353734493255615
Batch 2/64 loss: 0.21138358116149902
Batch 3/64 loss: 0.20291799306869507
Batch 4/64 loss: 0.20753085613250732
Batch 5/64 loss: 0.2228466272354126
Batch 6/64 loss: 0.2169729471206665
Batch 7/64 loss: 0.22018861770629883
Batch 8/64 loss: 0.20878207683563232
Batch 9/64 loss: 0.20222437381744385
Batch 10/64 loss: 0.21969753503799438
Batch 11/64 loss: 0.2137390375137329
Batch 12/64 loss: 0.22288298606872559
Batch 13/64 loss: 0.20722031593322754
Batch 14/64 loss: 0.20944452285766602
Batch 15/64 loss: 0.21026170253753662
Batch 16/64 loss: 0.2058253288269043
Batch 17/64 loss: 0.22366666793823242
Batch 18/64 loss: 0.2059462070465088
Batch 19/64 loss: 0.20521581172943115
Batch 20/64 loss: 0.20527172088623047
Batch 21/64 loss: 0.21425187587738037
Batch 22/64 loss: 0.21559369564056396
Batch 23/64 loss: 0.22129440307617188
Batch 24/64 loss: 0.21858620643615723
Batch 25/64 loss: 0.2105962038040161
Batch 26/64 loss: 0.21602463722229004
Batch 27/64 loss: 0.20939403772354126
Batch 28/64 loss: 0.21567022800445557
Batch 29/64 loss: 0.2196277379989624
Batch 30/64 loss: 0.2134498953819275
Batch 31/64 loss: 0.21178245544433594
Batch 32/64 loss: 0.21058142185211182
Batch 33/64 loss: 0.20574331283569336
Batch 34/64 loss: 0.22928375005722046
Batch 35/64 loss: 0.21049761772155762
Batch 36/64 loss: 0.20907843112945557
Batch 37/64 loss: 0.21371734142303467
Batch 38/64 loss: 0.21270596981048584
Batch 39/64 loss: 0.2136041522026062
Batch 40/64 loss: 0.20415937900543213
Batch 41/64 loss: 0.21330785751342773
Batch 42/64 loss: 0.20887446403503418
Batch 43/64 loss: 0.2051239013671875
Batch 44/64 loss: 0.20556199550628662
Batch 45/64 loss: 0.22370082139968872
Batch 46/64 loss: 0.22060281038284302
Batch 47/64 loss: 0.21243596076965332
Batch 48/64 loss: 0.21334320306777954
Batch 49/64 loss: 0.20478802919387817
Batch 50/64 loss: 0.2195647954940796
Batch 51/64 loss: 0.2018367052078247
Batch 52/64 loss: 0.22222131490707397
Batch 53/64 loss: 0.2074878215789795
Batch 54/64 loss: 0.21831095218658447
Batch 55/64 loss: 0.2106781005859375
Batch 56/64 loss: 0.2087322473526001
Batch 57/64 loss: 0.21845120191574097
Batch 58/64 loss: 0.20655041933059692
Batch 59/64 loss: 0.2153170108795166
Batch 60/64 loss: 0.21334898471832275
Batch 61/64 loss: 0.20511996746063232
Batch 62/64 loss: 0.2101048231124878
Batch 63/64 loss: 0.20591312646865845
Batch 64/64 loss: 0.2234325408935547
Epoch 296  Train loss: 0.21239450866100834  Val loss: 0.2945662605803447
Epoch 297
-------------------------------
Batch 1/64 loss: 0.2109161615371704
Batch 2/64 loss: 0.22036737203598022
Batch 3/64 loss: 0.22804462909698486
Batch 4/64 loss: 0.212962806224823
Batch 5/64 loss: 0.21784722805023193
Batch 6/64 loss: 0.21314597129821777
Batch 7/64 loss: 0.20588505268096924
Batch 8/64 loss: 0.20871102809906006
Batch 9/64 loss: 0.2166062593460083
Batch 10/64 loss: 0.21269965171813965
Batch 11/64 loss: 0.2048734426498413
Batch 12/64 loss: 0.21288776397705078
Batch 13/64 loss: 0.21107059717178345
Batch 14/64 loss: 0.22606432437896729
Batch 15/64 loss: 0.21714353561401367
Batch 16/64 loss: 0.20496320724487305
Batch 17/64 loss: 0.2034066915512085
Batch 18/64 loss: 0.21534955501556396
Batch 19/64 loss: 0.2029598355293274
Batch 20/64 loss: 0.2114754319190979
Batch 21/64 loss: 0.219437837600708
Batch 22/64 loss: 0.2084484100341797
Batch 23/64 loss: 0.2074425220489502
Batch 24/64 loss: 0.21691900491714478
Batch 25/64 loss: 0.21963661909103394
Batch 26/64 loss: 0.22252070903778076
Batch 27/64 loss: 0.2217470407485962
Batch 28/64 loss: 0.21075904369354248
Batch 29/64 loss: 0.2117118239402771
Batch 30/64 loss: 0.20030325651168823
Batch 31/64 loss: 0.21939235925674438
Batch 32/64 loss: 0.21612310409545898
Batch 33/64 loss: 0.21145963668823242
Batch 34/64 loss: 0.20227396488189697
Batch 35/64 loss: 0.20432829856872559
Batch 36/64 loss: 0.20277881622314453
Batch 37/64 loss: 0.21897971630096436
Batch 38/64 loss: 0.20731377601623535
Batch 39/64 loss: 0.20450758934020996
Batch 40/64 loss: 0.21180397272109985
Batch 41/64 loss: 0.2175397276878357
Batch 42/64 loss: 0.2150263786315918
Batch 43/64 loss: 0.2221086025238037
Batch 44/64 loss: 0.21498394012451172
Batch 45/64 loss: 0.21104967594146729
Batch 46/64 loss: 0.22798097133636475
Batch 47/64 loss: 0.2166222333908081
Batch 48/64 loss: 0.2049189805984497
Batch 49/64 loss: 0.20812588930130005
Batch 50/64 loss: 0.21137785911560059
Batch 51/64 loss: 0.2230548858642578
Batch 52/64 loss: 0.21066772937774658
Batch 53/64 loss: 0.20500969886779785
Batch 54/64 loss: 0.20433509349822998
Batch 55/64 loss: 0.2092745304107666
Batch 56/64 loss: 0.21232843399047852
Batch 57/64 loss: 0.21583276987075806
Batch 58/64 loss: 0.20501220226287842
Batch 59/64 loss: 0.2163940668106079
Batch 60/64 loss: 0.21593010425567627
Batch 61/64 loss: 0.2189551591873169
Batch 62/64 loss: 0.22269141674041748
Batch 63/64 loss: 0.21366465091705322
Batch 64/64 loss: 0.20424103736877441
Epoch 297  Train loss: 0.21288366785236434  Val loss: 0.29526930699233744
Epoch 298
-------------------------------
Batch 1/64 loss: 0.22118335962295532
Batch 2/64 loss: 0.21307027339935303
Batch 3/64 loss: 0.20601606369018555
Batch 4/64 loss: 0.2095872163772583
Batch 5/64 loss: 0.21787995100021362
Batch 6/64 loss: 0.20728164911270142
Batch 7/64 loss: 0.21572840213775635
Batch 8/64 loss: 0.20830285549163818
Batch 9/64 loss: 0.20782452821731567
Batch 10/64 loss: 0.20738661289215088
Batch 11/64 loss: 0.20638537406921387
Batch 12/64 loss: 0.21287190914154053
Batch 13/64 loss: 0.2190549373626709
Batch 14/64 loss: 0.20490968227386475
Batch 15/64 loss: 0.2061428427696228
Batch 16/64 loss: 0.20913398265838623
Batch 17/64 loss: 0.21465539932250977
Batch 18/64 loss: 0.20839601755142212
Batch 19/64 loss: 0.2082526683807373
Batch 20/64 loss: 0.21927565336227417
Batch 21/64 loss: 0.22524845600128174
Batch 22/64 loss: 0.2199035882949829
Batch 23/64 loss: 0.2223256230354309
Batch 24/64 loss: 0.20808088779449463
Batch 25/64 loss: 0.2060929536819458
Batch 26/64 loss: 0.20408964157104492
Batch 27/64 loss: 0.20623016357421875
Batch 28/64 loss: 0.21969228982925415
Batch 29/64 loss: 0.2083154320716858
Batch 30/64 loss: 0.22141551971435547
Batch 31/64 loss: 0.20749902725219727
Batch 32/64 loss: 0.2106839418411255
Batch 33/64 loss: 0.2191694974899292
Batch 34/64 loss: 0.20626580715179443
Batch 35/64 loss: 0.21557211875915527
Batch 36/64 loss: 0.2055048942565918
Batch 37/64 loss: 0.21379977464675903
Batch 38/64 loss: 0.20360851287841797
Batch 39/64 loss: 0.2085510492324829
Batch 40/64 loss: 0.21306568384170532
Batch 41/64 loss: 0.22125160694122314
Batch 42/64 loss: 0.21337151527404785
Batch 43/64 loss: 0.21999263763427734
Batch 44/64 loss: 0.21128183603286743
Batch 45/64 loss: 0.2209916114807129
Batch 46/64 loss: 0.21637022495269775
Batch 47/64 loss: 0.21817994117736816
Batch 48/64 loss: 0.20766860246658325
Batch 49/64 loss: 0.20906567573547363
Batch 50/64 loss: 0.22119146585464478
Batch 51/64 loss: 0.2072499394416809
Batch 52/64 loss: 0.2142682671546936
Batch 53/64 loss: 0.21504449844360352
Batch 54/64 loss: 0.20244282484054565
Batch 55/64 loss: 0.21290123462677002
Batch 56/64 loss: 0.20939671993255615
Batch 57/64 loss: 0.21274662017822266
Batch 58/64 loss: 0.2114931344985962
Batch 59/64 loss: 0.21706807613372803
Batch 60/64 loss: 0.2251453399658203
Batch 61/64 loss: 0.21858346462249756
Batch 62/64 loss: 0.21692132949829102
Batch 63/64 loss: 0.22945141792297363
Batch 64/64 loss: 0.21704065799713135
Epoch 298  Train loss: 0.21307157207937802  Val loss: 0.2939199872852601
Epoch 299
-------------------------------
Batch 1/64 loss: 0.20521849393844604
Batch 2/64 loss: 0.21086567640304565
Batch 3/64 loss: 0.22046393156051636
Batch 4/64 loss: 0.20482099056243896
Batch 5/64 loss: 0.21059578657150269
Batch 6/64 loss: 0.2185429334640503
Batch 7/64 loss: 0.21107441186904907
Batch 8/64 loss: 0.2089090347290039
Batch 9/64 loss: 0.21193146705627441
Batch 10/64 loss: 0.2044287919998169
Batch 11/64 loss: 0.206745445728302
Batch 12/64 loss: 0.2224254608154297
Batch 13/64 loss: 0.23748230934143066
Batch 14/64 loss: 0.21254587173461914
Batch 15/64 loss: 0.21086382865905762
Batch 16/64 loss: 0.20792782306671143
Batch 17/64 loss: 0.20434629917144775
Batch 18/64 loss: 0.2043834924697876
Batch 19/64 loss: 0.2164953351020813
Batch 20/64 loss: 0.20134389400482178
Batch 21/64 loss: 0.21892529726028442
Batch 22/64 loss: 0.20712530612945557
Batch 23/64 loss: 0.2091715931892395
Batch 24/64 loss: 0.2129601240158081
Batch 25/64 loss: 0.21442443132400513
Batch 26/64 loss: 0.21236813068389893
Batch 27/64 loss: 0.19966769218444824
Batch 28/64 loss: 0.20752298831939697
Batch 29/64 loss: 0.21063554286956787
Batch 30/64 loss: 0.21328115463256836
Batch 31/64 loss: 0.21743106842041016
Batch 32/64 loss: 0.2099856734275818
Batch 33/64 loss: 0.21535474061965942
Batch 34/64 loss: 0.21558266878128052
Batch 35/64 loss: 0.21496152877807617
Batch 36/64 loss: 0.20273101329803467
Batch 37/64 loss: 0.20468783378601074
Batch 38/64 loss: 0.21207797527313232
Batch 39/64 loss: 0.2141563892364502
Batch 40/64 loss: 0.20762741565704346
Batch 41/64 loss: 0.21605360507965088
Batch 42/64 loss: 0.20557230710983276
Batch 43/64 loss: 0.2070302963256836
Batch 44/64 loss: 0.21118056774139404
Batch 45/64 loss: 0.21410483121871948
Batch 46/64 loss: 0.20641225576400757
Batch 47/64 loss: 0.22423487901687622
Batch 48/64 loss: 0.21603572368621826
Batch 49/64 loss: 0.20286226272583008
Batch 50/64 loss: 0.2116398811340332
Batch 51/64 loss: 0.2131129503250122
Batch 52/64 loss: 0.21394604444503784
Batch 53/64 loss: 0.21423083543777466
Batch 54/64 loss: 0.2177661657333374
Batch 55/64 loss: 0.21503013372421265
Batch 56/64 loss: 0.20480096340179443
Batch 57/64 loss: 0.22412949800491333
Batch 58/64 loss: 0.2001199722290039
Batch 59/64 loss: 0.2093910574913025
Batch 60/64 loss: 0.21633052825927734
Batch 61/64 loss: 0.22539067268371582
Batch 62/64 loss: 0.21004337072372437
Batch 63/64 loss: 0.21221327781677246
Batch 64/64 loss: 0.2155977487564087
Epoch 299  Train loss: 0.21184972922007242  Val loss: 0.2944115131991016
Epoch 300
-------------------------------
Batch 1/64 loss: 0.21030980348587036
Batch 2/64 loss: 0.2038496732711792
Batch 3/64 loss: 0.21535754203796387
Batch 4/64 loss: 0.2121368646621704
Batch 5/64 loss: 0.2184741497039795
Batch 6/64 loss: 0.20474708080291748
Batch 7/64 loss: 0.21645504236221313
Batch 8/64 loss: 0.21472376585006714
Batch 9/64 loss: 0.2043473720550537
Batch 10/64 loss: 0.20619887113571167
Batch 11/64 loss: 0.21725130081176758
Batch 12/64 loss: 0.20748305320739746
Batch 13/64 loss: 0.22166657447814941
Batch 14/64 loss: 0.2003943920135498
Batch 15/64 loss: 0.2072962522506714
Batch 16/64 loss: 0.2132803201675415
Batch 17/64 loss: 0.20490175485610962
Batch 18/64 loss: 0.22300374507904053
Batch 19/64 loss: 0.2078167200088501
Batch 20/64 loss: 0.2161349058151245
Batch 21/64 loss: 0.21888667345046997
Batch 22/64 loss: 0.21095067262649536
Batch 23/64 loss: 0.20530331134796143
Batch 24/64 loss: 0.2165876030921936
Batch 25/64 loss: 0.21425670385360718
Batch 26/64 loss: 0.20383697748184204
Batch 27/64 loss: 0.20388269424438477
Batch 28/64 loss: 0.20606005191802979
Batch 29/64 loss: 0.20658254623413086
Batch 30/64 loss: 0.21420425176620483
Batch 31/64 loss: 0.19718801975250244
Batch 32/64 loss: 0.21187353134155273
Batch 33/64 loss: 0.20756661891937256
Batch 34/64 loss: 0.21140789985656738
Batch 35/64 loss: 0.20724177360534668
Batch 36/64 loss: 0.2229042649269104
Batch 37/64 loss: 0.20959365367889404
Batch 38/64 loss: 0.2155349850654602
Batch 39/64 loss: 0.21165001392364502
Batch 40/64 loss: 0.20593982934951782
Batch 41/64 loss: 0.20968854427337646
Batch 42/64 loss: 0.21173113584518433
Batch 43/64 loss: 0.2227494716644287
Batch 44/64 loss: 0.20789456367492676
Batch 45/64 loss: 0.21917718648910522
Batch 46/64 loss: 0.2171030044555664
Batch 47/64 loss: 0.21420836448669434
Batch 48/64 loss: 0.2139188051223755
Batch 49/64 loss: 0.20906108617782593
Batch 50/64 loss: 0.21666646003723145
Batch 51/64 loss: 0.20675140619277954
Batch 52/64 loss: 0.2082880735397339
Batch 53/64 loss: 0.21207892894744873
Batch 54/64 loss: 0.2078133225440979
Batch 55/64 loss: 0.21997296810150146
Batch 56/64 loss: 0.21527862548828125
Batch 57/64 loss: 0.21880722045898438
Batch 58/64 loss: 0.20575857162475586
Batch 59/64 loss: 0.20913898944854736
Batch 60/64 loss: 0.20504260063171387
Batch 61/64 loss: 0.2092207670211792
Batch 62/64 loss: 0.21017277240753174
Batch 63/64 loss: 0.2221508026123047
Batch 64/64 loss: 0.21204030513763428
Epoch 300  Train loss: 0.21143506134257598  Val loss: 0.2941191069448936
Epoch 301
-------------------------------
Batch 1/64 loss: 0.2034052610397339
Batch 2/64 loss: 0.217637836933136
Batch 3/64 loss: 0.21562641859054565
Batch 4/64 loss: 0.20337921380996704
Batch 5/64 loss: 0.2106095552444458
Batch 6/64 loss: 0.20417243242263794
Batch 7/64 loss: 0.21187996864318848
Batch 8/64 loss: 0.21010476350784302
Batch 9/64 loss: 0.20933496952056885
Batch 10/64 loss: 0.21237945556640625
Batch 11/64 loss: 0.20945143699645996
Batch 12/64 loss: 0.20313680171966553
Batch 13/64 loss: 0.2131516933441162
Batch 14/64 loss: 0.21803665161132812
Batch 15/64 loss: 0.2153422236442566
Batch 16/64 loss: 0.20996320247650146
Batch 17/64 loss: 0.21257472038269043
Batch 18/64 loss: 0.21263635158538818
Batch 19/64 loss: 0.2142033576965332
Batch 20/64 loss: 0.2016608715057373
Batch 21/64 loss: 0.20790183544158936
Batch 22/64 loss: 0.21491891145706177
Batch 23/64 loss: 0.21428513526916504
Batch 24/64 loss: 0.20452940464019775
Batch 25/64 loss: 0.22238552570343018
Batch 26/64 loss: 0.20459496974945068
Batch 27/64 loss: 0.2072662115097046
Batch 28/64 loss: 0.20849955081939697
Batch 29/64 loss: 0.21479451656341553
Batch 30/64 loss: 0.201135516166687
Batch 31/64 loss: 0.20237672328948975
Batch 32/64 loss: 0.20669472217559814
Batch 33/64 loss: 0.21500998735427856
Batch 34/64 loss: 0.21396946907043457
Batch 35/64 loss: 0.23161065578460693
Batch 36/64 loss: 0.21211856603622437
Batch 37/64 loss: 0.20588326454162598
Batch 38/64 loss: 0.21931815147399902
Batch 39/64 loss: 0.20738089084625244
Batch 40/64 loss: 0.22178655862808228
Batch 41/64 loss: 0.2078946828842163
Batch 42/64 loss: 0.21177959442138672
Batch 43/64 loss: 0.22335892915725708
Batch 44/64 loss: 0.2116333246231079
Batch 45/64 loss: 0.2217189073562622
Batch 46/64 loss: 0.21042871475219727
Batch 47/64 loss: 0.2104705572128296
Batch 48/64 loss: 0.2193387746810913
Batch 49/64 loss: 0.21366679668426514
Batch 50/64 loss: 0.20062094926834106
Batch 51/64 loss: 0.21345198154449463
Batch 52/64 loss: 0.2072916030883789
Batch 53/64 loss: 0.2122299075126648
Batch 54/64 loss: 0.21678686141967773
Batch 55/64 loss: 0.2164292335510254
Batch 56/64 loss: 0.21346795558929443
Batch 57/64 loss: 0.21411895751953125
Batch 58/64 loss: 0.21080327033996582
Batch 59/64 loss: 0.22653073072433472
Batch 60/64 loss: 0.21786975860595703
Batch 61/64 loss: 0.22071433067321777
Batch 62/64 loss: 0.21539151668548584
Batch 63/64 loss: 0.20849400758743286
Batch 64/64 loss: 0.21814733743667603
Epoch 301  Train loss: 0.21228626826230218  Val loss: 0.293697934380102
Epoch 302
-------------------------------
Batch 1/64 loss: 0.20983731746673584
Batch 2/64 loss: 0.20943522453308105
Batch 3/64 loss: 0.20813870429992676
Batch 4/64 loss: 0.205560564994812
Batch 5/64 loss: 0.22171729803085327
Batch 6/64 loss: 0.21545875072479248
Batch 7/64 loss: 0.21073424816131592
Batch 8/64 loss: 0.21033483743667603
Batch 9/64 loss: 0.2100905179977417
Batch 10/64 loss: 0.21251070499420166
Batch 11/64 loss: 0.23196029663085938
Batch 12/64 loss: 0.22155922651290894
Batch 13/64 loss: 0.2025519609451294
Batch 14/64 loss: 0.2051946520805359
Batch 15/64 loss: 0.212205171585083
Batch 16/64 loss: 0.22424721717834473
Batch 17/64 loss: 0.22049593925476074
Batch 18/64 loss: 0.2155975103378296
Batch 19/64 loss: 0.2172788381576538
Batch 20/64 loss: 0.21080493927001953
Batch 21/64 loss: 0.2034306526184082
Batch 22/64 loss: 0.210254967212677
Batch 23/64 loss: 0.20189988613128662
Batch 24/64 loss: 0.2093566656112671
Batch 25/64 loss: 0.20877832174301147
Batch 26/64 loss: 0.21581608057022095
Batch 27/64 loss: 0.2057485580444336
Batch 28/64 loss: 0.2076844573020935
Batch 29/64 loss: 0.21029400825500488
Batch 30/64 loss: 0.2076302170753479
Batch 31/64 loss: 0.21600967645645142
Batch 32/64 loss: 0.211176335811615
Batch 33/64 loss: 0.20559090375900269
Batch 34/64 loss: 0.20755761861801147
Batch 35/64 loss: 0.21916699409484863
Batch 36/64 loss: 0.21007102727890015
Batch 37/64 loss: 0.2141355276107788
Batch 38/64 loss: 0.21145087480545044
Batch 39/64 loss: 0.21318566799163818
Batch 40/64 loss: 0.20568186044692993
Batch 41/64 loss: 0.20445966720581055
Batch 42/64 loss: 0.20620465278625488
Batch 43/64 loss: 0.21846193075180054
Batch 44/64 loss: 0.2188715934753418
Batch 45/64 loss: 0.22095781564712524
Batch 46/64 loss: 0.20870143175125122
Batch 47/64 loss: 0.21157866716384888
Batch 48/64 loss: 0.20842576026916504
Batch 49/64 loss: 0.21370947360992432
Batch 50/64 loss: 0.2090100646018982
Batch 51/64 loss: 0.21663188934326172
Batch 52/64 loss: 0.21525144577026367
Batch 53/64 loss: 0.20806074142456055
Batch 54/64 loss: 0.22074270248413086
Batch 55/64 loss: 0.20846861600875854
Batch 56/64 loss: 0.2047576904296875
Batch 57/64 loss: 0.2176421880722046
Batch 58/64 loss: 0.2119404673576355
Batch 59/64 loss: 0.20476210117340088
Batch 60/64 loss: 0.20831573009490967
Batch 61/64 loss: 0.22126877307891846
Batch 62/64 loss: 0.20604091882705688
Batch 63/64 loss: 0.20268172025680542
Batch 64/64 loss: 0.2081853151321411
Epoch 302  Train loss: 0.21166618431315704  Val loss: 0.2946071712831451
Epoch 303
-------------------------------
Batch 1/64 loss: 0.20717889070510864
Batch 2/64 loss: 0.21160900592803955
Batch 3/64 loss: 0.2010331153869629
Batch 4/64 loss: 0.20451730489730835
Batch 5/64 loss: 0.2148301601409912
Batch 6/64 loss: 0.21318459510803223
Batch 7/64 loss: 0.20013606548309326
Batch 8/64 loss: 0.21954727172851562
Batch 9/64 loss: 0.21068942546844482
Batch 10/64 loss: 0.2090722918510437
Batch 11/64 loss: 0.20588231086730957
Batch 12/64 loss: 0.20735836029052734
Batch 13/64 loss: 0.20565342903137207
Batch 14/64 loss: 0.20342260599136353
Batch 15/64 loss: 0.20272481441497803
Batch 16/64 loss: 0.21316850185394287
Batch 17/64 loss: 0.20479559898376465
Batch 18/64 loss: 0.2076263427734375
Batch 19/64 loss: 0.2149217128753662
Batch 20/64 loss: 0.20540565252304077
Batch 21/64 loss: 0.21728205680847168
Batch 22/64 loss: 0.22849732637405396
Batch 23/64 loss: 0.2110893726348877
Batch 24/64 loss: 0.20637667179107666
Batch 25/64 loss: 0.21693074703216553
Batch 26/64 loss: 0.20836836099624634
Batch 27/64 loss: 0.21031183004379272
Batch 28/64 loss: 0.21758723258972168
Batch 29/64 loss: 0.21246463060379028
Batch 30/64 loss: 0.20911955833435059
Batch 31/64 loss: 0.21022647619247437
Batch 32/64 loss: 0.22568154335021973
Batch 33/64 loss: 0.22283947467803955
Batch 34/64 loss: 0.20683681964874268
Batch 35/64 loss: 0.20249807834625244
Batch 36/64 loss: 0.2069738507270813
Batch 37/64 loss: 0.2129228115081787
Batch 38/64 loss: 0.2270597219467163
Batch 39/64 loss: 0.2139887809753418
Batch 40/64 loss: 0.20669496059417725
Batch 41/64 loss: 0.2138735055923462
Batch 42/64 loss: 0.21697717905044556
Batch 43/64 loss: 0.21659350395202637
Batch 44/64 loss: 0.20844429731369019
Batch 45/64 loss: 0.20537841320037842
Batch 46/64 loss: 0.20242780447006226
Batch 47/64 loss: 0.201185941696167
Batch 48/64 loss: 0.2108370065689087
Batch 49/64 loss: 0.21771866083145142
Batch 50/64 loss: 0.21564388275146484
Batch 51/64 loss: 0.2139449119567871
Batch 52/64 loss: 0.22118324041366577
Batch 53/64 loss: 0.21332496404647827
Batch 54/64 loss: 0.22148501873016357
Batch 55/64 loss: 0.21339207887649536
Batch 56/64 loss: 0.20077168941497803
Batch 57/64 loss: 0.22492444515228271
Batch 58/64 loss: 0.2190149426460266
Batch 59/64 loss: 0.2169165015220642
Batch 60/64 loss: 0.2106560468673706
Batch 61/64 loss: 0.21646571159362793
Batch 62/64 loss: 0.22236847877502441
Batch 63/64 loss: 0.21587765216827393
Batch 64/64 loss: 0.21455657482147217
Epoch 303  Train loss: 0.21202872266956405  Val loss: 0.29451229072518365
Epoch 304
-------------------------------
Batch 1/64 loss: 0.22277897596359253
Batch 2/64 loss: 0.208415687084198
Batch 3/64 loss: 0.20563244819641113
Batch 4/64 loss: 0.21321696043014526
Batch 5/64 loss: 0.21516883373260498
Batch 6/64 loss: 0.2197636365890503
Batch 7/64 loss: 0.20441699028015137
Batch 8/64 loss: 0.20843547582626343
Batch 9/64 loss: 0.20798754692077637
Batch 10/64 loss: 0.19637590646743774
Batch 11/64 loss: 0.21423614025115967
Batch 12/64 loss: 0.2161325216293335
Batch 13/64 loss: 0.20813757181167603
Batch 14/64 loss: 0.21566498279571533
Batch 15/64 loss: 0.20808076858520508
Batch 16/64 loss: 0.204545795917511
Batch 17/64 loss: 0.2175586223602295
Batch 18/64 loss: 0.20580410957336426
Batch 19/64 loss: 0.20021188259124756
Batch 20/64 loss: 0.2080792784690857
Batch 21/64 loss: 0.219044029712677
Batch 22/64 loss: 0.21175789833068848
Batch 23/64 loss: 0.2137499451637268
Batch 24/64 loss: 0.2059633731842041
Batch 25/64 loss: 0.20660018920898438
Batch 26/64 loss: 0.20421314239501953
Batch 27/64 loss: 0.20844393968582153
Batch 28/64 loss: 0.21765565872192383
Batch 29/64 loss: 0.2144351601600647
Batch 30/64 loss: 0.2075432538986206
Batch 31/64 loss: 0.2108616828918457
Batch 32/64 loss: 0.2122189998626709
Batch 33/64 loss: 0.20774269104003906
Batch 34/64 loss: 0.22135019302368164
Batch 35/64 loss: 0.205857515335083
Batch 36/64 loss: 0.20152974128723145
Batch 37/64 loss: 0.21182775497436523
Batch 38/64 loss: 0.2203061580657959
Batch 39/64 loss: 0.2266864776611328
Batch 40/64 loss: 0.20774579048156738
Batch 41/64 loss: 0.2064051628112793
Batch 42/64 loss: 0.22110211849212646
Batch 43/64 loss: 0.21939951181411743
Batch 44/64 loss: 0.20385223627090454
Batch 45/64 loss: 0.2060004472732544
Batch 46/64 loss: 0.21496635675430298
Batch 47/64 loss: 0.21228909492492676
Batch 48/64 loss: 0.20689105987548828
Batch 49/64 loss: 0.22521698474884033
Batch 50/64 loss: 0.23230111598968506
Batch 51/64 loss: 0.20188331604003906
Batch 52/64 loss: 0.20714139938354492
Batch 53/64 loss: 0.21054619550704956
Batch 54/64 loss: 0.23673498630523682
Batch 55/64 loss: 0.22796344757080078
Batch 56/64 loss: 0.21021389961242676
Batch 57/64 loss: 0.20919257402420044
Batch 58/64 loss: 0.21164947748184204
Batch 59/64 loss: 0.20934319496154785
Batch 60/64 loss: 0.21215206384658813
Batch 61/64 loss: 0.20160794258117676
Batch 62/64 loss: 0.21763795614242554
Batch 63/64 loss: 0.21086394786834717
Batch 64/64 loss: 0.22105634212493896
Epoch 304  Train loss: 0.21203646239112406  Val loss: 0.2948445962466735
Epoch 305
-------------------------------
Batch 1/64 loss: 0.2101818323135376
Batch 2/64 loss: 0.20619386434555054
Batch 3/64 loss: 0.2114948034286499
Batch 4/64 loss: 0.22207283973693848
Batch 5/64 loss: 0.2142072319984436
Batch 6/64 loss: 0.20878386497497559
Batch 7/64 loss: 0.19889456033706665
Batch 8/64 loss: 0.21610480546951294
Batch 9/64 loss: 0.2114984393119812
Batch 10/64 loss: 0.21102988719940186
Batch 11/64 loss: 0.2006291151046753
Batch 12/64 loss: 0.20104891061782837
Batch 13/64 loss: 0.21912884712219238
Batch 14/64 loss: 0.20953184366226196
Batch 15/64 loss: 0.2078818678855896
Batch 16/64 loss: 0.21272790431976318
Batch 17/64 loss: 0.19613051414489746
Batch 18/64 loss: 0.2044031023979187
Batch 19/64 loss: 0.20397430658340454
Batch 20/64 loss: 0.2017473578453064
Batch 21/64 loss: 0.21358847618103027
Batch 22/64 loss: 0.20887869596481323
Batch 23/64 loss: 0.19542187452316284
Batch 24/64 loss: 0.2076440453529358
Batch 25/64 loss: 0.2036164402961731
Batch 26/64 loss: 0.19920802116394043
Batch 27/64 loss: 0.21924102306365967
Batch 28/64 loss: 0.20302480459213257
Batch 29/64 loss: 0.2005704641342163
Batch 30/64 loss: 0.22098028659820557
Batch 31/64 loss: 0.22198069095611572
Batch 32/64 loss: 0.21814286708831787
Batch 33/64 loss: 0.21049416065216064
Batch 34/64 loss: 0.20226770639419556
Batch 35/64 loss: 0.20805883407592773
Batch 36/64 loss: 0.20904940366744995
Batch 37/64 loss: 0.21199190616607666
Batch 38/64 loss: 0.21182680130004883
Batch 39/64 loss: 0.212549090385437
Batch 40/64 loss: 0.20760047435760498
Batch 41/64 loss: 0.2109944224357605
Batch 42/64 loss: 0.20390009880065918
Batch 43/64 loss: 0.2037062644958496
Batch 44/64 loss: 0.2124950885772705
Batch 45/64 loss: 0.20395666360855103
Batch 46/64 loss: 0.22138601541519165
Batch 47/64 loss: 0.19909650087356567
Batch 48/64 loss: 0.21973198652267456
Batch 49/64 loss: 0.2076740264892578
Batch 50/64 loss: 0.2111184000968933
Batch 51/64 loss: 0.21204251050949097
Batch 52/64 loss: 0.2162243127822876
Batch 53/64 loss: 0.21759909391403198
Batch 54/64 loss: 0.20036303997039795
Batch 55/64 loss: 0.2175566554069519
Batch 56/64 loss: 0.20898491144180298
Batch 57/64 loss: 0.20623242855072021
Batch 58/64 loss: 0.21707332134246826
Batch 59/64 loss: 0.2212633490562439
Batch 60/64 loss: 0.2084113359451294
Batch 61/64 loss: 0.21859127283096313
Batch 62/64 loss: 0.20860260725021362
Batch 63/64 loss: 0.2118668556213379
Batch 64/64 loss: 0.23431497812271118
Epoch 305  Train loss: 0.21001426449009017  Val loss: 0.29439333665002254
Epoch 306
-------------------------------
Batch 1/64 loss: 0.21307557821273804
Batch 2/64 loss: 0.20863449573516846
Batch 3/64 loss: 0.20718467235565186
Batch 4/64 loss: 0.21091389656066895
Batch 5/64 loss: 0.202567458152771
Batch 6/64 loss: 0.21956634521484375
Batch 7/64 loss: 0.22034496068954468
Batch 8/64 loss: 0.19643110036849976
Batch 9/64 loss: 0.21468621492385864
Batch 10/64 loss: 0.21310245990753174
Batch 11/64 loss: 0.20155829191207886
Batch 12/64 loss: 0.206964910030365
Batch 13/64 loss: 0.21325457096099854
Batch 14/64 loss: 0.21155142784118652
Batch 15/64 loss: 0.19892704486846924
Batch 16/64 loss: 0.21633481979370117
Batch 17/64 loss: 0.2084755301475525
Batch 18/64 loss: 0.21396923065185547
Batch 19/64 loss: 0.21188032627105713
Batch 20/64 loss: 0.2097926139831543
Batch 21/64 loss: 0.20607978105545044
Batch 22/64 loss: 0.21152186393737793
Batch 23/64 loss: 0.22273385524749756
Batch 24/64 loss: 0.22072374820709229
Batch 25/64 loss: 0.21033906936645508
Batch 26/64 loss: 0.21418029069900513
Batch 27/64 loss: 0.22198069095611572
Batch 28/64 loss: 0.2127084732055664
Batch 29/64 loss: 0.20963317155838013
Batch 30/64 loss: 0.2103562355041504
Batch 31/64 loss: 0.21027028560638428
Batch 32/64 loss: 0.21596115827560425
Batch 33/64 loss: 0.2147960662841797
Batch 34/64 loss: 0.21652424335479736
Batch 35/64 loss: 0.20702850818634033
Batch 36/64 loss: 0.2082863450050354
Batch 37/64 loss: 0.22195816040039062
Batch 38/64 loss: 0.20804178714752197
Batch 39/64 loss: 0.22139596939086914
Batch 40/64 loss: 0.20324790477752686
Batch 41/64 loss: 0.20672142505645752
Batch 42/64 loss: 0.20329010486602783
Batch 43/64 loss: 0.20998847484588623
Batch 44/64 loss: 0.21114152669906616
Batch 45/64 loss: 0.2151278853416443
Batch 46/64 loss: 0.21393746137619019
Batch 47/64 loss: 0.20602798461914062
Batch 48/64 loss: 0.22574150562286377
Batch 49/64 loss: 0.202195405960083
Batch 50/64 loss: 0.21577107906341553
Batch 51/64 loss: 0.20425772666931152
Batch 52/64 loss: 0.20189142227172852
Batch 53/64 loss: 0.20971083641052246
Batch 54/64 loss: 0.21778059005737305
Batch 55/64 loss: 0.19788897037506104
Batch 56/64 loss: 0.20807933807373047
Batch 57/64 loss: 0.20809757709503174
Batch 58/64 loss: 0.20936083793640137
Batch 59/64 loss: 0.20937275886535645
Batch 60/64 loss: 0.2015262246131897
Batch 61/64 loss: 0.21533238887786865
Batch 62/64 loss: 0.2027263045310974
Batch 63/64 loss: 0.20771169662475586
Batch 64/64 loss: 0.21367239952087402
Epoch 306  Train loss: 0.21068105697631836  Val loss: 0.29394170529244285
Epoch 307
-------------------------------
Batch 1/64 loss: 0.21255505084991455
Batch 2/64 loss: 0.20985668897628784
Batch 3/64 loss: 0.2116936445236206
Batch 4/64 loss: 0.21867507696151733
Batch 5/64 loss: 0.2132737636566162
Batch 6/64 loss: 0.2106395959854126
Batch 7/64 loss: 0.22809624671936035
Batch 8/64 loss: 0.20834112167358398
Batch 9/64 loss: 0.2205713987350464
Batch 10/64 loss: 0.2063049077987671
Batch 11/64 loss: 0.22688454389572144
Batch 12/64 loss: 0.21743381023406982
Batch 13/64 loss: 0.21844696998596191
Batch 14/64 loss: 0.20928800106048584
Batch 15/64 loss: 0.20294129848480225
Batch 16/64 loss: 0.20704638957977295
Batch 17/64 loss: 0.21112704277038574
Batch 18/64 loss: 0.21073192358016968
Batch 19/64 loss: 0.20582425594329834
Batch 20/64 loss: 0.21257978677749634
Batch 21/64 loss: 0.20806407928466797
Batch 22/64 loss: 0.19815105199813843
Batch 23/64 loss: 0.22120672464370728
Batch 24/64 loss: 0.2126360535621643
Batch 25/64 loss: 0.21312785148620605
Batch 26/64 loss: 0.2157314419746399
Batch 27/64 loss: 0.20977848768234253
Batch 28/64 loss: 0.2172824740409851
Batch 29/64 loss: 0.21447014808654785
Batch 30/64 loss: 0.21845412254333496
Batch 31/64 loss: 0.21360868215560913
Batch 32/64 loss: 0.21967649459838867
Batch 33/64 loss: 0.1974199414253235
Batch 34/64 loss: 0.20164549350738525
Batch 35/64 loss: 0.2075742483139038
Batch 36/64 loss: 0.21340537071228027
Batch 37/64 loss: 0.22491753101348877
Batch 38/64 loss: 0.2054513692855835
Batch 39/64 loss: 0.2121301293373108
Batch 40/64 loss: 0.21327686309814453
Batch 41/64 loss: 0.21162784099578857
Batch 42/64 loss: 0.21009153127670288
Batch 43/64 loss: 0.20751821994781494
Batch 44/64 loss: 0.2047232985496521
Batch 45/64 loss: 0.21245133876800537
Batch 46/64 loss: 0.2032928466796875
Batch 47/64 loss: 0.21027708053588867
Batch 48/64 loss: 0.2076587677001953
Batch 49/64 loss: 0.21104949712753296
Batch 50/64 loss: 0.20278668403625488
Batch 51/64 loss: 0.2146373987197876
Batch 52/64 loss: 0.2210143804550171
Batch 53/64 loss: 0.20370906591415405
Batch 54/64 loss: 0.2141299843788147
Batch 55/64 loss: 0.2101401686668396
Batch 56/64 loss: 0.2247166633605957
Batch 57/64 loss: 0.2090691328048706
Batch 58/64 loss: 0.19972878694534302
Batch 59/64 loss: 0.20247769355773926
Batch 60/64 loss: 0.21339690685272217
Batch 61/64 loss: 0.22247493267059326
Batch 62/64 loss: 0.2100176215171814
Batch 63/64 loss: 0.2129228115081787
Batch 64/64 loss: 0.2125847339630127
Epoch 307  Train loss: 0.2117595494962206  Val loss: 0.2948788963642317
Epoch 308
-------------------------------
Batch 1/64 loss: 0.21286845207214355
Batch 2/64 loss: 0.22250401973724365
Batch 3/64 loss: 0.21838128566741943
Batch 4/64 loss: 0.2201499342918396
Batch 5/64 loss: 0.2132880687713623
Batch 6/64 loss: 0.21329480409622192
Batch 7/64 loss: 0.20778942108154297
Batch 8/64 loss: 0.21462053060531616
Batch 9/64 loss: 0.22541439533233643
Batch 10/64 loss: 0.20475757122039795
Batch 11/64 loss: 0.21378982067108154
Batch 12/64 loss: 0.2204951047897339
Batch 13/64 loss: 0.20676738023757935
Batch 14/64 loss: 0.203685462474823
Batch 15/64 loss: 0.202964186668396
Batch 16/64 loss: 0.21317094564437866
Batch 17/64 loss: 0.21043908596038818
Batch 18/64 loss: 0.20786052942276
Batch 19/64 loss: 0.20602130889892578
Batch 20/64 loss: 0.20068681240081787
Batch 21/64 loss: 0.21321570873260498
Batch 22/64 loss: 0.19736194610595703
Batch 23/64 loss: 0.210235595703125
Batch 24/64 loss: 0.2228257656097412
Batch 25/64 loss: 0.21157407760620117
Batch 26/64 loss: 0.2029106616973877
Batch 27/64 loss: 0.21095579862594604
Batch 28/64 loss: 0.20442485809326172
Batch 29/64 loss: 0.20511293411254883
Batch 30/64 loss: 0.21203917264938354
Batch 31/64 loss: 0.21320009231567383
Batch 32/64 loss: 0.2139190435409546
Batch 33/64 loss: 0.21908199787139893
Batch 34/64 loss: 0.20362555980682373
Batch 35/64 loss: 0.20523005723953247
Batch 36/64 loss: 0.2237485647201538
Batch 37/64 loss: 0.20834237337112427
Batch 38/64 loss: 0.2122054100036621
Batch 39/64 loss: 0.21334755420684814
Batch 40/64 loss: 0.20469391345977783
Batch 41/64 loss: 0.2031482458114624
Batch 42/64 loss: 0.22041237354278564
Batch 43/64 loss: 0.20424306392669678
Batch 44/64 loss: 0.21868252754211426
Batch 45/64 loss: 0.21164387464523315
Batch 46/64 loss: 0.21662914752960205
Batch 47/64 loss: 0.21603524684906006
Batch 48/64 loss: 0.20419132709503174
Batch 49/64 loss: 0.20247173309326172
Batch 50/64 loss: 0.20776653289794922
Batch 51/64 loss: 0.20387780666351318
Batch 52/64 loss: 0.20837020874023438
Batch 53/64 loss: 0.21840250492095947
Batch 54/64 loss: 0.2119995355606079
Batch 55/64 loss: 0.20736956596374512
Batch 56/64 loss: 0.2124042510986328
Batch 57/64 loss: 0.20651912689208984
Batch 58/64 loss: 0.22418808937072754
Batch 59/64 loss: 0.2175980806350708
Batch 60/64 loss: 0.21463394165039062
Batch 61/64 loss: 0.21439683437347412
Batch 62/64 loss: 0.21359741687774658
Batch 63/64 loss: 0.2033613920211792
Batch 64/64 loss: 0.22291523218154907
Epoch 308  Train loss: 0.21139026599771837  Val loss: 0.29402555571388955
Epoch 309
-------------------------------
Batch 1/64 loss: 0.2091326117515564
Batch 2/64 loss: 0.197584867477417
Batch 3/64 loss: 0.2148514986038208
Batch 4/64 loss: 0.21282494068145752
Batch 5/64 loss: 0.21122294664382935
Batch 6/64 loss: 0.21084749698638916
Batch 7/64 loss: 0.21768426895141602
Batch 8/64 loss: 0.20708465576171875
Batch 9/64 loss: 0.20731091499328613
Batch 10/64 loss: 0.20785510540008545
Batch 11/64 loss: 0.20554780960083008
Batch 12/64 loss: 0.19778788089752197
Batch 13/64 loss: 0.20388132333755493
Batch 14/64 loss: 0.21171224117279053
Batch 15/64 loss: 0.210332989692688
Batch 16/64 loss: 0.21733582019805908
Batch 17/64 loss: 0.2005159854888916
Batch 18/64 loss: 0.21598541736602783
Batch 19/64 loss: 0.21707367897033691
Batch 20/64 loss: 0.21154725551605225
Batch 21/64 loss: 0.22121834754943848
Batch 22/64 loss: 0.20580029487609863
Batch 23/64 loss: 0.20699048042297363
Batch 24/64 loss: 0.2120245099067688
Batch 25/64 loss: 0.21205472946166992
Batch 26/64 loss: 0.21638774871826172
Batch 27/64 loss: 0.20356464385986328
Batch 28/64 loss: 0.20658087730407715
Batch 29/64 loss: 0.21523308753967285
Batch 30/64 loss: 0.2164846658706665
Batch 31/64 loss: 0.22634094953536987
Batch 32/64 loss: 0.22242999076843262
Batch 33/64 loss: 0.2063785195350647
Batch 34/64 loss: 0.21037280559539795
Batch 35/64 loss: 0.2178490161895752
Batch 36/64 loss: 0.20641660690307617
Batch 37/64 loss: 0.19773542881011963
Batch 38/64 loss: 0.2159411907196045
Batch 39/64 loss: 0.2048683762550354
Batch 40/64 loss: 0.2118079662322998
Batch 41/64 loss: 0.21673953533172607
Batch 42/64 loss: 0.21586650609970093
Batch 43/64 loss: 0.2044360637664795
Batch 44/64 loss: 0.2236931324005127
Batch 45/64 loss: 0.21153175830841064
Batch 46/64 loss: 0.20974230766296387
Batch 47/64 loss: 0.21573781967163086
Batch 48/64 loss: 0.20907610654830933
Batch 49/64 loss: 0.20268559455871582
Batch 50/64 loss: 0.21190094947814941
Batch 51/64 loss: 0.2008960247039795
Batch 52/64 loss: 0.21165192127227783
Batch 53/64 loss: 0.2139662504196167
Batch 54/64 loss: 0.21623098850250244
Batch 55/64 loss: 0.2150033712387085
Batch 56/64 loss: 0.2109156847000122
Batch 57/64 loss: 0.20007354021072388
Batch 58/64 loss: 0.20842742919921875
Batch 59/64 loss: 0.20614969730377197
Batch 60/64 loss: 0.21973133087158203
Batch 61/64 loss: 0.21164065599441528
Batch 62/64 loss: 0.2121647596359253
Batch 63/64 loss: 0.21413826942443848
Batch 64/64 loss: 0.213454008102417
Epoch 309  Train loss: 0.2109347474341299  Val loss: 0.29417257435952676
Epoch 310
-------------------------------
Batch 1/64 loss: 0.21565240621566772
Batch 2/64 loss: 0.20107603073120117
Batch 3/64 loss: 0.20318567752838135
Batch 4/64 loss: 0.2095499038696289
Batch 5/64 loss: 0.19897204637527466
Batch 6/64 loss: 0.20592963695526123
Batch 7/64 loss: 0.21898972988128662
Batch 8/64 loss: 0.20923089981079102
Batch 9/64 loss: 0.20754826068878174
Batch 10/64 loss: 0.21565377712249756
Batch 11/64 loss: 0.2089444398880005
Batch 12/64 loss: 0.20171034336090088
Batch 13/64 loss: 0.20679938793182373
Batch 14/64 loss: 0.20263677835464478
Batch 15/64 loss: 0.20196199417114258
Batch 16/64 loss: 0.20541155338287354
Batch 17/64 loss: 0.2211207151412964
Batch 18/64 loss: 0.20289045572280884
Batch 19/64 loss: 0.21202898025512695
Batch 20/64 loss: 0.21382015943527222
Batch 21/64 loss: 0.21926426887512207
Batch 22/64 loss: 0.20302194356918335
Batch 23/64 loss: 0.20858699083328247
Batch 24/64 loss: 0.2135290503501892
Batch 25/64 loss: 0.2213180661201477
Batch 26/64 loss: 0.2184840440750122
Batch 27/64 loss: 0.215778648853302
Batch 28/64 loss: 0.21317458152770996
Batch 29/64 loss: 0.21597039699554443
Batch 30/64 loss: 0.21166157722473145
Batch 31/64 loss: 0.20306259393692017
Batch 32/64 loss: 0.21136993169784546
Batch 33/64 loss: 0.20584696531295776
Batch 34/64 loss: 0.21201831102371216
Batch 35/64 loss: 0.21368062496185303
Batch 36/64 loss: 0.21930932998657227
Batch 37/64 loss: 0.2154834270477295
Batch 38/64 loss: 0.21972763538360596
Batch 39/64 loss: 0.21161794662475586
Batch 40/64 loss: 0.21015650033950806
Batch 41/64 loss: 0.22131818532943726
Batch 42/64 loss: 0.22610092163085938
Batch 43/64 loss: 0.19721323251724243
Batch 44/64 loss: 0.20014846324920654
Batch 45/64 loss: 0.22470998764038086
Batch 46/64 loss: 0.21528106927871704
Batch 47/64 loss: 0.21896517276763916
Batch 48/64 loss: 0.2089024782180786
Batch 49/64 loss: 0.2119889259338379
Batch 50/64 loss: 0.22269076108932495
Batch 51/64 loss: 0.20963871479034424
Batch 52/64 loss: 0.20910632610321045
Batch 53/64 loss: 0.20291143655776978
Batch 54/64 loss: 0.20210105180740356
Batch 55/64 loss: 0.22123348712921143
Batch 56/64 loss: 0.20839405059814453
Batch 57/64 loss: 0.21365630626678467
Batch 58/64 loss: 0.2050851583480835
Batch 59/64 loss: 0.20959067344665527
Batch 60/64 loss: 0.2063118815422058
Batch 61/64 loss: 0.21278750896453857
Batch 62/64 loss: 0.20299237966537476
Batch 63/64 loss: 0.20207732915878296
Batch 64/64 loss: 0.20161277055740356
Epoch 310  Train loss: 0.21067593869040993  Val loss: 0.2938829439202535
Epoch 311
-------------------------------
Batch 1/64 loss: 0.2121695876121521
Batch 2/64 loss: 0.20766544342041016
Batch 3/64 loss: 0.21076583862304688
Batch 4/64 loss: 0.20471268892288208
Batch 5/64 loss: 0.2062453031539917
Batch 6/64 loss: 0.20601630210876465
Batch 7/64 loss: 0.21836334466934204
Batch 8/64 loss: 0.21167361736297607
Batch 9/64 loss: 0.2120283842086792
Batch 10/64 loss: 0.20809614658355713
Batch 11/64 loss: 0.2036471962928772
Batch 12/64 loss: 0.2165396809577942
Batch 13/64 loss: 0.2052527666091919
Batch 14/64 loss: 0.21631628274917603
Batch 15/64 loss: 0.2143305540084839
Batch 16/64 loss: 0.22682803869247437
Batch 17/64 loss: 0.21213579177856445
Batch 18/64 loss: 0.21263408660888672
Batch 19/64 loss: 0.2072027325630188
Batch 20/64 loss: 0.21360135078430176
Batch 21/64 loss: 0.2169501781463623
Batch 22/64 loss: 0.2166602611541748
Batch 23/64 loss: 0.21201568841934204
Batch 24/64 loss: 0.2055649757385254
Batch 25/64 loss: 0.20887815952301025
Batch 26/64 loss: 0.21335572004318237
Batch 27/64 loss: 0.20618963241577148
Batch 28/64 loss: 0.2218179702758789
Batch 29/64 loss: 0.21004056930541992
Batch 30/64 loss: 0.21586209535598755
Batch 31/64 loss: 0.1983620524406433
Batch 32/64 loss: 0.21427702903747559
Batch 33/64 loss: 0.2116379737854004
Batch 34/64 loss: 0.20430898666381836
Batch 35/64 loss: 0.21153855323791504
Batch 36/64 loss: 0.21725749969482422
Batch 37/64 loss: 0.21063774824142456
Batch 38/64 loss: 0.20331346988677979
Batch 39/64 loss: 0.2164880633354187
Batch 40/64 loss: 0.20141160488128662
Batch 41/64 loss: 0.20729315280914307
Batch 42/64 loss: 0.20954954624176025
Batch 43/64 loss: 0.19935369491577148
Batch 44/64 loss: 0.21700561046600342
Batch 45/64 loss: 0.21009814739227295
Batch 46/64 loss: 0.21216809749603271
Batch 47/64 loss: 0.21148252487182617
Batch 48/64 loss: 0.20982730388641357
Batch 49/64 loss: 0.20070528984069824
Batch 50/64 loss: 0.21156126260757446
Batch 51/64 loss: 0.2026963233947754
Batch 52/64 loss: 0.20697957277297974
Batch 53/64 loss: 0.20209157466888428
Batch 54/64 loss: 0.20829284191131592
Batch 55/64 loss: 0.21646368503570557
Batch 56/64 loss: 0.20930469036102295
Batch 57/64 loss: 0.21567785739898682
Batch 58/64 loss: 0.21314865350723267
Batch 59/64 loss: 0.2136136293411255
Batch 60/64 loss: 0.20965200662612915
Batch 61/64 loss: 0.20804977416992188
Batch 62/64 loss: 0.21312516927719116
Batch 63/64 loss: 0.20373570919036865
Batch 64/64 loss: 0.21140778064727783
Epoch 311  Train loss: 0.21040353447783228  Val loss: 0.29425268853243275
Epoch 312
-------------------------------
Batch 1/64 loss: 0.22078603506088257
Batch 2/64 loss: 0.20659083127975464
Batch 3/64 loss: 0.21072959899902344
Batch 4/64 loss: 0.20218539237976074
Batch 5/64 loss: 0.2105124592781067
Batch 6/64 loss: 0.20841753482818604
Batch 7/64 loss: 0.2061557173728943
Batch 8/64 loss: 0.20792537927627563
Batch 9/64 loss: 0.20490801334381104
Batch 10/64 loss: 0.20373117923736572
Batch 11/64 loss: 0.20440709590911865
Batch 12/64 loss: 0.20204782485961914
Batch 13/64 loss: 0.21829915046691895
Batch 14/64 loss: 0.20629817247390747
Batch 15/64 loss: 0.19855880737304688
Batch 16/64 loss: 0.20992010831832886
Batch 17/64 loss: 0.2186872959136963
Batch 18/64 loss: 0.20515775680541992
Batch 19/64 loss: 0.20636963844299316
Batch 20/64 loss: 0.21307873725891113
Batch 21/64 loss: 0.2029854655265808
Batch 22/64 loss: 0.2060915231704712
Batch 23/64 loss: 0.2157813310623169
Batch 24/64 loss: 0.2022716999053955
Batch 25/64 loss: 0.22581398487091064
Batch 26/64 loss: 0.2041393518447876
Batch 27/64 loss: 0.2071305513381958
Batch 28/64 loss: 0.21239954233169556
Batch 29/64 loss: 0.2084798812866211
Batch 30/64 loss: 0.20904338359832764
Batch 31/64 loss: 0.19962078332901
Batch 32/64 loss: 0.2056804895401001
Batch 33/64 loss: 0.2057093381881714
Batch 34/64 loss: 0.21062088012695312
Batch 35/64 loss: 0.20769786834716797
Batch 36/64 loss: 0.21709918975830078
Batch 37/64 loss: 0.2184509038925171
Batch 38/64 loss: 0.22596454620361328
Batch 39/64 loss: 0.20885711908340454
Batch 40/64 loss: 0.2245824933052063
Batch 41/64 loss: 0.2063835859298706
Batch 42/64 loss: 0.21360492706298828
Batch 43/64 loss: 0.22977334260940552
Batch 44/64 loss: 0.21282696723937988
Batch 45/64 loss: 0.21018046140670776
Batch 46/64 loss: 0.2156505584716797
Batch 47/64 loss: 0.21592390537261963
Batch 48/64 loss: 0.21732604503631592
Batch 49/64 loss: 0.20091533660888672
Batch 50/64 loss: 0.21372616291046143
Batch 51/64 loss: 0.21702158451080322
Batch 52/64 loss: 0.20822608470916748
Batch 53/64 loss: 0.2108151912689209
Batch 54/64 loss: 0.20352935791015625
Batch 55/64 loss: 0.19779592752456665
Batch 56/64 loss: 0.2229819893836975
Batch 57/64 loss: 0.20411229133605957
Batch 58/64 loss: 0.20713746547698975
Batch 59/64 loss: 0.20624268054962158
Batch 60/64 loss: 0.21115541458129883
Batch 61/64 loss: 0.21147632598876953
Batch 62/64 loss: 0.20934337377548218
Batch 63/64 loss: 0.21719449758529663
Batch 64/64 loss: 0.2061173915863037
Epoch 312  Train loss: 0.21021362472982968  Val loss: 0.29453695148127185
Epoch 313
-------------------------------
Batch 1/64 loss: 0.22009235620498657
Batch 2/64 loss: 0.2116551399230957
Batch 3/64 loss: 0.20719581842422485
Batch 4/64 loss: 0.2085326910018921
Batch 5/64 loss: 0.20950758457183838
Batch 6/64 loss: 0.20977360010147095
Batch 7/64 loss: 0.22339105606079102
Batch 8/64 loss: 0.2064964771270752
Batch 9/64 loss: 0.2194678783416748
Batch 10/64 loss: 0.20933526754379272
Batch 11/64 loss: 0.21115952730178833
Batch 12/64 loss: 0.1982332468032837
Batch 13/64 loss: 0.20733284950256348
Batch 14/64 loss: 0.20588606595993042
Batch 15/64 loss: 0.21918249130249023
Batch 16/64 loss: 0.22335797548294067
Batch 17/64 loss: 0.20552247762680054
Batch 18/64 loss: 0.20703142881393433
Batch 19/64 loss: 0.21051561832427979
Batch 20/64 loss: 0.2040613293647766
Batch 21/64 loss: 0.2052934169769287
Batch 22/64 loss: 0.20799219608306885
Batch 23/64 loss: 0.20277166366577148
Batch 24/64 loss: 0.21666115522384644
Batch 25/64 loss: 0.20762163400650024
Batch 26/64 loss: 0.20088541507720947
Batch 27/64 loss: 0.21003782749176025
Batch 28/64 loss: 0.20519095659255981
Batch 29/64 loss: 0.20117616653442383
Batch 30/64 loss: 0.20716464519500732
Batch 31/64 loss: 0.21964210271835327
Batch 32/64 loss: 0.2137356996536255
Batch 33/64 loss: 0.20733177661895752
Batch 34/64 loss: 0.21760284900665283
Batch 35/64 loss: 0.2110961675643921
Batch 36/64 loss: 0.20618873834609985
Batch 37/64 loss: 0.21080970764160156
Batch 38/64 loss: 0.20878732204437256
Batch 39/64 loss: 0.20126450061798096
Batch 40/64 loss: 0.21156001091003418
Batch 41/64 loss: 0.2289125919342041
Batch 42/64 loss: 0.2151389718055725
Batch 43/64 loss: 0.2078418731689453
Batch 44/64 loss: 0.21967005729675293
Batch 45/64 loss: 0.21685993671417236
Batch 46/64 loss: 0.21126890182495117
Batch 47/64 loss: 0.21243584156036377
Batch 48/64 loss: 0.21199560165405273
Batch 49/64 loss: 0.2171916961669922
Batch 50/64 loss: 0.2051762342453003
Batch 51/64 loss: 0.20325559377670288
Batch 52/64 loss: 0.20675992965698242
Batch 53/64 loss: 0.1970432996749878
Batch 54/64 loss: 0.20752990245819092
Batch 55/64 loss: 0.20968663692474365
Batch 56/64 loss: 0.2038511037826538
Batch 57/64 loss: 0.20910120010375977
Batch 58/64 loss: 0.20419472455978394
Batch 59/64 loss: 0.20817172527313232
Batch 60/64 loss: 0.21824800968170166
Batch 61/64 loss: 0.20314699411392212
Batch 62/64 loss: 0.20305347442626953
Batch 63/64 loss: 0.20775991678237915
Batch 64/64 loss: 0.19915199279785156
Epoch 313  Train loss: 0.20969730265000286  Val loss: 0.29426430508852824
Epoch 314
-------------------------------
Batch 1/64 loss: 0.19875943660736084
Batch 2/64 loss: 0.19821083545684814
Batch 3/64 loss: 0.20606184005737305
Batch 4/64 loss: 0.2105870246887207
Batch 5/64 loss: 0.20951807498931885
Batch 6/64 loss: 0.19882285594940186
Batch 7/64 loss: 0.2139594554901123
Batch 8/64 loss: 0.21014463901519775
Batch 9/64 loss: 0.20089644193649292
Batch 10/64 loss: 0.2047528624534607
Batch 11/64 loss: 0.20140719413757324
Batch 12/64 loss: 0.20955759286880493
Batch 13/64 loss: 0.2123802900314331
Batch 14/64 loss: 0.19863730669021606
Batch 15/64 loss: 0.21201545000076294
Batch 16/64 loss: 0.21178144216537476
Batch 17/64 loss: 0.20787763595581055
Batch 18/64 loss: 0.21249669790267944
Batch 19/64 loss: 0.20722174644470215
Batch 20/64 loss: 0.20888686180114746
Batch 21/64 loss: 0.2058701515197754
Batch 22/64 loss: 0.20159506797790527
Batch 23/64 loss: 0.2045658826828003
Batch 24/64 loss: 0.20319050550460815
Batch 25/64 loss: 0.20973825454711914
Batch 26/64 loss: 0.21579813957214355
Batch 27/64 loss: 0.21666669845581055
Batch 28/64 loss: 0.21178913116455078
Batch 29/64 loss: 0.21638745069503784
Batch 30/64 loss: 0.20579206943511963
Batch 31/64 loss: 0.20555496215820312
Batch 32/64 loss: 0.21292883157730103
Batch 33/64 loss: 0.21132344007492065
Batch 34/64 loss: 0.2056722640991211
Batch 35/64 loss: 0.22544676065444946
Batch 36/64 loss: 0.2000722885131836
Batch 37/64 loss: 0.2207775115966797
Batch 38/64 loss: 0.20841217041015625
Batch 39/64 loss: 0.21182537078857422
Batch 40/64 loss: 0.19747555255889893
Batch 41/64 loss: 0.2130364179611206
Batch 42/64 loss: 0.2216430902481079
Batch 43/64 loss: 0.20897024869918823
Batch 44/64 loss: 0.22253680229187012
Batch 45/64 loss: 0.21097415685653687
Batch 46/64 loss: 0.21809077262878418
Batch 47/64 loss: 0.21399199962615967
Batch 48/64 loss: 0.20374953746795654
Batch 49/64 loss: 0.21584999561309814
Batch 50/64 loss: 0.20015746355056763
Batch 51/64 loss: 0.2032148838043213
Batch 52/64 loss: 0.20279443264007568
Batch 53/64 loss: 0.21494966745376587
Batch 54/64 loss: 0.206770658493042
Batch 55/64 loss: 0.20729279518127441
Batch 56/64 loss: 0.21672332286834717
Batch 57/64 loss: 0.21465718746185303
Batch 58/64 loss: 0.20587372779846191
Batch 59/64 loss: 0.2052026391029358
Batch 60/64 loss: 0.20075511932373047
Batch 61/64 loss: 0.2065058946609497
Batch 62/64 loss: 0.2033940553665161
Batch 63/64 loss: 0.2154632806777954
Batch 64/64 loss: 0.21670514345169067
Epoch 314  Train loss: 0.20894094425089219  Val loss: 0.29408554727678854
Epoch 315
-------------------------------
Batch 1/64 loss: 0.23016023635864258
Batch 2/64 loss: 0.2036726474761963
Batch 3/64 loss: 0.20180368423461914
Batch 4/64 loss: 0.2235022783279419
Batch 5/64 loss: 0.20508944988250732
Batch 6/64 loss: 0.21244168281555176
Batch 7/64 loss: 0.20887231826782227
Batch 8/64 loss: 0.2070709466934204
Batch 9/64 loss: 0.20959043502807617
Batch 10/64 loss: 0.19652169942855835
Batch 11/64 loss: 0.21117454767227173
Batch 12/64 loss: 0.21290814876556396
Batch 13/64 loss: 0.20695531368255615
Batch 14/64 loss: 0.20737671852111816
Batch 15/64 loss: 0.21643996238708496
Batch 16/64 loss: 0.21057593822479248
Batch 17/64 loss: 0.2120494842529297
Batch 18/64 loss: 0.2030961513519287
Batch 19/64 loss: 0.20583808422088623
Batch 20/64 loss: 0.2116316556930542
Batch 21/64 loss: 0.2039872407913208
Batch 22/64 loss: 0.1992226243019104
Batch 23/64 loss: 0.2088332176208496
Batch 24/64 loss: 0.2053004503250122
Batch 25/64 loss: 0.2105897068977356
Batch 26/64 loss: 0.2011396288871765
Batch 27/64 loss: 0.2121983766555786
Batch 28/64 loss: 0.20275074243545532
Batch 29/64 loss: 0.20569956302642822
Batch 30/64 loss: 0.22472190856933594
Batch 31/64 loss: 0.2037109136581421
Batch 32/64 loss: 0.20306813716888428
Batch 33/64 loss: 0.20695865154266357
Batch 34/64 loss: 0.21471869945526123
Batch 35/64 loss: 0.20682865381240845
Batch 36/64 loss: 0.21065294742584229
Batch 37/64 loss: 0.192135751247406
Batch 38/64 loss: 0.2168269157409668
Batch 39/64 loss: 0.22011935710906982
Batch 40/64 loss: 0.21394789218902588
Batch 41/64 loss: 0.21010982990264893
Batch 42/64 loss: 0.2023882269859314
Batch 43/64 loss: 0.19843417406082153
Batch 44/64 loss: 0.21079295873641968
Batch 45/64 loss: 0.21614199876785278
Batch 46/64 loss: 0.20372068881988525
Batch 47/64 loss: 0.2041645646095276
Batch 48/64 loss: 0.20605099201202393
Batch 49/64 loss: 0.21342957019805908
Batch 50/64 loss: 0.22524750232696533
Batch 51/64 loss: 0.2150229811668396
Batch 52/64 loss: 0.2074272632598877
Batch 53/64 loss: 0.20026272535324097
Batch 54/64 loss: 0.20029520988464355
Batch 55/64 loss: 0.2044849395751953
Batch 56/64 loss: 0.20458382368087769
Batch 57/64 loss: 0.2134411334991455
Batch 58/64 loss: 0.20499122142791748
Batch 59/64 loss: 0.2138015627861023
Batch 60/64 loss: 0.21696043014526367
Batch 61/64 loss: 0.2044353485107422
Batch 62/64 loss: 0.20730626583099365
Batch 63/64 loss: 0.21451467275619507
Batch 64/64 loss: 0.2095242142677307
Epoch 315  Train loss: 0.20886798442578783  Val loss: 0.2941969545026825
Epoch 316
-------------------------------
Batch 1/64 loss: 0.20762145519256592
Batch 2/64 loss: 0.19867539405822754
Batch 3/64 loss: 0.20776963233947754
Batch 4/64 loss: 0.1986391544342041
Batch 5/64 loss: 0.21013236045837402
Batch 6/64 loss: 0.21149635314941406
Batch 7/64 loss: 0.20142114162445068
Batch 8/64 loss: 0.20662367343902588
Batch 9/64 loss: 0.20967376232147217
Batch 10/64 loss: 0.21544337272644043
Batch 11/64 loss: 0.21703124046325684
Batch 12/64 loss: 0.20719367265701294
Batch 13/64 loss: 0.20401334762573242
Batch 14/64 loss: 0.2143096923828125
Batch 15/64 loss: 0.21139943599700928
Batch 16/64 loss: 0.2039160132408142
Batch 17/64 loss: 0.2109752893447876
Batch 18/64 loss: 0.21949851512908936
Batch 19/64 loss: 0.2128514051437378
Batch 20/64 loss: 0.20296239852905273
Batch 21/64 loss: 0.21353530883789062
Batch 22/64 loss: 0.20387870073318481
Batch 23/64 loss: 0.2216120958328247
Batch 24/64 loss: 0.21216297149658203
Batch 25/64 loss: 0.2216700315475464
Batch 26/64 loss: 0.21698600053787231
Batch 27/64 loss: 0.20531237125396729
Batch 28/64 loss: 0.2301790714263916
Batch 29/64 loss: 0.21067368984222412
Batch 30/64 loss: 0.2134377360343933
Batch 31/64 loss: 0.21828114986419678
Batch 32/64 loss: 0.20512688159942627
Batch 33/64 loss: 0.22084331512451172
Batch 34/64 loss: 0.21643871068954468
Batch 35/64 loss: 0.20226168632507324
Batch 36/64 loss: 0.21499335765838623
Batch 37/64 loss: 0.20886296033859253
Batch 38/64 loss: 0.2301982045173645
Batch 39/64 loss: 0.2053784728050232
Batch 40/64 loss: 0.2034274935722351
Batch 41/64 loss: 0.20962584018707275
Batch 42/64 loss: 0.2092968225479126
Batch 43/64 loss: 0.21290051937103271
Batch 44/64 loss: 0.206307053565979
Batch 45/64 loss: 0.21540415287017822
Batch 46/64 loss: 0.200545072555542
Batch 47/64 loss: 0.2071494460105896
Batch 48/64 loss: 0.19943970441818237
Batch 49/64 loss: 0.2041798233985901
Batch 50/64 loss: 0.20713675022125244
Batch 51/64 loss: 0.19883882999420166
Batch 52/64 loss: 0.2000826597213745
Batch 53/64 loss: 0.20359885692596436
Batch 54/64 loss: 0.2019869089126587
Batch 55/64 loss: 0.21254312992095947
Batch 56/64 loss: 0.21592199802398682
Batch 57/64 loss: 0.21533119678497314
Batch 58/64 loss: 0.2132924199104309
Batch 59/64 loss: 0.20495951175689697
Batch 60/64 loss: 0.20150303840637207
Batch 61/64 loss: 0.21497738361358643
Batch 62/64 loss: 0.20196104049682617
Batch 63/64 loss: 0.2133309245109558
Batch 64/64 loss: 0.22354936599731445
Epoch 316  Train loss: 0.20995894319870892  Val loss: 0.2950620720886283
Epoch 317
-------------------------------
Batch 1/64 loss: 0.20984911918640137
Batch 2/64 loss: 0.20098209381103516
Batch 3/64 loss: 0.20566868782043457
Batch 4/64 loss: 0.20073330402374268
Batch 5/64 loss: 0.199113130569458
Batch 6/64 loss: 0.19879591464996338
Batch 7/64 loss: 0.20512175559997559
Batch 8/64 loss: 0.20781302452087402
Batch 9/64 loss: 0.20244884490966797
Batch 10/64 loss: 0.21776950359344482
Batch 11/64 loss: 0.20496201515197754
Batch 12/64 loss: 0.20545756816864014
Batch 13/64 loss: 0.20184636116027832
Batch 14/64 loss: 0.2066894769668579
Batch 15/64 loss: 0.21940457820892334
Batch 16/64 loss: 0.19631552696228027
Batch 17/64 loss: 0.20255732536315918
Batch 18/64 loss: 0.2122754454612732
Batch 19/64 loss: 0.19974708557128906
Batch 20/64 loss: 0.21372324228286743
Batch 21/64 loss: 0.22938627004623413
Batch 22/64 loss: 0.2273106575012207
Batch 23/64 loss: 0.20401692390441895
Batch 24/64 loss: 0.2041192650794983
Batch 25/64 loss: 0.20117151737213135
Batch 26/64 loss: 0.21687299013137817
Batch 27/64 loss: 0.21203744411468506
Batch 28/64 loss: 0.1978636384010315
Batch 29/64 loss: 0.20749914646148682
Batch 30/64 loss: 0.21707767248153687
Batch 31/64 loss: 0.19912070035934448
Batch 32/64 loss: 0.21008169651031494
Batch 33/64 loss: 0.2065179944038391
Batch 34/64 loss: 0.21452659368515015
Batch 35/64 loss: 0.2235323190689087
Batch 36/64 loss: 0.1959460973739624
Batch 37/64 loss: 0.2022801637649536
Batch 38/64 loss: 0.22229957580566406
Batch 39/64 loss: 0.21963632106781006
Batch 40/64 loss: 0.20725369453430176
Batch 41/64 loss: 0.20907998085021973
Batch 42/64 loss: 0.20162224769592285
Batch 43/64 loss: 0.19688016176223755
Batch 44/64 loss: 0.21404725313186646
Batch 45/64 loss: 0.20209527015686035
Batch 46/64 loss: 0.20498639345169067
Batch 47/64 loss: 0.2220698595046997
Batch 48/64 loss: 0.21163421869277954
Batch 49/64 loss: 0.19751954078674316
Batch 50/64 loss: 0.2177417278289795
Batch 51/64 loss: 0.20680522918701172
Batch 52/64 loss: 0.21462547779083252
Batch 53/64 loss: 0.19916558265686035
Batch 54/64 loss: 0.201729416847229
Batch 55/64 loss: 0.20706713199615479
Batch 56/64 loss: 0.21321505308151245
Batch 57/64 loss: 0.22929692268371582
Batch 58/64 loss: 0.20490938425064087
Batch 59/64 loss: 0.20019632577896118
Batch 60/64 loss: 0.2357335090637207
Batch 61/64 loss: 0.20864802598953247
Batch 62/64 loss: 0.21545493602752686
Batch 63/64 loss: 0.21808910369873047
Batch 64/64 loss: 0.2173231840133667
Epoch 317  Train loss: 0.20902635022705676  Val loss: 0.2948225077075237
Epoch 318
-------------------------------
Batch 1/64 loss: 0.20730626583099365
Batch 2/64 loss: 0.23190462589263916
Batch 3/64 loss: 0.21014952659606934
Batch 4/64 loss: 0.21969956159591675
Batch 5/64 loss: 0.20605510473251343
Batch 6/64 loss: 0.21498900651931763
Batch 7/64 loss: 0.21823453903198242
Batch 8/64 loss: 0.21196210384368896
Batch 9/64 loss: 0.2181299924850464
Batch 10/64 loss: 0.21284782886505127
Batch 11/64 loss: 0.21553558111190796
Batch 12/64 loss: 0.20655590295791626
Batch 13/64 loss: 0.2143867015838623
Batch 14/64 loss: 0.2115929126739502
Batch 15/64 loss: 0.2017400860786438
Batch 16/64 loss: 0.211833655834198
Batch 17/64 loss: 0.2154865264892578
Batch 18/64 loss: 0.21165645122528076
Batch 19/64 loss: 0.20794576406478882
Batch 20/64 loss: 0.20630109310150146
Batch 21/64 loss: 0.19688284397125244
Batch 22/64 loss: 0.21303725242614746
Batch 23/64 loss: 0.20902234315872192
Batch 24/64 loss: 0.20688438415527344
Batch 25/64 loss: 0.2050865888595581
Batch 26/64 loss: 0.2144429087638855
Batch 27/64 loss: 0.2081981897354126
Batch 28/64 loss: 0.2085564136505127
Batch 29/64 loss: 0.20966792106628418
Batch 30/64 loss: 0.20851731300354004
Batch 31/64 loss: 0.2163546085357666
Batch 32/64 loss: 0.20978903770446777
Batch 33/64 loss: 0.2075444459915161
Batch 34/64 loss: 0.2104901671409607
Batch 35/64 loss: 0.2101132869720459
Batch 36/64 loss: 0.20624279975891113
Batch 37/64 loss: 0.2108609676361084
Batch 38/64 loss: 0.21349799633026123
Batch 39/64 loss: 0.20718598365783691
Batch 40/64 loss: 0.20080792903900146
Batch 41/64 loss: 0.20600348711013794
Batch 42/64 loss: 0.20275938510894775
Batch 43/64 loss: 0.19843578338623047
Batch 44/64 loss: 0.2032378911972046
Batch 45/64 loss: 0.21935147047042847
Batch 46/64 loss: 0.22229790687561035
Batch 47/64 loss: 0.22107458114624023
Batch 48/64 loss: 0.20967155694961548
Batch 49/64 loss: 0.20159059762954712
Batch 50/64 loss: 0.20396637916564941
Batch 51/64 loss: 0.20211297273635864
Batch 52/64 loss: 0.198755145072937
Batch 53/64 loss: 0.20201420783996582
Batch 54/64 loss: 0.21897751092910767
Batch 55/64 loss: 0.2104424238204956
Batch 56/64 loss: 0.20153826475143433
Batch 57/64 loss: 0.2159721851348877
Batch 58/64 loss: 0.21540534496307373
Batch 59/64 loss: 0.20011508464813232
Batch 60/64 loss: 0.19990664720535278
Batch 61/64 loss: 0.20046091079711914
Batch 62/64 loss: 0.1980922818183899
Batch 63/64 loss: 0.21392357349395752
Batch 64/64 loss: 0.21105778217315674
Epoch 318  Train loss: 0.20944149868161072  Val loss: 0.2949110292077474
Epoch 319
-------------------------------
Batch 1/64 loss: 0.21090924739837646
Batch 2/64 loss: 0.21517008543014526
Batch 3/64 loss: 0.21051454544067383
Batch 4/64 loss: 0.20796549320220947
Batch 5/64 loss: 0.2153606414794922
Batch 6/64 loss: 0.20209968090057373
Batch 7/64 loss: 0.2208251953125
Batch 8/64 loss: 0.21964216232299805
Batch 9/64 loss: 0.20646452903747559
Batch 10/64 loss: 0.20104056596755981
Batch 11/64 loss: 0.21675634384155273
Batch 12/64 loss: 0.2103855013847351
Batch 13/64 loss: 0.2121504545211792
Batch 14/64 loss: 0.21654486656188965
Batch 15/64 loss: 0.20170176029205322
Batch 16/64 loss: 0.20705914497375488
Batch 17/64 loss: 0.20596420764923096
Batch 18/64 loss: 0.20758599042892456
Batch 19/64 loss: 0.20551681518554688
Batch 20/64 loss: 0.20290017127990723
Batch 21/64 loss: 0.20976918935775757
Batch 22/64 loss: 0.20915019512176514
Batch 23/64 loss: 0.2061862349510193
Batch 24/64 loss: 0.20801901817321777
Batch 25/64 loss: 0.2133699655532837
Batch 26/64 loss: 0.21306729316711426
Batch 27/64 loss: 0.22409594058990479
Batch 28/64 loss: 0.20701372623443604
Batch 29/64 loss: 0.20820069313049316
Batch 30/64 loss: 0.20684492588043213
Batch 31/64 loss: 0.20071107149124146
Batch 32/64 loss: 0.20594114065170288
Batch 33/64 loss: 0.20651131868362427
Batch 34/64 loss: 0.19627749919891357
Batch 35/64 loss: 0.20835494995117188
Batch 36/64 loss: 0.22575092315673828
Batch 37/64 loss: 0.19837164878845215
Batch 38/64 loss: 0.20214813947677612
Batch 39/64 loss: 0.20779263973236084
Batch 40/64 loss: 0.2156277894973755
Batch 41/64 loss: 0.20264625549316406
Batch 42/64 loss: 0.2093527913093567
Batch 43/64 loss: 0.2043921947479248
Batch 44/64 loss: 0.20590567588806152
Batch 45/64 loss: 0.21686941385269165
Batch 46/64 loss: 0.20689135789871216
Batch 47/64 loss: 0.20422029495239258
Batch 48/64 loss: 0.20873045921325684
Batch 49/64 loss: 0.19929540157318115
Batch 50/64 loss: 0.20845723152160645
Batch 51/64 loss: 0.21327942609786987
Batch 52/64 loss: 0.2081790566444397
Batch 53/64 loss: 0.21616291999816895
Batch 54/64 loss: 0.2075340747833252
Batch 55/64 loss: 0.2111985683441162
Batch 56/64 loss: 0.20078623294830322
Batch 57/64 loss: 0.2093733549118042
Batch 58/64 loss: 0.21218812465667725
Batch 59/64 loss: 0.2090279459953308
Batch 60/64 loss: 0.20185869932174683
Batch 61/64 loss: 0.19546914100646973
Batch 62/64 loss: 0.21667027473449707
Batch 63/64 loss: 0.20068061351776123
Batch 64/64 loss: 0.21206486225128174
Epoch 319  Train loss: 0.20859576253330006  Val loss: 0.2945290748606023
Epoch 320
-------------------------------
Batch 1/64 loss: 0.19794607162475586
Batch 2/64 loss: 0.20139038562774658
Batch 3/64 loss: 0.20333260297775269
Batch 4/64 loss: 0.20553183555603027
Batch 5/64 loss: 0.1978130340576172
Batch 6/64 loss: 0.212529718875885
Batch 7/64 loss: 0.2098630666732788
Batch 8/64 loss: 0.21375411748886108
Batch 9/64 loss: 0.22114968299865723
Batch 10/64 loss: 0.20124787092208862
Batch 11/64 loss: 0.21051979064941406
Batch 12/64 loss: 0.20954358577728271
Batch 13/64 loss: 0.2071624994277954
Batch 14/64 loss: 0.21194326877593994
Batch 15/64 loss: 0.21290791034698486
Batch 16/64 loss: 0.21030032634735107
Batch 17/64 loss: 0.1989343762397766
Batch 18/64 loss: 0.20665037631988525
Batch 19/64 loss: 0.20919442176818848
Batch 20/64 loss: 0.2173393964767456
Batch 21/64 loss: 0.20953530073165894
Batch 22/64 loss: 0.20246702432632446
Batch 23/64 loss: 0.21033626794815063
Batch 24/64 loss: 0.20165956020355225
Batch 25/64 loss: 0.22056496143341064
Batch 26/64 loss: 0.21005558967590332
Batch 27/64 loss: 0.20974063873291016
Batch 28/64 loss: 0.21732640266418457
Batch 29/64 loss: 0.20638823509216309
Batch 30/64 loss: 0.2016323208808899
Batch 31/64 loss: 0.21943944692611694
Batch 32/64 loss: 0.21565085649490356
Batch 33/64 loss: 0.21331965923309326
Batch 34/64 loss: 0.20950883626937866
Batch 35/64 loss: 0.20551109313964844
Batch 36/64 loss: 0.21875280141830444
Batch 37/64 loss: 0.20218384265899658
Batch 38/64 loss: 0.19961941242218018
Batch 39/64 loss: 0.20865726470947266
Batch 40/64 loss: 0.19929301738739014
Batch 41/64 loss: 0.20992565155029297
Batch 42/64 loss: 0.20796620845794678
Batch 43/64 loss: 0.19693076610565186
Batch 44/64 loss: 0.2213047742843628
Batch 45/64 loss: 0.20403516292572021
Batch 46/64 loss: 0.20605254173278809
Batch 47/64 loss: 0.19864028692245483
Batch 48/64 loss: 0.20244014263153076
Batch 49/64 loss: 0.20422232151031494
Batch 50/64 loss: 0.2165466547012329
Batch 51/64 loss: 0.2172902226448059
Batch 52/64 loss: 0.2091679573059082
Batch 53/64 loss: 0.2023119330406189
Batch 54/64 loss: 0.22814875841140747
Batch 55/64 loss: 0.21532827615737915
Batch 56/64 loss: 0.21419227123260498
Batch 57/64 loss: 0.20767277479171753
Batch 58/64 loss: 0.206595778465271
Batch 59/64 loss: 0.2004791498184204
Batch 60/64 loss: 0.20483964681625366
Batch 61/64 loss: 0.2035834789276123
Batch 62/64 loss: 0.21844112873077393
Batch 63/64 loss: 0.20013540983200073
Batch 64/64 loss: 0.20086073875427246
Epoch 320  Train loss: 0.20843284270342657  Val loss: 0.2951751484494029
Epoch 321
-------------------------------
Batch 1/64 loss: 0.20578861236572266
Batch 2/64 loss: 0.20017880201339722
Batch 3/64 loss: 0.2129497528076172
Batch 4/64 loss: 0.20086896419525146
Batch 5/64 loss: 0.22757208347320557
Batch 6/64 loss: 0.21031403541564941
Batch 7/64 loss: 0.19723141193389893
Batch 8/64 loss: 0.20837312936782837
Batch 9/64 loss: 0.2048346996307373
Batch 10/64 loss: 0.20647728443145752
Batch 11/64 loss: 0.20719623565673828
Batch 12/64 loss: 0.21656501293182373
Batch 13/64 loss: 0.2048635482788086
Batch 14/64 loss: 0.20464026927947998
Batch 15/64 loss: 0.20221829414367676
Batch 16/64 loss: 0.21496236324310303
Batch 17/64 loss: 0.21619999408721924
Batch 18/64 loss: 0.20210617780685425
Batch 19/64 loss: 0.20037609338760376
Batch 20/64 loss: 0.20888614654541016
Batch 21/64 loss: 0.21321022510528564
Batch 22/64 loss: 0.19913893938064575
Batch 23/64 loss: 0.2128623127937317
Batch 24/64 loss: 0.2144528031349182
Batch 25/64 loss: 0.20626986026763916
Batch 26/64 loss: 0.20004534721374512
Batch 27/64 loss: 0.21899890899658203
Batch 28/64 loss: 0.2146470546722412
Batch 29/64 loss: 0.21245115995407104
Batch 30/64 loss: 0.2051786184310913
Batch 31/64 loss: 0.2150365710258484
Batch 32/64 loss: 0.20482158660888672
Batch 33/64 loss: 0.19665288925170898
Batch 34/64 loss: 0.2074834108352661
Batch 35/64 loss: 0.20552915334701538
Batch 36/64 loss: 0.2179335355758667
Batch 37/64 loss: 0.2255086898803711
Batch 38/64 loss: 0.20661258697509766
Batch 39/64 loss: 0.20527732372283936
Batch 40/64 loss: 0.21371090412139893
Batch 41/64 loss: 0.21058201789855957
Batch 42/64 loss: 0.20353424549102783
Batch 43/64 loss: 0.2054259181022644
Batch 44/64 loss: 0.19827622175216675
Batch 45/64 loss: 0.20439273118972778
Batch 46/64 loss: 0.21279489994049072
Batch 47/64 loss: 0.201393723487854
Batch 48/64 loss: 0.20708513259887695
Batch 49/64 loss: 0.21425098180770874
Batch 50/64 loss: 0.2021411657333374
Batch 51/64 loss: 0.22535407543182373
Batch 52/64 loss: 0.20127594470977783
Batch 53/64 loss: 0.20415908098220825
Batch 54/64 loss: 0.20526599884033203
Batch 55/64 loss: 0.2116236686706543
Batch 56/64 loss: 0.2098652720451355
Batch 57/64 loss: 0.20666098594665527
Batch 58/64 loss: 0.20497220754623413
Batch 59/64 loss: 0.21027064323425293
Batch 60/64 loss: 0.20791184902191162
Batch 61/64 loss: 0.21446841955184937
Batch 62/64 loss: 0.20371323823928833
Batch 63/64 loss: 0.20624887943267822
Batch 64/64 loss: 0.21273326873779297
Epoch 321  Train loss: 0.20830811051761403  Val loss: 0.2950950598798667
Epoch 322
-------------------------------
Batch 1/64 loss: 0.19788312911987305
Batch 2/64 loss: 0.2078840732574463
Batch 3/64 loss: 0.21077823638916016
Batch 4/64 loss: 0.21365272998809814
Batch 5/64 loss: 0.2001599669456482
Batch 6/64 loss: 0.2037104368209839
Batch 7/64 loss: 0.19915252923965454
Batch 8/64 loss: 0.196946382522583
Batch 9/64 loss: 0.19902551174163818
Batch 10/64 loss: 0.20952564477920532
Batch 11/64 loss: 0.20494580268859863
Batch 12/64 loss: 0.20686674118041992
Batch 13/64 loss: 0.21641898155212402
Batch 14/64 loss: 0.2020477056503296
Batch 15/64 loss: 0.20510774850845337
Batch 16/64 loss: 0.21693968772888184
Batch 17/64 loss: 0.20937442779541016
Batch 18/64 loss: 0.1994839906692505
Batch 19/64 loss: 0.19736486673355103
Batch 20/64 loss: 0.21387577056884766
Batch 21/64 loss: 0.19903713464736938
Batch 22/64 loss: 0.20907557010650635
Batch 23/64 loss: 0.20402896404266357
Batch 24/64 loss: 0.2039172649383545
Batch 25/64 loss: 0.2063438892364502
Batch 26/64 loss: 0.20360612869262695
Batch 27/64 loss: 0.2262876033782959
Batch 28/64 loss: 0.2028031349182129
Batch 29/64 loss: 0.21913236379623413
Batch 30/64 loss: 0.21344727277755737
Batch 31/64 loss: 0.2069079875946045
Batch 32/64 loss: 0.2118377685546875
Batch 33/64 loss: 0.21130549907684326
Batch 34/64 loss: 0.20353400707244873
Batch 35/64 loss: 0.20741474628448486
Batch 36/64 loss: 0.20258617401123047
Batch 37/64 loss: 0.2114894986152649
Batch 38/64 loss: 0.19916468858718872
Batch 39/64 loss: 0.20896565914154053
Batch 40/64 loss: 0.20276421308517456
Batch 41/64 loss: 0.2047540545463562
Batch 42/64 loss: 0.21134984493255615
Batch 43/64 loss: 0.20458579063415527
Batch 44/64 loss: 0.201651930809021
Batch 45/64 loss: 0.20533156394958496
Batch 46/64 loss: 0.21087193489074707
Batch 47/64 loss: 0.2013697624206543
Batch 48/64 loss: 0.21379196643829346
Batch 49/64 loss: 0.21127533912658691
Batch 50/64 loss: 0.2039881944656372
Batch 51/64 loss: 0.20619630813598633
Batch 52/64 loss: 0.20656585693359375
Batch 53/64 loss: 0.22032296657562256
Batch 54/64 loss: 0.2078903317451477
Batch 55/64 loss: 0.21832770109176636
Batch 56/64 loss: 0.19958674907684326
Batch 57/64 loss: 0.21145576238632202
Batch 58/64 loss: 0.21877038478851318
Batch 59/64 loss: 0.20396745204925537
Batch 60/64 loss: 0.21114259958267212
Batch 61/64 loss: 0.20925384759902954
Batch 62/64 loss: 0.21120309829711914
Batch 63/64 loss: 0.21888196468353271
Batch 64/64 loss: 0.2064003348350525
Epoch 322  Train loss: 0.20756281707801072  Val loss: 0.2946376519924177
Epoch 323
-------------------------------
Batch 1/64 loss: 0.20434367656707764
Batch 2/64 loss: 0.20643579959869385
Batch 3/64 loss: 0.2014826536178589
Batch 4/64 loss: 0.20696711540222168
Batch 5/64 loss: 0.20339834690093994
Batch 6/64 loss: 0.20594871044158936
Batch 7/64 loss: 0.20989269018173218
Batch 8/64 loss: 0.2056332230567932
Batch 9/64 loss: 0.2143065333366394
Batch 10/64 loss: 0.2078176736831665
Batch 11/64 loss: 0.20445752143859863
Batch 12/64 loss: 0.2087610960006714
Batch 13/64 loss: 0.21186769008636475
Batch 14/64 loss: 0.2103448510169983
Batch 15/64 loss: 0.20615124702453613
Batch 16/64 loss: 0.21169334650039673
Batch 17/64 loss: 0.22325754165649414
Batch 18/64 loss: 0.2248976230621338
Batch 19/64 loss: 0.20860075950622559
Batch 20/64 loss: 0.20659637451171875
Batch 21/64 loss: 0.1994953155517578
Batch 22/64 loss: 0.20595461130142212
Batch 23/64 loss: 0.2075536847114563
Batch 24/64 loss: 0.2123100757598877
Batch 25/64 loss: 0.20469212532043457
Batch 26/64 loss: 0.21487462520599365
Batch 27/64 loss: 0.212202787399292
Batch 28/64 loss: 0.21439248323440552
Batch 29/64 loss: 0.21232235431671143
Batch 30/64 loss: 0.21215838193893433
Batch 31/64 loss: 0.2370854616165161
Batch 32/64 loss: 0.20485937595367432
Batch 33/64 loss: 0.22067254781723022
Batch 34/64 loss: 0.21402418613433838
Batch 35/64 loss: 0.1985853910446167
Batch 36/64 loss: 0.21697866916656494
Batch 37/64 loss: 0.2067631483078003
Batch 38/64 loss: 0.21568810939788818
Batch 39/64 loss: 0.2141784429550171
Batch 40/64 loss: 0.21600258350372314
Batch 41/64 loss: 0.21172523498535156
Batch 42/64 loss: 0.20785194635391235
Batch 43/64 loss: 0.2004157304763794
Batch 44/64 loss: 0.2169588804244995
Batch 45/64 loss: 0.2225726842880249
Batch 46/64 loss: 0.2025243043899536
Batch 47/64 loss: 0.2092670202255249
Batch 48/64 loss: 0.2042231559753418
Batch 49/64 loss: 0.21219784021377563
Batch 50/64 loss: 0.20481359958648682
Batch 51/64 loss: 0.1998773217201233
Batch 52/64 loss: 0.2224481701850891
Batch 53/64 loss: 0.19968247413635254
Batch 54/64 loss: 0.20891070365905762
Batch 55/64 loss: 0.20305073261260986
Batch 56/64 loss: 0.20914596319198608
Batch 57/64 loss: 0.2066887617111206
Batch 58/64 loss: 0.2040315866470337
Batch 59/64 loss: 0.2133738398551941
Batch 60/64 loss: 0.20653361082077026
Batch 61/64 loss: 0.19907206296920776
Batch 62/64 loss: 0.20595014095306396
Batch 63/64 loss: 0.20007508993148804
Batch 64/64 loss: 0.21097272634506226
Epoch 323  Train loss: 0.20946304681254369  Val loss: 0.29519433008436485
Epoch 324
-------------------------------
Batch 1/64 loss: 0.2075730562210083
Batch 2/64 loss: 0.202869713306427
Batch 3/64 loss: 0.210648775100708
Batch 4/64 loss: 0.21503162384033203
Batch 5/64 loss: 0.20648586750030518
Batch 6/64 loss: 0.21786534786224365
Batch 7/64 loss: 0.20198416709899902
Batch 8/64 loss: 0.20343512296676636
Batch 9/64 loss: 0.20790493488311768
Batch 10/64 loss: 0.20440101623535156
Batch 11/64 loss: 0.20653313398361206
Batch 12/64 loss: 0.20185089111328125
Batch 13/64 loss: 0.21210449934005737
Batch 14/64 loss: 0.19495660066604614
Batch 15/64 loss: 0.20465558767318726
Batch 16/64 loss: 0.20583009719848633
Batch 17/64 loss: 0.21994465589523315
Batch 18/64 loss: 0.20577478408813477
Batch 19/64 loss: 0.21677231788635254
Batch 20/64 loss: 0.2126806378364563
Batch 21/64 loss: 0.20430314540863037
Batch 22/64 loss: 0.2022436261177063
Batch 23/64 loss: 0.2102649211883545
Batch 24/64 loss: 0.20219027996063232
Batch 25/64 loss: 0.21220719814300537
Batch 26/64 loss: 0.2086251974105835
Batch 27/64 loss: 0.19818568229675293
Batch 28/64 loss: 0.20851624011993408
Batch 29/64 loss: 0.20096027851104736
Batch 30/64 loss: 0.22069329023361206
Batch 31/64 loss: 0.21891802549362183
Batch 32/64 loss: 0.20656037330627441
Batch 33/64 loss: 0.21313261985778809
Batch 34/64 loss: 0.21252977848052979
Batch 35/64 loss: 0.20331275463104248
Batch 36/64 loss: 0.2055143117904663
Batch 37/64 loss: 0.21334290504455566
Batch 38/64 loss: 0.20781147480010986
Batch 39/64 loss: 0.2057514786720276
Batch 40/64 loss: 0.1997133493423462
Batch 41/64 loss: 0.2013239860534668
Batch 42/64 loss: 0.20463800430297852
Batch 43/64 loss: 0.22112596035003662
Batch 44/64 loss: 0.2074505090713501
Batch 45/64 loss: 0.21040832996368408
Batch 46/64 loss: 0.21553027629852295
Batch 47/64 loss: 0.20600199699401855
Batch 48/64 loss: 0.2098759412765503
Batch 49/64 loss: 0.21853113174438477
Batch 50/64 loss: 0.2051161527633667
Batch 51/64 loss: 0.21142512559890747
Batch 52/64 loss: 0.19741547107696533
Batch 53/64 loss: 0.20315313339233398
Batch 54/64 loss: 0.2159019112586975
Batch 55/64 loss: 0.2072981595993042
Batch 56/64 loss: 0.20554107427597046
Batch 57/64 loss: 0.2073608636856079
Batch 58/64 loss: 0.2139796018600464
Batch 59/64 loss: 0.20969033241271973
Batch 60/64 loss: 0.20245659351348877
Batch 61/64 loss: 0.21467643976211548
Batch 62/64 loss: 0.19943559169769287
Batch 63/64 loss: 0.20216894149780273
Batch 64/64 loss: 0.20462828874588013
Epoch 324  Train loss: 0.2079695138276792  Val loss: 0.2949046062439987
Epoch 325
-------------------------------
Batch 1/64 loss: 0.2105938196182251
Batch 2/64 loss: 0.20039063692092896
Batch 3/64 loss: 0.20172470808029175
Batch 4/64 loss: 0.20864808559417725
Batch 5/64 loss: 0.19839417934417725
Batch 6/64 loss: 0.20975953340530396
Batch 7/64 loss: 0.2089666724205017
Batch 8/64 loss: 0.20076918601989746
Batch 9/64 loss: 0.21045416593551636
Batch 10/64 loss: 0.20188701152801514
Batch 11/64 loss: 0.19691038131713867
Batch 12/64 loss: 0.21135491132736206
Batch 13/64 loss: 0.21603870391845703
Batch 14/64 loss: 0.2037428617477417
Batch 15/64 loss: 0.21773064136505127
Batch 16/64 loss: 0.20829075574874878
Batch 17/64 loss: 0.21650242805480957
Batch 18/64 loss: 0.20770490169525146
Batch 19/64 loss: 0.2001962661743164
Batch 20/64 loss: 0.21099865436553955
Batch 21/64 loss: 0.20196610689163208
Batch 22/64 loss: 0.19896364212036133
Batch 23/64 loss: 0.2072838544845581
Batch 24/64 loss: 0.20057201385498047
Batch 25/64 loss: 0.21038895845413208
Batch 26/64 loss: 0.2132202386856079
Batch 27/64 loss: 0.21449339389801025
Batch 28/64 loss: 0.20120203495025635
Batch 29/64 loss: 0.2067110538482666
Batch 30/64 loss: 0.2042618989944458
Batch 31/64 loss: 0.2176547646522522
Batch 32/64 loss: 0.2124699354171753
Batch 33/64 loss: 0.20912086963653564
Batch 34/64 loss: 0.21179723739624023
Batch 35/64 loss: 0.20359647274017334
Batch 36/64 loss: 0.2074628472328186
Batch 37/64 loss: 0.21182924509048462
Batch 38/64 loss: 0.20527857542037964
Batch 39/64 loss: 0.21370697021484375
Batch 40/64 loss: 0.20377910137176514
Batch 41/64 loss: 0.21227532625198364
Batch 42/64 loss: 0.2140899896621704
Batch 43/64 loss: 0.21878600120544434
Batch 44/64 loss: 0.20455420017242432
Batch 45/64 loss: 0.2081305980682373
Batch 46/64 loss: 0.19752585887908936
Batch 47/64 loss: 0.2092248797416687
Batch 48/64 loss: 0.20665156841278076
Batch 49/64 loss: 0.20818710327148438
Batch 50/64 loss: 0.19646084308624268
Batch 51/64 loss: 0.19745361804962158
Batch 52/64 loss: 0.20547473430633545
Batch 53/64 loss: 0.2218136191368103
Batch 54/64 loss: 0.21378910541534424
Batch 55/64 loss: 0.21175122261047363
Batch 56/64 loss: 0.20843398571014404
Batch 57/64 loss: 0.2095034122467041
Batch 58/64 loss: 0.21000802516937256
Batch 59/64 loss: 0.2112005352973938
Batch 60/64 loss: 0.2136296033859253
Batch 61/64 loss: 0.2069045901298523
Batch 62/64 loss: 0.20856642723083496
Batch 63/64 loss: 0.2010202407836914
Batch 64/64 loss: 0.2161470651626587
Epoch 325  Train loss: 0.20791158442403757  Val loss: 0.2952466469859749
Epoch 326
-------------------------------
Batch 1/64 loss: 0.19614893198013306
Batch 2/64 loss: 0.21063727140426636
Batch 3/64 loss: 0.1979687213897705
Batch 4/64 loss: 0.2057250738143921
Batch 5/64 loss: 0.20872211456298828
Batch 6/64 loss: 0.20365488529205322
Batch 7/64 loss: 0.21357733011245728
Batch 8/64 loss: 0.2024824619293213
Batch 9/64 loss: 0.20903515815734863
Batch 10/64 loss: 0.21029692888259888
Batch 11/64 loss: 0.2026086449623108
Batch 12/64 loss: 0.21888947486877441
Batch 13/64 loss: 0.20701158046722412
Batch 14/64 loss: 0.19554728269577026
Batch 15/64 loss: 0.20827770233154297
Batch 16/64 loss: 0.22289204597473145
Batch 17/64 loss: 0.1968444585800171
Batch 18/64 loss: 0.19766950607299805
Batch 19/64 loss: 0.21182137727737427
Batch 20/64 loss: 0.21006137132644653
Batch 21/64 loss: 0.20759999752044678
Batch 22/64 loss: 0.19705355167388916
Batch 23/64 loss: 0.21987783908843994
Batch 24/64 loss: 0.20471185445785522
Batch 25/64 loss: 0.207014262676239
Batch 26/64 loss: 0.19998407363891602
Batch 27/64 loss: 0.20421022176742554
Batch 28/64 loss: 0.21303904056549072
Batch 29/64 loss: 0.2083646059036255
Batch 30/64 loss: 0.2066923975944519
Batch 31/64 loss: 0.20578986406326294
Batch 32/64 loss: 0.2109057903289795
Batch 33/64 loss: 0.2031787633895874
Batch 34/64 loss: 0.2048371434211731
Batch 35/64 loss: 0.19823193550109863
Batch 36/64 loss: 0.20644718408584595
Batch 37/64 loss: 0.19545066356658936
Batch 38/64 loss: 0.20398950576782227
Batch 39/64 loss: 0.20443379878997803
Batch 40/64 loss: 0.2121589183807373
Batch 41/64 loss: 0.21146488189697266
Batch 42/64 loss: 0.2110656499862671
Batch 43/64 loss: 0.20724642276763916
Batch 44/64 loss: 0.21092969179153442
Batch 45/64 loss: 0.20939040184020996
Batch 46/64 loss: 0.21492481231689453
Batch 47/64 loss: 0.20745772123336792
Batch 48/64 loss: 0.21487784385681152
Batch 49/64 loss: 0.21553683280944824
Batch 50/64 loss: 0.20240867137908936
Batch 51/64 loss: 0.20032304525375366
Batch 52/64 loss: 0.2244488000869751
Batch 53/64 loss: 0.2040565013885498
Batch 54/64 loss: 0.2070518136024475
Batch 55/64 loss: 0.20406317710876465
Batch 56/64 loss: 0.20528775453567505
Batch 57/64 loss: 0.20912379026412964
Batch 58/64 loss: 0.21702063083648682
Batch 59/64 loss: 0.2050614356994629
Batch 60/64 loss: 0.20081740617752075
Batch 61/64 loss: 0.21730399131774902
Batch 62/64 loss: 0.21060240268707275
Batch 63/64 loss: 0.20876836776733398
Batch 64/64 loss: 0.2081127166748047
Epoch 326  Train loss: 0.20735937754313152  Val loss: 0.29497892094641615
Epoch 327
-------------------------------
Batch 1/64 loss: 0.19903767108917236
Batch 2/64 loss: 0.20510059595108032
Batch 3/64 loss: 0.218375563621521
Batch 4/64 loss: 0.21310114860534668
Batch 5/64 loss: 0.21580731868743896
Batch 6/64 loss: 0.21580374240875244
Batch 7/64 loss: 0.2067379355430603
Batch 8/64 loss: 0.2070721983909607
Batch 9/64 loss: 0.20223784446716309
Batch 10/64 loss: 0.19215655326843262
Batch 11/64 loss: 0.20428907871246338
Batch 12/64 loss: 0.21679377555847168
Batch 13/64 loss: 0.20708656311035156
Batch 14/64 loss: 0.20723390579223633
Batch 15/64 loss: 0.20011365413665771
Batch 16/64 loss: 0.19738847017288208
Batch 17/64 loss: 0.1996399164199829
Batch 18/64 loss: 0.2119070291519165
Batch 19/64 loss: 0.2075241208076477
Batch 20/64 loss: 0.2105180025100708
Batch 21/64 loss: 0.20836114883422852
Batch 22/64 loss: 0.19944792985916138
Batch 23/64 loss: 0.2097652554512024
Batch 24/64 loss: 0.21836566925048828
Batch 25/64 loss: 0.20664995908737183
Batch 26/64 loss: 0.2133932113647461
Batch 27/64 loss: 0.20971202850341797
Batch 28/64 loss: 0.20173919200897217
Batch 29/64 loss: 0.20766985416412354
Batch 30/64 loss: 0.2024374008178711
Batch 31/64 loss: 0.19421952962875366
Batch 32/64 loss: 0.20237630605697632
Batch 33/64 loss: 0.20898252725601196
Batch 34/64 loss: 0.2042410969734192
Batch 35/64 loss: 0.20324933528900146
Batch 36/64 loss: 0.21608740091323853
Batch 37/64 loss: 0.2062055468559265
Batch 38/64 loss: 0.2052677869796753
Batch 39/64 loss: 0.21645885705947876
Batch 40/64 loss: 0.2099844217300415
Batch 41/64 loss: 0.1974639892578125
Batch 42/64 loss: 0.21213579177856445
Batch 43/64 loss: 0.21117055416107178
Batch 44/64 loss: 0.20283222198486328
Batch 45/64 loss: 0.20455628633499146
Batch 46/64 loss: 0.20157921314239502
Batch 47/64 loss: 0.2127966284751892
Batch 48/64 loss: 0.1976710557937622
Batch 49/64 loss: 0.21681886911392212
Batch 50/64 loss: 0.20080935955047607
Batch 51/64 loss: 0.20363187789916992
Batch 52/64 loss: 0.20480412244796753
Batch 53/64 loss: 0.20373356342315674
Batch 54/64 loss: 0.2016916275024414
Batch 55/64 loss: 0.21011757850646973
Batch 56/64 loss: 0.2039719820022583
Batch 57/64 loss: 0.20319843292236328
Batch 58/64 loss: 0.20476371049880981
Batch 59/64 loss: 0.2072993516921997
Batch 60/64 loss: 0.20500147342681885
Batch 61/64 loss: 0.2187739610671997
Batch 62/64 loss: 0.19981598854064941
Batch 63/64 loss: 0.20830506086349487
Batch 64/64 loss: 0.20514988899230957
Epoch 327  Train loss: 0.20657795550776462  Val loss: 0.2952756492542647
Epoch 328
-------------------------------
Batch 1/64 loss: 0.2021651268005371
Batch 2/64 loss: 0.2186163067817688
Batch 3/64 loss: 0.21707993745803833
Batch 4/64 loss: 0.2013828158378601
Batch 5/64 loss: 0.20309042930603027
Batch 6/64 loss: 0.19697368144989014
Batch 7/64 loss: 0.21669960021972656
Batch 8/64 loss: 0.20818579196929932
Batch 9/64 loss: 0.20889008045196533
Batch 10/64 loss: 0.2032146453857422
Batch 11/64 loss: 0.19841814041137695
Batch 12/64 loss: 0.20022964477539062
Batch 13/64 loss: 0.19663208723068237
Batch 14/64 loss: 0.21069037914276123
Batch 15/64 loss: 0.20758938789367676
Batch 16/64 loss: 0.21373909711837769
Batch 17/64 loss: 0.20065224170684814
Batch 18/64 loss: 0.20231688022613525
Batch 19/64 loss: 0.205885648727417
Batch 20/64 loss: 0.2014918327331543
Batch 21/64 loss: 0.20301789045333862
Batch 22/64 loss: 0.20294487476348877
Batch 23/64 loss: 0.1983323097229004
Batch 24/64 loss: 0.20737719535827637
Batch 25/64 loss: 0.20522546768188477
Batch 26/64 loss: 0.21828877925872803
Batch 27/64 loss: 0.2098400592803955
Batch 28/64 loss: 0.2112034559249878
Batch 29/64 loss: 0.21515071392059326
Batch 30/64 loss: 0.2105158567428589
Batch 31/64 loss: 0.20940780639648438
Batch 32/64 loss: 0.20226538181304932
Batch 33/64 loss: 0.21148890256881714
Batch 34/64 loss: 0.21602559089660645
Batch 35/64 loss: 0.21063637733459473
Batch 36/64 loss: 0.1988481879234314
Batch 37/64 loss: 0.2023521065711975
Batch 38/64 loss: 0.20896708965301514
Batch 39/64 loss: 0.21295344829559326
Batch 40/64 loss: 0.2032308578491211
Batch 41/64 loss: 0.2126293182373047
Batch 42/64 loss: 0.20520120859146118
Batch 43/64 loss: 0.21479010581970215
Batch 44/64 loss: 0.20298880338668823
Batch 45/64 loss: 0.21916306018829346
Batch 46/64 loss: 0.22664988040924072
Batch 47/64 loss: 0.20528924465179443
Batch 48/64 loss: 0.197149395942688
Batch 49/64 loss: 0.21465671062469482
Batch 50/64 loss: 0.20521414279937744
Batch 51/64 loss: 0.20045912265777588
Batch 52/64 loss: 0.20558929443359375
Batch 53/64 loss: 0.2113485336303711
Batch 54/64 loss: 0.20109903812408447
Batch 55/64 loss: 0.2052595019340515
Batch 56/64 loss: 0.20795589685440063
Batch 57/64 loss: 0.1988050937652588
Batch 58/64 loss: 0.20254606008529663
Batch 59/64 loss: 0.2117430567741394
Batch 60/64 loss: 0.21882957220077515
Batch 61/64 loss: 0.2042359709739685
Batch 62/64 loss: 0.2006291151046753
Batch 63/64 loss: 0.20904576778411865
Batch 64/64 loss: 0.21168142557144165
Epoch 328  Train loss: 0.20724792270099415  Val loss: 0.2947394954379891
Epoch 329
-------------------------------
Batch 1/64 loss: 0.20163756608963013
Batch 2/64 loss: 0.20695972442626953
Batch 3/64 loss: 0.1944255828857422
Batch 4/64 loss: 0.19500446319580078
Batch 5/64 loss: 0.21054702997207642
Batch 6/64 loss: 0.20419514179229736
Batch 7/64 loss: 0.20552825927734375
Batch 8/64 loss: 0.21266621351242065
Batch 9/64 loss: 0.2055603265762329
Batch 10/64 loss: 0.2069067358970642
Batch 11/64 loss: 0.20002436637878418
Batch 12/64 loss: 0.2125338315963745
Batch 13/64 loss: 0.20276474952697754
Batch 14/64 loss: 0.21070188283920288
Batch 15/64 loss: 0.204986572265625
Batch 16/64 loss: 0.19629806280136108
Batch 17/64 loss: 0.22173887491226196
Batch 18/64 loss: 0.20201414823532104
Batch 19/64 loss: 0.2064133882522583
Batch 20/64 loss: 0.20853161811828613
Batch 21/64 loss: 0.2135820984840393
Batch 22/64 loss: 0.1965700387954712
Batch 23/64 loss: 0.2095043659210205
Batch 24/64 loss: 0.2142641544342041
Batch 25/64 loss: 0.2019282579421997
Batch 26/64 loss: 0.20515626668930054
Batch 27/64 loss: 0.2050519585609436
Batch 28/64 loss: 0.20198869705200195
Batch 29/64 loss: 0.2093818187713623
Batch 30/64 loss: 0.20849698781967163
Batch 31/64 loss: 0.20419752597808838
Batch 32/64 loss: 0.20561659336090088
Batch 33/64 loss: 0.20272296667099
Batch 34/64 loss: 0.2011837363243103
Batch 35/64 loss: 0.21518856287002563
Batch 36/64 loss: 0.2060142159461975
Batch 37/64 loss: 0.20173728466033936
Batch 38/64 loss: 0.2045612335205078
Batch 39/64 loss: 0.22109925746917725
Batch 40/64 loss: 0.20585548877716064
Batch 41/64 loss: 0.2114253044128418
Batch 42/64 loss: 0.21381855010986328
Batch 43/64 loss: 0.1980276107788086
Batch 44/64 loss: 0.2111375331878662
Batch 45/64 loss: 0.22421658039093018
Batch 46/64 loss: 0.20566534996032715
Batch 47/64 loss: 0.21273326873779297
Batch 48/64 loss: 0.22638070583343506
Batch 49/64 loss: 0.2029944658279419
Batch 50/64 loss: 0.20509231090545654
Batch 51/64 loss: 0.2050660252571106
Batch 52/64 loss: 0.21220993995666504
Batch 53/64 loss: 0.202903151512146
Batch 54/64 loss: 0.20397794246673584
Batch 55/64 loss: 0.20426690578460693
Batch 56/64 loss: 0.20751118659973145
Batch 57/64 loss: 0.20943069458007812
Batch 58/64 loss: 0.21058589220046997
Batch 59/64 loss: 0.19550389051437378
Batch 60/64 loss: 0.2018139362335205
Batch 61/64 loss: 0.1977798342704773
Batch 62/64 loss: 0.2162320613861084
Batch 63/64 loss: 0.1948544979095459
Batch 64/64 loss: 0.20758986473083496
Epoch 329  Train loss: 0.20663309938767377  Val loss: 0.2956486418075168
Epoch 330
-------------------------------
Batch 1/64 loss: 0.22012102603912354
Batch 2/64 loss: 0.20643669366836548
Batch 3/64 loss: 0.21683186292648315
Batch 4/64 loss: 0.20313036441802979
Batch 5/64 loss: 0.21333688497543335
Batch 6/64 loss: 0.21336162090301514
Batch 7/64 loss: 0.19509613513946533
Batch 8/64 loss: 0.21711623668670654
Batch 9/64 loss: 0.20501255989074707
Batch 10/64 loss: 0.2178107500076294
Batch 11/64 loss: 0.1981830596923828
Batch 12/64 loss: 0.20418322086334229
Batch 13/64 loss: 0.2074800729751587
Batch 14/64 loss: 0.20621156692504883
Batch 15/64 loss: 0.19761550426483154
Batch 16/64 loss: 0.20531612634658813
Batch 17/64 loss: 0.20137113332748413
Batch 18/64 loss: 0.20228326320648193
Batch 19/64 loss: 0.20223939418792725
Batch 20/64 loss: 0.21567511558532715
Batch 21/64 loss: 0.19993847608566284
Batch 22/64 loss: 0.20299440622329712
Batch 23/64 loss: 0.2192690372467041
Batch 24/64 loss: 0.21502667665481567
Batch 25/64 loss: 0.20544779300689697
Batch 26/64 loss: 0.20313525199890137
Batch 27/64 loss: 0.20049887895584106
Batch 28/64 loss: 0.20208168029785156
Batch 29/64 loss: 0.20170354843139648
Batch 30/64 loss: 0.20844459533691406
Batch 31/64 loss: 0.21259921789169312
Batch 32/64 loss: 0.21407818794250488
Batch 33/64 loss: 0.21924829483032227
Batch 34/64 loss: 0.21624243259429932
Batch 35/64 loss: 0.20416539907455444
Batch 36/64 loss: 0.20750278234481812
Batch 37/64 loss: 0.20536071062088013
Batch 38/64 loss: 0.20283830165863037
Batch 39/64 loss: 0.21299564838409424
Batch 40/64 loss: 0.208764910697937
Batch 41/64 loss: 0.19706153869628906
Batch 42/64 loss: 0.1985163688659668
Batch 43/64 loss: 0.1993621587753296
Batch 44/64 loss: 0.20483124256134033
Batch 45/64 loss: 0.210107684135437
Batch 46/64 loss: 0.21013283729553223
Batch 47/64 loss: 0.21073710918426514
Batch 48/64 loss: 0.20974469184875488
Batch 49/64 loss: 0.2311716079711914
Batch 50/64 loss: 0.19495141506195068
Batch 51/64 loss: 0.21420085430145264
Batch 52/64 loss: 0.2022765874862671
Batch 53/64 loss: 0.21045780181884766
Batch 54/64 loss: 0.2042173147201538
Batch 55/64 loss: 0.1977671980857849
Batch 56/64 loss: 0.2082045078277588
Batch 57/64 loss: 0.21005642414093018
Batch 58/64 loss: 0.21102511882781982
Batch 59/64 loss: 0.20347237586975098
Batch 60/64 loss: 0.21248114109039307
Batch 61/64 loss: 0.19697445631027222
Batch 62/64 loss: 0.20628702640533447
Batch 63/64 loss: 0.21300292015075684
Batch 64/64 loss: 0.2046530842781067
Epoch 330  Train loss: 0.2073988865403568  Val loss: 0.2952266407176801
Epoch 331
-------------------------------
Batch 1/64 loss: 0.20767569541931152
Batch 2/64 loss: 0.20987284183502197
Batch 3/64 loss: 0.2034975290298462
Batch 4/64 loss: 0.212630033493042
Batch 5/64 loss: 0.21531909704208374
Batch 6/64 loss: 0.20252728462219238
Batch 7/64 loss: 0.20371490716934204
Batch 8/64 loss: 0.19949007034301758
Batch 9/64 loss: 0.21232670545578003
Batch 10/64 loss: 0.21086156368255615
Batch 11/64 loss: 0.20958000421524048
Batch 12/64 loss: 0.19237136840820312
Batch 13/64 loss: 0.20935648679733276
Batch 14/64 loss: 0.21201550960540771
Batch 15/64 loss: 0.20513832569122314
Batch 16/64 loss: 0.20686310529708862
Batch 17/64 loss: 0.21450448036193848
Batch 18/64 loss: 0.20536702871322632
Batch 19/64 loss: 0.20659667253494263
Batch 20/64 loss: 0.21071165800094604
Batch 21/64 loss: 0.20935213565826416
Batch 22/64 loss: 0.20217537879943848
Batch 23/64 loss: 0.21379560232162476
Batch 24/64 loss: 0.20595550537109375
Batch 25/64 loss: 0.20761078596115112
Batch 26/64 loss: 0.21601730585098267
Batch 27/64 loss: 0.20746678113937378
Batch 28/64 loss: 0.20067721605300903
Batch 29/64 loss: 0.20821315050125122
Batch 30/64 loss: 0.21106106042861938
Batch 31/64 loss: 0.20011186599731445
Batch 32/64 loss: 0.20366013050079346
Batch 33/64 loss: 0.2152692675590515
Batch 34/64 loss: 0.20076435804367065
Batch 35/64 loss: 0.200078547000885
Batch 36/64 loss: 0.21706175804138184
Batch 37/64 loss: 0.20391184091567993
Batch 38/64 loss: 0.20343756675720215
Batch 39/64 loss: 0.19654381275177002
Batch 40/64 loss: 0.22361266613006592
Batch 41/64 loss: 0.20763254165649414
Batch 42/64 loss: 0.2012348175048828
Batch 43/64 loss: 0.20358139276504517
Batch 44/64 loss: 0.2013031244277954
Batch 45/64 loss: 0.20708966255187988
Batch 46/64 loss: 0.2054210901260376
Batch 47/64 loss: 0.21487396955490112
Batch 48/64 loss: 0.1967989206314087
Batch 49/64 loss: 0.20666980743408203
Batch 50/64 loss: 0.2055063247680664
Batch 51/64 loss: 0.20550000667572021
Batch 52/64 loss: 0.20505636930465698
Batch 53/64 loss: 0.19924992322921753
Batch 54/64 loss: 0.20866382122039795
Batch 55/64 loss: 0.20859193801879883
Batch 56/64 loss: 0.2038707137107849
Batch 57/64 loss: 0.20111596584320068
Batch 58/64 loss: 0.19748663902282715
Batch 59/64 loss: 0.20644831657409668
Batch 60/64 loss: 0.19686228036880493
Batch 61/64 loss: 0.20917505025863647
Batch 62/64 loss: 0.2154063582420349
Batch 63/64 loss: 0.1920906901359558
Batch 64/64 loss: 0.2257857322692871
Epoch 331  Train loss: 0.20652809610553816  Val loss: 0.2953286928819217
Epoch 332
-------------------------------
Batch 1/64 loss: 0.1968696117401123
Batch 2/64 loss: 0.21752917766571045
Batch 3/64 loss: 0.20154273509979248
Batch 4/64 loss: 0.20298033952713013
Batch 5/64 loss: 0.20163726806640625
Batch 6/64 loss: 0.21118247509002686
Batch 7/64 loss: 0.20721352100372314
Batch 8/64 loss: 0.20778512954711914
Batch 9/64 loss: 0.19795465469360352
Batch 10/64 loss: 0.21222013235092163
Batch 11/64 loss: 0.2154940366744995
Batch 12/64 loss: 0.19543468952178955
Batch 13/64 loss: 0.21664750576019287
Batch 14/64 loss: 0.2067875862121582
Batch 15/64 loss: 0.19841277599334717
Batch 16/64 loss: 0.2203426957130432
Batch 17/64 loss: 0.20777374505996704
Batch 18/64 loss: 0.196527361869812
Batch 19/64 loss: 0.21984052658081055
Batch 20/64 loss: 0.20293200016021729
Batch 21/64 loss: 0.1987730860710144
Batch 22/64 loss: 0.2080872654914856
Batch 23/64 loss: 0.19719886779785156
Batch 24/64 loss: 0.1951897144317627
Batch 25/64 loss: 0.20805877447128296
Batch 26/64 loss: 0.2034112811088562
Batch 27/64 loss: 0.21017968654632568
Batch 28/64 loss: 0.20516884326934814
Batch 29/64 loss: 0.21807831525802612
Batch 30/64 loss: 0.21434783935546875
Batch 31/64 loss: 0.20799189805984497
Batch 32/64 loss: 0.21040832996368408
Batch 33/64 loss: 0.20850348472595215
Batch 34/64 loss: 0.20437270402908325
Batch 35/64 loss: 0.20502173900604248
Batch 36/64 loss: 0.20625168085098267
Batch 37/64 loss: 0.20118176937103271
Batch 38/64 loss: 0.20895767211914062
Batch 39/64 loss: 0.20800912380218506
Batch 40/64 loss: 0.2240227460861206
Batch 41/64 loss: 0.20072168111801147
Batch 42/64 loss: 0.2015743851661682
Batch 43/64 loss: 0.21765971183776855
Batch 44/64 loss: 0.2043207883834839
Batch 45/64 loss: 0.20453917980194092
Batch 46/64 loss: 0.2062392234802246
Batch 47/64 loss: 0.20958232879638672
Batch 48/64 loss: 0.21308821439743042
Batch 49/64 loss: 0.20302271842956543
Batch 50/64 loss: 0.20244687795639038
Batch 51/64 loss: 0.19499248266220093
Batch 52/64 loss: 0.2027187943458557
Batch 53/64 loss: 0.20902419090270996
Batch 54/64 loss: 0.20773398876190186
Batch 55/64 loss: 0.20771247148513794
Batch 56/64 loss: 0.2133641242980957
Batch 57/64 loss: 0.19778144359588623
Batch 58/64 loss: 0.20281487703323364
Batch 59/64 loss: 0.203302264213562
Batch 60/64 loss: 0.21920859813690186
Batch 61/64 loss: 0.20845454931259155
Batch 62/64 loss: 0.22091108560562134
Batch 63/64 loss: 0.2019420862197876
Batch 64/64 loss: 0.23045426607131958
Epoch 332  Train loss: 0.20715795381396424  Val loss: 0.29529216076500225
Epoch 333
-------------------------------
Batch 1/64 loss: 0.20305240154266357
Batch 2/64 loss: 0.20600128173828125
Batch 3/64 loss: 0.20878446102142334
Batch 4/64 loss: 0.21940457820892334
Batch 5/64 loss: 0.20310264825820923
Batch 6/64 loss: 0.20436698198318481
Batch 7/64 loss: 0.21044433116912842
Batch 8/64 loss: 0.2036116123199463
Batch 9/64 loss: 0.20640969276428223
Batch 10/64 loss: 0.20286798477172852
Batch 11/64 loss: 0.21389591693878174
Batch 12/64 loss: 0.2020929455757141
Batch 13/64 loss: 0.1998124122619629
Batch 14/64 loss: 0.20151430368423462
Batch 15/64 loss: 0.2000054121017456
Batch 16/64 loss: 0.20366084575653076
Batch 17/64 loss: 0.2068120241165161
Batch 18/64 loss: 0.19117414951324463
Batch 19/64 loss: 0.21414828300476074
Batch 20/64 loss: 0.20885002613067627
Batch 21/64 loss: 0.20496994256973267
Batch 22/64 loss: 0.21208816766738892
Batch 23/64 loss: 0.20423543453216553
Batch 24/64 loss: 0.21538066864013672
Batch 25/64 loss: 0.2002432942390442
Batch 26/64 loss: 0.20265883207321167
Batch 27/64 loss: 0.214074969291687
Batch 28/64 loss: 0.2089793086051941
Batch 29/64 loss: 0.20721817016601562
Batch 30/64 loss: 0.21206039190292358
Batch 31/64 loss: 0.20675265789031982
Batch 32/64 loss: 0.20326530933380127
Batch 33/64 loss: 0.20274364948272705
Batch 34/64 loss: 0.2067074179649353
Batch 35/64 loss: 0.19854474067687988
Batch 36/64 loss: 0.1995086669921875
Batch 37/64 loss: 0.22003543376922607
Batch 38/64 loss: 0.21231228113174438
Batch 39/64 loss: 0.21796482801437378
Batch 40/64 loss: 0.20772552490234375
Batch 41/64 loss: 0.20950472354888916
Batch 42/64 loss: 0.21643030643463135
Batch 43/64 loss: 0.20938074588775635
Batch 44/64 loss: 0.21737492084503174
Batch 45/64 loss: 0.21141189336776733
Batch 46/64 loss: 0.20786768198013306
Batch 47/64 loss: 0.20936107635498047
Batch 48/64 loss: 0.21028655767440796
Batch 49/64 loss: 0.21272528171539307
Batch 50/64 loss: 0.20210087299346924
Batch 51/64 loss: 0.204492449760437
Batch 52/64 loss: 0.2061731219291687
Batch 53/64 loss: 0.21694105863571167
Batch 54/64 loss: 0.2029992938041687
Batch 55/64 loss: 0.20645380020141602
Batch 56/64 loss: 0.20686697959899902
Batch 57/64 loss: 0.20055818557739258
Batch 58/64 loss: 0.20259594917297363
Batch 59/64 loss: 0.2126026153564453
Batch 60/64 loss: 0.21651816368103027
Batch 61/64 loss: 0.21641510725021362
Batch 62/64 loss: 0.20302748680114746
Batch 63/64 loss: 0.20877206325531006
Batch 64/64 loss: 0.20754241943359375
Epoch 333  Train loss: 0.2075921432644713  Val loss: 0.29517128090678213
Epoch 334
-------------------------------
Batch 1/64 loss: 0.20324015617370605
Batch 2/64 loss: 0.21094077825546265
Batch 3/64 loss: 0.20727384090423584
Batch 4/64 loss: 0.19722646474838257
Batch 5/64 loss: 0.20590251684188843
Batch 6/64 loss: 0.20729631185531616
Batch 7/64 loss: 0.21300220489501953
Batch 8/64 loss: 0.2019573450088501
Batch 9/64 loss: 0.20604169368743896
Batch 10/64 loss: 0.19875824451446533
Batch 11/64 loss: 0.21468544006347656
Batch 12/64 loss: 0.197454571723938
Batch 13/64 loss: 0.2118484377861023
Batch 14/64 loss: 0.21197491884231567
Batch 15/64 loss: 0.20934641361236572
Batch 16/64 loss: 0.2089422345161438
Batch 17/64 loss: 0.2116658091545105
Batch 18/64 loss: 0.20824474096298218
Batch 19/64 loss: 0.21810734272003174
Batch 20/64 loss: 0.20999205112457275
Batch 21/64 loss: 0.22308731079101562
Batch 22/64 loss: 0.20524513721466064
Batch 23/64 loss: 0.203369140625
Batch 24/64 loss: 0.2034069299697876
Batch 25/64 loss: 0.2103055715560913
Batch 26/64 loss: 0.2068350911140442
Batch 27/64 loss: 0.21545934677124023
Batch 28/64 loss: 0.20686036348342896
Batch 29/64 loss: 0.1972036361694336
Batch 30/64 loss: 0.20145952701568604
Batch 31/64 loss: 0.2044048309326172
Batch 32/64 loss: 0.20360374450683594
Batch 33/64 loss: 0.20154225826263428
Batch 34/64 loss: 0.21296054124832153
Batch 35/64 loss: 0.21333062648773193
Batch 36/64 loss: 0.2045438289642334
Batch 37/64 loss: 0.21134638786315918
Batch 38/64 loss: 0.20516908168792725
Batch 39/64 loss: 0.20573514699935913
Batch 40/64 loss: 0.2004786729812622
Batch 41/64 loss: 0.20085811614990234
Batch 42/64 loss: 0.2181706428527832
Batch 43/64 loss: 0.2052137851715088
Batch 44/64 loss: 0.20672845840454102
Batch 45/64 loss: 0.20574545860290527
Batch 46/64 loss: 0.20547330379486084
Batch 47/64 loss: 0.20179152488708496
Batch 48/64 loss: 0.21430999040603638
Batch 49/64 loss: 0.2043129801750183
Batch 50/64 loss: 0.20645374059677124
Batch 51/64 loss: 0.21852457523345947
Batch 52/64 loss: 0.19485777616500854
Batch 53/64 loss: 0.19855690002441406
Batch 54/64 loss: 0.2010347843170166
Batch 55/64 loss: 0.19954335689544678
Batch 56/64 loss: 0.1941542625427246
Batch 57/64 loss: 0.22274476289749146
Batch 58/64 loss: 0.21569067239761353
Batch 59/64 loss: 0.20497673749923706
Batch 60/64 loss: 0.20052284002304077
Batch 61/64 loss: 0.20638859272003174
Batch 62/64 loss: 0.20393586158752441
Batch 63/64 loss: 0.20594114065170288
Batch 64/64 loss: 0.20590895414352417
Epoch 334  Train loss: 0.20675467720218732  Val loss: 0.2948566945557742
Epoch 335
-------------------------------
Batch 1/64 loss: 0.20279252529144287
Batch 2/64 loss: 0.20645767450332642
Batch 3/64 loss: 0.2074800729751587
Batch 4/64 loss: 0.2043660283088684
Batch 5/64 loss: 0.20800119638442993
Batch 6/64 loss: 0.2028740644454956
Batch 7/64 loss: 0.20117592811584473
Batch 8/64 loss: 0.20663344860076904
Batch 9/64 loss: 0.19992291927337646
Batch 10/64 loss: 0.20943987369537354
Batch 11/64 loss: 0.2001742720603943
Batch 12/64 loss: 0.19333231449127197
Batch 13/64 loss: 0.2093418836593628
Batch 14/64 loss: 0.21146583557128906
Batch 15/64 loss: 0.2070462703704834
Batch 16/64 loss: 0.20450317859649658
Batch 17/64 loss: 0.21295082569122314
Batch 18/64 loss: 0.21442198753356934
Batch 19/64 loss: 0.19160765409469604
Batch 20/64 loss: 0.21214288473129272
Batch 21/64 loss: 0.20578473806381226
Batch 22/64 loss: 0.201155424118042
Batch 23/64 loss: 0.20097815990447998
Batch 24/64 loss: 0.19882619380950928
Batch 25/64 loss: 0.19966024160385132
Batch 26/64 loss: 0.2107563614845276
Batch 27/64 loss: 0.21544432640075684
Batch 28/64 loss: 0.21207010746002197
Batch 29/64 loss: 0.2143392562866211
Batch 30/64 loss: 0.20761948823928833
Batch 31/64 loss: 0.20284634828567505
Batch 32/64 loss: 0.2187725305557251
Batch 33/64 loss: 0.20183712244033813
Batch 34/64 loss: 0.20064616203308105
Batch 35/64 loss: 0.2037956714630127
Batch 36/64 loss: 0.21209049224853516
Batch 37/64 loss: 0.20711326599121094
Batch 38/64 loss: 0.2048879861831665
Batch 39/64 loss: 0.20467841625213623
Batch 40/64 loss: 0.20332610607147217
Batch 41/64 loss: 0.23044949769973755
Batch 42/64 loss: 0.2073596715927124
Batch 43/64 loss: 0.2011844515800476
Batch 44/64 loss: 0.2110666036605835
Batch 45/64 loss: 0.2075333595275879
Batch 46/64 loss: 0.2096397876739502
Batch 47/64 loss: 0.2099853754043579
Batch 48/64 loss: 0.19789087772369385
Batch 49/64 loss: 0.21396994590759277
Batch 50/64 loss: 0.20757585763931274
Batch 51/64 loss: 0.20159626007080078
Batch 52/64 loss: 0.21100777387619019
Batch 53/64 loss: 0.21277999877929688
Batch 54/64 loss: 0.19807493686676025
Batch 55/64 loss: 0.20379477739334106
Batch 56/64 loss: 0.20204567909240723
Batch 57/64 loss: 0.19400346279144287
Batch 58/64 loss: 0.20416784286499023
Batch 59/64 loss: 0.21124231815338135
Batch 60/64 loss: 0.20520782470703125
Batch 61/64 loss: 0.21271753311157227
Batch 62/64 loss: 0.20966053009033203
Batch 63/64 loss: 0.19888818264007568
Batch 64/64 loss: 0.22263294458389282
Epoch 335  Train loss: 0.20645610187567917  Val loss: 0.29463299914324
Epoch 336
-------------------------------
Batch 1/64 loss: 0.21223461627960205
Batch 2/64 loss: 0.20782262086868286
Batch 3/64 loss: 0.2067117691040039
Batch 4/64 loss: 0.21440351009368896
Batch 5/64 loss: 0.2140822410583496
Batch 6/64 loss: 0.21158069372177124
Batch 7/64 loss: 0.20808684825897217
Batch 8/64 loss: 0.20153123140335083
Batch 9/64 loss: 0.20229053497314453
Batch 10/64 loss: 0.20433390140533447
Batch 11/64 loss: 0.21509313583374023
Batch 12/64 loss: 0.21215355396270752
Batch 13/64 loss: 0.2014855146408081
Batch 14/64 loss: 0.20314514636993408
Batch 15/64 loss: 0.20032405853271484
Batch 16/64 loss: 0.19735801219940186
Batch 17/64 loss: 0.2000531554222107
Batch 18/64 loss: 0.20840811729431152
Batch 19/64 loss: 0.20926165580749512
Batch 20/64 loss: 0.2035083770751953
Batch 21/64 loss: 0.21212637424468994
Batch 22/64 loss: 0.20171600580215454
Batch 23/64 loss: 0.20366519689559937
Batch 24/64 loss: 0.19777584075927734
Batch 25/64 loss: 0.20324385166168213
Batch 26/64 loss: 0.20625388622283936
Batch 27/64 loss: 0.201030433177948
Batch 28/64 loss: 0.19921410083770752
Batch 29/64 loss: 0.2074030041694641
Batch 30/64 loss: 0.1964489221572876
Batch 31/64 loss: 0.2034246325492859
Batch 32/64 loss: 0.20591521263122559
Batch 33/64 loss: 0.20618826150894165
Batch 34/64 loss: 0.20151793956756592
Batch 35/64 loss: 0.21454983949661255
Batch 36/64 loss: 0.2038356065750122
Batch 37/64 loss: 0.20668327808380127
Batch 38/64 loss: 0.20433557033538818
Batch 39/64 loss: 0.20505249500274658
Batch 40/64 loss: 0.20453345775604248
Batch 41/64 loss: 0.20128387212753296
Batch 42/64 loss: 0.20923876762390137
Batch 43/64 loss: 0.20812571048736572
Batch 44/64 loss: 0.20475983619689941
Batch 45/64 loss: 0.20710361003875732
Batch 46/64 loss: 0.19785338640213013
Batch 47/64 loss: 0.20534467697143555
Batch 48/64 loss: 0.2125694751739502
Batch 49/64 loss: 0.1975386142730713
Batch 50/64 loss: 0.20529842376708984
Batch 51/64 loss: 0.20547223091125488
Batch 52/64 loss: 0.21462011337280273
Batch 53/64 loss: 0.22588366270065308
Batch 54/64 loss: 0.20762068033218384
Batch 55/64 loss: 0.20317047834396362
Batch 56/64 loss: 0.20941317081451416
Batch 57/64 loss: 0.2041182518005371
Batch 58/64 loss: 0.1985682249069214
Batch 59/64 loss: 0.20410370826721191
Batch 60/64 loss: 0.22617018222808838
Batch 61/64 loss: 0.20950555801391602
Batch 62/64 loss: 0.22165381908416748
Batch 63/64 loss: 0.19955849647521973
Batch 64/64 loss: 0.20902973413467407
Epoch 336  Train loss: 0.2063455663475336  Val loss: 0.29516198667873633
Epoch 337
-------------------------------
Batch 1/64 loss: 0.20954066514968872
Batch 2/64 loss: 0.2078016996383667
Batch 3/64 loss: 0.2075454592704773
Batch 4/64 loss: 0.21874260902404785
Batch 5/64 loss: 0.20713990926742554
Batch 6/64 loss: 0.21586120128631592
Batch 7/64 loss: 0.20927971601486206
Batch 8/64 loss: 0.20675444602966309
Batch 9/64 loss: 0.19195735454559326
Batch 10/64 loss: 0.19957208633422852
Batch 11/64 loss: 0.20740628242492676
Batch 12/64 loss: 0.21245217323303223
Batch 13/64 loss: 0.20762217044830322
Batch 14/64 loss: 0.20480948686599731
Batch 15/64 loss: 0.20768582820892334
Batch 16/64 loss: 0.21151667833328247
Batch 17/64 loss: 0.2086278796195984
Batch 18/64 loss: 0.2117285132408142
Batch 19/64 loss: 0.2039017677307129
Batch 20/64 loss: 0.20738840103149414
Batch 21/64 loss: 0.20662736892700195
Batch 22/64 loss: 0.19500243663787842
Batch 23/64 loss: 0.20854443311691284
Batch 24/64 loss: 0.20366209745407104
Batch 25/64 loss: 0.20371651649475098
Batch 26/64 loss: 0.2064768671989441
Batch 27/64 loss: 0.19820988178253174
Batch 28/64 loss: 0.1985912322998047
Batch 29/64 loss: 0.21496200561523438
Batch 30/64 loss: 0.2072170376777649
Batch 31/64 loss: 0.20390552282333374
Batch 32/64 loss: 0.20390987396240234
Batch 33/64 loss: 0.2079581618309021
Batch 34/64 loss: 0.20777612924575806
Batch 35/64 loss: 0.20624548196792603
Batch 36/64 loss: 0.20330703258514404
Batch 37/64 loss: 0.22091269493103027
Batch 38/64 loss: 0.20775246620178223
Batch 39/64 loss: 0.2024930715560913
Batch 40/64 loss: 0.20281517505645752
Batch 41/64 loss: 0.20583033561706543
Batch 42/64 loss: 0.20731675624847412
Batch 43/64 loss: 0.2112172245979309
Batch 44/64 loss: 0.20739781856536865
Batch 45/64 loss: 0.20259207487106323
Batch 46/64 loss: 0.20198380947113037
Batch 47/64 loss: 0.19611668586730957
Batch 48/64 loss: 0.2042480707168579
Batch 49/64 loss: 0.2057449221611023
Batch 50/64 loss: 0.21034550666809082
Batch 51/64 loss: 0.2120281457901001
Batch 52/64 loss: 0.20176434516906738
Batch 53/64 loss: 0.20798075199127197
Batch 54/64 loss: 0.20954227447509766
Batch 55/64 loss: 0.20427894592285156
Batch 56/64 loss: 0.2110559344291687
Batch 57/64 loss: 0.20186150074005127
Batch 58/64 loss: 0.2065049409866333
Batch 59/64 loss: 0.1989869475364685
Batch 60/64 loss: 0.21075332164764404
Batch 61/64 loss: 0.20653319358825684
Batch 62/64 loss: 0.20354384183883667
Batch 63/64 loss: 0.20898258686065674
Batch 64/64 loss: 0.2014818787574768
Epoch 337  Train loss: 0.20635515544928756  Val loss: 0.2953140924067022
Epoch 338
-------------------------------
Batch 1/64 loss: 0.20254909992218018
Batch 2/64 loss: 0.2112666368484497
Batch 3/64 loss: 0.20505452156066895
Batch 4/64 loss: 0.21365368366241455
Batch 5/64 loss: 0.18971174955368042
Batch 6/64 loss: 0.2093331217765808
Batch 7/64 loss: 0.20328742265701294
Batch 8/64 loss: 0.20434564352035522
Batch 9/64 loss: 0.20703434944152832
Batch 10/64 loss: 0.20845019817352295
Batch 11/64 loss: 0.21157020330429077
Batch 12/64 loss: 0.23120224475860596
Batch 13/64 loss: 0.1957220435142517
Batch 14/64 loss: 0.21546125411987305
Batch 15/64 loss: 0.21060490608215332
Batch 16/64 loss: 0.2009040117263794
Batch 17/64 loss: 0.20415008068084717
Batch 18/64 loss: 0.20133864879608154
Batch 19/64 loss: 0.2113627791404724
Batch 20/64 loss: 0.20590204000473022
Batch 21/64 loss: 0.20821964740753174
Batch 22/64 loss: 0.2017226219177246
Batch 23/64 loss: 0.20577174425125122
Batch 24/64 loss: 0.22246479988098145
Batch 25/64 loss: 0.20293909311294556
Batch 26/64 loss: 0.20223915576934814
Batch 27/64 loss: 0.19736886024475098
Batch 28/64 loss: 0.19149577617645264
Batch 29/64 loss: 0.20517098903656006
Batch 30/64 loss: 0.20486795902252197
Batch 31/64 loss: 0.2085108757019043
Batch 32/64 loss: 0.19739490747451782
Batch 33/64 loss: 0.21291124820709229
Batch 34/64 loss: 0.20437276363372803
Batch 35/64 loss: 0.20733284950256348
Batch 36/64 loss: 0.21220707893371582
Batch 37/64 loss: 0.19468003511428833
Batch 38/64 loss: 0.20645606517791748
Batch 39/64 loss: 0.2150530219078064
Batch 40/64 loss: 0.1893966794013977
Batch 41/64 loss: 0.1983523964881897
Batch 42/64 loss: 0.21426928043365479
Batch 43/64 loss: 0.21938848495483398
Batch 44/64 loss: 0.202894926071167
Batch 45/64 loss: 0.20996159315109253
Batch 46/64 loss: 0.20266902446746826
Batch 47/64 loss: 0.21427500247955322
Batch 48/64 loss: 0.193747878074646
Batch 49/64 loss: 0.2128431797027588
Batch 50/64 loss: 0.20315438508987427
Batch 51/64 loss: 0.20954763889312744
Batch 52/64 loss: 0.19930928945541382
Batch 53/64 loss: 0.2284400463104248
Batch 54/64 loss: 0.2004266381263733
Batch 55/64 loss: 0.2077021598815918
Batch 56/64 loss: 0.21330583095550537
Batch 57/64 loss: 0.20578396320343018
Batch 58/64 loss: 0.19528961181640625
Batch 59/64 loss: 0.20846301317214966
Batch 60/64 loss: 0.21127218008041382
Batch 61/64 loss: 0.2094171643257141
Batch 62/64 loss: 0.20533418655395508
Batch 63/64 loss: 0.21915751695632935
Batch 64/64 loss: 0.20649081468582153
Epoch 338  Train loss: 0.20664085196513757  Val loss: 0.29558647047613085
Epoch 339
-------------------------------
Batch 1/64 loss: 0.19815433025360107
Batch 2/64 loss: 0.19507348537445068
Batch 3/64 loss: 0.2014116644859314
Batch 4/64 loss: 0.20874547958374023
Batch 5/64 loss: 0.22050046920776367
Batch 6/64 loss: 0.20664697885513306
Batch 7/64 loss: 0.19960010051727295
Batch 8/64 loss: 0.19325196743011475
Batch 9/64 loss: 0.21217989921569824
Batch 10/64 loss: 0.20993101596832275
Batch 11/64 loss: 0.20526480674743652
Batch 12/64 loss: 0.20052671432495117
Batch 13/64 loss: 0.2193772792816162
Batch 14/64 loss: 0.20145004987716675
Batch 15/64 loss: 0.2094154953956604
Batch 16/64 loss: 0.20395606756210327
Batch 17/64 loss: 0.2046259045600891
Batch 18/64 loss: 0.2212049961090088
Batch 19/64 loss: 0.21654868125915527
Batch 20/64 loss: 0.20367521047592163
Batch 21/64 loss: 0.19486331939697266
Batch 22/64 loss: 0.22031033039093018
Batch 23/64 loss: 0.21516555547714233
Batch 24/64 loss: 0.2018033266067505
Batch 25/64 loss: 0.20741045475006104
Batch 26/64 loss: 0.20429837703704834
Batch 27/64 loss: 0.20181328058242798
Batch 28/64 loss: 0.2134365439414978
Batch 29/64 loss: 0.2028709053993225
Batch 30/64 loss: 0.20712757110595703
Batch 31/64 loss: 0.19884109497070312
Batch 32/64 loss: 0.19830429553985596
Batch 33/64 loss: 0.19756466150283813
Batch 34/64 loss: 0.20454734563827515
Batch 35/64 loss: 0.20050585269927979
Batch 36/64 loss: 0.20415735244750977
Batch 37/64 loss: 0.19867324829101562
Batch 38/64 loss: 0.2050248384475708
Batch 39/64 loss: 0.20238876342773438
Batch 40/64 loss: 0.20449012517929077
Batch 41/64 loss: 0.18856960535049438
Batch 42/64 loss: 0.19732868671417236
Batch 43/64 loss: 0.20609188079833984
Batch 44/64 loss: 0.20216572284698486
Batch 45/64 loss: 0.1931285262107849
Batch 46/64 loss: 0.2103978991508484
Batch 47/64 loss: 0.20123815536499023
Batch 48/64 loss: 0.22304534912109375
Batch 49/64 loss: 0.1987518072128296
Batch 50/64 loss: 0.20726722478866577
Batch 51/64 loss: 0.20913207530975342
Batch 52/64 loss: 0.20076000690460205
Batch 53/64 loss: 0.2018110752105713
Batch 54/64 loss: 0.19981825351715088
Batch 55/64 loss: 0.197770893573761
Batch 56/64 loss: 0.21314501762390137
Batch 57/64 loss: 0.21085667610168457
Batch 58/64 loss: 0.21690130233764648
Batch 59/64 loss: 0.2089623212814331
Batch 60/64 loss: 0.19690096378326416
Batch 61/64 loss: 0.20289087295532227
Batch 62/64 loss: 0.20814496278762817
Batch 63/64 loss: 0.20473265647888184
Batch 64/64 loss: 0.2075788974761963
Epoch 339  Train loss: 0.20502955212312587  Val loss: 0.2958001844661752
Epoch 340
-------------------------------
Batch 1/64 loss: 0.20230317115783691
Batch 2/64 loss: 0.2136722207069397
Batch 3/64 loss: 0.19981658458709717
Batch 4/64 loss: 0.20484226942062378
Batch 5/64 loss: 0.2119077444076538
Batch 6/64 loss: 0.20083928108215332
Batch 7/64 loss: 0.196533203125
Batch 8/64 loss: 0.21601462364196777
Batch 9/64 loss: 0.19932639598846436
Batch 10/64 loss: 0.19114965200424194
Batch 11/64 loss: 0.1962764859199524
Batch 12/64 loss: 0.20622122287750244
Batch 13/64 loss: 0.2089110016822815
Batch 14/64 loss: 0.20468354225158691
Batch 15/64 loss: 0.21655094623565674
Batch 16/64 loss: 0.20151400566101074
Batch 17/64 loss: 0.1985539197921753
Batch 18/64 loss: 0.2006450891494751
Batch 19/64 loss: 0.21937471628189087
Batch 20/64 loss: 0.20751863718032837
Batch 21/64 loss: 0.19411849975585938
Batch 22/64 loss: 0.21040892601013184
Batch 23/64 loss: 0.2011358141899109
Batch 24/64 loss: 0.19964200258255005
Batch 25/64 loss: 0.20286965370178223
Batch 26/64 loss: 0.201765775680542
Batch 27/64 loss: 0.21732568740844727
Batch 28/64 loss: 0.20678699016571045
Batch 29/64 loss: 0.20190507173538208
Batch 30/64 loss: 0.20695245265960693
Batch 31/64 loss: 0.21592670679092407
Batch 32/64 loss: 0.19194871187210083
Batch 33/64 loss: 0.19515472650527954
Batch 34/64 loss: 0.20319747924804688
Batch 35/64 loss: 0.20485007762908936
Batch 36/64 loss: 0.20872211456298828
Batch 37/64 loss: 0.2014508843421936
Batch 38/64 loss: 0.20852923393249512
Batch 39/64 loss: 0.20188230276107788
Batch 40/64 loss: 0.19927191734313965
Batch 41/64 loss: 0.2098081111907959
Batch 42/64 loss: 0.2161586880683899
Batch 43/64 loss: 0.19973492622375488
Batch 44/64 loss: 0.2086796760559082
Batch 45/64 loss: 0.20523786544799805
Batch 46/64 loss: 0.21361225843429565
Batch 47/64 loss: 0.2080169916152954
Batch 48/64 loss: 0.20546674728393555
Batch 49/64 loss: 0.2119079828262329
Batch 50/64 loss: 0.19503462314605713
Batch 51/64 loss: 0.20489561557769775
Batch 52/64 loss: 0.2067074179649353
Batch 53/64 loss: 0.1937161684036255
Batch 54/64 loss: 0.19526320695877075
Batch 55/64 loss: 0.20055615901947021
Batch 56/64 loss: 0.22015392780303955
Batch 57/64 loss: 0.2105398178100586
Batch 58/64 loss: 0.19639229774475098
Batch 59/64 loss: 0.20283502340316772
Batch 60/64 loss: 0.201696515083313
Batch 61/64 loss: 0.2036799192428589
Batch 62/64 loss: 0.20681464672088623
Batch 63/64 loss: 0.20874762535095215
Batch 64/64 loss: 0.20615839958190918
Epoch 340  Train loss: 0.20471803534264657  Val loss: 0.2954624997791146
Epoch 341
-------------------------------
Batch 1/64 loss: 0.20479637384414673
Batch 2/64 loss: 0.2039703130722046
Batch 3/64 loss: 0.20550012588500977
Batch 4/64 loss: 0.2134690284729004
Batch 5/64 loss: 0.21307265758514404
Batch 6/64 loss: 0.20541739463806152
Batch 7/64 loss: 0.20231473445892334
Batch 8/64 loss: 0.2174210548400879
Batch 9/64 loss: 0.20991909503936768
Batch 10/64 loss: 0.2020295262336731
Batch 11/64 loss: 0.21000880002975464
Batch 12/64 loss: 0.19826459884643555
Batch 13/64 loss: 0.21121340990066528
Batch 14/64 loss: 0.2125747799873352
Batch 15/64 loss: 0.19869887828826904
Batch 16/64 loss: 0.21006399393081665
Batch 17/64 loss: 0.20955777168273926
Batch 18/64 loss: 0.19703245162963867
Batch 19/64 loss: 0.2094806432723999
Batch 20/64 loss: 0.199856698513031
Batch 21/64 loss: 0.2007155418395996
Batch 22/64 loss: 0.19744765758514404
Batch 23/64 loss: 0.20374655723571777
Batch 24/64 loss: 0.198874831199646
Batch 25/64 loss: 0.20477885007858276
Batch 26/64 loss: 0.20884132385253906
Batch 27/64 loss: 0.19734656810760498
Batch 28/64 loss: 0.20836591720581055
Batch 29/64 loss: 0.21227532625198364
Batch 30/64 loss: 0.20244824886322021
Batch 31/64 loss: 0.19616377353668213
Batch 32/64 loss: 0.2062849998474121
Batch 33/64 loss: 0.19662225246429443
Batch 34/64 loss: 0.21245431900024414
Batch 35/64 loss: 0.18498539924621582
Batch 36/64 loss: 0.1973191499710083
Batch 37/64 loss: 0.2080497145652771
Batch 38/64 loss: 0.20371294021606445
Batch 39/64 loss: 0.20533472299575806
Batch 40/64 loss: 0.19989538192749023
Batch 41/64 loss: 0.20144063234329224
Batch 42/64 loss: 0.2062842845916748
Batch 43/64 loss: 0.20071637630462646
Batch 44/64 loss: 0.21575677394866943
Batch 45/64 loss: 0.20123815536499023
Batch 46/64 loss: 0.19963133335113525
Batch 47/64 loss: 0.1899813413619995
Batch 48/64 loss: 0.21778863668441772
Batch 49/64 loss: 0.2093990445137024
Batch 50/64 loss: 0.2049887776374817
Batch 51/64 loss: 0.20867937803268433
Batch 52/64 loss: 0.20154982805252075
Batch 53/64 loss: 0.21654373407363892
Batch 54/64 loss: 0.1961498260498047
Batch 55/64 loss: 0.20004791021347046
Batch 56/64 loss: 0.2007201910018921
Batch 57/64 loss: 0.2083972692489624
Batch 58/64 loss: 0.20449382066726685
Batch 59/64 loss: 0.20514780282974243
Batch 60/64 loss: 0.20048093795776367
Batch 61/64 loss: 0.201524019241333
Batch 62/64 loss: 0.21101731061935425
Batch 63/64 loss: 0.22362983226776123
Batch 64/64 loss: 0.22713613510131836
Epoch 341  Train loss: 0.20511819802078546  Val loss: 0.2952864053323097
Epoch 342
-------------------------------
Batch 1/64 loss: 0.20457369089126587
Batch 2/64 loss: 0.20283722877502441
Batch 3/64 loss: 0.20586037635803223
Batch 4/64 loss: 0.2099066972732544
Batch 5/64 loss: 0.1968553066253662
Batch 6/64 loss: 0.20330750942230225
Batch 7/64 loss: 0.20742303133010864
Batch 8/64 loss: 0.21116596460342407
Batch 9/64 loss: 0.198614239692688
Batch 10/64 loss: 0.20797234773635864
Batch 11/64 loss: 0.19676655530929565
Batch 12/64 loss: 0.21019798517227173
Batch 13/64 loss: 0.20659363269805908
Batch 14/64 loss: 0.19990062713623047
Batch 15/64 loss: 0.19924980401992798
Batch 16/64 loss: 0.19965946674346924
Batch 17/64 loss: 0.19502496719360352
Batch 18/64 loss: 0.21608150005340576
Batch 19/64 loss: 0.20662903785705566
Batch 20/64 loss: 0.20707684755325317
Batch 21/64 loss: 0.2093503475189209
Batch 22/64 loss: 0.19899237155914307
Batch 23/64 loss: 0.19334018230438232
Batch 24/64 loss: 0.20730876922607422
Batch 25/64 loss: 0.19893097877502441
Batch 26/64 loss: 0.20078527927398682
Batch 27/64 loss: 0.19820916652679443
Batch 28/64 loss: 0.21361321210861206
Batch 29/64 loss: 0.21247851848602295
Batch 30/64 loss: 0.1951039433479309
Batch 31/64 loss: 0.20118260383605957
Batch 32/64 loss: 0.18957239389419556
Batch 33/64 loss: 0.2064914107322693
Batch 34/64 loss: 0.20384705066680908
Batch 35/64 loss: 0.2048758864402771
Batch 36/64 loss: 0.2089296579360962
Batch 37/64 loss: 0.22161638736724854
Batch 38/64 loss: 0.19798004627227783
Batch 39/64 loss: 0.20320677757263184
Batch 40/64 loss: 0.21229928731918335
Batch 41/64 loss: 0.19464725255966187
Batch 42/64 loss: 0.2058383822441101
Batch 43/64 loss: 0.19582366943359375
Batch 44/64 loss: 0.20568597316741943
Batch 45/64 loss: 0.2008610963821411
Batch 46/64 loss: 0.20953023433685303
Batch 47/64 loss: 0.20970773696899414
Batch 48/64 loss: 0.20231664180755615
Batch 49/64 loss: 0.21350783109664917
Batch 50/64 loss: 0.21570008993148804
Batch 51/64 loss: 0.20448893308639526
Batch 52/64 loss: 0.1986759901046753
Batch 53/64 loss: 0.20356571674346924
Batch 54/64 loss: 0.1994023323059082
Batch 55/64 loss: 0.21019208431243896
Batch 56/64 loss: 0.19513678550720215
Batch 57/64 loss: 0.1999770998954773
Batch 58/64 loss: 0.19985151290893555
Batch 59/64 loss: 0.21284723281860352
Batch 60/64 loss: 0.20701777935028076
Batch 61/64 loss: 0.2015405297279358
Batch 62/64 loss: 0.20602262020111084
Batch 63/64 loss: 0.2063138484954834
Batch 64/64 loss: 0.2041480541229248
Epoch 342  Train loss: 0.20416585884842217  Val loss: 0.29539676568762135
Epoch 343
-------------------------------
Batch 1/64 loss: 0.19859635829925537
Batch 2/64 loss: 0.20702683925628662
Batch 3/64 loss: 0.19608980417251587
Batch 4/64 loss: 0.214971661567688
Batch 5/64 loss: 0.2047663927078247
Batch 6/64 loss: 0.20535814762115479
Batch 7/64 loss: 0.20944744348526
Batch 8/64 loss: 0.20846718549728394
Batch 9/64 loss: 0.19090932607650757
Batch 10/64 loss: 0.20804548263549805
Batch 11/64 loss: 0.2007739543914795
Batch 12/64 loss: 0.20925581455230713
Batch 13/64 loss: 0.2090233564376831
Batch 14/64 loss: 0.19739389419555664
Batch 15/64 loss: 0.21073371171951294
Batch 16/64 loss: 0.21524262428283691
Batch 17/64 loss: 0.20149123668670654
Batch 18/64 loss: 0.20684558153152466
Batch 19/64 loss: 0.2034395933151245
Batch 20/64 loss: 0.20367968082427979
Batch 21/64 loss: 0.19649100303649902
Batch 22/64 loss: 0.20580744743347168
Batch 23/64 loss: 0.1970435380935669
Batch 24/64 loss: 0.2054460048675537
Batch 25/64 loss: 0.2005130648612976
Batch 26/64 loss: 0.20165061950683594
Batch 27/64 loss: 0.21898424625396729
Batch 28/64 loss: 0.18763315677642822
Batch 29/64 loss: 0.21574312448501587
Batch 30/64 loss: 0.2049807906150818
Batch 31/64 loss: 0.205535888671875
Batch 32/64 loss: 0.2010406255722046
Batch 33/64 loss: 0.21031200885772705
Batch 34/64 loss: 0.20141923427581787
Batch 35/64 loss: 0.20073574781417847
Batch 36/64 loss: 0.207020103931427
Batch 37/64 loss: 0.20563137531280518
Batch 38/64 loss: 0.20099925994873047
Batch 39/64 loss: 0.19867044687271118
Batch 40/64 loss: 0.20159989595413208
Batch 41/64 loss: 0.21313750743865967
Batch 42/64 loss: 0.19900977611541748
Batch 43/64 loss: 0.19524121284484863
Batch 44/64 loss: 0.2001035213470459
Batch 45/64 loss: 0.2228880524635315
Batch 46/64 loss: 0.2007770538330078
Batch 47/64 loss: 0.22020459175109863
Batch 48/64 loss: 0.20502960681915283
Batch 49/64 loss: 0.19689297676086426
Batch 50/64 loss: 0.20693159103393555
Batch 51/64 loss: 0.19937103986740112
Batch 52/64 loss: 0.2006998062133789
Batch 53/64 loss: 0.20190328359603882
Batch 54/64 loss: 0.2197585105895996
Batch 55/64 loss: 0.1977759599685669
Batch 56/64 loss: 0.20193058252334595
Batch 57/64 loss: 0.19774866104125977
Batch 58/64 loss: 0.19988059997558594
Batch 59/64 loss: 0.21149873733520508
Batch 60/64 loss: 0.20386123657226562
Batch 61/64 loss: 0.22701483964920044
Batch 62/64 loss: 0.195229172706604
Batch 63/64 loss: 0.20066988468170166
Batch 64/64 loss: 0.20083236694335938
Epoch 343  Train loss: 0.20450193180757412  Val loss: 0.29527472118331805
Epoch 344
-------------------------------
Batch 1/64 loss: 0.2001233696937561
Batch 2/64 loss: 0.19759660959243774
Batch 3/64 loss: 0.20431828498840332
Batch 4/64 loss: 0.19359201192855835
Batch 5/64 loss: 0.19639289379119873
Batch 6/64 loss: 0.21916747093200684
Batch 7/64 loss: 0.19991141557693481
Batch 8/64 loss: 0.20779883861541748
Batch 9/64 loss: 0.20312225818634033
Batch 10/64 loss: 0.21261954307556152
Batch 11/64 loss: 0.19962924718856812
Batch 12/64 loss: 0.20365136861801147
Batch 13/64 loss: 0.1946985125541687
Batch 14/64 loss: 0.20569700002670288
Batch 15/64 loss: 0.19987744092941284
Batch 16/64 loss: 0.20295023918151855
Batch 17/64 loss: 0.20248693227767944
Batch 18/64 loss: 0.2038959264755249
Batch 19/64 loss: 0.2131020426750183
Batch 20/64 loss: 0.19596636295318604
Batch 21/64 loss: 0.21067678928375244
Batch 22/64 loss: 0.20389336347579956
Batch 23/64 loss: 0.19302207231521606
Batch 24/64 loss: 0.19800269603729248
Batch 25/64 loss: 0.20423400402069092
Batch 26/64 loss: 0.22004729509353638
Batch 27/64 loss: 0.1991509199142456
Batch 28/64 loss: 0.2147822380065918
Batch 29/64 loss: 0.20999151468276978
Batch 30/64 loss: 0.20120245218276978
Batch 31/64 loss: 0.20572543144226074
Batch 32/64 loss: 0.2099042534828186
Batch 33/64 loss: 0.19976496696472168
Batch 34/64 loss: 0.20604431629180908
Batch 35/64 loss: 0.2132367491722107
Batch 36/64 loss: 0.2054944634437561
Batch 37/64 loss: 0.21660006046295166
Batch 38/64 loss: 0.20087558031082153
Batch 39/64 loss: 0.19583582878112793
Batch 40/64 loss: 0.20734727382659912
Batch 41/64 loss: 0.20663058757781982
Batch 42/64 loss: 0.20606893301010132
Batch 43/64 loss: 0.19688928127288818
Batch 44/64 loss: 0.21079659461975098
Batch 45/64 loss: 0.19335120916366577
Batch 46/64 loss: 0.21749985218048096
Batch 47/64 loss: 0.2053513526916504
Batch 48/64 loss: 0.20606905221939087
Batch 49/64 loss: 0.19892317056655884
Batch 50/64 loss: 0.20259833335876465
Batch 51/64 loss: 0.19981420040130615
Batch 52/64 loss: 0.20628714561462402
Batch 53/64 loss: 0.20413827896118164
Batch 54/64 loss: 0.21053850650787354
Batch 55/64 loss: 0.20709681510925293
Batch 56/64 loss: 0.21874237060546875
Batch 57/64 loss: 0.20074760913848877
Batch 58/64 loss: 0.19951128959655762
Batch 59/64 loss: 0.21896129846572876
Batch 60/64 loss: 0.1982872486114502
Batch 61/64 loss: 0.1973865032196045
Batch 62/64 loss: 0.21247124671936035
Batch 63/64 loss: 0.20273816585540771
Batch 64/64 loss: 0.23293662071228027
Epoch 344  Train loss: 0.20498873018750957  Val loss: 0.29503423344228685
Epoch 345
-------------------------------
Batch 1/64 loss: 0.19605010747909546
Batch 2/64 loss: 0.1978365182876587
Batch 3/64 loss: 0.20952296257019043
Batch 4/64 loss: 0.20290029048919678
Batch 5/64 loss: 0.20624125003814697
Batch 6/64 loss: 0.20044958591461182
Batch 7/64 loss: 0.19199728965759277
Batch 8/64 loss: 0.2106785774230957
Batch 9/64 loss: 0.20151770114898682
Batch 10/64 loss: 0.20245671272277832
Batch 11/64 loss: 0.2100832462310791
Batch 12/64 loss: 0.20744502544403076
Batch 13/64 loss: 0.2029200792312622
Batch 14/64 loss: 0.20716595649719238
Batch 15/64 loss: 0.21330076456069946
Batch 16/64 loss: 0.21203958988189697
Batch 17/64 loss: 0.20901072025299072
Batch 18/64 loss: 0.21085810661315918
Batch 19/64 loss: 0.21692168712615967
Batch 20/64 loss: 0.21525108814239502
Batch 21/64 loss: 0.20251500606536865
Batch 22/64 loss: 0.21607846021652222
Batch 23/64 loss: 0.19577866792678833
Batch 24/64 loss: 0.19500619173049927
Batch 25/64 loss: 0.20550763607025146
Batch 26/64 loss: 0.20658737421035767
Batch 27/64 loss: 0.21686625480651855
Batch 28/64 loss: 0.21219384670257568
Batch 29/64 loss: 0.2075214385986328
Batch 30/64 loss: 0.19834893941879272
Batch 31/64 loss: 0.20040738582611084
Batch 32/64 loss: 0.20318251848220825
Batch 33/64 loss: 0.20780503749847412
Batch 34/64 loss: 0.20065158605575562
Batch 35/64 loss: 0.196724534034729
Batch 36/64 loss: 0.20438015460968018
Batch 37/64 loss: 0.20487117767333984
Batch 38/64 loss: 0.20356309413909912
Batch 39/64 loss: 0.20839959383010864
Batch 40/64 loss: 0.19827497005462646
Batch 41/64 loss: 0.20081037282943726
Batch 42/64 loss: 0.20514726638793945
Batch 43/64 loss: 0.20312714576721191
Batch 44/64 loss: 0.19996637105941772
Batch 45/64 loss: 0.20131909847259521
Batch 46/64 loss: 0.1938827633857727
Batch 47/64 loss: 0.2091379165649414
Batch 48/64 loss: 0.19783854484558105
Batch 49/64 loss: 0.21103382110595703
Batch 50/64 loss: 0.19622480869293213
Batch 51/64 loss: 0.2013590931892395
Batch 52/64 loss: 0.2062082290649414
Batch 53/64 loss: 0.21624386310577393
Batch 54/64 loss: 0.21528446674346924
Batch 55/64 loss: 0.20165640115737915
Batch 56/64 loss: 0.20597875118255615
Batch 57/64 loss: 0.20942538976669312
Batch 58/64 loss: 0.19998180866241455
Batch 59/64 loss: 0.21578896045684814
Batch 60/64 loss: 0.19738638401031494
Batch 61/64 loss: 0.21624964475631714
Batch 62/64 loss: 0.19509345293045044
Batch 63/64 loss: 0.20732498168945312
Batch 64/64 loss: 0.1986011266708374
Epoch 345  Train loss: 0.20493696483911253  Val loss: 0.29571589981157753
Epoch 346
-------------------------------
Batch 1/64 loss: 0.20190739631652832
Batch 2/64 loss: 0.19151055812835693
Batch 3/64 loss: 0.2009131908416748
Batch 4/64 loss: 0.19471442699432373
Batch 5/64 loss: 0.19841241836547852
Batch 6/64 loss: 0.19568264484405518
Batch 7/64 loss: 0.2016674280166626
Batch 8/64 loss: 0.21561646461486816
Batch 9/64 loss: 0.20432114601135254
Batch 10/64 loss: 0.19440454244613647
Batch 11/64 loss: 0.2100539207458496
Batch 12/64 loss: 0.21074342727661133
Batch 13/64 loss: 0.19524109363555908
Batch 14/64 loss: 0.2030271291732788
Batch 15/64 loss: 0.20764821767807007
Batch 16/64 loss: 0.19728004932403564
Batch 17/64 loss: 0.20697474479675293
Batch 18/64 loss: 0.199662983417511
Batch 19/64 loss: 0.20621919631958008
Batch 20/64 loss: 0.20589810609817505
Batch 21/64 loss: 0.21350854635238647
Batch 22/64 loss: 0.19956481456756592
Batch 23/64 loss: 0.2071298360824585
Batch 24/64 loss: 0.2010047435760498
Batch 25/64 loss: 0.20741057395935059
Batch 26/64 loss: 0.20088410377502441
Batch 27/64 loss: 0.20403432846069336
Batch 28/64 loss: 0.20263397693634033
Batch 29/64 loss: 0.20285028219223022
Batch 30/64 loss: 0.1946934461593628
Batch 31/64 loss: 0.1968819499015808
Batch 32/64 loss: 0.19949394464492798
Batch 33/64 loss: 0.19241070747375488
Batch 34/64 loss: 0.20129084587097168
Batch 35/64 loss: 0.2093234658241272
Batch 36/64 loss: 0.19308686256408691
Batch 37/64 loss: 0.20078599452972412
Batch 38/64 loss: 0.19742846488952637
Batch 39/64 loss: 0.20081228017807007
Batch 40/64 loss: 0.21953356266021729
Batch 41/64 loss: 0.2092505693435669
Batch 42/64 loss: 0.20799481868743896
Batch 43/64 loss: 0.1996355652809143
Batch 44/64 loss: 0.21634221076965332
Batch 45/64 loss: 0.20652735233306885
Batch 46/64 loss: 0.20959174633026123
Batch 47/64 loss: 0.21226680278778076
Batch 48/64 loss: 0.21343553066253662
Batch 49/64 loss: 0.20940309762954712
Batch 50/64 loss: 0.20521795749664307
Batch 51/64 loss: 0.21372997760772705
Batch 52/64 loss: 0.20931923389434814
Batch 53/64 loss: 0.2080632448196411
Batch 54/64 loss: 0.2038184404373169
Batch 55/64 loss: 0.2071460485458374
Batch 56/64 loss: 0.19132095575332642
Batch 57/64 loss: 0.19747918844223022
Batch 58/64 loss: 0.21284306049346924
Batch 59/64 loss: 0.20241397619247437
Batch 60/64 loss: 0.21886801719665527
Batch 61/64 loss: 0.20201706886291504
Batch 62/64 loss: 0.221324622631073
Batch 63/64 loss: 0.20532286167144775
Batch 64/64 loss: 0.19732528924942017
Epoch 346  Train loss: 0.20420373537961176  Val loss: 0.2954261628622861
Epoch 347
-------------------------------
Batch 1/64 loss: 0.20956635475158691
Batch 2/64 loss: 0.2120743989944458
Batch 3/64 loss: 0.1906907558441162
Batch 4/64 loss: 0.201957106590271
Batch 5/64 loss: 0.2069631814956665
Batch 6/64 loss: 0.19518083333969116
Batch 7/64 loss: 0.20664221048355103
Batch 8/64 loss: 0.1995478868484497
Batch 9/64 loss: 0.21513938903808594
Batch 10/64 loss: 0.1943184733390808
Batch 11/64 loss: 0.20544487237930298
Batch 12/64 loss: 0.19393926858901978
Batch 13/64 loss: 0.19523775577545166
Batch 14/64 loss: 0.19998949766159058
Batch 15/64 loss: 0.20450204610824585
Batch 16/64 loss: 0.20558160543441772
Batch 17/64 loss: 0.20748960971832275
Batch 18/64 loss: 0.19539058208465576
Batch 19/64 loss: 0.20445549488067627
Batch 20/64 loss: 0.19985496997833252
Batch 21/64 loss: 0.19838255643844604
Batch 22/64 loss: 0.19157540798187256
Batch 23/64 loss: 0.1963491439819336
Batch 24/64 loss: 0.20014744997024536
Batch 25/64 loss: 0.20412182807922363
Batch 26/64 loss: 0.18621689081192017
Batch 27/64 loss: 0.2042320966720581
Batch 28/64 loss: 0.2032948136329651
Batch 29/64 loss: 0.20500034093856812
Batch 30/64 loss: 0.19793617725372314
Batch 31/64 loss: 0.21760106086730957
Batch 32/64 loss: 0.21621525287628174
Batch 33/64 loss: 0.20026874542236328
Batch 34/64 loss: 0.19806623458862305
Batch 35/64 loss: 0.21164745092391968
Batch 36/64 loss: 0.20566976070404053
Batch 37/64 loss: 0.20748835802078247
Batch 38/64 loss: 0.19879913330078125
Batch 39/64 loss: 0.19750142097473145
Batch 40/64 loss: 0.21127533912658691
Batch 41/64 loss: 0.21110320091247559
Batch 42/64 loss: 0.2053004503250122
Batch 43/64 loss: 0.20335805416107178
Batch 44/64 loss: 0.2101142406463623
Batch 45/64 loss: 0.1953490972518921
Batch 46/64 loss: 0.19638562202453613
Batch 47/64 loss: 0.20822405815124512
Batch 48/64 loss: 0.2094719409942627
Batch 49/64 loss: 0.21110588312149048
Batch 50/64 loss: 0.21515488624572754
Batch 51/64 loss: 0.20715367794036865
Batch 52/64 loss: 0.2019750475883484
Batch 53/64 loss: 0.20143800973892212
Batch 54/64 loss: 0.20712250471115112
Batch 55/64 loss: 0.20845335721969604
Batch 56/64 loss: 0.19966959953308105
Batch 57/64 loss: 0.2149108648300171
Batch 58/64 loss: 0.20816820859909058
Batch 59/64 loss: 0.21499371528625488
Batch 60/64 loss: 0.20330774784088135
Batch 61/64 loss: 0.1952981948852539
Batch 62/64 loss: 0.20449936389923096
Batch 63/64 loss: 0.20679813623428345
Batch 64/64 loss: 0.21663957834243774
Epoch 347  Train loss: 0.20388378512625602  Val loss: 0.2959119804536354
Epoch 348
-------------------------------
Batch 1/64 loss: 0.20721620321273804
Batch 2/64 loss: 0.1980297565460205
Batch 3/64 loss: 0.20073288679122925
Batch 4/64 loss: 0.19303584098815918
Batch 5/64 loss: 0.19573920965194702
Batch 6/64 loss: 0.21536409854888916
Batch 7/64 loss: 0.2053391933441162
Batch 8/64 loss: 0.20002472400665283
Batch 9/64 loss: 0.20206117630004883
Batch 10/64 loss: 0.1981210708618164
Batch 11/64 loss: 0.1974397897720337
Batch 12/64 loss: 0.21180278062820435
Batch 13/64 loss: 0.19524788856506348
Batch 14/64 loss: 0.20402789115905762
Batch 15/64 loss: 0.20292437076568604
Batch 16/64 loss: 0.2074110507965088
Batch 17/64 loss: 0.2099672555923462
Batch 18/64 loss: 0.20265889167785645
Batch 19/64 loss: 0.1998283863067627
Batch 20/64 loss: 0.20577514171600342
Batch 21/64 loss: 0.19720304012298584
Batch 22/64 loss: 0.20205950736999512
Batch 23/64 loss: 0.1977916955947876
Batch 24/64 loss: 0.21259033679962158
Batch 25/64 loss: 0.2028678059577942
Batch 26/64 loss: 0.19317954778671265
Batch 27/64 loss: 0.21926409006118774
Batch 28/64 loss: 0.20892518758773804
Batch 29/64 loss: 0.19748055934906006
Batch 30/64 loss: 0.20685029029846191
Batch 31/64 loss: 0.21434873342514038
Batch 32/64 loss: 0.21101045608520508
Batch 33/64 loss: 0.20834922790527344
Batch 34/64 loss: 0.2077111005783081
Batch 35/64 loss: 0.21102094650268555
Batch 36/64 loss: 0.20913124084472656
Batch 37/64 loss: 0.20408493280410767
Batch 38/64 loss: 0.21232718229293823
Batch 39/64 loss: 0.198622465133667
Batch 40/64 loss: 0.2037472128868103
Batch 41/64 loss: 0.20910656452178955
Batch 42/64 loss: 0.2131352424621582
Batch 43/64 loss: 0.1950930953025818
Batch 44/64 loss: 0.20179879665374756
Batch 45/64 loss: 0.20573794841766357
Batch 46/64 loss: 0.2147730588912964
Batch 47/64 loss: 0.20267987251281738
Batch 48/64 loss: 0.21288257837295532
Batch 49/64 loss: 0.20339280366897583
Batch 50/64 loss: 0.20918923616409302
Batch 51/64 loss: 0.21938806772232056
Batch 52/64 loss: 0.19616073369979858
Batch 53/64 loss: 0.2036973237991333
Batch 54/64 loss: 0.21047264337539673
Batch 55/64 loss: 0.20152610540390015
Batch 56/64 loss: 0.19894099235534668
Batch 57/64 loss: 0.20987629890441895
Batch 58/64 loss: 0.2147763967514038
Batch 59/64 loss: 0.19743579626083374
Batch 60/64 loss: 0.20057129859924316
Batch 61/64 loss: 0.20577943325042725
Batch 62/64 loss: 0.21719610691070557
Batch 63/64 loss: 0.19349509477615356
Batch 64/64 loss: 0.21518564224243164
Epoch 348  Train loss: 0.2050165943070954  Val loss: 0.29493159281019493
Epoch 349
-------------------------------
Batch 1/64 loss: 0.21042269468307495
Batch 2/64 loss: 0.1946643590927124
Batch 3/64 loss: 0.20245659351348877
Batch 4/64 loss: 0.19678419828414917
Batch 5/64 loss: 0.1975572109222412
Batch 6/64 loss: 0.1962519884109497
Batch 7/64 loss: 0.19471603631973267
Batch 8/64 loss: 0.20498013496398926
Batch 9/64 loss: 0.1999884843826294
Batch 10/64 loss: 0.19349932670593262
Batch 11/64 loss: 0.1919613480567932
Batch 12/64 loss: 0.20621824264526367
Batch 13/64 loss: 0.20714420080184937
Batch 14/64 loss: 0.21174699068069458
Batch 15/64 loss: 0.2028578519821167
Batch 16/64 loss: 0.19878661632537842
Batch 17/64 loss: 0.19144439697265625
Batch 18/64 loss: 0.20013582706451416
Batch 19/64 loss: 0.20766830444335938
Batch 20/64 loss: 0.19745290279388428
Batch 21/64 loss: 0.20632362365722656
Batch 22/64 loss: 0.19168496131896973
Batch 23/64 loss: 0.1944912075996399
Batch 24/64 loss: 0.2067679762840271
Batch 25/64 loss: 0.19958853721618652
Batch 26/64 loss: 0.19752466678619385
Batch 27/64 loss: 0.20610970258712769
Batch 28/64 loss: 0.20280665159225464
Batch 29/64 loss: 0.21760094165802002
Batch 30/64 loss: 0.19338029623031616
Batch 31/64 loss: 0.21213996410369873
Batch 32/64 loss: 0.1954898238182068
Batch 33/64 loss: 0.1900901198387146
Batch 34/64 loss: 0.21182644367218018
Batch 35/64 loss: 0.20813393592834473
Batch 36/64 loss: 0.2089855670928955
Batch 37/64 loss: 0.19981348514556885
Batch 38/64 loss: 0.21549445390701294
Batch 39/64 loss: 0.2020074725151062
Batch 40/64 loss: 0.21210604906082153
Batch 41/64 loss: 0.2051752805709839
Batch 42/64 loss: 0.20276331901550293
Batch 43/64 loss: 0.2004317045211792
Batch 44/64 loss: 0.1978548765182495
Batch 45/64 loss: 0.21288633346557617
Batch 46/64 loss: 0.19595003128051758
Batch 47/64 loss: 0.2033177614212036
Batch 48/64 loss: 0.21746397018432617
Batch 49/64 loss: 0.1937207579612732
Batch 50/64 loss: 0.21275174617767334
Batch 51/64 loss: 0.20146799087524414
Batch 52/64 loss: 0.2113204002380371
Batch 53/64 loss: 0.2086864709854126
Batch 54/64 loss: 0.20063960552215576
Batch 55/64 loss: 0.20137107372283936
Batch 56/64 loss: 0.21400463581085205
Batch 57/64 loss: 0.21003389358520508
Batch 58/64 loss: 0.21016603708267212
Batch 59/64 loss: 0.20161139965057373
Batch 60/64 loss: 0.20859605073928833
Batch 61/64 loss: 0.20721912384033203
Batch 62/64 loss: 0.1996937394142151
Batch 63/64 loss: 0.238794207572937
Batch 64/64 loss: 0.20011365413665771
Epoch 349  Train loss: 0.20368798807555555  Val loss: 0.2951304562313041
Epoch 350
-------------------------------
Batch 1/64 loss: 0.2149023413658142
Batch 2/64 loss: 0.21678507328033447
Batch 3/64 loss: 0.1899346113204956
Batch 4/64 loss: 0.20209723711013794
Batch 5/64 loss: 0.19722050428390503
Batch 6/64 loss: 0.2031802535057068
Batch 7/64 loss: 0.20790690183639526
Batch 8/64 loss: 0.20255106687545776
Batch 9/64 loss: 0.210790753364563
Batch 10/64 loss: 0.19959157705307007
Batch 11/64 loss: 0.2020600438117981
Batch 12/64 loss: 0.2053471803665161
Batch 13/64 loss: 0.20721286535263062
Batch 14/64 loss: 0.20203208923339844
Batch 15/64 loss: 0.22151577472686768
Batch 16/64 loss: 0.20876586437225342
Batch 17/64 loss: 0.20407402515411377
Batch 18/64 loss: 0.20212244987487793
Batch 19/64 loss: 0.21451103687286377
Batch 20/64 loss: 0.19930613040924072
Batch 21/64 loss: 0.20336699485778809
Batch 22/64 loss: 0.19714999198913574
Batch 23/64 loss: 0.19913899898529053
Batch 24/64 loss: 0.20891833305358887
Batch 25/64 loss: 0.19372081756591797
Batch 26/64 loss: 0.20261210203170776
Batch 27/64 loss: 0.19401443004608154
Batch 28/64 loss: 0.2004225254058838
Batch 29/64 loss: 0.21116310358047485
Batch 30/64 loss: 0.20198124647140503
Batch 31/64 loss: 0.20242172479629517
Batch 32/64 loss: 0.1993391513824463
Batch 33/64 loss: 0.2020055055618286
Batch 34/64 loss: 0.20654898881912231
Batch 35/64 loss: 0.21338212490081787
Batch 36/64 loss: 0.2022414207458496
Batch 37/64 loss: 0.20732176303863525
Batch 38/64 loss: 0.22473180294036865
Batch 39/64 loss: 0.19004428386688232
Batch 40/64 loss: 0.19997090101242065
Batch 41/64 loss: 0.20467787981033325
Batch 42/64 loss: 0.21327590942382812
Batch 43/64 loss: 0.20599627494812012
Batch 44/64 loss: 0.19632083177566528
Batch 45/64 loss: 0.21586167812347412
Batch 46/64 loss: 0.2097952961921692
Batch 47/64 loss: 0.20652461051940918
Batch 48/64 loss: 0.1998516321182251
Batch 49/64 loss: 0.20379698276519775
Batch 50/64 loss: 0.20184195041656494
Batch 51/64 loss: 0.1989227533340454
Batch 52/64 loss: 0.20273858308792114
Batch 53/64 loss: 0.21742546558380127
Batch 54/64 loss: 0.19279569387435913
Batch 55/64 loss: 0.21645396947860718
Batch 56/64 loss: 0.21368193626403809
Batch 57/64 loss: 0.19856631755828857
Batch 58/64 loss: 0.20383954048156738
Batch 59/64 loss: 0.20901334285736084
Batch 60/64 loss: 0.20602071285247803
Batch 61/64 loss: 0.1894822120666504
Batch 62/64 loss: 0.20471853017807007
Batch 63/64 loss: 0.19679737091064453
Batch 64/64 loss: 0.19581282138824463
Epoch 350  Train loss: 0.2043554993236766  Val loss: 0.2953994675600242
Epoch 351
-------------------------------
Batch 1/64 loss: 0.20048868656158447
Batch 2/64 loss: 0.2017090916633606
Batch 3/64 loss: 0.195817768573761
Batch 4/64 loss: 0.20070886611938477
Batch 5/64 loss: 0.2193218469619751
Batch 6/64 loss: 0.1947646141052246
Batch 7/64 loss: 0.2090209722518921
Batch 8/64 loss: 0.1986849308013916
Batch 9/64 loss: 0.20061779022216797
Batch 10/64 loss: 0.20547211170196533
Batch 11/64 loss: 0.20488077402114868
Batch 12/64 loss: 0.20605754852294922
Batch 13/64 loss: 0.20377087593078613
Batch 14/64 loss: 0.21314853429794312
Batch 15/64 loss: 0.20389431715011597
Batch 16/64 loss: 0.19454115629196167
Batch 17/64 loss: 0.20779335498809814
Batch 18/64 loss: 0.21760636568069458
Batch 19/64 loss: 0.21208298206329346
Batch 20/64 loss: 0.2005927562713623
Batch 21/64 loss: 0.20384454727172852
Batch 22/64 loss: 0.20122212171554565
Batch 23/64 loss: 0.20094150304794312
Batch 24/64 loss: 0.19998174905776978
Batch 25/64 loss: 0.2104935646057129
Batch 26/64 loss: 0.20000475645065308
Batch 27/64 loss: 0.2019336223602295
Batch 28/64 loss: 0.21326428651809692
Batch 29/64 loss: 0.19353431463241577
Batch 30/64 loss: 0.20209002494812012
Batch 31/64 loss: 0.19760549068450928
Batch 32/64 loss: 0.19710856676101685
Batch 33/64 loss: 0.1961073875427246
Batch 34/64 loss: 0.20674800872802734
Batch 35/64 loss: 0.2101755142211914
Batch 36/64 loss: 0.20307886600494385
Batch 37/64 loss: 0.20269036293029785
Batch 38/64 loss: 0.19857048988342285
Batch 39/64 loss: 0.2063910961151123
Batch 40/64 loss: 0.20032989978790283
Batch 41/64 loss: 0.21146881580352783
Batch 42/64 loss: 0.21270406246185303
Batch 43/64 loss: 0.20965725183486938
Batch 44/64 loss: 0.21681088209152222
Batch 45/64 loss: 0.20408868789672852
Batch 46/64 loss: 0.21380269527435303
Batch 47/64 loss: 0.20274138450622559
Batch 48/64 loss: 0.20366203784942627
Batch 49/64 loss: 0.20684361457824707
Batch 50/64 loss: 0.19506531953811646
Batch 51/64 loss: 0.2228788137435913
Batch 52/64 loss: 0.2174779176712036
Batch 53/64 loss: 0.1916458010673523
Batch 54/64 loss: 0.19521039724349976
Batch 55/64 loss: 0.20363163948059082
Batch 56/64 loss: 0.19637256860733032
Batch 57/64 loss: 0.20988774299621582
Batch 58/64 loss: 0.20678400993347168
Batch 59/64 loss: 0.21665740013122559
Batch 60/64 loss: 0.20323807001113892
Batch 61/64 loss: 0.2029893398284912
Batch 62/64 loss: 0.20098865032196045
Batch 63/64 loss: 0.19920849800109863
Batch 64/64 loss: 0.2070295214653015
Epoch 351  Train loss: 0.20448908642226574  Val loss: 0.29582986348273416
Epoch 352
-------------------------------
Batch 1/64 loss: 0.21101069450378418
Batch 2/64 loss: 0.21419799327850342
Batch 3/64 loss: 0.19456011056900024
Batch 4/64 loss: 0.19327890872955322
Batch 5/64 loss: 0.19850915670394897
Batch 6/64 loss: 0.19347065687179565
Batch 7/64 loss: 0.1936882734298706
Batch 8/64 loss: 0.2046424150466919
Batch 9/64 loss: 0.21322494745254517
Batch 10/64 loss: 0.20317530632019043
Batch 11/64 loss: 0.20405316352844238
Batch 12/64 loss: 0.1907140016555786
Batch 13/64 loss: 0.19477128982543945
Batch 14/64 loss: 0.2059870958328247
Batch 15/64 loss: 0.19695955514907837
Batch 16/64 loss: 0.19877344369888306
Batch 17/64 loss: 0.21282505989074707
Batch 18/64 loss: 0.1910938024520874
Batch 19/64 loss: 0.20040816068649292
Batch 20/64 loss: 0.21223890781402588
Batch 21/64 loss: 0.23125457763671875
Batch 22/64 loss: 0.2091381549835205
Batch 23/64 loss: 0.21362841129302979
Batch 24/64 loss: 0.20783698558807373
Batch 25/64 loss: 0.20097482204437256
Batch 26/64 loss: 0.2078688144683838
Batch 27/64 loss: 0.20125901699066162
Batch 28/64 loss: 0.2127981185913086
Batch 29/64 loss: 0.20341360569000244
Batch 30/64 loss: 0.19687402248382568
Batch 31/64 loss: 0.20450496673583984
Batch 32/64 loss: 0.19381928443908691
Batch 33/64 loss: 0.20186364650726318
Batch 34/64 loss: 0.2083975076675415
Batch 35/64 loss: 0.21001207828521729
Batch 36/64 loss: 0.2070993185043335
Batch 37/64 loss: 0.20446717739105225
Batch 38/64 loss: 0.19916272163391113
Batch 39/64 loss: 0.2009122371673584
Batch 40/64 loss: 0.20650094747543335
Batch 41/64 loss: 0.2065677046775818
Batch 42/64 loss: 0.21112245321273804
Batch 43/64 loss: 0.20192062854766846
Batch 44/64 loss: 0.21175217628479004
Batch 45/64 loss: 0.19943249225616455
Batch 46/64 loss: 0.19679296016693115
Batch 47/64 loss: 0.1970197558403015
Batch 48/64 loss: 0.20217472314834595
Batch 49/64 loss: 0.20251315832138062
Batch 50/64 loss: 0.19401419162750244
Batch 51/64 loss: 0.20780134201049805
Batch 52/64 loss: 0.20451009273529053
Batch 53/64 loss: 0.20298302173614502
Batch 54/64 loss: 0.19707059860229492
Batch 55/64 loss: 0.20453041791915894
Batch 56/64 loss: 0.19452863931655884
Batch 57/64 loss: 0.20739823579788208
Batch 58/64 loss: 0.20626741647720337
Batch 59/64 loss: 0.20843183994293213
Batch 60/64 loss: 0.20362484455108643
Batch 61/64 loss: 0.2072281837463379
Batch 62/64 loss: 0.1974952220916748
Batch 63/64 loss: 0.2055686116218567
Batch 64/64 loss: 0.19863933324813843
Epoch 352  Train loss: 0.20343682462093876  Val loss: 0.2951278225662782
Epoch 353
-------------------------------
Batch 1/64 loss: 0.20844614505767822
Batch 2/64 loss: 0.20213556289672852
Batch 3/64 loss: 0.19858092069625854
Batch 4/64 loss: 0.20683187246322632
Batch 5/64 loss: 0.20277279615402222
Batch 6/64 loss: 0.1902340054512024
Batch 7/64 loss: 0.19478625059127808
Batch 8/64 loss: 0.20228087902069092
Batch 9/64 loss: 0.19772911071777344
Batch 10/64 loss: 0.20785409212112427
Batch 11/64 loss: 0.19360393285751343
Batch 12/64 loss: 0.19878309965133667
Batch 13/64 loss: 0.2118145227432251
Batch 14/64 loss: 0.19990062713623047
Batch 15/64 loss: 0.1992276906967163
Batch 16/64 loss: 0.20462673902511597
Batch 17/64 loss: 0.20880794525146484
Batch 18/64 loss: 0.19436335563659668
Batch 19/64 loss: 0.20985150337219238
Batch 20/64 loss: 0.1988201141357422
Batch 21/64 loss: 0.1975347399711609
Batch 22/64 loss: 0.2159186601638794
Batch 23/64 loss: 0.1982792615890503
Batch 24/64 loss: 0.19812798500061035
Batch 25/64 loss: 0.21390140056610107
Batch 26/64 loss: 0.2274106740951538
Batch 27/64 loss: 0.21260637044906616
Batch 28/64 loss: 0.2056574821472168
Batch 29/64 loss: 0.20611655712127686
Batch 30/64 loss: 0.20367592573165894
Batch 31/64 loss: 0.20705819129943848
Batch 32/64 loss: 0.1965922713279724
Batch 33/64 loss: 0.1949215531349182
Batch 34/64 loss: 0.2057378888130188
Batch 35/64 loss: 0.2115616798400879
Batch 36/64 loss: 0.20753991603851318
Batch 37/64 loss: 0.19899195432662964
Batch 38/64 loss: 0.2042381763458252
Batch 39/64 loss: 0.20107120275497437
Batch 40/64 loss: 0.1986299753189087
Batch 41/64 loss: 0.20007717609405518
Batch 42/64 loss: 0.20271480083465576
Batch 43/64 loss: 0.1928623914718628
Batch 44/64 loss: 0.1942576766014099
Batch 45/64 loss: 0.20757943391799927
Batch 46/64 loss: 0.2017853856086731
Batch 47/64 loss: 0.20795488357543945
Batch 48/64 loss: 0.21701931953430176
Batch 49/64 loss: 0.2204534411430359
Batch 50/64 loss: 0.20312637090682983
Batch 51/64 loss: 0.2072434425354004
Batch 52/64 loss: 0.21105432510375977
Batch 53/64 loss: 0.1909591555595398
Batch 54/64 loss: 0.19867968559265137
Batch 55/64 loss: 0.200386643409729
Batch 56/64 loss: 0.20348548889160156
Batch 57/64 loss: 0.20753544569015503
Batch 58/64 loss: 0.22114431858062744
Batch 59/64 loss: 0.22148215770721436
Batch 60/64 loss: 0.2119375467300415
Batch 61/64 loss: 0.20192795991897583
Batch 62/64 loss: 0.21906501054763794
Batch 63/64 loss: 0.20810985565185547
Batch 64/64 loss: 0.20369184017181396
Epoch 353  Train loss: 0.2045589619991826  Val loss: 0.2962996672928538
Epoch 354
-------------------------------
Batch 1/64 loss: 0.21162629127502441
Batch 2/64 loss: 0.2014598846435547
Batch 3/64 loss: 0.2072662115097046
Batch 4/64 loss: 0.20181173086166382
Batch 5/64 loss: 0.20382016897201538
Batch 6/64 loss: 0.2091134786605835
Batch 7/64 loss: 0.19997745752334595
Batch 8/64 loss: 0.2000541090965271
Batch 9/64 loss: 0.2115880846977234
Batch 10/64 loss: 0.19070398807525635
Batch 11/64 loss: 0.20193099975585938
Batch 12/64 loss: 0.23355859518051147
Batch 13/64 loss: 0.19355863332748413
Batch 14/64 loss: 0.19944489002227783
Batch 15/64 loss: 0.20071625709533691
Batch 16/64 loss: 0.19679325819015503
Batch 17/64 loss: 0.1967531442642212
Batch 18/64 loss: 0.20554029941558838
Batch 19/64 loss: 0.19214439392089844
Batch 20/64 loss: 0.20677399635314941
Batch 21/64 loss: 0.19317758083343506
Batch 22/64 loss: 0.19579535722732544
Batch 23/64 loss: 0.19957435131072998
Batch 24/64 loss: 0.19897234439849854
Batch 25/64 loss: 0.1925981044769287
Batch 26/64 loss: 0.2129923701286316
Batch 27/64 loss: 0.19934594631195068
Batch 28/64 loss: 0.20845776796340942
Batch 29/64 loss: 0.21000128984451294
Batch 30/64 loss: 0.20936906337738037
Batch 31/64 loss: 0.2062443494796753
Batch 32/64 loss: 0.2008981704711914
Batch 33/64 loss: 0.203738272190094
Batch 34/64 loss: 0.21254998445510864
Batch 35/64 loss: 0.20153552293777466
Batch 36/64 loss: 0.20112228393554688
Batch 37/64 loss: 0.20489788055419922
Batch 38/64 loss: 0.19308316707611084
Batch 39/64 loss: 0.19571661949157715
Batch 40/64 loss: 0.21694087982177734
Batch 41/64 loss: 0.196336030960083
Batch 42/64 loss: 0.19541430473327637
Batch 43/64 loss: 0.19891071319580078
Batch 44/64 loss: 0.21258604526519775
Batch 45/64 loss: 0.20192182064056396
Batch 46/64 loss: 0.20657432079315186
Batch 47/64 loss: 0.20606952905654907
Batch 48/64 loss: 0.2089385986328125
Batch 49/64 loss: 0.19406557083129883
Batch 50/64 loss: 0.20308208465576172
Batch 51/64 loss: 0.19938379526138306
Batch 52/64 loss: 0.20529043674468994
Batch 53/64 loss: 0.2033625841140747
Batch 54/64 loss: 0.2081565260887146
Batch 55/64 loss: 0.20076370239257812
Batch 56/64 loss: 0.21816593408584595
Batch 57/64 loss: 0.20817804336547852
Batch 58/64 loss: 0.20595264434814453
Batch 59/64 loss: 0.19115465879440308
Batch 60/64 loss: 0.20089071989059448
Batch 61/64 loss: 0.2026594877243042
Batch 62/64 loss: 0.2000521421432495
Batch 63/64 loss: 0.21148037910461426
Batch 64/64 loss: 0.20022821426391602
Epoch 354  Train loss: 0.20315621039446663  Val loss: 0.2959341247057177
Epoch 355
-------------------------------
Batch 1/64 loss: 0.21743685007095337
Batch 2/64 loss: 0.19677281379699707
Batch 3/64 loss: 0.18856024742126465
Batch 4/64 loss: 0.2025059461593628
Batch 5/64 loss: 0.1926860809326172
Batch 6/64 loss: 0.19460159540176392
Batch 7/64 loss: 0.20668107271194458
Batch 8/64 loss: 0.19731539487838745
Batch 9/64 loss: 0.201646089553833
Batch 10/64 loss: 0.1906430721282959
Batch 11/64 loss: 0.20826107263565063
Batch 12/64 loss: 0.2205570936203003
Batch 13/64 loss: 0.19919359683990479
Batch 14/64 loss: 0.1972966194152832
Batch 15/64 loss: 0.20354878902435303
Batch 16/64 loss: 0.20003676414489746
Batch 17/64 loss: 0.20121443271636963
Batch 18/64 loss: 0.20216703414916992
Batch 19/64 loss: 0.20892882347106934
Batch 20/64 loss: 0.19231069087982178
Batch 21/64 loss: 0.2154141664505005
Batch 22/64 loss: 0.20012974739074707
Batch 23/64 loss: 0.205436110496521
Batch 24/64 loss: 0.20097815990447998
Batch 25/64 loss: 0.21037554740905762
Batch 26/64 loss: 0.19643425941467285
Batch 27/64 loss: 0.2108372449874878
Batch 28/64 loss: 0.19495713710784912
Batch 29/64 loss: 0.2166394591331482
Batch 30/64 loss: 0.2053511142730713
Batch 31/64 loss: 0.20042330026626587
Batch 32/64 loss: 0.20216834545135498
Batch 33/64 loss: 0.20782136917114258
Batch 34/64 loss: 0.2030375599861145
Batch 35/64 loss: 0.20048540830612183
Batch 36/64 loss: 0.2022821307182312
Batch 37/64 loss: 0.20177030563354492
Batch 38/64 loss: 0.2096397876739502
Batch 39/64 loss: 0.19398117065429688
Batch 40/64 loss: 0.18937045335769653
Batch 41/64 loss: 0.2023155689239502
Batch 42/64 loss: 0.20377802848815918
Batch 43/64 loss: 0.2103601098060608
Batch 44/64 loss: 0.21215569972991943
Batch 45/64 loss: 0.19884443283081055
Batch 46/64 loss: 0.19488829374313354
Batch 47/64 loss: 0.20803076028823853
Batch 48/64 loss: 0.19667887687683105
Batch 49/64 loss: 0.2207731008529663
Batch 50/64 loss: 0.1998370885848999
Batch 51/64 loss: 0.19355010986328125
Batch 52/64 loss: 0.2122100591659546
Batch 53/64 loss: 0.19337236881256104
Batch 54/64 loss: 0.21377712488174438
Batch 55/64 loss: 0.20320677757263184
Batch 56/64 loss: 0.20580977201461792
Batch 57/64 loss: 0.19206827878952026
Batch 58/64 loss: 0.2174464464187622
Batch 59/64 loss: 0.20515930652618408
Batch 60/64 loss: 0.21581804752349854
Batch 61/64 loss: 0.19999104738235474
Batch 62/64 loss: 0.21190184354782104
Batch 63/64 loss: 0.19405782222747803
Batch 64/64 loss: 0.22307825088500977
Epoch 355  Train loss: 0.20334488644319423  Val loss: 0.29579178225953145
Epoch 356
-------------------------------
Batch 1/64 loss: 0.20584213733673096
Batch 2/64 loss: 0.1992868185043335
Batch 3/64 loss: 0.20736730098724365
Batch 4/64 loss: 0.20561540126800537
Batch 5/64 loss: 0.21155524253845215
Batch 6/64 loss: 0.19318020343780518
Batch 7/64 loss: 0.2138901948928833
Batch 8/64 loss: 0.20172017812728882
Batch 9/64 loss: 0.1893886923789978
Batch 10/64 loss: 0.20431101322174072
Batch 11/64 loss: 0.1940011978149414
Batch 12/64 loss: 0.19325608015060425
Batch 13/64 loss: 0.20688605308532715
Batch 14/64 loss: 0.20623409748077393
Batch 15/64 loss: 0.19881027936935425
Batch 16/64 loss: 0.20183783769607544
Batch 17/64 loss: 0.20100533962249756
Batch 18/64 loss: 0.208632230758667
Batch 19/64 loss: 0.19663608074188232
Batch 20/64 loss: 0.21202069520950317
Batch 21/64 loss: 0.19806134700775146
Batch 22/64 loss: 0.21555346250534058
Batch 23/64 loss: 0.20013350248336792
Batch 24/64 loss: 0.21169406175613403
Batch 25/64 loss: 0.2065056562423706
Batch 26/64 loss: 0.21861833333969116
Batch 27/64 loss: 0.2119043469429016
Batch 28/64 loss: 0.21467381715774536
Batch 29/64 loss: 0.20400017499923706
Batch 30/64 loss: 0.19624483585357666
Batch 31/64 loss: 0.20410442352294922
Batch 32/64 loss: 0.19889521598815918
Batch 33/64 loss: 0.20268070697784424
Batch 34/64 loss: 0.21089422702789307
Batch 35/64 loss: 0.20654070377349854
Batch 36/64 loss: 0.2021762728691101
Batch 37/64 loss: 0.19200283288955688
Batch 38/64 loss: 0.20791852474212646
Batch 39/64 loss: 0.2075352668762207
Batch 40/64 loss: 0.204736590385437
Batch 41/64 loss: 0.21673071384429932
Batch 42/64 loss: 0.21302777528762817
Batch 43/64 loss: 0.2004501223564148
Batch 44/64 loss: 0.19200891256332397
Batch 45/64 loss: 0.19856953620910645
Batch 46/64 loss: 0.1915631890296936
Batch 47/64 loss: 0.19855749607086182
Batch 48/64 loss: 0.19942909479141235
Batch 49/64 loss: 0.19760775566101074
Batch 50/64 loss: 0.20869994163513184
Batch 51/64 loss: 0.20001661777496338
Batch 52/64 loss: 0.20697444677352905
Batch 53/64 loss: 0.2025417685508728
Batch 54/64 loss: 0.1937626600265503
Batch 55/64 loss: 0.2169780731201172
Batch 56/64 loss: 0.19681191444396973
Batch 57/64 loss: 0.2035742998123169
Batch 58/64 loss: 0.2065563201904297
Batch 59/64 loss: 0.20660299062728882
Batch 60/64 loss: 0.20838123559951782
Batch 61/64 loss: 0.20306789875030518
Batch 62/64 loss: 0.1946951150894165
Batch 63/64 loss: 0.20543891191482544
Batch 64/64 loss: 0.197881817817688
Epoch 356  Train loss: 0.20355779657176898  Val loss: 0.2956081845916014
Epoch 357
-------------------------------
Batch 1/64 loss: 0.19767677783966064
Batch 2/64 loss: 0.21248602867126465
Batch 3/64 loss: 0.20361769199371338
Batch 4/64 loss: 0.19128811359405518
Batch 5/64 loss: 0.19959044456481934
Batch 6/64 loss: 0.2037431001663208
Batch 7/64 loss: 0.20195794105529785
Batch 8/64 loss: 0.20394659042358398
Batch 9/64 loss: 0.19619876146316528
Batch 10/64 loss: 0.21011805534362793
Batch 11/64 loss: 0.20638740062713623
Batch 12/64 loss: 0.20276737213134766
Batch 13/64 loss: 0.20573896169662476
Batch 14/64 loss: 0.20008718967437744
Batch 15/64 loss: 0.2131727933883667
Batch 16/64 loss: 0.20343399047851562
Batch 17/64 loss: 0.20039331912994385
Batch 18/64 loss: 0.2067800760269165
Batch 19/64 loss: 0.20201504230499268
Batch 20/64 loss: 0.20535939931869507
Batch 21/64 loss: 0.1880212426185608
Batch 22/64 loss: 0.1995665431022644
Batch 23/64 loss: 0.21212828159332275
Batch 24/64 loss: 0.19469964504241943
Batch 25/64 loss: 0.20178258419036865
Batch 26/64 loss: 0.1995866298675537
Batch 27/64 loss: 0.20110869407653809
Batch 28/64 loss: 0.20869433879852295
Batch 29/64 loss: 0.20328110456466675
Batch 30/64 loss: 0.2004362940788269
Batch 31/64 loss: 0.20003736019134521
Batch 32/64 loss: 0.19711405038833618
Batch 33/64 loss: 0.20750951766967773
Batch 34/64 loss: 0.20181941986083984
Batch 35/64 loss: 0.20417726039886475
Batch 36/64 loss: 0.19969922304153442
Batch 37/64 loss: 0.20830905437469482
Batch 38/64 loss: 0.19879281520843506
Batch 39/64 loss: 0.20074939727783203
Batch 40/64 loss: 0.2002573013305664
Batch 41/64 loss: 0.19840770959854126
Batch 42/64 loss: 0.21083706617355347
Batch 43/64 loss: 0.20396184921264648
Batch 44/64 loss: 0.19798636436462402
Batch 45/64 loss: 0.19738823175430298
Batch 46/64 loss: 0.2126326560974121
Batch 47/64 loss: 0.20055389404296875
Batch 48/64 loss: 0.20842242240905762
Batch 49/64 loss: 0.2121368646621704
Batch 50/64 loss: 0.20682907104492188
Batch 51/64 loss: 0.2229529619216919
Batch 52/64 loss: 0.199088454246521
Batch 53/64 loss: 0.19855660200119019
Batch 54/64 loss: 0.2074567675590515
Batch 55/64 loss: 0.19448328018188477
Batch 56/64 loss: 0.20676052570343018
Batch 57/64 loss: 0.19728708267211914
Batch 58/64 loss: 0.21093475818634033
Batch 59/64 loss: 0.2040652632713318
Batch 60/64 loss: 0.19569069147109985
Batch 61/64 loss: 0.20104360580444336
Batch 62/64 loss: 0.20357507467269897
Batch 63/64 loss: 0.2086029052734375
Batch 64/64 loss: 0.22345751523971558
Epoch 357  Train loss: 0.20332199288349526  Val loss: 0.2971959513487275
Epoch 358
-------------------------------
Batch 1/64 loss: 0.2045069932937622
Batch 2/64 loss: 0.19365346431732178
Batch 3/64 loss: 0.2034127116203308
Batch 4/64 loss: 0.21068179607391357
Batch 5/64 loss: 0.21414083242416382
Batch 6/64 loss: 0.21577215194702148
Batch 7/64 loss: 0.1999596357345581
Batch 8/64 loss: 0.19815802574157715
Batch 9/64 loss: 0.19747650623321533
Batch 10/64 loss: 0.20115375518798828
Batch 11/64 loss: 0.19598639011383057
Batch 12/64 loss: 0.19835036993026733
Batch 13/64 loss: 0.20650780200958252
Batch 14/64 loss: 0.21180355548858643
Batch 15/64 loss: 0.19935858249664307
Batch 16/64 loss: 0.20385390520095825
Batch 17/64 loss: 0.1996714472770691
Batch 18/64 loss: 0.19103199243545532
Batch 19/64 loss: 0.2017952799797058
Batch 20/64 loss: 0.20268046855926514
Batch 21/64 loss: 0.19541311264038086
Batch 22/64 loss: 0.21459048986434937
Batch 23/64 loss: 0.20448994636535645
Batch 24/64 loss: 0.20311951637268066
Batch 25/64 loss: 0.20215725898742676
Batch 26/64 loss: 0.20782482624053955
Batch 27/64 loss: 0.1997489333152771
Batch 28/64 loss: 0.21090418100357056
Batch 29/64 loss: 0.2064448595046997
Batch 30/64 loss: 0.20205152034759521
Batch 31/64 loss: 0.19714844226837158
Batch 32/64 loss: 0.20751821994781494
Batch 33/64 loss: 0.19980502128601074
Batch 34/64 loss: 0.19306975603103638
Batch 35/64 loss: 0.1945962905883789
Batch 36/64 loss: 0.21063995361328125
Batch 37/64 loss: 0.20448195934295654
Batch 38/64 loss: 0.20693445205688477
Batch 39/64 loss: 0.18878555297851562
Batch 40/64 loss: 0.19282948970794678
Batch 41/64 loss: 0.2099665403366089
Batch 42/64 loss: 0.21000897884368896
Batch 43/64 loss: 0.19678276777267456
Batch 44/64 loss: 0.2002112865447998
Batch 45/64 loss: 0.22742247581481934
Batch 46/64 loss: 0.2036861777305603
Batch 47/64 loss: 0.21825456619262695
Batch 48/64 loss: 0.20387709140777588
Batch 49/64 loss: 0.204087495803833
Batch 50/64 loss: 0.2011575698852539
Batch 51/64 loss: 0.19455814361572266
Batch 52/64 loss: 0.20970028638839722
Batch 53/64 loss: 0.20074522495269775
Batch 54/64 loss: 0.20020467042922974
Batch 55/64 loss: 0.21490967273712158
Batch 56/64 loss: 0.20211756229400635
Batch 57/64 loss: 0.20911788940429688
Batch 58/64 loss: 0.20348751544952393
Batch 59/64 loss: 0.19634509086608887
Batch 60/64 loss: 0.21542400121688843
Batch 61/64 loss: 0.1923820972442627
Batch 62/64 loss: 0.19579583406448364
Batch 63/64 loss: 0.20898699760437012
Batch 64/64 loss: 0.2029428482055664
Epoch 358  Train loss: 0.20335602386325013  Val loss: 0.2963248796479399
Epoch 359
-------------------------------
Batch 1/64 loss: 0.199349045753479
Batch 2/64 loss: 0.2068403959274292
Batch 3/64 loss: 0.19814026355743408
Batch 4/64 loss: 0.2098550796508789
Batch 5/64 loss: 0.20204401016235352
Batch 6/64 loss: 0.2025960087776184
Batch 7/64 loss: 0.1949911117553711
Batch 8/64 loss: 0.2049427628517151
Batch 9/64 loss: 0.2165570855140686
Batch 10/64 loss: 0.20371782779693604
Batch 11/64 loss: 0.1974213719367981
Batch 12/64 loss: 0.19630813598632812
Batch 13/64 loss: 0.20044541358947754
Batch 14/64 loss: 0.2101459503173828
Batch 15/64 loss: 0.20470798015594482
Batch 16/64 loss: 0.19590061902999878
Batch 17/64 loss: 0.20506983995437622
Batch 18/64 loss: 0.21464717388153076
Batch 19/64 loss: 0.1958140730857849
Batch 20/64 loss: 0.21380555629730225
Batch 21/64 loss: 0.19586330652236938
Batch 22/64 loss: 0.20420479774475098
Batch 23/64 loss: 0.20589029788970947
Batch 24/64 loss: 0.19773215055465698
Batch 25/64 loss: 0.19446706771850586
Batch 26/64 loss: 0.21395790576934814
Batch 27/64 loss: 0.19637072086334229
Batch 28/64 loss: 0.19897794723510742
Batch 29/64 loss: 0.20142912864685059
Batch 30/64 loss: 0.20474296808242798
Batch 31/64 loss: 0.2011927366256714
Batch 32/64 loss: 0.20458388328552246
Batch 33/64 loss: 0.19985175132751465
Batch 34/64 loss: 0.19444286823272705
Batch 35/64 loss: 0.19623106718063354
Batch 36/64 loss: 0.20151448249816895
Batch 37/64 loss: 0.20925825834274292
Batch 38/64 loss: 0.1842271089553833
Batch 39/64 loss: 0.2118624448776245
Batch 40/64 loss: 0.19962775707244873
Batch 41/64 loss: 0.1905108094215393
Batch 42/64 loss: 0.1996505856513977
Batch 43/64 loss: 0.2089763879776001
Batch 44/64 loss: 0.20027124881744385
Batch 45/64 loss: 0.20302534103393555
Batch 46/64 loss: 0.20847666263580322
Batch 47/64 loss: 0.20515835285186768
Batch 48/64 loss: 0.20222830772399902
Batch 49/64 loss: 0.20521843433380127
Batch 50/64 loss: 0.19596600532531738
Batch 51/64 loss: 0.20941901206970215
Batch 52/64 loss: 0.19999724626541138
Batch 53/64 loss: 0.20216059684753418
Batch 54/64 loss: 0.2108238935470581
Batch 55/64 loss: 0.19860202074050903
Batch 56/64 loss: 0.18973064422607422
Batch 57/64 loss: 0.19489610195159912
Batch 58/64 loss: 0.20188111066818237
Batch 59/64 loss: 0.19887030124664307
Batch 60/64 loss: 0.1962183117866516
Batch 61/64 loss: 0.21320438385009766
Batch 62/64 loss: 0.1998516321182251
Batch 63/64 loss: 0.21114444732666016
Batch 64/64 loss: 0.2034851312637329
Epoch 359  Train loss: 0.20217449478074617  Val loss: 0.2957943071614426
Epoch 360
-------------------------------
Batch 1/64 loss: 0.1992926001548767
Batch 2/64 loss: 0.19460487365722656
Batch 3/64 loss: 0.2108457088470459
Batch 4/64 loss: 0.20568561553955078
Batch 5/64 loss: 0.2023007869720459
Batch 6/64 loss: 0.19711178541183472
Batch 7/64 loss: 0.19485050439834595
Batch 8/64 loss: 0.2011890411376953
Batch 9/64 loss: 0.2047806978225708
Batch 10/64 loss: 0.20288777351379395
Batch 11/64 loss: 0.2060772180557251
Batch 12/64 loss: 0.20620864629745483
Batch 13/64 loss: 0.21216297149658203
Batch 14/64 loss: 0.21769940853118896
Batch 15/64 loss: 0.19711780548095703
Batch 16/64 loss: 0.21274757385253906
Batch 17/64 loss: 0.20502400398254395
Batch 18/64 loss: 0.20597565174102783
Batch 19/64 loss: 0.1946777105331421
Batch 20/64 loss: 0.20149797201156616
Batch 21/64 loss: 0.20189225673675537
Batch 22/64 loss: 0.19984686374664307
Batch 23/64 loss: 0.19499969482421875
Batch 24/64 loss: 0.20001184940338135
Batch 25/64 loss: 0.20203548669815063
Batch 26/64 loss: 0.1977933645248413
Batch 27/64 loss: 0.2112586498260498
Batch 28/64 loss: 0.204010009765625
Batch 29/64 loss: 0.19914770126342773
Batch 30/64 loss: 0.19881266355514526
Batch 31/64 loss: 0.19180208444595337
Batch 32/64 loss: 0.19472569227218628
Batch 33/64 loss: 0.20541447401046753
Batch 34/64 loss: 0.19426482915878296
Batch 35/64 loss: 0.19704461097717285
Batch 36/64 loss: 0.21798110008239746
Batch 37/64 loss: 0.19678419828414917
Batch 38/64 loss: 0.1960519552230835
Batch 39/64 loss: 0.19662511348724365
Batch 40/64 loss: 0.20619702339172363
Batch 41/64 loss: 0.20740318298339844
Batch 42/64 loss: 0.19418442249298096
Batch 43/64 loss: 0.20724999904632568
Batch 44/64 loss: 0.1935787796974182
Batch 45/64 loss: 0.2032327651977539
Batch 46/64 loss: 0.20929557085037231
Batch 47/64 loss: 0.20829474925994873
Batch 48/64 loss: 0.20596396923065186
Batch 49/64 loss: 0.2085707187652588
Batch 50/64 loss: 0.20534169673919678
Batch 51/64 loss: 0.19879621267318726
Batch 52/64 loss: 0.1845276951789856
Batch 53/64 loss: 0.20513498783111572
Batch 54/64 loss: 0.21013855934143066
Batch 55/64 loss: 0.19717144966125488
Batch 56/64 loss: 0.20846152305603027
Batch 57/64 loss: 0.20264160633087158
Batch 58/64 loss: 0.19714516401290894
Batch 59/64 loss: 0.2157224416732788
Batch 60/64 loss: 0.2030109167098999
Batch 61/64 loss: 0.20588254928588867
Batch 62/64 loss: 0.2040334939956665
Batch 63/64 loss: 0.19755840301513672
Batch 64/64 loss: 0.21838581562042236
Epoch 360  Train loss: 0.20261283435073554  Val loss: 0.29629352985788454
Epoch 361
-------------------------------
Batch 1/64 loss: 0.1939765214920044
Batch 2/64 loss: 0.20071929693222046
Batch 3/64 loss: 0.19352424144744873
Batch 4/64 loss: 0.2190030813217163
Batch 5/64 loss: 0.2024012804031372
Batch 6/64 loss: 0.18563437461853027
Batch 7/64 loss: 0.19352400302886963
Batch 8/64 loss: 0.19848614931106567
Batch 9/64 loss: 0.21037578582763672
Batch 10/64 loss: 0.19912028312683105
Batch 11/64 loss: 0.19901281595230103
Batch 12/64 loss: 0.19700169563293457
Batch 13/64 loss: 0.19288784265518188
Batch 14/64 loss: 0.20107275247573853
Batch 15/64 loss: 0.2033957839012146
Batch 16/64 loss: 0.20968842506408691
Batch 17/64 loss: 0.19263726472854614
Batch 18/64 loss: 0.2131606936454773
Batch 19/64 loss: 0.2053050994873047
Batch 20/64 loss: 0.19868361949920654
Batch 21/64 loss: 0.19468587636947632
Batch 22/64 loss: 0.21758747100830078
Batch 23/64 loss: 0.19962096214294434
Batch 24/64 loss: 0.20572292804718018
Batch 25/64 loss: 0.20295333862304688
Batch 26/64 loss: 0.19842517375946045
Batch 27/64 loss: 0.20042943954467773
Batch 28/64 loss: 0.21140307188034058
Batch 29/64 loss: 0.21733248233795166
Batch 30/64 loss: 0.21405410766601562
Batch 31/64 loss: 0.20542848110198975
Batch 32/64 loss: 0.20531582832336426
Batch 33/64 loss: 0.19601917266845703
Batch 34/64 loss: 0.21050548553466797
Batch 35/64 loss: 0.20580506324768066
Batch 36/64 loss: 0.20428407192230225
Batch 37/64 loss: 0.1957547664642334
Batch 38/64 loss: 0.19464880228042603
Batch 39/64 loss: 0.18953579664230347
Batch 40/64 loss: 0.20538103580474854
Batch 41/64 loss: 0.2206757664680481
Batch 42/64 loss: 0.19876861572265625
Batch 43/64 loss: 0.20344018936157227
Batch 44/64 loss: 0.20529872179031372
Batch 45/64 loss: 0.20744836330413818
Batch 46/64 loss: 0.1964019536972046
Batch 47/64 loss: 0.20640772581100464
Batch 48/64 loss: 0.20340251922607422
Batch 49/64 loss: 0.19831252098083496
Batch 50/64 loss: 0.21708142757415771
Batch 51/64 loss: 0.20714938640594482
Batch 52/64 loss: 0.19067233800888062
Batch 53/64 loss: 0.21443068981170654
Batch 54/64 loss: 0.20618188381195068
Batch 55/64 loss: 0.20808857679367065
Batch 56/64 loss: 0.21224111318588257
Batch 57/64 loss: 0.19388175010681152
Batch 58/64 loss: 0.21000605821609497
Batch 59/64 loss: 0.21183627843856812
Batch 60/64 loss: 0.20229625701904297
Batch 61/64 loss: 0.2110130786895752
Batch 62/64 loss: 0.20726048946380615
Batch 63/64 loss: 0.2006314992904663
Batch 64/64 loss: 0.21480882167816162
Epoch 361  Train loss: 0.20358491271149878  Val loss: 0.29628331923402873
Epoch 362
-------------------------------
Batch 1/64 loss: 0.2101864218711853
Batch 2/64 loss: 0.204400897026062
Batch 3/64 loss: 0.20397567749023438
Batch 4/64 loss: 0.19881808757781982
Batch 5/64 loss: 0.1977478265762329
Batch 6/64 loss: 0.20196688175201416
Batch 7/64 loss: 0.19788622856140137
Batch 8/64 loss: 0.1944393515586853
Batch 9/64 loss: 0.2008819580078125
Batch 10/64 loss: 0.20577967166900635
Batch 11/64 loss: 0.2004612684249878
Batch 12/64 loss: 0.1995701789855957
Batch 13/64 loss: 0.20474660396575928
Batch 14/64 loss: 0.22005242109298706
Batch 15/64 loss: 0.2068449854850769
Batch 16/64 loss: 0.20025038719177246
Batch 17/64 loss: 0.21493959426879883
Batch 18/64 loss: 0.1943655014038086
Batch 19/64 loss: 0.208276629447937
Batch 20/64 loss: 0.19724971055984497
Batch 21/64 loss: 0.20376014709472656
Batch 22/64 loss: 0.1993827223777771
Batch 23/64 loss: 0.2032235860824585
Batch 24/64 loss: 0.20645880699157715
Batch 25/64 loss: 0.2044808268547058
Batch 26/64 loss: 0.20315766334533691
Batch 27/64 loss: 0.1993781328201294
Batch 28/64 loss: 0.20514416694641113
Batch 29/64 loss: 0.1974877119064331
Batch 30/64 loss: 0.20142853260040283
Batch 31/64 loss: 0.19892001152038574
Batch 32/64 loss: 0.2072853446006775
Batch 33/64 loss: 0.19467389583587646
Batch 34/64 loss: 0.1969839334487915
Batch 35/64 loss: 0.21971046924591064
Batch 36/64 loss: 0.19515681266784668
Batch 37/64 loss: 0.21414077281951904
Batch 38/64 loss: 0.20636093616485596
Batch 39/64 loss: 0.1983036994934082
Batch 40/64 loss: 0.2055342197418213
Batch 41/64 loss: 0.1998814344406128
Batch 42/64 loss: 0.2089630365371704
Batch 43/64 loss: 0.20451223850250244
Batch 44/64 loss: 0.20171892642974854
Batch 45/64 loss: 0.20690011978149414
Batch 46/64 loss: 0.19256550073623657
Batch 47/64 loss: 0.21177232265472412
Batch 48/64 loss: 0.20660430192947388
Batch 49/64 loss: 0.2083742618560791
Batch 50/64 loss: 0.20626282691955566
Batch 51/64 loss: 0.21144568920135498
Batch 52/64 loss: 0.19741398096084595
Batch 53/64 loss: 0.19854694604873657
Batch 54/64 loss: 0.20416897535324097
Batch 55/64 loss: 0.1970425844192505
Batch 56/64 loss: 0.1974271535873413
Batch 57/64 loss: 0.20570510625839233
Batch 58/64 loss: 0.20364993810653687
Batch 59/64 loss: 0.21375644207000732
Batch 60/64 loss: 0.206895112991333
Batch 61/64 loss: 0.2137572169303894
Batch 62/64 loss: 0.21455496549606323
Batch 63/64 loss: 0.20644217729568481
Batch 64/64 loss: 0.1963391900062561
Epoch 362  Train loss: 0.20375573845470654  Val loss: 0.2954145522461724
Epoch 363
-------------------------------
Batch 1/64 loss: 0.19950199127197266
Batch 2/64 loss: 0.19493603706359863
Batch 3/64 loss: 0.226742684841156
Batch 4/64 loss: 0.20996582508087158
Batch 5/64 loss: 0.1911029815673828
Batch 6/64 loss: 0.21070361137390137
Batch 7/64 loss: 0.2104528546333313
Batch 8/64 loss: 0.1962922215461731
Batch 9/64 loss: 0.20778274536132812
Batch 10/64 loss: 0.19784891605377197
Batch 11/64 loss: 0.21089327335357666
Batch 12/64 loss: 0.21157509088516235
Batch 13/64 loss: 0.20681500434875488
Batch 14/64 loss: 0.20267784595489502
Batch 15/64 loss: 0.20618879795074463
Batch 16/64 loss: 0.208204984664917
Batch 17/64 loss: 0.20752573013305664
Batch 18/64 loss: 0.19230437278747559
Batch 19/64 loss: 0.20047664642333984
Batch 20/64 loss: 0.19225192070007324
Batch 21/64 loss: 0.2074882984161377
Batch 22/64 loss: 0.2025374174118042
Batch 23/64 loss: 0.2049412727355957
Batch 24/64 loss: 0.20017242431640625
Batch 25/64 loss: 0.19798249006271362
Batch 26/64 loss: 0.19960373640060425
Batch 27/64 loss: 0.21124446392059326
Batch 28/64 loss: 0.21396589279174805
Batch 29/64 loss: 0.20427536964416504
Batch 30/64 loss: 0.20634102821350098
Batch 31/64 loss: 0.19273048639297485
Batch 32/64 loss: 0.19784188270568848
Batch 33/64 loss: 0.21218639612197876
Batch 34/64 loss: 0.19695806503295898
Batch 35/64 loss: 0.20133984088897705
Batch 36/64 loss: 0.21217751502990723
Batch 37/64 loss: 0.19582700729370117
Batch 38/64 loss: 0.20232391357421875
Batch 39/64 loss: 0.21276390552520752
Batch 40/64 loss: 0.1882672905921936
Batch 41/64 loss: 0.2183842658996582
Batch 42/64 loss: 0.20825862884521484
Batch 43/64 loss: 0.20522236824035645
Batch 44/64 loss: 0.20664554834365845
Batch 45/64 loss: 0.21947747468948364
Batch 46/64 loss: 0.20444703102111816
Batch 47/64 loss: 0.18921691179275513
Batch 48/64 loss: 0.18789511919021606
Batch 49/64 loss: 0.22028779983520508
Batch 50/64 loss: 0.19927501678466797
Batch 51/64 loss: 0.21887516975402832
Batch 52/64 loss: 0.2080763578414917
Batch 53/64 loss: 0.20855557918548584
Batch 54/64 loss: 0.19217222929000854
Batch 55/64 loss: 0.2043074369430542
Batch 56/64 loss: 0.21157044172286987
Batch 57/64 loss: 0.20680177211761475
Batch 58/64 loss: 0.2013065218925476
Batch 59/64 loss: 0.2051018476486206
Batch 60/64 loss: 0.19854235649108887
Batch 61/64 loss: 0.2013149857521057
Batch 62/64 loss: 0.2018423080444336
Batch 63/64 loss: 0.20383715629577637
Batch 64/64 loss: 0.2154066562652588
Epoch 363  Train loss: 0.20436363220214843  Val loss: 0.2958633444972874
Epoch 364
-------------------------------
Batch 1/64 loss: 0.20248430967330933
Batch 2/64 loss: 0.19228285551071167
Batch 3/64 loss: 0.2066175937652588
Batch 4/64 loss: 0.19167816638946533
Batch 5/64 loss: 0.20750105381011963
Batch 6/64 loss: 0.18650835752487183
Batch 7/64 loss: 0.198178231716156
Batch 8/64 loss: 0.2205834984779358
Batch 9/64 loss: 0.20614475011825562
Batch 10/64 loss: 0.19625234603881836
Batch 11/64 loss: 0.20892608165740967
Batch 12/64 loss: 0.2165968418121338
Batch 13/64 loss: 0.20599156618118286
Batch 14/64 loss: 0.20087838172912598
Batch 15/64 loss: 0.18526345491409302
Batch 16/64 loss: 0.2102816104888916
Batch 17/64 loss: 0.1975691318511963
Batch 18/64 loss: 0.19788169860839844
Batch 19/64 loss: 0.20279550552368164
Batch 20/64 loss: 0.2022690773010254
Batch 21/64 loss: 0.1941380500793457
Batch 22/64 loss: 0.2053324580192566
Batch 23/64 loss: 0.1919155716896057
Batch 24/64 loss: 0.2056562304496765
Batch 25/64 loss: 0.19539129734039307
Batch 26/64 loss: 0.20849347114562988
Batch 27/64 loss: 0.19656014442443848
Batch 28/64 loss: 0.21333515644073486
Batch 29/64 loss: 0.19087553024291992
Batch 30/64 loss: 0.20596522092819214
Batch 31/64 loss: 0.19325560331344604
Batch 32/64 loss: 0.20227259397506714
Batch 33/64 loss: 0.19834309816360474
Batch 34/64 loss: 0.20753705501556396
Batch 35/64 loss: 0.1989961862564087
Batch 36/64 loss: 0.2095026969909668
Batch 37/64 loss: 0.202251136302948
Batch 38/64 loss: 0.20564895868301392
Batch 39/64 loss: 0.1925828456878662
Batch 40/64 loss: 0.207802414894104
Batch 41/64 loss: 0.20176374912261963
Batch 42/64 loss: 0.20492982864379883
Batch 43/64 loss: 0.20112121105194092
Batch 44/64 loss: 0.2041149139404297
Batch 45/64 loss: 0.21227890253067017
Batch 46/64 loss: 0.21400940418243408
Batch 47/64 loss: 0.19721448421478271
Batch 48/64 loss: 0.19773614406585693
Batch 49/64 loss: 0.2015089988708496
Batch 50/64 loss: 0.19513863325119019
Batch 51/64 loss: 0.2018490433692932
Batch 52/64 loss: 0.19623160362243652
Batch 53/64 loss: 0.2044242024421692
Batch 54/64 loss: 0.19421309232711792
Batch 55/64 loss: 0.19750964641571045
Batch 56/64 loss: 0.1943836808204651
Batch 57/64 loss: 0.2005135416984558
Batch 58/64 loss: 0.2021033763885498
Batch 59/64 loss: 0.2086324691772461
Batch 60/64 loss: 0.19825410842895508
Batch 61/64 loss: 0.20516932010650635
Batch 62/64 loss: 0.20010030269622803
Batch 63/64 loss: 0.19462299346923828
Batch 64/64 loss: 0.18688946962356567
Epoch 364  Train loss: 0.2012632311559191  Val loss: 0.2957161013613042
Epoch 365
-------------------------------
Batch 1/64 loss: 0.20587384700775146
Batch 2/64 loss: 0.2141944169998169
Batch 3/64 loss: 0.19463926553726196
Batch 4/64 loss: 0.2005394697189331
Batch 5/64 loss: 0.19162005186080933
Batch 6/64 loss: 0.19122529029846191
Batch 7/64 loss: 0.18898916244506836
Batch 8/64 loss: 0.2032451629638672
Batch 9/64 loss: 0.19854122400283813
Batch 10/64 loss: 0.19452768564224243
Batch 11/64 loss: 0.1989428997039795
Batch 12/64 loss: 0.1985899806022644
Batch 13/64 loss: 0.20378947257995605
Batch 14/64 loss: 0.19070649147033691
Batch 15/64 loss: 0.19475597143173218
Batch 16/64 loss: 0.20878911018371582
Batch 17/64 loss: 0.19430303573608398
Batch 18/64 loss: 0.20571613311767578
Batch 19/64 loss: 0.20141077041625977
Batch 20/64 loss: 0.20234692096710205
Batch 21/64 loss: 0.19952815771102905
Batch 22/64 loss: 0.20147699117660522
Batch 23/64 loss: 0.20922106504440308
Batch 24/64 loss: 0.20766091346740723
Batch 25/64 loss: 0.19746917486190796
Batch 26/64 loss: 0.19992119073867798
Batch 27/64 loss: 0.19415497779846191
Batch 28/64 loss: 0.19745135307312012
Batch 29/64 loss: 0.20471394062042236
Batch 30/64 loss: 0.20951759815216064
Batch 31/64 loss: 0.19436562061309814
Batch 32/64 loss: 0.1974833607673645
Batch 33/64 loss: 0.19817912578582764
Batch 34/64 loss: 0.2119884490966797
Batch 35/64 loss: 0.20064514875411987
Batch 36/64 loss: 0.20152831077575684
Batch 37/64 loss: 0.20428848266601562
Batch 38/64 loss: 0.19842231273651123
Batch 39/64 loss: 0.20476967096328735
Batch 40/64 loss: 0.19723069667816162
Batch 41/64 loss: 0.1997753381729126
Batch 42/64 loss: 0.20149368047714233
Batch 43/64 loss: 0.20641803741455078
Batch 44/64 loss: 0.2081526517868042
Batch 45/64 loss: 0.1924436092376709
Batch 46/64 loss: 0.20087885856628418
Batch 47/64 loss: 0.1984592080116272
Batch 48/64 loss: 0.20436429977416992
Batch 49/64 loss: 0.19997382164001465
Batch 50/64 loss: 0.20135992765426636
Batch 51/64 loss: 0.20604485273361206
Batch 52/64 loss: 0.20239800214767456
Batch 53/64 loss: 0.21516108512878418
Batch 54/64 loss: 0.20427227020263672
Batch 55/64 loss: 0.19991129636764526
Batch 56/64 loss: 0.20239746570587158
Batch 57/64 loss: 0.21078038215637207
Batch 58/64 loss: 0.1963326334953308
Batch 59/64 loss: 0.1959242820739746
Batch 60/64 loss: 0.21043527126312256
Batch 61/64 loss: 0.19707107543945312
Batch 62/64 loss: 0.20405948162078857
Batch 63/64 loss: 0.1970134973526001
Batch 64/64 loss: 0.21485626697540283
Epoch 365  Train loss: 0.20123962561289468  Val loss: 0.2960017683989404
Epoch 366
-------------------------------
Batch 1/64 loss: 0.1935058832168579
Batch 2/64 loss: 0.19778531789779663
Batch 3/64 loss: 0.19393932819366455
Batch 4/64 loss: 0.2002195119857788
Batch 5/64 loss: 0.20689356327056885
Batch 6/64 loss: 0.1938861608505249
Batch 7/64 loss: 0.20445096492767334
Batch 8/64 loss: 0.215015709400177
Batch 9/64 loss: 0.19794464111328125
Batch 10/64 loss: 0.1934247612953186
Batch 11/64 loss: 0.2056330442428589
Batch 12/64 loss: 0.20274114608764648
Batch 13/64 loss: 0.18853026628494263
Batch 14/64 loss: 0.20034801959991455
Batch 15/64 loss: 0.1967686414718628
Batch 16/64 loss: 0.19910693168640137
Batch 17/64 loss: 0.20601940155029297
Batch 18/64 loss: 0.18785089254379272
Batch 19/64 loss: 0.1906070113182068
Batch 20/64 loss: 0.1910545825958252
Batch 21/64 loss: 0.2047274112701416
Batch 22/64 loss: 0.19770896434783936
Batch 23/64 loss: 0.2083442211151123
Batch 24/64 loss: 0.2093203067779541
Batch 25/64 loss: 0.19173669815063477
Batch 26/64 loss: 0.2011510729789734
Batch 27/64 loss: 0.19749784469604492
Batch 28/64 loss: 0.19437867403030396
Batch 29/64 loss: 0.20489227771759033
Batch 30/64 loss: 0.1991083025932312
Batch 31/64 loss: 0.20292943716049194
Batch 32/64 loss: 0.21114975214004517
Batch 33/64 loss: 0.21037602424621582
Batch 34/64 loss: 0.22688078880310059
Batch 35/64 loss: 0.21849900484085083
Batch 36/64 loss: 0.1977301836013794
Batch 37/64 loss: 0.20020461082458496
Batch 38/64 loss: 0.20646196603775024
Batch 39/64 loss: 0.19696152210235596
Batch 40/64 loss: 0.19876182079315186
Batch 41/64 loss: 0.21054565906524658
Batch 42/64 loss: 0.2015513777732849
Batch 43/64 loss: 0.20265251398086548
Batch 44/64 loss: 0.20798826217651367
Batch 45/64 loss: 0.20719313621520996
Batch 46/64 loss: 0.20976746082305908
Batch 47/64 loss: 0.201907217502594
Batch 48/64 loss: 0.20853018760681152
Batch 49/64 loss: 0.22249382734298706
Batch 50/64 loss: 0.20155620574951172
Batch 51/64 loss: 0.20582395792007446
Batch 52/64 loss: 0.1900707483291626
Batch 53/64 loss: 0.20208585262298584
Batch 54/64 loss: 0.1997997760772705
Batch 55/64 loss: 0.2008482813835144
Batch 56/64 loss: 0.19930976629257202
Batch 57/64 loss: 0.1889623999595642
Batch 58/64 loss: 0.20574980974197388
Batch 59/64 loss: 0.20558470487594604
Batch 60/64 loss: 0.19997918605804443
Batch 61/64 loss: 0.2046746015548706
Batch 62/64 loss: 0.19584083557128906
Batch 63/64 loss: 0.20257198810577393
Batch 64/64 loss: 0.21217036247253418
Epoch 366  Train loss: 0.20202607360540653  Val loss: 0.29551956047307176
Epoch 367
-------------------------------
Batch 1/64 loss: 0.20235180854797363
Batch 2/64 loss: 0.19933629035949707
Batch 3/64 loss: 0.20215260982513428
Batch 4/64 loss: 0.20201408863067627
Batch 5/64 loss: 0.1983809471130371
Batch 6/64 loss: 0.19422686100006104
Batch 7/64 loss: 0.20604819059371948
Batch 8/64 loss: 0.20016789436340332
Batch 9/64 loss: 0.19979912042617798
Batch 10/64 loss: 0.20700788497924805
Batch 11/64 loss: 0.20058536529541016
Batch 12/64 loss: 0.19827067852020264
Batch 13/64 loss: 0.21185213327407837
Batch 14/64 loss: 0.20558464527130127
Batch 15/64 loss: 0.21399879455566406
Batch 16/64 loss: 0.2033553123474121
Batch 17/64 loss: 0.20914554595947266
Batch 18/64 loss: 0.20086824893951416
Batch 19/64 loss: 0.19824230670928955
Batch 20/64 loss: 0.1952030062675476
Batch 21/64 loss: 0.20185589790344238
Batch 22/64 loss: 0.20273053646087646
Batch 23/64 loss: 0.21064329147338867
Batch 24/64 loss: 0.2082289457321167
Batch 25/64 loss: 0.21476316452026367
Batch 26/64 loss: 0.20226913690567017
Batch 27/64 loss: 0.19361287355422974
Batch 28/64 loss: 0.19552946090698242
Batch 29/64 loss: 0.20486891269683838
Batch 30/64 loss: 0.19654536247253418
Batch 31/64 loss: 0.20370566844940186
Batch 32/64 loss: 0.19349199533462524
Batch 33/64 loss: 0.203230619430542
Batch 34/64 loss: 0.2152726650238037
Batch 35/64 loss: 0.21679222583770752
Batch 36/64 loss: 0.20369285345077515
Batch 37/64 loss: 0.20658493041992188
Batch 38/64 loss: 0.19431215524673462
Batch 39/64 loss: 0.20100665092468262
Batch 40/64 loss: 0.1880607008934021
Batch 41/64 loss: 0.19389522075653076
Batch 42/64 loss: 0.1969028115272522
Batch 43/64 loss: 0.19572830200195312
Batch 44/64 loss: 0.20487868785858154
Batch 45/64 loss: 0.19875884056091309
Batch 46/64 loss: 0.19636303186416626
Batch 47/64 loss: 0.19867432117462158
Batch 48/64 loss: 0.20518839359283447
Batch 49/64 loss: 0.20244383811950684
Batch 50/64 loss: 0.2087033987045288
Batch 51/64 loss: 0.19883525371551514
Batch 52/64 loss: 0.20378458499908447
Batch 53/64 loss: 0.1976090669631958
Batch 54/64 loss: 0.19785863161087036
Batch 55/64 loss: 0.19837617874145508
Batch 56/64 loss: 0.19472676515579224
Batch 57/64 loss: 0.2096242904663086
Batch 58/64 loss: 0.2043219804763794
Batch 59/64 loss: 0.20006752014160156
Batch 60/64 loss: 0.2221810221672058
Batch 61/64 loss: 0.20362931489944458
Batch 62/64 loss: 0.20931309461593628
Batch 63/64 loss: 0.20395594835281372
Batch 64/64 loss: 0.2034500241279602
Epoch 367  Train loss: 0.20241878897536034  Val loss: 0.29621528432131633
Epoch 368
-------------------------------
Batch 1/64 loss: 0.19869863986968994
Batch 2/64 loss: 0.1941623091697693
Batch 3/64 loss: 0.197429358959198
Batch 4/64 loss: 0.1992853879928589
Batch 5/64 loss: 0.20190316438674927
Batch 6/64 loss: 0.20142793655395508
Batch 7/64 loss: 0.2055559754371643
Batch 8/64 loss: 0.21046721935272217
Batch 9/64 loss: 0.2122509479522705
Batch 10/64 loss: 0.21011751890182495
Batch 11/64 loss: 0.2044697403907776
Batch 12/64 loss: 0.19509416818618774
Batch 13/64 loss: 0.1967407464981079
Batch 14/64 loss: 0.19041824340820312
Batch 15/64 loss: 0.20951223373413086
Batch 16/64 loss: 0.21399784088134766
Batch 17/64 loss: 0.18962103128433228
Batch 18/64 loss: 0.21371519565582275
Batch 19/64 loss: 0.213006854057312
Batch 20/64 loss: 0.1928013563156128
Batch 21/64 loss: 0.19291353225708008
Batch 22/64 loss: 0.20739364624023438
Batch 23/64 loss: 0.19699066877365112
Batch 24/64 loss: 0.20006698369979858
Batch 25/64 loss: 0.2039363980293274
Batch 26/64 loss: 0.20503997802734375
Batch 27/64 loss: 0.20160210132598877
Batch 28/64 loss: 0.21398210525512695
Batch 29/64 loss: 0.19751191139221191
Batch 30/64 loss: 0.2087390422821045
Batch 31/64 loss: 0.21189385652542114
Batch 32/64 loss: 0.20311492681503296
Batch 33/64 loss: 0.19795739650726318
Batch 34/64 loss: 0.21450066566467285
Batch 35/64 loss: 0.19633567333221436
Batch 36/64 loss: 0.1972036361694336
Batch 37/64 loss: 0.20552802085876465
Batch 38/64 loss: 0.19943201541900635
Batch 39/64 loss: 0.21135962009429932
Batch 40/64 loss: 0.20522534847259521
Batch 41/64 loss: 0.19407975673675537
Batch 42/64 loss: 0.20165574550628662
Batch 43/64 loss: 0.20257580280303955
Batch 44/64 loss: 0.20294451713562012
Batch 45/64 loss: 0.20018935203552246
Batch 46/64 loss: 0.21444523334503174
Batch 47/64 loss: 0.1950228214263916
Batch 48/64 loss: 0.19856828451156616
Batch 49/64 loss: 0.2036278247833252
Batch 50/64 loss: 0.19255059957504272
Batch 51/64 loss: 0.18929356336593628
Batch 52/64 loss: 0.19092249870300293
Batch 53/64 loss: 0.20691299438476562
Batch 54/64 loss: 0.19230598211288452
Batch 55/64 loss: 0.2120058536529541
Batch 56/64 loss: 0.18877434730529785
Batch 57/64 loss: 0.18947213888168335
Batch 58/64 loss: 0.20442920923233032
Batch 59/64 loss: 0.20486211776733398
Batch 60/64 loss: 0.2161327600479126
Batch 61/64 loss: 0.19887900352478027
Batch 62/64 loss: 0.18322694301605225
Batch 63/64 loss: 0.21465682983398438
Batch 64/64 loss: 0.20706111192703247
Epoch 368  Train loss: 0.20194875936882167  Val loss: 0.2970593233698422
Epoch 369
-------------------------------
Batch 1/64 loss: 0.20520436763763428
Batch 2/64 loss: 0.21338891983032227
Batch 3/64 loss: 0.20692509412765503
Batch 4/64 loss: 0.2036576271057129
Batch 5/64 loss: 0.1977977752685547
Batch 6/64 loss: 0.20369595289230347
Batch 7/64 loss: 0.19345366954803467
Batch 8/64 loss: 0.2066478729248047
Batch 9/64 loss: 0.20333266258239746
Batch 10/64 loss: 0.19193273782730103
Batch 11/64 loss: 0.1943284273147583
Batch 12/64 loss: 0.20678269863128662
Batch 13/64 loss: 0.2078723907470703
Batch 14/64 loss: 0.19083595275878906
Batch 15/64 loss: 0.20358145236968994
Batch 16/64 loss: 0.21030724048614502
Batch 17/64 loss: 0.19851505756378174
Batch 18/64 loss: 0.19885611534118652
Batch 19/64 loss: 0.20734643936157227
Batch 20/64 loss: 0.20024538040161133
Batch 21/64 loss: 0.20245522260665894
Batch 22/64 loss: 0.2072688341140747
Batch 23/64 loss: 0.18837565183639526
Batch 24/64 loss: 0.20100778341293335
Batch 25/64 loss: 0.19413673877716064
Batch 26/64 loss: 0.20095914602279663
Batch 27/64 loss: 0.201224684715271
Batch 28/64 loss: 0.20948749780654907
Batch 29/64 loss: 0.19336462020874023
Batch 30/64 loss: 0.1896384358406067
Batch 31/64 loss: 0.198619544506073
Batch 32/64 loss: 0.2095733880996704
Batch 33/64 loss: 0.19430017471313477
Batch 34/64 loss: 0.18906420469284058
Batch 35/64 loss: 0.208698570728302
Batch 36/64 loss: 0.20612066984176636
Batch 37/64 loss: 0.19537115097045898
Batch 38/64 loss: 0.19921159744262695
Batch 39/64 loss: 0.19871848821640015
Batch 40/64 loss: 0.19716620445251465
Batch 41/64 loss: 0.20355677604675293
Batch 42/64 loss: 0.2019730806350708
Batch 43/64 loss: 0.20438611507415771
Batch 44/64 loss: 0.2033902406692505
Batch 45/64 loss: 0.19349145889282227
Batch 46/64 loss: 0.1967017650604248
Batch 47/64 loss: 0.20705115795135498
Batch 48/64 loss: 0.21494746208190918
Batch 49/64 loss: 0.19465774297714233
Batch 50/64 loss: 0.19885742664337158
Batch 51/64 loss: 0.20520228147506714
Batch 52/64 loss: 0.20142316818237305
Batch 53/64 loss: 0.2087709903717041
Batch 54/64 loss: 0.20208847522735596
Batch 55/64 loss: 0.1959909200668335
Batch 56/64 loss: 0.206720232963562
Batch 57/64 loss: 0.21033620834350586
Batch 58/64 loss: 0.19996726512908936
Batch 59/64 loss: 0.2188476324081421
Batch 60/64 loss: 0.21051710844039917
Batch 61/64 loss: 0.1957378387451172
Batch 62/64 loss: 0.19269347190856934
Batch 63/64 loss: 0.20193755626678467
Batch 64/64 loss: 0.20867472887039185
Epoch 369  Train loss: 0.20165055475982965  Val loss: 0.29620478775902714
Epoch 370
-------------------------------
Batch 1/64 loss: 0.19651073217391968
Batch 2/64 loss: 0.21197903156280518
Batch 3/64 loss: 0.20912575721740723
Batch 4/64 loss: 0.2110787034034729
Batch 5/64 loss: 0.20036280155181885
Batch 6/64 loss: 0.19816946983337402
Batch 7/64 loss: 0.19153106212615967
Batch 8/64 loss: 0.2076636552810669
Batch 9/64 loss: 0.19913828372955322
Batch 10/64 loss: 0.20368170738220215
Batch 11/64 loss: 0.2084771990776062
Batch 12/64 loss: 0.20198482275009155
Batch 13/64 loss: 0.2008833885192871
Batch 14/64 loss: 0.21305161714553833
Batch 15/64 loss: 0.20172488689422607
Batch 16/64 loss: 0.20346689224243164
Batch 17/64 loss: 0.20331799983978271
Batch 18/64 loss: 0.18511176109313965
Batch 19/64 loss: 0.19821566343307495
Batch 20/64 loss: 0.21937716007232666
Batch 21/64 loss: 0.1971752643585205
Batch 22/64 loss: 0.19443124532699585
Batch 23/64 loss: 0.1945502758026123
Batch 24/64 loss: 0.19265657663345337
Batch 25/64 loss: 0.19957029819488525
Batch 26/64 loss: 0.21405029296875
Batch 27/64 loss: 0.19780534505844116
Batch 28/64 loss: 0.192435622215271
Batch 29/64 loss: 0.21175557374954224
Batch 30/64 loss: 0.20797652006149292
Batch 31/64 loss: 0.19041496515274048
Batch 32/64 loss: 0.195203959941864
Batch 33/64 loss: 0.20948266983032227
Batch 34/64 loss: 0.21445423364639282
Batch 35/64 loss: 0.20710104703903198
Batch 36/64 loss: 0.20471590757369995
Batch 37/64 loss: 0.19973421096801758
Batch 38/64 loss: 0.19890546798706055
Batch 39/64 loss: 0.2025812864303589
Batch 40/64 loss: 0.20527660846710205
Batch 41/64 loss: 0.20805394649505615
Batch 42/64 loss: 0.1939907670021057
Batch 43/64 loss: 0.19493573904037476
Batch 44/64 loss: 0.20131808519363403
Batch 45/64 loss: 0.20466536283493042
Batch 46/64 loss: 0.20464491844177246
Batch 47/64 loss: 0.20092320442199707
Batch 48/64 loss: 0.2050461769104004
Batch 49/64 loss: 0.21277523040771484
Batch 50/64 loss: 0.20158600807189941
Batch 51/64 loss: 0.2157975435256958
Batch 52/64 loss: 0.19691705703735352
Batch 53/64 loss: 0.1971568465232849
Batch 54/64 loss: 0.20369118452072144
Batch 55/64 loss: 0.20708101987838745
Batch 56/64 loss: 0.2027178406715393
Batch 57/64 loss: 0.1945996880531311
Batch 58/64 loss: 0.21298432350158691
Batch 59/64 loss: 0.20318591594696045
Batch 60/64 loss: 0.19820237159729004
Batch 61/64 loss: 0.20340490341186523
Batch 62/64 loss: 0.19444811344146729
Batch 63/64 loss: 0.19746661186218262
Batch 64/64 loss: 0.19567161798477173
Epoch 370  Train loss: 0.20231335747475718  Val loss: 0.29637630084126265
Epoch 371
-------------------------------
Batch 1/64 loss: 0.2040501832962036
Batch 2/64 loss: 0.2073366641998291
Batch 3/64 loss: 0.20104944705963135
Batch 4/64 loss: 0.1922692060470581
Batch 5/64 loss: 0.1913982629776001
Batch 6/64 loss: 0.21110641956329346
Batch 7/64 loss: 0.21241796016693115
Batch 8/64 loss: 0.19696342945098877
Batch 9/64 loss: 0.1956789493560791
Batch 10/64 loss: 0.20366859436035156
Batch 11/64 loss: 0.1966545581817627
Batch 12/64 loss: 0.19880592823028564
Batch 13/64 loss: 0.19586211442947388
Batch 14/64 loss: 0.20127630233764648
Batch 15/64 loss: 0.2022939920425415
Batch 16/64 loss: 0.20748335123062134
Batch 17/64 loss: 0.19384139776229858
Batch 18/64 loss: 0.1920967698097229
Batch 19/64 loss: 0.18976765871047974
Batch 20/64 loss: 0.2007008194923401
Batch 21/64 loss: 0.18875133991241455
Batch 22/64 loss: 0.20477616786956787
Batch 23/64 loss: 0.19876503944396973
Batch 24/64 loss: 0.1959850788116455
Batch 25/64 loss: 0.19990527629852295
Batch 26/64 loss: 0.201202392578125
Batch 27/64 loss: 0.21098077297210693
Batch 28/64 loss: 0.19220149517059326
Batch 29/64 loss: 0.20009493827819824
Batch 30/64 loss: 0.19668567180633545
Batch 31/64 loss: 0.20512157678604126
Batch 32/64 loss: 0.21392381191253662
Batch 33/64 loss: 0.2102331519126892
Batch 34/64 loss: 0.2091078758239746
Batch 35/64 loss: 0.2063220739364624
Batch 36/64 loss: 0.18982470035552979
Batch 37/64 loss: 0.19362598657608032
Batch 38/64 loss: 0.20138901472091675
Batch 39/64 loss: 0.2183396816253662
Batch 40/64 loss: 0.19707238674163818
Batch 41/64 loss: 0.20809102058410645
Batch 42/64 loss: 0.19799572229385376
Batch 43/64 loss: 0.20881402492523193
Batch 44/64 loss: 0.19513875246047974
Batch 45/64 loss: 0.21147668361663818
Batch 46/64 loss: 0.21267175674438477
Batch 47/64 loss: 0.20029723644256592
Batch 48/64 loss: 0.21366775035858154
Batch 49/64 loss: 0.19780397415161133
Batch 50/64 loss: 0.19349652528762817
Batch 51/64 loss: 0.20204919576644897
Batch 52/64 loss: 0.20298540592193604
Batch 53/64 loss: 0.20836353302001953
Batch 54/64 loss: 0.19595175981521606
Batch 55/64 loss: 0.19354844093322754
Batch 56/64 loss: 0.20008456707000732
Batch 57/64 loss: 0.20119786262512207
Batch 58/64 loss: 0.20153307914733887
Batch 59/64 loss: 0.20648205280303955
Batch 60/64 loss: 0.20132076740264893
Batch 61/64 loss: 0.20848321914672852
Batch 62/64 loss: 0.18855124711990356
Batch 63/64 loss: 0.22588598728179932
Batch 64/64 loss: 0.2117946743965149
Epoch 371  Train loss: 0.20178458059535306  Val loss: 0.2961900510738805
Epoch 372
-------------------------------
Batch 1/64 loss: 0.1965535283088684
Batch 2/64 loss: 0.1900985836982727
Batch 3/64 loss: 0.19597339630126953
Batch 4/64 loss: 0.2008267641067505
Batch 5/64 loss: 0.20097535848617554
Batch 6/64 loss: 0.1958698034286499
Batch 7/64 loss: 0.20698899030685425
Batch 8/64 loss: 0.20345520973205566
Batch 9/64 loss: 0.20474791526794434
Batch 10/64 loss: 0.2006392478942871
Batch 11/64 loss: 0.21270453929901123
Batch 12/64 loss: 0.1968749761581421
Batch 13/64 loss: 0.19775956869125366
Batch 14/64 loss: 0.19841110706329346
Batch 15/64 loss: 0.2102947235107422
Batch 16/64 loss: 0.2066594362258911
Batch 17/64 loss: 0.20655286312103271
Batch 18/64 loss: 0.1901780366897583
Batch 19/64 loss: 0.21026813983917236
Batch 20/64 loss: 0.20904815196990967
Batch 21/64 loss: 0.20124489068984985
Batch 22/64 loss: 0.1996527910232544
Batch 23/64 loss: 0.20260369777679443
Batch 24/64 loss: 0.1953696608543396
Batch 25/64 loss: 0.2081710696220398
Batch 26/64 loss: 0.20262455940246582
Batch 27/64 loss: 0.1988365650177002
Batch 28/64 loss: 0.198944091796875
Batch 29/64 loss: 0.2176429033279419
Batch 30/64 loss: 0.196081280708313
Batch 31/64 loss: 0.19311660528182983
Batch 32/64 loss: 0.2008594274520874
Batch 33/64 loss: 0.19456958770751953
Batch 34/64 loss: 0.20148444175720215
Batch 35/64 loss: 0.202031672000885
Batch 36/64 loss: 0.208593487739563
Batch 37/64 loss: 0.20065045356750488
Batch 38/64 loss: 0.2171025276184082
Batch 39/64 loss: 0.190737783908844
Batch 40/64 loss: 0.18672198057174683
Batch 41/64 loss: 0.2065807580947876
Batch 42/64 loss: 0.2155013084411621
Batch 43/64 loss: 0.1934911608695984
Batch 44/64 loss: 0.20373868942260742
Batch 45/64 loss: 0.20382869243621826
Batch 46/64 loss: 0.20971965789794922
Batch 47/64 loss: 0.20072412490844727
Batch 48/64 loss: 0.20248878002166748
Batch 49/64 loss: 0.20626485347747803
Batch 50/64 loss: 0.19652116298675537
Batch 51/64 loss: 0.20071709156036377
Batch 52/64 loss: 0.19347929954528809
Batch 53/64 loss: 0.21018970012664795
Batch 54/64 loss: 0.19576627016067505
Batch 55/64 loss: 0.1978520154953003
Batch 56/64 loss: 0.19924670457839966
Batch 57/64 loss: 0.1948128342628479
Batch 58/64 loss: 0.19809716939926147
Batch 59/64 loss: 0.19709694385528564
Batch 60/64 loss: 0.2078799605369568
Batch 61/64 loss: 0.1894962191581726
Batch 62/64 loss: 0.20607393980026245
Batch 63/64 loss: 0.20659363269805908
Batch 64/64 loss: 0.19905853271484375
Epoch 372  Train loss: 0.20137058332854627  Val loss: 0.29564772397791805
Epoch 373
-------------------------------
Batch 1/64 loss: 0.19730830192565918
Batch 2/64 loss: 0.19968068599700928
Batch 3/64 loss: 0.19894492626190186
Batch 4/64 loss: 0.1949349045753479
Batch 5/64 loss: 0.2040313482284546
Batch 6/64 loss: 0.2019733190536499
Batch 7/64 loss: 0.2030419111251831
Batch 8/64 loss: 0.1943737268447876
Batch 9/64 loss: 0.20428967475891113
Batch 10/64 loss: 0.19045484066009521
Batch 11/64 loss: 0.1956828236579895
Batch 12/64 loss: 0.19903403520584106
Batch 13/64 loss: 0.198195219039917
Batch 14/64 loss: 0.20180553197860718
Batch 15/64 loss: 0.19765782356262207
Batch 16/64 loss: 0.20428287982940674
Batch 17/64 loss: 0.19602221250534058
Batch 18/64 loss: 0.191178560256958
Batch 19/64 loss: 0.19167929887771606
Batch 20/64 loss: 0.19392412900924683
Batch 21/64 loss: 0.18816477060317993
Batch 22/64 loss: 0.18801069259643555
Batch 23/64 loss: 0.1986454725265503
Batch 24/64 loss: 0.19262051582336426
Batch 25/64 loss: 0.2051539421081543
Batch 26/64 loss: 0.19843995571136475
Batch 27/64 loss: 0.20521074533462524
Batch 28/64 loss: 0.2005968689918518
Batch 29/64 loss: 0.19199323654174805
Batch 30/64 loss: 0.19418787956237793
Batch 31/64 loss: 0.20025551319122314
Batch 32/64 loss: 0.1959821581840515
Batch 33/64 loss: 0.2109363079071045
Batch 34/64 loss: 0.20450067520141602
Batch 35/64 loss: 0.2129945158958435
Batch 36/64 loss: 0.2056502103805542
Batch 37/64 loss: 0.19715845584869385
Batch 38/64 loss: 0.21424108743667603
Batch 39/64 loss: 0.21194422245025635
Batch 40/64 loss: 0.20432806015014648
Batch 41/64 loss: 0.19290071725845337
Batch 42/64 loss: 0.2047123908996582
Batch 43/64 loss: 0.1937464475631714
Batch 44/64 loss: 0.20293009281158447
Batch 45/64 loss: 0.20576035976409912
Batch 46/64 loss: 0.19068723917007446
Batch 47/64 loss: 0.1969238519668579
Batch 48/64 loss: 0.19904357194900513
Batch 49/64 loss: 0.20568645000457764
Batch 50/64 loss: 0.20454716682434082
Batch 51/64 loss: 0.20939600467681885
Batch 52/64 loss: 0.20399469137191772
Batch 53/64 loss: 0.19373440742492676
Batch 54/64 loss: 0.20366394519805908
Batch 55/64 loss: 0.2048400640487671
Batch 56/64 loss: 0.2019398808479309
Batch 57/64 loss: 0.20426470041275024
Batch 58/64 loss: 0.19734138250350952
Batch 59/64 loss: 0.20198285579681396
Batch 60/64 loss: 0.19946402311325073
Batch 61/64 loss: 0.20665854215621948
Batch 62/64 loss: 0.20976334810256958
Batch 63/64 loss: 0.2126302719116211
Batch 64/64 loss: 0.20090293884277344
Epoch 373  Train loss: 0.2004204086228913  Val loss: 0.29594221065953835
Epoch 374
-------------------------------
Batch 1/64 loss: 0.198083758354187
Batch 2/64 loss: 0.2095736861228943
Batch 3/64 loss: 0.2153313159942627
Batch 4/64 loss: 0.1972736120223999
Batch 5/64 loss: 0.19907736778259277
Batch 6/64 loss: 0.19645506143569946
Batch 7/64 loss: 0.20501506328582764
Batch 8/64 loss: 0.20361322164535522
Batch 9/64 loss: 0.2006528377532959
Batch 10/64 loss: 0.202994704246521
Batch 11/64 loss: 0.20724272727966309
Batch 12/64 loss: 0.2006005048751831
Batch 13/64 loss: 0.20217669010162354
Batch 14/64 loss: 0.19972068071365356
Batch 15/64 loss: 0.20488768815994263
Batch 16/64 loss: 0.1989130973815918
Batch 17/64 loss: 0.18952876329421997
Batch 18/64 loss: 0.20802181959152222
Batch 19/64 loss: 0.19607579708099365
Batch 20/64 loss: 0.2021281123161316
Batch 21/64 loss: 0.20428454875946045
Batch 22/64 loss: 0.20339453220367432
Batch 23/64 loss: 0.1968245506286621
Batch 24/64 loss: 0.19769632816314697
Batch 25/64 loss: 0.20392662286758423
Batch 26/64 loss: 0.2005521059036255
Batch 27/64 loss: 0.20286953449249268
Batch 28/64 loss: 0.1881113052368164
Batch 29/64 loss: 0.21069616079330444
Batch 30/64 loss: 0.20498907566070557
Batch 31/64 loss: 0.18950974941253662
Batch 32/64 loss: 0.20196354389190674
Batch 33/64 loss: 0.21579360961914062
Batch 34/64 loss: 0.20005828142166138
Batch 35/64 loss: 0.19209319353103638
Batch 36/64 loss: 0.19371426105499268
Batch 37/64 loss: 0.1976834535598755
Batch 38/64 loss: 0.20499730110168457
Batch 39/64 loss: 0.20110774040222168
Batch 40/64 loss: 0.2044752836227417
Batch 41/64 loss: 0.19984573125839233
Batch 42/64 loss: 0.2026439905166626
Batch 43/64 loss: 0.19094902276992798
Batch 44/64 loss: 0.1896960735321045
Batch 45/64 loss: 0.20135915279388428
Batch 46/64 loss: 0.20596843957901
Batch 47/64 loss: 0.20091044902801514
Batch 48/64 loss: 0.19329500198364258
Batch 49/64 loss: 0.1956377625465393
Batch 50/64 loss: 0.20347440242767334
Batch 51/64 loss: 0.21096956729888916
Batch 52/64 loss: 0.20832204818725586
Batch 53/64 loss: 0.19715559482574463
Batch 54/64 loss: 0.19426310062408447
Batch 55/64 loss: 0.20332050323486328
Batch 56/64 loss: 0.20074176788330078
Batch 57/64 loss: 0.20021235942840576
Batch 58/64 loss: 0.19443297386169434
Batch 59/64 loss: 0.1934528350830078
Batch 60/64 loss: 0.18825924396514893
Batch 61/64 loss: 0.1974562406539917
Batch 62/64 loss: 0.20114707946777344
Batch 63/64 loss: 0.1968698501586914
Batch 64/64 loss: 0.20160216093063354
Epoch 374  Train loss: 0.20037164711484723  Val loss: 0.2963844119887991
Epoch 375
-------------------------------
Batch 1/64 loss: 0.19432252645492554
Batch 2/64 loss: 0.2044980525970459
Batch 3/64 loss: 0.20033687353134155
Batch 4/64 loss: 0.20674312114715576
Batch 5/64 loss: 0.19154489040374756
Batch 6/64 loss: 0.2041337490081787
Batch 7/64 loss: 0.2055584192276001
Batch 8/64 loss: 0.1964116096496582
Batch 9/64 loss: 0.1930556297302246
Batch 10/64 loss: 0.1915397047996521
Batch 11/64 loss: 0.19945800304412842
Batch 12/64 loss: 0.20804363489151
Batch 13/64 loss: 0.21434080600738525
Batch 14/64 loss: 0.19613182544708252
Batch 15/64 loss: 0.21397030353546143
Batch 16/64 loss: 0.19544309377670288
Batch 17/64 loss: 0.19847488403320312
Batch 18/64 loss: 0.1853318214416504
Batch 19/64 loss: 0.2001304030418396
Batch 20/64 loss: 0.20710986852645874
Batch 21/64 loss: 0.20694875717163086
Batch 22/64 loss: 0.2168114185333252
Batch 23/64 loss: 0.19875550270080566
Batch 24/64 loss: 0.19754910469055176
Batch 25/64 loss: 0.20485782623291016
Batch 26/64 loss: 0.1939433217048645
Batch 27/64 loss: 0.2107049822807312
Batch 28/64 loss: 0.2215614914894104
Batch 29/64 loss: 0.1941928267478943
Batch 30/64 loss: 0.18880438804626465
Batch 31/64 loss: 0.20273256301879883
Batch 32/64 loss: 0.1950289011001587
Batch 33/64 loss: 0.20438265800476074
Batch 34/64 loss: 0.19626116752624512
Batch 35/64 loss: 0.1964970827102661
Batch 36/64 loss: 0.20610201358795166
Batch 37/64 loss: 0.192663311958313
Batch 38/64 loss: 0.19452500343322754
Batch 39/64 loss: 0.20424878597259521
Batch 40/64 loss: 0.1978926658630371
Batch 41/64 loss: 0.20263826847076416
Batch 42/64 loss: 0.20310163497924805
Batch 43/64 loss: 0.2012333869934082
Batch 44/64 loss: 0.18487966060638428
Batch 45/64 loss: 0.19297003746032715
Batch 46/64 loss: 0.20028185844421387
Batch 47/64 loss: 0.19537335634231567
Batch 48/64 loss: 0.1888895034790039
Batch 49/64 loss: 0.20336341857910156
Batch 50/64 loss: 0.2060708999633789
Batch 51/64 loss: 0.19127553701400757
Batch 52/64 loss: 0.20816302299499512
Batch 53/64 loss: 0.1991138458251953
Batch 54/64 loss: 0.21036303043365479
Batch 55/64 loss: 0.21126842498779297
Batch 56/64 loss: 0.19558078050613403
Batch 57/64 loss: 0.1982252597808838
Batch 58/64 loss: 0.19010835886001587
Batch 59/64 loss: 0.19822341203689575
Batch 60/64 loss: 0.1921093463897705
Batch 61/64 loss: 0.19756901264190674
Batch 62/64 loss: 0.20006310939788818
Batch 63/64 loss: 0.19576042890548706
Batch 64/64 loss: 0.20095157623291016
Epoch 375  Train loss: 0.19997462384841022  Val loss: 0.2969957186594042
Epoch 376
-------------------------------
Batch 1/64 loss: 0.19360607862472534
Batch 2/64 loss: 0.19170820713043213
Batch 3/64 loss: 0.18588662147521973
Batch 4/64 loss: 0.197698712348938
Batch 5/64 loss: 0.19630825519561768
Batch 6/64 loss: 0.195235013961792
Batch 7/64 loss: 0.196935772895813
Batch 8/64 loss: 0.20409905910491943
Batch 9/64 loss: 0.23121464252471924
Batch 10/64 loss: 0.18720650672912598
Batch 11/64 loss: 0.19761651754379272
Batch 12/64 loss: 0.1903597116470337
Batch 13/64 loss: 0.21076452732086182
Batch 14/64 loss: 0.20649105310440063
Batch 15/64 loss: 0.20923852920532227
Batch 16/64 loss: 0.20425188541412354
Batch 17/64 loss: 0.20238244533538818
Batch 18/64 loss: 0.20429158210754395
Batch 19/64 loss: 0.19816076755523682
Batch 20/64 loss: 0.19421589374542236
Batch 21/64 loss: 0.2072957158088684
Batch 22/64 loss: 0.19651544094085693
Batch 23/64 loss: 0.19781255722045898
Batch 24/64 loss: 0.20622432231903076
Batch 25/64 loss: 0.19368553161621094
Batch 26/64 loss: 0.1975318193435669
Batch 27/64 loss: 0.1982976198196411
Batch 28/64 loss: 0.19559001922607422
Batch 29/64 loss: 0.19107484817504883
Batch 30/64 loss: 0.19502508640289307
Batch 31/64 loss: 0.20911180973052979
Batch 32/64 loss: 0.20848608016967773
Batch 33/64 loss: 0.1995633840560913
Batch 34/64 loss: 0.19503039121627808
Batch 35/64 loss: 0.19993489980697632
Batch 36/64 loss: 0.2024146318435669
Batch 37/64 loss: 0.19458574056625366
Batch 38/64 loss: 0.19041317701339722
Batch 39/64 loss: 0.205649733543396
Batch 40/64 loss: 0.1974506378173828
Batch 41/64 loss: 0.20309126377105713
Batch 42/64 loss: 0.20043659210205078
Batch 43/64 loss: 0.20119285583496094
Batch 44/64 loss: 0.20192193984985352
Batch 45/64 loss: 0.19550782442092896
Batch 46/64 loss: 0.2015622854232788
Batch 47/64 loss: 0.19394969940185547
Batch 48/64 loss: 0.19626188278198242
Batch 49/64 loss: 0.1953033208847046
Batch 50/64 loss: 0.199232816696167
Batch 51/64 loss: 0.22077041864395142
Batch 52/64 loss: 0.1959528923034668
Batch 53/64 loss: 0.19792836904525757
Batch 54/64 loss: 0.20200717449188232
Batch 55/64 loss: 0.20126062631607056
Batch 56/64 loss: 0.20240062475204468
Batch 57/64 loss: 0.20047295093536377
Batch 58/64 loss: 0.2049722671508789
Batch 59/64 loss: 0.2073765993118286
Batch 60/64 loss: 0.19521915912628174
Batch 61/64 loss: 0.20615601539611816
Batch 62/64 loss: 0.20126891136169434
Batch 63/64 loss: 0.2175425887107849
Batch 64/64 loss: 0.2101615071296692
Epoch 376  Train loss: 0.2004513794300603  Val loss: 0.2963157232684368
Epoch 377
-------------------------------
Batch 1/64 loss: 0.20002424716949463
Batch 2/64 loss: 0.19826412200927734
Batch 3/64 loss: 0.20564627647399902
Batch 4/64 loss: 0.1966090202331543
Batch 5/64 loss: 0.19965195655822754
Batch 6/64 loss: 0.19069766998291016
Batch 7/64 loss: 0.19255584478378296
Batch 8/64 loss: 0.19878971576690674
Batch 9/64 loss: 0.20098876953125
Batch 10/64 loss: 0.20989274978637695
Batch 11/64 loss: 0.20426619052886963
Batch 12/64 loss: 0.20565271377563477
Batch 13/64 loss: 0.21627283096313477
Batch 14/64 loss: 0.2059694528579712
Batch 15/64 loss: 0.20595359802246094
Batch 16/64 loss: 0.20463156700134277
Batch 17/64 loss: 0.19616955518722534
Batch 18/64 loss: 0.20119595527648926
Batch 19/64 loss: 0.21529364585876465
Batch 20/64 loss: 0.19663399457931519
Batch 21/64 loss: 0.19561302661895752
Batch 22/64 loss: 0.22615987062454224
Batch 23/64 loss: 0.20464086532592773
Batch 24/64 loss: 0.20020967721939087
Batch 25/64 loss: 0.20542442798614502
Batch 26/64 loss: 0.20832526683807373
Batch 27/64 loss: 0.19655358791351318
Batch 28/64 loss: 0.20163345336914062
Batch 29/64 loss: 0.19917833805084229
Batch 30/64 loss: 0.20454013347625732
Batch 31/64 loss: 0.19096249341964722
Batch 32/64 loss: 0.20766568183898926
Batch 33/64 loss: 0.1953577995300293
Batch 34/64 loss: 0.19292569160461426
Batch 35/64 loss: 0.20166003704071045
Batch 36/64 loss: 0.19502413272857666
Batch 37/64 loss: 0.19236546754837036
Batch 38/64 loss: 0.1943017840385437
Batch 39/64 loss: 0.20322257280349731
Batch 40/64 loss: 0.19850265979766846
Batch 41/64 loss: 0.2020666003227234
Batch 42/64 loss: 0.20510733127593994
Batch 43/64 loss: 0.20125675201416016
Batch 44/64 loss: 0.20421987771987915
Batch 45/64 loss: 0.20664972066879272
Batch 46/64 loss: 0.1948864459991455
Batch 47/64 loss: 0.1981511116027832
Batch 48/64 loss: 0.2034839391708374
Batch 49/64 loss: 0.2019580602645874
Batch 50/64 loss: 0.19128692150115967
Batch 51/64 loss: 0.1989520788192749
Batch 52/64 loss: 0.19904261827468872
Batch 53/64 loss: 0.20263069868087769
Batch 54/64 loss: 0.1942359209060669
Batch 55/64 loss: 0.20009219646453857
Batch 56/64 loss: 0.19549775123596191
Batch 57/64 loss: 0.20471477508544922
Batch 58/64 loss: 0.19903254508972168
Batch 59/64 loss: 0.19958031177520752
Batch 60/64 loss: 0.20162808895111084
Batch 61/64 loss: 0.20688116550445557
Batch 62/64 loss: 0.20567339658737183
Batch 63/64 loss: 0.2094736099243164
Batch 64/64 loss: 0.19108080863952637
Epoch 377  Train loss: 0.20124297048531326  Val loss: 0.29640095627185
Epoch 378
-------------------------------
Batch 1/64 loss: 0.20888924598693848
Batch 2/64 loss: 0.19797229766845703
Batch 3/64 loss: 0.19888931512832642
Batch 4/64 loss: 0.20016896724700928
Batch 5/64 loss: 0.18756353855133057
Batch 6/64 loss: 0.19930756092071533
Batch 7/64 loss: 0.19936835765838623
Batch 8/64 loss: 0.1925426721572876
Batch 9/64 loss: 0.21443307399749756
Batch 10/64 loss: 0.19120651483535767
Batch 11/64 loss: 0.19819915294647217
Batch 12/64 loss: 0.20749300718307495
Batch 13/64 loss: 0.19121593236923218
Batch 14/64 loss: 0.1961161494255066
Batch 15/64 loss: 0.19438141584396362
Batch 16/64 loss: 0.19938665628433228
Batch 17/64 loss: 0.1939830780029297
Batch 18/64 loss: 0.21411263942718506
Batch 19/64 loss: 0.20113515853881836
Batch 20/64 loss: 0.20263314247131348
Batch 21/64 loss: 0.19419950246810913
Batch 22/64 loss: 0.20433425903320312
Batch 23/64 loss: 0.191817045211792
Batch 24/64 loss: 0.2026451826095581
Batch 25/64 loss: 0.2022722363471985
Batch 26/64 loss: 0.19856226444244385
Batch 27/64 loss: 0.2008967399597168
Batch 28/64 loss: 0.19755268096923828
Batch 29/64 loss: 0.19925880432128906
Batch 30/64 loss: 0.19858062267303467
Batch 31/64 loss: 0.198813796043396
Batch 32/64 loss: 0.19327199459075928
Batch 33/64 loss: 0.22069573402404785
Batch 34/64 loss: 0.2045665979385376
Batch 35/64 loss: 0.19582217931747437
Batch 36/64 loss: 0.21096980571746826
Batch 37/64 loss: 0.19986915588378906
Batch 38/64 loss: 0.20609748363494873
Batch 39/64 loss: 0.1952451467514038
Batch 40/64 loss: 0.19175148010253906
Batch 41/64 loss: 0.19633257389068604
Batch 42/64 loss: 0.21297204494476318
Batch 43/64 loss: 0.2067568302154541
Batch 44/64 loss: 0.1978682279586792
Batch 45/64 loss: 0.20047402381896973
Batch 46/64 loss: 0.2156909704208374
Batch 47/64 loss: 0.20685720443725586
Batch 48/64 loss: 0.20544499158859253
Batch 49/64 loss: 0.19317519664764404
Batch 50/64 loss: 0.2034745216369629
Batch 51/64 loss: 0.18667882680892944
Batch 52/64 loss: 0.19804632663726807
Batch 53/64 loss: 0.1928127408027649
Batch 54/64 loss: 0.19248181581497192
Batch 55/64 loss: 0.19426333904266357
Batch 56/64 loss: 0.18773198127746582
Batch 57/64 loss: 0.19843584299087524
Batch 58/64 loss: 0.20217186212539673
Batch 59/64 loss: 0.20093560218811035
Batch 60/64 loss: 0.1997530460357666
Batch 61/64 loss: 0.2013607621192932
Batch 62/64 loss: 0.21010392904281616
Batch 63/64 loss: 0.19739794731140137
Batch 64/64 loss: 0.20086169242858887
Epoch 378  Train loss: 0.19996999946295047  Val loss: 0.2968865546983542
Epoch 379
-------------------------------
Batch 1/64 loss: 0.18746566772460938
Batch 2/64 loss: 0.21342241764068604
Batch 3/64 loss: 0.19194555282592773
Batch 4/64 loss: 0.20104467868804932
Batch 5/64 loss: 0.18924200534820557
Batch 6/64 loss: 0.2028571367263794
Batch 7/64 loss: 0.19686013460159302
Batch 8/64 loss: 0.2051602602005005
Batch 9/64 loss: 0.19693201780319214
Batch 10/64 loss: 0.19653087854385376
Batch 11/64 loss: 0.20360338687896729
Batch 12/64 loss: 0.20327550172805786
Batch 13/64 loss: 0.18624961376190186
Batch 14/64 loss: 0.21516531705856323
Batch 15/64 loss: 0.20354855060577393
Batch 16/64 loss: 0.1953175663948059
Batch 17/64 loss: 0.20312613248825073
Batch 18/64 loss: 0.20538115501403809
Batch 19/64 loss: 0.19687527418136597
Batch 20/64 loss: 0.2028944492340088
Batch 21/64 loss: 0.21740150451660156
Batch 22/64 loss: 0.19813156127929688
Batch 23/64 loss: 0.19532263278961182
Batch 24/64 loss: 0.1961899995803833
Batch 25/64 loss: 0.19491708278656006
Batch 26/64 loss: 0.2031956911087036
Batch 27/64 loss: 0.1998308300971985
Batch 28/64 loss: 0.19407081604003906
Batch 29/64 loss: 0.19669699668884277
Batch 30/64 loss: 0.2029552459716797
Batch 31/64 loss: 0.19697880744934082
Batch 32/64 loss: 0.20251929759979248
Batch 33/64 loss: 0.1948794722557068
Batch 34/64 loss: 0.1971542239189148
Batch 35/64 loss: 0.200506329536438
Batch 36/64 loss: 0.2129054069519043
Batch 37/64 loss: 0.20070672035217285
Batch 38/64 loss: 0.20072221755981445
Batch 39/64 loss: 0.20492291450500488
Batch 40/64 loss: 0.1899811029434204
Batch 41/64 loss: 0.19252049922943115
Batch 42/64 loss: 0.19839322566986084
Batch 43/64 loss: 0.2062774896621704
Batch 44/64 loss: 0.20891857147216797
Batch 45/64 loss: 0.20706820487976074
Batch 46/64 loss: 0.2106865644454956
Batch 47/64 loss: 0.1940913200378418
Batch 48/64 loss: 0.18805813789367676
Batch 49/64 loss: 0.1976812481880188
Batch 50/64 loss: 0.20243358612060547
Batch 51/64 loss: 0.18896186351776123
Batch 52/64 loss: 0.20918899774551392
Batch 53/64 loss: 0.19172286987304688
Batch 54/64 loss: 0.21218633651733398
Batch 55/64 loss: 0.19837087392807007
Batch 56/64 loss: 0.18975043296813965
Batch 57/64 loss: 0.19699418544769287
Batch 58/64 loss: 0.2167431116104126
Batch 59/64 loss: 0.1992282271385193
Batch 60/64 loss: 0.18983960151672363
Batch 61/64 loss: 0.19527709484100342
Batch 62/64 loss: 0.20145106315612793
Batch 63/64 loss: 0.2100600004196167
Batch 64/64 loss: 0.19899582862854004
Epoch 379  Train loss: 0.2000319518294989  Val loss: 0.29645245345597415
Epoch 380
-------------------------------
Batch 1/64 loss: 0.20296889543533325
Batch 2/64 loss: 0.20013320446014404
Batch 3/64 loss: 0.20284783840179443
Batch 4/64 loss: 0.19665807485580444
Batch 5/64 loss: 0.18778878450393677
Batch 6/64 loss: 0.1965290904045105
Batch 7/64 loss: 0.19914579391479492
Batch 8/64 loss: 0.1843283772468567
Batch 9/64 loss: 0.20074862241744995
Batch 10/64 loss: 0.18668705224990845
Batch 11/64 loss: 0.21033835411071777
Batch 12/64 loss: 0.19013535976409912
Batch 13/64 loss: 0.19510185718536377
Batch 14/64 loss: 0.20143389701843262
Batch 15/64 loss: 0.20489948987960815
Batch 16/64 loss: 0.19504797458648682
Batch 17/64 loss: 0.20008623600006104
Batch 18/64 loss: 0.21061843633651733
Batch 19/64 loss: 0.19244569540023804
Batch 20/64 loss: 0.2026771903038025
Batch 21/64 loss: 0.1979750394821167
Batch 22/64 loss: 0.20010244846343994
Batch 23/64 loss: 0.1988464593887329
Batch 24/64 loss: 0.21644175052642822
Batch 25/64 loss: 0.20723581314086914
Batch 26/64 loss: 0.2066681981086731
Batch 27/64 loss: 0.19287604093551636
Batch 28/64 loss: 0.20639312267303467
Batch 29/64 loss: 0.19764870405197144
Batch 30/64 loss: 0.21848011016845703
Batch 31/64 loss: 0.2004392147064209
Batch 32/64 loss: 0.19556134939193726
Batch 33/64 loss: 0.19968056678771973
Batch 34/64 loss: 0.1932728886604309
Batch 35/64 loss: 0.19835615158081055
Batch 36/64 loss: 0.22091853618621826
Batch 37/64 loss: 0.19496148824691772
Batch 38/64 loss: 0.19327962398529053
Batch 39/64 loss: 0.19922566413879395
Batch 40/64 loss: 0.19380509853363037
Batch 41/64 loss: 0.1986086368560791
Batch 42/64 loss: 0.21848195791244507
Batch 43/64 loss: 0.20042645931243896
Batch 44/64 loss: 0.21348094940185547
Batch 45/64 loss: 0.20128166675567627
Batch 46/64 loss: 0.19862645864486694
Batch 47/64 loss: 0.1936323642730713
Batch 48/64 loss: 0.20254546403884888
Batch 49/64 loss: 0.19112801551818848
Batch 50/64 loss: 0.19915080070495605
Batch 51/64 loss: 0.19103491306304932
Batch 52/64 loss: 0.20066243410110474
Batch 53/64 loss: 0.20031464099884033
Batch 54/64 loss: 0.19188642501831055
Batch 55/64 loss: 0.20592951774597168
Batch 56/64 loss: 0.1972569227218628
Batch 57/64 loss: 0.19652193784713745
Batch 58/64 loss: 0.19845205545425415
Batch 59/64 loss: 0.1958363652229309
Batch 60/64 loss: 0.20856863260269165
Batch 61/64 loss: 0.1983497142791748
Batch 62/64 loss: 0.19766956567764282
Batch 63/64 loss: 0.19481444358825684
Batch 64/64 loss: 0.20913660526275635
Epoch 380  Train loss: 0.19991060845992145  Val loss: 0.2967591449567133
Epoch 381
-------------------------------
Batch 1/64 loss: 0.20310962200164795
Batch 2/64 loss: 0.19647914171218872
Batch 3/64 loss: 0.22256779670715332
Batch 4/64 loss: 0.1985827088356018
Batch 5/64 loss: 0.1852477788925171
Batch 6/64 loss: 0.2015542984008789
Batch 7/64 loss: 0.20420652627944946
Batch 8/64 loss: 0.20287156105041504
Batch 9/64 loss: 0.2029942274093628
Batch 10/64 loss: 0.19586974382400513
Batch 11/64 loss: 0.20785003900527954
Batch 12/64 loss: 0.19819509983062744
Batch 13/64 loss: 0.19706577062606812
Batch 14/64 loss: 0.20321112871170044
Batch 15/64 loss: 0.1952437162399292
Batch 16/64 loss: 0.20117521286010742
Batch 17/64 loss: 0.2024216651916504
Batch 18/64 loss: 0.20239442586898804
Batch 19/64 loss: 0.18875789642333984
Batch 20/64 loss: 0.1831262707710266
Batch 21/64 loss: 0.19502735137939453
Batch 22/64 loss: 0.20052659511566162
Batch 23/64 loss: 0.20135235786437988
Batch 24/64 loss: 0.19865620136260986
Batch 25/64 loss: 0.19861680269241333
Batch 26/64 loss: 0.19968074560165405
Batch 27/64 loss: 0.19306695461273193
Batch 28/64 loss: 0.20517569780349731
Batch 29/64 loss: 0.19189977645874023
Batch 30/64 loss: 0.20106685161590576
Batch 31/64 loss: 0.2005138397216797
Batch 32/64 loss: 0.19914430379867554
Batch 33/64 loss: 0.19842994213104248
Batch 34/64 loss: 0.19583821296691895
Batch 35/64 loss: 0.19211149215698242
Batch 36/64 loss: 0.19472569227218628
Batch 37/64 loss: 0.196915864944458
Batch 38/64 loss: 0.21226191520690918
Batch 39/64 loss: 0.19820618629455566
Batch 40/64 loss: 0.191558837890625
Batch 41/64 loss: 0.20692986249923706
Batch 42/64 loss: 0.19494402408599854
Batch 43/64 loss: 0.20723116397857666
Batch 44/64 loss: 0.20961987972259521
Batch 45/64 loss: 0.21217942237854004
Batch 46/64 loss: 0.20498067140579224
Batch 47/64 loss: 0.196516215801239
Batch 48/64 loss: 0.2039291262626648
Batch 49/64 loss: 0.19114834070205688
Batch 50/64 loss: 0.2062739133834839
Batch 51/64 loss: 0.19650161266326904
Batch 52/64 loss: 0.18952667713165283
Batch 53/64 loss: 0.1980499029159546
Batch 54/64 loss: 0.1978621482849121
Batch 55/64 loss: 0.20729470252990723
Batch 56/64 loss: 0.19983679056167603
Batch 57/64 loss: 0.20305776596069336
Batch 58/64 loss: 0.21850639581680298
Batch 59/64 loss: 0.19263964891433716
Batch 60/64 loss: 0.1910628080368042
Batch 61/64 loss: 0.20506614446640015
Batch 62/64 loss: 0.22343754768371582
Batch 63/64 loss: 0.20003312826156616
Batch 64/64 loss: 0.19813603162765503
Epoch 381  Train loss: 0.2002028261913973  Val loss: 0.29601939826486856
Epoch 382
-------------------------------
Batch 1/64 loss: 0.20327651500701904
Batch 2/64 loss: 0.18929988145828247
Batch 3/64 loss: 0.18911349773406982
Batch 4/64 loss: 0.20357215404510498
Batch 5/64 loss: 0.21861237287521362
Batch 6/64 loss: 0.20785897970199585
Batch 7/64 loss: 0.203446626663208
Batch 8/64 loss: 0.19576144218444824
Batch 9/64 loss: 0.19143086671829224
Batch 10/64 loss: 0.1931402087211609
Batch 11/64 loss: 0.20084738731384277
Batch 12/64 loss: 0.20816642045974731
Batch 13/64 loss: 0.19267714023590088
Batch 14/64 loss: 0.1921404004096985
Batch 15/64 loss: 0.20622092485427856
Batch 16/64 loss: 0.19410765171051025
Batch 17/64 loss: 0.20002543926239014
Batch 18/64 loss: 0.1925913691520691
Batch 19/64 loss: 0.20764529705047607
Batch 20/64 loss: 0.20313143730163574
Batch 21/64 loss: 0.20632755756378174
Batch 22/64 loss: 0.1981704831123352
Batch 23/64 loss: 0.1971961259841919
Batch 24/64 loss: 0.20645153522491455
Batch 25/64 loss: 0.2015829086303711
Batch 26/64 loss: 0.19788652658462524
Batch 27/64 loss: 0.21400922536849976
Batch 28/64 loss: 0.19766759872436523
Batch 29/64 loss: 0.2090069055557251
Batch 30/64 loss: 0.20611178874969482
Batch 31/64 loss: 0.1973673701286316
Batch 32/64 loss: 0.20653009414672852
Batch 33/64 loss: 0.19139188528060913
Batch 34/64 loss: 0.20015430450439453
Batch 35/64 loss: 0.22096699476242065
Batch 36/64 loss: 0.19417548179626465
Batch 37/64 loss: 0.19440746307373047
Batch 38/64 loss: 0.21011459827423096
Batch 39/64 loss: 0.19441407918930054
Batch 40/64 loss: 0.19410312175750732
Batch 41/64 loss: 0.19996172189712524
Batch 42/64 loss: 0.19894564151763916
Batch 43/64 loss: 0.20944100618362427
Batch 44/64 loss: 0.19995713233947754
Batch 45/64 loss: 0.198217511177063
Batch 46/64 loss: 0.19703280925750732
Batch 47/64 loss: 0.19717174768447876
Batch 48/64 loss: 0.20502161979675293
Batch 49/64 loss: 0.19509172439575195
Batch 50/64 loss: 0.20315945148468018
Batch 51/64 loss: 0.20318782329559326
Batch 52/64 loss: 0.20338445901870728
Batch 53/64 loss: 0.18890810012817383
Batch 54/64 loss: 0.19616657495498657
Batch 55/64 loss: 0.19808685779571533
Batch 56/64 loss: 0.19640016555786133
Batch 57/64 loss: 0.1983952522277832
Batch 58/64 loss: 0.1975674033164978
Batch 59/64 loss: 0.1904444694519043
Batch 60/64 loss: 0.199599027633667
Batch 61/64 loss: 0.19802099466323853
Batch 62/64 loss: 0.20879065990447998
Batch 63/64 loss: 0.20049142837524414
Batch 64/64 loss: 0.20975273847579956
Epoch 382  Train loss: 0.20034290505390542  Val loss: 0.29671534230209295
Epoch 383
-------------------------------
Batch 1/64 loss: 0.1897452473640442
Batch 2/64 loss: 0.20833611488342285
Batch 3/64 loss: 0.203993558883667
Batch 4/64 loss: 0.19695156812667847
Batch 5/64 loss: 0.18863481283187866
Batch 6/64 loss: 0.21367156505584717
Batch 7/64 loss: 0.1961500644683838
Batch 8/64 loss: 0.2079187035560608
Batch 9/64 loss: 0.20438086986541748
Batch 10/64 loss: 0.1911904215812683
Batch 11/64 loss: 0.19322192668914795
Batch 12/64 loss: 0.19967520236968994
Batch 13/64 loss: 0.20499247312545776
Batch 14/64 loss: 0.18951433897018433
Batch 15/64 loss: 0.2067607045173645
Batch 16/64 loss: 0.20518362522125244
Batch 17/64 loss: 0.20343267917633057
Batch 18/64 loss: 0.20347243547439575
Batch 19/64 loss: 0.1935226321220398
Batch 20/64 loss: 0.20436310768127441
Batch 21/64 loss: 0.20994532108306885
Batch 22/64 loss: 0.19511407613754272
Batch 23/64 loss: 0.20507550239562988
Batch 24/64 loss: 0.1976938247680664
Batch 25/64 loss: 0.20708858966827393
Batch 26/64 loss: 0.20141053199768066
Batch 27/64 loss: 0.20199215412139893
Batch 28/64 loss: 0.20008420944213867
Batch 29/64 loss: 0.19472897052764893
Batch 30/64 loss: 0.19551068544387817
Batch 31/64 loss: 0.19597047567367554
Batch 32/64 loss: 0.19008702039718628
Batch 33/64 loss: 0.1957385540008545
Batch 34/64 loss: 0.19989490509033203
Batch 35/64 loss: 0.2030550241470337
Batch 36/64 loss: 0.19319146871566772
Batch 37/64 loss: 0.20409196615219116
Batch 38/64 loss: 0.18378961086273193
Batch 39/64 loss: 0.20918649435043335
Batch 40/64 loss: 0.19714665412902832
Batch 41/64 loss: 0.19573974609375
Batch 42/64 loss: 0.20699620246887207
Batch 43/64 loss: 0.2060132622718811
Batch 44/64 loss: 0.19476836919784546
Batch 45/64 loss: 0.21214985847473145
Batch 46/64 loss: 0.19370269775390625
Batch 47/64 loss: 0.21434450149536133
Batch 48/64 loss: 0.20260155200958252
Batch 49/64 loss: 0.19765251874923706
Batch 50/64 loss: 0.20023608207702637
Batch 51/64 loss: 0.20224303007125854
Batch 52/64 loss: 0.202731192111969
Batch 53/64 loss: 0.19134920835494995
Batch 54/64 loss: 0.19085222482681274
Batch 55/64 loss: 0.19545340538024902
Batch 56/64 loss: 0.19934087991714478
Batch 57/64 loss: 0.19011300802230835
Batch 58/64 loss: 0.19530808925628662
Batch 59/64 loss: 0.20734703540802002
Batch 60/64 loss: 0.19117450714111328
Batch 61/64 loss: 0.19856595993041992
Batch 62/64 loss: 0.1978110671043396
Batch 63/64 loss: 0.19915390014648438
Batch 64/64 loss: 0.19916021823883057
Epoch 383  Train loss: 0.19954394592958338  Val loss: 0.2964881920732583
Epoch 384
-------------------------------
Batch 1/64 loss: 0.206914484500885
Batch 2/64 loss: 0.199060320854187
Batch 3/64 loss: 0.19440793991088867
Batch 4/64 loss: 0.1955922245979309
Batch 5/64 loss: 0.1891477108001709
Batch 6/64 loss: 0.2042783498764038
Batch 7/64 loss: 0.18663132190704346
Batch 8/64 loss: 0.19020229578018188
Batch 9/64 loss: 0.21056437492370605
Batch 10/64 loss: 0.21117210388183594
Batch 11/64 loss: 0.19885051250457764
Batch 12/64 loss: 0.19913828372955322
Batch 13/64 loss: 0.19806790351867676
Batch 14/64 loss: 0.20576447248458862
Batch 15/64 loss: 0.20096808671951294
Batch 16/64 loss: 0.19701331853866577
Batch 17/64 loss: 0.19534796476364136
Batch 18/64 loss: 0.18638890981674194
Batch 19/64 loss: 0.1907583475112915
Batch 20/64 loss: 0.19563889503479004
Batch 21/64 loss: 0.19797635078430176
Batch 22/64 loss: 0.19762146472930908
Batch 23/64 loss: 0.19462639093399048
Batch 24/64 loss: 0.20673918724060059
Batch 25/64 loss: 0.2001575231552124
Batch 26/64 loss: 0.2058699131011963
Batch 27/64 loss: 0.1921866536140442
Batch 28/64 loss: 0.20523768663406372
Batch 29/64 loss: 0.209600567817688
Batch 30/64 loss: 0.20265603065490723
Batch 31/64 loss: 0.18807172775268555
Batch 32/64 loss: 0.20630812644958496
Batch 33/64 loss: 0.1996714472770691
Batch 34/64 loss: 0.19685757160186768
Batch 35/64 loss: 0.19478291273117065
Batch 36/64 loss: 0.19931572675704956
Batch 37/64 loss: 0.19207465648651123
Batch 38/64 loss: 0.21280503273010254
Batch 39/64 loss: 0.18818271160125732
Batch 40/64 loss: 0.2070561647415161
Batch 41/64 loss: 0.21131324768066406
Batch 42/64 loss: 0.2006826400756836
Batch 43/64 loss: 0.20573967695236206
Batch 44/64 loss: 0.20198285579681396
Batch 45/64 loss: 0.20793628692626953
Batch 46/64 loss: 0.19151073694229126
Batch 47/64 loss: 0.20190227031707764
Batch 48/64 loss: 0.19729220867156982
Batch 49/64 loss: 0.1889556646347046
Batch 50/64 loss: 0.2087460160255432
Batch 51/64 loss: 0.2019639015197754
Batch 52/64 loss: 0.20334947109222412
Batch 53/64 loss: 0.19683289527893066
Batch 54/64 loss: 0.1920795440673828
Batch 55/64 loss: 0.19721710681915283
Batch 56/64 loss: 0.19929611682891846
Batch 57/64 loss: 0.2024550437927246
Batch 58/64 loss: 0.2032707929611206
Batch 59/64 loss: 0.20070487260818481
Batch 60/64 loss: 0.19689971208572388
Batch 61/64 loss: 0.2097567319869995
Batch 62/64 loss: 0.2101835012435913
Batch 63/64 loss: 0.21076029539108276
Batch 64/64 loss: 0.1951899528503418
Epoch 384  Train loss: 0.19985772114174039  Val loss: 0.29695232094767987
Epoch 385
-------------------------------
Batch 1/64 loss: 0.19717520475387573
Batch 2/64 loss: 0.18214267492294312
Batch 3/64 loss: 0.19223511219024658
Batch 4/64 loss: 0.19731569290161133
Batch 5/64 loss: 0.1975601315498352
Batch 6/64 loss: 0.19749540090560913
Batch 7/64 loss: 0.1897379755973816
Batch 8/64 loss: 0.19392460584640503
Batch 9/64 loss: 0.20027995109558105
Batch 10/64 loss: 0.19133883714675903
Batch 11/64 loss: 0.19918227195739746
Batch 12/64 loss: 0.19309097528457642
Batch 13/64 loss: 0.20371031761169434
Batch 14/64 loss: 0.1970531940460205
Batch 15/64 loss: 0.20885467529296875
Batch 16/64 loss: 0.19122320413589478
Batch 17/64 loss: 0.2052009105682373
Batch 18/64 loss: 0.19407719373703003
Batch 19/64 loss: 0.20490378141403198
Batch 20/64 loss: 0.2030925154685974
Batch 21/64 loss: 0.20182090997695923
Batch 22/64 loss: 0.19561755657196045
Batch 23/64 loss: 0.21049797534942627
Batch 24/64 loss: 0.206268310546875
Batch 25/64 loss: 0.2106698751449585
Batch 26/64 loss: 0.20565247535705566
Batch 27/64 loss: 0.19509482383728027
Batch 28/64 loss: 0.1962069272994995
Batch 29/64 loss: 0.19789433479309082
Batch 30/64 loss: 0.2022395133972168
Batch 31/64 loss: 0.19962149858474731
Batch 32/64 loss: 0.18727701902389526
Batch 33/64 loss: 0.2067573070526123
Batch 34/64 loss: 0.1970827579498291
Batch 35/64 loss: 0.20119696855545044
Batch 36/64 loss: 0.20503592491149902
Batch 37/64 loss: 0.2069706916809082
Batch 38/64 loss: 0.19655746221542358
Batch 39/64 loss: 0.21125680208206177
Batch 40/64 loss: 0.1952536702156067
Batch 41/64 loss: 0.1854296326637268
Batch 42/64 loss: 0.20634126663208008
Batch 43/64 loss: 0.20144033432006836
Batch 44/64 loss: 0.2217090129852295
Batch 45/64 loss: 0.20358234643936157
Batch 46/64 loss: 0.19608759880065918
Batch 47/64 loss: 0.19400560855865479
Batch 48/64 loss: 0.20930767059326172
Batch 49/64 loss: 0.19375741481781006
Batch 50/64 loss: 0.1932237148284912
Batch 51/64 loss: 0.20645201206207275
Batch 52/64 loss: 0.1979597806930542
Batch 53/64 loss: 0.19659870862960815
Batch 54/64 loss: 0.20379436016082764
Batch 55/64 loss: 0.19878625869750977
Batch 56/64 loss: 0.2068711519241333
Batch 57/64 loss: 0.204328715801239
Batch 58/64 loss: 0.19798725843429565
Batch 59/64 loss: 0.19478684663772583
Batch 60/64 loss: 0.20331501960754395
Batch 61/64 loss: 0.198073148727417
Batch 62/64 loss: 0.1963416337966919
Batch 63/64 loss: 0.20636463165283203
Batch 64/64 loss: 0.19635051488876343
Epoch 385  Train loss: 0.19972352069966934  Val loss: 0.29782452923325736
Epoch 386
-------------------------------
Batch 1/64 loss: 0.21069669723510742
Batch 2/64 loss: 0.1865752935409546
Batch 3/64 loss: 0.2072049379348755
Batch 4/64 loss: 0.2014385461807251
Batch 5/64 loss: 0.195745050907135
Batch 6/64 loss: 0.20461583137512207
Batch 7/64 loss: 0.19903850555419922
Batch 8/64 loss: 0.19243460893630981
Batch 9/64 loss: 0.19864320755004883
Batch 10/64 loss: 0.2005857229232788
Batch 11/64 loss: 0.19553887844085693
Batch 12/64 loss: 0.19090807437896729
Batch 13/64 loss: 0.19650185108184814
Batch 14/64 loss: 0.19128119945526123
Batch 15/64 loss: 0.20110708475112915
Batch 16/64 loss: 0.20066601037979126
Batch 17/64 loss: 0.21736949682235718
Batch 18/64 loss: 0.20004570484161377
Batch 19/64 loss: 0.21150779724121094
Batch 20/64 loss: 0.1946895718574524
Batch 21/64 loss: 0.1986398696899414
Batch 22/64 loss: 0.20923113822937012
Batch 23/64 loss: 0.20139861106872559
Batch 24/64 loss: 0.18517035245895386
Batch 25/64 loss: 0.18699151277542114
Batch 26/64 loss: 0.20055580139160156
Batch 27/64 loss: 0.19587916135787964
Batch 28/64 loss: 0.20946025848388672
Batch 29/64 loss: 0.19370579719543457
Batch 30/64 loss: 0.20069831609725952
Batch 31/64 loss: 0.19750267267227173
Batch 32/64 loss: 0.204684317111969
Batch 33/64 loss: 0.19265568256378174
Batch 34/64 loss: 0.20914697647094727
Batch 35/64 loss: 0.2086646556854248
Batch 36/64 loss: 0.19379162788391113
Batch 37/64 loss: 0.20181506872177124
Batch 38/64 loss: 0.1969340443611145
Batch 39/64 loss: 0.20359569787979126
Batch 40/64 loss: 0.19259238243103027
Batch 41/64 loss: 0.19203948974609375
Batch 42/64 loss: 0.2001287341117859
Batch 43/64 loss: 0.21001720428466797
Batch 44/64 loss: 0.19969546794891357
Batch 45/64 loss: 0.20842117071151733
Batch 46/64 loss: 0.19737482070922852
Batch 47/64 loss: 0.19860130548477173
Batch 48/64 loss: 0.19008439779281616
Batch 49/64 loss: 0.19174695014953613
Batch 50/64 loss: 0.2015400528907776
Batch 51/64 loss: 0.19271445274353027
Batch 52/64 loss: 0.20611393451690674
Batch 53/64 loss: 0.1928027868270874
Batch 54/64 loss: 0.2041553258895874
Batch 55/64 loss: 0.19459247589111328
Batch 56/64 loss: 0.19060498476028442
Batch 57/64 loss: 0.20906496047973633
Batch 58/64 loss: 0.19345903396606445
Batch 59/64 loss: 0.19707179069519043
Batch 60/64 loss: 0.19936680793762207
Batch 61/64 loss: 0.19646823406219482
Batch 62/64 loss: 0.20022708177566528
Batch 63/64 loss: 0.20745301246643066
Batch 64/64 loss: 0.2058185338973999
Epoch 386  Train loss: 0.1993382963479734  Val loss: 0.2967560332255675
Epoch 387
-------------------------------
Batch 1/64 loss: 0.19672644138336182
Batch 2/64 loss: 0.20086658000946045
Batch 3/64 loss: 0.20046621561050415
Batch 4/64 loss: 0.1895548701286316
Batch 5/64 loss: 0.19471651315689087
Batch 6/64 loss: 0.19393086433410645
Batch 7/64 loss: 0.2023555040359497
Batch 8/64 loss: 0.19143778085708618
Batch 9/64 loss: 0.197687566280365
Batch 10/64 loss: 0.2045280933380127
Batch 11/64 loss: 0.19121432304382324
Batch 12/64 loss: 0.20554232597351074
Batch 13/64 loss: 0.19188207387924194
Batch 14/64 loss: 0.19575989246368408
Batch 15/64 loss: 0.1876758337020874
Batch 16/64 loss: 0.19259101152420044
Batch 17/64 loss: 0.20288193225860596
Batch 18/64 loss: 0.18931788206100464
Batch 19/64 loss: 0.20059925317764282
Batch 20/64 loss: 0.18975871801376343
Batch 21/64 loss: 0.19441628456115723
Batch 22/64 loss: 0.1921679973602295
Batch 23/64 loss: 0.1884213089942932
Batch 24/64 loss: 0.21015620231628418
Batch 25/64 loss: 0.19998174905776978
Batch 26/64 loss: 0.19634056091308594
Batch 27/64 loss: 0.1912856101989746
Batch 28/64 loss: 0.2060779333114624
Batch 29/64 loss: 0.19405871629714966
Batch 30/64 loss: 0.2007054090499878
Batch 31/64 loss: 0.21836674213409424
Batch 32/64 loss: 0.19719594717025757
Batch 33/64 loss: 0.20408308506011963
Batch 34/64 loss: 0.20403170585632324
Batch 35/64 loss: 0.19687634706497192
Batch 36/64 loss: 0.20358818769454956
Batch 37/64 loss: 0.19668805599212646
Batch 38/64 loss: 0.19062060117721558
Batch 39/64 loss: 0.19967728853225708
Batch 40/64 loss: 0.19678479433059692
Batch 41/64 loss: 0.20288193225860596
Batch 42/64 loss: 0.20166665315628052
Batch 43/64 loss: 0.20953714847564697
Batch 44/64 loss: 0.19072747230529785
Batch 45/64 loss: 0.19177812337875366
Batch 46/64 loss: 0.21391475200653076
Batch 47/64 loss: 0.20435261726379395
Batch 48/64 loss: 0.20251929759979248
Batch 49/64 loss: 0.19601434469223022
Batch 50/64 loss: 0.19348084926605225
Batch 51/64 loss: 0.20598864555358887
Batch 52/64 loss: 0.19501137733459473
Batch 53/64 loss: 0.20799517631530762
Batch 54/64 loss: 0.20085227489471436
Batch 55/64 loss: 0.1942455768585205
Batch 56/64 loss: 0.1920609474182129
Batch 57/64 loss: 0.1978941559791565
Batch 58/64 loss: 0.19854062795639038
Batch 59/64 loss: 0.19346016645431519
Batch 60/64 loss: 0.18902349472045898
Batch 61/64 loss: 0.20240724086761475
Batch 62/64 loss: 0.21499717235565186
Batch 63/64 loss: 0.18641740083694458
Batch 64/64 loss: 0.19762682914733887
Epoch 387  Train loss: 0.19819616897433412  Val loss: 0.2975826808267443
Epoch 388
-------------------------------
Batch 1/64 loss: 0.20693659782409668
Batch 2/64 loss: 0.2059781551361084
Batch 3/64 loss: 0.18878436088562012
Batch 4/64 loss: 0.19775593280792236
Batch 5/64 loss: 0.20281171798706055
Batch 6/64 loss: 0.19093936681747437
Batch 7/64 loss: 0.1916409730911255
Batch 8/64 loss: 0.1911565065383911
Batch 9/64 loss: 0.19273757934570312
Batch 10/64 loss: 0.19063204526901245
Batch 11/64 loss: 0.19728541374206543
Batch 12/64 loss: 0.19917231798171997
Batch 13/64 loss: 0.188490629196167
Batch 14/64 loss: 0.20165705680847168
Batch 15/64 loss: 0.19008684158325195
Batch 16/64 loss: 0.20290887355804443
Batch 17/64 loss: 0.19786477088928223
Batch 18/64 loss: 0.2033597230911255
Batch 19/64 loss: 0.20000040531158447
Batch 20/64 loss: 0.20147734880447388
Batch 21/64 loss: 0.20495402812957764
Batch 22/64 loss: 0.202894926071167
Batch 23/64 loss: 0.20318305492401123
Batch 24/64 loss: 0.195792555809021
Batch 25/64 loss: 0.18317770957946777
Batch 26/64 loss: 0.20712703466415405
Batch 27/64 loss: 0.193717360496521
Batch 28/64 loss: 0.19453060626983643
Batch 29/64 loss: 0.19674628973007202
Batch 30/64 loss: 0.19625145196914673
Batch 31/64 loss: 0.19930493831634521
Batch 32/64 loss: 0.20121824741363525
Batch 33/64 loss: 0.19705164432525635
Batch 34/64 loss: 0.20383262634277344
Batch 35/64 loss: 0.20847278833389282
Batch 36/64 loss: 0.21458357572555542
Batch 37/64 loss: 0.20482420921325684
Batch 38/64 loss: 0.1946934461593628
Batch 39/64 loss: 0.19715625047683716
Batch 40/64 loss: 0.20836234092712402
Batch 41/64 loss: 0.1958722472190857
Batch 42/64 loss: 0.20902955532073975
Batch 43/64 loss: 0.19583457708358765
Batch 44/64 loss: 0.21933770179748535
Batch 45/64 loss: 0.20675551891326904
Batch 46/64 loss: 0.19658523797988892
Batch 47/64 loss: 0.1900315284729004
Batch 48/64 loss: 0.21564161777496338
Batch 49/64 loss: 0.20000982284545898
Batch 50/64 loss: 0.1955019235610962
Batch 51/64 loss: 0.20227718353271484
Batch 52/64 loss: 0.19243550300598145
Batch 53/64 loss: 0.18682682514190674
Batch 54/64 loss: 0.19270610809326172
Batch 55/64 loss: 0.20273542404174805
Batch 56/64 loss: 0.19978588819503784
Batch 57/64 loss: 0.18816733360290527
Batch 58/64 loss: 0.20657312870025635
Batch 59/64 loss: 0.2080904245376587
Batch 60/64 loss: 0.18961572647094727
Batch 61/64 loss: 0.1929120421409607
Batch 62/64 loss: 0.20145416259765625
Batch 63/64 loss: 0.19809812307357788
Batch 64/64 loss: 0.20165616273880005
Epoch 388  Train loss: 0.19901288514043772  Val loss: 0.29676583419550734
Epoch 389
-------------------------------
Batch 1/64 loss: 0.21296250820159912
Batch 2/64 loss: 0.2045009732246399
Batch 3/64 loss: 0.1923472285270691
Batch 4/64 loss: 0.18388259410858154
Batch 5/64 loss: 0.19159603118896484
Batch 6/64 loss: 0.19473516941070557
Batch 7/64 loss: 0.20050650835037231
Batch 8/64 loss: 0.18837463855743408
Batch 9/64 loss: 0.19451206922531128
Batch 10/64 loss: 0.20478582382202148
Batch 11/64 loss: 0.20428955554962158
Batch 12/64 loss: 0.1947718858718872
Batch 13/64 loss: 0.1999284029006958
Batch 14/64 loss: 0.19140899181365967
Batch 15/64 loss: 0.19370025396347046
Batch 16/64 loss: 0.19288420677185059
Batch 17/64 loss: 0.20645397901535034
Batch 18/64 loss: 0.19591718912124634
Batch 19/64 loss: 0.1897968053817749
Batch 20/64 loss: 0.19771456718444824
Batch 21/64 loss: 0.1940298080444336
Batch 22/64 loss: 0.19625693559646606
Batch 23/64 loss: 0.20090466737747192
Batch 24/64 loss: 0.20092356204986572
Batch 25/64 loss: 0.20848095417022705
Batch 26/64 loss: 0.1941627860069275
Batch 27/64 loss: 0.1987813115119934
Batch 28/64 loss: 0.19681316614151
Batch 29/64 loss: 0.19670945405960083
Batch 30/64 loss: 0.19774872064590454
Batch 31/64 loss: 0.19046616554260254
Batch 32/64 loss: 0.19830989837646484
Batch 33/64 loss: 0.1839708685874939
Batch 34/64 loss: 0.19630712270736694
Batch 35/64 loss: 0.19472390413284302
Batch 36/64 loss: 0.1973247528076172
Batch 37/64 loss: 0.1908642053604126
Batch 38/64 loss: 0.19847190380096436
Batch 39/64 loss: 0.1941726803779602
Batch 40/64 loss: 0.19945865869522095
Batch 41/64 loss: 0.21000921726226807
Batch 42/64 loss: 0.2021036148071289
Batch 43/64 loss: 0.20274150371551514
Batch 44/64 loss: 0.19582903385162354
Batch 45/64 loss: 0.2096903920173645
Batch 46/64 loss: 0.20115792751312256
Batch 47/64 loss: 0.20457518100738525
Batch 48/64 loss: 0.20046454668045044
Batch 49/64 loss: 0.1965315341949463
Batch 50/64 loss: 0.19633179903030396
Batch 51/64 loss: 0.20192009210586548
Batch 52/64 loss: 0.197576105594635
Batch 53/64 loss: 0.19842565059661865
Batch 54/64 loss: 0.18825215101242065
Batch 55/64 loss: 0.20759737491607666
Batch 56/64 loss: 0.20352232456207275
Batch 57/64 loss: 0.18846583366394043
Batch 58/64 loss: 0.19783079624176025
Batch 59/64 loss: 0.20249617099761963
Batch 60/64 loss: 0.19368493556976318
Batch 61/64 loss: 0.2100212574005127
Batch 62/64 loss: 0.2072528600692749
Batch 63/64 loss: 0.19916462898254395
Batch 64/64 loss: 0.20247375965118408
Epoch 389  Train loss: 0.19814041034848082  Val loss: 0.2973718805001773
Epoch 390
-------------------------------
Batch 1/64 loss: 0.18655312061309814
Batch 2/64 loss: 0.20202183723449707
Batch 3/64 loss: 0.20631301403045654
Batch 4/64 loss: 0.19045108556747437
Batch 5/64 loss: 0.20768696069717407
Batch 6/64 loss: 0.20207321643829346
Batch 7/64 loss: 0.19785922765731812
Batch 8/64 loss: 0.18339568376541138
Batch 9/64 loss: 0.1944788694381714
Batch 10/64 loss: 0.19770342111587524
Batch 11/64 loss: 0.20122778415679932
Batch 12/64 loss: 0.19788908958435059
Batch 13/64 loss: 0.18976426124572754
Batch 14/64 loss: 0.20493853092193604
Batch 15/64 loss: 0.20185184478759766
Batch 16/64 loss: 0.2046741247177124
Batch 17/64 loss: 0.19472408294677734
Batch 18/64 loss: 0.18424654006958008
Batch 19/64 loss: 0.19916415214538574
Batch 20/64 loss: 0.19265830516815186
Batch 21/64 loss: 0.20308220386505127
Batch 22/64 loss: 0.19171679019927979
Batch 23/64 loss: 0.19284319877624512
Batch 24/64 loss: 0.2066096067428589
Batch 25/64 loss: 0.1844385266304016
Batch 26/64 loss: 0.1890573501586914
Batch 27/64 loss: 0.20842742919921875
Batch 28/64 loss: 0.19128108024597168
Batch 29/64 loss: 0.19797325134277344
Batch 30/64 loss: 0.21863198280334473
Batch 31/64 loss: 0.18867874145507812
Batch 32/64 loss: 0.2027178406715393
Batch 33/64 loss: 0.20408421754837036
Batch 34/64 loss: 0.19597762823104858
Batch 35/64 loss: 0.20685535669326782
Batch 36/64 loss: 0.1961730718612671
Batch 37/64 loss: 0.2035321593284607
Batch 38/64 loss: 0.19681406021118164
Batch 39/64 loss: 0.22667717933654785
Batch 40/64 loss: 0.20850741863250732
Batch 41/64 loss: 0.18752789497375488
Batch 42/64 loss: 0.21122705936431885
Batch 43/64 loss: 0.18978160619735718
Batch 44/64 loss: 0.21368038654327393
Batch 45/64 loss: 0.18595540523529053
Batch 46/64 loss: 0.2100536823272705
Batch 47/64 loss: 0.20003855228424072
Batch 48/64 loss: 0.20728695392608643
Batch 49/64 loss: 0.2019805908203125
Batch 50/64 loss: 0.2046600580215454
Batch 51/64 loss: 0.2127661108970642
Batch 52/64 loss: 0.20661336183547974
Batch 53/64 loss: 0.19505250453948975
Batch 54/64 loss: 0.19323843717575073
Batch 55/64 loss: 0.2021092176437378
Batch 56/64 loss: 0.21146225929260254
Batch 57/64 loss: 0.19306379556655884
Batch 58/64 loss: 0.20042634010314941
Batch 59/64 loss: 0.18805009126663208
Batch 60/64 loss: 0.19647639989852905
Batch 61/64 loss: 0.20709234476089478
Batch 62/64 loss: 0.21177971363067627
Batch 63/64 loss: 0.20631122589111328
Batch 64/64 loss: 0.19139885902404785
Epoch 390  Train loss: 0.19974803737565583  Val loss: 0.2974749205448374
Epoch 391
-------------------------------
Batch 1/64 loss: 0.19595646858215332
Batch 2/64 loss: 0.2005823850631714
Batch 3/64 loss: 0.19814175367355347
Batch 4/64 loss: 0.2030695080757141
Batch 5/64 loss: 0.19067740440368652
Batch 6/64 loss: 0.1959819793701172
Batch 7/64 loss: 0.20104968547821045
Batch 8/64 loss: 0.1965314745903015
Batch 9/64 loss: 0.2043619155883789
Batch 10/64 loss: 0.2089671492576599
Batch 11/64 loss: 0.1951993703842163
Batch 12/64 loss: 0.1973050832748413
Batch 13/64 loss: 0.2094976305961609
Batch 14/64 loss: 0.21138310432434082
Batch 15/64 loss: 0.18958264589309692
Batch 16/64 loss: 0.19391155242919922
Batch 17/64 loss: 0.19403958320617676
Batch 18/64 loss: 0.20558124780654907
Batch 19/64 loss: 0.18953192234039307
Batch 20/64 loss: 0.1990259885787964
Batch 21/64 loss: 0.21780681610107422
Batch 22/64 loss: 0.21284937858581543
Batch 23/64 loss: 0.20065093040466309
Batch 24/64 loss: 0.19262194633483887
Batch 25/64 loss: 0.1869581937789917
Batch 26/64 loss: 0.1974714994430542
Batch 27/64 loss: 0.1985325813293457
Batch 28/64 loss: 0.20605456829071045
Batch 29/64 loss: 0.2063126564025879
Batch 30/64 loss: 0.20822185277938843
Batch 31/64 loss: 0.1957278847694397
Batch 32/64 loss: 0.2015836238861084
Batch 33/64 loss: 0.20030522346496582
Batch 34/64 loss: 0.19671297073364258
Batch 35/64 loss: 0.20886456966400146
Batch 36/64 loss: 0.1940574049949646
Batch 37/64 loss: 0.2019972801208496
Batch 38/64 loss: 0.1859225034713745
Batch 39/64 loss: 0.20937275886535645
Batch 40/64 loss: 0.18843555450439453
Batch 41/64 loss: 0.19115954637527466
Batch 42/64 loss: 0.1959552764892578
Batch 43/64 loss: 0.20409029722213745
Batch 44/64 loss: 0.19212985038757324
Batch 45/64 loss: 0.19355762004852295
Batch 46/64 loss: 0.21053344011306763
Batch 47/64 loss: 0.19401603937149048
Batch 48/64 loss: 0.19881093502044678
Batch 49/64 loss: 0.1979961395263672
Batch 50/64 loss: 0.19748783111572266
Batch 51/64 loss: 0.20044243335723877
Batch 52/64 loss: 0.18998795747756958
Batch 53/64 loss: 0.201865553855896
Batch 54/64 loss: 0.19854342937469482
Batch 55/64 loss: 0.20394152402877808
Batch 56/64 loss: 0.1948794722557068
Batch 57/64 loss: 0.21195650100708008
Batch 58/64 loss: 0.20035284757614136
Batch 59/64 loss: 0.2001827359199524
Batch 60/64 loss: 0.200933575630188
Batch 61/64 loss: 0.1889525055885315
Batch 62/64 loss: 0.1909465193748474
Batch 63/64 loss: 0.20003235340118408
Batch 64/64 loss: 0.19426560401916504
Epoch 391  Train loss: 0.1991418296215581  Val loss: 0.29712682409384816
Epoch 392
-------------------------------
Batch 1/64 loss: 0.1995171308517456
Batch 2/64 loss: 0.20465439558029175
Batch 3/64 loss: 0.19694137573242188
Batch 4/64 loss: 0.19572806358337402
Batch 5/64 loss: 0.19427871704101562
Batch 6/64 loss: 0.20002961158752441
Batch 7/64 loss: 0.19828510284423828
Batch 8/64 loss: 0.18904197216033936
Batch 9/64 loss: 0.18661147356033325
Batch 10/64 loss: 0.19297796487808228
Batch 11/64 loss: 0.19189238548278809
Batch 12/64 loss: 0.19654500484466553
Batch 13/64 loss: 0.19866943359375
Batch 14/64 loss: 0.19873976707458496
Batch 15/64 loss: 0.20621216297149658
Batch 16/64 loss: 0.18978416919708252
Batch 17/64 loss: 0.1999223232269287
Batch 18/64 loss: 0.19952982664108276
Batch 19/64 loss: 0.19843673706054688
Batch 20/64 loss: 0.19125044345855713
Batch 21/64 loss: 0.19189107418060303
Batch 22/64 loss: 0.20497393608093262
Batch 23/64 loss: 0.19400912523269653
Batch 24/64 loss: 0.18921619653701782
Batch 25/64 loss: 0.18323874473571777
Batch 26/64 loss: 0.19781428575515747
Batch 27/64 loss: 0.19675111770629883
Batch 28/64 loss: 0.1989816427230835
Batch 29/64 loss: 0.20416712760925293
Batch 30/64 loss: 0.20379209518432617
Batch 31/64 loss: 0.18709367513656616
Batch 32/64 loss: 0.19577574729919434
Batch 33/64 loss: 0.19666272401809692
Batch 34/64 loss: 0.1971169114112854
Batch 35/64 loss: 0.19448322057724
Batch 36/64 loss: 0.19443655014038086
Batch 37/64 loss: 0.1996915340423584
Batch 38/64 loss: 0.19665318727493286
Batch 39/64 loss: 0.2053380012512207
Batch 40/64 loss: 0.1928044557571411
Batch 41/64 loss: 0.2102891206741333
Batch 42/64 loss: 0.19568711519241333
Batch 43/64 loss: 0.20257419347763062
Batch 44/64 loss: 0.21042704582214355
Batch 45/64 loss: 0.1966099739074707
Batch 46/64 loss: 0.20192694664001465
Batch 47/64 loss: 0.19446253776550293
Batch 48/64 loss: 0.19411665201187134
Batch 49/64 loss: 0.18896156549453735
Batch 50/64 loss: 0.20298981666564941
Batch 51/64 loss: 0.19566774368286133
Batch 52/64 loss: 0.1932019591331482
Batch 53/64 loss: 0.20393729209899902
Batch 54/64 loss: 0.19707375764846802
Batch 55/64 loss: 0.1994991898536682
Batch 56/64 loss: 0.18784570693969727
Batch 57/64 loss: 0.205810546875
Batch 58/64 loss: 0.22580718994140625
Batch 59/64 loss: 0.20209765434265137
Batch 60/64 loss: 0.20634734630584717
Batch 61/64 loss: 0.19994127750396729
Batch 62/64 loss: 0.1963052749633789
Batch 63/64 loss: 0.20455831289291382
Batch 64/64 loss: 0.18977832794189453
Epoch 392  Train loss: 0.19784174713433958  Val loss: 0.29672580732103065
Epoch 393
-------------------------------
Batch 1/64 loss: 0.1979900598526001
Batch 2/64 loss: 0.19638442993164062
Batch 3/64 loss: 0.21661889553070068
Batch 4/64 loss: 0.196702241897583
Batch 5/64 loss: 0.20706945657730103
Batch 6/64 loss: 0.19265496730804443
Batch 7/64 loss: 0.2012133002281189
Batch 8/64 loss: 0.20014870166778564
Batch 9/64 loss: 0.20043718814849854
Batch 10/64 loss: 0.19062376022338867
Batch 11/64 loss: 0.19703471660614014
Batch 12/64 loss: 0.19546467065811157
Batch 13/64 loss: 0.2001362442970276
Batch 14/64 loss: 0.19755911827087402
Batch 15/64 loss: 0.1983729600906372
Batch 16/64 loss: 0.1889411211013794
Batch 17/64 loss: 0.200883150100708
Batch 18/64 loss: 0.19045203924179077
Batch 19/64 loss: 0.20655924081802368
Batch 20/64 loss: 0.1971774697303772
Batch 21/64 loss: 0.2099243402481079
Batch 22/64 loss: 0.19296222925186157
Batch 23/64 loss: 0.2055259346961975
Batch 24/64 loss: 0.18113499879837036
Batch 25/64 loss: 0.1922256350517273
Batch 26/64 loss: 0.19269394874572754
Batch 27/64 loss: 0.20256340503692627
Batch 28/64 loss: 0.20006513595581055
Batch 29/64 loss: 0.19118893146514893
Batch 30/64 loss: 0.2032567858695984
Batch 31/64 loss: 0.19439047574996948
Batch 32/64 loss: 0.18313223123550415
Batch 33/64 loss: 0.193933367729187
Batch 34/64 loss: 0.19206488132476807
Batch 35/64 loss: 0.19180870056152344
Batch 36/64 loss: 0.21971440315246582
Batch 37/64 loss: 0.2002297043800354
Batch 38/64 loss: 0.187036395072937
Batch 39/64 loss: 0.1892954707145691
Batch 40/64 loss: 0.2020338773727417
Batch 41/64 loss: 0.19828766584396362
Batch 42/64 loss: 0.2001509666442871
Batch 43/64 loss: 0.20540165901184082
Batch 44/64 loss: 0.19793033599853516
Batch 45/64 loss: 0.19941115379333496
Batch 46/64 loss: 0.20957469940185547
Batch 47/64 loss: 0.19359225034713745
Batch 48/64 loss: 0.2048358917236328
Batch 49/64 loss: 0.19454121589660645
Batch 50/64 loss: 0.20022320747375488
Batch 51/64 loss: 0.2022843360900879
Batch 52/64 loss: 0.1989002823829651
Batch 53/64 loss: 0.1913210153579712
Batch 54/64 loss: 0.20395183563232422
Batch 55/64 loss: 0.20605337619781494
Batch 56/64 loss: 0.18725943565368652
Batch 57/64 loss: 0.20378339290618896
Batch 58/64 loss: 0.200688898563385
Batch 59/64 loss: 0.19951367378234863
Batch 60/64 loss: 0.1939682960510254
Batch 61/64 loss: 0.19600909948349
Batch 62/64 loss: 0.18565237522125244
Batch 63/64 loss: 0.19257885217666626
Batch 64/64 loss: 0.20265734195709229
Epoch 393  Train loss: 0.19789037657719033  Val loss: 0.29793662037636404
Epoch 394
-------------------------------
Batch 1/64 loss: 0.18627333641052246
Batch 2/64 loss: 0.22331953048706055
Batch 3/64 loss: 0.1979522705078125
Batch 4/64 loss: 0.20028918981552124
Batch 5/64 loss: 0.19338130950927734
Batch 6/64 loss: 0.1930578351020813
Batch 7/64 loss: 0.198034405708313
Batch 8/64 loss: 0.19231903553009033
Batch 9/64 loss: 0.19729048013687134
Batch 10/64 loss: 0.2107418179512024
Batch 11/64 loss: 0.21451354026794434
Batch 12/64 loss: 0.2032337188720703
Batch 13/64 loss: 0.1994098424911499
Batch 14/64 loss: 0.19604402780532837
Batch 15/64 loss: 0.18824046850204468
Batch 16/64 loss: 0.2109861969947815
Batch 17/64 loss: 0.19890516996383667
Batch 18/64 loss: 0.19366496801376343
Batch 19/64 loss: 0.18719810247421265
Batch 20/64 loss: 0.18852055072784424
Batch 21/64 loss: 0.19901591539382935
Batch 22/64 loss: 0.20423901081085205
Batch 23/64 loss: 0.19955050945281982
Batch 24/64 loss: 0.19328558444976807
Batch 25/64 loss: 0.19435715675354004
Batch 26/64 loss: 0.21577084064483643
Batch 27/64 loss: 0.1973973512649536
Batch 28/64 loss: 0.20067381858825684
Batch 29/64 loss: 0.18742311000823975
Batch 30/64 loss: 0.1930859088897705
Batch 31/64 loss: 0.20441138744354248
Batch 32/64 loss: 0.18776440620422363
Batch 33/64 loss: 0.19980716705322266
Batch 34/64 loss: 0.20012938976287842
Batch 35/64 loss: 0.20175635814666748
Batch 36/64 loss: 0.18888050317764282
Batch 37/64 loss: 0.19908761978149414
Batch 38/64 loss: 0.18941724300384521
Batch 39/64 loss: 0.19153892993927002
Batch 40/64 loss: 0.20495331287384033
Batch 41/64 loss: 0.20441150665283203
Batch 42/64 loss: 0.2043321132659912
Batch 43/64 loss: 0.19292771816253662
Batch 44/64 loss: 0.20431303977966309
Batch 45/64 loss: 0.2025037407875061
Batch 46/64 loss: 0.21090340614318848
Batch 47/64 loss: 0.1958909034729004
Batch 48/64 loss: 0.19139152765274048
Batch 49/64 loss: 0.19994956254959106
Batch 50/64 loss: 0.21527844667434692
Batch 51/64 loss: 0.19786310195922852
Batch 52/64 loss: 0.19810664653778076
Batch 53/64 loss: 0.19893956184387207
Batch 54/64 loss: 0.1974157691001892
Batch 55/64 loss: 0.20521080493927002
Batch 56/64 loss: 0.20937579870224
Batch 57/64 loss: 0.19796884059906006
Batch 58/64 loss: 0.19456392526626587
Batch 59/64 loss: 0.20232141017913818
Batch 60/64 loss: 0.19815045595169067
Batch 61/64 loss: 0.19443750381469727
Batch 62/64 loss: 0.20578062534332275
Batch 63/64 loss: 0.20025330781936646
Batch 64/64 loss: 0.18001413345336914
Epoch 394  Train loss: 0.19895249628553205  Val loss: 0.2978239923818005
Epoch 395
-------------------------------
Batch 1/64 loss: 0.2022814154624939
Batch 2/64 loss: 0.19003236293792725
Batch 3/64 loss: 0.19384992122650146
Batch 4/64 loss: 0.19546741247177124
Batch 5/64 loss: 0.19782233238220215
Batch 6/64 loss: 0.21613264083862305
Batch 7/64 loss: 0.19252300262451172
Batch 8/64 loss: 0.20344990491867065
Batch 9/64 loss: 0.20030426979064941
Batch 10/64 loss: 0.20077061653137207
Batch 11/64 loss: 0.20458394289016724
Batch 12/64 loss: 0.20712876319885254
Batch 13/64 loss: 0.20702087879180908
Batch 14/64 loss: 0.19921433925628662
Batch 15/64 loss: 0.1985858678817749
Batch 16/64 loss: 0.1919894814491272
Batch 17/64 loss: 0.19376730918884277
Batch 18/64 loss: 0.20679891109466553
Batch 19/64 loss: 0.19345301389694214
Batch 20/64 loss: 0.21173465251922607
Batch 21/64 loss: 0.2094922661781311
Batch 22/64 loss: 0.19051837921142578
Batch 23/64 loss: 0.19804537296295166
Batch 24/64 loss: 0.1998910903930664
Batch 25/64 loss: 0.19583964347839355
Batch 26/64 loss: 0.20520150661468506
Batch 27/64 loss: 0.1926182508468628
Batch 28/64 loss: 0.1939079761505127
Batch 29/64 loss: 0.1882840394973755
Batch 30/64 loss: 0.20849549770355225
Batch 31/64 loss: 0.1971413493156433
Batch 32/64 loss: 0.19230496883392334
Batch 33/64 loss: 0.19278037548065186
Batch 34/64 loss: 0.1943361759185791
Batch 35/64 loss: 0.1907140016555786
Batch 36/64 loss: 0.19976305961608887
Batch 37/64 loss: 0.20304858684539795
Batch 38/64 loss: 0.1968144178390503
Batch 39/64 loss: 0.19350534677505493
Batch 40/64 loss: 0.20036011934280396
Batch 41/64 loss: 0.19670140743255615
Batch 42/64 loss: 0.1914527416229248
Batch 43/64 loss: 0.19656288623809814
Batch 44/64 loss: 0.19912880659103394
Batch 45/64 loss: 0.18971586227416992
Batch 46/64 loss: 0.2035934329032898
Batch 47/64 loss: 0.20998156070709229
Batch 48/64 loss: 0.19513368606567383
Batch 49/64 loss: 0.20138096809387207
Batch 50/64 loss: 0.20083165168762207
Batch 51/64 loss: 0.19233840703964233
Batch 52/64 loss: 0.19312310218811035
Batch 53/64 loss: 0.20157980918884277
Batch 54/64 loss: 0.19064652919769287
Batch 55/64 loss: 0.1983913779258728
Batch 56/64 loss: 0.1953633427619934
Batch 57/64 loss: 0.19306600093841553
Batch 58/64 loss: 0.19269311428070068
Batch 59/64 loss: 0.20194381475448608
Batch 60/64 loss: 0.1916080117225647
Batch 61/64 loss: 0.217845618724823
Batch 62/64 loss: 0.20049536228179932
Batch 63/64 loss: 0.19963622093200684
Batch 64/64 loss: 0.20371508598327637
Epoch 395  Train loss: 0.19852507441651587  Val loss: 0.2974672317504883
Epoch 396
-------------------------------
Batch 1/64 loss: 0.20793062448501587
Batch 2/64 loss: 0.19250857830047607
Batch 3/64 loss: 0.1949150562286377
Batch 4/64 loss: 0.1985100507736206
Batch 5/64 loss: 0.2005176544189453
Batch 6/64 loss: 0.19481980800628662
Batch 7/64 loss: 0.20173370838165283
Batch 8/64 loss: 0.1976248025894165
Batch 9/64 loss: 0.20204806327819824
Batch 10/64 loss: 0.20726102590560913
Batch 11/64 loss: 0.2067704200744629
Batch 12/64 loss: 0.19968724250793457
Batch 13/64 loss: 0.19572728872299194
Batch 14/64 loss: 0.1878284215927124
Batch 15/64 loss: 0.1961105465888977
Batch 16/64 loss: 0.19101965427398682
Batch 17/64 loss: 0.1932525634765625
Batch 18/64 loss: 0.18237245082855225
Batch 19/64 loss: 0.20119553804397583
Batch 20/64 loss: 0.19405609369277954
Batch 21/64 loss: 0.19686108827590942
Batch 22/64 loss: 0.18801623582839966
Batch 23/64 loss: 0.22476983070373535
Batch 24/64 loss: 0.20247459411621094
Batch 25/64 loss: 0.21039676666259766
Batch 26/64 loss: 0.1911635398864746
Batch 27/64 loss: 0.1970769166946411
Batch 28/64 loss: 0.19805830717086792
Batch 29/64 loss: 0.22195255756378174
Batch 30/64 loss: 0.20122528076171875
Batch 31/64 loss: 0.19539713859558105
Batch 32/64 loss: 0.19211721420288086
Batch 33/64 loss: 0.19484740495681763
Batch 34/64 loss: 0.19447237253189087
Batch 35/64 loss: 0.19920307397842407
Batch 36/64 loss: 0.2024562954902649
Batch 37/64 loss: 0.19191014766693115
Batch 38/64 loss: 0.1914151906967163
Batch 39/64 loss: 0.1935390830039978
Batch 40/64 loss: 0.193511962890625
Batch 41/64 loss: 0.1945953369140625
Batch 42/64 loss: 0.19442099332809448
Batch 43/64 loss: 0.19280534982681274
Batch 44/64 loss: 0.20091098546981812
Batch 45/64 loss: 0.18816369771957397
Batch 46/64 loss: 0.20829302072525024
Batch 47/64 loss: 0.18761563301086426
Batch 48/64 loss: 0.204972505569458
Batch 49/64 loss: 0.19154679775238037
Batch 50/64 loss: 0.21123617887496948
Batch 51/64 loss: 0.19235801696777344
Batch 52/64 loss: 0.18941271305084229
Batch 53/64 loss: 0.19010412693023682
Batch 54/64 loss: 0.20617544651031494
Batch 55/64 loss: 0.19793319702148438
Batch 56/64 loss: 0.19564509391784668
Batch 57/64 loss: 0.2035679817199707
Batch 58/64 loss: 0.2014515995979309
Batch 59/64 loss: 0.19870007038116455
Batch 60/64 loss: 0.21273624897003174
Batch 61/64 loss: 0.2004563808441162
Batch 62/64 loss: 0.1931062936782837
Batch 63/64 loss: 0.20835179090499878
Batch 64/64 loss: 0.18983817100524902
Epoch 396  Train loss: 0.19817557147904938  Val loss: 0.29779507470704436
Epoch 397
-------------------------------
Batch 1/64 loss: 0.20002669095993042
Batch 2/64 loss: 0.20033079385757446
Batch 3/64 loss: 0.20710384845733643
Batch 4/64 loss: 0.1938692331314087
Batch 5/64 loss: 0.19726675748825073
Batch 6/64 loss: 0.19558405876159668
Batch 7/64 loss: 0.191256582736969
Batch 8/64 loss: 0.217099130153656
Batch 9/64 loss: 0.18889987468719482
Batch 10/64 loss: 0.1905556321144104
Batch 11/64 loss: 0.1885945200920105
Batch 12/64 loss: 0.19654572010040283
Batch 13/64 loss: 0.19582712650299072
Batch 14/64 loss: 0.20822274684906006
Batch 15/64 loss: 0.20852649211883545
Batch 16/64 loss: 0.18404901027679443
Batch 17/64 loss: 0.19120550155639648
Batch 18/64 loss: 0.20944899320602417
Batch 19/64 loss: 0.20897436141967773
Batch 20/64 loss: 0.186984121799469
Batch 21/64 loss: 0.20709872245788574
Batch 22/64 loss: 0.19241297245025635
Batch 23/64 loss: 0.19583016633987427
Batch 24/64 loss: 0.1951104998588562
Batch 25/64 loss: 0.19790571928024292
Batch 26/64 loss: 0.19455504417419434
Batch 27/64 loss: 0.19888627529144287
Batch 28/64 loss: 0.19131523370742798
Batch 29/64 loss: 0.20085597038269043
Batch 30/64 loss: 0.19236266613006592
Batch 31/64 loss: 0.1924101710319519
Batch 32/64 loss: 0.1999276876449585
Batch 33/64 loss: 0.19462841749191284
Batch 34/64 loss: 0.20323193073272705
Batch 35/64 loss: 0.19768065214157104
Batch 36/64 loss: 0.19432008266448975
Batch 37/64 loss: 0.2022150754928589
Batch 38/64 loss: 0.1910756230354309
Batch 39/64 loss: 0.19409137964248657
Batch 40/64 loss: 0.19860750436782837
Batch 41/64 loss: 0.2015426754951477
Batch 42/64 loss: 0.19956129789352417
Batch 43/64 loss: 0.1944097876548767
Batch 44/64 loss: 0.2001197338104248
Batch 45/64 loss: 0.191211998462677
Batch 46/64 loss: 0.1967901587486267
Batch 47/64 loss: 0.1910579800605774
Batch 48/64 loss: 0.19861674308776855
Batch 49/64 loss: 0.21280115842819214
Batch 50/64 loss: 0.20995426177978516
Batch 51/64 loss: 0.1896761655807495
Batch 52/64 loss: 0.20091551542282104
Batch 53/64 loss: 0.2028113603591919
Batch 54/64 loss: 0.196743905544281
Batch 55/64 loss: 0.1940714716911316
Batch 56/64 loss: 0.20361334085464478
Batch 57/64 loss: 0.20607757568359375
Batch 58/64 loss: 0.18915992975234985
Batch 59/64 loss: 0.18958783149719238
Batch 60/64 loss: 0.20628762245178223
Batch 61/64 loss: 0.1936955451965332
Batch 62/64 loss: 0.20082294940948486
Batch 63/64 loss: 0.19569051265716553
Batch 64/64 loss: 0.2098408341407776
Epoch 397  Train loss: 0.19792146098379995  Val loss: 0.2980268804478072
Epoch 398
-------------------------------
Batch 1/64 loss: 0.18247348070144653
Batch 2/64 loss: 0.19927704334259033
Batch 3/64 loss: 0.19605225324630737
Batch 4/64 loss: 0.1933334469795227
Batch 5/64 loss: 0.20747941732406616
Batch 6/64 loss: 0.19819694757461548
Batch 7/64 loss: 0.18920308351516724
Batch 8/64 loss: 0.19545423984527588
Batch 9/64 loss: 0.19953930377960205
Batch 10/64 loss: 0.19004154205322266
Batch 11/64 loss: 0.18132072687149048
Batch 12/64 loss: 0.19413971900939941
Batch 13/64 loss: 0.190335214138031
Batch 14/64 loss: 0.1884852647781372
Batch 15/64 loss: 0.19501161575317383
Batch 16/64 loss: 0.1956443190574646
Batch 17/64 loss: 0.2084369659423828
Batch 18/64 loss: 0.18918073177337646
Batch 19/64 loss: 0.19534236192703247
Batch 20/64 loss: 0.1886170506477356
Batch 21/64 loss: 0.20409727096557617
Batch 22/64 loss: 0.19387543201446533
Batch 23/64 loss: 0.20252108573913574
Batch 24/64 loss: 0.2002083659172058
Batch 25/64 loss: 0.19793224334716797
Batch 26/64 loss: 0.1956934928894043
Batch 27/64 loss: 0.20598089694976807
Batch 28/64 loss: 0.20772922039031982
Batch 29/64 loss: 0.19107747077941895
Batch 30/64 loss: 0.19332879781723022
Batch 31/64 loss: 0.2113553285598755
Batch 32/64 loss: 0.19437503814697266
Batch 33/64 loss: 0.19236135482788086
Batch 34/64 loss: 0.2014794945716858
Batch 35/64 loss: 0.20750033855438232
Batch 36/64 loss: 0.18627214431762695
Batch 37/64 loss: 0.190507173538208
Batch 38/64 loss: 0.19303148984909058
Batch 39/64 loss: 0.20733630657196045
Batch 40/64 loss: 0.1877853274345398
Batch 41/64 loss: 0.1926407814025879
Batch 42/64 loss: 0.20268571376800537
Batch 43/64 loss: 0.19966226816177368
Batch 44/64 loss: 0.19608616828918457
Batch 45/64 loss: 0.19615280628204346
Batch 46/64 loss: 0.18961960077285767
Batch 47/64 loss: 0.2090931534767151
Batch 48/64 loss: 0.1911238431930542
Batch 49/64 loss: 0.19694948196411133
Batch 50/64 loss: 0.19712704420089722
Batch 51/64 loss: 0.20505291223526
Batch 52/64 loss: 0.19731062650680542
Batch 53/64 loss: 0.20275813341140747
Batch 54/64 loss: 0.18877321481704712
Batch 55/64 loss: 0.19119137525558472
Batch 56/64 loss: 0.20022881031036377
Batch 57/64 loss: 0.2010718584060669
Batch 58/64 loss: 0.20215755701065063
Batch 59/64 loss: 0.20247095823287964
Batch 60/64 loss: 0.20539188385009766
Batch 61/64 loss: 0.19803529977798462
Batch 62/64 loss: 0.18973541259765625
Batch 63/64 loss: 0.19955718517303467
Batch 64/64 loss: 0.20575255155563354
Epoch 398  Train loss: 0.19688162359536862  Val loss: 0.29733752180210915
Epoch 399
-------------------------------
Batch 1/64 loss: 0.1991569995880127
Batch 2/64 loss: 0.19574403762817383
Batch 3/64 loss: 0.19898325204849243
Batch 4/64 loss: 0.19442564249038696
Batch 5/64 loss: 0.19271481037139893
Batch 6/64 loss: 0.19866836071014404
Batch 7/64 loss: 0.2005707025527954
Batch 8/64 loss: 0.19186067581176758
Batch 9/64 loss: 0.21337902545928955
Batch 10/64 loss: 0.19221621751785278
Batch 11/64 loss: 0.19620048999786377
Batch 12/64 loss: 0.20807212591171265
Batch 13/64 loss: 0.19638895988464355
Batch 14/64 loss: 0.19526952505111694
Batch 15/64 loss: 0.21528315544128418
Batch 16/64 loss: 0.19437861442565918
Batch 17/64 loss: 0.19334030151367188
Batch 18/64 loss: 0.19345158338546753
Batch 19/64 loss: 0.1966313123703003
Batch 20/64 loss: 0.19556409120559692
Batch 21/64 loss: 0.2051396369934082
Batch 22/64 loss: 0.19645261764526367
Batch 23/64 loss: 0.19119131565093994
Batch 24/64 loss: 0.1968289017677307
Batch 25/64 loss: 0.18595314025878906
Batch 26/64 loss: 0.1981353759765625
Batch 27/64 loss: 0.1907254457473755
Batch 28/64 loss: 0.19546812772750854
Batch 29/64 loss: 0.20096516609191895
Batch 30/64 loss: 0.21007132530212402
Batch 31/64 loss: 0.20423412322998047
Batch 32/64 loss: 0.19304966926574707
Batch 33/64 loss: 0.19638603925704956
Batch 34/64 loss: 0.19128620624542236
Batch 35/64 loss: 0.19656622409820557
Batch 36/64 loss: 0.19919633865356445
Batch 37/64 loss: 0.19045287370681763
Batch 38/64 loss: 0.20658576488494873
Batch 39/64 loss: 0.1914123296737671
Batch 40/64 loss: 0.20335716009140015
Batch 41/64 loss: 0.19909971952438354
Batch 42/64 loss: 0.19984233379364014
Batch 43/64 loss: 0.2002289891242981
Batch 44/64 loss: 0.19453835487365723
Batch 45/64 loss: 0.20494186878204346
Batch 46/64 loss: 0.1945316195487976
Batch 47/64 loss: 0.19266003370285034
Batch 48/64 loss: 0.1993679404258728
Batch 49/64 loss: 0.19599288702011108
Batch 50/64 loss: 0.20126211643218994
Batch 51/64 loss: 0.1958301067352295
Batch 52/64 loss: 0.1986219882965088
Batch 53/64 loss: 0.1870039701461792
Batch 54/64 loss: 0.2120276689529419
Batch 55/64 loss: 0.21309685707092285
Batch 56/64 loss: 0.19215577840805054
Batch 57/64 loss: 0.19822990894317627
Batch 58/64 loss: 0.18903332948684692
Batch 59/64 loss: 0.1960166096687317
Batch 60/64 loss: 0.18957412242889404
Batch 61/64 loss: 0.20388489961624146
Batch 62/64 loss: 0.19661331176757812
Batch 63/64 loss: 0.1885850429534912
Batch 64/64 loss: 0.19682294130325317
Epoch 399  Train loss: 0.1975923816363017  Val loss: 0.29725954991435677
Epoch 400
-------------------------------
Batch 1/64 loss: 0.19133496284484863
Batch 2/64 loss: 0.19812655448913574
Batch 3/64 loss: 0.20120471715927124
Batch 4/64 loss: 0.19657009840011597
Batch 5/64 loss: 0.19807922840118408
Batch 6/64 loss: 0.18256402015686035
Batch 7/64 loss: 0.20453011989593506
Batch 8/64 loss: 0.1947069764137268
Batch 9/64 loss: 0.1975758671760559
Batch 10/64 loss: 0.19503283500671387
Batch 11/64 loss: 0.1937604546546936
Batch 12/64 loss: 0.19657999277114868
Batch 13/64 loss: 0.2019316554069519
Batch 14/64 loss: 0.19351732730865479
Batch 15/64 loss: 0.19953596591949463
Batch 16/64 loss: 0.19099366664886475
Batch 17/64 loss: 0.20640790462493896
Batch 18/64 loss: 0.1854233741760254
Batch 19/64 loss: 0.1969064474105835
Batch 20/64 loss: 0.20185530185699463
Batch 21/64 loss: 0.18328815698623657
Batch 22/64 loss: 0.1832442283630371
Batch 23/64 loss: 0.2007085084915161
Batch 24/64 loss: 0.20097088813781738
Batch 25/64 loss: 0.18407130241394043
Batch 26/64 loss: 0.2014971375465393
Batch 27/64 loss: 0.186673104763031
Batch 28/64 loss: 0.18902349472045898
Batch 29/64 loss: 0.18810057640075684
Batch 30/64 loss: 0.1862117052078247
Batch 31/64 loss: 0.20907503366470337
Batch 32/64 loss: 0.21948039531707764
Batch 33/64 loss: 0.20103472471237183
Batch 34/64 loss: 0.19681662321090698
Batch 35/64 loss: 0.19311797618865967
Batch 36/64 loss: 0.2036404013633728
Batch 37/64 loss: 0.1911942958831787
Batch 38/64 loss: 0.20892930030822754
Batch 39/64 loss: 0.19786548614501953
Batch 40/64 loss: 0.1950535774230957
Batch 41/64 loss: 0.19769227504730225
Batch 42/64 loss: 0.2000560760498047
Batch 43/64 loss: 0.19131314754486084
Batch 44/64 loss: 0.20573186874389648
Batch 45/64 loss: 0.19544243812561035
Batch 46/64 loss: 0.20786619186401367
Batch 47/64 loss: 0.19214612245559692
Batch 48/64 loss: 0.20387786626815796
Batch 49/64 loss: 0.19505661725997925
Batch 50/64 loss: 0.19384068250656128
Batch 51/64 loss: 0.18948715925216675
Batch 52/64 loss: 0.2010427713394165
Batch 53/64 loss: 0.18854689598083496
Batch 54/64 loss: 0.19819897413253784
Batch 55/64 loss: 0.19995886087417603
Batch 56/64 loss: 0.2027266025543213
Batch 57/64 loss: 0.19447100162506104
Batch 58/64 loss: 0.19511884450912476
Batch 59/64 loss: 0.19676613807678223
Batch 60/64 loss: 0.19577354192733765
Batch 61/64 loss: 0.2013634443283081
Batch 62/64 loss: 0.2099817395210266
Batch 63/64 loss: 0.2159121036529541
Batch 64/64 loss: 0.20115065574645996
Epoch 400  Train loss: 0.19717441166148467  Val loss: 0.29732126038508727
Epoch 401
-------------------------------
Batch 1/64 loss: 0.19938302040100098
Batch 2/64 loss: 0.19377481937408447
Batch 3/64 loss: 0.19287729263305664
Batch 4/64 loss: 0.19757938385009766
Batch 5/64 loss: 0.19423186779022217
Batch 6/64 loss: 0.2154659628868103
Batch 7/64 loss: 0.1938260793685913
Batch 8/64 loss: 0.19027119874954224
Batch 9/64 loss: 0.19170784950256348
Batch 10/64 loss: 0.19220876693725586
Batch 11/64 loss: 0.19437968730926514
Batch 12/64 loss: 0.19097435474395752
Batch 13/64 loss: 0.1941918134689331
Batch 14/64 loss: 0.19993382692337036
Batch 15/64 loss: 0.19999992847442627
Batch 16/64 loss: 0.1937417984008789
Batch 17/64 loss: 0.20903027057647705
Batch 18/64 loss: 0.19759142398834229
Batch 19/64 loss: 0.18828320503234863
Batch 20/64 loss: 0.18944549560546875
Batch 21/64 loss: 0.2060229778289795
Batch 22/64 loss: 0.19553184509277344
Batch 23/64 loss: 0.2094438076019287
Batch 24/64 loss: 0.18933188915252686
Batch 25/64 loss: 0.2112169861793518
Batch 26/64 loss: 0.21228528022766113
Batch 27/64 loss: 0.18579399585723877
Batch 28/64 loss: 0.21091604232788086
Batch 29/64 loss: 0.20118260383605957
Batch 30/64 loss: 0.2012040615081787
Batch 31/64 loss: 0.188679039478302
Batch 32/64 loss: 0.2021017074584961
Batch 33/64 loss: 0.1918736696243286
Batch 34/64 loss: 0.19327962398529053
Batch 35/64 loss: 0.18966293334960938
Batch 36/64 loss: 0.2032989263534546
Batch 37/64 loss: 0.18303239345550537
Batch 38/64 loss: 0.1915724277496338
Batch 39/64 loss: 0.1999531388282776
Batch 40/64 loss: 0.20186424255371094
Batch 41/64 loss: 0.19676440954208374
Batch 42/64 loss: 0.19299256801605225
Batch 43/64 loss: 0.19194310903549194
Batch 44/64 loss: 0.20234835147857666
Batch 45/64 loss: 0.19941556453704834
Batch 46/64 loss: 0.19401884078979492
Batch 47/64 loss: 0.18897193670272827
Batch 48/64 loss: 0.20178353786468506
Batch 49/64 loss: 0.19628173112869263
Batch 50/64 loss: 0.2010270357131958
Batch 51/64 loss: 0.19133800268173218
Batch 52/64 loss: 0.1956779956817627
Batch 53/64 loss: 0.2094530463218689
Batch 54/64 loss: 0.2006223201751709
Batch 55/64 loss: 0.200286865234375
Batch 56/64 loss: 0.1943681240081787
Batch 57/64 loss: 0.19259262084960938
Batch 58/64 loss: 0.1969730257987976
Batch 59/64 loss: 0.1887943148612976
Batch 60/64 loss: 0.19004064798355103
Batch 61/64 loss: 0.19861364364624023
Batch 62/64 loss: 0.19424986839294434
Batch 63/64 loss: 0.19837474822998047
Batch 64/64 loss: 0.20601022243499756
Epoch 401  Train loss: 0.1969974213955449  Val loss: 0.297420157394868
Epoch 402
-------------------------------
Batch 1/64 loss: 0.19085615873336792
Batch 2/64 loss: 0.18371355533599854
Batch 3/64 loss: 0.18828094005584717
Batch 4/64 loss: 0.1998007893562317
Batch 5/64 loss: 0.2083110809326172
Batch 6/64 loss: 0.1951979398727417
Batch 7/64 loss: 0.1924586296081543
Batch 8/64 loss: 0.2048080563545227
Batch 9/64 loss: 0.19468653202056885
Batch 10/64 loss: 0.1969199776649475
Batch 11/64 loss: 0.18602102994918823
Batch 12/64 loss: 0.18320387601852417
Batch 13/64 loss: 0.18388479948043823
Batch 14/64 loss: 0.19048285484313965
Batch 15/64 loss: 0.1978846788406372
Batch 16/64 loss: 0.18875688314437866
Batch 17/64 loss: 0.1780877709388733
Batch 18/64 loss: 0.19977468252182007
Batch 19/64 loss: 0.18638640642166138
Batch 20/64 loss: 0.1869356632232666
Batch 21/64 loss: 0.20442193746566772
Batch 22/64 loss: 0.196030855178833
Batch 23/64 loss: 0.20528137683868408
Batch 24/64 loss: 0.21201640367507935
Batch 25/64 loss: 0.20648658275604248
Batch 26/64 loss: 0.1986885666847229
Batch 27/64 loss: 0.21445119380950928
Batch 28/64 loss: 0.211575448513031
Batch 29/64 loss: 0.18989896774291992
Batch 30/64 loss: 0.21274125576019287
Batch 31/64 loss: 0.19733285903930664
Batch 32/64 loss: 0.20363080501556396
Batch 33/64 loss: 0.19660300016403198
Batch 34/64 loss: 0.2101682424545288
Batch 35/64 loss: 0.19645994901657104
Batch 36/64 loss: 0.20077556371688843
Batch 37/64 loss: 0.1934375762939453
Batch 38/64 loss: 0.19425970315933228
Batch 39/64 loss: 0.20586895942687988
Batch 40/64 loss: 0.19674503803253174
Batch 41/64 loss: 0.1944059133529663
Batch 42/64 loss: 0.19406020641326904
Batch 43/64 loss: 0.19685328006744385
Batch 44/64 loss: 0.19956529140472412
Batch 45/64 loss: 0.20455396175384521
Batch 46/64 loss: 0.21372061967849731
Batch 47/64 loss: 0.18319523334503174
Batch 48/64 loss: 0.1913301944732666
Batch 49/64 loss: 0.19872981309890747
Batch 50/64 loss: 0.20656436681747437
Batch 51/64 loss: 0.19376981258392334
Batch 52/64 loss: 0.1981898546218872
Batch 53/64 loss: 0.19562894105911255
Batch 54/64 loss: 0.19782733917236328
Batch 55/64 loss: 0.20614057779312134
Batch 56/64 loss: 0.18671292066574097
Batch 57/64 loss: 0.19176024198532104
Batch 58/64 loss: 0.19285839796066284
Batch 59/64 loss: 0.19969987869262695
Batch 60/64 loss: 0.19390195608139038
Batch 61/64 loss: 0.21132242679595947
Batch 62/64 loss: 0.20110559463500977
Batch 63/64 loss: 0.18629884719848633
Batch 64/64 loss: 0.20282495021820068
Epoch 402  Train loss: 0.1972335838804058  Val loss: 0.29722274005208227
Epoch 403
-------------------------------
Batch 1/64 loss: 0.1961740255355835
Batch 2/64 loss: 0.207564115524292
Batch 3/64 loss: 0.22262752056121826
Batch 4/64 loss: 0.1937100887298584
Batch 5/64 loss: 0.19483447074890137
Batch 6/64 loss: 0.20096993446350098
Batch 7/64 loss: 0.19876736402511597
Batch 8/64 loss: 0.18406236171722412
Batch 9/64 loss: 0.1964569091796875
Batch 10/64 loss: 0.19291061162948608
Batch 11/64 loss: 0.20407891273498535
Batch 12/64 loss: 0.20608681440353394
Batch 13/64 loss: 0.18870878219604492
Batch 14/64 loss: 0.19866609573364258
Batch 15/64 loss: 0.19607925415039062
Batch 16/64 loss: 0.20018845796585083
Batch 17/64 loss: 0.1874280571937561
Batch 18/64 loss: 0.1990758776664734
Batch 19/64 loss: 0.20042705535888672
Batch 20/64 loss: 0.1908777356147766
Batch 21/64 loss: 0.18958628177642822
Batch 22/64 loss: 0.1917175054550171
Batch 23/64 loss: 0.1885443925857544
Batch 24/64 loss: 0.19617050886154175
Batch 25/64 loss: 0.18768727779388428
Batch 26/64 loss: 0.19471192359924316
Batch 27/64 loss: 0.1912400722503662
Batch 28/64 loss: 0.19521284103393555
Batch 29/64 loss: 0.19141286611557007
Batch 30/64 loss: 0.2041645646095276
Batch 31/64 loss: 0.18835508823394775
Batch 32/64 loss: 0.19942331314086914
Batch 33/64 loss: 0.19458401203155518
Batch 34/64 loss: 0.19414860010147095
Batch 35/64 loss: 0.19589173793792725
Batch 36/64 loss: 0.19708847999572754
Batch 37/64 loss: 0.20150887966156006
Batch 38/64 loss: 0.20707553625106812
Batch 39/64 loss: 0.19512957334518433
Batch 40/64 loss: 0.19058769941329956
Batch 41/64 loss: 0.19431787729263306
Batch 42/64 loss: 0.19691437482833862
Batch 43/64 loss: 0.1925719976425171
Batch 44/64 loss: 0.1936206817626953
Batch 45/64 loss: 0.20529663562774658
Batch 46/64 loss: 0.20093762874603271
Batch 47/64 loss: 0.1927889585494995
Batch 48/64 loss: 0.20475256443023682
Batch 49/64 loss: 0.19104409217834473
Batch 50/64 loss: 0.19390904903411865
Batch 51/64 loss: 0.2060750126838684
Batch 52/64 loss: 0.2048128843307495
Batch 53/64 loss: 0.18634957075119019
Batch 54/64 loss: 0.1956196427345276
Batch 55/64 loss: 0.20757460594177246
Batch 56/64 loss: 0.19756942987442017
Batch 57/64 loss: 0.20242559909820557
Batch 58/64 loss: 0.19673460721969604
Batch 59/64 loss: 0.2013763189315796
Batch 60/64 loss: 0.1863117218017578
Batch 61/64 loss: 0.1922471523284912
Batch 62/64 loss: 0.19304800033569336
Batch 63/64 loss: 0.1998974084854126
Batch 64/64 loss: 0.21539950370788574
Epoch 403  Train loss: 0.19688911437988282  Val loss: 0.29752807989972563
Epoch 404
-------------------------------
Batch 1/64 loss: 0.18611180782318115
Batch 2/64 loss: 0.19174593687057495
Batch 3/64 loss: 0.20022743940353394
Batch 4/64 loss: 0.2023942470550537
Batch 5/64 loss: 0.20309805870056152
Batch 6/64 loss: 0.1889268159866333
Batch 7/64 loss: 0.19714397192001343
Batch 8/64 loss: 0.1875
Batch 9/64 loss: 0.1866651177406311
Batch 10/64 loss: 0.19014906883239746
Batch 11/64 loss: 0.19274985790252686
Batch 12/64 loss: 0.19918006658554077
Batch 13/64 loss: 0.20192110538482666
Batch 14/64 loss: 0.19974595308303833
Batch 15/64 loss: 0.20284539461135864
Batch 16/64 loss: 0.19647663831710815
Batch 17/64 loss: 0.19665688276290894
Batch 18/64 loss: 0.20546770095825195
Batch 19/64 loss: 0.19695401191711426
Batch 20/64 loss: 0.20920228958129883
Batch 21/64 loss: 0.1947079300880432
Batch 22/64 loss: 0.1865728497505188
Batch 23/64 loss: 0.19814246892929077
Batch 24/64 loss: 0.19080251455307007
Batch 25/64 loss: 0.20332497358322144
Batch 26/64 loss: 0.20609283447265625
Batch 27/64 loss: 0.2059827446937561
Batch 28/64 loss: 0.21389561891555786
Batch 29/64 loss: 0.21893846988677979
Batch 30/64 loss: 0.20068895816802979
Batch 31/64 loss: 0.1928216814994812
Batch 32/64 loss: 0.18786996603012085
Batch 33/64 loss: 0.20719420909881592
Batch 34/64 loss: 0.1887093186378479
Batch 35/64 loss: 0.19718867540359497
Batch 36/64 loss: 0.1994462013244629
Batch 37/64 loss: 0.1997847557067871
Batch 38/64 loss: 0.19457274675369263
Batch 39/64 loss: 0.18899112939834595
Batch 40/64 loss: 0.19253623485565186
Batch 41/64 loss: 0.20688873529434204
Batch 42/64 loss: 0.2014668583869934
Batch 43/64 loss: 0.19612282514572144
Batch 44/64 loss: 0.19333696365356445
Batch 45/64 loss: 0.19784986972808838
Batch 46/64 loss: 0.19834202527999878
Batch 47/64 loss: 0.19600731134414673
Batch 48/64 loss: 0.18097656965255737
Batch 49/64 loss: 0.19924139976501465
Batch 50/64 loss: 0.1936948299407959
Batch 51/64 loss: 0.19820445775985718
Batch 52/64 loss: 0.20158493518829346
Batch 53/64 loss: 0.18472731113433838
Batch 54/64 loss: 0.20813924074172974
Batch 55/64 loss: 0.19420647621154785
Batch 56/64 loss: 0.19008588790893555
Batch 57/64 loss: 0.19645673036575317
Batch 58/64 loss: 0.19596493244171143
Batch 59/64 loss: 0.20163214206695557
Batch 60/64 loss: 0.19452697038650513
Batch 61/64 loss: 0.19653701782226562
Batch 62/64 loss: 0.19473910331726074
Batch 63/64 loss: 0.18674904108047485
Batch 64/64 loss: 0.19958657026290894
Epoch 404  Train loss: 0.19702899152157352  Val loss: 0.29691107043695614
Epoch 405
-------------------------------
Batch 1/64 loss: 0.18918007612228394
Batch 2/64 loss: 0.20095068216323853
Batch 3/64 loss: 0.18617939949035645
Batch 4/64 loss: 0.1860758662223816
Batch 5/64 loss: 0.1954084038734436
Batch 6/64 loss: 0.18835985660552979
Batch 7/64 loss: 0.19257402420043945
Batch 8/64 loss: 0.1857689619064331
Batch 9/64 loss: 0.18945729732513428
Batch 10/64 loss: 0.1937306523323059
Batch 11/64 loss: 0.19457674026489258
Batch 12/64 loss: 0.19914299249649048
Batch 13/64 loss: 0.19025534391403198
Batch 14/64 loss: 0.19440722465515137
Batch 15/64 loss: 0.1891038417816162
Batch 16/64 loss: 0.1863311529159546
Batch 17/64 loss: 0.2063053846359253
Batch 18/64 loss: 0.2010328769683838
Batch 19/64 loss: 0.2044156789779663
Batch 20/64 loss: 0.1989108920097351
Batch 21/64 loss: 0.19580316543579102
Batch 22/64 loss: 0.19532907009124756
Batch 23/64 loss: 0.19483917951583862
Batch 24/64 loss: 0.20656144618988037
Batch 25/64 loss: 0.19706284999847412
Batch 26/64 loss: 0.21094727516174316
Batch 27/64 loss: 0.21235954761505127
Batch 28/64 loss: 0.20130383968353271
Batch 29/64 loss: 0.19170880317687988
Batch 30/64 loss: 0.20170366764068604
Batch 31/64 loss: 0.19196701049804688
Batch 32/64 loss: 0.18974536657333374
Batch 33/64 loss: 0.1880839467048645
Batch 34/64 loss: 0.2123844027519226
Batch 35/64 loss: 0.18443071842193604
Batch 36/64 loss: 0.20280301570892334
Batch 37/64 loss: 0.20094358921051025
Batch 38/64 loss: 0.19035929441452026
Batch 39/64 loss: 0.20412397384643555
Batch 40/64 loss: 0.20362555980682373
Batch 41/64 loss: 0.19710659980773926
Batch 42/64 loss: 0.20152854919433594
Batch 43/64 loss: 0.2038162350654602
Batch 44/64 loss: 0.19414693117141724
Batch 45/64 loss: 0.1934167742729187
Batch 46/64 loss: 0.20240604877471924
Batch 47/64 loss: 0.202528178691864
Batch 48/64 loss: 0.19349193572998047
Batch 49/64 loss: 0.20064550638198853
Batch 50/64 loss: 0.20574301481246948
Batch 51/64 loss: 0.19242393970489502
Batch 52/64 loss: 0.2029619812965393
Batch 53/64 loss: 0.1943897008895874
Batch 54/64 loss: 0.18480205535888672
Batch 55/64 loss: 0.19488126039505005
Batch 56/64 loss: 0.19289737939834595
Batch 57/64 loss: 0.2035350799560547
Batch 58/64 loss: 0.21105194091796875
Batch 59/64 loss: 0.20140433311462402
Batch 60/64 loss: 0.20421826839447021
Batch 61/64 loss: 0.20546960830688477
Batch 62/64 loss: 0.20014768838882446
Batch 63/64 loss: 0.19664835929870605
Batch 64/64 loss: 0.20141452550888062
Epoch 405  Train loss: 0.19731726015315337  Val loss: 0.2974807822827211
Epoch 406
-------------------------------
Batch 1/64 loss: 0.20346462726593018
Batch 2/64 loss: 0.1972370743751526
Batch 3/64 loss: 0.19721680879592896
Batch 4/64 loss: 0.20167481899261475
Batch 5/64 loss: 0.19196635484695435
Batch 6/64 loss: 0.195855975151062
Batch 7/64 loss: 0.19278913736343384
Batch 8/64 loss: 0.19122451543807983
Batch 9/64 loss: 0.19906282424926758
Batch 10/64 loss: 0.1834162473678589
Batch 11/64 loss: 0.19725334644317627
Batch 12/64 loss: 0.19373106956481934
Batch 13/64 loss: 0.19534450769424438
Batch 14/64 loss: 0.19721925258636475
Batch 15/64 loss: 0.19143903255462646
Batch 16/64 loss: 0.18812555074691772
Batch 17/64 loss: 0.19851267337799072
Batch 18/64 loss: 0.18663746118545532
Batch 19/64 loss: 0.18400031328201294
Batch 20/64 loss: 0.1809941530227661
Batch 21/64 loss: 0.18914896249771118
Batch 22/64 loss: 0.1983981728553772
Batch 23/64 loss: 0.19306623935699463
Batch 24/64 loss: 0.20672833919525146
Batch 25/64 loss: 0.19943463802337646
Batch 26/64 loss: 0.20225012302398682
Batch 27/64 loss: 0.19299930334091187
Batch 28/64 loss: 0.17925256490707397
Batch 29/64 loss: 0.20366430282592773
Batch 30/64 loss: 0.1883765459060669
Batch 31/64 loss: 0.19408416748046875
Batch 32/64 loss: 0.20385968685150146
Batch 33/64 loss: 0.19715678691864014
Batch 34/64 loss: 0.19173181056976318
Batch 35/64 loss: 0.20203375816345215
Batch 36/64 loss: 0.1937488317489624
Batch 37/64 loss: 0.195168137550354
Batch 38/64 loss: 0.19201380014419556
Batch 39/64 loss: 0.19541305303573608
Batch 40/64 loss: 0.19652646780014038
Batch 41/64 loss: 0.19079852104187012
Batch 42/64 loss: 0.2021082043647766
Batch 43/64 loss: 0.1971091628074646
Batch 44/64 loss: 0.1968609094619751
Batch 45/64 loss: 0.212108314037323
Batch 46/64 loss: 0.18969297409057617
Batch 47/64 loss: 0.20696771144866943
Batch 48/64 loss: 0.20677530765533447
Batch 49/64 loss: 0.21014249324798584
Batch 50/64 loss: 0.2043445110321045
Batch 51/64 loss: 0.20570993423461914
Batch 52/64 loss: 0.19405734539031982
Batch 53/64 loss: 0.20338749885559082
Batch 54/64 loss: 0.19949793815612793
Batch 55/64 loss: 0.2048313021659851
Batch 56/64 loss: 0.20570743083953857
Batch 57/64 loss: 0.20423340797424316
Batch 58/64 loss: 0.1989588737487793
Batch 59/64 loss: 0.195484459400177
Batch 60/64 loss: 0.19550049304962158
Batch 61/64 loss: 0.19880622625350952
Batch 62/64 loss: 0.21015620231628418
Batch 63/64 loss: 0.19621402025222778
Batch 64/64 loss: 0.20279109477996826
Epoch 406  Train loss: 0.19707871371624516  Val loss: 0.2972185664979863
Epoch 407
-------------------------------
Batch 1/64 loss: 0.19389945268630981
Batch 2/64 loss: 0.1968221664428711
Batch 3/64 loss: 0.19642865657806396
Batch 4/64 loss: 0.1946965456008911
Batch 5/64 loss: 0.20362192392349243
Batch 6/64 loss: 0.19151270389556885
Batch 7/64 loss: 0.1953532099723816
Batch 8/64 loss: 0.20044201612472534
Batch 9/64 loss: 0.183724045753479
Batch 10/64 loss: 0.20075201988220215
Batch 11/64 loss: 0.1869715452194214
Batch 12/64 loss: 0.1960321068763733
Batch 13/64 loss: 0.20285725593566895
Batch 14/64 loss: 0.19816994667053223
Batch 15/64 loss: 0.19428592920303345
Batch 16/64 loss: 0.1881125569343567
Batch 17/64 loss: 0.19989794492721558
Batch 18/64 loss: 0.19531893730163574
Batch 19/64 loss: 0.2046111822128296
Batch 20/64 loss: 0.211511492729187
Batch 21/64 loss: 0.20639193058013916
Batch 22/64 loss: 0.20033800601959229
Batch 23/64 loss: 0.19604802131652832
Batch 24/64 loss: 0.18934905529022217
Batch 25/64 loss: 0.19620686769485474
Batch 26/64 loss: 0.21050530672073364
Batch 27/64 loss: 0.20672988891601562
Batch 28/64 loss: 0.19465649127960205
Batch 29/64 loss: 0.19308525323867798
Batch 30/64 loss: 0.19895905256271362
Batch 31/64 loss: 0.19791603088378906
Batch 32/64 loss: 0.19483017921447754
Batch 33/64 loss: 0.19215267896652222
Batch 34/64 loss: 0.1967981457710266
Batch 35/64 loss: 0.1872386932373047
Batch 36/64 loss: 0.2004101276397705
Batch 37/64 loss: 0.20381850004196167
Batch 38/64 loss: 0.19590812921524048
Batch 39/64 loss: 0.18884670734405518
Batch 40/64 loss: 0.20498156547546387
Batch 41/64 loss: 0.2032996416091919
Batch 42/64 loss: 0.19583749771118164
Batch 43/64 loss: 0.20354080200195312
Batch 44/64 loss: 0.1974085569381714
Batch 45/64 loss: 0.1929624080657959
Batch 46/64 loss: 0.20820826292037964
Batch 47/64 loss: 0.19311821460723877
Batch 48/64 loss: 0.19773077964782715
Batch 49/64 loss: 0.1969364881515503
Batch 50/64 loss: 0.19010776281356812
Batch 51/64 loss: 0.2159557342529297
Batch 52/64 loss: 0.2014673948287964
Batch 53/64 loss: 0.1981833577156067
Batch 54/64 loss: 0.19027012586593628
Batch 55/64 loss: 0.2135840654373169
Batch 56/64 loss: 0.21011769771575928
Batch 57/64 loss: 0.19475162029266357
Batch 58/64 loss: 0.19457221031188965
Batch 59/64 loss: 0.1878347396850586
Batch 60/64 loss: 0.20971018075942993
Batch 61/64 loss: 0.1891126036643982
Batch 62/64 loss: 0.1857960820198059
Batch 63/64 loss: 0.1961471438407898
Batch 64/64 loss: 0.20266950130462646
Epoch 407  Train loss: 0.19778584732728846  Val loss: 0.29691411293659015
Epoch 408
-------------------------------
Batch 1/64 loss: 0.19033753871917725
Batch 2/64 loss: 0.19023466110229492
Batch 3/64 loss: 0.19883036613464355
Batch 4/64 loss: 0.18987739086151123
Batch 5/64 loss: 0.1864660382270813
Batch 6/64 loss: 0.1992446780204773
Batch 7/64 loss: 0.20128703117370605
Batch 8/64 loss: 0.19741064310073853
Batch 9/64 loss: 0.19705486297607422
Batch 10/64 loss: 0.19687390327453613
Batch 11/64 loss: 0.1932188868522644
Batch 12/64 loss: 0.19987118244171143
Batch 13/64 loss: 0.19748055934906006
Batch 14/64 loss: 0.1945657730102539
Batch 15/64 loss: 0.20449578762054443
Batch 16/64 loss: 0.19079303741455078
Batch 17/64 loss: 0.1960354447364807
Batch 18/64 loss: 0.19655120372772217
Batch 19/64 loss: 0.18730640411376953
Batch 20/64 loss: 0.19934475421905518
Batch 21/64 loss: 0.19945251941680908
Batch 22/64 loss: 0.19928205013275146
Batch 23/64 loss: 0.1928715705871582
Batch 24/64 loss: 0.19166016578674316
Batch 25/64 loss: 0.21470916271209717
Batch 26/64 loss: 0.21043670177459717
Batch 27/64 loss: 0.19310522079467773
Batch 28/64 loss: 0.19057536125183105
Batch 29/64 loss: 0.19272840023040771
Batch 30/64 loss: 0.19549328088760376
Batch 31/64 loss: 0.19251227378845215
Batch 32/64 loss: 0.17738670110702515
Batch 33/64 loss: 0.18438845872879028
Batch 34/64 loss: 0.1819303035736084
Batch 35/64 loss: 0.19329005479812622
Batch 36/64 loss: 0.20260459184646606
Batch 37/64 loss: 0.2021968960762024
Batch 38/64 loss: 0.19284963607788086
Batch 39/64 loss: 0.1941576600074768
Batch 40/64 loss: 0.19966161251068115
Batch 41/64 loss: 0.21079200506210327
Batch 42/64 loss: 0.20951318740844727
Batch 43/64 loss: 0.20472484827041626
Batch 44/64 loss: 0.19410324096679688
Batch 45/64 loss: 0.19181597232818604
Batch 46/64 loss: 0.19557547569274902
Batch 47/64 loss: 0.19810384511947632
Batch 48/64 loss: 0.1885230541229248
Batch 49/64 loss: 0.20250475406646729
Batch 50/64 loss: 0.19190102815628052
Batch 51/64 loss: 0.19155597686767578
Batch 52/64 loss: 0.18518412113189697
Batch 53/64 loss: 0.2032637596130371
Batch 54/64 loss: 0.1988285779953003
Batch 55/64 loss: 0.18846523761749268
Batch 56/64 loss: 0.2044159173965454
Batch 57/64 loss: 0.1968439221382141
Batch 58/64 loss: 0.19140589237213135
Batch 59/64 loss: 0.1896038055419922
Batch 60/64 loss: 0.19122081995010376
Batch 61/64 loss: 0.20049738883972168
Batch 62/64 loss: 0.19699609279632568
Batch 63/64 loss: 0.2101660966873169
Batch 64/64 loss: 0.20079851150512695
Epoch 408  Train loss: 0.19600277134016447  Val loss: 0.29753163815363987
Epoch 409
-------------------------------
Batch 1/64 loss: 0.18938851356506348
Batch 2/64 loss: 0.19367778301239014
Batch 3/64 loss: 0.18176108598709106
Batch 4/64 loss: 0.19825226068496704
Batch 5/64 loss: 0.1910332441329956
Batch 6/64 loss: 0.19122517108917236
Batch 7/64 loss: 0.19003528356552124
Batch 8/64 loss: 0.1907384991645813
Batch 9/64 loss: 0.20118272304534912
Batch 10/64 loss: 0.2046579122543335
Batch 11/64 loss: 0.1999514102935791
Batch 12/64 loss: 0.18226051330566406
Batch 13/64 loss: 0.20411914587020874
Batch 14/64 loss: 0.1992892026901245
Batch 15/64 loss: 0.19754111766815186
Batch 16/64 loss: 0.19971716403961182
Batch 17/64 loss: 0.2023618221282959
Batch 18/64 loss: 0.19566231966018677
Batch 19/64 loss: 0.20117652416229248
Batch 20/64 loss: 0.2028321623802185
Batch 21/64 loss: 0.19904595613479614
Batch 22/64 loss: 0.20119237899780273
Batch 23/64 loss: 0.19798684120178223
Batch 24/64 loss: 0.20108872652053833
Batch 25/64 loss: 0.19480419158935547
Batch 26/64 loss: 0.1932079792022705
Batch 27/64 loss: 0.18929564952850342
Batch 28/64 loss: 0.20410382747650146
Batch 29/64 loss: 0.1937834620475769
Batch 30/64 loss: 0.18177086114883423
Batch 31/64 loss: 0.18739807605743408
Batch 32/64 loss: 0.19541412591934204
Batch 33/64 loss: 0.18657910823822021
Batch 34/64 loss: 0.19101160764694214
Batch 35/64 loss: 0.19486236572265625
Batch 36/64 loss: 0.19681692123413086
Batch 37/64 loss: 0.19580495357513428
Batch 38/64 loss: 0.20760780572891235
Batch 39/64 loss: 0.200484037399292
Batch 40/64 loss: 0.212121844291687
Batch 41/64 loss: 0.19804316759109497
Batch 42/64 loss: 0.20530343055725098
Batch 43/64 loss: 0.18781113624572754
Batch 44/64 loss: 0.21044272184371948
Batch 45/64 loss: 0.19418513774871826
Batch 46/64 loss: 0.18790143728256226
Batch 47/64 loss: 0.19127899408340454
Batch 48/64 loss: 0.19187414646148682
Batch 49/64 loss: 0.1911751627922058
Batch 50/64 loss: 0.19444644451141357
Batch 51/64 loss: 0.18335294723510742
Batch 52/64 loss: 0.19215142726898193
Batch 53/64 loss: 0.19460290670394897
Batch 54/64 loss: 0.1956416368484497
Batch 55/64 loss: 0.20684564113616943
Batch 56/64 loss: 0.20133084058761597
Batch 57/64 loss: 0.2121412754058838
Batch 58/64 loss: 0.2054218053817749
Batch 59/64 loss: 0.19566243886947632
Batch 60/64 loss: 0.20054709911346436
Batch 61/64 loss: 0.19539868831634521
Batch 62/64 loss: 0.1956120729446411
Batch 63/64 loss: 0.19674766063690186
Batch 64/64 loss: 0.19802868366241455
Epoch 409  Train loss: 0.1963558323243085  Val loss: 0.29823941279113086
Epoch 410
-------------------------------
Batch 1/64 loss: 0.2114735245704651
Batch 2/64 loss: 0.18798387050628662
Batch 3/64 loss: 0.1999855637550354
Batch 4/64 loss: 0.21057718992233276
Batch 5/64 loss: 0.1921004056930542
Batch 6/64 loss: 0.19029450416564941
Batch 7/64 loss: 0.19460201263427734
Batch 8/64 loss: 0.19308972358703613
Batch 9/64 loss: 0.19442611932754517
Batch 10/64 loss: 0.21327650547027588
Batch 11/64 loss: 0.1925419569015503
Batch 12/64 loss: 0.2075202465057373
Batch 13/64 loss: 0.20974242687225342
Batch 14/64 loss: 0.19416844844818115
Batch 15/64 loss: 0.1853097677230835
Batch 16/64 loss: 0.18716853857040405
Batch 17/64 loss: 0.19919061660766602
Batch 18/64 loss: 0.19272112846374512
Batch 19/64 loss: 0.19589722156524658
Batch 20/64 loss: 0.21583718061447144
Batch 21/64 loss: 0.20437252521514893
Batch 22/64 loss: 0.19749420881271362
Batch 23/64 loss: 0.19788217544555664
Batch 24/64 loss: 0.19540166854858398
Batch 25/64 loss: 0.20212209224700928
Batch 26/64 loss: 0.1959691047668457
Batch 27/64 loss: 0.20178961753845215
Batch 28/64 loss: 0.192482590675354
Batch 29/64 loss: 0.18672049045562744
Batch 30/64 loss: 0.19114458560943604
Batch 31/64 loss: 0.20017766952514648
Batch 32/64 loss: 0.19251489639282227
Batch 33/64 loss: 0.19245946407318115
Batch 34/64 loss: 0.1846427321434021
Batch 35/64 loss: 0.193353533744812
Batch 36/64 loss: 0.19151777029037476
Batch 37/64 loss: 0.19884967803955078
Batch 38/64 loss: 0.19955480098724365
Batch 39/64 loss: 0.1937023401260376
Batch 40/64 loss: 0.18378472328186035
Batch 41/64 loss: 0.19316315650939941
Batch 42/64 loss: 0.19229167699813843
Batch 43/64 loss: 0.1939677596092224
Batch 44/64 loss: 0.19544172286987305
Batch 45/64 loss: 0.20405638217926025
Batch 46/64 loss: 0.19196712970733643
Batch 47/64 loss: 0.19033533334732056
Batch 48/64 loss: 0.20183956623077393
Batch 49/64 loss: 0.190993070602417
Batch 50/64 loss: 0.21150076389312744
Batch 51/64 loss: 0.1972598433494568
Batch 52/64 loss: 0.19215595722198486
Batch 53/64 loss: 0.19371986389160156
Batch 54/64 loss: 0.20892763137817383
Batch 55/64 loss: 0.19516348838806152
Batch 56/64 loss: 0.1989825963973999
Batch 57/64 loss: 0.20122665166854858
Batch 58/64 loss: 0.1980920433998108
Batch 59/64 loss: 0.19105106592178345
Batch 60/64 loss: 0.20545542240142822
Batch 61/64 loss: 0.1939389705657959
Batch 62/64 loss: 0.1964787244796753
Batch 63/64 loss: 0.19744223356246948
Batch 64/64 loss: 0.2052696943283081
Epoch 410  Train loss: 0.1969136775708666  Val loss: 0.29737998202084676
Epoch 411
-------------------------------
Batch 1/64 loss: 0.19879311323165894
Batch 2/64 loss: 0.1911766529083252
Batch 3/64 loss: 0.19006353616714478
Batch 4/64 loss: 0.19895035028457642
Batch 5/64 loss: 0.1975664496421814
Batch 6/64 loss: 0.1885596513748169
Batch 7/64 loss: 0.20259547233581543
Batch 8/64 loss: 0.19662034511566162
Batch 9/64 loss: 0.20913422107696533
Batch 10/64 loss: 0.19226282835006714
Batch 11/64 loss: 0.1893613338470459
Batch 12/64 loss: 0.19013619422912598
Batch 13/64 loss: 0.195098876953125
Batch 14/64 loss: 0.1945863962173462
Batch 15/64 loss: 0.20438164472579956
Batch 16/64 loss: 0.1959376335144043
Batch 17/64 loss: 0.1932341456413269
Batch 18/64 loss: 0.19567906856536865
Batch 19/64 loss: 0.20090973377227783
Batch 20/64 loss: 0.2056751251220703
Batch 21/64 loss: 0.20403993129730225
Batch 22/64 loss: 0.20384466648101807
Batch 23/64 loss: 0.19256192445755005
Batch 24/64 loss: 0.19118952751159668
Batch 25/64 loss: 0.21490108966827393
Batch 26/64 loss: 0.19710969924926758
Batch 27/64 loss: 0.18986237049102783
Batch 28/64 loss: 0.19051200151443481
Batch 29/64 loss: 0.1844937801361084
Batch 30/64 loss: 0.1901073455810547
Batch 31/64 loss: 0.20123648643493652
Batch 32/64 loss: 0.19030767679214478
Batch 33/64 loss: 0.19684958457946777
Batch 34/64 loss: 0.1887410283088684
Batch 35/64 loss: 0.18751293420791626
Batch 36/64 loss: 0.19227617979049683
Batch 37/64 loss: 0.1901923418045044
Batch 38/64 loss: 0.19159162044525146
Batch 39/64 loss: 0.19045835733413696
Batch 40/64 loss: 0.19318640232086182
Batch 41/64 loss: 0.19899892807006836
Batch 42/64 loss: 0.20528548955917358
Batch 43/64 loss: 0.20303553342819214
Batch 44/64 loss: 0.1970958113670349
Batch 45/64 loss: 0.19639170169830322
Batch 46/64 loss: 0.2049320936203003
Batch 47/64 loss: 0.19101965427398682
Batch 48/64 loss: 0.191003680229187
Batch 49/64 loss: 0.20891743898391724
Batch 50/64 loss: 0.18799495697021484
Batch 51/64 loss: 0.19690155982971191
Batch 52/64 loss: 0.20018762350082397
Batch 53/64 loss: 0.1956017017364502
Batch 54/64 loss: 0.1975710391998291
Batch 55/64 loss: 0.18827790021896362
Batch 56/64 loss: 0.18783438205718994
Batch 57/64 loss: 0.1906229853630066
Batch 58/64 loss: 0.19039267301559448
Batch 59/64 loss: 0.18793612718582153
Batch 60/64 loss: 0.19478541612625122
Batch 61/64 loss: 0.19403982162475586
Batch 62/64 loss: 0.18929797410964966
Batch 63/64 loss: 0.1952533721923828
Batch 64/64 loss: 0.19194555282592773
Epoch 411  Train loss: 0.1952789764778287  Val loss: 0.2967489179467008
Epoch 412
-------------------------------
Batch 1/64 loss: 0.1991497278213501
Batch 2/64 loss: 0.19130396842956543
Batch 3/64 loss: 0.18907701969146729
Batch 4/64 loss: 0.19046950340270996
Batch 5/64 loss: 0.18982595205307007
Batch 6/64 loss: 0.196478009223938
Batch 7/64 loss: 0.20162159204483032
Batch 8/64 loss: 0.2046239972114563
Batch 9/64 loss: 0.20312273502349854
Batch 10/64 loss: 0.20154523849487305
Batch 11/64 loss: 0.19805771112442017
Batch 12/64 loss: 0.1990511417388916
Batch 13/64 loss: 0.18652808666229248
Batch 14/64 loss: 0.19418132305145264
Batch 15/64 loss: 0.19536340236663818
Batch 16/64 loss: 0.2033843994140625
Batch 17/64 loss: 0.18581879138946533
Batch 18/64 loss: 0.19527441263198853
Batch 19/64 loss: 0.19338321685791016
Batch 20/64 loss: 0.19268685579299927
Batch 21/64 loss: 0.19286572933197021
Batch 22/64 loss: 0.1949697732925415
Batch 23/64 loss: 0.19169795513153076
Batch 24/64 loss: 0.19639909267425537
Batch 25/64 loss: 0.1976909637451172
Batch 26/64 loss: 0.204470694065094
Batch 27/64 loss: 0.19773328304290771
Batch 28/64 loss: 0.19583892822265625
Batch 29/64 loss: 0.20566093921661377
Batch 30/64 loss: 0.1919093132019043
Batch 31/64 loss: 0.20407378673553467
Batch 32/64 loss: 0.2022252082824707
Batch 33/64 loss: 0.18703722953796387
Batch 34/64 loss: 0.18956196308135986
Batch 35/64 loss: 0.1937151551246643
Batch 36/64 loss: 0.1934729814529419
Batch 37/64 loss: 0.20027434825897217
Batch 38/64 loss: 0.1970055103302002
Batch 39/64 loss: 0.19500267505645752
Batch 40/64 loss: 0.20042496919631958
Batch 41/64 loss: 0.19756370782852173
Batch 42/64 loss: 0.19954955577850342
Batch 43/64 loss: 0.1981945037841797
Batch 44/64 loss: 0.19582295417785645
Batch 45/64 loss: 0.19551891088485718
Batch 46/64 loss: 0.1912679672241211
Batch 47/64 loss: 0.19890356063842773
Batch 48/64 loss: 0.20202434062957764
Batch 49/64 loss: 0.20209109783172607
Batch 50/64 loss: 0.19669044017791748
Batch 51/64 loss: 0.19870346784591675
Batch 52/64 loss: 0.1910496950149536
Batch 53/64 loss: 0.1868574023246765
Batch 54/64 loss: 0.19137698411941528
Batch 55/64 loss: 0.18788063526153564
Batch 56/64 loss: 0.1872677206993103
Batch 57/64 loss: 0.19163137674331665
Batch 58/64 loss: 0.19730281829833984
Batch 59/64 loss: 0.18248355388641357
Batch 60/64 loss: 0.18966007232666016
Batch 61/64 loss: 0.19497746229171753
Batch 62/64 loss: 0.1941012740135193
Batch 63/64 loss: 0.2010132074356079
Batch 64/64 loss: 0.1947023868560791
Epoch 412  Train loss: 0.19546567972968606  Val loss: 0.2975661596891397
Epoch 413
-------------------------------
Batch 1/64 loss: 0.19006526470184326
Batch 2/64 loss: 0.19858086109161377
Batch 3/64 loss: 0.20336639881134033
Batch 4/64 loss: 0.18041396141052246
Batch 5/64 loss: 0.18408113718032837
Batch 6/64 loss: 0.1878964900970459
Batch 7/64 loss: 0.1935519576072693
Batch 8/64 loss: 0.21645069122314453
Batch 9/64 loss: 0.19672930240631104
Batch 10/64 loss: 0.18580836057662964
Batch 11/64 loss: 0.20160913467407227
Batch 12/64 loss: 0.2022639513015747
Batch 13/64 loss: 0.19599157571792603
Batch 14/64 loss: 0.2024340033531189
Batch 15/64 loss: 0.1975744366645813
Batch 16/64 loss: 0.18914192914962769
Batch 17/64 loss: 0.19217419624328613
Batch 18/64 loss: 0.19069135189056396
Batch 19/64 loss: 0.2035207748413086
Batch 20/64 loss: 0.19496726989746094
Batch 21/64 loss: 0.1838098168373108
Batch 22/64 loss: 0.19145721197128296
Batch 23/64 loss: 0.20472562313079834
Batch 24/64 loss: 0.19545942544937134
Batch 25/64 loss: 0.19511014223098755
Batch 26/64 loss: 0.19722217321395874
Batch 27/64 loss: 0.19485127925872803
Batch 28/64 loss: 0.19564038515090942
Batch 29/64 loss: 0.20256567001342773
Batch 30/64 loss: 0.19016796350479126
Batch 31/64 loss: 0.20642542839050293
Batch 32/64 loss: 0.19784843921661377
Batch 33/64 loss: 0.19904452562332153
Batch 34/64 loss: 0.19752293825149536
Batch 35/64 loss: 0.21032679080963135
Batch 36/64 loss: 0.20743072032928467
Batch 37/64 loss: 0.19044959545135498
Batch 38/64 loss: 0.1911323070526123
Batch 39/64 loss: 0.20348572731018066
Batch 40/64 loss: 0.19072550535202026
Batch 41/64 loss: 0.19411879777908325
Batch 42/64 loss: 0.1921999454498291
Batch 43/64 loss: 0.18870025873184204
Batch 44/64 loss: 0.19491499662399292
Batch 45/64 loss: 0.2065027356147766
Batch 46/64 loss: 0.2039419412612915
Batch 47/64 loss: 0.19417059421539307
Batch 48/64 loss: 0.19225943088531494
Batch 49/64 loss: 0.19224870204925537
Batch 50/64 loss: 0.18966186046600342
Batch 51/64 loss: 0.20313090085983276
Batch 52/64 loss: 0.18976545333862305
Batch 53/64 loss: 0.20259714126586914
Batch 54/64 loss: 0.19603854417800903
Batch 55/64 loss: 0.1924101710319519
Batch 56/64 loss: 0.199487566947937
Batch 57/64 loss: 0.1910257339477539
Batch 58/64 loss: 0.19328784942626953
Batch 59/64 loss: 0.1928236484527588
Batch 60/64 loss: 0.20018494129180908
Batch 61/64 loss: 0.1863473653793335
Batch 62/64 loss: 0.19301563501358032
Batch 63/64 loss: 0.20123302936553955
Batch 64/64 loss: 0.19583308696746826
Epoch 413  Train loss: 0.19591618472454594  Val loss: 0.2978191486338979
Epoch 414
-------------------------------
Batch 1/64 loss: 0.19480234384536743
Batch 2/64 loss: 0.1885240077972412
Batch 3/64 loss: 0.19695883989334106
Batch 4/64 loss: 0.19019871950149536
Batch 5/64 loss: 0.19200140237808228
Batch 6/64 loss: 0.1925950050354004
Batch 7/64 loss: 0.19779080152511597
Batch 8/64 loss: 0.18855059146881104
Batch 9/64 loss: 0.20123648643493652
Batch 10/64 loss: 0.19263982772827148
Batch 11/64 loss: 0.19746315479278564
Batch 12/64 loss: 0.19451820850372314
Batch 13/64 loss: 0.20301580429077148
Batch 14/64 loss: 0.19579488039016724
Batch 15/64 loss: 0.18717020750045776
Batch 16/64 loss: 0.1926148533821106
Batch 17/64 loss: 0.1870332956314087
Batch 18/64 loss: 0.196616530418396
Batch 19/64 loss: 0.1989351511001587
Batch 20/64 loss: 0.18541795015335083
Batch 21/64 loss: 0.19406402111053467
Batch 22/64 loss: 0.18335175514221191
Batch 23/64 loss: 0.20427542924880981
Batch 24/64 loss: 0.1970389485359192
Batch 25/64 loss: 0.19618439674377441
Batch 26/64 loss: 0.1894431710243225
Batch 27/64 loss: 0.2051294445991516
Batch 28/64 loss: 0.20120012760162354
Batch 29/64 loss: 0.21783334016799927
Batch 30/64 loss: 0.19841748476028442
Batch 31/64 loss: 0.19830387830734253
Batch 32/64 loss: 0.20564043521881104
Batch 33/64 loss: 0.2075589895248413
Batch 34/64 loss: 0.18927812576293945
Batch 35/64 loss: 0.19437956809997559
Batch 36/64 loss: 0.19296997785568237
Batch 37/64 loss: 0.18898028135299683
Batch 38/64 loss: 0.1928708553314209
Batch 39/64 loss: 0.20234167575836182
Batch 40/64 loss: 0.19196557998657227
Batch 41/64 loss: 0.19675523042678833
Batch 42/64 loss: 0.18841958045959473
Batch 43/64 loss: 0.19257628917694092
Batch 44/64 loss: 0.2000751495361328
Batch 45/64 loss: 0.19519388675689697
Batch 46/64 loss: 0.2086869478225708
Batch 47/64 loss: 0.20515453815460205
Batch 48/64 loss: 0.1936115026473999
Batch 49/64 loss: 0.19687938690185547
Batch 50/64 loss: 0.18978732824325562
Batch 51/64 loss: 0.1909315586090088
Batch 52/64 loss: 0.1946502923965454
Batch 53/64 loss: 0.21311843395233154
Batch 54/64 loss: 0.19396328926086426
Batch 55/64 loss: 0.1922588348388672
Batch 56/64 loss: 0.1935543417930603
Batch 57/64 loss: 0.19698816537857056
Batch 58/64 loss: 0.19390499591827393
Batch 59/64 loss: 0.18957096338272095
Batch 60/64 loss: 0.18710708618164062
Batch 61/64 loss: 0.20333456993103027
Batch 62/64 loss: 0.19173932075500488
Batch 63/64 loss: 0.19376546144485474
Batch 64/64 loss: 0.20004022121429443
Epoch 414  Train loss: 0.1957202018476  Val loss: 0.2974013061457893
Epoch 415
-------------------------------
Batch 1/64 loss: 0.19222187995910645
Batch 2/64 loss: 0.18264424800872803
Batch 3/64 loss: 0.20125287771224976
Batch 4/64 loss: 0.19508063793182373
Batch 5/64 loss: 0.19794976711273193
Batch 6/64 loss: 0.19618260860443115
Batch 7/64 loss: 0.1872226595878601
Batch 8/64 loss: 0.19644427299499512
Batch 9/64 loss: 0.18973463773727417
Batch 10/64 loss: 0.192438542842865
Batch 11/64 loss: 0.19652330875396729
Batch 12/64 loss: 0.19461560249328613
Batch 13/64 loss: 0.20336395502090454
Batch 14/64 loss: 0.19866955280303955
Batch 15/64 loss: 0.20151937007904053
Batch 16/64 loss: 0.18599438667297363
Batch 17/64 loss: 0.1931166648864746
Batch 18/64 loss: 0.183648943901062
Batch 19/64 loss: 0.19277870655059814
Batch 20/64 loss: 0.18019908666610718
Batch 21/64 loss: 0.17910194396972656
Batch 22/64 loss: 0.1893634796142578
Batch 23/64 loss: 0.2088172435760498
Batch 24/64 loss: 0.19557666778564453
Batch 25/64 loss: 0.20781469345092773
Batch 26/64 loss: 0.1888740062713623
Batch 27/64 loss: 0.2053539752960205
Batch 28/64 loss: 0.2028142213821411
Batch 29/64 loss: 0.18769890069961548
Batch 30/64 loss: 0.1877385377883911
Batch 31/64 loss: 0.20843040943145752
Batch 32/64 loss: 0.1982993483543396
Batch 33/64 loss: 0.20016419887542725
Batch 34/64 loss: 0.20932966470718384
Batch 35/64 loss: 0.18841630220413208
Batch 36/64 loss: 0.20551568269729614
Batch 37/64 loss: 0.19283783435821533
Batch 38/64 loss: 0.200996994972229
Batch 39/64 loss: 0.19739550352096558
Batch 40/64 loss: 0.2007608413696289
Batch 41/64 loss: 0.19078290462493896
Batch 42/64 loss: 0.19795715808868408
Batch 43/64 loss: 0.18757665157318115
Batch 44/64 loss: 0.1889449954032898
Batch 45/64 loss: 0.2031012773513794
Batch 46/64 loss: 0.2077426314353943
Batch 47/64 loss: 0.19885367155075073
Batch 48/64 loss: 0.19536781311035156
Batch 49/64 loss: 0.19327473640441895
Batch 50/64 loss: 0.1851271390914917
Batch 51/64 loss: 0.18333345651626587
Batch 52/64 loss: 0.20363140106201172
Batch 53/64 loss: 0.18986159563064575
Batch 54/64 loss: 0.19967782497406006
Batch 55/64 loss: 0.1920020580291748
Batch 56/64 loss: 0.20090919733047485
Batch 57/64 loss: 0.2052478790283203
Batch 58/64 loss: 0.19485968351364136
Batch 59/64 loss: 0.202359139919281
Batch 60/64 loss: 0.20068198442459106
Batch 61/64 loss: 0.18926715850830078
Batch 62/64 loss: 0.19342899322509766
Batch 63/64 loss: 0.18273192644119263
Batch 64/64 loss: 0.19307148456573486
Epoch 415  Train loss: 0.1952694439420513  Val loss: 0.298402424530475
Epoch 416
-------------------------------
Batch 1/64 loss: 0.19415313005447388
Batch 2/64 loss: 0.2030200958251953
Batch 3/64 loss: 0.19929444789886475
Batch 4/64 loss: 0.19721299409866333
Batch 5/64 loss: 0.18773019313812256
Batch 6/64 loss: 0.20131027698516846
Batch 7/64 loss: 0.19163018465042114
Batch 8/64 loss: 0.1989978551864624
Batch 9/64 loss: 0.19734704494476318
Batch 10/64 loss: 0.19145631790161133
Batch 11/64 loss: 0.19566035270690918
Batch 12/64 loss: 0.19515669345855713
Batch 13/64 loss: 0.18723207712173462
Batch 14/64 loss: 0.20389819145202637
Batch 15/64 loss: 0.20186376571655273
Batch 16/64 loss: 0.18954360485076904
Batch 17/64 loss: 0.19662326574325562
Batch 18/64 loss: 0.20169532299041748
Batch 19/64 loss: 0.1956043243408203
Batch 20/64 loss: 0.19515806436538696
Batch 21/64 loss: 0.19669020175933838
Batch 22/64 loss: 0.18268805742263794
Batch 23/64 loss: 0.19406360387802124
Batch 24/64 loss: 0.1927851438522339
Batch 25/64 loss: 0.18923860788345337
Batch 26/64 loss: 0.189400315284729
Batch 27/64 loss: 0.19287002086639404
Batch 28/64 loss: 0.19823282957077026
Batch 29/64 loss: 0.20398688316345215
Batch 30/64 loss: 0.20177048444747925
Batch 31/64 loss: 0.19566744565963745
Batch 32/64 loss: 0.19128429889678955
Batch 33/64 loss: 0.1816345453262329
Batch 34/64 loss: 0.19662410020828247
Batch 35/64 loss: 0.1892104148864746
Batch 36/64 loss: 0.19133198261260986
Batch 37/64 loss: 0.1996517777442932
Batch 38/64 loss: 0.1901683807373047
Batch 39/64 loss: 0.19173675775527954
Batch 40/64 loss: 0.2017032504081726
Batch 41/64 loss: 0.20166629552841187
Batch 42/64 loss: 0.1974133849143982
Batch 43/64 loss: 0.1893191933631897
Batch 44/64 loss: 0.20429962873458862
Batch 45/64 loss: 0.19347155094146729
Batch 46/64 loss: 0.19078034162521362
Batch 47/64 loss: 0.19134020805358887
Batch 48/64 loss: 0.20317554473876953
Batch 49/64 loss: 0.18282318115234375
Batch 50/64 loss: 0.19834887981414795
Batch 51/64 loss: 0.1914910078048706
Batch 52/64 loss: 0.1932586431503296
Batch 53/64 loss: 0.1969800591468811
Batch 54/64 loss: 0.1943480372428894
Batch 55/64 loss: 0.20321124792099
Batch 56/64 loss: 0.2094936966896057
Batch 57/64 loss: 0.19893360137939453
Batch 58/64 loss: 0.1843312382698059
Batch 59/64 loss: 0.2026100754737854
Batch 60/64 loss: 0.19138574600219727
Batch 61/64 loss: 0.19517827033996582
Batch 62/64 loss: 0.17959988117218018
Batch 63/64 loss: 0.19171178340911865
Batch 64/64 loss: 0.19745570421218872
Epoch 416  Train loss: 0.19495828362072215  Val loss: 0.29745209708656234
Epoch 417
-------------------------------
Batch 1/64 loss: 0.19148725271224976
Batch 2/64 loss: 0.19310301542282104
Batch 3/64 loss: 0.19501715898513794
Batch 4/64 loss: 0.19774961471557617
Batch 5/64 loss: 0.1892993450164795
Batch 6/64 loss: 0.19212108850479126
Batch 7/64 loss: 0.19500970840454102
Batch 8/64 loss: 0.19797056913375854
Batch 9/64 loss: 0.1852658987045288
Batch 10/64 loss: 0.19105923175811768
Batch 11/64 loss: 0.18508434295654297
Batch 12/64 loss: 0.1982749104499817
Batch 13/64 loss: 0.17929506301879883
Batch 14/64 loss: 0.18719804286956787
Batch 15/64 loss: 0.19525617361068726
Batch 16/64 loss: 0.18650317192077637
Batch 17/64 loss: 0.19759798049926758
Batch 18/64 loss: 0.18651705980300903
Batch 19/64 loss: 0.18825334310531616
Batch 20/64 loss: 0.19869863986968994
Batch 21/64 loss: 0.2162262201309204
Batch 22/64 loss: 0.1911056637763977
Batch 23/64 loss: 0.18859994411468506
Batch 24/64 loss: 0.20675158500671387
Batch 25/64 loss: 0.1989954113960266
Batch 26/64 loss: 0.2006893754005432
Batch 27/64 loss: 0.20431363582611084
Batch 28/64 loss: 0.19787222146987915
Batch 29/64 loss: 0.1984691619873047
Batch 30/64 loss: 0.2066330909729004
Batch 31/64 loss: 0.19270044565200806
Batch 32/64 loss: 0.20762312412261963
Batch 33/64 loss: 0.1926732063293457
Batch 34/64 loss: 0.19439125061035156
Batch 35/64 loss: 0.21777725219726562
Batch 36/64 loss: 0.20351701974868774
Batch 37/64 loss: 0.18674349784851074
Batch 38/64 loss: 0.1988002061843872
Batch 39/64 loss: 0.19943225383758545
Batch 40/64 loss: 0.19093120098114014
Batch 41/64 loss: 0.1876164674758911
Batch 42/64 loss: 0.1974506378173828
Batch 43/64 loss: 0.19642925262451172
Batch 44/64 loss: 0.2085355520248413
Batch 45/64 loss: 0.19756382703781128
Batch 46/64 loss: 0.19479024410247803
Batch 47/64 loss: 0.19532090425491333
Batch 48/64 loss: 0.19155919551849365
Batch 49/64 loss: 0.18172192573547363
Batch 50/64 loss: 0.18823623657226562
Batch 51/64 loss: 0.19305634498596191
Batch 52/64 loss: 0.18425017595291138
Batch 53/64 loss: 0.19573044776916504
Batch 54/64 loss: 0.20857489109039307
Batch 55/64 loss: 0.1977112889289856
Batch 56/64 loss: 0.1979060173034668
Batch 57/64 loss: 0.19574761390686035
Batch 58/64 loss: 0.20263731479644775
Batch 59/64 loss: 0.18782973289489746
Batch 60/64 loss: 0.19710034132003784
Batch 61/64 loss: 0.19054484367370605
Batch 62/64 loss: 0.1942157745361328
Batch 63/64 loss: 0.1898697018623352
Batch 64/64 loss: 0.19670897722244263
Epoch 417  Train loss: 0.19524608382991715  Val loss: 0.29823305782993226
Epoch 418
-------------------------------
Batch 1/64 loss: 0.2117767333984375
Batch 2/64 loss: 0.19615089893341064
Batch 3/64 loss: 0.18811488151550293
Batch 4/64 loss: 0.19617271423339844
Batch 5/64 loss: 0.20375394821166992
Batch 6/64 loss: 0.1926683783531189
Batch 7/64 loss: 0.19023072719573975
Batch 8/64 loss: 0.1857682466506958
Batch 9/64 loss: 0.183685302734375
Batch 10/64 loss: 0.17952704429626465
Batch 11/64 loss: 0.1872556209564209
Batch 12/64 loss: 0.19266396760940552
Batch 13/64 loss: 0.18950116634368896
Batch 14/64 loss: 0.18768548965454102
Batch 15/64 loss: 0.18768197298049927
Batch 16/64 loss: 0.20754027366638184
Batch 17/64 loss: 0.20037448406219482
Batch 18/64 loss: 0.194580078125
Batch 19/64 loss: 0.1936185359954834
Batch 20/64 loss: 0.19232714176177979
Batch 21/64 loss: 0.19735205173492432
Batch 22/64 loss: 0.20158880949020386
Batch 23/64 loss: 0.2089177966117859
Batch 24/64 loss: 0.2004106044769287
Batch 25/64 loss: 0.19041693210601807
Batch 26/64 loss: 0.19235312938690186
Batch 27/64 loss: 0.19114166498184204
Batch 28/64 loss: 0.1834927797317505
Batch 29/64 loss: 0.1939382553100586
Batch 30/64 loss: 0.19994044303894043
Batch 31/64 loss: 0.20066457986831665
Batch 32/64 loss: 0.18891775608062744
Batch 33/64 loss: 0.1866965889930725
Batch 34/64 loss: 0.18684107065200806
Batch 35/64 loss: 0.19457077980041504
Batch 36/64 loss: 0.19342303276062012
Batch 37/64 loss: 0.2019110918045044
Batch 38/64 loss: 0.18972152471542358
Batch 39/64 loss: 0.1921982765197754
Batch 40/64 loss: 0.2034149169921875
Batch 41/64 loss: 0.20198583602905273
Batch 42/64 loss: 0.19308453798294067
Batch 43/64 loss: 0.19774222373962402
Batch 44/64 loss: 0.19279897212982178
Batch 45/64 loss: 0.19745391607284546
Batch 46/64 loss: 0.21373134851455688
Batch 47/64 loss: 0.2066887617111206
Batch 48/64 loss: 0.21870702505111694
Batch 49/64 loss: 0.19599109888076782
Batch 50/64 loss: 0.19066238403320312
Batch 51/64 loss: 0.20985066890716553
Batch 52/64 loss: 0.2054484486579895
Batch 53/64 loss: 0.1974838376045227
Batch 54/64 loss: 0.187821626663208
Batch 55/64 loss: 0.20205974578857422
Batch 56/64 loss: 0.1974920630455017
Batch 57/64 loss: 0.19639205932617188
Batch 58/64 loss: 0.1946568489074707
Batch 59/64 loss: 0.19643688201904297
Batch 60/64 loss: 0.19498848915100098
Batch 61/64 loss: 0.19292855262756348
Batch 62/64 loss: 0.1935829520225525
Batch 63/64 loss: 0.1845683455467224
Batch 64/64 loss: 0.2085009217262268
Epoch 418  Train loss: 0.1957321099206513  Val loss: 0.29813054972088215
Epoch 419
-------------------------------
Batch 1/64 loss: 0.19307702779769897
Batch 2/64 loss: 0.19029080867767334
Batch 3/64 loss: 0.18736779689788818
Batch 4/64 loss: 0.18615806102752686
Batch 5/64 loss: 0.18988418579101562
Batch 6/64 loss: 0.17735010385513306
Batch 7/64 loss: 0.200617253780365
Batch 8/64 loss: 0.19945228099822998
Batch 9/64 loss: 0.18758875131607056
Batch 10/64 loss: 0.1802576184272766
Batch 11/64 loss: 0.20245122909545898
Batch 12/64 loss: 0.19395655393600464
Batch 13/64 loss: 0.2003498673439026
Batch 14/64 loss: 0.19552111625671387
Batch 15/64 loss: 0.19564002752304077
Batch 16/64 loss: 0.19568634033203125
Batch 17/64 loss: 0.21879446506500244
Batch 18/64 loss: 0.18928635120391846
Batch 19/64 loss: 0.19724029302597046
Batch 20/64 loss: 0.20103740692138672
Batch 21/64 loss: 0.19606322050094604
Batch 22/64 loss: 0.19181233644485474
Batch 23/64 loss: 0.19386637210845947
Batch 24/64 loss: 0.19677770137786865
Batch 25/64 loss: 0.17939823865890503
Batch 26/64 loss: 0.18813174962997437
Batch 27/64 loss: 0.19326049089431763
Batch 28/64 loss: 0.19976502656936646
Batch 29/64 loss: 0.1832658052444458
Batch 30/64 loss: 0.1939624547958374
Batch 31/64 loss: 0.19562506675720215
Batch 32/64 loss: 0.18854326009750366
Batch 33/64 loss: 0.2148137092590332
Batch 34/64 loss: 0.1830298900604248
Batch 35/64 loss: 0.19607925415039062
Batch 36/64 loss: 0.19174140691757202
Batch 37/64 loss: 0.201940655708313
Batch 38/64 loss: 0.18211132287979126
Batch 39/64 loss: 0.2011702060699463
Batch 40/64 loss: 0.1958378553390503
Batch 41/64 loss: 0.1933685541152954
Batch 42/64 loss: 0.19248652458190918
Batch 43/64 loss: 0.1916266679763794
Batch 44/64 loss: 0.2107142210006714
Batch 45/64 loss: 0.19597327709197998
Batch 46/64 loss: 0.19817912578582764
Batch 47/64 loss: 0.19861149787902832
Batch 48/64 loss: 0.19780796766281128
Batch 49/64 loss: 0.19891881942749023
Batch 50/64 loss: 0.196211040019989
Batch 51/64 loss: 0.19775426387786865
Batch 52/64 loss: 0.19702720642089844
Batch 53/64 loss: 0.20363396406173706
Batch 54/64 loss: 0.19646543264389038
Batch 55/64 loss: 0.1940595507621765
Batch 56/64 loss: 0.18613338470458984
Batch 57/64 loss: 0.19677400588989258
Batch 58/64 loss: 0.19514334201812744
Batch 59/64 loss: 0.18530350923538208
Batch 60/64 loss: 0.19874995946884155
Batch 61/64 loss: 0.19524627923965454
Batch 62/64 loss: 0.19710099697113037
Batch 63/64 loss: 0.19169074296951294
Batch 64/64 loss: 0.19726485013961792
Epoch 419  Train loss: 0.19460600053562838  Val loss: 0.29814798438671936
Epoch 420
-------------------------------
Batch 1/64 loss: 0.19798660278320312
Batch 2/64 loss: 0.19092309474945068
Batch 3/64 loss: 0.18672674894332886
Batch 4/64 loss: 0.19467341899871826
Batch 5/64 loss: 0.20246005058288574
Batch 6/64 loss: 0.20031261444091797
Batch 7/64 loss: 0.19689702987670898
Batch 8/64 loss: 0.19603019952774048
Batch 9/64 loss: 0.18759089708328247
Batch 10/64 loss: 0.1947423219680786
Batch 11/64 loss: 0.19067364931106567
Batch 12/64 loss: 0.19929265975952148
Batch 13/64 loss: 0.18353188037872314
Batch 14/64 loss: 0.18997591733932495
Batch 15/64 loss: 0.20833826065063477
Batch 16/64 loss: 0.19045788049697876
Batch 17/64 loss: 0.1860659122467041
Batch 18/64 loss: 0.20038765668869019
Batch 19/64 loss: 0.1992475986480713
Batch 20/64 loss: 0.19740253686904907
Batch 21/64 loss: 0.1965855360031128
Batch 22/64 loss: 0.19546562433242798
Batch 23/64 loss: 0.19072890281677246
Batch 24/64 loss: 0.1863391399383545
Batch 25/64 loss: 0.194011390209198
Batch 26/64 loss: 0.19509780406951904
Batch 27/64 loss: 0.1978001594543457
Batch 28/64 loss: 0.18671780824661255
Batch 29/64 loss: 0.18674147129058838
Batch 30/64 loss: 0.18415427207946777
Batch 31/64 loss: 0.1828160285949707
Batch 32/64 loss: 0.19812285900115967
Batch 33/64 loss: 0.19570589065551758
Batch 34/64 loss: 0.18912792205810547
Batch 35/64 loss: 0.18362051248550415
Batch 36/64 loss: 0.20402991771697998
Batch 37/64 loss: 0.21084725856781006
Batch 38/64 loss: 0.19563591480255127
Batch 39/64 loss: 0.1972978115081787
Batch 40/64 loss: 0.204700767993927
Batch 41/64 loss: 0.19256854057312012
Batch 42/64 loss: 0.21303009986877441
Batch 43/64 loss: 0.19070827960968018
Batch 44/64 loss: 0.1961601972579956
Batch 45/64 loss: 0.19191908836364746
Batch 46/64 loss: 0.19861209392547607
Batch 47/64 loss: 0.2099224328994751
Batch 48/64 loss: 0.2091130018234253
Batch 49/64 loss: 0.19265639781951904
Batch 50/64 loss: 0.18846410512924194
Batch 51/64 loss: 0.18782347440719604
Batch 52/64 loss: 0.19683104753494263
Batch 53/64 loss: 0.19465172290802002
Batch 54/64 loss: 0.19457173347473145
Batch 55/64 loss: 0.200958251953125
Batch 56/64 loss: 0.20852363109588623
Batch 57/64 loss: 0.19169622659683228
Batch 58/64 loss: 0.1883307695388794
Batch 59/64 loss: 0.19077521562576294
Batch 60/64 loss: 0.20017307996749878
Batch 61/64 loss: 0.19162720441818237
Batch 62/64 loss: 0.19067984819412231
Batch 63/64 loss: 0.20404279232025146
Batch 64/64 loss: 0.19938915967941284
Epoch 420  Train loss: 0.19517874554091807  Val loss: 0.29733492848799403
Epoch 421
-------------------------------
Batch 1/64 loss: 0.20160949230194092
Batch 2/64 loss: 0.18552613258361816
Batch 3/64 loss: 0.18933457136154175
Batch 4/64 loss: 0.19561851024627686
Batch 5/64 loss: 0.2006213665008545
Batch 6/64 loss: 0.19382542371749878
Batch 7/64 loss: 0.19131070375442505
Batch 8/64 loss: 0.20863032341003418
Batch 9/64 loss: 0.19978153705596924
Batch 10/64 loss: 0.19918256998062134
Batch 11/64 loss: 0.1930564045906067
Batch 12/64 loss: 0.19052457809448242
Batch 13/64 loss: 0.18731451034545898
Batch 14/64 loss: 0.18868649005889893
Batch 15/64 loss: 0.1887224316596985
Batch 16/64 loss: 0.1864020824432373
Batch 17/64 loss: 0.18181777000427246
Batch 18/64 loss: 0.1946621537208557
Batch 19/64 loss: 0.19199144840240479
Batch 20/64 loss: 0.1906490921974182
Batch 21/64 loss: 0.18869727849960327
Batch 22/64 loss: 0.19744741916656494
Batch 23/64 loss: 0.20002281665802002
Batch 24/64 loss: 0.1918262243270874
Batch 25/64 loss: 0.192551851272583
Batch 26/64 loss: 0.19315969944000244
Batch 27/64 loss: 0.203590989112854
Batch 28/64 loss: 0.19709569215774536
Batch 29/64 loss: 0.1816716194152832
Batch 30/64 loss: 0.19208431243896484
Batch 31/64 loss: 0.19329780340194702
Batch 32/64 loss: 0.19621354341506958
Batch 33/64 loss: 0.19200420379638672
Batch 34/64 loss: 0.18799972534179688
Batch 35/64 loss: 0.1908736228942871
Batch 36/64 loss: 0.19198095798492432
Batch 37/64 loss: 0.1887286901473999
Batch 38/64 loss: 0.19630801677703857
Batch 39/64 loss: 0.19160199165344238
Batch 40/64 loss: 0.18608170747756958
Batch 41/64 loss: 0.1921866536140442
Batch 42/64 loss: 0.19065076112747192
Batch 43/64 loss: 0.20222413539886475
Batch 44/64 loss: 0.18864911794662476
Batch 45/64 loss: 0.19678658246994019
Batch 46/64 loss: 0.18267738819122314
Batch 47/64 loss: 0.1944926381111145
Batch 48/64 loss: 0.1877613067626953
Batch 49/64 loss: 0.19221162796020508
Batch 50/64 loss: 0.19125986099243164
Batch 51/64 loss: 0.20057833194732666
Batch 52/64 loss: 0.18972432613372803
Batch 53/64 loss: 0.1982463002204895
Batch 54/64 loss: 0.19380426406860352
Batch 55/64 loss: 0.20095449686050415
Batch 56/64 loss: 0.19862020015716553
Batch 57/64 loss: 0.1867358684539795
Batch 58/64 loss: 0.19930988550186157
Batch 59/64 loss: 0.20496344566345215
Batch 60/64 loss: 0.20002472400665283
Batch 61/64 loss: 0.19825029373168945
Batch 62/64 loss: 0.19415199756622314
Batch 63/64 loss: 0.19963586330413818
Batch 64/64 loss: 0.19794297218322754
Epoch 421  Train loss: 0.19364491070018094  Val loss: 0.2976844359918968
Epoch 422
-------------------------------
Batch 1/64 loss: 0.1856616735458374
Batch 2/64 loss: 0.18145012855529785
Batch 3/64 loss: 0.19061285257339478
Batch 4/64 loss: 0.18836450576782227
Batch 5/64 loss: 0.18307888507843018
Batch 6/64 loss: 0.1907615065574646
Batch 7/64 loss: 0.19592469930648804
Batch 8/64 loss: 0.19749730825424194
Batch 9/64 loss: 0.19537198543548584
Batch 10/64 loss: 0.2082458734512329
Batch 11/64 loss: 0.17727071046829224
Batch 12/64 loss: 0.19204354286193848
Batch 13/64 loss: 0.19190800189971924
Batch 14/64 loss: 0.1856400966644287
Batch 15/64 loss: 0.19684052467346191
Batch 16/64 loss: 0.18951374292373657
Batch 17/64 loss: 0.19204503297805786
Batch 18/64 loss: 0.19449400901794434
Batch 19/64 loss: 0.18418020009994507
Batch 20/64 loss: 0.19188165664672852
Batch 21/64 loss: 0.21181952953338623
Batch 22/64 loss: 0.20226448774337769
Batch 23/64 loss: 0.1966707706451416
Batch 24/64 loss: 0.185330331325531
Batch 25/64 loss: 0.1939471960067749
Batch 26/64 loss: 0.20284152030944824
Batch 27/64 loss: 0.20657789707183838
Batch 28/64 loss: 0.18721622228622437
Batch 29/64 loss: 0.1939631700515747
Batch 30/64 loss: 0.1897624135017395
Batch 31/64 loss: 0.1862034797668457
Batch 32/64 loss: 0.1889849305152893
Batch 33/64 loss: 0.20171034336090088
Batch 34/64 loss: 0.20522713661193848
Batch 35/64 loss: 0.21319139003753662
Batch 36/64 loss: 0.21025192737579346
Batch 37/64 loss: 0.20206588506698608
Batch 38/64 loss: 0.1838228702545166
Batch 39/64 loss: 0.19314134120941162
Batch 40/64 loss: 0.19363832473754883
Batch 41/64 loss: 0.19840753078460693
Batch 42/64 loss: 0.19731783866882324
Batch 43/64 loss: 0.18952900171279907
Batch 44/64 loss: 0.20450830459594727
Batch 45/64 loss: 0.20085406303405762
Batch 46/64 loss: 0.2019263505935669
Batch 47/64 loss: 0.2053338885307312
Batch 48/64 loss: 0.19572407007217407
Batch 49/64 loss: 0.185888409614563
Batch 50/64 loss: 0.18462949991226196
Batch 51/64 loss: 0.20747119188308716
Batch 52/64 loss: 0.20277714729309082
Batch 53/64 loss: 0.20892465114593506
Batch 54/64 loss: 0.20357400178909302
Batch 55/64 loss: 0.18417882919311523
Batch 56/64 loss: 0.19740164279937744
Batch 57/64 loss: 0.18887436389923096
Batch 58/64 loss: 0.19842886924743652
Batch 59/64 loss: 0.19659674167633057
Batch 60/64 loss: 0.20428746938705444
Batch 61/64 loss: 0.1891370415687561
Batch 62/64 loss: 0.19262278079986572
Batch 63/64 loss: 0.19188880920410156
Batch 64/64 loss: 0.18823862075805664
Epoch 422  Train loss: 0.19502556183758904  Val loss: 0.2976264732400167
Epoch 423
-------------------------------
Batch 1/64 loss: 0.19712483882904053
Batch 2/64 loss: 0.1855924129486084
Batch 3/64 loss: 0.19237858057022095
Batch 4/64 loss: 0.19731533527374268
Batch 5/64 loss: 0.19792860746383667
Batch 6/64 loss: 0.19630271196365356
Batch 7/64 loss: 0.19341588020324707
Batch 8/64 loss: 0.20747727155685425
Batch 9/64 loss: 0.19585561752319336
Batch 10/64 loss: 0.1884022355079651
Batch 11/64 loss: 0.19498491287231445
Batch 12/64 loss: 0.1890261173248291
Batch 13/64 loss: 0.1907668113708496
Batch 14/64 loss: 0.19713807106018066
Batch 15/64 loss: 0.19282174110412598
Batch 16/64 loss: 0.1958191990852356
Batch 17/64 loss: 0.1910710334777832
Batch 18/64 loss: 0.18421030044555664
Batch 19/64 loss: 0.20262253284454346
Batch 20/64 loss: 0.19219690561294556
Batch 21/64 loss: 0.19669950008392334
Batch 22/64 loss: 0.18374383449554443
Batch 23/64 loss: 0.19537508487701416
Batch 24/64 loss: 0.1816697120666504
Batch 25/64 loss: 0.191783607006073
Batch 26/64 loss: 0.19571852684020996
Batch 27/64 loss: 0.20541691780090332
Batch 28/64 loss: 0.19622617959976196
Batch 29/64 loss: 0.1919969916343689
Batch 30/64 loss: 0.20892608165740967
Batch 31/64 loss: 0.18580704927444458
Batch 32/64 loss: 0.19212579727172852
Batch 33/64 loss: 0.19314545392990112
Batch 34/64 loss: 0.2067365050315857
Batch 35/64 loss: 0.18692100048065186
Batch 36/64 loss: 0.1908799409866333
Batch 37/64 loss: 0.19446444511413574
Batch 38/64 loss: 0.20537108182907104
Batch 39/64 loss: 0.1934923529624939
Batch 40/64 loss: 0.18707406520843506
Batch 41/64 loss: 0.19533109664916992
Batch 42/64 loss: 0.1956232786178589
Batch 43/64 loss: 0.1853761076927185
Batch 44/64 loss: 0.19449067115783691
Batch 45/64 loss: 0.19434982538223267
Batch 46/64 loss: 0.18778711557388306
Batch 47/64 loss: 0.18943917751312256
Batch 48/64 loss: 0.19483327865600586
Batch 49/64 loss: 0.1936013102531433
Batch 50/64 loss: 0.20083457231521606
Batch 51/64 loss: 0.19865179061889648
Batch 52/64 loss: 0.19003713130950928
Batch 53/64 loss: 0.1975560188293457
Batch 54/64 loss: 0.19031131267547607
Batch 55/64 loss: 0.21244841814041138
Batch 56/64 loss: 0.18561625480651855
Batch 57/64 loss: 0.19935816526412964
Batch 58/64 loss: 0.20713472366333008
Batch 59/64 loss: 0.1912553310394287
Batch 60/64 loss: 0.19587749242782593
Batch 61/64 loss: 0.19624042510986328
Batch 62/64 loss: 0.20218658447265625
Batch 63/64 loss: 0.1842581033706665
Batch 64/64 loss: 0.1980089545249939
Epoch 423  Train loss: 0.19446478661368874  Val loss: 0.29714621690540377
Epoch 424
-------------------------------
Batch 1/64 loss: 0.19215798377990723
Batch 2/64 loss: 0.1893022060394287
Batch 3/64 loss: 0.18569737672805786
Batch 4/64 loss: 0.18030953407287598
Batch 5/64 loss: 0.20630419254302979
Batch 6/64 loss: 0.19541674852371216
Batch 7/64 loss: 0.19599270820617676
Batch 8/64 loss: 0.19239729642868042
Batch 9/64 loss: 0.2068278193473816
Batch 10/64 loss: 0.1921519637107849
Batch 11/64 loss: 0.18876171112060547
Batch 12/64 loss: 0.19704455137252808
Batch 13/64 loss: 0.19216632843017578
Batch 14/64 loss: 0.19426113367080688
Batch 15/64 loss: 0.21470344066619873
Batch 16/64 loss: 0.1862359642982483
Batch 17/64 loss: 0.1920323371887207
Batch 18/64 loss: 0.18499362468719482
Batch 19/64 loss: 0.19341802597045898
Batch 20/64 loss: 0.19252032041549683
Batch 21/64 loss: 0.1928257942199707
Batch 22/64 loss: 0.19837456941604614
Batch 23/64 loss: 0.20655620098114014
Batch 24/64 loss: 0.18432360887527466
Batch 25/64 loss: 0.187219500541687
Batch 26/64 loss: 0.19927632808685303
Batch 27/64 loss: 0.18711107969284058
Batch 28/64 loss: 0.19017750024795532
Batch 29/64 loss: 0.1962757110595703
Batch 30/64 loss: 0.20552611351013184
Batch 31/64 loss: 0.18990468978881836
Batch 32/64 loss: 0.19873392581939697
Batch 33/64 loss: 0.2026066780090332
Batch 34/64 loss: 0.20882189273834229
Batch 35/64 loss: 0.1933479905128479
Batch 36/64 loss: 0.1974390745162964
Batch 37/64 loss: 0.1977781057357788
Batch 38/64 loss: 0.18567270040512085
Batch 39/64 loss: 0.20388996601104736
Batch 40/64 loss: 0.18806815147399902
Batch 41/64 loss: 0.19770550727844238
Batch 42/64 loss: 0.19527024030685425
Batch 43/64 loss: 0.20184993743896484
Batch 44/64 loss: 0.19501447677612305
Batch 45/64 loss: 0.19050097465515137
Batch 46/64 loss: 0.19546526670455933
Batch 47/64 loss: 0.20196902751922607
Batch 48/64 loss: 0.20141351222991943
Batch 49/64 loss: 0.1959717869758606
Batch 50/64 loss: 0.19251739978790283
Batch 51/64 loss: 0.18930822610855103
Batch 52/64 loss: 0.19053709506988525
Batch 53/64 loss: 0.1885884404182434
Batch 54/64 loss: 0.1958436369895935
Batch 55/64 loss: 0.21214056015014648
Batch 56/64 loss: 0.18821066617965698
Batch 57/64 loss: 0.1922789216041565
Batch 58/64 loss: 0.2076224684715271
Batch 59/64 loss: 0.19312864542007446
Batch 60/64 loss: 0.19212079048156738
Batch 61/64 loss: 0.19926953315734863
Batch 62/64 loss: 0.18875110149383545
Batch 63/64 loss: 0.1941179633140564
Batch 64/64 loss: 0.20316195487976074
Epoch 424  Train loss: 0.19511517636916217  Val loss: 0.29818477909179897
Epoch 425
-------------------------------
Batch 1/64 loss: 0.18633681535720825
Batch 2/64 loss: 0.19236832857131958
Batch 3/64 loss: 0.19394975900650024
Batch 4/64 loss: 0.21454626321792603
Batch 5/64 loss: 0.18392455577850342
Batch 6/64 loss: 0.21426606178283691
Batch 7/64 loss: 0.1913953423500061
Batch 8/64 loss: 0.20146584510803223
Batch 9/64 loss: 0.19886857271194458
Batch 10/64 loss: 0.20876860618591309
Batch 11/64 loss: 0.1889691948890686
Batch 12/64 loss: 0.1930828094482422
Batch 13/64 loss: 0.19443094730377197
Batch 14/64 loss: 0.18958479166030884
Batch 15/64 loss: 0.1851954460144043
Batch 16/64 loss: 0.19569098949432373
Batch 17/64 loss: 0.1870388388633728
Batch 18/64 loss: 0.18942880630493164
Batch 19/64 loss: 0.18863552808761597
Batch 20/64 loss: 0.19220852851867676
Batch 21/64 loss: 0.20538228750228882
Batch 22/64 loss: 0.20235419273376465
Batch 23/64 loss: 0.2054651975631714
Batch 24/64 loss: 0.18229341506958008
Batch 25/64 loss: 0.20141905546188354
Batch 26/64 loss: 0.18644076585769653
Batch 27/64 loss: 0.2051701545715332
Batch 28/64 loss: 0.19316118955612183
Batch 29/64 loss: 0.19145441055297852
Batch 30/64 loss: 0.191473126411438
Batch 31/64 loss: 0.18801498413085938
Batch 32/64 loss: 0.18995296955108643
Batch 33/64 loss: 0.1920744776725769
Batch 34/64 loss: 0.1925419569015503
Batch 35/64 loss: 0.187874436378479
Batch 36/64 loss: 0.20074093341827393
Batch 37/64 loss: 0.19275903701782227
Batch 38/64 loss: 0.2051692008972168
Batch 39/64 loss: 0.18688929080963135
Batch 40/64 loss: 0.1871923804283142
Batch 41/64 loss: 0.19893288612365723
Batch 42/64 loss: 0.1974145770072937
Batch 43/64 loss: 0.20138132572174072
Batch 44/64 loss: 0.20346015691757202
Batch 45/64 loss: 0.19293838739395142
Batch 46/64 loss: 0.19031798839569092
Batch 47/64 loss: 0.19900363683700562
Batch 48/64 loss: 0.1994532346725464
Batch 49/64 loss: 0.18721067905426025
Batch 50/64 loss: 0.19982337951660156
Batch 51/64 loss: 0.20258867740631104
Batch 52/64 loss: 0.19812381267547607
Batch 53/64 loss: 0.18649297952651978
Batch 54/64 loss: 0.20695745944976807
Batch 55/64 loss: 0.203436017036438
Batch 56/64 loss: 0.197607159614563
Batch 57/64 loss: 0.1911889910697937
Batch 58/64 loss: 0.18284600973129272
Batch 59/64 loss: 0.19302427768707275
Batch 60/64 loss: 0.1898455023765564
Batch 61/64 loss: 0.20871955156326294
Batch 62/64 loss: 0.189156174659729
Batch 63/64 loss: 0.19398707151412964
Batch 64/64 loss: 0.20614677667617798
Epoch 425  Train loss: 0.19523920802509084  Val loss: 0.2984090492487773
Epoch 426
-------------------------------
Batch 1/64 loss: 0.1931833028793335
Batch 2/64 loss: 0.19118893146514893
Batch 3/64 loss: 0.1923130750656128
Batch 4/64 loss: 0.18666374683380127
Batch 5/64 loss: 0.19276726245880127
Batch 6/64 loss: 0.19285345077514648
Batch 7/64 loss: 0.19488346576690674
Batch 8/64 loss: 0.18319666385650635
Batch 9/64 loss: 0.20525974035263062
Batch 10/64 loss: 0.19326812028884888
Batch 11/64 loss: 0.1934438943862915
Batch 12/64 loss: 0.1935514211654663
Batch 13/64 loss: 0.20606780052185059
Batch 14/64 loss: 0.19231116771697998
Batch 15/64 loss: 0.19669562578201294
Batch 16/64 loss: 0.20402169227600098
Batch 17/64 loss: 0.19930708408355713
Batch 18/64 loss: 0.1954917311668396
Batch 19/64 loss: 0.1933332085609436
Batch 20/64 loss: 0.18583357334136963
Batch 21/64 loss: 0.1894434690475464
Batch 22/64 loss: 0.2003117799758911
Batch 23/64 loss: 0.18936806917190552
Batch 24/64 loss: 0.20174658298492432
Batch 25/64 loss: 0.18838560581207275
Batch 26/64 loss: 0.19216597080230713
Batch 27/64 loss: 0.19306468963623047
Batch 28/64 loss: 0.20352816581726074
Batch 29/64 loss: 0.2335524559020996
Batch 30/64 loss: 0.20664817094802856
Batch 31/64 loss: 0.19316178560256958
Batch 32/64 loss: 0.19069570302963257
Batch 33/64 loss: 0.18782198429107666
Batch 34/64 loss: 0.1944568157196045
Batch 35/64 loss: 0.19303500652313232
Batch 36/64 loss: 0.20113897323608398
Batch 37/64 loss: 0.1973070502281189
Batch 38/64 loss: 0.18788141012191772
Batch 39/64 loss: 0.18834173679351807
Batch 40/64 loss: 0.18876123428344727
Batch 41/64 loss: 0.19534194469451904
Batch 42/64 loss: 0.18970227241516113
Batch 43/64 loss: 0.19315510988235474
Batch 44/64 loss: 0.1962728500366211
Batch 45/64 loss: 0.18899059295654297
Batch 46/64 loss: 0.20567798614501953
Batch 47/64 loss: 0.21034717559814453
Batch 48/64 loss: 0.19403910636901855
Batch 49/64 loss: 0.20880126953125
Batch 50/64 loss: 0.19347304105758667
Batch 51/64 loss: 0.2072635293006897
Batch 52/64 loss: 0.19752240180969238
Batch 53/64 loss: 0.2082505226135254
Batch 54/64 loss: 0.18691956996917725
Batch 55/64 loss: 0.2038605809211731
Batch 56/64 loss: 0.1972215175628662
Batch 57/64 loss: 0.20353221893310547
Batch 58/64 loss: 0.19413238763809204
Batch 59/64 loss: 0.20755505561828613
Batch 60/64 loss: 0.19192343950271606
Batch 61/64 loss: 0.19502878189086914
Batch 62/64 loss: 0.1933344006538391
Batch 63/64 loss: 0.1912379264831543
Batch 64/64 loss: 0.19890707731246948
Epoch 426  Train loss: 0.1962229899331635  Val loss: 0.2975582570554465
Epoch 427
-------------------------------
Batch 1/64 loss: 0.19069963693618774
Batch 2/64 loss: 0.1939154863357544
Batch 3/64 loss: 0.1975577473640442
Batch 4/64 loss: 0.2053355574607849
Batch 5/64 loss: 0.19596773386001587
Batch 6/64 loss: 0.1905597448348999
Batch 7/64 loss: 0.19829308986663818
Batch 8/64 loss: 0.18695759773254395
Batch 9/64 loss: 0.18791568279266357
Batch 10/64 loss: 0.18745285272598267
Batch 11/64 loss: 0.20343518257141113
Batch 12/64 loss: 0.17928987741470337
Batch 13/64 loss: 0.1989416480064392
Batch 14/64 loss: 0.19951432943344116
Batch 15/64 loss: 0.18761181831359863
Batch 16/64 loss: 0.19688135385513306
Batch 17/64 loss: 0.18939679861068726
Batch 18/64 loss: 0.19126158952713013
Batch 19/64 loss: 0.18898433446884155
Batch 20/64 loss: 0.20099550485610962
Batch 21/64 loss: 0.1800594925880432
Batch 22/64 loss: 0.1924905776977539
Batch 23/64 loss: 0.20210063457489014
Batch 24/64 loss: 0.1806638240814209
Batch 25/64 loss: 0.19874262809753418
Batch 26/64 loss: 0.20428067445755005
Batch 27/64 loss: 0.19975745677947998
Batch 28/64 loss: 0.19473427534103394
Batch 29/64 loss: 0.18858665227890015
Batch 30/64 loss: 0.19136512279510498
Batch 31/64 loss: 0.18909722566604614
Batch 32/64 loss: 0.1947554349899292
Batch 33/64 loss: 0.19621723890304565
Batch 34/64 loss: 0.18922138214111328
Batch 35/64 loss: 0.19729256629943848
Batch 36/64 loss: 0.1951531171798706
Batch 37/64 loss: 0.19362753629684448
Batch 38/64 loss: 0.18968886137008667
Batch 39/64 loss: 0.18577146530151367
Batch 40/64 loss: 0.19001466035842896
Batch 41/64 loss: 0.19037777185440063
Batch 42/64 loss: 0.20407873392105103
Batch 43/64 loss: 0.18825668096542358
Batch 44/64 loss: 0.18662428855895996
Batch 45/64 loss: 0.18929195404052734
Batch 46/64 loss: 0.18803036212921143
Batch 47/64 loss: 0.19403165578842163
Batch 48/64 loss: 0.19513458013534546
Batch 49/64 loss: 0.18778276443481445
Batch 50/64 loss: 0.19923371076583862
Batch 51/64 loss: 0.19248175621032715
Batch 52/64 loss: 0.18965601921081543
Batch 53/64 loss: 0.2039361596107483
Batch 54/64 loss: 0.21400153636932373
Batch 55/64 loss: 0.18934327363967896
Batch 56/64 loss: 0.1906774640083313
Batch 57/64 loss: 0.18694812059402466
Batch 58/64 loss: 0.19604283571243286
Batch 59/64 loss: 0.18982774019241333
Batch 60/64 loss: 0.20338743925094604
Batch 61/64 loss: 0.19715988636016846
Batch 62/64 loss: 0.19213581085205078
Batch 63/64 loss: 0.19386577606201172
Batch 64/64 loss: 0.20899057388305664
Epoch 427  Train loss: 0.19362568855285645  Val loss: 0.2982682325586011
Epoch 428
-------------------------------
Batch 1/64 loss: 0.19674921035766602
Batch 2/64 loss: 0.18550026416778564
Batch 3/64 loss: 0.18572747707366943
Batch 4/64 loss: 0.18868672847747803
Batch 5/64 loss: 0.19511693716049194
Batch 6/64 loss: 0.1929941177368164
Batch 7/64 loss: 0.19539403915405273
Batch 8/64 loss: 0.2060367465019226
Batch 9/64 loss: 0.19469738006591797
Batch 10/64 loss: 0.20048409700393677
Batch 11/64 loss: 0.18112218379974365
Batch 12/64 loss: 0.18992984294891357
Batch 13/64 loss: 0.21152853965759277
Batch 14/64 loss: 0.19198077917099
Batch 15/64 loss: 0.1858673095703125
Batch 16/64 loss: 0.18120020627975464
Batch 17/64 loss: 0.1874312162399292
Batch 18/64 loss: 0.19375038146972656
Batch 19/64 loss: 0.19431394338607788
Batch 20/64 loss: 0.18371367454528809
Batch 21/64 loss: 0.20326441526412964
Batch 22/64 loss: 0.19843769073486328
Batch 23/64 loss: 0.19265294075012207
Batch 24/64 loss: 0.1884692907333374
Batch 25/64 loss: 0.18612021207809448
Batch 26/64 loss: 0.20402675867080688
Batch 27/64 loss: 0.19457870721817017
Batch 28/64 loss: 0.19648957252502441
Batch 29/64 loss: 0.19694513082504272
Batch 30/64 loss: 0.1971074342727661
Batch 31/64 loss: 0.1936192512512207
Batch 32/64 loss: 0.20629996061325073
Batch 33/64 loss: 0.21732157468795776
Batch 34/64 loss: 0.1970013976097107
Batch 35/64 loss: 0.19087380170822144
Batch 36/64 loss: 0.19539833068847656
Batch 37/64 loss: 0.19834977388381958
Batch 38/64 loss: 0.19663786888122559
Batch 39/64 loss: 0.19874835014343262
Batch 40/64 loss: 0.20475226640701294
Batch 41/64 loss: 0.18764448165893555
Batch 42/64 loss: 0.1930912733078003
Batch 43/64 loss: 0.19200479984283447
Batch 44/64 loss: 0.19600015878677368
Batch 45/64 loss: 0.20151162147521973
Batch 46/64 loss: 0.1945885419845581
Batch 47/64 loss: 0.20723354816436768
Batch 48/64 loss: 0.19581562280654907
Batch 49/64 loss: 0.19136863946914673
Batch 50/64 loss: 0.19506311416625977
Batch 51/64 loss: 0.19264435768127441
Batch 52/64 loss: 0.19814765453338623
Batch 53/64 loss: 0.19880807399749756
Batch 54/64 loss: 0.1896640658378601
Batch 55/64 loss: 0.19391512870788574
Batch 56/64 loss: 0.18394160270690918
Batch 57/64 loss: 0.1792784333229065
Batch 58/64 loss: 0.19019901752471924
Batch 59/64 loss: 0.1957036852836609
Batch 60/64 loss: 0.1835193634033203
Batch 61/64 loss: 0.19130533933639526
Batch 62/64 loss: 0.1869264841079712
Batch 63/64 loss: 0.20450007915496826
Batch 64/64 loss: 0.19698548316955566
Epoch 428  Train loss: 0.19435190593495089  Val loss: 0.2980686000122647
Epoch 429
-------------------------------
Batch 1/64 loss: 0.18793272972106934
Batch 2/64 loss: 0.19686877727508545
Batch 3/64 loss: 0.17905539274215698
Batch 4/64 loss: 0.17733752727508545
Batch 5/64 loss: 0.19627803564071655
Batch 6/64 loss: 0.190871000289917
Batch 7/64 loss: 0.19236570596694946
Batch 8/64 loss: 0.18651437759399414
Batch 9/64 loss: 0.1926729679107666
Batch 10/64 loss: 0.18569207191467285
Batch 11/64 loss: 0.20560097694396973
Batch 12/64 loss: 0.19136017560958862
Batch 13/64 loss: 0.19665104150772095
Batch 14/64 loss: 0.19183683395385742
Batch 15/64 loss: 0.20341205596923828
Batch 16/64 loss: 0.19005829095840454
Batch 17/64 loss: 0.1904367208480835
Batch 18/64 loss: 0.18610268831253052
Batch 19/64 loss: 0.203122079372406
Batch 20/64 loss: 0.18871384859085083
Batch 21/64 loss: 0.19915294647216797
Batch 22/64 loss: 0.18457359075546265
Batch 23/64 loss: 0.19870543479919434
Batch 24/64 loss: 0.18440771102905273
Batch 25/64 loss: 0.19106602668762207
Batch 26/64 loss: 0.19859880208969116
Batch 27/64 loss: 0.20638442039489746
Batch 28/64 loss: 0.19831079244613647
Batch 29/64 loss: 0.1982114315032959
Batch 30/64 loss: 0.19252467155456543
Batch 31/64 loss: 0.19228506088256836
Batch 32/64 loss: 0.1943938136100769
Batch 33/64 loss: 0.19556427001953125
Batch 34/64 loss: 0.1875220537185669
Batch 35/64 loss: 0.19269275665283203
Batch 36/64 loss: 0.18821150064468384
Batch 37/64 loss: 0.1909618377685547
Batch 38/64 loss: 0.19993829727172852
Batch 39/64 loss: 0.1984841227531433
Batch 40/64 loss: 0.1915668249130249
Batch 41/64 loss: 0.19669628143310547
Batch 42/64 loss: 0.19673794507980347
Batch 43/64 loss: 0.18915265798568726
Batch 44/64 loss: 0.19112253189086914
Batch 45/64 loss: 0.19141864776611328
Batch 46/64 loss: 0.19075608253479004
Batch 47/64 loss: 0.1881771683692932
Batch 48/64 loss: 0.18858975172042847
Batch 49/64 loss: 0.2038211226463318
Batch 50/64 loss: 0.20039761066436768
Batch 51/64 loss: 0.21512466669082642
Batch 52/64 loss: 0.18917620182037354
Batch 53/64 loss: 0.18516439199447632
Batch 54/64 loss: 0.1991124153137207
Batch 55/64 loss: 0.20478546619415283
Batch 56/64 loss: 0.2064686417579651
Batch 57/64 loss: 0.1920904517173767
Batch 58/64 loss: 0.20114362239837646
Batch 59/64 loss: 0.19836902618408203
Batch 60/64 loss: 0.18897521495819092
Batch 61/64 loss: 0.1925230622291565
Batch 62/64 loss: 0.19578421115875244
Batch 63/64 loss: 0.1928795576095581
Batch 64/64 loss: 0.2052851915359497
Epoch 429  Train loss: 0.1940214947158215  Val loss: 0.2976469182476555
Epoch 430
-------------------------------
Batch 1/64 loss: 0.1973133087158203
Batch 2/64 loss: 0.18674421310424805
Batch 3/64 loss: 0.19208937883377075
Batch 4/64 loss: 0.19508033990859985
Batch 5/64 loss: 0.187677264213562
Batch 6/64 loss: 0.19754743576049805
Batch 7/64 loss: 0.19515705108642578
Batch 8/64 loss: 0.18549412488937378
Batch 9/64 loss: 0.1899537444114685
Batch 10/64 loss: 0.18865138292312622
Batch 11/64 loss: 0.20070350170135498
Batch 12/64 loss: 0.18308085203170776
Batch 13/64 loss: 0.186937153339386
Batch 14/64 loss: 0.20454871654510498
Batch 15/64 loss: 0.1805151104927063
Batch 16/64 loss: 0.19274306297302246
Batch 17/64 loss: 0.1928737759590149
Batch 18/64 loss: 0.19719815254211426
Batch 19/64 loss: 0.19427239894866943
Batch 20/64 loss: 0.1852952241897583
Batch 21/64 loss: 0.1960429549217224
Batch 22/64 loss: 0.19249176979064941
Batch 23/64 loss: 0.18363499641418457
Batch 24/64 loss: 0.19733566045761108
Batch 25/64 loss: 0.1940901279449463
Batch 26/64 loss: 0.19066625833511353
Batch 27/64 loss: 0.19587063789367676
Batch 28/64 loss: 0.19520628452301025
Batch 29/64 loss: 0.18305420875549316
Batch 30/64 loss: 0.18682461977005005
Batch 31/64 loss: 0.1803666353225708
Batch 32/64 loss: 0.19147449731826782
Batch 33/64 loss: 0.19524705410003662
Batch 34/64 loss: 0.1987849473953247
Batch 35/64 loss: 0.1963145136833191
Batch 36/64 loss: 0.19386661052703857
Batch 37/64 loss: 0.1923617124557495
Batch 38/64 loss: 0.21208959817886353
Batch 39/64 loss: 0.20195496082305908
Batch 40/64 loss: 0.19206756353378296
Batch 41/64 loss: 0.19479715824127197
Batch 42/64 loss: 0.18592602014541626
Batch 43/64 loss: 0.1968158483505249
Batch 44/64 loss: 0.2129393219947815
Batch 45/64 loss: 0.2028418779373169
Batch 46/64 loss: 0.18679141998291016
Batch 47/64 loss: 0.1826704740524292
Batch 48/64 loss: 0.19444286823272705
Batch 49/64 loss: 0.19881200790405273
Batch 50/64 loss: 0.19438064098358154
Batch 51/64 loss: 0.20432662963867188
Batch 52/64 loss: 0.18083328008651733
Batch 53/64 loss: 0.19813740253448486
Batch 54/64 loss: 0.18873298168182373
Batch 55/64 loss: 0.19450390338897705
Batch 56/64 loss: 0.19572627544403076
Batch 57/64 loss: 0.1919146180152893
Batch 58/64 loss: 0.18847566843032837
Batch 59/64 loss: 0.19805669784545898
Batch 60/64 loss: 0.18464338779449463
Batch 61/64 loss: 0.1925784945487976
Batch 62/64 loss: 0.1881568431854248
Batch 63/64 loss: 0.1879568099975586
Batch 64/64 loss: 0.19073396921157837
Epoch 430  Train loss: 0.1928020848947413  Val loss: 0.29799707648680385
Epoch 431
-------------------------------
Batch 1/64 loss: 0.18341416120529175
Batch 2/64 loss: 0.18625378608703613
Batch 3/64 loss: 0.19061225652694702
Batch 4/64 loss: 0.2086789608001709
Batch 5/64 loss: 0.1854853630065918
Batch 6/64 loss: 0.19836348295211792
Batch 7/64 loss: 0.18981468677520752
Batch 8/64 loss: 0.19660109281539917
Batch 9/64 loss: 0.19355285167694092
Batch 10/64 loss: 0.1952359676361084
Batch 11/64 loss: 0.19383776187896729
Batch 12/64 loss: 0.18499445915222168
Batch 13/64 loss: 0.19224309921264648
Batch 14/64 loss: 0.18845361471176147
Batch 15/64 loss: 0.19102805852890015
Batch 16/64 loss: 0.18970543146133423
Batch 17/64 loss: 0.19111430644989014
Batch 18/64 loss: 0.19319957494735718
Batch 19/64 loss: 0.19933784008026123
Batch 20/64 loss: 0.1863393783569336
Batch 21/64 loss: 0.1947600245475769
Batch 22/64 loss: 0.1904417872428894
Batch 23/64 loss: 0.19910120964050293
Batch 24/64 loss: 0.20506054162979126
Batch 25/64 loss: 0.18910831212997437
Batch 26/64 loss: 0.2151566743850708
Batch 27/64 loss: 0.18783801794052124
Batch 28/64 loss: 0.1896287202835083
Batch 29/64 loss: 0.2041386365890503
Batch 30/64 loss: 0.1898600459098816
Batch 31/64 loss: 0.19386792182922363
Batch 32/64 loss: 0.1848788857460022
Batch 33/64 loss: 0.19963860511779785
Batch 34/64 loss: 0.19451642036437988
Batch 35/64 loss: 0.19612419605255127
Batch 36/64 loss: 0.19499003887176514
Batch 37/64 loss: 0.1852913498878479
Batch 38/64 loss: 0.180222749710083
Batch 39/64 loss: 0.19354218244552612
Batch 40/64 loss: 0.19391489028930664
Batch 41/64 loss: 0.19880962371826172
Batch 42/64 loss: 0.1987559199333191
Batch 43/64 loss: 0.19975042343139648
Batch 44/64 loss: 0.1901787519454956
Batch 45/64 loss: 0.18510079383850098
Batch 46/64 loss: 0.1962435245513916
Batch 47/64 loss: 0.19199126958847046
Batch 48/64 loss: 0.1934986114501953
Batch 49/64 loss: 0.19779974222183228
Batch 50/64 loss: 0.18889397382736206
Batch 51/64 loss: 0.19588029384613037
Batch 52/64 loss: 0.1879723072052002
Batch 53/64 loss: 0.19610118865966797
Batch 54/64 loss: 0.1860121488571167
Batch 55/64 loss: 0.20020413398742676
Batch 56/64 loss: 0.18499541282653809
Batch 57/64 loss: 0.19146448373794556
Batch 58/64 loss: 0.18186479806900024
Batch 59/64 loss: 0.20833802223205566
Batch 60/64 loss: 0.18258774280548096
Batch 61/64 loss: 0.1959790587425232
Batch 62/64 loss: 0.1914910078048706
Batch 63/64 loss: 0.21481788158416748
Batch 64/64 loss: 0.18700790405273438
Epoch 431  Train loss: 0.19324446098477233  Val loss: 0.2980766042401291
Epoch 432
-------------------------------
Batch 1/64 loss: 0.1938067078590393
Batch 2/64 loss: 0.1947091817855835
Batch 3/64 loss: 0.19919729232788086
Batch 4/64 loss: 0.20349204540252686
Batch 5/64 loss: 0.1913256049156189
Batch 6/64 loss: 0.1991286277770996
Batch 7/64 loss: 0.19443845748901367
Batch 8/64 loss: 0.19934535026550293
Batch 9/64 loss: 0.18819814920425415
Batch 10/64 loss: 0.197512686252594
Batch 11/64 loss: 0.20026779174804688
Batch 12/64 loss: 0.18470996618270874
Batch 13/64 loss: 0.20272409915924072
Batch 14/64 loss: 0.19468265771865845
Batch 15/64 loss: 0.19149863719940186
Batch 16/64 loss: 0.177839457988739
Batch 17/64 loss: 0.18643802404403687
Batch 18/64 loss: 0.19369453191757202
Batch 19/64 loss: 0.19563180208206177
Batch 20/64 loss: 0.20097100734710693
Batch 21/64 loss: 0.20648646354675293
Batch 22/64 loss: 0.18746542930603027
Batch 23/64 loss: 0.20357203483581543
Batch 24/64 loss: 0.20493650436401367
Batch 25/64 loss: 0.18714678287506104
Batch 26/64 loss: 0.18545591831207275
Batch 27/64 loss: 0.18911224603652954
Batch 28/64 loss: 0.18611574172973633
Batch 29/64 loss: 0.18247932195663452
Batch 30/64 loss: 0.21073651313781738
Batch 31/64 loss: 0.1928877830505371
Batch 32/64 loss: 0.19139796495437622
Batch 33/64 loss: 0.1912904977798462
Batch 34/64 loss: 0.19350045919418335
Batch 35/64 loss: 0.1998499631881714
Batch 36/64 loss: 0.1879834532737732
Batch 37/64 loss: 0.18012863397598267
Batch 38/64 loss: 0.20469999313354492
Batch 39/64 loss: 0.18939900398254395
Batch 40/64 loss: 0.1866275668144226
Batch 41/64 loss: 0.19002443552017212
Batch 42/64 loss: 0.19161522388458252
Batch 43/64 loss: 0.2166668176651001
Batch 44/64 loss: 0.19439935684204102
Batch 45/64 loss: 0.19510245323181152
Batch 46/64 loss: 0.19023817777633667
Batch 47/64 loss: 0.19464755058288574
Batch 48/64 loss: 0.20562392473220825
Batch 49/64 loss: 0.18590658903121948
Batch 50/64 loss: 0.18878406286239624
Batch 51/64 loss: 0.18869203329086304
Batch 52/64 loss: 0.1957147717475891
Batch 53/64 loss: 0.19011306762695312
Batch 54/64 loss: 0.1921250820159912
Batch 55/64 loss: 0.18286776542663574
Batch 56/64 loss: 0.1934298872947693
Batch 57/64 loss: 0.18640297651290894
Batch 58/64 loss: 0.202070951461792
Batch 59/64 loss: 0.1868298053741455
Batch 60/64 loss: 0.1916518211364746
Batch 61/64 loss: 0.20228374004364014
Batch 62/64 loss: 0.20041972398757935
Batch 63/64 loss: 0.1914609670639038
Batch 64/64 loss: 0.20630896091461182
Epoch 432  Train loss: 0.193924506037843  Val loss: 0.2982124381048982
Epoch 433
-------------------------------
Batch 1/64 loss: 0.1856555938720703
Batch 2/64 loss: 0.1919879913330078
Batch 3/64 loss: 0.1941906213760376
Batch 4/64 loss: 0.19851082563400269
Batch 5/64 loss: 0.19194412231445312
Batch 6/64 loss: 0.19261431694030762
Batch 7/64 loss: 0.208227276802063
Batch 8/64 loss: 0.19616299867630005
Batch 9/64 loss: 0.19517099857330322
Batch 10/64 loss: 0.19549334049224854
Batch 11/64 loss: 0.18437820672988892
Batch 12/64 loss: 0.18444591760635376
Batch 13/64 loss: 0.19566607475280762
Batch 14/64 loss: 0.1974366307258606
Batch 15/64 loss: 0.19104892015457153
Batch 16/64 loss: 0.18913275003433228
Batch 17/64 loss: 0.18977981805801392
Batch 18/64 loss: 0.1936160922050476
Batch 19/64 loss: 0.19657182693481445
Batch 20/64 loss: 0.20042431354522705
Batch 21/64 loss: 0.19539284706115723
Batch 22/64 loss: 0.1896650791168213
Batch 23/64 loss: 0.204135000705719
Batch 24/64 loss: 0.20538783073425293
Batch 25/64 loss: 0.20674896240234375
Batch 26/64 loss: 0.18907296657562256
Batch 27/64 loss: 0.19462335109710693
Batch 28/64 loss: 0.18834680318832397
Batch 29/64 loss: 0.1987350583076477
Batch 30/64 loss: 0.1885436773300171
Batch 31/64 loss: 0.1955905556678772
Batch 32/64 loss: 0.20134007930755615
Batch 33/64 loss: 0.19391167163848877
Batch 34/64 loss: 0.20265120267868042
Batch 35/64 loss: 0.19586104154586792
Batch 36/64 loss: 0.19202882051467896
Batch 37/64 loss: 0.19079256057739258
Batch 38/64 loss: 0.18971294164657593
Batch 39/64 loss: 0.1880694031715393
Batch 40/64 loss: 0.18964362144470215
Batch 41/64 loss: 0.18658936023712158
Batch 42/64 loss: 0.20176076889038086
Batch 43/64 loss: 0.18783295154571533
Batch 44/64 loss: 0.19000566005706787
Batch 45/64 loss: 0.18760794401168823
Batch 46/64 loss: 0.19009065628051758
Batch 47/64 loss: 0.1937304139137268
Batch 48/64 loss: 0.20622587203979492
Batch 49/64 loss: 0.19012850522994995
Batch 50/64 loss: 0.19516324996948242
Batch 51/64 loss: 0.20861244201660156
Batch 52/64 loss: 0.19091057777404785
Batch 53/64 loss: 0.18728595972061157
Batch 54/64 loss: 0.1837533712387085
Batch 55/64 loss: 0.19590699672698975
Batch 56/64 loss: 0.2119666337966919
Batch 57/64 loss: 0.19087475538253784
Batch 58/64 loss: 0.20116955041885376
Batch 59/64 loss: 0.18474829196929932
Batch 60/64 loss: 0.18924951553344727
Batch 61/64 loss: 0.20370721817016602
Batch 62/64 loss: 0.18991237878799438
Batch 63/64 loss: 0.19070756435394287
Batch 64/64 loss: 0.20780134201049805
Epoch 433  Train loss: 0.19429809813405954  Val loss: 0.2987061659085382
Epoch 434
-------------------------------
Batch 1/64 loss: 0.19670510292053223
Batch 2/64 loss: 0.19072914123535156
Batch 3/64 loss: 0.18868404626846313
Batch 4/64 loss: 0.1987106204032898
Batch 5/64 loss: 0.18622779846191406
Batch 6/64 loss: 0.19118404388427734
Batch 7/64 loss: 0.21460247039794922
Batch 8/64 loss: 0.19528764486312866
Batch 9/64 loss: 0.1903669834136963
Batch 10/64 loss: 0.19798928499221802
Batch 11/64 loss: 0.18049031496047974
Batch 12/64 loss: 0.19130516052246094
Batch 13/64 loss: 0.19612568616867065
Batch 14/64 loss: 0.1967540979385376
Batch 15/64 loss: 0.19153940677642822
Batch 16/64 loss: 0.19323748350143433
Batch 17/64 loss: 0.18919384479522705
Batch 18/64 loss: 0.1932964324951172
Batch 19/64 loss: 0.1795494556427002
Batch 20/64 loss: 0.19559305906295776
Batch 21/64 loss: 0.18635129928588867
Batch 22/64 loss: 0.19195234775543213
Batch 23/64 loss: 0.19523799419403076
Batch 24/64 loss: 0.19003689289093018
Batch 25/64 loss: 0.19024264812469482
Batch 26/64 loss: 0.1851658821105957
Batch 27/64 loss: 0.18688184022903442
Batch 28/64 loss: 0.18971914052963257
Batch 29/64 loss: 0.20227378606796265
Batch 30/64 loss: 0.19882982969284058
Batch 31/64 loss: 0.17635750770568848
Batch 32/64 loss: 0.18749213218688965
Batch 33/64 loss: 0.1910184621810913
Batch 34/64 loss: 0.19407057762145996
Batch 35/64 loss: 0.19424951076507568
Batch 36/64 loss: 0.1905645728111267
Batch 37/64 loss: 0.20528900623321533
Batch 38/64 loss: 0.20278865098953247
Batch 39/64 loss: 0.20037853717803955
Batch 40/64 loss: 0.19808918237686157
Batch 41/64 loss: 0.18059498071670532
Batch 42/64 loss: 0.21401286125183105
Batch 43/64 loss: 0.1921095848083496
Batch 44/64 loss: 0.18122762441635132
Batch 45/64 loss: 0.1908261775970459
Batch 46/64 loss: 0.19086319208145142
Batch 47/64 loss: 0.19058024883270264
Batch 48/64 loss: 0.18985110521316528
Batch 49/64 loss: 0.19556105136871338
Batch 50/64 loss: 0.1955079436302185
Batch 51/64 loss: 0.20693057775497437
Batch 52/64 loss: 0.19761687517166138
Batch 53/64 loss: 0.20546764135360718
Batch 54/64 loss: 0.19764399528503418
Batch 55/64 loss: 0.1766185760498047
Batch 56/64 loss: 0.18836069107055664
Batch 57/64 loss: 0.18955981731414795
Batch 58/64 loss: 0.19249731302261353
Batch 59/64 loss: 0.19105219841003418
Batch 60/64 loss: 0.21373802423477173
Batch 61/64 loss: 0.20490241050720215
Batch 62/64 loss: 0.18682312965393066
Batch 63/64 loss: 0.19143199920654297
Batch 64/64 loss: 0.19605374336242676
Epoch 434  Train loss: 0.1933392973507152  Val loss: 0.2980278656654751
Epoch 435
-------------------------------
Batch 1/64 loss: 0.18435990810394287
Batch 2/64 loss: 0.19409668445587158
Batch 3/64 loss: 0.18872052431106567
Batch 4/64 loss: 0.1903914213180542
Batch 5/64 loss: 0.19265049695968628
Batch 6/64 loss: 0.20122891664505005
Batch 7/64 loss: 0.1940598487854004
Batch 8/64 loss: 0.20246809720993042
Batch 9/64 loss: 0.19451576471328735
Batch 10/64 loss: 0.18508780002593994
Batch 11/64 loss: 0.1888192892074585
Batch 12/64 loss: 0.18933629989624023
Batch 13/64 loss: 0.19728440046310425
Batch 14/64 loss: 0.18884986639022827
Batch 15/64 loss: 0.2001243233680725
Batch 16/64 loss: 0.19594544172286987
Batch 17/64 loss: 0.20131808519363403
Batch 18/64 loss: 0.19977575540542603
Batch 19/64 loss: 0.18210816383361816
Batch 20/64 loss: 0.19981420040130615
Batch 21/64 loss: 0.20476281642913818
Batch 22/64 loss: 0.20485639572143555
Batch 23/64 loss: 0.19978803396224976
Batch 24/64 loss: 0.19218862056732178
Batch 25/64 loss: 0.2021176815032959
Batch 26/64 loss: 0.19396406412124634
Batch 27/64 loss: 0.20041722059249878
Batch 28/64 loss: 0.19087576866149902
Batch 29/64 loss: 0.19550013542175293
Batch 30/64 loss: 0.18065941333770752
Batch 31/64 loss: 0.1946558952331543
Batch 32/64 loss: 0.1949121356010437
Batch 33/64 loss: 0.19303953647613525
Batch 34/64 loss: 0.2087079882621765
Batch 35/64 loss: 0.18136155605316162
Batch 36/64 loss: 0.1908159852027893
Batch 37/64 loss: 0.19831407070159912
Batch 38/64 loss: 0.18952280282974243
Batch 39/64 loss: 0.18759369850158691
Batch 40/64 loss: 0.1984107494354248
Batch 41/64 loss: 0.19803738594055176
Batch 42/64 loss: 0.19785070419311523
Batch 43/64 loss: 0.1844218373298645
Batch 44/64 loss: 0.19057166576385498
Batch 45/64 loss: 0.20443177223205566
Batch 46/64 loss: 0.1937476396560669
Batch 47/64 loss: 0.18845129013061523
Batch 48/64 loss: 0.18750977516174316
Batch 49/64 loss: 0.18943125009536743
Batch 50/64 loss: 0.1962084174156189
Batch 51/64 loss: 0.19098401069641113
Batch 52/64 loss: 0.19232070446014404
Batch 53/64 loss: 0.19771915674209595
Batch 54/64 loss: 0.18835633993148804
Batch 55/64 loss: 0.1844944953918457
Batch 56/64 loss: 0.19106268882751465
Batch 57/64 loss: 0.20449745655059814
Batch 58/64 loss: 0.19241613149642944
Batch 59/64 loss: 0.19328314065933228
Batch 60/64 loss: 0.19224554300308228
Batch 61/64 loss: 0.19145417213439941
Batch 62/64 loss: 0.19352000951766968
Batch 63/64 loss: 0.20589900016784668
Batch 64/64 loss: 0.19122284650802612
Epoch 435  Train loss: 0.1939725737945706  Val loss: 0.29867028370755644
Epoch 436
-------------------------------
Batch 1/64 loss: 0.20367282629013062
Batch 2/64 loss: 0.18477094173431396
Batch 3/64 loss: 0.1976335644721985
Batch 4/64 loss: 0.1881996989250183
Batch 5/64 loss: 0.19833451509475708
Batch 6/64 loss: 0.21524953842163086
Batch 7/64 loss: 0.19706541299819946
Batch 8/64 loss: 0.18692338466644287
Batch 9/64 loss: 0.19588792324066162
Batch 10/64 loss: 0.19255751371383667
Batch 11/64 loss: 0.194382905960083
Batch 12/64 loss: 0.1948087215423584
Batch 13/64 loss: 0.18553614616394043
Batch 14/64 loss: 0.1943964958190918
Batch 15/64 loss: 0.18882417678833008
Batch 16/64 loss: 0.18707305192947388
Batch 17/64 loss: 0.1869381070137024
Batch 18/64 loss: 0.18789267539978027
Batch 19/64 loss: 0.19965803623199463
Batch 20/64 loss: 0.20800846815109253
Batch 21/64 loss: 0.19862574338912964
Batch 22/64 loss: 0.19833385944366455
Batch 23/64 loss: 0.19132012128829956
Batch 24/64 loss: 0.18933916091918945
Batch 25/64 loss: 0.193567156791687
Batch 26/64 loss: 0.1837264895439148
Batch 27/64 loss: 0.18882471323013306
Batch 28/64 loss: 0.20123964548110962
Batch 29/64 loss: 0.1874651312828064
Batch 30/64 loss: 0.1974913477897644
Batch 31/64 loss: 0.19021129608154297
Batch 32/64 loss: 0.1928091049194336
Batch 33/64 loss: 0.19248533248901367
Batch 34/64 loss: 0.19922322034835815
Batch 35/64 loss: 0.19752681255340576
Batch 36/64 loss: 0.19352972507476807
Batch 37/64 loss: 0.1910151243209839
Batch 38/64 loss: 0.19724369049072266
Batch 39/64 loss: 0.20154213905334473
Batch 40/64 loss: 0.18882393836975098
Batch 41/64 loss: 0.19886082410812378
Batch 42/64 loss: 0.20369648933410645
Batch 43/64 loss: 0.1934220790863037
Batch 44/64 loss: 0.19393014907836914
Batch 45/64 loss: 0.19627583026885986
Batch 46/64 loss: 0.18759673833847046
Batch 47/64 loss: 0.19647961854934692
Batch 48/64 loss: 0.1882878541946411
Batch 49/64 loss: 0.19877302646636963
Batch 50/64 loss: 0.18715983629226685
Batch 51/64 loss: 0.18715333938598633
Batch 52/64 loss: 0.18726485967636108
Batch 53/64 loss: 0.1844359040260315
Batch 54/64 loss: 0.1895197629928589
Batch 55/64 loss: 0.19396686553955078
Batch 56/64 loss: 0.1869928240776062
Batch 57/64 loss: 0.1986527442932129
Batch 58/64 loss: 0.18545609712600708
Batch 59/64 loss: 0.1944493055343628
Batch 60/64 loss: 0.18670135736465454
Batch 61/64 loss: 0.1875603199005127
Batch 62/64 loss: 0.18629729747772217
Batch 63/64 loss: 0.19686537981033325
Batch 64/64 loss: 0.20548152923583984
Epoch 436  Train loss: 0.19335007854536468  Val loss: 0.2986613958561953
Epoch 437
-------------------------------
Batch 1/64 loss: 0.20338797569274902
Batch 2/64 loss: 0.19003045558929443
Batch 3/64 loss: 0.2025521993637085
Batch 4/64 loss: 0.19110935926437378
Batch 5/64 loss: 0.18526095151901245
Batch 6/64 loss: 0.18730539083480835
Batch 7/64 loss: 0.20402276515960693
Batch 8/64 loss: 0.19836729764938354
Batch 9/64 loss: 0.20027375221252441
Batch 10/64 loss: 0.18541806936264038
Batch 11/64 loss: 0.1964026689529419
Batch 12/64 loss: 0.19393110275268555
Batch 13/64 loss: 0.21274018287658691
Batch 14/64 loss: 0.19432103633880615
Batch 15/64 loss: 0.18765127658843994
Batch 16/64 loss: 0.19026726484298706
Batch 17/64 loss: 0.19385385513305664
Batch 18/64 loss: 0.19013309478759766
Batch 19/64 loss: 0.19673168659210205
Batch 20/64 loss: 0.2023133635520935
Batch 21/64 loss: 0.18951940536499023
Batch 22/64 loss: 0.19028335809707642
Batch 23/64 loss: 0.19371086359024048
Batch 24/64 loss: 0.1891770362854004
Batch 25/64 loss: 0.1821499466896057
Batch 26/64 loss: 0.18972373008728027
Batch 27/64 loss: 0.18523669242858887
Batch 28/64 loss: 0.1994122862815857
Batch 29/64 loss: 0.19272202253341675
Batch 30/64 loss: 0.1981026530265808
Batch 31/64 loss: 0.18350934982299805
Batch 32/64 loss: 0.18577545881271362
Batch 33/64 loss: 0.18537527322769165
Batch 34/64 loss: 0.2026461362838745
Batch 35/64 loss: 0.2111901044845581
Batch 36/64 loss: 0.2020552158355713
Batch 37/64 loss: 0.19154596328735352
Batch 38/64 loss: 0.19964319467544556
Batch 39/64 loss: 0.20573925971984863
Batch 40/64 loss: 0.1863926649093628
Batch 41/64 loss: 0.1907159686088562
Batch 42/64 loss: 0.18809324502944946
Batch 43/64 loss: 0.1844152808189392
Batch 44/64 loss: 0.19390881061553955
Batch 45/64 loss: 0.19094794988632202
Batch 46/64 loss: 0.19665658473968506
Batch 47/64 loss: 0.18193954229354858
Batch 48/64 loss: 0.19695228338241577
Batch 49/64 loss: 0.1840200424194336
Batch 50/64 loss: 0.1876760721206665
Batch 51/64 loss: 0.19171708822250366
Batch 52/64 loss: 0.19849228858947754
Batch 53/64 loss: 0.19150972366333008
Batch 54/64 loss: 0.20158684253692627
Batch 55/64 loss: 0.19026535749435425
Batch 56/64 loss: 0.20706230401992798
Batch 57/64 loss: 0.2056952714920044
Batch 58/64 loss: 0.19257938861846924
Batch 59/64 loss: 0.18596148490905762
Batch 60/64 loss: 0.1848595142364502
Batch 61/64 loss: 0.18837356567382812
Batch 62/64 loss: 0.1990954875946045
Batch 63/64 loss: 0.1949911117553711
Batch 64/64 loss: 0.20673227310180664
Epoch 437  Train loss: 0.19376547102834665  Val loss: 0.2985404180906892
Epoch 438
-------------------------------
Batch 1/64 loss: 0.19250506162643433
Batch 2/64 loss: 0.18518292903900146
Batch 3/64 loss: 0.19482940435409546
Batch 4/64 loss: 0.20696961879730225
Batch 5/64 loss: 0.19622474908828735
Batch 6/64 loss: 0.20647931098937988
Batch 7/64 loss: 0.18358981609344482
Batch 8/64 loss: 0.20448005199432373
Batch 9/64 loss: 0.18636775016784668
Batch 10/64 loss: 0.18953090906143188
Batch 11/64 loss: 0.19027161598205566
Batch 12/64 loss: 0.18564611673355103
Batch 13/64 loss: 0.18718141317367554
Batch 14/64 loss: 0.19054198265075684
Batch 15/64 loss: 0.18886947631835938
Batch 16/64 loss: 0.18917572498321533
Batch 17/64 loss: 0.19257748126983643
Batch 18/64 loss: 0.1987013816833496
Batch 19/64 loss: 0.1899702548980713
Batch 20/64 loss: 0.18676221370697021
Batch 21/64 loss: 0.19303923845291138
Batch 22/64 loss: 0.18095511198043823
Batch 23/64 loss: 0.1924188733100891
Batch 24/64 loss: 0.2019054889678955
Batch 25/64 loss: 0.19340604543685913
Batch 26/64 loss: 0.19570553302764893
Batch 27/64 loss: 0.19650179147720337
Batch 28/64 loss: 0.19088023900985718
Batch 29/64 loss: 0.20035356283187866
Batch 30/64 loss: 0.19829869270324707
Batch 31/64 loss: 0.2042757272720337
Batch 32/64 loss: 0.18346166610717773
Batch 33/64 loss: 0.18830227851867676
Batch 34/64 loss: 0.19945621490478516
Batch 35/64 loss: 0.1872057318687439
Batch 36/64 loss: 0.19303321838378906
Batch 37/64 loss: 0.1974257230758667
Batch 38/64 loss: 0.1924889087677002
Batch 39/64 loss: 0.19785189628601074
Batch 40/64 loss: 0.18584668636322021
Batch 41/64 loss: 0.19682800769805908
Batch 42/64 loss: 0.18722712993621826
Batch 43/64 loss: 0.19278603792190552
Batch 44/64 loss: 0.196608304977417
Batch 45/64 loss: 0.1862868070602417
Batch 46/64 loss: 0.19369369745254517
Batch 47/64 loss: 0.20326167345046997
Batch 48/64 loss: 0.1916278600692749
Batch 49/64 loss: 0.19447875022888184
Batch 50/64 loss: 0.19401943683624268
Batch 51/64 loss: 0.18853044509887695
Batch 52/64 loss: 0.19041770696640015
Batch 53/64 loss: 0.20466113090515137
Batch 54/64 loss: 0.1909102201461792
Batch 55/64 loss: 0.20219910144805908
Batch 56/64 loss: 0.21641087532043457
Batch 57/64 loss: 0.20425522327423096
Batch 58/64 loss: 0.1826511025428772
Batch 59/64 loss: 0.188825786113739
Batch 60/64 loss: 0.18622112274169922
Batch 61/64 loss: 0.18951302766799927
Batch 62/64 loss: 0.18343687057495117
Batch 63/64 loss: 0.1931692361831665
Batch 64/64 loss: 0.21281027793884277
Epoch 438  Train loss: 0.19351054359884823  Val loss: 0.2987428584049657
Epoch 439
-------------------------------
Batch 1/64 loss: 0.19686728715896606
Batch 2/64 loss: 0.18698227405548096
Batch 3/64 loss: 0.18966984748840332
Batch 4/64 loss: 0.21220535039901733
Batch 5/64 loss: 0.18908601999282837
Batch 6/64 loss: 0.18465125560760498
Batch 7/64 loss: 0.19425785541534424
Batch 8/64 loss: 0.1925724744796753
Batch 9/64 loss: 0.19267714023590088
Batch 10/64 loss: 0.19618761539459229
Batch 11/64 loss: 0.19870787858963013
Batch 12/64 loss: 0.19409000873565674
Batch 13/64 loss: 0.18657231330871582
Batch 14/64 loss: 0.20465350151062012
Batch 15/64 loss: 0.19368374347686768
Batch 16/64 loss: 0.18947410583496094
Batch 17/64 loss: 0.19171404838562012
Batch 18/64 loss: 0.18496805429458618
Batch 19/64 loss: 0.18728601932525635
Batch 20/64 loss: 0.18941718339920044
Batch 21/64 loss: 0.19310057163238525
Batch 22/64 loss: 0.18897366523742676
Batch 23/64 loss: 0.18657398223876953
Batch 24/64 loss: 0.18321603536605835
Batch 25/64 loss: 0.19840776920318604
Batch 26/64 loss: 0.18596988916397095
Batch 27/64 loss: 0.18883401155471802
Batch 28/64 loss: 0.1819629669189453
Batch 29/64 loss: 0.20183289051055908
Batch 30/64 loss: 0.19922959804534912
Batch 31/64 loss: 0.18947690725326538
Batch 32/64 loss: 0.1910938024520874
Batch 33/64 loss: 0.1886448860168457
Batch 34/64 loss: 0.18843930959701538
Batch 35/64 loss: 0.18911844491958618
Batch 36/64 loss: 0.18850970268249512
Batch 37/64 loss: 0.19870656728744507
Batch 38/64 loss: 0.19397759437561035
Batch 39/64 loss: 0.20206379890441895
Batch 40/64 loss: 0.1995665431022644
Batch 41/64 loss: 0.18804210424423218
Batch 42/64 loss: 0.18690705299377441
Batch 43/64 loss: 0.18492770195007324
Batch 44/64 loss: 0.19206780195236206
Batch 45/64 loss: 0.20787453651428223
Batch 46/64 loss: 0.19320422410964966
Batch 47/64 loss: 0.18574804067611694
Batch 48/64 loss: 0.1961469054222107
Batch 49/64 loss: 0.17994588613510132
Batch 50/64 loss: 0.19792509078979492
Batch 51/64 loss: 0.19337129592895508
Batch 52/64 loss: 0.18990737199783325
Batch 53/64 loss: 0.18912500143051147
Batch 54/64 loss: 0.1761946678161621
Batch 55/64 loss: 0.19856911897659302
Batch 56/64 loss: 0.18515413999557495
Batch 57/64 loss: 0.200062096118927
Batch 58/64 loss: 0.1938437819480896
Batch 59/64 loss: 0.18837261199951172
Batch 60/64 loss: 0.20140546560287476
Batch 61/64 loss: 0.20895040035247803
Batch 62/64 loss: 0.18800115585327148
Batch 63/64 loss: 0.19454604387283325
Batch 64/64 loss: 0.1996856927871704
Epoch 439  Train loss: 0.19236830870310465  Val loss: 0.2981425818708754
Epoch 440
-------------------------------
Batch 1/64 loss: 0.19958233833312988
Batch 2/64 loss: 0.19475394487380981
Batch 3/64 loss: 0.19036781787872314
Batch 4/64 loss: 0.18721520900726318
Batch 5/64 loss: 0.1883518099784851
Batch 6/64 loss: 0.19206291437149048
Batch 7/64 loss: 0.18343430757522583
Batch 8/64 loss: 0.18432402610778809
Batch 9/64 loss: 0.18944329023361206
Batch 10/64 loss: 0.1872648000717163
Batch 11/64 loss: 0.19597268104553223
Batch 12/64 loss: 0.18781620264053345
Batch 13/64 loss: 0.20120424032211304
Batch 14/64 loss: 0.19076496362686157
Batch 15/64 loss: 0.18858861923217773
Batch 16/64 loss: 0.19245344400405884
Batch 17/64 loss: 0.19903182983398438
Batch 18/64 loss: 0.18682903051376343
Batch 19/64 loss: 0.19394075870513916
Batch 20/64 loss: 0.1970764398574829
Batch 21/64 loss: 0.19063615798950195
Batch 22/64 loss: 0.1996806263923645
Batch 23/64 loss: 0.20823317766189575
Batch 24/64 loss: 0.18334323167800903
Batch 25/64 loss: 0.18799078464508057
Batch 26/64 loss: 0.18619310855865479
Batch 27/64 loss: 0.19486892223358154
Batch 28/64 loss: 0.19268006086349487
Batch 29/64 loss: 0.1841360330581665
Batch 30/64 loss: 0.2020554542541504
Batch 31/64 loss: 0.19256091117858887
Batch 32/64 loss: 0.19973856210708618
Batch 33/64 loss: 0.18947237730026245
Batch 34/64 loss: 0.19227027893066406
Batch 35/64 loss: 0.19656866788864136
Batch 36/64 loss: 0.18873310089111328
Batch 37/64 loss: 0.18691134452819824
Batch 38/64 loss: 0.19214868545532227
Batch 39/64 loss: 0.18675142526626587
Batch 40/64 loss: 0.2013377547264099
Batch 41/64 loss: 0.19475537538528442
Batch 42/64 loss: 0.18370598554611206
Batch 43/64 loss: 0.20001107454299927
Batch 44/64 loss: 0.19528186321258545
Batch 45/64 loss: 0.22177010774612427
Batch 46/64 loss: 0.18918567895889282
Batch 47/64 loss: 0.19760030508041382
Batch 48/64 loss: 0.20033419132232666
Batch 49/64 loss: 0.18496298789978027
Batch 50/64 loss: 0.18559789657592773
Batch 51/64 loss: 0.19803810119628906
Batch 52/64 loss: 0.18554508686065674
Batch 53/64 loss: 0.20148754119873047
Batch 54/64 loss: 0.19704550504684448
Batch 55/64 loss: 0.18207120895385742
Batch 56/64 loss: 0.1895836591720581
Batch 57/64 loss: 0.18352943658828735
Batch 58/64 loss: 0.1857672929763794
Batch 59/64 loss: 0.1926361322402954
Batch 60/64 loss: 0.20397067070007324
Batch 61/64 loss: 0.20921742916107178
Batch 62/64 loss: 0.20997625589370728
Batch 63/64 loss: 0.19305402040481567
Batch 64/64 loss: 0.20930540561676025
Epoch 440  Train loss: 0.1933944501128851  Val loss: 0.2983963253981469
Epoch 441
-------------------------------
Batch 1/64 loss: 0.19565242528915405
Batch 2/64 loss: 0.18422198295593262
Batch 3/64 loss: 0.18938952684402466
Batch 4/64 loss: 0.19205236434936523
Batch 5/64 loss: 0.1986483335494995
Batch 6/64 loss: 0.1821238398551941
Batch 7/64 loss: 0.19178664684295654
Batch 8/64 loss: 0.18939965963363647
Batch 9/64 loss: 0.18623679876327515
Batch 10/64 loss: 0.2111574411392212
Batch 11/64 loss: 0.19486278295516968
Batch 12/64 loss: 0.1966569423675537
Batch 13/64 loss: 0.18555498123168945
Batch 14/64 loss: 0.2022871971130371
Batch 15/64 loss: 0.19263601303100586
Batch 16/64 loss: 0.18052810430526733
Batch 17/64 loss: 0.19426876306533813
Batch 18/64 loss: 0.1959984302520752
Batch 19/64 loss: 0.19173741340637207
Batch 20/64 loss: 0.19986838102340698
Batch 21/64 loss: 0.1905643343925476
Batch 22/64 loss: 0.20104986429214478
Batch 23/64 loss: 0.18482905626296997
Batch 24/64 loss: 0.18698275089263916
Batch 25/64 loss: 0.18349099159240723
Batch 26/64 loss: 0.1855686902999878
Batch 27/64 loss: 0.1866070032119751
Batch 28/64 loss: 0.20095986127853394
Batch 29/64 loss: 0.18476301431655884
Batch 30/64 loss: 0.20396214723587036
Batch 31/64 loss: 0.1913021206855774
Batch 32/64 loss: 0.1950872540473938
Batch 33/64 loss: 0.21055340766906738
Batch 34/64 loss: 0.1980341076850891
Batch 35/64 loss: 0.19075381755828857
Batch 36/64 loss: 0.18926072120666504
Batch 37/64 loss: 0.19940590858459473
Batch 38/64 loss: 0.1906576156616211
Batch 39/64 loss: 0.19883358478546143
Batch 40/64 loss: 0.2039852738380432
Batch 41/64 loss: 0.19006937742233276
Batch 42/64 loss: 0.20120716094970703
Batch 43/64 loss: 0.18685537576675415
Batch 44/64 loss: 0.19224953651428223
Batch 45/64 loss: 0.1968064308166504
Batch 46/64 loss: 0.18240797519683838
Batch 47/64 loss: 0.18763679265975952
Batch 48/64 loss: 0.19391584396362305
Batch 49/64 loss: 0.19345396757125854
Batch 50/64 loss: 0.20704561471939087
Batch 51/64 loss: 0.2019137144088745
Batch 52/64 loss: 0.20264112949371338
Batch 53/64 loss: 0.1871626377105713
Batch 54/64 loss: 0.1995517611503601
Batch 55/64 loss: 0.1873159408569336
Batch 56/64 loss: 0.20017296075820923
Batch 57/64 loss: 0.1906261444091797
Batch 58/64 loss: 0.19867467880249023
Batch 59/64 loss: 0.1940644383430481
Batch 60/64 loss: 0.18640142679214478
Batch 61/64 loss: 0.19118285179138184
Batch 62/64 loss: 0.19518083333969116
Batch 63/64 loss: 0.19630247354507446
Batch 64/64 loss: 0.19481587409973145
Epoch 441  Train loss: 0.19357914550631655  Val loss: 0.29866911926630024
Epoch 442
-------------------------------
Batch 1/64 loss: 0.19976359605789185
Batch 2/64 loss: 0.1910971999168396
Batch 3/64 loss: 0.1797856092453003
Batch 4/64 loss: 0.1924511194229126
Batch 5/64 loss: 0.2001326084136963
Batch 6/64 loss: 0.19717824459075928
Batch 7/64 loss: 0.19918197393417358
Batch 8/64 loss: 0.20077449083328247
Batch 9/64 loss: 0.2090466022491455
Batch 10/64 loss: 0.19257676601409912
Batch 11/64 loss: 0.18924689292907715
Batch 12/64 loss: 0.19102489948272705
Batch 13/64 loss: 0.1934155821800232
Batch 14/64 loss: 0.19311422109603882
Batch 15/64 loss: 0.19005048274993896
Batch 16/64 loss: 0.18499189615249634
Batch 17/64 loss: 0.1859673261642456
Batch 18/64 loss: 0.19074797630310059
Batch 19/64 loss: 0.18908649682998657
Batch 20/64 loss: 0.19484800100326538
Batch 21/64 loss: 0.18760013580322266
Batch 22/64 loss: 0.19033104181289673
Batch 23/64 loss: 0.18716561794281006
Batch 24/64 loss: 0.1848691701889038
Batch 25/64 loss: 0.18883490562438965
Batch 26/64 loss: 0.17973202466964722
Batch 27/64 loss: 0.18589913845062256
Batch 28/64 loss: 0.19278132915496826
Batch 29/64 loss: 0.20752418041229248
Batch 30/64 loss: 0.18149840831756592
Batch 31/64 loss: 0.17769014835357666
Batch 32/64 loss: 0.18526774644851685
Batch 33/64 loss: 0.18180549144744873
Batch 34/64 loss: 0.18420100212097168
Batch 35/64 loss: 0.1962156891822815
Batch 36/64 loss: 0.19697004556655884
Batch 37/64 loss: 0.18525975942611694
Batch 38/64 loss: 0.18781906366348267
Batch 39/64 loss: 0.19325411319732666
Batch 40/64 loss: 0.19371438026428223
Batch 41/64 loss: 0.18839871883392334
Batch 42/64 loss: 0.19810718297958374
Batch 43/64 loss: 0.19112175703048706
Batch 44/64 loss: 0.20396429300308228
Batch 45/64 loss: 0.21115046739578247
Batch 46/64 loss: 0.1945943832397461
Batch 47/64 loss: 0.18299758434295654
Batch 48/64 loss: 0.1848057508468628
Batch 49/64 loss: 0.20318889617919922
Batch 50/64 loss: 0.1990397572517395
Batch 51/64 loss: 0.1975395679473877
Batch 52/64 loss: 0.19452881813049316
Batch 53/64 loss: 0.19888073205947876
Batch 54/64 loss: 0.19237756729125977
Batch 55/64 loss: 0.19013464450836182
Batch 56/64 loss: 0.2003762125968933
Batch 57/64 loss: 0.1897643804550171
Batch 58/64 loss: 0.18883031606674194
Batch 59/64 loss: 0.1964397430419922
Batch 60/64 loss: 0.19735705852508545
Batch 61/64 loss: 0.18532705307006836
Batch 62/64 loss: 0.19069361686706543
Batch 63/64 loss: 0.19069820642471313
Batch 64/64 loss: 0.20549649000167847
Epoch 442  Train loss: 0.19227222671695784  Val loss: 0.2984352898351925
Epoch 443
-------------------------------
Batch 1/64 loss: 0.1884247064590454
Batch 2/64 loss: 0.18648087978363037
Batch 3/64 loss: 0.17406517267227173
Batch 4/64 loss: 0.19001758098602295
Batch 5/64 loss: 0.18966203927993774
Batch 6/64 loss: 0.2001524567604065
Batch 7/64 loss: 0.18244105577468872
Batch 8/64 loss: 0.18952369689941406
Batch 9/64 loss: 0.19094383716583252
Batch 10/64 loss: 0.19442522525787354
Batch 11/64 loss: 0.1986602544784546
Batch 12/64 loss: 0.1949804425239563
Batch 13/64 loss: 0.18127089738845825
Batch 14/64 loss: 0.2033635973930359
Batch 15/64 loss: 0.19300562143325806
Batch 16/64 loss: 0.20027822256088257
Batch 17/64 loss: 0.18757033348083496
Batch 18/64 loss: 0.18733417987823486
Batch 19/64 loss: 0.18710285425186157
Batch 20/64 loss: 0.1995772123336792
Batch 21/64 loss: 0.1935216188430786
Batch 22/64 loss: 0.1977662444114685
Batch 23/64 loss: 0.18529736995697021
Batch 24/64 loss: 0.20407724380493164
Batch 25/64 loss: 0.20296412706375122
Batch 26/64 loss: 0.19146019220352173
Batch 27/64 loss: 0.18728387355804443
Batch 28/64 loss: 0.19541466236114502
Batch 29/64 loss: 0.18747109174728394
Batch 30/64 loss: 0.18649888038635254
Batch 31/64 loss: 0.18840289115905762
Batch 32/64 loss: 0.1893218755722046
Batch 33/64 loss: 0.1942644715309143
Batch 34/64 loss: 0.20810014009475708
Batch 35/64 loss: 0.1907898187637329
Batch 36/64 loss: 0.1875177025794983
Batch 37/64 loss: 0.19322192668914795
Batch 38/64 loss: 0.1893521547317505
Batch 39/64 loss: 0.19604277610778809
Batch 40/64 loss: 0.1967821717262268
Batch 41/64 loss: 0.19779860973358154
Batch 42/64 loss: 0.18961721658706665
Batch 43/64 loss: 0.19475007057189941
Batch 44/64 loss: 0.18774467706680298
Batch 45/64 loss: 0.1859053373336792
Batch 46/64 loss: 0.19303792715072632
Batch 47/64 loss: 0.19618439674377441
Batch 48/64 loss: 0.19494646787643433
Batch 49/64 loss: 0.19710689783096313
Batch 50/64 loss: 0.18705809116363525
Batch 51/64 loss: 0.1815558671951294
Batch 52/64 loss: 0.20035135746002197
Batch 53/64 loss: 0.1958295702934265
Batch 54/64 loss: 0.19371384382247925
Batch 55/64 loss: 0.19108504056930542
Batch 56/64 loss: 0.18747401237487793
Batch 57/64 loss: 0.19445723295211792
Batch 58/64 loss: 0.20119738578796387
Batch 59/64 loss: 0.19211876392364502
Batch 60/64 loss: 0.19602930545806885
Batch 61/64 loss: 0.1916337013244629
Batch 62/64 loss: 0.18107128143310547
Batch 63/64 loss: 0.18360179662704468
Batch 64/64 loss: 0.19684243202209473
Epoch 443  Train loss: 0.19210560275059121  Val loss: 0.2986606781425345
Epoch 444
-------------------------------
Batch 1/64 loss: 0.19321131706237793
Batch 2/64 loss: 0.18871766328811646
Batch 3/64 loss: 0.19530659914016724
Batch 4/64 loss: 0.19632220268249512
Batch 5/64 loss: 0.19691795110702515
Batch 6/64 loss: 0.20134055614471436
Batch 7/64 loss: 0.20340800285339355
Batch 8/64 loss: 0.1924114227294922
Batch 9/64 loss: 0.19598150253295898
Batch 10/64 loss: 0.2004188895225525
Batch 11/64 loss: 0.19058364629745483
Batch 12/64 loss: 0.18193787336349487
Batch 13/64 loss: 0.20178568363189697
Batch 14/64 loss: 0.19027066230773926
Batch 15/64 loss: 0.18668889999389648
Batch 16/64 loss: 0.19230109453201294
Batch 17/64 loss: 0.20591259002685547
Batch 18/64 loss: 0.19364118576049805
Batch 19/64 loss: 0.1941148042678833
Batch 20/64 loss: 0.20044928789138794
Batch 21/64 loss: 0.1783050298690796
Batch 22/64 loss: 0.18814033269882202
Batch 23/64 loss: 0.18258178234100342
Batch 24/64 loss: 0.18975406885147095
Batch 25/64 loss: 0.1844654083251953
Batch 26/64 loss: 0.19089347124099731
Batch 27/64 loss: 0.17905139923095703
Batch 28/64 loss: 0.19390451908111572
Batch 29/64 loss: 0.20705753564834595
Batch 30/64 loss: 0.19822978973388672
Batch 31/64 loss: 0.18721961975097656
Batch 32/64 loss: 0.19957482814788818
Batch 33/64 loss: 0.18695247173309326
Batch 34/64 loss: 0.19214165210723877
Batch 35/64 loss: 0.19432216882705688
Batch 36/64 loss: 0.20319652557373047
Batch 37/64 loss: 0.187552809715271
Batch 38/64 loss: 0.20042961835861206
Batch 39/64 loss: 0.19349265098571777
Batch 40/64 loss: 0.18697619438171387
Batch 41/64 loss: 0.18255925178527832
Batch 42/64 loss: 0.19855761528015137
Batch 43/64 loss: 0.18148398399353027
Batch 44/64 loss: 0.19155001640319824
Batch 45/64 loss: 0.18474596738815308
Batch 46/64 loss: 0.19706392288208008
Batch 47/64 loss: 0.19779914617538452
Batch 48/64 loss: 0.1977221965789795
Batch 49/64 loss: 0.17893826961517334
Batch 50/64 loss: 0.18946152925491333
Batch 51/64 loss: 0.18955254554748535
Batch 52/64 loss: 0.19728344678878784
Batch 53/64 loss: 0.18636006116867065
Batch 54/64 loss: 0.1888425350189209
Batch 55/64 loss: 0.1907973289489746
Batch 56/64 loss: 0.1991487741470337
Batch 57/64 loss: 0.1988862156867981
Batch 58/64 loss: 0.20647215843200684
Batch 59/64 loss: 0.18401318788528442
Batch 60/64 loss: 0.19923120737075806
Batch 61/64 loss: 0.1827870011329651
Batch 62/64 loss: 0.18936455249786377
Batch 63/64 loss: 0.18556100130081177
Batch 64/64 loss: 0.180927574634552
Epoch 444  Train loss: 0.19231123620388554  Val loss: 0.2983319210432649
Epoch 445
-------------------------------
Batch 1/64 loss: 0.18460047245025635
Batch 2/64 loss: 0.18065977096557617
Batch 3/64 loss: 0.18585777282714844
Batch 4/64 loss: 0.1899012327194214
Batch 5/64 loss: 0.20551741123199463
Batch 6/64 loss: 0.19120872020721436
Batch 7/64 loss: 0.19144278764724731
Batch 8/64 loss: 0.19121980667114258
Batch 9/64 loss: 0.20472580194473267
Batch 10/64 loss: 0.20202815532684326
Batch 11/64 loss: 0.1833915114402771
Batch 12/64 loss: 0.18345385789871216
Batch 13/64 loss: 0.18384075164794922
Batch 14/64 loss: 0.19440144300460815
Batch 15/64 loss: 0.19643700122833252
Batch 16/64 loss: 0.19393444061279297
Batch 17/64 loss: 0.19898676872253418
Batch 18/64 loss: 0.2044898271560669
Batch 19/64 loss: 0.18601614236831665
Batch 20/64 loss: 0.19143033027648926
Batch 21/64 loss: 0.18172043561935425
Batch 22/64 loss: 0.21110308170318604
Batch 23/64 loss: 0.18888288736343384
Batch 24/64 loss: 0.19296395778656006
Batch 25/64 loss: 0.1931188702583313
Batch 26/64 loss: 0.1784125566482544
Batch 27/64 loss: 0.18529170751571655
Batch 28/64 loss: 0.1830269694328308
Batch 29/64 loss: 0.20072627067565918
Batch 30/64 loss: 0.19383400678634644
Batch 31/64 loss: 0.19392871856689453
Batch 32/64 loss: 0.1836683750152588
Batch 33/64 loss: 0.1958511471748352
Batch 34/64 loss: 0.1795559525489807
Batch 35/64 loss: 0.1847172975540161
Batch 36/64 loss: 0.20216631889343262
Batch 37/64 loss: 0.1953832507133484
Batch 38/64 loss: 0.18702280521392822
Batch 39/64 loss: 0.18431079387664795
Batch 40/64 loss: 0.1913585066795349
Batch 41/64 loss: 0.19605034589767456
Batch 42/64 loss: 0.18692225217819214
Batch 43/64 loss: 0.19492411613464355
Batch 44/64 loss: 0.19549942016601562
Batch 45/64 loss: 0.19482767581939697
Batch 46/64 loss: 0.19386178255081177
Batch 47/64 loss: 0.19713640213012695
Batch 48/64 loss: 0.206803560256958
Batch 49/64 loss: 0.18926924467086792
Batch 50/64 loss: 0.19194209575653076
Batch 51/64 loss: 0.18481874465942383
Batch 52/64 loss: 0.19134140014648438
Batch 53/64 loss: 0.19724023342132568
Batch 54/64 loss: 0.18745112419128418
Batch 55/64 loss: 0.18885588645935059
Batch 56/64 loss: 0.20320695638656616
Batch 57/64 loss: 0.20233893394470215
Batch 58/64 loss: 0.18568086624145508
Batch 59/64 loss: 0.19216400384902954
Batch 60/64 loss: 0.19734376668930054
Batch 61/64 loss: 0.20256799459457397
Batch 62/64 loss: 0.2001778483390808
Batch 63/64 loss: 0.19774895906448364
Batch 64/64 loss: 0.20759344100952148
Epoch 445  Train loss: 0.1926973585988961  Val loss: 0.29914100555210177
Epoch 446
-------------------------------
Batch 1/64 loss: 0.19341450929641724
Batch 2/64 loss: 0.18666893243789673
Batch 3/64 loss: 0.18668681383132935
Batch 4/64 loss: 0.191348135471344
Batch 5/64 loss: 0.18619191646575928
Batch 6/64 loss: 0.1856589913368225
Batch 7/64 loss: 0.2106943130493164
Batch 8/64 loss: 0.18609392642974854
Batch 9/64 loss: 0.18573206663131714
Batch 10/64 loss: 0.19456684589385986
Batch 11/64 loss: 0.18680012226104736
Batch 12/64 loss: 0.18367069959640503
Batch 13/64 loss: 0.18492186069488525
Batch 14/64 loss: 0.20032203197479248
Batch 15/64 loss: 0.1772591471672058
Batch 16/64 loss: 0.1904836893081665
Batch 17/64 loss: 0.18685466051101685
Batch 18/64 loss: 0.18414205312728882
Batch 19/64 loss: 0.1976945400238037
Batch 20/64 loss: 0.18373823165893555
Batch 21/64 loss: 0.1858755350112915
Batch 22/64 loss: 0.1828879714012146
Batch 23/64 loss: 0.19155728816986084
Batch 24/64 loss: 0.19533127546310425
Batch 25/64 loss: 0.18736964464187622
Batch 26/64 loss: 0.1882544755935669
Batch 27/64 loss: 0.17995905876159668
Batch 28/64 loss: 0.20271021127700806
Batch 29/64 loss: 0.2044966220855713
Batch 30/64 loss: 0.195060133934021
Batch 31/64 loss: 0.18328291177749634
Batch 32/64 loss: 0.1918560266494751
Batch 33/64 loss: 0.1867152452468872
Batch 34/64 loss: 0.18989330530166626
Batch 35/64 loss: 0.19158309698104858
Batch 36/64 loss: 0.19746923446655273
Batch 37/64 loss: 0.20184433460235596
Batch 38/64 loss: 0.18152856826782227
Batch 39/64 loss: 0.18798184394836426
Batch 40/64 loss: 0.18635845184326172
Batch 41/64 loss: 0.19629579782485962
Batch 42/64 loss: 0.21186316013336182
Batch 43/64 loss: 0.20095807313919067
Batch 44/64 loss: 0.19034439325332642
Batch 45/64 loss: 0.19494885206222534
Batch 46/64 loss: 0.20267212390899658
Batch 47/64 loss: 0.186470627784729
Batch 48/64 loss: 0.19085973501205444
Batch 49/64 loss: 0.19432073831558228
Batch 50/64 loss: 0.17935395240783691
Batch 51/64 loss: 0.2010040283203125
Batch 52/64 loss: 0.2025306224822998
Batch 53/64 loss: 0.1968553066253662
Batch 54/64 loss: 0.18350958824157715
Batch 55/64 loss: 0.17980808019638062
Batch 56/64 loss: 0.18761801719665527
Batch 57/64 loss: 0.19486796855926514
Batch 58/64 loss: 0.19019246101379395
Batch 59/64 loss: 0.19231277704238892
Batch 60/64 loss: 0.19015741348266602
Batch 61/64 loss: 0.1895352005958557
Batch 62/64 loss: 0.2043418288230896
Batch 63/64 loss: 0.2026749849319458
Batch 64/64 loss: 0.2160639762878418
Epoch 446  Train loss: 0.19169415586134966  Val loss: 0.2988660650974287
Epoch 447
-------------------------------
Batch 1/64 loss: 0.19029223918914795
Batch 2/64 loss: 0.18237364292144775
Batch 3/64 loss: 0.18150269985198975
Batch 4/64 loss: 0.1820673942565918
Batch 5/64 loss: 0.1842479109764099
Batch 6/64 loss: 0.1918928027153015
Batch 7/64 loss: 0.18816900253295898
Batch 8/64 loss: 0.18974590301513672
Batch 9/64 loss: 0.1966792345046997
Batch 10/64 loss: 0.19231128692626953
Batch 11/64 loss: 0.19898921251296997
Batch 12/64 loss: 0.1851438283920288
Batch 13/64 loss: 0.1861501932144165
Batch 14/64 loss: 0.19886916875839233
Batch 15/64 loss: 0.20458078384399414
Batch 16/64 loss: 0.18517863750457764
Batch 17/64 loss: 0.19257092475891113
Batch 18/64 loss: 0.19696956872940063
Batch 19/64 loss: 0.18889081478118896
Batch 20/64 loss: 0.19480931758880615
Batch 21/64 loss: 0.19006019830703735
Batch 22/64 loss: 0.1853024959564209
Batch 23/64 loss: 0.18968653678894043
Batch 24/64 loss: 0.18967825174331665
Batch 25/64 loss: 0.1854417324066162
Batch 26/64 loss: 0.1828104853630066
Batch 27/64 loss: 0.19072383642196655
Batch 28/64 loss: 0.18469345569610596
Batch 29/64 loss: 0.18829667568206787
Batch 30/64 loss: 0.18599092960357666
Batch 31/64 loss: 0.18650424480438232
Batch 32/64 loss: 0.19211870431900024
Batch 33/64 loss: 0.19527655839920044
Batch 34/64 loss: 0.19360017776489258
Batch 35/64 loss: 0.1881435513496399
Batch 36/64 loss: 0.19805562496185303
Batch 37/64 loss: 0.18727803230285645
Batch 38/64 loss: 0.2074061632156372
Batch 39/64 loss: 0.19101840257644653
Batch 40/64 loss: 0.19561320543289185
Batch 41/64 loss: 0.21041083335876465
Batch 42/64 loss: 0.18858814239501953
Batch 43/64 loss: 0.18265199661254883
Batch 44/64 loss: 0.19148290157318115
Batch 45/64 loss: 0.20155805349349976
Batch 46/64 loss: 0.1884363889694214
Batch 47/64 loss: 0.19561362266540527
Batch 48/64 loss: 0.19328904151916504
Batch 49/64 loss: 0.19059884548187256
Batch 50/64 loss: 0.18445533514022827
Batch 51/64 loss: 0.1916142702102661
Batch 52/64 loss: 0.193833589553833
Batch 53/64 loss: 0.19340282678604126
Batch 54/64 loss: 0.19382435083389282
Batch 55/64 loss: 0.19325625896453857
Batch 56/64 loss: 0.18431037664413452
Batch 57/64 loss: 0.19643127918243408
Batch 58/64 loss: 0.19140899181365967
Batch 59/64 loss: 0.1905772089958191
Batch 60/64 loss: 0.19415628910064697
Batch 61/64 loss: 0.1966564655303955
Batch 62/64 loss: 0.18916714191436768
Batch 63/64 loss: 0.1814005970954895
Batch 64/64 loss: 0.1869957447052002
Epoch 447  Train loss: 0.1910040070028866  Val loss: 0.29901591281300965
Epoch 448
-------------------------------
Batch 1/64 loss: 0.18590134382247925
Batch 2/64 loss: 0.1941930651664734
Batch 3/64 loss: 0.1840217113494873
Batch 4/64 loss: 0.18754994869232178
Batch 5/64 loss: 0.1826602816581726
Batch 6/64 loss: 0.18963634967803955
Batch 7/64 loss: 0.20065784454345703
Batch 8/64 loss: 0.1845884919166565
Batch 9/64 loss: 0.19895070791244507
Batch 10/64 loss: 0.19088882207870483
Batch 11/64 loss: 0.19049334526062012
Batch 12/64 loss: 0.19814658164978027
Batch 13/64 loss: 0.19778680801391602
Batch 14/64 loss: 0.18975257873535156
Batch 15/64 loss: 0.1836233139038086
Batch 16/64 loss: 0.1805097460746765
Batch 17/64 loss: 0.1902393102645874
Batch 18/64 loss: 0.18417298793792725
Batch 19/64 loss: 0.19260019063949585
Batch 20/64 loss: 0.1850111484527588
Batch 21/64 loss: 0.18423718214035034
Batch 22/64 loss: 0.18413615226745605
Batch 23/64 loss: 0.1963137984275818
Batch 24/64 loss: 0.19052422046661377
Batch 25/64 loss: 0.19548821449279785
Batch 26/64 loss: 0.20039165019989014
Batch 27/64 loss: 0.19741010665893555
Batch 28/64 loss: 0.19590520858764648
Batch 29/64 loss: 0.20122849941253662
Batch 30/64 loss: 0.2042452096939087
Batch 31/64 loss: 0.18481045961380005
Batch 32/64 loss: 0.19364452362060547
Batch 33/64 loss: 0.19346141815185547
Batch 34/64 loss: 0.1919218897819519
Batch 35/64 loss: 0.20698589086532593
Batch 36/64 loss: 0.1887967586517334
Batch 37/64 loss: 0.1767151951789856
Batch 38/64 loss: 0.18822741508483887
Batch 39/64 loss: 0.20231330394744873
Batch 40/64 loss: 0.18535882234573364
Batch 41/64 loss: 0.20928955078125
Batch 42/64 loss: 0.19060981273651123
Batch 43/64 loss: 0.19403761625289917
Batch 44/64 loss: 0.1907152533531189
Batch 45/64 loss: 0.19091367721557617
Batch 46/64 loss: 0.19697463512420654
Batch 47/64 loss: 0.19469153881072998
Batch 48/64 loss: 0.18524181842803955
Batch 49/64 loss: 0.19545304775238037
Batch 50/64 loss: 0.18216168880462646
Batch 51/64 loss: 0.18683195114135742
Batch 52/64 loss: 0.18845397233963013
Batch 53/64 loss: 0.20109033584594727
Batch 54/64 loss: 0.19335341453552246
Batch 55/64 loss: 0.18603503704071045
Batch 56/64 loss: 0.1879979968070984
Batch 57/64 loss: 0.19583559036254883
Batch 58/64 loss: 0.200517475605011
Batch 59/64 loss: 0.19827014207839966
Batch 60/64 loss: 0.18732845783233643
Batch 61/64 loss: 0.20596057176589966
Batch 62/64 loss: 0.19149541854858398
Batch 63/64 loss: 0.18883180618286133
Batch 64/64 loss: 0.19918441772460938
Epoch 448  Train loss: 0.19207811168595856  Val loss: 0.29833940337204035
Epoch 449
-------------------------------
Batch 1/64 loss: 0.1889631748199463
Batch 2/64 loss: 0.19951677322387695
Batch 3/64 loss: 0.1872221827507019
Batch 4/64 loss: 0.18138742446899414
Batch 5/64 loss: 0.18531185388565063
Batch 6/64 loss: 0.20746636390686035
Batch 7/64 loss: 0.17847084999084473
Batch 8/64 loss: 0.19912302494049072
Batch 9/64 loss: 0.1988469362258911
Batch 10/64 loss: 0.19104230403900146
Batch 11/64 loss: 0.19524085521697998
Batch 12/64 loss: 0.187480628490448
Batch 13/64 loss: 0.18656468391418457
Batch 14/64 loss: 0.19237053394317627
Batch 15/64 loss: 0.18501174449920654
Batch 16/64 loss: 0.19474977254867554
Batch 17/64 loss: 0.17936623096466064
Batch 18/64 loss: 0.2024117112159729
Batch 19/64 loss: 0.19376879930496216
Batch 20/64 loss: 0.1832701563835144
Batch 21/64 loss: 0.18688029050827026
Batch 22/64 loss: 0.20486921072006226
Batch 23/64 loss: 0.1974770426750183
Batch 24/64 loss: 0.19288688898086548
Batch 25/64 loss: 0.18185162544250488
Batch 26/64 loss: 0.20309484004974365
Batch 27/64 loss: 0.2052815556526184
Batch 28/64 loss: 0.18239271640777588
Batch 29/64 loss: 0.1898040771484375
Batch 30/64 loss: 0.19108086824417114
Batch 31/64 loss: 0.20187902450561523
Batch 32/64 loss: 0.19382524490356445
Batch 33/64 loss: 0.19657331705093384
Batch 34/64 loss: 0.2015182375907898
Batch 35/64 loss: 0.1815546154975891
Batch 36/64 loss: 0.20953017473220825
Batch 37/64 loss: 0.19456183910369873
Batch 38/64 loss: 0.17968899011611938
Batch 39/64 loss: 0.1924801468849182
Batch 40/64 loss: 0.1928665041923523
Batch 41/64 loss: 0.186987042427063
Batch 42/64 loss: 0.2020307183265686
Batch 43/64 loss: 0.18739396333694458
Batch 44/64 loss: 0.17887675762176514
Batch 45/64 loss: 0.19694381952285767
Batch 46/64 loss: 0.18904119729995728
Batch 47/64 loss: 0.19427382946014404
Batch 48/64 loss: 0.20148050785064697
Batch 49/64 loss: 0.19095516204833984
Batch 50/64 loss: 0.1851305365562439
Batch 51/64 loss: 0.1945076584815979
Batch 52/64 loss: 0.21319609880447388
Batch 53/64 loss: 0.18239325284957886
Batch 54/64 loss: 0.18718206882476807
Batch 55/64 loss: 0.21077173948287964
Batch 56/64 loss: 0.19022095203399658
Batch 57/64 loss: 0.19074726104736328
Batch 58/64 loss: 0.1932849884033203
Batch 59/64 loss: 0.1890869140625
Batch 60/64 loss: 0.1890886425971985
Batch 61/64 loss: 0.1883533000946045
Batch 62/64 loss: 0.1938410997390747
Batch 63/64 loss: 0.18330293893814087
Batch 64/64 loss: 0.18858766555786133
Epoch 449  Train loss: 0.19228571629991717  Val loss: 0.29832152648480076
Epoch 450
-------------------------------
Batch 1/64 loss: 0.19566571712493896
Batch 2/64 loss: 0.19165503978729248
Batch 3/64 loss: 0.1884446144104004
Batch 4/64 loss: 0.19063889980316162
Batch 5/64 loss: 0.1982814073562622
Batch 6/64 loss: 0.1976255178451538
Batch 7/64 loss: 0.1842840313911438
Batch 8/64 loss: 0.19654428958892822
Batch 9/64 loss: 0.1889047622680664
Batch 10/64 loss: 0.20240044593811035
Batch 11/64 loss: 0.20635628700256348
Batch 12/64 loss: 0.19838440418243408
Batch 13/64 loss: 0.18309152126312256
Batch 14/64 loss: 0.18974876403808594
Batch 15/64 loss: 0.19366776943206787
Batch 16/64 loss: 0.20717281103134155
Batch 17/64 loss: 0.19458991289138794
Batch 18/64 loss: 0.1822701096534729
Batch 19/64 loss: 0.1869145631790161
Batch 20/64 loss: 0.1812201738357544
Batch 21/64 loss: 0.19488012790679932
Batch 22/64 loss: 0.19917285442352295
Batch 23/64 loss: 0.19717085361480713
Batch 24/64 loss: 0.19407403469085693
Batch 25/64 loss: 0.1814519166946411
Batch 26/64 loss: 0.2024034857749939
Batch 27/64 loss: 0.20181667804718018
Batch 28/64 loss: 0.20068764686584473
Batch 29/64 loss: 0.1797008514404297
Batch 30/64 loss: 0.18562841415405273
Batch 31/64 loss: 0.18956851959228516
Batch 32/64 loss: 0.18960952758789062
Batch 33/64 loss: 0.18753701448440552
Batch 34/64 loss: 0.19918739795684814
Batch 35/64 loss: 0.19434428215026855
Batch 36/64 loss: 0.18356221914291382
Batch 37/64 loss: 0.18322449922561646
Batch 38/64 loss: 0.1977216601371765
Batch 39/64 loss: 0.19296693801879883
Batch 40/64 loss: 0.18905043601989746
Batch 41/64 loss: 0.19646430015563965
Batch 42/64 loss: 0.19566601514816284
Batch 43/64 loss: 0.20673143863677979
Batch 44/64 loss: 0.19107496738433838
Batch 45/64 loss: 0.19722843170166016
Batch 46/64 loss: 0.20267993211746216
Batch 47/64 loss: 0.1897839903831482
Batch 48/64 loss: 0.19431889057159424
Batch 49/64 loss: 0.19326478242874146
Batch 50/64 loss: 0.19828635454177856
Batch 51/64 loss: 0.19414091110229492
Batch 52/64 loss: 0.19510912895202637
Batch 53/64 loss: 0.17920911312103271
Batch 54/64 loss: 0.19310152530670166
Batch 55/64 loss: 0.18864953517913818
Batch 56/64 loss: 0.1882309913635254
Batch 57/64 loss: 0.2014598846435547
Batch 58/64 loss: 0.19557112455368042
Batch 59/64 loss: 0.18425142765045166
Batch 60/64 loss: 0.1875278353691101
Batch 61/64 loss: 0.18655860424041748
Batch 62/64 loss: 0.19388580322265625
Batch 63/64 loss: 0.19089066982269287
Batch 64/64 loss: 0.18790215253829956
Epoch 450  Train loss: 0.19273149289336858  Val loss: 0.2994107274255392
Epoch 451
-------------------------------
Batch 1/64 loss: 0.19407272338867188
Batch 2/64 loss: 0.19441044330596924
Batch 3/64 loss: 0.2125677466392517
Batch 4/64 loss: 0.20357084274291992
Batch 5/64 loss: 0.21207427978515625
Batch 6/64 loss: 0.18454939126968384
Batch 7/64 loss: 0.20539748668670654
Batch 8/64 loss: 0.1945580244064331
Batch 9/64 loss: 0.18513458967208862
Batch 10/64 loss: 0.19492948055267334
Batch 11/64 loss: 0.1898362636566162
Batch 12/64 loss: 0.18262255191802979
Batch 13/64 loss: 0.21039986610412598
Batch 14/64 loss: 0.18909364938735962
Batch 15/64 loss: 0.19664818048477173
Batch 16/64 loss: 0.19216370582580566
Batch 17/64 loss: 0.19400912523269653
Batch 18/64 loss: 0.17679429054260254
Batch 19/64 loss: 0.19071853160858154
Batch 20/64 loss: 0.19424927234649658
Batch 21/64 loss: 0.17839014530181885
Batch 22/64 loss: 0.1956624984741211
Batch 23/64 loss: 0.18309146165847778
Batch 24/64 loss: 0.19587254524230957
Batch 25/64 loss: 0.19538384675979614
Batch 26/64 loss: 0.20211952924728394
Batch 27/64 loss: 0.19089055061340332
Batch 28/64 loss: 0.1826411485671997
Batch 29/64 loss: 0.188226580619812
Batch 30/64 loss: 0.19814765453338623
Batch 31/64 loss: 0.18989109992980957
Batch 32/64 loss: 0.179223895072937
Batch 33/64 loss: 0.1809232234954834
Batch 34/64 loss: 0.1864393949508667
Batch 35/64 loss: 0.19785279035568237
Batch 36/64 loss: 0.19242793321609497
Batch 37/64 loss: 0.18490523099899292
Batch 38/64 loss: 0.1986163854598999
Batch 39/64 loss: 0.20494109392166138
Batch 40/64 loss: 0.19958949089050293
Batch 41/64 loss: 0.19432979822158813
Batch 42/64 loss: 0.18841081857681274
Batch 43/64 loss: 0.19449299573898315
Batch 44/64 loss: 0.1961594820022583
Batch 45/64 loss: 0.1849244236946106
Batch 46/64 loss: 0.18081670999526978
Batch 47/64 loss: 0.18816131353378296
Batch 48/64 loss: 0.19296544790267944
Batch 49/64 loss: 0.1844710111618042
Batch 50/64 loss: 0.19505637884140015
Batch 51/64 loss: 0.18883204460144043
Batch 52/64 loss: 0.1899036169052124
Batch 53/64 loss: 0.20066136121749878
Batch 54/64 loss: 0.19315755367279053
Batch 55/64 loss: 0.20492148399353027
Batch 56/64 loss: 0.1941063404083252
Batch 57/64 loss: 0.20312833786010742
Batch 58/64 loss: 0.1918565034866333
Batch 59/64 loss: 0.19572800397872925
Batch 60/64 loss: 0.19328367710113525
Batch 61/64 loss: 0.1961941123008728
Batch 62/64 loss: 0.19403016567230225
Batch 63/64 loss: 0.20173859596252441
Batch 64/64 loss: 0.19330406188964844
Epoch 451  Train loss: 0.19318188499001895  Val loss: 0.29854450520780895
Epoch 452
-------------------------------
Batch 1/64 loss: 0.19379305839538574
Batch 2/64 loss: 0.18462693691253662
Batch 3/64 loss: 0.1889299750328064
Batch 4/64 loss: 0.19173508882522583
Batch 5/64 loss: 0.17830514907836914
Batch 6/64 loss: 0.2008213996887207
Batch 7/64 loss: 0.192690908908844
Batch 8/64 loss: 0.21372395753860474
Batch 9/64 loss: 0.19282793998718262
Batch 10/64 loss: 0.1884467601776123
Batch 11/64 loss: 0.18578040599822998
Batch 12/64 loss: 0.19419902563095093
Batch 13/64 loss: 0.19124507904052734
Batch 14/64 loss: 0.19285404682159424
Batch 15/64 loss: 0.1900915503501892
Batch 16/64 loss: 0.1988985538482666
Batch 17/64 loss: 0.20135021209716797
Batch 18/64 loss: 0.1965659260749817
Batch 19/64 loss: 0.18919122219085693
Batch 20/64 loss: 0.20041799545288086
Batch 21/64 loss: 0.18577265739440918
Batch 22/64 loss: 0.18482333421707153
Batch 23/64 loss: 0.19096672534942627
Batch 24/64 loss: 0.18753063678741455
Batch 25/64 loss: 0.194970965385437
Batch 26/64 loss: 0.19300782680511475
Batch 27/64 loss: 0.20800840854644775
Batch 28/64 loss: 0.19051921367645264
Batch 29/64 loss: 0.179071843624115
Batch 30/64 loss: 0.18600255250930786
Batch 31/64 loss: 0.19487124681472778
Batch 32/64 loss: 0.2047048807144165
Batch 33/64 loss: 0.19784235954284668
Batch 34/64 loss: 0.183538556098938
Batch 35/64 loss: 0.18792015314102173
Batch 36/64 loss: 0.18851685523986816
Batch 37/64 loss: 0.19113123416900635
Batch 38/64 loss: 0.18310856819152832
Batch 39/64 loss: 0.19274157285690308
Batch 40/64 loss: 0.1923123002052307
Batch 41/64 loss: 0.1878364086151123
Batch 42/64 loss: 0.1881481409072876
Batch 43/64 loss: 0.1927228569984436
Batch 44/64 loss: 0.18286395072937012
Batch 45/64 loss: 0.18730485439300537
Batch 46/64 loss: 0.19684076309204102
Batch 47/64 loss: 0.18882662057876587
Batch 48/64 loss: 0.20332598686218262
Batch 49/64 loss: 0.18477153778076172
Batch 50/64 loss: 0.1940842866897583
Batch 51/64 loss: 0.18527472019195557
Batch 52/64 loss: 0.18465834856033325
Batch 53/64 loss: 0.18674075603485107
Batch 54/64 loss: 0.18435269594192505
Batch 55/64 loss: 0.1941220760345459
Batch 56/64 loss: 0.19598108530044556
Batch 57/64 loss: 0.1837691068649292
Batch 58/64 loss: 0.19069451093673706
Batch 59/64 loss: 0.18525922298431396
Batch 60/64 loss: 0.19719141721725464
Batch 61/64 loss: 0.18283861875534058
Batch 62/64 loss: 0.1981920599937439
Batch 63/64 loss: 0.1954714059829712
Batch 64/64 loss: 0.20571428537368774
Epoch 452  Train loss: 0.19152022319681505  Val loss: 0.29860844399101544
Epoch 453
-------------------------------
Batch 1/64 loss: 0.1869603991508484
Batch 2/64 loss: 0.186664879322052
Batch 3/64 loss: 0.20288819074630737
Batch 4/64 loss: 0.19133245944976807
Batch 5/64 loss: 0.21021759510040283
Batch 6/64 loss: 0.18291974067687988
Batch 7/64 loss: 0.18404990434646606
Batch 8/64 loss: 0.19203335046768188
Batch 9/64 loss: 0.19452601671218872
Batch 10/64 loss: 0.17995703220367432
Batch 11/64 loss: 0.1920243501663208
Batch 12/64 loss: 0.18486982583999634
Batch 13/64 loss: 0.18912523984909058
Batch 14/64 loss: 0.19549965858459473
Batch 15/64 loss: 0.1970793604850769
Batch 16/64 loss: 0.18700706958770752
Batch 17/64 loss: 0.20483839511871338
Batch 18/64 loss: 0.18704724311828613
Batch 19/64 loss: 0.18790429830551147
Batch 20/64 loss: 0.1862819790840149
Batch 21/64 loss: 0.18335825204849243
Batch 22/64 loss: 0.18883830308914185
Batch 23/64 loss: 0.2019330859184265
Batch 24/64 loss: 0.18697524070739746
Batch 25/64 loss: 0.19204699993133545
Batch 26/64 loss: 0.18316245079040527
Batch 27/64 loss: 0.1982606053352356
Batch 28/64 loss: 0.18737947940826416
Batch 29/64 loss: 0.1873508095741272
Batch 30/64 loss: 0.1966121792793274
Batch 31/64 loss: 0.1854161024093628
Batch 32/64 loss: 0.1918656826019287
Batch 33/64 loss: 0.17723464965820312
Batch 34/64 loss: 0.1983788013458252
Batch 35/64 loss: 0.19808989763259888
Batch 36/64 loss: 0.20090645551681519
Batch 37/64 loss: 0.19829708337783813
Batch 38/64 loss: 0.19871705770492554
Batch 39/64 loss: 0.2018294334411621
Batch 40/64 loss: 0.18722069263458252
Batch 41/64 loss: 0.1947420835494995
Batch 42/64 loss: 0.19255805015563965
Batch 43/64 loss: 0.18401753902435303
Batch 44/64 loss: 0.1936248540878296
Batch 45/64 loss: 0.1779077649116516
Batch 46/64 loss: 0.18879562616348267
Batch 47/64 loss: 0.19511812925338745
Batch 48/64 loss: 0.18968498706817627
Batch 49/64 loss: 0.19084292650222778
Batch 50/64 loss: 0.18493592739105225
Batch 51/64 loss: 0.19102174043655396
Batch 52/64 loss: 0.1888095736503601
Batch 53/64 loss: 0.18488085269927979
Batch 54/64 loss: 0.20552194118499756
Batch 55/64 loss: 0.18299680948257446
Batch 56/64 loss: 0.18952035903930664
Batch 57/64 loss: 0.17865967750549316
Batch 58/64 loss: 0.20890414714813232
Batch 59/64 loss: 0.19480788707733154
Batch 60/64 loss: 0.19885575771331787
Batch 61/64 loss: 0.18371093273162842
Batch 62/64 loss: 0.19340384006500244
Batch 63/64 loss: 0.2016037106513977
Batch 64/64 loss: 0.1943223476409912
Epoch 453  Train loss: 0.1914943863363827  Val loss: 0.2995295334108097
Epoch 454
-------------------------------
Batch 1/64 loss: 0.19013243913650513
Batch 2/64 loss: 0.18462687730789185
Batch 3/64 loss: 0.19269227981567383
Batch 4/64 loss: 0.1867315173149109
Batch 5/64 loss: 0.18652504682540894
Batch 6/64 loss: 0.18713533878326416
Batch 7/64 loss: 0.1939806342124939
Batch 8/64 loss: 0.20707261562347412
Batch 9/64 loss: 0.1904265284538269
Batch 10/64 loss: 0.18821924924850464
Batch 11/64 loss: 0.17940956354141235
Batch 12/64 loss: 0.1909792423248291
Batch 13/64 loss: 0.1890425682067871
Batch 14/64 loss: 0.20575475692749023
Batch 15/64 loss: 0.1893368363380432
Batch 16/64 loss: 0.19338470697402954
Batch 17/64 loss: 0.20138907432556152
Batch 18/64 loss: 0.20891547203063965
Batch 19/64 loss: 0.18948698043823242
Batch 20/64 loss: 0.18380719423294067
Batch 21/64 loss: 0.1860029101371765
Batch 22/64 loss: 0.19615131616592407
Batch 23/64 loss: 0.18287289142608643
Batch 24/64 loss: 0.20063918828964233
Batch 25/64 loss: 0.19047296047210693
Batch 26/64 loss: 0.21195363998413086
Batch 27/64 loss: 0.18926787376403809
Batch 28/64 loss: 0.1974564790725708
Batch 29/64 loss: 0.18796342611312866
Batch 30/64 loss: 0.19238197803497314
Batch 31/64 loss: 0.18433725833892822
Batch 32/64 loss: 0.194158136844635
Batch 33/64 loss: 0.1990722417831421
Batch 34/64 loss: 0.18048125505447388
Batch 35/64 loss: 0.18526172637939453
Batch 36/64 loss: 0.19661080837249756
Batch 37/64 loss: 0.18241316080093384
Batch 38/64 loss: 0.18915927410125732
Batch 39/64 loss: 0.19614940881729126
Batch 40/64 loss: 0.1915358304977417
Batch 41/64 loss: 0.18996328115463257
Batch 42/64 loss: 0.19320011138916016
Batch 43/64 loss: 0.1838221549987793
Batch 44/64 loss: 0.18587064743041992
Batch 45/64 loss: 0.2058885097503662
Batch 46/64 loss: 0.18612074851989746
Batch 47/64 loss: 0.1995633840560913
Batch 48/64 loss: 0.18420112133026123
Batch 49/64 loss: 0.1829649806022644
Batch 50/64 loss: 0.1934812068939209
Batch 51/64 loss: 0.18547600507736206
Batch 52/64 loss: 0.1924557089805603
Batch 53/64 loss: 0.18345773220062256
Batch 54/64 loss: 0.21956437826156616
Batch 55/64 loss: 0.19724881649017334
Batch 56/64 loss: 0.1885811686515808
Batch 57/64 loss: 0.1948709487915039
Batch 58/64 loss: 0.19195842742919922
Batch 59/64 loss: 0.18540310859680176
Batch 60/64 loss: 0.1877463459968567
Batch 61/64 loss: 0.19394463300704956
Batch 62/64 loss: 0.19174867868423462
Batch 63/64 loss: 0.19750815629959106
Batch 64/64 loss: 0.1866421103477478
Epoch 454  Train loss: 0.19181823566848155  Val loss: 0.298567596784572
Epoch 455
-------------------------------
Batch 1/64 loss: 0.18585550785064697
Batch 2/64 loss: 0.18804967403411865
Batch 3/64 loss: 0.197418212890625
Batch 4/64 loss: 0.19721102714538574
Batch 5/64 loss: 0.19190502166748047
Batch 6/64 loss: 0.1880057454109192
Batch 7/64 loss: 0.19506436586380005
Batch 8/64 loss: 0.18700820207595825
Batch 9/64 loss: 0.18908697366714478
Batch 10/64 loss: 0.1988477110862732
Batch 11/64 loss: 0.19157302379608154
Batch 12/64 loss: 0.19052350521087646
Batch 13/64 loss: 0.19325149059295654
Batch 14/64 loss: 0.1839866042137146
Batch 15/64 loss: 0.185105562210083
Batch 16/64 loss: 0.18613547086715698
Batch 17/64 loss: 0.1930113434791565
Batch 18/64 loss: 0.20174086093902588
Batch 19/64 loss: 0.1808685064315796
Batch 20/64 loss: 0.19495654106140137
Batch 21/64 loss: 0.19033479690551758
Batch 22/64 loss: 0.1987050175666809
Batch 23/64 loss: 0.1936042308807373
Batch 24/64 loss: 0.1997630000114441
Batch 25/64 loss: 0.1945204734802246
Batch 26/64 loss: 0.19616806507110596
Batch 27/64 loss: 0.19026535749435425
Batch 28/64 loss: 0.18885385990142822
Batch 29/64 loss: 0.18763232231140137
Batch 30/64 loss: 0.18682003021240234
Batch 31/64 loss: 0.1898704171180725
Batch 32/64 loss: 0.18482351303100586
Batch 33/64 loss: 0.19064068794250488
Batch 34/64 loss: 0.18362540006637573
Batch 35/64 loss: 0.18530482053756714
Batch 36/64 loss: 0.20761984586715698
Batch 37/64 loss: 0.18403106927871704
Batch 38/64 loss: 0.20377981662750244
Batch 39/64 loss: 0.19718122482299805
Batch 40/64 loss: 0.1834903359413147
Batch 41/64 loss: 0.1778978705406189
Batch 42/64 loss: 0.18318212032318115
Batch 43/64 loss: 0.1816692352294922
Batch 44/64 loss: 0.19932478666305542
Batch 45/64 loss: 0.17836332321166992
Batch 46/64 loss: 0.1871381402015686
Batch 47/64 loss: 0.18738943338394165
Batch 48/64 loss: 0.18101340532302856
Batch 49/64 loss: 0.21134918928146362
Batch 50/64 loss: 0.1782960295677185
Batch 51/64 loss: 0.19026345014572144
Batch 52/64 loss: 0.18191522359848022
Batch 53/64 loss: 0.1889398694038391
Batch 54/64 loss: 0.20568329095840454
Batch 55/64 loss: 0.1849324107170105
Batch 56/64 loss: 0.19212603569030762
Batch 57/64 loss: 0.21394550800323486
Batch 58/64 loss: 0.19071215391159058
Batch 59/64 loss: 0.18656373023986816
Batch 60/64 loss: 0.18891692161560059
Batch 61/64 loss: 0.1900903582572937
Batch 62/64 loss: 0.20044755935668945
Batch 63/64 loss: 0.1889110803604126
Batch 64/64 loss: 0.2062423825263977
Epoch 455  Train loss: 0.1910649811520296  Val loss: 0.2992243889680843
Epoch 456
-------------------------------
Batch 1/64 loss: 0.18788713216781616
Batch 2/64 loss: 0.1791905164718628
Batch 3/64 loss: 0.18545657396316528
Batch 4/64 loss: 0.18695569038391113
Batch 5/64 loss: 0.18963712453842163
Batch 6/64 loss: 0.1927260160446167
Batch 7/64 loss: 0.1895047426223755
Batch 8/64 loss: 0.19928878545761108
Batch 9/64 loss: 0.18748408555984497
Batch 10/64 loss: 0.1773914098739624
Batch 11/64 loss: 0.19149357080459595
Batch 12/64 loss: 0.19108760356903076
Batch 13/64 loss: 0.20419442653656006
Batch 14/64 loss: 0.20089775323867798
Batch 15/64 loss: 0.19123470783233643
Batch 16/64 loss: 0.19062930345535278
Batch 17/64 loss: 0.1927715539932251
Batch 18/64 loss: 0.18580186367034912
Batch 19/64 loss: 0.18775546550750732
Batch 20/64 loss: 0.19054752588272095
Batch 21/64 loss: 0.18777793645858765
Batch 22/64 loss: 0.18381661176681519
Batch 23/64 loss: 0.19852590560913086
Batch 24/64 loss: 0.1914762258529663
Batch 25/64 loss: 0.19070124626159668
Batch 26/64 loss: 0.18895810842514038
Batch 27/64 loss: 0.19748365879058838
Batch 28/64 loss: 0.20751476287841797
Batch 29/64 loss: 0.20554715394973755
Batch 30/64 loss: 0.18389242887496948
Batch 31/64 loss: 0.18445760011672974
Batch 32/64 loss: 0.19350570440292358
Batch 33/64 loss: 0.20411348342895508
Batch 34/64 loss: 0.1803121566772461
Batch 35/64 loss: 0.18933457136154175
Batch 36/64 loss: 0.1884790062904358
Batch 37/64 loss: 0.19040274620056152
Batch 38/64 loss: 0.1791439652442932
Batch 39/64 loss: 0.1909356713294983
Batch 40/64 loss: 0.19082283973693848
Batch 41/64 loss: 0.1810280680656433
Batch 42/64 loss: 0.20570522546768188
Batch 43/64 loss: 0.1901702880859375
Batch 44/64 loss: 0.20063018798828125
Batch 45/64 loss: 0.19036400318145752
Batch 46/64 loss: 0.19918233156204224
Batch 47/64 loss: 0.180231511592865
Batch 48/64 loss: 0.19135034084320068
Batch 49/64 loss: 0.2066536545753479
Batch 50/64 loss: 0.18686902523040771
Batch 51/64 loss: 0.19332683086395264
Batch 52/64 loss: 0.18545585870742798
Batch 53/64 loss: 0.17922592163085938
Batch 54/64 loss: 0.1853998899459839
Batch 55/64 loss: 0.1881340742111206
Batch 56/64 loss: 0.18907898664474487
Batch 57/64 loss: 0.1933923363685608
Batch 58/64 loss: 0.19405412673950195
Batch 59/64 loss: 0.18588978052139282
Batch 60/64 loss: 0.21629130840301514
Batch 61/64 loss: 0.19397878646850586
Batch 62/64 loss: 0.19625556468963623
Batch 63/64 loss: 0.1974102258682251
Batch 64/64 loss: 0.19208621978759766
Epoch 456  Train loss: 0.19142400984670602  Val loss: 0.2987290631045181
Epoch 457
-------------------------------
Batch 1/64 loss: 0.1851329803466797
Batch 2/64 loss: 0.20181947946548462
Batch 3/64 loss: 0.1841357946395874
Batch 4/64 loss: 0.18638336658477783
Batch 5/64 loss: 0.19906657934188843
Batch 6/64 loss: 0.19236522912979126
Batch 7/64 loss: 0.18821513652801514
Batch 8/64 loss: 0.18816429376602173
Batch 9/64 loss: 0.1782294511795044
Batch 10/64 loss: 0.19342917203903198
Batch 11/64 loss: 0.18765270709991455
Batch 12/64 loss: 0.1984727382659912
Batch 13/64 loss: 0.19124746322631836
Batch 14/64 loss: 0.1838739514350891
Batch 15/64 loss: 0.18120509386062622
Batch 16/64 loss: 0.190820574760437
Batch 17/64 loss: 0.18692344427108765
Batch 18/64 loss: 0.19551962614059448
Batch 19/64 loss: 0.1941436529159546
Batch 20/64 loss: 0.19665682315826416
Batch 21/64 loss: 0.18331271409988403
Batch 22/64 loss: 0.1946854591369629
Batch 23/64 loss: 0.18718290328979492
Batch 24/64 loss: 0.21781057119369507
Batch 25/64 loss: 0.18619120121002197
Batch 26/64 loss: 0.18383800983428955
Batch 27/64 loss: 0.1936923861503601
Batch 28/64 loss: 0.19676488637924194
Batch 29/64 loss: 0.1906682848930359
Batch 30/64 loss: 0.19345849752426147
Batch 31/64 loss: 0.19714617729187012
Batch 32/64 loss: 0.19144046306610107
Batch 33/64 loss: 0.18745267391204834
Batch 34/64 loss: 0.20418643951416016
Batch 35/64 loss: 0.19615572690963745
Batch 36/64 loss: 0.18530112504959106
Batch 37/64 loss: 0.19280970096588135
Batch 38/64 loss: 0.1926497220993042
Batch 39/64 loss: 0.18874382972717285
Batch 40/64 loss: 0.1860814094543457
Batch 41/64 loss: 0.17759859561920166
Batch 42/64 loss: 0.20470666885375977
Batch 43/64 loss: 0.19717776775360107
Batch 44/64 loss: 0.18215811252593994
Batch 45/64 loss: 0.19874131679534912
Batch 46/64 loss: 0.1901012659072876
Batch 47/64 loss: 0.20005923509597778
Batch 48/64 loss: 0.19930273294448853
Batch 49/64 loss: 0.18458926677703857
Batch 50/64 loss: 0.18436074256896973
Batch 51/64 loss: 0.19222062826156616
Batch 52/64 loss: 0.19325870275497437
Batch 53/64 loss: 0.1900639533996582
Batch 54/64 loss: 0.18265628814697266
Batch 55/64 loss: 0.1936766505241394
Batch 56/64 loss: 0.19467419385910034
Batch 57/64 loss: 0.18348157405853271
Batch 58/64 loss: 0.19915330410003662
Batch 59/64 loss: 0.19627857208251953
Batch 60/64 loss: 0.187749445438385
Batch 61/64 loss: 0.2023327350616455
Batch 62/64 loss: 0.1786050796508789
Batch 63/64 loss: 0.187486469745636
Batch 64/64 loss: 0.19812703132629395
Epoch 457  Train loss: 0.19140483631807215  Val loss: 0.2994166794921115
Epoch 458
-------------------------------
Batch 1/64 loss: 0.18937581777572632
Batch 2/64 loss: 0.19039970636367798
Batch 3/64 loss: 0.18970829248428345
Batch 4/64 loss: 0.18342047929763794
Batch 5/64 loss: 0.18405258655548096
Batch 6/64 loss: 0.19420254230499268
Batch 7/64 loss: 0.19299256801605225
Batch 8/64 loss: 0.1984539031982422
Batch 9/64 loss: 0.19267690181732178
Batch 10/64 loss: 0.18885481357574463
Batch 11/64 loss: 0.18780434131622314
Batch 12/64 loss: 0.18766486644744873
Batch 13/64 loss: 0.1970474123954773
Batch 14/64 loss: 0.18539702892303467
Batch 15/64 loss: 0.1889559030532837
Batch 16/64 loss: 0.1940106749534607
Batch 17/64 loss: 0.18326979875564575
Batch 18/64 loss: 0.19839024543762207
Batch 19/64 loss: 0.19030630588531494
Batch 20/64 loss: 0.1789473295211792
Batch 21/64 loss: 0.19152945280075073
Batch 22/64 loss: 0.20058536529541016
Batch 23/64 loss: 0.19035863876342773
Batch 24/64 loss: 0.1925123929977417
Batch 25/64 loss: 0.19104814529418945
Batch 26/64 loss: 0.1864749789237976
Batch 27/64 loss: 0.1825580596923828
Batch 28/64 loss: 0.18504250049591064
Batch 29/64 loss: 0.20481252670288086
Batch 30/64 loss: 0.18429148197174072
Batch 31/64 loss: 0.19377708435058594
Batch 32/64 loss: 0.19171291589736938
Batch 33/64 loss: 0.193378746509552
Batch 34/64 loss: 0.19093531370162964
Batch 35/64 loss: 0.18256402015686035
Batch 36/64 loss: 0.1925840973854065
Batch 37/64 loss: 0.20409083366394043
Batch 38/64 loss: 0.19284915924072266
Batch 39/64 loss: 0.19607484340667725
Batch 40/64 loss: 0.18923330307006836
Batch 41/64 loss: 0.18423092365264893
Batch 42/64 loss: 0.18766134977340698
Batch 43/64 loss: 0.188107430934906
Batch 44/64 loss: 0.18216538429260254
Batch 45/64 loss: 0.18320125341415405
Batch 46/64 loss: 0.18646866083145142
Batch 47/64 loss: 0.19137966632843018
Batch 48/64 loss: 0.18813550472259521
Batch 49/64 loss: 0.20649641752243042
Batch 50/64 loss: 0.1873711347579956
Batch 51/64 loss: 0.20534276962280273
Batch 52/64 loss: 0.19020730257034302
Batch 53/64 loss: 0.18136858940124512
Batch 54/64 loss: 0.1867009401321411
Batch 55/64 loss: 0.19649314880371094
Batch 56/64 loss: 0.19291990995407104
Batch 57/64 loss: 0.1895429491996765
Batch 58/64 loss: 0.19281792640686035
Batch 59/64 loss: 0.18490052223205566
Batch 60/64 loss: 0.1908646821975708
Batch 61/64 loss: 0.19368016719818115
Batch 62/64 loss: 0.19978314638137817
Batch 63/64 loss: 0.19809943437576294
Batch 64/64 loss: 0.18318617343902588
Epoch 458  Train loss: 0.19070861526564056  Val loss: 0.2984242429028672
Epoch 459
-------------------------------
Batch 1/64 loss: 0.18446791172027588
Batch 2/64 loss: 0.19064444303512573
Batch 3/64 loss: 0.19629251956939697
Batch 4/64 loss: 0.18626415729522705
Batch 5/64 loss: 0.17986524105072021
Batch 6/64 loss: 0.19062161445617676
Batch 7/64 loss: 0.19423800706863403
Batch 8/64 loss: 0.1831291913986206
Batch 9/64 loss: 0.19040918350219727
Batch 10/64 loss: 0.18344521522521973
Batch 11/64 loss: 0.19405484199523926
Batch 12/64 loss: 0.21024179458618164
Batch 13/64 loss: 0.187322199344635
Batch 14/64 loss: 0.19035017490386963
Batch 15/64 loss: 0.18365710973739624
Batch 16/64 loss: 0.1879785656929016
Batch 17/64 loss: 0.1965329647064209
Batch 18/64 loss: 0.1980237364768982
Batch 19/64 loss: 0.2000964879989624
Batch 20/64 loss: 0.18645524978637695
Batch 21/64 loss: 0.20836114883422852
Batch 22/64 loss: 0.2005244493484497
Batch 23/64 loss: 0.195298969745636
Batch 24/64 loss: 0.2080744504928589
Batch 25/64 loss: 0.19763588905334473
Batch 26/64 loss: 0.19333219528198242
Batch 27/64 loss: 0.19363152980804443
Batch 28/64 loss: 0.18043744564056396
Batch 29/64 loss: 0.18984317779541016
Batch 30/64 loss: 0.18044990301132202
Batch 31/64 loss: 0.19460785388946533
Batch 32/64 loss: 0.200214684009552
Batch 33/64 loss: 0.1816372275352478
Batch 34/64 loss: 0.1946735978126526
Batch 35/64 loss: 0.20104175806045532
Batch 36/64 loss: 0.19531148672103882
Batch 37/64 loss: 0.18772202730178833
Batch 38/64 loss: 0.19124078750610352
Batch 39/64 loss: 0.183149516582489
Batch 40/64 loss: 0.19801992177963257
Batch 41/64 loss: 0.18858009576797485
Batch 42/64 loss: 0.18559831380844116
Batch 43/64 loss: 0.20182162523269653
Batch 44/64 loss: 0.18828517198562622
Batch 45/64 loss: 0.19004404544830322
Batch 46/64 loss: 0.18580186367034912
Batch 47/64 loss: 0.1850268840789795
Batch 48/64 loss: 0.19767063856124878
Batch 49/64 loss: 0.18200719356536865
Batch 50/64 loss: 0.18442988395690918
Batch 51/64 loss: 0.18542999029159546
Batch 52/64 loss: 0.19776219129562378
Batch 53/64 loss: 0.18254423141479492
Batch 54/64 loss: 0.18222254514694214
Batch 55/64 loss: 0.18473482131958008
Batch 56/64 loss: 0.18732470273971558
Batch 57/64 loss: 0.19431740045547485
Batch 58/64 loss: 0.19270509481430054
Batch 59/64 loss: 0.205841064453125
Batch 60/64 loss: 0.18285775184631348
Batch 61/64 loss: 0.18895918130874634
Batch 62/64 loss: 0.19089221954345703
Batch 63/64 loss: 0.1857956051826477
Batch 64/64 loss: 0.20131319761276245
Epoch 459  Train loss: 0.1912303693154279  Val loss: 0.2990640197013252
Epoch 460
-------------------------------
Batch 1/64 loss: 0.19337499141693115
Batch 2/64 loss: 0.1919708251953125
Batch 3/64 loss: 0.19295376539230347
Batch 4/64 loss: 0.19902342557907104
Batch 5/64 loss: 0.20057189464569092
Batch 6/64 loss: 0.18555212020874023
Batch 7/64 loss: 0.18161344528198242
Batch 8/64 loss: 0.20390623807907104
Batch 9/64 loss: 0.182789146900177
Batch 10/64 loss: 0.18968284130096436
Batch 11/64 loss: 0.19121259450912476
Batch 12/64 loss: 0.19299757480621338
Batch 13/64 loss: 0.18334746360778809
Batch 14/64 loss: 0.18937021493911743
Batch 15/64 loss: 0.18640923500061035
Batch 16/64 loss: 0.1888788938522339
Batch 17/64 loss: 0.18800246715545654
Batch 18/64 loss: 0.19898128509521484
Batch 19/64 loss: 0.203582763671875
Batch 20/64 loss: 0.1949363350868225
Batch 21/64 loss: 0.19179511070251465
Batch 22/64 loss: 0.18671607971191406
Batch 23/64 loss: 0.18691670894622803
Batch 24/64 loss: 0.19146263599395752
Batch 25/64 loss: 0.20362669229507446
Batch 26/64 loss: 0.19334250688552856
Batch 27/64 loss: 0.18442928791046143
Batch 28/64 loss: 0.1785123348236084
Batch 29/64 loss: 0.19591552019119263
Batch 30/64 loss: 0.193148672580719
Batch 31/64 loss: 0.1857725977897644
Batch 32/64 loss: 0.18531757593154907
Batch 33/64 loss: 0.20333409309387207
Batch 34/64 loss: 0.17637354135513306
Batch 35/64 loss: 0.18628346920013428
Batch 36/64 loss: 0.19572579860687256
Batch 37/64 loss: 0.18557137250900269
Batch 38/64 loss: 0.19491136074066162
Batch 39/64 loss: 0.1852344274520874
Batch 40/64 loss: 0.1904628872871399
Batch 41/64 loss: 0.19069844484329224
Batch 42/64 loss: 0.19657647609710693
Batch 43/64 loss: 0.1961023211479187
Batch 44/64 loss: 0.1844434142112732
Batch 45/64 loss: 0.19465476274490356
Batch 46/64 loss: 0.1949375867843628
Batch 47/64 loss: 0.20832163095474243
Batch 48/64 loss: 0.19535976648330688
Batch 49/64 loss: 0.2023754119873047
Batch 50/64 loss: 0.18833792209625244
Batch 51/64 loss: 0.19706660509109497
Batch 52/64 loss: 0.18467062711715698
Batch 53/64 loss: 0.19242465496063232
Batch 54/64 loss: 0.1963111162185669
Batch 55/64 loss: 0.19246774911880493
Batch 56/64 loss: 0.18178790807724
Batch 57/64 loss: 0.1941615343093872
Batch 58/64 loss: 0.2061091661453247
Batch 59/64 loss: 0.1890607476234436
Batch 60/64 loss: 0.18887829780578613
Batch 61/64 loss: 0.18582016229629517
Batch 62/64 loss: 0.196100115776062
Batch 63/64 loss: 0.1848583221435547
Batch 64/64 loss: 0.1871553659439087
Epoch 460  Train loss: 0.19162198375253117  Val loss: 0.2994713945077457
Epoch 461
-------------------------------
Batch 1/64 loss: 0.18793201446533203
Batch 2/64 loss: 0.18504709005355835
Batch 3/64 loss: 0.20976507663726807
Batch 4/64 loss: 0.20349979400634766
Batch 5/64 loss: 0.19363486766815186
Batch 6/64 loss: 0.20098793506622314
Batch 7/64 loss: 0.18853557109832764
Batch 8/64 loss: 0.18891072273254395
Batch 9/64 loss: 0.19149422645568848
Batch 10/64 loss: 0.19187712669372559
Batch 11/64 loss: 0.18590134382247925
Batch 12/64 loss: 0.19716590642929077
Batch 13/64 loss: 0.18511414527893066
Batch 14/64 loss: 0.18749970197677612
Batch 15/64 loss: 0.1866024136543274
Batch 16/64 loss: 0.1887548565864563
Batch 17/64 loss: 0.1865842342376709
Batch 18/64 loss: 0.1955338716506958
Batch 19/64 loss: 0.18404340744018555
Batch 20/64 loss: 0.1904834508895874
Batch 21/64 loss: 0.18983763456344604
Batch 22/64 loss: 0.18506121635437012
Batch 23/64 loss: 0.1856580376625061
Batch 24/64 loss: 0.1865924596786499
Batch 25/64 loss: 0.190407395362854
Batch 26/64 loss: 0.19042742252349854
Batch 27/64 loss: 0.19682782888412476
Batch 28/64 loss: 0.19079184532165527
Batch 29/64 loss: 0.1861528754234314
Batch 30/64 loss: 0.19000846147537231
Batch 31/64 loss: 0.18811661005020142
Batch 32/64 loss: 0.18506896495819092
Batch 33/64 loss: 0.18411314487457275
Batch 34/64 loss: 0.2032654881477356
Batch 35/64 loss: 0.1906135082244873
Batch 36/64 loss: 0.18697738647460938
Batch 37/64 loss: 0.18211495876312256
Batch 38/64 loss: 0.19500619173049927
Batch 39/64 loss: 0.18874764442443848
Batch 40/64 loss: 0.19427013397216797
Batch 41/64 loss: 0.18696993589401245
Batch 42/64 loss: 0.18495619297027588
Batch 43/64 loss: 0.1983965039253235
Batch 44/64 loss: 0.19740962982177734
Batch 45/64 loss: 0.19177109003067017
Batch 46/64 loss: 0.1977543830871582
Batch 47/64 loss: 0.1903994083404541
Batch 48/64 loss: 0.19479304552078247
Batch 49/64 loss: 0.2024322748184204
Batch 50/64 loss: 0.19696301221847534
Batch 51/64 loss: 0.18380039930343628
Batch 52/64 loss: 0.21175873279571533
Batch 53/64 loss: 0.19911551475524902
Batch 54/64 loss: 0.18835663795471191
Batch 55/64 loss: 0.17966437339782715
Batch 56/64 loss: 0.1883057951927185
Batch 57/64 loss: 0.1918332576751709
Batch 58/64 loss: 0.18154191970825195
Batch 59/64 loss: 0.18117940425872803
Batch 60/64 loss: 0.17794495820999146
Batch 61/64 loss: 0.19774556159973145
Batch 62/64 loss: 0.18991607427597046
Batch 63/64 loss: 0.19381952285766602
Batch 64/64 loss: 0.1968821883201599
Epoch 461  Train loss: 0.19096339193044926  Val loss: 0.299747899225897
Epoch 462
-------------------------------
Batch 1/64 loss: 0.18492454290390015
Batch 2/64 loss: 0.18409162759780884
Batch 3/64 loss: 0.1909557580947876
Batch 4/64 loss: 0.18034672737121582
Batch 5/64 loss: 0.19621187448501587
Batch 6/64 loss: 0.19381731748580933
Batch 7/64 loss: 0.18686038255691528
Batch 8/64 loss: 0.18664002418518066
Batch 9/64 loss: 0.2183694839477539
Batch 10/64 loss: 0.19490200281143188
Batch 11/64 loss: 0.18392807245254517
Batch 12/64 loss: 0.1936507225036621
Batch 13/64 loss: 0.18418776988983154
Batch 14/64 loss: 0.19695478677749634
Batch 15/64 loss: 0.19836539030075073
Batch 16/64 loss: 0.19484370946884155
Batch 17/64 loss: 0.20089852809906006
Batch 18/64 loss: 0.18543386459350586
Batch 19/64 loss: 0.18202590942382812
Batch 20/64 loss: 0.18283361196517944
Batch 21/64 loss: 0.18968290090560913
Batch 22/64 loss: 0.17871320247650146
Batch 23/64 loss: 0.1955825686454773
Batch 24/64 loss: 0.1923263669013977
Batch 25/64 loss: 0.19029664993286133
Batch 26/64 loss: 0.19584858417510986
Batch 27/64 loss: 0.17949604988098145
Batch 28/64 loss: 0.20030814409255981
Batch 29/64 loss: 0.18895524740219116
Batch 30/64 loss: 0.20098304748535156
Batch 31/64 loss: 0.18946146965026855
Batch 32/64 loss: 0.21088188886642456
Batch 33/64 loss: 0.19689828157424927
Batch 34/64 loss: 0.18463432788848877
Batch 35/64 loss: 0.20403069257736206
Batch 36/64 loss: 0.18647164106369019
Batch 37/64 loss: 0.19357824325561523
Batch 38/64 loss: 0.19731295108795166
Batch 39/64 loss: 0.1913224458694458
Batch 40/64 loss: 0.19332796335220337
Batch 41/64 loss: 0.19761770963668823
Batch 42/64 loss: 0.18864446878433228
Batch 43/64 loss: 0.20886218547821045
Batch 44/64 loss: 0.19570618867874146
Batch 45/64 loss: 0.20220947265625
Batch 46/64 loss: 0.18437576293945312
Batch 47/64 loss: 0.181479811668396
Batch 48/64 loss: 0.19792819023132324
Batch 49/64 loss: 0.19504165649414062
Batch 50/64 loss: 0.1905224323272705
Batch 51/64 loss: 0.1856393814086914
Batch 52/64 loss: 0.19214916229248047
Batch 53/64 loss: 0.1932220458984375
Batch 54/64 loss: 0.18266916275024414
Batch 55/64 loss: 0.19333338737487793
Batch 56/64 loss: 0.18852782249450684
Batch 57/64 loss: 0.18182647228240967
Batch 58/64 loss: 0.20224851369857788
Batch 59/64 loss: 0.18549412488937378
Batch 60/64 loss: 0.190626859664917
Batch 61/64 loss: 0.18562918901443481
Batch 62/64 loss: 0.17907971143722534
Batch 63/64 loss: 0.18733108043670654
Batch 64/64 loss: 0.19261574745178223
Epoch 462  Train loss: 0.19160755101372215  Val loss: 0.2994786902391624
Epoch 463
-------------------------------
Batch 1/64 loss: 0.18874424695968628
Batch 2/64 loss: 0.17921829223632812
Batch 3/64 loss: 0.1793110966682434
Batch 4/64 loss: 0.18627721071243286
Batch 5/64 loss: 0.17633193731307983
Batch 6/64 loss: 0.1857042908668518
Batch 7/64 loss: 0.18798810243606567
Batch 8/64 loss: 0.19844269752502441
Batch 9/64 loss: 0.19503343105316162
Batch 10/64 loss: 0.1951974630355835
Batch 11/64 loss: 0.17876112461090088
Batch 12/64 loss: 0.1886083483695984
Batch 13/64 loss: 0.18484508991241455
Batch 14/64 loss: 0.1964004635810852
Batch 15/64 loss: 0.1871882677078247
Batch 16/64 loss: 0.1828317642211914
Batch 17/64 loss: 0.1921616792678833
Batch 18/64 loss: 0.18381094932556152
Batch 19/64 loss: 0.18160951137542725
Batch 20/64 loss: 0.18670451641082764
Batch 21/64 loss: 0.1869715452194214
Batch 22/64 loss: 0.18513387441635132
Batch 23/64 loss: 0.1824539303779602
Batch 24/64 loss: 0.18776994943618774
Batch 25/64 loss: 0.18786442279815674
Batch 26/64 loss: 0.19616365432739258
Batch 27/64 loss: 0.19379806518554688
Batch 28/64 loss: 0.1811268925666809
Batch 29/64 loss: 0.1790245771408081
Batch 30/64 loss: 0.18784654140472412
Batch 31/64 loss: 0.19814318418502808
Batch 32/64 loss: 0.18669068813323975
Batch 33/64 loss: 0.19498991966247559
Batch 34/64 loss: 0.19358456134796143
Batch 35/64 loss: 0.18465697765350342
Batch 36/64 loss: 0.19591999053955078
Batch 37/64 loss: 0.19210445880889893
Batch 38/64 loss: 0.20959734916687012
Batch 39/64 loss: 0.19662392139434814
Batch 40/64 loss: 0.18900078535079956
Batch 41/64 loss: 0.2026432752609253
Batch 42/64 loss: 0.1906720995903015
Batch 43/64 loss: 0.18729126453399658
Batch 44/64 loss: 0.18164831399917603
Batch 45/64 loss: 0.18463671207427979
Batch 46/64 loss: 0.19101303815841675
Batch 47/64 loss: 0.20761263370513916
Batch 48/64 loss: 0.19888156652450562
Batch 49/64 loss: 0.20213204622268677
Batch 50/64 loss: 0.1977623701095581
Batch 51/64 loss: 0.19932854175567627
Batch 52/64 loss: 0.18341344594955444
Batch 53/64 loss: 0.19126015901565552
Batch 54/64 loss: 0.1917111873626709
Batch 55/64 loss: 0.18642181158065796
Batch 56/64 loss: 0.19322532415390015
Batch 57/64 loss: 0.19696199893951416
Batch 58/64 loss: 0.2054329514503479
Batch 59/64 loss: 0.19708478450775146
Batch 60/64 loss: 0.19573450088500977
Batch 61/64 loss: 0.191525399684906
Batch 62/64 loss: 0.19337856769561768
Batch 63/64 loss: 0.18407684564590454
Batch 64/64 loss: 0.20079267024993896
Epoch 463  Train loss: 0.19057379002664604  Val loss: 0.29890237231434824
Epoch 464
-------------------------------
Batch 1/64 loss: 0.2036834955215454
Batch 2/64 loss: 0.18379974365234375
Batch 3/64 loss: 0.1934802532196045
Batch 4/64 loss: 0.18689405918121338
Batch 5/64 loss: 0.18959516286849976
Batch 6/64 loss: 0.18442028760910034
Batch 7/64 loss: 0.18834030628204346
Batch 8/64 loss: 0.18882441520690918
Batch 9/64 loss: 0.18705463409423828
Batch 10/64 loss: 0.17989581823349
Batch 11/64 loss: 0.19013261795043945
Batch 12/64 loss: 0.20600658655166626
Batch 13/64 loss: 0.19244831800460815
Batch 14/64 loss: 0.1893647313117981
Batch 15/64 loss: 0.18928128480911255
Batch 16/64 loss: 0.1924678087234497
Batch 17/64 loss: 0.19121509790420532
Batch 18/64 loss: 0.19312113523483276
Batch 19/64 loss: 0.18497931957244873
Batch 20/64 loss: 0.1852717399597168
Batch 21/64 loss: 0.18573671579360962
Batch 22/64 loss: 0.193037748336792
Batch 23/64 loss: 0.1881951093673706
Batch 24/64 loss: 0.18463146686553955
Batch 25/64 loss: 0.2011927366256714
Batch 26/64 loss: 0.1860290765762329
Batch 27/64 loss: 0.1878112554550171
Batch 28/64 loss: 0.19687962532043457
Batch 29/64 loss: 0.19402867555618286
Batch 30/64 loss: 0.18796217441558838
Batch 31/64 loss: 0.18082541227340698
Batch 32/64 loss: 0.1936500072479248
Batch 33/64 loss: 0.19158530235290527
Batch 34/64 loss: 0.1806125044822693
Batch 35/64 loss: 0.195837140083313
Batch 36/64 loss: 0.18326067924499512
Batch 37/64 loss: 0.18768703937530518
Batch 38/64 loss: 0.19431012868881226
Batch 39/64 loss: 0.18747824430465698
Batch 40/64 loss: 0.18672072887420654
Batch 41/64 loss: 0.1849626898765564
Batch 42/64 loss: 0.18461143970489502
Batch 43/64 loss: 0.18312036991119385
Batch 44/64 loss: 0.19107401371002197
Batch 45/64 loss: 0.2043384313583374
Batch 46/64 loss: 0.19832336902618408
Batch 47/64 loss: 0.1828174591064453
Batch 48/64 loss: 0.1874033808708191
Batch 49/64 loss: 0.18431717157363892
Batch 50/64 loss: 0.19055360555648804
Batch 51/64 loss: 0.2013874053955078
Batch 52/64 loss: 0.1948835849761963
Batch 53/64 loss: 0.18979620933532715
Batch 54/64 loss: 0.19146054983139038
Batch 55/64 loss: 0.193947434425354
Batch 56/64 loss: 0.1981295943260193
Batch 57/64 loss: 0.19679522514343262
Batch 58/64 loss: 0.1865275502204895
Batch 59/64 loss: 0.18338274955749512
Batch 60/64 loss: 0.19423794746398926
Batch 61/64 loss: 0.1928226351737976
Batch 62/64 loss: 0.17878657579421997
Batch 63/64 loss: 0.2025442123413086
Batch 64/64 loss: 0.1927870512008667
Epoch 464  Train loss: 0.19025196047390208  Val loss: 0.299453264659213
Epoch 465
-------------------------------
Batch 1/64 loss: 0.19766902923583984
Batch 2/64 loss: 0.1783376932144165
Batch 3/64 loss: 0.19333791732788086
Batch 4/64 loss: 0.19689005613327026
Batch 5/64 loss: 0.1969124674797058
Batch 6/64 loss: 0.18202424049377441
Batch 7/64 loss: 0.20667076110839844
Batch 8/64 loss: 0.1870208978652954
Batch 9/64 loss: 0.20006948709487915
Batch 10/64 loss: 0.18039238452911377
Batch 11/64 loss: 0.18467915058135986
Batch 12/64 loss: 0.19714820384979248
Batch 13/64 loss: 0.18247008323669434
Batch 14/64 loss: 0.1766899824142456
Batch 15/64 loss: 0.18443286418914795
Batch 16/64 loss: 0.1861417293548584
Batch 17/64 loss: 0.1772012710571289
Batch 18/64 loss: 0.18919742107391357
Batch 19/64 loss: 0.2066575288772583
Batch 20/64 loss: 0.18404918909072876
Batch 21/64 loss: 0.18886619806289673
Batch 22/64 loss: 0.18359994888305664
Batch 23/64 loss: 0.191572368144989
Batch 24/64 loss: 0.19067174196243286
Batch 25/64 loss: 0.19692981243133545
Batch 26/64 loss: 0.20025289058685303
Batch 27/64 loss: 0.2067517638206482
Batch 28/64 loss: 0.19790589809417725
Batch 29/64 loss: 0.20720279216766357
Batch 30/64 loss: 0.1936633586883545
Batch 31/64 loss: 0.19295090436935425
Batch 32/64 loss: 0.19688796997070312
Batch 33/64 loss: 0.20697349309921265
Batch 34/64 loss: 0.19098424911499023
Batch 35/64 loss: 0.2058618664741516
Batch 36/64 loss: 0.18315011262893677
Batch 37/64 loss: 0.19189780950546265
Batch 38/64 loss: 0.19578123092651367
Batch 39/64 loss: 0.18787676095962524
Batch 40/64 loss: 0.19589775800704956
Batch 41/64 loss: 0.19480156898498535
Batch 42/64 loss: 0.19307923316955566
Batch 43/64 loss: 0.18534106016159058
Batch 44/64 loss: 0.2016751766204834
Batch 45/64 loss: 0.18809759616851807
Batch 46/64 loss: 0.1956174373626709
Batch 47/64 loss: 0.20156073570251465
Batch 48/64 loss: 0.19814777374267578
Batch 49/64 loss: 0.19082772731781006
Batch 50/64 loss: 0.18813133239746094
Batch 51/64 loss: 0.1973334550857544
Batch 52/64 loss: 0.18820738792419434
Batch 53/64 loss: 0.18503880500793457
Batch 54/64 loss: 0.20155280828475952
Batch 55/64 loss: 0.19082534313201904
Batch 56/64 loss: 0.19402772188186646
Batch 57/64 loss: 0.19138896465301514
Batch 58/64 loss: 0.19652217626571655
Batch 59/64 loss: 0.20202457904815674
Batch 60/64 loss: 0.18285489082336426
Batch 61/64 loss: 0.18785470724105835
Batch 62/64 loss: 0.19077789783477783
Batch 63/64 loss: 0.1906116008758545
Batch 64/64 loss: 0.1909356713294983
Epoch 465  Train loss: 0.1925203610869015  Val loss: 0.29886254248340516
Epoch 466
-------------------------------
Batch 1/64 loss: 0.20691066980361938
Batch 2/64 loss: 0.18072599172592163
Batch 3/64 loss: 0.18216758966445923
Batch 4/64 loss: 0.1894439458847046
Batch 5/64 loss: 0.1867436170578003
Batch 6/64 loss: 0.18303585052490234
Batch 7/64 loss: 0.18412089347839355
Batch 8/64 loss: 0.1996482014656067
Batch 9/64 loss: 0.18896734714508057
Batch 10/64 loss: 0.17476797103881836
Batch 11/64 loss: 0.19027721881866455
Batch 12/64 loss: 0.19764035940170288
Batch 13/64 loss: 0.18595409393310547
Batch 14/64 loss: 0.1873909831047058
Batch 15/64 loss: 0.1799870729446411
Batch 16/64 loss: 0.18131065368652344
Batch 17/64 loss: 0.20157009363174438
Batch 18/64 loss: 0.18141257762908936
Batch 19/64 loss: 0.19793611764907837
Batch 20/64 loss: 0.19479995965957642
Batch 21/64 loss: 0.19357168674468994
Batch 22/64 loss: 0.18355059623718262
Batch 23/64 loss: 0.17499589920043945
Batch 24/64 loss: 0.1856064796447754
Batch 25/64 loss: 0.1850600242614746
Batch 26/64 loss: 0.18513840436935425
Batch 27/64 loss: 0.20279717445373535
Batch 28/64 loss: 0.18457263708114624
Batch 29/64 loss: 0.1984238624572754
Batch 30/64 loss: 0.1876124143600464
Batch 31/64 loss: 0.19110143184661865
Batch 32/64 loss: 0.18585717678070068
Batch 33/64 loss: 0.1841830015182495
Batch 34/64 loss: 0.19877982139587402
Batch 35/64 loss: 0.18692874908447266
Batch 36/64 loss: 0.19794142246246338
Batch 37/64 loss: 0.177862286567688
Batch 38/64 loss: 0.19262033700942993
Batch 39/64 loss: 0.18214690685272217
Batch 40/64 loss: 0.19171196222305298
Batch 41/64 loss: 0.198993980884552
Batch 42/64 loss: 0.17912161350250244
Batch 43/64 loss: 0.18992626667022705
Batch 44/64 loss: 0.19243890047073364
Batch 45/64 loss: 0.1788935661315918
Batch 46/64 loss: 0.1912059783935547
Batch 47/64 loss: 0.1870189905166626
Batch 48/64 loss: 0.18935704231262207
Batch 49/64 loss: 0.1923280954360962
Batch 50/64 loss: 0.1899511218070984
Batch 51/64 loss: 0.19941943883895874
Batch 52/64 loss: 0.1886913776397705
Batch 53/64 loss: 0.1867184042930603
Batch 54/64 loss: 0.19112390279769897
Batch 55/64 loss: 0.1818954348564148
Batch 56/64 loss: 0.18962150812149048
Batch 57/64 loss: 0.18997806310653687
Batch 58/64 loss: 0.19911038875579834
Batch 59/64 loss: 0.19742894172668457
Batch 60/64 loss: 0.19270646572113037
Batch 61/64 loss: 0.20555251836776733
Batch 62/64 loss: 0.1922716498374939
Batch 63/64 loss: 0.1969590187072754
Batch 64/64 loss: 0.19693833589553833
Epoch 466  Train loss: 0.1897049396645789  Val loss: 0.29882272084554035
Epoch 467
-------------------------------
Batch 1/64 loss: 0.19452619552612305
Batch 2/64 loss: 0.19763749837875366
Batch 3/64 loss: 0.19514501094818115
Batch 4/64 loss: 0.19224709272384644
Batch 5/64 loss: 0.19403445720672607
Batch 6/64 loss: 0.18752765655517578
Batch 7/64 loss: 0.1895952820777893
Batch 8/64 loss: 0.1798473596572876
Batch 9/64 loss: 0.19492900371551514
Batch 10/64 loss: 0.1846795678138733
Batch 11/64 loss: 0.1909390687942505
Batch 12/64 loss: 0.1972407102584839
Batch 13/64 loss: 0.17994821071624756
Batch 14/64 loss: 0.1876099705696106
Batch 15/64 loss: 0.18025243282318115
Batch 16/64 loss: 0.18472301959991455
Batch 17/64 loss: 0.20148026943206787
Batch 18/64 loss: 0.18939727544784546
Batch 19/64 loss: 0.19320666790008545
Batch 20/64 loss: 0.19863981008529663
Batch 21/64 loss: 0.18047857284545898
Batch 22/64 loss: 0.19226467609405518
Batch 23/64 loss: 0.18478095531463623
Batch 24/64 loss: 0.17662125825881958
Batch 25/64 loss: 0.1887851357460022
Batch 26/64 loss: 0.17709767818450928
Batch 27/64 loss: 0.1975812315940857
Batch 28/64 loss: 0.1945115327835083
Batch 29/64 loss: 0.18095988035202026
Batch 30/64 loss: 0.19281673431396484
Batch 31/64 loss: 0.18266785144805908
Batch 32/64 loss: 0.1833881139755249
Batch 33/64 loss: 0.19294142723083496
Batch 34/64 loss: 0.1988527774810791
Batch 35/64 loss: 0.18871796131134033
Batch 36/64 loss: 0.17532801628112793
Batch 37/64 loss: 0.1916046142578125
Batch 38/64 loss: 0.18493205308914185
Batch 39/64 loss: 0.1966370940208435
Batch 40/64 loss: 0.21399950981140137
Batch 41/64 loss: 0.19240647554397583
Batch 42/64 loss: 0.18641412258148193
Batch 43/64 loss: 0.18895107507705688
Batch 44/64 loss: 0.1892029047012329
Batch 45/64 loss: 0.19728487730026245
Batch 46/64 loss: 0.1873706579208374
Batch 47/64 loss: 0.18911075592041016
Batch 48/64 loss: 0.19071608781814575
Batch 49/64 loss: 0.19369655847549438
Batch 50/64 loss: 0.19242608547210693
Batch 51/64 loss: 0.18777966499328613
Batch 52/64 loss: 0.1894822120666504
Batch 53/64 loss: 0.19140875339508057
Batch 54/64 loss: 0.19972991943359375
Batch 55/64 loss: 0.21169471740722656
Batch 56/64 loss: 0.2062872052192688
Batch 57/64 loss: 0.18752461671829224
Batch 58/64 loss: 0.20009899139404297
Batch 59/64 loss: 0.18493038415908813
Batch 60/64 loss: 0.1865377426147461
Batch 61/64 loss: 0.19672858715057373
Batch 62/64 loss: 0.18991750478744507
Batch 63/64 loss: 0.1750844120979309
Batch 64/64 loss: 0.19395387172698975
Epoch 467  Train loss: 0.19056977804969338  Val loss: 0.30019674124996276
Epoch 468
-------------------------------
Batch 1/64 loss: 0.19575363397598267
Batch 2/64 loss: 0.19020217657089233
Batch 3/64 loss: 0.19441723823547363
Batch 4/64 loss: 0.17721867561340332
Batch 5/64 loss: 0.17964684963226318
Batch 6/64 loss: 0.18396931886672974
Batch 7/64 loss: 0.18788421154022217
Batch 8/64 loss: 0.1928374171257019
Batch 9/64 loss: 0.1892184615135193
Batch 10/64 loss: 0.205549418926239
Batch 11/64 loss: 0.19534772634506226
Batch 12/64 loss: 0.1878684163093567
Batch 13/64 loss: 0.18859821557998657
Batch 14/64 loss: 0.1811961531639099
Batch 15/64 loss: 0.18309783935546875
Batch 16/64 loss: 0.18685799837112427
Batch 17/64 loss: 0.181596040725708
Batch 18/64 loss: 0.19421184062957764
Batch 19/64 loss: 0.19202595949172974
Batch 20/64 loss: 0.18357479572296143
Batch 21/64 loss: 0.18554121255874634
Batch 22/64 loss: 0.18054968118667603
Batch 23/64 loss: 0.18316912651062012
Batch 24/64 loss: 0.1811978816986084
Batch 25/64 loss: 0.19137990474700928
Batch 26/64 loss: 0.19801145792007446
Batch 27/64 loss: 0.19709086418151855
Batch 28/64 loss: 0.18715894222259521
Batch 29/64 loss: 0.1971161961555481
Batch 30/64 loss: 0.1989709734916687
Batch 31/64 loss: 0.18753981590270996
Batch 32/64 loss: 0.17824387550354004
Batch 33/64 loss: 0.18426185846328735
Batch 34/64 loss: 0.1814725399017334
Batch 35/64 loss: 0.1806401014328003
Batch 36/64 loss: 0.19299060106277466
Batch 37/64 loss: 0.1881089210510254
Batch 38/64 loss: 0.19332635402679443
Batch 39/64 loss: 0.19856703281402588
Batch 40/64 loss: 0.1859990358352661
Batch 41/64 loss: 0.18763881921768188
Batch 42/64 loss: 0.19200271368026733
Batch 43/64 loss: 0.1960851550102234
Batch 44/64 loss: 0.19124490022659302
Batch 45/64 loss: 0.19383227825164795
Batch 46/64 loss: 0.18069934844970703
Batch 47/64 loss: 0.19363754987716675
Batch 48/64 loss: 0.18597328662872314
Batch 49/64 loss: 0.18148088455200195
Batch 50/64 loss: 0.17903673648834229
Batch 51/64 loss: 0.19066953659057617
Batch 52/64 loss: 0.19923460483551025
Batch 53/64 loss: 0.2036910057067871
Batch 54/64 loss: 0.19102251529693604
Batch 55/64 loss: 0.1916581392288208
Batch 56/64 loss: 0.18550366163253784
Batch 57/64 loss: 0.19295620918273926
Batch 58/64 loss: 0.19070535898208618
Batch 59/64 loss: 0.19552308320999146
Batch 60/64 loss: 0.1964207887649536
Batch 61/64 loss: 0.19251251220703125
Batch 62/64 loss: 0.19666075706481934
Batch 63/64 loss: 0.19824570417404175
Batch 64/64 loss: 0.19986283779144287
Epoch 468  Train loss: 0.18978417948180554  Val loss: 0.29958866142325385
Epoch 469
-------------------------------
Batch 1/64 loss: 0.20740258693695068
Batch 2/64 loss: 0.18925344944000244
Batch 3/64 loss: 0.18439233303070068
Batch 4/64 loss: 0.1990237832069397
Batch 5/64 loss: 0.18076705932617188
Batch 6/64 loss: 0.18830323219299316
Batch 7/64 loss: 0.19914758205413818
Batch 8/64 loss: 0.18787378072738647
Batch 9/64 loss: 0.18066704273223877
Batch 10/64 loss: 0.18390226364135742
Batch 11/64 loss: 0.17049646377563477
Batch 12/64 loss: 0.17394983768463135
Batch 13/64 loss: 0.18951547145843506
Batch 14/64 loss: 0.19180142879486084
Batch 15/64 loss: 0.1912505030632019
Batch 16/64 loss: 0.19209200143814087
Batch 17/64 loss: 0.20094096660614014
Batch 18/64 loss: 0.19679594039916992
Batch 19/64 loss: 0.1838700771331787
Batch 20/64 loss: 0.19308233261108398
Batch 21/64 loss: 0.2016010880470276
Batch 22/64 loss: 0.19563335180282593
Batch 23/64 loss: 0.18937736749649048
Batch 24/64 loss: 0.18498456478118896
Batch 25/64 loss: 0.19491642713546753
Batch 26/64 loss: 0.19232594966888428
Batch 27/64 loss: 0.19129741191864014
Batch 28/64 loss: 0.1862671971321106
Batch 29/64 loss: 0.18882912397384644
Batch 30/64 loss: 0.1900528073310852
Batch 31/64 loss: 0.19386667013168335
Batch 32/64 loss: 0.1948344111442566
Batch 33/64 loss: 0.2007220983505249
Batch 34/64 loss: 0.17750799655914307
Batch 35/64 loss: 0.19972866773605347
Batch 36/64 loss: 0.1903875470161438
Batch 37/64 loss: 0.1868031620979309
Batch 38/64 loss: 0.18783318996429443
Batch 39/64 loss: 0.19014304876327515
Batch 40/64 loss: 0.1970924735069275
Batch 41/64 loss: 0.18149018287658691
Batch 42/64 loss: 0.19375872611999512
Batch 43/64 loss: 0.18953341245651245
Batch 44/64 loss: 0.20367205142974854
Batch 45/64 loss: 0.2001941204071045
Batch 46/64 loss: 0.19336575269699097
Batch 47/64 loss: 0.1882627010345459
Batch 48/64 loss: 0.18805021047592163
Batch 49/64 loss: 0.1767231822013855
Batch 50/64 loss: 0.1859649419784546
Batch 51/64 loss: 0.19582599401474
Batch 52/64 loss: 0.19424569606781006
Batch 53/64 loss: 0.19300472736358643
Batch 54/64 loss: 0.19219648838043213
Batch 55/64 loss: 0.19439542293548584
Batch 56/64 loss: 0.19198906421661377
Batch 57/64 loss: 0.18735384941101074
Batch 58/64 loss: 0.19190943241119385
Batch 59/64 loss: 0.18872475624084473
Batch 60/64 loss: 0.18866145610809326
Batch 61/64 loss: 0.18647277355194092
Batch 62/64 loss: 0.187890887260437
Batch 63/64 loss: 0.1913471221923828
Batch 64/64 loss: 0.18990522623062134
Epoch 469  Train loss: 0.19052854215397555  Val loss: 0.2993565519241123
Epoch 470
-------------------------------
Batch 1/64 loss: 0.1851365566253662
Batch 2/64 loss: 0.1984487771987915
Batch 3/64 loss: 0.194350004196167
Batch 4/64 loss: 0.17625105381011963
Batch 5/64 loss: 0.1901489496231079
Batch 6/64 loss: 0.19272416830062866
Batch 7/64 loss: 0.17992478609085083
Batch 8/64 loss: 0.18811500072479248
Batch 9/64 loss: 0.17682909965515137
Batch 10/64 loss: 0.19579094648361206
Batch 11/64 loss: 0.18603229522705078
Batch 12/64 loss: 0.18596231937408447
Batch 13/64 loss: 0.1912534236907959
Batch 14/64 loss: 0.18714022636413574
Batch 15/64 loss: 0.18421393632888794
Batch 16/64 loss: 0.19945144653320312
Batch 17/64 loss: 0.18346816301345825
Batch 18/64 loss: 0.1942698359489441
Batch 19/64 loss: 0.18361890316009521
Batch 20/64 loss: 0.2030620574951172
Batch 21/64 loss: 0.1873127818107605
Batch 22/64 loss: 0.18972384929656982
Batch 23/64 loss: 0.18386483192443848
Batch 24/64 loss: 0.18091368675231934
Batch 25/64 loss: 0.18826919794082642
Batch 26/64 loss: 0.17456036806106567
Batch 27/64 loss: 0.18240296840667725
Batch 28/64 loss: 0.2075577974319458
Batch 29/64 loss: 0.19638437032699585
Batch 30/64 loss: 0.18379580974578857
Batch 31/64 loss: 0.19244295358657837
Batch 32/64 loss: 0.1980915069580078
Batch 33/64 loss: 0.1800207495689392
Batch 34/64 loss: 0.19336950778961182
Batch 35/64 loss: 0.1900627613067627
Batch 36/64 loss: 0.18439722061157227
Batch 37/64 loss: 0.19434583187103271
Batch 38/64 loss: 0.18796366453170776
Batch 39/64 loss: 0.1964685320854187
Batch 40/64 loss: 0.1843709945678711
Batch 41/64 loss: 0.17864346504211426
Batch 42/64 loss: 0.18723821640014648
Batch 43/64 loss: 0.19220638275146484
Batch 44/64 loss: 0.18005937337875366
Batch 45/64 loss: 0.1829890012741089
Batch 46/64 loss: 0.19556939601898193
Batch 47/64 loss: 0.1938440203666687
Batch 48/64 loss: 0.18077725172042847
Batch 49/64 loss: 0.18056964874267578
Batch 50/64 loss: 0.19044482707977295
Batch 51/64 loss: 0.2035219669342041
Batch 52/64 loss: 0.1940956711769104
Batch 53/64 loss: 0.18838196992874146
Batch 54/64 loss: 0.18654078245162964
Batch 55/64 loss: 0.1886722445487976
Batch 56/64 loss: 0.1908329725265503
Batch 57/64 loss: 0.1839146614074707
Batch 58/64 loss: 0.19996899366378784
Batch 59/64 loss: 0.19082403182983398
Batch 60/64 loss: 0.19369792938232422
Batch 61/64 loss: 0.19766724109649658
Batch 62/64 loss: 0.1933174729347229
Batch 63/64 loss: 0.201788067817688
Batch 64/64 loss: 0.18766307830810547
Epoch 470  Train loss: 0.1893148899078369  Val loss: 0.2999075243563177
Epoch 471
-------------------------------
Batch 1/64 loss: 0.19423764944076538
Batch 2/64 loss: 0.18410402536392212
Batch 3/64 loss: 0.19629430770874023
Batch 4/64 loss: 0.1974543333053589
Batch 5/64 loss: 0.19544756412506104
Batch 6/64 loss: 0.19441008567810059
Batch 7/64 loss: 0.18904000520706177
Batch 8/64 loss: 0.18645358085632324
Batch 9/64 loss: 0.19725024700164795
Batch 10/64 loss: 0.18007975816726685
Batch 11/64 loss: 0.17982172966003418
Batch 12/64 loss: 0.19011235237121582
Batch 13/64 loss: 0.18645960092544556
Batch 14/64 loss: 0.21136486530303955
Batch 15/64 loss: 0.1891268491744995
Batch 16/64 loss: 0.18884539604187012
Batch 17/64 loss: 0.18803513050079346
Batch 18/64 loss: 0.18426513671875
Batch 19/64 loss: 0.19942444562911987
Batch 20/64 loss: 0.1777348518371582
Batch 21/64 loss: 0.19068723917007446
Batch 22/64 loss: 0.17711883783340454
Batch 23/64 loss: 0.19186758995056152
Batch 24/64 loss: 0.1871848702430725
Batch 25/64 loss: 0.19714099168777466
Batch 26/64 loss: 0.18632221221923828
Batch 27/64 loss: 0.18826830387115479
Batch 28/64 loss: 0.1823940873146057
Batch 29/64 loss: 0.18503409624099731
Batch 30/64 loss: 0.1962098479270935
Batch 31/64 loss: 0.1918870210647583
Batch 32/64 loss: 0.18594765663146973
Batch 33/64 loss: 0.20281898975372314
Batch 34/64 loss: 0.17690324783325195
Batch 35/64 loss: 0.19216197729110718
Batch 36/64 loss: 0.19171983003616333
Batch 37/64 loss: 0.18796193599700928
Batch 38/64 loss: 0.19009745121002197
Batch 39/64 loss: 0.18502962589263916
Batch 40/64 loss: 0.19392788410186768
Batch 41/64 loss: 0.18201172351837158
Batch 42/64 loss: 0.19085615873336792
Batch 43/64 loss: 0.18884700536727905
Batch 44/64 loss: 0.1912519335746765
Batch 45/64 loss: 0.19238466024398804
Batch 46/64 loss: 0.18215411901474
Batch 47/64 loss: 0.17945510149002075
Batch 48/64 loss: 0.18560993671417236
Batch 49/64 loss: 0.18503206968307495
Batch 50/64 loss: 0.1953679919242859
Batch 51/64 loss: 0.18338632583618164
Batch 52/64 loss: 0.20349180698394775
Batch 53/64 loss: 0.18681269884109497
Batch 54/64 loss: 0.19526124000549316
Batch 55/64 loss: 0.19369280338287354
Batch 56/64 loss: 0.1863684058189392
Batch 57/64 loss: 0.18907427787780762
Batch 58/64 loss: 0.1908499002456665
Batch 59/64 loss: 0.17655408382415771
Batch 60/64 loss: 0.1898338794708252
Batch 61/64 loss: 0.19245165586471558
Batch 62/64 loss: 0.1762896180152893
Batch 63/64 loss: 0.18960803747177124
Batch 64/64 loss: 0.21678197383880615
Epoch 471  Train loss: 0.18948827491087072  Val loss: 0.29969004216472717
Epoch 472
-------------------------------
Batch 1/64 loss: 0.1760774850845337
Batch 2/64 loss: 0.18779045343399048
Batch 3/64 loss: 0.1826367974281311
Batch 4/64 loss: 0.18226861953735352
Batch 5/64 loss: 0.19072163105010986
Batch 6/64 loss: 0.1892932653427124
Batch 7/64 loss: 0.1981472373008728
Batch 8/64 loss: 0.17793607711791992
Batch 9/64 loss: 0.18824833631515503
Batch 10/64 loss: 0.18477612733840942
Batch 11/64 loss: 0.18680202960968018
Batch 12/64 loss: 0.2009851336479187
Batch 13/64 loss: 0.18059056997299194
Batch 14/64 loss: 0.20727944374084473
Batch 15/64 loss: 0.19149494171142578
Batch 16/64 loss: 0.1802603006362915
Batch 17/64 loss: 0.1946524977684021
Batch 18/64 loss: 0.1860262155532837
Batch 19/64 loss: 0.19187772274017334
Batch 20/64 loss: 0.18770891427993774
Batch 21/64 loss: 0.18787270784378052
Batch 22/64 loss: 0.1924830675125122
Batch 23/64 loss: 0.19729065895080566
Batch 24/64 loss: 0.18467622995376587
Batch 25/64 loss: 0.19070136547088623
Batch 26/64 loss: 0.19024592638015747
Batch 27/64 loss: 0.1758131980895996
Batch 28/64 loss: 0.18553155660629272
Batch 29/64 loss: 0.19046956300735474
Batch 30/64 loss: 0.20225751399993896
Batch 31/64 loss: 0.1853085160255432
Batch 32/64 loss: 0.19401758909225464
Batch 33/64 loss: 0.19965612888336182
Batch 34/64 loss: 0.18811893463134766
Batch 35/64 loss: 0.19344985485076904
Batch 36/64 loss: 0.21291255950927734
Batch 37/64 loss: 0.1917542815208435
Batch 38/64 loss: 0.18623340129852295
Batch 39/64 loss: 0.18903708457946777
Batch 40/64 loss: 0.18984633684158325
Batch 41/64 loss: 0.1862623691558838
Batch 42/64 loss: 0.18473541736602783
Batch 43/64 loss: 0.19140195846557617
Batch 44/64 loss: 0.17662549018859863
Batch 45/64 loss: 0.19966858625411987
Batch 46/64 loss: 0.1831226348876953
Batch 47/64 loss: 0.2085503339767456
Batch 48/64 loss: 0.1909581422805786
Batch 49/64 loss: 0.18604499101638794
Batch 50/64 loss: 0.1895911693572998
Batch 51/64 loss: 0.1857525110244751
Batch 52/64 loss: 0.1847361922264099
Batch 53/64 loss: 0.18662571907043457
Batch 54/64 loss: 0.18727916479110718
Batch 55/64 loss: 0.20787060260772705
Batch 56/64 loss: 0.18470007181167603
Batch 57/64 loss: 0.1906414031982422
Batch 58/64 loss: 0.17492860555648804
Batch 59/64 loss: 0.18983542919158936
Batch 60/64 loss: 0.18841975927352905
Batch 61/64 loss: 0.20551550388336182
Batch 62/64 loss: 0.19469183683395386
Batch 63/64 loss: 0.18459665775299072
Batch 64/64 loss: 0.1904677152633667
Epoch 472  Train loss: 0.18978283311806474  Val loss: 0.29955655193001135
Epoch 473
-------------------------------
Batch 1/64 loss: 0.1783939003944397
Batch 2/64 loss: 0.20198410749435425
Batch 3/64 loss: 0.18747657537460327
Batch 4/64 loss: 0.19585466384887695
Batch 5/64 loss: 0.1843094825744629
Batch 6/64 loss: 0.19405174255371094
Batch 7/64 loss: 0.18021368980407715
Batch 8/64 loss: 0.1837061643600464
Batch 9/64 loss: 0.18718284368515015
Batch 10/64 loss: 0.19472408294677734
Batch 11/64 loss: 0.1936824917793274
Batch 12/64 loss: 0.17344814538955688
Batch 13/64 loss: 0.20094811916351318
Batch 14/64 loss: 0.19246447086334229
Batch 15/64 loss: 0.1942805051803589
Batch 16/64 loss: 0.1871856451034546
Batch 17/64 loss: 0.1883060336112976
Batch 18/64 loss: 0.17771553993225098
Batch 19/64 loss: 0.1857537031173706
Batch 20/64 loss: 0.20899707078933716
Batch 21/64 loss: 0.1948346495628357
Batch 22/64 loss: 0.19832122325897217
Batch 23/64 loss: 0.19019067287445068
Batch 24/64 loss: 0.1821507215499878
Batch 25/64 loss: 0.18859565258026123
Batch 26/64 loss: 0.17597943544387817
Batch 27/64 loss: 0.18171924352645874
Batch 28/64 loss: 0.1907368302345276
Batch 29/64 loss: 0.18451446294784546
Batch 30/64 loss: 0.18669146299362183
Batch 31/64 loss: 0.19024443626403809
Batch 32/64 loss: 0.18303728103637695
Batch 33/64 loss: 0.186303973197937
Batch 34/64 loss: 0.19500184059143066
Batch 35/64 loss: 0.18686950206756592
Batch 36/64 loss: 0.1846538782119751
Batch 37/64 loss: 0.18538713455200195
Batch 38/64 loss: 0.1902027130126953
Batch 39/64 loss: 0.19241315126419067
Batch 40/64 loss: 0.18620210886001587
Batch 41/64 loss: 0.19507938623428345
Batch 42/64 loss: 0.18897342681884766
Batch 43/64 loss: 0.1875653862953186
Batch 44/64 loss: 0.1947329044342041
Batch 45/64 loss: 0.19519275426864624
Batch 46/64 loss: 0.20064300298690796
Batch 47/64 loss: 0.18267744779586792
Batch 48/64 loss: 0.19710266590118408
Batch 49/64 loss: 0.18730908632278442
Batch 50/64 loss: 0.19151592254638672
Batch 51/64 loss: 0.1818375587463379
Batch 52/64 loss: 0.18622303009033203
Batch 53/64 loss: 0.1916554570198059
Batch 54/64 loss: 0.17774951457977295
Batch 55/64 loss: 0.20388269424438477
Batch 56/64 loss: 0.18122607469558716
Batch 57/64 loss: 0.18867474794387817
Batch 58/64 loss: 0.2027679681777954
Batch 59/64 loss: 0.18129831552505493
Batch 60/64 loss: 0.1792280077934265
Batch 61/64 loss: 0.18966996669769287
Batch 62/64 loss: 0.1851407289505005
Batch 63/64 loss: 0.19308561086654663
Batch 64/64 loss: 0.20076984167099
Epoch 473  Train loss: 0.1891535434068418  Val loss: 0.299717181736661
Epoch 474
-------------------------------
Batch 1/64 loss: 0.18712836503982544
Batch 2/64 loss: 0.18328624963760376
Batch 3/64 loss: 0.18682324886322021
Batch 4/64 loss: 0.18917107582092285
Batch 5/64 loss: 0.19591057300567627
Batch 6/64 loss: 0.1892540454864502
Batch 7/64 loss: 0.1887924075126648
Batch 8/64 loss: 0.18077200651168823
Batch 9/64 loss: 0.18220674991607666
Batch 10/64 loss: 0.17527377605438232
Batch 11/64 loss: 0.18645477294921875
Batch 12/64 loss: 0.1917291283607483
Batch 13/64 loss: 0.19859623908996582
Batch 14/64 loss: 0.19155704975128174
Batch 15/64 loss: 0.19945186376571655
Batch 16/64 loss: 0.20561188459396362
Batch 17/64 loss: 0.19559550285339355
Batch 18/64 loss: 0.1894860863685608
Batch 19/64 loss: 0.18279922008514404
Batch 20/64 loss: 0.19624602794647217
Batch 21/64 loss: 0.1818036437034607
Batch 22/64 loss: 0.19556015729904175
Batch 23/64 loss: 0.18179047107696533
Batch 24/64 loss: 0.18057024478912354
Batch 25/64 loss: 0.186295747756958
Batch 26/64 loss: 0.18603920936584473
Batch 27/64 loss: 0.1955384612083435
Batch 28/64 loss: 0.18120276927947998
Batch 29/64 loss: 0.1899598240852356
Batch 30/64 loss: 0.18484586477279663
Batch 31/64 loss: 0.19171810150146484
Batch 32/64 loss: 0.1925070881843567
Batch 33/64 loss: 0.18879932165145874
Batch 34/64 loss: 0.1821603775024414
Batch 35/64 loss: 0.1917216181755066
Batch 36/64 loss: 0.19043022394180298
Batch 37/64 loss: 0.2019081711769104
Batch 38/64 loss: 0.18754726648330688
Batch 39/64 loss: 0.19384372234344482
Batch 40/64 loss: 0.1886466145515442
Batch 41/64 loss: 0.18270522356033325
Batch 42/64 loss: 0.19433951377868652
Batch 43/64 loss: 0.18755698204040527
Batch 44/64 loss: 0.18416577577590942
Batch 45/64 loss: 0.20271944999694824
Batch 46/64 loss: 0.19754207134246826
Batch 47/64 loss: 0.19516831636428833
Batch 48/64 loss: 0.18058007955551147
Batch 49/64 loss: 0.1952732801437378
Batch 50/64 loss: 0.20084577798843384
Batch 51/64 loss: 0.17906951904296875
Batch 52/64 loss: 0.1943036913871765
Batch 53/64 loss: 0.1879633665084839
Batch 54/64 loss: 0.1894599199295044
Batch 55/64 loss: 0.2057027816772461
Batch 56/64 loss: 0.1836552619934082
Batch 57/64 loss: 0.18004995584487915
Batch 58/64 loss: 0.1863386034965515
Batch 59/64 loss: 0.18318462371826172
Batch 60/64 loss: 0.19245684146881104
Batch 61/64 loss: 0.19058763980865479
Batch 62/64 loss: 0.20978593826293945
Batch 63/64 loss: 0.17760848999023438
Batch 64/64 loss: 0.20207035541534424
Epoch 474  Train loss: 0.18982982027764414  Val loss: 0.2995981887443778
Epoch 475
-------------------------------
Batch 1/64 loss: 0.1828179955482483
Batch 2/64 loss: 0.19651097059249878
Batch 3/64 loss: 0.19212627410888672
Batch 4/64 loss: 0.1939263939857483
Batch 5/64 loss: 0.18487399816513062
Batch 6/64 loss: 0.18366986513137817
Batch 7/64 loss: 0.18890690803527832
Batch 8/64 loss: 0.1836668848991394
Batch 9/64 loss: 0.18160510063171387
Batch 10/64 loss: 0.17872989177703857
Batch 11/64 loss: 0.17764711380004883
Batch 12/64 loss: 0.18339741230010986
Batch 13/64 loss: 0.19746077060699463
Batch 14/64 loss: 0.20031946897506714
Batch 15/64 loss: 0.20771455764770508
Batch 16/64 loss: 0.18736118078231812
Batch 17/64 loss: 0.19347739219665527
Batch 18/64 loss: 0.190717875957489
Batch 19/64 loss: 0.19239258766174316
Batch 20/64 loss: 0.18673795461654663
Batch 21/64 loss: 0.19827008247375488
Batch 22/64 loss: 0.1979777216911316
Batch 23/64 loss: 0.18674546480178833
Batch 24/64 loss: 0.19897115230560303
Batch 25/64 loss: 0.18105322122573853
Batch 26/64 loss: 0.19516658782958984
Batch 27/64 loss: 0.1946202516555786
Batch 28/64 loss: 0.17733687162399292
Batch 29/64 loss: 0.18066662549972534
Batch 30/64 loss: 0.1868494749069214
Batch 31/64 loss: 0.1915653944015503
Batch 32/64 loss: 0.18292510509490967
Batch 33/64 loss: 0.19066500663757324
Batch 34/64 loss: 0.19655656814575195
Batch 35/64 loss: 0.1864711046218872
Batch 36/64 loss: 0.18974238634109497
Batch 37/64 loss: 0.2014232873916626
Batch 38/64 loss: 0.18773049116134644
Batch 39/64 loss: 0.1833360195159912
Batch 40/64 loss: 0.19171994924545288
Batch 41/64 loss: 0.17589139938354492
Batch 42/64 loss: 0.18817365169525146
Batch 43/64 loss: 0.18466639518737793
Batch 44/64 loss: 0.18117660284042358
Batch 45/64 loss: 0.19012069702148438
Batch 46/64 loss: 0.18911612033843994
Batch 47/64 loss: 0.19920456409454346
Batch 48/64 loss: 0.19138020277023315
Batch 49/64 loss: 0.18513178825378418
Batch 50/64 loss: 0.19240152835845947
Batch 51/64 loss: 0.19061017036437988
Batch 52/64 loss: 0.18321454524993896
Batch 53/64 loss: 0.21429443359375
Batch 54/64 loss: 0.17810297012329102
Batch 55/64 loss: 0.18028509616851807
Batch 56/64 loss: 0.19653630256652832
Batch 57/64 loss: 0.209403395652771
Batch 58/64 loss: 0.20101147890090942
Batch 59/64 loss: 0.18800902366638184
Batch 60/64 loss: 0.18822693824768066
Batch 61/64 loss: 0.20133453607559204
Batch 62/64 loss: 0.19214659929275513
Batch 63/64 loss: 0.19845610857009888
Batch 64/64 loss: 0.18630743026733398
Epoch 475  Train loss: 0.19015652525658702  Val loss: 0.29908684090650367
Epoch 476
-------------------------------
Batch 1/64 loss: 0.17185592651367188
Batch 2/64 loss: 0.20280909538269043
Batch 3/64 loss: 0.19237220287322998
Batch 4/64 loss: 0.1866304874420166
Batch 5/64 loss: 0.1791391372680664
Batch 6/64 loss: 0.185927152633667
Batch 7/64 loss: 0.17935287952423096
Batch 8/64 loss: 0.1879003643989563
Batch 9/64 loss: 0.1815604567527771
Batch 10/64 loss: 0.1841176152229309
Batch 11/64 loss: 0.172496497631073
Batch 12/64 loss: 0.18531018495559692
Batch 13/64 loss: 0.19477862119674683
Batch 14/64 loss: 0.17854291200637817
Batch 15/64 loss: 0.18383830785751343
Batch 16/64 loss: 0.19020205736160278
Batch 17/64 loss: 0.1988716721534729
Batch 18/64 loss: 0.18373966217041016
Batch 19/64 loss: 0.17645734548568726
Batch 20/64 loss: 0.1886557936668396
Batch 21/64 loss: 0.1796497106552124
Batch 22/64 loss: 0.19055241346359253
Batch 23/64 loss: 0.17852097749710083
Batch 24/64 loss: 0.20075809955596924
Batch 25/64 loss: 0.19325417280197144
Batch 26/64 loss: 0.1837559938430786
Batch 27/64 loss: 0.19829237461090088
Batch 28/64 loss: 0.20209991931915283
Batch 29/64 loss: 0.1748107671737671
Batch 30/64 loss: 0.19073021411895752
Batch 31/64 loss: 0.19172757863998413
Batch 32/64 loss: 0.18195027112960815
Batch 33/64 loss: 0.1915866732597351
Batch 34/64 loss: 0.18511807918548584
Batch 35/64 loss: 0.19348376989364624
Batch 36/64 loss: 0.20060288906097412
Batch 37/64 loss: 0.1835116147994995
Batch 38/64 loss: 0.18520933389663696
Batch 39/64 loss: 0.20447760820388794
Batch 40/64 loss: 0.19124972820281982
Batch 41/64 loss: 0.20303654670715332
Batch 42/64 loss: 0.18445897102355957
Batch 43/64 loss: 0.19712179899215698
Batch 44/64 loss: 0.19370317459106445
Batch 45/64 loss: 0.19927430152893066
Batch 46/64 loss: 0.17916470766067505
Batch 47/64 loss: 0.18914461135864258
Batch 48/64 loss: 0.19274914264678955
Batch 49/64 loss: 0.20049166679382324
Batch 50/64 loss: 0.18597793579101562
Batch 51/64 loss: 0.18339049816131592
Batch 52/64 loss: 0.1901187300682068
Batch 53/64 loss: 0.21796739101409912
Batch 54/64 loss: 0.19472545385360718
Batch 55/64 loss: 0.18647396564483643
Batch 56/64 loss: 0.19783663749694824
Batch 57/64 loss: 0.19933050870895386
Batch 58/64 loss: 0.19500648975372314
Batch 59/64 loss: 0.18825238943099976
Batch 60/64 loss: 0.18030405044555664
Batch 61/64 loss: 0.18747282028198242
Batch 62/64 loss: 0.18251562118530273
Batch 63/64 loss: 0.19922375679016113
Batch 64/64 loss: 0.20096898078918457
Epoch 476  Train loss: 0.1895587210561715  Val loss: 0.3003280220162828
Epoch 477
-------------------------------
Batch 1/64 loss: 0.18750131130218506
Batch 2/64 loss: 0.18269187211990356
Batch 3/64 loss: 0.2053733468055725
Batch 4/64 loss: 0.18722432851791382
Batch 5/64 loss: 0.190207839012146
Batch 6/64 loss: 0.18662279844284058
Batch 7/64 loss: 0.183191180229187
Batch 8/64 loss: 0.18634939193725586
Batch 9/64 loss: 0.17816805839538574
Batch 10/64 loss: 0.18572169542312622
Batch 11/64 loss: 0.20081710815429688
Batch 12/64 loss: 0.18579983711242676
Batch 13/64 loss: 0.17538762092590332
Batch 14/64 loss: 0.19709652662277222
Batch 15/64 loss: 0.1838025450706482
Batch 16/64 loss: 0.193933367729187
Batch 17/64 loss: 0.19095325469970703
Batch 18/64 loss: 0.19167423248291016
Batch 19/64 loss: 0.18022584915161133
Batch 20/64 loss: 0.18894803524017334
Batch 21/64 loss: 0.20783567428588867
Batch 22/64 loss: 0.186481773853302
Batch 23/64 loss: 0.1885281801223755
Batch 24/64 loss: 0.17581772804260254
Batch 25/64 loss: 0.2032589316368103
Batch 26/64 loss: 0.18184024095535278
Batch 27/64 loss: 0.1915508508682251
Batch 28/64 loss: 0.20207738876342773
Batch 29/64 loss: 0.19895309209823608
Batch 30/64 loss: 0.19622498750686646
Batch 31/64 loss: 0.1891689896583557
Batch 32/64 loss: 0.18914079666137695
Batch 33/64 loss: 0.18960446119308472
Batch 34/64 loss: 0.21213126182556152
Batch 35/64 loss: 0.17731505632400513
Batch 36/64 loss: 0.1947038173675537
Batch 37/64 loss: 0.18279439210891724
Batch 38/64 loss: 0.1862419843673706
Batch 39/64 loss: 0.18115580081939697
Batch 40/64 loss: 0.1888277530670166
Batch 41/64 loss: 0.19557291269302368
Batch 42/64 loss: 0.19370275735855103
Batch 43/64 loss: 0.18024814128875732
Batch 44/64 loss: 0.1921136975288391
Batch 45/64 loss: 0.18365782499313354
Batch 46/64 loss: 0.18828052282333374
Batch 47/64 loss: 0.19299834966659546
Batch 48/64 loss: 0.18838179111480713
Batch 49/64 loss: 0.19563955068588257
Batch 50/64 loss: 0.19215816259384155
Batch 51/64 loss: 0.19079655408859253
Batch 52/64 loss: 0.18171393871307373
Batch 53/64 loss: 0.19187027215957642
Batch 54/64 loss: 0.1814144253730774
Batch 55/64 loss: 0.18622475862503052
Batch 56/64 loss: 0.1852360963821411
Batch 57/64 loss: 0.19366991519927979
Batch 58/64 loss: 0.1800670623779297
Batch 59/64 loss: 0.1828647255897522
Batch 60/64 loss: 0.19156748056411743
Batch 61/64 loss: 0.18620896339416504
Batch 62/64 loss: 0.19716542959213257
Batch 63/64 loss: 0.18687379360198975
Batch 64/64 loss: 0.18707430362701416
Epoch 477  Train loss: 0.18924041121613747  Val loss: 0.29976329094765525
Epoch 478
-------------------------------
Batch 1/64 loss: 0.19011378288269043
Batch 2/64 loss: 0.19683235883712769
Batch 3/64 loss: 0.1873287558555603
Batch 4/64 loss: 0.1853771209716797
Batch 5/64 loss: 0.17252951860427856
Batch 6/64 loss: 0.18983352184295654
Batch 7/64 loss: 0.1966044306755066
Batch 8/64 loss: 0.18884843587875366
Batch 9/64 loss: 0.18483394384384155
Batch 10/64 loss: 0.1736810803413391
Batch 11/64 loss: 0.18946874141693115
Batch 12/64 loss: 0.20145314931869507
Batch 13/64 loss: 0.18844497203826904
Batch 14/64 loss: 0.18482518196105957
Batch 15/64 loss: 0.1854090690612793
Batch 16/64 loss: 0.18854886293411255
Batch 17/64 loss: 0.18040359020233154
Batch 18/64 loss: 0.185968816280365
Batch 19/64 loss: 0.1788259744644165
Batch 20/64 loss: 0.1777559518814087
Batch 21/64 loss: 0.1844058632850647
Batch 22/64 loss: 0.1876457929611206
Batch 23/64 loss: 0.1811133623123169
Batch 24/64 loss: 0.18396955728530884
Batch 25/64 loss: 0.20698750019073486
Batch 26/64 loss: 0.19283610582351685
Batch 27/64 loss: 0.18559634685516357
Batch 28/64 loss: 0.18400561809539795
Batch 29/64 loss: 0.18542444705963135
Batch 30/64 loss: 0.1806984543800354
Batch 31/64 loss: 0.1840035319328308
Batch 32/64 loss: 0.18874526023864746
Batch 33/64 loss: 0.19614851474761963
Batch 34/64 loss: 0.2013339400291443
Batch 35/64 loss: 0.18652570247650146
Batch 36/64 loss: 0.18457388877868652
Batch 37/64 loss: 0.19443190097808838
Batch 38/64 loss: 0.18344557285308838
Batch 39/64 loss: 0.17796307802200317
Batch 40/64 loss: 0.19441038370132446
Batch 41/64 loss: 0.19535797834396362
Batch 42/64 loss: 0.18439090251922607
Batch 43/64 loss: 0.18956869840621948
Batch 44/64 loss: 0.18954741954803467
Batch 45/64 loss: 0.18049359321594238
Batch 46/64 loss: 0.19033503532409668
Batch 47/64 loss: 0.18337446451187134
Batch 48/64 loss: 0.1744595170021057
Batch 49/64 loss: 0.18922007083892822
Batch 50/64 loss: 0.1821550726890564
Batch 51/64 loss: 0.1862185001373291
Batch 52/64 loss: 0.19109255075454712
Batch 53/64 loss: 0.19631290435791016
Batch 54/64 loss: 0.19291740655899048
Batch 55/64 loss: 0.1809237003326416
Batch 56/64 loss: 0.18384158611297607
Batch 57/64 loss: 0.20984160900115967
Batch 58/64 loss: 0.19818389415740967
Batch 59/64 loss: 0.1890222430229187
Batch 60/64 loss: 0.18851149082183838
Batch 61/64 loss: 0.1932925581932068
Batch 62/64 loss: 0.18530172109603882
Batch 63/64 loss: 0.18448269367218018
Batch 64/64 loss: 0.20175570249557495
Epoch 478  Train loss: 0.18794532500061334  Val loss: 0.2999343343616761
Epoch 479
-------------------------------
Batch 1/64 loss: 0.18603050708770752
Batch 2/64 loss: 0.19463902711868286
Batch 3/64 loss: 0.18878662586212158
Batch 4/64 loss: 0.20447063446044922
Batch 5/64 loss: 0.18987172842025757
Batch 6/64 loss: 0.18583762645721436
Batch 7/64 loss: 0.19524049758911133
Batch 8/64 loss: 0.17505282163619995
Batch 9/64 loss: 0.1848280429840088
Batch 10/64 loss: 0.18439888954162598
Batch 11/64 loss: 0.19028764963150024
Batch 12/64 loss: 0.19407272338867188
Batch 13/64 loss: 0.17553573846817017
Batch 14/64 loss: 0.17368578910827637
Batch 15/64 loss: 0.18913573026657104
Batch 16/64 loss: 0.20063096284866333
Batch 17/64 loss: 0.1832079291343689
Batch 18/64 loss: 0.19081473350524902
Batch 19/64 loss: 0.188071608543396
Batch 20/64 loss: 0.1884632110595703
Batch 21/64 loss: 0.18260788917541504
Batch 22/64 loss: 0.18533813953399658
Batch 23/64 loss: 0.19609487056732178
Batch 24/64 loss: 0.1848660707473755
Batch 25/64 loss: 0.18615174293518066
Batch 26/64 loss: 0.18600934743881226
Batch 27/64 loss: 0.18889868259429932
Batch 28/64 loss: 0.20351344347000122
Batch 29/64 loss: 0.20637059211730957
Batch 30/64 loss: 0.18379420042037964
Batch 31/64 loss: 0.1853211522102356
Batch 32/64 loss: 0.1864405870437622
Batch 33/64 loss: 0.19449490308761597
Batch 34/64 loss: 0.18620818853378296
Batch 35/64 loss: 0.18332046270370483
Batch 36/64 loss: 0.193800151348114
Batch 37/64 loss: 0.19060194492340088
Batch 38/64 loss: 0.1983817219734192
Batch 39/64 loss: 0.18614763021469116
Batch 40/64 loss: 0.1847408413887024
Batch 41/64 loss: 0.18787002563476562
Batch 42/64 loss: 0.17750859260559082
Batch 43/64 loss: 0.19494277238845825
Batch 44/64 loss: 0.17983543872833252
Batch 45/64 loss: 0.1899617314338684
Batch 46/64 loss: 0.17623788118362427
Batch 47/64 loss: 0.18979942798614502
Batch 48/64 loss: 0.19253301620483398
Batch 49/64 loss: 0.18800437450408936
Batch 50/64 loss: 0.18953019380569458
Batch 51/64 loss: 0.1877366304397583
Batch 52/64 loss: 0.20021909475326538
Batch 53/64 loss: 0.1916944980621338
Batch 54/64 loss: 0.1734883189201355
Batch 55/64 loss: 0.18693041801452637
Batch 56/64 loss: 0.19210970401763916
Batch 57/64 loss: 0.18628495931625366
Batch 58/64 loss: 0.1874653697013855
Batch 59/64 loss: 0.20128196477890015
Batch 60/64 loss: 0.1998906135559082
Batch 61/64 loss: 0.18332666158676147
Batch 62/64 loss: 0.19928032159805298
Batch 63/64 loss: 0.17759454250335693
Batch 64/64 loss: 0.19047820568084717
Epoch 479  Train loss: 0.18874588620428945  Val loss: 0.2993633529984255
Epoch 480
-------------------------------
Batch 1/64 loss: 0.19814187288284302
Batch 2/64 loss: 0.20528221130371094
Batch 3/64 loss: 0.1924724578857422
Batch 4/64 loss: 0.19776767492294312
Batch 5/64 loss: 0.19293493032455444
Batch 6/64 loss: 0.1848973035812378
Batch 7/64 loss: 0.19013750553131104
Batch 8/64 loss: 0.1897372603416443
Batch 9/64 loss: 0.1864883303642273
Batch 10/64 loss: 0.18718719482421875
Batch 11/64 loss: 0.18234634399414062
Batch 12/64 loss: 0.18460261821746826
Batch 13/64 loss: 0.2041369080543518
Batch 14/64 loss: 0.18527352809906006
Batch 15/64 loss: 0.1976156234741211
Batch 16/64 loss: 0.18637967109680176
Batch 17/64 loss: 0.20546823740005493
Batch 18/64 loss: 0.20162779092788696
Batch 19/64 loss: 0.19147956371307373
Batch 20/64 loss: 0.18335509300231934
Batch 21/64 loss: 0.1813570261001587
Batch 22/64 loss: 0.19223642349243164
Batch 23/64 loss: 0.18563055992126465
Batch 24/64 loss: 0.19095522165298462
Batch 25/64 loss: 0.18459957838058472
Batch 26/64 loss: 0.18440645933151245
Batch 27/64 loss: 0.1818041205406189
Batch 28/64 loss: 0.18492257595062256
Batch 29/64 loss: 0.1852724552154541
Batch 30/64 loss: 0.18130069971084595
Batch 31/64 loss: 0.18108773231506348
Batch 32/64 loss: 0.17959457635879517
Batch 33/64 loss: 0.19930428266525269
Batch 34/64 loss: 0.1974889039993286
Batch 35/64 loss: 0.17895746231079102
Batch 36/64 loss: 0.194302499294281
Batch 37/64 loss: 0.17984122037887573
Batch 38/64 loss: 0.17149370908737183
Batch 39/64 loss: 0.17709577083587646
Batch 40/64 loss: 0.18699097633361816
Batch 41/64 loss: 0.17989695072174072
Batch 42/64 loss: 0.19043058156967163
Batch 43/64 loss: 0.2026742696762085
Batch 44/64 loss: 0.1807706356048584
Batch 45/64 loss: 0.1865251064300537
Batch 46/64 loss: 0.18119019269943237
Batch 47/64 loss: 0.18650376796722412
Batch 48/64 loss: 0.1861708164215088
Batch 49/64 loss: 0.18281400203704834
Batch 50/64 loss: 0.18132996559143066
Batch 51/64 loss: 0.18903625011444092
Batch 52/64 loss: 0.18432313203811646
Batch 53/64 loss: 0.19208967685699463
Batch 54/64 loss: 0.18811333179473877
Batch 55/64 loss: 0.19161772727966309
Batch 56/64 loss: 0.1947106122970581
Batch 57/64 loss: 0.189497709274292
Batch 58/64 loss: 0.18444329500198364
Batch 59/64 loss: 0.20777040719985962
Batch 60/64 loss: 0.20037591457366943
Batch 61/64 loss: 0.19497716426849365
Batch 62/64 loss: 0.20232093334197998
Batch 63/64 loss: 0.19456565380096436
Batch 64/64 loss: 0.18477600812911987
Epoch 480  Train loss: 0.18912477610157985  Val loss: 0.29890695122099414
Epoch 481
-------------------------------
Batch 1/64 loss: 0.1805797815322876
Batch 2/64 loss: 0.18000859022140503
Batch 3/64 loss: 0.19694989919662476
Batch 4/64 loss: 0.18945902585983276
Batch 5/64 loss: 0.18629997968673706
Batch 6/64 loss: 0.19148337841033936
Batch 7/64 loss: 0.1844157576560974
Batch 8/64 loss: 0.18373405933380127
Batch 9/64 loss: 0.18594110012054443
Batch 10/64 loss: 0.1962202787399292
Batch 11/64 loss: 0.19696223735809326
Batch 12/64 loss: 0.18257898092269897
Batch 13/64 loss: 0.1817638874053955
Batch 14/64 loss: 0.18746817111968994
Batch 15/64 loss: 0.20452189445495605
Batch 16/64 loss: 0.18510979413986206
Batch 17/64 loss: 0.19056135416030884
Batch 18/64 loss: 0.19732534885406494
Batch 19/64 loss: 0.19242346286773682
Batch 20/64 loss: 0.19720548391342163
Batch 21/64 loss: 0.197160005569458
Batch 22/64 loss: 0.19055181741714478
Batch 23/64 loss: 0.19476938247680664
Batch 24/64 loss: 0.1806015968322754
Batch 25/64 loss: 0.18383044004440308
Batch 26/64 loss: 0.19261956214904785
Batch 27/64 loss: 0.1746940016746521
Batch 28/64 loss: 0.18943440914154053
Batch 29/64 loss: 0.18101775646209717
Batch 30/64 loss: 0.1874624490737915
Batch 31/64 loss: 0.19515204429626465
Batch 32/64 loss: 0.1904943585395813
Batch 33/64 loss: 0.17889273166656494
Batch 34/64 loss: 0.183099627494812
Batch 35/64 loss: 0.18301981687545776
Batch 36/64 loss: 0.18387693166732788
Batch 37/64 loss: 0.1917433738708496
Batch 38/64 loss: 0.1794825792312622
Batch 39/64 loss: 0.18837672472000122
Batch 40/64 loss: 0.18561774492263794
Batch 41/64 loss: 0.19231027364730835
Batch 42/64 loss: 0.18220734596252441
Batch 43/64 loss: 0.18470513820648193
Batch 44/64 loss: 0.17959511280059814
Batch 45/64 loss: 0.20782470703125
Batch 46/64 loss: 0.18669795989990234
Batch 47/64 loss: 0.2053929567337036
Batch 48/64 loss: 0.19927698373794556
Batch 49/64 loss: 0.1855241060256958
Batch 50/64 loss: 0.19345951080322266
Batch 51/64 loss: 0.1844252347946167
Batch 52/64 loss: 0.19078820943832397
Batch 53/64 loss: 0.18693506717681885
Batch 54/64 loss: 0.1879543662071228
Batch 55/64 loss: 0.19731342792510986
Batch 56/64 loss: 0.17529791593551636
Batch 57/64 loss: 0.20576226711273193
Batch 58/64 loss: 0.19276392459869385
Batch 59/64 loss: 0.18904751539230347
Batch 60/64 loss: 0.18394601345062256
Batch 61/64 loss: 0.19535672664642334
Batch 62/64 loss: 0.188459575176239
Batch 63/64 loss: 0.18529099225997925
Batch 64/64 loss: 0.18620353937149048
Epoch 481  Train loss: 0.18890820087171067  Val loss: 0.29972625761916954
Epoch 482
-------------------------------
Batch 1/64 loss: 0.18552035093307495
Batch 2/64 loss: 0.1850683093070984
Batch 3/64 loss: 0.18510359525680542
Batch 4/64 loss: 0.17704784870147705
Batch 5/64 loss: 0.1787813901901245
Batch 6/64 loss: 0.19020241498947144
Batch 7/64 loss: 0.19104290008544922
Batch 8/64 loss: 0.18750739097595215
Batch 9/64 loss: 0.2023966908454895
Batch 10/64 loss: 0.19690895080566406
Batch 11/64 loss: 0.17983633279800415
Batch 12/64 loss: 0.1878710389137268
Batch 13/64 loss: 0.18401861190795898
Batch 14/64 loss: 0.19106024503707886
Batch 15/64 loss: 0.19407105445861816
Batch 16/64 loss: 0.18443423509597778
Batch 17/64 loss: 0.20613884925842285
Batch 18/64 loss: 0.1998693346977234
Batch 19/64 loss: 0.18142211437225342
Batch 20/64 loss: 0.18287432193756104
Batch 21/64 loss: 0.1779172420501709
Batch 22/64 loss: 0.18244701623916626
Batch 23/64 loss: 0.1819353699684143
Batch 24/64 loss: 0.19152265787124634
Batch 25/64 loss: 0.17884355783462524
Batch 26/64 loss: 0.18439042568206787
Batch 27/64 loss: 0.18958866596221924
Batch 28/64 loss: 0.18023866415023804
Batch 29/64 loss: 0.18692243099212646
Batch 30/64 loss: 0.1903458833694458
Batch 31/64 loss: 0.21275192499160767
Batch 32/64 loss: 0.1750393509864807
Batch 33/64 loss: 0.19986730813980103
Batch 34/64 loss: 0.18823742866516113
Batch 35/64 loss: 0.19527840614318848
Batch 36/64 loss: 0.19132870435714722
Batch 37/64 loss: 0.18784821033477783
Batch 38/64 loss: 0.1889936923980713
Batch 39/64 loss: 0.18499654531478882
Batch 40/64 loss: 0.18717825412750244
Batch 41/64 loss: 0.19872218370437622
Batch 42/64 loss: 0.19602537155151367
Batch 43/64 loss: 0.2089468240737915
Batch 44/64 loss: 0.1871403455734253
Batch 45/64 loss: 0.18560165166854858
Batch 46/64 loss: 0.19061291217803955
Batch 47/64 loss: 0.19404631853103638
Batch 48/64 loss: 0.18620514869689941
Batch 49/64 loss: 0.18184196949005127
Batch 50/64 loss: 0.1862785816192627
Batch 51/64 loss: 0.1792648434638977
Batch 52/64 loss: 0.18370717763900757
Batch 53/64 loss: 0.17546319961547852
Batch 54/64 loss: 0.1868753433227539
Batch 55/64 loss: 0.18185657262802124
Batch 56/64 loss: 0.19150406122207642
Batch 57/64 loss: 0.18171781301498413
Batch 58/64 loss: 0.18474853038787842
Batch 59/64 loss: 0.18970024585723877
Batch 60/64 loss: 0.1801760196685791
Batch 61/64 loss: 0.19632118940353394
Batch 62/64 loss: 0.19826728105545044
Batch 63/64 loss: 0.19569993019104004
Batch 64/64 loss: 0.19376671314239502
Epoch 482  Train loss: 0.18843758854211545  Val loss: 0.30034421645488935
Epoch 483
-------------------------------
Batch 1/64 loss: 0.18495142459869385
Batch 2/64 loss: 0.1872125267982483
Batch 3/64 loss: 0.17298352718353271
Batch 4/64 loss: 0.1873488426208496
Batch 5/64 loss: 0.18359047174453735
Batch 6/64 loss: 0.18523848056793213
Batch 7/64 loss: 0.19005131721496582
Batch 8/64 loss: 0.1754920482635498
Batch 9/64 loss: 0.19515979290008545
Batch 10/64 loss: 0.18391239643096924
Batch 11/64 loss: 0.19507932662963867
Batch 12/64 loss: 0.1823362112045288
Batch 13/64 loss: 0.17759215831756592
Batch 14/64 loss: 0.19492822885513306
Batch 15/64 loss: 0.19334805011749268
Batch 16/64 loss: 0.1803951859474182
Batch 17/64 loss: 0.17768782377243042
Batch 18/64 loss: 0.18964099884033203
Batch 19/64 loss: 0.18497204780578613
Batch 20/64 loss: 0.1881617307662964
Batch 21/64 loss: 0.1827336549758911
Batch 22/64 loss: 0.18498742580413818
Batch 23/64 loss: 0.19273513555526733
Batch 24/64 loss: 0.18137288093566895
Batch 25/64 loss: 0.17586833238601685
Batch 26/64 loss: 0.17540007829666138
Batch 27/64 loss: 0.20885062217712402
Batch 28/64 loss: 0.19354504346847534
Batch 29/64 loss: 0.18940317630767822
Batch 30/64 loss: 0.1778436303138733
Batch 31/64 loss: 0.17783641815185547
Batch 32/64 loss: 0.19293051958084106
Batch 33/64 loss: 0.20731359720230103
Batch 34/64 loss: 0.18202781677246094
Batch 35/64 loss: 0.1915450096130371
Batch 36/64 loss: 0.17744606733322144
Batch 37/64 loss: 0.188099205493927
Batch 38/64 loss: 0.1796015501022339
Batch 39/64 loss: 0.18490147590637207
Batch 40/64 loss: 0.18840229511260986
Batch 41/64 loss: 0.1874988079071045
Batch 42/64 loss: 0.20300114154815674
Batch 43/64 loss: 0.196586012840271
Batch 44/64 loss: 0.20437538623809814
Batch 45/64 loss: 0.19683092832565308
Batch 46/64 loss: 0.18759304285049438
Batch 47/64 loss: 0.20011240243911743
Batch 48/64 loss: 0.19542348384857178
Batch 49/64 loss: 0.20225340127944946
Batch 50/64 loss: 0.20094645023345947
Batch 51/64 loss: 0.18535834550857544
Batch 52/64 loss: 0.20084846019744873
Batch 53/64 loss: 0.18641924858093262
Batch 54/64 loss: 0.18238967657089233
Batch 55/64 loss: 0.18820995092391968
Batch 56/64 loss: 0.1879643201828003
Batch 57/64 loss: 0.187005877494812
Batch 58/64 loss: 0.1876283884048462
Batch 59/64 loss: 0.19463109970092773
Batch 60/64 loss: 0.18579202890396118
Batch 61/64 loss: 0.17496275901794434
Batch 62/64 loss: 0.19001156091690063
Batch 63/64 loss: 0.19214189052581787
Batch 64/64 loss: 0.19878482818603516
Epoch 483  Train loss: 0.18839215390822467  Val loss: 0.29983340219124077
Epoch 484
-------------------------------
Batch 1/64 loss: 0.19686740636825562
Batch 2/64 loss: 0.18336725234985352
Batch 3/64 loss: 0.19049477577209473
Batch 4/64 loss: 0.1887684464454651
Batch 5/64 loss: 0.18912500143051147
Batch 6/64 loss: 0.1785864233970642
Batch 7/64 loss: 0.19325768947601318
Batch 8/64 loss: 0.1775425672531128
Batch 9/64 loss: 0.17820775508880615
Batch 10/64 loss: 0.18811142444610596
Batch 11/64 loss: 0.1758655309677124
Batch 12/64 loss: 0.19160997867584229
Batch 13/64 loss: 0.20256274938583374
Batch 14/64 loss: 0.20146644115447998
Batch 15/64 loss: 0.19333183765411377
Batch 16/64 loss: 0.20134025812149048
Batch 17/64 loss: 0.19374418258666992
Batch 18/64 loss: 0.18115496635437012
Batch 19/64 loss: 0.17834001779556274
Batch 20/64 loss: 0.18816876411437988
Batch 21/64 loss: 0.18527752161026
Batch 22/64 loss: 0.18217098712921143
Batch 23/64 loss: 0.18445050716400146
Batch 24/64 loss: 0.20669132471084595
Batch 25/64 loss: 0.18494915962219238
Batch 26/64 loss: 0.18093985319137573
Batch 27/64 loss: 0.18683946132659912
Batch 28/64 loss: 0.18679457902908325
Batch 29/64 loss: 0.17404919862747192
Batch 30/64 loss: 0.1888113021850586
Batch 31/64 loss: 0.1836795210838318
Batch 32/64 loss: 0.18587976694107056
Batch 33/64 loss: 0.19721734523773193
Batch 34/64 loss: 0.1906723976135254
Batch 35/64 loss: 0.18617981672286987
Batch 36/64 loss: 0.1864418387413025
Batch 37/64 loss: 0.1880115270614624
Batch 38/64 loss: 0.17630136013031006
Batch 39/64 loss: 0.1887567639350891
Batch 40/64 loss: 0.18824321031570435
Batch 41/64 loss: 0.20123237371444702
Batch 42/64 loss: 0.20479893684387207
Batch 43/64 loss: 0.19026798009872437
Batch 44/64 loss: 0.1795816421508789
Batch 45/64 loss: 0.18988192081451416
Batch 46/64 loss: 0.18757057189941406
Batch 47/64 loss: 0.19945275783538818
Batch 48/64 loss: 0.17874926328659058
Batch 49/64 loss: 0.18913370370864868
Batch 50/64 loss: 0.19233572483062744
Batch 51/64 loss: 0.20596957206726074
Batch 52/64 loss: 0.17780321836471558
Batch 53/64 loss: 0.18312758207321167
Batch 54/64 loss: 0.18996232748031616
Batch 55/64 loss: 0.18785858154296875
Batch 56/64 loss: 0.18008482456207275
Batch 57/64 loss: 0.17801451683044434
Batch 58/64 loss: 0.18574345111846924
Batch 59/64 loss: 0.1941167116165161
Batch 60/64 loss: 0.19745981693267822
Batch 61/64 loss: 0.19971495866775513
Batch 62/64 loss: 0.18578064441680908
Batch 63/64 loss: 0.20363473892211914
Batch 64/64 loss: 0.20057255029678345
Epoch 484  Train loss: 0.1888153120583179  Val loss: 0.29979823811357376
Epoch 485
-------------------------------
Batch 1/64 loss: 0.20060527324676514
Batch 2/64 loss: 0.18547797203063965
Batch 3/64 loss: 0.1907656192779541
Batch 4/64 loss: 0.1883227825164795
Batch 5/64 loss: 0.1956470012664795
Batch 6/64 loss: 0.19174790382385254
Batch 7/64 loss: 0.18933242559432983
Batch 8/64 loss: 0.1891331672668457
Batch 9/64 loss: 0.18622303009033203
Batch 10/64 loss: 0.18971878290176392
Batch 11/64 loss: 0.17893099784851074
Batch 12/64 loss: 0.17788457870483398
Batch 13/64 loss: 0.18399345874786377
Batch 14/64 loss: 0.1783663034439087
Batch 15/64 loss: 0.2042546272277832
Batch 16/64 loss: 0.185471773147583
Batch 17/64 loss: 0.18431276082992554
Batch 18/64 loss: 0.18161821365356445
Batch 19/64 loss: 0.18155008554458618
Batch 20/64 loss: 0.20282882452011108
Batch 21/64 loss: 0.1966361403465271
Batch 22/64 loss: 0.21508216857910156
Batch 23/64 loss: 0.1825515627861023
Batch 24/64 loss: 0.18054860830307007
Batch 25/64 loss: 0.207122802734375
Batch 26/64 loss: 0.19533628225326538
Batch 27/64 loss: 0.1965630054473877
Batch 28/64 loss: 0.1769750714302063
Batch 29/64 loss: 0.18251186609268188
Batch 30/64 loss: 0.1975400447845459
Batch 31/64 loss: 0.1950368881225586
Batch 32/64 loss: 0.1961778998374939
Batch 33/64 loss: 0.19059616327285767
Batch 34/64 loss: 0.1896200180053711
Batch 35/64 loss: 0.18343782424926758
Batch 36/64 loss: 0.18024545907974243
Batch 37/64 loss: 0.18645209074020386
Batch 38/64 loss: 0.18639230728149414
Batch 39/64 loss: 0.19517040252685547
Batch 40/64 loss: 0.18487566709518433
Batch 41/64 loss: 0.176954984664917
Batch 42/64 loss: 0.19050312042236328
Batch 43/64 loss: 0.17859727144241333
Batch 44/64 loss: 0.18946921825408936
Batch 45/64 loss: 0.19833838939666748
Batch 46/64 loss: 0.18403524160385132
Batch 47/64 loss: 0.182231605052948
Batch 48/64 loss: 0.19387716054916382
Batch 49/64 loss: 0.17817366123199463
Batch 50/64 loss: 0.20054948329925537
Batch 51/64 loss: 0.18781697750091553
Batch 52/64 loss: 0.17294204235076904
Batch 53/64 loss: 0.17748624086380005
Batch 54/64 loss: 0.17991602420806885
Batch 55/64 loss: 0.20231688022613525
Batch 56/64 loss: 0.1953505277633667
Batch 57/64 loss: 0.18307030200958252
Batch 58/64 loss: 0.17888230085372925
Batch 59/64 loss: 0.18063533306121826
Batch 60/64 loss: 0.17568129301071167
Batch 61/64 loss: 0.20023423433303833
Batch 62/64 loss: 0.19797974824905396
Batch 63/64 loss: 0.1914324164390564
Batch 64/64 loss: 0.18776822090148926
Epoch 485  Train loss: 0.188586015327304  Val loss: 0.29925681123209164
Epoch 486
-------------------------------
Batch 1/64 loss: 0.2013798952102661
Batch 2/64 loss: 0.19434064626693726
Batch 3/64 loss: 0.18465858697891235
Batch 4/64 loss: 0.18869692087173462
Batch 5/64 loss: 0.17972469329833984
Batch 6/64 loss: 0.18417304754257202
Batch 7/64 loss: 0.18968987464904785
Batch 8/64 loss: 0.18605279922485352
Batch 9/64 loss: 0.1933252215385437
Batch 10/64 loss: 0.1966235637664795
Batch 11/64 loss: 0.18728137016296387
Batch 12/64 loss: 0.19203168153762817
Batch 13/64 loss: 0.18774384260177612
Batch 14/64 loss: 0.18510329723358154
Batch 15/64 loss: 0.18586063385009766
Batch 16/64 loss: 0.18747812509536743
Batch 17/64 loss: 0.17392313480377197
Batch 18/64 loss: 0.1847401261329651
Batch 19/64 loss: 0.19055140018463135
Batch 20/64 loss: 0.18781960010528564
Batch 21/64 loss: 0.17923736572265625
Batch 22/64 loss: 0.1746593713760376
Batch 23/64 loss: 0.19572174549102783
Batch 24/64 loss: 0.18925446271896362
Batch 25/64 loss: 0.19456183910369873
Batch 26/64 loss: 0.18191850185394287
Batch 27/64 loss: 0.1807718276977539
Batch 28/64 loss: 0.180810809135437
Batch 29/64 loss: 0.18576622009277344
Batch 30/64 loss: 0.19536328315734863
Batch 31/64 loss: 0.18626856803894043
Batch 32/64 loss: 0.18821579217910767
Batch 33/64 loss: 0.19163382053375244
Batch 34/64 loss: 0.18870139122009277
Batch 35/64 loss: 0.18371760845184326
Batch 36/64 loss: 0.18705177307128906
Batch 37/64 loss: 0.2055099606513977
Batch 38/64 loss: 0.18420374393463135
Batch 39/64 loss: 0.19667530059814453
Batch 40/64 loss: 0.18525803089141846
Batch 41/64 loss: 0.18478810787200928
Batch 42/64 loss: 0.1892145872116089
Batch 43/64 loss: 0.18252140283584595
Batch 44/64 loss: 0.17969608306884766
Batch 45/64 loss: 0.18753772974014282
Batch 46/64 loss: 0.19610083103179932
Batch 47/64 loss: 0.1975935697555542
Batch 48/64 loss: 0.19154196977615356
Batch 49/64 loss: 0.17718642950057983
Batch 50/64 loss: 0.18580329418182373
Batch 51/64 loss: 0.17440438270568848
Batch 52/64 loss: 0.20035243034362793
Batch 53/64 loss: 0.1838119626045227
Batch 54/64 loss: 0.18815326690673828
Batch 55/64 loss: 0.17557191848754883
Batch 56/64 loss: 0.19829487800598145
Batch 57/64 loss: 0.20006752014160156
Batch 58/64 loss: 0.18756335973739624
Batch 59/64 loss: 0.19530004262924194
Batch 60/64 loss: 0.18280673027038574
Batch 61/64 loss: 0.20184427499771118
Batch 62/64 loss: 0.18747150897979736
Batch 63/64 loss: 0.19185757637023926
Batch 64/64 loss: 0.18512308597564697
Epoch 486  Train loss: 0.18815413409588383  Val loss: 0.3001307263407101
Epoch 487
-------------------------------
Batch 1/64 loss: 0.17558807134628296
Batch 2/64 loss: 0.18503743410110474
Batch 3/64 loss: 0.2003113031387329
Batch 4/64 loss: 0.17986011505126953
Batch 5/64 loss: 0.1925678253173828
Batch 6/64 loss: 0.18907690048217773
Batch 7/64 loss: 0.18742477893829346
Batch 8/64 loss: 0.2007509469985962
Batch 9/64 loss: 0.19505685567855835
Batch 10/64 loss: 0.17984986305236816
Batch 11/64 loss: 0.19109976291656494
Batch 12/64 loss: 0.1851903200149536
Batch 13/64 loss: 0.18063139915466309
Batch 14/64 loss: 0.17988324165344238
Batch 15/64 loss: 0.1881495714187622
Batch 16/64 loss: 0.19101190567016602
Batch 17/64 loss: 0.17612046003341675
Batch 18/64 loss: 0.19071704149246216
Batch 19/64 loss: 0.18632841110229492
Batch 20/64 loss: 0.184059739112854
Batch 21/64 loss: 0.190778911113739
Batch 22/64 loss: 0.17527681589126587
Batch 23/64 loss: 0.1858670711517334
Batch 24/64 loss: 0.17972075939178467
Batch 25/64 loss: 0.18176788091659546
Batch 26/64 loss: 0.1797240972518921
Batch 27/64 loss: 0.17356717586517334
Batch 28/64 loss: 0.1877669095993042
Batch 29/64 loss: 0.19991391897201538
Batch 30/64 loss: 0.1765156388282776
Batch 31/64 loss: 0.1872107982635498
Batch 32/64 loss: 0.17917805910110474
Batch 33/64 loss: 0.18416237831115723
Batch 34/64 loss: 0.17945873737335205
Batch 35/64 loss: 0.19218659400939941
Batch 36/64 loss: 0.1826726198196411
Batch 37/64 loss: 0.19489723443984985
Batch 38/64 loss: 0.18896985054016113
Batch 39/64 loss: 0.18767762184143066
Batch 40/64 loss: 0.1865025758743286
Batch 41/64 loss: 0.19520503282546997
Batch 42/64 loss: 0.1878756284713745
Batch 43/64 loss: 0.19169872999191284
Batch 44/64 loss: 0.1882457137107849
Batch 45/64 loss: 0.19036835432052612
Batch 46/64 loss: 0.19682973623275757
Batch 47/64 loss: 0.20479750633239746
Batch 48/64 loss: 0.19468027353286743
Batch 49/64 loss: 0.18184685707092285
Batch 50/64 loss: 0.1948544979095459
Batch 51/64 loss: 0.1902260184288025
Batch 52/64 loss: 0.19869565963745117
Batch 53/64 loss: 0.20359373092651367
Batch 54/64 loss: 0.20712357759475708
Batch 55/64 loss: 0.20667994022369385
Batch 56/64 loss: 0.18325358629226685
Batch 57/64 loss: 0.19730162620544434
Batch 58/64 loss: 0.18674874305725098
Batch 59/64 loss: 0.18039470911026
Batch 60/64 loss: 0.18922823667526245
Batch 61/64 loss: 0.18345677852630615
Batch 62/64 loss: 0.20367848873138428
Batch 63/64 loss: 0.19255119562149048
Batch 64/64 loss: 0.20091527700424194
Epoch 487  Train loss: 0.18874592430451337  Val loss: 0.30022426712553935
Epoch 488
-------------------------------
Batch 1/64 loss: 0.18473559617996216
Batch 2/64 loss: 0.182009756565094
Batch 3/64 loss: 0.18123531341552734
Batch 4/64 loss: 0.1930946707725525
Batch 5/64 loss: 0.1914733648300171
Batch 6/64 loss: 0.19042247533798218
Batch 7/64 loss: 0.18530410528182983
Batch 8/64 loss: 0.17658424377441406
Batch 9/64 loss: 0.19524312019348145
Batch 10/64 loss: 0.17834538221359253
Batch 11/64 loss: 0.1935107707977295
Batch 12/64 loss: 0.18594825267791748
Batch 13/64 loss: 0.1807335615158081
Batch 14/64 loss: 0.19441896677017212
Batch 15/64 loss: 0.18167757987976074
Batch 16/64 loss: 0.1788347363471985
Batch 17/64 loss: 0.1889936923980713
Batch 18/64 loss: 0.17761439085006714
Batch 19/64 loss: 0.19277352094650269
Batch 20/64 loss: 0.19041597843170166
Batch 21/64 loss: 0.1982191801071167
Batch 22/64 loss: 0.17813467979431152
Batch 23/64 loss: 0.1881413459777832
Batch 24/64 loss: 0.1857624650001526
Batch 25/64 loss: 0.18863749504089355
Batch 26/64 loss: 0.17974424362182617
Batch 27/64 loss: 0.1881771683692932
Batch 28/64 loss: 0.19742953777313232
Batch 29/64 loss: 0.1832612156867981
Batch 30/64 loss: 0.19457471370697021
Batch 31/64 loss: 0.1784137487411499
Batch 32/64 loss: 0.18243634700775146
Batch 33/64 loss: 0.19948440790176392
Batch 34/64 loss: 0.18139863014221191
Batch 35/64 loss: 0.18372118473052979
Batch 36/64 loss: 0.19586968421936035
Batch 37/64 loss: 0.18248766660690308
Batch 38/64 loss: 0.18983930349349976
Batch 39/64 loss: 0.18591904640197754
Batch 40/64 loss: 0.2072594165802002
Batch 41/64 loss: 0.19649481773376465
Batch 42/64 loss: 0.19246453046798706
Batch 43/64 loss: 0.19598126411437988
Batch 44/64 loss: 0.18470865488052368
Batch 45/64 loss: 0.18301063776016235
Batch 46/64 loss: 0.18576347827911377
Batch 47/64 loss: 0.18010085821151733
Batch 48/64 loss: 0.1915709376335144
Batch 49/64 loss: 0.18528831005096436
Batch 50/64 loss: 0.1938273310661316
Batch 51/64 loss: 0.19523215293884277
Batch 52/64 loss: 0.1848832368850708
Batch 53/64 loss: 0.1831350326538086
Batch 54/64 loss: 0.19913917779922485
Batch 55/64 loss: 0.18883323669433594
Batch 56/64 loss: 0.18359887599945068
Batch 57/64 loss: 0.184609055519104
Batch 58/64 loss: 0.18928301334381104
Batch 59/64 loss: 0.20022153854370117
Batch 60/64 loss: 0.17959344387054443
Batch 61/64 loss: 0.19057917594909668
Batch 62/64 loss: 0.17367231845855713
Batch 63/64 loss: 0.1946110725402832
Batch 64/64 loss: 0.21480512619018555
Epoch 488  Train loss: 0.18807822676265942  Val loss: 0.3004005217470254
Epoch 489
-------------------------------
Batch 1/64 loss: 0.18588238954544067
Batch 2/64 loss: 0.1771358847618103
Batch 3/64 loss: 0.18130230903625488
Batch 4/64 loss: 0.18810325860977173
Batch 5/64 loss: 0.1841335892677307
Batch 6/64 loss: 0.19349324703216553
Batch 7/64 loss: 0.18488675355911255
Batch 8/64 loss: 0.19159716367721558
Batch 9/64 loss: 0.19537091255187988
Batch 10/64 loss: 0.17920845746994019
Batch 11/64 loss: 0.19228798151016235
Batch 12/64 loss: 0.19417309761047363
Batch 13/64 loss: 0.1918007731437683
Batch 14/64 loss: 0.1867261528968811
Batch 15/64 loss: 0.1794295310974121
Batch 16/64 loss: 0.19032227993011475
Batch 17/64 loss: 0.1842823028564453
Batch 18/64 loss: 0.1895037293434143
Batch 19/64 loss: 0.2047688364982605
Batch 20/64 loss: 0.203036367893219
Batch 21/64 loss: 0.1860356330871582
Batch 22/64 loss: 0.18929922580718994
Batch 23/64 loss: 0.17227160930633545
Batch 24/64 loss: 0.18171143531799316
Batch 25/64 loss: 0.19321280717849731
Batch 26/64 loss: 0.20095068216323853
Batch 27/64 loss: 0.18653148412704468
Batch 28/64 loss: 0.1954253911972046
Batch 29/64 loss: 0.18514108657836914
Batch 30/64 loss: 0.18371057510375977
Batch 31/64 loss: 0.18183767795562744
Batch 32/64 loss: 0.18697530031204224
Batch 33/64 loss: 0.18446052074432373
Batch 34/64 loss: 0.21394723653793335
Batch 35/64 loss: 0.18281203508377075
Batch 36/64 loss: 0.17987889051437378
Batch 37/64 loss: 0.1851586103439331
Batch 38/64 loss: 0.18785607814788818
Batch 39/64 loss: 0.18933051824569702
Batch 40/64 loss: 0.18990743160247803
Batch 41/64 loss: 0.19106948375701904
Batch 42/64 loss: 0.18320196866989136
Batch 43/64 loss: 0.179551899433136
Batch 44/64 loss: 0.18061965703964233
Batch 45/64 loss: 0.18301337957382202
Batch 46/64 loss: 0.18629670143127441
Batch 47/64 loss: 0.1855839490890503
Batch 48/64 loss: 0.17678606510162354
Batch 49/64 loss: 0.1787186861038208
Batch 50/64 loss: 0.1854228973388672
Batch 51/64 loss: 0.18101155757904053
Batch 52/64 loss: 0.17448163032531738
Batch 53/64 loss: 0.1828123927116394
Batch 54/64 loss: 0.18647778034210205
Batch 55/64 loss: 0.19642597436904907
Batch 56/64 loss: 0.18335986137390137
Batch 57/64 loss: 0.18012303113937378
Batch 58/64 loss: 0.18992698192596436
Batch 59/64 loss: 0.19511187076568604
Batch 60/64 loss: 0.19579464197158813
Batch 61/64 loss: 0.19092023372650146
Batch 62/64 loss: 0.18784034252166748
Batch 63/64 loss: 0.17936140298843384
Batch 64/64 loss: 0.2100542187690735
Epoch 489  Train loss: 0.18737807530982822  Val loss: 0.299505157978674
Epoch 490
-------------------------------
Batch 1/64 loss: 0.20073896646499634
Batch 2/64 loss: 0.1793791651725769
Batch 3/64 loss: 0.18483132123947144
Batch 4/64 loss: 0.18510985374450684
Batch 5/64 loss: 0.17678606510162354
Batch 6/64 loss: 0.18723410367965698
Batch 7/64 loss: 0.1950998306274414
Batch 8/64 loss: 0.1839199662208557
Batch 9/64 loss: 0.1971888542175293
Batch 10/64 loss: 0.19777780771255493
Batch 11/64 loss: 0.18344974517822266
Batch 12/64 loss: 0.1962357759475708
Batch 13/64 loss: 0.18122416734695435
Batch 14/64 loss: 0.1860140562057495
Batch 15/64 loss: 0.190218985080719
Batch 16/64 loss: 0.1947009563446045
Batch 17/64 loss: 0.19236648082733154
Batch 18/64 loss: 0.19723016023635864
Batch 19/64 loss: 0.1815893054008484
Batch 20/64 loss: 0.19901877641677856
Batch 21/64 loss: 0.18391233682632446
Batch 22/64 loss: 0.1845809817314148
Batch 23/64 loss: 0.1849876046180725
Batch 24/64 loss: 0.18136900663375854
Batch 25/64 loss: 0.1865677833557129
Batch 26/64 loss: 0.19960105419158936
Batch 27/64 loss: 0.1915956735610962
Batch 28/64 loss: 0.19899845123291016
Batch 29/64 loss: 0.18519186973571777
Batch 30/64 loss: 0.18997180461883545
Batch 31/64 loss: 0.18385785818099976
Batch 32/64 loss: 0.1876024603843689
Batch 33/64 loss: 0.18261277675628662
Batch 34/64 loss: 0.18722528219223022
Batch 35/64 loss: 0.18624275922775269
Batch 36/64 loss: 0.17980742454528809
Batch 37/64 loss: 0.19762587547302246
Batch 38/64 loss: 0.19226157665252686
Batch 39/64 loss: 0.17974752187728882
Batch 40/64 loss: 0.19543057680130005
Batch 41/64 loss: 0.1832677721977234
Batch 42/64 loss: 0.1850728988647461
Batch 43/64 loss: 0.1893007755279541
Batch 44/64 loss: 0.18627405166625977
Batch 45/64 loss: 0.20267343521118164
Batch 46/64 loss: 0.19050830602645874
Batch 47/64 loss: 0.17902237176895142
Batch 48/64 loss: 0.18666881322860718
Batch 49/64 loss: 0.20865142345428467
Batch 50/64 loss: 0.1996161937713623
Batch 51/64 loss: 0.19559550285339355
Batch 52/64 loss: 0.18028944730758667
Batch 53/64 loss: 0.18508201837539673
Batch 54/64 loss: 0.18676471710205078
Batch 55/64 loss: 0.18500828742980957
Batch 56/64 loss: 0.1885393261909485
Batch 57/64 loss: 0.1780259609222412
Batch 58/64 loss: 0.1868220567703247
Batch 59/64 loss: 0.18949443101882935
Batch 60/64 loss: 0.19888347387313843
Batch 61/64 loss: 0.17577600479125977
Batch 62/64 loss: 0.18682587146759033
Batch 63/64 loss: 0.18912416696548462
Batch 64/64 loss: 0.19371920824050903
Epoch 490  Train loss: 0.18873539976045198  Val loss: 0.2995389114130813
Epoch 491
-------------------------------
Batch 1/64 loss: 0.18488752841949463
Batch 2/64 loss: 0.1889973282814026
Batch 3/64 loss: 0.19940710067749023
Batch 4/64 loss: 0.188792884349823
Batch 5/64 loss: 0.18967926502227783
Batch 6/64 loss: 0.18881726264953613
Batch 7/64 loss: 0.18464773893356323
Batch 8/64 loss: 0.18803447484970093
Batch 9/64 loss: 0.21403706073760986
Batch 10/64 loss: 0.1885662078857422
Batch 11/64 loss: 0.17998504638671875
Batch 12/64 loss: 0.17548972368240356
Batch 13/64 loss: 0.18750053644180298
Batch 14/64 loss: 0.19120436906814575
Batch 15/64 loss: 0.17618310451507568
Batch 16/64 loss: 0.1806071400642395
Batch 17/64 loss: 0.17836499214172363
Batch 18/64 loss: 0.20093685388565063
Batch 19/64 loss: 0.17972737550735474
Batch 20/64 loss: 0.18803369998931885
Batch 21/64 loss: 0.1863192319869995
Batch 22/64 loss: 0.18147313594818115
Batch 23/64 loss: 0.19839709997177124
Batch 24/64 loss: 0.18582266569137573
Batch 25/64 loss: 0.1772739291191101
Batch 26/64 loss: 0.18108528852462769
Batch 27/64 loss: 0.1848403811454773
Batch 28/64 loss: 0.1919594407081604
Batch 29/64 loss: 0.19091200828552246
Batch 30/64 loss: 0.18315178155899048
Batch 31/64 loss: 0.18726247549057007
Batch 32/64 loss: 0.1902584433555603
Batch 33/64 loss: 0.18142491579055786
Batch 34/64 loss: 0.19155240058898926
Batch 35/64 loss: 0.18736541271209717
Batch 36/64 loss: 0.1846194863319397
Batch 37/64 loss: 0.18803220987319946
Batch 38/64 loss: 0.19010913372039795
Batch 39/64 loss: 0.19367724657058716
Batch 40/64 loss: 0.18769341707229614
Batch 41/64 loss: 0.17965620756149292
Batch 42/64 loss: 0.1801614761352539
Batch 43/64 loss: 0.18793010711669922
Batch 44/64 loss: 0.1936778426170349
Batch 45/64 loss: 0.1867527961730957
Batch 46/64 loss: 0.1958484649658203
Batch 47/64 loss: 0.19248074293136597
Batch 48/64 loss: 0.1710166335105896
Batch 49/64 loss: 0.18110394477844238
Batch 50/64 loss: 0.19428038597106934
Batch 51/64 loss: 0.18700861930847168
Batch 52/64 loss: 0.1990906000137329
Batch 53/64 loss: 0.19155728816986084
Batch 54/64 loss: 0.1821860671043396
Batch 55/64 loss: 0.1822829246520996
Batch 56/64 loss: 0.18754220008850098
Batch 57/64 loss: 0.19182342290878296
Batch 58/64 loss: 0.18421655893325806
Batch 59/64 loss: 0.18246406316757202
Batch 60/64 loss: 0.19796526432037354
Batch 61/64 loss: 0.19233524799346924
Batch 62/64 loss: 0.19129449129104614
Batch 63/64 loss: 0.18671256303787231
Batch 64/64 loss: 0.18187779188156128
Epoch 491  Train loss: 0.18749687928779452  Val loss: 0.2996236864234164
Epoch 492
-------------------------------
Batch 1/64 loss: 0.19241702556610107
Batch 2/64 loss: 0.19539207220077515
Batch 3/64 loss: 0.18254679441452026
Batch 4/64 loss: 0.18042993545532227
Batch 5/64 loss: 0.18615585565567017
Batch 6/64 loss: 0.1960989236831665
Batch 7/64 loss: 0.1887577772140503
Batch 8/64 loss: 0.181205153465271
Batch 9/64 loss: 0.17774981260299683
Batch 10/64 loss: 0.17860865592956543
Batch 11/64 loss: 0.19150876998901367
Batch 12/64 loss: 0.18704146146774292
Batch 13/64 loss: 0.17840230464935303
Batch 14/64 loss: 0.18412721157073975
Batch 15/64 loss: 0.18858379125595093
Batch 16/64 loss: 0.18960422277450562
Batch 17/64 loss: 0.18253356218338013
Batch 18/64 loss: 0.18763840198516846
Batch 19/64 loss: 0.19679808616638184
Batch 20/64 loss: 0.18636775016784668
Batch 21/64 loss: 0.18450099229812622
Batch 22/64 loss: 0.1963353157043457
Batch 23/64 loss: 0.19868826866149902
Batch 24/64 loss: 0.19638389348983765
Batch 25/64 loss: 0.19012320041656494
Batch 26/64 loss: 0.17059916257858276
Batch 27/64 loss: 0.1914873719215393
Batch 28/64 loss: 0.18679368495941162
Batch 29/64 loss: 0.18342018127441406
Batch 30/64 loss: 0.19518202543258667
Batch 31/64 loss: 0.19277048110961914
Batch 32/64 loss: 0.17895805835723877
Batch 33/64 loss: 0.19417613744735718
Batch 34/64 loss: 0.1749693751335144
Batch 35/64 loss: 0.1740790605545044
Batch 36/64 loss: 0.18855905532836914
Batch 37/64 loss: 0.1843111515045166
Batch 38/64 loss: 0.18327665328979492
Batch 39/64 loss: 0.19441437721252441
Batch 40/64 loss: 0.181005597114563
Batch 41/64 loss: 0.19118136167526245
Batch 42/64 loss: 0.1801307201385498
Batch 43/64 loss: 0.18707787990570068
Batch 44/64 loss: 0.19141840934753418
Batch 45/64 loss: 0.19717830419540405
Batch 46/64 loss: 0.18810808658599854
Batch 47/64 loss: 0.18781566619873047
Batch 48/64 loss: 0.18689322471618652
Batch 49/64 loss: 0.18969708681106567
Batch 50/64 loss: 0.1959991455078125
Batch 51/64 loss: 0.18811529874801636
Batch 52/64 loss: 0.18977820873260498
Batch 53/64 loss: 0.19200384616851807
Batch 54/64 loss: 0.20534580945968628
Batch 55/64 loss: 0.2029476761817932
Batch 56/64 loss: 0.1971113681793213
Batch 57/64 loss: 0.1823115348815918
Batch 58/64 loss: 0.21168196201324463
Batch 59/64 loss: 0.19289398193359375
Batch 60/64 loss: 0.21777045726776123
Batch 61/64 loss: 0.1897040605545044
Batch 62/64 loss: 0.18702298402786255
Batch 63/64 loss: 0.18030190467834473
Batch 64/64 loss: 0.18149620294570923
Epoch 492  Train loss: 0.18887235674203612  Val loss: 0.29981998397722276
Epoch 493
-------------------------------
Batch 1/64 loss: 0.19130021333694458
Batch 2/64 loss: 0.19553512334823608
Batch 3/64 loss: 0.18791013956069946
Batch 4/64 loss: 0.18867599964141846
Batch 5/64 loss: 0.18132895231246948
Batch 6/64 loss: 0.17995113134384155
Batch 7/64 loss: 0.18657898902893066
Batch 8/64 loss: 0.18936443328857422
Batch 9/64 loss: 0.1838192343711853
Batch 10/64 loss: 0.18733710050582886
Batch 11/64 loss: 0.18989288806915283
Batch 12/64 loss: 0.19881319999694824
Batch 13/64 loss: 0.20153778791427612
Batch 14/64 loss: 0.18419557809829712
Batch 15/64 loss: 0.19147056341171265
Batch 16/64 loss: 0.18272292613983154
Batch 17/64 loss: 0.18344396352767944
Batch 18/64 loss: 0.19942325353622437
Batch 19/64 loss: 0.18629050254821777
Batch 20/64 loss: 0.17970943450927734
Batch 21/64 loss: 0.19382691383361816
Batch 22/64 loss: 0.1957608461380005
Batch 23/64 loss: 0.19749361276626587
Batch 24/64 loss: 0.17873483896255493
Batch 25/64 loss: 0.19507503509521484
Batch 26/64 loss: 0.19039320945739746
Batch 27/64 loss: 0.18820053339004517
Batch 28/64 loss: 0.18818151950836182
Batch 29/64 loss: 0.18824058771133423
Batch 30/64 loss: 0.18072569370269775
Batch 31/64 loss: 0.17869138717651367
Batch 32/64 loss: 0.19687241315841675
Batch 33/64 loss: 0.17979681491851807
Batch 34/64 loss: 0.18952429294586182
Batch 35/64 loss: 0.1859561800956726
Batch 36/64 loss: 0.18742364645004272
Batch 37/64 loss: 0.19688642024993896
Batch 38/64 loss: 0.19219374656677246
Batch 39/64 loss: 0.1860952377319336
Batch 40/64 loss: 0.20997971296310425
Batch 41/64 loss: 0.19390302896499634
Batch 42/64 loss: 0.18751239776611328
Batch 43/64 loss: 0.19069159030914307
Batch 44/64 loss: 0.1841907501220703
Batch 45/64 loss: 0.18283259868621826
Batch 46/64 loss: 0.1977701187133789
Batch 47/64 loss: 0.17878085374832153
Batch 48/64 loss: 0.18221259117126465
Batch 49/64 loss: 0.188362717628479
Batch 50/64 loss: 0.18489331007003784
Batch 51/64 loss: 0.18886017799377441
Batch 52/64 loss: 0.19315075874328613
Batch 53/64 loss: 0.19366538524627686
Batch 54/64 loss: 0.1786854863166809
Batch 55/64 loss: 0.17562222480773926
Batch 56/64 loss: 0.1884218454360962
Batch 57/64 loss: 0.19000238180160522
Batch 58/64 loss: 0.1905803680419922
Batch 59/64 loss: 0.19299757480621338
Batch 60/64 loss: 0.1861249804496765
Batch 61/64 loss: 0.19904839992523193
Batch 62/64 loss: 0.19593960046768188
Batch 63/64 loss: 0.18181419372558594
Batch 64/64 loss: 0.19400161504745483
Epoch 493  Train loss: 0.18887715456532497  Val loss: 0.2994081949450306
Epoch 494
-------------------------------
Batch 1/64 loss: 0.19064968824386597
Batch 2/64 loss: 0.18734729290008545
Batch 3/64 loss: 0.18230962753295898
Batch 4/64 loss: 0.1896684169769287
Batch 5/64 loss: 0.19869422912597656
Batch 6/64 loss: 0.1872970461845398
Batch 7/64 loss: 0.17867988348007202
Batch 8/64 loss: 0.19350028038024902
Batch 9/64 loss: 0.18364357948303223
Batch 10/64 loss: 0.1762179732322693
Batch 11/64 loss: 0.18054401874542236
Batch 12/64 loss: 0.1830291748046875
Batch 13/64 loss: 0.19159966707229614
Batch 14/64 loss: 0.18385720252990723
Batch 15/64 loss: 0.1957334280014038
Batch 16/64 loss: 0.1913471221923828
Batch 17/64 loss: 0.18745219707489014
Batch 18/64 loss: 0.1807597279548645
Batch 19/64 loss: 0.20116156339645386
Batch 20/64 loss: 0.18799817562103271
Batch 21/64 loss: 0.19689124822616577
Batch 22/64 loss: 0.18790775537490845
Batch 23/64 loss: 0.18103522062301636
Batch 24/64 loss: 0.18713068962097168
Batch 25/64 loss: 0.2055489420890808
Batch 26/64 loss: 0.1757301688194275
Batch 27/64 loss: 0.19139903783798218
Batch 28/64 loss: 0.181019127368927
Batch 29/64 loss: 0.19283080101013184
Batch 30/64 loss: 0.17810261249542236
Batch 31/64 loss: 0.195539653301239
Batch 32/64 loss: 0.18831384181976318
Batch 33/64 loss: 0.1888485550880432
Batch 34/64 loss: 0.19578886032104492
Batch 35/64 loss: 0.1740168333053589
Batch 36/64 loss: 0.20788168907165527
Batch 37/64 loss: 0.1903964877128601
Batch 38/64 loss: 0.19425159692764282
Batch 39/64 loss: 0.1993890404701233
Batch 40/64 loss: 0.18556207418441772
Batch 41/64 loss: 0.17972689867019653
Batch 42/64 loss: 0.17564457654953003
Batch 43/64 loss: 0.18446636199951172
Batch 44/64 loss: 0.19003057479858398
Batch 45/64 loss: 0.1838841438293457
Batch 46/64 loss: 0.18617689609527588
Batch 47/64 loss: 0.18691450357437134
Batch 48/64 loss: 0.17940926551818848
Batch 49/64 loss: 0.18942445516586304
Batch 50/64 loss: 0.1937551498413086
Batch 51/64 loss: 0.18934184312820435
Batch 52/64 loss: 0.1923084259033203
Batch 53/64 loss: 0.18362635374069214
Batch 54/64 loss: 0.20479202270507812
Batch 55/64 loss: 0.17839521169662476
Batch 56/64 loss: 0.19573068618774414
Batch 57/64 loss: 0.18026840686798096
Batch 58/64 loss: 0.18715810775756836
Batch 59/64 loss: 0.18895000219345093
Batch 60/64 loss: 0.17614126205444336
Batch 61/64 loss: 0.185014545917511
Batch 62/64 loss: 0.19112855195999146
Batch 63/64 loss: 0.1826421022415161
Batch 64/64 loss: 0.18082129955291748
Epoch 494  Train loss: 0.1877587584888234  Val loss: 0.2998822861930349
Epoch 495
-------------------------------
Batch 1/64 loss: 0.1908891797065735
Batch 2/64 loss: 0.17416542768478394
Batch 3/64 loss: 0.1968778371810913
Batch 4/64 loss: 0.1873493194580078
Batch 5/64 loss: 0.17242193222045898
Batch 6/64 loss: 0.1938718557357788
Batch 7/64 loss: 0.1794264316558838
Batch 8/64 loss: 0.19015532732009888
Batch 9/64 loss: 0.1926823854446411
Batch 10/64 loss: 0.18777090311050415
Batch 11/64 loss: 0.19285684823989868
Batch 12/64 loss: 0.1912732720375061
Batch 13/64 loss: 0.19500160217285156
Batch 14/64 loss: 0.19907402992248535
Batch 15/64 loss: 0.19638025760650635
Batch 16/64 loss: 0.1850433349609375
Batch 17/64 loss: 0.18640762567520142
Batch 18/64 loss: 0.19047147035598755
Batch 19/64 loss: 0.1875401735305786
Batch 20/64 loss: 0.1864650845527649
Batch 21/64 loss: 0.19850462675094604
Batch 22/64 loss: 0.17653685808181763
Batch 23/64 loss: 0.1884785294532776
Batch 24/64 loss: 0.1917322278022766
Batch 25/64 loss: 0.18557500839233398
Batch 26/64 loss: 0.1849307417869568
Batch 27/64 loss: 0.19948995113372803
Batch 28/64 loss: 0.18309003114700317
Batch 29/64 loss: 0.19600778818130493
Batch 30/64 loss: 0.18439781665802002
Batch 31/64 loss: 0.18020379543304443
Batch 32/64 loss: 0.18252700567245483
Batch 33/64 loss: 0.19163930416107178
Batch 34/64 loss: 0.18026745319366455
Batch 35/64 loss: 0.19779568910598755
Batch 36/64 loss: 0.19193673133850098
Batch 37/64 loss: 0.1834951639175415
Batch 38/64 loss: 0.2078375220298767
Batch 39/64 loss: 0.18782788515090942
Batch 40/64 loss: 0.18573039770126343
Batch 41/64 loss: 0.19184941053390503
Batch 42/64 loss: 0.18175631761550903
Batch 43/64 loss: 0.1881139874458313
Batch 44/64 loss: 0.18035632371902466
Batch 45/64 loss: 0.18741285800933838
Batch 46/64 loss: 0.18405526876449585
Batch 47/64 loss: 0.18565678596496582
Batch 48/64 loss: 0.18498831987380981
Batch 49/64 loss: 0.1821867823600769
Batch 50/64 loss: 0.18719542026519775
Batch 51/64 loss: 0.1890055537223816
Batch 52/64 loss: 0.18312382698059082
Batch 53/64 loss: 0.18505966663360596
Batch 54/64 loss: 0.19358766078948975
Batch 55/64 loss: 0.1756443977355957
Batch 56/64 loss: 0.19903546571731567
Batch 57/64 loss: 0.18234169483184814
Batch 58/64 loss: 0.18877887725830078
Batch 59/64 loss: 0.20061475038528442
Batch 60/64 loss: 0.17361873388290405
Batch 61/64 loss: 0.18142014741897583
Batch 62/64 loss: 0.2009219527244568
Batch 63/64 loss: 0.18630874156951904
Batch 64/64 loss: 0.17250299453735352
Epoch 495  Train loss: 0.18786727867874445  Val loss: 0.30084415317810687
Epoch 496
-------------------------------
Batch 1/64 loss: 0.1914176344871521
Batch 2/64 loss: 0.18149256706237793
Batch 3/64 loss: 0.19715887308120728
Batch 4/64 loss: 0.1879570484161377
Batch 5/64 loss: 0.18780994415283203
Batch 6/64 loss: 0.1826961636543274
Batch 7/64 loss: 0.1818314790725708
Batch 8/64 loss: 0.18471509218215942
Batch 9/64 loss: 0.17345470190048218
Batch 10/64 loss: 0.20323681831359863
Batch 11/64 loss: 0.19268584251403809
Batch 12/64 loss: 0.18260836601257324
Batch 13/64 loss: 0.17630404233932495
Batch 14/64 loss: 0.18296349048614502
Batch 15/64 loss: 0.19782507419586182
Batch 16/64 loss: 0.18878424167633057
Batch 17/64 loss: 0.17798596620559692
Batch 18/64 loss: 0.19375836849212646
Batch 19/64 loss: 0.1891968846321106
Batch 20/64 loss: 0.17651742696762085
Batch 21/64 loss: 0.19187670946121216
Batch 22/64 loss: 0.19397222995758057
Batch 23/64 loss: 0.1935443878173828
Batch 24/64 loss: 0.18889379501342773
Batch 25/64 loss: 0.18588614463806152
Batch 26/64 loss: 0.19085276126861572
Batch 27/64 loss: 0.18537724018096924
Batch 28/64 loss: 0.17859411239624023
Batch 29/64 loss: 0.18712174892425537
Batch 30/64 loss: 0.18020474910736084
Batch 31/64 loss: 0.1876177191734314
Batch 32/64 loss: 0.17861998081207275
Batch 33/64 loss: 0.19187378883361816
Batch 34/64 loss: 0.19616329669952393
Batch 35/64 loss: 0.18336671590805054
Batch 36/64 loss: 0.18218302726745605
Batch 37/64 loss: 0.18953746557235718
Batch 38/64 loss: 0.1960884928703308
Batch 39/64 loss: 0.1754601001739502
Batch 40/64 loss: 0.18478256464004517
Batch 41/64 loss: 0.18106871843338013
Batch 42/64 loss: 0.18377000093460083
Batch 43/64 loss: 0.1945757269859314
Batch 44/64 loss: 0.18979966640472412
Batch 45/64 loss: 0.19379514455795288
Batch 46/64 loss: 0.19626778364181519
Batch 47/64 loss: 0.19368016719818115
Batch 48/64 loss: 0.20915281772613525
Batch 49/64 loss: 0.20357221364974976
Batch 50/64 loss: 0.19361865520477295
Batch 51/64 loss: 0.18682026863098145
Batch 52/64 loss: 0.20363932847976685
Batch 53/64 loss: 0.1914481520652771
Batch 54/64 loss: 0.18006181716918945
Batch 55/64 loss: 0.18538129329681396
Batch 56/64 loss: 0.18306571245193481
Batch 57/64 loss: 0.18745911121368408
Batch 58/64 loss: 0.17543339729309082
Batch 59/64 loss: 0.19525182247161865
Batch 60/64 loss: 0.1930733323097229
Batch 61/64 loss: 0.18824249505996704
Batch 62/64 loss: 0.18814045190811157
Batch 63/64 loss: 0.19289064407348633
Batch 64/64 loss: 0.17861229181289673
Epoch 496  Train loss: 0.18818172543656592  Val loss: 0.29891267101379604
Epoch 497
-------------------------------
Batch 1/64 loss: 0.19098782539367676
Batch 2/64 loss: 0.18435853719711304
Batch 3/64 loss: 0.18157637119293213
Batch 4/64 loss: 0.19119656085968018
Batch 5/64 loss: 0.19656574726104736
Batch 6/64 loss: 0.1883496642112732
Batch 7/64 loss: 0.18011891841888428
Batch 8/64 loss: 0.1744874119758606
Batch 9/64 loss: 0.18689793348312378
Batch 10/64 loss: 0.19736802577972412
Batch 11/64 loss: 0.19317185878753662
Batch 12/64 loss: 0.18932104110717773
Batch 13/64 loss: 0.18553608655929565
Batch 14/64 loss: 0.18928438425064087
Batch 15/64 loss: 0.18521332740783691
Batch 16/64 loss: 0.18523555994033813
Batch 17/64 loss: 0.19491881132125854
Batch 18/64 loss: 0.20297306776046753
Batch 19/64 loss: 0.18178331851959229
Batch 20/64 loss: 0.1784975528717041
Batch 21/64 loss: 0.19065284729003906
Batch 22/64 loss: 0.17352157831192017
Batch 23/64 loss: 0.17688912153244019
Batch 24/64 loss: 0.17917251586914062
Batch 25/64 loss: 0.18669259548187256
Batch 26/64 loss: 0.18273496627807617
Batch 27/64 loss: 0.180137038230896
Batch 28/64 loss: 0.1793975830078125
Batch 29/64 loss: 0.17565101385116577
Batch 30/64 loss: 0.18974828720092773
Batch 31/64 loss: 0.1922985315322876
Batch 32/64 loss: 0.19168436527252197
Batch 33/64 loss: 0.18517982959747314
Batch 34/64 loss: 0.19345593452453613
Batch 35/64 loss: 0.18427318334579468
Batch 36/64 loss: 0.20751947164535522
Batch 37/64 loss: 0.18347632884979248
Batch 38/64 loss: 0.19020295143127441
Batch 39/64 loss: 0.17529237270355225
Batch 40/64 loss: 0.19445568323135376
Batch 41/64 loss: 0.19069373607635498
Batch 42/64 loss: 0.1812499761581421
Batch 43/64 loss: 0.181532084941864
Batch 44/64 loss: 0.18890178203582764
Batch 45/64 loss: 0.18406802415847778
Batch 46/64 loss: 0.1991763710975647
Batch 47/64 loss: 0.18304747343063354
Batch 48/64 loss: 0.17745184898376465
Batch 49/64 loss: 0.18505573272705078
Batch 50/64 loss: 0.18942248821258545
Batch 51/64 loss: 0.1844637393951416
Batch 52/64 loss: 0.19199687242507935
Batch 53/64 loss: 0.18978482484817505
Batch 54/64 loss: 0.18302839994430542
Batch 55/64 loss: 0.19069623947143555
Batch 56/64 loss: 0.18600910902023315
Batch 57/64 loss: 0.18777614831924438
Batch 58/64 loss: 0.2036736011505127
Batch 59/64 loss: 0.18656784296035767
Batch 60/64 loss: 0.1881704330444336
Batch 61/64 loss: 0.1861248016357422
Batch 62/64 loss: 0.18437939882278442
Batch 63/64 loss: 0.19796276092529297
Batch 64/64 loss: 0.19562464952468872
Epoch 497  Train loss: 0.18726635890848498  Val loss: 0.299842231052438
Epoch 498
-------------------------------
Batch 1/64 loss: 0.18191099166870117
Batch 2/64 loss: 0.1813526749610901
Batch 3/64 loss: 0.1861940622329712
Batch 4/64 loss: 0.1849069595336914
Batch 5/64 loss: 0.18172329664230347
Batch 6/64 loss: 0.20937955379486084
Batch 7/64 loss: 0.19853520393371582
Batch 8/64 loss: 0.1854724884033203
Batch 9/64 loss: 0.18008732795715332
Batch 10/64 loss: 0.18821990489959717
Batch 11/64 loss: 0.1846182942390442
Batch 12/64 loss: 0.18648838996887207
Batch 13/64 loss: 0.18332546949386597
Batch 14/64 loss: 0.19192123413085938
Batch 15/64 loss: 0.17642927169799805
Batch 16/64 loss: 0.17993199825286865
Batch 17/64 loss: 0.17795562744140625
Batch 18/64 loss: 0.19341033697128296
Batch 19/64 loss: 0.18904322385787964
Batch 20/64 loss: 0.18873149156570435
Batch 21/64 loss: 0.18496239185333252
Batch 22/64 loss: 0.18919062614440918
Batch 23/64 loss: 0.19050359725952148
Batch 24/64 loss: 0.1809503436088562
Batch 25/64 loss: 0.19989871978759766
Batch 26/64 loss: 0.19034522771835327
Batch 27/64 loss: 0.18791711330413818
Batch 28/64 loss: 0.19211620092391968
Batch 29/64 loss: 0.1841943860054016
Batch 30/64 loss: 0.18445813655853271
Batch 31/64 loss: 0.1886380910873413
Batch 32/64 loss: 0.19005119800567627
Batch 33/64 loss: 0.18079662322998047
Batch 34/64 loss: 0.1860792636871338
Batch 35/64 loss: 0.18183493614196777
Batch 36/64 loss: 0.18603301048278809
Batch 37/64 loss: 0.1914936900138855
Batch 38/64 loss: 0.20172655582427979
Batch 39/64 loss: 0.1773158311843872
Batch 40/64 loss: 0.18689239025115967
Batch 41/64 loss: 0.2013217806816101
Batch 42/64 loss: 0.17434734106063843
Batch 43/64 loss: 0.17857342958450317
Batch 44/64 loss: 0.18421030044555664
Batch 45/64 loss: 0.21688401699066162
Batch 46/64 loss: 0.18205833435058594
Batch 47/64 loss: 0.18253642320632935
Batch 48/64 loss: 0.17769378423690796
Batch 49/64 loss: 0.1908167004585266
Batch 50/64 loss: 0.18721115589141846
Batch 51/64 loss: 0.1766696572303772
Batch 52/64 loss: 0.18821388483047485
Batch 53/64 loss: 0.1864701509475708
Batch 54/64 loss: 0.17350775003433228
Batch 55/64 loss: 0.18132787942886353
Batch 56/64 loss: 0.19271671772003174
Batch 57/64 loss: 0.20610135793685913
Batch 58/64 loss: 0.1918286681175232
Batch 59/64 loss: 0.19004833698272705
Batch 60/64 loss: 0.1847967505455017
Batch 61/64 loss: 0.1735825538635254
Batch 62/64 loss: 0.1781092882156372
Batch 63/64 loss: 0.18612730503082275
Batch 64/64 loss: 0.1902846097946167
Epoch 498  Train loss: 0.18686906917422424  Val loss: 0.2993689115924114
Epoch 499
-------------------------------
Batch 1/64 loss: 0.19002258777618408
Batch 2/64 loss: 0.18568700551986694
Batch 3/64 loss: 0.18871653079986572
Batch 4/64 loss: 0.19216275215148926
Batch 5/64 loss: 0.18345904350280762
Batch 6/64 loss: 0.17503100633621216
Batch 7/64 loss: 0.18417906761169434
Batch 8/64 loss: 0.1823742389678955
Batch 9/64 loss: 0.1966511607170105
Batch 10/64 loss: 0.19777154922485352
Batch 11/64 loss: 0.18382471799850464
Batch 12/64 loss: 0.18946397304534912
Batch 13/64 loss: 0.18498289585113525
Batch 14/64 loss: 0.19554316997528076
Batch 15/64 loss: 0.18143582344055176
Batch 16/64 loss: 0.18260425329208374
Batch 17/64 loss: 0.17846965789794922
Batch 18/64 loss: 0.17120081186294556
Batch 19/64 loss: 0.18518567085266113
Batch 20/64 loss: 0.19219040870666504
Batch 21/64 loss: 0.18459969758987427
Batch 22/64 loss: 0.1818116307258606
Batch 23/64 loss: 0.18765783309936523
Batch 24/64 loss: 0.1884838342666626
Batch 25/64 loss: 0.1799033284187317
Batch 26/64 loss: 0.18559741973876953
Batch 27/64 loss: 0.19307661056518555
Batch 28/64 loss: 0.19231176376342773
Batch 29/64 loss: 0.18852132558822632
Batch 30/64 loss: 0.21174079179763794
Batch 31/64 loss: 0.20089006423950195
Batch 32/64 loss: 0.1850108504295349
Batch 33/64 loss: 0.18551713228225708
Batch 34/64 loss: 0.18065041303634644
Batch 35/64 loss: 0.18263185024261475
Batch 36/64 loss: 0.18304497003555298
Batch 37/64 loss: 0.19170546531677246
Batch 38/64 loss: 0.1871740221977234
Batch 39/64 loss: 0.18131810426712036
Batch 40/64 loss: 0.18631517887115479
Batch 41/64 loss: 0.20197898149490356
Batch 42/64 loss: 0.18590110540390015
Batch 43/64 loss: 0.19244384765625
Batch 44/64 loss: 0.1898730993270874
Batch 45/64 loss: 0.18146687746047974
Batch 46/64 loss: 0.18137860298156738
Batch 47/64 loss: 0.18136078119277954
Batch 48/64 loss: 0.19235867261886597
Batch 49/64 loss: 0.18731027841567993
Batch 50/64 loss: 0.1817030906677246
Batch 51/64 loss: 0.18098610639572144
Batch 52/64 loss: 0.18220609426498413
Batch 53/64 loss: 0.19555962085723877
Batch 54/64 loss: 0.19591975212097168
Batch 55/64 loss: 0.1758900284767151
Batch 56/64 loss: 0.17806565761566162
Batch 57/64 loss: 0.18495547771453857
Batch 58/64 loss: 0.18039321899414062
Batch 59/64 loss: 0.18676674365997314
Batch 60/64 loss: 0.1812489628791809
Batch 61/64 loss: 0.18765610456466675
Batch 62/64 loss: 0.19159185886383057
Batch 63/64 loss: 0.18025094270706177
Batch 64/64 loss: 0.17727982997894287
Epoch 499  Train loss: 0.1864963826011209  Val loss: 0.3006308308172062
Epoch 500
-------------------------------
Batch 1/64 loss: 0.1908942461013794
Batch 2/64 loss: 0.17855846881866455
Batch 3/64 loss: 0.18322670459747314
Batch 4/64 loss: 0.1838846206665039
Batch 5/64 loss: 0.199870765209198
Batch 6/64 loss: 0.18441277742385864
Batch 7/64 loss: 0.17516416311264038
Batch 8/64 loss: 0.1738954782485962
Batch 9/64 loss: 0.17997628450393677
Batch 10/64 loss: 0.17642468214035034
Batch 11/64 loss: 0.18014323711395264
Batch 12/64 loss: 0.1803259253501892
Batch 13/64 loss: 0.20646584033966064
Batch 14/64 loss: 0.1793750524520874
Batch 15/64 loss: 0.18312054872512817
Batch 16/64 loss: 0.18174099922180176
Batch 17/64 loss: 0.19399809837341309
Batch 18/64 loss: 0.20075637102127075
Batch 19/64 loss: 0.18465900421142578
Batch 20/64 loss: 0.2097562551498413
Batch 21/64 loss: 0.1819409728050232
Batch 22/64 loss: 0.17773538827896118
Batch 23/64 loss: 0.1801990270614624
Batch 24/64 loss: 0.1932600736618042
Batch 25/64 loss: 0.19582974910736084
Batch 26/64 loss: 0.20650357007980347
Batch 27/64 loss: 0.19150716066360474
Batch 28/64 loss: 0.17600858211517334
Batch 29/64 loss: 0.18263381719589233
Batch 30/64 loss: 0.19416338205337524
Batch 31/64 loss: 0.18668913841247559
Batch 32/64 loss: 0.1886589527130127
Batch 33/64 loss: 0.182522714138031
Batch 34/64 loss: 0.19840681552886963
Batch 35/64 loss: 0.20292067527770996
Batch 36/64 loss: 0.2029857635498047
Batch 37/64 loss: 0.18768829107284546
Batch 38/64 loss: 0.18529272079467773
Batch 39/64 loss: 0.1819779872894287
Batch 40/64 loss: 0.18505823612213135
Batch 41/64 loss: 0.18529856204986572
Batch 42/64 loss: 0.1891140341758728
Batch 43/64 loss: 0.1758040189743042
Batch 44/64 loss: 0.1948004961013794
Batch 45/64 loss: 0.20636284351348877
Batch 46/64 loss: 0.18845593929290771
Batch 47/64 loss: 0.18173974752426147
Batch 48/64 loss: 0.19549953937530518
Batch 49/64 loss: 0.1927187442779541
Batch 50/64 loss: 0.18351930379867554
Batch 51/64 loss: 0.19029748439788818
Batch 52/64 loss: 0.18677937984466553
Batch 53/64 loss: 0.19733816385269165
Batch 54/64 loss: 0.19464552402496338
Batch 55/64 loss: 0.1827872395515442
Batch 56/64 loss: 0.19213873147964478
Batch 57/64 loss: 0.18552571535110474
Batch 58/64 loss: 0.19299781322479248
Batch 59/64 loss: 0.17685627937316895
Batch 60/64 loss: 0.1875842809677124
Batch 61/64 loss: 0.18077212572097778
Batch 62/64 loss: 0.18505215644836426
Batch 63/64 loss: 0.18480360507965088
Batch 64/64 loss: 0.18620073795318604
Epoch 500  Train loss: 0.18790862466774735  Val loss: 0.3003318578107251
SLIC undersegmentation error: 0.054052233676975946
SLIC inter-cluster variation: 0.02397972047789259
SLIC number of superpixels: 162588
SLIC superpixels per image: 558.7216494845361
Model loaded
Test metrics:
0.2909197561519662 0.17516013745704465 13.795974080465882 tensor(0.1034, dtype=torch.float64) 0.4158222159561532 1.6996457712845638 56743
Inference time: 0.0046119272094411945 seconds
Relabeled undersegmentation error: 0.09497044673539518
Relabeled inter-cluster variation: 0.05286693097716334
Relabeled mean superpixels count: 331.4364261168385
Original mean superpixels count: 195.0
Done!
Job id: 421193
Job id: 422884
