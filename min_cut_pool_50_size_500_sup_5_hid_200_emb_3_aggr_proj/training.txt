Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 0.49343341588974
Batch 2/64 loss: 0.4183281660079956
Batch 3/64 loss: 0.3934124708175659
Batch 4/64 loss: 0.38835352659225464
Batch 5/64 loss: 0.38551926612854004
Batch 6/64 loss: 0.3852570056915283
Batch 7/64 loss: 0.38304567337036133
Batch 8/64 loss: 0.3826987147331238
Batch 9/64 loss: 0.38135331869125366
Batch 10/64 loss: 0.381702184677124
Batch 11/64 loss: 0.3822394609451294
Batch 12/64 loss: 0.3810708522796631
Batch 13/64 loss: 0.37984251976013184
Batch 14/64 loss: 0.3799271583557129
Batch 15/64 loss: 0.38121873140335083
Batch 16/64 loss: 0.38014310598373413
Batch 17/64 loss: 0.3791987895965576
Batch 18/64 loss: 0.3809690475463867
Batch 19/64 loss: 0.3787590265274048
Batch 20/64 loss: 0.3799993395805359
Batch 21/64 loss: 0.37912726402282715
Batch 22/64 loss: 0.37960898876190186
Batch 23/64 loss: 0.3790374994277954
Batch 24/64 loss: 0.37885963916778564
Batch 25/64 loss: 0.37853866815567017
Batch 26/64 loss: 0.3790186047554016
Batch 27/64 loss: 0.3786264657974243
Batch 28/64 loss: 0.3778735399246216
Batch 29/64 loss: 0.3791378140449524
Batch 30/64 loss: 0.3769756555557251
Batch 31/64 loss: 0.3783966302871704
Batch 32/64 loss: 0.3776516318321228
Batch 33/64 loss: 0.3788183927536011
Batch 34/64 loss: 0.3780645728111267
Batch 35/64 loss: 0.37613779306411743
Batch 36/64 loss: 0.3757966160774231
Batch 37/64 loss: 0.375779390335083
Batch 38/64 loss: 0.3774399757385254
Batch 39/64 loss: 0.37778156995773315
Batch 40/64 loss: 0.3772904872894287
Batch 41/64 loss: 0.3770645260810852
Batch 42/64 loss: 0.377109169960022
Batch 43/64 loss: 0.37504100799560547
Batch 44/64 loss: 0.3768391013145447
Batch 45/64 loss: 0.3749583959579468
Batch 46/64 loss: 0.3763324022293091
Batch 47/64 loss: 0.3751617670059204
Batch 48/64 loss: 0.37690556049346924
Batch 49/64 loss: 0.37739139795303345
Batch 50/64 loss: 0.3757323622703552
Batch 51/64 loss: 0.37539374828338623
Batch 52/64 loss: 0.37423956394195557
Batch 53/64 loss: 0.37623751163482666
Batch 54/64 loss: 0.37660837173461914
Batch 55/64 loss: 0.374043345451355
Batch 56/64 loss: 0.374906063079834
Batch 57/64 loss: 0.37480127811431885
Batch 58/64 loss: 0.37570512294769287
Batch 59/64 loss: 0.37404221296310425
Batch 60/64 loss: 0.3758755326271057
Batch 61/64 loss: 0.37275540828704834
Batch 62/64 loss: 0.3741421103477478
Batch 63/64 loss: 0.37326931953430176
Batch 64/64 loss: 0.37533724308013916
Epoch 1  Train loss: 0.3807449597938388  Val loss: 0.3763110305845123
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 0.37404417991638184
Batch 2/64 loss: 0.3737042546272278
Batch 3/64 loss: 0.3729156255722046
Batch 4/64 loss: 0.3736633062362671
Batch 5/64 loss: 0.37357068061828613
Batch 6/64 loss: 0.3736687898635864
Batch 7/64 loss: 0.3732146620750427
Batch 8/64 loss: 0.3738574981689453
Batch 9/64 loss: 0.37151360511779785
Batch 10/64 loss: 0.3746241331100464
Batch 11/64 loss: 0.37261635065078735
Batch 12/64 loss: 0.3757147192955017
Batch 13/64 loss: 0.3740167021751404
Batch 14/64 loss: 0.3711280822753906
Batch 15/64 loss: 0.37168872356414795
Batch 16/64 loss: 0.3723040819168091
Batch 17/64 loss: 0.3738105893135071
Batch 18/64 loss: 0.3730809688568115
Batch 19/64 loss: 0.3715031147003174
Batch 20/64 loss: 0.37137240171432495
Batch 21/64 loss: 0.3706650733947754
Batch 22/64 loss: 0.37335628271102905
Batch 23/64 loss: 0.3715277910232544
Batch 24/64 loss: 0.37226831912994385
Batch 25/64 loss: 0.3705930709838867
Batch 26/64 loss: 0.37114864587783813
Batch 27/64 loss: 0.370792031288147
Batch 28/64 loss: 0.3719501495361328
Batch 29/64 loss: 0.3709183931350708
Batch 30/64 loss: 0.37207233905792236
Batch 31/64 loss: 0.37204456329345703
Batch 32/64 loss: 0.37392979860305786
Batch 33/64 loss: 0.36953312158584595
Batch 34/64 loss: 0.37023842334747314
Batch 35/64 loss: 0.3712730407714844
Batch 36/64 loss: 0.369811475276947
Batch 37/64 loss: 0.3689839839935303
Batch 38/64 loss: 0.37043285369873047
Batch 39/64 loss: 0.37030911445617676
Batch 40/64 loss: 0.3688824772834778
Batch 41/64 loss: 0.3714754581451416
Batch 42/64 loss: 0.3695319890975952
Batch 43/64 loss: 0.37138569355010986
Batch 44/64 loss: 0.3708462715148926
Batch 45/64 loss: 0.36949700117111206
Batch 46/64 loss: 0.37069976329803467
Batch 47/64 loss: 0.3710576295852661
Batch 48/64 loss: 0.3698294162750244
Batch 49/64 loss: 0.37164556980133057
Batch 50/64 loss: 0.3704211115837097
Batch 51/64 loss: 0.3680630326271057
Batch 52/64 loss: 0.36982619762420654
Batch 53/64 loss: 0.36861085891723633
Batch 54/64 loss: 0.37084197998046875
Batch 55/64 loss: 0.37146657705307007
Batch 56/64 loss: 0.36872756481170654
Batch 57/64 loss: 0.37019383907318115
Batch 58/64 loss: 0.3656828999519348
Batch 59/64 loss: 0.3698326349258423
Batch 60/64 loss: 0.3686487674713135
Batch 61/64 loss: 0.36941468715667725
Batch 62/64 loss: 0.3682929277420044
Batch 63/64 loss: 0.3692411184310913
Batch 64/64 loss: 0.371029257774353
Epoch 2  Train loss: 0.37123526825624353  Val loss: 0.3710260307256299
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 0.36998552083969116
Batch 2/64 loss: 0.36789190769195557
Batch 3/64 loss: 0.36901700496673584
Batch 4/64 loss: 0.3681640625
Batch 5/64 loss: 0.3702467083930969
Batch 6/64 loss: 0.3691059350967407
Batch 7/64 loss: 0.36800551414489746
Batch 8/64 loss: 0.3676301836967468
Batch 9/64 loss: 0.3681492209434509
Batch 10/64 loss: 0.3699617385864258
Batch 11/64 loss: 0.37117624282836914
Batch 12/64 loss: 0.366313636302948
Batch 13/64 loss: 0.3677975535392761
Batch 14/64 loss: 0.36983102560043335
Batch 15/64 loss: 0.3689098358154297
Batch 16/64 loss: 0.3689500093460083
Batch 17/64 loss: 0.36634552478790283
Batch 18/64 loss: 0.36745697259902954
Batch 19/64 loss: 0.368979811668396
Batch 20/64 loss: 0.3686230182647705
Batch 21/64 loss: 0.36783313751220703
Batch 22/64 loss: 0.3686222434043884
Batch 23/64 loss: 0.37073230743408203
Batch 24/64 loss: 0.37013328075408936
Batch 25/64 loss: 0.3664199113845825
Batch 26/64 loss: 0.3699537515640259
Batch 27/64 loss: 0.36813122034072876
Batch 28/64 loss: 0.36589717864990234
Batch 29/64 loss: 0.3693622946739197
Batch 30/64 loss: 0.3674392104148865
Batch 31/64 loss: 0.3677455186843872
Batch 32/64 loss: 0.36852800846099854
Batch 33/64 loss: 0.37070757150650024
Batch 34/64 loss: 0.3666907548904419
Batch 35/64 loss: 0.3669426441192627
Batch 36/64 loss: 0.37042927742004395
Batch 37/64 loss: 0.36611616611480713
Batch 38/64 loss: 0.36990654468536377
Batch 39/64 loss: 0.3665615916252136
Batch 40/64 loss: 0.36556577682495117
Batch 41/64 loss: 0.36664092540740967
Batch 42/64 loss: 0.3659127354621887
Batch 43/64 loss: 0.3674633502960205
Batch 44/64 loss: 0.3640451431274414
Batch 45/64 loss: 0.3671635389328003
Batch 46/64 loss: 0.3661966919898987
Batch 47/64 loss: 0.36771589517593384
Batch 48/64 loss: 0.3670581579208374
Batch 49/64 loss: 0.36677414178848267
Batch 50/64 loss: 0.3673964738845825
Batch 51/64 loss: 0.365250825881958
Batch 52/64 loss: 0.3693654537200928
Batch 53/64 loss: 0.3684907555580139
Batch 54/64 loss: 0.36878204345703125
Batch 55/64 loss: 0.36639511585235596
Batch 56/64 loss: 0.36692965030670166
Batch 57/64 loss: 0.36467576026916504
Batch 58/64 loss: 0.3679386377334595
Batch 59/64 loss: 0.36710649728775024
Batch 60/64 loss: 0.36257755756378174
Batch 61/64 loss: 0.3624727725982666
Batch 62/64 loss: 0.3651171326637268
Batch 63/64 loss: 0.36553460359573364
Batch 64/64 loss: 0.36780738830566406
Epoch 3  Train loss: 0.3676724583494897  Val loss: 0.368178046241249
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 0.36568933725357056
Batch 2/64 loss: 0.3665039539337158
Batch 3/64 loss: 0.36462533473968506
Batch 4/64 loss: 0.36518752574920654
Batch 5/64 loss: 0.3687204122543335
Batch 6/64 loss: 0.3653208017349243
Batch 7/64 loss: 0.36505669355392456
Batch 8/64 loss: 0.36428898572921753
Batch 9/64 loss: 0.3646392822265625
Batch 10/64 loss: 0.36777281761169434
Batch 11/64 loss: 0.36503690481185913
Batch 12/64 loss: 0.3680771589279175
Batch 13/64 loss: 0.3645972013473511
Batch 14/64 loss: 0.3647233247756958
Batch 15/64 loss: 0.3627758026123047
Batch 16/64 loss: 0.36676132678985596
Batch 17/64 loss: 0.3667778968811035
Batch 18/64 loss: 0.3640934228897095
Batch 19/64 loss: 0.367168128490448
Batch 20/64 loss: 0.3682072162628174
Batch 21/64 loss: 0.3648959994316101
Batch 22/64 loss: 0.3650665879249573
Batch 23/64 loss: 0.3657139539718628
Batch 24/64 loss: 0.3662906885147095
Batch 25/64 loss: 0.36568593978881836
Batch 26/64 loss: 0.36429333686828613
Batch 27/64 loss: 0.36660587787628174
Batch 28/64 loss: 0.3623201847076416
Batch 29/64 loss: 0.363918662071228
Batch 30/64 loss: 0.36663782596588135
Batch 31/64 loss: 0.368449330329895
Batch 32/64 loss: 0.3698033094406128
Batch 33/64 loss: 0.36424142122268677
Batch 34/64 loss: 0.36395263671875
Batch 35/64 loss: 0.36337339878082275
Batch 36/64 loss: 0.3656364679336548
Batch 37/64 loss: 0.36777424812316895
Batch 38/64 loss: 0.36611002683639526
Batch 39/64 loss: 0.36530888080596924
Batch 40/64 loss: 0.36439263820648193
Batch 41/64 loss: 0.36596906185150146
Batch 42/64 loss: 0.36611682176589966
Batch 43/64 loss: 0.3667454719543457
Batch 44/64 loss: 0.364907443523407
Batch 45/64 loss: 0.3653489351272583
Batch 46/64 loss: 0.36522722244262695
Batch 47/64 loss: 0.364348828792572
Batch 48/64 loss: 0.36273711919784546
Batch 49/64 loss: 0.3637459874153137
Batch 50/64 loss: 0.3653673529624939
Batch 51/64 loss: 0.3655664920806885
Batch 52/64 loss: 0.3638337254524231
Batch 53/64 loss: 0.36548495292663574
Batch 54/64 loss: 0.3665931820869446
Batch 55/64 loss: 0.3646092414855957
Batch 56/64 loss: 0.3651503324508667
Batch 57/64 loss: 0.36449146270751953
Batch 58/64 loss: 0.3616570234298706
Batch 59/64 loss: 0.35998761653900146
Batch 60/64 loss: 0.36398690938949585
Batch 61/64 loss: 0.3652673363685608
Batch 62/64 loss: 0.3652002811431885
Batch 63/64 loss: 0.36492276191711426
Batch 64/64 loss: 0.36566388607025146
Epoch 4  Train loss: 0.365302092888776  Val loss: 0.365082572006278
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 0.3625326156616211
Batch 2/64 loss: 0.36246001720428467
Batch 3/64 loss: 0.3608996272087097
Batch 4/64 loss: 0.3630934953689575
Batch 5/64 loss: 0.36357706785202026
Batch 6/64 loss: 0.36296093463897705
Batch 7/64 loss: 0.35966241359710693
Batch 8/64 loss: 0.3650006055831909
Batch 9/64 loss: 0.3636716604232788
Batch 10/64 loss: 0.36466336250305176
Batch 11/64 loss: 0.36449337005615234
Batch 12/64 loss: 0.3655166029930115
Batch 13/64 loss: 0.364193320274353
Batch 14/64 loss: 0.363330602645874
Batch 15/64 loss: 0.3626556396484375
Batch 16/64 loss: 0.36303120851516724
Batch 17/64 loss: 0.3628370761871338
Batch 18/64 loss: 0.36218535900115967
Batch 19/64 loss: 0.3669940233230591
Batch 20/64 loss: 0.3640180826187134
Batch 21/64 loss: 0.3630748391151428
Batch 22/64 loss: 0.3632844090461731
Batch 23/64 loss: 0.3639906644821167
Batch 24/64 loss: 0.3627122640609741
Batch 25/64 loss: 0.3631613254547119
Batch 26/64 loss: 0.36498522758483887
Batch 27/64 loss: 0.3643559217453003
Batch 28/64 loss: 0.363484263420105
Batch 29/64 loss: 0.362074613571167
Batch 30/64 loss: 0.3643544316291809
Batch 31/64 loss: 0.3606519103050232
Batch 32/64 loss: 0.3653653860092163
Batch 33/64 loss: 0.36280202865600586
Batch 34/64 loss: 0.3598328232765198
Batch 35/64 loss: 0.3672177791595459
Batch 36/64 loss: 0.36436593532562256
Batch 37/64 loss: 0.3652994632720947
Batch 38/64 loss: 0.36298179626464844
Batch 39/64 loss: 0.36176347732543945
Batch 40/64 loss: 0.36789190769195557
Batch 41/64 loss: 0.36516445875167847
Batch 42/64 loss: 0.3617936372756958
Batch 43/64 loss: 0.36648350954055786
Batch 44/64 loss: 0.36051660776138306
Batch 45/64 loss: 0.36302149295806885
Batch 46/64 loss: 0.3618936538696289
Batch 47/64 loss: 0.3643055558204651
Batch 48/64 loss: 0.36126840114593506
Batch 49/64 loss: 0.36357343196868896
Batch 50/64 loss: 0.361758291721344
Batch 51/64 loss: 0.3597017526626587
Batch 52/64 loss: 0.36137092113494873
Batch 53/64 loss: 0.36268067359924316
Batch 54/64 loss: 0.364454984664917
Batch 55/64 loss: 0.36246150732040405
Batch 56/64 loss: 0.35999810695648193
Batch 57/64 loss: 0.3648422956466675
Batch 58/64 loss: 0.36445897817611694
Batch 59/64 loss: 0.36421823501586914
Batch 60/64 loss: 0.3624075651168823
Batch 61/64 loss: 0.3609306812286377
Batch 62/64 loss: 0.36309921741485596
Batch 63/64 loss: 0.3620379567146301
Batch 64/64 loss: 0.36100244522094727
Epoch 5  Train loss: 0.3632097459306904  Val loss: 0.36482752905678506
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 0.3642340898513794
Batch 2/64 loss: 0.365267276763916
Batch 3/64 loss: 0.3620225191116333
Batch 4/64 loss: 0.3622443675994873
Batch 5/64 loss: 0.3628368377685547
Batch 6/64 loss: 0.3610139489173889
Batch 7/64 loss: 0.35857343673706055
Batch 8/64 loss: 0.3622879981994629
Batch 9/64 loss: 0.3624995946884155
Batch 10/64 loss: 0.3580114245414734
Batch 11/64 loss: 0.3652554154396057
Batch 12/64 loss: 0.36224740743637085
Batch 13/64 loss: 0.3617181181907654
Batch 14/64 loss: 0.36147838830947876
Batch 15/64 loss: 0.36180973052978516
Batch 16/64 loss: 0.3602803349494934
Batch 17/64 loss: 0.3619943857192993
Batch 18/64 loss: 0.3612152338027954
Batch 19/64 loss: 0.359228253364563
Batch 20/64 loss: 0.36077308654785156
Batch 21/64 loss: 0.36130380630493164
Batch 22/64 loss: 0.3620677590370178
Batch 23/64 loss: 0.361893892288208
Batch 24/64 loss: 0.3636380434036255
Batch 25/64 loss: 0.3646087050437927
Batch 26/64 loss: 0.3592536449432373
Batch 27/64 loss: 0.3634018898010254
Batch 28/64 loss: 0.360720694065094
Batch 29/64 loss: 0.3615105152130127
Batch 30/64 loss: 0.35796529054641724
Batch 31/64 loss: 0.36101388931274414
Batch 32/64 loss: 0.3645252585411072
Batch 33/64 loss: 0.3609619140625
Batch 34/64 loss: 0.3617544174194336
Batch 35/64 loss: 0.3596944808959961
Batch 36/64 loss: 0.3593928813934326
Batch 37/64 loss: 0.36512255668640137
Batch 38/64 loss: 0.3640538454055786
Batch 39/64 loss: 0.3597705364227295
Batch 40/64 loss: 0.36387526988983154
Batch 41/64 loss: 0.36501020193099976
Batch 42/64 loss: 0.3606734275817871
Batch 43/64 loss: 0.3589324951171875
Batch 44/64 loss: 0.36690640449523926
Batch 45/64 loss: 0.36217713356018066
Batch 46/64 loss: 0.36261695623397827
Batch 47/64 loss: 0.3611147403717041
Batch 48/64 loss: 0.3584718704223633
Batch 49/64 loss: 0.36085355281829834
Batch 50/64 loss: 0.35904788970947266
Batch 51/64 loss: 0.36023223400115967
Batch 52/64 loss: 0.3601999878883362
Batch 53/64 loss: 0.3617943525314331
Batch 54/64 loss: 0.3595629930496216
Batch 55/64 loss: 0.36017823219299316
Batch 56/64 loss: 0.35924088954925537
Batch 57/64 loss: 0.36094367504119873
Batch 58/64 loss: 0.35992610454559326
Batch 59/64 loss: 0.35961711406707764
Batch 60/64 loss: 0.3584280014038086
Batch 61/64 loss: 0.3616199493408203
Batch 62/64 loss: 0.3589514493942261
Batch 63/64 loss: 0.3594987392425537
Batch 64/64 loss: 0.36131173372268677
Epoch 6  Train loss: 0.3613882875909992  Val loss: 0.36182841115800785
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.3566107749938965
Batch 2/64 loss: 0.3585575819015503
Batch 3/64 loss: 0.36113208532333374
Batch 4/64 loss: 0.35998713970184326
Batch 5/64 loss: 0.36262017488479614
Batch 6/64 loss: 0.3601245880126953
Batch 7/64 loss: 0.35702836513519287
Batch 8/64 loss: 0.3592461943626404
Batch 9/64 loss: 0.362363338470459
Batch 10/64 loss: 0.3569486141204834
Batch 11/64 loss: 0.3545476198196411
Batch 12/64 loss: 0.35767364501953125
Batch 13/64 loss: 0.35859060287475586
Batch 14/64 loss: 0.3605527877807617
Batch 15/64 loss: 0.35885727405548096
Batch 16/64 loss: 0.3593404293060303
Batch 17/64 loss: 0.359391450881958
Batch 18/64 loss: 0.36305874586105347
Batch 19/64 loss: 0.3557474613189697
Batch 20/64 loss: 0.35969018936157227
Batch 21/64 loss: 0.3589668869972229
Batch 22/64 loss: 0.35924607515335083
Batch 23/64 loss: 0.3609641194343567
Batch 24/64 loss: 0.3615482449531555
Batch 25/64 loss: 0.3613431453704834
Batch 26/64 loss: 0.3594324588775635
Batch 27/64 loss: 0.3563579320907593
Batch 28/64 loss: 0.3596091866493225
Batch 29/64 loss: 0.3603442907333374
Batch 30/64 loss: 0.3583695888519287
Batch 31/64 loss: 0.3560143709182739
Batch 32/64 loss: 0.3653128147125244
Batch 33/64 loss: 0.3633793592453003
Batch 34/64 loss: 0.3604475259780884
Batch 35/64 loss: 0.3593405485153198
Batch 36/64 loss: 0.3579998016357422
Batch 37/64 loss: 0.36262261867523193
Batch 38/64 loss: 0.35841965675354004
Batch 39/64 loss: 0.3618258237838745
Batch 40/64 loss: 0.35698258876800537
Batch 41/64 loss: 0.36064428091049194
Batch 42/64 loss: 0.36070168018341064
Batch 43/64 loss: 0.35892271995544434
Batch 44/64 loss: 0.3573777675628662
Batch 45/64 loss: 0.3597496747970581
Batch 46/64 loss: 0.36049753427505493
Batch 47/64 loss: 0.36205875873565674
Batch 48/64 loss: 0.35891085863113403
Batch 49/64 loss: 0.3592844605445862
Batch 50/64 loss: 0.3635125160217285
Batch 51/64 loss: 0.36143505573272705
Batch 52/64 loss: 0.35934293270111084
Batch 53/64 loss: 0.3562370538711548
Batch 54/64 loss: 0.3602207899093628
Batch 55/64 loss: 0.3601568937301636
Batch 56/64 loss: 0.3609602451324463
Batch 57/64 loss: 0.36140406131744385
Batch 58/64 loss: 0.3606531620025635
Batch 59/64 loss: 0.35920292139053345
Batch 60/64 loss: 0.3618457317352295
Batch 61/64 loss: 0.3628045320510864
Batch 62/64 loss: 0.35977882146835327
Batch 63/64 loss: 0.3625190258026123
Batch 64/64 loss: 0.36029332876205444
Epoch 7  Train loss: 0.359828040412828  Val loss: 0.3617454326849213
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 0.3584994077682495
Batch 2/64 loss: 0.3611733913421631
Batch 3/64 loss: 0.3578411340713501
Batch 4/64 loss: 0.3626868724822998
Batch 5/64 loss: 0.35688066482543945
Batch 6/64 loss: 0.3568931818008423
Batch 7/64 loss: 0.35741716623306274
Batch 8/64 loss: 0.35680627822875977
Batch 9/64 loss: 0.35924625396728516
Batch 10/64 loss: 0.35737258195877075
Batch 11/64 loss: 0.3584378957748413
Batch 12/64 loss: 0.3578799366950989
Batch 13/64 loss: 0.3594604730606079
Batch 14/64 loss: 0.3618755340576172
Batch 15/64 loss: 0.3571949005126953
Batch 16/64 loss: 0.35931795835494995
Batch 17/64 loss: 0.3612017035484314
Batch 18/64 loss: 0.35550111532211304
Batch 19/64 loss: 0.3603924512863159
Batch 20/64 loss: 0.35802197456359863
Batch 21/64 loss: 0.35892951488494873
Batch 22/64 loss: 0.35880184173583984
Batch 23/64 loss: 0.35983872413635254
Batch 24/64 loss: 0.36345380544662476
Batch 25/64 loss: 0.36288678646087646
Batch 26/64 loss: 0.3558213710784912
Batch 27/64 loss: 0.35714226961135864
Batch 28/64 loss: 0.3560832142829895
Batch 29/64 loss: 0.35739004611968994
Batch 30/64 loss: 0.3584011197090149
Batch 31/64 loss: 0.3588148355484009
Batch 32/64 loss: 0.358126163482666
Batch 33/64 loss: 0.3580814599990845
Batch 34/64 loss: 0.3592849373817444
Batch 35/64 loss: 0.35398799180984497
Batch 36/64 loss: 0.35980725288391113
Batch 37/64 loss: 0.3579697608947754
Batch 38/64 loss: 0.35652077198028564
Batch 39/64 loss: 0.3586299419403076
Batch 40/64 loss: 0.3603200912475586
Batch 41/64 loss: 0.3577122688293457
Batch 42/64 loss: 0.36049866676330566
Batch 43/64 loss: 0.3574448823928833
Batch 44/64 loss: 0.3606146574020386
Batch 45/64 loss: 0.35821229219436646
Batch 46/64 loss: 0.3586862087249756
Batch 47/64 loss: 0.35729682445526123
Batch 48/64 loss: 0.3583909273147583
Batch 49/64 loss: 0.3563755750656128
Batch 50/64 loss: 0.3593728542327881
Batch 51/64 loss: 0.3567810654640198
Batch 52/64 loss: 0.36028265953063965
Batch 53/64 loss: 0.3556215167045593
Batch 54/64 loss: 0.35580605268478394
Batch 55/64 loss: 0.36059725284576416
Batch 56/64 loss: 0.35651373863220215
Batch 57/64 loss: 0.36052215099334717
Batch 58/64 loss: 0.3563916087150574
Batch 59/64 loss: 0.3556407690048218
Batch 60/64 loss: 0.36080849170684814
Batch 61/64 loss: 0.3545472025871277
Batch 62/64 loss: 0.3572225570678711
Batch 63/64 loss: 0.3560205101966858
Batch 64/64 loss: 0.35690629482269287
Epoch 8  Train loss: 0.35832836440965243  Val loss: 0.3595210408017398
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 0.35634899139404297
Batch 2/64 loss: 0.35958993434906006
Batch 3/64 loss: 0.356974720954895
Batch 4/64 loss: 0.3537432551383972
Batch 5/64 loss: 0.35816502571105957
Batch 6/64 loss: 0.3583766222000122
Batch 7/64 loss: 0.35695838928222656
Batch 8/64 loss: 0.36173975467681885
Batch 9/64 loss: 0.35993361473083496
Batch 10/64 loss: 0.35563546419143677
Batch 11/64 loss: 0.3578861951828003
Batch 12/64 loss: 0.35612279176712036
Batch 13/64 loss: 0.35714423656463623
Batch 14/64 loss: 0.35745179653167725
Batch 15/64 loss: 0.3569226861000061
Batch 16/64 loss: 0.35932624340057373
Batch 17/64 loss: 0.3543195128440857
Batch 18/64 loss: 0.3561868667602539
Batch 19/64 loss: 0.354653000831604
Batch 20/64 loss: 0.36007100343704224
Batch 21/64 loss: 0.3587604761123657
Batch 22/64 loss: 0.36003804206848145
Batch 23/64 loss: 0.35921311378479004
Batch 24/64 loss: 0.3587173819541931
Batch 25/64 loss: 0.35785841941833496
Batch 26/64 loss: 0.3609025478363037
Batch 27/64 loss: 0.3581591844558716
Batch 28/64 loss: 0.361855149269104
Batch 29/64 loss: 0.3592485189437866
Batch 30/64 loss: 0.356691837310791
Batch 31/64 loss: 0.3607492446899414
Batch 32/64 loss: 0.35773754119873047
Batch 33/64 loss: 0.3579195737838745
Batch 34/64 loss: 0.36186301708221436
Batch 35/64 loss: 0.36278069019317627
Batch 36/64 loss: 0.35790741443634033
Batch 37/64 loss: 0.3582611083984375
Batch 38/64 loss: 0.35426318645477295
Batch 39/64 loss: 0.35888248682022095
Batch 40/64 loss: 0.3562997579574585
Batch 41/64 loss: 0.3580594062805176
Batch 42/64 loss: 0.3558952808380127
Batch 43/64 loss: 0.35785263776779175
Batch 44/64 loss: 0.3622768521308899
Batch 45/64 loss: 0.3572652339935303
Batch 46/64 loss: 0.3536086082458496
Batch 47/64 loss: 0.3577413558959961
Batch 48/64 loss: 0.35829269886016846
Batch 49/64 loss: 0.3600492477416992
Batch 50/64 loss: 0.3597622513771057
Batch 51/64 loss: 0.3569549322128296
Batch 52/64 loss: 0.35669100284576416
Batch 53/64 loss: 0.3577922582626343
Batch 54/64 loss: 0.3587743639945984
Batch 55/64 loss: 0.3576887249946594
Batch 56/64 loss: 0.3585824966430664
Batch 57/64 loss: 0.3585531711578369
Batch 58/64 loss: 0.356353759765625
Batch 59/64 loss: 0.3568881154060364
Batch 60/64 loss: 0.35649943351745605
Batch 61/64 loss: 0.35731035470962524
Batch 62/64 loss: 0.3575223684310913
Batch 63/64 loss: 0.35797446966171265
Batch 64/64 loss: 0.3602592349052429
Epoch 9  Train loss: 0.35802732939813653  Val loss: 0.36068541159744527
Epoch 10
-------------------------------
Batch 1/64 loss: 0.35872524976730347
Batch 2/64 loss: 0.35856735706329346
Batch 3/64 loss: 0.3550058603286743
Batch 4/64 loss: 0.35705292224884033
Batch 5/64 loss: 0.3563575744628906
Batch 6/64 loss: 0.3528953194618225
Batch 7/64 loss: 0.3575875759124756
Batch 8/64 loss: 0.35933583974838257
Batch 9/64 loss: 0.3544752597808838
Batch 10/64 loss: 0.35987675189971924
Batch 11/64 loss: 0.3603931665420532
Batch 12/64 loss: 0.3566550016403198
Batch 13/64 loss: 0.35525989532470703
Batch 14/64 loss: 0.35512590408325195
Batch 15/64 loss: 0.35900163650512695
Batch 16/64 loss: 0.3596687912940979
Batch 17/64 loss: 0.3597911596298218
Batch 18/64 loss: 0.357576847076416
Batch 19/64 loss: 0.3598206639289856
Batch 20/64 loss: 0.3595178723335266
Batch 21/64 loss: 0.357069730758667
Batch 22/64 loss: 0.35770249366760254
Batch 23/64 loss: 0.3529208302497864
Batch 24/64 loss: 0.3567248582839966
Batch 25/64 loss: 0.36014074087142944
Batch 26/64 loss: 0.35720276832580566
Batch 27/64 loss: 0.353126585483551
Batch 28/64 loss: 0.3586123585700989
Batch 29/64 loss: 0.3580654263496399
Batch 30/64 loss: 0.3587911128997803
Batch 31/64 loss: 0.35627996921539307
Batch 32/64 loss: 0.35593533515930176
Batch 33/64 loss: 0.3568071722984314
Batch 34/64 loss: 0.35577476024627686
Batch 35/64 loss: 0.3537293076515198
Batch 36/64 loss: 0.35335713624954224
Batch 37/64 loss: 0.35511237382888794
Batch 38/64 loss: 0.35353386402130127
Batch 39/64 loss: 0.3575395345687866
Batch 40/64 loss: 0.3567119836807251
Batch 41/64 loss: 0.36055612564086914
Batch 42/64 loss: 0.35370153188705444
Batch 43/64 loss: 0.3551313877105713
Batch 44/64 loss: 0.3569626808166504
Batch 45/64 loss: 0.35940372943878174
Batch 46/64 loss: 0.35427290201187134
Batch 47/64 loss: 0.3567318916320801
Batch 48/64 loss: 0.35744374990463257
Batch 49/64 loss: 0.3540646433830261
Batch 50/64 loss: 0.35615074634552
Batch 51/64 loss: 0.35213762521743774
Batch 52/64 loss: 0.35406380891799927
Batch 53/64 loss: 0.3555886149406433
Batch 54/64 loss: 0.3538398742675781
Batch 55/64 loss: 0.35651981830596924
Batch 56/64 loss: 0.35636717081069946
Batch 57/64 loss: 0.3569977283477783
Batch 58/64 loss: 0.3576110005378723
Batch 59/64 loss: 0.35831665992736816
Batch 60/64 loss: 0.35374748706817627
Batch 61/64 loss: 0.3523653745651245
Batch 62/64 loss: 0.3576374053955078
Batch 63/64 loss: 0.3592526316642761
Batch 64/64 loss: 0.3575132489204407
Epoch 10  Train loss: 0.35662476104848523  Val loss: 0.358295680321369
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: 0.3554057478904724
Batch 2/64 loss: 0.3577970862388611
Batch 3/64 loss: 0.3572065830230713
Batch 4/64 loss: 0.3538142442703247
Batch 5/64 loss: 0.35506153106689453
Batch 6/64 loss: 0.35385793447494507
Batch 7/64 loss: 0.35248661041259766
Batch 8/64 loss: 0.35567986965179443
Batch 9/64 loss: 0.35706090927124023
Batch 10/64 loss: 0.3582082986831665
Batch 11/64 loss: 0.3604794144630432
Batch 12/64 loss: 0.35373401641845703
Batch 13/64 loss: 0.3562992215156555
Batch 14/64 loss: 0.3551928997039795
Batch 15/64 loss: 0.35565221309661865
Batch 16/64 loss: 0.3593675494194031
Batch 17/64 loss: 0.35757625102996826
Batch 18/64 loss: 0.35589706897735596
Batch 19/64 loss: 0.35310137271881104
Batch 20/64 loss: 0.35737717151641846
Batch 21/64 loss: 0.35752880573272705
Batch 22/64 loss: 0.35839271545410156
Batch 23/64 loss: 0.3543761372566223
Batch 24/64 loss: 0.3552895784378052
Batch 25/64 loss: 0.35530149936676025
Batch 26/64 loss: 0.35816001892089844
Batch 27/64 loss: 0.35720282793045044
Batch 28/64 loss: 0.35820478200912476
Batch 29/64 loss: 0.35691332817077637
Batch 30/64 loss: 0.3605990409851074
Batch 31/64 loss: 0.35629069805145264
Batch 32/64 loss: 0.35603803396224976
Batch 33/64 loss: 0.3570682406425476
Batch 34/64 loss: 0.35795748233795166
Batch 35/64 loss: 0.3515651822090149
Batch 36/64 loss: 0.3591827154159546
Batch 37/64 loss: 0.35986584424972534
Batch 38/64 loss: 0.35582810640335083
Batch 39/64 loss: 0.359000563621521
Batch 40/64 loss: 0.3570471405982971
Batch 41/64 loss: 0.3545503616333008
Batch 42/64 loss: 0.3583773970603943
Batch 43/64 loss: 0.3567585349082947
Batch 44/64 loss: 0.3594491481781006
Batch 45/64 loss: 0.35265469551086426
Batch 46/64 loss: 0.3544543981552124
Batch 47/64 loss: 0.3570842742919922
Batch 48/64 loss: 0.3590889573097229
Batch 49/64 loss: 0.3563960790634155
Batch 50/64 loss: 0.3570948839187622
Batch 51/64 loss: 0.3546738624572754
Batch 52/64 loss: 0.3534125089645386
Batch 53/64 loss: 0.35783469676971436
Batch 54/64 loss: 0.3530001640319824
Batch 55/64 loss: 0.35751885175704956
Batch 56/64 loss: 0.35485178232192993
Batch 57/64 loss: 0.35478758811950684
Batch 58/64 loss: 0.3507888913154602
Batch 59/64 loss: 0.35558414459228516
Batch 60/64 loss: 0.353141725063324
Batch 61/64 loss: 0.35114479064941406
Batch 62/64 loss: 0.3540337085723877
Batch 63/64 loss: 0.3551027774810791
Batch 64/64 loss: 0.35308384895324707
Epoch 11  Train loss: 0.3560731897167131  Val loss: 0.3577712780421542
Saving best model, epoch: 11
Epoch 12
-------------------------------
Batch 1/64 loss: 0.3557385206222534
Batch 2/64 loss: 0.3571544885635376
Batch 3/64 loss: 0.3536832928657532
Batch 4/64 loss: 0.3538217544555664
Batch 5/64 loss: 0.3506965637207031
Batch 6/64 loss: 0.3568542003631592
Batch 7/64 loss: 0.35534918308258057
Batch 8/64 loss: 0.35303735733032227
Batch 9/64 loss: 0.35171639919281006
Batch 10/64 loss: 0.3566625118255615
Batch 11/64 loss: 0.3531836271286011
Batch 12/64 loss: 0.35273343324661255
Batch 13/64 loss: 0.35405832529067993
Batch 14/64 loss: 0.3590816259384155
Batch 15/64 loss: 0.35786372423171997
Batch 16/64 loss: 0.3597836494445801
Batch 17/64 loss: 0.3541070222854614
Batch 18/64 loss: 0.3565971851348877
Batch 19/64 loss: 0.3527027368545532
Batch 20/64 loss: 0.3518946170806885
Batch 21/64 loss: 0.35569268465042114
Batch 22/64 loss: 0.35686826705932617
Batch 23/64 loss: 0.35528385639190674
Batch 24/64 loss: 0.3561004400253296
Batch 25/64 loss: 0.3545248508453369
Batch 26/64 loss: 0.3561931848526001
Batch 27/64 loss: 0.35307979583740234
Batch 28/64 loss: 0.3536489009857178
Batch 29/64 loss: 0.35551726818084717
Batch 30/64 loss: 0.3546594977378845
Batch 31/64 loss: 0.35370856523513794
Batch 32/64 loss: 0.35538923740386963
Batch 33/64 loss: 0.35507047176361084
Batch 34/64 loss: 0.36072152853012085
Batch 35/64 loss: 0.35618162155151367
Batch 36/64 loss: 0.35249561071395874
Batch 37/64 loss: 0.35251402854919434
Batch 38/64 loss: 0.35186851024627686
Batch 39/64 loss: 0.35701870918273926
Batch 40/64 loss: 0.35473108291625977
Batch 41/64 loss: 0.35268253087997437
Batch 42/64 loss: 0.3535016179084778
Batch 43/64 loss: 0.35443544387817383
Batch 44/64 loss: 0.35585451126098633
Batch 45/64 loss: 0.35324668884277344
Batch 46/64 loss: 0.35426902770996094
Batch 47/64 loss: 0.35173559188842773
Batch 48/64 loss: 0.35901975631713867
Batch 49/64 loss: 0.3533145785331726
Batch 50/64 loss: 0.3528146743774414
Batch 51/64 loss: 0.35459959506988525
Batch 52/64 loss: 0.3571649193763733
Batch 53/64 loss: 0.3552587628364563
Batch 54/64 loss: 0.35470831394195557
Batch 55/64 loss: 0.3538552522659302
Batch 56/64 loss: 0.35567837953567505
Batch 57/64 loss: 0.35366183519363403
Batch 58/64 loss: 0.35382676124572754
Batch 59/64 loss: 0.35341012477874756
Batch 60/64 loss: 0.355613648891449
Batch 61/64 loss: 0.35321342945098877
Batch 62/64 loss: 0.3559286594390869
Batch 63/64 loss: 0.3522418737411499
Batch 64/64 loss: 0.3564489483833313
Epoch 12  Train loss: 0.3547507610975527  Val loss: 0.35717626904294253
Saving best model, epoch: 12
Epoch 13
-------------------------------
Batch 1/64 loss: 0.3516026735305786
Batch 2/64 loss: 0.35759615898132324
Batch 3/64 loss: 0.354861855506897
Batch 4/64 loss: 0.3557491898536682
Batch 5/64 loss: 0.3504428267478943
Batch 6/64 loss: 0.3536531925201416
Batch 7/64 loss: 0.35510724782943726
Batch 8/64 loss: 0.3512481451034546
Batch 9/64 loss: 0.3585214614868164
Batch 10/64 loss: 0.3595120906829834
Batch 11/64 loss: 0.3550375699996948
Batch 12/64 loss: 0.35539257526397705
Batch 13/64 loss: 0.35411620140075684
Batch 14/64 loss: 0.3596063256263733
Batch 15/64 loss: 0.3545401096343994
Batch 16/64 loss: 0.3527023196220398
Batch 17/64 loss: 0.3529698848724365
Batch 18/64 loss: 0.3553006649017334
Batch 19/64 loss: 0.3562673330307007
Batch 20/64 loss: 0.35370731353759766
Batch 21/64 loss: 0.3564116954803467
Batch 22/64 loss: 0.3557397127151489
Batch 23/64 loss: 0.3570438623428345
Batch 24/64 loss: 0.3538951277732849
Batch 25/64 loss: 0.3554144501686096
Batch 26/64 loss: 0.35349851846694946
Batch 27/64 loss: 0.3525697588920593
Batch 28/64 loss: 0.3566826581954956
Batch 29/64 loss: 0.35657596588134766
Batch 30/64 loss: 0.3564584255218506
Batch 31/64 loss: 0.3525417447090149
Batch 32/64 loss: 0.35448843240737915
Batch 33/64 loss: 0.35367703437805176
Batch 34/64 loss: 0.349597692489624
Batch 35/64 loss: 0.3563181161880493
Batch 36/64 loss: 0.3551822304725647
Batch 37/64 loss: 0.3535950183868408
Batch 38/64 loss: 0.35662025213241577
Batch 39/64 loss: 0.35051435232162476
Batch 40/64 loss: 0.3548004627227783
Batch 41/64 loss: 0.3538929224014282
Batch 42/64 loss: 0.3503603935241699
Batch 43/64 loss: 0.35281074047088623
Batch 44/64 loss: 0.3540995717048645
Batch 45/64 loss: 0.35409677028656006
Batch 46/64 loss: 0.35646963119506836
Batch 47/64 loss: 0.3565661907196045
Batch 48/64 loss: 0.3552563786506653
Batch 49/64 loss: 0.35168612003326416
Batch 50/64 loss: 0.35654664039611816
Batch 51/64 loss: 0.35324645042419434
Batch 52/64 loss: 0.35839104652404785
Batch 53/64 loss: 0.3549610376358032
Batch 54/64 loss: 0.35051071643829346
Batch 55/64 loss: 0.35472339391708374
Batch 56/64 loss: 0.35372793674468994
Batch 57/64 loss: 0.3529815077781677
Batch 58/64 loss: 0.35675501823425293
Batch 59/64 loss: 0.3532711863517761
Batch 60/64 loss: 0.35411250591278076
Batch 61/64 loss: 0.35525625944137573
Batch 62/64 loss: 0.3509622812271118
Batch 63/64 loss: 0.35351991653442383
Batch 64/64 loss: 0.35251569747924805
Epoch 13  Train loss: 0.35448081633623907  Val loss: 0.355365041809803
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: 0.35225802659988403
Batch 2/64 loss: 0.3583024740219116
Batch 3/64 loss: 0.35339605808258057
Batch 4/64 loss: 0.35242950916290283
Batch 5/64 loss: 0.3537198305130005
Batch 6/64 loss: 0.35403329133987427
Batch 7/64 loss: 0.3517303466796875
Batch 8/64 loss: 0.3547621965408325
Batch 9/64 loss: 0.35577118396759033
Batch 10/64 loss: 0.3518746495246887
Batch 11/64 loss: 0.3493003845214844
Batch 12/64 loss: 0.35764652490615845
Batch 13/64 loss: 0.3527340888977051
Batch 14/64 loss: 0.3534116744995117
Batch 15/64 loss: 0.35390913486480713
Batch 16/64 loss: 0.35295844078063965
Batch 17/64 loss: 0.35249340534210205
Batch 18/64 loss: 0.35379987955093384
Batch 19/64 loss: 0.35513460636138916
Batch 20/64 loss: 0.356883704662323
Batch 21/64 loss: 0.3533674478530884
Batch 22/64 loss: 0.3544735312461853
Batch 23/64 loss: 0.35401272773742676
Batch 24/64 loss: 0.3520606756210327
Batch 25/64 loss: 0.3539489507675171
Batch 26/64 loss: 0.3511691093444824
Batch 27/64 loss: 0.35386669635772705
Batch 28/64 loss: 0.35357195138931274
Batch 29/64 loss: 0.3549079895019531
Batch 30/64 loss: 0.3546847105026245
Batch 31/64 loss: 0.3526381254196167
Batch 32/64 loss: 0.3537755012512207
Batch 33/64 loss: 0.3504900336265564
Batch 34/64 loss: 0.3511631488800049
Batch 35/64 loss: 0.35424351692199707
Batch 36/64 loss: 0.35261374711990356
Batch 37/64 loss: 0.3536897897720337
Batch 38/64 loss: 0.34985560178756714
Batch 39/64 loss: 0.35375577211380005
Batch 40/64 loss: 0.35148513317108154
Batch 41/64 loss: 0.3514624238014221
Batch 42/64 loss: 0.35527247190475464
Batch 43/64 loss: 0.3534650206565857
Batch 44/64 loss: 0.3536386489868164
Batch 45/64 loss: 0.3516061305999756
Batch 46/64 loss: 0.3532973527908325
Batch 47/64 loss: 0.34781479835510254
Batch 48/64 loss: 0.35169875621795654
Batch 49/64 loss: 0.3532823920249939
Batch 50/64 loss: 0.3529093265533447
Batch 51/64 loss: 0.35387110710144043
Batch 52/64 loss: 0.34841352701187134
Batch 53/64 loss: 0.3545404076576233
Batch 54/64 loss: 0.35552406311035156
Batch 55/64 loss: 0.35533690452575684
Batch 56/64 loss: 0.3534938097000122
Batch 57/64 loss: 0.35441505908966064
Batch 58/64 loss: 0.35345959663391113
Batch 59/64 loss: 0.35378026962280273
Batch 60/64 loss: 0.3503214716911316
Batch 61/64 loss: 0.3552522659301758
Batch 62/64 loss: 0.3574933409690857
Batch 63/64 loss: 0.3538491129875183
Batch 64/64 loss: 0.35449814796447754
Epoch 14  Train loss: 0.3533552225898294  Val loss: 0.3561802578136274
Epoch 15
-------------------------------
Batch 1/64 loss: 0.35142403841018677
Batch 2/64 loss: 0.35284262895584106
Batch 3/64 loss: 0.35116273164749146
Batch 4/64 loss: 0.3523210287094116
Batch 5/64 loss: 0.3531312942504883
Batch 6/64 loss: 0.3544192314147949
Batch 7/64 loss: 0.3556394577026367
Batch 8/64 loss: 0.35324496030807495
Batch 9/64 loss: 0.3620607256889343
Batch 10/64 loss: 0.35487520694732666
Batch 11/64 loss: 0.3524683713912964
Batch 12/64 loss: 0.3516242504119873
Batch 13/64 loss: 0.35311126708984375
Batch 14/64 loss: 0.3556458353996277
Batch 15/64 loss: 0.3516864776611328
Batch 16/64 loss: 0.3532114028930664
Batch 17/64 loss: 0.35182929039001465
Batch 18/64 loss: 0.35231900215148926
Batch 19/64 loss: 0.35231155157089233
Batch 20/64 loss: 0.3538210988044739
Batch 21/64 loss: 0.3517550826072693
Batch 22/64 loss: 0.3523550033569336
Batch 23/64 loss: 0.35790371894836426
Batch 24/64 loss: 0.352435827255249
Batch 25/64 loss: 0.3494623899459839
Batch 26/64 loss: 0.3540998697280884
Batch 27/64 loss: 0.3484289050102234
Batch 28/64 loss: 0.34966766834259033
Batch 29/64 loss: 0.3508652448654175
Batch 30/64 loss: 0.3499380946159363
Batch 31/64 loss: 0.3533334732055664
Batch 32/64 loss: 0.35243189334869385
Batch 33/64 loss: 0.35504150390625
Batch 34/64 loss: 0.35603874921798706
Batch 35/64 loss: 0.3540918827056885
Batch 36/64 loss: 0.35539382696151733
Batch 37/64 loss: 0.360775351524353
Batch 38/64 loss: 0.35426682233810425
Batch 39/64 loss: 0.3489949703216553
Batch 40/64 loss: 0.35288840532302856
Batch 41/64 loss: 0.3546231985092163
Batch 42/64 loss: 0.3560619354248047
Batch 43/64 loss: 0.35046398639678955
Batch 44/64 loss: 0.35574132204055786
Batch 45/64 loss: 0.3515564799308777
Batch 46/64 loss: 0.34993600845336914
Batch 47/64 loss: 0.3544498085975647
Batch 48/64 loss: 0.35266053676605225
Batch 49/64 loss: 0.349093496799469
Batch 50/64 loss: 0.351499080657959
Batch 51/64 loss: 0.35407590866088867
Batch 52/64 loss: 0.3528451919555664
Batch 53/64 loss: 0.35256195068359375
Batch 54/64 loss: 0.35292279720306396
Batch 55/64 loss: 0.35046207904815674
Batch 56/64 loss: 0.3517530560493469
Batch 57/64 loss: 0.34884393215179443
Batch 58/64 loss: 0.35285139083862305
Batch 59/64 loss: 0.3558439016342163
Batch 60/64 loss: 0.34932994842529297
Batch 61/64 loss: 0.3520369529724121
Batch 62/64 loss: 0.35305726528167725
Batch 63/64 loss: 0.35190659761428833
Batch 64/64 loss: 0.3503842353820801
Epoch 15  Train loss: 0.35288915353662825  Val loss: 0.35487955788156833
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: 0.3562166094779968
Batch 2/64 loss: 0.346623957157135
Batch 3/64 loss: 0.35332685708999634
Batch 4/64 loss: 0.35040390491485596
Batch 5/64 loss: 0.3478062152862549
Batch 6/64 loss: 0.3523505926132202
Batch 7/64 loss: 0.3529181480407715
Batch 8/64 loss: 0.35284698009490967
Batch 9/64 loss: 0.35157597064971924
Batch 10/64 loss: 0.35222327709198
Batch 11/64 loss: 0.35318565368652344
Batch 12/64 loss: 0.3506739139556885
Batch 13/64 loss: 0.3484910726547241
Batch 14/64 loss: 0.3514465093612671
Batch 15/64 loss: 0.3563081622123718
Batch 16/64 loss: 0.3514425754547119
Batch 17/64 loss: 0.353996217250824
Batch 18/64 loss: 0.35605454444885254
Batch 19/64 loss: 0.3490816354751587
Batch 20/64 loss: 0.35653209686279297
Batch 21/64 loss: 0.34783852100372314
Batch 22/64 loss: 0.3490985035896301
Batch 23/64 loss: 0.3485487699508667
Batch 24/64 loss: 0.3545571565628052
Batch 25/64 loss: 0.3575628995895386
Batch 26/64 loss: 0.3548450469970703
Batch 27/64 loss: 0.35423266887664795
Batch 28/64 loss: 0.34898173809051514
Batch 29/64 loss: 0.34977924823760986
Batch 30/64 loss: 0.34872156381607056
Batch 31/64 loss: 0.3542006015777588
Batch 32/64 loss: 0.3508186340332031
Batch 33/64 loss: 0.3476138114929199
Batch 34/64 loss: 0.3499767780303955
Batch 35/64 loss: 0.35503578186035156
Batch 36/64 loss: 0.3513922691345215
Batch 37/64 loss: 0.35303306579589844
Batch 38/64 loss: 0.3497734069824219
Batch 39/64 loss: 0.3530043363571167
Batch 40/64 loss: 0.3555365800857544
Batch 41/64 loss: 0.34947824478149414
Batch 42/64 loss: 0.3539034128189087
Batch 43/64 loss: 0.3525657653808594
Batch 44/64 loss: 0.35006773471832275
Batch 45/64 loss: 0.35588961839675903
Batch 46/64 loss: 0.3501476049423218
Batch 47/64 loss: 0.35244232416152954
Batch 48/64 loss: 0.3549593687057495
Batch 49/64 loss: 0.3547229766845703
Batch 50/64 loss: 0.35395288467407227
Batch 51/64 loss: 0.3511449694633484
Batch 52/64 loss: 0.3528178930282593
Batch 53/64 loss: 0.3491947650909424
Batch 54/64 loss: 0.3501394987106323
Batch 55/64 loss: 0.35090160369873047
Batch 56/64 loss: 0.347966730594635
Batch 57/64 loss: 0.35383522510528564
Batch 58/64 loss: 0.34933286905288696
Batch 59/64 loss: 0.35181909799575806
Batch 60/64 loss: 0.3521451950073242
Batch 61/64 loss: 0.35236960649490356
Batch 62/64 loss: 0.3553231954574585
Batch 63/64 loss: 0.3555753231048584
Batch 64/64 loss: 0.35060131549835205
Epoch 16  Train loss: 0.3520267164005953  Val loss: 0.3532783976944861
Saving best model, epoch: 16
Epoch 17
-------------------------------
Batch 1/64 loss: 0.3489418029785156
Batch 2/64 loss: 0.35306310653686523
Batch 3/64 loss: 0.34699833393096924
Batch 4/64 loss: 0.3539785146713257
Batch 5/64 loss: 0.35315829515457153
Batch 6/64 loss: 0.34939080476760864
Batch 7/64 loss: 0.3561757802963257
Batch 8/64 loss: 0.3548431396484375
Batch 9/64 loss: 0.35299384593963623
Batch 10/64 loss: 0.3492772579193115
Batch 11/64 loss: 0.35006821155548096
Batch 12/64 loss: 0.35188114643096924
Batch 13/64 loss: 0.3549702763557434
Batch 14/64 loss: 0.358862042427063
Batch 15/64 loss: 0.35042744874954224
Batch 16/64 loss: 0.3503475785255432
Batch 17/64 loss: 0.34628403186798096
Batch 18/64 loss: 0.35034847259521484
Batch 19/64 loss: 0.3528517484664917
Batch 20/64 loss: 0.349534273147583
Batch 21/64 loss: 0.35063546895980835
Batch 22/64 loss: 0.35578984022140503
Batch 23/64 loss: 0.3533446788787842
Batch 24/64 loss: 0.35060930252075195
Batch 25/64 loss: 0.35034143924713135
Batch 26/64 loss: 0.3551124334335327
Batch 27/64 loss: 0.3545275926589966
Batch 28/64 loss: 0.35282230377197266
Batch 29/64 loss: 0.35607093572616577
Batch 30/64 loss: 0.3523421287536621
Batch 31/64 loss: 0.3526919484138489
Batch 32/64 loss: 0.3531074523925781
Batch 33/64 loss: 0.3554198741912842
Batch 34/64 loss: 0.3496602773666382
Batch 35/64 loss: 0.34780454635620117
Batch 36/64 loss: 0.35064542293548584
Batch 37/64 loss: 0.3521386384963989
Batch 38/64 loss: 0.34947967529296875
Batch 39/64 loss: 0.350963830947876
Batch 40/64 loss: 0.35252344608306885
Batch 41/64 loss: 0.35132545232772827
Batch 42/64 loss: 0.3504667282104492
Batch 43/64 loss: 0.35149794816970825
Batch 44/64 loss: 0.34569990634918213
Batch 45/64 loss: 0.3501325845718384
Batch 46/64 loss: 0.3512439727783203
Batch 47/64 loss: 0.34817075729370117
Batch 48/64 loss: 0.35189229249954224
Batch 49/64 loss: 0.3507238030433655
Batch 50/64 loss: 0.3535579442977905
Batch 51/64 loss: 0.351265549659729
Batch 52/64 loss: 0.3500843048095703
Batch 53/64 loss: 0.34797006845474243
Batch 54/64 loss: 0.3474048376083374
Batch 55/64 loss: 0.3536808490753174
Batch 56/64 loss: 0.34906458854675293
Batch 57/64 loss: 0.3509054183959961
Batch 58/64 loss: 0.34944939613342285
Batch 59/64 loss: 0.3504660129547119
Batch 60/64 loss: 0.35075777769088745
Batch 61/64 loss: 0.35186517238616943
Batch 62/64 loss: 0.350716233253479
Batch 63/64 loss: 0.35471397638320923
Batch 64/64 loss: 0.3532341718673706
Epoch 17  Train loss: 0.35150444788091323  Val loss: 0.35425708670796396
Epoch 18
-------------------------------
Batch 1/64 loss: 0.34731221199035645
Batch 2/64 loss: 0.3499937653541565
Batch 3/64 loss: 0.3536227345466614
Batch 4/64 loss: 0.3530477285385132
Batch 5/64 loss: 0.3504621982574463
Batch 6/64 loss: 0.35039210319519043
Batch 7/64 loss: 0.34790706634521484
Batch 8/64 loss: 0.3466988801956177
Batch 9/64 loss: 0.35569989681243896
Batch 10/64 loss: 0.34913384914398193
Batch 11/64 loss: 0.3505329489707947
Batch 12/64 loss: 0.3518059253692627
Batch 13/64 loss: 0.35181474685668945
Batch 14/64 loss: 0.3534453511238098
Batch 15/64 loss: 0.35100841522216797
Batch 16/64 loss: 0.35086333751678467
Batch 17/64 loss: 0.3488730192184448
Batch 18/64 loss: 0.3543989062309265
Batch 19/64 loss: 0.35136550664901733
Batch 20/64 loss: 0.35322272777557373
Batch 21/64 loss: 0.34848666191101074
Batch 22/64 loss: 0.3499354124069214
Batch 23/64 loss: 0.3521242141723633
Batch 24/64 loss: 0.3510199785232544
Batch 25/64 loss: 0.3523492217063904
Batch 26/64 loss: 0.3511587977409363
Batch 27/64 loss: 0.35057032108306885
Batch 28/64 loss: 0.3551815152168274
Batch 29/64 loss: 0.351925253868103
Batch 30/64 loss: 0.3489581346511841
Batch 31/64 loss: 0.3525061011314392
Batch 32/64 loss: 0.35237061977386475
Batch 33/64 loss: 0.3487144112586975
Batch 34/64 loss: 0.3516630530357361
Batch 35/64 loss: 0.35040032863616943
Batch 36/64 loss: 0.3524785041809082
Batch 37/64 loss: 0.3496323227882385
Batch 38/64 loss: 0.3498528003692627
Batch 39/64 loss: 0.34593528509140015
Batch 40/64 loss: 0.3500388264656067
Batch 41/64 loss: 0.3526584506034851
Batch 42/64 loss: 0.34929704666137695
Batch 43/64 loss: 0.3492017388343811
Batch 44/64 loss: 0.3515934944152832
Batch 45/64 loss: 0.3463897705078125
Batch 46/64 loss: 0.35170233249664307
Batch 47/64 loss: 0.35070687532424927
Batch 48/64 loss: 0.3540809154510498
Batch 49/64 loss: 0.35500574111938477
Batch 50/64 loss: 0.35132551193237305
Batch 51/64 loss: 0.35247665643692017
Batch 52/64 loss: 0.35270363092422485
Batch 53/64 loss: 0.3527563214302063
Batch 54/64 loss: 0.353751540184021
Batch 55/64 loss: 0.3545536994934082
Batch 56/64 loss: 0.3483017086982727
Batch 57/64 loss: 0.3454403281211853
Batch 58/64 loss: 0.34843361377716064
Batch 59/64 loss: 0.3515535593032837
Batch 60/64 loss: 0.34746623039245605
Batch 61/64 loss: 0.3524729609489441
Batch 62/64 loss: 0.350736141204834
Batch 63/64 loss: 0.35012155771255493
Batch 64/64 loss: 0.3509291410446167
Epoch 18  Train loss: 0.3509463492561789  Val loss: 0.3524993658065796
Saving best model, epoch: 18
Epoch 19
-------------------------------
Batch 1/64 loss: 0.35008955001831055
Batch 2/64 loss: 0.3510098457336426
Batch 3/64 loss: 0.3486515283584595
Batch 4/64 loss: 0.34609341621398926
Batch 5/64 loss: 0.35244566202163696
Batch 6/64 loss: 0.3492262363433838
Batch 7/64 loss: 0.346577525138855
Batch 8/64 loss: 0.35392338037490845
Batch 9/64 loss: 0.3472999334335327
Batch 10/64 loss: 0.3496302366256714
Batch 11/64 loss: 0.35076606273651123
Batch 12/64 loss: 0.3500978946685791
Batch 13/64 loss: 0.35156816244125366
Batch 14/64 loss: 0.35102391242980957
Batch 15/64 loss: 0.3499332070350647
Batch 16/64 loss: 0.3503987193107605
Batch 17/64 loss: 0.35142946243286133
Batch 18/64 loss: 0.3497014045715332
Batch 19/64 loss: 0.3506714701652527
Batch 20/64 loss: 0.35230690240859985
Batch 21/64 loss: 0.34803247451782227
Batch 22/64 loss: 0.35158848762512207
Batch 23/64 loss: 0.3514653444290161
Batch 24/64 loss: 0.34501081705093384
Batch 25/64 loss: 0.34835463762283325
Batch 26/64 loss: 0.349789559841156
Batch 27/64 loss: 0.3527272343635559
Batch 28/64 loss: 0.34911787509918213
Batch 29/64 loss: 0.3514268398284912
Batch 30/64 loss: 0.3542616367340088
Batch 31/64 loss: 0.35556089878082275
Batch 32/64 loss: 0.34987950325012207
Batch 33/64 loss: 0.35217201709747314
Batch 34/64 loss: 0.34811800718307495
Batch 35/64 loss: 0.3470184803009033
Batch 36/64 loss: 0.3527681827545166
Batch 37/64 loss: 0.35253626108169556
Batch 38/64 loss: 0.3502618074417114
Batch 39/64 loss: 0.3494741916656494
Batch 40/64 loss: 0.3520856499671936
Batch 41/64 loss: 0.35101598501205444
Batch 42/64 loss: 0.3549323081970215
Batch 43/64 loss: 0.3530665636062622
Batch 44/64 loss: 0.34904730319976807
Batch 45/64 loss: 0.3481888771057129
Batch 46/64 loss: 0.35120534896850586
Batch 47/64 loss: 0.3519323468208313
Batch 48/64 loss: 0.3477563261985779
Batch 49/64 loss: 0.3498234748840332
Batch 50/64 loss: 0.3469080924987793
Batch 51/64 loss: 0.3446131944656372
Batch 52/64 loss: 0.3489369750022888
Batch 53/64 loss: 0.34796035289764404
Batch 54/64 loss: 0.350203275680542
Batch 55/64 loss: 0.34888726472854614
Batch 56/64 loss: 0.35325658321380615
Batch 57/64 loss: 0.35129988193511963
Batch 58/64 loss: 0.349371075630188
Batch 59/64 loss: 0.35059481859207153
Batch 60/64 loss: 0.35127294063568115
Batch 61/64 loss: 0.35049211978912354
Batch 62/64 loss: 0.34856152534484863
Batch 63/64 loss: 0.3513561487197876
Batch 64/64 loss: 0.34703731536865234
Epoch 19  Train loss: 0.350203218647078  Val loss: 0.3543403996634729
Epoch 20
-------------------------------
Batch 1/64 loss: 0.35459446907043457
Batch 2/64 loss: 0.35386502742767334
Batch 3/64 loss: 0.3508026599884033
Batch 4/64 loss: 0.3489868640899658
Batch 5/64 loss: 0.34566909074783325
Batch 6/64 loss: 0.34847724437713623
Batch 7/64 loss: 0.3452349305152893
Batch 8/64 loss: 0.3533453345298767
Batch 9/64 loss: 0.3519223928451538
Batch 10/64 loss: 0.34911245107650757
Batch 11/64 loss: 0.34816330671310425
Batch 12/64 loss: 0.3502448797225952
Batch 13/64 loss: 0.35031962394714355
Batch 14/64 loss: 0.3488209843635559
Batch 15/64 loss: 0.3501272201538086
Batch 16/64 loss: 0.3485412001609802
Batch 17/64 loss: 0.3525722026824951
Batch 18/64 loss: 0.3514489531517029
Batch 19/64 loss: 0.3462177515029907
Batch 20/64 loss: 0.3513667583465576
Batch 21/64 loss: 0.34949183464050293
Batch 22/64 loss: 0.35100001096725464
Batch 23/64 loss: 0.35077470541000366
Batch 24/64 loss: 0.35004162788391113
Batch 25/64 loss: 0.3477964401245117
Batch 26/64 loss: 0.3479853868484497
Batch 27/64 loss: 0.3499496579170227
Batch 28/64 loss: 0.34744757413864136
Batch 29/64 loss: 0.3478407859802246
Batch 30/64 loss: 0.3493725061416626
Batch 31/64 loss: 0.3517841100692749
Batch 32/64 loss: 0.348813533782959
Batch 33/64 loss: 0.34718942642211914
Batch 34/64 loss: 0.35161685943603516
Batch 35/64 loss: 0.34678298234939575
Batch 36/64 loss: 0.35563308000564575
Batch 37/64 loss: 0.3545624613761902
Batch 38/64 loss: 0.35318171977996826
Batch 39/64 loss: 0.3484823703765869
Batch 40/64 loss: 0.34728574752807617
Batch 41/64 loss: 0.3486666679382324
Batch 42/64 loss: 0.3434605598449707
Batch 43/64 loss: 0.34753715991973877
Batch 44/64 loss: 0.3499966859817505
Batch 45/64 loss: 0.35206079483032227
Batch 46/64 loss: 0.3495352268218994
Batch 47/64 loss: 0.3460507392883301
Batch 48/64 loss: 0.3512890338897705
Batch 49/64 loss: 0.34938645362854004
Batch 50/64 loss: 0.34947091341018677
Batch 51/64 loss: 0.34999316930770874
Batch 52/64 loss: 0.3532295227050781
Batch 53/64 loss: 0.3482702970504761
Batch 54/64 loss: 0.35347986221313477
Batch 55/64 loss: 0.34955739974975586
Batch 56/64 loss: 0.3500046730041504
Batch 57/64 loss: 0.3465448021888733
Batch 58/64 loss: 0.35107672214508057
Batch 59/64 loss: 0.3509960174560547
Batch 60/64 loss: 0.3495069742202759
Batch 61/64 loss: 0.3443682789802551
Batch 62/64 loss: 0.3533473014831543
Batch 63/64 loss: 0.34807759523391724
Batch 64/64 loss: 0.3542149066925049
Epoch 20  Train loss: 0.34977935996710086  Val loss: 0.35241430731573464
Saving best model, epoch: 20
Epoch 21
-------------------------------
Batch 1/64 loss: 0.34827667474746704
Batch 2/64 loss: 0.3505522608757019
Batch 3/64 loss: 0.35204261541366577
Batch 4/64 loss: 0.3496741056442261
Batch 5/64 loss: 0.34842872619628906
Batch 6/64 loss: 0.3482772707939148
Batch 7/64 loss: 0.3501133322715759
Batch 8/64 loss: 0.3464946746826172
Batch 9/64 loss: 0.35338765382766724
Batch 10/64 loss: 0.3516894578933716
Batch 11/64 loss: 0.3484607934951782
Batch 12/64 loss: 0.35170745849609375
Batch 13/64 loss: 0.35207080841064453
Batch 14/64 loss: 0.3483104705810547
Batch 15/64 loss: 0.3508871793746948
Batch 16/64 loss: 0.3454086184501648
Batch 17/64 loss: 0.34479427337646484
Batch 18/64 loss: 0.35771459341049194
Batch 19/64 loss: 0.3488680124282837
Batch 20/64 loss: 0.35174375772476196
Batch 21/64 loss: 0.3513118624687195
Batch 22/64 loss: 0.34859681129455566
Batch 23/64 loss: 0.3514251708984375
Batch 24/64 loss: 0.34786438941955566
Batch 25/64 loss: 0.3483373522758484
Batch 26/64 loss: 0.34709370136260986
Batch 27/64 loss: 0.348779559135437
Batch 28/64 loss: 0.35204190015792847
Batch 29/64 loss: 0.3541831374168396
Batch 30/64 loss: 0.3542187213897705
Batch 31/64 loss: 0.3438231348991394
Batch 32/64 loss: 0.3520395755767822
Batch 33/64 loss: 0.3458324074745178
Batch 34/64 loss: 0.344667911529541
Batch 35/64 loss: 0.34466004371643066
Batch 36/64 loss: 0.3496168851852417
Batch 37/64 loss: 0.3470456004142761
Batch 38/64 loss: 0.35256993770599365
Batch 39/64 loss: 0.3525710105895996
Batch 40/64 loss: 0.3501971960067749
Batch 41/64 loss: 0.34998619556427
Batch 42/64 loss: 0.34792208671569824
Batch 43/64 loss: 0.3484123945236206
Batch 44/64 loss: 0.3462570905685425
Batch 45/64 loss: 0.3492811918258667
Batch 46/64 loss: 0.3475736379623413
Batch 47/64 loss: 0.3519272804260254
Batch 48/64 loss: 0.3523838520050049
Batch 49/64 loss: 0.3494482636451721
Batch 50/64 loss: 0.34819960594177246
Batch 51/64 loss: 0.35243117809295654
Batch 52/64 loss: 0.34965068101882935
Batch 53/64 loss: 0.3473764657974243
Batch 54/64 loss: 0.3484373092651367
Batch 55/64 loss: 0.3497195243835449
Batch 56/64 loss: 0.3476349115371704
Batch 57/64 loss: 0.3494054675102234
Batch 58/64 loss: 0.3492221236228943
Batch 59/64 loss: 0.35105741024017334
Batch 60/64 loss: 0.35531187057495117
Batch 61/64 loss: 0.3482860326766968
Batch 62/64 loss: 0.34718286991119385
Batch 63/64 loss: 0.34473347663879395
Batch 64/64 loss: 0.3499625325202942
Epoch 21  Train loss: 0.3494916371270722  Val loss: 0.3527017018639345
Epoch 22
-------------------------------
Batch 1/64 loss: 0.3509114384651184
Batch 2/64 loss: 0.34483492374420166
Batch 3/64 loss: 0.3463020920753479
Batch 4/64 loss: 0.3478132486343384
Batch 5/64 loss: 0.34945666790008545
Batch 6/64 loss: 0.352389931678772
Batch 7/64 loss: 0.3501802682876587
Batch 8/64 loss: 0.34820258617401123
Batch 9/64 loss: 0.3522191643714905
Batch 10/64 loss: 0.3503108620643616
Batch 11/64 loss: 0.3481626510620117
Batch 12/64 loss: 0.35080260038375854
Batch 13/64 loss: 0.35162675380706787
Batch 14/64 loss: 0.35254549980163574
Batch 15/64 loss: 0.35061341524124146
Batch 16/64 loss: 0.352630615234375
Batch 17/64 loss: 0.34777402877807617
Batch 18/64 loss: 0.3476513624191284
Batch 19/64 loss: 0.34786123037338257
Batch 20/64 loss: 0.3469853401184082
Batch 21/64 loss: 0.3526402711868286
Batch 22/64 loss: 0.3514735698699951
Batch 23/64 loss: 0.3515803813934326
Batch 24/64 loss: 0.35211920738220215
Batch 25/64 loss: 0.3524057865142822
Batch 26/64 loss: 0.34379827976226807
Batch 27/64 loss: 0.347906231880188
Batch 28/64 loss: 0.3470417261123657
Batch 29/64 loss: 0.3490791320800781
Batch 30/64 loss: 0.34674495458602905
Batch 31/64 loss: 0.3500823974609375
Batch 32/64 loss: 0.34920692443847656
Batch 33/64 loss: 0.3477253317832947
Batch 34/64 loss: 0.34640705585479736
Batch 35/64 loss: 0.3518940806388855
Batch 36/64 loss: 0.34838008880615234
Batch 37/64 loss: 0.34897446632385254
Batch 38/64 loss: 0.34815770387649536
Batch 39/64 loss: 0.3542494773864746
Batch 40/64 loss: 0.3472021818161011
Batch 41/64 loss: 0.3494236469268799
Batch 42/64 loss: 0.3515598773956299
Batch 43/64 loss: 0.34735554456710815
Batch 44/64 loss: 0.3455841541290283
Batch 45/64 loss: 0.34499824047088623
Batch 46/64 loss: 0.34388333559036255
Batch 47/64 loss: 0.3498671054840088
Batch 48/64 loss: 0.34627610445022583
Batch 49/64 loss: 0.34961605072021484
Batch 50/64 loss: 0.34834450483322144
Batch 51/64 loss: 0.3479975461959839
Batch 52/64 loss: 0.3493603467941284
Batch 53/64 loss: 0.3460288643836975
Batch 54/64 loss: 0.34843212366104126
Batch 55/64 loss: 0.3503149151802063
Batch 56/64 loss: 0.3472522497177124
Batch 57/64 loss: 0.3519129157066345
Batch 58/64 loss: 0.3520820140838623
Batch 59/64 loss: 0.3444511294364929
Batch 60/64 loss: 0.3496629595756531
Batch 61/64 loss: 0.3518065810203552
Batch 62/64 loss: 0.3463766574859619
Batch 63/64 loss: 0.3482646942138672
Batch 64/64 loss: 0.3478590250015259
Epoch 22  Train loss: 0.3489896433026183  Val loss: 0.3533083954217917
Epoch 23
-------------------------------
Batch 1/64 loss: 0.34950870275497437
Batch 2/64 loss: 0.344853937625885
Batch 3/64 loss: 0.3463631868362427
Batch 4/64 loss: 0.34843742847442627
Batch 5/64 loss: 0.35346174240112305
Batch 6/64 loss: 0.35064876079559326
Batch 7/64 loss: 0.3518344759941101
Batch 8/64 loss: 0.35226452350616455
Batch 9/64 loss: 0.3473767638206482
Batch 10/64 loss: 0.3499797582626343
Batch 11/64 loss: 0.3526337146759033
Batch 12/64 loss: 0.35050952434539795
Batch 13/64 loss: 0.34974145889282227
Batch 14/64 loss: 0.3507726788520813
Batch 15/64 loss: 0.3489193916320801
Batch 16/64 loss: 0.3508925437927246
Batch 17/64 loss: 0.3499617576599121
Batch 18/64 loss: 0.34839707612991333
Batch 19/64 loss: 0.3410504460334778
Batch 20/64 loss: 0.3483888506889343
Batch 21/64 loss: 0.3474310040473938
Batch 22/64 loss: 0.34825271368026733
Batch 23/64 loss: 0.3539804220199585
Batch 24/64 loss: 0.35032951831817627
Batch 25/64 loss: 0.34559714794158936
Batch 26/64 loss: 0.3494049310684204
Batch 27/64 loss: 0.3513084650039673
Batch 28/64 loss: 0.3495357036590576
Batch 29/64 loss: 0.3515206575393677
Batch 30/64 loss: 0.3499825596809387
Batch 31/64 loss: 0.34839576482772827
Batch 32/64 loss: 0.34646672010421753
Batch 33/64 loss: 0.35233908891677856
Batch 34/64 loss: 0.3463669419288635
Batch 35/64 loss: 0.3488178849220276
Batch 36/64 loss: 0.34450066089630127
Batch 37/64 loss: 0.3526532053947449
Batch 38/64 loss: 0.350727915763855
Batch 39/64 loss: 0.3459455966949463
Batch 40/64 loss: 0.3507159948348999
Batch 41/64 loss: 0.3471866250038147
Batch 42/64 loss: 0.3478870391845703
Batch 43/64 loss: 0.34847331047058105
Batch 44/64 loss: 0.35292893648147583
Batch 45/64 loss: 0.34936022758483887
Batch 46/64 loss: 0.3497767448425293
Batch 47/64 loss: 0.349202036857605
Batch 48/64 loss: 0.3527092933654785
Batch 49/64 loss: 0.34956610202789307
Batch 50/64 loss: 0.350064754486084
Batch 51/64 loss: 0.3505598306655884
Batch 52/64 loss: 0.35086584091186523
Batch 53/64 loss: 0.34546709060668945
Batch 54/64 loss: 0.344105064868927
Batch 55/64 loss: 0.34613263607025146
Batch 56/64 loss: 0.34613144397735596
Batch 57/64 loss: 0.3410104513168335
Batch 58/64 loss: 0.35233592987060547
Batch 59/64 loss: 0.3477092981338501
Batch 60/64 loss: 0.34812963008880615
Batch 61/64 loss: 0.3449433445930481
Batch 62/64 loss: 0.34961676597595215
Batch 63/64 loss: 0.35002636909484863
Batch 64/64 loss: 0.34723973274230957
Epoch 23  Train loss: 0.3489394225326239  Val loss: 0.35289228720353644
Epoch 24
-------------------------------
Batch 1/64 loss: 0.3471565246582031
Batch 2/64 loss: 0.34789764881134033
Batch 3/64 loss: 0.3442535400390625
Batch 4/64 loss: 0.35196518898010254
Batch 5/64 loss: 0.3461475968360901
Batch 6/64 loss: 0.34736084938049316
Batch 7/64 loss: 0.34789979457855225
Batch 8/64 loss: 0.35165679454803467
Batch 9/64 loss: 0.3514411449432373
Batch 10/64 loss: 0.3499046564102173
Batch 11/64 loss: 0.3466448187828064
Batch 12/64 loss: 0.3511365056037903
Batch 13/64 loss: 0.3443259596824646
Batch 14/64 loss: 0.349992036819458
Batch 15/64 loss: 0.3459778428077698
Batch 16/64 loss: 0.3519294261932373
Batch 17/64 loss: 0.3453397750854492
Batch 18/64 loss: 0.3479677438735962
Batch 19/64 loss: 0.3470280170440674
Batch 20/64 loss: 0.3498055934906006
Batch 21/64 loss: 0.3493283987045288
Batch 22/64 loss: 0.34684813022613525
Batch 23/64 loss: 0.34809303283691406
Batch 24/64 loss: 0.3532991409301758
Batch 25/64 loss: 0.3490981459617615
Batch 26/64 loss: 0.34768348932266235
Batch 27/64 loss: 0.34747815132141113
Batch 28/64 loss: 0.35317766666412354
Batch 29/64 loss: 0.3483894467353821
Batch 30/64 loss: 0.349475622177124
Batch 31/64 loss: 0.3522714376449585
Batch 32/64 loss: 0.34853410720825195
Batch 33/64 loss: 0.3509567975997925
Batch 34/64 loss: 0.34558558464050293
Batch 35/64 loss: 0.3456653356552124
Batch 36/64 loss: 0.3506396412849426
Batch 37/64 loss: 0.34585797786712646
Batch 38/64 loss: 0.3436967730522156
Batch 39/64 loss: 0.34159284830093384
Batch 40/64 loss: 0.3491945266723633
Batch 41/64 loss: 0.34586983919143677
Batch 42/64 loss: 0.3502655625343323
Batch 43/64 loss: 0.3469495177268982
Batch 44/64 loss: 0.34737980365753174
Batch 45/64 loss: 0.35095304250717163
Batch 46/64 loss: 0.35319119691848755
Batch 47/64 loss: 0.35154128074645996
Batch 48/64 loss: 0.34773391485214233
Batch 49/64 loss: 0.34627223014831543
Batch 50/64 loss: 0.34965258836746216
Batch 51/64 loss: 0.3453773260116577
Batch 52/64 loss: 0.3484647274017334
Batch 53/64 loss: 0.34838664531707764
Batch 54/64 loss: 0.35057955980300903
Batch 55/64 loss: 0.34563952684402466
Batch 56/64 loss: 0.35001516342163086
Batch 57/64 loss: 0.3504243493080139
Batch 58/64 loss: 0.3493366241455078
Batch 59/64 loss: 0.34977078437805176
Batch 60/64 loss: 0.3497266173362732
Batch 61/64 loss: 0.34884655475616455
Batch 62/64 loss: 0.3456777334213257
Batch 63/64 loss: 0.3472139835357666
Batch 64/64 loss: 0.35195469856262207
Epoch 24  Train loss: 0.34848521270003974  Val loss: 0.3510391589292546
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 0.3438091278076172
Batch 2/64 loss: 0.34568512439727783
Batch 3/64 loss: 0.3459768295288086
Batch 4/64 loss: 0.3479064702987671
Batch 5/64 loss: 0.349575400352478
Batch 6/64 loss: 0.3447573184967041
Batch 7/64 loss: 0.3483877182006836
Batch 8/64 loss: 0.34372180700302124
Batch 9/64 loss: 0.35033124685287476
Batch 10/64 loss: 0.3490181565284729
Batch 11/64 loss: 0.34563279151916504
Batch 12/64 loss: 0.347439169883728
Batch 13/64 loss: 0.3519604802131653
Batch 14/64 loss: 0.35021233558654785
Batch 15/64 loss: 0.34550613164901733
Batch 16/64 loss: 0.3525536060333252
Batch 17/64 loss: 0.34600234031677246
Batch 18/64 loss: 0.3466259241104126
Batch 19/64 loss: 0.34468597173690796
Batch 20/64 loss: 0.34834223985671997
Batch 21/64 loss: 0.348834753036499
Batch 22/64 loss: 0.3491668701171875
Batch 23/64 loss: 0.35079121589660645
Batch 24/64 loss: 0.34882473945617676
Batch 25/64 loss: 0.3499208688735962
Batch 26/64 loss: 0.3435525894165039
Batch 27/64 loss: 0.3450506925582886
Batch 28/64 loss: 0.3503439426422119
Batch 29/64 loss: 0.346362829208374
Batch 30/64 loss: 0.3489227294921875
Batch 31/64 loss: 0.34910863637924194
Batch 32/64 loss: 0.34547799825668335
Batch 33/64 loss: 0.3497021198272705
Batch 34/64 loss: 0.3500640392303467
Batch 35/64 loss: 0.35396111011505127
Batch 36/64 loss: 0.3489953279495239
Batch 37/64 loss: 0.34474414587020874
Batch 38/64 loss: 0.3474372625350952
Batch 39/64 loss: 0.35159969329833984
Batch 40/64 loss: 0.3501706123352051
Batch 41/64 loss: 0.34906721115112305
Batch 42/64 loss: 0.34783756732940674
Batch 43/64 loss: 0.3498774766921997
Batch 44/64 loss: 0.3444845676422119
Batch 45/64 loss: 0.35019439458847046
Batch 46/64 loss: 0.3478659391403198
Batch 47/64 loss: 0.35346519947052
Batch 48/64 loss: 0.3501718044281006
Batch 49/64 loss: 0.34768617153167725
Batch 50/64 loss: 0.3496119976043701
Batch 51/64 loss: 0.34683549404144287
Batch 52/64 loss: 0.3414195775985718
Batch 53/64 loss: 0.3479801416397095
Batch 54/64 loss: 0.34728682041168213
Batch 55/64 loss: 0.3435400724411011
Batch 56/64 loss: 0.3451254367828369
Batch 57/64 loss: 0.3482729196548462
Batch 58/64 loss: 0.3484063148498535
Batch 59/64 loss: 0.3455594778060913
Batch 60/64 loss: 0.3459566831588745
Batch 61/64 loss: 0.3459634780883789
Batch 62/64 loss: 0.34815001487731934
Batch 63/64 loss: 0.34852153062820435
Batch 64/64 loss: 0.3478580713272095
Epoch 25  Train loss: 0.34784841116736914  Val loss: 0.3524359900926806
Epoch 26
-------------------------------
Batch 1/64 loss: 0.3471181392669678
Batch 2/64 loss: 0.35073143243789673
Batch 3/64 loss: 0.3489394187927246
Batch 4/64 loss: 0.3460003137588501
Batch 5/64 loss: 0.3474055528640747
Batch 6/64 loss: 0.34944528341293335
Batch 7/64 loss: 0.34682297706604004
Batch 8/64 loss: 0.34634149074554443
Batch 9/64 loss: 0.34397244453430176
Batch 10/64 loss: 0.3527788519859314
Batch 11/64 loss: 0.3461974859237671
Batch 12/64 loss: 0.3475908041000366
Batch 13/64 loss: 0.3480297923088074
Batch 14/64 loss: 0.34925633668899536
Batch 15/64 loss: 0.3482168912887573
Batch 16/64 loss: 0.3487735986709595
Batch 17/64 loss: 0.3410453796386719
Batch 18/64 loss: 0.35300809144973755
Batch 19/64 loss: 0.34534603357315063
Batch 20/64 loss: 0.34075820446014404
Batch 21/64 loss: 0.34629470109939575
Batch 22/64 loss: 0.3419036865234375
Batch 23/64 loss: 0.346155047416687
Batch 24/64 loss: 0.34898388385772705
Batch 25/64 loss: 0.35003662109375
Batch 26/64 loss: 0.3423660397529602
Batch 27/64 loss: 0.3431864380836487
Batch 28/64 loss: 0.3471492528915405
Batch 29/64 loss: 0.3459378480911255
Batch 30/64 loss: 0.35129982233047485
Batch 31/64 loss: 0.3485664129257202
Batch 32/64 loss: 0.3436697721481323
Batch 33/64 loss: 0.3488597869873047
Batch 34/64 loss: 0.34594476222991943
Batch 35/64 loss: 0.34512192010879517
Batch 36/64 loss: 0.34299778938293457
Batch 37/64 loss: 0.3483152985572815
Batch 38/64 loss: 0.3522452116012573
Batch 39/64 loss: 0.34567415714263916
Batch 40/64 loss: 0.347690224647522
Batch 41/64 loss: 0.3441978693008423
Batch 42/64 loss: 0.3446539044380188
Batch 43/64 loss: 0.3480348587036133
Batch 44/64 loss: 0.34795188903808594
Batch 45/64 loss: 0.3478281497955322
Batch 46/64 loss: 0.34459686279296875
Batch 47/64 loss: 0.34615635871887207
Batch 48/64 loss: 0.3461989164352417
Batch 49/64 loss: 0.34830665588378906
Batch 50/64 loss: 0.34713900089263916
Batch 51/64 loss: 0.35098254680633545
Batch 52/64 loss: 0.3473449945449829
Batch 53/64 loss: 0.35170072317123413
Batch 54/64 loss: 0.3505110740661621
Batch 55/64 loss: 0.35267025232315063
Batch 56/64 loss: 0.3468642234802246
Batch 57/64 loss: 0.3481709957122803
Batch 58/64 loss: 0.34732556343078613
Batch 59/64 loss: 0.3534677028656006
Batch 60/64 loss: 0.34373897314071655
Batch 61/64 loss: 0.3514736294746399
Batch 62/64 loss: 0.3454676866531372
Batch 63/64 loss: 0.34586405754089355
Batch 64/64 loss: 0.3490513563156128
Epoch 26  Train loss: 0.34733509970646276  Val loss: 0.3498735053023112
Saving best model, epoch: 26
Epoch 27
-------------------------------
Batch 1/64 loss: 0.34760046005249023
Batch 2/64 loss: 0.3417288064956665
Batch 3/64 loss: 0.34376466274261475
Batch 4/64 loss: 0.3456379771232605
Batch 5/64 loss: 0.3462435007095337
Batch 6/64 loss: 0.34460920095443726
Batch 7/64 loss: 0.34248316287994385
Batch 8/64 loss: 0.3447189927101135
Batch 9/64 loss: 0.3503870368003845
Batch 10/64 loss: 0.34266209602355957
Batch 11/64 loss: 0.3482838273048401
Batch 12/64 loss: 0.3426980972290039
Batch 13/64 loss: 0.345603346824646
Batch 14/64 loss: 0.3519078493118286
Batch 15/64 loss: 0.3456847071647644
Batch 16/64 loss: 0.3444066047668457
Batch 17/64 loss: 0.3463238477706909
Batch 18/64 loss: 0.35123175382614136
Batch 19/64 loss: 0.34506499767303467
Batch 20/64 loss: 0.3428468704223633
Batch 21/64 loss: 0.34786689281463623
Batch 22/64 loss: 0.34634244441986084
Batch 23/64 loss: 0.3436537981033325
Batch 24/64 loss: 0.3510357737541199
Batch 25/64 loss: 0.341685950756073
Batch 26/64 loss: 0.350807249546051
Batch 27/64 loss: 0.3444821834564209
Batch 28/64 loss: 0.3508291244506836
Batch 29/64 loss: 0.34672117233276367
Batch 30/64 loss: 0.34879064559936523
Batch 31/64 loss: 0.3459773063659668
Batch 32/64 loss: 0.34828072786331177
Batch 33/64 loss: 0.347284197807312
Batch 34/64 loss: 0.3471561074256897
Batch 35/64 loss: 0.35054636001586914
Batch 36/64 loss: 0.353190541267395
Batch 37/64 loss: 0.3482486605644226
Batch 38/64 loss: 0.3491221070289612
Batch 39/64 loss: 0.3417379856109619
Batch 40/64 loss: 0.34465205669403076
Batch 41/64 loss: 0.3444114327430725
Batch 42/64 loss: 0.34869295358657837
Batch 43/64 loss: 0.3467400074005127
Batch 44/64 loss: 0.34949827194213867
Batch 45/64 loss: 0.34761810302734375
Batch 46/64 loss: 0.34996044635772705
Batch 47/64 loss: 0.3464149236679077
Batch 48/64 loss: 0.3488039970397949
Batch 49/64 loss: 0.34586548805236816
Batch 50/64 loss: 0.34654170274734497
Batch 51/64 loss: 0.3457372188568115
Batch 52/64 loss: 0.34902846813201904
Batch 53/64 loss: 0.3487488627433777
Batch 54/64 loss: 0.34664756059646606
Batch 55/64 loss: 0.3492262363433838
Batch 56/64 loss: 0.35126274824142456
Batch 57/64 loss: 0.34800243377685547
Batch 58/64 loss: 0.3495779037475586
Batch 59/64 loss: 0.3495138883590698
Batch 60/64 loss: 0.3451101779937744
Batch 61/64 loss: 0.34587961435317993
Batch 62/64 loss: 0.34321314096450806
Batch 63/64 loss: 0.3456932306289673
Batch 64/64 loss: 0.3503204584121704
Epoch 27  Train loss: 0.3469369135650934  Val loss: 0.35062092686027185
Epoch 28
-------------------------------
Batch 1/64 loss: 0.3446822762489319
Batch 2/64 loss: 0.34629249572753906
Batch 3/64 loss: 0.3496023416519165
Batch 4/64 loss: 0.34407591819763184
Batch 5/64 loss: 0.34769850969314575
Batch 6/64 loss: 0.3498491048812866
Batch 7/64 loss: 0.35283219814300537
Batch 8/64 loss: 0.34772002696990967
Batch 9/64 loss: 0.3483263850212097
Batch 10/64 loss: 0.34566617012023926
Batch 11/64 loss: 0.3428416848182678
Batch 12/64 loss: 0.35074925422668457
Batch 13/64 loss: 0.34878361225128174
Batch 14/64 loss: 0.3462982177734375
Batch 15/64 loss: 0.3439931869506836
Batch 16/64 loss: 0.34633827209472656
Batch 17/64 loss: 0.34277570247650146
Batch 18/64 loss: 0.34499722719192505
Batch 19/64 loss: 0.34858572483062744
Batch 20/64 loss: 0.34096425771713257
Batch 21/64 loss: 0.3497157096862793
Batch 22/64 loss: 0.3455926179885864
Batch 23/64 loss: 0.3462669253349304
Batch 24/64 loss: 0.34810328483581543
Batch 25/64 loss: 0.3438621759414673
Batch 26/64 loss: 0.34578102827072144
Batch 27/64 loss: 0.34237658977508545
Batch 28/64 loss: 0.34792089462280273
Batch 29/64 loss: 0.34859132766723633
Batch 30/64 loss: 0.34599578380584717
Batch 31/64 loss: 0.3453187942504883
Batch 32/64 loss: 0.34625089168548584
Batch 33/64 loss: 0.35006648302078247
Batch 34/64 loss: 0.34778648614883423
Batch 35/64 loss: 0.34822970628738403
Batch 36/64 loss: 0.3470344543457031
Batch 37/64 loss: 0.3456001877784729
Batch 38/64 loss: 0.3488147258758545
Batch 39/64 loss: 0.35167890787124634
Batch 40/64 loss: 0.34599173069000244
Batch 41/64 loss: 0.3429986834526062
Batch 42/64 loss: 0.3465295433998108
Batch 43/64 loss: 0.34629714488983154
Batch 44/64 loss: 0.34696078300476074
Batch 45/64 loss: 0.34343695640563965
Batch 46/64 loss: 0.3444911241531372
Batch 47/64 loss: 0.343522846698761
Batch 48/64 loss: 0.3446468114852905
Batch 49/64 loss: 0.3466057777404785
Batch 50/64 loss: 0.34515702724456787
Batch 51/64 loss: 0.3508397340774536
Batch 52/64 loss: 0.3464701175689697
Batch 53/64 loss: 0.34631556272506714
Batch 54/64 loss: 0.34799158573150635
Batch 55/64 loss: 0.34905505180358887
Batch 56/64 loss: 0.3494138717651367
Batch 57/64 loss: 0.34516406059265137
Batch 58/64 loss: 0.34590041637420654
Batch 59/64 loss: 0.34752070903778076
Batch 60/64 loss: 0.34862077236175537
Batch 61/64 loss: 0.34751999378204346
Batch 62/64 loss: 0.3454548120498657
Batch 63/64 loss: 0.3482850193977356
Batch 64/64 loss: 0.34493207931518555
Epoch 28  Train loss: 0.3466972351074219  Val loss: 0.34975801403170187
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: 0.345023512840271
Batch 2/64 loss: 0.3488008975982666
Batch 3/64 loss: 0.3464559316635132
Batch 4/64 loss: 0.3476725220680237
Batch 5/64 loss: 0.3391265869140625
Batch 6/64 loss: 0.3454385995864868
Batch 7/64 loss: 0.3492279648780823
Batch 8/64 loss: 0.3451901078224182
Batch 9/64 loss: 0.350780189037323
Batch 10/64 loss: 0.3489443063735962
Batch 11/64 loss: 0.3425653576850891
Batch 12/64 loss: 0.34667718410491943
Batch 13/64 loss: 0.3447561264038086
Batch 14/64 loss: 0.34274858236312866
Batch 15/64 loss: 0.34703099727630615
Batch 16/64 loss: 0.34506869316101074
Batch 17/64 loss: 0.34938085079193115
Batch 18/64 loss: 0.3431769013404846
Batch 19/64 loss: 0.34677278995513916
Batch 20/64 loss: 0.34435880184173584
Batch 21/64 loss: 0.3491423726081848
Batch 22/64 loss: 0.349568247795105
Batch 23/64 loss: 0.3481261730194092
Batch 24/64 loss: 0.3501790761947632
Batch 25/64 loss: 0.3499530553817749
Batch 26/64 loss: 0.34690940380096436
Batch 27/64 loss: 0.3431580662727356
Batch 28/64 loss: 0.34829026460647583
Batch 29/64 loss: 0.3450964093208313
Batch 30/64 loss: 0.3425328731536865
Batch 31/64 loss: 0.3481951951980591
Batch 32/64 loss: 0.350496768951416
Batch 33/64 loss: 0.34447193145751953
Batch 34/64 loss: 0.3445788025856018
Batch 35/64 loss: 0.3464028835296631
Batch 36/64 loss: 0.3473479747772217
Batch 37/64 loss: 0.3489115238189697
Batch 38/64 loss: 0.3527907729148865
Batch 39/64 loss: 0.34988725185394287
Batch 40/64 loss: 0.34262973070144653
Batch 41/64 loss: 0.34735506772994995
Batch 42/64 loss: 0.348697304725647
Batch 43/64 loss: 0.3456798195838928
Batch 44/64 loss: 0.3449290990829468
Batch 45/64 loss: 0.3450183868408203
Batch 46/64 loss: 0.34276795387268066
Batch 47/64 loss: 0.34393781423568726
Batch 48/64 loss: 0.348452627658844
Batch 49/64 loss: 0.3452262878417969
Batch 50/64 loss: 0.3469727039337158
Batch 51/64 loss: 0.34333765506744385
Batch 52/64 loss: 0.3454021215438843
Batch 53/64 loss: 0.34444427490234375
Batch 54/64 loss: 0.34902423620224
Batch 55/64 loss: 0.3456486463546753
Batch 56/64 loss: 0.3440171480178833
Batch 57/64 loss: 0.344509482383728
Batch 58/64 loss: 0.34409594535827637
Batch 59/64 loss: 0.34705591201782227
Batch 60/64 loss: 0.34906458854675293
Batch 61/64 loss: 0.34448307752609253
Batch 62/64 loss: 0.3468512296676636
Batch 63/64 loss: 0.34858477115631104
Batch 64/64 loss: 0.34628117084503174
Epoch 29  Train loss: 0.3464020817887549  Val loss: 0.34970102687062266
Saving best model, epoch: 29
Epoch 30
-------------------------------
Batch 1/64 loss: 0.3459334969520569
Batch 2/64 loss: 0.3484196066856384
Batch 3/64 loss: 0.34626221656799316
Batch 4/64 loss: 0.3416973352432251
Batch 5/64 loss: 0.3473036289215088
Batch 6/64 loss: 0.34651684761047363
Batch 7/64 loss: 0.3455107808113098
Batch 8/64 loss: 0.3403892517089844
Batch 9/64 loss: 0.3441486358642578
Batch 10/64 loss: 0.3502642512321472
Batch 11/64 loss: 0.34611159563064575
Batch 12/64 loss: 0.35140252113342285
Batch 13/64 loss: 0.3463653326034546
Batch 14/64 loss: 0.3485757112503052
Batch 15/64 loss: 0.3484323024749756
Batch 16/64 loss: 0.34541547298431396
Batch 17/64 loss: 0.3457990884780884
Batch 18/64 loss: 0.3472428321838379
Batch 19/64 loss: 0.34679800271987915
Batch 20/64 loss: 0.3429158926010132
Batch 21/64 loss: 0.3426705002784729
Batch 22/64 loss: 0.34500670433044434
Batch 23/64 loss: 0.34267330169677734
Batch 24/64 loss: 0.34323930740356445
Batch 25/64 loss: 0.3421766757965088
Batch 26/64 loss: 0.34136295318603516
Batch 27/64 loss: 0.34338444471359253
Batch 28/64 loss: 0.3462345004081726
Batch 29/64 loss: 0.34344160556793213
Batch 30/64 loss: 0.3462834358215332
Batch 31/64 loss: 0.3454769253730774
Batch 32/64 loss: 0.34796977043151855
Batch 33/64 loss: 0.3464810252189636
Batch 34/64 loss: 0.3460148572921753
Batch 35/64 loss: 0.3432648777961731
Batch 36/64 loss: 0.3462948799133301
Batch 37/64 loss: 0.34815526008605957
Batch 38/64 loss: 0.34523439407348633
Batch 39/64 loss: 0.3461136817932129
Batch 40/64 loss: 0.347975492477417
Batch 41/64 loss: 0.3459814786911011
Batch 42/64 loss: 0.3464423418045044
Batch 43/64 loss: 0.3494102954864502
Batch 44/64 loss: 0.3466571569442749
Batch 45/64 loss: 0.34624290466308594
Batch 46/64 loss: 0.34440189599990845
Batch 47/64 loss: 0.3447333574295044
Batch 48/64 loss: 0.34643304347991943
Batch 49/64 loss: 0.34548813104629517
Batch 50/64 loss: 0.3438377380371094
Batch 51/64 loss: 0.3442874550819397
Batch 52/64 loss: 0.338472843170166
Batch 53/64 loss: 0.3474529981613159
Batch 54/64 loss: 0.34580475091934204
Batch 55/64 loss: 0.3436976671218872
Batch 56/64 loss: 0.3414798974990845
Batch 57/64 loss: 0.34357261657714844
Batch 58/64 loss: 0.3484729528427124
Batch 59/64 loss: 0.34595513343811035
Batch 60/64 loss: 0.3538588285446167
Batch 61/64 loss: 0.3447589874267578
Batch 62/64 loss: 0.3456575870513916
Batch 63/64 loss: 0.3484616279602051
Batch 64/64 loss: 0.351474404335022
Epoch 30  Train loss: 0.34572748062657377  Val loss: 0.3508240009091564
Epoch 31
-------------------------------
Batch 1/64 loss: 0.34734249114990234
Batch 2/64 loss: 0.34314143657684326
Batch 3/64 loss: 0.3452564477920532
Batch 4/64 loss: 0.3419651985168457
Batch 5/64 loss: 0.3503662347793579
Batch 6/64 loss: 0.3463376760482788
Batch 7/64 loss: 0.3441023826599121
Batch 8/64 loss: 0.34777653217315674
Batch 9/64 loss: 0.3452591896057129
Batch 10/64 loss: 0.34830397367477417
Batch 11/64 loss: 0.3469681143760681
Batch 12/64 loss: 0.3446289896965027
Batch 13/64 loss: 0.34725576639175415
Batch 14/64 loss: 0.34510529041290283
Batch 15/64 loss: 0.3465123176574707
Batch 16/64 loss: 0.34474414587020874
Batch 17/64 loss: 0.3505842089653015
Batch 18/64 loss: 0.3428981304168701
Batch 19/64 loss: 0.34358662366867065
Batch 20/64 loss: 0.3438754081726074
Batch 21/64 loss: 0.3449065089225769
Batch 22/64 loss: 0.34521281719207764
Batch 23/64 loss: 0.34519410133361816
Batch 24/64 loss: 0.3448373079299927
Batch 25/64 loss: 0.3500748872756958
Batch 26/64 loss: 0.34398066997528076
Batch 27/64 loss: 0.34289395809173584
Batch 28/64 loss: 0.3456689715385437
Batch 29/64 loss: 0.3408029079437256
Batch 30/64 loss: 0.34277772903442383
Batch 31/64 loss: 0.34757983684539795
Batch 32/64 loss: 0.3463248014450073
Batch 33/64 loss: 0.3482896089553833
Batch 34/64 loss: 0.3479594588279724
Batch 35/64 loss: 0.34495311975479126
Batch 36/64 loss: 0.3494222164154053
Batch 37/64 loss: 0.3436964154243469
Batch 38/64 loss: 0.3422124981880188
Batch 39/64 loss: 0.34657907485961914
Batch 40/64 loss: 0.3430701494216919
Batch 41/64 loss: 0.34010612964630127
Batch 42/64 loss: 0.3400782346725464
Batch 43/64 loss: 0.347430944442749
Batch 44/64 loss: 0.347370982170105
Batch 45/64 loss: 0.3474684953689575
Batch 46/64 loss: 0.3475746512413025
Batch 47/64 loss: 0.3450055718421936
Batch 48/64 loss: 0.3415631055831909
Batch 49/64 loss: 0.34733033180236816
Batch 50/64 loss: 0.35074305534362793
Batch 51/64 loss: 0.3470996022224426
Batch 52/64 loss: 0.3451659083366394
Batch 53/64 loss: 0.3466636538505554
Batch 54/64 loss: 0.34686315059661865
Batch 55/64 loss: 0.3477433919906616
Batch 56/64 loss: 0.34663569927215576
Batch 57/64 loss: 0.34423160552978516
Batch 58/64 loss: 0.3440108895301819
Batch 59/64 loss: 0.3427160978317261
Batch 60/64 loss: 0.33943307399749756
Batch 61/64 loss: 0.34874963760375977
Batch 62/64 loss: 0.346444308757782
Batch 63/64 loss: 0.34544599056243896
Batch 64/64 loss: 0.34130752086639404
Epoch 31  Train loss: 0.34547925883648445  Val loss: 0.3500148795314671
Epoch 32
-------------------------------
Batch 1/64 loss: 0.3503619432449341
Batch 2/64 loss: 0.3447542190551758
Batch 3/64 loss: 0.3468972444534302
Batch 4/64 loss: 0.34713423252105713
Batch 5/64 loss: 0.35250234603881836
Batch 6/64 loss: 0.34760016202926636
Batch 7/64 loss: 0.34908926486968994
Batch 8/64 loss: 0.3445857763290405
Batch 9/64 loss: 0.34623008966445923
Batch 10/64 loss: 0.34724634885787964
Batch 11/64 loss: 0.34772348403930664
Batch 12/64 loss: 0.34446215629577637
Batch 13/64 loss: 0.34576416015625
Batch 14/64 loss: 0.35022640228271484
Batch 15/64 loss: 0.345638632774353
Batch 16/64 loss: 0.3403428792953491
Batch 17/64 loss: 0.34643054008483887
Batch 18/64 loss: 0.3502558469772339
Batch 19/64 loss: 0.34559887647628784
Batch 20/64 loss: 0.34950506687164307
Batch 21/64 loss: 0.34937363862991333
Batch 22/64 loss: 0.3441541790962219
Batch 23/64 loss: 0.3456836938858032
Batch 24/64 loss: 0.34571921825408936
Batch 25/64 loss: 0.3427320122718811
Batch 26/64 loss: 0.34877580404281616
Batch 27/64 loss: 0.34234046936035156
Batch 28/64 loss: 0.3447495698928833
Batch 29/64 loss: 0.3436431884765625
Batch 30/64 loss: 0.3424875736236572
Batch 31/64 loss: 0.34422123432159424
Batch 32/64 loss: 0.34118956327438354
Batch 33/64 loss: 0.3499581813812256
Batch 34/64 loss: 0.34426313638687134
Batch 35/64 loss: 0.34371882677078247
Batch 36/64 loss: 0.34442901611328125
Batch 37/64 loss: 0.346622109413147
Batch 38/64 loss: 0.34870779514312744
Batch 39/64 loss: 0.3491452932357788
Batch 40/64 loss: 0.3433361053466797
Batch 41/64 loss: 0.34018152952194214
Batch 42/64 loss: 0.34349966049194336
Batch 43/64 loss: 0.3435981273651123
Batch 44/64 loss: 0.3432885408401489
Batch 45/64 loss: 0.34367579221725464
Batch 46/64 loss: 0.34327298402786255
Batch 47/64 loss: 0.34804362058639526
Batch 48/64 loss: 0.34743791818618774
Batch 49/64 loss: 0.3467296361923218
Batch 50/64 loss: 0.3460036516189575
Batch 51/64 loss: 0.3441753387451172
Batch 52/64 loss: 0.3383920192718506
Batch 53/64 loss: 0.34324347972869873
Batch 54/64 loss: 0.3495487570762634
Batch 55/64 loss: 0.3432421088218689
Batch 56/64 loss: 0.3483320474624634
Batch 57/64 loss: 0.34906381368637085
Batch 58/64 loss: 0.34817397594451904
Batch 59/64 loss: 0.3461267948150635
Batch 60/64 loss: 0.34539008140563965
Batch 61/64 loss: 0.3480035066604614
Batch 62/64 loss: 0.3422781229019165
Batch 63/64 loss: 0.347808837890625
Batch 64/64 loss: 0.3430473208427429
Epoch 32  Train loss: 0.3457944488992878  Val loss: 0.3479823644218576
Saving best model, epoch: 32
Epoch 33
-------------------------------
Batch 1/64 loss: 0.3459399938583374
Batch 2/64 loss: 0.34441930055618286
Batch 3/64 loss: 0.34711360931396484
Batch 4/64 loss: 0.3470439910888672
Batch 5/64 loss: 0.34346210956573486
Batch 6/64 loss: 0.34252119064331055
Batch 7/64 loss: 0.34730327129364014
Batch 8/64 loss: 0.34573304653167725
Batch 9/64 loss: 0.3463866114616394
Batch 10/64 loss: 0.3435786962509155
Batch 11/64 loss: 0.34182703495025635
Batch 12/64 loss: 0.34178125858306885
Batch 13/64 loss: 0.34323418140411377
Batch 14/64 loss: 0.3434377908706665
Batch 15/64 loss: 0.34030604362487793
Batch 16/64 loss: 0.3452693819999695
Batch 17/64 loss: 0.34821397066116333
Batch 18/64 loss: 0.3457714319229126
Batch 19/64 loss: 0.34376394748687744
Batch 20/64 loss: 0.3466233015060425
Batch 21/64 loss: 0.34555530548095703
Batch 22/64 loss: 0.350277304649353
Batch 23/64 loss: 0.34369075298309326
Batch 24/64 loss: 0.3430863618850708
Batch 25/64 loss: 0.33837997913360596
Batch 26/64 loss: 0.34745556116104126
Batch 27/64 loss: 0.345528244972229
Batch 28/64 loss: 0.34577858448028564
Batch 29/64 loss: 0.34247469902038574
Batch 30/64 loss: 0.3430790305137634
Batch 31/64 loss: 0.34143632650375366
Batch 32/64 loss: 0.3441329002380371
Batch 33/64 loss: 0.338401734828949
Batch 34/64 loss: 0.34541845321655273
Batch 35/64 loss: 0.3406848907470703
Batch 36/64 loss: 0.34393322467803955
Batch 37/64 loss: 0.34629249572753906
Batch 38/64 loss: 0.3384130597114563
Batch 39/64 loss: 0.3453582525253296
Batch 40/64 loss: 0.34809982776641846
Batch 41/64 loss: 0.3438379764556885
Batch 42/64 loss: 0.3420752286911011
Batch 43/64 loss: 0.34441691637039185
Batch 44/64 loss: 0.34407615661621094
Batch 45/64 loss: 0.3467874526977539
Batch 46/64 loss: 0.3452070355415344
Batch 47/64 loss: 0.34182846546173096
Batch 48/64 loss: 0.3442022204399109
Batch 49/64 loss: 0.34469401836395264
Batch 50/64 loss: 0.3468305468559265
Batch 51/64 loss: 0.3460760712623596
Batch 52/64 loss: 0.347109317779541
Batch 53/64 loss: 0.3491010069847107
Batch 54/64 loss: 0.3444938659667969
Batch 55/64 loss: 0.3422810435295105
Batch 56/64 loss: 0.34730470180511475
Batch 57/64 loss: 0.34343671798706055
Batch 58/64 loss: 0.3426046371459961
Batch 59/64 loss: 0.3478962779045105
Batch 60/64 loss: 0.3445191979408264
Batch 61/64 loss: 0.3463294506072998
Batch 62/64 loss: 0.34646159410476685
Batch 63/64 loss: 0.34613990783691406
Batch 64/64 loss: 0.3409109115600586
Epoch 33  Train loss: 0.3445427473853616  Val loss: 0.3478276823804141
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: 0.34848153591156006
Batch 2/64 loss: 0.34143173694610596
Batch 3/64 loss: 0.3471008539199829
Batch 4/64 loss: 0.3454742431640625
Batch 5/64 loss: 0.348080575466156
Batch 6/64 loss: 0.3432319164276123
Batch 7/64 loss: 0.3461499810218811
Batch 8/64 loss: 0.33966100215911865
Batch 9/64 loss: 0.3464919924736023
Batch 10/64 loss: 0.3399902582168579
Batch 11/64 loss: 0.3433558940887451
Batch 12/64 loss: 0.3436223268508911
Batch 13/64 loss: 0.3448273539543152
Batch 14/64 loss: 0.3465985655784607
Batch 15/64 loss: 0.34469497203826904
Batch 16/64 loss: 0.34803295135498047
Batch 17/64 loss: 0.34364020824432373
Batch 18/64 loss: 0.344494104385376
Batch 19/64 loss: 0.3408427834510803
Batch 20/64 loss: 0.34718871116638184
Batch 21/64 loss: 0.3492157459259033
Batch 22/64 loss: 0.3436189889907837
Batch 23/64 loss: 0.3440580368041992
Batch 24/64 loss: 0.34756898880004883
Batch 25/64 loss: 0.33858728408813477
Batch 26/64 loss: 0.3449898958206177
Batch 27/64 loss: 0.34255439043045044
Batch 28/64 loss: 0.3393341302871704
Batch 29/64 loss: 0.3440256118774414
Batch 30/64 loss: 0.34290337562561035
Batch 31/64 loss: 0.34244048595428467
Batch 32/64 loss: 0.3442758321762085
Batch 33/64 loss: 0.33768147230148315
Batch 34/64 loss: 0.34116190671920776
Batch 35/64 loss: 0.34840285778045654
Batch 36/64 loss: 0.34355413913726807
Batch 37/64 loss: 0.3435574769973755
Batch 38/64 loss: 0.3443315625190735
Batch 39/64 loss: 0.34204578399658203
Batch 40/64 loss: 0.3440321683883667
Batch 41/64 loss: 0.34822988510131836
Batch 42/64 loss: 0.34434711933135986
Batch 43/64 loss: 0.3502269387245178
Batch 44/64 loss: 0.3482404947280884
Batch 45/64 loss: 0.3467061519622803
Batch 46/64 loss: 0.34096771478652954
Batch 47/64 loss: 0.3416860103607178
Batch 48/64 loss: 0.34421980381011963
Batch 49/64 loss: 0.34536319971084595
Batch 50/64 loss: 0.34452348947525024
Batch 51/64 loss: 0.34509778022766113
Batch 52/64 loss: 0.34165865182876587
Batch 53/64 loss: 0.3418799638748169
Batch 54/64 loss: 0.3423110246658325
Batch 55/64 loss: 0.3451201319694519
Batch 56/64 loss: 0.33879518508911133
Batch 57/64 loss: 0.3443450927734375
Batch 58/64 loss: 0.3493614196777344
Batch 59/64 loss: 0.33889293670654297
Batch 60/64 loss: 0.34483325481414795
Batch 61/64 loss: 0.3461979031562805
Batch 62/64 loss: 0.3404114842414856
Batch 63/64 loss: 0.3448326587677002
Batch 64/64 loss: 0.34403932094573975
Epoch 34  Train loss: 0.34412564530092127  Val loss: 0.3474034718221815
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: 0.3413112163543701
Batch 2/64 loss: 0.3390316367149353
Batch 3/64 loss: 0.3433152437210083
Batch 4/64 loss: 0.3455425500869751
Batch 5/64 loss: 0.33833616971969604
Batch 6/64 loss: 0.34623706340789795
Batch 7/64 loss: 0.34335291385650635
Batch 8/64 loss: 0.34340786933898926
Batch 9/64 loss: 0.3430774211883545
Batch 10/64 loss: 0.340678334236145
Batch 11/64 loss: 0.33977627754211426
Batch 12/64 loss: 0.3492633104324341
Batch 13/64 loss: 0.3439033627510071
Batch 14/64 loss: 0.34288299083709717
Batch 15/64 loss: 0.3402479887008667
Batch 16/64 loss: 0.34142041206359863
Batch 17/64 loss: 0.3474283218383789
Batch 18/64 loss: 0.3446974754333496
Batch 19/64 loss: 0.349365234375
Batch 20/64 loss: 0.3430187702178955
Batch 21/64 loss: 0.3456772565841675
Batch 22/64 loss: 0.3434538245201111
Batch 23/64 loss: 0.34640824794769287
Batch 24/64 loss: 0.34403014183044434
Batch 25/64 loss: 0.3493943214416504
Batch 26/64 loss: 0.3483744263648987
Batch 27/64 loss: 0.34819936752319336
Batch 28/64 loss: 0.3450382351875305
Batch 29/64 loss: 0.33829134702682495
Batch 30/64 loss: 0.3461416959762573
Batch 31/64 loss: 0.3434591293334961
Batch 32/64 loss: 0.34590816497802734
Batch 33/64 loss: 0.3415478467941284
Batch 34/64 loss: 0.34228456020355225
Batch 35/64 loss: 0.34884244203567505
Batch 36/64 loss: 0.34328365325927734
Batch 37/64 loss: 0.34687310457229614
Batch 38/64 loss: 0.34450268745422363
Batch 39/64 loss: 0.3455171585083008
Batch 40/64 loss: 0.34675097465515137
Batch 41/64 loss: 0.34226930141448975
Batch 42/64 loss: 0.34285473823547363
Batch 43/64 loss: 0.3402262330055237
Batch 44/64 loss: 0.3426405191421509
Batch 45/64 loss: 0.3429144024848938
Batch 46/64 loss: 0.34282082319259644
Batch 47/64 loss: 0.34601712226867676
Batch 48/64 loss: 0.3413987159729004
Batch 49/64 loss: 0.34403300285339355
Batch 50/64 loss: 0.34524619579315186
Batch 51/64 loss: 0.33988797664642334
Batch 52/64 loss: 0.34184783697128296
Batch 53/64 loss: 0.34287530183792114
Batch 54/64 loss: 0.33819442987442017
Batch 55/64 loss: 0.34456026554107666
Batch 56/64 loss: 0.3425661325454712
Batch 57/64 loss: 0.3431888222694397
Batch 58/64 loss: 0.3418048620223999
Batch 59/64 loss: 0.33957183361053467
Batch 60/64 loss: 0.34445881843566895
Batch 61/64 loss: 0.3455374836921692
Batch 62/64 loss: 0.34191012382507324
Batch 63/64 loss: 0.34439122676849365
Batch 64/64 loss: 0.3355921506881714
Epoch 35  Train loss: 0.3435793479283651  Val loss: 0.34683250971266494
Saving best model, epoch: 35
Epoch 36
-------------------------------
Batch 1/64 loss: 0.33869099617004395
Batch 2/64 loss: 0.3411141633987427
Batch 3/64 loss: 0.34329962730407715
Batch 4/64 loss: 0.3407730460166931
Batch 5/64 loss: 0.345325767993927
Batch 6/64 loss: 0.34319496154785156
Batch 7/64 loss: 0.34329652786254883
Batch 8/64 loss: 0.34022074937820435
Batch 9/64 loss: 0.3413546085357666
Batch 10/64 loss: 0.3373948931694031
Batch 11/64 loss: 0.34353888034820557
Batch 12/64 loss: 0.34747451543807983
Batch 13/64 loss: 0.34761130809783936
Batch 14/64 loss: 0.34449148178100586
Batch 15/64 loss: 0.3421940803527832
Batch 16/64 loss: 0.34043562412261963
Batch 17/64 loss: 0.3415498733520508
Batch 18/64 loss: 0.34369659423828125
Batch 19/64 loss: 0.342685341835022
Batch 20/64 loss: 0.3435549736022949
Batch 21/64 loss: 0.3469451665878296
Batch 22/64 loss: 0.34424418210983276
Batch 23/64 loss: 0.3441101312637329
Batch 24/64 loss: 0.342549204826355
Batch 25/64 loss: 0.3452855348587036
Batch 26/64 loss: 0.3427279591560364
Batch 27/64 loss: 0.34684956073760986
Batch 28/64 loss: 0.34240710735321045
Batch 29/64 loss: 0.34421998262405396
Batch 30/64 loss: 0.3438286781311035
Batch 31/64 loss: 0.34805959463119507
Batch 32/64 loss: 0.34182238578796387
Batch 33/64 loss: 0.3458453416824341
Batch 34/64 loss: 0.34379708766937256
Batch 35/64 loss: 0.3435937166213989
Batch 36/64 loss: 0.3462820053100586
Batch 37/64 loss: 0.3434638977050781
Batch 38/64 loss: 0.34462839365005493
Batch 39/64 loss: 0.3486992120742798
Batch 40/64 loss: 0.3469257354736328
Batch 41/64 loss: 0.34265315532684326
Batch 42/64 loss: 0.3438597321510315
Batch 43/64 loss: 0.34955185651779175
Batch 44/64 loss: 0.342690110206604
Batch 45/64 loss: 0.3421720266342163
Batch 46/64 loss: 0.3473280072212219
Batch 47/64 loss: 0.3446473479270935
Batch 48/64 loss: 0.3422856330871582
Batch 49/64 loss: 0.3384830951690674
Batch 50/64 loss: 0.3429785370826721
Batch 51/64 loss: 0.34366726875305176
Batch 52/64 loss: 0.34742480516433716
Batch 53/64 loss: 0.34162062406539917
Batch 54/64 loss: 0.3410235643386841
Batch 55/64 loss: 0.34441614151000977
Batch 56/64 loss: 0.3404555320739746
Batch 57/64 loss: 0.33831262588500977
Batch 58/64 loss: 0.342390775680542
Batch 59/64 loss: 0.34151631593704224
Batch 60/64 loss: 0.33947575092315674
Batch 61/64 loss: 0.34198248386383057
Batch 62/64 loss: 0.3399742841720581
Batch 63/64 loss: 0.34187960624694824
Batch 64/64 loss: 0.3431153893470764
Epoch 36  Train loss: 0.34331464650584204  Val loss: 0.3462981489515796
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 0.3433181643486023
Batch 2/64 loss: 0.33935749530792236
Batch 3/64 loss: 0.3404478430747986
Batch 4/64 loss: 0.34321874380111694
Batch 5/64 loss: 0.3457024097442627
Batch 6/64 loss: 0.34107351303100586
Batch 7/64 loss: 0.33982670307159424
Batch 8/64 loss: 0.3411417007446289
Batch 9/64 loss: 0.34145891666412354
Batch 10/64 loss: 0.3422192335128784
Batch 11/64 loss: 0.34223878383636475
Batch 12/64 loss: 0.3505859375
Batch 13/64 loss: 0.3403674364089966
Batch 14/64 loss: 0.33886587619781494
Batch 15/64 loss: 0.33996546268463135
Batch 16/64 loss: 0.3460170030593872
Batch 17/64 loss: 0.3406585454940796
Batch 18/64 loss: 0.3467633128166199
Batch 19/64 loss: 0.3394731879234314
Batch 20/64 loss: 0.34033751487731934
Batch 21/64 loss: 0.34582608938217163
Batch 22/64 loss: 0.34365594387054443
Batch 23/64 loss: 0.34626710414886475
Batch 24/64 loss: 0.3417220115661621
Batch 25/64 loss: 0.34233301877975464
Batch 26/64 loss: 0.34266382455825806
Batch 27/64 loss: 0.34444278478622437
Batch 28/64 loss: 0.34601688385009766
Batch 29/64 loss: 0.34213173389434814
Batch 30/64 loss: 0.34587740898132324
Batch 31/64 loss: 0.3476865291595459
Batch 32/64 loss: 0.3382827639579773
Batch 33/64 loss: 0.34670376777648926
Batch 34/64 loss: 0.34463000297546387
Batch 35/64 loss: 0.3400232791900635
Batch 36/64 loss: 0.3418845534324646
Batch 37/64 loss: 0.34335947036743164
Batch 38/64 loss: 0.3407166004180908
Batch 39/64 loss: 0.34617167711257935
Batch 40/64 loss: 0.34438639879226685
Batch 41/64 loss: 0.3400822877883911
Batch 42/64 loss: 0.3426731824874878
Batch 43/64 loss: 0.34441304206848145
Batch 44/64 loss: 0.34280651807785034
Batch 45/64 loss: 0.34215641021728516
Batch 46/64 loss: 0.3392164707183838
Batch 47/64 loss: 0.3442285656929016
Batch 48/64 loss: 0.34292882680892944
Batch 49/64 loss: 0.3490966558456421
Batch 50/64 loss: 0.3430764675140381
Batch 51/64 loss: 0.33854520320892334
Batch 52/64 loss: 0.3420788049697876
Batch 53/64 loss: 0.34315401315689087
Batch 54/64 loss: 0.34288567304611206
Batch 55/64 loss: 0.34451109170913696
Batch 56/64 loss: 0.3531389832496643
Batch 57/64 loss: 0.3415982127189636
Batch 58/64 loss: 0.34798377752304077
Batch 59/64 loss: 0.34343743324279785
Batch 60/64 loss: 0.3428003191947937
Batch 61/64 loss: 0.34600114822387695
Batch 62/64 loss: 0.3436216115951538
Batch 63/64 loss: 0.3425391912460327
Batch 64/64 loss: 0.3409213423728943
Epoch 37  Train loss: 0.34316054161857157  Val loss: 0.34596511055923407
Saving best model, epoch: 37
Epoch 38
-------------------------------
Batch 1/64 loss: 0.3426012396812439
Batch 2/64 loss: 0.3428691625595093
Batch 3/64 loss: 0.3403768539428711
Batch 4/64 loss: 0.341715931892395
Batch 5/64 loss: 0.3404492139816284
Batch 6/64 loss: 0.34168338775634766
Batch 7/64 loss: 0.34569036960601807
Batch 8/64 loss: 0.3448285460472107
Batch 9/64 loss: 0.34119200706481934
Batch 10/64 loss: 0.3427281975746155
Batch 11/64 loss: 0.3377843499183655
Batch 12/64 loss: 0.34883999824523926
Batch 13/64 loss: 0.3425464630126953
Batch 14/64 loss: 0.3418196439743042
Batch 15/64 loss: 0.3436011075973511
Batch 16/64 loss: 0.34064364433288574
Batch 17/64 loss: 0.34286999702453613
Batch 18/64 loss: 0.34525758028030396
Batch 19/64 loss: 0.3430672883987427
Batch 20/64 loss: 0.3426933288574219
Batch 21/64 loss: 0.3473659157752991
Batch 22/64 loss: 0.3433946967124939
Batch 23/64 loss: 0.3410145044326782
Batch 24/64 loss: 0.33858048915863037
Batch 25/64 loss: 0.3401995897293091
Batch 26/64 loss: 0.34164905548095703
Batch 27/64 loss: 0.3434840440750122
Batch 28/64 loss: 0.3379128575325012
Batch 29/64 loss: 0.3406983017921448
Batch 30/64 loss: 0.34055376052856445
Batch 31/64 loss: 0.3486744165420532
Batch 32/64 loss: 0.3429609537124634
Batch 33/64 loss: 0.339011549949646
Batch 34/64 loss: 0.34182924032211304
Batch 35/64 loss: 0.34043657779693604
Batch 36/64 loss: 0.3419804573059082
Batch 37/64 loss: 0.34067845344543457
Batch 38/64 loss: 0.3424249291419983
Batch 39/64 loss: 0.34416478872299194
Batch 40/64 loss: 0.3430161476135254
Batch 41/64 loss: 0.3425564169883728
Batch 42/64 loss: 0.33854174613952637
Batch 43/64 loss: 0.3436880111694336
Batch 44/64 loss: 0.34427332878112793
Batch 45/64 loss: 0.34160757064819336
Batch 46/64 loss: 0.34508228302001953
Batch 47/64 loss: 0.3414410352706909
Batch 48/64 loss: 0.3420279622077942
Batch 49/64 loss: 0.3423405885696411
Batch 50/64 loss: 0.33898937702178955
Batch 51/64 loss: 0.34225332736968994
Batch 52/64 loss: 0.344879150390625
Batch 53/64 loss: 0.3418205976486206
Batch 54/64 loss: 0.3411526679992676
Batch 55/64 loss: 0.34324026107788086
Batch 56/64 loss: 0.3437410593032837
Batch 57/64 loss: 0.3410770893096924
Batch 58/64 loss: 0.3438091278076172
Batch 59/64 loss: 0.34565138816833496
Batch 60/64 loss: 0.34249377250671387
Batch 61/64 loss: 0.34471428394317627
Batch 62/64 loss: 0.34498751163482666
Batch 63/64 loss: 0.3351083993911743
Batch 64/64 loss: 0.3398692011833191
Epoch 38  Train loss: 0.342332045470967  Val loss: 0.3462004327692117
Epoch 39
-------------------------------
Batch 1/64 loss: 0.3435436487197876
Batch 2/64 loss: 0.34091854095458984
Batch 3/64 loss: 0.3415724039077759
Batch 4/64 loss: 0.34473323822021484
Batch 5/64 loss: 0.3408365249633789
Batch 6/64 loss: 0.34287846088409424
Batch 7/64 loss: 0.3407368063926697
Batch 8/64 loss: 0.3434699773788452
Batch 9/64 loss: 0.3420764207839966
Batch 10/64 loss: 0.34178054332733154
Batch 11/64 loss: 0.3413912057876587
Batch 12/64 loss: 0.3491777181625366
Batch 13/64 loss: 0.3448346257209778
Batch 14/64 loss: 0.3447924852371216
Batch 15/64 loss: 0.3428465723991394
Batch 16/64 loss: 0.3399864435195923
Batch 17/64 loss: 0.34144097566604614
Batch 18/64 loss: 0.34214526414871216
Batch 19/64 loss: 0.34673070907592773
Batch 20/64 loss: 0.34752321243286133
Batch 21/64 loss: 0.3402266502380371
Batch 22/64 loss: 0.3388819694519043
Batch 23/64 loss: 0.338530957698822
Batch 24/64 loss: 0.343511700630188
Batch 25/64 loss: 0.3434072732925415
Batch 26/64 loss: 0.3428548574447632
Batch 27/64 loss: 0.34483879804611206
Batch 28/64 loss: 0.3416197896003723
Batch 29/64 loss: 0.3457714915275574
Batch 30/64 loss: 0.3417525291442871
Batch 31/64 loss: 0.34772294759750366
Batch 32/64 loss: 0.3407776951789856
Batch 33/64 loss: 0.3417379856109619
Batch 34/64 loss: 0.34481966495513916
Batch 35/64 loss: 0.34499555826187134
Batch 36/64 loss: 0.3447827100753784
Batch 37/64 loss: 0.3402249813079834
Batch 38/64 loss: 0.3434444069862366
Batch 39/64 loss: 0.34440356492996216
Batch 40/64 loss: 0.3414578437805176
Batch 41/64 loss: 0.3405906558036804
Batch 42/64 loss: 0.3430013656616211
Batch 43/64 loss: 0.346235990524292
Batch 44/64 loss: 0.3401215076446533
Batch 45/64 loss: 0.34774112701416016
Batch 46/64 loss: 0.3384212255477905
Batch 47/64 loss: 0.33689630031585693
Batch 48/64 loss: 0.3445611596107483
Batch 49/64 loss: 0.3454212546348572
Batch 50/64 loss: 0.3417353630065918
Batch 51/64 loss: 0.34752923250198364
Batch 52/64 loss: 0.3453871011734009
Batch 53/64 loss: 0.34503108263015747
Batch 54/64 loss: 0.34119439125061035
Batch 55/64 loss: 0.3382919430732727
Batch 56/64 loss: 0.34306371212005615
Batch 57/64 loss: 0.33584535121917725
Batch 58/64 loss: 0.3445383310317993
Batch 59/64 loss: 0.34144967794418335
Batch 60/64 loss: 0.3422775864601135
Batch 61/64 loss: 0.3421905040740967
Batch 62/64 loss: 0.34184467792510986
Batch 63/64 loss: 0.34372758865356445
Batch 64/64 loss: 0.3401336669921875
Epoch 39  Train loss: 0.34276669072169885  Val loss: 0.34607011981026825
Epoch 40
-------------------------------
Batch 1/64 loss: 0.3438771963119507
Batch 2/64 loss: 0.3398611545562744
Batch 3/64 loss: 0.3416365385055542
Batch 4/64 loss: 0.3441065549850464
Batch 5/64 loss: 0.3376631736755371
Batch 6/64 loss: 0.34121787548065186
Batch 7/64 loss: 0.3400832414627075
Batch 8/64 loss: 0.34131765365600586
Batch 9/64 loss: 0.34338295459747314
Batch 10/64 loss: 0.34348344802856445
Batch 11/64 loss: 0.3419864773750305
Batch 12/64 loss: 0.34322357177734375
Batch 13/64 loss: 0.3423413634300232
Batch 14/64 loss: 0.33893537521362305
Batch 15/64 loss: 0.34418153762817383
Batch 16/64 loss: 0.33932971954345703
Batch 17/64 loss: 0.3415732979774475
Batch 18/64 loss: 0.33833467960357666
Batch 19/64 loss: 0.3421192169189453
Batch 20/64 loss: 0.3430713415145874
Batch 21/64 loss: 0.3412611484527588
Batch 22/64 loss: 0.34483838081359863
Batch 23/64 loss: 0.3442509174346924
Batch 24/64 loss: 0.34335941076278687
Batch 25/64 loss: 0.3424581289291382
Batch 26/64 loss: 0.3403865694999695
Batch 27/64 loss: 0.3406779170036316
Batch 28/64 loss: 0.3397749662399292
Batch 29/64 loss: 0.34002310037612915
Batch 30/64 loss: 0.34060394763946533
Batch 31/64 loss: 0.3400113582611084
Batch 32/64 loss: 0.3388690948486328
Batch 33/64 loss: 0.3433109521865845
Batch 34/64 loss: 0.33995020389556885
Batch 35/64 loss: 0.34276700019836426
Batch 36/64 loss: 0.3449544906616211
Batch 37/64 loss: 0.34036529064178467
Batch 38/64 loss: 0.3379814624786377
Batch 39/64 loss: 0.34373927116394043
Batch 40/64 loss: 0.34042632579803467
Batch 41/64 loss: 0.3392115831375122
Batch 42/64 loss: 0.34104979038238525
Batch 43/64 loss: 0.3426862359046936
Batch 44/64 loss: 0.3440927267074585
Batch 45/64 loss: 0.34325265884399414
Batch 46/64 loss: 0.3476259708404541
Batch 47/64 loss: 0.3397238254547119
Batch 48/64 loss: 0.3417873978614807
Batch 49/64 loss: 0.3399827480316162
Batch 50/64 loss: 0.34840285778045654
Batch 51/64 loss: 0.33631789684295654
Batch 52/64 loss: 0.3435816764831543
Batch 53/64 loss: 0.33957892656326294
Batch 54/64 loss: 0.33751392364501953
Batch 55/64 loss: 0.35200560092926025
Batch 56/64 loss: 0.3481607437133789
Batch 57/64 loss: 0.3430967330932617
Batch 58/64 loss: 0.3378080129623413
Batch 59/64 loss: 0.3395996689796448
Batch 60/64 loss: 0.3398832082748413
Batch 61/64 loss: 0.3457920551300049
Batch 62/64 loss: 0.3370358943939209
Batch 63/64 loss: 0.3470558524131775
Batch 64/64 loss: 0.3507629632949829
Epoch 40  Train loss: 0.3419616395351934  Val loss: 0.34574150547538834
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: 0.3430168628692627
Batch 2/64 loss: 0.3438522219657898
Batch 3/64 loss: 0.33999937772750854
Batch 4/64 loss: 0.3406333923339844
Batch 5/64 loss: 0.3419872522354126
Batch 6/64 loss: 0.33734190464019775
Batch 7/64 loss: 0.33952653408050537
Batch 8/64 loss: 0.33577418327331543
Batch 9/64 loss: 0.3433712124824524
Batch 10/64 loss: 0.34193527698516846
Batch 11/64 loss: 0.3386467695236206
Batch 12/64 loss: 0.34462910890579224
Batch 13/64 loss: 0.34807848930358887
Batch 14/64 loss: 0.33933693170547485
Batch 15/64 loss: 0.34197115898132324
Batch 16/64 loss: 0.3483704924583435
Batch 17/64 loss: 0.34005939960479736
Batch 18/64 loss: 0.349346399307251
Batch 19/64 loss: 0.3414418697357178
Batch 20/64 loss: 0.3415619134902954
Batch 21/64 loss: 0.34159719944000244
Batch 22/64 loss: 0.3406810760498047
Batch 23/64 loss: 0.34522414207458496
Batch 24/64 loss: 0.34209299087524414
Batch 25/64 loss: 0.3375587463378906
Batch 26/64 loss: 0.34452688694000244
Batch 27/64 loss: 0.3423858880996704
Batch 28/64 loss: 0.34029173851013184
Batch 29/64 loss: 0.3413916230201721
Batch 30/64 loss: 0.3391013741493225
Batch 31/64 loss: 0.34456539154052734
Batch 32/64 loss: 0.34317463636398315
Batch 33/64 loss: 0.3398720622062683
Batch 34/64 loss: 0.34334051609039307
Batch 35/64 loss: 0.34262484312057495
Batch 36/64 loss: 0.3465585708618164
Batch 37/64 loss: 0.338138222694397
Batch 38/64 loss: 0.3474581241607666
Batch 39/64 loss: 0.3395899534225464
Batch 40/64 loss: 0.3385820984840393
Batch 41/64 loss: 0.3386852741241455
Batch 42/64 loss: 0.3411603569984436
Batch 43/64 loss: 0.341033399105072
Batch 44/64 loss: 0.3382720947265625
Batch 45/64 loss: 0.34234511852264404
Batch 46/64 loss: 0.34304606914520264
Batch 47/64 loss: 0.3427189588546753
Batch 48/64 loss: 0.3445422649383545
Batch 49/64 loss: 0.3427050709724426
Batch 50/64 loss: 0.343397319316864
Batch 51/64 loss: 0.34162408113479614
Batch 52/64 loss: 0.34548866748809814
Batch 53/64 loss: 0.34364163875579834
Batch 54/64 loss: 0.3376408815383911
Batch 55/64 loss: 0.34400200843811035
Batch 56/64 loss: 0.339335560798645
Batch 57/64 loss: 0.3410160541534424
Batch 58/64 loss: 0.33839350938796997
Batch 59/64 loss: 0.336872935295105
Batch 60/64 loss: 0.3409702777862549
Batch 61/64 loss: 0.34453773498535156
Batch 62/64 loss: 0.3450225591659546
Batch 63/64 loss: 0.34014856815338135
Batch 64/64 loss: 0.33886289596557617
Epoch 41  Train loss: 0.3418099515578326  Val loss: 0.34663321943217534
Epoch 42
-------------------------------
Batch 1/64 loss: 0.3450191020965576
Batch 2/64 loss: 0.3356579542160034
Batch 3/64 loss: 0.3396787643432617
Batch 4/64 loss: 0.3404524326324463
Batch 5/64 loss: 0.3425236940383911
Batch 6/64 loss: 0.34405839443206787
Batch 7/64 loss: 0.3436664342880249
Batch 8/64 loss: 0.3414521813392639
Batch 9/64 loss: 0.34196555614471436
Batch 10/64 loss: 0.3443673253059387
Batch 11/64 loss: 0.33980220556259155
Batch 12/64 loss: 0.34098464250564575
Batch 13/64 loss: 0.3441157341003418
Batch 14/64 loss: 0.3401303291320801
Batch 15/64 loss: 0.34055477380752563
Batch 16/64 loss: 0.340798020362854
Batch 17/64 loss: 0.3397867679595947
Batch 18/64 loss: 0.34007537364959717
Batch 19/64 loss: 0.3447967767715454
Batch 20/64 loss: 0.33905160427093506
Batch 21/64 loss: 0.3380749821662903
Batch 22/64 loss: 0.3373669385910034
Batch 23/64 loss: 0.342545747756958
Batch 24/64 loss: 0.34275007247924805
Batch 25/64 loss: 0.3442385196685791
Batch 26/64 loss: 0.3445127010345459
Batch 27/64 loss: 0.3374790549278259
Batch 28/64 loss: 0.34026026725769043
Batch 29/64 loss: 0.33800262212753296
Batch 30/64 loss: 0.3388836979866028
Batch 31/64 loss: 0.3521265387535095
Batch 32/64 loss: 0.34039413928985596
Batch 33/64 loss: 0.338309645652771
Batch 34/64 loss: 0.3443870544433594
Batch 35/64 loss: 0.34412670135498047
Batch 36/64 loss: 0.33421993255615234
Batch 37/64 loss: 0.33834099769592285
Batch 38/64 loss: 0.34122705459594727
Batch 39/64 loss: 0.33853644132614136
Batch 40/64 loss: 0.3392038345336914
Batch 41/64 loss: 0.3400030732154846
Batch 42/64 loss: 0.3398284912109375
Batch 43/64 loss: 0.34603047370910645
Batch 44/64 loss: 0.34581804275512695
Batch 45/64 loss: 0.3420978784561157
Batch 46/64 loss: 0.3386368751525879
Batch 47/64 loss: 0.34550368785858154
Batch 48/64 loss: 0.33835357427597046
Batch 49/64 loss: 0.33937668800354004
Batch 50/64 loss: 0.34168195724487305
Batch 51/64 loss: 0.3388328552246094
Batch 52/64 loss: 0.34090864658355713
Batch 53/64 loss: 0.3394887447357178
Batch 54/64 loss: 0.33985471725463867
Batch 55/64 loss: 0.3392937183380127
Batch 56/64 loss: 0.34123867750167847
Batch 57/64 loss: 0.337673544883728
Batch 58/64 loss: 0.34086155891418457
Batch 59/64 loss: 0.33889949321746826
Batch 60/64 loss: 0.3415731191635132
Batch 61/64 loss: 0.3416999578475952
Batch 62/64 loss: 0.34196364879608154
Batch 63/64 loss: 0.33876925706863403
Batch 64/64 loss: 0.3406516909599304
Epoch 42  Train loss: 0.34098513663983815  Val loss: 0.34501491789145977
Saving best model, epoch: 42
Epoch 43
-------------------------------
Batch 1/64 loss: 0.3409475088119507
Batch 2/64 loss: 0.3381173610687256
Batch 3/64 loss: 0.3427616357803345
Batch 4/64 loss: 0.3463785648345947
Batch 5/64 loss: 0.3408496379852295
Batch 6/64 loss: 0.3365476727485657
Batch 7/64 loss: 0.34282803535461426
Batch 8/64 loss: 0.33835726976394653
Batch 9/64 loss: 0.3404421806335449
Batch 10/64 loss: 0.33801335096359253
Batch 11/64 loss: 0.34084880352020264
Batch 12/64 loss: 0.3450852036476135
Batch 13/64 loss: 0.3399540185928345
Batch 14/64 loss: 0.34095776081085205
Batch 15/64 loss: 0.33809220790863037
Batch 16/64 loss: 0.340221643447876
Batch 17/64 loss: 0.3437366485595703
Batch 18/64 loss: 0.3334738612174988
Batch 19/64 loss: 0.3390730023384094
Batch 20/64 loss: 0.3327960968017578
Batch 21/64 loss: 0.3344457149505615
Batch 22/64 loss: 0.34137189388275146
Batch 23/64 loss: 0.3399627208709717
Batch 24/64 loss: 0.3370360732078552
Batch 25/64 loss: 0.34115350246429443
Batch 26/64 loss: 0.34131771326065063
Batch 27/64 loss: 0.3390963673591614
Batch 28/64 loss: 0.3370943069458008
Batch 29/64 loss: 0.3432324528694153
Batch 30/64 loss: 0.3456491231918335
Batch 31/64 loss: 0.33911335468292236
Batch 32/64 loss: 0.3375912308692932
Batch 33/64 loss: 0.34535038471221924
Batch 34/64 loss: 0.34423959255218506
Batch 35/64 loss: 0.3448437452316284
Batch 36/64 loss: 0.3362077474594116
Batch 37/64 loss: 0.34209591150283813
Batch 38/64 loss: 0.33923768997192383
Batch 39/64 loss: 0.33972710371017456
Batch 40/64 loss: 0.3397427797317505
Batch 41/64 loss: 0.3425229787826538
Batch 42/64 loss: 0.3412668704986572
Batch 43/64 loss: 0.33916735649108887
Batch 44/64 loss: 0.3343965411186218
Batch 45/64 loss: 0.34396952390670776
Batch 46/64 loss: 0.3446536064147949
Batch 47/64 loss: 0.3367488384246826
Batch 48/64 loss: 0.3387943506240845
Batch 49/64 loss: 0.33672213554382324
Batch 50/64 loss: 0.340426504611969
Batch 51/64 loss: 0.33973968029022217
Batch 52/64 loss: 0.33943504095077515
Batch 53/64 loss: 0.34411609172821045
Batch 54/64 loss: 0.3427419066429138
Batch 55/64 loss: 0.33860301971435547
Batch 56/64 loss: 0.34480518102645874
Batch 57/64 loss: 0.34251105785369873
Batch 58/64 loss: 0.3425943851470947
Batch 59/64 loss: 0.33682191371917725
Batch 60/64 loss: 0.33885180950164795
Batch 61/64 loss: 0.337902307510376
Batch 62/64 loss: 0.3423042297363281
Batch 63/64 loss: 0.3413301110267639
Batch 64/64 loss: 0.340898334980011
Epoch 43  Train loss: 0.3402994677132251  Val loss: 0.3450280956386291
Epoch 44
-------------------------------
Batch 1/64 loss: 0.3432963490486145
Batch 2/64 loss: 0.3429991602897644
Batch 3/64 loss: 0.33999377489089966
Batch 4/64 loss: 0.3359513282775879
Batch 5/64 loss: 0.3406945466995239
Batch 6/64 loss: 0.33796805143356323
Batch 7/64 loss: 0.34377843141555786
Batch 8/64 loss: 0.3408876657485962
Batch 9/64 loss: 0.33339643478393555
Batch 10/64 loss: 0.3340487480163574
Batch 11/64 loss: 0.33387231826782227
Batch 12/64 loss: 0.34289658069610596
Batch 13/64 loss: 0.3387921452522278
Batch 14/64 loss: 0.34020674228668213
Batch 15/64 loss: 0.33850520849227905
Batch 16/64 loss: 0.34315383434295654
Batch 17/64 loss: 0.34275150299072266
Batch 18/64 loss: 0.33843231201171875
Batch 19/64 loss: 0.34132909774780273
Batch 20/64 loss: 0.3355097770690918
Batch 21/64 loss: 0.33840036392211914
Batch 22/64 loss: 0.33880627155303955
Batch 23/64 loss: 0.33764803409576416
Batch 24/64 loss: 0.34264445304870605
Batch 25/64 loss: 0.34135860204696655
Batch 26/64 loss: 0.3412964344024658
Batch 27/64 loss: 0.3343784213066101
Batch 28/64 loss: 0.3388251066207886
Batch 29/64 loss: 0.34106147289276123
Batch 30/64 loss: 0.33997029066085815
Batch 31/64 loss: 0.3372037410736084
Batch 32/64 loss: 0.3394988775253296
Batch 33/64 loss: 0.34215956926345825
Batch 34/64 loss: 0.33711522817611694
Batch 35/64 loss: 0.3381093740463257
Batch 36/64 loss: 0.3372049927711487
Batch 37/64 loss: 0.34060025215148926
Batch 38/64 loss: 0.34552788734436035
Batch 39/64 loss: 0.3384212255477905
Batch 40/64 loss: 0.341280460357666
Batch 41/64 loss: 0.3389852046966553
Batch 42/64 loss: 0.34126341342926025
Batch 43/64 loss: 0.34076768159866333
Batch 44/64 loss: 0.33623337745666504
Batch 45/64 loss: 0.34237730503082275
Batch 46/64 loss: 0.3461378812789917
Batch 47/64 loss: 0.3371601104736328
Batch 48/64 loss: 0.34188294410705566
Batch 49/64 loss: 0.3450013995170593
Batch 50/64 loss: 0.3421363830566406
Batch 51/64 loss: 0.343176007270813
Batch 52/64 loss: 0.34924113750457764
Batch 53/64 loss: 0.3383495807647705
Batch 54/64 loss: 0.3409883379936218
Batch 55/64 loss: 0.3399217128753662
Batch 56/64 loss: 0.34227776527404785
Batch 57/64 loss: 0.3425363302230835
Batch 58/64 loss: 0.3414151668548584
Batch 59/64 loss: 0.3407740592956543
Batch 60/64 loss: 0.34349334239959717
Batch 61/64 loss: 0.3381326198577881
Batch 62/64 loss: 0.34259605407714844
Batch 63/64 loss: 0.3404557704925537
Batch 64/64 loss: 0.34204769134521484
Epoch 44  Train loss: 0.3402637556487439  Val loss: 0.34415087257463906
Saving best model, epoch: 44
Epoch 45
-------------------------------
Batch 1/64 loss: 0.3385499119758606
Batch 2/64 loss: 0.33904945850372314
Batch 3/64 loss: 0.3403647541999817
Batch 4/64 loss: 0.3387874364852905
Batch 5/64 loss: 0.3438683748245239
Batch 6/64 loss: 0.3410986661911011
Batch 7/64 loss: 0.3336479663848877
Batch 8/64 loss: 0.3374096155166626
Batch 9/64 loss: 0.33760929107666016
Batch 10/64 loss: 0.3389856219291687
Batch 11/64 loss: 0.33863669633865356
Batch 12/64 loss: 0.3380032181739807
Batch 13/64 loss: 0.3395456075668335
Batch 14/64 loss: 0.33853381872177124
Batch 15/64 loss: 0.3440970778465271
Batch 16/64 loss: 0.33881378173828125
Batch 17/64 loss: 0.34133899211883545
Batch 18/64 loss: 0.33979332447052
Batch 19/64 loss: 0.33767247200012207
Batch 20/64 loss: 0.33845680952072144
Batch 21/64 loss: 0.34133589267730713
Batch 22/64 loss: 0.3348811864852905
Batch 23/64 loss: 0.3423779010772705
Batch 24/64 loss: 0.3434237241744995
Batch 25/64 loss: 0.3466617465019226
Batch 26/64 loss: 0.34015578031539917
Batch 27/64 loss: 0.3391314744949341
Batch 28/64 loss: 0.3408740162849426
Batch 29/64 loss: 0.3412359952926636
Batch 30/64 loss: 0.34044283628463745
Batch 31/64 loss: 0.3377058506011963
Batch 32/64 loss: 0.3385888338088989
Batch 33/64 loss: 0.33500969409942627
Batch 34/64 loss: 0.338454008102417
Batch 35/64 loss: 0.33685314655303955
Batch 36/64 loss: 0.3446693420410156
Batch 37/64 loss: 0.3397384285926819
Batch 38/64 loss: 0.3451530337333679
Batch 39/64 loss: 0.337571382522583
Batch 40/64 loss: 0.34061741828918457
Batch 41/64 loss: 0.3361448049545288
Batch 42/64 loss: 0.3364828824996948
Batch 43/64 loss: 0.34348464012145996
Batch 44/64 loss: 0.3394768238067627
Batch 45/64 loss: 0.3382657766342163
Batch 46/64 loss: 0.3400087356567383
Batch 47/64 loss: 0.33949577808380127
Batch 48/64 loss: 0.3392757177352905
Batch 49/64 loss: 0.3387486934661865
Batch 50/64 loss: 0.34420841932296753
Batch 51/64 loss: 0.33606886863708496
Batch 52/64 loss: 0.3377654552459717
Batch 53/64 loss: 0.3413602113723755
Batch 54/64 loss: 0.33750760555267334
Batch 55/64 loss: 0.3379380702972412
Batch 56/64 loss: 0.3446328043937683
Batch 57/64 loss: 0.33856499195098877
Batch 58/64 loss: 0.34101998805999756
Batch 59/64 loss: 0.34447646141052246
Batch 60/64 loss: 0.34113019704818726
Batch 61/64 loss: 0.3382045030593872
Batch 62/64 loss: 0.33833783864974976
Batch 63/64 loss: 0.33563268184661865
Batch 64/64 loss: 0.3414134979248047
Epoch 45  Train loss: 0.3396617515414369  Val loss: 0.3436443639784744
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: 0.3323780298233032
Batch 2/64 loss: 0.33376312255859375
Batch 3/64 loss: 0.3381640315055847
Batch 4/64 loss: 0.3448410630226135
Batch 5/64 loss: 0.3454837203025818
Batch 6/64 loss: 0.3399583101272583
Batch 7/64 loss: 0.33972597122192383
Batch 8/64 loss: 0.339033842086792
Batch 9/64 loss: 0.3413013219833374
Batch 10/64 loss: 0.3394731879234314
Batch 11/64 loss: 0.33892470598220825
Batch 12/64 loss: 0.33857738971710205
Batch 13/64 loss: 0.3372093439102173
Batch 14/64 loss: 0.3403921127319336
Batch 15/64 loss: 0.33784162998199463
Batch 16/64 loss: 0.3368086814880371
Batch 17/64 loss: 0.34112513065338135
Batch 18/64 loss: 0.3403904438018799
Batch 19/64 loss: 0.33795613050460815
Batch 20/64 loss: 0.3367469310760498
Batch 21/64 loss: 0.33432871103286743
Batch 22/64 loss: 0.33946382999420166
Batch 23/64 loss: 0.34346044063568115
Batch 24/64 loss: 0.3378337025642395
Batch 25/64 loss: 0.345104455947876
Batch 26/64 loss: 0.3362351059913635
Batch 27/64 loss: 0.3377368450164795
Batch 28/64 loss: 0.3409336805343628
Batch 29/64 loss: 0.3410910367965698
Batch 30/64 loss: 0.33631253242492676
Batch 31/64 loss: 0.34134387969970703
Batch 32/64 loss: 0.34253519773483276
Batch 33/64 loss: 0.33600175380706787
Batch 34/64 loss: 0.3386377692222595
Batch 35/64 loss: 0.3371655344963074
Batch 36/64 loss: 0.33857262134552
Batch 37/64 loss: 0.3371264934539795
Batch 38/64 loss: 0.3413240909576416
Batch 39/64 loss: 0.33685702085494995
Batch 40/64 loss: 0.3356351852416992
Batch 41/64 loss: 0.3362311124801636
Batch 42/64 loss: 0.3412666320800781
Batch 43/64 loss: 0.34143394231796265
Batch 44/64 loss: 0.3345400094985962
Batch 45/64 loss: 0.34287917613983154
Batch 46/64 loss: 0.3430490493774414
Batch 47/64 loss: 0.3440169095993042
Batch 48/64 loss: 0.3440313935279846
Batch 49/64 loss: 0.3391910195350647
Batch 50/64 loss: 0.342576801776886
Batch 51/64 loss: 0.3430963158607483
Batch 52/64 loss: 0.3455870747566223
Batch 53/64 loss: 0.340215802192688
Batch 54/64 loss: 0.3429659605026245
Batch 55/64 loss: 0.34051865339279175
Batch 56/64 loss: 0.3393791913986206
Batch 57/64 loss: 0.342765748500824
Batch 58/64 loss: 0.33832991123199463
Batch 59/64 loss: 0.34093809127807617
Batch 60/64 loss: 0.3442060351371765
Batch 61/64 loss: 0.3419206738471985
Batch 62/64 loss: 0.3421715497970581
Batch 63/64 loss: 0.34123504161834717
Batch 64/64 loss: 0.341596782207489
Epoch 46  Train loss: 0.33986727326524024  Val loss: 0.34457472755327256
Epoch 47
-------------------------------
Batch 1/64 loss: 0.3379727602005005
Batch 2/64 loss: 0.3392210602760315
Batch 3/64 loss: 0.3413776755332947
Batch 4/64 loss: 0.33646929264068604
Batch 5/64 loss: 0.3360021114349365
Batch 6/64 loss: 0.3391437530517578
Batch 7/64 loss: 0.341744601726532
Batch 8/64 loss: 0.3392826318740845
Batch 9/64 loss: 0.3383136987686157
Batch 10/64 loss: 0.34445738792419434
Batch 11/64 loss: 0.34165310859680176
Batch 12/64 loss: 0.3391856551170349
Batch 13/64 loss: 0.33709490299224854
Batch 14/64 loss: 0.34247446060180664
Batch 15/64 loss: 0.33761274814605713
Batch 16/64 loss: 0.33748859167099
Batch 17/64 loss: 0.33880800008773804
Batch 18/64 loss: 0.33817267417907715
Batch 19/64 loss: 0.33835434913635254
Batch 20/64 loss: 0.3411940336227417
Batch 21/64 loss: 0.3445259928703308
Batch 22/64 loss: 0.3364219069480896
Batch 23/64 loss: 0.3382871150970459
Batch 24/64 loss: 0.33922338485717773
Batch 25/64 loss: 0.34225428104400635
Batch 26/64 loss: 0.33862006664276123
Batch 27/64 loss: 0.33939021825790405
Batch 28/64 loss: 0.3451838493347168
Batch 29/64 loss: 0.33912885189056396
Batch 30/64 loss: 0.34182727336883545
Batch 31/64 loss: 0.3435695171356201
Batch 32/64 loss: 0.3375231623649597
Batch 33/64 loss: 0.3424783945083618
Batch 34/64 loss: 0.33868932723999023
Batch 35/64 loss: 0.33985042572021484
Batch 36/64 loss: 0.33892762660980225
Batch 37/64 loss: 0.3380197286605835
Batch 38/64 loss: 0.33430516719818115
Batch 39/64 loss: 0.34193575382232666
Batch 40/64 loss: 0.33956849575042725
Batch 41/64 loss: 0.33937835693359375
Batch 42/64 loss: 0.3405458927154541
Batch 43/64 loss: 0.33721303939819336
Batch 44/64 loss: 0.33300071954727173
Batch 45/64 loss: 0.33985280990600586
Batch 46/64 loss: 0.34048283100128174
Batch 47/64 loss: 0.3382391333580017
Batch 48/64 loss: 0.3382577896118164
Batch 49/64 loss: 0.34213000535964966
Batch 50/64 loss: 0.3375454545021057
Batch 51/64 loss: 0.34151768684387207
Batch 52/64 loss: 0.33811354637145996
Batch 53/64 loss: 0.33618593215942383
Batch 54/64 loss: 0.34127700328826904
Batch 55/64 loss: 0.33753371238708496
Batch 56/64 loss: 0.3341250419616699
Batch 57/64 loss: 0.3395034074783325
Batch 58/64 loss: 0.339408278465271
Batch 59/64 loss: 0.3443504571914673
Batch 60/64 loss: 0.3388708829879761
Batch 61/64 loss: 0.34021908044815063
Batch 62/64 loss: 0.33973848819732666
Batch 63/64 loss: 0.3397136330604553
Batch 64/64 loss: 0.3389383554458618
Epoch 47  Train loss: 0.3394064468495986  Val loss: 0.34464285955396307
Epoch 48
-------------------------------
Batch 1/64 loss: 0.3384881019592285
Batch 2/64 loss: 0.3376850485801697
Batch 3/64 loss: 0.3368030786514282
Batch 4/64 loss: 0.3397132158279419
Batch 5/64 loss: 0.33849310874938965
Batch 6/64 loss: 0.3406940698623657
Batch 7/64 loss: 0.33708178997039795
Batch 8/64 loss: 0.3368811011314392
Batch 9/64 loss: 0.3412541151046753
Batch 10/64 loss: 0.3355165719985962
Batch 11/64 loss: 0.3361610174179077
Batch 12/64 loss: 0.3379424810409546
Batch 13/64 loss: 0.3373678922653198
Batch 14/64 loss: 0.34138405323028564
Batch 15/64 loss: 0.3415983319282532
Batch 16/64 loss: 0.33790987730026245
Batch 17/64 loss: 0.3423565626144409
Batch 18/64 loss: 0.3414773941040039
Batch 19/64 loss: 0.3433794379234314
Batch 20/64 loss: 0.33544063568115234
Batch 21/64 loss: 0.3382698893547058
Batch 22/64 loss: 0.3366197943687439
Batch 23/64 loss: 0.3392699360847473
Batch 24/64 loss: 0.34156399965286255
Batch 25/64 loss: 0.3348311185836792
Batch 26/64 loss: 0.34198230504989624
Batch 27/64 loss: 0.3357372283935547
Batch 28/64 loss: 0.3393898010253906
Batch 29/64 loss: 0.3366692066192627
Batch 30/64 loss: 0.3394755721092224
Batch 31/64 loss: 0.33761101961135864
Batch 32/64 loss: 0.33607184886932373
Batch 33/64 loss: 0.33781909942626953
Batch 34/64 loss: 0.34186530113220215
Batch 35/64 loss: 0.33617836236953735
Batch 36/64 loss: 0.3399547338485718
Batch 37/64 loss: 0.3406745195388794
Batch 38/64 loss: 0.3415776491165161
Batch 39/64 loss: 0.3393346071243286
Batch 40/64 loss: 0.3355276584625244
Batch 41/64 loss: 0.34020018577575684
Batch 42/64 loss: 0.3333284854888916
Batch 43/64 loss: 0.3424088954925537
Batch 44/64 loss: 0.3410378694534302
Batch 45/64 loss: 0.334380567073822
Batch 46/64 loss: 0.3325730562210083
Batch 47/64 loss: 0.3409883975982666
Batch 48/64 loss: 0.3363844156265259
Batch 49/64 loss: 0.33758729696273804
Batch 50/64 loss: 0.3371671438217163
Batch 51/64 loss: 0.3382897973060608
Batch 52/64 loss: 0.3413155674934387
Batch 53/64 loss: 0.340320348739624
Batch 54/64 loss: 0.33279502391815186
Batch 55/64 loss: 0.3471486568450928
Batch 56/64 loss: 0.335345983505249
Batch 57/64 loss: 0.34130728244781494
Batch 58/64 loss: 0.3370795249938965
Batch 59/64 loss: 0.3370860815048218
Batch 60/64 loss: 0.33695393800735474
Batch 61/64 loss: 0.33768802881240845
Batch 62/64 loss: 0.3419911861419678
Batch 63/64 loss: 0.33869147300720215
Batch 64/64 loss: 0.33622485399246216
Epoch 48  Train loss: 0.3385457158088684  Val loss: 0.3444023505109282
Epoch 49
-------------------------------
Batch 1/64 loss: 0.3386286497116089
Batch 2/64 loss: 0.3353238105773926
Batch 3/64 loss: 0.33494508266448975
Batch 4/64 loss: 0.33608561754226685
Batch 5/64 loss: 0.3366203308105469
Batch 6/64 loss: 0.33224189281463623
Batch 7/64 loss: 0.3420783281326294
Batch 8/64 loss: 0.337070107460022
Batch 9/64 loss: 0.34175896644592285
Batch 10/64 loss: 0.33744120597839355
Batch 11/64 loss: 0.3445708751678467
Batch 12/64 loss: 0.33870482444763184
Batch 13/64 loss: 0.3411121368408203
Batch 14/64 loss: 0.33503150939941406
Batch 15/64 loss: 0.3367328643798828
Batch 16/64 loss: 0.3391267657279968
Batch 17/64 loss: 0.33379656076431274
Batch 18/64 loss: 0.3391740918159485
Batch 19/64 loss: 0.33347368240356445
Batch 20/64 loss: 0.3367750644683838
Batch 21/64 loss: 0.3396780490875244
Batch 22/64 loss: 0.3418433666229248
Batch 23/64 loss: 0.3368719220161438
Batch 24/64 loss: 0.33760493993759155
Batch 25/64 loss: 0.3397059440612793
Batch 26/64 loss: 0.3353539705276489
Batch 27/64 loss: 0.3350589871406555
Batch 28/64 loss: 0.3355073928833008
Batch 29/64 loss: 0.33885639905929565
Batch 30/64 loss: 0.34109002351760864
Batch 31/64 loss: 0.34035706520080566
Batch 32/64 loss: 0.3348674774169922
Batch 33/64 loss: 0.33529555797576904
Batch 34/64 loss: 0.3392660617828369
Batch 35/64 loss: 0.3388022184371948
Batch 36/64 loss: 0.336955189704895
Batch 37/64 loss: 0.3410451412200928
Batch 38/64 loss: 0.3436499834060669
Batch 39/64 loss: 0.3375011086463928
Batch 40/64 loss: 0.34100377559661865
Batch 41/64 loss: 0.34109681844711304
Batch 42/64 loss: 0.33725011348724365
Batch 43/64 loss: 0.3388206958770752
Batch 44/64 loss: 0.34165942668914795
Batch 45/64 loss: 0.3414071798324585
Batch 46/64 loss: 0.33864825963974
Batch 47/64 loss: 0.3352351188659668
Batch 48/64 loss: 0.3363187313079834
Batch 49/64 loss: 0.3354865312576294
Batch 50/64 loss: 0.3372722864151001
Batch 51/64 loss: 0.34061551094055176
Batch 52/64 loss: 0.33849191665649414
Batch 53/64 loss: 0.3371897339820862
Batch 54/64 loss: 0.3409302830696106
Batch 55/64 loss: 0.3454056978225708
Batch 56/64 loss: 0.3376045823097229
Batch 57/64 loss: 0.3415724039077759
Batch 58/64 loss: 0.33542346954345703
Batch 59/64 loss: 0.3365519642829895
Batch 60/64 loss: 0.34465545415878296
Batch 61/64 loss: 0.33514147996902466
Batch 62/64 loss: 0.33873021602630615
Batch 63/64 loss: 0.3369019031524658
Batch 64/64 loss: 0.3410452604293823
Epoch 49  Train loss: 0.3383404025844499  Val loss: 0.34288881980266767
Saving best model, epoch: 49
Epoch 50
-------------------------------
Batch 1/64 loss: 0.33847576379776
Batch 2/64 loss: 0.3348320722579956
Batch 3/64 loss: 0.3368726968765259
Batch 4/64 loss: 0.3319648504257202
Batch 5/64 loss: 0.34416520595550537
Batch 6/64 loss: 0.34024733304977417
Batch 7/64 loss: 0.3384869694709778
Batch 8/64 loss: 0.33639222383499146
Batch 9/64 loss: 0.3348689079284668
Batch 10/64 loss: 0.33673787117004395
Batch 11/64 loss: 0.33744609355926514
Batch 12/64 loss: 0.3397769331932068
Batch 13/64 loss: 0.3391364812850952
Batch 14/64 loss: 0.34178972244262695
Batch 15/64 loss: 0.3412919044494629
Batch 16/64 loss: 0.34201449155807495
Batch 17/64 loss: 0.33977341651916504
Batch 18/64 loss: 0.3327254056930542
Batch 19/64 loss: 0.3423861265182495
Batch 20/64 loss: 0.34026122093200684
Batch 21/64 loss: 0.3315640091896057
Batch 22/64 loss: 0.33499741554260254
Batch 23/64 loss: 0.33716148138046265
Batch 24/64 loss: 0.33906495571136475
Batch 25/64 loss: 0.3380173444747925
Batch 26/64 loss: 0.3431280851364136
Batch 27/64 loss: 0.3404524326324463
Batch 28/64 loss: 0.33838796615600586
Batch 29/64 loss: 0.33874833583831787
Batch 30/64 loss: 0.34168046712875366
Batch 31/64 loss: 0.3429596424102783
Batch 32/64 loss: 0.3401603698730469
Batch 33/64 loss: 0.3377997875213623
Batch 34/64 loss: 0.33600914478302
Batch 35/64 loss: 0.33621203899383545
Batch 36/64 loss: 0.33940428495407104
Batch 37/64 loss: 0.33773159980773926
Batch 38/64 loss: 0.340427041053772
Batch 39/64 loss: 0.338981032371521
Batch 40/64 loss: 0.34092915058135986
Batch 41/64 loss: 0.33506298065185547
Batch 42/64 loss: 0.34027302265167236
Batch 43/64 loss: 0.3370457887649536
Batch 44/64 loss: 0.3371776342391968
Batch 45/64 loss: 0.3399008512496948
Batch 46/64 loss: 0.3390932083129883
Batch 47/64 loss: 0.34419071674346924
Batch 48/64 loss: 0.33828461170196533
Batch 49/64 loss: 0.33983683586120605
Batch 50/64 loss: 0.34560441970825195
Batch 51/64 loss: 0.3363766670227051
Batch 52/64 loss: 0.33894509077072144
Batch 53/64 loss: 0.3335566520690918
Batch 54/64 loss: 0.34222841262817383
Batch 55/64 loss: 0.3356856107711792
Batch 56/64 loss: 0.33422696590423584
Batch 57/64 loss: 0.34152209758758545
Batch 58/64 loss: 0.3375687003135681
Batch 59/64 loss: 0.33914750814437866
Batch 60/64 loss: 0.3372570872306824
Batch 61/64 loss: 0.33784258365631104
Batch 62/64 loss: 0.3348567485809326
Batch 63/64 loss: 0.3414044976234436
Batch 64/64 loss: 0.33803290128707886
Epoch 50  Train loss: 0.33857373560176174  Val loss: 0.34180785413460224
Saving best model, epoch: 50
Epoch 51
-------------------------------
Batch 1/64 loss: 0.33469194173812866
Batch 2/64 loss: 0.34153711795806885
Batch 3/64 loss: 0.3404979705810547
Batch 4/64 loss: 0.33833742141723633
Batch 5/64 loss: 0.3367447257041931
Batch 6/64 loss: 0.3356069326400757
Batch 7/64 loss: 0.3407059907913208
Batch 8/64 loss: 0.3385261297225952
Batch 9/64 loss: 0.34127277135849
Batch 10/64 loss: 0.34473997354507446
Batch 11/64 loss: 0.3374215364456177
Batch 12/64 loss: 0.3384336829185486
Batch 13/64 loss: 0.33596014976501465
Batch 14/64 loss: 0.33323490619659424
Batch 15/64 loss: 0.3369002342224121
Batch 16/64 loss: 0.3367388844490051
Batch 17/64 loss: 0.3378375768661499
Batch 18/64 loss: 0.3376622796058655
Batch 19/64 loss: 0.33606618642807007
Batch 20/64 loss: 0.33773648738861084
Batch 21/64 loss: 0.34041500091552734
Batch 22/64 loss: 0.33340561389923096
Batch 23/64 loss: 0.33584535121917725
Batch 24/64 loss: 0.3370516300201416
Batch 25/64 loss: 0.33850693702697754
Batch 26/64 loss: 0.33601200580596924
Batch 27/64 loss: 0.33843791484832764
Batch 28/64 loss: 0.33889830112457275
Batch 29/64 loss: 0.33821719884872437
Batch 30/64 loss: 0.34032076597213745
Batch 31/64 loss: 0.33785057067871094
Batch 32/64 loss: 0.33932554721832275
Batch 33/64 loss: 0.33910173177719116
Batch 34/64 loss: 0.33951032161712646
Batch 35/64 loss: 0.34086287021636963
Batch 36/64 loss: 0.34434807300567627
Batch 37/64 loss: 0.3385404348373413
Batch 38/64 loss: 0.33413612842559814
Batch 39/64 loss: 0.33726823329925537
Batch 40/64 loss: 0.34099602699279785
Batch 41/64 loss: 0.3358348608016968
Batch 42/64 loss: 0.33846360445022583
Batch 43/64 loss: 0.33745676279067993
Batch 44/64 loss: 0.3372122645378113
Batch 45/64 loss: 0.33440589904785156
Batch 46/64 loss: 0.33861708641052246
Batch 47/64 loss: 0.33137357234954834
Batch 48/64 loss: 0.3385382890701294
Batch 49/64 loss: 0.3393266201019287
Batch 50/64 loss: 0.3334228992462158
Batch 51/64 loss: 0.33218735456466675
Batch 52/64 loss: 0.3410903215408325
Batch 53/64 loss: 0.3392099142074585
Batch 54/64 loss: 0.3380591869354248
Batch 55/64 loss: 0.3394054174423218
Batch 56/64 loss: 0.3340362310409546
Batch 57/64 loss: 0.33528685569763184
Batch 58/64 loss: 0.3405168056488037
Batch 59/64 loss: 0.3402094841003418
Batch 60/64 loss: 0.3384479284286499
Batch 61/64 loss: 0.3350221514701843
Batch 62/64 loss: 0.3350808620452881
Batch 63/64 loss: 0.332314133644104
Batch 64/64 loss: 0.33612585067749023
Epoch 51  Train loss: 0.3376833953109442  Val loss: 0.3430081263850235
Epoch 52
-------------------------------
Batch 1/64 loss: 0.3410249948501587
Batch 2/64 loss: 0.3319653272628784
Batch 3/64 loss: 0.33855241537094116
Batch 4/64 loss: 0.33910131454467773
Batch 5/64 loss: 0.33966004848480225
Batch 6/64 loss: 0.3330545425415039
Batch 7/64 loss: 0.33448827266693115
Batch 8/64 loss: 0.3345069885253906
Batch 9/64 loss: 0.3376753330230713
Batch 10/64 loss: 0.3409351110458374
Batch 11/64 loss: 0.3403703570365906
Batch 12/64 loss: 0.34367871284484863
Batch 13/64 loss: 0.3393760919570923
Batch 14/64 loss: 0.3416604995727539
Batch 15/64 loss: 0.3345867395401001
Batch 16/64 loss: 0.33483612537384033
Batch 17/64 loss: 0.33176910877227783
Batch 18/64 loss: 0.33739519119262695
Batch 19/64 loss: 0.33732712268829346
Batch 20/64 loss: 0.3443704843521118
Batch 21/64 loss: 0.33740341663360596
Batch 22/64 loss: 0.33759987354278564
Batch 23/64 loss: 0.33588099479675293
Batch 24/64 loss: 0.33815109729766846
Batch 25/64 loss: 0.33852994441986084
Batch 26/64 loss: 0.340686559677124
Batch 27/64 loss: 0.33831608295440674
Batch 28/64 loss: 0.34264135360717773
Batch 29/64 loss: 0.3354980945587158
Batch 30/64 loss: 0.33837491273880005
Batch 31/64 loss: 0.336128294467926
Batch 32/64 loss: 0.33604228496551514
Batch 33/64 loss: 0.33452558517456055
Batch 34/64 loss: 0.33559679985046387
Batch 35/64 loss: 0.3377559781074524
Batch 36/64 loss: 0.3374868631362915
Batch 37/64 loss: 0.3364372253417969
Batch 38/64 loss: 0.3372498154640198
Batch 39/64 loss: 0.34195369482040405
Batch 40/64 loss: 0.3378545045852661
Batch 41/64 loss: 0.3381764888763428
Batch 42/64 loss: 0.34113240242004395
Batch 43/64 loss: 0.3359956741333008
Batch 44/64 loss: 0.3371758460998535
Batch 45/64 loss: 0.3380616307258606
Batch 46/64 loss: 0.3340580463409424
Batch 47/64 loss: 0.3395113945007324
Batch 48/64 loss: 0.33840447664260864
Batch 49/64 loss: 0.3403952121734619
Batch 50/64 loss: 0.33661335706710815
Batch 51/64 loss: 0.3372783660888672
Batch 52/64 loss: 0.33866727352142334
Batch 53/64 loss: 0.3397253751754761
Batch 54/64 loss: 0.3352104425430298
Batch 55/64 loss: 0.3396509885787964
Batch 56/64 loss: 0.33865034580230713
Batch 57/64 loss: 0.33292168378829956
Batch 58/64 loss: 0.33613479137420654
Batch 59/64 loss: 0.3380260467529297
Batch 60/64 loss: 0.3347599506378174
Batch 61/64 loss: 0.33862602710723877
Batch 62/64 loss: 0.34031569957733154
Batch 63/64 loss: 0.3386274576187134
Batch 64/64 loss: 0.3409966230392456
Epoch 52  Train loss: 0.3377931702370737  Val loss: 0.3428603683140679
Epoch 53
-------------------------------
Batch 1/64 loss: 0.336004376411438
Batch 2/64 loss: 0.3368828296661377
Batch 3/64 loss: 0.33720076084136963
Batch 4/64 loss: 0.33674943447113037
Batch 5/64 loss: 0.33649301528930664
Batch 6/64 loss: 0.336487352848053
Batch 7/64 loss: 0.3381544351577759
Batch 8/64 loss: 0.33799660205841064
Batch 9/64 loss: 0.3356298804283142
Batch 10/64 loss: 0.3341589570045471
Batch 11/64 loss: 0.33918195962905884
Batch 12/64 loss: 0.3411210775375366
Batch 13/64 loss: 0.3345050811767578
Batch 14/64 loss: 0.34099382162094116
Batch 15/64 loss: 0.338553786277771
Batch 16/64 loss: 0.3347665071487427
Batch 17/64 loss: 0.33545565605163574
Batch 18/64 loss: 0.33755844831466675
Batch 19/64 loss: 0.33491504192352295
Batch 20/64 loss: 0.33562058210372925
Batch 21/64 loss: 0.33338069915771484
Batch 22/64 loss: 0.3345620632171631
Batch 23/64 loss: 0.34126460552215576
Batch 24/64 loss: 0.3335685729980469
Batch 25/64 loss: 0.34168541431427
Batch 26/64 loss: 0.34410572052001953
Batch 27/64 loss: 0.33714568614959717
Batch 28/64 loss: 0.342018723487854
Batch 29/64 loss: 0.3373318910598755
Batch 30/64 loss: 0.335548996925354
Batch 31/64 loss: 0.3411163091659546
Batch 32/64 loss: 0.3366113305091858
Batch 33/64 loss: 0.3344259262084961
Batch 34/64 loss: 0.33812659978866577
Batch 35/64 loss: 0.33659398555755615
Batch 36/64 loss: 0.3406062722206116
Batch 37/64 loss: 0.33966922760009766
Batch 38/64 loss: 0.3394116163253784
Batch 39/64 loss: 0.33655810356140137
Batch 40/64 loss: 0.3386220932006836
Batch 41/64 loss: 0.33889758586883545
Batch 42/64 loss: 0.33659446239471436
Batch 43/64 loss: 0.3345448970794678
Batch 44/64 loss: 0.3367041349411011
Batch 45/64 loss: 0.33256280422210693
Batch 46/64 loss: 0.34123432636260986
Batch 47/64 loss: 0.3324556350708008
Batch 48/64 loss: 0.3303937315940857
Batch 49/64 loss: 0.33512377738952637
Batch 50/64 loss: 0.33907079696655273
Batch 51/64 loss: 0.3394150733947754
Batch 52/64 loss: 0.3352985978126526
Batch 53/64 loss: 0.33808016777038574
Batch 54/64 loss: 0.33983945846557617
Batch 55/64 loss: 0.3296065926551819
Batch 56/64 loss: 0.3400348424911499
Batch 57/64 loss: 0.3399215340614319
Batch 58/64 loss: 0.3418351411819458
Batch 59/64 loss: 0.3378799557685852
Batch 60/64 loss: 0.33789968490600586
Batch 61/64 loss: 0.3380115032196045
Batch 62/64 loss: 0.3364553451538086
Batch 63/64 loss: 0.33419185876846313
Batch 64/64 loss: 0.33434683084487915
Epoch 53  Train loss: 0.33721718390782673  Val loss: 0.3405283513347718
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: 0.3345656991004944
Batch 2/64 loss: 0.33461320400238037
Batch 3/64 loss: 0.3345561623573303
Batch 4/64 loss: 0.330208420753479
Batch 5/64 loss: 0.33881521224975586
Batch 6/64 loss: 0.3345215320587158
Batch 7/64 loss: 0.34095633029937744
Batch 8/64 loss: 0.3333449959754944
Batch 9/64 loss: 0.33405327796936035
Batch 10/64 loss: 0.33423733711242676
Batch 11/64 loss: 0.3325542211532593
Batch 12/64 loss: 0.3382847309112549
Batch 13/64 loss: 0.33282268047332764
Batch 14/64 loss: 0.3350297212600708
Batch 15/64 loss: 0.337105393409729
Batch 16/64 loss: 0.3370189666748047
Batch 17/64 loss: 0.33876049518585205
Batch 18/64 loss: 0.34034693241119385
Batch 19/64 loss: 0.3441433906555176
Batch 20/64 loss: 0.3308544158935547
Batch 21/64 loss: 0.34056317806243896
Batch 22/64 loss: 0.33835721015930176
Batch 23/64 loss: 0.3374331593513489
Batch 24/64 loss: 0.3409438729286194
Batch 25/64 loss: 0.33737003803253174
Batch 26/64 loss: 0.33037132024765015
Batch 27/64 loss: 0.33318912982940674
Batch 28/64 loss: 0.33519649505615234
Batch 29/64 loss: 0.335277795791626
Batch 30/64 loss: 0.3364359140396118
Batch 31/64 loss: 0.33976542949676514
Batch 32/64 loss: 0.34023767709732056
Batch 33/64 loss: 0.33862578868865967
Batch 34/64 loss: 0.3388100862503052
Batch 35/64 loss: 0.3363072872161865
Batch 36/64 loss: 0.3361104726791382
Batch 37/64 loss: 0.33633387088775635
Batch 38/64 loss: 0.336928129196167
Batch 39/64 loss: 0.3374450206756592
Batch 40/64 loss: 0.3383188247680664
Batch 41/64 loss: 0.33850669860839844
Batch 42/64 loss: 0.3385147452354431
Batch 43/64 loss: 0.34151124954223633
Batch 44/64 loss: 0.3318024277687073
Batch 45/64 loss: 0.3317899703979492
Batch 46/64 loss: 0.33487415313720703
Batch 47/64 loss: 0.33667469024658203
Batch 48/64 loss: 0.3447134494781494
Batch 49/64 loss: 0.334495484828949
Batch 50/64 loss: 0.33863502740859985
Batch 51/64 loss: 0.33812832832336426
Batch 52/64 loss: 0.33417677879333496
Batch 53/64 loss: 0.33648431301116943
Batch 54/64 loss: 0.3387261629104614
Batch 55/64 loss: 0.3363266587257385
Batch 56/64 loss: 0.33368682861328125
Batch 57/64 loss: 0.3340946435928345
Batch 58/64 loss: 0.33961546421051025
Batch 59/64 loss: 0.33302152156829834
Batch 60/64 loss: 0.33362388610839844
Batch 61/64 loss: 0.333585262298584
Batch 62/64 loss: 0.32761526107788086
Batch 63/64 loss: 0.3361093997955322
Batch 64/64 loss: 0.33916914463043213
Epoch 54  Train loss: 0.33634357779633767  Val loss: 0.3419083979531252
Epoch 55
-------------------------------
Batch 1/64 loss: 0.33728963136672974
Batch 2/64 loss: 0.3389613628387451
Batch 3/64 loss: 0.33749186992645264
Batch 4/64 loss: 0.3363605737686157
Batch 5/64 loss: 0.3361748456954956
Batch 6/64 loss: 0.33384376764297485
Batch 7/64 loss: 0.34239792823791504
Batch 8/64 loss: 0.33157819509506226
Batch 9/64 loss: 0.33333760499954224
Batch 10/64 loss: 0.33742010593414307
Batch 11/64 loss: 0.3347098231315613
Batch 12/64 loss: 0.33788490295410156
Batch 13/64 loss: 0.33842766284942627
Batch 14/64 loss: 0.33262020349502563
Batch 15/64 loss: 0.3369884490966797
Batch 16/64 loss: 0.33979880809783936
Batch 17/64 loss: 0.341755747795105
Batch 18/64 loss: 0.3351937532424927
Batch 19/64 loss: 0.3409838080406189
Batch 20/64 loss: 0.3346938490867615
Batch 21/64 loss: 0.3343147039413452
Batch 22/64 loss: 0.3328550457954407
Batch 23/64 loss: 0.33151310682296753
Batch 24/64 loss: 0.3351350426673889
Batch 25/64 loss: 0.327762246131897
Batch 26/64 loss: 0.3354508876800537
Batch 27/64 loss: 0.33580100536346436
Batch 28/64 loss: 0.33157527446746826
Batch 29/64 loss: 0.33437639474868774
Batch 30/64 loss: 0.33940333127975464
Batch 31/64 loss: 0.33487093448638916
Batch 32/64 loss: 0.33620357513427734
Batch 33/64 loss: 0.32308006286621094
Batch 34/64 loss: 0.34070444107055664
Batch 35/64 loss: 0.3389705419540405
Batch 36/64 loss: 0.33507412672042847
Batch 37/64 loss: 0.3353912830352783
Batch 38/64 loss: 0.33409249782562256
Batch 39/64 loss: 0.33997976779937744
Batch 40/64 loss: 0.3433573246002197
Batch 41/64 loss: 0.33785301446914673
Batch 42/64 loss: 0.3314861059188843
Batch 43/64 loss: 0.3326677680015564
Batch 44/64 loss: 0.3341035842895508
Batch 45/64 loss: 0.33272063732147217
Batch 46/64 loss: 0.33970844745635986
Batch 47/64 loss: 0.33655238151550293
Batch 48/64 loss: 0.33775556087493896
Batch 49/64 loss: 0.34099364280700684
Batch 50/64 loss: 0.33505749702453613
Batch 51/64 loss: 0.33408206701278687
Batch 52/64 loss: 0.3374544382095337
Batch 53/64 loss: 0.3424239158630371
Batch 54/64 loss: 0.33819514513015747
Batch 55/64 loss: 0.3345223665237427
Batch 56/64 loss: 0.3310537338256836
Batch 57/64 loss: 0.3327407240867615
Batch 58/64 loss: 0.3415190577507019
Batch 59/64 loss: 0.3322223424911499
Batch 60/64 loss: 0.3366849422454834
Batch 61/64 loss: 0.3399122953414917
Batch 62/64 loss: 0.33762651681900024
Batch 63/64 loss: 0.335329532623291
Batch 64/64 loss: 0.33995938301086426
Epoch 55  Train loss: 0.33608564302033067  Val loss: 0.3414018307764506
Epoch 56
-------------------------------
Batch 1/64 loss: 0.3352959156036377
Batch 2/64 loss: 0.3384436368942261
Batch 3/64 loss: 0.3405071496963501
Batch 4/64 loss: 0.34017157554626465
Batch 5/64 loss: 0.33498096466064453
Batch 6/64 loss: 0.3347911834716797
Batch 7/64 loss: 0.3314629793167114
Batch 8/64 loss: 0.333635151386261
Batch 9/64 loss: 0.3351462483406067
Batch 10/64 loss: 0.33642351627349854
Batch 11/64 loss: 0.335818350315094
Batch 12/64 loss: 0.3371194005012512
Batch 13/64 loss: 0.33569270372390747
Batch 14/64 loss: 0.33221787214279175
Batch 15/64 loss: 0.3332909941673279
Batch 16/64 loss: 0.3319934606552124
Batch 17/64 loss: 0.33852750062942505
Batch 18/64 loss: 0.33366715908050537
Batch 19/64 loss: 0.34173524379730225
Batch 20/64 loss: 0.3354470729827881
Batch 21/64 loss: 0.3347562551498413
Batch 22/64 loss: 0.3361583948135376
Batch 23/64 loss: 0.33533287048339844
Batch 24/64 loss: 0.3285895586013794
Batch 25/64 loss: 0.3366374969482422
Batch 26/64 loss: 0.34079569578170776
Batch 27/64 loss: 0.33283090591430664
Batch 28/64 loss: 0.3363340497016907
Batch 29/64 loss: 0.32980507612228394
Batch 30/64 loss: 0.33393293619155884
Batch 31/64 loss: 0.3366711735725403
Batch 32/64 loss: 0.33544087409973145
Batch 33/64 loss: 0.34058505296707153
Batch 34/64 loss: 0.3368583917617798
Batch 35/64 loss: 0.34040653705596924
Batch 36/64 loss: 0.3409721851348877
Batch 37/64 loss: 0.33963727951049805
Batch 38/64 loss: 0.33585989475250244
Batch 39/64 loss: 0.3386128544807434
Batch 40/64 loss: 0.3371380567550659
Batch 41/64 loss: 0.337638258934021
Batch 42/64 loss: 0.3358694911003113
Batch 43/64 loss: 0.33252108097076416
Batch 44/64 loss: 0.3332917094230652
Batch 45/64 loss: 0.3298581838607788
Batch 46/64 loss: 0.3315020799636841
Batch 47/64 loss: 0.3386152982711792
Batch 48/64 loss: 0.337558388710022
Batch 49/64 loss: 0.3345262408256531
Batch 50/64 loss: 0.33438658714294434
Batch 51/64 loss: 0.3332807421684265
Batch 52/64 loss: 0.32692646980285645
Batch 53/64 loss: 0.33651572465896606
Batch 54/64 loss: 0.3360593914985657
Batch 55/64 loss: 0.3377707600593567
Batch 56/64 loss: 0.3366160988807678
Batch 57/64 loss: 0.33979690074920654
Batch 58/64 loss: 0.33581018447875977
Batch 59/64 loss: 0.3395644426345825
Batch 60/64 loss: 0.3357279896736145
Batch 61/64 loss: 0.3349417448043823
Batch 62/64 loss: 0.3363106846809387
Batch 63/64 loss: 0.33280032873153687
Batch 64/64 loss: 0.3313075304031372
Epoch 56  Train loss: 0.33568773409899544  Val loss: 0.3401843067706655
Saving best model, epoch: 56
Epoch 57
-------------------------------
Batch 1/64 loss: 0.33200299739837646
Batch 2/64 loss: 0.3345419764518738
Batch 3/64 loss: 0.33453893661499023
Batch 4/64 loss: 0.336475133895874
Batch 5/64 loss: 0.3396916389465332
Batch 6/64 loss: 0.33407676219940186
Batch 7/64 loss: 0.3387117385864258
Batch 8/64 loss: 0.33833277225494385
Batch 9/64 loss: 0.3323884606361389
Batch 10/64 loss: 0.33661848306655884
Batch 11/64 loss: 0.33463263511657715
Batch 12/64 loss: 0.3370269536972046
Batch 13/64 loss: 0.33063507080078125
Batch 14/64 loss: 0.32935988903045654
Batch 15/64 loss: 0.3359949588775635
Batch 16/64 loss: 0.3348160982131958
Batch 17/64 loss: 0.3352752923965454
Batch 18/64 loss: 0.33459436893463135
Batch 19/64 loss: 0.3396952152252197
Batch 20/64 loss: 0.3368670344352722
Batch 21/64 loss: 0.3328019380569458
Batch 22/64 loss: 0.331678569316864
Batch 23/64 loss: 0.3369828462600708
Batch 24/64 loss: 0.3375566005706787
Batch 25/64 loss: 0.3334646224975586
Batch 26/64 loss: 0.33050066232681274
Batch 27/64 loss: 0.33517658710479736
Batch 28/64 loss: 0.33226919174194336
Batch 29/64 loss: 0.33435529470443726
Batch 30/64 loss: 0.3363901376724243
Batch 31/64 loss: 0.33465486764907837
Batch 32/64 loss: 0.33854812383651733
Batch 33/64 loss: 0.33688288927078247
Batch 34/64 loss: 0.33879607915878296
Batch 35/64 loss: 0.33466124534606934
Batch 36/64 loss: 0.3327064514160156
Batch 37/64 loss: 0.33735668659210205
Batch 38/64 loss: 0.33748728036880493
Batch 39/64 loss: 0.332977831363678
Batch 40/64 loss: 0.33121901750564575
Batch 41/64 loss: 0.3354165554046631
Batch 42/64 loss: 0.3418338894844055
Batch 43/64 loss: 0.33682674169540405
Batch 44/64 loss: 0.33470702171325684
Batch 45/64 loss: 0.33544814586639404
Batch 46/64 loss: 0.3363126516342163
Batch 47/64 loss: 0.3440999984741211
Batch 48/64 loss: 0.336870014667511
Batch 49/64 loss: 0.333238422870636
Batch 50/64 loss: 0.3366645574569702
Batch 51/64 loss: 0.3368249535560608
Batch 52/64 loss: 0.33630961179733276
Batch 53/64 loss: 0.33598291873931885
Batch 54/64 loss: 0.330100417137146
Batch 55/64 loss: 0.33569055795669556
Batch 56/64 loss: 0.3307279348373413
Batch 57/64 loss: 0.33162349462509155
Batch 58/64 loss: 0.33760547637939453
Batch 59/64 loss: 0.3378944396972656
Batch 60/64 loss: 0.3348621129989624
Batch 61/64 loss: 0.3374953269958496
Batch 62/64 loss: 0.3380244970321655
Batch 63/64 loss: 0.3275243639945984
Batch 64/64 loss: 0.33465033769607544
Epoch 57  Train loss: 0.33530690506392835  Val loss: 0.34022465932000545
Epoch 58
-------------------------------
Batch 1/64 loss: 0.3371012806892395
Batch 2/64 loss: 0.33404868841171265
Batch 3/64 loss: 0.3315849304199219
Batch 4/64 loss: 0.3394012451171875
Batch 5/64 loss: 0.33496153354644775
Batch 6/64 loss: 0.33472251892089844
Batch 7/64 loss: 0.33610206842422485
Batch 8/64 loss: 0.3354405164718628
Batch 9/64 loss: 0.3346114158630371
Batch 10/64 loss: 0.33588075637817383
Batch 11/64 loss: 0.33528196811676025
Batch 12/64 loss: 0.3340160846710205
Batch 13/64 loss: 0.33355188369750977
Batch 14/64 loss: 0.33116209506988525
Batch 15/64 loss: 0.3299175500869751
Batch 16/64 loss: 0.3341212868690491
Batch 17/64 loss: 0.3343856930732727
Batch 18/64 loss: 0.3357422351837158
Batch 19/64 loss: 0.3302426338195801
Batch 20/64 loss: 0.33410394191741943
Batch 21/64 loss: 0.3340674042701721
Batch 22/64 loss: 0.3388911485671997
Batch 23/64 loss: 0.3337533473968506
Batch 24/64 loss: 0.33033639192581177
Batch 25/64 loss: 0.33605313301086426
Batch 26/64 loss: 0.3334178328514099
Batch 27/64 loss: 0.3390123248100281
Batch 28/64 loss: 0.3387622833251953
Batch 29/64 loss: 0.3329853415489197
Batch 30/64 loss: 0.33266985416412354
Batch 31/64 loss: 0.3402979373931885
Batch 32/64 loss: 0.33391618728637695
Batch 33/64 loss: 0.32933926582336426
Batch 34/64 loss: 0.32894784212112427
Batch 35/64 loss: 0.33279919624328613
Batch 36/64 loss: 0.33253228664398193
Batch 37/64 loss: 0.33938735723495483
Batch 38/64 loss: 0.33929479122161865
Batch 39/64 loss: 0.33171385526657104
Batch 40/64 loss: 0.3318656086921692
Batch 41/64 loss: 0.3296993374824524
Batch 42/64 loss: 0.3354841470718384
Batch 43/64 loss: 0.334814190864563
Batch 44/64 loss: 0.3332960605621338
Batch 45/64 loss: 0.3353617191314697
Batch 46/64 loss: 0.3315540552139282
Batch 47/64 loss: 0.3350651264190674
Batch 48/64 loss: 0.33257347345352173
Batch 49/64 loss: 0.3310505151748657
Batch 50/64 loss: 0.33348220586776733
Batch 51/64 loss: 0.3353177309036255
Batch 52/64 loss: 0.3353106379508972
Batch 53/64 loss: 0.33509528636932373
Batch 54/64 loss: 0.3364059329032898
Batch 55/64 loss: 0.3380715847015381
Batch 56/64 loss: 0.3362724781036377
Batch 57/64 loss: 0.33602482080459595
Batch 58/64 loss: 0.3340187072753906
Batch 59/64 loss: 0.3359397053718567
Batch 60/64 loss: 0.33910906314849854
Batch 61/64 loss: 0.3369532823562622
Batch 62/64 loss: 0.33303725719451904
Batch 63/64 loss: 0.33261358737945557
Batch 64/64 loss: 0.33844953775405884
Epoch 58  Train loss: 0.3345382239304337  Val loss: 0.3395995923743625
Saving best model, epoch: 58
Epoch 59
-------------------------------
Batch 1/64 loss: 0.3323013186454773
Batch 2/64 loss: 0.3345358371734619
Batch 3/64 loss: 0.3348538875579834
Batch 4/64 loss: 0.3338038921356201
Batch 5/64 loss: 0.3360942006111145
Batch 6/64 loss: 0.33224260807037354
Batch 7/64 loss: 0.3331311345100403
Batch 8/64 loss: 0.33345913887023926
Batch 9/64 loss: 0.33884531259536743
Batch 10/64 loss: 0.33342039585113525
Batch 11/64 loss: 0.3313845992088318
Batch 12/64 loss: 0.33578312397003174
Batch 13/64 loss: 0.3370524048805237
Batch 14/64 loss: 0.3323897123336792
Batch 15/64 loss: 0.3300868272781372
Batch 16/64 loss: 0.33700889348983765
Batch 17/64 loss: 0.33046162128448486
Batch 18/64 loss: 0.33527445793151855
Batch 19/64 loss: 0.3350883722305298
Batch 20/64 loss: 0.3346124291419983
Batch 21/64 loss: 0.33299410343170166
Batch 22/64 loss: 0.33342039585113525
Batch 23/64 loss: 0.33599716424942017
Batch 24/64 loss: 0.33173203468322754
Batch 25/64 loss: 0.33603715896606445
Batch 26/64 loss: 0.3320455551147461
Batch 27/64 loss: 0.33500468730926514
Batch 28/64 loss: 0.33287060260772705
Batch 29/64 loss: 0.32927149534225464
Batch 30/64 loss: 0.3314422369003296
Batch 31/64 loss: 0.33564096689224243
Batch 32/64 loss: 0.339139461517334
Batch 33/64 loss: 0.33489298820495605
Batch 34/64 loss: 0.33393698930740356
Batch 35/64 loss: 0.33530211448669434
Batch 36/64 loss: 0.3349192142486572
Batch 37/64 loss: 0.3340514302253723
Batch 38/64 loss: 0.3312232494354248
Batch 39/64 loss: 0.3398215174674988
Batch 40/64 loss: 0.33621466159820557
Batch 41/64 loss: 0.3362888693809509
Batch 42/64 loss: 0.33439648151397705
Batch 43/64 loss: 0.3354266881942749
Batch 44/64 loss: 0.3346141576766968
Batch 45/64 loss: 0.3375500440597534
Batch 46/64 loss: 0.3351823091506958
Batch 47/64 loss: 0.33087968826293945
Batch 48/64 loss: 0.33646684885025024
Batch 49/64 loss: 0.3305712938308716
Batch 50/64 loss: 0.3365929126739502
Batch 51/64 loss: 0.33332085609436035
Batch 52/64 loss: 0.33643585443496704
Batch 53/64 loss: 0.3297586441040039
Batch 54/64 loss: 0.3355863094329834
Batch 55/64 loss: 0.3384987711906433
Batch 56/64 loss: 0.34114712476730347
Batch 57/64 loss: 0.3357778787612915
Batch 58/64 loss: 0.32700884342193604
Batch 59/64 loss: 0.3315572738647461
Batch 60/64 loss: 0.33271723985671997
Batch 61/64 loss: 0.33849620819091797
Batch 62/64 loss: 0.3380742073059082
Batch 63/64 loss: 0.33389437198638916
Batch 64/64 loss: 0.33276963233947754
Epoch 59  Train loss: 0.33439385563719504  Val loss: 0.3416644537571779
Epoch 60
-------------------------------
Batch 1/64 loss: 0.3331589698791504
Batch 2/64 loss: 0.3332213759422302
Batch 3/64 loss: 0.3354825973510742
Batch 4/64 loss: 0.3378959894180298
Batch 5/64 loss: 0.3363165855407715
Batch 6/64 loss: 0.3329579830169678
Batch 7/64 loss: 0.33321404457092285
Batch 8/64 loss: 0.3348104953765869
Batch 9/64 loss: 0.334775447845459
Batch 10/64 loss: 0.32838356494903564
Batch 11/64 loss: 0.3340831995010376
Batch 12/64 loss: 0.32997459173202515
Batch 13/64 loss: 0.33285796642303467
Batch 14/64 loss: 0.3340575695037842
Batch 15/64 loss: 0.33641231060028076
Batch 16/64 loss: 0.33520156145095825
Batch 17/64 loss: 0.33093059062957764
Batch 18/64 loss: 0.33327871561050415
Batch 19/64 loss: 0.3289235830307007
Batch 20/64 loss: 0.3370710611343384
Batch 21/64 loss: 0.3392302393913269
Batch 22/64 loss: 0.333135187625885
Batch 23/64 loss: 0.3360018730163574
Batch 24/64 loss: 0.3388829231262207
Batch 25/64 loss: 0.32661324739456177
Batch 26/64 loss: 0.3317123055458069
Batch 27/64 loss: 0.3311864137649536
Batch 28/64 loss: 0.33564722537994385
Batch 29/64 loss: 0.3355135917663574
Batch 30/64 loss: 0.329268217086792
Batch 31/64 loss: 0.3371267318725586
Batch 32/64 loss: 0.33268463611602783
Batch 33/64 loss: 0.33650773763656616
Batch 34/64 loss: 0.3332782983779907
Batch 35/64 loss: 0.3341999053955078
Batch 36/64 loss: 0.33031368255615234
Batch 37/64 loss: 0.33878135681152344
Batch 38/64 loss: 0.33729004859924316
Batch 39/64 loss: 0.3315349221229553
Batch 40/64 loss: 0.33301621675491333
Batch 41/64 loss: 0.33454805612564087
Batch 42/64 loss: 0.33875834941864014
Batch 43/64 loss: 0.33312922716140747
Batch 44/64 loss: 0.3342422842979431
Batch 45/64 loss: 0.33538269996643066
Batch 46/64 loss: 0.3385891914367676
Batch 47/64 loss: 0.332161545753479
Batch 48/64 loss: 0.33367663621902466
Batch 49/64 loss: 0.33241283893585205
Batch 50/64 loss: 0.33244776725769043
Batch 51/64 loss: 0.3319562077522278
Batch 52/64 loss: 0.3382263779640198
Batch 53/64 loss: 0.32667577266693115
Batch 54/64 loss: 0.3364015221595764
Batch 55/64 loss: 0.335416316986084
Batch 56/64 loss: 0.3358626365661621
Batch 57/64 loss: 0.3371468782424927
Batch 58/64 loss: 0.32924699783325195
Batch 59/64 loss: 0.3367863893508911
Batch 60/64 loss: 0.33383244276046753
Batch 61/64 loss: 0.33530235290527344
Batch 62/64 loss: 0.33570730686187744
Batch 63/64 loss: 0.3275109529495239
Batch 64/64 loss: 0.3309307098388672
Epoch 60  Train loss: 0.33393806663213993  Val loss: 0.3388087257896502
Saving best model, epoch: 60
Epoch 61
-------------------------------
Batch 1/64 loss: 0.33383268117904663
Batch 2/64 loss: 0.3340733051300049
Batch 3/64 loss: 0.32845330238342285
Batch 4/64 loss: 0.3327900171279907
Batch 5/64 loss: 0.3359721899032593
Batch 6/64 loss: 0.3384060859680176
Batch 7/64 loss: 0.334147572517395
Batch 8/64 loss: 0.33312392234802246
Batch 9/64 loss: 0.32921266555786133
Batch 10/64 loss: 0.3353129029273987
Batch 11/64 loss: 0.33148324489593506
Batch 12/64 loss: 0.33092910051345825
Batch 13/64 loss: 0.33164745569229126
Batch 14/64 loss: 0.33716464042663574
Batch 15/64 loss: 0.3426592946052551
Batch 16/64 loss: 0.3338366746902466
Batch 17/64 loss: 0.3352346420288086
Batch 18/64 loss: 0.34002453088760376
Batch 19/64 loss: 0.3287574052810669
Batch 20/64 loss: 0.3278827667236328
Batch 21/64 loss: 0.33293765783309937
Batch 22/64 loss: 0.3253759741783142
Batch 23/64 loss: 0.3312857151031494
Batch 24/64 loss: 0.32837146520614624
Batch 25/64 loss: 0.33180463314056396
Batch 26/64 loss: 0.33318251371383667
Batch 27/64 loss: 0.3337184190750122
Batch 28/64 loss: 0.33486878871917725
Batch 29/64 loss: 0.3322436809539795
Batch 30/64 loss: 0.3338302969932556
Batch 31/64 loss: 0.3280486464500427
Batch 32/64 loss: 0.3322659730911255
Batch 33/64 loss: 0.33212220668792725
Batch 34/64 loss: 0.3323621153831482
Batch 35/64 loss: 0.332400918006897
Batch 36/64 loss: 0.3328862190246582
Batch 37/64 loss: 0.33713841438293457
Batch 38/64 loss: 0.33371031284332275
Batch 39/64 loss: 0.3386070132255554
Batch 40/64 loss: 0.3269943594932556
Batch 41/64 loss: 0.33351337909698486
Batch 42/64 loss: 0.33190757036209106
Batch 43/64 loss: 0.3309403657913208
Batch 44/64 loss: 0.32995831966400146
Batch 45/64 loss: 0.3355522155761719
Batch 46/64 loss: 0.3375523090362549
Batch 47/64 loss: 0.33406925201416016
Batch 48/64 loss: 0.33047616481781006
Batch 49/64 loss: 0.33343398571014404
Batch 50/64 loss: 0.33701837062835693
Batch 51/64 loss: 0.3381962776184082
Batch 52/64 loss: 0.3345221281051636
Batch 53/64 loss: 0.3317365050315857
Batch 54/64 loss: 0.33033114671707153
Batch 55/64 loss: 0.33431053161621094
Batch 56/64 loss: 0.331866979598999
Batch 57/64 loss: 0.33411431312561035
Batch 58/64 loss: 0.3344721794128418
Batch 59/64 loss: 0.33053863048553467
Batch 60/64 loss: 0.33346736431121826
Batch 61/64 loss: 0.33363914489746094
Batch 62/64 loss: 0.3321167826652527
Batch 63/64 loss: 0.33241772651672363
Batch 64/64 loss: 0.33483630418777466
Epoch 61  Train loss: 0.33311966423894845  Val loss: 0.33726372956410305
Saving best model, epoch: 61
Epoch 62
-------------------------------
Batch 1/64 loss: 0.3288857340812683
Batch 2/64 loss: 0.33467257022857666
Batch 3/64 loss: 0.33025676012039185
Batch 4/64 loss: 0.33447515964508057
Batch 5/64 loss: 0.3268924951553345
Batch 6/64 loss: 0.33097320795059204
Batch 7/64 loss: 0.33684033155441284
Batch 8/64 loss: 0.3344777822494507
Batch 9/64 loss: 0.3353956937789917
Batch 10/64 loss: 0.33258944749832153
Batch 11/64 loss: 0.33577245473861694
Batch 12/64 loss: 0.33473944664001465
Batch 13/64 loss: 0.3337063193321228
Batch 14/64 loss: 0.33396613597869873
Batch 15/64 loss: 0.33364176750183105
Batch 16/64 loss: 0.33045971393585205
Batch 17/64 loss: 0.33188414573669434
Batch 18/64 loss: 0.33188676834106445
Batch 19/64 loss: 0.329669713973999
Batch 20/64 loss: 0.33155643939971924
Batch 21/64 loss: 0.3309805393218994
Batch 22/64 loss: 0.3346596956253052
Batch 23/64 loss: 0.33363157510757446
Batch 24/64 loss: 0.337039589881897
Batch 25/64 loss: 0.3342832326889038
Batch 26/64 loss: 0.3324964642524719
Batch 27/64 loss: 0.3333144187927246
Batch 28/64 loss: 0.33975541591644287
Batch 29/64 loss: 0.3331921696662903
Batch 30/64 loss: 0.3280479907989502
Batch 31/64 loss: 0.33327919244766235
Batch 32/64 loss: 0.3334658145904541
Batch 33/64 loss: 0.33930504322052
Batch 34/64 loss: 0.33587002754211426
Batch 35/64 loss: 0.3339461088180542
Batch 36/64 loss: 0.33370548486709595
Batch 37/64 loss: 0.3346707820892334
Batch 38/64 loss: 0.335152268409729
Batch 39/64 loss: 0.3291536569595337
Batch 40/64 loss: 0.3288710117340088
Batch 41/64 loss: 0.3363964557647705
Batch 42/64 loss: 0.33300942182540894
Batch 43/64 loss: 0.33134180307388306
Batch 44/64 loss: 0.32464665174484253
Batch 45/64 loss: 0.33066707849502563
Batch 46/64 loss: 0.3333466053009033
Batch 47/64 loss: 0.33046674728393555
Batch 48/64 loss: 0.3359428644180298
Batch 49/64 loss: 0.3342081308364868
Batch 50/64 loss: 0.3380107283592224
Batch 51/64 loss: 0.3299601674079895
Batch 52/64 loss: 0.33142709732055664
Batch 53/64 loss: 0.33307480812072754
Batch 54/64 loss: 0.33206528425216675
Batch 55/64 loss: 0.33184814453125
Batch 56/64 loss: 0.3283982276916504
Batch 57/64 loss: 0.3275437355041504
Batch 58/64 loss: 0.331723690032959
Batch 59/64 loss: 0.3303089141845703
Batch 60/64 loss: 0.33733808994293213
Batch 61/64 loss: 0.3338661193847656
Batch 62/64 loss: 0.3294292688369751
Batch 63/64 loss: 0.33627939224243164
Batch 64/64 loss: 0.33822786808013916
Epoch 62  Train loss: 0.3329024768343159  Val loss: 0.3372508680697569
Saving best model, epoch: 62
Epoch 63
-------------------------------
Batch 1/64 loss: 0.32858818769454956
Batch 2/64 loss: 0.3334757089614868
Batch 3/64 loss: 0.33211755752563477
Batch 4/64 loss: 0.33055293560028076
Batch 5/64 loss: 0.33172857761383057
Batch 6/64 loss: 0.327472448348999
Batch 7/64 loss: 0.330228328704834
Batch 8/64 loss: 0.3361016511917114
Batch 9/64 loss: 0.33486104011535645
Batch 10/64 loss: 0.33229732513427734
Batch 11/64 loss: 0.3330787420272827
Batch 12/64 loss: 0.3325607180595398
Batch 13/64 loss: 0.333135724067688
Batch 14/64 loss: 0.33767396211624146
Batch 15/64 loss: 0.33680880069732666
Batch 16/64 loss: 0.33772629499435425
Batch 17/64 loss: 0.33626002073287964
Batch 18/64 loss: 0.329473078250885
Batch 19/64 loss: 0.3338850736618042
Batch 20/64 loss: 0.3301655650138855
Batch 21/64 loss: 0.3317052125930786
Batch 22/64 loss: 0.33476781845092773
Batch 23/64 loss: 0.33115118741989136
Batch 24/64 loss: 0.328741192817688
Batch 25/64 loss: 0.33357465267181396
Batch 26/64 loss: 0.3352597951889038
Batch 27/64 loss: 0.32754600048065186
Batch 28/64 loss: 0.33549559116363525
Batch 29/64 loss: 0.3325655460357666
Batch 30/64 loss: 0.3331826329231262
Batch 31/64 loss: 0.33110707998275757
Batch 32/64 loss: 0.3306524157524109
Batch 33/64 loss: 0.33307433128356934
Batch 34/64 loss: 0.3330872058868408
Batch 35/64 loss: 0.3295443058013916
Batch 36/64 loss: 0.32562506198883057
Batch 37/64 loss: 0.32639575004577637
Batch 38/64 loss: 0.33049625158309937
Batch 39/64 loss: 0.33432650566101074
Batch 40/64 loss: 0.32735931873321533
Batch 41/64 loss: 0.32942134141921997
Batch 42/64 loss: 0.3320428133010864
Batch 43/64 loss: 0.3364185690879822
Batch 44/64 loss: 0.3326151371002197
Batch 45/64 loss: 0.33622872829437256
Batch 46/64 loss: 0.33289116621017456
Batch 47/64 loss: 0.33250540494918823
Batch 48/64 loss: 0.3306926488876343
Batch 49/64 loss: 0.3311021327972412
Batch 50/64 loss: 0.33138370513916016
Batch 51/64 loss: 0.333113431930542
Batch 52/64 loss: 0.3339792490005493
Batch 53/64 loss: 0.34091877937316895
Batch 54/64 loss: 0.3278593420982361
Batch 55/64 loss: 0.3265734314918518
Batch 56/64 loss: 0.33284974098205566
Batch 57/64 loss: 0.3330256938934326
Batch 58/64 loss: 0.3350409269332886
Batch 59/64 loss: 0.3306949734687805
Batch 60/64 loss: 0.33587193489074707
Batch 61/64 loss: 0.3228098154067993
Batch 62/64 loss: 0.3337136507034302
Batch 63/64 loss: 0.32623815536499023
Batch 64/64 loss: 0.33414971828460693
Epoch 63  Train loss: 0.332116904445723  Val loss: 0.3365850407643007
Saving best model, epoch: 63
Epoch 64
-------------------------------
Batch 1/64 loss: 0.3294917345046997
Batch 2/64 loss: 0.3263009786605835
Batch 3/64 loss: 0.33274686336517334
Batch 4/64 loss: 0.3308490514755249
Batch 5/64 loss: 0.33067822456359863
Batch 6/64 loss: 0.329811155796051
Batch 7/64 loss: 0.3314415216445923
Batch 8/64 loss: 0.331500768661499
Batch 9/64 loss: 0.3308980464935303
Batch 10/64 loss: 0.33002370595932007
Batch 11/64 loss: 0.32557350397109985
Batch 12/64 loss: 0.33292609453201294
Batch 13/64 loss: 0.3389279842376709
Batch 14/64 loss: 0.3316640257835388
Batch 15/64 loss: 0.33801907300949097
Batch 16/64 loss: 0.33065950870513916
Batch 17/64 loss: 0.3357999920845032
Batch 18/64 loss: 0.3315955400466919
Batch 19/64 loss: 0.33092552423477173
Batch 20/64 loss: 0.32902657985687256
Batch 21/64 loss: 0.3367156386375427
Batch 22/64 loss: 0.33454495668411255
Batch 23/64 loss: 0.3363454341888428
Batch 24/64 loss: 0.3266514539718628
Batch 25/64 loss: 0.3285689353942871
Batch 26/64 loss: 0.3285364508628845
Batch 27/64 loss: 0.32801318168640137
Batch 28/64 loss: 0.33475279808044434
Batch 29/64 loss: 0.33091360330581665
Batch 30/64 loss: 0.3322504162788391
Batch 31/64 loss: 0.3348374366760254
Batch 32/64 loss: 0.3326781988143921
Batch 33/64 loss: 0.33447325229644775
Batch 34/64 loss: 0.33862602710723877
Batch 35/64 loss: 0.32731205224990845
Batch 36/64 loss: 0.335284948348999
Batch 37/64 loss: 0.33190715312957764
Batch 38/64 loss: 0.3352862596511841
Batch 39/64 loss: 0.3314923048019409
Batch 40/64 loss: 0.3311748504638672
Batch 41/64 loss: 0.32918936014175415
Batch 42/64 loss: 0.33610790967941284
Batch 43/64 loss: 0.3286786675453186
Batch 44/64 loss: 0.3286947011947632
Batch 45/64 loss: 0.33406925201416016
Batch 46/64 loss: 0.3313003182411194
Batch 47/64 loss: 0.3274726867675781
Batch 48/64 loss: 0.32567864656448364
Batch 49/64 loss: 0.3294464349746704
Batch 50/64 loss: 0.3328951597213745
Batch 51/64 loss: 0.32913386821746826
Batch 52/64 loss: 0.33041971921920776
Batch 53/64 loss: 0.3299161195755005
Batch 54/64 loss: 0.33057379722595215
Batch 55/64 loss: 0.3298034071922302
Batch 56/64 loss: 0.3351926803588867
Batch 57/64 loss: 0.33721911907196045
Batch 58/64 loss: 0.33559566736221313
Batch 59/64 loss: 0.3270726799964905
Batch 60/64 loss: 0.3336437940597534
Batch 61/64 loss: 0.32981687784194946
Batch 62/64 loss: 0.32733553647994995
Batch 63/64 loss: 0.3316535949707031
Batch 64/64 loss: 0.3307979106903076
Epoch 64  Train loss: 0.3315801358690449  Val loss: 0.3360940912335189
Saving best model, epoch: 64
Epoch 65
-------------------------------
Batch 1/64 loss: 0.33543771505355835
Batch 2/64 loss: 0.33141857385635376
Batch 3/64 loss: 0.3281007409095764
Batch 4/64 loss: 0.3270176649093628
Batch 5/64 loss: 0.32766711711883545
Batch 6/64 loss: 0.32618916034698486
Batch 7/64 loss: 0.3276982307434082
Batch 8/64 loss: 0.3302028179168701
Batch 9/64 loss: 0.3309951424598694
Batch 10/64 loss: 0.328914999961853
Batch 11/64 loss: 0.3397906422615051
Batch 12/64 loss: 0.3311876058578491
Batch 13/64 loss: 0.33458709716796875
Batch 14/64 loss: 0.3305649757385254
Batch 15/64 loss: 0.3250921964645386
Batch 16/64 loss: 0.3325202465057373
Batch 17/64 loss: 0.33333921432495117
Batch 18/64 loss: 0.32999956607818604
Batch 19/64 loss: 0.3344384431838989
Batch 20/64 loss: 0.33247649669647217
Batch 21/64 loss: 0.335019588470459
Batch 22/64 loss: 0.3261387348175049
Batch 23/64 loss: 0.325223445892334
Batch 24/64 loss: 0.32720375061035156
Batch 25/64 loss: 0.3342142105102539
Batch 26/64 loss: 0.3328632116317749
Batch 27/64 loss: 0.33060067892074585
Batch 28/64 loss: 0.3305250406265259
Batch 29/64 loss: 0.3257361650466919
Batch 30/64 loss: 0.3277714252471924
Batch 31/64 loss: 0.3391331434249878
Batch 32/64 loss: 0.3374159336090088
Batch 33/64 loss: 0.3276446461677551
Batch 34/64 loss: 0.3260074853897095
Batch 35/64 loss: 0.3307323455810547
Batch 36/64 loss: 0.32786744832992554
Batch 37/64 loss: 0.3316389322280884
Batch 38/64 loss: 0.32989639043807983
Batch 39/64 loss: 0.3335837125778198
Batch 40/64 loss: 0.32585597038269043
Batch 41/64 loss: 0.3356475830078125
Batch 42/64 loss: 0.33307576179504395
Batch 43/64 loss: 0.3306933641433716
Batch 44/64 loss: 0.3351588249206543
Batch 45/64 loss: 0.33619147539138794
Batch 46/64 loss: 0.32921433448791504
Batch 47/64 loss: 0.3394606113433838
Batch 48/64 loss: 0.32923150062561035
Batch 49/64 loss: 0.3273278474807739
Batch 50/64 loss: 0.3299827575683594
Batch 51/64 loss: 0.3278014659881592
Batch 52/64 loss: 0.3298133611679077
Batch 53/64 loss: 0.3349154591560364
Batch 54/64 loss: 0.32945823669433594
Batch 55/64 loss: 0.331498920917511
Batch 56/64 loss: 0.32854342460632324
Batch 57/64 loss: 0.3299551010131836
Batch 58/64 loss: 0.3312671184539795
Batch 59/64 loss: 0.32769447565078735
Batch 60/64 loss: 0.32950758934020996
Batch 61/64 loss: 0.33120179176330566
Batch 62/64 loss: 0.3353955149650574
Batch 63/64 loss: 0.3282002806663513
Batch 64/64 loss: 0.3315196633338928
Epoch 65  Train loss: 0.33086411695854334  Val loss: 0.33643989014052034
Epoch 66
-------------------------------
Batch 1/64 loss: 0.33211779594421387
Batch 2/64 loss: 0.33182644844055176
Batch 3/64 loss: 0.3340263366699219
Batch 4/64 loss: 0.32845592498779297
Batch 5/64 loss: 0.3303349018096924
Batch 6/64 loss: 0.3375052213668823
Batch 7/64 loss: 0.332175612449646
Batch 8/64 loss: 0.33268892765045166
Batch 9/64 loss: 0.33018314838409424
Batch 10/64 loss: 0.33369386196136475
Batch 11/64 loss: 0.3304433226585388
Batch 12/64 loss: 0.32926565408706665
Batch 13/64 loss: 0.3290122151374817
Batch 14/64 loss: 0.33463525772094727
Batch 15/64 loss: 0.3353199362754822
Batch 16/64 loss: 0.32517707347869873
Batch 17/64 loss: 0.3327862620353699
Batch 18/64 loss: 0.3296821117401123
Batch 19/64 loss: 0.33315861225128174
Batch 20/64 loss: 0.3271753787994385
Batch 21/64 loss: 0.3238975405693054
Batch 22/64 loss: 0.3328084349632263
Batch 23/64 loss: 0.33581870794296265
Batch 24/64 loss: 0.33080410957336426
Batch 25/64 loss: 0.3297279477119446
Batch 26/64 loss: 0.330000638961792
Batch 27/64 loss: 0.32987892627716064
Batch 28/64 loss: 0.3264584541320801
Batch 29/64 loss: 0.33442139625549316
Batch 30/64 loss: 0.3326261043548584
Batch 31/64 loss: 0.33360373973846436
Batch 32/64 loss: 0.33660078048706055
Batch 33/64 loss: 0.3351169228553772
Batch 34/64 loss: 0.3403252363204956
Batch 35/64 loss: 0.32643985748291016
Batch 36/64 loss: 0.32975924015045166
Batch 37/64 loss: 0.33520960807800293
Batch 38/64 loss: 0.3304924964904785
Batch 39/64 loss: 0.3335456848144531
Batch 40/64 loss: 0.3258638381958008
Batch 41/64 loss: 0.33112382888793945
Batch 42/64 loss: 0.3325713276863098
Batch 43/64 loss: 0.32989728450775146
Batch 44/64 loss: 0.3362598419189453
Batch 45/64 loss: 0.32973313331604004
Batch 46/64 loss: 0.3312268853187561
Batch 47/64 loss: 0.33065229654312134
Batch 48/64 loss: 0.32788366079330444
Batch 49/64 loss: 0.3287358283996582
Batch 50/64 loss: 0.32725852727890015
Batch 51/64 loss: 0.329789400100708
Batch 52/64 loss: 0.330615758895874
Batch 53/64 loss: 0.32887375354766846
Batch 54/64 loss: 0.3311288356781006
Batch 55/64 loss: 0.3289332985877991
Batch 56/64 loss: 0.32165998220443726
Batch 57/64 loss: 0.33042967319488525
Batch 58/64 loss: 0.33204102516174316
Batch 59/64 loss: 0.3261663317680359
Batch 60/64 loss: 0.32971644401550293
Batch 61/64 loss: 0.3302517533302307
Batch 62/64 loss: 0.3277214765548706
Batch 63/64 loss: 0.32795828580856323
Batch 64/64 loss: 0.32590413093566895
Epoch 66  Train loss: 0.3307940455044017  Val loss: 0.3355279673415771
Saving best model, epoch: 66
Epoch 67
-------------------------------
Batch 1/64 loss: 0.3307955265045166
Batch 2/64 loss: 0.3269442915916443
Batch 3/64 loss: 0.3300435543060303
Batch 4/64 loss: 0.330119252204895
Batch 5/64 loss: 0.3301474452018738
Batch 6/64 loss: 0.33350586891174316
Batch 7/64 loss: 0.33067387342453003
Batch 8/64 loss: 0.33392858505249023
Batch 9/64 loss: 0.3324531316757202
Batch 10/64 loss: 0.3310088515281677
Batch 11/64 loss: 0.33139169216156006
Batch 12/64 loss: 0.3340085744857788
Batch 13/64 loss: 0.33539533615112305
Batch 14/64 loss: 0.3329163193702698
Batch 15/64 loss: 0.3273499011993408
Batch 16/64 loss: 0.32702648639678955
Batch 17/64 loss: 0.3305964469909668
Batch 18/64 loss: 0.3268042802810669
Batch 19/64 loss: 0.32822489738464355
Batch 20/64 loss: 0.33122068643569946
Batch 21/64 loss: 0.33356213569641113
Batch 22/64 loss: 0.3284209370613098
Batch 23/64 loss: 0.32989197969436646
Batch 24/64 loss: 0.32812440395355225
Batch 25/64 loss: 0.33012551069259644
Batch 26/64 loss: 0.32654500007629395
Batch 27/64 loss: 0.32725512981414795
Batch 28/64 loss: 0.3301249146461487
Batch 29/64 loss: 0.3361157178878784
Batch 30/64 loss: 0.32928645610809326
Batch 31/64 loss: 0.33508604764938354
Batch 32/64 loss: 0.33211982250213623
Batch 33/64 loss: 0.3332000970840454
Batch 34/64 loss: 0.3273913264274597
Batch 35/64 loss: 0.33071017265319824
Batch 36/64 loss: 0.3280138373374939
Batch 37/64 loss: 0.3303922414779663
Batch 38/64 loss: 0.32719212770462036
Batch 39/64 loss: 0.32713377475738525
Batch 40/64 loss: 0.33185631036758423
Batch 41/64 loss: 0.33576345443725586
Batch 42/64 loss: 0.3307384252548218
Batch 43/64 loss: 0.3296213150024414
Batch 44/64 loss: 0.32767343521118164
Batch 45/64 loss: 0.3328707218170166
Batch 46/64 loss: 0.3299344778060913
Batch 47/64 loss: 0.33453285694122314
Batch 48/64 loss: 0.3258461356163025
Batch 49/64 loss: 0.3291870951652527
Batch 50/64 loss: 0.32847344875335693
Batch 51/64 loss: 0.3339332342147827
Batch 52/64 loss: 0.3269052505493164
Batch 53/64 loss: 0.3263208866119385
Batch 54/64 loss: 0.331085741519928
Batch 55/64 loss: 0.33432984352111816
Batch 56/64 loss: 0.33239948749542236
Batch 57/64 loss: 0.32634150981903076
Batch 58/64 loss: 0.3300037384033203
Batch 59/64 loss: 0.33482229709625244
Batch 60/64 loss: 0.32617324590682983
Batch 61/64 loss: 0.32592374086380005
Batch 62/64 loss: 0.3333892822265625
Batch 63/64 loss: 0.3266109228134155
Batch 64/64 loss: 0.33146196603775024
Epoch 67  Train loss: 0.33033066614001405  Val loss: 0.3363295433037879
Epoch 68
-------------------------------
Batch 1/64 loss: 0.3350721597671509
Batch 2/64 loss: 0.3333985209465027
Batch 3/64 loss: 0.33052945137023926
Batch 4/64 loss: 0.3318016529083252
Batch 5/64 loss: 0.328596293926239
Batch 6/64 loss: 0.32477307319641113
Batch 7/64 loss: 0.3323901891708374
Batch 8/64 loss: 0.32497191429138184
Batch 9/64 loss: 0.331592321395874
Batch 10/64 loss: 0.3247544765472412
Batch 11/64 loss: 0.33652418851852417
Batch 12/64 loss: 0.3295391798019409
Batch 13/64 loss: 0.32646894454956055
Batch 14/64 loss: 0.33534061908721924
Batch 15/64 loss: 0.3271249532699585
Batch 16/64 loss: 0.3259544372558594
Batch 17/64 loss: 0.33098316192626953
Batch 18/64 loss: 0.33187347650527954
Batch 19/64 loss: 0.33023154735565186
Batch 20/64 loss: 0.32758164405822754
Batch 21/64 loss: 0.32796382904052734
Batch 22/64 loss: 0.3294827342033386
Batch 23/64 loss: 0.32305359840393066
Batch 24/64 loss: 0.32504117488861084
Batch 25/64 loss: 0.3244279623031616
Batch 26/64 loss: 0.3286551833152771
Batch 27/64 loss: 0.32970118522644043
Batch 28/64 loss: 0.33702337741851807
Batch 29/64 loss: 0.32721447944641113
Batch 30/64 loss: 0.33480530977249146
Batch 31/64 loss: 0.3289726972579956
Batch 32/64 loss: 0.3290671110153198
Batch 33/64 loss: 0.32951873540878296
Batch 34/64 loss: 0.3255212903022766
Batch 35/64 loss: 0.32963961362838745
Batch 36/64 loss: 0.33144932985305786
Batch 37/64 loss: 0.3292471170425415
Batch 38/64 loss: 0.3307042717933655
Batch 39/64 loss: 0.33613067865371704
Batch 40/64 loss: 0.32911455631256104
Batch 41/64 loss: 0.3289541006088257
Batch 42/64 loss: 0.3322221636772156
Batch 43/64 loss: 0.3288283348083496
Batch 44/64 loss: 0.33178818225860596
Batch 45/64 loss: 0.3355644941329956
Batch 46/64 loss: 0.33212435245513916
Batch 47/64 loss: 0.33064234256744385
Batch 48/64 loss: 0.3319801092147827
Batch 49/64 loss: 0.33156144618988037
Batch 50/64 loss: 0.33145976066589355
Batch 51/64 loss: 0.3286397457122803
Batch 52/64 loss: 0.33172327280044556
Batch 53/64 loss: 0.3284115791320801
Batch 54/64 loss: 0.3316851854324341
Batch 55/64 loss: 0.32843291759490967
Batch 56/64 loss: 0.3299444913864136
Batch 57/64 loss: 0.3282918930053711
Batch 58/64 loss: 0.3331791162490845
Batch 59/64 loss: 0.32960963249206543
Batch 60/64 loss: 0.3264327049255371
Batch 61/64 loss: 0.33521896600723267
Batch 62/64 loss: 0.33067023754119873
Batch 63/64 loss: 0.3264186978340149
Batch 64/64 loss: 0.331992506980896
Epoch 68  Train loss: 0.33002375761667885  Val loss: 0.33710499768404617
Epoch 69
-------------------------------
Batch 1/64 loss: 0.32539260387420654
Batch 2/64 loss: 0.329801082611084
Batch 3/64 loss: 0.33017492294311523
Batch 4/64 loss: 0.3310340642929077
Batch 5/64 loss: 0.3291434049606323
Batch 6/64 loss: 0.32622605562210083
Batch 7/64 loss: 0.3266371488571167
Batch 8/64 loss: 0.33090901374816895
Batch 9/64 loss: 0.3261653184890747
Batch 10/64 loss: 0.3278430700302124
Batch 11/64 loss: 0.3281330466270447
Batch 12/64 loss: 0.32523441314697266
Batch 13/64 loss: 0.3248633146286011
Batch 14/64 loss: 0.3335740566253662
Batch 15/64 loss: 0.32876235246658325
Batch 16/64 loss: 0.32733893394470215
Batch 17/64 loss: 0.3256821632385254
Batch 18/64 loss: 0.33290088176727295
Batch 19/64 loss: 0.33501970767974854
Batch 20/64 loss: 0.3263128399848938
Batch 21/64 loss: 0.33099812269210815
Batch 22/64 loss: 0.33038973808288574
Batch 23/64 loss: 0.3322834372520447
Batch 24/64 loss: 0.3226199150085449
Batch 25/64 loss: 0.334056556224823
Batch 26/64 loss: 0.33148401975631714
Batch 27/64 loss: 0.3297790288925171
Batch 28/64 loss: 0.32609665393829346
Batch 29/64 loss: 0.32869523763656616
Batch 30/64 loss: 0.32217031717300415
Batch 31/64 loss: 0.32911109924316406
Batch 32/64 loss: 0.3276795744895935
Batch 33/64 loss: 0.3313140273094177
Batch 34/64 loss: 0.3289428949356079
Batch 35/64 loss: 0.32471656799316406
Batch 36/64 loss: 0.3309556245803833
Batch 37/64 loss: 0.33057498931884766
Batch 38/64 loss: 0.32508212327957153
Batch 39/64 loss: 0.33378732204437256
Batch 40/64 loss: 0.3268256187438965
Batch 41/64 loss: 0.3280845880508423
Batch 42/64 loss: 0.335366427898407
Batch 43/64 loss: 0.33100688457489014
Batch 44/64 loss: 0.32638001441955566
Batch 45/64 loss: 0.32025372982025146
Batch 46/64 loss: 0.3322184681892395
Batch 47/64 loss: 0.3222843408584595
Batch 48/64 loss: 0.33044493198394775
Batch 49/64 loss: 0.32380402088165283
Batch 50/64 loss: 0.33000648021698
Batch 51/64 loss: 0.3237922191619873
Batch 52/64 loss: 0.328072726726532
Batch 53/64 loss: 0.3318323493003845
Batch 54/64 loss: 0.3235670328140259
Batch 55/64 loss: 0.32809579372406006
Batch 56/64 loss: 0.318928599357605
Batch 57/64 loss: 0.32549941539764404
Batch 58/64 loss: 0.32727378606796265
Batch 59/64 loss: 0.3314821124076843
Batch 60/64 loss: 0.32912516593933105
Batch 61/64 loss: 0.33171361684799194
Batch 62/64 loss: 0.33365917205810547
Batch 63/64 loss: 0.33611106872558594
Batch 64/64 loss: 0.3330562114715576
Epoch 69  Train loss: 0.3285883351868274  Val loss: 0.33539700610531153
Saving best model, epoch: 69
Epoch 70
-------------------------------
Batch 1/64 loss: 0.32938939332962036
Batch 2/64 loss: 0.32625633478164673
Batch 3/64 loss: 0.3294038772583008
Batch 4/64 loss: 0.3322420120239258
Batch 5/64 loss: 0.32909345626831055
Batch 6/64 loss: 0.33545273542404175
Batch 7/64 loss: 0.325527548789978
Batch 8/64 loss: 0.3282659649848938
Batch 9/64 loss: 0.32426774501800537
Batch 10/64 loss: 0.3305455446243286
Batch 11/64 loss: 0.32356804609298706
Batch 12/64 loss: 0.3267442584037781
Batch 13/64 loss: 0.3267395496368408
Batch 14/64 loss: 0.33414459228515625
Batch 15/64 loss: 0.32564693689346313
Batch 16/64 loss: 0.32235240936279297
Batch 17/64 loss: 0.3268628716468811
Batch 18/64 loss: 0.32719022035598755
Batch 19/64 loss: 0.3290666341781616
Batch 20/64 loss: 0.33316731452941895
Batch 21/64 loss: 0.32903802394866943
Batch 22/64 loss: 0.3286197781562805
Batch 23/64 loss: 0.32747530937194824
Batch 24/64 loss: 0.3296473026275635
Batch 25/64 loss: 0.3271033763885498
Batch 26/64 loss: 0.32763242721557617
Batch 27/64 loss: 0.32825225591659546
Batch 28/64 loss: 0.32927846908569336
Batch 29/64 loss: 0.3276142477989197
Batch 30/64 loss: 0.3271595239639282
Batch 31/64 loss: 0.33159035444259644
Batch 32/64 loss: 0.3273860216140747
Batch 33/64 loss: 0.3318060040473938
Batch 34/64 loss: 0.328945517539978
Batch 35/64 loss: 0.32693684101104736
Batch 36/64 loss: 0.323830246925354
Batch 37/64 loss: 0.3354673385620117
Batch 38/64 loss: 0.3246847987174988
Batch 39/64 loss: 0.32672053575515747
Batch 40/64 loss: 0.33081912994384766
Batch 41/64 loss: 0.32788801193237305
Batch 42/64 loss: 0.3253035545349121
Batch 43/64 loss: 0.3312198519706726
Batch 44/64 loss: 0.33567869663238525
Batch 45/64 loss: 0.32322967052459717
Batch 46/64 loss: 0.3258892893791199
Batch 47/64 loss: 0.32635724544525146
Batch 48/64 loss: 0.3299463987350464
Batch 49/64 loss: 0.33151310682296753
Batch 50/64 loss: 0.3220239281654358
Batch 51/64 loss: 0.32622236013412476
Batch 52/64 loss: 0.33371734619140625
Batch 53/64 loss: 0.3313713073730469
Batch 54/64 loss: 0.3339090347290039
Batch 55/64 loss: 0.32608771324157715
Batch 56/64 loss: 0.32539045810699463
Batch 57/64 loss: 0.32977813482284546
Batch 58/64 loss: 0.3255014419555664
Batch 59/64 loss: 0.3358718156814575
Batch 60/64 loss: 0.3294750452041626
Batch 61/64 loss: 0.3319828510284424
Batch 62/64 loss: 0.33481669425964355
Batch 63/64 loss: 0.3234829902648926
Batch 64/64 loss: 0.3267343044281006
Epoch 70  Train loss: 0.32859047253926593  Val loss: 0.33492611773644937
Saving best model, epoch: 70
Epoch 71
-------------------------------
Batch 1/64 loss: 0.32623231410980225
Batch 2/64 loss: 0.32118070125579834
Batch 3/64 loss: 0.3283131718635559
Batch 4/64 loss: 0.3302341103553772
Batch 5/64 loss: 0.3264174461364746
Batch 6/64 loss: 0.32795751094818115
Batch 7/64 loss: 0.32899248600006104
Batch 8/64 loss: 0.32746052742004395
Batch 9/64 loss: 0.32777076959609985
Batch 10/64 loss: 0.32454806566238403
Batch 11/64 loss: 0.3334078788757324
Batch 12/64 loss: 0.3261300325393677
Batch 13/64 loss: 0.32515817880630493
Batch 14/64 loss: 0.3205804228782654
Batch 15/64 loss: 0.3317614197731018
Batch 16/64 loss: 0.3228079080581665
Batch 17/64 loss: 0.33137214183807373
Batch 18/64 loss: 0.32543832063674927
Batch 19/64 loss: 0.3313649892807007
Batch 20/64 loss: 0.32724642753601074
Batch 21/64 loss: 0.32302993535995483
Batch 22/64 loss: 0.33005690574645996
Batch 23/64 loss: 0.32895100116729736
Batch 24/64 loss: 0.32677125930786133
Batch 25/64 loss: 0.3255615234375
Batch 26/64 loss: 0.3267390727996826
Batch 27/64 loss: 0.33544647693634033
Batch 28/64 loss: 0.3279738426208496
Batch 29/64 loss: 0.3230048418045044
Batch 30/64 loss: 0.33943378925323486
Batch 31/64 loss: 0.3242872953414917
Batch 32/64 loss: 0.3238328695297241
Batch 33/64 loss: 0.3307669758796692
Batch 34/64 loss: 0.33044499158859253
Batch 35/64 loss: 0.32223987579345703
Batch 36/64 loss: 0.3256654143333435
Batch 37/64 loss: 0.3274397850036621
Batch 38/64 loss: 0.32635796070098877
Batch 39/64 loss: 0.33007240295410156
Batch 40/64 loss: 0.322878897190094
Batch 41/64 loss: 0.3260418176651001
Batch 42/64 loss: 0.32510530948638916
Batch 43/64 loss: 0.32661205530166626
Batch 44/64 loss: 0.3298511505126953
Batch 45/64 loss: 0.32926446199417114
Batch 46/64 loss: 0.3263356685638428
Batch 47/64 loss: 0.3291918635368347
Batch 48/64 loss: 0.32918643951416016
Batch 49/64 loss: 0.33176541328430176
Batch 50/64 loss: 0.3281644582748413
Batch 51/64 loss: 0.3386911153793335
Batch 52/64 loss: 0.32921355962753296
Batch 53/64 loss: 0.3322737216949463
Batch 54/64 loss: 0.3302602171897888
Batch 55/64 loss: 0.33171403408050537
Batch 56/64 loss: 0.32938432693481445
Batch 57/64 loss: 0.32679176330566406
Batch 58/64 loss: 0.32635998725891113
Batch 59/64 loss: 0.32521378993988037
Batch 60/64 loss: 0.32680803537368774
Batch 61/64 loss: 0.330599844455719
Batch 62/64 loss: 0.3320496082305908
Batch 63/64 loss: 0.3272673487663269
Batch 64/64 loss: 0.33939796686172485
Epoch 71  Train loss: 0.32812587303273816  Val loss: 0.33299911247495934
Saving best model, epoch: 71
Epoch 72
-------------------------------
Batch 1/64 loss: 0.32869017124176025
Batch 2/64 loss: 0.33222222328186035
Batch 3/64 loss: 0.33005648851394653
Batch 4/64 loss: 0.32683801651000977
Batch 5/64 loss: 0.32815253734588623
Batch 6/64 loss: 0.3314061164855957
Batch 7/64 loss: 0.32490217685699463
Batch 8/64 loss: 0.33036965131759644
Batch 9/64 loss: 0.3251720666885376
Batch 10/64 loss: 0.3241158723831177
Batch 11/64 loss: 0.32319509983062744
Batch 12/64 loss: 0.32418954372406006
Batch 13/64 loss: 0.32731300592422485
Batch 14/64 loss: 0.3278266191482544
Batch 15/64 loss: 0.3349263072013855
Batch 16/64 loss: 0.32745683193206787
Batch 17/64 loss: 0.324385404586792
Batch 18/64 loss: 0.32185590267181396
Batch 19/64 loss: 0.3291059136390686
Batch 20/64 loss: 0.32561302185058594
Batch 21/64 loss: 0.32764995098114014
Batch 22/64 loss: 0.3273906707763672
Batch 23/64 loss: 0.3202385902404785
Batch 24/64 loss: 0.32642048597335815
Batch 25/64 loss: 0.32263875007629395
Batch 26/64 loss: 0.326774001121521
Batch 27/64 loss: 0.33056211471557617
Batch 28/64 loss: 0.3270838260650635
Batch 29/64 loss: 0.3222231864929199
Batch 30/64 loss: 0.32469403743743896
Batch 31/64 loss: 0.3297853469848633
Batch 32/64 loss: 0.3250267505645752
Batch 33/64 loss: 0.32487034797668457
Batch 34/64 loss: 0.3332240581512451
Batch 35/64 loss: 0.32954347133636475
Batch 36/64 loss: 0.32989925146102905
Batch 37/64 loss: 0.3301386833190918
Batch 38/64 loss: 0.33025461435317993
Batch 39/64 loss: 0.3329901099205017
Batch 40/64 loss: 0.32194983959198
Batch 41/64 loss: 0.324506938457489
Batch 42/64 loss: 0.3250162601470947
Batch 43/64 loss: 0.3255113363265991
Batch 44/64 loss: 0.3343304395675659
Batch 45/64 loss: 0.33125627040863037
Batch 46/64 loss: 0.3266221880912781
Batch 47/64 loss: 0.3290063142776489
Batch 48/64 loss: 0.3296225070953369
Batch 49/64 loss: 0.32537150382995605
Batch 50/64 loss: 0.32581090927124023
Batch 51/64 loss: 0.32802408933639526
Batch 52/64 loss: 0.32758456468582153
Batch 53/64 loss: 0.33246952295303345
Batch 54/64 loss: 0.32935643196105957
Batch 55/64 loss: 0.33395159244537354
Batch 56/64 loss: 0.3171612620353699
Batch 57/64 loss: 0.328003466129303
Batch 58/64 loss: 0.33193373680114746
Batch 59/64 loss: 0.3247222900390625
Batch 60/64 loss: 0.3258199691772461
Batch 61/64 loss: 0.3266645669937134
Batch 62/64 loss: 0.3278840184211731
Batch 63/64 loss: 0.3262662887573242
Batch 64/64 loss: 0.3266441226005554
Epoch 72  Train loss: 0.32742008812287277  Val loss: 0.33204857631237644
Saving best model, epoch: 72
Epoch 73
-------------------------------
Batch 1/64 loss: 0.32790517807006836
Batch 2/64 loss: 0.3189926743507385
Batch 3/64 loss: 0.32687604427337646
Batch 4/64 loss: 0.32532304525375366
Batch 5/64 loss: 0.3268511891365051
Batch 6/64 loss: 0.32652997970581055
Batch 7/64 loss: 0.31999850273132324
Batch 8/64 loss: 0.32445114850997925
Batch 9/64 loss: 0.3244417905807495
Batch 10/64 loss: 0.3270072937011719
Batch 11/64 loss: 0.3224940299987793
Batch 12/64 loss: 0.32969123125076294
Batch 13/64 loss: 0.3237338066101074
Batch 14/64 loss: 0.32745468616485596
Batch 15/64 loss: 0.32633960247039795
Batch 16/64 loss: 0.3305537700653076
Batch 17/64 loss: 0.3253629207611084
Batch 18/64 loss: 0.3290724754333496
Batch 19/64 loss: 0.32758617401123047
Batch 20/64 loss: 0.3283025026321411
Batch 21/64 loss: 0.32956480979919434
Batch 22/64 loss: 0.3240970969200134
Batch 23/64 loss: 0.3283836841583252
Batch 24/64 loss: 0.32333844900131226
Batch 25/64 loss: 0.32498276233673096
Batch 26/64 loss: 0.3280360698699951
Batch 27/64 loss: 0.3268083930015564
Batch 28/64 loss: 0.3228102922439575
Batch 29/64 loss: 0.3225862979888916
Batch 30/64 loss: 0.3233753442764282
Batch 31/64 loss: 0.32951289415359497
Batch 32/64 loss: 0.3297315239906311
Batch 33/64 loss: 0.33145982027053833
Batch 34/64 loss: 0.3261615037918091
Batch 35/64 loss: 0.3277459144592285
Batch 36/64 loss: 0.32887208461761475
Batch 37/64 loss: 0.3255707025527954
Batch 38/64 loss: 0.3294105529785156
Batch 39/64 loss: 0.3262258768081665
Batch 40/64 loss: 0.321330189704895
Batch 41/64 loss: 0.32092928886413574
Batch 42/64 loss: 0.33011412620544434
Batch 43/64 loss: 0.32089805603027344
Batch 44/64 loss: 0.3342791795730591
Batch 45/64 loss: 0.3266330361366272
Batch 46/64 loss: 0.3282233476638794
Batch 47/64 loss: 0.3267495036125183
Batch 48/64 loss: 0.3279036283493042
Batch 49/64 loss: 0.32684624195098877
Batch 50/64 loss: 0.3296041488647461
Batch 51/64 loss: 0.32892876863479614
Batch 52/64 loss: 0.32564324140548706
Batch 53/64 loss: 0.3296477794647217
Batch 54/64 loss: 0.3284375071525574
Batch 55/64 loss: 0.32894206047058105
Batch 56/64 loss: 0.3303799629211426
Batch 57/64 loss: 0.3279697895050049
Batch 58/64 loss: 0.33007097244262695
Batch 59/64 loss: 0.32970595359802246
Batch 60/64 loss: 0.3304719924926758
Batch 61/64 loss: 0.3320533037185669
Batch 62/64 loss: 0.33205366134643555
Batch 63/64 loss: 0.32026296854019165
Batch 64/64 loss: 0.3250523805618286
Epoch 73  Train loss: 0.32689427628236656  Val loss: 0.33130422592982395
Saving best model, epoch: 73
Epoch 74
-------------------------------
Batch 1/64 loss: 0.32126593589782715
Batch 2/64 loss: 0.32550370693206787
Batch 3/64 loss: 0.32768774032592773
Batch 4/64 loss: 0.3245726227760315
Batch 5/64 loss: 0.32761096954345703
Batch 6/64 loss: 0.33017897605895996
Batch 7/64 loss: 0.32533860206604004
Batch 8/64 loss: 0.3317797780036926
Batch 9/64 loss: 0.32330429553985596
Batch 10/64 loss: 0.31984996795654297
Batch 11/64 loss: 0.3303196430206299
Batch 12/64 loss: 0.3215216398239136
Batch 13/64 loss: 0.32509106397628784
Batch 14/64 loss: 0.32874417304992676
Batch 15/64 loss: 0.323467493057251
Batch 16/64 loss: 0.32734185457229614
Batch 17/64 loss: 0.3259645700454712
Batch 18/64 loss: 0.32636773586273193
Batch 19/64 loss: 0.3274728059768677
Batch 20/64 loss: 0.32997000217437744
Batch 21/64 loss: 0.32658058404922485
Batch 22/64 loss: 0.32659202814102173
Batch 23/64 loss: 0.32605576515197754
Batch 24/64 loss: 0.32335925102233887
Batch 25/64 loss: 0.32937896251678467
Batch 26/64 loss: 0.32678699493408203
Batch 27/64 loss: 0.33131206035614014
Batch 28/64 loss: 0.32805347442626953
Batch 29/64 loss: 0.3258805274963379
Batch 30/64 loss: 0.32790476083755493
Batch 31/64 loss: 0.3322787284851074
Batch 32/64 loss: 0.3238849639892578
Batch 33/64 loss: 0.32272785902023315
Batch 34/64 loss: 0.322873055934906
Batch 35/64 loss: 0.32303547859191895
Batch 36/64 loss: 0.32462358474731445
Batch 37/64 loss: 0.32815277576446533
Batch 38/64 loss: 0.3246692419052124
Batch 39/64 loss: 0.33015012741088867
Batch 40/64 loss: 0.3228747844696045
Batch 41/64 loss: 0.323508083820343
Batch 42/64 loss: 0.32271623611450195
Batch 43/64 loss: 0.32012689113616943
Batch 44/64 loss: 0.32394200563430786
Batch 45/64 loss: 0.3308194875717163
Batch 46/64 loss: 0.32700270414352417
Batch 47/64 loss: 0.3249887228012085
Batch 48/64 loss: 0.32962942123413086
Batch 49/64 loss: 0.3297078609466553
Batch 50/64 loss: 0.3221166133880615
Batch 51/64 loss: 0.3221999406814575
Batch 52/64 loss: 0.32448577880859375
Batch 53/64 loss: 0.33043527603149414
Batch 54/64 loss: 0.3210107088088989
Batch 55/64 loss: 0.3253876566886902
Batch 56/64 loss: 0.33100461959838867
Batch 57/64 loss: 0.3294694423675537
Batch 58/64 loss: 0.3205084204673767
Batch 59/64 loss: 0.31735777854919434
Batch 60/64 loss: 0.3240145444869995
Batch 61/64 loss: 0.33408045768737793
Batch 62/64 loss: 0.32056760787963867
Batch 63/64 loss: 0.32853949069976807
Batch 64/64 loss: 0.3301793336868286
Epoch 74  Train loss: 0.32598875036426617  Val loss: 0.33001314405723126
Saving best model, epoch: 74
Epoch 75
-------------------------------
Batch 1/64 loss: 0.3247504234313965
Batch 2/64 loss: 0.3170583248138428
Batch 3/64 loss: 0.32286351919174194
Batch 4/64 loss: 0.32132261991500854
Batch 5/64 loss: 0.32155996561050415
Batch 6/64 loss: 0.32931697368621826
Batch 7/64 loss: 0.3246957063674927
Batch 8/64 loss: 0.32300865650177
Batch 9/64 loss: 0.328374981880188
Batch 10/64 loss: 0.3251175880432129
Batch 11/64 loss: 0.32620906829833984
Batch 12/64 loss: 0.32895028591156006
Batch 13/64 loss: 0.3241308927536011
Batch 14/64 loss: 0.32744455337524414
Batch 15/64 loss: 0.3276402950286865
Batch 16/64 loss: 0.3225746154785156
Batch 17/64 loss: 0.32076531648635864
Batch 18/64 loss: 0.3291589021682739
Batch 19/64 loss: 0.32274991273880005
Batch 20/64 loss: 0.3293555974960327
Batch 21/64 loss: 0.3242819905281067
Batch 22/64 loss: 0.3202780485153198
Batch 23/64 loss: 0.32558345794677734
Batch 24/64 loss: 0.3292633295059204
Batch 25/64 loss: 0.32314813137054443
Batch 26/64 loss: 0.3307011127471924
Batch 27/64 loss: 0.322223424911499
Batch 28/64 loss: 0.3325232267379761
Batch 29/64 loss: 0.3280521631240845
Batch 30/64 loss: 0.3273437023162842
Batch 31/64 loss: 0.33001863956451416
Batch 32/64 loss: 0.324160099029541
Batch 33/64 loss: 0.3305478096008301
Batch 34/64 loss: 0.3220013380050659
Batch 35/64 loss: 0.32722675800323486
Batch 36/64 loss: 0.3232191801071167
Batch 37/64 loss: 0.32458043098449707
Batch 38/64 loss: 0.3320488929748535
Batch 39/64 loss: 0.32471543550491333
Batch 40/64 loss: 0.3198866844177246
Batch 41/64 loss: 0.3202478289604187
Batch 42/64 loss: 0.3243333101272583
Batch 43/64 loss: 0.323927104473114
Batch 44/64 loss: 0.3271749019622803
Batch 45/64 loss: 0.32556307315826416
Batch 46/64 loss: 0.32667654752731323
Batch 47/64 loss: 0.329950213432312
Batch 48/64 loss: 0.32624155282974243
Batch 49/64 loss: 0.3241288661956787
Batch 50/64 loss: 0.32404452562332153
Batch 51/64 loss: 0.3186652660369873
Batch 52/64 loss: 0.3308875560760498
Batch 53/64 loss: 0.31754791736602783
Batch 54/64 loss: 0.32996225357055664
Batch 55/64 loss: 0.3320201635360718
Batch 56/64 loss: 0.32618939876556396
Batch 57/64 loss: 0.3294060230255127
Batch 58/64 loss: 0.33432531356811523
Batch 59/64 loss: 0.33205747604370117
Batch 60/64 loss: 0.3286042809486389
Batch 61/64 loss: 0.3256317377090454
Batch 62/64 loss: 0.3179924488067627
Batch 63/64 loss: 0.32269835472106934
Batch 64/64 loss: 0.3317866921424866
Epoch 75  Train loss: 0.32574067746891694  Val loss: 0.3324389691205369
Epoch 76
-------------------------------
Batch 1/64 loss: 0.32412660121917725
Batch 2/64 loss: 0.3270964026451111
Batch 3/64 loss: 0.3272048234939575
Batch 4/64 loss: 0.3225595951080322
Batch 5/64 loss: 0.3268510699272156
Batch 6/64 loss: 0.32759344577789307
Batch 7/64 loss: 0.32608526945114136
Batch 8/64 loss: 0.3248671293258667
Batch 9/64 loss: 0.31781136989593506
Batch 10/64 loss: 0.32590270042419434
Batch 11/64 loss: 0.31622302532196045
Batch 12/64 loss: 0.3258640766143799
Batch 13/64 loss: 0.33017265796661377
Batch 14/64 loss: 0.3297889232635498
Batch 15/64 loss: 0.33271050453186035
Batch 16/64 loss: 0.3342958688735962
Batch 17/64 loss: 0.32802218198776245
Batch 18/64 loss: 0.32449954748153687
Batch 19/64 loss: 0.3277522325515747
Batch 20/64 loss: 0.3221316337585449
Batch 21/64 loss: 0.32574570178985596
Batch 22/64 loss: 0.3226848244667053
Batch 23/64 loss: 0.3225787281990051
Batch 24/64 loss: 0.32651787996292114
Batch 25/64 loss: 0.32855260372161865
Batch 26/64 loss: 0.3246263861656189
Batch 27/64 loss: 0.3278934955596924
Batch 28/64 loss: 0.31892240047454834
Batch 29/64 loss: 0.3225058317184448
Batch 30/64 loss: 0.32499462366104126
Batch 31/64 loss: 0.3295326232910156
Batch 32/64 loss: 0.3279452323913574
Batch 33/64 loss: 0.32137542963027954
Batch 34/64 loss: 0.3195772171020508
Batch 35/64 loss: 0.32486408948898315
Batch 36/64 loss: 0.3203788995742798
Batch 37/64 loss: 0.32560431957244873
Batch 38/64 loss: 0.3179800510406494
Batch 39/64 loss: 0.32647764682769775
Batch 40/64 loss: 0.32145875692367554
Batch 41/64 loss: 0.3242861032485962
Batch 42/64 loss: 0.32044804096221924
Batch 43/64 loss: 0.3171900510787964
Batch 44/64 loss: 0.3269493579864502
Batch 45/64 loss: 0.3226245641708374
Batch 46/64 loss: 0.3271205425262451
Batch 47/64 loss: 0.3256540298461914
Batch 48/64 loss: 0.331645131111145
Batch 49/64 loss: 0.3263585567474365
Batch 50/64 loss: 0.33068472146987915
Batch 51/64 loss: 0.32755720615386963
Batch 52/64 loss: 0.3169090151786804
Batch 53/64 loss: 0.32389938831329346
Batch 54/64 loss: 0.3228846788406372
Batch 55/64 loss: 0.31948578357696533
Batch 56/64 loss: 0.3256319761276245
Batch 57/64 loss: 0.32954615354537964
Batch 58/64 loss: 0.32817864418029785
Batch 59/64 loss: 0.3293963670730591
Batch 60/64 loss: 0.33210718631744385
Batch 61/64 loss: 0.317108154296875
Batch 62/64 loss: 0.32082706689834595
Batch 63/64 loss: 0.3256969451904297
Batch 64/64 loss: 0.32300472259521484
Epoch 76  Train loss: 0.32496029816421806  Val loss: 0.3296135371083656
Saving best model, epoch: 76
Epoch 77
-------------------------------
Batch 1/64 loss: 0.3225080966949463
Batch 2/64 loss: 0.3268861770629883
Batch 3/64 loss: 0.3219817876815796
Batch 4/64 loss: 0.3202759623527527
Batch 5/64 loss: 0.3218574523925781
Batch 6/64 loss: 0.32393592596054077
Batch 7/64 loss: 0.3196038007736206
Batch 8/64 loss: 0.3208519220352173
Batch 9/64 loss: 0.32004183530807495
Batch 10/64 loss: 0.3267183303833008
Batch 11/64 loss: 0.3281707763671875
Batch 12/64 loss: 0.3273540139198303
Batch 13/64 loss: 0.3227614164352417
Batch 14/64 loss: 0.3217775225639343
Batch 15/64 loss: 0.32741475105285645
Batch 16/64 loss: 0.32670867443084717
Batch 17/64 loss: 0.32252776622772217
Batch 18/64 loss: 0.3280729055404663
Batch 19/64 loss: 0.3210982084274292
Batch 20/64 loss: 0.32129544019699097
Batch 21/64 loss: 0.3195542097091675
Batch 22/64 loss: 0.329461932182312
Batch 23/64 loss: 0.3242166042327881
Batch 24/64 loss: 0.3308706283569336
Batch 25/64 loss: 0.3237570524215698
Batch 26/64 loss: 0.32245391607284546
Batch 27/64 loss: 0.33661508560180664
Batch 28/64 loss: 0.32682669162750244
Batch 29/64 loss: 0.3320056200027466
Batch 30/64 loss: 0.3311123251914978
Batch 31/64 loss: 0.3230213522911072
Batch 32/64 loss: 0.3252617120742798
Batch 33/64 loss: 0.32498490810394287
Batch 34/64 loss: 0.327511727809906
Batch 35/64 loss: 0.32592833042144775
Batch 36/64 loss: 0.3267998695373535
Batch 37/64 loss: 0.32288289070129395
Batch 38/64 loss: 0.32137972116470337
Batch 39/64 loss: 0.3250678777694702
Batch 40/64 loss: 0.3194936513900757
Batch 41/64 loss: 0.32163381576538086
Batch 42/64 loss: 0.3246653079986572
Batch 43/64 loss: 0.3210598826408386
Batch 44/64 loss: 0.3227836489677429
Batch 45/64 loss: 0.3214711546897888
Batch 46/64 loss: 0.3213561773300171
Batch 47/64 loss: 0.3308805823326111
Batch 48/64 loss: 0.32363373041152954
Batch 49/64 loss: 0.3234734535217285
Batch 50/64 loss: 0.3258678913116455
Batch 51/64 loss: 0.3252061605453491
Batch 52/64 loss: 0.32822680473327637
Batch 53/64 loss: 0.3206912875175476
Batch 54/64 loss: 0.32164740562438965
Batch 55/64 loss: 0.3201444149017334
Batch 56/64 loss: 0.3197089433670044
Batch 57/64 loss: 0.32819080352783203
Batch 58/64 loss: 0.32687675952911377
Batch 59/64 loss: 0.3194742798805237
Batch 60/64 loss: 0.3263578414916992
Batch 61/64 loss: 0.3254503011703491
Batch 62/64 loss: 0.32305431365966797
Batch 63/64 loss: 0.3224097490310669
Batch 64/64 loss: 0.32926732301712036
Epoch 77  Train loss: 0.3244276717597363  Val loss: 0.3327213193952423
Epoch 78
-------------------------------
Batch 1/64 loss: 0.3239806890487671
Batch 2/64 loss: 0.3273526430130005
Batch 3/64 loss: 0.3330853581428528
Batch 4/64 loss: 0.3317107558250427
Batch 5/64 loss: 0.32332032918930054
Batch 6/64 loss: 0.32432425022125244
Batch 7/64 loss: 0.3192150592803955
Batch 8/64 loss: 0.3242894411087036
Batch 9/64 loss: 0.3287961483001709
Batch 10/64 loss: 0.3331024646759033
Batch 11/64 loss: 0.32695311307907104
Batch 12/64 loss: 0.3237670660018921
Batch 13/64 loss: 0.3286610245704651
Batch 14/64 loss: 0.3244389295578003
Batch 15/64 loss: 0.3255470395088196
Batch 16/64 loss: 0.33364343643188477
Batch 17/64 loss: 0.32541704177856445
Batch 18/64 loss: 0.3304784297943115
Batch 19/64 loss: 0.320226788520813
Batch 20/64 loss: 0.32813239097595215
Batch 21/64 loss: 0.32250404357910156
Batch 22/64 loss: 0.3234107494354248
Batch 23/64 loss: 0.3266991376876831
Batch 24/64 loss: 0.3204779028892517
Batch 25/64 loss: 0.31871795654296875
Batch 26/64 loss: 0.3240640163421631
Batch 27/64 loss: 0.3190176486968994
Batch 28/64 loss: 0.3212015628814697
Batch 29/64 loss: 0.32530176639556885
Batch 30/64 loss: 0.32302868366241455
Batch 31/64 loss: 0.32243216037750244
Batch 32/64 loss: 0.32359445095062256
Batch 33/64 loss: 0.3264361619949341
Batch 34/64 loss: 0.3265606164932251
Batch 35/64 loss: 0.32877814769744873
Batch 36/64 loss: 0.32163137197494507
Batch 37/64 loss: 0.322451651096344
Batch 38/64 loss: 0.3225366473197937
Batch 39/64 loss: 0.322873592376709
Batch 40/64 loss: 0.3274228572845459
Batch 41/64 loss: 0.32198071479797363
Batch 42/64 loss: 0.32585036754608154
Batch 43/64 loss: 0.32410889863967896
Batch 44/64 loss: 0.3257089853286743
Batch 45/64 loss: 0.3197122812271118
Batch 46/64 loss: 0.321144700050354
Batch 47/64 loss: 0.32944488525390625
Batch 48/64 loss: 0.32824093103408813
Batch 49/64 loss: 0.3177095651626587
Batch 50/64 loss: 0.32408732175827026
Batch 51/64 loss: 0.31786054372787476
Batch 52/64 loss: 0.32548677921295166
Batch 53/64 loss: 0.32210713624954224
Batch 54/64 loss: 0.3234274387359619
Batch 55/64 loss: 0.32322049140930176
Batch 56/64 loss: 0.3222203254699707
Batch 57/64 loss: 0.32463473081588745
Batch 58/64 loss: 0.32909995317459106
Batch 59/64 loss: 0.3262799382209778
Batch 60/64 loss: 0.32684779167175293
Batch 61/64 loss: 0.3244515061378479
Batch 62/64 loss: 0.3297426700592041
Batch 63/64 loss: 0.32423579692840576
Batch 64/64 loss: 0.31717562675476074
Epoch 78  Train loss: 0.32472265093934305  Val loss: 0.3307226392411694
Epoch 79
-------------------------------
Batch 1/64 loss: 0.3203850984573364
Batch 2/64 loss: 0.31740427017211914
Batch 3/64 loss: 0.3249295949935913
Batch 4/64 loss: 0.3190033435821533
Batch 5/64 loss: 0.3239101767539978
Batch 6/64 loss: 0.33122730255126953
Batch 7/64 loss: 0.31743043661117554
Batch 8/64 loss: 0.32553958892822266
Batch 9/64 loss: 0.32250678539276123
Batch 10/64 loss: 0.3229416012763977
Batch 11/64 loss: 0.3254122734069824
Batch 12/64 loss: 0.3242838382720947
Batch 13/64 loss: 0.3275856375694275
Batch 14/64 loss: 0.32573604583740234
Batch 15/64 loss: 0.319791316986084
Batch 16/64 loss: 0.3228761553764343
Batch 17/64 loss: 0.32139790058135986
Batch 18/64 loss: 0.32696759700775146
Batch 19/64 loss: 0.32997584342956543
Batch 20/64 loss: 0.32519590854644775
Batch 21/64 loss: 0.325908362865448
Batch 22/64 loss: 0.3156841993331909
Batch 23/64 loss: 0.3356834650039673
Batch 24/64 loss: 0.32423460483551025
Batch 25/64 loss: 0.31923651695251465
Batch 26/64 loss: 0.32365119457244873
Batch 27/64 loss: 0.3200123906135559
Batch 28/64 loss: 0.32455354928970337
Batch 29/64 loss: 0.32646119594573975
Batch 30/64 loss: 0.3223075866699219
Batch 31/64 loss: 0.3219031095504761
Batch 32/64 loss: 0.3235645890235901
Batch 33/64 loss: 0.32595741748809814
Batch 34/64 loss: 0.3196728229522705
Batch 35/64 loss: 0.32511603832244873
Batch 36/64 loss: 0.3210521340370178
Batch 37/64 loss: 0.3257409334182739
Batch 38/64 loss: 0.3189927339553833
Batch 39/64 loss: 0.31745415925979614
Batch 40/64 loss: 0.3275911808013916
Batch 41/64 loss: 0.32492291927337646
Batch 42/64 loss: 0.32017624378204346
Batch 43/64 loss: 0.32343244552612305
Batch 44/64 loss: 0.32685983180999756
Batch 45/64 loss: 0.32511627674102783
Batch 46/64 loss: 0.32831883430480957
Batch 47/64 loss: 0.32074689865112305
Batch 48/64 loss: 0.32319217920303345
Batch 49/64 loss: 0.32256650924682617
Batch 50/64 loss: 0.32374852895736694
Batch 51/64 loss: 0.3198910355567932
Batch 52/64 loss: 0.3202214241027832
Batch 53/64 loss: 0.3203001022338867
Batch 54/64 loss: 0.31810468435287476
Batch 55/64 loss: 0.3287004232406616
Batch 56/64 loss: 0.326482892036438
Batch 57/64 loss: 0.3263562321662903
Batch 58/64 loss: 0.31848257780075073
Batch 59/64 loss: 0.3239668607711792
Batch 60/64 loss: 0.33326971530914307
Batch 61/64 loss: 0.3225131630897522
Batch 62/64 loss: 0.32673192024230957
Batch 63/64 loss: 0.3204401135444641
Batch 64/64 loss: 0.3248823881149292
Epoch 79  Train loss: 0.32356835299847175  Val loss: 0.3293018275519827
Saving best model, epoch: 79
Epoch 80
-------------------------------
Batch 1/64 loss: 0.31982094049453735
Batch 2/64 loss: 0.32647645473480225
Batch 3/64 loss: 0.3137550354003906
Batch 4/64 loss: 0.3276739716529846
Batch 5/64 loss: 0.32140153646469116
Batch 6/64 loss: 0.31769615411758423
Batch 7/64 loss: 0.3126066327095032
Batch 8/64 loss: 0.3189106583595276
Batch 9/64 loss: 0.3208022117614746
Batch 10/64 loss: 0.32683706283569336
Batch 11/64 loss: 0.3218960762023926
Batch 12/64 loss: 0.31843388080596924
Batch 13/64 loss: 0.32132476568222046
Batch 14/64 loss: 0.32494205236434937
Batch 15/64 loss: 0.3234771490097046
Batch 16/64 loss: 0.3213091492652893
Batch 17/64 loss: 0.31782400608062744
Batch 18/64 loss: 0.31802916526794434
Batch 19/64 loss: 0.32171952724456787
Batch 20/64 loss: 0.3249856233596802
Batch 21/64 loss: 0.3219870328903198
Batch 22/64 loss: 0.3237994313240051
Batch 23/64 loss: 0.32043468952178955
Batch 24/64 loss: 0.3189544081687927
Batch 25/64 loss: 0.322883665561676
Batch 26/64 loss: 0.3240143060684204
Batch 27/64 loss: 0.3233991861343384
Batch 28/64 loss: 0.31969988346099854
Batch 29/64 loss: 0.3180451989173889
Batch 30/64 loss: 0.32480037212371826
Batch 31/64 loss: 0.3158247470855713
Batch 32/64 loss: 0.3214092254638672
Batch 33/64 loss: 0.323366641998291
Batch 34/64 loss: 0.3244069814682007
Batch 35/64 loss: 0.32825493812561035
Batch 36/64 loss: 0.3224104046821594
Batch 37/64 loss: 0.31989336013793945
Batch 38/64 loss: 0.3298143148422241
Batch 39/64 loss: 0.321826696395874
Batch 40/64 loss: 0.3131605386734009
Batch 41/64 loss: 0.32484734058380127
Batch 42/64 loss: 0.3267778158187866
Batch 43/64 loss: 0.325705349445343
Batch 44/64 loss: 0.32668542861938477
Batch 45/64 loss: 0.322070837020874
Batch 46/64 loss: 0.32744652032852173
Batch 47/64 loss: 0.3254817724227905
Batch 48/64 loss: 0.32508206367492676
Batch 49/64 loss: 0.32093000411987305
Batch 50/64 loss: 0.32701927423477173
Batch 51/64 loss: 0.3306654691696167
Batch 52/64 loss: 0.32623326778411865
Batch 53/64 loss: 0.3157584071159363
Batch 54/64 loss: 0.32616233825683594
Batch 55/64 loss: 0.32090139389038086
Batch 56/64 loss: 0.3191683292388916
Batch 57/64 loss: 0.31494659185409546
Batch 58/64 loss: 0.3247945308685303
Batch 59/64 loss: 0.3251379728317261
Batch 60/64 loss: 0.3176853656768799
Batch 61/64 loss: 0.32894742488861084
Batch 62/64 loss: 0.32635021209716797
Batch 63/64 loss: 0.3209899663925171
Batch 64/64 loss: 0.3210502862930298
Epoch 80  Train loss: 0.3223354269476498  Val loss: 0.3302839087047118
Epoch 81
-------------------------------
Batch 1/64 loss: 0.3220103979110718
Batch 2/64 loss: 0.32064545154571533
Batch 3/64 loss: 0.31617188453674316
Batch 4/64 loss: 0.32833927869796753
Batch 5/64 loss: 0.3265976905822754
Batch 6/64 loss: 0.3239961862564087
Batch 7/64 loss: 0.32640576362609863
Batch 8/64 loss: 0.3248555660247803
Batch 9/64 loss: 0.3290395736694336
Batch 10/64 loss: 0.3206890821456909
Batch 11/64 loss: 0.32990366220474243
Batch 12/64 loss: 0.31921470165252686
Batch 13/64 loss: 0.3213540315628052
Batch 14/64 loss: 0.3250536322593689
Batch 15/64 loss: 0.32245874404907227
Batch 16/64 loss: 0.3235843777656555
Batch 17/64 loss: 0.32101696729660034
Batch 18/64 loss: 0.326862096786499
Batch 19/64 loss: 0.32524633407592773
Batch 20/64 loss: 0.3219698667526245
Batch 21/64 loss: 0.3238958716392517
Batch 22/64 loss: 0.32380664348602295
Batch 23/64 loss: 0.3238048553466797
Batch 24/64 loss: 0.3248786926269531
Batch 25/64 loss: 0.3223893642425537
Batch 26/64 loss: 0.33070439100265503
Batch 27/64 loss: 0.32447779178619385
Batch 28/64 loss: 0.3236449956893921
Batch 29/64 loss: 0.319205641746521
Batch 30/64 loss: 0.3245192766189575
Batch 31/64 loss: 0.32596468925476074
Batch 32/64 loss: 0.32746100425720215
Batch 33/64 loss: 0.3177454471588135
Batch 34/64 loss: 0.32111477851867676
Batch 35/64 loss: 0.32459837198257446
Batch 36/64 loss: 0.31624388694763184
Batch 37/64 loss: 0.32033324241638184
Batch 38/64 loss: 0.31902801990509033
Batch 39/64 loss: 0.32098138332366943
Batch 40/64 loss: 0.31773245334625244
Batch 41/64 loss: 0.32711368799209595
Batch 42/64 loss: 0.323655903339386
Batch 43/64 loss: 0.31684279441833496
Batch 44/64 loss: 0.32483136653900146
Batch 45/64 loss: 0.3201298713684082
Batch 46/64 loss: 0.3170963525772095
Batch 47/64 loss: 0.32444047927856445
Batch 48/64 loss: 0.3264040946960449
Batch 49/64 loss: 0.3252747058868408
Batch 50/64 loss: 0.3215874433517456
Batch 51/64 loss: 0.33164483308792114
Batch 52/64 loss: 0.3184487819671631
Batch 53/64 loss: 0.32060688734054565
Batch 54/64 loss: 0.31812751293182373
Batch 55/64 loss: 0.3255784511566162
Batch 56/64 loss: 0.32077014446258545
Batch 57/64 loss: 0.32487964630126953
Batch 58/64 loss: 0.32452380657196045
Batch 59/64 loss: 0.32903778553009033
Batch 60/64 loss: 0.3185974955558777
Batch 61/64 loss: 0.3214346170425415
Batch 62/64 loss: 0.32328999042510986
Batch 63/64 loss: 0.317657470703125
Batch 64/64 loss: 0.32750898599624634
Epoch 81  Train loss: 0.32306748161128923  Val loss: 0.3276330888066505
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: 0.3218541145324707
Batch 2/64 loss: 0.31627970933914185
Batch 3/64 loss: 0.31780028343200684
Batch 4/64 loss: 0.3220713138580322
Batch 5/64 loss: 0.3239474892616272
Batch 6/64 loss: 0.31634819507598877
Batch 7/64 loss: 0.32721519470214844
Batch 8/64 loss: 0.3208872079849243
Batch 9/64 loss: 0.32224422693252563
Batch 10/64 loss: 0.3194829225540161
Batch 11/64 loss: 0.31847625970840454
Batch 12/64 loss: 0.3227144479751587
Batch 13/64 loss: 0.32137584686279297
Batch 14/64 loss: 0.3259854316711426
Batch 15/64 loss: 0.3187541961669922
Batch 16/64 loss: 0.32439374923706055
Batch 17/64 loss: 0.319945752620697
Batch 18/64 loss: 0.3201092481613159
Batch 19/64 loss: 0.32051944732666016
Batch 20/64 loss: 0.32347631454467773
Batch 21/64 loss: 0.3224562406539917
Batch 22/64 loss: 0.31637197732925415
Batch 23/64 loss: 0.3265366554260254
Batch 24/64 loss: 0.32155704498291016
Batch 25/64 loss: 0.3179956078529358
Batch 26/64 loss: 0.3096945285797119
Batch 27/64 loss: 0.32177913188934326
Batch 28/64 loss: 0.3252089023590088
Batch 29/64 loss: 0.31547749042510986
Batch 30/64 loss: 0.31978273391723633
Batch 31/64 loss: 0.32395970821380615
Batch 32/64 loss: 0.3274359703063965
Batch 33/64 loss: 0.32536613941192627
Batch 34/64 loss: 0.32174479961395264
Batch 35/64 loss: 0.32749366760253906
Batch 36/64 loss: 0.3225383162498474
Batch 37/64 loss: 0.3202371597290039
Batch 38/64 loss: 0.32137417793273926
Batch 39/64 loss: 0.3271436095237732
Batch 40/64 loss: 0.3152848482131958
Batch 41/64 loss: 0.3180501461029053
Batch 42/64 loss: 0.3264976739883423
Batch 43/64 loss: 0.3202474117279053
Batch 44/64 loss: 0.31620025634765625
Batch 45/64 loss: 0.32564520835876465
Batch 46/64 loss: 0.31918203830718994
Batch 47/64 loss: 0.3163720369338989
Batch 48/64 loss: 0.3240004777908325
Batch 49/64 loss: 0.31687384843826294
Batch 50/64 loss: 0.31728363037109375
Batch 51/64 loss: 0.32427752017974854
Batch 52/64 loss: 0.31966590881347656
Batch 53/64 loss: 0.3242506980895996
Batch 54/64 loss: 0.3204408884048462
Batch 55/64 loss: 0.32484298944473267
Batch 56/64 loss: 0.3169372081756592
Batch 57/64 loss: 0.3298209309577942
Batch 58/64 loss: 0.3171525001525879
Batch 59/64 loss: 0.319580078125
Batch 60/64 loss: 0.32280921936035156
Batch 61/64 loss: 0.3256644010543823
Batch 62/64 loss: 0.3212112784385681
Batch 63/64 loss: 0.3273455500602722
Batch 64/64 loss: 0.32639265060424805
Epoch 82  Train loss: 0.3214504541135302  Val loss: 0.32994847609005434
Epoch 83
-------------------------------
Batch 1/64 loss: 0.32235753536224365
Batch 2/64 loss: 0.3235030770301819
Batch 3/64 loss: 0.31756067276000977
Batch 4/64 loss: 0.3218298554420471
Batch 5/64 loss: 0.32251209020614624
Batch 6/64 loss: 0.32165247201919556
Batch 7/64 loss: 0.3197978734970093
Batch 8/64 loss: 0.31887078285217285
Batch 9/64 loss: 0.3184962272644043
Batch 10/64 loss: 0.32700324058532715
Batch 11/64 loss: 0.3171415328979492
Batch 12/64 loss: 0.3257656693458557
Batch 13/64 loss: 0.3264808654785156
Batch 14/64 loss: 0.3261023759841919
Batch 15/64 loss: 0.32029807567596436
Batch 16/64 loss: 0.3211261034011841
Batch 17/64 loss: 0.31989187002182007
Batch 18/64 loss: 0.3258941173553467
Batch 19/64 loss: 0.3220817446708679
Batch 20/64 loss: 0.31887030601501465
Batch 21/64 loss: 0.3177506923675537
Batch 22/64 loss: 0.31970441341400146
Batch 23/64 loss: 0.3287535309791565
Batch 24/64 loss: 0.32188475131988525
Batch 25/64 loss: 0.31798386573791504
Batch 26/64 loss: 0.32399988174438477
Batch 27/64 loss: 0.3229883313179016
Batch 28/64 loss: 0.31413161754608154
Batch 29/64 loss: 0.324243426322937
Batch 30/64 loss: 0.32342857122421265
Batch 31/64 loss: 0.32294249534606934
Batch 32/64 loss: 0.3201965093612671
Batch 33/64 loss: 0.32733404636383057
Batch 34/64 loss: 0.33074951171875
Batch 35/64 loss: 0.315768837928772
Batch 36/64 loss: 0.32052409648895264
Batch 37/64 loss: 0.32173073291778564
Batch 38/64 loss: 0.31962817907333374
Batch 39/64 loss: 0.3194394111633301
Batch 40/64 loss: 0.32438671588897705
Batch 41/64 loss: 0.3154730796813965
Batch 42/64 loss: 0.3256617784500122
Batch 43/64 loss: 0.3214554786682129
Batch 44/64 loss: 0.31808745861053467
Batch 45/64 loss: 0.32563096284866333
Batch 46/64 loss: 0.32002830505371094
Batch 47/64 loss: 0.3210188150405884
Batch 48/64 loss: 0.31636130809783936
Batch 49/64 loss: 0.3196946382522583
Batch 50/64 loss: 0.3246098756790161
Batch 51/64 loss: 0.32254791259765625
Batch 52/64 loss: 0.3183879256248474
Batch 53/64 loss: 0.3182622790336609
Batch 54/64 loss: 0.32357895374298096
Batch 55/64 loss: 0.31192946434020996
Batch 56/64 loss: 0.3204188346862793
Batch 57/64 loss: 0.32113879919052124
Batch 58/64 loss: 0.3273066282272339
Batch 59/64 loss: 0.320331335067749
Batch 60/64 loss: 0.3151201009750366
Batch 61/64 loss: 0.32202035188674927
Batch 62/64 loss: 0.30997616052627563
Batch 63/64 loss: 0.3222757577896118
Batch 64/64 loss: 0.32076340913772583
Epoch 83  Train loss: 0.3212030567374884  Val loss: 0.3279049277715257
Epoch 84
-------------------------------
Batch 1/64 loss: 0.31644588708877563
Batch 2/64 loss: 0.31933867931365967
Batch 3/64 loss: 0.3131725788116455
Batch 4/64 loss: 0.31957459449768066
Batch 5/64 loss: 0.31893789768218994
Batch 6/64 loss: 0.31708192825317383
Batch 7/64 loss: 0.32499128580093384
Batch 8/64 loss: 0.3229961395263672
Batch 9/64 loss: 0.31668907403945923
Batch 10/64 loss: 0.3190625309944153
Batch 11/64 loss: 0.31845927238464355
Batch 12/64 loss: 0.31849169731140137
Batch 13/64 loss: 0.3198888301849365
Batch 14/64 loss: 0.32612740993499756
Batch 15/64 loss: 0.3230706453323364
Batch 16/64 loss: 0.3148886561393738
Batch 17/64 loss: 0.3196523189544678
Batch 18/64 loss: 0.3259390592575073
Batch 19/64 loss: 0.31479692459106445
Batch 20/64 loss: 0.32243984937667847
Batch 21/64 loss: 0.3234822154045105
Batch 22/64 loss: 0.32935667037963867
Batch 23/64 loss: 0.3185325860977173
Batch 24/64 loss: 0.3221595287322998
Batch 25/64 loss: 0.31773531436920166
Batch 26/64 loss: 0.3242242932319641
Batch 27/64 loss: 0.31919223070144653
Batch 28/64 loss: 0.31616467237472534
Batch 29/64 loss: 0.32790160179138184
Batch 30/64 loss: 0.32340478897094727
Batch 31/64 loss: 0.32003843784332275
Batch 32/64 loss: 0.31970030069351196
Batch 33/64 loss: 0.3250277042388916
Batch 34/64 loss: 0.31909680366516113
Batch 35/64 loss: 0.3203936219215393
Batch 36/64 loss: 0.3214225769042969
Batch 37/64 loss: 0.31682848930358887
Batch 38/64 loss: 0.3206658363342285
Batch 39/64 loss: 0.3184064030647278
Batch 40/64 loss: 0.31747472286224365
Batch 41/64 loss: 0.3220714330673218
Batch 42/64 loss: 0.3216240406036377
Batch 43/64 loss: 0.3139227032661438
Batch 44/64 loss: 0.3165419101715088
Batch 45/64 loss: 0.32633769512176514
Batch 46/64 loss: 0.31917691230773926
Batch 47/64 loss: 0.32076495885849
Batch 48/64 loss: 0.321807324886322
Batch 49/64 loss: 0.33157700300216675
Batch 50/64 loss: 0.31747615337371826
Batch 51/64 loss: 0.31605851650238037
Batch 52/64 loss: 0.3096050024032593
Batch 53/64 loss: 0.32539570331573486
Batch 54/64 loss: 0.3292735815048218
Batch 55/64 loss: 0.31683170795440674
Batch 56/64 loss: 0.31860142946243286
Batch 57/64 loss: 0.3181902766227722
Batch 58/64 loss: 0.31673169136047363
Batch 59/64 loss: 0.32538437843322754
Batch 60/64 loss: 0.31704074144363403
Batch 61/64 loss: 0.32570523023605347
Batch 62/64 loss: 0.3223423957824707
Batch 63/64 loss: 0.3248962163925171
Batch 64/64 loss: 0.32072222232818604
Epoch 84  Train loss: 0.3204886702930226  Val loss: 0.3267164250829375
Saving best model, epoch: 84
Epoch 85
-------------------------------
Batch 1/64 loss: 0.31734567880630493
Batch 2/64 loss: 0.31231415271759033
Batch 3/64 loss: 0.31885409355163574
Batch 4/64 loss: 0.3206726312637329
Batch 5/64 loss: 0.32479870319366455
Batch 6/64 loss: 0.3168737292289734
Batch 7/64 loss: 0.32100486755371094
Batch 8/64 loss: 0.3239651918411255
Batch 9/64 loss: 0.31436264514923096
Batch 10/64 loss: 0.31908369064331055
Batch 11/64 loss: 0.3181530237197876
Batch 12/64 loss: 0.3224295973777771
Batch 13/64 loss: 0.320767879486084
Batch 14/64 loss: 0.3132486939430237
Batch 15/64 loss: 0.31562376022338867
Batch 16/64 loss: 0.3156391978263855
Batch 17/64 loss: 0.32335054874420166
Batch 18/64 loss: 0.3213183283805847
Batch 19/64 loss: 0.31546473503112793
Batch 20/64 loss: 0.3225940465927124
Batch 21/64 loss: 0.316997766494751
Batch 22/64 loss: 0.3198733925819397
Batch 23/64 loss: 0.31805598735809326
Batch 24/64 loss: 0.3192567229270935
Batch 25/64 loss: 0.31821346282958984
Batch 26/64 loss: 0.31554198265075684
Batch 27/64 loss: 0.3251485824584961
Batch 28/64 loss: 0.32417434453964233
Batch 29/64 loss: 0.3239205479621887
Batch 30/64 loss: 0.32251012325286865
Batch 31/64 loss: 0.32280606031417847
Batch 32/64 loss: 0.3226360082626343
Batch 33/64 loss: 0.3220387101173401
Batch 34/64 loss: 0.3197265863418579
Batch 35/64 loss: 0.3213379383087158
Batch 36/64 loss: 0.32815372943878174
Batch 37/64 loss: 0.32307302951812744
Batch 38/64 loss: 0.3150482177734375
Batch 39/64 loss: 0.3205382227897644
Batch 40/64 loss: 0.32855820655822754
Batch 41/64 loss: 0.32078802585601807
Batch 42/64 loss: 0.32058751583099365
Batch 43/64 loss: 0.3179418444633484
Batch 44/64 loss: 0.31898820400238037
Batch 45/64 loss: 0.31874948740005493
Batch 46/64 loss: 0.32557547092437744
Batch 47/64 loss: 0.3226117491722107
Batch 48/64 loss: 0.3190861940383911
Batch 49/64 loss: 0.32159483432769775
Batch 50/64 loss: 0.31968510150909424
Batch 51/64 loss: 0.3170809745788574
Batch 52/64 loss: 0.31627315282821655
Batch 53/64 loss: 0.3168313503265381
Batch 54/64 loss: 0.3215465545654297
Batch 55/64 loss: 0.3214571475982666
Batch 56/64 loss: 0.3178974390029907
Batch 57/64 loss: 0.32235777378082275
Batch 58/64 loss: 0.32459819316864014
Batch 59/64 loss: 0.3244743347167969
Batch 60/64 loss: 0.31260228157043457
Batch 61/64 loss: 0.32027506828308105
Batch 62/64 loss: 0.32557594776153564
Batch 63/64 loss: 0.321483850479126
Batch 64/64 loss: 0.3153025507926941
Epoch 85  Train loss: 0.3201570859142378  Val loss: 0.3268669593784817
Epoch 86
-------------------------------
Batch 1/64 loss: 0.31934380531311035
Batch 2/64 loss: 0.31913208961486816
Batch 3/64 loss: 0.31780779361724854
Batch 4/64 loss: 0.3184760808944702
Batch 5/64 loss: 0.3146568536758423
Batch 6/64 loss: 0.3232063055038452
Batch 7/64 loss: 0.32874321937561035
Batch 8/64 loss: 0.3237852454185486
Batch 9/64 loss: 0.31484079360961914
Batch 10/64 loss: 0.31756556034088135
Batch 11/64 loss: 0.3168454170227051
Batch 12/64 loss: 0.3241187334060669
Batch 13/64 loss: 0.32497549057006836
Batch 14/64 loss: 0.32038307189941406
Batch 15/64 loss: 0.3207545876502991
Batch 16/64 loss: 0.31276214122772217
Batch 17/64 loss: 0.31404340267181396
Batch 18/64 loss: 0.31788623332977295
Batch 19/64 loss: 0.3201477527618408
Batch 20/64 loss: 0.317699670791626
Batch 21/64 loss: 0.32255202531814575
Batch 22/64 loss: 0.317609965801239
Batch 23/64 loss: 0.3233494758605957
Batch 24/64 loss: 0.3198343515396118
Batch 25/64 loss: 0.3210268020629883
Batch 26/64 loss: 0.321678102016449
Batch 27/64 loss: 0.3128528594970703
Batch 28/64 loss: 0.32200491428375244
Batch 29/64 loss: 0.3115996718406677
Batch 30/64 loss: 0.32352304458618164
Batch 31/64 loss: 0.32601189613342285
Batch 32/64 loss: 0.32641321420669556
Batch 33/64 loss: 0.31911176443099976
Batch 34/64 loss: 0.31738269329071045
Batch 35/64 loss: 0.32196277379989624
Batch 36/64 loss: 0.32269173860549927
Batch 37/64 loss: 0.31597793102264404
Batch 38/64 loss: 0.31680524349212646
Batch 39/64 loss: 0.3176290988922119
Batch 40/64 loss: 0.3180537819862366
Batch 41/64 loss: 0.31224727630615234
Batch 42/64 loss: 0.32082903385162354
Batch 43/64 loss: 0.31855571269989014
Batch 44/64 loss: 0.31663358211517334
Batch 45/64 loss: 0.3218151330947876
Batch 46/64 loss: 0.31467533111572266
Batch 47/64 loss: 0.3240283727645874
Batch 48/64 loss: 0.3194929361343384
Batch 49/64 loss: 0.3263733386993408
Batch 50/64 loss: 0.3244129419326782
Batch 51/64 loss: 0.3188234567642212
Batch 52/64 loss: 0.32513535022735596
Batch 53/64 loss: 0.3162194490432739
Batch 54/64 loss: 0.31927645206451416
Batch 55/64 loss: 0.3221879005432129
Batch 56/64 loss: 0.3149951696395874
Batch 57/64 loss: 0.32671618461608887
Batch 58/64 loss: 0.31936734914779663
Batch 59/64 loss: 0.3247159719467163
Batch 60/64 loss: 0.32853806018829346
Batch 61/64 loss: 0.32349538803100586
Batch 62/64 loss: 0.32007908821105957
Batch 63/64 loss: 0.31999313831329346
Batch 64/64 loss: 0.3236987590789795
Epoch 86  Train loss: 0.32010394171172496  Val loss: 0.32712709965165127
Epoch 87
-------------------------------
Batch 1/64 loss: 0.3158782124519348
Batch 2/64 loss: 0.3170938491821289
Batch 3/64 loss: 0.3198273181915283
Batch 4/64 loss: 0.3208315372467041
Batch 5/64 loss: 0.3179001808166504
Batch 6/64 loss: 0.32526302337646484
Batch 7/64 loss: 0.3258259892463684
Batch 8/64 loss: 0.3175092935562134
Batch 9/64 loss: 0.3214700222015381
Batch 10/64 loss: 0.3175464868545532
Batch 11/64 loss: 0.3209782838821411
Batch 12/64 loss: 0.3153505325317383
Batch 13/64 loss: 0.32560837268829346
Batch 14/64 loss: 0.3140377998352051
Batch 15/64 loss: 0.3245552182197571
Batch 16/64 loss: 0.31867051124572754
Batch 17/64 loss: 0.3210947513580322
Batch 18/64 loss: 0.317732572555542
Batch 19/64 loss: 0.31670641899108887
Batch 20/64 loss: 0.31305015087127686
Batch 21/64 loss: 0.31611037254333496
Batch 22/64 loss: 0.31848931312561035
Batch 23/64 loss: 0.31518131494522095
Batch 24/64 loss: 0.3198843002319336
Batch 25/64 loss: 0.31647664308547974
Batch 26/64 loss: 0.3157864809036255
Batch 27/64 loss: 0.3205753564834595
Batch 28/64 loss: 0.3196467161178589
Batch 29/64 loss: 0.31748104095458984
Batch 30/64 loss: 0.3166484832763672
Batch 31/64 loss: 0.31547605991363525
Batch 32/64 loss: 0.31166237592697144
Batch 33/64 loss: 0.32093632221221924
Batch 34/64 loss: 0.3176882266998291
Batch 35/64 loss: 0.3177976608276367
Batch 36/64 loss: 0.3185001611709595
Batch 37/64 loss: 0.32546138763427734
Batch 38/64 loss: 0.3155038356781006
Batch 39/64 loss: 0.31974929571151733
Batch 40/64 loss: 0.3221014142036438
Batch 41/64 loss: 0.3208799362182617
Batch 42/64 loss: 0.312444806098938
Batch 43/64 loss: 0.3245503306388855
Batch 44/64 loss: 0.31709015369415283
Batch 45/64 loss: 0.31525546312332153
Batch 46/64 loss: 0.3246881365776062
Batch 47/64 loss: 0.3203463554382324
Batch 48/64 loss: 0.3224413990974426
Batch 49/64 loss: 0.31955015659332275
Batch 50/64 loss: 0.31818193197250366
Batch 51/64 loss: 0.3208083510398865
Batch 52/64 loss: 0.32644808292388916
Batch 53/64 loss: 0.32112962007522583
Batch 54/64 loss: 0.3196144104003906
Batch 55/64 loss: 0.3229936361312866
Batch 56/64 loss: 0.31479573249816895
Batch 57/64 loss: 0.32325029373168945
Batch 58/64 loss: 0.31626105308532715
Batch 59/64 loss: 0.32317471504211426
Batch 60/64 loss: 0.31504905223846436
Batch 61/64 loss: 0.3197152614593506
Batch 62/64 loss: 0.31856513023376465
Batch 63/64 loss: 0.3185073137283325
Batch 64/64 loss: 0.3177037239074707
Epoch 87  Train loss: 0.31909186512816184  Val loss: 0.32598479506895717
Saving best model, epoch: 87
Epoch 88
-------------------------------
Batch 1/64 loss: 0.3233785629272461
Batch 2/64 loss: 0.3175954818725586
Batch 3/64 loss: 0.3159165382385254
Batch 4/64 loss: 0.3194890022277832
Batch 5/64 loss: 0.32475560903549194
Batch 6/64 loss: 0.3131873607635498
Batch 7/64 loss: 0.31591033935546875
Batch 8/64 loss: 0.31940484046936035
Batch 9/64 loss: 0.3175632953643799
Batch 10/64 loss: 0.31893980503082275
Batch 11/64 loss: 0.31789088249206543
Batch 12/64 loss: 0.3251004219055176
Batch 13/64 loss: 0.3198644518852234
Batch 14/64 loss: 0.3236273527145386
Batch 15/64 loss: 0.3229103088378906
Batch 16/64 loss: 0.31951820850372314
Batch 17/64 loss: 0.3215552568435669
Batch 18/64 loss: 0.3166238069534302
Batch 19/64 loss: 0.31596481800079346
Batch 20/64 loss: 0.3182259798049927
Batch 21/64 loss: 0.31942641735076904
Batch 22/64 loss: 0.32024872303009033
Batch 23/64 loss: 0.32628560066223145
Batch 24/64 loss: 0.322365403175354
Batch 25/64 loss: 0.3177981376647949
Batch 26/64 loss: 0.31865811347961426
Batch 27/64 loss: 0.3198421001434326
Batch 28/64 loss: 0.3155118227005005
Batch 29/64 loss: 0.3146531581878662
Batch 30/64 loss: 0.321552574634552
Batch 31/64 loss: 0.3219379782676697
Batch 32/64 loss: 0.3145042061805725
Batch 33/64 loss: 0.3212859630584717
Batch 34/64 loss: 0.3228262662887573
Batch 35/64 loss: 0.319158673286438
Batch 36/64 loss: 0.3163236379623413
Batch 37/64 loss: 0.3163689374923706
Batch 38/64 loss: 0.32554543018341064
Batch 39/64 loss: 0.32475346326828003
Batch 40/64 loss: 0.3169513940811157
Batch 41/64 loss: 0.3252432942390442
Batch 42/64 loss: 0.3273537755012512
Batch 43/64 loss: 0.31709951162338257
Batch 44/64 loss: 0.3237038850784302
Batch 45/64 loss: 0.3223329782485962
Batch 46/64 loss: 0.3183706998825073
Batch 47/64 loss: 0.32241499423980713
Batch 48/64 loss: 0.32587528228759766
Batch 49/64 loss: 0.3182445764541626
Batch 50/64 loss: 0.31534481048583984
Batch 51/64 loss: 0.3135868310928345
Batch 52/64 loss: 0.31365007162094116
Batch 53/64 loss: 0.32163578271865845
Batch 54/64 loss: 0.30622923374176025
Batch 55/64 loss: 0.3262823224067688
Batch 56/64 loss: 0.3283655643463135
Batch 57/64 loss: 0.32132136821746826
Batch 58/64 loss: 0.319973349571228
Batch 59/64 loss: 0.32018929719924927
Batch 60/64 loss: 0.31432127952575684
Batch 61/64 loss: 0.31794989109039307
Batch 62/64 loss: 0.31926947832107544
Batch 63/64 loss: 0.3149603605270386
Batch 64/64 loss: 0.3102707266807556
Epoch 88  Train loss: 0.3195269334549997  Val loss: 0.32807355217917267
Epoch 89
-------------------------------
Batch 1/64 loss: 0.3123694658279419
Batch 2/64 loss: 0.3223453760147095
Batch 3/64 loss: 0.31742870807647705
Batch 4/64 loss: 0.312023401260376
Batch 5/64 loss: 0.31999075412750244
Batch 6/64 loss: 0.32287561893463135
Batch 7/64 loss: 0.3240621089935303
Batch 8/64 loss: 0.3150615692138672
Batch 9/64 loss: 0.31506139039993286
Batch 10/64 loss: 0.32763558626174927
Batch 11/64 loss: 0.3205944299697876
Batch 12/64 loss: 0.32070034742355347
Batch 13/64 loss: 0.31525248289108276
Batch 14/64 loss: 0.31809449195861816
Batch 15/64 loss: 0.31823062896728516
Batch 16/64 loss: 0.31369131803512573
Batch 17/64 loss: 0.3185340166091919
Batch 18/64 loss: 0.31516098976135254
Batch 19/64 loss: 0.3170683979988098
Batch 20/64 loss: 0.3198334574699402
Batch 21/64 loss: 0.31969398260116577
Batch 22/64 loss: 0.31481724977493286
Batch 23/64 loss: 0.3235350251197815
Batch 24/64 loss: 0.3142804503440857
Batch 25/64 loss: 0.31743836402893066
Batch 26/64 loss: 0.3241267204284668
Batch 27/64 loss: 0.3203051686286926
Batch 28/64 loss: 0.3152928352355957
Batch 29/64 loss: 0.31444990634918213
Batch 30/64 loss: 0.3218895196914673
Batch 31/64 loss: 0.3178713321685791
Batch 32/64 loss: 0.3190886974334717
Batch 33/64 loss: 0.32095175981521606
Batch 34/64 loss: 0.31438148021698
Batch 35/64 loss: 0.3204457759857178
Batch 36/64 loss: 0.3194769620895386
Batch 37/64 loss: 0.3174060583114624
Batch 38/64 loss: 0.30998992919921875
Batch 39/64 loss: 0.317996084690094
Batch 40/64 loss: 0.31259024143218994
Batch 41/64 loss: 0.31673967838287354
Batch 42/64 loss: 0.31606537103652954
Batch 43/64 loss: 0.32180941104888916
Batch 44/64 loss: 0.3139287233352661
Batch 45/64 loss: 0.31490182876586914
Batch 46/64 loss: 0.31385940313339233
Batch 47/64 loss: 0.31972992420196533
Batch 48/64 loss: 0.31616538763046265
Batch 49/64 loss: 0.3153902292251587
Batch 50/64 loss: 0.3200804591178894
Batch 51/64 loss: 0.32237088680267334
Batch 52/64 loss: 0.3176194429397583
Batch 53/64 loss: 0.31718122959136963
Batch 54/64 loss: 0.3120235204696655
Batch 55/64 loss: 0.31823039054870605
Batch 56/64 loss: 0.3184396028518677
Batch 57/64 loss: 0.3135814666748047
Batch 58/64 loss: 0.31994760036468506
Batch 59/64 loss: 0.3178321123123169
Batch 60/64 loss: 0.31014204025268555
Batch 61/64 loss: 0.31877970695495605
Batch 62/64 loss: 0.3302805423736572
Batch 63/64 loss: 0.3126142621040344
Batch 64/64 loss: 0.31560713052749634
Epoch 89  Train loss: 0.3177484023804758  Val loss: 0.3246662981321722
Saving best model, epoch: 89
Epoch 90
-------------------------------
Batch 1/64 loss: 0.3173987865447998
Batch 2/64 loss: 0.31612998247146606
Batch 3/64 loss: 0.3159526586532593
Batch 4/64 loss: 0.3086845874786377
Batch 5/64 loss: 0.3102908730506897
Batch 6/64 loss: 0.3172951936721802
Batch 7/64 loss: 0.320611834526062
Batch 8/64 loss: 0.31373780965805054
Batch 9/64 loss: 0.31126487255096436
Batch 10/64 loss: 0.31492966413497925
Batch 11/64 loss: 0.31922709941864014
Batch 12/64 loss: 0.32103824615478516
Batch 13/64 loss: 0.32462364435195923
Batch 14/64 loss: 0.3158838152885437
Batch 15/64 loss: 0.31801438331604004
Batch 16/64 loss: 0.3136442303657532
Batch 17/64 loss: 0.3182857036590576
Batch 18/64 loss: 0.3173724412918091
Batch 19/64 loss: 0.30844926834106445
Batch 20/64 loss: 0.31480079889297485
Batch 21/64 loss: 0.31775152683258057
Batch 22/64 loss: 0.31684017181396484
Batch 23/64 loss: 0.3181666135787964
Batch 24/64 loss: 0.3150184154510498
Batch 25/64 loss: 0.319596529006958
Batch 26/64 loss: 0.3160303235054016
Batch 27/64 loss: 0.32200419902801514
Batch 28/64 loss: 0.3178195357322693
Batch 29/64 loss: 0.3107781410217285
Batch 30/64 loss: 0.3180629014968872
Batch 31/64 loss: 0.32428932189941406
Batch 32/64 loss: 0.31367403268814087
Batch 33/64 loss: 0.31148529052734375
Batch 34/64 loss: 0.3147890567779541
Batch 35/64 loss: 0.3146691918373108
Batch 36/64 loss: 0.3195440173149109
Batch 37/64 loss: 0.31772172451019287
Batch 38/64 loss: 0.3211491107940674
Batch 39/64 loss: 0.32492780685424805
Batch 40/64 loss: 0.3158146142959595
Batch 41/64 loss: 0.32328230142593384
Batch 42/64 loss: 0.3200267553329468
Batch 43/64 loss: 0.32178378105163574
Batch 44/64 loss: 0.32038259506225586
Batch 45/64 loss: 0.31584441661834717
Batch 46/64 loss: 0.3135222792625427
Batch 47/64 loss: 0.32194405794143677
Batch 48/64 loss: 0.32481008768081665
Batch 49/64 loss: 0.31200528144836426
Batch 50/64 loss: 0.31815576553344727
Batch 51/64 loss: 0.3248927593231201
Batch 52/64 loss: 0.3160474896430969
Batch 53/64 loss: 0.3158387541770935
Batch 54/64 loss: 0.32266879081726074
Batch 55/64 loss: 0.31720662117004395
Batch 56/64 loss: 0.31560850143432617
Batch 57/64 loss: 0.3142659664154053
Batch 58/64 loss: 0.31791913509368896
Batch 59/64 loss: 0.3233972191810608
Batch 60/64 loss: 0.311994731426239
Batch 61/64 loss: 0.3125995397567749
Batch 62/64 loss: 0.32173776626586914
Batch 63/64 loss: 0.31747889518737793
Batch 64/64 loss: 0.314849853515625
Epoch 90  Train loss: 0.3172912831399955  Val loss: 0.3271028313440146
Epoch 91
-------------------------------
Batch 1/64 loss: 0.3195246458053589
Batch 2/64 loss: 0.3229804039001465
Batch 3/64 loss: 0.3129093647003174
Batch 4/64 loss: 0.31972968578338623
Batch 5/64 loss: 0.3133736252784729
Batch 6/64 loss: 0.3152329921722412
Batch 7/64 loss: 0.31495022773742676
Batch 8/64 loss: 0.31562310457229614
Batch 9/64 loss: 0.31299448013305664
Batch 10/64 loss: 0.3152666687965393
Batch 11/64 loss: 0.3227194547653198
Batch 12/64 loss: 0.3198081851005554
Batch 13/64 loss: 0.32718998193740845
Batch 14/64 loss: 0.31737667322158813
Batch 15/64 loss: 0.31491732597351074
Batch 16/64 loss: 0.3228745460510254
Batch 17/64 loss: 0.3151901960372925
Batch 18/64 loss: 0.31292450428009033
Batch 19/64 loss: 0.3115859031677246
Batch 20/64 loss: 0.3116183280944824
Batch 21/64 loss: 0.3216401934623718
Batch 22/64 loss: 0.3172038793563843
Batch 23/64 loss: 0.3148341178894043
Batch 24/64 loss: 0.3173946142196655
Batch 25/64 loss: 0.31350475549697876
Batch 26/64 loss: 0.31744635105133057
Batch 27/64 loss: 0.32294636964797974
Batch 28/64 loss: 0.31232136487960815
Batch 29/64 loss: 0.3128439784049988
Batch 30/64 loss: 0.318109929561615
Batch 31/64 loss: 0.31415855884552
Batch 32/64 loss: 0.31197798252105713
Batch 33/64 loss: 0.30930471420288086
Batch 34/64 loss: 0.31503617763519287
Batch 35/64 loss: 0.3177694082260132
Batch 36/64 loss: 0.3193925619125366
Batch 37/64 loss: 0.31666111946105957
Batch 38/64 loss: 0.3127998113632202
Batch 39/64 loss: 0.31133437156677246
Batch 40/64 loss: 0.3151586055755615
Batch 41/64 loss: 0.31681132316589355
Batch 42/64 loss: 0.3081313371658325
Batch 43/64 loss: 0.31523793935775757
Batch 44/64 loss: 0.3206931948661804
Batch 45/64 loss: 0.32466357946395874
Batch 46/64 loss: 0.3155447244644165
Batch 47/64 loss: 0.31736648082733154
Batch 48/64 loss: 0.3184468746185303
Batch 49/64 loss: 0.3222426176071167
Batch 50/64 loss: 0.3168870210647583
Batch 51/64 loss: 0.31478649377822876
Batch 52/64 loss: 0.32164669036865234
Batch 53/64 loss: 0.320407509803772
Batch 54/64 loss: 0.31799352169036865
Batch 55/64 loss: 0.32172417640686035
Batch 56/64 loss: 0.31984782218933105
Batch 57/64 loss: 0.317618727684021
Batch 58/64 loss: 0.32208144664764404
Batch 59/64 loss: 0.328522264957428
Batch 60/64 loss: 0.31352269649505615
Batch 61/64 loss: 0.32098859548568726
Batch 62/64 loss: 0.31359124183654785
Batch 63/64 loss: 0.3158714771270752
Batch 64/64 loss: 0.31062281131744385
Epoch 91  Train loss: 0.3169917494642968  Val loss: 0.32499460809419245
Epoch 92
-------------------------------
Batch 1/64 loss: 0.3130769729614258
Batch 2/64 loss: 0.3234783411026001
Batch 3/64 loss: 0.3138483762741089
Batch 4/64 loss: 0.31874024868011475
Batch 5/64 loss: 0.3143136501312256
Batch 6/64 loss: 0.3129281997680664
Batch 7/64 loss: 0.3164774179458618
Batch 8/64 loss: 0.31346046924591064
Batch 9/64 loss: 0.3163909912109375
Batch 10/64 loss: 0.3115447759628296
Batch 11/64 loss: 0.3096066117286682
Batch 12/64 loss: 0.3197593688964844
Batch 13/64 loss: 0.319439172744751
Batch 14/64 loss: 0.31328678131103516
Batch 15/64 loss: 0.31822776794433594
Batch 16/64 loss: 0.32177096605300903
Batch 17/64 loss: 0.3206254243850708
Batch 18/64 loss: 0.31576967239379883
Batch 19/64 loss: 0.3156306743621826
Batch 20/64 loss: 0.3210254907608032
Batch 21/64 loss: 0.3188105821609497
Batch 22/64 loss: 0.3218005299568176
Batch 23/64 loss: 0.3143375515937805
Batch 24/64 loss: 0.314839243888855
Batch 25/64 loss: 0.3176674246788025
Batch 26/64 loss: 0.31786978244781494
Batch 27/64 loss: 0.3173096179962158
Batch 28/64 loss: 0.3128874897956848
Batch 29/64 loss: 0.3164241313934326
Batch 30/64 loss: 0.31175750494003296
Batch 31/64 loss: 0.3163410425186157
Batch 32/64 loss: 0.3175610303878784
Batch 33/64 loss: 0.31381577253341675
Batch 34/64 loss: 0.3141767978668213
Batch 35/64 loss: 0.32033562660217285
Batch 36/64 loss: 0.31442463397979736
Batch 37/64 loss: 0.3155617117881775
Batch 38/64 loss: 0.3233398199081421
Batch 39/64 loss: 0.3176702857017517
Batch 40/64 loss: 0.31418609619140625
Batch 41/64 loss: 0.31479549407958984
Batch 42/64 loss: 0.31471890211105347
Batch 43/64 loss: 0.3185654878616333
Batch 44/64 loss: 0.3055793046951294
Batch 45/64 loss: 0.31550300121307373
Batch 46/64 loss: 0.3208826184272766
Batch 47/64 loss: 0.3233225345611572
Batch 48/64 loss: 0.31245672702789307
Batch 49/64 loss: 0.31525272130966187
Batch 50/64 loss: 0.31806468963623047
Batch 51/64 loss: 0.31388652324676514
Batch 52/64 loss: 0.3148653507232666
Batch 53/64 loss: 0.310660719871521
Batch 54/64 loss: 0.316280722618103
Batch 55/64 loss: 0.31404101848602295
Batch 56/64 loss: 0.31616467237472534
Batch 57/64 loss: 0.32311058044433594
Batch 58/64 loss: 0.3207986354827881
Batch 59/64 loss: 0.3108057975769043
Batch 60/64 loss: 0.3089466094970703
Batch 61/64 loss: 0.30948328971862793
Batch 62/64 loss: 0.3200685977935791
Batch 63/64 loss: 0.3153795003890991
Batch 64/64 loss: 0.32233375310897827
Epoch 92  Train loss: 0.31617100963405537  Val loss: 0.323106084492608
Saving best model, epoch: 92
Epoch 93
-------------------------------
Batch 1/64 loss: 0.3148149847984314
Batch 2/64 loss: 0.3129611015319824
Batch 3/64 loss: 0.31681734323501587
Batch 4/64 loss: 0.3150966167449951
Batch 5/64 loss: 0.3146452307701111
Batch 6/64 loss: 0.32138776779174805
Batch 7/64 loss: 0.31236016750335693
Batch 8/64 loss: 0.3131696581840515
Batch 9/64 loss: 0.31470054388046265
Batch 10/64 loss: 0.30930018424987793
Batch 11/64 loss: 0.31382203102111816
Batch 12/64 loss: 0.3134620189666748
Batch 13/64 loss: 0.3206578493118286
Batch 14/64 loss: 0.3118598461151123
Batch 15/64 loss: 0.319186806678772
Batch 16/64 loss: 0.32228803634643555
Batch 17/64 loss: 0.32104140520095825
Batch 18/64 loss: 0.3150637745857239
Batch 19/64 loss: 0.3224702477455139
Batch 20/64 loss: 0.31464338302612305
Batch 21/64 loss: 0.3172191381454468
Batch 22/64 loss: 0.31679046154022217
Batch 23/64 loss: 0.32722485065460205
Batch 24/64 loss: 0.3144831657409668
Batch 25/64 loss: 0.3129301071166992
Batch 26/64 loss: 0.3217540979385376
Batch 27/64 loss: 0.32028764486312866
Batch 28/64 loss: 0.3122570514678955
Batch 29/64 loss: 0.3206249475479126
Batch 30/64 loss: 0.31803733110427856
Batch 31/64 loss: 0.31989842653274536
Batch 32/64 loss: 0.3177598714828491
Batch 33/64 loss: 0.3172428607940674
Batch 34/64 loss: 0.3199225664138794
Batch 35/64 loss: 0.3115370273590088
Batch 36/64 loss: 0.31600064039230347
Batch 37/64 loss: 0.32013142108917236
Batch 38/64 loss: 0.31311148405075073
Batch 39/64 loss: 0.311195969581604
Batch 40/64 loss: 0.31596672534942627
Batch 41/64 loss: 0.3148460388183594
Batch 42/64 loss: 0.3236347436904907
Batch 43/64 loss: 0.3214276432991028
Batch 44/64 loss: 0.32617974281311035
Batch 45/64 loss: 0.31348228454589844
Batch 46/64 loss: 0.31822407245635986
Batch 47/64 loss: 0.3170841336250305
Batch 48/64 loss: 0.3138723373413086
Batch 49/64 loss: 0.3120262622833252
Batch 50/64 loss: 0.3106819987297058
Batch 51/64 loss: 0.3209507465362549
Batch 52/64 loss: 0.3123338222503662
Batch 53/64 loss: 0.3182082772254944
Batch 54/64 loss: 0.32821226119995117
Batch 55/64 loss: 0.31538641452789307
Batch 56/64 loss: 0.32106029987335205
Batch 57/64 loss: 0.3139316439628601
Batch 58/64 loss: 0.31814372539520264
Batch 59/64 loss: 0.31083154678344727
Batch 60/64 loss: 0.31048357486724854
Batch 61/64 loss: 0.3110809326171875
Batch 62/64 loss: 0.3151925802230835
Batch 63/64 loss: 0.31572186946868896
Batch 64/64 loss: 0.30966395139694214
Epoch 93  Train loss: 0.3165391325950623  Val loss: 0.32336678128062246
Epoch 94
-------------------------------
Batch 1/64 loss: 0.3165910840034485
Batch 2/64 loss: 0.3077648878097534
Batch 3/64 loss: 0.31844663619995117
Batch 4/64 loss: 0.3152463436126709
Batch 5/64 loss: 0.32019907236099243
Batch 6/64 loss: 0.3070802688598633
Batch 7/64 loss: 0.3193241357803345
Batch 8/64 loss: 0.31981849670410156
Batch 9/64 loss: 0.30866849422454834
Batch 10/64 loss: 0.30915355682373047
Batch 11/64 loss: 0.3058953285217285
Batch 12/64 loss: 0.31598806381225586
Batch 13/64 loss: 0.31861448287963867
Batch 14/64 loss: 0.316983699798584
Batch 15/64 loss: 0.31347227096557617
Batch 16/64 loss: 0.31805169582366943
Batch 17/64 loss: 0.3113129138946533
Batch 18/64 loss: 0.3179042935371399
Batch 19/64 loss: 0.3151804208755493
Batch 20/64 loss: 0.3140299916267395
Batch 21/64 loss: 0.3070324659347534
Batch 22/64 loss: 0.31148719787597656
Batch 23/64 loss: 0.30989742279052734
Batch 24/64 loss: 0.3183661103248596
Batch 25/64 loss: 0.313318133354187
Batch 26/64 loss: 0.31910645961761475
Batch 27/64 loss: 0.31387531757354736
Batch 28/64 loss: 0.31949669122695923
Batch 29/64 loss: 0.31945711374282837
Batch 30/64 loss: 0.31652355194091797
Batch 31/64 loss: 0.31234240531921387
Batch 32/64 loss: 0.3158178925514221
Batch 33/64 loss: 0.31686198711395264
Batch 34/64 loss: 0.31442791223526
Batch 35/64 loss: 0.31140202283859253
Batch 36/64 loss: 0.3149093985557556
Batch 37/64 loss: 0.310512900352478
Batch 38/64 loss: 0.31716418266296387
Batch 39/64 loss: 0.3160339593887329
Batch 40/64 loss: 0.31483376026153564
Batch 41/64 loss: 0.3196260929107666
Batch 42/64 loss: 0.31191569566726685
Batch 43/64 loss: 0.3192785978317261
Batch 44/64 loss: 0.3191291093826294
Batch 45/64 loss: 0.31818968057632446
Batch 46/64 loss: 0.30955004692077637
Batch 47/64 loss: 0.31605958938598633
Batch 48/64 loss: 0.3131706118583679
Batch 49/64 loss: 0.32672667503356934
Batch 50/64 loss: 0.3219987750053406
Batch 51/64 loss: 0.30718594789505005
Batch 52/64 loss: 0.31395769119262695
Batch 53/64 loss: 0.3126333951950073
Batch 54/64 loss: 0.31988853216171265
Batch 55/64 loss: 0.31229639053344727
Batch 56/64 loss: 0.3205437660217285
Batch 57/64 loss: 0.3108445405960083
Batch 58/64 loss: 0.32055020332336426
Batch 59/64 loss: 0.3120310306549072
Batch 60/64 loss: 0.3242114782333374
Batch 61/64 loss: 0.3159852623939514
Batch 62/64 loss: 0.3141339421272278
Batch 63/64 loss: 0.31655019521713257
Batch 64/64 loss: 0.3097264766693115
Epoch 94  Train loss: 0.31515835500230976  Val loss: 0.3236283072081628
Epoch 95
-------------------------------
Batch 1/64 loss: 0.31447941064834595
Batch 2/64 loss: 0.3091343641281128
Batch 3/64 loss: 0.31771939992904663
Batch 4/64 loss: 0.31887125968933105
Batch 5/64 loss: 0.3138844966888428
Batch 6/64 loss: 0.3148747682571411
Batch 7/64 loss: 0.3133772611618042
Batch 8/64 loss: 0.31081610918045044
Batch 9/64 loss: 0.3093438148498535
Batch 10/64 loss: 0.31451451778411865
Batch 11/64 loss: 0.31067991256713867
Batch 12/64 loss: 0.30920571088790894
Batch 13/64 loss: 0.31247347593307495
Batch 14/64 loss: 0.3119388222694397
Batch 15/64 loss: 0.3186125159263611
Batch 16/64 loss: 0.30799341201782227
Batch 17/64 loss: 0.31580179929733276
Batch 18/64 loss: 0.30922001600265503
Batch 19/64 loss: 0.320060133934021
Batch 20/64 loss: 0.30706965923309326
Batch 21/64 loss: 0.32128894329071045
Batch 22/64 loss: 0.310544490814209
Batch 23/64 loss: 0.31918227672576904
Batch 24/64 loss: 0.3158341646194458
Batch 25/64 loss: 0.3151916265487671
Batch 26/64 loss: 0.3141448497772217
Batch 27/64 loss: 0.31255799531936646
Batch 28/64 loss: 0.31118160486221313
Batch 29/64 loss: 0.32073974609375
Batch 30/64 loss: 0.3131742477416992
Batch 31/64 loss: 0.3230476975440979
Batch 32/64 loss: 0.3117173910140991
Batch 33/64 loss: 0.31509673595428467
Batch 34/64 loss: 0.32080864906311035
Batch 35/64 loss: 0.3072783946990967
Batch 36/64 loss: 0.31487083435058594
Batch 37/64 loss: 0.3153010606765747
Batch 38/64 loss: 0.31235605478286743
Batch 39/64 loss: 0.3074876070022583
Batch 40/64 loss: 0.3126561641693115
Batch 41/64 loss: 0.318081259727478
Batch 42/64 loss: 0.3191426396369934
Batch 43/64 loss: 0.317122220993042
Batch 44/64 loss: 0.31602025032043457
Batch 45/64 loss: 0.31880033016204834
Batch 46/64 loss: 0.3129767179489136
Batch 47/64 loss: 0.30844956636428833
Batch 48/64 loss: 0.3194357752799988
Batch 49/64 loss: 0.3139932155609131
Batch 50/64 loss: 0.3187530040740967
Batch 51/64 loss: 0.3182826042175293
Batch 52/64 loss: 0.31696265935897827
Batch 53/64 loss: 0.31310904026031494
Batch 54/64 loss: 0.3118954300880432
Batch 55/64 loss: 0.31090497970581055
Batch 56/64 loss: 0.31227827072143555
Batch 57/64 loss: 0.331514835357666
Batch 58/64 loss: 0.32242918014526367
Batch 59/64 loss: 0.31011414527893066
Batch 60/64 loss: 0.31473982334136963
Batch 61/64 loss: 0.3226954936981201
Batch 62/64 loss: 0.3204544186592102
Batch 63/64 loss: 0.3074702024459839
Batch 64/64 loss: 0.31626760959625244
Epoch 95  Train loss: 0.314782088878108  Val loss: 0.32267489855232107
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: 0.32128632068634033
Batch 2/64 loss: 0.3081558346748352
Batch 3/64 loss: 0.3141874670982361
Batch 4/64 loss: 0.314289391040802
Batch 5/64 loss: 0.3106113076210022
Batch 6/64 loss: 0.31110531091690063
Batch 7/64 loss: 0.317202091217041
Batch 8/64 loss: 0.3157876133918762
Batch 9/64 loss: 0.31412792205810547
Batch 10/64 loss: 0.3129199743270874
Batch 11/64 loss: 0.3202453851699829
Batch 12/64 loss: 0.3164621591567993
Batch 13/64 loss: 0.31889593601226807
Batch 14/64 loss: 0.31240785121917725
Batch 15/64 loss: 0.31073498725891113
Batch 16/64 loss: 0.315775990486145
Batch 17/64 loss: 0.3160895109176636
Batch 18/64 loss: 0.31667155027389526
Batch 19/64 loss: 0.32012999057769775
Batch 20/64 loss: 0.3157174587249756
Batch 21/64 loss: 0.3088052272796631
Batch 22/64 loss: 0.3123600482940674
Batch 23/64 loss: 0.3093085289001465
Batch 24/64 loss: 0.31007814407348633
Batch 25/64 loss: 0.31964850425720215
Batch 26/64 loss: 0.30845773220062256
Batch 27/64 loss: 0.32700788974761963
Batch 28/64 loss: 0.30678290128707886
Batch 29/64 loss: 0.31261110305786133
Batch 30/64 loss: 0.3126509189605713
Batch 31/64 loss: 0.3153005838394165
Batch 32/64 loss: 0.3165781497955322
Batch 33/64 loss: 0.3165156841278076
Batch 34/64 loss: 0.3117886185646057
Batch 35/64 loss: 0.30908679962158203
Batch 36/64 loss: 0.3149714469909668
Batch 37/64 loss: 0.31532180309295654
Batch 38/64 loss: 0.3159973621368408
Batch 39/64 loss: 0.3124960660934448
Batch 40/64 loss: 0.3072624206542969
Batch 41/64 loss: 0.3089367747306824
Batch 42/64 loss: 0.31606656312942505
Batch 43/64 loss: 0.32058167457580566
Batch 44/64 loss: 0.3190450668334961
Batch 45/64 loss: 0.31529659032821655
Batch 46/64 loss: 0.31111210584640503
Batch 47/64 loss: 0.315263032913208
Batch 48/64 loss: 0.3161332607269287
Batch 49/64 loss: 0.3125278949737549
Batch 50/64 loss: 0.3047105669975281
Batch 51/64 loss: 0.31097447872161865
Batch 52/64 loss: 0.31346559524536133
Batch 53/64 loss: 0.3091340661048889
Batch 54/64 loss: 0.3138757348060608
Batch 55/64 loss: 0.3190602660179138
Batch 56/64 loss: 0.3160444498062134
Batch 57/64 loss: 0.3130568265914917
Batch 58/64 loss: 0.3135634660720825
Batch 59/64 loss: 0.31460797786712646
Batch 60/64 loss: 0.3195674419403076
Batch 61/64 loss: 0.31497883796691895
Batch 62/64 loss: 0.31115949153900146
Batch 63/64 loss: 0.3126002550125122
Batch 64/64 loss: 0.321181058883667
Epoch 96  Train loss: 0.314172269783768  Val loss: 0.32165738540826383
Saving best model, epoch: 96
Epoch 97
-------------------------------
Batch 1/64 loss: 0.3129347562789917
Batch 2/64 loss: 0.31498897075653076
Batch 3/64 loss: 0.3228415250778198
Batch 4/64 loss: 0.3112293481826782
Batch 5/64 loss: 0.3101762533187866
Batch 6/64 loss: 0.3164733052253723
Batch 7/64 loss: 0.31166791915893555
Batch 8/64 loss: 0.32469701766967773
Batch 9/64 loss: 0.31275027990341187
Batch 10/64 loss: 0.320784330368042
Batch 11/64 loss: 0.3114522099494934
Batch 12/64 loss: 0.311062753200531
Batch 13/64 loss: 0.3088228702545166
Batch 14/64 loss: 0.31196731328964233
Batch 15/64 loss: 0.3189491033554077
Batch 16/64 loss: 0.3119077682495117
Batch 17/64 loss: 0.3153437376022339
Batch 18/64 loss: 0.3074628710746765
Batch 19/64 loss: 0.31542879343032837
Batch 20/64 loss: 0.3208380937576294
Batch 21/64 loss: 0.3166179656982422
Batch 22/64 loss: 0.3095893859863281
Batch 23/64 loss: 0.3134852647781372
Batch 24/64 loss: 0.3195875287055969
Batch 25/64 loss: 0.30264514684677124
Batch 26/64 loss: 0.3143399953842163
Batch 27/64 loss: 0.30880677700042725
Batch 28/64 loss: 0.3156707286834717
Batch 29/64 loss: 0.3210598826408386
Batch 30/64 loss: 0.3043481111526489
Batch 31/64 loss: 0.31660598516464233
Batch 32/64 loss: 0.31711554527282715
Batch 33/64 loss: 0.32318878173828125
Batch 34/64 loss: 0.31641995906829834
Batch 35/64 loss: 0.314955472946167
Batch 36/64 loss: 0.3105813264846802
Batch 37/64 loss: 0.3186333179473877
Batch 38/64 loss: 0.3069676160812378
Batch 39/64 loss: 0.3140677809715271
Batch 40/64 loss: 0.31471753120422363
Batch 41/64 loss: 0.3137771487236023
Batch 42/64 loss: 0.31783926486968994
Batch 43/64 loss: 0.3146435022354126
Batch 44/64 loss: 0.31247925758361816
Batch 45/64 loss: 0.316827654838562
Batch 46/64 loss: 0.3174976706504822
Batch 47/64 loss: 0.3051280975341797
Batch 48/64 loss: 0.3124138116836548
Batch 49/64 loss: 0.31869739294052124
Batch 50/64 loss: 0.3146822452545166
Batch 51/64 loss: 0.30941593647003174
Batch 52/64 loss: 0.31486034393310547
Batch 53/64 loss: 0.305259644985199
Batch 54/64 loss: 0.3092978596687317
Batch 55/64 loss: 0.3168196678161621
Batch 56/64 loss: 0.3125873804092407
Batch 57/64 loss: 0.3104880452156067
Batch 58/64 loss: 0.30829012393951416
Batch 59/64 loss: 0.31392747163772583
Batch 60/64 loss: 0.31597113609313965
Batch 61/64 loss: 0.31016653776168823
Batch 62/64 loss: 0.3057653307914734
Batch 63/64 loss: 0.3158993721008301
Batch 64/64 loss: 0.31153416633605957
Epoch 97  Train loss: 0.31368735444312  Val loss: 0.32204602756041434
Epoch 98
-------------------------------
Batch 1/64 loss: 0.31271374225616455
Batch 2/64 loss: 0.32062143087387085
Batch 3/64 loss: 0.31036806106567383
Batch 4/64 loss: 0.31286919116973877
Batch 5/64 loss: 0.31143051385879517
Batch 6/64 loss: 0.3121020197868347
Batch 7/64 loss: 0.31374478340148926
Batch 8/64 loss: 0.3119257688522339
Batch 9/64 loss: 0.3115675449371338
Batch 10/64 loss: 0.31568604707717896
Batch 11/64 loss: 0.3106679916381836
Batch 12/64 loss: 0.31500673294067383
Batch 13/64 loss: 0.31313061714172363
Batch 14/64 loss: 0.3144240379333496
Batch 15/64 loss: 0.31290531158447266
Batch 16/64 loss: 0.31532901525497437
Batch 17/64 loss: 0.3106456995010376
Batch 18/64 loss: 0.3125133514404297
Batch 19/64 loss: 0.3133283853530884
Batch 20/64 loss: 0.3145747184753418
Batch 21/64 loss: 0.31894421577453613
Batch 22/64 loss: 0.31564849615097046
Batch 23/64 loss: 0.31122303009033203
Batch 24/64 loss: 0.31522542238235474
Batch 25/64 loss: 0.31447356939315796
Batch 26/64 loss: 0.31356775760650635
Batch 27/64 loss: 0.3178757429122925
Batch 28/64 loss: 0.31346428394317627
Batch 29/64 loss: 0.31178855895996094
Batch 30/64 loss: 0.30901116132736206
Batch 31/64 loss: 0.31184864044189453
Batch 32/64 loss: 0.3138570785522461
Batch 33/64 loss: 0.3065038323402405
Batch 34/64 loss: 0.3136286735534668
Batch 35/64 loss: 0.31631946563720703
Batch 36/64 loss: 0.31659823656082153
Batch 37/64 loss: 0.3105872869491577
Batch 38/64 loss: 0.3148782253265381
Batch 39/64 loss: 0.3088192343711853
Batch 40/64 loss: 0.31231141090393066
Batch 41/64 loss: 0.3135915994644165
Batch 42/64 loss: 0.3088575601577759
Batch 43/64 loss: 0.31792616844177246
Batch 44/64 loss: 0.31599485874176025
Batch 45/64 loss: 0.32195866107940674
Batch 46/64 loss: 0.3090892434120178
Batch 47/64 loss: 0.31160205602645874
Batch 48/64 loss: 0.3145492672920227
Batch 49/64 loss: 0.3120688199996948
Batch 50/64 loss: 0.3205055594444275
Batch 51/64 loss: 0.3119887709617615
Batch 52/64 loss: 0.3111339807510376
Batch 53/64 loss: 0.3124943971633911
Batch 54/64 loss: 0.31065666675567627
Batch 55/64 loss: 0.31155121326446533
Batch 56/64 loss: 0.3159068822860718
Batch 57/64 loss: 0.31169044971466064
Batch 58/64 loss: 0.31957507133483887
Batch 59/64 loss: 0.3086385726928711
Batch 60/64 loss: 0.31680214405059814
Batch 61/64 loss: 0.319161593914032
Batch 62/64 loss: 0.3093549609184265
Batch 63/64 loss: 0.312247097492218
Batch 64/64 loss: 0.31662118434906006
Epoch 98  Train loss: 0.3135206395504521  Val loss: 0.3221534822404999
Epoch 99
-------------------------------
Batch 1/64 loss: 0.31363749504089355
Batch 2/64 loss: 0.3091496229171753
Batch 3/64 loss: 0.30923938751220703
Batch 4/64 loss: 0.3135000467300415
Batch 5/64 loss: 0.31379175186157227
Batch 6/64 loss: 0.31419479846954346
Batch 7/64 loss: 0.3150402307510376
Batch 8/64 loss: 0.3117939829826355
Batch 9/64 loss: 0.31396347284317017
Batch 10/64 loss: 0.309698224067688
Batch 11/64 loss: 0.3194151520729065
Batch 12/64 loss: 0.30945253372192383
Batch 13/64 loss: 0.3104703426361084
Batch 14/64 loss: 0.31515973806381226
Batch 15/64 loss: 0.31012606620788574
Batch 16/64 loss: 0.30591315031051636
Batch 17/64 loss: 0.3085472583770752
Batch 18/64 loss: 0.3033052682876587
Batch 19/64 loss: 0.31461143493652344
Batch 20/64 loss: 0.31142884492874146
Batch 21/64 loss: 0.3156414031982422
Batch 22/64 loss: 0.31139981746673584
Batch 23/64 loss: 0.31511110067367554
Batch 24/64 loss: 0.3150476813316345
Batch 25/64 loss: 0.30424821376800537
Batch 26/64 loss: 0.3155345916748047
Batch 27/64 loss: 0.31981050968170166
Batch 28/64 loss: 0.3070577383041382
Batch 29/64 loss: 0.31224125623703003
Batch 30/64 loss: 0.31185638904571533
Batch 31/64 loss: 0.3184014558792114
Batch 32/64 loss: 0.3118923306465149
Batch 33/64 loss: 0.31344687938690186
Batch 34/64 loss: 0.3119237422943115
Batch 35/64 loss: 0.313313364982605
Batch 36/64 loss: 0.3111000657081604
Batch 37/64 loss: 0.3073697090148926
Batch 38/64 loss: 0.3132666349411011
Batch 39/64 loss: 0.312397301197052
Batch 40/64 loss: 0.31418830156326294
Batch 41/64 loss: 0.3087496757507324
Batch 42/64 loss: 0.312976598739624
Batch 43/64 loss: 0.3069000244140625
Batch 44/64 loss: 0.3184322714805603
Batch 45/64 loss: 0.3064494729042053
Batch 46/64 loss: 0.31423622369766235
Batch 47/64 loss: 0.320789098739624
Batch 48/64 loss: 0.30952298641204834
Batch 49/64 loss: 0.317801833152771
Batch 50/64 loss: 0.3140296936035156
Batch 51/64 loss: 0.31197309494018555
Batch 52/64 loss: 0.3200985789299011
Batch 53/64 loss: 0.3104677200317383
Batch 54/64 loss: 0.31066572666168213
Batch 55/64 loss: 0.3087446689605713
Batch 56/64 loss: 0.31642818450927734
Batch 57/64 loss: 0.31933093070983887
Batch 58/64 loss: 0.3178844451904297
Batch 59/64 loss: 0.31873130798339844
Batch 60/64 loss: 0.3102174997329712
Batch 61/64 loss: 0.30952727794647217
Batch 62/64 loss: 0.312433123588562
Batch 63/64 loss: 0.31822288036346436
Batch 64/64 loss: 0.3167549967765808
Epoch 99  Train loss: 0.312782225188087  Val loss: 0.32240116780566186
Epoch 100
-------------------------------
Batch 1/64 loss: 0.31629514694213867
Batch 2/64 loss: 0.3134129047393799
Batch 3/64 loss: 0.31594014167785645
Batch 4/64 loss: 0.3219817876815796
Batch 5/64 loss: 0.3159918785095215
Batch 6/64 loss: 0.31572526693344116
Batch 7/64 loss: 0.307422935962677
Batch 8/64 loss: 0.30776768922805786
Batch 9/64 loss: 0.31357020139694214
Batch 10/64 loss: 0.3200950622558594
Batch 11/64 loss: 0.31244444847106934
Batch 12/64 loss: 0.3149762749671936
Batch 13/64 loss: 0.3162311315536499
Batch 14/64 loss: 0.30492103099823
Batch 15/64 loss: 0.3049008250236511
Batch 16/64 loss: 0.30864590406417847
Batch 17/64 loss: 0.3174628019332886
Batch 18/64 loss: 0.3105167746543884
Batch 19/64 loss: 0.30726635456085205
Batch 20/64 loss: 0.31593966484069824
Batch 21/64 loss: 0.3041243553161621
Batch 22/64 loss: 0.31370222568511963
Batch 23/64 loss: 0.3148590326309204
Batch 24/64 loss: 0.31898242235183716
Batch 25/64 loss: 0.311323881149292
Batch 26/64 loss: 0.30927038192749023
Batch 27/64 loss: 0.3099290132522583
Batch 28/64 loss: 0.3130875825881958
Batch 29/64 loss: 0.30377334356307983
Batch 30/64 loss: 0.31303703784942627
Batch 31/64 loss: 0.31194597482681274
Batch 32/64 loss: 0.31476521492004395
Batch 33/64 loss: 0.31266725063323975
Batch 34/64 loss: 0.3119865655899048
Batch 35/64 loss: 0.3109922409057617
Batch 36/64 loss: 0.3097999095916748
Batch 37/64 loss: 0.31095755100250244
Batch 38/64 loss: 0.31025266647338867
Batch 39/64 loss: 0.3088145852088928
Batch 40/64 loss: 0.32075947523117065
Batch 41/64 loss: 0.3134196400642395
Batch 42/64 loss: 0.31803590059280396
Batch 43/64 loss: 0.3089437484741211
Batch 44/64 loss: 0.31379544734954834
Batch 45/64 loss: 0.31784939765930176
Batch 46/64 loss: 0.3145869970321655
Batch 47/64 loss: 0.31286323070526123
Batch 48/64 loss: 0.31423521041870117
Batch 49/64 loss: 0.31734663248062134
Batch 50/64 loss: 0.31335926055908203
Batch 51/64 loss: 0.314847469329834
Batch 52/64 loss: 0.31859952211380005
Batch 53/64 loss: 0.3099159598350525
Batch 54/64 loss: 0.31383025646209717
Batch 55/64 loss: 0.3144063949584961
Batch 56/64 loss: 0.30985021591186523
Batch 57/64 loss: 0.3223755359649658
Batch 58/64 loss: 0.3117977976799011
Batch 59/64 loss: 0.3111840486526489
Batch 60/64 loss: 0.31595849990844727
Batch 61/64 loss: 0.3054875135421753
Batch 62/64 loss: 0.30956703424453735
Batch 63/64 loss: 0.3071069121360779
Batch 64/64 loss: 0.3122275471687317
Epoch 100  Train loss: 0.31278544664382935  Val loss: 0.3212723688980968
Saving best model, epoch: 100
Epoch 101
-------------------------------
Batch 1/64 loss: 0.3181036114692688
Batch 2/64 loss: 0.3074879050254822
Batch 3/64 loss: 0.31254786252975464
Batch 4/64 loss: 0.3103533983230591
Batch 5/64 loss: 0.31466972827911377
Batch 6/64 loss: 0.31019580364227295
Batch 7/64 loss: 0.3113524913787842
Batch 8/64 loss: 0.31224024295806885
Batch 9/64 loss: 0.31393373012542725
Batch 10/64 loss: 0.31373077630996704
Batch 11/64 loss: 0.3171066641807556
Batch 12/64 loss: 0.31111741065979004
Batch 13/64 loss: 0.31015533208847046
Batch 14/64 loss: 0.3095661997795105
Batch 15/64 loss: 0.3007274866104126
Batch 16/64 loss: 0.3166393041610718
Batch 17/64 loss: 0.3107489347457886
Batch 18/64 loss: 0.3130168914794922
Batch 19/64 loss: 0.3093072175979614
Batch 20/64 loss: 0.3101980686187744
Batch 21/64 loss: 0.31763291358947754
Batch 22/64 loss: 0.3161355257034302
Batch 23/64 loss: 0.3096252679824829
Batch 24/64 loss: 0.31479835510253906
Batch 25/64 loss: 0.30404937267303467
Batch 26/64 loss: 0.31018900871276855
Batch 27/64 loss: 0.31323492527008057
Batch 28/64 loss: 0.3079338073730469
Batch 29/64 loss: 0.31104904413223267
Batch 30/64 loss: 0.3184569478034973
Batch 31/64 loss: 0.31192052364349365
Batch 32/64 loss: 0.30881190299987793
Batch 33/64 loss: 0.3052941560745239
Batch 34/64 loss: 0.30765730142593384
Batch 35/64 loss: 0.30707311630249023
Batch 36/64 loss: 0.3052724003791809
Batch 37/64 loss: 0.3030032515525818
Batch 38/64 loss: 0.32082676887512207
Batch 39/64 loss: 0.30878376960754395
Batch 40/64 loss: 0.3149838447570801
Batch 41/64 loss: 0.31806135177612305
Batch 42/64 loss: 0.3119550943374634
Batch 43/64 loss: 0.30812501907348633
Batch 44/64 loss: 0.3115091323852539
Batch 45/64 loss: 0.3174688220024109
Batch 46/64 loss: 0.3122846484184265
Batch 47/64 loss: 0.31273478269577026
Batch 48/64 loss: 0.3114004135131836
Batch 49/64 loss: 0.30641770362854004
Batch 50/64 loss: 0.30737435817718506
Batch 51/64 loss: 0.3155348300933838
Batch 52/64 loss: 0.3082241415977478
Batch 53/64 loss: 0.31377214193344116
Batch 54/64 loss: 0.3150632381439209
Batch 55/64 loss: 0.31837373971939087
Batch 56/64 loss: 0.31607937812805176
Batch 57/64 loss: 0.3123354911804199
Batch 58/64 loss: 0.31274235248565674
Batch 59/64 loss: 0.31500065326690674
Batch 60/64 loss: 0.3081324100494385
Batch 61/64 loss: 0.3120366334915161
Batch 62/64 loss: 0.3163306713104248
Batch 63/64 loss: 0.31212878227233887
Batch 64/64 loss: 0.31292736530303955
Epoch 101  Train loss: 0.311807256118924  Val loss: 0.320233117264161
Saving best model, epoch: 101
Epoch 102
-------------------------------
Batch 1/64 loss: 0.3062540292739868
Batch 2/64 loss: 0.31827306747436523
Batch 3/64 loss: 0.3086652159690857
Batch 4/64 loss: 0.3113456964492798
Batch 5/64 loss: 0.3146061897277832
Batch 6/64 loss: 0.3099462389945984
Batch 7/64 loss: 0.31655579805374146
Batch 8/64 loss: 0.3165942430496216
Batch 9/64 loss: 0.31213921308517456
Batch 10/64 loss: 0.3101416230201721
Batch 11/64 loss: 0.3086838722229004
Batch 12/64 loss: 0.31042206287384033
Batch 13/64 loss: 0.3060004711151123
Batch 14/64 loss: 0.31312882900238037
Batch 15/64 loss: 0.3192784786224365
Batch 16/64 loss: 0.30808210372924805
Batch 17/64 loss: 0.3090388774871826
Batch 18/64 loss: 0.31521832942962646
Batch 19/64 loss: 0.30561137199401855
Batch 20/64 loss: 0.31819796562194824
Batch 21/64 loss: 0.30796635150909424
Batch 22/64 loss: 0.313093900680542
Batch 23/64 loss: 0.31252729892730713
Batch 24/64 loss: 0.29958486557006836
Batch 25/64 loss: 0.3053171634674072
Batch 26/64 loss: 0.30913251638412476
Batch 27/64 loss: 0.3134832978248596
Batch 28/64 loss: 0.31259191036224365
Batch 29/64 loss: 0.31041228771209717
Batch 30/64 loss: 0.31342560052871704
Batch 31/64 loss: 0.31147730350494385
Batch 32/64 loss: 0.30863773822784424
Batch 33/64 loss: 0.3058866262435913
Batch 34/64 loss: 0.3117464780807495
Batch 35/64 loss: 0.30974340438842773
Batch 36/64 loss: 0.31467127799987793
Batch 37/64 loss: 0.3149457573890686
Batch 38/64 loss: 0.3134266138076782
Batch 39/64 loss: 0.31129759550094604
Batch 40/64 loss: 0.30950069427490234
Batch 41/64 loss: 0.30844664573669434
Batch 42/64 loss: 0.30976951122283936
Batch 43/64 loss: 0.31098663806915283
Batch 44/64 loss: 0.31977033615112305
Batch 45/64 loss: 0.30467939376831055
Batch 46/64 loss: 0.30668437480926514
Batch 47/64 loss: 0.3109208345413208
Batch 48/64 loss: 0.3114457130432129
Batch 49/64 loss: 0.3086314797401428
Batch 50/64 loss: 0.3132286071777344
Batch 51/64 loss: 0.31453073024749756
Batch 52/64 loss: 0.3063198924064636
Batch 53/64 loss: 0.3107945919036865
Batch 54/64 loss: 0.31664055585861206
Batch 55/64 loss: 0.3173609972000122
Batch 56/64 loss: 0.3067042827606201
Batch 57/64 loss: 0.3106503486633301
Batch 58/64 loss: 0.31004083156585693
Batch 59/64 loss: 0.3090876340866089
Batch 60/64 loss: 0.3065492510795593
Batch 61/64 loss: 0.314725399017334
Batch 62/64 loss: 0.3101198077201843
Batch 63/64 loss: 0.3075409531593323
Batch 64/64 loss: 0.31306886672973633
Epoch 102  Train loss: 0.31101933834599516  Val loss: 0.3205275642093514
Epoch 103
-------------------------------
Batch 1/64 loss: 0.31607145071029663
Batch 2/64 loss: 0.3065448999404907
Batch 3/64 loss: 0.3094187378883362
Batch 4/64 loss: 0.3137350082397461
Batch 5/64 loss: 0.30714452266693115
Batch 6/64 loss: 0.3165167570114136
Batch 7/64 loss: 0.3141093850135803
Batch 8/64 loss: 0.3126105070114136
Batch 9/64 loss: 0.3078543543815613
Batch 10/64 loss: 0.30919378995895386
Batch 11/64 loss: 0.31917399168014526
Batch 12/64 loss: 0.3061617612838745
Batch 13/64 loss: 0.3094583749771118
Batch 14/64 loss: 0.3046196699142456
Batch 15/64 loss: 0.31391608715057373
Batch 16/64 loss: 0.312546968460083
Batch 17/64 loss: 0.3109375238418579
Batch 18/64 loss: 0.30767565965652466
Batch 19/64 loss: 0.31080901622772217
Batch 20/64 loss: 0.31674981117248535
Batch 21/64 loss: 0.31455761194229126
Batch 22/64 loss: 0.3124443292617798
Batch 23/64 loss: 0.31592321395874023
Batch 24/64 loss: 0.31017810106277466
Batch 25/64 loss: 0.3095892667770386
Batch 26/64 loss: 0.3077510595321655
Batch 27/64 loss: 0.3140972852706909
Batch 28/64 loss: 0.3158811330795288
Batch 29/64 loss: 0.30938392877578735
Batch 30/64 loss: 0.30828046798706055
Batch 31/64 loss: 0.30742883682250977
Batch 32/64 loss: 0.3123779296875
Batch 33/64 loss: 0.3131589889526367
Batch 34/64 loss: 0.30822449922561646
Batch 35/64 loss: 0.31562691926956177
Batch 36/64 loss: 0.30898094177246094
Batch 37/64 loss: 0.3076671361923218
Batch 38/64 loss: 0.3035559058189392
Batch 39/64 loss: 0.30884695053100586
Batch 40/64 loss: 0.3171871304512024
Batch 41/64 loss: 0.3096276521682739
Batch 42/64 loss: 0.31155824661254883
Batch 43/64 loss: 0.306460976600647
Batch 44/64 loss: 0.31330639123916626
Batch 45/64 loss: 0.3050185441970825
Batch 46/64 loss: 0.309177041053772
Batch 47/64 loss: 0.30653613805770874
Batch 48/64 loss: 0.30843162536621094
Batch 49/64 loss: 0.3086897134780884
Batch 50/64 loss: 0.31276726722717285
Batch 51/64 loss: 0.31389081478118896
Batch 52/64 loss: 0.3103199005126953
Batch 53/64 loss: 0.31178736686706543
Batch 54/64 loss: 0.31034624576568604
Batch 55/64 loss: 0.3216950297355652
Batch 56/64 loss: 0.3155333995819092
Batch 57/64 loss: 0.3211049437522888
Batch 58/64 loss: 0.3067740201950073
Batch 59/64 loss: 0.30566418170928955
Batch 60/64 loss: 0.3030872344970703
Batch 61/64 loss: 0.3211914896965027
Batch 62/64 loss: 0.3124920129776001
Batch 63/64 loss: 0.30981504917144775
Batch 64/64 loss: 0.30270785093307495
Epoch 103  Train loss: 0.3110383699922001  Val loss: 0.31985033869333696
Saving best model, epoch: 103
Epoch 104
-------------------------------
Batch 1/64 loss: 0.3133392930030823
Batch 2/64 loss: 0.3052734136581421
Batch 3/64 loss: 0.310397744178772
Batch 4/64 loss: 0.30943024158477783
Batch 5/64 loss: 0.30846107006073
Batch 6/64 loss: 0.3124024271965027
Batch 7/64 loss: 0.31931406259536743
Batch 8/64 loss: 0.3102530241012573
Batch 9/64 loss: 0.30631107091903687
Batch 10/64 loss: 0.305059552192688
Batch 11/64 loss: 0.31393229961395264
Batch 12/64 loss: 0.31208550930023193
Batch 13/64 loss: 0.3113035559654236
Batch 14/64 loss: 0.3042107820510864
Batch 15/64 loss: 0.30879461765289307
Batch 16/64 loss: 0.3090780973434448
Batch 17/64 loss: 0.3116246461868286
Batch 18/64 loss: 0.3151895999908447
Batch 19/64 loss: 0.3081297278404236
Batch 20/64 loss: 0.3096664547920227
Batch 21/64 loss: 0.3074629306793213
Batch 22/64 loss: 0.3119734525680542
Batch 23/64 loss: 0.31172025203704834
Batch 24/64 loss: 0.31736093759536743
Batch 25/64 loss: 0.30871450901031494
Batch 26/64 loss: 0.31051206588745117
Batch 27/64 loss: 0.31531840562820435
Batch 28/64 loss: 0.3028322458267212
Batch 29/64 loss: 0.30956244468688965
Batch 30/64 loss: 0.3130277991294861
Batch 31/64 loss: 0.3137756586074829
Batch 32/64 loss: 0.3117866516113281
Batch 33/64 loss: 0.31077611446380615
Batch 34/64 loss: 0.316017210483551
Batch 35/64 loss: 0.30688536167144775
Batch 36/64 loss: 0.3060820698738098
Batch 37/64 loss: 0.31285572052001953
Batch 38/64 loss: 0.30297183990478516
Batch 39/64 loss: 0.3063523769378662
Batch 40/64 loss: 0.31457579135894775
Batch 41/64 loss: 0.2998964786529541
Batch 42/64 loss: 0.30753999948501587
Batch 43/64 loss: 0.3173013925552368
Batch 44/64 loss: 0.2996317148208618
Batch 45/64 loss: 0.31049996614456177
Batch 46/64 loss: 0.3097238540649414
Batch 47/64 loss: 0.30592310428619385
Batch 48/64 loss: 0.30436813831329346
Batch 49/64 loss: 0.31033360958099365
Batch 50/64 loss: 0.308984637260437
Batch 51/64 loss: 0.31765174865722656
Batch 52/64 loss: 0.3214157819747925
Batch 53/64 loss: 0.3060012459754944
Batch 54/64 loss: 0.3058898448944092
Batch 55/64 loss: 0.3060934543609619
Batch 56/64 loss: 0.3060597777366638
Batch 57/64 loss: 0.3056502342224121
Batch 58/64 loss: 0.30642151832580566
Batch 59/64 loss: 0.3158037066459656
Batch 60/64 loss: 0.3110544681549072
Batch 61/64 loss: 0.30787837505340576
Batch 62/64 loss: 0.30756306648254395
Batch 63/64 loss: 0.30690377950668335
Batch 64/64 loss: 0.3168758153915405
Epoch 104  Train loss: 0.3098206711750405  Val loss: 0.31927730250604375
Saving best model, epoch: 104
Epoch 105
-------------------------------
Batch 1/64 loss: 0.29729634523391724
Batch 2/64 loss: 0.3054507374763489
Batch 3/64 loss: 0.3097018003463745
Batch 4/64 loss: 0.30651992559432983
Batch 5/64 loss: 0.31049007177352905
Batch 6/64 loss: 0.31208503246307373
Batch 7/64 loss: 0.31534701585769653
Batch 8/64 loss: 0.30686867237091064
Batch 9/64 loss: 0.30834656953811646
Batch 10/64 loss: 0.3023233413696289
Batch 11/64 loss: 0.3097341060638428
Batch 12/64 loss: 0.31178414821624756
Batch 13/64 loss: 0.307339072227478
Batch 14/64 loss: 0.31395697593688965
Batch 15/64 loss: 0.31851935386657715
Batch 16/64 loss: 0.30799829959869385
Batch 17/64 loss: 0.31413084268569946
Batch 18/64 loss: 0.3056821823120117
Batch 19/64 loss: 0.306262731552124
Batch 20/64 loss: 0.31395936012268066
Batch 21/64 loss: 0.3138556480407715
Batch 22/64 loss: 0.3101598620414734
Batch 23/64 loss: 0.30655670166015625
Batch 24/64 loss: 0.31121355295181274
Batch 25/64 loss: 0.31055009365081787
Batch 26/64 loss: 0.305467426776886
Batch 27/64 loss: 0.3085530996322632
Batch 28/64 loss: 0.30868613719940186
Batch 29/64 loss: 0.310388445854187
Batch 30/64 loss: 0.3204570412635803
Batch 31/64 loss: 0.30780029296875
Batch 32/64 loss: 0.3060416579246521
Batch 33/64 loss: 0.3120683431625366
Batch 34/64 loss: 0.31368476152420044
Batch 35/64 loss: 0.30225270986557007
Batch 36/64 loss: 0.3119999170303345
Batch 37/64 loss: 0.3125995397567749
Batch 38/64 loss: 0.31500911712646484
Batch 39/64 loss: 0.30862271785736084
Batch 40/64 loss: 0.30743181705474854
Batch 41/64 loss: 0.30850720405578613
Batch 42/64 loss: 0.31015545129776
Batch 43/64 loss: 0.3113565444946289
Batch 44/64 loss: 0.3088432550430298
Batch 45/64 loss: 0.3099260926246643
Batch 46/64 loss: 0.3066987991333008
Batch 47/64 loss: 0.3087656497955322
Batch 48/64 loss: 0.307395339012146
Batch 49/64 loss: 0.3080331087112427
Batch 50/64 loss: 0.3084213137626648
Batch 51/64 loss: 0.3080456256866455
Batch 52/64 loss: 0.30939334630966187
Batch 53/64 loss: 0.31110477447509766
Batch 54/64 loss: 0.30778276920318604
Batch 55/64 loss: 0.30372393131256104
Batch 56/64 loss: 0.30428457260131836
Batch 57/64 loss: 0.31034547090530396
Batch 58/64 loss: 0.3138018846511841
Batch 59/64 loss: 0.3110799193382263
Batch 60/64 loss: 0.31120961904525757
Batch 61/64 loss: 0.3110608458518982
Batch 62/64 loss: 0.31506335735321045
Batch 63/64 loss: 0.3087550401687622
Batch 64/64 loss: 0.30602002143859863
Epoch 105  Train loss: 0.309497480766446  Val loss: 0.3179068211018015
Saving best model, epoch: 105
Epoch 106
-------------------------------
Batch 1/64 loss: 0.3079873323440552
Batch 2/64 loss: 0.30791914463043213
Batch 3/64 loss: 0.30979764461517334
Batch 4/64 loss: 0.30361104011535645
Batch 5/64 loss: 0.31783533096313477
Batch 6/64 loss: 0.3005097508430481
Batch 7/64 loss: 0.3154149055480957
Batch 8/64 loss: 0.3124057650566101
Batch 9/64 loss: 0.30773037672042847
Batch 10/64 loss: 0.31005150079727173
Batch 11/64 loss: 0.3047868013381958
Batch 12/64 loss: 0.299809992313385
Batch 13/64 loss: 0.3165910243988037
Batch 14/64 loss: 0.30789715051651
Batch 15/64 loss: 0.31492042541503906
Batch 16/64 loss: 0.31543564796447754
Batch 17/64 loss: 0.3081548810005188
Batch 18/64 loss: 0.3160092234611511
Batch 19/64 loss: 0.304259717464447
Batch 20/64 loss: 0.31266796588897705
Batch 21/64 loss: 0.3139340877532959
Batch 22/64 loss: 0.3025178909301758
Batch 23/64 loss: 0.3034740090370178
Batch 24/64 loss: 0.31109440326690674
Batch 25/64 loss: 0.3169066905975342
Batch 26/64 loss: 0.3057440519332886
Batch 27/64 loss: 0.31426000595092773
Batch 28/64 loss: 0.3117908239364624
Batch 29/64 loss: 0.3098808526992798
Batch 30/64 loss: 0.30467939376831055
Batch 31/64 loss: 0.30772078037261963
Batch 32/64 loss: 0.311225950717926
Batch 33/64 loss: 0.3111675977706909
Batch 34/64 loss: 0.3076804280281067
Batch 35/64 loss: 0.30655646324157715
Batch 36/64 loss: 0.3100728988647461
Batch 37/64 loss: 0.30867600440979004
Batch 38/64 loss: 0.3137701749801636
Batch 39/64 loss: 0.30632537603378296
Batch 40/64 loss: 0.3069326877593994
Batch 41/64 loss: 0.31116247177124023
Batch 42/64 loss: 0.3090780973434448
Batch 43/64 loss: 0.31490659713745117
Batch 44/64 loss: 0.311031699180603
Batch 45/64 loss: 0.3082547187805176
Batch 46/64 loss: 0.3076939582824707
Batch 47/64 loss: 0.30601364374160767
Batch 48/64 loss: 0.30710411071777344
Batch 49/64 loss: 0.30538028478622437
Batch 50/64 loss: 0.3083873391151428
Batch 51/64 loss: 0.30776453018188477
Batch 52/64 loss: 0.3079841136932373
Batch 53/64 loss: 0.30250728130340576
Batch 54/64 loss: 0.3055703043937683
Batch 55/64 loss: 0.30846333503723145
Batch 56/64 loss: 0.31433963775634766
Batch 57/64 loss: 0.3138498067855835
Batch 58/64 loss: 0.3052905201911926
Batch 59/64 loss: 0.308297336101532
Batch 60/64 loss: 0.2981182336807251
Batch 61/64 loss: 0.3105364441871643
Batch 62/64 loss: 0.30836403369903564
Batch 63/64 loss: 0.30666404962539673
Batch 64/64 loss: 0.3117635250091553
Epoch 106  Train loss: 0.30900064917171705  Val loss: 0.31868473197176694
Epoch 107
-------------------------------
Batch 1/64 loss: 0.3074353337287903
Batch 2/64 loss: 0.30397164821624756
Batch 3/64 loss: 0.3064068555831909
Batch 4/64 loss: 0.30829918384552
Batch 5/64 loss: 0.3131605386734009
Batch 6/64 loss: 0.3140627145767212
Batch 7/64 loss: 0.3129047155380249
Batch 8/64 loss: 0.314483106136322
Batch 9/64 loss: 0.30225086212158203
Batch 10/64 loss: 0.3061990737915039
Batch 11/64 loss: 0.30619531869888306
Batch 12/64 loss: 0.3020789623260498
Batch 13/64 loss: 0.30153852701187134
Batch 14/64 loss: 0.31138885021209717
Batch 15/64 loss: 0.3086610436439514
Batch 16/64 loss: 0.32033228874206543
Batch 17/64 loss: 0.31062233448028564
Batch 18/64 loss: 0.30836570262908936
Batch 19/64 loss: 0.31040316820144653
Batch 20/64 loss: 0.30839550495147705
Batch 21/64 loss: 0.3075815439224243
Batch 22/64 loss: 0.30783694982528687
Batch 23/64 loss: 0.3027368187904358
Batch 24/64 loss: 0.3046109676361084
Batch 25/64 loss: 0.3043634295463562
Batch 26/64 loss: 0.3050776720046997
Batch 27/64 loss: 0.31168365478515625
Batch 28/64 loss: 0.30384182929992676
Batch 29/64 loss: 0.31215834617614746
Batch 30/64 loss: 0.30489039421081543
Batch 31/64 loss: 0.3158605694770813
Batch 32/64 loss: 0.31084805727005005
Batch 33/64 loss: 0.3087698221206665
Batch 34/64 loss: 0.3208637833595276
Batch 35/64 loss: 0.30894947052001953
Batch 36/64 loss: 0.3109623193740845
Batch 37/64 loss: 0.30903375148773193
Batch 38/64 loss: 0.3057664632797241
Batch 39/64 loss: 0.31225574016571045
Batch 40/64 loss: 0.3022446632385254
Batch 41/64 loss: 0.31269729137420654
Batch 42/64 loss: 0.3046455383300781
Batch 43/64 loss: 0.30807459354400635
Batch 44/64 loss: 0.3101210594177246
Batch 45/64 loss: 0.31376850605010986
Batch 46/64 loss: 0.31046605110168457
Batch 47/64 loss: 0.31028008460998535
Batch 48/64 loss: 0.3128812313079834
Batch 49/64 loss: 0.3098384737968445
Batch 50/64 loss: 0.3039205074310303
Batch 51/64 loss: 0.30924832820892334
Batch 52/64 loss: 0.311123251914978
Batch 53/64 loss: 0.3116005063056946
Batch 54/64 loss: 0.3070904016494751
Batch 55/64 loss: 0.30690956115722656
Batch 56/64 loss: 0.3164529800415039
Batch 57/64 loss: 0.3106238842010498
Batch 58/64 loss: 0.30903637409210205
Batch 59/64 loss: 0.30647218227386475
Batch 60/64 loss: 0.30693525075912476
Batch 61/64 loss: 0.30828315019607544
Batch 62/64 loss: 0.3067382574081421
Batch 63/64 loss: 0.3087269067764282
Batch 64/64 loss: 0.30221349000930786
Epoch 107  Train loss: 0.30886410147536036  Val loss: 0.31724965818149525
Saving best model, epoch: 107
Epoch 108
-------------------------------
Batch 1/64 loss: 0.3142892122268677
Batch 2/64 loss: 0.30454087257385254
Batch 3/64 loss: 0.3036090135574341
Batch 4/64 loss: 0.3088999390602112
Batch 5/64 loss: 0.3059321641921997
Batch 6/64 loss: 0.3178943395614624
Batch 7/64 loss: 0.3034929037094116
Batch 8/64 loss: 0.3042351007461548
Batch 9/64 loss: 0.3063337802886963
Batch 10/64 loss: 0.3083920478820801
Batch 11/64 loss: 0.3091222643852234
Batch 12/64 loss: 0.3021693229675293
Batch 13/64 loss: 0.3040201663970947
Batch 14/64 loss: 0.29734551906585693
Batch 15/64 loss: 0.30892181396484375
Batch 16/64 loss: 0.3083900213241577
Batch 17/64 loss: 0.31008803844451904
Batch 18/64 loss: 0.3092994689941406
Batch 19/64 loss: 0.308282732963562
Batch 20/64 loss: 0.30630552768707275
Batch 21/64 loss: 0.30603182315826416
Batch 22/64 loss: 0.31015944480895996
Batch 23/64 loss: 0.3155761957168579
Batch 24/64 loss: 0.30959558486938477
Batch 25/64 loss: 0.30568158626556396
Batch 26/64 loss: 0.30660223960876465
Batch 27/64 loss: 0.2976464629173279
Batch 28/64 loss: 0.30796200037002563
Batch 29/64 loss: 0.31151247024536133
Batch 30/64 loss: 0.3075111508369446
Batch 31/64 loss: 0.30712950229644775
Batch 32/64 loss: 0.30024486780166626
Batch 33/64 loss: 0.310183584690094
Batch 34/64 loss: 0.3089148998260498
Batch 35/64 loss: 0.31336545944213867
Batch 36/64 loss: 0.3095419406890869
Batch 37/64 loss: 0.3034478425979614
Batch 38/64 loss: 0.30715465545654297
Batch 39/64 loss: 0.3059645891189575
Batch 40/64 loss: 0.3118579387664795
Batch 41/64 loss: 0.30420976877212524
Batch 42/64 loss: 0.3118116855621338
Batch 43/64 loss: 0.2999691367149353
Batch 44/64 loss: 0.3063981533050537
Batch 45/64 loss: 0.3069995641708374
Batch 46/64 loss: 0.31389909982681274
Batch 47/64 loss: 0.30293965339660645
Batch 48/64 loss: 0.2998000383377075
Batch 49/64 loss: 0.30731016397476196
Batch 50/64 loss: 0.3110876679420471
Batch 51/64 loss: 0.3070623278617859
Batch 52/64 loss: 0.3037869930267334
Batch 53/64 loss: 0.3094218969345093
Batch 54/64 loss: 0.3061932325363159
Batch 55/64 loss: 0.3114468455314636
Batch 56/64 loss: 0.31416183710098267
Batch 57/64 loss: 0.3062744140625
Batch 58/64 loss: 0.3028034567832947
Batch 59/64 loss: 0.31087028980255127
Batch 60/64 loss: 0.31070494651794434
Batch 61/64 loss: 0.30705034732818604
Batch 62/64 loss: 0.3042536973953247
Batch 63/64 loss: 0.3062335252761841
Batch 64/64 loss: 0.31492531299591064
Epoch 108  Train loss: 0.3074279406491448  Val loss: 0.31617859180030955
Saving best model, epoch: 108
Epoch 109
-------------------------------
Batch 1/64 loss: 0.3037242889404297
Batch 2/64 loss: 0.3076432943344116
Batch 3/64 loss: 0.3028370141983032
Batch 4/64 loss: 0.3100096583366394
Batch 5/64 loss: 0.31823670864105225
Batch 6/64 loss: 0.3054007887840271
Batch 7/64 loss: 0.3083215355873108
Batch 8/64 loss: 0.3098863959312439
Batch 9/64 loss: 0.3101140260696411
Batch 10/64 loss: 0.30529189109802246
Batch 11/64 loss: 0.3117895722389221
Batch 12/64 loss: 0.3047661781311035
Batch 13/64 loss: 0.30525803565979004
Batch 14/64 loss: 0.30893296003341675
Batch 15/64 loss: 0.30220556259155273
Batch 16/64 loss: 0.30694568157196045
Batch 17/64 loss: 0.30558228492736816
Batch 18/64 loss: 0.30670326948165894
Batch 19/64 loss: 0.30251073837280273
Batch 20/64 loss: 0.31009459495544434
Batch 21/64 loss: 0.31346648931503296
Batch 22/64 loss: 0.3076751232147217
Batch 23/64 loss: 0.30787742137908936
Batch 24/64 loss: 0.3040503263473511
Batch 25/64 loss: 0.30159473419189453
Batch 26/64 loss: 0.3082699775695801
Batch 27/64 loss: 0.3014606237411499
Batch 28/64 loss: 0.30700886249542236
Batch 29/64 loss: 0.3119414448738098
Batch 30/64 loss: 0.3005771040916443
Batch 31/64 loss: 0.30706560611724854
Batch 32/64 loss: 0.29675519466400146
Batch 33/64 loss: 0.30344802141189575
Batch 34/64 loss: 0.30561280250549316
Batch 35/64 loss: 0.3077406883239746
Batch 36/64 loss: 0.3044503331184387
Batch 37/64 loss: 0.3102540969848633
Batch 38/64 loss: 0.30473506450653076
Batch 39/64 loss: 0.3071219325065613
Batch 40/64 loss: 0.30201590061187744
Batch 41/64 loss: 0.3100242018699646
Batch 42/64 loss: 0.3140527606010437
Batch 43/64 loss: 0.3145713210105896
Batch 44/64 loss: 0.3070080876350403
Batch 45/64 loss: 0.3152417540550232
Batch 46/64 loss: 0.3086642026901245
Batch 47/64 loss: 0.3039782643318176
Batch 48/64 loss: 0.30953526496887207
Batch 49/64 loss: 0.3130996823310852
Batch 50/64 loss: 0.3077418804168701
Batch 51/64 loss: 0.29729926586151123
Batch 52/64 loss: 0.30728375911712646
Batch 53/64 loss: 0.3078199028968811
Batch 54/64 loss: 0.31008023023605347
Batch 55/64 loss: 0.3057466745376587
Batch 56/64 loss: 0.3145381212234497
Batch 57/64 loss: 0.3079288601875305
Batch 58/64 loss: 0.3085924983024597
Batch 59/64 loss: 0.3092207908630371
Batch 60/64 loss: 0.30272048711776733
Batch 61/64 loss: 0.3105355501174927
Batch 62/64 loss: 0.3139190077781677
Batch 63/64 loss: 0.3102428913116455
Batch 64/64 loss: 0.3074043393135071
Epoch 109  Train loss: 0.30744745006748275  Val loss: 0.3163055968038815
Epoch 110
-------------------------------
Batch 1/64 loss: 0.30718743801116943
Batch 2/64 loss: 0.3051914572715759
Batch 3/64 loss: 0.30243778228759766
Batch 4/64 loss: 0.30484282970428467
Batch 5/64 loss: 0.30248427391052246
Batch 6/64 loss: 0.30725157260894775
Batch 7/64 loss: 0.30584704875946045
Batch 8/64 loss: 0.30213892459869385
Batch 9/64 loss: 0.3050914406776428
Batch 10/64 loss: 0.304068922996521
Batch 11/64 loss: 0.30595362186431885
Batch 12/64 loss: 0.30384254455566406
Batch 13/64 loss: 0.31410878896713257
Batch 14/64 loss: 0.30819523334503174
Batch 15/64 loss: 0.30411314964294434
Batch 16/64 loss: 0.3052959442138672
Batch 17/64 loss: 0.30452001094818115
Batch 18/64 loss: 0.3099963665008545
Batch 19/64 loss: 0.3056674599647522
Batch 20/64 loss: 0.2951345443725586
Batch 21/64 loss: 0.29924172163009644
Batch 22/64 loss: 0.3095541000366211
Batch 23/64 loss: 0.30833762884140015
Batch 24/64 loss: 0.30254966020584106
Batch 25/64 loss: 0.3052494525909424
Batch 26/64 loss: 0.2999644875526428
Batch 27/64 loss: 0.3068808317184448
Batch 28/64 loss: 0.3034090995788574
Batch 29/64 loss: 0.3170222043991089
Batch 30/64 loss: 0.3096879720687866
Batch 31/64 loss: 0.30782657861709595
Batch 32/64 loss: 0.30511319637298584
Batch 33/64 loss: 0.31387341022491455
Batch 34/64 loss: 0.30417191982269287
Batch 35/64 loss: 0.3034062385559082
Batch 36/64 loss: 0.303999125957489
Batch 37/64 loss: 0.30953556299209595
Batch 38/64 loss: 0.30073630809783936
Batch 39/64 loss: 0.30147695541381836
Batch 40/64 loss: 0.31250816583633423
Batch 41/64 loss: 0.2989844083786011
Batch 42/64 loss: 0.30917590856552124
Batch 43/64 loss: 0.3140159249305725
Batch 44/64 loss: 0.30852460861206055
Batch 45/64 loss: 0.30876821279525757
Batch 46/64 loss: 0.3114975094795227
Batch 47/64 loss: 0.30585700273513794
Batch 48/64 loss: 0.309359073638916
Batch 49/64 loss: 0.31666409969329834
Batch 50/64 loss: 0.3029415011405945
Batch 51/64 loss: 0.2962304353713989
Batch 52/64 loss: 0.30737072229385376
Batch 53/64 loss: 0.3209604024887085
Batch 54/64 loss: 0.30580127239227295
Batch 55/64 loss: 0.311431348323822
Batch 56/64 loss: 0.3200315833091736
Batch 57/64 loss: 0.2981456518173218
Batch 58/64 loss: 0.3074526786804199
Batch 59/64 loss: 0.3144456148147583
Batch 60/64 loss: 0.30872273445129395
Batch 61/64 loss: 0.30238282680511475
Batch 62/64 loss: 0.30795609951019287
Batch 63/64 loss: 0.3082091808319092
Batch 64/64 loss: 0.30201542377471924
Epoch 110  Train loss: 0.3066565387389239  Val loss: 0.3168918967656663
Epoch 111
-------------------------------
Batch 1/64 loss: 0.30248332023620605
Batch 2/64 loss: 0.3015185594558716
Batch 3/64 loss: 0.3045339584350586
Batch 4/64 loss: 0.30417174100875854
Batch 5/64 loss: 0.30557405948638916
Batch 6/64 loss: 0.305889368057251
Batch 7/64 loss: 0.3037426471710205
Batch 8/64 loss: 0.30250442028045654
Batch 9/64 loss: 0.30639517307281494
Batch 10/64 loss: 0.3078348636627197
Batch 11/64 loss: 0.30771195888519287
Batch 12/64 loss: 0.30411994457244873
Batch 13/64 loss: 0.307711124420166
Batch 14/64 loss: 0.3097883462905884
Batch 15/64 loss: 0.31531596183776855
Batch 16/64 loss: 0.3070928454399109
Batch 17/64 loss: 0.3077467679977417
Batch 18/64 loss: 0.29471665620803833
Batch 19/64 loss: 0.30015772581100464
Batch 20/64 loss: 0.3051684498786926
Batch 21/64 loss: 0.30372154712677
Batch 22/64 loss: 0.30841171741485596
Batch 23/64 loss: 0.2997801899909973
Batch 24/64 loss: 0.30315154790878296
Batch 25/64 loss: 0.3007146120071411
Batch 26/64 loss: 0.3189338445663452
Batch 27/64 loss: 0.29578423500061035
Batch 28/64 loss: 0.302711546421051
Batch 29/64 loss: 0.3122408390045166
Batch 30/64 loss: 0.3062313199043274
Batch 31/64 loss: 0.29764628410339355
Batch 32/64 loss: 0.3102360963821411
Batch 33/64 loss: 0.30780714750289917
Batch 34/64 loss: 0.2996252775192261
Batch 35/64 loss: 0.30776286125183105
Batch 36/64 loss: 0.30567431449890137
Batch 37/64 loss: 0.30084240436553955
Batch 38/64 loss: 0.3111386299133301
Batch 39/64 loss: 0.3047196865081787
Batch 40/64 loss: 0.30696535110473633
Batch 41/64 loss: 0.30840903520584106
Batch 42/64 loss: 0.3057694435119629
Batch 43/64 loss: 0.3069028854370117
Batch 44/64 loss: 0.31047844886779785
Batch 45/64 loss: 0.31053316593170166
Batch 46/64 loss: 0.31134557723999023
Batch 47/64 loss: 0.30949723720550537
Batch 48/64 loss: 0.3077129125595093
Batch 49/64 loss: 0.3060922622680664
Batch 50/64 loss: 0.30926382541656494
Batch 51/64 loss: 0.3045949935913086
Batch 52/64 loss: 0.3070491552352905
Batch 53/64 loss: 0.3075956106185913
Batch 54/64 loss: 0.30708038806915283
Batch 55/64 loss: 0.3146144151687622
Batch 56/64 loss: 0.3037607669830322
Batch 57/64 loss: 0.30970847606658936
Batch 58/64 loss: 0.309070348739624
Batch 59/64 loss: 0.3054043650627136
Batch 60/64 loss: 0.3065493106842041
Batch 61/64 loss: 0.3124616742134094
Batch 62/64 loss: 0.3110617399215698
Batch 63/64 loss: 0.3087267279624939
Batch 64/64 loss: 0.31272268295288086
Epoch 111  Train loss: 0.3064549352608475  Val loss: 0.3171305209910337
Epoch 112
-------------------------------
Batch 1/64 loss: 0.30895060300827026
Batch 2/64 loss: 0.3077348470687866
Batch 3/64 loss: 0.3048657178878784
Batch 4/64 loss: 0.3047405481338501
Batch 5/64 loss: 0.3186277747154236
Batch 6/64 loss: 0.30115175247192383
Batch 7/64 loss: 0.30793488025665283
Batch 8/64 loss: 0.3052029609680176
Batch 9/64 loss: 0.301643967628479
Batch 10/64 loss: 0.3115936517715454
Batch 11/64 loss: 0.30290424823760986
Batch 12/64 loss: 0.3034077286720276
Batch 13/64 loss: 0.305527925491333
Batch 14/64 loss: 0.3054652810096741
Batch 15/64 loss: 0.3047889471054077
Batch 16/64 loss: 0.3052297830581665
Batch 17/64 loss: 0.30890095233917236
Batch 18/64 loss: 0.3060699701309204
Batch 19/64 loss: 0.30659765005111694
Batch 20/64 loss: 0.3055320978164673
Batch 21/64 loss: 0.3027738928794861
Batch 22/64 loss: 0.30926036834716797
Batch 23/64 loss: 0.30613797903060913
Batch 24/64 loss: 0.29628515243530273
Batch 25/64 loss: 0.3103199005126953
Batch 26/64 loss: 0.3031378388404846
Batch 27/64 loss: 0.30708587169647217
Batch 28/64 loss: 0.3021453619003296
Batch 29/64 loss: 0.30844801664352417
Batch 30/64 loss: 0.30985546112060547
Batch 31/64 loss: 0.3121809959411621
Batch 32/64 loss: 0.31292057037353516
Batch 33/64 loss: 0.30886363983154297
Batch 34/64 loss: 0.30706989765167236
Batch 35/64 loss: 0.3110830783843994
Batch 36/64 loss: 0.30871903896331787
Batch 37/64 loss: 0.30746740102767944
Batch 38/64 loss: 0.30848217010498047
Batch 39/64 loss: 0.30306828022003174
Batch 40/64 loss: 0.30972719192504883
Batch 41/64 loss: 0.30416977405548096
Batch 42/64 loss: 0.30345839262008667
Batch 43/64 loss: 0.31310558319091797
Batch 44/64 loss: 0.3059741258621216
Batch 45/64 loss: 0.30620741844177246
Batch 46/64 loss: 0.30170828104019165
Batch 47/64 loss: 0.30396783351898193
Batch 48/64 loss: 0.30185532569885254
Batch 49/64 loss: 0.30488288402557373
Batch 50/64 loss: 0.3048079013824463
Batch 51/64 loss: 0.3070613145828247
Batch 52/64 loss: 0.3073417544364929
Batch 53/64 loss: 0.3019683361053467
Batch 54/64 loss: 0.3075430989265442
Batch 55/64 loss: 0.3041040897369385
Batch 56/64 loss: 0.3088304400444031
Batch 57/64 loss: 0.30639612674713135
Batch 58/64 loss: 0.30962687730789185
Batch 59/64 loss: 0.30368882417678833
Batch 60/64 loss: 0.3084034323692322
Batch 61/64 loss: 0.31123781204223633
Batch 62/64 loss: 0.3066202402114868
Batch 63/64 loss: 0.3029930591583252
Batch 64/64 loss: 0.30448269844055176
Epoch 112  Train loss: 0.3064504838457294  Val loss: 0.31500123169823613
Saving best model, epoch: 112
Epoch 113
-------------------------------
Batch 1/64 loss: 0.3039977550506592
Batch 2/64 loss: 0.30138105154037476
Batch 3/64 loss: 0.3107166290283203
Batch 4/64 loss: 0.3083226680755615
Batch 5/64 loss: 0.311413049697876
Batch 6/64 loss: 0.3058549165725708
Batch 7/64 loss: 0.30274641513824463
Batch 8/64 loss: 0.31384706497192383
Batch 9/64 loss: 0.30897247791290283
Batch 10/64 loss: 0.3094596266746521
Batch 11/64 loss: 0.3106642961502075
Batch 12/64 loss: 0.311617374420166
Batch 13/64 loss: 0.3103628158569336
Batch 14/64 loss: 0.30959928035736084
Batch 15/64 loss: 0.305523157119751
Batch 16/64 loss: 0.3051048517227173
Batch 17/64 loss: 0.3003268241882324
Batch 18/64 loss: 0.3032563328742981
Batch 19/64 loss: 0.299710214138031
Batch 20/64 loss: 0.31059902906417847
Batch 21/64 loss: 0.3061544895172119
Batch 22/64 loss: 0.30135977268218994
Batch 23/64 loss: 0.3060176968574524
Batch 24/64 loss: 0.3091472387313843
Batch 25/64 loss: 0.3017057180404663
Batch 26/64 loss: 0.3007858395576477
Batch 27/64 loss: 0.30412864685058594
Batch 28/64 loss: 0.31048154830932617
Batch 29/64 loss: 0.29661619663238525
Batch 30/64 loss: 0.3112502098083496
Batch 31/64 loss: 0.3065091371536255
Batch 32/64 loss: 0.30870580673217773
Batch 33/64 loss: 0.29976212978363037
Batch 34/64 loss: 0.29870057106018066
Batch 35/64 loss: 0.3072620630264282
Batch 36/64 loss: 0.29944300651550293
Batch 37/64 loss: 0.3038836717605591
Batch 38/64 loss: 0.3128281235694885
Batch 39/64 loss: 0.29750776290893555
Batch 40/64 loss: 0.2983994483947754
Batch 41/64 loss: 0.30286478996276855
Batch 42/64 loss: 0.29956281185150146
Batch 43/64 loss: 0.308796763420105
Batch 44/64 loss: 0.3080568313598633
Batch 45/64 loss: 0.3085121512413025
Batch 46/64 loss: 0.3056894540786743
Batch 47/64 loss: 0.3057600259780884
Batch 48/64 loss: 0.3055416941642761
Batch 49/64 loss: 0.3034157156944275
Batch 50/64 loss: 0.3072448968887329
Batch 51/64 loss: 0.31097865104675293
Batch 52/64 loss: 0.29989486932754517
Batch 53/64 loss: 0.304219126701355
Batch 54/64 loss: 0.30285322666168213
Batch 55/64 loss: 0.29953277111053467
Batch 56/64 loss: 0.3010844588279724
Batch 57/64 loss: 0.31436944007873535
Batch 58/64 loss: 0.3103288412094116
Batch 59/64 loss: 0.3025723099708557
Batch 60/64 loss: 0.30219554901123047
Batch 61/64 loss: 0.31085681915283203
Batch 62/64 loss: 0.310610830783844
Batch 63/64 loss: 0.2998136878013611
Batch 64/64 loss: 0.30718809366226196
Epoch 113  Train loss: 0.305557203059103  Val loss: 0.3162790278798526
Epoch 114
-------------------------------
Batch 1/64 loss: 0.29945099353790283
Batch 2/64 loss: 0.30760014057159424
Batch 3/64 loss: 0.31030213832855225
Batch 4/64 loss: 0.30629926919937134
Batch 5/64 loss: 0.31050795316696167
Batch 6/64 loss: 0.30808961391448975
Batch 7/64 loss: 0.30369120836257935
Batch 8/64 loss: 0.30766189098358154
Batch 9/64 loss: 0.29911041259765625
Batch 10/64 loss: 0.30570316314697266
Batch 11/64 loss: 0.3016669750213623
Batch 12/64 loss: 0.31251609325408936
Batch 13/64 loss: 0.2996116280555725
Batch 14/64 loss: 0.3037465810775757
Batch 15/64 loss: 0.3005819320678711
Batch 16/64 loss: 0.30190664529800415
Batch 17/64 loss: 0.3081545829772949
Batch 18/64 loss: 0.30798089504241943
Batch 19/64 loss: 0.3044698238372803
Batch 20/64 loss: 0.3073888421058655
Batch 21/64 loss: 0.3067373037338257
Batch 22/64 loss: 0.300894558429718
Batch 23/64 loss: 0.30893415212631226
Batch 24/64 loss: 0.3095747232437134
Batch 25/64 loss: 0.31247425079345703
Batch 26/64 loss: 0.3129926919937134
Batch 27/64 loss: 0.3111174702644348
Batch 28/64 loss: 0.3069462776184082
Batch 29/64 loss: 0.3023155927658081
Batch 30/64 loss: 0.3014247417449951
Batch 31/64 loss: 0.3096538782119751
Batch 32/64 loss: 0.30267858505249023
Batch 33/64 loss: 0.31074976921081543
Batch 34/64 loss: 0.31081533432006836
Batch 35/64 loss: 0.3030914068222046
Batch 36/64 loss: 0.30263596773147583
Batch 37/64 loss: 0.3079746961593628
Batch 38/64 loss: 0.3137422204017639
Batch 39/64 loss: 0.30424851179122925
Batch 40/64 loss: 0.3028820753097534
Batch 41/64 loss: 0.30237507820129395
Batch 42/64 loss: 0.31022000312805176
Batch 43/64 loss: 0.3081347942352295
Batch 44/64 loss: 0.30592775344848633
Batch 45/64 loss: 0.3066598176956177
Batch 46/64 loss: 0.30644357204437256
Batch 47/64 loss: 0.30228352546691895
Batch 48/64 loss: 0.3080786466598511
Batch 49/64 loss: 0.3100869655609131
Batch 50/64 loss: 0.2974887490272522
Batch 51/64 loss: 0.29902929067611694
Batch 52/64 loss: 0.3039354085922241
Batch 53/64 loss: 0.31003642082214355
Batch 54/64 loss: 0.2940307855606079
Batch 55/64 loss: 0.3021695613861084
Batch 56/64 loss: 0.30721068382263184
Batch 57/64 loss: 0.30304622650146484
Batch 58/64 loss: 0.30578750371932983
Batch 59/64 loss: 0.30526530742645264
Batch 60/64 loss: 0.3041982650756836
Batch 61/64 loss: 0.3041527271270752
Batch 62/64 loss: 0.3052852153778076
Batch 63/64 loss: 0.30726158618927
Batch 64/64 loss: 0.3000010848045349
Epoch 114  Train loss: 0.3056068030058169  Val loss: 0.31458497190803186
Saving best model, epoch: 114
Epoch 115
-------------------------------
Batch 1/64 loss: 0.30998295545578003
Batch 2/64 loss: 0.29832923412323
Batch 3/64 loss: 0.30997323989868164
Batch 4/64 loss: 0.2998305559158325
Batch 5/64 loss: 0.2975656986236572
Batch 6/64 loss: 0.3051670789718628
Batch 7/64 loss: 0.2982768416404724
Batch 8/64 loss: 0.30458545684814453
Batch 9/64 loss: 0.3064824342727661
Batch 10/64 loss: 0.30181241035461426
Batch 11/64 loss: 0.30328917503356934
Batch 12/64 loss: 0.3041713833808899
Batch 13/64 loss: 0.3024556040763855
Batch 14/64 loss: 0.29674744606018066
Batch 15/64 loss: 0.31199461221694946
Batch 16/64 loss: 0.3032207489013672
Batch 17/64 loss: 0.31263983249664307
Batch 18/64 loss: 0.30168330669403076
Batch 19/64 loss: 0.30961310863494873
Batch 20/64 loss: 0.3079887628555298
Batch 21/64 loss: 0.3030294179916382
Batch 22/64 loss: 0.2991983890533447
Batch 23/64 loss: 0.30511850118637085
Batch 24/64 loss: 0.30243200063705444
Batch 25/64 loss: 0.3108525276184082
Batch 26/64 loss: 0.30617237091064453
Batch 27/64 loss: 0.3103187084197998
Batch 28/64 loss: 0.3129196763038635
Batch 29/64 loss: 0.30109965801239014
Batch 30/64 loss: 0.31664639711380005
Batch 31/64 loss: 0.29911673069000244
Batch 32/64 loss: 0.30258476734161377
Batch 33/64 loss: 0.3054664134979248
Batch 34/64 loss: 0.30717891454696655
Batch 35/64 loss: 0.3094515800476074
Batch 36/64 loss: 0.3052264451980591
Batch 37/64 loss: 0.30033135414123535
Batch 38/64 loss: 0.2989821434020996
Batch 39/64 loss: 0.3047511577606201
Batch 40/64 loss: 0.30565178394317627
Batch 41/64 loss: 0.30643630027770996
Batch 42/64 loss: 0.3013855814933777
Batch 43/64 loss: 0.3079885244369507
Batch 44/64 loss: 0.309836745262146
Batch 45/64 loss: 0.30550456047058105
Batch 46/64 loss: 0.30234140157699585
Batch 47/64 loss: 0.3039063811302185
Batch 48/64 loss: 0.3025616407394409
Batch 49/64 loss: 0.30001139640808105
Batch 50/64 loss: 0.3062640428543091
Batch 51/64 loss: 0.3107985854148865
Batch 52/64 loss: 0.2984727621078491
Batch 53/64 loss: 0.3014794588088989
Batch 54/64 loss: 0.3067057132720947
Batch 55/64 loss: 0.3083815574645996
Batch 56/64 loss: 0.29865843057632446
Batch 57/64 loss: 0.3075176477432251
Batch 58/64 loss: 0.2998383045196533
Batch 59/64 loss: 0.3049811124801636
Batch 60/64 loss: 0.31256425380706787
Batch 61/64 loss: 0.3144136071205139
Batch 62/64 loss: 0.3016514182090759
Batch 63/64 loss: 0.30525606870651245
Batch 64/64 loss: 0.3083098530769348
Epoch 115  Train loss: 0.3049494385719299  Val loss: 0.31676631080325934
Epoch 116
-------------------------------
Batch 1/64 loss: 0.3088259696960449
Batch 2/64 loss: 0.3080903887748718
Batch 3/64 loss: 0.30865418910980225
Batch 4/64 loss: 0.305997371673584
Batch 5/64 loss: 0.3042891025543213
Batch 6/64 loss: 0.3025881052017212
Batch 7/64 loss: 0.30125927925109863
Batch 8/64 loss: 0.30708497762680054
Batch 9/64 loss: 0.31000202894210815
Batch 10/64 loss: 0.3032485246658325
Batch 11/64 loss: 0.30336952209472656
Batch 12/64 loss: 0.30265235900878906
Batch 13/64 loss: 0.29705512523651123
Batch 14/64 loss: 0.2948201894760132
Batch 15/64 loss: 0.298698365688324
Batch 16/64 loss: 0.29818224906921387
Batch 17/64 loss: 0.3104671239852905
Batch 18/64 loss: 0.3040217161178589
Batch 19/64 loss: 0.3098956346511841
Batch 20/64 loss: 0.30875468254089355
Batch 21/64 loss: 0.30905890464782715
Batch 22/64 loss: 0.3003966808319092
Batch 23/64 loss: 0.29716670513153076
Batch 24/64 loss: 0.3055376410484314
Batch 25/64 loss: 0.3026692867279053
Batch 26/64 loss: 0.3016728162765503
Batch 27/64 loss: 0.30453169345855713
Batch 28/64 loss: 0.2962137460708618
Batch 29/64 loss: 0.30772578716278076
Batch 30/64 loss: 0.30125993490219116
Batch 31/64 loss: 0.3061550259590149
Batch 32/64 loss: 0.3002603054046631
Batch 33/64 loss: 0.30009353160858154
Batch 34/64 loss: 0.3028753995895386
Batch 35/64 loss: 0.30910301208496094
Batch 36/64 loss: 0.31141746044158936
Batch 37/64 loss: 0.299418568611145
Batch 38/64 loss: 0.30836236476898193
Batch 39/64 loss: 0.3014475703239441
Batch 40/64 loss: 0.3002520799636841
Batch 41/64 loss: 0.3001747131347656
Batch 42/64 loss: 0.3039664030075073
Batch 43/64 loss: 0.30158668756484985
Batch 44/64 loss: 0.3023698329925537
Batch 45/64 loss: 0.2958475351333618
Batch 46/64 loss: 0.30323517322540283
Batch 47/64 loss: 0.3016160726547241
Batch 48/64 loss: 0.30387043952941895
Batch 49/64 loss: 0.3150121569633484
Batch 50/64 loss: 0.3097078800201416
Batch 51/64 loss: 0.3002643585205078
Batch 52/64 loss: 0.3041245937347412
Batch 53/64 loss: 0.3069373369216919
Batch 54/64 loss: 0.3100717067718506
Batch 55/64 loss: 0.3023872375488281
Batch 56/64 loss: 0.31020426750183105
Batch 57/64 loss: 0.3123131990432739
Batch 58/64 loss: 0.3042110800743103
Batch 59/64 loss: 0.3171112537384033
Batch 60/64 loss: 0.3067418336868286
Batch 61/64 loss: 0.30283355712890625
Batch 62/64 loss: 0.29848068952560425
Batch 63/64 loss: 0.3028494119644165
Batch 64/64 loss: 0.30648207664489746
Epoch 116  Train loss: 0.3043035984039307  Val loss: 0.314485583108725
Saving best model, epoch: 116
Epoch 117
-------------------------------
Batch 1/64 loss: 0.30006134510040283
Batch 2/64 loss: 0.3053182363510132
Batch 3/64 loss: 0.30842792987823486
Batch 4/64 loss: 0.30030345916748047
Batch 5/64 loss: 0.3040663003921509
Batch 6/64 loss: 0.30231034755706787
Batch 7/64 loss: 0.30198556184768677
Batch 8/64 loss: 0.30071985721588135
Batch 9/64 loss: 0.2990429401397705
Batch 10/64 loss: 0.30246204137802124
Batch 11/64 loss: 0.29204756021499634
Batch 12/64 loss: 0.3065551519393921
Batch 13/64 loss: 0.2967996597290039
Batch 14/64 loss: 0.30220460891723633
Batch 15/64 loss: 0.3007824420928955
Batch 16/64 loss: 0.3018641471862793
Batch 17/64 loss: 0.3108804225921631
Batch 18/64 loss: 0.3036577105522156
Batch 19/64 loss: 0.3012622594833374
Batch 20/64 loss: 0.30581408739089966
Batch 21/64 loss: 0.3077167868614197
Batch 22/64 loss: 0.31599539518356323
Batch 23/64 loss: 0.3020029067993164
Batch 24/64 loss: 0.30640602111816406
Batch 25/64 loss: 0.29952043294906616
Batch 26/64 loss: 0.3033524751663208
Batch 27/64 loss: 0.30260205268859863
Batch 28/64 loss: 0.31100553274154663
Batch 29/64 loss: 0.2968289852142334
Batch 30/64 loss: 0.3045669198036194
Batch 31/64 loss: 0.29782652854919434
Batch 32/64 loss: 0.3036864399909973
Batch 33/64 loss: 0.30105292797088623
Batch 34/64 loss: 0.30413877964019775
Batch 35/64 loss: 0.3058507442474365
Batch 36/64 loss: 0.29420626163482666
Batch 37/64 loss: 0.29915690422058105
Batch 38/64 loss: 0.30320876836776733
Batch 39/64 loss: 0.2976701259613037
Batch 40/64 loss: 0.2982218861579895
Batch 41/64 loss: 0.3007073402404785
Batch 42/64 loss: 0.30033600330352783
Batch 43/64 loss: 0.31325286626815796
Batch 44/64 loss: 0.30847615003585815
Batch 45/64 loss: 0.3039723038673401
Batch 46/64 loss: 0.30901873111724854
Batch 47/64 loss: 0.2981029152870178
Batch 48/64 loss: 0.30467867851257324
Batch 49/64 loss: 0.30511003732681274
Batch 50/64 loss: 0.30571210384368896
Batch 51/64 loss: 0.29846489429473877
Batch 52/64 loss: 0.31443578004837036
Batch 53/64 loss: 0.3076268434524536
Batch 54/64 loss: 0.29884982109069824
Batch 55/64 loss: 0.30780231952667236
Batch 56/64 loss: 0.30459892749786377
Batch 57/64 loss: 0.2949155569076538
Batch 58/64 loss: 0.2991188168525696
Batch 59/64 loss: 0.3047176003456116
Batch 60/64 loss: 0.3052607774734497
Batch 61/64 loss: 0.30973440408706665
Batch 62/64 loss: 0.29670143127441406
Batch 63/64 loss: 0.30831146240234375
Batch 64/64 loss: 0.3027913570404053
Epoch 117  Train loss: 0.30319344670164816  Val loss: 0.31485725391361724
Epoch 118
-------------------------------
Batch 1/64 loss: 0.3008314371109009
Batch 2/64 loss: 0.30648064613342285
Batch 3/64 loss: 0.30199867486953735
Batch 4/64 loss: 0.3050838112831116
Batch 5/64 loss: 0.3050193190574646
Batch 6/64 loss: 0.30231940746307373
Batch 7/64 loss: 0.30069106817245483
Batch 8/64 loss: 0.3059515953063965
Batch 9/64 loss: 0.30280816555023193
Batch 10/64 loss: 0.3006007671356201
Batch 11/64 loss: 0.3085981011390686
Batch 12/64 loss: 0.30107611417770386
Batch 13/64 loss: 0.3062453866004944
Batch 14/64 loss: 0.30739474296569824
Batch 15/64 loss: 0.3062845468521118
Batch 16/64 loss: 0.31118035316467285
Batch 17/64 loss: 0.30423641204833984
Batch 18/64 loss: 0.299291729927063
Batch 19/64 loss: 0.3041849136352539
Batch 20/64 loss: 0.30241167545318604
Batch 21/64 loss: 0.30725014209747314
Batch 22/64 loss: 0.30498671531677246
Batch 23/64 loss: 0.30593669414520264
Batch 24/64 loss: 0.2964017391204834
Batch 25/64 loss: 0.30691713094711304
Batch 26/64 loss: 0.3056122064590454
Batch 27/64 loss: 0.3052533268928528
Batch 28/64 loss: 0.29493898153305054
Batch 29/64 loss: 0.30205851793289185
Batch 30/64 loss: 0.3028232455253601
Batch 31/64 loss: 0.3042309284210205
Batch 32/64 loss: 0.30486583709716797
Batch 33/64 loss: 0.2981882095336914
Batch 34/64 loss: 0.30092155933380127
Batch 35/64 loss: 0.2947295904159546
Batch 36/64 loss: 0.2967819571495056
Batch 37/64 loss: 0.30513089895248413
Batch 38/64 loss: 0.299028217792511
Batch 39/64 loss: 0.2979573607444763
Batch 40/64 loss: 0.301846444606781
Batch 41/64 loss: 0.3115060329437256
Batch 42/64 loss: 0.3008492588996887
Batch 43/64 loss: 0.303219199180603
Batch 44/64 loss: 0.3077969551086426
Batch 45/64 loss: 0.2964822053909302
Batch 46/64 loss: 0.3068408966064453
Batch 47/64 loss: 0.3058896064758301
Batch 48/64 loss: 0.30671894550323486
Batch 49/64 loss: 0.29753541946411133
Batch 50/64 loss: 0.3106229305267334
Batch 51/64 loss: 0.30736464262008667
Batch 52/64 loss: 0.30732113122940063
Batch 53/64 loss: 0.30148744583129883
Batch 54/64 loss: 0.3023020029067993
Batch 55/64 loss: 0.2986186742782593
Batch 56/64 loss: 0.30309271812438965
Batch 57/64 loss: 0.30924201011657715
Batch 58/64 loss: 0.2931215167045593
Batch 59/64 loss: 0.3004852533340454
Batch 60/64 loss: 0.297113299369812
Batch 61/64 loss: 0.30993926525115967
Batch 62/64 loss: 0.306119441986084
Batch 63/64 loss: 0.30033886432647705
Batch 64/64 loss: 0.29949408769607544
Epoch 118  Train loss: 0.3031714016315984  Val loss: 0.31385126720179396
Saving best model, epoch: 118
Epoch 119
-------------------------------
Batch 1/64 loss: 0.3007715940475464
Batch 2/64 loss: 0.30539631843566895
Batch 3/64 loss: 0.3032122850418091
Batch 4/64 loss: 0.30073511600494385
Batch 5/64 loss: 0.3040086030960083
Batch 6/64 loss: 0.30170881748199463
Batch 7/64 loss: 0.3017786741256714
Batch 8/64 loss: 0.301419734954834
Batch 9/64 loss: 0.30746543407440186
Batch 10/64 loss: 0.2945481538772583
Batch 11/64 loss: 0.30488455295562744
Batch 12/64 loss: 0.29851698875427246
Batch 13/64 loss: 0.3060072660446167
Batch 14/64 loss: 0.2996334433555603
Batch 15/64 loss: 0.29975056648254395
Batch 16/64 loss: 0.3061681389808655
Batch 17/64 loss: 0.3011056184768677
Batch 18/64 loss: 0.29972314834594727
Batch 19/64 loss: 0.3052264451980591
Batch 20/64 loss: 0.2979816198348999
Batch 21/64 loss: 0.3089379072189331
Batch 22/64 loss: 0.3078528642654419
Batch 23/64 loss: 0.30347740650177
Batch 24/64 loss: 0.30296558141708374
Batch 25/64 loss: 0.30538880825042725
Batch 26/64 loss: 0.30294328927993774
Batch 27/64 loss: 0.2983013391494751
Batch 28/64 loss: 0.3006134033203125
Batch 29/64 loss: 0.3032108545303345
Batch 30/64 loss: 0.29969996213912964
Batch 31/64 loss: 0.30297935009002686
Batch 32/64 loss: 0.3081589937210083
Batch 33/64 loss: 0.3029114603996277
Batch 34/64 loss: 0.303716242313385
Batch 35/64 loss: 0.3058379888534546
Batch 36/64 loss: 0.2973322868347168
Batch 37/64 loss: 0.3033353090286255
Batch 38/64 loss: 0.3036537170410156
Batch 39/64 loss: 0.3095232844352722
Batch 40/64 loss: 0.30496037006378174
Batch 41/64 loss: 0.3071037530899048
Batch 42/64 loss: 0.3071012496948242
Batch 43/64 loss: 0.30542147159576416
Batch 44/64 loss: 0.30778318643569946
Batch 45/64 loss: 0.2958947420120239
Batch 46/64 loss: 0.2982994318008423
Batch 47/64 loss: 0.3017616868019104
Batch 48/64 loss: 0.3053964376449585
Batch 49/64 loss: 0.29848504066467285
Batch 50/64 loss: 0.302418053150177
Batch 51/64 loss: 0.31079357862472534
Batch 52/64 loss: 0.2987147569656372
Batch 53/64 loss: 0.3015390634536743
Batch 54/64 loss: 0.30628520250320435
Batch 55/64 loss: 0.30734169483184814
Batch 56/64 loss: 0.30163753032684326
Batch 57/64 loss: 0.3057515621185303
Batch 58/64 loss: 0.30303502082824707
Batch 59/64 loss: 0.30809295177459717
Batch 60/64 loss: 0.2952412962913513
Batch 61/64 loss: 0.3080396056175232
Batch 62/64 loss: 0.3080677390098572
Batch 63/64 loss: 0.30965304374694824
Batch 64/64 loss: 0.31022870540618896
Epoch 119  Train loss: 0.30340976574841666  Val loss: 0.31438620762317043
Epoch 120
-------------------------------
Batch 1/64 loss: 0.3033548593521118
Batch 2/64 loss: 0.3009200096130371
Batch 3/64 loss: 0.30167388916015625
Batch 4/64 loss: 0.30673933029174805
Batch 5/64 loss: 0.2960519790649414
Batch 6/64 loss: 0.3035987615585327
Batch 7/64 loss: 0.30350756645202637
Batch 8/64 loss: 0.30713629722595215
Batch 9/64 loss: 0.2979428768157959
Batch 10/64 loss: 0.3047797679901123
Batch 11/64 loss: 0.3014390468597412
Batch 12/64 loss: 0.2944594621658325
Batch 13/64 loss: 0.2893263101577759
Batch 14/64 loss: 0.28831303119659424
Batch 15/64 loss: 0.3007981777191162
Batch 16/64 loss: 0.30854904651641846
Batch 17/64 loss: 0.2942458987236023
Batch 18/64 loss: 0.31067389249801636
Batch 19/64 loss: 0.29658281803131104
Batch 20/64 loss: 0.29294806718826294
Batch 21/64 loss: 0.31005561351776123
Batch 22/64 loss: 0.3044634461402893
Batch 23/64 loss: 0.3007049560546875
Batch 24/64 loss: 0.3117866516113281
Batch 25/64 loss: 0.2939814329147339
Batch 26/64 loss: 0.30165934562683105
Batch 27/64 loss: 0.30292844772338867
Batch 28/64 loss: 0.3023533821105957
Batch 29/64 loss: 0.295762836933136
Batch 30/64 loss: 0.3044852018356323
Batch 31/64 loss: 0.30136704444885254
Batch 32/64 loss: 0.3091198801994324
Batch 33/64 loss: 0.30156809091567993
Batch 34/64 loss: 0.30144786834716797
Batch 35/64 loss: 0.3078177571296692
Batch 36/64 loss: 0.29966044425964355
Batch 37/64 loss: 0.2954654097557068
Batch 38/64 loss: 0.29166746139526367
Batch 39/64 loss: 0.3069545030593872
Batch 40/64 loss: 0.2942643165588379
Batch 41/64 loss: 0.3102167844772339
Batch 42/64 loss: 0.29445600509643555
Batch 43/64 loss: 0.29899847507476807
Batch 44/64 loss: 0.29621148109436035
Batch 45/64 loss: 0.2991848587989807
Batch 46/64 loss: 0.30187201499938965
Batch 47/64 loss: 0.31479412317276
Batch 48/64 loss: 0.2996506690979004
Batch 49/64 loss: 0.3054501414299011
Batch 50/64 loss: 0.30728888511657715
Batch 51/64 loss: 0.2997763752937317
Batch 52/64 loss: 0.30384552478790283
Batch 53/64 loss: 0.3090173006057739
Batch 54/64 loss: 0.3080192804336548
Batch 55/64 loss: 0.30774009227752686
Batch 56/64 loss: 0.3075423240661621
Batch 57/64 loss: 0.2943382263183594
Batch 58/64 loss: 0.3073182702064514
Batch 59/64 loss: 0.2973533868789673
Batch 60/64 loss: 0.296358585357666
Batch 61/64 loss: 0.30283355712890625
Batch 62/64 loss: 0.30269330739974976
Batch 63/64 loss: 0.3002278804779053
Batch 64/64 loss: 0.2958912253379822
Epoch 120  Train loss: 0.30161037094452803  Val loss: 0.31178240554848896
Saving best model, epoch: 120
Epoch 121
-------------------------------
Batch 1/64 loss: 0.29930949211120605
Batch 2/64 loss: 0.305050790309906
Batch 3/64 loss: 0.29906827211380005
Batch 4/64 loss: 0.3005944490432739
Batch 5/64 loss: 0.302456796169281
Batch 6/64 loss: 0.29911017417907715
Batch 7/64 loss: 0.29891353845596313
Batch 8/64 loss: 0.30728405714035034
Batch 9/64 loss: 0.30581629276275635
Batch 10/64 loss: 0.3019619584083557
Batch 11/64 loss: 0.2984539270401001
Batch 12/64 loss: 0.3047916293144226
Batch 13/64 loss: 0.30538409948349
Batch 14/64 loss: 0.302406370639801
Batch 15/64 loss: 0.30005383491516113
Batch 16/64 loss: 0.29235053062438965
Batch 17/64 loss: 0.29571568965911865
Batch 18/64 loss: 0.2976491451263428
Batch 19/64 loss: 0.29818910360336304
Batch 20/64 loss: 0.298947811126709
Batch 21/64 loss: 0.2988293766975403
Batch 22/64 loss: 0.29988551139831543
Batch 23/64 loss: 0.3039788007736206
Batch 24/64 loss: 0.30800795555114746
Batch 25/64 loss: 0.30666935443878174
Batch 26/64 loss: 0.30103570222854614
Batch 27/64 loss: 0.296819806098938
Batch 28/64 loss: 0.30117267370224
Batch 29/64 loss: 0.3008837103843689
Batch 30/64 loss: 0.29763513803482056
Batch 31/64 loss: 0.30272364616394043
Batch 32/64 loss: 0.30959075689315796
Batch 33/64 loss: 0.30075693130493164
Batch 34/64 loss: 0.30712205171585083
Batch 35/64 loss: 0.29918330907821655
Batch 36/64 loss: 0.30572450160980225
Batch 37/64 loss: 0.3090210556983948
Batch 38/64 loss: 0.30400586128234863
Batch 39/64 loss: 0.2914379835128784
Batch 40/64 loss: 0.29857683181762695
Batch 41/64 loss: 0.305184543132782
Batch 42/64 loss: 0.3025132417678833
Batch 43/64 loss: 0.3051058053970337
Batch 44/64 loss: 0.3060847520828247
Batch 45/64 loss: 0.3037072420120239
Batch 46/64 loss: 0.29835236072540283
Batch 47/64 loss: 0.2988312840461731
Batch 48/64 loss: 0.30222415924072266
Batch 49/64 loss: 0.29368340969085693
Batch 50/64 loss: 0.29915064573287964
Batch 51/64 loss: 0.2997068762779236
Batch 52/64 loss: 0.29655027389526367
Batch 53/64 loss: 0.3042283058166504
Batch 54/64 loss: 0.2931826114654541
Batch 55/64 loss: 0.29714083671569824
Batch 56/64 loss: 0.28876209259033203
Batch 57/64 loss: 0.29536187648773193
Batch 58/64 loss: 0.2993983030319214
Batch 59/64 loss: 0.29938745498657227
Batch 60/64 loss: 0.3066478371620178
Batch 61/64 loss: 0.29759252071380615
Batch 62/64 loss: 0.3090972900390625
Batch 63/64 loss: 0.3044825792312622
Batch 64/64 loss: 0.30465424060821533
Epoch 121  Train loss: 0.30104213181663964  Val loss: 0.3113814094631942
Saving best model, epoch: 121
Epoch 122
-------------------------------
Batch 1/64 loss: 0.2971500754356384
Batch 2/64 loss: 0.30098283290863037
Batch 3/64 loss: 0.3064635992050171
Batch 4/64 loss: 0.30797648429870605
Batch 5/64 loss: 0.30107688903808594
Batch 6/64 loss: 0.29579901695251465
Batch 7/64 loss: 0.3039902448654175
Batch 8/64 loss: 0.30069684982299805
Batch 9/64 loss: 0.3108891248703003
Batch 10/64 loss: 0.3013228178024292
Batch 11/64 loss: 0.2957040071487427
Batch 12/64 loss: 0.29948174953460693
Batch 13/64 loss: 0.2955888509750366
Batch 14/64 loss: 0.30293357372283936
Batch 15/64 loss: 0.29660654067993164
Batch 16/64 loss: 0.30163848400115967
Batch 17/64 loss: 0.301643431186676
Batch 18/64 loss: 0.3026738166809082
Batch 19/64 loss: 0.3023643493652344
Batch 20/64 loss: 0.2960907220840454
Batch 21/64 loss: 0.294567346572876
Batch 22/64 loss: 0.29946303367614746
Batch 23/64 loss: 0.30041199922561646
Batch 24/64 loss: 0.2921537160873413
Batch 25/64 loss: 0.30093955993652344
Batch 26/64 loss: 0.2965999245643616
Batch 27/64 loss: 0.30283665657043457
Batch 28/64 loss: 0.3025883436203003
Batch 29/64 loss: 0.3020023703575134
Batch 30/64 loss: 0.2978097200393677
Batch 31/64 loss: 0.30319106578826904
Batch 32/64 loss: 0.29711174964904785
Batch 33/64 loss: 0.2945997714996338
Batch 34/64 loss: 0.3011038899421692
Batch 35/64 loss: 0.3059849143028259
Batch 36/64 loss: 0.3080769181251526
Batch 37/64 loss: 0.30605244636535645
Batch 38/64 loss: 0.3013979196548462
Batch 39/64 loss: 0.3071436882019043
Batch 40/64 loss: 0.29451054334640503
Batch 41/64 loss: 0.30367207527160645
Batch 42/64 loss: 0.3009074926376343
Batch 43/64 loss: 0.3032642602920532
Batch 44/64 loss: 0.3078559637069702
Batch 45/64 loss: 0.29748058319091797
Batch 46/64 loss: 0.2962672710418701
Batch 47/64 loss: 0.3053613305091858
Batch 48/64 loss: 0.30184948444366455
Batch 49/64 loss: 0.3089035749435425
Batch 50/64 loss: 0.3110692501068115
Batch 51/64 loss: 0.30353623628616333
Batch 52/64 loss: 0.30324018001556396
Batch 53/64 loss: 0.29692673683166504
Batch 54/64 loss: 0.3030552864074707
Batch 55/64 loss: 0.30756473541259766
Batch 56/64 loss: 0.3043689727783203
Batch 57/64 loss: 0.298936128616333
Batch 58/64 loss: 0.2944459915161133
Batch 59/64 loss: 0.2942410111427307
Batch 60/64 loss: 0.3069952726364136
Batch 61/64 loss: 0.3040037155151367
Batch 62/64 loss: 0.2976515293121338
Batch 63/64 loss: 0.2986733913421631
Batch 64/64 loss: 0.2944376468658447
Epoch 122  Train loss: 0.30118772936802285  Val loss: 0.3123100168516546
Epoch 123
-------------------------------
Batch 1/64 loss: 0.3041468858718872
Batch 2/64 loss: 0.2973255515098572
Batch 3/64 loss: 0.30906713008880615
Batch 4/64 loss: 0.29805314540863037
Batch 5/64 loss: 0.2982329726219177
Batch 6/64 loss: 0.28989553451538086
Batch 7/64 loss: 0.3017040491104126
Batch 8/64 loss: 0.304548978805542
Batch 9/64 loss: 0.3002285361289978
Batch 10/64 loss: 0.30214500427246094
Batch 11/64 loss: 0.304834246635437
Batch 12/64 loss: 0.2967015504837036
Batch 13/64 loss: 0.299866259098053
Batch 14/64 loss: 0.2928932309150696
Batch 15/64 loss: 0.30529940128326416
Batch 16/64 loss: 0.30644071102142334
Batch 17/64 loss: 0.29713648557662964
Batch 18/64 loss: 0.30287837982177734
Batch 19/64 loss: 0.29900234937667847
Batch 20/64 loss: 0.3005439043045044
Batch 21/64 loss: 0.3040618896484375
Batch 22/64 loss: 0.3080782890319824
Batch 23/64 loss: 0.29955780506134033
Batch 24/64 loss: 0.2992669939994812
Batch 25/64 loss: 0.2951880693435669
Batch 26/64 loss: 0.29572176933288574
Batch 27/64 loss: 0.2925092577934265
Batch 28/64 loss: 0.30126482248306274
Batch 29/64 loss: 0.3001287579536438
Batch 30/64 loss: 0.3018794059753418
Batch 31/64 loss: 0.30119943618774414
Batch 32/64 loss: 0.2963145971298218
Batch 33/64 loss: 0.3033480644226074
Batch 34/64 loss: 0.304338276386261
Batch 35/64 loss: 0.29824477434158325
Batch 36/64 loss: 0.3075081706047058
Batch 37/64 loss: 0.3041543960571289
Batch 38/64 loss: 0.30341875553131104
Batch 39/64 loss: 0.3016842007637024
Batch 40/64 loss: 0.30486345291137695
Batch 41/64 loss: 0.30106109380722046
Batch 42/64 loss: 0.29449474811553955
Batch 43/64 loss: 0.29793310165405273
Batch 44/64 loss: 0.2967081069946289
Batch 45/64 loss: 0.29805541038513184
Batch 46/64 loss: 0.291398823261261
Batch 47/64 loss: 0.30454468727111816
Batch 48/64 loss: 0.30394303798675537
Batch 49/64 loss: 0.30661046504974365
Batch 50/64 loss: 0.30216580629348755
Batch 51/64 loss: 0.29610341787338257
Batch 52/64 loss: 0.300429105758667
Batch 53/64 loss: 0.3003028631210327
Batch 54/64 loss: 0.304890513420105
Batch 55/64 loss: 0.29391229152679443
Batch 56/64 loss: 0.3052985668182373
Batch 57/64 loss: 0.30268752574920654
Batch 58/64 loss: 0.30522429943084717
Batch 59/64 loss: 0.2929285168647766
Batch 60/64 loss: 0.2955220937728882
Batch 61/64 loss: 0.297784686088562
Batch 62/64 loss: 0.29902416467666626
Batch 63/64 loss: 0.2975350022315979
Batch 64/64 loss: 0.3036700487136841
Epoch 123  Train loss: 0.3003919428470088  Val loss: 0.31383020689397334
Epoch 124
-------------------------------
Batch 1/64 loss: 0.301461398601532
Batch 2/64 loss: 0.29164010286331177
Batch 3/64 loss: 0.3022726774215698
Batch 4/64 loss: 0.29878658056259155
Batch 5/64 loss: 0.31061625480651855
Batch 6/64 loss: 0.29505252838134766
Batch 7/64 loss: 0.2990618944168091
Batch 8/64 loss: 0.3059375286102295
Batch 9/64 loss: 0.2928723692893982
Batch 10/64 loss: 0.2983033061027527
Batch 11/64 loss: 0.3119724988937378
Batch 12/64 loss: 0.29944121837615967
Batch 13/64 loss: 0.29751861095428467
Batch 14/64 loss: 0.29694294929504395
Batch 15/64 loss: 0.3004109859466553
Batch 16/64 loss: 0.30378448963165283
Batch 17/64 loss: 0.2907777428627014
Batch 18/64 loss: 0.30155837535858154
Batch 19/64 loss: 0.29462599754333496
Batch 20/64 loss: 0.3028309941291809
Batch 21/64 loss: 0.2947980761528015
Batch 22/64 loss: 0.29922962188720703
Batch 23/64 loss: 0.30115437507629395
Batch 24/64 loss: 0.2926560640335083
Batch 25/64 loss: 0.29428768157958984
Batch 26/64 loss: 0.29465681314468384
Batch 27/64 loss: 0.30101847648620605
Batch 28/64 loss: 0.2972104549407959
Batch 29/64 loss: 0.29192376136779785
Batch 30/64 loss: 0.3007928133010864
Batch 31/64 loss: 0.2996004819869995
Batch 32/64 loss: 0.30149418115615845
Batch 33/64 loss: 0.29758769273757935
Batch 34/64 loss: 0.3002781867980957
Batch 35/64 loss: 0.297370970249176
Batch 36/64 loss: 0.2969050407409668
Batch 37/64 loss: 0.3021444082260132
Batch 38/64 loss: 0.30460262298583984
Batch 39/64 loss: 0.29935920238494873
Batch 40/64 loss: 0.3006119728088379
Batch 41/64 loss: 0.2982481122016907
Batch 42/64 loss: 0.29415494203567505
Batch 43/64 loss: 0.29691576957702637
Batch 44/64 loss: 0.2979954481124878
Batch 45/64 loss: 0.2970127463340759
Batch 46/64 loss: 0.30733048915863037
Batch 47/64 loss: 0.29715871810913086
Batch 48/64 loss: 0.29903995990753174
Batch 49/64 loss: 0.2909409999847412
Batch 50/64 loss: 0.3029521107673645
Batch 51/64 loss: 0.302653431892395
Batch 52/64 loss: 0.2946053743362427
Batch 53/64 loss: 0.2963902950286865
Batch 54/64 loss: 0.2997729182243347
Batch 55/64 loss: 0.29542434215545654
Batch 56/64 loss: 0.2940351366996765
Batch 57/64 loss: 0.3128421902656555
Batch 58/64 loss: 0.3034266233444214
Batch 59/64 loss: 0.31127387285232544
Batch 60/64 loss: 0.3036450147628784
Batch 61/64 loss: 0.29954051971435547
Batch 62/64 loss: 0.3073744773864746
Batch 63/64 loss: 0.3046138882637024
Batch 64/64 loss: 0.3023594617843628
Epoch 124  Train loss: 0.2995712686987484  Val loss: 0.3097306100773238
Saving best model, epoch: 124
Epoch 125
-------------------------------
Batch 1/64 loss: 0.2938697338104248
Batch 2/64 loss: 0.2993844747543335
Batch 3/64 loss: 0.3066835403442383
Batch 4/64 loss: 0.2991877794265747
Batch 5/64 loss: 0.29580074548721313
Batch 6/64 loss: 0.30016767978668213
Batch 7/64 loss: 0.29855525493621826
Batch 8/64 loss: 0.29912781715393066
Batch 9/64 loss: 0.2968612313270569
Batch 10/64 loss: 0.3001835346221924
Batch 11/64 loss: 0.3060101270675659
Batch 12/64 loss: 0.29791176319122314
Batch 13/64 loss: 0.2985246181488037
Batch 14/64 loss: 0.30639517307281494
Batch 15/64 loss: 0.29564690589904785
Batch 16/64 loss: 0.2952784299850464
Batch 17/64 loss: 0.29921209812164307
Batch 18/64 loss: 0.29623663425445557
Batch 19/64 loss: 0.2982255220413208
Batch 20/64 loss: 0.30021095275878906
Batch 21/64 loss: 0.2989821434020996
Batch 22/64 loss: 0.29688870906829834
Batch 23/64 loss: 0.3092734217643738
Batch 24/64 loss: 0.30069804191589355
Batch 25/64 loss: 0.3073645830154419
Batch 26/64 loss: 0.2977168560028076
Batch 27/64 loss: 0.29332393407821655
Batch 28/64 loss: 0.29589223861694336
Batch 29/64 loss: 0.29847121238708496
Batch 30/64 loss: 0.298317551612854
Batch 31/64 loss: 0.2951047420501709
Batch 32/64 loss: 0.300881028175354
Batch 33/64 loss: 0.302831768989563
Batch 34/64 loss: 0.29855406284332275
Batch 35/64 loss: 0.302223801612854
Batch 36/64 loss: 0.29517585039138794
Batch 37/64 loss: 0.2876110076904297
Batch 38/64 loss: 0.3069164752960205
Batch 39/64 loss: 0.3032072186470032
Batch 40/64 loss: 0.3034018278121948
Batch 41/64 loss: 0.2999271750450134
Batch 42/64 loss: 0.3026310205459595
Batch 43/64 loss: 0.2994987964630127
Batch 44/64 loss: 0.3027834892272949
Batch 45/64 loss: 0.29735422134399414
Batch 46/64 loss: 0.3064451217651367
Batch 47/64 loss: 0.3069610595703125
Batch 48/64 loss: 0.30601757764816284
Batch 49/64 loss: 0.29765236377716064
Batch 50/64 loss: 0.29204368591308594
Batch 51/64 loss: 0.3080112934112549
Batch 52/64 loss: 0.30543702840805054
Batch 53/64 loss: 0.2969222664833069
Batch 54/64 loss: 0.3060917854309082
Batch 55/64 loss: 0.3141803741455078
Batch 56/64 loss: 0.30198174715042114
Batch 57/64 loss: 0.29538363218307495
Batch 58/64 loss: 0.29249894618988037
Batch 59/64 loss: 0.29749011993408203
Batch 60/64 loss: 0.30306363105773926
Batch 61/64 loss: 0.2988024950027466
Batch 62/64 loss: 0.30552756786346436
Batch 63/64 loss: 0.29927730560302734
Batch 64/64 loss: 0.29170453548431396
Epoch 125  Train loss: 0.3000952407425525  Val loss: 0.3113939686329504
Epoch 126
-------------------------------
Batch 1/64 loss: 0.2997857332229614
Batch 2/64 loss: 0.3004329204559326
Batch 3/64 loss: 0.3039008378982544
Batch 4/64 loss: 0.29447054862976074
Batch 5/64 loss: 0.3054838180541992
Batch 6/64 loss: 0.2984588146209717
Batch 7/64 loss: 0.30263376235961914
Batch 8/64 loss: 0.29941582679748535
Batch 9/64 loss: 0.294891357421875
Batch 10/64 loss: 0.30235743522644043
Batch 11/64 loss: 0.304803729057312
Batch 12/64 loss: 0.2901325225830078
Batch 13/64 loss: 0.29912227392196655
Batch 14/64 loss: 0.3011680841445923
Batch 15/64 loss: 0.3084144592285156
Batch 16/64 loss: 0.303769052028656
Batch 17/64 loss: 0.2963172197341919
Batch 18/64 loss: 0.2954288125038147
Batch 19/64 loss: 0.29784882068634033
Batch 20/64 loss: 0.2970413565635681
Batch 21/64 loss: 0.2997056841850281
Batch 22/64 loss: 0.30075645446777344
Batch 23/64 loss: 0.2943011522293091
Batch 24/64 loss: 0.294150710105896
Batch 25/64 loss: 0.2959325313568115
Batch 26/64 loss: 0.30226659774780273
Batch 27/64 loss: 0.3049962520599365
Batch 28/64 loss: 0.30503541231155396
Batch 29/64 loss: 0.299379825592041
Batch 30/64 loss: 0.300081729888916
Batch 31/64 loss: 0.30035704374313354
Batch 32/64 loss: 0.29933637380599976
Batch 33/64 loss: 0.30473875999450684
Batch 34/64 loss: 0.3049215078353882
Batch 35/64 loss: 0.30421513319015503
Batch 36/64 loss: 0.3081914782524109
Batch 37/64 loss: 0.29948872327804565
Batch 38/64 loss: 0.30248790979385376
Batch 39/64 loss: 0.2961663603782654
Batch 40/64 loss: 0.3023728132247925
Batch 41/64 loss: 0.3036612272262573
Batch 42/64 loss: 0.29630887508392334
Batch 43/64 loss: 0.3056483864784241
Batch 44/64 loss: 0.305278480052948
Batch 45/64 loss: 0.30280542373657227
Batch 46/64 loss: 0.30068540573120117
Batch 47/64 loss: 0.29706746339797974
Batch 48/64 loss: 0.30028653144836426
Batch 49/64 loss: 0.30396294593811035
Batch 50/64 loss: 0.29894256591796875
Batch 51/64 loss: 0.29805874824523926
Batch 52/64 loss: 0.2988821268081665
Batch 53/64 loss: 0.29565221071243286
Batch 54/64 loss: 0.2981640100479126
Batch 55/64 loss: 0.29979562759399414
Batch 56/64 loss: 0.29826080799102783
Batch 57/64 loss: 0.30000633001327515
Batch 58/64 loss: 0.29718178510665894
Batch 59/64 loss: 0.2952948212623596
Batch 60/64 loss: 0.29598987102508545
Batch 61/64 loss: 0.29704368114471436
Batch 62/64 loss: 0.29470789432525635
Batch 63/64 loss: 0.2965707778930664
Batch 64/64 loss: 0.3030146360397339
Epoch 126  Train loss: 0.299957283337911  Val loss: 0.3118142172233346
Epoch 127
-------------------------------
Batch 1/64 loss: 0.2918548583984375
Batch 2/64 loss: 0.291733980178833
Batch 3/64 loss: 0.2981894016265869
Batch 4/64 loss: 0.3022298812866211
Batch 5/64 loss: 0.3039802312850952
Batch 6/64 loss: 0.310268759727478
Batch 7/64 loss: 0.30692291259765625
Batch 8/64 loss: 0.3005722165107727
Batch 9/64 loss: 0.3063904643058777
Batch 10/64 loss: 0.30297696590423584
Batch 11/64 loss: 0.30363428592681885
Batch 12/64 loss: 0.2954636812210083
Batch 13/64 loss: 0.30250632762908936
Batch 14/64 loss: 0.29879796504974365
Batch 15/64 loss: 0.29811203479766846
Batch 16/64 loss: 0.2975153923034668
Batch 17/64 loss: 0.2985000014305115
Batch 18/64 loss: 0.30617791414260864
Batch 19/64 loss: 0.2949695587158203
Batch 20/64 loss: 0.29564160108566284
Batch 21/64 loss: 0.2988860607147217
Batch 22/64 loss: 0.29647207260131836
Batch 23/64 loss: 0.302051305770874
Batch 24/64 loss: 0.299704909324646
Batch 25/64 loss: 0.29022079706192017
Batch 26/64 loss: 0.2956503629684448
Batch 27/64 loss: 0.30074381828308105
Batch 28/64 loss: 0.3026895523071289
Batch 29/64 loss: 0.29625940322875977
Batch 30/64 loss: 0.29157400131225586
Batch 31/64 loss: 0.2959681749343872
Batch 32/64 loss: 0.30140751600265503
Batch 33/64 loss: 0.29878997802734375
Batch 34/64 loss: 0.2954373359680176
Batch 35/64 loss: 0.30690550804138184
Batch 36/64 loss: 0.3056514263153076
Batch 37/64 loss: 0.29302287101745605
Batch 38/64 loss: 0.29881876707077026
Batch 39/64 loss: 0.2978607416152954
Batch 40/64 loss: 0.29577118158340454
Batch 41/64 loss: 0.2959902882575989
Batch 42/64 loss: 0.29930269718170166
Batch 43/64 loss: 0.30004799365997314
Batch 44/64 loss: 0.2980738878250122
Batch 45/64 loss: 0.3013721704483032
Batch 46/64 loss: 0.2982959747314453
Batch 47/64 loss: 0.3078652024269104
Batch 48/64 loss: 0.3008323907852173
Batch 49/64 loss: 0.2985348701477051
Batch 50/64 loss: 0.2898104786872864
Batch 51/64 loss: 0.30662816762924194
Batch 52/64 loss: 0.2972185015678406
Batch 53/64 loss: 0.2966945171356201
Batch 54/64 loss: 0.29954057931900024
Batch 55/64 loss: 0.28851592540740967
Batch 56/64 loss: 0.296414315700531
Batch 57/64 loss: 0.2990957498550415
Batch 58/64 loss: 0.30555588006973267
Batch 59/64 loss: 0.299801230430603
Batch 60/64 loss: 0.3015926480293274
Batch 61/64 loss: 0.29318737983703613
Batch 62/64 loss: 0.2960737943649292
Batch 63/64 loss: 0.301425039768219
Batch 64/64 loss: 0.29571616649627686
Epoch 127  Train loss: 0.29904283962997735  Val loss: 0.31104070603642675
Epoch 128
-------------------------------
Batch 1/64 loss: 0.3062366247177124
Batch 2/64 loss: 0.2982785701751709
Batch 3/64 loss: 0.29151153564453125
Batch 4/64 loss: 0.29524707794189453
Batch 5/64 loss: 0.2947980761528015
Batch 6/64 loss: 0.3043651580810547
Batch 7/64 loss: 0.3063974380493164
Batch 8/64 loss: 0.3044204115867615
Batch 9/64 loss: 0.29805153608322144
Batch 10/64 loss: 0.2962857484817505
Batch 11/64 loss: 0.3029913902282715
Batch 12/64 loss: 0.3016541600227356
Batch 13/64 loss: 0.30097126960754395
Batch 14/64 loss: 0.30256056785583496
Batch 15/64 loss: 0.30181747674942017
Batch 16/64 loss: 0.29384684562683105
Batch 17/64 loss: 0.30117475986480713
Batch 18/64 loss: 0.30576586723327637
Batch 19/64 loss: 0.29957664012908936
Batch 20/64 loss: 0.3067350387573242
Batch 21/64 loss: 0.3041786551475525
Batch 22/64 loss: 0.3023498058319092
Batch 23/64 loss: 0.29645514488220215
Batch 24/64 loss: 0.3045309782028198
Batch 25/64 loss: 0.2996560335159302
Batch 26/64 loss: 0.28937816619873047
Batch 27/64 loss: 0.3017413020133972
Batch 28/64 loss: 0.29756951332092285
Batch 29/64 loss: 0.29241621494293213
Batch 30/64 loss: 0.30263155698776245
Batch 31/64 loss: 0.29621440172195435
Batch 32/64 loss: 0.3022359013557434
Batch 33/64 loss: 0.29959970712661743
Batch 34/64 loss: 0.30532288551330566
Batch 35/64 loss: 0.29880785942077637
Batch 36/64 loss: 0.2948140501976013
Batch 37/64 loss: 0.2995670437812805
Batch 38/64 loss: 0.29763078689575195
Batch 39/64 loss: 0.2998366355895996
Batch 40/64 loss: 0.3034667372703552
Batch 41/64 loss: 0.2965744733810425
Batch 42/64 loss: 0.29880857467651367
Batch 43/64 loss: 0.29336321353912354
Batch 44/64 loss: 0.30488765239715576
Batch 45/64 loss: 0.2925375699996948
Batch 46/64 loss: 0.30193328857421875
Batch 47/64 loss: 0.31277740001678467
Batch 48/64 loss: 0.2955923080444336
Batch 49/64 loss: 0.3000110387802124
Batch 50/64 loss: 0.30029094219207764
Batch 51/64 loss: 0.294008731842041
Batch 52/64 loss: 0.29018986225128174
Batch 53/64 loss: 0.29506802558898926
Batch 54/64 loss: 0.30556273460388184
Batch 55/64 loss: 0.30325615406036377
Batch 56/64 loss: 0.2907431721687317
Batch 57/64 loss: 0.2957260012626648
Batch 58/64 loss: 0.3023579716682434
Batch 59/64 loss: 0.2958170175552368
Batch 60/64 loss: 0.29803311824798584
Batch 61/64 loss: 0.2965714931488037
Batch 62/64 loss: 0.2977888584136963
Batch 63/64 loss: 0.292594313621521
Batch 64/64 loss: 0.2935435175895691
Epoch 128  Train loss: 0.2992273117981705  Val loss: 0.3114382364495923
Epoch 129
-------------------------------
Batch 1/64 loss: 0.30055636167526245
Batch 2/64 loss: 0.2903052568435669
Batch 3/64 loss: 0.3059822916984558
Batch 4/64 loss: 0.2971401810646057
Batch 5/64 loss: 0.3028329610824585
Batch 6/64 loss: 0.2978113293647766
Batch 7/64 loss: 0.3015502095222473
Batch 8/64 loss: 0.2878478169441223
Batch 9/64 loss: 0.2916884422302246
Batch 10/64 loss: 0.29119306802749634
Batch 11/64 loss: 0.2976423501968384
Batch 12/64 loss: 0.2980630397796631
Batch 13/64 loss: 0.2907264232635498
Batch 14/64 loss: 0.302301824092865
Batch 15/64 loss: 0.2977011203765869
Batch 16/64 loss: 0.2963290214538574
Batch 17/64 loss: 0.300903856754303
Batch 18/64 loss: 0.2928694486618042
Batch 19/64 loss: 0.30787819623947144
Batch 20/64 loss: 0.294622004032135
Batch 21/64 loss: 0.2948330044746399
Batch 22/64 loss: 0.30156487226486206
Batch 23/64 loss: 0.29640525579452515
Batch 24/64 loss: 0.3021182417869568
Batch 25/64 loss: 0.297763466835022
Batch 26/64 loss: 0.2974454164505005
Batch 27/64 loss: 0.2997359037399292
Batch 28/64 loss: 0.30046409368515015
Batch 29/64 loss: 0.2955350875854492
Batch 30/64 loss: 0.3020783066749573
Batch 31/64 loss: 0.2993595004081726
Batch 32/64 loss: 0.29865074157714844
Batch 33/64 loss: 0.3050856590270996
Batch 34/64 loss: 0.2988467812538147
Batch 35/64 loss: 0.2966681718826294
Batch 36/64 loss: 0.28925639390945435
Batch 37/64 loss: 0.2992272973060608
Batch 38/64 loss: 0.30023807287216187
Batch 39/64 loss: 0.29939186573028564
Batch 40/64 loss: 0.2918511629104614
Batch 41/64 loss: 0.2945854067802429
Batch 42/64 loss: 0.2989327907562256
Batch 43/64 loss: 0.295962929725647
Batch 44/64 loss: 0.2980448007583618
Batch 45/64 loss: 0.3004828691482544
Batch 46/64 loss: 0.30003422498703003
Batch 47/64 loss: 0.29507356882095337
Batch 48/64 loss: 0.29850077629089355
Batch 49/64 loss: 0.29584312438964844
Batch 50/64 loss: 0.3025054931640625
Batch 51/64 loss: 0.2902138829231262
Batch 52/64 loss: 0.3081769347190857
Batch 53/64 loss: 0.30476832389831543
Batch 54/64 loss: 0.29042214155197144
Batch 55/64 loss: 0.29474252462387085
Batch 56/64 loss: 0.2947651147842407
Batch 57/64 loss: 0.30172252655029297
Batch 58/64 loss: 0.29516100883483887
Batch 59/64 loss: 0.29113316535949707
Batch 60/64 loss: 0.3017176389694214
Batch 61/64 loss: 0.3019235134124756
Batch 62/64 loss: 0.29253774881362915
Batch 63/64 loss: 0.29317939281463623
Batch 64/64 loss: 0.2953610420227051
Epoch 129  Train loss: 0.29763788522458545  Val loss: 0.3104642064301009
Epoch 130
-------------------------------
Batch 1/64 loss: 0.2997743487358093
Batch 2/64 loss: 0.28910738229751587
Batch 3/64 loss: 0.2892261743545532
Batch 4/64 loss: 0.3092314600944519
Batch 5/64 loss: 0.2899059057235718
Batch 6/64 loss: 0.28954190015792847
Batch 7/64 loss: 0.29645317792892456
Batch 8/64 loss: 0.3022165298461914
Batch 9/64 loss: 0.2928001880645752
Batch 10/64 loss: 0.29913121461868286
Batch 11/64 loss: 0.3064265251159668
Batch 12/64 loss: 0.2872885465621948
Batch 13/64 loss: 0.29715847969055176
Batch 14/64 loss: 0.29384225606918335
Batch 15/64 loss: 0.29474830627441406
Batch 16/64 loss: 0.293967604637146
Batch 17/64 loss: 0.29740601778030396
Batch 18/64 loss: 0.30202925205230713
Batch 19/64 loss: 0.2989221215248108
Batch 20/64 loss: 0.2988671660423279
Batch 21/64 loss: 0.3051843047142029
Batch 22/64 loss: 0.3004375696182251
Batch 23/64 loss: 0.2967568039894104
Batch 24/64 loss: 0.29200196266174316
Batch 25/64 loss: 0.30268555879592896
Batch 26/64 loss: 0.29303598403930664
Batch 27/64 loss: 0.3024895191192627
Batch 28/64 loss: 0.29873204231262207
Batch 29/64 loss: 0.298079252243042
Batch 30/64 loss: 0.30766499042510986
Batch 31/64 loss: 0.2958400845527649
Batch 32/64 loss: 0.29981184005737305
Batch 33/64 loss: 0.3025687336921692
Batch 34/64 loss: 0.30278241634368896
Batch 35/64 loss: 0.29485946893692017
Batch 36/64 loss: 0.29881906509399414
Batch 37/64 loss: 0.29742348194122314
Batch 38/64 loss: 0.29725801944732666
Batch 39/64 loss: 0.2865004539489746
Batch 40/64 loss: 0.2998127341270447
Batch 41/64 loss: 0.30256152153015137
Batch 42/64 loss: 0.2979542016983032
Batch 43/64 loss: 0.29577016830444336
Batch 44/64 loss: 0.3099743127822876
Batch 45/64 loss: 0.29383236169815063
Batch 46/64 loss: 0.2917686700820923
Batch 47/64 loss: 0.294611394405365
Batch 48/64 loss: 0.30199134349823
Batch 49/64 loss: 0.30145132541656494
Batch 50/64 loss: 0.3063795566558838
Batch 51/64 loss: 0.28846830129623413
Batch 52/64 loss: 0.29599976539611816
Batch 53/64 loss: 0.3010450005531311
Batch 54/64 loss: 0.2985866069793701
Batch 55/64 loss: 0.29822349548339844
Batch 56/64 loss: 0.29780328273773193
Batch 57/64 loss: 0.2999148368835449
Batch 58/64 loss: 0.2987987995147705
Batch 59/64 loss: 0.29500019550323486
Batch 60/64 loss: 0.2968086004257202
Batch 61/64 loss: 0.29155945777893066
Batch 62/64 loss: 0.28929710388183594
Batch 63/64 loss: 0.298295259475708
Batch 64/64 loss: 0.29568761587142944
Epoch 130  Train loss: 0.2975474528237885  Val loss: 0.30809054751576426
Saving best model, epoch: 130
Epoch 131
-------------------------------
Batch 1/64 loss: 0.2862669825553894
Batch 2/64 loss: 0.2983752489089966
Batch 3/64 loss: 0.29420530796051025
Batch 4/64 loss: 0.28864824771881104
Batch 5/64 loss: 0.2964484691619873
Batch 6/64 loss: 0.294694185256958
Batch 7/64 loss: 0.3041127920150757
Batch 8/64 loss: 0.3019947409629822
Batch 9/64 loss: 0.30318737030029297
Batch 10/64 loss: 0.29598093032836914
Batch 11/64 loss: 0.28730690479278564
Batch 12/64 loss: 0.2960382103919983
Batch 13/64 loss: 0.29440468549728394
Batch 14/64 loss: 0.29753875732421875
Batch 15/64 loss: 0.29928267002105713
Batch 16/64 loss: 0.30264097452163696
Batch 17/64 loss: 0.29226619005203247
Batch 18/64 loss: 0.28965842723846436
Batch 19/64 loss: 0.3048763871192932
Batch 20/64 loss: 0.29157567024230957
Batch 21/64 loss: 0.2999093532562256
Batch 22/64 loss: 0.2954034209251404
Batch 23/64 loss: 0.28816330432891846
Batch 24/64 loss: 0.2958148717880249
Batch 25/64 loss: 0.3000861406326294
Batch 26/64 loss: 0.2984040379524231
Batch 27/64 loss: 0.30285143852233887
Batch 28/64 loss: 0.2975005507469177
Batch 29/64 loss: 0.29370880126953125
Batch 30/64 loss: 0.2939521074295044
Batch 31/64 loss: 0.2983183264732361
Batch 32/64 loss: 0.2919861078262329
Batch 33/64 loss: 0.284725546836853
Batch 34/64 loss: 0.2948343753814697
Batch 35/64 loss: 0.30129510164260864
Batch 36/64 loss: 0.29726171493530273
Batch 37/64 loss: 0.29791259765625
Batch 38/64 loss: 0.2985389232635498
Batch 39/64 loss: 0.2977280616760254
Batch 40/64 loss: 0.28932619094848633
Batch 41/64 loss: 0.29594647884368896
Batch 42/64 loss: 0.2934519052505493
Batch 43/64 loss: 0.28730154037475586
Batch 44/64 loss: 0.2965266704559326
Batch 45/64 loss: 0.2980101704597473
Batch 46/64 loss: 0.2994953393936157
Batch 47/64 loss: 0.29778558015823364
Batch 48/64 loss: 0.3003418445587158
Batch 49/64 loss: 0.2961766719818115
Batch 50/64 loss: 0.2938762903213501
Batch 51/64 loss: 0.2919071316719055
Batch 52/64 loss: 0.3025815486907959
Batch 53/64 loss: 0.2950405478477478
Batch 54/64 loss: 0.302581787109375
Batch 55/64 loss: 0.2989005446434021
Batch 56/64 loss: 0.3046358823776245
Batch 57/64 loss: 0.30099034309387207
Batch 58/64 loss: 0.2931153178215027
Batch 59/64 loss: 0.3015901446342468
Batch 60/64 loss: 0.29668354988098145
Batch 61/64 loss: 0.30525755882263184
Batch 62/64 loss: 0.30170297622680664
Batch 63/64 loss: 0.30655229091644287
Batch 64/64 loss: 0.2998749613761902
Epoch 131  Train loss: 0.29682482294007845  Val loss: 0.3078580672798288
Saving best model, epoch: 131
Epoch 132
-------------------------------
Batch 1/64 loss: 0.29934585094451904
Batch 2/64 loss: 0.3013675808906555
Batch 3/64 loss: 0.2981712818145752
Batch 4/64 loss: 0.2911437749862671
Batch 5/64 loss: 0.2973204255104065
Batch 6/64 loss: 0.3006415367126465
Batch 7/64 loss: 0.29408055543899536
Batch 8/64 loss: 0.29702138900756836
Batch 9/64 loss: 0.2958877682685852
Batch 10/64 loss: 0.30577242374420166
Batch 11/64 loss: 0.3055914044380188
Batch 12/64 loss: 0.29384273290634155
Batch 13/64 loss: 0.29490959644317627
Batch 14/64 loss: 0.29865574836730957
Batch 15/64 loss: 0.30060774087905884
Batch 16/64 loss: 0.29293566942214966
Batch 17/64 loss: 0.30025988817214966
Batch 18/64 loss: 0.29403257369995117
Batch 19/64 loss: 0.2904065251350403
Batch 20/64 loss: 0.29672664403915405
Batch 21/64 loss: 0.29708653688430786
Batch 22/64 loss: 0.2887653708457947
Batch 23/64 loss: 0.2949426770210266
Batch 24/64 loss: 0.30129849910736084
Batch 25/64 loss: 0.29754549264907837
Batch 26/64 loss: 0.30068373680114746
Batch 27/64 loss: 0.29088127613067627
Batch 28/64 loss: 0.2970844507217407
Batch 29/64 loss: 0.29658955335617065
Batch 30/64 loss: 0.28906673192977905
Batch 31/64 loss: 0.3022572994232178
Batch 32/64 loss: 0.2902933359146118
Batch 33/64 loss: 0.30573147535324097
Batch 34/64 loss: 0.29346102476119995
Batch 35/64 loss: 0.28897976875305176
Batch 36/64 loss: 0.28908205032348633
Batch 37/64 loss: 0.297948956489563
Batch 38/64 loss: 0.2955523729324341
Batch 39/64 loss: 0.2942413091659546
Batch 40/64 loss: 0.2977592349052429
Batch 41/64 loss: 0.2878957986831665
Batch 42/64 loss: 0.30028200149536133
Batch 43/64 loss: 0.2987951636314392
Batch 44/64 loss: 0.2931879162788391
Batch 45/64 loss: 0.2952996492385864
Batch 46/64 loss: 0.292308509349823
Batch 47/64 loss: 0.29568809270858765
Batch 48/64 loss: 0.2912025451660156
Batch 49/64 loss: 0.290361225605011
Batch 50/64 loss: 0.29718637466430664
Batch 51/64 loss: 0.29967379570007324
Batch 52/64 loss: 0.2992972135543823
Batch 53/64 loss: 0.29760313034057617
Batch 54/64 loss: 0.2943549156188965
Batch 55/64 loss: 0.2954674959182739
Batch 56/64 loss: 0.2885776162147522
Batch 57/64 loss: 0.29378068447113037
Batch 58/64 loss: 0.29541265964508057
Batch 59/64 loss: 0.2927659749984741
Batch 60/64 loss: 0.3033694624900818
Batch 61/64 loss: 0.2986377477645874
Batch 62/64 loss: 0.29698944091796875
Batch 63/64 loss: 0.2956218719482422
Batch 64/64 loss: 0.29346442222595215
Epoch 132  Train loss: 0.29602870380177215  Val loss: 0.3063860136209075
Saving best model, epoch: 132
Epoch 133
-------------------------------
Batch 1/64 loss: 0.29548460245132446
Batch 2/64 loss: 0.28985798358917236
Batch 3/64 loss: 0.29707014560699463
Batch 4/64 loss: 0.29659152030944824
Batch 5/64 loss: 0.2969304919242859
Batch 6/64 loss: 0.30633848905563354
Batch 7/64 loss: 0.29102271795272827
Batch 8/64 loss: 0.29789066314697266
Batch 9/64 loss: 0.29818302392959595
Batch 10/64 loss: 0.313448965549469
Batch 11/64 loss: 0.29274284839630127
Batch 12/64 loss: 0.2950894832611084
Batch 13/64 loss: 0.2941932678222656
Batch 14/64 loss: 0.306463360786438
Batch 15/64 loss: 0.29382628202438354
Batch 16/64 loss: 0.29300183057785034
Batch 17/64 loss: 0.3042970895767212
Batch 18/64 loss: 0.2902090549468994
Batch 19/64 loss: 0.3018094301223755
Batch 20/64 loss: 0.3010466694831848
Batch 21/64 loss: 0.29346686601638794
Batch 22/64 loss: 0.29133427143096924
Batch 23/64 loss: 0.2946256399154663
Batch 24/64 loss: 0.29906344413757324
Batch 25/64 loss: 0.3001556396484375
Batch 26/64 loss: 0.302343487739563
Batch 27/64 loss: 0.29152780771255493
Batch 28/64 loss: 0.29487931728363037
Batch 29/64 loss: 0.2953289747238159
Batch 30/64 loss: 0.3028815984725952
Batch 31/64 loss: 0.2911036014556885
Batch 32/64 loss: 0.29595035314559937
Batch 33/64 loss: 0.2935314178466797
Batch 34/64 loss: 0.29266202449798584
Batch 35/64 loss: 0.2964145541191101
Batch 36/64 loss: 0.29370421171188354
Batch 37/64 loss: 0.29775869846343994
Batch 38/64 loss: 0.29822713136672974
Batch 39/64 loss: 0.2977789044380188
Batch 40/64 loss: 0.29971957206726074
Batch 41/64 loss: 0.2989990711212158
Batch 42/64 loss: 0.28852617740631104
Batch 43/64 loss: 0.30648648738861084
Batch 44/64 loss: 0.2962053418159485
Batch 45/64 loss: 0.2965075969696045
Batch 46/64 loss: 0.29266971349716187
Batch 47/64 loss: 0.28458040952682495
Batch 48/64 loss: 0.30052340030670166
Batch 49/64 loss: 0.30739015340805054
Batch 50/64 loss: 0.28737199306488037
Batch 51/64 loss: 0.29309403896331787
Batch 52/64 loss: 0.2950209975242615
Batch 53/64 loss: 0.29248446226119995
Batch 54/64 loss: 0.29387497901916504
Batch 55/64 loss: 0.28898268938064575
Batch 56/64 loss: 0.2988603115081787
Batch 57/64 loss: 0.2927662134170532
Batch 58/64 loss: 0.29248344898223877
Batch 59/64 loss: 0.3042411804199219
Batch 60/64 loss: 0.2935676574707031
Batch 61/64 loss: 0.29388880729675293
Batch 62/64 loss: 0.29546111822128296
Batch 63/64 loss: 0.2933591604232788
Batch 64/64 loss: 0.2911391258239746
Epoch 133  Train loss: 0.2962141990661621  Val loss: 0.3074526723307842
Epoch 134
-------------------------------
Batch 1/64 loss: 0.29345548152923584
Batch 2/64 loss: 0.291884183883667
Batch 3/64 loss: 0.29052579402923584
Batch 4/64 loss: 0.2938723564147949
Batch 5/64 loss: 0.3048478364944458
Batch 6/64 loss: 0.29607701301574707
Batch 7/64 loss: 0.2808946371078491
Batch 8/64 loss: 0.2993887662887573
Batch 9/64 loss: 0.2989969253540039
Batch 10/64 loss: 0.2938516139984131
Batch 11/64 loss: 0.29778003692626953
Batch 12/64 loss: 0.29707610607147217
Batch 13/64 loss: 0.29046666622161865
Batch 14/64 loss: 0.29373276233673096
Batch 15/64 loss: 0.30157387256622314
Batch 16/64 loss: 0.3027421236038208
Batch 17/64 loss: 0.2980097532272339
Batch 18/64 loss: 0.29086172580718994
Batch 19/64 loss: 0.3005567193031311
Batch 20/64 loss: 0.294472336769104
Batch 21/64 loss: 0.2856258153915405
Batch 22/64 loss: 0.2874845266342163
Batch 23/64 loss: 0.29190361499786377
Batch 24/64 loss: 0.2948726415634155
Batch 25/64 loss: 0.2945237159729004
Batch 26/64 loss: 0.30030912160873413
Batch 27/64 loss: 0.29241180419921875
Batch 28/64 loss: 0.29483479261398315
Batch 29/64 loss: 0.3020471930503845
Batch 30/64 loss: 0.2883455753326416
Batch 31/64 loss: 0.2987474799156189
Batch 32/64 loss: 0.2927777171134949
Batch 33/64 loss: 0.2952136993408203
Batch 34/64 loss: 0.3007444143295288
Batch 35/64 loss: 0.2932283282279968
Batch 36/64 loss: 0.2972641587257385
Batch 37/64 loss: 0.2983042001724243
Batch 38/64 loss: 0.2983855605125427
Batch 39/64 loss: 0.30344682931900024
Batch 40/64 loss: 0.293143630027771
Batch 41/64 loss: 0.3020750880241394
Batch 42/64 loss: 0.297717809677124
Batch 43/64 loss: 0.29847776889801025
Batch 44/64 loss: 0.29197824001312256
Batch 45/64 loss: 0.2913930416107178
Batch 46/64 loss: 0.29071903228759766
Batch 47/64 loss: 0.29526418447494507
Batch 48/64 loss: 0.2963857054710388
Batch 49/64 loss: 0.29247570037841797
Batch 50/64 loss: 0.29315394163131714
Batch 51/64 loss: 0.2911731004714966
Batch 52/64 loss: 0.2982836365699768
Batch 53/64 loss: 0.29228514432907104
Batch 54/64 loss: 0.29675793647766113
Batch 55/64 loss: 0.29055505990982056
Batch 56/64 loss: 0.29992377758026123
Batch 57/64 loss: 0.2990705370903015
Batch 58/64 loss: 0.29744434356689453
Batch 59/64 loss: 0.29479628801345825
Batch 60/64 loss: 0.29225683212280273
Batch 61/64 loss: 0.2916715145111084
Batch 62/64 loss: 0.2992018461227417
Batch 63/64 loss: 0.2954561710357666
Batch 64/64 loss: 0.299008846282959
Epoch 134  Train loss: 0.29533262533300064  Val loss: 0.3081305219545397
Epoch 135
-------------------------------
Batch 1/64 loss: 0.2999371886253357
Batch 2/64 loss: 0.29605889320373535
Batch 3/64 loss: 0.2915297746658325
Batch 4/64 loss: 0.29031360149383545
Batch 5/64 loss: 0.2947613000869751
Batch 6/64 loss: 0.2833116054534912
Batch 7/64 loss: 0.29333603382110596
Batch 8/64 loss: 0.29495346546173096
Batch 9/64 loss: 0.29620563983917236
Batch 10/64 loss: 0.2989078760147095
Batch 11/64 loss: 0.2982383966445923
Batch 12/64 loss: 0.28676295280456543
Batch 13/64 loss: 0.30055856704711914
Batch 14/64 loss: 0.2912794351577759
Batch 15/64 loss: 0.29186999797821045
Batch 16/64 loss: 0.2964862585067749
Batch 17/64 loss: 0.2894155979156494
Batch 18/64 loss: 0.2990453243255615
Batch 19/64 loss: 0.29146575927734375
Batch 20/64 loss: 0.2985948324203491
Batch 21/64 loss: 0.29719746112823486
Batch 22/64 loss: 0.2923230528831482
Batch 23/64 loss: 0.29037225246429443
Batch 24/64 loss: 0.3033463954925537
Batch 25/64 loss: 0.3026859760284424
Batch 26/64 loss: 0.29711276292800903
Batch 27/64 loss: 0.2911205291748047
Batch 28/64 loss: 0.28261685371398926
Batch 29/64 loss: 0.29515963792800903
Batch 30/64 loss: 0.2986559271812439
Batch 31/64 loss: 0.29955291748046875
Batch 32/64 loss: 0.290738582611084
Batch 33/64 loss: 0.2902986407279968
Batch 34/64 loss: 0.29451388120651245
Batch 35/64 loss: 0.2993403673171997
Batch 36/64 loss: 0.30782008171081543
Batch 37/64 loss: 0.29196465015411377
Batch 38/64 loss: 0.2952582836151123
Batch 39/64 loss: 0.29146790504455566
Batch 40/64 loss: 0.2899351119995117
Batch 41/64 loss: 0.2987990379333496
Batch 42/64 loss: 0.29655706882476807
Batch 43/64 loss: 0.29863059520721436
Batch 44/64 loss: 0.3011791706085205
Batch 45/64 loss: 0.2980331778526306
Batch 46/64 loss: 0.28837448358535767
Batch 47/64 loss: 0.29965126514434814
Batch 48/64 loss: 0.29899752140045166
Batch 49/64 loss: 0.2950340509414673
Batch 50/64 loss: 0.2930040955543518
Batch 51/64 loss: 0.290235698223114
Batch 52/64 loss: 0.2907494306564331
Batch 53/64 loss: 0.29993951320648193
Batch 54/64 loss: 0.3017008900642395
Batch 55/64 loss: 0.29451560974121094
Batch 56/64 loss: 0.28896814584732056
Batch 57/64 loss: 0.2836189270019531
Batch 58/64 loss: 0.2949250340461731
Batch 59/64 loss: 0.29235661029815674
Batch 60/64 loss: 0.30159109830856323
Batch 61/64 loss: 0.30833953619003296
Batch 62/64 loss: 0.28487199544906616
Batch 63/64 loss: 0.2898142337799072
Batch 64/64 loss: 0.29391443729400635
Epoch 135  Train loss: 0.29482096924501305  Val loss: 0.3064509691651334
Epoch 136
-------------------------------
Batch 1/64 loss: 0.3023030757904053
Batch 2/64 loss: 0.2966780662536621
Batch 3/64 loss: 0.28640735149383545
Batch 4/64 loss: 0.2906306982040405
Batch 5/64 loss: 0.29669153690338135
Batch 6/64 loss: 0.2877160310745239
Batch 7/64 loss: 0.29338395595550537
Batch 8/64 loss: 0.2873913645744324
Batch 9/64 loss: 0.295823872089386
Batch 10/64 loss: 0.28906023502349854
Batch 11/64 loss: 0.28870701789855957
Batch 12/64 loss: 0.30068665742874146
Batch 13/64 loss: 0.29045653343200684
Batch 14/64 loss: 0.2975219488143921
Batch 15/64 loss: 0.2975843548774719
Batch 16/64 loss: 0.2948514223098755
Batch 17/64 loss: 0.2945623993873596
Batch 18/64 loss: 0.29692208766937256
Batch 19/64 loss: 0.292736291885376
Batch 20/64 loss: 0.29736441373825073
Batch 21/64 loss: 0.2995256781578064
Batch 22/64 loss: 0.29715287685394287
Batch 23/64 loss: 0.28911566734313965
Batch 24/64 loss: 0.2973833680152893
Batch 25/64 loss: 0.3048821687698364
Batch 26/64 loss: 0.2838943600654602
Batch 27/64 loss: 0.2935224771499634
Batch 28/64 loss: 0.2933783531188965
Batch 29/64 loss: 0.2854316830635071
Batch 30/64 loss: 0.2845454216003418
Batch 31/64 loss: 0.29587340354919434
Batch 32/64 loss: 0.29864662885665894
Batch 33/64 loss: 0.29589414596557617
Batch 34/64 loss: 0.2993248701095581
Batch 35/64 loss: 0.29011285305023193
Batch 36/64 loss: 0.29525840282440186
Batch 37/64 loss: 0.29817163944244385
Batch 38/64 loss: 0.296964168548584
Batch 39/64 loss: 0.2988043427467346
Batch 40/64 loss: 0.301472544670105
Batch 41/64 loss: 0.29958951473236084
Batch 42/64 loss: 0.2898539900779724
Batch 43/64 loss: 0.31168025732040405
Batch 44/64 loss: 0.2958136796951294
Batch 45/64 loss: 0.2873666286468506
Batch 46/64 loss: 0.2975943088531494
Batch 47/64 loss: 0.29281342029571533
Batch 48/64 loss: 0.2923295497894287
Batch 49/64 loss: 0.2960280179977417
Batch 50/64 loss: 0.2969186305999756
Batch 51/64 loss: 0.297508180141449
Batch 52/64 loss: 0.29173290729522705
Batch 53/64 loss: 0.29216206073760986
Batch 54/64 loss: 0.295576810836792
Batch 55/64 loss: 0.287278413772583
Batch 56/64 loss: 0.29205334186553955
Batch 57/64 loss: 0.28736162185668945
Batch 58/64 loss: 0.29089319705963135
Batch 59/64 loss: 0.2969224452972412
Batch 60/64 loss: 0.30019664764404297
Batch 61/64 loss: 0.30641984939575195
Batch 62/64 loss: 0.29650795459747314
Batch 63/64 loss: 0.299296498298645
Batch 64/64 loss: 0.3009139895439148
Epoch 136  Train loss: 0.29484576921837  Val loss: 0.3067994910417144
Epoch 137
-------------------------------
Batch 1/64 loss: 0.3012084364891052
Batch 2/64 loss: 0.2900437116622925
Batch 3/64 loss: 0.29246610403060913
Batch 4/64 loss: 0.3021828532218933
Batch 5/64 loss: 0.29018521308898926
Batch 6/64 loss: 0.2989046573638916
Batch 7/64 loss: 0.29743659496307373
Batch 8/64 loss: 0.29672926664352417
Batch 9/64 loss: 0.29714155197143555
Batch 10/64 loss: 0.28801167011260986
Batch 11/64 loss: 0.28655028343200684
Batch 12/64 loss: 0.28638243675231934
Batch 13/64 loss: 0.297313392162323
Batch 14/64 loss: 0.28771406412124634
Batch 15/64 loss: 0.2914198040962219
Batch 16/64 loss: 0.2926592230796814
Batch 17/64 loss: 0.29628801345825195
Batch 18/64 loss: 0.3007967472076416
Batch 19/64 loss: 0.2899984121322632
Batch 20/64 loss: 0.29134976863861084
Batch 21/64 loss: 0.30180567502975464
Batch 22/64 loss: 0.2946476340293884
Batch 23/64 loss: 0.29882103204727173
Batch 24/64 loss: 0.2860759496688843
Batch 25/64 loss: 0.2898368835449219
Batch 26/64 loss: 0.28599852323532104
Batch 27/64 loss: 0.2945428490638733
Batch 28/64 loss: 0.2890833020210266
Batch 29/64 loss: 0.296705424785614
Batch 30/64 loss: 0.2989850640296936
Batch 31/64 loss: 0.29281580448150635
Batch 32/64 loss: 0.28970885276794434
Batch 33/64 loss: 0.2926267385482788
Batch 34/64 loss: 0.29570287466049194
Batch 35/64 loss: 0.30148380994796753
Batch 36/64 loss: 0.296608567237854
Batch 37/64 loss: 0.2945120930671692
Batch 38/64 loss: 0.29443836212158203
Batch 39/64 loss: 0.2913801074028015
Batch 40/64 loss: 0.2866365909576416
Batch 41/64 loss: 0.2923300266265869
Batch 42/64 loss: 0.30056607723236084
Batch 43/64 loss: 0.2950388193130493
Batch 44/64 loss: 0.29542142152786255
Batch 45/64 loss: 0.28472834825515747
Batch 46/64 loss: 0.29578328132629395
Batch 47/64 loss: 0.28866302967071533
Batch 48/64 loss: 0.29462021589279175
Batch 49/64 loss: 0.2915247678756714
Batch 50/64 loss: 0.2966848611831665
Batch 51/64 loss: 0.2965039014816284
Batch 52/64 loss: 0.2960541248321533
Batch 53/64 loss: 0.2896881699562073
Batch 54/64 loss: 0.3011760711669922
Batch 55/64 loss: 0.2954009771347046
Batch 56/64 loss: 0.29756879806518555
Batch 57/64 loss: 0.2908717393875122
Batch 58/64 loss: 0.29802483320236206
Batch 59/64 loss: 0.29576945304870605
Batch 60/64 loss: 0.29238003492355347
Batch 61/64 loss: 0.2908133268356323
Batch 62/64 loss: 0.2877305746078491
Batch 63/64 loss: 0.2972618341445923
Batch 64/64 loss: 0.29593807458877563
Epoch 137  Train loss: 0.2938628484221066  Val loss: 0.3071543559995304
Epoch 138
-------------------------------
Batch 1/64 loss: 0.29281938076019287
Batch 2/64 loss: 0.29910141229629517
Batch 3/64 loss: 0.2975149154663086
Batch 4/64 loss: 0.29322606325149536
Batch 5/64 loss: 0.3051729202270508
Batch 6/64 loss: 0.28961002826690674
Batch 7/64 loss: 0.2929365634918213
Batch 8/64 loss: 0.29278016090393066
Batch 9/64 loss: 0.2929002046585083
Batch 10/64 loss: 0.2914930582046509
Batch 11/64 loss: 0.2986464500427246
Batch 12/64 loss: 0.28534603118896484
Batch 13/64 loss: 0.28772664070129395
Batch 14/64 loss: 0.28753483295440674
Batch 15/64 loss: 0.30325937271118164
Batch 16/64 loss: 0.29276764392852783
Batch 17/64 loss: 0.290321946144104
Batch 18/64 loss: 0.2910430431365967
Batch 19/64 loss: 0.30060362815856934
Batch 20/64 loss: 0.2910562753677368
Batch 21/64 loss: 0.298747181892395
Batch 22/64 loss: 0.28952181339263916
Batch 23/64 loss: 0.2890653610229492
Batch 24/64 loss: 0.29791510105133057
Batch 25/64 loss: 0.28745585680007935
Batch 26/64 loss: 0.3000452518463135
Batch 27/64 loss: 0.2954217195510864
Batch 28/64 loss: 0.28826332092285156
Batch 29/64 loss: 0.28803300857543945
Batch 30/64 loss: 0.2930554151535034
Batch 31/64 loss: 0.2961322069168091
Batch 32/64 loss: 0.298525333404541
Batch 33/64 loss: 0.28948909044265747
Batch 34/64 loss: 0.2929432988166809
Batch 35/64 loss: 0.28832095861434937
Batch 36/64 loss: 0.29053759574890137
Batch 37/64 loss: 0.29552966356277466
Batch 38/64 loss: 0.289445698261261
Batch 39/64 loss: 0.2925540804862976
Batch 40/64 loss: 0.29313981533050537
Batch 41/64 loss: 0.2845442295074463
Batch 42/64 loss: 0.2904754877090454
Batch 43/64 loss: 0.2934303283691406
Batch 44/64 loss: 0.2970629930496216
Batch 45/64 loss: 0.29835569858551025
Batch 46/64 loss: 0.2912564277648926
Batch 47/64 loss: 0.2917467951774597
Batch 48/64 loss: 0.30125516653060913
Batch 49/64 loss: 0.2881307601928711
Batch 50/64 loss: 0.2875560522079468
Batch 51/64 loss: 0.284176766872406
Batch 52/64 loss: 0.2933237552642822
Batch 53/64 loss: 0.2960302233695984
Batch 54/64 loss: 0.2869359254837036
Batch 55/64 loss: 0.29072362184524536
Batch 56/64 loss: 0.2938319444656372
Batch 57/64 loss: 0.2887014150619507
Batch 58/64 loss: 0.2963848114013672
Batch 59/64 loss: 0.29373276233673096
Batch 60/64 loss: 0.30195820331573486
Batch 61/64 loss: 0.2985907793045044
Batch 62/64 loss: 0.2975785732269287
Batch 63/64 loss: 0.302024781703949
Batch 64/64 loss: 0.2935851812362671
Epoch 138  Train loss: 0.29330194089926925  Val loss: 0.3056231165669628
Saving best model, epoch: 138
Epoch 139
-------------------------------
Batch 1/64 loss: 0.2914391756057739
Batch 2/64 loss: 0.2957600951194763
Batch 3/64 loss: 0.3018544316291809
Batch 4/64 loss: 0.28772222995758057
Batch 5/64 loss: 0.29785585403442383
Batch 6/64 loss: 0.2856760025024414
Batch 7/64 loss: 0.2876368761062622
Batch 8/64 loss: 0.2870759963989258
Batch 9/64 loss: 0.2922835350036621
Batch 10/64 loss: 0.28547847270965576
Batch 11/64 loss: 0.2974139451980591
Batch 12/64 loss: 0.28935033082962036
Batch 13/64 loss: 0.2964610457420349
Batch 14/64 loss: 0.28906941413879395
Batch 15/64 loss: 0.2879229187965393
Batch 16/64 loss: 0.2843557596206665
Batch 17/64 loss: 0.29015159606933594
Batch 18/64 loss: 0.2871849536895752
Batch 19/64 loss: 0.2936397194862366
Batch 20/64 loss: 0.289894163608551
Batch 21/64 loss: 0.28711217641830444
Batch 22/64 loss: 0.3049527406692505
Batch 23/64 loss: 0.28322821855545044
Batch 24/64 loss: 0.29440248012542725
Batch 25/64 loss: 0.2909321188926697
Batch 26/64 loss: 0.2932751774787903
Batch 27/64 loss: 0.2931325435638428
Batch 28/64 loss: 0.2884642481803894
Batch 29/64 loss: 0.2890447974205017
Batch 30/64 loss: 0.2893255352973938
Batch 31/64 loss: 0.29669976234436035
Batch 32/64 loss: 0.29267680644989014
Batch 33/64 loss: 0.2957502603530884
Batch 34/64 loss: 0.2907668352127075
Batch 35/64 loss: 0.2994593381881714
Batch 36/64 loss: 0.2940385937690735
Batch 37/64 loss: 0.3015364408493042
Batch 38/64 loss: 0.2931551933288574
Batch 39/64 loss: 0.29876184463500977
Batch 40/64 loss: 0.29312241077423096
Batch 41/64 loss: 0.2925831079483032
Batch 42/64 loss: 0.28584009408950806
Batch 43/64 loss: 0.29102015495300293
Batch 44/64 loss: 0.2916213870048523
Batch 45/64 loss: 0.2952430248260498
Batch 46/64 loss: 0.2926311492919922
Batch 47/64 loss: 0.29145729541778564
Batch 48/64 loss: 0.29746413230895996
Batch 49/64 loss: 0.2905843257904053
Batch 50/64 loss: 0.28518497943878174
Batch 51/64 loss: 0.2952166795730591
Batch 52/64 loss: 0.29152756929397583
Batch 53/64 loss: 0.2911475896835327
Batch 54/64 loss: 0.28812575340270996
Batch 55/64 loss: 0.2990924119949341
Batch 56/64 loss: 0.3069812059402466
Batch 57/64 loss: 0.29415154457092285
Batch 58/64 loss: 0.2984588146209717
Batch 59/64 loss: 0.2927985191345215
Batch 60/64 loss: 0.2896856665611267
Batch 61/64 loss: 0.2910192012786865
Batch 62/64 loss: 0.2975260019302368
Batch 63/64 loss: 0.2942396402359009
Batch 64/64 loss: 0.30392956733703613
Epoch 139  Train loss: 0.2926997876634785  Val loss: 0.30575971996661316
Epoch 140
-------------------------------
Batch 1/64 loss: 0.28704380989074707
Batch 2/64 loss: 0.3003643751144409
Batch 3/64 loss: 0.29152941703796387
Batch 4/64 loss: 0.2950829267501831
Batch 5/64 loss: 0.2825310230255127
Batch 6/64 loss: 0.2941763401031494
Batch 7/64 loss: 0.29858219623565674
Batch 8/64 loss: 0.29484909772872925
Batch 9/64 loss: 0.29998600482940674
Batch 10/64 loss: 0.29188960790634155
Batch 11/64 loss: 0.2845270037651062
Batch 12/64 loss: 0.29049551486968994
Batch 13/64 loss: 0.29179203510284424
Batch 14/64 loss: 0.2895314693450928
Batch 15/64 loss: 0.2953253984451294
Batch 16/64 loss: 0.3082129955291748
Batch 17/64 loss: 0.2964468002319336
Batch 18/64 loss: 0.2998605966567993
Batch 19/64 loss: 0.2922157645225525
Batch 20/64 loss: 0.27910906076431274
Batch 21/64 loss: 0.2879026532173157
Batch 22/64 loss: 0.2956830859184265
Batch 23/64 loss: 0.2924603223800659
Batch 24/64 loss: 0.3020469546318054
Batch 25/64 loss: 0.29677581787109375
Batch 26/64 loss: 0.2953082323074341
Batch 27/64 loss: 0.2991969585418701
Batch 28/64 loss: 0.2878924012184143
Batch 29/64 loss: 0.2944988012313843
Batch 30/64 loss: 0.29265540838241577
Batch 31/64 loss: 0.2917463779449463
Batch 32/64 loss: 0.292486310005188
Batch 33/64 loss: 0.2924180030822754
Batch 34/64 loss: 0.29658907651901245
Batch 35/64 loss: 0.28780174255371094
Batch 36/64 loss: 0.28922879695892334
Batch 37/64 loss: 0.29179608821868896
Batch 38/64 loss: 0.3004157543182373
Batch 39/64 loss: 0.29824304580688477
Batch 40/64 loss: 0.28920096158981323
Batch 41/64 loss: 0.2947770357131958
Batch 42/64 loss: 0.28865528106689453
Batch 43/64 loss: 0.2891005873680115
Batch 44/64 loss: 0.28988343477249146
Batch 45/64 loss: 0.29684531688690186
Batch 46/64 loss: 0.29298532009124756
Batch 47/64 loss: 0.29223108291625977
Batch 48/64 loss: 0.292399525642395
Batch 49/64 loss: 0.28671830892562866
Batch 50/64 loss: 0.2850102186203003
Batch 51/64 loss: 0.2929912805557251
Batch 52/64 loss: 0.2958940267562866
Batch 53/64 loss: 0.2931380271911621
Batch 54/64 loss: 0.29198700189590454
Batch 55/64 loss: 0.28959888219833374
Batch 56/64 loss: 0.28689074516296387
Batch 57/64 loss: 0.3008310794830322
Batch 58/64 loss: 0.28519904613494873
Batch 59/64 loss: 0.2855703830718994
Batch 60/64 loss: 0.28625184297561646
Batch 61/64 loss: 0.290880024433136
Batch 62/64 loss: 0.2931175231933594
Batch 63/64 loss: 0.2904132008552551
Batch 64/64 loss: 0.2965143918991089
Epoch 140  Train loss: 0.2925749521629483  Val loss: 0.30449944877952234
Saving best model, epoch: 140
Epoch 141
-------------------------------
Batch 1/64 loss: 0.28481143712997437
Batch 2/64 loss: 0.3004510998725891
Batch 3/64 loss: 0.28977882862091064
Batch 4/64 loss: 0.28385162353515625
Batch 5/64 loss: 0.290871262550354
Batch 6/64 loss: 0.30149275064468384
Batch 7/64 loss: 0.28893178701400757
Batch 8/64 loss: 0.29490596055984497
Batch 9/64 loss: 0.28466033935546875
Batch 10/64 loss: 0.29242241382598877
Batch 11/64 loss: 0.28661537170410156
Batch 12/64 loss: 0.2928398847579956
Batch 13/64 loss: 0.29437023401260376
Batch 14/64 loss: 0.28978192806243896
Batch 15/64 loss: 0.29343271255493164
Batch 16/64 loss: 0.2883192300796509
Batch 17/64 loss: 0.29528653621673584
Batch 18/64 loss: 0.2894745469093323
Batch 19/64 loss: 0.2950713634490967
Batch 20/64 loss: 0.2967698574066162
Batch 21/64 loss: 0.29090410470962524
Batch 22/64 loss: 0.2906978130340576
Batch 23/64 loss: 0.2902263402938843
Batch 24/64 loss: 0.294100284576416
Batch 25/64 loss: 0.29288923740386963
Batch 26/64 loss: 0.293178915977478
Batch 27/64 loss: 0.2905008792877197
Batch 28/64 loss: 0.29595625400543213
Batch 29/64 loss: 0.2912050485610962
Batch 30/64 loss: 0.3028010129928589
Batch 31/64 loss: 0.2871466875076294
Batch 32/64 loss: 0.2890625596046448
Batch 33/64 loss: 0.28325873613357544
Batch 34/64 loss: 0.29392004013061523
Batch 35/64 loss: 0.28659117221832275
Batch 36/64 loss: 0.2917959690093994
Batch 37/64 loss: 0.28852301836013794
Batch 38/64 loss: 0.29353368282318115
Batch 39/64 loss: 0.2997346520423889
Batch 40/64 loss: 0.2900203466415405
Batch 41/64 loss: 0.2911236882209778
Batch 42/64 loss: 0.29157888889312744
Batch 43/64 loss: 0.29402029514312744
Batch 44/64 loss: 0.30228787660598755
Batch 45/64 loss: 0.2980659008026123
Batch 46/64 loss: 0.2898067831993103
Batch 47/64 loss: 0.2798752784729004
Batch 48/64 loss: 0.28918224573135376
Batch 49/64 loss: 0.299096941947937
Batch 50/64 loss: 0.2952912449836731
Batch 51/64 loss: 0.2953358292579651
Batch 52/64 loss: 0.2869650721549988
Batch 53/64 loss: 0.287217378616333
Batch 54/64 loss: 0.2844582200050354
Batch 55/64 loss: 0.2952836751937866
Batch 56/64 loss: 0.28541725873947144
Batch 57/64 loss: 0.28683745861053467
Batch 58/64 loss: 0.290810227394104
Batch 59/64 loss: 0.2855372428894043
Batch 60/64 loss: 0.2936367988586426
Batch 61/64 loss: 0.30255937576293945
Batch 62/64 loss: 0.2830479145050049
Batch 63/64 loss: 0.3022061586380005
Batch 64/64 loss: 0.2878463864326477
Epoch 141  Train loss: 0.2916974504788717  Val loss: 0.30552219074616316
Epoch 142
-------------------------------
Batch 1/64 loss: 0.2887585163116455
Batch 2/64 loss: 0.29718446731567383
Batch 3/64 loss: 0.28585493564605713
Batch 4/64 loss: 0.29512470960617065
Batch 5/64 loss: 0.2912081480026245
Batch 6/64 loss: 0.2876875400543213
Batch 7/64 loss: 0.29135334491729736
Batch 8/64 loss: 0.2941465377807617
Batch 9/64 loss: 0.2925630211830139
Batch 10/64 loss: 0.2922775149345398
Batch 11/64 loss: 0.2929551601409912
Batch 12/64 loss: 0.28148967027664185
Batch 13/64 loss: 0.2949601411819458
Batch 14/64 loss: 0.28805315494537354
Batch 15/64 loss: 0.28837496042251587
Batch 16/64 loss: 0.2893649935722351
Batch 17/64 loss: 0.29130470752716064
Batch 18/64 loss: 0.29348087310791016
Batch 19/64 loss: 0.28803616762161255
Batch 20/64 loss: 0.29382050037384033
Batch 21/64 loss: 0.3000560998916626
Batch 22/64 loss: 0.28649652004241943
Batch 23/64 loss: 0.2956758141517639
Batch 24/64 loss: 0.28888487815856934
Batch 25/64 loss: 0.28612667322158813
Batch 26/64 loss: 0.28636986017227173
Batch 27/64 loss: 0.2972937822341919
Batch 28/64 loss: 0.29315185546875
Batch 29/64 loss: 0.30432409048080444
Batch 30/64 loss: 0.29394638538360596
Batch 31/64 loss: 0.2898779511451721
Batch 32/64 loss: 0.2825013995170593
Batch 33/64 loss: 0.2998008728027344
Batch 34/64 loss: 0.2889145612716675
Batch 35/64 loss: 0.2857428193092346
Batch 36/64 loss: 0.30003708600997925
Batch 37/64 loss: 0.29495131969451904
Batch 38/64 loss: 0.2878856658935547
Batch 39/64 loss: 0.29234254360198975
Batch 40/64 loss: 0.28584134578704834
Batch 41/64 loss: 0.2885000705718994
Batch 42/64 loss: 0.2947251796722412
Batch 43/64 loss: 0.3002985715866089
Batch 44/64 loss: 0.2936367988586426
Batch 45/64 loss: 0.29253488779067993
Batch 46/64 loss: 0.2865626811981201
Batch 47/64 loss: 0.291013240814209
Batch 48/64 loss: 0.2956669330596924
Batch 49/64 loss: 0.29856157302856445
Batch 50/64 loss: 0.29509973526000977
Batch 51/64 loss: 0.2945628762245178
Batch 52/64 loss: 0.28882312774658203
Batch 53/64 loss: 0.2935705780982971
Batch 54/64 loss: 0.289023756980896
Batch 55/64 loss: 0.29909276962280273
Batch 56/64 loss: 0.28840434551239014
Batch 57/64 loss: 0.2903714179992676
Batch 58/64 loss: 0.29269343614578247
Batch 59/64 loss: 0.2906748056411743
Batch 60/64 loss: 0.2933443784713745
Batch 61/64 loss: 0.2911307215690613
Batch 62/64 loss: 0.2840809226036072
Batch 63/64 loss: 0.29607683420181274
Batch 64/64 loss: 0.30524957180023193
Epoch 142  Train loss: 0.29200952801049923  Val loss: 0.3044717979595014
Saving best model, epoch: 142
Epoch 143
-------------------------------
Batch 1/64 loss: 0.2921638488769531
Batch 2/64 loss: 0.2963401675224304
Batch 3/64 loss: 0.28951096534729004
Batch 4/64 loss: 0.30473792552948
Batch 5/64 loss: 0.28482234477996826
Batch 6/64 loss: 0.29219377040863037
Batch 7/64 loss: 0.2953420877456665
Batch 8/64 loss: 0.293082594871521
Batch 9/64 loss: 0.2834428548812866
Batch 10/64 loss: 0.29438918828964233
Batch 11/64 loss: 0.2958794832229614
Batch 12/64 loss: 0.2919328212738037
Batch 13/64 loss: 0.285118043422699
Batch 14/64 loss: 0.2819299101829529
Batch 15/64 loss: 0.2955208420753479
Batch 16/64 loss: 0.2888239622116089
Batch 17/64 loss: 0.2925223112106323
Batch 18/64 loss: 0.29513049125671387
Batch 19/64 loss: 0.29384148120880127
Batch 20/64 loss: 0.28327488899230957
Batch 21/64 loss: 0.2816733121871948
Batch 22/64 loss: 0.2899740934371948
Batch 23/64 loss: 0.286815881729126
Batch 24/64 loss: 0.28860175609588623
Batch 25/64 loss: 0.2893342971801758
Batch 26/64 loss: 0.29073643684387207
Batch 27/64 loss: 0.3016323447227478
Batch 28/64 loss: 0.2953219413757324
Batch 29/64 loss: 0.295956015586853
Batch 30/64 loss: 0.2891271114349365
Batch 31/64 loss: 0.28561878204345703
Batch 32/64 loss: 0.29887741804122925
Batch 33/64 loss: 0.28559792041778564
Batch 34/64 loss: 0.28885871171951294
Batch 35/64 loss: 0.2944803833961487
Batch 36/64 loss: 0.28872859477996826
Batch 37/64 loss: 0.2989528775215149
Batch 38/64 loss: 0.2981165647506714
Batch 39/64 loss: 0.2993231415748596
Batch 40/64 loss: 0.28975826501846313
Batch 41/64 loss: 0.29691076278686523
Batch 42/64 loss: 0.3009253740310669
Batch 43/64 loss: 0.2889937162399292
Batch 44/64 loss: 0.2872426509857178
Batch 45/64 loss: 0.2895323634147644
Batch 46/64 loss: 0.2899801731109619
Batch 47/64 loss: 0.2888460159301758
Batch 48/64 loss: 0.2814895510673523
Batch 49/64 loss: 0.28684645891189575
Batch 50/64 loss: 0.2936974763870239
Batch 51/64 loss: 0.29499441385269165
Batch 52/64 loss: 0.2928285598754883
Batch 53/64 loss: 0.28456664085388184
Batch 54/64 loss: 0.28568124771118164
Batch 55/64 loss: 0.2846059799194336
Batch 56/64 loss: 0.29073482751846313
Batch 57/64 loss: 0.297325074672699
Batch 58/64 loss: 0.29210174083709717
Batch 59/64 loss: 0.2896387577056885
Batch 60/64 loss: 0.29003405570983887
Batch 61/64 loss: 0.2928812503814697
Batch 62/64 loss: 0.2990354895591736
Batch 63/64 loss: 0.29397445917129517
Batch 64/64 loss: 0.2900741696357727
Epoch 143  Train loss: 0.291418172565161  Val loss: 0.304981437335719
Epoch 144
-------------------------------
Batch 1/64 loss: 0.29204386472702026
Batch 2/64 loss: 0.2915949821472168
Batch 3/64 loss: 0.2985183000564575
Batch 4/64 loss: 0.2849618196487427
Batch 5/64 loss: 0.2811317443847656
Batch 6/64 loss: 0.29292768239974976
Batch 7/64 loss: 0.2983437776565552
Batch 8/64 loss: 0.29227763414382935
Batch 9/64 loss: 0.29514169692993164
Batch 10/64 loss: 0.28522539138793945
Batch 11/64 loss: 0.28558528423309326
Batch 12/64 loss: 0.29751908779144287
Batch 13/64 loss: 0.2856578826904297
Batch 14/64 loss: 0.29289937019348145
Batch 15/64 loss: 0.2813640832901001
Batch 16/64 loss: 0.2898956537246704
Batch 17/64 loss: 0.2981680631637573
Batch 18/64 loss: 0.2885725498199463
Batch 19/64 loss: 0.29014456272125244
Batch 20/64 loss: 0.2848173975944519
Batch 21/64 loss: 0.2898179888725281
Batch 22/64 loss: 0.28596562147140503
Batch 23/64 loss: 0.29878532886505127
Batch 24/64 loss: 0.296175479888916
Batch 25/64 loss: 0.28756076097488403
Batch 26/64 loss: 0.29551249742507935
Batch 27/64 loss: 0.2989741563796997
Batch 28/64 loss: 0.2888152599334717
Batch 29/64 loss: 0.2813400626182556
Batch 30/64 loss: 0.2953925132751465
Batch 31/64 loss: 0.2904125452041626
Batch 32/64 loss: 0.29085493087768555
Batch 33/64 loss: 0.2822485566139221
Batch 34/64 loss: 0.29238200187683105
Batch 35/64 loss: 0.28154104948043823
Batch 36/64 loss: 0.2897299528121948
Batch 37/64 loss: 0.2925742268562317
Batch 38/64 loss: 0.2988377809524536
Batch 39/64 loss: 0.29326653480529785
Batch 40/64 loss: 0.29472386837005615
Batch 41/64 loss: 0.28630685806274414
Batch 42/64 loss: 0.28827589750289917
Batch 43/64 loss: 0.30063700675964355
Batch 44/64 loss: 0.28820621967315674
Batch 45/64 loss: 0.28836727142333984
Batch 46/64 loss: 0.28240108489990234
Batch 47/64 loss: 0.2875613570213318
Batch 48/64 loss: 0.28639018535614014
Batch 49/64 loss: 0.2898353338241577
Batch 50/64 loss: 0.2893514633178711
Batch 51/64 loss: 0.2899090051651001
Batch 52/64 loss: 0.29910874366760254
Batch 53/64 loss: 0.2905348539352417
Batch 54/64 loss: 0.28944718837738037
Batch 55/64 loss: 0.289439857006073
Batch 56/64 loss: 0.302059531211853
Batch 57/64 loss: 0.2949753999710083
Batch 58/64 loss: 0.29004770517349243
Batch 59/64 loss: 0.29553472995758057
Batch 60/64 loss: 0.2902219295501709
Batch 61/64 loss: 0.2935639023780823
Batch 62/64 loss: 0.2930307388305664
Batch 63/64 loss: 0.287219762802124
Batch 64/64 loss: 0.29211127758026123
Epoch 144  Train loss: 0.29087390478919534  Val loss: 0.30280388876334907
Saving best model, epoch: 144
Epoch 145
-------------------------------
Batch 1/64 loss: 0.28669118881225586
Batch 2/64 loss: 0.28568071126937866
Batch 3/64 loss: 0.2977031469345093
Batch 4/64 loss: 0.28821873664855957
Batch 5/64 loss: 0.2909311056137085
Batch 6/64 loss: 0.28462547063827515
Batch 7/64 loss: 0.289082407951355
Batch 8/64 loss: 0.29057252407073975
Batch 9/64 loss: 0.29440444707870483
Batch 10/64 loss: 0.29852914810180664
Batch 11/64 loss: 0.2889767289161682
Batch 12/64 loss: 0.2951963543891907
Batch 13/64 loss: 0.2883286476135254
Batch 14/64 loss: 0.2839726209640503
Batch 15/64 loss: 0.28728675842285156
Batch 16/64 loss: 0.2959865927696228
Batch 17/64 loss: 0.28560686111450195
Batch 18/64 loss: 0.2910770773887634
Batch 19/64 loss: 0.3029059171676636
Batch 20/64 loss: 0.28845417499542236
Batch 21/64 loss: 0.2944333553314209
Batch 22/64 loss: 0.29012972116470337
Batch 23/64 loss: 0.28838294744491577
Batch 24/64 loss: 0.28388941287994385
Batch 25/64 loss: 0.2929818630218506
Batch 26/64 loss: 0.2885209918022156
Batch 27/64 loss: 0.29209768772125244
Batch 28/64 loss: 0.29313474893569946
Batch 29/64 loss: 0.2980799674987793
Batch 30/64 loss: 0.2961418032646179
Batch 31/64 loss: 0.2886521816253662
Batch 32/64 loss: 0.29295802116394043
Batch 33/64 loss: 0.29288017749786377
Batch 34/64 loss: 0.28964853286743164
Batch 35/64 loss: 0.2921692132949829
Batch 36/64 loss: 0.29321008920669556
Batch 37/64 loss: 0.29044175148010254
Batch 38/64 loss: 0.2839440107345581
Batch 39/64 loss: 0.2870069742202759
Batch 40/64 loss: 0.29431796073913574
Batch 41/64 loss: 0.2919653058052063
Batch 42/64 loss: 0.30150777101516724
Batch 43/64 loss: 0.287619948387146
Batch 44/64 loss: 0.2945402264595032
Batch 45/64 loss: 0.28512728214263916
Batch 46/64 loss: 0.29021090269088745
Batch 47/64 loss: 0.2891727685928345
Batch 48/64 loss: 0.2866562604904175
Batch 49/64 loss: 0.28949248790740967
Batch 50/64 loss: 0.29476267099380493
Batch 51/64 loss: 0.2896556854248047
Batch 52/64 loss: 0.2895522117614746
Batch 53/64 loss: 0.28920018672943115
Batch 54/64 loss: 0.2951729893684387
Batch 55/64 loss: 0.28256356716156006
Batch 56/64 loss: 0.28748637437820435
Batch 57/64 loss: 0.2804276943206787
Batch 58/64 loss: 0.2897633910179138
Batch 59/64 loss: 0.2879292964935303
Batch 60/64 loss: 0.2901724576950073
Batch 61/64 loss: 0.2813211679458618
Batch 62/64 loss: 0.3063666820526123
Batch 63/64 loss: 0.28060048818588257
Batch 64/64 loss: 0.28913986682891846
Epoch 145  Train loss: 0.29043725097880646  Val loss: 0.30392665797492485
Epoch 146
-------------------------------
Batch 1/64 loss: 0.2899284362792969
Batch 2/64 loss: 0.28162288665771484
Batch 3/64 loss: 0.28494083881378174
Batch 4/64 loss: 0.28787797689437866
Batch 5/64 loss: 0.2959047555923462
Batch 6/64 loss: 0.293462336063385
Batch 7/64 loss: 0.2959326505661011
Batch 8/64 loss: 0.29078221321105957
Batch 9/64 loss: 0.28967297077178955
Batch 10/64 loss: 0.2916889786720276
Batch 11/64 loss: 0.2845858931541443
Batch 12/64 loss: 0.2899879813194275
Batch 13/64 loss: 0.2878967523574829
Batch 14/64 loss: 0.2882636785507202
Batch 15/64 loss: 0.28824806213378906
Batch 16/64 loss: 0.29041242599487305
Batch 17/64 loss: 0.2984654903411865
Batch 18/64 loss: 0.2857629060745239
Batch 19/64 loss: 0.285231351852417
Batch 20/64 loss: 0.2842807173728943
Batch 21/64 loss: 0.28707432746887207
Batch 22/64 loss: 0.2910647988319397
Batch 23/64 loss: 0.29147183895111084
Batch 24/64 loss: 0.2845897674560547
Batch 25/64 loss: 0.2876853942871094
Batch 26/64 loss: 0.28866612911224365
Batch 27/64 loss: 0.29485028982162476
Batch 28/64 loss: 0.29898178577423096
Batch 29/64 loss: 0.2894914150238037
Batch 30/64 loss: 0.28907567262649536
Batch 31/64 loss: 0.28774529695510864
Batch 32/64 loss: 0.29613637924194336
Batch 33/64 loss: 0.29517531394958496
Batch 34/64 loss: 0.29325443506240845
Batch 35/64 loss: 0.28969013690948486
Batch 36/64 loss: 0.2922772765159607
Batch 37/64 loss: 0.28665614128112793
Batch 38/64 loss: 0.28935718536376953
Batch 39/64 loss: 0.29026395082473755
Batch 40/64 loss: 0.2818397879600525
Batch 41/64 loss: 0.28665781021118164
Batch 42/64 loss: 0.2874775528907776
Batch 43/64 loss: 0.28323549032211304
Batch 44/64 loss: 0.2964492440223694
Batch 45/64 loss: 0.2858099341392517
Batch 46/64 loss: 0.28871607780456543
Batch 47/64 loss: 0.28825312852859497
Batch 48/64 loss: 0.28734833002090454
Batch 49/64 loss: 0.285638689994812
Batch 50/64 loss: 0.2945641279220581
Batch 51/64 loss: 0.28296416997909546
Batch 52/64 loss: 0.2982923984527588
Batch 53/64 loss: 0.28479480743408203
Batch 54/64 loss: 0.2881959080696106
Batch 55/64 loss: 0.29179084300994873
Batch 56/64 loss: 0.2931886315345764
Batch 57/64 loss: 0.28703927993774414
Batch 58/64 loss: 0.2916322946548462
Batch 59/64 loss: 0.28721702098846436
Batch 60/64 loss: 0.290253221988678
Batch 61/64 loss: 0.2872803211212158
Batch 62/64 loss: 0.2827642560005188
Batch 63/64 loss: 0.29155540466308594
Batch 64/64 loss: 0.28240716457366943
Epoch 146  Train loss: 0.2893054265601962  Val loss: 0.3040190707776964
Epoch 147
-------------------------------
Batch 1/64 loss: 0.29532814025878906
Batch 2/64 loss: 0.28626906871795654
Batch 3/64 loss: 0.2851240634918213
Batch 4/64 loss: 0.2875267267227173
Batch 5/64 loss: 0.28438055515289307
Batch 6/64 loss: 0.2950352430343628
Batch 7/64 loss: 0.2888988256454468
Batch 8/64 loss: 0.28669679164886475
Batch 9/64 loss: 0.2941223978996277
Batch 10/64 loss: 0.2951112389564514
Batch 11/64 loss: 0.28596001863479614
Batch 12/64 loss: 0.2954719066619873
Batch 13/64 loss: 0.2861679792404175
Batch 14/64 loss: 0.2865028381347656
Batch 15/64 loss: 0.28700196743011475
Batch 16/64 loss: 0.28551995754241943
Batch 17/64 loss: 0.28760474920272827
Batch 18/64 loss: 0.2895216941833496
Batch 19/64 loss: 0.2878143787384033
Batch 20/64 loss: 0.28994429111480713
Batch 21/64 loss: 0.2892327308654785
Batch 22/64 loss: 0.2896162271499634
Batch 23/64 loss: 0.29031240940093994
Batch 24/64 loss: 0.2905322313308716
Batch 25/64 loss: 0.2896054983139038
Batch 26/64 loss: 0.28927797079086304
Batch 27/64 loss: 0.2957085967063904
Batch 28/64 loss: 0.2884562015533447
Batch 29/64 loss: 0.29231446981430054
Batch 30/64 loss: 0.2875955104827881
Batch 31/64 loss: 0.2982069253921509
Batch 32/64 loss: 0.29109692573547363
Batch 33/64 loss: 0.2852071523666382
Batch 34/64 loss: 0.29059070348739624
Batch 35/64 loss: 0.2924612760543823
Batch 36/64 loss: 0.28907138109207153
Batch 37/64 loss: 0.29157257080078125
Batch 38/64 loss: 0.2939845323562622
Batch 39/64 loss: 0.29490816593170166
Batch 40/64 loss: 0.28662675619125366
Batch 41/64 loss: 0.2905310392379761
Batch 42/64 loss: 0.2942606210708618
Batch 43/64 loss: 0.286527156829834
Batch 44/64 loss: 0.2922174334526062
Batch 45/64 loss: 0.2841804027557373
Batch 46/64 loss: 0.2953612804412842
Batch 47/64 loss: 0.2943069338798523
Batch 48/64 loss: 0.28413820266723633
Batch 49/64 loss: 0.2893754243850708
Batch 50/64 loss: 0.30085182189941406
Batch 51/64 loss: 0.2892564535140991
Batch 52/64 loss: 0.2877779006958008
Batch 53/64 loss: 0.29083001613616943
Batch 54/64 loss: 0.2848343253135681
Batch 55/64 loss: 0.2874934673309326
Batch 56/64 loss: 0.2900674343109131
Batch 57/64 loss: 0.28375518321990967
Batch 58/64 loss: 0.2893896698951721
Batch 59/64 loss: 0.2902839183807373
Batch 60/64 loss: 0.287350058555603
Batch 61/64 loss: 0.2754957675933838
Batch 62/64 loss: 0.2906578779220581
Batch 63/64 loss: 0.29198944568634033
Batch 64/64 loss: 0.2831721901893616
Epoch 147  Train loss: 0.2895637968007256  Val loss: 0.3032062082356194
Epoch 148
-------------------------------
Batch 1/64 loss: 0.28218501806259155
Batch 2/64 loss: 0.2781899571418762
Batch 3/64 loss: 0.2857632637023926
Batch 4/64 loss: 0.2885103225708008
Batch 5/64 loss: 0.2923572063446045
Batch 6/64 loss: 0.28364717960357666
Batch 7/64 loss: 0.29295897483825684
Batch 8/64 loss: 0.29032647609710693
Batch 9/64 loss: 0.2893880605697632
Batch 10/64 loss: 0.2943687438964844
Batch 11/64 loss: 0.2845902442932129
Batch 12/64 loss: 0.29429829120635986
Batch 13/64 loss: 0.29049479961395264
Batch 14/64 loss: 0.2942843437194824
Batch 15/64 loss: 0.29106104373931885
Batch 16/64 loss: 0.2930499315261841
Batch 17/64 loss: 0.28358548879623413
Batch 18/64 loss: 0.2843562364578247
Batch 19/64 loss: 0.28967130184173584
Batch 20/64 loss: 0.2895461320877075
Batch 21/64 loss: 0.29147619009017944
Batch 22/64 loss: 0.2913999557495117
Batch 23/64 loss: 0.2827785015106201
Batch 24/64 loss: 0.2926790714263916
Batch 25/64 loss: 0.29414427280426025
Batch 26/64 loss: 0.2893713116645813
Batch 27/64 loss: 0.2902708053588867
Batch 28/64 loss: 0.284975528717041
Batch 29/64 loss: 0.2897823452949524
Batch 30/64 loss: 0.28591740131378174
Batch 31/64 loss: 0.30077219009399414
Batch 32/64 loss: 0.2897758483886719
Batch 33/64 loss: 0.2877606153488159
Batch 34/64 loss: 0.29277002811431885
Batch 35/64 loss: 0.2960931062698364
Batch 36/64 loss: 0.28441542387008667
Batch 37/64 loss: 0.29535746574401855
Batch 38/64 loss: 0.285799503326416
Batch 39/64 loss: 0.2927793264389038
Batch 40/64 loss: 0.27865779399871826
Batch 41/64 loss: 0.293194055557251
Batch 42/64 loss: 0.2858778238296509
Batch 43/64 loss: 0.2886793613433838
Batch 44/64 loss: 0.28171420097351074
Batch 45/64 loss: 0.28215861320495605
Batch 46/64 loss: 0.28686827421188354
Batch 47/64 loss: 0.28743791580200195
Batch 48/64 loss: 0.29242026805877686
Batch 49/64 loss: 0.2866560220718384
Batch 50/64 loss: 0.290014386177063
Batch 51/64 loss: 0.2841341495513916
Batch 52/64 loss: 0.2864198088645935
Batch 53/64 loss: 0.2893680930137634
Batch 54/64 loss: 0.2837851047515869
Batch 55/64 loss: 0.28413885831832886
Batch 56/64 loss: 0.2859620451927185
Batch 57/64 loss: 0.2906116247177124
Batch 58/64 loss: 0.2895098924636841
Batch 59/64 loss: 0.2896597385406494
Batch 60/64 loss: 0.28815633058547974
Batch 61/64 loss: 0.2862163782119751
Batch 62/64 loss: 0.2863033413887024
Batch 63/64 loss: 0.3051266074180603
Batch 64/64 loss: 0.30290883779525757
Epoch 148  Train loss: 0.2889600662624135  Val loss: 0.301638984598245
Saving best model, epoch: 148
Epoch 149
-------------------------------
Batch 1/64 loss: 0.303409218788147
Batch 2/64 loss: 0.3007042407989502
Batch 3/64 loss: 0.28903728723526
Batch 4/64 loss: 0.2833983898162842
Batch 5/64 loss: 0.2911723852157593
Batch 6/64 loss: 0.2889305353164673
Batch 7/64 loss: 0.29419827461242676
Batch 8/64 loss: 0.2850291132926941
Batch 9/64 loss: 0.29908478260040283
Batch 10/64 loss: 0.2891828417778015
Batch 11/64 loss: 0.2889195680618286
Batch 12/64 loss: 0.2890664339065552
Batch 13/64 loss: 0.2853965759277344
Batch 14/64 loss: 0.2856940031051636
Batch 15/64 loss: 0.29352623224258423
Batch 16/64 loss: 0.2877572774887085
Batch 17/64 loss: 0.2874263525009155
Batch 18/64 loss: 0.28188347816467285
Batch 19/64 loss: 0.29067814350128174
Batch 20/64 loss: 0.28707897663116455
Batch 21/64 loss: 0.2959677577018738
Batch 22/64 loss: 0.2926296591758728
Batch 23/64 loss: 0.2920275330543518
Batch 24/64 loss: 0.29227954149246216
Batch 25/64 loss: 0.2877649664878845
Batch 26/64 loss: 0.2845790386199951
Batch 27/64 loss: 0.28503942489624023
Batch 28/64 loss: 0.2897982597351074
Batch 29/64 loss: 0.2880001664161682
Batch 30/64 loss: 0.2833597660064697
Batch 31/64 loss: 0.28573769330978394
Batch 32/64 loss: 0.2898980379104614
Batch 33/64 loss: 0.2916470766067505
Batch 34/64 loss: 0.29262709617614746
Batch 35/64 loss: 0.28011053800582886
Batch 36/64 loss: 0.29410886764526367
Batch 37/64 loss: 0.28742361068725586
Batch 38/64 loss: 0.2871878147125244
Batch 39/64 loss: 0.2865036725997925
Batch 40/64 loss: 0.27967917919158936
Batch 41/64 loss: 0.28752779960632324
Batch 42/64 loss: 0.29361432790756226
Batch 43/64 loss: 0.29449641704559326
Batch 44/64 loss: 0.2868933081626892
Batch 45/64 loss: 0.2870463728904724
Batch 46/64 loss: 0.29824531078338623
Batch 47/64 loss: 0.2902621030807495
Batch 48/64 loss: 0.27998900413513184
Batch 49/64 loss: 0.2801070213317871
Batch 50/64 loss: 0.28532135486602783
Batch 51/64 loss: 0.29095882177352905
Batch 52/64 loss: 0.28504812717437744
Batch 53/64 loss: 0.2892807722091675
Batch 54/64 loss: 0.28391754627227783
Batch 55/64 loss: 0.28819113969802856
Batch 56/64 loss: 0.2945641279220581
Batch 57/64 loss: 0.29419124126434326
Batch 58/64 loss: 0.2863668203353882
Batch 59/64 loss: 0.2910662889480591
Batch 60/64 loss: 0.28204309940338135
Batch 61/64 loss: 0.2794696092605591
Batch 62/64 loss: 0.2809793949127197
Batch 63/64 loss: 0.29805272817611694
Batch 64/64 loss: 0.29389774799346924
Epoch 149  Train loss: 0.2888784291697483  Val loss: 0.30248796304886283
Epoch 150
-------------------------------
Batch 1/64 loss: 0.287469744682312
Batch 2/64 loss: 0.28911590576171875
Batch 3/64 loss: 0.2937713861465454
Batch 4/64 loss: 0.28017204999923706
Batch 5/64 loss: 0.2872418165206909
Batch 6/64 loss: 0.2860907316207886
Batch 7/64 loss: 0.283905029296875
Batch 8/64 loss: 0.28634119033813477
Batch 9/64 loss: 0.2823193073272705
Batch 10/64 loss: 0.2887096405029297
Batch 11/64 loss: 0.2826651334762573
Batch 12/64 loss: 0.2810060977935791
Batch 13/64 loss: 0.2883039712905884
Batch 14/64 loss: 0.2830078601837158
Batch 15/64 loss: 0.28376293182373047
Batch 16/64 loss: 0.2902648448944092
Batch 17/64 loss: 0.29841864109039307
Batch 18/64 loss: 0.2877633571624756
Batch 19/64 loss: 0.292091965675354
Batch 20/64 loss: 0.28646862506866455
Batch 21/64 loss: 0.29339373111724854
Batch 22/64 loss: 0.29046571254730225
Batch 23/64 loss: 0.29185450077056885
Batch 24/64 loss: 0.2912227511405945
Batch 25/64 loss: 0.2893427014350891
Batch 26/64 loss: 0.2903364896774292
Batch 27/64 loss: 0.29490119218826294
Batch 28/64 loss: 0.2964625954627991
Batch 29/64 loss: 0.29281479120254517
Batch 30/64 loss: 0.29217928647994995
Batch 31/64 loss: 0.2883874177932739
Batch 32/64 loss: 0.29208385944366455
Batch 33/64 loss: 0.2866748571395874
Batch 34/64 loss: 0.2927982807159424
Batch 35/64 loss: 0.2844388484954834
Batch 36/64 loss: 0.28233516216278076
Batch 37/64 loss: 0.29120469093322754
Batch 38/64 loss: 0.28256362676620483
Batch 39/64 loss: 0.29300791025161743
Batch 40/64 loss: 0.29128748178482056
Batch 41/64 loss: 0.28237903118133545
Batch 42/64 loss: 0.2956623435020447
Batch 43/64 loss: 0.2881505489349365
Batch 44/64 loss: 0.2832610607147217
Batch 45/64 loss: 0.28832221031188965
Batch 46/64 loss: 0.2931709289550781
Batch 47/64 loss: 0.2830471992492676
Batch 48/64 loss: 0.28789758682250977
Batch 49/64 loss: 0.2826049327850342
Batch 50/64 loss: 0.2911284565925598
Batch 51/64 loss: 0.2879140377044678
Batch 52/64 loss: 0.28804337978363037
Batch 53/64 loss: 0.2893468141555786
Batch 54/64 loss: 0.28662586212158203
Batch 55/64 loss: 0.2926255464553833
Batch 56/64 loss: 0.29274046421051025
Batch 57/64 loss: 0.28463393449783325
Batch 58/64 loss: 0.2962438464164734
Batch 59/64 loss: 0.2864418029785156
Batch 60/64 loss: 0.288582444190979
Batch 61/64 loss: 0.29812824726104736
Batch 62/64 loss: 0.278209388256073
Batch 63/64 loss: 0.2841864824295044
Batch 64/64 loss: 0.2805364727973938
Epoch 150  Train loss: 0.28841403956506767  Val loss: 0.3011404308666478
Saving best model, epoch: 150
Epoch 151
-------------------------------
Batch 1/64 loss: 0.2894480228424072
Batch 2/64 loss: 0.2814144492149353
Batch 3/64 loss: 0.2920278310775757
Batch 4/64 loss: 0.29338306188583374
Batch 5/64 loss: 0.2777986526489258
Batch 6/64 loss: 0.28257685899734497
Batch 7/64 loss: 0.29872238636016846
Batch 8/64 loss: 0.29417943954467773
Batch 9/64 loss: 0.28676265478134155
Batch 10/64 loss: 0.29408490657806396
Batch 11/64 loss: 0.2843564748764038
Batch 12/64 loss: 0.2862321138381958
Batch 13/64 loss: 0.29339736700057983
Batch 14/64 loss: 0.29012244939804077
Batch 15/64 loss: 0.28749144077301025
Batch 16/64 loss: 0.28636622428894043
Batch 17/64 loss: 0.288685142993927
Batch 18/64 loss: 0.290752649307251
Batch 19/64 loss: 0.2866576910018921
Batch 20/64 loss: 0.2858506441116333
Batch 21/64 loss: 0.2858062982559204
Batch 22/64 loss: 0.28319287300109863
Batch 23/64 loss: 0.28244155645370483
Batch 24/64 loss: 0.2783491611480713
Batch 25/64 loss: 0.2889670133590698
Batch 26/64 loss: 0.28335797786712646
Batch 27/64 loss: 0.29195475578308105
Batch 28/64 loss: 0.29537320137023926
Batch 29/64 loss: 0.28413987159729004
Batch 30/64 loss: 0.2885028123855591
Batch 31/64 loss: 0.28148674964904785
Batch 32/64 loss: 0.297812819480896
Batch 33/64 loss: 0.2911810874938965
Batch 34/64 loss: 0.2890869379043579
Batch 35/64 loss: 0.28711962699890137
Batch 36/64 loss: 0.2943824529647827
Batch 37/64 loss: 0.2857990264892578
Batch 38/64 loss: 0.29619890451431274
Batch 39/64 loss: 0.29319244623184204
Batch 40/64 loss: 0.28136563301086426
Batch 41/64 loss: 0.28679198026657104
Batch 42/64 loss: 0.2894097566604614
Batch 43/64 loss: 0.28413569927215576
Batch 44/64 loss: 0.2835302948951721
Batch 45/64 loss: 0.28554022312164307
Batch 46/64 loss: 0.29172778129577637
Batch 47/64 loss: 0.2913479804992676
Batch 48/64 loss: 0.28649741411209106
Batch 49/64 loss: 0.2802395820617676
Batch 50/64 loss: 0.2881951928138733
Batch 51/64 loss: 0.2813628315925598
Batch 52/64 loss: 0.28931158781051636
Batch 53/64 loss: 0.2976635694503784
Batch 54/64 loss: 0.28709495067596436
Batch 55/64 loss: 0.2959522604942322
Batch 56/64 loss: 0.28250235319137573
Batch 57/64 loss: 0.2826641798019409
Batch 58/64 loss: 0.29311859607696533
Batch 59/64 loss: 0.2928972840309143
Batch 60/64 loss: 0.28477227687835693
Batch 61/64 loss: 0.28861624002456665
Batch 62/64 loss: 0.29300546646118164
Batch 63/64 loss: 0.292705774307251
Batch 64/64 loss: 0.2896362543106079
Epoch 151  Train loss: 0.2882561903373868  Val loss: 0.3013396250832941
Epoch 152
-------------------------------
Batch 1/64 loss: 0.2844235897064209
Batch 2/64 loss: 0.2847854495048523
Batch 3/64 loss: 0.29004502296447754
Batch 4/64 loss: 0.28977543115615845
Batch 5/64 loss: 0.29810094833374023
Batch 6/64 loss: 0.29342567920684814
Batch 7/64 loss: 0.2860543727874756
Batch 8/64 loss: 0.2853425145149231
Batch 9/64 loss: 0.29149317741394043
Batch 10/64 loss: 0.2861967086791992
Batch 11/64 loss: 0.28317713737487793
Batch 12/64 loss: 0.2830319404602051
Batch 13/64 loss: 0.2823331952095032
Batch 14/64 loss: 0.28690803050994873
Batch 15/64 loss: 0.29465579986572266
Batch 16/64 loss: 0.285815954208374
Batch 17/64 loss: 0.2840127944946289
Batch 18/64 loss: 0.2784655690193176
Batch 19/64 loss: 0.2943434715270996
Batch 20/64 loss: 0.2813541293144226
Batch 21/64 loss: 0.2932571768760681
Batch 22/64 loss: 0.2772696018218994
Batch 23/64 loss: 0.2738610506057739
Batch 24/64 loss: 0.2898094058036804
Batch 25/64 loss: 0.28114956617355347
Batch 26/64 loss: 0.30040156841278076
Batch 27/64 loss: 0.2915072441101074
Batch 28/64 loss: 0.2814437747001648
Batch 29/64 loss: 0.2809791564941406
Batch 30/64 loss: 0.29339009523391724
Batch 31/64 loss: 0.279161274433136
Batch 32/64 loss: 0.2868921756744385
Batch 33/64 loss: 0.2804657220840454
Batch 34/64 loss: 0.28677278757095337
Batch 35/64 loss: 0.28722667694091797
Batch 36/64 loss: 0.2828305959701538
Batch 37/64 loss: 0.28357231616973877
Batch 38/64 loss: 0.2848470211029053
Batch 39/64 loss: 0.2917461395263672
Batch 40/64 loss: 0.28875643014907837
Batch 41/64 loss: 0.2812669277191162
Batch 42/64 loss: 0.2886091470718384
Batch 43/64 loss: 0.28699398040771484
Batch 44/64 loss: 0.2888873815536499
Batch 45/64 loss: 0.290030300617218
Batch 46/64 loss: 0.2814134359359741
Batch 47/64 loss: 0.29472285509109497
Batch 48/64 loss: 0.29056525230407715
Batch 49/64 loss: 0.28119468688964844
Batch 50/64 loss: 0.28739428520202637
Batch 51/64 loss: 0.27967172861099243
Batch 52/64 loss: 0.28912878036499023
Batch 53/64 loss: 0.2897084951400757
Batch 54/64 loss: 0.28910523653030396
Batch 55/64 loss: 0.28910624980926514
Batch 56/64 loss: 0.30074381828308105
Batch 57/64 loss: 0.2893252372741699
Batch 58/64 loss: 0.28697508573532104
Batch 59/64 loss: 0.28608596324920654
Batch 60/64 loss: 0.2838733196258545
Batch 61/64 loss: 0.2896501421928406
Batch 62/64 loss: 0.2907007932662964
Batch 63/64 loss: 0.2872818112373352
Batch 64/64 loss: 0.28627121448516846
Epoch 152  Train loss: 0.28699951405618707  Val loss: 0.30144092225536856
Epoch 153
-------------------------------
Batch 1/64 loss: 0.2865917682647705
Batch 2/64 loss: 0.2816334366798401
Batch 3/64 loss: 0.2907617688179016
Batch 4/64 loss: 0.2824242115020752
Batch 5/64 loss: 0.29314905405044556
Batch 6/64 loss: 0.2915222644805908
Batch 7/64 loss: 0.2695522904396057
Batch 8/64 loss: 0.29208970069885254
Batch 9/64 loss: 0.2889317274093628
Batch 10/64 loss: 0.293510377407074
Batch 11/64 loss: 0.2904980182647705
Batch 12/64 loss: 0.2824850082397461
Batch 13/64 loss: 0.2854025363922119
Batch 14/64 loss: 0.2771492004394531
Batch 15/64 loss: 0.2814202308654785
Batch 16/64 loss: 0.2895923852920532
Batch 17/64 loss: 0.2874223589897156
Batch 18/64 loss: 0.2843906879425049
Batch 19/64 loss: 0.29825758934020996
Batch 20/64 loss: 0.28370606899261475
Batch 21/64 loss: 0.2886914014816284
Batch 22/64 loss: 0.2915771007537842
Batch 23/64 loss: 0.28362607955932617
Batch 24/64 loss: 0.2824738025665283
Batch 25/64 loss: 0.28965163230895996
Batch 26/64 loss: 0.28522539138793945
Batch 27/64 loss: 0.28544241189956665
Batch 28/64 loss: 0.2880210876464844
Batch 29/64 loss: 0.2845035791397095
Batch 30/64 loss: 0.2898426055908203
Batch 31/64 loss: 0.2862534523010254
Batch 32/64 loss: 0.28134655952453613
Batch 33/64 loss: 0.28534412384033203
Batch 34/64 loss: 0.2885863780975342
Batch 35/64 loss: 0.2871493697166443
Batch 36/64 loss: 0.2888574004173279
Batch 37/64 loss: 0.2816046476364136
Batch 38/64 loss: 0.2781630754470825
Batch 39/64 loss: 0.2913205623626709
Batch 40/64 loss: 0.29881298542022705
Batch 41/64 loss: 0.2829200029373169
Batch 42/64 loss: 0.28865671157836914
Batch 43/64 loss: 0.2879824638366699
Batch 44/64 loss: 0.28371989727020264
Batch 45/64 loss: 0.2961576581001282
Batch 46/64 loss: 0.28777313232421875
Batch 47/64 loss: 0.29414963722229004
Batch 48/64 loss: 0.2814829349517822
Batch 49/64 loss: 0.2788090705871582
Batch 50/64 loss: 0.29464101791381836
Batch 51/64 loss: 0.2829909324645996
Batch 52/64 loss: 0.28786784410476685
Batch 53/64 loss: 0.2835557460784912
Batch 54/64 loss: 0.3005359172821045
Batch 55/64 loss: 0.2934389114379883
Batch 56/64 loss: 0.29214125871658325
Batch 57/64 loss: 0.2892059087753296
Batch 58/64 loss: 0.29126256704330444
Batch 59/64 loss: 0.28849363327026367
Batch 60/64 loss: 0.2897779941558838
Batch 61/64 loss: 0.28965771198272705
Batch 62/64 loss: 0.28910380601882935
Batch 63/64 loss: 0.287014365196228
Batch 64/64 loss: 0.286133348941803
Epoch 153  Train loss: 0.2874184073186388  Val loss: 0.3005534738199817
Saving best model, epoch: 153
Epoch 154
-------------------------------
Batch 1/64 loss: 0.28623437881469727
Batch 2/64 loss: 0.2841470241546631
Batch 3/64 loss: 0.29849177598953247
Batch 4/64 loss: 0.2841354012489319
Batch 5/64 loss: 0.28881359100341797
Batch 6/64 loss: 0.2797846794128418
Batch 7/64 loss: 0.2843419909477234
Batch 8/64 loss: 0.2821313142776489
Batch 9/64 loss: 0.2880781888961792
Batch 10/64 loss: 0.2862628698348999
Batch 11/64 loss: 0.28620046377182007
Batch 12/64 loss: 0.29358673095703125
Batch 13/64 loss: 0.29294949769973755
Batch 14/64 loss: 0.2813182473182678
Batch 15/64 loss: 0.280251145362854
Batch 16/64 loss: 0.2847309112548828
Batch 17/64 loss: 0.288363516330719
Batch 18/64 loss: 0.28572511672973633
Batch 19/64 loss: 0.28767454624176025
Batch 20/64 loss: 0.30003154277801514
Batch 21/64 loss: 0.2868388891220093
Batch 22/64 loss: 0.28979945182800293
Batch 23/64 loss: 0.28802502155303955
Batch 24/64 loss: 0.28087663650512695
Batch 25/64 loss: 0.2898680567741394
Batch 26/64 loss: 0.28767824172973633
Batch 27/64 loss: 0.28042203187942505
Batch 28/64 loss: 0.2778291702270508
Batch 29/64 loss: 0.28730493783950806
Batch 30/64 loss: 0.28234750032424927
Batch 31/64 loss: 0.2876604199409485
Batch 32/64 loss: 0.2880910634994507
Batch 33/64 loss: 0.28556138277053833
Batch 34/64 loss: 0.28780150413513184
Batch 35/64 loss: 0.2807725667953491
Batch 36/64 loss: 0.2843611240386963
Batch 37/64 loss: 0.2970319986343384
Batch 38/64 loss: 0.28700125217437744
Batch 39/64 loss: 0.2844521403312683
Batch 40/64 loss: 0.2864556908607483
Batch 41/64 loss: 0.28290772438049316
Batch 42/64 loss: 0.28447794914245605
Batch 43/64 loss: 0.2925128936767578
Batch 44/64 loss: 0.2896403670310974
Batch 45/64 loss: 0.28253990411758423
Batch 46/64 loss: 0.2864210605621338
Batch 47/64 loss: 0.2801622152328491
Batch 48/64 loss: 0.2799626588821411
Batch 49/64 loss: 0.2889566421508789
Batch 50/64 loss: 0.2765052914619446
Batch 51/64 loss: 0.28057968616485596
Batch 52/64 loss: 0.2827175259590149
Batch 53/64 loss: 0.2852360010147095
Batch 54/64 loss: 0.2791177034378052
Batch 55/64 loss: 0.28542113304138184
Batch 56/64 loss: 0.28339600563049316
Batch 57/64 loss: 0.28535687923431396
Batch 58/64 loss: 0.2898421287536621
Batch 59/64 loss: 0.29382753372192383
Batch 60/64 loss: 0.28659749031066895
Batch 61/64 loss: 0.2856086492538452
Batch 62/64 loss: 0.2954402565956116
Batch 63/64 loss: 0.28911924362182617
Batch 64/64 loss: 0.28462111949920654
Epoch 154  Train loss: 0.2861685458351584  Val loss: 0.3002383176403767
Saving best model, epoch: 154
Epoch 155
-------------------------------
Batch 1/64 loss: 0.27862071990966797
Batch 2/64 loss: 0.29715192317962646
Batch 3/64 loss: 0.2784794569015503
Batch 4/64 loss: 0.29174089431762695
Batch 5/64 loss: 0.2889553904533386
Batch 6/64 loss: 0.27580857276916504
Batch 7/64 loss: 0.2799711227416992
Batch 8/64 loss: 0.28331005573272705
Batch 9/64 loss: 0.282733678817749
Batch 10/64 loss: 0.2892467975616455
Batch 11/64 loss: 0.2867164611816406
Batch 12/64 loss: 0.2898290157318115
Batch 13/64 loss: 0.28988099098205566
Batch 14/64 loss: 0.2910504937171936
Batch 15/64 loss: 0.2852623462677002
Batch 16/64 loss: 0.2847388982772827
Batch 17/64 loss: 0.2858341932296753
Batch 18/64 loss: 0.292417049407959
Batch 19/64 loss: 0.28371167182922363
Batch 20/64 loss: 0.28220486640930176
Batch 21/64 loss: 0.2911641597747803
Batch 22/64 loss: 0.2875833511352539
Batch 23/64 loss: 0.29128390550613403
Batch 24/64 loss: 0.2907368540763855
Batch 25/64 loss: 0.2854433059692383
Batch 26/64 loss: 0.2818310856819153
Batch 27/64 loss: 0.2825450897216797
Batch 28/64 loss: 0.27702176570892334
Batch 29/64 loss: 0.292061448097229
Batch 30/64 loss: 0.2895497679710388
Batch 31/64 loss: 0.28820139169692993
Batch 32/64 loss: 0.2819535732269287
Batch 33/64 loss: 0.28785109519958496
Batch 34/64 loss: 0.2976231575012207
Batch 35/64 loss: 0.28831154108047485
Batch 36/64 loss: 0.28495466709136963
Batch 37/64 loss: 0.28537875413894653
Batch 38/64 loss: 0.2802863121032715
Batch 39/64 loss: 0.28918445110321045
Batch 40/64 loss: 0.2950233221054077
Batch 41/64 loss: 0.2864396572113037
Batch 42/64 loss: 0.2825428247451782
Batch 43/64 loss: 0.2966355085372925
Batch 44/64 loss: 0.288785457611084
Batch 45/64 loss: 0.28727149963378906
Batch 46/64 loss: 0.2908543348312378
Batch 47/64 loss: 0.28729552030563354
Batch 48/64 loss: 0.2810167670249939
Batch 49/64 loss: 0.29023778438568115
Batch 50/64 loss: 0.2841132879257202
Batch 51/64 loss: 0.2897869348526001
Batch 52/64 loss: 0.2789323329925537
Batch 53/64 loss: 0.280490517616272
Batch 54/64 loss: 0.2902800440788269
Batch 55/64 loss: 0.27819204330444336
Batch 56/64 loss: 0.28050559759140015
Batch 57/64 loss: 0.2746519446372986
Batch 58/64 loss: 0.2828889489173889
Batch 59/64 loss: 0.2904871702194214
Batch 60/64 loss: 0.28186339139938354
Batch 61/64 loss: 0.282975971698761
Batch 62/64 loss: 0.28796154260635376
Batch 63/64 loss: 0.286851167678833
Batch 64/64 loss: 0.28615623712539673
Epoch 155  Train loss: 0.28613852589738137  Val loss: 0.30159620648806856
Epoch 156
-------------------------------
Batch 1/64 loss: 0.2880983352661133
Batch 2/64 loss: 0.28080135583877563
Batch 3/64 loss: 0.2831832766532898
Batch 4/64 loss: 0.2841881513595581
Batch 5/64 loss: 0.2814300060272217
Batch 6/64 loss: 0.28651249408721924
Batch 7/64 loss: 0.29225170612335205
Batch 8/64 loss: 0.2945946455001831
Batch 9/64 loss: 0.2892739772796631
Batch 10/64 loss: 0.3045148253440857
Batch 11/64 loss: 0.2773195505142212
Batch 12/64 loss: 0.28128570318222046
Batch 13/64 loss: 0.28420352935791016
Batch 14/64 loss: 0.28465908765792847
Batch 15/64 loss: 0.2799326181411743
Batch 16/64 loss: 0.28195101022720337
Batch 17/64 loss: 0.27770382165908813
Batch 18/64 loss: 0.28295278549194336
Batch 19/64 loss: 0.2827272415161133
Batch 20/64 loss: 0.2864125967025757
Batch 21/64 loss: 0.2832820415496826
Batch 22/64 loss: 0.2859809398651123
Batch 23/64 loss: 0.2866441607475281
Batch 24/64 loss: 0.2819730043411255
Batch 25/64 loss: 0.280326247215271
Batch 26/64 loss: 0.2762370705604553
Batch 27/64 loss: 0.28323495388031006
Batch 28/64 loss: 0.2859729528427124
Batch 29/64 loss: 0.28832268714904785
Batch 30/64 loss: 0.29343241453170776
Batch 31/64 loss: 0.29119402170181274
Batch 32/64 loss: 0.2829957604408264
Batch 33/64 loss: 0.28460192680358887
Batch 34/64 loss: 0.28579211235046387
Batch 35/64 loss: 0.28479206562042236
Batch 36/64 loss: 0.28706127405166626
Batch 37/64 loss: 0.2863110303878784
Batch 38/64 loss: 0.2766231894493103
Batch 39/64 loss: 0.28036069869995117
Batch 40/64 loss: 0.27768051624298096
Batch 41/64 loss: 0.29416751861572266
Batch 42/64 loss: 0.28871846199035645
Batch 43/64 loss: 0.29135191440582275
Batch 44/64 loss: 0.27712011337280273
Batch 45/64 loss: 0.2862201929092407
Batch 46/64 loss: 0.28032124042510986
Batch 47/64 loss: 0.2852323055267334
Batch 48/64 loss: 0.28002989292144775
Batch 49/64 loss: 0.28202539682388306
Batch 50/64 loss: 0.28843367099761963
Batch 51/64 loss: 0.2845733165740967
Batch 52/64 loss: 0.2851450443267822
Batch 53/64 loss: 0.29005908966064453
Batch 54/64 loss: 0.2842133045196533
Batch 55/64 loss: 0.28686249256134033
Batch 56/64 loss: 0.27989161014556885
Batch 57/64 loss: 0.28575217723846436
Batch 58/64 loss: 0.2815313935279846
Batch 59/64 loss: 0.27995526790618896
Batch 60/64 loss: 0.2966861128807068
Batch 61/64 loss: 0.28916192054748535
Batch 62/64 loss: 0.28292763233184814
Batch 63/64 loss: 0.2821773290634155
Batch 64/64 loss: 0.29745912551879883
Epoch 156  Train loss: 0.2850583141925288  Val loss: 0.3026334291061585
Epoch 157
-------------------------------
Batch 1/64 loss: 0.28099799156188965
Batch 2/64 loss: 0.2846029996871948
Batch 3/64 loss: 0.289676308631897
Batch 4/64 loss: 0.2829272150993347
Batch 5/64 loss: 0.2796357274055481
Batch 6/64 loss: 0.2824448347091675
Batch 7/64 loss: 0.2808302044868469
Batch 8/64 loss: 0.2920456528663635
Batch 9/64 loss: 0.28873127698898315
Batch 10/64 loss: 0.28941917419433594
Batch 11/64 loss: 0.28648483753204346
Batch 12/64 loss: 0.2880769968032837
Batch 13/64 loss: 0.275787889957428
Batch 14/64 loss: 0.2880364656448364
Batch 15/64 loss: 0.2824392318725586
Batch 16/64 loss: 0.2932974696159363
Batch 17/64 loss: 0.2862623333930969
Batch 18/64 loss: 0.28537315130233765
Batch 19/64 loss: 0.29051893949508667
Batch 20/64 loss: 0.2780493497848511
Batch 21/64 loss: 0.2855236530303955
Batch 22/64 loss: 0.28138065338134766
Batch 23/64 loss: 0.2842424511909485
Batch 24/64 loss: 0.2793726921081543
Batch 25/64 loss: 0.2818574905395508
Batch 26/64 loss: 0.28546011447906494
Batch 27/64 loss: 0.2818422317504883
Batch 28/64 loss: 0.27758270502090454
Batch 29/64 loss: 0.2940266728401184
Batch 30/64 loss: 0.2878307104110718
Batch 31/64 loss: 0.29017043113708496
Batch 32/64 loss: 0.2858647108078003
Batch 33/64 loss: 0.28304964303970337
Batch 34/64 loss: 0.2910415530204773
Batch 35/64 loss: 0.2902868986129761
Batch 36/64 loss: 0.28676116466522217
Batch 37/64 loss: 0.2807586193084717
Batch 38/64 loss: 0.29167628288269043
Batch 39/64 loss: 0.28241515159606934
Batch 40/64 loss: 0.2798597812652588
Batch 41/64 loss: 0.29173731803894043
Batch 42/64 loss: 0.2972344160079956
Batch 43/64 loss: 0.28384363651275635
Batch 44/64 loss: 0.27398598194122314
Batch 45/64 loss: 0.2902771234512329
Batch 46/64 loss: 0.28970223665237427
Batch 47/64 loss: 0.2830849289894104
Batch 48/64 loss: 0.29324638843536377
Batch 49/64 loss: 0.2854716181755066
Batch 50/64 loss: 0.2823762893676758
Batch 51/64 loss: 0.28237664699554443
Batch 52/64 loss: 0.28371918201446533
Batch 53/64 loss: 0.2811248302459717
Batch 54/64 loss: 0.2895849943161011
Batch 55/64 loss: 0.2797459363937378
Batch 56/64 loss: 0.2772684693336487
Batch 57/64 loss: 0.2818261384963989
Batch 58/64 loss: 0.2930859327316284
Batch 59/64 loss: 0.27985304594039917
Batch 60/64 loss: 0.28846275806427
Batch 61/64 loss: 0.2898007035255432
Batch 62/64 loss: 0.28373706340789795
Batch 63/64 loss: 0.2852579355239868
Batch 64/64 loss: 0.2871205806732178
Epoch 157  Train loss: 0.28531428505392636  Val loss: 0.2999405232082118
Saving best model, epoch: 157
Epoch 158
-------------------------------
Batch 1/64 loss: 0.2788955569267273
Batch 2/64 loss: 0.28389406204223633
Batch 3/64 loss: 0.28440171480178833
Batch 4/64 loss: 0.27904725074768066
Batch 5/64 loss: 0.28606611490249634
Batch 6/64 loss: 0.2865678668022156
Batch 7/64 loss: 0.28721582889556885
Batch 8/64 loss: 0.29155945777893066
Batch 9/64 loss: 0.28068965673446655
Batch 10/64 loss: 0.28747057914733887
Batch 11/64 loss: 0.2854582667350769
Batch 12/64 loss: 0.274086058139801
Batch 13/64 loss: 0.2762753963470459
Batch 14/64 loss: 0.29223793745040894
Batch 15/64 loss: 0.2863438129425049
Batch 16/64 loss: 0.28214776515960693
Batch 17/64 loss: 0.28692692518234253
Batch 18/64 loss: 0.27548712491989136
Batch 19/64 loss: 0.27915632724761963
Batch 20/64 loss: 0.28521329164505005
Batch 21/64 loss: 0.28244948387145996
Batch 22/64 loss: 0.2915363311767578
Batch 23/64 loss: 0.2848622798919678
Batch 24/64 loss: 0.288912296295166
Batch 25/64 loss: 0.2804008722305298
Batch 26/64 loss: 0.2764142155647278
Batch 27/64 loss: 0.28579849004745483
Batch 28/64 loss: 0.2867974042892456
Batch 29/64 loss: 0.28448760509490967
Batch 30/64 loss: 0.27630615234375
Batch 31/64 loss: 0.2942500114440918
Batch 32/64 loss: 0.2944701910018921
Batch 33/64 loss: 0.28958553075790405
Batch 34/64 loss: 0.28071296215057373
Batch 35/64 loss: 0.28937608003616333
Batch 36/64 loss: 0.2889106869697571
Batch 37/64 loss: 0.2865738868713379
Batch 38/64 loss: 0.2922455668449402
Batch 39/64 loss: 0.2839624285697937
Batch 40/64 loss: 0.2802671194076538
Batch 41/64 loss: 0.27719342708587646
Batch 42/64 loss: 0.2844393253326416
Batch 43/64 loss: 0.2847825884819031
Batch 44/64 loss: 0.2817577123641968
Batch 45/64 loss: 0.28664088249206543
Batch 46/64 loss: 0.2943393588066101
Batch 47/64 loss: 0.2906210422515869
Batch 48/64 loss: 0.2834891080856323
Batch 49/64 loss: 0.2892436981201172
Batch 50/64 loss: 0.29423755407333374
Batch 51/64 loss: 0.28220486640930176
Batch 52/64 loss: 0.29249703884124756
Batch 53/64 loss: 0.2944682836532593
Batch 54/64 loss: 0.28739869594573975
Batch 55/64 loss: 0.2860451936721802
Batch 56/64 loss: 0.2925933599472046
Batch 57/64 loss: 0.2839750051498413
Batch 58/64 loss: 0.28980231285095215
Batch 59/64 loss: 0.2824631929397583
Batch 60/64 loss: 0.2821720838546753
Batch 61/64 loss: 0.2905535101890564
Batch 62/64 loss: 0.28575968742370605
Batch 63/64 loss: 0.2820882797241211
Batch 64/64 loss: 0.2828529477119446
Epoch 158  Train loss: 0.28546457267275044  Val loss: 0.30019605487482653
Epoch 159
-------------------------------
Batch 1/64 loss: 0.28617143630981445
Batch 2/64 loss: 0.28437602519989014
Batch 3/64 loss: 0.2811155319213867
Batch 4/64 loss: 0.28485822677612305
Batch 5/64 loss: 0.28164148330688477
Batch 6/64 loss: 0.2859795093536377
Batch 7/64 loss: 0.2847644090652466
Batch 8/64 loss: 0.2944851517677307
Batch 9/64 loss: 0.28237247467041016
Batch 10/64 loss: 0.2876765727996826
Batch 11/64 loss: 0.28147661685943604
Batch 12/64 loss: 0.2918349504470825
Batch 13/64 loss: 0.28521645069122314
Batch 14/64 loss: 0.2821080684661865
Batch 15/64 loss: 0.28869491815567017
Batch 16/64 loss: 0.283974289894104
Batch 17/64 loss: 0.2923084497451782
Batch 18/64 loss: 0.2867574691772461
Batch 19/64 loss: 0.2812219262123108
Batch 20/64 loss: 0.28656214475631714
Batch 21/64 loss: 0.28122973442077637
Batch 22/64 loss: 0.28308892250061035
Batch 23/64 loss: 0.28112995624542236
Batch 24/64 loss: 0.2864886522293091
Batch 25/64 loss: 0.27254772186279297
Batch 26/64 loss: 0.2739371657371521
Batch 27/64 loss: 0.2854486107826233
Batch 28/64 loss: 0.2835090160369873
Batch 29/64 loss: 0.28373467922210693
Batch 30/64 loss: 0.2851862907409668
Batch 31/64 loss: 0.28219664096832275
Batch 32/64 loss: 0.2857986092567444
Batch 33/64 loss: 0.28714776039123535
Batch 34/64 loss: 0.28145623207092285
Batch 35/64 loss: 0.28496479988098145
Batch 36/64 loss: 0.2924998998641968
Batch 37/64 loss: 0.2886162996292114
Batch 38/64 loss: 0.2806891202926636
Batch 39/64 loss: 0.27982521057128906
Batch 40/64 loss: 0.2919142246246338
Batch 41/64 loss: 0.28612810373306274
Batch 42/64 loss: 0.27833592891693115
Batch 43/64 loss: 0.2861006259918213
Batch 44/64 loss: 0.2871565818786621
Batch 45/64 loss: 0.2813127040863037
Batch 46/64 loss: 0.2927272319793701
Batch 47/64 loss: 0.287789523601532
Batch 48/64 loss: 0.2833883762359619
Batch 49/64 loss: 0.2838047742843628
Batch 50/64 loss: 0.2813628911972046
Batch 51/64 loss: 0.2865836024284363
Batch 52/64 loss: 0.2886805534362793
Batch 53/64 loss: 0.2861417531967163
Batch 54/64 loss: 0.2866959571838379
Batch 55/64 loss: 0.2906125783920288
Batch 56/64 loss: 0.2870028018951416
Batch 57/64 loss: 0.28563809394836426
Batch 58/64 loss: 0.2846958637237549
Batch 59/64 loss: 0.2931176424026489
Batch 60/64 loss: 0.2800845503807068
Batch 61/64 loss: 0.2823244333267212
Batch 62/64 loss: 0.2841684818267822
Batch 63/64 loss: 0.27837586402893066
Batch 64/64 loss: 0.28741806745529175
Epoch 159  Train loss: 0.2849066372011222  Val loss: 0.2981820176147513
Saving best model, epoch: 159
Epoch 160
-------------------------------
Batch 1/64 loss: 0.27555322647094727
Batch 2/64 loss: 0.28119003772735596
Batch 3/64 loss: 0.2896689176559448
Batch 4/64 loss: 0.27937978506088257
Batch 5/64 loss: 0.29363536834716797
Batch 6/64 loss: 0.283408522605896
Batch 7/64 loss: 0.28133052587509155
Batch 8/64 loss: 0.2820947766304016
Batch 9/64 loss: 0.28349828720092773
Batch 10/64 loss: 0.2842140197753906
Batch 11/64 loss: 0.2830010652542114
Batch 12/64 loss: 0.28747689723968506
Batch 13/64 loss: 0.2760664224624634
Batch 14/64 loss: 0.2806648015975952
Batch 15/64 loss: 0.2800038456916809
Batch 16/64 loss: 0.2805135250091553
Batch 17/64 loss: 0.2839308977127075
Batch 18/64 loss: 0.28236979246139526
Batch 19/64 loss: 0.29376155138015747
Batch 20/64 loss: 0.2866203784942627
Batch 21/64 loss: 0.2900780439376831
Batch 22/64 loss: 0.2893519997596741
Batch 23/64 loss: 0.2855321168899536
Batch 24/64 loss: 0.28200602531433105
Batch 25/64 loss: 0.2820814847946167
Batch 26/64 loss: 0.28151053190231323
Batch 27/64 loss: 0.2789955139160156
Batch 28/64 loss: 0.2805711627006531
Batch 29/64 loss: 0.29018062353134155
Batch 30/64 loss: 0.2820814847946167
Batch 31/64 loss: 0.28348004817962646
Batch 32/64 loss: 0.27829694747924805
Batch 33/64 loss: 0.2918126583099365
Batch 34/64 loss: 0.27709436416625977
Batch 35/64 loss: 0.3010380268096924
Batch 36/64 loss: 0.28358936309814453
Batch 37/64 loss: 0.2870238423347473
Batch 38/64 loss: 0.28381723165512085
Batch 39/64 loss: 0.2905538082122803
Batch 40/64 loss: 0.2841709852218628
Batch 41/64 loss: 0.2894447445869446
Batch 42/64 loss: 0.2811230421066284
Batch 43/64 loss: 0.277707576751709
Batch 44/64 loss: 0.28003108501434326
Batch 45/64 loss: 0.29331648349761963
Batch 46/64 loss: 0.28874534368515015
Batch 47/64 loss: 0.28753775358200073
Batch 48/64 loss: 0.28289055824279785
Batch 49/64 loss: 0.2824590802192688
Batch 50/64 loss: 0.281238853931427
Batch 51/64 loss: 0.2823004722595215
Batch 52/64 loss: 0.2743180990219116
Batch 53/64 loss: 0.2869769334793091
Batch 54/64 loss: 0.2830057144165039
Batch 55/64 loss: 0.2894864082336426
Batch 56/64 loss: 0.28715717792510986
Batch 57/64 loss: 0.28056764602661133
Batch 58/64 loss: 0.29680687189102173
Batch 59/64 loss: 0.2837599515914917
Batch 60/64 loss: 0.29027259349823
Batch 61/64 loss: 0.2901236414909363
Batch 62/64 loss: 0.28566408157348633
Batch 63/64 loss: 0.2823218107223511
Batch 64/64 loss: 0.2758062481880188
Epoch 160  Train loss: 0.2844825022360858  Val loss: 0.3000216297677292
Epoch 161
-------------------------------
Batch 1/64 loss: 0.2832656502723694
Batch 2/64 loss: 0.289689302444458
Batch 3/64 loss: 0.2884998321533203
Batch 4/64 loss: 0.28621697425842285
Batch 5/64 loss: 0.2839086055755615
Batch 6/64 loss: 0.27846503257751465
Batch 7/64 loss: 0.27998852729797363
Batch 8/64 loss: 0.28505998849868774
Batch 9/64 loss: 0.2827725410461426
Batch 10/64 loss: 0.28750932216644287
Batch 11/64 loss: 0.28580355644226074
Batch 12/64 loss: 0.29051029682159424
Batch 13/64 loss: 0.2868615388870239
Batch 14/64 loss: 0.2925158739089966
Batch 15/64 loss: 0.2930135726928711
Batch 16/64 loss: 0.280644953250885
Batch 17/64 loss: 0.27021944522857666
Batch 18/64 loss: 0.28831565380096436
Batch 19/64 loss: 0.2857210636138916
Batch 20/64 loss: 0.28768157958984375
Batch 21/64 loss: 0.28021109104156494
Batch 22/64 loss: 0.28664684295654297
Batch 23/64 loss: 0.2827568054199219
Batch 24/64 loss: 0.28777915239334106
Batch 25/64 loss: 0.28404736518859863
Batch 26/64 loss: 0.2823556661605835
Batch 27/64 loss: 0.2740711569786072
Batch 28/64 loss: 0.28274524211883545
Batch 29/64 loss: 0.2872505187988281
Batch 30/64 loss: 0.2854177951812744
Batch 31/64 loss: 0.2827662229537964
Batch 32/64 loss: 0.2895040512084961
Batch 33/64 loss: 0.2838360667228699
Batch 34/64 loss: 0.28218382596969604
Batch 35/64 loss: 0.27604228258132935
Batch 36/64 loss: 0.2889708876609802
Batch 37/64 loss: 0.28951942920684814
Batch 38/64 loss: 0.2759386897087097
Batch 39/64 loss: 0.28636133670806885
Batch 40/64 loss: 0.2791212797164917
Batch 41/64 loss: 0.28931379318237305
Batch 42/64 loss: 0.2908214330673218
Batch 43/64 loss: 0.28173965215682983
Batch 44/64 loss: 0.29452186822891235
Batch 45/64 loss: 0.27763211727142334
Batch 46/64 loss: 0.28585386276245117
Batch 47/64 loss: 0.2794097661972046
Batch 48/64 loss: 0.28624117374420166
Batch 49/64 loss: 0.28262990713119507
Batch 50/64 loss: 0.29068851470947266
Batch 51/64 loss: 0.28622502088546753
Batch 52/64 loss: 0.28402596712112427
Batch 53/64 loss: 0.2825111150741577
Batch 54/64 loss: 0.288705050945282
Batch 55/64 loss: 0.2974858283996582
Batch 56/64 loss: 0.2816060781478882
Batch 57/64 loss: 0.28842759132385254
Batch 58/64 loss: 0.27573972940444946
Batch 59/64 loss: 0.2887089252471924
Batch 60/64 loss: 0.2802566885948181
Batch 61/64 loss: 0.2785452604293823
Batch 62/64 loss: 0.28005242347717285
Batch 63/64 loss: 0.2859065532684326
Batch 64/64 loss: 0.27747249603271484
Epoch 161  Train loss: 0.28453869352153704  Val loss: 0.2987349696995057
Epoch 162
-------------------------------
Batch 1/64 loss: 0.2878502607345581
Batch 2/64 loss: 0.2797727584838867
Batch 3/64 loss: 0.28415417671203613
Batch 4/64 loss: 0.2856893539428711
Batch 5/64 loss: 0.27626335620880127
Batch 6/64 loss: 0.28028202056884766
Batch 7/64 loss: 0.28339505195617676
Batch 8/64 loss: 0.2874724864959717
Batch 9/64 loss: 0.2760074734687805
Batch 10/64 loss: 0.2856528162956238
Batch 11/64 loss: 0.2834237813949585
Batch 12/64 loss: 0.2791712284088135
Batch 13/64 loss: 0.27547281980514526
Batch 14/64 loss: 0.28649091720581055
Batch 15/64 loss: 0.2826409339904785
Batch 16/64 loss: 0.2785264253616333
Batch 17/64 loss: 0.2800934910774231
Batch 18/64 loss: 0.2830691337585449
Batch 19/64 loss: 0.27795302867889404
Batch 20/64 loss: 0.2805376648902893
Batch 21/64 loss: 0.286456823348999
Batch 22/64 loss: 0.27794742584228516
Batch 23/64 loss: 0.2883354425430298
Batch 24/64 loss: 0.2782706022262573
Batch 25/64 loss: 0.2841414213180542
Batch 26/64 loss: 0.28081178665161133
Batch 27/64 loss: 0.27665120363235474
Batch 28/64 loss: 0.2863285541534424
Batch 29/64 loss: 0.2894933223724365
Batch 30/64 loss: 0.28439831733703613
Batch 31/64 loss: 0.2823839783668518
Batch 32/64 loss: 0.285646915435791
Batch 33/64 loss: 0.2799452543258667
Batch 34/64 loss: 0.2815329432487488
Batch 35/64 loss: 0.283608615398407
Batch 36/64 loss: 0.2899366617202759
Batch 37/64 loss: 0.2841651439666748
Batch 38/64 loss: 0.291989803314209
Batch 39/64 loss: 0.274075448513031
Batch 40/64 loss: 0.2831946611404419
Batch 41/64 loss: 0.2824731469154358
Batch 42/64 loss: 0.277563214302063
Batch 43/64 loss: 0.2808603048324585
Batch 44/64 loss: 0.28070175647735596
Batch 45/64 loss: 0.2799370288848877
Batch 46/64 loss: 0.2726384401321411
Batch 47/64 loss: 0.28483808040618896
Batch 48/64 loss: 0.290716290473938
Batch 49/64 loss: 0.2879789471626282
Batch 50/64 loss: 0.27521514892578125
Batch 51/64 loss: 0.2807488441467285
Batch 52/64 loss: 0.2823672890663147
Batch 53/64 loss: 0.2934107780456543
Batch 54/64 loss: 0.28860926628112793
Batch 55/64 loss: 0.27956509590148926
Batch 56/64 loss: 0.288494348526001
Batch 57/64 loss: 0.28666698932647705
Batch 58/64 loss: 0.28287994861602783
Batch 59/64 loss: 0.28123992681503296
Batch 60/64 loss: 0.291175901889801
Batch 61/64 loss: 0.3080936074256897
Batch 62/64 loss: 0.28755927085876465
Batch 63/64 loss: 0.2753431797027588
Batch 64/64 loss: 0.28849703073501587
Epoch 162  Train loss: 0.2832734601170409  Val loss: 0.29784267464863884
Saving best model, epoch: 162
Epoch 163
-------------------------------
Batch 1/64 loss: 0.2862941026687622
Batch 2/64 loss: 0.2804805040359497
Batch 3/64 loss: 0.2822682857513428
Batch 4/64 loss: 0.2723686695098877
Batch 5/64 loss: 0.28430110216140747
Batch 6/64 loss: 0.27772843837738037
Batch 7/64 loss: 0.27287405729293823
Batch 8/64 loss: 0.28104305267333984
Batch 9/64 loss: 0.2789584994316101
Batch 10/64 loss: 0.28790557384490967
Batch 11/64 loss: 0.28880560398101807
Batch 12/64 loss: 0.2773491144180298
Batch 13/64 loss: 0.2754850387573242
Batch 14/64 loss: 0.28997647762298584
Batch 15/64 loss: 0.27770233154296875
Batch 16/64 loss: 0.27713894844055176
Batch 17/64 loss: 0.28109049797058105
Batch 18/64 loss: 0.2763552665710449
Batch 19/64 loss: 0.2872192859649658
Batch 20/64 loss: 0.2880546450614929
Batch 21/64 loss: 0.2776849865913391
Batch 22/64 loss: 0.2863779067993164
Batch 23/64 loss: 0.2759321928024292
Batch 24/64 loss: 0.28491997718811035
Batch 25/64 loss: 0.28866326808929443
Batch 26/64 loss: 0.2860081195831299
Batch 27/64 loss: 0.2814134359359741
Batch 28/64 loss: 0.27812302112579346
Batch 29/64 loss: 0.29179584980010986
Batch 30/64 loss: 0.2877923846244812
Batch 31/64 loss: 0.2869100570678711
Batch 32/64 loss: 0.28709983825683594
Batch 33/64 loss: 0.27926862239837646
Batch 34/64 loss: 0.2858286499977112
Batch 35/64 loss: 0.28139346837997437
Batch 36/64 loss: 0.28154653310775757
Batch 37/64 loss: 0.29422450065612793
Batch 38/64 loss: 0.2837238311767578
Batch 39/64 loss: 0.2763959765434265
Batch 40/64 loss: 0.28710734844207764
Batch 41/64 loss: 0.28646016120910645
Batch 42/64 loss: 0.29181885719299316
Batch 43/64 loss: 0.28072279691696167
Batch 44/64 loss: 0.28222572803497314
Batch 45/64 loss: 0.288954496383667
Batch 46/64 loss: 0.28606653213500977
Batch 47/64 loss: 0.2841149568557739
Batch 48/64 loss: 0.2879500389099121
Batch 49/64 loss: 0.279127836227417
Batch 50/64 loss: 0.27852678298950195
Batch 51/64 loss: 0.28547751903533936
Batch 52/64 loss: 0.28586769104003906
Batch 53/64 loss: 0.27585190534591675
Batch 54/64 loss: 0.28259599208831787
Batch 55/64 loss: 0.2824118733406067
Batch 56/64 loss: 0.28435349464416504
Batch 57/64 loss: 0.28519976139068604
Batch 58/64 loss: 0.27489012479782104
Batch 59/64 loss: 0.28451645374298096
Batch 60/64 loss: 0.280519962310791
Batch 61/64 loss: 0.28477901220321655
Batch 62/64 loss: 0.27980923652648926
Batch 63/64 loss: 0.2899913787841797
Batch 64/64 loss: 0.28044211864471436
Epoch 163  Train loss: 0.28295174346250646  Val loss: 0.29736340660409827
Saving best model, epoch: 163
Epoch 164
-------------------------------
Batch 1/64 loss: 0.2877078652381897
Batch 2/64 loss: 0.28400862216949463
Batch 3/64 loss: 0.2864421606063843
Batch 4/64 loss: 0.2849205732345581
Batch 5/64 loss: 0.28261685371398926
Batch 6/64 loss: 0.27674245834350586
Batch 7/64 loss: 0.2856394052505493
Batch 8/64 loss: 0.27439236640930176
Batch 9/64 loss: 0.2821664810180664
Batch 10/64 loss: 0.27610957622528076
Batch 11/64 loss: 0.28218257427215576
Batch 12/64 loss: 0.27493083477020264
Batch 13/64 loss: 0.2809315323829651
Batch 14/64 loss: 0.28186798095703125
Batch 15/64 loss: 0.27645134925842285
Batch 16/64 loss: 0.28424715995788574
Batch 17/64 loss: 0.29207903146743774
Batch 18/64 loss: 0.2845247983932495
Batch 19/64 loss: 0.27542710304260254
Batch 20/64 loss: 0.2950100302696228
Batch 21/64 loss: 0.2790597677230835
Batch 22/64 loss: 0.29643863439559937
Batch 23/64 loss: 0.2859553098678589
Batch 24/64 loss: 0.285502552986145
Batch 25/64 loss: 0.268396258354187
Batch 26/64 loss: 0.28760063648223877
Batch 27/64 loss: 0.27678120136260986
Batch 28/64 loss: 0.2828197479248047
Batch 29/64 loss: 0.28723883628845215
Batch 30/64 loss: 0.2757500410079956
Batch 31/64 loss: 0.2848619222640991
Batch 32/64 loss: 0.2808834910392761
Batch 33/64 loss: 0.2899322509765625
Batch 34/64 loss: 0.2800743579864502
Batch 35/64 loss: 0.28325778245925903
Batch 36/64 loss: 0.2874913215637207
Batch 37/64 loss: 0.27724242210388184
Batch 38/64 loss: 0.2818124294281006
Batch 39/64 loss: 0.27947288751602173
Batch 40/64 loss: 0.28140151500701904
Batch 41/64 loss: 0.2795255184173584
Batch 42/64 loss: 0.28619712591171265
Batch 43/64 loss: 0.29028022289276123
Batch 44/64 loss: 0.28900980949401855
Batch 45/64 loss: 0.28788936138153076
Batch 46/64 loss: 0.28236639499664307
Batch 47/64 loss: 0.2817872166633606
Batch 48/64 loss: 0.2831305265426636
Batch 49/64 loss: 0.2826879024505615
Batch 50/64 loss: 0.2826937437057495
Batch 51/64 loss: 0.28640031814575195
Batch 52/64 loss: 0.28569579124450684
Batch 53/64 loss: 0.274807333946228
Batch 54/64 loss: 0.27597224712371826
Batch 55/64 loss: 0.2920159101486206
Batch 56/64 loss: 0.27728235721588135
Batch 57/64 loss: 0.2895376682281494
Batch 58/64 loss: 0.29312121868133545
Batch 59/64 loss: 0.2860570549964905
Batch 60/64 loss: 0.2854524254798889
Batch 61/64 loss: 0.28483766317367554
Batch 62/64 loss: 0.2907165288925171
Batch 63/64 loss: 0.27944862842559814
Batch 64/64 loss: 0.29168349504470825
Epoch 164  Train loss: 0.2833889837358512  Val loss: 0.30056155096624315
Epoch 165
-------------------------------
Batch 1/64 loss: 0.28500545024871826
Batch 2/64 loss: 0.28995513916015625
Batch 3/64 loss: 0.2854806184768677
Batch 4/64 loss: 0.2834889888763428
Batch 5/64 loss: 0.27947187423706055
Batch 6/64 loss: 0.2805377244949341
Batch 7/64 loss: 0.28311145305633545
Batch 8/64 loss: 0.28629064559936523
Batch 9/64 loss: 0.27242714166641235
Batch 10/64 loss: 0.2747849225997925
Batch 11/64 loss: 0.280987024307251
Batch 12/64 loss: 0.2880859971046448
Batch 13/64 loss: 0.27863407135009766
Batch 14/64 loss: 0.2884635925292969
Batch 15/64 loss: 0.28550469875335693
Batch 16/64 loss: 0.2786750793457031
Batch 17/64 loss: 0.2787775993347168
Batch 18/64 loss: 0.2919817566871643
Batch 19/64 loss: 0.2919033169746399
Batch 20/64 loss: 0.28673022985458374
Batch 21/64 loss: 0.2810966372489929
Batch 22/64 loss: 0.2831844687461853
Batch 23/64 loss: 0.2872820496559143
Batch 24/64 loss: 0.27859586477279663
Batch 25/64 loss: 0.28077632188796997
Batch 26/64 loss: 0.2897986173629761
Batch 27/64 loss: 0.2813847064971924
Batch 28/64 loss: 0.28414130210876465
Batch 29/64 loss: 0.2812955379486084
Batch 30/64 loss: 0.2849072217941284
Batch 31/64 loss: 0.2888681888580322
Batch 32/64 loss: 0.2754666805267334
Batch 33/64 loss: 0.2813173532485962
Batch 34/64 loss: 0.28407859802246094
Batch 35/64 loss: 0.28084272146224976
Batch 36/64 loss: 0.2800813317298889
Batch 37/64 loss: 0.2805614471435547
Batch 38/64 loss: 0.2764970064163208
Batch 39/64 loss: 0.27836334705352783
Batch 40/64 loss: 0.2831372022628784
Batch 41/64 loss: 0.2828384041786194
Batch 42/64 loss: 0.2760646939277649
Batch 43/64 loss: 0.2845275402069092
Batch 44/64 loss: 0.2867155075073242
Batch 45/64 loss: 0.2806907892227173
Batch 46/64 loss: 0.2789497375488281
Batch 47/64 loss: 0.27943265438079834
Batch 48/64 loss: 0.28203248977661133
Batch 49/64 loss: 0.28057193756103516
Batch 50/64 loss: 0.2870523929595947
Batch 51/64 loss: 0.286532998085022
Batch 52/64 loss: 0.27831315994262695
Batch 53/64 loss: 0.29020726680755615
Batch 54/64 loss: 0.2813279628753662
Batch 55/64 loss: 0.27798110246658325
Batch 56/64 loss: 0.28391122817993164
Batch 57/64 loss: 0.2842857837677002
Batch 58/64 loss: 0.284030556678772
Batch 59/64 loss: 0.2751762866973877
Batch 60/64 loss: 0.28215503692626953
Batch 61/64 loss: 0.2797303795814514
Batch 62/64 loss: 0.2972545623779297
Batch 63/64 loss: 0.28755152225494385
Batch 64/64 loss: 0.2749738097190857
Epoch 165  Train loss: 0.28275354165656896  Val loss: 0.29932823623578575
Epoch 166
-------------------------------
Batch 1/64 loss: 0.29135823249816895
Batch 2/64 loss: 0.2933307886123657
Batch 3/64 loss: 0.27573084831237793
Batch 4/64 loss: 0.27935177087783813
Batch 5/64 loss: 0.2822749614715576
Batch 6/64 loss: 0.27892595529556274
Batch 7/64 loss: 0.2903381586074829
Batch 8/64 loss: 0.28514063358306885
Batch 9/64 loss: 0.27856743335723877
Batch 10/64 loss: 0.2827186584472656
Batch 11/64 loss: 0.28005337715148926
Batch 12/64 loss: 0.28388047218322754
Batch 13/64 loss: 0.27985942363739014
Batch 14/64 loss: 0.27980804443359375
Batch 15/64 loss: 0.27941811084747314
Batch 16/64 loss: 0.2827122211456299
Batch 17/64 loss: 0.28305238485336304
Batch 18/64 loss: 0.28460514545440674
Batch 19/64 loss: 0.2830202579498291
Batch 20/64 loss: 0.27699458599090576
Batch 21/64 loss: 0.28646498918533325
Batch 22/64 loss: 0.28855371475219727
Batch 23/64 loss: 0.28190380334854126
Batch 24/64 loss: 0.28978586196899414
Batch 25/64 loss: 0.28727591037750244
Batch 26/64 loss: 0.28975868225097656
Batch 27/64 loss: 0.27473723888397217
Batch 28/64 loss: 0.27993398904800415
Batch 29/64 loss: 0.27996325492858887
Batch 30/64 loss: 0.28696608543395996
Batch 31/64 loss: 0.28370118141174316
Batch 32/64 loss: 0.28065043687820435
Batch 33/64 loss: 0.27322977781295776
Batch 34/64 loss: 0.27297115325927734
Batch 35/64 loss: 0.2800079584121704
Batch 36/64 loss: 0.2850832939147949
Batch 37/64 loss: 0.2807958126068115
Batch 38/64 loss: 0.282863974571228
Batch 39/64 loss: 0.2922782897949219
Batch 40/64 loss: 0.28006505966186523
Batch 41/64 loss: 0.2902308702468872
Batch 42/64 loss: 0.2868974208831787
Batch 43/64 loss: 0.27863001823425293
Batch 44/64 loss: 0.2839655876159668
Batch 45/64 loss: 0.2823218107223511
Batch 46/64 loss: 0.2881591320037842
Batch 47/64 loss: 0.2844083905220032
Batch 48/64 loss: 0.2784104347229004
Batch 49/64 loss: 0.28629207611083984
Batch 50/64 loss: 0.2862281799316406
Batch 51/64 loss: 0.2834794521331787
Batch 52/64 loss: 0.2763137221336365
Batch 53/64 loss: 0.28374987840652466
Batch 54/64 loss: 0.2822883129119873
Batch 55/64 loss: 0.2877107858657837
Batch 56/64 loss: 0.2785987854003906
Batch 57/64 loss: 0.279132604598999
Batch 58/64 loss: 0.28409290313720703
Batch 59/64 loss: 0.2808029055595398
Batch 60/64 loss: 0.2847602367401123
Batch 61/64 loss: 0.27558088302612305
Batch 62/64 loss: 0.2755809426307678
Batch 63/64 loss: 0.28273093700408936
Batch 64/64 loss: 0.2756686210632324
Epoch 166  Train loss: 0.2825921516792447  Val loss: 0.29822463063439963
Epoch 167
-------------------------------
Batch 1/64 loss: 0.2822732925415039
Batch 2/64 loss: 0.2823575735092163
Batch 3/64 loss: 0.2811744213104248
Batch 4/64 loss: 0.2850185036659241
Batch 5/64 loss: 0.2866523861885071
Batch 6/64 loss: 0.2961621880531311
Batch 7/64 loss: 0.275676965713501
Batch 8/64 loss: 0.2799816131591797
Batch 9/64 loss: 0.27395033836364746
Batch 10/64 loss: 0.2790907621383667
Batch 11/64 loss: 0.28012073040008545
Batch 12/64 loss: 0.2862684726715088
Batch 13/64 loss: 0.28555870056152344
Batch 14/64 loss: 0.2736314535140991
Batch 15/64 loss: 0.2842597961425781
Batch 16/64 loss: 0.29157859086990356
Batch 17/64 loss: 0.27589118480682373
Batch 18/64 loss: 0.27745580673217773
Batch 19/64 loss: 0.2839243412017822
Batch 20/64 loss: 0.2899578809738159
Batch 21/64 loss: 0.2826623320579529
Batch 22/64 loss: 0.2725033760070801
Batch 23/64 loss: 0.2830827236175537
Batch 24/64 loss: 0.2807055115699768
Batch 25/64 loss: 0.2836958169937134
Batch 26/64 loss: 0.28339076042175293
Batch 27/64 loss: 0.28083211183547974
Batch 28/64 loss: 0.2856205701828003
Batch 29/64 loss: 0.2778059244155884
Batch 30/64 loss: 0.28583037853240967
Batch 31/64 loss: 0.2809593677520752
Batch 32/64 loss: 0.28083157539367676
Batch 33/64 loss: 0.2773135304450989
Batch 34/64 loss: 0.2867978811264038
Batch 35/64 loss: 0.2834210991859436
Batch 36/64 loss: 0.2838863134384155
Batch 37/64 loss: 0.2833711504936218
Batch 38/64 loss: 0.28758692741394043
Batch 39/64 loss: 0.2766207456588745
Batch 40/64 loss: 0.2840573191642761
Batch 41/64 loss: 0.28434818983078003
Batch 42/64 loss: 0.2885582447052002
Batch 43/64 loss: 0.2836913466453552
Batch 44/64 loss: 0.2815614938735962
Batch 45/64 loss: 0.275626003742218
Batch 46/64 loss: 0.27906447649002075
Batch 47/64 loss: 0.27159297466278076
Batch 48/64 loss: 0.28639650344848633
Batch 49/64 loss: 0.28279566764831543
Batch 50/64 loss: 0.29098230600357056
Batch 51/64 loss: 0.27392399311065674
Batch 52/64 loss: 0.27529072761535645
Batch 53/64 loss: 0.27398717403411865
Batch 54/64 loss: 0.2912060022354126
Batch 55/64 loss: 0.28524643182754517
Batch 56/64 loss: 0.27748703956604004
Batch 57/64 loss: 0.28182750940322876
Batch 58/64 loss: 0.2741352319717407
Batch 59/64 loss: 0.27545011043548584
Batch 60/64 loss: 0.2816429138183594
Batch 61/64 loss: 0.2848128080368042
Batch 62/64 loss: 0.2786794900894165
Batch 63/64 loss: 0.2870490550994873
Batch 64/64 loss: 0.27840250730514526
Epoch 167  Train loss: 0.2818214587136811  Val loss: 0.30091079321923536
Epoch 168
-------------------------------
Batch 1/64 loss: 0.2771216630935669
Batch 2/64 loss: 0.2818296551704407
Batch 3/64 loss: 0.28441524505615234
Batch 4/64 loss: 0.2866336703300476
Batch 5/64 loss: 0.2846449017524719
Batch 6/64 loss: 0.2836947441101074
Batch 7/64 loss: 0.28390413522720337
Batch 8/64 loss: 0.29314088821411133
Batch 9/64 loss: 0.2795447111129761
Batch 10/64 loss: 0.283460795879364
Batch 11/64 loss: 0.2803518772125244
Batch 12/64 loss: 0.2826507091522217
Batch 13/64 loss: 0.27528393268585205
Batch 14/64 loss: 0.274922251701355
Batch 15/64 loss: 0.2810232639312744
Batch 16/64 loss: 0.2765588164329529
Batch 17/64 loss: 0.2995847463607788
Batch 18/64 loss: 0.2711712718009949
Batch 19/64 loss: 0.2824103832244873
Batch 20/64 loss: 0.2709749937057495
Batch 21/64 loss: 0.28484904766082764
Batch 22/64 loss: 0.27726060152053833
Batch 23/64 loss: 0.2885349988937378
Batch 24/64 loss: 0.27904462814331055
Batch 25/64 loss: 0.27450019121170044
Batch 26/64 loss: 0.27818989753723145
Batch 27/64 loss: 0.2694503664970398
Batch 28/64 loss: 0.2863273024559021
Batch 29/64 loss: 0.27245157957077026
Batch 30/64 loss: 0.27845239639282227
Batch 31/64 loss: 0.2807425260543823
Batch 32/64 loss: 0.278883159160614
Batch 33/64 loss: 0.27305305004119873
Batch 34/64 loss: 0.28461068868637085
Batch 35/64 loss: 0.2796338200569153
Batch 36/64 loss: 0.2909740209579468
Batch 37/64 loss: 0.28376996517181396
Batch 38/64 loss: 0.2787134647369385
Batch 39/64 loss: 0.2788017988204956
Batch 40/64 loss: 0.27929234504699707
Batch 41/64 loss: 0.28662824630737305
Batch 42/64 loss: 0.28358519077301025
Batch 43/64 loss: 0.2816891670227051
Batch 44/64 loss: 0.2731848359107971
Batch 45/64 loss: 0.28418397903442383
Batch 46/64 loss: 0.27697354555130005
Batch 47/64 loss: 0.28979623317718506
Batch 48/64 loss: 0.28382110595703125
Batch 49/64 loss: 0.2785886526107788
Batch 50/64 loss: 0.2908371090888977
Batch 51/64 loss: 0.2760053873062134
Batch 52/64 loss: 0.2904740571975708
Batch 53/64 loss: 0.27382856607437134
Batch 54/64 loss: 0.2780039310455322
Batch 55/64 loss: 0.2768588066101074
Batch 56/64 loss: 0.28512346744537354
Batch 57/64 loss: 0.2921176552772522
Batch 58/64 loss: 0.28028178215026855
Batch 59/64 loss: 0.2782254219055176
Batch 60/64 loss: 0.27813076972961426
Batch 61/64 loss: 0.2749873399734497
Batch 62/64 loss: 0.28519105911254883
Batch 63/64 loss: 0.2853090763092041
Batch 64/64 loss: 0.2810269594192505
Epoch 168  Train loss: 0.2811835938808965  Val loss: 0.29773764040871586
Epoch 169
-------------------------------
Batch 1/64 loss: 0.27683860063552856
Batch 2/64 loss: 0.2748836278915405
Batch 3/64 loss: 0.2803860902786255
Batch 4/64 loss: 0.27230507135391235
Batch 5/64 loss: 0.2845997214317322
Batch 6/64 loss: 0.27675163745880127
Batch 7/64 loss: 0.2892513871192932
Batch 8/64 loss: 0.2793703079223633
Batch 9/64 loss: 0.2803182601928711
Batch 10/64 loss: 0.2849324941635132
Batch 11/64 loss: 0.2852075695991516
Batch 12/64 loss: 0.28624939918518066
Batch 13/64 loss: 0.2833646535873413
Batch 14/64 loss: 0.2786695957183838
Batch 15/64 loss: 0.26968318223953247
Batch 16/64 loss: 0.28125321865081787
Batch 17/64 loss: 0.2754983901977539
Batch 18/64 loss: 0.28023219108581543
Batch 19/64 loss: 0.2839318513870239
Batch 20/64 loss: 0.27901995182037354
Batch 21/64 loss: 0.28436291217803955
Batch 22/64 loss: 0.2819126844406128
Batch 23/64 loss: 0.2736549377441406
Batch 24/64 loss: 0.2827780246734619
Batch 25/64 loss: 0.2761882543563843
Batch 26/64 loss: 0.27669447660446167
Batch 27/64 loss: 0.28380560874938965
Batch 28/64 loss: 0.27534037828445435
Batch 29/64 loss: 0.2720797061920166
Batch 30/64 loss: 0.2914871573448181
Batch 31/64 loss: 0.27708548307418823
Batch 32/64 loss: 0.2787187695503235
Batch 33/64 loss: 0.2733986973762512
Batch 34/64 loss: 0.28006184101104736
Batch 35/64 loss: 0.2759469747543335
Batch 36/64 loss: 0.2909148931503296
Batch 37/64 loss: 0.2743631601333618
Batch 38/64 loss: 0.27346837520599365
Batch 39/64 loss: 0.2810271978378296
Batch 40/64 loss: 0.27845966815948486
Batch 41/64 loss: 0.28579336404800415
Batch 42/64 loss: 0.2833293676376343
Batch 43/64 loss: 0.2921137809753418
Batch 44/64 loss: 0.2833945155143738
Batch 45/64 loss: 0.2756592035293579
Batch 46/64 loss: 0.288738489151001
Batch 47/64 loss: 0.2774583101272583
Batch 48/64 loss: 0.2818976640701294
Batch 49/64 loss: 0.28776073455810547
Batch 50/64 loss: 0.2833733558654785
Batch 51/64 loss: 0.2774417996406555
Batch 52/64 loss: 0.2813537120819092
Batch 53/64 loss: 0.2796679735183716
Batch 54/64 loss: 0.2826422452926636
Batch 55/64 loss: 0.2848660945892334
Batch 56/64 loss: 0.2847527265548706
Batch 57/64 loss: 0.2769883871078491
Batch 58/64 loss: 0.28608715534210205
Batch 59/64 loss: 0.273288369178772
Batch 60/64 loss: 0.28400641679763794
Batch 61/64 loss: 0.28169071674346924
Batch 62/64 loss: 0.28223955631256104
Batch 63/64 loss: 0.28209567070007324
Batch 64/64 loss: 0.2848713994026184
Epoch 169  Train loss: 0.2807025813588909  Val loss: 0.298293421358587
Epoch 170
-------------------------------
Batch 1/64 loss: 0.28098803758621216
Batch 2/64 loss: 0.28053581714630127
Batch 3/64 loss: 0.2873859405517578
Batch 4/64 loss: 0.28046590089797974
Batch 5/64 loss: 0.2837126851081848
Batch 6/64 loss: 0.28003859519958496
Batch 7/64 loss: 0.2835428714752197
Batch 8/64 loss: 0.282983660697937
Batch 9/64 loss: 0.27523791790008545
Batch 10/64 loss: 0.27663683891296387
Batch 11/64 loss: 0.27827179431915283
Batch 12/64 loss: 0.29350316524505615
Batch 13/64 loss: 0.27419131994247437
Batch 14/64 loss: 0.27564966678619385
Batch 15/64 loss: 0.2794804573059082
Batch 16/64 loss: 0.28516173362731934
Batch 17/64 loss: 0.28325605392456055
Batch 18/64 loss: 0.26954376697540283
Batch 19/64 loss: 0.2802886962890625
Batch 20/64 loss: 0.27813249826431274
Batch 21/64 loss: 0.28975915908813477
Batch 22/64 loss: 0.2777531147003174
Batch 23/64 loss: 0.28435492515563965
Batch 24/64 loss: 0.2859222888946533
Batch 25/64 loss: 0.2797362208366394
Batch 26/64 loss: 0.27608442306518555
Batch 27/64 loss: 0.279064416885376
Batch 28/64 loss: 0.28724586963653564
Batch 29/64 loss: 0.27770352363586426
Batch 30/64 loss: 0.2783234119415283
Batch 31/64 loss: 0.28369808197021484
Batch 32/64 loss: 0.28193438053131104
Batch 33/64 loss: 0.2867124676704407
Batch 34/64 loss: 0.2794167995452881
Batch 35/64 loss: 0.27606111764907837
Batch 36/64 loss: 0.27800214290618896
Batch 37/64 loss: 0.27557384967803955
Batch 38/64 loss: 0.28974688053131104
Batch 39/64 loss: 0.2813578248023987
Batch 40/64 loss: 0.28202807903289795
Batch 41/64 loss: 0.2810157537460327
Batch 42/64 loss: 0.2741827964782715
Batch 43/64 loss: 0.2760807275772095
Batch 44/64 loss: 0.280239462852478
Batch 45/64 loss: 0.2836998701095581
Batch 46/64 loss: 0.277748703956604
Batch 47/64 loss: 0.2813982367515564
Batch 48/64 loss: 0.2780792713165283
Batch 49/64 loss: 0.28287291526794434
Batch 50/64 loss: 0.28213047981262207
Batch 51/64 loss: 0.28258228302001953
Batch 52/64 loss: 0.2857251763343811
Batch 53/64 loss: 0.2863132953643799
Batch 54/64 loss: 0.27477675676345825
Batch 55/64 loss: 0.281155526638031
Batch 56/64 loss: 0.2807081937789917
Batch 57/64 loss: 0.2759352922439575
Batch 58/64 loss: 0.2816774249076843
Batch 59/64 loss: 0.2772670388221741
Batch 60/64 loss: 0.29047465324401855
Batch 61/64 loss: 0.2741643786430359
Batch 62/64 loss: 0.2859703302383423
Batch 63/64 loss: 0.2804147005081177
Batch 64/64 loss: 0.28955280780792236
Epoch 170  Train loss: 0.2809610081653969  Val loss: 0.2968193710464792
Saving best model, epoch: 170
Epoch 171
-------------------------------
Batch 1/64 loss: 0.27943354845046997
Batch 2/64 loss: 0.2673218250274658
Batch 3/64 loss: 0.2777364253997803
Batch 4/64 loss: 0.28864622116088867
Batch 5/64 loss: 0.2804548740386963
Batch 6/64 loss: 0.2798181176185608
Batch 7/64 loss: 0.2829209566116333
Batch 8/64 loss: 0.27577638626098633
Batch 9/64 loss: 0.287183940410614
Batch 10/64 loss: 0.2776613235473633
Batch 11/64 loss: 0.2707117795944214
Batch 12/64 loss: 0.27581942081451416
Batch 13/64 loss: 0.2821640372276306
Batch 14/64 loss: 0.279762864112854
Batch 15/64 loss: 0.2849109172821045
Batch 16/64 loss: 0.283524751663208
Batch 17/64 loss: 0.2892283797264099
Batch 18/64 loss: 0.2834155559539795
Batch 19/64 loss: 0.2737054228782654
Batch 20/64 loss: 0.2858400344848633
Batch 21/64 loss: 0.27606719732284546
Batch 22/64 loss: 0.2793603539466858
Batch 23/64 loss: 0.2936365604400635
Batch 24/64 loss: 0.2852892279624939
Batch 25/64 loss: 0.27564001083374023
Batch 26/64 loss: 0.2823560833930969
Batch 27/64 loss: 0.27309203147888184
Batch 28/64 loss: 0.2755013704299927
Batch 29/64 loss: 0.2870032787322998
Batch 30/64 loss: 0.2774066925048828
Batch 31/64 loss: 0.2782372236251831
Batch 32/64 loss: 0.2853595018386841
Batch 33/64 loss: 0.2735999822616577
Batch 34/64 loss: 0.27601683139801025
Batch 35/64 loss: 0.287256121635437
Batch 36/64 loss: 0.27571576833724976
Batch 37/64 loss: 0.2715801000595093
Batch 38/64 loss: 0.28443723917007446
Batch 39/64 loss: 0.2753344774246216
Batch 40/64 loss: 0.28442156314849854
Batch 41/64 loss: 0.29089170694351196
Batch 42/64 loss: 0.2806539535522461
Batch 43/64 loss: 0.28864723443984985
Batch 44/64 loss: 0.2833331823348999
Batch 45/64 loss: 0.28652673959732056
Batch 46/64 loss: 0.2796623110771179
Batch 47/64 loss: 0.27657246589660645
Batch 48/64 loss: 0.28687840700149536
Batch 49/64 loss: 0.281730592250824
Batch 50/64 loss: 0.28232771158218384
Batch 51/64 loss: 0.28298038244247437
Batch 52/64 loss: 0.2878161668777466
Batch 53/64 loss: 0.28458696603775024
Batch 54/64 loss: 0.2816625237464905
Batch 55/64 loss: 0.2878772020339966
Batch 56/64 loss: 0.2790490984916687
Batch 57/64 loss: 0.2842142581939697
Batch 58/64 loss: 0.2762051820755005
Batch 59/64 loss: 0.2799128293991089
Batch 60/64 loss: 0.27412670850753784
Batch 61/64 loss: 0.27884727716445923
Batch 62/64 loss: 0.2841808795928955
Batch 63/64 loss: 0.27478253841400146
Batch 64/64 loss: 0.2788800001144409
Epoch 171  Train loss: 0.28087803475997025  Val loss: 0.29632831439119844
Saving best model, epoch: 171
Epoch 172
-------------------------------
Batch 1/64 loss: 0.2769205570220947
Batch 2/64 loss: 0.2740831971168518
Batch 3/64 loss: 0.279504656791687
Batch 4/64 loss: 0.279435932636261
Batch 5/64 loss: 0.27579331398010254
Batch 6/64 loss: 0.2756732106208801
Batch 7/64 loss: 0.2832304835319519
Batch 8/64 loss: 0.28172147274017334
Batch 9/64 loss: 0.2721043825149536
Batch 10/64 loss: 0.2780757546424866
Batch 11/64 loss: 0.277850866317749
Batch 12/64 loss: 0.27730458974838257
Batch 13/64 loss: 0.28512895107269287
Batch 14/64 loss: 0.28235530853271484
Batch 15/64 loss: 0.2873520255088806
Batch 16/64 loss: 0.276311993598938
Batch 17/64 loss: 0.27765703201293945
Batch 18/64 loss: 0.2721633315086365
Batch 19/64 loss: 0.2786867618560791
Batch 20/64 loss: 0.28013062477111816
Batch 21/64 loss: 0.28072118759155273
Batch 22/64 loss: 0.2747344970703125
Batch 23/64 loss: 0.2748340368270874
Batch 24/64 loss: 0.2737067937850952
Batch 25/64 loss: 0.27852433919906616
Batch 26/64 loss: 0.2731708288192749
Batch 27/64 loss: 0.2769263982772827
Batch 28/64 loss: 0.28566133975982666
Batch 29/64 loss: 0.28027546405792236
Batch 30/64 loss: 0.28145885467529297
Batch 31/64 loss: 0.28629493713378906
Batch 32/64 loss: 0.28398215770721436
Batch 33/64 loss: 0.2749074101448059
Batch 34/64 loss: 0.2835056781768799
Batch 35/64 loss: 0.28373563289642334
Batch 36/64 loss: 0.2856249213218689
Batch 37/64 loss: 0.2782072424888611
Batch 38/64 loss: 0.2828577756881714
Batch 39/64 loss: 0.2764890193939209
Batch 40/64 loss: 0.2809023857116699
Batch 41/64 loss: 0.28398430347442627
Batch 42/64 loss: 0.28290390968322754
Batch 43/64 loss: 0.2702488899230957
Batch 44/64 loss: 0.281313955783844
Batch 45/64 loss: 0.2850559949874878
Batch 46/64 loss: 0.2774757146835327
Batch 47/64 loss: 0.2766587734222412
Batch 48/64 loss: 0.2868082523345947
Batch 49/64 loss: 0.28016674518585205
Batch 50/64 loss: 0.29252880811691284
Batch 51/64 loss: 0.2868145704269409
Batch 52/64 loss: 0.2803589105606079
Batch 53/64 loss: 0.2735268473625183
Batch 54/64 loss: 0.2741238474845886
Batch 55/64 loss: 0.27565568685531616
Batch 56/64 loss: 0.28629589080810547
Batch 57/64 loss: 0.28894752264022827
Batch 58/64 loss: 0.28954052925109863
Batch 59/64 loss: 0.2876976728439331
Batch 60/64 loss: 0.2772865295410156
Batch 61/64 loss: 0.2830365300178528
Batch 62/64 loss: 0.28523683547973633
Batch 63/64 loss: 0.2774519920349121
Batch 64/64 loss: 0.27863889932632446
Epoch 172  Train loss: 0.28015848211213656  Val loss: 0.29570313458590164
Saving best model, epoch: 172
Epoch 173
-------------------------------
Batch 1/64 loss: 0.27334797382354736
Batch 2/64 loss: 0.2786487340927124
Batch 3/64 loss: 0.28048038482666016
Batch 4/64 loss: 0.2798886299133301
Batch 5/64 loss: 0.2819279432296753
Batch 6/64 loss: 0.27450263500213623
Batch 7/64 loss: 0.27534204721450806
Batch 8/64 loss: 0.27108871936798096
Batch 9/64 loss: 0.27763456106185913
Batch 10/64 loss: 0.27939504384994507
Batch 11/64 loss: 0.2779427766799927
Batch 12/64 loss: 0.28751927614212036
Batch 13/64 loss: 0.2750743627548218
Batch 14/64 loss: 0.2876514792442322
Batch 15/64 loss: 0.28074073791503906
Batch 16/64 loss: 0.2790263891220093
Batch 17/64 loss: 0.27516108751296997
Batch 18/64 loss: 0.2813163995742798
Batch 19/64 loss: 0.2740257978439331
Batch 20/64 loss: 0.2760508060455322
Batch 21/64 loss: 0.27904212474823
Batch 22/64 loss: 0.27902501821517944
Batch 23/64 loss: 0.284363329410553
Batch 24/64 loss: 0.2814311981201172
Batch 25/64 loss: 0.28434085845947266
Batch 26/64 loss: 0.27527570724487305
Batch 27/64 loss: 0.2830023765563965
Batch 28/64 loss: 0.27413880825042725
Batch 29/64 loss: 0.2766260504722595
Batch 30/64 loss: 0.270743727684021
Batch 31/64 loss: 0.2815368175506592
Batch 32/64 loss: 0.2726948857307434
Batch 33/64 loss: 0.27615272998809814
Batch 34/64 loss: 0.28457510471343994
Batch 35/64 loss: 0.284234881401062
Batch 36/64 loss: 0.28003793954849243
Batch 37/64 loss: 0.28700709342956543
Batch 38/64 loss: 0.2798800468444824
Batch 39/64 loss: 0.2832232117652893
Batch 40/64 loss: 0.27820539474487305
Batch 41/64 loss: 0.2781033515930176
Batch 42/64 loss: 0.2764827013015747
Batch 43/64 loss: 0.27483540773391724
Batch 44/64 loss: 0.279111385345459
Batch 45/64 loss: 0.27733075618743896
Batch 46/64 loss: 0.2872737646102905
Batch 47/64 loss: 0.2816413640975952
Batch 48/64 loss: 0.2752872705459595
Batch 49/64 loss: 0.2859175205230713
Batch 50/64 loss: 0.2777400016784668
Batch 51/64 loss: 0.28250962495803833
Batch 52/64 loss: 0.28663915395736694
Batch 53/64 loss: 0.27246713638305664
Batch 54/64 loss: 0.2865767478942871
Batch 55/64 loss: 0.2831495404243469
Batch 56/64 loss: 0.2767012119293213
Batch 57/64 loss: 0.2817651033401489
Batch 58/64 loss: 0.28440606594085693
Batch 59/64 loss: 0.2849331498146057
Batch 60/64 loss: 0.2806786298751831
Batch 61/64 loss: 0.2786548137664795
Batch 62/64 loss: 0.2896592617034912
Batch 63/64 loss: 0.2747511863708496
Batch 64/64 loss: 0.2747800946235657
Epoch 173  Train loss: 0.27960789507510614  Val loss: 0.29658251529706714
Epoch 174
-------------------------------
Batch 1/64 loss: 0.27929413318634033
Batch 2/64 loss: 0.28016984462738037
Batch 3/64 loss: 0.2786438465118408
Batch 4/64 loss: 0.26555967330932617
Batch 5/64 loss: 0.2830777168273926
Batch 6/64 loss: 0.2771298885345459
Batch 7/64 loss: 0.27707570791244507
Batch 8/64 loss: 0.27013927698135376
Batch 9/64 loss: 0.28374332189559937
Batch 10/64 loss: 0.27534937858581543
Batch 11/64 loss: 0.28137171268463135
Batch 12/64 loss: 0.2775142788887024
Batch 13/64 loss: 0.2743017077445984
Batch 14/64 loss: 0.27605193853378296
Batch 15/64 loss: 0.27816492319107056
Batch 16/64 loss: 0.2821784019470215
Batch 17/64 loss: 0.28129082918167114
Batch 18/64 loss: 0.27824997901916504
Batch 19/64 loss: 0.2860333323478699
Batch 20/64 loss: 0.2742384076118469
Batch 21/64 loss: 0.2655448317527771
Batch 22/64 loss: 0.27966904640197754
Batch 23/64 loss: 0.2833973169326782
Batch 24/64 loss: 0.2800082564353943
Batch 25/64 loss: 0.2772589921951294
Batch 26/64 loss: 0.27525103092193604
Batch 27/64 loss: 0.2829170227050781
Batch 28/64 loss: 0.27464425563812256
Batch 29/64 loss: 0.27177751064300537
Batch 30/64 loss: 0.27408838272094727
Batch 31/64 loss: 0.27567315101623535
Batch 32/64 loss: 0.28074347972869873
Batch 33/64 loss: 0.2782372832298279
Batch 34/64 loss: 0.28539639711380005
Batch 35/64 loss: 0.2710498571395874
Batch 36/64 loss: 0.2798383831977844
Batch 37/64 loss: 0.2781076431274414
Batch 38/64 loss: 0.27734506130218506
Batch 39/64 loss: 0.27868950366973877
Batch 40/64 loss: 0.27032196521759033
Batch 41/64 loss: 0.2864633798599243
Batch 42/64 loss: 0.2727881669998169
Batch 43/64 loss: 0.28186333179473877
Batch 44/64 loss: 0.27238547801971436
Batch 45/64 loss: 0.277146577835083
Batch 46/64 loss: 0.2744787931442261
Batch 47/64 loss: 0.2871589660644531
Batch 48/64 loss: 0.2782794237136841
Batch 49/64 loss: 0.2790560722351074
Batch 50/64 loss: 0.2794089913368225
Batch 51/64 loss: 0.2868877053260803
Batch 52/64 loss: 0.2893495559692383
Batch 53/64 loss: 0.2889195680618286
Batch 54/64 loss: 0.2903962731361389
Batch 55/64 loss: 0.2932138442993164
Batch 56/64 loss: 0.2862424850463867
Batch 57/64 loss: 0.28000712394714355
Batch 58/64 loss: 0.2759881019592285
Batch 59/64 loss: 0.2873547077178955
Batch 60/64 loss: 0.2790466547012329
Batch 61/64 loss: 0.2815653681755066
Batch 62/64 loss: 0.28095293045043945
Batch 63/64 loss: 0.28304624557495117
Batch 64/64 loss: 0.2764514684677124
Epoch 174  Train loss: 0.2791980551738365  Val loss: 0.2955014042018615
Saving best model, epoch: 174
Epoch 175
-------------------------------
Batch 1/64 loss: 0.2799145579338074
Batch 2/64 loss: 0.27675896883010864
Batch 3/64 loss: 0.27589666843414307
Batch 4/64 loss: 0.27154505252838135
Batch 5/64 loss: 0.2864508628845215
Batch 6/64 loss: 0.2742815613746643
Batch 7/64 loss: 0.27066218852996826
Batch 8/64 loss: 0.2751229405403137
Batch 9/64 loss: 0.2713169455528259
Batch 10/64 loss: 0.2727104425430298
Batch 11/64 loss: 0.2794424295425415
Batch 12/64 loss: 0.27938657999038696
Batch 13/64 loss: 0.2786283493041992
Batch 14/64 loss: 0.2759556770324707
Batch 15/64 loss: 0.2786594033241272
Batch 16/64 loss: 0.28576552867889404
Batch 17/64 loss: 0.2727062702178955
Batch 18/64 loss: 0.26873117685317993
Batch 19/64 loss: 0.2915138006210327
Batch 20/64 loss: 0.26700079441070557
Batch 21/64 loss: 0.28976672887802124
Batch 22/64 loss: 0.28495585918426514
Batch 23/64 loss: 0.27586424350738525
Batch 24/64 loss: 0.28552234172821045
Batch 25/64 loss: 0.2776307463645935
Batch 26/64 loss: 0.27585577964782715
Batch 27/64 loss: 0.2830580472946167
Batch 28/64 loss: 0.2905513048171997
Batch 29/64 loss: 0.28472965955734253
Batch 30/64 loss: 0.2761290669441223
Batch 31/64 loss: 0.2837456464767456
Batch 32/64 loss: 0.2778491973876953
Batch 33/64 loss: 0.2853636145591736
Batch 34/64 loss: 0.2846953868865967
Batch 35/64 loss: 0.27900218963623047
Batch 36/64 loss: 0.27636998891830444
Batch 37/64 loss: 0.27492618560791016
Batch 38/64 loss: 0.277921199798584
Batch 39/64 loss: 0.2888883948326111
Batch 40/64 loss: 0.2791306972503662
Batch 41/64 loss: 0.28129422664642334
Batch 42/64 loss: 0.2791646718978882
Batch 43/64 loss: 0.2860974073410034
Batch 44/64 loss: 0.2817178964614868
Batch 45/64 loss: 0.2771108150482178
Batch 46/64 loss: 0.2756197452545166
Batch 47/64 loss: 0.272308349609375
Batch 48/64 loss: 0.2782701253890991
Batch 49/64 loss: 0.2812201976776123
Batch 50/64 loss: 0.28204452991485596
Batch 51/64 loss: 0.285722553730011
Batch 52/64 loss: 0.27469074726104736
Batch 53/64 loss: 0.2815011739730835
Batch 54/64 loss: 0.2768979072570801
Batch 55/64 loss: 0.27721714973449707
Batch 56/64 loss: 0.27860701084136963
Batch 57/64 loss: 0.2773732542991638
Batch 58/64 loss: 0.28787875175476074
Batch 59/64 loss: 0.2905501127243042
Batch 60/64 loss: 0.274310827255249
Batch 61/64 loss: 0.2660123109817505
Batch 62/64 loss: 0.28193384408950806
Batch 63/64 loss: 0.28538572788238525
Batch 64/64 loss: 0.27904003858566284
Epoch 175  Train loss: 0.27931946422539505  Val loss: 0.29571005609846607
Epoch 176
-------------------------------
Batch 1/64 loss: 0.2827945947647095
Batch 2/64 loss: 0.2836180329322815
Batch 3/64 loss: 0.27922433614730835
Batch 4/64 loss: 0.27086341381073
Batch 5/64 loss: 0.275199294090271
Batch 6/64 loss: 0.27902913093566895
Batch 7/64 loss: 0.26847338676452637
Batch 8/64 loss: 0.27358096837997437
Batch 9/64 loss: 0.2788197994232178
Batch 10/64 loss: 0.28173768520355225
Batch 11/64 loss: 0.2754025459289551
Batch 12/64 loss: 0.27831053733825684
Batch 13/64 loss: 0.28554409742355347
Batch 14/64 loss: 0.26722025871276855
Batch 15/64 loss: 0.2792459726333618
Batch 16/64 loss: 0.27431124448776245
Batch 17/64 loss: 0.293057382106781
Batch 18/64 loss: 0.2818027138710022
Batch 19/64 loss: 0.2783719301223755
Batch 20/64 loss: 0.27966785430908203
Batch 21/64 loss: 0.28107190132141113
Batch 22/64 loss: 0.2857920527458191
Batch 23/64 loss: 0.2776048183441162
Batch 24/64 loss: 0.2743208408355713
Batch 25/64 loss: 0.2833535075187683
Batch 26/64 loss: 0.27390384674072266
Batch 27/64 loss: 0.2735482454299927
Batch 28/64 loss: 0.28566062450408936
Batch 29/64 loss: 0.28545260429382324
Batch 30/64 loss: 0.27868491411209106
Batch 31/64 loss: 0.27911484241485596
Batch 32/64 loss: 0.2797132134437561
Batch 33/64 loss: 0.2809017300605774
Batch 34/64 loss: 0.2815004587173462
Batch 35/64 loss: 0.27192407846450806
Batch 36/64 loss: 0.2854970097541809
Batch 37/64 loss: 0.27353620529174805
Batch 38/64 loss: 0.27538830041885376
Batch 39/64 loss: 0.285709023475647
Batch 40/64 loss: 0.2762293815612793
Batch 41/64 loss: 0.2729840874671936
Batch 42/64 loss: 0.2896270751953125
Batch 43/64 loss: 0.27968865633010864
Batch 44/64 loss: 0.2830815315246582
Batch 45/64 loss: 0.2785552740097046
Batch 46/64 loss: 0.28409069776535034
Batch 47/64 loss: 0.270466148853302
Batch 48/64 loss: 0.2916678786277771
Batch 49/64 loss: 0.28816235065460205
Batch 50/64 loss: 0.27553021907806396
Batch 51/64 loss: 0.2754197120666504
Batch 52/64 loss: 0.28454601764678955
Batch 53/64 loss: 0.27358782291412354
Batch 54/64 loss: 0.27424097061157227
Batch 55/64 loss: 0.28126823902130127
Batch 56/64 loss: 0.27759385108947754
Batch 57/64 loss: 0.2723557949066162
Batch 58/64 loss: 0.28260737657546997
Batch 59/64 loss: 0.2792322635650635
Batch 60/64 loss: 0.2734711170196533
Batch 61/64 loss: 0.2808328866958618
Batch 62/64 loss: 0.2772231698036194
Batch 63/64 loss: 0.2761304974555969
Batch 64/64 loss: 0.2789674997329712
Epoch 176  Train loss: 0.27900818890216306  Val loss: 0.29524244721402826
Saving best model, epoch: 176
Epoch 177
-------------------------------
Batch 1/64 loss: 0.27752232551574707
Batch 2/64 loss: 0.27737993001937866
Batch 3/64 loss: 0.2790544033050537
Batch 4/64 loss: 0.27758800983428955
Batch 5/64 loss: 0.28257590532302856
Batch 6/64 loss: 0.27917909622192383
Batch 7/64 loss: 0.27763617038726807
Batch 8/64 loss: 0.2809889316558838
Batch 9/64 loss: 0.2815275192260742
Batch 10/64 loss: 0.2780876159667969
Batch 11/64 loss: 0.2834268808364868
Batch 12/64 loss: 0.2774113416671753
Batch 13/64 loss: 0.2750295400619507
Batch 14/64 loss: 0.28424322605133057
Batch 15/64 loss: 0.2780822515487671
Batch 16/64 loss: 0.27282387018203735
Batch 17/64 loss: 0.28905177116394043
Batch 18/64 loss: 0.27213895320892334
Batch 19/64 loss: 0.2721601128578186
Batch 20/64 loss: 0.28181350231170654
Batch 21/64 loss: 0.2748570442199707
Batch 22/64 loss: 0.2808889150619507
Batch 23/64 loss: 0.2737182378768921
Batch 24/64 loss: 0.2762889266014099
Batch 25/64 loss: 0.26930737495422363
Batch 26/64 loss: 0.274613618850708
Batch 27/64 loss: 0.27659326791763306
Batch 28/64 loss: 0.27740275859832764
Batch 29/64 loss: 0.2743452787399292
Batch 30/64 loss: 0.283602774143219
Batch 31/64 loss: 0.2728675603866577
Batch 32/64 loss: 0.27954256534576416
Batch 33/64 loss: 0.2904292345046997
Batch 34/64 loss: 0.2768581509590149
Batch 35/64 loss: 0.2792309522628784
Batch 36/64 loss: 0.27922630310058594
Batch 37/64 loss: 0.2765130400657654
Batch 38/64 loss: 0.27743232250213623
Batch 39/64 loss: 0.27979397773742676
Batch 40/64 loss: 0.2812221050262451
Batch 41/64 loss: 0.2762104272842407
Batch 42/64 loss: 0.2695871591567993
Batch 43/64 loss: 0.28118348121643066
Batch 44/64 loss: 0.2784174084663391
Batch 45/64 loss: 0.2733924388885498
Batch 46/64 loss: 0.27411001920700073
Batch 47/64 loss: 0.28729933500289917
Batch 48/64 loss: 0.2728201150894165
Batch 49/64 loss: 0.2817358374595642
Batch 50/64 loss: 0.27972686290740967
Batch 51/64 loss: 0.28144747018814087
Batch 52/64 loss: 0.2792515158653259
Batch 53/64 loss: 0.28085434436798096
Batch 54/64 loss: 0.2796192169189453
Batch 55/64 loss: 0.2853187322616577
Batch 56/64 loss: 0.28031492233276367
Batch 57/64 loss: 0.2757294178009033
Batch 58/64 loss: 0.282912015914917
Batch 59/64 loss: 0.2731034755706787
Batch 60/64 loss: 0.27499163150787354
Batch 61/64 loss: 0.2781258225440979
Batch 62/64 loss: 0.2865053415298462
Batch 63/64 loss: 0.26589643955230713
Batch 64/64 loss: 0.27518635988235474
Epoch 177  Train loss: 0.27823370928857843  Val loss: 0.2950294050564061
Saving best model, epoch: 177
Epoch 178
-------------------------------
Batch 1/64 loss: 0.27454906702041626
Batch 2/64 loss: 0.2740492820739746
Batch 3/64 loss: 0.27473050355911255
Batch 4/64 loss: 0.2787686586380005
Batch 5/64 loss: 0.2794584631919861
Batch 6/64 loss: 0.2849404215812683
Batch 7/64 loss: 0.275301992893219
Batch 8/64 loss: 0.2753002643585205
Batch 9/64 loss: 0.28643906116485596
Batch 10/64 loss: 0.2756763696670532
Batch 11/64 loss: 0.2737888693809509
Batch 12/64 loss: 0.28750717639923096
Batch 13/64 loss: 0.2876855134963989
Batch 14/64 loss: 0.28075969219207764
Batch 15/64 loss: 0.27689194679260254
Batch 16/64 loss: 0.26891374588012695
Batch 17/64 loss: 0.2732386589050293
Batch 18/64 loss: 0.2814105749130249
Batch 19/64 loss: 0.2780662178993225
Batch 20/64 loss: 0.29011887311935425
Batch 21/64 loss: 0.28556662797927856
Batch 22/64 loss: 0.2818794250488281
Batch 23/64 loss: 0.28204989433288574
Batch 24/64 loss: 0.28089189529418945
Batch 25/64 loss: 0.28772491216659546
Batch 26/64 loss: 0.2785589098930359
Batch 27/64 loss: 0.2718328833580017
Batch 28/64 loss: 0.27277565002441406
Batch 29/64 loss: 0.2680979371070862
Batch 30/64 loss: 0.2777888774871826
Batch 31/64 loss: 0.28615278005599976
Batch 32/64 loss: 0.27222466468811035
Batch 33/64 loss: 0.281221866607666
Batch 34/64 loss: 0.2800139784812927
Batch 35/64 loss: 0.27880674600601196
Batch 36/64 loss: 0.2716062664985657
Batch 37/64 loss: 0.27914416790008545
Batch 38/64 loss: 0.2820552587509155
Batch 39/64 loss: 0.28242170810699463
Batch 40/64 loss: 0.2724202871322632
Batch 41/64 loss: 0.2786397933959961
Batch 42/64 loss: 0.2802920341491699
Batch 43/64 loss: 0.2743939161300659
Batch 44/64 loss: 0.2834283113479614
Batch 45/64 loss: 0.27355217933654785
Batch 46/64 loss: 0.2695814371109009
Batch 47/64 loss: 0.28277677297592163
Batch 48/64 loss: 0.26767969131469727
Batch 49/64 loss: 0.27816683053970337
Batch 50/64 loss: 0.27047908306121826
Batch 51/64 loss: 0.2727479934692383
Batch 52/64 loss: 0.26827216148376465
Batch 53/64 loss: 0.2684696912765503
Batch 54/64 loss: 0.27745354175567627
Batch 55/64 loss: 0.27447736263275146
Batch 56/64 loss: 0.2794607877731323
Batch 57/64 loss: 0.275634765625
Batch 58/64 loss: 0.2788897156715393
Batch 59/64 loss: 0.28251785039901733
Batch 60/64 loss: 0.2775212526321411
Batch 61/64 loss: 0.27596426010131836
Batch 62/64 loss: 0.28960949182510376
Batch 63/64 loss: 0.27467072010040283
Batch 64/64 loss: 0.2743881940841675
Epoch 178  Train loss: 0.27782432752497055  Val loss: 0.2952244027783371
Epoch 179
-------------------------------
Batch 1/64 loss: 0.279720664024353
Batch 2/64 loss: 0.27053534984588623
Batch 3/64 loss: 0.2791750431060791
Batch 4/64 loss: 0.2760435938835144
Batch 5/64 loss: 0.27391135692596436
Batch 6/64 loss: 0.2758558988571167
Batch 7/64 loss: 0.2738829255104065
Batch 8/64 loss: 0.2839716076850891
Batch 9/64 loss: 0.28108900785446167
Batch 10/64 loss: 0.2788962125778198
Batch 11/64 loss: 0.2768104672431946
Batch 12/64 loss: 0.2766702175140381
Batch 13/64 loss: 0.2865016460418701
Batch 14/64 loss: 0.27239298820495605
Batch 15/64 loss: 0.27408158779144287
Batch 16/64 loss: 0.2789773941040039
Batch 17/64 loss: 0.27545398473739624
Batch 18/64 loss: 0.2856624722480774
Batch 19/64 loss: 0.2838539481163025
Batch 20/64 loss: 0.2816486358642578
Batch 21/64 loss: 0.28756773471832275
Batch 22/64 loss: 0.27858835458755493
Batch 23/64 loss: 0.27745532989501953
Batch 24/64 loss: 0.2833031415939331
Batch 25/64 loss: 0.287484347820282
Batch 26/64 loss: 0.27355247735977173
Batch 27/64 loss: 0.2793228030204773
Batch 28/64 loss: 0.28362154960632324
Batch 29/64 loss: 0.2699636220932007
Batch 30/64 loss: 0.26840680837631226
Batch 31/64 loss: 0.29527896642684937
Batch 32/64 loss: 0.2761037349700928
Batch 33/64 loss: 0.2814164161682129
Batch 34/64 loss: 0.27842050790786743
Batch 35/64 loss: 0.28050845861434937
Batch 36/64 loss: 0.27571749687194824
Batch 37/64 loss: 0.28009718656539917
Batch 38/64 loss: 0.27611851692199707
Batch 39/64 loss: 0.27824270725250244
Batch 40/64 loss: 0.2744067311286926
Batch 41/64 loss: 0.2733227610588074
Batch 42/64 loss: 0.2809288501739502
Batch 43/64 loss: 0.2878316640853882
Batch 44/64 loss: 0.27704858779907227
Batch 45/64 loss: 0.2767859101295471
Batch 46/64 loss: 0.2783399820327759
Batch 47/64 loss: 0.2719201445579529
Batch 48/64 loss: 0.27844250202178955
Batch 49/64 loss: 0.27362608909606934
Batch 50/64 loss: 0.27884364128112793
Batch 51/64 loss: 0.28113675117492676
Batch 52/64 loss: 0.2775188684463501
Batch 53/64 loss: 0.2718340754508972
Batch 54/64 loss: 0.26830583810806274
Batch 55/64 loss: 0.2811319828033447
Batch 56/64 loss: 0.2771339416503906
Batch 57/64 loss: 0.2712555527687073
Batch 58/64 loss: 0.2746449112892151
Batch 59/64 loss: 0.2861514091491699
Batch 60/64 loss: 0.28361809253692627
Batch 61/64 loss: 0.2862356901168823
Batch 62/64 loss: 0.2696303129196167
Batch 63/64 loss: 0.28137707710266113
Batch 64/64 loss: 0.2706814408302307
Epoch 179  Train loss: 0.27828686447704537  Val loss: 0.29709352250771015
Epoch 180
-------------------------------
Batch 1/64 loss: 0.27983367443084717
Batch 2/64 loss: 0.28520679473876953
Batch 3/64 loss: 0.2749252915382385
Batch 4/64 loss: 0.27513283491134644
Batch 5/64 loss: 0.2684212327003479
Batch 6/64 loss: 0.2709556818008423
Batch 7/64 loss: 0.27545130252838135
Batch 8/64 loss: 0.26758503913879395
Batch 9/64 loss: 0.28414487838745117
Batch 10/64 loss: 0.279061496257782
Batch 11/64 loss: 0.27638065814971924
Batch 12/64 loss: 0.2783932685852051
Batch 13/64 loss: 0.2841840982437134
Batch 14/64 loss: 0.27040737867355347
Batch 15/64 loss: 0.27428555488586426
Batch 16/64 loss: 0.2814066410064697
Batch 17/64 loss: 0.2722971439361572
Batch 18/64 loss: 0.28109610080718994
Batch 19/64 loss: 0.2758786082267761
Batch 20/64 loss: 0.2795290946960449
Batch 21/64 loss: 0.2801462411880493
Batch 22/64 loss: 0.2755046486854553
Batch 23/64 loss: 0.2745605707168579
Batch 24/64 loss: 0.27555280923843384
Batch 25/64 loss: 0.2740601897239685
Batch 26/64 loss: 0.2762114405632019
Batch 27/64 loss: 0.2793441414833069
Batch 28/64 loss: 0.2775343656539917
Batch 29/64 loss: 0.273952841758728
Batch 30/64 loss: 0.2693490982055664
Batch 31/64 loss: 0.2847297191619873
Batch 32/64 loss: 0.2818480134010315
Batch 33/64 loss: 0.2716672420501709
Batch 34/64 loss: 0.27470874786376953
Batch 35/64 loss: 0.28980743885040283
Batch 36/64 loss: 0.27673906087875366
Batch 37/64 loss: 0.27930283546447754
Batch 38/64 loss: 0.27965736389160156
Batch 39/64 loss: 0.274135947227478
Batch 40/64 loss: 0.2869721055030823
Batch 41/64 loss: 0.27516210079193115
Batch 42/64 loss: 0.28595030307769775
Batch 43/64 loss: 0.2789948582649231
Batch 44/64 loss: 0.27846622467041016
Batch 45/64 loss: 0.2805076837539673
Batch 46/64 loss: 0.2823181748390198
Batch 47/64 loss: 0.2849313020706177
Batch 48/64 loss: 0.2792637348175049
Batch 49/64 loss: 0.28072357177734375
Batch 50/64 loss: 0.2831340432167053
Batch 51/64 loss: 0.27625572681427
Batch 52/64 loss: 0.2728426456451416
Batch 53/64 loss: 0.27310752868652344
Batch 54/64 loss: 0.2785983681678772
Batch 55/64 loss: 0.2716118097305298
Batch 56/64 loss: 0.2754618525505066
Batch 57/64 loss: 0.27857506275177
Batch 58/64 loss: 0.2723231911659241
Batch 59/64 loss: 0.2828308343887329
Batch 60/64 loss: 0.27542924880981445
Batch 61/64 loss: 0.28284913301467896
Batch 62/64 loss: 0.2790209650993347
Batch 63/64 loss: 0.28172993659973145
Batch 64/64 loss: 0.28133779764175415
Epoch 180  Train loss: 0.2778267175543542  Val loss: 0.2954068976579253
Epoch 181
-------------------------------
Batch 1/64 loss: 0.2719653844833374
Batch 2/64 loss: 0.279987096786499
Batch 3/64 loss: 0.27514731884002686
Batch 4/64 loss: 0.27674710750579834
Batch 5/64 loss: 0.2757314443588257
Batch 6/64 loss: 0.2750898599624634
Batch 7/64 loss: 0.27553659677505493
Batch 8/64 loss: 0.27407991886138916
Batch 9/64 loss: 0.2822449803352356
Batch 10/64 loss: 0.2711000442504883
Batch 11/64 loss: 0.2791444659233093
Batch 12/64 loss: 0.2792394161224365
Batch 13/64 loss: 0.272957980632782
Batch 14/64 loss: 0.2657281756401062
Batch 15/64 loss: 0.2799146771430969
Batch 16/64 loss: 0.2881436347961426
Batch 17/64 loss: 0.27834486961364746
Batch 18/64 loss: 0.2758675217628479
Batch 19/64 loss: 0.28595125675201416
Batch 20/64 loss: 0.2738776206970215
Batch 21/64 loss: 0.2732975482940674
Batch 22/64 loss: 0.28113043308258057
Batch 23/64 loss: 0.2722862958908081
Batch 24/64 loss: 0.2777635455131531
Batch 25/64 loss: 0.28334224224090576
Batch 26/64 loss: 0.27327609062194824
Batch 27/64 loss: 0.2810699939727783
Batch 28/64 loss: 0.27916157245635986
Batch 29/64 loss: 0.2878248691558838
Batch 30/64 loss: 0.2852852940559387
Batch 31/64 loss: 0.2765198349952698
Batch 32/64 loss: 0.2718706727027893
Batch 33/64 loss: 0.2715801000595093
Batch 34/64 loss: 0.26957839727401733
Batch 35/64 loss: 0.27613508701324463
Batch 36/64 loss: 0.27523767948150635
Batch 37/64 loss: 0.2842746376991272
Batch 38/64 loss: 0.2699021100997925
Batch 39/64 loss: 0.2726738452911377
Batch 40/64 loss: 0.279904305934906
Batch 41/64 loss: 0.28105640411376953
Batch 42/64 loss: 0.2848767638206482
Batch 43/64 loss: 0.26841700077056885
Batch 44/64 loss: 0.2737971544265747
Batch 45/64 loss: 0.28299957513809204
Batch 46/64 loss: 0.2762681841850281
Batch 47/64 loss: 0.2807828187942505
Batch 48/64 loss: 0.2771366834640503
Batch 49/64 loss: 0.27430450916290283
Batch 50/64 loss: 0.2907889485359192
Batch 51/64 loss: 0.2732034921646118
Batch 52/64 loss: 0.2717354893684387
Batch 53/64 loss: 0.2893751859664917
Batch 54/64 loss: 0.2805786728858948
Batch 55/64 loss: 0.27398449182510376
Batch 56/64 loss: 0.27230972051620483
Batch 57/64 loss: 0.28147780895233154
Batch 58/64 loss: 0.2850978374481201
Batch 59/64 loss: 0.2791489362716675
Batch 60/64 loss: 0.28172415494918823
Batch 61/64 loss: 0.2774749994277954
Batch 62/64 loss: 0.27370309829711914
Batch 63/64 loss: 0.26988327503204346
Batch 64/64 loss: 0.27412116527557373
Epoch 181  Train loss: 0.27740596088708613  Val loss: 0.2947285419067566
Saving best model, epoch: 181
Epoch 182
-------------------------------
Batch 1/64 loss: 0.2770437002182007
Batch 2/64 loss: 0.2810594439506531
Batch 3/64 loss: 0.2725449800491333
Batch 4/64 loss: 0.27180182933807373
Batch 5/64 loss: 0.2606682777404785
Batch 6/64 loss: 0.2719307541847229
Batch 7/64 loss: 0.273618221282959
Batch 8/64 loss: 0.2718442678451538
Batch 9/64 loss: 0.27704542875289917
Batch 10/64 loss: 0.268301784992218
Batch 11/64 loss: 0.27560585737228394
Batch 12/64 loss: 0.2799335718154907
Batch 13/64 loss: 0.2767346501350403
Batch 14/64 loss: 0.27626651525497437
Batch 15/64 loss: 0.27933478355407715
Batch 16/64 loss: 0.2778438329696655
Batch 17/64 loss: 0.28285592794418335
Batch 18/64 loss: 0.2838757634162903
Batch 19/64 loss: 0.2746332883834839
Batch 20/64 loss: 0.2778637409210205
Batch 21/64 loss: 0.27919161319732666
Batch 22/64 loss: 0.2794492244720459
Batch 23/64 loss: 0.273571252822876
Batch 24/64 loss: 0.27386462688446045
Batch 25/64 loss: 0.2747673988342285
Batch 26/64 loss: 0.2743310332298279
Batch 27/64 loss: 0.27656829357147217
Batch 28/64 loss: 0.2692805528640747
Batch 29/64 loss: 0.28983598947525024
Batch 30/64 loss: 0.2732946276664734
Batch 31/64 loss: 0.26832711696624756
Batch 32/64 loss: 0.2744269371032715
Batch 33/64 loss: 0.2791561484336853
Batch 34/64 loss: 0.27328360080718994
Batch 35/64 loss: 0.2693856954574585
Batch 36/64 loss: 0.2740700840950012
Batch 37/64 loss: 0.28513526916503906
Batch 38/64 loss: 0.280856728553772
Batch 39/64 loss: 0.2852092981338501
Batch 40/64 loss: 0.2750242352485657
Batch 41/64 loss: 0.2784498929977417
Batch 42/64 loss: 0.2818976640701294
Batch 43/64 loss: 0.2705153822898865
Batch 44/64 loss: 0.28160691261291504
Batch 45/64 loss: 0.2819401025772095
Batch 46/64 loss: 0.272327184677124
Batch 47/64 loss: 0.28353774547576904
Batch 48/64 loss: 0.2806965112686157
Batch 49/64 loss: 0.2749595046043396
Batch 50/64 loss: 0.27144861221313477
Batch 51/64 loss: 0.27311116456985474
Batch 52/64 loss: 0.2719947099685669
Batch 53/64 loss: 0.2728825807571411
Batch 54/64 loss: 0.27185124158859253
Batch 55/64 loss: 0.2800321578979492
Batch 56/64 loss: 0.2808966636657715
Batch 57/64 loss: 0.2720794677734375
Batch 58/64 loss: 0.27620160579681396
Batch 59/64 loss: 0.2832862138748169
Batch 60/64 loss: 0.2721424102783203
Batch 61/64 loss: 0.2818846106529236
Batch 62/64 loss: 0.27797722816467285
Batch 63/64 loss: 0.28394436836242676
Batch 64/64 loss: 0.2769206166267395
Epoch 182  Train loss: 0.2764422077758639  Val loss: 0.29327384077806246
Saving best model, epoch: 182
Epoch 183
-------------------------------
Batch 1/64 loss: 0.2804824113845825
Batch 2/64 loss: 0.27672821283340454
Batch 3/64 loss: 0.2738153338432312
Batch 4/64 loss: 0.2679980993270874
Batch 5/64 loss: 0.26859724521636963
Batch 6/64 loss: 0.2758336067199707
Batch 7/64 loss: 0.28219854831695557
Batch 8/64 loss: 0.2730966806411743
Batch 9/64 loss: 0.2788769006729126
Batch 10/64 loss: 0.2778249979019165
Batch 11/64 loss: 0.2738553285598755
Batch 12/64 loss: 0.2733984589576721
Batch 13/64 loss: 0.270526647567749
Batch 14/64 loss: 0.266853928565979
Batch 15/64 loss: 0.2743638753890991
Batch 16/64 loss: 0.2708120346069336
Batch 17/64 loss: 0.27998483180999756
Batch 18/64 loss: 0.27370667457580566
Batch 19/64 loss: 0.27326953411102295
Batch 20/64 loss: 0.277016282081604
Batch 21/64 loss: 0.28402650356292725
Batch 22/64 loss: 0.2747654318809509
Batch 23/64 loss: 0.2688775062561035
Batch 24/64 loss: 0.2808260917663574
Batch 25/64 loss: 0.2757986783981323
Batch 26/64 loss: 0.26951074600219727
Batch 27/64 loss: 0.282696008682251
Batch 28/64 loss: 0.28253912925720215
Batch 29/64 loss: 0.27652430534362793
Batch 30/64 loss: 0.2775290012359619
Batch 31/64 loss: 0.27776896953582764
Batch 32/64 loss: 0.2710907459259033
Batch 33/64 loss: 0.27987152338027954
Batch 34/64 loss: 0.2768172025680542
Batch 35/64 loss: 0.27091825008392334
Batch 36/64 loss: 0.2733585238456726
Batch 37/64 loss: 0.27666985988616943
Batch 38/64 loss: 0.27845728397369385
Batch 39/64 loss: 0.2737579941749573
Batch 40/64 loss: 0.27079904079437256
Batch 41/64 loss: 0.2759588360786438
Batch 42/64 loss: 0.27294814586639404
Batch 43/64 loss: 0.2717900276184082
Batch 44/64 loss: 0.2731666564941406
Batch 45/64 loss: 0.28320634365081787
Batch 46/64 loss: 0.2714926600456238
Batch 47/64 loss: 0.2749136686325073
Batch 48/64 loss: 0.28228759765625
Batch 49/64 loss: 0.26540762186050415
Batch 50/64 loss: 0.2787938714027405
Batch 51/64 loss: 0.27387285232543945
Batch 52/64 loss: 0.26725661754608154
Batch 53/64 loss: 0.2807145118713379
Batch 54/64 loss: 0.2813609838485718
Batch 55/64 loss: 0.27452051639556885
Batch 56/64 loss: 0.280997633934021
Batch 57/64 loss: 0.27708327770233154
Batch 58/64 loss: 0.27761924266815186
Batch 59/64 loss: 0.2834526300430298
Batch 60/64 loss: 0.2718214988708496
Batch 61/64 loss: 0.2695953845977783
Batch 62/64 loss: 0.28396522998809814
Batch 63/64 loss: 0.2773473262786865
Batch 64/64 loss: 0.2704286575317383
Epoch 183  Train loss: 0.2755174440496108  Val loss: 0.2934428265004633
Epoch 184
-------------------------------
Batch 1/64 loss: 0.2671232223510742
Batch 2/64 loss: 0.273317813873291
Batch 3/64 loss: 0.2675896883010864
Batch 4/64 loss: 0.28153860569000244
Batch 5/64 loss: 0.27955853939056396
Batch 6/64 loss: 0.27036142349243164
Batch 7/64 loss: 0.27403146028518677
Batch 8/64 loss: 0.27623021602630615
Batch 9/64 loss: 0.28049981594085693
Batch 10/64 loss: 0.2611933946609497
Batch 11/64 loss: 0.27145713567733765
Batch 12/64 loss: 0.2806215286254883
Batch 13/64 loss: 0.2799936532974243
Batch 14/64 loss: 0.2803608775138855
Batch 15/64 loss: 0.28818124532699585
Batch 16/64 loss: 0.2778043746948242
Batch 17/64 loss: 0.2810027599334717
Batch 18/64 loss: 0.28132307529449463
Batch 19/64 loss: 0.2730576992034912
Batch 20/64 loss: 0.26724159717559814
Batch 21/64 loss: 0.27229923009872437
Batch 22/64 loss: 0.27694380283355713
Batch 23/64 loss: 0.26838964223861694
Batch 24/64 loss: 0.2824892997741699
Batch 25/64 loss: 0.2819065451622009
Batch 26/64 loss: 0.26632440090179443
Batch 27/64 loss: 0.26579540967941284
Batch 28/64 loss: 0.28047478199005127
Batch 29/64 loss: 0.2874568700790405
Batch 30/64 loss: 0.2792855501174927
Batch 31/64 loss: 0.28594517707824707
Batch 32/64 loss: 0.2772560119628906
Batch 33/64 loss: 0.2747997045516968
Batch 34/64 loss: 0.2696113586425781
Batch 35/64 loss: 0.2791694402694702
Batch 36/64 loss: 0.2737235426902771
Batch 37/64 loss: 0.26871293783187866
Batch 38/64 loss: 0.27849459648132324
Batch 39/64 loss: 0.2772125005722046
Batch 40/64 loss: 0.28274405002593994
Batch 41/64 loss: 0.27964890003204346
Batch 42/64 loss: 0.27158498764038086
Batch 43/64 loss: 0.28520745038986206
Batch 44/64 loss: 0.2779357433319092
Batch 45/64 loss: 0.27552419900894165
Batch 46/64 loss: 0.2695547342300415
Batch 47/64 loss: 0.2741045355796814
Batch 48/64 loss: 0.2784605622291565
Batch 49/64 loss: 0.27574682235717773
Batch 50/64 loss: 0.266787052154541
Batch 51/64 loss: 0.2674604654312134
Batch 52/64 loss: 0.2841948866844177
Batch 53/64 loss: 0.2713848948478699
Batch 54/64 loss: 0.2769585847854614
Batch 55/64 loss: 0.2819749116897583
Batch 56/64 loss: 0.27037525177001953
Batch 57/64 loss: 0.2782176733016968
Batch 58/64 loss: 0.27685976028442383
Batch 59/64 loss: 0.27959144115448
Batch 60/64 loss: 0.277507483959198
Batch 61/64 loss: 0.2774921655654907
Batch 62/64 loss: 0.2731170654296875
Batch 63/64 loss: 0.27770233154296875
Batch 64/64 loss: 0.2681248188018799
Epoch 184  Train loss: 0.2759217019174613  Val loss: 0.29547820877783076
Epoch 185
-------------------------------
Batch 1/64 loss: 0.28430652618408203
Batch 2/64 loss: 0.2815614342689514
Batch 3/64 loss: 0.2699927091598511
Batch 4/64 loss: 0.276037335395813
Batch 5/64 loss: 0.2825245261192322
Batch 6/64 loss: 0.2692737579345703
Batch 7/64 loss: 0.2777639627456665
Batch 8/64 loss: 0.2712898254394531
Batch 9/64 loss: 0.2747650742530823
Batch 10/64 loss: 0.27681517601013184
Batch 11/64 loss: 0.27785271406173706
Batch 12/64 loss: 0.2681785821914673
Batch 13/64 loss: 0.2693677544593811
Batch 14/64 loss: 0.26352763175964355
Batch 15/64 loss: 0.2795102000236511
Batch 16/64 loss: 0.27564918994903564
Batch 17/64 loss: 0.27488887310028076
Batch 18/64 loss: 0.2895739674568176
Batch 19/64 loss: 0.28444355726242065
Batch 20/64 loss: 0.27904874086380005
Batch 21/64 loss: 0.27543139457702637
Batch 22/64 loss: 0.2745673656463623
Batch 23/64 loss: 0.28122448921203613
Batch 24/64 loss: 0.27252864837646484
Batch 25/64 loss: 0.27316784858703613
Batch 26/64 loss: 0.27791041135787964
Batch 27/64 loss: 0.27933216094970703
Batch 28/64 loss: 0.2817562222480774
Batch 29/64 loss: 0.2772980332374573
Batch 30/64 loss: 0.2619706392288208
Batch 31/64 loss: 0.28028082847595215
Batch 32/64 loss: 0.2696002721786499
Batch 33/64 loss: 0.2800965905189514
Batch 34/64 loss: 0.2686176300048828
Batch 35/64 loss: 0.27548062801361084
Batch 36/64 loss: 0.27130329608917236
Batch 37/64 loss: 0.283921480178833
Batch 38/64 loss: 0.27235639095306396
Batch 39/64 loss: 0.2600873112678528
Batch 40/64 loss: 0.2704033851623535
Batch 41/64 loss: 0.28534823656082153
Batch 42/64 loss: 0.2778747081756592
Batch 43/64 loss: 0.2865888476371765
Batch 44/64 loss: 0.27555716037750244
Batch 45/64 loss: 0.2698960304260254
Batch 46/64 loss: 0.27374911308288574
Batch 47/64 loss: 0.269878625869751
Batch 48/64 loss: 0.2831394672393799
Batch 49/64 loss: 0.27401280403137207
Batch 50/64 loss: 0.2773536443710327
Batch 51/64 loss: 0.27902281284332275
Batch 52/64 loss: 0.27346205711364746
Batch 53/64 loss: 0.2662043571472168
Batch 54/64 loss: 0.26983046531677246
Batch 55/64 loss: 0.2704428434371948
Batch 56/64 loss: 0.2699301242828369
Batch 57/64 loss: 0.28268420696258545
Batch 58/64 loss: 0.27723777294158936
Batch 59/64 loss: 0.27504390478134155
Batch 60/64 loss: 0.27878105640411377
Batch 61/64 loss: 0.2728157043457031
Batch 62/64 loss: 0.28323113918304443
Batch 63/64 loss: 0.2755565643310547
Batch 64/64 loss: 0.26886868476867676
Epoch 185  Train loss: 0.27549803490732233  Val loss: 0.29455590371004087
Epoch 186
-------------------------------
Batch 1/64 loss: 0.28096336126327515
Batch 2/64 loss: 0.27805590629577637
Batch 3/64 loss: 0.2725980877876282
Batch 4/64 loss: 0.27459442615509033
Batch 5/64 loss: 0.27908217906951904
Batch 6/64 loss: 0.2739531993865967
Batch 7/64 loss: 0.27763551473617554
Batch 8/64 loss: 0.26696276664733887
Batch 9/64 loss: 0.2730923891067505
Batch 10/64 loss: 0.27418434619903564
Batch 11/64 loss: 0.27074337005615234
Batch 12/64 loss: 0.27247631549835205
Batch 13/64 loss: 0.26630401611328125
Batch 14/64 loss: 0.2711940407752991
Batch 15/64 loss: 0.2684040069580078
Batch 16/64 loss: 0.278403639793396
Batch 17/64 loss: 0.28428536653518677
Batch 18/64 loss: 0.27542251348495483
Batch 19/64 loss: 0.2791649103164673
Batch 20/64 loss: 0.27706485986709595
Batch 21/64 loss: 0.27081549167633057
Batch 22/64 loss: 0.2717694044113159
Batch 23/64 loss: 0.2765474319458008
Batch 24/64 loss: 0.27083879709243774
Batch 25/64 loss: 0.28686678409576416
Batch 26/64 loss: 0.2700232267379761
Batch 27/64 loss: 0.2634057402610779
Batch 28/64 loss: 0.27921581268310547
Batch 29/64 loss: 0.27984678745269775
Batch 30/64 loss: 0.2802658677101135
Batch 31/64 loss: 0.267029345035553
Batch 32/64 loss: 0.26878130435943604
Batch 33/64 loss: 0.2784155011177063
Batch 34/64 loss: 0.2785743474960327
Batch 35/64 loss: 0.27038896083831787
Batch 36/64 loss: 0.2855719327926636
Batch 37/64 loss: 0.27269935607910156
Batch 38/64 loss: 0.27114176750183105
Batch 39/64 loss: 0.2771046757698059
Batch 40/64 loss: 0.2796154022216797
Batch 41/64 loss: 0.2747459411621094
Batch 42/64 loss: 0.27239882946014404
Batch 43/64 loss: 0.2707209587097168
Batch 44/64 loss: 0.2699480652809143
Batch 45/64 loss: 0.27202874422073364
Batch 46/64 loss: 0.27555733919143677
Batch 47/64 loss: 0.2805171012878418
Batch 48/64 loss: 0.28735339641571045
Batch 49/64 loss: 0.27333688735961914
Batch 50/64 loss: 0.27661192417144775
Batch 51/64 loss: 0.2717883586883545
Batch 52/64 loss: 0.27619481086730957
Batch 53/64 loss: 0.2753709554672241
Batch 54/64 loss: 0.2751680016517639
Batch 55/64 loss: 0.2703624963760376
Batch 56/64 loss: 0.27821552753448486
Batch 57/64 loss: 0.28151965141296387
Batch 58/64 loss: 0.2829113006591797
Batch 59/64 loss: 0.288349449634552
Batch 60/64 loss: 0.26979053020477295
Batch 61/64 loss: 0.2690533399581909
Batch 62/64 loss: 0.282090425491333
Batch 63/64 loss: 0.27356529235839844
Batch 64/64 loss: 0.2742593288421631
Epoch 186  Train loss: 0.27524387415717627  Val loss: 0.29440531042433277
Epoch 187
-------------------------------
Batch 1/64 loss: 0.2711528539657593
Batch 2/64 loss: 0.27304166555404663
Batch 3/64 loss: 0.2724475860595703
Batch 4/64 loss: 0.2708057761192322
Batch 5/64 loss: 0.2689089775085449
Batch 6/64 loss: 0.2910640239715576
Batch 7/64 loss: 0.27788323163986206
Batch 8/64 loss: 0.2699774503707886
Batch 9/64 loss: 0.27149897813796997
Batch 10/64 loss: 0.27035951614379883
Batch 11/64 loss: 0.27772057056427
Batch 12/64 loss: 0.2789846658706665
Batch 13/64 loss: 0.2714059352874756
Batch 14/64 loss: 0.270807147026062
Batch 15/64 loss: 0.2705957293510437
Batch 16/64 loss: 0.27291399240493774
Batch 17/64 loss: 0.2715193033218384
Batch 18/64 loss: 0.2759860157966614
Batch 19/64 loss: 0.2718479633331299
Batch 20/64 loss: 0.2808605432510376
Batch 21/64 loss: 0.27856969833374023
Batch 22/64 loss: 0.2760707139968872
Batch 23/64 loss: 0.2815980911254883
Batch 24/64 loss: 0.2759649157524109
Batch 25/64 loss: 0.2687543034553528
Batch 26/64 loss: 0.28164196014404297
Batch 27/64 loss: 0.27114081382751465
Batch 28/64 loss: 0.2782997488975525
Batch 29/64 loss: 0.2644294500350952
Batch 30/64 loss: 0.2706714868545532
Batch 31/64 loss: 0.2766457796096802
Batch 32/64 loss: 0.2682223320007324
Batch 33/64 loss: 0.2805863618850708
Batch 34/64 loss: 0.2706000804901123
Batch 35/64 loss: 0.2809852361679077
Batch 36/64 loss: 0.27821940183639526
Batch 37/64 loss: 0.27361559867858887
Batch 38/64 loss: 0.27877485752105713
Batch 39/64 loss: 0.2688467502593994
Batch 40/64 loss: 0.28111010789871216
Batch 41/64 loss: 0.273919939994812
Batch 42/64 loss: 0.2695438861846924
Batch 43/64 loss: 0.2762185335159302
Batch 44/64 loss: 0.27763599157333374
Batch 45/64 loss: 0.2796964645385742
Batch 46/64 loss: 0.27174174785614014
Batch 47/64 loss: 0.27078086137771606
Batch 48/64 loss: 0.2682726979255676
Batch 49/64 loss: 0.2678852081298828
Batch 50/64 loss: 0.2738068699836731
Batch 51/64 loss: 0.27491307258605957
Batch 52/64 loss: 0.2732617259025574
Batch 53/64 loss: 0.2690761089324951
Batch 54/64 loss: 0.2808140516281128
Batch 55/64 loss: 0.27308034896850586
Batch 56/64 loss: 0.2804100513458252
Batch 57/64 loss: 0.2741520404815674
Batch 58/64 loss: 0.2768646478652954
Batch 59/64 loss: 0.27333688735961914
Batch 60/64 loss: 0.2718205451965332
Batch 61/64 loss: 0.26806652545928955
Batch 62/64 loss: 0.2749307155609131
Batch 63/64 loss: 0.2781527042388916
Batch 64/64 loss: 0.27724963426589966
Epoch 187  Train loss: 0.27436625045888563  Val loss: 0.294950105889966
Epoch 188
-------------------------------
Batch 1/64 loss: 0.272804856300354
Batch 2/64 loss: 0.2737555503845215
Batch 3/64 loss: 0.27304041385650635
Batch 4/64 loss: 0.2726061940193176
Batch 5/64 loss: 0.2661534547805786
Batch 6/64 loss: 0.27822279930114746
Batch 7/64 loss: 0.2729470729827881
Batch 8/64 loss: 0.27209722995758057
Batch 9/64 loss: 0.2711806893348694
Batch 10/64 loss: 0.27916038036346436
Batch 11/64 loss: 0.2736746072769165
Batch 12/64 loss: 0.26851409673690796
Batch 13/64 loss: 0.27297526597976685
Batch 14/64 loss: 0.2761880159378052
Batch 15/64 loss: 0.2830313444137573
Batch 16/64 loss: 0.26692676544189453
Batch 17/64 loss: 0.28223663568496704
Batch 18/64 loss: 0.2741004228591919
Batch 19/64 loss: 0.27852392196655273
Batch 20/64 loss: 0.2679067850112915
Batch 21/64 loss: 0.27040791511535645
Batch 22/64 loss: 0.27254998683929443
Batch 23/64 loss: 0.2792332172393799
Batch 24/64 loss: 0.27901726961135864
Batch 25/64 loss: 0.27649515867233276
Batch 26/64 loss: 0.28118306398391724
Batch 27/64 loss: 0.2787057161331177
Batch 28/64 loss: 0.27017366886138916
Batch 29/64 loss: 0.27619391679763794
Batch 30/64 loss: 0.27552640438079834
Batch 31/64 loss: 0.27266740798950195
Batch 32/64 loss: 0.28428322076797485
Batch 33/64 loss: 0.2680908441543579
Batch 34/64 loss: 0.27746790647506714
Batch 35/64 loss: 0.276705265045166
Batch 36/64 loss: 0.2852531671524048
Batch 37/64 loss: 0.2804429531097412
Batch 38/64 loss: 0.2719426155090332
Batch 39/64 loss: 0.27606576681137085
Batch 40/64 loss: 0.2669893503189087
Batch 41/64 loss: 0.27049028873443604
Batch 42/64 loss: 0.2776808738708496
Batch 43/64 loss: 0.2765709161758423
Batch 44/64 loss: 0.27917391061782837
Batch 45/64 loss: 0.27846193313598633
Batch 46/64 loss: 0.2701849937438965
Batch 47/64 loss: 0.2729836702346802
Batch 48/64 loss: 0.2775413990020752
Batch 49/64 loss: 0.2656262516975403
Batch 50/64 loss: 0.27803587913513184
Batch 51/64 loss: 0.2784609794616699
Batch 52/64 loss: 0.27505922317504883
Batch 53/64 loss: 0.2741636037826538
Batch 54/64 loss: 0.2754695415496826
Batch 55/64 loss: 0.27796506881713867
Batch 56/64 loss: 0.26703017950057983
Batch 57/64 loss: 0.278331995010376
Batch 58/64 loss: 0.2778908610343933
Batch 59/64 loss: 0.27322930097579956
Batch 60/64 loss: 0.27539074420928955
Batch 61/64 loss: 0.27158063650131226
Batch 62/64 loss: 0.27589040994644165
Batch 63/64 loss: 0.27667152881622314
Batch 64/64 loss: 0.27738404273986816
Epoch 188  Train loss: 0.2749390359018363  Val loss: 0.29275264998072204
Saving best model, epoch: 188
Epoch 189
-------------------------------
Batch 1/64 loss: 0.27889299392700195
Batch 2/64 loss: 0.2765665650367737
Batch 3/64 loss: 0.27538836002349854
Batch 4/64 loss: 0.26408565044403076
Batch 5/64 loss: 0.27160829305648804
Batch 6/64 loss: 0.2736130952835083
Batch 7/64 loss: 0.27574020624160767
Batch 8/64 loss: 0.27397942543029785
Batch 9/64 loss: 0.27537810802459717
Batch 10/64 loss: 0.2882702350616455
Batch 11/64 loss: 0.26673781871795654
Batch 12/64 loss: 0.27218276262283325
Batch 13/64 loss: 0.2682194709777832
Batch 14/64 loss: 0.27533113956451416
Batch 15/64 loss: 0.27812355756759644
Batch 16/64 loss: 0.2689553499221802
Batch 17/64 loss: 0.2750016450881958
Batch 18/64 loss: 0.27236586809158325
Batch 19/64 loss: 0.2731153964996338
Batch 20/64 loss: 0.27493393421173096
Batch 21/64 loss: 0.26648402214050293
Batch 22/64 loss: 0.27159690856933594
Batch 23/64 loss: 0.27485084533691406
Batch 24/64 loss: 0.2852994203567505
Batch 25/64 loss: 0.27782630920410156
Batch 26/64 loss: 0.2705312967300415
Batch 27/64 loss: 0.2747023105621338
Batch 28/64 loss: 0.2727189064025879
Batch 29/64 loss: 0.28351855278015137
Batch 30/64 loss: 0.27209389209747314
Batch 31/64 loss: 0.28785616159439087
Batch 32/64 loss: 0.27858108282089233
Batch 33/64 loss: 0.2828149199485779
Batch 34/64 loss: 0.2722703218460083
Batch 35/64 loss: 0.2821716070175171
Batch 36/64 loss: 0.27368277311325073
Batch 37/64 loss: 0.28460192680358887
Batch 38/64 loss: 0.26146769523620605
Batch 39/64 loss: 0.27631646394729614
Batch 40/64 loss: 0.2770853042602539
Batch 41/64 loss: 0.2807037830352783
Batch 42/64 loss: 0.2741430997848511
Batch 43/64 loss: 0.2710913419723511
Batch 44/64 loss: 0.27358734607696533
Batch 45/64 loss: 0.27863264083862305
Batch 46/64 loss: 0.2725118398666382
Batch 47/64 loss: 0.27885788679122925
Batch 48/64 loss: 0.26828277111053467
Batch 49/64 loss: 0.2851625680923462
Batch 50/64 loss: 0.2658827304840088
Batch 51/64 loss: 0.2870328426361084
Batch 52/64 loss: 0.2701904773712158
Batch 53/64 loss: 0.2692875266075134
Batch 54/64 loss: 0.27789199352264404
Batch 55/64 loss: 0.27030301094055176
Batch 56/64 loss: 0.2686692476272583
Batch 57/64 loss: 0.2704053521156311
Batch 58/64 loss: 0.27190524339675903
Batch 59/64 loss: 0.2889893651008606
Batch 60/64 loss: 0.264212965965271
Batch 61/64 loss: 0.28301525115966797
Batch 62/64 loss: 0.2683650255203247
Batch 63/64 loss: 0.26699721813201904
Batch 64/64 loss: 0.2729318141937256
Epoch 189  Train loss: 0.2747573487898883  Val loss: 0.29367000130853294
Epoch 190
-------------------------------
Batch 1/64 loss: 0.26656806468963623
Batch 2/64 loss: 0.2689405083656311
Batch 3/64 loss: 0.27581286430358887
Batch 4/64 loss: 0.2690289616584778
Batch 5/64 loss: 0.27795708179473877
Batch 6/64 loss: 0.27918457984924316
Batch 7/64 loss: 0.26427149772644043
Batch 8/64 loss: 0.26973652839660645
Batch 9/64 loss: 0.2823277711868286
Batch 10/64 loss: 0.27514147758483887
Batch 11/64 loss: 0.2710537910461426
Batch 12/64 loss: 0.2704519033432007
Batch 13/64 loss: 0.2684119939804077
Batch 14/64 loss: 0.28371328115463257
Batch 15/64 loss: 0.2688330411911011
Batch 16/64 loss: 0.2723653316497803
Batch 17/64 loss: 0.2682456970214844
Batch 18/64 loss: 0.2688414454460144
Batch 19/64 loss: 0.27719640731811523
Batch 20/64 loss: 0.2718822956085205
Batch 21/64 loss: 0.2670183777809143
Batch 22/64 loss: 0.2711980938911438
Batch 23/64 loss: 0.26683783531188965
Batch 24/64 loss: 0.27285611629486084
Batch 25/64 loss: 0.26530516147613525
Batch 26/64 loss: 0.27729612588882446
Batch 27/64 loss: 0.26893800497055054
Batch 28/64 loss: 0.2829899787902832
Batch 29/64 loss: 0.27397632598876953
Batch 30/64 loss: 0.27680039405822754
Batch 31/64 loss: 0.27573251724243164
Batch 32/64 loss: 0.2683490514755249
Batch 33/64 loss: 0.2759853005409241
Batch 34/64 loss: 0.2649710178375244
Batch 35/64 loss: 0.27532172203063965
Batch 36/64 loss: 0.27967798709869385
Batch 37/64 loss: 0.27834784984588623
Batch 38/64 loss: 0.27135276794433594
Batch 39/64 loss: 0.2755851745605469
Batch 40/64 loss: 0.2778005599975586
Batch 41/64 loss: 0.2627357244491577
Batch 42/64 loss: 0.2813462018966675
Batch 43/64 loss: 0.27253472805023193
Batch 44/64 loss: 0.273473858833313
Batch 45/64 loss: 0.27963078022003174
Batch 46/64 loss: 0.2756139039993286
Batch 47/64 loss: 0.2797555923461914
Batch 48/64 loss: 0.27797240018844604
Batch 49/64 loss: 0.2769061326980591
Batch 50/64 loss: 0.2799030542373657
Batch 51/64 loss: 0.27426379919052124
Batch 52/64 loss: 0.28303229808807373
Batch 53/64 loss: 0.27319061756134033
Batch 54/64 loss: 0.2786684036254883
Batch 55/64 loss: 0.2797967195510864
Batch 56/64 loss: 0.28206968307495117
Batch 57/64 loss: 0.27324461936950684
Batch 58/64 loss: 0.2699418067932129
Batch 59/64 loss: 0.2729107141494751
Batch 60/64 loss: 0.28522419929504395
Batch 61/64 loss: 0.2749098539352417
Batch 62/64 loss: 0.27510374784469604
Batch 63/64 loss: 0.26344525814056396
Batch 64/64 loss: 0.27747583389282227
Epoch 190  Train loss: 0.2740405624988032  Val loss: 0.2941805878046042
Epoch 191
-------------------------------
Batch 1/64 loss: 0.27691733837127686
Batch 2/64 loss: 0.26206886768341064
Batch 3/64 loss: 0.26650965213775635
Batch 4/64 loss: 0.2723294496536255
Batch 5/64 loss: 0.27470678091049194
Batch 6/64 loss: 0.2649648189544678
Batch 7/64 loss: 0.26737773418426514
Batch 8/64 loss: 0.2745572328567505
Batch 9/64 loss: 0.26632410287857056
Batch 10/64 loss: 0.27170729637145996
Batch 11/64 loss: 0.2820196747779846
Batch 12/64 loss: 0.2817646265029907
Batch 13/64 loss: 0.2672804594039917
Batch 14/64 loss: 0.2803375720977783
Batch 15/64 loss: 0.27719056606292725
Batch 16/64 loss: 0.2854158878326416
Batch 17/64 loss: 0.27547287940979004
Batch 18/64 loss: 0.2675653100013733
Batch 19/64 loss: 0.2702077031135559
Batch 20/64 loss: 0.27766960859298706
Batch 21/64 loss: 0.274361252784729
Batch 22/64 loss: 0.25357282161712646
Batch 23/64 loss: 0.27551430463790894
Batch 24/64 loss: 0.28182899951934814
Batch 25/64 loss: 0.2655460834503174
Batch 26/64 loss: 0.26771676540374756
Batch 27/64 loss: 0.2758833169937134
Batch 28/64 loss: 0.28103071451187134
Batch 29/64 loss: 0.2668255567550659
Batch 30/64 loss: 0.2696608304977417
Batch 31/64 loss: 0.26539409160614014
Batch 32/64 loss: 0.27219903469085693
Batch 33/64 loss: 0.27683526277542114
Batch 34/64 loss: 0.2768508195877075
Batch 35/64 loss: 0.27607572078704834
Batch 36/64 loss: 0.2707167863845825
Batch 37/64 loss: 0.2761693596839905
Batch 38/64 loss: 0.27528291940689087
Batch 39/64 loss: 0.2715839147567749
Batch 40/64 loss: 0.2669316530227661
Batch 41/64 loss: 0.27237260341644287
Batch 42/64 loss: 0.27358853816986084
Batch 43/64 loss: 0.2666296362876892
Batch 44/64 loss: 0.2678322196006775
Batch 45/64 loss: 0.27091580629348755
Batch 46/64 loss: 0.2743244767189026
Batch 47/64 loss: 0.2838900089263916
Batch 48/64 loss: 0.2759737968444824
Batch 49/64 loss: 0.2736090421676636
Batch 50/64 loss: 0.2927108407020569
Batch 51/64 loss: 0.28144586086273193
Batch 52/64 loss: 0.27239328622817993
Batch 53/64 loss: 0.27103400230407715
Batch 54/64 loss: 0.28456270694732666
Batch 55/64 loss: 0.27170825004577637
Batch 56/64 loss: 0.2744958996772766
Batch 57/64 loss: 0.28003865480422974
Batch 58/64 loss: 0.2748619318008423
Batch 59/64 loss: 0.27690649032592773
Batch 60/64 loss: 0.2817392349243164
Batch 61/64 loss: 0.27074193954467773
Batch 62/64 loss: 0.27790606021881104
Batch 63/64 loss: 0.28942394256591797
Batch 64/64 loss: 0.2715914845466614
Epoch 191  Train loss: 0.27396339785818963  Val loss: 0.29166452622495564
Saving best model, epoch: 191
Epoch 192
-------------------------------
Batch 1/64 loss: 0.26051628589630127
Batch 2/64 loss: 0.2742050290107727
Batch 3/64 loss: 0.2719593048095703
Batch 4/64 loss: 0.266947865486145
Batch 5/64 loss: 0.28258049488067627
Batch 6/64 loss: 0.27510952949523926
Batch 7/64 loss: 0.2727471590042114
Batch 8/64 loss: 0.2694479823112488
Batch 9/64 loss: 0.27432215213775635
Batch 10/64 loss: 0.2799876928329468
Batch 11/64 loss: 0.2685422897338867
Batch 12/64 loss: 0.28205549716949463
Batch 13/64 loss: 0.27645909786224365
Batch 14/64 loss: 0.2650938034057617
Batch 15/64 loss: 0.27516478300094604
Batch 16/64 loss: 0.26865673065185547
Batch 17/64 loss: 0.2681815028190613
Batch 18/64 loss: 0.27007925510406494
Batch 19/64 loss: 0.27343690395355225
Batch 20/64 loss: 0.2783578634262085
Batch 21/64 loss: 0.272702693939209
Batch 22/64 loss: 0.2728050947189331
Batch 23/64 loss: 0.27890026569366455
Batch 24/64 loss: 0.2670201063156128
Batch 25/64 loss: 0.275088369846344
Batch 26/64 loss: 0.2760730981826782
Batch 27/64 loss: 0.2673221826553345
Batch 28/64 loss: 0.2760999798774719
Batch 29/64 loss: 0.27688950300216675
Batch 30/64 loss: 0.27160656452178955
Batch 31/64 loss: 0.2746734619140625
Batch 32/64 loss: 0.2743401527404785
Batch 33/64 loss: 0.27303171157836914
Batch 34/64 loss: 0.266460657119751
Batch 35/64 loss: 0.2627977132797241
Batch 36/64 loss: 0.26729828119277954
Batch 37/64 loss: 0.27539414167404175
Batch 38/64 loss: 0.2802931070327759
Batch 39/64 loss: 0.2647227644920349
Batch 40/64 loss: 0.2714614272117615
Batch 41/64 loss: 0.2671489715576172
Batch 42/64 loss: 0.2656455636024475
Batch 43/64 loss: 0.265869677066803
Batch 44/64 loss: 0.26914161443710327
Batch 45/64 loss: 0.28356367349624634
Batch 46/64 loss: 0.27980250120162964
Batch 47/64 loss: 0.2673858404159546
Batch 48/64 loss: 0.2724013328552246
Batch 49/64 loss: 0.27583909034729004
Batch 50/64 loss: 0.2700269818305969
Batch 51/64 loss: 0.2742347717285156
Batch 52/64 loss: 0.27605903148651123
Batch 53/64 loss: 0.27414095401763916
Batch 54/64 loss: 0.27274250984191895
Batch 55/64 loss: 0.28002500534057617
Batch 56/64 loss: 0.27229243516921997
Batch 57/64 loss: 0.26733797788619995
Batch 58/64 loss: 0.27331751585006714
Batch 59/64 loss: 0.279049813747406
Batch 60/64 loss: 0.272128701210022
Batch 61/64 loss: 0.2783411145210266
Batch 62/64 loss: 0.28484708070755005
Batch 63/64 loss: 0.27653050422668457
Batch 64/64 loss: 0.2866377830505371
Epoch 192  Train loss: 0.27312444705589145  Val loss: 0.29199694358196454
Epoch 193
-------------------------------
Batch 1/64 loss: 0.26473116874694824
Batch 2/64 loss: 0.2759479880332947
Batch 3/64 loss: 0.2689859867095947
Batch 4/64 loss: 0.27082395553588867
Batch 5/64 loss: 0.26428520679473877
Batch 6/64 loss: 0.27071309089660645
Batch 7/64 loss: 0.2829824686050415
Batch 8/64 loss: 0.27160459756851196
Batch 9/64 loss: 0.26702451705932617
Batch 10/64 loss: 0.27019643783569336
Batch 11/64 loss: 0.2730724811553955
Batch 12/64 loss: 0.2732205390930176
Batch 13/64 loss: 0.2765932083129883
Batch 14/64 loss: 0.2707256078720093
Batch 15/64 loss: 0.2783287763595581
Batch 16/64 loss: 0.27150899171829224
Batch 17/64 loss: 0.27114981412887573
Batch 18/64 loss: 0.26870179176330566
Batch 19/64 loss: 0.27151602506637573
Batch 20/64 loss: 0.2690023183822632
Batch 21/64 loss: 0.270114004611969
Batch 22/64 loss: 0.2747300863265991
Batch 23/64 loss: 0.2716218829154968
Batch 24/64 loss: 0.2822698950767517
Batch 25/64 loss: 0.27229613065719604
Batch 26/64 loss: 0.27657604217529297
Batch 27/64 loss: 0.27860599756240845
Batch 28/64 loss: 0.26313507556915283
Batch 29/64 loss: 0.27311408519744873
Batch 30/64 loss: 0.2776799201965332
Batch 31/64 loss: 0.283535897731781
Batch 32/64 loss: 0.27433621883392334
Batch 33/64 loss: 0.2724825143814087
Batch 34/64 loss: 0.2662513256072998
Batch 35/64 loss: 0.2751910090446472
Batch 36/64 loss: 0.2679077386856079
Batch 37/64 loss: 0.27453720569610596
Batch 38/64 loss: 0.27906930446624756
Batch 39/64 loss: 0.26606905460357666
Batch 40/64 loss: 0.2794393301010132
Batch 41/64 loss: 0.28856492042541504
Batch 42/64 loss: 0.2890356183052063
Batch 43/64 loss: 0.26613783836364746
Batch 44/64 loss: 0.27102869749069214
Batch 45/64 loss: 0.27457278966903687
Batch 46/64 loss: 0.27618956565856934
Batch 47/64 loss: 0.2705118656158447
Batch 48/64 loss: 0.26833391189575195
Batch 49/64 loss: 0.2741023898124695
Batch 50/64 loss: 0.2770858407020569
Batch 51/64 loss: 0.271938681602478
Batch 52/64 loss: 0.2651556730270386
Batch 53/64 loss: 0.26833200454711914
Batch 54/64 loss: 0.27648305892944336
Batch 55/64 loss: 0.26553618907928467
Batch 56/64 loss: 0.27628445625305176
Batch 57/64 loss: 0.2735278010368347
Batch 58/64 loss: 0.27211904525756836
Batch 59/64 loss: 0.2779421806335449
Batch 60/64 loss: 0.2780795097351074
Batch 61/64 loss: 0.2667849063873291
Batch 62/64 loss: 0.27184081077575684
Batch 63/64 loss: 0.2779744863510132
Batch 64/64 loss: 0.2737622857093811
Epoch 193  Train loss: 0.27314449642218797  Val loss: 0.2932011968491413
Epoch 194
-------------------------------
Batch 1/64 loss: 0.27176153659820557
Batch 2/64 loss: 0.26992475986480713
Batch 3/64 loss: 0.2742018699645996
Batch 4/64 loss: 0.27926260232925415
Batch 5/64 loss: 0.2723262310028076
Batch 6/64 loss: 0.26762932538986206
Batch 7/64 loss: 0.2685527205467224
Batch 8/64 loss: 0.26625025272369385
Batch 9/64 loss: 0.2735787630081177
Batch 10/64 loss: 0.26553428173065186
Batch 11/64 loss: 0.2701791524887085
Batch 12/64 loss: 0.2735810875892639
Batch 13/64 loss: 0.27575427293777466
Batch 14/64 loss: 0.27107423543930054
Batch 15/64 loss: 0.2789040803909302
Batch 16/64 loss: 0.2724757194519043
Batch 17/64 loss: 0.2621206045150757
Batch 18/64 loss: 0.2659134864807129
Batch 19/64 loss: 0.27967369556427
Batch 20/64 loss: 0.28026366233825684
Batch 21/64 loss: 0.2668958902359009
Batch 22/64 loss: 0.26880013942718506
Batch 23/64 loss: 0.2761620283126831
Batch 24/64 loss: 0.26632189750671387
Batch 25/64 loss: 0.2736009955406189
Batch 26/64 loss: 0.27767759561538696
Batch 27/64 loss: 0.2747584581375122
Batch 28/64 loss: 0.2738962769508362
Batch 29/64 loss: 0.27325868606567383
Batch 30/64 loss: 0.268778920173645
Batch 31/64 loss: 0.27122199535369873
Batch 32/64 loss: 0.2699390649795532
Batch 33/64 loss: 0.27826470136642456
Batch 34/64 loss: 0.2706414461135864
Batch 35/64 loss: 0.26641738414764404
Batch 36/64 loss: 0.27334654331207275
Batch 37/64 loss: 0.2816702127456665
Batch 38/64 loss: 0.26415252685546875
Batch 39/64 loss: 0.2730802297592163
Batch 40/64 loss: 0.2681298851966858
Batch 41/64 loss: 0.2726719379425049
Batch 42/64 loss: 0.2714933753013611
Batch 43/64 loss: 0.27439916133880615
Batch 44/64 loss: 0.2778383493423462
Batch 45/64 loss: 0.265230655670166
Batch 46/64 loss: 0.26668310165405273
Batch 47/64 loss: 0.2754228711128235
Batch 48/64 loss: 0.2760102152824402
Batch 49/64 loss: 0.27592897415161133
Batch 50/64 loss: 0.26608437299728394
Batch 51/64 loss: 0.27833062410354614
Batch 52/64 loss: 0.2620365619659424
Batch 53/64 loss: 0.27607035636901855
Batch 54/64 loss: 0.26863324642181396
Batch 55/64 loss: 0.27820003032684326
Batch 56/64 loss: 0.2770122289657593
Batch 57/64 loss: 0.2682904601097107
Batch 58/64 loss: 0.2711341381072998
Batch 59/64 loss: 0.27772659063339233
Batch 60/64 loss: 0.2839928865432739
Batch 61/64 loss: 0.2726980447769165
Batch 62/64 loss: 0.2765762209892273
Batch 63/64 loss: 0.2700346112251282
Batch 64/64 loss: 0.28016144037246704
Epoch 194  Train loss: 0.2724485853139092  Val loss: 0.29151323775655213
Saving best model, epoch: 194
Epoch 195
-------------------------------
Batch 1/64 loss: 0.2728751301765442
Batch 2/64 loss: 0.27271223068237305
Batch 3/64 loss: 0.2773354649543762
Batch 4/64 loss: 0.2743072509765625
Batch 5/64 loss: 0.2677268981933594
Batch 6/64 loss: 0.28278303146362305
Batch 7/64 loss: 0.27411025762557983
Batch 8/64 loss: 0.271972119808197
Batch 9/64 loss: 0.28536057472229004
Batch 10/64 loss: 0.27156972885131836
Batch 11/64 loss: 0.2671908140182495
Batch 12/64 loss: 0.2710414528846741
Batch 13/64 loss: 0.26643288135528564
Batch 14/64 loss: 0.2719792127609253
Batch 15/64 loss: 0.28664904832839966
Batch 16/64 loss: 0.2665175795555115
Batch 17/64 loss: 0.26512396335601807
Batch 18/64 loss: 0.277917742729187
Batch 19/64 loss: 0.26280343532562256
Batch 20/64 loss: 0.28334468603134155
Batch 21/64 loss: 0.27950286865234375
Batch 22/64 loss: 0.279132604598999
Batch 23/64 loss: 0.26905572414398193
Batch 24/64 loss: 0.2776334285736084
Batch 25/64 loss: 0.26741063594818115
Batch 26/64 loss: 0.2811439633369446
Batch 27/64 loss: 0.26820337772369385
Batch 28/64 loss: 0.27120286226272583
Batch 29/64 loss: 0.2630144953727722
Batch 30/64 loss: 0.2739284038543701
Batch 31/64 loss: 0.268873929977417
Batch 32/64 loss: 0.27413129806518555
Batch 33/64 loss: 0.2661287784576416
Batch 34/64 loss: 0.27645009756088257
Batch 35/64 loss: 0.27465343475341797
Batch 36/64 loss: 0.26923197507858276
Batch 37/64 loss: 0.27842533588409424
Batch 38/64 loss: 0.2672743797302246
Batch 39/64 loss: 0.27248501777648926
Batch 40/64 loss: 0.2781713008880615
Batch 41/64 loss: 0.270763099193573
Batch 42/64 loss: 0.27299606800079346
Batch 43/64 loss: 0.28006428480148315
Batch 44/64 loss: 0.27210772037506104
Batch 45/64 loss: 0.2689335346221924
Batch 46/64 loss: 0.27449488639831543
Batch 47/64 loss: 0.26607853174209595
Batch 48/64 loss: 0.26332223415374756
Batch 49/64 loss: 0.2605621814727783
Batch 50/64 loss: 0.2760103940963745
Batch 51/64 loss: 0.27426862716674805
Batch 52/64 loss: 0.28128480911254883
Batch 53/64 loss: 0.2647970914840698
Batch 54/64 loss: 0.27430295944213867
Batch 55/64 loss: 0.2720180153846741
Batch 56/64 loss: 0.27269232273101807
Batch 57/64 loss: 0.2738354206085205
Batch 58/64 loss: 0.27912962436676025
Batch 59/64 loss: 0.26549839973449707
Batch 60/64 loss: 0.270518958568573
Batch 61/64 loss: 0.26977628469467163
Batch 62/64 loss: 0.2688984274864197
Batch 63/64 loss: 0.2739274501800537
Batch 64/64 loss: 0.2802402973175049
Epoch 195  Train loss: 0.27266304259206736  Val loss: 0.2962993260511418
Epoch 196
-------------------------------
Batch 1/64 loss: 0.27869701385498047
Batch 2/64 loss: 0.2736520767211914
Batch 3/64 loss: 0.2738305330276489
Batch 4/64 loss: 0.26797425746917725
Batch 5/64 loss: 0.26889562606811523
Batch 6/64 loss: 0.2742334008216858
Batch 7/64 loss: 0.262703537940979
Batch 8/64 loss: 0.2801510691642761
Batch 9/64 loss: 0.28458017110824585
Batch 10/64 loss: 0.27048248052597046
Batch 11/64 loss: 0.2756968140602112
Batch 12/64 loss: 0.2663799524307251
Batch 13/64 loss: 0.2772665023803711
Batch 14/64 loss: 0.26503705978393555
Batch 15/64 loss: 0.2760887145996094
Batch 16/64 loss: 0.26787757873535156
Batch 17/64 loss: 0.27848362922668457
Batch 18/64 loss: 0.2708336114883423
Batch 19/64 loss: 0.2662348747253418
Batch 20/64 loss: 0.2689516544342041
Batch 21/64 loss: 0.26182276010513306
Batch 22/64 loss: 0.2660059332847595
Batch 23/64 loss: 0.271078884601593
Batch 24/64 loss: 0.28032755851745605
Batch 25/64 loss: 0.274169921875
Batch 26/64 loss: 0.28039753437042236
Batch 27/64 loss: 0.274782657623291
Batch 28/64 loss: 0.2734585404396057
Batch 29/64 loss: 0.268749475479126
Batch 30/64 loss: 0.27182620763778687
Batch 31/64 loss: 0.2734503746032715
Batch 32/64 loss: 0.2683448791503906
Batch 33/64 loss: 0.27219855785369873
Batch 34/64 loss: 0.27819710969924927
Batch 35/64 loss: 0.26517850160598755
Batch 36/64 loss: 0.28348636627197266
Batch 37/64 loss: 0.2718619704246521
Batch 38/64 loss: 0.2731778621673584
Batch 39/64 loss: 0.2690749764442444
Batch 40/64 loss: 0.287739098072052
Batch 41/64 loss: 0.27626538276672363
Batch 42/64 loss: 0.27587616443634033
Batch 43/64 loss: 0.2782326340675354
Batch 44/64 loss: 0.26911473274230957
Batch 45/64 loss: 0.26441287994384766
Batch 46/64 loss: 0.2729385495185852
Batch 47/64 loss: 0.28376686573028564
Batch 48/64 loss: 0.2732267379760742
Batch 49/64 loss: 0.2756027579307556
Batch 50/64 loss: 0.2660263180732727
Batch 51/64 loss: 0.2676408290863037
Batch 52/64 loss: 0.280891478061676
Batch 53/64 loss: 0.2672646641731262
Batch 54/64 loss: 0.280002236366272
Batch 55/64 loss: 0.27978944778442383
Batch 56/64 loss: 0.2725106477737427
Batch 57/64 loss: 0.2760692834854126
Batch 58/64 loss: 0.27143579721450806
Batch 59/64 loss: 0.2658281922340393
Batch 60/64 loss: 0.2696602940559387
Batch 61/64 loss: 0.27895045280456543
Batch 62/64 loss: 0.27650558948516846
Batch 63/64 loss: 0.281757116317749
Batch 64/64 loss: 0.2815402150154114
Epoch 196  Train loss: 0.27338515987583234  Val loss: 0.29262642680164874
Epoch 197
-------------------------------
Batch 1/64 loss: 0.2680851221084595
Batch 2/64 loss: 0.26984429359436035
Batch 3/64 loss: 0.27561497688293457
Batch 4/64 loss: 0.28726351261138916
Batch 5/64 loss: 0.26720130443573
Batch 6/64 loss: 0.2694951295852661
Batch 7/64 loss: 0.27816450595855713
Batch 8/64 loss: 0.2721226215362549
Batch 9/64 loss: 0.27657896280288696
Batch 10/64 loss: 0.2713109850883484
Batch 11/64 loss: 0.2720244526863098
Batch 12/64 loss: 0.2662617564201355
Batch 13/64 loss: 0.2741548418998718
Batch 14/64 loss: 0.2746596932411194
Batch 15/64 loss: 0.27517783641815186
Batch 16/64 loss: 0.27015602588653564
Batch 17/64 loss: 0.27806270122528076
Batch 18/64 loss: 0.26754820346832275
Batch 19/64 loss: 0.2717297673225403
Batch 20/64 loss: 0.2815197706222534
Batch 21/64 loss: 0.2638741731643677
Batch 22/64 loss: 0.2664988040924072
Batch 23/64 loss: 0.2685418128967285
Batch 24/64 loss: 0.2718559503555298
Batch 25/64 loss: 0.2712479829788208
Batch 26/64 loss: 0.26584792137145996
Batch 27/64 loss: 0.2714654207229614
Batch 28/64 loss: 0.2791026830673218
Batch 29/64 loss: 0.2657420039176941
Batch 30/64 loss: 0.28017646074295044
Batch 31/64 loss: 0.2836175560951233
Batch 32/64 loss: 0.26899921894073486
Batch 33/64 loss: 0.2765345573425293
Batch 34/64 loss: 0.276339054107666
Batch 35/64 loss: 0.28196513652801514
Batch 36/64 loss: 0.2716149091720581
Batch 37/64 loss: 0.2661628723144531
Batch 38/64 loss: 0.2708294987678528
Batch 39/64 loss: 0.27980107069015503
Batch 40/64 loss: 0.26947081089019775
Batch 41/64 loss: 0.2773088812828064
Batch 42/64 loss: 0.265386164188385
Batch 43/64 loss: 0.2710137963294983
Batch 44/64 loss: 0.2756003141403198
Batch 45/64 loss: 0.27553898096084595
Batch 46/64 loss: 0.2704041600227356
Batch 47/64 loss: 0.2755166292190552
Batch 48/64 loss: 0.2679927349090576
Batch 49/64 loss: 0.267774760723114
Batch 50/64 loss: 0.2693394422531128
Batch 51/64 loss: 0.27160465717315674
Batch 52/64 loss: 0.26726746559143066
Batch 53/64 loss: 0.28056657314300537
Batch 54/64 loss: 0.2711527943611145
Batch 55/64 loss: 0.2646375894546509
Batch 56/64 loss: 0.28201013803482056
Batch 57/64 loss: 0.2748600244522095
Batch 58/64 loss: 0.2810314893722534
Batch 59/64 loss: 0.27379894256591797
Batch 60/64 loss: 0.2691582441329956
Batch 61/64 loss: 0.2713524103164673
Batch 62/64 loss: 0.2784072160720825
Batch 63/64 loss: 0.2651113271713257
Batch 64/64 loss: 0.2652174234390259
Epoch 197  Train loss: 0.27266528886907243  Val loss: 0.29157236925105456
Epoch 198
-------------------------------
Batch 1/64 loss: 0.27434056997299194
Batch 2/64 loss: 0.2729188799858093
Batch 3/64 loss: 0.269763708114624
Batch 4/64 loss: 0.27615272998809814
Batch 5/64 loss: 0.26838064193725586
Batch 6/64 loss: 0.27013468742370605
Batch 7/64 loss: 0.2676656246185303
Batch 8/64 loss: 0.2769496440887451
Batch 9/64 loss: 0.2688535451889038
Batch 10/64 loss: 0.27305614948272705
Batch 11/64 loss: 0.2794262170791626
Batch 12/64 loss: 0.26375675201416016
Batch 13/64 loss: 0.2622966170310974
Batch 14/64 loss: 0.2730445861816406
Batch 15/64 loss: 0.2745785713195801
Batch 16/64 loss: 0.27521491050720215
Batch 17/64 loss: 0.2802731990814209
Batch 18/64 loss: 0.2822369337081909
Batch 19/64 loss: 0.2669993042945862
Batch 20/64 loss: 0.27452439069747925
Batch 21/64 loss: 0.26758813858032227
Batch 22/64 loss: 0.2574005126953125
Batch 23/64 loss: 0.26987308263778687
Batch 24/64 loss: 0.2705341577529907
Batch 25/64 loss: 0.26734495162963867
Batch 26/64 loss: 0.27549678087234497
Batch 27/64 loss: 0.27481234073638916
Batch 28/64 loss: 0.27030831575393677
Batch 29/64 loss: 0.27101969718933105
Batch 30/64 loss: 0.2724921703338623
Batch 31/64 loss: 0.27310168743133545
Batch 32/64 loss: 0.26793068647384644
Batch 33/64 loss: 0.2766009569168091
Batch 34/64 loss: 0.27389419078826904
Batch 35/64 loss: 0.27434152364730835
Batch 36/64 loss: 0.2654426693916321
Batch 37/64 loss: 0.27756041288375854
Batch 38/64 loss: 0.2817438840866089
Batch 39/64 loss: 0.26814544200897217
Batch 40/64 loss: 0.27088499069213867
Batch 41/64 loss: 0.2629268765449524
Batch 42/64 loss: 0.2739109992980957
Batch 43/64 loss: 0.26766538619995117
Batch 44/64 loss: 0.2760683298110962
Batch 45/64 loss: 0.2720910310745239
Batch 46/64 loss: 0.269569993019104
Batch 47/64 loss: 0.27567219734191895
Batch 48/64 loss: 0.2738182544708252
Batch 49/64 loss: 0.2639279365539551
Batch 50/64 loss: 0.26824951171875
Batch 51/64 loss: 0.27193814516067505
Batch 52/64 loss: 0.2743741273880005
Batch 53/64 loss: 0.26566237211227417
Batch 54/64 loss: 0.2641950845718384
Batch 55/64 loss: 0.287555992603302
Batch 56/64 loss: 0.27647852897644043
Batch 57/64 loss: 0.27512896060943604
Batch 58/64 loss: 0.2729613780975342
Batch 59/64 loss: 0.2755624055862427
Batch 60/64 loss: 0.2699472904205322
Batch 61/64 loss: 0.27326714992523193
Batch 62/64 loss: 0.27310436964035034
Batch 63/64 loss: 0.26952505111694336
Batch 64/64 loss: 0.26408082246780396
Epoch 198  Train loss: 0.2718234704990013  Val loss: 0.29180838910165113
Epoch 199
-------------------------------
Batch 1/64 loss: 0.2660433053970337
Batch 2/64 loss: 0.26946091651916504
Batch 3/64 loss: 0.27059441804885864
Batch 4/64 loss: 0.26896369457244873
Batch 5/64 loss: 0.2699260115623474
Batch 6/64 loss: 0.275860071182251
Batch 7/64 loss: 0.2766304612159729
Batch 8/64 loss: 0.2749593257904053
Batch 9/64 loss: 0.27330946922302246
Batch 10/64 loss: 0.2795103192329407
Batch 11/64 loss: 0.2776746153831482
Batch 12/64 loss: 0.2677479386329651
Batch 13/64 loss: 0.27030348777770996
Batch 14/64 loss: 0.2663160562515259
Batch 15/64 loss: 0.26625120639801025
Batch 16/64 loss: 0.2699258327484131
Batch 17/64 loss: 0.2747606039047241
Batch 18/64 loss: 0.2717990279197693
Batch 19/64 loss: 0.2691754102706909
Batch 20/64 loss: 0.2713717818260193
Batch 21/64 loss: 0.27766263484954834
Batch 22/64 loss: 0.27511900663375854
Batch 23/64 loss: 0.26982581615448
Batch 24/64 loss: 0.26711738109588623
Batch 25/64 loss: 0.27368736267089844
Batch 26/64 loss: 0.264034628868103
Batch 27/64 loss: 0.26120978593826294
Batch 28/64 loss: 0.2740783095359802
Batch 29/64 loss: 0.26860761642456055
Batch 30/64 loss: 0.2660480737686157
Batch 31/64 loss: 0.2740018963813782
Batch 32/64 loss: 0.2713747024536133
Batch 33/64 loss: 0.26898646354675293
Batch 34/64 loss: 0.2659933567047119
Batch 35/64 loss: 0.27900123596191406
Batch 36/64 loss: 0.2737245559692383
Batch 37/64 loss: 0.26354098320007324
Batch 38/64 loss: 0.2710380554199219
Batch 39/64 loss: 0.2775663137435913
Batch 40/64 loss: 0.27305281162261963
Batch 41/64 loss: 0.26666003465652466
Batch 42/64 loss: 0.27594172954559326
Batch 43/64 loss: 0.2708195447921753
Batch 44/64 loss: 0.27377450466156006
Batch 45/64 loss: 0.27741074562072754
Batch 46/64 loss: 0.2726544737815857
Batch 47/64 loss: 0.2693001627922058
Batch 48/64 loss: 0.2679487466812134
Batch 49/64 loss: 0.2747036814689636
Batch 50/64 loss: 0.2762092351913452
Batch 51/64 loss: 0.27507251501083374
Batch 52/64 loss: 0.27284568548202515
Batch 53/64 loss: 0.2707630395889282
Batch 54/64 loss: 0.2676449418067932
Batch 55/64 loss: 0.27665024995803833
Batch 56/64 loss: 0.2650712728500366
Batch 57/64 loss: 0.27313244342803955
Batch 58/64 loss: 0.2790610194206238
Batch 59/64 loss: 0.2660449743270874
Batch 60/64 loss: 0.26537978649139404
Batch 61/64 loss: 0.2718226909637451
Batch 62/64 loss: 0.2671443223953247
Batch 63/64 loss: 0.25846970081329346
Batch 64/64 loss: 0.2714899182319641
Epoch 199  Train loss: 0.2711278099639743  Val loss: 0.29071604980226234
Saving best model, epoch: 199
Epoch 200
-------------------------------
Batch 1/64 loss: 0.2734256386756897
Batch 2/64 loss: 0.2694780230522156
Batch 3/64 loss: 0.27149879932403564
Batch 4/64 loss: 0.26913297176361084
Batch 5/64 loss: 0.27646303176879883
Batch 6/64 loss: 0.26412081718444824
Batch 7/64 loss: 0.2692691683769226
Batch 8/64 loss: 0.26790016889572144
Batch 9/64 loss: 0.261776864528656
Batch 10/64 loss: 0.2683889865875244
Batch 11/64 loss: 0.2774757146835327
Batch 12/64 loss: 0.26791316270828247
Batch 13/64 loss: 0.2734558582305908
Batch 14/64 loss: 0.2691633105278015
Batch 15/64 loss: 0.2712936997413635
Batch 16/64 loss: 0.2676979899406433
Batch 17/64 loss: 0.2740342617034912
Batch 18/64 loss: 0.2717646360397339
Batch 19/64 loss: 0.2733262777328491
Batch 20/64 loss: 0.2583799362182617
Batch 21/64 loss: 0.26941734552383423
Batch 22/64 loss: 0.27283960580825806
Batch 23/64 loss: 0.2735379934310913
Batch 24/64 loss: 0.2756194472312927
Batch 25/64 loss: 0.2618093490600586
Batch 26/64 loss: 0.2634464502334595
Batch 27/64 loss: 0.2679886817932129
Batch 28/64 loss: 0.2660566568374634
Batch 29/64 loss: 0.2764902114868164
Batch 30/64 loss: 0.2677270770072937
Batch 31/64 loss: 0.26726341247558594
Batch 32/64 loss: 0.2839308977127075
Batch 33/64 loss: 0.26924026012420654
Batch 34/64 loss: 0.27480727434158325
Batch 35/64 loss: 0.27399730682373047
Batch 36/64 loss: 0.27344346046447754
Batch 37/64 loss: 0.2704926133155823
Batch 38/64 loss: 0.2771620750427246
Batch 39/64 loss: 0.27520573139190674
Batch 40/64 loss: 0.2661231756210327
Batch 41/64 loss: 0.2711031436920166
Batch 42/64 loss: 0.27188289165496826
Batch 43/64 loss: 0.2648615837097168
Batch 44/64 loss: 0.2818632125854492
Batch 45/64 loss: 0.2744249105453491
Batch 46/64 loss: 0.2724451422691345
Batch 47/64 loss: 0.2704122066497803
Batch 48/64 loss: 0.27549779415130615
Batch 49/64 loss: 0.270832896232605
Batch 50/64 loss: 0.25482499599456787
Batch 51/64 loss: 0.26189708709716797
Batch 52/64 loss: 0.28131771087646484
Batch 53/64 loss: 0.28382575511932373
Batch 54/64 loss: 0.2681165933609009
Batch 55/64 loss: 0.27270662784576416
Batch 56/64 loss: 0.2695610523223877
Batch 57/64 loss: 0.28024041652679443
Batch 58/64 loss: 0.27921628952026367
Batch 59/64 loss: 0.27423596382141113
Batch 60/64 loss: 0.2771186828613281
Batch 61/64 loss: 0.2709459066390991
Batch 62/64 loss: 0.2670629024505615
Batch 63/64 loss: 0.2685204744338989
Batch 64/64 loss: 0.27480703592300415
Epoch 200  Train loss: 0.27124043703079226  Val loss: 0.29166253735519354
Epoch 201
-------------------------------
Batch 1/64 loss: 0.26981449127197266
Batch 2/64 loss: 0.271541953086853
Batch 3/64 loss: 0.2782990336418152
Batch 4/64 loss: 0.26983916759490967
Batch 5/64 loss: 0.26818734407424927
Batch 6/64 loss: 0.26646316051483154
Batch 7/64 loss: 0.27115166187286377
Batch 8/64 loss: 0.2664831876754761
Batch 9/64 loss: 0.2664140462875366
Batch 10/64 loss: 0.27193117141723633
Batch 11/64 loss: 0.26121532917022705
Batch 12/64 loss: 0.26873016357421875
Batch 13/64 loss: 0.2714425325393677
Batch 14/64 loss: 0.27749717235565186
Batch 15/64 loss: 0.26841795444488525
Batch 16/64 loss: 0.26642751693725586
Batch 17/64 loss: 0.2747381925582886
Batch 18/64 loss: 0.26681220531463623
Batch 19/64 loss: 0.27463698387145996
Batch 20/64 loss: 0.2692776918411255
Batch 21/64 loss: 0.2741539478302002
Batch 22/64 loss: 0.2791082262992859
Batch 23/64 loss: 0.273553729057312
Batch 24/64 loss: 0.27407824993133545
Batch 25/64 loss: 0.27140021324157715
Batch 26/64 loss: 0.26676249504089355
Batch 27/64 loss: 0.27452921867370605
Batch 28/64 loss: 0.274288535118103
Batch 29/64 loss: 0.27908945083618164
Batch 30/64 loss: 0.2674654722213745
Batch 31/64 loss: 0.27155226469039917
Batch 32/64 loss: 0.26589012145996094
Batch 33/64 loss: 0.28384411334991455
Batch 34/64 loss: 0.270779013633728
Batch 35/64 loss: 0.2630811929702759
Batch 36/64 loss: 0.2720755338668823
Batch 37/64 loss: 0.2737199068069458
Batch 38/64 loss: 0.2611943483352661
Batch 39/64 loss: 0.2744448184967041
Batch 40/64 loss: 0.2691575288772583
Batch 41/64 loss: 0.2686549425125122
Batch 42/64 loss: 0.2712913751602173
Batch 43/64 loss: 0.2697107791900635
Batch 44/64 loss: 0.27161705493927
Batch 45/64 loss: 0.26799046993255615
Batch 46/64 loss: 0.275390088558197
Batch 47/64 loss: 0.2717169523239136
Batch 48/64 loss: 0.27226579189300537
Batch 49/64 loss: 0.2760828137397766
Batch 50/64 loss: 0.272640585899353
Batch 51/64 loss: 0.2689945697784424
Batch 52/64 loss: 0.2653856873512268
Batch 53/64 loss: 0.2712552547454834
Batch 54/64 loss: 0.2735050916671753
Batch 55/64 loss: 0.26749950647354126
Batch 56/64 loss: 0.2662208080291748
Batch 57/64 loss: 0.26925432682037354
Batch 58/64 loss: 0.27510303258895874
Batch 59/64 loss: 0.26506638526916504
Batch 60/64 loss: 0.2630831003189087
Batch 61/64 loss: 0.27648401260375977
Batch 62/64 loss: 0.28046101331710815
Batch 63/64 loss: 0.26605385541915894
Batch 64/64 loss: 0.270749568939209
Epoch 201  Train loss: 0.27087496495714375  Val loss: 0.2901971966949935
Saving best model, epoch: 201
Epoch 202
-------------------------------
Batch 1/64 loss: 0.27110791206359863
Batch 2/64 loss: 0.2699292302131653
Batch 3/64 loss: 0.2820456027984619
Batch 4/64 loss: 0.2832690477371216
Batch 5/64 loss: 0.2712690830230713
Batch 6/64 loss: 0.2799949049949646
Batch 7/64 loss: 0.2692187428474426
Batch 8/64 loss: 0.2654758095741272
Batch 9/64 loss: 0.2700284719467163
Batch 10/64 loss: 0.27330124378204346
Batch 11/64 loss: 0.2701127529144287
Batch 12/64 loss: 0.26930344104766846
Batch 13/64 loss: 0.27596068382263184
Batch 14/64 loss: 0.2855558395385742
Batch 15/64 loss: 0.27139556407928467
Batch 16/64 loss: 0.26900291442871094
Batch 17/64 loss: 0.26690638065338135
Batch 18/64 loss: 0.2730717658996582
Batch 19/64 loss: 0.263924241065979
Batch 20/64 loss: 0.2698925733566284
Batch 21/64 loss: 0.2692960500717163
Batch 22/64 loss: 0.26333147287368774
Batch 23/64 loss: 0.256972074508667
Batch 24/64 loss: 0.27657127380371094
Batch 25/64 loss: 0.2631223797798157
Batch 26/64 loss: 0.26878929138183594
Batch 27/64 loss: 0.26518869400024414
Batch 28/64 loss: 0.26333868503570557
Batch 29/64 loss: 0.2695850133895874
Batch 30/64 loss: 0.26679766178131104
Batch 31/64 loss: 0.2718247175216675
Batch 32/64 loss: 0.26836228370666504
Batch 33/64 loss: 0.26705312728881836
Batch 34/64 loss: 0.2651010751724243
Batch 35/64 loss: 0.2684187889099121
Batch 36/64 loss: 0.26638537645339966
Batch 37/64 loss: 0.26235711574554443
Batch 38/64 loss: 0.2729199528694153
Batch 39/64 loss: 0.2653844356536865
Batch 40/64 loss: 0.27949124574661255
Batch 41/64 loss: 0.2727702856063843
Batch 42/64 loss: 0.27879178524017334
Batch 43/64 loss: 0.2660874128341675
Batch 44/64 loss: 0.272286593914032
Batch 45/64 loss: 0.28670740127563477
Batch 46/64 loss: 0.2696492075920105
Batch 47/64 loss: 0.2680092453956604
Batch 48/64 loss: 0.27102118730545044
Batch 49/64 loss: 0.2743387818336487
Batch 50/64 loss: 0.2699834108352661
Batch 51/64 loss: 0.26668334007263184
Batch 52/64 loss: 0.26802313327789307
Batch 53/64 loss: 0.2652912139892578
Batch 54/64 loss: 0.2713208794593811
Batch 55/64 loss: 0.27116459608078003
Batch 56/64 loss: 0.2691653370857239
Batch 57/64 loss: 0.2698251008987427
Batch 58/64 loss: 0.2697771191596985
Batch 59/64 loss: 0.27517271041870117
Batch 60/64 loss: 0.28331422805786133
Batch 61/64 loss: 0.2659091353416443
Batch 62/64 loss: 0.26859939098358154
Batch 63/64 loss: 0.27375364303588867
Batch 64/64 loss: 0.2683917284011841
Epoch 202  Train loss: 0.2705881703133677  Val loss: 0.2913870856524333
Epoch 203
-------------------------------
Batch 1/64 loss: 0.2656230330467224
Batch 2/64 loss: 0.26206958293914795
Batch 3/64 loss: 0.26733994483947754
Batch 4/64 loss: 0.27309727668762207
Batch 5/64 loss: 0.2614765167236328
Batch 6/64 loss: 0.2770369052886963
Batch 7/64 loss: 0.2685734033584595
Batch 8/64 loss: 0.26935791969299316
Batch 9/64 loss: 0.2740964889526367
Batch 10/64 loss: 0.268078088760376
Batch 11/64 loss: 0.2752043604850769
Batch 12/64 loss: 0.27257561683654785
Batch 13/64 loss: 0.26559388637542725
Batch 14/64 loss: 0.2638026475906372
Batch 15/64 loss: 0.2724562883377075
Batch 16/64 loss: 0.278448224067688
Batch 17/64 loss: 0.2675579786300659
Batch 18/64 loss: 0.2738664150238037
Batch 19/64 loss: 0.2596501111984253
Batch 20/64 loss: 0.2757410407066345
Batch 21/64 loss: 0.2718766927719116
Batch 22/64 loss: 0.2721899747848511
Batch 23/64 loss: 0.27210772037506104
Batch 24/64 loss: 0.2765321731567383
Batch 25/64 loss: 0.2675876021385193
Batch 26/64 loss: 0.27066731452941895
Batch 27/64 loss: 0.26530027389526367
Batch 28/64 loss: 0.2667754292488098
Batch 29/64 loss: 0.26601552963256836
Batch 30/64 loss: 0.26378029584884644
Batch 31/64 loss: 0.2652326822280884
Batch 32/64 loss: 0.26091980934143066
Batch 33/64 loss: 0.2650938630104065
Batch 34/64 loss: 0.27102428674697876
Batch 35/64 loss: 0.26745086908340454
Batch 36/64 loss: 0.27248382568359375
Batch 37/64 loss: 0.26757383346557617
Batch 38/64 loss: 0.27384960651397705
Batch 39/64 loss: 0.267943799495697
Batch 40/64 loss: 0.25853729248046875
Batch 41/64 loss: 0.2779924273490906
Batch 42/64 loss: 0.2698049545288086
Batch 43/64 loss: 0.26707935333251953
Batch 44/64 loss: 0.2732325792312622
Batch 45/64 loss: 0.26477909088134766
Batch 46/64 loss: 0.2630549669265747
Batch 47/64 loss: 0.27646350860595703
Batch 48/64 loss: 0.2733147144317627
Batch 49/64 loss: 0.2713351249694824
Batch 50/64 loss: 0.2625453472137451
Batch 51/64 loss: 0.2821025848388672
Batch 52/64 loss: 0.27475231885910034
Batch 53/64 loss: 0.29394853115081787
Batch 54/64 loss: 0.2689790725708008
Batch 55/64 loss: 0.2771243453025818
Batch 56/64 loss: 0.2667112946510315
Batch 57/64 loss: 0.27153515815734863
Batch 58/64 loss: 0.2748652696609497
Batch 59/64 loss: 0.28037166595458984
Batch 60/64 loss: 0.2842830419540405
Batch 61/64 loss: 0.2726977467536926
Batch 62/64 loss: 0.2777712941169739
Batch 63/64 loss: 0.26744139194488525
Batch 64/64 loss: 0.27303898334503174
Epoch 203  Train loss: 0.2706126058802885  Val loss: 0.2915522462313937
Epoch 204
-------------------------------
Batch 1/64 loss: 0.2608931064605713
Batch 2/64 loss: 0.25879502296447754
Batch 3/64 loss: 0.27472102642059326
Batch 4/64 loss: 0.269432008266449
Batch 5/64 loss: 0.27320951223373413
Batch 6/64 loss: 0.2695690393447876
Batch 7/64 loss: 0.26236891746520996
Batch 8/64 loss: 0.27056431770324707
Batch 9/64 loss: 0.2732493281364441
Batch 10/64 loss: 0.2687671184539795
Batch 11/64 loss: 0.26564276218414307
Batch 12/64 loss: 0.2762768268585205
Batch 13/64 loss: 0.2669088840484619
Batch 14/64 loss: 0.27631473541259766
Batch 15/64 loss: 0.26900434494018555
Batch 16/64 loss: 0.2774279713630676
Batch 17/64 loss: 0.2735412120819092
Batch 18/64 loss: 0.27351653575897217
Batch 19/64 loss: 0.27526605129241943
Batch 20/64 loss: 0.2791358232498169
Batch 21/64 loss: 0.2786141633987427
Batch 22/64 loss: 0.27854394912719727
Batch 23/64 loss: 0.27073222398757935
Batch 24/64 loss: 0.2664455771446228
Batch 25/64 loss: 0.2626030445098877
Batch 26/64 loss: 0.2631596326828003
Batch 27/64 loss: 0.2758263349533081
Batch 28/64 loss: 0.2715451717376709
Batch 29/64 loss: 0.266592800617218
Batch 30/64 loss: 0.27828001976013184
Batch 31/64 loss: 0.2658179998397827
Batch 32/64 loss: 0.2746243476867676
Batch 33/64 loss: 0.2699577808380127
Batch 34/64 loss: 0.2718876004219055
Batch 35/64 loss: 0.26576054096221924
Batch 36/64 loss: 0.26841068267822266
Batch 37/64 loss: 0.26263415813446045
Batch 38/64 loss: 0.2629454731941223
Batch 39/64 loss: 0.2703257203102112
Batch 40/64 loss: 0.26908254623413086
Batch 41/64 loss: 0.27252352237701416
Batch 42/64 loss: 0.2721506953239441
Batch 43/64 loss: 0.276253342628479
Batch 44/64 loss: 0.26989996433258057
Batch 45/64 loss: 0.26899659633636475
Batch 46/64 loss: 0.26787811517715454
Batch 47/64 loss: 0.27531272172927856
Batch 48/64 loss: 0.2727348208427429
Batch 49/64 loss: 0.25876277685165405
Batch 50/64 loss: 0.2748006582260132
Batch 51/64 loss: 0.2766754627227783
Batch 52/64 loss: 0.26427435874938965
Batch 53/64 loss: 0.2609686851501465
Batch 54/64 loss: 0.27381443977355957
Batch 55/64 loss: 0.28396105766296387
Batch 56/64 loss: 0.27271193265914917
Batch 57/64 loss: 0.2749978303909302
Batch 58/64 loss: 0.2692965269088745
Batch 59/64 loss: 0.26717710494995117
Batch 60/64 loss: 0.2687598466873169
Batch 61/64 loss: 0.2722625136375427
Batch 62/64 loss: 0.2747463583946228
Batch 63/64 loss: 0.27504444122314453
Batch 64/64 loss: 0.26615989208221436
Epoch 204  Train loss: 0.2706198902691112  Val loss: 0.2921980021335825
Epoch 205
-------------------------------
Batch 1/64 loss: 0.2636157274246216
Batch 2/64 loss: 0.2693505883216858
Batch 3/64 loss: 0.27191805839538574
Batch 4/64 loss: 0.2724924087524414
Batch 5/64 loss: 0.26892703771591187
Batch 6/64 loss: 0.26364845037460327
Batch 7/64 loss: 0.27741801738739014
Batch 8/64 loss: 0.2743944525718689
Batch 9/64 loss: 0.27022767066955566
Batch 10/64 loss: 0.26711422204971313
Batch 11/64 loss: 0.2627915143966675
Batch 12/64 loss: 0.27604812383651733
Batch 13/64 loss: 0.2810560464859009
Batch 14/64 loss: 0.2797212600708008
Batch 15/64 loss: 0.263045072555542
Batch 16/64 loss: 0.27224230766296387
Batch 17/64 loss: 0.27055448293685913
Batch 18/64 loss: 0.2759435176849365
Batch 19/64 loss: 0.2635241150856018
Batch 20/64 loss: 0.2687722444534302
Batch 21/64 loss: 0.26962995529174805
Batch 22/64 loss: 0.2772918939590454
Batch 23/64 loss: 0.2721966505050659
Batch 24/64 loss: 0.27372103929519653
Batch 25/64 loss: 0.2721866965293884
Batch 26/64 loss: 0.27032363414764404
Batch 27/64 loss: 0.27018916606903076
Batch 28/64 loss: 0.26985490322113037
Batch 29/64 loss: 0.26386529207229614
Batch 30/64 loss: 0.26193296909332275
Batch 31/64 loss: 0.26863741874694824
Batch 32/64 loss: 0.27379143238067627
Batch 33/64 loss: 0.2751718759536743
Batch 34/64 loss: 0.27305614948272705
Batch 35/64 loss: 0.2629935145378113
Batch 36/64 loss: 0.2786160707473755
Batch 37/64 loss: 0.2683948278427124
Batch 38/64 loss: 0.2785228490829468
Batch 39/64 loss: 0.27785468101501465
Batch 40/64 loss: 0.2734243869781494
Batch 41/64 loss: 0.26822441816329956
Batch 42/64 loss: 0.2719534635543823
Batch 43/64 loss: 0.27545166015625
Batch 44/64 loss: 0.2728998064994812
Batch 45/64 loss: 0.2764502167701721
Batch 46/64 loss: 0.26948899030685425
Batch 47/64 loss: 0.26505494117736816
Batch 48/64 loss: 0.2741510272026062
Batch 49/64 loss: 0.2641952633857727
Batch 50/64 loss: 0.26763105392456055
Batch 51/64 loss: 0.2839401364326477
Batch 52/64 loss: 0.27715420722961426
Batch 53/64 loss: 0.2685907483100891
Batch 54/64 loss: 0.2559117078781128
Batch 55/64 loss: 0.2630068063735962
Batch 56/64 loss: 0.2813103199005127
Batch 57/64 loss: 0.2747241258621216
Batch 58/64 loss: 0.28255653381347656
Batch 59/64 loss: 0.26363587379455566
Batch 60/64 loss: 0.2785983085632324
Batch 61/64 loss: 0.26800453662872314
Batch 62/64 loss: 0.2683452367782593
Batch 63/64 loss: 0.2746084928512573
Batch 64/64 loss: 0.2649216651916504
Epoch 205  Train loss: 0.27120062510172527  Val loss: 0.2913162433814347
Epoch 206
-------------------------------
Batch 1/64 loss: 0.26897966861724854
Batch 2/64 loss: 0.27941471338272095
Batch 3/64 loss: 0.263729453086853
Batch 4/64 loss: 0.27665817737579346
Batch 5/64 loss: 0.263663649559021
Batch 6/64 loss: 0.27325987815856934
Batch 7/64 loss: 0.2729043960571289
Batch 8/64 loss: 0.26347672939300537
Batch 9/64 loss: 0.26535648107528687
Batch 10/64 loss: 0.2660742998123169
Batch 11/64 loss: 0.2680577039718628
Batch 12/64 loss: 0.2735790014266968
Batch 13/64 loss: 0.270516037940979
Batch 14/64 loss: 0.2706837058067322
Batch 15/64 loss: 0.2653385400772095
Batch 16/64 loss: 0.2645292282104492
Batch 17/64 loss: 0.2641240954399109
Batch 18/64 loss: 0.27448248863220215
Batch 19/64 loss: 0.2736644744873047
Batch 20/64 loss: 0.26830989122390747
Batch 21/64 loss: 0.2754994034767151
Batch 22/64 loss: 0.27185022830963135
Batch 23/64 loss: 0.26086926460266113
Batch 24/64 loss: 0.2637210488319397
Batch 25/64 loss: 0.2605555057525635
Batch 26/64 loss: 0.2723010182380676
Batch 27/64 loss: 0.27365636825561523
Batch 28/64 loss: 0.2630718946456909
Batch 29/64 loss: 0.26810526847839355
Batch 30/64 loss: 0.2664351463317871
Batch 31/64 loss: 0.26483118534088135
Batch 32/64 loss: 0.2677973508834839
Batch 33/64 loss: 0.26756972074508667
Batch 34/64 loss: 0.27664774656295776
Batch 35/64 loss: 0.27199673652648926
Batch 36/64 loss: 0.27356088161468506
Batch 37/64 loss: 0.26865822076797485
Batch 38/64 loss: 0.27738118171691895
Batch 39/64 loss: 0.26959067583084106
Batch 40/64 loss: 0.2675405740737915
Batch 41/64 loss: 0.27368253469467163
Batch 42/64 loss: 0.26296329498291016
Batch 43/64 loss: 0.2811547517776489
Batch 44/64 loss: 0.26736152172088623
Batch 45/64 loss: 0.2668190002441406
Batch 46/64 loss: 0.27199608087539673
Batch 47/64 loss: 0.26655709743499756
Batch 48/64 loss: 0.2875765562057495
Batch 49/64 loss: 0.27523112297058105
Batch 50/64 loss: 0.26722240447998047
Batch 51/64 loss: 0.25623154640197754
Batch 52/64 loss: 0.2637479305267334
Batch 53/64 loss: 0.27187615633010864
Batch 54/64 loss: 0.2659671902656555
Batch 55/64 loss: 0.26516401767730713
Batch 56/64 loss: 0.26608359813690186
Batch 57/64 loss: 0.2642347812652588
Batch 58/64 loss: 0.26976001262664795
Batch 59/64 loss: 0.26860547065734863
Batch 60/64 loss: 0.2677873373031616
Batch 61/64 loss: 0.26449573040008545
Batch 62/64 loss: 0.2712421417236328
Batch 63/64 loss: 0.2716010808944702
Batch 64/64 loss: 0.2919920086860657
Epoch 206  Train loss: 0.2694085866797204  Val loss: 0.2898337664882752
Saving best model, epoch: 206
Epoch 207
-------------------------------
Batch 1/64 loss: 0.266471266746521
Batch 2/64 loss: 0.2653764486312866
Batch 3/64 loss: 0.2674524784088135
Batch 4/64 loss: 0.27191388607025146
Batch 5/64 loss: 0.25774645805358887
Batch 6/64 loss: 0.26927894353866577
Batch 7/64 loss: 0.26926255226135254
Batch 8/64 loss: 0.26301467418670654
Batch 9/64 loss: 0.26512157917022705
Batch 10/64 loss: 0.27566397190093994
Batch 11/64 loss: 0.26460039615631104
Batch 12/64 loss: 0.2744075059890747
Batch 13/64 loss: 0.27071624994277954
Batch 14/64 loss: 0.27717602252960205
Batch 15/64 loss: 0.2566767930984497
Batch 16/64 loss: 0.26760411262512207
Batch 17/64 loss: 0.26062965393066406
Batch 18/64 loss: 0.26321613788604736
Batch 19/64 loss: 0.2687351107597351
Batch 20/64 loss: 0.2687734365463257
Batch 21/64 loss: 0.2634153962135315
Batch 22/64 loss: 0.2750042676925659
Batch 23/64 loss: 0.28085261583328247
Batch 24/64 loss: 0.2601580023765564
Batch 25/64 loss: 0.27294719219207764
Batch 26/64 loss: 0.2763075828552246
Batch 27/64 loss: 0.2668755054473877
Batch 28/64 loss: 0.2615358233451843
Batch 29/64 loss: 0.2781611680984497
Batch 30/64 loss: 0.2685588002204895
Batch 31/64 loss: 0.2717442512512207
Batch 32/64 loss: 0.26817452907562256
Batch 33/64 loss: 0.27503764629364014
Batch 34/64 loss: 0.2679523825645447
Batch 35/64 loss: 0.26842063665390015
Batch 36/64 loss: 0.26880455017089844
Batch 37/64 loss: 0.26457679271698
Batch 38/64 loss: 0.26493537425994873
Batch 39/64 loss: 0.267689049243927
Batch 40/64 loss: 0.26931852102279663
Batch 41/64 loss: 0.2689330577850342
Batch 42/64 loss: 0.2602250576019287
Batch 43/64 loss: 0.2629495859146118
Batch 44/64 loss: 0.26763778924942017
Batch 45/64 loss: 0.2788662314414978
Batch 46/64 loss: 0.2723264694213867
Batch 47/64 loss: 0.2724437117576599
Batch 48/64 loss: 0.27693653106689453
Batch 49/64 loss: 0.2694706916809082
Batch 50/64 loss: 0.2627773880958557
Batch 51/64 loss: 0.2681926488876343
Batch 52/64 loss: 0.26937395334243774
Batch 53/64 loss: 0.2641174793243408
Batch 54/64 loss: 0.27253615856170654
Batch 55/64 loss: 0.2696900963783264
Batch 56/64 loss: 0.27157169580459595
Batch 57/64 loss: 0.2657421827316284
Batch 58/64 loss: 0.282931923866272
Batch 59/64 loss: 0.2672652006149292
Batch 60/64 loss: 0.28739500045776367
Batch 61/64 loss: 0.26966726779937744
Batch 62/64 loss: 0.2680022120475769
Batch 63/64 loss: 0.2647765874862671
Batch 64/64 loss: 0.27606719732284546
Epoch 207  Train loss: 0.2691009738866021  Val loss: 0.2902181230459836
Epoch 208
-------------------------------
Batch 1/64 loss: 0.27194684743881226
Batch 2/64 loss: 0.2619367241859436
Batch 3/64 loss: 0.27233564853668213
Batch 4/64 loss: 0.26123273372650146
Batch 5/64 loss: 0.2616901993751526
Batch 6/64 loss: 0.26833510398864746
Batch 7/64 loss: 0.2650463581085205
Batch 8/64 loss: 0.2721882462501526
Batch 9/64 loss: 0.26629340648651123
Batch 10/64 loss: 0.27462518215179443
Batch 11/64 loss: 0.26703548431396484
Batch 12/64 loss: 0.26686394214630127
Batch 13/64 loss: 0.26579296588897705
Batch 14/64 loss: 0.27519500255584717
Batch 15/64 loss: 0.2717117667198181
Batch 16/64 loss: 0.26957839727401733
Batch 17/64 loss: 0.27824336290359497
Batch 18/64 loss: 0.26882636547088623
Batch 19/64 loss: 0.271295428276062
Batch 20/64 loss: 0.26868677139282227
Batch 21/64 loss: 0.2750948667526245
Batch 22/64 loss: 0.26750242710113525
Batch 23/64 loss: 0.2574141025543213
Batch 24/64 loss: 0.2699964642524719
Batch 25/64 loss: 0.2658708095550537
Batch 26/64 loss: 0.2727922201156616
Batch 27/64 loss: 0.2696399688720703
Batch 28/64 loss: 0.27454960346221924
Batch 29/64 loss: 0.27717363834381104
Batch 30/64 loss: 0.26543140411376953
Batch 31/64 loss: 0.26591694355010986
Batch 32/64 loss: 0.2646130323410034
Batch 33/64 loss: 0.2723069190979004
Batch 34/64 loss: 0.27069926261901855
Batch 35/64 loss: 0.2721383571624756
Batch 36/64 loss: 0.2689669132232666
Batch 37/64 loss: 0.26299047470092773
Batch 38/64 loss: 0.2605917453765869
Batch 39/64 loss: 0.2621985673904419
Batch 40/64 loss: 0.26183557510375977
Batch 41/64 loss: 0.2704179883003235
Batch 42/64 loss: 0.2740442752838135
Batch 43/64 loss: 0.269308865070343
Batch 44/64 loss: 0.2772676944732666
Batch 45/64 loss: 0.2694605588912964
Batch 46/64 loss: 0.27503252029418945
Batch 47/64 loss: 0.26402485370635986
Batch 48/64 loss: 0.2723376750946045
Batch 49/64 loss: 0.27197813987731934
Batch 50/64 loss: 0.26383787393569946
Batch 51/64 loss: 0.26542699337005615
Batch 52/64 loss: 0.2651677131652832
Batch 53/64 loss: 0.2663794755935669
Batch 54/64 loss: 0.262093722820282
Batch 55/64 loss: 0.26559746265411377
Batch 56/64 loss: 0.27612948417663574
Batch 57/64 loss: 0.2608257532119751
Batch 58/64 loss: 0.25860339403152466
Batch 59/64 loss: 0.26084864139556885
Batch 60/64 loss: 0.2713817358016968
Batch 61/64 loss: 0.26508164405822754
Batch 62/64 loss: 0.2765223979949951
Batch 63/64 loss: 0.29035311937332153
Batch 64/64 loss: 0.2690214514732361
Epoch 208  Train loss: 0.26871327535778866  Val loss: 0.29242158161405846
Epoch 209
-------------------------------
Batch 1/64 loss: 0.26457250118255615
Batch 2/64 loss: 0.2701945900917053
Batch 3/64 loss: 0.2725904583930969
Batch 4/64 loss: 0.2712332010269165
Batch 5/64 loss: 0.2814220190048218
Batch 6/64 loss: 0.2678854465484619
Batch 7/64 loss: 0.2759883403778076
Batch 8/64 loss: 0.26669859886169434
Batch 9/64 loss: 0.26964300870895386
Batch 10/64 loss: 0.265283465385437
Batch 11/64 loss: 0.2688654661178589
Batch 12/64 loss: 0.2748606204986572
Batch 13/64 loss: 0.2611217498779297
Batch 14/64 loss: 0.26804888248443604
Batch 15/64 loss: 0.2648172378540039
Batch 16/64 loss: 0.2703512907028198
Batch 17/64 loss: 0.27506518363952637
Batch 18/64 loss: 0.2624204158782959
Batch 19/64 loss: 0.26928776502609253
Batch 20/64 loss: 0.27992671728134155
Batch 21/64 loss: 0.2730107307434082
Batch 22/64 loss: 0.2816210985183716
Batch 23/64 loss: 0.2718583345413208
Batch 24/64 loss: 0.26295363903045654
Batch 25/64 loss: 0.26937592029571533
Batch 26/64 loss: 0.27225005626678467
Batch 27/64 loss: 0.2595473527908325
Batch 28/64 loss: 0.26804113388061523
Batch 29/64 loss: 0.2669421434402466
Batch 30/64 loss: 0.27142465114593506
Batch 31/64 loss: 0.2652376890182495
Batch 32/64 loss: 0.26370060443878174
Batch 33/64 loss: 0.26629823446273804
Batch 34/64 loss: 0.2688789367675781
Batch 35/64 loss: 0.2806345224380493
Batch 36/64 loss: 0.2659569978713989
Batch 37/64 loss: 0.2693726420402527
Batch 38/64 loss: 0.27028584480285645
Batch 39/64 loss: 0.26785165071487427
Batch 40/64 loss: 0.27554893493652344
Batch 41/64 loss: 0.26580941677093506
Batch 42/64 loss: 0.27025967836380005
Batch 43/64 loss: 0.2643665075302124
Batch 44/64 loss: 0.263297438621521
Batch 45/64 loss: 0.2656280994415283
Batch 46/64 loss: 0.2582324147224426
Batch 47/64 loss: 0.2619725465774536
Batch 48/64 loss: 0.26340627670288086
Batch 49/64 loss: 0.27504676580429077
Batch 50/64 loss: 0.2661857604980469
Batch 51/64 loss: 0.26751571893692017
Batch 52/64 loss: 0.27114027738571167
Batch 53/64 loss: 0.2718362808227539
Batch 54/64 loss: 0.2747899889945984
Batch 55/64 loss: 0.2712268829345703
Batch 56/64 loss: 0.2691800594329834
Batch 57/64 loss: 0.2612156271934509
Batch 58/64 loss: 0.265278697013855
Batch 59/64 loss: 0.2715054750442505
Batch 60/64 loss: 0.26533353328704834
Batch 61/64 loss: 0.2717142701148987
Batch 62/64 loss: 0.2717539072036743
Batch 63/64 loss: 0.2750067710876465
Batch 64/64 loss: 0.26769447326660156
Epoch 209  Train loss: 0.26907515806310317  Val loss: 0.28996820916834565
Epoch 210
-------------------------------
Batch 1/64 loss: 0.2660369873046875
Batch 2/64 loss: 0.26577383279800415
Batch 3/64 loss: 0.26586294174194336
Batch 4/64 loss: 0.2775624990463257
Batch 5/64 loss: 0.2765929698944092
Batch 6/64 loss: 0.26435917615890503
Batch 7/64 loss: 0.26982349157333374
Batch 8/64 loss: 0.26473087072372437
Batch 9/64 loss: 0.2717893123626709
Batch 10/64 loss: 0.2627275586128235
Batch 11/64 loss: 0.2678641080856323
Batch 12/64 loss: 0.265461266040802
Batch 13/64 loss: 0.27652209997177124
Batch 14/64 loss: 0.27865731716156006
Batch 15/64 loss: 0.26405107975006104
Batch 16/64 loss: 0.2719306945800781
Batch 17/64 loss: 0.26370716094970703
Batch 18/64 loss: 0.26059651374816895
Batch 19/64 loss: 0.26762133836746216
Batch 20/64 loss: 0.27061426639556885
Batch 21/64 loss: 0.2731230854988098
Batch 22/64 loss: 0.2735978364944458
Batch 23/64 loss: 0.2572622299194336
Batch 24/64 loss: 0.2560614347457886
Batch 25/64 loss: 0.26547151803970337
Batch 26/64 loss: 0.2661125063896179
Batch 27/64 loss: 0.26017147302627563
Batch 28/64 loss: 0.26051199436187744
Batch 29/64 loss: 0.28145134449005127
Batch 30/64 loss: 0.27025461196899414
Batch 31/64 loss: 0.26355671882629395
Batch 32/64 loss: 0.2674916982650757
Batch 33/64 loss: 0.26994168758392334
Batch 34/64 loss: 0.2646253705024719
Batch 35/64 loss: 0.2618972659111023
Batch 36/64 loss: 0.2747005224227905
Batch 37/64 loss: 0.27507084608078003
Batch 38/64 loss: 0.26919472217559814
Batch 39/64 loss: 0.2627497911453247
Batch 40/64 loss: 0.2704199552536011
Batch 41/64 loss: 0.26833295822143555
Batch 42/64 loss: 0.27106839418411255
Batch 43/64 loss: 0.2740060091018677
Batch 44/64 loss: 0.2713012099266052
Batch 45/64 loss: 0.26407408714294434
Batch 46/64 loss: 0.2614414095878601
Batch 47/64 loss: 0.2790168523788452
Batch 48/64 loss: 0.26928234100341797
Batch 49/64 loss: 0.2786548137664795
Batch 50/64 loss: 0.2655590772628784
Batch 51/64 loss: 0.2725738286972046
Batch 52/64 loss: 0.26711058616638184
Batch 53/64 loss: 0.2663198709487915
Batch 54/64 loss: 0.2639329433441162
Batch 55/64 loss: 0.2766064405441284
Batch 56/64 loss: 0.2705036401748657
Batch 57/64 loss: 0.26169705390930176
Batch 58/64 loss: 0.2761211395263672
Batch 59/64 loss: 0.2718545198440552
Batch 60/64 loss: 0.2706946134567261
Batch 61/64 loss: 0.2661224603652954
Batch 62/64 loss: 0.2721865773200989
Batch 63/64 loss: 0.2827664613723755
Batch 64/64 loss: 0.26711714267730713
Epoch 210  Train loss: 0.2688237998999801  Val loss: 0.2905398574481715
Epoch 211
-------------------------------
Batch 1/64 loss: 0.27948713302612305
Batch 2/64 loss: 0.271600604057312
Batch 3/64 loss: 0.2625124454498291
Batch 4/64 loss: 0.2600981593132019
Batch 5/64 loss: 0.27743279933929443
Batch 6/64 loss: 0.28851187229156494
Batch 7/64 loss: 0.27448344230651855
Batch 8/64 loss: 0.2666236162185669
Batch 9/64 loss: 0.2647356390953064
Batch 10/64 loss: 0.2567114233970642
Batch 11/64 loss: 0.2697852849960327
Batch 12/64 loss: 0.2652963399887085
Batch 13/64 loss: 0.26576387882232666
Batch 14/64 loss: 0.2709689140319824
Batch 15/64 loss: 0.26995235681533813
Batch 16/64 loss: 0.267267107963562
Batch 17/64 loss: 0.2692919969558716
Batch 18/64 loss: 0.26861000061035156
Batch 19/64 loss: 0.26619845628738403
Batch 20/64 loss: 0.2724500894546509
Batch 21/64 loss: 0.2644302248954773
Batch 22/64 loss: 0.26674848794937134
Batch 23/64 loss: 0.2634737491607666
Batch 24/64 loss: 0.2597033381462097
Batch 25/64 loss: 0.2705453038215637
Batch 26/64 loss: 0.2687293291091919
Batch 27/64 loss: 0.2560516595840454
Batch 28/64 loss: 0.2737404704093933
Batch 29/64 loss: 0.26221996545791626
Batch 30/64 loss: 0.26834720373153687
Batch 31/64 loss: 0.27547234296798706
Batch 32/64 loss: 0.2759460210800171
Batch 33/64 loss: 0.26398545503616333
Batch 34/64 loss: 0.2594350576400757
Batch 35/64 loss: 0.25530123710632324
Batch 36/64 loss: 0.27132415771484375
Batch 37/64 loss: 0.2663825750350952
Batch 38/64 loss: 0.26811814308166504
Batch 39/64 loss: 0.26285290718078613
Batch 40/64 loss: 0.2621009349822998
Batch 41/64 loss: 0.26669472455978394
Batch 42/64 loss: 0.26593518257141113
Batch 43/64 loss: 0.2660471200942993
Batch 44/64 loss: 0.26594293117523193
Batch 45/64 loss: 0.26470816135406494
Batch 46/64 loss: 0.2634528875350952
Batch 47/64 loss: 0.2640751004219055
Batch 48/64 loss: 0.27017199993133545
Batch 49/64 loss: 0.27207744121551514
Batch 50/64 loss: 0.26322758197784424
Batch 51/64 loss: 0.26630496978759766
Batch 52/64 loss: 0.28052276372909546
Batch 53/64 loss: 0.2639274597167969
Batch 54/64 loss: 0.2642385959625244
Batch 55/64 loss: 0.2669118642807007
Batch 56/64 loss: 0.2773643732070923
Batch 57/64 loss: 0.2706966996192932
Batch 58/64 loss: 0.2686537504196167
Batch 59/64 loss: 0.2658247947692871
Batch 60/64 loss: 0.2645743489265442
Batch 61/64 loss: 0.282004177570343
Batch 62/64 loss: 0.26671719551086426
Batch 63/64 loss: 0.2632976770401001
Batch 64/64 loss: 0.2637603282928467
Epoch 211  Train loss: 0.26766873995463053  Val loss: 0.289583098232951
Saving best model, epoch: 211
Epoch 212
-------------------------------
Batch 1/64 loss: 0.2633543610572815
Batch 2/64 loss: 0.2676852345466614
Batch 3/64 loss: 0.26674532890319824
Batch 4/64 loss: 0.2640359401702881
Batch 5/64 loss: 0.26201629638671875
Batch 6/64 loss: 0.27374160289764404
Batch 7/64 loss: 0.26140356063842773
Batch 8/64 loss: 0.2659926414489746
Batch 9/64 loss: 0.2634463310241699
Batch 10/64 loss: 0.27204710245132446
Batch 11/64 loss: 0.2769520878791809
Batch 12/64 loss: 0.2650570869445801
Batch 13/64 loss: 0.2745128273963928
Batch 14/64 loss: 0.2735196352005005
Batch 15/64 loss: 0.26312094926834106
Batch 16/64 loss: 0.2694387435913086
Batch 17/64 loss: 0.266182541847229
Batch 18/64 loss: 0.2727011442184448
Batch 19/64 loss: 0.26731860637664795
Batch 20/64 loss: 0.2755749225616455
Batch 21/64 loss: 0.2695479989051819
Batch 22/64 loss: 0.2731095552444458
Batch 23/64 loss: 0.26726657152175903
Batch 24/64 loss: 0.2749600410461426
Batch 25/64 loss: 0.27103567123413086
Batch 26/64 loss: 0.2728955149650574
Batch 27/64 loss: 0.2744782567024231
Batch 28/64 loss: 0.26700448989868164
Batch 29/64 loss: 0.27390438318252563
Batch 30/64 loss: 0.2615681290626526
Batch 31/64 loss: 0.26987504959106445
Batch 32/64 loss: 0.2766531705856323
Batch 33/64 loss: 0.2771725654602051
Batch 34/64 loss: 0.27419596910476685
Batch 35/64 loss: 0.26465916633605957
Batch 36/64 loss: 0.26921677589416504
Batch 37/64 loss: 0.28284525871276855
Batch 38/64 loss: 0.2613121271133423
Batch 39/64 loss: 0.2681393623352051
Batch 40/64 loss: 0.2604002356529236
Batch 41/64 loss: 0.2679382562637329
Batch 42/64 loss: 0.2659454345703125
Batch 43/64 loss: 0.2661411166191101
Batch 44/64 loss: 0.27066242694854736
Batch 45/64 loss: 0.2770841121673584
Batch 46/64 loss: 0.26837050914764404
Batch 47/64 loss: 0.26315855979919434
Batch 48/64 loss: 0.2701139450073242
Batch 49/64 loss: 0.2727311849594116
Batch 50/64 loss: 0.2608095407485962
Batch 51/64 loss: 0.25509554147720337
Batch 52/64 loss: 0.25973427295684814
Batch 53/64 loss: 0.2648658752441406
Batch 54/64 loss: 0.2705053687095642
Batch 55/64 loss: 0.26514720916748047
Batch 56/64 loss: 0.2750890254974365
Batch 57/64 loss: 0.26432132720947266
Batch 58/64 loss: 0.25804316997528076
Batch 59/64 loss: 0.27524077892303467
Batch 60/64 loss: 0.2773054838180542
Batch 61/64 loss: 0.2687516212463379
Batch 62/64 loss: 0.25903230905532837
Batch 63/64 loss: 0.2629058361053467
Batch 64/64 loss: 0.2755250930786133
Epoch 212  Train loss: 0.2685603758868049  Val loss: 0.2903929616987091
Epoch 213
-------------------------------
Batch 1/64 loss: 0.2726823091506958
Batch 2/64 loss: 0.2675192952156067
Batch 3/64 loss: 0.2746049165725708
Batch 4/64 loss: 0.26803386211395264
Batch 5/64 loss: 0.26888954639434814
Batch 6/64 loss: 0.2733933925628662
Batch 7/64 loss: 0.27270227670669556
Batch 8/64 loss: 0.261638343334198
Batch 9/64 loss: 0.2633196711540222
Batch 10/64 loss: 0.2645057439804077
Batch 11/64 loss: 0.2683448791503906
Batch 12/64 loss: 0.26027393341064453
Batch 13/64 loss: 0.2625349760055542
Batch 14/64 loss: 0.2714533805847168
Batch 15/64 loss: 0.26672089099884033
Batch 16/64 loss: 0.27175599336624146
Batch 17/64 loss: 0.2648738622665405
Batch 18/64 loss: 0.2691589593887329
Batch 19/64 loss: 0.2620842456817627
Batch 20/64 loss: 0.2699275016784668
Batch 21/64 loss: 0.25842559337615967
Batch 22/64 loss: 0.2732674479484558
Batch 23/64 loss: 0.2697187066078186
Batch 24/64 loss: 0.2684628963470459
Batch 25/64 loss: 0.2693859934806824
Batch 26/64 loss: 0.26997804641723633
Batch 27/64 loss: 0.26534461975097656
Batch 28/64 loss: 0.2633037567138672
Batch 29/64 loss: 0.2670334577560425
Batch 30/64 loss: 0.28336769342422485
Batch 31/64 loss: 0.26015448570251465
Batch 32/64 loss: 0.26557183265686035
Batch 33/64 loss: 0.27339452505111694
Batch 34/64 loss: 0.27002328634262085
Batch 35/64 loss: 0.27660638093948364
Batch 36/64 loss: 0.26560676097869873
Batch 37/64 loss: 0.2703360319137573
Batch 38/64 loss: 0.2653222680091858
Batch 39/64 loss: 0.2758297920227051
Batch 40/64 loss: 0.27160727977752686
Batch 41/64 loss: 0.27243274450302124
Batch 42/64 loss: 0.2815418839454651
Batch 43/64 loss: 0.2752651572227478
Batch 44/64 loss: 0.2630540132522583
Batch 45/64 loss: 0.27388858795166016
Batch 46/64 loss: 0.2715243697166443
Batch 47/64 loss: 0.2766898274421692
Batch 48/64 loss: 0.2707141637802124
Batch 49/64 loss: 0.273323655128479
Batch 50/64 loss: 0.26176244020462036
Batch 51/64 loss: 0.2637404799461365
Batch 52/64 loss: 0.2805436849594116
Batch 53/64 loss: 0.2610175609588623
Batch 54/64 loss: 0.2627990245819092
Batch 55/64 loss: 0.2642059922218323
Batch 56/64 loss: 0.27005261182785034
Batch 57/64 loss: 0.2615780830383301
Batch 58/64 loss: 0.27028781175613403
Batch 59/64 loss: 0.25809139013290405
Batch 60/64 loss: 0.26388466358184814
Batch 61/64 loss: 0.271476686000824
Batch 62/64 loss: 0.2712976336479187
Batch 63/64 loss: 0.2647545337677002
Batch 64/64 loss: 0.2675701975822449
Epoch 213  Train loss: 0.26857668208140956  Val loss: 0.28941282189588774
Saving best model, epoch: 213
Epoch 214
-------------------------------
Batch 1/64 loss: 0.2628633975982666
Batch 2/64 loss: 0.267392635345459
Batch 3/64 loss: 0.26481151580810547
Batch 4/64 loss: 0.27186131477355957
Batch 5/64 loss: 0.2642834186553955
Batch 6/64 loss: 0.2804015874862671
Batch 7/64 loss: 0.27857422828674316
Batch 8/64 loss: 0.2582917809486389
Batch 9/64 loss: 0.2605879306793213
Batch 10/64 loss: 0.26608216762542725
Batch 11/64 loss: 0.26647675037384033
Batch 12/64 loss: 0.2641545534133911
Batch 13/64 loss: 0.26558971405029297
Batch 14/64 loss: 0.2626461386680603
Batch 15/64 loss: 0.2677002549171448
Batch 16/64 loss: 0.2685878276824951
Batch 17/64 loss: 0.2660090923309326
Batch 18/64 loss: 0.26293623447418213
Batch 19/64 loss: 0.2720087170600891
Batch 20/64 loss: 0.2683170437812805
Batch 21/64 loss: 0.27799081802368164
Batch 22/64 loss: 0.2647193670272827
Batch 23/64 loss: 0.2690664529800415
Batch 24/64 loss: 0.26341938972473145
Batch 25/64 loss: 0.2663232088088989
Batch 26/64 loss: 0.2679978013038635
Batch 27/64 loss: 0.2702208161354065
Batch 28/64 loss: 0.26974278688430786
Batch 29/64 loss: 0.2694399356842041
Batch 30/64 loss: 0.2712847590446472
Batch 31/64 loss: 0.26616501808166504
Batch 32/64 loss: 0.27444589138031006
Batch 33/64 loss: 0.26641613245010376
Batch 34/64 loss: 0.26760292053222656
Batch 35/64 loss: 0.2729862928390503
Batch 36/64 loss: 0.2624173164367676
Batch 37/64 loss: 0.2714191675186157
Batch 38/64 loss: 0.26550352573394775
Batch 39/64 loss: 0.2741250991821289
Batch 40/64 loss: 0.2620750665664673
Batch 41/64 loss: 0.26594823598861694
Batch 42/64 loss: 0.27398860454559326
Batch 43/64 loss: 0.26277458667755127
Batch 44/64 loss: 0.2742152214050293
Batch 45/64 loss: 0.27270442247390747
Batch 46/64 loss: 0.26149940490722656
Batch 47/64 loss: 0.2600474953651428
Batch 48/64 loss: 0.2679005265235901
Batch 49/64 loss: 0.25774145126342773
Batch 50/64 loss: 0.27534186840057373
Batch 51/64 loss: 0.2610257863998413
Batch 52/64 loss: 0.2683071494102478
Batch 53/64 loss: 0.26690852642059326
Batch 54/64 loss: 0.2691378593444824
Batch 55/64 loss: 0.2639698386192322
Batch 56/64 loss: 0.2644592523574829
Batch 57/64 loss: 0.2699434757232666
Batch 58/64 loss: 0.262226939201355
Batch 59/64 loss: 0.26395368576049805
Batch 60/64 loss: 0.27503496408462524
Batch 61/64 loss: 0.27326834201812744
Batch 62/64 loss: 0.26705288887023926
Batch 63/64 loss: 0.2736946940422058
Batch 64/64 loss: 0.2736849784851074
Epoch 214  Train loss: 0.2677544631210028  Val loss: 0.2901215305443072
Epoch 215
-------------------------------
Batch 1/64 loss: 0.2583073377609253
Batch 2/64 loss: 0.2710946798324585
Batch 3/64 loss: 0.2718634605407715
Batch 4/64 loss: 0.2700432538986206
Batch 5/64 loss: 0.2629396915435791
Batch 6/64 loss: 0.2655641436576843
Batch 7/64 loss: 0.2678614854812622
Batch 8/64 loss: 0.26772749423980713
Batch 9/64 loss: 0.26867806911468506
Batch 10/64 loss: 0.2701306939125061
Batch 11/64 loss: 0.260925829410553
Batch 12/64 loss: 0.26355886459350586
Batch 13/64 loss: 0.2670539617538452
Batch 14/64 loss: 0.27039438486099243
Batch 15/64 loss: 0.27190226316452026
Batch 16/64 loss: 0.25537288188934326
Batch 17/64 loss: 0.26411378383636475
Batch 18/64 loss: 0.2696564197540283
Batch 19/64 loss: 0.2613487243652344
Batch 20/64 loss: 0.2643476724624634
Batch 21/64 loss: 0.265950083732605
Batch 22/64 loss: 0.27874696254730225
Batch 23/64 loss: 0.26143085956573486
Batch 24/64 loss: 0.2773197889328003
Batch 25/64 loss: 0.2713104486465454
Batch 26/64 loss: 0.2599451541900635
Batch 27/64 loss: 0.2627633213996887
Batch 28/64 loss: 0.2731146812438965
Batch 29/64 loss: 0.2704630494117737
Batch 30/64 loss: 0.2745199203491211
Batch 31/64 loss: 0.2646564245223999
Batch 32/64 loss: 0.26465100049972534
Batch 33/64 loss: 0.2597912549972534
Batch 34/64 loss: 0.2649662494659424
Batch 35/64 loss: 0.2686028480529785
Batch 36/64 loss: 0.26757287979125977
Batch 37/64 loss: 0.27239394187927246
Batch 38/64 loss: 0.26549363136291504
Batch 39/64 loss: 0.26249372959136963
Batch 40/64 loss: 0.26783812046051025
Batch 41/64 loss: 0.2699974775314331
Batch 42/64 loss: 0.2581709623336792
Batch 43/64 loss: 0.2705809473991394
Batch 44/64 loss: 0.26090967655181885
Batch 45/64 loss: 0.28023993968963623
Batch 46/64 loss: 0.2697256803512573
Batch 47/64 loss: 0.26858019828796387
Batch 48/64 loss: 0.2642277479171753
Batch 49/64 loss: 0.2702710032463074
Batch 50/64 loss: 0.26865774393081665
Batch 51/64 loss: 0.27289676666259766
Batch 52/64 loss: 0.26055800914764404
Batch 53/64 loss: 0.26634442806243896
Batch 54/64 loss: 0.2620745897293091
Batch 55/64 loss: 0.26587414741516113
Batch 56/64 loss: 0.2631107568740845
Batch 57/64 loss: 0.2740224003791809
Batch 58/64 loss: 0.26287776231765747
Batch 59/64 loss: 0.26117080450057983
Batch 60/64 loss: 0.26216888427734375
Batch 61/64 loss: 0.27581822872161865
Batch 62/64 loss: 0.26544368267059326
Batch 63/64 loss: 0.2794480323791504
Batch 64/64 loss: 0.2730531692504883
Epoch 215  Train loss: 0.2672136344161688  Val loss: 0.28897441273292723
Saving best model, epoch: 215
Epoch 216
-------------------------------
Batch 1/64 loss: 0.25453150272369385
Batch 2/64 loss: 0.2710126042366028
Batch 3/64 loss: 0.2728617787361145
Batch 4/64 loss: 0.26511073112487793
Batch 5/64 loss: 0.26333796977996826
Batch 6/64 loss: 0.2597452402114868
Batch 7/64 loss: 0.2715204954147339
Batch 8/64 loss: 0.2617630362510681
Batch 9/64 loss: 0.26233935356140137
Batch 10/64 loss: 0.263180673122406
Batch 11/64 loss: 0.25940507650375366
Batch 12/64 loss: 0.26354700326919556
Batch 13/64 loss: 0.26781660318374634
Batch 14/64 loss: 0.27464377880096436
Batch 15/64 loss: 0.25684118270874023
Batch 16/64 loss: 0.2806466221809387
Batch 17/64 loss: 0.25516557693481445
Batch 18/64 loss: 0.2687770128250122
Batch 19/64 loss: 0.2716761827468872
Batch 20/64 loss: 0.26141881942749023
Batch 21/64 loss: 0.2687579393386841
Batch 22/64 loss: 0.27154552936553955
Batch 23/64 loss: 0.2698523998260498
Batch 24/64 loss: 0.2715720534324646
Batch 25/64 loss: 0.27189964056015015
Batch 26/64 loss: 0.2637391686439514
Batch 27/64 loss: 0.26022404432296753
Batch 28/64 loss: 0.27397429943084717
Batch 29/64 loss: 0.26621711254119873
Batch 30/64 loss: 0.25845468044281006
Batch 31/64 loss: 0.2733273506164551
Batch 32/64 loss: 0.2602285146713257
Batch 33/64 loss: 0.2674481272697449
Batch 34/64 loss: 0.2613445520401001
Batch 35/64 loss: 0.25749635696411133
Batch 36/64 loss: 0.2693026661872864
Batch 37/64 loss: 0.27368009090423584
Batch 38/64 loss: 0.2674793004989624
Batch 39/64 loss: 0.2670532464981079
Batch 40/64 loss: 0.26493752002716064
Batch 41/64 loss: 0.26862919330596924
Batch 42/64 loss: 0.2685210704803467
Batch 43/64 loss: 0.2784043550491333
Batch 44/64 loss: 0.2761352062225342
Batch 45/64 loss: 0.26362282037734985
Batch 46/64 loss: 0.2654874324798584
Batch 47/64 loss: 0.2660475969314575
Batch 48/64 loss: 0.2699252963066101
Batch 49/64 loss: 0.2705342769622803
Batch 50/64 loss: 0.26807987689971924
Batch 51/64 loss: 0.27332019805908203
Batch 52/64 loss: 0.2689858675003052
Batch 53/64 loss: 0.2726978659629822
Batch 54/64 loss: 0.2631568908691406
Batch 55/64 loss: 0.27129697799682617
Batch 56/64 loss: 0.25867605209350586
Batch 57/64 loss: 0.2686343193054199
Batch 58/64 loss: 0.2719228267669678
Batch 59/64 loss: 0.2587754726409912
Batch 60/64 loss: 0.2659790515899658
Batch 61/64 loss: 0.2644028663635254
Batch 62/64 loss: 0.271373987197876
Batch 63/64 loss: 0.25620436668395996
Batch 64/64 loss: 0.2665424942970276
Epoch 216  Train loss: 0.2667387698210922  Val loss: 0.28830868640716134
Saving best model, epoch: 216
Epoch 217
-------------------------------
Batch 1/64 loss: 0.2739371061325073
Batch 2/64 loss: 0.26402246952056885
Batch 3/64 loss: 0.2604182958602905
Batch 4/64 loss: 0.2636526823043823
Batch 5/64 loss: 0.26521778106689453
Batch 6/64 loss: 0.26227307319641113
Batch 7/64 loss: 0.26511019468307495
Batch 8/64 loss: 0.2673664093017578
Batch 9/64 loss: 0.27253901958465576
Batch 10/64 loss: 0.26585328578948975
Batch 11/64 loss: 0.27387142181396484
Batch 12/64 loss: 0.27676767110824585
Batch 13/64 loss: 0.27442771196365356
Batch 14/64 loss: 0.26885032653808594
Batch 15/64 loss: 0.26142799854278564
Batch 16/64 loss: 0.2635563611984253
Batch 17/64 loss: 0.26198679208755493
Batch 18/64 loss: 0.26885151863098145
Batch 19/64 loss: 0.26341867446899414
Batch 20/64 loss: 0.2621579170227051
Batch 21/64 loss: 0.26837074756622314
Batch 22/64 loss: 0.26147496700286865
Batch 23/64 loss: 0.26308107376098633
Batch 24/64 loss: 0.2631281614303589
Batch 25/64 loss: 0.2638007402420044
Batch 26/64 loss: 0.2533833980560303
Batch 27/64 loss: 0.267757773399353
Batch 28/64 loss: 0.2731369733810425
Batch 29/64 loss: 0.2700708508491516
Batch 30/64 loss: 0.2618870139122009
Batch 31/64 loss: 0.272702157497406
Batch 32/64 loss: 0.2649562358856201
Batch 33/64 loss: 0.26167750358581543
Batch 34/64 loss: 0.26244550943374634
Batch 35/64 loss: 0.2593379020690918
Batch 36/64 loss: 0.2632705569267273
Batch 37/64 loss: 0.26956772804260254
Batch 38/64 loss: 0.27098381519317627
Batch 39/64 loss: 0.26737284660339355
Batch 40/64 loss: 0.2694162130355835
Batch 41/64 loss: 0.25533032417297363
Batch 42/64 loss: 0.2694929838180542
Batch 43/64 loss: 0.2713332176208496
Batch 44/64 loss: 0.25938481092453003
Batch 45/64 loss: 0.26237666606903076
Batch 46/64 loss: 0.26557356119155884
Batch 47/64 loss: 0.28008532524108887
Batch 48/64 loss: 0.26547539234161377
Batch 49/64 loss: 0.2723315358161926
Batch 50/64 loss: 0.26204514503479004
Batch 51/64 loss: 0.26177823543548584
Batch 52/64 loss: 0.2634207606315613
Batch 53/64 loss: 0.26382875442504883
Batch 54/64 loss: 0.27323830127716064
Batch 55/64 loss: 0.27352678775787354
Batch 56/64 loss: 0.2727147340774536
Batch 57/64 loss: 0.26639872789382935
Batch 58/64 loss: 0.2679011821746826
Batch 59/64 loss: 0.2603808641433716
Batch 60/64 loss: 0.2630411982536316
Batch 61/64 loss: 0.265433669090271
Batch 62/64 loss: 0.2689465284347534
Batch 63/64 loss: 0.2646910548210144
Batch 64/64 loss: 0.2616058588027954
Epoch 217  Train loss: 0.2661719691519644  Val loss: 0.287623434541971
Saving best model, epoch: 217
Epoch 218
-------------------------------
Batch 1/64 loss: 0.26924943923950195
Batch 2/64 loss: 0.27009284496307373
Batch 3/64 loss: 0.2677321434020996
Batch 4/64 loss: 0.26879405975341797
Batch 5/64 loss: 0.26001203060150146
Batch 6/64 loss: 0.2640042304992676
Batch 7/64 loss: 0.262098491191864
Batch 8/64 loss: 0.26043403148651123
Batch 9/64 loss: 0.26626062393188477
Batch 10/64 loss: 0.2674179673194885
Batch 11/64 loss: 0.2700350880622864
Batch 12/64 loss: 0.2630288600921631
Batch 13/64 loss: 0.2613106966018677
Batch 14/64 loss: 0.27123159170150757
Batch 15/64 loss: 0.25790417194366455
Batch 16/64 loss: 0.2702738642692566
Batch 17/64 loss: 0.2715620994567871
Batch 18/64 loss: 0.26691699028015137
Batch 19/64 loss: 0.2759491205215454
Batch 20/64 loss: 0.27036428451538086
Batch 21/64 loss: 0.268210232257843
Batch 22/64 loss: 0.25823116302490234
Batch 23/64 loss: 0.2738058567047119
Batch 24/64 loss: 0.26317495107650757
Batch 25/64 loss: 0.2601848840713501
Batch 26/64 loss: 0.2690531015396118
Batch 27/64 loss: 0.266748309135437
Batch 28/64 loss: 0.2590845823287964
Batch 29/64 loss: 0.2719980478286743
Batch 30/64 loss: 0.26593899726867676
Batch 31/64 loss: 0.26911795139312744
Batch 32/64 loss: 0.2638956904411316
Batch 33/64 loss: 0.2667611241340637
Batch 34/64 loss: 0.2775103449821472
Batch 35/64 loss: 0.26673638820648193
Batch 36/64 loss: 0.267319917678833
Batch 37/64 loss: 0.25911134481430054
Batch 38/64 loss: 0.2659536600112915
Batch 39/64 loss: 0.2639709711074829
Batch 40/64 loss: 0.26526153087615967
Batch 41/64 loss: 0.26826441287994385
Batch 42/64 loss: 0.26453977823257446
Batch 43/64 loss: 0.2666579484939575
Batch 44/64 loss: 0.2641366720199585
Batch 45/64 loss: 0.272991418838501
Batch 46/64 loss: 0.2627989649772644
Batch 47/64 loss: 0.259448766708374
Batch 48/64 loss: 0.27042126655578613
Batch 49/64 loss: 0.27341151237487793
Batch 50/64 loss: 0.2748848795890808
Batch 51/64 loss: 0.25780272483825684
Batch 52/64 loss: 0.2675884962081909
Batch 53/64 loss: 0.2760833501815796
Batch 54/64 loss: 0.2682785987854004
Batch 55/64 loss: 0.26100629568099976
Batch 56/64 loss: 0.2616550922393799
Batch 57/64 loss: 0.27082502841949463
Batch 58/64 loss: 0.2625880241394043
Batch 59/64 loss: 0.2678769826889038
Batch 60/64 loss: 0.2665446400642395
Batch 61/64 loss: 0.2683616876602173
Batch 62/64 loss: 0.2648658752441406
Batch 63/64 loss: 0.26669585704803467
Batch 64/64 loss: 0.2687774896621704
Epoch 218  Train loss: 0.2666047540365481  Val loss: 0.2893606866757894
Epoch 219
-------------------------------
Batch 1/64 loss: 0.2587559223175049
Batch 2/64 loss: 0.2628920078277588
Batch 3/64 loss: 0.2588402032852173
Batch 4/64 loss: 0.2605476379394531
Batch 5/64 loss: 0.2606990337371826
Batch 6/64 loss: 0.26618069410324097
Batch 7/64 loss: 0.2766764163970947
Batch 8/64 loss: 0.262897789478302
Batch 9/64 loss: 0.264143168926239
Batch 10/64 loss: 0.2660597562789917
Batch 11/64 loss: 0.2714465260505676
Batch 12/64 loss: 0.26522088050842285
Batch 13/64 loss: 0.2618730068206787
Batch 14/64 loss: 0.2598952651023865
Batch 15/64 loss: 0.26234734058380127
Batch 16/64 loss: 0.2622235417366028
Batch 17/64 loss: 0.26909875869750977
Batch 18/64 loss: 0.2618117928504944
Batch 19/64 loss: 0.26004600524902344
Batch 20/64 loss: 0.2632784843444824
Batch 21/64 loss: 0.26225292682647705
Batch 22/64 loss: 0.27275848388671875
Batch 23/64 loss: 0.2591259479522705
Batch 24/64 loss: 0.26537561416625977
Batch 25/64 loss: 0.2793869972229004
Batch 26/64 loss: 0.26630425453186035
Batch 27/64 loss: 0.26824140548706055
Batch 28/64 loss: 0.26228344440460205
Batch 29/64 loss: 0.26019251346588135
Batch 30/64 loss: 0.2705243229866028
Batch 31/64 loss: 0.2721520662307739
Batch 32/64 loss: 0.2700570225715637
Batch 33/64 loss: 0.2585211992263794
Batch 34/64 loss: 0.2703787088394165
Batch 35/64 loss: 0.27594006061553955
Batch 36/64 loss: 0.26109135150909424
Batch 37/64 loss: 0.2580125331878662
Batch 38/64 loss: 0.2673412561416626
Batch 39/64 loss: 0.273673415184021
Batch 40/64 loss: 0.2665896415710449
Batch 41/64 loss: 0.2746086120605469
Batch 42/64 loss: 0.2770843505859375
Batch 43/64 loss: 0.2694896459579468
Batch 44/64 loss: 0.27458858489990234
Batch 45/64 loss: 0.261883020401001
Batch 46/64 loss: 0.2603641748428345
Batch 47/64 loss: 0.2638108730316162
Batch 48/64 loss: 0.2616308331489563
Batch 49/64 loss: 0.28020334243774414
Batch 50/64 loss: 0.25548726320266724
Batch 51/64 loss: 0.2686900496482849
Batch 52/64 loss: 0.2661573886871338
Batch 53/64 loss: 0.2687654495239258
Batch 54/64 loss: 0.2788044214248657
Batch 55/64 loss: 0.2736521363258362
Batch 56/64 loss: 0.27073121070861816
Batch 57/64 loss: 0.2741338610649109
Batch 58/64 loss: 0.2667304277420044
Batch 59/64 loss: 0.2582985758781433
Batch 60/64 loss: 0.2628207206726074
Batch 61/64 loss: 0.26974523067474365
Batch 62/64 loss: 0.27384018898010254
Batch 63/64 loss: 0.2613462209701538
Batch 64/64 loss: 0.2735537886619568
Epoch 219  Train loss: 0.2665595187860377  Val loss: 0.2896567347533105
Epoch 220
-------------------------------
Batch 1/64 loss: 0.26531702280044556
Batch 2/64 loss: 0.2626267671585083
Batch 3/64 loss: 0.27687138319015503
Batch 4/64 loss: 0.2610433101654053
Batch 5/64 loss: 0.26655519008636475
Batch 6/64 loss: 0.2671944499015808
Batch 7/64 loss: 0.26577311754226685
Batch 8/64 loss: 0.26841485500335693
Batch 9/64 loss: 0.2619762420654297
Batch 10/64 loss: 0.2686711549758911
Batch 11/64 loss: 0.26628339290618896
Batch 12/64 loss: 0.2669197916984558
Batch 13/64 loss: 0.2577788829803467
Batch 14/64 loss: 0.27142220735549927
Batch 15/64 loss: 0.26883387565612793
Batch 16/64 loss: 0.2701539397239685
Batch 17/64 loss: 0.2658972144126892
Batch 18/64 loss: 0.270790159702301
Batch 19/64 loss: 0.2593069076538086
Batch 20/64 loss: 0.2622849941253662
Batch 21/64 loss: 0.2595953941345215
Batch 22/64 loss: 0.26685643196105957
Batch 23/64 loss: 0.25927305221557617
Batch 24/64 loss: 0.2688467502593994
Batch 25/64 loss: 0.26774728298187256
Batch 26/64 loss: 0.2615913152694702
Batch 27/64 loss: 0.26743030548095703
Batch 28/64 loss: 0.27545350790023804
Batch 29/64 loss: 0.2584998607635498
Batch 30/64 loss: 0.26358097791671753
Batch 31/64 loss: 0.267223596572876
Batch 32/64 loss: 0.2681539058685303
Batch 33/64 loss: 0.2552291750907898
Batch 34/64 loss: 0.2642168402671814
Batch 35/64 loss: 0.2589244842529297
Batch 36/64 loss: 0.258475661277771
Batch 37/64 loss: 0.2750779390335083
Batch 38/64 loss: 0.25865012407302856
Batch 39/64 loss: 0.26401251554489136
Batch 40/64 loss: 0.2729227542877197
Batch 41/64 loss: 0.2745457887649536
Batch 42/64 loss: 0.2670544385910034
Batch 43/64 loss: 0.26506030559539795
Batch 44/64 loss: 0.26758837699890137
Batch 45/64 loss: 0.266118586063385
Batch 46/64 loss: 0.2600955367088318
Batch 47/64 loss: 0.2634342908859253
Batch 48/64 loss: 0.2663344144821167
Batch 49/64 loss: 0.26001060009002686
Batch 50/64 loss: 0.2833733558654785
Batch 51/64 loss: 0.2560328245162964
Batch 52/64 loss: 0.2654494047164917
Batch 53/64 loss: 0.27918708324432373
Batch 54/64 loss: 0.2655695676803589
Batch 55/64 loss: 0.27383577823638916
Batch 56/64 loss: 0.27478086948394775
Batch 57/64 loss: 0.27438318729400635
Batch 58/64 loss: 0.2647098898887634
Batch 59/64 loss: 0.2707754373550415
Batch 60/64 loss: 0.2821943759918213
Batch 61/64 loss: 0.26237428188323975
Batch 62/64 loss: 0.2723127007484436
Batch 63/64 loss: 0.26238811016082764
Batch 64/64 loss: 0.2735059857368469
Epoch 220  Train loss: 0.26664494790282905  Val loss: 0.2907244589730227
Epoch 221
-------------------------------
Batch 1/64 loss: 0.2814585566520691
Batch 2/64 loss: 0.2688496708869934
Batch 3/64 loss: 0.2685604691505432
Batch 4/64 loss: 0.27099692821502686
Batch 5/64 loss: 0.26174604892730713
Batch 6/64 loss: 0.26592373847961426
Batch 7/64 loss: 0.2664451599121094
Batch 8/64 loss: 0.26659464836120605
Batch 9/64 loss: 0.2596103549003601
Batch 10/64 loss: 0.26500678062438965
Batch 11/64 loss: 0.2594820261001587
Batch 12/64 loss: 0.26838886737823486
Batch 13/64 loss: 0.2661786675453186
Batch 14/64 loss: 0.27345001697540283
Batch 15/64 loss: 0.2590675354003906
Batch 16/64 loss: 0.26872968673706055
Batch 17/64 loss: 0.26600968837738037
Batch 18/64 loss: 0.26152467727661133
Batch 19/64 loss: 0.26495110988616943
Batch 20/64 loss: 0.2737154960632324
Batch 21/64 loss: 0.2629559636116028
Batch 22/64 loss: 0.25755441188812256
Batch 23/64 loss: 0.26425135135650635
Batch 24/64 loss: 0.26678502559661865
Batch 25/64 loss: 0.26825976371765137
Batch 26/64 loss: 0.25903522968292236
Batch 27/64 loss: 0.2616182565689087
Batch 28/64 loss: 0.2785646915435791
Batch 29/64 loss: 0.2637995481491089
Batch 30/64 loss: 0.26440584659576416
Batch 31/64 loss: 0.2637133002281189
Batch 32/64 loss: 0.2783297300338745
Batch 33/64 loss: 0.26726675033569336
Batch 34/64 loss: 0.2669248580932617
Batch 35/64 loss: 0.2602502107620239
Batch 36/64 loss: 0.26349878311157227
Batch 37/64 loss: 0.2617999315261841
Batch 38/64 loss: 0.26516658067703247
Batch 39/64 loss: 0.26759982109069824
Batch 40/64 loss: 0.26333320140838623
Batch 41/64 loss: 0.27331435680389404
Batch 42/64 loss: 0.268363893032074
Batch 43/64 loss: 0.2578546404838562
Batch 44/64 loss: 0.2599521279335022
Batch 45/64 loss: 0.2673828601837158
Batch 46/64 loss: 0.27725642919540405
Batch 47/64 loss: 0.2690330743789673
Batch 48/64 loss: 0.26900768280029297
Batch 49/64 loss: 0.26841533184051514
Batch 50/64 loss: 0.258827805519104
Batch 51/64 loss: 0.2628498077392578
Batch 52/64 loss: 0.25977087020874023
Batch 53/64 loss: 0.2650079131126404
Batch 54/64 loss: 0.26494431495666504
Batch 55/64 loss: 0.26923513412475586
Batch 56/64 loss: 0.2671005129814148
Batch 57/64 loss: 0.26566803455352783
Batch 58/64 loss: 0.2669021487236023
Batch 59/64 loss: 0.2742888927459717
Batch 60/64 loss: 0.2622098922729492
Batch 61/64 loss: 0.2639533281326294
Batch 62/64 loss: 0.2683306932449341
Batch 63/64 loss: 0.2641732692718506
Batch 64/64 loss: 0.2659541368484497
Epoch 221  Train loss: 0.2661194039326088  Val loss: 0.2887751623936945
Epoch 222
-------------------------------
Batch 1/64 loss: 0.26640820503234863
Batch 2/64 loss: 0.27322322130203247
Batch 3/64 loss: 0.260551393032074
Batch 4/64 loss: 0.26846516132354736
Batch 5/64 loss: 0.2749677896499634
Batch 6/64 loss: 0.2747424840927124
Batch 7/64 loss: 0.27023839950561523
Batch 8/64 loss: 0.2716670036315918
Batch 9/64 loss: 0.27585458755493164
Batch 10/64 loss: 0.2626994252204895
Batch 11/64 loss: 0.26678359508514404
Batch 12/64 loss: 0.2741212844848633
Batch 13/64 loss: 0.2620219588279724
Batch 14/64 loss: 0.2643454074859619
Batch 15/64 loss: 0.26847749948501587
Batch 16/64 loss: 0.2656681537628174
Batch 17/64 loss: 0.2578189969062805
Batch 18/64 loss: 0.2689577341079712
Batch 19/64 loss: 0.257920503616333
Batch 20/64 loss: 0.27251821756362915
Batch 21/64 loss: 0.2616342306137085
Batch 22/64 loss: 0.25995659828186035
Batch 23/64 loss: 0.2675938010215759
Batch 24/64 loss: 0.2661300301551819
Batch 25/64 loss: 0.2664238214492798
Batch 26/64 loss: 0.2696031332015991
Batch 27/64 loss: 0.26595187187194824
Batch 28/64 loss: 0.26195406913757324
Batch 29/64 loss: 0.26646071672439575
Batch 30/64 loss: 0.265011191368103
Batch 31/64 loss: 0.2644176483154297
Batch 32/64 loss: 0.26825547218322754
Batch 33/64 loss: 0.26353251934051514
Batch 34/64 loss: 0.2536795139312744
Batch 35/64 loss: 0.2634814977645874
Batch 36/64 loss: 0.2635631561279297
Batch 37/64 loss: 0.2640659809112549
Batch 38/64 loss: 0.26841020584106445
Batch 39/64 loss: 0.2646191120147705
Batch 40/64 loss: 0.26382291316986084
Batch 41/64 loss: 0.26461076736450195
Batch 42/64 loss: 0.25213634967803955
Batch 43/64 loss: 0.2589966654777527
Batch 44/64 loss: 0.26180553436279297
Batch 45/64 loss: 0.2660505771636963
Batch 46/64 loss: 0.27375471591949463
Batch 47/64 loss: 0.2617621421813965
Batch 48/64 loss: 0.26769137382507324
Batch 49/64 loss: 0.2655274271965027
Batch 50/64 loss: 0.2649879455566406
Batch 51/64 loss: 0.27258431911468506
Batch 52/64 loss: 0.257981538772583
Batch 53/64 loss: 0.26136887073516846
Batch 54/64 loss: 0.26808929443359375
Batch 55/64 loss: 0.26701366901397705
Batch 56/64 loss: 0.25931811332702637
Batch 57/64 loss: 0.26334917545318604
Batch 58/64 loss: 0.2593269944190979
Batch 59/64 loss: 0.2663522958755493
Batch 60/64 loss: 0.26628535985946655
Batch 61/64 loss: 0.2635529637336731
Batch 62/64 loss: 0.2851600646972656
Batch 63/64 loss: 0.264606237411499
Batch 64/64 loss: 0.26159238815307617
Epoch 222  Train loss: 0.2656396108515122  Val loss: 0.2887593354146505
Epoch 223
-------------------------------
Batch 1/64 loss: 0.2539200186729431
Batch 2/64 loss: 0.25876736640930176
Batch 3/64 loss: 0.25794684886932373
Batch 4/64 loss: 0.263200581073761
Batch 5/64 loss: 0.25697338581085205
Batch 6/64 loss: 0.2588478922843933
Batch 7/64 loss: 0.2672010660171509
Batch 8/64 loss: 0.2641187906265259
Batch 9/64 loss: 0.26075828075408936
Batch 10/64 loss: 0.25598883628845215
Batch 11/64 loss: 0.2619234323501587
Batch 12/64 loss: 0.26656609773635864
Batch 13/64 loss: 0.2618914842605591
Batch 14/64 loss: 0.2672927975654602
Batch 15/64 loss: 0.27283596992492676
Batch 16/64 loss: 0.2614619731903076
Batch 17/64 loss: 0.26162803173065186
Batch 18/64 loss: 0.26016396284103394
Batch 19/64 loss: 0.2654651999473572
Batch 20/64 loss: 0.26509976387023926
Batch 21/64 loss: 0.26035749912261963
Batch 22/64 loss: 0.2568262815475464
Batch 23/64 loss: 0.25981438159942627
Batch 24/64 loss: 0.26746541261672974
Batch 25/64 loss: 0.26987290382385254
Batch 26/64 loss: 0.263541579246521
Batch 27/64 loss: 0.26915836334228516
Batch 28/64 loss: 0.257993221282959
Batch 29/64 loss: 0.2664072513580322
Batch 30/64 loss: 0.2654932141304016
Batch 31/64 loss: 0.27378547191619873
Batch 32/64 loss: 0.25796258449554443
Batch 33/64 loss: 0.2645747661590576
Batch 34/64 loss: 0.27122318744659424
Batch 35/64 loss: 0.2683761715888977
Batch 36/64 loss: 0.26489293575286865
Batch 37/64 loss: 0.2618154287338257
Batch 38/64 loss: 0.26941990852355957
Batch 39/64 loss: 0.26770544052124023
Batch 40/64 loss: 0.2683795690536499
Batch 41/64 loss: 0.2653856873512268
Batch 42/64 loss: 0.2659493684768677
Batch 43/64 loss: 0.2662503123283386
Batch 44/64 loss: 0.2602815628051758
Batch 45/64 loss: 0.27166861295700073
Batch 46/64 loss: 0.2663213014602661
Batch 47/64 loss: 0.2674880027770996
Batch 48/64 loss: 0.27456235885620117
Batch 49/64 loss: 0.2537252902984619
Batch 50/64 loss: 0.2673395872116089
Batch 51/64 loss: 0.2654527425765991
Batch 52/64 loss: 0.2689220905303955
Batch 53/64 loss: 0.2592201232910156
Batch 54/64 loss: 0.2685338258743286
Batch 55/64 loss: 0.26664793491363525
Batch 56/64 loss: 0.2712899446487427
Batch 57/64 loss: 0.26707661151885986
Batch 58/64 loss: 0.2670300006866455
Batch 59/64 loss: 0.2704986333847046
Batch 60/64 loss: 0.2713005542755127
Batch 61/64 loss: 0.2689805030822754
Batch 62/64 loss: 0.2777990698814392
Batch 63/64 loss: 0.2638634443283081
Batch 64/64 loss: 0.26858556270599365
Epoch 223  Train loss: 0.26500618177301744  Val loss: 0.2878824054580374
Epoch 224
-------------------------------
Batch 1/64 loss: 0.2673377990722656
Batch 2/64 loss: 0.2746935486793518
Batch 3/64 loss: 0.2617737054824829
Batch 4/64 loss: 0.2700387239456177
Batch 5/64 loss: 0.25958776473999023
Batch 6/64 loss: 0.2647501230239868
Batch 7/64 loss: 0.26747429370880127
Batch 8/64 loss: 0.2603660821914673
Batch 9/64 loss: 0.2627906799316406
Batch 10/64 loss: 0.2666666507720947
Batch 11/64 loss: 0.25757700204849243
Batch 12/64 loss: 0.2675971984863281
Batch 13/64 loss: 0.2658875584602356
Batch 14/64 loss: 0.26213181018829346
Batch 15/64 loss: 0.26300573348999023
Batch 16/64 loss: 0.2624906301498413
Batch 17/64 loss: 0.26416873931884766
Batch 18/64 loss: 0.25994062423706055
Batch 19/64 loss: 0.26780909299850464
Batch 20/64 loss: 0.2682901620864868
Batch 21/64 loss: 0.26138949394226074
Batch 22/64 loss: 0.2632378935813904
Batch 23/64 loss: 0.25467753410339355
Batch 24/64 loss: 0.2749323844909668
Batch 25/64 loss: 0.2648512125015259
Batch 26/64 loss: 0.2731889486312866
Batch 27/64 loss: 0.2573462724685669
Batch 28/64 loss: 0.2814421057701111
Batch 29/64 loss: 0.2691636085510254
Batch 30/64 loss: 0.26170146465301514
Batch 31/64 loss: 0.26528114080429077
Batch 32/64 loss: 0.26642149686813354
Batch 33/64 loss: 0.25409209728240967
Batch 34/64 loss: 0.2581794261932373
Batch 35/64 loss: 0.25701308250427246
Batch 36/64 loss: 0.26732468605041504
Batch 37/64 loss: 0.26151490211486816
Batch 38/64 loss: 0.2642301321029663
Batch 39/64 loss: 0.2592509388923645
Batch 40/64 loss: 0.27121472358703613
Batch 41/64 loss: 0.27383875846862793
Batch 42/64 loss: 0.2626710534095764
Batch 43/64 loss: 0.26106464862823486
Batch 44/64 loss: 0.2666984796524048
Batch 45/64 loss: 0.26540547609329224
Batch 46/64 loss: 0.2659212350845337
Batch 47/64 loss: 0.2645382285118103
Batch 48/64 loss: 0.27238982915878296
Batch 49/64 loss: 0.26597368717193604
Batch 50/64 loss: 0.26916950941085815
Batch 51/64 loss: 0.26460593938827515
Batch 52/64 loss: 0.2645500898361206
Batch 53/64 loss: 0.2612649202346802
Batch 54/64 loss: 0.2740246057510376
Batch 55/64 loss: 0.263092041015625
Batch 56/64 loss: 0.274993896484375
Batch 57/64 loss: 0.26231276988983154
Batch 58/64 loss: 0.2756105661392212
Batch 59/64 loss: 0.2693279981613159
Batch 60/64 loss: 0.26359671354293823
Batch 61/64 loss: 0.2681713104248047
Batch 62/64 loss: 0.26143360137939453
Batch 63/64 loss: 0.26455843448638916
Batch 64/64 loss: 0.2658785581588745
Epoch 224  Train loss: 0.2653404577105653  Val loss: 0.2893040632873876
Epoch 225
-------------------------------
Batch 1/64 loss: 0.2662106156349182
Batch 2/64 loss: 0.26519501209259033
Batch 3/64 loss: 0.27848607301712036
Batch 4/64 loss: 0.27491676807403564
Batch 5/64 loss: 0.2594034671783447
Batch 6/64 loss: 0.27089542150497437
Batch 7/64 loss: 0.2672574520111084
Batch 8/64 loss: 0.26065540313720703
Batch 9/64 loss: 0.2603883743286133
Batch 10/64 loss: 0.2551616430282593
Batch 11/64 loss: 0.2563456892967224
Batch 12/64 loss: 0.26006489992141724
Batch 13/64 loss: 0.26527953147888184
Batch 14/64 loss: 0.2724330425262451
Batch 15/64 loss: 0.2674548625946045
Batch 16/64 loss: 0.25897473096847534
Batch 17/64 loss: 0.25914984941482544
Batch 18/64 loss: 0.2710409164428711
Batch 19/64 loss: 0.2623162865638733
Batch 20/64 loss: 0.2650892734527588
Batch 21/64 loss: 0.26356041431427
Batch 22/64 loss: 0.26514530181884766
Batch 23/64 loss: 0.28038883209228516
Batch 24/64 loss: 0.26120638847351074
Batch 25/64 loss: 0.2618175148963928
Batch 26/64 loss: 0.25835978984832764
Batch 27/64 loss: 0.2588050365447998
Batch 28/64 loss: 0.25478678941726685
Batch 29/64 loss: 0.2689114212989807
Batch 30/64 loss: 0.2688397765159607
Batch 31/64 loss: 0.2715226411819458
Batch 32/64 loss: 0.2633413076400757
Batch 33/64 loss: 0.26027244329452515
Batch 34/64 loss: 0.262592613697052
Batch 35/64 loss: 0.25754159688949585
Batch 36/64 loss: 0.25717973709106445
Batch 37/64 loss: 0.2609872817993164
Batch 38/64 loss: 0.27846574783325195
Batch 39/64 loss: 0.2716929316520691
Batch 40/64 loss: 0.2710827589035034
Batch 41/64 loss: 0.26143884658813477
Batch 42/64 loss: 0.2573050260543823
Batch 43/64 loss: 0.27105188369750977
Batch 44/64 loss: 0.2557356357574463
Batch 45/64 loss: 0.263023316860199
Batch 46/64 loss: 0.263466477394104
Batch 47/64 loss: 0.26520413160324097
Batch 48/64 loss: 0.2563896179199219
Batch 49/64 loss: 0.26994454860687256
Batch 50/64 loss: 0.272807240486145
Batch 51/64 loss: 0.2738889455795288
Batch 52/64 loss: 0.2696961760520935
Batch 53/64 loss: 0.27404820919036865
Batch 54/64 loss: 0.2666332721710205
Batch 55/64 loss: 0.25851672887802124
Batch 56/64 loss: 0.2696188688278198
Batch 57/64 loss: 0.2680940628051758
Batch 58/64 loss: 0.25914353132247925
Batch 59/64 loss: 0.2683086395263672
Batch 60/64 loss: 0.2621748447418213
Batch 61/64 loss: 0.260036826133728
Batch 62/64 loss: 0.2667893171310425
Batch 63/64 loss: 0.2674033045768738
Batch 64/64 loss: 0.25552845001220703
Epoch 225  Train loss: 0.2648719282711253  Val loss: 0.28853021024428693
Epoch 226
-------------------------------
Batch 1/64 loss: 0.25630664825439453
Batch 2/64 loss: 0.2666592597961426
Batch 3/64 loss: 0.2692175507545471
Batch 4/64 loss: 0.26444995403289795
Batch 5/64 loss: 0.270174503326416
Batch 6/64 loss: 0.2612765431404114
Batch 7/64 loss: 0.25918853282928467
Batch 8/64 loss: 0.2624676823616028
Batch 9/64 loss: 0.2686866521835327
Batch 10/64 loss: 0.2660186290740967
Batch 11/64 loss: 0.2624436616897583
Batch 12/64 loss: 0.2696833610534668
Batch 13/64 loss: 0.27224981784820557
Batch 14/64 loss: 0.26854074001312256
Batch 15/64 loss: 0.2655831575393677
Batch 16/64 loss: 0.259446382522583
Batch 17/64 loss: 0.26400482654571533
Batch 18/64 loss: 0.26895570755004883
Batch 19/64 loss: 0.27282702922821045
Batch 20/64 loss: 0.2674369215965271
Batch 21/64 loss: 0.27522361278533936
Batch 22/64 loss: 0.26518261432647705
Batch 23/64 loss: 0.25446534156799316
Batch 24/64 loss: 0.264198362827301
Batch 25/64 loss: 0.27708542346954346
Batch 26/64 loss: 0.2726248502731323
Batch 27/64 loss: 0.2632160186767578
Batch 28/64 loss: 0.25239068269729614
Batch 29/64 loss: 0.2588869333267212
Batch 30/64 loss: 0.25579458475112915
Batch 31/64 loss: 0.25598788261413574
Batch 32/64 loss: 0.26156407594680786
Batch 33/64 loss: 0.26201343536376953
Batch 34/64 loss: 0.264614462852478
Batch 35/64 loss: 0.26488733291625977
Batch 36/64 loss: 0.26647794246673584
Batch 37/64 loss: 0.2687627077102661
Batch 38/64 loss: 0.26573795080184937
Batch 39/64 loss: 0.26545947790145874
Batch 40/64 loss: 0.2622948884963989
Batch 41/64 loss: 0.2649877071380615
Batch 42/64 loss: 0.2661328911781311
Batch 43/64 loss: 0.2647538185119629
Batch 44/64 loss: 0.26060670614242554
Batch 45/64 loss: 0.2707158327102661
Batch 46/64 loss: 0.25786256790161133
Batch 47/64 loss: 0.27530401945114136
Batch 48/64 loss: 0.26014113426208496
Batch 49/64 loss: 0.2631371021270752
Batch 50/64 loss: 0.25841081142425537
Batch 51/64 loss: 0.25475406646728516
Batch 52/64 loss: 0.2631133794784546
Batch 53/64 loss: 0.278476357460022
Batch 54/64 loss: 0.26671266555786133
Batch 55/64 loss: 0.2725406289100647
Batch 56/64 loss: 0.2607995271682739
Batch 57/64 loss: 0.2725565433502197
Batch 58/64 loss: 0.26024627685546875
Batch 59/64 loss: 0.2775508761405945
Batch 60/64 loss: 0.27027612924575806
Batch 61/64 loss: 0.2538691759109497
Batch 62/64 loss: 0.2741560935974121
Batch 63/64 loss: 0.2587782144546509
Batch 64/64 loss: 0.2578125
Epoch 226  Train loss: 0.2649682830361759  Val loss: 0.2897724789852129
Epoch 227
-------------------------------
Batch 1/64 loss: 0.26601314544677734
Batch 2/64 loss: 0.26653409004211426
Batch 3/64 loss: 0.25343191623687744
Batch 4/64 loss: 0.2609604001045227
Batch 5/64 loss: 0.2615063190460205
Batch 6/64 loss: 0.26173222064971924
Batch 7/64 loss: 0.25769561529159546
Batch 8/64 loss: 0.26034486293792725
Batch 9/64 loss: 0.25978344678878784
Batch 10/64 loss: 0.2724299430847168
Batch 11/64 loss: 0.25622260570526123
Batch 12/64 loss: 0.2620905637741089
Batch 13/64 loss: 0.27564501762390137
Batch 14/64 loss: 0.2520413398742676
Batch 15/64 loss: 0.27196240425109863
Batch 16/64 loss: 0.2705802917480469
Batch 17/64 loss: 0.25819534063339233
Batch 18/64 loss: 0.26698076725006104
Batch 19/64 loss: 0.25818169116973877
Batch 20/64 loss: 0.26252663135528564
Batch 21/64 loss: 0.2644573450088501
Batch 22/64 loss: 0.2650432586669922
Batch 23/64 loss: 0.26270151138305664
Batch 24/64 loss: 0.26166754961013794
Batch 25/64 loss: 0.2703835964202881
Batch 26/64 loss: 0.25813937187194824
Batch 27/64 loss: 0.2612212896347046
Batch 28/64 loss: 0.26953816413879395
Batch 29/64 loss: 0.26972538232803345
Batch 30/64 loss: 0.2620930075645447
Batch 31/64 loss: 0.2663644552230835
Batch 32/64 loss: 0.26349925994873047
Batch 33/64 loss: 0.2706213593482971
Batch 34/64 loss: 0.2576290965080261
Batch 35/64 loss: 0.2693135738372803
Batch 36/64 loss: 0.2602652311325073
Batch 37/64 loss: 0.2645224332809448
Batch 38/64 loss: 0.2769815921783447
Batch 39/64 loss: 0.2636798024177551
Batch 40/64 loss: 0.26095354557037354
Batch 41/64 loss: 0.2662872076034546
Batch 42/64 loss: 0.2621966600418091
Batch 43/64 loss: 0.2595405578613281
Batch 44/64 loss: 0.2737652063369751
Batch 45/64 loss: 0.2723677158355713
Batch 46/64 loss: 0.27052587270736694
Batch 47/64 loss: 0.2651233673095703
Batch 48/64 loss: 0.26340609788894653
Batch 49/64 loss: 0.26944679021835327
Batch 50/64 loss: 0.2699858546257019
Batch 51/64 loss: 0.2627871036529541
Batch 52/64 loss: 0.26729416847229004
Batch 53/64 loss: 0.26603615283966064
Batch 54/64 loss: 0.2645711898803711
Batch 55/64 loss: 0.2626674771308899
Batch 56/64 loss: 0.26324158906936646
Batch 57/64 loss: 0.2683687210083008
Batch 58/64 loss: 0.27185213565826416
Batch 59/64 loss: 0.26343047618865967
Batch 60/64 loss: 0.26786720752716064
Batch 61/64 loss: 0.26461321115493774
Batch 62/64 loss: 0.26874840259552
Batch 63/64 loss: 0.2689874768257141
Batch 64/64 loss: 0.25552141666412354
Epoch 227  Train loss: 0.2647593904944027  Val loss: 0.28733228817838163
Saving best model, epoch: 227
Epoch 228
-------------------------------
Batch 1/64 loss: 0.26244068145751953
Batch 2/64 loss: 0.2643367052078247
Batch 3/64 loss: 0.26535558700561523
Batch 4/64 loss: 0.2624623775482178
Batch 5/64 loss: 0.2702326774597168
Batch 6/64 loss: 0.2641066312789917
Batch 7/64 loss: 0.2679309844970703
Batch 8/64 loss: 0.26935458183288574
Batch 9/64 loss: 0.26891422271728516
Batch 10/64 loss: 0.2641589641571045
Batch 11/64 loss: 0.268191933631897
Batch 12/64 loss: 0.2632722854614258
Batch 13/64 loss: 0.27101457118988037
Batch 14/64 loss: 0.258567214012146
Batch 15/64 loss: 0.2734639644622803
Batch 16/64 loss: 0.2611147165298462
Batch 17/64 loss: 0.250257670879364
Batch 18/64 loss: 0.2611006498336792
Batch 19/64 loss: 0.2591390609741211
Batch 20/64 loss: 0.2572000026702881
Batch 21/64 loss: 0.26548802852630615
Batch 22/64 loss: 0.25738072395324707
Batch 23/64 loss: 0.266981840133667
Batch 24/64 loss: 0.26149487495422363
Batch 25/64 loss: 0.2575693130493164
Batch 26/64 loss: 0.25915420055389404
Batch 27/64 loss: 0.2693434953689575
Batch 28/64 loss: 0.263185977935791
Batch 29/64 loss: 0.25791120529174805
Batch 30/64 loss: 0.25579559803009033
Batch 31/64 loss: 0.2740265130996704
Batch 32/64 loss: 0.2598578929901123
Batch 33/64 loss: 0.2620922327041626
Batch 34/64 loss: 0.2698812484741211
Batch 35/64 loss: 0.2740037441253662
Batch 36/64 loss: 0.2661728858947754
Batch 37/64 loss: 0.26848363876342773
Batch 38/64 loss: 0.259130597114563
Batch 39/64 loss: 0.26480579376220703
Batch 40/64 loss: 0.27376270294189453
Batch 41/64 loss: 0.2617543339729309
Batch 42/64 loss: 0.26267021894454956
Batch 43/64 loss: 0.2577807903289795
Batch 44/64 loss: 0.2593262195587158
Batch 45/64 loss: 0.26357901096343994
Batch 46/64 loss: 0.2611246109008789
Batch 47/64 loss: 0.2587355375289917
Batch 48/64 loss: 0.26514530181884766
Batch 49/64 loss: 0.2595463991165161
Batch 50/64 loss: 0.2596774101257324
Batch 51/64 loss: 0.26414257287979126
Batch 52/64 loss: 0.2658529281616211
Batch 53/64 loss: 0.25787055492401123
Batch 54/64 loss: 0.26452499628067017
Batch 55/64 loss: 0.2721596956253052
Batch 56/64 loss: 0.26652175188064575
Batch 57/64 loss: 0.26849764585494995
Batch 58/64 loss: 0.26993894577026367
Batch 59/64 loss: 0.2703520655632019
Batch 60/64 loss: 0.26373767852783203
Batch 61/64 loss: 0.2619287371635437
Batch 62/64 loss: 0.260731041431427
Batch 63/64 loss: 0.2663249969482422
Batch 64/64 loss: 0.2623939514160156
Epoch 228  Train loss: 0.2639663827185537  Val loss: 0.2887918527183664
Epoch 229
-------------------------------
Batch 1/64 loss: 0.2748984098434448
Batch 2/64 loss: 0.2616722583770752
Batch 3/64 loss: 0.2611740827560425
Batch 4/64 loss: 0.26171040534973145
Batch 5/64 loss: 0.2569756507873535
Batch 6/64 loss: 0.2713509798049927
Batch 7/64 loss: 0.2525455355644226
Batch 8/64 loss: 0.25432151556015015
Batch 9/64 loss: 0.26408851146698
Batch 10/64 loss: 0.2658195495605469
Batch 11/64 loss: 0.26833856105804443
Batch 12/64 loss: 0.26236259937286377
Batch 13/64 loss: 0.25417542457580566
Batch 14/64 loss: 0.2635914087295532
Batch 15/64 loss: 0.26117146015167236
Batch 16/64 loss: 0.2648719549179077
Batch 17/64 loss: 0.26862215995788574
Batch 18/64 loss: 0.255179762840271
Batch 19/64 loss: 0.25949203968048096
Batch 20/64 loss: 0.26843559741973877
Batch 21/64 loss: 0.2600005865097046
Batch 22/64 loss: 0.26396989822387695
Batch 23/64 loss: 0.26302778720855713
Batch 24/64 loss: 0.2702442407608032
Batch 25/64 loss: 0.2607489824295044
Batch 26/64 loss: 0.2586219310760498
Batch 27/64 loss: 0.26165181398391724
Batch 28/64 loss: 0.26315581798553467
Batch 29/64 loss: 0.25735604763031006
Batch 30/64 loss: 0.2651008367538452
Batch 31/64 loss: 0.2578312158584595
Batch 32/64 loss: 0.26640641689300537
Batch 33/64 loss: 0.2634729743003845
Batch 34/64 loss: 0.2758330702781677
Batch 35/64 loss: 0.26880180835723877
Batch 36/64 loss: 0.2651042342185974
Batch 37/64 loss: 0.26519709825515747
Batch 38/64 loss: 0.2723708152770996
Batch 39/64 loss: 0.2599766254425049
Batch 40/64 loss: 0.265593945980072
Batch 41/64 loss: 0.26477479934692383
Batch 42/64 loss: 0.28150635957717896
Batch 43/64 loss: 0.26768505573272705
Batch 44/64 loss: 0.2683151960372925
Batch 45/64 loss: 0.25629377365112305
Batch 46/64 loss: 0.25335144996643066
Batch 47/64 loss: 0.2629373073577881
Batch 48/64 loss: 0.25872135162353516
Batch 49/64 loss: 0.25950026512145996
Batch 50/64 loss: 0.2538943886756897
Batch 51/64 loss: 0.2659282088279724
Batch 52/64 loss: 0.26782315969467163
Batch 53/64 loss: 0.2587859630584717
Batch 54/64 loss: 0.27157777547836304
Batch 55/64 loss: 0.2677621841430664
Batch 56/64 loss: 0.2580028772354126
Batch 57/64 loss: 0.2682204246520996
Batch 58/64 loss: 0.2657541036605835
Batch 59/64 loss: 0.26048481464385986
Batch 60/64 loss: 0.26345157623291016
Batch 61/64 loss: 0.2637823224067688
Batch 62/64 loss: 0.2657896876335144
Batch 63/64 loss: 0.2576538920402527
Batch 64/64 loss: 0.26728177070617676
Epoch 229  Train loss: 0.26349368282392915  Val loss: 0.28826968960745636
Epoch 230
-------------------------------
Batch 1/64 loss: 0.26126354932785034
Batch 2/64 loss: 0.2599964737892151
Batch 3/64 loss: 0.2591499090194702
Batch 4/64 loss: 0.2618831396102905
Batch 5/64 loss: 0.2586956024169922
Batch 6/64 loss: 0.2588183879852295
Batch 7/64 loss: 0.27039074897766113
Batch 8/64 loss: 0.2635989189147949
Batch 9/64 loss: 0.2569376230239868
Batch 10/64 loss: 0.26933878660202026
Batch 11/64 loss: 0.2596398591995239
Batch 12/64 loss: 0.26701629161834717
Batch 13/64 loss: 0.2658300995826721
Batch 14/64 loss: 0.2663155198097229
Batch 15/64 loss: 0.266277551651001
Batch 16/64 loss: 0.25527262687683105
Batch 17/64 loss: 0.2524435520172119
Batch 18/64 loss: 0.25318753719329834
Batch 19/64 loss: 0.2646704316139221
Batch 20/64 loss: 0.26648932695388794
Batch 21/64 loss: 0.26185840368270874
Batch 22/64 loss: 0.263847291469574
Batch 23/64 loss: 0.26795411109924316
Batch 24/64 loss: 0.2610146403312683
Batch 25/64 loss: 0.26153671741485596
Batch 26/64 loss: 0.26242947578430176
Batch 27/64 loss: 0.25979292392730713
Batch 28/64 loss: 0.26123517751693726
Batch 29/64 loss: 0.2634100914001465
Batch 30/64 loss: 0.2674473524093628
Batch 31/64 loss: 0.26157623529434204
Batch 32/64 loss: 0.2631279230117798
Batch 33/64 loss: 0.2620837688446045
Batch 34/64 loss: 0.25394511222839355
Batch 35/64 loss: 0.26701295375823975
Batch 36/64 loss: 0.25727617740631104
Batch 37/64 loss: 0.2569003701210022
Batch 38/64 loss: 0.27278828620910645
Batch 39/64 loss: 0.2688583731651306
Batch 40/64 loss: 0.27759772539138794
Batch 41/64 loss: 0.2564941644668579
Batch 42/64 loss: 0.2752612233161926
Batch 43/64 loss: 0.2627220153808594
Batch 44/64 loss: 0.2573215961456299
Batch 45/64 loss: 0.2624567151069641
Batch 46/64 loss: 0.26278263330459595
Batch 47/64 loss: 0.25935351848602295
Batch 48/64 loss: 0.2554718255996704
Batch 49/64 loss: 0.26837158203125
Batch 50/64 loss: 0.26755475997924805
Batch 51/64 loss: 0.2583427429199219
Batch 52/64 loss: 0.2641185522079468
Batch 53/64 loss: 0.2723996639251709
Batch 54/64 loss: 0.26516854763031006
Batch 55/64 loss: 0.2693409323692322
Batch 56/64 loss: 0.2674061059951782
Batch 57/64 loss: 0.25959575176239014
Batch 58/64 loss: 0.2585184574127197
Batch 59/64 loss: 0.2579774856567383
Batch 60/64 loss: 0.2590444087982178
Batch 61/64 loss: 0.2658662796020508
Batch 62/64 loss: 0.2771121859550476
Batch 63/64 loss: 0.26657164096832275
Batch 64/64 loss: 0.25954902172088623
Epoch 230  Train loss: 0.26310311532488057  Val loss: 0.28869502446086137
Epoch 231
-------------------------------
Batch 1/64 loss: 0.26033705472946167
Batch 2/64 loss: 0.25852060317993164
Batch 3/64 loss: 0.2552512288093567
Batch 4/64 loss: 0.25940489768981934
Batch 5/64 loss: 0.2639526128768921
Batch 6/64 loss: 0.2501751184463501
Batch 7/64 loss: 0.25518059730529785
Batch 8/64 loss: 0.2527284026145935
Batch 9/64 loss: 0.2537182569503784
Batch 10/64 loss: 0.25624924898147583
Batch 11/64 loss: 0.2815535068511963
Batch 12/64 loss: 0.2634071707725525
Batch 13/64 loss: 0.26171547174453735
Batch 14/64 loss: 0.2559599280357361
Batch 15/64 loss: 0.2652340531349182
Batch 16/64 loss: 0.2602226138114929
Batch 17/64 loss: 0.26094210147857666
Batch 18/64 loss: 0.26150381565093994
Batch 19/64 loss: 0.26301872730255127
Batch 20/64 loss: 0.26123303174972534
Batch 21/64 loss: 0.2627134323120117
Batch 22/64 loss: 0.2574790120124817
Batch 23/64 loss: 0.24986201524734497
Batch 24/64 loss: 0.2679867148399353
Batch 25/64 loss: 0.2598426342010498
Batch 26/64 loss: 0.261898398399353
Batch 27/64 loss: 0.27563631534576416
Batch 28/64 loss: 0.2774553894996643
Batch 29/64 loss: 0.2739403247833252
Batch 30/64 loss: 0.2667057514190674
Batch 31/64 loss: 0.26254260540008545
Batch 32/64 loss: 0.26815974712371826
Batch 33/64 loss: 0.26529860496520996
Batch 34/64 loss: 0.2625918388366699
Batch 35/64 loss: 0.2533515691757202
Batch 36/64 loss: 0.27015507221221924
Batch 37/64 loss: 0.2561686038970947
Batch 38/64 loss: 0.25959253311157227
Batch 39/64 loss: 0.2693415880203247
Batch 40/64 loss: 0.26233720779418945
Batch 41/64 loss: 0.2723463773727417
Batch 42/64 loss: 0.2632334232330322
Batch 43/64 loss: 0.26310670375823975
Batch 44/64 loss: 0.25382745265960693
Batch 45/64 loss: 0.2592587471008301
Batch 46/64 loss: 0.2771800756454468
Batch 47/64 loss: 0.26489585638046265
Batch 48/64 loss: 0.27400702238082886
Batch 49/64 loss: 0.2738020420074463
Batch 50/64 loss: 0.26709800958633423
Batch 51/64 loss: 0.26897263526916504
Batch 52/64 loss: 0.26989203691482544
Batch 53/64 loss: 0.27674639225006104
Batch 54/64 loss: 0.2660248279571533
Batch 55/64 loss: 0.2633747458457947
Batch 56/64 loss: 0.272083044052124
Batch 57/64 loss: 0.2616047263145447
Batch 58/64 loss: 0.26093900203704834
Batch 59/64 loss: 0.2624436020851135
Batch 60/64 loss: 0.2649298906326294
Batch 61/64 loss: 0.2651742696762085
Batch 62/64 loss: 0.26525449752807617
Batch 63/64 loss: 0.2612413167953491
Batch 64/64 loss: 0.2668246626853943
Epoch 231  Train loss: 0.2637007528660344  Val loss: 0.28923157646074327
Epoch 232
-------------------------------
Batch 1/64 loss: 0.25701165199279785
Batch 2/64 loss: 0.27057158946990967
Batch 3/64 loss: 0.27013808488845825
Batch 4/64 loss: 0.2618345022201538
Batch 5/64 loss: 0.26870548725128174
Batch 6/64 loss: 0.2687901258468628
Batch 7/64 loss: 0.26314181089401245
Batch 8/64 loss: 0.2589341402053833
Batch 9/64 loss: 0.25725364685058594
Batch 10/64 loss: 0.26936376094818115
Batch 11/64 loss: 0.261081337928772
Batch 12/64 loss: 0.2688865661621094
Batch 13/64 loss: 0.2787640690803528
Batch 14/64 loss: 0.26374518871307373
Batch 15/64 loss: 0.26229196786880493
Batch 16/64 loss: 0.2574959993362427
Batch 17/64 loss: 0.2546042203903198
Batch 18/64 loss: 0.26659083366394043
Batch 19/64 loss: 0.2709314823150635
Batch 20/64 loss: 0.25905096530914307
Batch 21/64 loss: 0.2592674493789673
Batch 22/64 loss: 0.2572399377822876
Batch 23/64 loss: 0.2557474374771118
Batch 24/64 loss: 0.25344550609588623
Batch 25/64 loss: 0.2612786889076233
Batch 26/64 loss: 0.27364957332611084
Batch 27/64 loss: 0.26258206367492676
Batch 28/64 loss: 0.25682562589645386
Batch 29/64 loss: 0.25608086585998535
Batch 30/64 loss: 0.2552459239959717
Batch 31/64 loss: 0.2539212703704834
Batch 32/64 loss: 0.2636209726333618
Batch 33/64 loss: 0.26426082849502563
Batch 34/64 loss: 0.25438380241394043
Batch 35/64 loss: 0.2645527720451355
Batch 36/64 loss: 0.2575540542602539
Batch 37/64 loss: 0.2559020519256592
Batch 38/64 loss: 0.2715926170349121
Batch 39/64 loss: 0.2634497880935669
Batch 40/64 loss: 0.2689096927642822
Batch 41/64 loss: 0.2746185064315796
Batch 42/64 loss: 0.27491652965545654
Batch 43/64 loss: 0.2572544813156128
Batch 44/64 loss: 0.2716394066810608
Batch 45/64 loss: 0.27388352155685425
Batch 46/64 loss: 0.26358044147491455
Batch 47/64 loss: 0.2638155221939087
Batch 48/64 loss: 0.26175135374069214
Batch 49/64 loss: 0.2592765688896179
Batch 50/64 loss: 0.2668795585632324
Batch 51/64 loss: 0.2661036252975464
Batch 52/64 loss: 0.26281464099884033
Batch 53/64 loss: 0.2715758681297302
Batch 54/64 loss: 0.26308155059814453
Batch 55/64 loss: 0.26708054542541504
Batch 56/64 loss: 0.2718244791030884
Batch 57/64 loss: 0.2650795578956604
Batch 58/64 loss: 0.26425623893737793
Batch 59/64 loss: 0.25753843784332275
Batch 60/64 loss: 0.26809918880462646
Batch 61/64 loss: 0.2586180567741394
Batch 62/64 loss: 0.26372629404067993
Batch 63/64 loss: 0.260333776473999
Batch 64/64 loss: 0.2532541751861572
Epoch 232  Train loss: 0.263472739387961  Val loss: 0.2874579876149233
Epoch 233
-------------------------------
Batch 1/64 loss: 0.2733338475227356
Batch 2/64 loss: 0.2584053874015808
Batch 3/64 loss: 0.2614501714706421
Batch 4/64 loss: 0.2665674090385437
Batch 5/64 loss: 0.2601413130760193
Batch 6/64 loss: 0.264789879322052
Batch 7/64 loss: 0.2603379487991333
Batch 8/64 loss: 0.25888872146606445
Batch 9/64 loss: 0.2652420997619629
Batch 10/64 loss: 0.2561916708946228
Batch 11/64 loss: 0.2612265348434448
Batch 12/64 loss: 0.2576320171356201
Batch 13/64 loss: 0.2576636075973511
Batch 14/64 loss: 0.26514220237731934
Batch 15/64 loss: 0.2698439955711365
Batch 16/64 loss: 0.259645938873291
Batch 17/64 loss: 0.24802172183990479
Batch 18/64 loss: 0.2638702392578125
Batch 19/64 loss: 0.2618556618690491
Batch 20/64 loss: 0.2605794072151184
Batch 21/64 loss: 0.2592146396636963
Batch 22/64 loss: 0.25621289014816284
Batch 23/64 loss: 0.268854558467865
Batch 24/64 loss: 0.2621750235557556
Batch 25/64 loss: 0.26568782329559326
Batch 26/64 loss: 0.26000165939331055
Batch 27/64 loss: 0.263716459274292
Batch 28/64 loss: 0.26758480072021484
Batch 29/64 loss: 0.271930456161499
Batch 30/64 loss: 0.25491583347320557
Batch 31/64 loss: 0.2665681838989258
Batch 32/64 loss: 0.2606184482574463
Batch 33/64 loss: 0.2628781795501709
Batch 34/64 loss: 0.26438164710998535
Batch 35/64 loss: 0.25986015796661377
Batch 36/64 loss: 0.25842225551605225
Batch 37/64 loss: 0.26326167583465576
Batch 38/64 loss: 0.2680943012237549
Batch 39/64 loss: 0.25796520709991455
Batch 40/64 loss: 0.2657623887062073
Batch 41/64 loss: 0.26605093479156494
Batch 42/64 loss: 0.2590862512588501
Batch 43/64 loss: 0.27114343643188477
Batch 44/64 loss: 0.26130008697509766
Batch 45/64 loss: 0.27122175693511963
Batch 46/64 loss: 0.26390165090560913
Batch 47/64 loss: 0.26211249828338623
Batch 48/64 loss: 0.27235519886016846
Batch 49/64 loss: 0.26279759407043457
Batch 50/64 loss: 0.26168662309646606
Batch 51/64 loss: 0.26439952850341797
Batch 52/64 loss: 0.2556079030036926
Batch 53/64 loss: 0.2619365453720093
Batch 54/64 loss: 0.2571881413459778
Batch 55/64 loss: 0.25383543968200684
Batch 56/64 loss: 0.2630690336227417
Batch 57/64 loss: 0.2652488946914673
Batch 58/64 loss: 0.2679774761199951
Batch 59/64 loss: 0.2568078637123108
Batch 60/64 loss: 0.2700406312942505
Batch 61/64 loss: 0.27266013622283936
Batch 62/64 loss: 0.26693445444107056
Batch 63/64 loss: 0.2621390223503113
Batch 64/64 loss: 0.26614099740982056
Epoch 233  Train loss: 0.2628712661126081  Val loss: 0.28894059088631596
Epoch 234
-------------------------------
Batch 1/64 loss: 0.2577589750289917
Batch 2/64 loss: 0.2624936103820801
Batch 3/64 loss: 0.26058852672576904
Batch 4/64 loss: 0.262282133102417
Batch 5/64 loss: 0.2652939558029175
Batch 6/64 loss: 0.2607126832008362
Batch 7/64 loss: 0.2628697156906128
Batch 8/64 loss: 0.25976210832595825
Batch 9/64 loss: 0.2511582374572754
Batch 10/64 loss: 0.262454092502594
Batch 11/64 loss: 0.2843893766403198
Batch 12/64 loss: 0.27055561542510986
Batch 13/64 loss: 0.26253652572631836
Batch 14/64 loss: 0.2598581910133362
Batch 15/64 loss: 0.2688038945198059
Batch 16/64 loss: 0.2598714828491211
Batch 17/64 loss: 0.2625475525856018
Batch 18/64 loss: 0.27331459522247314
Batch 19/64 loss: 0.26709771156311035
Batch 20/64 loss: 0.2653505802154541
Batch 21/64 loss: 0.2626124620437622
Batch 22/64 loss: 0.2725924253463745
Batch 23/64 loss: 0.2682141065597534
Batch 24/64 loss: 0.25941145420074463
Batch 25/64 loss: 0.25653791427612305
Batch 26/64 loss: 0.2653074264526367
Batch 27/64 loss: 0.26362156867980957
Batch 28/64 loss: 0.2642574906349182
Batch 29/64 loss: 0.258530855178833
Batch 30/64 loss: 0.2667957544326782
Batch 31/64 loss: 0.2667762041091919
Batch 32/64 loss: 0.2599046230316162
Batch 33/64 loss: 0.284069299697876
Batch 34/64 loss: 0.26864397525787354
Batch 35/64 loss: 0.25967931747436523
Batch 36/64 loss: 0.2636983394622803
Batch 37/64 loss: 0.255692720413208
Batch 38/64 loss: 0.2656219005584717
Batch 39/64 loss: 0.26310253143310547
Batch 40/64 loss: 0.2608259916305542
Batch 41/64 loss: 0.2602788209915161
Batch 42/64 loss: 0.2620953917503357
Batch 43/64 loss: 0.2615737318992615
Batch 44/64 loss: 0.262873113155365
Batch 45/64 loss: 0.2594703435897827
Batch 46/64 loss: 0.2539193630218506
Batch 47/64 loss: 0.2610297203063965
Batch 48/64 loss: 0.2540474534034729
Batch 49/64 loss: 0.25853997468948364
Batch 50/64 loss: 0.26367998123168945
Batch 51/64 loss: 0.2648566961288452
Batch 52/64 loss: 0.25840383768081665
Batch 53/64 loss: 0.25677424669265747
Batch 54/64 loss: 0.2623475193977356
Batch 55/64 loss: 0.2571028470993042
Batch 56/64 loss: 0.2557196617126465
Batch 57/64 loss: 0.267048180103302
Batch 58/64 loss: 0.26019448041915894
Batch 59/64 loss: 0.2635784149169922
Batch 60/64 loss: 0.2618982791900635
Batch 61/64 loss: 0.26827532052993774
Batch 62/64 loss: 0.2529451251029968
Batch 63/64 loss: 0.25784510374069214
Batch 64/64 loss: 0.2639898657798767
Epoch 234  Train loss: 0.2627150734265645  Val loss: 0.28793473260099534
Epoch 235
-------------------------------
Batch 1/64 loss: 0.2576178312301636
Batch 2/64 loss: 0.2693803310394287
Batch 3/64 loss: 0.2621827721595764
Batch 4/64 loss: 0.2679312229156494
Batch 5/64 loss: 0.2542264461517334
Batch 6/64 loss: 0.26636314392089844
Batch 7/64 loss: 0.26458990573883057
Batch 8/64 loss: 0.2528858184814453
Batch 9/64 loss: 0.2589181065559387
Batch 10/64 loss: 0.26604682207107544
Batch 11/64 loss: 0.267148494720459
Batch 12/64 loss: 0.2681628465652466
Batch 13/64 loss: 0.25940632820129395
Batch 14/64 loss: 0.26344454288482666
Batch 15/64 loss: 0.26660406589508057
Batch 16/64 loss: 0.26504361629486084
Batch 17/64 loss: 0.2618199586868286
Batch 18/64 loss: 0.26453328132629395
Batch 19/64 loss: 0.2583273649215698
Batch 20/64 loss: 0.2660837173461914
Batch 21/64 loss: 0.2541975975036621
Batch 22/64 loss: 0.2571219205856323
Batch 23/64 loss: 0.26657551527023315
Batch 24/64 loss: 0.2591683864593506
Batch 25/64 loss: 0.25622355937957764
Batch 26/64 loss: 0.2562544345855713
Batch 27/64 loss: 0.2586345672607422
Batch 28/64 loss: 0.2568168640136719
Batch 29/64 loss: 0.2653179168701172
Batch 30/64 loss: 0.25332367420196533
Batch 31/64 loss: 0.2529754042625427
Batch 32/64 loss: 0.25648176670074463
Batch 33/64 loss: 0.25785160064697266
Batch 34/64 loss: 0.2562401294708252
Batch 35/64 loss: 0.25707894563674927
Batch 36/64 loss: 0.25405848026275635
Batch 37/64 loss: 0.25381243228912354
Batch 38/64 loss: 0.2565803527832031
Batch 39/64 loss: 0.2572540044784546
Batch 40/64 loss: 0.27015697956085205
Batch 41/64 loss: 0.25883960723876953
Batch 42/64 loss: 0.27214932441711426
Batch 43/64 loss: 0.2679988145828247
Batch 44/64 loss: 0.2519311308860779
Batch 45/64 loss: 0.2600071430206299
Batch 46/64 loss: 0.26590240001678467
Batch 47/64 loss: 0.2684509754180908
Batch 48/64 loss: 0.26548194885253906
Batch 49/64 loss: 0.2718536853790283
Batch 50/64 loss: 0.26838934421539307
Batch 51/64 loss: 0.26492345333099365
Batch 52/64 loss: 0.26391732692718506
Batch 53/64 loss: 0.2588734030723572
Batch 54/64 loss: 0.2653723359107971
Batch 55/64 loss: 0.2710694670677185
Batch 56/64 loss: 0.2628328800201416
Batch 57/64 loss: 0.265189528465271
Batch 58/64 loss: 0.2540348172187805
Batch 59/64 loss: 0.2715585231781006
Batch 60/64 loss: 0.2600367069244385
Batch 61/64 loss: 0.26917916536331177
Batch 62/64 loss: 0.2632138133049011
Batch 63/64 loss: 0.26160764694213867
Batch 64/64 loss: 0.2731335163116455
Epoch 235  Train loss: 0.26203144671870215  Val loss: 0.2874127999204131
Epoch 236
-------------------------------
Batch 1/64 loss: 0.26576846837997437
Batch 2/64 loss: 0.2627284526824951
Batch 3/64 loss: 0.26114362478256226
Batch 4/64 loss: 0.2688145637512207
Batch 5/64 loss: 0.2574862241744995
Batch 6/64 loss: 0.25843966007232666
Batch 7/64 loss: 0.2561686635017395
Batch 8/64 loss: 0.268074095249176
Batch 9/64 loss: 0.2610507011413574
Batch 10/64 loss: 0.260190486907959
Batch 11/64 loss: 0.2557235360145569
Batch 12/64 loss: 0.26422548294067383
Batch 13/64 loss: 0.25685179233551025
Batch 14/64 loss: 0.2660501003265381
Batch 15/64 loss: 0.25829648971557617
Batch 16/64 loss: 0.2667192220687866
Batch 17/64 loss: 0.26480191946029663
Batch 18/64 loss: 0.25753581523895264
Batch 19/64 loss: 0.26727819442749023
Batch 20/64 loss: 0.24995017051696777
Batch 21/64 loss: 0.25666022300720215
Batch 22/64 loss: 0.27025794982910156
Batch 23/64 loss: 0.25885719060897827
Batch 24/64 loss: 0.257615864276886
Batch 25/64 loss: 0.26083362102508545
Batch 26/64 loss: 0.26320505142211914
Batch 27/64 loss: 0.26533031463623047
Batch 28/64 loss: 0.26823848485946655
Batch 29/64 loss: 0.2609894275665283
Batch 30/64 loss: 0.2606136202812195
Batch 31/64 loss: 0.27568763494491577
Batch 32/64 loss: 0.267957866191864
Batch 33/64 loss: 0.2679230570793152
Batch 34/64 loss: 0.26546674966812134
Batch 35/64 loss: 0.25766539573669434
Batch 36/64 loss: 0.2553168535232544
Batch 37/64 loss: 0.26645588874816895
Batch 38/64 loss: 0.26533979177474976
Batch 39/64 loss: 0.2673313617706299
Batch 40/64 loss: 0.2659822702407837
Batch 41/64 loss: 0.2645145654678345
Batch 42/64 loss: 0.2632181644439697
Batch 43/64 loss: 0.27253395318984985
Batch 44/64 loss: 0.2657160758972168
Batch 45/64 loss: 0.2635599970817566
Batch 46/64 loss: 0.25516271591186523
Batch 47/64 loss: 0.25930947065353394
Batch 48/64 loss: 0.26316916942596436
Batch 49/64 loss: 0.27245092391967773
Batch 50/64 loss: 0.26308107376098633
Batch 51/64 loss: 0.2513120174407959
Batch 52/64 loss: 0.26058340072631836
Batch 53/64 loss: 0.2593654990196228
Batch 54/64 loss: 0.27096647024154663
Batch 55/64 loss: 0.26260101795196533
Batch 56/64 loss: 0.25874704122543335
Batch 57/64 loss: 0.26825010776519775
Batch 58/64 loss: 0.2552352547645569
Batch 59/64 loss: 0.25351381301879883
Batch 60/64 loss: 0.25939708948135376
Batch 61/64 loss: 0.27111780643463135
Batch 62/64 loss: 0.27135491371154785
Batch 63/64 loss: 0.2629109025001526
Batch 64/64 loss: 0.26872217655181885
Epoch 236  Train loss: 0.2628178722718183  Val loss: 0.28778443344679894
Epoch 237
-------------------------------
Batch 1/64 loss: 0.2629086971282959
Batch 2/64 loss: 0.25997841358184814
Batch 3/64 loss: 0.2556734085083008
Batch 4/64 loss: 0.2689657211303711
Batch 5/64 loss: 0.25730133056640625
Batch 6/64 loss: 0.26328152418136597
Batch 7/64 loss: 0.25377678871154785
Batch 8/64 loss: 0.2597924470901489
Batch 9/64 loss: 0.2615512013435364
Batch 10/64 loss: 0.2599005103111267
Batch 11/64 loss: 0.2569819688796997
Batch 12/64 loss: 0.257230281829834
Batch 13/64 loss: 0.2538102865219116
Batch 14/64 loss: 0.2566307783126831
Batch 15/64 loss: 0.2607295513153076
Batch 16/64 loss: 0.2610466480255127
Batch 17/64 loss: 0.2549126148223877
Batch 18/64 loss: 0.25604796409606934
Batch 19/64 loss: 0.2503548860549927
Batch 20/64 loss: 0.2634139657020569
Batch 21/64 loss: 0.26632118225097656
Batch 22/64 loss: 0.26488161087036133
Batch 23/64 loss: 0.2680763006210327
Batch 24/64 loss: 0.262517511844635
Batch 25/64 loss: 0.2648206353187561
Batch 26/64 loss: 0.2600444555282593
Batch 27/64 loss: 0.260165810585022
Batch 28/64 loss: 0.2619816064834595
Batch 29/64 loss: 0.25857460498809814
Batch 30/64 loss: 0.27139586210250854
Batch 31/64 loss: 0.25704461336135864
Batch 32/64 loss: 0.27930670976638794
Batch 33/64 loss: 0.2713339924812317
Batch 34/64 loss: 0.2558557391166687
Batch 35/64 loss: 0.2558457851409912
Batch 36/64 loss: 0.26247936487197876
Batch 37/64 loss: 0.26355278491973877
Batch 38/64 loss: 0.25738197565078735
Batch 39/64 loss: 0.2596069574356079
Batch 40/64 loss: 0.2597891092300415
Batch 41/64 loss: 0.2597973346710205
Batch 42/64 loss: 0.2749596834182739
Batch 43/64 loss: 0.25233036279678345
Batch 44/64 loss: 0.2735961675643921
Batch 45/64 loss: 0.24566078186035156
Batch 46/64 loss: 0.26016664505004883
Batch 47/64 loss: 0.2735843062400818
Batch 48/64 loss: 0.2660778760910034
Batch 49/64 loss: 0.2555351257324219
Batch 50/64 loss: 0.2615928649902344
Batch 51/64 loss: 0.26066625118255615
Batch 52/64 loss: 0.2643048167228699
Batch 53/64 loss: 0.2633754014968872
Batch 54/64 loss: 0.26576876640319824
Batch 55/64 loss: 0.261465847492218
Batch 56/64 loss: 0.2618502974510193
Batch 57/64 loss: 0.2658882141113281
Batch 58/64 loss: 0.27687835693359375
Batch 59/64 loss: 0.26549774408340454
Batch 60/64 loss: 0.26370203495025635
Batch 61/64 loss: 0.2627965807914734
Batch 62/64 loss: 0.2638927698135376
Batch 63/64 loss: 0.26624763011932373
Batch 64/64 loss: 0.2666279077529907
Epoch 237  Train loss: 0.26197446888568354  Val loss: 0.2861691537181946
Saving best model, epoch: 237
Epoch 238
-------------------------------
Batch 1/64 loss: 0.2640184164047241
Batch 2/64 loss: 0.263388991355896
Batch 3/64 loss: 0.26115942001342773
Batch 4/64 loss: 0.268404483795166
Batch 5/64 loss: 0.26276731491088867
Batch 6/64 loss: 0.2584083080291748
Batch 7/64 loss: 0.2555459141731262
Batch 8/64 loss: 0.2550485134124756
Batch 9/64 loss: 0.2554572820663452
Batch 10/64 loss: 0.2620142102241516
Batch 11/64 loss: 0.254091739654541
Batch 12/64 loss: 0.2647361755371094
Batch 13/64 loss: 0.2738744616508484
Batch 14/64 loss: 0.25185513496398926
Batch 15/64 loss: 0.2667011618614197
Batch 16/64 loss: 0.2541007995605469
Batch 17/64 loss: 0.2653326988220215
Batch 18/64 loss: 0.26539039611816406
Batch 19/64 loss: 0.261552095413208
Batch 20/64 loss: 0.26228833198547363
Batch 21/64 loss: 0.25609785318374634
Batch 22/64 loss: 0.2619868516921997
Batch 23/64 loss: 0.26849496364593506
Batch 24/64 loss: 0.2589305639266968
Batch 25/64 loss: 0.2704653739929199
Batch 26/64 loss: 0.2611846923828125
Batch 27/64 loss: 0.26330268383026123
Batch 28/64 loss: 0.25827229022979736
Batch 29/64 loss: 0.25886499881744385
Batch 30/64 loss: 0.26133692264556885
Batch 31/64 loss: 0.2637638449668884
Batch 32/64 loss: 0.26733243465423584
Batch 33/64 loss: 0.2617950439453125
Batch 34/64 loss: 0.2590447664260864
Batch 35/64 loss: 0.2598915696144104
Batch 36/64 loss: 0.2565355896949768
Batch 37/64 loss: 0.2645035982131958
Batch 38/64 loss: 0.26225847005844116
Batch 39/64 loss: 0.25699615478515625
Batch 40/64 loss: 0.25653183460235596
Batch 41/64 loss: 0.26157963275909424
Batch 42/64 loss: 0.258669912815094
Batch 43/64 loss: 0.26595592498779297
Batch 44/64 loss: 0.2628708481788635
Batch 45/64 loss: 0.2714008688926697
Batch 46/64 loss: 0.2736625075340271
Batch 47/64 loss: 0.2637171745300293
Batch 48/64 loss: 0.2636643052101135
Batch 49/64 loss: 0.26045310497283936
Batch 50/64 loss: 0.2548512816429138
Batch 51/64 loss: 0.25942009687423706
Batch 52/64 loss: 0.26464593410491943
Batch 53/64 loss: 0.2538570165634155
Batch 54/64 loss: 0.2671775221824646
Batch 55/64 loss: 0.26995575428009033
Batch 56/64 loss: 0.26217877864837646
Batch 57/64 loss: 0.2713649868965149
Batch 58/64 loss: 0.26484084129333496
Batch 59/64 loss: 0.2604596018791199
Batch 60/64 loss: 0.2657632827758789
Batch 61/64 loss: 0.26069700717926025
Batch 62/64 loss: 0.26179957389831543
Batch 63/64 loss: 0.2634391188621521
Batch 64/64 loss: 0.2582736015319824
Epoch 238  Train loss: 0.2621153981077905  Val loss: 0.28912715813548295
Epoch 239
-------------------------------
Batch 1/64 loss: 0.2595817446708679
Batch 2/64 loss: 0.2777153253555298
Batch 3/64 loss: 0.25332021713256836
Batch 4/64 loss: 0.2649382948875427
Batch 5/64 loss: 0.2578237056732178
Batch 6/64 loss: 0.2647913098335266
Batch 7/64 loss: 0.2627291679382324
Batch 8/64 loss: 0.27031946182250977
Batch 9/64 loss: 0.2609350085258484
Batch 10/64 loss: 0.25644052028656006
Batch 11/64 loss: 0.2621139883995056
Batch 12/64 loss: 0.26441729068756104
Batch 13/64 loss: 0.2690095901489258
Batch 14/64 loss: 0.2584414482116699
Batch 15/64 loss: 0.2622632384300232
Batch 16/64 loss: 0.25716543197631836
Batch 17/64 loss: 0.25744324922561646
Batch 18/64 loss: 0.263141930103302
Batch 19/64 loss: 0.272552490234375
Batch 20/64 loss: 0.2502704858779907
Batch 21/64 loss: 0.25467032194137573
Batch 22/64 loss: 0.27327215671539307
Batch 23/64 loss: 0.2633444666862488
Batch 24/64 loss: 0.26114577054977417
Batch 25/64 loss: 0.25960826873779297
Batch 26/64 loss: 0.25718700885772705
Batch 27/64 loss: 0.27715760469436646
Batch 28/64 loss: 0.2526339888572693
Batch 29/64 loss: 0.2535449266433716
Batch 30/64 loss: 0.26025301218032837
Batch 31/64 loss: 0.25527966022491455
Batch 32/64 loss: 0.26400697231292725
Batch 33/64 loss: 0.26648473739624023
Batch 34/64 loss: 0.26505130529403687
Batch 35/64 loss: 0.2565723657608032
Batch 36/64 loss: 0.2653436064720154
Batch 37/64 loss: 0.2684519290924072
Batch 38/64 loss: 0.27019888162612915
Batch 39/64 loss: 0.26133978366851807
Batch 40/64 loss: 0.2693992853164673
Batch 41/64 loss: 0.2587616443634033
Batch 42/64 loss: 0.273260235786438
Batch 43/64 loss: 0.2669728994369507
Batch 44/64 loss: 0.26135051250457764
Batch 45/64 loss: 0.2541297674179077
Batch 46/64 loss: 0.26169121265411377
Batch 47/64 loss: 0.2700824737548828
Batch 48/64 loss: 0.25921905040740967
Batch 49/64 loss: 0.26916539669036865
Batch 50/64 loss: 0.2599950432777405
Batch 51/64 loss: 0.25713229179382324
Batch 52/64 loss: 0.26300859451293945
Batch 53/64 loss: 0.2630695104598999
Batch 54/64 loss: 0.2693965435028076
Batch 55/64 loss: 0.25967371463775635
Batch 56/64 loss: 0.261968195438385
Batch 57/64 loss: 0.26243340969085693
Batch 58/64 loss: 0.2689526081085205
Batch 59/64 loss: 0.2610347867012024
Batch 60/64 loss: 0.2707807421684265
Batch 61/64 loss: 0.25845324993133545
Batch 62/64 loss: 0.2587679624557495
Batch 63/64 loss: 0.2672905921936035
Batch 64/64 loss: 0.2626792788505554
Epoch 239  Train loss: 0.2628072133251265  Val loss: 0.2882376745394415
Epoch 240
-------------------------------
Batch 1/64 loss: 0.24788892269134521
Batch 2/64 loss: 0.2615222930908203
Batch 3/64 loss: 0.2589993476867676
Batch 4/64 loss: 0.2660928964614868
Batch 5/64 loss: 0.264970064163208
Batch 6/64 loss: 0.2624375820159912
Batch 7/64 loss: 0.25838810205459595
Batch 8/64 loss: 0.25834017992019653
Batch 9/64 loss: 0.25769495964050293
Batch 10/64 loss: 0.25049376487731934
Batch 11/64 loss: 0.27149271965026855
Batch 12/64 loss: 0.25859928131103516
Batch 13/64 loss: 0.2597324848175049
Batch 14/64 loss: 0.2503906488418579
Batch 15/64 loss: 0.26653146743774414
Batch 16/64 loss: 0.27689898014068604
Batch 17/64 loss: 0.2621828317642212
Batch 18/64 loss: 0.2683420181274414
Batch 19/64 loss: 0.26712727546691895
Batch 20/64 loss: 0.2663840055465698
Batch 21/64 loss: 0.25998443365097046
Batch 22/64 loss: 0.2643720507621765
Batch 23/64 loss: 0.26467955112457275
Batch 24/64 loss: 0.2644920349121094
Batch 25/64 loss: 0.2623005509376526
Batch 26/64 loss: 0.2537931799888611
Batch 27/64 loss: 0.25727379322052
Batch 28/64 loss: 0.26252734661102295
Batch 29/64 loss: 0.262395441532135
Batch 30/64 loss: 0.2581362724304199
Batch 31/64 loss: 0.25664758682250977
Batch 32/64 loss: 0.2601405382156372
Batch 33/64 loss: 0.26189374923706055
Batch 34/64 loss: 0.26706862449645996
Batch 35/64 loss: 0.25669562816619873
Batch 36/64 loss: 0.25754880905151367
Batch 37/64 loss: 0.26439517736434937
Batch 38/64 loss: 0.25864100456237793
Batch 39/64 loss: 0.27084577083587646
Batch 40/64 loss: 0.2582240700721741
Batch 41/64 loss: 0.2637828588485718
Batch 42/64 loss: 0.2552884817123413
Batch 43/64 loss: 0.26293671131134033
Batch 44/64 loss: 0.25972020626068115
Batch 45/64 loss: 0.254727303981781
Batch 46/64 loss: 0.2611188292503357
Batch 47/64 loss: 0.2654725909233093
Batch 48/64 loss: 0.2659536600112915
Batch 49/64 loss: 0.2680785655975342
Batch 50/64 loss: 0.2697560787200928
Batch 51/64 loss: 0.26457566022872925
Batch 52/64 loss: 0.2619144916534424
Batch 53/64 loss: 0.26580512523651123
Batch 54/64 loss: 0.26410889625549316
Batch 55/64 loss: 0.2597509026527405
Batch 56/64 loss: 0.2631400227546692
Batch 57/64 loss: 0.27383995056152344
Batch 58/64 loss: 0.26141417026519775
Batch 59/64 loss: 0.2687784433364868
Batch 60/64 loss: 0.2623850107192993
Batch 61/64 loss: 0.2527424693107605
Batch 62/64 loss: 0.2647817134857178
Batch 63/64 loss: 0.2661398649215698
Batch 64/64 loss: 0.25478214025497437
Epoch 240  Train loss: 0.2620213969081056  Val loss: 0.2883706236213343
Epoch 241
-------------------------------
Batch 1/64 loss: 0.2627301812171936
Batch 2/64 loss: 0.2732424736022949
Batch 3/64 loss: 0.2607502341270447
Batch 4/64 loss: 0.2732885479927063
Batch 5/64 loss: 0.25005388259887695
Batch 6/64 loss: 0.2608357071876526
Batch 7/64 loss: 0.25946664810180664
Batch 8/64 loss: 0.2592834234237671
Batch 9/64 loss: 0.25843489170074463
Batch 10/64 loss: 0.2647562623023987
Batch 11/64 loss: 0.2502230405807495
Batch 12/64 loss: 0.2618408203125
Batch 13/64 loss: 0.2596343755722046
Batch 14/64 loss: 0.2559998631477356
Batch 15/64 loss: 0.25643467903137207
Batch 16/64 loss: 0.26966553926467896
Batch 17/64 loss: 0.25399863719940186
Batch 18/64 loss: 0.25861263275146484
Batch 19/64 loss: 0.27173173427581787
Batch 20/64 loss: 0.25815439224243164
Batch 21/64 loss: 0.25583600997924805
Batch 22/64 loss: 0.2576873302459717
Batch 23/64 loss: 0.2562517523765564
Batch 24/64 loss: 0.261199951171875
Batch 25/64 loss: 0.2530530095100403
Batch 26/64 loss: 0.26091110706329346
Batch 27/64 loss: 0.262509822845459
Batch 28/64 loss: 0.26294124126434326
Batch 29/64 loss: 0.2707362174987793
Batch 30/64 loss: 0.2695983648300171
Batch 31/64 loss: 0.25872278213500977
Batch 32/64 loss: 0.2673196792602539
Batch 33/64 loss: 0.24996066093444824
Batch 34/64 loss: 0.2594132423400879
Batch 35/64 loss: 0.2622642517089844
Batch 36/64 loss: 0.25612127780914307
Batch 37/64 loss: 0.26747381687164307
Batch 38/64 loss: 0.26211071014404297
Batch 39/64 loss: 0.2625131607055664
Batch 40/64 loss: 0.2614312171936035
Batch 41/64 loss: 0.26816487312316895
Batch 42/64 loss: 0.2571728229522705
Batch 43/64 loss: 0.2550767660140991
Batch 44/64 loss: 0.26259517669677734
Batch 45/64 loss: 0.2600402235984802
Batch 46/64 loss: 0.2646963596343994
Batch 47/64 loss: 0.25776565074920654
Batch 48/64 loss: 0.253092885017395
Batch 49/64 loss: 0.2575775384902954
Batch 50/64 loss: 0.265389084815979
Batch 51/64 loss: 0.2657628059387207
Batch 52/64 loss: 0.25845301151275635
Batch 53/64 loss: 0.2599433660507202
Batch 54/64 loss: 0.25912702083587646
Batch 55/64 loss: 0.2592507004737854
Batch 56/64 loss: 0.2680087685585022
Batch 57/64 loss: 0.27405649423599243
Batch 58/64 loss: 0.2627975344657898
Batch 59/64 loss: 0.26631319522857666
Batch 60/64 loss: 0.2575026750564575
Batch 61/64 loss: 0.25989294052124023
Batch 62/64 loss: 0.2579731345176697
Batch 63/64 loss: 0.2671539783477783
Batch 64/64 loss: 0.2609167695045471
Epoch 241  Train loss: 0.2611872651997735  Val loss: 0.2862653595065743
Epoch 242
-------------------------------
Batch 1/64 loss: 0.25678372383117676
Batch 2/64 loss: 0.2544962167739868
Batch 3/64 loss: 0.2654130458831787
Batch 4/64 loss: 0.26364290714263916
Batch 5/64 loss: 0.2738528251647949
Batch 6/64 loss: 0.25739574432373047
Batch 7/64 loss: 0.2637660503387451
Batch 8/64 loss: 0.2624400854110718
Batch 9/64 loss: 0.26624059677124023
Batch 10/64 loss: 0.2567265033721924
Batch 11/64 loss: 0.2541300058364868
Batch 12/64 loss: 0.26424574851989746
Batch 13/64 loss: 0.26312148571014404
Batch 14/64 loss: 0.2547453045845032
Batch 15/64 loss: 0.2656702399253845
Batch 16/64 loss: 0.2669990658760071
Batch 17/64 loss: 0.2628370523452759
Batch 18/64 loss: 0.2680792808532715
Batch 19/64 loss: 0.2669864296913147
Batch 20/64 loss: 0.2478092908859253
Batch 21/64 loss: 0.2596474289894104
Batch 22/64 loss: 0.2541295289993286
Batch 23/64 loss: 0.26317548751831055
Batch 24/64 loss: 0.2573051452636719
Batch 25/64 loss: 0.25636160373687744
Batch 26/64 loss: 0.2546725273132324
Batch 27/64 loss: 0.2591269016265869
Batch 28/64 loss: 0.2523907423019409
Batch 29/64 loss: 0.2642284035682678
Batch 30/64 loss: 0.2614043951034546
Batch 31/64 loss: 0.26044440269470215
Batch 32/64 loss: 0.26370882987976074
Batch 33/64 loss: 0.2671642303466797
Batch 34/64 loss: 0.2631556987762451
Batch 35/64 loss: 0.2596706748008728
Batch 36/64 loss: 0.26718610525131226
Batch 37/64 loss: 0.24738770723342896
Batch 38/64 loss: 0.2616935968399048
Batch 39/64 loss: 0.2705862522125244
Batch 40/64 loss: 0.2598562240600586
Batch 41/64 loss: 0.2568201422691345
Batch 42/64 loss: 0.2632063627243042
Batch 43/64 loss: 0.2702077627182007
Batch 44/64 loss: 0.25605106353759766
Batch 45/64 loss: 0.2643533945083618
Batch 46/64 loss: 0.2526259422302246
Batch 47/64 loss: 0.24866998195648193
Batch 48/64 loss: 0.2521439790725708
Batch 49/64 loss: 0.27008819580078125
Batch 50/64 loss: 0.26307570934295654
Batch 51/64 loss: 0.26253318786621094
Batch 52/64 loss: 0.26147955656051636
Batch 53/64 loss: 0.2588236927986145
Batch 54/64 loss: 0.2722892761230469
Batch 55/64 loss: 0.263885498046875
Batch 56/64 loss: 0.2695118188858032
Batch 57/64 loss: 0.2599908113479614
Batch 58/64 loss: 0.2586919665336609
Batch 59/64 loss: 0.25791001319885254
Batch 60/64 loss: 0.2644916772842407
Batch 61/64 loss: 0.2619014382362366
Batch 62/64 loss: 0.25670015811920166
Batch 63/64 loss: 0.2609844207763672
Batch 64/64 loss: 0.2749990224838257
Epoch 242  Train loss: 0.2611978479460174  Val loss: 0.28711168258050873
Epoch 243
-------------------------------
Batch 1/64 loss: 0.25511765480041504
Batch 2/64 loss: 0.2595917582511902
Batch 3/64 loss: 0.25628262758255005
Batch 4/64 loss: 0.2690933346748352
Batch 5/64 loss: 0.24974632263183594
Batch 6/64 loss: 0.25761836767196655
Batch 7/64 loss: 0.25744664669036865
Batch 8/64 loss: 0.2553422451019287
Batch 9/64 loss: 0.24979013204574585
Batch 10/64 loss: 0.2570827007293701
Batch 11/64 loss: 0.25926029682159424
Batch 12/64 loss: 0.2634294033050537
Batch 13/64 loss: 0.2586745023727417
Batch 14/64 loss: 0.26851069927215576
Batch 15/64 loss: 0.2594975233078003
Batch 16/64 loss: 0.2597956657409668
Batch 17/64 loss: 0.2517573833465576
Batch 18/64 loss: 0.2640726566314697
Batch 19/64 loss: 0.25955647230148315
Batch 20/64 loss: 0.2554605007171631
Batch 21/64 loss: 0.2647205591201782
Batch 22/64 loss: 0.26590806245803833
Batch 23/64 loss: 0.2621012330055237
Batch 24/64 loss: 0.2602633237838745
Batch 25/64 loss: 0.25631505250930786
Batch 26/64 loss: 0.262176513671875
Batch 27/64 loss: 0.26868903636932373
Batch 28/64 loss: 0.27036285400390625
Batch 29/64 loss: 0.26840096712112427
Batch 30/64 loss: 0.2646200656890869
Batch 31/64 loss: 0.25859534740448
Batch 32/64 loss: 0.25430846214294434
Batch 33/64 loss: 0.2561938762664795
Batch 34/64 loss: 0.25910717248916626
Batch 35/64 loss: 0.26526516675949097
Batch 36/64 loss: 0.2561979293823242
Batch 37/64 loss: 0.26721179485321045
Batch 38/64 loss: 0.2557973861694336
Batch 39/64 loss: 0.257119357585907
Batch 40/64 loss: 0.2599605917930603
Batch 41/64 loss: 0.25678783655166626
Batch 42/64 loss: 0.2581360340118408
Batch 43/64 loss: 0.2594413757324219
Batch 44/64 loss: 0.26491427421569824
Batch 45/64 loss: 0.26093578338623047
Batch 46/64 loss: 0.256567120552063
Batch 47/64 loss: 0.26354122161865234
Batch 48/64 loss: 0.265247106552124
Batch 49/64 loss: 0.258215069770813
Batch 50/64 loss: 0.26195859909057617
Batch 51/64 loss: 0.26969510316848755
Batch 52/64 loss: 0.2589348554611206
Batch 53/64 loss: 0.2565518617630005
Batch 54/64 loss: 0.2660113573074341
Batch 55/64 loss: 0.26090019941329956
Batch 56/64 loss: 0.2630377411842346
Batch 57/64 loss: 0.26718270778656006
Batch 58/64 loss: 0.26006466150283813
Batch 59/64 loss: 0.2567484378814697
Batch 60/64 loss: 0.2713426947593689
Batch 61/64 loss: 0.2573808431625366
Batch 62/64 loss: 0.24862831830978394
Batch 63/64 loss: 0.25610780715942383
Batch 64/64 loss: 0.2765161991119385
Epoch 243  Train loss: 0.26048878127453373  Val loss: 0.28851186205021706
Epoch 244
-------------------------------
Batch 1/64 loss: 0.2568182945251465
Batch 2/64 loss: 0.26300597190856934
Batch 3/64 loss: 0.25147175788879395
Batch 4/64 loss: 0.2592366933822632
Batch 5/64 loss: 0.25758886337280273
Batch 6/64 loss: 0.2574154734611511
Batch 7/64 loss: 0.26044702529907227
Batch 8/64 loss: 0.252439022064209
Batch 9/64 loss: 0.2625664472579956
Batch 10/64 loss: 0.2582261562347412
Batch 11/64 loss: 0.26303577423095703
Batch 12/64 loss: 0.2668694257736206
Batch 13/64 loss: 0.2564826011657715
Batch 14/64 loss: 0.25663644075393677
Batch 15/64 loss: 0.2677825689315796
Batch 16/64 loss: 0.25934547185897827
Batch 17/64 loss: 0.2597135305404663
Batch 18/64 loss: 0.2654895782470703
Batch 19/64 loss: 0.2619471549987793
Batch 20/64 loss: 0.25360041856765747
Batch 21/64 loss: 0.2586174011230469
Batch 22/64 loss: 0.2657902240753174
Batch 23/64 loss: 0.2535563111305237
Batch 24/64 loss: 0.2676825523376465
Batch 25/64 loss: 0.26078957319259644
Batch 26/64 loss: 0.256075382232666
Batch 27/64 loss: 0.26342296600341797
Batch 28/64 loss: 0.26617610454559326
Batch 29/64 loss: 0.26053452491760254
Batch 30/64 loss: 0.2578505277633667
Batch 31/64 loss: 0.2611604332923889
Batch 32/64 loss: 0.2712298035621643
Batch 33/64 loss: 0.25859272480010986
Batch 34/64 loss: 0.2664903402328491
Batch 35/64 loss: 0.25740402936935425
Batch 36/64 loss: 0.2628967761993408
Batch 37/64 loss: 0.26625287532806396
Batch 38/64 loss: 0.26862668991088867
Batch 39/64 loss: 0.2582300305366516
Batch 40/64 loss: 0.25751447677612305
Batch 41/64 loss: 0.2511359453201294
Batch 42/64 loss: 0.27348291873931885
Batch 43/64 loss: 0.25831127166748047
Batch 44/64 loss: 0.26027601957321167
Batch 45/64 loss: 0.26402735710144043
Batch 46/64 loss: 0.2522616386413574
Batch 47/64 loss: 0.26393669843673706
Batch 48/64 loss: 0.2703823447227478
Batch 49/64 loss: 0.26722806692123413
Batch 50/64 loss: 0.25333523750305176
Batch 51/64 loss: 0.2585543394088745
Batch 52/64 loss: 0.2734733819961548
Batch 53/64 loss: 0.26862335205078125
Batch 54/64 loss: 0.266243577003479
Batch 55/64 loss: 0.2590121030807495
Batch 56/64 loss: 0.2549177408218384
Batch 57/64 loss: 0.2607567310333252
Batch 58/64 loss: 0.26701486110687256
Batch 59/64 loss: 0.26305896043777466
Batch 60/64 loss: 0.265950083732605
Batch 61/64 loss: 0.2627209424972534
Batch 62/64 loss: 0.2571314573287964
Batch 63/64 loss: 0.2725900411605835
Batch 64/64 loss: 0.25727009773254395
Epoch 244  Train loss: 0.26143356959025066  Val loss: 0.2874046705432774
Epoch 245
-------------------------------
Batch 1/64 loss: 0.26704537868499756
Batch 2/64 loss: 0.25519800186157227
Batch 3/64 loss: 0.25837481021881104
Batch 4/64 loss: 0.26331841945648193
Batch 5/64 loss: 0.26944756507873535
Batch 6/64 loss: 0.2619864344596863
Batch 7/64 loss: 0.25470685958862305
Batch 8/64 loss: 0.2647020220756531
Batch 9/64 loss: 0.25777602195739746
Batch 10/64 loss: 0.2656440734863281
Batch 11/64 loss: 0.2605990767478943
Batch 12/64 loss: 0.2526669502258301
Batch 13/64 loss: 0.258852481842041
Batch 14/64 loss: 0.26239532232284546
Batch 15/64 loss: 0.26947081089019775
Batch 16/64 loss: 0.2616546154022217
Batch 17/64 loss: 0.25988060235977173
Batch 18/64 loss: 0.2623186707496643
Batch 19/64 loss: 0.2602691054344177
Batch 20/64 loss: 0.25804924964904785
Batch 21/64 loss: 0.25778722763061523
Batch 22/64 loss: 0.26104772090911865
Batch 23/64 loss: 0.25761789083480835
Batch 24/64 loss: 0.27234888076782227
Batch 25/64 loss: 0.2623934745788574
Batch 26/64 loss: 0.26248687505722046
Batch 27/64 loss: 0.2682133913040161
Batch 28/64 loss: 0.26164674758911133
Batch 29/64 loss: 0.2600352168083191
Batch 30/64 loss: 0.2505875825881958
Batch 31/64 loss: 0.256411075592041
Batch 32/64 loss: 0.25278937816619873
Batch 33/64 loss: 0.259759783744812
Batch 34/64 loss: 0.2600741386413574
Batch 35/64 loss: 0.2591061592102051
Batch 36/64 loss: 0.2585756182670593
Batch 37/64 loss: 0.26308465003967285
Batch 38/64 loss: 0.2636822462081909
Batch 39/64 loss: 0.26632964611053467
Batch 40/64 loss: 0.2616140842437744
Batch 41/64 loss: 0.27084553241729736
Batch 42/64 loss: 0.2586871385574341
Batch 43/64 loss: 0.2609527111053467
Batch 44/64 loss: 0.2591726779937744
Batch 45/64 loss: 0.25895559787750244
Batch 46/64 loss: 0.2676680088043213
Batch 47/64 loss: 0.2631124258041382
Batch 48/64 loss: 0.27386951446533203
Batch 49/64 loss: 0.2691587209701538
Batch 50/64 loss: 0.2591705918312073
Batch 51/64 loss: 0.25361961126327515
Batch 52/64 loss: 0.26023125648498535
Batch 53/64 loss: 0.2552775740623474
Batch 54/64 loss: 0.25629281997680664
Batch 55/64 loss: 0.26934194564819336
Batch 56/64 loss: 0.2616969347000122
Batch 57/64 loss: 0.2570270299911499
Batch 58/64 loss: 0.26543712615966797
Batch 59/64 loss: 0.25696974992752075
Batch 60/64 loss: 0.2549945116043091
Batch 61/64 loss: 0.2565975785255432
Batch 62/64 loss: 0.2594977021217346
Batch 63/64 loss: 0.25305330753326416
Batch 64/64 loss: 0.25726890563964844
Epoch 245  Train loss: 0.26093380404453653  Val loss: 0.28675415589637365
Epoch 246
-------------------------------
Batch 1/64 loss: 0.26149511337280273
Batch 2/64 loss: 0.2552710771560669
Batch 3/64 loss: 0.26989060640335083
Batch 4/64 loss: 0.25738292932510376
Batch 5/64 loss: 0.26631128787994385
Batch 6/64 loss: 0.2607090473175049
Batch 7/64 loss: 0.2700408697128296
Batch 8/64 loss: 0.24918991327285767
Batch 9/64 loss: 0.2635376453399658
Batch 10/64 loss: 0.26438868045806885
Batch 11/64 loss: 0.26022517681121826
Batch 12/64 loss: 0.25741422176361084
Batch 13/64 loss: 0.2525402307510376
Batch 14/64 loss: 0.25437408685684204
Batch 15/64 loss: 0.26575493812561035
Batch 16/64 loss: 0.2597402334213257
Batch 17/64 loss: 0.26535117626190186
Batch 18/64 loss: 0.25556421279907227
Batch 19/64 loss: 0.26677238941192627
Batch 20/64 loss: 0.26526665687561035
Batch 21/64 loss: 0.25887227058410645
Batch 22/64 loss: 0.2613060474395752
Batch 23/64 loss: 0.25466805696487427
Batch 24/64 loss: 0.25923532247543335
Batch 25/64 loss: 0.25267481803894043
Batch 26/64 loss: 0.26172691583633423
Batch 27/64 loss: 0.274977445602417
Batch 28/64 loss: 0.2624293565750122
Batch 29/64 loss: 0.2641890048980713
Batch 30/64 loss: 0.25807440280914307
Batch 31/64 loss: 0.24970686435699463
Batch 32/64 loss: 0.26175427436828613
Batch 33/64 loss: 0.2505946159362793
Batch 34/64 loss: 0.26227134466171265
Batch 35/64 loss: 0.2575380802154541
Batch 36/64 loss: 0.25465142726898193
Batch 37/64 loss: 0.25390905141830444
Batch 38/64 loss: 0.25978314876556396
Batch 39/64 loss: 0.2605689764022827
Batch 40/64 loss: 0.2569342851638794
Batch 41/64 loss: 0.25512242317199707
Batch 42/64 loss: 0.2628127336502075
Batch 43/64 loss: 0.2547537088394165
Batch 44/64 loss: 0.24947720766067505
Batch 45/64 loss: 0.26683861017227173
Batch 46/64 loss: 0.2588726878166199
Batch 47/64 loss: 0.2618396282196045
Batch 48/64 loss: 0.2639084458351135
Batch 49/64 loss: 0.2525498867034912
Batch 50/64 loss: 0.26007288694381714
Batch 51/64 loss: 0.259027361869812
Batch 52/64 loss: 0.26248836517333984
Batch 53/64 loss: 0.2617391347885132
Batch 54/64 loss: 0.2641773819923401
Batch 55/64 loss: 0.27051442861557007
Batch 56/64 loss: 0.25776171684265137
Batch 57/64 loss: 0.2692246437072754
Batch 58/64 loss: 0.2615477442741394
Batch 59/64 loss: 0.2580708861351013
Batch 60/64 loss: 0.25182044506073
Batch 61/64 loss: 0.26136016845703125
Batch 62/64 loss: 0.2642688751220703
Batch 63/64 loss: 0.2637329697608948
Batch 64/64 loss: 0.2647886872291565
Epoch 246  Train loss: 0.26019858916600547  Val loss: 0.2860631107055035
Saving best model, epoch: 246
Epoch 247
-------------------------------
Batch 1/64 loss: 0.26783227920532227
Batch 2/64 loss: 0.26895999908447266
Batch 3/64 loss: 0.2612723112106323
Batch 4/64 loss: 0.2616661787033081
Batch 5/64 loss: 0.2606881260871887
Batch 6/64 loss: 0.26049530506134033
Batch 7/64 loss: 0.2595445513725281
Batch 8/64 loss: 0.2558528184890747
Batch 9/64 loss: 0.26674604415893555
Batch 10/64 loss: 0.2603575587272644
Batch 11/64 loss: 0.2596423029899597
Batch 12/64 loss: 0.26449429988861084
Batch 13/64 loss: 0.2559351921081543
Batch 14/64 loss: 0.2622668147087097
Batch 15/64 loss: 0.24887758493423462
Batch 16/64 loss: 0.25749218463897705
Batch 17/64 loss: 0.25779134035110474
Batch 18/64 loss: 0.2488539218902588
Batch 19/64 loss: 0.2620776891708374
Batch 20/64 loss: 0.25294846296310425
Batch 21/64 loss: 0.25922220945358276
Batch 22/64 loss: 0.26662707328796387
Batch 23/64 loss: 0.2649960517883301
Batch 24/64 loss: 0.25675642490386963
Batch 25/64 loss: 0.2526335120201111
Batch 26/64 loss: 0.26019448041915894
Batch 27/64 loss: 0.25455009937286377
Batch 28/64 loss: 0.26046276092529297
Batch 29/64 loss: 0.25664353370666504
Batch 30/64 loss: 0.2549059987068176
Batch 31/64 loss: 0.2562103271484375
Batch 32/64 loss: 0.2638722062110901
Batch 33/64 loss: 0.2614392638206482
Batch 34/64 loss: 0.26351553201675415
Batch 35/64 loss: 0.2696843147277832
Batch 36/64 loss: 0.2517423629760742
Batch 37/64 loss: 0.2710713744163513
Batch 38/64 loss: 0.2599720358848572
Batch 39/64 loss: 0.26166343688964844
Batch 40/64 loss: 0.2670289874076843
Batch 41/64 loss: 0.26105040311813354
Batch 42/64 loss: 0.2607358694076538
Batch 43/64 loss: 0.26063036918640137
Batch 44/64 loss: 0.25712674856185913
Batch 45/64 loss: 0.25539064407348633
Batch 46/64 loss: 0.2651853561401367
Batch 47/64 loss: 0.26311278343200684
Batch 48/64 loss: 0.26761889457702637
Batch 49/64 loss: 0.26355117559432983
Batch 50/64 loss: 0.2571079134941101
Batch 51/64 loss: 0.2661522626876831
Batch 52/64 loss: 0.2579765319824219
Batch 53/64 loss: 0.2549494504928589
Batch 54/64 loss: 0.26230764389038086
Batch 55/64 loss: 0.2652028799057007
Batch 56/64 loss: 0.26275694370269775
Batch 57/64 loss: 0.2555732727050781
Batch 58/64 loss: 0.26163148880004883
Batch 59/64 loss: 0.25022703409194946
Batch 60/64 loss: 0.26313352584838867
Batch 61/64 loss: 0.2546212673187256
Batch 62/64 loss: 0.2573413848876953
Batch 63/64 loss: 0.2474597692489624
Batch 64/64 loss: 0.25930213928222656
Epoch 247  Train loss: 0.2599577595205868  Val loss: 0.28625005729419667
Epoch 248
-------------------------------
Batch 1/64 loss: 0.26334667205810547
Batch 2/64 loss: 0.25264084339141846
Batch 3/64 loss: 0.26860105991363525
Batch 4/64 loss: 0.2536870241165161
Batch 5/64 loss: 0.2599982023239136
Batch 6/64 loss: 0.2771605849266052
Batch 7/64 loss: 0.25483059883117676
Batch 8/64 loss: 0.2650684118270874
Batch 9/64 loss: 0.2614360451698303
Batch 10/64 loss: 0.26488667726516724
Batch 11/64 loss: 0.2599818706512451
Batch 12/64 loss: 0.254177451133728
Batch 13/64 loss: 0.2596057653427124
Batch 14/64 loss: 0.2505619525909424
Batch 15/64 loss: 0.2582237720489502
Batch 16/64 loss: 0.2605394721031189
Batch 17/64 loss: 0.25624531507492065
Batch 18/64 loss: 0.2628360986709595
Batch 19/64 loss: 0.26182782649993896
Batch 20/64 loss: 0.2578493356704712
Batch 21/64 loss: 0.26110386848449707
Batch 22/64 loss: 0.25455164909362793
Batch 23/64 loss: 0.2606431245803833
Batch 24/64 loss: 0.266007661819458
Batch 25/64 loss: 0.26035767793655396
Batch 26/64 loss: 0.25441431999206543
Batch 27/64 loss: 0.25936591625213623
Batch 28/64 loss: 0.25347989797592163
Batch 29/64 loss: 0.2654186487197876
Batch 30/64 loss: 0.2569979429244995
Batch 31/64 loss: 0.26777923107147217
Batch 32/64 loss: 0.25532370805740356
Batch 33/64 loss: 0.26134711503982544
Batch 34/64 loss: 0.25655466318130493
Batch 35/64 loss: 0.2549901008605957
Batch 36/64 loss: 0.26602673530578613
Batch 37/64 loss: 0.25377821922302246
Batch 38/64 loss: 0.2493540644645691
Batch 39/64 loss: 0.2642720937728882
Batch 40/64 loss: 0.26037853956222534
Batch 41/64 loss: 0.2666294574737549
Batch 42/64 loss: 0.25471562147140503
Batch 43/64 loss: 0.25157666206359863
Batch 44/64 loss: 0.2651442885398865
Batch 45/64 loss: 0.2518245577812195
Batch 46/64 loss: 0.25223982334136963
Batch 47/64 loss: 0.26415348052978516
Batch 48/64 loss: 0.25930583477020264
Batch 49/64 loss: 0.25223052501678467
Batch 50/64 loss: 0.260586678981781
Batch 51/64 loss: 0.25536859035491943
Batch 52/64 loss: 0.2621351480484009
Batch 53/64 loss: 0.26023751497268677
Batch 54/64 loss: 0.26205974817276
Batch 55/64 loss: 0.2582993507385254
Batch 56/64 loss: 0.2641311287879944
Batch 57/64 loss: 0.26293206214904785
Batch 58/64 loss: 0.25706684589385986
Batch 59/64 loss: 0.27118760347366333
Batch 60/64 loss: 0.25486868619918823
Batch 61/64 loss: 0.2553790211677551
Batch 62/64 loss: 0.26493608951568604
Batch 63/64 loss: 0.2597755193710327
Batch 64/64 loss: 0.25836288928985596
Epoch 248  Train loss: 0.2595483382542928  Val loss: 0.2860088123079018
Saving best model, epoch: 248
Epoch 249
-------------------------------
Batch 1/64 loss: 0.26771748065948486
Batch 2/64 loss: 0.2729364037513733
Batch 3/64 loss: 0.252377986907959
Batch 4/64 loss: 0.27386367321014404
Batch 5/64 loss: 0.26430851221084595
Batch 6/64 loss: 0.2599315047264099
Batch 7/64 loss: 0.25316035747528076
Batch 8/64 loss: 0.25290584564208984
Batch 9/64 loss: 0.2584928274154663
Batch 10/64 loss: 0.25424885749816895
Batch 11/64 loss: 0.26276516914367676
Batch 12/64 loss: 0.26083147525787354
Batch 13/64 loss: 0.2526565194129944
Batch 14/64 loss: 0.2565854787826538
Batch 15/64 loss: 0.2532840967178345
Batch 16/64 loss: 0.273665189743042
Batch 17/64 loss: 0.2503223419189453
Batch 18/64 loss: 0.26352590322494507
Batch 19/64 loss: 0.2500538229942322
Batch 20/64 loss: 0.26182103157043457
Batch 21/64 loss: 0.2576029300689697
Batch 22/64 loss: 0.2644835114479065
Batch 23/64 loss: 0.25865638256073
Batch 24/64 loss: 0.2615126371383667
Batch 25/64 loss: 0.262596070766449
Batch 26/64 loss: 0.2533169388771057
Batch 27/64 loss: 0.25810301303863525
Batch 28/64 loss: 0.26551735401153564
Batch 29/64 loss: 0.2552257776260376
Batch 30/64 loss: 0.26697325706481934
Batch 31/64 loss: 0.2578461170196533
Batch 32/64 loss: 0.25320470333099365
Batch 33/64 loss: 0.26467061042785645
Batch 34/64 loss: 0.2501603364944458
Batch 35/64 loss: 0.25851893424987793
Batch 36/64 loss: 0.2602006196975708
Batch 37/64 loss: 0.26323580741882324
Batch 38/64 loss: 0.2632595896720886
Batch 39/64 loss: 0.24958312511444092
Batch 40/64 loss: 0.2574636936187744
Batch 41/64 loss: 0.2547159194946289
Batch 42/64 loss: 0.25068289041519165
Batch 43/64 loss: 0.2579842805862427
Batch 44/64 loss: 0.2666260004043579
Batch 45/64 loss: 0.2495436668395996
Batch 46/64 loss: 0.2530689835548401
Batch 47/64 loss: 0.25914233922958374
Batch 48/64 loss: 0.2634505033493042
Batch 49/64 loss: 0.26273787021636963
Batch 50/64 loss: 0.26799535751342773
Batch 51/64 loss: 0.25977832078933716
Batch 52/64 loss: 0.26539361476898193
Batch 53/64 loss: 0.26236391067504883
Batch 54/64 loss: 0.25829386711120605
Batch 55/64 loss: 0.2601360082626343
Batch 56/64 loss: 0.2626838684082031
Batch 57/64 loss: 0.2694273591041565
Batch 58/64 loss: 0.2616386413574219
Batch 59/64 loss: 0.2690579891204834
Batch 60/64 loss: 0.259460985660553
Batch 61/64 loss: 0.2583419680595398
Batch 62/64 loss: 0.2509285807609558
Batch 63/64 loss: 0.26057446002960205
Batch 64/64 loss: 0.25287747383117676
Epoch 249  Train loss: 0.2596277863371606  Val loss: 0.2864022496639658
Epoch 250
-------------------------------
Batch 1/64 loss: 0.2606379985809326
Batch 2/64 loss: 0.255196213722229
Batch 3/64 loss: 0.25795745849609375
Batch 4/64 loss: 0.2635766267776489
Batch 5/64 loss: 0.2503838539123535
Batch 6/64 loss: 0.2649793028831482
Batch 7/64 loss: 0.2546508312225342
Batch 8/64 loss: 0.26517045497894287
Batch 9/64 loss: 0.264289915561676
Batch 10/64 loss: 0.25763821601867676
Batch 11/64 loss: 0.2535232901573181
Batch 12/64 loss: 0.2651856541633606
Batch 13/64 loss: 0.25011157989501953
Batch 14/64 loss: 0.26289451122283936
Batch 15/64 loss: 0.257265567779541
Batch 16/64 loss: 0.2640063762664795
Batch 17/64 loss: 0.25255656242370605
Batch 18/64 loss: 0.2571868896484375
Batch 19/64 loss: 0.25971782207489014
Batch 20/64 loss: 0.2566063404083252
Batch 21/64 loss: 0.262448787689209
Batch 22/64 loss: 0.25997596979141235
Batch 23/64 loss: 0.26489341259002686
Batch 24/64 loss: 0.2556467056274414
Batch 25/64 loss: 0.2532098889350891
Batch 26/64 loss: 0.2585449814796448
Batch 27/64 loss: 0.25777655839920044
Batch 28/64 loss: 0.2608073949813843
Batch 29/64 loss: 0.2541055679321289
Batch 30/64 loss: 0.2749693989753723
Batch 31/64 loss: 0.2614835500717163
Batch 32/64 loss: 0.25813913345336914
Batch 33/64 loss: 0.2580159306526184
Batch 34/64 loss: 0.2600744366645813
Batch 35/64 loss: 0.25890350341796875
Batch 36/64 loss: 0.25505685806274414
Batch 37/64 loss: 0.26447391510009766
Batch 38/64 loss: 0.2624671459197998
Batch 39/64 loss: 0.2538183331489563
Batch 40/64 loss: 0.26349830627441406
Batch 41/64 loss: 0.25051045417785645
Batch 42/64 loss: 0.25714433193206787
Batch 43/64 loss: 0.2649849057197571
Batch 44/64 loss: 0.2487245798110962
Batch 45/64 loss: 0.2656552791595459
Batch 46/64 loss: 0.2486124038696289
Batch 47/64 loss: 0.258039653301239
Batch 48/64 loss: 0.2565683126449585
Batch 49/64 loss: 0.2581111192703247
Batch 50/64 loss: 0.25948381423950195
Batch 51/64 loss: 0.2548907995223999
Batch 52/64 loss: 0.27013468742370605
Batch 53/64 loss: 0.26296091079711914
Batch 54/64 loss: 0.27710890769958496
Batch 55/64 loss: 0.2655702829360962
Batch 56/64 loss: 0.26050031185150146
Batch 57/64 loss: 0.2658209204673767
Batch 58/64 loss: 0.2603045701980591
Batch 59/64 loss: 0.2564046382904053
Batch 60/64 loss: 0.25960803031921387
Batch 61/64 loss: 0.25984901189804077
Batch 62/64 loss: 0.26664161682128906
Batch 63/64 loss: 0.25981438159942627
Batch 64/64 loss: 0.26038485765457153
Epoch 250  Train loss: 0.2596796519616071  Val loss: 0.28598139580992077
Saving best model, epoch: 250
Epoch 251
-------------------------------
Batch 1/64 loss: 0.25565510988235474
Batch 2/64 loss: 0.26307713985443115
Batch 3/64 loss: 0.25900089740753174
Batch 4/64 loss: 0.2484142780303955
Batch 5/64 loss: 0.2586030960083008
Batch 6/64 loss: 0.27498698234558105
Batch 7/64 loss: 0.2615450620651245
Batch 8/64 loss: 0.26288074254989624
Batch 9/64 loss: 0.263797402381897
Batch 10/64 loss: 0.24882733821868896
Batch 11/64 loss: 0.25717902183532715
Batch 12/64 loss: 0.2654517889022827
Batch 13/64 loss: 0.24978482723236084
Batch 14/64 loss: 0.2554817199707031
Batch 15/64 loss: 0.2622056007385254
Batch 16/64 loss: 0.2533695697784424
Batch 17/64 loss: 0.2592175602912903
Batch 18/64 loss: 0.2649925947189331
Batch 19/64 loss: 0.26014864444732666
Batch 20/64 loss: 0.25080275535583496
Batch 21/64 loss: 0.25246620178222656
Batch 22/64 loss: 0.2536604404449463
Batch 23/64 loss: 0.2591569423675537
Batch 24/64 loss: 0.25927603244781494
Batch 25/64 loss: 0.25841885805130005
Batch 26/64 loss: 0.2594444751739502
Batch 27/64 loss: 0.2547937035560608
Batch 28/64 loss: 0.24851274490356445
Batch 29/64 loss: 0.262138307094574
Batch 30/64 loss: 0.2611318826675415
Batch 31/64 loss: 0.26775962114334106
Batch 32/64 loss: 0.2569526433944702
Batch 33/64 loss: 0.2609679102897644
Batch 34/64 loss: 0.27239370346069336
Batch 35/64 loss: 0.2562415599822998
Batch 36/64 loss: 0.25642937421798706
Batch 37/64 loss: 0.2483956217765808
Batch 38/64 loss: 0.25973546504974365
Batch 39/64 loss: 0.26162445545196533
Batch 40/64 loss: 0.2565612196922302
Batch 41/64 loss: 0.25844383239746094
Batch 42/64 loss: 0.2514234781265259
Batch 43/64 loss: 0.249947190284729
Batch 44/64 loss: 0.25408732891082764
Batch 45/64 loss: 0.24952876567840576
Batch 46/64 loss: 0.2540764808654785
Batch 47/64 loss: 0.25923657417297363
Batch 48/64 loss: 0.2589724063873291
Batch 49/64 loss: 0.260403037071228
Batch 50/64 loss: 0.25096726417541504
Batch 51/64 loss: 0.25853586196899414
Batch 52/64 loss: 0.2681382894515991
Batch 53/64 loss: 0.25347381830215454
Batch 54/64 loss: 0.2605818510055542
Batch 55/64 loss: 0.25493311882019043
Batch 56/64 loss: 0.2827730178833008
Batch 57/64 loss: 0.2598838806152344
Batch 58/64 loss: 0.26417702436447144
Batch 59/64 loss: 0.25425148010253906
Batch 60/64 loss: 0.25006550550460815
Batch 61/64 loss: 0.26555293798446655
Batch 62/64 loss: 0.2529144883155823
Batch 63/64 loss: 0.26687300205230713
Batch 64/64 loss: 0.25879770517349243
Epoch 251  Train loss: 0.25842858365937776  Val loss: 0.2879015014753309
Epoch 252
-------------------------------
Batch 1/64 loss: 0.25418347120285034
Batch 2/64 loss: 0.24835145473480225
Batch 3/64 loss: 0.2539442181587219
Batch 4/64 loss: 0.2522784471511841
Batch 5/64 loss: 0.25293219089508057
Batch 6/64 loss: 0.2498100996017456
Batch 7/64 loss: 0.2590945363044739
Batch 8/64 loss: 0.2613917589187622
Batch 9/64 loss: 0.2543025016784668
Batch 10/64 loss: 0.2669057846069336
Batch 11/64 loss: 0.2558096647262573
Batch 12/64 loss: 0.24849462509155273
Batch 13/64 loss: 0.2603915333747864
Batch 14/64 loss: 0.24456286430358887
Batch 15/64 loss: 0.25998085737228394
Batch 16/64 loss: 0.25305265188217163
Batch 17/64 loss: 0.2538151741027832
Batch 18/64 loss: 0.2579219937324524
Batch 19/64 loss: 0.256911039352417
Batch 20/64 loss: 0.2616382837295532
Batch 21/64 loss: 0.2602917551994324
Batch 22/64 loss: 0.2594410181045532
Batch 23/64 loss: 0.26047760248184204
Batch 24/64 loss: 0.2615923285484314
Batch 25/64 loss: 0.2593194246292114
Batch 26/64 loss: 0.25772225856781006
Batch 27/64 loss: 0.25823014974594116
Batch 28/64 loss: 0.2630108594894409
Batch 29/64 loss: 0.2588077783584595
Batch 30/64 loss: 0.25404858589172363
Batch 31/64 loss: 0.26767730712890625
Batch 32/64 loss: 0.258695125579834
Batch 33/64 loss: 0.25886082649230957
Batch 34/64 loss: 0.25384461879730225
Batch 35/64 loss: 0.24761736392974854
Batch 36/64 loss: 0.258001446723938
Batch 37/64 loss: 0.2552223801612854
Batch 38/64 loss: 0.2589629292488098
Batch 39/64 loss: 0.25112462043762207
Batch 40/64 loss: 0.2606743574142456
Batch 41/64 loss: 0.2590978741645813
Batch 42/64 loss: 0.26691102981567383
Batch 43/64 loss: 0.2655894160270691
Batch 44/64 loss: 0.259189248085022
Batch 45/64 loss: 0.2639766335487366
Batch 46/64 loss: 0.2602577805519104
Batch 47/64 loss: 0.2532033920288086
Batch 48/64 loss: 0.25098395347595215
Batch 49/64 loss: 0.26292502880096436
Batch 50/64 loss: 0.2629326581954956
Batch 51/64 loss: 0.25843745470046997
Batch 52/64 loss: 0.2537879943847656
Batch 53/64 loss: 0.247242271900177
Batch 54/64 loss: 0.27033090591430664
Batch 55/64 loss: 0.25810182094573975
Batch 56/64 loss: 0.2564864754676819
Batch 57/64 loss: 0.2627938985824585
Batch 58/64 loss: 0.2641969919204712
Batch 59/64 loss: 0.25998151302337646
Batch 60/64 loss: 0.2656540870666504
Batch 61/64 loss: 0.25414329767227173
Batch 62/64 loss: 0.2640921473503113
Batch 63/64 loss: 0.26015937328338623
Batch 64/64 loss: 0.27234411239624023
Epoch 252  Train loss: 0.25810398774988513  Val loss: 0.2864609581908
Epoch 253
-------------------------------
Batch 1/64 loss: 0.2571202516555786
Batch 2/64 loss: 0.2539372444152832
Batch 3/64 loss: 0.26011204719543457
Batch 4/64 loss: 0.23732614517211914
Batch 5/64 loss: 0.26414602994918823
Batch 6/64 loss: 0.2527785301208496
Batch 7/64 loss: 0.25176453590393066
Batch 8/64 loss: 0.2581382989883423
Batch 9/64 loss: 0.2556098699569702
Batch 10/64 loss: 0.2550698518753052
Batch 11/64 loss: 0.2599126100540161
Batch 12/64 loss: 0.25837504863739014
Batch 13/64 loss: 0.2524465322494507
Batch 14/64 loss: 0.262917697429657
Batch 15/64 loss: 0.2529672384262085
Batch 16/64 loss: 0.2467881441116333
Batch 17/64 loss: 0.2679102420806885
Batch 18/64 loss: 0.2576044797897339
Batch 19/64 loss: 0.2541542649269104
Batch 20/64 loss: 0.2552976608276367
Batch 21/64 loss: 0.2506866455078125
Batch 22/64 loss: 0.26100003719329834
Batch 23/64 loss: 0.2529860734939575
Batch 24/64 loss: 0.2682475447654724
Batch 25/64 loss: 0.26001787185668945
Batch 26/64 loss: 0.2569701671600342
Batch 27/64 loss: 0.2585068941116333
Batch 28/64 loss: 0.26154589653015137
Batch 29/64 loss: 0.2564389705657959
Batch 30/64 loss: 0.2607819437980652
Batch 31/64 loss: 0.2581920623779297
Batch 32/64 loss: 0.2659837007522583
Batch 33/64 loss: 0.26041698455810547
Batch 34/64 loss: 0.26110732555389404
Batch 35/64 loss: 0.26021426916122437
Batch 36/64 loss: 0.2500043511390686
Batch 37/64 loss: 0.2594379186630249
Batch 38/64 loss: 0.26046836376190186
Batch 39/64 loss: 0.27148938179016113
Batch 40/64 loss: 0.2638258934020996
Batch 41/64 loss: 0.26370954513549805
Batch 42/64 loss: 0.25857478380203247
Batch 43/64 loss: 0.26420629024505615
Batch 44/64 loss: 0.2614161968231201
Batch 45/64 loss: 0.2628210783004761
Batch 46/64 loss: 0.25939619541168213
Batch 47/64 loss: 0.2597044110298157
Batch 48/64 loss: 0.25844669342041016
Batch 49/64 loss: 0.25473636388778687
Batch 50/64 loss: 0.266124963760376
Batch 51/64 loss: 0.259598970413208
Batch 52/64 loss: 0.26496315002441406
Batch 53/64 loss: 0.2704610228538513
Batch 54/64 loss: 0.2534278631210327
Batch 55/64 loss: 0.2667856216430664
Batch 56/64 loss: 0.261787474155426
Batch 57/64 loss: 0.25953805446624756
Batch 58/64 loss: 0.25526297092437744
Batch 59/64 loss: 0.2590830326080322
Batch 60/64 loss: 0.2608799934387207
Batch 61/64 loss: 0.25405049324035645
Batch 62/64 loss: 0.25464242696762085
Batch 63/64 loss: 0.25415825843811035
Batch 64/64 loss: 0.28090572357177734
Epoch 253  Train loss: 0.25893575163448557  Val loss: 0.28767683886990103
Epoch 254
-------------------------------
Batch 1/64 loss: 0.26043063402175903
Batch 2/64 loss: 0.2603083848953247
Batch 3/64 loss: 0.26192963123321533
Batch 4/64 loss: 0.24871045351028442
Batch 5/64 loss: 0.2734096050262451
Batch 6/64 loss: 0.24942946434020996
Batch 7/64 loss: 0.2625312805175781
Batch 8/64 loss: 0.25779104232788086
Batch 9/64 loss: 0.27572154998779297
Batch 10/64 loss: 0.2608800530433655
Batch 11/64 loss: 0.2614437937736511
Batch 12/64 loss: 0.25995469093322754
Batch 13/64 loss: 0.2589329481124878
Batch 14/64 loss: 0.2586204409599304
Batch 15/64 loss: 0.25147509574890137
Batch 16/64 loss: 0.2646663188934326
Batch 17/64 loss: 0.2560490369796753
Batch 18/64 loss: 0.248751699924469
Batch 19/64 loss: 0.25604915618896484
Batch 20/64 loss: 0.26806730031967163
Batch 21/64 loss: 0.25907015800476074
Batch 22/64 loss: 0.2518088221549988
Batch 23/64 loss: 0.25653862953186035
Batch 24/64 loss: 0.2562238574028015
Batch 25/64 loss: 0.2517625093460083
Batch 26/64 loss: 0.26567399501800537
Batch 27/64 loss: 0.2666729688644409
Batch 28/64 loss: 0.2553200125694275
Batch 29/64 loss: 0.26767176389694214
Batch 30/64 loss: 0.26331865787506104
Batch 31/64 loss: 0.2634696960449219
Batch 32/64 loss: 0.26825660467147827
Batch 33/64 loss: 0.2578590512275696
Batch 34/64 loss: 0.2490938901901245
Batch 35/64 loss: 0.26337552070617676
Batch 36/64 loss: 0.25026774406433105
Batch 37/64 loss: 0.260475218296051
Batch 38/64 loss: 0.2589929699897766
Batch 39/64 loss: 0.26252466440200806
Batch 40/64 loss: 0.2642788290977478
Batch 41/64 loss: 0.2616320252418518
Batch 42/64 loss: 0.25763654708862305
Batch 43/64 loss: 0.24637508392333984
Batch 44/64 loss: 0.26165854930877686
Batch 45/64 loss: 0.26383864879608154
Batch 46/64 loss: 0.25888514518737793
Batch 47/64 loss: 0.24598544836044312
Batch 48/64 loss: 0.25504374504089355
Batch 49/64 loss: 0.26374340057373047
Batch 50/64 loss: 0.25184035301208496
Batch 51/64 loss: 0.2603446841239929
Batch 52/64 loss: 0.2625846862792969
Batch 53/64 loss: 0.2557333707809448
Batch 54/64 loss: 0.2535203695297241
Batch 55/64 loss: 0.26209956407546997
Batch 56/64 loss: 0.24835634231567383
Batch 57/64 loss: 0.27109646797180176
Batch 58/64 loss: 0.25361669063568115
Batch 59/64 loss: 0.27222132682800293
Batch 60/64 loss: 0.2595711946487427
Batch 61/64 loss: 0.2559269070625305
Batch 62/64 loss: 0.25286829471588135
Batch 63/64 loss: 0.2560758590698242
Batch 64/64 loss: 0.2619210481643677
Epoch 254  Train loss: 0.2590573119182213  Val loss: 0.28716902675497574
Epoch 255
-------------------------------
Batch 1/64 loss: 0.25446611642837524
Batch 2/64 loss: 0.26671838760375977
Batch 3/64 loss: 0.25609493255615234
Batch 4/64 loss: 0.25298750400543213
Batch 5/64 loss: 0.2694087028503418
Batch 6/64 loss: 0.257393479347229
Batch 7/64 loss: 0.2690337896347046
Batch 8/64 loss: 0.2562296390533447
Batch 9/64 loss: 0.26073157787323
Batch 10/64 loss: 0.275482177734375
Batch 11/64 loss: 0.2633897066116333
Batch 12/64 loss: 0.26239335536956787
Batch 13/64 loss: 0.2668393850326538
Batch 14/64 loss: 0.2670682668685913
Batch 15/64 loss: 0.2600356340408325
Batch 16/64 loss: 0.2549722194671631
Batch 17/64 loss: 0.2533438205718994
Batch 18/64 loss: 0.2595254182815552
Batch 19/64 loss: 0.25655174255371094
Batch 20/64 loss: 0.2552616596221924
Batch 21/64 loss: 0.25364065170288086
Batch 22/64 loss: 0.25418949127197266
Batch 23/64 loss: 0.25888216495513916
Batch 24/64 loss: 0.2591674327850342
Batch 25/64 loss: 0.2560769319534302
Batch 26/64 loss: 0.26123058795928955
Batch 27/64 loss: 0.2655383348464966
Batch 28/64 loss: 0.25697803497314453
Batch 29/64 loss: 0.2605118155479431
Batch 30/64 loss: 0.24707603454589844
Batch 31/64 loss: 0.2494593858718872
Batch 32/64 loss: 0.25453466176986694
Batch 33/64 loss: 0.25690627098083496
Batch 34/64 loss: 0.2589768171310425
Batch 35/64 loss: 0.2529958486557007
Batch 36/64 loss: 0.2573201060295105
Batch 37/64 loss: 0.26035547256469727
Batch 38/64 loss: 0.26780176162719727
Batch 39/64 loss: 0.25653964281082153
Batch 40/64 loss: 0.2560831308364868
Batch 41/64 loss: 0.25888538360595703
Batch 42/64 loss: 0.2566196918487549
Batch 43/64 loss: 0.25323474407196045
Batch 44/64 loss: 0.254528284072876
Batch 45/64 loss: 0.26321256160736084
Batch 46/64 loss: 0.2466726303100586
Batch 47/64 loss: 0.2597205638885498
Batch 48/64 loss: 0.2558925151824951
Batch 49/64 loss: 0.2548820972442627
Batch 50/64 loss: 0.2557324171066284
Batch 51/64 loss: 0.2554202079772949
Batch 52/64 loss: 0.25920140743255615
Batch 53/64 loss: 0.2597774267196655
Batch 54/64 loss: 0.2668420076370239
Batch 55/64 loss: 0.2513432502746582
Batch 56/64 loss: 0.25102388858795166
Batch 57/64 loss: 0.2578086853027344
Batch 58/64 loss: 0.2558462619781494
Batch 59/64 loss: 0.2599964141845703
Batch 60/64 loss: 0.26167356967926025
Batch 61/64 loss: 0.25302958488464355
Batch 62/64 loss: 0.2533433437347412
Batch 63/64 loss: 0.2685343027114868
Batch 64/64 loss: 0.25502943992614746
Epoch 255  Train loss: 0.258300947675518  Val loss: 0.285340788847802
Saving best model, epoch: 255
Epoch 256
-------------------------------
Batch 1/64 loss: 0.2553228735923767
Batch 2/64 loss: 0.260367751121521
Batch 3/64 loss: 0.2542538642883301
Batch 4/64 loss: 0.2561779022216797
Batch 5/64 loss: 0.2605794668197632
Batch 6/64 loss: 0.2659832239151001
Batch 7/64 loss: 0.2703152298927307
Batch 8/64 loss: 0.26258909702301025
Batch 9/64 loss: 0.2596747875213623
Batch 10/64 loss: 0.25904029607772827
Batch 11/64 loss: 0.24818634986877441
Batch 12/64 loss: 0.25621700286865234
Batch 13/64 loss: 0.25212788581848145
Batch 14/64 loss: 0.2535579204559326
Batch 15/64 loss: 0.265214204788208
Batch 16/64 loss: 0.26703178882598877
Batch 17/64 loss: 0.25535279512405396
Batch 18/64 loss: 0.25856202840805054
Batch 19/64 loss: 0.2569981813430786
Batch 20/64 loss: 0.2536693215370178
Batch 21/64 loss: 0.2580161690711975
Batch 22/64 loss: 0.2635303735733032
Batch 23/64 loss: 0.2648890018463135
Batch 24/64 loss: 0.24874699115753174
Batch 25/64 loss: 0.2588425874710083
Batch 26/64 loss: 0.27167123556137085
Batch 27/64 loss: 0.26243847608566284
Batch 28/64 loss: 0.2510918378829956
Batch 29/64 loss: 0.25501275062561035
Batch 30/64 loss: 0.25347185134887695
Batch 31/64 loss: 0.2599191665649414
Batch 32/64 loss: 0.26011645793914795
Batch 33/64 loss: 0.2589496970176697
Batch 34/64 loss: 0.24654608964920044
Batch 35/64 loss: 0.26449888944625854
Batch 36/64 loss: 0.2535213232040405
Batch 37/64 loss: 0.24925649166107178
Batch 38/64 loss: 0.25083041191101074
Batch 39/64 loss: 0.25111085176467896
Batch 40/64 loss: 0.27203893661499023
Batch 41/64 loss: 0.26893240213394165
Batch 42/64 loss: 0.2532362937927246
Batch 43/64 loss: 0.2514273524284363
Batch 44/64 loss: 0.2616385221481323
Batch 45/64 loss: 0.26642167568206787
Batch 46/64 loss: 0.2550327777862549
Batch 47/64 loss: 0.2508203387260437
Batch 48/64 loss: 0.25704872608184814
Batch 49/64 loss: 0.24929273128509521
Batch 50/64 loss: 0.26388025283813477
Batch 51/64 loss: 0.26305103302001953
Batch 52/64 loss: 0.2532076835632324
Batch 53/64 loss: 0.2591514587402344
Batch 54/64 loss: 0.2599543333053589
Batch 55/64 loss: 0.2566388249397278
Batch 56/64 loss: 0.26428818702697754
Batch 57/64 loss: 0.2575070261955261
Batch 58/64 loss: 0.2652490735054016
Batch 59/64 loss: 0.25068598985671997
Batch 60/64 loss: 0.2511392831802368
Batch 61/64 loss: 0.2585687041282654
Batch 62/64 loss: 0.26459693908691406
Batch 63/64 loss: 0.26101863384246826
Batch 64/64 loss: 0.2716001272201538
Epoch 256  Train loss: 0.25838760628419766  Val loss: 0.2864912869184697
Epoch 257
-------------------------------
Batch 1/64 loss: 0.2534518241882324
Batch 2/64 loss: 0.2530384659767151
Batch 3/64 loss: 0.2544294595718384
Batch 4/64 loss: 0.25739026069641113
Batch 5/64 loss: 0.2501254677772522
Batch 6/64 loss: 0.2647205591201782
Batch 7/64 loss: 0.2682783007621765
Batch 8/64 loss: 0.25071030855178833
Batch 9/64 loss: 0.2557028532028198
Batch 10/64 loss: 0.24870049953460693
Batch 11/64 loss: 0.2592584490776062
Batch 12/64 loss: 0.25196731090545654
Batch 13/64 loss: 0.25811469554901123
Batch 14/64 loss: 0.2586190700531006
Batch 15/64 loss: 0.2625879645347595
Batch 16/64 loss: 0.26828229427337646
Batch 17/64 loss: 0.25816094875335693
Batch 18/64 loss: 0.25911009311676025
Batch 19/64 loss: 0.269733190536499
Batch 20/64 loss: 0.2628512382507324
Batch 21/64 loss: 0.2538819909095764
Batch 22/64 loss: 0.25774478912353516
Batch 23/64 loss: 0.26048123836517334
Batch 24/64 loss: 0.2450534701347351
Batch 25/64 loss: 0.2568265199661255
Batch 26/64 loss: 0.255731463432312
Batch 27/64 loss: 0.25971877574920654
Batch 28/64 loss: 0.2525750994682312
Batch 29/64 loss: 0.26056456565856934
Batch 30/64 loss: 0.25105494260787964
Batch 31/64 loss: 0.2593141794204712
Batch 32/64 loss: 0.26140856742858887
Batch 33/64 loss: 0.2564586400985718
Batch 34/64 loss: 0.2510356307029724
Batch 35/64 loss: 0.25774550437927246
Batch 36/64 loss: 0.26412463188171387
Batch 37/64 loss: 0.25481778383255005
Batch 38/64 loss: 0.25450557470321655
Batch 39/64 loss: 0.25640004873275757
Batch 40/64 loss: 0.2590962052345276
Batch 41/64 loss: 0.25980281829833984
Batch 42/64 loss: 0.2588401436805725
Batch 43/64 loss: 0.2550652027130127
Batch 44/64 loss: 0.25075310468673706
Batch 45/64 loss: 0.24995887279510498
Batch 46/64 loss: 0.2682681083679199
Batch 47/64 loss: 0.265703022480011
Batch 48/64 loss: 0.2760277986526489
Batch 49/64 loss: 0.25132983922958374
Batch 50/64 loss: 0.254596471786499
Batch 51/64 loss: 0.2603302001953125
Batch 52/64 loss: 0.25624269247055054
Batch 53/64 loss: 0.25860679149627686
Batch 54/64 loss: 0.27311432361602783
Batch 55/64 loss: 0.26071274280548096
Batch 56/64 loss: 0.2646695375442505
Batch 57/64 loss: 0.2540466785430908
Batch 58/64 loss: 0.2548248767852783
Batch 59/64 loss: 0.2515357732772827
Batch 60/64 loss: 0.2637906074523926
Batch 61/64 loss: 0.2581007480621338
Batch 62/64 loss: 0.26109981536865234
Batch 63/64 loss: 0.25555360317230225
Batch 64/64 loss: 0.25554537773132324
Epoch 257  Train loss: 0.258014206792794  Val loss: 0.2855257066254763
Epoch 258
-------------------------------
Batch 1/64 loss: 0.25732696056365967
Batch 2/64 loss: 0.2542765736579895
Batch 3/64 loss: 0.25420135259628296
Batch 4/64 loss: 0.2533884048461914
Batch 5/64 loss: 0.2551116943359375
Batch 6/64 loss: 0.25019001960754395
Batch 7/64 loss: 0.25444042682647705
Batch 8/64 loss: 0.26296913623809814
Batch 9/64 loss: 0.2533552646636963
Batch 10/64 loss: 0.2547762393951416
Batch 11/64 loss: 0.2595008611679077
Batch 12/64 loss: 0.25720882415771484
Batch 13/64 loss: 0.2589397430419922
Batch 14/64 loss: 0.24951857328414917
Batch 15/64 loss: 0.2584960460662842
Batch 16/64 loss: 0.25286805629730225
Batch 17/64 loss: 0.26058292388916016
Batch 18/64 loss: 0.2566981315612793
Batch 19/64 loss: 0.24973320960998535
Batch 20/64 loss: 0.2536677122116089
Batch 21/64 loss: 0.2561498284339905
Batch 22/64 loss: 0.2588404417037964
Batch 23/64 loss: 0.25844430923461914
Batch 24/64 loss: 0.2608147859573364
Batch 25/64 loss: 0.26051127910614014
Batch 26/64 loss: 0.26661694049835205
Batch 27/64 loss: 0.25286751985549927
Batch 28/64 loss: 0.257274866104126
Batch 29/64 loss: 0.2609119415283203
Batch 30/64 loss: 0.26878058910369873
Batch 31/64 loss: 0.2545265555381775
Batch 32/64 loss: 0.2594674825668335
Batch 33/64 loss: 0.2626602053642273
Batch 34/64 loss: 0.2643023133277893
Batch 35/64 loss: 0.2564336061477661
Batch 36/64 loss: 0.2609304189682007
Batch 37/64 loss: 0.25476688146591187
Batch 38/64 loss: 0.252577543258667
Batch 39/64 loss: 0.2582380175590515
Batch 40/64 loss: 0.2560085654258728
Batch 41/64 loss: 0.248063325881958
Batch 42/64 loss: 0.2573224902153015
Batch 43/64 loss: 0.26065683364868164
Batch 44/64 loss: 0.25124967098236084
Batch 45/64 loss: 0.26277804374694824
Batch 46/64 loss: 0.256328821182251
Batch 47/64 loss: 0.25944769382476807
Batch 48/64 loss: 0.26318538188934326
Batch 49/64 loss: 0.266168475151062
Batch 50/64 loss: 0.2597200870513916
Batch 51/64 loss: 0.2558358907699585
Batch 52/64 loss: 0.25398755073547363
Batch 53/64 loss: 0.25829076766967773
Batch 54/64 loss: 0.2574939727783203
Batch 55/64 loss: 0.2572978734970093
Batch 56/64 loss: 0.26734858751296997
Batch 57/64 loss: 0.2518168091773987
Batch 58/64 loss: 0.2603651285171509
Batch 59/64 loss: 0.25285863876342773
Batch 60/64 loss: 0.2682065963745117
Batch 61/64 loss: 0.2662994861602783
Batch 62/64 loss: 0.26540064811706543
Batch 63/64 loss: 0.2500709295272827
Batch 64/64 loss: 0.25395816564559937
Epoch 258  Train loss: 0.25771037760902854  Val loss: 0.285182959640149
Saving best model, epoch: 258
Epoch 259
-------------------------------
Batch 1/64 loss: 0.2582753896713257
Batch 2/64 loss: 0.2613788843154907
Batch 3/64 loss: 0.25836676359176636
Batch 4/64 loss: 0.25407904386520386
Batch 5/64 loss: 0.25448334217071533
Batch 6/64 loss: 0.2575899362564087
Batch 7/64 loss: 0.2666201591491699
Batch 8/64 loss: 0.2563186287879944
Batch 9/64 loss: 0.2610185742378235
Batch 10/64 loss: 0.2502986192703247
Batch 11/64 loss: 0.26276063919067383
Batch 12/64 loss: 0.24884510040283203
Batch 13/64 loss: 0.25698375701904297
Batch 14/64 loss: 0.25949907302856445
Batch 15/64 loss: 0.2555003762245178
Batch 16/64 loss: 0.25316184759140015
Batch 17/64 loss: 0.24897068738937378
Batch 18/64 loss: 0.2584612965583801
Batch 19/64 loss: 0.26791930198669434
Batch 20/64 loss: 0.2620154619216919
Batch 21/64 loss: 0.2602617144584656
Batch 22/64 loss: 0.24720966815948486
Batch 23/64 loss: 0.24912786483764648
Batch 24/64 loss: 0.2531737685203552
Batch 25/64 loss: 0.2615087032318115
Batch 26/64 loss: 0.26554346084594727
Batch 27/64 loss: 0.24710345268249512
Batch 28/64 loss: 0.2507573366165161
Batch 29/64 loss: 0.2619600296020508
Batch 30/64 loss: 0.25253623723983765
Batch 31/64 loss: 0.2541712522506714
Batch 32/64 loss: 0.26139557361602783
Batch 33/64 loss: 0.24407029151916504
Batch 34/64 loss: 0.25954389572143555
Batch 35/64 loss: 0.24645864963531494
Batch 36/64 loss: 0.254605770111084
Batch 37/64 loss: 0.2527334690093994
Batch 38/64 loss: 0.2672916650772095
Batch 39/64 loss: 0.2629767656326294
Batch 40/64 loss: 0.26058030128479004
Batch 41/64 loss: 0.26201188564300537
Batch 42/64 loss: 0.2715955972671509
Batch 43/64 loss: 0.25858575105667114
Batch 44/64 loss: 0.26303958892822266
Batch 45/64 loss: 0.2607835531234741
Batch 46/64 loss: 0.2648816704750061
Batch 47/64 loss: 0.2528787851333618
Batch 48/64 loss: 0.2543641924858093
Batch 49/64 loss: 0.263999342918396
Batch 50/64 loss: 0.25183039903640747
Batch 51/64 loss: 0.26305389404296875
Batch 52/64 loss: 0.2506825923919678
Batch 53/64 loss: 0.2609090209007263
Batch 54/64 loss: 0.2614697217941284
Batch 55/64 loss: 0.24998217821121216
Batch 56/64 loss: 0.2612927556037903
Batch 57/64 loss: 0.2623905539512634
Batch 58/64 loss: 0.2605029344558716
Batch 59/64 loss: 0.26175403594970703
Batch 60/64 loss: 0.26661431789398193
Batch 61/64 loss: 0.2557255029678345
Batch 62/64 loss: 0.2575119733810425
Batch 63/64 loss: 0.2604484558105469
Batch 64/64 loss: 0.2527109980583191
Epoch 259  Train loss: 0.25774743066114536  Val loss: 0.2859099869875564
Epoch 260
-------------------------------
Batch 1/64 loss: 0.24865341186523438
Batch 2/64 loss: 0.26021575927734375
Batch 3/64 loss: 0.25873202085494995
Batch 4/64 loss: 0.25843536853790283
Batch 5/64 loss: 0.2525317668914795
Batch 6/64 loss: 0.24786412715911865
Batch 7/64 loss: 0.26097553968429565
Batch 8/64 loss: 0.2568010091781616
Batch 9/64 loss: 0.26149797439575195
Batch 10/64 loss: 0.24939370155334473
Batch 11/64 loss: 0.26073157787323
Batch 12/64 loss: 0.25780314207077026
Batch 13/64 loss: 0.2587566375732422
Batch 14/64 loss: 0.2541325092315674
Batch 15/64 loss: 0.2575852870941162
Batch 16/64 loss: 0.25054264068603516
Batch 17/64 loss: 0.24957799911499023
Batch 18/64 loss: 0.2590636610984802
Batch 19/64 loss: 0.2552366256713867
Batch 20/64 loss: 0.2673865556716919
Batch 21/64 loss: 0.2516756057739258
Batch 22/64 loss: 0.2596650719642639
Batch 23/64 loss: 0.24683010578155518
Batch 24/64 loss: 0.2549055814743042
Batch 25/64 loss: 0.2649405002593994
Batch 26/64 loss: 0.2561683654785156
Batch 27/64 loss: 0.27533429861068726
Batch 28/64 loss: 0.26236414909362793
Batch 29/64 loss: 0.2557733654975891
Batch 30/64 loss: 0.2585493326187134
Batch 31/64 loss: 0.2505633234977722
Batch 32/64 loss: 0.2585800886154175
Batch 33/64 loss: 0.2638667821884155
Batch 34/64 loss: 0.259975790977478
Batch 35/64 loss: 0.2620376944541931
Batch 36/64 loss: 0.25281989574432373
Batch 37/64 loss: 0.2535409927368164
Batch 38/64 loss: 0.2513805031776428
Batch 39/64 loss: 0.259834885597229
Batch 40/64 loss: 0.25316083431243896
Batch 41/64 loss: 0.26390814781188965
Batch 42/64 loss: 0.257510781288147
Batch 43/64 loss: 0.2528378963470459
Batch 44/64 loss: 0.26202988624572754
Batch 45/64 loss: 0.26324665546417236
Batch 46/64 loss: 0.26134324073791504
Batch 47/64 loss: 0.2547013759613037
Batch 48/64 loss: 0.26074039936065674
Batch 49/64 loss: 0.2610573172569275
Batch 50/64 loss: 0.25545376539230347
Batch 51/64 loss: 0.2592421770095825
Batch 52/64 loss: 0.2641516327857971
Batch 53/64 loss: 0.258617639541626
Batch 54/64 loss: 0.25397026538848877
Batch 55/64 loss: 0.25410622358322144
Batch 56/64 loss: 0.2562662363052368
Batch 57/64 loss: 0.25533103942871094
Batch 58/64 loss: 0.26067662239074707
Batch 59/64 loss: 0.25320595502853394
Batch 60/64 loss: 0.2583877444267273
Batch 61/64 loss: 0.264556884765625
Batch 62/64 loss: 0.2615402936935425
Batch 63/64 loss: 0.2616238594055176
Batch 64/64 loss: 0.25718486309051514
Epoch 260  Train loss: 0.2576514379650939  Val loss: 0.2857943189512823
Epoch 261
-------------------------------
Batch 1/64 loss: 0.25462430715560913
Batch 2/64 loss: 0.25263893604278564
Batch 3/64 loss: 0.25544559955596924
Batch 4/64 loss: 0.2586565613746643
Batch 5/64 loss: 0.24500000476837158
Batch 6/64 loss: 0.26162147521972656
Batch 7/64 loss: 0.2466500997543335
Batch 8/64 loss: 0.26233339309692383
Batch 9/64 loss: 0.25784432888031006
Batch 10/64 loss: 0.2528267502784729
Batch 11/64 loss: 0.26183056831359863
Batch 12/64 loss: 0.25080299377441406
Batch 13/64 loss: 0.24644899368286133
Batch 14/64 loss: 0.24851703643798828
Batch 15/64 loss: 0.2563576102256775
Batch 16/64 loss: 0.25402969121932983
Batch 17/64 loss: 0.2591690421104431
Batch 18/64 loss: 0.24481791257858276
Batch 19/64 loss: 0.25660914182662964
Batch 20/64 loss: 0.2679569721221924
Batch 21/64 loss: 0.2603491544723511
Batch 22/64 loss: 0.2584512233734131
Batch 23/64 loss: 0.2622995376586914
Batch 24/64 loss: 0.2535831928253174
Batch 25/64 loss: 0.272630512714386
Batch 26/64 loss: 0.2502205967903137
Batch 27/64 loss: 0.2579500675201416
Batch 28/64 loss: 0.2681901454925537
Batch 29/64 loss: 0.2555619478225708
Batch 30/64 loss: 0.2524815797805786
Batch 31/64 loss: 0.2574770450592041
Batch 32/64 loss: 0.2602868676185608
Batch 33/64 loss: 0.2501591444015503
Batch 34/64 loss: 0.24724632501602173
Batch 35/64 loss: 0.24881207942962646
Batch 36/64 loss: 0.24979066848754883
Batch 37/64 loss: 0.250704288482666
Batch 38/64 loss: 0.26373690366744995
Batch 39/64 loss: 0.2529919743537903
Batch 40/64 loss: 0.24435269832611084
Batch 41/64 loss: 0.2571427822113037
Batch 42/64 loss: 0.25871896743774414
Batch 43/64 loss: 0.25776100158691406
Batch 44/64 loss: 0.25937724113464355
Batch 45/64 loss: 0.2596193552017212
Batch 46/64 loss: 0.24863791465759277
Batch 47/64 loss: 0.2516390085220337
Batch 48/64 loss: 0.2642826437950134
Batch 49/64 loss: 0.27469736337661743
Batch 50/64 loss: 0.2540140748023987
Batch 51/64 loss: 0.26284778118133545
Batch 52/64 loss: 0.26351863145828247
Batch 53/64 loss: 0.26725900173187256
Batch 54/64 loss: 0.2558727264404297
Batch 55/64 loss: 0.2603405714035034
Batch 56/64 loss: 0.25967371463775635
Batch 57/64 loss: 0.2690349817276001
Batch 58/64 loss: 0.26240575313568115
Batch 59/64 loss: 0.2546076774597168
Batch 60/64 loss: 0.24719887971878052
Batch 61/64 loss: 0.25309252738952637
Batch 62/64 loss: 0.25894689559936523
Batch 63/64 loss: 0.261979877948761
Batch 64/64 loss: 0.261816143989563
Epoch 261  Train loss: 0.25679198199627445  Val loss: 0.2861530592351435
Epoch 262
-------------------------------
Batch 1/64 loss: 0.25623786449432373
Batch 2/64 loss: 0.2682229280471802
Batch 3/64 loss: 0.2597391605377197
Batch 4/64 loss: 0.2538813352584839
Batch 5/64 loss: 0.2672414779663086
Batch 6/64 loss: 0.2595165967941284
Batch 7/64 loss: 0.2495943307876587
Batch 8/64 loss: 0.26003777980804443
Batch 9/64 loss: 0.251883327960968
Batch 10/64 loss: 0.2586895227432251
Batch 11/64 loss: 0.25206708908081055
Batch 12/64 loss: 0.2468588948249817
Batch 13/64 loss: 0.2734792232513428
Batch 14/64 loss: 0.25059956312179565
Batch 15/64 loss: 0.2573678493499756
Batch 16/64 loss: 0.2645832896232605
Batch 17/64 loss: 0.2571783661842346
Batch 18/64 loss: 0.24935120344161987
Batch 19/64 loss: 0.26178431510925293
Batch 20/64 loss: 0.24574661254882812
Batch 21/64 loss: 0.25569212436676025
Batch 22/64 loss: 0.26015913486480713
Batch 23/64 loss: 0.25727272033691406
Batch 24/64 loss: 0.250286340713501
Batch 25/64 loss: 0.2529160976409912
Batch 26/64 loss: 0.25960326194763184
Batch 27/64 loss: 0.25633567571640015
Batch 28/64 loss: 0.26394444704055786
Batch 29/64 loss: 0.25248146057128906
Batch 30/64 loss: 0.2552165985107422
Batch 31/64 loss: 0.24984192848205566
Batch 32/64 loss: 0.25612854957580566
Batch 33/64 loss: 0.2524978518486023
Batch 34/64 loss: 0.263213574886322
Batch 35/64 loss: 0.25285857915878296
Batch 36/64 loss: 0.25234484672546387
Batch 37/64 loss: 0.2684227228164673
Batch 38/64 loss: 0.2567287087440491
Batch 39/64 loss: 0.25502967834472656
Batch 40/64 loss: 0.2687612771987915
Batch 41/64 loss: 0.26168715953826904
Batch 42/64 loss: 0.2602365016937256
Batch 43/64 loss: 0.2541469931602478
Batch 44/64 loss: 0.2569735646247864
Batch 45/64 loss: 0.26088041067123413
Batch 46/64 loss: 0.2596772313117981
Batch 47/64 loss: 0.2694946527481079
Batch 48/64 loss: 0.26348352432250977
Batch 49/64 loss: 0.2461632490158081
Batch 50/64 loss: 0.2552694082260132
Batch 51/64 loss: 0.26084834337234497
Batch 52/64 loss: 0.2589574456214905
Batch 53/64 loss: 0.2541029453277588
Batch 54/64 loss: 0.25498753786087036
Batch 55/64 loss: 0.2542073726654053
Batch 56/64 loss: 0.26249587535858154
Batch 57/64 loss: 0.2573601007461548
Batch 58/64 loss: 0.25965142250061035
Batch 59/64 loss: 0.2649575471878052
Batch 60/64 loss: 0.26549232006073
Batch 61/64 loss: 0.2642921209335327
Batch 62/64 loss: 0.25385230779647827
Batch 63/64 loss: 0.26021331548690796
Batch 64/64 loss: 0.24790525436401367
Epoch 262  Train loss: 0.25771226041457235  Val loss: 0.285102118946023
Saving best model, epoch: 262
Epoch 263
-------------------------------
Batch 1/64 loss: 0.2601054906845093
Batch 2/64 loss: 0.24455463886260986
Batch 3/64 loss: 0.24597150087356567
Batch 4/64 loss: 0.25314295291900635
Batch 5/64 loss: 0.26275116205215454
Batch 6/64 loss: 0.2626712918281555
Batch 7/64 loss: 0.2503676414489746
Batch 8/64 loss: 0.25619256496429443
Batch 9/64 loss: 0.267583966255188
Batch 10/64 loss: 0.2488207221031189
Batch 11/64 loss: 0.25576698780059814
Batch 12/64 loss: 0.254219651222229
Batch 13/64 loss: 0.25058722496032715
Batch 14/64 loss: 0.2557501792907715
Batch 15/64 loss: 0.252685546875
Batch 16/64 loss: 0.259684681892395
Batch 17/64 loss: 0.26266855001449585
Batch 18/64 loss: 0.2555420398712158
Batch 19/64 loss: 0.25845086574554443
Batch 20/64 loss: 0.2546408772468567
Batch 21/64 loss: 0.261677622795105
Batch 22/64 loss: 0.2590625286102295
Batch 23/64 loss: 0.2616669535636902
Batch 24/64 loss: 0.2534216642379761
Batch 25/64 loss: 0.2659488916397095
Batch 26/64 loss: 0.255995512008667
Batch 27/64 loss: 0.2559303045272827
Batch 28/64 loss: 0.2577800750732422
Batch 29/64 loss: 0.26246917247772217
Batch 30/64 loss: 0.2571742534637451
Batch 31/64 loss: 0.2483816146850586
Batch 32/64 loss: 0.25923919677734375
Batch 33/64 loss: 0.26373374462127686
Batch 34/64 loss: 0.256775438785553
Batch 35/64 loss: 0.25730061531066895
Batch 36/64 loss: 0.25666701793670654
Batch 37/64 loss: 0.26791369915008545
Batch 38/64 loss: 0.25792330503463745
Batch 39/64 loss: 0.2692529559135437
Batch 40/64 loss: 0.2580934762954712
Batch 41/64 loss: 0.2559841275215149
Batch 42/64 loss: 0.2542792558670044
Batch 43/64 loss: 0.2585894465446472
Batch 44/64 loss: 0.2506769895553589
Batch 45/64 loss: 0.26856398582458496
Batch 46/64 loss: 0.26276707649230957
Batch 47/64 loss: 0.24830341339111328
Batch 48/64 loss: 0.25814616680145264
Batch 49/64 loss: 0.2578234076499939
Batch 50/64 loss: 0.25956547260284424
Batch 51/64 loss: 0.2612851858139038
Batch 52/64 loss: 0.25099754333496094
Batch 53/64 loss: 0.2531017065048218
Batch 54/64 loss: 0.2505049705505371
Batch 55/64 loss: 0.2590970993041992
Batch 56/64 loss: 0.2557007074356079
Batch 57/64 loss: 0.2523730993270874
Batch 58/64 loss: 0.2567545175552368
Batch 59/64 loss: 0.24889254570007324
Batch 60/64 loss: 0.25223398208618164
Batch 61/64 loss: 0.2619768977165222
Batch 62/64 loss: 0.2612330913543701
Batch 63/64 loss: 0.250909686088562
Batch 64/64 loss: 0.2581478953361511
Epoch 263  Train loss: 0.256971574530882  Val loss: 0.28522128051089257
Epoch 264
-------------------------------
Batch 1/64 loss: 0.25782275199890137
Batch 2/64 loss: 0.2583400011062622
Batch 3/64 loss: 0.24599766731262207
Batch 4/64 loss: 0.25055813789367676
Batch 5/64 loss: 0.2555302381515503
Batch 6/64 loss: 0.2569863796234131
Batch 7/64 loss: 0.2547363042831421
Batch 8/64 loss: 0.25681430101394653
Batch 9/64 loss: 0.24709880352020264
Batch 10/64 loss: 0.26164495944976807
Batch 11/64 loss: 0.25698602199554443
Batch 12/64 loss: 0.2530582547187805
Batch 13/64 loss: 0.25477147102355957
Batch 14/64 loss: 0.24741530418395996
Batch 15/64 loss: 0.27550429105758667
Batch 16/64 loss: 0.25738251209259033
Batch 17/64 loss: 0.2586498260498047
Batch 18/64 loss: 0.2587467432022095
Batch 19/64 loss: 0.24600905179977417
Batch 20/64 loss: 0.25075870752334595
Batch 21/64 loss: 0.25697922706604004
Batch 22/64 loss: 0.25579869747161865
Batch 23/64 loss: 0.2508080005645752
Batch 24/64 loss: 0.2652997374534607
Batch 25/64 loss: 0.24518859386444092
Batch 26/64 loss: 0.26262974739074707
Batch 27/64 loss: 0.2592356204986572
Batch 28/64 loss: 0.2620850205421448
Batch 29/64 loss: 0.2622605562210083
Batch 30/64 loss: 0.2571655511856079
Batch 31/64 loss: 0.25130635499954224
Batch 32/64 loss: 0.26017946004867554
Batch 33/64 loss: 0.25424933433532715
Batch 34/64 loss: 0.25464433431625366
Batch 35/64 loss: 0.26432234048843384
Batch 36/64 loss: 0.25554007291793823
Batch 37/64 loss: 0.2546072006225586
Batch 38/64 loss: 0.2546972632408142
Batch 39/64 loss: 0.2619040012359619
Batch 40/64 loss: 0.25631678104400635
Batch 41/64 loss: 0.24908363819122314
Batch 42/64 loss: 0.25885307788848877
Batch 43/64 loss: 0.25939589738845825
Batch 44/64 loss: 0.251989483833313
Batch 45/64 loss: 0.24940437078475952
Batch 46/64 loss: 0.2466796636581421
Batch 47/64 loss: 0.25244206190109253
Batch 48/64 loss: 0.25019657611846924
Batch 49/64 loss: 0.2527546286582947
Batch 50/64 loss: 0.2529348134994507
Batch 51/64 loss: 0.25510919094085693
Batch 52/64 loss: 0.25424671173095703
Batch 53/64 loss: 0.2525193691253662
Batch 54/64 loss: 0.2618281841278076
Batch 55/64 loss: 0.26168161630630493
Batch 56/64 loss: 0.26815664768218994
Batch 57/64 loss: 0.2534351348876953
Batch 58/64 loss: 0.2628510594367981
Batch 59/64 loss: 0.2569315433502197
Batch 60/64 loss: 0.25500738620758057
Batch 61/64 loss: 0.2537885904312134
Batch 62/64 loss: 0.25536274909973145
Batch 63/64 loss: 0.2484568953514099
Batch 64/64 loss: 0.26113462448120117
Epoch 264  Train loss: 0.2558272922740263  Val loss: 0.28529688377970275
Epoch 265
-------------------------------
Batch 1/64 loss: 0.2678256630897522
Batch 2/64 loss: 0.2548341155052185
Batch 3/64 loss: 0.2505342960357666
Batch 4/64 loss: 0.25772106647491455
Batch 5/64 loss: 0.2533057928085327
Batch 6/64 loss: 0.25292766094207764
Batch 7/64 loss: 0.2610139846801758
Batch 8/64 loss: 0.2626769542694092
Batch 9/64 loss: 0.25479555130004883
Batch 10/64 loss: 0.260026216506958
Batch 11/64 loss: 0.25661057233810425
Batch 12/64 loss: 0.2522376775741577
Batch 13/64 loss: 0.2578046917915344
Batch 14/64 loss: 0.25199276208877563
Batch 15/64 loss: 0.26205360889434814
Batch 16/64 loss: 0.24676525592803955
Batch 17/64 loss: 0.26190078258514404
Batch 18/64 loss: 0.2549930810928345
Batch 19/64 loss: 0.256217896938324
Batch 20/64 loss: 0.2520540952682495
Batch 21/64 loss: 0.25420892238616943
Batch 22/64 loss: 0.2515714764595032
Batch 23/64 loss: 0.2559925317764282
Batch 24/64 loss: 0.2524222135543823
Batch 25/64 loss: 0.2566223740577698
Batch 26/64 loss: 0.247688889503479
Batch 27/64 loss: 0.25831228494644165
Batch 28/64 loss: 0.2560904026031494
Batch 29/64 loss: 0.24858784675598145
Batch 30/64 loss: 0.2527419328689575
Batch 31/64 loss: 0.24554139375686646
Batch 32/64 loss: 0.24835145473480225
Batch 33/64 loss: 0.24851375818252563
Batch 34/64 loss: 0.249639093875885
Batch 35/64 loss: 0.24326324462890625
Batch 36/64 loss: 0.2582804560661316
Batch 37/64 loss: 0.2710120677947998
Batch 38/64 loss: 0.26514118909835815
Batch 39/64 loss: 0.25078803300857544
Batch 40/64 loss: 0.2607555389404297
Batch 41/64 loss: 0.26112473011016846
Batch 42/64 loss: 0.2621995210647583
Batch 43/64 loss: 0.2675447463989258
Batch 44/64 loss: 0.2677575349807739
Batch 45/64 loss: 0.2559521198272705
Batch 46/64 loss: 0.2582654356956482
Batch 47/64 loss: 0.26374638080596924
Batch 48/64 loss: 0.2525483965873718
Batch 49/64 loss: 0.26274746656417847
Batch 50/64 loss: 0.2570767402648926
Batch 51/64 loss: 0.24479329586029053
Batch 52/64 loss: 0.2548859119415283
Batch 53/64 loss: 0.25502192974090576
Batch 54/64 loss: 0.2615593671798706
Batch 55/64 loss: 0.25951647758483887
Batch 56/64 loss: 0.2522968053817749
Batch 57/64 loss: 0.2618675231933594
Batch 58/64 loss: 0.2540614604949951
Batch 59/64 loss: 0.2603055238723755
Batch 60/64 loss: 0.25805699825286865
Batch 61/64 loss: 0.25613605976104736
Batch 62/64 loss: 0.25279510021209717
Batch 63/64 loss: 0.26509636640548706
Batch 64/64 loss: 0.25316381454467773
Epoch 265  Train loss: 0.2562987542619892  Val loss: 0.2859320308744293
Epoch 266
-------------------------------
Batch 1/64 loss: 0.258992075920105
Batch 2/64 loss: 0.26160478591918945
Batch 3/64 loss: 0.2581096887588501
Batch 4/64 loss: 0.26581478118896484
Batch 5/64 loss: 0.2591216564178467
Batch 6/64 loss: 0.26088160276412964
Batch 7/64 loss: 0.2589043974876404
Batch 8/64 loss: 0.2553595304489136
Batch 9/64 loss: 0.2563236951828003
Batch 10/64 loss: 0.24949324131011963
Batch 11/64 loss: 0.25488513708114624
Batch 12/64 loss: 0.25524383783340454
Batch 13/64 loss: 0.25167155265808105
Batch 14/64 loss: 0.25854742527008057
Batch 15/64 loss: 0.2543879747390747
Batch 16/64 loss: 0.2574955224990845
Batch 17/64 loss: 0.2520939111709595
Batch 18/64 loss: 0.26259946823120117
Batch 19/64 loss: 0.24880141019821167
Batch 20/64 loss: 0.2573355436325073
Batch 21/64 loss: 0.2565504312515259
Batch 22/64 loss: 0.2522701025009155
Batch 23/64 loss: 0.2552666664123535
Batch 24/64 loss: 0.2552664279937744
Batch 25/64 loss: 0.25574254989624023
Batch 26/64 loss: 0.2572234869003296
Batch 27/64 loss: 0.26162487268447876
Batch 28/64 loss: 0.24844586849212646
Batch 29/64 loss: 0.2584989070892334
Batch 30/64 loss: 0.2510124444961548
Batch 31/64 loss: 0.25667786598205566
Batch 32/64 loss: 0.2465413212776184
Batch 33/64 loss: 0.2622873783111572
Batch 34/64 loss: 0.25491130352020264
Batch 35/64 loss: 0.25631773471832275
Batch 36/64 loss: 0.24359524250030518
Batch 37/64 loss: 0.26276934146881104
Batch 38/64 loss: 0.25405216217041016
Batch 39/64 loss: 0.2511497735977173
Batch 40/64 loss: 0.26510584354400635
Batch 41/64 loss: 0.2497919797897339
Batch 42/64 loss: 0.24466264247894287
Batch 43/64 loss: 0.25306880474090576
Batch 44/64 loss: 0.253203809261322
Batch 45/64 loss: 0.25684797763824463
Batch 46/64 loss: 0.26520973443984985
Batch 47/64 loss: 0.26577305793762207
Batch 48/64 loss: 0.2543262839317322
Batch 49/64 loss: 0.2664828300476074
Batch 50/64 loss: 0.25834333896636963
Batch 51/64 loss: 0.2566591501235962
Batch 52/64 loss: 0.26059722900390625
Batch 53/64 loss: 0.2539830207824707
Batch 54/64 loss: 0.2500845193862915
Batch 55/64 loss: 0.24986004829406738
Batch 56/64 loss: 0.2637646794319153
Batch 57/64 loss: 0.2583956718444824
Batch 58/64 loss: 0.2532646656036377
Batch 59/64 loss: 0.2522360682487488
Batch 60/64 loss: 0.25022757053375244
Batch 61/64 loss: 0.2650498151779175
Batch 62/64 loss: 0.25197696685791016
Batch 63/64 loss: 0.25173407793045044
Batch 64/64 loss: 0.252627968788147
Epoch 266  Train loss: 0.2559685001186296  Val loss: 0.2861754402671893
Epoch 267
-------------------------------
Batch 1/64 loss: 0.26538437604904175
Batch 2/64 loss: 0.24317872524261475
Batch 3/64 loss: 0.24495208263397217
Batch 4/64 loss: 0.25982099771499634
Batch 5/64 loss: 0.2588977813720703
Batch 6/64 loss: 0.25701892375946045
Batch 7/64 loss: 0.24712353944778442
Batch 8/64 loss: 0.2582666873931885
Batch 9/64 loss: 0.26107048988342285
Batch 10/64 loss: 0.25969046354293823
Batch 11/64 loss: 0.25163328647613525
Batch 12/64 loss: 0.250618577003479
Batch 13/64 loss: 0.25218600034713745
Batch 14/64 loss: 0.25487077236175537
Batch 15/64 loss: 0.25009799003601074
Batch 16/64 loss: 0.25799983739852905
Batch 17/64 loss: 0.2615772485733032
Batch 18/64 loss: 0.2529478073120117
Batch 19/64 loss: 0.24876528978347778
Batch 20/64 loss: 0.2536412477493286
Batch 21/64 loss: 0.25646698474884033
Batch 22/64 loss: 0.26549071073532104
Batch 23/64 loss: 0.26277077198028564
Batch 24/64 loss: 0.2689852714538574
Batch 25/64 loss: 0.26435214281082153
Batch 26/64 loss: 0.24636828899383545
Batch 27/64 loss: 0.2542203664779663
Batch 28/64 loss: 0.25601232051849365
Batch 29/64 loss: 0.253754198551178
Batch 30/64 loss: 0.25317758321762085
Batch 31/64 loss: 0.2568359971046448
Batch 32/64 loss: 0.2681002616882324
Batch 33/64 loss: 0.2625517249107361
Batch 34/64 loss: 0.25981414318084717
Batch 35/64 loss: 0.2534325122833252
Batch 36/64 loss: 0.2559293508529663
Batch 37/64 loss: 0.2601207494735718
Batch 38/64 loss: 0.2527827024459839
Batch 39/64 loss: 0.25415992736816406
Batch 40/64 loss: 0.2559671401977539
Batch 41/64 loss: 0.2531599998474121
Batch 42/64 loss: 0.25837546586990356
Batch 43/64 loss: 0.2669970989227295
Batch 44/64 loss: 0.26002103090286255
Batch 45/64 loss: 0.2576172947883606
Batch 46/64 loss: 0.26075857877731323
Batch 47/64 loss: 0.26193010807037354
Batch 48/64 loss: 0.257019579410553
Batch 49/64 loss: 0.25239670276641846
Batch 50/64 loss: 0.25476109981536865
Batch 51/64 loss: 0.2537115216255188
Batch 52/64 loss: 0.2533297538757324
Batch 53/64 loss: 0.260211706161499
Batch 54/64 loss: 0.255592405796051
Batch 55/64 loss: 0.25696229934692383
Batch 56/64 loss: 0.2588934898376465
Batch 57/64 loss: 0.25166070461273193
Batch 58/64 loss: 0.2590130567550659
Batch 59/64 loss: 0.25941240787506104
Batch 60/64 loss: 0.2598797082901001
Batch 61/64 loss: 0.26474320888519287
Batch 62/64 loss: 0.2533212900161743
Batch 63/64 loss: 0.25227946043014526
Batch 64/64 loss: 0.2624031901359558
Epoch 267  Train loss: 0.2567825198173523  Val loss: 0.284668061331785
Saving best model, epoch: 267
Epoch 268
-------------------------------
Batch 1/64 loss: 0.2510634660720825
Batch 2/64 loss: 0.2489105463027954
Batch 3/64 loss: 0.2580134868621826
Batch 4/64 loss: 0.257668673992157
Batch 5/64 loss: 0.2610042095184326
Batch 6/64 loss: 0.25438356399536133
Batch 7/64 loss: 0.24746739864349365
Batch 8/64 loss: 0.2541388273239136
Batch 9/64 loss: 0.2596414089202881
Batch 10/64 loss: 0.24967330694198608
Batch 11/64 loss: 0.2520565390586853
Batch 12/64 loss: 0.25885897874832153
Batch 13/64 loss: 0.25360727310180664
Batch 14/64 loss: 0.2582809329032898
Batch 15/64 loss: 0.25450634956359863
Batch 16/64 loss: 0.2625751495361328
Batch 17/64 loss: 0.2505584955215454
Batch 18/64 loss: 0.25641894340515137
Batch 19/64 loss: 0.2539369463920593
Batch 20/64 loss: 0.25500965118408203
Batch 21/64 loss: 0.2507791519165039
Batch 22/64 loss: 0.25782346725463867
Batch 23/64 loss: 0.248948872089386
Batch 24/64 loss: 0.2479410171508789
Batch 25/64 loss: 0.2578577399253845
Batch 26/64 loss: 0.2620888948440552
Batch 27/64 loss: 0.2560141682624817
Batch 28/64 loss: 0.26479268074035645
Batch 29/64 loss: 0.26104462146759033
Batch 30/64 loss: 0.25974488258361816
Batch 31/64 loss: 0.25724583864212036
Batch 32/64 loss: 0.25637364387512207
Batch 33/64 loss: 0.24608957767486572
Batch 34/64 loss: 0.2512158155441284
Batch 35/64 loss: 0.2516287565231323
Batch 36/64 loss: 0.25333917140960693
Batch 37/64 loss: 0.2529817819595337
Batch 38/64 loss: 0.2528735399246216
Batch 39/64 loss: 0.25996506214141846
Batch 40/64 loss: 0.2564404010772705
Batch 41/64 loss: 0.25558435916900635
Batch 42/64 loss: 0.2563137412071228
Batch 43/64 loss: 0.25678497552871704
Batch 44/64 loss: 0.25823718309402466
Batch 45/64 loss: 0.25857245922088623
Batch 46/64 loss: 0.2669951915740967
Batch 47/64 loss: 0.2559572458267212
Batch 48/64 loss: 0.2606384754180908
Batch 49/64 loss: 0.2642925977706909
Batch 50/64 loss: 0.25571995973587036
Batch 51/64 loss: 0.25894469022750854
Batch 52/64 loss: 0.25146985054016113
Batch 53/64 loss: 0.26108360290527344
Batch 54/64 loss: 0.262142539024353
Batch 55/64 loss: 0.2552976608276367
Batch 56/64 loss: 0.2638767957687378
Batch 57/64 loss: 0.2532339096069336
Batch 58/64 loss: 0.2584341764450073
Batch 59/64 loss: 0.25615984201431274
Batch 60/64 loss: 0.2545492649078369
Batch 61/64 loss: 0.2514200806617737
Batch 62/64 loss: 0.2613387107849121
Batch 63/64 loss: 0.25354689359664917
Batch 64/64 loss: 0.26431238651275635
Epoch 268  Train loss: 0.2561849682938819  Val loss: 0.2841976272691156
Saving best model, epoch: 268
Epoch 269
-------------------------------
Batch 1/64 loss: 0.2429828643798828
Batch 2/64 loss: 0.2559051513671875
Batch 3/64 loss: 0.252422571182251
Batch 4/64 loss: 0.24244868755340576
Batch 5/64 loss: 0.25304341316223145
Batch 6/64 loss: 0.25430774688720703
Batch 7/64 loss: 0.2633953094482422
Batch 8/64 loss: 0.2511157989501953
Batch 9/64 loss: 0.24579691886901855
Batch 10/64 loss: 0.25206393003463745
Batch 11/64 loss: 0.2532995343208313
Batch 12/64 loss: 0.2537617087364197
Batch 13/64 loss: 0.2518653869628906
Batch 14/64 loss: 0.24814438819885254
Batch 15/64 loss: 0.26167500019073486
Batch 16/64 loss: 0.25934839248657227
Batch 17/64 loss: 0.25159454345703125
Batch 18/64 loss: 0.2573072910308838
Batch 19/64 loss: 0.25004470348358154
Batch 20/64 loss: 0.26084351539611816
Batch 21/64 loss: 0.25309324264526367
Batch 22/64 loss: 0.2558269500732422
Batch 23/64 loss: 0.2589154839515686
Batch 24/64 loss: 0.2588390111923218
Batch 25/64 loss: 0.24990218877792358
Batch 26/64 loss: 0.24741297960281372
Batch 27/64 loss: 0.25737643241882324
Batch 28/64 loss: 0.24725008010864258
Batch 29/64 loss: 0.2503929138183594
Batch 30/64 loss: 0.2526388168334961
Batch 31/64 loss: 0.2653844356536865
Batch 32/64 loss: 0.2660555839538574
Batch 33/64 loss: 0.2589993476867676
Batch 34/64 loss: 0.2565033435821533
Batch 35/64 loss: 0.2566659450531006
Batch 36/64 loss: 0.253786563873291
Batch 37/64 loss: 0.25486040115356445
Batch 38/64 loss: 0.2635308504104614
Batch 39/64 loss: 0.2584967613220215
Batch 40/64 loss: 0.25620192289352417
Batch 41/64 loss: 0.26863086223602295
Batch 42/64 loss: 0.25258755683898926
Batch 43/64 loss: 0.2645800709724426
Batch 44/64 loss: 0.2508710026741028
Batch 45/64 loss: 0.2581901550292969
Batch 46/64 loss: 0.2567440867424011
Batch 47/64 loss: 0.25211668014526367
Batch 48/64 loss: 0.25921952724456787
Batch 49/64 loss: 0.26456648111343384
Batch 50/64 loss: 0.2526618242263794
Batch 51/64 loss: 0.26303422451019287
Batch 52/64 loss: 0.25478172302246094
Batch 53/64 loss: 0.24694854021072388
Batch 54/64 loss: 0.25647103786468506
Batch 55/64 loss: 0.2553977966308594
Batch 56/64 loss: 0.25596296787261963
Batch 57/64 loss: 0.2540990114212036
Batch 58/64 loss: 0.2531331777572632
Batch 59/64 loss: 0.24611502885818481
Batch 60/64 loss: 0.2558428645133972
Batch 61/64 loss: 0.2541104555130005
Batch 62/64 loss: 0.2586660385131836
Batch 63/64 loss: 0.25235652923583984
Batch 64/64 loss: 0.26173853874206543
Epoch 269  Train loss: 0.2551669279734294  Val loss: 0.28673404455184937
Epoch 270
-------------------------------
Batch 1/64 loss: 0.24693918228149414
Batch 2/64 loss: 0.255295991897583
Batch 3/64 loss: 0.2507603168487549
Batch 4/64 loss: 0.2544536590576172
Batch 5/64 loss: 0.25794875621795654
Batch 6/64 loss: 0.25517845153808594
Batch 7/64 loss: 0.2530325651168823
Batch 8/64 loss: 0.2601144313812256
Batch 9/64 loss: 0.2585504651069641
Batch 10/64 loss: 0.2607906460762024
Batch 11/64 loss: 0.2538689970970154
Batch 12/64 loss: 0.25254565477371216
Batch 13/64 loss: 0.24959373474121094
Batch 14/64 loss: 0.26375794410705566
Batch 15/64 loss: 0.2533535361289978
Batch 16/64 loss: 0.26286816596984863
Batch 17/64 loss: 0.25336754322052
Batch 18/64 loss: 0.2559354305267334
Batch 19/64 loss: 0.2588531970977783
Batch 20/64 loss: 0.25287628173828125
Batch 21/64 loss: 0.25298500061035156
Batch 22/64 loss: 0.2546800971031189
Batch 23/64 loss: 0.24979442358016968
Batch 24/64 loss: 0.2522062063217163
Batch 25/64 loss: 0.26557743549346924
Batch 26/64 loss: 0.25794553756713867
Batch 27/64 loss: 0.2626999616622925
Batch 28/64 loss: 0.25434935092926025
Batch 29/64 loss: 0.2605627775192261
Batch 30/64 loss: 0.2548827528953552
Batch 31/64 loss: 0.26216042041778564
Batch 32/64 loss: 0.26043033599853516
Batch 33/64 loss: 0.25407469272613525
Batch 34/64 loss: 0.24829083681106567
Batch 35/64 loss: 0.2417830228805542
Batch 36/64 loss: 0.24413228034973145
Batch 37/64 loss: 0.25579380989074707
Batch 38/64 loss: 0.24989312887191772
Batch 39/64 loss: 0.25830286741256714
Batch 40/64 loss: 0.2555729150772095
Batch 41/64 loss: 0.2557748556137085
Batch 42/64 loss: 0.2553340196609497
Batch 43/64 loss: 0.24910640716552734
Batch 44/64 loss: 0.25971221923828125
Batch 45/64 loss: 0.2552913427352905
Batch 46/64 loss: 0.25377243757247925
Batch 47/64 loss: 0.2582933306694031
Batch 48/64 loss: 0.26032721996307373
Batch 49/64 loss: 0.25568830966949463
Batch 50/64 loss: 0.25365281105041504
Batch 51/64 loss: 0.26223939657211304
Batch 52/64 loss: 0.2611178159713745
Batch 53/64 loss: 0.265009343624115
Batch 54/64 loss: 0.2463822364807129
Batch 55/64 loss: 0.25346678495407104
Batch 56/64 loss: 0.2574712038040161
Batch 57/64 loss: 0.25403058528900146
Batch 58/64 loss: 0.2545672655105591
Batch 59/64 loss: 0.248282790184021
Batch 60/64 loss: 0.246992826461792
Batch 61/64 loss: 0.2700057625770569
Batch 62/64 loss: 0.2514013648033142
Batch 63/64 loss: 0.25990843772888184
Batch 64/64 loss: 0.2474384903907776
Epoch 270  Train loss: 0.25536643827662747  Val loss: 0.2847514881710826
Epoch 271
-------------------------------
Batch 1/64 loss: 0.2629886269569397
Batch 2/64 loss: 0.2546513080596924
Batch 3/64 loss: 0.24799638986587524
Batch 4/64 loss: 0.24999183416366577
Batch 5/64 loss: 0.2573353052139282
Batch 6/64 loss: 0.25436437129974365
Batch 7/64 loss: 0.2503199577331543
Batch 8/64 loss: 0.2665085196495056
Batch 9/64 loss: 0.24999940395355225
Batch 10/64 loss: 0.25946110486984253
Batch 11/64 loss: 0.2571432590484619
Batch 12/64 loss: 0.2528644800186157
Batch 13/64 loss: 0.2725817561149597
Batch 14/64 loss: 0.25186681747436523
Batch 15/64 loss: 0.24999821186065674
Batch 16/64 loss: 0.253445029258728
Batch 17/64 loss: 0.2556406259536743
Batch 18/64 loss: 0.25204408168792725
Batch 19/64 loss: 0.25294578075408936
Batch 20/64 loss: 0.25220727920532227
Batch 21/64 loss: 0.2543919086456299
Batch 22/64 loss: 0.2504976987838745
Batch 23/64 loss: 0.2504647970199585
Batch 24/64 loss: 0.24940961599349976
Batch 25/64 loss: 0.25797176361083984
Batch 26/64 loss: 0.2533853054046631
Batch 27/64 loss: 0.2532165050506592
Batch 28/64 loss: 0.2524983286857605
Batch 29/64 loss: 0.25290948152542114
Batch 30/64 loss: 0.24895650148391724
Batch 31/64 loss: 0.24268841743469238
Batch 32/64 loss: 0.25317996740341187
Batch 33/64 loss: 0.26687151193618774
Batch 34/64 loss: 0.2527236342430115
Batch 35/64 loss: 0.25719213485717773
Batch 36/64 loss: 0.2624273896217346
Batch 37/64 loss: 0.25328052043914795
Batch 38/64 loss: 0.2699012756347656
Batch 39/64 loss: 0.24684321880340576
Batch 40/64 loss: 0.25317227840423584
Batch 41/64 loss: 0.2534668445587158
Batch 42/64 loss: 0.25396740436553955
Batch 43/64 loss: 0.2547260522842407
Batch 44/64 loss: 0.26240289211273193
Batch 45/64 loss: 0.26902836561203003
Batch 46/64 loss: 0.2583550214767456
Batch 47/64 loss: 0.25685787200927734
Batch 48/64 loss: 0.24668943881988525
Batch 49/64 loss: 0.2613219618797302
Batch 50/64 loss: 0.25510239601135254
Batch 51/64 loss: 0.24968886375427246
Batch 52/64 loss: 0.2547823190689087
Batch 53/64 loss: 0.2553212642669678
Batch 54/64 loss: 0.2472083568572998
Batch 55/64 loss: 0.2608858346939087
Batch 56/64 loss: 0.2776849865913391
Batch 57/64 loss: 0.25168097019195557
Batch 58/64 loss: 0.2530719041824341
Batch 59/64 loss: 0.25646400451660156
Batch 60/64 loss: 0.2637138366699219
Batch 61/64 loss: 0.25112640857696533
Batch 62/64 loss: 0.25562798976898193
Batch 63/64 loss: 0.251995325088501
Batch 64/64 loss: 0.253928005695343
Epoch 271  Train loss: 0.25534043475693347  Val loss: 0.28501713316874816
Epoch 272
-------------------------------
Batch 1/64 loss: 0.25841861963272095
Batch 2/64 loss: 0.26147955656051636
Batch 3/64 loss: 0.24888694286346436
Batch 4/64 loss: 0.24637317657470703
Batch 5/64 loss: 0.25897955894470215
Batch 6/64 loss: 0.24879860877990723
Batch 7/64 loss: 0.2571941614151001
Batch 8/64 loss: 0.24839651584625244
Batch 9/64 loss: 0.26119768619537354
Batch 10/64 loss: 0.24578529596328735
Batch 11/64 loss: 0.2605045437812805
Batch 12/64 loss: 0.2500072717666626
Batch 13/64 loss: 0.25030773878097534
Batch 14/64 loss: 0.2558016777038574
Batch 15/64 loss: 0.26189935207366943
Batch 16/64 loss: 0.2522965669631958
Batch 17/64 loss: 0.2538185119628906
Batch 18/64 loss: 0.2569126486778259
Batch 19/64 loss: 0.2419375777244568
Batch 20/64 loss: 0.2483440637588501
Batch 21/64 loss: 0.26255834102630615
Batch 22/64 loss: 0.25892966985702515
Batch 23/64 loss: 0.2420213222503662
Batch 24/64 loss: 0.24555909633636475
Batch 25/64 loss: 0.26352381706237793
Batch 26/64 loss: 0.26564204692840576
Batch 27/64 loss: 0.2482393980026245
Batch 28/64 loss: 0.2591071128845215
Batch 29/64 loss: 0.25753700733184814
Batch 30/64 loss: 0.25876426696777344
Batch 31/64 loss: 0.25595778226852417
Batch 32/64 loss: 0.25547194480895996
Batch 33/64 loss: 0.2588777542114258
Batch 34/64 loss: 0.261696457862854
Batch 35/64 loss: 0.25576484203338623
Batch 36/64 loss: 0.25527095794677734
Batch 37/64 loss: 0.256384015083313
Batch 38/64 loss: 0.2501451373100281
Batch 39/64 loss: 0.24616843461990356
Batch 40/64 loss: 0.25251561403274536
Batch 41/64 loss: 0.25547611713409424
Batch 42/64 loss: 0.2554222345352173
Batch 43/64 loss: 0.2586261034011841
Batch 44/64 loss: 0.2616572976112366
Batch 45/64 loss: 0.26223593950271606
Batch 46/64 loss: 0.2605245113372803
Batch 47/64 loss: 0.259992778301239
Batch 48/64 loss: 0.25164932012557983
Batch 49/64 loss: 0.25807666778564453
Batch 50/64 loss: 0.25768065452575684
Batch 51/64 loss: 0.24470049142837524
Batch 52/64 loss: 0.25424301624298096
Batch 53/64 loss: 0.2555358409881592
Batch 54/64 loss: 0.25002968311309814
Batch 55/64 loss: 0.25349175930023193
Batch 56/64 loss: 0.25983816385269165
Batch 57/64 loss: 0.24688607454299927
Batch 58/64 loss: 0.2533838748931885
Batch 59/64 loss: 0.25189775228500366
Batch 60/64 loss: 0.2546565532684326
Batch 61/64 loss: 0.2611755132675171
Batch 62/64 loss: 0.258042573928833
Batch 63/64 loss: 0.25833553075790405
Batch 64/64 loss: 0.25922447443008423
Epoch 272  Train loss: 0.25498748082740635  Val loss: 0.28608128459183213
Epoch 273
-------------------------------
Batch 1/64 loss: 0.24851953983306885
Batch 2/64 loss: 0.24949312210083008
Batch 3/64 loss: 0.24828863143920898
Batch 4/64 loss: 0.25754034519195557
Batch 5/64 loss: 0.2583099603652954
Batch 6/64 loss: 0.2440711259841919
Batch 7/64 loss: 0.2488570213317871
Batch 8/64 loss: 0.2479778528213501
Batch 9/64 loss: 0.2518157362937927
Batch 10/64 loss: 0.2495456337928772
Batch 11/64 loss: 0.2612982988357544
Batch 12/64 loss: 0.2600531578063965
Batch 13/64 loss: 0.2542293071746826
Batch 14/64 loss: 0.25654375553131104
Batch 15/64 loss: 0.259366512298584
Batch 16/64 loss: 0.25024092197418213
Batch 17/64 loss: 0.26428377628326416
Batch 18/64 loss: 0.2568892240524292
Batch 19/64 loss: 0.2615177631378174
Batch 20/64 loss: 0.25249814987182617
Batch 21/64 loss: 0.25266408920288086
Batch 22/64 loss: 0.26070547103881836
Batch 23/64 loss: 0.2563748359680176
Batch 24/64 loss: 0.2471596598625183
Batch 25/64 loss: 0.26408469676971436
Batch 26/64 loss: 0.25134503841400146
Batch 27/64 loss: 0.24807286262512207
Batch 28/64 loss: 0.2566874027252197
Batch 29/64 loss: 0.26300692558288574
Batch 30/64 loss: 0.2529061436653137
Batch 31/64 loss: 0.24920392036437988
Batch 32/64 loss: 0.2570701837539673
Batch 33/64 loss: 0.2454150915145874
Batch 34/64 loss: 0.26425570249557495
Batch 35/64 loss: 0.26972436904907227
Batch 36/64 loss: 0.26563966274261475
Batch 37/64 loss: 0.2544219493865967
Batch 38/64 loss: 0.2594032287597656
Batch 39/64 loss: 0.26119881868362427
Batch 40/64 loss: 0.26266372203826904
Batch 41/64 loss: 0.2583802342414856
Batch 42/64 loss: 0.2517266273498535
Batch 43/64 loss: 0.2603888511657715
Batch 44/64 loss: 0.24612462520599365
Batch 45/64 loss: 0.2500978112220764
Batch 46/64 loss: 0.2541130781173706
Batch 47/64 loss: 0.2534075975418091
Batch 48/64 loss: 0.2421424388885498
Batch 49/64 loss: 0.2590135931968689
Batch 50/64 loss: 0.2520102262496948
Batch 51/64 loss: 0.25062477588653564
Batch 52/64 loss: 0.2572333812713623
Batch 53/64 loss: 0.2480618953704834
Batch 54/64 loss: 0.2591341733932495
Batch 55/64 loss: 0.24981236457824707
Batch 56/64 loss: 0.25620657205581665
Batch 57/64 loss: 0.2662489414215088
Batch 58/64 loss: 0.25330615043640137
Batch 59/64 loss: 0.24827975034713745
Batch 60/64 loss: 0.25342899560928345
Batch 61/64 loss: 0.2563825249671936
Batch 62/64 loss: 0.25072282552719116
Batch 63/64 loss: 0.2546501159667969
Batch 64/64 loss: 0.2566983103752136
Epoch 273  Train loss: 0.25486062578126495  Val loss: 0.2850793933950339
Epoch 274
-------------------------------
Batch 1/64 loss: 0.24701803922653198
Batch 2/64 loss: 0.26109278202056885
Batch 3/64 loss: 0.25511282682418823
Batch 4/64 loss: 0.25361311435699463
Batch 5/64 loss: 0.25277554988861084
Batch 6/64 loss: 0.24894964694976807
Batch 7/64 loss: 0.2631846070289612
Batch 8/64 loss: 0.2606658935546875
Batch 9/64 loss: 0.25280773639678955
Batch 10/64 loss: 0.2518550157546997
Batch 11/64 loss: 0.2551981210708618
Batch 12/64 loss: 0.24758976697921753
Batch 13/64 loss: 0.2553982138633728
Batch 14/64 loss: 0.25899451971054077
Batch 15/64 loss: 0.2608243227005005
Batch 16/64 loss: 0.24603378772735596
Batch 17/64 loss: 0.25305819511413574
Batch 18/64 loss: 0.25866371393203735
Batch 19/64 loss: 0.2524154782295227
Batch 20/64 loss: 0.2644681930541992
Batch 21/64 loss: 0.25864994525909424
Batch 22/64 loss: 0.2534196376800537
Batch 23/64 loss: 0.2542300224304199
Batch 24/64 loss: 0.255163311958313
Batch 25/64 loss: 0.25113821029663086
Batch 26/64 loss: 0.24920660257339478
Batch 27/64 loss: 0.2527840733528137
Batch 28/64 loss: 0.2540419101715088
Batch 29/64 loss: 0.25394415855407715
Batch 30/64 loss: 0.25224584341049194
Batch 31/64 loss: 0.24994397163391113
Batch 32/64 loss: 0.25314557552337646
Batch 33/64 loss: 0.2498731017112732
Batch 34/64 loss: 0.2587679624557495
Batch 35/64 loss: 0.2600148916244507
Batch 36/64 loss: 0.24725854396820068
Batch 37/64 loss: 0.25052517652511597
Batch 38/64 loss: 0.24782013893127441
Batch 39/64 loss: 0.24780648946762085
Batch 40/64 loss: 0.26695483922958374
Batch 41/64 loss: 0.25341928005218506
Batch 42/64 loss: 0.270877480506897
Batch 43/64 loss: 0.2516544461250305
Batch 44/64 loss: 0.2523462176322937
Batch 45/64 loss: 0.25398361682891846
Batch 46/64 loss: 0.25175946950912476
Batch 47/64 loss: 0.25232720375061035
Batch 48/64 loss: 0.2549194097518921
Batch 49/64 loss: 0.2514743208885193
Batch 50/64 loss: 0.2511560320854187
Batch 51/64 loss: 0.2619607448577881
Batch 52/64 loss: 0.25791382789611816
Batch 53/64 loss: 0.24456650018692017
Batch 54/64 loss: 0.2608226537704468
Batch 55/64 loss: 0.2540764808654785
Batch 56/64 loss: 0.25345075130462646
Batch 57/64 loss: 0.24625706672668457
Batch 58/64 loss: 0.25472646951675415
Batch 59/64 loss: 0.2545486092567444
Batch 60/64 loss: 0.2626138925552368
Batch 61/64 loss: 0.2571840286254883
Batch 62/64 loss: 0.2502073049545288
Batch 63/64 loss: 0.2602006793022156
Batch 64/64 loss: 0.2564144730567932
Epoch 274  Train loss: 0.2544535101628771  Val loss: 0.2846404316089407
Epoch 275
-------------------------------
Batch 1/64 loss: 0.25319600105285645
Batch 2/64 loss: 0.2731802463531494
Batch 3/64 loss: 0.25632423162460327
Batch 4/64 loss: 0.26270973682403564
Batch 5/64 loss: 0.2543102502822876
Batch 6/64 loss: 0.2550973892211914
Batch 7/64 loss: 0.24638843536376953
Batch 8/64 loss: 0.2626301646232605
Batch 9/64 loss: 0.25149500370025635
Batch 10/64 loss: 0.25582265853881836
Batch 11/64 loss: 0.254957914352417
Batch 12/64 loss: 0.25892460346221924
Batch 13/64 loss: 0.2650712728500366
Batch 14/64 loss: 0.25179386138916016
Batch 15/64 loss: 0.24986612796783447
Batch 16/64 loss: 0.2539921998977661
Batch 17/64 loss: 0.2524334192276001
Batch 18/64 loss: 0.25496530532836914
Batch 19/64 loss: 0.2520994544029236
Batch 20/64 loss: 0.24926424026489258
Batch 21/64 loss: 0.2637786269187927
Batch 22/64 loss: 0.2513836622238159
Batch 23/64 loss: 0.25525999069213867
Batch 24/64 loss: 0.25052201747894287
Batch 25/64 loss: 0.2610369920730591
Batch 26/64 loss: 0.2421736717224121
Batch 27/64 loss: 0.25273633003234863
Batch 28/64 loss: 0.24940210580825806
Batch 29/64 loss: 0.25053995847702026
Batch 30/64 loss: 0.2650104761123657
Batch 31/64 loss: 0.2462385892868042
Batch 32/64 loss: 0.25770771503448486
Batch 33/64 loss: 0.24422931671142578
Batch 34/64 loss: 0.2549511194229126
Batch 35/64 loss: 0.25248539447784424
Batch 36/64 loss: 0.25426095724105835
Batch 37/64 loss: 0.2556002736091614
Batch 38/64 loss: 0.24787569046020508
Batch 39/64 loss: 0.2609788775444031
Batch 40/64 loss: 0.2539691925048828
Batch 41/64 loss: 0.24853956699371338
Batch 42/64 loss: 0.25429606437683105
Batch 43/64 loss: 0.2614959478378296
Batch 44/64 loss: 0.2653225064277649
Batch 45/64 loss: 0.26845282316207886
Batch 46/64 loss: 0.24941933155059814
Batch 47/64 loss: 0.2563387155532837
Batch 48/64 loss: 0.25372159481048584
Batch 49/64 loss: 0.25752854347229004
Batch 50/64 loss: 0.25430572032928467
Batch 51/64 loss: 0.2523726224899292
Batch 52/64 loss: 0.2602328062057495
Batch 53/64 loss: 0.2505519390106201
Batch 54/64 loss: 0.2677760720252991
Batch 55/64 loss: 0.24574965238571167
Batch 56/64 loss: 0.2511886954307556
Batch 57/64 loss: 0.2613471746444702
Batch 58/64 loss: 0.25198328495025635
Batch 59/64 loss: 0.25267332792282104
Batch 60/64 loss: 0.25753068923950195
Batch 61/64 loss: 0.24685680866241455
Batch 62/64 loss: 0.24789214134216309
Batch 63/64 loss: 0.26042675971984863
Batch 64/64 loss: 0.25211358070373535
Epoch 275  Train loss: 0.2548980619393143  Val loss: 0.2849901533618416
Epoch 276
-------------------------------
Batch 1/64 loss: 0.26031821966171265
Batch 2/64 loss: 0.2532617449760437
Batch 3/64 loss: 0.2495477795600891
Batch 4/64 loss: 0.24592900276184082
Batch 5/64 loss: 0.25338804721832275
Batch 6/64 loss: 0.2577873468399048
Batch 7/64 loss: 0.2535983920097351
Batch 8/64 loss: 0.25168609619140625
Batch 9/64 loss: 0.2590404748916626
Batch 10/64 loss: 0.2506653070449829
Batch 11/64 loss: 0.25053858757019043
Batch 12/64 loss: 0.2527327537536621
Batch 13/64 loss: 0.2505769729614258
Batch 14/64 loss: 0.2564696669578552
Batch 15/64 loss: 0.2514064311981201
Batch 16/64 loss: 0.24802041053771973
Batch 17/64 loss: 0.2534383535385132
Batch 18/64 loss: 0.25627654790878296
Batch 19/64 loss: 0.25570595264434814
Batch 20/64 loss: 0.2573803663253784
Batch 21/64 loss: 0.24889367818832397
Batch 22/64 loss: 0.2437915802001953
Batch 23/64 loss: 0.26605820655822754
Batch 24/64 loss: 0.24963068962097168
Batch 25/64 loss: 0.2560436725616455
Batch 26/64 loss: 0.25200045108795166
Batch 27/64 loss: 0.2653317451477051
Batch 28/64 loss: 0.26243460178375244
Batch 29/64 loss: 0.24403446912765503
Batch 30/64 loss: 0.2564089894294739
Batch 31/64 loss: 0.2509082555770874
Batch 32/64 loss: 0.24330151081085205
Batch 33/64 loss: 0.25816673040390015
Batch 34/64 loss: 0.26215171813964844
Batch 35/64 loss: 0.2582993507385254
Batch 36/64 loss: 0.2603088617324829
Batch 37/64 loss: 0.2477046251296997
Batch 38/64 loss: 0.25454193353652954
Batch 39/64 loss: 0.25034666061401367
Batch 40/64 loss: 0.24637043476104736
Batch 41/64 loss: 0.26051533222198486
Batch 42/64 loss: 0.2486698031425476
Batch 43/64 loss: 0.25344139337539673
Batch 44/64 loss: 0.25000810623168945
Batch 45/64 loss: 0.24827677011489868
Batch 46/64 loss: 0.254319429397583
Batch 47/64 loss: 0.25827425718307495
Batch 48/64 loss: 0.25611841678619385
Batch 49/64 loss: 0.2516913414001465
Batch 50/64 loss: 0.24421477317810059
Batch 51/64 loss: 0.25816071033477783
Batch 52/64 loss: 0.25364089012145996
Batch 53/64 loss: 0.244728684425354
Batch 54/64 loss: 0.24968594312667847
Batch 55/64 loss: 0.2634294033050537
Batch 56/64 loss: 0.2536076307296753
Batch 57/64 loss: 0.25568175315856934
Batch 58/64 loss: 0.2538515329360962
Batch 59/64 loss: 0.24268925189971924
Batch 60/64 loss: 0.2685117721557617
Batch 61/64 loss: 0.24949920177459717
Batch 62/64 loss: 0.2735251188278198
Batch 63/64 loss: 0.2586686611175537
Batch 64/64 loss: 0.2557104825973511
Epoch 276  Train loss: 0.2539214064093197  Val loss: 0.2857477337224377
Epoch 277
-------------------------------
Batch 1/64 loss: 0.24959319829940796
Batch 2/64 loss: 0.2586180567741394
Batch 3/64 loss: 0.2517756223678589
Batch 4/64 loss: 0.2552792429924011
Batch 5/64 loss: 0.27350467443466187
Batch 6/64 loss: 0.2502226233482361
Batch 7/64 loss: 0.26615357398986816
Batch 8/64 loss: 0.25521254539489746
Batch 9/64 loss: 0.2497326135635376
Batch 10/64 loss: 0.27370351552963257
Batch 11/64 loss: 0.2788090705871582
Batch 12/64 loss: 0.259083092212677
Batch 13/64 loss: 0.25862932205200195
Batch 14/64 loss: 0.24500292539596558
Batch 15/64 loss: 0.24788224697113037
Batch 16/64 loss: 0.25839680433273315
Batch 17/64 loss: 0.2634843587875366
Batch 18/64 loss: 0.2525508999824524
Batch 19/64 loss: 0.2511695623397827
Batch 20/64 loss: 0.25355422496795654
Batch 21/64 loss: 0.2559783458709717
Batch 22/64 loss: 0.2582498788833618
Batch 23/64 loss: 0.2467924952507019
Batch 24/64 loss: 0.25789451599121094
Batch 25/64 loss: 0.24828815460205078
Batch 26/64 loss: 0.25347256660461426
Batch 27/64 loss: 0.2436600923538208
Batch 28/64 loss: 0.24441808462142944
Batch 29/64 loss: 0.25283169746398926
Batch 30/64 loss: 0.25905561447143555
Batch 31/64 loss: 0.25490206480026245
Batch 32/64 loss: 0.26715242862701416
Batch 33/64 loss: 0.24606668949127197
Batch 34/64 loss: 0.24411165714263916
Batch 35/64 loss: 0.24569040536880493
Batch 36/64 loss: 0.2482873797416687
Batch 37/64 loss: 0.24823510646820068
Batch 38/64 loss: 0.2536659240722656
Batch 39/64 loss: 0.24877816438674927
Batch 40/64 loss: 0.2561764717102051
Batch 41/64 loss: 0.25271034240722656
Batch 42/64 loss: 0.2503293752670288
Batch 43/64 loss: 0.2577945590019226
Batch 44/64 loss: 0.252175509929657
Batch 45/64 loss: 0.25892531871795654
Batch 46/64 loss: 0.2517784833908081
Batch 47/64 loss: 0.25522464513778687
Batch 48/64 loss: 0.25830984115600586
Batch 49/64 loss: 0.26200878620147705
Batch 50/64 loss: 0.2552800178527832
Batch 51/64 loss: 0.24808871746063232
Batch 52/64 loss: 0.2476961612701416
Batch 53/64 loss: 0.2586438059806824
Batch 54/64 loss: 0.2474750280380249
Batch 55/64 loss: 0.2696070671081543
Batch 56/64 loss: 0.2538391351699829
Batch 57/64 loss: 0.2683286666870117
Batch 58/64 loss: 0.2590627670288086
Batch 59/64 loss: 0.2559983730316162
Batch 60/64 loss: 0.2469298243522644
Batch 61/64 loss: 0.25834012031555176
Batch 62/64 loss: 0.24674421548843384
Batch 63/64 loss: 0.24792790412902832
Batch 64/64 loss: 0.25783276557922363
Epoch 277  Train loss: 0.25478681022045657  Val loss: 0.28530682075474273
Epoch 278
-------------------------------
Batch 1/64 loss: 0.2572649121284485
Batch 2/64 loss: 0.2515653371810913
Batch 3/64 loss: 0.2512422800064087
Batch 4/64 loss: 0.2543776035308838
Batch 5/64 loss: 0.2744603157043457
Batch 6/64 loss: 0.24940097332000732
Batch 7/64 loss: 0.2541924715042114
Batch 8/64 loss: 0.25308918952941895
Batch 9/64 loss: 0.24823272228240967
Batch 10/64 loss: 0.2481822371482849
Batch 11/64 loss: 0.251491904258728
Batch 12/64 loss: 0.2493918538093567
Batch 13/64 loss: 0.25766944885253906
Batch 14/64 loss: 0.25321924686431885
Batch 15/64 loss: 0.2550259828567505
Batch 16/64 loss: 0.2549949884414673
Batch 17/64 loss: 0.24990308284759521
Batch 18/64 loss: 0.25660836696624756
Batch 19/64 loss: 0.2571549415588379
Batch 20/64 loss: 0.2606920003890991
Batch 21/64 loss: 0.25110381841659546
Batch 22/64 loss: 0.2529970407485962
Batch 23/64 loss: 0.24927014112472534
Batch 24/64 loss: 0.26265692710876465
Batch 25/64 loss: 0.25124478340148926
Batch 26/64 loss: 0.23945248126983643
Batch 27/64 loss: 0.2525540590286255
Batch 28/64 loss: 0.2575685977935791
Batch 29/64 loss: 0.24880707263946533
Batch 30/64 loss: 0.2519872188568115
Batch 31/64 loss: 0.2653295397758484
Batch 32/64 loss: 0.2628663182258606
Batch 33/64 loss: 0.25912928581237793
Batch 34/64 loss: 0.25093305110931396
Batch 35/64 loss: 0.2515881061553955
Batch 36/64 loss: 0.25788116455078125
Batch 37/64 loss: 0.2532576322555542
Batch 38/64 loss: 0.2570626139640808
Batch 39/64 loss: 0.24981439113616943
Batch 40/64 loss: 0.2511744499206543
Batch 41/64 loss: 0.2535436153411865
Batch 42/64 loss: 0.24373972415924072
Batch 43/64 loss: 0.2619680166244507
Batch 44/64 loss: 0.2499569058418274
Batch 45/64 loss: 0.2550942301750183
Batch 46/64 loss: 0.25386250019073486
Batch 47/64 loss: 0.2551649808883667
Batch 48/64 loss: 0.2652265429496765
Batch 49/64 loss: 0.2563982605934143
Batch 50/64 loss: 0.2501586675643921
Batch 51/64 loss: 0.25380563735961914
Batch 52/64 loss: 0.25051939487457275
Batch 53/64 loss: 0.24930274486541748
Batch 54/64 loss: 0.25073039531707764
Batch 55/64 loss: 0.267291784286499
Batch 56/64 loss: 0.26035112142562866
Batch 57/64 loss: 0.2554687261581421
Batch 58/64 loss: 0.26140904426574707
Batch 59/64 loss: 0.25035911798477173
Batch 60/64 loss: 0.24984890222549438
Batch 61/64 loss: 0.2544374465942383
Batch 62/64 loss: 0.24900901317596436
Batch 63/64 loss: 0.24215233325958252
Batch 64/64 loss: 0.25326746702194214
Epoch 278  Train loss: 0.25403275700176464  Val loss: 0.2845796629325631
Epoch 279
-------------------------------
Batch 1/64 loss: 0.2552311420440674
Batch 2/64 loss: 0.24476373195648193
Batch 3/64 loss: 0.25982892513275146
Batch 4/64 loss: 0.24762964248657227
Batch 5/64 loss: 0.2750716209411621
Batch 6/64 loss: 0.25572019815444946
Batch 7/64 loss: 0.2529211640357971
Batch 8/64 loss: 0.2493463158607483
Batch 9/64 loss: 0.2509315013885498
Batch 10/64 loss: 0.2561519145965576
Batch 11/64 loss: 0.2542731761932373
Batch 12/64 loss: 0.2541612386703491
Batch 13/64 loss: 0.25517839193344116
Batch 14/64 loss: 0.24620413780212402
Batch 15/64 loss: 0.24670708179473877
Batch 16/64 loss: 0.2577831745147705
Batch 17/64 loss: 0.2530706524848938
Batch 18/64 loss: 0.2555809020996094
Batch 19/64 loss: 0.2516094446182251
Batch 20/64 loss: 0.2564026117324829
Batch 21/64 loss: 0.262786328792572
Batch 22/64 loss: 0.2593064308166504
Batch 23/64 loss: 0.2532837390899658
Batch 24/64 loss: 0.2510331869125366
Batch 25/64 loss: 0.2482503056526184
Batch 26/64 loss: 0.24781060218811035
Batch 27/64 loss: 0.2540854215621948
Batch 28/64 loss: 0.24663126468658447
Batch 29/64 loss: 0.25762516260147095
Batch 30/64 loss: 0.26033252477645874
Batch 31/64 loss: 0.2564176917076111
Batch 32/64 loss: 0.2529184818267822
Batch 33/64 loss: 0.25529956817626953
Batch 34/64 loss: 0.24711287021636963
Batch 35/64 loss: 0.24843740463256836
Batch 36/64 loss: 0.2557615041732788
Batch 37/64 loss: 0.2506188154220581
Batch 38/64 loss: 0.2572339177131653
Batch 39/64 loss: 0.24260938167572021
Batch 40/64 loss: 0.25292736291885376
Batch 41/64 loss: 0.24950015544891357
Batch 42/64 loss: 0.2504462003707886
Batch 43/64 loss: 0.25498658418655396
Batch 44/64 loss: 0.25959861278533936
Batch 45/64 loss: 0.2591257095336914
Batch 46/64 loss: 0.2591754198074341
Batch 47/64 loss: 0.25335758924484253
Batch 48/64 loss: 0.2544163465499878
Batch 49/64 loss: 0.2525262236595154
Batch 50/64 loss: 0.2493411898612976
Batch 51/64 loss: 0.25269484519958496
Batch 52/64 loss: 0.26153504848480225
Batch 53/64 loss: 0.2524009943008423
Batch 54/64 loss: 0.2415635585784912
Batch 55/64 loss: 0.25007104873657227
Batch 56/64 loss: 0.25010740756988525
Batch 57/64 loss: 0.2439855933189392
Batch 58/64 loss: 0.24964040517807007
Batch 59/64 loss: 0.25747621059417725
Batch 60/64 loss: 0.2456679344177246
Batch 61/64 loss: 0.2559760808944702
Batch 62/64 loss: 0.2693846821784973
Batch 63/64 loss: 0.2541522979736328
Batch 64/64 loss: 0.2577517628669739
Epoch 279  Train loss: 0.25348224149030796  Val loss: 0.2853717668769286
Epoch 280
-------------------------------
Batch 1/64 loss: 0.2591354250907898
Batch 2/64 loss: 0.2541840076446533
Batch 3/64 loss: 0.2451791763305664
Batch 4/64 loss: 0.24779462814331055
Batch 5/64 loss: 0.2499719262123108
Batch 6/64 loss: 0.25679725408554077
Batch 7/64 loss: 0.2519413232803345
Batch 8/64 loss: 0.2466902732849121
Batch 9/64 loss: 0.26083308458328247
Batch 10/64 loss: 0.25316137075424194
Batch 11/64 loss: 0.24992185831069946
Batch 12/64 loss: 0.2468874454498291
Batch 13/64 loss: 0.257526159286499
Batch 14/64 loss: 0.2530421018600464
Batch 15/64 loss: 0.2568190097808838
Batch 16/64 loss: 0.25217556953430176
Batch 17/64 loss: 0.24739181995391846
Batch 18/64 loss: 0.2544841766357422
Batch 19/64 loss: 0.24829953908920288
Batch 20/64 loss: 0.2509979009628296
Batch 21/64 loss: 0.24655115604400635
Batch 22/64 loss: 0.2533271312713623
Batch 23/64 loss: 0.2537948489189148
Batch 24/64 loss: 0.25365376472473145
Batch 25/64 loss: 0.24769455194473267
Batch 26/64 loss: 0.2655552625656128
Batch 27/64 loss: 0.2567281126976013
Batch 28/64 loss: 0.26180946826934814
Batch 29/64 loss: 0.25382786989212036
Batch 30/64 loss: 0.251853883266449
Batch 31/64 loss: 0.257191002368927
Batch 32/64 loss: 0.26139116287231445
Batch 33/64 loss: 0.2560286521911621
Batch 34/64 loss: 0.24833303689956665
Batch 35/64 loss: 0.25989049673080444
Batch 36/64 loss: 0.2526901364326477
Batch 37/64 loss: 0.2452825903892517
Batch 38/64 loss: 0.25810420513153076
Batch 39/64 loss: 0.2588275671005249
Batch 40/64 loss: 0.26283150911331177
Batch 41/64 loss: 0.2548544406890869
Batch 42/64 loss: 0.26377201080322266
Batch 43/64 loss: 0.2513096332550049
Batch 44/64 loss: 0.2611043453216553
Batch 45/64 loss: 0.2591053247451782
Batch 46/64 loss: 0.25338053703308105
Batch 47/64 loss: 0.24634623527526855
Batch 48/64 loss: 0.2607725262641907
Batch 49/64 loss: 0.2559846043586731
Batch 50/64 loss: 0.25537848472595215
Batch 51/64 loss: 0.2506147027015686
Batch 52/64 loss: 0.2506062388420105
Batch 53/64 loss: 0.25828564167022705
Batch 54/64 loss: 0.25963473320007324
Batch 55/64 loss: 0.2578237056732178
Batch 56/64 loss: 0.24156808853149414
Batch 57/64 loss: 0.24755018949508667
Batch 58/64 loss: 0.25435686111450195
Batch 59/64 loss: 0.25964218378067017
Batch 60/64 loss: 0.257581889629364
Batch 61/64 loss: 0.25544995069503784
Batch 62/64 loss: 0.24686455726623535
Batch 63/64 loss: 0.25092828273773193
Batch 64/64 loss: 0.23532569408416748
Epoch 280  Train loss: 0.25377270427404663  Val loss: 0.2842408318290186
Epoch 281
-------------------------------
Batch 1/64 loss: 0.2509502172470093
Batch 2/64 loss: 0.25494498014450073
Batch 3/64 loss: 0.25128018856048584
Batch 4/64 loss: 0.254868745803833
Batch 5/64 loss: 0.2458956241607666
Batch 6/64 loss: 0.25430887937545776
Batch 7/64 loss: 0.2534923553466797
Batch 8/64 loss: 0.2623647451400757
Batch 9/64 loss: 0.24676060676574707
Batch 10/64 loss: 0.240317702293396
Batch 11/64 loss: 0.25051963329315186
Batch 12/64 loss: 0.2548011541366577
Batch 13/64 loss: 0.24734997749328613
Batch 14/64 loss: 0.2466767430305481
Batch 15/64 loss: 0.2517094016075134
Batch 16/64 loss: 0.2518656253814697
Batch 17/64 loss: 0.25475358963012695
Batch 18/64 loss: 0.25219082832336426
Batch 19/64 loss: 0.24569284915924072
Batch 20/64 loss: 0.2554662227630615
Batch 21/64 loss: 0.255220890045166
Batch 22/64 loss: 0.24801594018936157
Batch 23/64 loss: 0.26996803283691406
Batch 24/64 loss: 0.25026094913482666
Batch 25/64 loss: 0.2529011368751526
Batch 26/64 loss: 0.25449836254119873
Batch 27/64 loss: 0.25794869661331177
Batch 28/64 loss: 0.25298619270324707
Batch 29/64 loss: 0.25050055980682373
Batch 30/64 loss: 0.24358463287353516
Batch 31/64 loss: 0.24313431978225708
Batch 32/64 loss: 0.26136255264282227
Batch 33/64 loss: 0.25380223989486694
Batch 34/64 loss: 0.2630084753036499
Batch 35/64 loss: 0.2621690034866333
Batch 36/64 loss: 0.24637174606323242
Batch 37/64 loss: 0.25369852781295776
Batch 38/64 loss: 0.25272178649902344
Batch 39/64 loss: 0.2422637939453125
Batch 40/64 loss: 0.25309401750564575
Batch 41/64 loss: 0.2562832236289978
Batch 42/64 loss: 0.24524164199829102
Batch 43/64 loss: 0.24770784378051758
Batch 44/64 loss: 0.25367486476898193
Batch 45/64 loss: 0.25148606300354004
Batch 46/64 loss: 0.2623569965362549
Batch 47/64 loss: 0.24871617555618286
Batch 48/64 loss: 0.25164276361465454
Batch 49/64 loss: 0.2670789957046509
Batch 50/64 loss: 0.254338800907135
Batch 51/64 loss: 0.26115602254867554
Batch 52/64 loss: 0.2539446949958801
Batch 53/64 loss: 0.25212645530700684
Batch 54/64 loss: 0.26646310091018677
Batch 55/64 loss: 0.2512233257293701
Batch 56/64 loss: 0.2585355043411255
Batch 57/64 loss: 0.2542116045951843
Batch 58/64 loss: 0.25500595569610596
Batch 59/64 loss: 0.2588188052177429
Batch 60/64 loss: 0.24956530332565308
Batch 61/64 loss: 0.263452410697937
Batch 62/64 loss: 0.24593347311019897
Batch 63/64 loss: 0.2509421110153198
Batch 64/64 loss: 0.2542535066604614
Epoch 281  Train loss: 0.25324420695211375  Val loss: 0.28584218004724826
Epoch 282
-------------------------------
Batch 1/64 loss: 0.2549198269844055
Batch 2/64 loss: 0.2450600266456604
Batch 3/64 loss: 0.2605357766151428
Batch 4/64 loss: 0.2518199682235718
Batch 5/64 loss: 0.24487251043319702
Batch 6/64 loss: 0.2572956085205078
Batch 7/64 loss: 0.24773681163787842
Batch 8/64 loss: 0.24842041730880737
Batch 9/64 loss: 0.25423741340637207
Batch 10/64 loss: 0.2562198042869568
Batch 11/64 loss: 0.2494504451751709
Batch 12/64 loss: 0.24465882778167725
Batch 13/64 loss: 0.25020110607147217
Batch 14/64 loss: 0.25015532970428467
Batch 15/64 loss: 0.2466924786567688
Batch 16/64 loss: 0.25512832403182983
Batch 17/64 loss: 0.2509004473686218
Batch 18/64 loss: 0.2543603181838989
Batch 19/64 loss: 0.25890904664993286
Batch 20/64 loss: 0.24842894077301025
Batch 21/64 loss: 0.2541780471801758
Batch 22/64 loss: 0.24574804306030273
Batch 23/64 loss: 0.2519221305847168
Batch 24/64 loss: 0.2452765703201294
Batch 25/64 loss: 0.24835431575775146
Batch 26/64 loss: 0.25539451837539673
Batch 27/64 loss: 0.2502393126487732
Batch 28/64 loss: 0.2529847025871277
Batch 29/64 loss: 0.2567065954208374
Batch 30/64 loss: 0.24958014488220215
Batch 31/64 loss: 0.25694841146469116
Batch 32/64 loss: 0.26200437545776367
Batch 33/64 loss: 0.253426194190979
Batch 34/64 loss: 0.25113433599472046
Batch 35/64 loss: 0.24934256076812744
Batch 36/64 loss: 0.2608070373535156
Batch 37/64 loss: 0.2519437074661255
Batch 38/64 loss: 0.2472440004348755
Batch 39/64 loss: 0.2571507692337036
Batch 40/64 loss: 0.25854891538619995
Batch 41/64 loss: 0.25082772970199585
Batch 42/64 loss: 0.25581109523773193
Batch 43/64 loss: 0.2529076337814331
Batch 44/64 loss: 0.2682269811630249
Batch 45/64 loss: 0.24822497367858887
Batch 46/64 loss: 0.25286197662353516
Batch 47/64 loss: 0.2547447085380554
Batch 48/64 loss: 0.26103949546813965
Batch 49/64 loss: 0.2456735372543335
Batch 50/64 loss: 0.26113438606262207
Batch 51/64 loss: 0.2555692195892334
Batch 52/64 loss: 0.25897878408432007
Batch 53/64 loss: 0.2552204132080078
Batch 54/64 loss: 0.25609254837036133
Batch 55/64 loss: 0.25304317474365234
Batch 56/64 loss: 0.2553292512893677
Batch 57/64 loss: 0.25660425424575806
Batch 58/64 loss: 0.25741440057754517
Batch 59/64 loss: 0.24992036819458008
Batch 60/64 loss: 0.2572137713432312
Batch 61/64 loss: 0.25426769256591797
Batch 62/64 loss: 0.2598787546157837
Batch 63/64 loss: 0.2566021680831909
Batch 64/64 loss: 0.24885326623916626
Epoch 282  Train loss: 0.25338298643336576  Val loss: 0.28556950518355745
Epoch 283
-------------------------------
Batch 1/64 loss: 0.2569236755371094
Batch 2/64 loss: 0.252422571182251
Batch 3/64 loss: 0.246293306350708
Batch 4/64 loss: 0.2484602928161621
Batch 5/64 loss: 0.2551519274711609
Batch 6/64 loss: 0.2537428140640259
Batch 7/64 loss: 0.24202394485473633
Batch 8/64 loss: 0.27033108472824097
Batch 9/64 loss: 0.25990867614746094
Batch 10/64 loss: 0.24853074550628662
Batch 11/64 loss: 0.25276464223861694
Batch 12/64 loss: 0.26680266857147217
Batch 13/64 loss: 0.24517977237701416
Batch 14/64 loss: 0.2488328218460083
Batch 15/64 loss: 0.24868899583816528
Batch 16/64 loss: 0.259183406829834
Batch 17/64 loss: 0.2552129030227661
Batch 18/64 loss: 0.2556517720222473
Batch 19/64 loss: 0.25019896030426025
Batch 20/64 loss: 0.25045937299728394
Batch 21/64 loss: 0.2532517910003662
Batch 22/64 loss: 0.2515171766281128
Batch 23/64 loss: 0.25743579864501953
Batch 24/64 loss: 0.2527860999107361
Batch 25/64 loss: 0.24994713068008423
Batch 26/64 loss: 0.2638469934463501
Batch 27/64 loss: 0.2510778307914734
Batch 28/64 loss: 0.26175904273986816
Batch 29/64 loss: 0.2435004711151123
Batch 30/64 loss: 0.24810326099395752
Batch 31/64 loss: 0.254061222076416
Batch 32/64 loss: 0.25478219985961914
Batch 33/64 loss: 0.25783759355545044
Batch 34/64 loss: 0.26079094409942627
Batch 35/64 loss: 0.254722535610199
Batch 36/64 loss: 0.25018709897994995
Batch 37/64 loss: 0.25343865156173706
Batch 38/64 loss: 0.2493809461593628
Batch 39/64 loss: 0.25656670331954956
Batch 40/64 loss: 0.2572925090789795
Batch 41/64 loss: 0.26423192024230957
Batch 42/64 loss: 0.2481139898300171
Batch 43/64 loss: 0.24588632583618164
Batch 44/64 loss: 0.2550102472305298
Batch 45/64 loss: 0.24955952167510986
Batch 46/64 loss: 0.26000678539276123
Batch 47/64 loss: 0.24837887287139893
Batch 48/64 loss: 0.2553752660751343
Batch 49/64 loss: 0.2520335912704468
Batch 50/64 loss: 0.25131678581237793
Batch 51/64 loss: 0.25386375188827515
Batch 52/64 loss: 0.26059049367904663
Batch 53/64 loss: 0.25088709592819214
Batch 54/64 loss: 0.2506871223449707
Batch 55/64 loss: 0.25601720809936523
Batch 56/64 loss: 0.25040775537490845
Batch 57/64 loss: 0.2563481330871582
Batch 58/64 loss: 0.24737119674682617
Batch 59/64 loss: 0.2654353380203247
Batch 60/64 loss: 0.2607268691062927
Batch 61/64 loss: 0.2559085488319397
Batch 62/64 loss: 0.2530801296234131
Batch 63/64 loss: 0.2546182870864868
Batch 64/64 loss: 0.24133121967315674
Epoch 283  Train loss: 0.25373967067868103  Val loss: 0.28363073220367696
Saving best model, epoch: 283
Epoch 284
-------------------------------
Batch 1/64 loss: 0.25045865774154663
Batch 2/64 loss: 0.24439918994903564
Batch 3/64 loss: 0.24841630458831787
Batch 4/64 loss: 0.24897605180740356
Batch 5/64 loss: 0.26044487953186035
Batch 6/64 loss: 0.25280165672302246
Batch 7/64 loss: 0.2589288353919983
Batch 8/64 loss: 0.2436915636062622
Batch 9/64 loss: 0.25145530700683594
Batch 10/64 loss: 0.25321269035339355
Batch 11/64 loss: 0.2575817108154297
Batch 12/64 loss: 0.25232696533203125
Batch 13/64 loss: 0.2542268633842468
Batch 14/64 loss: 0.2531239986419678
Batch 15/64 loss: 0.237545907497406
Batch 16/64 loss: 0.24874842166900635
Batch 17/64 loss: 0.2429591417312622
Batch 18/64 loss: 0.25629568099975586
Batch 19/64 loss: 0.2613667845726013
Batch 20/64 loss: 0.25949883460998535
Batch 21/64 loss: 0.2458268404006958
Batch 22/64 loss: 0.24634671211242676
Batch 23/64 loss: 0.24571162462234497
Batch 24/64 loss: 0.24963057041168213
Batch 25/64 loss: 0.24770379066467285
Batch 26/64 loss: 0.23899614810943604
Batch 27/64 loss: 0.24820631742477417
Batch 28/64 loss: 0.25045251846313477
Batch 29/64 loss: 0.2493959665298462
Batch 30/64 loss: 0.2487412691116333
Batch 31/64 loss: 0.24899327754974365
Batch 32/64 loss: 0.2569584846496582
Batch 33/64 loss: 0.2599477171897888
Batch 34/64 loss: 0.2558729648590088
Batch 35/64 loss: 0.2507895231246948
Batch 36/64 loss: 0.24987709522247314
Batch 37/64 loss: 0.25097548961639404
Batch 38/64 loss: 0.25474148988723755
Batch 39/64 loss: 0.2565591335296631
Batch 40/64 loss: 0.2522314786911011
Batch 41/64 loss: 0.25984543561935425
Batch 42/64 loss: 0.2606959342956543
Batch 43/64 loss: 0.24187076091766357
Batch 44/64 loss: 0.25105392932891846
Batch 45/64 loss: 0.2518594264984131
Batch 46/64 loss: 0.24979209899902344
Batch 47/64 loss: 0.2518043518066406
Batch 48/64 loss: 0.25419944524765015
Batch 49/64 loss: 0.253564715385437
Batch 50/64 loss: 0.2561461329460144
Batch 51/64 loss: 0.25613415241241455
Batch 52/64 loss: 0.2499956488609314
Batch 53/64 loss: 0.24583524465560913
Batch 54/64 loss: 0.2577161192893982
Batch 55/64 loss: 0.2537437677383423
Batch 56/64 loss: 0.25444459915161133
Batch 57/64 loss: 0.2709171175956726
Batch 58/64 loss: 0.27435463666915894
Batch 59/64 loss: 0.26057112216949463
Batch 60/64 loss: 0.25731390714645386
Batch 61/64 loss: 0.25390690565109253
Batch 62/64 loss: 0.2668416500091553
Batch 63/64 loss: 0.26518702507019043
Batch 64/64 loss: 0.2469601035118103
Epoch 284  Train loss: 0.2529793264819126  Val loss: 0.2841761511625703
Epoch 285
-------------------------------
Batch 1/64 loss: 0.2431809902191162
Batch 2/64 loss: 0.25804269313812256
Batch 3/64 loss: 0.26823365688323975
Batch 4/64 loss: 0.24938082695007324
Batch 5/64 loss: 0.2570648193359375
Batch 6/64 loss: 0.2514309883117676
Batch 7/64 loss: 0.2561039924621582
Batch 8/64 loss: 0.2510952353477478
Batch 9/64 loss: 0.24847888946533203
Batch 10/64 loss: 0.26201415061950684
Batch 11/64 loss: 0.2532040476799011
Batch 12/64 loss: 0.24621635675430298
Batch 13/64 loss: 0.24954986572265625
Batch 14/64 loss: 0.2561933398246765
Batch 15/64 loss: 0.24420005083084106
Batch 16/64 loss: 0.24893534183502197
Batch 17/64 loss: 0.2554194927215576
Batch 18/64 loss: 0.24808335304260254
Batch 19/64 loss: 0.246893048286438
Batch 20/64 loss: 0.24510979652404785
Batch 21/64 loss: 0.2597305178642273
Batch 22/64 loss: 0.25663912296295166
Batch 23/64 loss: 0.25267136096954346
Batch 24/64 loss: 0.24648511409759521
Batch 25/64 loss: 0.2528327703475952
Batch 26/64 loss: 0.2549542188644409
Batch 27/64 loss: 0.26453065872192383
Batch 28/64 loss: 0.24719756841659546
Batch 29/64 loss: 0.24430423974990845
Batch 30/64 loss: 0.24678707122802734
Batch 31/64 loss: 0.24613112211227417
Batch 32/64 loss: 0.25432610511779785
Batch 33/64 loss: 0.25282716751098633
Batch 34/64 loss: 0.2526988983154297
Batch 35/64 loss: 0.26496195793151855
Batch 36/64 loss: 0.2575644850730896
Batch 37/64 loss: 0.2525287866592407
Batch 38/64 loss: 0.2598276138305664
Batch 39/64 loss: 0.26236045360565186
Batch 40/64 loss: 0.2611377239227295
Batch 41/64 loss: 0.24816346168518066
Batch 42/64 loss: 0.25894439220428467
Batch 43/64 loss: 0.24337565898895264
Batch 44/64 loss: 0.24852526187896729
Batch 45/64 loss: 0.26798826456069946
Batch 46/64 loss: 0.2523770332336426
Batch 47/64 loss: 0.257516086101532
Batch 48/64 loss: 0.25784653425216675
Batch 49/64 loss: 0.25573253631591797
Batch 50/64 loss: 0.2591879963874817
Batch 51/64 loss: 0.24069708585739136
Batch 52/64 loss: 0.26021039485931396
Batch 53/64 loss: 0.252862811088562
Batch 54/64 loss: 0.25140416622161865
Batch 55/64 loss: 0.25368547439575195
Batch 56/64 loss: 0.250363290309906
Batch 57/64 loss: 0.24121510982513428
Batch 58/64 loss: 0.24851346015930176
Batch 59/64 loss: 0.25399577617645264
Batch 60/64 loss: 0.25133776664733887
Batch 61/64 loss: 0.25796085596084595
Batch 62/64 loss: 0.2512681484222412
Batch 63/64 loss: 0.2583353519439697
Batch 64/64 loss: 0.2430782914161682
Epoch 285  Train loss: 0.2530689181066027  Val loss: 0.28574357532553657
Epoch 286
-------------------------------
Batch 1/64 loss: 0.2582472562789917
Batch 2/64 loss: 0.24429017305374146
Batch 3/64 loss: 0.24399995803833008
Batch 4/64 loss: 0.24186307191848755
Batch 5/64 loss: 0.24956047534942627
Batch 6/64 loss: 0.24497056007385254
Batch 7/64 loss: 0.2635572552680969
Batch 8/64 loss: 0.25224852561950684
Batch 9/64 loss: 0.251420795917511
Batch 10/64 loss: 0.24331390857696533
Batch 11/64 loss: 0.24720680713653564
Batch 12/64 loss: 0.2499333620071411
Batch 13/64 loss: 0.2516007423400879
Batch 14/64 loss: 0.25147688388824463
Batch 15/64 loss: 0.2512736916542053
Batch 16/64 loss: 0.25505757331848145
Batch 17/64 loss: 0.25415313243865967
Batch 18/64 loss: 0.2542717456817627
Batch 19/64 loss: 0.24881720542907715
Batch 20/64 loss: 0.25618577003479004
Batch 21/64 loss: 0.2691592574119568
Batch 22/64 loss: 0.25087374448776245
Batch 23/64 loss: 0.2578316926956177
Batch 24/64 loss: 0.2528468370437622
Batch 25/64 loss: 0.24418771266937256
Batch 26/64 loss: 0.24739229679107666
Batch 27/64 loss: 0.2450028657913208
Batch 28/64 loss: 0.25333452224731445
Batch 29/64 loss: 0.25453972816467285
Batch 30/64 loss: 0.25462961196899414
Batch 31/64 loss: 0.26410651206970215
Batch 32/64 loss: 0.2417842149734497
Batch 33/64 loss: 0.24451887607574463
Batch 34/64 loss: 0.253808856010437
Batch 35/64 loss: 0.2545417547225952
Batch 36/64 loss: 0.24789386987686157
Batch 37/64 loss: 0.25822770595550537
Batch 38/64 loss: 0.2600337266921997
Batch 39/64 loss: 0.2627406120300293
Batch 40/64 loss: 0.2478630542755127
Batch 41/64 loss: 0.2680003046989441
Batch 42/64 loss: 0.24661779403686523
Batch 43/64 loss: 0.25337857007980347
Batch 44/64 loss: 0.2554575204849243
Batch 45/64 loss: 0.24916326999664307
Batch 46/64 loss: 0.24610519409179688
Batch 47/64 loss: 0.2651069164276123
Batch 48/64 loss: 0.2500211000442505
Batch 49/64 loss: 0.24750113487243652
Batch 50/64 loss: 0.25025665760040283
Batch 51/64 loss: 0.24261069297790527
Batch 52/64 loss: 0.25965070724487305
Batch 53/64 loss: 0.2592475414276123
Batch 54/64 loss: 0.2560058832168579
Batch 55/64 loss: 0.25544995069503784
Batch 56/64 loss: 0.2602170705795288
Batch 57/64 loss: 0.26094961166381836
Batch 58/64 loss: 0.2515592575073242
Batch 59/64 loss: 0.24546611309051514
Batch 60/64 loss: 0.2535219192504883
Batch 61/64 loss: 0.25654757022857666
Batch 62/64 loss: 0.25365257263183594
Batch 63/64 loss: 0.24917447566986084
Batch 64/64 loss: 0.2479308843612671
Epoch 286  Train loss: 0.2525549229453592  Val loss: 0.2843674322993485
Epoch 287
-------------------------------
Batch 1/64 loss: 0.24390649795532227
Batch 2/64 loss: 0.25324422121047974
Batch 3/64 loss: 0.24779295921325684
Batch 4/64 loss: 0.243158221244812
Batch 5/64 loss: 0.25367987155914307
Batch 6/64 loss: 0.25488096475601196
Batch 7/64 loss: 0.2606699466705322
Batch 8/64 loss: 0.25176990032196045
Batch 9/64 loss: 0.24699729681015015
Batch 10/64 loss: 0.253892719745636
Batch 11/64 loss: 0.2505863904953003
Batch 12/64 loss: 0.25500231981277466
Batch 13/64 loss: 0.2548847198486328
Batch 14/64 loss: 0.24830591678619385
Batch 15/64 loss: 0.24693453311920166
Batch 16/64 loss: 0.24194884300231934
Batch 17/64 loss: 0.2522873878479004
Batch 18/64 loss: 0.26297253370285034
Batch 19/64 loss: 0.25580358505249023
Batch 20/64 loss: 0.2473229169845581
Batch 21/64 loss: 0.24920856952667236
Batch 22/64 loss: 0.25064516067504883
Batch 23/64 loss: 0.25177884101867676
Batch 24/64 loss: 0.2492579221725464
Batch 25/64 loss: 0.24513977766036987
Batch 26/64 loss: 0.25358152389526367
Batch 27/64 loss: 0.25718265771865845
Batch 28/64 loss: 0.24622106552124023
Batch 29/64 loss: 0.2613464593887329
Batch 30/64 loss: 0.25169670581817627
Batch 31/64 loss: 0.25482046604156494
Batch 32/64 loss: 0.25696802139282227
Batch 33/64 loss: 0.2528945207595825
Batch 34/64 loss: 0.25888288021087646
Batch 35/64 loss: 0.25692427158355713
Batch 36/64 loss: 0.2527925968170166
Batch 37/64 loss: 0.2553647756576538
Batch 38/64 loss: 0.258602499961853
Batch 39/64 loss: 0.2645583152770996
Batch 40/64 loss: 0.24381959438323975
Batch 41/64 loss: 0.2540677785873413
Batch 42/64 loss: 0.24344408512115479
Batch 43/64 loss: 0.24184966087341309
Batch 44/64 loss: 0.26241815090179443
Batch 45/64 loss: 0.24594366550445557
Batch 46/64 loss: 0.2524247169494629
Batch 47/64 loss: 0.24407589435577393
Batch 48/64 loss: 0.2593510150909424
Batch 49/64 loss: 0.2484055757522583
Batch 50/64 loss: 0.25109922885894775
Batch 51/64 loss: 0.25662243366241455
Batch 52/64 loss: 0.25825977325439453
Batch 53/64 loss: 0.2520436644554138
Batch 54/64 loss: 0.26141321659088135
Batch 55/64 loss: 0.24874860048294067
Batch 56/64 loss: 0.2537146806716919
Batch 57/64 loss: 0.2504621744155884
Batch 58/64 loss: 0.2555149793624878
Batch 59/64 loss: 0.25510841608047485
Batch 60/64 loss: 0.24971354007720947
Batch 61/64 loss: 0.24000650644302368
Batch 62/64 loss: 0.2572537660598755
Batch 63/64 loss: 0.2533925771713257
Batch 64/64 loss: 0.25391560792922974
Epoch 287  Train loss: 0.2522901831888685  Val loss: 0.2847934785167786
Epoch 288
-------------------------------
Batch 1/64 loss: 0.25931835174560547
Batch 2/64 loss: 0.2557711601257324
Batch 3/64 loss: 0.2443034052848816
Batch 4/64 loss: 0.26006996631622314
Batch 5/64 loss: 0.24128401279449463
Batch 6/64 loss: 0.24901896715164185
Batch 7/64 loss: 0.26063311100006104
Batch 8/64 loss: 0.24913954734802246
Batch 9/64 loss: 0.2495419979095459
Batch 10/64 loss: 0.25007951259613037
Batch 11/64 loss: 0.2580219507217407
Batch 12/64 loss: 0.25415724515914917
Batch 13/64 loss: 0.25299644470214844
Batch 14/64 loss: 0.24985045194625854
Batch 15/64 loss: 0.24644005298614502
Batch 16/64 loss: 0.24939781427383423
Batch 17/64 loss: 0.2579535245895386
Batch 18/64 loss: 0.25051140785217285
Batch 19/64 loss: 0.2508530616760254
Batch 20/64 loss: 0.2524455785751343
Batch 21/64 loss: 0.252066969871521
Batch 22/64 loss: 0.2583639621734619
Batch 23/64 loss: 0.2499523162841797
Batch 24/64 loss: 0.23573529720306396
Batch 25/64 loss: 0.24290680885314941
Batch 26/64 loss: 0.2518930435180664
Batch 27/64 loss: 0.2627497911453247
Batch 28/64 loss: 0.24848324060440063
Batch 29/64 loss: 0.2576488256454468
Batch 30/64 loss: 0.25319623947143555
Batch 31/64 loss: 0.25973379611968994
Batch 32/64 loss: 0.25082921981811523
Batch 33/64 loss: 0.2493891716003418
Batch 34/64 loss: 0.24368298053741455
Batch 35/64 loss: 0.2628664970397949
Batch 36/64 loss: 0.25796884298324585
Batch 37/64 loss: 0.2509883642196655
Batch 38/64 loss: 0.24807322025299072
Batch 39/64 loss: 0.24084985256195068
Batch 40/64 loss: 0.26041513681411743
Batch 41/64 loss: 0.2506219148635864
Batch 42/64 loss: 0.254863977432251
Batch 43/64 loss: 0.2573602795600891
Batch 44/64 loss: 0.2548064589500427
Batch 45/64 loss: 0.2537853717803955
Batch 46/64 loss: 0.24595022201538086
Batch 47/64 loss: 0.2564818263053894
Batch 48/64 loss: 0.2478022575378418
Batch 49/64 loss: 0.2457590103149414
Batch 50/64 loss: 0.24743187427520752
Batch 51/64 loss: 0.254547119140625
Batch 52/64 loss: 0.2479642629623413
Batch 53/64 loss: 0.2574443817138672
Batch 54/64 loss: 0.2541011571884155
Batch 55/64 loss: 0.2544100880622864
Batch 56/64 loss: 0.2566051483154297
Batch 57/64 loss: 0.2566572427749634
Batch 58/64 loss: 0.2550792694091797
Batch 59/64 loss: 0.2614567279815674
Batch 60/64 loss: 0.24802857637405396
Batch 61/64 loss: 0.25057268142700195
Batch 62/64 loss: 0.25985586643218994
Batch 63/64 loss: 0.24596846103668213
Batch 64/64 loss: 0.23809128999710083
Epoch 288  Train loss: 0.252167902507034  Val loss: 0.28332822326942
Saving best model, epoch: 288
Epoch 289
-------------------------------
Batch 1/64 loss: 0.24931609630584717
Batch 2/64 loss: 0.24852609634399414
Batch 3/64 loss: 0.24842369556427002
Batch 4/64 loss: 0.26139211654663086
Batch 5/64 loss: 0.25316447019577026
Batch 6/64 loss: 0.2578524351119995
Batch 7/64 loss: 0.2678333520889282
Batch 8/64 loss: 0.2492358684539795
Batch 9/64 loss: 0.26348572969436646
Batch 10/64 loss: 0.25506681203842163
Batch 11/64 loss: 0.2563801407814026
Batch 12/64 loss: 0.2503358721733093
Batch 13/64 loss: 0.24311769008636475
Batch 14/64 loss: 0.2517298460006714
Batch 15/64 loss: 0.2468147873878479
Batch 16/64 loss: 0.25255125761032104
Batch 17/64 loss: 0.256855309009552
Batch 18/64 loss: 0.2583498954772949
Batch 19/64 loss: 0.2533413767814636
Batch 20/64 loss: 0.26006317138671875
Batch 21/64 loss: 0.2429133653640747
Batch 22/64 loss: 0.24983620643615723
Batch 23/64 loss: 0.25181102752685547
Batch 24/64 loss: 0.24871128797531128
Batch 25/64 loss: 0.25751030445098877
Batch 26/64 loss: 0.25429534912109375
Batch 27/64 loss: 0.2592982053756714
Batch 28/64 loss: 0.2584400773048401
Batch 29/64 loss: 0.2557714581489563
Batch 30/64 loss: 0.2607494592666626
Batch 31/64 loss: 0.255399227142334
Batch 32/64 loss: 0.25815069675445557
Batch 33/64 loss: 0.2534092664718628
Batch 34/64 loss: 0.24871575832366943
Batch 35/64 loss: 0.25557923316955566
Batch 36/64 loss: 0.2522081136703491
Batch 37/64 loss: 0.258317232131958
Batch 38/64 loss: 0.24777239561080933
Batch 39/64 loss: 0.24890804290771484
Batch 40/64 loss: 0.24789053201675415
Batch 41/64 loss: 0.24842894077301025
Batch 42/64 loss: 0.24863815307617188
Batch 43/64 loss: 0.26074397563934326
Batch 44/64 loss: 0.246079683303833
Batch 45/64 loss: 0.2521357536315918
Batch 46/64 loss: 0.25573956966400146
Batch 47/64 loss: 0.25088226795196533
Batch 48/64 loss: 0.24230527877807617
Batch 49/64 loss: 0.24646872282028198
Batch 50/64 loss: 0.24603891372680664
Batch 51/64 loss: 0.24393755197525024
Batch 52/64 loss: 0.24372893571853638
Batch 53/64 loss: 0.2413727045059204
Batch 54/64 loss: 0.25132644176483154
Batch 55/64 loss: 0.24789071083068848
Batch 56/64 loss: 0.25835907459259033
Batch 57/64 loss: 0.24524211883544922
Batch 58/64 loss: 0.24975013732910156
Batch 59/64 loss: 0.24783283472061157
Batch 60/64 loss: 0.26114845275878906
Batch 61/64 loss: 0.2556875944137573
Batch 62/64 loss: 0.250657320022583
Batch 63/64 loss: 0.264773964881897
Batch 64/64 loss: 0.24748671054840088
Epoch 289  Train loss: 0.25245972380918613  Val loss: 0.2841871251764986
Epoch 290
-------------------------------
Batch 1/64 loss: 0.24775391817092896
Batch 2/64 loss: 0.24723458290100098
Batch 3/64 loss: 0.25266551971435547
Batch 4/64 loss: 0.2521204352378845
Batch 5/64 loss: 0.2525186538696289
Batch 6/64 loss: 0.25463569164276123
Batch 7/64 loss: 0.24604541063308716
Batch 8/64 loss: 0.2506953477859497
Batch 9/64 loss: 0.2517569065093994
Batch 10/64 loss: 0.24448716640472412
Batch 11/64 loss: 0.24271464347839355
Batch 12/64 loss: 0.2534215450286865
Batch 13/64 loss: 0.24692535400390625
Batch 14/64 loss: 0.2613532543182373
Batch 15/64 loss: 0.2539181709289551
Batch 16/64 loss: 0.2532144784927368
Batch 17/64 loss: 0.25743532180786133
Batch 18/64 loss: 0.26179420948028564
Batch 19/64 loss: 0.25132185220718384
Batch 20/64 loss: 0.25244200229644775
Batch 21/64 loss: 0.2468363642692566
Batch 22/64 loss: 0.2507660388946533
Batch 23/64 loss: 0.2471643090248108
Batch 24/64 loss: 0.2534470558166504
Batch 25/64 loss: 0.25264227390289307
Batch 26/64 loss: 0.24370849132537842
Batch 27/64 loss: 0.24898594617843628
Batch 28/64 loss: 0.24858546257019043
Batch 29/64 loss: 0.2520950436592102
Batch 30/64 loss: 0.2525547742843628
Batch 31/64 loss: 0.26134753227233887
Batch 32/64 loss: 0.25590407848358154
Batch 33/64 loss: 0.24751222133636475
Batch 34/64 loss: 0.24989104270935059
Batch 35/64 loss: 0.24829983711242676
Batch 36/64 loss: 0.24830245971679688
Batch 37/64 loss: 0.2550215721130371
Batch 38/64 loss: 0.25861114263534546
Batch 39/64 loss: 0.24210774898529053
Batch 40/64 loss: 0.24786198139190674
Batch 41/64 loss: 0.23908531665802002
Batch 42/64 loss: 0.2476292848587036
Batch 43/64 loss: 0.25849318504333496
Batch 44/64 loss: 0.24263513088226318
Batch 45/64 loss: 0.26231634616851807
Batch 46/64 loss: 0.25983965396881104
Batch 47/64 loss: 0.25233495235443115
Batch 48/64 loss: 0.2508660554885864
Batch 49/64 loss: 0.25282740592956543
Batch 50/64 loss: 0.2545478343963623
Batch 51/64 loss: 0.25300782918930054
Batch 52/64 loss: 0.2505512237548828
Batch 53/64 loss: 0.2552875876426697
Batch 54/64 loss: 0.25081872940063477
Batch 55/64 loss: 0.25822019577026367
Batch 56/64 loss: 0.2572972774505615
Batch 57/64 loss: 0.2510209083557129
Batch 58/64 loss: 0.2530776262283325
Batch 59/64 loss: 0.24989068508148193
Batch 60/64 loss: 0.2526562213897705
Batch 61/64 loss: 0.25200003385543823
Batch 62/64 loss: 0.24857985973358154
Batch 63/64 loss: 0.2474353313446045
Batch 64/64 loss: 0.2501755356788635
Epoch 290  Train loss: 0.25151608107136747  Val loss: 0.28325816876290183
Saving best model, epoch: 290
Epoch 291
-------------------------------
Batch 1/64 loss: 0.2437748908996582
Batch 2/64 loss: 0.2444974184036255
Batch 3/64 loss: 0.25512397289276123
Batch 4/64 loss: 0.25598812103271484
Batch 5/64 loss: 0.2529942989349365
Batch 6/64 loss: 0.24398303031921387
Batch 7/64 loss: 0.24741214513778687
Batch 8/64 loss: 0.2451627254486084
Batch 9/64 loss: 0.25505274534225464
Batch 10/64 loss: 0.25119030475616455
Batch 11/64 loss: 0.2445542812347412
Batch 12/64 loss: 0.25982725620269775
Batch 13/64 loss: 0.24367201328277588
Batch 14/64 loss: 0.25313907861709595
Batch 15/64 loss: 0.2526879906654358
Batch 16/64 loss: 0.2524264454841614
Batch 17/64 loss: 0.24292445182800293
Batch 18/64 loss: 0.2539142370223999
Batch 19/64 loss: 0.2506343126296997
Batch 20/64 loss: 0.2533232569694519
Batch 21/64 loss: 0.2447887659072876
Batch 22/64 loss: 0.25301170349121094
Batch 23/64 loss: 0.2503630518913269
Batch 24/64 loss: 0.251556396484375
Batch 25/64 loss: 0.2485133409500122
Batch 26/64 loss: 0.24851417541503906
Batch 27/64 loss: 0.2555924654006958
Batch 28/64 loss: 0.25247514247894287
Batch 29/64 loss: 0.2529960870742798
Batch 30/64 loss: 0.2536731958389282
Batch 31/64 loss: 0.26023781299591064
Batch 32/64 loss: 0.25759029388427734
Batch 33/64 loss: 0.26205217838287354
Batch 34/64 loss: 0.24186748266220093
Batch 35/64 loss: 0.24598652124404907
Batch 36/64 loss: 0.24811267852783203
Batch 37/64 loss: 0.24547135829925537
Batch 38/64 loss: 0.2522175908088684
Batch 39/64 loss: 0.24387812614440918
Batch 40/64 loss: 0.2614286541938782
Batch 41/64 loss: 0.2562122344970703
Batch 42/64 loss: 0.2589450478553772
Batch 43/64 loss: 0.25114762783050537
Batch 44/64 loss: 0.2520287036895752
Batch 45/64 loss: 0.2439386248588562
Batch 46/64 loss: 0.24844110012054443
Batch 47/64 loss: 0.2477477788925171
Batch 48/64 loss: 0.25988149642944336
Batch 49/64 loss: 0.2518341541290283
Batch 50/64 loss: 0.24551331996917725
Batch 51/64 loss: 0.2580111026763916
Batch 52/64 loss: 0.2562500238418579
Batch 53/64 loss: 0.24597477912902832
Batch 54/64 loss: 0.25554370880126953
Batch 55/64 loss: 0.25440049171447754
Batch 56/64 loss: 0.2579953670501709
Batch 57/64 loss: 0.2564448118209839
Batch 58/64 loss: 0.2489945888519287
Batch 59/64 loss: 0.2487030029296875
Batch 60/64 loss: 0.25348830223083496
Batch 61/64 loss: 0.2530302405357361
Batch 62/64 loss: 0.25726819038391113
Batch 63/64 loss: 0.24408555030822754
Batch 64/64 loss: 0.25142937898635864
Epoch 291  Train loss: 0.2514048985406464  Val loss: 0.28353112301056327
Epoch 292
-------------------------------
Batch 1/64 loss: 0.2458968162536621
Batch 2/64 loss: 0.25242459774017334
Batch 3/64 loss: 0.26278603076934814
Batch 4/64 loss: 0.25048828125
Batch 5/64 loss: 0.24686670303344727
Batch 6/64 loss: 0.2397112250328064
Batch 7/64 loss: 0.2533048391342163
Batch 8/64 loss: 0.2550818920135498
Batch 9/64 loss: 0.2455195188522339
Batch 10/64 loss: 0.2515109181404114
Batch 11/64 loss: 0.2512993812561035
Batch 12/64 loss: 0.24472421407699585
Batch 13/64 loss: 0.2409820556640625
Batch 14/64 loss: 0.2515939474105835
Batch 15/64 loss: 0.2573246955871582
Batch 16/64 loss: 0.24985694885253906
Batch 17/64 loss: 0.24669647216796875
Batch 18/64 loss: 0.2473962903022766
Batch 19/64 loss: 0.2465071678161621
Batch 20/64 loss: 0.2532930374145508
Batch 21/64 loss: 0.25585663318634033
Batch 22/64 loss: 0.25785815715789795
Batch 23/64 loss: 0.2438645362854004
Batch 24/64 loss: 0.2408236861228943
Batch 25/64 loss: 0.24254578351974487
Batch 26/64 loss: 0.2590157985687256
Batch 27/64 loss: 0.25792884826660156
Batch 28/64 loss: 0.25267183780670166
Batch 29/64 loss: 0.2446041703224182
Batch 30/64 loss: 0.24988675117492676
Batch 31/64 loss: 0.27202898263931274
Batch 32/64 loss: 0.24617141485214233
Batch 33/64 loss: 0.24920958280563354
Batch 34/64 loss: 0.24803286790847778
Batch 35/64 loss: 0.24619174003601074
Batch 36/64 loss: 0.26030433177948
Batch 37/64 loss: 0.2583235502243042
Batch 38/64 loss: 0.2615523934364319
Batch 39/64 loss: 0.24921345710754395
Batch 40/64 loss: 0.24635714292526245
Batch 41/64 loss: 0.24899685382843018
Batch 42/64 loss: 0.2506002187728882
Batch 43/64 loss: 0.2475278377532959
Batch 44/64 loss: 0.2444944977760315
Batch 45/64 loss: 0.2584083080291748
Batch 46/64 loss: 0.24607253074645996
Batch 47/64 loss: 0.2528270483016968
Batch 48/64 loss: 0.24964523315429688
Batch 49/64 loss: 0.2521711587905884
Batch 50/64 loss: 0.2550511360168457
Batch 51/64 loss: 0.25710761547088623
Batch 52/64 loss: 0.2566148042678833
Batch 53/64 loss: 0.2551460266113281
Batch 54/64 loss: 0.24727225303649902
Batch 55/64 loss: 0.2582210302352905
Batch 56/64 loss: 0.25781118869781494
Batch 57/64 loss: 0.24967002868652344
Batch 58/64 loss: 0.25527334213256836
Batch 59/64 loss: 0.24858033657073975
Batch 60/64 loss: 0.2483152151107788
Batch 61/64 loss: 0.24560189247131348
Batch 62/64 loss: 0.2447195053100586
Batch 63/64 loss: 0.25170600414276123
Batch 64/64 loss: 0.25452589988708496
Epoch 292  Train loss: 0.2511127088584152  Val loss: 0.2833300341445556
Epoch 293
-------------------------------
Batch 1/64 loss: 0.23958104848861694
Batch 2/64 loss: 0.25335967540740967
Batch 3/64 loss: 0.26228904724121094
Batch 4/64 loss: 0.2559835910797119
Batch 5/64 loss: 0.24900877475738525
Batch 6/64 loss: 0.257074773311615
Batch 7/64 loss: 0.2582826614379883
Batch 8/64 loss: 0.25286614894866943
Batch 9/64 loss: 0.2482980489730835
Batch 10/64 loss: 0.24596673250198364
Batch 11/64 loss: 0.2526460886001587
Batch 12/64 loss: 0.2526744604110718
Batch 13/64 loss: 0.2546870708465576
Batch 14/64 loss: 0.24964416027069092
Batch 15/64 loss: 0.2535976767539978
Batch 16/64 loss: 0.243380606174469
Batch 17/64 loss: 0.2496415376663208
Batch 18/64 loss: 0.2592315673828125
Batch 19/64 loss: 0.24962258338928223
Batch 20/64 loss: 0.25533533096313477
Batch 21/64 loss: 0.2586625814437866
Batch 22/64 loss: 0.24435389041900635
Batch 23/64 loss: 0.2573896646499634
Batch 24/64 loss: 0.2494041919708252
Batch 25/64 loss: 0.2665256857872009
Batch 26/64 loss: 0.24227547645568848
Batch 27/64 loss: 0.2450464963912964
Batch 28/64 loss: 0.25215673446655273
Batch 29/64 loss: 0.24596858024597168
Batch 30/64 loss: 0.25043928623199463
Batch 31/64 loss: 0.24229776859283447
Batch 32/64 loss: 0.25222110748291016
Batch 33/64 loss: 0.25576865673065186
Batch 34/64 loss: 0.25661277770996094
Batch 35/64 loss: 0.26467347145080566
Batch 36/64 loss: 0.25625425577163696
Batch 37/64 loss: 0.26402080059051514
Batch 38/64 loss: 0.23899132013320923
Batch 39/64 loss: 0.2520841360092163
Batch 40/64 loss: 0.2520042657852173
Batch 41/64 loss: 0.24530667066574097
Batch 42/64 loss: 0.25186872482299805
Batch 43/64 loss: 0.25250446796417236
Batch 44/64 loss: 0.24116647243499756
Batch 45/64 loss: 0.24756669998168945
Batch 46/64 loss: 0.25134849548339844
Batch 47/64 loss: 0.24158704280853271
Batch 48/64 loss: 0.24906373023986816
Batch 49/64 loss: 0.24593257904052734
Batch 50/64 loss: 0.2569495439529419
Batch 51/64 loss: 0.2662017345428467
Batch 52/64 loss: 0.25580424070358276
Batch 53/64 loss: 0.26452261209487915
Batch 54/64 loss: 0.2519456148147583
Batch 55/64 loss: 0.2512853145599365
Batch 56/64 loss: 0.25462567806243896
Batch 57/64 loss: 0.24996280670166016
Batch 58/64 loss: 0.2593998908996582
Batch 59/64 loss: 0.25112640857696533
Batch 60/64 loss: 0.2565370202064514
Batch 61/64 loss: 0.24792003631591797
Batch 62/64 loss: 0.2508779764175415
Batch 63/64 loss: 0.24976927042007446
Batch 64/64 loss: 0.2455776333808899
Epoch 293  Train loss: 0.25204359199486526  Val loss: 0.28453547028741477
Epoch 294
-------------------------------
Batch 1/64 loss: 0.237990140914917
Batch 2/64 loss: 0.25809502601623535
Batch 3/64 loss: 0.25302016735076904
Batch 4/64 loss: 0.24786490201950073
Batch 5/64 loss: 0.24923861026763916
Batch 6/64 loss: 0.24797159433364868
Batch 7/64 loss: 0.24294543266296387
Batch 8/64 loss: 0.24475789070129395
Batch 9/64 loss: 0.24321508407592773
Batch 10/64 loss: 0.25217533111572266
Batch 11/64 loss: 0.2453901767730713
Batch 12/64 loss: 0.25589340925216675
Batch 13/64 loss: 0.26540660858154297
Batch 14/64 loss: 0.2542762756347656
Batch 15/64 loss: 0.25141847133636475
Batch 16/64 loss: 0.24374830722808838
Batch 17/64 loss: 0.23981887102127075
Batch 18/64 loss: 0.2519940733909607
Batch 19/64 loss: 0.24779832363128662
Batch 20/64 loss: 0.24362099170684814
Batch 21/64 loss: 0.24803614616394043
Batch 22/64 loss: 0.254888653755188
Batch 23/64 loss: 0.24605894088745117
Batch 24/64 loss: 0.24616503715515137
Batch 25/64 loss: 0.2431093454360962
Batch 26/64 loss: 0.24523985385894775
Batch 27/64 loss: 0.24645406007766724
Batch 28/64 loss: 0.25047969818115234
Batch 29/64 loss: 0.2439042329788208
Batch 30/64 loss: 0.24921244382858276
Batch 31/64 loss: 0.25940096378326416
Batch 32/64 loss: 0.2477511167526245
Batch 33/64 loss: 0.24636662006378174
Batch 34/64 loss: 0.2555689215660095
Batch 35/64 loss: 0.25230854749679565
Batch 36/64 loss: 0.27306532859802246
Batch 37/64 loss: 0.25801384449005127
Batch 38/64 loss: 0.24599051475524902
Batch 39/64 loss: 0.2512979507446289
Batch 40/64 loss: 0.2568745017051697
Batch 41/64 loss: 0.25214362144470215
Batch 42/64 loss: 0.2502385377883911
Batch 43/64 loss: 0.25670182704925537
Batch 44/64 loss: 0.2630816698074341
Batch 45/64 loss: 0.24690604209899902
Batch 46/64 loss: 0.24623048305511475
Batch 47/64 loss: 0.2520354986190796
Batch 48/64 loss: 0.25251901149749756
Batch 49/64 loss: 0.2598823308944702
Batch 50/64 loss: 0.25031864643096924
Batch 51/64 loss: 0.25410032272338867
Batch 52/64 loss: 0.26771581172943115
Batch 53/64 loss: 0.2452961802482605
Batch 54/64 loss: 0.2539329528808594
Batch 55/64 loss: 0.2440909743309021
Batch 56/64 loss: 0.26430392265319824
Batch 57/64 loss: 0.2610103487968445
Batch 58/64 loss: 0.2501002550125122
Batch 59/64 loss: 0.24598336219787598
Batch 60/64 loss: 0.25022733211517334
Batch 61/64 loss: 0.23907935619354248
Batch 62/64 loss: 0.24917060136795044
Batch 63/64 loss: 0.2473917007446289
Batch 64/64 loss: 0.2676364779472351
Epoch 294  Train loss: 0.2509806205244625  Val loss: 0.28487959207128416
Epoch 295
-------------------------------
Batch 1/64 loss: 0.24684399366378784
Batch 2/64 loss: 0.23988580703735352
Batch 3/64 loss: 0.24126994609832764
Batch 4/64 loss: 0.2556583881378174
Batch 5/64 loss: 0.2412947416305542
Batch 6/64 loss: 0.2442118525505066
Batch 7/64 loss: 0.2444019317626953
Batch 8/64 loss: 0.25209271907806396
Batch 9/64 loss: 0.24298691749572754
Batch 10/64 loss: 0.26622241735458374
Batch 11/64 loss: 0.2557384967803955
Batch 12/64 loss: 0.2516116499900818
Batch 13/64 loss: 0.25388067960739136
Batch 14/64 loss: 0.2474602460861206
Batch 15/64 loss: 0.2549617290496826
Batch 16/64 loss: 0.24894213676452637
Batch 17/64 loss: 0.25925636291503906
Batch 18/64 loss: 0.25777608156204224
Batch 19/64 loss: 0.25287091732025146
Batch 20/64 loss: 0.24532723426818848
Batch 21/64 loss: 0.25358664989471436
Batch 22/64 loss: 0.24415266513824463
Batch 23/64 loss: 0.2482803463935852
Batch 24/64 loss: 0.25056034326553345
Batch 25/64 loss: 0.24145185947418213
Batch 26/64 loss: 0.2502717971801758
Batch 27/64 loss: 0.25011777877807617
Batch 28/64 loss: 0.24653053283691406
Batch 29/64 loss: 0.24673336744308472
Batch 30/64 loss: 0.25167274475097656
Batch 31/64 loss: 0.2572459578514099
Batch 32/64 loss: 0.2654836177825928
Batch 33/64 loss: 0.2555541396141052
Batch 34/64 loss: 0.2435460090637207
Batch 35/64 loss: 0.25783073902130127
Batch 36/64 loss: 0.2546323537826538
Batch 37/64 loss: 0.2515418529510498
Batch 38/64 loss: 0.24963438510894775
Batch 39/64 loss: 0.24406278133392334
Batch 40/64 loss: 0.2632824182510376
Batch 41/64 loss: 0.26224374771118164
Batch 42/64 loss: 0.24952322244644165
Batch 43/64 loss: 0.24885541200637817
Batch 44/64 loss: 0.2466728687286377
Batch 45/64 loss: 0.2529144287109375
Batch 46/64 loss: 0.24913179874420166
Batch 47/64 loss: 0.2445395588874817
Batch 48/64 loss: 0.25368034839630127
Batch 49/64 loss: 0.24471676349639893
Batch 50/64 loss: 0.25765764713287354
Batch 51/64 loss: 0.25810718536376953
Batch 52/64 loss: 0.2443808913230896
Batch 53/64 loss: 0.254550576210022
Batch 54/64 loss: 0.25794053077697754
Batch 55/64 loss: 0.25613152980804443
Batch 56/64 loss: 0.25589990615844727
Batch 57/64 loss: 0.24437546730041504
Batch 58/64 loss: 0.24425899982452393
Batch 59/64 loss: 0.24747347831726074
Batch 60/64 loss: 0.2594801187515259
Batch 61/64 loss: 0.2538938522338867
Batch 62/64 loss: 0.2507110834121704
Batch 63/64 loss: 0.24880540370941162
Batch 64/64 loss: 0.24099361896514893
Epoch 295  Train loss: 0.2509106921214683  Val loss: 0.2839190284001459
Epoch 296
-------------------------------
Batch 1/64 loss: 0.2530710697174072
Batch 2/64 loss: 0.24993443489074707
Batch 3/64 loss: 0.2507098913192749
Batch 4/64 loss: 0.24812465906143188
Batch 5/64 loss: 0.24031317234039307
Batch 6/64 loss: 0.24830543994903564
Batch 7/64 loss: 0.25175440311431885
Batch 8/64 loss: 0.2518461346626282
Batch 9/64 loss: 0.25129640102386475
Batch 10/64 loss: 0.2503080368041992
Batch 11/64 loss: 0.25529515743255615
Batch 12/64 loss: 0.2579338550567627
Batch 13/64 loss: 0.24830317497253418
Batch 14/64 loss: 0.24938130378723145
Batch 15/64 loss: 0.23836743831634521
Batch 16/64 loss: 0.25481027364730835
Batch 17/64 loss: 0.2514784336090088
Batch 18/64 loss: 0.24973666667938232
Batch 19/64 loss: 0.2475266456604004
Batch 20/64 loss: 0.24376147985458374
Batch 21/64 loss: 0.25592535734176636
Batch 22/64 loss: 0.2635449171066284
Batch 23/64 loss: 0.25134170055389404
Batch 24/64 loss: 0.25671136379241943
Batch 25/64 loss: 0.2487131953239441
Batch 26/64 loss: 0.25244390964508057
Batch 27/64 loss: 0.2548817992210388
Batch 28/64 loss: 0.24927383661270142
Batch 29/64 loss: 0.24923723936080933
Batch 30/64 loss: 0.24774527549743652
Batch 31/64 loss: 0.2489461898803711
Batch 32/64 loss: 0.24774664640426636
Batch 33/64 loss: 0.24504315853118896
Batch 34/64 loss: 0.25100696086883545
Batch 35/64 loss: 0.2525981068611145
Batch 36/64 loss: 0.24883168935775757
Batch 37/64 loss: 0.25614750385284424
Batch 38/64 loss: 0.24676775932312012
Batch 39/64 loss: 0.24892151355743408
Batch 40/64 loss: 0.2424992322921753
Batch 41/64 loss: 0.2506195306777954
Batch 42/64 loss: 0.24744081497192383
Batch 43/64 loss: 0.2509697675704956
Batch 44/64 loss: 0.255346417427063
Batch 45/64 loss: 0.2465376853942871
Batch 46/64 loss: 0.2520284652709961
Batch 47/64 loss: 0.2500349283218384
Batch 48/64 loss: 0.2501406669616699
Batch 49/64 loss: 0.2529633045196533
Batch 50/64 loss: 0.2640518546104431
Batch 51/64 loss: 0.24531036615371704
Batch 52/64 loss: 0.2571200132369995
Batch 53/64 loss: 0.2507857084274292
Batch 54/64 loss: 0.25126802921295166
Batch 55/64 loss: 0.2505159378051758
Batch 56/64 loss: 0.2474985122680664
Batch 57/64 loss: 0.25298428535461426
Batch 58/64 loss: 0.25343453884124756
Batch 59/64 loss: 0.24185848236083984
Batch 60/64 loss: 0.2511597275733948
Batch 61/64 loss: 0.2543797492980957
Batch 62/64 loss: 0.25113314390182495
Batch 63/64 loss: 0.248679518699646
Batch 64/64 loss: 0.2516512870788574
Epoch 296  Train loss: 0.25059741712084005  Val loss: 0.2851372949036536
Epoch 297
-------------------------------
Batch 1/64 loss: 0.2408258318901062
Batch 2/64 loss: 0.2443351149559021
Batch 3/64 loss: 0.2564563751220703
Batch 4/64 loss: 0.24890542030334473
Batch 5/64 loss: 0.25424516201019287
Batch 6/64 loss: 0.251143217086792
Batch 7/64 loss: 0.24928045272827148
Batch 8/64 loss: 0.2406787872314453
Batch 9/64 loss: 0.2514077425003052
Batch 10/64 loss: 0.26798367500305176
Batch 11/64 loss: 0.25176870822906494
Batch 12/64 loss: 0.2515912652015686
Batch 13/64 loss: 0.2450352907180786
Batch 14/64 loss: 0.24325048923492432
Batch 15/64 loss: 0.25152045488357544
Batch 16/64 loss: 0.25589442253112793
Batch 17/64 loss: 0.2464430332183838
Batch 18/64 loss: 0.2467617392539978
Batch 19/64 loss: 0.25144946575164795
Batch 20/64 loss: 0.2524830102920532
Batch 21/64 loss: 0.24891793727874756
Batch 22/64 loss: 0.24727606773376465
Batch 23/64 loss: 0.2632840871810913
Batch 24/64 loss: 0.25433260202407837
Batch 25/64 loss: 0.25007128715515137
Batch 26/64 loss: 0.2565782070159912
Batch 27/64 loss: 0.24466323852539062
Batch 28/64 loss: 0.24836981296539307
Batch 29/64 loss: 0.2463393211364746
Batch 30/64 loss: 0.24825608730316162
Batch 31/64 loss: 0.2500235438346863
Batch 32/64 loss: 0.25108838081359863
Batch 33/64 loss: 0.26174139976501465
Batch 34/64 loss: 0.2577543258666992
Batch 35/64 loss: 0.26228833198547363
Batch 36/64 loss: 0.25226253271102905
Batch 37/64 loss: 0.24639612436294556
Batch 38/64 loss: 0.2515782117843628
Batch 39/64 loss: 0.2554998993873596
Batch 40/64 loss: 0.25227034091949463
Batch 41/64 loss: 0.25717437267303467
Batch 42/64 loss: 0.251508891582489
Batch 43/64 loss: 0.25092798471450806
Batch 44/64 loss: 0.2528688311576843
Batch 45/64 loss: 0.24618887901306152
Batch 46/64 loss: 0.24588704109191895
Batch 47/64 loss: 0.24233698844909668
Batch 48/64 loss: 0.2543203830718994
Batch 49/64 loss: 0.24726450443267822
Batch 50/64 loss: 0.2565509080886841
Batch 51/64 loss: 0.2516869306564331
Batch 52/64 loss: 0.2515036463737488
Batch 53/64 loss: 0.25649601221084595
Batch 54/64 loss: 0.2409501075744629
Batch 55/64 loss: 0.25735950469970703
Batch 56/64 loss: 0.2563440799713135
Batch 57/64 loss: 0.2374371886253357
Batch 58/64 loss: 0.25074028968811035
Batch 59/64 loss: 0.2606537342071533
Batch 60/64 loss: 0.2536282539367676
Batch 61/64 loss: 0.24920469522476196
Batch 62/64 loss: 0.24694478511810303
Batch 63/64 loss: 0.25038284063339233
Batch 64/64 loss: 0.2549436092376709
Epoch 297  Train loss: 0.2511375679689295  Val loss: 0.2845733583587961
Epoch 298
-------------------------------
Batch 1/64 loss: 0.24486291408538818
Batch 2/64 loss: 0.2571765184402466
Batch 3/64 loss: 0.24830204248428345
Batch 4/64 loss: 0.24749064445495605
Batch 5/64 loss: 0.24917638301849365
Batch 6/64 loss: 0.2500416040420532
Batch 7/64 loss: 0.2452404499053955
Batch 8/64 loss: 0.2568209171295166
Batch 9/64 loss: 0.24442672729492188
Batch 10/64 loss: 0.2650829553604126
Batch 11/64 loss: 0.24734008312225342
Batch 12/64 loss: 0.25260406732559204
Batch 13/64 loss: 0.24401205778121948
Batch 14/64 loss: 0.24673539400100708
Batch 15/64 loss: 0.24646282196044922
Batch 16/64 loss: 0.24719858169555664
Batch 17/64 loss: 0.24805009365081787
Batch 18/64 loss: 0.24893701076507568
Batch 19/64 loss: 0.25115543603897095
Batch 20/64 loss: 0.25805509090423584
Batch 21/64 loss: 0.24843740463256836
Batch 22/64 loss: 0.24949675798416138
Batch 23/64 loss: 0.2498127818107605
Batch 24/64 loss: 0.25777435302734375
Batch 25/64 loss: 0.2517669200897217
Batch 26/64 loss: 0.2569464445114136
Batch 27/64 loss: 0.2525256276130676
Batch 28/64 loss: 0.2399517297744751
Batch 29/64 loss: 0.245417058467865
Batch 30/64 loss: 0.25572967529296875
Batch 31/64 loss: 0.2605292797088623
Batch 32/64 loss: 0.24893558025360107
Batch 33/64 loss: 0.2510221004486084
Batch 34/64 loss: 0.24901539087295532
Batch 35/64 loss: 0.24702084064483643
Batch 36/64 loss: 0.24338936805725098
Batch 37/64 loss: 0.2567455768585205
Batch 38/64 loss: 0.23373448848724365
Batch 39/64 loss: 0.24923980236053467
Batch 40/64 loss: 0.24888741970062256
Batch 41/64 loss: 0.2496262788772583
Batch 42/64 loss: 0.24835169315338135
Batch 43/64 loss: 0.2566800117492676
Batch 44/64 loss: 0.24033617973327637
Batch 45/64 loss: 0.2467745542526245
Batch 46/64 loss: 0.25420403480529785
Batch 47/64 loss: 0.23556232452392578
Batch 48/64 loss: 0.24710321426391602
Batch 49/64 loss: 0.24845433235168457
Batch 50/64 loss: 0.2470182180404663
Batch 51/64 loss: 0.24901539087295532
Batch 52/64 loss: 0.2531932592391968
Batch 53/64 loss: 0.24927252531051636
Batch 54/64 loss: 0.2574770450592041
Batch 55/64 loss: 0.2533077001571655
Batch 56/64 loss: 0.26033860445022583
Batch 57/64 loss: 0.25079232454299927
Batch 58/64 loss: 0.2534080147743225
Batch 59/64 loss: 0.24841606616973877
Batch 60/64 loss: 0.2474132776260376
Batch 61/64 loss: 0.24993491172790527
Batch 62/64 loss: 0.26463139057159424
Batch 63/64 loss: 0.2510029673576355
Batch 64/64 loss: 0.24779129028320312
Epoch 298  Train loss: 0.25009738323735253  Val loss: 0.2855626004668036
Epoch 299
-------------------------------
Batch 1/64 loss: 0.24995917081832886
Batch 2/64 loss: 0.2437964677810669
Batch 3/64 loss: 0.25166988372802734
Batch 4/64 loss: 0.2530714273452759
Batch 5/64 loss: 0.24845433235168457
Batch 6/64 loss: 0.24360334873199463
Batch 7/64 loss: 0.24620938301086426
Batch 8/64 loss: 0.2511698007583618
Batch 9/64 loss: 0.24623781442642212
Batch 10/64 loss: 0.24174869060516357
Batch 11/64 loss: 0.244576096534729
Batch 12/64 loss: 0.24263685941696167
Batch 13/64 loss: 0.25643253326416016
Batch 14/64 loss: 0.2454947829246521
Batch 15/64 loss: 0.25413358211517334
Batch 16/64 loss: 0.2474895715713501
Batch 17/64 loss: 0.2555750608444214
Batch 18/64 loss: 0.24474549293518066
Batch 19/64 loss: 0.2501963973045349
Batch 20/64 loss: 0.2528703212738037
Batch 21/64 loss: 0.25459539890289307
Batch 22/64 loss: 0.23860937356948853
Batch 23/64 loss: 0.2432492971420288
Batch 24/64 loss: 0.2480311393737793
Batch 25/64 loss: 0.25095486640930176
Batch 26/64 loss: 0.24637830257415771
Batch 27/64 loss: 0.24976372718811035
Batch 28/64 loss: 0.24805951118469238
Batch 29/64 loss: 0.25662606954574585
Batch 30/64 loss: 0.24851548671722412
Batch 31/64 loss: 0.24558711051940918
Batch 32/64 loss: 0.2460472583770752
Batch 33/64 loss: 0.24848192930221558
Batch 34/64 loss: 0.252996563911438
Batch 35/64 loss: 0.24529671669006348
Batch 36/64 loss: 0.2601587176322937
Batch 37/64 loss: 0.24328887462615967
Batch 38/64 loss: 0.25744926929473877
Batch 39/64 loss: 0.2583400011062622
Batch 40/64 loss: 0.25407034158706665
Batch 41/64 loss: 0.26527857780456543
Batch 42/64 loss: 0.2522704601287842
Batch 43/64 loss: 0.24694156646728516
Batch 44/64 loss: 0.24600660800933838
Batch 45/64 loss: 0.2484668493270874
Batch 46/64 loss: 0.25292015075683594
Batch 47/64 loss: 0.23970723152160645
Batch 48/64 loss: 0.25136280059814453
Batch 49/64 loss: 0.2577657699584961
Batch 50/64 loss: 0.25334131717681885
Batch 51/64 loss: 0.2558547258377075
Batch 52/64 loss: 0.2510484457015991
Batch 53/64 loss: 0.24249833822250366
Batch 54/64 loss: 0.24097639322280884
Batch 55/64 loss: 0.2542775869369507
Batch 56/64 loss: 0.24721485376358032
Batch 57/64 loss: 0.2452716827392578
Batch 58/64 loss: 0.2556310296058655
Batch 59/64 loss: 0.2487475872039795
Batch 60/64 loss: 0.24990254640579224
Batch 61/64 loss: 0.26431822776794434
Batch 62/64 loss: 0.2437201738357544
Batch 63/64 loss: 0.24544501304626465
Batch 64/64 loss: 0.24877315759658813
Epoch 299  Train loss: 0.24960186317855237  Val loss: 0.28307395907202126
Saving best model, epoch: 299
Epoch 300
-------------------------------
Batch 1/64 loss: 0.25698649883270264
Batch 2/64 loss: 0.24324250221252441
Batch 3/64 loss: 0.25611191987991333
Batch 4/64 loss: 0.25432467460632324
Batch 5/64 loss: 0.238969087600708
Batch 6/64 loss: 0.25902318954467773
Batch 7/64 loss: 0.2640753984451294
Batch 8/64 loss: 0.24750566482543945
Batch 9/64 loss: 0.2533099055290222
Batch 10/64 loss: 0.25126779079437256
Batch 11/64 loss: 0.2561345100402832
Batch 12/64 loss: 0.26026463508605957
Batch 13/64 loss: 0.24643594026565552
Batch 14/64 loss: 0.24841487407684326
Batch 15/64 loss: 0.24574583768844604
Batch 16/64 loss: 0.2410517930984497
Batch 17/64 loss: 0.24584698677062988
Batch 18/64 loss: 0.2545645236968994
Batch 19/64 loss: 0.2506248950958252
Batch 20/64 loss: 0.2533780336380005
Batch 21/64 loss: 0.2548901438713074
Batch 22/64 loss: 0.24550080299377441
Batch 23/64 loss: 0.25276070833206177
Batch 24/64 loss: 0.2516169548034668
Batch 25/64 loss: 0.2516818046569824
Batch 26/64 loss: 0.24920332431793213
Batch 27/64 loss: 0.24237191677093506
Batch 28/64 loss: 0.2462294101715088
Batch 29/64 loss: 0.2567936182022095
Batch 30/64 loss: 0.25525838136672974
Batch 31/64 loss: 0.24955058097839355
Batch 32/64 loss: 0.2543520927429199
Batch 33/64 loss: 0.2527398467063904
Batch 34/64 loss: 0.2611495852470398
Batch 35/64 loss: 0.24296504259109497
Batch 36/64 loss: 0.24875879287719727
Batch 37/64 loss: 0.251556396484375
Batch 38/64 loss: 0.2526189088821411
Batch 39/64 loss: 0.25042974948883057
Batch 40/64 loss: 0.26233506202697754
Batch 41/64 loss: 0.24940288066864014
Batch 42/64 loss: 0.25188422203063965
Batch 43/64 loss: 0.2738380432128906
Batch 44/64 loss: 0.24994230270385742
Batch 45/64 loss: 0.23906785249710083
Batch 46/64 loss: 0.2417004108428955
Batch 47/64 loss: 0.24436432123184204
Batch 48/64 loss: 0.24882525205612183
Batch 49/64 loss: 0.25083136558532715
Batch 50/64 loss: 0.25380438566207886
Batch 51/64 loss: 0.24303710460662842
Batch 52/64 loss: 0.24812555313110352
Batch 53/64 loss: 0.2532389163970947
Batch 54/64 loss: 0.24388235807418823
Batch 55/64 loss: 0.25503838062286377
Batch 56/64 loss: 0.2508049011230469
Batch 57/64 loss: 0.25138962268829346
Batch 58/64 loss: 0.24643635749816895
Batch 59/64 loss: 0.24996674060821533
Batch 60/64 loss: 0.2483586072921753
Batch 61/64 loss: 0.2493985891342163
Batch 62/64 loss: 0.25283271074295044
Batch 63/64 loss: 0.24315869808197021
Batch 64/64 loss: 0.25081920623779297
Epoch 300  Train loss: 0.2507840904535032  Val loss: 0.2837894126721674
Epoch 301
-------------------------------
Batch 1/64 loss: 0.24055755138397217
Batch 2/64 loss: 0.24440795183181763
Batch 3/64 loss: 0.25534874200820923
Batch 4/64 loss: 0.2508299946784973
Batch 5/64 loss: 0.25274884700775146
Batch 6/64 loss: 0.2556051015853882
Batch 7/64 loss: 0.24430692195892334
Batch 8/64 loss: 0.24389290809631348
Batch 9/64 loss: 0.24905002117156982
Batch 10/64 loss: 0.24539798498153687
Batch 11/64 loss: 0.2460271716117859
Batch 12/64 loss: 0.25448060035705566
Batch 13/64 loss: 0.2458939552307129
Batch 14/64 loss: 0.2623184323310852
Batch 15/64 loss: 0.2419142723083496
Batch 16/64 loss: 0.26531028747558594
Batch 17/64 loss: 0.25726407766342163
Batch 18/64 loss: 0.24669557809829712
Batch 19/64 loss: 0.2504984140396118
Batch 20/64 loss: 0.250044584274292
Batch 21/64 loss: 0.24089264869689941
Batch 22/64 loss: 0.24562835693359375
Batch 23/64 loss: 0.2469731569290161
Batch 24/64 loss: 0.24745142459869385
Batch 25/64 loss: 0.25355708599090576
Batch 26/64 loss: 0.24849790334701538
Batch 27/64 loss: 0.25020498037338257
Batch 28/64 loss: 0.25637364387512207
Batch 29/64 loss: 0.25478148460388184
Batch 30/64 loss: 0.2545938491821289
Batch 31/64 loss: 0.2557753324508667
Batch 32/64 loss: 0.2588299512863159
Batch 33/64 loss: 0.2502729892730713
Batch 34/64 loss: 0.2593761086463928
Batch 35/64 loss: 0.24439215660095215
Batch 36/64 loss: 0.25106382369995117
Batch 37/64 loss: 0.25065791606903076
Batch 38/64 loss: 0.26029032468795776
Batch 39/64 loss: 0.26447129249572754
Batch 40/64 loss: 0.2558910846710205
Batch 41/64 loss: 0.2594735026359558
Batch 42/64 loss: 0.24944382905960083
Batch 43/64 loss: 0.24519789218902588
Batch 44/64 loss: 0.2524561285972595
Batch 45/64 loss: 0.2487165331840515
Batch 46/64 loss: 0.24828249216079712
Batch 47/64 loss: 0.2464572787284851
Batch 48/64 loss: 0.25068652629852295
Batch 49/64 loss: 0.24710649251937866
Batch 50/64 loss: 0.2501603364944458
Batch 51/64 loss: 0.2451305389404297
Batch 52/64 loss: 0.25060707330703735
Batch 53/64 loss: 0.2577083110809326
Batch 54/64 loss: 0.2469865083694458
Batch 55/64 loss: 0.2432970404624939
Batch 56/64 loss: 0.2403060793876648
Batch 57/64 loss: 0.2515219449996948
Batch 58/64 loss: 0.24472343921661377
Batch 59/64 loss: 0.24525415897369385
Batch 60/64 loss: 0.25373971462249756
Batch 61/64 loss: 0.2519128918647766
Batch 62/64 loss: 0.2549583911895752
Batch 63/64 loss: 0.24458634853363037
Batch 64/64 loss: 0.24525976181030273
Epoch 301  Train loss: 0.25043493626164454  Val loss: 0.2836218761004943
Epoch 302
-------------------------------
Batch 1/64 loss: 0.246201753616333
Batch 2/64 loss: 0.2492402195930481
Batch 3/64 loss: 0.25684404373168945
Batch 4/64 loss: 0.24923920631408691
Batch 5/64 loss: 0.25287926197052
Batch 6/64 loss: 0.24369943141937256
Batch 7/64 loss: 0.24494314193725586
Batch 8/64 loss: 0.2528093457221985
Batch 9/64 loss: 0.24916255474090576
Batch 10/64 loss: 0.2424154281616211
Batch 11/64 loss: 0.2513164281845093
Batch 12/64 loss: 0.24974799156188965
Batch 13/64 loss: 0.249858558177948
Batch 14/64 loss: 0.23958885669708252
Batch 15/64 loss: 0.2467774748802185
Batch 16/64 loss: 0.25264525413513184
Batch 17/64 loss: 0.24974077939987183
Batch 18/64 loss: 0.2449132204055786
Batch 19/64 loss: 0.25728118419647217
Batch 20/64 loss: 0.24880486726760864
Batch 21/64 loss: 0.2506554126739502
Batch 22/64 loss: 0.24747633934020996
Batch 23/64 loss: 0.2642197608947754
Batch 24/64 loss: 0.2509903311729431
Batch 25/64 loss: 0.25342196226119995
Batch 26/64 loss: 0.2516521215438843
Batch 27/64 loss: 0.24538564682006836
Batch 28/64 loss: 0.25471997261047363
Batch 29/64 loss: 0.25160908699035645
Batch 30/64 loss: 0.2527264356613159
Batch 31/64 loss: 0.24338847398757935
Batch 32/64 loss: 0.24488818645477295
Batch 33/64 loss: 0.25325047969818115
Batch 34/64 loss: 0.2511407136917114
Batch 35/64 loss: 0.24313652515411377
Batch 36/64 loss: 0.24732673168182373
Batch 37/64 loss: 0.24755096435546875
Batch 38/64 loss: 0.25756585597991943
Batch 39/64 loss: 0.24903863668441772
Batch 40/64 loss: 0.24838495254516602
Batch 41/64 loss: 0.2540432810783386
Batch 42/64 loss: 0.24503827095031738
Batch 43/64 loss: 0.24229073524475098
Batch 44/64 loss: 0.2511707544326782
Batch 45/64 loss: 0.2408379316329956
Batch 46/64 loss: 0.244379460811615
Batch 47/64 loss: 0.2439500093460083
Batch 48/64 loss: 0.2571612596511841
Batch 49/64 loss: 0.2420210838317871
Batch 50/64 loss: 0.25067138671875
Batch 51/64 loss: 0.24799102544784546
Batch 52/64 loss: 0.24637621641159058
Batch 53/64 loss: 0.2505103349685669
Batch 54/64 loss: 0.2486717700958252
Batch 55/64 loss: 0.2573659420013428
Batch 56/64 loss: 0.24426311254501343
Batch 57/64 loss: 0.24726641178131104
Batch 58/64 loss: 0.24503493309020996
Batch 59/64 loss: 0.24464762210845947
Batch 60/64 loss: 0.2553762197494507
Batch 61/64 loss: 0.2498246431350708
Batch 62/64 loss: 0.24871373176574707
Batch 63/64 loss: 0.251667857170105
Batch 64/64 loss: 0.250515341758728
Epoch 302  Train loss: 0.24915761713888132  Val loss: 0.28361821399931236
Epoch 303
-------------------------------
Batch 1/64 loss: 0.2425473928451538
Batch 2/64 loss: 0.25254786014556885
Batch 3/64 loss: 0.25454020500183105
Batch 4/64 loss: 0.25160372257232666
Batch 5/64 loss: 0.25044792890548706
Batch 6/64 loss: 0.24300724267959595
Batch 7/64 loss: 0.2550569772720337
Batch 8/64 loss: 0.25197774171829224
Batch 9/64 loss: 0.2546772360801697
Batch 10/64 loss: 0.2506685256958008
Batch 11/64 loss: 0.24005603790283203
Batch 12/64 loss: 0.24432373046875
Batch 13/64 loss: 0.24428343772888184
Batch 14/64 loss: 0.2583373188972473
Batch 15/64 loss: 0.24295014142990112
Batch 16/64 loss: 0.24265289306640625
Batch 17/64 loss: 0.2503020167350769
Batch 18/64 loss: 0.2608112692832947
Batch 19/64 loss: 0.24877101182937622
Batch 20/64 loss: 0.2498931884765625
Batch 21/64 loss: 0.23654890060424805
Batch 22/64 loss: 0.24769771099090576
Batch 23/64 loss: 0.2431643009185791
Batch 24/64 loss: 0.2542564272880554
Batch 25/64 loss: 0.24772238731384277
Batch 26/64 loss: 0.241713285446167
Batch 27/64 loss: 0.24981606006622314
Batch 28/64 loss: 0.25439882278442383
Batch 29/64 loss: 0.2440032958984375
Batch 30/64 loss: 0.24812555313110352
Batch 31/64 loss: 0.2528608441352844
Batch 32/64 loss: 0.2528975009918213
Batch 33/64 loss: 0.24403631687164307
Batch 34/64 loss: 0.254524827003479
Batch 35/64 loss: 0.24195080995559692
Batch 36/64 loss: 0.24625694751739502
Batch 37/64 loss: 0.2595183253288269
Batch 38/64 loss: 0.25325000286102295
Batch 39/64 loss: 0.25513577461242676
Batch 40/64 loss: 0.24724388122558594
Batch 41/64 loss: 0.24780654907226562
Batch 42/64 loss: 0.24445396661758423
Batch 43/64 loss: 0.258556604385376
Batch 44/64 loss: 0.25338220596313477
Batch 45/64 loss: 0.24678486585617065
Batch 46/64 loss: 0.25601834058761597
Batch 47/64 loss: 0.24966394901275635
Batch 48/64 loss: 0.2447735071182251
Batch 49/64 loss: 0.24880266189575195
Batch 50/64 loss: 0.24546879529953003
Batch 51/64 loss: 0.24522751569747925
Batch 52/64 loss: 0.24676978588104248
Batch 53/64 loss: 0.2548256516456604
Batch 54/64 loss: 0.24622070789337158
Batch 55/64 loss: 0.24924921989440918
Batch 56/64 loss: 0.24735915660858154
Batch 57/64 loss: 0.25001657009124756
Batch 58/64 loss: 0.25134384632110596
Batch 59/64 loss: 0.2496277093887329
Batch 60/64 loss: 0.24659967422485352
Batch 61/64 loss: 0.2529752254486084
Batch 62/64 loss: 0.24053645133972168
Batch 63/64 loss: 0.24908876419067383
Batch 64/64 loss: 0.24454188346862793
Epoch 303  Train loss: 0.24899664299160826  Val loss: 0.28264614847517505
Saving best model, epoch: 303
Epoch 304
-------------------------------
Batch 1/64 loss: 0.24193894863128662
Batch 2/64 loss: 0.24745231866836548
Batch 3/64 loss: 0.25284260511398315
Batch 4/64 loss: 0.24349850416183472
Batch 5/64 loss: 0.2630023956298828
Batch 6/64 loss: 0.25297409296035767
Batch 7/64 loss: 0.2468932867050171
Batch 8/64 loss: 0.2518775463104248
Batch 9/64 loss: 0.24339663982391357
Batch 10/64 loss: 0.24196696281433105
Batch 11/64 loss: 0.24791204929351807
Batch 12/64 loss: 0.24419879913330078
Batch 13/64 loss: 0.24382221698760986
Batch 14/64 loss: 0.251197874546051
Batch 15/64 loss: 0.2510834336280823
Batch 16/64 loss: 0.24104297161102295
Batch 17/64 loss: 0.2490137815475464
Batch 18/64 loss: 0.2465541958808899
Batch 19/64 loss: 0.24930733442306519
Batch 20/64 loss: 0.25246578454971313
Batch 21/64 loss: 0.24282652139663696
Batch 22/64 loss: 0.2524570822715759
Batch 23/64 loss: 0.2385721206665039
Batch 24/64 loss: 0.25296998023986816
Batch 25/64 loss: 0.24816787242889404
Batch 26/64 loss: 0.24797773361206055
Batch 27/64 loss: 0.24305343627929688
Batch 28/64 loss: 0.2500354051589966
Batch 29/64 loss: 0.2537350058555603
Batch 30/64 loss: 0.24766767024993896
Batch 31/64 loss: 0.23911595344543457
Batch 32/64 loss: 0.2497107982635498
Batch 33/64 loss: 0.25161778926849365
Batch 34/64 loss: 0.24546140432357788
Batch 35/64 loss: 0.25488829612731934
Batch 36/64 loss: 0.2520153522491455
Batch 37/64 loss: 0.25485479831695557
Batch 38/64 loss: 0.25307923555374146
Batch 39/64 loss: 0.2432265281677246
Batch 40/64 loss: 0.2420177459716797
Batch 41/64 loss: 0.24210357666015625
Batch 42/64 loss: 0.2520991563796997
Batch 43/64 loss: 0.24617993831634521
Batch 44/64 loss: 0.24512016773223877
Batch 45/64 loss: 0.24721908569335938
Batch 46/64 loss: 0.24629950523376465
Batch 47/64 loss: 0.2561107873916626
Batch 48/64 loss: 0.24276310205459595
Batch 49/64 loss: 0.2527017593383789
Batch 50/64 loss: 0.2606062889099121
Batch 51/64 loss: 0.2513909339904785
Batch 52/64 loss: 0.250748872756958
Batch 53/64 loss: 0.25195562839508057
Batch 54/64 loss: 0.24165773391723633
Batch 55/64 loss: 0.25388187170028687
Batch 56/64 loss: 0.2540639638900757
Batch 57/64 loss: 0.254591166973114
Batch 58/64 loss: 0.24492895603179932
Batch 59/64 loss: 0.25315719842910767
Batch 60/64 loss: 0.2587367296218872
Batch 61/64 loss: 0.26484358310699463
Batch 62/64 loss: 0.25775575637817383
Batch 63/64 loss: 0.2504150867462158
Batch 64/64 loss: 0.25125980377197266
Epoch 304  Train loss: 0.24931244195676316  Val loss: 0.2835156028623024
Epoch 305
-------------------------------
Batch 1/64 loss: 0.25153112411499023
Batch 2/64 loss: 0.2502555847167969
Batch 3/64 loss: 0.24760961532592773
Batch 4/64 loss: 0.2480229139328003
Batch 5/64 loss: 0.2416764497756958
Batch 6/64 loss: 0.25769221782684326
Batch 7/64 loss: 0.24856120347976685
Batch 8/64 loss: 0.2501387596130371
Batch 9/64 loss: 0.25588828325271606
Batch 10/64 loss: 0.25469720363616943
Batch 11/64 loss: 0.25064897537231445
Batch 12/64 loss: 0.2606550455093384
Batch 13/64 loss: 0.2422029972076416
Batch 14/64 loss: 0.2423475980758667
Batch 15/64 loss: 0.24268501996994019
Batch 16/64 loss: 0.25181078910827637
Batch 17/64 loss: 0.24390214681625366
Batch 18/64 loss: 0.2429789900779724
Batch 19/64 loss: 0.2411057949066162
Batch 20/64 loss: 0.24548745155334473
Batch 21/64 loss: 0.24569422006607056
Batch 22/64 loss: 0.23810410499572754
Batch 23/64 loss: 0.24351125955581665
Batch 24/64 loss: 0.23733723163604736
Batch 25/64 loss: 0.2482818365097046
Batch 26/64 loss: 0.2513927221298218
Batch 27/64 loss: 0.2523590326309204
Batch 28/64 loss: 0.254158616065979
Batch 29/64 loss: 0.2375374436378479
Batch 30/64 loss: 0.253399133682251
Batch 31/64 loss: 0.24374961853027344
Batch 32/64 loss: 0.24701166152954102
Batch 33/64 loss: 0.2533888816833496
Batch 34/64 loss: 0.24741804599761963
Batch 35/64 loss: 0.25149381160736084
Batch 36/64 loss: 0.2535696029663086
Batch 37/64 loss: 0.2508191466331482
Batch 38/64 loss: 0.24664902687072754
Batch 39/64 loss: 0.24987173080444336
Batch 40/64 loss: 0.25137418508529663
Batch 41/64 loss: 0.25115346908569336
Batch 42/64 loss: 0.25288891792297363
Batch 43/64 loss: 0.24846965074539185
Batch 44/64 loss: 0.24167966842651367
Batch 45/64 loss: 0.25217097997665405
Batch 46/64 loss: 0.25453323125839233
Batch 47/64 loss: 0.24036872386932373
Batch 48/64 loss: 0.2577258348464966
Batch 49/64 loss: 0.2523900270462036
Batch 50/64 loss: 0.24952161312103271
Batch 51/64 loss: 0.243968665599823
Batch 52/64 loss: 0.25315678119659424
Batch 53/64 loss: 0.2607685923576355
Batch 54/64 loss: 0.24675655364990234
Batch 55/64 loss: 0.2582114338874817
Batch 56/64 loss: 0.25203937292099
Batch 57/64 loss: 0.24836504459381104
Batch 58/64 loss: 0.25695884227752686
Batch 59/64 loss: 0.2512444853782654
Batch 60/64 loss: 0.23796331882476807
Batch 61/64 loss: 0.2523878812789917
Batch 62/64 loss: 0.25046682357788086
Batch 63/64 loss: 0.24372637271881104
Batch 64/64 loss: 0.25597137212753296
Epoch 305  Train loss: 0.24903394965564504  Val loss: 0.28324088321109
Epoch 306
-------------------------------
Batch 1/64 loss: 0.23946309089660645
Batch 2/64 loss: 0.2459932565689087
Batch 3/64 loss: 0.2577037811279297
Batch 4/64 loss: 0.24604147672653198
Batch 5/64 loss: 0.243399977684021
Batch 6/64 loss: 0.24240994453430176
Batch 7/64 loss: 0.24186575412750244
Batch 8/64 loss: 0.25612109899520874
Batch 9/64 loss: 0.2489904761314392
Batch 10/64 loss: 0.24632775783538818
Batch 11/64 loss: 0.25710296630859375
Batch 12/64 loss: 0.2501816153526306
Batch 13/64 loss: 0.25124669075012207
Batch 14/64 loss: 0.24741733074188232
Batch 15/64 loss: 0.2504197359085083
Batch 16/64 loss: 0.24967002868652344
Batch 17/64 loss: 0.24794542789459229
Batch 18/64 loss: 0.25305402278900146
Batch 19/64 loss: 0.2575336694717407
Batch 20/64 loss: 0.23895734548568726
Batch 21/64 loss: 0.25548696517944336
Batch 22/64 loss: 0.24053966999053955
Batch 23/64 loss: 0.24811327457427979
Batch 24/64 loss: 0.2451632022857666
Batch 25/64 loss: 0.24996310472488403
Batch 26/64 loss: 0.23818135261535645
Batch 27/64 loss: 0.2456374168395996
Batch 28/64 loss: 0.25666385889053345
Batch 29/64 loss: 0.24915236234664917
Batch 30/64 loss: 0.24448460340499878
Batch 31/64 loss: 0.2540436387062073
Batch 32/64 loss: 0.25111520290374756
Batch 33/64 loss: 0.25921058654785156
Batch 34/64 loss: 0.24553322792053223
Batch 35/64 loss: 0.24848341941833496
Batch 36/64 loss: 0.24223613739013672
Batch 37/64 loss: 0.24828600883483887
Batch 38/64 loss: 0.2490558624267578
Batch 39/64 loss: 0.24484610557556152
Batch 40/64 loss: 0.25317084789276123
Batch 41/64 loss: 0.25480228662490845
Batch 42/64 loss: 0.24859106540679932
Batch 43/64 loss: 0.25677490234375
Batch 44/64 loss: 0.24602723121643066
Batch 45/64 loss: 0.24003982543945312
Batch 46/64 loss: 0.25432783365249634
Batch 47/64 loss: 0.24462676048278809
Batch 48/64 loss: 0.2452068328857422
Batch 49/64 loss: 0.2445695996284485
Batch 50/64 loss: 0.24389195442199707
Batch 51/64 loss: 0.249936044216156
Batch 52/64 loss: 0.25364089012145996
Batch 53/64 loss: 0.253187358379364
Batch 54/64 loss: 0.24894386529922485
Batch 55/64 loss: 0.24720656871795654
Batch 56/64 loss: 0.2551049590110779
Batch 57/64 loss: 0.24787533283233643
Batch 58/64 loss: 0.24632680416107178
Batch 59/64 loss: 0.24268382787704468
Batch 60/64 loss: 0.25178563594818115
Batch 61/64 loss: 0.2429049015045166
Batch 62/64 loss: 0.25270795822143555
Batch 63/64 loss: 0.24215805530548096
Batch 64/64 loss: 0.2437419891357422
Epoch 306  Train loss: 0.24842885148291494  Val loss: 0.28370432652968314
Epoch 307
-------------------------------
Batch 1/64 loss: 0.2288529872894287
Batch 2/64 loss: 0.24801093339920044
Batch 3/64 loss: 0.24836742877960205
Batch 4/64 loss: 0.25268757343292236
Batch 5/64 loss: 0.24268215894699097
Batch 6/64 loss: 0.24632024765014648
Batch 7/64 loss: 0.24460172653198242
Batch 8/64 loss: 0.24824440479278564
Batch 9/64 loss: 0.24287432432174683
Batch 10/64 loss: 0.23562729358673096
Batch 11/64 loss: 0.2586510181427002
Batch 12/64 loss: 0.2554512023925781
Batch 13/64 loss: 0.24730300903320312
Batch 14/64 loss: 0.24706673622131348
Batch 15/64 loss: 0.24608081579208374
Batch 16/64 loss: 0.25912052392959595
Batch 17/64 loss: 0.24449849128723145
Batch 18/64 loss: 0.24842560291290283
Batch 19/64 loss: 0.26290982961654663
Batch 20/64 loss: 0.23895400762557983
Batch 21/64 loss: 0.23819267749786377
Batch 22/64 loss: 0.25241923332214355
Batch 23/64 loss: 0.25744104385375977
Batch 24/64 loss: 0.25333333015441895
Batch 25/64 loss: 0.24406111240386963
Batch 26/64 loss: 0.24871480464935303
Batch 27/64 loss: 0.24209946393966675
Batch 28/64 loss: 0.24762916564941406
Batch 29/64 loss: 0.2533632516860962
Batch 30/64 loss: 0.2459334135055542
Batch 31/64 loss: 0.2531723976135254
Batch 32/64 loss: 0.2561097741127014
Batch 33/64 loss: 0.2595638036727905
Batch 34/64 loss: 0.24211716651916504
Batch 35/64 loss: 0.24739396572113037
Batch 36/64 loss: 0.24324166774749756
Batch 37/64 loss: 0.24578773975372314
Batch 38/64 loss: 0.25691521167755127
Batch 39/64 loss: 0.25711727142333984
Batch 40/64 loss: 0.24629110097885132
Batch 41/64 loss: 0.24933111667633057
Batch 42/64 loss: 0.24480736255645752
Batch 43/64 loss: 0.25566673278808594
Batch 44/64 loss: 0.2461949586868286
Batch 45/64 loss: 0.24123430252075195
Batch 46/64 loss: 0.24072039127349854
Batch 47/64 loss: 0.24713200330734253
Batch 48/64 loss: 0.25449931621551514
Batch 49/64 loss: 0.24843621253967285
Batch 50/64 loss: 0.24700748920440674
Batch 51/64 loss: 0.24856871366500854
Batch 52/64 loss: 0.24548786878585815
Batch 53/64 loss: 0.24923396110534668
Batch 54/64 loss: 0.23835444450378418
Batch 55/64 loss: 0.2512141466140747
Batch 56/64 loss: 0.24681967496871948
Batch 57/64 loss: 0.25818705558776855
Batch 58/64 loss: 0.239355206489563
Batch 59/64 loss: 0.23936748504638672
Batch 60/64 loss: 0.26556867361068726
Batch 61/64 loss: 0.2532418966293335
Batch 62/64 loss: 0.24839264154434204
Batch 63/64 loss: 0.25894367694854736
Batch 64/64 loss: 0.25525879859924316
Epoch 307  Train loss: 0.24857784065545774  Val loss: 0.28260007326545583
Saving best model, epoch: 307
Epoch 308
-------------------------------
Batch 1/64 loss: 0.26099520921707153
Batch 2/64 loss: 0.24203991889953613
Batch 3/64 loss: 0.25322258472442627
Batch 4/64 loss: 0.2433943748474121
Batch 5/64 loss: 0.24650919437408447
Batch 6/64 loss: 0.2468494176864624
Batch 7/64 loss: 0.24775546789169312
Batch 8/64 loss: 0.24089300632476807
Batch 9/64 loss: 0.2449830174446106
Batch 10/64 loss: 0.255754292011261
Batch 11/64 loss: 0.23703312873840332
Batch 12/64 loss: 0.24517780542373657
Batch 13/64 loss: 0.24722331762313843
Batch 14/64 loss: 0.23770171403884888
Batch 15/64 loss: 0.26676106452941895
Batch 16/64 loss: 0.25740647315979004
Batch 17/64 loss: 0.25512880086898804
Batch 18/64 loss: 0.25421273708343506
Batch 19/64 loss: 0.23674887418746948
Batch 20/64 loss: 0.24403929710388184
Batch 21/64 loss: 0.24294090270996094
Batch 22/64 loss: 0.246762216091156
Batch 23/64 loss: 0.25237417221069336
Batch 24/64 loss: 0.23848700523376465
Batch 25/64 loss: 0.24840307235717773
Batch 26/64 loss: 0.24265164136886597
Batch 27/64 loss: 0.25078141689300537
Batch 28/64 loss: 0.2545090317726135
Batch 29/64 loss: 0.2459496259689331
Batch 30/64 loss: 0.2508554458618164
Batch 31/64 loss: 0.2415604591369629
Batch 32/64 loss: 0.24336785078048706
Batch 33/64 loss: 0.2354567050933838
Batch 34/64 loss: 0.2491776943206787
Batch 35/64 loss: 0.249686598777771
Batch 36/64 loss: 0.25653713941574097
Batch 37/64 loss: 0.24283945560455322
Batch 38/64 loss: 0.24899131059646606
Batch 39/64 loss: 0.2488728165626526
Batch 40/64 loss: 0.2477642297744751
Batch 41/64 loss: 0.24895113706588745
Batch 42/64 loss: 0.2534482479095459
Batch 43/64 loss: 0.25578129291534424
Batch 44/64 loss: 0.24787884950637817
Batch 45/64 loss: 0.25328123569488525
Batch 46/64 loss: 0.25326693058013916
Batch 47/64 loss: 0.23935747146606445
Batch 48/64 loss: 0.24062126874923706
Batch 49/64 loss: 0.24480801820755005
Batch 50/64 loss: 0.24818670749664307
Batch 51/64 loss: 0.252811074256897
Batch 52/64 loss: 0.2476203441619873
Batch 53/64 loss: 0.26220858097076416
Batch 54/64 loss: 0.24438291788101196
Batch 55/64 loss: 0.24376952648162842
Batch 56/64 loss: 0.24144399166107178
Batch 57/64 loss: 0.25449931621551514
Batch 58/64 loss: 0.24470305442810059
Batch 59/64 loss: 0.24901461601257324
Batch 60/64 loss: 0.25297558307647705
Batch 61/64 loss: 0.25090909004211426
Batch 62/64 loss: 0.24235975742340088
Batch 63/64 loss: 0.247483491897583
Batch 64/64 loss: 0.2540144920349121
Epoch 308  Train loss: 0.2480324997621424  Val loss: 0.28528590956094746
Epoch 309
-------------------------------
Batch 1/64 loss: 0.24424958229064941
Batch 2/64 loss: 0.2594733238220215
Batch 3/64 loss: 0.24453818798065186
Batch 4/64 loss: 0.2420693039894104
Batch 5/64 loss: 0.25578439235687256
Batch 6/64 loss: 0.2459937334060669
Batch 7/64 loss: 0.24931955337524414
Batch 8/64 loss: 0.2497880458831787
Batch 9/64 loss: 0.24362659454345703
Batch 10/64 loss: 0.24882829189300537
Batch 11/64 loss: 0.25924980640411377
Batch 12/64 loss: 0.2567206621170044
Batch 13/64 loss: 0.257426917552948
Batch 14/64 loss: 0.24467504024505615
Batch 15/64 loss: 0.25722336769104004
Batch 16/64 loss: 0.25122374296188354
Batch 17/64 loss: 0.23673301935195923
Batch 18/64 loss: 0.25186777114868164
Batch 19/64 loss: 0.24287128448486328
Batch 20/64 loss: 0.2491016387939453
Batch 21/64 loss: 0.25327491760253906
Batch 22/64 loss: 0.25401151180267334
Batch 23/64 loss: 0.24692249298095703
Batch 24/64 loss: 0.24466001987457275
Batch 25/64 loss: 0.24385976791381836
Batch 26/64 loss: 0.2530086040496826
Batch 27/64 loss: 0.2455710768699646
Batch 28/64 loss: 0.24607378244400024
Batch 29/64 loss: 0.2519845962524414
Batch 30/64 loss: 0.24831128120422363
Batch 31/64 loss: 0.24739354848861694
Batch 32/64 loss: 0.24806135892868042
Batch 33/64 loss: 0.24626612663269043
Batch 34/64 loss: 0.24427485466003418
Batch 35/64 loss: 0.2466374635696411
Batch 36/64 loss: 0.25605785846710205
Batch 37/64 loss: 0.24524366855621338
Batch 38/64 loss: 0.23586595058441162
Batch 39/64 loss: 0.24534893035888672
Batch 40/64 loss: 0.24492406845092773
Batch 41/64 loss: 0.2561527490615845
Batch 42/64 loss: 0.2562331557273865
Batch 43/64 loss: 0.2524023652076721
Batch 44/64 loss: 0.23799419403076172
Batch 45/64 loss: 0.2540792226791382
Batch 46/64 loss: 0.24488556385040283
Batch 47/64 loss: 0.24535179138183594
Batch 48/64 loss: 0.249958336353302
Batch 49/64 loss: 0.24942803382873535
Batch 50/64 loss: 0.25178998708724976
Batch 51/64 loss: 0.23887169361114502
Batch 52/64 loss: 0.253584623336792
Batch 53/64 loss: 0.24966198205947876
Batch 54/64 loss: 0.2517521381378174
Batch 55/64 loss: 0.25280749797821045
Batch 56/64 loss: 0.255481481552124
Batch 57/64 loss: 0.2463511824607849
Batch 58/64 loss: 0.24563497304916382
Batch 59/64 loss: 0.24514758586883545
Batch 60/64 loss: 0.2540714740753174
Batch 61/64 loss: 0.24627840518951416
Batch 62/64 loss: 0.2541138529777527
Batch 63/64 loss: 0.24333679676055908
Batch 64/64 loss: 0.25067442655563354
Epoch 309  Train loss: 0.24881397719476736  Val loss: 0.28258985485817556
Saving best model, epoch: 309
Epoch 310
-------------------------------
Batch 1/64 loss: 0.2704193592071533
Batch 2/64 loss: 0.25911659002304077
Batch 3/64 loss: 0.24640566110610962
Batch 4/64 loss: 0.24308693408966064
Batch 5/64 loss: 0.24550604820251465
Batch 6/64 loss: 0.24943745136260986
Batch 7/64 loss: 0.24930500984191895
Batch 8/64 loss: 0.24363738298416138
Batch 9/64 loss: 0.25274932384490967
Batch 10/64 loss: 0.25399959087371826
Batch 11/64 loss: 0.24690306186676025
Batch 12/64 loss: 0.244890034198761
Batch 13/64 loss: 0.24461424350738525
Batch 14/64 loss: 0.24789249897003174
Batch 15/64 loss: 0.24699193239212036
Batch 16/64 loss: 0.2521018981933594
Batch 17/64 loss: 0.25629866123199463
Batch 18/64 loss: 0.2496585249900818
Batch 19/64 loss: 0.23794984817504883
Batch 20/64 loss: 0.2396160364151001
Batch 21/64 loss: 0.25797533988952637
Batch 22/64 loss: 0.24563103914260864
Batch 23/64 loss: 0.2581729292869568
Batch 24/64 loss: 0.24719297885894775
Batch 25/64 loss: 0.24771225452423096
Batch 26/64 loss: 0.24270474910736084
Batch 27/64 loss: 0.24705135822296143
Batch 28/64 loss: 0.2609783411026001
Batch 29/64 loss: 0.24977880716323853
Batch 30/64 loss: 0.25246739387512207
Batch 31/64 loss: 0.24647772312164307
Batch 32/64 loss: 0.24897289276123047
Batch 33/64 loss: 0.2475484013557434
Batch 34/64 loss: 0.2452554702758789
Batch 35/64 loss: 0.2501465678215027
Batch 36/64 loss: 0.2480815052986145
Batch 37/64 loss: 0.2501363158226013
Batch 38/64 loss: 0.247231125831604
Batch 39/64 loss: 0.24699747562408447
Batch 40/64 loss: 0.25109994411468506
Batch 41/64 loss: 0.24116355180740356
Batch 42/64 loss: 0.2535250186920166
Batch 43/64 loss: 0.2569378614425659
Batch 44/64 loss: 0.24901044368743896
Batch 45/64 loss: 0.24368596076965332
Batch 46/64 loss: 0.23622840642929077
Batch 47/64 loss: 0.24559926986694336
Batch 48/64 loss: 0.2378585934638977
Batch 49/64 loss: 0.2526950240135193
Batch 50/64 loss: 0.250205397605896
Batch 51/64 loss: 0.2479926347732544
Batch 52/64 loss: 0.24292147159576416
Batch 53/64 loss: 0.24263650178909302
Batch 54/64 loss: 0.2522846460342407
Batch 55/64 loss: 0.25948846340179443
Batch 56/64 loss: 0.2581906318664551
Batch 57/64 loss: 0.24001049995422363
Batch 58/64 loss: 0.24459826946258545
Batch 59/64 loss: 0.24627244472503662
Batch 60/64 loss: 0.23901259899139404
Batch 61/64 loss: 0.24505335092544556
Batch 62/64 loss: 0.24886852502822876
Batch 63/64 loss: 0.2553580403327942
Batch 64/64 loss: 0.2454674243927002
Epoch 310  Train loss: 0.24856299419029088  Val loss: 0.284306375226614
Epoch 311
-------------------------------
Batch 1/64 loss: 0.24106532335281372
Batch 2/64 loss: 0.24552243947982788
Batch 3/64 loss: 0.241574227809906
Batch 4/64 loss: 0.2559579610824585
Batch 5/64 loss: 0.23792362213134766
Batch 6/64 loss: 0.23223870992660522
Batch 7/64 loss: 0.25941359996795654
Batch 8/64 loss: 0.24019181728363037
Batch 9/64 loss: 0.24365651607513428
Batch 10/64 loss: 0.24896323680877686
Batch 11/64 loss: 0.24174261093139648
Batch 12/64 loss: 0.24042820930480957
Batch 13/64 loss: 0.24517875909805298
Batch 14/64 loss: 0.23523271083831787
Batch 15/64 loss: 0.24972039461135864
Batch 16/64 loss: 0.25014418363571167
Batch 17/64 loss: 0.24613672494888306
Batch 18/64 loss: 0.2481527328491211
Batch 19/64 loss: 0.2407568097114563
Batch 20/64 loss: 0.259006142616272
Batch 21/64 loss: 0.25475841760635376
Batch 22/64 loss: 0.25212836265563965
Batch 23/64 loss: 0.24816131591796875
Batch 24/64 loss: 0.2578834891319275
Batch 25/64 loss: 0.25022953748703003
Batch 26/64 loss: 0.26018667221069336
Batch 27/64 loss: 0.2463749647140503
Batch 28/64 loss: 0.2442624568939209
Batch 29/64 loss: 0.24694085121154785
Batch 30/64 loss: 0.24438977241516113
Batch 31/64 loss: 0.2473139762878418
Batch 32/64 loss: 0.2604641914367676
Batch 33/64 loss: 0.25033241510391235
Batch 34/64 loss: 0.2552333474159241
Batch 35/64 loss: 0.2616806626319885
Batch 36/64 loss: 0.24268990755081177
Batch 37/64 loss: 0.24002182483673096
Batch 38/64 loss: 0.23596954345703125
Batch 39/64 loss: 0.24822998046875
Batch 40/64 loss: 0.2520221471786499
Batch 41/64 loss: 0.2507571578025818
Batch 42/64 loss: 0.24642133712768555
Batch 43/64 loss: 0.24781382083892822
Batch 44/64 loss: 0.2562912702560425
Batch 45/64 loss: 0.2422310709953308
Batch 46/64 loss: 0.24428677558898926
Batch 47/64 loss: 0.2543298602104187
Batch 48/64 loss: 0.23944473266601562
Batch 49/64 loss: 0.25037217140197754
Batch 50/64 loss: 0.23892682790756226
Batch 51/64 loss: 0.24067836999893188
Batch 52/64 loss: 0.2514357566833496
Batch 53/64 loss: 0.24268823862075806
Batch 54/64 loss: 0.26314789056777954
Batch 55/64 loss: 0.2603052258491516
Batch 56/64 loss: 0.2412915825843811
Batch 57/64 loss: 0.2592266798019409
Batch 58/64 loss: 0.24307328462600708
Batch 59/64 loss: 0.2523708939552307
Batch 60/64 loss: 0.2509804964065552
Batch 61/64 loss: 0.25510716438293457
Batch 62/64 loss: 0.242420494556427
Batch 63/64 loss: 0.24634796380996704
Batch 64/64 loss: 0.2509021759033203
Epoch 311  Train loss: 0.24800637282577215  Val loss: 0.2836015781586113
Epoch 312
-------------------------------
Batch 1/64 loss: 0.24579942226409912
Batch 2/64 loss: 0.24878144264221191
Batch 3/64 loss: 0.25533950328826904
Batch 4/64 loss: 0.24860739707946777
Batch 5/64 loss: 0.25431227684020996
Batch 6/64 loss: 0.24627423286437988
Batch 7/64 loss: 0.25075507164001465
Batch 8/64 loss: 0.24573731422424316
Batch 9/64 loss: 0.2512378692626953
Batch 10/64 loss: 0.25486046075820923
Batch 11/64 loss: 0.2518156170845032
Batch 12/64 loss: 0.24581104516983032
Batch 13/64 loss: 0.24120551347732544
Batch 14/64 loss: 0.2519761323928833
Batch 15/64 loss: 0.2449018955230713
Batch 16/64 loss: 0.24505579471588135
Batch 17/64 loss: 0.24409830570220947
Batch 18/64 loss: 0.24828261137008667
Batch 19/64 loss: 0.25124335289001465
Batch 20/64 loss: 0.23998379707336426
Batch 21/64 loss: 0.24288082122802734
Batch 22/64 loss: 0.25280892848968506
Batch 23/64 loss: 0.23580467700958252
Batch 24/64 loss: 0.24413901567459106
Batch 25/64 loss: 0.2422717809677124
Batch 26/64 loss: 0.2543620467185974
Batch 27/64 loss: 0.25214213132858276
Batch 28/64 loss: 0.2529040575027466
Batch 29/64 loss: 0.2569965124130249
Batch 30/64 loss: 0.25855183601379395
Batch 31/64 loss: 0.24794518947601318
Batch 32/64 loss: 0.24070286750793457
Batch 33/64 loss: 0.2452390193939209
Batch 34/64 loss: 0.24926745891571045
Batch 35/64 loss: 0.24859833717346191
Batch 36/64 loss: 0.24714714288711548
Batch 37/64 loss: 0.24753820896148682
Batch 38/64 loss: 0.24458450078964233
Batch 39/64 loss: 0.23907709121704102
Batch 40/64 loss: 0.246789813041687
Batch 41/64 loss: 0.24717849493026733
Batch 42/64 loss: 0.24793791770935059
Batch 43/64 loss: 0.24356210231781006
Batch 44/64 loss: 0.24858570098876953
Batch 45/64 loss: 0.24684858322143555
Batch 46/64 loss: 0.25090253353118896
Batch 47/64 loss: 0.25003039836883545
Batch 48/64 loss: 0.2426973581314087
Batch 49/64 loss: 0.24546849727630615
Batch 50/64 loss: 0.24634402990341187
Batch 51/64 loss: 0.24994945526123047
Batch 52/64 loss: 0.25350630283355713
Batch 53/64 loss: 0.24685180187225342
Batch 54/64 loss: 0.25111687183380127
Batch 55/64 loss: 0.23852449655532837
Batch 56/64 loss: 0.2546108365058899
Batch 57/64 loss: 0.2412503957748413
Batch 58/64 loss: 0.24955278635025024
Batch 59/64 loss: 0.26142632961273193
Batch 60/64 loss: 0.24931758642196655
Batch 61/64 loss: 0.2496625781059265
Batch 62/64 loss: 0.26195228099823
Batch 63/64 loss: 0.23974931240081787
Batch 64/64 loss: 0.2434065341949463
Epoch 312  Train loss: 0.24808489481608073  Val loss: 0.28337018821657317
Epoch 313
-------------------------------
Batch 1/64 loss: 0.25331979990005493
Batch 2/64 loss: 0.24707233905792236
Batch 3/64 loss: 0.24256658554077148
Batch 4/64 loss: 0.2526019811630249
Batch 5/64 loss: 0.23335176706314087
Batch 6/64 loss: 0.26078641414642334
Batch 7/64 loss: 0.2485746145248413
Batch 8/64 loss: 0.25282853841781616
Batch 9/64 loss: 0.2476731538772583
Batch 10/64 loss: 0.256195068359375
Batch 11/64 loss: 0.2482128143310547
Batch 12/64 loss: 0.24705159664154053
Batch 13/64 loss: 0.2421809434890747
Batch 14/64 loss: 0.2526887059211731
Batch 15/64 loss: 0.2509753704071045
Batch 16/64 loss: 0.2463468313217163
Batch 17/64 loss: 0.2514135241508484
Batch 18/64 loss: 0.25296199321746826
Batch 19/64 loss: 0.2540209889411926
Batch 20/64 loss: 0.24503719806671143
Batch 21/64 loss: 0.24438583850860596
Batch 22/64 loss: 0.24510300159454346
Batch 23/64 loss: 0.2503049969673157
Batch 24/64 loss: 0.24190402030944824
Batch 25/64 loss: 0.24318671226501465
Batch 26/64 loss: 0.24494636058807373
Batch 27/64 loss: 0.24677520990371704
Batch 28/64 loss: 0.251644492149353
Batch 29/64 loss: 0.24442195892333984
Batch 30/64 loss: 0.24465811252593994
Batch 31/64 loss: 0.24158436059951782
Batch 32/64 loss: 0.23440098762512207
Batch 33/64 loss: 0.25316041707992554
Batch 34/64 loss: 0.24866676330566406
Batch 35/64 loss: 0.24825048446655273
Batch 36/64 loss: 0.24067670106887817
Batch 37/64 loss: 0.24497056007385254
Batch 38/64 loss: 0.24653947353363037
Batch 39/64 loss: 0.24598145484924316
Batch 40/64 loss: 0.24909162521362305
Batch 41/64 loss: 0.24921000003814697
Batch 42/64 loss: 0.247198224067688
Batch 43/64 loss: 0.25872802734375
Batch 44/64 loss: 0.251730740070343
Batch 45/64 loss: 0.2521761655807495
Batch 46/64 loss: 0.25918030738830566
Batch 47/64 loss: 0.24335408210754395
Batch 48/64 loss: 0.23523277044296265
Batch 49/64 loss: 0.24530720710754395
Batch 50/64 loss: 0.24083828926086426
Batch 51/64 loss: 0.24333739280700684
Batch 52/64 loss: 0.24531275033950806
Batch 53/64 loss: 0.2471013069152832
Batch 54/64 loss: 0.2564513683319092
Batch 55/64 loss: 0.25268805027008057
Batch 56/64 loss: 0.25562524795532227
Batch 57/64 loss: 0.25116950273513794
Batch 58/64 loss: 0.24674737453460693
Batch 59/64 loss: 0.2492600679397583
Batch 60/64 loss: 0.2516688108444214
Batch 61/64 loss: 0.24824988842010498
Batch 62/64 loss: 0.24944597482681274
Batch 63/64 loss: 0.25031566619873047
Batch 64/64 loss: 0.25796395540237427
Epoch 313  Train loss: 0.24816181870067822  Val loss: 0.2831183768219964
Epoch 314
-------------------------------
Batch 1/64 loss: 0.254231333732605
Batch 2/64 loss: 0.26382923126220703
Batch 3/64 loss: 0.24160504341125488
Batch 4/64 loss: 0.23874634504318237
Batch 5/64 loss: 0.2547054886817932
Batch 6/64 loss: 0.24469125270843506
Batch 7/64 loss: 0.24665284156799316
Batch 8/64 loss: 0.25730955600738525
Batch 9/64 loss: 0.24959397315979004
Batch 10/64 loss: 0.24254387617111206
Batch 11/64 loss: 0.24000263214111328
Batch 12/64 loss: 0.2381429672241211
Batch 13/64 loss: 0.25681084394454956
Batch 14/64 loss: 0.25346553325653076
Batch 15/64 loss: 0.24724650382995605
Batch 16/64 loss: 0.24046194553375244
Batch 17/64 loss: 0.2416074275970459
Batch 18/64 loss: 0.2451779842376709
Batch 19/64 loss: 0.24735218286514282
Batch 20/64 loss: 0.24796688556671143
Batch 21/64 loss: 0.24491751194000244
Batch 22/64 loss: 0.25693416595458984
Batch 23/64 loss: 0.24358707666397095
Batch 24/64 loss: 0.2411724328994751
Batch 25/64 loss: 0.2542574405670166
Batch 26/64 loss: 0.25194448232650757
Batch 27/64 loss: 0.24367451667785645
Batch 28/64 loss: 0.24625277519226074
Batch 29/64 loss: 0.24250543117523193
Batch 30/64 loss: 0.24866998195648193
Batch 31/64 loss: 0.24344050884246826
Batch 32/64 loss: 0.2425926923751831
Batch 33/64 loss: 0.2511557340621948
Batch 34/64 loss: 0.24855995178222656
Batch 35/64 loss: 0.24472731351852417
Batch 36/64 loss: 0.24372774362564087
Batch 37/64 loss: 0.23751521110534668
Batch 38/64 loss: 0.2477315068244934
Batch 39/64 loss: 0.25121670961380005
Batch 40/64 loss: 0.2442338466644287
Batch 41/64 loss: 0.23953920602798462
Batch 42/64 loss: 0.244132399559021
Batch 43/64 loss: 0.2521325349807739
Batch 44/64 loss: 0.2394498586654663
Batch 45/64 loss: 0.24928855895996094
Batch 46/64 loss: 0.24885356426239014
Batch 47/64 loss: 0.24144518375396729
Batch 48/64 loss: 0.24667662382125854
Batch 49/64 loss: 0.2581908702850342
Batch 50/64 loss: 0.25347626209259033
Batch 51/64 loss: 0.25336259603500366
Batch 52/64 loss: 0.246057391166687
Batch 53/64 loss: 0.2503448724746704
Batch 54/64 loss: 0.24975740909576416
Batch 55/64 loss: 0.24606037139892578
Batch 56/64 loss: 0.2360159158706665
Batch 57/64 loss: 0.25861603021621704
Batch 58/64 loss: 0.25995779037475586
Batch 59/64 loss: 0.24248254299163818
Batch 60/64 loss: 0.24526244401931763
Batch 61/64 loss: 0.24505984783172607
Batch 62/64 loss: 0.2443699836730957
Batch 63/64 loss: 0.23963522911071777
Batch 64/64 loss: 0.24992692470550537
Epoch 314  Train loss: 0.24719331077500886  Val loss: 0.2839785054377264
Epoch 315
-------------------------------
Batch 1/64 loss: 0.24240589141845703
Batch 2/64 loss: 0.24184727668762207
Batch 3/64 loss: 0.2445858120918274
Batch 4/64 loss: 0.24672919511795044
Batch 5/64 loss: 0.26249802112579346
Batch 6/64 loss: 0.24450558423995972
Batch 7/64 loss: 0.24646949768066406
Batch 8/64 loss: 0.24756157398223877
Batch 9/64 loss: 0.2449260950088501
Batch 10/64 loss: 0.23916053771972656
Batch 11/64 loss: 0.24450194835662842
Batch 12/64 loss: 0.24583566188812256
Batch 13/64 loss: 0.24221020936965942
Batch 14/64 loss: 0.24189305305480957
Batch 15/64 loss: 0.25496137142181396
Batch 16/64 loss: 0.24711871147155762
Batch 17/64 loss: 0.24177885055541992
Batch 18/64 loss: 0.2358163595199585
Batch 19/64 loss: 0.24920541048049927
Batch 20/64 loss: 0.25031155347824097
Batch 21/64 loss: 0.24375247955322266
Batch 22/64 loss: 0.25057685375213623
Batch 23/64 loss: 0.24337369203567505
Batch 24/64 loss: 0.24563634395599365
Batch 25/64 loss: 0.24776709079742432
Batch 26/64 loss: 0.24572038650512695
Batch 27/64 loss: 0.24619966745376587
Batch 28/64 loss: 0.25433146953582764
Batch 29/64 loss: 0.24940192699432373
Batch 30/64 loss: 0.2589561939239502
Batch 31/64 loss: 0.24746102094650269
Batch 32/64 loss: 0.24878084659576416
Batch 33/64 loss: 0.24120020866394043
Batch 34/64 loss: 0.24937129020690918
Batch 35/64 loss: 0.24807751178741455
Batch 36/64 loss: 0.24874240159988403
Batch 37/64 loss: 0.24654412269592285
Batch 38/64 loss: 0.24415147304534912
Batch 39/64 loss: 0.2598074674606323
Batch 40/64 loss: 0.24146056175231934
Batch 41/64 loss: 0.2398066520690918
Batch 42/64 loss: 0.24294507503509521
Batch 43/64 loss: 0.24304461479187012
Batch 44/64 loss: 0.253603458404541
Batch 45/64 loss: 0.2479468584060669
Batch 46/64 loss: 0.23586905002593994
Batch 47/64 loss: 0.24333882331848145
Batch 48/64 loss: 0.2445439100265503
Batch 49/64 loss: 0.242814302444458
Batch 50/64 loss: 0.2437349557876587
Batch 51/64 loss: 0.24738550186157227
Batch 52/64 loss: 0.25481468439102173
Batch 53/64 loss: 0.24675703048706055
Batch 54/64 loss: 0.24808967113494873
Batch 55/64 loss: 0.25017452239990234
Batch 56/64 loss: 0.24863702058792114
Batch 57/64 loss: 0.24476200342178345
Batch 58/64 loss: 0.2518033981323242
Batch 59/64 loss: 0.2458704113960266
Batch 60/64 loss: 0.24376463890075684
Batch 61/64 loss: 0.2563343644142151
Batch 62/64 loss: 0.24966561794281006
Batch 63/64 loss: 0.2412501573562622
Batch 64/64 loss: 0.24732279777526855
Epoch 315  Train loss: 0.24671505011764228  Val loss: 0.28364210255776895
Epoch 316
-------------------------------
Batch 1/64 loss: 0.2497248649597168
Batch 2/64 loss: 0.24336659908294678
Batch 3/64 loss: 0.24478745460510254
Batch 4/64 loss: 0.26158320903778076
Batch 5/64 loss: 0.25899118185043335
Batch 6/64 loss: 0.24613094329833984
Batch 7/64 loss: 0.2440016269683838
Batch 8/64 loss: 0.2395094633102417
Batch 9/64 loss: 0.25798237323760986
Batch 10/64 loss: 0.2399057149887085
Batch 11/64 loss: 0.2505960464477539
Batch 12/64 loss: 0.2457747459411621
Batch 13/64 loss: 0.23819994926452637
Batch 14/64 loss: 0.24770933389663696
Batch 15/64 loss: 0.24759161472320557
Batch 16/64 loss: 0.2384580373764038
Batch 17/64 loss: 0.23614799976348877
Batch 18/64 loss: 0.25144433975219727
Batch 19/64 loss: 0.25018835067749023
Batch 20/64 loss: 0.24658358097076416
Batch 21/64 loss: 0.2343299388885498
Batch 22/64 loss: 0.25397205352783203
Batch 23/64 loss: 0.2559654712677002
Batch 24/64 loss: 0.25097382068634033
Batch 25/64 loss: 0.24500906467437744
Batch 26/64 loss: 0.24221396446228027
Batch 27/64 loss: 0.24544751644134521
Batch 28/64 loss: 0.24551761150360107
Batch 29/64 loss: 0.2443854808807373
Batch 30/64 loss: 0.24386221170425415
Batch 31/64 loss: 0.24374079704284668
Batch 32/64 loss: 0.24242734909057617
Batch 33/64 loss: 0.24584996700286865
Batch 34/64 loss: 0.24812638759613037
Batch 35/64 loss: 0.24215424060821533
Batch 36/64 loss: 0.24954068660736084
Batch 37/64 loss: 0.2539837956428528
Batch 38/64 loss: 0.2542693614959717
Batch 39/64 loss: 0.24393141269683838
Batch 40/64 loss: 0.24247276782989502
Batch 41/64 loss: 0.2420293092727661
Batch 42/64 loss: 0.24222242832183838
Batch 43/64 loss: 0.25092577934265137
Batch 44/64 loss: 0.25591182708740234
Batch 45/64 loss: 0.25171446800231934
Batch 46/64 loss: 0.2535865306854248
Batch 47/64 loss: 0.246027410030365
Batch 48/64 loss: 0.24522817134857178
Batch 49/64 loss: 0.24562382698059082
Batch 50/64 loss: 0.24387741088867188
Batch 51/64 loss: 0.25525766611099243
Batch 52/64 loss: 0.24513578414916992
Batch 53/64 loss: 0.24273598194122314
Batch 54/64 loss: 0.2592509388923645
Batch 55/64 loss: 0.24524998664855957
Batch 56/64 loss: 0.2483741044998169
Batch 57/64 loss: 0.2513155937194824
Batch 58/64 loss: 0.24688220024108887
Batch 59/64 loss: 0.2501904368400574
Batch 60/64 loss: 0.24085426330566406
Batch 61/64 loss: 0.23936718702316284
Batch 62/64 loss: 0.2568945288658142
Batch 63/64 loss: 0.2493240237236023
Batch 64/64 loss: 0.24454432725906372
Epoch 316  Train loss: 0.2471880695399116  Val loss: 0.2830603798640143
Epoch 317
-------------------------------
Batch 1/64 loss: 0.25910937786102295
Batch 2/64 loss: 0.24391329288482666
Batch 3/64 loss: 0.24540168046951294
Batch 4/64 loss: 0.25020575523376465
Batch 5/64 loss: 0.23663592338562012
Batch 6/64 loss: 0.24589145183563232
Batch 7/64 loss: 0.2415449023246765
Batch 8/64 loss: 0.24581003189086914
Batch 9/64 loss: 0.24205756187438965
Batch 10/64 loss: 0.24429553747177124
Batch 11/64 loss: 0.24524295330047607
Batch 12/64 loss: 0.24713706970214844
Batch 13/64 loss: 0.23962974548339844
Batch 14/64 loss: 0.2543099522590637
Batch 15/64 loss: 0.24312007427215576
Batch 16/64 loss: 0.24959796667099
Batch 17/64 loss: 0.24289989471435547
Batch 18/64 loss: 0.24352437257766724
Batch 19/64 loss: 0.2546471357345581
Batch 20/64 loss: 0.23709046840667725
Batch 21/64 loss: 0.24863088130950928
Batch 22/64 loss: 0.2509121298789978
Batch 23/64 loss: 0.24081504344940186
Batch 24/64 loss: 0.24256563186645508
Batch 25/64 loss: 0.24834716320037842
Batch 26/64 loss: 0.25061655044555664
Batch 27/64 loss: 0.24267041683197021
Batch 28/64 loss: 0.2344365119934082
Batch 29/64 loss: 0.25143396854400635
Batch 30/64 loss: 0.24503934383392334
Batch 31/64 loss: 0.23845553398132324
Batch 32/64 loss: 0.2584860324859619
Batch 33/64 loss: 0.24633830785751343
Batch 34/64 loss: 0.24406564235687256
Batch 35/64 loss: 0.24921905994415283
Batch 36/64 loss: 0.24631285667419434
Batch 37/64 loss: 0.23443841934204102
Batch 38/64 loss: 0.24945437908172607
Batch 39/64 loss: 0.24396038055419922
Batch 40/64 loss: 0.24700725078582764
Batch 41/64 loss: 0.24483132362365723
Batch 42/64 loss: 0.24010080099105835
Batch 43/64 loss: 0.24301862716674805
Batch 44/64 loss: 0.24320602416992188
Batch 45/64 loss: 0.24785268306732178
Batch 46/64 loss: 0.24352622032165527
Batch 47/64 loss: 0.25215619802474976
Batch 48/64 loss: 0.2459195852279663
Batch 49/64 loss: 0.2553877830505371
Batch 50/64 loss: 0.24558210372924805
Batch 51/64 loss: 0.25042492151260376
Batch 52/64 loss: 0.24055325984954834
Batch 53/64 loss: 0.2418508529663086
Batch 54/64 loss: 0.23841476440429688
Batch 55/64 loss: 0.25008541345596313
Batch 56/64 loss: 0.2544689178466797
Batch 57/64 loss: 0.2502017021179199
Batch 58/64 loss: 0.25459790229797363
Batch 59/64 loss: 0.2535037398338318
Batch 60/64 loss: 0.24871498346328735
Batch 61/64 loss: 0.25234389305114746
Batch 62/64 loss: 0.2458571195602417
Batch 63/64 loss: 0.25568389892578125
Batch 64/64 loss: 0.24813926219940186
Epoch 317  Train loss: 0.24642600498947442  Val loss: 0.2832712979660821
Epoch 318
-------------------------------
Batch 1/64 loss: 0.23889034986495972
Batch 2/64 loss: 0.24166083335876465
Batch 3/64 loss: 0.2560425400733948
Batch 4/64 loss: 0.24068880081176758
Batch 5/64 loss: 0.24936383962631226
Batch 6/64 loss: 0.23589515686035156
Batch 7/64 loss: 0.23571211099624634
Batch 8/64 loss: 0.24806785583496094
Batch 9/64 loss: 0.2508922815322876
Batch 10/64 loss: 0.24860602617263794
Batch 11/64 loss: 0.2442590594291687
Batch 12/64 loss: 0.25247085094451904
Batch 13/64 loss: 0.245339035987854
Batch 14/64 loss: 0.25490057468414307
Batch 15/64 loss: 0.2475927472114563
Batch 16/64 loss: 0.23886334896087646
Batch 17/64 loss: 0.25349563360214233
Batch 18/64 loss: 0.2466028928756714
Batch 19/64 loss: 0.24404913187026978
Batch 20/64 loss: 0.2569977641105652
Batch 21/64 loss: 0.24511992931365967
Batch 22/64 loss: 0.25492799282073975
Batch 23/64 loss: 0.24817359447479248
Batch 24/64 loss: 0.2442227005958557
Batch 25/64 loss: 0.2439357042312622
Batch 26/64 loss: 0.24756908416748047
Batch 27/64 loss: 0.24894654750823975
Batch 28/64 loss: 0.2477148175239563
Batch 29/64 loss: 0.2558249831199646
Batch 30/64 loss: 0.24657851457595825
Batch 31/64 loss: 0.24305039644241333
Batch 32/64 loss: 0.255157470703125
Batch 33/64 loss: 0.25247734785079956
Batch 34/64 loss: 0.2507966160774231
Batch 35/64 loss: 0.24418151378631592
Batch 36/64 loss: 0.2476453185081482
Batch 37/64 loss: 0.24540752172470093
Batch 38/64 loss: 0.24140024185180664
Batch 39/64 loss: 0.2442328929901123
Batch 40/64 loss: 0.24296963214874268
Batch 41/64 loss: 0.24576646089553833
Batch 42/64 loss: 0.2409982681274414
Batch 43/64 loss: 0.24293941259384155
Batch 44/64 loss: 0.2461339831352234
Batch 45/64 loss: 0.2526050806045532
Batch 46/64 loss: 0.2517350912094116
Batch 47/64 loss: 0.259454607963562
Batch 48/64 loss: 0.25426363945007324
Batch 49/64 loss: 0.2529534697532654
Batch 50/64 loss: 0.25047677755355835
Batch 51/64 loss: 0.23584413528442383
Batch 52/64 loss: 0.2470187544822693
Batch 53/64 loss: 0.2486790418624878
Batch 54/64 loss: 0.2520592212677002
Batch 55/64 loss: 0.24354207515716553
Batch 56/64 loss: 0.2512941360473633
Batch 57/64 loss: 0.25126194953918457
Batch 58/64 loss: 0.24374258518218994
Batch 59/64 loss: 0.25551462173461914
Batch 60/64 loss: 0.24696111679077148
Batch 61/64 loss: 0.23928558826446533
Batch 62/64 loss: 0.24300521612167358
Batch 63/64 loss: 0.23508858680725098
Batch 64/64 loss: 0.2451242208480835
Epoch 318  Train loss: 0.2471402453441246  Val loss: 0.28334726398343485
Epoch 319
-------------------------------
Batch 1/64 loss: 0.24634230136871338
Batch 2/64 loss: 0.23847484588623047
Batch 3/64 loss: 0.24009943008422852
Batch 4/64 loss: 0.23832029104232788
Batch 5/64 loss: 0.24058473110198975
Batch 6/64 loss: 0.23647558689117432
Batch 7/64 loss: 0.2480250597000122
Batch 8/64 loss: 0.2471948266029358
Batch 9/64 loss: 0.24909353256225586
Batch 10/64 loss: 0.246593177318573
Batch 11/64 loss: 0.2432652711868286
Batch 12/64 loss: 0.248931884765625
Batch 13/64 loss: 0.25022685527801514
Batch 14/64 loss: 0.24409842491149902
Batch 15/64 loss: 0.24222326278686523
Batch 16/64 loss: 0.255024790763855
Batch 17/64 loss: 0.2489532232284546
Batch 18/64 loss: 0.2394024133682251
Batch 19/64 loss: 0.25542449951171875
Batch 20/64 loss: 0.24769628047943115
Batch 21/64 loss: 0.2440629005432129
Batch 22/64 loss: 0.23573029041290283
Batch 23/64 loss: 0.2493497133255005
Batch 24/64 loss: 0.24271994829177856
Batch 25/64 loss: 0.25601333379745483
Batch 26/64 loss: 0.24346500635147095
Batch 27/64 loss: 0.2560268044471741
Batch 28/64 loss: 0.25474679470062256
Batch 29/64 loss: 0.24383443593978882
Batch 30/64 loss: 0.24321556091308594
Batch 31/64 loss: 0.2512936592102051
Batch 32/64 loss: 0.2445310354232788
Batch 33/64 loss: 0.23774707317352295
Batch 34/64 loss: 0.2379804253578186
Batch 35/64 loss: 0.24228262901306152
Batch 36/64 loss: 0.24169576168060303
Batch 37/64 loss: 0.24150961637496948
Batch 38/64 loss: 0.2480839490890503
Batch 39/64 loss: 0.24517369270324707
Batch 40/64 loss: 0.2533634305000305
Batch 41/64 loss: 0.2432115077972412
Batch 42/64 loss: 0.25090253353118896
Batch 43/64 loss: 0.2491135597229004
Batch 44/64 loss: 0.2505459785461426
Batch 45/64 loss: 0.24696648120880127
Batch 46/64 loss: 0.24086260795593262
Batch 47/64 loss: 0.24685972929000854
Batch 48/64 loss: 0.2522512674331665
Batch 49/64 loss: 0.26391512155532837
Batch 50/64 loss: 0.24655210971832275
Batch 51/64 loss: 0.23702669143676758
Batch 52/64 loss: 0.24958574771881104
Batch 53/64 loss: 0.24240761995315552
Batch 54/64 loss: 0.2538125514984131
Batch 55/64 loss: 0.2450120449066162
Batch 56/64 loss: 0.24244320392608643
Batch 57/64 loss: 0.2445152997970581
Batch 58/64 loss: 0.24362599849700928
Batch 59/64 loss: 0.24565154314041138
Batch 60/64 loss: 0.2489912509918213
Batch 61/64 loss: 0.2504684329032898
Batch 62/64 loss: 0.24835747480392456
Batch 63/64 loss: 0.2577413320541382
Batch 64/64 loss: 0.24535834789276123
Epoch 319  Train loss: 0.2463390682257858  Val loss: 0.2839620350972074
Epoch 320
-------------------------------
Batch 1/64 loss: 0.25169193744659424
Batch 2/64 loss: 0.2404564619064331
Batch 3/64 loss: 0.24703311920166016
Batch 4/64 loss: 0.25216323137283325
Batch 5/64 loss: 0.25575393438339233
Batch 6/64 loss: 0.24187737703323364
Batch 7/64 loss: 0.24639427661895752
Batch 8/64 loss: 0.25010472536087036
Batch 9/64 loss: 0.24243974685668945
Batch 10/64 loss: 0.2541006803512573
Batch 11/64 loss: 0.25469446182250977
Batch 12/64 loss: 0.2399802803993225
Batch 13/64 loss: 0.24784135818481445
Batch 14/64 loss: 0.2509641647338867
Batch 15/64 loss: 0.24989330768585205
Batch 16/64 loss: 0.2504269480705261
Batch 17/64 loss: 0.2575439214706421
Batch 18/64 loss: 0.23811805248260498
Batch 19/64 loss: 0.24991774559020996
Batch 20/64 loss: 0.24489688873291016
Batch 21/64 loss: 0.24116140604019165
Batch 22/64 loss: 0.23545384407043457
Batch 23/64 loss: 0.24990582466125488
Batch 24/64 loss: 0.23858749866485596
Batch 25/64 loss: 0.24045133590698242
Batch 26/64 loss: 0.24228352308273315
Batch 27/64 loss: 0.24277019500732422
Batch 28/64 loss: 0.2528003454208374
Batch 29/64 loss: 0.24417918920516968
Batch 30/64 loss: 0.23990583419799805
Batch 31/64 loss: 0.24857491254806519
Batch 32/64 loss: 0.25655317306518555
Batch 33/64 loss: 0.2473323941230774
Batch 34/64 loss: 0.2529876232147217
Batch 35/64 loss: 0.2472836971282959
Batch 36/64 loss: 0.25159525871276855
Batch 37/64 loss: 0.23909473419189453
Batch 38/64 loss: 0.2417917251586914
Batch 39/64 loss: 0.23861682415008545
Batch 40/64 loss: 0.24991071224212646
Batch 41/64 loss: 0.24623215198516846
Batch 42/64 loss: 0.25513648986816406
Batch 43/64 loss: 0.24236279726028442
Batch 44/64 loss: 0.24239397048950195
Batch 45/64 loss: 0.2522435188293457
Batch 46/64 loss: 0.24356353282928467
Batch 47/64 loss: 0.24160116910934448
Batch 48/64 loss: 0.2509136199951172
Batch 49/64 loss: 0.24637854099273682
Batch 50/64 loss: 0.24829798936843872
Batch 51/64 loss: 0.257196307182312
Batch 52/64 loss: 0.24962538480758667
Batch 53/64 loss: 0.2450963258743286
Batch 54/64 loss: 0.2436659336090088
Batch 55/64 loss: 0.2512187957763672
Batch 56/64 loss: 0.24145996570587158
Batch 57/64 loss: 0.24563217163085938
Batch 58/64 loss: 0.23910963535308838
Batch 59/64 loss: 0.236841082572937
Batch 60/64 loss: 0.25210946798324585
Batch 61/64 loss: 0.25663745403289795
Batch 62/64 loss: 0.24989062547683716
Batch 63/64 loss: 0.24733245372772217
Batch 64/64 loss: 0.2535346746444702
Epoch 320  Train loss: 0.24694310683830112  Val loss: 0.2826407234283657
Epoch 321
-------------------------------
Batch 1/64 loss: 0.25257784128189087
Batch 2/64 loss: 0.2556569576263428
Batch 3/64 loss: 0.24356120824813843
Batch 4/64 loss: 0.2406754493713379
Batch 5/64 loss: 0.22972822189331055
Batch 6/64 loss: 0.24425148963928223
Batch 7/64 loss: 0.24155724048614502
Batch 8/64 loss: 0.25221025943756104
Batch 9/64 loss: 0.23908227682113647
Batch 10/64 loss: 0.24178671836853027
Batch 11/64 loss: 0.2438790202140808
Batch 12/64 loss: 0.2438981533050537
Batch 13/64 loss: 0.25167661905288696
Batch 14/64 loss: 0.24445706605911255
Batch 15/64 loss: 0.23596560955047607
Batch 16/64 loss: 0.24922913312911987
Batch 17/64 loss: 0.2518954873085022
Batch 18/64 loss: 0.26240503787994385
Batch 19/64 loss: 0.24334609508514404
Batch 20/64 loss: 0.2524658441543579
Batch 21/64 loss: 0.26445698738098145
Batch 22/64 loss: 0.2545918822288513
Batch 23/64 loss: 0.24746859073638916
Batch 24/64 loss: 0.23869657516479492
Batch 25/64 loss: 0.24465954303741455
Batch 26/64 loss: 0.2409200668334961
Batch 27/64 loss: 0.23937582969665527
Batch 28/64 loss: 0.24112403392791748
Batch 29/64 loss: 0.2444385290145874
Batch 30/64 loss: 0.2490546703338623
Batch 31/64 loss: 0.23637771606445312
Batch 32/64 loss: 0.23840737342834473
Batch 33/64 loss: 0.24790716171264648
Batch 34/64 loss: 0.24953198432922363
Batch 35/64 loss: 0.23646175861358643
Batch 36/64 loss: 0.23359858989715576
Batch 37/64 loss: 0.2430579662322998
Batch 38/64 loss: 0.24117231369018555
Batch 39/64 loss: 0.242933988571167
Batch 40/64 loss: 0.2516549825668335
Batch 41/64 loss: 0.2467130422592163
Batch 42/64 loss: 0.25524091720581055
Batch 43/64 loss: 0.2457280158996582
Batch 44/64 loss: 0.24409425258636475
Batch 45/64 loss: 0.26059526205062866
Batch 46/64 loss: 0.24206358194351196
Batch 47/64 loss: 0.24757426977157593
Batch 48/64 loss: 0.25286126136779785
Batch 49/64 loss: 0.2530220150947571
Batch 50/64 loss: 0.24108803272247314
Batch 51/64 loss: 0.2480531930923462
Batch 52/64 loss: 0.23875212669372559
Batch 53/64 loss: 0.24485540390014648
Batch 54/64 loss: 0.2508034110069275
Batch 55/64 loss: 0.24648910760879517
Batch 56/64 loss: 0.24677681922912598
Batch 57/64 loss: 0.24806690216064453
Batch 58/64 loss: 0.2489193081855774
Batch 59/64 loss: 0.25156253576278687
Batch 60/64 loss: 0.24859440326690674
Batch 61/64 loss: 0.24375402927398682
Batch 62/64 loss: 0.24930953979492188
Batch 63/64 loss: 0.2479323148727417
Batch 64/64 loss: 0.25333505868911743
Epoch 321  Train loss: 0.24625956568063473  Val loss: 0.28247708389439535
Saving best model, epoch: 321
Epoch 322
-------------------------------
Batch 1/64 loss: 0.2449890375137329
Batch 2/64 loss: 0.24892771244049072
Batch 3/64 loss: 0.24024724960327148
Batch 4/64 loss: 0.25149744749069214
Batch 5/64 loss: 0.24300938844680786
Batch 6/64 loss: 0.2496335506439209
Batch 7/64 loss: 0.24251031875610352
Batch 8/64 loss: 0.24989545345306396
Batch 9/64 loss: 0.2410421371459961
Batch 10/64 loss: 0.24646210670471191
Batch 11/64 loss: 0.23885571956634521
Batch 12/64 loss: 0.25071191787719727
Batch 13/64 loss: 0.24212145805358887
Batch 14/64 loss: 0.23693645000457764
Batch 15/64 loss: 0.2482055425643921
Batch 16/64 loss: 0.2409346103668213
Batch 17/64 loss: 0.24462825059890747
Batch 18/64 loss: 0.24659287929534912
Batch 19/64 loss: 0.2485567331314087
Batch 20/64 loss: 0.24227994680404663
Batch 21/64 loss: 0.24055218696594238
Batch 22/64 loss: 0.24694204330444336
Batch 23/64 loss: 0.2521059513092041
Batch 24/64 loss: 0.24274933338165283
Batch 25/64 loss: 0.26120972633361816
Batch 26/64 loss: 0.2577928304672241
Batch 27/64 loss: 0.2361944317817688
Batch 28/64 loss: 0.2423868179321289
Batch 29/64 loss: 0.24459826946258545
Batch 30/64 loss: 0.251206636428833
Batch 31/64 loss: 0.23688644170761108
Batch 32/64 loss: 0.24131685495376587
Batch 33/64 loss: 0.2516169548034668
Batch 34/64 loss: 0.24574458599090576
Batch 35/64 loss: 0.24273061752319336
Batch 36/64 loss: 0.25166547298431396
Batch 37/64 loss: 0.24104726314544678
Batch 38/64 loss: 0.2442670464515686
Batch 39/64 loss: 0.24293935298919678
Batch 40/64 loss: 0.24403101205825806
Batch 41/64 loss: 0.2475525140762329
Batch 42/64 loss: 0.23760056495666504
Batch 43/64 loss: 0.23899966478347778
Batch 44/64 loss: 0.2460312843322754
Batch 45/64 loss: 0.268096387386322
Batch 46/64 loss: 0.23962277173995972
Batch 47/64 loss: 0.25099581480026245
Batch 48/64 loss: 0.25544512271881104
Batch 49/64 loss: 0.25251150131225586
Batch 50/64 loss: 0.2482907772064209
Batch 51/64 loss: 0.25314831733703613
Batch 52/64 loss: 0.2614744305610657
Batch 53/64 loss: 0.244185209274292
Batch 54/64 loss: 0.24659311771392822
Batch 55/64 loss: 0.255038857460022
Batch 56/64 loss: 0.25186991691589355
Batch 57/64 loss: 0.2527869939804077
Batch 58/64 loss: 0.24791193008422852
Batch 59/64 loss: 0.24745804071426392
Batch 60/64 loss: 0.24139869213104248
Batch 61/64 loss: 0.23815810680389404
Batch 62/64 loss: 0.2571674585342407
Batch 63/64 loss: 0.2591874599456787
Batch 64/64 loss: 0.24394440650939941
Epoch 322  Train loss: 0.24690988204058478  Val loss: 0.282802222725452
Epoch 323
-------------------------------
Batch 1/64 loss: 0.26002418994903564
Batch 2/64 loss: 0.25027042627334595
Batch 3/64 loss: 0.24311745166778564
Batch 4/64 loss: 0.2379469871520996
Batch 5/64 loss: 0.24465423822402954
Batch 6/64 loss: 0.2466031312942505
Batch 7/64 loss: 0.2443007230758667
Batch 8/64 loss: 0.2358459234237671
Batch 9/64 loss: 0.2605811357498169
Batch 10/64 loss: 0.24403691291809082
Batch 11/64 loss: 0.24539810419082642
Batch 12/64 loss: 0.2486940622329712
Batch 13/64 loss: 0.23674839735031128
Batch 14/64 loss: 0.25149768590927124
Batch 15/64 loss: 0.24530529975891113
Batch 16/64 loss: 0.2504451274871826
Batch 17/64 loss: 0.2493422031402588
Batch 18/64 loss: 0.2408137321472168
Batch 19/64 loss: 0.25059205293655396
Batch 20/64 loss: 0.24251198768615723
Batch 21/64 loss: 0.23976284265518188
Batch 22/64 loss: 0.23877650499343872
Batch 23/64 loss: 0.2513757348060608
Batch 24/64 loss: 0.2390526533126831
Batch 25/64 loss: 0.2521336078643799
Batch 26/64 loss: 0.2552032470703125
Batch 27/64 loss: 0.24497640132904053
Batch 28/64 loss: 0.24175453186035156
Batch 29/64 loss: 0.23700928688049316
Batch 30/64 loss: 0.24582695960998535
Batch 31/64 loss: 0.25332891941070557
Batch 32/64 loss: 0.2370375394821167
Batch 33/64 loss: 0.24885547161102295
Batch 34/64 loss: 0.2456766963005066
Batch 35/64 loss: 0.2511611580848694
Batch 36/64 loss: 0.24982798099517822
Batch 37/64 loss: 0.24876618385314941
Batch 38/64 loss: 0.24398553371429443
Batch 39/64 loss: 0.2430950403213501
Batch 40/64 loss: 0.24465018510818481
Batch 41/64 loss: 0.24871587753295898
Batch 42/64 loss: 0.24305903911590576
Batch 43/64 loss: 0.2446882724761963
Batch 44/64 loss: 0.24862539768218994
Batch 45/64 loss: 0.2520819902420044
Batch 46/64 loss: 0.23980724811553955
Batch 47/64 loss: 0.23768174648284912
Batch 48/64 loss: 0.24400436878204346
Batch 49/64 loss: 0.2530210018157959
Batch 50/64 loss: 0.247966468334198
Batch 51/64 loss: 0.2545846700668335
Batch 52/64 loss: 0.25025272369384766
Batch 53/64 loss: 0.2527647018432617
Batch 54/64 loss: 0.2393040657043457
Batch 55/64 loss: 0.23938071727752686
Batch 56/64 loss: 0.24588459730148315
Batch 57/64 loss: 0.2414739727973938
Batch 58/64 loss: 0.2513386011123657
Batch 59/64 loss: 0.24113929271697998
Batch 60/64 loss: 0.2566600441932678
Batch 61/64 loss: 0.24363863468170166
Batch 62/64 loss: 0.24290823936462402
Batch 63/64 loss: 0.2392423152923584
Batch 64/64 loss: 0.2500077486038208
Epoch 323  Train loss: 0.24606613411622888  Val loss: 0.284325990480246
Epoch 324
-------------------------------
Batch 1/64 loss: 0.2485826015472412
Batch 2/64 loss: 0.25317472219467163
Batch 3/64 loss: 0.24626076221466064
Batch 4/64 loss: 0.253836989402771
Batch 5/64 loss: 0.24259477853775024
Batch 6/64 loss: 0.25360727310180664
Batch 7/64 loss: 0.2525521516799927
Batch 8/64 loss: 0.2523980140686035
Batch 9/64 loss: 0.23811781406402588
Batch 10/64 loss: 0.24619722366333008
Batch 11/64 loss: 0.23558777570724487
Batch 12/64 loss: 0.2596231698989868
Batch 13/64 loss: 0.24721759557724
Batch 14/64 loss: 0.2404460906982422
Batch 15/64 loss: 0.24175190925598145
Batch 16/64 loss: 0.24408239126205444
Batch 17/64 loss: 0.25424909591674805
Batch 18/64 loss: 0.24441111087799072
Batch 19/64 loss: 0.24461698532104492
Batch 20/64 loss: 0.24032235145568848
Batch 21/64 loss: 0.23873603343963623
Batch 22/64 loss: 0.24402141571044922
Batch 23/64 loss: 0.2404589056968689
Batch 24/64 loss: 0.24808108806610107
Batch 25/64 loss: 0.2422754168510437
Batch 26/64 loss: 0.24165022373199463
Batch 27/64 loss: 0.24208956956863403
Batch 28/64 loss: 0.2550760507583618
Batch 29/64 loss: 0.2435460090637207
Batch 30/64 loss: 0.25036144256591797
Batch 31/64 loss: 0.2464503049850464
Batch 32/64 loss: 0.2460317611694336
Batch 33/64 loss: 0.24054360389709473
Batch 34/64 loss: 0.2589460611343384
Batch 35/64 loss: 0.2447243332862854
Batch 36/64 loss: 0.25239408016204834
Batch 37/64 loss: 0.24303436279296875
Batch 38/64 loss: 0.24453413486480713
Batch 39/64 loss: 0.25406575202941895
Batch 40/64 loss: 0.2425099015235901
Batch 41/64 loss: 0.24895644187927246
Batch 42/64 loss: 0.2413514256477356
Batch 43/64 loss: 0.24079036712646484
Batch 44/64 loss: 0.24034589529037476
Batch 45/64 loss: 0.2450176477432251
Batch 46/64 loss: 0.23770397901535034
Batch 47/64 loss: 0.24143457412719727
Batch 48/64 loss: 0.2553905248641968
Batch 49/64 loss: 0.23574316501617432
Batch 50/64 loss: 0.24651753902435303
Batch 51/64 loss: 0.24444115161895752
Batch 52/64 loss: 0.25511276721954346
Batch 53/64 loss: 0.24542951583862305
Batch 54/64 loss: 0.2566438913345337
Batch 55/64 loss: 0.25031089782714844
Batch 56/64 loss: 0.25172245502471924
Batch 57/64 loss: 0.24348461627960205
Batch 58/64 loss: 0.24217045307159424
Batch 59/64 loss: 0.2486647367477417
Batch 60/64 loss: 0.2391262650489807
Batch 61/64 loss: 0.2509016990661621
Batch 62/64 loss: 0.24378257989883423
Batch 63/64 loss: 0.2404862642288208
Batch 64/64 loss: 0.2502014636993408
Epoch 324  Train loss: 0.24615437189737957  Val loss: 0.2824236746506183
Saving best model, epoch: 324
Epoch 325
-------------------------------
Batch 1/64 loss: 0.2367687225341797
Batch 2/64 loss: 0.23229974508285522
Batch 3/64 loss: 0.24487543106079102
Batch 4/64 loss: 0.24080675840377808
Batch 5/64 loss: 0.2417440414428711
Batch 6/64 loss: 0.23549914360046387
Batch 7/64 loss: 0.23735028505325317
Batch 8/64 loss: 0.2395806908607483
Batch 9/64 loss: 0.24833524227142334
Batch 10/64 loss: 0.25108444690704346
Batch 11/64 loss: 0.24065732955932617
Batch 12/64 loss: 0.2437812089920044
Batch 13/64 loss: 0.24311494827270508
Batch 14/64 loss: 0.24088072776794434
Batch 15/64 loss: 0.24512863159179688
Batch 16/64 loss: 0.2515103816986084
Batch 17/64 loss: 0.261244535446167
Batch 18/64 loss: 0.24983352422714233
Batch 19/64 loss: 0.24803274869918823
Batch 20/64 loss: 0.2456669807434082
Batch 21/64 loss: 0.250421404838562
Batch 22/64 loss: 0.24743711948394775
Batch 23/64 loss: 0.24906504154205322
Batch 24/64 loss: 0.25224852561950684
Batch 25/64 loss: 0.24004268646240234
Batch 26/64 loss: 0.23471444845199585
Batch 27/64 loss: 0.24582350254058838
Batch 28/64 loss: 0.2456289529800415
Batch 29/64 loss: 0.2367846965789795
Batch 30/64 loss: 0.24941343069076538
Batch 31/64 loss: 0.23653048276901245
Batch 32/64 loss: 0.24439704418182373
Batch 33/64 loss: 0.2394850254058838
Batch 34/64 loss: 0.24604058265686035
Batch 35/64 loss: 0.24933278560638428
Batch 36/64 loss: 0.2517726421356201
Batch 37/64 loss: 0.2532297372817993
Batch 38/64 loss: 0.25014030933380127
Batch 39/64 loss: 0.24737727642059326
Batch 40/64 loss: 0.2482999563217163
Batch 41/64 loss: 0.2474195957183838
Batch 42/64 loss: 0.247453510761261
Batch 43/64 loss: 0.2588549852371216
Batch 44/64 loss: 0.24708116054534912
Batch 45/64 loss: 0.24181914329528809
Batch 46/64 loss: 0.2444523572921753
Batch 47/64 loss: 0.2501654624938965
Batch 48/64 loss: 0.24393272399902344
Batch 49/64 loss: 0.2568156123161316
Batch 50/64 loss: 0.25034308433532715
Batch 51/64 loss: 0.24049782752990723
Batch 52/64 loss: 0.2533274292945862
Batch 53/64 loss: 0.24093222618103027
Batch 54/64 loss: 0.24951553344726562
Batch 55/64 loss: 0.2510445713996887
Batch 56/64 loss: 0.25155192613601685
Batch 57/64 loss: 0.2390105128288269
Batch 58/64 loss: 0.23296523094177246
Batch 59/64 loss: 0.2419571876525879
Batch 60/64 loss: 0.24588477611541748
Batch 61/64 loss: 0.2586040496826172
Batch 62/64 loss: 0.248726487159729
Batch 63/64 loss: 0.24485445022583008
Batch 64/64 loss: 0.2530195713043213
Epoch 325  Train loss: 0.24585655997781192  Val loss: 0.28355559000034924
Epoch 326
-------------------------------
Batch 1/64 loss: 0.23896276950836182
Batch 2/64 loss: 0.2493266463279724
Batch 3/64 loss: 0.24536508321762085
Batch 4/64 loss: 0.24950659275054932
Batch 5/64 loss: 0.24717724323272705
Batch 6/64 loss: 0.242079496383667
Batch 7/64 loss: 0.24664545059204102
Batch 8/64 loss: 0.2435407042503357
Batch 9/64 loss: 0.2485448122024536
Batch 10/64 loss: 0.2564471960067749
Batch 11/64 loss: 0.2487114667892456
Batch 12/64 loss: 0.24155265092849731
Batch 13/64 loss: 0.23853802680969238
Batch 14/64 loss: 0.24326848983764648
Batch 15/64 loss: 0.24428462982177734
Batch 16/64 loss: 0.2403385043144226
Batch 17/64 loss: 0.24084937572479248
Batch 18/64 loss: 0.24740540981292725
Batch 19/64 loss: 0.23476147651672363
Batch 20/64 loss: 0.24069815874099731
Batch 21/64 loss: 0.2436351180076599
Batch 22/64 loss: 0.25319409370422363
Batch 23/64 loss: 0.23886817693710327
Batch 24/64 loss: 0.24275636672973633
Batch 25/64 loss: 0.24142158031463623
Batch 26/64 loss: 0.2399592399597168
Batch 27/64 loss: 0.24135684967041016
Batch 28/64 loss: 0.24785637855529785
Batch 29/64 loss: 0.24725693464279175
Batch 30/64 loss: 0.24229371547698975
Batch 31/64 loss: 0.24213212728500366
Batch 32/64 loss: 0.24076956510543823
Batch 33/64 loss: 0.24894660711288452
Batch 34/64 loss: 0.24916422367095947
Batch 35/64 loss: 0.24327605962753296
Batch 36/64 loss: 0.24319052696228027
Batch 37/64 loss: 0.24229657649993896
Batch 38/64 loss: 0.24849337339401245
Batch 39/64 loss: 0.23436039686203003
Batch 40/64 loss: 0.2521643042564392
Batch 41/64 loss: 0.24297654628753662
Batch 42/64 loss: 0.24190056324005127
Batch 43/64 loss: 0.24531060457229614
Batch 44/64 loss: 0.2471226453781128
Batch 45/64 loss: 0.2413831353187561
Batch 46/64 loss: 0.24298596382141113
Batch 47/64 loss: 0.2410721778869629
Batch 48/64 loss: 0.2417939305305481
Batch 49/64 loss: 0.2528766393661499
Batch 50/64 loss: 0.2441025972366333
Batch 51/64 loss: 0.24781107902526855
Batch 52/64 loss: 0.24888622760772705
Batch 53/64 loss: 0.2418893575668335
Batch 54/64 loss: 0.24859803915023804
Batch 55/64 loss: 0.24731802940368652
Batch 56/64 loss: 0.24516081809997559
Batch 57/64 loss: 0.2432553768157959
Batch 58/64 loss: 0.2469770908355713
Batch 59/64 loss: 0.2516475319862366
Batch 60/64 loss: 0.24609267711639404
Batch 61/64 loss: 0.2529860734939575
Batch 62/64 loss: 0.25069868564605713
Batch 63/64 loss: 0.2664400339126587
Batch 64/64 loss: 0.24127918481826782
Epoch 326  Train loss: 0.24520222135618622  Val loss: 0.2835415624261312
Epoch 327
-------------------------------
Batch 1/64 loss: 0.25486499071121216
Batch 2/64 loss: 0.24368536472320557
Batch 3/64 loss: 0.23734349012374878
Batch 4/64 loss: 0.2485896348953247
Batch 5/64 loss: 0.24924039840698242
Batch 6/64 loss: 0.24610477685928345
Batch 7/64 loss: 0.2427656650543213
Batch 8/64 loss: 0.2410181164741516
Batch 9/64 loss: 0.2409510612487793
Batch 10/64 loss: 0.25202643871307373
Batch 11/64 loss: 0.24058938026428223
Batch 12/64 loss: 0.2484738826751709
Batch 13/64 loss: 0.24280816316604614
Batch 14/64 loss: 0.24989908933639526
Batch 15/64 loss: 0.23918819427490234
Batch 16/64 loss: 0.2503819465637207
Batch 17/64 loss: 0.24813944101333618
Batch 18/64 loss: 0.23920893669128418
Batch 19/64 loss: 0.25539612770080566
Batch 20/64 loss: 0.24075734615325928
Batch 21/64 loss: 0.2408658266067505
Batch 22/64 loss: 0.2468966245651245
Batch 23/64 loss: 0.25256073474884033
Batch 24/64 loss: 0.24966371059417725
Batch 25/64 loss: 0.2442982792854309
Batch 26/64 loss: 0.2472345232963562
Batch 27/64 loss: 0.2462003231048584
Batch 28/64 loss: 0.23795479536056519
Batch 29/64 loss: 0.2387201189994812
Batch 30/64 loss: 0.24419498443603516
Batch 31/64 loss: 0.23878848552703857
Batch 32/64 loss: 0.25516629219055176
Batch 33/64 loss: 0.25487351417541504
Batch 34/64 loss: 0.2515125870704651
Batch 35/64 loss: 0.2478998899459839
Batch 36/64 loss: 0.2469174861907959
Batch 37/64 loss: 0.2508462071418762
Batch 38/64 loss: 0.246901273727417
Batch 39/64 loss: 0.24524718523025513
Batch 40/64 loss: 0.241347074508667
Batch 41/64 loss: 0.23443615436553955
Batch 42/64 loss: 0.23853814601898193
Batch 43/64 loss: 0.2466784119606018
Batch 44/64 loss: 0.24931234121322632
Batch 45/64 loss: 0.24787664413452148
Batch 46/64 loss: 0.2546755075454712
Batch 47/64 loss: 0.2554762363433838
Batch 48/64 loss: 0.24937808513641357
Batch 49/64 loss: 0.24363726377487183
Batch 50/64 loss: 0.24497175216674805
Batch 51/64 loss: 0.24714958667755127
Batch 52/64 loss: 0.24215173721313477
Batch 53/64 loss: 0.23743712902069092
Batch 54/64 loss: 0.2555520534515381
Batch 55/64 loss: 0.24019145965576172
Batch 56/64 loss: 0.2517324686050415
Batch 57/64 loss: 0.24198400974273682
Batch 58/64 loss: 0.24519866704940796
Batch 59/64 loss: 0.24231523275375366
Batch 60/64 loss: 0.24395287036895752
Batch 61/64 loss: 0.24778294563293457
Batch 62/64 loss: 0.2345292568206787
Batch 63/64 loss: 0.25016850233078003
Batch 64/64 loss: 0.24894076585769653
Epoch 327  Train loss: 0.24582516702951168  Val loss: 0.2833254103808059
Epoch 328
-------------------------------
Batch 1/64 loss: 0.24033725261688232
Batch 2/64 loss: 0.23445665836334229
Batch 3/64 loss: 0.2518908977508545
Batch 4/64 loss: 0.2529160976409912
Batch 5/64 loss: 0.24633145332336426
Batch 6/64 loss: 0.24594640731811523
Batch 7/64 loss: 0.2515334486961365
Batch 8/64 loss: 0.25292593240737915
Batch 9/64 loss: 0.24762052297592163
Batch 10/64 loss: 0.24912488460540771
Batch 11/64 loss: 0.24396741390228271
Batch 12/64 loss: 0.24906927347183228
Batch 13/64 loss: 0.23429203033447266
Batch 14/64 loss: 0.24739444255828857
Batch 15/64 loss: 0.23628777265548706
Batch 16/64 loss: 0.24447453022003174
Batch 17/64 loss: 0.24534761905670166
Batch 18/64 loss: 0.2423766851425171
Batch 19/64 loss: 0.24486392736434937
Batch 20/64 loss: 0.24476099014282227
Batch 21/64 loss: 0.2423795461654663
Batch 22/64 loss: 0.260273814201355
Batch 23/64 loss: 0.25111544132232666
Batch 24/64 loss: 0.24570012092590332
Batch 25/64 loss: 0.24165499210357666
Batch 26/64 loss: 0.24409818649291992
Batch 27/64 loss: 0.2464742660522461
Batch 28/64 loss: 0.24196231365203857
Batch 29/64 loss: 0.23593610525131226
Batch 30/64 loss: 0.24870288372039795
Batch 31/64 loss: 0.24514234066009521
Batch 32/64 loss: 0.2568877935409546
Batch 33/64 loss: 0.24485862255096436
Batch 34/64 loss: 0.2414003610610962
Batch 35/64 loss: 0.24401867389678955
Batch 36/64 loss: 0.2402459979057312
Batch 37/64 loss: 0.24042952060699463
Batch 38/64 loss: 0.2522639036178589
Batch 39/64 loss: 0.2477923035621643
Batch 40/64 loss: 0.2465038299560547
Batch 41/64 loss: 0.2532493472099304
Batch 42/64 loss: 0.25627386569976807
Batch 43/64 loss: 0.24408859014511108
Batch 44/64 loss: 0.2528855800628662
Batch 45/64 loss: 0.24319583177566528
Batch 46/64 loss: 0.23779821395874023
Batch 47/64 loss: 0.2506554126739502
Batch 48/64 loss: 0.24166792631149292
Batch 49/64 loss: 0.24348443746566772
Batch 50/64 loss: 0.24683016538619995
Batch 51/64 loss: 0.24393188953399658
Batch 52/64 loss: 0.2450297474861145
Batch 53/64 loss: 0.25377845764160156
Batch 54/64 loss: 0.2413332462310791
Batch 55/64 loss: 0.24506723880767822
Batch 56/64 loss: 0.23919260501861572
Batch 57/64 loss: 0.2467583417892456
Batch 58/64 loss: 0.252533495426178
Batch 59/64 loss: 0.24389362335205078
Batch 60/64 loss: 0.2420274019241333
Batch 61/64 loss: 0.2439885139465332
Batch 62/64 loss: 0.24866318702697754
Batch 63/64 loss: 0.23976659774780273
Batch 64/64 loss: 0.2456485629081726
Epoch 328  Train loss: 0.245711206221113  Val loss: 0.28334216952733565
Epoch 329
-------------------------------
Batch 1/64 loss: 0.24280059337615967
Batch 2/64 loss: 0.24977898597717285
Batch 3/64 loss: 0.2421778440475464
Batch 4/64 loss: 0.24354398250579834
Batch 5/64 loss: 0.24319952726364136
Batch 6/64 loss: 0.2432795763015747
Batch 7/64 loss: 0.23413145542144775
Batch 8/64 loss: 0.23827916383743286
Batch 9/64 loss: 0.2452014684677124
Batch 10/64 loss: 0.24313020706176758
Batch 11/64 loss: 0.24937069416046143
Batch 12/64 loss: 0.24156975746154785
Batch 13/64 loss: 0.2377428412437439
Batch 14/64 loss: 0.23930764198303223
Batch 15/64 loss: 0.25465214252471924
Batch 16/64 loss: 0.2449343204498291
Batch 17/64 loss: 0.2464907169342041
Batch 18/64 loss: 0.23676413297653198
Batch 19/64 loss: 0.24221664667129517
Batch 20/64 loss: 0.24501609802246094
Batch 21/64 loss: 0.2418918013572693
Batch 22/64 loss: 0.24364012479782104
Batch 23/64 loss: 0.24141252040863037
Batch 24/64 loss: 0.2513198256492615
Batch 25/64 loss: 0.23919832706451416
Batch 26/64 loss: 0.23173224925994873
Batch 27/64 loss: 0.2453751564025879
Batch 28/64 loss: 0.24722903966903687
Batch 29/64 loss: 0.23453348875045776
Batch 30/64 loss: 0.24797701835632324
Batch 31/64 loss: 0.24807482957839966
Batch 32/64 loss: 0.2401643991470337
Batch 33/64 loss: 0.24108505249023438
Batch 34/64 loss: 0.25307291746139526
Batch 35/64 loss: 0.24353080987930298
Batch 36/64 loss: 0.24802452325820923
Batch 37/64 loss: 0.24633336067199707
Batch 38/64 loss: 0.24916023015975952
Batch 39/64 loss: 0.2409343123435974
Batch 40/64 loss: 0.24099278450012207
Batch 41/64 loss: 0.23688679933547974
Batch 42/64 loss: 0.25473088026046753
Batch 43/64 loss: 0.2377362847328186
Batch 44/64 loss: 0.24975532293319702
Batch 45/64 loss: 0.25333213806152344
Batch 46/64 loss: 0.2418859601020813
Batch 47/64 loss: 0.2629159092903137
Batch 48/64 loss: 0.2532072067260742
Batch 49/64 loss: 0.23959308862686157
Batch 50/64 loss: 0.24910104274749756
Batch 51/64 loss: 0.248388409614563
Batch 52/64 loss: 0.23746895790100098
Batch 53/64 loss: 0.2419847846031189
Batch 54/64 loss: 0.24212628602981567
Batch 55/64 loss: 0.2509925365447998
Batch 56/64 loss: 0.249953031539917
Batch 57/64 loss: 0.24843645095825195
Batch 58/64 loss: 0.24598991870880127
Batch 59/64 loss: 0.25214993953704834
Batch 60/64 loss: 0.24729406833648682
Batch 61/64 loss: 0.24779963493347168
Batch 62/64 loss: 0.24508357048034668
Batch 63/64 loss: 0.24006521701812744
Batch 64/64 loss: 0.24910789728164673
Epoch 329  Train loss: 0.24475261066474166  Val loss: 0.2828242405993013
Epoch 330
-------------------------------
Batch 1/64 loss: 0.24279934167861938
Batch 2/64 loss: 0.23810672760009766
Batch 3/64 loss: 0.25000548362731934
Batch 4/64 loss: 0.24237900972366333
Batch 5/64 loss: 0.2522587776184082
Batch 6/64 loss: 0.2529529333114624
Batch 7/64 loss: 0.24369794130325317
Batch 8/64 loss: 0.24635595083236694
Batch 9/64 loss: 0.2429584264755249
Batch 10/64 loss: 0.24267852306365967
Batch 11/64 loss: 0.24643993377685547
Batch 12/64 loss: 0.2549877166748047
Batch 13/64 loss: 0.2550508975982666
Batch 14/64 loss: 0.23522156476974487
Batch 15/64 loss: 0.24628639221191406
Batch 16/64 loss: 0.254869282245636
Batch 17/64 loss: 0.25235962867736816
Batch 18/64 loss: 0.24233651161193848
Batch 19/64 loss: 0.25070327520370483
Batch 20/64 loss: 0.2494504451751709
Batch 21/64 loss: 0.23622143268585205
Batch 22/64 loss: 0.24395501613616943
Batch 23/64 loss: 0.2504798173904419
Batch 24/64 loss: 0.23712366819381714
Batch 25/64 loss: 0.24661672115325928
Batch 26/64 loss: 0.25253450870513916
Batch 27/64 loss: 0.2428802251815796
Batch 28/64 loss: 0.25066041946411133
Batch 29/64 loss: 0.2497941255569458
Batch 30/64 loss: 0.24509263038635254
Batch 31/64 loss: 0.24194681644439697
Batch 32/64 loss: 0.23666054010391235
Batch 33/64 loss: 0.250438928604126
Batch 34/64 loss: 0.23825299739837646
Batch 35/64 loss: 0.2431136965751648
Batch 36/64 loss: 0.24914753437042236
Batch 37/64 loss: 0.23817235231399536
Batch 38/64 loss: 0.2445012927055359
Batch 39/64 loss: 0.25749218463897705
Batch 40/64 loss: 0.24621552228927612
Batch 41/64 loss: 0.2527245283126831
Batch 42/64 loss: 0.23986071348190308
Batch 43/64 loss: 0.24437671899795532
Batch 44/64 loss: 0.24479639530181885
Batch 45/64 loss: 0.24495995044708252
Batch 46/64 loss: 0.25149500370025635
Batch 47/64 loss: 0.24095118045806885
Batch 48/64 loss: 0.24548983573913574
Batch 49/64 loss: 0.2539346218109131
Batch 50/64 loss: 0.2455102801322937
Batch 51/64 loss: 0.2545866370201111
Batch 52/64 loss: 0.24282824993133545
Batch 53/64 loss: 0.23858213424682617
Batch 54/64 loss: 0.23619389533996582
Batch 55/64 loss: 0.24393737316131592
Batch 56/64 loss: 0.23860245943069458
Batch 57/64 loss: 0.24641287326812744
Batch 58/64 loss: 0.24576640129089355
Batch 59/64 loss: 0.24102026224136353
Batch 60/64 loss: 0.2565581798553467
Batch 61/64 loss: 0.24761056900024414
Batch 62/64 loss: 0.2356051206588745
Batch 63/64 loss: 0.24073517322540283
Batch 64/64 loss: 0.25224143266677856
Epoch 330  Train loss: 0.24572421686322082  Val loss: 0.2833596009159416
Epoch 331
-------------------------------
Batch 1/64 loss: 0.244032621383667
Batch 2/64 loss: 0.24967330694198608
Batch 3/64 loss: 0.2469731569290161
Batch 4/64 loss: 0.24410033226013184
Batch 5/64 loss: 0.2492697834968567
Batch 6/64 loss: 0.24745821952819824
Batch 7/64 loss: 0.2409961223602295
Batch 8/64 loss: 0.23915666341781616
Batch 9/64 loss: 0.2425059676170349
Batch 10/64 loss: 0.2412126064300537
Batch 11/64 loss: 0.24300485849380493
Batch 12/64 loss: 0.24301183223724365
Batch 13/64 loss: 0.24417102336883545
Batch 14/64 loss: 0.247308611869812
Batch 15/64 loss: 0.23439913988113403
Batch 16/64 loss: 0.25085127353668213
Batch 17/64 loss: 0.24299287796020508
Batch 18/64 loss: 0.23770004510879517
Batch 19/64 loss: 0.24792540073394775
Batch 20/64 loss: 0.2516251802444458
Batch 21/64 loss: 0.24136054515838623
Batch 22/64 loss: 0.2398446798324585
Batch 23/64 loss: 0.2546842694282532
Batch 24/64 loss: 0.25259387493133545
Batch 25/64 loss: 0.2403581738471985
Batch 26/64 loss: 0.24508881568908691
Batch 27/64 loss: 0.250906765460968
Batch 28/64 loss: 0.24375545978546143
Batch 29/64 loss: 0.2558072805404663
Batch 30/64 loss: 0.24053001403808594
Batch 31/64 loss: 0.25321340560913086
Batch 32/64 loss: 0.25272196531295776
Batch 33/64 loss: 0.23380762338638306
Batch 34/64 loss: 0.23936080932617188
Batch 35/64 loss: 0.24836862087249756
Batch 36/64 loss: 0.2484985589981079
Batch 37/64 loss: 0.24261939525604248
Batch 38/64 loss: 0.24333274364471436
Batch 39/64 loss: 0.23796594142913818
Batch 40/64 loss: 0.2531967759132385
Batch 41/64 loss: 0.234322190284729
Batch 42/64 loss: 0.2422013282775879
Batch 43/64 loss: 0.24433636665344238
Batch 44/64 loss: 0.24751663208007812
Batch 45/64 loss: 0.2399606704711914
Batch 46/64 loss: 0.24848711490631104
Batch 47/64 loss: 0.2427750825881958
Batch 48/64 loss: 0.23752182722091675
Batch 49/64 loss: 0.24060606956481934
Batch 50/64 loss: 0.24440431594848633
Batch 51/64 loss: 0.23886597156524658
Batch 52/64 loss: 0.25149083137512207
Batch 53/64 loss: 0.24847984313964844
Batch 54/64 loss: 0.2503002882003784
Batch 55/64 loss: 0.24541008472442627
Batch 56/64 loss: 0.24155783653259277
Batch 57/64 loss: 0.2392527461051941
Batch 58/64 loss: 0.24423712491989136
Batch 59/64 loss: 0.24420148134231567
Batch 60/64 loss: 0.2415616512298584
Batch 61/64 loss: 0.25834983587265015
Batch 62/64 loss: 0.23721259832382202
Batch 63/64 loss: 0.2389143705368042
Batch 64/64 loss: 0.24955248832702637
Epoch 331  Train loss: 0.24463553522147385  Val loss: 0.2820969621340434
Saving best model, epoch: 331
Epoch 332
-------------------------------
Batch 1/64 loss: 0.244190514087677
Batch 2/64 loss: 0.24480539560317993
Batch 3/64 loss: 0.23649215698242188
Batch 4/64 loss: 0.23918521404266357
Batch 5/64 loss: 0.23734265565872192
Batch 6/64 loss: 0.24646532535552979
Batch 7/64 loss: 0.2410796880722046
Batch 8/64 loss: 0.24891692399978638
Batch 9/64 loss: 0.2465132474899292
Batch 10/64 loss: 0.24012446403503418
Batch 11/64 loss: 0.2273085117340088
Batch 12/64 loss: 0.24198782444000244
Batch 13/64 loss: 0.2386084794998169
Batch 14/64 loss: 0.25366365909576416
Batch 15/64 loss: 0.24512696266174316
Batch 16/64 loss: 0.2418677806854248
Batch 17/64 loss: 0.24062728881835938
Batch 18/64 loss: 0.24100220203399658
Batch 19/64 loss: 0.2427302598953247
Batch 20/64 loss: 0.2577931880950928
Batch 21/64 loss: 0.25239360332489014
Batch 22/64 loss: 0.22838586568832397
Batch 23/64 loss: 0.2416667938232422
Batch 24/64 loss: 0.24884498119354248
Batch 25/64 loss: 0.2438790202140808
Batch 26/64 loss: 0.24094057083129883
Batch 27/64 loss: 0.2374628186225891
Batch 28/64 loss: 0.2559535503387451
Batch 29/64 loss: 0.23981237411499023
Batch 30/64 loss: 0.2433995008468628
Batch 31/64 loss: 0.23956650495529175
Batch 32/64 loss: 0.242018461227417
Batch 33/64 loss: 0.24369627237319946
Batch 34/64 loss: 0.23577630519866943
Batch 35/64 loss: 0.2470608949661255
Batch 36/64 loss: 0.23614901304244995
Batch 37/64 loss: 0.24229204654693604
Batch 38/64 loss: 0.23965448141098022
Batch 39/64 loss: 0.23708629608154297
Batch 40/64 loss: 0.24769234657287598
Batch 41/64 loss: 0.2444092035293579
Batch 42/64 loss: 0.2580305337905884
Batch 43/64 loss: 0.24097228050231934
Batch 44/64 loss: 0.2540398836135864
Batch 45/64 loss: 0.25116652250289917
Batch 46/64 loss: 0.25737297534942627
Batch 47/64 loss: 0.24891811609268188
Batch 48/64 loss: 0.23731327056884766
Batch 49/64 loss: 0.2583921551704407
Batch 50/64 loss: 0.2513291835784912
Batch 51/64 loss: 0.23506402969360352
Batch 52/64 loss: 0.24340516328811646
Batch 53/64 loss: 0.2432621717453003
Batch 54/64 loss: 0.24014568328857422
Batch 55/64 loss: 0.24984192848205566
Batch 56/64 loss: 0.2403637170791626
Batch 57/64 loss: 0.24399811029434204
Batch 58/64 loss: 0.2461327314376831
Batch 59/64 loss: 0.2498486042022705
Batch 60/64 loss: 0.24265217781066895
Batch 61/64 loss: 0.25167417526245117
Batch 62/64 loss: 0.23968273401260376
Batch 63/64 loss: 0.2571251392364502
Batch 64/64 loss: 0.24533617496490479
Epoch 332  Train loss: 0.24421499710456998  Val loss: 0.2818280864007694
Saving best model, epoch: 332
Epoch 333
-------------------------------
Batch 1/64 loss: 0.24472957849502563
Batch 2/64 loss: 0.24465018510818481
Batch 3/64 loss: 0.2434067726135254
Batch 4/64 loss: 0.23541224002838135
Batch 5/64 loss: 0.24046367406845093
Batch 6/64 loss: 0.24416518211364746
Batch 7/64 loss: 0.23672443628311157
Batch 8/64 loss: 0.24718785285949707
Batch 9/64 loss: 0.2457714080810547
Batch 10/64 loss: 0.241438627243042
Batch 11/64 loss: 0.24863028526306152
Batch 12/64 loss: 0.24360334873199463
Batch 13/64 loss: 0.24217897653579712
Batch 14/64 loss: 0.22985553741455078
Batch 15/64 loss: 0.23732316493988037
Batch 16/64 loss: 0.2448638677597046
Batch 17/64 loss: 0.2514498233795166
Batch 18/64 loss: 0.25389909744262695
Batch 19/64 loss: 0.24673569202423096
Batch 20/64 loss: 0.2511157989501953
Batch 21/64 loss: 0.25461477041244507
Batch 22/64 loss: 0.25253498554229736
Batch 23/64 loss: 0.2378692626953125
Batch 24/64 loss: 0.24073106050491333
Batch 25/64 loss: 0.2422327995300293
Batch 26/64 loss: 0.248571515083313
Batch 27/64 loss: 0.24290555715560913
Batch 28/64 loss: 0.24133169651031494
Batch 29/64 loss: 0.24098193645477295
Batch 30/64 loss: 0.236419677734375
Batch 31/64 loss: 0.25214534997940063
Batch 32/64 loss: 0.2571287751197815
Batch 33/64 loss: 0.23768264055252075
Batch 34/64 loss: 0.2385009527206421
Batch 35/64 loss: 0.2401801347732544
Batch 36/64 loss: 0.24809372425079346
Batch 37/64 loss: 0.2450922131538391
Batch 38/64 loss: 0.24474912881851196
Batch 39/64 loss: 0.2586851119995117
Batch 40/64 loss: 0.24070227146148682
Batch 41/64 loss: 0.2454872727394104
Batch 42/64 loss: 0.23376154899597168
Batch 43/64 loss: 0.24044013023376465
Batch 44/64 loss: 0.24855482578277588
Batch 45/64 loss: 0.2347038984298706
Batch 46/64 loss: 0.24456804990768433
Batch 47/64 loss: 0.2408597469329834
Batch 48/64 loss: 0.2520935535430908
Batch 49/64 loss: 0.24203747510910034
Batch 50/64 loss: 0.24597692489624023
Batch 51/64 loss: 0.25419849157333374
Batch 52/64 loss: 0.2415066957473755
Batch 53/64 loss: 0.24956905841827393
Batch 54/64 loss: 0.2522619366645813
Batch 55/64 loss: 0.24627721309661865
Batch 56/64 loss: 0.24440455436706543
Batch 57/64 loss: 0.24047118425369263
Batch 58/64 loss: 0.2510627508163452
Batch 59/64 loss: 0.24373555183410645
Batch 60/64 loss: 0.23882830142974854
Batch 61/64 loss: 0.2383977770805359
Batch 62/64 loss: 0.2440287470817566
Batch 63/64 loss: 0.24781107902526855
Batch 64/64 loss: 0.24213767051696777
Epoch 333  Train loss: 0.2443513589746812  Val loss: 0.282487573287741
Epoch 334
-------------------------------
Batch 1/64 loss: 0.2575458288192749
Batch 2/64 loss: 0.24104416370391846
Batch 3/64 loss: 0.24144357442855835
Batch 4/64 loss: 0.2381938099861145
Batch 5/64 loss: 0.2472916841506958
Batch 6/64 loss: 0.24416649341583252
Batch 7/64 loss: 0.2556794285774231
Batch 8/64 loss: 0.24301493167877197
Batch 9/64 loss: 0.2368251085281372
Batch 10/64 loss: 0.23778963088989258
Batch 11/64 loss: 0.24325108528137207
Batch 12/64 loss: 0.24769246578216553
Batch 13/64 loss: 0.23271846771240234
Batch 14/64 loss: 0.2364872694015503
Batch 15/64 loss: 0.24142122268676758
Batch 16/64 loss: 0.23572856187820435
Batch 17/64 loss: 0.24646270275115967
Batch 18/64 loss: 0.24369215965270996
Batch 19/64 loss: 0.2501915693283081
Batch 20/64 loss: 0.24669873714447021
Batch 21/64 loss: 0.245863676071167
Batch 22/64 loss: 0.24828362464904785
Batch 23/64 loss: 0.23739409446716309
Batch 24/64 loss: 0.24732595682144165
Batch 25/64 loss: 0.24467575550079346
Batch 26/64 loss: 0.2462221384048462
Batch 27/64 loss: 0.2441859245300293
Batch 28/64 loss: 0.23913025856018066
Batch 29/64 loss: 0.2424018383026123
Batch 30/64 loss: 0.24847733974456787
Batch 31/64 loss: 0.24075031280517578
Batch 32/64 loss: 0.24088358879089355
Batch 33/64 loss: 0.25075864791870117
Batch 34/64 loss: 0.24776971340179443
Batch 35/64 loss: 0.24001288414001465
Batch 36/64 loss: 0.23553025722503662
Batch 37/64 loss: 0.2505086064338684
Batch 38/64 loss: 0.24742329120635986
Batch 39/64 loss: 0.23929089307785034
Batch 40/64 loss: 0.2508971691131592
Batch 41/64 loss: 0.24773633480072021
Batch 42/64 loss: 0.24217402935028076
Batch 43/64 loss: 0.2502622604370117
Batch 44/64 loss: 0.24438798427581787
Batch 45/64 loss: 0.24525511264801025
Batch 46/64 loss: 0.2542163133621216
Batch 47/64 loss: 0.23993903398513794
Batch 48/64 loss: 0.23965203762054443
Batch 49/64 loss: 0.23984861373901367
Batch 50/64 loss: 0.25244879722595215
Batch 51/64 loss: 0.245785653591156
Batch 52/64 loss: 0.24756550788879395
Batch 53/64 loss: 0.25421518087387085
Batch 54/64 loss: 0.2486802339553833
Batch 55/64 loss: 0.2427901029586792
Batch 56/64 loss: 0.250092089176178
Batch 57/64 loss: 0.23820751905441284
Batch 58/64 loss: 0.24905771017074585
Batch 59/64 loss: 0.2498173713684082
Batch 60/64 loss: 0.240614652633667
Batch 61/64 loss: 0.23937076330184937
Batch 62/64 loss: 0.23835736513137817
Batch 63/64 loss: 0.2428070306777954
Batch 64/64 loss: 0.2539733052253723
Epoch 334  Train loss: 0.2445315536330728  Val loss: 0.2832870399419385
Epoch 335
-------------------------------
Batch 1/64 loss: 0.24799835681915283
Batch 2/64 loss: 0.25028491020202637
Batch 3/64 loss: 0.23358619213104248
Batch 4/64 loss: 0.24016427993774414
Batch 5/64 loss: 0.24014407396316528
Batch 6/64 loss: 0.23977482318878174
Batch 7/64 loss: 0.23930728435516357
Batch 8/64 loss: 0.23855608701705933
Batch 9/64 loss: 0.25224900245666504
Batch 10/64 loss: 0.2340184450149536
Batch 11/64 loss: 0.2519536018371582
Batch 12/64 loss: 0.24301207065582275
Batch 13/64 loss: 0.2506963610649109
Batch 14/64 loss: 0.23940575122833252
Batch 15/64 loss: 0.25280630588531494
Batch 16/64 loss: 0.2368917465209961
Batch 17/64 loss: 0.24625009298324585
Batch 18/64 loss: 0.23544448614120483
Batch 19/64 loss: 0.23315870761871338
Batch 20/64 loss: 0.23749059438705444
Batch 21/64 loss: 0.24647289514541626
Batch 22/64 loss: 0.24193978309631348
Batch 23/64 loss: 0.2500724792480469
Batch 24/64 loss: 0.2443310022354126
Batch 25/64 loss: 0.2453017234802246
Batch 26/64 loss: 0.2299182415008545
Batch 27/64 loss: 0.2427496314048767
Batch 28/64 loss: 0.24459803104400635
Batch 29/64 loss: 0.24933898448944092
Batch 30/64 loss: 0.24877691268920898
Batch 31/64 loss: 0.23695862293243408
Batch 32/64 loss: 0.24531453847885132
Batch 33/64 loss: 0.2500905394554138
Batch 34/64 loss: 0.24695587158203125
Batch 35/64 loss: 0.24706017971038818
Batch 36/64 loss: 0.2520483732223511
Batch 37/64 loss: 0.24567759037017822
Batch 38/64 loss: 0.24804776906967163
Batch 39/64 loss: 0.25438404083251953
Batch 40/64 loss: 0.24378859996795654
Batch 41/64 loss: 0.24792933464050293
Batch 42/64 loss: 0.24048399925231934
Batch 43/64 loss: 0.24823987483978271
Batch 44/64 loss: 0.23898035287857056
Batch 45/64 loss: 0.2439950704574585
Batch 46/64 loss: 0.24039119482040405
Batch 47/64 loss: 0.2485334277153015
Batch 48/64 loss: 0.2391834259033203
Batch 49/64 loss: 0.25057244300842285
Batch 50/64 loss: 0.2418917417526245
Batch 51/64 loss: 0.24504899978637695
Batch 52/64 loss: 0.23680418729782104
Batch 53/64 loss: 0.23205339908599854
Batch 54/64 loss: 0.2462560534477234
Batch 55/64 loss: 0.25099384784698486
Batch 56/64 loss: 0.2442430853843689
Batch 57/64 loss: 0.24764752388000488
Batch 58/64 loss: 0.2498776912689209
Batch 59/64 loss: 0.2603834271430969
Batch 60/64 loss: 0.24881768226623535
Batch 61/64 loss: 0.2509983777999878
Batch 62/64 loss: 0.24475014209747314
Batch 63/64 loss: 0.23973679542541504
Batch 64/64 loss: 0.2464812994003296
Epoch 335  Train loss: 0.24438732605354457  Val loss: 0.2839831705765216
Epoch 336
-------------------------------
Batch 1/64 loss: 0.2500492334365845
Batch 2/64 loss: 0.2425999641418457
Batch 3/64 loss: 0.2462041974067688
Batch 4/64 loss: 0.24910515546798706
Batch 5/64 loss: 0.2397838830947876
Batch 6/64 loss: 0.24135565757751465
Batch 7/64 loss: 0.2470366358757019
Batch 8/64 loss: 0.23414427042007446
Batch 9/64 loss: 0.24440765380859375
Batch 10/64 loss: 0.26058995723724365
Batch 11/64 loss: 0.23920881748199463
Batch 12/64 loss: 0.24823760986328125
Batch 13/64 loss: 0.2468637228012085
Batch 14/64 loss: 0.2359175682067871
Batch 15/64 loss: 0.23593401908874512
Batch 16/64 loss: 0.24239087104797363
Batch 17/64 loss: 0.25116991996765137
Batch 18/64 loss: 0.23973500728607178
Batch 19/64 loss: 0.24378490447998047
Batch 20/64 loss: 0.2404005527496338
Batch 21/64 loss: 0.2424226999282837
Batch 22/64 loss: 0.2423262596130371
Batch 23/64 loss: 0.2455054521560669
Batch 24/64 loss: 0.24815750122070312
Batch 25/64 loss: 0.24198013544082642
Batch 26/64 loss: 0.24002808332443237
Batch 27/64 loss: 0.24575847387313843
Batch 28/64 loss: 0.24831151962280273
Batch 29/64 loss: 0.24313652515411377
Batch 30/64 loss: 0.2345724105834961
Batch 31/64 loss: 0.25465309619903564
Batch 32/64 loss: 0.24262750148773193
Batch 33/64 loss: 0.242090106010437
Batch 34/64 loss: 0.24545562267303467
Batch 35/64 loss: 0.2546755075454712
Batch 36/64 loss: 0.24914872646331787
Batch 37/64 loss: 0.2394806146621704
Batch 38/64 loss: 0.2488575577735901
Batch 39/64 loss: 0.24358677864074707
Batch 40/64 loss: 0.24765276908874512
Batch 41/64 loss: 0.2446100115776062
Batch 42/64 loss: 0.2406480312347412
Batch 43/64 loss: 0.24403774738311768
Batch 44/64 loss: 0.23894935846328735
Batch 45/64 loss: 0.24663382768630981
Batch 46/64 loss: 0.25251758098602295
Batch 47/64 loss: 0.2409067153930664
Batch 48/64 loss: 0.2463589310646057
Batch 49/64 loss: 0.2496841549873352
Batch 50/64 loss: 0.24586474895477295
Batch 51/64 loss: 0.2494363784790039
Batch 52/64 loss: 0.24131864309310913
Batch 53/64 loss: 0.24712133407592773
Batch 54/64 loss: 0.24719369411468506
Batch 55/64 loss: 0.24773049354553223
Batch 56/64 loss: 0.237237811088562
Batch 57/64 loss: 0.24364793300628662
Batch 58/64 loss: 0.24614810943603516
Batch 59/64 loss: 0.23203063011169434
Batch 60/64 loss: 0.25307631492614746
Batch 61/64 loss: 0.24588948488235474
Batch 62/64 loss: 0.24885469675064087
Batch 63/64 loss: 0.23911118507385254
Batch 64/64 loss: 0.24188339710235596
Epoch 336  Train loss: 0.24454536952224432  Val loss: 0.28218999187561244
Epoch 337
-------------------------------
Batch 1/64 loss: 0.24037790298461914
Batch 2/64 loss: 0.24493145942687988
Batch 3/64 loss: 0.24133634567260742
Batch 4/64 loss: 0.25482189655303955
Batch 5/64 loss: 0.23509663343429565
Batch 6/64 loss: 0.24194872379302979
Batch 7/64 loss: 0.24400168657302856
Batch 8/64 loss: 0.2534593343734741
Batch 9/64 loss: 0.24716711044311523
Batch 10/64 loss: 0.23673087358474731
Batch 11/64 loss: 0.24266302585601807
Batch 12/64 loss: 0.23942184448242188
Batch 13/64 loss: 0.2374197244644165
Batch 14/64 loss: 0.2467682957649231
Batch 15/64 loss: 0.2553291320800781
Batch 16/64 loss: 0.24967741966247559
Batch 17/64 loss: 0.24029701948165894
Batch 18/64 loss: 0.2396996021270752
Batch 19/64 loss: 0.24666297435760498
Batch 20/64 loss: 0.23829329013824463
Batch 21/64 loss: 0.24285995960235596
Batch 22/64 loss: 0.23841649293899536
Batch 23/64 loss: 0.24243462085723877
Batch 24/64 loss: 0.25394362211227417
Batch 25/64 loss: 0.2563284635543823
Batch 26/64 loss: 0.23139941692352295
Batch 27/64 loss: 0.2426997423171997
Batch 28/64 loss: 0.26495444774627686
Batch 29/64 loss: 0.2510805130004883
Batch 30/64 loss: 0.2503710389137268
Batch 31/64 loss: 0.24131512641906738
Batch 32/64 loss: 0.24881583452224731
Batch 33/64 loss: 0.24358630180358887
Batch 34/64 loss: 0.24145793914794922
Batch 35/64 loss: 0.2552410364151001
Batch 36/64 loss: 0.24545341730117798
Batch 37/64 loss: 0.24228745698928833
Batch 38/64 loss: 0.24594509601593018
Batch 39/64 loss: 0.2475077509880066
Batch 40/64 loss: 0.2428572177886963
Batch 41/64 loss: 0.2408236265182495
Batch 42/64 loss: 0.23707884550094604
Batch 43/64 loss: 0.25080204010009766
Batch 44/64 loss: 0.24799227714538574
Batch 45/64 loss: 0.23681676387786865
Batch 46/64 loss: 0.2453048825263977
Batch 47/64 loss: 0.25298750400543213
Batch 48/64 loss: 0.2456570863723755
Batch 49/64 loss: 0.24416303634643555
Batch 50/64 loss: 0.2351018786430359
Batch 51/64 loss: 0.24322247505187988
Batch 52/64 loss: 0.24209094047546387
Batch 53/64 loss: 0.24147045612335205
Batch 54/64 loss: 0.23628365993499756
Batch 55/64 loss: 0.24285399913787842
Batch 56/64 loss: 0.24155402183532715
Batch 57/64 loss: 0.23956501483917236
Batch 58/64 loss: 0.24675917625427246
Batch 59/64 loss: 0.24123382568359375
Batch 60/64 loss: 0.23580694198608398
Batch 61/64 loss: 0.24155622720718384
Batch 62/64 loss: 0.2390347719192505
Batch 63/64 loss: 0.24951791763305664
Batch 64/64 loss: 0.2443554401397705
Epoch 337  Train loss: 0.24417260768366794  Val loss: 0.28321056472476813
Epoch 338
-------------------------------
Batch 1/64 loss: 0.25018131732940674
Batch 2/64 loss: 0.23378288745880127
Batch 3/64 loss: 0.2373144030570984
Batch 4/64 loss: 0.23896491527557373
Batch 5/64 loss: 0.2509431838989258
Batch 6/64 loss: 0.2341022491455078
Batch 7/64 loss: 0.24764055013656616
Batch 8/64 loss: 0.23789608478546143
Batch 9/64 loss: 0.2554417848587036
Batch 10/64 loss: 0.23855149745941162
Batch 11/64 loss: 0.24170255661010742
Batch 12/64 loss: 0.2290906310081482
Batch 13/64 loss: 0.25088101625442505
Batch 14/64 loss: 0.24902689456939697
Batch 15/64 loss: 0.24877291917800903
Batch 16/64 loss: 0.24342989921569824
Batch 17/64 loss: 0.242051899433136
Batch 18/64 loss: 0.24705040454864502
Batch 19/64 loss: 0.24558758735656738
Batch 20/64 loss: 0.24562907218933105
Batch 21/64 loss: 0.23461240530014038
Batch 22/64 loss: 0.24967724084854126
Batch 23/64 loss: 0.24138391017913818
Batch 24/64 loss: 0.23833239078521729
Batch 25/64 loss: 0.23890089988708496
Batch 26/64 loss: 0.24938488006591797
Batch 27/64 loss: 0.24576354026794434
Batch 28/64 loss: 0.23919695615768433
Batch 29/64 loss: 0.24452924728393555
Batch 30/64 loss: 0.2437470555305481
Batch 31/64 loss: 0.24252545833587646
Batch 32/64 loss: 0.24544751644134521
Batch 33/64 loss: 0.2456430196762085
Batch 34/64 loss: 0.2528679370880127
Batch 35/64 loss: 0.2514674663543701
Batch 36/64 loss: 0.2500162124633789
Batch 37/64 loss: 0.2364369034767151
Batch 38/64 loss: 0.24347245693206787
Batch 39/64 loss: 0.24166333675384521
Batch 40/64 loss: 0.23453056812286377
Batch 41/64 loss: 0.23938804864883423
Batch 42/64 loss: 0.2447655200958252
Batch 43/64 loss: 0.2377493977546692
Batch 44/64 loss: 0.2506728172302246
Batch 45/64 loss: 0.24232369661331177
Batch 46/64 loss: 0.2518746852874756
Batch 47/64 loss: 0.24706125259399414
Batch 48/64 loss: 0.24634897708892822
Batch 49/64 loss: 0.25096404552459717
Batch 50/64 loss: 0.24897700548171997
Batch 51/64 loss: 0.24887794256210327
Batch 52/64 loss: 0.25704026222229004
Batch 53/64 loss: 0.2374476194381714
Batch 54/64 loss: 0.2443845272064209
Batch 55/64 loss: 0.24358505010604858
Batch 56/64 loss: 0.23494642972946167
Batch 57/64 loss: 0.24131810665130615
Batch 58/64 loss: 0.23432111740112305
Batch 59/64 loss: 0.2407386302947998
Batch 60/64 loss: 0.23965376615524292
Batch 61/64 loss: 0.2446138858795166
Batch 62/64 loss: 0.24598705768585205
Batch 63/64 loss: 0.2546238899230957
Batch 64/64 loss: 0.23795580863952637
Epoch 338  Train loss: 0.24382387049057905  Val loss: 0.282724434567481
Epoch 339
-------------------------------
Batch 1/64 loss: 0.239851713180542
Batch 2/64 loss: 0.23152083158493042
Batch 3/64 loss: 0.23794180154800415
Batch 4/64 loss: 0.2409704327583313
Batch 5/64 loss: 0.2452634572982788
Batch 6/64 loss: 0.23980343341827393
Batch 7/64 loss: 0.23664367198944092
Batch 8/64 loss: 0.23946750164031982
Batch 9/64 loss: 0.23811954259872437
Batch 10/64 loss: 0.24626827239990234
Batch 11/64 loss: 0.24077612161636353
Batch 12/64 loss: 0.24002528190612793
Batch 13/64 loss: 0.24325895309448242
Batch 14/64 loss: 0.24917006492614746
Batch 15/64 loss: 0.23980116844177246
Batch 16/64 loss: 0.251162052154541
Batch 17/64 loss: 0.2393210530281067
Batch 18/64 loss: 0.24634552001953125
Batch 19/64 loss: 0.25003838539123535
Batch 20/64 loss: 0.25353145599365234
Batch 21/64 loss: 0.2462477684020996
Batch 22/64 loss: 0.23914313316345215
Batch 23/64 loss: 0.24402141571044922
Batch 24/64 loss: 0.24452906847000122
Batch 25/64 loss: 0.24392807483673096
Batch 26/64 loss: 0.2439361810684204
Batch 27/64 loss: 0.2440885305404663
Batch 28/64 loss: 0.239474356174469
Batch 29/64 loss: 0.2426619529724121
Batch 30/64 loss: 0.2379029393196106
Batch 31/64 loss: 0.23898518085479736
Batch 32/64 loss: 0.24762344360351562
Batch 33/64 loss: 0.24106085300445557
Batch 34/64 loss: 0.23474210500717163
Batch 35/64 loss: 0.24294281005859375
Batch 36/64 loss: 0.24358922243118286
Batch 37/64 loss: 0.25843822956085205
Batch 38/64 loss: 0.2357286810874939
Batch 39/64 loss: 0.23417264223098755
Batch 40/64 loss: 0.24593615531921387
Batch 41/64 loss: 0.24611639976501465
Batch 42/64 loss: 0.2445858120918274
Batch 43/64 loss: 0.24222862720489502
Batch 44/64 loss: 0.24380576610565186
Batch 45/64 loss: 0.24771332740783691
Batch 46/64 loss: 0.25195080041885376
Batch 47/64 loss: 0.24810266494750977
Batch 48/64 loss: 0.24244147539138794
Batch 49/64 loss: 0.24203795194625854
Batch 50/64 loss: 0.24312305450439453
Batch 51/64 loss: 0.24194121360778809
Batch 52/64 loss: 0.24374902248382568
Batch 53/64 loss: 0.24209940433502197
Batch 54/64 loss: 0.2547551393508911
Batch 55/64 loss: 0.26376980543136597
Batch 56/64 loss: 0.24870717525482178
Batch 57/64 loss: 0.24785804748535156
Batch 58/64 loss: 0.2406536340713501
Batch 59/64 loss: 0.23687684535980225
Batch 60/64 loss: 0.24996888637542725
Batch 61/64 loss: 0.2514222264289856
Batch 62/64 loss: 0.24075722694396973
Batch 63/64 loss: 0.24373894929885864
Batch 64/64 loss: 0.23598212003707886
Epoch 339  Train loss: 0.24366781968696444  Val loss: 0.2834719341645126
Epoch 340
-------------------------------
Batch 1/64 loss: 0.24179387092590332
Batch 2/64 loss: 0.23748433589935303
Batch 3/64 loss: 0.2507743835449219
Batch 4/64 loss: 0.24739205837249756
Batch 5/64 loss: 0.2440485954284668
Batch 6/64 loss: 0.23254990577697754
Batch 7/64 loss: 0.24285173416137695
Batch 8/64 loss: 0.24992632865905762
Batch 9/64 loss: 0.23630237579345703
Batch 10/64 loss: 0.2486327886581421
Batch 11/64 loss: 0.25180691480636597
Batch 12/64 loss: 0.2515007257461548
Batch 13/64 loss: 0.24387896060943604
Batch 14/64 loss: 0.242139995098114
Batch 15/64 loss: 0.24262046813964844
Batch 16/64 loss: 0.23743903636932373
Batch 17/64 loss: 0.2353009581565857
Batch 18/64 loss: 0.25957393646240234
Batch 19/64 loss: 0.23684561252593994
Batch 20/64 loss: 0.24292147159576416
Batch 21/64 loss: 0.24245524406433105
Batch 22/64 loss: 0.2479616403579712
Batch 23/64 loss: 0.2385426163673401
Batch 24/64 loss: 0.23905539512634277
Batch 25/64 loss: 0.23947715759277344
Batch 26/64 loss: 0.24300217628479004
Batch 27/64 loss: 0.2359025478363037
Batch 28/64 loss: 0.24095463752746582
Batch 29/64 loss: 0.246945321559906
Batch 30/64 loss: 0.24138081073760986
Batch 31/64 loss: 0.24185025691986084
Batch 32/64 loss: 0.24664634466171265
Batch 33/64 loss: 0.2446107268333435
Batch 34/64 loss: 0.23892027139663696
Batch 35/64 loss: 0.24605721235275269
Batch 36/64 loss: 0.24800151586532593
Batch 37/64 loss: 0.24754148721694946
Batch 38/64 loss: 0.24516749382019043
Batch 39/64 loss: 0.24038279056549072
Batch 40/64 loss: 0.24061894416809082
Batch 41/64 loss: 0.2403540015220642
Batch 42/64 loss: 0.24979734420776367
Batch 43/64 loss: 0.24455857276916504
Batch 44/64 loss: 0.23819470405578613
Batch 45/64 loss: 0.24583011865615845
Batch 46/64 loss: 0.24745702743530273
Batch 47/64 loss: 0.24598455429077148
Batch 48/64 loss: 0.2419593334197998
Batch 49/64 loss: 0.24617749452590942
Batch 50/64 loss: 0.2424178123474121
Batch 51/64 loss: 0.239302396774292
Batch 52/64 loss: 0.238944411277771
Batch 53/64 loss: 0.24320971965789795
Batch 54/64 loss: 0.25394606590270996
Batch 55/64 loss: 0.25026899576187134
Batch 56/64 loss: 0.22941017150878906
Batch 57/64 loss: 0.240226149559021
Batch 58/64 loss: 0.24471056461334229
Batch 59/64 loss: 0.2396426796913147
Batch 60/64 loss: 0.2320106029510498
Batch 61/64 loss: 0.24786972999572754
Batch 62/64 loss: 0.2545081377029419
Batch 63/64 loss: 0.23755526542663574
Batch 64/64 loss: 0.2384042739868164
Epoch 340  Train loss: 0.2432062448239794  Val loss: 0.28213407821262004
Epoch 341
-------------------------------
Batch 1/64 loss: 0.24785149097442627
Batch 2/64 loss: 0.23629021644592285
Batch 3/64 loss: 0.23674136400222778
Batch 4/64 loss: 0.24135684967041016
Batch 5/64 loss: 0.24243426322937012
Batch 6/64 loss: 0.23579657077789307
Batch 7/64 loss: 0.23878216743469238
Batch 8/64 loss: 0.2370067834854126
Batch 9/64 loss: 0.2457701563835144
Batch 10/64 loss: 0.24460077285766602
Batch 11/64 loss: 0.24404311180114746
Batch 12/64 loss: 0.23438364267349243
Batch 13/64 loss: 0.23393595218658447
Batch 14/64 loss: 0.24550771713256836
Batch 15/64 loss: 0.24119961261749268
Batch 16/64 loss: 0.24236637353897095
Batch 17/64 loss: 0.23565661907196045
Batch 18/64 loss: 0.24651801586151123
Batch 19/64 loss: 0.239757239818573
Batch 20/64 loss: 0.24596208333969116
Batch 21/64 loss: 0.24571526050567627
Batch 22/64 loss: 0.23446232080459595
Batch 23/64 loss: 0.23939168453216553
Batch 24/64 loss: 0.24834215641021729
Batch 25/64 loss: 0.2356259822845459
Batch 26/64 loss: 0.2407311201095581
Batch 27/64 loss: 0.23602133989334106
Batch 28/64 loss: 0.23802852630615234
Batch 29/64 loss: 0.26048439741134644
Batch 30/64 loss: 0.23909389972686768
Batch 31/64 loss: 0.24165141582489014
Batch 32/64 loss: 0.23466277122497559
Batch 33/64 loss: 0.24032938480377197
Batch 34/64 loss: 0.24010628461837769
Batch 35/64 loss: 0.23844242095947266
Batch 36/64 loss: 0.24316465854644775
Batch 37/64 loss: 0.24519586563110352
Batch 38/64 loss: 0.24500936269760132
Batch 39/64 loss: 0.24858081340789795
Batch 40/64 loss: 0.24904799461364746
Batch 41/64 loss: 0.24009907245635986
Batch 42/64 loss: 0.2420758605003357
Batch 43/64 loss: 0.2574198842048645
Batch 44/64 loss: 0.25553762912750244
Batch 45/64 loss: 0.2502424716949463
Batch 46/64 loss: 0.249589741230011
Batch 47/64 loss: 0.2493220567703247
Batch 48/64 loss: 0.2454291582107544
Batch 49/64 loss: 0.24672168493270874
Batch 50/64 loss: 0.25324422121047974
Batch 51/64 loss: 0.24491119384765625
Batch 52/64 loss: 0.24617397785186768
Batch 53/64 loss: 0.24125397205352783
Batch 54/64 loss: 0.2468460202217102
Batch 55/64 loss: 0.2429850697517395
Batch 56/64 loss: 0.2414776086807251
Batch 57/64 loss: 0.2381681203842163
Batch 58/64 loss: 0.24035799503326416
Batch 59/64 loss: 0.2365204095840454
Batch 60/64 loss: 0.24476617574691772
Batch 61/64 loss: 0.24014592170715332
Batch 62/64 loss: 0.2585529088973999
Batch 63/64 loss: 0.24095076322555542
Batch 64/64 loss: 0.25149643421173096
Epoch 341  Train loss: 0.24316020245645562  Val loss: 0.2823583448875401
Epoch 342
-------------------------------
Batch 1/64 loss: 0.24551045894622803
Batch 2/64 loss: 0.24058043956756592
Batch 3/64 loss: 0.24158960580825806
Batch 4/64 loss: 0.2446761131286621
Batch 5/64 loss: 0.24796587228775024
Batch 6/64 loss: 0.24554991722106934
Batch 7/64 loss: 0.24587547779083252
Batch 8/64 loss: 0.23860538005828857
Batch 9/64 loss: 0.24986135959625244
Batch 10/64 loss: 0.22739028930664062
Batch 11/64 loss: 0.2436612844467163
Batch 12/64 loss: 0.23115050792694092
Batch 13/64 loss: 0.24360501766204834
Batch 14/64 loss: 0.24021637439727783
Batch 15/64 loss: 0.23770606517791748
Batch 16/64 loss: 0.2375432848930359
Batch 17/64 loss: 0.24428677558898926
Batch 18/64 loss: 0.24411344528198242
Batch 19/64 loss: 0.24568402767181396
Batch 20/64 loss: 0.23374605178833008
Batch 21/64 loss: 0.24443411827087402
Batch 22/64 loss: 0.2377912998199463
Batch 23/64 loss: 0.24796420335769653
Batch 24/64 loss: 0.2417234182357788
Batch 25/64 loss: 0.23395967483520508
Batch 26/64 loss: 0.23732751607894897
Batch 27/64 loss: 0.2436947226524353
Batch 28/64 loss: 0.24681907892227173
Batch 29/64 loss: 0.25131964683532715
Batch 30/64 loss: 0.240899920463562
Batch 31/64 loss: 0.2429056167602539
Batch 32/64 loss: 0.2321457862854004
Batch 33/64 loss: 0.23821967840194702
Batch 34/64 loss: 0.23806023597717285
Batch 35/64 loss: 0.24668550491333008
Batch 36/64 loss: 0.2428903579711914
Batch 37/64 loss: 0.2517671585083008
Batch 38/64 loss: 0.24111753702163696
Batch 39/64 loss: 0.2487843632698059
Batch 40/64 loss: 0.2555805444717407
Batch 41/64 loss: 0.2687007188796997
Batch 42/64 loss: 0.24173063039779663
Batch 43/64 loss: 0.23541665077209473
Batch 44/64 loss: 0.23895269632339478
Batch 45/64 loss: 0.24032866954803467
Batch 46/64 loss: 0.23651891946792603
Batch 47/64 loss: 0.25229722261428833
Batch 48/64 loss: 0.2438269853591919
Batch 49/64 loss: 0.2335938811302185
Batch 50/64 loss: 0.23792529106140137
Batch 51/64 loss: 0.23644959926605225
Batch 52/64 loss: 0.24607837200164795
Batch 53/64 loss: 0.24820536375045776
Batch 54/64 loss: 0.24111688137054443
Batch 55/64 loss: 0.24948269128799438
Batch 56/64 loss: 0.2397632598876953
Batch 57/64 loss: 0.24570661783218384
Batch 58/64 loss: 0.24862253665924072
Batch 59/64 loss: 0.2453533411026001
Batch 60/64 loss: 0.24530887603759766
Batch 61/64 loss: 0.24081051349639893
Batch 62/64 loss: 0.23592650890350342
Batch 63/64 loss: 0.2423243522644043
Batch 64/64 loss: 0.2412148118019104
Epoch 342  Train loss: 0.242647212860631  Val loss: 0.2837940376648788
Epoch 343
-------------------------------
Batch 1/64 loss: 0.24191445112228394
Batch 2/64 loss: 0.24486136436462402
Batch 3/64 loss: 0.24624478816986084
Batch 4/64 loss: 0.23920786380767822
Batch 5/64 loss: 0.24108630418777466
Batch 6/64 loss: 0.24289989471435547
Batch 7/64 loss: 0.2338641881942749
Batch 8/64 loss: 0.22826170921325684
Batch 9/64 loss: 0.23904085159301758
Batch 10/64 loss: 0.2432824969291687
Batch 11/64 loss: 0.2312103509902954
Batch 12/64 loss: 0.23819923400878906
Batch 13/64 loss: 0.23475539684295654
Batch 14/64 loss: 0.2444765567779541
Batch 15/64 loss: 0.24632108211517334
Batch 16/64 loss: 0.2505987882614136
Batch 17/64 loss: 0.25042080879211426
Batch 18/64 loss: 0.24618005752563477
Batch 19/64 loss: 0.24332702159881592
Batch 20/64 loss: 0.25383007526397705
Batch 21/64 loss: 0.2344588041305542
Batch 22/64 loss: 0.24285125732421875
Batch 23/64 loss: 0.24114680290222168
Batch 24/64 loss: 0.23373210430145264
Batch 25/64 loss: 0.23885804414749146
Batch 26/64 loss: 0.24115335941314697
Batch 27/64 loss: 0.24708616733551025
Batch 28/64 loss: 0.22960853576660156
Batch 29/64 loss: 0.22932910919189453
Batch 30/64 loss: 0.2358177900314331
Batch 31/64 loss: 0.2433164119720459
Batch 32/64 loss: 0.24180328845977783
Batch 33/64 loss: 0.2410326600074768
Batch 34/64 loss: 0.24232536554336548
Batch 35/64 loss: 0.2484130859375
Batch 36/64 loss: 0.23583340644836426
Batch 37/64 loss: 0.2370055913925171
Batch 38/64 loss: 0.2455660104751587
Batch 39/64 loss: 0.24382537603378296
Batch 40/64 loss: 0.24347937107086182
Batch 41/64 loss: 0.234000563621521
Batch 42/64 loss: 0.24876773357391357
Batch 43/64 loss: 0.24515634775161743
Batch 44/64 loss: 0.23857372999191284
Batch 45/64 loss: 0.24168050289154053
Batch 46/64 loss: 0.2525251507759094
Batch 47/64 loss: 0.2614457607269287
Batch 48/64 loss: 0.24525201320648193
Batch 49/64 loss: 0.2428465485572815
Batch 50/64 loss: 0.2463899850845337
Batch 51/64 loss: 0.2476881742477417
Batch 52/64 loss: 0.24599266052246094
Batch 53/64 loss: 0.2389662265777588
Batch 54/64 loss: 0.249442458152771
Batch 55/64 loss: 0.2512502074241638
Batch 56/64 loss: 0.2456721067428589
Batch 57/64 loss: 0.24560260772705078
Batch 58/64 loss: 0.24766862392425537
Batch 59/64 loss: 0.2534390687942505
Batch 60/64 loss: 0.23581922054290771
Batch 61/64 loss: 0.2414945363998413
Batch 62/64 loss: 0.23666155338287354
Batch 63/64 loss: 0.23761534690856934
Batch 64/64 loss: 0.2622302770614624
Epoch 343  Train loss: 0.24262352410484764  Val loss: 0.2820734764702132
Epoch 344
-------------------------------
Batch 1/64 loss: 0.23379158973693848
Batch 2/64 loss: 0.2456706166267395
Batch 3/64 loss: 0.24271732568740845
Batch 4/64 loss: 0.23591405153274536
Batch 5/64 loss: 0.24763768911361694
Batch 6/64 loss: 0.23519635200500488
Batch 7/64 loss: 0.23847252130508423
Batch 8/64 loss: 0.24233436584472656
Batch 9/64 loss: 0.23418617248535156
Batch 10/64 loss: 0.2422647476196289
Batch 11/64 loss: 0.23863142728805542
Batch 12/64 loss: 0.2324601411819458
Batch 13/64 loss: 0.2505303621292114
Batch 14/64 loss: 0.24777191877365112
Batch 15/64 loss: 0.24257999658584595
Batch 16/64 loss: 0.2543420195579529
Batch 17/64 loss: 0.24316328763961792
Batch 18/64 loss: 0.2364635467529297
Batch 19/64 loss: 0.24682152271270752
Batch 20/64 loss: 0.2422962188720703
Batch 21/64 loss: 0.23768287897109985
Batch 22/64 loss: 0.2501201629638672
Batch 23/64 loss: 0.23656916618347168
Batch 24/64 loss: 0.2448531985282898
Batch 25/64 loss: 0.24169373512268066
Batch 26/64 loss: 0.23971152305603027
Batch 27/64 loss: 0.23574405908584595
Batch 28/64 loss: 0.24943071603775024
Batch 29/64 loss: 0.23993873596191406
Batch 30/64 loss: 0.24857556819915771
Batch 31/64 loss: 0.24596166610717773
Batch 32/64 loss: 0.24200373888015747
Batch 33/64 loss: 0.2537255883216858
Batch 34/64 loss: 0.23289263248443604
Batch 35/64 loss: 0.25208866596221924
Batch 36/64 loss: 0.24252331256866455
Batch 37/64 loss: 0.23241442441940308
Batch 38/64 loss: 0.25297868251800537
Batch 39/64 loss: 0.24155521392822266
Batch 40/64 loss: 0.2390831708908081
Batch 41/64 loss: 0.23970818519592285
Batch 42/64 loss: 0.24872350692749023
Batch 43/64 loss: 0.2384183406829834
Batch 44/64 loss: 0.2495993971824646
Batch 45/64 loss: 0.23461806774139404
Batch 46/64 loss: 0.24784350395202637
Batch 47/64 loss: 0.2450934648513794
Batch 48/64 loss: 0.23376160860061646
Batch 49/64 loss: 0.23953354358673096
Batch 50/64 loss: 0.24601686000823975
Batch 51/64 loss: 0.23425710201263428
Batch 52/64 loss: 0.24783575534820557
Batch 53/64 loss: 0.24454009532928467
Batch 54/64 loss: 0.24443650245666504
Batch 55/64 loss: 0.24319708347320557
Batch 56/64 loss: 0.23833847045898438
Batch 57/64 loss: 0.24784308671951294
Batch 58/64 loss: 0.24064207077026367
Batch 59/64 loss: 0.23300981521606445
Batch 60/64 loss: 0.23922568559646606
Batch 61/64 loss: 0.24143660068511963
Batch 62/64 loss: 0.24437689781188965
Batch 63/64 loss: 0.24616742134094238
Batch 64/64 loss: 0.25626540184020996
Epoch 344  Train loss: 0.24240964440738452  Val loss: 0.28339684357757833
Epoch 345
-------------------------------
Batch 1/64 loss: 0.24845504760742188
Batch 2/64 loss: 0.24258685111999512
Batch 3/64 loss: 0.24220800399780273
Batch 4/64 loss: 0.24694561958312988
Batch 5/64 loss: 0.23728960752487183
Batch 6/64 loss: 0.24474847316741943
Batch 7/64 loss: 0.23395037651062012
Batch 8/64 loss: 0.23474150896072388
Batch 9/64 loss: 0.23652517795562744
Batch 10/64 loss: 0.2342461347579956
Batch 11/64 loss: 0.23789924383163452
Batch 12/64 loss: 0.2471296787261963
Batch 13/64 loss: 0.254871129989624
Batch 14/64 loss: 0.23720777034759521
Batch 15/64 loss: 0.24157476425170898
Batch 16/64 loss: 0.24286216497421265
Batch 17/64 loss: 0.2364058494567871
Batch 18/64 loss: 0.22932171821594238
Batch 19/64 loss: 0.24091601371765137
Batch 20/64 loss: 0.2357693910598755
Batch 21/64 loss: 0.23844408988952637
Batch 22/64 loss: 0.24265271425247192
Batch 23/64 loss: 0.2560276389122009
Batch 24/64 loss: 0.26265382766723633
Batch 25/64 loss: 0.235731840133667
Batch 26/64 loss: 0.2519066333770752
Batch 27/64 loss: 0.24487358331680298
Batch 28/64 loss: 0.23739415407180786
Batch 29/64 loss: 0.24519681930541992
Batch 30/64 loss: 0.2545536756515503
Batch 31/64 loss: 0.2330613136291504
Batch 32/64 loss: 0.23506224155426025
Batch 33/64 loss: 0.25618112087249756
Batch 34/64 loss: 0.24753224849700928
Batch 35/64 loss: 0.24339115619659424
Batch 36/64 loss: 0.24050372838974
Batch 37/64 loss: 0.2521693706512451
Batch 38/64 loss: 0.23978936672210693
Batch 39/64 loss: 0.23585933446884155
Batch 40/64 loss: 0.24173641204833984
Batch 41/64 loss: 0.23786091804504395
Batch 42/64 loss: 0.2407900094985962
Batch 43/64 loss: 0.24179977178573608
Batch 44/64 loss: 0.24697065353393555
Batch 45/64 loss: 0.24153286218643188
Batch 46/64 loss: 0.24308621883392334
Batch 47/64 loss: 0.25138700008392334
Batch 48/64 loss: 0.24596959352493286
Batch 49/64 loss: 0.2414764165878296
Batch 50/64 loss: 0.23785042762756348
Batch 51/64 loss: 0.2437329888343811
Batch 52/64 loss: 0.23778533935546875
Batch 53/64 loss: 0.2455531358718872
Batch 54/64 loss: 0.24541723728179932
Batch 55/64 loss: 0.2414252758026123
Batch 56/64 loss: 0.23940974473953247
Batch 57/64 loss: 0.23663651943206787
Batch 58/64 loss: 0.25150227546691895
Batch 59/64 loss: 0.2378253936767578
Batch 60/64 loss: 0.23870933055877686
Batch 61/64 loss: 0.24555695056915283
Batch 62/64 loss: 0.23719632625579834
Batch 63/64 loss: 0.2426537275314331
Batch 64/64 loss: 0.24112117290496826
Epoch 345  Train loss: 0.2424054085039625  Val loss: 0.2837460381058893
Epoch 346
-------------------------------
Batch 1/64 loss: 0.2462242841720581
Batch 2/64 loss: 0.2340792417526245
Batch 3/64 loss: 0.2344210147857666
Batch 4/64 loss: 0.2346041202545166
Batch 5/64 loss: 0.2415860891342163
Batch 6/64 loss: 0.24271678924560547
Batch 7/64 loss: 0.2418450117111206
Batch 8/64 loss: 0.24175727367401123
Batch 9/64 loss: 0.23911893367767334
Batch 10/64 loss: 0.23391342163085938
Batch 11/64 loss: 0.2519528865814209
Batch 12/64 loss: 0.23782271146774292
Batch 13/64 loss: 0.2471674680709839
Batch 14/64 loss: 0.23334413766860962
Batch 15/64 loss: 0.24660754203796387
Batch 16/64 loss: 0.2534339427947998
Batch 17/64 loss: 0.23685646057128906
Batch 18/64 loss: 0.25843000411987305
Batch 19/64 loss: 0.24565333127975464
Batch 20/64 loss: 0.2518477439880371
Batch 21/64 loss: 0.24653112888336182
Batch 22/64 loss: 0.2469540238380432
Batch 23/64 loss: 0.2528116703033447
Batch 24/64 loss: 0.23814380168914795
Batch 25/64 loss: 0.23836815357208252
Batch 26/64 loss: 0.23953700065612793
Batch 27/64 loss: 0.24673330783843994
Batch 28/64 loss: 0.23685318231582642
Batch 29/64 loss: 0.237176775932312
Batch 30/64 loss: 0.2428126335144043
Batch 31/64 loss: 0.23873138427734375
Batch 32/64 loss: 0.24007928371429443
Batch 33/64 loss: 0.2372959852218628
Batch 34/64 loss: 0.23647987842559814
Batch 35/64 loss: 0.2323731780052185
Batch 36/64 loss: 0.24076926708221436
Batch 37/64 loss: 0.24628746509552002
Batch 38/64 loss: 0.2391899824142456
Batch 39/64 loss: 0.2465806007385254
Batch 40/64 loss: 0.24152541160583496
Batch 41/64 loss: 0.24304187297821045
Batch 42/64 loss: 0.23716014623641968
Batch 43/64 loss: 0.24167877435684204
Batch 44/64 loss: 0.2440406084060669
Batch 45/64 loss: 0.24841952323913574
Batch 46/64 loss: 0.2400977611541748
Batch 47/64 loss: 0.24084889888763428
Batch 48/64 loss: 0.23969227075576782
Batch 49/64 loss: 0.2428557276725769
Batch 50/64 loss: 0.23855578899383545
Batch 51/64 loss: 0.2537500858306885
Batch 52/64 loss: 0.24308264255523682
Batch 53/64 loss: 0.24435913562774658
Batch 54/64 loss: 0.24776196479797363
Batch 55/64 loss: 0.24142450094223022
Batch 56/64 loss: 0.2434309720993042
Batch 57/64 loss: 0.2540862560272217
Batch 58/64 loss: 0.23385858535766602
Batch 59/64 loss: 0.2506282925605774
Batch 60/64 loss: 0.24296855926513672
Batch 61/64 loss: 0.23517155647277832
Batch 62/64 loss: 0.2469387650489807
Batch 63/64 loss: 0.2385387420654297
Batch 64/64 loss: 0.23481661081314087
Epoch 346  Train loss: 0.2423077711872026  Val loss: 0.2843757232849541
Epoch 347
-------------------------------
Batch 1/64 loss: 0.24190986156463623
Batch 2/64 loss: 0.2335149049758911
Batch 3/64 loss: 0.24404561519622803
Batch 4/64 loss: 0.2454512119293213
Batch 5/64 loss: 0.2461986541748047
Batch 6/64 loss: 0.23077774047851562
Batch 7/64 loss: 0.2422475814819336
Batch 8/64 loss: 0.23469692468643188
Batch 9/64 loss: 0.24335819482803345
Batch 10/64 loss: 0.23958754539489746
Batch 11/64 loss: 0.23290276527404785
Batch 12/64 loss: 0.24509787559509277
Batch 13/64 loss: 0.24706155061721802
Batch 14/64 loss: 0.23550188541412354
Batch 15/64 loss: 0.23628926277160645
Batch 16/64 loss: 0.24559259414672852
Batch 17/64 loss: 0.24471193552017212
Batch 18/64 loss: 0.23721802234649658
Batch 19/64 loss: 0.24290764331817627
Batch 20/64 loss: 0.2428838014602661
Batch 21/64 loss: 0.24447506666183472
Batch 22/64 loss: 0.254294753074646
Batch 23/64 loss: 0.2454237937927246
Batch 24/64 loss: 0.23405861854553223
Batch 25/64 loss: 0.2407461404800415
Batch 26/64 loss: 0.2593429684638977
Batch 27/64 loss: 0.23654413223266602
Batch 28/64 loss: 0.2416021227836609
Batch 29/64 loss: 0.2406320571899414
Batch 30/64 loss: 0.243880033493042
Batch 31/64 loss: 0.240028977394104
Batch 32/64 loss: 0.2422267198562622
Batch 33/64 loss: 0.2401266098022461
Batch 34/64 loss: 0.24469667673110962
Batch 35/64 loss: 0.24500662088394165
Batch 36/64 loss: 0.23817622661590576
Batch 37/64 loss: 0.24212855100631714
Batch 38/64 loss: 0.24099284410476685
Batch 39/64 loss: 0.2465742826461792
Batch 40/64 loss: 0.2423025369644165
Batch 41/64 loss: 0.23924005031585693
Batch 42/64 loss: 0.24511265754699707
Batch 43/64 loss: 0.24366629123687744
Batch 44/64 loss: 0.24116116762161255
Batch 45/64 loss: 0.24019169807434082
Batch 46/64 loss: 0.24067485332489014
Batch 47/64 loss: 0.24264419078826904
Batch 48/64 loss: 0.2434934377670288
Batch 49/64 loss: 0.2611280083656311
Batch 50/64 loss: 0.23691612482070923
Batch 51/64 loss: 0.24439942836761475
Batch 52/64 loss: 0.249411940574646
Batch 53/64 loss: 0.25369739532470703
Batch 54/64 loss: 0.23361027240753174
Batch 55/64 loss: 0.24409008026123047
Batch 56/64 loss: 0.24050664901733398
Batch 57/64 loss: 0.24061930179595947
Batch 58/64 loss: 0.24370276927947998
Batch 59/64 loss: 0.24321889877319336
Batch 60/64 loss: 0.2544867992401123
Batch 61/64 loss: 0.24248778820037842
Batch 62/64 loss: 0.24479907751083374
Batch 63/64 loss: 0.24159514904022217
Batch 64/64 loss: 0.23503053188323975
Epoch 347  Train loss: 0.24254654482299207  Val loss: 0.282574981758275
Epoch 348
-------------------------------
Batch 1/64 loss: 0.2391282320022583
Batch 2/64 loss: 0.24267208576202393
Batch 3/64 loss: 0.2427685260772705
Batch 4/64 loss: 0.23608112335205078
Batch 5/64 loss: 0.23867398500442505
Batch 6/64 loss: 0.24246275424957275
Batch 7/64 loss: 0.2465139627456665
Batch 8/64 loss: 0.24305510520935059
Batch 9/64 loss: 0.2420373558998108
Batch 10/64 loss: 0.24531638622283936
Batch 11/64 loss: 0.23757833242416382
Batch 12/64 loss: 0.24430739879608154
Batch 13/64 loss: 0.2351146936416626
Batch 14/64 loss: 0.2501857876777649
Batch 15/64 loss: 0.23408186435699463
Batch 16/64 loss: 0.24632418155670166
Batch 17/64 loss: 0.24448740482330322
Batch 18/64 loss: 0.2517135739326477
Batch 19/64 loss: 0.24339830875396729
Batch 20/64 loss: 0.23964464664459229
Batch 21/64 loss: 0.24762868881225586
Batch 22/64 loss: 0.23766648769378662
Batch 23/64 loss: 0.2461940050125122
Batch 24/64 loss: 0.23438382148742676
Batch 25/64 loss: 0.24496501684188843
Batch 26/64 loss: 0.24038469791412354
Batch 27/64 loss: 0.23819315433502197
Batch 28/64 loss: 0.239937424659729
Batch 29/64 loss: 0.24561548233032227
Batch 30/64 loss: 0.23548656702041626
Batch 31/64 loss: 0.24002611637115479
Batch 32/64 loss: 0.2367006540298462
Batch 33/64 loss: 0.24063515663146973
Batch 34/64 loss: 0.2394711971282959
Batch 35/64 loss: 0.24813055992126465
Batch 36/64 loss: 0.2485804557800293
Batch 37/64 loss: 0.24503076076507568
Batch 38/64 loss: 0.23278868198394775
Batch 39/64 loss: 0.2386465072631836
Batch 40/64 loss: 0.24077171087265015
Batch 41/64 loss: 0.23152172565460205
Batch 42/64 loss: 0.24537014961242676
Batch 43/64 loss: 0.2362879514694214
Batch 44/64 loss: 0.2334808111190796
Batch 45/64 loss: 0.24524831771850586
Batch 46/64 loss: 0.24298983812332153
Batch 47/64 loss: 0.2525908350944519
Batch 48/64 loss: 0.23709452152252197
Batch 49/64 loss: 0.23930412530899048
Batch 50/64 loss: 0.2360975742340088
Batch 51/64 loss: 0.24515700340270996
Batch 52/64 loss: 0.24102723598480225
Batch 53/64 loss: 0.2550382614135742
Batch 54/64 loss: 0.23745298385620117
Batch 55/64 loss: 0.23946893215179443
Batch 56/64 loss: 0.24234026670455933
Batch 57/64 loss: 0.24133312702178955
Batch 58/64 loss: 0.2701883316040039
Batch 59/64 loss: 0.23852336406707764
Batch 60/64 loss: 0.23652887344360352
Batch 61/64 loss: 0.2392095923423767
Batch 62/64 loss: 0.24511802196502686
Batch 63/64 loss: 0.2464868426322937
Batch 64/64 loss: 0.24602460861206055
Epoch 348  Train loss: 0.24202603919833315  Val loss: 0.28188801999763935
Epoch 349
-------------------------------
Batch 1/64 loss: 0.24366939067840576
Batch 2/64 loss: 0.23963862657546997
Batch 3/64 loss: 0.24443930387496948
Batch 4/64 loss: 0.2566714882850647
Batch 5/64 loss: 0.23605728149414062
Batch 6/64 loss: 0.24477839469909668
Batch 7/64 loss: 0.24420857429504395
Batch 8/64 loss: 0.24533820152282715
Batch 9/64 loss: 0.23323339223861694
Batch 10/64 loss: 0.24952638149261475
Batch 11/64 loss: 0.24772262573242188
Batch 12/64 loss: 0.2391490936279297
Batch 13/64 loss: 0.2371373176574707
Batch 14/64 loss: 0.24721288681030273
Batch 15/64 loss: 0.2340071201324463
Batch 16/64 loss: 0.24839818477630615
Batch 17/64 loss: 0.23798257112503052
Batch 18/64 loss: 0.2383413314819336
Batch 19/64 loss: 0.23410701751708984
Batch 20/64 loss: 0.24749970436096191
Batch 21/64 loss: 0.23734712600708008
Batch 22/64 loss: 0.2359708547592163
Batch 23/64 loss: 0.24717652797698975
Batch 24/64 loss: 0.23754137754440308
Batch 25/64 loss: 0.245231032371521
Batch 26/64 loss: 0.2373875379562378
Batch 27/64 loss: 0.2502310276031494
Batch 28/64 loss: 0.24460947513580322
Batch 29/64 loss: 0.2343462109565735
Batch 30/64 loss: 0.2349613904953003
Batch 31/64 loss: 0.23870182037353516
Batch 32/64 loss: 0.23515284061431885
Batch 33/64 loss: 0.23630714416503906
Batch 34/64 loss: 0.24531471729278564
Batch 35/64 loss: 0.23567575216293335
Batch 36/64 loss: 0.23860013484954834
Batch 37/64 loss: 0.24080431461334229
Batch 38/64 loss: 0.2404237985610962
Batch 39/64 loss: 0.2473393678665161
Batch 40/64 loss: 0.23250138759613037
Batch 41/64 loss: 0.24427807331085205
Batch 42/64 loss: 0.2362891435623169
Batch 43/64 loss: 0.24088704586029053
Batch 44/64 loss: 0.2378706932067871
Batch 45/64 loss: 0.24695175886154175
Batch 46/64 loss: 0.24484527111053467
Batch 47/64 loss: 0.24329650402069092
Batch 48/64 loss: 0.23793935775756836
Batch 49/64 loss: 0.24354612827301025
Batch 50/64 loss: 0.23531341552734375
Batch 51/64 loss: 0.23880034685134888
Batch 52/64 loss: 0.2358974814414978
Batch 53/64 loss: 0.23297548294067383
Batch 54/64 loss: 0.25091809034347534
Batch 55/64 loss: 0.246079683303833
Batch 56/64 loss: 0.24227046966552734
Batch 57/64 loss: 0.23992305994033813
Batch 58/64 loss: 0.25026237964630127
Batch 59/64 loss: 0.24062126874923706
Batch 60/64 loss: 0.23491907119750977
Batch 61/64 loss: 0.2512013912200928
Batch 62/64 loss: 0.23625272512435913
Batch 63/64 loss: 0.26794177293777466
Batch 64/64 loss: 0.2368343472480774
Epoch 349  Train loss: 0.2415944957265667  Val loss: 0.2832267939839576
Epoch 350
-------------------------------
Batch 1/64 loss: 0.24513942003250122
Batch 2/64 loss: 0.2381269931793213
Batch 3/64 loss: 0.2336021065711975
Batch 4/64 loss: 0.24433600902557373
Batch 5/64 loss: 0.2561800479888916
Batch 6/64 loss: 0.23463279008865356
Batch 7/64 loss: 0.2329167127609253
Batch 8/64 loss: 0.23098266124725342
Batch 9/64 loss: 0.22808098793029785
Batch 10/64 loss: 0.2479192018508911
Batch 11/64 loss: 0.2459251880645752
Batch 12/64 loss: 0.24199432134628296
Batch 13/64 loss: 0.24299168586730957
Batch 14/64 loss: 0.24808502197265625
Batch 15/64 loss: 0.24957966804504395
Batch 16/64 loss: 0.24475431442260742
Batch 17/64 loss: 0.2359706163406372
Batch 18/64 loss: 0.23736071586608887
Batch 19/64 loss: 0.24732714891433716
Batch 20/64 loss: 0.24596619606018066
Batch 21/64 loss: 0.24658668041229248
Batch 22/64 loss: 0.23573064804077148
Batch 23/64 loss: 0.2395687699317932
Batch 24/64 loss: 0.2530437111854553
Batch 25/64 loss: 0.22911548614501953
Batch 26/64 loss: 0.23754703998565674
Batch 27/64 loss: 0.23471194505691528
Batch 28/64 loss: 0.23804527521133423
Batch 29/64 loss: 0.25208842754364014
Batch 30/64 loss: 0.24429476261138916
Batch 31/64 loss: 0.23794889450073242
Batch 32/64 loss: 0.24756133556365967
Batch 33/64 loss: 0.24303483963012695
Batch 34/64 loss: 0.2424640655517578
Batch 35/64 loss: 0.2467581033706665
Batch 36/64 loss: 0.23618584871292114
Batch 37/64 loss: 0.2421824336051941
Batch 38/64 loss: 0.23392868041992188
Batch 39/64 loss: 0.24431240558624268
Batch 40/64 loss: 0.23796159029006958
Batch 41/64 loss: 0.2562946081161499
Batch 42/64 loss: 0.2334129810333252
Batch 43/64 loss: 0.251914381980896
Batch 44/64 loss: 0.23635923862457275
Batch 45/64 loss: 0.24356597661972046
Batch 46/64 loss: 0.24904048442840576
Batch 47/64 loss: 0.2398587465286255
Batch 48/64 loss: 0.25021445751190186
Batch 49/64 loss: 0.24534595012664795
Batch 50/64 loss: 0.23568087816238403
Batch 51/64 loss: 0.24470162391662598
Batch 52/64 loss: 0.23955154418945312
Batch 53/64 loss: 0.23656988143920898
Batch 54/64 loss: 0.24743324518203735
Batch 55/64 loss: 0.24433660507202148
Batch 56/64 loss: 0.241174578666687
Batch 57/64 loss: 0.23693519830703735
Batch 58/64 loss: 0.23425030708312988
Batch 59/64 loss: 0.24252688884735107
Batch 60/64 loss: 0.22797584533691406
Batch 61/64 loss: 0.24676620960235596
Batch 62/64 loss: 0.24663490056991577
Batch 63/64 loss: 0.24195796251296997
Batch 64/64 loss: 0.23728680610656738
Epoch 350  Train loss: 0.24165349567637723  Val loss: 0.28330287654784947
Epoch 351
-------------------------------
Batch 1/64 loss: 0.23930108547210693
Batch 2/64 loss: 0.23430150747299194
Batch 3/64 loss: 0.23511749505996704
Batch 4/64 loss: 0.23671042919158936
Batch 5/64 loss: 0.23836219310760498
Batch 6/64 loss: 0.2536931037902832
Batch 7/64 loss: 0.2428572177886963
Batch 8/64 loss: 0.2463386058807373
Batch 9/64 loss: 0.25095176696777344
Batch 10/64 loss: 0.238427996635437
Batch 11/64 loss: 0.23437172174453735
Batch 12/64 loss: 0.24643385410308838
Batch 13/64 loss: 0.23304897546768188
Batch 14/64 loss: 0.24290287494659424
Batch 15/64 loss: 0.2378082275390625
Batch 16/64 loss: 0.23809218406677246
Batch 17/64 loss: 0.24301767349243164
Batch 18/64 loss: 0.23546940088272095
Batch 19/64 loss: 0.24506187438964844
Batch 20/64 loss: 0.24233007431030273
Batch 21/64 loss: 0.23782533407211304
Batch 22/64 loss: 0.24378424882888794
Batch 23/64 loss: 0.2501315474510193
Batch 24/64 loss: 0.23641371726989746
Batch 25/64 loss: 0.2377181053161621
Batch 26/64 loss: 0.23340463638305664
Batch 27/64 loss: 0.24293410778045654
Batch 28/64 loss: 0.23941850662231445
Batch 29/64 loss: 0.23444890975952148
Batch 30/64 loss: 0.23910343647003174
Batch 31/64 loss: 0.24948930740356445
Batch 32/64 loss: 0.2394627332687378
Batch 33/64 loss: 0.2328091859817505
Batch 34/64 loss: 0.24320125579833984
Batch 35/64 loss: 0.23753416538238525
Batch 36/64 loss: 0.242353618144989
Batch 37/64 loss: 0.23802697658538818
Batch 38/64 loss: 0.24841678142547607
Batch 39/64 loss: 0.2490612268447876
Batch 40/64 loss: 0.2464449405670166
Batch 41/64 loss: 0.2421891689300537
Batch 42/64 loss: 0.24574899673461914
Batch 43/64 loss: 0.2435600757598877
Batch 44/64 loss: 0.23762714862823486
Batch 45/64 loss: 0.24178004264831543
Batch 46/64 loss: 0.23353302478790283
Batch 47/64 loss: 0.2536916732788086
Batch 48/64 loss: 0.24433809518814087
Batch 49/64 loss: 0.24145376682281494
Batch 50/64 loss: 0.2474399209022522
Batch 51/64 loss: 0.2445441484451294
Batch 52/64 loss: 0.2462480068206787
Batch 53/64 loss: 0.24487733840942383
Batch 54/64 loss: 0.2637735605239868
Batch 55/64 loss: 0.23572522401809692
Batch 56/64 loss: 0.24854058027267456
Batch 57/64 loss: 0.24987733364105225
Batch 58/64 loss: 0.23979592323303223
Batch 59/64 loss: 0.24830305576324463
Batch 60/64 loss: 0.2425222396850586
Batch 61/64 loss: 0.24933820962905884
Batch 62/64 loss: 0.24197059869766235
Batch 63/64 loss: 0.2391986846923828
Batch 64/64 loss: 0.24889904260635376
Epoch 351  Train loss: 0.24234246436287374  Val loss: 0.28389213666883123
Epoch 352
-------------------------------
Batch 1/64 loss: 0.24053657054901123
Batch 2/64 loss: 0.24800753593444824
Batch 3/64 loss: 0.24172258377075195
Batch 4/64 loss: 0.24722200632095337
Batch 5/64 loss: 0.2346634864807129
Batch 6/64 loss: 0.24378198385238647
Batch 7/64 loss: 0.2412571907043457
Batch 8/64 loss: 0.2351059913635254
Batch 9/64 loss: 0.2382889986038208
Batch 10/64 loss: 0.24836397171020508
Batch 11/64 loss: 0.24102258682250977
Batch 12/64 loss: 0.2481478452682495
Batch 13/64 loss: 0.2386457324028015
Batch 14/64 loss: 0.2408292293548584
Batch 15/64 loss: 0.24372297525405884
Batch 16/64 loss: 0.23728901147842407
Batch 17/64 loss: 0.24293780326843262
Batch 18/64 loss: 0.2392789125442505
Batch 19/64 loss: 0.22900032997131348
Batch 20/64 loss: 0.24269741773605347
Batch 21/64 loss: 0.24674415588378906
Batch 22/64 loss: 0.23304295539855957
Batch 23/64 loss: 0.24443304538726807
Batch 24/64 loss: 0.24441903829574585
Batch 25/64 loss: 0.24698102474212646
Batch 26/64 loss: 0.23788893222808838
Batch 27/64 loss: 0.2537193298339844
Batch 28/64 loss: 0.2458869218826294
Batch 29/64 loss: 0.23766064643859863
Batch 30/64 loss: 0.24944627285003662
Batch 31/64 loss: 0.22953927516937256
Batch 32/64 loss: 0.24651992321014404
Batch 33/64 loss: 0.23838770389556885
Batch 34/64 loss: 0.2459195852279663
Batch 35/64 loss: 0.23967725038528442
Batch 36/64 loss: 0.23409497737884521
Batch 37/64 loss: 0.23704051971435547
Batch 38/64 loss: 0.235207200050354
Batch 39/64 loss: 0.24457228183746338
Batch 40/64 loss: 0.24507254362106323
Batch 41/64 loss: 0.24519383907318115
Batch 42/64 loss: 0.24914038181304932
Batch 43/64 loss: 0.2427290678024292
Batch 44/64 loss: 0.24105620384216309
Batch 45/64 loss: 0.24394279718399048
Batch 46/64 loss: 0.24111825227737427
Batch 47/64 loss: 0.2434176206588745
Batch 48/64 loss: 0.229897141456604
Batch 49/64 loss: 0.23403233289718628
Batch 50/64 loss: 0.24860602617263794
Batch 51/64 loss: 0.24309086799621582
Batch 52/64 loss: 0.23727130889892578
Batch 53/64 loss: 0.2458553910255432
Batch 54/64 loss: 0.24726271629333496
Batch 55/64 loss: 0.24066126346588135
Batch 56/64 loss: 0.23756623268127441
Batch 57/64 loss: 0.2481045126914978
Batch 58/64 loss: 0.2490990161895752
Batch 59/64 loss: 0.24446380138397217
Batch 60/64 loss: 0.2409663200378418
Batch 61/64 loss: 0.2493150234222412
Batch 62/64 loss: 0.24526554346084595
Batch 63/64 loss: 0.24893128871917725
Batch 64/64 loss: 0.24471235275268555
Epoch 352  Train loss: 0.24218505036597157  Val loss: 0.28190000114572006
Epoch 353
-------------------------------
Batch 1/64 loss: 0.2535167932510376
Batch 2/64 loss: 0.23523366451263428
Batch 3/64 loss: 0.23973453044891357
Batch 4/64 loss: 0.2335721254348755
Batch 5/64 loss: 0.23999953269958496
Batch 6/64 loss: 0.2371666431427002
Batch 7/64 loss: 0.24372124671936035
Batch 8/64 loss: 0.24231958389282227
Batch 9/64 loss: 0.23792743682861328
Batch 10/64 loss: 0.23262888193130493
Batch 11/64 loss: 0.23192709684371948
Batch 12/64 loss: 0.24449455738067627
Batch 13/64 loss: 0.2518090009689331
Batch 14/64 loss: 0.24674415588378906
Batch 15/64 loss: 0.2445744276046753
Batch 16/64 loss: 0.23031949996948242
Batch 17/64 loss: 0.23824220895767212
Batch 18/64 loss: 0.2449437379837036
Batch 19/64 loss: 0.24731040000915527
Batch 20/64 loss: 0.24597382545471191
Batch 21/64 loss: 0.24027585983276367
Batch 22/64 loss: 0.25098973512649536
Batch 23/64 loss: 0.23593538999557495
Batch 24/64 loss: 0.23153823614120483
Batch 25/64 loss: 0.24460148811340332
Batch 26/64 loss: 0.24018877744674683
Batch 27/64 loss: 0.23697316646575928
Batch 28/64 loss: 0.2423974871635437
Batch 29/64 loss: 0.24583733081817627
Batch 30/64 loss: 0.24140501022338867
Batch 31/64 loss: 0.24729788303375244
Batch 32/64 loss: 0.24593651294708252
Batch 33/64 loss: 0.23856472969055176
Batch 34/64 loss: 0.24648821353912354
Batch 35/64 loss: 0.2333660125732422
Batch 36/64 loss: 0.24998801946640015
Batch 37/64 loss: 0.23485779762268066
Batch 38/64 loss: 0.2430732250213623
Batch 39/64 loss: 0.24462556838989258
Batch 40/64 loss: 0.2467334270477295
Batch 41/64 loss: 0.2381277084350586
Batch 42/64 loss: 0.23531872034072876
Batch 43/64 loss: 0.2380061149597168
Batch 44/64 loss: 0.2546265721321106
Batch 45/64 loss: 0.23532533645629883
Batch 46/64 loss: 0.24528640508651733
Batch 47/64 loss: 0.24944782257080078
Batch 48/64 loss: 0.2372792363166809
Batch 49/64 loss: 0.23737603425979614
Batch 50/64 loss: 0.24193859100341797
Batch 51/64 loss: 0.23591887950897217
Batch 52/64 loss: 0.23338842391967773
Batch 53/64 loss: 0.24128872156143188
Batch 54/64 loss: 0.24248802661895752
Batch 55/64 loss: 0.24975872039794922
Batch 56/64 loss: 0.2420024871826172
Batch 57/64 loss: 0.2378525733947754
Batch 58/64 loss: 0.24125009775161743
Batch 59/64 loss: 0.24754512310028076
Batch 60/64 loss: 0.23984956741333008
Batch 61/64 loss: 0.24399077892303467
Batch 62/64 loss: 0.2484305500984192
Batch 63/64 loss: 0.24468576908111572
Batch 64/64 loss: 0.24074864387512207
Epoch 353  Train loss: 0.24164669747446096  Val loss: 0.283979623792917
Epoch 354
-------------------------------
Batch 1/64 loss: 0.23376870155334473
Batch 2/64 loss: 0.24409723281860352
Batch 3/64 loss: 0.2312312126159668
Batch 4/64 loss: 0.24534428119659424
Batch 5/64 loss: 0.24382996559143066
Batch 6/64 loss: 0.24118763208389282
Batch 7/64 loss: 0.24735033512115479
Batch 8/64 loss: 0.24184036254882812
Batch 9/64 loss: 0.2362116575241089
Batch 10/64 loss: 0.2389000654220581
Batch 11/64 loss: 0.24885016679763794
Batch 12/64 loss: 0.24766874313354492
Batch 13/64 loss: 0.24363040924072266
Batch 14/64 loss: 0.24492555856704712
Batch 15/64 loss: 0.24156510829925537
Batch 16/64 loss: 0.23708009719848633
Batch 17/64 loss: 0.23593515157699585
Batch 18/64 loss: 0.23311829566955566
Batch 19/64 loss: 0.23598122596740723
Batch 20/64 loss: 0.2509278655052185
Batch 21/64 loss: 0.23894208669662476
Batch 22/64 loss: 0.2432105541229248
Batch 23/64 loss: 0.24915152788162231
Batch 24/64 loss: 0.23132163286209106
Batch 25/64 loss: 0.24343180656433105
Batch 26/64 loss: 0.245236337184906
Batch 27/64 loss: 0.23373150825500488
Batch 28/64 loss: 0.2348388433456421
Batch 29/64 loss: 0.24905413389205933
Batch 30/64 loss: 0.23946863412857056
Batch 31/64 loss: 0.24149084091186523
Batch 32/64 loss: 0.23307311534881592
Batch 33/64 loss: 0.24352014064788818
Batch 34/64 loss: 0.24784553050994873
Batch 35/64 loss: 0.25004422664642334
Batch 36/64 loss: 0.23635625839233398
Batch 37/64 loss: 0.23930788040161133
Batch 38/64 loss: 0.23489511013031006
Batch 39/64 loss: 0.2342703938484192
Batch 40/64 loss: 0.24547481536865234
Batch 41/64 loss: 0.24084675312042236
Batch 42/64 loss: 0.25149619579315186
Batch 43/64 loss: 0.251248836517334
Batch 44/64 loss: 0.24048733711242676
Batch 45/64 loss: 0.2503291368484497
Batch 46/64 loss: 0.24702060222625732
Batch 47/64 loss: 0.23939251899719238
Batch 48/64 loss: 0.2361552119255066
Batch 49/64 loss: 0.24219298362731934
Batch 50/64 loss: 0.24180054664611816
Batch 51/64 loss: 0.2504727244377136
Batch 52/64 loss: 0.2393627166748047
Batch 53/64 loss: 0.2410184144973755
Batch 54/64 loss: 0.2355939745903015
Batch 55/64 loss: 0.24126189947128296
Batch 56/64 loss: 0.25143003463745117
Batch 57/64 loss: 0.2464081048965454
Batch 58/64 loss: 0.24367833137512207
Batch 59/64 loss: 0.24208670854568481
Batch 60/64 loss: 0.24450170993804932
Batch 61/64 loss: 0.2427021861076355
Batch 62/64 loss: 0.23830527067184448
Batch 63/64 loss: 0.2410496473312378
Batch 64/64 loss: 0.24115890264511108
Epoch 354  Train loss: 0.24184816421246996  Val loss: 0.28188344989855263
Epoch 355
-------------------------------
Batch 1/64 loss: 0.22855478525161743
Batch 2/64 loss: 0.24096155166625977
Batch 3/64 loss: 0.2439589500427246
Batch 4/64 loss: 0.2396758794784546
Batch 5/64 loss: 0.2401214838027954
Batch 6/64 loss: 0.23599648475646973
Batch 7/64 loss: 0.24327272176742554
Batch 8/64 loss: 0.24073338508605957
Batch 9/64 loss: 0.24322158098220825
Batch 10/64 loss: 0.2416425347328186
Batch 11/64 loss: 0.23928046226501465
Batch 12/64 loss: 0.24269354343414307
Batch 13/64 loss: 0.2334098219871521
Batch 14/64 loss: 0.23229175806045532
Batch 15/64 loss: 0.24129807949066162
Batch 16/64 loss: 0.24919664859771729
Batch 17/64 loss: 0.2353825569152832
Batch 18/64 loss: 0.2404446005821228
Batch 19/64 loss: 0.23487019538879395
Batch 20/64 loss: 0.24646663665771484
Batch 21/64 loss: 0.254349946975708
Batch 22/64 loss: 0.2503542900085449
Batch 23/64 loss: 0.24645233154296875
Batch 24/64 loss: 0.23614680767059326
Batch 25/64 loss: 0.2347702980041504
Batch 26/64 loss: 0.2294551134109497
Batch 27/64 loss: 0.24203145503997803
Batch 28/64 loss: 0.22750413417816162
Batch 29/64 loss: 0.2292068600654602
Batch 30/64 loss: 0.24292480945587158
Batch 31/64 loss: 0.23840856552124023
Batch 32/64 loss: 0.22729063034057617
Batch 33/64 loss: 0.2448267936706543
Batch 34/64 loss: 0.22846698760986328
Batch 35/64 loss: 0.25180375576019287
Batch 36/64 loss: 0.23981338739395142
Batch 37/64 loss: 0.2335439920425415
Batch 38/64 loss: 0.24608445167541504
Batch 39/64 loss: 0.24126923084259033
Batch 40/64 loss: 0.23873436450958252
Batch 41/64 loss: 0.23943710327148438
Batch 42/64 loss: 0.23090457916259766
Batch 43/64 loss: 0.2469218373298645
Batch 44/64 loss: 0.2588998079299927
Batch 45/64 loss: 0.2411012053489685
Batch 46/64 loss: 0.24893403053283691
Batch 47/64 loss: 0.2450798749923706
Batch 48/64 loss: 0.24887335300445557
Batch 49/64 loss: 0.23913425207138062
Batch 50/64 loss: 0.2419975996017456
Batch 51/64 loss: 0.25182783603668213
Batch 52/64 loss: 0.2424565553665161
Batch 53/64 loss: 0.24775946140289307
Batch 54/64 loss: 0.23692560195922852
Batch 55/64 loss: 0.24780529737472534
Batch 56/64 loss: 0.23970478773117065
Batch 57/64 loss: 0.23441165685653687
Batch 58/64 loss: 0.23722898960113525
Batch 59/64 loss: 0.2509419918060303
Batch 60/64 loss: 0.2360842227935791
Batch 61/64 loss: 0.24172019958496094
Batch 62/64 loss: 0.2553086280822754
Batch 63/64 loss: 0.2440727949142456
Batch 64/64 loss: 0.2353876829147339
Epoch 355  Train loss: 0.24095661640167237  Val loss: 0.2820655369676675
Epoch 356
-------------------------------
Batch 1/64 loss: 0.2483767867088318
Batch 2/64 loss: 0.23387134075164795
Batch 3/64 loss: 0.2344576120376587
Batch 4/64 loss: 0.23456060886383057
Batch 5/64 loss: 0.24264109134674072
Batch 6/64 loss: 0.2377415895462036
Batch 7/64 loss: 0.2285352349281311
Batch 8/64 loss: 0.23217427730560303
Batch 9/64 loss: 0.2387598752975464
Batch 10/64 loss: 0.2541842460632324
Batch 11/64 loss: 0.23898553848266602
Batch 12/64 loss: 0.2475498914718628
Batch 13/64 loss: 0.2521946430206299
Batch 14/64 loss: 0.23920834064483643
Batch 15/64 loss: 0.23549652099609375
Batch 16/64 loss: 0.244981050491333
Batch 17/64 loss: 0.23564714193344116
Batch 18/64 loss: 0.244043231010437
Batch 19/64 loss: 0.2389327883720398
Batch 20/64 loss: 0.23676049709320068
Batch 21/64 loss: 0.23532521724700928
Batch 22/64 loss: 0.23965537548065186
Batch 23/64 loss: 0.2327423095703125
Batch 24/64 loss: 0.2465451955795288
Batch 25/64 loss: 0.23700696229934692
Batch 26/64 loss: 0.2429523468017578
Batch 27/64 loss: 0.24872052669525146
Batch 28/64 loss: 0.2410600185394287
Batch 29/64 loss: 0.24612510204315186
Batch 30/64 loss: 0.2407916784286499
Batch 31/64 loss: 0.23653995990753174
Batch 32/64 loss: 0.2419722080230713
Batch 33/64 loss: 0.24110233783721924
Batch 34/64 loss: 0.2411932349205017
Batch 35/64 loss: 0.23759979009628296
Batch 36/64 loss: 0.23774659633636475
Batch 37/64 loss: 0.23614108562469482
Batch 38/64 loss: 0.24596279859542847
Batch 39/64 loss: 0.23820620775222778
Batch 40/64 loss: 0.24341881275177002
Batch 41/64 loss: 0.24630087614059448
Batch 42/64 loss: 0.23459357023239136
Batch 43/64 loss: 0.245261549949646
Batch 44/64 loss: 0.2344120740890503
Batch 45/64 loss: 0.2387094497680664
Batch 46/64 loss: 0.23313021659851074
Batch 47/64 loss: 0.2558082938194275
Batch 48/64 loss: 0.23853611946105957
Batch 49/64 loss: 0.2368842363357544
Batch 50/64 loss: 0.23900258541107178
Batch 51/64 loss: 0.24732470512390137
Batch 52/64 loss: 0.24300217628479004
Batch 53/64 loss: 0.23655664920806885
Batch 54/64 loss: 0.2460816502571106
Batch 55/64 loss: 0.2416478395462036
Batch 56/64 loss: 0.23382329940795898
Batch 57/64 loss: 0.23951303958892822
Batch 58/64 loss: 0.23429083824157715
Batch 59/64 loss: 0.2476171851158142
Batch 60/64 loss: 0.23353034257888794
Batch 61/64 loss: 0.23422741889953613
Batch 62/64 loss: 0.23541080951690674
Batch 63/64 loss: 0.23868650197982788
Batch 64/64 loss: 0.2467833161354065
Epoch 356  Train loss: 0.24014665075376923  Val loss: 0.28288938478915554
Epoch 357
-------------------------------
Batch 1/64 loss: 0.23918282985687256
Batch 2/64 loss: 0.23467695713043213
Batch 3/64 loss: 0.24318808317184448
Batch 4/64 loss: 0.24634814262390137
Batch 5/64 loss: 0.237768292427063
Batch 6/64 loss: 0.23477792739868164
Batch 7/64 loss: 0.24023908376693726
Batch 8/64 loss: 0.2297622561454773
Batch 9/64 loss: 0.2289983034133911
Batch 10/64 loss: 0.24751383066177368
Batch 11/64 loss: 0.2381882667541504
Batch 12/64 loss: 0.24014079570770264
Batch 13/64 loss: 0.23881244659423828
Batch 14/64 loss: 0.24071341753005981
Batch 15/64 loss: 0.23670423030853271
Batch 16/64 loss: 0.23897898197174072
Batch 17/64 loss: 0.23559021949768066
Batch 18/64 loss: 0.2383543848991394
Batch 19/64 loss: 0.23759078979492188
Batch 20/64 loss: 0.23564016819000244
Batch 21/64 loss: 0.23844629526138306
Batch 22/64 loss: 0.24237757921218872
Batch 23/64 loss: 0.24796342849731445
Batch 24/64 loss: 0.2317824363708496
Batch 25/64 loss: 0.23200809955596924
Batch 26/64 loss: 0.23915868997573853
Batch 27/64 loss: 0.2441197633743286
Batch 28/64 loss: 0.23353338241577148
Batch 29/64 loss: 0.24586939811706543
Batch 30/64 loss: 0.23954707384109497
Batch 31/64 loss: 0.24183011054992676
Batch 32/64 loss: 0.24063587188720703
Batch 33/64 loss: 0.25041764974594116
Batch 34/64 loss: 0.25012218952178955
Batch 35/64 loss: 0.23795604705810547
Batch 36/64 loss: 0.24767112731933594
Batch 37/64 loss: 0.23186367750167847
Batch 38/64 loss: 0.24043118953704834
Batch 39/64 loss: 0.24264639616012573
Batch 40/64 loss: 0.24173390865325928
Batch 41/64 loss: 0.24574625492095947
Batch 42/64 loss: 0.2325037717819214
Batch 43/64 loss: 0.24139392375946045
Batch 44/64 loss: 0.24520349502563477
Batch 45/64 loss: 0.23632746934890747
Batch 46/64 loss: 0.2402990460395813
Batch 47/64 loss: 0.23281991481781006
Batch 48/64 loss: 0.22975999116897583
Batch 49/64 loss: 0.2371591329574585
Batch 50/64 loss: 0.2338947057723999
Batch 51/64 loss: 0.25691449642181396
Batch 52/64 loss: 0.2421485185623169
Batch 53/64 loss: 0.2356356382369995
Batch 54/64 loss: 0.2476920485496521
Batch 55/64 loss: 0.24470585584640503
Batch 56/64 loss: 0.2400972843170166
Batch 57/64 loss: 0.2514265775680542
Batch 58/64 loss: 0.25107741355895996
Batch 59/64 loss: 0.2398032546043396
Batch 60/64 loss: 0.24131637811660767
Batch 61/64 loss: 0.24454057216644287
Batch 62/64 loss: 0.23853766918182373
Batch 63/64 loss: 0.23880350589752197
Batch 64/64 loss: 0.24518638849258423
Epoch 357  Train loss: 0.2402349871747634  Val loss: 0.28237827741813004
Epoch 358
-------------------------------
Batch 1/64 loss: 0.22956621646881104
Batch 2/64 loss: 0.24772703647613525
Batch 3/64 loss: 0.24486392736434937
Batch 4/64 loss: 0.251213014125824
Batch 5/64 loss: 0.23438918590545654
Batch 6/64 loss: 0.24528038501739502
Batch 7/64 loss: 0.24174213409423828
Batch 8/64 loss: 0.25120365619659424
Batch 9/64 loss: 0.23784148693084717
Batch 10/64 loss: 0.2276415228843689
Batch 11/64 loss: 0.2376645803451538
Batch 12/64 loss: 0.23335689306259155
Batch 13/64 loss: 0.2485102415084839
Batch 14/64 loss: 0.24140024185180664
Batch 15/64 loss: 0.23724591732025146
Batch 16/64 loss: 0.2445380687713623
Batch 17/64 loss: 0.23163193464279175
Batch 18/64 loss: 0.24820315837860107
Batch 19/64 loss: 0.23002761602401733
Batch 20/64 loss: 0.23188072443008423
Batch 21/64 loss: 0.24441862106323242
Batch 22/64 loss: 0.236869215965271
Batch 23/64 loss: 0.24932444095611572
Batch 24/64 loss: 0.22904866933822632
Batch 25/64 loss: 0.24476683139801025
Batch 26/64 loss: 0.2349032163619995
Batch 27/64 loss: 0.24695396423339844
Batch 28/64 loss: 0.2431984543800354
Batch 29/64 loss: 0.2374129295349121
Batch 30/64 loss: 0.2470463514328003
Batch 31/64 loss: 0.23930543661117554
Batch 32/64 loss: 0.24698412418365479
Batch 33/64 loss: 0.23932278156280518
Batch 34/64 loss: 0.24313193559646606
Batch 35/64 loss: 0.23906028270721436
Batch 36/64 loss: 0.24543046951293945
Batch 37/64 loss: 0.23329758644104004
Batch 38/64 loss: 0.23498845100402832
Batch 39/64 loss: 0.2323216199874878
Batch 40/64 loss: 0.24290692806243896
Batch 41/64 loss: 0.2304697036743164
Batch 42/64 loss: 0.24399805068969727
Batch 43/64 loss: 0.23874938488006592
Batch 44/64 loss: 0.23715496063232422
Batch 45/64 loss: 0.24413883686065674
Batch 46/64 loss: 0.24571484327316284
Batch 47/64 loss: 0.238059401512146
Batch 48/64 loss: 0.2585865259170532
Batch 49/64 loss: 0.24230408668518066
Batch 50/64 loss: 0.26176488399505615
Batch 51/64 loss: 0.24004340171813965
Batch 52/64 loss: 0.23872840404510498
Batch 53/64 loss: 0.24386709928512573
Batch 54/64 loss: 0.24843168258666992
Batch 55/64 loss: 0.2440556287765503
Batch 56/64 loss: 0.23857229948043823
Batch 57/64 loss: 0.2413511872291565
Batch 58/64 loss: 0.2314334511756897
Batch 59/64 loss: 0.23500949144363403
Batch 60/64 loss: 0.24090516567230225
Batch 61/64 loss: 0.2328561544418335
Batch 62/64 loss: 0.23655575513839722
Batch 63/64 loss: 0.2525133490562439
Batch 64/64 loss: 0.23401635885238647
Epoch 358  Train loss: 0.24074347089318668  Val loss: 0.2818879603929946
Epoch 359
-------------------------------
Batch 1/64 loss: 0.24967175722122192
Batch 2/64 loss: 0.24205327033996582
Batch 3/64 loss: 0.24534547328948975
Batch 4/64 loss: 0.23477405309677124
Batch 5/64 loss: 0.24802923202514648
Batch 6/64 loss: 0.24083614349365234
Batch 7/64 loss: 0.23958873748779297
Batch 8/64 loss: 0.2417609691619873
Batch 9/64 loss: 0.23347532749176025
Batch 10/64 loss: 0.232408344745636
Batch 11/64 loss: 0.24230337142944336
Batch 12/64 loss: 0.24614006280899048
Batch 13/64 loss: 0.24156665802001953
Batch 14/64 loss: 0.23965346813201904
Batch 15/64 loss: 0.224778413772583
Batch 16/64 loss: 0.24342107772827148
Batch 17/64 loss: 0.23650825023651123
Batch 18/64 loss: 0.24388766288757324
Batch 19/64 loss: 0.24049049615859985
Batch 20/64 loss: 0.23689085245132446
Batch 21/64 loss: 0.24239391088485718
Batch 22/64 loss: 0.24074506759643555
Batch 23/64 loss: 0.24453246593475342
Batch 24/64 loss: 0.2455657720565796
Batch 25/64 loss: 0.23576408624649048
Batch 26/64 loss: 0.23406779766082764
Batch 27/64 loss: 0.22990739345550537
Batch 28/64 loss: 0.2540205717086792
Batch 29/64 loss: 0.2274964451789856
Batch 30/64 loss: 0.24050700664520264
Batch 31/64 loss: 0.24778836965560913
Batch 32/64 loss: 0.24606990814208984
Batch 33/64 loss: 0.23574841022491455
Batch 34/64 loss: 0.23257124423980713
Batch 35/64 loss: 0.2336595058441162
Batch 36/64 loss: 0.2499186396598816
Batch 37/64 loss: 0.23679953813552856
Batch 38/64 loss: 0.24332737922668457
Batch 39/64 loss: 0.2460263967514038
Batch 40/64 loss: 0.23958492279052734
Batch 41/64 loss: 0.24276316165924072
Batch 42/64 loss: 0.22677350044250488
Batch 43/64 loss: 0.24038338661193848
Batch 44/64 loss: 0.23622798919677734
Batch 45/64 loss: 0.23420655727386475
Batch 46/64 loss: 0.24121147394180298
Batch 47/64 loss: 0.24695801734924316
Batch 48/64 loss: 0.23081374168395996
Batch 49/64 loss: 0.24252969026565552
Batch 50/64 loss: 0.24225205183029175
Batch 51/64 loss: 0.24206596612930298
Batch 52/64 loss: 0.23717164993286133
Batch 53/64 loss: 0.23577094078063965
Batch 54/64 loss: 0.2411421537399292
Batch 55/64 loss: 0.24761193990707397
Batch 56/64 loss: 0.23314297199249268
Batch 57/64 loss: 0.22783935070037842
Batch 58/64 loss: 0.23879516124725342
Batch 59/64 loss: 0.248002827167511
Batch 60/64 loss: 0.24470341205596924
Batch 61/64 loss: 0.24373269081115723
Batch 62/64 loss: 0.24379032850265503
Batch 63/64 loss: 0.23434150218963623
Batch 64/64 loss: 0.2355300784111023
Epoch 359  Train loss: 0.23982676828608793  Val loss: 0.2827085182838833
Epoch 360
-------------------------------
Batch 1/64 loss: 0.23611903190612793
Batch 2/64 loss: 0.23496413230895996
Batch 3/64 loss: 0.24482929706573486
Batch 4/64 loss: 0.23232793807983398
Batch 5/64 loss: 0.23399782180786133
Batch 6/64 loss: 0.2348068356513977
Batch 7/64 loss: 0.23984277248382568
Batch 8/64 loss: 0.2427576780319214
Batch 9/64 loss: 0.24023032188415527
Batch 10/64 loss: 0.2318558692932129
Batch 11/64 loss: 0.23671609163284302
Batch 12/64 loss: 0.2569594383239746
Batch 13/64 loss: 0.23670393228530884
Batch 14/64 loss: 0.23251855373382568
Batch 15/64 loss: 0.24250257015228271
Batch 16/64 loss: 0.24570268392562866
Batch 17/64 loss: 0.23960727453231812
Batch 18/64 loss: 0.23181664943695068
Batch 19/64 loss: 0.23513448238372803
Batch 20/64 loss: 0.23933172225952148
Batch 21/64 loss: 0.2543081045150757
Batch 22/64 loss: 0.2458205223083496
Batch 23/64 loss: 0.250737726688385
Batch 24/64 loss: 0.24134910106658936
Batch 25/64 loss: 0.23653274774551392
Batch 26/64 loss: 0.23528671264648438
Batch 27/64 loss: 0.24058914184570312
Batch 28/64 loss: 0.23868179321289062
Batch 29/64 loss: 0.24046802520751953
Batch 30/64 loss: 0.23753267526626587
Batch 31/64 loss: 0.24847859144210815
Batch 32/64 loss: 0.24513298273086548
Batch 33/64 loss: 0.24754178524017334
Batch 34/64 loss: 0.24668031930923462
Batch 35/64 loss: 0.22844946384429932
Batch 36/64 loss: 0.23187100887298584
Batch 37/64 loss: 0.24874287843704224
Batch 38/64 loss: 0.2357303500175476
Batch 39/64 loss: 0.2411949634552002
Batch 40/64 loss: 0.24327510595321655
Batch 41/64 loss: 0.23502397537231445
Batch 42/64 loss: 0.2517983913421631
Batch 43/64 loss: 0.23126161098480225
Batch 44/64 loss: 0.2574946880340576
Batch 45/64 loss: 0.23589372634887695
Batch 46/64 loss: 0.24258852005004883
Batch 47/64 loss: 0.2433803677558899
Batch 48/64 loss: 0.24733543395996094
Batch 49/64 loss: 0.24564075469970703
Batch 50/64 loss: 0.23966753482818604
Batch 51/64 loss: 0.23177391290664673
Batch 52/64 loss: 0.23637932538986206
Batch 53/64 loss: 0.23872435092926025
Batch 54/64 loss: 0.24370241165161133
Batch 55/64 loss: 0.24337059259414673
Batch 56/64 loss: 0.24785244464874268
Batch 57/64 loss: 0.23704415559768677
Batch 58/64 loss: 0.24261713027954102
Batch 59/64 loss: 0.23781073093414307
Batch 60/64 loss: 0.23848319053649902
Batch 61/64 loss: 0.22662949562072754
Batch 62/64 loss: 0.2461872100830078
Batch 63/64 loss: 0.2509331703186035
Batch 64/64 loss: 0.24240505695343018
Epoch 360  Train loss: 0.2406357021892772  Val loss: 0.28277988798429876
Epoch 361
-------------------------------
Batch 1/64 loss: 0.2296074628829956
Batch 2/64 loss: 0.23425066471099854
Batch 3/64 loss: 0.2430952787399292
Batch 4/64 loss: 0.24109971523284912
Batch 5/64 loss: 0.23949289321899414
Batch 6/64 loss: 0.2431734800338745
Batch 7/64 loss: 0.24453377723693848
Batch 8/64 loss: 0.24482685327529907
Batch 9/64 loss: 0.23896408081054688
Batch 10/64 loss: 0.23601937294006348
Batch 11/64 loss: 0.23922884464263916
Batch 12/64 loss: 0.24332857131958008
Batch 13/64 loss: 0.23022615909576416
Batch 14/64 loss: 0.22819221019744873
Batch 15/64 loss: 0.23697572946548462
Batch 16/64 loss: 0.23529136180877686
Batch 17/64 loss: 0.24160051345825195
Batch 18/64 loss: 0.24542003870010376
Batch 19/64 loss: 0.2465379238128662
Batch 20/64 loss: 0.2436375617980957
Batch 21/64 loss: 0.23528361320495605
Batch 22/64 loss: 0.23749136924743652
Batch 23/64 loss: 0.2372223138809204
Batch 24/64 loss: 0.23710572719573975
Batch 25/64 loss: 0.24267101287841797
Batch 26/64 loss: 0.24841415882110596
Batch 27/64 loss: 0.23064005374908447
Batch 28/64 loss: 0.23807299137115479
Batch 29/64 loss: 0.2425748109817505
Batch 30/64 loss: 0.2435886263847351
Batch 31/64 loss: 0.23435324430465698
Batch 32/64 loss: 0.2354869842529297
Batch 33/64 loss: 0.2515473961830139
Batch 34/64 loss: 0.23721212148666382
Batch 35/64 loss: 0.24969947338104248
Batch 36/64 loss: 0.24346071481704712
Batch 37/64 loss: 0.23384976387023926
Batch 38/64 loss: 0.24044758081436157
Batch 39/64 loss: 0.2374941110610962
Batch 40/64 loss: 0.238145649433136
Batch 41/64 loss: 0.23682701587677002
Batch 42/64 loss: 0.24582338333129883
Batch 43/64 loss: 0.23848742246627808
Batch 44/64 loss: 0.2383694052696228
Batch 45/64 loss: 0.23665809631347656
Batch 46/64 loss: 0.25520312786102295
Batch 47/64 loss: 0.24328887462615967
Batch 48/64 loss: 0.23648697137832642
Batch 49/64 loss: 0.24719750881195068
Batch 50/64 loss: 0.24606448411941528
Batch 51/64 loss: 0.2283005714416504
Batch 52/64 loss: 0.23548316955566406
Batch 53/64 loss: 0.244948148727417
Batch 54/64 loss: 0.24226319789886475
Batch 55/64 loss: 0.23346960544586182
Batch 56/64 loss: 0.23969364166259766
Batch 57/64 loss: 0.23246318101882935
Batch 58/64 loss: 0.23901617527008057
Batch 59/64 loss: 0.24155616760253906
Batch 60/64 loss: 0.24009788036346436
Batch 61/64 loss: 0.24234658479690552
Batch 62/64 loss: 0.2393079400062561
Batch 63/64 loss: 0.23666608333587646
Batch 64/64 loss: 0.23390018939971924
Epoch 361  Train loss: 0.2396189488616644  Val loss: 0.2830867843119959
Epoch 362
-------------------------------
Batch 1/64 loss: 0.2328055500984192
Batch 2/64 loss: 0.2341979742050171
Batch 3/64 loss: 0.23127001523971558
Batch 4/64 loss: 0.23119890689849854
Batch 5/64 loss: 0.23686683177947998
Batch 6/64 loss: 0.2410060167312622
Batch 7/64 loss: 0.24011975526809692
Batch 8/64 loss: 0.2316732406616211
Batch 9/64 loss: 0.24671030044555664
Batch 10/64 loss: 0.23203933238983154
Batch 11/64 loss: 0.24813538789749146
Batch 12/64 loss: 0.2431570291519165
Batch 13/64 loss: 0.24300873279571533
Batch 14/64 loss: 0.23374545574188232
Batch 15/64 loss: 0.24571335315704346
Batch 16/64 loss: 0.2359810471534729
Batch 17/64 loss: 0.23818814754486084
Batch 18/64 loss: 0.2385808229446411
Batch 19/64 loss: 0.23775750398635864
Batch 20/64 loss: 0.2455289363861084
Batch 21/64 loss: 0.236120343208313
Batch 22/64 loss: 0.23550134897232056
Batch 23/64 loss: 0.2538607716560364
Batch 24/64 loss: 0.23536360263824463
Batch 25/64 loss: 0.2509429454803467
Batch 26/64 loss: 0.24478423595428467
Batch 27/64 loss: 0.2443464994430542
Batch 28/64 loss: 0.24140161275863647
Batch 29/64 loss: 0.2443060278892517
Batch 30/64 loss: 0.247430682182312
Batch 31/64 loss: 0.23999834060668945
Batch 32/64 loss: 0.23301631212234497
Batch 33/64 loss: 0.24950528144836426
Batch 34/64 loss: 0.24019920825958252
Batch 35/64 loss: 0.24185091257095337
Batch 36/64 loss: 0.24219059944152832
Batch 37/64 loss: 0.23542237281799316
Batch 38/64 loss: 0.238838791847229
Batch 39/64 loss: 0.24729466438293457
Batch 40/64 loss: 0.24245685338974
Batch 41/64 loss: 0.24069035053253174
Batch 42/64 loss: 0.23803257942199707
Batch 43/64 loss: 0.24677801132202148
Batch 44/64 loss: 0.24143695831298828
Batch 45/64 loss: 0.24176263809204102
Batch 46/64 loss: 0.2501201629638672
Batch 47/64 loss: 0.23577922582626343
Batch 48/64 loss: 0.24150526523590088
Batch 49/64 loss: 0.2482752799987793
Batch 50/64 loss: 0.24532699584960938
Batch 51/64 loss: 0.24651622772216797
Batch 52/64 loss: 0.23610007762908936
Batch 53/64 loss: 0.23828577995300293
Batch 54/64 loss: 0.24354863166809082
Batch 55/64 loss: 0.23879867792129517
Batch 56/64 loss: 0.24310302734375
Batch 57/64 loss: 0.23228400945663452
Batch 58/64 loss: 0.240028977394104
Batch 59/64 loss: 0.23714303970336914
Batch 60/64 loss: 0.23841512203216553
Batch 61/64 loss: 0.2344522476196289
Batch 62/64 loss: 0.22604763507843018
Batch 63/64 loss: 0.2320770025253296
Batch 64/64 loss: 0.24058687686920166
Epoch 362  Train loss: 0.24014845221650366  Val loss: 0.28316298915758165
Epoch 363
-------------------------------
Batch 1/64 loss: 0.2403724193572998
Batch 2/64 loss: 0.24591726064682007
Batch 3/64 loss: 0.23290735483169556
Batch 4/64 loss: 0.22979414463043213
Batch 5/64 loss: 0.2507338523864746
Batch 6/64 loss: 0.24577248096466064
Batch 7/64 loss: 0.24293386936187744
Batch 8/64 loss: 0.23361563682556152
Batch 9/64 loss: 0.23548197746276855
Batch 10/64 loss: 0.2437768578529358
Batch 11/64 loss: 0.2323157787322998
Batch 12/64 loss: 0.23076224327087402
Batch 13/64 loss: 0.23203128576278687
Batch 14/64 loss: 0.23244792222976685
Batch 15/64 loss: 0.24406838417053223
Batch 16/64 loss: 0.25163888931274414
Batch 17/64 loss: 0.24476724863052368
Batch 18/64 loss: 0.2506529688835144
Batch 19/64 loss: 0.23601269721984863
Batch 20/64 loss: 0.2366045117378235
Batch 21/64 loss: 0.24267739057540894
Batch 22/64 loss: 0.23847568035125732
Batch 23/64 loss: 0.24854117631912231
Batch 24/64 loss: 0.2393968105316162
Batch 25/64 loss: 0.24235951900482178
Batch 26/64 loss: 0.24601763486862183
Batch 27/64 loss: 0.23334777355194092
Batch 28/64 loss: 0.23284447193145752
Batch 29/64 loss: 0.2489681839942932
Batch 30/64 loss: 0.22996819019317627
Batch 31/64 loss: 0.24820148944854736
Batch 32/64 loss: 0.2341741919517517
Batch 33/64 loss: 0.23681074380874634
Batch 34/64 loss: 0.24217760562896729
Batch 35/64 loss: 0.23354363441467285
Batch 36/64 loss: 0.24191021919250488
Batch 37/64 loss: 0.23605000972747803
Batch 38/64 loss: 0.23001593351364136
Batch 39/64 loss: 0.2511380910873413
Batch 40/64 loss: 0.24886083602905273
Batch 41/64 loss: 0.23704081773757935
Batch 42/64 loss: 0.24336493015289307
Batch 43/64 loss: 0.24111902713775635
Batch 44/64 loss: 0.23925042152404785
Batch 45/64 loss: 0.23041081428527832
Batch 46/64 loss: 0.24049162864685059
Batch 47/64 loss: 0.23957431316375732
Batch 48/64 loss: 0.24917960166931152
Batch 49/64 loss: 0.2497173547744751
Batch 50/64 loss: 0.2442159652709961
Batch 51/64 loss: 0.24756407737731934
Batch 52/64 loss: 0.23442316055297852
Batch 53/64 loss: 0.23914510011672974
Batch 54/64 loss: 0.22844457626342773
Batch 55/64 loss: 0.24444198608398438
Batch 56/64 loss: 0.2382570505142212
Batch 57/64 loss: 0.23977971076965332
Batch 58/64 loss: 0.2340003252029419
Batch 59/64 loss: 0.25101006031036377
Batch 60/64 loss: 0.23962855339050293
Batch 61/64 loss: 0.23412549495697021
Batch 62/64 loss: 0.23294830322265625
Batch 63/64 loss: 0.24363350868225098
Batch 64/64 loss: 0.24784451723098755
Epoch 363  Train loss: 0.24009000062942504  Val loss: 0.2827952977308293
Epoch 364
-------------------------------
Batch 1/64 loss: 0.24710428714752197
Batch 2/64 loss: 0.241441547870636
Batch 3/64 loss: 0.23790371417999268
Batch 4/64 loss: 0.2357271909713745
Batch 5/64 loss: 0.24078333377838135
Batch 6/64 loss: 0.24106323719024658
Batch 7/64 loss: 0.23871099948883057
Batch 8/64 loss: 0.2231975793838501
Batch 9/64 loss: 0.24662721157073975
Batch 10/64 loss: 0.23994123935699463
Batch 11/64 loss: 0.23085260391235352
Batch 12/64 loss: 0.2515455484390259
Batch 13/64 loss: 0.2425013780593872
Batch 14/64 loss: 0.2409883737564087
Batch 15/64 loss: 0.24066215753555298
Batch 16/64 loss: 0.2372702956199646
Batch 17/64 loss: 0.23868560791015625
Batch 18/64 loss: 0.2380160689353943
Batch 19/64 loss: 0.23286831378936768
Batch 20/64 loss: 0.23096704483032227
Batch 21/64 loss: 0.238081157207489
Batch 22/64 loss: 0.23295044898986816
Batch 23/64 loss: 0.23282384872436523
Batch 24/64 loss: 0.23655450344085693
Batch 25/64 loss: 0.23321443796157837
Batch 26/64 loss: 0.23745465278625488
Batch 27/64 loss: 0.2370949387550354
Batch 28/64 loss: 0.24818849563598633
Batch 29/64 loss: 0.2487884759902954
Batch 30/64 loss: 0.23499435186386108
Batch 31/64 loss: 0.24127542972564697
Batch 32/64 loss: 0.23512834310531616
Batch 33/64 loss: 0.242537260055542
Batch 34/64 loss: 0.23372936248779297
Batch 35/64 loss: 0.25653475522994995
Batch 36/64 loss: 0.24198031425476074
Batch 37/64 loss: 0.2398439645767212
Batch 38/64 loss: 0.23058360815048218
Batch 39/64 loss: 0.2327197790145874
Batch 40/64 loss: 0.23658537864685059
Batch 41/64 loss: 0.2369370460510254
Batch 42/64 loss: 0.24349874258041382
Batch 43/64 loss: 0.24941861629486084
Batch 44/64 loss: 0.24818480014801025
Batch 45/64 loss: 0.24096477031707764
Batch 46/64 loss: 0.241835355758667
Batch 47/64 loss: 0.24036991596221924
Batch 48/64 loss: 0.23664391040802002
Batch 49/64 loss: 0.23593097925186157
Batch 50/64 loss: 0.24085783958435059
Batch 51/64 loss: 0.24884581565856934
Batch 52/64 loss: 0.23452484607696533
Batch 53/64 loss: 0.23664939403533936
Batch 54/64 loss: 0.25399506092071533
Batch 55/64 loss: 0.238988995552063
Batch 56/64 loss: 0.2456817626953125
Batch 57/64 loss: 0.2389158010482788
Batch 58/64 loss: 0.23147320747375488
Batch 59/64 loss: 0.23792070150375366
Batch 60/64 loss: 0.2414371371269226
Batch 61/64 loss: 0.23025643825531006
Batch 62/64 loss: 0.23934710025787354
Batch 63/64 loss: 0.24370229244232178
Batch 64/64 loss: 0.2463991641998291
Epoch 364  Train loss: 0.23951531204522825  Val loss: 0.28262254913238316
Epoch 365
-------------------------------
Batch 1/64 loss: 0.24480372667312622
Batch 2/64 loss: 0.24692535400390625
Batch 3/64 loss: 0.2418445348739624
Batch 4/64 loss: 0.2336411476135254
Batch 5/64 loss: 0.24455392360687256
Batch 6/64 loss: 0.2414020299911499
Batch 7/64 loss: 0.2434033751487732
Batch 8/64 loss: 0.24626505374908447
Batch 9/64 loss: 0.23761683702468872
Batch 10/64 loss: 0.235845148563385
Batch 11/64 loss: 0.2368701696395874
Batch 12/64 loss: 0.23708570003509521
Batch 13/64 loss: 0.239315927028656
Batch 14/64 loss: 0.2313191294670105
Batch 15/64 loss: 0.23248255252838135
Batch 16/64 loss: 0.2459425926208496
Batch 17/64 loss: 0.23917537927627563
Batch 18/64 loss: 0.23828959465026855
Batch 19/64 loss: 0.23371994495391846
Batch 20/64 loss: 0.2389984130859375
Batch 21/64 loss: 0.24315619468688965
Batch 22/64 loss: 0.23594576120376587
Batch 23/64 loss: 0.23284292221069336
Batch 24/64 loss: 0.2550871968269348
Batch 25/64 loss: 0.23761975765228271
Batch 26/64 loss: 0.2353752851486206
Batch 27/64 loss: 0.24631178379058838
Batch 28/64 loss: 0.23242247104644775
Batch 29/64 loss: 0.23308980464935303
Batch 30/64 loss: 0.2395845651626587
Batch 31/64 loss: 0.23238617181777954
Batch 32/64 loss: 0.23899590969085693
Batch 33/64 loss: 0.22949481010437012
Batch 34/64 loss: 0.2299773097038269
Batch 35/64 loss: 0.235113263130188
Batch 36/64 loss: 0.2373511791229248
Batch 37/64 loss: 0.24509525299072266
Batch 38/64 loss: 0.24175572395324707
Batch 39/64 loss: 0.23715460300445557
Batch 40/64 loss: 0.24014604091644287
Batch 41/64 loss: 0.23261237144470215
Batch 42/64 loss: 0.232252299785614
Batch 43/64 loss: 0.22871261835098267
Batch 44/64 loss: 0.25027960538864136
Batch 45/64 loss: 0.23758536577224731
Batch 46/64 loss: 0.2510219216346741
Batch 47/64 loss: 0.22943854331970215
Batch 48/64 loss: 0.23982477188110352
Batch 49/64 loss: 0.23969513177871704
Batch 50/64 loss: 0.24169981479644775
Batch 51/64 loss: 0.2556917667388916
Batch 52/64 loss: 0.24347639083862305
Batch 53/64 loss: 0.23108088970184326
Batch 54/64 loss: 0.247919499874115
Batch 55/64 loss: 0.23741644620895386
Batch 56/64 loss: 0.24017512798309326
Batch 57/64 loss: 0.2400350570678711
Batch 58/64 loss: 0.24195456504821777
Batch 59/64 loss: 0.24726104736328125
Batch 60/64 loss: 0.23230111598968506
Batch 61/64 loss: 0.2506226897239685
Batch 62/64 loss: 0.25258493423461914
Batch 63/64 loss: 0.23582327365875244
Batch 64/64 loss: 0.2442474365234375
Epoch 365  Train loss: 0.23954599791882084  Val loss: 0.2830942066264726
Epoch 366
-------------------------------
Batch 1/64 loss: 0.22917437553405762
Batch 2/64 loss: 0.2454596757888794
Batch 3/64 loss: 0.23612582683563232
Batch 4/64 loss: 0.23867452144622803
Batch 5/64 loss: 0.24750065803527832
Batch 6/64 loss: 0.23977982997894287
Batch 7/64 loss: 0.2394862174987793
Batch 8/64 loss: 0.2291419506072998
Batch 9/64 loss: 0.23317742347717285
Batch 10/64 loss: 0.2388971447944641
Batch 11/64 loss: 0.24278491735458374
Batch 12/64 loss: 0.24073833227157593
Batch 13/64 loss: 0.23201680183410645
Batch 14/64 loss: 0.24137723445892334
Batch 15/64 loss: 0.22785687446594238
Batch 16/64 loss: 0.24562782049179077
Batch 17/64 loss: 0.23441874980926514
Batch 18/64 loss: 0.23516321182250977
Batch 19/64 loss: 0.23714804649353027
Batch 20/64 loss: 0.23629742860794067
Batch 21/64 loss: 0.23795020580291748
Batch 22/64 loss: 0.23391640186309814
Batch 23/64 loss: 0.24788081645965576
Batch 24/64 loss: 0.23838746547698975
Batch 25/64 loss: 0.24350595474243164
Batch 26/64 loss: 0.24138808250427246
Batch 27/64 loss: 0.25076234340667725
Batch 28/64 loss: 0.23676669597625732
Batch 29/64 loss: 0.23907417058944702
Batch 30/64 loss: 0.23922139406204224
Batch 31/64 loss: 0.24298030138015747
Batch 32/64 loss: 0.24602371454238892
Batch 33/64 loss: 0.25843316316604614
Batch 34/64 loss: 0.2334073781967163
Batch 35/64 loss: 0.23465943336486816
Batch 36/64 loss: 0.2392517328262329
Batch 37/64 loss: 0.23806756734848022
Batch 38/64 loss: 0.22945988178253174
Batch 39/64 loss: 0.23476707935333252
Batch 40/64 loss: 0.2431311011314392
Batch 41/64 loss: 0.24564790725708008
Batch 42/64 loss: 0.24067401885986328
Batch 43/64 loss: 0.24370044469833374
Batch 44/64 loss: 0.2328348159790039
Batch 45/64 loss: 0.23854297399520874
Batch 46/64 loss: 0.23583459854125977
Batch 47/64 loss: 0.22990989685058594
Batch 48/64 loss: 0.2452836036682129
Batch 49/64 loss: 0.23115968704223633
Batch 50/64 loss: 0.2428939938545227
Batch 51/64 loss: 0.24604564905166626
Batch 52/64 loss: 0.2423340082168579
Batch 53/64 loss: 0.24142009019851685
Batch 54/64 loss: 0.24360907077789307
Batch 55/64 loss: 0.24010193347930908
Batch 56/64 loss: 0.2511204481124878
Batch 57/64 loss: 0.2371748685836792
Batch 58/64 loss: 0.24528300762176514
Batch 59/64 loss: 0.24446547031402588
Batch 60/64 loss: 0.23422664403915405
Batch 61/64 loss: 0.23761194944381714
Batch 62/64 loss: 0.2437242865562439
Batch 63/64 loss: 0.23958086967468262
Batch 64/64 loss: 0.23175621032714844
Epoch 366  Train loss: 0.2394804599238377  Val loss: 0.28211462579641966
Epoch 367
-------------------------------
Batch 1/64 loss: 0.23352432250976562
Batch 2/64 loss: 0.24031192064285278
Batch 3/64 loss: 0.2348853349685669
Batch 4/64 loss: 0.23567867279052734
Batch 5/64 loss: 0.22983551025390625
Batch 6/64 loss: 0.24117577075958252
Batch 7/64 loss: 0.2494279146194458
Batch 8/64 loss: 0.23581600189208984
Batch 9/64 loss: 0.23083597421646118
Batch 10/64 loss: 0.23196208477020264
Batch 11/64 loss: 0.2403109073638916
Batch 12/64 loss: 0.23294419050216675
Batch 13/64 loss: 0.23843997716903687
Batch 14/64 loss: 0.25136423110961914
Batch 15/64 loss: 0.23105347156524658
Batch 16/64 loss: 0.23655188083648682
Batch 17/64 loss: 0.24072915315628052
Batch 18/64 loss: 0.25471895933151245
Batch 19/64 loss: 0.24462544918060303
Batch 20/64 loss: 0.2409682273864746
Batch 21/64 loss: 0.2589069604873657
Batch 22/64 loss: 0.23416882753372192
Batch 23/64 loss: 0.24642974138259888
Batch 24/64 loss: 0.23434531688690186
Batch 25/64 loss: 0.2555626630783081
Batch 26/64 loss: 0.24144411087036133
Batch 27/64 loss: 0.23881906270980835
Batch 28/64 loss: 0.2400151491165161
Batch 29/64 loss: 0.23799049854278564
Batch 30/64 loss: 0.23301208019256592
Batch 31/64 loss: 0.23699772357940674
Batch 32/64 loss: 0.2512636184692383
Batch 33/64 loss: 0.22910237312316895
Batch 34/64 loss: 0.2474527359008789
Batch 35/64 loss: 0.24555110931396484
Batch 36/64 loss: 0.24311161041259766
Batch 37/64 loss: 0.2336428165435791
Batch 38/64 loss: 0.24491941928863525
Batch 39/64 loss: 0.2440626621246338
Batch 40/64 loss: 0.23658573627471924
Batch 41/64 loss: 0.24022233486175537
Batch 42/64 loss: 0.2606050968170166
Batch 43/64 loss: 0.23450911045074463
Batch 44/64 loss: 0.22853970527648926
Batch 45/64 loss: 0.24042022228240967
Batch 46/64 loss: 0.2284489870071411
Batch 47/64 loss: 0.23277074098587036
Batch 48/64 loss: 0.23773115873336792
Batch 49/64 loss: 0.22721362113952637
Batch 50/64 loss: 0.24327057600021362
Batch 51/64 loss: 0.24673306941986084
Batch 52/64 loss: 0.2402026653289795
Batch 53/64 loss: 0.23413711786270142
Batch 54/64 loss: 0.2378448247909546
Batch 55/64 loss: 0.2410426139831543
Batch 56/64 loss: 0.23892319202423096
Batch 57/64 loss: 0.24245047569274902
Batch 58/64 loss: 0.23835408687591553
Batch 59/64 loss: 0.24477612972259521
Batch 60/64 loss: 0.2424030303955078
Batch 61/64 loss: 0.23372483253479004
Batch 62/64 loss: 0.24436414241790771
Batch 63/64 loss: 0.23759138584136963
Batch 64/64 loss: 0.23329460620880127
Epoch 367  Train loss: 0.23968304699542475  Val loss: 0.28187452620247383
Epoch 368
-------------------------------
Batch 1/64 loss: 0.22576022148132324
Batch 2/64 loss: 0.22941362857818604
Batch 3/64 loss: 0.22782468795776367
Batch 4/64 loss: 0.2352617383003235
Batch 5/64 loss: 0.23763978481292725
Batch 6/64 loss: 0.22166651487350464
Batch 7/64 loss: 0.23065054416656494
Batch 8/64 loss: 0.23749017715454102
Batch 9/64 loss: 0.2436668872833252
Batch 10/64 loss: 0.2423003911972046
Batch 11/64 loss: 0.24549782276153564
Batch 12/64 loss: 0.2374945878982544
Batch 13/64 loss: 0.24103033542633057
Batch 14/64 loss: 0.23586535453796387
Batch 15/64 loss: 0.2320406436920166
Batch 16/64 loss: 0.24485671520233154
Batch 17/64 loss: 0.23947161436080933
Batch 18/64 loss: 0.243333637714386
Batch 19/64 loss: 0.23951220512390137
Batch 20/64 loss: 0.22431087493896484
Batch 21/64 loss: 0.23920667171478271
Batch 22/64 loss: 0.23515063524246216
Batch 23/64 loss: 0.24833756685256958
Batch 24/64 loss: 0.26087242364883423
Batch 25/64 loss: 0.24438905715942383
Batch 26/64 loss: 0.23524510860443115
Batch 27/64 loss: 0.23562973737716675
Batch 28/64 loss: 0.23977380990982056
Batch 29/64 loss: 0.240281879901886
Batch 30/64 loss: 0.24102848768234253
Batch 31/64 loss: 0.23447179794311523
Batch 32/64 loss: 0.2416035532951355
Batch 33/64 loss: 0.23385179042816162
Batch 34/64 loss: 0.24894952774047852
Batch 35/64 loss: 0.22884851694107056
Batch 36/64 loss: 0.23710405826568604
Batch 37/64 loss: 0.2416108250617981
Batch 38/64 loss: 0.2367103099822998
Batch 39/64 loss: 0.24730658531188965
Batch 40/64 loss: 0.23330163955688477
Batch 41/64 loss: 0.24118733406066895
Batch 42/64 loss: 0.24338316917419434
Batch 43/64 loss: 0.23425859212875366
Batch 44/64 loss: 0.23361515998840332
Batch 45/64 loss: 0.24131178855895996
Batch 46/64 loss: 0.2374475598335266
Batch 47/64 loss: 0.23909729719161987
Batch 48/64 loss: 0.24519950151443481
Batch 49/64 loss: 0.23823153972625732
Batch 50/64 loss: 0.244179368019104
Batch 51/64 loss: 0.24894976615905762
Batch 52/64 loss: 0.2362370491027832
Batch 53/64 loss: 0.24888277053833008
Batch 54/64 loss: 0.2371811866760254
Batch 55/64 loss: 0.23903286457061768
Batch 56/64 loss: 0.23933428525924683
Batch 57/64 loss: 0.23728233575820923
Batch 58/64 loss: 0.2356107234954834
Batch 59/64 loss: 0.23837244510650635
Batch 60/64 loss: 0.25492537021636963
Batch 61/64 loss: 0.23699772357940674
Batch 62/64 loss: 0.2386118769645691
Batch 63/64 loss: 0.23739409446716309
Batch 64/64 loss: 0.24448740482330322
Epoch 368  Train loss: 0.23888394832611085  Val loss: 0.28210640178922936
Epoch 369
-------------------------------
Batch 1/64 loss: 0.245003342628479
Batch 2/64 loss: 0.22816503047943115
Batch 3/64 loss: 0.22926867008209229
Batch 4/64 loss: 0.24566292762756348
Batch 5/64 loss: 0.2464522123336792
Batch 6/64 loss: 0.24391233921051025
Batch 7/64 loss: 0.2362232208251953
Batch 8/64 loss: 0.23584520816802979
Batch 9/64 loss: 0.2290482521057129
Batch 10/64 loss: 0.25089526176452637
Batch 11/64 loss: 0.24105572700500488
Batch 12/64 loss: 0.23272705078125
Batch 13/64 loss: 0.24080896377563477
Batch 14/64 loss: 0.24170494079589844
Batch 15/64 loss: 0.23728519678115845
Batch 16/64 loss: 0.2366161346435547
Batch 17/64 loss: 0.23645591735839844
Batch 18/64 loss: 0.23444068431854248
Batch 19/64 loss: 0.23758411407470703
Batch 20/64 loss: 0.2359938621520996
Batch 21/64 loss: 0.23817718029022217
Batch 22/64 loss: 0.23525947332382202
Batch 23/64 loss: 0.2360624074935913
Batch 24/64 loss: 0.23967242240905762
Batch 25/64 loss: 0.24295783042907715
Batch 26/64 loss: 0.25515955686569214
Batch 27/64 loss: 0.24450141191482544
Batch 28/64 loss: 0.24400103092193604
Batch 29/64 loss: 0.24137532711029053
Batch 30/64 loss: 0.22945547103881836
Batch 31/64 loss: 0.23096132278442383
Batch 32/64 loss: 0.2369154691696167
Batch 33/64 loss: 0.2338646650314331
Batch 34/64 loss: 0.24386334419250488
Batch 35/64 loss: 0.23654377460479736
Batch 36/64 loss: 0.23917549848556519
Batch 37/64 loss: 0.23763585090637207
Batch 38/64 loss: 0.2414647936820984
Batch 39/64 loss: 0.23673105239868164
Batch 40/64 loss: 0.23414134979248047
Batch 41/64 loss: 0.23436468839645386
Batch 42/64 loss: 0.23557579517364502
Batch 43/64 loss: 0.24148601293563843
Batch 44/64 loss: 0.23635029792785645
Batch 45/64 loss: 0.2381434440612793
Batch 46/64 loss: 0.24520152807235718
Batch 47/64 loss: 0.22742211818695068
Batch 48/64 loss: 0.2269841432571411
Batch 49/64 loss: 0.24477159976959229
Batch 50/64 loss: 0.24248206615447998
Batch 51/64 loss: 0.24527692794799805
Batch 52/64 loss: 0.23818153142929077
Batch 53/64 loss: 0.22795891761779785
Batch 54/64 loss: 0.2408987283706665
Batch 55/64 loss: 0.2462761402130127
Batch 56/64 loss: 0.24049699306488037
Batch 57/64 loss: 0.23733270168304443
Batch 58/64 loss: 0.24272644519805908
Batch 59/64 loss: 0.23429155349731445
Batch 60/64 loss: 0.2433556318283081
Batch 61/64 loss: 0.23174434900283813
Batch 62/64 loss: 0.24139404296875
Batch 63/64 loss: 0.24065792560577393
Batch 64/64 loss: 0.24076253175735474
Epoch 369  Train loss: 0.2385413924853007  Val loss: 0.28133621781142715
Saving best model, epoch: 369
Epoch 370
-------------------------------
Batch 1/64 loss: 0.23977220058441162
Batch 2/64 loss: 0.23447930812835693
Batch 3/64 loss: 0.23901641368865967
Batch 4/64 loss: 0.23098701238632202
Batch 5/64 loss: 0.24732303619384766
Batch 6/64 loss: 0.24453169107437134
Batch 7/64 loss: 0.23524129390716553
Batch 8/64 loss: 0.22792357206344604
Batch 9/64 loss: 0.2386714220046997
Batch 10/64 loss: 0.24013137817382812
Batch 11/64 loss: 0.2432337999343872
Batch 12/64 loss: 0.2357553243637085
Batch 13/64 loss: 0.2355036735534668
Batch 14/64 loss: 0.2348577380180359
Batch 15/64 loss: 0.24224752187728882
Batch 16/64 loss: 0.24897730350494385
Batch 17/64 loss: 0.2412710189819336
Batch 18/64 loss: 0.23895537853240967
Batch 19/64 loss: 0.23245561122894287
Batch 20/64 loss: 0.22987228631973267
Batch 21/64 loss: 0.23227357864379883
Batch 22/64 loss: 0.23387479782104492
Batch 23/64 loss: 0.23772430419921875
Batch 24/64 loss: 0.24602913856506348
Batch 25/64 loss: 0.24300873279571533
Batch 26/64 loss: 0.2309049367904663
Batch 27/64 loss: 0.2371867299079895
Batch 28/64 loss: 0.23521190881729126
Batch 29/64 loss: 0.24075818061828613
Batch 30/64 loss: 0.23438775539398193
Batch 31/64 loss: 0.24693530797958374
Batch 32/64 loss: 0.2354806661605835
Batch 33/64 loss: 0.2420417070388794
Batch 34/64 loss: 0.2439163327217102
Batch 35/64 loss: 0.24879992008209229
Batch 36/64 loss: 0.2331310510635376
Batch 37/64 loss: 0.2376854419708252
Batch 38/64 loss: 0.24305713176727295
Batch 39/64 loss: 0.2323000431060791
Batch 40/64 loss: 0.2258005142211914
Batch 41/64 loss: 0.23992717266082764
Batch 42/64 loss: 0.23307901620864868
Batch 43/64 loss: 0.23034876585006714
Batch 44/64 loss: 0.24814128875732422
Batch 45/64 loss: 0.24928522109985352
Batch 46/64 loss: 0.2314559817314148
Batch 47/64 loss: 0.24643796682357788
Batch 48/64 loss: 0.23034441471099854
Batch 49/64 loss: 0.2501002550125122
Batch 50/64 loss: 0.22804051637649536
Batch 51/64 loss: 0.23461401462554932
Batch 52/64 loss: 0.22942256927490234
Batch 53/64 loss: 0.241030752658844
Batch 54/64 loss: 0.24626731872558594
Batch 55/64 loss: 0.23418521881103516
Batch 56/64 loss: 0.23786628246307373
Batch 57/64 loss: 0.24100160598754883
Batch 58/64 loss: 0.240797758102417
Batch 59/64 loss: 0.23134398460388184
Batch 60/64 loss: 0.2582489252090454
Batch 61/64 loss: 0.23055893182754517
Batch 62/64 loss: 0.251120388507843
Batch 63/64 loss: 0.23667699098587036
Batch 64/64 loss: 0.2410198450088501
Epoch 370  Train loss: 0.238474908062056  Val loss: 0.28178329852848116
Epoch 371
-------------------------------
Batch 1/64 loss: 0.22737789154052734
Batch 2/64 loss: 0.23289364576339722
Batch 3/64 loss: 0.23361128568649292
Batch 4/64 loss: 0.2363206148147583
Batch 5/64 loss: 0.23125755786895752
Batch 6/64 loss: 0.23620867729187012
Batch 7/64 loss: 0.23736464977264404
Batch 8/64 loss: 0.2365800142288208
Batch 9/64 loss: 0.24474883079528809
Batch 10/64 loss: 0.23842763900756836
Batch 11/64 loss: 0.24507546424865723
Batch 12/64 loss: 0.23869729042053223
Batch 13/64 loss: 0.2455260157585144
Batch 14/64 loss: 0.245045006275177
Batch 15/64 loss: 0.23164361715316772
Batch 16/64 loss: 0.24017012119293213
Batch 17/64 loss: 0.24157100915908813
Batch 18/64 loss: 0.24317747354507446
Batch 19/64 loss: 0.25281405448913574
Batch 20/64 loss: 0.2348576784133911
Batch 21/64 loss: 0.23545634746551514
Batch 22/64 loss: 0.23375821113586426
Batch 23/64 loss: 0.23294150829315186
Batch 24/64 loss: 0.23610758781433105
Batch 25/64 loss: 0.23688548803329468
Batch 26/64 loss: 0.2400684952735901
Batch 27/64 loss: 0.23608678579330444
Batch 28/64 loss: 0.2402765154838562
Batch 29/64 loss: 0.24006938934326172
Batch 30/64 loss: 0.23495322465896606
Batch 31/64 loss: 0.2285591959953308
Batch 32/64 loss: 0.2280881404876709
Batch 33/64 loss: 0.23762845993041992
Batch 34/64 loss: 0.2377912998199463
Batch 35/64 loss: 0.24849683046340942
Batch 36/64 loss: 0.24303162097930908
Batch 37/64 loss: 0.256051242351532
Batch 38/64 loss: 0.23732388019561768
Batch 39/64 loss: 0.23874008655548096
Batch 40/64 loss: 0.24181783199310303
Batch 41/64 loss: 0.2349001169204712
Batch 42/64 loss: 0.24183183908462524
Batch 43/64 loss: 0.24267446994781494
Batch 44/64 loss: 0.24139153957366943
Batch 45/64 loss: 0.23695486783981323
Batch 46/64 loss: 0.24296116828918457
Batch 47/64 loss: 0.24558836221694946
Batch 48/64 loss: 0.24858033657073975
Batch 49/64 loss: 0.24575316905975342
Batch 50/64 loss: 0.2365936040878296
Batch 51/64 loss: 0.24392032623291016
Batch 52/64 loss: 0.24356824159622192
Batch 53/64 loss: 0.23405182361602783
Batch 54/64 loss: 0.2406376600265503
Batch 55/64 loss: 0.2469923496246338
Batch 56/64 loss: 0.24503356218338013
Batch 57/64 loss: 0.23965418338775635
Batch 58/64 loss: 0.2436281442642212
Batch 59/64 loss: 0.2377692461013794
Batch 60/64 loss: 0.23830312490463257
Batch 61/64 loss: 0.2480853796005249
Batch 62/64 loss: 0.24861550331115723
Batch 63/64 loss: 0.24255728721618652
Batch 64/64 loss: 0.24674153327941895
Epoch 371  Train loss: 0.23988397074680703  Val loss: 0.28157546655418947
Epoch 372
-------------------------------
Batch 1/64 loss: 0.2483730912208557
Batch 2/64 loss: 0.2361752986907959
Batch 3/64 loss: 0.24419403076171875
Batch 4/64 loss: 0.23127079010009766
Batch 5/64 loss: 0.24108123779296875
Batch 6/64 loss: 0.24637055397033691
Batch 7/64 loss: 0.23630297183990479
Batch 8/64 loss: 0.2392907738685608
Batch 9/64 loss: 0.23455119132995605
Batch 10/64 loss: 0.24209308624267578
Batch 11/64 loss: 0.23045170307159424
Batch 12/64 loss: 0.2354496717453003
Batch 13/64 loss: 0.22738415002822876
Batch 14/64 loss: 0.24163222312927246
Batch 15/64 loss: 0.23426377773284912
Batch 16/64 loss: 0.23100131750106812
Batch 17/64 loss: 0.24179506301879883
Batch 18/64 loss: 0.24081116914749146
Batch 19/64 loss: 0.24515962600708008
Batch 20/64 loss: 0.22622591257095337
Batch 21/64 loss: 0.23963695764541626
Batch 22/64 loss: 0.229225754737854
Batch 23/64 loss: 0.23278486728668213
Batch 24/64 loss: 0.22793537378311157
Batch 25/64 loss: 0.25045955181121826
Batch 26/64 loss: 0.2421015501022339
Batch 27/64 loss: 0.23446643352508545
Batch 28/64 loss: 0.24927937984466553
Batch 29/64 loss: 0.23451459407806396
Batch 30/64 loss: 0.2424837350845337
Batch 31/64 loss: 0.25131702423095703
Batch 32/64 loss: 0.2403881549835205
Batch 33/64 loss: 0.24031591415405273
Batch 34/64 loss: 0.24397003650665283
Batch 35/64 loss: 0.2557303309440613
Batch 36/64 loss: 0.2385823130607605
Batch 37/64 loss: 0.24064528942108154
Batch 38/64 loss: 0.24401211738586426
Batch 39/64 loss: 0.24629396200180054
Batch 40/64 loss: 0.25039827823638916
Batch 41/64 loss: 0.2371373176574707
Batch 42/64 loss: 0.2464362382888794
Batch 43/64 loss: 0.24133676290512085
Batch 44/64 loss: 0.24758940935134888
Batch 45/64 loss: 0.24466198682785034
Batch 46/64 loss: 0.2472749948501587
Batch 47/64 loss: 0.24526220560073853
Batch 48/64 loss: 0.22884154319763184
Batch 49/64 loss: 0.2498934268951416
Batch 50/64 loss: 0.2417839765548706
Batch 51/64 loss: 0.24528765678405762
Batch 52/64 loss: 0.23941147327423096
Batch 53/64 loss: 0.24556076526641846
Batch 54/64 loss: 0.2427748441696167
Batch 55/64 loss: 0.24695825576782227
Batch 56/64 loss: 0.23061716556549072
Batch 57/64 loss: 0.23955553770065308
Batch 58/64 loss: 0.2347767949104309
Batch 59/64 loss: 0.24272948503494263
Batch 60/64 loss: 0.23110365867614746
Batch 61/64 loss: 0.24097073078155518
Batch 62/64 loss: 0.23115277290344238
Batch 63/64 loss: 0.23573732376098633
Batch 64/64 loss: 0.23355019092559814
Epoch 372  Train loss: 0.24000684280021517  Val loss: 0.2828072948554127
Epoch 373
-------------------------------
Batch 1/64 loss: 0.23408359289169312
Batch 2/64 loss: 0.24142330884933472
Batch 3/64 loss: 0.23912477493286133
Batch 4/64 loss: 0.23313260078430176
Batch 5/64 loss: 0.2281961441040039
Batch 6/64 loss: 0.23764526844024658
Batch 7/64 loss: 0.23418742418289185
Batch 8/64 loss: 0.23234879970550537
Batch 9/64 loss: 0.2480630874633789
Batch 10/64 loss: 0.23501408100128174
Batch 11/64 loss: 0.24072515964508057
Batch 12/64 loss: 0.236616849899292
Batch 13/64 loss: 0.23323559761047363
Batch 14/64 loss: 0.2462206482887268
Batch 15/64 loss: 0.2546982765197754
Batch 16/64 loss: 0.23488622903823853
Batch 17/64 loss: 0.24195820093154907
Batch 18/64 loss: 0.24444365501403809
Batch 19/64 loss: 0.23564112186431885
Batch 20/64 loss: 0.23180389404296875
Batch 21/64 loss: 0.255365252494812
Batch 22/64 loss: 0.2525938153266907
Batch 23/64 loss: 0.2467360496520996
Batch 24/64 loss: 0.242220938205719
Batch 25/64 loss: 0.24164605140686035
Batch 26/64 loss: 0.24841469526290894
Batch 27/64 loss: 0.22809767723083496
Batch 28/64 loss: 0.23427164554595947
Batch 29/64 loss: 0.23331427574157715
Batch 30/64 loss: 0.24697953462600708
Batch 31/64 loss: 0.23519057035446167
Batch 32/64 loss: 0.2391597032546997
Batch 33/64 loss: 0.2397426962852478
Batch 34/64 loss: 0.2442253828048706
Batch 35/64 loss: 0.23801863193511963
Batch 36/64 loss: 0.23188704252243042
Batch 37/64 loss: 0.23455268144607544
Batch 38/64 loss: 0.22978758811950684
Batch 39/64 loss: 0.23797178268432617
Batch 40/64 loss: 0.2449789047241211
Batch 41/64 loss: 0.22906309366226196
Batch 42/64 loss: 0.22370994091033936
Batch 43/64 loss: 0.23519176244735718
Batch 44/64 loss: 0.2501547932624817
Batch 45/64 loss: 0.23856580257415771
Batch 46/64 loss: 0.23675024509429932
Batch 47/64 loss: 0.2524142265319824
Batch 48/64 loss: 0.22943037748336792
Batch 49/64 loss: 0.23533159494400024
Batch 50/64 loss: 0.24273192882537842
Batch 51/64 loss: 0.24636846780776978
Batch 52/64 loss: 0.23646682500839233
Batch 53/64 loss: 0.24010425806045532
Batch 54/64 loss: 0.2480211853981018
Batch 55/64 loss: 0.22824114561080933
Batch 56/64 loss: 0.24685120582580566
Batch 57/64 loss: 0.2537374496459961
Batch 58/64 loss: 0.23494023084640503
Batch 59/64 loss: 0.24328649044036865
Batch 60/64 loss: 0.2379244565963745
Batch 61/64 loss: 0.2373218536376953
Batch 62/64 loss: 0.23670506477355957
Batch 63/64 loss: 0.24058693647384644
Batch 64/64 loss: 0.2386106252670288
Epoch 373  Train loss: 0.23923860297483557  Val loss: 0.28300931691304104
Epoch 374
-------------------------------
Batch 1/64 loss: 0.2374434471130371
Batch 2/64 loss: 0.23847520351409912
Batch 3/64 loss: 0.23629212379455566
Batch 4/64 loss: 0.2370074987411499
Batch 5/64 loss: 0.23283827304840088
Batch 6/64 loss: 0.23551714420318604
Batch 7/64 loss: 0.23358631134033203
Batch 8/64 loss: 0.23129284381866455
Batch 9/64 loss: 0.22973573207855225
Batch 10/64 loss: 0.23934119939804077
Batch 11/64 loss: 0.23212647438049316
Batch 12/64 loss: 0.2244553565979004
Batch 13/64 loss: 0.23854565620422363
Batch 14/64 loss: 0.22996342182159424
Batch 15/64 loss: 0.22809481620788574
Batch 16/64 loss: 0.249214768409729
Batch 17/64 loss: 0.24212157726287842
Batch 18/64 loss: 0.23789918422698975
Batch 19/64 loss: 0.23869025707244873
Batch 20/64 loss: 0.23271572589874268
Batch 21/64 loss: 0.23751604557037354
Batch 22/64 loss: 0.2368861436843872
Batch 23/64 loss: 0.22793644666671753
Batch 24/64 loss: 0.24164092540740967
Batch 25/64 loss: 0.24393141269683838
Batch 26/64 loss: 0.23242175579071045
Batch 27/64 loss: 0.2379656434059143
Batch 28/64 loss: 0.2379446029663086
Batch 29/64 loss: 0.23337239027023315
Batch 30/64 loss: 0.2501448392868042
Batch 31/64 loss: 0.23786306381225586
Batch 32/64 loss: 0.24241334199905396
Batch 33/64 loss: 0.23979127407073975
Batch 34/64 loss: 0.23611533641815186
Batch 35/64 loss: 0.2360469102859497
Batch 36/64 loss: 0.23639410734176636
Batch 37/64 loss: 0.2447029948234558
Batch 38/64 loss: 0.23436158895492554
Batch 39/64 loss: 0.23037689924240112
Batch 40/64 loss: 0.23782646656036377
Batch 41/64 loss: 0.2460004687309265
Batch 42/64 loss: 0.24573183059692383
Batch 43/64 loss: 0.24570190906524658
Batch 44/64 loss: 0.23803859949111938
Batch 45/64 loss: 0.24118149280548096
Batch 46/64 loss: 0.24373358488082886
Batch 47/64 loss: 0.23941141366958618
Batch 48/64 loss: 0.24395716190338135
Batch 49/64 loss: 0.2385948896408081
Batch 50/64 loss: 0.24164849519729614
Batch 51/64 loss: 0.23534148931503296
Batch 52/64 loss: 0.23673659563064575
Batch 53/64 loss: 0.23130786418914795
Batch 54/64 loss: 0.24386978149414062
Batch 55/64 loss: 0.23654061555862427
Batch 56/64 loss: 0.2307339906692505
Batch 57/64 loss: 0.2390628457069397
Batch 58/64 loss: 0.25191807746887207
Batch 59/64 loss: 0.2422429323196411
Batch 60/64 loss: 0.23679614067077637
Batch 61/64 loss: 0.2419811487197876
Batch 62/64 loss: 0.2459697723388672
Batch 63/64 loss: 0.2360389232635498
Batch 64/64 loss: 0.23922514915466309
Epoch 374  Train loss: 0.23800734258165546  Val loss: 0.28309767106964007
Epoch 375
-------------------------------
Batch 1/64 loss: 0.24381059408187866
Batch 2/64 loss: 0.24055403470993042
Batch 3/64 loss: 0.23884958028793335
Batch 4/64 loss: 0.24807751178741455
Batch 5/64 loss: 0.2285059690475464
Batch 6/64 loss: 0.23809188604354858
Batch 7/64 loss: 0.23281699419021606
Batch 8/64 loss: 0.22984039783477783
Batch 9/64 loss: 0.2348872423171997
Batch 10/64 loss: 0.2328789234161377
Batch 11/64 loss: 0.24042654037475586
Batch 12/64 loss: 0.2364138960838318
Batch 13/64 loss: 0.24115502834320068
Batch 14/64 loss: 0.25005805492401123
Batch 15/64 loss: 0.23428034782409668
Batch 16/64 loss: 0.24468064308166504
Batch 17/64 loss: 0.22835755348205566
Batch 18/64 loss: 0.23053216934204102
Batch 19/64 loss: 0.23686259984970093
Batch 20/64 loss: 0.23684841394424438
Batch 21/64 loss: 0.2384476661682129
Batch 22/64 loss: 0.22617971897125244
Batch 23/64 loss: 0.24571257829666138
Batch 24/64 loss: 0.23419082164764404
Batch 25/64 loss: 0.23212063312530518
Batch 26/64 loss: 0.2277144193649292
Batch 27/64 loss: 0.2332247495651245
Batch 28/64 loss: 0.24036681652069092
Batch 29/64 loss: 0.24511796236038208
Batch 30/64 loss: 0.2372155785560608
Batch 31/64 loss: 0.23446226119995117
Batch 32/64 loss: 0.24375730752944946
Batch 33/64 loss: 0.2332664132118225
Batch 34/64 loss: 0.24374908208847046
Batch 35/64 loss: 0.24160218238830566
Batch 36/64 loss: 0.23596274852752686
Batch 37/64 loss: 0.24257183074951172
Batch 38/64 loss: 0.23672723770141602
Batch 39/64 loss: 0.23933112621307373
Batch 40/64 loss: 0.23766976594924927
Batch 41/64 loss: 0.23213046789169312
Batch 42/64 loss: 0.23368167877197266
Batch 43/64 loss: 0.23530417680740356
Batch 44/64 loss: 0.236896812915802
Batch 45/64 loss: 0.23559868335723877
Batch 46/64 loss: 0.25315606594085693
Batch 47/64 loss: 0.23529815673828125
Batch 48/64 loss: 0.23859763145446777
Batch 49/64 loss: 0.24121606349945068
Batch 50/64 loss: 0.2342151403427124
Batch 51/64 loss: 0.2412567138671875
Batch 52/64 loss: 0.2401389479637146
Batch 53/64 loss: 0.2286244034767151
Batch 54/64 loss: 0.2441483736038208
Batch 55/64 loss: 0.24016571044921875
Batch 56/64 loss: 0.2363896369934082
Batch 57/64 loss: 0.2413012981414795
Batch 58/64 loss: 0.23977422714233398
Batch 59/64 loss: 0.24272620677947998
Batch 60/64 loss: 0.2452111840248108
Batch 61/64 loss: 0.2402857542037964
Batch 62/64 loss: 0.2336585521697998
Batch 63/64 loss: 0.23571282625198364
Batch 64/64 loss: 0.2444617748260498
Epoch 375  Train loss: 0.23790046000013165  Val loss: 0.28161483327138054
Epoch 376
-------------------------------
Batch 1/64 loss: 0.23354041576385498
Batch 2/64 loss: 0.25280511379241943
Batch 3/64 loss: 0.23468828201293945
Batch 4/64 loss: 0.23730474710464478
Batch 5/64 loss: 0.24276745319366455
Batch 6/64 loss: 0.24499404430389404
Batch 7/64 loss: 0.23613226413726807
Batch 8/64 loss: 0.23279130458831787
Batch 9/64 loss: 0.23813897371292114
Batch 10/64 loss: 0.24444442987442017
Batch 11/64 loss: 0.23268413543701172
Batch 12/64 loss: 0.23736566305160522
Batch 13/64 loss: 0.23974168300628662
Batch 14/64 loss: 0.2463533878326416
Batch 15/64 loss: 0.24359917640686035
Batch 16/64 loss: 0.23794829845428467
Batch 17/64 loss: 0.22721022367477417
Batch 18/64 loss: 0.23881256580352783
Batch 19/64 loss: 0.23978310823440552
Batch 20/64 loss: 0.23198562860488892
Batch 21/64 loss: 0.23559951782226562
Batch 22/64 loss: 0.23850703239440918
Batch 23/64 loss: 0.2395014762878418
Batch 24/64 loss: 0.23986464738845825
Batch 25/64 loss: 0.23955035209655762
Batch 26/64 loss: 0.24063622951507568
Batch 27/64 loss: 0.23205804824829102
Batch 28/64 loss: 0.23250913619995117
Batch 29/64 loss: 0.235337495803833
Batch 30/64 loss: 0.23087507486343384
Batch 31/64 loss: 0.23313796520233154
Batch 32/64 loss: 0.23238587379455566
Batch 33/64 loss: 0.23144525289535522
Batch 34/64 loss: 0.2480309009552002
Batch 35/64 loss: 0.23350924253463745
Batch 36/64 loss: 0.23795533180236816
Batch 37/64 loss: 0.23757433891296387
Batch 38/64 loss: 0.23638570308685303
Batch 39/64 loss: 0.23608636856079102
Batch 40/64 loss: 0.2379361391067505
Batch 41/64 loss: 0.24376612901687622
Batch 42/64 loss: 0.2448555827140808
Batch 43/64 loss: 0.2360459566116333
Batch 44/64 loss: 0.24781125783920288
Batch 45/64 loss: 0.23815596103668213
Batch 46/64 loss: 0.2404077649116516
Batch 47/64 loss: 0.24677228927612305
Batch 48/64 loss: 0.2382957935333252
Batch 49/64 loss: 0.2450239658355713
Batch 50/64 loss: 0.24028325080871582
Batch 51/64 loss: 0.23836541175842285
Batch 52/64 loss: 0.22897660732269287
Batch 53/64 loss: 0.23917502164840698
Batch 54/64 loss: 0.23263204097747803
Batch 55/64 loss: 0.2425609827041626
Batch 56/64 loss: 0.24419569969177246
Batch 57/64 loss: 0.23598897457122803
Batch 58/64 loss: 0.2260180115699768
Batch 59/64 loss: 0.2503758668899536
Batch 60/64 loss: 0.23734736442565918
Batch 61/64 loss: 0.23908329010009766
Batch 62/64 loss: 0.23792481422424316
Batch 63/64 loss: 0.23930078744888306
Batch 64/64 loss: 0.24711042642593384
Epoch 376  Train loss: 0.23844192425409952  Val loss: 0.28259934776837065
Epoch 377
-------------------------------
Batch 1/64 loss: 0.23513448238372803
Batch 2/64 loss: 0.2392336130142212
Batch 3/64 loss: 0.22829174995422363
Batch 4/64 loss: 0.2478715181350708
Batch 5/64 loss: 0.236777663230896
Batch 6/64 loss: 0.23923051357269287
Batch 7/64 loss: 0.23233377933502197
Batch 8/64 loss: 0.22666823863983154
Batch 9/64 loss: 0.23991727828979492
Batch 10/64 loss: 0.233803391456604
Batch 11/64 loss: 0.2478032112121582
Batch 12/64 loss: 0.22750109434127808
Batch 13/64 loss: 0.23613280057907104
Batch 14/64 loss: 0.23577094078063965
Batch 15/64 loss: 0.23992645740509033
Batch 16/64 loss: 0.23276489973068237
Batch 17/64 loss: 0.23306655883789062
Batch 18/64 loss: 0.23359251022338867
Batch 19/64 loss: 0.23253893852233887
Batch 20/64 loss: 0.23044919967651367
Batch 21/64 loss: 0.2287994623184204
Batch 22/64 loss: 0.23929941654205322
Batch 23/64 loss: 0.22653281688690186
Batch 24/64 loss: 0.2478199005126953
Batch 25/64 loss: 0.2346128225326538
Batch 26/64 loss: 0.23844850063323975
Batch 27/64 loss: 0.2395327091217041
Batch 28/64 loss: 0.25445008277893066
Batch 29/64 loss: 0.2377212643623352
Batch 30/64 loss: 0.2399808168411255
Batch 31/64 loss: 0.23329699039459229
Batch 32/64 loss: 0.24697613716125488
Batch 33/64 loss: 0.25509119033813477
Batch 34/64 loss: 0.23872745037078857
Batch 35/64 loss: 0.23917436599731445
Batch 36/64 loss: 0.2314632534980774
Batch 37/64 loss: 0.242997407913208
Batch 38/64 loss: 0.24456298351287842
Batch 39/64 loss: 0.2332981824874878
Batch 40/64 loss: 0.2457571029663086
Batch 41/64 loss: 0.23990607261657715
Batch 42/64 loss: 0.23625564575195312
Batch 43/64 loss: 0.23213952779769897
Batch 44/64 loss: 0.2455970048904419
Batch 45/64 loss: 0.23867857456207275
Batch 46/64 loss: 0.2470497488975525
Batch 47/64 loss: 0.24495470523834229
Batch 48/64 loss: 0.23924052715301514
Batch 49/64 loss: 0.23869162797927856
Batch 50/64 loss: 0.23081684112548828
Batch 51/64 loss: 0.23552370071411133
Batch 52/64 loss: 0.2364358901977539
Batch 53/64 loss: 0.24887090921401978
Batch 54/64 loss: 0.2373746633529663
Batch 55/64 loss: 0.2363494634628296
Batch 56/64 loss: 0.23674988746643066
Batch 57/64 loss: 0.24634814262390137
Batch 58/64 loss: 0.23869842290878296
Batch 59/64 loss: 0.2513783574104309
Batch 60/64 loss: 0.24083441495895386
Batch 61/64 loss: 0.23039162158966064
Batch 62/64 loss: 0.236441969871521
Batch 63/64 loss: 0.2338402271270752
Batch 64/64 loss: 0.23708641529083252
Epoch 377  Train loss: 0.23823897184110154  Val loss: 0.2814765160845727
Epoch 378
-------------------------------
Batch 1/64 loss: 0.24794209003448486
Batch 2/64 loss: 0.23680543899536133
Batch 3/64 loss: 0.22787690162658691
Batch 4/64 loss: 0.2460622787475586
Batch 5/64 loss: 0.2442989945411682
Batch 6/64 loss: 0.2312023639678955
Batch 7/64 loss: 0.22997945547103882
Batch 8/64 loss: 0.23798227310180664
Batch 9/64 loss: 0.23453450202941895
Batch 10/64 loss: 0.2438793182373047
Batch 11/64 loss: 0.23692774772644043
Batch 12/64 loss: 0.23434996604919434
Batch 13/64 loss: 0.2400088906288147
Batch 14/64 loss: 0.23368602991104126
Batch 15/64 loss: 0.23461520671844482
Batch 16/64 loss: 0.24217736721038818
Batch 17/64 loss: 0.23323237895965576
Batch 18/64 loss: 0.2350197434425354
Batch 19/64 loss: 0.2480766773223877
Batch 20/64 loss: 0.23832261562347412
Batch 21/64 loss: 0.24332427978515625
Batch 22/64 loss: 0.2351384162902832
Batch 23/64 loss: 0.23776066303253174
Batch 24/64 loss: 0.2367982268333435
Batch 25/64 loss: 0.23535370826721191
Batch 26/64 loss: 0.22980189323425293
Batch 27/64 loss: 0.24793583154678345
Batch 28/64 loss: 0.2349104881286621
Batch 29/64 loss: 0.23220956325531006
Batch 30/64 loss: 0.2366710901260376
Batch 31/64 loss: 0.23570966720581055
Batch 32/64 loss: 0.2414277195930481
Batch 33/64 loss: 0.23855513334274292
Batch 34/64 loss: 0.2438175082206726
Batch 35/64 loss: 0.23232018947601318
Batch 36/64 loss: 0.23997992277145386
Batch 37/64 loss: 0.24016833305358887
Batch 38/64 loss: 0.23214960098266602
Batch 39/64 loss: 0.24114030599594116
Batch 40/64 loss: 0.2360149621963501
Batch 41/64 loss: 0.24379116296768188
Batch 42/64 loss: 0.22876274585723877
Batch 43/64 loss: 0.24886846542358398
Batch 44/64 loss: 0.23524659872055054
Batch 45/64 loss: 0.23280435800552368
Batch 46/64 loss: 0.24023830890655518
Batch 47/64 loss: 0.24271994829177856
Batch 48/64 loss: 0.23376721143722534
Batch 49/64 loss: 0.24754977226257324
Batch 50/64 loss: 0.24506115913391113
Batch 51/64 loss: 0.24123716354370117
Batch 52/64 loss: 0.24661648273468018
Batch 53/64 loss: 0.244240403175354
Batch 54/64 loss: 0.23064404726028442
Batch 55/64 loss: 0.23806005716323853
Batch 56/64 loss: 0.24616175889968872
Batch 57/64 loss: 0.23521429300308228
Batch 58/64 loss: 0.2449091672897339
Batch 59/64 loss: 0.23313993215560913
Batch 60/64 loss: 0.24330270290374756
Batch 61/64 loss: 0.2324059009552002
Batch 62/64 loss: 0.23073601722717285
Batch 63/64 loss: 0.22843122482299805
Batch 64/64 loss: 0.23786723613739014
Epoch 378  Train loss: 0.23812513024199242  Val loss: 0.2822794525074385
Epoch 379
-------------------------------
Batch 1/64 loss: 0.2283729910850525
Batch 2/64 loss: 0.25279510021209717
Batch 3/64 loss: 0.23602241277694702
Batch 4/64 loss: 0.2389886975288391
Batch 5/64 loss: 0.2353190779685974
Batch 6/64 loss: 0.24184954166412354
Batch 7/64 loss: 0.24425047636032104
Batch 8/64 loss: 0.23496657609939575
Batch 9/64 loss: 0.23711103200912476
Batch 10/64 loss: 0.2436596155166626
Batch 11/64 loss: 0.2378249168395996
Batch 12/64 loss: 0.23644739389419556
Batch 13/64 loss: 0.22740137577056885
Batch 14/64 loss: 0.23601555824279785
Batch 15/64 loss: 0.24072647094726562
Batch 16/64 loss: 0.23578804731369019
Batch 17/64 loss: 0.2297789454460144
Batch 18/64 loss: 0.23229879140853882
Batch 19/64 loss: 0.2297811508178711
Batch 20/64 loss: 0.23234403133392334
Batch 21/64 loss: 0.24428808689117432
Batch 22/64 loss: 0.2428663969039917
Batch 23/64 loss: 0.2316427230834961
Batch 24/64 loss: 0.23124849796295166
Batch 25/64 loss: 0.23716199398040771
Batch 26/64 loss: 0.23167133331298828
Batch 27/64 loss: 0.23344498872756958
Batch 28/64 loss: 0.23430746793746948
Batch 29/64 loss: 0.2498234510421753
Batch 30/64 loss: 0.24467527866363525
Batch 31/64 loss: 0.23086220026016235
Batch 32/64 loss: 0.2360743284225464
Batch 33/64 loss: 0.23144620656967163
Batch 34/64 loss: 0.24297797679901123
Batch 35/64 loss: 0.23164772987365723
Batch 36/64 loss: 0.23800086975097656
Batch 37/64 loss: 0.23628830909729004
Batch 38/64 loss: 0.23745346069335938
Batch 39/64 loss: 0.23908615112304688
Batch 40/64 loss: 0.24478769302368164
Batch 41/64 loss: 0.23034626245498657
Batch 42/64 loss: 0.2421633005142212
Batch 43/64 loss: 0.24075865745544434
Batch 44/64 loss: 0.2382427453994751
Batch 45/64 loss: 0.23624759912490845
Batch 46/64 loss: 0.24387311935424805
Batch 47/64 loss: 0.23208487033843994
Batch 48/64 loss: 0.2332521677017212
Batch 49/64 loss: 0.24096930027008057
Batch 50/64 loss: 0.2321997880935669
Batch 51/64 loss: 0.23603928089141846
Batch 52/64 loss: 0.23611092567443848
Batch 53/64 loss: 0.23066306114196777
Batch 54/64 loss: 0.2335296869277954
Batch 55/64 loss: 0.22935950756072998
Batch 56/64 loss: 0.22413426637649536
Batch 57/64 loss: 0.2309173345565796
Batch 58/64 loss: 0.23820996284484863
Batch 59/64 loss: 0.23511278629302979
Batch 60/64 loss: 0.2396146059036255
Batch 61/64 loss: 0.23673593997955322
Batch 62/64 loss: 0.23338329792022705
Batch 63/64 loss: 0.24319082498550415
Batch 64/64 loss: 0.23624557256698608
Epoch 379  Train loss: 0.23648346382028917  Val loss: 0.2821416912209947
Epoch 380
-------------------------------
Batch 1/64 loss: 0.22696423530578613
Batch 2/64 loss: 0.2327824831008911
Batch 3/64 loss: 0.23963594436645508
Batch 4/64 loss: 0.23803842067718506
Batch 5/64 loss: 0.2426607608795166
Batch 6/64 loss: 0.23801803588867188
Batch 7/64 loss: 0.23349201679229736
Batch 8/64 loss: 0.24509024620056152
Batch 9/64 loss: 0.23193126916885376
Batch 10/64 loss: 0.25240617990493774
Batch 11/64 loss: 0.2434634566307068
Batch 12/64 loss: 0.2266174554824829
Batch 13/64 loss: 0.2457582950592041
Batch 14/64 loss: 0.23545432090759277
Batch 15/64 loss: 0.2373943328857422
Batch 16/64 loss: 0.23191165924072266
Batch 17/64 loss: 0.2330746054649353
Batch 18/64 loss: 0.23755449056625366
Batch 19/64 loss: 0.2285674810409546
Batch 20/64 loss: 0.23359179496765137
Batch 21/64 loss: 0.23368465900421143
Batch 22/64 loss: 0.22798806428909302
Batch 23/64 loss: 0.22999972105026245
Batch 24/64 loss: 0.23180466890335083
Batch 25/64 loss: 0.23914849758148193
Batch 26/64 loss: 0.2417818307876587
Batch 27/64 loss: 0.23285377025604248
Batch 28/64 loss: 0.24219942092895508
Batch 29/64 loss: 0.2312362790107727
Batch 30/64 loss: 0.23780184984207153
Batch 31/64 loss: 0.241013765335083
Batch 32/64 loss: 0.22975122928619385
Batch 33/64 loss: 0.24392461776733398
Batch 34/64 loss: 0.22882795333862305
Batch 35/64 loss: 0.2437991499900818
Batch 36/64 loss: 0.2477228045463562
Batch 37/64 loss: 0.23841845989227295
Batch 38/64 loss: 0.24679100513458252
Batch 39/64 loss: 0.23023295402526855
Batch 40/64 loss: 0.24400168657302856
Batch 41/64 loss: 0.22579216957092285
Batch 42/64 loss: 0.2411888837814331
Batch 43/64 loss: 0.2444850206375122
Batch 44/64 loss: 0.24123477935791016
Batch 45/64 loss: 0.23299181461334229
Batch 46/64 loss: 0.2229163646697998
Batch 47/64 loss: 0.23757469654083252
Batch 48/64 loss: 0.23999983072280884
Batch 49/64 loss: 0.2386094331741333
Batch 50/64 loss: 0.2526264190673828
Batch 51/64 loss: 0.22648298740386963
Batch 52/64 loss: 0.23563551902770996
Batch 53/64 loss: 0.23335254192352295
Batch 54/64 loss: 0.23640048503875732
Batch 55/64 loss: 0.23958301544189453
Batch 56/64 loss: 0.23938024044036865
Batch 57/64 loss: 0.24166840314865112
Batch 58/64 loss: 0.24056166410446167
Batch 59/64 loss: 0.24264073371887207
Batch 60/64 loss: 0.24880260229110718
Batch 61/64 loss: 0.23730164766311646
Batch 62/64 loss: 0.24933940172195435
Batch 63/64 loss: 0.24554592370986938
Batch 64/64 loss: 0.24011576175689697
Epoch 380  Train loss: 0.23767201993979659  Val loss: 0.2824943122994859
Epoch 381
-------------------------------
Batch 1/64 loss: 0.2395925521850586
Batch 2/64 loss: 0.241593599319458
Batch 3/64 loss: 0.22717952728271484
Batch 4/64 loss: 0.2359158992767334
Batch 5/64 loss: 0.2368534803390503
Batch 6/64 loss: 0.23304122686386108
Batch 7/64 loss: 0.2485058307647705
Batch 8/64 loss: 0.23297792673110962
Batch 9/64 loss: 0.2331562042236328
Batch 10/64 loss: 0.22850853204727173
Batch 11/64 loss: 0.226823627948761
Batch 12/64 loss: 0.235984206199646
Batch 13/64 loss: 0.23476958274841309
Batch 14/64 loss: 0.2348887324333191
Batch 15/64 loss: 0.23446500301361084
Batch 16/64 loss: 0.23715394735336304
Batch 17/64 loss: 0.2403801679611206
Batch 18/64 loss: 0.2452215552330017
Batch 19/64 loss: 0.23117828369140625
Batch 20/64 loss: 0.23983770608901978
Batch 21/64 loss: 0.24058759212493896
Batch 22/64 loss: 0.2536207437515259
Batch 23/64 loss: 0.23731380701065063
Batch 24/64 loss: 0.23736584186553955
Batch 25/64 loss: 0.22855156660079956
Batch 26/64 loss: 0.23083817958831787
Batch 27/64 loss: 0.23796623945236206
Batch 28/64 loss: 0.23527145385742188
Batch 29/64 loss: 0.23033589124679565
Batch 30/64 loss: 0.23825562000274658
Batch 31/64 loss: 0.24085652828216553
Batch 32/64 loss: 0.23172438144683838
Batch 33/64 loss: 0.23470652103424072
Batch 34/64 loss: 0.23888325691223145
Batch 35/64 loss: 0.2378096580505371
Batch 36/64 loss: 0.23049819469451904
Batch 37/64 loss: 0.23721444606781006
Batch 38/64 loss: 0.24541038274765015
Batch 39/64 loss: 0.23707962036132812
Batch 40/64 loss: 0.2445007562637329
Batch 41/64 loss: 0.23423027992248535
Batch 42/64 loss: 0.22836118936538696
Batch 43/64 loss: 0.23106598854064941
Batch 44/64 loss: 0.24027496576309204
Batch 45/64 loss: 0.2434711456298828
Batch 46/64 loss: 0.23918771743774414
Batch 47/64 loss: 0.2425093650817871
Batch 48/64 loss: 0.24238866567611694
Batch 49/64 loss: 0.24091100692749023
Batch 50/64 loss: 0.23891615867614746
Batch 51/64 loss: 0.2481415867805481
Batch 52/64 loss: 0.23788601160049438
Batch 53/64 loss: 0.23338806629180908
Batch 54/64 loss: 0.2309320569038391
Batch 55/64 loss: 0.23489850759506226
Batch 56/64 loss: 0.23321318626403809
Batch 57/64 loss: 0.23798227310180664
Batch 58/64 loss: 0.22756344079971313
Batch 59/64 loss: 0.23446965217590332
Batch 60/64 loss: 0.24104362726211548
Batch 61/64 loss: 0.25145745277404785
Batch 62/64 loss: 0.2415611743927002
Batch 63/64 loss: 0.23911833763122559
Batch 64/64 loss: 0.23846769332885742
Epoch 381  Train loss: 0.2371551513671875  Val loss: 0.2822525597519891
Epoch 382
-------------------------------
Batch 1/64 loss: 0.2340993881225586
Batch 2/64 loss: 0.23723554611206055
Batch 3/64 loss: 0.22361981868743896
Batch 4/64 loss: 0.2359580397605896
Batch 5/64 loss: 0.22882699966430664
Batch 6/64 loss: 0.24162113666534424
Batch 7/64 loss: 0.23974794149398804
Batch 8/64 loss: 0.23207151889801025
Batch 9/64 loss: 0.2315998077392578
Batch 10/64 loss: 0.23071467876434326
Batch 11/64 loss: 0.2321838140487671
Batch 12/64 loss: 0.2307041883468628
Batch 13/64 loss: 0.22359955310821533
Batch 14/64 loss: 0.2329980731010437
Batch 15/64 loss: 0.24599778652191162
Batch 16/64 loss: 0.2408425211906433
Batch 17/64 loss: 0.2406376600265503
Batch 18/64 loss: 0.24686837196350098
Batch 19/64 loss: 0.23486018180847168
Batch 20/64 loss: 0.2426300048828125
Batch 21/64 loss: 0.2357335090637207
Batch 22/64 loss: 0.22924470901489258
Batch 23/64 loss: 0.2334163784980774
Batch 24/64 loss: 0.23509973287582397
Batch 25/64 loss: 0.23774367570877075
Batch 26/64 loss: 0.23927974700927734
Batch 27/64 loss: 0.2448183298110962
Batch 28/64 loss: 0.24052226543426514
Batch 29/64 loss: 0.2399194836616516
Batch 30/64 loss: 0.2323906421661377
Batch 31/64 loss: 0.23455357551574707
Batch 32/64 loss: 0.23342502117156982
Batch 33/64 loss: 0.23999470472335815
Batch 34/64 loss: 0.23693811893463135
Batch 35/64 loss: 0.24162954092025757
Batch 36/64 loss: 0.2409631609916687
Batch 37/64 loss: 0.24927294254302979
Batch 38/64 loss: 0.22535228729248047
Batch 39/64 loss: 0.24992620944976807
Batch 40/64 loss: 0.23911142349243164
Batch 41/64 loss: 0.23361575603485107
Batch 42/64 loss: 0.23782438039779663
Batch 43/64 loss: 0.22819548845291138
Batch 44/64 loss: 0.23394572734832764
Batch 45/64 loss: 0.23383218050003052
Batch 46/64 loss: 0.24147379398345947
Batch 47/64 loss: 0.23381930589675903
Batch 48/64 loss: 0.23417747020721436
Batch 49/64 loss: 0.23162221908569336
Batch 50/64 loss: 0.2283514142036438
Batch 51/64 loss: 0.24282574653625488
Batch 52/64 loss: 0.23437750339508057
Batch 53/64 loss: 0.23962640762329102
Batch 54/64 loss: 0.23911052942276
Batch 55/64 loss: 0.24944555759429932
Batch 56/64 loss: 0.2435738444328308
Batch 57/64 loss: 0.2396225929260254
Batch 58/64 loss: 0.2286897897720337
Batch 59/64 loss: 0.23847931623458862
Batch 60/64 loss: 0.23849821090698242
Batch 61/64 loss: 0.23788177967071533
Batch 62/64 loss: 0.23683202266693115
Batch 63/64 loss: 0.23968100547790527
Batch 64/64 loss: 0.2387900948524475
Epoch 382  Train loss: 0.23671760161717734  Val loss: 0.2825304814630358
Epoch 383
-------------------------------
Batch 1/64 loss: 0.24356281757354736
Batch 2/64 loss: 0.22669005393981934
Batch 3/64 loss: 0.2310549020767212
Batch 4/64 loss: 0.22997426986694336
Batch 5/64 loss: 0.23646217584609985
Batch 6/64 loss: 0.22675347328186035
Batch 7/64 loss: 0.23685228824615479
Batch 8/64 loss: 0.24379587173461914
Batch 9/64 loss: 0.2447507381439209
Batch 10/64 loss: 0.23561108112335205
Batch 11/64 loss: 0.2409237027168274
Batch 12/64 loss: 0.24438637495040894
Batch 13/64 loss: 0.22990453243255615
Batch 14/64 loss: 0.2262653112411499
Batch 15/64 loss: 0.24174171686172485
Batch 16/64 loss: 0.24126017093658447
Batch 17/64 loss: 0.23487800359725952
Batch 18/64 loss: 0.2315431833267212
Batch 19/64 loss: 0.24131643772125244
Batch 20/64 loss: 0.23362970352172852
Batch 21/64 loss: 0.23526716232299805
Batch 22/64 loss: 0.24185240268707275
Batch 23/64 loss: 0.22975051403045654
Batch 24/64 loss: 0.24322819709777832
Batch 25/64 loss: 0.23381763696670532
Batch 26/64 loss: 0.23038113117218018
Batch 27/64 loss: 0.23726940155029297
Batch 28/64 loss: 0.2419421672821045
Batch 29/64 loss: 0.24154233932495117
Batch 30/64 loss: 0.25157344341278076
Batch 31/64 loss: 0.23579251766204834
Batch 32/64 loss: 0.2355971336364746
Batch 33/64 loss: 0.2312840223312378
Batch 34/64 loss: 0.24260938167572021
Batch 35/64 loss: 0.25218892097473145
Batch 36/64 loss: 0.24691367149353027
Batch 37/64 loss: 0.23753535747528076
Batch 38/64 loss: 0.2419854998588562
Batch 39/64 loss: 0.23869937658309937
Batch 40/64 loss: 0.23235666751861572
Batch 41/64 loss: 0.23238515853881836
Batch 42/64 loss: 0.23663008213043213
Batch 43/64 loss: 0.23102229833602905
Batch 44/64 loss: 0.22958409786224365
Batch 45/64 loss: 0.23477959632873535
Batch 46/64 loss: 0.23156273365020752
Batch 47/64 loss: 0.2548432946205139
Batch 48/64 loss: 0.22787338495254517
Batch 49/64 loss: 0.23634421825408936
Batch 50/64 loss: 0.2393438220024109
Batch 51/64 loss: 0.2392057180404663
Batch 52/64 loss: 0.24601709842681885
Batch 53/64 loss: 0.23429417610168457
Batch 54/64 loss: 0.23810279369354248
Batch 55/64 loss: 0.23349273204803467
Batch 56/64 loss: 0.2323664426803589
Batch 57/64 loss: 0.24290907382965088
Batch 58/64 loss: 0.24128425121307373
Batch 59/64 loss: 0.23625457286834717
Batch 60/64 loss: 0.2409144639968872
Batch 61/64 loss: 0.24329328536987305
Batch 62/64 loss: 0.2456626296043396
Batch 63/64 loss: 0.22806864976882935
Batch 64/64 loss: 0.23566389083862305
Epoch 383  Train loss: 0.23742629406498927  Val loss: 0.2828079781581446
Epoch 384
-------------------------------
Batch 1/64 loss: 0.23104459047317505
Batch 2/64 loss: 0.23080766201019287
Batch 3/64 loss: 0.24982142448425293
Batch 4/64 loss: 0.24242591857910156
Batch 5/64 loss: 0.22944819927215576
Batch 6/64 loss: 0.23724400997161865
Batch 7/64 loss: 0.2249664068222046
Batch 8/64 loss: 0.230105459690094
Batch 9/64 loss: 0.2296067476272583
Batch 10/64 loss: 0.23762106895446777
Batch 11/64 loss: 0.23278695344924927
Batch 12/64 loss: 0.2367931604385376
Batch 13/64 loss: 0.2373865842819214
Batch 14/64 loss: 0.23020994663238525
Batch 15/64 loss: 0.2370145320892334
Batch 16/64 loss: 0.23495793342590332
Batch 17/64 loss: 0.23277461528778076
Batch 18/64 loss: 0.23974275588989258
Batch 19/64 loss: 0.23526549339294434
Batch 20/64 loss: 0.24440395832061768
Batch 21/64 loss: 0.24187970161437988
Batch 22/64 loss: 0.23396378755569458
Batch 23/64 loss: 0.23881113529205322
Batch 24/64 loss: 0.23891663551330566
Batch 25/64 loss: 0.24150586128234863
Batch 26/64 loss: 0.22960364818572998
Batch 27/64 loss: 0.24515992403030396
Batch 28/64 loss: 0.2319197654724121
Batch 29/64 loss: 0.24177956581115723
Batch 30/64 loss: 0.2337813377380371
Batch 31/64 loss: 0.2371932864189148
Batch 32/64 loss: 0.23472446203231812
Batch 33/64 loss: 0.24130642414093018
Batch 34/64 loss: 0.23293250799179077
Batch 35/64 loss: 0.23536187410354614
Batch 36/64 loss: 0.23716413974761963
Batch 37/64 loss: 0.2288849949836731
Batch 38/64 loss: 0.23246830701828003
Batch 39/64 loss: 0.23912006616592407
Batch 40/64 loss: 0.2311687469482422
Batch 41/64 loss: 0.23415184020996094
Batch 42/64 loss: 0.23376178741455078
Batch 43/64 loss: 0.2380734086036682
Batch 44/64 loss: 0.2388826608657837
Batch 45/64 loss: 0.24334073066711426
Batch 46/64 loss: 0.24114853143692017
Batch 47/64 loss: 0.23965513706207275
Batch 48/64 loss: 0.24206876754760742
Batch 49/64 loss: 0.23204779624938965
Batch 50/64 loss: 0.22820687294006348
Batch 51/64 loss: 0.23807227611541748
Batch 52/64 loss: 0.23912274837493896
Batch 53/64 loss: 0.23123276233673096
Batch 54/64 loss: 0.23507380485534668
Batch 55/64 loss: 0.2494971752166748
Batch 56/64 loss: 0.24243062734603882
Batch 57/64 loss: 0.23687469959259033
Batch 58/64 loss: 0.242875337600708
Batch 59/64 loss: 0.2490168809890747
Batch 60/64 loss: 0.23934489488601685
Batch 61/64 loss: 0.2317577600479126
Batch 62/64 loss: 0.23597723245620728
Batch 63/64 loss: 0.2317965030670166
Batch 64/64 loss: 0.24915766716003418
Epoch 384  Train loss: 0.23675846399045458  Val loss: 0.28204746959135707
Epoch 385
-------------------------------
Batch 1/64 loss: 0.24527490139007568
Batch 2/64 loss: 0.2403184175491333
Batch 3/64 loss: 0.2299274206161499
Batch 4/64 loss: 0.24094974994659424
Batch 5/64 loss: 0.2343733310699463
Batch 6/64 loss: 0.23441624641418457
Batch 7/64 loss: 0.24001163244247437
Batch 8/64 loss: 0.23543894290924072
Batch 9/64 loss: 0.23511123657226562
Batch 10/64 loss: 0.22550547122955322
Batch 11/64 loss: 0.2231670618057251
Batch 12/64 loss: 0.2278243899345398
Batch 13/64 loss: 0.23446375131607056
Batch 14/64 loss: 0.2327948808670044
Batch 15/64 loss: 0.23419398069381714
Batch 16/64 loss: 0.23766398429870605
Batch 17/64 loss: 0.242273211479187
Batch 18/64 loss: 0.24062609672546387
Batch 19/64 loss: 0.24203550815582275
Batch 20/64 loss: 0.2347886562347412
Batch 21/64 loss: 0.25197142362594604
Batch 22/64 loss: 0.24199628829956055
Batch 23/64 loss: 0.24507474899291992
Batch 24/64 loss: 0.2357161045074463
Batch 25/64 loss: 0.2408064603805542
Batch 26/64 loss: 0.2316138744354248
Batch 27/64 loss: 0.2349541187286377
Batch 28/64 loss: 0.23062574863433838
Batch 29/64 loss: 0.22796732187271118
Batch 30/64 loss: 0.23663735389709473
Batch 31/64 loss: 0.24507784843444824
Batch 32/64 loss: 0.24097371101379395
Batch 33/64 loss: 0.23811876773834229
Batch 34/64 loss: 0.23719525337219238
Batch 35/64 loss: 0.24067944288253784
Batch 36/64 loss: 0.25306200981140137
Batch 37/64 loss: 0.22946321964263916
Batch 38/64 loss: 0.23722028732299805
Batch 39/64 loss: 0.2341359257698059
Batch 40/64 loss: 0.23767602443695068
Batch 41/64 loss: 0.24541401863098145
Batch 42/64 loss: 0.2356356382369995
Batch 43/64 loss: 0.22816872596740723
Batch 44/64 loss: 0.252799391746521
Batch 45/64 loss: 0.24047672748565674
Batch 46/64 loss: 0.23393511772155762
Batch 47/64 loss: 0.2314392328262329
Batch 48/64 loss: 0.24162232875823975
Batch 49/64 loss: 0.23350942134857178
Batch 50/64 loss: 0.23555713891983032
Batch 51/64 loss: 0.2309093475341797
Batch 52/64 loss: 0.23207485675811768
Batch 53/64 loss: 0.23132258653640747
Batch 54/64 loss: 0.2344563603401184
Batch 55/64 loss: 0.23574817180633545
Batch 56/64 loss: 0.2437143325805664
Batch 57/64 loss: 0.23931670188903809
Batch 58/64 loss: 0.24365615844726562
Batch 59/64 loss: 0.2336747646331787
Batch 60/64 loss: 0.24086105823516846
Batch 61/64 loss: 0.23336255550384521
Batch 62/64 loss: 0.2289736270904541
Batch 63/64 loss: 0.23304736614227295
Batch 64/64 loss: 0.23475587368011475
Epoch 385  Train loss: 0.2368292916054819  Val loss: 0.2823128087823743
Epoch 386
-------------------------------
Batch 1/64 loss: 0.23714685440063477
Batch 2/64 loss: 0.23831188678741455
Batch 3/64 loss: 0.2348569631576538
Batch 4/64 loss: 0.24182945489883423
Batch 5/64 loss: 0.24562156200408936
Batch 6/64 loss: 0.2327479124069214
Batch 7/64 loss: 0.22941511869430542
Batch 8/64 loss: 0.23996484279632568
Batch 9/64 loss: 0.2403298020362854
Batch 10/64 loss: 0.24263161420822144
Batch 11/64 loss: 0.22728776931762695
Batch 12/64 loss: 0.22504419088363647
Batch 13/64 loss: 0.24018806219100952
Batch 14/64 loss: 0.23562097549438477
Batch 15/64 loss: 0.2358754277229309
Batch 16/64 loss: 0.22464793920516968
Batch 17/64 loss: 0.2281583547592163
Batch 18/64 loss: 0.2217724323272705
Batch 19/64 loss: 0.2296457290649414
Batch 20/64 loss: 0.23341333866119385
Batch 21/64 loss: 0.22944319248199463
Batch 22/64 loss: 0.2359999418258667
Batch 23/64 loss: 0.23209494352340698
Batch 24/64 loss: 0.24660277366638184
Batch 25/64 loss: 0.23405808210372925
Batch 26/64 loss: 0.24678891897201538
Batch 27/64 loss: 0.23920226097106934
Batch 28/64 loss: 0.22742462158203125
Batch 29/64 loss: 0.23676085472106934
Batch 30/64 loss: 0.23581337928771973
Batch 31/64 loss: 0.2401440143585205
Batch 32/64 loss: 0.23550736904144287
Batch 33/64 loss: 0.23731088638305664
Batch 34/64 loss: 0.24015748500823975
Batch 35/64 loss: 0.23728299140930176
Batch 36/64 loss: 0.2310631275177002
Batch 37/64 loss: 0.25213027000427246
Batch 38/64 loss: 0.22778594493865967
Batch 39/64 loss: 0.23215901851654053
Batch 40/64 loss: 0.264346718788147
Batch 41/64 loss: 0.23363685607910156
Batch 42/64 loss: 0.2445177435874939
Batch 43/64 loss: 0.23357194662094116
Batch 44/64 loss: 0.2489435076713562
Batch 45/64 loss: 0.23499488830566406
Batch 46/64 loss: 0.24604463577270508
Batch 47/64 loss: 0.2426595687866211
Batch 48/64 loss: 0.22910666465759277
Batch 49/64 loss: 0.23849046230316162
Batch 50/64 loss: 0.23819392919540405
Batch 51/64 loss: 0.23964303731918335
Batch 52/64 loss: 0.23749327659606934
Batch 53/64 loss: 0.2361782193183899
Batch 54/64 loss: 0.2359747290611267
Batch 55/64 loss: 0.22723174095153809
Batch 56/64 loss: 0.2360019087791443
Batch 57/64 loss: 0.23927640914916992
Batch 58/64 loss: 0.23278886079788208
Batch 59/64 loss: 0.2399158477783203
Batch 60/64 loss: 0.24662816524505615
Batch 61/64 loss: 0.23125004768371582
Batch 62/64 loss: 0.22883063554763794
Batch 63/64 loss: 0.2379319667816162
Batch 64/64 loss: 0.23692190647125244
Epoch 386  Train loss: 0.2366052314346912  Val loss: 0.2824233844108188
Epoch 387
-------------------------------
Batch 1/64 loss: 0.23071789741516113
Batch 2/64 loss: 0.23462212085723877
Batch 3/64 loss: 0.25094926357269287
Batch 4/64 loss: 0.24620848894119263
Batch 5/64 loss: 0.23254191875457764
Batch 6/64 loss: 0.22886431217193604
Batch 7/64 loss: 0.23945963382720947
Batch 8/64 loss: 0.2349092960357666
Batch 9/64 loss: 0.2373439073562622
Batch 10/64 loss: 0.22776973247528076
Batch 11/64 loss: 0.23977363109588623
Batch 12/64 loss: 0.2321634292602539
Batch 13/64 loss: 0.23023104667663574
Batch 14/64 loss: 0.2248188853263855
Batch 15/64 loss: 0.23887956142425537
Batch 16/64 loss: 0.2454075813293457
Batch 17/64 loss: 0.23282647132873535
Batch 18/64 loss: 0.2382124662399292
Batch 19/64 loss: 0.22297394275665283
Batch 20/64 loss: 0.22623026371002197
Batch 21/64 loss: 0.2388613224029541
Batch 22/64 loss: 0.23456203937530518
Batch 23/64 loss: 0.22911018133163452
Batch 24/64 loss: 0.24709755182266235
Batch 25/64 loss: 0.2327960729598999
Batch 26/64 loss: 0.23717457056045532
Batch 27/64 loss: 0.23974192142486572
Batch 28/64 loss: 0.2252712845802307
Batch 29/64 loss: 0.23280274868011475
Batch 30/64 loss: 0.23613321781158447
Batch 31/64 loss: 0.24409955739974976
Batch 32/64 loss: 0.23938870429992676
Batch 33/64 loss: 0.23858261108398438
Batch 34/64 loss: 0.23721790313720703
Batch 35/64 loss: 0.2388325333595276
Batch 36/64 loss: 0.23554670810699463
Batch 37/64 loss: 0.23663640022277832
Batch 38/64 loss: 0.23141032457351685
Batch 39/64 loss: 0.2308194637298584
Batch 40/64 loss: 0.23059701919555664
Batch 41/64 loss: 0.2541534900665283
Batch 42/64 loss: 0.23008519411087036
Batch 43/64 loss: 0.24578875303268433
Batch 44/64 loss: 0.23350930213928223
Batch 45/64 loss: 0.24153292179107666
Batch 46/64 loss: 0.241784930229187
Batch 47/64 loss: 0.22920942306518555
Batch 48/64 loss: 0.22871315479278564
Batch 49/64 loss: 0.22802412509918213
Batch 50/64 loss: 0.24608314037322998
Batch 51/64 loss: 0.2428293228149414
Batch 52/64 loss: 0.2299593687057495
Batch 53/64 loss: 0.2415618896484375
Batch 54/64 loss: 0.24242496490478516
Batch 55/64 loss: 0.22768718004226685
Batch 56/64 loss: 0.2354060411453247
Batch 57/64 loss: 0.24026238918304443
Batch 58/64 loss: 0.23717927932739258
Batch 59/64 loss: 0.23815321922302246
Batch 60/64 loss: 0.23889625072479248
Batch 61/64 loss: 0.242706298828125
Batch 62/64 loss: 0.2341541051864624
Batch 63/64 loss: 0.2282353639602661
Batch 64/64 loss: 0.23210495710372925
Epoch 387  Train loss: 0.235984389220967  Val loss: 0.2822402895930706
Epoch 388
-------------------------------
Batch 1/64 loss: 0.24052917957305908
Batch 2/64 loss: 0.2437572479248047
Batch 3/64 loss: 0.22692912817001343
Batch 4/64 loss: 0.23850148916244507
Batch 5/64 loss: 0.23688387870788574
Batch 6/64 loss: 0.23795825242996216
Batch 7/64 loss: 0.23561501502990723
Batch 8/64 loss: 0.24290716648101807
Batch 9/64 loss: 0.23349308967590332
Batch 10/64 loss: 0.24476748704910278
Batch 11/64 loss: 0.22590315341949463
Batch 12/64 loss: 0.2294602394104004
Batch 13/64 loss: 0.23880773782730103
Batch 14/64 loss: 0.2335655689239502
Batch 15/64 loss: 0.22639787197113037
Batch 16/64 loss: 0.23468124866485596
Batch 17/64 loss: 0.23260724544525146
Batch 18/64 loss: 0.2329227328300476
Batch 19/64 loss: 0.23130309581756592
Batch 20/64 loss: 0.23358154296875
Batch 21/64 loss: 0.23140954971313477
Batch 22/64 loss: 0.23080575466156006
Batch 23/64 loss: 0.22653162479400635
Batch 24/64 loss: 0.22913575172424316
Batch 25/64 loss: 0.233878493309021
Batch 26/64 loss: 0.23193985223770142
Batch 27/64 loss: 0.22781729698181152
Batch 28/64 loss: 0.2443068027496338
Batch 29/64 loss: 0.230857253074646
Batch 30/64 loss: 0.23186230659484863
Batch 31/64 loss: 0.23101842403411865
Batch 32/64 loss: 0.23406225442886353
Batch 33/64 loss: 0.2391464114189148
Batch 34/64 loss: 0.23579013347625732
Batch 35/64 loss: 0.2344520092010498
Batch 36/64 loss: 0.2355821132659912
Batch 37/64 loss: 0.22928553819656372
Batch 38/64 loss: 0.2399766445159912
Batch 39/64 loss: 0.2290450930595398
Batch 40/64 loss: 0.2440798282623291
Batch 41/64 loss: 0.2266601324081421
Batch 42/64 loss: 0.23426294326782227
Batch 43/64 loss: 0.2234671711921692
Batch 44/64 loss: 0.2362276315689087
Batch 45/64 loss: 0.23079067468643188
Batch 46/64 loss: 0.23264926671981812
Batch 47/64 loss: 0.24510055780410767
Batch 48/64 loss: 0.23993456363677979
Batch 49/64 loss: 0.22941339015960693
Batch 50/64 loss: 0.23456358909606934
Batch 51/64 loss: 0.25768959522247314
Batch 52/64 loss: 0.24349892139434814
Batch 53/64 loss: 0.23904860019683838
Batch 54/64 loss: 0.24163371324539185
Batch 55/64 loss: 0.24492287635803223
Batch 56/64 loss: 0.2447662353515625
Batch 57/64 loss: 0.23697686195373535
Batch 58/64 loss: 0.238972008228302
Batch 59/64 loss: 0.24679666757583618
Batch 60/64 loss: 0.2507959008216858
Batch 61/64 loss: 0.23930996656417847
Batch 62/64 loss: 0.24364978075027466
Batch 63/64 loss: 0.23544073104858398
Batch 64/64 loss: 0.23490077257156372
Epoch 388  Train loss: 0.23598906456255445  Val loss: 0.28150369416397464
Epoch 389
-------------------------------
Batch 1/64 loss: 0.2404218316078186
Batch 2/64 loss: 0.2372981309890747
Batch 3/64 loss: 0.24309629201889038
Batch 4/64 loss: 0.2303379774093628
Batch 5/64 loss: 0.23685866594314575
Batch 6/64 loss: 0.22934943437576294
Batch 7/64 loss: 0.24859100580215454
Batch 8/64 loss: 0.23899805545806885
Batch 9/64 loss: 0.2378138303756714
Batch 10/64 loss: 0.2348262071609497
Batch 11/64 loss: 0.23070454597473145
Batch 12/64 loss: 0.23960381746292114
Batch 13/64 loss: 0.23617017269134521
Batch 14/64 loss: 0.2387184500694275
Batch 15/64 loss: 0.2268385887145996
Batch 16/64 loss: 0.2388976812362671
Batch 17/64 loss: 0.22995620965957642
Batch 18/64 loss: 0.2383703589439392
Batch 19/64 loss: 0.22910559177398682
Batch 20/64 loss: 0.23168706893920898
Batch 21/64 loss: 0.22422027587890625
Batch 22/64 loss: 0.23316854238510132
Batch 23/64 loss: 0.2349422574043274
Batch 24/64 loss: 0.24737179279327393
Batch 25/64 loss: 0.2363584041595459
Batch 26/64 loss: 0.22376543283462524
Batch 27/64 loss: 0.23141765594482422
Batch 28/64 loss: 0.2367473840713501
Batch 29/64 loss: 0.2369869351387024
Batch 30/64 loss: 0.22966718673706055
Batch 31/64 loss: 0.2304571270942688
Batch 32/64 loss: 0.24474835395812988
Batch 33/64 loss: 0.24131989479064941
Batch 34/64 loss: 0.23531365394592285
Batch 35/64 loss: 0.2317357063293457
Batch 36/64 loss: 0.23993176221847534
Batch 37/64 loss: 0.24810022115707397
Batch 38/64 loss: 0.23495948314666748
Batch 39/64 loss: 0.24027156829833984
Batch 40/64 loss: 0.2374253273010254
Batch 41/64 loss: 0.2287377119064331
Batch 42/64 loss: 0.2511104941368103
Batch 43/64 loss: 0.22887670993804932
Batch 44/64 loss: 0.2361900806427002
Batch 45/64 loss: 0.23919188976287842
Batch 46/64 loss: 0.2385278344154358
Batch 47/64 loss: 0.2271173596382141
Batch 48/64 loss: 0.22705644369125366
Batch 49/64 loss: 0.22554773092269897
Batch 50/64 loss: 0.24229836463928223
Batch 51/64 loss: 0.2410719394683838
Batch 52/64 loss: 0.22970610857009888
Batch 53/64 loss: 0.2300388216972351
Batch 54/64 loss: 0.23007512092590332
Batch 55/64 loss: 0.2277824878692627
Batch 56/64 loss: 0.2444758415222168
Batch 57/64 loss: 0.22774875164031982
Batch 58/64 loss: 0.2409723401069641
Batch 59/64 loss: 0.23602724075317383
Batch 60/64 loss: 0.23511528968811035
Batch 61/64 loss: 0.24736613035202026
Batch 62/64 loss: 0.23743820190429688
Batch 63/64 loss: 0.24623459577560425
Batch 64/64 loss: 0.23996126651763916
Epoch 389  Train loss: 0.2358467658360799  Val loss: 0.2814968799807362
Epoch 390
-------------------------------
Batch 1/64 loss: 0.241613507270813
Batch 2/64 loss: 0.2326008677482605
Batch 3/64 loss: 0.2360473871231079
Batch 4/64 loss: 0.230665922164917
Batch 5/64 loss: 0.22948473691940308
Batch 6/64 loss: 0.2301279902458191
Batch 7/64 loss: 0.2378603219985962
Batch 8/64 loss: 0.23146915435791016
Batch 9/64 loss: 0.23497164249420166
Batch 10/64 loss: 0.24021899700164795
Batch 11/64 loss: 0.2408597469329834
Batch 12/64 loss: 0.2303428053855896
Batch 13/64 loss: 0.2412128448486328
Batch 14/64 loss: 0.2393711805343628
Batch 15/64 loss: 0.23130500316619873
Batch 16/64 loss: 0.22665798664093018
Batch 17/64 loss: 0.23530960083007812
Batch 18/64 loss: 0.23532629013061523
Batch 19/64 loss: 0.2357785701751709
Batch 20/64 loss: 0.23174870014190674
Batch 21/64 loss: 0.237362802028656
Batch 22/64 loss: 0.23464393615722656
Batch 23/64 loss: 0.24090373516082764
Batch 24/64 loss: 0.228385329246521
Batch 25/64 loss: 0.24428480863571167
Batch 26/64 loss: 0.23880410194396973
Batch 27/64 loss: 0.2386155128479004
Batch 28/64 loss: 0.24723923206329346
Batch 29/64 loss: 0.22963225841522217
Batch 30/64 loss: 0.23822498321533203
Batch 31/64 loss: 0.23944085836410522
Batch 32/64 loss: 0.23241198062896729
Batch 33/64 loss: 0.23582887649536133
Batch 34/64 loss: 0.24326658248901367
Batch 35/64 loss: 0.233201265335083
Batch 36/64 loss: 0.23165011405944824
Batch 37/64 loss: 0.23424381017684937
Batch 38/64 loss: 0.2349274754524231
Batch 39/64 loss: 0.23488831520080566
Batch 40/64 loss: 0.2262629270553589
Batch 41/64 loss: 0.24299979209899902
Batch 42/64 loss: 0.23882842063903809
Batch 43/64 loss: 0.23460179567337036
Batch 44/64 loss: 0.23245185613632202
Batch 45/64 loss: 0.2398563027381897
Batch 46/64 loss: 0.23438549041748047
Batch 47/64 loss: 0.2377324104309082
Batch 48/64 loss: 0.23497605323791504
Batch 49/64 loss: 0.2395648956298828
Batch 50/64 loss: 0.23759496212005615
Batch 51/64 loss: 0.23612576723098755
Batch 52/64 loss: 0.23829400539398193
Batch 53/64 loss: 0.23822277784347534
Batch 54/64 loss: 0.22970366477966309
Batch 55/64 loss: 0.24722826480865479
Batch 56/64 loss: 0.24663662910461426
Batch 57/64 loss: 0.2209147810935974
Batch 58/64 loss: 0.24854862689971924
Batch 59/64 loss: 0.2314774990081787
Batch 60/64 loss: 0.23255860805511475
Batch 61/64 loss: 0.23482370376586914
Batch 62/64 loss: 0.23783791065216064
Batch 63/64 loss: 0.23554420471191406
Batch 64/64 loss: 0.2451164722442627
Epoch 390  Train loss: 0.23610883039586683  Val loss: 0.28167192346041964
Epoch 391
-------------------------------
Batch 1/64 loss: 0.22960269451141357
Batch 2/64 loss: 0.2333359718322754
Batch 3/64 loss: 0.23049211502075195
Batch 4/64 loss: 0.23105376958847046
Batch 5/64 loss: 0.2376425862312317
Batch 6/64 loss: 0.23504865169525146
Batch 7/64 loss: 0.24041664600372314
Batch 8/64 loss: 0.24021613597869873
Batch 9/64 loss: 0.23781847953796387
Batch 10/64 loss: 0.22297978401184082
Batch 11/64 loss: 0.229561448097229
Batch 12/64 loss: 0.23215854167938232
Batch 13/64 loss: 0.24412870407104492
Batch 14/64 loss: 0.23814499378204346
Batch 15/64 loss: 0.23426997661590576
Batch 16/64 loss: 0.24265623092651367
Batch 17/64 loss: 0.243536114692688
Batch 18/64 loss: 0.23365533351898193
Batch 19/64 loss: 0.2386263608932495
Batch 20/64 loss: 0.23656237125396729
Batch 21/64 loss: 0.22257167100906372
Batch 22/64 loss: 0.2255752682685852
Batch 23/64 loss: 0.2483004331588745
Batch 24/64 loss: 0.22900819778442383
Batch 25/64 loss: 0.23310744762420654
Batch 26/64 loss: 0.23565208911895752
Batch 27/64 loss: 0.2425418496131897
Batch 28/64 loss: 0.23393213748931885
Batch 29/64 loss: 0.23534154891967773
Batch 30/64 loss: 0.2415427565574646
Batch 31/64 loss: 0.24794453382492065
Batch 32/64 loss: 0.2378380298614502
Batch 33/64 loss: 0.2341165542602539
Batch 34/64 loss: 0.24195367097854614
Batch 35/64 loss: 0.24072420597076416
Batch 36/64 loss: 0.24206304550170898
Batch 37/64 loss: 0.23462361097335815
Batch 38/64 loss: 0.2363789677619934
Batch 39/64 loss: 0.23471486568450928
Batch 40/64 loss: 0.23005086183547974
Batch 41/64 loss: 0.23354870080947876
Batch 42/64 loss: 0.23977410793304443
Batch 43/64 loss: 0.23684406280517578
Batch 44/64 loss: 0.25345659255981445
Batch 45/64 loss: 0.2316347360610962
Batch 46/64 loss: 0.22883892059326172
Batch 47/64 loss: 0.25278711318969727
Batch 48/64 loss: 0.22896873950958252
Batch 49/64 loss: 0.23805540800094604
Batch 50/64 loss: 0.23015284538269043
Batch 51/64 loss: 0.24729418754577637
Batch 52/64 loss: 0.23021864891052246
Batch 53/64 loss: 0.2305591106414795
Batch 54/64 loss: 0.22955071926116943
Batch 55/64 loss: 0.23386693000793457
Batch 56/64 loss: 0.2370682954788208
Batch 57/64 loss: 0.24199795722961426
Batch 58/64 loss: 0.23641520738601685
Batch 59/64 loss: 0.2394871711730957
Batch 60/64 loss: 0.22833430767059326
Batch 61/64 loss: 0.2311772108078003
Batch 62/64 loss: 0.23177474737167358
Batch 63/64 loss: 0.2349644899368286
Batch 64/64 loss: 0.23138153553009033
Epoch 391  Train loss: 0.23592462773416556  Val loss: 0.2812900748039849
Saving best model, epoch: 391
Epoch 392
-------------------------------
Batch 1/64 loss: 0.25163495540618896
Batch 2/64 loss: 0.22600561380386353
Batch 3/64 loss: 0.2397783398628235
Batch 4/64 loss: 0.25002366304397583
Batch 5/64 loss: 0.23319053649902344
Batch 6/64 loss: 0.2272477149963379
Batch 7/64 loss: 0.23960620164871216
Batch 8/64 loss: 0.2277321219444275
Batch 9/64 loss: 0.23496097326278687
Batch 10/64 loss: 0.22780781984329224
Batch 11/64 loss: 0.2349081039428711
Batch 12/64 loss: 0.2415410280227661
Batch 13/64 loss: 0.23589575290679932
Batch 14/64 loss: 0.23895233869552612
Batch 15/64 loss: 0.2403498888015747
Batch 16/64 loss: 0.24378514289855957
Batch 17/64 loss: 0.238925039768219
Batch 18/64 loss: 0.23633897304534912
Batch 19/64 loss: 0.22511029243469238
Batch 20/64 loss: 0.2342991828918457
Batch 21/64 loss: 0.2281644344329834
Batch 22/64 loss: 0.22852355241775513
Batch 23/64 loss: 0.23713445663452148
Batch 24/64 loss: 0.2367534637451172
Batch 25/64 loss: 0.24052298069000244
Batch 26/64 loss: 0.21907955408096313
Batch 27/64 loss: 0.24526536464691162
Batch 28/64 loss: 0.2337205410003662
Batch 29/64 loss: 0.2274109125137329
Batch 30/64 loss: 0.2349252700805664
Batch 31/64 loss: 0.23608219623565674
Batch 32/64 loss: 0.24002617597579956
Batch 33/64 loss: 0.24208450317382812
Batch 34/64 loss: 0.2326074242591858
Batch 35/64 loss: 0.23335832357406616
Batch 36/64 loss: 0.23268049955368042
Batch 37/64 loss: 0.23735535144805908
Batch 38/64 loss: 0.23722755908966064
Batch 39/64 loss: 0.23676282167434692
Batch 40/64 loss: 0.23188060522079468
Batch 41/64 loss: 0.23181283473968506
Batch 42/64 loss: 0.23272550106048584
Batch 43/64 loss: 0.22780197858810425
Batch 44/64 loss: 0.23039394617080688
Batch 45/64 loss: 0.2351055145263672
Batch 46/64 loss: 0.23334455490112305
Batch 47/64 loss: 0.233708918094635
Batch 48/64 loss: 0.22919487953186035
Batch 49/64 loss: 0.24244964122772217
Batch 50/64 loss: 0.2384902834892273
Batch 51/64 loss: 0.23575657606124878
Batch 52/64 loss: 0.2344146966934204
Batch 53/64 loss: 0.23686981201171875
Batch 54/64 loss: 0.23241019248962402
Batch 55/64 loss: 0.23560357093811035
Batch 56/64 loss: 0.23472261428833008
Batch 57/64 loss: 0.23241400718688965
Batch 58/64 loss: 0.2323175072669983
Batch 59/64 loss: 0.23769700527191162
Batch 60/64 loss: 0.2361372709274292
Batch 61/64 loss: 0.2280692458152771
Batch 62/64 loss: 0.24160420894622803
Batch 63/64 loss: 0.23127686977386475
Batch 64/64 loss: 0.25627458095550537
Epoch 392  Train loss: 0.23523430964526007  Val loss: 0.2820589655043743
Epoch 393
-------------------------------
Batch 1/64 loss: 0.23228269815444946
Batch 2/64 loss: 0.23186254501342773
Batch 3/64 loss: 0.2214517593383789
Batch 4/64 loss: 0.2375638484954834
Batch 5/64 loss: 0.22651851177215576
Batch 6/64 loss: 0.2258971929550171
Batch 7/64 loss: 0.2441859245300293
Batch 8/64 loss: 0.23488223552703857
Batch 9/64 loss: 0.23444318771362305
Batch 10/64 loss: 0.23944950103759766
Batch 11/64 loss: 0.23501312732696533
Batch 12/64 loss: 0.23757362365722656
Batch 13/64 loss: 0.23298537731170654
Batch 14/64 loss: 0.24559146165847778
Batch 15/64 loss: 0.22937405109405518
Batch 16/64 loss: 0.23614728450775146
Batch 17/64 loss: 0.24574488401412964
Batch 18/64 loss: 0.2374427318572998
Batch 19/64 loss: 0.23514091968536377
Batch 20/64 loss: 0.22700655460357666
Batch 21/64 loss: 0.2365037202835083
Batch 22/64 loss: 0.23752200603485107
Batch 23/64 loss: 0.23172438144683838
Batch 24/64 loss: 0.2384595274925232
Batch 25/64 loss: 0.22856098413467407
Batch 26/64 loss: 0.23775172233581543
Batch 27/64 loss: 0.2310166358947754
Batch 28/64 loss: 0.22589612007141113
Batch 29/64 loss: 0.2286975383758545
Batch 30/64 loss: 0.21953696012496948
Batch 31/64 loss: 0.23407578468322754
Batch 32/64 loss: 0.23829573392868042
Batch 33/64 loss: 0.23124158382415771
Batch 34/64 loss: 0.24536120891571045
Batch 35/64 loss: 0.24196946620941162
Batch 36/64 loss: 0.2446122169494629
Batch 37/64 loss: 0.24306190013885498
Batch 38/64 loss: 0.2380739450454712
Batch 39/64 loss: 0.22927838563919067
Batch 40/64 loss: 0.22441381216049194
Batch 41/64 loss: 0.22414171695709229
Batch 42/64 loss: 0.22725766897201538
Batch 43/64 loss: 0.23448985815048218
Batch 44/64 loss: 0.2420278787612915
Batch 45/64 loss: 0.24012839794158936
Batch 46/64 loss: 0.23123514652252197
Batch 47/64 loss: 0.230698823928833
Batch 48/64 loss: 0.23961138725280762
Batch 49/64 loss: 0.2361048460006714
Batch 50/64 loss: 0.24246180057525635
Batch 51/64 loss: 0.23622053861618042
Batch 52/64 loss: 0.23692560195922852
Batch 53/64 loss: 0.2355358600616455
Batch 54/64 loss: 0.2381533980369568
Batch 55/64 loss: 0.22866100072860718
Batch 56/64 loss: 0.24104321002960205
Batch 57/64 loss: 0.23848974704742432
Batch 58/64 loss: 0.22937190532684326
Batch 59/64 loss: 0.23281997442245483
Batch 60/64 loss: 0.23774611949920654
Batch 61/64 loss: 0.23938143253326416
Batch 62/64 loss: 0.23923367261886597
Batch 63/64 loss: 0.24290400743484497
Batch 64/64 loss: 0.25067049264907837
Epoch 393  Train loss: 0.23512561438130397  Val loss: 0.28217207852917436
Epoch 394
-------------------------------
Batch 1/64 loss: 0.24027681350708008
Batch 2/64 loss: 0.2376699447631836
Batch 3/64 loss: 0.23195821046829224
Batch 4/64 loss: 0.22989308834075928
Batch 5/64 loss: 0.23034489154815674
Batch 6/64 loss: 0.24904286861419678
Batch 7/64 loss: 0.22982776165008545
Batch 8/64 loss: 0.23046839237213135
Batch 9/64 loss: 0.23175561428070068
Batch 10/64 loss: 0.23913788795471191
Batch 11/64 loss: 0.22845131158828735
Batch 12/64 loss: 0.2333078384399414
Batch 13/64 loss: 0.2269284725189209
Batch 14/64 loss: 0.22997832298278809
Batch 15/64 loss: 0.23419189453125
Batch 16/64 loss: 0.2334883213043213
Batch 17/64 loss: 0.23153293132781982
Batch 18/64 loss: 0.21934878826141357
Batch 19/64 loss: 0.25009095668792725
Batch 20/64 loss: 0.24447417259216309
Batch 21/64 loss: 0.2305067777633667
Batch 22/64 loss: 0.24299657344818115
Batch 23/64 loss: 0.2331799864768982
Batch 24/64 loss: 0.24292194843292236
Batch 25/64 loss: 0.2350093126296997
Batch 26/64 loss: 0.23342108726501465
Batch 27/64 loss: 0.23573017120361328
Batch 28/64 loss: 0.23323965072631836
Batch 29/64 loss: 0.24225842952728271
Batch 30/64 loss: 0.2303980588912964
Batch 31/64 loss: 0.23846149444580078
Batch 32/64 loss: 0.22381460666656494
Batch 33/64 loss: 0.24107646942138672
Batch 34/64 loss: 0.24499940872192383
Batch 35/64 loss: 0.23144125938415527
Batch 36/64 loss: 0.2348421812057495
Batch 37/64 loss: 0.23823261260986328
Batch 38/64 loss: 0.22778701782226562
Batch 39/64 loss: 0.2287205457687378
Batch 40/64 loss: 0.23777300119400024
Batch 41/64 loss: 0.2421175241470337
Batch 42/64 loss: 0.2323390245437622
Batch 43/64 loss: 0.23371899127960205
Batch 44/64 loss: 0.23938167095184326
Batch 45/64 loss: 0.23133158683776855
Batch 46/64 loss: 0.22978949546813965
Batch 47/64 loss: 0.23210811614990234
Batch 48/64 loss: 0.22541475296020508
Batch 49/64 loss: 0.2381800413131714
Batch 50/64 loss: 0.221216082572937
Batch 51/64 loss: 0.23201203346252441
Batch 52/64 loss: 0.24692338705062866
Batch 53/64 loss: 0.23123836517333984
Batch 54/64 loss: 0.22924387454986572
Batch 55/64 loss: 0.23244309425354004
Batch 56/64 loss: 0.22936558723449707
Batch 57/64 loss: 0.2417466640472412
Batch 58/64 loss: 0.23131561279296875
Batch 59/64 loss: 0.2321956753730774
Batch 60/64 loss: 0.23759639263153076
Batch 61/64 loss: 0.23934829235076904
Batch 62/64 loss: 0.23532158136367798
Batch 63/64 loss: 0.24119752645492554
Batch 64/64 loss: 0.24114829301834106
Epoch 394  Train loss: 0.23459428502064125  Val loss: 0.28247085633556457
Epoch 395
-------------------------------
Batch 1/64 loss: 0.22796231508255005
Batch 2/64 loss: 0.23921000957489014
Batch 3/64 loss: 0.2309308648109436
Batch 4/64 loss: 0.22843670845031738
Batch 5/64 loss: 0.22434508800506592
Batch 6/64 loss: 0.2285822033882141
Batch 7/64 loss: 0.23357892036437988
Batch 8/64 loss: 0.2412031888961792
Batch 9/64 loss: 0.2454860806465149
Batch 10/64 loss: 0.22815322875976562
Batch 11/64 loss: 0.23040759563446045
Batch 12/64 loss: 0.23542571067810059
Batch 13/64 loss: 0.23285198211669922
Batch 14/64 loss: 0.23427844047546387
Batch 15/64 loss: 0.23664450645446777
Batch 16/64 loss: 0.23578917980194092
Batch 17/64 loss: 0.22218912839889526
Batch 18/64 loss: 0.23878628015518188
Batch 19/64 loss: 0.23392099142074585
Batch 20/64 loss: 0.2322838306427002
Batch 21/64 loss: 0.2325730323791504
Batch 22/64 loss: 0.23649775981903076
Batch 23/64 loss: 0.24518728256225586
Batch 24/64 loss: 0.22721564769744873
Batch 25/64 loss: 0.23602783679962158
Batch 26/64 loss: 0.23275721073150635
Batch 27/64 loss: 0.22727340459823608
Batch 28/64 loss: 0.2266237735748291
Batch 29/64 loss: 0.23285651206970215
Batch 30/64 loss: 0.22585922479629517
Batch 31/64 loss: 0.2287890911102295
Batch 32/64 loss: 0.23550856113433838
Batch 33/64 loss: 0.23272627592086792
Batch 34/64 loss: 0.23340857028961182
Batch 35/64 loss: 0.24700427055358887
Batch 36/64 loss: 0.23565733432769775
Batch 37/64 loss: 0.2388756275177002
Batch 38/64 loss: 0.2507622241973877
Batch 39/64 loss: 0.2410954236984253
Batch 40/64 loss: 0.24006223678588867
Batch 41/64 loss: 0.23496466875076294
Batch 42/64 loss: 0.23824405670166016
Batch 43/64 loss: 0.2412019968032837
Batch 44/64 loss: 0.24650514125823975
Batch 45/64 loss: 0.23788148164749146
Batch 46/64 loss: 0.2376757264137268
Batch 47/64 loss: 0.2360823154449463
Batch 48/64 loss: 0.2302798628807068
Batch 49/64 loss: 0.23185455799102783
Batch 50/64 loss: 0.2281796932220459
Batch 51/64 loss: 0.2459937334060669
Batch 52/64 loss: 0.22741997241973877
Batch 53/64 loss: 0.23247003555297852
Batch 54/64 loss: 0.23694348335266113
Batch 55/64 loss: 0.2347015142440796
Batch 56/64 loss: 0.23075228929519653
Batch 57/64 loss: 0.23753571510314941
Batch 58/64 loss: 0.2334282398223877
Batch 59/64 loss: 0.24615240097045898
Batch 60/64 loss: 0.2340850830078125
Batch 61/64 loss: 0.23442822694778442
Batch 62/64 loss: 0.2323208451271057
Batch 63/64 loss: 0.23663115501403809
Batch 64/64 loss: 0.22945934534072876
Epoch 395  Train loss: 0.23474594915614408  Val loss: 0.28202527187943865
Epoch 396
-------------------------------
Batch 1/64 loss: 0.22934561967849731
Batch 2/64 loss: 0.2247517704963684
Batch 3/64 loss: 0.23367631435394287
Batch 4/64 loss: 0.2422131896018982
Batch 5/64 loss: 0.23345762491226196
Batch 6/64 loss: 0.2398010492324829
Batch 7/64 loss: 0.22845780849456787
Batch 8/64 loss: 0.2338123321533203
Batch 9/64 loss: 0.23609274625778198
Batch 10/64 loss: 0.23619294166564941
Batch 11/64 loss: 0.23283791542053223
Batch 12/64 loss: 0.23034000396728516
Batch 13/64 loss: 0.23349833488464355
Batch 14/64 loss: 0.23296606540679932
Batch 15/64 loss: 0.23059701919555664
Batch 16/64 loss: 0.22729098796844482
Batch 17/64 loss: 0.22948932647705078
Batch 18/64 loss: 0.23296523094177246
Batch 19/64 loss: 0.2264363169670105
Batch 20/64 loss: 0.2253130078315735
Batch 21/64 loss: 0.25079840421676636
Batch 22/64 loss: 0.232635498046875
Batch 23/64 loss: 0.23892217874526978
Batch 24/64 loss: 0.23889237642288208
Batch 25/64 loss: 0.23756444454193115
Batch 26/64 loss: 0.23557060956954956
Batch 27/64 loss: 0.23474043607711792
Batch 28/64 loss: 0.2271307110786438
Batch 29/64 loss: 0.23565006256103516
Batch 30/64 loss: 0.23048341274261475
Batch 31/64 loss: 0.2406860589981079
Batch 32/64 loss: 0.22716659307479858
Batch 33/64 loss: 0.2418375015258789
Batch 34/64 loss: 0.23365378379821777
Batch 35/64 loss: 0.2221861481666565
Batch 36/64 loss: 0.23053473234176636
Batch 37/64 loss: 0.23096150159835815
Batch 38/64 loss: 0.2321884036064148
Batch 39/64 loss: 0.23901772499084473
Batch 40/64 loss: 0.23734241724014282
Batch 41/64 loss: 0.2357933521270752
Batch 42/64 loss: 0.23440462350845337
Batch 43/64 loss: 0.23098307847976685
Batch 44/64 loss: 0.23853003978729248
Batch 45/64 loss: 0.2262263298034668
Batch 46/64 loss: 0.23379182815551758
Batch 47/64 loss: 0.23050439357757568
Batch 48/64 loss: 0.2341850996017456
Batch 49/64 loss: 0.22966432571411133
Batch 50/64 loss: 0.23730218410491943
Batch 51/64 loss: 0.23681187629699707
Batch 52/64 loss: 0.23366820812225342
Batch 53/64 loss: 0.23989301919937134
Batch 54/64 loss: 0.24704056978225708
Batch 55/64 loss: 0.24052387475967407
Batch 56/64 loss: 0.24515962600708008
Batch 57/64 loss: 0.23384153842926025
Batch 58/64 loss: 0.2428138256072998
Batch 59/64 loss: 0.22690832614898682
Batch 60/64 loss: 0.23118853569030762
Batch 61/64 loss: 0.23856568336486816
Batch 62/64 loss: 0.23523390293121338
Batch 63/64 loss: 0.235554039478302
Batch 64/64 loss: 0.25274765491485596
Epoch 396  Train loss: 0.2344415314057294  Val loss: 0.28111306416619686
Saving best model, epoch: 396
Epoch 397
-------------------------------
Batch 1/64 loss: 0.24294400215148926
Batch 2/64 loss: 0.22849810123443604
Batch 3/64 loss: 0.23096758127212524
Batch 4/64 loss: 0.22801220417022705
Batch 5/64 loss: 0.23704564571380615
Batch 6/64 loss: 0.23837846517562866
Batch 7/64 loss: 0.2467939257621765
Batch 8/64 loss: 0.23009878396987915
Batch 9/64 loss: 0.23132294416427612
Batch 10/64 loss: 0.23744988441467285
Batch 11/64 loss: 0.22644591331481934
Batch 12/64 loss: 0.22646653652191162
Batch 13/64 loss: 0.2323022484779358
Batch 14/64 loss: 0.2453244924545288
Batch 15/64 loss: 0.2395923137664795
Batch 16/64 loss: 0.23957359790802002
Batch 17/64 loss: 0.2328428030014038
Batch 18/64 loss: 0.22240424156188965
Batch 19/64 loss: 0.2440260648727417
Batch 20/64 loss: 0.24142491817474365
Batch 21/64 loss: 0.23565977811813354
Batch 22/64 loss: 0.23226583003997803
Batch 23/64 loss: 0.23478782176971436
Batch 24/64 loss: 0.23931336402893066
Batch 25/64 loss: 0.2255876064300537
Batch 26/64 loss: 0.23417067527770996
Batch 27/64 loss: 0.22575640678405762
Batch 28/64 loss: 0.2469002604484558
Batch 29/64 loss: 0.24401050806045532
Batch 30/64 loss: 0.23960727453231812
Batch 31/64 loss: 0.23557281494140625
Batch 32/64 loss: 0.23705458641052246
Batch 33/64 loss: 0.2264445424079895
Batch 34/64 loss: 0.23402899503707886
Batch 35/64 loss: 0.2387528419494629
Batch 36/64 loss: 0.24235224723815918
Batch 37/64 loss: 0.23497086763381958
Batch 38/64 loss: 0.2347501516342163
Batch 39/64 loss: 0.22767287492752075
Batch 40/64 loss: 0.22991955280303955
Batch 41/64 loss: 0.23374128341674805
Batch 42/64 loss: 0.23219138383865356
Batch 43/64 loss: 0.2461071014404297
Batch 44/64 loss: 0.24578046798706055
Batch 45/64 loss: 0.22902154922485352
Batch 46/64 loss: 0.2310657501220703
Batch 47/64 loss: 0.24069994688034058
Batch 48/64 loss: 0.2264409065246582
Batch 49/64 loss: 0.23721683025360107
Batch 50/64 loss: 0.2379152774810791
Batch 51/64 loss: 0.24115663766860962
Batch 52/64 loss: 0.22692745923995972
Batch 53/64 loss: 0.2306605577468872
Batch 54/64 loss: 0.23114150762557983
Batch 55/64 loss: 0.23469007015228271
Batch 56/64 loss: 0.2480350136756897
Batch 57/64 loss: 0.23517227172851562
Batch 58/64 loss: 0.24187684059143066
Batch 59/64 loss: 0.2338724136352539
Batch 60/64 loss: 0.23288565874099731
Batch 61/64 loss: 0.23456132411956787
Batch 62/64 loss: 0.24803948402404785
Batch 63/64 loss: 0.23791581392288208
Batch 64/64 loss: 0.2337043285369873
Epoch 397  Train loss: 0.23551196023529652  Val loss: 0.2812209895386319
Epoch 398
-------------------------------
Batch 1/64 loss: 0.23675113916397095
Batch 2/64 loss: 0.23703157901763916
Batch 3/64 loss: 0.24094748497009277
Batch 4/64 loss: 0.24269956350326538
Batch 5/64 loss: 0.22962218523025513
Batch 6/64 loss: 0.22567367553710938
Batch 7/64 loss: 0.23432236909866333
Batch 8/64 loss: 0.2273961305618286
Batch 9/64 loss: 0.23642385005950928
Batch 10/64 loss: 0.2279953956604004
Batch 11/64 loss: 0.22490495443344116
Batch 12/64 loss: 0.23627567291259766
Batch 13/64 loss: 0.25199151039123535
Batch 14/64 loss: 0.23416578769683838
Batch 15/64 loss: 0.23430085182189941
Batch 16/64 loss: 0.22432851791381836
Batch 17/64 loss: 0.23118221759796143
Batch 18/64 loss: 0.24819684028625488
Batch 19/64 loss: 0.24091511964797974
Batch 20/64 loss: 0.23689663410186768
Batch 21/64 loss: 0.24101603031158447
Batch 22/64 loss: 0.23587679862976074
Batch 23/64 loss: 0.24087101221084595
Batch 24/64 loss: 0.23959946632385254
Batch 25/64 loss: 0.24061381816864014
Batch 26/64 loss: 0.24132418632507324
Batch 27/64 loss: 0.2386455535888672
Batch 28/64 loss: 0.232974112033844
Batch 29/64 loss: 0.2353219985961914
Batch 30/64 loss: 0.23232829570770264
Batch 31/64 loss: 0.22524237632751465
Batch 32/64 loss: 0.24074405431747437
Batch 33/64 loss: 0.23192167282104492
Batch 34/64 loss: 0.22997570037841797
Batch 35/64 loss: 0.23200488090515137
Batch 36/64 loss: 0.22540438175201416
Batch 37/64 loss: 0.2292025089263916
Batch 38/64 loss: 0.24127674102783203
Batch 39/64 loss: 0.2301706075668335
Batch 40/64 loss: 0.22966963052749634
Batch 41/64 loss: 0.2338983416557312
Batch 42/64 loss: 0.23232793807983398
Batch 43/64 loss: 0.2339347004890442
Batch 44/64 loss: 0.23383218050003052
Batch 45/64 loss: 0.23245257139205933
Batch 46/64 loss: 0.23180580139160156
Batch 47/64 loss: 0.23165249824523926
Batch 48/64 loss: 0.23296773433685303
Batch 49/64 loss: 0.2269020676612854
Batch 50/64 loss: 0.23210930824279785
Batch 51/64 loss: 0.245164692401886
Batch 52/64 loss: 0.2302485704421997
Batch 53/64 loss: 0.2434478998184204
Batch 54/64 loss: 0.24537140130996704
Batch 55/64 loss: 0.23229312896728516
Batch 56/64 loss: 0.2446545958518982
Batch 57/64 loss: 0.23347455263137817
Batch 58/64 loss: 0.23436814546585083
Batch 59/64 loss: 0.21867746114730835
Batch 60/64 loss: 0.22981178760528564
Batch 61/64 loss: 0.24728155136108398
Batch 62/64 loss: 0.23571884632110596
Batch 63/64 loss: 0.22693979740142822
Batch 64/64 loss: 0.24007552862167358
Epoch 398  Train loss: 0.23475447098414104  Val loss: 0.2805019766604368
Saving best model, epoch: 398
Epoch 399
-------------------------------
Batch 1/64 loss: 0.225713312625885
Batch 2/64 loss: 0.24184727668762207
Batch 3/64 loss: 0.23401737213134766
Batch 4/64 loss: 0.23021996021270752
Batch 5/64 loss: 0.23912948369979858
Batch 6/64 loss: 0.23386001586914062
Batch 7/64 loss: 0.2362593412399292
Batch 8/64 loss: 0.23776781558990479
Batch 9/64 loss: 0.2484613060951233
Batch 10/64 loss: 0.23786556720733643
Batch 11/64 loss: 0.23622465133666992
Batch 12/64 loss: 0.23020970821380615
Batch 13/64 loss: 0.23754411935806274
Batch 14/64 loss: 0.23945540189743042
Batch 15/64 loss: 0.23441529273986816
Batch 16/64 loss: 0.23265337944030762
Batch 17/64 loss: 0.22987592220306396
Batch 18/64 loss: 0.22617954015731812
Batch 19/64 loss: 0.23067474365234375
Batch 20/64 loss: 0.231814444065094
Batch 21/64 loss: 0.22614479064941406
Batch 22/64 loss: 0.24197852611541748
Batch 23/64 loss: 0.23568344116210938
Batch 24/64 loss: 0.2348705530166626
Batch 25/64 loss: 0.22836613655090332
Batch 26/64 loss: 0.2298075556755066
Batch 27/64 loss: 0.2324751615524292
Batch 28/64 loss: 0.23005425930023193
Batch 29/64 loss: 0.2404111623764038
Batch 30/64 loss: 0.2400970458984375
Batch 31/64 loss: 0.24873024225234985
Batch 32/64 loss: 0.2325860857963562
Batch 33/64 loss: 0.23252272605895996
Batch 34/64 loss: 0.2280232310295105
Batch 35/64 loss: 0.24769079685211182
Batch 36/64 loss: 0.2288724184036255
Batch 37/64 loss: 0.2334975004196167
Batch 38/64 loss: 0.22642171382904053
Batch 39/64 loss: 0.22997426986694336
Batch 40/64 loss: 0.22398221492767334
Batch 41/64 loss: 0.22906458377838135
Batch 42/64 loss: 0.23016393184661865
Batch 43/64 loss: 0.23171424865722656
Batch 44/64 loss: 0.2305746078491211
Batch 45/64 loss: 0.23306995630264282
Batch 46/64 loss: 0.2252027988433838
Batch 47/64 loss: 0.23162448406219482
Batch 48/64 loss: 0.2418447732925415
Batch 49/64 loss: 0.23592078685760498
Batch 50/64 loss: 0.23602831363677979
Batch 51/64 loss: 0.22717416286468506
Batch 52/64 loss: 0.22641384601593018
Batch 53/64 loss: 0.237809419631958
Batch 54/64 loss: 0.23843848705291748
Batch 55/64 loss: 0.23187196254730225
Batch 56/64 loss: 0.22309792041778564
Batch 57/64 loss: 0.2505252957344055
Batch 58/64 loss: 0.2359708547592163
Batch 59/64 loss: 0.2244476079940796
Batch 60/64 loss: 0.23230016231536865
Batch 61/64 loss: 0.24032634496688843
Batch 62/64 loss: 0.2297641634941101
Batch 63/64 loss: 0.2357625961303711
Batch 64/64 loss: 0.2599220871925354
Epoch 399  Train loss: 0.23404598212709612  Val loss: 0.2825263232709616
Epoch 400
-------------------------------
Batch 1/64 loss: 0.2287260890007019
Batch 2/64 loss: 0.2506052255630493
Batch 3/64 loss: 0.23107635974884033
Batch 4/64 loss: 0.23588407039642334
Batch 5/64 loss: 0.2338346242904663
Batch 6/64 loss: 0.25185632705688477
Batch 7/64 loss: 0.2353009581565857
Batch 8/64 loss: 0.23593533039093018
Batch 9/64 loss: 0.23286527395248413
Batch 10/64 loss: 0.22588509321212769
Batch 11/64 loss: 0.23498177528381348
Batch 12/64 loss: 0.22347640991210938
Batch 13/64 loss: 0.23058807849884033
Batch 14/64 loss: 0.2218034267425537
Batch 15/64 loss: 0.22653377056121826
Batch 16/64 loss: 0.2382434606552124
Batch 17/64 loss: 0.23991769552230835
Batch 18/64 loss: 0.23964709043502808
Batch 19/64 loss: 0.24663692712783813
Batch 20/64 loss: 0.23457276821136475
Batch 21/64 loss: 0.2343515157699585
Batch 22/64 loss: 0.2244207262992859
Batch 23/64 loss: 0.224595308303833
Batch 24/64 loss: 0.2270432710647583
Batch 25/64 loss: 0.22899383306503296
Batch 26/64 loss: 0.24004113674163818
Batch 27/64 loss: 0.23533570766448975
Batch 28/64 loss: 0.23197698593139648
Batch 29/64 loss: 0.22359633445739746
Batch 30/64 loss: 0.2388579249382019
Batch 31/64 loss: 0.22987353801727295
Batch 32/64 loss: 0.2501131296157837
Batch 33/64 loss: 0.23021972179412842
Batch 34/64 loss: 0.24199140071868896
Batch 35/64 loss: 0.23186469078063965
Batch 36/64 loss: 0.22354543209075928
Batch 37/64 loss: 0.2332046627998352
Batch 38/64 loss: 0.2357872724533081
Batch 39/64 loss: 0.23116517066955566
Batch 40/64 loss: 0.22950351238250732
Batch 41/64 loss: 0.2303258180618286
Batch 42/64 loss: 0.2266993522644043
Batch 43/64 loss: 0.22727131843566895
Batch 44/64 loss: 0.23970884084701538
Batch 45/64 loss: 0.238897442817688
Batch 46/64 loss: 0.2338472604751587
Batch 47/64 loss: 0.2361307144165039
Batch 48/64 loss: 0.23006212711334229
Batch 49/64 loss: 0.23348605632781982
Batch 50/64 loss: 0.24548959732055664
Batch 51/64 loss: 0.22385519742965698
Batch 52/64 loss: 0.2286233901977539
Batch 53/64 loss: 0.2327260971069336
Batch 54/64 loss: 0.2421039342880249
Batch 55/64 loss: 0.23591649532318115
Batch 56/64 loss: 0.2323881983757019
Batch 57/64 loss: 0.24051940441131592
Batch 58/64 loss: 0.2462160587310791
Batch 59/64 loss: 0.23792624473571777
Batch 60/64 loss: 0.2283254861831665
Batch 61/64 loss: 0.2534043788909912
Batch 62/64 loss: 0.24037206172943115
Batch 63/64 loss: 0.23171234130859375
Batch 64/64 loss: 0.24124246835708618
Epoch 400  Train loss: 0.23438104624841727  Val loss: 0.28114632478694324
Epoch 401
-------------------------------
Batch 1/64 loss: 0.22589576244354248
Batch 2/64 loss: 0.23666751384735107
Batch 3/64 loss: 0.22942566871643066
Batch 4/64 loss: 0.23557496070861816
Batch 5/64 loss: 0.22933423519134521
Batch 6/64 loss: 0.23905956745147705
Batch 7/64 loss: 0.23690348863601685
Batch 8/64 loss: 0.23128414154052734
Batch 9/64 loss: 0.24011284112930298
Batch 10/64 loss: 0.23242855072021484
Batch 11/64 loss: 0.2270280122756958
Batch 12/64 loss: 0.2240477204322815
Batch 13/64 loss: 0.23913908004760742
Batch 14/64 loss: 0.25814032554626465
Batch 15/64 loss: 0.22320270538330078
Batch 16/64 loss: 0.22480720281600952
Batch 17/64 loss: 0.2383100390434265
Batch 18/64 loss: 0.2354143261909485
Batch 19/64 loss: 0.23344171047210693
Batch 20/64 loss: 0.22901856899261475
Batch 21/64 loss: 0.2409084439277649
Batch 22/64 loss: 0.22326982021331787
Batch 23/64 loss: 0.23424053192138672
Batch 24/64 loss: 0.22840440273284912
Batch 25/64 loss: 0.24439942836761475
Batch 26/64 loss: 0.22462308406829834
Batch 27/64 loss: 0.23193007707595825
Batch 28/64 loss: 0.2393627166748047
Batch 29/64 loss: 0.23566573858261108
Batch 30/64 loss: 0.24322831630706787
Batch 31/64 loss: 0.22876673936843872
Batch 32/64 loss: 0.22863370180130005
Batch 33/64 loss: 0.23520660400390625
Batch 34/64 loss: 0.22228288650512695
Batch 35/64 loss: 0.23716223239898682
Batch 36/64 loss: 0.23363947868347168
Batch 37/64 loss: 0.2370600700378418
Batch 38/64 loss: 0.23908483982086182
Batch 39/64 loss: 0.23181986808776855
Batch 40/64 loss: 0.23740720748901367
Batch 41/64 loss: 0.23887896537780762
Batch 42/64 loss: 0.24115020036697388
Batch 43/64 loss: 0.23739218711853027
Batch 44/64 loss: 0.2428194284439087
Batch 45/64 loss: 0.22843122482299805
Batch 46/64 loss: 0.23706477880477905
Batch 47/64 loss: 0.23966503143310547
Batch 48/64 loss: 0.2386840581893921
Batch 49/64 loss: 0.23349201679229736
Batch 50/64 loss: 0.22852885723114014
Batch 51/64 loss: 0.23201966285705566
Batch 52/64 loss: 0.22297978401184082
Batch 53/64 loss: 0.23516231775283813
Batch 54/64 loss: 0.24267041683197021
Batch 55/64 loss: 0.235706627368927
Batch 56/64 loss: 0.24336862564086914
Batch 57/64 loss: 0.2278270721435547
Batch 58/64 loss: 0.23747050762176514
Batch 59/64 loss: 0.23748672008514404
Batch 60/64 loss: 0.23489856719970703
Batch 61/64 loss: 0.22212016582489014
Batch 62/64 loss: 0.22961241006851196
Batch 63/64 loss: 0.2274964451789856
Batch 64/64 loss: 0.2475166916847229
Epoch 401  Train loss: 0.23414739136602364  Val loss: 0.28284938515666425
Epoch 402
-------------------------------
Batch 1/64 loss: 0.22994601726531982
Batch 2/64 loss: 0.22462648153305054
Batch 3/64 loss: 0.2334250807762146
Batch 4/64 loss: 0.2218482494354248
Batch 5/64 loss: 0.23967266082763672
Batch 6/64 loss: 0.2386571168899536
Batch 7/64 loss: 0.24245965480804443
Batch 8/64 loss: 0.23284697532653809
Batch 9/64 loss: 0.229528546333313
Batch 10/64 loss: 0.23551803827285767
Batch 11/64 loss: 0.22738420963287354
Batch 12/64 loss: 0.23665446043014526
Batch 13/64 loss: 0.23499417304992676
Batch 14/64 loss: 0.23435300588607788
Batch 15/64 loss: 0.23049885034561157
Batch 16/64 loss: 0.23121386766433716
Batch 17/64 loss: 0.23273980617523193
Batch 18/64 loss: 0.23806297779083252
Batch 19/64 loss: 0.23521673679351807
Batch 20/64 loss: 0.23167216777801514
Batch 21/64 loss: 0.23398470878601074
Batch 22/64 loss: 0.2328016757965088
Batch 23/64 loss: 0.23302364349365234
Batch 24/64 loss: 0.2503206729888916
Batch 25/64 loss: 0.23547333478927612
Batch 26/64 loss: 0.23276394605636597
Batch 27/64 loss: 0.23074442148208618
Batch 28/64 loss: 0.2330000400543213
Batch 29/64 loss: 0.23554599285125732
Batch 30/64 loss: 0.23009908199310303
Batch 31/64 loss: 0.23184937238693237
Batch 32/64 loss: 0.243699312210083
Batch 33/64 loss: 0.23579049110412598
Batch 34/64 loss: 0.23077833652496338
Batch 35/64 loss: 0.23676466941833496
Batch 36/64 loss: 0.2476710081100464
Batch 37/64 loss: 0.22233009338378906
Batch 38/64 loss: 0.22969132661819458
Batch 39/64 loss: 0.2295404076576233
Batch 40/64 loss: 0.2403520941734314
Batch 41/64 loss: 0.2361053228378296
Batch 42/64 loss: 0.25114166736602783
Batch 43/64 loss: 0.23458504676818848
Batch 44/64 loss: 0.22612059116363525
Batch 45/64 loss: 0.23638933897018433
Batch 46/64 loss: 0.2396526336669922
Batch 47/64 loss: 0.22675883769989014
Batch 48/64 loss: 0.23141998052597046
Batch 49/64 loss: 0.23060429096221924
Batch 50/64 loss: 0.23340696096420288
Batch 51/64 loss: 0.2383279800415039
Batch 52/64 loss: 0.23929178714752197
Batch 53/64 loss: 0.2397107481956482
Batch 54/64 loss: 0.23002028465270996
Batch 55/64 loss: 0.23360341787338257
Batch 56/64 loss: 0.2506592273712158
Batch 57/64 loss: 0.23236215114593506
Batch 58/64 loss: 0.23375368118286133
Batch 59/64 loss: 0.2406526803970337
Batch 60/64 loss: 0.2343706488609314
Batch 61/64 loss: 0.23515552282333374
Batch 62/64 loss: 0.2315247654914856
Batch 63/64 loss: 0.22573614120483398
Batch 64/64 loss: 0.22083687782287598
Epoch 402  Train loss: 0.23426705996195477  Val loss: 0.2819821644075138
Epoch 403
-------------------------------
Batch 1/64 loss: 0.22501152753829956
Batch 2/64 loss: 0.2359602451324463
Batch 3/64 loss: 0.23687636852264404
Batch 4/64 loss: 0.22258508205413818
Batch 5/64 loss: 0.23653435707092285
Batch 6/64 loss: 0.2223876714706421
Batch 7/64 loss: 0.23581010103225708
Batch 8/64 loss: 0.22034794092178345
Batch 9/64 loss: 0.23404192924499512
Batch 10/64 loss: 0.22844833135604858
Batch 11/64 loss: 0.2364482879638672
Batch 12/64 loss: 0.23433351516723633
Batch 13/64 loss: 0.22998195886611938
Batch 14/64 loss: 0.2269722819328308
Batch 15/64 loss: 0.2392498254776001
Batch 16/64 loss: 0.23967528343200684
Batch 17/64 loss: 0.23075509071350098
Batch 18/64 loss: 0.2303394079208374
Batch 19/64 loss: 0.23706966638565063
Batch 20/64 loss: 0.23702740669250488
Batch 21/64 loss: 0.24230337142944336
Batch 22/64 loss: 0.22696149349212646
Batch 23/64 loss: 0.23627132177352905
Batch 24/64 loss: 0.23210906982421875
Batch 25/64 loss: 0.23617368936538696
Batch 26/64 loss: 0.22964531183242798
Batch 27/64 loss: 0.23960840702056885
Batch 28/64 loss: 0.2336028814315796
Batch 29/64 loss: 0.2256045937538147
Batch 30/64 loss: 0.23450303077697754
Batch 31/64 loss: 0.2336033582687378
Batch 32/64 loss: 0.22670376300811768
Batch 33/64 loss: 0.24022424221038818
Batch 34/64 loss: 0.23746931552886963
Batch 35/64 loss: 0.22856825590133667
Batch 36/64 loss: 0.23484349250793457
Batch 37/64 loss: 0.23228520154953003
Batch 38/64 loss: 0.24492603540420532
Batch 39/64 loss: 0.23549103736877441
Batch 40/64 loss: 0.2234761118888855
Batch 41/64 loss: 0.23551106452941895
Batch 42/64 loss: 0.228668212890625
Batch 43/64 loss: 0.23653548955917358
Batch 44/64 loss: 0.23646008968353271
Batch 45/64 loss: 0.2339215874671936
Batch 46/64 loss: 0.2331773042678833
Batch 47/64 loss: 0.2275984287261963
Batch 48/64 loss: 0.23373794555664062
Batch 49/64 loss: 0.23743152618408203
Batch 50/64 loss: 0.2436402440071106
Batch 51/64 loss: 0.24846291542053223
Batch 52/64 loss: 0.24316751956939697
Batch 53/64 loss: 0.23899084329605103
Batch 54/64 loss: 0.23445945978164673
Batch 55/64 loss: 0.22975963354110718
Batch 56/64 loss: 0.228843092918396
Batch 57/64 loss: 0.23418033123016357
Batch 58/64 loss: 0.23186659812927246
Batch 59/64 loss: 0.23755347728729248
Batch 60/64 loss: 0.23599940538406372
Batch 61/64 loss: 0.25839704275131226
Batch 62/64 loss: 0.23069924116134644
Batch 63/64 loss: 0.2303849458694458
Batch 64/64 loss: 0.23522675037384033
Epoch 403  Train loss: 0.23404073294471292  Val loss: 0.2808436601841982
Epoch 404
-------------------------------
Batch 1/64 loss: 0.22802478075027466
Batch 2/64 loss: 0.2276613712310791
Batch 3/64 loss: 0.24031084775924683
Batch 4/64 loss: 0.229996919631958
Batch 5/64 loss: 0.24274468421936035
Batch 6/64 loss: 0.22897732257843018
Batch 7/64 loss: 0.22629386186599731
Batch 8/64 loss: 0.22815310955047607
Batch 9/64 loss: 0.22695744037628174
Batch 10/64 loss: 0.23008430004119873
Batch 11/64 loss: 0.23197102546691895
Batch 12/64 loss: 0.22440171241760254
Batch 13/64 loss: 0.2305888533592224
Batch 14/64 loss: 0.22859978675842285
Batch 15/64 loss: 0.23874735832214355
Batch 16/64 loss: 0.244922935962677
Batch 17/64 loss: 0.23707032203674316
Batch 18/64 loss: 0.23166030645370483
Batch 19/64 loss: 0.24453330039978027
Batch 20/64 loss: 0.2431560754776001
Batch 21/64 loss: 0.24286705255508423
Batch 22/64 loss: 0.23273825645446777
Batch 23/64 loss: 0.23574507236480713
Batch 24/64 loss: 0.2338259220123291
Batch 25/64 loss: 0.22753095626831055
Batch 26/64 loss: 0.2385329008102417
Batch 27/64 loss: 0.22831737995147705
Batch 28/64 loss: 0.23278123140335083
Batch 29/64 loss: 0.23748505115509033
Batch 30/64 loss: 0.23132193088531494
Batch 31/64 loss: 0.22547483444213867
Batch 32/64 loss: 0.22974061965942383
Batch 33/64 loss: 0.23134571313858032
Batch 34/64 loss: 0.23451584577560425
Batch 35/64 loss: 0.2243761420249939
Batch 36/64 loss: 0.2265026569366455
Batch 37/64 loss: 0.23671698570251465
Batch 38/64 loss: 0.23190349340438843
Batch 39/64 loss: 0.22983956336975098
Batch 40/64 loss: 0.2347874641418457
Batch 41/64 loss: 0.22319179773330688
Batch 42/64 loss: 0.24256980419158936
Batch 43/64 loss: 0.2446303367614746
Batch 44/64 loss: 0.2397933006286621
Batch 45/64 loss: 0.25485754013061523
Batch 46/64 loss: 0.23931705951690674
Batch 47/64 loss: 0.23374724388122559
Batch 48/64 loss: 0.23873353004455566
Batch 49/64 loss: 0.23853152990341187
Batch 50/64 loss: 0.2283029556274414
Batch 51/64 loss: 0.2339766025543213
Batch 52/64 loss: 0.23580169677734375
Batch 53/64 loss: 0.23803842067718506
Batch 54/64 loss: 0.2354806661605835
Batch 55/64 loss: 0.2256556749343872
Batch 56/64 loss: 0.24148225784301758
Batch 57/64 loss: 0.2535043954849243
Batch 58/64 loss: 0.24065130949020386
Batch 59/64 loss: 0.24001681804656982
Batch 60/64 loss: 0.24768364429473877
Batch 61/64 loss: 0.24501943588256836
Batch 62/64 loss: 0.2231488823890686
Batch 63/64 loss: 0.22921264171600342
Batch 64/64 loss: 0.24724572896957397
Epoch 404  Train loss: 0.23482332907471  Val loss: 0.28179701640433874
Epoch 405
-------------------------------
Batch 1/64 loss: 0.22562986612319946
Batch 2/64 loss: 0.22471261024475098
Batch 3/64 loss: 0.22872322797775269
Batch 4/64 loss: 0.23069453239440918
Batch 5/64 loss: 0.22314369678497314
Batch 6/64 loss: 0.23140215873718262
Batch 7/64 loss: 0.24680614471435547
Batch 8/64 loss: 0.2293059229850769
Batch 9/64 loss: 0.23219561576843262
Batch 10/64 loss: 0.22493213415145874
Batch 11/64 loss: 0.24193549156188965
Batch 12/64 loss: 0.2340470552444458
Batch 13/64 loss: 0.24007946252822876
Batch 14/64 loss: 0.2420598268508911
Batch 15/64 loss: 0.2323501706123352
Batch 16/64 loss: 0.22602558135986328
Batch 17/64 loss: 0.23903727531433105
Batch 18/64 loss: 0.232621967792511
Batch 19/64 loss: 0.22756069898605347
Batch 20/64 loss: 0.23575645685195923
Batch 21/64 loss: 0.23203545808792114
Batch 22/64 loss: 0.23084640502929688
Batch 23/64 loss: 0.23513758182525635
Batch 24/64 loss: 0.2316063642501831
Batch 25/64 loss: 0.2434539794921875
Batch 26/64 loss: 0.22825169563293457
Batch 27/64 loss: 0.22460639476776123
Batch 28/64 loss: 0.2282644510269165
Batch 29/64 loss: 0.23791074752807617
Batch 30/64 loss: 0.23542273044586182
Batch 31/64 loss: 0.23159527778625488
Batch 32/64 loss: 0.23817002773284912
Batch 33/64 loss: 0.23398232460021973
Batch 34/64 loss: 0.2383885383605957
Batch 35/64 loss: 0.22819995880126953
Batch 36/64 loss: 0.24615883827209473
Batch 37/64 loss: 0.2312307357788086
Batch 38/64 loss: 0.23972487449645996
Batch 39/64 loss: 0.23428714275360107
Batch 40/64 loss: 0.2305099368095398
Batch 41/64 loss: 0.23646610975265503
Batch 42/64 loss: 0.25054943561553955
Batch 43/64 loss: 0.2514973282814026
Batch 44/64 loss: 0.24087822437286377
Batch 45/64 loss: 0.23486018180847168
Batch 46/64 loss: 0.2320953607559204
Batch 47/64 loss: 0.24206757545471191
Batch 48/64 loss: 0.2331629991531372
Batch 49/64 loss: 0.23928862810134888
Batch 50/64 loss: 0.22994542121887207
Batch 51/64 loss: 0.2323058843612671
Batch 52/64 loss: 0.23074030876159668
Batch 53/64 loss: 0.23446869850158691
Batch 54/64 loss: 0.2391589879989624
Batch 55/64 loss: 0.22956395149230957
Batch 56/64 loss: 0.2453913688659668
Batch 57/64 loss: 0.2372514009475708
Batch 58/64 loss: 0.2261960506439209
Batch 59/64 loss: 0.2277866005897522
Batch 60/64 loss: 0.22989892959594727
Batch 61/64 loss: 0.24282586574554443
Batch 62/64 loss: 0.23211222887039185
Batch 63/64 loss: 0.2371736764907837
Batch 64/64 loss: 0.2362390160560608
Epoch 405  Train loss: 0.2343791033707413  Val loss: 0.28136399337106555
Epoch 406
-------------------------------
Batch 1/64 loss: 0.2323731780052185
Batch 2/64 loss: 0.2266446352005005
Batch 3/64 loss: 0.2345362901687622
Batch 4/64 loss: 0.22678273916244507
Batch 5/64 loss: 0.2338254451751709
Batch 6/64 loss: 0.23469418287277222
Batch 7/64 loss: 0.23046875
Batch 8/64 loss: 0.22742116451263428
Batch 9/64 loss: 0.2422868013381958
Batch 10/64 loss: 0.23471635580062866
Batch 11/64 loss: 0.22298723459243774
Batch 12/64 loss: 0.2316884994506836
Batch 13/64 loss: 0.2310592532157898
Batch 14/64 loss: 0.22959566116333008
Batch 15/64 loss: 0.23279404640197754
Batch 16/64 loss: 0.23442083597183228
Batch 17/64 loss: 0.2328760027885437
Batch 18/64 loss: 0.22771567106246948
Batch 19/64 loss: 0.23623180389404297
Batch 20/64 loss: 0.22882229089736938
Batch 21/64 loss: 0.23223453760147095
Batch 22/64 loss: 0.2267390489578247
Batch 23/64 loss: 0.23682117462158203
Batch 24/64 loss: 0.2307714819908142
Batch 25/64 loss: 0.238287091255188
Batch 26/64 loss: 0.23562490940093994
Batch 27/64 loss: 0.23925960063934326
Batch 28/64 loss: 0.24188518524169922
Batch 29/64 loss: 0.23896753787994385
Batch 30/64 loss: 0.23691719770431519
Batch 31/64 loss: 0.22748887538909912
Batch 32/64 loss: 0.2290295958518982
Batch 33/64 loss: 0.22840595245361328
Batch 34/64 loss: 0.23202812671661377
Batch 35/64 loss: 0.22963058948516846
Batch 36/64 loss: 0.23122847080230713
Batch 37/64 loss: 0.22900164127349854
Batch 38/64 loss: 0.23996925354003906
Batch 39/64 loss: 0.23684251308441162
Batch 40/64 loss: 0.2349451184272766
Batch 41/64 loss: 0.23792308568954468
Batch 42/64 loss: 0.23033690452575684
Batch 43/64 loss: 0.2381591796875
Batch 44/64 loss: 0.22916918992996216
Batch 45/64 loss: 0.2301652431488037
Batch 46/64 loss: 0.22865593433380127
Batch 47/64 loss: 0.24654459953308105
Batch 48/64 loss: 0.23211610317230225
Batch 49/64 loss: 0.24682289361953735
Batch 50/64 loss: 0.23110049962997437
Batch 51/64 loss: 0.24428141117095947
Batch 52/64 loss: 0.22694122791290283
Batch 53/64 loss: 0.23426151275634766
Batch 54/64 loss: 0.23715883493423462
Batch 55/64 loss: 0.23309111595153809
Batch 56/64 loss: 0.22805368900299072
Batch 57/64 loss: 0.22245121002197266
Batch 58/64 loss: 0.22399353981018066
Batch 59/64 loss: 0.2348807454109192
Batch 60/64 loss: 0.23075830936431885
Batch 61/64 loss: 0.23793280124664307
Batch 62/64 loss: 0.24066215753555298
Batch 63/64 loss: 0.2350780963897705
Batch 64/64 loss: 0.23043137788772583
Epoch 406  Train loss: 0.2331196950931175  Val loss: 0.28182079845277713
Epoch 407
-------------------------------
Batch 1/64 loss: 0.22864830493927002
Batch 2/64 loss: 0.23783528804779053
Batch 3/64 loss: 0.22910654544830322
Batch 4/64 loss: 0.23027372360229492
Batch 5/64 loss: 0.22665709257125854
Batch 6/64 loss: 0.2287527322769165
Batch 7/64 loss: 0.23419320583343506
Batch 8/64 loss: 0.2243748903274536
Batch 9/64 loss: 0.23141193389892578
Batch 10/64 loss: 0.23378533124923706
Batch 11/64 loss: 0.21960151195526123
Batch 12/64 loss: 0.2274339199066162
Batch 13/64 loss: 0.23384249210357666
Batch 14/64 loss: 0.22862708568572998
Batch 15/64 loss: 0.23512393236160278
Batch 16/64 loss: 0.23397773504257202
Batch 17/64 loss: 0.2412254810333252
Batch 18/64 loss: 0.2287324070930481
Batch 19/64 loss: 0.23288655281066895
Batch 20/64 loss: 0.2370666265487671
Batch 21/64 loss: 0.23371261358261108
Batch 22/64 loss: 0.22998392581939697
Batch 23/64 loss: 0.240531325340271
Batch 24/64 loss: 0.22491765022277832
Batch 25/64 loss: 0.2437838315963745
Batch 26/64 loss: 0.23658877611160278
Batch 27/64 loss: 0.2326831817626953
Batch 28/64 loss: 0.2353956699371338
Batch 29/64 loss: 0.2332918643951416
Batch 30/64 loss: 0.2300194501876831
Batch 31/64 loss: 0.23449522256851196
Batch 32/64 loss: 0.2277507781982422
Batch 33/64 loss: 0.23106825351715088
Batch 34/64 loss: 0.23449450731277466
Batch 35/64 loss: 0.22381561994552612
Batch 36/64 loss: 0.24327635765075684
Batch 37/64 loss: 0.2470717430114746
Batch 38/64 loss: 0.22681796550750732
Batch 39/64 loss: 0.239548921585083
Batch 40/64 loss: 0.23472297191619873
Batch 41/64 loss: 0.22948366403579712
Batch 42/64 loss: 0.23349833488464355
Batch 43/64 loss: 0.23944151401519775
Batch 44/64 loss: 0.2373950481414795
Batch 45/64 loss: 0.2273883819580078
Batch 46/64 loss: 0.23406946659088135
Batch 47/64 loss: 0.23039311170578003
Batch 48/64 loss: 0.23864758014678955
Batch 49/64 loss: 0.2297467589378357
Batch 50/64 loss: 0.23776769638061523
Batch 51/64 loss: 0.22574138641357422
Batch 52/64 loss: 0.2301318645477295
Batch 53/64 loss: 0.2327439785003662
Batch 54/64 loss: 0.22992146015167236
Batch 55/64 loss: 0.24911534786224365
Batch 56/64 loss: 0.23279601335525513
Batch 57/64 loss: 0.2445685863494873
Batch 58/64 loss: 0.23179137706756592
Batch 59/64 loss: 0.23058319091796875
Batch 60/64 loss: 0.2384660840034485
Batch 61/64 loss: 0.2319427728652954
Batch 62/64 loss: 0.23052984476089478
Batch 63/64 loss: 0.24636530876159668
Batch 64/64 loss: 0.2270040512084961
Epoch 407  Train loss: 0.2332597526849485  Val loss: 0.28419912701210204
Epoch 408
-------------------------------
Batch 1/64 loss: 0.22561228275299072
Batch 2/64 loss: 0.22574418783187866
Batch 3/64 loss: 0.23741114139556885
Batch 4/64 loss: 0.2353193759918213
Batch 5/64 loss: 0.2310936450958252
Batch 6/64 loss: 0.24139082431793213
Batch 7/64 loss: 0.23070251941680908
Batch 8/64 loss: 0.2311006784439087
Batch 9/64 loss: 0.22378969192504883
Batch 10/64 loss: 0.23179268836975098
Batch 11/64 loss: 0.22677093744277954
Batch 12/64 loss: 0.2329007387161255
Batch 13/64 loss: 0.23133957386016846
Batch 14/64 loss: 0.2374686598777771
Batch 15/64 loss: 0.23701345920562744
Batch 16/64 loss: 0.22890639305114746
Batch 17/64 loss: 0.22593212127685547
Batch 18/64 loss: 0.2510128617286682
Batch 19/64 loss: 0.2274714708328247
Batch 20/64 loss: 0.2364189624786377
Batch 21/64 loss: 0.2300509810447693
Batch 22/64 loss: 0.2293490767478943
Batch 23/64 loss: 0.23925918340682983
Batch 24/64 loss: 0.22710567712783813
Batch 25/64 loss: 0.2516133189201355
Batch 26/64 loss: 0.23021847009658813
Batch 27/64 loss: 0.23727846145629883
Batch 28/64 loss: 0.23877251148223877
Batch 29/64 loss: 0.22973662614822388
Batch 30/64 loss: 0.23247236013412476
Batch 31/64 loss: 0.23023205995559692
Batch 32/64 loss: 0.22325748205184937
Batch 33/64 loss: 0.24404919147491455
Batch 34/64 loss: 0.22288572788238525
Batch 35/64 loss: 0.23110175132751465
Batch 36/64 loss: 0.2399769425392151
Batch 37/64 loss: 0.22759991884231567
Batch 38/64 loss: 0.22743666172027588
Batch 39/64 loss: 0.2275736927986145
Batch 40/64 loss: 0.23047655820846558
Batch 41/64 loss: 0.23840183019638062
Batch 42/64 loss: 0.23061370849609375
Batch 43/64 loss: 0.23714637756347656
Batch 44/64 loss: 0.23322486877441406
Batch 45/64 loss: 0.22921407222747803
Batch 46/64 loss: 0.23735862970352173
Batch 47/64 loss: 0.24362695217132568
Batch 48/64 loss: 0.24143457412719727
Batch 49/64 loss: 0.23330307006835938
Batch 50/64 loss: 0.2336721420288086
Batch 51/64 loss: 0.23292040824890137
Batch 52/64 loss: 0.2348703145980835
Batch 53/64 loss: 0.22696638107299805
Batch 54/64 loss: 0.24724310636520386
Batch 55/64 loss: 0.23399335145950317
Batch 56/64 loss: 0.2391759157180786
Batch 57/64 loss: 0.24004781246185303
Batch 58/64 loss: 0.2445659637451172
Batch 59/64 loss: 0.23360127210617065
Batch 60/64 loss: 0.2282770276069641
Batch 61/64 loss: 0.22459512948989868
Batch 62/64 loss: 0.2358546257019043
Batch 63/64 loss: 0.2377883791923523
Batch 64/64 loss: 0.2234649658203125
Epoch 408  Train loss: 0.2334922902724322  Val loss: 0.28182008790805985
Epoch 409
-------------------------------
Batch 1/64 loss: 0.22907185554504395
Batch 2/64 loss: 0.22850632667541504
Batch 3/64 loss: 0.22793078422546387
Batch 4/64 loss: 0.23621034622192383
Batch 5/64 loss: 0.22717690467834473
Batch 6/64 loss: 0.2385295033454895
Batch 7/64 loss: 0.22905296087265015
Batch 8/64 loss: 0.2367679476737976
Batch 9/64 loss: 0.24721097946166992
Batch 10/64 loss: 0.23674917221069336
Batch 11/64 loss: 0.23160886764526367
Batch 12/64 loss: 0.22463804483413696
Batch 13/64 loss: 0.2459583282470703
Batch 14/64 loss: 0.22360152006149292
Batch 15/64 loss: 0.23241502046585083
Batch 16/64 loss: 0.2367820143699646
Batch 17/64 loss: 0.23789113759994507
Batch 18/64 loss: 0.23206406831741333
Batch 19/64 loss: 0.2303769588470459
Batch 20/64 loss: 0.2401648759841919
Batch 21/64 loss: 0.23893290758132935
Batch 22/64 loss: 0.24401557445526123
Batch 23/64 loss: 0.2314218282699585
Batch 24/64 loss: 0.23360753059387207
Batch 25/64 loss: 0.24176424741744995
Batch 26/64 loss: 0.23789167404174805
Batch 27/64 loss: 0.24110066890716553
Batch 28/64 loss: 0.22548580169677734
Batch 29/64 loss: 0.2219751477241516
Batch 30/64 loss: 0.23540657758712769
Batch 31/64 loss: 0.2358231544494629
Batch 32/64 loss: 0.2312856912612915
Batch 33/64 loss: 0.2259860634803772
Batch 34/64 loss: 0.24103152751922607
Batch 35/64 loss: 0.2283269166946411
Batch 36/64 loss: 0.23603934049606323
Batch 37/64 loss: 0.2306581735610962
Batch 38/64 loss: 0.2309802770614624
Batch 39/64 loss: 0.23446249961853027
Batch 40/64 loss: 0.22658997774124146
Batch 41/64 loss: 0.22472155094146729
Batch 42/64 loss: 0.2324965000152588
Batch 43/64 loss: 0.2250373363494873
Batch 44/64 loss: 0.2350471019744873
Batch 45/64 loss: 0.23011833429336548
Batch 46/64 loss: 0.2356012463569641
Batch 47/64 loss: 0.23438209295272827
Batch 48/64 loss: 0.22498047351837158
Batch 49/64 loss: 0.2381150722503662
Batch 50/64 loss: 0.22894281148910522
Batch 51/64 loss: 0.23142272233963013
Batch 52/64 loss: 0.22307336330413818
Batch 53/64 loss: 0.22856628894805908
Batch 54/64 loss: 0.24180197715759277
Batch 55/64 loss: 0.23564958572387695
Batch 56/64 loss: 0.2254495620727539
Batch 57/64 loss: 0.2486114501953125
Batch 58/64 loss: 0.2356647253036499
Batch 59/64 loss: 0.23188984394073486
Batch 60/64 loss: 0.2305687665939331
Batch 61/64 loss: 0.2359706163406372
Batch 62/64 loss: 0.23223257064819336
Batch 63/64 loss: 0.2434290647506714
Batch 64/64 loss: 0.23332929611206055
Epoch 409  Train loss: 0.23332177610958324  Val loss: 0.28149634865960715
Epoch 410
-------------------------------
Batch 1/64 loss: 0.22951769828796387
Batch 2/64 loss: 0.22636616230010986
Batch 3/64 loss: 0.23834288120269775
Batch 4/64 loss: 0.24331796169281006
Batch 5/64 loss: 0.23529338836669922
Batch 6/64 loss: 0.23673641681671143
Batch 7/64 loss: 0.24206972122192383
Batch 8/64 loss: 0.2336568832397461
Batch 9/64 loss: 0.2352534532546997
Batch 10/64 loss: 0.23259299993515015
Batch 11/64 loss: 0.2343515157699585
Batch 12/64 loss: 0.22759020328521729
Batch 13/64 loss: 0.23367857933044434
Batch 14/64 loss: 0.24880683422088623
Batch 15/64 loss: 0.2348012924194336
Batch 16/64 loss: 0.22573888301849365
Batch 17/64 loss: 0.23776555061340332
Batch 18/64 loss: 0.23731708526611328
Batch 19/64 loss: 0.23092812299728394
Batch 20/64 loss: 0.22927069664001465
Batch 21/64 loss: 0.24293971061706543
Batch 22/64 loss: 0.2246929407119751
Batch 23/64 loss: 0.22711396217346191
Batch 24/64 loss: 0.22719454765319824
Batch 25/64 loss: 0.24027681350708008
Batch 26/64 loss: 0.23849833011627197
Batch 27/64 loss: 0.23276948928833008
Batch 28/64 loss: 0.24006617069244385
Batch 29/64 loss: 0.24353885650634766
Batch 30/64 loss: 0.23146867752075195
Batch 31/64 loss: 0.23853611946105957
Batch 32/64 loss: 0.2393282651901245
Batch 33/64 loss: 0.22626054286956787
Batch 34/64 loss: 0.2292804718017578
Batch 35/64 loss: 0.2307456135749817
Batch 36/64 loss: 0.23758435249328613
Batch 37/64 loss: 0.23846840858459473
Batch 38/64 loss: 0.2342585325241089
Batch 39/64 loss: 0.235318124294281
Batch 40/64 loss: 0.22197306156158447
Batch 41/64 loss: 0.2425382137298584
Batch 42/64 loss: 0.23411208391189575
Batch 43/64 loss: 0.22204524278640747
Batch 44/64 loss: 0.2361547350883484
Batch 45/64 loss: 0.23080110549926758
Batch 46/64 loss: 0.23170047998428345
Batch 47/64 loss: 0.2258778214454651
Batch 48/64 loss: 0.2292393445968628
Batch 49/64 loss: 0.23324298858642578
Batch 50/64 loss: 0.23509764671325684
Batch 51/64 loss: 0.23309332132339478
Batch 52/64 loss: 0.22460883855819702
Batch 53/64 loss: 0.23858129978179932
Batch 54/64 loss: 0.23164838552474976
Batch 55/64 loss: 0.22811859846115112
Batch 56/64 loss: 0.22060096263885498
Batch 57/64 loss: 0.23490536212921143
Batch 58/64 loss: 0.24021267890930176
Batch 59/64 loss: 0.2259311079978943
Batch 60/64 loss: 0.23847222328186035
Batch 61/64 loss: 0.22698885202407837
Batch 62/64 loss: 0.2273552417755127
Batch 63/64 loss: 0.23639678955078125
Batch 64/64 loss: 0.23764193058013916
Epoch 410  Train loss: 0.23340649558048623  Val loss: 0.28110648758222967
Epoch 411
-------------------------------
Batch 1/64 loss: 0.22948074340820312
Batch 2/64 loss: 0.2293325662612915
Batch 3/64 loss: 0.2402471899986267
Batch 4/64 loss: 0.23499226570129395
Batch 5/64 loss: 0.23426109552383423
Batch 6/64 loss: 0.23088133335113525
Batch 7/64 loss: 0.23323887586593628
Batch 8/64 loss: 0.23287558555603027
Batch 9/64 loss: 0.22423040866851807
Batch 10/64 loss: 0.22574841976165771
Batch 11/64 loss: 0.22602558135986328
Batch 12/64 loss: 0.23075056076049805
Batch 13/64 loss: 0.2401362657546997
Batch 14/64 loss: 0.24046295881271362
Batch 15/64 loss: 0.22697144746780396
Batch 16/64 loss: 0.2290182113647461
Batch 17/64 loss: 0.23174011707305908
Batch 18/64 loss: 0.22144949436187744
Batch 19/64 loss: 0.2260817289352417
Batch 20/64 loss: 0.23612117767333984
Batch 21/64 loss: 0.2333616018295288
Batch 22/64 loss: 0.23090583086013794
Batch 23/64 loss: 0.23061299324035645
Batch 24/64 loss: 0.22301578521728516
Batch 25/64 loss: 0.23214495182037354
Batch 26/64 loss: 0.22690939903259277
Batch 27/64 loss: 0.22204208374023438
Batch 28/64 loss: 0.22919189929962158
Batch 29/64 loss: 0.24293756484985352
Batch 30/64 loss: 0.23609203100204468
Batch 31/64 loss: 0.24789661169052124
Batch 32/64 loss: 0.23863381147384644
Batch 33/64 loss: 0.24207329750061035
Batch 34/64 loss: 0.2300318479537964
Batch 35/64 loss: 0.22846853733062744
Batch 36/64 loss: 0.23195022344589233
Batch 37/64 loss: 0.22699320316314697
Batch 38/64 loss: 0.22797441482543945
Batch 39/64 loss: 0.23384565114974976
Batch 40/64 loss: 0.2375882863998413
Batch 41/64 loss: 0.22856664657592773
Batch 42/64 loss: 0.24367785453796387
Batch 43/64 loss: 0.23075509071350098
Batch 44/64 loss: 0.23395979404449463
Batch 45/64 loss: 0.22195285558700562
Batch 46/64 loss: 0.23301661014556885
Batch 47/64 loss: 0.22323119640350342
Batch 48/64 loss: 0.23757827281951904
Batch 49/64 loss: 0.23158180713653564
Batch 50/64 loss: 0.23804986476898193
Batch 51/64 loss: 0.2317138910293579
Batch 52/64 loss: 0.2298121452331543
Batch 53/64 loss: 0.23503494262695312
Batch 54/64 loss: 0.23865008354187012
Batch 55/64 loss: 0.24519729614257812
Batch 56/64 loss: 0.22580993175506592
Batch 57/64 loss: 0.22801172733306885
Batch 58/64 loss: 0.23924142122268677
Batch 59/64 loss: 0.22762739658355713
Batch 60/64 loss: 0.23731976747512817
Batch 61/64 loss: 0.24087262153625488
Batch 62/64 loss: 0.23880553245544434
Batch 63/64 loss: 0.22934859991073608
Batch 64/64 loss: 0.23191529512405396
Epoch 411  Train loss: 0.2324779274416905  Val loss: 0.2830347283599303
Epoch 412
-------------------------------
Batch 1/64 loss: 0.22755104303359985
Batch 2/64 loss: 0.22413665056228638
Batch 3/64 loss: 0.23071932792663574
Batch 4/64 loss: 0.23353946208953857
Batch 5/64 loss: 0.22330200672149658
Batch 6/64 loss: 0.23667526245117188
Batch 7/64 loss: 0.22475463151931763
Batch 8/64 loss: 0.23152905702590942
Batch 9/64 loss: 0.245391845703125
Batch 10/64 loss: 0.23070967197418213
Batch 11/64 loss: 0.23762351274490356
Batch 12/64 loss: 0.23338240385055542
Batch 13/64 loss: 0.22216129302978516
Batch 14/64 loss: 0.24865233898162842
Batch 15/64 loss: 0.22411203384399414
Batch 16/64 loss: 0.23072904348373413
Batch 17/64 loss: 0.24224406480789185
Batch 18/64 loss: 0.2286112904548645
Batch 19/64 loss: 0.24057114124298096
Batch 20/64 loss: 0.23106896877288818
Batch 21/64 loss: 0.23190820217132568
Batch 22/64 loss: 0.23545807600021362
Batch 23/64 loss: 0.233282208442688
Batch 24/64 loss: 0.22629129886627197
Batch 25/64 loss: 0.24162650108337402
Batch 26/64 loss: 0.2165328860282898
Batch 27/64 loss: 0.244773268699646
Batch 28/64 loss: 0.23941433429718018
Batch 29/64 loss: 0.23229587078094482
Batch 30/64 loss: 0.22396492958068848
Batch 31/64 loss: 0.2315623164176941
Batch 32/64 loss: 0.22765541076660156
Batch 33/64 loss: 0.23925966024398804
Batch 34/64 loss: 0.22645807266235352
Batch 35/64 loss: 0.22818320989608765
Batch 36/64 loss: 0.24185150861740112
Batch 37/64 loss: 0.23950040340423584
Batch 38/64 loss: 0.22208625078201294
Batch 39/64 loss: 0.23910129070281982
Batch 40/64 loss: 0.24143481254577637
Batch 41/64 loss: 0.2385556697845459
Batch 42/64 loss: 0.23677337169647217
Batch 43/64 loss: 0.22670936584472656
Batch 44/64 loss: 0.24003005027770996
Batch 45/64 loss: 0.23022866249084473
Batch 46/64 loss: 0.23810827732086182
Batch 47/64 loss: 0.23853850364685059
Batch 48/64 loss: 0.23935580253601074
Batch 49/64 loss: 0.2285965085029602
Batch 50/64 loss: 0.23466241359710693
Batch 51/64 loss: 0.22890543937683105
Batch 52/64 loss: 0.2344900369644165
Batch 53/64 loss: 0.23521912097930908
Batch 54/64 loss: 0.22297680377960205
Batch 55/64 loss: 0.2335207462310791
Batch 56/64 loss: 0.23344427347183228
Batch 57/64 loss: 0.23145055770874023
Batch 58/64 loss: 0.24498212337493896
Batch 59/64 loss: 0.22637701034545898
Batch 60/64 loss: 0.2370808720588684
Batch 61/64 loss: 0.2284390926361084
Batch 62/64 loss: 0.23443186283111572
Batch 63/64 loss: 0.24792635440826416
Batch 64/64 loss: 0.23419344425201416
Epoch 412  Train loss: 0.23335770298452937  Val loss: 0.28208842576574217
Epoch 413
-------------------------------
Batch 1/64 loss: 0.23551976680755615
Batch 2/64 loss: 0.23406243324279785
Batch 3/64 loss: 0.23898333311080933
Batch 4/64 loss: 0.23700517416000366
Batch 5/64 loss: 0.24239063262939453
Batch 6/64 loss: 0.2345094084739685
Batch 7/64 loss: 0.22184264659881592
Batch 8/64 loss: 0.2333967685699463
Batch 9/64 loss: 0.23299628496170044
Batch 10/64 loss: 0.22551310062408447
Batch 11/64 loss: 0.24141144752502441
Batch 12/64 loss: 0.2362663745880127
Batch 13/64 loss: 0.2291584014892578
Batch 14/64 loss: 0.22292065620422363
Batch 15/64 loss: 0.22457289695739746
Batch 16/64 loss: 0.23968267440795898
Batch 17/64 loss: 0.22915363311767578
Batch 18/64 loss: 0.2297896146774292
Batch 19/64 loss: 0.2372903823852539
Batch 20/64 loss: 0.23711049556732178
Batch 21/64 loss: 0.24125587940216064
Batch 22/64 loss: 0.24584734439849854
Batch 23/64 loss: 0.23632735013961792
Batch 24/64 loss: 0.24023115634918213
Batch 25/64 loss: 0.23354727029800415
Batch 26/64 loss: 0.23466777801513672
Batch 27/64 loss: 0.22685766220092773
Batch 28/64 loss: 0.22384244203567505
Batch 29/64 loss: 0.2424529790878296
Batch 30/64 loss: 0.23949891328811646
Batch 31/64 loss: 0.2275211215019226
Batch 32/64 loss: 0.22907227277755737
Batch 33/64 loss: 0.23915696144104004
Batch 34/64 loss: 0.22911381721496582
Batch 35/64 loss: 0.23811960220336914
Batch 36/64 loss: 0.23110783100128174
Batch 37/64 loss: 0.24016481637954712
Batch 38/64 loss: 0.22908586263656616
Batch 39/64 loss: 0.22266745567321777
Batch 40/64 loss: 0.22797852754592896
Batch 41/64 loss: 0.2243795394897461
Batch 42/64 loss: 0.24370062351226807
Batch 43/64 loss: 0.23661309480667114
Batch 44/64 loss: 0.2440178394317627
Batch 45/64 loss: 0.23242568969726562
Batch 46/64 loss: 0.2226962447166443
Batch 47/64 loss: 0.23012375831604004
Batch 48/64 loss: 0.23021924495697021
Batch 49/64 loss: 0.23043715953826904
Batch 50/64 loss: 0.2345874309539795
Batch 51/64 loss: 0.2250509262084961
Batch 52/64 loss: 0.22328108549118042
Batch 53/64 loss: 0.2323610782623291
Batch 54/64 loss: 0.24959099292755127
Batch 55/64 loss: 0.23899102210998535
Batch 56/64 loss: 0.23537760972976685
Batch 57/64 loss: 0.23572790622711182
Batch 58/64 loss: 0.23205292224884033
Batch 59/64 loss: 0.23565518856048584
Batch 60/64 loss: 0.23606669902801514
Batch 61/64 loss: 0.23078244924545288
Batch 62/64 loss: 0.2353108525276184
Batch 63/64 loss: 0.23153752088546753
Batch 64/64 loss: 0.2378827929496765
Epoch 413  Train loss: 0.2335920336199742  Val loss: 0.2821826643960173
Epoch 414
-------------------------------
Batch 1/64 loss: 0.244728684425354
Batch 2/64 loss: 0.23090773820877075
Batch 3/64 loss: 0.23197460174560547
Batch 4/64 loss: 0.23129045963287354
Batch 5/64 loss: 0.22726452350616455
Batch 6/64 loss: 0.23746836185455322
Batch 7/64 loss: 0.22844690084457397
Batch 8/64 loss: 0.23066747188568115
Batch 9/64 loss: 0.22759252786636353
Batch 10/64 loss: 0.22604060173034668
Batch 11/64 loss: 0.2360520362854004
Batch 12/64 loss: 0.24198830127716064
Batch 13/64 loss: 0.22946810722351074
Batch 14/64 loss: 0.22258293628692627
Batch 15/64 loss: 0.22153359651565552
Batch 16/64 loss: 0.22825229167938232
Batch 17/64 loss: 0.23219186067581177
Batch 18/64 loss: 0.2311221957206726
Batch 19/64 loss: 0.22518718242645264
Batch 20/64 loss: 0.2364952564239502
Batch 21/64 loss: 0.2324584722518921
Batch 22/64 loss: 0.2310882806777954
Batch 23/64 loss: 0.2292303442955017
Batch 24/64 loss: 0.2311704158782959
Batch 25/64 loss: 0.21776902675628662
Batch 26/64 loss: 0.23984867334365845
Batch 27/64 loss: 0.23730891942977905
Batch 28/64 loss: 0.23762571811676025
Batch 29/64 loss: 0.22644853591918945
Batch 30/64 loss: 0.2329820990562439
Batch 31/64 loss: 0.2298731803894043
Batch 32/64 loss: 0.22562283277511597
Batch 33/64 loss: 0.218508780002594
Batch 34/64 loss: 0.24549734592437744
Batch 35/64 loss: 0.22872233390808105
Batch 36/64 loss: 0.23537719249725342
Batch 37/64 loss: 0.23701488971710205
Batch 38/64 loss: 0.23676180839538574
Batch 39/64 loss: 0.2263181209564209
Batch 40/64 loss: 0.23564010858535767
Batch 41/64 loss: 0.22883689403533936
Batch 42/64 loss: 0.23668795824050903
Batch 43/64 loss: 0.23429620265960693
Batch 44/64 loss: 0.22961044311523438
Batch 45/64 loss: 0.23601865768432617
Batch 46/64 loss: 0.2477036714553833
Batch 47/64 loss: 0.23358464241027832
Batch 48/64 loss: 0.22973501682281494
Batch 49/64 loss: 0.2365700602531433
Batch 50/64 loss: 0.2268306016921997
Batch 51/64 loss: 0.23715662956237793
Batch 52/64 loss: 0.2327982783317566
Batch 53/64 loss: 0.23300611972808838
Batch 54/64 loss: 0.23004311323165894
Batch 55/64 loss: 0.2340969443321228
Batch 56/64 loss: 0.2263392210006714
Batch 57/64 loss: 0.23302936553955078
Batch 58/64 loss: 0.23009419441223145
Batch 59/64 loss: 0.23266732692718506
Batch 60/64 loss: 0.24695509672164917
Batch 61/64 loss: 0.23560500144958496
Batch 62/64 loss: 0.2327052354812622
Batch 63/64 loss: 0.2315918207168579
Batch 64/64 loss: 0.23669439554214478
Epoch 414  Train loss: 0.23231381972630818  Val loss: 0.28114438261772756
Epoch 415
-------------------------------
Batch 1/64 loss: 0.2325676679611206
Batch 2/64 loss: 0.23457551002502441
Batch 3/64 loss: 0.23147153854370117
Batch 4/64 loss: 0.22791457176208496
Batch 5/64 loss: 0.23237931728363037
Batch 6/64 loss: 0.2267589569091797
Batch 7/64 loss: 0.23991656303405762
Batch 8/64 loss: 0.23347079753875732
Batch 9/64 loss: 0.22941648960113525
Batch 10/64 loss: 0.23146653175354004
Batch 11/64 loss: 0.2176365852355957
Batch 12/64 loss: 0.23816800117492676
Batch 13/64 loss: 0.22924667596817017
Batch 14/64 loss: 0.22743189334869385
Batch 15/64 loss: 0.2266303300857544
Batch 16/64 loss: 0.22115355730056763
Batch 17/64 loss: 0.23288553953170776
Batch 18/64 loss: 0.22978639602661133
Batch 19/64 loss: 0.2290574312210083
Batch 20/64 loss: 0.2343050241470337
Batch 21/64 loss: 0.22517091035842896
Batch 22/64 loss: 0.23110437393188477
Batch 23/64 loss: 0.23274719715118408
Batch 24/64 loss: 0.233994722366333
Batch 25/64 loss: 0.2325652837753296
Batch 26/64 loss: 0.2313319444656372
Batch 27/64 loss: 0.24114346504211426
Batch 28/64 loss: 0.24590802192687988
Batch 29/64 loss: 0.23719263076782227
Batch 30/64 loss: 0.2384408712387085
Batch 31/64 loss: 0.22501391172409058
Batch 32/64 loss: 0.2395799160003662
Batch 33/64 loss: 0.23833072185516357
Batch 34/64 loss: 0.23344337940216064
Batch 35/64 loss: 0.23186969757080078
Batch 36/64 loss: 0.22197246551513672
Batch 37/64 loss: 0.23593157529830933
Batch 38/64 loss: 0.23282164335250854
Batch 39/64 loss: 0.22970879077911377
Batch 40/64 loss: 0.2307034134864807
Batch 41/64 loss: 0.23451626300811768
Batch 42/64 loss: 0.23623281717300415
Batch 43/64 loss: 0.23597633838653564
Batch 44/64 loss: 0.22881066799163818
Batch 45/64 loss: 0.23293399810791016
Batch 46/64 loss: 0.23195475339889526
Batch 47/64 loss: 0.2247229814529419
Batch 48/64 loss: 0.24557065963745117
Batch 49/64 loss: 0.22034919261932373
Batch 50/64 loss: 0.2403772473335266
Batch 51/64 loss: 0.22770559787750244
Batch 52/64 loss: 0.23078227043151855
Batch 53/64 loss: 0.235376238822937
Batch 54/64 loss: 0.23811936378479004
Batch 55/64 loss: 0.22937297821044922
Batch 56/64 loss: 0.23195219039916992
Batch 57/64 loss: 0.22558104991912842
Batch 58/64 loss: 0.23222088813781738
Batch 59/64 loss: 0.2299785017967224
Batch 60/64 loss: 0.23002398014068604
Batch 61/64 loss: 0.22886991500854492
Batch 62/64 loss: 0.232668936252594
Batch 63/64 loss: 0.23585665225982666
Batch 64/64 loss: 0.23860150575637817
Epoch 415  Train loss: 0.23206461060280895  Val loss: 0.28117398851106257
Epoch 416
-------------------------------
Batch 1/64 loss: 0.23188209533691406
Batch 2/64 loss: 0.22626090049743652
Batch 3/64 loss: 0.23580402135849
Batch 4/64 loss: 0.23464131355285645
Batch 5/64 loss: 0.2386377453804016
Batch 6/64 loss: 0.2313377857208252
Batch 7/64 loss: 0.22352206707000732
Batch 8/64 loss: 0.2261396050453186
Batch 9/64 loss: 0.23102271556854248
Batch 10/64 loss: 0.22631335258483887
Batch 11/64 loss: 0.235711932182312
Batch 12/64 loss: 0.22902345657348633
Batch 13/64 loss: 0.22856402397155762
Batch 14/64 loss: 0.2210584282875061
Batch 15/64 loss: 0.23432517051696777
Batch 16/64 loss: 0.22385835647583008
Batch 17/64 loss: 0.22186815738677979
Batch 18/64 loss: 0.23672115802764893
Batch 19/64 loss: 0.23252737522125244
Batch 20/64 loss: 0.23164349794387817
Batch 21/64 loss: 0.22821944952011108
Batch 22/64 loss: 0.2341674566268921
Batch 23/64 loss: 0.22799158096313477
Batch 24/64 loss: 0.22726577520370483
Batch 25/64 loss: 0.22838914394378662
Batch 26/64 loss: 0.227533221244812
Batch 27/64 loss: 0.22351038455963135
Batch 28/64 loss: 0.24377524852752686
Batch 29/64 loss: 0.23079675436019897
Batch 30/64 loss: 0.23739278316497803
Batch 31/64 loss: 0.22740095853805542
Batch 32/64 loss: 0.23415660858154297
Batch 33/64 loss: 0.22428542375564575
Batch 34/64 loss: 0.2337491512298584
Batch 35/64 loss: 0.23285996913909912
Batch 36/64 loss: 0.23260611295700073
Batch 37/64 loss: 0.2409498691558838
Batch 38/64 loss: 0.23555290699005127
Batch 39/64 loss: 0.23511552810668945
Batch 40/64 loss: 0.2365894317626953
Batch 41/64 loss: 0.23823148012161255
Batch 42/64 loss: 0.2527264952659607
Batch 43/64 loss: 0.22919219732284546
Batch 44/64 loss: 0.23902684450149536
Batch 45/64 loss: 0.23875808715820312
Batch 46/64 loss: 0.23238027095794678
Batch 47/64 loss: 0.22756946086883545
Batch 48/64 loss: 0.23829740285873413
Batch 49/64 loss: 0.23021382093429565
Batch 50/64 loss: 0.22338652610778809
Batch 51/64 loss: 0.23469090461730957
Batch 52/64 loss: 0.23436307907104492
Batch 53/64 loss: 0.22368711233139038
Batch 54/64 loss: 0.23996829986572266
Batch 55/64 loss: 0.23236608505249023
Batch 56/64 loss: 0.23905354738235474
Batch 57/64 loss: 0.23326241970062256
Batch 58/64 loss: 0.23213869333267212
Batch 59/64 loss: 0.23475348949432373
Batch 60/64 loss: 0.2458285689353943
Batch 61/64 loss: 0.23673689365386963
Batch 62/64 loss: 0.23533892631530762
Batch 63/64 loss: 0.2328144907951355
Batch 64/64 loss: 0.2333667278289795
Epoch 416  Train loss: 0.23251734995374493  Val loss: 0.28116628886088474
Epoch 417
-------------------------------
Batch 1/64 loss: 0.22819280624389648
Batch 2/64 loss: 0.22645783424377441
Batch 3/64 loss: 0.23155033588409424
Batch 4/64 loss: 0.23314714431762695
Batch 5/64 loss: 0.23196399211883545
Batch 6/64 loss: 0.2301539182662964
Batch 7/64 loss: 0.22714591026306152
Batch 8/64 loss: 0.2339072823524475
Batch 9/64 loss: 0.24300312995910645
Batch 10/64 loss: 0.24064290523529053
Batch 11/64 loss: 0.22005575895309448
Batch 12/64 loss: 0.2349381446838379
Batch 13/64 loss: 0.22296643257141113
Batch 14/64 loss: 0.24128293991088867
Batch 15/64 loss: 0.2407844066619873
Batch 16/64 loss: 0.22967666387557983
Batch 17/64 loss: 0.23448491096496582
Batch 18/64 loss: 0.2377070188522339
Batch 19/64 loss: 0.2283470630645752
Batch 20/64 loss: 0.23545241355895996
Batch 21/64 loss: 0.23392421007156372
Batch 22/64 loss: 0.23991245031356812
Batch 23/64 loss: 0.23163902759552002
Batch 24/64 loss: 0.23229002952575684
Batch 25/64 loss: 0.22799909114837646
Batch 26/64 loss: 0.23436766862869263
Batch 27/64 loss: 0.23818814754486084
Batch 28/64 loss: 0.23066675662994385
Batch 29/64 loss: 0.23045045137405396
Batch 30/64 loss: 0.23422282934188843
Batch 31/64 loss: 0.23011553287506104
Batch 32/64 loss: 0.23354852199554443
Batch 33/64 loss: 0.22179502248764038
Batch 34/64 loss: 0.23458266258239746
Batch 35/64 loss: 0.22424840927124023
Batch 36/64 loss: 0.23844760656356812
Batch 37/64 loss: 0.24498862028121948
Batch 38/64 loss: 0.23587048053741455
Batch 39/64 loss: 0.23319923877716064
Batch 40/64 loss: 0.22959589958190918
Batch 41/64 loss: 0.23287880420684814
Batch 42/64 loss: 0.2386486530303955
Batch 43/64 loss: 0.2357025146484375
Batch 44/64 loss: 0.2363007664680481
Batch 45/64 loss: 0.23425590991973877
Batch 46/64 loss: 0.23266327381134033
Batch 47/64 loss: 0.24106425046920776
Batch 48/64 loss: 0.23870253562927246
Batch 49/64 loss: 0.24012959003448486
Batch 50/64 loss: 0.23835349082946777
Batch 51/64 loss: 0.22329086065292358
Batch 52/64 loss: 0.23059165477752686
Batch 53/64 loss: 0.22884845733642578
Batch 54/64 loss: 0.23112010955810547
Batch 55/64 loss: 0.24462288618087769
Batch 56/64 loss: 0.22793710231781006
Batch 57/64 loss: 0.22693806886672974
Batch 58/64 loss: 0.23228973150253296
Batch 59/64 loss: 0.23977965116500854
Batch 60/64 loss: 0.22267693281173706
Batch 61/64 loss: 0.22896325588226318
Batch 62/64 loss: 0.23908042907714844
Batch 63/64 loss: 0.23282545804977417
Batch 64/64 loss: 0.22795188426971436
Epoch 417  Train loss: 0.23310654069863113  Val loss: 0.2828217177456597
Epoch 418
-------------------------------
Batch 1/64 loss: 0.21870452165603638
Batch 2/64 loss: 0.2346583604812622
Batch 3/64 loss: 0.22459781169891357
Batch 4/64 loss: 0.23127317428588867
Batch 5/64 loss: 0.23339468240737915
Batch 6/64 loss: 0.2349797487258911
Batch 7/64 loss: 0.23476803302764893
Batch 8/64 loss: 0.21849405765533447
Batch 9/64 loss: 0.2190767526626587
Batch 10/64 loss: 0.2306452989578247
Batch 11/64 loss: 0.2312309741973877
Batch 12/64 loss: 0.2292649745941162
Batch 13/64 loss: 0.23093628883361816
Batch 14/64 loss: 0.23276042938232422
Batch 15/64 loss: 0.24248254299163818
Batch 16/64 loss: 0.23921728134155273
Batch 17/64 loss: 0.23793566226959229
Batch 18/64 loss: 0.23581182956695557
Batch 19/64 loss: 0.23660063743591309
Batch 20/64 loss: 0.22989904880523682
Batch 21/64 loss: 0.23212754726409912
Batch 22/64 loss: 0.22689849138259888
Batch 23/64 loss: 0.2356863021850586
Batch 24/64 loss: 0.2330126166343689
Batch 25/64 loss: 0.23701614141464233
Batch 26/64 loss: 0.2243025302886963
Batch 27/64 loss: 0.2173703908920288
Batch 28/64 loss: 0.2290785312652588
Batch 29/64 loss: 0.23165810108184814
Batch 30/64 loss: 0.2509869933128357
Batch 31/64 loss: 0.2494233250617981
Batch 32/64 loss: 0.227275550365448
Batch 33/64 loss: 0.22214627265930176
Batch 34/64 loss: 0.230971097946167
Batch 35/64 loss: 0.23029875755310059
Batch 36/64 loss: 0.2319856882095337
Batch 37/64 loss: 0.2263408899307251
Batch 38/64 loss: 0.22661751508712769
Batch 39/64 loss: 0.232915997505188
Batch 40/64 loss: 0.23406565189361572
Batch 41/64 loss: 0.2363753318786621
Batch 42/64 loss: 0.2255955934524536
Batch 43/64 loss: 0.2405582070350647
Batch 44/64 loss: 0.2254199981689453
Batch 45/64 loss: 0.23784255981445312
Batch 46/64 loss: 0.23166024684906006
Batch 47/64 loss: 0.2334202527999878
Batch 48/64 loss: 0.22594451904296875
Batch 49/64 loss: 0.23240512609481812
Batch 50/64 loss: 0.22850251197814941
Batch 51/64 loss: 0.2353830337524414
Batch 52/64 loss: 0.238861083984375
Batch 53/64 loss: 0.2376861572265625
Batch 54/64 loss: 0.22003412246704102
Batch 55/64 loss: 0.23226690292358398
Batch 56/64 loss: 0.22420823574066162
Batch 57/64 loss: 0.24460560083389282
Batch 58/64 loss: 0.23507630825042725
Batch 59/64 loss: 0.2382914423942566
Batch 60/64 loss: 0.23993909358978271
Batch 61/64 loss: 0.23024851083755493
Batch 62/64 loss: 0.227433443069458
Batch 63/64 loss: 0.23501765727996826
Batch 64/64 loss: 0.22292935848236084
Epoch 418  Train loss: 0.23185699547038358  Val loss: 0.28128965859560623
Epoch 419
-------------------------------
Batch 1/64 loss: 0.2252170443534851
Batch 2/64 loss: 0.22228527069091797
Batch 3/64 loss: 0.24344658851623535
Batch 4/64 loss: 0.23976683616638184
Batch 5/64 loss: 0.23447978496551514
Batch 6/64 loss: 0.22778642177581787
Batch 7/64 loss: 0.22253334522247314
Batch 8/64 loss: 0.23364341259002686
Batch 9/64 loss: 0.22407090663909912
Batch 10/64 loss: 0.22296380996704102
Batch 11/64 loss: 0.23194611072540283
Batch 12/64 loss: 0.22871756553649902
Batch 13/64 loss: 0.23246008157730103
Batch 14/64 loss: 0.2308487892150879
Batch 15/64 loss: 0.2347823977470398
Batch 16/64 loss: 0.23272758722305298
Batch 17/64 loss: 0.2324817180633545
Batch 18/64 loss: 0.23655933141708374
Batch 19/64 loss: 0.24225223064422607
Batch 20/64 loss: 0.2300710678100586
Batch 21/64 loss: 0.2339501976966858
Batch 22/64 loss: 0.2418157458305359
Batch 23/64 loss: 0.2351425290107727
Batch 24/64 loss: 0.22883272171020508
Batch 25/64 loss: 0.2230379581451416
Batch 26/64 loss: 0.23449110984802246
Batch 27/64 loss: 0.23804020881652832
Batch 28/64 loss: 0.2292935848236084
Batch 29/64 loss: 0.22953790426254272
Batch 30/64 loss: 0.24331706762313843
Batch 31/64 loss: 0.23331522941589355
Batch 32/64 loss: 0.2276625633239746
Batch 33/64 loss: 0.2327895164489746
Batch 34/64 loss: 0.23663055896759033
Batch 35/64 loss: 0.23269331455230713
Batch 36/64 loss: 0.22392290830612183
Batch 37/64 loss: 0.22465091943740845
Batch 38/64 loss: 0.2282257080078125
Batch 39/64 loss: 0.2333836555480957
Batch 40/64 loss: 0.22762274742126465
Batch 41/64 loss: 0.23103582859039307
Batch 42/64 loss: 0.23224616050720215
Batch 43/64 loss: 0.22247767448425293
Batch 44/64 loss: 0.2336406111717224
Batch 45/64 loss: 0.22980237007141113
Batch 46/64 loss: 0.2328474521636963
Batch 47/64 loss: 0.22578513622283936
Batch 48/64 loss: 0.2304013967514038
Batch 49/64 loss: 0.23461580276489258
Batch 50/64 loss: 0.23739105463027954
Batch 51/64 loss: 0.24179279804229736
Batch 52/64 loss: 0.2265046238899231
Batch 53/64 loss: 0.23246222734451294
Batch 54/64 loss: 0.241327166557312
Batch 55/64 loss: 0.22897988557815552
Batch 56/64 loss: 0.22941887378692627
Batch 57/64 loss: 0.22841250896453857
Batch 58/64 loss: 0.23380696773529053
Batch 59/64 loss: 0.22880512475967407
Batch 60/64 loss: 0.23471975326538086
Batch 61/64 loss: 0.2339991331100464
Batch 62/64 loss: 0.23047411441802979
Batch 63/64 loss: 0.22984981536865234
Batch 64/64 loss: 0.244240403175354
Epoch 419  Train loss: 0.23186467815847958  Val loss: 0.2826280854002307
Epoch 420
-------------------------------
Batch 1/64 loss: 0.23585748672485352
Batch 2/64 loss: 0.22801190614700317
Batch 3/64 loss: 0.22410762310028076
Batch 4/64 loss: 0.22816073894500732
Batch 5/64 loss: 0.23539996147155762
Batch 6/64 loss: 0.22695505619049072
Batch 7/64 loss: 0.2333892583847046
Batch 8/64 loss: 0.23173457384109497
Batch 9/64 loss: 0.23234963417053223
Batch 10/64 loss: 0.2229304313659668
Batch 11/64 loss: 0.2234351634979248
Batch 12/64 loss: 0.22446763515472412
Batch 13/64 loss: 0.22251743078231812
Batch 14/64 loss: 0.23822665214538574
Batch 15/64 loss: 0.2260112762451172
Batch 16/64 loss: 0.24666303396224976
Batch 17/64 loss: 0.22110015153884888
Batch 18/64 loss: 0.22553151845932007
Batch 19/64 loss: 0.23811089992523193
Batch 20/64 loss: 0.23206055164337158
Batch 21/64 loss: 0.2331022024154663
Batch 22/64 loss: 0.23299354314804077
Batch 23/64 loss: 0.22927385568618774
Batch 24/64 loss: 0.23326992988586426
Batch 25/64 loss: 0.2354649305343628
Batch 26/64 loss: 0.23602831363677979
Batch 27/64 loss: 0.230859637260437
Batch 28/64 loss: 0.22061574459075928
Batch 29/64 loss: 0.2232046127319336
Batch 30/64 loss: 0.2281416654586792
Batch 31/64 loss: 0.2271583080291748
Batch 32/64 loss: 0.22940164804458618
Batch 33/64 loss: 0.23749613761901855
Batch 34/64 loss: 0.2365356683731079
Batch 35/64 loss: 0.23210859298706055
Batch 36/64 loss: 0.23835456371307373
Batch 37/64 loss: 0.23234057426452637
Batch 38/64 loss: 0.2456129789352417
Batch 39/64 loss: 0.22657334804534912
Batch 40/64 loss: 0.235173761844635
Batch 41/64 loss: 0.22935044765472412
Batch 42/64 loss: 0.24363231658935547
Batch 43/64 loss: 0.23463237285614014
Batch 44/64 loss: 0.22619599103927612
Batch 45/64 loss: 0.23705261945724487
Batch 46/64 loss: 0.23283171653747559
Batch 47/64 loss: 0.22940278053283691
Batch 48/64 loss: 0.22760140895843506
Batch 49/64 loss: 0.2323889136314392
Batch 50/64 loss: 0.24301934242248535
Batch 51/64 loss: 0.23163771629333496
Batch 52/64 loss: 0.229350745677948
Batch 53/64 loss: 0.24331098794937134
Batch 54/64 loss: 0.22830820083618164
Batch 55/64 loss: 0.2326509952545166
Batch 56/64 loss: 0.2387036681175232
Batch 57/64 loss: 0.2295771837234497
Batch 58/64 loss: 0.22851967811584473
Batch 59/64 loss: 0.24048066139221191
Batch 60/64 loss: 0.23006165027618408
Batch 61/64 loss: 0.2512050271034241
Batch 62/64 loss: 0.230019211769104
Batch 63/64 loss: 0.22538596391677856
Batch 64/64 loss: 0.23665982484817505
Epoch 420  Train loss: 0.23205561521006565  Val loss: 0.2822903091555199
Epoch 421
-------------------------------
Batch 1/64 loss: 0.23177063465118408
Batch 2/64 loss: 0.22861528396606445
Batch 3/64 loss: 0.24890470504760742
Batch 4/64 loss: 0.23332446813583374
Batch 5/64 loss: 0.23162412643432617
Batch 6/64 loss: 0.23184806108474731
Batch 7/64 loss: 0.22744786739349365
Batch 8/64 loss: 0.22993582487106323
Batch 9/64 loss: 0.24125206470489502
Batch 10/64 loss: 0.2241387963294983
Batch 11/64 loss: 0.22817182540893555
Batch 12/64 loss: 0.22786682844161987
Batch 13/64 loss: 0.2274937629699707
Batch 14/64 loss: 0.22052639722824097
Batch 15/64 loss: 0.22887885570526123
Batch 16/64 loss: 0.24045634269714355
Batch 17/64 loss: 0.2317827343940735
Batch 18/64 loss: 0.23943042755126953
Batch 19/64 loss: 0.2430959939956665
Batch 20/64 loss: 0.22756826877593994
Batch 21/64 loss: 0.23379623889923096
Batch 22/64 loss: 0.2314404845237732
Batch 23/64 loss: 0.22887051105499268
Batch 24/64 loss: 0.24152135848999023
Batch 25/64 loss: 0.22665917873382568
Batch 26/64 loss: 0.2282487154006958
Batch 27/64 loss: 0.22776895761489868
Batch 28/64 loss: 0.23254823684692383
Batch 29/64 loss: 0.22979199886322021
Batch 30/64 loss: 0.23969602584838867
Batch 31/64 loss: 0.22438538074493408
Batch 32/64 loss: 0.23663127422332764
Batch 33/64 loss: 0.22608661651611328
Batch 34/64 loss: 0.22792434692382812
Batch 35/64 loss: 0.22617483139038086
Batch 36/64 loss: 0.23117804527282715
Batch 37/64 loss: 0.22664391994476318
Batch 38/64 loss: 0.23139357566833496
Batch 39/64 loss: 0.2346651554107666
Batch 40/64 loss: 0.2287982702255249
Batch 41/64 loss: 0.24062740802764893
Batch 42/64 loss: 0.22674214839935303
Batch 43/64 loss: 0.22736799716949463
Batch 44/64 loss: 0.22479641437530518
Batch 45/64 loss: 0.2314697504043579
Batch 46/64 loss: 0.23249703645706177
Batch 47/64 loss: 0.22961485385894775
Batch 48/64 loss: 0.23573315143585205
Batch 49/64 loss: 0.23128622770309448
Batch 50/64 loss: 0.21636712551116943
Batch 51/64 loss: 0.23317301273345947
Batch 52/64 loss: 0.2280815839767456
Batch 53/64 loss: 0.2300814390182495
Batch 54/64 loss: 0.22620421648025513
Batch 55/64 loss: 0.22542858123779297
Batch 56/64 loss: 0.2352467179298401
Batch 57/64 loss: 0.24053025245666504
Batch 58/64 loss: 0.23454433679580688
Batch 59/64 loss: 0.2368314266204834
Batch 60/64 loss: 0.23222970962524414
Batch 61/64 loss: 0.2452096939086914
Batch 62/64 loss: 0.23913532495498657
Batch 63/64 loss: 0.22722768783569336
Batch 64/64 loss: 0.24004864692687988
Epoch 421  Train loss: 0.23166774861952838  Val loss: 0.281346233440019
Epoch 422
-------------------------------
Batch 1/64 loss: 0.23625558614730835
Batch 2/64 loss: 0.2234668731689453
Batch 3/64 loss: 0.2277367115020752
Batch 4/64 loss: 0.23564410209655762
Batch 5/64 loss: 0.21629542112350464
Batch 6/64 loss: 0.22748416662216187
Batch 7/64 loss: 0.2330152988433838
Batch 8/64 loss: 0.225244402885437
Batch 9/64 loss: 0.22954928874969482
Batch 10/64 loss: 0.2241835594177246
Batch 11/64 loss: 0.23287290334701538
Batch 12/64 loss: 0.23447400331497192
Batch 13/64 loss: 0.22977030277252197
Batch 14/64 loss: 0.24572664499282837
Batch 15/64 loss: 0.22995686531066895
Batch 16/64 loss: 0.22276091575622559
Batch 17/64 loss: 0.2287658452987671
Batch 18/64 loss: 0.228080153465271
Batch 19/64 loss: 0.2331637144088745
Batch 20/64 loss: 0.23788875341415405
Batch 21/64 loss: 0.21995043754577637
Batch 22/64 loss: 0.2421790361404419
Batch 23/64 loss: 0.2291911244392395
Batch 24/64 loss: 0.2306525707244873
Batch 25/64 loss: 0.22560381889343262
Batch 26/64 loss: 0.2388467788696289
Batch 27/64 loss: 0.24244117736816406
Batch 28/64 loss: 0.2386331558227539
Batch 29/64 loss: 0.22671711444854736
Batch 30/64 loss: 0.2292860746383667
Batch 31/64 loss: 0.22043561935424805
Batch 32/64 loss: 0.23403692245483398
Batch 33/64 loss: 0.22475028038024902
Batch 34/64 loss: 0.22554939985275269
Batch 35/64 loss: 0.23589026927947998
Batch 36/64 loss: 0.236730694770813
Batch 37/64 loss: 0.22584372758865356
Batch 38/64 loss: 0.23790037631988525
Batch 39/64 loss: 0.23260098695755005
Batch 40/64 loss: 0.22609585523605347
Batch 41/64 loss: 0.229162335395813
Batch 42/64 loss: 0.22739076614379883
Batch 43/64 loss: 0.24016273021697998
Batch 44/64 loss: 0.2375926375389099
Batch 45/64 loss: 0.21548032760620117
Batch 46/64 loss: 0.23730546236038208
Batch 47/64 loss: 0.23666048049926758
Batch 48/64 loss: 0.24465417861938477
Batch 49/64 loss: 0.2270115613937378
Batch 50/64 loss: 0.23573851585388184
Batch 51/64 loss: 0.2301616668701172
Batch 52/64 loss: 0.22315406799316406
Batch 53/64 loss: 0.23003339767456055
Batch 54/64 loss: 0.23033368587493896
Batch 55/64 loss: 0.23305296897888184
Batch 56/64 loss: 0.23249733448028564
Batch 57/64 loss: 0.2335296869277954
Batch 58/64 loss: 0.23637008666992188
Batch 59/64 loss: 0.25051814317703247
Batch 60/64 loss: 0.23236966133117676
Batch 61/64 loss: 0.23535102605819702
Batch 62/64 loss: 0.23634755611419678
Batch 63/64 loss: 0.2272965908050537
Batch 64/64 loss: 0.2300199270248413
Epoch 422  Train loss: 0.231535070550208  Val loss: 0.28149126833656807
Epoch 423
-------------------------------
Batch 1/64 loss: 0.2309984564781189
Batch 2/64 loss: 0.2255152463912964
Batch 3/64 loss: 0.23522841930389404
Batch 4/64 loss: 0.23427945375442505
Batch 5/64 loss: 0.2430562973022461
Batch 6/64 loss: 0.23302996158599854
Batch 7/64 loss: 0.22312712669372559
Batch 8/64 loss: 0.2268744707107544
Batch 9/64 loss: 0.23288363218307495
Batch 10/64 loss: 0.24085044860839844
Batch 11/64 loss: 0.22788482904434204
Batch 12/64 loss: 0.22268569469451904
Batch 13/64 loss: 0.23107391595840454
Batch 14/64 loss: 0.22681552171707153
Batch 15/64 loss: 0.22461998462677002
Batch 16/64 loss: 0.2351256012916565
Batch 17/64 loss: 0.23035812377929688
Batch 18/64 loss: 0.24221694469451904
Batch 19/64 loss: 0.2391236424446106
Batch 20/64 loss: 0.2334672212600708
Batch 21/64 loss: 0.22109264135360718
Batch 22/64 loss: 0.22030377388000488
Batch 23/64 loss: 0.22928273677825928
Batch 24/64 loss: 0.2289595603942871
Batch 25/64 loss: 0.23128938674926758
Batch 26/64 loss: 0.23801058530807495
Batch 27/64 loss: 0.2304145097732544
Batch 28/64 loss: 0.2363189458847046
Batch 29/64 loss: 0.2251078486442566
Batch 30/64 loss: 0.22687643766403198
Batch 31/64 loss: 0.2314605712890625
Batch 32/64 loss: 0.25485682487487793
Batch 33/64 loss: 0.22826671600341797
Batch 34/64 loss: 0.22400707006454468
Batch 35/64 loss: 0.2288738489151001
Batch 36/64 loss: 0.230451762676239
Batch 37/64 loss: 0.22948157787322998
Batch 38/64 loss: 0.2411060333251953
Batch 39/64 loss: 0.23843920230865479
Batch 40/64 loss: 0.23316121101379395
Batch 41/64 loss: 0.22858446836471558
Batch 42/64 loss: 0.2266886830329895
Batch 43/64 loss: 0.22494256496429443
Batch 44/64 loss: 0.23443603515625
Batch 45/64 loss: 0.2284976840019226
Batch 46/64 loss: 0.23927617073059082
Batch 47/64 loss: 0.22503608465194702
Batch 48/64 loss: 0.23286902904510498
Batch 49/64 loss: 0.2328634262084961
Batch 50/64 loss: 0.22715318202972412
Batch 51/64 loss: 0.2335602045059204
Batch 52/64 loss: 0.22379767894744873
Batch 53/64 loss: 0.2303915023803711
Batch 54/64 loss: 0.2346045970916748
Batch 55/64 loss: 0.23554927110671997
Batch 56/64 loss: 0.221000075340271
Batch 57/64 loss: 0.23314404487609863
Batch 58/64 loss: 0.22809970378875732
Batch 59/64 loss: 0.235146164894104
Batch 60/64 loss: 0.230584979057312
Batch 61/64 loss: 0.2352370023727417
Batch 62/64 loss: 0.23248213529586792
Batch 63/64 loss: 0.22990012168884277
Batch 64/64 loss: 0.24620819091796875
Epoch 423  Train loss: 0.23145846572576784  Val loss: 0.2821423661258213
Epoch 424
-------------------------------
Batch 1/64 loss: 0.23622441291809082
Batch 2/64 loss: 0.22776633501052856
Batch 3/64 loss: 0.23737359046936035
Batch 4/64 loss: 0.23202228546142578
Batch 5/64 loss: 0.22676914930343628
Batch 6/64 loss: 0.22918576002120972
Batch 7/64 loss: 0.24012845754623413
Batch 8/64 loss: 0.23147118091583252
Batch 9/64 loss: 0.22990471124649048
Batch 10/64 loss: 0.24693024158477783
Batch 11/64 loss: 0.2322373390197754
Batch 12/64 loss: 0.2455449104309082
Batch 13/64 loss: 0.22536230087280273
Batch 14/64 loss: 0.24099749326705933
Batch 15/64 loss: 0.2293371558189392
Batch 16/64 loss: 0.22731828689575195
Batch 17/64 loss: 0.22602719068527222
Batch 18/64 loss: 0.23003530502319336
Batch 19/64 loss: 0.22972524166107178
Batch 20/64 loss: 0.22017264366149902
Batch 21/64 loss: 0.22656989097595215
Batch 22/64 loss: 0.23436975479125977
Batch 23/64 loss: 0.22990906238555908
Batch 24/64 loss: 0.22977805137634277
Batch 25/64 loss: 0.2346319556236267
Batch 26/64 loss: 0.23368722200393677
Batch 27/64 loss: 0.2250303030014038
Batch 28/64 loss: 0.22301650047302246
Batch 29/64 loss: 0.22989344596862793
Batch 30/64 loss: 0.22361326217651367
Batch 31/64 loss: 0.2223595380783081
Batch 32/64 loss: 0.22439146041870117
Batch 33/64 loss: 0.24633580446243286
Batch 34/64 loss: 0.22594976425170898
Batch 35/64 loss: 0.23028814792633057
Batch 36/64 loss: 0.23645919561386108
Batch 37/64 loss: 0.22682636976242065
Batch 38/64 loss: 0.22842490673065186
Batch 39/64 loss: 0.2266826629638672
Batch 40/64 loss: 0.2383318543434143
Batch 41/64 loss: 0.2308298945426941
Batch 42/64 loss: 0.22690743207931519
Batch 43/64 loss: 0.2398817539215088
Batch 44/64 loss: 0.23333346843719482
Batch 45/64 loss: 0.22626221179962158
Batch 46/64 loss: 0.24219024181365967
Batch 47/64 loss: 0.23151326179504395
Batch 48/64 loss: 0.23379546403884888
Batch 49/64 loss: 0.2277599573135376
Batch 50/64 loss: 0.22609055042266846
Batch 51/64 loss: 0.23334968090057373
Batch 52/64 loss: 0.2399221658706665
Batch 53/64 loss: 0.23332130908966064
Batch 54/64 loss: 0.23982834815979004
Batch 55/64 loss: 0.24291878938674927
Batch 56/64 loss: 0.23047763109207153
Batch 57/64 loss: 0.22886496782302856
Batch 58/64 loss: 0.22569429874420166
Batch 59/64 loss: 0.23538464307785034
Batch 60/64 loss: 0.23775792121887207
Batch 61/64 loss: 0.24214589595794678
Batch 62/64 loss: 0.2298048734664917
Batch 63/64 loss: 0.22148913145065308
Batch 64/64 loss: 0.23140162229537964
Epoch 424  Train loss: 0.2317515020276986  Val loss: 0.2815439559749721
Epoch 425
-------------------------------
Batch 1/64 loss: 0.24295294284820557
Batch 2/64 loss: 0.2258141040802002
Batch 3/64 loss: 0.22969073057174683
Batch 4/64 loss: 0.22798001766204834
Batch 5/64 loss: 0.2364131212234497
Batch 6/64 loss: 0.24021434783935547
Batch 7/64 loss: 0.23188412189483643
Batch 8/64 loss: 0.22476083040237427
Batch 9/64 loss: 0.22178035974502563
Batch 10/64 loss: 0.2370471954345703
Batch 11/64 loss: 0.23354500532150269
Batch 12/64 loss: 0.2219194769859314
Batch 13/64 loss: 0.23793911933898926
Batch 14/64 loss: 0.2321683168411255
Batch 15/64 loss: 0.22535711526870728
Batch 16/64 loss: 0.22944462299346924
Batch 17/64 loss: 0.22877514362335205
Batch 18/64 loss: 0.238439679145813
Batch 19/64 loss: 0.24359345436096191
Batch 20/64 loss: 0.23216599225997925
Batch 21/64 loss: 0.2283603549003601
Batch 22/64 loss: 0.22975856065750122
Batch 23/64 loss: 0.2424677610397339
Batch 24/64 loss: 0.22134184837341309
Batch 25/64 loss: 0.2261783480644226
Batch 26/64 loss: 0.24589872360229492
Batch 27/64 loss: 0.24055469036102295
Batch 28/64 loss: 0.23275935649871826
Batch 29/64 loss: 0.22783887386322021
Batch 30/64 loss: 0.23456060886383057
Batch 31/64 loss: 0.23437583446502686
Batch 32/64 loss: 0.23470216989517212
Batch 33/64 loss: 0.2338343858718872
Batch 34/64 loss: 0.22809016704559326
Batch 35/64 loss: 0.2254531979560852
Batch 36/64 loss: 0.22836482524871826
Batch 37/64 loss: 0.22440952062606812
Batch 38/64 loss: 0.24219465255737305
Batch 39/64 loss: 0.23720085620880127
Batch 40/64 loss: 0.23220276832580566
Batch 41/64 loss: 0.24050211906433105
Batch 42/64 loss: 0.23489773273468018
Batch 43/64 loss: 0.22285544872283936
Batch 44/64 loss: 0.23147523403167725
Batch 45/64 loss: 0.22893035411834717
Batch 46/64 loss: 0.22875428199768066
Batch 47/64 loss: 0.2349313497543335
Batch 48/64 loss: 0.2339249849319458
Batch 49/64 loss: 0.2327638864517212
Batch 50/64 loss: 0.24174898862838745
Batch 51/64 loss: 0.23234981298446655
Batch 52/64 loss: 0.2295595407485962
Batch 53/64 loss: 0.23747289180755615
Batch 54/64 loss: 0.23796427249908447
Batch 55/64 loss: 0.23807919025421143
Batch 56/64 loss: 0.2391487956047058
Batch 57/64 loss: 0.22749197483062744
Batch 58/64 loss: 0.22531431913375854
Batch 59/64 loss: 0.23569786548614502
Batch 60/64 loss: 0.23082202672958374
Batch 61/64 loss: 0.23181724548339844
Batch 62/64 loss: 0.23229092359542847
Batch 63/64 loss: 0.22487127780914307
Batch 64/64 loss: 0.24006259441375732
Epoch 425  Train loss: 0.23256697514477898  Val loss: 0.2814833247374833
Epoch 426
-------------------------------
Batch 1/64 loss: 0.224753737449646
Batch 2/64 loss: 0.23940247297286987
Batch 3/64 loss: 0.23141074180603027
Batch 4/64 loss: 0.22832441329956055
Batch 5/64 loss: 0.22735381126403809
Batch 6/64 loss: 0.22169089317321777
Batch 7/64 loss: 0.23558473587036133
Batch 8/64 loss: 0.22754067182540894
Batch 9/64 loss: 0.22238075733184814
Batch 10/64 loss: 0.23897475004196167
Batch 11/64 loss: 0.23230671882629395
Batch 12/64 loss: 0.2385185956954956
Batch 13/64 loss: 0.23119354248046875
Batch 14/64 loss: 0.23702609539031982
Batch 15/64 loss: 0.23479682207107544
Batch 16/64 loss: 0.23150485754013062
Batch 17/64 loss: 0.23285400867462158
Batch 18/64 loss: 0.22617530822753906
Batch 19/64 loss: 0.2241271734237671
Batch 20/64 loss: 0.22754645347595215
Batch 21/64 loss: 0.22292625904083252
Batch 22/64 loss: 0.2296433448791504
Batch 23/64 loss: 0.2219080924987793
Batch 24/64 loss: 0.2318425178527832
Batch 25/64 loss: 0.23181498050689697
Batch 26/64 loss: 0.22946453094482422
Batch 27/64 loss: 0.2404455542564392
Batch 28/64 loss: 0.2299187183380127
Batch 29/64 loss: 0.2430095672607422
Batch 30/64 loss: 0.22717046737670898
Batch 31/64 loss: 0.22447770833969116
Batch 32/64 loss: 0.22877919673919678
Batch 33/64 loss: 0.23136788606643677
Batch 34/64 loss: 0.22646069526672363
Batch 35/64 loss: 0.23430538177490234
Batch 36/64 loss: 0.22824597358703613
Batch 37/64 loss: 0.24693244695663452
Batch 38/64 loss: 0.22363555431365967
Batch 39/64 loss: 0.23656940460205078
Batch 40/64 loss: 0.2243647575378418
Batch 41/64 loss: 0.2287256121635437
Batch 42/64 loss: 0.2300323247909546
Batch 43/64 loss: 0.2404041886329651
Batch 44/64 loss: 0.2342226505279541
Batch 45/64 loss: 0.24346673488616943
Batch 46/64 loss: 0.23651105165481567
Batch 47/64 loss: 0.22696083784103394
Batch 48/64 loss: 0.23208099603652954
Batch 49/64 loss: 0.2311844825744629
Batch 50/64 loss: 0.23279142379760742
Batch 51/64 loss: 0.22938525676727295
Batch 52/64 loss: 0.23194873332977295
Batch 53/64 loss: 0.23156559467315674
Batch 54/64 loss: 0.23266011476516724
Batch 55/64 loss: 0.23788738250732422
Batch 56/64 loss: 0.23919618129730225
Batch 57/64 loss: 0.22429585456848145
Batch 58/64 loss: 0.22800421714782715
Batch 59/64 loss: 0.2228286862373352
Batch 60/64 loss: 0.23235666751861572
Batch 61/64 loss: 0.23607885837554932
Batch 62/64 loss: 0.226190447807312
Batch 63/64 loss: 0.24606561660766602
Batch 64/64 loss: 0.23909640312194824
Epoch 426  Train loss: 0.2315437775032193  Val loss: 0.2828744016971785
Epoch 427
-------------------------------
Batch 1/64 loss: 0.2286137342453003
Batch 2/64 loss: 0.22380679845809937
Batch 3/64 loss: 0.22531980276107788
Batch 4/64 loss: 0.22805094718933105
Batch 5/64 loss: 0.21494412422180176
Batch 6/64 loss: 0.22613519430160522
Batch 7/64 loss: 0.23019897937774658
Batch 8/64 loss: 0.22935569286346436
Batch 9/64 loss: 0.22987890243530273
Batch 10/64 loss: 0.22621458768844604
Batch 11/64 loss: 0.22575289011001587
Batch 12/64 loss: 0.21732521057128906
Batch 13/64 loss: 0.2372187376022339
Batch 14/64 loss: 0.2253570556640625
Batch 15/64 loss: 0.23987412452697754
Batch 16/64 loss: 0.2375677227973938
Batch 17/64 loss: 0.2192654013633728
Batch 18/64 loss: 0.23038709163665771
Batch 19/64 loss: 0.22797048091888428
Batch 20/64 loss: 0.2242085337638855
Batch 21/64 loss: 0.2270095944404602
Batch 22/64 loss: 0.2264135479927063
Batch 23/64 loss: 0.23645353317260742
Batch 24/64 loss: 0.2303985357284546
Batch 25/64 loss: 0.2307877540588379
Batch 26/64 loss: 0.22246235609054565
Batch 27/64 loss: 0.23452019691467285
Batch 28/64 loss: 0.23097383975982666
Batch 29/64 loss: 0.23360735177993774
Batch 30/64 loss: 0.22925925254821777
Batch 31/64 loss: 0.229742169380188
Batch 32/64 loss: 0.2334231734275818
Batch 33/64 loss: 0.23413217067718506
Batch 34/64 loss: 0.22732889652252197
Batch 35/64 loss: 0.23008215427398682
Batch 36/64 loss: 0.22410273551940918
Batch 37/64 loss: 0.22457528114318848
Batch 38/64 loss: 0.23246359825134277
Batch 39/64 loss: 0.2406378984451294
Batch 40/64 loss: 0.22678637504577637
Batch 41/64 loss: 0.23412251472473145
Batch 42/64 loss: 0.22989213466644287
Batch 43/64 loss: 0.2268155813217163
Batch 44/64 loss: 0.22927838563919067
Batch 45/64 loss: 0.23227143287658691
Batch 46/64 loss: 0.2214658260345459
Batch 47/64 loss: 0.23604720830917358
Batch 48/64 loss: 0.23357641696929932
Batch 49/64 loss: 0.24131792783737183
Batch 50/64 loss: 0.2294325828552246
Batch 51/64 loss: 0.22892636060714722
Batch 52/64 loss: 0.22459030151367188
Batch 53/64 loss: 0.23531609773635864
Batch 54/64 loss: 0.23028242588043213
Batch 55/64 loss: 0.2370316982269287
Batch 56/64 loss: 0.23173248767852783
Batch 57/64 loss: 0.22596192359924316
Batch 58/64 loss: 0.22192871570587158
Batch 59/64 loss: 0.24109846353530884
Batch 60/64 loss: 0.2342166304588318
Batch 61/64 loss: 0.2324649691581726
Batch 62/64 loss: 0.23439955711364746
Batch 63/64 loss: 0.2349257469177246
Batch 64/64 loss: 0.25287926197052
Epoch 427  Train loss: 0.2301076276629579  Val loss: 0.2818272195730832
Epoch 428
-------------------------------
Batch 1/64 loss: 0.23136812448501587
Batch 2/64 loss: 0.22267913818359375
Batch 3/64 loss: 0.22968721389770508
Batch 4/64 loss: 0.2266627550125122
Batch 5/64 loss: 0.2254663109779358
Batch 6/64 loss: 0.22371184825897217
Batch 7/64 loss: 0.2292303442955017
Batch 8/64 loss: 0.23219966888427734
Batch 9/64 loss: 0.22152209281921387
Batch 10/64 loss: 0.23922669887542725
Batch 11/64 loss: 0.2343597412109375
Batch 12/64 loss: 0.22190338373184204
Batch 13/64 loss: 0.2335132360458374
Batch 14/64 loss: 0.22236371040344238
Batch 15/64 loss: 0.23469918966293335
Batch 16/64 loss: 0.21750879287719727
Batch 17/64 loss: 0.2265629768371582
Batch 18/64 loss: 0.22460007667541504
Batch 19/64 loss: 0.23299717903137207
Batch 20/64 loss: 0.23192650079727173
Batch 21/64 loss: 0.23921525478363037
Batch 22/64 loss: 0.23378610610961914
Batch 23/64 loss: 0.23370790481567383
Batch 24/64 loss: 0.22959542274475098
Batch 25/64 loss: 0.2198779582977295
Batch 26/64 loss: 0.23377668857574463
Batch 27/64 loss: 0.22633373737335205
Batch 28/64 loss: 0.23046863079071045
Batch 29/64 loss: 0.22142541408538818
Batch 30/64 loss: 0.2284843921661377
Batch 31/64 loss: 0.23614108562469482
Batch 32/64 loss: 0.23102009296417236
Batch 33/64 loss: 0.24558591842651367
Batch 34/64 loss: 0.22339200973510742
Batch 35/64 loss: 0.23194313049316406
Batch 36/64 loss: 0.23251372575759888
Batch 37/64 loss: 0.23058760166168213
Batch 38/64 loss: 0.24178731441497803
Batch 39/64 loss: 0.2322879433631897
Batch 40/64 loss: 0.23546767234802246
Batch 41/64 loss: 0.22965073585510254
Batch 42/64 loss: 0.23631978034973145
Batch 43/64 loss: 0.22405743598937988
Batch 44/64 loss: 0.2467581033706665
Batch 45/64 loss: 0.23713421821594238
Batch 46/64 loss: 0.2310953140258789
Batch 47/64 loss: 0.23023170232772827
Batch 48/64 loss: 0.23101353645324707
Batch 49/64 loss: 0.23161083459854126
Batch 50/64 loss: 0.2288196086883545
Batch 51/64 loss: 0.22954213619232178
Batch 52/64 loss: 0.22396516799926758
Batch 53/64 loss: 0.23571807146072388
Batch 54/64 loss: 0.2379809021949768
Batch 55/64 loss: 0.22720849514007568
Batch 56/64 loss: 0.22563719749450684
Batch 57/64 loss: 0.22974175214767456
Batch 58/64 loss: 0.2331925630569458
Batch 59/64 loss: 0.2281211018562317
Batch 60/64 loss: 0.23272109031677246
Batch 61/64 loss: 0.23253130912780762
Batch 62/64 loss: 0.2309468388557434
Batch 63/64 loss: 0.22324120998382568
Batch 64/64 loss: 0.23754405975341797
Epoch 428  Train loss: 0.23050955510606952  Val loss: 0.2841508646601254
Epoch 429
-------------------------------
Batch 1/64 loss: 0.22724401950836182
Batch 2/64 loss: 0.23197078704833984
Batch 3/64 loss: 0.22398698329925537
Batch 4/64 loss: 0.24796158075332642
Batch 5/64 loss: 0.24598562717437744
Batch 6/64 loss: 0.23161625862121582
Batch 7/64 loss: 0.22939682006835938
Batch 8/64 loss: 0.23513472080230713
Batch 9/64 loss: 0.23502981662750244
Batch 10/64 loss: 0.22576874494552612
Batch 11/64 loss: 0.22418594360351562
Batch 12/64 loss: 0.23206549882888794
Batch 13/64 loss: 0.22400188446044922
Batch 14/64 loss: 0.22476661205291748
Batch 15/64 loss: 0.23024415969848633
Batch 16/64 loss: 0.23317259550094604
Batch 17/64 loss: 0.23060429096221924
Batch 18/64 loss: 0.22356528043746948
Batch 19/64 loss: 0.22278720140457153
Batch 20/64 loss: 0.2310962677001953
Batch 21/64 loss: 0.23351550102233887
Batch 22/64 loss: 0.22864389419555664
Batch 23/64 loss: 0.22816181182861328
Batch 24/64 loss: 0.22499334812164307
Batch 25/64 loss: 0.23431521654129028
Batch 26/64 loss: 0.22500395774841309
Batch 27/64 loss: 0.22203350067138672
Batch 28/64 loss: 0.22124826908111572
Batch 29/64 loss: 0.22618365287780762
Batch 30/64 loss: 0.23821043968200684
Batch 31/64 loss: 0.22544217109680176
Batch 32/64 loss: 0.22394603490829468
Batch 33/64 loss: 0.23262715339660645
Batch 34/64 loss: 0.23379242420196533
Batch 35/64 loss: 0.2293757200241089
Batch 36/64 loss: 0.2409105896949768
Batch 37/64 loss: 0.2385038137435913
Batch 38/64 loss: 0.2324737310409546
Batch 39/64 loss: 0.22199761867523193
Batch 40/64 loss: 0.2361588478088379
Batch 41/64 loss: 0.2380678653717041
Batch 42/64 loss: 0.23172813653945923
Batch 43/64 loss: 0.23327457904815674
Batch 44/64 loss: 0.22462892532348633
Batch 45/64 loss: 0.23412662744522095
Batch 46/64 loss: 0.22735893726348877
Batch 47/64 loss: 0.23576772212982178
Batch 48/64 loss: 0.22916913032531738
Batch 49/64 loss: 0.24789822101593018
Batch 50/64 loss: 0.23634159564971924
Batch 51/64 loss: 0.22359633445739746
Batch 52/64 loss: 0.23568105697631836
Batch 53/64 loss: 0.22664332389831543
Batch 54/64 loss: 0.23807883262634277
Batch 55/64 loss: 0.25213325023651123
Batch 56/64 loss: 0.2266213297843933
Batch 57/64 loss: 0.2423490285873413
Batch 58/64 loss: 0.22704768180847168
Batch 59/64 loss: 0.22578132152557373
Batch 60/64 loss: 0.22539961338043213
Batch 61/64 loss: 0.22956496477127075
Batch 62/64 loss: 0.22909927368164062
Batch 63/64 loss: 0.2279578447341919
Batch 64/64 loss: 0.2390550971031189
Epoch 429  Train loss: 0.23114870132184495  Val loss: 0.281978613732197
Epoch 430
-------------------------------
Batch 1/64 loss: 0.22112548351287842
Batch 2/64 loss: 0.23257815837860107
Batch 3/64 loss: 0.22038590908050537
Batch 4/64 loss: 0.22590899467468262
Batch 5/64 loss: 0.241491436958313
Batch 6/64 loss: 0.23412543535232544
Batch 7/64 loss: 0.2278439998626709
Batch 8/64 loss: 0.22657865285873413
Batch 9/64 loss: 0.2341163158416748
Batch 10/64 loss: 0.23298341035842896
Batch 11/64 loss: 0.22559821605682373
Batch 12/64 loss: 0.24529653787612915
Batch 13/64 loss: 0.22356104850769043
Batch 14/64 loss: 0.22649872303009033
Batch 15/64 loss: 0.23261141777038574
Batch 16/64 loss: 0.2281125783920288
Batch 17/64 loss: 0.235662579536438
Batch 18/64 loss: 0.2448056936264038
Batch 19/64 loss: 0.23232674598693848
Batch 20/64 loss: 0.2249801754951477
Batch 21/64 loss: 0.22192835807800293
Batch 22/64 loss: 0.2376110553741455
Batch 23/64 loss: 0.22711026668548584
Batch 24/64 loss: 0.24088072776794434
Batch 25/64 loss: 0.23315751552581787
Batch 26/64 loss: 0.24281412363052368
Batch 27/64 loss: 0.23296833038330078
Batch 28/64 loss: 0.2406766414642334
Batch 29/64 loss: 0.22807669639587402
Batch 30/64 loss: 0.22991019487380981
Batch 31/64 loss: 0.22734487056732178
Batch 32/64 loss: 0.23989105224609375
Batch 33/64 loss: 0.23943960666656494
Batch 34/64 loss: 0.23345255851745605
Batch 35/64 loss: 0.23470371961593628
Batch 36/64 loss: 0.2482898235321045
Batch 37/64 loss: 0.22597813606262207
Batch 38/64 loss: 0.23011994361877441
Batch 39/64 loss: 0.22939997911453247
Batch 40/64 loss: 0.2363835573196411
Batch 41/64 loss: 0.2289026975631714
Batch 42/64 loss: 0.2394329309463501
Batch 43/64 loss: 0.23566925525665283
Batch 44/64 loss: 0.23340654373168945
Batch 45/64 loss: 0.2202097773551941
Batch 46/64 loss: 0.22511184215545654
Batch 47/64 loss: 0.22804999351501465
Batch 48/64 loss: 0.23267453908920288
Batch 49/64 loss: 0.22726058959960938
Batch 50/64 loss: 0.22834700345993042
Batch 51/64 loss: 0.22824609279632568
Batch 52/64 loss: 0.23303771018981934
Batch 53/64 loss: 0.2301924228668213
Batch 54/64 loss: 0.23453372716903687
Batch 55/64 loss: 0.2283492088317871
Batch 56/64 loss: 0.22546136379241943
Batch 57/64 loss: 0.22788310050964355
Batch 58/64 loss: 0.23228609561920166
Batch 59/64 loss: 0.23862498998641968
Batch 60/64 loss: 0.2187764048576355
Batch 61/64 loss: 0.24184417724609375
Batch 62/64 loss: 0.22329944372177124
Batch 63/64 loss: 0.2286694049835205
Batch 64/64 loss: 0.2205105423927307
Epoch 430  Train loss: 0.23140989635504927  Val loss: 0.2818879040655811
Epoch 431
-------------------------------
Batch 1/64 loss: 0.22350889444351196
Batch 2/64 loss: 0.22784268856048584
Batch 3/64 loss: 0.2390473484992981
Batch 4/64 loss: 0.22160840034484863
Batch 5/64 loss: 0.22322052717208862
Batch 6/64 loss: 0.22592401504516602
Batch 7/64 loss: 0.22438853979110718
Batch 8/64 loss: 0.23559081554412842
Batch 9/64 loss: 0.21871066093444824
Batch 10/64 loss: 0.2266269326210022
Batch 11/64 loss: 0.2306586503982544
Batch 12/64 loss: 0.22531408071517944
Batch 13/64 loss: 0.2340404987335205
Batch 14/64 loss: 0.21843695640563965
Batch 15/64 loss: 0.22376000881195068
Batch 16/64 loss: 0.23900556564331055
Batch 17/64 loss: 0.23470377922058105
Batch 18/64 loss: 0.22639083862304688
Batch 19/64 loss: 0.22806328535079956
Batch 20/64 loss: 0.22383904457092285
Batch 21/64 loss: 0.2309049367904663
Batch 22/64 loss: 0.23165816068649292
Batch 23/64 loss: 0.23489665985107422
Batch 24/64 loss: 0.22184467315673828
Batch 25/64 loss: 0.2280128002166748
Batch 26/64 loss: 0.23215341567993164
Batch 27/64 loss: 0.22693485021591187
Batch 28/64 loss: 0.2320694923400879
Batch 29/64 loss: 0.23299437761306763
Batch 30/64 loss: 0.2331829071044922
Batch 31/64 loss: 0.22737008333206177
Batch 32/64 loss: 0.2381429672241211
Batch 33/64 loss: 0.239571213722229
Batch 34/64 loss: 0.23146194219589233
Batch 35/64 loss: 0.2355194091796875
Batch 36/64 loss: 0.22957932949066162
Batch 37/64 loss: 0.2267143726348877
Batch 38/64 loss: 0.23273849487304688
Batch 39/64 loss: 0.23776376247406006
Batch 40/64 loss: 0.23253190517425537
Batch 41/64 loss: 0.22282010316848755
Batch 42/64 loss: 0.2229769229888916
Batch 43/64 loss: 0.23634237051010132
Batch 44/64 loss: 0.22504013776779175
Batch 45/64 loss: 0.23531609773635864
Batch 46/64 loss: 0.22401893138885498
Batch 47/64 loss: 0.24100762605667114
Batch 48/64 loss: 0.23401230573654175
Batch 49/64 loss: 0.22839879989624023
Batch 50/64 loss: 0.2334350347518921
Batch 51/64 loss: 0.2270638346672058
Batch 52/64 loss: 0.22837036848068237
Batch 53/64 loss: 0.23783814907073975
Batch 54/64 loss: 0.23392200469970703
Batch 55/64 loss: 0.22522354125976562
Batch 56/64 loss: 0.22108179330825806
Batch 57/64 loss: 0.24024856090545654
Batch 58/64 loss: 0.2359752058982849
Batch 59/64 loss: 0.23854196071624756
Batch 60/64 loss: 0.24391496181488037
Batch 61/64 loss: 0.22403842210769653
Batch 62/64 loss: 0.2346387505531311
Batch 63/64 loss: 0.23833054304122925
Batch 64/64 loss: 0.21999335289001465
Epoch 431  Train loss: 0.2303416270835727  Val loss: 0.2815288155758913
Epoch 432
-------------------------------
Batch 1/64 loss: 0.2135182023048401
Batch 2/64 loss: 0.22862470149993896
Batch 3/64 loss: 0.2370222806930542
Batch 4/64 loss: 0.23029720783233643
Batch 5/64 loss: 0.2258414626121521
Batch 6/64 loss: 0.23042964935302734
Batch 7/64 loss: 0.2360209822654724
Batch 8/64 loss: 0.21743357181549072
Batch 9/64 loss: 0.2246410846710205
Batch 10/64 loss: 0.2337557077407837
Batch 11/64 loss: 0.22183281183242798
Batch 12/64 loss: 0.21336233615875244
Batch 13/64 loss: 0.23655343055725098
Batch 14/64 loss: 0.22354084253311157
Batch 15/64 loss: 0.22085899114608765
Batch 16/64 loss: 0.23077726364135742
Batch 17/64 loss: 0.23339903354644775
Batch 18/64 loss: 0.2190234661102295
Batch 19/64 loss: 0.22974979877471924
Batch 20/64 loss: 0.23869383335113525
Batch 21/64 loss: 0.22562730312347412
Batch 22/64 loss: 0.24331879615783691
Batch 23/64 loss: 0.24113011360168457
Batch 24/64 loss: 0.22596323490142822
Batch 25/64 loss: 0.23125910758972168
Batch 26/64 loss: 0.22547608613967896
Batch 27/64 loss: 0.23185956478118896
Batch 28/64 loss: 0.2459099292755127
Batch 29/64 loss: 0.22784292697906494
Batch 30/64 loss: 0.24582433700561523
Batch 31/64 loss: 0.2286677360534668
Batch 32/64 loss: 0.22333842515945435
Batch 33/64 loss: 0.23332202434539795
Batch 34/64 loss: 0.23621785640716553
Batch 35/64 loss: 0.232191801071167
Batch 36/64 loss: 0.23967671394348145
Batch 37/64 loss: 0.23699438571929932
Batch 38/64 loss: 0.2292957305908203
Batch 39/64 loss: 0.22890770435333252
Batch 40/64 loss: 0.24730545282363892
Batch 41/64 loss: 0.23192834854125977
Batch 42/64 loss: 0.22571277618408203
Batch 43/64 loss: 0.22686612606048584
Batch 44/64 loss: 0.22912812232971191
Batch 45/64 loss: 0.22958916425704956
Batch 46/64 loss: 0.22031307220458984
Batch 47/64 loss: 0.22367078065872192
Batch 48/64 loss: 0.22293412685394287
Batch 49/64 loss: 0.2339954376220703
Batch 50/64 loss: 0.23144066333770752
Batch 51/64 loss: 0.225530743598938
Batch 52/64 loss: 0.24228614568710327
Batch 53/64 loss: 0.22707253694534302
Batch 54/64 loss: 0.23403573036193848
Batch 55/64 loss: 0.23878097534179688
Batch 56/64 loss: 0.22928833961486816
Batch 57/64 loss: 0.2289922833442688
Batch 58/64 loss: 0.23467445373535156
Batch 59/64 loss: 0.21549010276794434
Batch 60/64 loss: 0.23166215419769287
Batch 61/64 loss: 0.2295539379119873
Batch 62/64 loss: 0.22252339124679565
Batch 63/64 loss: 0.2312372326850891
Batch 64/64 loss: 0.2427201271057129
Epoch 432  Train loss: 0.23018435496909945  Val loss: 0.28175185513250606
Epoch 433
-------------------------------
Batch 1/64 loss: 0.22527992725372314
Batch 2/64 loss: 0.22695612907409668
Batch 3/64 loss: 0.2472095489501953
Batch 4/64 loss: 0.22272831201553345
Batch 5/64 loss: 0.21957910060882568
Batch 6/64 loss: 0.22688305377960205
Batch 7/64 loss: 0.23966670036315918
Batch 8/64 loss: 0.24276304244995117
Batch 9/64 loss: 0.226096510887146
Batch 10/64 loss: 0.23794740438461304
Batch 11/64 loss: 0.22852712869644165
Batch 12/64 loss: 0.23151946067810059
Batch 13/64 loss: 0.2322523593902588
Batch 14/64 loss: 0.23159116506576538
Batch 15/64 loss: 0.23596733808517456
Batch 16/64 loss: 0.22107446193695068
Batch 17/64 loss: 0.23176831007003784
Batch 18/64 loss: 0.22704285383224487
Batch 19/64 loss: 0.21742945909500122
Batch 20/64 loss: 0.2215414047241211
Batch 21/64 loss: 0.23440438508987427
Batch 22/64 loss: 0.2264573574066162
Batch 23/64 loss: 0.2384585738182068
Batch 24/64 loss: 0.23107105493545532
Batch 25/64 loss: 0.2269781231880188
Batch 26/64 loss: 0.2298753261566162
Batch 27/64 loss: 0.22898900508880615
Batch 28/64 loss: 0.24962198734283447
Batch 29/64 loss: 0.23114216327667236
Batch 30/64 loss: 0.2263798713684082
Batch 31/64 loss: 0.23311924934387207
Batch 32/64 loss: 0.22248929738998413
Batch 33/64 loss: 0.23413503170013428
Batch 34/64 loss: 0.22507715225219727
Batch 35/64 loss: 0.23095238208770752
Batch 36/64 loss: 0.21705877780914307
Batch 37/64 loss: 0.24253171682357788
Batch 38/64 loss: 0.23074907064437866
Batch 39/64 loss: 0.2270578145980835
Batch 40/64 loss: 0.23588746786117554
Batch 41/64 loss: 0.21892261505126953
Batch 42/64 loss: 0.22665202617645264
Batch 43/64 loss: 0.23637962341308594
Batch 44/64 loss: 0.2353959083557129
Batch 45/64 loss: 0.22626638412475586
Batch 46/64 loss: 0.23114442825317383
Batch 47/64 loss: 0.2251707911491394
Batch 48/64 loss: 0.23128384351730347
Batch 49/64 loss: 0.22818541526794434
Batch 50/64 loss: 0.23261022567749023
Batch 51/64 loss: 0.2284502387046814
Batch 52/64 loss: 0.23057258129119873
Batch 53/64 loss: 0.23495328426361084
Batch 54/64 loss: 0.23367005586624146
Batch 55/64 loss: 0.21693384647369385
Batch 56/64 loss: 0.23298746347427368
Batch 57/64 loss: 0.23368620872497559
Batch 58/64 loss: 0.22851932048797607
Batch 59/64 loss: 0.22859174013137817
Batch 60/64 loss: 0.2284071445465088
Batch 61/64 loss: 0.23278915882110596
Batch 62/64 loss: 0.23006129264831543
Batch 63/64 loss: 0.23361098766326904
Batch 64/64 loss: 0.24309998750686646
Epoch 433  Train loss: 0.23033457339978686  Val loss: 0.28215368097180765
Epoch 434
-------------------------------
Batch 1/64 loss: 0.23172438144683838
Batch 2/64 loss: 0.2272576093673706
Batch 3/64 loss: 0.22895920276641846
Batch 4/64 loss: 0.21784913539886475
Batch 5/64 loss: 0.2336919903755188
Batch 6/64 loss: 0.22830164432525635
Batch 7/64 loss: 0.2230081558227539
Batch 8/64 loss: 0.2189997434616089
Batch 9/64 loss: 0.22677010297775269
Batch 10/64 loss: 0.23578906059265137
Batch 11/64 loss: 0.23646461963653564
Batch 12/64 loss: 0.22858166694641113
Batch 13/64 loss: 0.23286521434783936
Batch 14/64 loss: 0.23001891374588013
Batch 15/64 loss: 0.22769498825073242
Batch 16/64 loss: 0.23389720916748047
Batch 17/64 loss: 0.22222214937210083
Batch 18/64 loss: 0.22514861822128296
Batch 19/64 loss: 0.23129785060882568
Batch 20/64 loss: 0.2298908829689026
Batch 21/64 loss: 0.2322601079940796
Batch 22/64 loss: 0.22351694107055664
Batch 23/64 loss: 0.2449691891670227
Batch 24/64 loss: 0.23780930042266846
Batch 25/64 loss: 0.23357635736465454
Batch 26/64 loss: 0.2203536033630371
Batch 27/64 loss: 0.22367024421691895
Batch 28/64 loss: 0.2270066738128662
Batch 29/64 loss: 0.2349187135696411
Batch 30/64 loss: 0.24054884910583496
Batch 31/64 loss: 0.2307719588279724
Batch 32/64 loss: 0.22884654998779297
Batch 33/64 loss: 0.22692692279815674
Batch 34/64 loss: 0.24103033542633057
Batch 35/64 loss: 0.2284395694732666
Batch 36/64 loss: 0.23188209533691406
Batch 37/64 loss: 0.23796874284744263
Batch 38/64 loss: 0.23537737131118774
Batch 39/64 loss: 0.22520893812179565
Batch 40/64 loss: 0.21954715251922607
Batch 41/64 loss: 0.23630690574645996
Batch 42/64 loss: 0.22831100225448608
Batch 43/64 loss: 0.23857736587524414
Batch 44/64 loss: 0.22827374935150146
Batch 45/64 loss: 0.2351289987564087
Batch 46/64 loss: 0.22688394784927368
Batch 47/64 loss: 0.2315627932548523
Batch 48/64 loss: 0.22311723232269287
Batch 49/64 loss: 0.23059320449829102
Batch 50/64 loss: 0.22626721858978271
Batch 51/64 loss: 0.23023712635040283
Batch 52/64 loss: 0.2339434027671814
Batch 53/64 loss: 0.23149830102920532
Batch 54/64 loss: 0.2233213186264038
Batch 55/64 loss: 0.21923577785491943
Batch 56/64 loss: 0.23193752765655518
Batch 57/64 loss: 0.2343481183052063
Batch 58/64 loss: 0.24301636219024658
Batch 59/64 loss: 0.23599684238433838
Batch 60/64 loss: 0.23289358615875244
Batch 61/64 loss: 0.2270401120185852
Batch 62/64 loss: 0.23844683170318604
Batch 63/64 loss: 0.23644936084747314
Batch 64/64 loss: 0.22970259189605713
Epoch 434  Train loss: 0.23044277312708836  Val loss: 0.28056702499127467
Epoch 435
-------------------------------
Batch 1/64 loss: 0.22924339771270752
Batch 2/64 loss: 0.21868693828582764
Batch 3/64 loss: 0.2288743257522583
Batch 4/64 loss: 0.22767019271850586
Batch 5/64 loss: 0.2293628454208374
Batch 6/64 loss: 0.22635430097579956
Batch 7/64 loss: 0.2381284236907959
Batch 8/64 loss: 0.22351276874542236
Batch 9/64 loss: 0.22344058752059937
Batch 10/64 loss: 0.2379685640335083
Batch 11/64 loss: 0.23318934440612793
Batch 12/64 loss: 0.22718393802642822
Batch 13/64 loss: 0.2308027744293213
Batch 14/64 loss: 0.22946739196777344
Batch 15/64 loss: 0.23149633407592773
Batch 16/64 loss: 0.23021149635314941
Batch 17/64 loss: 0.24245387315750122
Batch 18/64 loss: 0.2245466113090515
Batch 19/64 loss: 0.22203224897384644
Batch 20/64 loss: 0.224295973777771
Batch 21/64 loss: 0.2298058271408081
Batch 22/64 loss: 0.2313631772994995
Batch 23/64 loss: 0.22275662422180176
Batch 24/64 loss: 0.23547083139419556
Batch 25/64 loss: 0.21771013736724854
Batch 26/64 loss: 0.22840988636016846
Batch 27/64 loss: 0.23165535926818848
Batch 28/64 loss: 0.22246086597442627
Batch 29/64 loss: 0.22752249240875244
Batch 30/64 loss: 0.23524397611618042
Batch 31/64 loss: 0.23012834787368774
Batch 32/64 loss: 0.2307569980621338
Batch 33/64 loss: 0.23782896995544434
Batch 34/64 loss: 0.22019273042678833
Batch 35/64 loss: 0.23935115337371826
Batch 36/64 loss: 0.22476136684417725
Batch 37/64 loss: 0.2338728904724121
Batch 38/64 loss: 0.22507941722869873
Batch 39/64 loss: 0.2195875644683838
Batch 40/64 loss: 0.22035610675811768
Batch 41/64 loss: 0.22469818592071533
Batch 42/64 loss: 0.24192047119140625
Batch 43/64 loss: 0.22285020351409912
Batch 44/64 loss: 0.22559255361557007
Batch 45/64 loss: 0.23347711563110352
Batch 46/64 loss: 0.24376946687698364
Batch 47/64 loss: 0.22899025678634644
Batch 48/64 loss: 0.22945058345794678
Batch 49/64 loss: 0.22908353805541992
Batch 50/64 loss: 0.2344754934310913
Batch 51/64 loss: 0.22681528329849243
Batch 52/64 loss: 0.23019510507583618
Batch 53/64 loss: 0.24043631553649902
Batch 54/64 loss: 0.22786539793014526
Batch 55/64 loss: 0.22033840417861938
Batch 56/64 loss: 0.2294939160346985
Batch 57/64 loss: 0.23553478717803955
Batch 58/64 loss: 0.23452746868133545
Batch 59/64 loss: 0.23314636945724487
Batch 60/64 loss: 0.24341118335723877
Batch 61/64 loss: 0.23263394832611084
Batch 62/64 loss: 0.23318982124328613
Batch 63/64 loss: 0.23965895175933838
Batch 64/64 loss: 0.23711764812469482
Epoch 435  Train loss: 0.2300020409565346  Val loss: 0.2807213070056692
Epoch 436
-------------------------------
Batch 1/64 loss: 0.22972917556762695
Batch 2/64 loss: 0.230621337890625
Batch 3/64 loss: 0.23395061492919922
Batch 4/64 loss: 0.2368605136871338
Batch 5/64 loss: 0.23089277744293213
Batch 6/64 loss: 0.22550344467163086
Batch 7/64 loss: 0.22771596908569336
Batch 8/64 loss: 0.22437632083892822
Batch 9/64 loss: 0.2206054925918579
Batch 10/64 loss: 0.23305046558380127
Batch 11/64 loss: 0.23065221309661865
Batch 12/64 loss: 0.2338700294494629
Batch 13/64 loss: 0.229638934135437
Batch 14/64 loss: 0.2298293113708496
Batch 15/64 loss: 0.22959530353546143
Batch 16/64 loss: 0.22135305404663086
Batch 17/64 loss: 0.23914802074432373
Batch 18/64 loss: 0.2454201579093933
Batch 19/64 loss: 0.23530536890029907
Batch 20/64 loss: 0.23351794481277466
Batch 21/64 loss: 0.22560489177703857
Batch 22/64 loss: 0.224351704120636
Batch 23/64 loss: 0.22192639112472534
Batch 24/64 loss: 0.22251534461975098
Batch 25/64 loss: 0.23669493198394775
Batch 26/64 loss: 0.2275407314300537
Batch 27/64 loss: 0.235107421875
Batch 28/64 loss: 0.23525846004486084
Batch 29/64 loss: 0.2294520139694214
Batch 30/64 loss: 0.23031085729599
Batch 31/64 loss: 0.23603570461273193
Batch 32/64 loss: 0.22299492359161377
Batch 33/64 loss: 0.23815715312957764
Batch 34/64 loss: 0.24021798372268677
Batch 35/64 loss: 0.23544740676879883
Batch 36/64 loss: 0.21802383661270142
Batch 37/64 loss: 0.2242264747619629
Batch 38/64 loss: 0.22362244129180908
Batch 39/64 loss: 0.24033617973327637
Batch 40/64 loss: 0.22487282752990723
Batch 41/64 loss: 0.2356090545654297
Batch 42/64 loss: 0.23100340366363525
Batch 43/64 loss: 0.22403234243392944
Batch 44/64 loss: 0.2329978346824646
Batch 45/64 loss: 0.2242347002029419
Batch 46/64 loss: 0.23214632272720337
Batch 47/64 loss: 0.2290194034576416
Batch 48/64 loss: 0.22278892993927002
Batch 49/64 loss: 0.23681706190109253
Batch 50/64 loss: 0.22935259342193604
Batch 51/64 loss: 0.22644728422164917
Batch 52/64 loss: 0.22647947072982788
Batch 53/64 loss: 0.2262539267539978
Batch 54/64 loss: 0.23072314262390137
Batch 55/64 loss: 0.23524123430252075
Batch 56/64 loss: 0.22031962871551514
Batch 57/64 loss: 0.22948318719863892
Batch 58/64 loss: 0.23422890901565552
Batch 59/64 loss: 0.23080140352249146
Batch 60/64 loss: 0.23354077339172363
Batch 61/64 loss: 0.23743176460266113
Batch 62/64 loss: 0.22299212217330933
Batch 63/64 loss: 0.21787655353546143
Batch 64/64 loss: 0.21972274780273438
Epoch 436  Train loss: 0.22978740766936656  Val loss: 0.28215198254667195
Epoch 437
-------------------------------
Batch 1/64 loss: 0.22908616065979004
Batch 2/64 loss: 0.2287769317626953
Batch 3/64 loss: 0.21832847595214844
Batch 4/64 loss: 0.22306334972381592
Batch 5/64 loss: 0.2315232753753662
Batch 6/64 loss: 0.24056220054626465
Batch 7/64 loss: 0.23021280765533447
Batch 8/64 loss: 0.2297104001045227
Batch 9/64 loss: 0.2315448522567749
Batch 10/64 loss: 0.23125529289245605
Batch 11/64 loss: 0.23282098770141602
Batch 12/64 loss: 0.23332256078720093
Batch 13/64 loss: 0.2339223027229309
Batch 14/64 loss: 0.24621903896331787
Batch 15/64 loss: 0.22833144664764404
Batch 16/64 loss: 0.22179746627807617
Batch 17/64 loss: 0.22867679595947266
Batch 18/64 loss: 0.2329450249671936
Batch 19/64 loss: 0.22568893432617188
Batch 20/64 loss: 0.243843674659729
Batch 21/64 loss: 0.22957193851470947
Batch 22/64 loss: 0.22214901447296143
Batch 23/64 loss: 0.23162376880645752
Batch 24/64 loss: 0.22156673669815063
Batch 25/64 loss: 0.22471284866333008
Batch 26/64 loss: 0.2349298596382141
Batch 27/64 loss: 0.2286158800125122
Batch 28/64 loss: 0.23106175661087036
Batch 29/64 loss: 0.22819310426712036
Batch 30/64 loss: 0.22151339054107666
Batch 31/64 loss: 0.22662568092346191
Batch 32/64 loss: 0.22097712755203247
Batch 33/64 loss: 0.22339248657226562
Batch 34/64 loss: 0.23297417163848877
Batch 35/64 loss: 0.23310428857803345
Batch 36/64 loss: 0.22543299198150635
Batch 37/64 loss: 0.22666066884994507
Batch 38/64 loss: 0.22283780574798584
Batch 39/64 loss: 0.23035740852355957
Batch 40/64 loss: 0.2286067008972168
Batch 41/64 loss: 0.23263859748840332
Batch 42/64 loss: 0.23183512687683105
Batch 43/64 loss: 0.23185330629348755
Batch 44/64 loss: 0.2295459508895874
Batch 45/64 loss: 0.23254668712615967
Batch 46/64 loss: 0.22898882627487183
Batch 47/64 loss: 0.22511601448059082
Batch 48/64 loss: 0.21958422660827637
Batch 49/64 loss: 0.22639071941375732
Batch 50/64 loss: 0.23861432075500488
Batch 51/64 loss: 0.2285478115081787
Batch 52/64 loss: 0.2220250964164734
Batch 53/64 loss: 0.23146265745162964
Batch 54/64 loss: 0.2322344183921814
Batch 55/64 loss: 0.23191410303115845
Batch 56/64 loss: 0.21821004152297974
Batch 57/64 loss: 0.250160813331604
Batch 58/64 loss: 0.22169721126556396
Batch 59/64 loss: 0.22718960046768188
Batch 60/64 loss: 0.23688817024230957
Batch 61/64 loss: 0.22339260578155518
Batch 62/64 loss: 0.23731422424316406
Batch 63/64 loss: 0.22670871019363403
Batch 64/64 loss: 0.2217116355895996
Epoch 437  Train loss: 0.22929698158712947  Val loss: 0.2821398299584274
Epoch 438
-------------------------------
Batch 1/64 loss: 0.2386767864227295
Batch 2/64 loss: 0.22501766681671143
Batch 3/64 loss: 0.2259775996208191
Batch 4/64 loss: 0.243880033493042
Batch 5/64 loss: 0.2279413938522339
Batch 6/64 loss: 0.21779298782348633
Batch 7/64 loss: 0.22426235675811768
Batch 8/64 loss: 0.22312307357788086
Batch 9/64 loss: 0.22164654731750488
Batch 10/64 loss: 0.22795134782791138
Batch 11/64 loss: 0.2282785177230835
Batch 12/64 loss: 0.2343190312385559
Batch 13/64 loss: 0.2249058485031128
Batch 14/64 loss: 0.23133480548858643
Batch 15/64 loss: 0.2387779951095581
Batch 16/64 loss: 0.21849191188812256
Batch 17/64 loss: 0.22638046741485596
Batch 18/64 loss: 0.228221595287323
Batch 19/64 loss: 0.22936367988586426
Batch 20/64 loss: 0.23022300004959106
Batch 21/64 loss: 0.2291504144668579
Batch 22/64 loss: 0.22762799263000488
Batch 23/64 loss: 0.22125840187072754
Batch 24/64 loss: 0.24386614561080933
Batch 25/64 loss: 0.23328536748886108
Batch 26/64 loss: 0.23427271842956543
Batch 27/64 loss: 0.22626382112503052
Batch 28/64 loss: 0.24350684881210327
Batch 29/64 loss: 0.231769859790802
Batch 30/64 loss: 0.229087233543396
Batch 31/64 loss: 0.22504186630249023
Batch 32/64 loss: 0.22252881526947021
Batch 33/64 loss: 0.22517728805541992
Batch 34/64 loss: 0.22444254159927368
Batch 35/64 loss: 0.23372578620910645
Batch 36/64 loss: 0.24446618556976318
Batch 37/64 loss: 0.2306300401687622
Batch 38/64 loss: 0.23797690868377686
Batch 39/64 loss: 0.22682154178619385
Batch 40/64 loss: 0.22264117002487183
Batch 41/64 loss: 0.2247735857963562
Batch 42/64 loss: 0.23615562915802002
Batch 43/64 loss: 0.2379443645477295
Batch 44/64 loss: 0.2304774522781372
Batch 45/64 loss: 0.23494869470596313
Batch 46/64 loss: 0.23311984539031982
Batch 47/64 loss: 0.2261195182800293
Batch 48/64 loss: 0.22024977207183838
Batch 49/64 loss: 0.23209649324417114
Batch 50/64 loss: 0.2293207049369812
Batch 51/64 loss: 0.2299061417579651
Batch 52/64 loss: 0.23041611909866333
Batch 53/64 loss: 0.23270070552825928
Batch 54/64 loss: 0.2254154086112976
Batch 55/64 loss: 0.22542691230773926
Batch 56/64 loss: 0.23229753971099854
Batch 57/64 loss: 0.23069334030151367
Batch 58/64 loss: 0.21211278438568115
Batch 59/64 loss: 0.2272963523864746
Batch 60/64 loss: 0.237848699092865
Batch 61/64 loss: 0.22480738162994385
Batch 62/64 loss: 0.22064435482025146
Batch 63/64 loss: 0.22627389430999756
Batch 64/64 loss: 0.23422539234161377
Epoch 438  Train loss: 0.22928348756303973  Val loss: 0.28165978561971605
Epoch 439
-------------------------------
Batch 1/64 loss: 0.23833423852920532
Batch 2/64 loss: 0.22486084699630737
Batch 3/64 loss: 0.22064512968063354
Batch 4/64 loss: 0.22610580921173096
Batch 5/64 loss: 0.231398344039917
Batch 6/64 loss: 0.23416566848754883
Batch 7/64 loss: 0.22547650337219238
Batch 8/64 loss: 0.2319645881652832
Batch 9/64 loss: 0.22937482595443726
Batch 10/64 loss: 0.23079770803451538
Batch 11/64 loss: 0.22021162509918213
Batch 12/64 loss: 0.21909230947494507
Batch 13/64 loss: 0.22757494449615479
Batch 14/64 loss: 0.2361295223236084
Batch 15/64 loss: 0.21996676921844482
Batch 16/64 loss: 0.229139506816864
Batch 17/64 loss: 0.2339458465576172
Batch 18/64 loss: 0.22250396013259888
Batch 19/64 loss: 0.238835871219635
Batch 20/64 loss: 0.22490626573562622
Batch 21/64 loss: 0.228249192237854
Batch 22/64 loss: 0.2448805570602417
Batch 23/64 loss: 0.24081844091415405
Batch 24/64 loss: 0.2355526089668274
Batch 25/64 loss: 0.22431325912475586
Batch 26/64 loss: 0.23172950744628906
Batch 27/64 loss: 0.22775816917419434
Batch 28/64 loss: 0.22383910417556763
Batch 29/64 loss: 0.21903270483016968
Batch 30/64 loss: 0.22410082817077637
Batch 31/64 loss: 0.22883737087249756
Batch 32/64 loss: 0.22414642572402954
Batch 33/64 loss: 0.2341289520263672
Batch 34/64 loss: 0.22862571477890015
Batch 35/64 loss: 0.23558926582336426
Batch 36/64 loss: 0.2314673662185669
Batch 37/64 loss: 0.23850208520889282
Batch 38/64 loss: 0.22822213172912598
Batch 39/64 loss: 0.24656063318252563
Batch 40/64 loss: 0.23205780982971191
Batch 41/64 loss: 0.22463995218276978
Batch 42/64 loss: 0.2290865182876587
Batch 43/64 loss: 0.2295529842376709
Batch 44/64 loss: 0.23750174045562744
Batch 45/64 loss: 0.2290278673171997
Batch 46/64 loss: 0.22218036651611328
Batch 47/64 loss: 0.22708535194396973
Batch 48/64 loss: 0.2423229217529297
Batch 49/64 loss: 0.22854626178741455
Batch 50/64 loss: 0.22624599933624268
Batch 51/64 loss: 0.23151767253875732
Batch 52/64 loss: 0.2349259853363037
Batch 53/64 loss: 0.22722584009170532
Batch 54/64 loss: 0.22353506088256836
Batch 55/64 loss: 0.2432752251625061
Batch 56/64 loss: 0.2273256778717041
Batch 57/64 loss: 0.22134912014007568
Batch 58/64 loss: 0.2267400622367859
Batch 59/64 loss: 0.23046982288360596
Batch 60/64 loss: 0.22540903091430664
Batch 61/64 loss: 0.22578412294387817
Batch 62/64 loss: 0.2367032766342163
Batch 63/64 loss: 0.22580838203430176
Batch 64/64 loss: 0.22762054204940796
Epoch 439  Train loss: 0.2296598754677118  Val loss: 0.28176713604288
Epoch 440
-------------------------------
Batch 1/64 loss: 0.2230866551399231
Batch 2/64 loss: 0.22889935970306396
Batch 3/64 loss: 0.2284940481185913
Batch 4/64 loss: 0.2279025912284851
Batch 5/64 loss: 0.22269701957702637
Batch 6/64 loss: 0.22625106573104858
Batch 7/64 loss: 0.22621726989746094
Batch 8/64 loss: 0.22641801834106445
Batch 9/64 loss: 0.2259448766708374
Batch 10/64 loss: 0.23452800512313843
Batch 11/64 loss: 0.22939085960388184
Batch 12/64 loss: 0.23728227615356445
Batch 13/64 loss: 0.24057304859161377
Batch 14/64 loss: 0.22181320190429688
Batch 15/64 loss: 0.22222673892974854
Batch 16/64 loss: 0.2262113094329834
Batch 17/64 loss: 0.22507119178771973
Batch 18/64 loss: 0.22098112106323242
Batch 19/64 loss: 0.24539697170257568
Batch 20/64 loss: 0.23495590686798096
Batch 21/64 loss: 0.24363303184509277
Batch 22/64 loss: 0.24200528860092163
Batch 23/64 loss: 0.21931087970733643
Batch 24/64 loss: 0.2441638708114624
Batch 25/64 loss: 0.23842406272888184
Batch 26/64 loss: 0.22137552499771118
Batch 27/64 loss: 0.24281615018844604
Batch 28/64 loss: 0.22349703311920166
Batch 29/64 loss: 0.22923076152801514
Batch 30/64 loss: 0.2274286150932312
Batch 31/64 loss: 0.22249114513397217
Batch 32/64 loss: 0.2270064353942871
Batch 33/64 loss: 0.23108750581741333
Batch 34/64 loss: 0.22796565294265747
Batch 35/64 loss: 0.22342133522033691
Batch 36/64 loss: 0.23652124404907227
Batch 37/64 loss: 0.2286127209663391
Batch 38/64 loss: 0.2319498062133789
Batch 39/64 loss: 0.2266254425048828
Batch 40/64 loss: 0.2338329553604126
Batch 41/64 loss: 0.23202741146087646
Batch 42/64 loss: 0.2263559103012085
Batch 43/64 loss: 0.23793864250183105
Batch 44/64 loss: 0.2329508662223816
Batch 45/64 loss: 0.2281581163406372
Batch 46/64 loss: 0.21903109550476074
Batch 47/64 loss: 0.21943950653076172
Batch 48/64 loss: 0.22364795207977295
Batch 49/64 loss: 0.23566967248916626
Batch 50/64 loss: 0.22645002603530884
Batch 51/64 loss: 0.2272953987121582
Batch 52/64 loss: 0.23465406894683838
Batch 53/64 loss: 0.22521865367889404
Batch 54/64 loss: 0.22193121910095215
Batch 55/64 loss: 0.22665512561798096
Batch 56/64 loss: 0.2189682126045227
Batch 57/64 loss: 0.2272154688835144
Batch 58/64 loss: 0.22608983516693115
Batch 59/64 loss: 0.22767317295074463
Batch 60/64 loss: 0.2279055118560791
Batch 61/64 loss: 0.23208749294281006
Batch 62/64 loss: 0.22537338733673096
Batch 63/64 loss: 0.23214060068130493
Batch 64/64 loss: 0.2316904067993164
Epoch 440  Train loss: 0.22908841020920698  Val loss: 0.28268212407724963
Epoch 441
-------------------------------
Batch 1/64 loss: 0.22746992111206055
Batch 2/64 loss: 0.2242494821548462
Batch 3/64 loss: 0.22580039501190186
Batch 4/64 loss: 0.22688227891921997
Batch 5/64 loss: 0.21933132410049438
Batch 6/64 loss: 0.23526382446289062
Batch 7/64 loss: 0.26089632511138916
Batch 8/64 loss: 0.22590374946594238
Batch 9/64 loss: 0.2203097939491272
Batch 10/64 loss: 0.2283230423927307
Batch 11/64 loss: 0.22677868604660034
Batch 12/64 loss: 0.23233824968338013
Batch 13/64 loss: 0.2240198850631714
Batch 14/64 loss: 0.23683381080627441
Batch 15/64 loss: 0.22289633750915527
Batch 16/64 loss: 0.23125672340393066
Batch 17/64 loss: 0.23136931657791138
Batch 18/64 loss: 0.22213798761367798
Batch 19/64 loss: 0.22990906238555908
Batch 20/64 loss: 0.23444485664367676
Batch 21/64 loss: 0.2222205400466919
Batch 22/64 loss: 0.23967236280441284
Batch 23/64 loss: 0.22840571403503418
Batch 24/64 loss: 0.22704869508743286
Batch 25/64 loss: 0.22763800621032715
Batch 26/64 loss: 0.22739684581756592
Batch 27/64 loss: 0.23720061779022217
Batch 28/64 loss: 0.2357282042503357
Batch 29/64 loss: 0.2218022346496582
Batch 30/64 loss: 0.2300039529800415
Batch 31/64 loss: 0.23022979497909546
Batch 32/64 loss: 0.22544479370117188
Batch 33/64 loss: 0.228310227394104
Batch 34/64 loss: 0.22270965576171875
Batch 35/64 loss: 0.23238033056259155
Batch 36/64 loss: 0.22429323196411133
Batch 37/64 loss: 0.22561776638031006
Batch 38/64 loss: 0.22611093521118164
Batch 39/64 loss: 0.23069614171981812
Batch 40/64 loss: 0.22123503684997559
Batch 41/64 loss: 0.23080074787139893
Batch 42/64 loss: 0.22668910026550293
Batch 43/64 loss: 0.2371259331703186
Batch 44/64 loss: 0.22151273488998413
Batch 45/64 loss: 0.2280592918395996
Batch 46/64 loss: 0.23071104288101196
Batch 47/64 loss: 0.22888082265853882
Batch 48/64 loss: 0.2249888777732849
Batch 49/64 loss: 0.22041761875152588
Batch 50/64 loss: 0.21559512615203857
Batch 51/64 loss: 0.2313673496246338
Batch 52/64 loss: 0.22420775890350342
Batch 53/64 loss: 0.22329801321029663
Batch 54/64 loss: 0.2321157455444336
Batch 55/64 loss: 0.2339450716972351
Batch 56/64 loss: 0.21905094385147095
Batch 57/64 loss: 0.2232649326324463
Batch 58/64 loss: 0.2232905626296997
Batch 59/64 loss: 0.22020506858825684
Batch 60/64 loss: 0.22266077995300293
Batch 61/64 loss: 0.23045527935028076
Batch 62/64 loss: 0.23203963041305542
Batch 63/64 loss: 0.2355770468711853
Batch 64/64 loss: 0.2361953854560852
Epoch 441  Train loss: 0.22814064563489428  Val loss: 0.28143507610891283
Epoch 442
-------------------------------
Batch 1/64 loss: 0.22637885808944702
Batch 2/64 loss: 0.22903859615325928
Batch 3/64 loss: 0.22077971696853638
Batch 4/64 loss: 0.21492981910705566
Batch 5/64 loss: 0.2242976427078247
Batch 6/64 loss: 0.2220059633255005
Batch 7/64 loss: 0.22617268562316895
Batch 8/64 loss: 0.2175612449645996
Batch 9/64 loss: 0.223494291305542
Batch 10/64 loss: 0.23355966806411743
Batch 11/64 loss: 0.2265334129333496
Batch 12/64 loss: 0.23629140853881836
Batch 13/64 loss: 0.21728718280792236
Batch 14/64 loss: 0.22512412071228027
Batch 15/64 loss: 0.22801268100738525
Batch 16/64 loss: 0.22794485092163086
Batch 17/64 loss: 0.23033177852630615
Batch 18/64 loss: 0.21574872732162476
Batch 19/64 loss: 0.23140084743499756
Batch 20/64 loss: 0.21932083368301392
Batch 21/64 loss: 0.22424346208572388
Batch 22/64 loss: 0.23148757219314575
Batch 23/64 loss: 0.24140411615371704
Batch 24/64 loss: 0.22443634271621704
Batch 25/64 loss: 0.22156298160552979
Batch 26/64 loss: 0.2415897250175476
Batch 27/64 loss: 0.23461878299713135
Batch 28/64 loss: 0.2375943660736084
Batch 29/64 loss: 0.23319852352142334
Batch 30/64 loss: 0.226651132106781
Batch 31/64 loss: 0.2217400074005127
Batch 32/64 loss: 0.23774981498718262
Batch 33/64 loss: 0.2244875431060791
Batch 34/64 loss: 0.22786498069763184
Batch 35/64 loss: 0.22864985466003418
Batch 36/64 loss: 0.2266964316368103
Batch 37/64 loss: 0.23048532009124756
Batch 38/64 loss: 0.23031532764434814
Batch 39/64 loss: 0.22977745532989502
Batch 40/64 loss: 0.22843945026397705
Batch 41/64 loss: 0.2372732162475586
Batch 42/64 loss: 0.22723174095153809
Batch 43/64 loss: 0.240120530128479
Batch 44/64 loss: 0.2285841703414917
Batch 45/64 loss: 0.23502492904663086
Batch 46/64 loss: 0.22835206985473633
Batch 47/64 loss: 0.23172903060913086
Batch 48/64 loss: 0.21974825859069824
Batch 49/64 loss: 0.22797870635986328
Batch 50/64 loss: 0.23968183994293213
Batch 51/64 loss: 0.22365468740463257
Batch 52/64 loss: 0.23385179042816162
Batch 53/64 loss: 0.236153244972229
Batch 54/64 loss: 0.22656071186065674
Batch 55/64 loss: 0.21966242790222168
Batch 56/64 loss: 0.2246587872505188
Batch 57/64 loss: 0.23049205541610718
Batch 58/64 loss: 0.23910152912139893
Batch 59/64 loss: 0.23505771160125732
Batch 60/64 loss: 0.22382009029388428
Batch 61/64 loss: 0.23009127378463745
Batch 62/64 loss: 0.22444427013397217
Batch 63/64 loss: 0.23978519439697266
Batch 64/64 loss: 0.2282395362854004
Epoch 442  Train loss: 0.22860306571511663  Val loss: 0.2825224164015649
Epoch 443
-------------------------------
Batch 1/64 loss: 0.23760384321212769
Batch 2/64 loss: 0.22165709733963013
Batch 3/64 loss: 0.22497326135635376
Batch 4/64 loss: 0.2248086929321289
Batch 5/64 loss: 0.22319388389587402
Batch 6/64 loss: 0.23480892181396484
Batch 7/64 loss: 0.22411930561065674
Batch 8/64 loss: 0.22685998678207397
Batch 9/64 loss: 0.22880852222442627
Batch 10/64 loss: 0.21971583366394043
Batch 11/64 loss: 0.22261559963226318
Batch 12/64 loss: 0.2243049144744873
Batch 13/64 loss: 0.23051834106445312
Batch 14/64 loss: 0.22911369800567627
Batch 15/64 loss: 0.23553884029388428
Batch 16/64 loss: 0.23201388120651245
Batch 17/64 loss: 0.22713029384613037
Batch 18/64 loss: 0.22614002227783203
Batch 19/64 loss: 0.22034019231796265
Batch 20/64 loss: 0.22213447093963623
Batch 21/64 loss: 0.23264038562774658
Batch 22/64 loss: 0.23004400730133057
Batch 23/64 loss: 0.2249995470046997
Batch 24/64 loss: 0.22249257564544678
Batch 25/64 loss: 0.2248508334159851
Batch 26/64 loss: 0.2303895354270935
Batch 27/64 loss: 0.2333967089653015
Batch 28/64 loss: 0.22696763277053833
Batch 29/64 loss: 0.22382628917694092
Batch 30/64 loss: 0.23261094093322754
Batch 31/64 loss: 0.21984964609146118
Batch 32/64 loss: 0.2205682396888733
Batch 33/64 loss: 0.2350238561630249
Batch 34/64 loss: 0.22823965549468994
Batch 35/64 loss: 0.2274482250213623
Batch 36/64 loss: 0.2237757444381714
Batch 37/64 loss: 0.238006591796875
Batch 38/64 loss: 0.23636949062347412
Batch 39/64 loss: 0.23080378770828247
Batch 40/64 loss: 0.2337358593940735
Batch 41/64 loss: 0.225813627243042
Batch 42/64 loss: 0.2327892780303955
Batch 43/64 loss: 0.23967772722244263
Batch 44/64 loss: 0.23099064826965332
Batch 45/64 loss: 0.24054598808288574
Batch 46/64 loss: 0.2291724681854248
Batch 47/64 loss: 0.2261996865272522
Batch 48/64 loss: 0.21783983707427979
Batch 49/64 loss: 0.2324191927909851
Batch 50/64 loss: 0.22642064094543457
Batch 51/64 loss: 0.23206549882888794
Batch 52/64 loss: 0.2313166856765747
Batch 53/64 loss: 0.22963017225265503
Batch 54/64 loss: 0.23128044605255127
Batch 55/64 loss: 0.2265235185623169
Batch 56/64 loss: 0.23462486267089844
Batch 57/64 loss: 0.22940921783447266
Batch 58/64 loss: 0.2304232120513916
Batch 59/64 loss: 0.2330949902534485
Batch 60/64 loss: 0.23651909828186035
Batch 61/64 loss: 0.23099112510681152
Batch 62/64 loss: 0.2304682731628418
Batch 63/64 loss: 0.23750126361846924
Batch 64/64 loss: 0.2512162923812866
Epoch 443  Train loss: 0.22927951111513026  Val loss: 0.28203841337223645
Epoch 444
-------------------------------
Batch 1/64 loss: 0.22286832332611084
Batch 2/64 loss: 0.22694653272628784
Batch 3/64 loss: 0.2264692783355713
Batch 4/64 loss: 0.2330302596092224
Batch 5/64 loss: 0.21977484226226807
Batch 6/64 loss: 0.2206125259399414
Batch 7/64 loss: 0.23700791597366333
Batch 8/64 loss: 0.2229744791984558
Batch 9/64 loss: 0.2391139268875122
Batch 10/64 loss: 0.23915159702301025
Batch 11/64 loss: 0.22435832023620605
Batch 12/64 loss: 0.23017656803131104
Batch 13/64 loss: 0.22343432903289795
Batch 14/64 loss: 0.2376105785369873
Batch 15/64 loss: 0.22628933191299438
Batch 16/64 loss: 0.2303166389465332
Batch 17/64 loss: 0.22887909412384033
Batch 18/64 loss: 0.23499053716659546
Batch 19/64 loss: 0.23346346616744995
Batch 20/64 loss: 0.23942351341247559
Batch 21/64 loss: 0.22649234533309937
Batch 22/64 loss: 0.22440779209136963
Batch 23/64 loss: 0.22241371870040894
Batch 24/64 loss: 0.22238516807556152
Batch 25/64 loss: 0.2272343635559082
Batch 26/64 loss: 0.2283039093017578
Batch 27/64 loss: 0.2394043207168579
Batch 28/64 loss: 0.22862166166305542
Batch 29/64 loss: 0.22584378719329834
Batch 30/64 loss: 0.22036206722259521
Batch 31/64 loss: 0.23848533630371094
Batch 32/64 loss: 0.23520523309707642
Batch 33/64 loss: 0.22069895267486572
Batch 34/64 loss: 0.23530304431915283
Batch 35/64 loss: 0.2244420051574707
Batch 36/64 loss: 0.2339848279953003
Batch 37/64 loss: 0.22495687007904053
Batch 38/64 loss: 0.22584712505340576
Batch 39/64 loss: 0.22289633750915527
Batch 40/64 loss: 0.2353435754776001
Batch 41/64 loss: 0.22364425659179688
Batch 42/64 loss: 0.24101781845092773
Batch 43/64 loss: 0.24205046892166138
Batch 44/64 loss: 0.22386252880096436
Batch 45/64 loss: 0.22350800037384033
Batch 46/64 loss: 0.24336349964141846
Batch 47/64 loss: 0.23277497291564941
Batch 48/64 loss: 0.22717493772506714
Batch 49/64 loss: 0.23182255029678345
Batch 50/64 loss: 0.2352045774459839
Batch 51/64 loss: 0.22088170051574707
Batch 52/64 loss: 0.22704607248306274
Batch 53/64 loss: 0.22008466720581055
Batch 54/64 loss: 0.23248255252838135
Batch 55/64 loss: 0.2386261224746704
Batch 56/64 loss: 0.24105852842330933
Batch 57/64 loss: 0.23648780584335327
Batch 58/64 loss: 0.227378249168396
Batch 59/64 loss: 0.22033733129501343
Batch 60/64 loss: 0.22772884368896484
Batch 61/64 loss: 0.22579127550125122
Batch 62/64 loss: 0.22934186458587646
Batch 63/64 loss: 0.22687286138534546
Batch 64/64 loss: 0.23001182079315186
Epoch 444  Train loss: 0.22949921336828494  Val loss: 0.281935087798797
Epoch 445
-------------------------------
Batch 1/64 loss: 0.2453327178955078
Batch 2/64 loss: 0.22449135780334473
Batch 3/64 loss: 0.23499268293380737
Batch 4/64 loss: 0.22483313083648682
Batch 5/64 loss: 0.2193736433982849
Batch 6/64 loss: 0.22337442636489868
Batch 7/64 loss: 0.23280978202819824
Batch 8/64 loss: 0.2352890968322754
Batch 9/64 loss: 0.2245497703552246
Batch 10/64 loss: 0.2246953845024109
Batch 11/64 loss: 0.23289310932159424
Batch 12/64 loss: 0.2356046438217163
Batch 13/64 loss: 0.23955881595611572
Batch 14/64 loss: 0.2171270251274109
Batch 15/64 loss: 0.24918019771575928
Batch 16/64 loss: 0.22806227207183838
Batch 17/64 loss: 0.22464513778686523
Batch 18/64 loss: 0.22128909826278687
Batch 19/64 loss: 0.23063218593597412
Batch 20/64 loss: 0.21700632572174072
Batch 21/64 loss: 0.23273926973342896
Batch 22/64 loss: 0.22766566276550293
Batch 23/64 loss: 0.22434282302856445
Batch 24/64 loss: 0.22543001174926758
Batch 25/64 loss: 0.22443044185638428
Batch 26/64 loss: 0.2299274206161499
Batch 27/64 loss: 0.23444277048110962
Batch 28/64 loss: 0.2276754379272461
Batch 29/64 loss: 0.22861385345458984
Batch 30/64 loss: 0.2267928123474121
Batch 31/64 loss: 0.23095810413360596
Batch 32/64 loss: 0.22028475999832153
Batch 33/64 loss: 0.23386776447296143
Batch 34/64 loss: 0.23099064826965332
Batch 35/64 loss: 0.23206865787506104
Batch 36/64 loss: 0.2299438714981079
Batch 37/64 loss: 0.22942900657653809
Batch 38/64 loss: 0.22258400917053223
Batch 39/64 loss: 0.21896743774414062
Batch 40/64 loss: 0.23162418603897095
Batch 41/64 loss: 0.22880852222442627
Batch 42/64 loss: 0.22380536794662476
Batch 43/64 loss: 0.22846317291259766
Batch 44/64 loss: 0.23062491416931152
Batch 45/64 loss: 0.23965096473693848
Batch 46/64 loss: 0.2246936559677124
Batch 47/64 loss: 0.2383679747581482
Batch 48/64 loss: 0.22887945175170898
Batch 49/64 loss: 0.22855675220489502
Batch 50/64 loss: 0.2278212308883667
Batch 51/64 loss: 0.23126846551895142
Batch 52/64 loss: 0.23021191358566284
Batch 53/64 loss: 0.2217082977294922
Batch 54/64 loss: 0.2284759283065796
Batch 55/64 loss: 0.2290360927581787
Batch 56/64 loss: 0.22074323892593384
Batch 57/64 loss: 0.22844505310058594
Batch 58/64 loss: 0.23693400621414185
Batch 59/64 loss: 0.23015236854553223
Batch 60/64 loss: 0.2203143835067749
Batch 61/64 loss: 0.22595715522766113
Batch 62/64 loss: 0.21868520975112915
Batch 63/64 loss: 0.2370905876159668
Batch 64/64 loss: 0.2289867401123047
Epoch 445  Train loss: 0.2286894826328053  Val loss: 0.28200542168928583
Epoch 446
-------------------------------
Batch 1/64 loss: 0.22647690773010254
Batch 2/64 loss: 0.22725951671600342
Batch 3/64 loss: 0.24983882904052734
Batch 4/64 loss: 0.22978812456130981
Batch 5/64 loss: 0.2348085641860962
Batch 6/64 loss: 0.22423726320266724
Batch 7/64 loss: 0.2245931625366211
Batch 8/64 loss: 0.22891056537628174
Batch 9/64 loss: 0.22755175828933716
Batch 10/64 loss: 0.24266153573989868
Batch 11/64 loss: 0.22037500143051147
Batch 12/64 loss: 0.22872406244277954
Batch 13/64 loss: 0.22787988185882568
Batch 14/64 loss: 0.22670185565948486
Batch 15/64 loss: 0.22127562761306763
Batch 16/64 loss: 0.2321774959564209
Batch 17/64 loss: 0.2190845012664795
Batch 18/64 loss: 0.2251412272453308
Batch 19/64 loss: 0.22924715280532837
Batch 20/64 loss: 0.2208775281906128
Batch 21/64 loss: 0.2128995656967163
Batch 22/64 loss: 0.23303943872451782
Batch 23/64 loss: 0.23606741428375244
Batch 24/64 loss: 0.22400325536727905
Batch 25/64 loss: 0.2188594937324524
Batch 26/64 loss: 0.22731328010559082
Batch 27/64 loss: 0.23228096961975098
Batch 28/64 loss: 0.2338637113571167
Batch 29/64 loss: 0.23425984382629395
Batch 30/64 loss: 0.2272200584411621
Batch 31/64 loss: 0.22496211528778076
Batch 32/64 loss: 0.2270725965499878
Batch 33/64 loss: 0.22203612327575684
Batch 34/64 loss: 0.21850919723510742
Batch 35/64 loss: 0.22277939319610596
Batch 36/64 loss: 0.2311648726463318
Batch 37/64 loss: 0.23086684942245483
Batch 38/64 loss: 0.23103666305541992
Batch 39/64 loss: 0.22654831409454346
Batch 40/64 loss: 0.23267388343811035
Batch 41/64 loss: 0.22842013835906982
Batch 42/64 loss: 0.23087966442108154
Batch 43/64 loss: 0.23257756233215332
Batch 44/64 loss: 0.22054851055145264
Batch 45/64 loss: 0.23129332065582275
Batch 46/64 loss: 0.23021847009658813
Batch 47/64 loss: 0.2417096495628357
Batch 48/64 loss: 0.23175090551376343
Batch 49/64 loss: 0.2470209002494812
Batch 50/64 loss: 0.22434008121490479
Batch 51/64 loss: 0.23441839218139648
Batch 52/64 loss: 0.2262468934059143
Batch 53/64 loss: 0.23398548364639282
Batch 54/64 loss: 0.22801554203033447
Batch 55/64 loss: 0.24161672592163086
Batch 56/64 loss: 0.23621129989624023
Batch 57/64 loss: 0.23679673671722412
Batch 58/64 loss: 0.22549957036972046
Batch 59/64 loss: 0.23085945844650269
Batch 60/64 loss: 0.22836780548095703
Batch 61/64 loss: 0.23966997861862183
Batch 62/64 loss: 0.22488558292388916
Batch 63/64 loss: 0.22486209869384766
Batch 64/64 loss: 0.23101019859313965
Epoch 446  Train loss: 0.22931011798335058  Val loss: 0.2813152976052458
Epoch 447
-------------------------------
Batch 1/64 loss: 0.23542600870132446
Batch 2/64 loss: 0.23127973079681396
Batch 3/64 loss: 0.22955453395843506
Batch 4/64 loss: 0.22062420845031738
Batch 5/64 loss: 0.22393572330474854
Batch 6/64 loss: 0.22994601726531982
Batch 7/64 loss: 0.22646558284759521
Batch 8/64 loss: 0.23021447658538818
Batch 9/64 loss: 0.22274941205978394
Batch 10/64 loss: 0.22225451469421387
Batch 11/64 loss: 0.22500061988830566
Batch 12/64 loss: 0.21679049730300903
Batch 13/64 loss: 0.22272825241088867
Batch 14/64 loss: 0.22469067573547363
Batch 15/64 loss: 0.232060968875885
Batch 16/64 loss: 0.2315731644630432
Batch 17/64 loss: 0.2299666404724121
Batch 18/64 loss: 0.21987807750701904
Batch 19/64 loss: 0.21869200468063354
Batch 20/64 loss: 0.24066424369812012
Batch 21/64 loss: 0.23604142665863037
Batch 22/64 loss: 0.22366756200790405
Batch 23/64 loss: 0.2215869426727295
Batch 24/64 loss: 0.24170589447021484
Batch 25/64 loss: 0.2300252914428711
Batch 26/64 loss: 0.2317124605178833
Batch 27/64 loss: 0.22431105375289917
Batch 28/64 loss: 0.22246551513671875
Batch 29/64 loss: 0.2288651466369629
Batch 30/64 loss: 0.2394500970840454
Batch 31/64 loss: 0.23362624645233154
Batch 32/64 loss: 0.23202121257781982
Batch 33/64 loss: 0.23674994707107544
Batch 34/64 loss: 0.2360149621963501
Batch 35/64 loss: 0.22929489612579346
Batch 36/64 loss: 0.22943979501724243
Batch 37/64 loss: 0.22572767734527588
Batch 38/64 loss: 0.22611916065216064
Batch 39/64 loss: 0.22702455520629883
Batch 40/64 loss: 0.22141385078430176
Batch 41/64 loss: 0.2291785478591919
Batch 42/64 loss: 0.21853399276733398
Batch 43/64 loss: 0.22011327743530273
Batch 44/64 loss: 0.22538089752197266
Batch 45/64 loss: 0.23181051015853882
Batch 46/64 loss: 0.23301196098327637
Batch 47/64 loss: 0.22753119468688965
Batch 48/64 loss: 0.23076295852661133
Batch 49/64 loss: 0.22702497243881226
Batch 50/64 loss: 0.23649024963378906
Batch 51/64 loss: 0.23276352882385254
Batch 52/64 loss: 0.2264341115951538
Batch 53/64 loss: 0.2269967794418335
Batch 54/64 loss: 0.23164308071136475
Batch 55/64 loss: 0.23266732692718506
Batch 56/64 loss: 0.2417677640914917
Batch 57/64 loss: 0.22857606410980225
Batch 58/64 loss: 0.23017793893814087
Batch 59/64 loss: 0.23543918132781982
Batch 60/64 loss: 0.22631895542144775
Batch 61/64 loss: 0.2368701696395874
Batch 62/64 loss: 0.22282981872558594
Batch 63/64 loss: 0.23258310556411743
Batch 64/64 loss: 0.22620081901550293
Epoch 447  Train loss: 0.228804957632925  Val loss: 0.28228280429577907
Epoch 448
-------------------------------
Batch 1/64 loss: 0.24180662631988525
Batch 2/64 loss: 0.2241758108139038
Batch 3/64 loss: 0.2339422106742859
Batch 4/64 loss: 0.23492610454559326
Batch 5/64 loss: 0.23096060752868652
Batch 6/64 loss: 0.22466033697128296
Batch 7/64 loss: 0.22234296798706055
Batch 8/64 loss: 0.22610712051391602
Batch 9/64 loss: 0.22665637731552124
Batch 10/64 loss: 0.22070682048797607
Batch 11/64 loss: 0.23534953594207764
Batch 12/64 loss: 0.23990899324417114
Batch 13/64 loss: 0.22990751266479492
Batch 14/64 loss: 0.23241198062896729
Batch 15/64 loss: 0.2323014736175537
Batch 16/64 loss: 0.22078591585159302
Batch 17/64 loss: 0.2297426462173462
Batch 18/64 loss: 0.22405719757080078
Batch 19/64 loss: 0.2212982177734375
Batch 20/64 loss: 0.23609232902526855
Batch 21/64 loss: 0.23389989137649536
Batch 22/64 loss: 0.2324124574661255
Batch 23/64 loss: 0.2297852635383606
Batch 24/64 loss: 0.22500693798065186
Batch 25/64 loss: 0.22949117422103882
Batch 26/64 loss: 0.22812533378601074
Batch 27/64 loss: 0.23909807205200195
Batch 28/64 loss: 0.23909181356430054
Batch 29/64 loss: 0.2282106876373291
Batch 30/64 loss: 0.22657829523086548
Batch 31/64 loss: 0.23432469367980957
Batch 32/64 loss: 0.21794748306274414
Batch 33/64 loss: 0.22658872604370117
Batch 34/64 loss: 0.2248474359512329
Batch 35/64 loss: 0.22325944900512695
Batch 36/64 loss: 0.23571395874023438
Batch 37/64 loss: 0.22494864463806152
Batch 38/64 loss: 0.24195408821105957
Batch 39/64 loss: 0.23137682676315308
Batch 40/64 loss: 0.23156452178955078
Batch 41/64 loss: 0.22919660806655884
Batch 42/64 loss: 0.22776031494140625
Batch 43/64 loss: 0.2393646240234375
Batch 44/64 loss: 0.22786808013916016
Batch 45/64 loss: 0.22641682624816895
Batch 46/64 loss: 0.23372554779052734
Batch 47/64 loss: 0.22547310590744019
Batch 48/64 loss: 0.23087078332901
Batch 49/64 loss: 0.22717702388763428
Batch 50/64 loss: 0.22720801830291748
Batch 51/64 loss: 0.2300034761428833
Batch 52/64 loss: 0.22249680757522583
Batch 53/64 loss: 0.2250714898109436
Batch 54/64 loss: 0.223313570022583
Batch 55/64 loss: 0.23251241445541382
Batch 56/64 loss: 0.2193145751953125
Batch 57/64 loss: 0.23055928945541382
Batch 58/64 loss: 0.22093123197555542
Batch 59/64 loss: 0.2290470004081726
Batch 60/64 loss: 0.23003530502319336
Batch 61/64 loss: 0.22082674503326416
Batch 62/64 loss: 0.22632086277008057
Batch 63/64 loss: 0.22706663608551025
Batch 64/64 loss: 0.2199426293373108
Epoch 448  Train loss: 0.22886092312195722  Val loss: 0.28176368593759965
Epoch 449
-------------------------------
Batch 1/64 loss: 0.2411123514175415
Batch 2/64 loss: 0.22683840990066528
Batch 3/64 loss: 0.22567367553710938
Batch 4/64 loss: 0.22947287559509277
Batch 5/64 loss: 0.22873878479003906
Batch 6/64 loss: 0.23137909173965454
Batch 7/64 loss: 0.22871172428131104
Batch 8/64 loss: 0.22508764266967773
Batch 9/64 loss: 0.23879706859588623
Batch 10/64 loss: 0.2228708267211914
Batch 11/64 loss: 0.22353148460388184
Batch 12/64 loss: 0.22283339500427246
Batch 13/64 loss: 0.22480493783950806
Batch 14/64 loss: 0.2264779806137085
Batch 15/64 loss: 0.2252088189125061
Batch 16/64 loss: 0.22545039653778076
Batch 17/64 loss: 0.2246909737586975
Batch 18/64 loss: 0.2231907844543457
Batch 19/64 loss: 0.2239862084388733
Batch 20/64 loss: 0.22820603847503662
Batch 21/64 loss: 0.2195117473602295
Batch 22/64 loss: 0.22357451915740967
Batch 23/64 loss: 0.2193031907081604
Batch 24/64 loss: 0.21541696786880493
Batch 25/64 loss: 0.22573113441467285
Batch 26/64 loss: 0.23408985137939453
Batch 27/64 loss: 0.23193269968032837
Batch 28/64 loss: 0.22821950912475586
Batch 29/64 loss: 0.2346619963645935
Batch 30/64 loss: 0.22617435455322266
Batch 31/64 loss: 0.22730684280395508
Batch 32/64 loss: 0.21660387516021729
Batch 33/64 loss: 0.2259838581085205
Batch 34/64 loss: 0.23715078830718994
Batch 35/64 loss: 0.22581952810287476
Batch 36/64 loss: 0.2267943024635315
Batch 37/64 loss: 0.2382725477218628
Batch 38/64 loss: 0.23015117645263672
Batch 39/64 loss: 0.22763913869857788
Batch 40/64 loss: 0.2296086549758911
Batch 41/64 loss: 0.2333526611328125
Batch 42/64 loss: 0.22063100337982178
Batch 43/64 loss: 0.22810131311416626
Batch 44/64 loss: 0.2261183261871338
Batch 45/64 loss: 0.2325117588043213
Batch 46/64 loss: 0.22040098905563354
Batch 47/64 loss: 0.2286791205406189
Batch 48/64 loss: 0.23378783464431763
Batch 49/64 loss: 0.22384721040725708
Batch 50/64 loss: 0.22264587879180908
Batch 51/64 loss: 0.22773969173431396
Batch 52/64 loss: 0.23511290550231934
Batch 53/64 loss: 0.22523659467697144
Batch 54/64 loss: 0.2349553108215332
Batch 55/64 loss: 0.22410225868225098
Batch 56/64 loss: 0.22875702381134033
Batch 57/64 loss: 0.22512704133987427
Batch 58/64 loss: 0.2293170690536499
Batch 59/64 loss: 0.23953622579574585
Batch 60/64 loss: 0.2187403440475464
Batch 61/64 loss: 0.2249336838722229
Batch 62/64 loss: 0.2341545820236206
Batch 63/64 loss: 0.22654283046722412
Batch 64/64 loss: 0.23153483867645264
Epoch 449  Train loss: 0.2275920461205875  Val loss: 0.281182943340839
Epoch 450
-------------------------------
Batch 1/64 loss: 0.22085118293762207
Batch 2/64 loss: 0.21962428092956543
Batch 3/64 loss: 0.2285950779914856
Batch 4/64 loss: 0.23407196998596191
Batch 5/64 loss: 0.22509890794754028
Batch 6/64 loss: 0.21331751346588135
Batch 7/64 loss: 0.2359933853149414
Batch 8/64 loss: 0.21908164024353027
Batch 9/64 loss: 0.22254931926727295
Batch 10/64 loss: 0.23535394668579102
Batch 11/64 loss: 0.23015087842941284
Batch 12/64 loss: 0.2179279327392578
Batch 13/64 loss: 0.23001360893249512
Batch 14/64 loss: 0.22943615913391113
Batch 15/64 loss: 0.22348612546920776
Batch 16/64 loss: 0.22579604387283325
Batch 17/64 loss: 0.23112702369689941
Batch 18/64 loss: 0.22384369373321533
Batch 19/64 loss: 0.2225683331489563
Batch 20/64 loss: 0.23365145921707153
Batch 21/64 loss: 0.21647077798843384
Batch 22/64 loss: 0.2310352325439453
Batch 23/64 loss: 0.23174822330474854
Batch 24/64 loss: 0.2319658398628235
Batch 25/64 loss: 0.2267788052558899
Batch 26/64 loss: 0.22146809101104736
Batch 27/64 loss: 0.21772229671478271
Batch 28/64 loss: 0.2390202283859253
Batch 29/64 loss: 0.22420692443847656
Batch 30/64 loss: 0.22203892469406128
Batch 31/64 loss: 0.23240971565246582
Batch 32/64 loss: 0.23400914669036865
Batch 33/64 loss: 0.22222918272018433
Batch 34/64 loss: 0.22772014141082764
Batch 35/64 loss: 0.21881449222564697
Batch 36/64 loss: 0.2305697202682495
Batch 37/64 loss: 0.23295706510543823
Batch 38/64 loss: 0.22843551635742188
Batch 39/64 loss: 0.22214221954345703
Batch 40/64 loss: 0.22139930725097656
Batch 41/64 loss: 0.2270175814628601
Batch 42/64 loss: 0.22792339324951172
Batch 43/64 loss: 0.22938764095306396
Batch 44/64 loss: 0.22073149681091309
Batch 45/64 loss: 0.23035061359405518
Batch 46/64 loss: 0.22801721096038818
Batch 47/64 loss: 0.24410933256149292
Batch 48/64 loss: 0.21403610706329346
Batch 49/64 loss: 0.23175209760665894
Batch 50/64 loss: 0.22789335250854492
Batch 51/64 loss: 0.22782433032989502
Batch 52/64 loss: 0.23003137111663818
Batch 53/64 loss: 0.2398221492767334
Batch 54/64 loss: 0.22229087352752686
Batch 55/64 loss: 0.221490740776062
Batch 56/64 loss: 0.23365479707717896
Batch 57/64 loss: 0.23408401012420654
Batch 58/64 loss: 0.23259717226028442
Batch 59/64 loss: 0.23088383674621582
Batch 60/64 loss: 0.23071396350860596
Batch 61/64 loss: 0.2347792387008667
Batch 62/64 loss: 0.229836106300354
Batch 63/64 loss: 0.23368334770202637
Batch 64/64 loss: 0.2256503701210022
Epoch 450  Train loss: 0.2275737862960965  Val loss: 0.2815039424142477
Epoch 451
-------------------------------
Batch 1/64 loss: 0.22779440879821777
Batch 2/64 loss: 0.2274898886680603
Batch 3/64 loss: 0.22009992599487305
Batch 4/64 loss: 0.2289028763771057
Batch 5/64 loss: 0.22156846523284912
Batch 6/64 loss: 0.22399288415908813
Batch 7/64 loss: 0.21941900253295898
Batch 8/64 loss: 0.23061037063598633
Batch 9/64 loss: 0.23179668188095093
Batch 10/64 loss: 0.23532545566558838
Batch 11/64 loss: 0.23681169748306274
Batch 12/64 loss: 0.22199511528015137
Batch 13/64 loss: 0.22740691900253296
Batch 14/64 loss: 0.23165488243103027
Batch 15/64 loss: 0.23065602779388428
Batch 16/64 loss: 0.22835969924926758
Batch 17/64 loss: 0.21109259128570557
Batch 18/64 loss: 0.2363497018814087
Batch 19/64 loss: 0.21939468383789062
Batch 20/64 loss: 0.2268897294998169
Batch 21/64 loss: 0.23384642601013184
Batch 22/64 loss: 0.21814143657684326
Batch 23/64 loss: 0.23012912273406982
Batch 24/64 loss: 0.2252832055091858
Batch 25/64 loss: 0.2327079176902771
Batch 26/64 loss: 0.2358676791191101
Batch 27/64 loss: 0.22265899181365967
Batch 28/64 loss: 0.21374547481536865
Batch 29/64 loss: 0.2401341199874878
Batch 30/64 loss: 0.22563475370407104
Batch 31/64 loss: 0.2303510308265686
Batch 32/64 loss: 0.2319396734237671
Batch 33/64 loss: 0.2254927158355713
Batch 34/64 loss: 0.23179912567138672
Batch 35/64 loss: 0.2314697504043579
Batch 36/64 loss: 0.22569918632507324
Batch 37/64 loss: 0.22086423635482788
Batch 38/64 loss: 0.229322612285614
Batch 39/64 loss: 0.2326035499572754
Batch 40/64 loss: 0.22313439846038818
Batch 41/64 loss: 0.22568851709365845
Batch 42/64 loss: 0.24093472957611084
Batch 43/64 loss: 0.22669076919555664
Batch 44/64 loss: 0.22522354125976562
Batch 45/64 loss: 0.23590219020843506
Batch 46/64 loss: 0.23448127508163452
Batch 47/64 loss: 0.23422998189926147
Batch 48/64 loss: 0.23053723573684692
Batch 49/64 loss: 0.2328416109085083
Batch 50/64 loss: 0.24774926900863647
Batch 51/64 loss: 0.22476261854171753
Batch 52/64 loss: 0.2241140604019165
Batch 53/64 loss: 0.2257029414176941
Batch 54/64 loss: 0.22442471981048584
Batch 55/64 loss: 0.22037947177886963
Batch 56/64 loss: 0.23830580711364746
Batch 57/64 loss: 0.22490477561950684
Batch 58/64 loss: 0.22381627559661865
Batch 59/64 loss: 0.2354792356491089
Batch 60/64 loss: 0.22564738988876343
Batch 61/64 loss: 0.22508084774017334
Batch 62/64 loss: 0.22996938228607178
Batch 63/64 loss: 0.23691147565841675
Batch 64/64 loss: 0.2253398895263672
Epoch 451  Train loss: 0.2284112855499866  Val loss: 0.2822760409096262
Epoch 452
-------------------------------
Batch 1/64 loss: 0.22357887029647827
Batch 2/64 loss: 0.22740626335144043
Batch 3/64 loss: 0.22800177335739136
Batch 4/64 loss: 0.2182578444480896
Batch 5/64 loss: 0.23634493350982666
Batch 6/64 loss: 0.2351853847503662
Batch 7/64 loss: 0.22519755363464355
Batch 8/64 loss: 0.2233729362487793
Batch 9/64 loss: 0.22901612520217896
Batch 10/64 loss: 0.22603559494018555
Batch 11/64 loss: 0.22311627864837646
Batch 12/64 loss: 0.21985113620758057
Batch 13/64 loss: 0.21424365043640137
Batch 14/64 loss: 0.22142481803894043
Batch 15/64 loss: 0.23439043760299683
Batch 16/64 loss: 0.22391319274902344
Batch 17/64 loss: 0.22813808917999268
Batch 18/64 loss: 0.22220879793167114
Batch 19/64 loss: 0.22931426763534546
Batch 20/64 loss: 0.23080754280090332
Batch 21/64 loss: 0.22603309154510498
Batch 22/64 loss: 0.21834397315979004
Batch 23/64 loss: 0.24003994464874268
Batch 24/64 loss: 0.22952282428741455
Batch 25/64 loss: 0.23728764057159424
Batch 26/64 loss: 0.23292207717895508
Batch 27/64 loss: 0.22461187839508057
Batch 28/64 loss: 0.22996151447296143
Batch 29/64 loss: 0.2338275909423828
Batch 30/64 loss: 0.22793316841125488
Batch 31/64 loss: 0.22422051429748535
Batch 32/64 loss: 0.22995072603225708
Batch 33/64 loss: 0.22461307048797607
Batch 34/64 loss: 0.2265681028366089
Batch 35/64 loss: 0.2187809944152832
Batch 36/64 loss: 0.2255711555480957
Batch 37/64 loss: 0.2276003360748291
Batch 38/64 loss: 0.21587872505187988
Batch 39/64 loss: 0.23240721225738525
Batch 40/64 loss: 0.22452431917190552
Batch 41/64 loss: 0.2217584252357483
Batch 42/64 loss: 0.2201756238937378
Batch 43/64 loss: 0.2224646806716919
Batch 44/64 loss: 0.2194061279296875
Batch 45/64 loss: 0.23263418674468994
Batch 46/64 loss: 0.22922688722610474
Batch 47/64 loss: 0.2414170503616333
Batch 48/64 loss: 0.2249433398246765
Batch 49/64 loss: 0.22715753316879272
Batch 50/64 loss: 0.2291432023048401
Batch 51/64 loss: 0.22896933555603027
Batch 52/64 loss: 0.2250458002090454
Batch 53/64 loss: 0.22792494297027588
Batch 54/64 loss: 0.2341609001159668
Batch 55/64 loss: 0.23316287994384766
Batch 56/64 loss: 0.23313486576080322
Batch 57/64 loss: 0.2201862931251526
Batch 58/64 loss: 0.22924494743347168
Batch 59/64 loss: 0.22760462760925293
Batch 60/64 loss: 0.2383636236190796
Batch 61/64 loss: 0.22542428970336914
Batch 62/64 loss: 0.22300803661346436
Batch 63/64 loss: 0.23591268062591553
Batch 64/64 loss: 0.22060924768447876
Epoch 452  Train loss: 0.227236573602639  Val loss: 0.28210467284487695
Epoch 453
-------------------------------
Batch 1/64 loss: 0.23084038496017456
Batch 2/64 loss: 0.22544342279434204
Batch 3/64 loss: 0.2408009171485901
Batch 4/64 loss: 0.22398561239242554
Batch 5/64 loss: 0.2336748242378235
Batch 6/64 loss: 0.2312905192375183
Batch 7/64 loss: 0.22139179706573486
Batch 8/64 loss: 0.2158442735671997
Batch 9/64 loss: 0.23650825023651123
Batch 10/64 loss: 0.23101651668548584
Batch 11/64 loss: 0.2231515645980835
Batch 12/64 loss: 0.22854864597320557
Batch 13/64 loss: 0.22385478019714355
Batch 14/64 loss: 0.2328629493713379
Batch 15/64 loss: 0.2396259307861328
Batch 16/64 loss: 0.23470836877822876
Batch 17/64 loss: 0.23468172550201416
Batch 18/64 loss: 0.22142243385314941
Batch 19/64 loss: 0.21879959106445312
Batch 20/64 loss: 0.22540730237960815
Batch 21/64 loss: 0.2258228063583374
Batch 22/64 loss: 0.2356487512588501
Batch 23/64 loss: 0.2285449504852295
Batch 24/64 loss: 0.22813081741333008
Batch 25/64 loss: 0.22628188133239746
Batch 26/64 loss: 0.233320951461792
Batch 27/64 loss: 0.21997439861297607
Batch 28/64 loss: 0.21575897932052612
Batch 29/64 loss: 0.23121005296707153
Batch 30/64 loss: 0.23262536525726318
Batch 31/64 loss: 0.21785759925842285
Batch 32/64 loss: 0.22565382719039917
Batch 33/64 loss: 0.2210618257522583
Batch 34/64 loss: 0.22171568870544434
Batch 35/64 loss: 0.22834426164627075
Batch 36/64 loss: 0.22287076711654663
Batch 37/64 loss: 0.22046935558319092
Batch 38/64 loss: 0.22839868068695068
Batch 39/64 loss: 0.2301778793334961
Batch 40/64 loss: 0.22274738550186157
Batch 41/64 loss: 0.2320522665977478
Batch 42/64 loss: 0.22979283332824707
Batch 43/64 loss: 0.23771929740905762
Batch 44/64 loss: 0.23281466960906982
Batch 45/64 loss: 0.2258571982383728
Batch 46/64 loss: 0.2301849126815796
Batch 47/64 loss: 0.22433507442474365
Batch 48/64 loss: 0.22321128845214844
Batch 49/64 loss: 0.23017501831054688
Batch 50/64 loss: 0.2347455620765686
Batch 51/64 loss: 0.22685396671295166
Batch 52/64 loss: 0.23192179203033447
Batch 53/64 loss: 0.23045742511749268
Batch 54/64 loss: 0.2212233543395996
Batch 55/64 loss: 0.22313201427459717
Batch 56/64 loss: 0.220575213432312
Batch 57/64 loss: 0.23233336210250854
Batch 58/64 loss: 0.22135186195373535
Batch 59/64 loss: 0.2327110767364502
Batch 60/64 loss: 0.22965240478515625
Batch 61/64 loss: 0.2244584560394287
Batch 62/64 loss: 0.22175544500350952
Batch 63/64 loss: 0.23605167865753174
Batch 64/64 loss: 0.23409730195999146
Epoch 453  Train loss: 0.2277555323114582  Val loss: 0.2808983325958252
Epoch 454
-------------------------------
Batch 1/64 loss: 0.22935396432876587
Batch 2/64 loss: 0.2270451784133911
Batch 3/64 loss: 0.23667556047439575
Batch 4/64 loss: 0.22198402881622314
Batch 5/64 loss: 0.225103497505188
Batch 6/64 loss: 0.22315919399261475
Batch 7/64 loss: 0.2183895707130432
Batch 8/64 loss: 0.22632670402526855
Batch 9/64 loss: 0.22657734155654907
Batch 10/64 loss: 0.21744459867477417
Batch 11/64 loss: 0.22081589698791504
Batch 12/64 loss: 0.23225265741348267
Batch 13/64 loss: 0.22517859935760498
Batch 14/64 loss: 0.234544038772583
Batch 15/64 loss: 0.22042399644851685
Batch 16/64 loss: 0.22186803817749023
Batch 17/64 loss: 0.2335227131843567
Batch 18/64 loss: 0.23445624113082886
Batch 19/64 loss: 0.23159682750701904
Batch 20/64 loss: 0.22838807106018066
Batch 21/64 loss: 0.2343805432319641
Batch 22/64 loss: 0.2228490114212036
Batch 23/64 loss: 0.22754120826721191
Batch 24/64 loss: 0.2174466848373413
Batch 25/64 loss: 0.2358769178390503
Batch 26/64 loss: 0.2269688844680786
Batch 27/64 loss: 0.23302650451660156
Batch 28/64 loss: 0.23799872398376465
Batch 29/64 loss: 0.23142629861831665
Batch 30/64 loss: 0.22041773796081543
Batch 31/64 loss: 0.22496670484542847
Batch 32/64 loss: 0.2348620891571045
Batch 33/64 loss: 0.22767794132232666
Batch 34/64 loss: 0.23796546459197998
Batch 35/64 loss: 0.2265552282333374
Batch 36/64 loss: 0.23224616050720215
Batch 37/64 loss: 0.2213599681854248
Batch 38/64 loss: 0.22633260488510132
Batch 39/64 loss: 0.22247672080993652
Batch 40/64 loss: 0.22747015953063965
Batch 41/64 loss: 0.23129642009735107
Batch 42/64 loss: 0.21970051527023315
Batch 43/64 loss: 0.22121727466583252
Batch 44/64 loss: 0.2177433967590332
Batch 45/64 loss: 0.22718095779418945
Batch 46/64 loss: 0.23322904109954834
Batch 47/64 loss: 0.22955310344696045
Batch 48/64 loss: 0.23198747634887695
Batch 49/64 loss: 0.22381913661956787
Batch 50/64 loss: 0.22478020191192627
Batch 51/64 loss: 0.2180185317993164
Batch 52/64 loss: 0.22302788496017456
Batch 53/64 loss: 0.2198694944381714
Batch 54/64 loss: 0.2376309037208557
Batch 55/64 loss: 0.21949243545532227
Batch 56/64 loss: 0.2249215841293335
Batch 57/64 loss: 0.22244930267333984
Batch 58/64 loss: 0.22682970762252808
Batch 59/64 loss: 0.2381500005722046
Batch 60/64 loss: 0.2309943437576294
Batch 61/64 loss: 0.23358070850372314
Batch 62/64 loss: 0.22919273376464844
Batch 63/64 loss: 0.23736631870269775
Batch 64/64 loss: 0.2308235764503479
Epoch 454  Train loss: 0.2274525714855568  Val loss: 0.28206730380500716
Epoch 455
-------------------------------
Batch 1/64 loss: 0.22394144535064697
Batch 2/64 loss: 0.22509771585464478
Batch 3/64 loss: 0.2308483123779297
Batch 4/64 loss: 0.22675049304962158
Batch 5/64 loss: 0.23033511638641357
Batch 6/64 loss: 0.22735220193862915
Batch 7/64 loss: 0.23652797937393188
Batch 8/64 loss: 0.22642022371292114
Batch 9/64 loss: 0.2170286774635315
Batch 10/64 loss: 0.22781521081924438
Batch 11/64 loss: 0.21949821710586548
Batch 12/64 loss: 0.2234025001525879
Batch 13/64 loss: 0.2221817970275879
Batch 14/64 loss: 0.23032361268997192
Batch 15/64 loss: 0.22241461277008057
Batch 16/64 loss: 0.21480929851531982
Batch 17/64 loss: 0.22891205549240112
Batch 18/64 loss: 0.23172712326049805
Batch 19/64 loss: 0.22356951236724854
Batch 20/64 loss: 0.22634202241897583
Batch 21/64 loss: 0.22860181331634521
Batch 22/64 loss: 0.23093181848526
Batch 23/64 loss: 0.23053038120269775
Batch 24/64 loss: 0.2377602458000183
Batch 25/64 loss: 0.23650109767913818
Batch 26/64 loss: 0.2225145697593689
Batch 27/64 loss: 0.22912240028381348
Batch 28/64 loss: 0.22291260957717896
Batch 29/64 loss: 0.2367270588874817
Batch 30/64 loss: 0.2349414825439453
Batch 31/64 loss: 0.2278423309326172
Batch 32/64 loss: 0.23114752769470215
Batch 33/64 loss: 0.23036670684814453
Batch 34/64 loss: 0.23453933000564575
Batch 35/64 loss: 0.2197265625
Batch 36/64 loss: 0.2253943681716919
Batch 37/64 loss: 0.2254367470741272
Batch 38/64 loss: 0.23224568367004395
Batch 39/64 loss: 0.22419589757919312
Batch 40/64 loss: 0.22805285453796387
Batch 41/64 loss: 0.23247456550598145
Batch 42/64 loss: 0.22885197401046753
Batch 43/64 loss: 0.24368762969970703
Batch 44/64 loss: 0.2246609926223755
Batch 45/64 loss: 0.23231220245361328
Batch 46/64 loss: 0.23056000471115112
Batch 47/64 loss: 0.22083771228790283
Batch 48/64 loss: 0.22799253463745117
Batch 49/64 loss: 0.2378087043762207
Batch 50/64 loss: 0.22103238105773926
Batch 51/64 loss: 0.22823530435562134
Batch 52/64 loss: 0.2310449481010437
Batch 53/64 loss: 0.22950315475463867
Batch 54/64 loss: 0.23227179050445557
Batch 55/64 loss: 0.22957605123519897
Batch 56/64 loss: 0.2222711443901062
Batch 57/64 loss: 0.22403419017791748
Batch 58/64 loss: 0.23015010356903076
Batch 59/64 loss: 0.2213979959487915
Batch 60/64 loss: 0.2355005145072937
Batch 61/64 loss: 0.21720683574676514
Batch 62/64 loss: 0.22255182266235352
Batch 63/64 loss: 0.21589207649230957
Batch 64/64 loss: 0.2267296314239502
Epoch 455  Train loss: 0.2276814348557416  Val loss: 0.2816587780759097
Epoch 456
-------------------------------
Batch 1/64 loss: 0.23692166805267334
Batch 2/64 loss: 0.22122395038604736
Batch 3/64 loss: 0.23437738418579102
Batch 4/64 loss: 0.22000348567962646
Batch 5/64 loss: 0.23205959796905518
Batch 6/64 loss: 0.22228693962097168
Batch 7/64 loss: 0.2333027720451355
Batch 8/64 loss: 0.22037160396575928
Batch 9/64 loss: 0.23489642143249512
Batch 10/64 loss: 0.23309248685836792
Batch 11/64 loss: 0.23371851444244385
Batch 12/64 loss: 0.22939836978912354
Batch 13/64 loss: 0.23013007640838623
Batch 14/64 loss: 0.23380452394485474
Batch 15/64 loss: 0.22609126567840576
Batch 16/64 loss: 0.2265031337738037
Batch 17/64 loss: 0.2287103533744812
Batch 18/64 loss: 0.23543453216552734
Batch 19/64 loss: 0.22599399089813232
Batch 20/64 loss: 0.23147094249725342
Batch 21/64 loss: 0.22876155376434326
Batch 22/64 loss: 0.22875916957855225
Batch 23/64 loss: 0.22552376985549927
Batch 24/64 loss: 0.23253369331359863
Batch 25/64 loss: 0.23029589653015137
Batch 26/64 loss: 0.22582173347473145
Batch 27/64 loss: 0.24183285236358643
Batch 28/64 loss: 0.22867560386657715
Batch 29/64 loss: 0.2358264923095703
Batch 30/64 loss: 0.2245635986328125
Batch 31/64 loss: 0.22197288274765015
Batch 32/64 loss: 0.23404169082641602
Batch 33/64 loss: 0.22167247533798218
Batch 34/64 loss: 0.22457754611968994
Batch 35/64 loss: 0.21601104736328125
Batch 36/64 loss: 0.23704320192337036
Batch 37/64 loss: 0.2301783561706543
Batch 38/64 loss: 0.23144304752349854
Batch 39/64 loss: 0.23384582996368408
Batch 40/64 loss: 0.2276449203491211
Batch 41/64 loss: 0.22513657808303833
Batch 42/64 loss: 0.22507190704345703
Batch 43/64 loss: 0.23204809427261353
Batch 44/64 loss: 0.22375786304473877
Batch 45/64 loss: 0.2368236780166626
Batch 46/64 loss: 0.2188529372215271
Batch 47/64 loss: 0.2179984450340271
Batch 48/64 loss: 0.22294104099273682
Batch 49/64 loss: 0.23186731338500977
Batch 50/64 loss: 0.22650712728500366
Batch 51/64 loss: 0.2281489372253418
Batch 52/64 loss: 0.23270416259765625
Batch 53/64 loss: 0.22592639923095703
Batch 54/64 loss: 0.22915446758270264
Batch 55/64 loss: 0.22201275825500488
Batch 56/64 loss: 0.2305234670639038
Batch 57/64 loss: 0.22742390632629395
Batch 58/64 loss: 0.23564249277114868
Batch 59/64 loss: 0.2332547903060913
Batch 60/64 loss: 0.23007017374038696
Batch 61/64 loss: 0.22305893898010254
Batch 62/64 loss: 0.22032421827316284
Batch 63/64 loss: 0.23569190502166748
Batch 64/64 loss: 0.2249334454536438
Epoch 456  Train loss: 0.22861896566316192  Val loss: 0.28242540298048985
Epoch 457
-------------------------------
Batch 1/64 loss: 0.22836709022521973
Batch 2/64 loss: 0.22427761554718018
Batch 3/64 loss: 0.22813928127288818
Batch 4/64 loss: 0.2303633689880371
Batch 5/64 loss: 0.22383224964141846
Batch 6/64 loss: 0.22521793842315674
Batch 7/64 loss: 0.23019063472747803
Batch 8/64 loss: 0.22584891319274902
Batch 9/64 loss: 0.22981512546539307
Batch 10/64 loss: 0.22883403301239014
Batch 11/64 loss: 0.22467517852783203
Batch 12/64 loss: 0.22705936431884766
Batch 13/64 loss: 0.22569900751113892
Batch 14/64 loss: 0.2277926206588745
Batch 15/64 loss: 0.22448599338531494
Batch 16/64 loss: 0.22753870487213135
Batch 17/64 loss: 0.22112536430358887
Batch 18/64 loss: 0.225425124168396
Batch 19/64 loss: 0.21973061561584473
Batch 20/64 loss: 0.22123146057128906
Batch 21/64 loss: 0.2226191759109497
Batch 22/64 loss: 0.2261243462562561
Batch 23/64 loss: 0.22304856777191162
Batch 24/64 loss: 0.23804926872253418
Batch 25/64 loss: 0.22478270530700684
Batch 26/64 loss: 0.23055428266525269
Batch 27/64 loss: 0.23157823085784912
Batch 28/64 loss: 0.23962676525115967
Batch 29/64 loss: 0.22223782539367676
Batch 30/64 loss: 0.2156296968460083
Batch 31/64 loss: 0.2288774847984314
Batch 32/64 loss: 0.2160860300064087
Batch 33/64 loss: 0.22178351879119873
Batch 34/64 loss: 0.22966033220291138
Batch 35/64 loss: 0.23065650463104248
Batch 36/64 loss: 0.21838116645812988
Batch 37/64 loss: 0.2258768081665039
Batch 38/64 loss: 0.23293828964233398
Batch 39/64 loss: 0.2320278286933899
Batch 40/64 loss: 0.23985731601715088
Batch 41/64 loss: 0.22515475749969482
Batch 42/64 loss: 0.23437440395355225
Batch 43/64 loss: 0.23069411516189575
Batch 44/64 loss: 0.223244309425354
Batch 45/64 loss: 0.22336477041244507
Batch 46/64 loss: 0.22714519500732422
Batch 47/64 loss: 0.22247278690338135
Batch 48/64 loss: 0.23599529266357422
Batch 49/64 loss: 0.22617214918136597
Batch 50/64 loss: 0.22047889232635498
Batch 51/64 loss: 0.23601824045181274
Batch 52/64 loss: 0.22585344314575195
Batch 53/64 loss: 0.23497217893600464
Batch 54/64 loss: 0.22474980354309082
Batch 55/64 loss: 0.24188673496246338
Batch 56/64 loss: 0.22604119777679443
Batch 57/64 loss: 0.23389458656311035
Batch 58/64 loss: 0.21346288919448853
Batch 59/64 loss: 0.21945375204086304
Batch 60/64 loss: 0.22222942113876343
Batch 61/64 loss: 0.2370409369468689
Batch 62/64 loss: 0.23736244440078735
Batch 63/64 loss: 0.22621512413024902
Batch 64/64 loss: 0.22190535068511963
Epoch 457  Train loss: 0.2272118002760644  Val loss: 0.2817315580099309
Epoch 458
-------------------------------
Batch 1/64 loss: 0.21969497203826904
Batch 2/64 loss: 0.22085976600646973
Batch 3/64 loss: 0.21993792057037354
Batch 4/64 loss: 0.22090435028076172
Batch 5/64 loss: 0.22613894939422607
Batch 6/64 loss: 0.22270441055297852
Batch 7/64 loss: 0.22210437059402466
Batch 8/64 loss: 0.22318017482757568
Batch 9/64 loss: 0.2224351167678833
Batch 10/64 loss: 0.22106003761291504
Batch 11/64 loss: 0.22035270929336548
Batch 12/64 loss: 0.22013413906097412
Batch 13/64 loss: 0.2134738564491272
Batch 14/64 loss: 0.22051024436950684
Batch 15/64 loss: 0.22620272636413574
Batch 16/64 loss: 0.22843420505523682
Batch 17/64 loss: 0.22112298011779785
Batch 18/64 loss: 0.22888702154159546
Batch 19/64 loss: 0.22851896286010742
Batch 20/64 loss: 0.22645950317382812
Batch 21/64 loss: 0.22618639469146729
Batch 22/64 loss: 0.23750460147857666
Batch 23/64 loss: 0.22175157070159912
Batch 24/64 loss: 0.22739791870117188
Batch 25/64 loss: 0.23680061101913452
Batch 26/64 loss: 0.2325667142868042
Batch 27/64 loss: 0.22742128372192383
Batch 28/64 loss: 0.2307898998260498
Batch 29/64 loss: 0.23252665996551514
Batch 30/64 loss: 0.21816837787628174
Batch 31/64 loss: 0.23064565658569336
Batch 32/64 loss: 0.22183692455291748
Batch 33/64 loss: 0.23345917463302612
Batch 34/64 loss: 0.24168360233306885
Batch 35/64 loss: 0.2260955572128296
Batch 36/64 loss: 0.22657006978988647
Batch 37/64 loss: 0.2357732653617859
Batch 38/64 loss: 0.2260192632675171
Batch 39/64 loss: 0.22502905130386353
Batch 40/64 loss: 0.23238348960876465
Batch 41/64 loss: 0.2341209053993225
Batch 42/64 loss: 0.22269272804260254
Batch 43/64 loss: 0.22999989986419678
Batch 44/64 loss: 0.24251878261566162
Batch 45/64 loss: 0.22428297996520996
Batch 46/64 loss: 0.23352205753326416
Batch 47/64 loss: 0.23294270038604736
Batch 48/64 loss: 0.22332674264907837
Batch 49/64 loss: 0.24571645259857178
Batch 50/64 loss: 0.22568219900131226
Batch 51/64 loss: 0.231967031955719
Batch 52/64 loss: 0.2243313193321228
Batch 53/64 loss: 0.22013580799102783
Batch 54/64 loss: 0.21641558408737183
Batch 55/64 loss: 0.2270510196685791
Batch 56/64 loss: 0.2281590700149536
Batch 57/64 loss: 0.22339046001434326
Batch 58/64 loss: 0.2238025665283203
Batch 59/64 loss: 0.2269994616508484
Batch 60/64 loss: 0.22770172357559204
Batch 61/64 loss: 0.22009629011154175
Batch 62/64 loss: 0.2290911078453064
Batch 63/64 loss: 0.22630292177200317
Batch 64/64 loss: 0.25091129541397095
Epoch 458  Train loss: 0.22701427118450987  Val loss: 0.2811227528909637
Epoch 459
-------------------------------
Batch 1/64 loss: 0.22211086750030518
Batch 2/64 loss: 0.22868472337722778
Batch 3/64 loss: 0.2242245078086853
Batch 4/64 loss: 0.2263948917388916
Batch 5/64 loss: 0.2410857081413269
Batch 6/64 loss: 0.22563034296035767
Batch 7/64 loss: 0.2244492769241333
Batch 8/64 loss: 0.2218238115310669
Batch 9/64 loss: 0.22200638055801392
Batch 10/64 loss: 0.2272857427597046
Batch 11/64 loss: 0.22245001792907715
Batch 12/64 loss: 0.22454315423965454
Batch 13/64 loss: 0.21409302949905396
Batch 14/64 loss: 0.22863459587097168
Batch 15/64 loss: 0.22853171825408936
Batch 16/64 loss: 0.2211894989013672
Batch 17/64 loss: 0.22518056631088257
Batch 18/64 loss: 0.22527897357940674
Batch 19/64 loss: 0.22335129976272583
Batch 20/64 loss: 0.22737425565719604
Batch 21/64 loss: 0.2244558334350586
Batch 22/64 loss: 0.237007737159729
Batch 23/64 loss: 0.22803622484207153
Batch 24/64 loss: 0.21985238790512085
Batch 25/64 loss: 0.21950745582580566
Batch 26/64 loss: 0.22258037328720093
Batch 27/64 loss: 0.23193258047103882
Batch 28/64 loss: 0.2164018154144287
Batch 29/64 loss: 0.233859121799469
Batch 30/64 loss: 0.2341219186782837
Batch 31/64 loss: 0.22278648614883423
Batch 32/64 loss: 0.22399038076400757
Batch 33/64 loss: 0.23700207471847534
Batch 34/64 loss: 0.22704720497131348
Batch 35/64 loss: 0.2275368571281433
Batch 36/64 loss: 0.2305506467819214
Batch 37/64 loss: 0.22577643394470215
Batch 38/64 loss: 0.2289230227470398
Batch 39/64 loss: 0.23081070184707642
Batch 40/64 loss: 0.22667241096496582
Batch 41/64 loss: 0.2295393943786621
Batch 42/64 loss: 0.22527045011520386
Batch 43/64 loss: 0.221504807472229
Batch 44/64 loss: 0.22696202993392944
Batch 45/64 loss: 0.22023725509643555
Batch 46/64 loss: 0.2217680811882019
Batch 47/64 loss: 0.22979426383972168
Batch 48/64 loss: 0.23743367195129395
Batch 49/64 loss: 0.22653812170028687
Batch 50/64 loss: 0.23027873039245605
Batch 51/64 loss: 0.22693276405334473
Batch 52/64 loss: 0.22326892614364624
Batch 53/64 loss: 0.22427266836166382
Batch 54/64 loss: 0.2339869737625122
Batch 55/64 loss: 0.2315385937690735
Batch 56/64 loss: 0.23506802320480347
Batch 57/64 loss: 0.23250466585159302
Batch 58/64 loss: 0.22357070446014404
Batch 59/64 loss: 0.23143517971038818
Batch 60/64 loss: 0.23394787311553955
Batch 61/64 loss: 0.22594094276428223
Batch 62/64 loss: 0.2252388596534729
Batch 63/64 loss: 0.2289416790008545
Batch 64/64 loss: 0.22957181930541992
Epoch 459  Train loss: 0.22700123225941377  Val loss: 0.28159748483769265
Epoch 460
-------------------------------
Batch 1/64 loss: 0.23773765563964844
Batch 2/64 loss: 0.22985708713531494
Batch 3/64 loss: 0.22636914253234863
Batch 4/64 loss: 0.22627806663513184
Batch 5/64 loss: 0.24002492427825928
Batch 6/64 loss: 0.22662585973739624
Batch 7/64 loss: 0.23685085773468018
Batch 8/64 loss: 0.2288883924484253
Batch 9/64 loss: 0.2174115777015686
Batch 10/64 loss: 0.2241908311843872
Batch 11/64 loss: 0.2183598279953003
Batch 12/64 loss: 0.2243567705154419
Batch 13/64 loss: 0.2186684012413025
Batch 14/64 loss: 0.2263050675392151
Batch 15/64 loss: 0.21921610832214355
Batch 16/64 loss: 0.2322094440460205
Batch 17/64 loss: 0.22830736637115479
Batch 18/64 loss: 0.2193284034729004
Batch 19/64 loss: 0.21833395957946777
Batch 20/64 loss: 0.22388261556625366
Batch 21/64 loss: 0.22476541996002197
Batch 22/64 loss: 0.21967172622680664
Batch 23/64 loss: 0.23056310415267944
Batch 24/64 loss: 0.2269335389137268
Batch 25/64 loss: 0.22424912452697754
Batch 26/64 loss: 0.23034453392028809
Batch 27/64 loss: 0.23324257135391235
Batch 28/64 loss: 0.21914654970169067
Batch 29/64 loss: 0.22468209266662598
Batch 30/64 loss: 0.23179131746292114
Batch 31/64 loss: 0.24123001098632812
Batch 32/64 loss: 0.21788835525512695
Batch 33/64 loss: 0.22432184219360352
Batch 34/64 loss: 0.22290289402008057
Batch 35/64 loss: 0.21422582864761353
Batch 36/64 loss: 0.2417234182357788
Batch 37/64 loss: 0.22604358196258545
Batch 38/64 loss: 0.22252678871154785
Batch 39/64 loss: 0.22215169668197632
Batch 40/64 loss: 0.23631197214126587
Batch 41/64 loss: 0.2198934555053711
Batch 42/64 loss: 0.21751415729522705
Batch 43/64 loss: 0.23171663284301758
Batch 44/64 loss: 0.22131359577178955
Batch 45/64 loss: 0.21853673458099365
Batch 46/64 loss: 0.2170737385749817
Batch 47/64 loss: 0.22212088108062744
Batch 48/64 loss: 0.2319745421409607
Batch 49/64 loss: 0.22163212299346924
Batch 50/64 loss: 0.2297114133834839
Batch 51/64 loss: 0.24559807777404785
Batch 52/64 loss: 0.23304533958435059
Batch 53/64 loss: 0.23590350151062012
Batch 54/64 loss: 0.2185186743736267
Batch 55/64 loss: 0.2263830304145813
Batch 56/64 loss: 0.23961615562438965
Batch 57/64 loss: 0.2307671308517456
Batch 58/64 loss: 0.2300097942352295
Batch 59/64 loss: 0.22976255416870117
Batch 60/64 loss: 0.22729754447937012
Batch 61/64 loss: 0.22624647617340088
Batch 62/64 loss: 0.22997790575027466
Batch 63/64 loss: 0.23325204849243164
Batch 64/64 loss: 0.22546625137329102
Epoch 460  Train loss: 0.22690013997695024  Val loss: 0.2819773618298298
Epoch 461
-------------------------------
Batch 1/64 loss: 0.2257843017578125
Batch 2/64 loss: 0.2149200439453125
Batch 3/64 loss: 0.22489571571350098
Batch 4/64 loss: 0.22911345958709717
Batch 5/64 loss: 0.22826552391052246
Batch 6/64 loss: 0.22091317176818848
Batch 7/64 loss: 0.22339630126953125
Batch 8/64 loss: 0.2119821310043335
Batch 9/64 loss: 0.21925008296966553
Batch 10/64 loss: 0.2231377363204956
Batch 11/64 loss: 0.2255321741104126
Batch 12/64 loss: 0.223871111869812
Batch 13/64 loss: 0.2267574667930603
Batch 14/64 loss: 0.22457349300384521
Batch 15/64 loss: 0.22796553373336792
Batch 16/64 loss: 0.2306811809539795
Batch 17/64 loss: 0.23016130924224854
Batch 18/64 loss: 0.22433698177337646
Batch 19/64 loss: 0.225446879863739
Batch 20/64 loss: 0.24538379907608032
Batch 21/64 loss: 0.2347816824913025
Batch 22/64 loss: 0.22981548309326172
Batch 23/64 loss: 0.22572803497314453
Batch 24/64 loss: 0.21906644105911255
Batch 25/64 loss: 0.22393274307250977
Batch 26/64 loss: 0.21813827753067017
Batch 27/64 loss: 0.22283315658569336
Batch 28/64 loss: 0.2268991470336914
Batch 29/64 loss: 0.22791695594787598
Batch 30/64 loss: 0.22622042894363403
Batch 31/64 loss: 0.23210418224334717
Batch 32/64 loss: 0.22411584854125977
Batch 33/64 loss: 0.2256518006324768
Batch 34/64 loss: 0.22786015272140503
Batch 35/64 loss: 0.23404622077941895
Batch 36/64 loss: 0.23049086332321167
Batch 37/64 loss: 0.22238218784332275
Batch 38/64 loss: 0.2183225154876709
Batch 39/64 loss: 0.22806578874588013
Batch 40/64 loss: 0.21741783618927002
Batch 41/64 loss: 0.22259777784347534
Batch 42/64 loss: 0.2445639967918396
Batch 43/64 loss: 0.2288517951965332
Batch 44/64 loss: 0.2215580940246582
Batch 45/64 loss: 0.22327715158462524
Batch 46/64 loss: 0.22984802722930908
Batch 47/64 loss: 0.22715651988983154
Batch 48/64 loss: 0.2203681468963623
Batch 49/64 loss: 0.22285747528076172
Batch 50/64 loss: 0.240744948387146
Batch 51/64 loss: 0.22878384590148926
Batch 52/64 loss: 0.2295362949371338
Batch 53/64 loss: 0.22964727878570557
Batch 54/64 loss: 0.22127294540405273
Batch 55/64 loss: 0.22486937046051025
Batch 56/64 loss: 0.23493421077728271
Batch 57/64 loss: 0.2404821515083313
Batch 58/64 loss: 0.22082382440567017
Batch 59/64 loss: 0.2206745743751526
Batch 60/64 loss: 0.22388005256652832
Batch 61/64 loss: 0.22517085075378418
Batch 62/64 loss: 0.23330962657928467
Batch 63/64 loss: 0.22702187299728394
Batch 64/64 loss: 0.2318832278251648
Epoch 461  Train loss: 0.2264831592054928  Val loss: 0.28215581199147854
Epoch 462
-------------------------------
Batch 1/64 loss: 0.22814804315567017
Batch 2/64 loss: 0.226068377494812
Batch 3/64 loss: 0.2301039695739746
Batch 4/64 loss: 0.22262024879455566
Batch 5/64 loss: 0.21990430355072021
Batch 6/64 loss: 0.2194681167602539
Batch 7/64 loss: 0.22426003217697144
Batch 8/64 loss: 0.23123371601104736
Batch 9/64 loss: 0.22931039333343506
Batch 10/64 loss: 0.22319751977920532
Batch 11/64 loss: 0.2243461012840271
Batch 12/64 loss: 0.2334609031677246
Batch 13/64 loss: 0.22803795337677002
Batch 14/64 loss: 0.23182344436645508
Batch 15/64 loss: 0.2273784875869751
Batch 16/64 loss: 0.2224874496459961
Batch 17/64 loss: 0.22110521793365479
Batch 18/64 loss: 0.2252591848373413
Batch 19/64 loss: 0.223393976688385
Batch 20/64 loss: 0.2192981243133545
Batch 21/64 loss: 0.22984904050827026
Batch 22/64 loss: 0.2218623161315918
Batch 23/64 loss: 0.21593761444091797
Batch 24/64 loss: 0.23312807083129883
Batch 25/64 loss: 0.2306821346282959
Batch 26/64 loss: 0.22433161735534668
Batch 27/64 loss: 0.2207632064819336
Batch 28/64 loss: 0.22282588481903076
Batch 29/64 loss: 0.22302186489105225
Batch 30/64 loss: 0.22372853755950928
Batch 31/64 loss: 0.23304951190948486
Batch 32/64 loss: 0.230296790599823
Batch 33/64 loss: 0.22499752044677734
Batch 34/64 loss: 0.23244166374206543
Batch 35/64 loss: 0.21574050188064575
Batch 36/64 loss: 0.2299625277519226
Batch 37/64 loss: 0.2188631296157837
Batch 38/64 loss: 0.23020827770233154
Batch 39/64 loss: 0.22607851028442383
Batch 40/64 loss: 0.2258152961730957
Batch 41/64 loss: 0.24705147743225098
Batch 42/64 loss: 0.2193899154663086
Batch 43/64 loss: 0.22517579793930054
Batch 44/64 loss: 0.2266334891319275
Batch 45/64 loss: 0.2300865650177002
Batch 46/64 loss: 0.2359088659286499
Batch 47/64 loss: 0.23023450374603271
Batch 48/64 loss: 0.21982288360595703
Batch 49/64 loss: 0.22474700212478638
Batch 50/64 loss: 0.23442834615707397
Batch 51/64 loss: 0.2305288314819336
Batch 52/64 loss: 0.23021924495697021
Batch 53/64 loss: 0.22057461738586426
Batch 54/64 loss: 0.2235879898071289
Batch 55/64 loss: 0.22643709182739258
Batch 56/64 loss: 0.23668283224105835
Batch 57/64 loss: 0.22512352466583252
Batch 58/64 loss: 0.23524212837219238
Batch 59/64 loss: 0.22398746013641357
Batch 60/64 loss: 0.22823995351791382
Batch 61/64 loss: 0.22942817211151123
Batch 62/64 loss: 0.2345668077468872
Batch 63/64 loss: 0.22299808263778687
Batch 64/64 loss: 0.23353230953216553
Epoch 462  Train loss: 0.22683504936741847  Val loss: 0.28108666217613876
Epoch 463
-------------------------------
Batch 1/64 loss: 0.2241075038909912
Batch 2/64 loss: 0.22298598289489746
Batch 3/64 loss: 0.22550129890441895
Batch 4/64 loss: 0.2190966010093689
Batch 5/64 loss: 0.2262253761291504
Batch 6/64 loss: 0.23303759098052979
Batch 7/64 loss: 0.22192370891571045
Batch 8/64 loss: 0.2210216522216797
Batch 9/64 loss: 0.22451400756835938
Batch 10/64 loss: 0.22219383716583252
Batch 11/64 loss: 0.2204989194869995
Batch 12/64 loss: 0.21743261814117432
Batch 13/64 loss: 0.24280321598052979
Batch 14/64 loss: 0.23024344444274902
Batch 15/64 loss: 0.21791911125183105
Batch 16/64 loss: 0.21489256620407104
Batch 17/64 loss: 0.21416819095611572
Batch 18/64 loss: 0.22205281257629395
Batch 19/64 loss: 0.22275912761688232
Batch 20/64 loss: 0.22473686933517456
Batch 21/64 loss: 0.22761857509613037
Batch 22/64 loss: 0.2228037714958191
Batch 23/64 loss: 0.23238539695739746
Batch 24/64 loss: 0.22957485914230347
Batch 25/64 loss: 0.21604013442993164
Batch 26/64 loss: 0.22306174039840698
Batch 27/64 loss: 0.22169411182403564
Batch 28/64 loss: 0.22650539875030518
Batch 29/64 loss: 0.22313177585601807
Batch 30/64 loss: 0.22275006771087646
Batch 31/64 loss: 0.22191143035888672
Batch 32/64 loss: 0.22141754627227783
Batch 33/64 loss: 0.24123036861419678
Batch 34/64 loss: 0.2397938370704651
Batch 35/64 loss: 0.22288095951080322
Batch 36/64 loss: 0.22454190254211426
Batch 37/64 loss: 0.22379827499389648
Batch 38/64 loss: 0.23270893096923828
Batch 39/64 loss: 0.22376275062561035
Batch 40/64 loss: 0.23976492881774902
Batch 41/64 loss: 0.23080921173095703
Batch 42/64 loss: 0.2319135069847107
Batch 43/64 loss: 0.22151398658752441
Batch 44/64 loss: 0.22584879398345947
Batch 45/64 loss: 0.22877800464630127
Batch 46/64 loss: 0.2253502607345581
Batch 47/64 loss: 0.2323400378227234
Batch 48/64 loss: 0.23553407192230225
Batch 49/64 loss: 0.23512840270996094
Batch 50/64 loss: 0.22774899005889893
Batch 51/64 loss: 0.23569905757904053
Batch 52/64 loss: 0.23188817501068115
Batch 53/64 loss: 0.22349786758422852
Batch 54/64 loss: 0.23378586769104004
Batch 55/64 loss: 0.22258174419403076
Batch 56/64 loss: 0.2326241135597229
Batch 57/64 loss: 0.22435593605041504
Batch 58/64 loss: 0.22763824462890625
Batch 59/64 loss: 0.22719579935073853
Batch 60/64 loss: 0.2260040044784546
Batch 61/64 loss: 0.2182697057723999
Batch 62/64 loss: 0.2278907299041748
Batch 63/64 loss: 0.2246895432472229
Batch 64/64 loss: 0.230491042137146
Epoch 463  Train loss: 0.22634424368540446  Val loss: 0.28159093713432654
Epoch 464
-------------------------------
Batch 1/64 loss: 0.22634565830230713
Batch 2/64 loss: 0.2196827530860901
Batch 3/64 loss: 0.21550321578979492
Batch 4/64 loss: 0.22584295272827148
Batch 5/64 loss: 0.2258901596069336
Batch 6/64 loss: 0.2213405966758728
Batch 7/64 loss: 0.23253607749938965
Batch 8/64 loss: 0.23698925971984863
Batch 9/64 loss: 0.24268507957458496
Batch 10/64 loss: 0.2174631953239441
Batch 11/64 loss: 0.21997052431106567
Batch 12/64 loss: 0.24240779876708984
Batch 13/64 loss: 0.2245577573776245
Batch 14/64 loss: 0.2253696322441101
Batch 15/64 loss: 0.22303080558776855
Batch 16/64 loss: 0.2366344928741455
Batch 17/64 loss: 0.22579866647720337
Batch 18/64 loss: 0.22165930271148682
Batch 19/64 loss: 0.22620165348052979
Batch 20/64 loss: 0.2247328758239746
Batch 21/64 loss: 0.2267817258834839
Batch 22/64 loss: 0.22762823104858398
Batch 23/64 loss: 0.22022908926010132
Batch 24/64 loss: 0.22476541996002197
Batch 25/64 loss: 0.224298357963562
Batch 26/64 loss: 0.235248863697052
Batch 27/64 loss: 0.23211795091629028
Batch 28/64 loss: 0.22561275959014893
Batch 29/64 loss: 0.22571885585784912
Batch 30/64 loss: 0.22730344533920288
Batch 31/64 loss: 0.2198917269706726
Batch 32/64 loss: 0.223419189453125
Batch 33/64 loss: 0.2239817976951599
Batch 34/64 loss: 0.22335565090179443
Batch 35/64 loss: 0.23505079746246338
Batch 36/64 loss: 0.22927320003509521
Batch 37/64 loss: 0.2217056155204773
Batch 38/64 loss: 0.2219768762588501
Batch 39/64 loss: 0.2270970344543457
Batch 40/64 loss: 0.24123477935791016
Batch 41/64 loss: 0.21762537956237793
Batch 42/64 loss: 0.23131942749023438
Batch 43/64 loss: 0.2191140055656433
Batch 44/64 loss: 0.23244047164916992
Batch 45/64 loss: 0.2306746244430542
Batch 46/64 loss: 0.23082983493804932
Batch 47/64 loss: 0.22639310359954834
Batch 48/64 loss: 0.22661727666854858
Batch 49/64 loss: 0.22384941577911377
Batch 50/64 loss: 0.22634756565093994
Batch 51/64 loss: 0.23481082916259766
Batch 52/64 loss: 0.2302919626235962
Batch 53/64 loss: 0.2292037010192871
Batch 54/64 loss: 0.22813916206359863
Batch 55/64 loss: 0.22736245393753052
Batch 56/64 loss: 0.2226848006248474
Batch 57/64 loss: 0.23553967475891113
Batch 58/64 loss: 0.2260751724243164
Batch 59/64 loss: 0.22082006931304932
Batch 60/64 loss: 0.22274696826934814
Batch 61/64 loss: 0.232047438621521
Batch 62/64 loss: 0.23108237981796265
Batch 63/64 loss: 0.23805862665176392
Batch 64/64 loss: 0.21774089336395264
Epoch 464  Train loss: 0.22711707984699922  Val loss: 0.28117736754138856
Epoch 465
-------------------------------
Batch 1/64 loss: 0.21914899349212646
Batch 2/64 loss: 0.22323203086853027
Batch 3/64 loss: 0.22395575046539307
Batch 4/64 loss: 0.23699599504470825
Batch 5/64 loss: 0.23023635149002075
Batch 6/64 loss: 0.2242603898048401
Batch 7/64 loss: 0.22221732139587402
Batch 8/64 loss: 0.22253292798995972
Batch 9/64 loss: 0.22118139266967773
Batch 10/64 loss: 0.2331463098526001
Batch 11/64 loss: 0.21995079517364502
Batch 12/64 loss: 0.22112834453582764
Batch 13/64 loss: 0.22012078762054443
Batch 14/64 loss: 0.22612226009368896
Batch 15/64 loss: 0.22025805711746216
Batch 16/64 loss: 0.23175400495529175
Batch 17/64 loss: 0.23099076747894287
Batch 18/64 loss: 0.2344425916671753
Batch 19/64 loss: 0.22879159450531006
Batch 20/64 loss: 0.21749085187911987
Batch 21/64 loss: 0.2226395606994629
Batch 22/64 loss: 0.221967875957489
Batch 23/64 loss: 0.22595560550689697
Batch 24/64 loss: 0.22620368003845215
Batch 25/64 loss: 0.23875242471694946
Batch 26/64 loss: 0.22299927473068237
Batch 27/64 loss: 0.2340889573097229
Batch 28/64 loss: 0.2245863676071167
Batch 29/64 loss: 0.22557741403579712
Batch 30/64 loss: 0.22585201263427734
Batch 31/64 loss: 0.23692762851715088
Batch 32/64 loss: 0.22169369459152222
Batch 33/64 loss: 0.2269124984741211
Batch 34/64 loss: 0.22802412509918213
Batch 35/64 loss: 0.22767490148544312
Batch 36/64 loss: 0.226762592792511
Batch 37/64 loss: 0.23567748069763184
Batch 38/64 loss: 0.2236202359199524
Batch 39/64 loss: 0.23404324054718018
Batch 40/64 loss: 0.22234678268432617
Batch 41/64 loss: 0.23344242572784424
Batch 42/64 loss: 0.2133195400238037
Batch 43/64 loss: 0.22638261318206787
Batch 44/64 loss: 0.22535663843154907
Batch 45/64 loss: 0.2254863977432251
Batch 46/64 loss: 0.22401005029678345
Batch 47/64 loss: 0.22577565908432007
Batch 48/64 loss: 0.22476375102996826
Batch 49/64 loss: 0.22111254930496216
Batch 50/64 loss: 0.2285265326499939
Batch 51/64 loss: 0.22153830528259277
Batch 52/64 loss: 0.22021734714508057
Batch 53/64 loss: 0.220253586769104
Batch 54/64 loss: 0.22822177410125732
Batch 55/64 loss: 0.23657041788101196
Batch 56/64 loss: 0.21765589714050293
Batch 57/64 loss: 0.2214159369468689
Batch 58/64 loss: 0.23376011848449707
Batch 59/64 loss: 0.23058390617370605
Batch 60/64 loss: 0.2227022647857666
Batch 61/64 loss: 0.22450774908065796
Batch 62/64 loss: 0.2396456003189087
Batch 63/64 loss: 0.2152719497680664
Batch 64/64 loss: 0.21443116664886475
Epoch 465  Train loss: 0.22590758052526735  Val loss: 0.2821250846705486
Epoch 466
-------------------------------
Batch 1/64 loss: 0.2238140106201172
Batch 2/64 loss: 0.2339998483657837
Batch 3/64 loss: 0.22431886196136475
Batch 4/64 loss: 0.22862482070922852
Batch 5/64 loss: 0.217917799949646
Batch 6/64 loss: 0.22422736883163452
Batch 7/64 loss: 0.21149325370788574
Batch 8/64 loss: 0.2258915901184082
Batch 9/64 loss: 0.21984446048736572
Batch 10/64 loss: 0.22959136962890625
Batch 11/64 loss: 0.2203386425971985
Batch 12/64 loss: 0.22499918937683105
Batch 13/64 loss: 0.22877728939056396
Batch 14/64 loss: 0.2293500304222107
Batch 15/64 loss: 0.21519047021865845
Batch 16/64 loss: 0.23372960090637207
Batch 17/64 loss: 0.22715818881988525
Batch 18/64 loss: 0.23448103666305542
Batch 19/64 loss: 0.21987789869308472
Batch 20/64 loss: 0.2292804718017578
Batch 21/64 loss: 0.2167109251022339
Batch 22/64 loss: 0.23320508003234863
Batch 23/64 loss: 0.2314298152923584
Batch 24/64 loss: 0.22131597995758057
Batch 25/64 loss: 0.23066198825836182
Batch 26/64 loss: 0.2155480980873108
Batch 27/64 loss: 0.22735488414764404
Batch 28/64 loss: 0.23138892650604248
Batch 29/64 loss: 0.2178424596786499
Batch 30/64 loss: 0.22622287273406982
Batch 31/64 loss: 0.22471225261688232
Batch 32/64 loss: 0.22938692569732666
Batch 33/64 loss: 0.2221319079399109
Batch 34/64 loss: 0.21966814994812012
Batch 35/64 loss: 0.21714258193969727
Batch 36/64 loss: 0.2395504117012024
Batch 37/64 loss: 0.22046375274658203
Batch 38/64 loss: 0.22918391227722168
Batch 39/64 loss: 0.2211245894432068
Batch 40/64 loss: 0.232163667678833
Batch 41/64 loss: 0.23401862382888794
Batch 42/64 loss: 0.21881729364395142
Batch 43/64 loss: 0.21476376056671143
Batch 44/64 loss: 0.22124183177947998
Batch 45/64 loss: 0.23142606019973755
Batch 46/64 loss: 0.22813540697097778
Batch 47/64 loss: 0.22863030433654785
Batch 48/64 loss: 0.2208680510520935
Batch 49/64 loss: 0.22424566745758057
Batch 50/64 loss: 0.21972906589508057
Batch 51/64 loss: 0.22485852241516113
Batch 52/64 loss: 0.22844147682189941
Batch 53/64 loss: 0.2410762906074524
Batch 54/64 loss: 0.22314167022705078
Batch 55/64 loss: 0.23405778408050537
Batch 56/64 loss: 0.2245655655860901
Batch 57/64 loss: 0.23445361852645874
Batch 58/64 loss: 0.23662930727005005
Batch 59/64 loss: 0.2250605821609497
Batch 60/64 loss: 0.2452947497367859
Batch 61/64 loss: 0.23055851459503174
Batch 62/64 loss: 0.23625564575195312
Batch 63/64 loss: 0.22948861122131348
Batch 64/64 loss: 0.22715765237808228
Epoch 466  Train loss: 0.22645085535797418  Val loss: 0.2813395970465801
Epoch 467
-------------------------------
Batch 1/64 loss: 0.23612916469573975
Batch 2/64 loss: 0.22747421264648438
Batch 3/64 loss: 0.23246431350708008
Batch 4/64 loss: 0.2361236810684204
Batch 5/64 loss: 0.22730785608291626
Batch 6/64 loss: 0.23414891958236694
Batch 7/64 loss: 0.22640275955200195
Batch 8/64 loss: 0.2177335023880005
Batch 9/64 loss: 0.21912431716918945
Batch 10/64 loss: 0.22468125820159912
Batch 11/64 loss: 0.22943490743637085
Batch 12/64 loss: 0.22091925144195557
Batch 13/64 loss: 0.2269648313522339
Batch 14/64 loss: 0.21717047691345215
Batch 15/64 loss: 0.22478699684143066
Batch 16/64 loss: 0.21939319372177124
Batch 17/64 loss: 0.2317650318145752
Batch 18/64 loss: 0.21464753150939941
Batch 19/64 loss: 0.22441554069519043
Batch 20/64 loss: 0.21358299255371094
Batch 21/64 loss: 0.2192072868347168
Batch 22/64 loss: 0.2192280888557434
Batch 23/64 loss: 0.22827982902526855
Batch 24/64 loss: 0.21914607286453247
Batch 25/64 loss: 0.2233394980430603
Batch 26/64 loss: 0.22287321090698242
Batch 27/64 loss: 0.22591102123260498
Batch 28/64 loss: 0.2270679473876953
Batch 29/64 loss: 0.22712862491607666
Batch 30/64 loss: 0.22076517343521118
Batch 31/64 loss: 0.23593109846115112
Batch 32/64 loss: 0.23041129112243652
Batch 33/64 loss: 0.22365713119506836
Batch 34/64 loss: 0.2218167781829834
Batch 35/64 loss: 0.24029171466827393
Batch 36/64 loss: 0.21888530254364014
Batch 37/64 loss: 0.22621697187423706
Batch 38/64 loss: 0.22491979598999023
Batch 39/64 loss: 0.2312580943107605
Batch 40/64 loss: 0.2240428924560547
Batch 41/64 loss: 0.22497212886810303
Batch 42/64 loss: 0.22107219696044922
Batch 43/64 loss: 0.21946096420288086
Batch 44/64 loss: 0.21693706512451172
Batch 45/64 loss: 0.253157377243042
Batch 46/64 loss: 0.22962844371795654
Batch 47/64 loss: 0.22209447622299194
Batch 48/64 loss: 0.22668206691741943
Batch 49/64 loss: 0.23129487037658691
Batch 50/64 loss: 0.23861545324325562
Batch 51/64 loss: 0.22602200508117676
Batch 52/64 loss: 0.23563337326049805
Batch 53/64 loss: 0.22010022401809692
Batch 54/64 loss: 0.21509671211242676
Batch 55/64 loss: 0.23530149459838867
Batch 56/64 loss: 0.2280319333076477
Batch 57/64 loss: 0.22117984294891357
Batch 58/64 loss: 0.21998149156570435
Batch 59/64 loss: 0.2222151756286621
Batch 60/64 loss: 0.21273291110992432
Batch 61/64 loss: 0.24342310428619385
Batch 62/64 loss: 0.23044371604919434
Batch 63/64 loss: 0.21658611297607422
Batch 64/64 loss: 0.22610265016555786
Epoch 467  Train loss: 0.2258084500537199  Val loss: 0.28159725502184574
Epoch 468
-------------------------------
Batch 1/64 loss: 0.2185605764389038
Batch 2/64 loss: 0.22922104597091675
Batch 3/64 loss: 0.2219473123550415
Batch 4/64 loss: 0.2257344126701355
Batch 5/64 loss: 0.2378825545310974
Batch 6/64 loss: 0.22361135482788086
Batch 7/64 loss: 0.22422611713409424
Batch 8/64 loss: 0.22095012664794922
Batch 9/64 loss: 0.22983300685882568
Batch 10/64 loss: 0.22302836179733276
Batch 11/64 loss: 0.25275570154190063
Batch 12/64 loss: 0.2295987606048584
Batch 13/64 loss: 0.21952462196350098
Batch 14/64 loss: 0.22665202617645264
Batch 15/64 loss: 0.23727381229400635
Batch 16/64 loss: 0.22363364696502686
Batch 17/64 loss: 0.22579795122146606
Batch 18/64 loss: 0.23131251335144043
Batch 19/64 loss: 0.2314702272415161
Batch 20/64 loss: 0.22442877292633057
Batch 21/64 loss: 0.22553682327270508
Batch 22/64 loss: 0.22946250438690186
Batch 23/64 loss: 0.2262566089630127
Batch 24/64 loss: 0.22657793760299683
Batch 25/64 loss: 0.2331911325454712
Batch 26/64 loss: 0.2321825623512268
Batch 27/64 loss: 0.2310335636138916
Batch 28/64 loss: 0.2187972068786621
Batch 29/64 loss: 0.24155759811401367
Batch 30/64 loss: 0.23353737592697144
Batch 31/64 loss: 0.22018438577651978
Batch 32/64 loss: 0.22552227973937988
Batch 33/64 loss: 0.22466444969177246
Batch 34/64 loss: 0.21745407581329346
Batch 35/64 loss: 0.23024272918701172
Batch 36/64 loss: 0.22118067741394043
Batch 37/64 loss: 0.22709506750106812
Batch 38/64 loss: 0.2314743995666504
Batch 39/64 loss: 0.21626532077789307
Batch 40/64 loss: 0.2266063690185547
Batch 41/64 loss: 0.2397845983505249
Batch 42/64 loss: 0.21628957986831665
Batch 43/64 loss: 0.22258365154266357
Batch 44/64 loss: 0.22435086965560913
Batch 45/64 loss: 0.21821439266204834
Batch 46/64 loss: 0.22061508893966675
Batch 47/64 loss: 0.2266472578048706
Batch 48/64 loss: 0.22158712148666382
Batch 49/64 loss: 0.23886197805404663
Batch 50/64 loss: 0.219948410987854
Batch 51/64 loss: 0.21869242191314697
Batch 52/64 loss: 0.22429585456848145
Batch 53/64 loss: 0.21416527032852173
Batch 54/64 loss: 0.21857857704162598
Batch 55/64 loss: 0.22584205865859985
Batch 56/64 loss: 0.21767163276672363
Batch 57/64 loss: 0.2247227430343628
Batch 58/64 loss: 0.22482240200042725
Batch 59/64 loss: 0.22961753606796265
Batch 60/64 loss: 0.23598551750183105
Batch 61/64 loss: 0.23140722513198853
Batch 62/64 loss: 0.22680127620697021
Batch 63/64 loss: 0.22489511966705322
Batch 64/64 loss: 0.22652506828308105
Epoch 468  Train loss: 0.22639278991549622  Val loss: 0.28204831306877004
Epoch 469
-------------------------------
Batch 1/64 loss: 0.22228586673736572
Batch 2/64 loss: 0.22437846660614014
Batch 3/64 loss: 0.21689271926879883
Batch 4/64 loss: 0.22324252128601074
Batch 5/64 loss: 0.23084759712219238
Batch 6/64 loss: 0.23234045505523682
Batch 7/64 loss: 0.22116267681121826
Batch 8/64 loss: 0.21447360515594482
Batch 9/64 loss: 0.22470200061798096
Batch 10/64 loss: 0.2158326506614685
Batch 11/64 loss: 0.22000986337661743
Batch 12/64 loss: 0.23751318454742432
Batch 13/64 loss: 0.21995127201080322
Batch 14/64 loss: 0.224137544631958
Batch 15/64 loss: 0.23919618129730225
Batch 16/64 loss: 0.2206634283065796
Batch 17/64 loss: 0.22968488931655884
Batch 18/64 loss: 0.2386900782585144
Batch 19/64 loss: 0.23058712482452393
Batch 20/64 loss: 0.21875780820846558
Batch 21/64 loss: 0.21917414665222168
Batch 22/64 loss: 0.2340087890625
Batch 23/64 loss: 0.2305411696434021
Batch 24/64 loss: 0.22497832775115967
Batch 25/64 loss: 0.21570974588394165
Batch 26/64 loss: 0.22222959995269775
Batch 27/64 loss: 0.21681398153305054
Batch 28/64 loss: 0.21502119302749634
Batch 29/64 loss: 0.22452658414840698
Batch 30/64 loss: 0.22471106052398682
Batch 31/64 loss: 0.21814841032028198
Batch 32/64 loss: 0.22564446926116943
Batch 33/64 loss: 0.244672954082489
Batch 34/64 loss: 0.22471493482589722
Batch 35/64 loss: 0.2288246750831604
Batch 36/64 loss: 0.21870744228363037
Batch 37/64 loss: 0.22757488489151
Batch 38/64 loss: 0.23328369855880737
Batch 39/64 loss: 0.22104144096374512
Batch 40/64 loss: 0.2277926206588745
Batch 41/64 loss: 0.22425520420074463
Batch 42/64 loss: 0.23185491561889648
Batch 43/64 loss: 0.22926300764083862
Batch 44/64 loss: 0.23138642311096191
Batch 45/64 loss: 0.22845542430877686
Batch 46/64 loss: 0.21829617023468018
Batch 47/64 loss: 0.22823011875152588
Batch 48/64 loss: 0.22574365139007568
Batch 49/64 loss: 0.22992026805877686
Batch 50/64 loss: 0.2315962314605713
Batch 51/64 loss: 0.2236717939376831
Batch 52/64 loss: 0.23200321197509766
Batch 53/64 loss: 0.23041069507598877
Batch 54/64 loss: 0.23586928844451904
Batch 55/64 loss: 0.2254260778427124
Batch 56/64 loss: 0.2219616174697876
Batch 57/64 loss: 0.22830462455749512
Batch 58/64 loss: 0.2197338342666626
Batch 59/64 loss: 0.2364165186882019
Batch 60/64 loss: 0.22257351875305176
Batch 61/64 loss: 0.22218888998031616
Batch 62/64 loss: 0.22354382276535034
Batch 63/64 loss: 0.21998149156570435
Batch 64/64 loss: 0.23853492736816406
Epoch 469  Train loss: 0.22593659700131885  Val loss: 0.28196235866481084
Epoch 470
-------------------------------
Batch 1/64 loss: 0.22083771228790283
Batch 2/64 loss: 0.21804720163345337
Batch 3/64 loss: 0.22893470525741577
Batch 4/64 loss: 0.22865957021713257
Batch 5/64 loss: 0.23026597499847412
Batch 6/64 loss: 0.2299196720123291
Batch 7/64 loss: 0.227580726146698
Batch 8/64 loss: 0.21902340650558472
Batch 9/64 loss: 0.23143965005874634
Batch 10/64 loss: 0.23048043251037598
Batch 11/64 loss: 0.22242718935012817
Batch 12/64 loss: 0.22298544645309448
Batch 13/64 loss: 0.22095823287963867
Batch 14/64 loss: 0.22621029615402222
Batch 15/64 loss: 0.21707475185394287
Batch 16/64 loss: 0.22569870948791504
Batch 17/64 loss: 0.23376482725143433
Batch 18/64 loss: 0.21384131908416748
Batch 19/64 loss: 0.2207028865814209
Batch 20/64 loss: 0.23238146305084229
Batch 21/64 loss: 0.2136002779006958
Batch 22/64 loss: 0.22517997026443481
Batch 23/64 loss: 0.21388030052185059
Batch 24/64 loss: 0.23142147064208984
Batch 25/64 loss: 0.231475830078125
Batch 26/64 loss: 0.2234034538269043
Batch 27/64 loss: 0.22713440656661987
Batch 28/64 loss: 0.22982454299926758
Batch 29/64 loss: 0.22561895847320557
Batch 30/64 loss: 0.22502565383911133
Batch 31/64 loss: 0.2247256636619568
Batch 32/64 loss: 0.22922372817993164
Batch 33/64 loss: 0.22922730445861816
Batch 34/64 loss: 0.23199349641799927
Batch 35/64 loss: 0.21614909172058105
Batch 36/64 loss: 0.2232893705368042
Batch 37/64 loss: 0.21915149688720703
Batch 38/64 loss: 0.2164880633354187
Batch 39/64 loss: 0.2148360013961792
Batch 40/64 loss: 0.23495721817016602
Batch 41/64 loss: 0.22139155864715576
Batch 42/64 loss: 0.2226560115814209
Batch 43/64 loss: 0.23080486059188843
Batch 44/64 loss: 0.2295929193496704
Batch 45/64 loss: 0.22231483459472656
Batch 46/64 loss: 0.2248241901397705
Batch 47/64 loss: 0.22199273109436035
Batch 48/64 loss: 0.22033488750457764
Batch 49/64 loss: 0.22349578142166138
Batch 50/64 loss: 0.2254422903060913
Batch 51/64 loss: 0.220406174659729
Batch 52/64 loss: 0.23021328449249268
Batch 53/64 loss: 0.22340905666351318
Batch 54/64 loss: 0.230496346950531
Batch 55/64 loss: 0.23884505033493042
Batch 56/64 loss: 0.22529292106628418
Batch 57/64 loss: 0.22906959056854248
Batch 58/64 loss: 0.22279250621795654
Batch 59/64 loss: 0.2369251251220703
Batch 60/64 loss: 0.23209869861602783
Batch 61/64 loss: 0.2442481517791748
Batch 62/64 loss: 0.2152082920074463
Batch 63/64 loss: 0.22501683235168457
Batch 64/64 loss: 0.22293245792388916
Epoch 470  Train loss: 0.22544175550049428  Val loss: 0.28247198370314136
Epoch 471
-------------------------------
Batch 1/64 loss: 0.22853469848632812
Batch 2/64 loss: 0.22594225406646729
Batch 3/64 loss: 0.21415019035339355
Batch 4/64 loss: 0.22570013999938965
Batch 5/64 loss: 0.23343634605407715
Batch 6/64 loss: 0.2246692180633545
Batch 7/64 loss: 0.22938954830169678
Batch 8/64 loss: 0.2213355302810669
Batch 9/64 loss: 0.23002535104751587
Batch 10/64 loss: 0.21988964080810547
Batch 11/64 loss: 0.22785604000091553
Batch 12/64 loss: 0.22292983531951904
Batch 13/64 loss: 0.2236083745956421
Batch 14/64 loss: 0.22347211837768555
Batch 15/64 loss: 0.22729498147964478
Batch 16/64 loss: 0.22570717334747314
Batch 17/64 loss: 0.22591924667358398
Batch 18/64 loss: 0.22880250215530396
Batch 19/64 loss: 0.2238454818725586
Batch 20/64 loss: 0.2370167374610901
Batch 21/64 loss: 0.23413914442062378
Batch 22/64 loss: 0.2208322286605835
Batch 23/64 loss: 0.21620452404022217
Batch 24/64 loss: 0.22021973133087158
Batch 25/64 loss: 0.22376108169555664
Batch 26/64 loss: 0.21794992685317993
Batch 27/64 loss: 0.2219867706298828
Batch 28/64 loss: 0.2232176661491394
Batch 29/64 loss: 0.22084474563598633
Batch 30/64 loss: 0.2221604585647583
Batch 31/64 loss: 0.22418087720870972
Batch 32/64 loss: 0.2274845838546753
Batch 33/64 loss: 0.22289466857910156
Batch 34/64 loss: 0.22247552871704102
Batch 35/64 loss: 0.21916431188583374
Batch 36/64 loss: 0.22347891330718994
Batch 37/64 loss: 0.2228667140007019
Batch 38/64 loss: 0.22655975818634033
Batch 39/64 loss: 0.23981159925460815
Batch 40/64 loss: 0.22668778896331787
Batch 41/64 loss: 0.22900784015655518
Batch 42/64 loss: 0.23996460437774658
Batch 43/64 loss: 0.23313236236572266
Batch 44/64 loss: 0.2336496114730835
Batch 45/64 loss: 0.22930318117141724
Batch 46/64 loss: 0.2318798303604126
Batch 47/64 loss: 0.22449028491973877
Batch 48/64 loss: 0.24060380458831787
Batch 49/64 loss: 0.2293795347213745
Batch 50/64 loss: 0.22736752033233643
Batch 51/64 loss: 0.23074334859848022
Batch 52/64 loss: 0.22865140438079834
Batch 53/64 loss: 0.2282894253730774
Batch 54/64 loss: 0.22267580032348633
Batch 55/64 loss: 0.23243677616119385
Batch 56/64 loss: 0.22490227222442627
Batch 57/64 loss: 0.23163282871246338
Batch 58/64 loss: 0.21521294116973877
Batch 59/64 loss: 0.22820669412612915
Batch 60/64 loss: 0.22430062294006348
Batch 61/64 loss: 0.23246824741363525
Batch 62/64 loss: 0.21945041418075562
Batch 63/64 loss: 0.22977709770202637
Batch 64/64 loss: 0.2319667935371399
Epoch 471  Train loss: 0.22647761527229757  Val loss: 0.28135067716087264
Epoch 472
-------------------------------
Batch 1/64 loss: 0.22222155332565308
Batch 2/64 loss: 0.23535895347595215
Batch 3/64 loss: 0.22650182247161865
Batch 4/64 loss: 0.22034019231796265
Batch 5/64 loss: 0.21689385175704956
Batch 6/64 loss: 0.22875583171844482
Batch 7/64 loss: 0.2232799530029297
Batch 8/64 loss: 0.22573018074035645
Batch 9/64 loss: 0.22684544324874878
Batch 10/64 loss: 0.22312963008880615
Batch 11/64 loss: 0.22500133514404297
Batch 12/64 loss: 0.23304474353790283
Batch 13/64 loss: 0.22300875186920166
Batch 14/64 loss: 0.21895897388458252
Batch 15/64 loss: 0.2242441177368164
Batch 16/64 loss: 0.22101294994354248
Batch 17/64 loss: 0.2220989465713501
Batch 18/64 loss: 0.22945642471313477
Batch 19/64 loss: 0.22149038314819336
Batch 20/64 loss: 0.21681785583496094
Batch 21/64 loss: 0.22488975524902344
Batch 22/64 loss: 0.21570026874542236
Batch 23/64 loss: 0.21976184844970703
Batch 24/64 loss: 0.22435474395751953
Batch 25/64 loss: 0.2339574098587036
Batch 26/64 loss: 0.22610580921173096
Batch 27/64 loss: 0.22463297843933105
Batch 28/64 loss: 0.2235041856765747
Batch 29/64 loss: 0.22478514909744263
Batch 30/64 loss: 0.22344034910202026
Batch 31/64 loss: 0.2198265790939331
Batch 32/64 loss: 0.22807717323303223
Batch 33/64 loss: 0.24363189935684204
Batch 34/64 loss: 0.22085189819335938
Batch 35/64 loss: 0.21526575088500977
Batch 36/64 loss: 0.22819066047668457
Batch 37/64 loss: 0.22546321153640747
Batch 38/64 loss: 0.21410489082336426
Batch 39/64 loss: 0.2338651418685913
Batch 40/64 loss: 0.2177344560623169
Batch 41/64 loss: 0.22985851764678955
Batch 42/64 loss: 0.22867119312286377
Batch 43/64 loss: 0.23194754123687744
Batch 44/64 loss: 0.21536612510681152
Batch 45/64 loss: 0.23365700244903564
Batch 46/64 loss: 0.22541671991348267
Batch 47/64 loss: 0.22785526514053345
Batch 48/64 loss: 0.224048912525177
Batch 49/64 loss: 0.21989643573760986
Batch 50/64 loss: 0.24050581455230713
Batch 51/64 loss: 0.22902941703796387
Batch 52/64 loss: 0.22848641872406006
Batch 53/64 loss: 0.2153174877166748
Batch 54/64 loss: 0.22170579433441162
Batch 55/64 loss: 0.23952561616897583
Batch 56/64 loss: 0.22973370552062988
Batch 57/64 loss: 0.23199403285980225
Batch 58/64 loss: 0.23424690961837769
Batch 59/64 loss: 0.22353345155715942
Batch 60/64 loss: 0.23208343982696533
Batch 61/64 loss: 0.22979503870010376
Batch 62/64 loss: 0.22602593898773193
Batch 63/64 loss: 0.23085105419158936
Batch 64/64 loss: 0.22487056255340576
Epoch 472  Train loss: 0.2257339734657138  Val loss: 0.28185799769109876
Epoch 473
-------------------------------
Batch 1/64 loss: 0.22826576232910156
Batch 2/64 loss: 0.22308385372161865
Batch 3/64 loss: 0.22317755222320557
Batch 4/64 loss: 0.22736799716949463
Batch 5/64 loss: 0.23421800136566162
Batch 6/64 loss: 0.23008400201797485
Batch 7/64 loss: 0.22441792488098145
Batch 8/64 loss: 0.21774756908416748
Batch 9/64 loss: 0.22125470638275146
Batch 10/64 loss: 0.22170889377593994
Batch 11/64 loss: 0.2127685546875
Batch 12/64 loss: 0.22620141506195068
Batch 13/64 loss: 0.24339914321899414
Batch 14/64 loss: 0.2253442406654358
Batch 15/64 loss: 0.21889030933380127
Batch 16/64 loss: 0.2223968505859375
Batch 17/64 loss: 0.22203922271728516
Batch 18/64 loss: 0.22395604848861694
Batch 19/64 loss: 0.23051995038986206
Batch 20/64 loss: 0.21849769353866577
Batch 21/64 loss: 0.22774982452392578
Batch 22/64 loss: 0.22345447540283203
Batch 23/64 loss: 0.22467082738876343
Batch 24/64 loss: 0.23073923587799072
Batch 25/64 loss: 0.21728944778442383
Batch 26/64 loss: 0.2289387583732605
Batch 27/64 loss: 0.22109508514404297
Batch 28/64 loss: 0.22239118814468384
Batch 29/64 loss: 0.2190731167793274
Batch 30/64 loss: 0.23801368474960327
Batch 31/64 loss: 0.2223987579345703
Batch 32/64 loss: 0.2210935354232788
Batch 33/64 loss: 0.216821551322937
Batch 34/64 loss: 0.22369277477264404
Batch 35/64 loss: 0.22498643398284912
Batch 36/64 loss: 0.21693819761276245
Batch 37/64 loss: 0.22134381532669067
Batch 38/64 loss: 0.21932685375213623
Batch 39/64 loss: 0.22980964183807373
Batch 40/64 loss: 0.22623276710510254
Batch 41/64 loss: 0.22493696212768555
Batch 42/64 loss: 0.2242734432220459
Batch 43/64 loss: 0.21586358547210693
Batch 44/64 loss: 0.22233682870864868
Batch 45/64 loss: 0.2276543378829956
Batch 46/64 loss: 0.23061776161193848
Batch 47/64 loss: 0.2299349308013916
Batch 48/64 loss: 0.2199750542640686
Batch 49/64 loss: 0.22191154956817627
Batch 50/64 loss: 0.2342294454574585
Batch 51/64 loss: 0.2226778268814087
Batch 52/64 loss: 0.22450268268585205
Batch 53/64 loss: 0.22957909107208252
Batch 54/64 loss: 0.22997993230819702
Batch 55/64 loss: 0.22950387001037598
Batch 56/64 loss: 0.2258039116859436
Batch 57/64 loss: 0.23255544900894165
Batch 58/64 loss: 0.21741461753845215
Batch 59/64 loss: 0.2211322784423828
Batch 60/64 loss: 0.2289031744003296
Batch 61/64 loss: 0.22969496250152588
Batch 62/64 loss: 0.2237529158592224
Batch 63/64 loss: 0.22858446836471558
Batch 64/64 loss: 0.2422642707824707
Epoch 473  Train loss: 0.22508105016222188  Val loss: 0.28190840478615253
Epoch 474
-------------------------------
Batch 1/64 loss: 0.2241356372833252
Batch 2/64 loss: 0.2293543815612793
Batch 3/64 loss: 0.22875773906707764
Batch 4/64 loss: 0.22603344917297363
Batch 5/64 loss: 0.22889453172683716
Batch 6/64 loss: 0.22477591037750244
Batch 7/64 loss: 0.22105848789215088
Batch 8/64 loss: 0.21881258487701416
Batch 9/64 loss: 0.22708112001419067
Batch 10/64 loss: 0.2146376371383667
Batch 11/64 loss: 0.21372872591018677
Batch 12/64 loss: 0.23444122076034546
Batch 13/64 loss: 0.23702764511108398
Batch 14/64 loss: 0.23819172382354736
Batch 15/64 loss: 0.22301846742630005
Batch 16/64 loss: 0.23933303356170654
Batch 17/64 loss: 0.22424006462097168
Batch 18/64 loss: 0.2238752841949463
Batch 19/64 loss: 0.23220813274383545
Batch 20/64 loss: 0.23199331760406494
Batch 21/64 loss: 0.23033088445663452
Batch 22/64 loss: 0.22939133644104004
Batch 23/64 loss: 0.23062217235565186
Batch 24/64 loss: 0.21663713455200195
Batch 25/64 loss: 0.2280895709991455
Batch 26/64 loss: 0.22232717275619507
Batch 27/64 loss: 0.221929669380188
Batch 28/64 loss: 0.2175755500793457
Batch 29/64 loss: 0.23003780841827393
Batch 30/64 loss: 0.22284966707229614
Batch 31/64 loss: 0.2367539405822754
Batch 32/64 loss: 0.21775197982788086
Batch 33/64 loss: 0.21404963731765747
Batch 34/64 loss: 0.23122310638427734
Batch 35/64 loss: 0.22937065362930298
Batch 36/64 loss: 0.22441613674163818
Batch 37/64 loss: 0.217063307762146
Batch 38/64 loss: 0.2282087802886963
Batch 39/64 loss: 0.22945129871368408
Batch 40/64 loss: 0.23256587982177734
Batch 41/64 loss: 0.23119056224822998
Batch 42/64 loss: 0.23342221975326538
Batch 43/64 loss: 0.22455453872680664
Batch 44/64 loss: 0.23134416341781616
Batch 45/64 loss: 0.23174965381622314
Batch 46/64 loss: 0.21884918212890625
Batch 47/64 loss: 0.21936583518981934
Batch 48/64 loss: 0.2223849892616272
Batch 49/64 loss: 0.23091602325439453
Batch 50/64 loss: 0.22408068180084229
Batch 51/64 loss: 0.24710845947265625
Batch 52/64 loss: 0.23546576499938965
Batch 53/64 loss: 0.22311115264892578
Batch 54/64 loss: 0.22186297178268433
Batch 55/64 loss: 0.2243589162826538
Batch 56/64 loss: 0.22609007358551025
Batch 57/64 loss: 0.22190141677856445
Batch 58/64 loss: 0.2353959083557129
Batch 59/64 loss: 0.2192542552947998
Batch 60/64 loss: 0.21916836500167847
Batch 61/64 loss: 0.22665345668792725
Batch 62/64 loss: 0.2282981276512146
Batch 63/64 loss: 0.2234100103378296
Batch 64/64 loss: 0.23012936115264893
Epoch 474  Train loss: 0.22658476128297694  Val loss: 0.2811517940763755
Epoch 475
-------------------------------
Batch 1/64 loss: 0.22558796405792236
Batch 2/64 loss: 0.2163487672805786
Batch 3/64 loss: 0.22987514734268188
Batch 4/64 loss: 0.22836756706237793
Batch 5/64 loss: 0.2206786870956421
Batch 6/64 loss: 0.22732555866241455
Batch 7/64 loss: 0.23041093349456787
Batch 8/64 loss: 0.22618061304092407
Batch 9/64 loss: 0.2302083969116211
Batch 10/64 loss: 0.21058684587478638
Batch 11/64 loss: 0.2243281602859497
Batch 12/64 loss: 0.22851306200027466
Batch 13/64 loss: 0.22111475467681885
Batch 14/64 loss: 0.23147451877593994
Batch 15/64 loss: 0.21701079607009888
Batch 16/64 loss: 0.22440481185913086
Batch 17/64 loss: 0.22128498554229736
Batch 18/64 loss: 0.22733795642852783
Batch 19/64 loss: 0.23472601175308228
Batch 20/64 loss: 0.21791476011276245
Batch 21/64 loss: 0.22539067268371582
Batch 22/64 loss: 0.22654885053634644
Batch 23/64 loss: 0.21105623245239258
Batch 24/64 loss: 0.2157551646232605
Batch 25/64 loss: 0.22373831272125244
Batch 26/64 loss: 0.2210066318511963
Batch 27/64 loss: 0.23154842853546143
Batch 28/64 loss: 0.23053193092346191
Batch 29/64 loss: 0.2399463653564453
Batch 30/64 loss: 0.2367129921913147
Batch 31/64 loss: 0.22360968589782715
Batch 32/64 loss: 0.22021251916885376
Batch 33/64 loss: 0.22457987070083618
Batch 34/64 loss: 0.22890543937683105
Batch 35/64 loss: 0.22544008493423462
Batch 36/64 loss: 0.22653716802597046
Batch 37/64 loss: 0.21772748231887817
Batch 38/64 loss: 0.22568398714065552
Batch 39/64 loss: 0.22024929523468018
Batch 40/64 loss: 0.22719824314117432
Batch 41/64 loss: 0.22306621074676514
Batch 42/64 loss: 0.2390608787536621
Batch 43/64 loss: 0.22110998630523682
Batch 44/64 loss: 0.23245620727539062
Batch 45/64 loss: 0.21869176626205444
Batch 46/64 loss: 0.22089993953704834
Batch 47/64 loss: 0.22088634967803955
Batch 48/64 loss: 0.22486555576324463
Batch 49/64 loss: 0.2238086462020874
Batch 50/64 loss: 0.23477911949157715
Batch 51/64 loss: 0.22321677207946777
Batch 52/64 loss: 0.22453844547271729
Batch 53/64 loss: 0.22882097959518433
Batch 54/64 loss: 0.2322201132774353
Batch 55/64 loss: 0.2293853759765625
Batch 56/64 loss: 0.23496437072753906
Batch 57/64 loss: 0.22237122058868408
Batch 58/64 loss: 0.24341249465942383
Batch 59/64 loss: 0.23044663667678833
Batch 60/64 loss: 0.2210005521774292
Batch 61/64 loss: 0.2255956530570984
Batch 62/64 loss: 0.22844278812408447
Batch 63/64 loss: 0.22551965713500977
Batch 64/64 loss: 0.22756987810134888
Epoch 475  Train loss: 0.22582426328285068  Val loss: 0.28115590823065373
Epoch 476
-------------------------------
Batch 1/64 loss: 0.22507822513580322
Batch 2/64 loss: 0.22981607913970947
Batch 3/64 loss: 0.22468137741088867
Batch 4/64 loss: 0.22372078895568848
Batch 5/64 loss: 0.22763681411743164
Batch 6/64 loss: 0.22519290447235107
Batch 7/64 loss: 0.22268617153167725
Batch 8/64 loss: 0.2308640480041504
Batch 9/64 loss: 0.2165622115135193
Batch 10/64 loss: 0.22271579504013062
Batch 11/64 loss: 0.2236524224281311
Batch 12/64 loss: 0.21873736381530762
Batch 13/64 loss: 0.22512191534042358
Batch 14/64 loss: 0.21982944011688232
Batch 15/64 loss: 0.22509419918060303
Batch 16/64 loss: 0.21550250053405762
Batch 17/64 loss: 0.23199790716171265
Batch 18/64 loss: 0.22747766971588135
Batch 19/64 loss: 0.22695255279541016
Batch 20/64 loss: 0.2292901873588562
Batch 21/64 loss: 0.2164294719696045
Batch 22/64 loss: 0.2349015474319458
Batch 23/64 loss: 0.224320650100708
Batch 24/64 loss: 0.23195970058441162
Batch 25/64 loss: 0.22527050971984863
Batch 26/64 loss: 0.2212618589401245
Batch 27/64 loss: 0.226662278175354
Batch 28/64 loss: 0.2193814516067505
Batch 29/64 loss: 0.22953522205352783
Batch 30/64 loss: 0.22451597452163696
Batch 31/64 loss: 0.22965872287750244
Batch 32/64 loss: 0.22314751148223877
Batch 33/64 loss: 0.22382915019989014
Batch 34/64 loss: 0.2240285873413086
Batch 35/64 loss: 0.21962159872055054
Batch 36/64 loss: 0.2117236852645874
Batch 37/64 loss: 0.22291743755340576
Batch 38/64 loss: 0.224162757396698
Batch 39/64 loss: 0.2281801700592041
Batch 40/64 loss: 0.23214292526245117
Batch 41/64 loss: 0.2194279432296753
Batch 42/64 loss: 0.22968924045562744
Batch 43/64 loss: 0.23284834623336792
Batch 44/64 loss: 0.21731597185134888
Batch 45/64 loss: 0.22215455770492554
Batch 46/64 loss: 0.23176628351211548
Batch 47/64 loss: 0.22750234603881836
Batch 48/64 loss: 0.23415255546569824
Batch 49/64 loss: 0.21495044231414795
Batch 50/64 loss: 0.22939443588256836
Batch 51/64 loss: 0.23022735118865967
Batch 52/64 loss: 0.22039735317230225
Batch 53/64 loss: 0.23147213459014893
Batch 54/64 loss: 0.24129045009613037
Batch 55/64 loss: 0.22939437627792358
Batch 56/64 loss: 0.2181522250175476
Batch 57/64 loss: 0.22312986850738525
Batch 58/64 loss: 0.22468507289886475
Batch 59/64 loss: 0.2302149534225464
Batch 60/64 loss: 0.22913384437561035
Batch 61/64 loss: 0.23364132642745972
Batch 62/64 loss: 0.23743754625320435
Batch 63/64 loss: 0.22078639268875122
Batch 64/64 loss: 0.22355961799621582
Epoch 476  Train loss: 0.22561720025305654  Val loss: 0.28230221103556785
Epoch 477
-------------------------------
Batch 1/64 loss: 0.24036383628845215
Batch 2/64 loss: 0.22008365392684937
Batch 3/64 loss: 0.2207411527633667
Batch 4/64 loss: 0.2254399061203003
Batch 5/64 loss: 0.22905051708221436
Batch 6/64 loss: 0.2307349443435669
Batch 7/64 loss: 0.22133058309555054
Batch 8/64 loss: 0.233734130859375
Batch 9/64 loss: 0.22885417938232422
Batch 10/64 loss: 0.22704195976257324
Batch 11/64 loss: 0.22446191310882568
Batch 12/64 loss: 0.21978849172592163
Batch 13/64 loss: 0.22663670778274536
Batch 14/64 loss: 0.2148880958557129
Batch 15/64 loss: 0.22791236639022827
Batch 16/64 loss: 0.21782541275024414
Batch 17/64 loss: 0.22908544540405273
Batch 18/64 loss: 0.2239580750465393
Batch 19/64 loss: 0.22447288036346436
Batch 20/64 loss: 0.21471500396728516
Batch 21/64 loss: 0.22339683771133423
Batch 22/64 loss: 0.2202085256576538
Batch 23/64 loss: 0.2327284812927246
Batch 24/64 loss: 0.22833919525146484
Batch 25/64 loss: 0.21675139665603638
Batch 26/64 loss: 0.2180575132369995
Batch 27/64 loss: 0.22729623317718506
Batch 28/64 loss: 0.21983623504638672
Batch 29/64 loss: 0.22372615337371826
Batch 30/64 loss: 0.22468173503875732
Batch 31/64 loss: 0.2316635251045227
Batch 32/64 loss: 0.22760260105133057
Batch 33/64 loss: 0.21551251411437988
Batch 34/64 loss: 0.21829438209533691
Batch 35/64 loss: 0.22269248962402344
Batch 36/64 loss: 0.22302848100662231
Batch 37/64 loss: 0.22390365600585938
Batch 38/64 loss: 0.2290676236152649
Batch 39/64 loss: 0.2350149154663086
Batch 40/64 loss: 0.22181838750839233
Batch 41/64 loss: 0.22428101301193237
Batch 42/64 loss: 0.22051483392715454
Batch 43/64 loss: 0.21536076068878174
Batch 44/64 loss: 0.22761785984039307
Batch 45/64 loss: 0.22829759120941162
Batch 46/64 loss: 0.22195839881896973
Batch 47/64 loss: 0.22209346294403076
Batch 48/64 loss: 0.22694623470306396
Batch 49/64 loss: 0.24282413721084595
Batch 50/64 loss: 0.2247437834739685
Batch 51/64 loss: 0.22671818733215332
Batch 52/64 loss: 0.23203128576278687
Batch 53/64 loss: 0.22229504585266113
Batch 54/64 loss: 0.2247987985610962
Batch 55/64 loss: 0.22522157430648804
Batch 56/64 loss: 0.23748362064361572
Batch 57/64 loss: 0.2186642289161682
Batch 58/64 loss: 0.22699964046478271
Batch 59/64 loss: 0.22725635766983032
Batch 60/64 loss: 0.2260468602180481
Batch 61/64 loss: 0.21951138973236084
Batch 62/64 loss: 0.22893297672271729
Batch 63/64 loss: 0.22662919759750366
Batch 64/64 loss: 0.21696710586547852
Epoch 477  Train loss: 0.22501478756175322  Val loss: 0.2815069629973972
Epoch 478
-------------------------------
Batch 1/64 loss: 0.2161826491355896
Batch 2/64 loss: 0.22500205039978027
Batch 3/64 loss: 0.21729505062103271
Batch 4/64 loss: 0.22206342220306396
Batch 5/64 loss: 0.22582274675369263
Batch 6/64 loss: 0.21783363819122314
Batch 7/64 loss: 0.22044622898101807
Batch 8/64 loss: 0.21493268013000488
Batch 9/64 loss: 0.22857868671417236
Batch 10/64 loss: 0.2250351905822754
Batch 11/64 loss: 0.23658782243728638
Batch 12/64 loss: 0.22363662719726562
Batch 13/64 loss: 0.22296035289764404
Batch 14/64 loss: 0.21977877616882324
Batch 15/64 loss: 0.21802055835723877
Batch 16/64 loss: 0.236913800239563
Batch 17/64 loss: 0.2173978090286255
Batch 18/64 loss: 0.20828545093536377
Batch 19/64 loss: 0.232305645942688
Batch 20/64 loss: 0.22598272562026978
Batch 21/64 loss: 0.22439193725585938
Batch 22/64 loss: 0.23231375217437744
Batch 23/64 loss: 0.22592902183532715
Batch 24/64 loss: 0.2313256859779358
Batch 25/64 loss: 0.23229074478149414
Batch 26/64 loss: 0.21634787321090698
Batch 27/64 loss: 0.22446304559707642
Batch 28/64 loss: 0.22844362258911133
Batch 29/64 loss: 0.22776246070861816
Batch 30/64 loss: 0.2228618860244751
Batch 31/64 loss: 0.2275179624557495
Batch 32/64 loss: 0.22327560186386108
Batch 33/64 loss: 0.22626203298568726
Batch 34/64 loss: 0.2193658947944641
Batch 35/64 loss: 0.22299480438232422
Batch 36/64 loss: 0.22426766157150269
Batch 37/64 loss: 0.22281545400619507
Batch 38/64 loss: 0.22759246826171875
Batch 39/64 loss: 0.2249058485031128
Batch 40/64 loss: 0.2229095697402954
Batch 41/64 loss: 0.2172255516052246
Batch 42/64 loss: 0.22341406345367432
Batch 43/64 loss: 0.22039592266082764
Batch 44/64 loss: 0.22768336534500122
Batch 45/64 loss: 0.2268061637878418
Batch 46/64 loss: 0.2255314588546753
Batch 47/64 loss: 0.23158615827560425
Batch 48/64 loss: 0.22091835737228394
Batch 49/64 loss: 0.2246265411376953
Batch 50/64 loss: 0.23792743682861328
Batch 51/64 loss: 0.21992844343185425
Batch 52/64 loss: 0.22226238250732422
Batch 53/64 loss: 0.23092293739318848
Batch 54/64 loss: 0.24055474996566772
Batch 55/64 loss: 0.21879374980926514
Batch 56/64 loss: 0.23324871063232422
Batch 57/64 loss: 0.22635769844055176
Batch 58/64 loss: 0.22441482543945312
Batch 59/64 loss: 0.23211652040481567
Batch 60/64 loss: 0.2202332615852356
Batch 61/64 loss: 0.2238469123840332
Batch 62/64 loss: 0.22574645280838013
Batch 63/64 loss: 0.22795957326889038
Batch 64/64 loss: 0.22449016571044922
Epoch 478  Train loss: 0.22484655847736434  Val loss: 0.28233704288390904
Epoch 479
-------------------------------
Batch 1/64 loss: 0.23250353336334229
Batch 2/64 loss: 0.22680151462554932
Batch 3/64 loss: 0.23152142763137817
Batch 4/64 loss: 0.21673583984375
Batch 5/64 loss: 0.22590011358261108
Batch 6/64 loss: 0.23297655582427979
Batch 7/64 loss: 0.228995680809021
Batch 8/64 loss: 0.2267693281173706
Batch 9/64 loss: 0.22585606575012207
Batch 10/64 loss: 0.22053742408752441
Batch 11/64 loss: 0.22362196445465088
Batch 12/64 loss: 0.22238373756408691
Batch 13/64 loss: 0.2233119010925293
Batch 14/64 loss: 0.2228756546974182
Batch 15/64 loss: 0.2238978147506714
Batch 16/64 loss: 0.2277519702911377
Batch 17/64 loss: 0.2305033802986145
Batch 18/64 loss: 0.2270745038986206
Batch 19/64 loss: 0.257396399974823
Batch 20/64 loss: 0.2266407012939453
Batch 21/64 loss: 0.2154674530029297
Batch 22/64 loss: 0.24390137195587158
Batch 23/64 loss: 0.22187566757202148
Batch 24/64 loss: 0.22201263904571533
Batch 25/64 loss: 0.22052478790283203
Batch 26/64 loss: 0.2208060622215271
Batch 27/64 loss: 0.23235511779785156
Batch 28/64 loss: 0.22050583362579346
Batch 29/64 loss: 0.21903574466705322
Batch 30/64 loss: 0.21395385265350342
Batch 31/64 loss: 0.22185349464416504
Batch 32/64 loss: 0.22309249639511108
Batch 33/64 loss: 0.22506773471832275
Batch 34/64 loss: 0.22672367095947266
Batch 35/64 loss: 0.21967947483062744
Batch 36/64 loss: 0.22555625438690186
Batch 37/64 loss: 0.2267134189605713
Batch 38/64 loss: 0.2246077060699463
Batch 39/64 loss: 0.22971409559249878
Batch 40/64 loss: 0.21392279863357544
Batch 41/64 loss: 0.24025654792785645
Batch 42/64 loss: 0.21921133995056152
Batch 43/64 loss: 0.22575199604034424
Batch 44/64 loss: 0.22436118125915527
Batch 45/64 loss: 0.22608840465545654
Batch 46/64 loss: 0.22802495956420898
Batch 47/64 loss: 0.2151191234588623
Batch 48/64 loss: 0.23283863067626953
Batch 49/64 loss: 0.22412800788879395
Batch 50/64 loss: 0.2185838222503662
Batch 51/64 loss: 0.22288960218429565
Batch 52/64 loss: 0.22334080934524536
Batch 53/64 loss: 0.21761798858642578
Batch 54/64 loss: 0.22240817546844482
Batch 55/64 loss: 0.2258046269416809
Batch 56/64 loss: 0.2181408405303955
Batch 57/64 loss: 0.22467219829559326
Batch 58/64 loss: 0.2183980941772461
Batch 59/64 loss: 0.2211201786994934
Batch 60/64 loss: 0.21787112951278687
Batch 61/64 loss: 0.22786945104599
Batch 62/64 loss: 0.21963000297546387
Batch 63/64 loss: 0.22929590940475464
Batch 64/64 loss: 0.23536932468414307
Epoch 479  Train loss: 0.2249627482657339  Val loss: 0.2821786174249813
Epoch 480
-------------------------------
Batch 1/64 loss: 0.22105348110198975
Batch 2/64 loss: 0.2280292510986328
Batch 3/64 loss: 0.23379004001617432
Batch 4/64 loss: 0.22267675399780273
Batch 5/64 loss: 0.22143805027008057
Batch 6/64 loss: 0.23790192604064941
Batch 7/64 loss: 0.21264052391052246
Batch 8/64 loss: 0.2196422815322876
Batch 9/64 loss: 0.21624332666397095
Batch 10/64 loss: 0.21951282024383545
Batch 11/64 loss: 0.22790729999542236
Batch 12/64 loss: 0.22938919067382812
Batch 13/64 loss: 0.23464101552963257
Batch 14/64 loss: 0.22325557470321655
Batch 15/64 loss: 0.2167496681213379
Batch 16/64 loss: 0.2250078320503235
Batch 17/64 loss: 0.23408877849578857
Batch 18/64 loss: 0.22399979829788208
Batch 19/64 loss: 0.22816407680511475
Batch 20/64 loss: 0.22318333387374878
Batch 21/64 loss: 0.2230370044708252
Batch 22/64 loss: 0.22126984596252441
Batch 23/64 loss: 0.21578752994537354
Batch 24/64 loss: 0.2167370319366455
Batch 25/64 loss: 0.22005105018615723
Batch 26/64 loss: 0.23224622011184692
Batch 27/64 loss: 0.22661423683166504
Batch 28/64 loss: 0.22417783737182617
Batch 29/64 loss: 0.23217272758483887
Batch 30/64 loss: 0.2242039442062378
Batch 31/64 loss: 0.22165954113006592
Batch 32/64 loss: 0.21333515644073486
Batch 33/64 loss: 0.22117960453033447
Batch 34/64 loss: 0.22841876745224
Batch 35/64 loss: 0.22625738382339478
Batch 36/64 loss: 0.23307788372039795
Batch 37/64 loss: 0.221390962600708
Batch 38/64 loss: 0.2340337634086609
Batch 39/64 loss: 0.21844613552093506
Batch 40/64 loss: 0.22318661212921143
Batch 41/64 loss: 0.2261282205581665
Batch 42/64 loss: 0.2285633087158203
Batch 43/64 loss: 0.2279556393623352
Batch 44/64 loss: 0.22369718551635742
Batch 45/64 loss: 0.21746736764907837
Batch 46/64 loss: 0.223724365234375
Batch 47/64 loss: 0.22375458478927612
Batch 48/64 loss: 0.21580791473388672
Batch 49/64 loss: 0.21528387069702148
Batch 50/64 loss: 0.22189873456954956
Batch 51/64 loss: 0.23143672943115234
Batch 52/64 loss: 0.22472840547561646
Batch 53/64 loss: 0.21360576152801514
Batch 54/64 loss: 0.22865986824035645
Batch 55/64 loss: 0.23612958192825317
Batch 56/64 loss: 0.23510217666625977
Batch 57/64 loss: 0.22664743661880493
Batch 58/64 loss: 0.22681701183319092
Batch 59/64 loss: 0.21606826782226562
Batch 60/64 loss: 0.2206459641456604
Batch 61/64 loss: 0.22946196794509888
Batch 62/64 loss: 0.23003804683685303
Batch 63/64 loss: 0.21236050128936768
Batch 64/64 loss: 0.22051817178726196
Epoch 480  Train loss: 0.2242818792661031  Val loss: 0.28201828932844075
Epoch 481
-------------------------------
Batch 1/64 loss: 0.2240840196609497
Batch 2/64 loss: 0.2225133180618286
Batch 3/64 loss: 0.21772050857543945
Batch 4/64 loss: 0.22077786922454834
Batch 5/64 loss: 0.22059869766235352
Batch 6/64 loss: 0.22589486837387085
Batch 7/64 loss: 0.2256484031677246
Batch 8/64 loss: 0.2165893316268921
Batch 9/64 loss: 0.2249320149421692
Batch 10/64 loss: 0.2230823040008545
Batch 11/64 loss: 0.225813627243042
Batch 12/64 loss: 0.23302745819091797
Batch 13/64 loss: 0.22896206378936768
Batch 14/64 loss: 0.22314274311065674
Batch 15/64 loss: 0.22213876247406006
Batch 16/64 loss: 0.22735369205474854
Batch 17/64 loss: 0.2330007553100586
Batch 18/64 loss: 0.22337698936462402
Batch 19/64 loss: 0.22519302368164062
Batch 20/64 loss: 0.23072373867034912
Batch 21/64 loss: 0.22652816772460938
Batch 22/64 loss: 0.22495722770690918
Batch 23/64 loss: 0.22223889827728271
Batch 24/64 loss: 0.2242898941040039
Batch 25/64 loss: 0.22436749935150146
Batch 26/64 loss: 0.22633373737335205
Batch 27/64 loss: 0.2207963466644287
Batch 28/64 loss: 0.22859632968902588
Batch 29/64 loss: 0.22311943769454956
Batch 30/64 loss: 0.21398234367370605
Batch 31/64 loss: 0.22213220596313477
Batch 32/64 loss: 0.22167497873306274
Batch 33/64 loss: 0.2266308069229126
Batch 34/64 loss: 0.23330390453338623
Batch 35/64 loss: 0.2196718454360962
Batch 36/64 loss: 0.22159874439239502
Batch 37/64 loss: 0.2231043577194214
Batch 38/64 loss: 0.22048479318618774
Batch 39/64 loss: 0.23095428943634033
Batch 40/64 loss: 0.2181972861289978
Batch 41/64 loss: 0.23573517799377441
Batch 42/64 loss: 0.22160720825195312
Batch 43/64 loss: 0.21418416500091553
Batch 44/64 loss: 0.22283655405044556
Batch 45/64 loss: 0.21534794569015503
Batch 46/64 loss: 0.23487496376037598
Batch 47/64 loss: 0.2241138219833374
Batch 48/64 loss: 0.22856014966964722
Batch 49/64 loss: 0.22630679607391357
Batch 50/64 loss: 0.22620773315429688
Batch 51/64 loss: 0.22242170572280884
Batch 52/64 loss: 0.22858941555023193
Batch 53/64 loss: 0.22787702083587646
Batch 54/64 loss: 0.22917240858078003
Batch 55/64 loss: 0.22675436735153198
Batch 56/64 loss: 0.22454607486724854
Batch 57/64 loss: 0.21412992477416992
Batch 58/64 loss: 0.22870874404907227
Batch 59/64 loss: 0.22159987688064575
Batch 60/64 loss: 0.2299240231513977
Batch 61/64 loss: 0.21848297119140625
Batch 62/64 loss: 0.22542762756347656
Batch 63/64 loss: 0.22552502155303955
Batch 64/64 loss: 0.2285504937171936
Epoch 481  Train loss: 0.22450013885311051  Val loss: 0.2815921966152912
Epoch 482
-------------------------------
Batch 1/64 loss: 0.23040735721588135
Batch 2/64 loss: 0.21122586727142334
Batch 3/64 loss: 0.2240598201751709
Batch 4/64 loss: 0.21822643280029297
Batch 5/64 loss: 0.21219050884246826
Batch 6/64 loss: 0.23187947273254395
Batch 7/64 loss: 0.22041398286819458
Batch 8/64 loss: 0.2295210361480713
Batch 9/64 loss: 0.22001326084136963
Batch 10/64 loss: 0.22561585903167725
Batch 11/64 loss: 0.21948844194412231
Batch 12/64 loss: 0.22063195705413818
Batch 13/64 loss: 0.22894924879074097
Batch 14/64 loss: 0.2191380262374878
Batch 15/64 loss: 0.22103482484817505
Batch 16/64 loss: 0.22517627477645874
Batch 17/64 loss: 0.22826188802719116
Batch 18/64 loss: 0.23940515518188477
Batch 19/64 loss: 0.2233991026878357
Batch 20/64 loss: 0.2257009744644165
Batch 21/64 loss: 0.22365731000900269
Batch 22/64 loss: 0.22499656677246094
Batch 23/64 loss: 0.22201776504516602
Batch 24/64 loss: 0.22286856174468994
Batch 25/64 loss: 0.22285771369934082
Batch 26/64 loss: 0.22181344032287598
Batch 27/64 loss: 0.21727800369262695
Batch 28/64 loss: 0.22764086723327637
Batch 29/64 loss: 0.2211022973060608
Batch 30/64 loss: 0.22417157888412476
Batch 31/64 loss: 0.22465729713439941
Batch 32/64 loss: 0.22388529777526855
Batch 33/64 loss: 0.22012782096862793
Batch 34/64 loss: 0.2267124056816101
Batch 35/64 loss: 0.23555684089660645
Batch 36/64 loss: 0.2283598780632019
Batch 37/64 loss: 0.21512174606323242
Batch 38/64 loss: 0.2374119758605957
Batch 39/64 loss: 0.2215617299079895
Batch 40/64 loss: 0.2179708480834961
Batch 41/64 loss: 0.21502035856246948
Batch 42/64 loss: 0.21516895294189453
Batch 43/64 loss: 0.22097593545913696
Batch 44/64 loss: 0.21778368949890137
Batch 45/64 loss: 0.21751940250396729
Batch 46/64 loss: 0.21753346920013428
Batch 47/64 loss: 0.2188929319381714
Batch 48/64 loss: 0.2264818549156189
Batch 49/64 loss: 0.22513830661773682
Batch 50/64 loss: 0.23623651266098022
Batch 51/64 loss: 0.22418427467346191
Batch 52/64 loss: 0.21871733665466309
Batch 53/64 loss: 0.2227623462677002
Batch 54/64 loss: 0.24425208568572998
Batch 55/64 loss: 0.23481357097625732
Batch 56/64 loss: 0.2200983762741089
Batch 57/64 loss: 0.2297307252883911
Batch 58/64 loss: 0.23489975929260254
Batch 59/64 loss: 0.22575175762176514
Batch 60/64 loss: 0.2290768027305603
Batch 61/64 loss: 0.23440712690353394
Batch 62/64 loss: 0.22132503986358643
Batch 63/64 loss: 0.21458959579467773
Batch 64/64 loss: 0.22136437892913818
Epoch 482  Train loss: 0.22409243817422905  Val loss: 0.28231970059502987
Epoch 483
-------------------------------
Batch 1/64 loss: 0.22668886184692383
Batch 2/64 loss: 0.2345728874206543
Batch 3/64 loss: 0.2360045313835144
Batch 4/64 loss: 0.21495842933654785
Batch 5/64 loss: 0.23044991493225098
Batch 6/64 loss: 0.22790181636810303
Batch 7/64 loss: 0.21742641925811768
Batch 8/64 loss: 0.22753340005874634
Batch 9/64 loss: 0.224259614944458
Batch 10/64 loss: 0.22203278541564941
Batch 11/64 loss: 0.2246081829071045
Batch 12/64 loss: 0.21795272827148438
Batch 13/64 loss: 0.22101157903671265
Batch 14/64 loss: 0.227494478225708
Batch 15/64 loss: 0.22423261404037476
Batch 16/64 loss: 0.22610777616500854
Batch 17/64 loss: 0.2229604721069336
Batch 18/64 loss: 0.23006868362426758
Batch 19/64 loss: 0.2263796329498291
Batch 20/64 loss: 0.22007882595062256
Batch 21/64 loss: 0.22800689935684204
Batch 22/64 loss: 0.2170276641845703
Batch 23/64 loss: 0.22702211141586304
Batch 24/64 loss: 0.2175559401512146
Batch 25/64 loss: 0.22398996353149414
Batch 26/64 loss: 0.22740817070007324
Batch 27/64 loss: 0.22449564933776855
Batch 28/64 loss: 0.22513848543167114
Batch 29/64 loss: 0.2137848138809204
Batch 30/64 loss: 0.22292184829711914
Batch 31/64 loss: 0.21773815155029297
Batch 32/64 loss: 0.23187780380249023
Batch 33/64 loss: 0.21724462509155273
Batch 34/64 loss: 0.22592437267303467
Batch 35/64 loss: 0.2277994155883789
Batch 36/64 loss: 0.2190760374069214
Batch 37/64 loss: 0.2305692434310913
Batch 38/64 loss: 0.21740388870239258
Batch 39/64 loss: 0.22415691614151
Batch 40/64 loss: 0.23249101638793945
Batch 41/64 loss: 0.23947978019714355
Batch 42/64 loss: 0.21880698204040527
Batch 43/64 loss: 0.21107280254364014
Batch 44/64 loss: 0.2194920778274536
Batch 45/64 loss: 0.22383785247802734
Batch 46/64 loss: 0.2416013479232788
Batch 47/64 loss: 0.22243714332580566
Batch 48/64 loss: 0.23205304145812988
Batch 49/64 loss: 0.22593772411346436
Batch 50/64 loss: 0.22398853302001953
Batch 51/64 loss: 0.2215489149093628
Batch 52/64 loss: 0.235101580619812
Batch 53/64 loss: 0.21905964612960815
Batch 54/64 loss: 0.22186076641082764
Batch 55/64 loss: 0.22438573837280273
Batch 56/64 loss: 0.2259262204170227
Batch 57/64 loss: 0.23018616437911987
Batch 58/64 loss: 0.2196558117866516
Batch 59/64 loss: 0.22538745403289795
Batch 60/64 loss: 0.22961807250976562
Batch 61/64 loss: 0.2188870906829834
Batch 62/64 loss: 0.21922975778579712
Batch 63/64 loss: 0.21770751476287842
Batch 64/64 loss: 0.24386608600616455
Epoch 483  Train loss: 0.2246983252319635  Val loss: 0.282501440072797
Epoch 484
-------------------------------
Batch 1/64 loss: 0.22242069244384766
Batch 2/64 loss: 0.2122591733932495
Batch 3/64 loss: 0.22709202766418457
Batch 4/64 loss: 0.22702425718307495
Batch 5/64 loss: 0.2142575979232788
Batch 6/64 loss: 0.22112315893173218
Batch 7/64 loss: 0.23242712020874023
Batch 8/64 loss: 0.22467011213302612
Batch 9/64 loss: 0.22007834911346436
Batch 10/64 loss: 0.21905559301376343
Batch 11/64 loss: 0.21403050422668457
Batch 12/64 loss: 0.21759319305419922
Batch 13/64 loss: 0.2201606035232544
Batch 14/64 loss: 0.23406344652175903
Batch 15/64 loss: 0.22916972637176514
Batch 16/64 loss: 0.21512365341186523
Batch 17/64 loss: 0.21906721591949463
Batch 18/64 loss: 0.22680050134658813
Batch 19/64 loss: 0.2164539098739624
Batch 20/64 loss: 0.2419966459274292
Batch 21/64 loss: 0.22197961807250977
Batch 22/64 loss: 0.22396284341812134
Batch 23/64 loss: 0.23339378833770752
Batch 24/64 loss: 0.23339194059371948
Batch 25/64 loss: 0.22069883346557617
Batch 26/64 loss: 0.2238454818725586
Batch 27/64 loss: 0.2177048921585083
Batch 28/64 loss: 0.2356252670288086
Batch 29/64 loss: 0.22512435913085938
Batch 30/64 loss: 0.22720468044281006
Batch 31/64 loss: 0.23078083992004395
Batch 32/64 loss: 0.22064030170440674
Batch 33/64 loss: 0.22658014297485352
Batch 34/64 loss: 0.2367127537727356
Batch 35/64 loss: 0.2327028512954712
Batch 36/64 loss: 0.22986769676208496
Batch 37/64 loss: 0.23023951053619385
Batch 38/64 loss: 0.22209417819976807
Batch 39/64 loss: 0.22060668468475342
Batch 40/64 loss: 0.22294771671295166
Batch 41/64 loss: 0.2129310965538025
Batch 42/64 loss: 0.2288823127746582
Batch 43/64 loss: 0.2273539900779724
Batch 44/64 loss: 0.23069769144058228
Batch 45/64 loss: 0.23416781425476074
Batch 46/64 loss: 0.2209593653678894
Batch 47/64 loss: 0.23341745138168335
Batch 48/64 loss: 0.22680246829986572
Batch 49/64 loss: 0.22072792053222656
Batch 50/64 loss: 0.21990430355072021
Batch 51/64 loss: 0.22728443145751953
Batch 52/64 loss: 0.22178810834884644
Batch 53/64 loss: 0.2269965410232544
Batch 54/64 loss: 0.22780144214630127
Batch 55/64 loss: 0.22821861505508423
Batch 56/64 loss: 0.2199763059616089
Batch 57/64 loss: 0.21995604038238525
Batch 58/64 loss: 0.22462141513824463
Batch 59/64 loss: 0.22604519128799438
Batch 60/64 loss: 0.22725582122802734
Batch 61/64 loss: 0.23376882076263428
Batch 62/64 loss: 0.22458279132843018
Batch 63/64 loss: 0.21557211875915527
Batch 64/64 loss: 0.22636032104492188
Epoch 484  Train loss: 0.22494830056732776  Val loss: 0.28260159000907975
Epoch 485
-------------------------------
Batch 1/64 loss: 0.2297053337097168
Batch 2/64 loss: 0.22197788953781128
Batch 3/64 loss: 0.22373312711715698
Batch 4/64 loss: 0.22458374500274658
Batch 5/64 loss: 0.21799933910369873
Batch 6/64 loss: 0.22016263008117676
Batch 7/64 loss: 0.21722400188446045
Batch 8/64 loss: 0.22741854190826416
Batch 9/64 loss: 0.2154117226600647
Batch 10/64 loss: 0.21454882621765137
Batch 11/64 loss: 0.23118120431900024
Batch 12/64 loss: 0.21549826860427856
Batch 13/64 loss: 0.222398042678833
Batch 14/64 loss: 0.2280275821685791
Batch 15/64 loss: 0.2343442440032959
Batch 16/64 loss: 0.22680842876434326
Batch 17/64 loss: 0.23924773931503296
Batch 18/64 loss: 0.2221294641494751
Batch 19/64 loss: 0.227536141872406
Batch 20/64 loss: 0.24209845066070557
Batch 21/64 loss: 0.22425460815429688
Batch 22/64 loss: 0.21822142601013184
Batch 23/64 loss: 0.21734577417373657
Batch 24/64 loss: 0.22413265705108643
Batch 25/64 loss: 0.21508216857910156
Batch 26/64 loss: 0.22256958484649658
Batch 27/64 loss: 0.23559093475341797
Batch 28/64 loss: 0.21772819757461548
Batch 29/64 loss: 0.21733683347702026
Batch 30/64 loss: 0.22106963396072388
Batch 31/64 loss: 0.22441184520721436
Batch 32/64 loss: 0.226845383644104
Batch 33/64 loss: 0.22014379501342773
Batch 34/64 loss: 0.2256619930267334
Batch 35/64 loss: 0.23733305931091309
Batch 36/64 loss: 0.22378170490264893
Batch 37/64 loss: 0.23127305507659912
Batch 38/64 loss: 0.23519515991210938
Batch 39/64 loss: 0.22408640384674072
Batch 40/64 loss: 0.22677266597747803
Batch 41/64 loss: 0.23235833644866943
Batch 42/64 loss: 0.22615456581115723
Batch 43/64 loss: 0.21937185525894165
Batch 44/64 loss: 0.2369292974472046
Batch 45/64 loss: 0.2223970890045166
Batch 46/64 loss: 0.22921621799468994
Batch 47/64 loss: 0.22058391571044922
Batch 48/64 loss: 0.21504950523376465
Batch 49/64 loss: 0.22248101234436035
Batch 50/64 loss: 0.22213292121887207
Batch 51/64 loss: 0.21652376651763916
Batch 52/64 loss: 0.2196447253227234
Batch 53/64 loss: 0.21570861339569092
Batch 54/64 loss: 0.22576969861984253
Batch 55/64 loss: 0.2250370979309082
Batch 56/64 loss: 0.22780942916870117
Batch 57/64 loss: 0.22147536277770996
Batch 58/64 loss: 0.22556626796722412
Batch 59/64 loss: 0.22711223363876343
Batch 60/64 loss: 0.22728073596954346
Batch 61/64 loss: 0.21943044662475586
Batch 62/64 loss: 0.21884584426879883
Batch 63/64 loss: 0.2299724817276001
Batch 64/64 loss: 0.23140203952789307
Epoch 485  Train loss: 0.2244905813067567  Val loss: 0.2827585718476076
Epoch 486
-------------------------------
Batch 1/64 loss: 0.21405184268951416
Batch 2/64 loss: 0.22187095880508423
Batch 3/64 loss: 0.2159796953201294
Batch 4/64 loss: 0.21866673231124878
Batch 5/64 loss: 0.2262357473373413
Batch 6/64 loss: 0.23629838228225708
Batch 7/64 loss: 0.22788596153259277
Batch 8/64 loss: 0.22912061214447021
Batch 9/64 loss: 0.22123593091964722
Batch 10/64 loss: 0.21906179189682007
Batch 11/64 loss: 0.22985869646072388
Batch 12/64 loss: 0.2307797074317932
Batch 13/64 loss: 0.2187793254852295
Batch 14/64 loss: 0.2220773696899414
Batch 15/64 loss: 0.232283353805542
Batch 16/64 loss: 0.2271043062210083
Batch 17/64 loss: 0.2215512990951538
Batch 18/64 loss: 0.2197776436805725
Batch 19/64 loss: 0.22021567821502686
Batch 20/64 loss: 0.22740763425827026
Batch 21/64 loss: 0.23728013038635254
Batch 22/64 loss: 0.22930121421813965
Batch 23/64 loss: 0.22995758056640625
Batch 24/64 loss: 0.2201327085494995
Batch 25/64 loss: 0.221568763256073
Batch 26/64 loss: 0.21763193607330322
Batch 27/64 loss: 0.21221071481704712
Batch 28/64 loss: 0.22753989696502686
Batch 29/64 loss: 0.21410852670669556
Batch 30/64 loss: 0.218059241771698
Batch 31/64 loss: 0.2260149121284485
Batch 32/64 loss: 0.22810155153274536
Batch 33/64 loss: 0.23209106922149658
Batch 34/64 loss: 0.22567659616470337
Batch 35/64 loss: 0.22212159633636475
Batch 36/64 loss: 0.22646218538284302
Batch 37/64 loss: 0.21588337421417236
Batch 38/64 loss: 0.21968209743499756
Batch 39/64 loss: 0.22001242637634277
Batch 40/64 loss: 0.22649002075195312
Batch 41/64 loss: 0.21890044212341309
Batch 42/64 loss: 0.22817617654800415
Batch 43/64 loss: 0.219241201877594
Batch 44/64 loss: 0.21812021732330322
Batch 45/64 loss: 0.22515332698822021
Batch 46/64 loss: 0.22464632987976074
Batch 47/64 loss: 0.217431902885437
Batch 48/64 loss: 0.22644805908203125
Batch 49/64 loss: 0.22182345390319824
Batch 50/64 loss: 0.21722179651260376
Batch 51/64 loss: 0.23206555843353271
Batch 52/64 loss: 0.22290951013565063
Batch 53/64 loss: 0.2202211618423462
Batch 54/64 loss: 0.21508657932281494
Batch 55/64 loss: 0.2325999140739441
Batch 56/64 loss: 0.2369319200515747
Batch 57/64 loss: 0.2255486249923706
Batch 58/64 loss: 0.22333312034606934
Batch 59/64 loss: 0.22736036777496338
Batch 60/64 loss: 0.2169068455696106
Batch 61/64 loss: 0.21446919441223145
Batch 62/64 loss: 0.23506319522857666
Batch 63/64 loss: 0.21604740619659424
Batch 64/64 loss: 0.21488654613494873
Epoch 486  Train loss: 0.22348926160849777  Val loss: 0.28187261045593576
Epoch 487
-------------------------------
Batch 1/64 loss: 0.22033977508544922
Batch 2/64 loss: 0.2175689935684204
Batch 3/64 loss: 0.22140514850616455
Batch 4/64 loss: 0.22966337203979492
Batch 5/64 loss: 0.21949267387390137
Batch 6/64 loss: 0.22905027866363525
Batch 7/64 loss: 0.2199697494506836
Batch 8/64 loss: 0.2174016237258911
Batch 9/64 loss: 0.2308787703514099
Batch 10/64 loss: 0.2169170379638672
Batch 11/64 loss: 0.22008442878723145
Batch 12/64 loss: 0.225458562374115
Batch 13/64 loss: 0.2307431697845459
Batch 14/64 loss: 0.22465616464614868
Batch 15/64 loss: 0.22380197048187256
Batch 16/64 loss: 0.22092795372009277
Batch 17/64 loss: 0.22371447086334229
Batch 18/64 loss: 0.23493903875350952
Batch 19/64 loss: 0.2336810827255249
Batch 20/64 loss: 0.2196020483970642
Batch 21/64 loss: 0.22812247276306152
Batch 22/64 loss: 0.22661811113357544
Batch 23/64 loss: 0.21061038970947266
Batch 24/64 loss: 0.22642672061920166
Batch 25/64 loss: 0.22218823432922363
Batch 26/64 loss: 0.21914494037628174
Batch 27/64 loss: 0.21403926610946655
Batch 28/64 loss: 0.2206360101699829
Batch 29/64 loss: 0.20866310596466064
Batch 30/64 loss: 0.22361361980438232
Batch 31/64 loss: 0.22672045230865479
Batch 32/64 loss: 0.23471248149871826
Batch 33/64 loss: 0.2262662649154663
Batch 34/64 loss: 0.22909283638000488
Batch 35/64 loss: 0.22623991966247559
Batch 36/64 loss: 0.22083306312561035
Batch 37/64 loss: 0.22047996520996094
Batch 38/64 loss: 0.2212512493133545
Batch 39/64 loss: 0.22251874208450317
Batch 40/64 loss: 0.22844678163528442
Batch 41/64 loss: 0.22029876708984375
Batch 42/64 loss: 0.22119677066802979
Batch 43/64 loss: 0.21882116794586182
Batch 44/64 loss: 0.20976632833480835
Batch 45/64 loss: 0.21817129850387573
Batch 46/64 loss: 0.2317032814025879
Batch 47/64 loss: 0.2330493927001953
Batch 48/64 loss: 0.22417426109313965
Batch 49/64 loss: 0.22821414470672607
Batch 50/64 loss: 0.22511637210845947
Batch 51/64 loss: 0.2289544939994812
Batch 52/64 loss: 0.22568625211715698
Batch 53/64 loss: 0.22278887033462524
Batch 54/64 loss: 0.21609055995941162
Batch 55/64 loss: 0.21981501579284668
Batch 56/64 loss: 0.22464358806610107
Batch 57/64 loss: 0.22836536169052124
Batch 58/64 loss: 0.22277957201004028
Batch 59/64 loss: 0.22143816947937012
Batch 60/64 loss: 0.23709571361541748
Batch 61/64 loss: 0.24119168519973755
Batch 62/64 loss: 0.22442346811294556
Batch 63/64 loss: 0.23094689846038818
Batch 64/64 loss: 0.22316282987594604
Epoch 487  Train loss: 0.22398469798705156  Val loss: 0.28184275467371206
Epoch 488
-------------------------------
Batch 1/64 loss: 0.21794193983078003
Batch 2/64 loss: 0.21449613571166992
Batch 3/64 loss: 0.21485888957977295
Batch 4/64 loss: 0.21800482273101807
Batch 5/64 loss: 0.21577715873718262
Batch 6/64 loss: 0.21676981449127197
Batch 7/64 loss: 0.21895188093185425
Batch 8/64 loss: 0.23102712631225586
Batch 9/64 loss: 0.20985448360443115
Batch 10/64 loss: 0.21656984090805054
Batch 11/64 loss: 0.2211543321609497
Batch 12/64 loss: 0.22838985919952393
Batch 13/64 loss: 0.2240527868270874
Batch 14/64 loss: 0.2204453945159912
Batch 15/64 loss: 0.2232135534286499
Batch 16/64 loss: 0.2212238907814026
Batch 17/64 loss: 0.22213780879974365
Batch 18/64 loss: 0.2176896333694458
Batch 19/64 loss: 0.2278892993927002
Batch 20/64 loss: 0.2169966697692871
Batch 21/64 loss: 0.2248520851135254
Batch 22/64 loss: 0.22374331951141357
Batch 23/64 loss: 0.21698546409606934
Batch 24/64 loss: 0.22424042224884033
Batch 25/64 loss: 0.22575849294662476
Batch 26/64 loss: 0.22068965435028076
Batch 27/64 loss: 0.22474825382232666
Batch 28/64 loss: 0.21942317485809326
Batch 29/64 loss: 0.23417532444000244
Batch 30/64 loss: 0.22434067726135254
Batch 31/64 loss: 0.2156050205230713
Batch 32/64 loss: 0.22137820720672607
Batch 33/64 loss: 0.2188122272491455
Batch 34/64 loss: 0.21809613704681396
Batch 35/64 loss: 0.22568738460540771
Batch 36/64 loss: 0.23613691329956055
Batch 37/64 loss: 0.2307422161102295
Batch 38/64 loss: 0.23267805576324463
Batch 39/64 loss: 0.2265845537185669
Batch 40/64 loss: 0.22536706924438477
Batch 41/64 loss: 0.22760021686553955
Batch 42/64 loss: 0.22216856479644775
Batch 43/64 loss: 0.2308982014656067
Batch 44/64 loss: 0.21661651134490967
Batch 45/64 loss: 0.22367316484451294
Batch 46/64 loss: 0.22455263137817383
Batch 47/64 loss: 0.22808027267456055
Batch 48/64 loss: 0.22378957271575928
Batch 49/64 loss: 0.22688651084899902
Batch 50/64 loss: 0.22127866744995117
Batch 51/64 loss: 0.23135465383529663
Batch 52/64 loss: 0.2175959348678589
Batch 53/64 loss: 0.2373303771018982
Batch 54/64 loss: 0.22557294368743896
Batch 55/64 loss: 0.21819597482681274
Batch 56/64 loss: 0.21975493431091309
Batch 57/64 loss: 0.22201114892959595
Batch 58/64 loss: 0.22605198621749878
Batch 59/64 loss: 0.2266606092453003
Batch 60/64 loss: 0.22637009620666504
Batch 61/64 loss: 0.2213648557662964
Batch 62/64 loss: 0.21785235404968262
Batch 63/64 loss: 0.22268736362457275
Batch 64/64 loss: 0.22766447067260742
Epoch 488  Train loss: 0.22300526862050973  Val loss: 0.28198520485887824
Epoch 489
-------------------------------
Batch 1/64 loss: 0.21324288845062256
Batch 2/64 loss: 0.2319321632385254
Batch 3/64 loss: 0.21388483047485352
Batch 4/64 loss: 0.23072576522827148
Batch 5/64 loss: 0.21700966358184814
Batch 6/64 loss: 0.225805401802063
Batch 7/64 loss: 0.23594725131988525
Batch 8/64 loss: 0.2155572772026062
Batch 9/64 loss: 0.21339821815490723
Batch 10/64 loss: 0.22694087028503418
Batch 11/64 loss: 0.215684175491333
Batch 12/64 loss: 0.22249722480773926
Batch 13/64 loss: 0.22100019454956055
Batch 14/64 loss: 0.21970391273498535
Batch 15/64 loss: 0.22765600681304932
Batch 16/64 loss: 0.21901428699493408
Batch 17/64 loss: 0.22393381595611572
Batch 18/64 loss: 0.2157009243965149
Batch 19/64 loss: 0.2285636067390442
Batch 20/64 loss: 0.2231515645980835
Batch 21/64 loss: 0.21477681398391724
Batch 22/64 loss: 0.2307060956954956
Batch 23/64 loss: 0.22188812494277954
Batch 24/64 loss: 0.2238302230834961
Batch 25/64 loss: 0.219415545463562
Batch 26/64 loss: 0.22412443161010742
Batch 27/64 loss: 0.22420167922973633
Batch 28/64 loss: 0.23425394296646118
Batch 29/64 loss: 0.22568726539611816
Batch 30/64 loss: 0.22176027297973633
Batch 31/64 loss: 0.2275317907333374
Batch 32/64 loss: 0.23101294040679932
Batch 33/64 loss: 0.2239251732826233
Batch 34/64 loss: 0.23161649703979492
Batch 35/64 loss: 0.22056883573532104
Batch 36/64 loss: 0.2191990613937378
Batch 37/64 loss: 0.22098129987716675
Batch 38/64 loss: 0.23166871070861816
Batch 39/64 loss: 0.2176363468170166
Batch 40/64 loss: 0.23996061086654663
Batch 41/64 loss: 0.22595834732055664
Batch 42/64 loss: 0.2259756326675415
Batch 43/64 loss: 0.21469730138778687
Batch 44/64 loss: 0.21795719861984253
Batch 45/64 loss: 0.22183537483215332
Batch 46/64 loss: 0.23457586765289307
Batch 47/64 loss: 0.221726655960083
Batch 48/64 loss: 0.2271326780319214
Batch 49/64 loss: 0.2181457281112671
Batch 50/64 loss: 0.22874599695205688
Batch 51/64 loss: 0.23156464099884033
Batch 52/64 loss: 0.2351003885269165
Batch 53/64 loss: 0.22337162494659424
Batch 54/64 loss: 0.22048425674438477
Batch 55/64 loss: 0.21850252151489258
Batch 56/64 loss: 0.21379578113555908
Batch 57/64 loss: 0.21714365482330322
Batch 58/64 loss: 0.22215604782104492
Batch 59/64 loss: 0.22665047645568848
Batch 60/64 loss: 0.22015106678009033
Batch 61/64 loss: 0.22240161895751953
Batch 62/64 loss: 0.22843635082244873
Batch 63/64 loss: 0.2365490198135376
Batch 64/64 loss: 0.21856963634490967
Epoch 489  Train loss: 0.22373460648106594  Val loss: 0.28216779989884894
Epoch 490
-------------------------------
Batch 1/64 loss: 0.22879111766815186
Batch 2/64 loss: 0.2131136655807495
Batch 3/64 loss: 0.22487175464630127
Batch 4/64 loss: 0.22083330154418945
Batch 5/64 loss: 0.2250453233718872
Batch 6/64 loss: 0.22555094957351685
Batch 7/64 loss: 0.2222449779510498
Batch 8/64 loss: 0.23171532154083252
Batch 9/64 loss: 0.2211993932723999
Batch 10/64 loss: 0.21886217594146729
Batch 11/64 loss: 0.2151200771331787
Batch 12/64 loss: 0.22484749555587769
Batch 13/64 loss: 0.21989846229553223
Batch 14/64 loss: 0.22235608100891113
Batch 15/64 loss: 0.22111356258392334
Batch 16/64 loss: 0.22738349437713623
Batch 17/64 loss: 0.22147750854492188
Batch 18/64 loss: 0.23846733570098877
Batch 19/64 loss: 0.22364091873168945
Batch 20/64 loss: 0.22198861837387085
Batch 21/64 loss: 0.22828203439712524
Batch 22/64 loss: 0.22864478826522827
Batch 23/64 loss: 0.22155606746673584
Batch 24/64 loss: 0.22441768646240234
Batch 25/64 loss: 0.21729445457458496
Batch 26/64 loss: 0.22123968601226807
Batch 27/64 loss: 0.2248414158821106
Batch 28/64 loss: 0.21986454725265503
Batch 29/64 loss: 0.2213449478149414
Batch 30/64 loss: 0.22983503341674805
Batch 31/64 loss: 0.21885323524475098
Batch 32/64 loss: 0.21967434883117676
Batch 33/64 loss: 0.2163560390472412
Batch 34/64 loss: 0.22779250144958496
Batch 35/64 loss: 0.22841835021972656
Batch 36/64 loss: 0.24205613136291504
Batch 37/64 loss: 0.2359822392463684
Batch 38/64 loss: 0.22862517833709717
Batch 39/64 loss: 0.22400569915771484
Batch 40/64 loss: 0.21732807159423828
Batch 41/64 loss: 0.20872598886489868
Batch 42/64 loss: 0.22115755081176758
Batch 43/64 loss: 0.21934419870376587
Batch 44/64 loss: 0.23815661668777466
Batch 45/64 loss: 0.22048074007034302
Batch 46/64 loss: 0.226798415184021
Batch 47/64 loss: 0.22134864330291748
Batch 48/64 loss: 0.22257894277572632
Batch 49/64 loss: 0.21223878860473633
Batch 50/64 loss: 0.21683084964752197
Batch 51/64 loss: 0.22417032718658447
Batch 52/64 loss: 0.2294471263885498
Batch 53/64 loss: 0.2239995002746582
Batch 54/64 loss: 0.23251873254776
Batch 55/64 loss: 0.22247982025146484
Batch 56/64 loss: 0.23322242498397827
Batch 57/64 loss: 0.22251880168914795
Batch 58/64 loss: 0.2263650894165039
Batch 59/64 loss: 0.2162296175956726
Batch 60/64 loss: 0.2212660312652588
Batch 61/64 loss: 0.22993826866149902
Batch 62/64 loss: 0.22327393293380737
Batch 63/64 loss: 0.21829164028167725
Batch 64/64 loss: 0.22020763158798218
Epoch 490  Train loss: 0.22370936099220726  Val loss: 0.2817198584989174
Epoch 491
-------------------------------
Batch 1/64 loss: 0.21773600578308105
Batch 2/64 loss: 0.22644078731536865
Batch 3/64 loss: 0.22235143184661865
Batch 4/64 loss: 0.2185649871826172
Batch 5/64 loss: 0.21675652265548706
Batch 6/64 loss: 0.2207598090171814
Batch 7/64 loss: 0.2260035276412964
Batch 8/64 loss: 0.22878992557525635
Batch 9/64 loss: 0.2262629270553589
Batch 10/64 loss: 0.2141932249069214
Batch 11/64 loss: 0.22635674476623535
Batch 12/64 loss: 0.22423815727233887
Batch 13/64 loss: 0.21273452043533325
Batch 14/64 loss: 0.23627030849456787
Batch 15/64 loss: 0.22179824113845825
Batch 16/64 loss: 0.23626673221588135
Batch 17/64 loss: 0.21486198902130127
Batch 18/64 loss: 0.22280478477478027
Batch 19/64 loss: 0.2310502529144287
Batch 20/64 loss: 0.21875685453414917
Batch 21/64 loss: 0.2243201732635498
Batch 22/64 loss: 0.21475601196289062
Batch 23/64 loss: 0.22887998819351196
Batch 24/64 loss: 0.23400914669036865
Batch 25/64 loss: 0.2358940839767456
Batch 26/64 loss: 0.21658474206924438
Batch 27/64 loss: 0.22847461700439453
Batch 28/64 loss: 0.22255748510360718
Batch 29/64 loss: 0.23121964931488037
Batch 30/64 loss: 0.22338902950286865
Batch 31/64 loss: 0.23214566707611084
Batch 32/64 loss: 0.22438478469848633
Batch 33/64 loss: 0.2248813509941101
Batch 34/64 loss: 0.2363857626914978
Batch 35/64 loss: 0.22534871101379395
Batch 36/64 loss: 0.23569869995117188
Batch 37/64 loss: 0.2257976531982422
Batch 38/64 loss: 0.2230285406112671
Batch 39/64 loss: 0.21253889799118042
Batch 40/64 loss: 0.21910512447357178
Batch 41/64 loss: 0.21809589862823486
Batch 42/64 loss: 0.23667097091674805
Batch 43/64 loss: 0.22271931171417236
Batch 44/64 loss: 0.2204376459121704
Batch 45/64 loss: 0.22355890274047852
Batch 46/64 loss: 0.22098898887634277
Batch 47/64 loss: 0.21850258111953735
Batch 48/64 loss: 0.21468079090118408
Batch 49/64 loss: 0.22223371267318726
Batch 50/64 loss: 0.23142296075820923
Batch 51/64 loss: 0.2199021577835083
Batch 52/64 loss: 0.21819019317626953
Batch 53/64 loss: 0.216353178024292
Batch 54/64 loss: 0.22288274765014648
Batch 55/64 loss: 0.22031748294830322
Batch 56/64 loss: 0.22536981105804443
Batch 57/64 loss: 0.22760504484176636
Batch 58/64 loss: 0.2236344814300537
Batch 59/64 loss: 0.2249985933303833
Batch 60/64 loss: 0.22695612907409668
Batch 61/64 loss: 0.2359755039215088
Batch 62/64 loss: 0.2249830961227417
Batch 63/64 loss: 0.22916245460510254
Batch 64/64 loss: 0.23062974214553833
Epoch 491  Train loss: 0.2243296125355889  Val loss: 0.2835977237249158
Epoch 492
-------------------------------
Batch 1/64 loss: 0.21683919429779053
Batch 2/64 loss: 0.2298240065574646
Batch 3/64 loss: 0.22317206859588623
Batch 4/64 loss: 0.23010540008544922
Batch 5/64 loss: 0.2264689803123474
Batch 6/64 loss: 0.22249430418014526
Batch 7/64 loss: 0.23966944217681885
Batch 8/64 loss: 0.21621525287628174
Batch 9/64 loss: 0.22366857528686523
Batch 10/64 loss: 0.21767950057983398
Batch 11/64 loss: 0.2182459831237793
Batch 12/64 loss: 0.22458428144454956
Batch 13/64 loss: 0.23071706295013428
Batch 14/64 loss: 0.22011131048202515
Batch 15/64 loss: 0.21852457523345947
Batch 16/64 loss: 0.22678053379058838
Batch 17/64 loss: 0.23417240381240845
Batch 18/64 loss: 0.21852803230285645
Batch 19/64 loss: 0.2246091365814209
Batch 20/64 loss: 0.22999334335327148
Batch 21/64 loss: 0.2275904417037964
Batch 22/64 loss: 0.2089291214942932
Batch 23/64 loss: 0.2208118438720703
Batch 24/64 loss: 0.21065187454223633
Batch 25/64 loss: 0.22161245346069336
Batch 26/64 loss: 0.22595512866973877
Batch 27/64 loss: 0.21021246910095215
Batch 28/64 loss: 0.22687441110610962
Batch 29/64 loss: 0.23334884643554688
Batch 30/64 loss: 0.2206031084060669
Batch 31/64 loss: 0.23022091388702393
Batch 32/64 loss: 0.2182520627975464
Batch 33/64 loss: 0.21962255239486694
Batch 34/64 loss: 0.22304171323776245
Batch 35/64 loss: 0.21855586767196655
Batch 36/64 loss: 0.214211106300354
Batch 37/64 loss: 0.22510844469070435
Batch 38/64 loss: 0.23309993743896484
Batch 39/64 loss: 0.2300325632095337
Batch 40/64 loss: 0.2215670347213745
Batch 41/64 loss: 0.22392559051513672
Batch 42/64 loss: 0.22983115911483765
Batch 43/64 loss: 0.2179551124572754
Batch 44/64 loss: 0.22260946035385132
Batch 45/64 loss: 0.22467172145843506
Batch 46/64 loss: 0.22584521770477295
Batch 47/64 loss: 0.22095227241516113
Batch 48/64 loss: 0.22218596935272217
Batch 49/64 loss: 0.22208774089813232
Batch 50/64 loss: 0.22056233882904053
Batch 51/64 loss: 0.22137731313705444
Batch 52/64 loss: 0.23052990436553955
Batch 53/64 loss: 0.2360692024230957
Batch 54/64 loss: 0.22295153141021729
Batch 55/64 loss: 0.21825051307678223
Batch 56/64 loss: 0.21987605094909668
Batch 57/64 loss: 0.2163500189781189
Batch 58/64 loss: 0.22242474555969238
Batch 59/64 loss: 0.2303299903869629
Batch 60/64 loss: 0.23338615894317627
Batch 61/64 loss: 0.23101425170898438
Batch 62/64 loss: 0.2201223373413086
Batch 63/64 loss: 0.21712422370910645
Batch 64/64 loss: 0.23638176918029785
Epoch 492  Train loss: 0.2236929323159012  Val loss: 0.28179027206709295
Epoch 493
-------------------------------
Batch 1/64 loss: 0.21175086498260498
Batch 2/64 loss: 0.21969300508499146
Batch 3/64 loss: 0.23134243488311768
Batch 4/64 loss: 0.22349411249160767
Batch 5/64 loss: 0.2254244089126587
Batch 6/64 loss: 0.2295706868171692
Batch 7/64 loss: 0.21820545196533203
Batch 8/64 loss: 0.22485435009002686
Batch 9/64 loss: 0.22184693813323975
Batch 10/64 loss: 0.22663605213165283
Batch 11/64 loss: 0.23501276969909668
Batch 12/64 loss: 0.2231454849243164
Batch 13/64 loss: 0.22497129440307617
Batch 14/64 loss: 0.21854567527770996
Batch 15/64 loss: 0.21947890520095825
Batch 16/64 loss: 0.2173011302947998
Batch 17/64 loss: 0.2231317162513733
Batch 18/64 loss: 0.21664202213287354
Batch 19/64 loss: 0.23144304752349854
Batch 20/64 loss: 0.21826744079589844
Batch 21/64 loss: 0.23685693740844727
Batch 22/64 loss: 0.22570157051086426
Batch 23/64 loss: 0.2298372983932495
Batch 24/64 loss: 0.21930742263793945
Batch 25/64 loss: 0.22603833675384521
Batch 26/64 loss: 0.22178292274475098
Batch 27/64 loss: 0.22146642208099365
Batch 28/64 loss: 0.2127334475517273
Batch 29/64 loss: 0.22721022367477417
Batch 30/64 loss: 0.2166231870651245
Batch 31/64 loss: 0.21838176250457764
Batch 32/64 loss: 0.21753036975860596
Batch 33/64 loss: 0.22214186191558838
Batch 34/64 loss: 0.21824759244918823
Batch 35/64 loss: 0.21918123960494995
Batch 36/64 loss: 0.2152881622314453
Batch 37/64 loss: 0.22883546352386475
Batch 38/64 loss: 0.22694158554077148
Batch 39/64 loss: 0.22515982389450073
Batch 40/64 loss: 0.22446125745773315
Batch 41/64 loss: 0.21386700868606567
Batch 42/64 loss: 0.2397335171699524
Batch 43/64 loss: 0.2285122275352478
Batch 44/64 loss: 0.22357910871505737
Batch 45/64 loss: 0.22163444757461548
Batch 46/64 loss: 0.22963488101959229
Batch 47/64 loss: 0.22408246994018555
Batch 48/64 loss: 0.2106609344482422
Batch 49/64 loss: 0.23255681991577148
Batch 50/64 loss: 0.22427219152450562
Batch 51/64 loss: 0.23440217971801758
Batch 52/64 loss: 0.22323894500732422
Batch 53/64 loss: 0.22545188665390015
Batch 54/64 loss: 0.22855156660079956
Batch 55/64 loss: 0.22127044200897217
Batch 56/64 loss: 0.21997594833374023
Batch 57/64 loss: 0.22896552085876465
Batch 58/64 loss: 0.22922372817993164
Batch 59/64 loss: 0.22454726696014404
Batch 60/64 loss: 0.22025996446609497
Batch 61/64 loss: 0.23023027181625366
Batch 62/64 loss: 0.23058342933654785
Batch 63/64 loss: 0.2247859239578247
Batch 64/64 loss: 0.22316038608551025
Epoch 493  Train loss: 0.22387255921083338  Val loss: 0.2812123827098571
Epoch 494
-------------------------------
Batch 1/64 loss: 0.22649532556533813
Batch 2/64 loss: 0.22912979125976562
Batch 3/64 loss: 0.21851104497909546
Batch 4/64 loss: 0.220442533493042
Batch 5/64 loss: 0.21438908576965332
Batch 6/64 loss: 0.22103047370910645
Batch 7/64 loss: 0.2173764705657959
Batch 8/64 loss: 0.2170301079750061
Batch 9/64 loss: 0.228834331035614
Batch 10/64 loss: 0.2329775094985962
Batch 11/64 loss: 0.22137939929962158
Batch 12/64 loss: 0.23455047607421875
Batch 13/64 loss: 0.2190873622894287
Batch 14/64 loss: 0.2274235486984253
Batch 15/64 loss: 0.2350618839263916
Batch 16/64 loss: 0.22273409366607666
Batch 17/64 loss: 0.21984100341796875
Batch 18/64 loss: 0.2192678451538086
Batch 19/64 loss: 0.223666250705719
Batch 20/64 loss: 0.21297508478164673
Batch 21/64 loss: 0.22716224193572998
Batch 22/64 loss: 0.23341912031173706
Batch 23/64 loss: 0.22048258781433105
Batch 24/64 loss: 0.2186577320098877
Batch 25/64 loss: 0.22000926733016968
Batch 26/64 loss: 0.22026222944259644
Batch 27/64 loss: 0.23567050695419312
Batch 28/64 loss: 0.2333458662033081
Batch 29/64 loss: 0.21839219331741333
Batch 30/64 loss: 0.23835480213165283
Batch 31/64 loss: 0.22820311784744263
Batch 32/64 loss: 0.2228618860244751
Batch 33/64 loss: 0.22562944889068604
Batch 34/64 loss: 0.22519290447235107
Batch 35/64 loss: 0.22034931182861328
Batch 36/64 loss: 0.21318024396896362
Batch 37/64 loss: 0.22980177402496338
Batch 38/64 loss: 0.2212376594543457
Batch 39/64 loss: 0.22114795446395874
Batch 40/64 loss: 0.22783291339874268
Batch 41/64 loss: 0.20994508266448975
Batch 42/64 loss: 0.21500235795974731
Batch 43/64 loss: 0.21440237760543823
Batch 44/64 loss: 0.22071313858032227
Batch 45/64 loss: 0.22155457735061646
Batch 46/64 loss: 0.2265205979347229
Batch 47/64 loss: 0.2291254997253418
Batch 48/64 loss: 0.2178349494934082
Batch 49/64 loss: 0.2242894172668457
Batch 50/64 loss: 0.22124958038330078
Batch 51/64 loss: 0.21226531267166138
Batch 52/64 loss: 0.22262346744537354
Batch 53/64 loss: 0.2198946475982666
Batch 54/64 loss: 0.2302045226097107
Batch 55/64 loss: 0.23071599006652832
Batch 56/64 loss: 0.21654987335205078
Batch 57/64 loss: 0.22118079662322998
Batch 58/64 loss: 0.21796244382858276
Batch 59/64 loss: 0.22409003973007202
Batch 60/64 loss: 0.22289282083511353
Batch 61/64 loss: 0.22391968965530396
Batch 62/64 loss: 0.2323651909828186
Batch 63/64 loss: 0.2274773120880127
Batch 64/64 loss: 0.22148287296295166
Epoch 494  Train loss: 0.2232515956841263  Val loss: 0.28195953963138803
Epoch 495
-------------------------------
Batch 1/64 loss: 0.22873926162719727
Batch 2/64 loss: 0.22172081470489502
Batch 3/64 loss: 0.21629106998443604
Batch 4/64 loss: 0.22729772329330444
Batch 5/64 loss: 0.22336876392364502
Batch 6/64 loss: 0.23460322618484497
Batch 7/64 loss: 0.21913498640060425
Batch 8/64 loss: 0.23187756538391113
Batch 9/64 loss: 0.22527384757995605
Batch 10/64 loss: 0.23144686222076416
Batch 11/64 loss: 0.22208356857299805
Batch 12/64 loss: 0.2211400270462036
Batch 13/64 loss: 0.2236778736114502
Batch 14/64 loss: 0.22706735134124756
Batch 15/64 loss: 0.2195603847503662
Batch 16/64 loss: 0.219451904296875
Batch 17/64 loss: 0.21657401323318481
Batch 18/64 loss: 0.23027706146240234
Batch 19/64 loss: 0.21526473760604858
Batch 20/64 loss: 0.2243659496307373
Batch 21/64 loss: 0.20998787879943848
Batch 22/64 loss: 0.22426432371139526
Batch 23/64 loss: 0.22056305408477783
Batch 24/64 loss: 0.22161179780960083
Batch 25/64 loss: 0.21634894609451294
Batch 26/64 loss: 0.22124195098876953
Batch 27/64 loss: 0.22497057914733887
Batch 28/64 loss: 0.23846423625946045
Batch 29/64 loss: 0.21873176097869873
Batch 30/64 loss: 0.21378231048583984
Batch 31/64 loss: 0.2188735008239746
Batch 32/64 loss: 0.21641170978546143
Batch 33/64 loss: 0.21571248769760132
Batch 34/64 loss: 0.22461092472076416
Batch 35/64 loss: 0.21488714218139648
Batch 36/64 loss: 0.22540020942687988
Batch 37/64 loss: 0.229253888130188
Batch 38/64 loss: 0.22642362117767334
Batch 39/64 loss: 0.23222965002059937
Batch 40/64 loss: 0.22115397453308105
Batch 41/64 loss: 0.2239398956298828
Batch 42/64 loss: 0.22447288036346436
Batch 43/64 loss: 0.22289037704467773
Batch 44/64 loss: 0.2150089144706726
Batch 45/64 loss: 0.2134718894958496
Batch 46/64 loss: 0.21876311302185059
Batch 47/64 loss: 0.22702360153198242
Batch 48/64 loss: 0.2293623685836792
Batch 49/64 loss: 0.2283552885055542
Batch 50/64 loss: 0.22732436656951904
Batch 51/64 loss: 0.23108422756195068
Batch 52/64 loss: 0.22650253772735596
Batch 53/64 loss: 0.225150465965271
Batch 54/64 loss: 0.22777551412582397
Batch 55/64 loss: 0.22724676132202148
Batch 56/64 loss: 0.22341537475585938
Batch 57/64 loss: 0.21614062786102295
Batch 58/64 loss: 0.2262188196182251
Batch 59/64 loss: 0.21770155429840088
Batch 60/64 loss: 0.2223532795906067
Batch 61/64 loss: 0.23041343688964844
Batch 62/64 loss: 0.23412835597991943
Batch 63/64 loss: 0.23007839918136597
Batch 64/64 loss: 0.22114050388336182
Epoch 495  Train loss: 0.22351087635638667  Val loss: 0.28267653639783563
Epoch 496
-------------------------------
Batch 1/64 loss: 0.23475611209869385
Batch 2/64 loss: 0.2191462516784668
Batch 3/64 loss: 0.2251042127609253
Batch 4/64 loss: 0.223471999168396
Batch 5/64 loss: 0.21409106254577637
Batch 6/64 loss: 0.221824049949646
Batch 7/64 loss: 0.21708476543426514
Batch 8/64 loss: 0.22063887119293213
Batch 9/64 loss: 0.2238243818283081
Batch 10/64 loss: 0.2397139072418213
Batch 11/64 loss: 0.21927523612976074
Batch 12/64 loss: 0.2190183401107788
Batch 13/64 loss: 0.22190064191818237
Batch 14/64 loss: 0.22564786672592163
Batch 15/64 loss: 0.22696244716644287
Batch 16/64 loss: 0.22098028659820557
Batch 17/64 loss: 0.21885907649993896
Batch 18/64 loss: 0.22819149494171143
Batch 19/64 loss: 0.2157624363899231
Batch 20/64 loss: 0.23579728603363037
Batch 21/64 loss: 0.22089052200317383
Batch 22/64 loss: 0.21506094932556152
Batch 23/64 loss: 0.22180819511413574
Batch 24/64 loss: 0.22572433948516846
Batch 25/64 loss: 0.23038172721862793
Batch 26/64 loss: 0.22315043210983276
Batch 27/64 loss: 0.21831047534942627
Batch 28/64 loss: 0.222143292427063
Batch 29/64 loss: 0.2175803780555725
Batch 30/64 loss: 0.2318040132522583
Batch 31/64 loss: 0.2229558229446411
Batch 32/64 loss: 0.21373218297958374
Batch 33/64 loss: 0.22592031955718994
Batch 34/64 loss: 0.22193384170532227
Batch 35/64 loss: 0.22318994998931885
Batch 36/64 loss: 0.22310882806777954
Batch 37/64 loss: 0.22554242610931396
Batch 38/64 loss: 0.2343342900276184
Batch 39/64 loss: 0.22570812702178955
Batch 40/64 loss: 0.2253841757774353
Batch 41/64 loss: 0.2172609567642212
Batch 42/64 loss: 0.23529750108718872
Batch 43/64 loss: 0.21664977073669434
Batch 44/64 loss: 0.22132694721221924
Batch 45/64 loss: 0.22410959005355835
Batch 46/64 loss: 0.2163635492324829
Batch 47/64 loss: 0.23127639293670654
Batch 48/64 loss: 0.2192246913909912
Batch 49/64 loss: 0.23649239540100098
Batch 50/64 loss: 0.21982717514038086
Batch 51/64 loss: 0.2335292100906372
Batch 52/64 loss: 0.23319196701049805
Batch 53/64 loss: 0.22133100032806396
Batch 54/64 loss: 0.2170029878616333
Batch 55/64 loss: 0.2281879186630249
Batch 56/64 loss: 0.22047996520996094
Batch 57/64 loss: 0.22126346826553345
Batch 58/64 loss: 0.2193770408630371
Batch 59/64 loss: 0.21671897172927856
Batch 60/64 loss: 0.21698349714279175
Batch 61/64 loss: 0.21379852294921875
Batch 62/64 loss: 0.22164463996887207
Batch 63/64 loss: 0.234988272190094
Batch 64/64 loss: 0.22642767429351807
Epoch 496  Train loss: 0.2234801914177689  Val loss: 0.2824367393333068
Epoch 497
-------------------------------
Batch 1/64 loss: 0.2208768129348755
Batch 2/64 loss: 0.21915417909622192
Batch 3/64 loss: 0.23041987419128418
Batch 4/64 loss: 0.22205960750579834
Batch 5/64 loss: 0.21652042865753174
Batch 6/64 loss: 0.22114765644073486
Batch 7/64 loss: 0.23012548685073853
Batch 8/64 loss: 0.21645236015319824
Batch 9/64 loss: 0.2140364646911621
Batch 10/64 loss: 0.2182113528251648
Batch 11/64 loss: 0.22947317361831665
Batch 12/64 loss: 0.22036045789718628
Batch 13/64 loss: 0.23064714670181274
Batch 14/64 loss: 0.22604906558990479
Batch 15/64 loss: 0.21465373039245605
Batch 16/64 loss: 0.21920257806777954
Batch 17/64 loss: 0.23343783617019653
Batch 18/64 loss: 0.21532130241394043
Batch 19/64 loss: 0.22521471977233887
Batch 20/64 loss: 0.23766934871673584
Batch 21/64 loss: 0.2071824073791504
Batch 22/64 loss: 0.21534067392349243
Batch 23/64 loss: 0.224462628364563
Batch 24/64 loss: 0.23299527168273926
Batch 25/64 loss: 0.22572076320648193
Batch 26/64 loss: 0.21611404418945312
Batch 27/64 loss: 0.22785460948944092
Batch 28/64 loss: 0.22494471073150635
Batch 29/64 loss: 0.22997534275054932
Batch 30/64 loss: 0.21715021133422852
Batch 31/64 loss: 0.22890007495880127
Batch 32/64 loss: 0.22237980365753174
Batch 33/64 loss: 0.22108536958694458
Batch 34/64 loss: 0.22605907917022705
Batch 35/64 loss: 0.23649334907531738
Batch 36/64 loss: 0.22569596767425537
Batch 37/64 loss: 0.22587502002716064
Batch 38/64 loss: 0.22396856546401978
Batch 39/64 loss: 0.2210676670074463
Batch 40/64 loss: 0.22386884689331055
Batch 41/64 loss: 0.22356784343719482
Batch 42/64 loss: 0.2289634346961975
Batch 43/64 loss: 0.22794115543365479
Batch 44/64 loss: 0.21852362155914307
Batch 45/64 loss: 0.22431325912475586
Batch 46/64 loss: 0.22298192977905273
Batch 47/64 loss: 0.23500216007232666
Batch 48/64 loss: 0.21720296144485474
Batch 49/64 loss: 0.2268904447555542
Batch 50/64 loss: 0.22200453281402588
Batch 51/64 loss: 0.22327202558517456
Batch 52/64 loss: 0.2256118655204773
Batch 53/64 loss: 0.2296069860458374
Batch 54/64 loss: 0.2280651330947876
Batch 55/64 loss: 0.22501039505004883
Batch 56/64 loss: 0.22904646396636963
Batch 57/64 loss: 0.22168636322021484
Batch 58/64 loss: 0.2228052020072937
Batch 59/64 loss: 0.2212144136428833
Batch 60/64 loss: 0.22042226791381836
Batch 61/64 loss: 0.2406495213508606
Batch 62/64 loss: 0.22477853298187256
Batch 63/64 loss: 0.21007251739501953
Batch 64/64 loss: 0.2220209240913391
Epoch 497  Train loss: 0.22391085040335562  Val loss: 0.2811724248620653
Epoch 498
-------------------------------
Batch 1/64 loss: 0.217901349067688
Batch 2/64 loss: 0.2091677188873291
Batch 3/64 loss: 0.2106400728225708
Batch 4/64 loss: 0.22083234786987305
Batch 5/64 loss: 0.22572457790374756
Batch 6/64 loss: 0.22061949968338013
Batch 7/64 loss: 0.22468990087509155
Batch 8/64 loss: 0.23910248279571533
Batch 9/64 loss: 0.21793913841247559
Batch 10/64 loss: 0.21130859851837158
Batch 11/64 loss: 0.21745723485946655
Batch 12/64 loss: 0.22528398036956787
Batch 13/64 loss: 0.2291300892829895
Batch 14/64 loss: 0.21926724910736084
Batch 15/64 loss: 0.22450566291809082
Batch 16/64 loss: 0.21779298782348633
Batch 17/64 loss: 0.21489793062210083
Batch 18/64 loss: 0.22117918729782104
Batch 19/64 loss: 0.22355592250823975
Batch 20/64 loss: 0.23056328296661377
Batch 21/64 loss: 0.21734941005706787
Batch 22/64 loss: 0.22242724895477295
Batch 23/64 loss: 0.2225055694580078
Batch 24/64 loss: 0.22049975395202637
Batch 25/64 loss: 0.22887229919433594
Batch 26/64 loss: 0.22219550609588623
Batch 27/64 loss: 0.22619551420211792
Batch 28/64 loss: 0.2272159457206726
Batch 29/64 loss: 0.23587143421173096
Batch 30/64 loss: 0.23100030422210693
Batch 31/64 loss: 0.2189100980758667
Batch 32/64 loss: 0.21911460161209106
Batch 33/64 loss: 0.21915102005004883
Batch 34/64 loss: 0.21375900506973267
Batch 35/64 loss: 0.21578609943389893
Batch 36/64 loss: 0.2203000783920288
Batch 37/64 loss: 0.22308850288391113
Batch 38/64 loss: 0.21822893619537354
Batch 39/64 loss: 0.22259652614593506
Batch 40/64 loss: 0.22504067420959473
Batch 41/64 loss: 0.22202003002166748
Batch 42/64 loss: 0.23825347423553467
Batch 43/64 loss: 0.22127056121826172
Batch 44/64 loss: 0.21858346462249756
Batch 45/64 loss: 0.2322055697441101
Batch 46/64 loss: 0.23180997371673584
Batch 47/64 loss: 0.21831190586090088
Batch 48/64 loss: 0.2162550687789917
Batch 49/64 loss: 0.24313753843307495
Batch 50/64 loss: 0.2211393117904663
Batch 51/64 loss: 0.22788774967193604
Batch 52/64 loss: 0.22041678428649902
Batch 53/64 loss: 0.2170611023902893
Batch 54/64 loss: 0.23879021406173706
Batch 55/64 loss: 0.21585261821746826
Batch 56/64 loss: 0.21968746185302734
Batch 57/64 loss: 0.22751760482788086
Batch 58/64 loss: 0.23531627655029297
Batch 59/64 loss: 0.22391462326049805
Batch 60/64 loss: 0.21939200162887573
Batch 61/64 loss: 0.222070574760437
Batch 62/64 loss: 0.22544866800308228
Batch 63/64 loss: 0.21539294719696045
Batch 64/64 loss: 0.2296406626701355
Epoch 498  Train loss: 0.22299033356647865  Val loss: 0.28180899898620815
Epoch 499
-------------------------------
Batch 1/64 loss: 0.21347904205322266
Batch 2/64 loss: 0.21101748943328857
Batch 3/64 loss: 0.22835922241210938
Batch 4/64 loss: 0.21801114082336426
Batch 5/64 loss: 0.22376835346221924
Batch 6/64 loss: 0.23814433813095093
Batch 7/64 loss: 0.2192450761795044
Batch 8/64 loss: 0.22618389129638672
Batch 9/64 loss: 0.21476387977600098
Batch 10/64 loss: 0.23693817853927612
Batch 11/64 loss: 0.22818994522094727
Batch 12/64 loss: 0.20809364318847656
Batch 13/64 loss: 0.2148655652999878
Batch 14/64 loss: 0.2112112045288086
Batch 15/64 loss: 0.22875893115997314
Batch 16/64 loss: 0.23563754558563232
Batch 17/64 loss: 0.2241499423980713
Batch 18/64 loss: 0.2267506718635559
Batch 19/64 loss: 0.21724188327789307
Batch 20/64 loss: 0.22410213947296143
Batch 21/64 loss: 0.22133195400238037
Batch 22/64 loss: 0.21151328086853027
Batch 23/64 loss: 0.2304059863090515
Batch 24/64 loss: 0.22248142957687378
Batch 25/64 loss: 0.222373366355896
Batch 26/64 loss: 0.21041208505630493
Batch 27/64 loss: 0.2295798659324646
Batch 28/64 loss: 0.22361540794372559
Batch 29/64 loss: 0.21155887842178345
Batch 30/64 loss: 0.2231319546699524
Batch 31/64 loss: 0.22711646556854248
Batch 32/64 loss: 0.23176556825637817
Batch 33/64 loss: 0.23763179779052734
Batch 34/64 loss: 0.22934842109680176
Batch 35/64 loss: 0.22138214111328125
Batch 36/64 loss: 0.226252019405365
Batch 37/64 loss: 0.22433042526245117
Batch 38/64 loss: 0.22598117589950562
Batch 39/64 loss: 0.22626018524169922
Batch 40/64 loss: 0.22814661264419556
Batch 41/64 loss: 0.22066867351531982
Batch 42/64 loss: 0.2134162187576294
Batch 43/64 loss: 0.2170749306678772
Batch 44/64 loss: 0.22239536046981812
Batch 45/64 loss: 0.21670663356781006
Batch 46/64 loss: 0.21436762809753418
Batch 47/64 loss: 0.23819130659103394
Batch 48/64 loss: 0.22363269329071045
Batch 49/64 loss: 0.21570438146591187
Batch 50/64 loss: 0.2265000343322754
Batch 51/64 loss: 0.21726572513580322
Batch 52/64 loss: 0.21989166736602783
Batch 53/64 loss: 0.22010374069213867
Batch 54/64 loss: 0.21194255352020264
Batch 55/64 loss: 0.21746063232421875
Batch 56/64 loss: 0.22892791032791138
Batch 57/64 loss: 0.21725142002105713
Batch 58/64 loss: 0.2236253023147583
Batch 59/64 loss: 0.21939194202423096
Batch 60/64 loss: 0.23809587955474854
Batch 61/64 loss: 0.22244751453399658
Batch 62/64 loss: 0.22057175636291504
Batch 63/64 loss: 0.22186851501464844
Batch 64/64 loss: 0.22034335136413574
Epoch 499  Train loss: 0.22253005551356894  Val loss: 0.2820728640376088
Epoch 500
-------------------------------
Batch 1/64 loss: 0.21337687969207764
Batch 2/64 loss: 0.20953798294067383
Batch 3/64 loss: 0.22789406776428223
Batch 4/64 loss: 0.2187855839729309
Batch 5/64 loss: 0.2248934507369995
Batch 6/64 loss: 0.22524166107177734
Batch 7/64 loss: 0.23404473066329956
Batch 8/64 loss: 0.2273874282836914
Batch 9/64 loss: 0.22491735219955444
Batch 10/64 loss: 0.22899079322814941
Batch 11/64 loss: 0.23322391510009766
Batch 12/64 loss: 0.22237837314605713
Batch 13/64 loss: 0.22280943393707275
Batch 14/64 loss: 0.22382211685180664
Batch 15/64 loss: 0.22253262996673584
Batch 16/64 loss: 0.22112756967544556
Batch 17/64 loss: 0.2274254560470581
Batch 18/64 loss: 0.22455978393554688
Batch 19/64 loss: 0.21717298030853271
Batch 20/64 loss: 0.21931838989257812
Batch 21/64 loss: 0.21783459186553955
Batch 22/64 loss: 0.2261485457420349
Batch 23/64 loss: 0.22365254163742065
Batch 24/64 loss: 0.22173386812210083
Batch 25/64 loss: 0.23439466953277588
Batch 26/64 loss: 0.21842432022094727
Batch 27/64 loss: 0.22316014766693115
Batch 28/64 loss: 0.22485381364822388
Batch 29/64 loss: 0.231231689453125
Batch 30/64 loss: 0.22728770971298218
Batch 31/64 loss: 0.21826696395874023
Batch 32/64 loss: 0.22626566886901855
Batch 33/64 loss: 0.22977042198181152
Batch 34/64 loss: 0.22302842140197754
Batch 35/64 loss: 0.20998156070709229
Batch 36/64 loss: 0.24119412899017334
Batch 37/64 loss: 0.22685503959655762
Batch 38/64 loss: 0.22571265697479248
Batch 39/64 loss: 0.2193310260772705
Batch 40/64 loss: 0.22059500217437744
Batch 41/64 loss: 0.21785080432891846
Batch 42/64 loss: 0.21448582410812378
Batch 43/64 loss: 0.22939252853393555
Batch 44/64 loss: 0.21596664190292358
Batch 45/64 loss: 0.2260475754737854
Batch 46/64 loss: 0.22267675399780273
Batch 47/64 loss: 0.21455174684524536
Batch 48/64 loss: 0.23302948474884033
Batch 49/64 loss: 0.2306218147277832
Batch 50/64 loss: 0.21930718421936035
Batch 51/64 loss: 0.21143949031829834
Batch 52/64 loss: 0.21659088134765625
Batch 53/64 loss: 0.22221475839614868
Batch 54/64 loss: 0.2263491153717041
Batch 55/64 loss: 0.2217627763748169
Batch 56/64 loss: 0.22529828548431396
Batch 57/64 loss: 0.21147441864013672
Batch 58/64 loss: 0.22392714023590088
Batch 59/64 loss: 0.23022902011871338
Batch 60/64 loss: 0.2272946834564209
Batch 61/64 loss: 0.22169208526611328
Batch 62/64 loss: 0.2322787642478943
Batch 63/64 loss: 0.21769320964813232
Batch 64/64 loss: 0.21362954378128052
Epoch 500  Train loss: 0.22324016491572063  Val loss: 0.2816683584472158
SLIC undersegmentation error: 0.054052233676975946
SLIC inter-cluster variation: 0.02397972047789259
SLIC number of superpixels: 162588
SLIC superpixels per image: 558.7216494845361
Model loaded
Test metrics:
0.2775890784165294 0.17698831615120275 11.691137695411072 tensor(0.0958, dtype=torch.float64) 0.4235363561520419 1.6938036876524225 64377
Inference time: 0.004425129939600364 seconds
Relabeled undersegmentation error: 0.08795601374570453
Relabeled inter-cluster variation: 0.047446581911766844
Relabeled mean superpixels count: 374.7147766323024
Original mean superpixels count: 221.22680412371133
Done!
Job id: 420585
Job id: 422878
