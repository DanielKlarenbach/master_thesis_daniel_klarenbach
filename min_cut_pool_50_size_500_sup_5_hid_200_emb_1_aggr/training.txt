Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 0.444977343082428
Batch 2/64 loss: 0.4045381546020508
Batch 3/64 loss: 0.3957916498184204
Batch 4/64 loss: 0.3908134698867798
Batch 5/64 loss: 0.3862936496734619
Batch 6/64 loss: 0.3867369294166565
Batch 7/64 loss: 0.3853006958961487
Batch 8/64 loss: 0.3849303722381592
Batch 9/64 loss: 0.38315653800964355
Batch 10/64 loss: 0.38305366039276123
Batch 11/64 loss: 0.38215136528015137
Batch 12/64 loss: 0.38114798069000244
Batch 13/64 loss: 0.38175439834594727
Batch 14/64 loss: 0.381862998008728
Batch 15/64 loss: 0.3809557557106018
Batch 16/64 loss: 0.38133686780929565
Batch 17/64 loss: 0.38150328397750854
Batch 18/64 loss: 0.37990570068359375
Batch 19/64 loss: 0.37955063581466675
Batch 20/64 loss: 0.3802868723869324
Batch 21/64 loss: 0.37891125679016113
Batch 22/64 loss: 0.38047170639038086
Batch 23/64 loss: 0.379925012588501
Batch 24/64 loss: 0.3790804147720337
Batch 25/64 loss: 0.37832391262054443
Batch 26/64 loss: 0.3789796829223633
Batch 27/64 loss: 0.3789864778518677
Batch 28/64 loss: 0.37830376625061035
Batch 29/64 loss: 0.37910377979278564
Batch 30/64 loss: 0.3788536787033081
Batch 31/64 loss: 0.3778151273727417
Batch 32/64 loss: 0.37778109312057495
Batch 33/64 loss: 0.3795959949493408
Batch 34/64 loss: 0.37865084409713745
Batch 35/64 loss: 0.3790842294692993
Batch 36/64 loss: 0.37677836418151855
Batch 37/64 loss: 0.37790191173553467
Batch 38/64 loss: 0.3787320852279663
Batch 39/64 loss: 0.3770846128463745
Batch 40/64 loss: 0.3769937753677368
Batch 41/64 loss: 0.3774927258491516
Batch 42/64 loss: 0.3765318989753723
Batch 43/64 loss: 0.3760772943496704
Batch 44/64 loss: 0.376304030418396
Batch 45/64 loss: 0.37676167488098145
Batch 46/64 loss: 0.37623417377471924
Batch 47/64 loss: 0.3776496648788452
Batch 48/64 loss: 0.37743693590164185
Batch 49/64 loss: 0.3771359920501709
Batch 50/64 loss: 0.3767836093902588
Batch 51/64 loss: 0.37445420026779175
Batch 52/64 loss: 0.3737984299659729
Batch 53/64 loss: 0.3763117790222168
Batch 54/64 loss: 0.37300145626068115
Batch 55/64 loss: 0.3765296936035156
Batch 56/64 loss: 0.37609410285949707
Batch 57/64 loss: 0.37580811977386475
Batch 58/64 loss: 0.3754308223724365
Batch 59/64 loss: 0.3745386600494385
Batch 60/64 loss: 0.37573957443237305
Batch 61/64 loss: 0.3752481937408447
Batch 62/64 loss: 0.37405312061309814
Batch 63/64 loss: 0.3749009370803833
Batch 64/64 loss: 0.3746035695075989
Epoch 1  Train loss: 0.3804341304535959  Val loss: 0.3775603236611356
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 0.37432628870010376
Batch 2/64 loss: 0.37627851963043213
Batch 3/64 loss: 0.3751729726791382
Batch 4/64 loss: 0.37501049041748047
Batch 5/64 loss: 0.37437593936920166
Batch 6/64 loss: 0.37472301721572876
Batch 7/64 loss: 0.373785138130188
Batch 8/64 loss: 0.37554627656936646
Batch 9/64 loss: 0.37263762950897217
Batch 10/64 loss: 0.3739645481109619
Batch 11/64 loss: 0.3742086887359619
Batch 12/64 loss: 0.3748760223388672
Batch 13/64 loss: 0.37391769886016846
Batch 14/64 loss: 0.37411338090896606
Batch 15/64 loss: 0.3733079433441162
Batch 16/64 loss: 0.3730137348175049
Batch 17/64 loss: 0.3729838728904724
Batch 18/64 loss: 0.3728630542755127
Batch 19/64 loss: 0.37351858615875244
Batch 20/64 loss: 0.37282270193099976
Batch 21/64 loss: 0.37290048599243164
Batch 22/64 loss: 0.37222254276275635
Batch 23/64 loss: 0.3733920454978943
Batch 24/64 loss: 0.3744434118270874
Batch 25/64 loss: 0.3741731643676758
Batch 26/64 loss: 0.37232571840286255
Batch 27/64 loss: 0.37349534034729004
Batch 28/64 loss: 0.37266719341278076
Batch 29/64 loss: 0.3742140531539917
Batch 30/64 loss: 0.3732330799102783
Batch 31/64 loss: 0.37425661087036133
Batch 32/64 loss: 0.37296175956726074
Batch 33/64 loss: 0.37209653854370117
Batch 34/64 loss: 0.3726932406425476
Batch 35/64 loss: 0.37403953075408936
Batch 36/64 loss: 0.37262213230133057
Batch 37/64 loss: 0.3734312057495117
Batch 38/64 loss: 0.3740614652633667
Batch 39/64 loss: 0.37428373098373413
Batch 40/64 loss: 0.37248754501342773
Batch 41/64 loss: 0.37225663661956787
Batch 42/64 loss: 0.3711584806442261
Batch 43/64 loss: 0.3742350935935974
Batch 44/64 loss: 0.37280064821243286
Batch 45/64 loss: 0.37339985370635986
Batch 46/64 loss: 0.3717488646507263
Batch 47/64 loss: 0.3731963634490967
Batch 48/64 loss: 0.3740568161010742
Batch 49/64 loss: 0.37212681770324707
Batch 50/64 loss: 0.37354838848114014
Batch 51/64 loss: 0.37162017822265625
Batch 52/64 loss: 0.37311822175979614
Batch 53/64 loss: 0.3705986738204956
Batch 54/64 loss: 0.3725926876068115
Batch 55/64 loss: 0.37303054332733154
Batch 56/64 loss: 0.3705545663833618
Batch 57/64 loss: 0.3716582655906677
Batch 58/64 loss: 0.36987829208374023
Batch 59/64 loss: 0.37307101488113403
Batch 60/64 loss: 0.3742353916168213
Batch 61/64 loss: 0.3712259531021118
Batch 62/64 loss: 0.3703348636627197
Batch 63/64 loss: 0.37150847911834717
Batch 64/64 loss: 0.36978137493133545
Epoch 2  Train loss: 0.37312530863518806  Val loss: 0.3716194068443325
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 0.3715493679046631
Batch 2/64 loss: 0.3726005554199219
Batch 3/64 loss: 0.3729012608528137
Batch 4/64 loss: 0.3706256151199341
Batch 5/64 loss: 0.37152522802352905
Batch 6/64 loss: 0.3723379373550415
Batch 7/64 loss: 0.3701040744781494
Batch 8/64 loss: 0.37046366930007935
Batch 9/64 loss: 0.36963099241256714
Batch 10/64 loss: 0.36953628063201904
Batch 11/64 loss: 0.37048518657684326
Batch 12/64 loss: 0.3720736503601074
Batch 13/64 loss: 0.3708644509315491
Batch 14/64 loss: 0.3713763952255249
Batch 15/64 loss: 0.3712478280067444
Batch 16/64 loss: 0.37058472633361816
Batch 17/64 loss: 0.37026745080947876
Batch 18/64 loss: 0.37101197242736816
Batch 19/64 loss: 0.37115269899368286
Batch 20/64 loss: 0.37207722663879395
Batch 21/64 loss: 0.36661219596862793
Batch 22/64 loss: 0.3726454973220825
Batch 23/64 loss: 0.37019968032836914
Batch 24/64 loss: 0.3701011538505554
Batch 25/64 loss: 0.36979615688323975
Batch 26/64 loss: 0.37035661935806274
Batch 27/64 loss: 0.3700184226036072
Batch 28/64 loss: 0.36961662769317627
Batch 29/64 loss: 0.37049102783203125
Batch 30/64 loss: 0.37061262130737305
Batch 31/64 loss: 0.3710405230522156
Batch 32/64 loss: 0.36861371994018555
Batch 33/64 loss: 0.3705834150314331
Batch 34/64 loss: 0.372955322265625
Batch 35/64 loss: 0.3699023723602295
Batch 36/64 loss: 0.36760902404785156
Batch 37/64 loss: 0.3693479299545288
Batch 38/64 loss: 0.36934608221054077
Batch 39/64 loss: 0.3691062927246094
Batch 40/64 loss: 0.3691515326499939
Batch 41/64 loss: 0.36746877431869507
Batch 42/64 loss: 0.36934566497802734
Batch 43/64 loss: 0.3681877851486206
Batch 44/64 loss: 0.3694576025009155
Batch 45/64 loss: 0.36980533599853516
Batch 46/64 loss: 0.3693891763687134
Batch 47/64 loss: 0.36932867765426636
Batch 48/64 loss: 0.36870884895324707
Batch 49/64 loss: 0.3698608875274658
Batch 50/64 loss: 0.3689444065093994
Batch 51/64 loss: 0.3707408905029297
Batch 52/64 loss: 0.3712965250015259
Batch 53/64 loss: 0.37134552001953125
Batch 54/64 loss: 0.36999380588531494
Batch 55/64 loss: 0.36721599102020264
Batch 56/64 loss: 0.36889559030532837
Batch 57/64 loss: 0.37050294876098633
Batch 58/64 loss: 0.37004685401916504
Batch 59/64 loss: 0.3691287040710449
Batch 60/64 loss: 0.369141161441803
Batch 61/64 loss: 0.3678765296936035
Batch 62/64 loss: 0.3719025254249573
Batch 63/64 loss: 0.36789369583129883
Batch 64/64 loss: 0.3696041703224182
Epoch 3  Train loss: 0.3701051578802221  Val loss: 0.36960494600210814
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 0.3694523572921753
Batch 2/64 loss: 0.3701150417327881
Batch 3/64 loss: 0.36785244941711426
Batch 4/64 loss: 0.36761653423309326
Batch 5/64 loss: 0.3686635494232178
Batch 6/64 loss: 0.36546194553375244
Batch 7/64 loss: 0.3670090436935425
Batch 8/64 loss: 0.36743074655532837
Batch 9/64 loss: 0.3683953285217285
Batch 10/64 loss: 0.3680351972579956
Batch 11/64 loss: 0.36954420804977417
Batch 12/64 loss: 0.37011706829071045
Batch 13/64 loss: 0.36526036262512207
Batch 14/64 loss: 0.3652859330177307
Batch 15/64 loss: 0.3654848337173462
Batch 16/64 loss: 0.36593008041381836
Batch 17/64 loss: 0.36941468715667725
Batch 18/64 loss: 0.36950576305389404
Batch 19/64 loss: 0.3691589832305908
Batch 20/64 loss: 0.3683728575706482
Batch 21/64 loss: 0.36705541610717773
Batch 22/64 loss: 0.36760854721069336
Batch 23/64 loss: 0.37063050270080566
Batch 24/64 loss: 0.3673081398010254
Batch 25/64 loss: 0.367548406124115
Batch 26/64 loss: 0.3688652515411377
Batch 27/64 loss: 0.36821550130844116
Batch 28/64 loss: 0.3681635856628418
Batch 29/64 loss: 0.3696960210800171
Batch 30/64 loss: 0.3673602342605591
Batch 31/64 loss: 0.3659292459487915
Batch 32/64 loss: 0.36760228872299194
Batch 33/64 loss: 0.3696720600128174
Batch 34/64 loss: 0.36688554286956787
Batch 35/64 loss: 0.367445707321167
Batch 36/64 loss: 0.3682277202606201
Batch 37/64 loss: 0.36748194694519043
Batch 38/64 loss: 0.36877644062042236
Batch 39/64 loss: 0.3698287010192871
Batch 40/64 loss: 0.36904603242874146
Batch 41/64 loss: 0.36781758069992065
Batch 42/64 loss: 0.36655962467193604
Batch 43/64 loss: 0.36963701248168945
Batch 44/64 loss: 0.36599665880203247
Batch 45/64 loss: 0.37092679738998413
Batch 46/64 loss: 0.3665890693664551
Batch 47/64 loss: 0.36825239658355713
Batch 48/64 loss: 0.36804258823394775
Batch 49/64 loss: 0.36955511569976807
Batch 50/64 loss: 0.3672734498977661
Batch 51/64 loss: 0.36887621879577637
Batch 52/64 loss: 0.3661438226699829
Batch 53/64 loss: 0.369911253452301
Batch 54/64 loss: 0.3676239252090454
Batch 55/64 loss: 0.36673057079315186
Batch 56/64 loss: 0.36790579557418823
Batch 57/64 loss: 0.36699241399765015
Batch 58/64 loss: 0.3666803240776062
Batch 59/64 loss: 0.3670196533203125
Batch 60/64 loss: 0.36626148223876953
Batch 61/64 loss: 0.3679412603378296
Batch 62/64 loss: 0.3660910129547119
Batch 63/64 loss: 0.3670805096626282
Batch 64/64 loss: 0.36961662769317627
Epoch 4  Train loss: 0.36791490620257805  Val loss: 0.36803624965890575
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 0.3692512512207031
Batch 2/64 loss: 0.3678860664367676
Batch 3/64 loss: 0.36759811639785767
Batch 4/64 loss: 0.3662493824958801
Batch 5/64 loss: 0.36314618587493896
Batch 6/64 loss: 0.36730051040649414
Batch 7/64 loss: 0.3662107586860657
Batch 8/64 loss: 0.3669142723083496
Batch 9/64 loss: 0.36569446325302124
Batch 10/64 loss: 0.36732470989227295
Batch 11/64 loss: 0.3683643341064453
Batch 12/64 loss: 0.36626482009887695
Batch 13/64 loss: 0.36808478832244873
Batch 14/64 loss: 0.3657376170158386
Batch 15/64 loss: 0.3662583827972412
Batch 16/64 loss: 0.36770099401474
Batch 17/64 loss: 0.36613595485687256
Batch 18/64 loss: 0.36665499210357666
Batch 19/64 loss: 0.3671773076057434
Batch 20/64 loss: 0.36713331937789917
Batch 21/64 loss: 0.3663212060928345
Batch 22/64 loss: 0.3673158884048462
Batch 23/64 loss: 0.3710924983024597
Batch 24/64 loss: 0.3653923273086548
Batch 25/64 loss: 0.3655582666397095
Batch 26/64 loss: 0.36858832836151123
Batch 27/64 loss: 0.369734525680542
Batch 28/64 loss: 0.36535733938217163
Batch 29/64 loss: 0.3649328947067261
Batch 30/64 loss: 0.36273902654647827
Batch 31/64 loss: 0.3654971122741699
Batch 32/64 loss: 0.36460936069488525
Batch 33/64 loss: 0.3667166233062744
Batch 34/64 loss: 0.36467456817626953
Batch 35/64 loss: 0.36837977170944214
Batch 36/64 loss: 0.36655235290527344
Batch 37/64 loss: 0.36879557371139526
Batch 38/64 loss: 0.366249680519104
Batch 39/64 loss: 0.3638318181037903
Batch 40/64 loss: 0.3682125210762024
Batch 41/64 loss: 0.36146318912506104
Batch 42/64 loss: 0.36706387996673584
Batch 43/64 loss: 0.36793947219848633
Batch 44/64 loss: 0.3668692708015442
Batch 45/64 loss: 0.3654831051826477
Batch 46/64 loss: 0.36848580837249756
Batch 47/64 loss: 0.3683267831802368
Batch 48/64 loss: 0.36763179302215576
Batch 49/64 loss: 0.3664153814315796
Batch 50/64 loss: 0.3673973083496094
Batch 51/64 loss: 0.3697901964187622
Batch 52/64 loss: 0.36688506603240967
Batch 53/64 loss: 0.36497652530670166
Batch 54/64 loss: 0.36503100395202637
Batch 55/64 loss: 0.36872339248657227
Batch 56/64 loss: 0.3666849136352539
Batch 57/64 loss: 0.3655296564102173
Batch 58/64 loss: 0.36555981636047363
Batch 59/64 loss: 0.36560672521591187
Batch 60/64 loss: 0.3659026622772217
Batch 61/64 loss: 0.366990327835083
Batch 62/64 loss: 0.3660341501235962
Batch 63/64 loss: 0.369636595249176
Batch 64/64 loss: 0.3654099106788635
Epoch 5  Train loss: 0.36668430379792755  Val loss: 0.3674815114830777
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 0.36698251962661743
Batch 2/64 loss: 0.3656824827194214
Batch 3/64 loss: 0.36828362941741943
Batch 4/64 loss: 0.36479806900024414
Batch 5/64 loss: 0.36261284351348877
Batch 6/64 loss: 0.3639949560165405
Batch 7/64 loss: 0.36555635929107666
Batch 8/64 loss: 0.36419016122817993
Batch 9/64 loss: 0.3676069378852844
Batch 10/64 loss: 0.36726701259613037
Batch 11/64 loss: 0.3676316738128662
Batch 12/64 loss: 0.36681807041168213
Batch 13/64 loss: 0.36788344383239746
Batch 14/64 loss: 0.3675159215927124
Batch 15/64 loss: 0.366674542427063
Batch 16/64 loss: 0.36640065908432007
Batch 17/64 loss: 0.36448854207992554
Batch 18/64 loss: 0.36698806285858154
Batch 19/64 loss: 0.3667573928833008
Batch 20/64 loss: 0.36438196897506714
Batch 21/64 loss: 0.36490607261657715
Batch 22/64 loss: 0.3631730079650879
Batch 23/64 loss: 0.3683486580848694
Batch 24/64 loss: 0.3642832040786743
Batch 25/64 loss: 0.36447787284851074
Batch 26/64 loss: 0.365806519985199
Batch 27/64 loss: 0.367686927318573
Batch 28/64 loss: 0.36554574966430664
Batch 29/64 loss: 0.36484289169311523
Batch 30/64 loss: 0.36858510971069336
Batch 31/64 loss: 0.365112841129303
Batch 32/64 loss: 0.36481547355651855
Batch 33/64 loss: 0.3656004071235657
Batch 34/64 loss: 0.36624228954315186
Batch 35/64 loss: 0.36624419689178467
Batch 36/64 loss: 0.3650937080383301
Batch 37/64 loss: 0.3660205602645874
Batch 38/64 loss: 0.36822712421417236
Batch 39/64 loss: 0.36690211296081543
Batch 40/64 loss: 0.3639606237411499
Batch 41/64 loss: 0.36556732654571533
Batch 42/64 loss: 0.36573493480682373
Batch 43/64 loss: 0.3648836016654968
Batch 44/64 loss: 0.365817666053772
Batch 45/64 loss: 0.3660183548927307
Batch 46/64 loss: 0.36890411376953125
Batch 47/64 loss: 0.36593759059906006
Batch 48/64 loss: 0.3650197386741638
Batch 49/64 loss: 0.3631983995437622
Batch 50/64 loss: 0.36397409439086914
Batch 51/64 loss: 0.36319899559020996
Batch 52/64 loss: 0.36736977100372314
Batch 53/64 loss: 0.3649824857711792
Batch 54/64 loss: 0.3670809864997864
Batch 55/64 loss: 0.3673607110977173
Batch 56/64 loss: 0.3665814995765686
Batch 57/64 loss: 0.36190521717071533
Batch 58/64 loss: 0.3635581135749817
Batch 59/64 loss: 0.36592793464660645
Batch 60/64 loss: 0.36427903175354004
Batch 61/64 loss: 0.3647047281265259
Batch 62/64 loss: 0.3624010682106018
Batch 63/64 loss: 0.36662667989730835
Batch 64/64 loss: 0.36385565996170044
Epoch 6  Train loss: 0.36568337865904266  Val loss: 0.3655697852885191
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.36677074432373047
Batch 2/64 loss: 0.364615261554718
Batch 3/64 loss: 0.3637317419052124
Batch 4/64 loss: 0.367415189743042
Batch 5/64 loss: 0.36646807193756104
Batch 6/64 loss: 0.36373233795166016
Batch 7/64 loss: 0.3640615940093994
Batch 8/64 loss: 0.36267614364624023
Batch 9/64 loss: 0.36535245180130005
Batch 10/64 loss: 0.3649575710296631
Batch 11/64 loss: 0.36748838424682617
Batch 12/64 loss: 0.3637511730194092
Batch 13/64 loss: 0.36608582735061646
Batch 14/64 loss: 0.3612159490585327
Batch 15/64 loss: 0.3637261390686035
Batch 16/64 loss: 0.3633633852005005
Batch 17/64 loss: 0.36604052782058716
Batch 18/64 loss: 0.3649938106536865
Batch 19/64 loss: 0.36408770084381104
Batch 20/64 loss: 0.36421775817871094
Batch 21/64 loss: 0.36128515005111694
Batch 22/64 loss: 0.36305147409439087
Batch 23/64 loss: 0.36491304636001587
Batch 24/64 loss: 0.3646465539932251
Batch 25/64 loss: 0.36414480209350586
Batch 26/64 loss: 0.36389851570129395
Batch 27/64 loss: 0.3650864362716675
Batch 28/64 loss: 0.3633672595024109
Batch 29/64 loss: 0.3637714385986328
Batch 30/64 loss: 0.3627532720565796
Batch 31/64 loss: 0.36140263080596924
Batch 32/64 loss: 0.360897958278656
Batch 33/64 loss: 0.36429858207702637
Batch 34/64 loss: 0.36299777030944824
Batch 35/64 loss: 0.3674635887145996
Batch 36/64 loss: 0.36245524883270264
Batch 37/64 loss: 0.36443769931793213
Batch 38/64 loss: 0.36555248498916626
Batch 39/64 loss: 0.3664877414703369
Batch 40/64 loss: 0.36477696895599365
Batch 41/64 loss: 0.3661520481109619
Batch 42/64 loss: 0.362423300743103
Batch 43/64 loss: 0.36803674697875977
Batch 44/64 loss: 0.36328303813934326
Batch 45/64 loss: 0.3635488748550415
Batch 46/64 loss: 0.36465728282928467
Batch 47/64 loss: 0.36796414852142334
Batch 48/64 loss: 0.36631596088409424
Batch 49/64 loss: 0.3658076524734497
Batch 50/64 loss: 0.3641238808631897
Batch 51/64 loss: 0.3647181987762451
Batch 52/64 loss: 0.3628309965133667
Batch 53/64 loss: 0.36360687017440796
Batch 54/64 loss: 0.3642314672470093
Batch 55/64 loss: 0.3658761978149414
Batch 56/64 loss: 0.36548173427581787
Batch 57/64 loss: 0.36634528636932373
Batch 58/64 loss: 0.3664064407348633
Batch 59/64 loss: 0.36396700143814087
Batch 60/64 loss: 0.36363911628723145
Batch 61/64 loss: 0.36403799057006836
Batch 62/64 loss: 0.36549508571624756
Batch 63/64 loss: 0.3640252947807312
Batch 64/64 loss: 0.36637556552886963
Epoch 7  Train loss: 0.3645521047068577  Val loss: 0.36518168592780725
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 0.36656397581100464
Batch 2/64 loss: 0.36429160833358765
Batch 3/64 loss: 0.3642466068267822
Batch 4/64 loss: 0.36465853452682495
Batch 5/64 loss: 0.367911159992218
Batch 6/64 loss: 0.36405396461486816
Batch 7/64 loss: 0.36674392223358154
Batch 8/64 loss: 0.36803483963012695
Batch 9/64 loss: 0.3641575574874878
Batch 10/64 loss: 0.364255428314209
Batch 11/64 loss: 0.3647279739379883
Batch 12/64 loss: 0.3627837896347046
Batch 13/64 loss: 0.36458826065063477
Batch 14/64 loss: 0.36712682247161865
Batch 15/64 loss: 0.3649211525917053
Batch 16/64 loss: 0.36651676893234253
Batch 17/64 loss: 0.361971378326416
Batch 18/64 loss: 0.36532509326934814
Batch 19/64 loss: 0.36603957414627075
Batch 20/64 loss: 0.36664509773254395
Batch 21/64 loss: 0.3662717342376709
Batch 22/64 loss: 0.36233508586883545
Batch 23/64 loss: 0.364219069480896
Batch 24/64 loss: 0.3660750389099121
Batch 25/64 loss: 0.36532342433929443
Batch 26/64 loss: 0.3622457981109619
Batch 27/64 loss: 0.36589741706848145
Batch 28/64 loss: 0.3637272119522095
Batch 29/64 loss: 0.36209845542907715
Batch 30/64 loss: 0.3647068738937378
Batch 31/64 loss: 0.3640092611312866
Batch 32/64 loss: 0.3656672239303589
Batch 33/64 loss: 0.36383265256881714
Batch 34/64 loss: 0.36375904083251953
Batch 35/64 loss: 0.36525774002075195
Batch 36/64 loss: 0.3630424737930298
Batch 37/64 loss: 0.3597104549407959
Batch 38/64 loss: 0.3615182638168335
Batch 39/64 loss: 0.36372458934783936
Batch 40/64 loss: 0.36375415325164795
Batch 41/64 loss: 0.36353546380996704
Batch 42/64 loss: 0.3627622127532959
Batch 43/64 loss: 0.36676573753356934
Batch 44/64 loss: 0.36687982082366943
Batch 45/64 loss: 0.36550140380859375
Batch 46/64 loss: 0.3622572422027588
Batch 47/64 loss: 0.359529972076416
Batch 48/64 loss: 0.36429595947265625
Batch 49/64 loss: 0.361788272857666
Batch 50/64 loss: 0.3650967478752136
Batch 51/64 loss: 0.361586332321167
Batch 52/64 loss: 0.3623032569885254
Batch 53/64 loss: 0.3576085567474365
Batch 54/64 loss: 0.362155556678772
Batch 55/64 loss: 0.3636956214904785
Batch 56/64 loss: 0.36397480964660645
Batch 57/64 loss: 0.363339900970459
Batch 58/64 loss: 0.3608582019805908
Batch 59/64 loss: 0.36247897148132324
Batch 60/64 loss: 0.362760066986084
Batch 61/64 loss: 0.3588217496871948
Batch 62/64 loss: 0.3617042303085327
Batch 63/64 loss: 0.36032116413116455
Batch 64/64 loss: 0.3596651554107666
Epoch 8  Train loss: 0.3638040720247755  Val loss: 0.36336273057354274
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 0.3608216643333435
Batch 2/64 loss: 0.3628295660018921
Batch 3/64 loss: 0.359214186668396
Batch 4/64 loss: 0.36062145233154297
Batch 5/64 loss: 0.3631367087364197
Batch 6/64 loss: 0.3629360795021057
Batch 7/64 loss: 0.3592647314071655
Batch 8/64 loss: 0.3638803958892822
Batch 9/64 loss: 0.3623506426811218
Batch 10/64 loss: 0.3639715909957886
Batch 11/64 loss: 0.3601781129837036
Batch 12/64 loss: 0.35958850383758545
Batch 13/64 loss: 0.3615870475769043
Batch 14/64 loss: 0.3665580749511719
Batch 15/64 loss: 0.36334317922592163
Batch 16/64 loss: 0.3617953658103943
Batch 17/64 loss: 0.3639756441116333
Batch 18/64 loss: 0.36392873525619507
Batch 19/64 loss: 0.36278867721557617
Batch 20/64 loss: 0.36704492568969727
Batch 21/64 loss: 0.36453497409820557
Batch 22/64 loss: 0.36444395780563354
Batch 23/64 loss: 0.36329591274261475
Batch 24/64 loss: 0.3638070821762085
Batch 25/64 loss: 0.36632436513900757
Batch 26/64 loss: 0.3630390167236328
Batch 27/64 loss: 0.3612675666809082
Batch 28/64 loss: 0.36809325218200684
Batch 29/64 loss: 0.36088067293167114
Batch 30/64 loss: 0.36134636402130127
Batch 31/64 loss: 0.36410003900527954
Batch 32/64 loss: 0.36471331119537354
Batch 33/64 loss: 0.3679131865501404
Batch 34/64 loss: 0.363910436630249
Batch 35/64 loss: 0.3650246858596802
Batch 36/64 loss: 0.36337733268737793
Batch 37/64 loss: 0.3619486093521118
Batch 38/64 loss: 0.3633420467376709
Batch 39/64 loss: 0.36383575201034546
Batch 40/64 loss: 0.36332428455352783
Batch 41/64 loss: 0.36326122283935547
Batch 42/64 loss: 0.36530429124832153
Batch 43/64 loss: 0.363122820854187
Batch 44/64 loss: 0.36068373918533325
Batch 45/64 loss: 0.3618367910385132
Batch 46/64 loss: 0.3671988248825073
Batch 47/64 loss: 0.36426055431365967
Batch 48/64 loss: 0.36290574073791504
Batch 49/64 loss: 0.3666917681694031
Batch 50/64 loss: 0.36158835887908936
Batch 51/64 loss: 0.3600897789001465
Batch 52/64 loss: 0.3614387512207031
Batch 53/64 loss: 0.36267876625061035
Batch 54/64 loss: 0.36114585399627686
Batch 55/64 loss: 0.3624676465988159
Batch 56/64 loss: 0.361976683139801
Batch 57/64 loss: 0.3631731867790222
Batch 58/64 loss: 0.36225032806396484
Batch 59/64 loss: 0.3621925115585327
Batch 60/64 loss: 0.3604707717895508
Batch 61/64 loss: 0.36198556423187256
Batch 62/64 loss: 0.3641930818557739
Batch 63/64 loss: 0.36244380474090576
Batch 64/64 loss: 0.36491215229034424
Epoch 9  Train loss: 0.3630648327808754  Val loss: 0.3638792373880078
Epoch 10
-------------------------------
Batch 1/64 loss: 0.3632187247276306
Batch 2/64 loss: 0.36236488819122314
Batch 3/64 loss: 0.3636382818222046
Batch 4/64 loss: 0.36537742614746094
Batch 5/64 loss: 0.3622947335243225
Batch 6/64 loss: 0.3663409948348999
Batch 7/64 loss: 0.36149996519088745
Batch 8/64 loss: 0.36332619190216064
Batch 9/64 loss: 0.36327290534973145
Batch 10/64 loss: 0.36362743377685547
Batch 11/64 loss: 0.36806225776672363
Batch 12/64 loss: 0.3617842197418213
Batch 13/64 loss: 0.36381614208221436
Batch 14/64 loss: 0.3622320294380188
Batch 15/64 loss: 0.36338186264038086
Batch 16/64 loss: 0.36312443017959595
Batch 17/64 loss: 0.36067771911621094
Batch 18/64 loss: 0.36054205894470215
Batch 19/64 loss: 0.36367952823638916
Batch 20/64 loss: 0.3608938455581665
Batch 21/64 loss: 0.36361628770828247
Batch 22/64 loss: 0.3593667149543762
Batch 23/64 loss: 0.36456263065338135
Batch 24/64 loss: 0.364449143409729
Batch 25/64 loss: 0.36270326375961304
Batch 26/64 loss: 0.364760160446167
Batch 27/64 loss: 0.36456620693206787
Batch 28/64 loss: 0.3627861738204956
Batch 29/64 loss: 0.36200201511383057
Batch 30/64 loss: 0.3611730933189392
Batch 31/64 loss: 0.36299824714660645
Batch 32/64 loss: 0.3631032705307007
Batch 33/64 loss: 0.36118972301483154
Batch 34/64 loss: 0.3596299886703491
Batch 35/64 loss: 0.36472970247268677
Batch 36/64 loss: 0.36215364933013916
Batch 37/64 loss: 0.3658301830291748
Batch 38/64 loss: 0.3647066354751587
Batch 39/64 loss: 0.3618500232696533
Batch 40/64 loss: 0.3626251220703125
Batch 41/64 loss: 0.3646741509437561
Batch 42/64 loss: 0.36260509490966797
Batch 43/64 loss: 0.36063075065612793
Batch 44/64 loss: 0.3634946346282959
Batch 45/64 loss: 0.3619333505630493
Batch 46/64 loss: 0.36200201511383057
Batch 47/64 loss: 0.3615846633911133
Batch 48/64 loss: 0.365018367767334
Batch 49/64 loss: 0.364854097366333
Batch 50/64 loss: 0.36150264739990234
Batch 51/64 loss: 0.3619225025177002
Batch 52/64 loss: 0.3612477779388428
Batch 53/64 loss: 0.3652147054672241
Batch 54/64 loss: 0.36186087131500244
Batch 55/64 loss: 0.3620855212211609
Batch 56/64 loss: 0.3614732027053833
Batch 57/64 loss: 0.3591601848602295
Batch 58/64 loss: 0.36163872480392456
Batch 59/64 loss: 0.3605049252510071
Batch 60/64 loss: 0.3673931360244751
Batch 61/64 loss: 0.3626142740249634
Batch 62/64 loss: 0.3633766770362854
Batch 63/64 loss: 0.35887032747268677
Batch 64/64 loss: 0.3592154383659363
Epoch 10  Train loss: 0.36277697343452303  Val loss: 0.36373648897479083
Epoch 11
-------------------------------
Batch 1/64 loss: 0.3628242015838623
Batch 2/64 loss: 0.362265944480896
Batch 3/64 loss: 0.3647775650024414
Batch 4/64 loss: 0.3643249273300171
Batch 5/64 loss: 0.3631132245063782
Batch 6/64 loss: 0.3630608320236206
Batch 7/64 loss: 0.36474084854125977
Batch 8/64 loss: 0.36516374349594116
Batch 9/64 loss: 0.3628101348876953
Batch 10/64 loss: 0.3595505356788635
Batch 11/64 loss: 0.36411261558532715
Batch 12/64 loss: 0.3630249500274658
Batch 13/64 loss: 0.3610161542892456
Batch 14/64 loss: 0.36203253269195557
Batch 15/64 loss: 0.3635474443435669
Batch 16/64 loss: 0.36349523067474365
Batch 17/64 loss: 0.3609713315963745
Batch 18/64 loss: 0.3656045198440552
Batch 19/64 loss: 0.36068063974380493
Batch 20/64 loss: 0.3614952564239502
Batch 21/64 loss: 0.36176735162734985
Batch 22/64 loss: 0.3612196445465088
Batch 23/64 loss: 0.3600805997848511
Batch 24/64 loss: 0.36129069328308105
Batch 25/64 loss: 0.36284685134887695
Batch 26/64 loss: 0.36166149377822876
Batch 27/64 loss: 0.3605419397354126
Batch 28/64 loss: 0.35966956615448
Batch 29/64 loss: 0.3636699318885803
Batch 30/64 loss: 0.36204367876052856
Batch 31/64 loss: 0.36306190490722656
Batch 32/64 loss: 0.36130428314208984
Batch 33/64 loss: 0.3628106117248535
Batch 34/64 loss: 0.35829442739486694
Batch 35/64 loss: 0.36234819889068604
Batch 36/64 loss: 0.36056166887283325
Batch 37/64 loss: 0.3596036434173584
Batch 38/64 loss: 0.3617424964904785
Batch 39/64 loss: 0.36178815364837646
Batch 40/64 loss: 0.359271764755249
Batch 41/64 loss: 0.36021220684051514
Batch 42/64 loss: 0.35772836208343506
Batch 43/64 loss: 0.36212337017059326
Batch 44/64 loss: 0.3624657392501831
Batch 45/64 loss: 0.36103808879852295
Batch 46/64 loss: 0.365445613861084
Batch 47/64 loss: 0.35974764823913574
Batch 48/64 loss: 0.36481142044067383
Batch 49/64 loss: 0.36237436532974243
Batch 50/64 loss: 0.3598172664642334
Batch 51/64 loss: 0.36368757486343384
Batch 52/64 loss: 0.36201608180999756
Batch 53/64 loss: 0.3603893518447876
Batch 54/64 loss: 0.36332952976226807
Batch 55/64 loss: 0.3578328490257263
Batch 56/64 loss: 0.361441969871521
Batch 57/64 loss: 0.36146944761276245
Batch 58/64 loss: 0.3633754253387451
Batch 59/64 loss: 0.3649793267250061
Batch 60/64 loss: 0.3620094656944275
Batch 61/64 loss: 0.36612117290496826
Batch 62/64 loss: 0.361636757850647
Batch 63/64 loss: 0.3609731197357178
Batch 64/64 loss: 0.3622286915779114
Epoch 11  Train loss: 0.36205316408007754  Val loss: 0.36283487347802756
Saving best model, epoch: 11
Epoch 12
-------------------------------
Batch 1/64 loss: 0.3627263903617859
Batch 2/64 loss: 0.36142081022262573
Batch 3/64 loss: 0.3619692921638489
Batch 4/64 loss: 0.3609265089035034
Batch 5/64 loss: 0.36116230487823486
Batch 6/64 loss: 0.35952556133270264
Batch 7/64 loss: 0.36146557331085205
Batch 8/64 loss: 0.3626090884208679
Batch 9/64 loss: 0.36155444383621216
Batch 10/64 loss: 0.3614721894264221
Batch 11/64 loss: 0.3625962734222412
Batch 12/64 loss: 0.3592691421508789
Batch 13/64 loss: 0.35944855213165283
Batch 14/64 loss: 0.3621203899383545
Batch 15/64 loss: 0.362141489982605
Batch 16/64 loss: 0.3595515489578247
Batch 17/64 loss: 0.36162108182907104
Batch 18/64 loss: 0.3617027997970581
Batch 19/64 loss: 0.3602675795555115
Batch 20/64 loss: 0.35862207412719727
Batch 21/64 loss: 0.35887134075164795
Batch 22/64 loss: 0.3611716032028198
Batch 23/64 loss: 0.363247275352478
Batch 24/64 loss: 0.35885685682296753
Batch 25/64 loss: 0.36373263597488403
Batch 26/64 loss: 0.3622232675552368
Batch 27/64 loss: 0.3613734245300293
Batch 28/64 loss: 0.3600834012031555
Batch 29/64 loss: 0.3598170280456543
Batch 30/64 loss: 0.35707730054855347
Batch 31/64 loss: 0.3633601665496826
Batch 32/64 loss: 0.36165791749954224
Batch 33/64 loss: 0.35978472232818604
Batch 34/64 loss: 0.3597675561904907
Batch 35/64 loss: 0.3623570203781128
Batch 36/64 loss: 0.36134278774261475
Batch 37/64 loss: 0.36043107509613037
Batch 38/64 loss: 0.3594728708267212
Batch 39/64 loss: 0.36351466178894043
Batch 40/64 loss: 0.365073025226593
Batch 41/64 loss: 0.3609476089477539
Batch 42/64 loss: 0.35993313789367676
Batch 43/64 loss: 0.35844433307647705
Batch 44/64 loss: 0.3626880645751953
Batch 45/64 loss: 0.36316537857055664
Batch 46/64 loss: 0.3646395206451416
Batch 47/64 loss: 0.3625664710998535
Batch 48/64 loss: 0.36351871490478516
Batch 49/64 loss: 0.36356109380722046
Batch 50/64 loss: 0.3610171675682068
Batch 51/64 loss: 0.36453676223754883
Batch 52/64 loss: 0.36102956533432007
Batch 53/64 loss: 0.36299455165863037
Batch 54/64 loss: 0.3632246255874634
Batch 55/64 loss: 0.3650687336921692
Batch 56/64 loss: 0.363699734210968
Batch 57/64 loss: 0.3586982488632202
Batch 58/64 loss: 0.36189305782318115
Batch 59/64 loss: 0.36198532581329346
Batch 60/64 loss: 0.3609522581100464
Batch 61/64 loss: 0.36120545864105225
Batch 62/64 loss: 0.36180394887924194
Batch 63/64 loss: 0.364501416683197
Batch 64/64 loss: 0.36026155948638916
Epoch 12  Train loss: 0.36153192753885305  Val loss: 0.36216471387758287
Saving best model, epoch: 12
Epoch 13
-------------------------------
Batch 1/64 loss: 0.35919952392578125
Batch 2/64 loss: 0.3611801266670227
Batch 3/64 loss: 0.3610788583755493
Batch 4/64 loss: 0.36243993043899536
Batch 5/64 loss: 0.36168575286865234
Batch 6/64 loss: 0.3637833595275879
Batch 7/64 loss: 0.3593664765357971
Batch 8/64 loss: 0.36209946870803833
Batch 9/64 loss: 0.3643723726272583
Batch 10/64 loss: 0.3588249087333679
Batch 11/64 loss: 0.36103057861328125
Batch 12/64 loss: 0.3634450435638428
Batch 13/64 loss: 0.36528921127319336
Batch 14/64 loss: 0.35900449752807617
Batch 15/64 loss: 0.3624721169471741
Batch 16/64 loss: 0.3640865683555603
Batch 17/64 loss: 0.3597601652145386
Batch 18/64 loss: 0.3602931499481201
Batch 19/64 loss: 0.359325647354126
Batch 20/64 loss: 0.36348462104797363
Batch 21/64 loss: 0.36109161376953125
Batch 22/64 loss: 0.3591083288192749
Batch 23/64 loss: 0.35798609256744385
Batch 24/64 loss: 0.3577747941017151
Batch 25/64 loss: 0.35799849033355713
Batch 26/64 loss: 0.3621059060096741
Batch 27/64 loss: 0.36137545108795166
Batch 28/64 loss: 0.35782408714294434
Batch 29/64 loss: 0.3593575954437256
Batch 30/64 loss: 0.3595135807991028
Batch 31/64 loss: 0.36080414056777954
Batch 32/64 loss: 0.3617823123931885
Batch 33/64 loss: 0.3603382110595703
Batch 34/64 loss: 0.3616018295288086
Batch 35/64 loss: 0.3632575273513794
Batch 36/64 loss: 0.3617110252380371
Batch 37/64 loss: 0.3626518249511719
Batch 38/64 loss: 0.36213546991348267
Batch 39/64 loss: 0.36256301403045654
Batch 40/64 loss: 0.36113572120666504
Batch 41/64 loss: 0.359688937664032
Batch 42/64 loss: 0.36149269342422485
Batch 43/64 loss: 0.3602427840232849
Batch 44/64 loss: 0.36120784282684326
Batch 45/64 loss: 0.3610038757324219
Batch 46/64 loss: 0.36015546321868896
Batch 47/64 loss: 0.36110126972198486
Batch 48/64 loss: 0.3605775833129883
Batch 49/64 loss: 0.36257660388946533
Batch 50/64 loss: 0.3622422218322754
Batch 51/64 loss: 0.35913920402526855
Batch 52/64 loss: 0.36380958557128906
Batch 53/64 loss: 0.36295318603515625
Batch 54/64 loss: 0.3626328706741333
Batch 55/64 loss: 0.3611118197441101
Batch 56/64 loss: 0.3613088130950928
Batch 57/64 loss: 0.36274105310440063
Batch 58/64 loss: 0.3618316054344177
Batch 59/64 loss: 0.36226069927215576
Batch 60/64 loss: 0.3602966070175171
Batch 61/64 loss: 0.35847944021224976
Batch 62/64 loss: 0.35625773668289185
Batch 63/64 loss: 0.3631182909011841
Batch 64/64 loss: 0.36110764741897583
Epoch 13  Train loss: 0.36112000498117186  Val loss: 0.3617733612502973
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: 0.3565666079521179
Batch 2/64 loss: 0.36432433128356934
Batch 3/64 loss: 0.3594438433647156
Batch 4/64 loss: 0.3607443571090698
Batch 5/64 loss: 0.3633374571800232
Batch 6/64 loss: 0.35984885692596436
Batch 7/64 loss: 0.3620516061782837
Batch 8/64 loss: 0.35859131813049316
Batch 9/64 loss: 0.3611278533935547
Batch 10/64 loss: 0.36068272590637207
Batch 11/64 loss: 0.36319470405578613
Batch 12/64 loss: 0.361858069896698
Batch 13/64 loss: 0.36187195777893066
Batch 14/64 loss: 0.35937440395355225
Batch 15/64 loss: 0.35633498430252075
Batch 16/64 loss: 0.35849910974502563
Batch 17/64 loss: 0.36078667640686035
Batch 18/64 loss: 0.3594973087310791
Batch 19/64 loss: 0.359932541847229
Batch 20/64 loss: 0.3615943193435669
Batch 21/64 loss: 0.35892993211746216
Batch 22/64 loss: 0.36241382360458374
Batch 23/64 loss: 0.36088812351226807
Batch 24/64 loss: 0.3608438968658447
Batch 25/64 loss: 0.3586851954460144
Batch 26/64 loss: 0.36102747917175293
Batch 27/64 loss: 0.3600471615791321
Batch 28/64 loss: 0.35890722274780273
Batch 29/64 loss: 0.36059898138046265
Batch 30/64 loss: 0.3605024814605713
Batch 31/64 loss: 0.35988712310791016
Batch 32/64 loss: 0.3619217872619629
Batch 33/64 loss: 0.3623828887939453
Batch 34/64 loss: 0.35922563076019287
Batch 35/64 loss: 0.36056458950042725
Batch 36/64 loss: 0.36652833223342896
Batch 37/64 loss: 0.3601168394088745
Batch 38/64 loss: 0.359106183052063
Batch 39/64 loss: 0.3612385392189026
Batch 40/64 loss: 0.3584965467453003
Batch 41/64 loss: 0.3610139489173889
Batch 42/64 loss: 0.35922229290008545
Batch 43/64 loss: 0.35947078466415405
Batch 44/64 loss: 0.360819935798645
Batch 45/64 loss: 0.358320951461792
Batch 46/64 loss: 0.3618062138557434
Batch 47/64 loss: 0.36061882972717285
Batch 48/64 loss: 0.35770487785339355
Batch 49/64 loss: 0.3642634153366089
Batch 50/64 loss: 0.36014676094055176
Batch 51/64 loss: 0.35602498054504395
Batch 52/64 loss: 0.35886383056640625
Batch 53/64 loss: 0.3613777756690979
Batch 54/64 loss: 0.35854005813598633
Batch 55/64 loss: 0.3645387887954712
Batch 56/64 loss: 0.35777342319488525
Batch 57/64 loss: 0.36283814907073975
Batch 58/64 loss: 0.35969817638397217
Batch 59/64 loss: 0.3578747510910034
Batch 60/64 loss: 0.358772873878479
Batch 61/64 loss: 0.3634469509124756
Batch 62/64 loss: 0.3621795177459717
Batch 63/64 loss: 0.3607974052429199
Batch 64/64 loss: 0.35579901933670044
Epoch 14  Train loss: 0.3603912117434483  Val loss: 0.36207793463546384
Epoch 15
-------------------------------
Batch 1/64 loss: 0.35886913537979126
Batch 2/64 loss: 0.35932600498199463
Batch 3/64 loss: 0.36272871494293213
Batch 4/64 loss: 0.36298108100891113
Batch 5/64 loss: 0.36027735471725464
Batch 6/64 loss: 0.355421781539917
Batch 7/64 loss: 0.3593326807022095
Batch 8/64 loss: 0.360617995262146
Batch 9/64 loss: 0.3587607145309448
Batch 10/64 loss: 0.3639965057373047
Batch 11/64 loss: 0.3599889278411865
Batch 12/64 loss: 0.36374759674072266
Batch 13/64 loss: 0.35827088356018066
Batch 14/64 loss: 0.3597283959388733
Batch 15/64 loss: 0.36086124181747437
Batch 16/64 loss: 0.3574513792991638
Batch 17/64 loss: 0.3602195382118225
Batch 18/64 loss: 0.36002278327941895
Batch 19/64 loss: 0.35706448554992676
Batch 20/64 loss: 0.36055195331573486
Batch 21/64 loss: 0.35987794399261475
Batch 22/64 loss: 0.36288321018218994
Batch 23/64 loss: 0.36142390966415405
Batch 24/64 loss: 0.35630059242248535
Batch 25/64 loss: 0.3611077666282654
Batch 26/64 loss: 0.35542023181915283
Batch 27/64 loss: 0.3607290983200073
Batch 28/64 loss: 0.3594973087310791
Batch 29/64 loss: 0.3622140884399414
Batch 30/64 loss: 0.3609183430671692
Batch 31/64 loss: 0.35942864418029785
Batch 32/64 loss: 0.3603134751319885
Batch 33/64 loss: 0.3598278760910034
Batch 34/64 loss: 0.3585246205329895
Batch 35/64 loss: 0.3593604564666748
Batch 36/64 loss: 0.3591200113296509
Batch 37/64 loss: 0.3644323945045471
Batch 38/64 loss: 0.362346887588501
Batch 39/64 loss: 0.3609914779663086
Batch 40/64 loss: 0.3596522808074951
Batch 41/64 loss: 0.3588467836380005
Batch 42/64 loss: 0.3610283136367798
Batch 43/64 loss: 0.3580150604248047
Batch 44/64 loss: 0.36157554388046265
Batch 45/64 loss: 0.3570637106895447
Batch 46/64 loss: 0.36110806465148926
Batch 47/64 loss: 0.3602859377861023
Batch 48/64 loss: 0.36268436908721924
Batch 49/64 loss: 0.3603273630142212
Batch 50/64 loss: 0.35819703340530396
Batch 51/64 loss: 0.36210715770721436
Batch 52/64 loss: 0.36088478565216064
Batch 53/64 loss: 0.3603322505950928
Batch 54/64 loss: 0.36076462268829346
Batch 55/64 loss: 0.3603658676147461
Batch 56/64 loss: 0.3584071397781372
Batch 57/64 loss: 0.36328983306884766
Batch 58/64 loss: 0.3618791103363037
Batch 59/64 loss: 0.36036843061447144
Batch 60/64 loss: 0.36016058921813965
Batch 61/64 loss: 0.3631824851036072
Batch 62/64 loss: 0.3611493706703186
Batch 63/64 loss: 0.3595728278160095
Batch 64/64 loss: 0.3594058156013489
Epoch 15  Train loss: 0.3602469142745523  Val loss: 0.3612879252515708
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: 0.3584766983985901
Batch 2/64 loss: 0.3592967987060547
Batch 3/64 loss: 0.3640068769454956
Batch 4/64 loss: 0.3594895601272583
Batch 5/64 loss: 0.36125648021698
Batch 6/64 loss: 0.35998767614364624
Batch 7/64 loss: 0.35994696617126465
Batch 8/64 loss: 0.3588218688964844
Batch 9/64 loss: 0.3632007837295532
Batch 10/64 loss: 0.35972410440444946
Batch 11/64 loss: 0.36114639043807983
Batch 12/64 loss: 0.3638811707496643
Batch 13/64 loss: 0.35950517654418945
Batch 14/64 loss: 0.359279990196228
Batch 15/64 loss: 0.36148273944854736
Batch 16/64 loss: 0.3602139353752136
Batch 17/64 loss: 0.3578560948371887
Batch 18/64 loss: 0.36004775762557983
Batch 19/64 loss: 0.36054569482803345
Batch 20/64 loss: 0.36114245653152466
Batch 21/64 loss: 0.35661715269088745
Batch 22/64 loss: 0.3602128028869629
Batch 23/64 loss: 0.36045634746551514
Batch 24/64 loss: 0.3623563051223755
Batch 25/64 loss: 0.3613440990447998
Batch 26/64 loss: 0.35859763622283936
Batch 27/64 loss: 0.35881394147872925
Batch 28/64 loss: 0.357654869556427
Batch 29/64 loss: 0.3605918884277344
Batch 30/64 loss: 0.3586989641189575
Batch 31/64 loss: 0.3596838116645813
Batch 32/64 loss: 0.3590954542160034
Batch 33/64 loss: 0.3592430353164673
Batch 34/64 loss: 0.36119216680526733
Batch 35/64 loss: 0.3594791889190674
Batch 36/64 loss: 0.35975199937820435
Batch 37/64 loss: 0.36039072275161743
Batch 38/64 loss: 0.36106061935424805
Batch 39/64 loss: 0.36115407943725586
Batch 40/64 loss: 0.3606550693511963
Batch 41/64 loss: 0.36037224531173706
Batch 42/64 loss: 0.3599269986152649
Batch 43/64 loss: 0.3578973412513733
Batch 44/64 loss: 0.3578174114227295
Batch 45/64 loss: 0.3584853410720825
Batch 46/64 loss: 0.3568754196166992
Batch 47/64 loss: 0.36203253269195557
Batch 48/64 loss: 0.3601433038711548
Batch 49/64 loss: 0.3611873388290405
Batch 50/64 loss: 0.3590461015701294
Batch 51/64 loss: 0.358190655708313
Batch 52/64 loss: 0.35657382011413574
Batch 53/64 loss: 0.35956835746765137
Batch 54/64 loss: 0.3625815510749817
Batch 55/64 loss: 0.35828709602355957
Batch 56/64 loss: 0.357183575630188
Batch 57/64 loss: 0.3605670928955078
Batch 58/64 loss: 0.3575904369354248
Batch 59/64 loss: 0.35954147577285767
Batch 60/64 loss: 0.36191266775131226
Batch 61/64 loss: 0.3562764525413513
Batch 62/64 loss: 0.3592742085456848
Batch 63/64 loss: 0.35584795475006104
Batch 64/64 loss: 0.36239033937454224
Epoch 16  Train loss: 0.3597699060159571  Val loss: 0.36161638453244344
Epoch 17
-------------------------------
Batch 1/64 loss: 0.3604145050048828
Batch 2/64 loss: 0.35926949977874756
Batch 3/64 loss: 0.36258465051651
Batch 4/64 loss: 0.3586024045944214
Batch 5/64 loss: 0.35746920108795166
Batch 6/64 loss: 0.360001802444458
Batch 7/64 loss: 0.3588167428970337
Batch 8/64 loss: 0.3598194122314453
Batch 9/64 loss: 0.3610374927520752
Batch 10/64 loss: 0.3569070100784302
Batch 11/64 loss: 0.3603360652923584
Batch 12/64 loss: 0.36060744524002075
Batch 13/64 loss: 0.3579407334327698
Batch 14/64 loss: 0.3644724488258362
Batch 15/64 loss: 0.3611910939216614
Batch 16/64 loss: 0.3601132035255432
Batch 17/64 loss: 0.3602161407470703
Batch 18/64 loss: 0.35796451568603516
Batch 19/64 loss: 0.3579302430152893
Batch 20/64 loss: 0.36063069105148315
Batch 21/64 loss: 0.3627328872680664
Batch 22/64 loss: 0.3595917224884033
Batch 23/64 loss: 0.3610130548477173
Batch 24/64 loss: 0.3604886531829834
Batch 25/64 loss: 0.3571673035621643
Batch 26/64 loss: 0.35918712615966797
Batch 27/64 loss: 0.3602166175842285
Batch 28/64 loss: 0.3606942892074585
Batch 29/64 loss: 0.36438989639282227
Batch 30/64 loss: 0.35948461294174194
Batch 31/64 loss: 0.36059433221817017
Batch 32/64 loss: 0.3599097728729248
Batch 33/64 loss: 0.3587324619293213
Batch 34/64 loss: 0.35651272535324097
Batch 35/64 loss: 0.35765188932418823
Batch 36/64 loss: 0.3595684766769409
Batch 37/64 loss: 0.3609706163406372
Batch 38/64 loss: 0.35816240310668945
Batch 39/64 loss: 0.35975027084350586
Batch 40/64 loss: 0.3605884313583374
Batch 41/64 loss: 0.358987033367157
Batch 42/64 loss: 0.3565938472747803
Batch 43/64 loss: 0.357180118560791
Batch 44/64 loss: 0.3606593608856201
Batch 45/64 loss: 0.35624468326568604
Batch 46/64 loss: 0.36121463775634766
Batch 47/64 loss: 0.35980749130249023
Batch 48/64 loss: 0.36116713285446167
Batch 49/64 loss: 0.36129331588745117
Batch 50/64 loss: 0.35965001583099365
Batch 51/64 loss: 0.35930806398391724
Batch 52/64 loss: 0.3611694574356079
Batch 53/64 loss: 0.3610117435455322
Batch 54/64 loss: 0.35812437534332275
Batch 55/64 loss: 0.36353909969329834
Batch 56/64 loss: 0.3611220121383667
Batch 57/64 loss: 0.3583691716194153
Batch 58/64 loss: 0.361589252948761
Batch 59/64 loss: 0.3615473508834839
Batch 60/64 loss: 0.360085129737854
Batch 61/64 loss: 0.3601877689361572
Batch 62/64 loss: 0.3637888431549072
Batch 63/64 loss: 0.35863763093948364
Batch 64/64 loss: 0.3632090091705322
Epoch 17  Train loss: 0.35995948454912974  Val loss: 0.3628621191503256
Epoch 18
-------------------------------
Batch 1/64 loss: 0.3644336462020874
Batch 2/64 loss: 0.36035728454589844
Batch 3/64 loss: 0.36130082607269287
Batch 4/64 loss: 0.35806095600128174
Batch 5/64 loss: 0.3615027666091919
Batch 6/64 loss: 0.35848402976989746
Batch 7/64 loss: 0.36274999380111694
Batch 8/64 loss: 0.36055177450180054
Batch 9/64 loss: 0.36022132635116577
Batch 10/64 loss: 0.3609893321990967
Batch 11/64 loss: 0.3627300262451172
Batch 12/64 loss: 0.3586037755012512
Batch 13/64 loss: 0.36050891876220703
Batch 14/64 loss: 0.35820817947387695
Batch 15/64 loss: 0.3578392267227173
Batch 16/64 loss: 0.35729700326919556
Batch 17/64 loss: 0.3620733618736267
Batch 18/64 loss: 0.35987794399261475
Batch 19/64 loss: 0.3601875305175781
Batch 20/64 loss: 0.361064076423645
Batch 21/64 loss: 0.36086881160736084
Batch 22/64 loss: 0.3580000400543213
Batch 23/64 loss: 0.3598959445953369
Batch 24/64 loss: 0.35946500301361084
Batch 25/64 loss: 0.3606547713279724
Batch 26/64 loss: 0.36034369468688965
Batch 27/64 loss: 0.36037677526474
Batch 28/64 loss: 0.35811150074005127
Batch 29/64 loss: 0.36040639877319336
Batch 30/64 loss: 0.3594095706939697
Batch 31/64 loss: 0.35993432998657227
Batch 32/64 loss: 0.3591036796569824
Batch 33/64 loss: 0.3605918884277344
Batch 34/64 loss: 0.3601142168045044
Batch 35/64 loss: 0.3578951358795166
Batch 36/64 loss: 0.360282838344574
Batch 37/64 loss: 0.35863399505615234
Batch 38/64 loss: 0.3601139187812805
Batch 39/64 loss: 0.36267298460006714
Batch 40/64 loss: 0.3595116138458252
Batch 41/64 loss: 0.3622695207595825
Batch 42/64 loss: 0.3604412078857422
Batch 43/64 loss: 0.35855400562286377
Batch 44/64 loss: 0.35868144035339355
Batch 45/64 loss: 0.3586326241493225
Batch 46/64 loss: 0.35621339082717896
Batch 47/64 loss: 0.3611726760864258
Batch 48/64 loss: 0.3593828082084656
Batch 49/64 loss: 0.35732656717300415
Batch 50/64 loss: 0.35565948486328125
Batch 51/64 loss: 0.35710465908050537
Batch 52/64 loss: 0.3570142984390259
Batch 53/64 loss: 0.3584607243537903
Batch 54/64 loss: 0.36044102907180786
Batch 55/64 loss: 0.35979533195495605
Batch 56/64 loss: 0.35967761278152466
Batch 57/64 loss: 0.3582572340965271
Batch 58/64 loss: 0.3575865626335144
Batch 59/64 loss: 0.35780131816864014
Batch 60/64 loss: 0.35961735248565674
Batch 61/64 loss: 0.3617413640022278
Batch 62/64 loss: 0.3621487021446228
Batch 63/64 loss: 0.3582879304885864
Batch 64/64 loss: 0.3559051752090454
Epoch 18  Train loss: 0.35963334616492776  Val loss: 0.3615662897985006
Epoch 19
-------------------------------
Batch 1/64 loss: 0.35803478956222534
Batch 2/64 loss: 0.3589302897453308
Batch 3/64 loss: 0.35973697900772095
Batch 4/64 loss: 0.3564814329147339
Batch 5/64 loss: 0.3575308918952942
Batch 6/64 loss: 0.35871297121047974
Batch 7/64 loss: 0.36190640926361084
Batch 8/64 loss: 0.3576139211654663
Batch 9/64 loss: 0.3538084030151367
Batch 10/64 loss: 0.35889947414398193
Batch 11/64 loss: 0.35798758268356323
Batch 12/64 loss: 0.3606233596801758
Batch 13/64 loss: 0.3560500741004944
Batch 14/64 loss: 0.3609652519226074
Batch 15/64 loss: 0.3578667640686035
Batch 16/64 loss: 0.36262941360473633
Batch 17/64 loss: 0.3592989444732666
Batch 18/64 loss: 0.35598695278167725
Batch 19/64 loss: 0.35949647426605225
Batch 20/64 loss: 0.3583948612213135
Batch 21/64 loss: 0.3551420569419861
Batch 22/64 loss: 0.35890525579452515
Batch 23/64 loss: 0.3591724634170532
Batch 24/64 loss: 0.3581543564796448
Batch 25/64 loss: 0.35847628116607666
Batch 26/64 loss: 0.3583935499191284
Batch 27/64 loss: 0.35887080430984497
Batch 28/64 loss: 0.35834091901779175
Batch 29/64 loss: 0.35773736238479614
Batch 30/64 loss: 0.35968273878097534
Batch 31/64 loss: 0.3603024482727051
Batch 32/64 loss: 0.3568357229232788
Batch 33/64 loss: 0.3572976589202881
Batch 34/64 loss: 0.3575229048728943
Batch 35/64 loss: 0.3574337959289551
Batch 36/64 loss: 0.36028575897216797
Batch 37/64 loss: 0.3594639301300049
Batch 38/64 loss: 0.35897111892700195
Batch 39/64 loss: 0.3568105697631836
Batch 40/64 loss: 0.3572472333908081
Batch 41/64 loss: 0.3578376770019531
Batch 42/64 loss: 0.3567119240760803
Batch 43/64 loss: 0.35708320140838623
Batch 44/64 loss: 0.3585120439529419
Batch 45/64 loss: 0.3552706241607666
Batch 46/64 loss: 0.36184918880462646
Batch 47/64 loss: 0.35863614082336426
Batch 48/64 loss: 0.3568679094314575
Batch 49/64 loss: 0.359394371509552
Batch 50/64 loss: 0.36088430881500244
Batch 51/64 loss: 0.359912633895874
Batch 52/64 loss: 0.3592989444732666
Batch 53/64 loss: 0.3558518886566162
Batch 54/64 loss: 0.3609539270401001
Batch 55/64 loss: 0.36154669523239136
Batch 56/64 loss: 0.35674452781677246
Batch 57/64 loss: 0.36157381534576416
Batch 58/64 loss: 0.35797011852264404
Batch 59/64 loss: 0.3607328534126282
Batch 60/64 loss: 0.36198586225509644
Batch 61/64 loss: 0.36193597316741943
Batch 62/64 loss: 0.3604127764701843
Batch 63/64 loss: 0.35928428173065186
Batch 64/64 loss: 0.3611832857131958
Epoch 19  Train loss: 0.358715942326714  Val loss: 0.36052709756438267
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 0.3584740161895752
Batch 2/64 loss: 0.355466365814209
Batch 3/64 loss: 0.359483540058136
Batch 4/64 loss: 0.3551371097564697
Batch 5/64 loss: 0.35851430892944336
Batch 6/64 loss: 0.3583875894546509
Batch 7/64 loss: 0.35690295696258545
Batch 8/64 loss: 0.35963428020477295
Batch 9/64 loss: 0.35912394523620605
Batch 10/64 loss: 0.3596677780151367
Batch 11/64 loss: 0.3544647693634033
Batch 12/64 loss: 0.35830384492874146
Batch 13/64 loss: 0.35765594244003296
Batch 14/64 loss: 0.36044448614120483
Batch 15/64 loss: 0.357507586479187
Batch 16/64 loss: 0.36118006706237793
Batch 17/64 loss: 0.3588942885398865
Batch 18/64 loss: 0.3592339754104614
Batch 19/64 loss: 0.3592895269393921
Batch 20/64 loss: 0.3583436608314514
Batch 21/64 loss: 0.35834991931915283
Batch 22/64 loss: 0.361291766166687
Batch 23/64 loss: 0.3579363226890564
Batch 24/64 loss: 0.35883212089538574
Batch 25/64 loss: 0.35475093126296997
Batch 26/64 loss: 0.36011481285095215
Batch 27/64 loss: 0.3605097532272339
Batch 28/64 loss: 0.3603784441947937
Batch 29/64 loss: 0.3594212532043457
Batch 30/64 loss: 0.35698288679122925
Batch 31/64 loss: 0.36165714263916016
Batch 32/64 loss: 0.35873544216156006
Batch 33/64 loss: 0.36065733432769775
Batch 34/64 loss: 0.356775164604187
Batch 35/64 loss: 0.357336163520813
Batch 36/64 loss: 0.3576807975769043
Batch 37/64 loss: 0.3569152355194092
Batch 38/64 loss: 0.3605610728263855
Batch 39/64 loss: 0.3603939414024353
Batch 40/64 loss: 0.3612211346626282
Batch 41/64 loss: 0.35790061950683594
Batch 42/64 loss: 0.35520386695861816
Batch 43/64 loss: 0.3537360429763794
Batch 44/64 loss: 0.3574918508529663
Batch 45/64 loss: 0.35886263847351074
Batch 46/64 loss: 0.3563653230667114
Batch 47/64 loss: 0.36216968297958374
Batch 48/64 loss: 0.3570246696472168
Batch 49/64 loss: 0.35599637031555176
Batch 50/64 loss: 0.36183053255081177
Batch 51/64 loss: 0.36174172163009644
Batch 52/64 loss: 0.3586430549621582
Batch 53/64 loss: 0.3560085892677307
Batch 54/64 loss: 0.3604000210762024
Batch 55/64 loss: 0.3557109236717224
Batch 56/64 loss: 0.362467885017395
Batch 57/64 loss: 0.3563891649246216
Batch 58/64 loss: 0.3568890690803528
Batch 59/64 loss: 0.36148738861083984
Batch 60/64 loss: 0.35680150985717773
Batch 61/64 loss: 0.36135125160217285
Batch 62/64 loss: 0.35584837198257446
Batch 63/64 loss: 0.35941553115844727
Batch 64/64 loss: 0.35668498277664185
Epoch 20  Train loss: 0.35849194503297993  Val loss: 0.3610435849202867
Epoch 21
-------------------------------
Batch 1/64 loss: 0.3584032654762268
Batch 2/64 loss: 0.3608112335205078
Batch 3/64 loss: 0.35890865325927734
Batch 4/64 loss: 0.3610096573829651
Batch 5/64 loss: 0.35946762561798096
Batch 6/64 loss: 0.35843437910079956
Batch 7/64 loss: 0.3557826280593872
Batch 8/64 loss: 0.3571057915687561
Batch 9/64 loss: 0.3621494770050049
Batch 10/64 loss: 0.36199069023132324
Batch 11/64 loss: 0.3569778800010681
Batch 12/64 loss: 0.35691893100738525
Batch 13/64 loss: 0.36058175563812256
Batch 14/64 loss: 0.35620999336242676
Batch 15/64 loss: 0.35767728090286255
Batch 16/64 loss: 0.3540303707122803
Batch 17/64 loss: 0.3583720922470093
Batch 18/64 loss: 0.3578152656555176
Batch 19/64 loss: 0.3575957417488098
Batch 20/64 loss: 0.3605060577392578
Batch 21/64 loss: 0.3575018644332886
Batch 22/64 loss: 0.3586541414260864
Batch 23/64 loss: 0.3572906255722046
Batch 24/64 loss: 0.3554149866104126
Batch 25/64 loss: 0.3551344871520996
Batch 26/64 loss: 0.3579803705215454
Batch 27/64 loss: 0.3595234155654907
Batch 28/64 loss: 0.35585612058639526
Batch 29/64 loss: 0.36295396089553833
Batch 30/64 loss: 0.36089855432510376
Batch 31/64 loss: 0.36221182346343994
Batch 32/64 loss: 0.3580751419067383
Batch 33/64 loss: 0.3543071746826172
Batch 34/64 loss: 0.35879063606262207
Batch 35/64 loss: 0.35664820671081543
Batch 36/64 loss: 0.36193913221359253
Batch 37/64 loss: 0.3595737814903259
Batch 38/64 loss: 0.35926663875579834
Batch 39/64 loss: 0.35467231273651123
Batch 40/64 loss: 0.35880714654922485
Batch 41/64 loss: 0.3563603162765503
Batch 42/64 loss: 0.3571450114250183
Batch 43/64 loss: 0.35550689697265625
Batch 44/64 loss: 0.3531298041343689
Batch 45/64 loss: 0.361446738243103
Batch 46/64 loss: 0.3601462244987488
Batch 47/64 loss: 0.3571711778640747
Batch 48/64 loss: 0.36035943031311035
Batch 49/64 loss: 0.3595132827758789
Batch 50/64 loss: 0.3563750982284546
Batch 51/64 loss: 0.3557783365249634
Batch 52/64 loss: 0.35758787393569946
Batch 53/64 loss: 0.3562270402908325
Batch 54/64 loss: 0.36097919940948486
Batch 55/64 loss: 0.3595060706138611
Batch 56/64 loss: 0.35711729526519775
Batch 57/64 loss: 0.36064398288726807
Batch 58/64 loss: 0.35762953758239746
Batch 59/64 loss: 0.35948050022125244
Batch 60/64 loss: 0.3572845458984375
Batch 61/64 loss: 0.361189603805542
Batch 62/64 loss: 0.3617020845413208
Batch 63/64 loss: 0.35825085639953613
Batch 64/64 loss: 0.36220842599868774
Epoch 21  Train loss: 0.35840684736476225  Val loss: 0.359414206132856
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 0.3571740388870239
Batch 2/64 loss: 0.3551238775253296
Batch 3/64 loss: 0.35303419828414917
Batch 4/64 loss: 0.35947227478027344
Batch 5/64 loss: 0.358985960483551
Batch 6/64 loss: 0.3584616780281067
Batch 7/64 loss: 0.35734808444976807
Batch 8/64 loss: 0.3582524061203003
Batch 9/64 loss: 0.3589531183242798
Batch 10/64 loss: 0.3568558692932129
Batch 11/64 loss: 0.35673820972442627
Batch 12/64 loss: 0.3597832918167114
Batch 13/64 loss: 0.35829102993011475
Batch 14/64 loss: 0.3581352233886719
Batch 15/64 loss: 0.3604466915130615
Batch 16/64 loss: 0.35689812898635864
Batch 17/64 loss: 0.3604879379272461
Batch 18/64 loss: 0.35935986042022705
Batch 19/64 loss: 0.3576171398162842
Batch 20/64 loss: 0.35641753673553467
Batch 21/64 loss: 0.35949522256851196
Batch 22/64 loss: 0.3591066598892212
Batch 23/64 loss: 0.3562736511230469
Batch 24/64 loss: 0.36038458347320557
Batch 25/64 loss: 0.3550897240638733
Batch 26/64 loss: 0.3594430685043335
Batch 27/64 loss: 0.3560539484024048
Batch 28/64 loss: 0.3572552800178528
Batch 29/64 loss: 0.35635000467300415
Batch 30/64 loss: 0.3568454384803772
Batch 31/64 loss: 0.358611524105072
Batch 32/64 loss: 0.3598978519439697
Batch 33/64 loss: 0.35662126541137695
Batch 34/64 loss: 0.35662734508514404
Batch 35/64 loss: 0.3614339828491211
Batch 36/64 loss: 0.35770463943481445
Batch 37/64 loss: 0.36156678199768066
Batch 38/64 loss: 0.35725176334381104
Batch 39/64 loss: 0.35426104068756104
Batch 40/64 loss: 0.35871177911758423
Batch 41/64 loss: 0.3598117232322693
Batch 42/64 loss: 0.35474687814712524
Batch 43/64 loss: 0.358704149723053
Batch 44/64 loss: 0.3563219904899597
Batch 45/64 loss: 0.3569919466972351
Batch 46/64 loss: 0.36087971925735474
Batch 47/64 loss: 0.3573107123374939
Batch 48/64 loss: 0.3571927547454834
Batch 49/64 loss: 0.35803860425949097
Batch 50/64 loss: 0.35915935039520264
Batch 51/64 loss: 0.3596658706665039
Batch 52/64 loss: 0.3539280295372009
Batch 53/64 loss: 0.35784298181533813
Batch 54/64 loss: 0.3611375689506531
Batch 55/64 loss: 0.35684525966644287
Batch 56/64 loss: 0.35928666591644287
Batch 57/64 loss: 0.3561360239982605
Batch 58/64 loss: 0.35657799243927
Batch 59/64 loss: 0.3585226535797119
Batch 60/64 loss: 0.35906457901000977
Batch 61/64 loss: 0.35815227031707764
Batch 62/64 loss: 0.356960654258728
Batch 63/64 loss: 0.3592491149902344
Batch 64/64 loss: 0.35700106620788574
Epoch 22  Train loss: 0.3579153004814597  Val loss: 0.35925255485416685
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: 0.35541021823883057
Batch 2/64 loss: 0.35759735107421875
Batch 3/64 loss: 0.361311674118042
Batch 4/64 loss: 0.35824573040008545
Batch 5/64 loss: 0.35625898838043213
Batch 6/64 loss: 0.35588598251342773
Batch 7/64 loss: 0.356473445892334
Batch 8/64 loss: 0.3594256043434143
Batch 9/64 loss: 0.35683417320251465
Batch 10/64 loss: 0.36027956008911133
Batch 11/64 loss: 0.3567330837249756
Batch 12/64 loss: 0.35839664936065674
Batch 13/64 loss: 0.36326611042022705
Batch 14/64 loss: 0.36007463932037354
Batch 15/64 loss: 0.3582829236984253
Batch 16/64 loss: 0.35814255475997925
Batch 17/64 loss: 0.3574860095977783
Batch 18/64 loss: 0.35417282581329346
Batch 19/64 loss: 0.3582935333251953
Batch 20/64 loss: 0.35411518812179565
Batch 21/64 loss: 0.3534266948699951
Batch 22/64 loss: 0.35412323474884033
Batch 23/64 loss: 0.35731041431427
Batch 24/64 loss: 0.35998237133026123
Batch 25/64 loss: 0.3615293502807617
Batch 26/64 loss: 0.35438311100006104
Batch 27/64 loss: 0.3557523488998413
Batch 28/64 loss: 0.3578369617462158
Batch 29/64 loss: 0.35686349868774414
Batch 30/64 loss: 0.35657060146331787
Batch 31/64 loss: 0.35868990421295166
Batch 32/64 loss: 0.3551180958747864
Batch 33/64 loss: 0.3562101721763611
Batch 34/64 loss: 0.35586220026016235
Batch 35/64 loss: 0.3602868318557739
Batch 36/64 loss: 0.36010152101516724
Batch 37/64 loss: 0.35658466815948486
Batch 38/64 loss: 0.35633230209350586
Batch 39/64 loss: 0.35598570108413696
Batch 40/64 loss: 0.35575878620147705
Batch 41/64 loss: 0.3578329086303711
Batch 42/64 loss: 0.35851097106933594
Batch 43/64 loss: 0.3554680347442627
Batch 44/64 loss: 0.36080968379974365
Batch 45/64 loss: 0.35719501972198486
Batch 46/64 loss: 0.3544946312904358
Batch 47/64 loss: 0.3596916198730469
Batch 48/64 loss: 0.3533433675765991
Batch 49/64 loss: 0.35728681087493896
Batch 50/64 loss: 0.35463380813598633
Batch 51/64 loss: 0.3583548069000244
Batch 52/64 loss: 0.3587436079978943
Batch 53/64 loss: 0.3564729690551758
Batch 54/64 loss: 0.35888636112213135
Batch 55/64 loss: 0.3572445511817932
Batch 56/64 loss: 0.35943543910980225
Batch 57/64 loss: 0.3557446002960205
Batch 58/64 loss: 0.35902708768844604
Batch 59/64 loss: 0.3567172884941101
Batch 60/64 loss: 0.3593059778213501
Batch 61/64 loss: 0.360281765460968
Batch 62/64 loss: 0.3577481508255005
Batch 63/64 loss: 0.3547813296318054
Batch 64/64 loss: 0.3595096468925476
Epoch 23  Train loss: 0.35744373401006063  Val loss: 0.35947222541697654
Epoch 24
-------------------------------
Batch 1/64 loss: 0.35434770584106445
Batch 2/64 loss: 0.3556993007659912
Batch 3/64 loss: 0.35830146074295044
Batch 4/64 loss: 0.35449135303497314
Batch 5/64 loss: 0.35665440559387207
Batch 6/64 loss: 0.35386717319488525
Batch 7/64 loss: 0.35720837116241455
Batch 8/64 loss: 0.35697126388549805
Batch 9/64 loss: 0.36273229122161865
Batch 10/64 loss: 0.3631015419960022
Batch 11/64 loss: 0.3572394847869873
Batch 12/64 loss: 0.35782402753829956
Batch 13/64 loss: 0.36057955026626587
Batch 14/64 loss: 0.35585975646972656
Batch 15/64 loss: 0.36193692684173584
Batch 16/64 loss: 0.35520005226135254
Batch 17/64 loss: 0.36005133390426636
Batch 18/64 loss: 0.3574669361114502
Batch 19/64 loss: 0.35929548740386963
Batch 20/64 loss: 0.35615360736846924
Batch 21/64 loss: 0.3521175980567932
Batch 22/64 loss: 0.3562973141670227
Batch 23/64 loss: 0.3566701412200928
Batch 24/64 loss: 0.35717928409576416
Batch 25/64 loss: 0.3528711199760437
Batch 26/64 loss: 0.3572744131088257
Batch 27/64 loss: 0.359575092792511
Batch 28/64 loss: 0.35892021656036377
Batch 29/64 loss: 0.35821592807769775
Batch 30/64 loss: 0.3584306240081787
Batch 31/64 loss: 0.36064863204956055
Batch 32/64 loss: 0.35883069038391113
Batch 33/64 loss: 0.3568376898765564
Batch 34/64 loss: 0.3579667806625366
Batch 35/64 loss: 0.3568642735481262
Batch 36/64 loss: 0.3564489483833313
Batch 37/64 loss: 0.35743314027786255
Batch 38/64 loss: 0.35616135597229004
Batch 39/64 loss: 0.3563499450683594
Batch 40/64 loss: 0.3589114546775818
Batch 41/64 loss: 0.35620903968811035
Batch 42/64 loss: 0.3557014465332031
Batch 43/64 loss: 0.3627326488494873
Batch 44/64 loss: 0.35675346851348877
Batch 45/64 loss: 0.3571261167526245
Batch 46/64 loss: 0.3581850528717041
Batch 47/64 loss: 0.35647475719451904
Batch 48/64 loss: 0.3574451208114624
Batch 49/64 loss: 0.35274696350097656
Batch 50/64 loss: 0.35921549797058105
Batch 51/64 loss: 0.3598420023918152
Batch 52/64 loss: 0.35894936323165894
Batch 53/64 loss: 0.35603147745132446
Batch 54/64 loss: 0.35674023628234863
Batch 55/64 loss: 0.3586943745613098
Batch 56/64 loss: 0.356107234954834
Batch 57/64 loss: 0.36035484075546265
Batch 58/64 loss: 0.35520946979522705
Batch 59/64 loss: 0.359361469745636
Batch 60/64 loss: 0.35635805130004883
Batch 61/64 loss: 0.3613952398300171
Batch 62/64 loss: 0.3538662791252136
Batch 63/64 loss: 0.35790491104125977
Batch 64/64 loss: 0.35732316970825195
Epoch 24  Train loss: 0.35749622139276244  Val loss: 0.3586119810740153
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 0.35709065198898315
Batch 2/64 loss: 0.35441410541534424
Batch 3/64 loss: 0.35379457473754883
Batch 4/64 loss: 0.3552984595298767
Batch 5/64 loss: 0.3601433038711548
Batch 6/64 loss: 0.35497772693634033
Batch 7/64 loss: 0.3574850559234619
Batch 8/64 loss: 0.3574606776237488
Batch 9/64 loss: 0.353820264339447
Batch 10/64 loss: 0.3569248914718628
Batch 11/64 loss: 0.3543573021888733
Batch 12/64 loss: 0.36091065406799316
Batch 13/64 loss: 0.35976362228393555
Batch 14/64 loss: 0.3557727336883545
Batch 15/64 loss: 0.35820847749710083
Batch 16/64 loss: 0.3572584390640259
Batch 17/64 loss: 0.3562659025192261
Batch 18/64 loss: 0.3563964366912842
Batch 19/64 loss: 0.3591638207435608
Batch 20/64 loss: 0.3528653383255005
Batch 21/64 loss: 0.3587827682495117
Batch 22/64 loss: 0.3565758466720581
Batch 23/64 loss: 0.3548957109451294
Batch 24/64 loss: 0.35873639583587646
Batch 25/64 loss: 0.3544367551803589
Batch 26/64 loss: 0.3557739853858948
Batch 27/64 loss: 0.3574226498603821
Batch 28/64 loss: 0.35949069261550903
Batch 29/64 loss: 0.3573707342147827
Batch 30/64 loss: 0.35869061946868896
Batch 31/64 loss: 0.35597503185272217
Batch 32/64 loss: 0.35813188552856445
Batch 33/64 loss: 0.35998475551605225
Batch 34/64 loss: 0.3560214042663574
Batch 35/64 loss: 0.35890525579452515
Batch 36/64 loss: 0.3569362163543701
Batch 37/64 loss: 0.35708290338516235
Batch 38/64 loss: 0.3545994758605957
Batch 39/64 loss: 0.35906004905700684
Batch 40/64 loss: 0.35862207412719727
Batch 41/64 loss: 0.35817456245422363
Batch 42/64 loss: 0.3598109483718872
Batch 43/64 loss: 0.3585699796676636
Batch 44/64 loss: 0.3562896251678467
Batch 45/64 loss: 0.35760724544525146
Batch 46/64 loss: 0.35922545194625854
Batch 47/64 loss: 0.3568531274795532
Batch 48/64 loss: 0.3582950234413147
Batch 49/64 loss: 0.35486340522766113
Batch 50/64 loss: 0.3555551767349243
Batch 51/64 loss: 0.3578813672065735
Batch 52/64 loss: 0.35583919286727905
Batch 53/64 loss: 0.35549020767211914
Batch 54/64 loss: 0.3568105697631836
Batch 55/64 loss: 0.35549163818359375
Batch 56/64 loss: 0.3585352301597595
Batch 57/64 loss: 0.3586888313293457
Batch 58/64 loss: 0.3568291664123535
Batch 59/64 loss: 0.3568321466445923
Batch 60/64 loss: 0.3564828634262085
Batch 61/64 loss: 0.3587091565132141
Batch 62/64 loss: 0.35570991039276123
Batch 63/64 loss: 0.35882568359375
Batch 64/64 loss: 0.35897183418273926
Epoch 25  Train loss: 0.3571210515265371  Val loss: 0.3590077800849049
Epoch 26
-------------------------------
Batch 1/64 loss: 0.35691338777542114
Batch 2/64 loss: 0.3543895483016968
Batch 3/64 loss: 0.3589034080505371
Batch 4/64 loss: 0.35849422216415405
Batch 5/64 loss: 0.35620689392089844
Batch 6/64 loss: 0.35970842838287354
Batch 7/64 loss: 0.35841238498687744
Batch 8/64 loss: 0.35602521896362305
Batch 9/64 loss: 0.3556184768676758
Batch 10/64 loss: 0.3550288677215576
Batch 11/64 loss: 0.35681915283203125
Batch 12/64 loss: 0.36105120182037354
Batch 13/64 loss: 0.3624938726425171
Batch 14/64 loss: 0.35743093490600586
Batch 15/64 loss: 0.3576704263687134
Batch 16/64 loss: 0.3584972023963928
Batch 17/64 loss: 0.3569289445877075
Batch 18/64 loss: 0.35506337881088257
Batch 19/64 loss: 0.35622549057006836
Batch 20/64 loss: 0.3560594916343689
Batch 21/64 loss: 0.3555639982223511
Batch 22/64 loss: 0.35602766275405884
Batch 23/64 loss: 0.3558793067932129
Batch 24/64 loss: 0.3573201894760132
Batch 25/64 loss: 0.3577688932418823
Batch 26/64 loss: 0.35602712631225586
Batch 27/64 loss: 0.35787689685821533
Batch 28/64 loss: 0.355685830116272
Batch 29/64 loss: 0.35751181840896606
Batch 30/64 loss: 0.35804492235183716
Batch 31/64 loss: 0.35799717903137207
Batch 32/64 loss: 0.35428082942962646
Batch 33/64 loss: 0.35641980171203613
Batch 34/64 loss: 0.3614109754562378
Batch 35/64 loss: 0.35820460319519043
Batch 36/64 loss: 0.3566474914550781
Batch 37/64 loss: 0.3528902530670166
Batch 38/64 loss: 0.35624778270721436
Batch 39/64 loss: 0.3613584041595459
Batch 40/64 loss: 0.3548082113265991
Batch 41/64 loss: 0.36133503913879395
Batch 42/64 loss: 0.3551267385482788
Batch 43/64 loss: 0.3556394577026367
Batch 44/64 loss: 0.3574630618095398
Batch 45/64 loss: 0.3549923896789551
Batch 46/64 loss: 0.3550434112548828
Batch 47/64 loss: 0.3582404851913452
Batch 48/64 loss: 0.35797810554504395
Batch 49/64 loss: 0.3593473434448242
Batch 50/64 loss: 0.3534635901451111
Batch 51/64 loss: 0.3545859456062317
Batch 52/64 loss: 0.35617494583129883
Batch 53/64 loss: 0.353218674659729
Batch 54/64 loss: 0.355938196182251
Batch 55/64 loss: 0.3550090789794922
Batch 56/64 loss: 0.35397326946258545
Batch 57/64 loss: 0.355160117149353
Batch 58/64 loss: 0.35608887672424316
Batch 59/64 loss: 0.3558380603790283
Batch 60/64 loss: 0.3563886880874634
Batch 61/64 loss: 0.3577094078063965
Batch 62/64 loss: 0.35619205236434937
Batch 63/64 loss: 0.3557307720184326
Batch 64/64 loss: 0.35474222898483276
Epoch 26  Train loss: 0.35674678414475686  Val loss: 0.35972987315089433
Epoch 27
-------------------------------
Batch 1/64 loss: 0.35363924503326416
Batch 2/64 loss: 0.35498976707458496
Batch 3/64 loss: 0.35800254344940186
Batch 4/64 loss: 0.357035756111145
Batch 5/64 loss: 0.35567033290863037
Batch 6/64 loss: 0.35786640644073486
Batch 7/64 loss: 0.35568082332611084
Batch 8/64 loss: 0.35828697681427
Batch 9/64 loss: 0.3560483455657959
Batch 10/64 loss: 0.3573840856552124
Batch 11/64 loss: 0.35770630836486816
Batch 12/64 loss: 0.3574223518371582
Batch 13/64 loss: 0.35577392578125
Batch 14/64 loss: 0.35520702600479126
Batch 15/64 loss: 0.3564422130584717
Batch 16/64 loss: 0.361120343208313
Batch 17/64 loss: 0.35855257511138916
Batch 18/64 loss: 0.358443021774292
Batch 19/64 loss: 0.3558589220046997
Batch 20/64 loss: 0.3560160994529724
Batch 21/64 loss: 0.3592846989631653
Batch 22/64 loss: 0.35357868671417236
Batch 23/64 loss: 0.3564927577972412
Batch 24/64 loss: 0.3591424226760864
Batch 25/64 loss: 0.35574424266815186
Batch 26/64 loss: 0.36058473587036133
Batch 27/64 loss: 0.35693323612213135
Batch 28/64 loss: 0.3556947708129883
Batch 29/64 loss: 0.3560730218887329
Batch 30/64 loss: 0.3559190034866333
Batch 31/64 loss: 0.35822880268096924
Batch 32/64 loss: 0.3545709252357483
Batch 33/64 loss: 0.3540527820587158
Batch 34/64 loss: 0.35736197233200073
Batch 35/64 loss: 0.3571653366088867
Batch 36/64 loss: 0.3574044108390808
Batch 37/64 loss: 0.356357216835022
Batch 38/64 loss: 0.3570626974105835
Batch 39/64 loss: 0.35345256328582764
Batch 40/64 loss: 0.35619938373565674
Batch 41/64 loss: 0.35911720991134644
Batch 42/64 loss: 0.351382851600647
Batch 43/64 loss: 0.3551591634750366
Batch 44/64 loss: 0.35684067010879517
Batch 45/64 loss: 0.35620903968811035
Batch 46/64 loss: 0.3550611734390259
Batch 47/64 loss: 0.36037158966064453
Batch 48/64 loss: 0.3539077639579773
Batch 49/64 loss: 0.3575829267501831
Batch 50/64 loss: 0.3595544099807739
Batch 51/64 loss: 0.35536932945251465
Batch 52/64 loss: 0.3549731373786926
Batch 53/64 loss: 0.3570689558982849
Batch 54/64 loss: 0.35406965017318726
Batch 55/64 loss: 0.3568694591522217
Batch 56/64 loss: 0.35892385244369507
Batch 57/64 loss: 0.3527562618255615
Batch 58/64 loss: 0.3554137945175171
Batch 59/64 loss: 0.3588813543319702
Batch 60/64 loss: 0.35734546184539795
Batch 61/64 loss: 0.35507529973983765
Batch 62/64 loss: 0.35317564010620117
Batch 63/64 loss: 0.3564567565917969
Batch 64/64 loss: 0.355985164642334
Epoch 27  Train loss: 0.35650204490212833  Val loss: 0.3579525101635464
Saving best model, epoch: 27
Epoch 28
-------------------------------
Batch 1/64 loss: 0.35592198371887207
Batch 2/64 loss: 0.3543119430541992
Batch 3/64 loss: 0.35500359535217285
Batch 4/64 loss: 0.35752415657043457
Batch 5/64 loss: 0.3562576174736023
Batch 6/64 loss: 0.3564978241920471
Batch 7/64 loss: 0.3553352355957031
Batch 8/64 loss: 0.35958677530288696
Batch 9/64 loss: 0.3602808713912964
Batch 10/64 loss: 0.3528376817703247
Batch 11/64 loss: 0.35856378078460693
Batch 12/64 loss: 0.3554081916809082
Batch 13/64 loss: 0.35652172565460205
Batch 14/64 loss: 0.355965793132782
Batch 15/64 loss: 0.3588745594024658
Batch 16/64 loss: 0.3546699285507202
Batch 17/64 loss: 0.353543758392334
Batch 18/64 loss: 0.35754966735839844
Batch 19/64 loss: 0.35723739862442017
Batch 20/64 loss: 0.3540421724319458
Batch 21/64 loss: 0.35667842626571655
Batch 22/64 loss: 0.3568427562713623
Batch 23/64 loss: 0.3578459620475769
Batch 24/64 loss: 0.3588111400604248
Batch 25/64 loss: 0.35689079761505127
Batch 26/64 loss: 0.3565332889556885
Batch 27/64 loss: 0.35645294189453125
Batch 28/64 loss: 0.357926607131958
Batch 29/64 loss: 0.35389578342437744
Batch 30/64 loss: 0.357629656791687
Batch 31/64 loss: 0.3556821346282959
Batch 32/64 loss: 0.3551381826400757
Batch 33/64 loss: 0.3562192916870117
Batch 34/64 loss: 0.35479968786239624
Batch 35/64 loss: 0.35357916355133057
Batch 36/64 loss: 0.3557288646697998
Batch 37/64 loss: 0.3586500287055969
Batch 38/64 loss: 0.3561028242111206
Batch 39/64 loss: 0.35632646083831787
Batch 40/64 loss: 0.356442928314209
Batch 41/64 loss: 0.3564380407333374
Batch 42/64 loss: 0.3547070026397705
Batch 43/64 loss: 0.3535928726196289
Batch 44/64 loss: 0.3593214750289917
Batch 45/64 loss: 0.35623979568481445
Batch 46/64 loss: 0.35686159133911133
Batch 47/64 loss: 0.354925274848938
Batch 48/64 loss: 0.3569899797439575
Batch 49/64 loss: 0.3561004400253296
Batch 50/64 loss: 0.35842621326446533
Batch 51/64 loss: 0.35802769660949707
Batch 52/64 loss: 0.35719090700149536
Batch 53/64 loss: 0.3566932678222656
Batch 54/64 loss: 0.3594841957092285
Batch 55/64 loss: 0.35650813579559326
Batch 56/64 loss: 0.3595084547996521
Batch 57/64 loss: 0.35592472553253174
Batch 58/64 loss: 0.3554213047027588
Batch 59/64 loss: 0.3573852777481079
Batch 60/64 loss: 0.3551381826400757
Batch 61/64 loss: 0.35719186067581177
Batch 62/64 loss: 0.35824501514434814
Batch 63/64 loss: 0.35437071323394775
Batch 64/64 loss: 0.35481393337249756
Epoch 28  Train loss: 0.35646924645292993  Val loss: 0.35969341579581454
Epoch 29
-------------------------------
Batch 1/64 loss: 0.35776185989379883
Batch 2/64 loss: 0.3577679395675659
Batch 3/64 loss: 0.35492026805877686
Batch 4/64 loss: 0.3541538715362549
Batch 5/64 loss: 0.3578478693962097
Batch 6/64 loss: 0.3574587106704712
Batch 7/64 loss: 0.35406339168548584
Batch 8/64 loss: 0.35845065116882324
Batch 9/64 loss: 0.3590989112854004
Batch 10/64 loss: 0.3556942343711853
Batch 11/64 loss: 0.35861068964004517
Batch 12/64 loss: 0.35654544830322266
Batch 13/64 loss: 0.3568190336227417
Batch 14/64 loss: 0.35516810417175293
Batch 15/64 loss: 0.35684895515441895
Batch 16/64 loss: 0.35583341121673584
Batch 17/64 loss: 0.3532688021659851
Batch 18/64 loss: 0.3548697233200073
Batch 19/64 loss: 0.35631388425827026
Batch 20/64 loss: 0.35351550579071045
Batch 21/64 loss: 0.356756329536438
Batch 22/64 loss: 0.3547475337982178
Batch 23/64 loss: 0.35758984088897705
Batch 24/64 loss: 0.3526831865310669
Batch 25/64 loss: 0.3562641739845276
Batch 26/64 loss: 0.35713404417037964
Batch 27/64 loss: 0.35214340686798096
Batch 28/64 loss: 0.35602688789367676
Batch 29/64 loss: 0.3526766300201416
Batch 30/64 loss: 0.3577834367752075
Batch 31/64 loss: 0.3564494848251343
Batch 32/64 loss: 0.3542454242706299
Batch 33/64 loss: 0.3580765128135681
Batch 34/64 loss: 0.3575829267501831
Batch 35/64 loss: 0.35459232330322266
Batch 36/64 loss: 0.35915279388427734
Batch 37/64 loss: 0.3516029119491577
Batch 38/64 loss: 0.3569944500923157
Batch 39/64 loss: 0.3556050658226013
Batch 40/64 loss: 0.35921210050582886
Batch 41/64 loss: 0.3540463447570801
Batch 42/64 loss: 0.35887277126312256
Batch 43/64 loss: 0.35429155826568604
Batch 44/64 loss: 0.3556631803512573
Batch 45/64 loss: 0.3550136089324951
Batch 46/64 loss: 0.35505229234695435
Batch 47/64 loss: 0.35698676109313965
Batch 48/64 loss: 0.35730528831481934
Batch 49/64 loss: 0.3562098741531372
Batch 50/64 loss: 0.3532527685165405
Batch 51/64 loss: 0.3598839044570923
Batch 52/64 loss: 0.35581886768341064
Batch 53/64 loss: 0.3561989665031433
Batch 54/64 loss: 0.35980188846588135
Batch 55/64 loss: 0.3565119504928589
Batch 56/64 loss: 0.3578702211380005
Batch 57/64 loss: 0.3533514738082886
Batch 58/64 loss: 0.3596974015235901
Batch 59/64 loss: 0.35591983795166016
Batch 60/64 loss: 0.3572113513946533
Batch 61/64 loss: 0.36032164096832275
Batch 62/64 loss: 0.35459446907043457
Batch 63/64 loss: 0.3514222502708435
Batch 64/64 loss: 0.35275930166244507
Epoch 29  Train loss: 0.3561129235753826  Val loss: 0.35827560236363887
Epoch 30
-------------------------------
Batch 1/64 loss: 0.3586132526397705
Batch 2/64 loss: 0.3551439642906189
Batch 3/64 loss: 0.35394132137298584
Batch 4/64 loss: 0.3538912534713745
Batch 5/64 loss: 0.35336029529571533
Batch 6/64 loss: 0.3610764741897583
Batch 7/64 loss: 0.3589433431625366
Batch 8/64 loss: 0.35631489753723145
Batch 9/64 loss: 0.35223621129989624
Batch 10/64 loss: 0.3559304475784302
Batch 11/64 loss: 0.3564212918281555
Batch 12/64 loss: 0.35472166538238525
Batch 13/64 loss: 0.35560184717178345
Batch 14/64 loss: 0.3544875383377075
Batch 15/64 loss: 0.3587082624435425
Batch 16/64 loss: 0.35680413246154785
Batch 17/64 loss: 0.35156309604644775
Batch 18/64 loss: 0.3571595549583435
Batch 19/64 loss: 0.35542184114456177
Batch 20/64 loss: 0.3554118871688843
Batch 21/64 loss: 0.3559454679489136
Batch 22/64 loss: 0.35761862993240356
Batch 23/64 loss: 0.3573164939880371
Batch 24/64 loss: 0.35767662525177
Batch 25/64 loss: 0.3534504175186157
Batch 26/64 loss: 0.3558938503265381
Batch 27/64 loss: 0.353951096534729
Batch 28/64 loss: 0.35730159282684326
Batch 29/64 loss: 0.3558080196380615
Batch 30/64 loss: 0.35486865043640137
Batch 31/64 loss: 0.35298681259155273
Batch 32/64 loss: 0.35522812604904175
Batch 33/64 loss: 0.35241615772247314
Batch 34/64 loss: 0.35460031032562256
Batch 35/64 loss: 0.35698485374450684
Batch 36/64 loss: 0.3533374071121216
Batch 37/64 loss: 0.35486340522766113
Batch 38/64 loss: 0.3578048348426819
Batch 39/64 loss: 0.35518592596054077
Batch 40/64 loss: 0.35506343841552734
Batch 41/64 loss: 0.35407334566116333
Batch 42/64 loss: 0.35591399669647217
Batch 43/64 loss: 0.356813907623291
Batch 44/64 loss: 0.3579786419868469
Batch 45/64 loss: 0.3599233627319336
Batch 46/64 loss: 0.35679179430007935
Batch 47/64 loss: 0.3536747097969055
Batch 48/64 loss: 0.3540761470794678
Batch 49/64 loss: 0.3558849096298218
Batch 50/64 loss: 0.35537660121917725
Batch 51/64 loss: 0.3568387031555176
Batch 52/64 loss: 0.35751575231552124
Batch 53/64 loss: 0.3557038903236389
Batch 54/64 loss: 0.3564213514328003
Batch 55/64 loss: 0.35510361194610596
Batch 56/64 loss: 0.3581368923187256
Batch 57/64 loss: 0.35595154762268066
Batch 58/64 loss: 0.3558419942855835
Batch 59/64 loss: 0.35870903730392456
Batch 60/64 loss: 0.35671567916870117
Batch 61/64 loss: 0.3561629056930542
Batch 62/64 loss: 0.3585953712463379
Batch 63/64 loss: 0.3583911657333374
Batch 64/64 loss: 0.35343581438064575
Epoch 30  Train loss: 0.355917284301683  Val loss: 0.35954854619462057
Epoch 31
-------------------------------
Batch 1/64 loss: 0.35689330101013184
Batch 2/64 loss: 0.3575405478477478
Batch 3/64 loss: 0.35850226879119873
Batch 4/64 loss: 0.3575860261917114
Batch 5/64 loss: 0.3556584119796753
Batch 6/64 loss: 0.3536117672920227
Batch 7/64 loss: 0.35253798961639404
Batch 8/64 loss: 0.35198748111724854
Batch 9/64 loss: 0.3515574336051941
Batch 10/64 loss: 0.35414040088653564
Batch 11/64 loss: 0.3555593490600586
Batch 12/64 loss: 0.3579005002975464
Batch 13/64 loss: 0.3541943430900574
Batch 14/64 loss: 0.3529379963874817
Batch 15/64 loss: 0.35673636198043823
Batch 16/64 loss: 0.3568127155303955
Batch 17/64 loss: 0.3553144931793213
Batch 18/64 loss: 0.35373473167419434
Batch 19/64 loss: 0.3527069687843323
Batch 20/64 loss: 0.3499714136123657
Batch 21/64 loss: 0.3539283275604248
Batch 22/64 loss: 0.35821306705474854
Batch 23/64 loss: 0.3554965853691101
Batch 24/64 loss: 0.3573777675628662
Batch 25/64 loss: 0.3601377010345459
Batch 26/64 loss: 0.35767149925231934
Batch 27/64 loss: 0.3565713167190552
Batch 28/64 loss: 0.3565734624862671
Batch 29/64 loss: 0.35643959045410156
Batch 30/64 loss: 0.3502327799797058
Batch 31/64 loss: 0.3547942638397217
Batch 32/64 loss: 0.35449230670928955
Batch 33/64 loss: 0.35430455207824707
Batch 34/64 loss: 0.35423052310943604
Batch 35/64 loss: 0.35820531845092773
Batch 36/64 loss: 0.35707807540893555
Batch 37/64 loss: 0.3561345338821411
Batch 38/64 loss: 0.35429847240448
Batch 39/64 loss: 0.356656014919281
Batch 40/64 loss: 0.3541427254676819
Batch 41/64 loss: 0.357952356338501
Batch 42/64 loss: 0.35594630241394043
Batch 43/64 loss: 0.3563718795776367
Batch 44/64 loss: 0.3593742251396179
Batch 45/64 loss: 0.35569024085998535
Batch 46/64 loss: 0.3567294478416443
Batch 47/64 loss: 0.3544912338256836
Batch 48/64 loss: 0.35588449239730835
Batch 49/64 loss: 0.35372328758239746
Batch 50/64 loss: 0.35601770877838135
Batch 51/64 loss: 0.35747772455215454
Batch 52/64 loss: 0.35791730880737305
Batch 53/64 loss: 0.36050742864608765
Batch 54/64 loss: 0.3553716540336609
Batch 55/64 loss: 0.35793352127075195
Batch 56/64 loss: 0.3534696102142334
Batch 57/64 loss: 0.3553449511528015
Batch 58/64 loss: 0.3558000326156616
Batch 59/64 loss: 0.35769420862197876
Batch 60/64 loss: 0.3556334972381592
Batch 61/64 loss: 0.3569852113723755
Batch 62/64 loss: 0.3548946976661682
Batch 63/64 loss: 0.35664886236190796
Batch 64/64 loss: 0.35848671197891235
Epoch 31  Train loss: 0.35575824788972443  Val loss: 0.35821787106622127
Epoch 32
-------------------------------
Batch 1/64 loss: 0.3546069860458374
Batch 2/64 loss: 0.35756146907806396
Batch 3/64 loss: 0.35543811321258545
Batch 4/64 loss: 0.35245203971862793
Batch 5/64 loss: 0.3577601909637451
Batch 6/64 loss: 0.35794776678085327
Batch 7/64 loss: 0.3570222854614258
Batch 8/64 loss: 0.3568580746650696
Batch 9/64 loss: 0.35123950242996216
Batch 10/64 loss: 0.356184720993042
Batch 11/64 loss: 0.35734713077545166
Batch 12/64 loss: 0.3584102988243103
Batch 13/64 loss: 0.3543761968612671
Batch 14/64 loss: 0.35838550329208374
Batch 15/64 loss: 0.35199451446533203
Batch 16/64 loss: 0.35415971279144287
Batch 17/64 loss: 0.3597855567932129
Batch 18/64 loss: 0.3572499752044678
Batch 19/64 loss: 0.3537309765815735
Batch 20/64 loss: 0.3552793860435486
Batch 21/64 loss: 0.3532138466835022
Batch 22/64 loss: 0.357208251953125
Batch 23/64 loss: 0.35753345489501953
Batch 24/64 loss: 0.3582497835159302
Batch 25/64 loss: 0.3558099865913391
Batch 26/64 loss: 0.3553844094276428
Batch 27/64 loss: 0.35558074712753296
Batch 28/64 loss: 0.3553445339202881
Batch 29/64 loss: 0.3558155298233032
Batch 30/64 loss: 0.3559912443161011
Batch 31/64 loss: 0.3524935245513916
Batch 32/64 loss: 0.3528480529785156
Batch 33/64 loss: 0.3559699058532715
Batch 34/64 loss: 0.3557835817337036
Batch 35/64 loss: 0.3586856722831726
Batch 36/64 loss: 0.3543790578842163
Batch 37/64 loss: 0.35485726594924927
Batch 38/64 loss: 0.3566156029701233
Batch 39/64 loss: 0.3546013832092285
Batch 40/64 loss: 0.354070246219635
Batch 41/64 loss: 0.3581562042236328
Batch 42/64 loss: 0.356799840927124
Batch 43/64 loss: 0.3575160503387451
Batch 44/64 loss: 0.3536940813064575
Batch 45/64 loss: 0.3554840087890625
Batch 46/64 loss: 0.35866081714630127
Batch 47/64 loss: 0.3525715470314026
Batch 48/64 loss: 0.35675764083862305
Batch 49/64 loss: 0.3547734022140503
Batch 50/64 loss: 0.355044960975647
Batch 51/64 loss: 0.3578334450721741
Batch 52/64 loss: 0.3587374687194824
Batch 53/64 loss: 0.3537214994430542
Batch 54/64 loss: 0.3540501594543457
Batch 55/64 loss: 0.353715181350708
Batch 56/64 loss: 0.36042553186416626
Batch 57/64 loss: 0.35474860668182373
Batch 58/64 loss: 0.35645341873168945
Batch 59/64 loss: 0.35770219564437866
Batch 60/64 loss: 0.355183482170105
Batch 61/64 loss: 0.35245227813720703
Batch 62/64 loss: 0.35169124603271484
Batch 63/64 loss: 0.3590191602706909
Batch 64/64 loss: 0.3549576997756958
Epoch 32  Train loss: 0.3557590115304087  Val loss: 0.3583039627042423
Epoch 33
-------------------------------
Batch 1/64 loss: 0.35342729091644287
Batch 2/64 loss: 0.35478293895721436
Batch 3/64 loss: 0.3550110459327698
Batch 4/64 loss: 0.35268282890319824
Batch 5/64 loss: 0.3535747528076172
Batch 6/64 loss: 0.3573310375213623
Batch 7/64 loss: 0.35543012619018555
Batch 8/64 loss: 0.35190415382385254
Batch 9/64 loss: 0.35476064682006836
Batch 10/64 loss: 0.35681426525115967
Batch 11/64 loss: 0.35261595249176025
Batch 12/64 loss: 0.3566579222679138
Batch 13/64 loss: 0.35588526725769043
Batch 14/64 loss: 0.35374516248703003
Batch 15/64 loss: 0.35198163986206055
Batch 16/64 loss: 0.3582943081855774
Batch 17/64 loss: 0.35392284393310547
Batch 18/64 loss: 0.3559669852256775
Batch 19/64 loss: 0.3561803102493286
Batch 20/64 loss: 0.35424232482910156
Batch 21/64 loss: 0.35294562578201294
Batch 22/64 loss: 0.3588639497756958
Batch 23/64 loss: 0.35097944736480713
Batch 24/64 loss: 0.3535889983177185
Batch 25/64 loss: 0.3554117679595947
Batch 26/64 loss: 0.35957765579223633
Batch 27/64 loss: 0.3550131320953369
Batch 28/64 loss: 0.35719287395477295
Batch 29/64 loss: 0.35162580013275146
Batch 30/64 loss: 0.3553816080093384
Batch 31/64 loss: 0.35572612285614014
Batch 32/64 loss: 0.35716378688812256
Batch 33/64 loss: 0.35601580142974854
Batch 34/64 loss: 0.3576177954673767
Batch 35/64 loss: 0.35515880584716797
Batch 36/64 loss: 0.35141217708587646
Batch 37/64 loss: 0.3502851724624634
Batch 38/64 loss: 0.35534071922302246
Batch 39/64 loss: 0.35420411825180054
Batch 40/64 loss: 0.35545480251312256
Batch 41/64 loss: 0.3545803427696228
Batch 42/64 loss: 0.35562461614608765
Batch 43/64 loss: 0.35440945625305176
Batch 44/64 loss: 0.35809051990509033
Batch 45/64 loss: 0.3606374263763428
Batch 46/64 loss: 0.3576236367225647
Batch 47/64 loss: 0.35735225677490234
Batch 48/64 loss: 0.3519670367240906
Batch 49/64 loss: 0.35876941680908203
Batch 50/64 loss: 0.3566393256187439
Batch 51/64 loss: 0.3550769090652466
Batch 52/64 loss: 0.35948121547698975
Batch 53/64 loss: 0.35840559005737305
Batch 54/64 loss: 0.35236549377441406
Batch 55/64 loss: 0.35425257682800293
Batch 56/64 loss: 0.35625922679901123
Batch 57/64 loss: 0.35741668939590454
Batch 58/64 loss: 0.3570380210876465
Batch 59/64 loss: 0.3567546606063843
Batch 60/64 loss: 0.35215961933135986
Batch 61/64 loss: 0.35378265380859375
Batch 62/64 loss: 0.3571106195449829
Batch 63/64 loss: 0.35351282358169556
Batch 64/64 loss: 0.3537217378616333
Epoch 33  Train loss: 0.3552748768937354  Val loss: 0.357813025667905
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: 0.3528406023979187
Batch 2/64 loss: 0.35928475856781006
Batch 3/64 loss: 0.3540545105934143
Batch 4/64 loss: 0.3551710247993469
Batch 5/64 loss: 0.35701489448547363
Batch 6/64 loss: 0.35647618770599365
Batch 7/64 loss: 0.3551628589630127
Batch 8/64 loss: 0.3565749526023865
Batch 9/64 loss: 0.351509153842926
Batch 10/64 loss: 0.35601580142974854
Batch 11/64 loss: 0.3567037582397461
Batch 12/64 loss: 0.349942684173584
Batch 13/64 loss: 0.35355937480926514
Batch 14/64 loss: 0.3548351526260376
Batch 15/64 loss: 0.35548222064971924
Batch 16/64 loss: 0.35476136207580566
Batch 17/64 loss: 0.3567603826522827
Batch 18/64 loss: 0.3551110029220581
Batch 19/64 loss: 0.35449427366256714
Batch 20/64 loss: 0.3559858798980713
Batch 21/64 loss: 0.35485678911209106
Batch 22/64 loss: 0.3554654121398926
Batch 23/64 loss: 0.35402870178222656
Batch 24/64 loss: 0.35050201416015625
Batch 25/64 loss: 0.3574948310852051
Batch 26/64 loss: 0.3501729369163513
Batch 27/64 loss: 0.3556203842163086
Batch 28/64 loss: 0.35181117057800293
Batch 29/64 loss: 0.35740047693252563
Batch 30/64 loss: 0.3537421226501465
Batch 31/64 loss: 0.3570859432220459
Batch 32/64 loss: 0.3528222441673279
Batch 33/64 loss: 0.3547934889793396
Batch 34/64 loss: 0.3547786474227905
Batch 35/64 loss: 0.3549278974533081
Batch 36/64 loss: 0.3564324378967285
Batch 37/64 loss: 0.35531485080718994
Batch 38/64 loss: 0.35529595613479614
Batch 39/64 loss: 0.35451817512512207
Batch 40/64 loss: 0.35513806343078613
Batch 41/64 loss: 0.3546290993690491
Batch 42/64 loss: 0.35641801357269287
Batch 43/64 loss: 0.356820285320282
Batch 44/64 loss: 0.35672104358673096
Batch 45/64 loss: 0.35532671213150024
Batch 46/64 loss: 0.35199296474456787
Batch 47/64 loss: 0.3519752621650696
Batch 48/64 loss: 0.3510374426841736
Batch 49/64 loss: 0.35690850019454956
Batch 50/64 loss: 0.3548489809036255
Batch 51/64 loss: 0.351865291595459
Batch 52/64 loss: 0.35437989234924316
Batch 53/64 loss: 0.3543928861618042
Batch 54/64 loss: 0.354330837726593
Batch 55/64 loss: 0.35779476165771484
Batch 56/64 loss: 0.3561199903488159
Batch 57/64 loss: 0.3495628833770752
Batch 58/64 loss: 0.3564029335975647
Batch 59/64 loss: 0.3524874448776245
Batch 60/64 loss: 0.3585299849510193
Batch 61/64 loss: 0.35199403762817383
Batch 62/64 loss: 0.3516886234283447
Batch 63/64 loss: 0.3555110692977905
Batch 64/64 loss: 0.35288006067276
Epoch 34  Train loss: 0.35467203715268303  Val loss: 0.3577429062312411
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: 0.3578979969024658
Batch 2/64 loss: 0.3560086488723755
Batch 3/64 loss: 0.355973482131958
Batch 4/64 loss: 0.34895867109298706
Batch 5/64 loss: 0.3528895378112793
Batch 6/64 loss: 0.35782790184020996
Batch 7/64 loss: 0.3550443649291992
Batch 8/64 loss: 0.35244786739349365
Batch 9/64 loss: 0.3553798198699951
Batch 10/64 loss: 0.35480135679244995
Batch 11/64 loss: 0.3520474433898926
Batch 12/64 loss: 0.3559441566467285
Batch 13/64 loss: 0.353681743144989
Batch 14/64 loss: 0.3519836664199829
Batch 15/64 loss: 0.35338300466537476
Batch 16/64 loss: 0.3551701307296753
Batch 17/64 loss: 0.3506816625595093
Batch 18/64 loss: 0.3567800521850586
Batch 19/64 loss: 0.35317641496658325
Batch 20/64 loss: 0.35367679595947266
Batch 21/64 loss: 0.3575620651245117
Batch 22/64 loss: 0.3560142517089844
Batch 23/64 loss: 0.35695040225982666
Batch 24/64 loss: 0.35911786556243896
Batch 25/64 loss: 0.35272216796875
Batch 26/64 loss: 0.3548735976219177
Batch 27/64 loss: 0.3530811071395874
Batch 28/64 loss: 0.3533055782318115
Batch 29/64 loss: 0.3554341197013855
Batch 30/64 loss: 0.3589280843734741
Batch 31/64 loss: 0.35608816146850586
Batch 32/64 loss: 0.3548774719238281
Batch 33/64 loss: 0.3567264676094055
Batch 34/64 loss: 0.35649967193603516
Batch 35/64 loss: 0.3544456362724304
Batch 36/64 loss: 0.35377073287963867
Batch 37/64 loss: 0.3565142750740051
Batch 38/64 loss: 0.3513789772987366
Batch 39/64 loss: 0.3553926348686218
Batch 40/64 loss: 0.3563196659088135
Batch 41/64 loss: 0.3544588088989258
Batch 42/64 loss: 0.3573724031448364
Batch 43/64 loss: 0.351997435092926
Batch 44/64 loss: 0.35219424962997437
Batch 45/64 loss: 0.35926032066345215
Batch 46/64 loss: 0.3489943742752075
Batch 47/64 loss: 0.3551921844482422
Batch 48/64 loss: 0.3566364049911499
Batch 49/64 loss: 0.3573067784309387
Batch 50/64 loss: 0.35404038429260254
Batch 51/64 loss: 0.35535991191864014
Batch 52/64 loss: 0.35810422897338867
Batch 53/64 loss: 0.3555319309234619
Batch 54/64 loss: 0.35317009687423706
Batch 55/64 loss: 0.3509365916252136
Batch 56/64 loss: 0.34917283058166504
Batch 57/64 loss: 0.35257136821746826
Batch 58/64 loss: 0.35441112518310547
Batch 59/64 loss: 0.35897648334503174
Batch 60/64 loss: 0.35593312978744507
Batch 61/64 loss: 0.35491490364074707
Batch 62/64 loss: 0.35343730449676514
Batch 63/64 loss: 0.34989309310913086
Batch 64/64 loss: 0.35559308528900146
Epoch 35  Train loss: 0.3546716676038854  Val loss: 0.3576739397655238
Saving best model, epoch: 35
Epoch 36
-------------------------------
Batch 1/64 loss: 0.35656797885894775
Batch 2/64 loss: 0.3533153533935547
Batch 3/64 loss: 0.34939950704574585
Batch 4/64 loss: 0.354763388633728
Batch 5/64 loss: 0.35418564081192017
Batch 6/64 loss: 0.3532758951187134
Batch 7/64 loss: 0.35754215717315674
Batch 8/64 loss: 0.3550300598144531
Batch 9/64 loss: 0.3529837131500244
Batch 10/64 loss: 0.3568723201751709
Batch 11/64 loss: 0.3519171476364136
Batch 12/64 loss: 0.35211873054504395
Batch 13/64 loss: 0.35091233253479004
Batch 14/64 loss: 0.35275477170944214
Batch 15/64 loss: 0.352292537689209
Batch 16/64 loss: 0.35403621196746826
Batch 17/64 loss: 0.356390118598938
Batch 18/64 loss: 0.3562058210372925
Batch 19/64 loss: 0.35395723581314087
Batch 20/64 loss: 0.3543294668197632
Batch 21/64 loss: 0.3559147119522095
Batch 22/64 loss: 0.3500617742538452
Batch 23/64 loss: 0.35649538040161133
Batch 24/64 loss: 0.35691124200820923
Batch 25/64 loss: 0.35349583625793457
Batch 26/64 loss: 0.35723841190338135
Batch 27/64 loss: 0.35790109634399414
Batch 28/64 loss: 0.35418999195098877
Batch 29/64 loss: 0.35388994216918945
Batch 30/64 loss: 0.3521360158920288
Batch 31/64 loss: 0.355979859828949
Batch 32/64 loss: 0.35108113288879395
Batch 33/64 loss: 0.35023099184036255
Batch 34/64 loss: 0.35400688648223877
Batch 35/64 loss: 0.3548702597618103
Batch 36/64 loss: 0.3528081178665161
Batch 37/64 loss: 0.3591160774230957
Batch 38/64 loss: 0.35733169317245483
Batch 39/64 loss: 0.35276031494140625
Batch 40/64 loss: 0.3513745665550232
Batch 41/64 loss: 0.35645782947540283
Batch 42/64 loss: 0.35753440856933594
Batch 43/64 loss: 0.35291796922683716
Batch 44/64 loss: 0.35509586334228516
Batch 45/64 loss: 0.35551917552948
Batch 46/64 loss: 0.351513147354126
Batch 47/64 loss: 0.3533145785331726
Batch 48/64 loss: 0.35583609342575073
Batch 49/64 loss: 0.3527601957321167
Batch 50/64 loss: 0.3579058051109314
Batch 51/64 loss: 0.3542957305908203
Batch 52/64 loss: 0.3576561212539673
Batch 53/64 loss: 0.3551466464996338
Batch 54/64 loss: 0.3576691150665283
Batch 55/64 loss: 0.35355180501937866
Batch 56/64 loss: 0.35469627380371094
Batch 57/64 loss: 0.3543599843978882
Batch 58/64 loss: 0.3557695746421814
Batch 59/64 loss: 0.35840916633605957
Batch 60/64 loss: 0.35475867986679077
Batch 61/64 loss: 0.3550609350204468
Batch 62/64 loss: 0.3576012849807739
Batch 63/64 loss: 0.3503350615501404
Batch 64/64 loss: 0.35541832447052
Epoch 36  Train loss: 0.3545313549976723  Val loss: 0.35700522173720944
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 0.35239386558532715
Batch 2/64 loss: 0.3539865016937256
Batch 3/64 loss: 0.3529844284057617
Batch 4/64 loss: 0.35430943965911865
Batch 5/64 loss: 0.35218048095703125
Batch 6/64 loss: 0.3544996976852417
Batch 7/64 loss: 0.352533757686615
Batch 8/64 loss: 0.35456883907318115
Batch 9/64 loss: 0.354552686214447
Batch 10/64 loss: 0.3535432815551758
Batch 11/64 loss: 0.3569011688232422
Batch 12/64 loss: 0.35384947061538696
Batch 13/64 loss: 0.3556786775588989
Batch 14/64 loss: 0.35909879207611084
Batch 15/64 loss: 0.35491931438446045
Batch 16/64 loss: 0.3511713743209839
Batch 17/64 loss: 0.3529951572418213
Batch 18/64 loss: 0.35718369483947754
Batch 19/64 loss: 0.3518833518028259
Batch 20/64 loss: 0.3524024486541748
Batch 21/64 loss: 0.35192734003067017
Batch 22/64 loss: 0.3557388186454773
Batch 23/64 loss: 0.3549466133117676
Batch 24/64 loss: 0.3536555767059326
Batch 25/64 loss: 0.358046293258667
Batch 26/64 loss: 0.352644681930542
Batch 27/64 loss: 0.35142219066619873
Batch 28/64 loss: 0.3506917953491211
Batch 29/64 loss: 0.35079628229141235
Batch 30/64 loss: 0.35543859004974365
Batch 31/64 loss: 0.3532869815826416
Batch 32/64 loss: 0.3553258776664734
Batch 33/64 loss: 0.3556098937988281
Batch 34/64 loss: 0.35456418991088867
Batch 35/64 loss: 0.3560718297958374
Batch 36/64 loss: 0.35777193307876587
Batch 37/64 loss: 0.35349947214126587
Batch 38/64 loss: 0.3575202226638794
Batch 39/64 loss: 0.3556671738624573
Batch 40/64 loss: 0.35501396656036377
Batch 41/64 loss: 0.3526667356491089
Batch 42/64 loss: 0.3577531576156616
Batch 43/64 loss: 0.353859543800354
Batch 44/64 loss: 0.35334789752960205
Batch 45/64 loss: 0.3532547950744629
Batch 46/64 loss: 0.35127782821655273
Batch 47/64 loss: 0.3521692752838135
Batch 48/64 loss: 0.3551182150840759
Batch 49/64 loss: 0.3569508194923401
Batch 50/64 loss: 0.352512001991272
Batch 51/64 loss: 0.3526657819747925
Batch 52/64 loss: 0.35192763805389404
Batch 53/64 loss: 0.35041189193725586
Batch 54/64 loss: 0.35694456100463867
Batch 55/64 loss: 0.3530477285385132
Batch 56/64 loss: 0.3529503345489502
Batch 57/64 loss: 0.3587977886199951
Batch 58/64 loss: 0.35501599311828613
Batch 59/64 loss: 0.3542659282684326
Batch 60/64 loss: 0.3565025329589844
Batch 61/64 loss: 0.35517555475234985
Batch 62/64 loss: 0.3555052876472473
Batch 63/64 loss: 0.35225069522857666
Batch 64/64 loss: 0.35324907302856445
Epoch 37  Train loss: 0.35420525401246317  Val loss: 0.3568016319340447
Saving best model, epoch: 37
Epoch 38
-------------------------------
Batch 1/64 loss: 0.35469233989715576
Batch 2/64 loss: 0.3575444221496582
Batch 3/64 loss: 0.35514676570892334
Batch 4/64 loss: 0.3540722131729126
Batch 5/64 loss: 0.3507930040359497
Batch 6/64 loss: 0.35363930463790894
Batch 7/64 loss: 0.35465019941329956
Batch 8/64 loss: 0.35435837507247925
Batch 9/64 loss: 0.3552038073539734
Batch 10/64 loss: 0.3565976619720459
Batch 11/64 loss: 0.3553093671798706
Batch 12/64 loss: 0.35597938299179077
Batch 13/64 loss: 0.3549346923828125
Batch 14/64 loss: 0.35385847091674805
Batch 15/64 loss: 0.35176903009414673
Batch 16/64 loss: 0.3550206422805786
Batch 17/64 loss: 0.3515269160270691
Batch 18/64 loss: 0.35430908203125
Batch 19/64 loss: 0.3556300401687622
Batch 20/64 loss: 0.3579918146133423
Batch 21/64 loss: 0.35598158836364746
Batch 22/64 loss: 0.3516407012939453
Batch 23/64 loss: 0.35221266746520996
Batch 24/64 loss: 0.355707049369812
Batch 25/64 loss: 0.3527386784553528
Batch 26/64 loss: 0.3519620895385742
Batch 27/64 loss: 0.34945619106292725
Batch 28/64 loss: 0.3526355028152466
Batch 29/64 loss: 0.3545835018157959
Batch 30/64 loss: 0.3544285297393799
Batch 31/64 loss: 0.35321128368377686
Batch 32/64 loss: 0.35245728492736816
Batch 33/64 loss: 0.3570358157157898
Batch 34/64 loss: 0.3527598977088928
Batch 35/64 loss: 0.35291504859924316
Batch 36/64 loss: 0.35250747203826904
Batch 37/64 loss: 0.3587278127670288
Batch 38/64 loss: 0.35334569215774536
Batch 39/64 loss: 0.3543431758880615
Batch 40/64 loss: 0.3531135320663452
Batch 41/64 loss: 0.3516879081726074
Batch 42/64 loss: 0.3531712293624878
Batch 43/64 loss: 0.34924256801605225
Batch 44/64 loss: 0.35319840908050537
Batch 45/64 loss: 0.35176312923431396
Batch 46/64 loss: 0.3556731939315796
Batch 47/64 loss: 0.35764646530151367
Batch 48/64 loss: 0.35150784254074097
Batch 49/64 loss: 0.3553774356842041
Batch 50/64 loss: 0.35205578804016113
Batch 51/64 loss: 0.35779476165771484
Batch 52/64 loss: 0.3546754717826843
Batch 53/64 loss: 0.3533642292022705
Batch 54/64 loss: 0.35423219203948975
Batch 55/64 loss: 0.35356199741363525
Batch 56/64 loss: 0.3556615114212036
Batch 57/64 loss: 0.3573960065841675
Batch 58/64 loss: 0.35316139459609985
Batch 59/64 loss: 0.3580896854400635
Batch 60/64 loss: 0.35090118646621704
Batch 61/64 loss: 0.35222113132476807
Batch 62/64 loss: 0.35274314880371094
Batch 63/64 loss: 0.35081326961517334
Batch 64/64 loss: 0.351539671421051
Epoch 38  Train loss: 0.3539511491270626  Val loss: 0.35618996947901355
Saving best model, epoch: 38
Epoch 39
-------------------------------
Batch 1/64 loss: 0.3539386987686157
Batch 2/64 loss: 0.352123498916626
Batch 3/64 loss: 0.35819119215011597
Batch 4/64 loss: 0.35061943531036377
Batch 5/64 loss: 0.3531450629234314
Batch 6/64 loss: 0.3541910648345947
Batch 7/64 loss: 0.3520506024360657
Batch 8/64 loss: 0.3541107773780823
Batch 9/64 loss: 0.3578503727912903
Batch 10/64 loss: 0.35455405712127686
Batch 11/64 loss: 0.3541589379310608
Batch 12/64 loss: 0.35211431980133057
Batch 13/64 loss: 0.35434746742248535
Batch 14/64 loss: 0.3515981435775757
Batch 15/64 loss: 0.35279470682144165
Batch 16/64 loss: 0.3548293113708496
Batch 17/64 loss: 0.35626113414764404
Batch 18/64 loss: 0.35612738132476807
Batch 19/64 loss: 0.35326969623565674
Batch 20/64 loss: 0.3547576069831848
Batch 21/64 loss: 0.3566180467605591
Batch 22/64 loss: 0.35466182231903076
Batch 23/64 loss: 0.3530759811401367
Batch 24/64 loss: 0.35513949394226074
Batch 25/64 loss: 0.35174453258514404
Batch 26/64 loss: 0.35440361499786377
Batch 27/64 loss: 0.3544654846191406
Batch 28/64 loss: 0.3534266948699951
Batch 29/64 loss: 0.35202622413635254
Batch 30/64 loss: 0.3523305654525757
Batch 31/64 loss: 0.3539416790008545
Batch 32/64 loss: 0.3531543016433716
Batch 33/64 loss: 0.35383182764053345
Batch 34/64 loss: 0.35663115978240967
Batch 35/64 loss: 0.3551309108734131
Batch 36/64 loss: 0.3492181897163391
Batch 37/64 loss: 0.35334551334381104
Batch 38/64 loss: 0.3542611598968506
Batch 39/64 loss: 0.3545982837677002
Batch 40/64 loss: 0.3559413552284241
Batch 41/64 loss: 0.35343557596206665
Batch 42/64 loss: 0.3485492467880249
Batch 43/64 loss: 0.35600435733795166
Batch 44/64 loss: 0.3546876907348633
Batch 45/64 loss: 0.359413743019104
Batch 46/64 loss: 0.35429292917251587
Batch 47/64 loss: 0.35257261991500854
Batch 48/64 loss: 0.3539503812789917
Batch 49/64 loss: 0.35627782344818115
Batch 50/64 loss: 0.35162562131881714
Batch 51/64 loss: 0.3534306287765503
Batch 52/64 loss: 0.3543283939361572
Batch 53/64 loss: 0.35560691356658936
Batch 54/64 loss: 0.35483062267303467
Batch 55/64 loss: 0.34998440742492676
Batch 56/64 loss: 0.3563504219055176
Batch 57/64 loss: 0.35410529375076294
Batch 58/64 loss: 0.353635311126709
Batch 59/64 loss: 0.3524867296218872
Batch 60/64 loss: 0.35304903984069824
Batch 61/64 loss: 0.35320067405700684
Batch 62/64 loss: 0.3516373634338379
Batch 63/64 loss: 0.35492777824401855
Batch 64/64 loss: 0.3558845520019531
Epoch 39  Train loss: 0.35394944770663395  Val loss: 0.35770015864028143
Epoch 40
-------------------------------
Batch 1/64 loss: 0.3551139831542969
Batch 2/64 loss: 0.35132813453674316
Batch 3/64 loss: 0.35538190603256226
Batch 4/64 loss: 0.35141462087631226
Batch 5/64 loss: 0.35387182235717773
Batch 6/64 loss: 0.35278797149658203
Batch 7/64 loss: 0.3503808379173279
Batch 8/64 loss: 0.35505998134613037
Batch 9/64 loss: 0.35431182384490967
Batch 10/64 loss: 0.35384416580200195
Batch 11/64 loss: 0.35466527938842773
Batch 12/64 loss: 0.3527120351791382
Batch 13/64 loss: 0.3529607653617859
Batch 14/64 loss: 0.3561352491378784
Batch 15/64 loss: 0.35409820079803467
Batch 16/64 loss: 0.3538479804992676
Batch 17/64 loss: 0.3523677587509155
Batch 18/64 loss: 0.3577989935874939
Batch 19/64 loss: 0.35427606105804443
Batch 20/64 loss: 0.3550935983657837
Batch 21/64 loss: 0.3495561480522156
Batch 22/64 loss: 0.35393035411834717
Batch 23/64 loss: 0.35644882917404175
Batch 24/64 loss: 0.35365623235702515
Batch 25/64 loss: 0.35664844512939453
Batch 26/64 loss: 0.3513947129249573
Batch 27/64 loss: 0.35635852813720703
Batch 28/64 loss: 0.3510831594467163
Batch 29/64 loss: 0.35377615690231323
Batch 30/64 loss: 0.3577152490615845
Batch 31/64 loss: 0.35231077671051025
Batch 32/64 loss: 0.35232698917388916
Batch 33/64 loss: 0.35562098026275635
Batch 34/64 loss: 0.35497725009918213
Batch 35/64 loss: 0.3513737916946411
Batch 36/64 loss: 0.35272711515426636
Batch 37/64 loss: 0.3552319407463074
Batch 38/64 loss: 0.35533463954925537
Batch 39/64 loss: 0.35709190368652344
Batch 40/64 loss: 0.35515475273132324
Batch 41/64 loss: 0.35445141792297363
Batch 42/64 loss: 0.35712242126464844
Batch 43/64 loss: 0.3496062755584717
Batch 44/64 loss: 0.35083717107772827
Batch 45/64 loss: 0.3531147241592407
Batch 46/64 loss: 0.35649824142456055
Batch 47/64 loss: 0.3537546992301941
Batch 48/64 loss: 0.3563442826271057
Batch 49/64 loss: 0.3545222282409668
Batch 50/64 loss: 0.35514187812805176
Batch 51/64 loss: 0.3561445474624634
Batch 52/64 loss: 0.35462188720703125
Batch 53/64 loss: 0.3525702953338623
Batch 54/64 loss: 0.35277259349823
Batch 55/64 loss: 0.3554614186286926
Batch 56/64 loss: 0.3541671633720398
Batch 57/64 loss: 0.3517303466796875
Batch 58/64 loss: 0.35518085956573486
Batch 59/64 loss: 0.3565864562988281
Batch 60/64 loss: 0.353623628616333
Batch 61/64 loss: 0.3573873043060303
Batch 62/64 loss: 0.35509371757507324
Batch 63/64 loss: 0.3550146818161011
Batch 64/64 loss: 0.35527563095092773
Epoch 40  Train loss: 0.35417057392643947  Val loss: 0.35764048967984124
Epoch 41
-------------------------------
Batch 1/64 loss: 0.35219669342041016
Batch 2/64 loss: 0.35632503032684326
Batch 3/64 loss: 0.3558347821235657
Batch 4/64 loss: 0.3536115884780884
Batch 5/64 loss: 0.35515087842941284
Batch 6/64 loss: 0.35335463285446167
Batch 7/64 loss: 0.35692572593688965
Batch 8/64 loss: 0.3552013635635376
Batch 9/64 loss: 0.3507121205329895
Batch 10/64 loss: 0.3548088073730469
Batch 11/64 loss: 0.3507208824157715
Batch 12/64 loss: 0.3576664328575134
Batch 13/64 loss: 0.35361289978027344
Batch 14/64 loss: 0.3536158800125122
Batch 15/64 loss: 0.35337990522384644
Batch 16/64 loss: 0.3541980981826782
Batch 17/64 loss: 0.35494816303253174
Batch 18/64 loss: 0.35233062505722046
Batch 19/64 loss: 0.35393399000167847
Batch 20/64 loss: 0.3508385419845581
Batch 21/64 loss: 0.35473084449768066
Batch 22/64 loss: 0.3503572940826416
Batch 23/64 loss: 0.3525964021682739
Batch 24/64 loss: 0.35696375370025635
Batch 25/64 loss: 0.3516596555709839
Batch 26/64 loss: 0.3567344546318054
Batch 27/64 loss: 0.3489973545074463
Batch 28/64 loss: 0.3517758846282959
Batch 29/64 loss: 0.35390496253967285
Batch 30/64 loss: 0.3555600047111511
Batch 31/64 loss: 0.3516489863395691
Batch 32/64 loss: 0.3513756990432739
Batch 33/64 loss: 0.35358142852783203
Batch 34/64 loss: 0.35118210315704346
Batch 35/64 loss: 0.351689875125885
Batch 36/64 loss: 0.35170871019363403
Batch 37/64 loss: 0.351642370223999
Batch 38/64 loss: 0.35632503032684326
Batch 39/64 loss: 0.3553372025489807
Batch 40/64 loss: 0.34919798374176025
Batch 41/64 loss: 0.35715365409851074
Batch 42/64 loss: 0.35314828157424927
Batch 43/64 loss: 0.3559519052505493
Batch 44/64 loss: 0.35180163383483887
Batch 45/64 loss: 0.3531830310821533
Batch 46/64 loss: 0.35332679748535156
Batch 47/64 loss: 0.35330188274383545
Batch 48/64 loss: 0.3563159108161926
Batch 49/64 loss: 0.3551652431488037
Batch 50/64 loss: 0.35560721158981323
Batch 51/64 loss: 0.3533332347869873
Batch 52/64 loss: 0.3521939516067505
Batch 53/64 loss: 0.3537888526916504
Batch 54/64 loss: 0.3531641364097595
Batch 55/64 loss: 0.354445219039917
Batch 56/64 loss: 0.3543342351913452
Batch 57/64 loss: 0.3484436273574829
Batch 58/64 loss: 0.3550366163253784
Batch 59/64 loss: 0.35488367080688477
Batch 60/64 loss: 0.3567643165588379
Batch 61/64 loss: 0.35196226835250854
Batch 62/64 loss: 0.35088682174682617
Batch 63/64 loss: 0.3537660837173462
Batch 64/64 loss: 0.35412275791168213
Epoch 41  Train loss: 0.353566865827523  Val loss: 0.35668933883155746
Epoch 42
-------------------------------
Batch 1/64 loss: 0.3513869643211365
Batch 2/64 loss: 0.3570749759674072
Batch 3/64 loss: 0.3565217852592468
Batch 4/64 loss: 0.3565875291824341
Batch 5/64 loss: 0.3511001467704773
Batch 6/64 loss: 0.35146260261535645
Batch 7/64 loss: 0.3495391011238098
Batch 8/64 loss: 0.35345888137817383
Batch 9/64 loss: 0.3515728712081909
Batch 10/64 loss: 0.3557615280151367
Batch 11/64 loss: 0.3519619107246399
Batch 12/64 loss: 0.35063695907592773
Batch 13/64 loss: 0.35523152351379395
Batch 14/64 loss: 0.35119539499282837
Batch 15/64 loss: 0.3517622947692871
Batch 16/64 loss: 0.35755038261413574
Batch 17/64 loss: 0.3531031608581543
Batch 18/64 loss: 0.3544495701789856
Batch 19/64 loss: 0.3561556935310364
Batch 20/64 loss: 0.35377103090286255
Batch 21/64 loss: 0.3508363962173462
Batch 22/64 loss: 0.3539513349533081
Batch 23/64 loss: 0.35155153274536133
Batch 24/64 loss: 0.35593414306640625
Batch 25/64 loss: 0.3568337559700012
Batch 26/64 loss: 0.3565137982368469
Batch 27/64 loss: 0.35621535778045654
Batch 28/64 loss: 0.35273492336273193
Batch 29/64 loss: 0.3540470004081726
Batch 30/64 loss: 0.35300755500793457
Batch 31/64 loss: 0.35439038276672363
Batch 32/64 loss: 0.35737472772598267
Batch 33/64 loss: 0.35801005363464355
Batch 34/64 loss: 0.35414350032806396
Batch 35/64 loss: 0.3490191698074341
Batch 36/64 loss: 0.35514193773269653
Batch 37/64 loss: 0.35309290885925293
Batch 38/64 loss: 0.353884756565094
Batch 39/64 loss: 0.349612832069397
Batch 40/64 loss: 0.35609549283981323
Batch 41/64 loss: 0.3539459705352783
Batch 42/64 loss: 0.35519087314605713
Batch 43/64 loss: 0.353837251663208
Batch 44/64 loss: 0.3530595302581787
Batch 45/64 loss: 0.3539358377456665
Batch 46/64 loss: 0.3582417368888855
Batch 47/64 loss: 0.35383546352386475
Batch 48/64 loss: 0.3524430990219116
Batch 49/64 loss: 0.35258328914642334
Batch 50/64 loss: 0.35482096672058105
Batch 51/64 loss: 0.3523324728012085
Batch 52/64 loss: 0.3556479215621948
Batch 53/64 loss: 0.3534008264541626
Batch 54/64 loss: 0.3523498773574829
Batch 55/64 loss: 0.35244178771972656
Batch 56/64 loss: 0.3510335683822632
Batch 57/64 loss: 0.3552033305168152
Batch 58/64 loss: 0.35227692127227783
Batch 59/64 loss: 0.35232317447662354
Batch 60/64 loss: 0.3538705110549927
Batch 61/64 loss: 0.35316842794418335
Batch 62/64 loss: 0.3502235412597656
Batch 63/64 loss: 0.3500378727912903
Batch 64/64 loss: 0.3568391799926758
Epoch 42  Train loss: 0.35367073732263904  Val loss: 0.3565828906711434
Epoch 43
-------------------------------
Batch 1/64 loss: 0.3512125611305237
Batch 2/64 loss: 0.35561978816986084
Batch 3/64 loss: 0.34901976585388184
Batch 4/64 loss: 0.35046350955963135
Batch 5/64 loss: 0.35492998361587524
Batch 6/64 loss: 0.35222142934799194
Batch 7/64 loss: 0.3523182272911072
Batch 8/64 loss: 0.35594427585601807
Batch 9/64 loss: 0.3514406681060791
Batch 10/64 loss: 0.3492366075515747
Batch 11/64 loss: 0.35286617279052734
Batch 12/64 loss: 0.35270780324935913
Batch 13/64 loss: 0.35646700859069824
Batch 14/64 loss: 0.35793882608413696
Batch 15/64 loss: 0.3533637523651123
Batch 16/64 loss: 0.3521711826324463
Batch 17/64 loss: 0.35632264614105225
Batch 18/64 loss: 0.34814751148223877
Batch 19/64 loss: 0.3527868986129761
Batch 20/64 loss: 0.35169148445129395
Batch 21/64 loss: 0.3548349142074585
Batch 22/64 loss: 0.35345184803009033
Batch 23/64 loss: 0.3532581329345703
Batch 24/64 loss: 0.352677583694458
Batch 25/64 loss: 0.35662841796875
Batch 26/64 loss: 0.35635673999786377
Batch 27/64 loss: 0.35629117488861084
Batch 28/64 loss: 0.35318315029144287
Batch 29/64 loss: 0.35614705085754395
Batch 30/64 loss: 0.3558751344680786
Batch 31/64 loss: 0.3529926538467407
Batch 32/64 loss: 0.35501033067703247
Batch 33/64 loss: 0.352912962436676
Batch 34/64 loss: 0.3599240779876709
Batch 35/64 loss: 0.35330140590667725
Batch 36/64 loss: 0.3498932123184204
Batch 37/64 loss: 0.3525090217590332
Batch 38/64 loss: 0.35132795572280884
Batch 39/64 loss: 0.3516911268234253
Batch 40/64 loss: 0.35254818201065063
Batch 41/64 loss: 0.3498991131782532
Batch 42/64 loss: 0.3571593761444092
Batch 43/64 loss: 0.3518710732460022
Batch 44/64 loss: 0.3591751456260681
Batch 45/64 loss: 0.35308021306991577
Batch 46/64 loss: 0.35274529457092285
Batch 47/64 loss: 0.3524191975593567
Batch 48/64 loss: 0.35657715797424316
Batch 49/64 loss: 0.35009491443634033
Batch 50/64 loss: 0.3514212369918823
Batch 51/64 loss: 0.3539271354675293
Batch 52/64 loss: 0.3524463176727295
Batch 53/64 loss: 0.35231107473373413
Batch 54/64 loss: 0.35100120306015015
Batch 55/64 loss: 0.35105907917022705
Batch 56/64 loss: 0.3520057201385498
Batch 57/64 loss: 0.35137683153152466
Batch 58/64 loss: 0.3501163721084595
Batch 59/64 loss: 0.35247278213500977
Batch 60/64 loss: 0.3550499677658081
Batch 61/64 loss: 0.35194915533065796
Batch 62/64 loss: 0.3523714542388916
Batch 63/64 loss: 0.35490548610687256
Batch 64/64 loss: 0.34963876008987427
Epoch 43  Train loss: 0.35318195375741696  Val loss: 0.3569882659568
Epoch 44
-------------------------------
Batch 1/64 loss: 0.3489305377006531
Batch 2/64 loss: 0.35248327255249023
Batch 3/64 loss: 0.3569380044937134
Batch 4/64 loss: 0.35251080989837646
Batch 5/64 loss: 0.35386133193969727
Batch 6/64 loss: 0.35258376598358154
Batch 7/64 loss: 0.3531290888786316
Batch 8/64 loss: 0.3509014844894409
Batch 9/64 loss: 0.35228538513183594
Batch 10/64 loss: 0.3520274758338928
Batch 11/64 loss: 0.35448741912841797
Batch 12/64 loss: 0.3564035892486572
Batch 13/64 loss: 0.3526318073272705
Batch 14/64 loss: 0.35171663761138916
Batch 15/64 loss: 0.3543182611465454
Batch 16/64 loss: 0.3546156883239746
Batch 17/64 loss: 0.356900691986084
Batch 18/64 loss: 0.3526308536529541
Batch 19/64 loss: 0.35149919986724854
Batch 20/64 loss: 0.356376051902771
Batch 21/64 loss: 0.3551802635192871
Batch 22/64 loss: 0.352971613407135
Batch 23/64 loss: 0.35297679901123047
Batch 24/64 loss: 0.35119110345840454
Batch 25/64 loss: 0.3521057367324829
Batch 26/64 loss: 0.35300564765930176
Batch 27/64 loss: 0.3537520170211792
Batch 28/64 loss: 0.3534337282180786
Batch 29/64 loss: 0.3547811508178711
Batch 30/64 loss: 0.352123498916626
Batch 31/64 loss: 0.35473722219467163
Batch 32/64 loss: 0.3514537215232849
Batch 33/64 loss: 0.36055755615234375
Batch 34/64 loss: 0.3541884422302246
Batch 35/64 loss: 0.3537752032279968
Batch 36/64 loss: 0.35468101501464844
Batch 37/64 loss: 0.35551583766937256
Batch 38/64 loss: 0.35123056173324585
Batch 39/64 loss: 0.3513251543045044
Batch 40/64 loss: 0.3538097143173218
Batch 41/64 loss: 0.3533565402030945
Batch 42/64 loss: 0.3522335886955261
Batch 43/64 loss: 0.35170912742614746
Batch 44/64 loss: 0.3549523949623108
Batch 45/64 loss: 0.35288476943969727
Batch 46/64 loss: 0.34679746627807617
Batch 47/64 loss: 0.35196453332901
Batch 48/64 loss: 0.35228466987609863
Batch 49/64 loss: 0.357144296169281
Batch 50/64 loss: 0.3577779531478882
Batch 51/64 loss: 0.35343360900878906
Batch 52/64 loss: 0.3502712845802307
Batch 53/64 loss: 0.35400301218032837
Batch 54/64 loss: 0.34915781021118164
Batch 55/64 loss: 0.35267239809036255
Batch 56/64 loss: 0.35228025913238525
Batch 57/64 loss: 0.35419851541519165
Batch 58/64 loss: 0.34990572929382324
Batch 59/64 loss: 0.3507685661315918
Batch 60/64 loss: 0.3514838218688965
Batch 61/64 loss: 0.3491189479827881
Batch 62/64 loss: 0.352988600730896
Batch 63/64 loss: 0.35706627368927
Batch 64/64 loss: 0.34694790840148926
Epoch 44  Train loss: 0.3530775285234638  Val loss: 0.35599070111500847
Saving best model, epoch: 44
Epoch 45
-------------------------------
Batch 1/64 loss: 0.3554497957229614
Batch 2/64 loss: 0.3509379029273987
Batch 3/64 loss: 0.34905892610549927
Batch 4/64 loss: 0.35391974449157715
Batch 5/64 loss: 0.3504817485809326
Batch 6/64 loss: 0.35237354040145874
Batch 7/64 loss: 0.35490477085113525
Batch 8/64 loss: 0.3510175943374634
Batch 9/64 loss: 0.3464846611022949
Batch 10/64 loss: 0.34877192974090576
Batch 11/64 loss: 0.3538200855255127
Batch 12/64 loss: 0.352597713470459
Batch 13/64 loss: 0.3543851375579834
Batch 14/64 loss: 0.35011959075927734
Batch 15/64 loss: 0.3522747755050659
Batch 16/64 loss: 0.35334908962249756
Batch 17/64 loss: 0.3540548086166382
Batch 18/64 loss: 0.35127711296081543
Batch 19/64 loss: 0.3528646230697632
Batch 20/64 loss: 0.35294783115386963
Batch 21/64 loss: 0.35539889335632324
Batch 22/64 loss: 0.3496319651603699
Batch 23/64 loss: 0.35214048624038696
Batch 24/64 loss: 0.349793016910553
Batch 25/64 loss: 0.35213446617126465
Batch 26/64 loss: 0.35181015729904175
Batch 27/64 loss: 0.3481557369232178
Batch 28/64 loss: 0.3546426296234131
Batch 29/64 loss: 0.355266809463501
Batch 30/64 loss: 0.3544938564300537
Batch 31/64 loss: 0.3581092357635498
Batch 32/64 loss: 0.3534494638442993
Batch 33/64 loss: 0.35241401195526123
Batch 34/64 loss: 0.3558780550956726
Batch 35/64 loss: 0.3571273684501648
Batch 36/64 loss: 0.35164040327072144
Batch 37/64 loss: 0.353903591632843
Batch 38/64 loss: 0.35231614112854004
Batch 39/64 loss: 0.35598617792129517
Batch 40/64 loss: 0.351767897605896
Batch 41/64 loss: 0.35442137718200684
Batch 42/64 loss: 0.3526597023010254
Batch 43/64 loss: 0.35653698444366455
Batch 44/64 loss: 0.35137420892715454
Batch 45/64 loss: 0.3524996042251587
Batch 46/64 loss: 0.35195356607437134
Batch 47/64 loss: 0.35627007484436035
Batch 48/64 loss: 0.35048460960388184
Batch 49/64 loss: 0.35513174533843994
Batch 50/64 loss: 0.3511972427368164
Batch 51/64 loss: 0.3537970781326294
Batch 52/64 loss: 0.35661762952804565
Batch 53/64 loss: 0.3546525239944458
Batch 54/64 loss: 0.3524559736251831
Batch 55/64 loss: 0.3472835421562195
Batch 56/64 loss: 0.35011184215545654
Batch 57/64 loss: 0.3499103784561157
Batch 58/64 loss: 0.35413360595703125
Batch 59/64 loss: 0.3526604175567627
Batch 60/64 loss: 0.3538621664047241
Batch 61/64 loss: 0.35866808891296387
Batch 62/64 loss: 0.3524562120437622
Batch 63/64 loss: 0.34907251596450806
Batch 64/64 loss: 0.35583770275115967
Epoch 45  Train loss: 0.352819468460831  Val loss: 0.35557039722134565
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: 0.3554956912994385
Batch 2/64 loss: 0.3520282506942749
Batch 3/64 loss: 0.35271120071411133
Batch 4/64 loss: 0.3511871099472046
Batch 5/64 loss: 0.3541439175605774
Batch 6/64 loss: 0.35103321075439453
Batch 7/64 loss: 0.34877848625183105
Batch 8/64 loss: 0.3536643981933594
Batch 9/64 loss: 0.35301244258880615
Batch 10/64 loss: 0.3496243357658386
Batch 11/64 loss: 0.35233449935913086
Batch 12/64 loss: 0.3516783118247986
Batch 13/64 loss: 0.35027962923049927
Batch 14/64 loss: 0.350622296333313
Batch 15/64 loss: 0.3546178340911865
Batch 16/64 loss: 0.35267317295074463
Batch 17/64 loss: 0.35355299711227417
Batch 18/64 loss: 0.35486024618148804
Batch 19/64 loss: 0.3526124358177185
Batch 20/64 loss: 0.35085684061050415
Batch 21/64 loss: 0.3532700538635254
Batch 22/64 loss: 0.35442882776260376
Batch 23/64 loss: 0.35020923614501953
Batch 24/64 loss: 0.3535747528076172
Batch 25/64 loss: 0.3520456552505493
Batch 26/64 loss: 0.3530237078666687
Batch 27/64 loss: 0.35044431686401367
Batch 28/64 loss: 0.3495105504989624
Batch 29/64 loss: 0.3534867763519287
Batch 30/64 loss: 0.3535473346710205
Batch 31/64 loss: 0.35396015644073486
Batch 32/64 loss: 0.3543708324432373
Batch 33/64 loss: 0.35492122173309326
Batch 34/64 loss: 0.3513433337211609
Batch 35/64 loss: 0.3552815914154053
Batch 36/64 loss: 0.3520064353942871
Batch 37/64 loss: 0.3487735390663147
Batch 38/64 loss: 0.3520016670227051
Batch 39/64 loss: 0.3502594232559204
Batch 40/64 loss: 0.35516417026519775
Batch 41/64 loss: 0.35102200508117676
Batch 42/64 loss: 0.3565073609352112
Batch 43/64 loss: 0.3536348342895508
Batch 44/64 loss: 0.34934115409851074
Batch 45/64 loss: 0.3515768051147461
Batch 46/64 loss: 0.35086899995803833
Batch 47/64 loss: 0.3531029224395752
Batch 48/64 loss: 0.35169368982315063
Batch 49/64 loss: 0.3538789749145508
Batch 50/64 loss: 0.3533007502555847
Batch 51/64 loss: 0.35406410694122314
Batch 52/64 loss: 0.35056567192077637
Batch 53/64 loss: 0.3536377549171448
Batch 54/64 loss: 0.35241830348968506
Batch 55/64 loss: 0.3543100357055664
Batch 56/64 loss: 0.35250526666641235
Batch 57/64 loss: 0.3585777282714844
Batch 58/64 loss: 0.35239458084106445
Batch 59/64 loss: 0.3504266142845154
Batch 60/64 loss: 0.35048383474349976
Batch 61/64 loss: 0.3537518382072449
Batch 62/64 loss: 0.3528549075126648
Batch 63/64 loss: 0.3539840579032898
Batch 64/64 loss: 0.3512558937072754
Epoch 46  Train loss: 0.35256054915633855  Val loss: 0.35462497272032645
Saving best model, epoch: 46
Epoch 47
-------------------------------
Batch 1/64 loss: 0.35123634338378906
Batch 2/64 loss: 0.35569411516189575
Batch 3/64 loss: 0.3522099256515503
Batch 4/64 loss: 0.35235655307769775
Batch 5/64 loss: 0.35538262128829956
Batch 6/64 loss: 0.3487139940261841
Batch 7/64 loss: 0.3533250093460083
Batch 8/64 loss: 0.3498852252960205
Batch 9/64 loss: 0.3474050760269165
Batch 10/64 loss: 0.3532434105873108
Batch 11/64 loss: 0.3526933193206787
Batch 12/64 loss: 0.3515191674232483
Batch 13/64 loss: 0.35077404975891113
Batch 14/64 loss: 0.35393965244293213
Batch 15/64 loss: 0.3512253761291504
Batch 16/64 loss: 0.34627723693847656
Batch 17/64 loss: 0.35140806436538696
Batch 18/64 loss: 0.354050874710083
Batch 19/64 loss: 0.35259079933166504
Batch 20/64 loss: 0.35411500930786133
Batch 21/64 loss: 0.34886837005615234
Batch 22/64 loss: 0.3522452116012573
Batch 23/64 loss: 0.3547840118408203
Batch 24/64 loss: 0.34918761253356934
Batch 25/64 loss: 0.3561944365501404
Batch 26/64 loss: 0.353726863861084
Batch 27/64 loss: 0.34632670879364014
Batch 28/64 loss: 0.34945619106292725
Batch 29/64 loss: 0.35379791259765625
Batch 30/64 loss: 0.3517288565635681
Batch 31/64 loss: 0.35153061151504517
Batch 32/64 loss: 0.3534277081489563
Batch 33/64 loss: 0.35138559341430664
Batch 34/64 loss: 0.3530927300453186
Batch 35/64 loss: 0.3487999439239502
Batch 36/64 loss: 0.35582631826400757
Batch 37/64 loss: 0.3512364625930786
Batch 38/64 loss: 0.3503406047821045
Batch 39/64 loss: 0.35193300247192383
Batch 40/64 loss: 0.3535226583480835
Batch 41/64 loss: 0.3511069416999817
Batch 42/64 loss: 0.35002368688583374
Batch 43/64 loss: 0.34817254543304443
Batch 44/64 loss: 0.3481830358505249
Batch 45/64 loss: 0.3540455102920532
Batch 46/64 loss: 0.35806500911712646
Batch 47/64 loss: 0.356134295463562
Batch 48/64 loss: 0.3561197519302368
Batch 49/64 loss: 0.34898823499679565
Batch 50/64 loss: 0.34918123483657837
Batch 51/64 loss: 0.35419762134552
Batch 52/64 loss: 0.3539031744003296
Batch 53/64 loss: 0.3558892011642456
Batch 54/64 loss: 0.35639166831970215
Batch 55/64 loss: 0.35717475414276123
Batch 56/64 loss: 0.3534284830093384
Batch 57/64 loss: 0.3538493514060974
Batch 58/64 loss: 0.35514044761657715
Batch 59/64 loss: 0.3479211926460266
Batch 60/64 loss: 0.3548371195793152
Batch 61/64 loss: 0.35446012020111084
Batch 62/64 loss: 0.35295480489730835
Batch 63/64 loss: 0.351926326751709
Batch 64/64 loss: 0.351179838180542
Epoch 47  Train loss: 0.3523284238927505  Val loss: 0.35552611281372015
Epoch 48
-------------------------------
Batch 1/64 loss: 0.35176175832748413
Batch 2/64 loss: 0.3550405502319336
Batch 3/64 loss: 0.3574281930923462
Batch 4/64 loss: 0.3490767478942871
Batch 5/64 loss: 0.3534378409385681
Batch 6/64 loss: 0.35322993993759155
Batch 7/64 loss: 0.35297060012817383
Batch 8/64 loss: 0.35397160053253174
Batch 9/64 loss: 0.35028040409088135
Batch 10/64 loss: 0.3540779948234558
Batch 11/64 loss: 0.34922146797180176
Batch 12/64 loss: 0.3512701988220215
Batch 13/64 loss: 0.348716139793396
Batch 14/64 loss: 0.3541608452796936
Batch 15/64 loss: 0.35739368200302124
Batch 16/64 loss: 0.35119426250457764
Batch 17/64 loss: 0.3513926863670349
Batch 18/64 loss: 0.35445982217788696
Batch 19/64 loss: 0.3511568307876587
Batch 20/64 loss: 0.3482247591018677
Batch 21/64 loss: 0.3536161184310913
Batch 22/64 loss: 0.35229766368865967
Batch 23/64 loss: 0.35357344150543213
Batch 24/64 loss: 0.3540405035018921
Batch 25/64 loss: 0.3549458384513855
Batch 26/64 loss: 0.3551582098007202
Batch 27/64 loss: 0.3561742305755615
Batch 28/64 loss: 0.3509991765022278
Batch 29/64 loss: 0.3485269546508789
Batch 30/64 loss: 0.3540022373199463
Batch 31/64 loss: 0.3500659465789795
Batch 32/64 loss: 0.3494303822517395
Batch 33/64 loss: 0.35490572452545166
Batch 34/64 loss: 0.3559004068374634
Batch 35/64 loss: 0.3534497022628784
Batch 36/64 loss: 0.34874290227890015
Batch 37/64 loss: 0.351923406124115
Batch 38/64 loss: 0.35136914253234863
Batch 39/64 loss: 0.3548710346221924
Batch 40/64 loss: 0.3532572388648987
Batch 41/64 loss: 0.35128724575042725
Batch 42/64 loss: 0.35002362728118896
Batch 43/64 loss: 0.3586062788963318
Batch 44/64 loss: 0.3514865040779114
Batch 45/64 loss: 0.35217446088790894
Batch 46/64 loss: 0.3546891212463379
Batch 47/64 loss: 0.34906333684921265
Batch 48/64 loss: 0.3519917130470276
Batch 49/64 loss: 0.35126811265945435
Batch 50/64 loss: 0.353664755821228
Batch 51/64 loss: 0.35464972257614136
Batch 52/64 loss: 0.3525322675704956
Batch 53/64 loss: 0.35475480556488037
Batch 54/64 loss: 0.3483694791793823
Batch 55/64 loss: 0.3514179587364197
Batch 56/64 loss: 0.35127270221710205
Batch 57/64 loss: 0.3517574071884155
Batch 58/64 loss: 0.3520625829696655
Batch 59/64 loss: 0.35014861822128296
Batch 60/64 loss: 0.35011017322540283
Batch 61/64 loss: 0.3526034951210022
Batch 62/64 loss: 0.34977173805236816
Batch 63/64 loss: 0.34980809688568115
Batch 64/64 loss: 0.3524230122566223
Epoch 48  Train loss: 0.35236938116597194  Val loss: 0.3551899805101742
Epoch 49
-------------------------------
Batch 1/64 loss: 0.35386866331100464
Batch 2/64 loss: 0.348327100276947
Batch 3/64 loss: 0.352638840675354
Batch 4/64 loss: 0.3481241464614868
Batch 5/64 loss: 0.35668396949768066
Batch 6/64 loss: 0.3500286340713501
Batch 7/64 loss: 0.35159754753112793
Batch 8/64 loss: 0.35229671001434326
Batch 9/64 loss: 0.353582501411438
Batch 10/64 loss: 0.35126936435699463
Batch 11/64 loss: 0.3486964702606201
Batch 12/64 loss: 0.3529590964317322
Batch 13/64 loss: 0.35463953018188477
Batch 14/64 loss: 0.35252809524536133
Batch 15/64 loss: 0.3513132333755493
Batch 16/64 loss: 0.35310089588165283
Batch 17/64 loss: 0.35420382022857666
Batch 18/64 loss: 0.35232555866241455
Batch 19/64 loss: 0.3507571220397949
Batch 20/64 loss: 0.3489183783531189
Batch 21/64 loss: 0.35050636529922485
Batch 22/64 loss: 0.3517880439758301
Batch 23/64 loss: 0.3542194962501526
Batch 24/64 loss: 0.3521285057067871
Batch 25/64 loss: 0.354175865650177
Batch 26/64 loss: 0.35088270902633667
Batch 27/64 loss: 0.3497927784919739
Batch 28/64 loss: 0.34752488136291504
Batch 29/64 loss: 0.3545181155204773
Batch 30/64 loss: 0.3519209027290344
Batch 31/64 loss: 0.35364437103271484
Batch 32/64 loss: 0.35626161098480225
Batch 33/64 loss: 0.3519315719604492
Batch 34/64 loss: 0.35390037298202515
Batch 35/64 loss: 0.35664618015289307
Batch 36/64 loss: 0.3537275791168213
Batch 37/64 loss: 0.35492634773254395
Batch 38/64 loss: 0.3488994836807251
Batch 39/64 loss: 0.3517436981201172
Batch 40/64 loss: 0.35335230827331543
Batch 41/64 loss: 0.3524961471557617
Batch 42/64 loss: 0.35093170404434204
Batch 43/64 loss: 0.34986478090286255
Batch 44/64 loss: 0.35301434993743896
Batch 45/64 loss: 0.3497750759124756
Batch 46/64 loss: 0.35170578956604004
Batch 47/64 loss: 0.3515390157699585
Batch 48/64 loss: 0.35336732864379883
Batch 49/64 loss: 0.3542179465293884
Batch 50/64 loss: 0.3533221483230591
Batch 51/64 loss: 0.3505473732948303
Batch 52/64 loss: 0.35199546813964844
Batch 53/64 loss: 0.3474792242050171
Batch 54/64 loss: 0.35154181718826294
Batch 55/64 loss: 0.35280364751815796
Batch 56/64 loss: 0.35251009464263916
Batch 57/64 loss: 0.35051220655441284
Batch 58/64 loss: 0.3518035411834717
Batch 59/64 loss: 0.3494378328323364
Batch 60/64 loss: 0.35273289680480957
Batch 61/64 loss: 0.35573434829711914
Batch 62/64 loss: 0.352871298789978
Batch 63/64 loss: 0.3535308837890625
Batch 64/64 loss: 0.3525733947753906
Epoch 49  Train loss: 0.3521335816850849  Val loss: 0.356362853058425
Epoch 50
-------------------------------
Batch 1/64 loss: 0.3519632816314697
Batch 2/64 loss: 0.34724652767181396
Batch 3/64 loss: 0.34880757331848145
Batch 4/64 loss: 0.34792202711105347
Batch 5/64 loss: 0.35099053382873535
Batch 6/64 loss: 0.3502328395843506
Batch 7/64 loss: 0.3547847270965576
Batch 8/64 loss: 0.34909486770629883
Batch 9/64 loss: 0.35338294506073
Batch 10/64 loss: 0.3519650101661682
Batch 11/64 loss: 0.35726141929626465
Batch 12/64 loss: 0.3529650568962097
Batch 13/64 loss: 0.3548010587692261
Batch 14/64 loss: 0.35387808084487915
Batch 15/64 loss: 0.35467690229415894
Batch 16/64 loss: 0.3553866744041443
Batch 17/64 loss: 0.3521134853363037
Batch 18/64 loss: 0.3528198003768921
Batch 19/64 loss: 0.35695958137512207
Batch 20/64 loss: 0.35106921195983887
Batch 21/64 loss: 0.3524375557899475
Batch 22/64 loss: 0.3501243591308594
Batch 23/64 loss: 0.34846484661102295
Batch 24/64 loss: 0.3478637933731079
Batch 25/64 loss: 0.3485468626022339
Batch 26/64 loss: 0.3486180305480957
Batch 27/64 loss: 0.3520592451095581
Batch 28/64 loss: 0.35161447525024414
Batch 29/64 loss: 0.35043537616729736
Batch 30/64 loss: 0.35386455059051514
Batch 31/64 loss: 0.3550388813018799
Batch 32/64 loss: 0.3521016240119934
Batch 33/64 loss: 0.3524622321128845
Batch 34/64 loss: 0.3504575490951538
Batch 35/64 loss: 0.3508896827697754
Batch 36/64 loss: 0.35198450088500977
Batch 37/64 loss: 0.3544262647628784
Batch 38/64 loss: 0.350519061088562
Batch 39/64 loss: 0.35025739669799805
Batch 40/64 loss: 0.35128945112228394
Batch 41/64 loss: 0.35737884044647217
Batch 42/64 loss: 0.3509976267814636
Batch 43/64 loss: 0.351701021194458
Batch 44/64 loss: 0.35343170166015625
Batch 45/64 loss: 0.3524952530860901
Batch 46/64 loss: 0.355543315410614
Batch 47/64 loss: 0.3525354862213135
Batch 48/64 loss: 0.352047324180603
Batch 49/64 loss: 0.3533369302749634
Batch 50/64 loss: 0.35244596004486084
Batch 51/64 loss: 0.34940797090530396
Batch 52/64 loss: 0.3534393310546875
Batch 53/64 loss: 0.3517594337463379
Batch 54/64 loss: 0.35612285137176514
Batch 55/64 loss: 0.35376954078674316
Batch 56/64 loss: 0.3570253252983093
Batch 57/64 loss: 0.3505063056945801
Batch 58/64 loss: 0.35213738679885864
Batch 59/64 loss: 0.35366618633270264
Batch 60/64 loss: 0.3537602424621582
Batch 61/64 loss: 0.34881144762039185
Batch 62/64 loss: 0.3503168821334839
Batch 63/64 loss: 0.3518519401550293
Batch 64/64 loss: 0.3529261350631714
Epoch 50  Train loss: 0.3521719254699408  Val loss: 0.35534819684077784
Epoch 51
-------------------------------
Batch 1/64 loss: 0.3492498993873596
Batch 2/64 loss: 0.353521466255188
Batch 3/64 loss: 0.35404133796691895
Batch 4/64 loss: 0.3512641191482544
Batch 5/64 loss: 0.35116302967071533
Batch 6/64 loss: 0.3502177596092224
Batch 7/64 loss: 0.3522210121154785
Batch 8/64 loss: 0.35217487812042236
Batch 9/64 loss: 0.3503537178039551
Batch 10/64 loss: 0.3481106758117676
Batch 11/64 loss: 0.3488588333129883
Batch 12/64 loss: 0.353989839553833
Batch 13/64 loss: 0.35018080472946167
Batch 14/64 loss: 0.351704478263855
Batch 15/64 loss: 0.3466893434524536
Batch 16/64 loss: 0.35391271114349365
Batch 17/64 loss: 0.3514874577522278
Batch 18/64 loss: 0.3560057282447815
Batch 19/64 loss: 0.352962851524353
Batch 20/64 loss: 0.3521437644958496
Batch 21/64 loss: 0.34750741720199585
Batch 22/64 loss: 0.3549399971961975
Batch 23/64 loss: 0.35304927825927734
Batch 24/64 loss: 0.35014641284942627
Batch 25/64 loss: 0.3535785675048828
Batch 26/64 loss: 0.35078567266464233
Batch 27/64 loss: 0.35444170236587524
Batch 28/64 loss: 0.35419148206710815
Batch 29/64 loss: 0.35069739818573
Batch 30/64 loss: 0.3561187982559204
Batch 31/64 loss: 0.3519240617752075
Batch 32/64 loss: 0.35317957401275635
Batch 33/64 loss: 0.35072362422943115
Batch 34/64 loss: 0.35168808698654175
Batch 35/64 loss: 0.3525642156600952
Batch 36/64 loss: 0.35102391242980957
Batch 37/64 loss: 0.35585159063339233
Batch 38/64 loss: 0.35142600536346436
Batch 39/64 loss: 0.3562105894088745
Batch 40/64 loss: 0.34855496883392334
Batch 41/64 loss: 0.35490185022354126
Batch 42/64 loss: 0.35812675952911377
Batch 43/64 loss: 0.3525940775871277
Batch 44/64 loss: 0.35318541526794434
Batch 45/64 loss: 0.34963440895080566
Batch 46/64 loss: 0.35394251346588135
Batch 47/64 loss: 0.3571905493736267
Batch 48/64 loss: 0.3471439480781555
Batch 49/64 loss: 0.3551565408706665
Batch 50/64 loss: 0.35097837448120117
Batch 51/64 loss: 0.35254156589508057
Batch 52/64 loss: 0.34952646493911743
Batch 53/64 loss: 0.3501623272895813
Batch 54/64 loss: 0.34968996047973633
Batch 55/64 loss: 0.3541533946990967
Batch 56/64 loss: 0.3490210771560669
Batch 57/64 loss: 0.35009562969207764
Batch 58/64 loss: 0.34996145963668823
Batch 59/64 loss: 0.3541443943977356
Batch 60/64 loss: 0.3507300615310669
Batch 61/64 loss: 0.3509756326675415
Batch 62/64 loss: 0.3481321334838867
Batch 63/64 loss: 0.3526564836502075
Batch 64/64 loss: 0.3558177947998047
Epoch 51  Train loss: 0.35200573229322246  Val loss: 0.3550344807995144
Epoch 52
-------------------------------
Batch 1/64 loss: 0.349001407623291
Batch 2/64 loss: 0.3508877754211426
Batch 3/64 loss: 0.35102295875549316
Batch 4/64 loss: 0.34682929515838623
Batch 5/64 loss: 0.35322582721710205
Batch 6/64 loss: 0.35373377799987793
Batch 7/64 loss: 0.35777294635772705
Batch 8/64 loss: 0.3558499813079834
Batch 9/64 loss: 0.3566395044326782
Batch 10/64 loss: 0.35679203271865845
Batch 11/64 loss: 0.351471483707428
Batch 12/64 loss: 0.349733829498291
Batch 13/64 loss: 0.35313618183135986
Batch 14/64 loss: 0.3519532084465027
Batch 15/64 loss: 0.3499382734298706
Batch 16/64 loss: 0.35332775115966797
Batch 17/64 loss: 0.34922897815704346
Batch 18/64 loss: 0.35353922843933105
Batch 19/64 loss: 0.3500959873199463
Batch 20/64 loss: 0.349664568901062
Batch 21/64 loss: 0.35513460636138916
Batch 22/64 loss: 0.3535071611404419
Batch 23/64 loss: 0.35273921489715576
Batch 24/64 loss: 0.35438239574432373
Batch 25/64 loss: 0.347847580909729
Batch 26/64 loss: 0.35068196058273315
Batch 27/64 loss: 0.3534647822380066
Batch 28/64 loss: 0.35445350408554077
Batch 29/64 loss: 0.3560265898704529
Batch 30/64 loss: 0.35275691747665405
Batch 31/64 loss: 0.34626835584640503
Batch 32/64 loss: 0.354053795337677
Batch 33/64 loss: 0.348868727684021
Batch 34/64 loss: 0.35339808464050293
Batch 35/64 loss: 0.34890538454055786
Batch 36/64 loss: 0.3511449098587036
Batch 37/64 loss: 0.35278475284576416
Batch 38/64 loss: 0.34718984365463257
Batch 39/64 loss: 0.351972758769989
Batch 40/64 loss: 0.35254091024398804
Batch 41/64 loss: 0.3544684648513794
Batch 42/64 loss: 0.3481360673904419
Batch 43/64 loss: 0.34963345527648926
Batch 44/64 loss: 0.3470008373260498
Batch 45/64 loss: 0.35032618045806885
Batch 46/64 loss: 0.3489779233932495
Batch 47/64 loss: 0.3505452871322632
Batch 48/64 loss: 0.3519536256790161
Batch 49/64 loss: 0.3549729585647583
Batch 50/64 loss: 0.3466989994049072
Batch 51/64 loss: 0.3519221544265747
Batch 52/64 loss: 0.3496514558792114
Batch 53/64 loss: 0.3510279059410095
Batch 54/64 loss: 0.3520880937576294
Batch 55/64 loss: 0.35109013319015503
Batch 56/64 loss: 0.35178685188293457
Batch 57/64 loss: 0.3536115884780884
Batch 58/64 loss: 0.35513800382614136
Batch 59/64 loss: 0.3536263108253479
Batch 60/64 loss: 0.3530266284942627
Batch 61/64 loss: 0.3515312671661377
Batch 62/64 loss: 0.3532804250717163
Batch 63/64 loss: 0.3499445915222168
Batch 64/64 loss: 0.3453787565231323
Epoch 52  Train loss: 0.35170887077555935  Val loss: 0.35481102360073236
Epoch 53
-------------------------------
Batch 1/64 loss: 0.3548269271850586
Batch 2/64 loss: 0.3527017831802368
Batch 3/64 loss: 0.3516468405723572
Batch 4/64 loss: 0.34511780738830566
Batch 5/64 loss: 0.3521881103515625
Batch 6/64 loss: 0.3548191785812378
Batch 7/64 loss: 0.3527836799621582
Batch 8/64 loss: 0.3508843779563904
Batch 9/64 loss: 0.3499656915664673
Batch 10/64 loss: 0.352098286151886
Batch 11/64 loss: 0.3553617596626282
Batch 12/64 loss: 0.3515450954437256
Batch 13/64 loss: 0.3527780771255493
Batch 14/64 loss: 0.3522871732711792
Batch 15/64 loss: 0.35439515113830566
Batch 16/64 loss: 0.34900885820388794
Batch 17/64 loss: 0.35407912731170654
Batch 18/64 loss: 0.3458501100540161
Batch 19/64 loss: 0.34663569927215576
Batch 20/64 loss: 0.35181570053100586
Batch 21/64 loss: 0.34761786460876465
Batch 22/64 loss: 0.35765576362609863
Batch 23/64 loss: 0.3474733829498291
Batch 24/64 loss: 0.3521668314933777
Batch 25/64 loss: 0.34666430950164795
Batch 26/64 loss: 0.3529306650161743
Batch 27/64 loss: 0.35164129734039307
Batch 28/64 loss: 0.35497814416885376
Batch 29/64 loss: 0.3547564744949341
Batch 30/64 loss: 0.3534923791885376
Batch 31/64 loss: 0.3518175482749939
Batch 32/64 loss: 0.3482024669647217
Batch 33/64 loss: 0.35009288787841797
Batch 34/64 loss: 0.3530508279800415
Batch 35/64 loss: 0.3539855480194092
Batch 36/64 loss: 0.3517575263977051
Batch 37/64 loss: 0.34975844621658325
Batch 38/64 loss: 0.34923791885375977
Batch 39/64 loss: 0.35472166538238525
Batch 40/64 loss: 0.3512483239173889
Batch 41/64 loss: 0.35086309909820557
Batch 42/64 loss: 0.3527858257293701
Batch 43/64 loss: 0.34889084100723267
Batch 44/64 loss: 0.3498632311820984
Batch 45/64 loss: 0.35126984119415283
Batch 46/64 loss: 0.35445141792297363
Batch 47/64 loss: 0.35410773754119873
Batch 48/64 loss: 0.35352301597595215
Batch 49/64 loss: 0.3539344072341919
Batch 50/64 loss: 0.34988081455230713
Batch 51/64 loss: 0.3508265018463135
Batch 52/64 loss: 0.3494443893432617
Batch 53/64 loss: 0.3497563600540161
Batch 54/64 loss: 0.3492170572280884
Batch 55/64 loss: 0.35206925868988037
Batch 56/64 loss: 0.349979043006897
Batch 57/64 loss: 0.35031557083129883
Batch 58/64 loss: 0.34839797019958496
Batch 59/64 loss: 0.3509049415588379
Batch 60/64 loss: 0.35267990827560425
Batch 61/64 loss: 0.35021328926086426
Batch 62/64 loss: 0.35194337368011475
Batch 63/64 loss: 0.35457128286361694
Batch 64/64 loss: 0.3490346074104309
Epoch 53  Train loss: 0.3514620367218466  Val loss: 0.3542953473595819
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: 0.35414552688598633
Batch 2/64 loss: 0.350983202457428
Batch 3/64 loss: 0.35618966817855835
Batch 4/64 loss: 0.3544139862060547
Batch 5/64 loss: 0.35315150022506714
Batch 6/64 loss: 0.3528432846069336
Batch 7/64 loss: 0.35320043563842773
Batch 8/64 loss: 0.34884142875671387
Batch 9/64 loss: 0.34788262844085693
Batch 10/64 loss: 0.35069555044174194
Batch 11/64 loss: 0.35182249546051025
Batch 12/64 loss: 0.3516838550567627
Batch 13/64 loss: 0.3507215976715088
Batch 14/64 loss: 0.3483099341392517
Batch 15/64 loss: 0.3527243137359619
Batch 16/64 loss: 0.3507803678512573
Batch 17/64 loss: 0.34932422637939453
Batch 18/64 loss: 0.34774303436279297
Batch 19/64 loss: 0.3514120578765869
Batch 20/64 loss: 0.34972304105758667
Batch 21/64 loss: 0.35413962602615356
Batch 22/64 loss: 0.35052990913391113
Batch 23/64 loss: 0.35184967517852783
Batch 24/64 loss: 0.34976476430892944
Batch 25/64 loss: 0.35485827922821045
Batch 26/64 loss: 0.3533504605293274
Batch 27/64 loss: 0.3498774766921997
Batch 28/64 loss: 0.3520193099975586
Batch 29/64 loss: 0.3536420464515686
Batch 30/64 loss: 0.35274022817611694
Batch 31/64 loss: 0.3511664867401123
Batch 32/64 loss: 0.35017549991607666
Batch 33/64 loss: 0.3517676591873169
Batch 34/64 loss: 0.34966063499450684
Batch 35/64 loss: 0.3495507836341858
Batch 36/64 loss: 0.3502417206764221
Batch 37/64 loss: 0.3519026041030884
Batch 38/64 loss: 0.34977471828460693
Batch 39/64 loss: 0.35073012113571167
Batch 40/64 loss: 0.34867870807647705
Batch 41/64 loss: 0.35090577602386475
Batch 42/64 loss: 0.3533759117126465
Batch 43/64 loss: 0.3482125997543335
Batch 44/64 loss: 0.3501749038696289
Batch 45/64 loss: 0.35037243366241455
Batch 46/64 loss: 0.3485734462738037
Batch 47/64 loss: 0.350172758102417
Batch 48/64 loss: 0.3504628539085388
Batch 49/64 loss: 0.3552377223968506
Batch 50/64 loss: 0.3525956869125366
Batch 51/64 loss: 0.3489598035812378
Batch 52/64 loss: 0.3533834218978882
Batch 53/64 loss: 0.35787802934646606
Batch 54/64 loss: 0.34654927253723145
Batch 55/64 loss: 0.3500922918319702
Batch 56/64 loss: 0.35344141721725464
Batch 57/64 loss: 0.3533991575241089
Batch 58/64 loss: 0.3501620292663574
Batch 59/64 loss: 0.3530281186103821
Batch 60/64 loss: 0.3492695093154907
Batch 61/64 loss: 0.3535482883453369
Batch 62/64 loss: 0.35433387756347656
Batch 63/64 loss: 0.34881335496902466
Batch 64/64 loss: 0.349368155002594
Epoch 54  Train loss: 0.35134088829451915  Val loss: 0.3551986696793861
Epoch 55
-------------------------------
Batch 1/64 loss: 0.35456836223602295
Batch 2/64 loss: 0.35200321674346924
Batch 3/64 loss: 0.3473784327507019
Batch 4/64 loss: 0.34932708740234375
Batch 5/64 loss: 0.35268115997314453
Batch 6/64 loss: 0.34723079204559326
Batch 7/64 loss: 0.3499254584312439
Batch 8/64 loss: 0.35331904888153076
Batch 9/64 loss: 0.34909069538116455
Batch 10/64 loss: 0.35128092765808105
Batch 11/64 loss: 0.3516014814376831
Batch 12/64 loss: 0.34981226921081543
Batch 13/64 loss: 0.349595844745636
Batch 14/64 loss: 0.35201287269592285
Batch 15/64 loss: 0.352154016494751
Batch 16/64 loss: 0.3496774435043335
Batch 17/64 loss: 0.348569393157959
Batch 18/64 loss: 0.35140687227249146
Batch 19/64 loss: 0.35399001836776733
Batch 20/64 loss: 0.3499079942703247
Batch 21/64 loss: 0.35647326707839966
Batch 22/64 loss: 0.35065221786499023
Batch 23/64 loss: 0.35375940799713135
Batch 24/64 loss: 0.35054630041122437
Batch 25/64 loss: 0.3454328179359436
Batch 26/64 loss: 0.3530924916267395
Batch 27/64 loss: 0.35313570499420166
Batch 28/64 loss: 0.3517559766769409
Batch 29/64 loss: 0.35306572914123535
Batch 30/64 loss: 0.3509436845779419
Batch 31/64 loss: 0.3502821922302246
Batch 32/64 loss: 0.3451384902000427
Batch 33/64 loss: 0.35291242599487305
Batch 34/64 loss: 0.35239988565444946
Batch 35/64 loss: 0.3548240065574646
Batch 36/64 loss: 0.34977322816848755
Batch 37/64 loss: 0.35157912969589233
Batch 38/64 loss: 0.35081636905670166
Batch 39/64 loss: 0.3536100387573242
Batch 40/64 loss: 0.3573460578918457
Batch 41/64 loss: 0.3536115884780884
Batch 42/64 loss: 0.3485029935836792
Batch 43/64 loss: 0.3494831323623657
Batch 44/64 loss: 0.35257089138031006
Batch 45/64 loss: 0.35082608461380005
Batch 46/64 loss: 0.35011792182922363
Batch 47/64 loss: 0.3518562316894531
Batch 48/64 loss: 0.3588451147079468
Batch 49/64 loss: 0.35302734375
Batch 50/64 loss: 0.35258948802948
Batch 51/64 loss: 0.3518085479736328
Batch 52/64 loss: 0.3502576947212219
Batch 53/64 loss: 0.3525952100753784
Batch 54/64 loss: 0.3508436679840088
Batch 55/64 loss: 0.3527596592903137
Batch 56/64 loss: 0.3527573347091675
Batch 57/64 loss: 0.351253867149353
Batch 58/64 loss: 0.3494686484336853
Batch 59/64 loss: 0.3511312007904053
Batch 60/64 loss: 0.34932053089141846
Batch 61/64 loss: 0.34965193271636963
Batch 62/64 loss: 0.35039961338043213
Batch 63/64 loss: 0.3477461338043213
Batch 64/64 loss: 0.3472943902015686
Epoch 55  Train loss: 0.3512936225124434  Val loss: 0.3550337641099884
Epoch 56
-------------------------------
Batch 1/64 loss: 0.34807729721069336
Batch 2/64 loss: 0.35190320014953613
Batch 3/64 loss: 0.3473968505859375
Batch 4/64 loss: 0.3473942279815674
Batch 5/64 loss: 0.3504016399383545
Batch 6/64 loss: 0.3512011766433716
Batch 7/64 loss: 0.34845125675201416
Batch 8/64 loss: 0.3487039804458618
Batch 9/64 loss: 0.35159367322921753
Batch 10/64 loss: 0.34990495443344116
Batch 11/64 loss: 0.35046064853668213
Batch 12/64 loss: 0.35459834337234497
Batch 13/64 loss: 0.3485196828842163
Batch 14/64 loss: 0.348732590675354
Batch 15/64 loss: 0.3512881398200989
Batch 16/64 loss: 0.34750765562057495
Batch 17/64 loss: 0.3489082455635071
Batch 18/64 loss: 0.350730299949646
Batch 19/64 loss: 0.3540329933166504
Batch 20/64 loss: 0.35081231594085693
Batch 21/64 loss: 0.3520010709762573
Batch 22/64 loss: 0.34915125370025635
Batch 23/64 loss: 0.3568021059036255
Batch 24/64 loss: 0.350551962852478
Batch 25/64 loss: 0.3481614589691162
Batch 26/64 loss: 0.3529209494590759
Batch 27/64 loss: 0.35158562660217285
Batch 28/64 loss: 0.3492007851600647
Batch 29/64 loss: 0.34900665283203125
Batch 30/64 loss: 0.3505769968032837
Batch 31/64 loss: 0.35429996252059937
Batch 32/64 loss: 0.35371971130371094
Batch 33/64 loss: 0.34796321392059326
Batch 34/64 loss: 0.353928804397583
Batch 35/64 loss: 0.35043609142303467
Batch 36/64 loss: 0.35191285610198975
Batch 37/64 loss: 0.34750479459762573
Batch 38/64 loss: 0.3474698066711426
Batch 39/64 loss: 0.3486021161079407
Batch 40/64 loss: 0.35019195079803467
Batch 41/64 loss: 0.3556220531463623
Batch 42/64 loss: 0.35447901487350464
Batch 43/64 loss: 0.35237276554107666
Batch 44/64 loss: 0.353792667388916
Batch 45/64 loss: 0.35145318508148193
Batch 46/64 loss: 0.3457779884338379
Batch 47/64 loss: 0.350344181060791
Batch 48/64 loss: 0.34959179162979126
Batch 49/64 loss: 0.35442280769348145
Batch 50/64 loss: 0.3524131774902344
Batch 51/64 loss: 0.3484863042831421
Batch 52/64 loss: 0.353190541267395
Batch 53/64 loss: 0.3473927974700928
Batch 54/64 loss: 0.3498647212982178
Batch 55/64 loss: 0.35396039485931396
Batch 56/64 loss: 0.353778600692749
Batch 57/64 loss: 0.3503497838973999
Batch 58/64 loss: 0.3488882780075073
Batch 59/64 loss: 0.3535885810852051
Batch 60/64 loss: 0.35410159826278687
Batch 61/64 loss: 0.3532921075820923
Batch 62/64 loss: 0.3497833013534546
Batch 63/64 loss: 0.34906506538391113
Batch 64/64 loss: 0.35229504108428955
Epoch 56  Train loss: 0.35085239737641577  Val loss: 0.3567165806121433
Epoch 57
-------------------------------
Batch 1/64 loss: 0.3517822027206421
Batch 2/64 loss: 0.3518843650817871
Batch 3/64 loss: 0.3494332432746887
Batch 4/64 loss: 0.3476600646972656
Batch 5/64 loss: 0.34807097911834717
Batch 6/64 loss: 0.3528190851211548
Batch 7/64 loss: 0.35216593742370605
Batch 8/64 loss: 0.3568210005760193
Batch 9/64 loss: 0.3526993989944458
Batch 10/64 loss: 0.3533604145050049
Batch 11/64 loss: 0.34907954931259155
Batch 12/64 loss: 0.35160839557647705
Batch 13/64 loss: 0.3538525700569153
Batch 14/64 loss: 0.3528749346733093
Batch 15/64 loss: 0.34955722093582153
Batch 16/64 loss: 0.3527516722679138
Batch 17/64 loss: 0.34672969579696655
Batch 18/64 loss: 0.34961938858032227
Batch 19/64 loss: 0.35317957401275635
Batch 20/64 loss: 0.3537139296531677
Batch 21/64 loss: 0.3508796691894531
Batch 22/64 loss: 0.35364216566085815
Batch 23/64 loss: 0.35655641555786133
Batch 24/64 loss: 0.3546628952026367
Batch 25/64 loss: 0.34628671407699585
Batch 26/64 loss: 0.34956926107406616
Batch 27/64 loss: 0.3511539697647095
Batch 28/64 loss: 0.3545689582824707
Batch 29/64 loss: 0.35033267736434937
Batch 30/64 loss: 0.3520803451538086
Batch 31/64 loss: 0.3550527095794678
Batch 32/64 loss: 0.35102319717407227
Batch 33/64 loss: 0.3519996404647827
Batch 34/64 loss: 0.34627097845077515
Batch 35/64 loss: 0.3459509015083313
Batch 36/64 loss: 0.346829354763031
Batch 37/64 loss: 0.3496004343032837
Batch 38/64 loss: 0.350307822227478
Batch 39/64 loss: 0.3504818081855774
Batch 40/64 loss: 0.3468259572982788
Batch 41/64 loss: 0.34827083349227905
Batch 42/64 loss: 0.3504981994628906
Batch 43/64 loss: 0.3494163751602173
Batch 44/64 loss: 0.3492281436920166
Batch 45/64 loss: 0.3530726432800293
Batch 46/64 loss: 0.3466048240661621
Batch 47/64 loss: 0.3500707745552063
Batch 48/64 loss: 0.35216468572616577
Batch 49/64 loss: 0.34534895420074463
Batch 50/64 loss: 0.35101318359375
Batch 51/64 loss: 0.3473089933395386
Batch 52/64 loss: 0.3540935516357422
Batch 53/64 loss: 0.3485097885131836
Batch 54/64 loss: 0.3514108657836914
Batch 55/64 loss: 0.3470299243927002
Batch 56/64 loss: 0.35143280029296875
Batch 57/64 loss: 0.35152602195739746
Batch 58/64 loss: 0.34950923919677734
Batch 59/64 loss: 0.35100674629211426
Batch 60/64 loss: 0.3493802547454834
Batch 61/64 loss: 0.34807395935058594
Batch 62/64 loss: 0.3503834009170532
Batch 63/64 loss: 0.3496769666671753
Batch 64/64 loss: 0.35468852519989014
Epoch 57  Train loss: 0.3506633258333393  Val loss: 0.3560136091668172
Epoch 58
-------------------------------
Batch 1/64 loss: 0.3496718406677246
Batch 2/64 loss: 0.350566029548645
Batch 3/64 loss: 0.3520657420158386
Batch 4/64 loss: 0.3486493229866028
Batch 5/64 loss: 0.3517947793006897
Batch 6/64 loss: 0.3467872142791748
Batch 7/64 loss: 0.3474302291870117
Batch 8/64 loss: 0.34708869457244873
Batch 9/64 loss: 0.3508331775665283
Batch 10/64 loss: 0.35192185640335083
Batch 11/64 loss: 0.349475622177124
Batch 12/64 loss: 0.3484451174736023
Batch 13/64 loss: 0.3463471531867981
Batch 14/64 loss: 0.3530921936035156
Batch 15/64 loss: 0.35276830196380615
Batch 16/64 loss: 0.35229766368865967
Batch 17/64 loss: 0.35263288021087646
Batch 18/64 loss: 0.3510555028915405
Batch 19/64 loss: 0.34934860467910767
Batch 20/64 loss: 0.351654589176178
Batch 21/64 loss: 0.3469761610031128
Batch 22/64 loss: 0.35253602266311646
Batch 23/64 loss: 0.35185950994491577
Batch 24/64 loss: 0.35009902715682983
Batch 25/64 loss: 0.34848129749298096
Batch 26/64 loss: 0.3516026735305786
Batch 27/64 loss: 0.3493478298187256
Batch 28/64 loss: 0.35673606395721436
Batch 29/64 loss: 0.3542745113372803
Batch 30/64 loss: 0.34641993045806885
Batch 31/64 loss: 0.35136878490448
Batch 32/64 loss: 0.3501759171485901
Batch 33/64 loss: 0.34834814071655273
Batch 34/64 loss: 0.34840017557144165
Batch 35/64 loss: 0.3515387177467346
Batch 36/64 loss: 0.35548365116119385
Batch 37/64 loss: 0.3512352705001831
Batch 38/64 loss: 0.3488777279853821
Batch 39/64 loss: 0.3486734628677368
Batch 40/64 loss: 0.3454575538635254
Batch 41/64 loss: 0.3508719205856323
Batch 42/64 loss: 0.34910833835601807
Batch 43/64 loss: 0.35187000036239624
Batch 44/64 loss: 0.3537086248397827
Batch 45/64 loss: 0.3503366708755493
Batch 46/64 loss: 0.35017842054367065
Batch 47/64 loss: 0.3483392596244812
Batch 48/64 loss: 0.3475090265274048
Batch 49/64 loss: 0.35331207513809204
Batch 50/64 loss: 0.3529278635978699
Batch 51/64 loss: 0.3506420850753784
Batch 52/64 loss: 0.3529791831970215
Batch 53/64 loss: 0.3497740626335144
Batch 54/64 loss: 0.35050439834594727
Batch 55/64 loss: 0.35215699672698975
Batch 56/64 loss: 0.34959256649017334
Batch 57/64 loss: 0.3504011631011963
Batch 58/64 loss: 0.3506026268005371
Batch 59/64 loss: 0.3513127565383911
Batch 60/64 loss: 0.3520151376724243
Batch 61/64 loss: 0.353753924369812
Batch 62/64 loss: 0.34920692443847656
Batch 63/64 loss: 0.3513110280036926
Batch 64/64 loss: 0.3506026268005371
Epoch 58  Train loss: 0.3505440936369054  Val loss: 0.35405882691190005
Saving best model, epoch: 58
Epoch 59
-------------------------------
Batch 1/64 loss: 0.3546394109725952
Batch 2/64 loss: 0.35329169034957886
Batch 3/64 loss: 0.35069704055786133
Batch 4/64 loss: 0.35037893056869507
Batch 5/64 loss: 0.3506584167480469
Batch 6/64 loss: 0.3512658476829529
Batch 7/64 loss: 0.3550259470939636
Batch 8/64 loss: 0.3490293025970459
Batch 9/64 loss: 0.3522251844406128
Batch 10/64 loss: 0.3493306636810303
Batch 11/64 loss: 0.34869253635406494
Batch 12/64 loss: 0.34822267293930054
Batch 13/64 loss: 0.3490610122680664
Batch 14/64 loss: 0.349765419960022
Batch 15/64 loss: 0.3497406244277954
Batch 16/64 loss: 0.3547670245170593
Batch 17/64 loss: 0.3518221974372864
Batch 18/64 loss: 0.3555215001106262
Batch 19/64 loss: 0.34846198558807373
Batch 20/64 loss: 0.35124754905700684
Batch 21/64 loss: 0.3486126661300659
Batch 22/64 loss: 0.3541961908340454
Batch 23/64 loss: 0.34688079357147217
Batch 24/64 loss: 0.3464425802230835
Batch 25/64 loss: 0.34605318307876587
Batch 26/64 loss: 0.35057878494262695
Batch 27/64 loss: 0.3506832718849182
Batch 28/64 loss: 0.3523804545402527
Batch 29/64 loss: 0.35109853744506836
Batch 30/64 loss: 0.349581241607666
Batch 31/64 loss: 0.34667205810546875
Batch 32/64 loss: 0.35071611404418945
Batch 33/64 loss: 0.34975117444992065
Batch 34/64 loss: 0.35444802045822144
Batch 35/64 loss: 0.3508153557777405
Batch 36/64 loss: 0.3532341718673706
Batch 37/64 loss: 0.3534369468688965
Batch 38/64 loss: 0.3501242995262146
Batch 39/64 loss: 0.35260164737701416
Batch 40/64 loss: 0.35481560230255127
Batch 41/64 loss: 0.35121774673461914
Batch 42/64 loss: 0.3568243980407715
Batch 43/64 loss: 0.35008931159973145
Batch 44/64 loss: 0.34961795806884766
Batch 45/64 loss: 0.35092365741729736
Batch 46/64 loss: 0.3518112301826477
Batch 47/64 loss: 0.349311888217926
Batch 48/64 loss: 0.34978187084198
Batch 49/64 loss: 0.34994471073150635
Batch 50/64 loss: 0.3476754426956177
Batch 51/64 loss: 0.3478353023529053
Batch 52/64 loss: 0.35191893577575684
Batch 53/64 loss: 0.34809523820877075
Batch 54/64 loss: 0.34713566303253174
Batch 55/64 loss: 0.3555143475532532
Batch 56/64 loss: 0.3493208885192871
Batch 57/64 loss: 0.35106146335601807
Batch 58/64 loss: 0.3482756018638611
Batch 59/64 loss: 0.3473215103149414
Batch 60/64 loss: 0.3483705520629883
Batch 61/64 loss: 0.3548824191093445
Batch 62/64 loss: 0.3508739471435547
Batch 63/64 loss: 0.352245569229126
Batch 64/64 loss: 0.35437124967575073
Epoch 59  Train loss: 0.35078895910113467  Val loss: 0.3542537134127928
Epoch 60
-------------------------------
Batch 1/64 loss: 0.35323935747146606
Batch 2/64 loss: 0.3508877754211426
Batch 3/64 loss: 0.3492351770401001
Batch 4/64 loss: 0.3515792489051819
Batch 5/64 loss: 0.34978604316711426
Batch 6/64 loss: 0.35350799560546875
Batch 7/64 loss: 0.3524969816207886
Batch 8/64 loss: 0.3494780659675598
Batch 9/64 loss: 0.3482619524002075
Batch 10/64 loss: 0.351550817489624
Batch 11/64 loss: 0.3511319160461426
Batch 12/64 loss: 0.3504679203033447
Batch 13/64 loss: 0.35063034296035767
Batch 14/64 loss: 0.3486415147781372
Batch 15/64 loss: 0.34897398948669434
Batch 16/64 loss: 0.35390913486480713
Batch 17/64 loss: 0.35272055864334106
Batch 18/64 loss: 0.3502998352050781
Batch 19/64 loss: 0.35045409202575684
Batch 20/64 loss: 0.35223567485809326
Batch 21/64 loss: 0.3533216118812561
Batch 22/64 loss: 0.3476576805114746
Batch 23/64 loss: 0.35307562351226807
Batch 24/64 loss: 0.35241901874542236
Batch 25/64 loss: 0.3531620502471924
Batch 26/64 loss: 0.35375988483428955
Batch 27/64 loss: 0.3516721725463867
Batch 28/64 loss: 0.35056328773498535
Batch 29/64 loss: 0.3467264175415039
Batch 30/64 loss: 0.3522799015045166
Batch 31/64 loss: 0.3514111638069153
Batch 32/64 loss: 0.3567417860031128
Batch 33/64 loss: 0.34788423776626587
Batch 34/64 loss: 0.34510987997055054
Batch 35/64 loss: 0.3472524881362915
Batch 36/64 loss: 0.3506382703781128
Batch 37/64 loss: 0.3495447635650635
Batch 38/64 loss: 0.3463016748428345
Batch 39/64 loss: 0.35159534215927124
Batch 40/64 loss: 0.3518892526626587
Batch 41/64 loss: 0.3438817262649536
Batch 42/64 loss: 0.3496159315109253
Batch 43/64 loss: 0.34814250469207764
Batch 44/64 loss: 0.3509737253189087
Batch 45/64 loss: 0.34877073764801025
Batch 46/64 loss: 0.3459893465042114
Batch 47/64 loss: 0.3488243818283081
Batch 48/64 loss: 0.3473489284515381
Batch 49/64 loss: 0.3534165024757385
Batch 50/64 loss: 0.3531498908996582
Batch 51/64 loss: 0.3491695523262024
Batch 52/64 loss: 0.3484731912612915
Batch 53/64 loss: 0.35015928745269775
Batch 54/64 loss: 0.34662002325057983
Batch 55/64 loss: 0.34889841079711914
Batch 56/64 loss: 0.3565508723258972
Batch 57/64 loss: 0.34888947010040283
Batch 58/64 loss: 0.3505859971046448
Batch 59/64 loss: 0.3493613004684448
Batch 60/64 loss: 0.3493853807449341
Batch 61/64 loss: 0.34751319885253906
Batch 62/64 loss: 0.35293036699295044
Batch 63/64 loss: 0.3517104387283325
Batch 64/64 loss: 0.34889066219329834
Epoch 60  Train loss: 0.3503454755334293  Val loss: 0.35527402285448056
Epoch 61
-------------------------------
Batch 1/64 loss: 0.3479815125465393
Batch 2/64 loss: 0.3501686453819275
Batch 3/64 loss: 0.35302144289016724
Batch 4/64 loss: 0.35422301292419434
Batch 5/64 loss: 0.351948618888855
Batch 6/64 loss: 0.34734731912612915
Batch 7/64 loss: 0.35200852155685425
Batch 8/64 loss: 0.3530808091163635
Batch 9/64 loss: 0.3474194407463074
Batch 10/64 loss: 0.3466334342956543
Batch 11/64 loss: 0.35257434844970703
Batch 12/64 loss: 0.3496568202972412
Batch 13/64 loss: 0.34995222091674805
Batch 14/64 loss: 0.3502490520477295
Batch 15/64 loss: 0.34786736965179443
Batch 16/64 loss: 0.3521536588668823
Batch 17/64 loss: 0.3480212688446045
Batch 18/64 loss: 0.3454812169075012
Batch 19/64 loss: 0.35191458463668823
Batch 20/64 loss: 0.34973788261413574
Batch 21/64 loss: 0.35021018981933594
Batch 22/64 loss: 0.3459092378616333
Batch 23/64 loss: 0.3513847589492798
Batch 24/64 loss: 0.34991300106048584
Batch 25/64 loss: 0.35305559635162354
Batch 26/64 loss: 0.34750425815582275
Batch 27/64 loss: 0.350000262260437
Batch 28/64 loss: 0.3519861102104187
Batch 29/64 loss: 0.3548205494880676
Batch 30/64 loss: 0.35045695304870605
Batch 31/64 loss: 0.35369056463241577
Batch 32/64 loss: 0.3495626449584961
Batch 33/64 loss: 0.3577789068222046
Batch 34/64 loss: 0.3514235019683838
Batch 35/64 loss: 0.34972894191741943
Batch 36/64 loss: 0.34987038373947144
Batch 37/64 loss: 0.3537712097167969
Batch 38/64 loss: 0.3468340039253235
Batch 39/64 loss: 0.35465073585510254
Batch 40/64 loss: 0.349271297454834
Batch 41/64 loss: 0.35259783267974854
Batch 42/64 loss: 0.3458268642425537
Batch 43/64 loss: 0.3490486741065979
Batch 44/64 loss: 0.34607791900634766
Batch 45/64 loss: 0.34833812713623047
Batch 46/64 loss: 0.35126829147338867
Batch 47/64 loss: 0.343630313873291
Batch 48/64 loss: 0.354048490524292
Batch 49/64 loss: 0.3493928909301758
Batch 50/64 loss: 0.3467268943786621
Batch 51/64 loss: 0.35162365436553955
Batch 52/64 loss: 0.3478914499282837
Batch 53/64 loss: 0.3537074327468872
Batch 54/64 loss: 0.3518039584159851
Batch 55/64 loss: 0.35187625885009766
Batch 56/64 loss: 0.3551630973815918
Batch 57/64 loss: 0.34814703464508057
Batch 58/64 loss: 0.348278284072876
Batch 59/64 loss: 0.3450794219970703
Batch 60/64 loss: 0.35156750679016113
Batch 61/64 loss: 0.3550686240196228
Batch 62/64 loss: 0.3532123565673828
Batch 63/64 loss: 0.34762197732925415
Batch 64/64 loss: 0.35208189487457275
Epoch 61  Train loss: 0.35035800887089147  Val loss: 0.3549739628313333
Epoch 62
-------------------------------
Batch 1/64 loss: 0.35194820165634155
Batch 2/64 loss: 0.3474874496459961
Batch 3/64 loss: 0.3526345491409302
Batch 4/64 loss: 0.34936225414276123
Batch 5/64 loss: 0.3458830714225769
Batch 6/64 loss: 0.34914112091064453
Batch 7/64 loss: 0.3510109782218933
Batch 8/64 loss: 0.3518615961074829
Batch 9/64 loss: 0.35068076848983765
Batch 10/64 loss: 0.3562272787094116
Batch 11/64 loss: 0.35036545991897583
Batch 12/64 loss: 0.3500244617462158
Batch 13/64 loss: 0.35158348083496094
Batch 14/64 loss: 0.34701240062713623
Batch 15/64 loss: 0.3498753309249878
Batch 16/64 loss: 0.3455533981323242
Batch 17/64 loss: 0.348400354385376
Batch 18/64 loss: 0.3485985994338989
Batch 19/64 loss: 0.34942626953125
Batch 20/64 loss: 0.3507363796234131
Batch 21/64 loss: 0.3497704267501831
Batch 22/64 loss: 0.3547874093055725
Batch 23/64 loss: 0.34721946716308594
Batch 24/64 loss: 0.34783005714416504
Batch 25/64 loss: 0.35152697563171387
Batch 26/64 loss: 0.34951865673065186
Batch 27/64 loss: 0.34857630729675293
Batch 28/64 loss: 0.35104799270629883
Batch 29/64 loss: 0.3521779775619507
Batch 30/64 loss: 0.3488609790802002
Batch 31/64 loss: 0.3523916006088257
Batch 32/64 loss: 0.35288745164871216
Batch 33/64 loss: 0.34961336851119995
Batch 34/64 loss: 0.35064268112182617
Batch 35/64 loss: 0.35049450397491455
Batch 36/64 loss: 0.3525075912475586
Batch 37/64 loss: 0.3464570641517639
Batch 38/64 loss: 0.34955519437789917
Batch 39/64 loss: 0.3491407036781311
Batch 40/64 loss: 0.34844183921813965
Batch 41/64 loss: 0.35036277770996094
Batch 42/64 loss: 0.3489471673965454
Batch 43/64 loss: 0.3508126735687256
Batch 44/64 loss: 0.34810489416122437
Batch 45/64 loss: 0.348014235496521
Batch 46/64 loss: 0.34925174713134766
Batch 47/64 loss: 0.3482722043991089
Batch 48/64 loss: 0.34939104318618774
Batch 49/64 loss: 0.34892719984054565
Batch 50/64 loss: 0.34557461738586426
Batch 51/64 loss: 0.34679800271987915
Batch 52/64 loss: 0.3485649824142456
Batch 53/64 loss: 0.35041534900665283
Batch 54/64 loss: 0.3484659790992737
Batch 55/64 loss: 0.3513513207435608
Batch 56/64 loss: 0.3540552258491516
Batch 57/64 loss: 0.3487081527709961
Batch 58/64 loss: 0.347892165184021
Batch 59/64 loss: 0.35189199447631836
Batch 60/64 loss: 0.34972983598709106
Batch 61/64 loss: 0.3588482141494751
Batch 62/64 loss: 0.3483186960220337
Batch 63/64 loss: 0.3497852087020874
Batch 64/64 loss: 0.3489152789115906
Epoch 62  Train loss: 0.3498891262447133  Val loss: 0.35318177180601557
Saving best model, epoch: 62
Epoch 63
-------------------------------
Batch 1/64 loss: 0.34770357608795166
Batch 2/64 loss: 0.35446012020111084
Batch 3/64 loss: 0.34729015827178955
Batch 4/64 loss: 0.35242152214050293
Batch 5/64 loss: 0.34951287508010864
Batch 6/64 loss: 0.3502695560455322
Batch 7/64 loss: 0.3467198610305786
Batch 8/64 loss: 0.35083115100860596
Batch 9/64 loss: 0.34831076860427856
Batch 10/64 loss: 0.3505273461341858
Batch 11/64 loss: 0.35213786363601685
Batch 12/64 loss: 0.3466618061065674
Batch 13/64 loss: 0.3523225784301758
Batch 14/64 loss: 0.3503945469856262
Batch 15/64 loss: 0.34862518310546875
Batch 16/64 loss: 0.3483378291130066
Batch 17/64 loss: 0.3482305407524109
Batch 18/64 loss: 0.3492922782897949
Batch 19/64 loss: 0.3557763695716858
Batch 20/64 loss: 0.3466903567314148
Batch 21/64 loss: 0.346676766872406
Batch 22/64 loss: 0.3539431691169739
Batch 23/64 loss: 0.34925639629364014
Batch 24/64 loss: 0.3467589020729065
Batch 25/64 loss: 0.35081207752227783
Batch 26/64 loss: 0.35204821825027466
Batch 27/64 loss: 0.35234999656677246
Batch 28/64 loss: 0.3495505452156067
Batch 29/64 loss: 0.3457754850387573
Batch 30/64 loss: 0.3547287583351135
Batch 31/64 loss: 0.35159993171691895
Batch 32/64 loss: 0.35080838203430176
Batch 33/64 loss: 0.34792155027389526
Batch 34/64 loss: 0.34723788499832153
Batch 35/64 loss: 0.34654414653778076
Batch 36/64 loss: 0.3472416400909424
Batch 37/64 loss: 0.3476383686065674
Batch 38/64 loss: 0.348006010055542
Batch 39/64 loss: 0.35025525093078613
Batch 40/64 loss: 0.34926748275756836
Batch 41/64 loss: 0.3538327217102051
Batch 42/64 loss: 0.3522496223449707
Batch 43/64 loss: 0.35242509841918945
Batch 44/64 loss: 0.34685248136520386
Batch 45/64 loss: 0.3516644835472107
Batch 46/64 loss: 0.35206353664398193
Batch 47/64 loss: 0.35169708728790283
Batch 48/64 loss: 0.3515479564666748
Batch 49/64 loss: 0.3526076674461365
Batch 50/64 loss: 0.3527509570121765
Batch 51/64 loss: 0.34922659397125244
Batch 52/64 loss: 0.34835875034332275
Batch 53/64 loss: 0.34806549549102783
Batch 54/64 loss: 0.3499171733856201
Batch 55/64 loss: 0.3473263382911682
Batch 56/64 loss: 0.3491741418838501
Batch 57/64 loss: 0.3524951934814453
Batch 58/64 loss: 0.35355818271636963
Batch 59/64 loss: 0.34839290380477905
Batch 60/64 loss: 0.35012876987457275
Batch 61/64 loss: 0.34854865074157715
Batch 62/64 loss: 0.3539477586746216
Batch 63/64 loss: 0.3515418767929077
Batch 64/64 loss: 0.3482850193977356
Epoch 63  Train loss: 0.3500317561860178  Val loss: 0.353956650212868
Epoch 64
-------------------------------
Batch 1/64 loss: 0.3512341380119324
Batch 2/64 loss: 0.34629470109939575
Batch 3/64 loss: 0.34891533851623535
Batch 4/64 loss: 0.3506932854652405
Batch 5/64 loss: 0.347866415977478
Batch 6/64 loss: 0.34721171855926514
Batch 7/64 loss: 0.34786760807037354
Batch 8/64 loss: 0.3522845506668091
Batch 9/64 loss: 0.35052573680877686
Batch 10/64 loss: 0.34627699851989746
Batch 11/64 loss: 0.34721839427948
Batch 12/64 loss: 0.3510429859161377
Batch 13/64 loss: 0.35368049144744873
Batch 14/64 loss: 0.34699440002441406
Batch 15/64 loss: 0.34981030225753784
Batch 16/64 loss: 0.3484584093093872
Batch 17/64 loss: 0.35328543186187744
Batch 18/64 loss: 0.35012030601501465
Batch 19/64 loss: 0.34463995695114136
Batch 20/64 loss: 0.3511717915534973
Batch 21/64 loss: 0.35362911224365234
Batch 22/64 loss: 0.3529850244522095
Batch 23/64 loss: 0.3490012288093567
Batch 24/64 loss: 0.34740149974823
Batch 25/64 loss: 0.3493013381958008
Batch 26/64 loss: 0.34615659713745117
Batch 27/64 loss: 0.34951484203338623
Batch 28/64 loss: 0.3500862121582031
Batch 29/64 loss: 0.34512484073638916
Batch 30/64 loss: 0.3484764099121094
Batch 31/64 loss: 0.3489886522293091
Batch 32/64 loss: 0.35294604301452637
Batch 33/64 loss: 0.3520164489746094
Batch 34/64 loss: 0.349717915058136
Batch 35/64 loss: 0.34898841381073
Batch 36/64 loss: 0.3462994694709778
Batch 37/64 loss: 0.350911021232605
Batch 38/64 loss: 0.3516847491264343
Batch 39/64 loss: 0.3489500880241394
Batch 40/64 loss: 0.3454066514968872
Batch 41/64 loss: 0.34876054525375366
Batch 42/64 loss: 0.3498656749725342
Batch 43/64 loss: 0.3483257293701172
Batch 44/64 loss: 0.3484308123588562
Batch 45/64 loss: 0.3497963547706604
Batch 46/64 loss: 0.3441380262374878
Batch 47/64 loss: 0.3531106114387512
Batch 48/64 loss: 0.34790098667144775
Batch 49/64 loss: 0.35259515047073364
Batch 50/64 loss: 0.3463267683982849
Batch 51/64 loss: 0.3466343879699707
Batch 52/64 loss: 0.3513997197151184
Batch 53/64 loss: 0.35348260402679443
Batch 54/64 loss: 0.3499763011932373
Batch 55/64 loss: 0.34880971908569336
Batch 56/64 loss: 0.35363608598709106
Batch 57/64 loss: 0.3494749069213867
Batch 58/64 loss: 0.3484914302825928
Batch 59/64 loss: 0.3497525453567505
Batch 60/64 loss: 0.35470664501190186
Batch 61/64 loss: 0.3534073829650879
Batch 62/64 loss: 0.34415698051452637
Batch 63/64 loss: 0.3508363962173462
Batch 64/64 loss: 0.3484078049659729
Epoch 64  Train loss: 0.34946668451907587  Val loss: 0.3531515000202402
Saving best model, epoch: 64
Epoch 65
-------------------------------
Batch 1/64 loss: 0.3474239706993103
Batch 2/64 loss: 0.35017549991607666
Batch 3/64 loss: 0.34711408615112305
Batch 4/64 loss: 0.3467833995819092
Batch 5/64 loss: 0.3546222448348999
Batch 6/64 loss: 0.3488880395889282
Batch 7/64 loss: 0.3523815870285034
Batch 8/64 loss: 0.3522294759750366
Batch 9/64 loss: 0.345791220664978
Batch 10/64 loss: 0.346429705619812
Batch 11/64 loss: 0.35267961025238037
Batch 12/64 loss: 0.3490179777145386
Batch 13/64 loss: 0.3527849316596985
Batch 14/64 loss: 0.35112208127975464
Batch 15/64 loss: 0.3462412357330322
Batch 16/64 loss: 0.3476361036300659
Batch 17/64 loss: 0.3540875315666199
Batch 18/64 loss: 0.3467097282409668
Batch 19/64 loss: 0.3432283401489258
Batch 20/64 loss: 0.34894388914108276
Batch 21/64 loss: 0.35187697410583496
Batch 22/64 loss: 0.35268521308898926
Batch 23/64 loss: 0.34938549995422363
Batch 24/64 loss: 0.3487107753753662
Batch 25/64 loss: 0.3486424684524536
Batch 26/64 loss: 0.3479619026184082
Batch 27/64 loss: 0.35028076171875
Batch 28/64 loss: 0.344873309135437
Batch 29/64 loss: 0.3515357971191406
Batch 30/64 loss: 0.35007429122924805
Batch 31/64 loss: 0.3507651090621948
Batch 32/64 loss: 0.3479492664337158
Batch 33/64 loss: 0.3548678755760193
Batch 34/64 loss: 0.3490934371948242
Batch 35/64 loss: 0.3483477234840393
Batch 36/64 loss: 0.35105258226394653
Batch 37/64 loss: 0.35038864612579346
Batch 38/64 loss: 0.34890687465667725
Batch 39/64 loss: 0.34909290075302124
Batch 40/64 loss: 0.34468895196914673
Batch 41/64 loss: 0.34894508123397827
Batch 42/64 loss: 0.3539344072341919
Batch 43/64 loss: 0.3537459373474121
Batch 44/64 loss: 0.3529350757598877
Batch 45/64 loss: 0.350482702255249
Batch 46/64 loss: 0.3518717288970947
Batch 47/64 loss: 0.352081298828125
Batch 48/64 loss: 0.3501918911933899
Batch 49/64 loss: 0.3494768738746643
Batch 50/64 loss: 0.3512897491455078
Batch 51/64 loss: 0.35175544023513794
Batch 52/64 loss: 0.3479844927787781
Batch 53/64 loss: 0.35151374340057373
Batch 54/64 loss: 0.34963876008987427
Batch 55/64 loss: 0.34908783435821533
Batch 56/64 loss: 0.3514931797981262
Batch 57/64 loss: 0.34904831647872925
Batch 58/64 loss: 0.35348474979400635
Batch 59/64 loss: 0.3484541177749634
Batch 60/64 loss: 0.34853774309158325
Batch 61/64 loss: 0.34885144233703613
Batch 62/64 loss: 0.34994637966156006
Batch 63/64 loss: 0.35210752487182617
Batch 64/64 loss: 0.3508530855178833
Epoch 65  Train loss: 0.34988971457761875  Val loss: 0.3546448413449055
Epoch 66
-------------------------------
Batch 1/64 loss: 0.3484410047531128
Batch 2/64 loss: 0.34848034381866455
Batch 3/64 loss: 0.35009318590164185
Batch 4/64 loss: 0.3480358123779297
Batch 5/64 loss: 0.34648799896240234
Batch 6/64 loss: 0.35455483198165894
Batch 7/64 loss: 0.3500198721885681
Batch 8/64 loss: 0.34983569383621216
Batch 9/64 loss: 0.3522760272026062
Batch 10/64 loss: 0.34489911794662476
Batch 11/64 loss: 0.3491036295890808
Batch 12/64 loss: 0.34927594661712646
Batch 13/64 loss: 0.3514084815979004
Batch 14/64 loss: 0.34876394271850586
Batch 15/64 loss: 0.34806156158447266
Batch 16/64 loss: 0.34645402431488037
Batch 17/64 loss: 0.35099494457244873
Batch 18/64 loss: 0.348783016204834
Batch 19/64 loss: 0.35617512464523315
Batch 20/64 loss: 0.35389280319213867
Batch 21/64 loss: 0.34665918350219727
Batch 22/64 loss: 0.3462948203086853
Batch 23/64 loss: 0.350810170173645
Batch 24/64 loss: 0.3480255603790283
Batch 25/64 loss: 0.3471735715866089
Batch 26/64 loss: 0.3478049039840698
Batch 27/64 loss: 0.3526275157928467
Batch 28/64 loss: 0.35230326652526855
Batch 29/64 loss: 0.3519071936607361
Batch 30/64 loss: 0.3498450517654419
Batch 31/64 loss: 0.3507930040359497
Batch 32/64 loss: 0.35032951831817627
Batch 33/64 loss: 0.35076475143432617
Batch 34/64 loss: 0.3530193567276001
Batch 35/64 loss: 0.3513023853302002
Batch 36/64 loss: 0.3495509624481201
Batch 37/64 loss: 0.3498256802558899
Batch 38/64 loss: 0.3517012596130371
Batch 39/64 loss: 0.34610414505004883
Batch 40/64 loss: 0.3480187654495239
Batch 41/64 loss: 0.3455547094345093
Batch 42/64 loss: 0.35272765159606934
Batch 43/64 loss: 0.3521648645401001
Batch 44/64 loss: 0.3483349680900574
Batch 45/64 loss: 0.3500978350639343
Batch 46/64 loss: 0.3506322503089905
Batch 47/64 loss: 0.3458595275878906
Batch 48/64 loss: 0.3523494005203247
Batch 49/64 loss: 0.34974074363708496
Batch 50/64 loss: 0.3523221015930176
Batch 51/64 loss: 0.34954798221588135
Batch 52/64 loss: 0.3470792770385742
Batch 53/64 loss: 0.3498151898384094
Batch 54/64 loss: 0.3471566438674927
Batch 55/64 loss: 0.3509182929992676
Batch 56/64 loss: 0.35036903619766235
Batch 57/64 loss: 0.3517586588859558
Batch 58/64 loss: 0.34937119483947754
Batch 59/64 loss: 0.35021018981933594
Batch 60/64 loss: 0.347267746925354
Batch 61/64 loss: 0.3506968021392822
Batch 62/64 loss: 0.346413791179657
Batch 63/64 loss: 0.347312331199646
Batch 64/64 loss: 0.3508709669113159
Epoch 66  Train loss: 0.3496745544321397  Val loss: 0.3534654731193359
Epoch 67
-------------------------------
Batch 1/64 loss: 0.3490327000617981
Batch 2/64 loss: 0.3509964346885681
Batch 3/64 loss: 0.3531644940376282
Batch 4/64 loss: 0.35241150856018066
Batch 5/64 loss: 0.34834861755371094
Batch 6/64 loss: 0.3481616973876953
Batch 7/64 loss: 0.3485541343688965
Batch 8/64 loss: 0.3476872444152832
Batch 9/64 loss: 0.34987175464630127
Batch 10/64 loss: 0.3519167900085449
Batch 11/64 loss: 0.35334622859954834
Batch 12/64 loss: 0.3472480773925781
Batch 13/64 loss: 0.34838175773620605
Batch 14/64 loss: 0.348793089389801
Batch 15/64 loss: 0.3512610197067261
Batch 16/64 loss: 0.35183119773864746
Batch 17/64 loss: 0.3527606725692749
Batch 18/64 loss: 0.3458433151245117
Batch 19/64 loss: 0.3498956561088562
Batch 20/64 loss: 0.3480207324028015
Batch 21/64 loss: 0.35150325298309326
Batch 22/64 loss: 0.34984999895095825
Batch 23/64 loss: 0.3513098359107971
Batch 24/64 loss: 0.3497389554977417
Batch 25/64 loss: 0.3476879596710205
Batch 26/64 loss: 0.34997379779815674
Batch 27/64 loss: 0.35316622257232666
Batch 28/64 loss: 0.3498663902282715
Batch 29/64 loss: 0.34896183013916016
Batch 30/64 loss: 0.3490157723426819
Batch 31/64 loss: 0.35149240493774414
Batch 32/64 loss: 0.3524981141090393
Batch 33/64 loss: 0.34944963455200195
Batch 34/64 loss: 0.3485078811645508
Batch 35/64 loss: 0.3495299220085144
Batch 36/64 loss: 0.3478891849517822
Batch 37/64 loss: 0.3466695547103882
Batch 38/64 loss: 0.3463802933692932
Batch 39/64 loss: 0.3464629054069519
Batch 40/64 loss: 0.34672486782073975
Batch 41/64 loss: 0.35027170181274414
Batch 42/64 loss: 0.3466207981109619
Batch 43/64 loss: 0.3548527956008911
Batch 44/64 loss: 0.34971821308135986
Batch 45/64 loss: 0.3520700931549072
Batch 46/64 loss: 0.34727180004119873
Batch 47/64 loss: 0.3447321057319641
Batch 48/64 loss: 0.34848999977111816
Batch 49/64 loss: 0.35096681118011475
Batch 50/64 loss: 0.3457508087158203
Batch 51/64 loss: 0.34659528732299805
Batch 52/64 loss: 0.3471956253051758
Batch 53/64 loss: 0.3510892391204834
Batch 54/64 loss: 0.3510117530822754
Batch 55/64 loss: 0.3445699214935303
Batch 56/64 loss: 0.35557591915130615
Batch 57/64 loss: 0.3504842519760132
Batch 58/64 loss: 0.34558844566345215
Batch 59/64 loss: 0.35048431158065796
Batch 60/64 loss: 0.3497657775878906
Batch 61/64 loss: 0.3458571434020996
Batch 62/64 loss: 0.3537144660949707
Batch 63/64 loss: 0.34995996952056885
Batch 64/64 loss: 0.34513747692108154
Epoch 67  Train loss: 0.3494226862402523  Val loss: 0.35324322685752946
Epoch 68
-------------------------------
Batch 1/64 loss: 0.35000741481781006
Batch 2/64 loss: 0.3494430184364319
Batch 3/64 loss: 0.3522684574127197
Batch 4/64 loss: 0.3455183506011963
Batch 5/64 loss: 0.34873539209365845
Batch 6/64 loss: 0.3508222699165344
Batch 7/64 loss: 0.34499073028564453
Batch 8/64 loss: 0.3518637418746948
Batch 9/64 loss: 0.3460754156112671
Batch 10/64 loss: 0.346996545791626
Batch 11/64 loss: 0.34649646282196045
Batch 12/64 loss: 0.3440697193145752
Batch 13/64 loss: 0.3500574827194214
Batch 14/64 loss: 0.347001314163208
Batch 15/64 loss: 0.35053277015686035
Batch 16/64 loss: 0.34838855266571045
Batch 17/64 loss: 0.3505796194076538
Batch 18/64 loss: 0.34737563133239746
Batch 19/64 loss: 0.35437268018722534
Batch 20/64 loss: 0.3533223867416382
Batch 21/64 loss: 0.34741127490997314
Batch 22/64 loss: 0.34826183319091797
Batch 23/64 loss: 0.3487219214439392
Batch 24/64 loss: 0.35247600078582764
Batch 25/64 loss: 0.34944015741348267
Batch 26/64 loss: 0.3481888771057129
Batch 27/64 loss: 0.3463725447654724
Batch 28/64 loss: 0.3492637872695923
Batch 29/64 loss: 0.3471074104309082
Batch 30/64 loss: 0.35290127992630005
Batch 31/64 loss: 0.3503221273422241
Batch 32/64 loss: 0.3483917713165283
Batch 33/64 loss: 0.34582555294036865
Batch 34/64 loss: 0.3482903838157654
Batch 35/64 loss: 0.3496479392051697
Batch 36/64 loss: 0.35116469860076904
Batch 37/64 loss: 0.35151588916778564
Batch 38/64 loss: 0.3534930944442749
Batch 39/64 loss: 0.34654951095581055
Batch 40/64 loss: 0.3497798442840576
Batch 41/64 loss: 0.3507312536239624
Batch 42/64 loss: 0.34737980365753174
Batch 43/64 loss: 0.34944379329681396
Batch 44/64 loss: 0.34679579734802246
Batch 45/64 loss: 0.34565049409866333
Batch 46/64 loss: 0.3495081067085266
Batch 47/64 loss: 0.34957432746887207
Batch 48/64 loss: 0.3489499092102051
Batch 49/64 loss: 0.3504401445388794
Batch 50/64 loss: 0.35254883766174316
Batch 51/64 loss: 0.34760230779647827
Batch 52/64 loss: 0.3470683693885803
Batch 53/64 loss: 0.3498219847679138
Batch 54/64 loss: 0.3488394021987915
Batch 55/64 loss: 0.35346710681915283
Batch 56/64 loss: 0.35070180892944336
Batch 57/64 loss: 0.3511083126068115
Batch 58/64 loss: 0.35189491510391235
Batch 59/64 loss: 0.3473770022392273
Batch 60/64 loss: 0.3444024920463562
Batch 61/64 loss: 0.347395658493042
Batch 62/64 loss: 0.35351085662841797
Batch 63/64 loss: 0.3497161269187927
Batch 64/64 loss: 0.34590965509414673
Epoch 68  Train loss: 0.3491357632711822  Val loss: 0.35285389341439577
Saving best model, epoch: 68
Epoch 69
-------------------------------
Batch 1/64 loss: 0.3472634553909302
Batch 2/64 loss: 0.34678030014038086
Batch 3/64 loss: 0.352929949760437
Batch 4/64 loss: 0.3453332185745239
Batch 5/64 loss: 0.34874463081359863
Batch 6/64 loss: 0.349567711353302
Batch 7/64 loss: 0.3442823886871338
Batch 8/64 loss: 0.34572529792785645
Batch 9/64 loss: 0.3454200029373169
Batch 10/64 loss: 0.34681570529937744
Batch 11/64 loss: 0.34999603033065796
Batch 12/64 loss: 0.34659671783447266
Batch 13/64 loss: 0.3522104024887085
Batch 14/64 loss: 0.3474659323692322
Batch 15/64 loss: 0.34738051891326904
Batch 16/64 loss: 0.34992098808288574
Batch 17/64 loss: 0.34773778915405273
Batch 18/64 loss: 0.3478180766105652
Batch 19/64 loss: 0.35380077362060547
Batch 20/64 loss: 0.3478546142578125
Batch 21/64 loss: 0.3454369306564331
Batch 22/64 loss: 0.35288912057876587
Batch 23/64 loss: 0.34906482696533203
Batch 24/64 loss: 0.3489503264427185
Batch 25/64 loss: 0.3497639298439026
Batch 26/64 loss: 0.34770822525024414
Batch 27/64 loss: 0.3506460189819336
Batch 28/64 loss: 0.35225164890289307
Batch 29/64 loss: 0.3502131700515747
Batch 30/64 loss: 0.3490784764289856
Batch 31/64 loss: 0.3443930149078369
Batch 32/64 loss: 0.34547698497772217
Batch 33/64 loss: 0.3490638732910156
Batch 34/64 loss: 0.3527944087982178
Batch 35/64 loss: 0.34784603118896484
Batch 36/64 loss: 0.34246861934661865
Batch 37/64 loss: 0.34772199392318726
Batch 38/64 loss: 0.34967076778411865
Batch 39/64 loss: 0.3477731943130493
Batch 40/64 loss: 0.3472442626953125
Batch 41/64 loss: 0.34951478242874146
Batch 42/64 loss: 0.3503994941711426
Batch 43/64 loss: 0.34531426429748535
Batch 44/64 loss: 0.3490392565727234
Batch 45/64 loss: 0.3492887020111084
Batch 46/64 loss: 0.35225218534469604
Batch 47/64 loss: 0.3468165397644043
Batch 48/64 loss: 0.3517416715621948
Batch 49/64 loss: 0.34590625762939453
Batch 50/64 loss: 0.3545048236846924
Batch 51/64 loss: 0.35603004693984985
Batch 52/64 loss: 0.3504105806350708
Batch 53/64 loss: 0.3487892150878906
Batch 54/64 loss: 0.3532058000564575
Batch 55/64 loss: 0.3502962589263916
Batch 56/64 loss: 0.3407400846481323
Batch 57/64 loss: 0.3507426977157593
Batch 58/64 loss: 0.35209470987319946
Batch 59/64 loss: 0.35115039348602295
Batch 60/64 loss: 0.348019003868103
Batch 61/64 loss: 0.34978336095809937
Batch 62/64 loss: 0.34876811504364014
Batch 63/64 loss: 0.35082554817199707
Batch 64/64 loss: 0.34913837909698486
Epoch 69  Train loss: 0.34888765344432754  Val loss: 0.35244632422719213
Saving best model, epoch: 69
Epoch 70
-------------------------------
Batch 1/64 loss: 0.3469141125679016
Batch 2/64 loss: 0.3488568067550659
Batch 3/64 loss: 0.349850058555603
Batch 4/64 loss: 0.3468950390815735
Batch 5/64 loss: 0.3487595319747925
Batch 6/64 loss: 0.35058867931365967
Batch 7/64 loss: 0.34760499000549316
Batch 8/64 loss: 0.34733402729034424
Batch 9/64 loss: 0.3468809127807617
Batch 10/64 loss: 0.35458076000213623
Batch 11/64 loss: 0.34515559673309326
Batch 12/64 loss: 0.35354673862457275
Batch 13/64 loss: 0.34800881147384644
Batch 14/64 loss: 0.35001981258392334
Batch 15/64 loss: 0.35052287578582764
Batch 16/64 loss: 0.34662437438964844
Batch 17/64 loss: 0.34478747844696045
Batch 18/64 loss: 0.3467317223548889
Batch 19/64 loss: 0.35045909881591797
Batch 20/64 loss: 0.3507969379425049
Batch 21/64 loss: 0.34968364238739014
Batch 22/64 loss: 0.346693754196167
Batch 23/64 loss: 0.3482930064201355
Batch 24/64 loss: 0.3456794023513794
Batch 25/64 loss: 0.34857451915740967
Batch 26/64 loss: 0.34553229808807373
Batch 27/64 loss: 0.34629178047180176
Batch 28/64 loss: 0.35161375999450684
Batch 29/64 loss: 0.34744012355804443
Batch 30/64 loss: 0.34272491931915283
Batch 31/64 loss: 0.34945982694625854
Batch 32/64 loss: 0.3519120216369629
Batch 33/64 loss: 0.35093414783477783
Batch 34/64 loss: 0.3469899296760559
Batch 35/64 loss: 0.3465524911880493
Batch 36/64 loss: 0.3489283323287964
Batch 37/64 loss: 0.34593021869659424
Batch 38/64 loss: 0.34639978408813477
Batch 39/64 loss: 0.35144615173339844
Batch 40/64 loss: 0.34277665615081787
Batch 41/64 loss: 0.3452446460723877
Batch 42/64 loss: 0.3489672541618347
Batch 43/64 loss: 0.3501380681991577
Batch 44/64 loss: 0.3499685525894165
Batch 45/64 loss: 0.3537214994430542
Batch 46/64 loss: 0.3452955484390259
Batch 47/64 loss: 0.34832239151000977
Batch 48/64 loss: 0.3539808392524719
Batch 49/64 loss: 0.3521842360496521
Batch 50/64 loss: 0.3456372022628784
Batch 51/64 loss: 0.34690821170806885
Batch 52/64 loss: 0.35045015811920166
Batch 53/64 loss: 0.34915363788604736
Batch 54/64 loss: 0.3490234613418579
Batch 55/64 loss: 0.34672945737838745
Batch 56/64 loss: 0.3471987247467041
Batch 57/64 loss: 0.34953200817108154
Batch 58/64 loss: 0.350311279296875
Batch 59/64 loss: 0.3491218686103821
Batch 60/64 loss: 0.35155653953552246
Batch 61/64 loss: 0.3500281572341919
Batch 62/64 loss: 0.3505300283432007
Batch 63/64 loss: 0.34998881816864014
Batch 64/64 loss: 0.34811723232269287
Epoch 70  Train loss: 0.3486095003053254  Val loss: 0.3524907331696081
Epoch 71
-------------------------------
Batch 1/64 loss: 0.34453338384628296
Batch 2/64 loss: 0.3502563238143921
Batch 3/64 loss: 0.3479447364807129
Batch 4/64 loss: 0.3461894392967224
Batch 5/64 loss: 0.34806376695632935
Batch 6/64 loss: 0.3508549928665161
Batch 7/64 loss: 0.34879881143569946
Batch 8/64 loss: 0.3486952781677246
Batch 9/64 loss: 0.34859079122543335
Batch 10/64 loss: 0.3476985692977905
Batch 11/64 loss: 0.35206425189971924
Batch 12/64 loss: 0.35160648822784424
Batch 13/64 loss: 0.3452775478363037
Batch 14/64 loss: 0.3481881618499756
Batch 15/64 loss: 0.3472414016723633
Batch 16/64 loss: 0.34377026557922363
Batch 17/64 loss: 0.35107874870300293
Batch 18/64 loss: 0.3519221544265747
Batch 19/64 loss: 0.3460105061531067
Batch 20/64 loss: 0.3478062152862549
Batch 21/64 loss: 0.3494962453842163
Batch 22/64 loss: 0.3492492437362671
Batch 23/64 loss: 0.3507995009422302
Batch 24/64 loss: 0.351359486579895
Batch 25/64 loss: 0.3470304608345032
Batch 26/64 loss: 0.34848666191101074
Batch 27/64 loss: 0.34786468744277954
Batch 28/64 loss: 0.34928977489471436
Batch 29/64 loss: 0.34932589530944824
Batch 30/64 loss: 0.3508791923522949
Batch 31/64 loss: 0.34911084175109863
Batch 32/64 loss: 0.34868937730789185
Batch 33/64 loss: 0.3460162878036499
Batch 34/64 loss: 0.3494689464569092
Batch 35/64 loss: 0.3508785367012024
Batch 36/64 loss: 0.3495161533355713
Batch 37/64 loss: 0.34458571672439575
Batch 38/64 loss: 0.34953105449676514
Batch 39/64 loss: 0.3521536588668823
Batch 40/64 loss: 0.35037660598754883
Batch 41/64 loss: 0.3472325801849365
Batch 42/64 loss: 0.347506046295166
Batch 43/64 loss: 0.3505708575248718
Batch 44/64 loss: 0.3499712347984314
Batch 45/64 loss: 0.35349345207214355
Batch 46/64 loss: 0.344951868057251
Batch 47/64 loss: 0.3448830246925354
Batch 48/64 loss: 0.3476499319076538
Batch 49/64 loss: 0.3516996502876282
Batch 50/64 loss: 0.3466305136680603
Batch 51/64 loss: 0.3456975221633911
Batch 52/64 loss: 0.35066938400268555
Batch 53/64 loss: 0.3468480706214905
Batch 54/64 loss: 0.3491692543029785
Batch 55/64 loss: 0.34580546617507935
Batch 56/64 loss: 0.3501034379005432
Batch 57/64 loss: 0.3507764935493469
Batch 58/64 loss: 0.3486661911010742
Batch 59/64 loss: 0.3478553295135498
Batch 60/64 loss: 0.35093700885772705
Batch 61/64 loss: 0.3502105474472046
Batch 62/64 loss: 0.343017578125
Batch 63/64 loss: 0.3482269048690796
Batch 64/64 loss: 0.35395699739456177
Epoch 71  Train loss: 0.34868612172556857  Val loss: 0.35362263110904757
Epoch 72
-------------------------------
Batch 1/64 loss: 0.3494149446487427
Batch 2/64 loss: 0.3493015766143799
Batch 3/64 loss: 0.347520112991333
Batch 4/64 loss: 0.34688127040863037
Batch 5/64 loss: 0.348169207572937
Batch 6/64 loss: 0.34680700302124023
Batch 7/64 loss: 0.3473426103591919
Batch 8/64 loss: 0.3468487858772278
Batch 9/64 loss: 0.3515070676803589
Batch 10/64 loss: 0.35023486614227295
Batch 11/64 loss: 0.3491683006286621
Batch 12/64 loss: 0.3489987254142761
Batch 13/64 loss: 0.3518219590187073
Batch 14/64 loss: 0.3457636833190918
Batch 15/64 loss: 0.3496971130371094
Batch 16/64 loss: 0.35098445415496826
Batch 17/64 loss: 0.34983497858047485
Batch 18/64 loss: 0.35070091485977173
Batch 19/64 loss: 0.3480013608932495
Batch 20/64 loss: 0.3488503694534302
Batch 21/64 loss: 0.3500109314918518
Batch 22/64 loss: 0.3498857021331787
Batch 23/64 loss: 0.3449515104293823
Batch 24/64 loss: 0.35544800758361816
Batch 25/64 loss: 0.3521733283996582
Batch 26/64 loss: 0.3483325242996216
Batch 27/64 loss: 0.34831929206848145
Batch 28/64 loss: 0.34746038913726807
Batch 29/64 loss: 0.34923261404037476
Batch 30/64 loss: 0.3458430767059326
Batch 31/64 loss: 0.34949254989624023
Batch 32/64 loss: 0.3486303687095642
Batch 33/64 loss: 0.3468492031097412
Batch 34/64 loss: 0.3481457829475403
Batch 35/64 loss: 0.35379743576049805
Batch 36/64 loss: 0.3497210741043091
Batch 37/64 loss: 0.34820425510406494
Batch 38/64 loss: 0.3527200222015381
Batch 39/64 loss: 0.3440042734146118
Batch 40/64 loss: 0.34610629081726074
Batch 41/64 loss: 0.35204577445983887
Batch 42/64 loss: 0.35083794593811035
Batch 43/64 loss: 0.34840255975723267
Batch 44/64 loss: 0.34433144330978394
Batch 45/64 loss: 0.3527160882949829
Batch 46/64 loss: 0.3473483920097351
Batch 47/64 loss: 0.34700560569763184
Batch 48/64 loss: 0.3475520610809326
Batch 49/64 loss: 0.3472326993942261
Batch 50/64 loss: 0.35125744342803955
Batch 51/64 loss: 0.3517742156982422
Batch 52/64 loss: 0.35001564025878906
Batch 53/64 loss: 0.35021406412124634
Batch 54/64 loss: 0.3457825183868408
Batch 55/64 loss: 0.3485698699951172
Batch 56/64 loss: 0.3507767915725708
Batch 57/64 loss: 0.34952592849731445
Batch 58/64 loss: 0.34949982166290283
Batch 59/64 loss: 0.34713321924209595
Batch 60/64 loss: 0.3456769585609436
Batch 61/64 loss: 0.34429287910461426
Batch 62/64 loss: 0.34971708059310913
Batch 63/64 loss: 0.3477899432182312
Batch 64/64 loss: 0.3452375531196594
Epoch 72  Train loss: 0.34879380464553833  Val loss: 0.35299221572187756
Epoch 73
-------------------------------
Batch 1/64 loss: 0.3498607277870178
Batch 2/64 loss: 0.34897422790527344
Batch 3/64 loss: 0.3453183174133301
Batch 4/64 loss: 0.35043632984161377
Batch 5/64 loss: 0.34717416763305664
Batch 6/64 loss: 0.34731316566467285
Batch 7/64 loss: 0.35011106729507446
Batch 8/64 loss: 0.34846067428588867
Batch 9/64 loss: 0.34793078899383545
Batch 10/64 loss: 0.3505861163139343
Batch 11/64 loss: 0.35002774000167847
Batch 12/64 loss: 0.3439880609512329
Batch 13/64 loss: 0.34569525718688965
Batch 14/64 loss: 0.34589123725891113
Batch 15/64 loss: 0.35065752267837524
Batch 16/64 loss: 0.35218167304992676
Batch 17/64 loss: 0.344585657119751
Batch 18/64 loss: 0.3444710373878479
Batch 19/64 loss: 0.34710192680358887
Batch 20/64 loss: 0.353240430355072
Batch 21/64 loss: 0.3498424291610718
Batch 22/64 loss: 0.3480972647666931
Batch 23/64 loss: 0.35167044401168823
Batch 24/64 loss: 0.34542912244796753
Batch 25/64 loss: 0.34946292638778687
Batch 26/64 loss: 0.34918057918548584
Batch 27/64 loss: 0.3484914302825928
Batch 28/64 loss: 0.3457311987876892
Batch 29/64 loss: 0.3487800359725952
Batch 30/64 loss: 0.3485165238380432
Batch 31/64 loss: 0.3444167375564575
Batch 32/64 loss: 0.3486672043800354
Batch 33/64 loss: 0.35277754068374634
Batch 34/64 loss: 0.3439038395881653
Batch 35/64 loss: 0.35033077001571655
Batch 36/64 loss: 0.35352134704589844
Batch 37/64 loss: 0.3465436100959778
Batch 38/64 loss: 0.3499135375022888
Batch 39/64 loss: 0.35063087940216064
Batch 40/64 loss: 0.34938180446624756
Batch 41/64 loss: 0.34907853603363037
Batch 42/64 loss: 0.3468092679977417
Batch 43/64 loss: 0.3501873016357422
Batch 44/64 loss: 0.3427952527999878
Batch 45/64 loss: 0.35220927000045776
Batch 46/64 loss: 0.35028696060180664
Batch 47/64 loss: 0.3489910364151001
Batch 48/64 loss: 0.35022884607315063
Batch 49/64 loss: 0.34941476583480835
Batch 50/64 loss: 0.3485894203186035
Batch 51/64 loss: 0.34573447704315186
Batch 52/64 loss: 0.34944039583206177
Batch 53/64 loss: 0.34817272424697876
Batch 54/64 loss: 0.34691953659057617
Batch 55/64 loss: 0.3494252562522888
Batch 56/64 loss: 0.35327208042144775
Batch 57/64 loss: 0.34839296340942383
Batch 58/64 loss: 0.35017192363739014
Batch 59/64 loss: 0.3451440930366516
Batch 60/64 loss: 0.35064244270324707
Batch 61/64 loss: 0.35061073303222656
Batch 62/64 loss: 0.34823280572891235
Batch 63/64 loss: 0.3491213321685791
Batch 64/64 loss: 0.34508198499679565
Epoch 73  Train loss: 0.34858005116967594  Val loss: 0.35262322753565417
Epoch 74
-------------------------------
Batch 1/64 loss: 0.345831036567688
Batch 2/64 loss: 0.3471391201019287
Batch 3/64 loss: 0.34986990690231323
Batch 4/64 loss: 0.35131680965423584
Batch 5/64 loss: 0.34686148166656494
Batch 6/64 loss: 0.35065996646881104
Batch 7/64 loss: 0.3474719524383545
Batch 8/64 loss: 0.34891194105148315
Batch 9/64 loss: 0.34814202785491943
Batch 10/64 loss: 0.3474767208099365
Batch 11/64 loss: 0.3500267267227173
Batch 12/64 loss: 0.3499526381492615
Batch 13/64 loss: 0.34832215309143066
Batch 14/64 loss: 0.3497278690338135
Batch 15/64 loss: 0.3498882055282593
Batch 16/64 loss: 0.3485441207885742
Batch 17/64 loss: 0.34987401962280273
Batch 18/64 loss: 0.3481370210647583
Batch 19/64 loss: 0.34687113761901855
Batch 20/64 loss: 0.34840667247772217
Batch 21/64 loss: 0.3474828600883484
Batch 22/64 loss: 0.34614813327789307
Batch 23/64 loss: 0.3427189588546753
Batch 24/64 loss: 0.35020244121551514
Batch 25/64 loss: 0.34494543075561523
Batch 26/64 loss: 0.34966176748275757
Batch 27/64 loss: 0.34919774532318115
Batch 28/64 loss: 0.348932147026062
Batch 29/64 loss: 0.3484560251235962
Batch 30/64 loss: 0.34886598587036133
Batch 31/64 loss: 0.3503078818321228
Batch 32/64 loss: 0.3461262583732605
Batch 33/64 loss: 0.3552027940750122
Batch 34/64 loss: 0.3493121862411499
Batch 35/64 loss: 0.34952378273010254
Batch 36/64 loss: 0.3466074466705322
Batch 37/64 loss: 0.3485800623893738
Batch 38/64 loss: 0.3467053174972534
Batch 39/64 loss: 0.35193562507629395
Batch 40/64 loss: 0.34966814517974854
Batch 41/64 loss: 0.34957969188690186
Batch 42/64 loss: 0.3504432439804077
Batch 43/64 loss: 0.3485187292098999
Batch 44/64 loss: 0.35035455226898193
Batch 45/64 loss: 0.34993720054626465
Batch 46/64 loss: 0.3489975333213806
Batch 47/64 loss: 0.34833836555480957
Batch 48/64 loss: 0.34551215171813965
Batch 49/64 loss: 0.3459931015968323
Batch 50/64 loss: 0.34810811281204224
Batch 51/64 loss: 0.3501262664794922
Batch 52/64 loss: 0.34488022327423096
Batch 53/64 loss: 0.3503914475440979
Batch 54/64 loss: 0.34780561923980713
Batch 55/64 loss: 0.3476388454437256
Batch 56/64 loss: 0.3461350202560425
Batch 57/64 loss: 0.3483259677886963
Batch 58/64 loss: 0.35153019428253174
Batch 59/64 loss: 0.34973907470703125
Batch 60/64 loss: 0.35028934478759766
Batch 61/64 loss: 0.3490462303161621
Batch 62/64 loss: 0.3433551788330078
Batch 63/64 loss: 0.3481767773628235
Batch 64/64 loss: 0.3517458438873291
Epoch 74  Train loss: 0.3485654082952761  Val loss: 0.3522395987281275
Saving best model, epoch: 74
Epoch 75
-------------------------------
Batch 1/64 loss: 0.3506143093109131
Batch 2/64 loss: 0.34907281398773193
Batch 3/64 loss: 0.35063427686691284
Batch 4/64 loss: 0.34648972749710083
Batch 5/64 loss: 0.347270131111145
Batch 6/64 loss: 0.3477466106414795
Batch 7/64 loss: 0.34662818908691406
Batch 8/64 loss: 0.3441781997680664
Batch 9/64 loss: 0.3496864438056946
Batch 10/64 loss: 0.34426867961883545
Batch 11/64 loss: 0.3479858636856079
Batch 12/64 loss: 0.34663498401641846
Batch 13/64 loss: 0.3464656472206116
Batch 14/64 loss: 0.34574562311172485
Batch 15/64 loss: 0.3508773446083069
Batch 16/64 loss: 0.3473249077796936
Batch 17/64 loss: 0.34734779596328735
Batch 18/64 loss: 0.34938502311706543
Batch 19/64 loss: 0.34902894496917725
Batch 20/64 loss: 0.35302144289016724
Batch 21/64 loss: 0.34267759323120117
Batch 22/64 loss: 0.3479762673377991
Batch 23/64 loss: 0.3443758487701416
Batch 24/64 loss: 0.3511749505996704
Batch 25/64 loss: 0.34954172372817993
Batch 26/64 loss: 0.34830379486083984
Batch 27/64 loss: 0.34818559885025024
Batch 28/64 loss: 0.344643771648407
Batch 29/64 loss: 0.34855616092681885
Batch 30/64 loss: 0.34697431325912476
Batch 31/64 loss: 0.34616929292678833
Batch 32/64 loss: 0.3499385118484497
Batch 33/64 loss: 0.3489053249359131
Batch 34/64 loss: 0.34736907482147217
Batch 35/64 loss: 0.35254406929016113
Batch 36/64 loss: 0.351492702960968
Batch 37/64 loss: 0.351540744304657
Batch 38/64 loss: 0.3525838851928711
Batch 39/64 loss: 0.34690093994140625
Batch 40/64 loss: 0.3461266756057739
Batch 41/64 loss: 0.3441370725631714
Batch 42/64 loss: 0.3514409065246582
Batch 43/64 loss: 0.3474595546722412
Batch 44/64 loss: 0.3484819531440735
Batch 45/64 loss: 0.34634995460510254
Batch 46/64 loss: 0.3492708206176758
Batch 47/64 loss: 0.34940338134765625
Batch 48/64 loss: 0.3524003028869629
Batch 49/64 loss: 0.3495740294456482
Batch 50/64 loss: 0.3498591184616089
Batch 51/64 loss: 0.3426971435546875
Batch 52/64 loss: 0.3453812599182129
Batch 53/64 loss: 0.3506587743759155
Batch 54/64 loss: 0.34788984060287476
Batch 55/64 loss: 0.34992337226867676
Batch 56/64 loss: 0.3494532108306885
Batch 57/64 loss: 0.3521541357040405
Batch 58/64 loss: 0.3444474935531616
Batch 59/64 loss: 0.34656763076782227
Batch 60/64 loss: 0.3428536653518677
Batch 61/64 loss: 0.34722232818603516
Batch 62/64 loss: 0.3478301763534546
Batch 63/64 loss: 0.35082000494003296
Batch 64/64 loss: 0.3459409475326538
Epoch 75  Train loss: 0.34811168698703543  Val loss: 0.35188122918106024
Saving best model, epoch: 75
Epoch 76
-------------------------------
Batch 1/64 loss: 0.3500855565071106
Batch 2/64 loss: 0.3532392978668213
Batch 3/64 loss: 0.347292959690094
Batch 4/64 loss: 0.3441012501716614
Batch 5/64 loss: 0.35067588090896606
Batch 6/64 loss: 0.3435983657836914
Batch 7/64 loss: 0.34686601161956787
Batch 8/64 loss: 0.3475145101547241
Batch 9/64 loss: 0.34923017024993896
Batch 10/64 loss: 0.34803974628448486
Batch 11/64 loss: 0.3473402261734009
Batch 12/64 loss: 0.34798097610473633
Batch 13/64 loss: 0.3503073453903198
Batch 14/64 loss: 0.3492673635482788
Batch 15/64 loss: 0.34702080488204956
Batch 16/64 loss: 0.3443152904510498
Batch 17/64 loss: 0.3481904864311218
Batch 18/64 loss: 0.34729284048080444
Batch 19/64 loss: 0.34873735904693604
Batch 20/64 loss: 0.34844350814819336
Batch 21/64 loss: 0.34501397609710693
Batch 22/64 loss: 0.34996020793914795
Batch 23/64 loss: 0.35068297386169434
Batch 24/64 loss: 0.34381556510925293
Batch 25/64 loss: 0.34831762313842773
Batch 26/64 loss: 0.3460550308227539
Batch 27/64 loss: 0.3428671360015869
Batch 28/64 loss: 0.3510247468948364
Batch 29/64 loss: 0.3517792820930481
Batch 30/64 loss: 0.34749889373779297
Batch 31/64 loss: 0.3497990369796753
Batch 32/64 loss: 0.3437073230743408
Batch 33/64 loss: 0.34772825241088867
Batch 34/64 loss: 0.346341609954834
Batch 35/64 loss: 0.3446955680847168
Batch 36/64 loss: 0.3521538972854614
Batch 37/64 loss: 0.3496363162994385
Batch 38/64 loss: 0.34938228130340576
Batch 39/64 loss: 0.3470192551612854
Batch 40/64 loss: 0.3482012152671814
Batch 41/64 loss: 0.34658557176589966
Batch 42/64 loss: 0.3491706848144531
Batch 43/64 loss: 0.34924525022506714
Batch 44/64 loss: 0.3485848307609558
Batch 45/64 loss: 0.35292088985443115
Batch 46/64 loss: 0.3481794595718384
Batch 47/64 loss: 0.34988152980804443
Batch 48/64 loss: 0.3469393253326416
Batch 49/64 loss: 0.3456897735595703
Batch 50/64 loss: 0.3521904945373535
Batch 51/64 loss: 0.34615039825439453
Batch 52/64 loss: 0.3446815609931946
Batch 53/64 loss: 0.3489764332771301
Batch 54/64 loss: 0.3458162546157837
Batch 55/64 loss: 0.3459465503692627
Batch 56/64 loss: 0.3467101454734802
Batch 57/64 loss: 0.35193419456481934
Batch 58/64 loss: 0.34515607357025146
Batch 59/64 loss: 0.34661930799484253
Batch 60/64 loss: 0.34539157152175903
Batch 61/64 loss: 0.35285210609436035
Batch 62/64 loss: 0.3511381149291992
Batch 63/64 loss: 0.34886598587036133
Batch 64/64 loss: 0.3490343689918518
Epoch 76  Train loss: 0.34802544981825584  Val loss: 0.3534258427898499
Epoch 77
-------------------------------
Batch 1/64 loss: 0.3463701605796814
Batch 2/64 loss: 0.34822821617126465
Batch 3/64 loss: 0.3514796495437622
Batch 4/64 loss: 0.34451019763946533
Batch 5/64 loss: 0.3488858938217163
Batch 6/64 loss: 0.3482159376144409
Batch 7/64 loss: 0.3485218286514282
Batch 8/64 loss: 0.3517918586730957
Batch 9/64 loss: 0.34883105754852295
Batch 10/64 loss: 0.3498692512512207
Batch 11/64 loss: 0.3493396043777466
Batch 12/64 loss: 0.3458985686302185
Batch 13/64 loss: 0.3520500659942627
Batch 14/64 loss: 0.3499882221221924
Batch 15/64 loss: 0.3468558192253113
Batch 16/64 loss: 0.3474322557449341
Batch 17/64 loss: 0.3495996594429016
Batch 18/64 loss: 0.35027289390563965
Batch 19/64 loss: 0.34671294689178467
Batch 20/64 loss: 0.3477652072906494
Batch 21/64 loss: 0.3472045660018921
Batch 22/64 loss: 0.34805333614349365
Batch 23/64 loss: 0.3479374051094055
Batch 24/64 loss: 0.34952259063720703
Batch 25/64 loss: 0.34871387481689453
Batch 26/64 loss: 0.34715795516967773
Batch 27/64 loss: 0.34732913970947266
Batch 28/64 loss: 0.34979569911956787
Batch 29/64 loss: 0.3500845432281494
Batch 30/64 loss: 0.3463982343673706
Batch 31/64 loss: 0.3513737916946411
Batch 32/64 loss: 0.3469890356063843
Batch 33/64 loss: 0.3479585647583008
Batch 34/64 loss: 0.3478684425354004
Batch 35/64 loss: 0.3487762212753296
Batch 36/64 loss: 0.34600985050201416
Batch 37/64 loss: 0.34699374437332153
Batch 38/64 loss: 0.3460426330566406
Batch 39/64 loss: 0.35211169719696045
Batch 40/64 loss: 0.34776437282562256
Batch 41/64 loss: 0.35278570652008057
Batch 42/64 loss: 0.3482357859611511
Batch 43/64 loss: 0.3474884033203125
Batch 44/64 loss: 0.3477802276611328
Batch 45/64 loss: 0.3473365306854248
Batch 46/64 loss: 0.3490719795227051
Batch 47/64 loss: 0.34353071451187134
Batch 48/64 loss: 0.3451305031776428
Batch 49/64 loss: 0.3484795093536377
Batch 50/64 loss: 0.35367846488952637
Batch 51/64 loss: 0.34569984674453735
Batch 52/64 loss: 0.3477576971054077
Batch 53/64 loss: 0.35016852617263794
Batch 54/64 loss: 0.34919828176498413
Batch 55/64 loss: 0.34318214654922485
Batch 56/64 loss: 0.34544098377227783
Batch 57/64 loss: 0.34998178482055664
Batch 58/64 loss: 0.34483712911605835
Batch 59/64 loss: 0.346232533454895
Batch 60/64 loss: 0.3489592671394348
Batch 61/64 loss: 0.35463786125183105
Batch 62/64 loss: 0.35186493396759033
Batch 63/64 loss: 0.3450314402580261
Batch 64/64 loss: 0.3501410484313965
Epoch 77  Train loss: 0.34832660450654873  Val loss: 0.3521338574255455
Epoch 78
-------------------------------
Batch 1/64 loss: 0.3482942581176758
Batch 2/64 loss: 0.3479427099227905
Batch 3/64 loss: 0.34596073627471924
Batch 4/64 loss: 0.34869420528411865
Batch 5/64 loss: 0.34779107570648193
Batch 6/64 loss: 0.35034406185150146
Batch 7/64 loss: 0.34974825382232666
Batch 8/64 loss: 0.35093623399734497
Batch 9/64 loss: 0.34738004207611084
Batch 10/64 loss: 0.3508167862892151
Batch 11/64 loss: 0.34647923707962036
Batch 12/64 loss: 0.34869641065597534
Batch 13/64 loss: 0.35226303339004517
Batch 14/64 loss: 0.3466629385948181
Batch 15/64 loss: 0.3466372489929199
Batch 16/64 loss: 0.3503427505493164
Batch 17/64 loss: 0.348427414894104
Batch 18/64 loss: 0.3476623296737671
Batch 19/64 loss: 0.34636855125427246
Batch 20/64 loss: 0.35032421350479126
Batch 21/64 loss: 0.3472748398780823
Batch 22/64 loss: 0.343781054019928
Batch 23/64 loss: 0.34979069232940674
Batch 24/64 loss: 0.3476715087890625
Batch 25/64 loss: 0.3460257649421692
Batch 26/64 loss: 0.34592366218566895
Batch 27/64 loss: 0.34969329833984375
Batch 28/64 loss: 0.3488408923149109
Batch 29/64 loss: 0.3433416485786438
Batch 30/64 loss: 0.35123491287231445
Batch 31/64 loss: 0.3444894552230835
Batch 32/64 loss: 0.34593284130096436
Batch 33/64 loss: 0.34824109077453613
Batch 34/64 loss: 0.3439079523086548
Batch 35/64 loss: 0.3457467555999756
Batch 36/64 loss: 0.35039931535720825
Batch 37/64 loss: 0.35115379095077515
Batch 38/64 loss: 0.3411586880683899
Batch 39/64 loss: 0.3468061089515686
Batch 40/64 loss: 0.34414446353912354
Batch 41/64 loss: 0.34905707836151123
Batch 42/64 loss: 0.35307788848876953
Batch 43/64 loss: 0.3492703437805176
Batch 44/64 loss: 0.3463415503501892
Batch 45/64 loss: 0.34811246395111084
Batch 46/64 loss: 0.343183696269989
Batch 47/64 loss: 0.3514363765716553
Batch 48/64 loss: 0.3502384424209595
Batch 49/64 loss: 0.34874939918518066
Batch 50/64 loss: 0.34785616397857666
Batch 51/64 loss: 0.34614861011505127
Batch 52/64 loss: 0.3490515947341919
Batch 53/64 loss: 0.34995245933532715
Batch 54/64 loss: 0.34849119186401367
Batch 55/64 loss: 0.34264880418777466
Batch 56/64 loss: 0.3452274203300476
Batch 57/64 loss: 0.34796959161758423
Batch 58/64 loss: 0.3509540557861328
Batch 59/64 loss: 0.34870195388793945
Batch 60/64 loss: 0.34787213802337646
Batch 61/64 loss: 0.3488137722015381
Batch 62/64 loss: 0.34748977422714233
Batch 63/64 loss: 0.3469177484512329
Batch 64/64 loss: 0.35015106201171875
Epoch 78  Train loss: 0.3478824634178012  Val loss: 0.3516570821250837
Saving best model, epoch: 78
Epoch 79
-------------------------------
Batch 1/64 loss: 0.3464430570602417
Batch 2/64 loss: 0.34301722049713135
Batch 3/64 loss: 0.35004061460494995
Batch 4/64 loss: 0.3439584970474243
Batch 5/64 loss: 0.348858118057251
Batch 6/64 loss: 0.34972935914993286
Batch 7/64 loss: 0.3427464962005615
Batch 8/64 loss: 0.3414965867996216
Batch 9/64 loss: 0.3517240285873413
Batch 10/64 loss: 0.34848833084106445
Batch 11/64 loss: 0.3478107452392578
Batch 12/64 loss: 0.34379738569259644
Batch 13/64 loss: 0.3478965759277344
Batch 14/64 loss: 0.345866322517395
Batch 15/64 loss: 0.3479064106941223
Batch 16/64 loss: 0.3432602882385254
Batch 17/64 loss: 0.34859228134155273
Batch 18/64 loss: 0.3474060297012329
Batch 19/64 loss: 0.34930044412612915
Batch 20/64 loss: 0.3497124910354614
Batch 21/64 loss: 0.3510324954986572
Batch 22/64 loss: 0.34412455558776855
Batch 23/64 loss: 0.3434615135192871
Batch 24/64 loss: 0.35015273094177246
Batch 25/64 loss: 0.34850096702575684
Batch 26/64 loss: 0.3423595428466797
Batch 27/64 loss: 0.348361611366272
Batch 28/64 loss: 0.34760475158691406
Batch 29/64 loss: 0.35238999128341675
Batch 30/64 loss: 0.3440278172492981
Batch 31/64 loss: 0.34267866611480713
Batch 32/64 loss: 0.34760159254074097
Batch 33/64 loss: 0.3505621552467346
Batch 34/64 loss: 0.3495478630065918
Batch 35/64 loss: 0.34948599338531494
Batch 36/64 loss: 0.35066449642181396
Batch 37/64 loss: 0.35032355785369873
Batch 38/64 loss: 0.3475334644317627
Batch 39/64 loss: 0.3463470935821533
Batch 40/64 loss: 0.3447940945625305
Batch 41/64 loss: 0.3512216806411743
Batch 42/64 loss: 0.34628790616989136
Batch 43/64 loss: 0.346455454826355
Batch 44/64 loss: 0.34462714195251465
Batch 45/64 loss: 0.3517359495162964
Batch 46/64 loss: 0.3462035655975342
Batch 47/64 loss: 0.34703898429870605
Batch 48/64 loss: 0.34494078159332275
Batch 49/64 loss: 0.34955263137817383
Batch 50/64 loss: 0.34534233808517456
Batch 51/64 loss: 0.3476333022117615
Batch 52/64 loss: 0.34728777408599854
Batch 53/64 loss: 0.3402611017227173
Batch 54/64 loss: 0.3482125401496887
Batch 55/64 loss: 0.35058993101119995
Batch 56/64 loss: 0.3489319682121277
Batch 57/64 loss: 0.3504847288131714
Batch 58/64 loss: 0.34621870517730713
Batch 59/64 loss: 0.35105013847351074
Batch 60/64 loss: 0.34799492359161377
Batch 61/64 loss: 0.3493114113807678
Batch 62/64 loss: 0.34773385524749756
Batch 63/64 loss: 0.34646308422088623
Batch 64/64 loss: 0.34803307056427
Epoch 79  Train loss: 0.34739154413634654  Val loss: 0.35223553475645397
Epoch 80
-------------------------------
Batch 1/64 loss: 0.3487333059310913
Batch 2/64 loss: 0.3496466875076294
Batch 3/64 loss: 0.3514540195465088
Batch 4/64 loss: 0.3490544557571411
Batch 5/64 loss: 0.3488689064979553
Batch 6/64 loss: 0.3498116731643677
Batch 7/64 loss: 0.34696680307388306
Batch 8/64 loss: 0.34895116090774536
Batch 9/64 loss: 0.34709101915359497
Batch 10/64 loss: 0.3450441360473633
Batch 11/64 loss: 0.34629160165786743
Batch 12/64 loss: 0.3460906744003296
Batch 13/64 loss: 0.34985071420669556
Batch 14/64 loss: 0.348968505859375
Batch 15/64 loss: 0.34624719619750977
Batch 16/64 loss: 0.3488931655883789
Batch 17/64 loss: 0.3472023010253906
Batch 18/64 loss: 0.35003650188446045
Batch 19/64 loss: 0.3471325635910034
Batch 20/64 loss: 0.3479965329170227
Batch 21/64 loss: 0.34862852096557617
Batch 22/64 loss: 0.3476217985153198
Batch 23/64 loss: 0.34588491916656494
Batch 24/64 loss: 0.3478055000305176
Batch 25/64 loss: 0.34473681449890137
Batch 26/64 loss: 0.3468204736709595
Batch 27/64 loss: 0.3472723364830017
Batch 28/64 loss: 0.35102808475494385
Batch 29/64 loss: 0.3446037769317627
Batch 30/64 loss: 0.3479515314102173
Batch 31/64 loss: 0.34901124238967896
Batch 32/64 loss: 0.3495790958404541
Batch 33/64 loss: 0.34571707248687744
Batch 34/64 loss: 0.3421304225921631
Batch 35/64 loss: 0.3473206162452698
Batch 36/64 loss: 0.34953707456588745
Batch 37/64 loss: 0.3529655933380127
Batch 38/64 loss: 0.3466923236846924
Batch 39/64 loss: 0.345628023147583
Batch 40/64 loss: 0.3444477915763855
Batch 41/64 loss: 0.34551942348480225
Batch 42/64 loss: 0.34643101692199707
Batch 43/64 loss: 0.34814250469207764
Batch 44/64 loss: 0.3479963541030884
Batch 45/64 loss: 0.3423048257827759
Batch 46/64 loss: 0.3455701470375061
Batch 47/64 loss: 0.34524405002593994
Batch 48/64 loss: 0.3489276170730591
Batch 49/64 loss: 0.3485431671142578
Batch 50/64 loss: 0.35199856758117676
Batch 51/64 loss: 0.34861481189727783
Batch 52/64 loss: 0.35084760189056396
Batch 53/64 loss: 0.34347259998321533
Batch 54/64 loss: 0.3458176851272583
Batch 55/64 loss: 0.34130120277404785
Batch 56/64 loss: 0.3462486267089844
Batch 57/64 loss: 0.3482370972633362
Batch 58/64 loss: 0.34710001945495605
Batch 59/64 loss: 0.349354088306427
Batch 60/64 loss: 0.3476695418357849
Batch 61/64 loss: 0.3468131422996521
Batch 62/64 loss: 0.3501788377761841
Batch 63/64 loss: 0.34588128328323364
Batch 64/64 loss: 0.34683936834335327
Epoch 80  Train loss: 0.34748327334721885  Val loss: 0.3516152695691872
Saving best model, epoch: 80
Epoch 81
-------------------------------
Batch 1/64 loss: 0.34956085681915283
Batch 2/64 loss: 0.3491564989089966
Batch 3/64 loss: 0.33939313888549805
Batch 4/64 loss: 0.3489384651184082
Batch 5/64 loss: 0.3430516719818115
Batch 6/64 loss: 0.34523534774780273
Batch 7/64 loss: 0.3447418808937073
Batch 8/64 loss: 0.3498075604438782
Batch 9/64 loss: 0.34995079040527344
Batch 10/64 loss: 0.35005271434783936
Batch 11/64 loss: 0.3494833707809448
Batch 12/64 loss: 0.34982824325561523
Batch 13/64 loss: 0.34748804569244385
Batch 14/64 loss: 0.345678448677063
Batch 15/64 loss: 0.3455424904823303
Batch 16/64 loss: 0.3473053574562073
Batch 17/64 loss: 0.3431144952774048
Batch 18/64 loss: 0.34373706579208374
Batch 19/64 loss: 0.3430647850036621
Batch 20/64 loss: 0.3465588688850403
Batch 21/64 loss: 0.34865736961364746
Batch 22/64 loss: 0.34701061248779297
Batch 23/64 loss: 0.34748828411102295
Batch 24/64 loss: 0.3452397584915161
Batch 25/64 loss: 0.34421586990356445
Batch 26/64 loss: 0.3461723327636719
Batch 27/64 loss: 0.3470197916030884
Batch 28/64 loss: 0.34610307216644287
Batch 29/64 loss: 0.3505282998085022
Batch 30/64 loss: 0.34869635105133057
Batch 31/64 loss: 0.34239721298217773
Batch 32/64 loss: 0.343927800655365
Batch 33/64 loss: 0.3424774408340454
Batch 34/64 loss: 0.34729301929473877
Batch 35/64 loss: 0.3504589796066284
Batch 36/64 loss: 0.34992218017578125
Batch 37/64 loss: 0.3475765585899353
Batch 38/64 loss: 0.3465663194656372
Batch 39/64 loss: 0.3464754819869995
Batch 40/64 loss: 0.3494638204574585
Batch 41/64 loss: 0.3438894748687744
Batch 42/64 loss: 0.34819453954696655
Batch 43/64 loss: 0.3471708297729492
Batch 44/64 loss: 0.34453582763671875
Batch 45/64 loss: 0.35072219371795654
Batch 46/64 loss: 0.34918832778930664
Batch 47/64 loss: 0.34391283988952637
Batch 48/64 loss: 0.3488703966140747
Batch 49/64 loss: 0.353501558303833
Batch 50/64 loss: 0.34870070219039917
Batch 51/64 loss: 0.3511008024215698
Batch 52/64 loss: 0.34673160314559937
Batch 53/64 loss: 0.3464527130126953
Batch 54/64 loss: 0.34497129917144775
Batch 55/64 loss: 0.3512692451477051
Batch 56/64 loss: 0.34491872787475586
Batch 57/64 loss: 0.3450993299484253
Batch 58/64 loss: 0.3478471636772156
Batch 59/64 loss: 0.35191774368286133
Batch 60/64 loss: 0.3507305383682251
Batch 61/64 loss: 0.35283899307250977
Batch 62/64 loss: 0.3458362817764282
Batch 63/64 loss: 0.35229671001434326
Batch 64/64 loss: 0.33950018882751465
Epoch 81  Train loss: 0.3472110374301088  Val loss: 0.3513770275509235
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: 0.35071688890457153
Batch 2/64 loss: 0.34259867668151855
Batch 3/64 loss: 0.34288591146469116
Batch 4/64 loss: 0.3448268175125122
Batch 5/64 loss: 0.3438083529472351
Batch 6/64 loss: 0.35031986236572266
Batch 7/64 loss: 0.34471064805984497
Batch 8/64 loss: 0.34417611360549927
Batch 9/64 loss: 0.34482455253601074
Batch 10/64 loss: 0.3493257164955139
Batch 11/64 loss: 0.3473780155181885
Batch 12/64 loss: 0.3484094738960266
Batch 13/64 loss: 0.3468623161315918
Batch 14/64 loss: 0.3443431854248047
Batch 15/64 loss: 0.3457576036453247
Batch 16/64 loss: 0.3462831377983093
Batch 17/64 loss: 0.3418760299682617
Batch 18/64 loss: 0.34787988662719727
Batch 19/64 loss: 0.351310670375824
Batch 20/64 loss: 0.3480027914047241
Batch 21/64 loss: 0.3462255001068115
Batch 22/64 loss: 0.3474181890487671
Batch 23/64 loss: 0.3505406975746155
Batch 24/64 loss: 0.34337687492370605
Batch 25/64 loss: 0.3476080894470215
Batch 26/64 loss: 0.3468171954154968
Batch 27/64 loss: 0.351692259311676
Batch 28/64 loss: 0.3511812090873718
Batch 29/64 loss: 0.3463151454925537
Batch 30/64 loss: 0.3454446792602539
Batch 31/64 loss: 0.35166358947753906
Batch 32/64 loss: 0.34317392110824585
Batch 33/64 loss: 0.34474486112594604
Batch 34/64 loss: 0.3473726511001587
Batch 35/64 loss: 0.34676289558410645
Batch 36/64 loss: 0.3447759747505188
Batch 37/64 loss: 0.35055094957351685
Batch 38/64 loss: 0.3465691804885864
Batch 39/64 loss: 0.34852826595306396
Batch 40/64 loss: 0.34626877307891846
Batch 41/64 loss: 0.34245675802230835
Batch 42/64 loss: 0.34812039136886597
Batch 43/64 loss: 0.34968996047973633
Batch 44/64 loss: 0.3478670120239258
Batch 45/64 loss: 0.3452349901199341
Batch 46/64 loss: 0.34794437885284424
Batch 47/64 loss: 0.3486122488975525
Batch 48/64 loss: 0.3505915403366089
Batch 49/64 loss: 0.3504546880722046
Batch 50/64 loss: 0.3458545207977295
Batch 51/64 loss: 0.35035717487335205
Batch 52/64 loss: 0.34771764278411865
Batch 53/64 loss: 0.3439508080482483
Batch 54/64 loss: 0.3508749008178711
Batch 55/64 loss: 0.3489740490913391
Batch 56/64 loss: 0.3478129506111145
Batch 57/64 loss: 0.3457086682319641
Batch 58/64 loss: 0.34879136085510254
Batch 59/64 loss: 0.35123467445373535
Batch 60/64 loss: 0.34810781478881836
Batch 61/64 loss: 0.3486432433128357
Batch 62/64 loss: 0.34586644172668457
Batch 63/64 loss: 0.3478943109512329
Batch 64/64 loss: 0.3424363136291504
Epoch 82  Train loss: 0.3471829853805841  Val loss: 0.3516633871085046
Epoch 83
-------------------------------
Batch 1/64 loss: 0.3476055860519409
Batch 2/64 loss: 0.34581828117370605
Batch 3/64 loss: 0.347514808177948
Batch 4/64 loss: 0.3424793481826782
Batch 5/64 loss: 0.3477996587753296
Batch 6/64 loss: 0.35097169876098633
Batch 7/64 loss: 0.34738028049468994
Batch 8/64 loss: 0.3415316343307495
Batch 9/64 loss: 0.3425915241241455
Batch 10/64 loss: 0.34449684619903564
Batch 11/64 loss: 0.34026265144348145
Batch 12/64 loss: 0.348773717880249
Batch 13/64 loss: 0.3476293087005615
Batch 14/64 loss: 0.3448030948638916
Batch 15/64 loss: 0.34627223014831543
Batch 16/64 loss: 0.3470507860183716
Batch 17/64 loss: 0.3499378561973572
Batch 18/64 loss: 0.3473207354545593
Batch 19/64 loss: 0.34645193815231323
Batch 20/64 loss: 0.34774893522262573
Batch 21/64 loss: 0.34854745864868164
Batch 22/64 loss: 0.34822899103164673
Batch 23/64 loss: 0.34810972213745117
Batch 24/64 loss: 0.3470391035079956
Batch 25/64 loss: 0.3524969816207886
Batch 26/64 loss: 0.3492603302001953
Batch 27/64 loss: 0.3506026268005371
Batch 28/64 loss: 0.344287633895874
Batch 29/64 loss: 0.3492276668548584
Batch 30/64 loss: 0.348629891872406
Batch 31/64 loss: 0.34825193881988525
Batch 32/64 loss: 0.34912383556365967
Batch 33/64 loss: 0.34956657886505127
Batch 34/64 loss: 0.3449118733406067
Batch 35/64 loss: 0.34771865606307983
Batch 36/64 loss: 0.341678261756897
Batch 37/64 loss: 0.34315788745880127
Batch 38/64 loss: 0.3509746789932251
Batch 39/64 loss: 0.34749704599380493
Batch 40/64 loss: 0.3482867479324341
Batch 41/64 loss: 0.34899067878723145
Batch 42/64 loss: 0.34845948219299316
Batch 43/64 loss: 0.3467193841934204
Batch 44/64 loss: 0.34580886363983154
Batch 45/64 loss: 0.345125675201416
Batch 46/64 loss: 0.3428637981414795
Batch 47/64 loss: 0.3451794385910034
Batch 48/64 loss: 0.3476601839065552
Batch 49/64 loss: 0.34626901149749756
Batch 50/64 loss: 0.3483998775482178
Batch 51/64 loss: 0.34691399335861206
Batch 52/64 loss: 0.34678518772125244
Batch 53/64 loss: 0.3458768129348755
Batch 54/64 loss: 0.34660887718200684
Batch 55/64 loss: 0.3536263704299927
Batch 56/64 loss: 0.3461698293685913
Batch 57/64 loss: 0.3453853130340576
Batch 58/64 loss: 0.3449873924255371
Batch 59/64 loss: 0.35137009620666504
Batch 60/64 loss: 0.3471367359161377
Batch 61/64 loss: 0.34899669885635376
Batch 62/64 loss: 0.3451771140098572
Batch 63/64 loss: 0.34588146209716797
Batch 64/64 loss: 0.3514823913574219
Epoch 83  Train loss: 0.3470751827838374  Val loss: 0.3518397115759833
Epoch 84
-------------------------------
Batch 1/64 loss: 0.3474029302597046
Batch 2/64 loss: 0.3487131595611572
Batch 3/64 loss: 0.3491349220275879
Batch 4/64 loss: 0.3429945707321167
Batch 5/64 loss: 0.3443242311477661
Batch 6/64 loss: 0.349267840385437
Batch 7/64 loss: 0.34780246019363403
Batch 8/64 loss: 0.34905314445495605
Batch 9/64 loss: 0.3485349416732788
Batch 10/64 loss: 0.3451206088066101
Batch 11/64 loss: 0.34771275520324707
Batch 12/64 loss: 0.34965455532073975
Batch 13/64 loss: 0.3509124517440796
Batch 14/64 loss: 0.3465205430984497
Batch 15/64 loss: 0.3472294211387634
Batch 16/64 loss: 0.3479459285736084
Batch 17/64 loss: 0.346085786819458
Batch 18/64 loss: 0.3485637903213501
Batch 19/64 loss: 0.34545958042144775
Batch 20/64 loss: 0.35130226612091064
Batch 21/64 loss: 0.34536683559417725
Batch 22/64 loss: 0.35291481018066406
Batch 23/64 loss: 0.3434918522834778
Batch 24/64 loss: 0.34702229499816895
Batch 25/64 loss: 0.35120415687561035
Batch 26/64 loss: 0.35356199741363525
Batch 27/64 loss: 0.34678196907043457
Batch 28/64 loss: 0.3468262553215027
Batch 29/64 loss: 0.3452213406562805
Batch 30/64 loss: 0.3496556282043457
Batch 31/64 loss: 0.3448978066444397
Batch 32/64 loss: 0.3489607572555542
Batch 33/64 loss: 0.3485366702079773
Batch 34/64 loss: 0.34433311223983765
Batch 35/64 loss: 0.35220038890838623
Batch 36/64 loss: 0.34530067443847656
Batch 37/64 loss: 0.3463299870491028
Batch 38/64 loss: 0.3470498323440552
Batch 39/64 loss: 0.3427388668060303
Batch 40/64 loss: 0.348527193069458
Batch 41/64 loss: 0.3461655378341675
Batch 42/64 loss: 0.34402328729629517
Batch 43/64 loss: 0.34271693229675293
Batch 44/64 loss: 0.34663718938827515
Batch 45/64 loss: 0.3421964645385742
Batch 46/64 loss: 0.3469710946083069
Batch 47/64 loss: 0.34849095344543457
Batch 48/64 loss: 0.34653371572494507
Batch 49/64 loss: 0.34630662202835083
Batch 50/64 loss: 0.3480560779571533
Batch 51/64 loss: 0.3441634178161621
Batch 52/64 loss: 0.34311991930007935
Batch 53/64 loss: 0.34758132696151733
Batch 54/64 loss: 0.34820306301116943
Batch 55/64 loss: 0.34416747093200684
Batch 56/64 loss: 0.34897327423095703
Batch 57/64 loss: 0.3460967540740967
Batch 58/64 loss: 0.349590003490448
Batch 59/64 loss: 0.35132908821105957
Batch 60/64 loss: 0.34934693574905396
Batch 61/64 loss: 0.34982073307037354
Batch 62/64 loss: 0.34667837619781494
Batch 63/64 loss: 0.3476065397262573
Batch 64/64 loss: 0.3486001491546631
Epoch 84  Train loss: 0.3473079718795477  Val loss: 0.35198437471160365
Epoch 85
-------------------------------
Batch 1/64 loss: 0.34926486015319824
Batch 2/64 loss: 0.3444322347640991
Batch 3/64 loss: 0.34417760372161865
Batch 4/64 loss: 0.3501681685447693
Batch 5/64 loss: 0.3502453565597534
Batch 6/64 loss: 0.35069942474365234
Batch 7/64 loss: 0.3475682735443115
Batch 8/64 loss: 0.3434396982192993
Batch 9/64 loss: 0.34241950511932373
Batch 10/64 loss: 0.34420156478881836
Batch 11/64 loss: 0.34818458557128906
Batch 12/64 loss: 0.3459298610687256
Batch 13/64 loss: 0.3434028625488281
Batch 14/64 loss: 0.3477115035057068
Batch 15/64 loss: 0.34888756275177
Batch 16/64 loss: 0.3503817319869995
Batch 17/64 loss: 0.3459877371788025
Batch 18/64 loss: 0.34594476222991943
Batch 19/64 loss: 0.3433634638786316
Batch 20/64 loss: 0.35169118642807007
Batch 21/64 loss: 0.3432621955871582
Batch 22/64 loss: 0.34678196907043457
Batch 23/64 loss: 0.3501417636871338
Batch 24/64 loss: 0.3414704203605652
Batch 25/64 loss: 0.34387123584747314
Batch 26/64 loss: 0.34363389015197754
Batch 27/64 loss: 0.3443230390548706
Batch 28/64 loss: 0.3463122844696045
Batch 29/64 loss: 0.35076868534088135
Batch 30/64 loss: 0.34551626443862915
Batch 31/64 loss: 0.3511384129524231
Batch 32/64 loss: 0.3426436185836792
Batch 33/64 loss: 0.349135160446167
Batch 34/64 loss: 0.34807682037353516
Batch 35/64 loss: 0.3490523099899292
Batch 36/64 loss: 0.347625732421875
Batch 37/64 loss: 0.3447916507720947
Batch 38/64 loss: 0.34297919273376465
Batch 39/64 loss: 0.34233665466308594
Batch 40/64 loss: 0.3485984802246094
Batch 41/64 loss: 0.34899306297302246
Batch 42/64 loss: 0.34920763969421387
Batch 43/64 loss: 0.34538018703460693
Batch 44/64 loss: 0.3466932773590088
Batch 45/64 loss: 0.3471029996871948
Batch 46/64 loss: 0.3426056504249573
Batch 47/64 loss: 0.3481452465057373
Batch 48/64 loss: 0.35159897804260254
Batch 49/64 loss: 0.3480188846588135
Batch 50/64 loss: 0.3395439386367798
Batch 51/64 loss: 0.3476628065109253
Batch 52/64 loss: 0.3506467938423157
Batch 53/64 loss: 0.3487691879272461
Batch 54/64 loss: 0.34859681129455566
Batch 55/64 loss: 0.351098895072937
Batch 56/64 loss: 0.3418142795562744
Batch 57/64 loss: 0.3493694067001343
Batch 58/64 loss: 0.35061442852020264
Batch 59/64 loss: 0.34796929359436035
Batch 60/64 loss: 0.34511423110961914
Batch 61/64 loss: 0.34066230058670044
Batch 62/64 loss: 0.34736180305480957
Batch 63/64 loss: 0.34628069400787354
Batch 64/64 loss: 0.34585362672805786
Epoch 85  Train loss: 0.3467169058089163  Val loss: 0.35167894330631005
Epoch 86
-------------------------------
Batch 1/64 loss: 0.3429238796234131
Batch 2/64 loss: 0.35135066509246826
Batch 3/64 loss: 0.3422467112541199
Batch 4/64 loss: 0.34747791290283203
Batch 5/64 loss: 0.34402596950531006
Batch 6/64 loss: 0.3476067781448364
Batch 7/64 loss: 0.34802210330963135
Batch 8/64 loss: 0.3484804630279541
Batch 9/64 loss: 0.34141862392425537
Batch 10/64 loss: 0.3493318557739258
Batch 11/64 loss: 0.34336400032043457
Batch 12/64 loss: 0.3445654511451721
Batch 13/64 loss: 0.3483225107192993
Batch 14/64 loss: 0.34239423274993896
Batch 15/64 loss: 0.3490399718284607
Batch 16/64 loss: 0.3470880389213562
Batch 17/64 loss: 0.34371721744537354
Batch 18/64 loss: 0.3481859564781189
Batch 19/64 loss: 0.3465791344642639
Batch 20/64 loss: 0.34536606073379517
Batch 21/64 loss: 0.35233771800994873
Batch 22/64 loss: 0.34716933965682983
Batch 23/64 loss: 0.3471487760543823
Batch 24/64 loss: 0.3450981378555298
Batch 25/64 loss: 0.34515440464019775
Batch 26/64 loss: 0.3453580141067505
Batch 27/64 loss: 0.34741127490997314
Batch 28/64 loss: 0.3497995138168335
Batch 29/64 loss: 0.3450177311897278
Batch 30/64 loss: 0.3444783687591553
Batch 31/64 loss: 0.35358667373657227
Batch 32/64 loss: 0.3495136499404907
Batch 33/64 loss: 0.34629613161087036
Batch 34/64 loss: 0.3442264795303345
Batch 35/64 loss: 0.34798264503479004
Batch 36/64 loss: 0.3467112183570862
Batch 37/64 loss: 0.34475648403167725
Batch 38/64 loss: 0.34786367416381836
Batch 39/64 loss: 0.34637773036956787
Batch 40/64 loss: 0.34651756286621094
Batch 41/64 loss: 0.3477661609649658
Batch 42/64 loss: 0.34823405742645264
Batch 43/64 loss: 0.34796321392059326
Batch 44/64 loss: 0.3493579626083374
Batch 45/64 loss: 0.34681594371795654
Batch 46/64 loss: 0.34701573848724365
Batch 47/64 loss: 0.33918267488479614
Batch 48/64 loss: 0.34730255603790283
Batch 49/64 loss: 0.345625638961792
Batch 50/64 loss: 0.34649133682250977
Batch 51/64 loss: 0.347210168838501
Batch 52/64 loss: 0.3460644483566284
Batch 53/64 loss: 0.3483940362930298
Batch 54/64 loss: 0.34496641159057617
Batch 55/64 loss: 0.348352313041687
Batch 56/64 loss: 0.34355759620666504
Batch 57/64 loss: 0.3510280251502991
Batch 58/64 loss: 0.3480460047721863
Batch 59/64 loss: 0.3435887098312378
Batch 60/64 loss: 0.34515202045440674
Batch 61/64 loss: 0.34390920400619507
Batch 62/64 loss: 0.34461188316345215
Batch 63/64 loss: 0.3455353379249573
Batch 64/64 loss: 0.34593719244003296
Epoch 86  Train loss: 0.34650882202036243  Val loss: 0.35044433202120856
Saving best model, epoch: 86
Epoch 87
-------------------------------
Batch 1/64 loss: 0.34121716022491455
Batch 2/64 loss: 0.34755778312683105
Batch 3/64 loss: 0.3443772792816162
Batch 4/64 loss: 0.34871214628219604
Batch 5/64 loss: 0.34633868932724
Batch 6/64 loss: 0.34772348403930664
Batch 7/64 loss: 0.3444446325302124
Batch 8/64 loss: 0.3449397683143616
Batch 9/64 loss: 0.35252249240875244
Batch 10/64 loss: 0.34958416223526
Batch 11/64 loss: 0.3499959111213684
Batch 12/64 loss: 0.3441007137298584
Batch 13/64 loss: 0.3400360345840454
Batch 14/64 loss: 0.3446313142776489
Batch 15/64 loss: 0.3409310579299927
Batch 16/64 loss: 0.3466736078262329
Batch 17/64 loss: 0.34921491146087646
Batch 18/64 loss: 0.3413255214691162
Batch 19/64 loss: 0.3479878306388855
Batch 20/64 loss: 0.3495969772338867
Batch 21/64 loss: 0.34934478998184204
Batch 22/64 loss: 0.34715771675109863
Batch 23/64 loss: 0.3545738458633423
Batch 24/64 loss: 0.34846723079681396
Batch 25/64 loss: 0.345403790473938
Batch 26/64 loss: 0.3474661707878113
Batch 27/64 loss: 0.3475832939147949
Batch 28/64 loss: 0.34087300300598145
Batch 29/64 loss: 0.3491055965423584
Batch 30/64 loss: 0.3453153371810913
Batch 31/64 loss: 0.34465116262435913
Batch 32/64 loss: 0.3426106572151184
Batch 33/64 loss: 0.34559595584869385
Batch 34/64 loss: 0.34360337257385254
Batch 35/64 loss: 0.3444885015487671
Batch 36/64 loss: 0.3475090265274048
Batch 37/64 loss: 0.34537941217422485
Batch 38/64 loss: 0.34552907943725586
Batch 39/64 loss: 0.34505730867385864
Batch 40/64 loss: 0.34474045038223267
Batch 41/64 loss: 0.3484550714492798
Batch 42/64 loss: 0.35137689113616943
Batch 43/64 loss: 0.3472447395324707
Batch 44/64 loss: 0.3422715663909912
Batch 45/64 loss: 0.34504276514053345
Batch 46/64 loss: 0.34628021717071533
Batch 47/64 loss: 0.3518356680870056
Batch 48/64 loss: 0.3441498279571533
Batch 49/64 loss: 0.34487396478652954
Batch 50/64 loss: 0.34586620330810547
Batch 51/64 loss: 0.3494829535484314
Batch 52/64 loss: 0.34584707021713257
Batch 53/64 loss: 0.3488057851791382
Batch 54/64 loss: 0.3467448353767395
Batch 55/64 loss: 0.35452568531036377
Batch 56/64 loss: 0.3446059226989746
Batch 57/64 loss: 0.3472711443901062
Batch 58/64 loss: 0.349493145942688
Batch 59/64 loss: 0.3527357578277588
Batch 60/64 loss: 0.3462737798690796
Batch 61/64 loss: 0.346277117729187
Batch 62/64 loss: 0.3463345766067505
Batch 63/64 loss: 0.3443071246147156
Batch 64/64 loss: 0.3421132564544678
Epoch 87  Train loss: 0.34655770881503234  Val loss: 0.3514466142326696
Epoch 88
-------------------------------
Batch 1/64 loss: 0.3465331196784973
Batch 2/64 loss: 0.3469196557998657
Batch 3/64 loss: 0.3466758728027344
Batch 4/64 loss: 0.3456728458404541
Batch 5/64 loss: 0.34740734100341797
Batch 6/64 loss: 0.3463374972343445
Batch 7/64 loss: 0.3462594747543335
Batch 8/64 loss: 0.34615933895111084
Batch 9/64 loss: 0.34587347507476807
Batch 10/64 loss: 0.34652161598205566
Batch 11/64 loss: 0.34742844104766846
Batch 12/64 loss: 0.34121572971343994
Batch 13/64 loss: 0.35375285148620605
Batch 14/64 loss: 0.3432198762893677
Batch 15/64 loss: 0.3491867780685425
Batch 16/64 loss: 0.34853023290634155
Batch 17/64 loss: 0.34639328718185425
Batch 18/64 loss: 0.344734251499176
Batch 19/64 loss: 0.34763193130493164
Batch 20/64 loss: 0.34916311502456665
Batch 21/64 loss: 0.3397921323776245
Batch 22/64 loss: 0.34213221073150635
Batch 23/64 loss: 0.34966588020324707
Batch 24/64 loss: 0.34723615646362305
Batch 25/64 loss: 0.3450666069984436
Batch 26/64 loss: 0.3474571704864502
Batch 27/64 loss: 0.34802353382110596
Batch 28/64 loss: 0.342479407787323
Batch 29/64 loss: 0.3418738842010498
Batch 30/64 loss: 0.3423014283180237
Batch 31/64 loss: 0.3478173017501831
Batch 32/64 loss: 0.34463196992874146
Batch 33/64 loss: 0.3492313623428345
Batch 34/64 loss: 0.3497745990753174
Batch 35/64 loss: 0.3476322293281555
Batch 36/64 loss: 0.3419543504714966
Batch 37/64 loss: 0.3446871042251587
Batch 38/64 loss: 0.34543001651763916
Batch 39/64 loss: 0.3507424592971802
Batch 40/64 loss: 0.34683966636657715
Batch 41/64 loss: 0.34361201524734497
Batch 42/64 loss: 0.34322547912597656
Batch 43/64 loss: 0.33936309814453125
Batch 44/64 loss: 0.347306489944458
Batch 45/64 loss: 0.3426612615585327
Batch 46/64 loss: 0.3458925485610962
Batch 47/64 loss: 0.3498551845550537
Batch 48/64 loss: 0.3471483588218689
Batch 49/64 loss: 0.34838682413101196
Batch 50/64 loss: 0.3476833701133728
Batch 51/64 loss: 0.3463808298110962
Batch 52/64 loss: 0.3483247756958008
Batch 53/64 loss: 0.34462106227874756
Batch 54/64 loss: 0.346840500831604
Batch 55/64 loss: 0.3456881642341614
Batch 56/64 loss: 0.34210026264190674
Batch 57/64 loss: 0.3425147533416748
Batch 58/64 loss: 0.3471500277519226
Batch 59/64 loss: 0.3475102186203003
Batch 60/64 loss: 0.34662580490112305
Batch 61/64 loss: 0.34247279167175293
Batch 62/64 loss: 0.347359836101532
Batch 63/64 loss: 0.34895026683807373
Batch 64/64 loss: 0.34434938430786133
Epoch 88  Train loss: 0.34604426926257564  Val loss: 0.35155605962595987
Epoch 89
-------------------------------
Batch 1/64 loss: 0.3376172184944153
Batch 2/64 loss: 0.34110188484191895
Batch 3/64 loss: 0.3459926247596741
Batch 4/64 loss: 0.3484339714050293
Batch 5/64 loss: 0.3479698896408081
Batch 6/64 loss: 0.3442270755767822
Batch 7/64 loss: 0.3485095500946045
Batch 8/64 loss: 0.34511232376098633
Batch 9/64 loss: 0.3427126407623291
Batch 10/64 loss: 0.3476182818412781
Batch 11/64 loss: 0.3447195291519165
Batch 12/64 loss: 0.3430796265602112
Batch 13/64 loss: 0.34791624546051025
Batch 14/64 loss: 0.34058940410614014
Batch 15/64 loss: 0.3411216139793396
Batch 16/64 loss: 0.35150808095932007
Batch 17/64 loss: 0.34866440296173096
Batch 18/64 loss: 0.34400129318237305
Batch 19/64 loss: 0.3445706367492676
Batch 20/64 loss: 0.3443793058395386
Batch 21/64 loss: 0.34713488817214966
Batch 22/64 loss: 0.3480778932571411
Batch 23/64 loss: 0.34767746925354004
Batch 24/64 loss: 0.3484777808189392
Batch 25/64 loss: 0.3486784100532532
Batch 26/64 loss: 0.3477935194969177
Batch 27/64 loss: 0.3457642197608948
Batch 28/64 loss: 0.34587883949279785
Batch 29/64 loss: 0.34778207540512085
Batch 30/64 loss: 0.34682297706604004
Batch 31/64 loss: 0.34562230110168457
Batch 32/64 loss: 0.3442894220352173
Batch 33/64 loss: 0.34813249111175537
Batch 34/64 loss: 0.3430602550506592
Batch 35/64 loss: 0.3462122082710266
Batch 36/64 loss: 0.3476608991622925
Batch 37/64 loss: 0.34325700998306274
Batch 38/64 loss: 0.34536415338516235
Batch 39/64 loss: 0.3465876579284668
Batch 40/64 loss: 0.3482280969619751
Batch 41/64 loss: 0.34544837474823
Batch 42/64 loss: 0.3464850187301636
Batch 43/64 loss: 0.3451352119445801
Batch 44/64 loss: 0.34292078018188477
Batch 45/64 loss: 0.35010743141174316
Batch 46/64 loss: 0.34869837760925293
Batch 47/64 loss: 0.3441324234008789
Batch 48/64 loss: 0.34532302618026733
Batch 49/64 loss: 0.34973782300949097
Batch 50/64 loss: 0.3428955078125
Batch 51/64 loss: 0.34674423933029175
Batch 52/64 loss: 0.34535980224609375
Batch 53/64 loss: 0.3484541177749634
Batch 54/64 loss: 0.34580713510513306
Batch 55/64 loss: 0.3437495827674866
Batch 56/64 loss: 0.3459041118621826
Batch 57/64 loss: 0.34694933891296387
Batch 58/64 loss: 0.34839528799057007
Batch 59/64 loss: 0.34427595138549805
Batch 60/64 loss: 0.34175896644592285
Batch 61/64 loss: 0.343328595161438
Batch 62/64 loss: 0.34517359733581543
Batch 63/64 loss: 0.3466283082962036
Batch 64/64 loss: 0.3426293134689331
Epoch 89  Train loss: 0.34576836333555333  Val loss: 0.3503503682687111
Saving best model, epoch: 89
Epoch 90
-------------------------------
Batch 1/64 loss: 0.3407478928565979
Batch 2/64 loss: 0.3438812494277954
Batch 3/64 loss: 0.34174662828445435
Batch 4/64 loss: 0.34696364402770996
Batch 5/64 loss: 0.3441885709762573
Batch 6/64 loss: 0.3476712703704834
Batch 7/64 loss: 0.345151424407959
Batch 8/64 loss: 0.3412432074546814
Batch 9/64 loss: 0.3431210517883301
Batch 10/64 loss: 0.34392082691192627
Batch 11/64 loss: 0.34806227684020996
Batch 12/64 loss: 0.3452796936035156
Batch 13/64 loss: 0.3503110408782959
Batch 14/64 loss: 0.34482455253601074
Batch 15/64 loss: 0.34330469369888306
Batch 16/64 loss: 0.3430728316307068
Batch 17/64 loss: 0.3453725576400757
Batch 18/64 loss: 0.34138208627700806
Batch 19/64 loss: 0.34574878215789795
Batch 20/64 loss: 0.3456176519393921
Batch 21/64 loss: 0.3460894823074341
Batch 22/64 loss: 0.35135388374328613
Batch 23/64 loss: 0.344008207321167
Batch 24/64 loss: 0.35010337829589844
Batch 25/64 loss: 0.34906142950057983
Batch 26/64 loss: 0.3485788106918335
Batch 27/64 loss: 0.3487939238548279
Batch 28/64 loss: 0.3465970754623413
Batch 29/64 loss: 0.3481738567352295
Batch 30/64 loss: 0.34501874446868896
Batch 31/64 loss: 0.3498525619506836
Batch 32/64 loss: 0.3470805883407593
Batch 33/64 loss: 0.3452000617980957
Batch 34/64 loss: 0.34923893213272095
Batch 35/64 loss: 0.346277117729187
Batch 36/64 loss: 0.34644562005996704
Batch 37/64 loss: 0.3429868221282959
Batch 38/64 loss: 0.34614282846450806
Batch 39/64 loss: 0.34742701053619385
Batch 40/64 loss: 0.3447638154029846
Batch 41/64 loss: 0.3462945818901062
Batch 42/64 loss: 0.3495359420776367
Batch 43/64 loss: 0.34144580364227295
Batch 44/64 loss: 0.34550178050994873
Batch 45/64 loss: 0.3489365577697754
Batch 46/64 loss: 0.34591472148895264
Batch 47/64 loss: 0.34725672006607056
Batch 48/64 loss: 0.3475189805030823
Batch 49/64 loss: 0.3447239398956299
Batch 50/64 loss: 0.34726113080978394
Batch 51/64 loss: 0.3441927433013916
Batch 52/64 loss: 0.3452487587928772
Batch 53/64 loss: 0.3449627161026001
Batch 54/64 loss: 0.34282761812210083
Batch 55/64 loss: 0.34468305110931396
Batch 56/64 loss: 0.34186649322509766
Batch 57/64 loss: 0.339105486869812
Batch 58/64 loss: 0.3560105562210083
Batch 59/64 loss: 0.34732240438461304
Batch 60/64 loss: 0.34544575214385986
Batch 61/64 loss: 0.3442404270172119
Batch 62/64 loss: 0.34027963876724243
Batch 63/64 loss: 0.34855300188064575
Batch 64/64 loss: 0.345473051071167
Epoch 90  Train loss: 0.34577317144356523  Val loss: 0.35103591918126004
Epoch 91
-------------------------------
Batch 1/64 loss: 0.3424733877182007
Batch 2/64 loss: 0.34358859062194824
Batch 3/64 loss: 0.346330463886261
Batch 4/64 loss: 0.3451169729232788
Batch 5/64 loss: 0.34741002321243286
Batch 6/64 loss: 0.3468737006187439
Batch 7/64 loss: 0.34256184101104736
Batch 8/64 loss: 0.35045570135116577
Batch 9/64 loss: 0.34512168169021606
Batch 10/64 loss: 0.3427330255508423
Batch 11/64 loss: 0.34442806243896484
Batch 12/64 loss: 0.3391469717025757
Batch 13/64 loss: 0.3479270935058594
Batch 14/64 loss: 0.34804320335388184
Batch 15/64 loss: 0.3421551585197449
Batch 16/64 loss: 0.3458300828933716
Batch 17/64 loss: 0.3431342840194702
Batch 18/64 loss: 0.3431739807128906
Batch 19/64 loss: 0.3460966944694519
Batch 20/64 loss: 0.3460623025894165
Batch 21/64 loss: 0.3474121689796448
Batch 22/64 loss: 0.3433424234390259
Batch 23/64 loss: 0.34917426109313965
Batch 24/64 loss: 0.3460143804550171
Batch 25/64 loss: 0.3462507724761963
Batch 26/64 loss: 0.3505399227142334
Batch 27/64 loss: 0.3429880738258362
Batch 28/64 loss: 0.3443117141723633
Batch 29/64 loss: 0.3461383581161499
Batch 30/64 loss: 0.3472355604171753
Batch 31/64 loss: 0.3400573134422302
Batch 32/64 loss: 0.3458024263381958
Batch 33/64 loss: 0.34706735610961914
Batch 34/64 loss: 0.3449059724807739
Batch 35/64 loss: 0.33913445472717285
Batch 36/64 loss: 0.34830063581466675
Batch 37/64 loss: 0.3494036793708801
Batch 38/64 loss: 0.3445954918861389
Batch 39/64 loss: 0.34487295150756836
Batch 40/64 loss: 0.34761059284210205
Batch 41/64 loss: 0.35049402713775635
Batch 42/64 loss: 0.3460378646850586
Batch 43/64 loss: 0.34286725521087646
Batch 44/64 loss: 0.345966100692749
Batch 45/64 loss: 0.34961676597595215
Batch 46/64 loss: 0.34309184551239014
Batch 47/64 loss: 0.34441059827804565
Batch 48/64 loss: 0.3485398292541504
Batch 49/64 loss: 0.34777939319610596
Batch 50/64 loss: 0.3427000045776367
Batch 51/64 loss: 0.3501319885253906
Batch 52/64 loss: 0.3409910798072815
Batch 53/64 loss: 0.344459593296051
Batch 54/64 loss: 0.3459262251853943
Batch 55/64 loss: 0.35215067863464355
Batch 56/64 loss: 0.3447561264038086
Batch 57/64 loss: 0.3460131287574768
Batch 58/64 loss: 0.3459019064903259
Batch 59/64 loss: 0.34450656175613403
Batch 60/64 loss: 0.34469354152679443
Batch 61/64 loss: 0.3481177091598511
Batch 62/64 loss: 0.34319496154785156
Batch 63/64 loss: 0.34048062562942505
Batch 64/64 loss: 0.3523438572883606
Epoch 91  Train loss: 0.34558286176008335  Val loss: 0.3504490897417888
Epoch 92
-------------------------------
Batch 1/64 loss: 0.343061625957489
Batch 2/64 loss: 0.34548479318618774
Batch 3/64 loss: 0.3457988500595093
Batch 4/64 loss: 0.3471682071685791
Batch 5/64 loss: 0.34229499101638794
Batch 6/64 loss: 0.34581756591796875
Batch 7/64 loss: 0.34419119358062744
Batch 8/64 loss: 0.34269559383392334
Batch 9/64 loss: 0.34206104278564453
Batch 10/64 loss: 0.34386205673217773
Batch 11/64 loss: 0.3469997048377991
Batch 12/64 loss: 0.34340208768844604
Batch 13/64 loss: 0.3414989709854126
Batch 14/64 loss: 0.34269773960113525
Batch 15/64 loss: 0.34695136547088623
Batch 16/64 loss: 0.3452664017677307
Batch 17/64 loss: 0.3471490144729614
Batch 18/64 loss: 0.34660959243774414
Batch 19/64 loss: 0.3478010892868042
Batch 20/64 loss: 0.343647837638855
Batch 21/64 loss: 0.34188640117645264
Batch 22/64 loss: 0.3476146459579468
Batch 23/64 loss: 0.3459659814834595
Batch 24/64 loss: 0.34920215606689453
Batch 25/64 loss: 0.3487938642501831
Batch 26/64 loss: 0.3476858139038086
Batch 27/64 loss: 0.34809160232543945
Batch 28/64 loss: 0.34905266761779785
Batch 29/64 loss: 0.34427279233932495
Batch 30/64 loss: 0.3466479778289795
Batch 31/64 loss: 0.3453176021575928
Batch 32/64 loss: 0.34199953079223633
Batch 33/64 loss: 0.34523582458496094
Batch 34/64 loss: 0.3493208885192871
Batch 35/64 loss: 0.34720557928085327
Batch 36/64 loss: 0.3472479581832886
Batch 37/64 loss: 0.34565460681915283
Batch 38/64 loss: 0.34427666664123535
Batch 39/64 loss: 0.3445699214935303
Batch 40/64 loss: 0.34982532262802124
Batch 41/64 loss: 0.34773385524749756
Batch 42/64 loss: 0.34574973583221436
Batch 43/64 loss: 0.3463718295097351
Batch 44/64 loss: 0.34468215703964233
Batch 45/64 loss: 0.34376585483551025
Batch 46/64 loss: 0.3419663906097412
Batch 47/64 loss: 0.34498870372772217
Batch 48/64 loss: 0.34535038471221924
Batch 49/64 loss: 0.35069024562835693
Batch 50/64 loss: 0.3487081527709961
Batch 51/64 loss: 0.34197258949279785
Batch 52/64 loss: 0.3461305499076843
Batch 53/64 loss: 0.3440893888473511
Batch 54/64 loss: 0.345439076423645
Batch 55/64 loss: 0.34480178356170654
Batch 56/64 loss: 0.3519238233566284
Batch 57/64 loss: 0.3478734493255615
Batch 58/64 loss: 0.3476620316505432
Batch 59/64 loss: 0.3414158821105957
Batch 60/64 loss: 0.35109448432922363
Batch 61/64 loss: 0.3447412848472595
Batch 62/64 loss: 0.34772932529449463
Batch 63/64 loss: 0.3445025086402893
Batch 64/64 loss: 0.3514218330383301
Epoch 92  Train loss: 0.3458396453483432  Val loss: 0.3509737466209123
Epoch 93
-------------------------------
Batch 1/64 loss: 0.346049964427948
Batch 2/64 loss: 0.3501145839691162
Batch 3/64 loss: 0.348588764667511
Batch 4/64 loss: 0.3470519185066223
Batch 5/64 loss: 0.34617698192596436
Batch 6/64 loss: 0.34671223163604736
Batch 7/64 loss: 0.34549474716186523
Batch 8/64 loss: 0.3463541269302368
Batch 9/64 loss: 0.3430795669555664
Batch 10/64 loss: 0.3447225093841553
Batch 11/64 loss: 0.3461994528770447
Batch 12/64 loss: 0.34392452239990234
Batch 13/64 loss: 0.34241580963134766
Batch 14/64 loss: 0.3521714210510254
Batch 15/64 loss: 0.3462873101234436
Batch 16/64 loss: 0.3436950445175171
Batch 17/64 loss: 0.34480804204940796
Batch 18/64 loss: 0.3425518870353699
Batch 19/64 loss: 0.34601545333862305
Batch 20/64 loss: 0.34899020195007324
Batch 21/64 loss: 0.3462413549423218
Batch 22/64 loss: 0.34636855125427246
Batch 23/64 loss: 0.34609442949295044
Batch 24/64 loss: 0.3433265686035156
Batch 25/64 loss: 0.34883177280426025
Batch 26/64 loss: 0.34208083152770996
Batch 27/64 loss: 0.3466905355453491
Batch 28/64 loss: 0.34415173530578613
Batch 29/64 loss: 0.3449254035949707
Batch 30/64 loss: 0.34448593854904175
Batch 31/64 loss: 0.34325116872787476
Batch 32/64 loss: 0.3450613021850586
Batch 33/64 loss: 0.34104257822036743
Batch 34/64 loss: 0.34001094102859497
Batch 35/64 loss: 0.34948861598968506
Batch 36/64 loss: 0.3461570739746094
Batch 37/64 loss: 0.3441389799118042
Batch 38/64 loss: 0.34273648262023926
Batch 39/64 loss: 0.34200143814086914
Batch 40/64 loss: 0.347919225692749
Batch 41/64 loss: 0.3466033935546875
Batch 42/64 loss: 0.34441959857940674
Batch 43/64 loss: 0.3502286672592163
Batch 44/64 loss: 0.34355366230010986
Batch 45/64 loss: 0.3467278480529785
Batch 46/64 loss: 0.34282052516937256
Batch 47/64 loss: 0.34831172227859497
Batch 48/64 loss: 0.34646153450012207
Batch 49/64 loss: 0.34330201148986816
Batch 50/64 loss: 0.34516382217407227
Batch 51/64 loss: 0.3475446105003357
Batch 52/64 loss: 0.34438538551330566
Batch 53/64 loss: 0.34720277786254883
Batch 54/64 loss: 0.34261155128479004
Batch 55/64 loss: 0.3467376232147217
Batch 56/64 loss: 0.34764349460601807
Batch 57/64 loss: 0.3465815782546997
Batch 58/64 loss: 0.34715700149536133
Batch 59/64 loss: 0.3475252389907837
Batch 60/64 loss: 0.3448392152786255
Batch 61/64 loss: 0.34529805183410645
Batch 62/64 loss: 0.345845103263855
Batch 63/64 loss: 0.347133994102478
Batch 64/64 loss: 0.34691429138183594
Epoch 93  Train loss: 0.3456422525293687  Val loss: 0.35052834691870255
Epoch 94
-------------------------------
Batch 1/64 loss: 0.34559887647628784
Batch 2/64 loss: 0.3464805483818054
Batch 3/64 loss: 0.341410756111145
Batch 4/64 loss: 0.3444657325744629
Batch 5/64 loss: 0.3463522791862488
Batch 6/64 loss: 0.3423923850059509
Batch 7/64 loss: 0.3451588749885559
Batch 8/64 loss: 0.34128427505493164
Batch 9/64 loss: 0.34848183393478394
Batch 10/64 loss: 0.3414968252182007
Batch 11/64 loss: 0.3434267044067383
Batch 12/64 loss: 0.34551119804382324
Batch 13/64 loss: 0.3457670211791992
Batch 14/64 loss: 0.34667348861694336
Batch 15/64 loss: 0.3490002155303955
Batch 16/64 loss: 0.3417852520942688
Batch 17/64 loss: 0.3450621962547302
Batch 18/64 loss: 0.34576648473739624
Batch 19/64 loss: 0.34743010997772217
Batch 20/64 loss: 0.3479803800582886
Batch 21/64 loss: 0.34068357944488525
Batch 22/64 loss: 0.34361928701400757
Batch 23/64 loss: 0.34555429220199585
Batch 24/64 loss: 0.3472428321838379
Batch 25/64 loss: 0.3488948345184326
Batch 26/64 loss: 0.34469354152679443
Batch 27/64 loss: 0.3525170087814331
Batch 28/64 loss: 0.35080695152282715
Batch 29/64 loss: 0.35128867626190186
Batch 30/64 loss: 0.3453174829483032
Batch 31/64 loss: 0.3461928367614746
Batch 32/64 loss: 0.3466179370880127
Batch 33/64 loss: 0.3435257077217102
Batch 34/64 loss: 0.3439180254936218
Batch 35/64 loss: 0.34506744146347046
Batch 36/64 loss: 0.3460806608200073
Batch 37/64 loss: 0.34435123205184937
Batch 38/64 loss: 0.34548330307006836
Batch 39/64 loss: 0.3389613628387451
Batch 40/64 loss: 0.34786391258239746
Batch 41/64 loss: 0.3432644009590149
Batch 42/64 loss: 0.34828275442123413
Batch 43/64 loss: 0.3436720371246338
Batch 44/64 loss: 0.3467767834663391
Batch 45/64 loss: 0.346976637840271
Batch 46/64 loss: 0.3408561944961548
Batch 47/64 loss: 0.3458685874938965
Batch 48/64 loss: 0.34904253482818604
Batch 49/64 loss: 0.34286701679229736
Batch 50/64 loss: 0.3450964093208313
Batch 51/64 loss: 0.3484917879104614
Batch 52/64 loss: 0.34707391262054443
Batch 53/64 loss: 0.3427882790565491
Batch 54/64 loss: 0.3459930419921875
Batch 55/64 loss: 0.3443787097930908
Batch 56/64 loss: 0.3445609211921692
Batch 57/64 loss: 0.33954668045043945
Batch 58/64 loss: 0.34381169080734253
Batch 59/64 loss: 0.3478073477745056
Batch 60/64 loss: 0.3467496633529663
Batch 61/64 loss: 0.3489578366279602
Batch 62/64 loss: 0.348832368850708
Batch 63/64 loss: 0.34492063522338867
Batch 64/64 loss: 0.344756543636322
Epoch 94  Train loss: 0.34549631347843246  Val loss: 0.3503462862722653
Saving best model, epoch: 94
Epoch 95
-------------------------------
Batch 1/64 loss: 0.3479197025299072
Batch 2/64 loss: 0.3476524353027344
Batch 3/64 loss: 0.3456697463989258
Batch 4/64 loss: 0.34312063455581665
Batch 5/64 loss: 0.3468403220176697
Batch 6/64 loss: 0.3459625244140625
Batch 7/64 loss: 0.34186041355133057
Batch 8/64 loss: 0.3431522846221924
Batch 9/64 loss: 0.34368932247161865
Batch 10/64 loss: 0.3458932638168335
Batch 11/64 loss: 0.34955859184265137
Batch 12/64 loss: 0.3450382947921753
Batch 13/64 loss: 0.34530532360076904
Batch 14/64 loss: 0.3444993495941162
Batch 15/64 loss: 0.34510087966918945
Batch 16/64 loss: 0.3430188298225403
Batch 17/64 loss: 0.3514326810836792
Batch 18/64 loss: 0.34401071071624756
Batch 19/64 loss: 0.34457188844680786
Batch 20/64 loss: 0.3381953239440918
Batch 21/64 loss: 0.3425533175468445
Batch 22/64 loss: 0.3477323055267334
Batch 23/64 loss: 0.3427785634994507
Batch 24/64 loss: 0.3435094952583313
Batch 25/64 loss: 0.34374332427978516
Batch 26/64 loss: 0.3426545262336731
Batch 27/64 loss: 0.34676826000213623
Batch 28/64 loss: 0.342751145362854
Batch 29/64 loss: 0.3426473140716553
Batch 30/64 loss: 0.34224605560302734
Batch 31/64 loss: 0.3447781205177307
Batch 32/64 loss: 0.34478306770324707
Batch 33/64 loss: 0.34813201427459717
Batch 34/64 loss: 0.3435708284378052
Batch 35/64 loss: 0.3468440771102905
Batch 36/64 loss: 0.34773457050323486
Batch 37/64 loss: 0.3505263328552246
Batch 38/64 loss: 0.3467367887496948
Batch 39/64 loss: 0.3462275266647339
Batch 40/64 loss: 0.3459736108779907
Batch 41/64 loss: 0.3428322672843933
Batch 42/64 loss: 0.3432399034500122
Batch 43/64 loss: 0.340507447719574
Batch 44/64 loss: 0.348543643951416
Batch 45/64 loss: 0.34704792499542236
Batch 46/64 loss: 0.341052770614624
Batch 47/64 loss: 0.34508216381073
Batch 48/64 loss: 0.34500372409820557
Batch 49/64 loss: 0.34222424030303955
Batch 50/64 loss: 0.3471824526786804
Batch 51/64 loss: 0.3416178226470947
Batch 52/64 loss: 0.3462938070297241
Batch 53/64 loss: 0.3486739993095398
Batch 54/64 loss: 0.3480185270309448
Batch 55/64 loss: 0.34500443935394287
Batch 56/64 loss: 0.34571373462677
Batch 57/64 loss: 0.3469194173812866
Batch 58/64 loss: 0.34496742486953735
Batch 59/64 loss: 0.3475062847137451
Batch 60/64 loss: 0.34423828125
Batch 61/64 loss: 0.34347689151763916
Batch 62/64 loss: 0.3469734191894531
Batch 63/64 loss: 0.34744685888290405
Batch 64/64 loss: 0.35100817680358887
Epoch 95  Train loss: 0.3452236446679807  Val loss: 0.3500815642248724
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: 0.34536510705947876
Batch 2/64 loss: 0.3429363965988159
Batch 3/64 loss: 0.34490931034088135
Batch 4/64 loss: 0.3408752679824829
Batch 5/64 loss: 0.3482213020324707
Batch 6/64 loss: 0.3468848466873169
Batch 7/64 loss: 0.3462628126144409
Batch 8/64 loss: 0.34460222721099854
Batch 9/64 loss: 0.34776103496551514
Batch 10/64 loss: 0.34771597385406494
Batch 11/64 loss: 0.3380768895149231
Batch 12/64 loss: 0.3470977544784546
Batch 13/64 loss: 0.3417384624481201
Batch 14/64 loss: 0.3436989188194275
Batch 15/64 loss: 0.34187185764312744
Batch 16/64 loss: 0.34345459938049316
Batch 17/64 loss: 0.34900611639022827
Batch 18/64 loss: 0.3468688726425171
Batch 19/64 loss: 0.34268665313720703
Batch 20/64 loss: 0.3401867151260376
Batch 21/64 loss: 0.3438897728919983
Batch 22/64 loss: 0.3446577787399292
Batch 23/64 loss: 0.3429304361343384
Batch 24/64 loss: 0.34348249435424805
Batch 25/64 loss: 0.3406810760498047
Batch 26/64 loss: 0.3455815315246582
Batch 27/64 loss: 0.3447299003601074
Batch 28/64 loss: 0.3416879177093506
Batch 29/64 loss: 0.3401341438293457
Batch 30/64 loss: 0.3441741466522217
Batch 31/64 loss: 0.344262957572937
Batch 32/64 loss: 0.34783661365509033
Batch 33/64 loss: 0.34420663118362427
Batch 34/64 loss: 0.3456645607948303
Batch 35/64 loss: 0.35156142711639404
Batch 36/64 loss: 0.3428059220314026
Batch 37/64 loss: 0.3457053303718567
Batch 38/64 loss: 0.3476448059082031
Batch 39/64 loss: 0.3474438190460205
Batch 40/64 loss: 0.3413383364677429
Batch 41/64 loss: 0.3500903844833374
Batch 42/64 loss: 0.34318065643310547
Batch 43/64 loss: 0.34092044830322266
Batch 44/64 loss: 0.34854137897491455
Batch 45/64 loss: 0.342960000038147
Batch 46/64 loss: 0.34234726428985596
Batch 47/64 loss: 0.3458540439605713
Batch 48/64 loss: 0.3442755341529846
Batch 49/64 loss: 0.35018497705459595
Batch 50/64 loss: 0.3462483882904053
Batch 51/64 loss: 0.3420022130012512
Batch 52/64 loss: 0.34423476457595825
Batch 53/64 loss: 0.3471338748931885
Batch 54/64 loss: 0.3445683717727661
Batch 55/64 loss: 0.347988486289978
Batch 56/64 loss: 0.3481745719909668
Batch 57/64 loss: 0.3445841073989868
Batch 58/64 loss: 0.3487210273742676
Batch 59/64 loss: 0.344585657119751
Batch 60/64 loss: 0.34488922357559204
Batch 61/64 loss: 0.34557628631591797
Batch 62/64 loss: 0.3465263843536377
Batch 63/64 loss: 0.3437061905860901
Batch 64/64 loss: 0.3421642780303955
Epoch 96  Train loss: 0.34485581435409246  Val loss: 0.3507818069654642
Epoch 97
-------------------------------
Batch 1/64 loss: 0.343370258808136
Batch 2/64 loss: 0.3460574150085449
Batch 3/64 loss: 0.3468133211135864
Batch 4/64 loss: 0.3449363112449646
Batch 5/64 loss: 0.34496021270751953
Batch 6/64 loss: 0.350211501121521
Batch 7/64 loss: 0.34365785121917725
Batch 8/64 loss: 0.34725964069366455
Batch 9/64 loss: 0.3469628095626831
Batch 10/64 loss: 0.3483653664588928
Batch 11/64 loss: 0.3464639186859131
Batch 12/64 loss: 0.3414270877838135
Batch 13/64 loss: 0.3397098183631897
Batch 14/64 loss: 0.3446096181869507
Batch 15/64 loss: 0.34384655952453613
Batch 16/64 loss: 0.341086745262146
Batch 17/64 loss: 0.343580961227417
Batch 18/64 loss: 0.3466755151748657
Batch 19/64 loss: 0.34505516290664673
Batch 20/64 loss: 0.3387258052825928
Batch 21/64 loss: 0.3396124243736267
Batch 22/64 loss: 0.34366708993911743
Batch 23/64 loss: 0.34485137462615967
Batch 24/64 loss: 0.34543073177337646
Batch 25/64 loss: 0.3456408977508545
Batch 26/64 loss: 0.34388256072998047
Batch 27/64 loss: 0.3420293927192688
Batch 28/64 loss: 0.34474170207977295
Batch 29/64 loss: 0.34286820888519287
Batch 30/64 loss: 0.3491097092628479
Batch 31/64 loss: 0.3443615436553955
Batch 32/64 loss: 0.34750139713287354
Batch 33/64 loss: 0.34456974267959595
Batch 34/64 loss: 0.34234702587127686
Batch 35/64 loss: 0.34345686435699463
Batch 36/64 loss: 0.3493537902832031
Batch 37/64 loss: 0.3435779809951782
Batch 38/64 loss: 0.341627836227417
Batch 39/64 loss: 0.34133094549179077
Batch 40/64 loss: 0.3430967926979065
Batch 41/64 loss: 0.3428460359573364
Batch 42/64 loss: 0.3441678285598755
Batch 43/64 loss: 0.35017216205596924
Batch 44/64 loss: 0.3457597494125366
Batch 45/64 loss: 0.3449758291244507
Batch 46/64 loss: 0.3486638069152832
Batch 47/64 loss: 0.34851163625717163
Batch 48/64 loss: 0.34910517930984497
Batch 49/64 loss: 0.3518707752227783
Batch 50/64 loss: 0.3463270664215088
Batch 51/64 loss: 0.3425297141075134
Batch 52/64 loss: 0.3427655100822449
Batch 53/64 loss: 0.34231722354888916
Batch 54/64 loss: 0.34967100620269775
Batch 55/64 loss: 0.3494434356689453
Batch 56/64 loss: 0.34400153160095215
Batch 57/64 loss: 0.34553563594818115
Batch 58/64 loss: 0.33986496925354004
Batch 59/64 loss: 0.34903156757354736
Batch 60/64 loss: 0.3450946807861328
Batch 61/64 loss: 0.3458470106124878
Batch 62/64 loss: 0.35076236724853516
Batch 63/64 loss: 0.3424394726753235
Batch 64/64 loss: 0.3448280096054077
Epoch 97  Train loss: 0.34505347597832775  Val loss: 0.3499226099027391
Saving best model, epoch: 97
Epoch 98
-------------------------------
Batch 1/64 loss: 0.3471260666847229
Batch 2/64 loss: 0.34236598014831543
Batch 3/64 loss: 0.3481091260910034
Batch 4/64 loss: 0.340848445892334
Batch 5/64 loss: 0.3467596769332886
Batch 6/64 loss: 0.33962059020996094
Batch 7/64 loss: 0.3524031639099121
Batch 8/64 loss: 0.34322720766067505
Batch 9/64 loss: 0.34257400035858154
Batch 10/64 loss: 0.34880632162094116
Batch 11/64 loss: 0.3415142297744751
Batch 12/64 loss: 0.34444689750671387
Batch 13/64 loss: 0.33680111169815063
Batch 14/64 loss: 0.341680645942688
Batch 15/64 loss: 0.34442949295043945
Batch 16/64 loss: 0.34661805629730225
Batch 17/64 loss: 0.3456355929374695
Batch 18/64 loss: 0.3483315706253052
Batch 19/64 loss: 0.3458733558654785
Batch 20/64 loss: 0.3458528518676758
Batch 21/64 loss: 0.3467898368835449
Batch 22/64 loss: 0.34394586086273193
Batch 23/64 loss: 0.3443966507911682
Batch 24/64 loss: 0.34858429431915283
Batch 25/64 loss: 0.34927356243133545
Batch 26/64 loss: 0.3490556478500366
Batch 27/64 loss: 0.3420743942260742
Batch 28/64 loss: 0.34914642572402954
Batch 29/64 loss: 0.3513180613517761
Batch 30/64 loss: 0.34424030780792236
Batch 31/64 loss: 0.34638500213623047
Batch 32/64 loss: 0.34252285957336426
Batch 33/64 loss: 0.35072338581085205
Batch 34/64 loss: 0.3455594778060913
Batch 35/64 loss: 0.34343624114990234
Batch 36/64 loss: 0.34379780292510986
Batch 37/64 loss: 0.3452714681625366
Batch 38/64 loss: 0.3477826714515686
Batch 39/64 loss: 0.3451036810874939
Batch 40/64 loss: 0.3430800437927246
Batch 41/64 loss: 0.3471851348876953
Batch 42/64 loss: 0.34478819370269775
Batch 43/64 loss: 0.3405734896659851
Batch 44/64 loss: 0.34437936544418335
Batch 45/64 loss: 0.34500646591186523
Batch 46/64 loss: 0.3506377339363098
Batch 47/64 loss: 0.3477898836135864
Batch 48/64 loss: 0.344632625579834
Batch 49/64 loss: 0.34938132762908936
Batch 50/64 loss: 0.34442007541656494
Batch 51/64 loss: 0.3483509421348572
Batch 52/64 loss: 0.3411442041397095
Batch 53/64 loss: 0.33992719650268555
Batch 54/64 loss: 0.34234100580215454
Batch 55/64 loss: 0.34080153703689575
Batch 56/64 loss: 0.3466254472732544
Batch 57/64 loss: 0.34533989429473877
Batch 58/64 loss: 0.3438795804977417
Batch 59/64 loss: 0.34380465745925903
Batch 60/64 loss: 0.3413134813308716
Batch 61/64 loss: 0.34678590297698975
Batch 62/64 loss: 0.34379249811172485
Batch 63/64 loss: 0.3417168855667114
Batch 64/64 loss: 0.34645944833755493
Epoch 98  Train loss: 0.3450976341378455  Val loss: 0.3498130920007057
Saving best model, epoch: 98
Epoch 99
-------------------------------
Batch 1/64 loss: 0.34191739559173584
Batch 2/64 loss: 0.3409050703048706
Batch 3/64 loss: 0.3401404023170471
Batch 4/64 loss: 0.3426520824432373
Batch 5/64 loss: 0.3428558111190796
Batch 6/64 loss: 0.34737563133239746
Batch 7/64 loss: 0.34382569789886475
Batch 8/64 loss: 0.345209002494812
Batch 9/64 loss: 0.34756404161453247
Batch 10/64 loss: 0.3456827402114868
Batch 11/64 loss: 0.3477853536605835
Batch 12/64 loss: 0.3415827751159668
Batch 13/64 loss: 0.34509754180908203
Batch 14/64 loss: 0.33893609046936035
Batch 15/64 loss: 0.3434838056564331
Batch 16/64 loss: 0.3444305658340454
Batch 17/64 loss: 0.34618687629699707
Batch 18/64 loss: 0.34217584133148193
Batch 19/64 loss: 0.34977757930755615
Batch 20/64 loss: 0.3417549133300781
Batch 21/64 loss: 0.34207284450531006
Batch 22/64 loss: 0.3447549343109131
Batch 23/64 loss: 0.3499688506126404
Batch 24/64 loss: 0.3475534915924072
Batch 25/64 loss: 0.3434082269668579
Batch 26/64 loss: 0.34454119205474854
Batch 27/64 loss: 0.34032416343688965
Batch 28/64 loss: 0.34427350759506226
Batch 29/64 loss: 0.3452707529067993
Batch 30/64 loss: 0.3439236283302307
Batch 31/64 loss: 0.349487841129303
Batch 32/64 loss: 0.34954434633255005
Batch 33/64 loss: 0.3444634675979614
Batch 34/64 loss: 0.34127020835876465
Batch 35/64 loss: 0.34627485275268555
Batch 36/64 loss: 0.3409358263015747
Batch 37/64 loss: 0.3446117639541626
Batch 38/64 loss: 0.3451666235923767
Batch 39/64 loss: 0.344551682472229
Batch 40/64 loss: 0.34223878383636475
Batch 41/64 loss: 0.34497129917144775
Batch 42/64 loss: 0.34333086013793945
Batch 43/64 loss: 0.34124839305877686
Batch 44/64 loss: 0.3484581708908081
Batch 45/64 loss: 0.34442925453186035
Batch 46/64 loss: 0.34412384033203125
Batch 47/64 loss: 0.33784228563308716
Batch 48/64 loss: 0.350841760635376
Batch 49/64 loss: 0.3450319766998291
Batch 50/64 loss: 0.3432973623275757
Batch 51/64 loss: 0.35006052255630493
Batch 52/64 loss: 0.34345847368240356
Batch 53/64 loss: 0.34732770919799805
Batch 54/64 loss: 0.3404059410095215
Batch 55/64 loss: 0.348504900932312
Batch 56/64 loss: 0.3424486517906189
Batch 57/64 loss: 0.3500301241874695
Batch 58/64 loss: 0.3444749712944031
Batch 59/64 loss: 0.3487142324447632
Batch 60/64 loss: 0.3518047332763672
Batch 61/64 loss: 0.34180498123168945
Batch 62/64 loss: 0.34529244899749756
Batch 63/64 loss: 0.3435852527618408
Batch 64/64 loss: 0.34001457691192627
Epoch 99  Train loss: 0.3446349064509074  Val loss: 0.349935277630783
Epoch 100
-------------------------------
Batch 1/64 loss: 0.33784735202789307
Batch 2/64 loss: 0.34175968170166016
Batch 3/64 loss: 0.3467075824737549
Batch 4/64 loss: 0.347705602645874
Batch 5/64 loss: 0.3401224613189697
Batch 6/64 loss: 0.34005385637283325
Batch 7/64 loss: 0.3466140031814575
Batch 8/64 loss: 0.34417569637298584
Batch 9/64 loss: 0.33744823932647705
Batch 10/64 loss: 0.34506678581237793
Batch 11/64 loss: 0.34573090076446533
Batch 12/64 loss: 0.34235721826553345
Batch 13/64 loss: 0.3472573757171631
Batch 14/64 loss: 0.3436928987503052
Batch 15/64 loss: 0.3408471345901489
Batch 16/64 loss: 0.3450268507003784
Batch 17/64 loss: 0.345527708530426
Batch 18/64 loss: 0.34621191024780273
Batch 19/64 loss: 0.3459293842315674
Batch 20/64 loss: 0.33712100982666016
Batch 21/64 loss: 0.3413224220275879
Batch 22/64 loss: 0.3494780659675598
Batch 23/64 loss: 0.34860748052597046
Batch 24/64 loss: 0.3442181348800659
Batch 25/64 loss: 0.34378480911254883
Batch 26/64 loss: 0.34664255380630493
Batch 27/64 loss: 0.3487412929534912
Batch 28/64 loss: 0.34423577785491943
Batch 29/64 loss: 0.345615029335022
Batch 30/64 loss: 0.34461843967437744
Batch 31/64 loss: 0.35001063346862793
Batch 32/64 loss: 0.34805727005004883
Batch 33/64 loss: 0.3435284495353699
Batch 34/64 loss: 0.3459937572479248
Batch 35/64 loss: 0.3464893102645874
Batch 36/64 loss: 0.34524935483932495
Batch 37/64 loss: 0.3436775207519531
Batch 38/64 loss: 0.3424884080886841
Batch 39/64 loss: 0.34226977825164795
Batch 40/64 loss: 0.3468906879425049
Batch 41/64 loss: 0.34298354387283325
Batch 42/64 loss: 0.34571123123168945
Batch 43/64 loss: 0.34056907892227173
Batch 44/64 loss: 0.3424382209777832
Batch 45/64 loss: 0.3430236577987671
Batch 46/64 loss: 0.3409518003463745
Batch 47/64 loss: 0.34283292293548584
Batch 48/64 loss: 0.34514713287353516
Batch 49/64 loss: 0.33775413036346436
Batch 50/64 loss: 0.3475645184516907
Batch 51/64 loss: 0.34500157833099365
Batch 52/64 loss: 0.344463586807251
Batch 53/64 loss: 0.34332698583602905
Batch 54/64 loss: 0.34533387422561646
Batch 55/64 loss: 0.3415926694869995
Batch 56/64 loss: 0.3453407287597656
Batch 57/64 loss: 0.3431328535079956
Batch 58/64 loss: 0.34465134143829346
Batch 59/64 loss: 0.347359836101532
Batch 60/64 loss: 0.34551525115966797
Batch 61/64 loss: 0.34538543224334717
Batch 62/64 loss: 0.3457314968109131
Batch 63/64 loss: 0.34953463077545166
Batch 64/64 loss: 0.348328173160553
Epoch 100  Train loss: 0.3444033798049478  Val loss: 0.350547477142098
Epoch 101
-------------------------------
Batch 1/64 loss: 0.34414488077163696
Batch 2/64 loss: 0.3430442810058594
Batch 3/64 loss: 0.34675413370132446
Batch 4/64 loss: 0.3462473750114441
Batch 5/64 loss: 0.3419758081436157
Batch 6/64 loss: 0.342624306678772
Batch 7/64 loss: 0.34713631868362427
Batch 8/64 loss: 0.3448554277420044
Batch 9/64 loss: 0.34513163566589355
Batch 10/64 loss: 0.34369999170303345
Batch 11/64 loss: 0.3447801470756531
Batch 12/64 loss: 0.34819138050079346
Batch 13/64 loss: 0.3437941074371338
Batch 14/64 loss: 0.3432219624519348
Batch 15/64 loss: 0.3442974090576172
Batch 16/64 loss: 0.34906214475631714
Batch 17/64 loss: 0.34502410888671875
Batch 18/64 loss: 0.3399909734725952
Batch 19/64 loss: 0.34313905239105225
Batch 20/64 loss: 0.34480583667755127
Batch 21/64 loss: 0.34153908491134644
Batch 22/64 loss: 0.3423045873641968
Batch 23/64 loss: 0.34198516607284546
Batch 24/64 loss: 0.3414738178253174
Batch 25/64 loss: 0.33785146474838257
Batch 26/64 loss: 0.34343528747558594
Batch 27/64 loss: 0.34566354751586914
Batch 28/64 loss: 0.34419023990631104
Batch 29/64 loss: 0.3448098301887512
Batch 30/64 loss: 0.3447416424751282
Batch 31/64 loss: 0.34547650814056396
Batch 32/64 loss: 0.3464704155921936
Batch 33/64 loss: 0.35179072618484497
Batch 34/64 loss: 0.34481632709503174
Batch 35/64 loss: 0.34169673919677734
Batch 36/64 loss: 0.34352749586105347
Batch 37/64 loss: 0.3504542112350464
Batch 38/64 loss: 0.3476843237876892
Batch 39/64 loss: 0.3432231545448303
Batch 40/64 loss: 0.3455721139907837
Batch 41/64 loss: 0.3481025695800781
Batch 42/64 loss: 0.3447032570838928
Batch 43/64 loss: 0.34687918424606323
Batch 44/64 loss: 0.3453388214111328
Batch 45/64 loss: 0.3456326127052307
Batch 46/64 loss: 0.34178149700164795
Batch 47/64 loss: 0.33869004249572754
Batch 48/64 loss: 0.3440983295440674
Batch 49/64 loss: 0.342399001121521
Batch 50/64 loss: 0.34978485107421875
Batch 51/64 loss: 0.33984386920928955
Batch 52/64 loss: 0.34748172760009766
Batch 53/64 loss: 0.342440128326416
Batch 54/64 loss: 0.3443338871002197
Batch 55/64 loss: 0.3421664834022522
Batch 56/64 loss: 0.34466874599456787
Batch 57/64 loss: 0.3512223958969116
Batch 58/64 loss: 0.3424513339996338
Batch 59/64 loss: 0.3468489646911621
Batch 60/64 loss: 0.3435046672821045
Batch 61/64 loss: 0.3431413173675537
Batch 62/64 loss: 0.34536534547805786
Batch 63/64 loss: 0.3410536050796509
Batch 64/64 loss: 0.3479008674621582
Epoch 101  Train loss: 0.34452527457592536  Val loss: 0.35073609450428755
Epoch 102
-------------------------------
Batch 1/64 loss: 0.3435784578323364
Batch 2/64 loss: 0.34582722187042236
Batch 3/64 loss: 0.3446109890937805
Batch 4/64 loss: 0.34138476848602295
Batch 5/64 loss: 0.3448387384414673
Batch 6/64 loss: 0.3461112380027771
Batch 7/64 loss: 0.3441527485847473
Batch 8/64 loss: 0.3420330286026001
Batch 9/64 loss: 0.34776437282562256
Batch 10/64 loss: 0.3422771692276001
Batch 11/64 loss: 0.34309566020965576
Batch 12/64 loss: 0.34520792961120605
Batch 13/64 loss: 0.34678709506988525
Batch 14/64 loss: 0.3481624126434326
Batch 15/64 loss: 0.3491355776786804
Batch 16/64 loss: 0.34262073040008545
Batch 17/64 loss: 0.3428567051887512
Batch 18/64 loss: 0.3453625440597534
Batch 19/64 loss: 0.3500405550003052
Batch 20/64 loss: 0.3363912105560303
Batch 21/64 loss: 0.3442663550376892
Batch 22/64 loss: 0.34216272830963135
Batch 23/64 loss: 0.34673959016799927
Batch 24/64 loss: 0.347506582736969
Batch 25/64 loss: 0.3428402543067932
Batch 26/64 loss: 0.34682774543762207
Batch 27/64 loss: 0.3443729877471924
Batch 28/64 loss: 0.349589467048645
Batch 29/64 loss: 0.34123778343200684
Batch 30/64 loss: 0.34618598222732544
Batch 31/64 loss: 0.3400050401687622
Batch 32/64 loss: 0.3395380973815918
Batch 33/64 loss: 0.34050267934799194
Batch 34/64 loss: 0.3485974073410034
Batch 35/64 loss: 0.3452194333076477
Batch 36/64 loss: 0.34567761421203613
Batch 37/64 loss: 0.34571367502212524
Batch 38/64 loss: 0.34086424112319946
Batch 39/64 loss: 0.3468080759048462
Batch 40/64 loss: 0.33979272842407227
Batch 41/64 loss: 0.3430432081222534
Batch 42/64 loss: 0.3432542085647583
Batch 43/64 loss: 0.3424495458602905
Batch 44/64 loss: 0.3450397253036499
Batch 45/64 loss: 0.3476078510284424
Batch 46/64 loss: 0.33832287788391113
Batch 47/64 loss: 0.3392249345779419
Batch 48/64 loss: 0.34737831354141235
Batch 49/64 loss: 0.34404683113098145
Batch 50/64 loss: 0.34609854221343994
Batch 51/64 loss: 0.3437202572822571
Batch 52/64 loss: 0.3465712070465088
Batch 53/64 loss: 0.3423745632171631
Batch 54/64 loss: 0.3435685634613037
Batch 55/64 loss: 0.3432413339614868
Batch 56/64 loss: 0.3444487452507019
Batch 57/64 loss: 0.343927800655365
Batch 58/64 loss: 0.3465299606323242
Batch 59/64 loss: 0.34046030044555664
Batch 60/64 loss: 0.346510648727417
Batch 61/64 loss: 0.3427804708480835
Batch 62/64 loss: 0.34643083810806274
Batch 63/64 loss: 0.3452419638633728
Batch 64/64 loss: 0.3425334692001343
Epoch 102  Train loss: 0.3442487908344643  Val loss: 0.34899468417839496
Saving best model, epoch: 102
Epoch 103
-------------------------------
Batch 1/64 loss: 0.3413032293319702
Batch 2/64 loss: 0.3427468538284302
Batch 3/64 loss: 0.3429480791091919
Batch 4/64 loss: 0.3447255492210388
Batch 5/64 loss: 0.3409302830696106
Batch 6/64 loss: 0.342140793800354
Batch 7/64 loss: 0.3437376022338867
Batch 8/64 loss: 0.3394607901573181
Batch 9/64 loss: 0.34343385696411133
Batch 10/64 loss: 0.3442422151565552
Batch 11/64 loss: 0.3444165587425232
Batch 12/64 loss: 0.3445448875427246
Batch 13/64 loss: 0.3468656539916992
Batch 14/64 loss: 0.33839136362075806
Batch 15/64 loss: 0.3421696424484253
Batch 16/64 loss: 0.35062819719314575
Batch 17/64 loss: 0.3400574326515198
Batch 18/64 loss: 0.3437913656234741
Batch 19/64 loss: 0.3473339080810547
Batch 20/64 loss: 0.34615373611450195
Batch 21/64 loss: 0.34206318855285645
Batch 22/64 loss: 0.34150469303131104
Batch 23/64 loss: 0.3396158218383789
Batch 24/64 loss: 0.35261356830596924
Batch 25/64 loss: 0.33681678771972656
Batch 26/64 loss: 0.34383076429367065
Batch 27/64 loss: 0.3466014862060547
Batch 28/64 loss: 0.3417719602584839
Batch 29/64 loss: 0.3431752324104309
Batch 30/64 loss: 0.34139305353164673
Batch 31/64 loss: 0.34426748752593994
Batch 32/64 loss: 0.34722352027893066
Batch 33/64 loss: 0.34763920307159424
Batch 34/64 loss: 0.3432043790817261
Batch 35/64 loss: 0.3439217805862427
Batch 36/64 loss: 0.3439391851425171
Batch 37/64 loss: 0.3448599576950073
Batch 38/64 loss: 0.3417726755142212
Batch 39/64 loss: 0.34584081172943115
Batch 40/64 loss: 0.3477790355682373
Batch 41/64 loss: 0.3426990509033203
Batch 42/64 loss: 0.3444035053253174
Batch 43/64 loss: 0.34467267990112305
Batch 44/64 loss: 0.3407468795776367
Batch 45/64 loss: 0.34394049644470215
Batch 46/64 loss: 0.34546542167663574
Batch 47/64 loss: 0.3414403200149536
Batch 48/64 loss: 0.34807050228118896
Batch 49/64 loss: 0.34666645526885986
Batch 50/64 loss: 0.34507429599761963
Batch 51/64 loss: 0.34403812885284424
Batch 52/64 loss: 0.34692174196243286
Batch 53/64 loss: 0.343280553817749
Batch 54/64 loss: 0.3446422815322876
Batch 55/64 loss: 0.3440685272216797
Batch 56/64 loss: 0.3440079689025879
Batch 57/64 loss: 0.3434281349182129
Batch 58/64 loss: 0.3460294008255005
Batch 59/64 loss: 0.3444249629974365
Batch 60/64 loss: 0.3368074893951416
Batch 61/64 loss: 0.34703779220581055
Batch 62/64 loss: 0.3443911075592041
Batch 63/64 loss: 0.3424949645996094
Batch 64/64 loss: 0.34223246574401855
Epoch 103  Train loss: 0.34386327219944374  Val loss: 0.3489695179093744
Saving best model, epoch: 103
Epoch 104
-------------------------------
Batch 1/64 loss: 0.33974409103393555
Batch 2/64 loss: 0.34228789806365967
Batch 3/64 loss: 0.3444054126739502
Batch 4/64 loss: 0.3359913229942322
Batch 5/64 loss: 0.3457290530204773
Batch 6/64 loss: 0.34298115968704224
Batch 7/64 loss: 0.3412315845489502
Batch 8/64 loss: 0.3443313241004944
Batch 9/64 loss: 0.3458387851715088
Batch 10/64 loss: 0.3410912752151489
Batch 11/64 loss: 0.34106385707855225
Batch 12/64 loss: 0.3416064977645874
Batch 13/64 loss: 0.3442351222038269
Batch 14/64 loss: 0.34515905380249023
Batch 15/64 loss: 0.34516453742980957
Batch 16/64 loss: 0.345358669757843
Batch 17/64 loss: 0.34095871448516846
Batch 18/64 loss: 0.33899879455566406
Batch 19/64 loss: 0.34072548151016235
Batch 20/64 loss: 0.33975768089294434
Batch 21/64 loss: 0.347554087638855
Batch 22/64 loss: 0.3441277742385864
Batch 23/64 loss: 0.34286630153656006
Batch 24/64 loss: 0.34655314683914185
Batch 25/64 loss: 0.3416774272918701
Batch 26/64 loss: 0.34681373834609985
Batch 27/64 loss: 0.33820050954818726
Batch 28/64 loss: 0.341722309589386
Batch 29/64 loss: 0.34947502613067627
Batch 30/64 loss: 0.34284770488739014
Batch 31/64 loss: 0.3442383408546448
Batch 32/64 loss: 0.3471602201461792
Batch 33/64 loss: 0.3455810546875
Batch 34/64 loss: 0.3423548936843872
Batch 35/64 loss: 0.3463912606239319
Batch 36/64 loss: 0.34478795528411865
Batch 37/64 loss: 0.3428034782409668
Batch 38/64 loss: 0.3360271453857422
Batch 39/64 loss: 0.34548890590667725
Batch 40/64 loss: 0.3441351652145386
Batch 41/64 loss: 0.34041398763656616
Batch 42/64 loss: 0.3430522680282593
Batch 43/64 loss: 0.3478773832321167
Batch 44/64 loss: 0.3470405340194702
Batch 45/64 loss: 0.34727680683135986
Batch 46/64 loss: 0.34392380714416504
Batch 47/64 loss: 0.3529796600341797
Batch 48/64 loss: 0.34422463178634644
Batch 49/64 loss: 0.3452690839767456
Batch 50/64 loss: 0.33867859840393066
Batch 51/64 loss: 0.3428162932395935
Batch 52/64 loss: 0.34672635793685913
Batch 53/64 loss: 0.3435053825378418
Batch 54/64 loss: 0.3476496934890747
Batch 55/64 loss: 0.34182512760162354
Batch 56/64 loss: 0.3468199372291565
Batch 57/64 loss: 0.34527742862701416
Batch 58/64 loss: 0.3432285785675049
Batch 59/64 loss: 0.34739017486572266
Batch 60/64 loss: 0.3435875177383423
Batch 61/64 loss: 0.34475505352020264
Batch 62/64 loss: 0.3415863513946533
Batch 63/64 loss: 0.34328794479370117
Batch 64/64 loss: 0.3498178720474243
Epoch 104  Train loss: 0.3438278081370335  Val loss: 0.34890677797835307
Saving best model, epoch: 104
Epoch 105
-------------------------------
Batch 1/64 loss: 0.3451545238494873
Batch 2/64 loss: 0.34454917907714844
Batch 3/64 loss: 0.338376522064209
Batch 4/64 loss: 0.34837794303894043
Batch 5/64 loss: 0.3426005244255066
Batch 6/64 loss: 0.3397422432899475
Batch 7/64 loss: 0.34028518199920654
Batch 8/64 loss: 0.3452855348587036
Batch 9/64 loss: 0.3448702096939087
Batch 10/64 loss: 0.34478676319122314
Batch 11/64 loss: 0.3473557233810425
Batch 12/64 loss: 0.34532463550567627
Batch 13/64 loss: 0.3384425640106201
Batch 14/64 loss: 0.34378767013549805
Batch 15/64 loss: 0.3429403305053711
Batch 16/64 loss: 0.3425067067146301
Batch 17/64 loss: 0.33992981910705566
Batch 18/64 loss: 0.3436025381088257
Batch 19/64 loss: 0.34542977809906006
Batch 20/64 loss: 0.340667724609375
Batch 21/64 loss: 0.3469240665435791
Batch 22/64 loss: 0.34195637702941895
Batch 23/64 loss: 0.3412083387374878
Batch 24/64 loss: 0.3461005687713623
Batch 25/64 loss: 0.3431133031845093
Batch 26/64 loss: 0.34084248542785645
Batch 27/64 loss: 0.34527701139450073
Batch 28/64 loss: 0.3401085138320923
Batch 29/64 loss: 0.3495334982872009
Batch 30/64 loss: 0.3438221216201782
Batch 31/64 loss: 0.3490992784500122
Batch 32/64 loss: 0.34108346700668335
Batch 33/64 loss: 0.3432818651199341
Batch 34/64 loss: 0.3385828733444214
Batch 35/64 loss: 0.3487231135368347
Batch 36/64 loss: 0.34452927112579346
Batch 37/64 loss: 0.3418821692466736
Batch 38/64 loss: 0.34042656421661377
Batch 39/64 loss: 0.3439682722091675
Batch 40/64 loss: 0.3438277244567871
Batch 41/64 loss: 0.33977174758911133
Batch 42/64 loss: 0.34403806924819946
Batch 43/64 loss: 0.3455544114112854
Batch 44/64 loss: 0.3404136300086975
Batch 45/64 loss: 0.344147264957428
Batch 46/64 loss: 0.34499281644821167
Batch 47/64 loss: 0.3408047556877136
Batch 48/64 loss: 0.34633582830429077
Batch 49/64 loss: 0.3454177975654602
Batch 50/64 loss: 0.34935158491134644
Batch 51/64 loss: 0.3406957983970642
Batch 52/64 loss: 0.34471839666366577
Batch 53/64 loss: 0.3428001403808594
Batch 54/64 loss: 0.3420170545578003
Batch 55/64 loss: 0.3534635305404663
Batch 56/64 loss: 0.34571516513824463
Batch 57/64 loss: 0.34798359870910645
Batch 58/64 loss: 0.34362971782684326
Batch 59/64 loss: 0.3420506715774536
Batch 60/64 loss: 0.3403412103652954
Batch 61/64 loss: 0.340645968914032
Batch 62/64 loss: 0.3467733860015869
Batch 63/64 loss: 0.34350907802581787
Batch 64/64 loss: 0.3437806963920593
Epoch 105  Train loss: 0.3437068885447932  Val loss: 0.3504255512326034
Epoch 106
-------------------------------
Batch 1/64 loss: 0.3453519940376282
Batch 2/64 loss: 0.34493690729141235
Batch 3/64 loss: 0.3456655740737915
Batch 4/64 loss: 0.3439774513244629
Batch 5/64 loss: 0.33893752098083496
Batch 6/64 loss: 0.34412527084350586
Batch 7/64 loss: 0.3399862051010132
Batch 8/64 loss: 0.3408850431442261
Batch 9/64 loss: 0.34356582164764404
Batch 10/64 loss: 0.34463363885879517
Batch 11/64 loss: 0.34262609481811523
Batch 12/64 loss: 0.3435405492782593
Batch 13/64 loss: 0.34672629833221436
Batch 14/64 loss: 0.345694899559021
Batch 15/64 loss: 0.34590572118759155
Batch 16/64 loss: 0.34452134370803833
Batch 17/64 loss: 0.3473798632621765
Batch 18/64 loss: 0.33784782886505127
Batch 19/64 loss: 0.3397923707962036
Batch 20/64 loss: 0.33665406703948975
Batch 21/64 loss: 0.34458285570144653
Batch 22/64 loss: 0.3463737368583679
Batch 23/64 loss: 0.3430660367012024
Batch 24/64 loss: 0.34330880641937256
Batch 25/64 loss: 0.3416261672973633
Batch 26/64 loss: 0.3447604775428772
Batch 27/64 loss: 0.3459780216217041
Batch 28/64 loss: 0.34518879652023315
Batch 29/64 loss: 0.3426017761230469
Batch 30/64 loss: 0.3416072130203247
Batch 31/64 loss: 0.3454955816268921
Batch 32/64 loss: 0.34049737453460693
Batch 33/64 loss: 0.3465777635574341
Batch 34/64 loss: 0.34596723318099976
Batch 35/64 loss: 0.3435554504394531
Batch 36/64 loss: 0.34473735094070435
Batch 37/64 loss: 0.3437081575393677
Batch 38/64 loss: 0.3449360728263855
Batch 39/64 loss: 0.3445332646369934
Batch 40/64 loss: 0.3405618667602539
Batch 41/64 loss: 0.34242910146713257
Batch 42/64 loss: 0.34296369552612305
Batch 43/64 loss: 0.34654438495635986
Batch 44/64 loss: 0.3456599712371826
Batch 45/64 loss: 0.3512973189353943
Batch 46/64 loss: 0.3456296920776367
Batch 47/64 loss: 0.3432246446609497
Batch 48/64 loss: 0.34528493881225586
Batch 49/64 loss: 0.34272927045822144
Batch 50/64 loss: 0.3418371081352234
Batch 51/64 loss: 0.34440088272094727
Batch 52/64 loss: 0.3414264917373657
Batch 53/64 loss: 0.3469341993331909
Batch 54/64 loss: 0.3481886386871338
Batch 55/64 loss: 0.3424057960510254
Batch 56/64 loss: 0.3390318751335144
Batch 57/64 loss: 0.3416173458099365
Batch 58/64 loss: 0.3400496244430542
Batch 59/64 loss: 0.3412264585494995
Batch 60/64 loss: 0.34309935569763184
Batch 61/64 loss: 0.339593768119812
Batch 62/64 loss: 0.34287428855895996
Batch 63/64 loss: 0.3496968746185303
Batch 64/64 loss: 0.33991318941116333
Epoch 106  Train loss: 0.343615671933866  Val loss: 0.34964390124651984
Epoch 107
-------------------------------
Batch 1/64 loss: 0.3488312363624573
Batch 2/64 loss: 0.3462151288986206
Batch 3/64 loss: 0.3353017568588257
Batch 4/64 loss: 0.3420417308807373
Batch 5/64 loss: 0.3461883068084717
Batch 6/64 loss: 0.34731215238571167
Batch 7/64 loss: 0.34269052743911743
Batch 8/64 loss: 0.34328240156173706
Batch 9/64 loss: 0.3400719165802002
Batch 10/64 loss: 0.3405667543411255
Batch 11/64 loss: 0.34262585639953613
Batch 12/64 loss: 0.3436870574951172
Batch 13/64 loss: 0.34439241886138916
Batch 14/64 loss: 0.3444643020629883
Batch 15/64 loss: 0.34650468826293945
Batch 16/64 loss: 0.34259843826293945
Batch 17/64 loss: 0.34467458724975586
Batch 18/64 loss: 0.34223395586013794
Batch 19/64 loss: 0.3407402038574219
Batch 20/64 loss: 0.3425479531288147
Batch 21/64 loss: 0.3430896997451782
Batch 22/64 loss: 0.3435145616531372
Batch 23/64 loss: 0.33978158235549927
Batch 24/64 loss: 0.3479750156402588
Batch 25/64 loss: 0.3428868055343628
Batch 26/64 loss: 0.34682583808898926
Batch 27/64 loss: 0.3432232141494751
Batch 28/64 loss: 0.3490382432937622
Batch 29/64 loss: 0.3409271240234375
Batch 30/64 loss: 0.3426099419593811
Batch 31/64 loss: 0.344302773475647
Batch 32/64 loss: 0.341499924659729
Batch 33/64 loss: 0.34474116563796997
Batch 34/64 loss: 0.3415490984916687
Batch 35/64 loss: 0.3480948209762573
Batch 36/64 loss: 0.3406236171722412
Batch 37/64 loss: 0.3358573913574219
Batch 38/64 loss: 0.3459770083427429
Batch 39/64 loss: 0.34155112504959106
Batch 40/64 loss: 0.3397986888885498
Batch 41/64 loss: 0.34041154384613037
Batch 42/64 loss: 0.3401975631713867
Batch 43/64 loss: 0.34290969371795654
Batch 44/64 loss: 0.34313881397247314
Batch 45/64 loss: 0.34605300426483154
Batch 46/64 loss: 0.34515637159347534
Batch 47/64 loss: 0.34054744243621826
Batch 48/64 loss: 0.3437730669975281
Batch 49/64 loss: 0.34312719106674194
Batch 50/64 loss: 0.34698307514190674
Batch 51/64 loss: 0.34347105026245117
Batch 52/64 loss: 0.3399529457092285
Batch 53/64 loss: 0.3432239294052124
Batch 54/64 loss: 0.3399483561515808
Batch 55/64 loss: 0.3461158275604248
Batch 56/64 loss: 0.34299176931381226
Batch 57/64 loss: 0.3423128128051758
Batch 58/64 loss: 0.3407352566719055
Batch 59/64 loss: 0.342043399810791
Batch 60/64 loss: 0.34558796882629395
Batch 61/64 loss: 0.3507702350616455
Batch 62/64 loss: 0.3428632616996765
Batch 63/64 loss: 0.3441653251647949
Batch 64/64 loss: 0.345941960811615
Epoch 107  Train loss: 0.34332196689119526  Val loss: 0.3485776034417431
Saving best model, epoch: 107
Epoch 108
-------------------------------
Batch 1/64 loss: 0.3472515344619751
Batch 2/64 loss: 0.3414731025695801
Batch 3/64 loss: 0.33879292011260986
Batch 4/64 loss: 0.3436269760131836
Batch 5/64 loss: 0.33817118406295776
Batch 6/64 loss: 0.3482774496078491
Batch 7/64 loss: 0.3391159772872925
Batch 8/64 loss: 0.33990293741226196
Batch 9/64 loss: 0.34167367219924927
Batch 10/64 loss: 0.34165632724761963
Batch 11/64 loss: 0.3442232608795166
Batch 12/64 loss: 0.34195196628570557
Batch 13/64 loss: 0.34322357177734375
Batch 14/64 loss: 0.34733861684799194
Batch 15/64 loss: 0.3397747278213501
Batch 16/64 loss: 0.34276580810546875
Batch 17/64 loss: 0.34691107273101807
Batch 18/64 loss: 0.3414471745491028
Batch 19/64 loss: 0.3460593819618225
Batch 20/64 loss: 0.3446069359779358
Batch 21/64 loss: 0.3428735136985779
Batch 22/64 loss: 0.340673565864563
Batch 23/64 loss: 0.3436375856399536
Batch 24/64 loss: 0.3408372402191162
Batch 25/64 loss: 0.34598177671432495
Batch 26/64 loss: 0.3449251651763916
Batch 27/64 loss: 0.3460705280303955
Batch 28/64 loss: 0.3416283130645752
Batch 29/64 loss: 0.3481423854827881
Batch 30/64 loss: 0.3460720181465149
Batch 31/64 loss: 0.3480832576751709
Batch 32/64 loss: 0.3439323902130127
Batch 33/64 loss: 0.34178125858306885
Batch 34/64 loss: 0.3440263271331787
Batch 35/64 loss: 0.3464597463607788
Batch 36/64 loss: 0.3393617868423462
Batch 37/64 loss: 0.34249597787857056
Batch 38/64 loss: 0.3428281545639038
Batch 39/64 loss: 0.3480798602104187
Batch 40/64 loss: 0.34434837102890015
Batch 41/64 loss: 0.3441324234008789
Batch 42/64 loss: 0.34414172172546387
Batch 43/64 loss: 0.3395722508430481
Batch 44/64 loss: 0.3452834486961365
Batch 45/64 loss: 0.33999037742614746
Batch 46/64 loss: 0.34097808599472046
Batch 47/64 loss: 0.3439229726791382
Batch 48/64 loss: 0.3392915725708008
Batch 49/64 loss: 0.3455524444580078
Batch 50/64 loss: 0.3434954881668091
Batch 51/64 loss: 0.34388577938079834
Batch 52/64 loss: 0.3462292551994324
Batch 53/64 loss: 0.3390956521034241
Batch 54/64 loss: 0.34658318758010864
Batch 55/64 loss: 0.34161603450775146
Batch 56/64 loss: 0.3434385657310486
Batch 57/64 loss: 0.34129250049591064
Batch 58/64 loss: 0.34485507011413574
Batch 59/64 loss: 0.34886491298675537
Batch 60/64 loss: 0.34039950370788574
Batch 61/64 loss: 0.3434290885925293
Batch 62/64 loss: 0.3387984037399292
Batch 63/64 loss: 0.3438282012939453
Batch 64/64 loss: 0.343916118144989
Epoch 108  Train loss: 0.3433270251049715  Val loss: 0.3487116209010488
Epoch 109
-------------------------------
Batch 1/64 loss: 0.3441709876060486
Batch 2/64 loss: 0.34245556592941284
Batch 3/64 loss: 0.3467320203781128
Batch 4/64 loss: 0.3416425585746765
Batch 5/64 loss: 0.34211528301239014
Batch 6/64 loss: 0.3434222936630249
Batch 7/64 loss: 0.34399354457855225
Batch 8/64 loss: 0.35011982917785645
Batch 9/64 loss: 0.34407806396484375
Batch 10/64 loss: 0.3436632752418518
Batch 11/64 loss: 0.33942127227783203
Batch 12/64 loss: 0.3407135605812073
Batch 13/64 loss: 0.342571496963501
Batch 14/64 loss: 0.3419037461280823
Batch 15/64 loss: 0.3382343649864197
Batch 16/64 loss: 0.342628538608551
Batch 17/64 loss: 0.3419734239578247
Batch 18/64 loss: 0.3431607484817505
Batch 19/64 loss: 0.3440983295440674
Batch 20/64 loss: 0.34432435035705566
Batch 21/64 loss: 0.33968889713287354
Batch 22/64 loss: 0.3415650725364685
Batch 23/64 loss: 0.3429677486419678
Batch 24/64 loss: 0.3436417579650879
Batch 25/64 loss: 0.34585392475128174
Batch 26/64 loss: 0.34588855504989624
Batch 27/64 loss: 0.3412741422653198
Batch 28/64 loss: 0.3470844030380249
Batch 29/64 loss: 0.34142476320266724
Batch 30/64 loss: 0.3499021530151367
Batch 31/64 loss: 0.3395006060600281
Batch 32/64 loss: 0.34221720695495605
Batch 33/64 loss: 0.3485996723175049
Batch 34/64 loss: 0.3391209840774536
Batch 35/64 loss: 0.33953791856765747
Batch 36/64 loss: 0.3442373275756836
Batch 37/64 loss: 0.3434833288192749
Batch 38/64 loss: 0.3406407833099365
Batch 39/64 loss: 0.3471314311027527
Batch 40/64 loss: 0.3399229049682617
Batch 41/64 loss: 0.34732139110565186
Batch 42/64 loss: 0.34238797426223755
Batch 43/64 loss: 0.3407917618751526
Batch 44/64 loss: 0.3395223021507263
Batch 45/64 loss: 0.3418894410133362
Batch 46/64 loss: 0.34331071376800537
Batch 47/64 loss: 0.3446383476257324
Batch 48/64 loss: 0.34123557806015015
Batch 49/64 loss: 0.3445228338241577
Batch 50/64 loss: 0.3426157236099243
Batch 51/64 loss: 0.3463231325149536
Batch 52/64 loss: 0.33918827772140503
Batch 53/64 loss: 0.34029507637023926
Batch 54/64 loss: 0.3447868227958679
Batch 55/64 loss: 0.34397852420806885
Batch 56/64 loss: 0.3452368974685669
Batch 57/64 loss: 0.34516048431396484
Batch 58/64 loss: 0.339740514755249
Batch 59/64 loss: 0.34284722805023193
Batch 60/64 loss: 0.3477028012275696
Batch 61/64 loss: 0.3382868766784668
Batch 62/64 loss: 0.3405892252922058
Batch 63/64 loss: 0.3448428511619568
Batch 64/64 loss: 0.3454629182815552
Epoch 109  Train loss: 0.3430810792773378  Val loss: 0.35005822501231715
Epoch 110
-------------------------------
Batch 1/64 loss: 0.3437303304672241
Batch 2/64 loss: 0.3433132767677307
Batch 3/64 loss: 0.3423691391944885
Batch 4/64 loss: 0.34573894739151
Batch 5/64 loss: 0.340933620929718
Batch 6/64 loss: 0.3387741446495056
Batch 7/64 loss: 0.3416682481765747
Batch 8/64 loss: 0.3486744165420532
Batch 9/64 loss: 0.34440743923187256
Batch 10/64 loss: 0.3408240079879761
Batch 11/64 loss: 0.3439420461654663
Batch 12/64 loss: 0.3418042063713074
Batch 13/64 loss: 0.3435719609260559
Batch 14/64 loss: 0.3469492197036743
Batch 15/64 loss: 0.34007346630096436
Batch 16/64 loss: 0.3409658670425415
Batch 17/64 loss: 0.3460419178009033
Batch 18/64 loss: 0.33755743503570557
Batch 19/64 loss: 0.3443620800971985
Batch 20/64 loss: 0.34425485134124756
Batch 21/64 loss: 0.34507155418395996
Batch 22/64 loss: 0.34453505277633667
Batch 23/64 loss: 0.34039759635925293
Batch 24/64 loss: 0.34281837940216064
Batch 25/64 loss: 0.3445259928703308
Batch 26/64 loss: 0.3468360900878906
Batch 27/64 loss: 0.34360694885253906
Batch 28/64 loss: 0.3439948558807373
Batch 29/64 loss: 0.3405064344406128
Batch 30/64 loss: 0.34341728687286377
Batch 31/64 loss: 0.3377470374107361
Batch 32/64 loss: 0.3449183702468872
Batch 33/64 loss: 0.3474530577659607
Batch 34/64 loss: 0.3482625484466553
Batch 35/64 loss: 0.3448066711425781
Batch 36/64 loss: 0.3399103879928589
Batch 37/64 loss: 0.3441590666770935
Batch 38/64 loss: 0.3400752544403076
Batch 39/64 loss: 0.3486562967300415
Batch 40/64 loss: 0.3439074158668518
Batch 41/64 loss: 0.3470137119293213
Batch 42/64 loss: 0.3425520658493042
Batch 43/64 loss: 0.34131157398223877
Batch 44/64 loss: 0.3469620943069458
Batch 45/64 loss: 0.34169572591781616
Batch 46/64 loss: 0.34163516759872437
Batch 47/64 loss: 0.3407900333404541
Batch 48/64 loss: 0.34748393297195435
Batch 49/64 loss: 0.34615087509155273
Batch 50/64 loss: 0.339438796043396
Batch 51/64 loss: 0.3424343466758728
Batch 52/64 loss: 0.34078627824783325
Batch 53/64 loss: 0.3422185778617859
Batch 54/64 loss: 0.3386843204498291
Batch 55/64 loss: 0.345436692237854
Batch 56/64 loss: 0.346036434173584
Batch 57/64 loss: 0.33840566873550415
Batch 58/64 loss: 0.3427469730377197
Batch 59/64 loss: 0.3460162281990051
Batch 60/64 loss: 0.34097909927368164
Batch 61/64 loss: 0.3421362638473511
Batch 62/64 loss: 0.34190940856933594
Batch 63/64 loss: 0.34097468852996826
Batch 64/64 loss: 0.3442651629447937
Epoch 110  Train loss: 0.3431774235239216  Val loss: 0.34807066040760054
Saving best model, epoch: 110
Epoch 111
-------------------------------
Batch 1/64 loss: 0.34044981002807617
Batch 2/64 loss: 0.3408709764480591
Batch 3/64 loss: 0.33960145711898804
Batch 4/64 loss: 0.34288692474365234
Batch 5/64 loss: 0.3428061604499817
Batch 6/64 loss: 0.34079408645629883
Batch 7/64 loss: 0.3435176610946655
Batch 8/64 loss: 0.3437540531158447
Batch 9/64 loss: 0.34438949823379517
Batch 10/64 loss: 0.3445039987564087
Batch 11/64 loss: 0.3437250852584839
Batch 12/64 loss: 0.3434585928916931
Batch 13/64 loss: 0.343492329120636
Batch 14/64 loss: 0.3429138660430908
Batch 15/64 loss: 0.3418828248977661
Batch 16/64 loss: 0.34367871284484863
Batch 17/64 loss: 0.34210848808288574
Batch 18/64 loss: 0.3414512872695923
Batch 19/64 loss: 0.3385445475578308
Batch 20/64 loss: 0.34240227937698364
Batch 21/64 loss: 0.34816551208496094
Batch 22/64 loss: 0.34171104431152344
Batch 23/64 loss: 0.34719371795654297
Batch 24/64 loss: 0.3424542546272278
Batch 25/64 loss: 0.34263336658477783
Batch 26/64 loss: 0.3392907977104187
Batch 27/64 loss: 0.3437352180480957
Batch 28/64 loss: 0.34285271167755127
Batch 29/64 loss: 0.34180736541748047
Batch 30/64 loss: 0.34382784366607666
Batch 31/64 loss: 0.34314918518066406
Batch 32/64 loss: 0.3442661762237549
Batch 33/64 loss: 0.3374745845794678
Batch 34/64 loss: 0.3436007499694824
Batch 35/64 loss: 0.34610164165496826
Batch 36/64 loss: 0.34406352043151855
Batch 37/64 loss: 0.34325242042541504
Batch 38/64 loss: 0.3412777781486511
Batch 39/64 loss: 0.34428489208221436
Batch 40/64 loss: 0.3419761657714844
Batch 41/64 loss: 0.34134089946746826
Batch 42/64 loss: 0.3419688940048218
Batch 43/64 loss: 0.34186965227127075
Batch 44/64 loss: 0.3422577381134033
Batch 45/64 loss: 0.34548985958099365
Batch 46/64 loss: 0.3444937467575073
Batch 47/64 loss: 0.3402867317199707
Batch 48/64 loss: 0.3426681160926819
Batch 49/64 loss: 0.3456606864929199
Batch 50/64 loss: 0.34427177906036377
Batch 51/64 loss: 0.3434133529663086
Batch 52/64 loss: 0.34556519985198975
Batch 53/64 loss: 0.34349656105041504
Batch 54/64 loss: 0.3451725244522095
Batch 55/64 loss: 0.33840465545654297
Batch 56/64 loss: 0.3421051502227783
Batch 57/64 loss: 0.3435455560684204
Batch 58/64 loss: 0.3404085040092468
Batch 59/64 loss: 0.3443390727043152
Batch 60/64 loss: 0.34947800636291504
Batch 61/64 loss: 0.3396676182746887
Batch 62/64 loss: 0.33721065521240234
Batch 63/64 loss: 0.34097951650619507
Batch 64/64 loss: 0.3407366871833801
Epoch 111  Train loss: 0.34274507574006624  Val loss: 0.3479011107965843
Saving best model, epoch: 111
Epoch 112
-------------------------------
Batch 1/64 loss: 0.3408384323120117
Batch 2/64 loss: 0.34092843532562256
Batch 3/64 loss: 0.3421001434326172
Batch 4/64 loss: 0.3434567451477051
Batch 5/64 loss: 0.3415583372116089
Batch 6/64 loss: 0.34261441230773926
Batch 7/64 loss: 0.3439463973045349
Batch 8/64 loss: 0.339438796043396
Batch 9/64 loss: 0.3395199775695801
Batch 10/64 loss: 0.34593093395233154
Batch 11/64 loss: 0.3404989242553711
Batch 12/64 loss: 0.3383888602256775
Batch 13/64 loss: 0.33831489086151123
Batch 14/64 loss: 0.3451698422431946
Batch 15/64 loss: 0.3422991633415222
Batch 16/64 loss: 0.3403661251068115
Batch 17/64 loss: 0.3435872793197632
Batch 18/64 loss: 0.3422759771347046
Batch 19/64 loss: 0.34557557106018066
Batch 20/64 loss: 0.34286999702453613
Batch 21/64 loss: 0.3385680913925171
Batch 22/64 loss: 0.33825981616973877
Batch 23/64 loss: 0.3462703227996826
Batch 24/64 loss: 0.3438434600830078
Batch 25/64 loss: 0.34359198808670044
Batch 26/64 loss: 0.3439316749572754
Batch 27/64 loss: 0.3413444757461548
Batch 28/64 loss: 0.34362083673477173
Batch 29/64 loss: 0.3392934203147888
Batch 30/64 loss: 0.3477374315261841
Batch 31/64 loss: 0.3455100655555725
Batch 32/64 loss: 0.34790003299713135
Batch 33/64 loss: 0.34266161918640137
Batch 34/64 loss: 0.3472384214401245
Batch 35/64 loss: 0.33989912271499634
Batch 36/64 loss: 0.3431882858276367
Batch 37/64 loss: 0.34815216064453125
Batch 38/64 loss: 0.34329795837402344
Batch 39/64 loss: 0.34253549575805664
Batch 40/64 loss: 0.3424633741378784
Batch 41/64 loss: 0.340815007686615
Batch 42/64 loss: 0.3443335294723511
Batch 43/64 loss: 0.3438596725463867
Batch 44/64 loss: 0.3416628837585449
Batch 45/64 loss: 0.3436843156814575
Batch 46/64 loss: 0.3448837995529175
Batch 47/64 loss: 0.3441654443740845
Batch 48/64 loss: 0.3438842296600342
Batch 49/64 loss: 0.34684044122695923
Batch 50/64 loss: 0.34966206550598145
Batch 51/64 loss: 0.3423818349838257
Batch 52/64 loss: 0.34226030111312866
Batch 53/64 loss: 0.339668333530426
Batch 54/64 loss: 0.3404797315597534
Batch 55/64 loss: 0.34425830841064453
Batch 56/64 loss: 0.34185218811035156
Batch 57/64 loss: 0.34468042850494385
Batch 58/64 loss: 0.3415765166282654
Batch 59/64 loss: 0.33910030126571655
Batch 60/64 loss: 0.33805912733078003
Batch 61/64 loss: 0.34082531929016113
Batch 62/64 loss: 0.34259146451950073
Batch 63/64 loss: 0.342077374458313
Batch 64/64 loss: 0.34454792737960815
Epoch 112  Train loss: 0.34276079780915203  Val loss: 0.3492484551524788
Epoch 113
-------------------------------
Batch 1/64 loss: 0.34264683723449707
Batch 2/64 loss: 0.33900928497314453
Batch 3/64 loss: 0.3496668338775635
Batch 4/64 loss: 0.34605085849761963
Batch 5/64 loss: 0.3454597592353821
Batch 6/64 loss: 0.341569185256958
Batch 7/64 loss: 0.3414314389228821
Batch 8/64 loss: 0.3410710096359253
Batch 9/64 loss: 0.34488445520401
Batch 10/64 loss: 0.34087443351745605
Batch 11/64 loss: 0.3458554744720459
Batch 12/64 loss: 0.3429168462753296
Batch 13/64 loss: 0.34368205070495605
Batch 14/64 loss: 0.346421480178833
Batch 15/64 loss: 0.34296220541000366
Batch 16/64 loss: 0.3415480852127075
Batch 17/64 loss: 0.3491058349609375
Batch 18/64 loss: 0.33800679445266724
Batch 19/64 loss: 0.34009313583374023
Batch 20/64 loss: 0.33873236179351807
Batch 21/64 loss: 0.33999598026275635
Batch 22/64 loss: 0.33983319997787476
Batch 23/64 loss: 0.3398208022117615
Batch 24/64 loss: 0.3448089361190796
Batch 25/64 loss: 0.3410281538963318
Batch 26/64 loss: 0.33690351247787476
Batch 27/64 loss: 0.34388476610183716
Batch 28/64 loss: 0.34719228744506836
Batch 29/64 loss: 0.3413351774215698
Batch 30/64 loss: 0.344310462474823
Batch 31/64 loss: 0.3389095067977905
Batch 32/64 loss: 0.34283679723739624
Batch 33/64 loss: 0.34105587005615234
Batch 34/64 loss: 0.34583258628845215
Batch 35/64 loss: 0.3398247957229614
Batch 36/64 loss: 0.34022241830825806
Batch 37/64 loss: 0.34302079677581787
Batch 38/64 loss: 0.34361732006073
Batch 39/64 loss: 0.3419014811515808
Batch 40/64 loss: 0.34455740451812744
Batch 41/64 loss: 0.3468153476715088
Batch 42/64 loss: 0.3433495759963989
Batch 43/64 loss: 0.33926206827163696
Batch 44/64 loss: 0.3415803909301758
Batch 45/64 loss: 0.3445003032684326
Batch 46/64 loss: 0.34586310386657715
Batch 47/64 loss: 0.3422304391860962
Batch 48/64 loss: 0.3402714729309082
Batch 49/64 loss: 0.3413814306259155
Batch 50/64 loss: 0.3389014005661011
Batch 51/64 loss: 0.34419310092926025
Batch 52/64 loss: 0.34154200553894043
Batch 53/64 loss: 0.3435009717941284
Batch 54/64 loss: 0.3419821262359619
Batch 55/64 loss: 0.3420001268386841
Batch 56/64 loss: 0.34407955408096313
Batch 57/64 loss: 0.34102094173431396
Batch 58/64 loss: 0.34373724460601807
Batch 59/64 loss: 0.35027092695236206
Batch 60/64 loss: 0.34027934074401855
Batch 61/64 loss: 0.34068405628204346
Batch 62/64 loss: 0.34126996994018555
Batch 63/64 loss: 0.34247255325317383
Batch 64/64 loss: 0.3410968780517578
Epoch 113  Train loss: 0.3425865369684556  Val loss: 0.34823768880359085
Epoch 114
-------------------------------
Batch 1/64 loss: 0.3407377600669861
Batch 2/64 loss: 0.34479641914367676
Batch 3/64 loss: 0.34166693687438965
Batch 4/64 loss: 0.34055304527282715
Batch 5/64 loss: 0.3444642424583435
Batch 6/64 loss: 0.34244340658187866
Batch 7/64 loss: 0.341738224029541
Batch 8/64 loss: 0.34501171112060547
Batch 9/64 loss: 0.3409448266029358
Batch 10/64 loss: 0.3441908359527588
Batch 11/64 loss: 0.34480947256088257
Batch 12/64 loss: 0.3413785696029663
Batch 13/64 loss: 0.3403666615486145
Batch 14/64 loss: 0.34316033124923706
Batch 15/64 loss: 0.3423023223876953
Batch 16/64 loss: 0.3391600251197815
Batch 17/64 loss: 0.3444196581840515
Batch 18/64 loss: 0.34684503078460693
Batch 19/64 loss: 0.34162265062332153
Batch 20/64 loss: 0.3430325984954834
Batch 21/64 loss: 0.3446767330169678
Batch 22/64 loss: 0.3416101932525635
Batch 23/64 loss: 0.3417741060256958
Batch 24/64 loss: 0.34053611755371094
Batch 25/64 loss: 0.33733463287353516
Batch 26/64 loss: 0.3412870764732361
Batch 27/64 loss: 0.34265410900115967
Batch 28/64 loss: 0.34195297956466675
Batch 29/64 loss: 0.34116554260253906
Batch 30/64 loss: 0.3441542387008667
Batch 31/64 loss: 0.3409915566444397
Batch 32/64 loss: 0.34041690826416016
Batch 33/64 loss: 0.33749687671661377
Batch 34/64 loss: 0.3424537181854248
Batch 35/64 loss: 0.339760422706604
Batch 36/64 loss: 0.3439866304397583
Batch 37/64 loss: 0.3433688282966614
Batch 38/64 loss: 0.34161144495010376
Batch 39/64 loss: 0.34905779361724854
Batch 40/64 loss: 0.34211885929107666
Batch 41/64 loss: 0.3431457281112671
Batch 42/64 loss: 0.34389960765838623
Batch 43/64 loss: 0.34545522928237915
Batch 44/64 loss: 0.34080296754837036
Batch 45/64 loss: 0.3401114344596863
Batch 46/64 loss: 0.3443247079849243
Batch 47/64 loss: 0.34422075748443604
Batch 48/64 loss: 0.34163421392440796
Batch 49/64 loss: 0.3461686372756958
Batch 50/64 loss: 0.3411030173301697
Batch 51/64 loss: 0.34171658754348755
Batch 52/64 loss: 0.3382601737976074
Batch 53/64 loss: 0.3461810350418091
Batch 54/64 loss: 0.34554505348205566
Batch 55/64 loss: 0.34211039543151855
Batch 56/64 loss: 0.34190768003463745
Batch 57/64 loss: 0.3459364175796509
Batch 58/64 loss: 0.3395553231239319
Batch 59/64 loss: 0.34449267387390137
Batch 60/64 loss: 0.3505764603614807
Batch 61/64 loss: 0.3427726626396179
Batch 62/64 loss: 0.3399389982223511
Batch 63/64 loss: 0.34233295917510986
Batch 64/64 loss: 0.33950161933898926
Epoch 114  Train loss: 0.34257054796405867  Val loss: 0.34790606392208245
Epoch 115
-------------------------------
Batch 1/64 loss: 0.34388166666030884
Batch 2/64 loss: 0.34217262268066406
Batch 3/64 loss: 0.3491697311401367
Batch 4/64 loss: 0.3436371088027954
Batch 5/64 loss: 0.34815388917922974
Batch 6/64 loss: 0.3459949493408203
Batch 7/64 loss: 0.3427169919013977
Batch 8/64 loss: 0.34129273891448975
Batch 9/64 loss: 0.34064018726348877
Batch 10/64 loss: 0.3445512056350708
Batch 11/64 loss: 0.34413254261016846
Batch 12/64 loss: 0.34113413095474243
Batch 13/64 loss: 0.3430945873260498
Batch 14/64 loss: 0.34266483783721924
Batch 15/64 loss: 0.3402066230773926
Batch 16/64 loss: 0.341876745223999
Batch 17/64 loss: 0.3402000665664673
Batch 18/64 loss: 0.3419904112815857
Batch 19/64 loss: 0.3416823744773865
Batch 20/64 loss: 0.33985888957977295
Batch 21/64 loss: 0.3470974564552307
Batch 22/64 loss: 0.34151017665863037
Batch 23/64 loss: 0.3414657711982727
Batch 24/64 loss: 0.3392481803894043
Batch 25/64 loss: 0.3372834324836731
Batch 26/64 loss: 0.34044623374938965
Batch 27/64 loss: 0.3454608917236328
Batch 28/64 loss: 0.3358471989631653
Batch 29/64 loss: 0.3395735025405884
Batch 30/64 loss: 0.34174102544784546
Batch 31/64 loss: 0.3462297320365906
Batch 32/64 loss: 0.34236037731170654
Batch 33/64 loss: 0.33943718671798706
Batch 34/64 loss: 0.3489876985549927
Batch 35/64 loss: 0.34220361709594727
Batch 36/64 loss: 0.3400919437408447
Batch 37/64 loss: 0.34040582180023193
Batch 38/64 loss: 0.34163355827331543
Batch 39/64 loss: 0.34135687351226807
Batch 40/64 loss: 0.3444035053253174
Batch 41/64 loss: 0.345839262008667
Batch 42/64 loss: 0.34196746349334717
Batch 43/64 loss: 0.335665762424469
Batch 44/64 loss: 0.3451184034347534
Batch 45/64 loss: 0.3416825532913208
Batch 46/64 loss: 0.34019458293914795
Batch 47/64 loss: 0.3422914743423462
Batch 48/64 loss: 0.3449462652206421
Batch 49/64 loss: 0.3431142568588257
Batch 50/64 loss: 0.3411139249801636
Batch 51/64 loss: 0.3416309952735901
Batch 52/64 loss: 0.34017258882522583
Batch 53/64 loss: 0.3481004238128662
Batch 54/64 loss: 0.3461298942565918
Batch 55/64 loss: 0.33697307109832764
Batch 56/64 loss: 0.3372945785522461
Batch 57/64 loss: 0.34347009658813477
Batch 58/64 loss: 0.3466503620147705
Batch 59/64 loss: 0.3395744562149048
Batch 60/64 loss: 0.34209877252578735
Batch 61/64 loss: 0.34465283155441284
Batch 62/64 loss: 0.3422175645828247
Batch 63/64 loss: 0.344720721244812
Batch 64/64 loss: 0.3416776657104492
Epoch 115  Train loss: 0.3423955300275017  Val loss: 0.3473641382869576
Saving best model, epoch: 115
Epoch 116
-------------------------------
Batch 1/64 loss: 0.3424067497253418
Batch 2/64 loss: 0.3370019197463989
Batch 3/64 loss: 0.3379875421524048
Batch 4/64 loss: 0.342692494392395
Batch 5/64 loss: 0.3427398204803467
Batch 6/64 loss: 0.340137779712677
Batch 7/64 loss: 0.34461259841918945
Batch 8/64 loss: 0.3409954309463501
Batch 9/64 loss: 0.3416874408721924
Batch 10/64 loss: 0.34087860584259033
Batch 11/64 loss: 0.3427729606628418
Batch 12/64 loss: 0.33913761377334595
Batch 13/64 loss: 0.3388800621032715
Batch 14/64 loss: 0.34655725955963135
Batch 15/64 loss: 0.33702361583709717
Batch 16/64 loss: 0.3367636203765869
Batch 17/64 loss: 0.33444106578826904
Batch 18/64 loss: 0.3416430354118347
Batch 19/64 loss: 0.34420257806777954
Batch 20/64 loss: 0.34612685441970825
Batch 21/64 loss: 0.3450492024421692
Batch 22/64 loss: 0.34897518157958984
Batch 23/64 loss: 0.3474775552749634
Batch 24/64 loss: 0.33992815017700195
Batch 25/64 loss: 0.34324485063552856
Batch 26/64 loss: 0.33434033393859863
Batch 27/64 loss: 0.34254223108291626
Batch 28/64 loss: 0.3412848711013794
Batch 29/64 loss: 0.33878040313720703
Batch 30/64 loss: 0.33795881271362305
Batch 31/64 loss: 0.334903359413147
Batch 32/64 loss: 0.34203779697418213
Batch 33/64 loss: 0.3348977565765381
Batch 34/64 loss: 0.34131181240081787
Batch 35/64 loss: 0.3424074649810791
Batch 36/64 loss: 0.34477758407592773
Batch 37/64 loss: 0.34101879596710205
Batch 38/64 loss: 0.34193241596221924
Batch 39/64 loss: 0.3433524966239929
Batch 40/64 loss: 0.34244072437286377
Batch 41/64 loss: 0.34101784229278564
Batch 42/64 loss: 0.3393089771270752
Batch 43/64 loss: 0.344821572303772
Batch 44/64 loss: 0.34498119354248047
Batch 45/64 loss: 0.3417070508003235
Batch 46/64 loss: 0.34416472911834717
Batch 47/64 loss: 0.3447922468185425
Batch 48/64 loss: 0.34757155179977417
Batch 49/64 loss: 0.34195828437805176
Batch 50/64 loss: 0.34379154443740845
Batch 51/64 loss: 0.33973515033721924
Batch 52/64 loss: 0.34412193298339844
Batch 53/64 loss: 0.34785717725753784
Batch 54/64 loss: 0.340543270111084
Batch 55/64 loss: 0.34866082668304443
Batch 56/64 loss: 0.344163179397583
Batch 57/64 loss: 0.33871352672576904
Batch 58/64 loss: 0.33867043256759644
Batch 59/64 loss: 0.3432357907295227
Batch 60/64 loss: 0.3430875539779663
Batch 61/64 loss: 0.34728991985321045
Batch 62/64 loss: 0.34521400928497314
Batch 63/64 loss: 0.34582579135894775
Batch 64/64 loss: 0.33932334184646606
Epoch 116  Train loss: 0.3420090495371351  Val loss: 0.3489693122631086
Epoch 117
-------------------------------
Batch 1/64 loss: 0.3403390645980835
Batch 2/64 loss: 0.3401646614074707
Batch 3/64 loss: 0.34197306632995605
Batch 4/64 loss: 0.3411467671394348
Batch 5/64 loss: 0.3404994010925293
Batch 6/64 loss: 0.344974160194397
Batch 7/64 loss: 0.3419896960258484
Batch 8/64 loss: 0.34138453006744385
Batch 9/64 loss: 0.34544140100479126
Batch 10/64 loss: 0.34411656856536865
Batch 11/64 loss: 0.34170007705688477
Batch 12/64 loss: 0.3426626920700073
Batch 13/64 loss: 0.34541839361190796
Batch 14/64 loss: 0.33950114250183105
Batch 15/64 loss: 0.34198832511901855
Batch 16/64 loss: 0.3398946523666382
Batch 17/64 loss: 0.3411105275154114
Batch 18/64 loss: 0.34323620796203613
Batch 19/64 loss: 0.3405216932296753
Batch 20/64 loss: 0.33991312980651855
Batch 21/64 loss: 0.34812402725219727
Batch 22/64 loss: 0.34125572443008423
Batch 23/64 loss: 0.33902764320373535
Batch 24/64 loss: 0.34139513969421387
Batch 25/64 loss: 0.34058815240859985
Batch 26/64 loss: 0.341768741607666
Batch 27/64 loss: 0.34409862756729126
Batch 28/64 loss: 0.33816438913345337
Batch 29/64 loss: 0.3380473852157593
Batch 30/64 loss: 0.3423272371292114
Batch 31/64 loss: 0.3447808027267456
Batch 32/64 loss: 0.34205687046051025
Batch 33/64 loss: 0.3416128158569336
Batch 34/64 loss: 0.34044480323791504
Batch 35/64 loss: 0.3445584774017334
Batch 36/64 loss: 0.34289097785949707
Batch 37/64 loss: 0.3395644426345825
Batch 38/64 loss: 0.3410221338272095
Batch 39/64 loss: 0.3456299304962158
Batch 40/64 loss: 0.34076064825057983
Batch 41/64 loss: 0.34493696689605713
Batch 42/64 loss: 0.33882176876068115
Batch 43/64 loss: 0.34430789947509766
Batch 44/64 loss: 0.3462892770767212
Batch 45/64 loss: 0.33989882469177246
Batch 46/64 loss: 0.34555649757385254
Batch 47/64 loss: 0.34163904190063477
Batch 48/64 loss: 0.33786123991012573
Batch 49/64 loss: 0.3446348309516907
Batch 50/64 loss: 0.3416762351989746
Batch 51/64 loss: 0.34247153997421265
Batch 52/64 loss: 0.3472781181335449
Batch 53/64 loss: 0.3419848680496216
Batch 54/64 loss: 0.3432050943374634
Batch 55/64 loss: 0.3398746848106384
Batch 56/64 loss: 0.3413856029510498
Batch 57/64 loss: 0.337268590927124
Batch 58/64 loss: 0.3419156074523926
Batch 59/64 loss: 0.3395901918411255
Batch 60/64 loss: 0.3451331853866577
Batch 61/64 loss: 0.34058916568756104
Batch 62/64 loss: 0.3460690975189209
Batch 63/64 loss: 0.3391488790512085
Batch 64/64 loss: 0.3421144485473633
Epoch 117  Train loss: 0.34202695173375747  Val loss: 0.34803941958548684
Epoch 118
-------------------------------
Batch 1/64 loss: 0.3424510955810547
Batch 2/64 loss: 0.3399156332015991
Batch 3/64 loss: 0.3378022313117981
Batch 4/64 loss: 0.3412798047065735
Batch 5/64 loss: 0.3398529291152954
Batch 6/64 loss: 0.3449287414550781
Batch 7/64 loss: 0.33884334564208984
Batch 8/64 loss: 0.33970189094543457
Batch 9/64 loss: 0.3397482633590698
Batch 10/64 loss: 0.3420870304107666
Batch 11/64 loss: 0.3391530513763428
Batch 12/64 loss: 0.3390342593193054
Batch 13/64 loss: 0.33969342708587646
Batch 14/64 loss: 0.3460702896118164
Batch 15/64 loss: 0.34365010261535645
Batch 16/64 loss: 0.34635233879089355
Batch 17/64 loss: 0.34044861793518066
Batch 18/64 loss: 0.33575642108917236
Batch 19/64 loss: 0.34839582443237305
Batch 20/64 loss: 0.3417651653289795
Batch 21/64 loss: 0.3435394763946533
Batch 22/64 loss: 0.34397387504577637
Batch 23/64 loss: 0.3403177857398987
Batch 24/64 loss: 0.3417712450027466
Batch 25/64 loss: 0.3427548408508301
Batch 26/64 loss: 0.34526920318603516
Batch 27/64 loss: 0.3378167152404785
Batch 28/64 loss: 0.34585726261138916
Batch 29/64 loss: 0.34203994274139404
Batch 30/64 loss: 0.3461054563522339
Batch 31/64 loss: 0.34774088859558105
Batch 32/64 loss: 0.34269797801971436
Batch 33/64 loss: 0.3364377021789551
Batch 34/64 loss: 0.33968937397003174
Batch 35/64 loss: 0.3435022830963135
Batch 36/64 loss: 0.34181803464889526
Batch 37/64 loss: 0.34118711948394775
Batch 38/64 loss: 0.34167879819869995
Batch 39/64 loss: 0.3373373746871948
Batch 40/64 loss: 0.3374084234237671
Batch 41/64 loss: 0.34523361921310425
Batch 42/64 loss: 0.3424490690231323
Batch 43/64 loss: 0.34392058849334717
Batch 44/64 loss: 0.343944787979126
Batch 45/64 loss: 0.3421175479888916
Batch 46/64 loss: 0.3423309326171875
Batch 47/64 loss: 0.3409350514411926
Batch 48/64 loss: 0.34181272983551025
Batch 49/64 loss: 0.34542298316955566
Batch 50/64 loss: 0.34363245964050293
Batch 51/64 loss: 0.34024953842163086
Batch 52/64 loss: 0.34013187885284424
Batch 53/64 loss: 0.3439462184906006
Batch 54/64 loss: 0.3375958204269409
Batch 55/64 loss: 0.3391796350479126
Batch 56/64 loss: 0.3396637439727783
Batch 57/64 loss: 0.3446183204650879
Batch 58/64 loss: 0.3397095799446106
Batch 59/64 loss: 0.33760887384414673
Batch 60/64 loss: 0.34199458360671997
Batch 61/64 loss: 0.3475388288497925
Batch 62/64 loss: 0.3387795090675354
Batch 63/64 loss: 0.3428111672401428
Batch 64/64 loss: 0.3424223065376282
Epoch 118  Train loss: 0.3417775441618527  Val loss: 0.34750674229716927
Epoch 119
-------------------------------
Batch 1/64 loss: 0.3403970003128052
Batch 2/64 loss: 0.34533190727233887
Batch 3/64 loss: 0.3389861583709717
Batch 4/64 loss: 0.3398667573928833
Batch 5/64 loss: 0.3402855396270752
Batch 6/64 loss: 0.34503453969955444
Batch 7/64 loss: 0.3500317335128784
Batch 8/64 loss: 0.34066110849380493
Batch 9/64 loss: 0.3427833318710327
Batch 10/64 loss: 0.34030723571777344
Batch 11/64 loss: 0.34189528226852417
Batch 12/64 loss: 0.34415751695632935
Batch 13/64 loss: 0.34144723415374756
Batch 14/64 loss: 0.3416332006454468
Batch 15/64 loss: 0.3447444438934326
Batch 16/64 loss: 0.3437243103981018
Batch 17/64 loss: 0.337795615196228
Batch 18/64 loss: 0.34446096420288086
Batch 19/64 loss: 0.34043586254119873
Batch 20/64 loss: 0.34436172246932983
Batch 21/64 loss: 0.3461017608642578
Batch 22/64 loss: 0.3349655866622925
Batch 23/64 loss: 0.3456084132194519
Batch 24/64 loss: 0.34765517711639404
Batch 25/64 loss: 0.34096646308898926
Batch 26/64 loss: 0.3407186269760132
Batch 27/64 loss: 0.3421003818511963
Batch 28/64 loss: 0.3435876965522766
Batch 29/64 loss: 0.34132105112075806
Batch 30/64 loss: 0.3418238162994385
Batch 31/64 loss: 0.34054261445999146
Batch 32/64 loss: 0.34157633781433105
Batch 33/64 loss: 0.33674103021621704
Batch 34/64 loss: 0.3444948196411133
Batch 35/64 loss: 0.3432151675224304
Batch 36/64 loss: 0.34061235189437866
Batch 37/64 loss: 0.34360384941101074
Batch 38/64 loss: 0.3381097912788391
Batch 39/64 loss: 0.34597915410995483
Batch 40/64 loss: 0.34289640188217163
Batch 41/64 loss: 0.3428835868835449
Batch 42/64 loss: 0.339668333530426
Batch 43/64 loss: 0.33954012393951416
Batch 44/64 loss: 0.34109652042388916
Batch 45/64 loss: 0.3388080596923828
Batch 46/64 loss: 0.3437161445617676
Batch 47/64 loss: 0.34148848056793213
Batch 48/64 loss: 0.33918678760528564
Batch 49/64 loss: 0.3396245241165161
Batch 50/64 loss: 0.33815181255340576
Batch 51/64 loss: 0.34239304065704346
Batch 52/64 loss: 0.3435007333755493
Batch 53/64 loss: 0.340364933013916
Batch 54/64 loss: 0.3409755825996399
Batch 55/64 loss: 0.34473955631256104
Batch 56/64 loss: 0.3418610095977783
Batch 57/64 loss: 0.3405376672744751
Batch 58/64 loss: 0.33494168519973755
Batch 59/64 loss: 0.3418577313423157
Batch 60/64 loss: 0.33579957485198975
Batch 61/64 loss: 0.34921908378601074
Batch 62/64 loss: 0.3362867832183838
Batch 63/64 loss: 0.34282875061035156
Batch 64/64 loss: 0.33992207050323486
Epoch 119  Train loss: 0.3417313571069755  Val loss: 0.3476379642781523
Epoch 120
-------------------------------
Batch 1/64 loss: 0.34201812744140625
Batch 2/64 loss: 0.3445502519607544
Batch 3/64 loss: 0.3436000347137451
Batch 4/64 loss: 0.3409784436225891
Batch 5/64 loss: 0.34269994497299194
Batch 6/64 loss: 0.33914440870285034
Batch 7/64 loss: 0.33941495418548584
Batch 8/64 loss: 0.3402693271636963
Batch 9/64 loss: 0.3397409915924072
Batch 10/64 loss: 0.3404942750930786
Batch 11/64 loss: 0.33746016025543213
Batch 12/64 loss: 0.3438187837600708
Batch 13/64 loss: 0.3360161781311035
Batch 14/64 loss: 0.33952653408050537
Batch 15/64 loss: 0.3471064567565918
Batch 16/64 loss: 0.33427172899246216
Batch 17/64 loss: 0.34201228618621826
Batch 18/64 loss: 0.3369032144546509
Batch 19/64 loss: 0.3366668224334717
Batch 20/64 loss: 0.33865588903427124
Batch 21/64 loss: 0.3436231017112732
Batch 22/64 loss: 0.3430139422416687
Batch 23/64 loss: 0.34130144119262695
Batch 24/64 loss: 0.3391622304916382
Batch 25/64 loss: 0.33973532915115356
Batch 26/64 loss: 0.3348591923713684
Batch 27/64 loss: 0.33916640281677246
Batch 28/64 loss: 0.3441321849822998
Batch 29/64 loss: 0.3339977264404297
Batch 30/64 loss: 0.34252333641052246
Batch 31/64 loss: 0.34048712253570557
Batch 32/64 loss: 0.34519171714782715
Batch 33/64 loss: 0.34345924854278564
Batch 34/64 loss: 0.34154027700424194
Batch 35/64 loss: 0.3406173586845398
Batch 36/64 loss: 0.3417088985443115
Batch 37/64 loss: 0.34285420179367065
Batch 38/64 loss: 0.3428915739059448
Batch 39/64 loss: 0.3483750820159912
Batch 40/64 loss: 0.34487026929855347
Batch 41/64 loss: 0.34456968307495117
Batch 42/64 loss: 0.34305882453918457
Batch 43/64 loss: 0.34072959423065186
Batch 44/64 loss: 0.3408204913139343
Batch 45/64 loss: 0.34144127368927
Batch 46/64 loss: 0.3436005115509033
Batch 47/64 loss: 0.34311938285827637
Batch 48/64 loss: 0.34133899211883545
Batch 49/64 loss: 0.3401987552642822
Batch 50/64 loss: 0.34279459714889526
Batch 51/64 loss: 0.3452284336090088
Batch 52/64 loss: 0.3427325487136841
Batch 53/64 loss: 0.34164857864379883
Batch 54/64 loss: 0.335895299911499
Batch 55/64 loss: 0.34305888414382935
Batch 56/64 loss: 0.34096336364746094
Batch 57/64 loss: 0.3490966558456421
Batch 58/64 loss: 0.3427020311355591
Batch 59/64 loss: 0.3429068326950073
Batch 60/64 loss: 0.3433868885040283
Batch 61/64 loss: 0.3420335054397583
Batch 62/64 loss: 0.34066861867904663
Batch 63/64 loss: 0.3427926301956177
Batch 64/64 loss: 0.34012484550476074
Epoch 120  Train loss: 0.34147042293174595  Val loss: 0.34739431523785147
Epoch 121
-------------------------------
Batch 1/64 loss: 0.34256941080093384
Batch 2/64 loss: 0.3452274799346924
Batch 3/64 loss: 0.34193360805511475
Batch 4/64 loss: 0.34408509731292725
Batch 5/64 loss: 0.33775538206100464
Batch 6/64 loss: 0.34248512983322144
Batch 7/64 loss: 0.34201037883758545
Batch 8/64 loss: 0.34720027446746826
Batch 9/64 loss: 0.3409658670425415
Batch 10/64 loss: 0.34325432777404785
Batch 11/64 loss: 0.3380783796310425
Batch 12/64 loss: 0.33680152893066406
Batch 13/64 loss: 0.3427965044975281
Batch 14/64 loss: 0.34026670455932617
Batch 15/64 loss: 0.3406307101249695
Batch 16/64 loss: 0.3412601947784424
Batch 17/64 loss: 0.3438749313354492
Batch 18/64 loss: 0.3399582505226135
Batch 19/64 loss: 0.3417130708694458
Batch 20/64 loss: 0.34072601795196533
Batch 21/64 loss: 0.3398963212966919
Batch 22/64 loss: 0.3450343608856201
Batch 23/64 loss: 0.34135788679122925
Batch 24/64 loss: 0.3412867784500122
Batch 25/64 loss: 0.3418848514556885
Batch 26/64 loss: 0.34397101402282715
Batch 27/64 loss: 0.3366098403930664
Batch 28/64 loss: 0.3430476188659668
Batch 29/64 loss: 0.33871740102767944
Batch 30/64 loss: 0.33723175525665283
Batch 31/64 loss: 0.3402775526046753
Batch 32/64 loss: 0.3420649766921997
Batch 33/64 loss: 0.33545762300491333
Batch 34/64 loss: 0.34087276458740234
Batch 35/64 loss: 0.34039974212646484
Batch 36/64 loss: 0.33855193853378296
Batch 37/64 loss: 0.3440847396850586
Batch 38/64 loss: 0.3416516184806824
Batch 39/64 loss: 0.33827900886535645
Batch 40/64 loss: 0.34223419427871704
Batch 41/64 loss: 0.34185343980789185
Batch 42/64 loss: 0.34012651443481445
Batch 43/64 loss: 0.33846956491470337
Batch 44/64 loss: 0.342826247215271
Batch 45/64 loss: 0.34321117401123047
Batch 46/64 loss: 0.34263086318969727
Batch 47/64 loss: 0.342021644115448
Batch 48/64 loss: 0.34117841720581055
Batch 49/64 loss: 0.34204548597335815
Batch 50/64 loss: 0.34184277057647705
Batch 51/64 loss: 0.34261876344680786
Batch 52/64 loss: 0.33977359533309937
Batch 53/64 loss: 0.3381316661834717
Batch 54/64 loss: 0.34312039613723755
Batch 55/64 loss: 0.33975863456726074
Batch 56/64 loss: 0.3432199954986572
Batch 57/64 loss: 0.3409448266029358
Batch 58/64 loss: 0.3440234661102295
Batch 59/64 loss: 0.343731164932251
Batch 60/64 loss: 0.33588528633117676
Batch 61/64 loss: 0.3409948945045471
Batch 62/64 loss: 0.34282147884368896
Batch 63/64 loss: 0.34238874912261963
Batch 64/64 loss: 0.3412191867828369
Epoch 121  Train loss: 0.34127119475719975  Val loss: 0.3472099646260239
Saving best model, epoch: 121
Epoch 122
-------------------------------
Batch 1/64 loss: 0.34215688705444336
Batch 2/64 loss: 0.3407399654388428
Batch 3/64 loss: 0.34298276901245117
Batch 4/64 loss: 0.3376007676124573
Batch 5/64 loss: 0.34338802099227905
Batch 6/64 loss: 0.3406471610069275
Batch 7/64 loss: 0.3409249186515808
Batch 8/64 loss: 0.33808040618896484
Batch 9/64 loss: 0.3439788818359375
Batch 10/64 loss: 0.34387385845184326
Batch 11/64 loss: 0.33465874195098877
Batch 12/64 loss: 0.3401716351509094
Batch 13/64 loss: 0.34326112270355225
Batch 14/64 loss: 0.33695173263549805
Batch 15/64 loss: 0.33823704719543457
Batch 16/64 loss: 0.3400212526321411
Batch 17/64 loss: 0.3434772491455078
Batch 18/64 loss: 0.33813154697418213
Batch 19/64 loss: 0.3454793691635132
Batch 20/64 loss: 0.34365636110305786
Batch 21/64 loss: 0.3419368863105774
Batch 22/64 loss: 0.34227025508880615
Batch 23/64 loss: 0.33979296684265137
Batch 24/64 loss: 0.33935970067977905
Batch 25/64 loss: 0.3408546447753906
Batch 26/64 loss: 0.34547698497772217
Batch 27/64 loss: 0.34334099292755127
Batch 28/64 loss: 0.33741527795791626
Batch 29/64 loss: 0.3380904197692871
Batch 30/64 loss: 0.3451324701309204
Batch 31/64 loss: 0.3437016010284424
Batch 32/64 loss: 0.3339768648147583
Batch 33/64 loss: 0.344027042388916
Batch 34/64 loss: 0.3406083583831787
Batch 35/64 loss: 0.33820128440856934
Batch 36/64 loss: 0.34037649631500244
Batch 37/64 loss: 0.3407558798789978
Batch 38/64 loss: 0.3420841693878174
Batch 39/64 loss: 0.33935606479644775
Batch 40/64 loss: 0.3420623540878296
Batch 41/64 loss: 0.3460371494293213
Batch 42/64 loss: 0.3390922546386719
Batch 43/64 loss: 0.3458455204963684
Batch 44/64 loss: 0.33946436643600464
Batch 45/64 loss: 0.33701467514038086
Batch 46/64 loss: 0.339901328086853
Batch 47/64 loss: 0.34606659412384033
Batch 48/64 loss: 0.3434714078903198
Batch 49/64 loss: 0.34435439109802246
Batch 50/64 loss: 0.3469552993774414
Batch 51/64 loss: 0.34754449129104614
Batch 52/64 loss: 0.34125256538391113
Batch 53/64 loss: 0.34279704093933105
Batch 54/64 loss: 0.3438314199447632
Batch 55/64 loss: 0.3384721279144287
Batch 56/64 loss: 0.34393972158432007
Batch 57/64 loss: 0.34199273586273193
Batch 58/64 loss: 0.3422245383262634
Batch 59/64 loss: 0.3403747081756592
Batch 60/64 loss: 0.3439044952392578
Batch 61/64 loss: 0.34116166830062866
Batch 62/64 loss: 0.3400914669036865
Batch 63/64 loss: 0.336536169052124
Batch 64/64 loss: 0.33812546730041504
Epoch 122  Train loss: 0.34138291209351784  Val loss: 0.34756630065105215
Epoch 123
-------------------------------
Batch 1/64 loss: 0.3385983109474182
Batch 2/64 loss: 0.33727550506591797
Batch 3/64 loss: 0.34497499465942383
Batch 4/64 loss: 0.34069550037384033
Batch 5/64 loss: 0.3427508473396301
Batch 6/64 loss: 0.34312719106674194
Batch 7/64 loss: 0.34405070543289185
Batch 8/64 loss: 0.3405008316040039
Batch 9/64 loss: 0.337540864944458
Batch 10/64 loss: 0.34267592430114746
Batch 11/64 loss: 0.3380851149559021
Batch 12/64 loss: 0.3382047414779663
Batch 13/64 loss: 0.33874475955963135
Batch 14/64 loss: 0.34072190523147583
Batch 15/64 loss: 0.34232497215270996
Batch 16/64 loss: 0.34176284074783325
Batch 17/64 loss: 0.3358027935028076
Batch 18/64 loss: 0.34390270709991455
Batch 19/64 loss: 0.33471763134002686
Batch 20/64 loss: 0.3414222002029419
Batch 21/64 loss: 0.3438464403152466
Batch 22/64 loss: 0.3394773602485657
Batch 23/64 loss: 0.33896297216415405
Batch 24/64 loss: 0.3376988172531128
Batch 25/64 loss: 0.3413578271865845
Batch 26/64 loss: 0.33763206005096436
Batch 27/64 loss: 0.34703314304351807
Batch 28/64 loss: 0.3416546583175659
Batch 29/64 loss: 0.3370228409767151
Batch 30/64 loss: 0.3410794734954834
Batch 31/64 loss: 0.3396569490432739
Batch 32/64 loss: 0.3399624824523926
Batch 33/64 loss: 0.3425511121749878
Batch 34/64 loss: 0.3407706618309021
Batch 35/64 loss: 0.3383432626724243
Batch 36/64 loss: 0.3444145917892456
Batch 37/64 loss: 0.3376072645187378
Batch 38/64 loss: 0.3410027027130127
Batch 39/64 loss: 0.339197039604187
Batch 40/64 loss: 0.3403743505477905
Batch 41/64 loss: 0.34527164697647095
Batch 42/64 loss: 0.3435795307159424
Batch 43/64 loss: 0.3417964577674866
Batch 44/64 loss: 0.3410453796386719
Batch 45/64 loss: 0.3350372314453125
Batch 46/64 loss: 0.34453463554382324
Batch 47/64 loss: 0.34287989139556885
Batch 48/64 loss: 0.337937593460083
Batch 49/64 loss: 0.3428879976272583
Batch 50/64 loss: 0.34023308753967285
Batch 51/64 loss: 0.34221893548965454
Batch 52/64 loss: 0.3436475396156311
Batch 53/64 loss: 0.3446376919746399
Batch 54/64 loss: 0.3417227268218994
Batch 55/64 loss: 0.34258556365966797
Batch 56/64 loss: 0.34490060806274414
Batch 57/64 loss: 0.3408830165863037
Batch 58/64 loss: 0.33913350105285645
Batch 59/64 loss: 0.3427853584289551
Batch 60/64 loss: 0.3406796455383301
Batch 61/64 loss: 0.34048914909362793
Batch 62/64 loss: 0.341239333152771
Batch 63/64 loss: 0.3421539068222046
Batch 64/64 loss: 0.34231382608413696
Epoch 123  Train loss: 0.3409653670647565  Val loss: 0.3481151488228762
Epoch 124
-------------------------------
Batch 1/64 loss: 0.33299434185028076
Batch 2/64 loss: 0.341558039188385
Batch 3/64 loss: 0.34486913681030273
Batch 4/64 loss: 0.3409721851348877
Batch 5/64 loss: 0.3382394313812256
Batch 6/64 loss: 0.3425769805908203
Batch 7/64 loss: 0.3398313522338867
Batch 8/64 loss: 0.3424757122993469
Batch 9/64 loss: 0.3398902416229248
Batch 10/64 loss: 0.3383726477622986
Batch 11/64 loss: 0.34400469064712524
Batch 12/64 loss: 0.3370412588119507
Batch 13/64 loss: 0.34094440937042236
Batch 14/64 loss: 0.3377048969268799
Batch 15/64 loss: 0.3434962034225464
Batch 16/64 loss: 0.33665895462036133
Batch 17/64 loss: 0.3414650559425354
Batch 18/64 loss: 0.3382236957550049
Batch 19/64 loss: 0.34401196241378784
Batch 20/64 loss: 0.3390389680862427
Batch 21/64 loss: 0.3372364044189453
Batch 22/64 loss: 0.3466600179672241
Batch 23/64 loss: 0.3438745141029358
Batch 24/64 loss: 0.34115809202194214
Batch 25/64 loss: 0.3399820923805237
Batch 26/64 loss: 0.3452789783477783
Batch 27/64 loss: 0.34661275148391724
Batch 28/64 loss: 0.3427020311355591
Batch 29/64 loss: 0.3365992307662964
Batch 30/64 loss: 0.33872830867767334
Batch 31/64 loss: 0.33935004472732544
Batch 32/64 loss: 0.3413962125778198
Batch 33/64 loss: 0.33900177478790283
Batch 34/64 loss: 0.3393869996070862
Batch 35/64 loss: 0.34257006645202637
Batch 36/64 loss: 0.34432584047317505
Batch 37/64 loss: 0.33810412883758545
Batch 38/64 loss: 0.3442513942718506
Batch 39/64 loss: 0.34126341342926025
Batch 40/64 loss: 0.34013235569000244
Batch 41/64 loss: 0.33989548683166504
Batch 42/64 loss: 0.34437692165374756
Batch 43/64 loss: 0.34575963020324707
Batch 44/64 loss: 0.34461426734924316
Batch 45/64 loss: 0.33927714824676514
Batch 46/64 loss: 0.34317290782928467
Batch 47/64 loss: 0.3376655578613281
Batch 48/64 loss: 0.3444310426712036
Batch 49/64 loss: 0.3377634286880493
Batch 50/64 loss: 0.344330370426178
Batch 51/64 loss: 0.3393937349319458
Batch 52/64 loss: 0.3371272087097168
Batch 53/64 loss: 0.34730613231658936
Batch 54/64 loss: 0.3416060209274292
Batch 55/64 loss: 0.3443913459777832
Batch 56/64 loss: 0.34673309326171875
Batch 57/64 loss: 0.3390384912490845
Batch 58/64 loss: 0.3369123339653015
Batch 59/64 loss: 0.3413914442062378
Batch 60/64 loss: 0.3370143175125122
Batch 61/64 loss: 0.33644741773605347
Batch 62/64 loss: 0.34093624353408813
Batch 63/64 loss: 0.34297215938568115
Batch 64/64 loss: 0.34068989753723145
Epoch 124  Train loss: 0.3410362187553855  Val loss: 0.3463314374287923
Saving best model, epoch: 124
Epoch 125
-------------------------------
Batch 1/64 loss: 0.3400026559829712
Batch 2/64 loss: 0.3405512571334839
Batch 3/64 loss: 0.34397828578948975
Batch 4/64 loss: 0.3397923707962036
Batch 5/64 loss: 0.33542633056640625
Batch 6/64 loss: 0.3374440670013428
Batch 7/64 loss: 0.3384590148925781
Batch 8/64 loss: 0.34010833501815796
Batch 9/64 loss: 0.33400964736938477
Batch 10/64 loss: 0.3390067219734192
Batch 11/64 loss: 0.3433711528778076
Batch 12/64 loss: 0.34637439250946045
Batch 13/64 loss: 0.34205079078674316
Batch 14/64 loss: 0.3396836519241333
Batch 15/64 loss: 0.3412591814994812
Batch 16/64 loss: 0.3411176800727844
Batch 17/64 loss: 0.3388313055038452
Batch 18/64 loss: 0.33653509616851807
Batch 19/64 loss: 0.34403955936431885
Batch 20/64 loss: 0.34147316217422485
Batch 21/64 loss: 0.336306095123291
Batch 22/64 loss: 0.3410487771034241
Batch 23/64 loss: 0.3398793935775757
Batch 24/64 loss: 0.34045183658599854
Batch 25/64 loss: 0.3389008641242981
Batch 26/64 loss: 0.3423253297805786
Batch 27/64 loss: 0.3424988389015198
Batch 28/64 loss: 0.33813250064849854
Batch 29/64 loss: 0.338584840297699
Batch 30/64 loss: 0.33526015281677246
Batch 31/64 loss: 0.343464732170105
Batch 32/64 loss: 0.3420751094818115
Batch 33/64 loss: 0.3380904197692871
Batch 34/64 loss: 0.34575414657592773
Batch 35/64 loss: 0.3469146490097046
Batch 36/64 loss: 0.3445051908493042
Batch 37/64 loss: 0.3437443971633911
Batch 38/64 loss: 0.34063124656677246
Batch 39/64 loss: 0.3400759696960449
Batch 40/64 loss: 0.34156930446624756
Batch 41/64 loss: 0.3454122543334961
Batch 42/64 loss: 0.34523916244506836
Batch 43/64 loss: 0.3434961438179016
Batch 44/64 loss: 0.33456850051879883
Batch 45/64 loss: 0.34027099609375
Batch 46/64 loss: 0.33801043033599854
Batch 47/64 loss: 0.334836483001709
Batch 48/64 loss: 0.34749770164489746
Batch 49/64 loss: 0.3385007381439209
Batch 50/64 loss: 0.34129583835601807
Batch 51/64 loss: 0.339819073677063
Batch 52/64 loss: 0.33933424949645996
Batch 53/64 loss: 0.3393831253051758
Batch 54/64 loss: 0.34121620655059814
Batch 55/64 loss: 0.33425354957580566
Batch 56/64 loss: 0.3372815251350403
Batch 57/64 loss: 0.33965277671813965
Batch 58/64 loss: 0.3434067964553833
Batch 59/64 loss: 0.341372013092041
Batch 60/64 loss: 0.34311580657958984
Batch 61/64 loss: 0.3385426998138428
Batch 62/64 loss: 0.3424578309059143
Batch 63/64 loss: 0.34044039249420166
Batch 64/64 loss: 0.34473490715026855
Epoch 125  Train loss: 0.340575434179867  Val loss: 0.34798099658743215
Epoch 126
-------------------------------
Batch 1/64 loss: 0.34003299474716187
Batch 2/64 loss: 0.3485879898071289
Batch 3/64 loss: 0.34697115421295166
Batch 4/64 loss: 0.3411872386932373
Batch 5/64 loss: 0.3410416841506958
Batch 6/64 loss: 0.3456493616104126
Batch 7/64 loss: 0.34079456329345703
Batch 8/64 loss: 0.3400198221206665
Batch 9/64 loss: 0.3407912254333496
Batch 10/64 loss: 0.34092462062835693
Batch 11/64 loss: 0.3412359356880188
Batch 12/64 loss: 0.34090906381607056
Batch 13/64 loss: 0.33866286277770996
Batch 14/64 loss: 0.33989083766937256
Batch 15/64 loss: 0.34009456634521484
Batch 16/64 loss: 0.3447745442390442
Batch 17/64 loss: 0.3386331796646118
Batch 18/64 loss: 0.3394896984100342
Batch 19/64 loss: 0.33771753311157227
Batch 20/64 loss: 0.3409067988395691
Batch 21/64 loss: 0.3392931818962097
Batch 22/64 loss: 0.34307360649108887
Batch 23/64 loss: 0.33575332164764404
Batch 24/64 loss: 0.3367253541946411
Batch 25/64 loss: 0.34205639362335205
Batch 26/64 loss: 0.3418385982513428
Batch 27/64 loss: 0.3400009274482727
Batch 28/64 loss: 0.3378422260284424
Batch 29/64 loss: 0.34612804651260376
Batch 30/64 loss: 0.33954232931137085
Batch 31/64 loss: 0.3368539810180664
Batch 32/64 loss: 0.3382829427719116
Batch 33/64 loss: 0.34301304817199707
Batch 34/64 loss: 0.3407154083251953
Batch 35/64 loss: 0.33920764923095703
Batch 36/64 loss: 0.3438105583190918
Batch 37/64 loss: 0.34193360805511475
Batch 38/64 loss: 0.3397815227508545
Batch 39/64 loss: 0.33917999267578125
Batch 40/64 loss: 0.34216779470443726
Batch 41/64 loss: 0.34278416633605957
Batch 42/64 loss: 0.3361932039260864
Batch 43/64 loss: 0.3403284549713135
Batch 44/64 loss: 0.3425990343093872
Batch 45/64 loss: 0.33581894636154175
Batch 46/64 loss: 0.3383151888847351
Batch 47/64 loss: 0.33896881341934204
Batch 48/64 loss: 0.34470605850219727
Batch 49/64 loss: 0.3433234691619873
Batch 50/64 loss: 0.3407396674156189
Batch 51/64 loss: 0.34155863523483276
Batch 52/64 loss: 0.34126007556915283
Batch 53/64 loss: 0.3459257483482361
Batch 54/64 loss: 0.3416494131088257
Batch 55/64 loss: 0.3396153450012207
Batch 56/64 loss: 0.33920758962631226
Batch 57/64 loss: 0.3376115560531616
Batch 58/64 loss: 0.33818209171295166
Batch 59/64 loss: 0.33898240327835083
Batch 60/64 loss: 0.33959996700286865
Batch 61/64 loss: 0.3379170298576355
Batch 62/64 loss: 0.34391289949417114
Batch 63/64 loss: 0.3389991521835327
Batch 64/64 loss: 0.33927541971206665
Epoch 126  Train loss: 0.3406772022153817  Val loss: 0.3470259747144693
Epoch 127
-------------------------------
Batch 1/64 loss: 0.33966755867004395
Batch 2/64 loss: 0.3427112102508545
Batch 3/64 loss: 0.34021347761154175
Batch 4/64 loss: 0.34213340282440186
Batch 5/64 loss: 0.33531785011291504
Batch 6/64 loss: 0.3394123315811157
Batch 7/64 loss: 0.34175312519073486
Batch 8/64 loss: 0.33766210079193115
Batch 9/64 loss: 0.3360377550125122
Batch 10/64 loss: 0.3425174355506897
Batch 11/64 loss: 0.34159958362579346
Batch 12/64 loss: 0.34330421686172485
Batch 13/64 loss: 0.34016621112823486
Batch 14/64 loss: 0.3429093360900879
Batch 15/64 loss: 0.3357135057449341
Batch 16/64 loss: 0.33605414628982544
Batch 17/64 loss: 0.33951276540756226
Batch 18/64 loss: 0.3433956503868103
Batch 19/64 loss: 0.33729422092437744
Batch 20/64 loss: 0.3420177698135376
Batch 21/64 loss: 0.3413029909133911
Batch 22/64 loss: 0.3406502604484558
Batch 23/64 loss: 0.34427183866500854
Batch 24/64 loss: 0.3409295082092285
Batch 25/64 loss: 0.33768635988235474
Batch 26/64 loss: 0.3373454213142395
Batch 27/64 loss: 0.3444652557373047
Batch 28/64 loss: 0.33965563774108887
Batch 29/64 loss: 0.33579766750335693
Batch 30/64 loss: 0.340628445148468
Batch 31/64 loss: 0.34088242053985596
Batch 32/64 loss: 0.3361201882362366
Batch 33/64 loss: 0.3420511484146118
Batch 34/64 loss: 0.3379470109939575
Batch 35/64 loss: 0.3371801972389221
Batch 36/64 loss: 0.3398244380950928
Batch 37/64 loss: 0.33976423740386963
Batch 38/64 loss: 0.3406655788421631
Batch 39/64 loss: 0.34477686882019043
Batch 40/64 loss: 0.33799540996551514
Batch 41/64 loss: 0.3370184302330017
Batch 42/64 loss: 0.3422701358795166
Batch 43/64 loss: 0.3438223600387573
Batch 44/64 loss: 0.3407759666442871
Batch 45/64 loss: 0.34320998191833496
Batch 46/64 loss: 0.335416316986084
Batch 47/64 loss: 0.34423828125
Batch 48/64 loss: 0.34352338314056396
Batch 49/64 loss: 0.33508026599884033
Batch 50/64 loss: 0.33348095417022705
Batch 51/64 loss: 0.3379577398300171
Batch 52/64 loss: 0.34172195196151733
Batch 53/64 loss: 0.34175753593444824
Batch 54/64 loss: 0.3427700996398926
Batch 55/64 loss: 0.34156036376953125
Batch 56/64 loss: 0.34212350845336914
Batch 57/64 loss: 0.3421895503997803
Batch 58/64 loss: 0.3402218818664551
Batch 59/64 loss: 0.3397589325904846
Batch 60/64 loss: 0.3437936305999756
Batch 61/64 loss: 0.34494727849960327
Batch 62/64 loss: 0.34266090393066406
Batch 63/64 loss: 0.33830857276916504
Batch 64/64 loss: 0.34747177362442017
Epoch 127  Train loss: 0.3403693552110709  Val loss: 0.34698491162041206
Epoch 128
-------------------------------
Batch 1/64 loss: 0.3402446508407593
Batch 2/64 loss: 0.33653581142425537
Batch 3/64 loss: 0.3382219076156616
Batch 4/64 loss: 0.34089016914367676
Batch 5/64 loss: 0.33868658542633057
Batch 6/64 loss: 0.33835744857788086
Batch 7/64 loss: 0.34327685832977295
Batch 8/64 loss: 0.34689146280288696
Batch 9/64 loss: 0.3354095220565796
Batch 10/64 loss: 0.3417872190475464
Batch 11/64 loss: 0.34097009897232056
Batch 12/64 loss: 0.34214651584625244
Batch 13/64 loss: 0.33635151386260986
Batch 14/64 loss: 0.33956122398376465
Batch 15/64 loss: 0.3367661237716675
Batch 16/64 loss: 0.34038519859313965
Batch 17/64 loss: 0.340503990650177
Batch 18/64 loss: 0.339871883392334
Batch 19/64 loss: 0.3389365077018738
Batch 20/64 loss: 0.3360835909843445
Batch 21/64 loss: 0.340396523475647
Batch 22/64 loss: 0.33572590351104736
Batch 23/64 loss: 0.346110999584198
Batch 24/64 loss: 0.34015053510665894
Batch 25/64 loss: 0.34216904640197754
Batch 26/64 loss: 0.34085768461227417
Batch 27/64 loss: 0.3411344289779663
Batch 28/64 loss: 0.3435800075531006
Batch 29/64 loss: 0.33940356969833374
Batch 30/64 loss: 0.34081757068634033
Batch 31/64 loss: 0.34147417545318604
Batch 32/64 loss: 0.3453274965286255
Batch 33/64 loss: 0.33523499965667725
Batch 34/64 loss: 0.3397582769393921
Batch 35/64 loss: 0.34464019536972046
Batch 36/64 loss: 0.34088611602783203
Batch 37/64 loss: 0.3408629298210144
Batch 38/64 loss: 0.3412880301475525
Batch 39/64 loss: 0.33951735496520996
Batch 40/64 loss: 0.34204351902008057
Batch 41/64 loss: 0.33826708793640137
Batch 42/64 loss: 0.3392595052719116
Batch 43/64 loss: 0.34593015909194946
Batch 44/64 loss: 0.3433188199996948
Batch 45/64 loss: 0.34401655197143555
Batch 46/64 loss: 0.34081244468688965
Batch 47/64 loss: 0.34016382694244385
Batch 48/64 loss: 0.33928799629211426
Batch 49/64 loss: 0.34201472997665405
Batch 50/64 loss: 0.3419015407562256
Batch 51/64 loss: 0.3433570861816406
Batch 52/64 loss: 0.3415043354034424
Batch 53/64 loss: 0.3437851667404175
Batch 54/64 loss: 0.33981919288635254
Batch 55/64 loss: 0.3428458571434021
Batch 56/64 loss: 0.3391479253768921
Batch 57/64 loss: 0.33904385566711426
Batch 58/64 loss: 0.3380703926086426
Batch 59/64 loss: 0.34073615074157715
Batch 60/64 loss: 0.33745062351226807
Batch 61/64 loss: 0.3416173458099365
Batch 62/64 loss: 0.33999568223953247
Batch 63/64 loss: 0.3389672040939331
Batch 64/64 loss: 0.33977580070495605
Epoch 128  Train loss: 0.34053965456345503  Val loss: 0.3464263065164441
Epoch 129
-------------------------------
Batch 1/64 loss: 0.3395600914955139
Batch 2/64 loss: 0.34209126234054565
Batch 3/64 loss: 0.34282898902893066
Batch 4/64 loss: 0.3426259160041809
Batch 5/64 loss: 0.34047961235046387
Batch 6/64 loss: 0.34393835067749023
Batch 7/64 loss: 0.3458000421524048
Batch 8/64 loss: 0.3410518765449524
Batch 9/64 loss: 0.3451472520828247
Batch 10/64 loss: 0.3372694253921509
Batch 11/64 loss: 0.3421860337257385
Batch 12/64 loss: 0.3340029716491699
Batch 13/64 loss: 0.3390251398086548
Batch 14/64 loss: 0.34286928176879883
Batch 15/64 loss: 0.3437443971633911
Batch 16/64 loss: 0.3404400944709778
Batch 17/64 loss: 0.3416537046432495
Batch 18/64 loss: 0.33976978063583374
Batch 19/64 loss: 0.3353115916252136
Batch 20/64 loss: 0.338861346244812
Batch 21/64 loss: 0.33932602405548096
Batch 22/64 loss: 0.34241193532943726
Batch 23/64 loss: 0.3392922282218933
Batch 24/64 loss: 0.33950603008270264
Batch 25/64 loss: 0.34389811754226685
Batch 26/64 loss: 0.33792924880981445
Batch 27/64 loss: 0.34317004680633545
Batch 28/64 loss: 0.3383033871650696
Batch 29/64 loss: 0.3407314419746399
Batch 30/64 loss: 0.34397196769714355
Batch 31/64 loss: 0.34428977966308594
Batch 32/64 loss: 0.33783555030822754
Batch 33/64 loss: 0.3390665054321289
Batch 34/64 loss: 0.34070050716400146
Batch 35/64 loss: 0.335685670375824
Batch 36/64 loss: 0.3375852108001709
Batch 37/64 loss: 0.3400381803512573
Batch 38/64 loss: 0.3362236022949219
Batch 39/64 loss: 0.33729708194732666
Batch 40/64 loss: 0.33483248949050903
Batch 41/64 loss: 0.3361046314239502
Batch 42/64 loss: 0.3430900573730469
Batch 43/64 loss: 0.3359713554382324
Batch 44/64 loss: 0.3396080732345581
Batch 45/64 loss: 0.3384528160095215
Batch 46/64 loss: 0.3417891263961792
Batch 47/64 loss: 0.33760392665863037
Batch 48/64 loss: 0.3437446355819702
Batch 49/64 loss: 0.34823358058929443
Batch 50/64 loss: 0.339521586894989
Batch 51/64 loss: 0.34111177921295166
Batch 52/64 loss: 0.34304559230804443
Batch 53/64 loss: 0.3427215814590454
Batch 54/64 loss: 0.33913856744766235
Batch 55/64 loss: 0.3417511582374573
Batch 56/64 loss: 0.338276743888855
Batch 57/64 loss: 0.33538031578063965
Batch 58/64 loss: 0.3389686346054077
Batch 59/64 loss: 0.34243786334991455
Batch 60/64 loss: 0.33343613147735596
Batch 61/64 loss: 0.339419960975647
Batch 62/64 loss: 0.34397584199905396
Batch 63/64 loss: 0.3379351496696472
Batch 64/64 loss: 0.3467540144920349
Epoch 129  Train loss: 0.3402750868423312  Val loss: 0.34630216151168663
Saving best model, epoch: 129
Epoch 130
-------------------------------
Batch 1/64 loss: 0.34091711044311523
Batch 2/64 loss: 0.3414345979690552
Batch 3/64 loss: 0.34174656867980957
Batch 4/64 loss: 0.34010136127471924
Batch 5/64 loss: 0.3392271399497986
Batch 6/64 loss: 0.3412414789199829
Batch 7/64 loss: 0.3411668539047241
Batch 8/64 loss: 0.34283268451690674
Batch 9/64 loss: 0.3363323211669922
Batch 10/64 loss: 0.3455539345741272
Batch 11/64 loss: 0.3403230309486389
Batch 12/64 loss: 0.33935344219207764
Batch 13/64 loss: 0.3421679139137268
Batch 14/64 loss: 0.3374407887458801
Batch 15/64 loss: 0.3347952961921692
Batch 16/64 loss: 0.33747154474258423
Batch 17/64 loss: 0.34289515018463135
Batch 18/64 loss: 0.3328113555908203
Batch 19/64 loss: 0.3382037878036499
Batch 20/64 loss: 0.34278666973114014
Batch 21/64 loss: 0.3365159034729004
Batch 22/64 loss: 0.33729875087738037
Batch 23/64 loss: 0.34041619300842285
Batch 24/64 loss: 0.34113359451293945
Batch 25/64 loss: 0.34015023708343506
Batch 26/64 loss: 0.3429824113845825
Batch 27/64 loss: 0.34187382459640503
Batch 28/64 loss: 0.3420001268386841
Batch 29/64 loss: 0.3388705253601074
Batch 30/64 loss: 0.3375529646873474
Batch 31/64 loss: 0.34154200553894043
Batch 32/64 loss: 0.3425554037094116
Batch 33/64 loss: 0.34187835454940796
Batch 34/64 loss: 0.3401249647140503
Batch 35/64 loss: 0.34092026948928833
Batch 36/64 loss: 0.33896350860595703
Batch 37/64 loss: 0.34032565355300903
Batch 38/64 loss: 0.3425179719924927
Batch 39/64 loss: 0.3452792763710022
Batch 40/64 loss: 0.33754003047943115
Batch 41/64 loss: 0.3362652063369751
Batch 42/64 loss: 0.3438722491264343
Batch 43/64 loss: 0.34002232551574707
Batch 44/64 loss: 0.3405323028564453
Batch 45/64 loss: 0.34534400701522827
Batch 46/64 loss: 0.3409419059753418
Batch 47/64 loss: 0.34161436557769775
Batch 48/64 loss: 0.34156399965286255
Batch 49/64 loss: 0.3347592353820801
Batch 50/64 loss: 0.3364298343658447
Batch 51/64 loss: 0.3418562412261963
Batch 52/64 loss: 0.3375915288925171
Batch 53/64 loss: 0.3405311703681946
Batch 54/64 loss: 0.34210872650146484
Batch 55/64 loss: 0.3344501256942749
Batch 56/64 loss: 0.33696913719177246
Batch 57/64 loss: 0.34058135747909546
Batch 58/64 loss: 0.3388139605522156
Batch 59/64 loss: 0.33943861722946167
Batch 60/64 loss: 0.34170031547546387
Batch 61/64 loss: 0.3393808603286743
Batch 62/64 loss: 0.345218300819397
Batch 63/64 loss: 0.3421027660369873
Batch 64/64 loss: 0.337282657623291
Epoch 130  Train loss: 0.3401458123150994  Val loss: 0.34622106929005625
Saving best model, epoch: 130
Epoch 131
-------------------------------
Batch 1/64 loss: 0.33827078342437744
Batch 2/64 loss: 0.3374284505844116
Batch 3/64 loss: 0.33273637294769287
Batch 4/64 loss: 0.3483368158340454
Batch 5/64 loss: 0.3435933589935303
Batch 6/64 loss: 0.3400146961212158
Batch 7/64 loss: 0.34681642055511475
Batch 8/64 loss: 0.3462122678756714
Batch 9/64 loss: 0.34004640579223633
Batch 10/64 loss: 0.3372911214828491
Batch 11/64 loss: 0.3395211696624756
Batch 12/64 loss: 0.3386877775192261
Batch 13/64 loss: 0.3381198048591614
Batch 14/64 loss: 0.3423084616661072
Batch 15/64 loss: 0.34206390380859375
Batch 16/64 loss: 0.3379209041595459
Batch 17/64 loss: 0.33729344606399536
Batch 18/64 loss: 0.3396247625350952
Batch 19/64 loss: 0.3387840986251831
Batch 20/64 loss: 0.3374495506286621
Batch 21/64 loss: 0.342049241065979
Batch 22/64 loss: 0.3447216749191284
Batch 23/64 loss: 0.3406432271003723
Batch 24/64 loss: 0.34024137258529663
Batch 25/64 loss: 0.3449188470840454
Batch 26/64 loss: 0.34349143505096436
Batch 27/64 loss: 0.34176546335220337
Batch 28/64 loss: 0.34197044372558594
Batch 29/64 loss: 0.3451969623565674
Batch 30/64 loss: 0.33545732498168945
Batch 31/64 loss: 0.3375145196914673
Batch 32/64 loss: 0.3402937650680542
Batch 33/64 loss: 0.3413258194923401
Batch 34/64 loss: 0.3387562036514282
Batch 35/64 loss: 0.34062135219573975
Batch 36/64 loss: 0.3364964723587036
Batch 37/64 loss: 0.3378429412841797
Batch 38/64 loss: 0.3365594148635864
Batch 39/64 loss: 0.339044451713562
Batch 40/64 loss: 0.34067416191101074
Batch 41/64 loss: 0.33663928508758545
Batch 42/64 loss: 0.33642578125
Batch 43/64 loss: 0.333707332611084
Batch 44/64 loss: 0.3403444290161133
Batch 45/64 loss: 0.3351740837097168
Batch 46/64 loss: 0.34195899963378906
Batch 47/64 loss: 0.33966076374053955
Batch 48/64 loss: 0.3444758653640747
Batch 49/64 loss: 0.3388526439666748
Batch 50/64 loss: 0.3409767150878906
Batch 51/64 loss: 0.3417879343032837
Batch 52/64 loss: 0.3411306142807007
Batch 53/64 loss: 0.3427113890647888
Batch 54/64 loss: 0.337349534034729
Batch 55/64 loss: 0.34209907054901123
Batch 56/64 loss: 0.3416789770126343
Batch 57/64 loss: 0.3382638692855835
Batch 58/64 loss: 0.3356291651725769
Batch 59/64 loss: 0.3364097476005554
Batch 60/64 loss: 0.33628398180007935
Batch 61/64 loss: 0.3406388759613037
Batch 62/64 loss: 0.33954858779907227
Batch 63/64 loss: 0.3380919098854065
Batch 64/64 loss: 0.34112703800201416
Epoch 131  Train loss: 0.33988690984015374  Val loss: 0.34687954269323973
Epoch 132
-------------------------------
Batch 1/64 loss: 0.34141743183135986
Batch 2/64 loss: 0.33952200412750244
Batch 3/64 loss: 0.3422905206680298
Batch 4/64 loss: 0.3370552062988281
Batch 5/64 loss: 0.34042423963546753
Batch 6/64 loss: 0.3408527374267578
Batch 7/64 loss: 0.34319353103637695
Batch 8/64 loss: 0.3350982666015625
Batch 9/64 loss: 0.34018754959106445
Batch 10/64 loss: 0.3398609757423401
Batch 11/64 loss: 0.3379165530204773
Batch 12/64 loss: 0.3423226475715637
Batch 13/64 loss: 0.33951854705810547
Batch 14/64 loss: 0.3435049057006836
Batch 15/64 loss: 0.34225326776504517
Batch 16/64 loss: 0.3420482277870178
Batch 17/64 loss: 0.34211403131484985
Batch 18/64 loss: 0.34107738733291626
Batch 19/64 loss: 0.34022313356399536
Batch 20/64 loss: 0.3342992067337036
Batch 21/64 loss: 0.34417885541915894
Batch 22/64 loss: 0.34118974208831787
Batch 23/64 loss: 0.339865505695343
Batch 24/64 loss: 0.3406749367713928
Batch 25/64 loss: 0.3397960662841797
Batch 26/64 loss: 0.340024471282959
Batch 27/64 loss: 0.3388299345970154
Batch 28/64 loss: 0.3375053405761719
Batch 29/64 loss: 0.3398934006690979
Batch 30/64 loss: 0.34521496295928955
Batch 31/64 loss: 0.33891719579696655
Batch 32/64 loss: 0.33974480628967285
Batch 33/64 loss: 0.33681368827819824
Batch 34/64 loss: 0.33935242891311646
Batch 35/64 loss: 0.3382434844970703
Batch 36/64 loss: 0.3380018472671509
Batch 37/64 loss: 0.34459006786346436
Batch 38/64 loss: 0.3441309332847595
Batch 39/64 loss: 0.34349703788757324
Batch 40/64 loss: 0.3397144675254822
Batch 41/64 loss: 0.3384266495704651
Batch 42/64 loss: 0.33891522884368896
Batch 43/64 loss: 0.3425931930541992
Batch 44/64 loss: 0.3387306332588196
Batch 45/64 loss: 0.34244585037231445
Batch 46/64 loss: 0.3367719054222107
Batch 47/64 loss: 0.33791565895080566
Batch 48/64 loss: 0.3385869264602661
Batch 49/64 loss: 0.3383737802505493
Batch 50/64 loss: 0.33897554874420166
Batch 51/64 loss: 0.3366190791130066
Batch 52/64 loss: 0.3424566984176636
Batch 53/64 loss: 0.3378169536590576
Batch 54/64 loss: 0.3380542993545532
Batch 55/64 loss: 0.3402467966079712
Batch 56/64 loss: 0.34131574630737305
Batch 57/64 loss: 0.34085798263549805
Batch 58/64 loss: 0.33861297369003296
Batch 59/64 loss: 0.3365747928619385
Batch 60/64 loss: 0.33985936641693115
Batch 61/64 loss: 0.33414506912231445
Batch 62/64 loss: 0.3417171239852905
Batch 63/64 loss: 0.33596301078796387
Batch 64/64 loss: 0.33531326055526733
Epoch 132  Train loss: 0.3398089373812956  Val loss: 0.34681534726185487
Epoch 133
-------------------------------
Batch 1/64 loss: 0.3388260006904602
Batch 2/64 loss: 0.33715975284576416
Batch 3/64 loss: 0.3385223150253296
Batch 4/64 loss: 0.3419908285140991
Batch 5/64 loss: 0.33820778131484985
Batch 6/64 loss: 0.3431330919265747
Batch 7/64 loss: 0.34251952171325684
Batch 8/64 loss: 0.3349193334579468
Batch 9/64 loss: 0.3379591703414917
Batch 10/64 loss: 0.3369460105895996
Batch 11/64 loss: 0.3412361145019531
Batch 12/64 loss: 0.3375810384750366
Batch 13/64 loss: 0.3443388342857361
Batch 14/64 loss: 0.3427967429161072
Batch 15/64 loss: 0.3367995023727417
Batch 16/64 loss: 0.3406999111175537
Batch 17/64 loss: 0.33817803859710693
Batch 18/64 loss: 0.3394123315811157
Batch 19/64 loss: 0.3394361734390259
Batch 20/64 loss: 0.33869469165802
Batch 21/64 loss: 0.33644235134124756
Batch 22/64 loss: 0.33838003873825073
Batch 23/64 loss: 0.33973968029022217
Batch 24/64 loss: 0.34187984466552734
Batch 25/64 loss: 0.3417901396751404
Batch 26/64 loss: 0.3382912874221802
Batch 27/64 loss: 0.3350863456726074
Batch 28/64 loss: 0.34301358461380005
Batch 29/64 loss: 0.3438854217529297
Batch 30/64 loss: 0.3389005661010742
Batch 31/64 loss: 0.34174948930740356
Batch 32/64 loss: 0.3424190878868103
Batch 33/64 loss: 0.33751845359802246
Batch 34/64 loss: 0.3448377847671509
Batch 35/64 loss: 0.33208906650543213
Batch 36/64 loss: 0.341391921043396
Batch 37/64 loss: 0.3381601572036743
Batch 38/64 loss: 0.334736168384552
Batch 39/64 loss: 0.3408777117729187
Batch 40/64 loss: 0.33938783407211304
Batch 41/64 loss: 0.3408372402191162
Batch 42/64 loss: 0.3396190404891968
Batch 43/64 loss: 0.34238314628601074
Batch 44/64 loss: 0.3431464433670044
Batch 45/64 loss: 0.3382660746574402
Batch 46/64 loss: 0.3394765853881836
Batch 47/64 loss: 0.34124934673309326
Batch 48/64 loss: 0.33706724643707275
Batch 49/64 loss: 0.3363965153694153
Batch 50/64 loss: 0.34267228841781616
Batch 51/64 loss: 0.3386593461036682
Batch 52/64 loss: 0.33661460876464844
Batch 53/64 loss: 0.33467626571655273
Batch 54/64 loss: 0.3397979736328125
Batch 55/64 loss: 0.3407183885574341
Batch 56/64 loss: 0.33380329608917236
Batch 57/64 loss: 0.3398374915122986
Batch 58/64 loss: 0.3416648507118225
Batch 59/64 loss: 0.33825504779815674
Batch 60/64 loss: 0.3429293632507324
Batch 61/64 loss: 0.3402225971221924
Batch 62/64 loss: 0.33551669120788574
Batch 63/64 loss: 0.34483885765075684
Batch 64/64 loss: 0.337882936000824
Epoch 133  Train loss: 0.33948227494370703  Val loss: 0.3474456055467481
Epoch 134
-------------------------------
Batch 1/64 loss: 0.3416009545326233
Batch 2/64 loss: 0.34049558639526367
Batch 3/64 loss: 0.34218722581863403
Batch 4/64 loss: 0.3383405804634094
Batch 5/64 loss: 0.3396782875061035
Batch 6/64 loss: 0.3381618857383728
Batch 7/64 loss: 0.33913499116897583
Batch 8/64 loss: 0.3365859389305115
Batch 9/64 loss: 0.34177249670028687
Batch 10/64 loss: 0.34166717529296875
Batch 11/64 loss: 0.3377339839935303
Batch 12/64 loss: 0.34020739793777466
Batch 13/64 loss: 0.33826369047164917
Batch 14/64 loss: 0.34243398904800415
Batch 15/64 loss: 0.338456928730011
Batch 16/64 loss: 0.3403623104095459
Batch 17/64 loss: 0.3375740051269531
Batch 18/64 loss: 0.3415548801422119
Batch 19/64 loss: 0.33588099479675293
Batch 20/64 loss: 0.3400266766548157
Batch 21/64 loss: 0.3407388925552368
Batch 22/64 loss: 0.3426835536956787
Batch 23/64 loss: 0.34139883518218994
Batch 24/64 loss: 0.33608824014663696
Batch 25/64 loss: 0.33887219429016113
Batch 26/64 loss: 0.3375491499900818
Batch 27/64 loss: 0.3387903571128845
Batch 28/64 loss: 0.3358776569366455
Batch 29/64 loss: 0.3429079055786133
Batch 30/64 loss: 0.3397860527038574
Batch 31/64 loss: 0.3411339521408081
Batch 32/64 loss: 0.335737407207489
Batch 33/64 loss: 0.34372860193252563
Batch 34/64 loss: 0.33816099166870117
Batch 35/64 loss: 0.3378601670265198
Batch 36/64 loss: 0.3409231901168823
Batch 37/64 loss: 0.3399397134780884
Batch 38/64 loss: 0.34096938371658325
Batch 39/64 loss: 0.3396860361099243
Batch 40/64 loss: 0.34258556365966797
Batch 41/64 loss: 0.34256136417388916
Batch 42/64 loss: 0.34279024600982666
Batch 43/64 loss: 0.3412901759147644
Batch 44/64 loss: 0.33717286586761475
Batch 45/64 loss: 0.33995509147644043
Batch 46/64 loss: 0.34237873554229736
Batch 47/64 loss: 0.34166836738586426
Batch 48/64 loss: 0.34357333183288574
Batch 49/64 loss: 0.3324710726737976
Batch 50/64 loss: 0.3430529236793518
Batch 51/64 loss: 0.33726590871810913
Batch 52/64 loss: 0.3416493535041809
Batch 53/64 loss: 0.33445656299591064
Batch 54/64 loss: 0.33582019805908203
Batch 55/64 loss: 0.33751165866851807
Batch 56/64 loss: 0.33549070358276367
Batch 57/64 loss: 0.3385952115058899
Batch 58/64 loss: 0.3375762701034546
Batch 59/64 loss: 0.33995354175567627
Batch 60/64 loss: 0.3453361988067627
Batch 61/64 loss: 0.34059393405914307
Batch 62/64 loss: 0.33864760398864746
Batch 63/64 loss: 0.34289562702178955
Batch 64/64 loss: 0.33754169940948486
Epoch 134  Train loss: 0.33966119289398194  Val loss: 0.3457875722872023
Saving best model, epoch: 134
Epoch 135
-------------------------------
Batch 1/64 loss: 0.3422403335571289
Batch 2/64 loss: 0.33639729022979736
Batch 3/64 loss: 0.3428303003311157
Batch 4/64 loss: 0.3410463333129883
Batch 5/64 loss: 0.3377164602279663
Batch 6/64 loss: 0.3405987024307251
Batch 7/64 loss: 0.33520036935806274
Batch 8/64 loss: 0.34146320819854736
Batch 9/64 loss: 0.33849167823791504
Batch 10/64 loss: 0.3351719379425049
Batch 11/64 loss: 0.33353185653686523
Batch 12/64 loss: 0.34097111225128174
Batch 13/64 loss: 0.34159576892852783
Batch 14/64 loss: 0.34121716022491455
Batch 15/64 loss: 0.3394414186477661
Batch 16/64 loss: 0.33709895610809326
Batch 17/64 loss: 0.33883488178253174
Batch 18/64 loss: 0.34137535095214844
Batch 19/64 loss: 0.3405124545097351
Batch 20/64 loss: 0.3342706561088562
Batch 21/64 loss: 0.33844614028930664
Batch 22/64 loss: 0.3334859609603882
Batch 23/64 loss: 0.34398967027664185
Batch 24/64 loss: 0.34047067165374756
Batch 25/64 loss: 0.3405301570892334
Batch 26/64 loss: 0.3451595902442932
Batch 27/64 loss: 0.3368239402770996
Batch 28/64 loss: 0.341508150100708
Batch 29/64 loss: 0.34292811155319214
Batch 30/64 loss: 0.3380219340324402
Batch 31/64 loss: 0.3395587205886841
Batch 32/64 loss: 0.33176493644714355
Batch 33/64 loss: 0.34204769134521484
Batch 34/64 loss: 0.33439695835113525
Batch 35/64 loss: 0.33927011489868164
Batch 36/64 loss: 0.3362579345703125
Batch 37/64 loss: 0.33602631092071533
Batch 38/64 loss: 0.3367648124694824
Batch 39/64 loss: 0.3406863212585449
Batch 40/64 loss: 0.34160828590393066
Batch 41/64 loss: 0.3409217596054077
Batch 42/64 loss: 0.3395915627479553
Batch 43/64 loss: 0.34334421157836914
Batch 44/64 loss: 0.33811140060424805
Batch 45/64 loss: 0.33986490964889526
Batch 46/64 loss: 0.3427155017852783
Batch 47/64 loss: 0.33490651845932007
Batch 48/64 loss: 0.34137237071990967
Batch 49/64 loss: 0.33636802434921265
Batch 50/64 loss: 0.33353549242019653
Batch 51/64 loss: 0.3401700258255005
Batch 52/64 loss: 0.33459311723709106
Batch 53/64 loss: 0.3393479585647583
Batch 54/64 loss: 0.34886234998703003
Batch 55/64 loss: 0.3413517475128174
Batch 56/64 loss: 0.3321693539619446
Batch 57/64 loss: 0.33695781230926514
Batch 58/64 loss: 0.33693641424179077
Batch 59/64 loss: 0.3406860828399658
Batch 60/64 loss: 0.34008294343948364
Batch 61/64 loss: 0.33667993545532227
Batch 62/64 loss: 0.33802902698516846
Batch 63/64 loss: 0.34345871210098267
Batch 64/64 loss: 0.3361161947250366
Epoch 135  Train loss: 0.3390101493573656  Val loss: 0.3458653887112935
Epoch 136
-------------------------------
Batch 1/64 loss: 0.34073805809020996
Batch 2/64 loss: 0.3356151580810547
Batch 3/64 loss: 0.3374570608139038
Batch 4/64 loss: 0.3363914489746094
Batch 5/64 loss: 0.3444575071334839
Batch 6/64 loss: 0.3392748236656189
Batch 7/64 loss: 0.34308087825775146
Batch 8/64 loss: 0.33667004108428955
Batch 9/64 loss: 0.3407936096191406
Batch 10/64 loss: 0.3374403715133667
Batch 11/64 loss: 0.34322428703308105
Batch 12/64 loss: 0.3401976227760315
Batch 13/64 loss: 0.33596891164779663
Batch 14/64 loss: 0.34113776683807373
Batch 15/64 loss: 0.3380744457244873
Batch 16/64 loss: 0.3364272117614746
Batch 17/64 loss: 0.33275818824768066
Batch 18/64 loss: 0.33797234296798706
Batch 19/64 loss: 0.3380575180053711
Batch 20/64 loss: 0.3374711275100708
Batch 21/64 loss: 0.33538079261779785
Batch 22/64 loss: 0.34125852584838867
Batch 23/64 loss: 0.33833444118499756
Batch 24/64 loss: 0.33671092987060547
Batch 25/64 loss: 0.33411097526550293
Batch 26/64 loss: 0.3346874713897705
Batch 27/64 loss: 0.3397365212440491
Batch 28/64 loss: 0.3390536308288574
Batch 29/64 loss: 0.3378707766532898
Batch 30/64 loss: 0.34052425622940063
Batch 31/64 loss: 0.3412569761276245
Batch 32/64 loss: 0.3382960557937622
Batch 33/64 loss: 0.3420172333717346
Batch 34/64 loss: 0.33968955278396606
Batch 35/64 loss: 0.33320099115371704
Batch 36/64 loss: 0.3388064503669739
Batch 37/64 loss: 0.34270596504211426
Batch 38/64 loss: 0.3444696068763733
Batch 39/64 loss: 0.34429752826690674
Batch 40/64 loss: 0.34028077125549316
Batch 41/64 loss: 0.33558183908462524
Batch 42/64 loss: 0.34009766578674316
Batch 43/64 loss: 0.3314688205718994
Batch 44/64 loss: 0.3410830497741699
Batch 45/64 loss: 0.3410249948501587
Batch 46/64 loss: 0.34258586168289185
Batch 47/64 loss: 0.33469444513320923
Batch 48/64 loss: 0.3373929262161255
Batch 49/64 loss: 0.3398427367210388
Batch 50/64 loss: 0.3419555425643921
Batch 51/64 loss: 0.33868592977523804
Batch 52/64 loss: 0.34335780143737793
Batch 53/64 loss: 0.3378217816352844
Batch 54/64 loss: 0.3341794013977051
Batch 55/64 loss: 0.34205710887908936
Batch 56/64 loss: 0.3414524793624878
Batch 57/64 loss: 0.3375662565231323
Batch 58/64 loss: 0.34137487411499023
Batch 59/64 loss: 0.34096938371658325
Batch 60/64 loss: 0.3432255983352661
Batch 61/64 loss: 0.3415595293045044
Batch 62/64 loss: 0.33641254901885986
Batch 63/64 loss: 0.3400965929031372
Batch 64/64 loss: 0.3392823338508606
Epoch 136  Train loss: 0.33905641962500177  Val loss: 0.34693391257544975
Epoch 137
-------------------------------
Batch 1/64 loss: 0.3420078158378601
Batch 2/64 loss: 0.3343437910079956
Batch 3/64 loss: 0.3410300016403198
Batch 4/64 loss: 0.34405577182769775
Batch 5/64 loss: 0.3353698253631592
Batch 6/64 loss: 0.3389934301376343
Batch 7/64 loss: 0.33970534801483154
Batch 8/64 loss: 0.33880722522735596
Batch 9/64 loss: 0.3331235647201538
Batch 10/64 loss: 0.3354940414428711
Batch 11/64 loss: 0.34073013067245483
Batch 12/64 loss: 0.33632993698120117
Batch 13/64 loss: 0.3348914384841919
Batch 14/64 loss: 0.3369559645652771
Batch 15/64 loss: 0.3385446071624756
Batch 16/64 loss: 0.3334892988204956
Batch 17/64 loss: 0.33740460872650146
Batch 18/64 loss: 0.34184205532073975
Batch 19/64 loss: 0.3382481336593628
Batch 20/64 loss: 0.34504109621047974
Batch 21/64 loss: 0.3364102840423584
Batch 22/64 loss: 0.3363863229751587
Batch 23/64 loss: 0.33095723390579224
Batch 24/64 loss: 0.335568904876709
Batch 25/64 loss: 0.3362492322921753
Batch 26/64 loss: 0.3357734680175781
Batch 27/64 loss: 0.3407072424888611
Batch 28/64 loss: 0.3381497859954834
Batch 29/64 loss: 0.3440236449241638
Batch 30/64 loss: 0.341249942779541
Batch 31/64 loss: 0.3441213369369507
Batch 32/64 loss: 0.3406710624694824
Batch 33/64 loss: 0.34374701976776123
Batch 34/64 loss: 0.3417165279388428
Batch 35/64 loss: 0.3368542194366455
Batch 36/64 loss: 0.33573853969573975
Batch 37/64 loss: 0.34276920557022095
Batch 38/64 loss: 0.3436329960823059
Batch 39/64 loss: 0.33821672201156616
Batch 40/64 loss: 0.3422314524650574
Batch 41/64 loss: 0.3417825698852539
Batch 42/64 loss: 0.3378029465675354
Batch 43/64 loss: 0.33220887184143066
Batch 44/64 loss: 0.33743321895599365
Batch 45/64 loss: 0.3443533182144165
Batch 46/64 loss: 0.3430739641189575
Batch 47/64 loss: 0.3416823148727417
Batch 48/64 loss: 0.34145545959472656
Batch 49/64 loss: 0.3462165594100952
Batch 50/64 loss: 0.3385159373283386
Batch 51/64 loss: 0.3340420126914978
Batch 52/64 loss: 0.3389582633972168
Batch 53/64 loss: 0.3381595015525818
Batch 54/64 loss: 0.33404189348220825
Batch 55/64 loss: 0.3412899374961853
Batch 56/64 loss: 0.34265387058258057
Batch 57/64 loss: 0.3399677276611328
Batch 58/64 loss: 0.33538395166397095
Batch 59/64 loss: 0.3416036367416382
Batch 60/64 loss: 0.33954358100891113
Batch 61/64 loss: 0.33968544006347656
Batch 62/64 loss: 0.34188544750213623
Batch 63/64 loss: 0.330578088760376
Batch 64/64 loss: 0.334524929523468
Epoch 137  Train loss: 0.3388987520161797  Val loss: 0.34575795164632633
Saving best model, epoch: 137
Epoch 138
-------------------------------
Batch 1/64 loss: 0.3352487087249756
Batch 2/64 loss: 0.34365904331207275
Batch 3/64 loss: 0.34242695569992065
Batch 4/64 loss: 0.3381616473197937
Batch 5/64 loss: 0.3323080539703369
Batch 6/64 loss: 0.33488011360168457
Batch 7/64 loss: 0.3369320034980774
Batch 8/64 loss: 0.3387625813484192
Batch 9/64 loss: 0.3383711576461792
Batch 10/64 loss: 0.34126484394073486
Batch 11/64 loss: 0.337710976600647
Batch 12/64 loss: 0.33637964725494385
Batch 13/64 loss: 0.3411359190940857
Batch 14/64 loss: 0.3386956453323364
Batch 15/64 loss: 0.3389289975166321
Batch 16/64 loss: 0.33507072925567627
Batch 17/64 loss: 0.3374289274215698
Batch 18/64 loss: 0.3374924659729004
Batch 19/64 loss: 0.3389061689376831
Batch 20/64 loss: 0.34199386835098267
Batch 21/64 loss: 0.33424055576324463
Batch 22/64 loss: 0.3392958641052246
Batch 23/64 loss: 0.3429104685783386
Batch 24/64 loss: 0.33908939361572266
Batch 25/64 loss: 0.34246349334716797
Batch 26/64 loss: 0.34396445751190186
Batch 27/64 loss: 0.3416401147842407
Batch 28/64 loss: 0.33725833892822266
Batch 29/64 loss: 0.34226828813552856
Batch 30/64 loss: 0.3363990783691406
Batch 31/64 loss: 0.33517301082611084
Batch 32/64 loss: 0.3359873294830322
Batch 33/64 loss: 0.34355777502059937
Batch 34/64 loss: 0.335208535194397
Batch 35/64 loss: 0.3394102454185486
Batch 36/64 loss: 0.3364555835723877
Batch 37/64 loss: 0.3313201665878296
Batch 38/64 loss: 0.3358718156814575
Batch 39/64 loss: 0.3414170742034912
Batch 40/64 loss: 0.3433166742324829
Batch 41/64 loss: 0.3407026529312134
Batch 42/64 loss: 0.3432505130767822
Batch 43/64 loss: 0.33997786045074463
Batch 44/64 loss: 0.34208178520202637
Batch 45/64 loss: 0.3358229398727417
Batch 46/64 loss: 0.33726662397384644
Batch 47/64 loss: 0.33837372064590454
Batch 48/64 loss: 0.33822953701019287
Batch 49/64 loss: 0.33541417121887207
Batch 50/64 loss: 0.33783870935440063
Batch 51/64 loss: 0.3392225503921509
Batch 52/64 loss: 0.3435945510864258
Batch 53/64 loss: 0.3424875736236572
Batch 54/64 loss: 0.3431921601295471
Batch 55/64 loss: 0.33841097354888916
Batch 56/64 loss: 0.3383702039718628
Batch 57/64 loss: 0.33546245098114014
Batch 58/64 loss: 0.33885812759399414
Batch 59/64 loss: 0.3418254852294922
Batch 60/64 loss: 0.3424125909805298
Batch 61/64 loss: 0.3331567049026489
Batch 62/64 loss: 0.3380163908004761
Batch 63/64 loss: 0.33955246210098267
Batch 64/64 loss: 0.34563708305358887
Epoch 138  Train loss: 0.33891380814945  Val loss: 0.34627209045633006
Epoch 139
-------------------------------
Batch 1/64 loss: 0.3384026288986206
Batch 2/64 loss: 0.3320075273513794
Batch 3/64 loss: 0.33155184984207153
Batch 4/64 loss: 0.3322482109069824
Batch 5/64 loss: 0.3455975651741028
Batch 6/64 loss: 0.3410317897796631
Batch 7/64 loss: 0.3413335680961609
Batch 8/64 loss: 0.3423715829849243
Batch 9/64 loss: 0.34250640869140625
Batch 10/64 loss: 0.3352698087692261
Batch 11/64 loss: 0.33645182847976685
Batch 12/64 loss: 0.3413844704627991
Batch 13/64 loss: 0.33616745471954346
Batch 14/64 loss: 0.3412657380104065
Batch 15/64 loss: 0.3431876301765442
Batch 16/64 loss: 0.3447911739349365
Batch 17/64 loss: 0.3416883945465088
Batch 18/64 loss: 0.3348590135574341
Batch 19/64 loss: 0.3350833058357239
Batch 20/64 loss: 0.33914655447006226
Batch 21/64 loss: 0.33961087465286255
Batch 22/64 loss: 0.3364989757537842
Batch 23/64 loss: 0.3398388624191284
Batch 24/64 loss: 0.3388429880142212
Batch 25/64 loss: 0.34137511253356934
Batch 26/64 loss: 0.3457881212234497
Batch 27/64 loss: 0.34109699726104736
Batch 28/64 loss: 0.3419920802116394
Batch 29/64 loss: 0.3409932851791382
Batch 30/64 loss: 0.3365682363510132
Batch 31/64 loss: 0.34190261363983154
Batch 32/64 loss: 0.33330023288726807
Batch 33/64 loss: 0.33356088399887085
Batch 34/64 loss: 0.34016674757003784
Batch 35/64 loss: 0.3353985548019409
Batch 36/64 loss: 0.34135550260543823
Batch 37/64 loss: 0.3386247158050537
Batch 38/64 loss: 0.34262382984161377
Batch 39/64 loss: 0.3398590087890625
Batch 40/64 loss: 0.3411051034927368
Batch 41/64 loss: 0.3365321159362793
Batch 42/64 loss: 0.3369927406311035
Batch 43/64 loss: 0.34002387523651123
Batch 44/64 loss: 0.33909356594085693
Batch 45/64 loss: 0.3360031247138977
Batch 46/64 loss: 0.34116727113723755
Batch 47/64 loss: 0.3365226984024048
Batch 48/64 loss: 0.34214162826538086
Batch 49/64 loss: 0.34033864736557007
Batch 50/64 loss: 0.3400142192840576
Batch 51/64 loss: 0.33371108770370483
Batch 52/64 loss: 0.33753740787506104
Batch 53/64 loss: 0.34038031101226807
Batch 54/64 loss: 0.333199679851532
Batch 55/64 loss: 0.33830010890960693
Batch 56/64 loss: 0.33796876668930054
Batch 57/64 loss: 0.3382399082183838
Batch 58/64 loss: 0.33473771810531616
Batch 59/64 loss: 0.3349863290786743
Batch 60/64 loss: 0.33964359760284424
Batch 61/64 loss: 0.3327523469924927
Batch 62/64 loss: 0.3393458127975464
Batch 63/64 loss: 0.3406881093978882
Batch 64/64 loss: 0.3375966548919678
Epoch 139  Train loss: 0.338672435984892  Val loss: 0.34668297456302183
Epoch 140
-------------------------------
Batch 1/64 loss: 0.3392314910888672
Batch 2/64 loss: 0.3379170894622803
Batch 3/64 loss: 0.3315120339393616
Batch 4/64 loss: 0.33575642108917236
Batch 5/64 loss: 0.3410787582397461
Batch 6/64 loss: 0.33909904956817627
Batch 7/64 loss: 0.3411419987678528
Batch 8/64 loss: 0.34568071365356445
Batch 9/64 loss: 0.33968091011047363
Batch 10/64 loss: 0.3376960754394531
Batch 11/64 loss: 0.3401443362236023
Batch 12/64 loss: 0.33989524841308594
Batch 13/64 loss: 0.3426504135131836
Batch 14/64 loss: 0.3328763246536255
Batch 15/64 loss: 0.3403375744819641
Batch 16/64 loss: 0.3410522937774658
Batch 17/64 loss: 0.33434516191482544
Batch 18/64 loss: 0.3384522795677185
Batch 19/64 loss: 0.33954012393951416
Batch 20/64 loss: 0.33659273386001587
Batch 21/64 loss: 0.34096217155456543
Batch 22/64 loss: 0.3373434543609619
Batch 23/64 loss: 0.33791857957839966
Batch 24/64 loss: 0.3343132734298706
Batch 25/64 loss: 0.34146833419799805
Batch 26/64 loss: 0.33711129426956177
Batch 27/64 loss: 0.3328489065170288
Batch 28/64 loss: 0.3403513431549072
Batch 29/64 loss: 0.33549755811691284
Batch 30/64 loss: 0.3343452215194702
Batch 31/64 loss: 0.341918408870697
Batch 32/64 loss: 0.3395751118659973
Batch 33/64 loss: 0.33399099111557007
Batch 34/64 loss: 0.33631277084350586
Batch 35/64 loss: 0.3378760814666748
Batch 36/64 loss: 0.3444817066192627
Batch 37/64 loss: 0.34098148345947266
Batch 38/64 loss: 0.3426297903060913
Batch 39/64 loss: 0.337704062461853
Batch 40/64 loss: 0.3387017250061035
Batch 41/64 loss: 0.3417052626609802
Batch 42/64 loss: 0.33558738231658936
Batch 43/64 loss: 0.34332358837127686
Batch 44/64 loss: 0.34417277574539185
Batch 45/64 loss: 0.3406224250793457
Batch 46/64 loss: 0.33425235748291016
Batch 47/64 loss: 0.3347674608230591
Batch 48/64 loss: 0.336597204208374
Batch 49/64 loss: 0.3413255214691162
Batch 50/64 loss: 0.3368077278137207
Batch 51/64 loss: 0.3394179940223694
Batch 52/64 loss: 0.3444046378135681
Batch 53/64 loss: 0.3403465747833252
Batch 54/64 loss: 0.3387995958328247
Batch 55/64 loss: 0.3345397114753723
Batch 56/64 loss: 0.33886706829071045
Batch 57/64 loss: 0.33333420753479004
Batch 58/64 loss: 0.338864266872406
Batch 59/64 loss: 0.3389763832092285
Batch 60/64 loss: 0.334555983543396
Batch 61/64 loss: 0.3408692479133606
Batch 62/64 loss: 0.3393685817718506
Batch 63/64 loss: 0.3409358859062195
Batch 64/64 loss: 0.3332759141921997
Epoch 140  Train loss: 0.33856332676083434  Val loss: 0.34529123683156016
Saving best model, epoch: 140
Epoch 141
-------------------------------
Batch 1/64 loss: 0.3358255624771118
Batch 2/64 loss: 0.34177637100219727
Batch 3/64 loss: 0.3386315107345581
Batch 4/64 loss: 0.3320775032043457
Batch 5/64 loss: 0.3384196162223816
Batch 6/64 loss: 0.33561229705810547
Batch 7/64 loss: 0.3392956852912903
Batch 8/64 loss: 0.34261131286621094
Batch 9/64 loss: 0.3405405282974243
Batch 10/64 loss: 0.3403312563896179
Batch 11/64 loss: 0.33551228046417236
Batch 12/64 loss: 0.3331716060638428
Batch 13/64 loss: 0.33463311195373535
Batch 14/64 loss: 0.34226667881011963
Batch 15/64 loss: 0.336831271648407
Batch 16/64 loss: 0.3363873362541199
Batch 17/64 loss: 0.34112000465393066
Batch 18/64 loss: 0.3372160792350769
Batch 19/64 loss: 0.3290520906448364
Batch 20/64 loss: 0.34638428688049316
Batch 21/64 loss: 0.3387804627418518
Batch 22/64 loss: 0.33342015743255615
Batch 23/64 loss: 0.33378541469573975
Batch 24/64 loss: 0.33483099937438965
Batch 25/64 loss: 0.34205907583236694
Batch 26/64 loss: 0.33901453018188477
Batch 27/64 loss: 0.34138667583465576
Batch 28/64 loss: 0.3397698998451233
Batch 29/64 loss: 0.340226411819458
Batch 30/64 loss: 0.33302873373031616
Batch 31/64 loss: 0.331770122051239
Batch 32/64 loss: 0.33818644285202026
Batch 33/64 loss: 0.3391990661621094
Batch 34/64 loss: 0.34741783142089844
Batch 35/64 loss: 0.3378108739852905
Batch 36/64 loss: 0.3366283178329468
Batch 37/64 loss: 0.34478759765625
Batch 38/64 loss: 0.33781635761260986
Batch 39/64 loss: 0.3380197286605835
Batch 40/64 loss: 0.3420780897140503
Batch 41/64 loss: 0.34307777881622314
Batch 42/64 loss: 0.33826160430908203
Batch 43/64 loss: 0.33329933881759644
Batch 44/64 loss: 0.34237539768218994
Batch 45/64 loss: 0.3398324251174927
Batch 46/64 loss: 0.3344259262084961
Batch 47/64 loss: 0.33535587787628174
Batch 48/64 loss: 0.3348740339279175
Batch 49/64 loss: 0.3392682671546936
Batch 50/64 loss: 0.3391602039337158
Batch 51/64 loss: 0.3388622999191284
Batch 52/64 loss: 0.33966946601867676
Batch 53/64 loss: 0.3367115259170532
Batch 54/64 loss: 0.3352999687194824
Batch 55/64 loss: 0.3353818655014038
Batch 56/64 loss: 0.3394466042518616
Batch 57/64 loss: 0.3358832597732544
Batch 58/64 loss: 0.34163784980773926
Batch 59/64 loss: 0.3358613848686218
Batch 60/64 loss: 0.3329629898071289
Batch 61/64 loss: 0.3369741439819336
Batch 62/64 loss: 0.34133124351501465
Batch 63/64 loss: 0.334539532661438
Batch 64/64 loss: 0.33823883533477783
Epoch 141  Train loss: 0.3379746712890326  Val loss: 0.34547180633774327
Epoch 142
-------------------------------
Batch 1/64 loss: 0.33933061361312866
Batch 2/64 loss: 0.34028327465057373
Batch 3/64 loss: 0.34688401222229004
Batch 4/64 loss: 0.3406403660774231
Batch 5/64 loss: 0.3416748046875
Batch 6/64 loss: 0.34667670726776123
Batch 7/64 loss: 0.33621782064437866
Batch 8/64 loss: 0.3347684144973755
Batch 9/64 loss: 0.3431978225708008
Batch 10/64 loss: 0.3405177593231201
Batch 11/64 loss: 0.3405115604400635
Batch 12/64 loss: 0.33959829807281494
Batch 13/64 loss: 0.3350391387939453
Batch 14/64 loss: 0.3336111903190613
Batch 15/64 loss: 0.3365520238876343
Batch 16/64 loss: 0.3315662145614624
Batch 17/64 loss: 0.3402208685874939
Batch 18/64 loss: 0.3342617154121399
Batch 19/64 loss: 0.3362581729888916
Batch 20/64 loss: 0.33097946643829346
Batch 21/64 loss: 0.3379993438720703
Batch 22/64 loss: 0.337499737739563
Batch 23/64 loss: 0.3375789523124695
Batch 24/64 loss: 0.3439258337020874
Batch 25/64 loss: 0.3359236717224121
Batch 26/64 loss: 0.33196866512298584
Batch 27/64 loss: 0.33635765314102173
Batch 28/64 loss: 0.33718323707580566
Batch 29/64 loss: 0.3410230875015259
Batch 30/64 loss: 0.33469557762145996
Batch 31/64 loss: 0.34047889709472656
Batch 32/64 loss: 0.33442550897598267
Batch 33/64 loss: 0.3352149724960327
Batch 34/64 loss: 0.3345848321914673
Batch 35/64 loss: 0.3406912684440613
Batch 36/64 loss: 0.3346062898635864
Batch 37/64 loss: 0.3361286520957947
Batch 38/64 loss: 0.3427165150642395
Batch 39/64 loss: 0.3355344533920288
Batch 40/64 loss: 0.33615654706954956
Batch 41/64 loss: 0.3402162194252014
Batch 42/64 loss: 0.3380393981933594
Batch 43/64 loss: 0.3392600417137146
Batch 44/64 loss: 0.3368690609931946
Batch 45/64 loss: 0.3330346941947937
Batch 46/64 loss: 0.3393179774284363
Batch 47/64 loss: 0.32738757133483887
Batch 48/64 loss: 0.33963584899902344
Batch 49/64 loss: 0.34188568592071533
Batch 50/64 loss: 0.33922672271728516
Batch 51/64 loss: 0.3422989845275879
Batch 52/64 loss: 0.3364619016647339
Batch 53/64 loss: 0.34352898597717285
Batch 54/64 loss: 0.3352457880973816
Batch 55/64 loss: 0.33940577507019043
Batch 56/64 loss: 0.33941829204559326
Batch 57/64 loss: 0.33860552310943604
Batch 58/64 loss: 0.33947187662124634
Batch 59/64 loss: 0.3380555510520935
Batch 60/64 loss: 0.3369821310043335
Batch 61/64 loss: 0.33592021465301514
Batch 62/64 loss: 0.3373459577560425
Batch 63/64 loss: 0.34103310108184814
Batch 64/64 loss: 0.33284127712249756
Epoch 142  Train loss: 0.3379099953408335  Val loss: 0.3447547450508039
Saving best model, epoch: 142
Epoch 143
-------------------------------
Batch 1/64 loss: 0.3405972123146057
Batch 2/64 loss: 0.3347874879837036
Batch 3/64 loss: 0.3386273980140686
Batch 4/64 loss: 0.33434534072875977
Batch 5/64 loss: 0.3393261432647705
Batch 6/64 loss: 0.34122318029403687
Batch 7/64 loss: 0.3352939486503601
Batch 8/64 loss: 0.3346753716468811
Batch 9/64 loss: 0.3412278890609741
Batch 10/64 loss: 0.3448864817619324
Batch 11/64 loss: 0.3389514684677124
Batch 12/64 loss: 0.3341403603553772
Batch 13/64 loss: 0.3365473747253418
Batch 14/64 loss: 0.3412927985191345
Batch 15/64 loss: 0.3376031517982483
Batch 16/64 loss: 0.33458250761032104
Batch 17/64 loss: 0.34025347232818604
Batch 18/64 loss: 0.3372797966003418
Batch 19/64 loss: 0.3374019265174866
Batch 20/64 loss: 0.33884239196777344
Batch 21/64 loss: 0.3365882635116577
Batch 22/64 loss: 0.33065319061279297
Batch 23/64 loss: 0.34057438373565674
Batch 24/64 loss: 0.3403107523918152
Batch 25/64 loss: 0.3383437395095825
Batch 26/64 loss: 0.33722275495529175
Batch 27/64 loss: 0.3350028991699219
Batch 28/64 loss: 0.34416663646698
Batch 29/64 loss: 0.33718156814575195
Batch 30/64 loss: 0.33919864892959595
Batch 31/64 loss: 0.33466893434524536
Batch 32/64 loss: 0.34205472469329834
Batch 33/64 loss: 0.3364908695220947
Batch 34/64 loss: 0.3365887403488159
Batch 35/64 loss: 0.33774101734161377
Batch 36/64 loss: 0.33998793363571167
Batch 37/64 loss: 0.3412003517150879
Batch 38/64 loss: 0.33909595012664795
Batch 39/64 loss: 0.34559905529022217
Batch 40/64 loss: 0.3372188210487366
Batch 41/64 loss: 0.34080034494400024
Batch 42/64 loss: 0.338672399520874
Batch 43/64 loss: 0.33327794075012207
Batch 44/64 loss: 0.3334054946899414
Batch 45/64 loss: 0.33246445655822754
Batch 46/64 loss: 0.33959686756134033
Batch 47/64 loss: 0.34211570024490356
Batch 48/64 loss: 0.33658039569854736
Batch 49/64 loss: 0.33566051721572876
Batch 50/64 loss: 0.3400113582611084
Batch 51/64 loss: 0.33911824226379395
Batch 52/64 loss: 0.33887994289398193
Batch 53/64 loss: 0.33517420291900635
Batch 54/64 loss: 0.33979636430740356
Batch 55/64 loss: 0.3375915288925171
Batch 56/64 loss: 0.3367120623588562
Batch 57/64 loss: 0.34104418754577637
Batch 58/64 loss: 0.337110698223114
Batch 59/64 loss: 0.336678147315979
Batch 60/64 loss: 0.33696597814559937
Batch 61/64 loss: 0.33566200733184814
Batch 62/64 loss: 0.34150993824005127
Batch 63/64 loss: 0.3358008861541748
Batch 64/64 loss: 0.3396111726760864
Epoch 143  Train loss: 0.33805667419059604  Val loss: 0.34558862427255954
Epoch 144
-------------------------------
Batch 1/64 loss: 0.33966970443725586
Batch 2/64 loss: 0.3410319685935974
Batch 3/64 loss: 0.3368234634399414
Batch 4/64 loss: 0.3384578824043274
Batch 5/64 loss: 0.3391011953353882
Batch 6/64 loss: 0.3357505798339844
Batch 7/64 loss: 0.3348170518875122
Batch 8/64 loss: 0.3352939486503601
Batch 9/64 loss: 0.3365863561630249
Batch 10/64 loss: 0.33906328678131104
Batch 11/64 loss: 0.3329598903656006
Batch 12/64 loss: 0.3402063250541687
Batch 13/64 loss: 0.34062105417251587
Batch 14/64 loss: 0.3350338935852051
Batch 15/64 loss: 0.3411632180213928
Batch 16/64 loss: 0.3444838523864746
Batch 17/64 loss: 0.33905231952667236
Batch 18/64 loss: 0.33462613821029663
Batch 19/64 loss: 0.3342247009277344
Batch 20/64 loss: 0.33982396125793457
Batch 21/64 loss: 0.3351471424102783
Batch 22/64 loss: 0.33354651927948
Batch 23/64 loss: 0.34193360805511475
Batch 24/64 loss: 0.33854997158050537
Batch 25/64 loss: 0.33946722745895386
Batch 26/64 loss: 0.3384673595428467
Batch 27/64 loss: 0.3371616005897522
Batch 28/64 loss: 0.3346860408782959
Batch 29/64 loss: 0.33696913719177246
Batch 30/64 loss: 0.33767127990722656
Batch 31/64 loss: 0.3392505645751953
Batch 32/64 loss: 0.3338671922683716
Batch 33/64 loss: 0.33421385288238525
Batch 34/64 loss: 0.3369227647781372
Batch 35/64 loss: 0.33859992027282715
Batch 36/64 loss: 0.3445535898208618
Batch 37/64 loss: 0.3388894200325012
Batch 38/64 loss: 0.334567129611969
Batch 39/64 loss: 0.34626734256744385
Batch 40/64 loss: 0.33661603927612305
Batch 41/64 loss: 0.3374328017234802
Batch 42/64 loss: 0.3429988622665405
Batch 43/64 loss: 0.33845776319503784
Batch 44/64 loss: 0.34090107679367065
Batch 45/64 loss: 0.3354564905166626
Batch 46/64 loss: 0.3399066925048828
Batch 47/64 loss: 0.3408719301223755
Batch 48/64 loss: 0.33682239055633545
Batch 49/64 loss: 0.34091418981552124
Batch 50/64 loss: 0.3362618684768677
Batch 51/64 loss: 0.3358497619628906
Batch 52/64 loss: 0.33754509687423706
Batch 53/64 loss: 0.34018683433532715
Batch 54/64 loss: 0.33689379692077637
Batch 55/64 loss: 0.3344688415527344
Batch 56/64 loss: 0.3344672918319702
Batch 57/64 loss: 0.3341182470321655
Batch 58/64 loss: 0.3395127058029175
Batch 59/64 loss: 0.34252268075942993
Batch 60/64 loss: 0.3405558466911316
Batch 61/64 loss: 0.3343698978424072
Batch 62/64 loss: 0.3363726735115051
Batch 63/64 loss: 0.3273749351501465
Batch 64/64 loss: 0.3426392078399658
Epoch 144  Train loss: 0.3378412639393526  Val loss: 0.345199782414125
Epoch 145
-------------------------------
Batch 1/64 loss: 0.33840620517730713
Batch 2/64 loss: 0.3420931100845337
Batch 3/64 loss: 0.3334510326385498
Batch 4/64 loss: 0.3350192904472351
Batch 5/64 loss: 0.3369086980819702
Batch 6/64 loss: 0.33366817235946655
Batch 7/64 loss: 0.3350592255592346
Batch 8/64 loss: 0.33858323097229004
Batch 9/64 loss: 0.33235496282577515
Batch 10/64 loss: 0.3358520269393921
Batch 11/64 loss: 0.33269381523132324
Batch 12/64 loss: 0.33626025915145874
Batch 13/64 loss: 0.3418079614639282
Batch 14/64 loss: 0.3390713334083557
Batch 15/64 loss: 0.3449587821960449
Batch 16/64 loss: 0.33436059951782227
Batch 17/64 loss: 0.3421083688735962
Batch 18/64 loss: 0.339752197265625
Batch 19/64 loss: 0.337679386138916
Batch 20/64 loss: 0.3387524485588074
Batch 21/64 loss: 0.3392636775970459
Batch 22/64 loss: 0.336315393447876
Batch 23/64 loss: 0.3325995206832886
Batch 24/64 loss: 0.33808231353759766
Batch 25/64 loss: 0.33743011951446533
Batch 26/64 loss: 0.3451012969017029
Batch 27/64 loss: 0.3360138535499573
Batch 28/64 loss: 0.3425384759902954
Batch 29/64 loss: 0.33405792713165283
Batch 30/64 loss: 0.3387412428855896
Batch 31/64 loss: 0.337921142578125
Batch 32/64 loss: 0.33796489238739014
Batch 33/64 loss: 0.34062647819519043
Batch 34/64 loss: 0.34010857343673706
Batch 35/64 loss: 0.3376142978668213
Batch 36/64 loss: 0.3391311764717102
Batch 37/64 loss: 0.33786702156066895
Batch 38/64 loss: 0.34022223949432373
Batch 39/64 loss: 0.340415358543396
Batch 40/64 loss: 0.3365046977996826
Batch 41/64 loss: 0.3431251049041748
Batch 42/64 loss: 0.33542025089263916
Batch 43/64 loss: 0.3412840962409973
Batch 44/64 loss: 0.33736467361450195
Batch 45/64 loss: 0.33517521619796753
Batch 46/64 loss: 0.3385305404663086
Batch 47/64 loss: 0.3376297950744629
Batch 48/64 loss: 0.3321191072463989
Batch 49/64 loss: 0.33476734161376953
Batch 50/64 loss: 0.3348344564437866
Batch 51/64 loss: 0.3421695828437805
Batch 52/64 loss: 0.3392426371574402
Batch 53/64 loss: 0.3425337076187134
Batch 54/64 loss: 0.33885782957077026
Batch 55/64 loss: 0.33465397357940674
Batch 56/64 loss: 0.3418136239051819
Batch 57/64 loss: 0.3350502848625183
Batch 58/64 loss: 0.3345605731010437
Batch 59/64 loss: 0.3375256657600403
Batch 60/64 loss: 0.33923768997192383
Batch 61/64 loss: 0.3373180627822876
Batch 62/64 loss: 0.3383874297142029
Batch 63/64 loss: 0.33828651905059814
Batch 64/64 loss: 0.3363363742828369
Epoch 145  Train loss: 0.33787452940847357  Val loss: 0.34509910484359846
Epoch 146
-------------------------------
Batch 1/64 loss: 0.3346902132034302
Batch 2/64 loss: 0.3395082950592041
Batch 3/64 loss: 0.34336209297180176
Batch 4/64 loss: 0.33513540029525757
Batch 5/64 loss: 0.33609771728515625
Batch 6/64 loss: 0.33276766538619995
Batch 7/64 loss: 0.3336018919944763
Batch 8/64 loss: 0.3408343195915222
Batch 9/64 loss: 0.33673959970474243
Batch 10/64 loss: 0.3339928388595581
Batch 11/64 loss: 0.3379162549972534
Batch 12/64 loss: 0.33937156200408936
Batch 13/64 loss: 0.33742058277130127
Batch 14/64 loss: 0.3458079695701599
Batch 15/64 loss: 0.3366800546646118
Batch 16/64 loss: 0.33815646171569824
Batch 17/64 loss: 0.3391587734222412
Batch 18/64 loss: 0.33701980113983154
Batch 19/64 loss: 0.3365376591682434
Batch 20/64 loss: 0.3356531262397766
Batch 21/64 loss: 0.33909904956817627
Batch 22/64 loss: 0.33543330430984497
Batch 23/64 loss: 0.3391993045806885
Batch 24/64 loss: 0.3391380310058594
Batch 25/64 loss: 0.33363068103790283
Batch 26/64 loss: 0.33971065282821655
Batch 27/64 loss: 0.3363463878631592
Batch 28/64 loss: 0.3308013081550598
Batch 29/64 loss: 0.33713746070861816
Batch 30/64 loss: 0.3380066156387329
Batch 31/64 loss: 0.33616435527801514
Batch 32/64 loss: 0.33587443828582764
Batch 33/64 loss: 0.33625710010528564
Batch 34/64 loss: 0.3402491807937622
Batch 35/64 loss: 0.33431243896484375
Batch 36/64 loss: 0.3372389078140259
Batch 37/64 loss: 0.3408550024032593
Batch 38/64 loss: 0.339036226272583
Batch 39/64 loss: 0.33619922399520874
Batch 40/64 loss: 0.3353234529495239
Batch 41/64 loss: 0.33435332775115967
Batch 42/64 loss: 0.33596205711364746
Batch 43/64 loss: 0.3387158513069153
Batch 44/64 loss: 0.3374900221824646
Batch 45/64 loss: 0.3350163698196411
Batch 46/64 loss: 0.3375101089477539
Batch 47/64 loss: 0.342792272567749
Batch 48/64 loss: 0.3312779664993286
Batch 49/64 loss: 0.339089572429657
Batch 50/64 loss: 0.3306710124015808
Batch 51/64 loss: 0.34024637937545776
Batch 52/64 loss: 0.3361300230026245
Batch 53/64 loss: 0.34414494037628174
Batch 54/64 loss: 0.34219610691070557
Batch 55/64 loss: 0.3437725901603699
Batch 56/64 loss: 0.33791375160217285
Batch 57/64 loss: 0.335247278213501
Batch 58/64 loss: 0.3362523317337036
Batch 59/64 loss: 0.33907008171081543
Batch 60/64 loss: 0.3408200740814209
Batch 61/64 loss: 0.33748698234558105
Batch 62/64 loss: 0.3344593048095703
Batch 63/64 loss: 0.3357342481613159
Batch 64/64 loss: 0.33348792791366577
Epoch 146  Train loss: 0.3373636706202638  Val loss: 0.3448095653474945
Epoch 147
-------------------------------
Batch 1/64 loss: 0.33314359188079834
Batch 2/64 loss: 0.33453577756881714
Batch 3/64 loss: 0.33983707427978516
Batch 4/64 loss: 0.33843719959259033
Batch 5/64 loss: 0.33659011125564575
Batch 6/64 loss: 0.34131109714508057
Batch 7/64 loss: 0.3313401937484741
Batch 8/64 loss: 0.3384321331977844
Batch 9/64 loss: 0.3368905782699585
Batch 10/64 loss: 0.3371732831001282
Batch 11/64 loss: 0.3353883624076843
Batch 12/64 loss: 0.3341236710548401
Batch 13/64 loss: 0.3361705541610718
Batch 14/64 loss: 0.3346971869468689
Batch 15/64 loss: 0.33329010009765625
Batch 16/64 loss: 0.33549678325653076
Batch 17/64 loss: 0.3362828493118286
Batch 18/64 loss: 0.3424743413925171
Batch 19/64 loss: 0.33710408210754395
Batch 20/64 loss: 0.33559948205947876
Batch 21/64 loss: 0.33852601051330566
Batch 22/64 loss: 0.33386051654815674
Batch 23/64 loss: 0.3368690013885498
Batch 24/64 loss: 0.3350018858909607
Batch 25/64 loss: 0.33671700954437256
Batch 26/64 loss: 0.3418561816215515
Batch 27/64 loss: 0.33657217025756836
Batch 28/64 loss: 0.3408106565475464
Batch 29/64 loss: 0.33617448806762695
Batch 30/64 loss: 0.338619589805603
Batch 31/64 loss: 0.3397345542907715
Batch 32/64 loss: 0.3391011953353882
Batch 33/64 loss: 0.33893799781799316
Batch 34/64 loss: 0.34023070335388184
Batch 35/64 loss: 0.3322521448135376
Batch 36/64 loss: 0.3375805616378784
Batch 37/64 loss: 0.33425432443618774
Batch 38/64 loss: 0.33531951904296875
Batch 39/64 loss: 0.339250385761261
Batch 40/64 loss: 0.33558619022369385
Batch 41/64 loss: 0.33693504333496094
Batch 42/64 loss: 0.3340708613395691
Batch 43/64 loss: 0.3378952741622925
Batch 44/64 loss: 0.33170974254608154
Batch 45/64 loss: 0.33949553966522217
Batch 46/64 loss: 0.3400488495826721
Batch 47/64 loss: 0.33338725566864014
Batch 48/64 loss: 0.3401988744735718
Batch 49/64 loss: 0.3378283381462097
Batch 50/64 loss: 0.3391668200492859
Batch 51/64 loss: 0.33527684211730957
Batch 52/64 loss: 0.3392637372016907
Batch 53/64 loss: 0.34701621532440186
Batch 54/64 loss: 0.33753252029418945
Batch 55/64 loss: 0.34120386838912964
Batch 56/64 loss: 0.3369636535644531
Batch 57/64 loss: 0.33432066440582275
Batch 58/64 loss: 0.3378816246986389
Batch 59/64 loss: 0.33605897426605225
Batch 60/64 loss: 0.33916717767715454
Batch 61/64 loss: 0.33665746450424194
Batch 62/64 loss: 0.3364051580429077
Batch 63/64 loss: 0.3350933790206909
Batch 64/64 loss: 0.3324838876724243
Epoch 147  Train loss: 0.33707473465040616  Val loss: 0.34476865648813676
Epoch 148
-------------------------------
Batch 1/64 loss: 0.33215057849884033
Batch 2/64 loss: 0.3325795531272888
Batch 3/64 loss: 0.3375316858291626
Batch 4/64 loss: 0.33267366886138916
Batch 5/64 loss: 0.33629465103149414
Batch 6/64 loss: 0.3381783962249756
Batch 7/64 loss: 0.3330667018890381
Batch 8/64 loss: 0.3396899700164795
Batch 9/64 loss: 0.3383423686027527
Batch 10/64 loss: 0.33564525842666626
Batch 11/64 loss: 0.3372799754142761
Batch 12/64 loss: 0.34037792682647705
Batch 13/64 loss: 0.33844733238220215
Batch 14/64 loss: 0.3488471508026123
Batch 15/64 loss: 0.33762800693511963
Batch 16/64 loss: 0.3337334990501404
Batch 17/64 loss: 0.337673544883728
Batch 18/64 loss: 0.338534414768219
Batch 19/64 loss: 0.3413580656051636
Batch 20/64 loss: 0.34237658977508545
Batch 21/64 loss: 0.3364756107330322
Batch 22/64 loss: 0.3383786082267761
Batch 23/64 loss: 0.33524489402770996
Batch 24/64 loss: 0.336996853351593
Batch 25/64 loss: 0.33782660961151123
Batch 26/64 loss: 0.33702778816223145
Batch 27/64 loss: 0.3353290557861328
Batch 28/64 loss: 0.3354332447052002
Batch 29/64 loss: 0.33505403995513916
Batch 30/64 loss: 0.33356666564941406
Batch 31/64 loss: 0.3343721628189087
Batch 32/64 loss: 0.33702772855758667
Batch 33/64 loss: 0.33910852670669556
Batch 34/64 loss: 0.3368363380432129
Batch 35/64 loss: 0.3379652500152588
Batch 36/64 loss: 0.3389705419540405
Batch 37/64 loss: 0.33768898248672485
Batch 38/64 loss: 0.3320655822753906
Batch 39/64 loss: 0.33770281076431274
Batch 40/64 loss: 0.34023356437683105
Batch 41/64 loss: 0.3411422371864319
Batch 42/64 loss: 0.3325873613357544
Batch 43/64 loss: 0.3385082483291626
Batch 44/64 loss: 0.3376200199127197
Batch 45/64 loss: 0.3333287835121155
Batch 46/64 loss: 0.33607959747314453
Batch 47/64 loss: 0.33955061435699463
Batch 48/64 loss: 0.33610260486602783
Batch 49/64 loss: 0.330751895904541
Batch 50/64 loss: 0.3343672752380371
Batch 51/64 loss: 0.3352736234664917
Batch 52/64 loss: 0.33433806896209717
Batch 53/64 loss: 0.33968544006347656
Batch 54/64 loss: 0.33831673860549927
Batch 55/64 loss: 0.34252768754959106
Batch 56/64 loss: 0.340573251247406
Batch 57/64 loss: 0.33220237493515015
Batch 58/64 loss: 0.33390748500823975
Batch 59/64 loss: 0.3345443606376648
Batch 60/64 loss: 0.3398411273956299
Batch 61/64 loss: 0.3364896774291992
Batch 62/64 loss: 0.3368809223175049
Batch 63/64 loss: 0.33606797456741333
Batch 64/64 loss: 0.33724164962768555
Epoch 148  Train loss: 0.33693071066164504  Val loss: 0.3447658741187394
Epoch 149
-------------------------------
Batch 1/64 loss: 0.33235812187194824
Batch 2/64 loss: 0.34049296379089355
Batch 3/64 loss: 0.3351818323135376
Batch 4/64 loss: 0.33323216438293457
Batch 5/64 loss: 0.3354710340499878
Batch 6/64 loss: 0.3355486989021301
Batch 7/64 loss: 0.3369549512863159
Batch 8/64 loss: 0.335171103477478
Batch 9/64 loss: 0.3368203639984131
Batch 10/64 loss: 0.33763444423675537
Batch 11/64 loss: 0.3423740267753601
Batch 12/64 loss: 0.33642321825027466
Batch 13/64 loss: 0.3399296998977661
Batch 14/64 loss: 0.33689069747924805
Batch 15/64 loss: 0.33796966075897217
Batch 16/64 loss: 0.3303847312927246
Batch 17/64 loss: 0.33448976278305054
Batch 18/64 loss: 0.33700060844421387
Batch 19/64 loss: 0.33299243450164795
Batch 20/64 loss: 0.3388717770576477
Batch 21/64 loss: 0.3364579677581787
Batch 22/64 loss: 0.3377033472061157
Batch 23/64 loss: 0.3331756591796875
Batch 24/64 loss: 0.3341277241706848
Batch 25/64 loss: 0.33487236499786377
Batch 26/64 loss: 0.33718228340148926
Batch 27/64 loss: 0.33935558795928955
Batch 28/64 loss: 0.34484124183654785
Batch 29/64 loss: 0.334919810295105
Batch 30/64 loss: 0.33328914642333984
Batch 31/64 loss: 0.3358536958694458
Batch 32/64 loss: 0.3399966359138489
Batch 33/64 loss: 0.33641159534454346
Batch 34/64 loss: 0.3358609676361084
Batch 35/64 loss: 0.3404815196990967
Batch 36/64 loss: 0.3369435667991638
Batch 37/64 loss: 0.3388980031013489
Batch 38/64 loss: 0.33913302421569824
Batch 39/64 loss: 0.33902835845947266
Batch 40/64 loss: 0.33286458253860474
Batch 41/64 loss: 0.33412373065948486
Batch 42/64 loss: 0.33771491050720215
Batch 43/64 loss: 0.336597204208374
Batch 44/64 loss: 0.3439057469367981
Batch 45/64 loss: 0.33899229764938354
Batch 46/64 loss: 0.34075140953063965
Batch 47/64 loss: 0.3330347537994385
Batch 48/64 loss: 0.3387199640274048
Batch 49/64 loss: 0.3367116451263428
Batch 50/64 loss: 0.3365837335586548
Batch 51/64 loss: 0.33324944972991943
Batch 52/64 loss: 0.33708858489990234
Batch 53/64 loss: 0.3393528461456299
Batch 54/64 loss: 0.3352264165878296
Batch 55/64 loss: 0.33031439781188965
Batch 56/64 loss: 0.3406280279159546
Batch 57/64 loss: 0.3350818157196045
Batch 58/64 loss: 0.3308714032173157
Batch 59/64 loss: 0.33619046211242676
Batch 60/64 loss: 0.3353548049926758
Batch 61/64 loss: 0.342573881149292
Batch 62/64 loss: 0.3398500680923462
Batch 63/64 loss: 0.33444082736968994
Batch 64/64 loss: 0.33974432945251465
Epoch 149  Train loss: 0.336780486387365  Val loss: 0.34442131175208335
Saving best model, epoch: 149
Epoch 150
-------------------------------
Batch 1/64 loss: 0.33767223358154297
Batch 2/64 loss: 0.34080809354782104
Batch 3/64 loss: 0.34020739793777466
Batch 4/64 loss: 0.33766674995422363
Batch 5/64 loss: 0.3343374729156494
Batch 6/64 loss: 0.3372960686683655
Batch 7/64 loss: 0.33411210775375366
Batch 8/64 loss: 0.3339540958404541
Batch 9/64 loss: 0.3358689546585083
Batch 10/64 loss: 0.3355445861816406
Batch 11/64 loss: 0.33722227811813354
Batch 12/64 loss: 0.3376789689064026
Batch 13/64 loss: 0.3340756893157959
Batch 14/64 loss: 0.34216153621673584
Batch 15/64 loss: 0.3394539952278137
Batch 16/64 loss: 0.3342757821083069
Batch 17/64 loss: 0.3319774270057678
Batch 18/64 loss: 0.3425372242927551
Batch 19/64 loss: 0.3355482816696167
Batch 20/64 loss: 0.3343755602836609
Batch 21/64 loss: 0.3366125822067261
Batch 22/64 loss: 0.33967459201812744
Batch 23/64 loss: 0.3371201157569885
Batch 24/64 loss: 0.33412235975265503
Batch 25/64 loss: 0.3366265892982483
Batch 26/64 loss: 0.3354818820953369
Batch 27/64 loss: 0.33174431324005127
Batch 28/64 loss: 0.3394775986671448
Batch 29/64 loss: 0.33585166931152344
Batch 30/64 loss: 0.33346259593963623
Batch 31/64 loss: 0.33390432596206665
Batch 32/64 loss: 0.3411317467689514
Batch 33/64 loss: 0.340202271938324
Batch 34/64 loss: 0.3372786045074463
Batch 35/64 loss: 0.3380774259567261
Batch 36/64 loss: 0.3376227021217346
Batch 37/64 loss: 0.3422449827194214
Batch 38/64 loss: 0.3317905068397522
Batch 39/64 loss: 0.3372035026550293
Batch 40/64 loss: 0.334946870803833
Batch 41/64 loss: 0.33331817388534546
Batch 42/64 loss: 0.3352225422859192
Batch 43/64 loss: 0.34701502323150635
Batch 44/64 loss: 0.33740687370300293
Batch 45/64 loss: 0.3392099142074585
Batch 46/64 loss: 0.33668631315231323
Batch 47/64 loss: 0.3358626365661621
Batch 48/64 loss: 0.3392629623413086
Batch 49/64 loss: 0.33713263273239136
Batch 50/64 loss: 0.3366239666938782
Batch 51/64 loss: 0.3330684304237366
Batch 52/64 loss: 0.3366600275039673
Batch 53/64 loss: 0.3350156545639038
Batch 54/64 loss: 0.3340364694595337
Batch 55/64 loss: 0.3400052785873413
Batch 56/64 loss: 0.33956336975097656
Batch 57/64 loss: 0.33633118867874146
Batch 58/64 loss: 0.33085083961486816
Batch 59/64 loss: 0.34129297733306885
Batch 60/64 loss: 0.3404250144958496
Batch 61/64 loss: 0.33711814880371094
Batch 62/64 loss: 0.3383563756942749
Batch 63/64 loss: 0.33459651470184326
Batch 64/64 loss: 0.33596140146255493
Epoch 150  Train loss: 0.3369158293686661  Val loss: 0.3445469083654921
Epoch 151
-------------------------------
Batch 1/64 loss: 0.3336027264595032
Batch 2/64 loss: 0.33714258670806885
Batch 3/64 loss: 0.3431577682495117
Batch 4/64 loss: 0.3395899534225464
Batch 5/64 loss: 0.33833205699920654
Batch 6/64 loss: 0.3289189338684082
Batch 7/64 loss: 0.33432137966156006
Batch 8/64 loss: 0.3300741910934448
Batch 9/64 loss: 0.3384181261062622
Batch 10/64 loss: 0.3361032009124756
Batch 11/64 loss: 0.339225709438324
Batch 12/64 loss: 0.33463120460510254
Batch 13/64 loss: 0.33985793590545654
Batch 14/64 loss: 0.33601802587509155
Batch 15/64 loss: 0.33721762895584106
Batch 16/64 loss: 0.32617199420928955
Batch 17/64 loss: 0.33492618799209595
Batch 18/64 loss: 0.33821606636047363
Batch 19/64 loss: 0.3354325294494629
Batch 20/64 loss: 0.33345961570739746
Batch 21/64 loss: 0.3334304690361023
Batch 22/64 loss: 0.34146106243133545
Batch 23/64 loss: 0.3333475589752197
Batch 24/64 loss: 0.3388296365737915
Batch 25/64 loss: 0.33829861879348755
Batch 26/64 loss: 0.3419307470321655
Batch 27/64 loss: 0.331187903881073
Batch 28/64 loss: 0.33890819549560547
Batch 29/64 loss: 0.33982324600219727
Batch 30/64 loss: 0.33887094259262085
Batch 31/64 loss: 0.33830952644348145
Batch 32/64 loss: 0.3398626446723938
Batch 33/64 loss: 0.3391570448875427
Batch 34/64 loss: 0.3360142111778259
Batch 35/64 loss: 0.3376729488372803
Batch 36/64 loss: 0.3320136070251465
Batch 37/64 loss: 0.3373757600784302
Batch 38/64 loss: 0.3349009156227112
Batch 39/64 loss: 0.3380330801010132
Batch 40/64 loss: 0.34037506580352783
Batch 41/64 loss: 0.33646708726882935
Batch 42/64 loss: 0.3353400230407715
Batch 43/64 loss: 0.33510279655456543
Batch 44/64 loss: 0.3348997235298157
Batch 45/64 loss: 0.3331851363182068
Batch 46/64 loss: 0.335371196269989
Batch 47/64 loss: 0.33697354793548584
Batch 48/64 loss: 0.3363480567932129
Batch 49/64 loss: 0.33414173126220703
Batch 50/64 loss: 0.3332395553588867
Batch 51/64 loss: 0.3386099338531494
Batch 52/64 loss: 0.3383386731147766
Batch 53/64 loss: 0.34385257959365845
Batch 54/64 loss: 0.335491418838501
Batch 55/64 loss: 0.3396499752998352
Batch 56/64 loss: 0.3365004062652588
Batch 57/64 loss: 0.33255040645599365
Batch 58/64 loss: 0.34108924865722656
Batch 59/64 loss: 0.3405721187591553
Batch 60/64 loss: 0.3365747332572937
Batch 61/64 loss: 0.34047138690948486
Batch 62/64 loss: 0.33578765392303467
Batch 63/64 loss: 0.3401676416397095
Batch 64/64 loss: 0.34080588817596436
Epoch 151  Train loss: 0.3367992228152705  Val loss: 0.34528088467227636
Epoch 152
-------------------------------
Batch 1/64 loss: 0.33600354194641113
Batch 2/64 loss: 0.33942699432373047
Batch 3/64 loss: 0.33871281147003174
Batch 4/64 loss: 0.3371105194091797
Batch 5/64 loss: 0.3335857391357422
Batch 6/64 loss: 0.3390389680862427
Batch 7/64 loss: 0.3384994864463806
Batch 8/64 loss: 0.33745455741882324
Batch 9/64 loss: 0.3390783667564392
Batch 10/64 loss: 0.3384566307067871
Batch 11/64 loss: 0.33943289518356323
Batch 12/64 loss: 0.3365910053253174
Batch 13/64 loss: 0.3355104923248291
Batch 14/64 loss: 0.3329629898071289
Batch 15/64 loss: 0.32932496070861816
Batch 16/64 loss: 0.33649277687072754
Batch 17/64 loss: 0.3307020664215088
Batch 18/64 loss: 0.33535438776016235
Batch 19/64 loss: 0.3350546956062317
Batch 20/64 loss: 0.3383439779281616
Batch 21/64 loss: 0.3373461365699768
Batch 22/64 loss: 0.33948689699172974
Batch 23/64 loss: 0.3350299596786499
Batch 24/64 loss: 0.33889687061309814
Batch 25/64 loss: 0.33728301525115967
Batch 26/64 loss: 0.3378582000732422
Batch 27/64 loss: 0.3409711718559265
Batch 28/64 loss: 0.3361467123031616
Batch 29/64 loss: 0.33484023809432983
Batch 30/64 loss: 0.33766305446624756
Batch 31/64 loss: 0.3315321207046509
Batch 32/64 loss: 0.3353327512741089
Batch 33/64 loss: 0.3367037773132324
Batch 34/64 loss: 0.3370637893676758
Batch 35/64 loss: 0.33983057737350464
Batch 36/64 loss: 0.3343657851219177
Batch 37/64 loss: 0.33717113733291626
Batch 38/64 loss: 0.33966803550720215
Batch 39/64 loss: 0.3380509614944458
Batch 40/64 loss: 0.336755633354187
Batch 41/64 loss: 0.3329397439956665
Batch 42/64 loss: 0.3350898027420044
Batch 43/64 loss: 0.3311913013458252
Batch 44/64 loss: 0.3359759449958801
Batch 45/64 loss: 0.3408912420272827
Batch 46/64 loss: 0.3389848470687866
Batch 47/64 loss: 0.33376801013946533
Batch 48/64 loss: 0.33813297748565674
Batch 49/64 loss: 0.34125369787216187
Batch 50/64 loss: 0.33415210247039795
Batch 51/64 loss: 0.3430354595184326
Batch 52/64 loss: 0.3364921808242798
Batch 53/64 loss: 0.34123438596725464
Batch 54/64 loss: 0.33333301544189453
Batch 55/64 loss: 0.34369003772735596
Batch 56/64 loss: 0.3338022232055664
Batch 57/64 loss: 0.3353961706161499
Batch 58/64 loss: 0.3339272737503052
Batch 59/64 loss: 0.33317941427230835
Batch 60/64 loss: 0.3327011466026306
Batch 61/64 loss: 0.3360811471939087
Batch 62/64 loss: 0.3301910161972046
Batch 63/64 loss: 0.3368282914161682
Batch 64/64 loss: 0.3392064571380615
Epoch 152  Train loss: 0.3365617406134512  Val loss: 0.34492933258567887
Epoch 153
-------------------------------
Batch 1/64 loss: 0.330918550491333
Batch 2/64 loss: 0.33051949739456177
Batch 3/64 loss: 0.3374300003051758
Batch 4/64 loss: 0.3402523994445801
Batch 5/64 loss: 0.33191919326782227
Batch 6/64 loss: 0.3387298583984375
Batch 7/64 loss: 0.33733606338500977
Batch 8/64 loss: 0.3427605628967285
Batch 9/64 loss: 0.3372202515602112
Batch 10/64 loss: 0.3332917094230652
Batch 11/64 loss: 0.3406103849411011
Batch 12/64 loss: 0.33798718452453613
Batch 13/64 loss: 0.33841174840927124
Batch 14/64 loss: 0.33056020736694336
Batch 15/64 loss: 0.3335866332054138
Batch 16/64 loss: 0.3333877921104431
Batch 17/64 loss: 0.33968985080718994
Batch 18/64 loss: 0.33667999505996704
Batch 19/64 loss: 0.3327585458755493
Batch 20/64 loss: 0.33466577529907227
Batch 21/64 loss: 0.3325287103652954
Batch 22/64 loss: 0.3343846797943115
Batch 23/64 loss: 0.333290159702301
Batch 24/64 loss: 0.33699971437454224
Batch 25/64 loss: 0.3392982482910156
Batch 26/64 loss: 0.33044230937957764
Batch 27/64 loss: 0.33409786224365234
Batch 28/64 loss: 0.338171124458313
Batch 29/64 loss: 0.33432137966156006
Batch 30/64 loss: 0.33422422409057617
Batch 31/64 loss: 0.3342587351799011
Batch 32/64 loss: 0.3404122591018677
Batch 33/64 loss: 0.33682781457901
Batch 34/64 loss: 0.34168291091918945
Batch 35/64 loss: 0.3398209810256958
Batch 36/64 loss: 0.33460497856140137
Batch 37/64 loss: 0.33658266067504883
Batch 38/64 loss: 0.3302919864654541
Batch 39/64 loss: 0.3367009162902832
Batch 40/64 loss: 0.3362962007522583
Batch 41/64 loss: 0.3302537202835083
Batch 42/64 loss: 0.3381849527359009
Batch 43/64 loss: 0.3331223726272583
Batch 44/64 loss: 0.33905911445617676
Batch 45/64 loss: 0.3429849147796631
Batch 46/64 loss: 0.33065736293792725
Batch 47/64 loss: 0.33435291051864624
Batch 48/64 loss: 0.33976030349731445
Batch 49/64 loss: 0.33411020040512085
Batch 50/64 loss: 0.335279643535614
Batch 51/64 loss: 0.3408629894256592
Batch 52/64 loss: 0.33581483364105225
Batch 53/64 loss: 0.33766651153564453
Batch 54/64 loss: 0.3361389636993408
Batch 55/64 loss: 0.3368549346923828
Batch 56/64 loss: 0.3376989960670471
Batch 57/64 loss: 0.33618080615997314
Batch 58/64 loss: 0.3360710144042969
Batch 59/64 loss: 0.33903682231903076
Batch 60/64 loss: 0.3381127715110779
Batch 61/64 loss: 0.33321845531463623
Batch 62/64 loss: 0.33483415842056274
Batch 63/64 loss: 0.33345746994018555
Batch 64/64 loss: 0.33553171157836914
Epoch 153  Train loss: 0.3359892873203053  Val loss: 0.34409517951028046
Saving best model, epoch: 153
Epoch 154
-------------------------------
Batch 1/64 loss: 0.33631235361099243
Batch 2/64 loss: 0.343397855758667
Batch 3/64 loss: 0.3363630771636963
Batch 4/64 loss: 0.3365612030029297
Batch 5/64 loss: 0.33240532875061035
Batch 6/64 loss: 0.3362849950790405
Batch 7/64 loss: 0.33668458461761475
Batch 8/64 loss: 0.33167004585266113
Batch 9/64 loss: 0.33542299270629883
Batch 10/64 loss: 0.34155040979385376
Batch 11/64 loss: 0.3336632251739502
Batch 12/64 loss: 0.33873891830444336
Batch 13/64 loss: 0.33369505405426025
Batch 14/64 loss: 0.3392655849456787
Batch 15/64 loss: 0.33109354972839355
Batch 16/64 loss: 0.33505964279174805
Batch 17/64 loss: 0.3361635208129883
Batch 18/64 loss: 0.3340393304824829
Batch 19/64 loss: 0.33076369762420654
Batch 20/64 loss: 0.33631688356399536
Batch 21/64 loss: 0.3386918306350708
Batch 22/64 loss: 0.3348351716995239
Batch 23/64 loss: 0.3403390645980835
Batch 24/64 loss: 0.33475375175476074
Batch 25/64 loss: 0.335523784160614
Batch 26/64 loss: 0.3429974913597107
Batch 27/64 loss: 0.32929885387420654
Batch 28/64 loss: 0.33786261081695557
Batch 29/64 loss: 0.3362031579017639
Batch 30/64 loss: 0.3392898440361023
Batch 31/64 loss: 0.3350750207901001
Batch 32/64 loss: 0.33894068002700806
Batch 33/64 loss: 0.3349032998085022
Batch 34/64 loss: 0.33671581745147705
Batch 35/64 loss: 0.33645081520080566
Batch 36/64 loss: 0.33496350049972534
Batch 37/64 loss: 0.33451932668685913
Batch 38/64 loss: 0.3325214385986328
Batch 39/64 loss: 0.3324934244155884
Batch 40/64 loss: 0.34010422229766846
Batch 41/64 loss: 0.33829784393310547
Batch 42/64 loss: 0.33423852920532227
Batch 43/64 loss: 0.33843284845352173
Batch 44/64 loss: 0.3421022891998291
Batch 45/64 loss: 0.3353077173233032
Batch 46/64 loss: 0.33421504497528076
Batch 47/64 loss: 0.3312647342681885
Batch 48/64 loss: 0.337749719619751
Batch 49/64 loss: 0.33397603034973145
Batch 50/64 loss: 0.3385138511657715
Batch 51/64 loss: 0.337398886680603
Batch 52/64 loss: 0.33895331621170044
Batch 53/64 loss: 0.3369535803794861
Batch 54/64 loss: 0.3331056833267212
Batch 55/64 loss: 0.3364056348800659
Batch 56/64 loss: 0.33267152309417725
Batch 57/64 loss: 0.33930087089538574
Batch 58/64 loss: 0.3345041871070862
Batch 59/64 loss: 0.33837831020355225
Batch 60/64 loss: 0.33854424953460693
Batch 61/64 loss: 0.3303665518760681
Batch 62/64 loss: 0.3396605849266052
Batch 63/64 loss: 0.3378187417984009
Batch 64/64 loss: 0.339699923992157
Epoch 154  Train loss: 0.3362332711032793  Val loss: 0.3452568793624537
Epoch 155
-------------------------------
Batch 1/64 loss: 0.33608460426330566
Batch 2/64 loss: 0.3286035656929016
Batch 3/64 loss: 0.33524560928344727
Batch 4/64 loss: 0.3380504846572876
Batch 5/64 loss: 0.3360123634338379
Batch 6/64 loss: 0.336525559425354
Batch 7/64 loss: 0.33852171897888184
Batch 8/64 loss: 0.32941925525665283
Batch 9/64 loss: 0.33800792694091797
Batch 10/64 loss: 0.33297187089920044
Batch 11/64 loss: 0.33508551120758057
Batch 12/64 loss: 0.3349565267562866
Batch 13/64 loss: 0.338586688041687
Batch 14/64 loss: 0.33565330505371094
Batch 15/64 loss: 0.3367108106613159
Batch 16/64 loss: 0.33480948209762573
Batch 17/64 loss: 0.33560454845428467
Batch 18/64 loss: 0.3412741422653198
Batch 19/64 loss: 0.33589375019073486
Batch 20/64 loss: 0.3382379412651062
Batch 21/64 loss: 0.337846577167511
Batch 22/64 loss: 0.33360230922698975
Batch 23/64 loss: 0.33535486459732056
Batch 24/64 loss: 0.33719050884246826
Batch 25/64 loss: 0.33613866567611694
Batch 26/64 loss: 0.33539915084838867
Batch 27/64 loss: 0.3332187533378601
Batch 28/64 loss: 0.3401702642440796
Batch 29/64 loss: 0.33601343631744385
Batch 30/64 loss: 0.33004307746887207
Batch 31/64 loss: 0.3351873755455017
Batch 32/64 loss: 0.33554261922836304
Batch 33/64 loss: 0.3322564363479614
Batch 34/64 loss: 0.3352605700492859
Batch 35/64 loss: 0.3355790376663208
Batch 36/64 loss: 0.3387475609779358
Batch 37/64 loss: 0.33424484729766846
Batch 38/64 loss: 0.33458709716796875
Batch 39/64 loss: 0.33926570415496826
Batch 40/64 loss: 0.3313315510749817
Batch 41/64 loss: 0.331742525100708
Batch 42/64 loss: 0.3385544419288635
Batch 43/64 loss: 0.33695733547210693
Batch 44/64 loss: 0.33354008197784424
Batch 45/64 loss: 0.33746224641799927
Batch 46/64 loss: 0.33319151401519775
Batch 47/64 loss: 0.3369091749191284
Batch 48/64 loss: 0.3371758460998535
Batch 49/64 loss: 0.34081411361694336
Batch 50/64 loss: 0.33372974395751953
Batch 51/64 loss: 0.33302539587020874
Batch 52/64 loss: 0.3385704755783081
Batch 53/64 loss: 0.34000563621520996
Batch 54/64 loss: 0.33644556999206543
Batch 55/64 loss: 0.3389824628829956
Batch 56/64 loss: 0.3329482078552246
Batch 57/64 loss: 0.33754801750183105
Batch 58/64 loss: 0.33886003494262695
Batch 59/64 loss: 0.3364899158477783
Batch 60/64 loss: 0.3360498547554016
Batch 61/64 loss: 0.33610522747039795
Batch 62/64 loss: 0.333573579788208
Batch 63/64 loss: 0.3401668071746826
Batch 64/64 loss: 0.3399996757507324
Epoch 155  Train loss: 0.3359542594236486  Val loss: 0.34448754848893154
Epoch 156
-------------------------------
Batch 1/64 loss: 0.33651161193847656
Batch 2/64 loss: 0.3369351625442505
Batch 3/64 loss: 0.33614158630371094
Batch 4/64 loss: 0.334991455078125
Batch 5/64 loss: 0.3396862745285034
Batch 6/64 loss: 0.34009164571762085
Batch 7/64 loss: 0.33395951986312866
Batch 8/64 loss: 0.3368293046951294
Batch 9/64 loss: 0.33462631702423096
Batch 10/64 loss: 0.3318849205970764
Batch 11/64 loss: 0.33540356159210205
Batch 12/64 loss: 0.3339316248893738
Batch 13/64 loss: 0.33921968936920166
Batch 14/64 loss: 0.3302597999572754
Batch 15/64 loss: 0.33740222454071045
Batch 16/64 loss: 0.33280324935913086
Batch 17/64 loss: 0.3344736099243164
Batch 18/64 loss: 0.33257484436035156
Batch 19/64 loss: 0.3363546133041382
Batch 20/64 loss: 0.3350629210472107
Batch 21/64 loss: 0.33556830883026123
Batch 22/64 loss: 0.3438858985900879
Batch 23/64 loss: 0.33154916763305664
Batch 24/64 loss: 0.3322690725326538
Batch 25/64 loss: 0.3384459614753723
Batch 26/64 loss: 0.3396773338317871
Batch 27/64 loss: 0.3372321128845215
Batch 28/64 loss: 0.33905845880508423
Batch 29/64 loss: 0.3398170471191406
Batch 30/64 loss: 0.3335970640182495
Batch 31/64 loss: 0.3333733081817627
Batch 32/64 loss: 0.3327127695083618
Batch 33/64 loss: 0.33238017559051514
Batch 34/64 loss: 0.34090757369995117
Batch 35/64 loss: 0.3428342938423157
Batch 36/64 loss: 0.33128821849823
Batch 37/64 loss: 0.3352952003479004
Batch 38/64 loss: 0.3348967432975769
Batch 39/64 loss: 0.33189451694488525
Batch 40/64 loss: 0.334298312664032
Batch 41/64 loss: 0.3334275484085083
Batch 42/64 loss: 0.33923542499542236
Batch 43/64 loss: 0.33198702335357666
Batch 44/64 loss: 0.3389087915420532
Batch 45/64 loss: 0.33695757389068604
Batch 46/64 loss: 0.3353898525238037
Batch 47/64 loss: 0.33704304695129395
Batch 48/64 loss: 0.3397201895713806
Batch 49/64 loss: 0.33370500802993774
Batch 50/64 loss: 0.33731192350387573
Batch 51/64 loss: 0.3321537971496582
Batch 52/64 loss: 0.3336203098297119
Batch 53/64 loss: 0.34096843004226685
Batch 54/64 loss: 0.336029052734375
Batch 55/64 loss: 0.332866907119751
Batch 56/64 loss: 0.33566051721572876
Batch 57/64 loss: 0.3378426432609558
Batch 58/64 loss: 0.3316081762313843
Batch 59/64 loss: 0.33918309211730957
Batch 60/64 loss: 0.33588844537734985
Batch 61/64 loss: 0.3406258821487427
Batch 62/64 loss: 0.32826924324035645
Batch 63/64 loss: 0.3334953188896179
Batch 64/64 loss: 0.33337974548339844
Epoch 156  Train loss: 0.33571856442619774  Val loss: 0.3435686122101197
Saving best model, epoch: 156
Epoch 157
-------------------------------
Batch 1/64 loss: 0.3371269702911377
Batch 2/64 loss: 0.33947253227233887
Batch 3/64 loss: 0.33690065145492554
Batch 4/64 loss: 0.3335599899291992
Batch 5/64 loss: 0.33181893825531006
Batch 6/64 loss: 0.3441505432128906
Batch 7/64 loss: 0.33783507347106934
Batch 8/64 loss: 0.33365482091903687
Batch 9/64 loss: 0.32758212089538574
Batch 10/64 loss: 0.33378762006759644
Batch 11/64 loss: 0.33597368001937866
Batch 12/64 loss: 0.3305739164352417
Batch 13/64 loss: 0.34037888050079346
Batch 14/64 loss: 0.33089184761047363
Batch 15/64 loss: 0.3343702554702759
Batch 16/64 loss: 0.32924675941467285
Batch 17/64 loss: 0.3357490301132202
Batch 18/64 loss: 0.33622539043426514
Batch 19/64 loss: 0.3316124677658081
Batch 20/64 loss: 0.34011685848236084
Batch 21/64 loss: 0.3384225368499756
Batch 22/64 loss: 0.33901548385620117
Batch 23/64 loss: 0.3379021883010864
Batch 24/64 loss: 0.33549565076828003
Batch 25/64 loss: 0.33414191007614136
Batch 26/64 loss: 0.34133756160736084
Batch 27/64 loss: 0.3395974040031433
Batch 28/64 loss: 0.33122891187667847
Batch 29/64 loss: 0.3355606198310852
Batch 30/64 loss: 0.33880865573883057
Batch 31/64 loss: 0.33217209577560425
Batch 32/64 loss: 0.33682894706726074
Batch 33/64 loss: 0.336320161819458
Batch 34/64 loss: 0.3312082886695862
Batch 35/64 loss: 0.3358588218688965
Batch 36/64 loss: 0.3338789939880371
Batch 37/64 loss: 0.3347954750061035
Batch 38/64 loss: 0.33488404750823975
Batch 39/64 loss: 0.3324524760246277
Batch 40/64 loss: 0.33585959672927856
Batch 41/64 loss: 0.337762713432312
Batch 42/64 loss: 0.3370041847229004
Batch 43/64 loss: 0.3404068946838379
Batch 44/64 loss: 0.332342267036438
Batch 45/64 loss: 0.33713865280151367
Batch 46/64 loss: 0.3398035764694214
Batch 47/64 loss: 0.3320862650871277
Batch 48/64 loss: 0.33879756927490234
Batch 49/64 loss: 0.3326683044433594
Batch 50/64 loss: 0.3407599925994873
Batch 51/64 loss: 0.33764469623565674
Batch 52/64 loss: 0.33222299814224243
Batch 53/64 loss: 0.3377394676208496
Batch 54/64 loss: 0.33982348442077637
Batch 55/64 loss: 0.33026909828186035
Batch 56/64 loss: 0.330971360206604
Batch 57/64 loss: 0.33088159561157227
Batch 58/64 loss: 0.33360254764556885
Batch 59/64 loss: 0.3325706124305725
Batch 60/64 loss: 0.3372226357460022
Batch 61/64 loss: 0.3299661874771118
Batch 62/64 loss: 0.3325057029724121
Batch 63/64 loss: 0.3320509195327759
Batch 64/64 loss: 0.3405523896217346
Epoch 157  Train loss: 0.3353483010740841  Val loss: 0.3430723498777016
Saving best model, epoch: 157
Epoch 158
-------------------------------
Batch 1/64 loss: 0.34020859003067017
Batch 2/64 loss: 0.3383275866508484
Batch 3/64 loss: 0.332527756690979
Batch 4/64 loss: 0.33197951316833496
Batch 5/64 loss: 0.3308776021003723
Batch 6/64 loss: 0.33325690031051636
Batch 7/64 loss: 0.3455616235733032
Batch 8/64 loss: 0.3330662250518799
Batch 9/64 loss: 0.3379417657852173
Batch 10/64 loss: 0.33227312564849854
Batch 11/64 loss: 0.33637332916259766
Batch 12/64 loss: 0.3351808786392212
Batch 13/64 loss: 0.33486080169677734
Batch 14/64 loss: 0.33186447620391846
Batch 15/64 loss: 0.3269233703613281
Batch 16/64 loss: 0.3386162519454956
Batch 17/64 loss: 0.3297464847564697
Batch 18/64 loss: 0.3369683027267456
Batch 19/64 loss: 0.3323090076446533
Batch 20/64 loss: 0.3336954712867737
Batch 21/64 loss: 0.33398163318634033
Batch 22/64 loss: 0.3316107988357544
Batch 23/64 loss: 0.33614397048950195
Batch 24/64 loss: 0.33402585983276367
Batch 25/64 loss: 0.33631670475006104
Batch 26/64 loss: 0.3377242684364319
Batch 27/64 loss: 0.33796167373657227
Batch 28/64 loss: 0.3307487368583679
Batch 29/64 loss: 0.3379470109939575
Batch 30/64 loss: 0.33668994903564453
Batch 31/64 loss: 0.3315895199775696
Batch 32/64 loss: 0.3378869891166687
Batch 33/64 loss: 0.33661317825317383
Batch 34/64 loss: 0.3297555446624756
Batch 35/64 loss: 0.33066415786743164
Batch 36/64 loss: 0.33204931020736694
Batch 37/64 loss: 0.33348995447158813
Batch 38/64 loss: 0.33762598037719727
Batch 39/64 loss: 0.3342403173446655
Batch 40/64 loss: 0.3326110243797302
Batch 41/64 loss: 0.3376634120941162
Batch 42/64 loss: 0.33996403217315674
Batch 43/64 loss: 0.3350340723991394
Batch 44/64 loss: 0.33956629037857056
Batch 45/64 loss: 0.32991981506347656
Batch 46/64 loss: 0.33438462018966675
Batch 47/64 loss: 0.3292763829231262
Batch 48/64 loss: 0.3340919017791748
Batch 49/64 loss: 0.3407479524612427
Batch 50/64 loss: 0.3334183096885681
Batch 51/64 loss: 0.33365023136138916
Batch 52/64 loss: 0.34234780073165894
Batch 53/64 loss: 0.335040807723999
Batch 54/64 loss: 0.3351653814315796
Batch 55/64 loss: 0.33263498544692993
Batch 56/64 loss: 0.33487337827682495
Batch 57/64 loss: 0.3331797122955322
Batch 58/64 loss: 0.33671772480010986
Batch 59/64 loss: 0.3414093255996704
Batch 60/64 loss: 0.34102946519851685
Batch 61/64 loss: 0.3351716995239258
Batch 62/64 loss: 0.3340303897857666
Batch 63/64 loss: 0.3354334235191345
Batch 64/64 loss: 0.33244311809539795
Epoch 158  Train loss: 0.33500108391630884  Val loss: 0.3434872172542454
Epoch 159
-------------------------------
Batch 1/64 loss: 0.3389444351196289
Batch 2/64 loss: 0.3306543231010437
Batch 3/64 loss: 0.3338526487350464
Batch 4/64 loss: 0.33327627182006836
Batch 5/64 loss: 0.34111714363098145
Batch 6/64 loss: 0.33762919902801514
Batch 7/64 loss: 0.32953375577926636
Batch 8/64 loss: 0.3331705927848816
Batch 9/64 loss: 0.33561813831329346
Batch 10/64 loss: 0.3381839394569397
Batch 11/64 loss: 0.3373197913169861
Batch 12/64 loss: 0.34024298191070557
Batch 13/64 loss: 0.3358050584793091
Batch 14/64 loss: 0.3354763984680176
Batch 15/64 loss: 0.3350992202758789
Batch 16/64 loss: 0.3306872844696045
Batch 17/64 loss: 0.3375680446624756
Batch 18/64 loss: 0.33344602584838867
Batch 19/64 loss: 0.33491694927215576
Batch 20/64 loss: 0.331457257270813
Batch 21/64 loss: 0.32973212003707886
Batch 22/64 loss: 0.3346925377845764
Batch 23/64 loss: 0.3332599401473999
Batch 24/64 loss: 0.3349270820617676
Batch 25/64 loss: 0.3332972526550293
Batch 26/64 loss: 0.3287947177886963
Batch 27/64 loss: 0.3309471011161804
Batch 28/64 loss: 0.3366774320602417
Batch 29/64 loss: 0.33476096391677856
Batch 30/64 loss: 0.33268052339553833
Batch 31/64 loss: 0.3331354856491089
Batch 32/64 loss: 0.3358898162841797
Batch 33/64 loss: 0.3368089199066162
Batch 34/64 loss: 0.3397374153137207
Batch 35/64 loss: 0.33247196674346924
Batch 36/64 loss: 0.33607757091522217
Batch 37/64 loss: 0.33144843578338623
Batch 38/64 loss: 0.3346385955810547
Batch 39/64 loss: 0.33667421340942383
Batch 40/64 loss: 0.33220362663269043
Batch 41/64 loss: 0.3410748243331909
Batch 42/64 loss: 0.3381575345993042
Batch 43/64 loss: 0.33803391456604004
Batch 44/64 loss: 0.3351860046386719
Batch 45/64 loss: 0.3395242691040039
Batch 46/64 loss: 0.3306245803833008
Batch 47/64 loss: 0.33364659547805786
Batch 48/64 loss: 0.33324921131134033
Batch 49/64 loss: 0.3351867198944092
Batch 50/64 loss: 0.3347962498664856
Batch 51/64 loss: 0.3350621461868286
Batch 52/64 loss: 0.3283959627151489
Batch 53/64 loss: 0.3401523232460022
Batch 54/64 loss: 0.33137577772140503
Batch 55/64 loss: 0.3346989154815674
Batch 56/64 loss: 0.34145039319992065
Batch 57/64 loss: 0.3347861170768738
Batch 58/64 loss: 0.331132709980011
Batch 59/64 loss: 0.3324495553970337
Batch 60/64 loss: 0.337782084941864
Batch 61/64 loss: 0.3396230936050415
Batch 62/64 loss: 0.3341735005378723
Batch 63/64 loss: 0.33574479818344116
Batch 64/64 loss: 0.33965039253234863
Epoch 159  Train loss: 0.33496314123565074  Val loss: 0.3439518893297595
Epoch 160
-------------------------------
Batch 1/64 loss: 0.3344684839248657
Batch 2/64 loss: 0.33657824993133545
Batch 3/64 loss: 0.3323262929916382
Batch 4/64 loss: 0.3354684114456177
Batch 5/64 loss: 0.3413412570953369
Batch 6/64 loss: 0.33173173666000366
Batch 7/64 loss: 0.33479952812194824
Batch 8/64 loss: 0.34505605697631836
Batch 9/64 loss: 0.33080852031707764
Batch 10/64 loss: 0.33499789237976074
Batch 11/64 loss: 0.33816492557525635
Batch 12/64 loss: 0.3306165337562561
Batch 13/64 loss: 0.3380483388900757
Batch 14/64 loss: 0.330330491065979
Batch 15/64 loss: 0.3352550268173218
Batch 16/64 loss: 0.33538269996643066
Batch 17/64 loss: 0.3346843719482422
Batch 18/64 loss: 0.33024120330810547
Batch 19/64 loss: 0.3364902138710022
Batch 20/64 loss: 0.3380470275878906
Batch 21/64 loss: 0.33328789472579956
Batch 22/64 loss: 0.3339015245437622
Batch 23/64 loss: 0.33497703075408936
Batch 24/64 loss: 0.3343779444694519
Batch 25/64 loss: 0.3325622081756592
Batch 26/64 loss: 0.335010290145874
Batch 27/64 loss: 0.33645159006118774
Batch 28/64 loss: 0.3326449990272522
Batch 29/64 loss: 0.33483779430389404
Batch 30/64 loss: 0.33544647693634033
Batch 31/64 loss: 0.3317779302597046
Batch 32/64 loss: 0.33963096141815186
Batch 33/64 loss: 0.33582979440689087
Batch 34/64 loss: 0.33546388149261475
Batch 35/64 loss: 0.339213490486145
Batch 36/64 loss: 0.3357425928115845
Batch 37/64 loss: 0.33268630504608154
Batch 38/64 loss: 0.3297041058540344
Batch 39/64 loss: 0.33118492364883423
Batch 40/64 loss: 0.3344498872756958
Batch 41/64 loss: 0.3364619016647339
Batch 42/64 loss: 0.3330869674682617
Batch 43/64 loss: 0.3315671682357788
Batch 44/64 loss: 0.32967859506607056
Batch 45/64 loss: 0.33915388584136963
Batch 46/64 loss: 0.3314380645751953
Batch 47/64 loss: 0.33400362730026245
Batch 48/64 loss: 0.33231908082962036
Batch 49/64 loss: 0.33995282649993896
Batch 50/64 loss: 0.3366285562515259
Batch 51/64 loss: 0.3356545567512512
Batch 52/64 loss: 0.3392249345779419
Batch 53/64 loss: 0.33232760429382324
Batch 54/64 loss: 0.33502423763275146
Batch 55/64 loss: 0.33574920892715454
Batch 56/64 loss: 0.3357700705528259
Batch 57/64 loss: 0.3365797996520996
Batch 58/64 loss: 0.33648622035980225
Batch 59/64 loss: 0.3345481753349304
Batch 60/64 loss: 0.3363197445869446
Batch 61/64 loss: 0.3352471590042114
Batch 62/64 loss: 0.3319512605667114
Batch 63/64 loss: 0.33185040950775146
Batch 64/64 loss: 0.33318501710891724
Epoch 160  Train loss: 0.3348224581456652  Val loss: 0.3441959228302605
Epoch 161
-------------------------------
Batch 1/64 loss: 0.3436669111251831
Batch 2/64 loss: 0.34106916189193726
Batch 3/64 loss: 0.340671181678772
Batch 4/64 loss: 0.33323895931243896
Batch 5/64 loss: 0.3344383239746094
Batch 6/64 loss: 0.33210253715515137
Batch 7/64 loss: 0.33998340368270874
Batch 8/64 loss: 0.3322036862373352
Batch 9/64 loss: 0.33185213804244995
Batch 10/64 loss: 0.32966554164886475
Batch 11/64 loss: 0.33443212509155273
Batch 12/64 loss: 0.339189350605011
Batch 13/64 loss: 0.33613908290863037
Batch 14/64 loss: 0.342238187789917
Batch 15/64 loss: 0.33874404430389404
Batch 16/64 loss: 0.3325899839401245
Batch 17/64 loss: 0.3335542678833008
Batch 18/64 loss: 0.3276982307434082
Batch 19/64 loss: 0.33251094818115234
Batch 20/64 loss: 0.3282792568206787
Batch 21/64 loss: 0.3372718095779419
Batch 22/64 loss: 0.3275735378265381
Batch 23/64 loss: 0.33358895778656006
Batch 24/64 loss: 0.3346797823905945
Batch 25/64 loss: 0.3367452025413513
Batch 26/64 loss: 0.33398282527923584
Batch 27/64 loss: 0.33175283670425415
Batch 28/64 loss: 0.3351709842681885
Batch 29/64 loss: 0.3328598141670227
Batch 30/64 loss: 0.33830004930496216
Batch 31/64 loss: 0.32878780364990234
Batch 32/64 loss: 0.3387431502342224
Batch 33/64 loss: 0.3339608907699585
Batch 34/64 loss: 0.3349626064300537
Batch 35/64 loss: 0.33350443840026855
Batch 36/64 loss: 0.3303709030151367
Batch 37/64 loss: 0.33438026905059814
Batch 38/64 loss: 0.3335082530975342
Batch 39/64 loss: 0.33800041675567627
Batch 40/64 loss: 0.3341236114501953
Batch 41/64 loss: 0.3360205888748169
Batch 42/64 loss: 0.3343607187271118
Batch 43/64 loss: 0.33602404594421387
Batch 44/64 loss: 0.3365745544433594
Batch 45/64 loss: 0.3370962142944336
Batch 46/64 loss: 0.3305017948150635
Batch 47/64 loss: 0.33240246772766113
Batch 48/64 loss: 0.3345146179199219
Batch 49/64 loss: 0.33606064319610596
Batch 50/64 loss: 0.33005428314208984
Batch 51/64 loss: 0.33489835262298584
Batch 52/64 loss: 0.33523106575012207
Batch 53/64 loss: 0.33612585067749023
Batch 54/64 loss: 0.32760244607925415
Batch 55/64 loss: 0.3367804288864136
Batch 56/64 loss: 0.3358268737792969
Batch 57/64 loss: 0.33606207370758057
Batch 58/64 loss: 0.3290441036224365
Batch 59/64 loss: 0.3369849920272827
Batch 60/64 loss: 0.3359931707382202
Batch 61/64 loss: 0.3369084596633911
Batch 62/64 loss: 0.34001582860946655
Batch 63/64 loss: 0.3309173583984375
Batch 64/64 loss: 0.3334026336669922
Epoch 161  Train loss: 0.3346288372488583  Val loss: 0.34328635533650714
Epoch 162
-------------------------------
Batch 1/64 loss: 0.32778722047805786
Batch 2/64 loss: 0.3269427418708801
Batch 3/64 loss: 0.327314555644989
Batch 4/64 loss: 0.3348351716995239
Batch 5/64 loss: 0.33377397060394287
Batch 6/64 loss: 0.32477521896362305
Batch 7/64 loss: 0.33436524868011475
Batch 8/64 loss: 0.3374415636062622
Batch 9/64 loss: 0.33773577213287354
Batch 10/64 loss: 0.3369366526603699
Batch 11/64 loss: 0.3357807397842407
Batch 12/64 loss: 0.33397185802459717
Batch 13/64 loss: 0.3395981788635254
Batch 14/64 loss: 0.33844953775405884
Batch 15/64 loss: 0.3321026563644409
Batch 16/64 loss: 0.3330729007720947
Batch 17/64 loss: 0.3343425989151001
Batch 18/64 loss: 0.3319307565689087
Batch 19/64 loss: 0.334464967250824
Batch 20/64 loss: 0.3282816410064697
Batch 21/64 loss: 0.33511364459991455
Batch 22/64 loss: 0.3311358690261841
Batch 23/64 loss: 0.3348844051361084
Batch 24/64 loss: 0.33792877197265625
Batch 25/64 loss: 0.3376760482788086
Batch 26/64 loss: 0.33569371700286865
Batch 27/64 loss: 0.3378041982650757
Batch 28/64 loss: 0.3373692035675049
Batch 29/64 loss: 0.3327178955078125
Batch 30/64 loss: 0.33839190006256104
Batch 31/64 loss: 0.3312709331512451
Batch 32/64 loss: 0.33689481019973755
Batch 33/64 loss: 0.33188456296920776
Batch 34/64 loss: 0.3337389826774597
Batch 35/64 loss: 0.33304667472839355
Batch 36/64 loss: 0.34038078784942627
Batch 37/64 loss: 0.3336181640625
Batch 38/64 loss: 0.33350229263305664
Batch 39/64 loss: 0.33797717094421387
Batch 40/64 loss: 0.33456116914749146
Batch 41/64 loss: 0.33475935459136963
Batch 42/64 loss: 0.3330603241920471
Batch 43/64 loss: 0.33368629217147827
Batch 44/64 loss: 0.3378392457962036
Batch 45/64 loss: 0.33099496364593506
Batch 46/64 loss: 0.33985406160354614
Batch 47/64 loss: 0.33832281827926636
Batch 48/64 loss: 0.33228880167007446
Batch 49/64 loss: 0.3346695899963379
Batch 50/64 loss: 0.3389056921005249
Batch 51/64 loss: 0.33837586641311646
Batch 52/64 loss: 0.33458781242370605
Batch 53/64 loss: 0.33177435398101807
Batch 54/64 loss: 0.33612120151519775
Batch 55/64 loss: 0.3371749520301819
Batch 56/64 loss: 0.3338612914085388
Batch 57/64 loss: 0.33644068241119385
Batch 58/64 loss: 0.33867233991622925
Batch 59/64 loss: 0.33342796564102173
Batch 60/64 loss: 0.33204352855682373
Batch 61/64 loss: 0.33172011375427246
Batch 62/64 loss: 0.332991361618042
Batch 63/64 loss: 0.3389418125152588
Batch 64/64 loss: 0.3339604139328003
Epoch 162  Train loss: 0.334595762982088  Val loss: 0.3426360123345942
Saving best model, epoch: 162
Epoch 163
-------------------------------
Batch 1/64 loss: 0.3291780948638916
Batch 2/64 loss: 0.33603131771087646
Batch 3/64 loss: 0.3278375267982483
Batch 4/64 loss: 0.3384225368499756
Batch 5/64 loss: 0.3347667455673218
Batch 6/64 loss: 0.331301748752594
Batch 7/64 loss: 0.3385831117630005
Batch 8/64 loss: 0.3373507261276245
Batch 9/64 loss: 0.3368983268737793
Batch 10/64 loss: 0.3351271152496338
Batch 11/64 loss: 0.32983100414276123
Batch 12/64 loss: 0.3341742157936096
Batch 13/64 loss: 0.3360300064086914
Batch 14/64 loss: 0.336871862411499
Batch 15/64 loss: 0.338390588760376
Batch 16/64 loss: 0.3344705104827881
Batch 17/64 loss: 0.330663800239563
Batch 18/64 loss: 0.3391484022140503
Batch 19/64 loss: 0.33375662565231323
Batch 20/64 loss: 0.33214354515075684
Batch 21/64 loss: 0.330197811126709
Batch 22/64 loss: 0.3330564498901367
Batch 23/64 loss: 0.3372466564178467
Batch 24/64 loss: 0.33555883169174194
Batch 25/64 loss: 0.3302513360977173
Batch 26/64 loss: 0.33141177892684937
Batch 27/64 loss: 0.3304009437561035
Batch 28/64 loss: 0.33675479888916016
Batch 29/64 loss: 0.33388209342956543
Batch 30/64 loss: 0.3395118713378906
Batch 31/64 loss: 0.3340616226196289
Batch 32/64 loss: 0.33664989471435547
Batch 33/64 loss: 0.33466434478759766
Batch 34/64 loss: 0.33469158411026
Batch 35/64 loss: 0.33685147762298584
Batch 36/64 loss: 0.3424413204193115
Batch 37/64 loss: 0.3377980589866638
Batch 38/64 loss: 0.33724308013916016
Batch 39/64 loss: 0.32980847358703613
Batch 40/64 loss: 0.33716368675231934
Batch 41/64 loss: 0.33769041299819946
Batch 42/64 loss: 0.33262908458709717
Batch 43/64 loss: 0.33205652236938477
Batch 44/64 loss: 0.33315426111221313
Batch 45/64 loss: 0.33748674392700195
Batch 46/64 loss: 0.3351612091064453
Batch 47/64 loss: 0.3338465690612793
Batch 48/64 loss: 0.3367750644683838
Batch 49/64 loss: 0.3341652750968933
Batch 50/64 loss: 0.33786725997924805
Batch 51/64 loss: 0.3293052911758423
Batch 52/64 loss: 0.33596479892730713
Batch 53/64 loss: 0.3367656469345093
Batch 54/64 loss: 0.3354395031929016
Batch 55/64 loss: 0.33924317359924316
Batch 56/64 loss: 0.33369725942611694
Batch 57/64 loss: 0.33239179849624634
Batch 58/64 loss: 0.33084696531295776
Batch 59/64 loss: 0.33715909719467163
Batch 60/64 loss: 0.3352353572845459
Batch 61/64 loss: 0.33524537086486816
Batch 62/64 loss: 0.33585870265960693
Batch 63/64 loss: 0.33792412281036377
Batch 64/64 loss: 0.33115315437316895
Epoch 163  Train loss: 0.33482193385853487  Val loss: 0.34474929562958656
Epoch 164
-------------------------------
Batch 1/64 loss: 0.3309175968170166
Batch 2/64 loss: 0.33449119329452515
Batch 3/64 loss: 0.34751439094543457
Batch 4/64 loss: 0.33574461936950684
Batch 5/64 loss: 0.33249199390411377
Batch 6/64 loss: 0.33670687675476074
Batch 7/64 loss: 0.33816397190093994
Batch 8/64 loss: 0.33136314153671265
Batch 9/64 loss: 0.3357795476913452
Batch 10/64 loss: 0.3374362587928772
Batch 11/64 loss: 0.3350539207458496
Batch 12/64 loss: 0.3256884813308716
Batch 13/64 loss: 0.335534930229187
Batch 14/64 loss: 0.33337152004241943
Batch 15/64 loss: 0.33144962787628174
Batch 16/64 loss: 0.3312253952026367
Batch 17/64 loss: 0.3358652591705322
Batch 18/64 loss: 0.33188390731811523
Batch 19/64 loss: 0.33615970611572266
Batch 20/64 loss: 0.3304494619369507
Batch 21/64 loss: 0.33333563804626465
Batch 22/64 loss: 0.329004168510437
Batch 23/64 loss: 0.3399203419685364
Batch 24/64 loss: 0.32968008518218994
Batch 25/64 loss: 0.33612704277038574
Batch 26/64 loss: 0.335124135017395
Batch 27/64 loss: 0.3333747386932373
Batch 28/64 loss: 0.3359936475753784
Batch 29/64 loss: 0.3296046257019043
Batch 30/64 loss: 0.3313749432563782
Batch 31/64 loss: 0.3375290632247925
Batch 32/64 loss: 0.33214908838272095
Batch 33/64 loss: 0.33331263065338135
Batch 34/64 loss: 0.3332594633102417
Batch 35/64 loss: 0.33595991134643555
Batch 36/64 loss: 0.3398001194000244
Batch 37/64 loss: 0.3343796730041504
Batch 38/64 loss: 0.3346920609474182
Batch 39/64 loss: 0.3378564119338989
Batch 40/64 loss: 0.3351261019706726
Batch 41/64 loss: 0.3372265696525574
Batch 42/64 loss: 0.34095650911331177
Batch 43/64 loss: 0.3338965177536011
Batch 44/64 loss: 0.33197903633117676
Batch 45/64 loss: 0.33765721321105957
Batch 46/64 loss: 0.32920336723327637
Batch 47/64 loss: 0.3313800096511841
Batch 48/64 loss: 0.3281213045120239
Batch 49/64 loss: 0.3340983986854553
Batch 50/64 loss: 0.33715999126434326
Batch 51/64 loss: 0.33989065885543823
Batch 52/64 loss: 0.33696770668029785
Batch 53/64 loss: 0.33353984355926514
Batch 54/64 loss: 0.334997296333313
Batch 55/64 loss: 0.3347221612930298
Batch 56/64 loss: 0.33432137966156006
Batch 57/64 loss: 0.3304954767227173
Batch 58/64 loss: 0.32964175939559937
Batch 59/64 loss: 0.3376438617706299
Batch 60/64 loss: 0.3332637548446655
Batch 61/64 loss: 0.3295856714248657
Batch 62/64 loss: 0.33962464332580566
Batch 63/64 loss: 0.33445489406585693
Batch 64/64 loss: 0.3408956527709961
Epoch 164  Train loss: 0.33445326206730863  Val loss: 0.3427977520985292
Epoch 165
-------------------------------
Batch 1/64 loss: 0.3346201181411743
Batch 2/64 loss: 0.32987141609191895
Batch 3/64 loss: 0.33060431480407715
Batch 4/64 loss: 0.3385807275772095
Batch 5/64 loss: 0.3341137170791626
Batch 6/64 loss: 0.33840370178222656
Batch 7/64 loss: 0.3282686471939087
Batch 8/64 loss: 0.33364707231521606
Batch 9/64 loss: 0.33679890632629395
Batch 10/64 loss: 0.32709836959838867
Batch 11/64 loss: 0.3356359004974365
Batch 12/64 loss: 0.3379446268081665
Batch 13/64 loss: 0.3357253670692444
Batch 14/64 loss: 0.33788001537323
Batch 15/64 loss: 0.3393787145614624
Batch 16/64 loss: 0.3345189094543457
Batch 17/64 loss: 0.32947683334350586
Batch 18/64 loss: 0.3346090316772461
Batch 19/64 loss: 0.33151423931121826
Batch 20/64 loss: 0.3349043130874634
Batch 21/64 loss: 0.33771461248397827
Batch 22/64 loss: 0.3332563638687134
Batch 23/64 loss: 0.3349916934967041
Batch 24/64 loss: 0.33827149868011475
Batch 25/64 loss: 0.3372558355331421
Batch 26/64 loss: 0.33594971895217896
Batch 27/64 loss: 0.33187365531921387
Batch 28/64 loss: 0.32891708612442017
Batch 29/64 loss: 0.32584279775619507
Batch 30/64 loss: 0.3372727036476135
Batch 31/64 loss: 0.33966749906539917
Batch 32/64 loss: 0.3345552682876587
Batch 33/64 loss: 0.3355415463447571
Batch 34/64 loss: 0.33154571056365967
Batch 35/64 loss: 0.3320671319961548
Batch 36/64 loss: 0.3381999731063843
Batch 37/64 loss: 0.3340691924095154
Batch 38/64 loss: 0.33338308334350586
Batch 39/64 loss: 0.32953566312789917
Batch 40/64 loss: 0.32896316051483154
Batch 41/64 loss: 0.33704960346221924
Batch 42/64 loss: 0.3365768790245056
Batch 43/64 loss: 0.3319195508956909
Batch 44/64 loss: 0.33268189430236816
Batch 45/64 loss: 0.3282827138900757
Batch 46/64 loss: 0.3283344507217407
Batch 47/64 loss: 0.3394761085510254
Batch 48/64 loss: 0.3346827030181885
Batch 49/64 loss: 0.33250463008880615
Batch 50/64 loss: 0.33737850189208984
Batch 51/64 loss: 0.33702027797698975
Batch 52/64 loss: 0.33615201711654663
Batch 53/64 loss: 0.34218013286590576
Batch 54/64 loss: 0.332833468914032
Batch 55/64 loss: 0.3319358825683594
Batch 56/64 loss: 0.33554649353027344
Batch 57/64 loss: 0.3290807008743286
Batch 58/64 loss: 0.3340526223182678
Batch 59/64 loss: 0.3340975046157837
Batch 60/64 loss: 0.336686372756958
Batch 61/64 loss: 0.33252692222595215
Batch 62/64 loss: 0.3336533308029175
Batch 63/64 loss: 0.3336266279220581
Batch 64/64 loss: 0.3323262929916382
Epoch 165  Train loss: 0.3341175411261764  Val loss: 0.3432177370766184
Epoch 166
-------------------------------
Batch 1/64 loss: 0.33157455921173096
Batch 2/64 loss: 0.3373211622238159
Batch 3/64 loss: 0.33892345428466797
Batch 4/64 loss: 0.3308480381965637
Batch 5/64 loss: 0.3358039855957031
Batch 6/64 loss: 0.3373792767524719
Batch 7/64 loss: 0.33426493406295776
Batch 8/64 loss: 0.33283793926239014
Batch 9/64 loss: 0.33764219284057617
Batch 10/64 loss: 0.32460349798202515
Batch 11/64 loss: 0.33577191829681396
Batch 12/64 loss: 0.33386898040771484
Batch 13/64 loss: 0.33246535062789917
Batch 14/64 loss: 0.33327460289001465
Batch 15/64 loss: 0.3337957262992859
Batch 16/64 loss: 0.33226025104522705
Batch 17/64 loss: 0.33764469623565674
Batch 18/64 loss: 0.33792614936828613
Batch 19/64 loss: 0.33217668533325195
Batch 20/64 loss: 0.33367490768432617
Batch 21/64 loss: 0.336073637008667
Batch 22/64 loss: 0.33854156732559204
Batch 23/64 loss: 0.3365870714187622
Batch 24/64 loss: 0.33072948455810547
Batch 25/64 loss: 0.3388103246688843
Batch 26/64 loss: 0.3370903730392456
Batch 27/64 loss: 0.33677756786346436
Batch 28/64 loss: 0.3361448049545288
Batch 29/64 loss: 0.3360505700111389
Batch 30/64 loss: 0.3334416151046753
Batch 31/64 loss: 0.337699294090271
Batch 32/64 loss: 0.3312551975250244
Batch 33/64 loss: 0.33278965950012207
Batch 34/64 loss: 0.3405265808105469
Batch 35/64 loss: 0.33323848247528076
Batch 36/64 loss: 0.33082377910614014
Batch 37/64 loss: 0.3335791826248169
Batch 38/64 loss: 0.3345494270324707
Batch 39/64 loss: 0.33163362741470337
Batch 40/64 loss: 0.33140718936920166
Batch 41/64 loss: 0.325697660446167
Batch 42/64 loss: 0.3368576765060425
Batch 43/64 loss: 0.332533597946167
Batch 44/64 loss: 0.33680111169815063
Batch 45/64 loss: 0.33680689334869385
Batch 46/64 loss: 0.33150482177734375
Batch 47/64 loss: 0.3390411138534546
Batch 48/64 loss: 0.33115899562835693
Batch 49/64 loss: 0.33545058965682983
Batch 50/64 loss: 0.3304290175437927
Batch 51/64 loss: 0.32852602005004883
Batch 52/64 loss: 0.32808756828308105
Batch 53/64 loss: 0.3343623876571655
Batch 54/64 loss: 0.330660879611969
Batch 55/64 loss: 0.33145445585250854
Batch 56/64 loss: 0.328086256980896
Batch 57/64 loss: 0.33611029386520386
Batch 58/64 loss: 0.3296014666557312
Batch 59/64 loss: 0.33006930351257324
Batch 60/64 loss: 0.34233200550079346
Batch 61/64 loss: 0.3304870128631592
Batch 62/64 loss: 0.3320329189300537
Batch 63/64 loss: 0.3371608853340149
Batch 64/64 loss: 0.3311495780944824
Epoch 166  Train loss: 0.3338889860639385  Val loss: 0.34303507567271335
Epoch 167
-------------------------------
Batch 1/64 loss: 0.3421013355255127
Batch 2/64 loss: 0.3261932134628296
Batch 3/64 loss: 0.3295596241950989
Batch 4/64 loss: 0.32629942893981934
Batch 5/64 loss: 0.3261624574661255
Batch 6/64 loss: 0.3376613259315491
Batch 7/64 loss: 0.3332366347312927
Batch 8/64 loss: 0.3308148980140686
Batch 9/64 loss: 0.3308194875717163
Batch 10/64 loss: 0.33157557249069214
Batch 11/64 loss: 0.3322843909263611
Batch 12/64 loss: 0.33697783946990967
Batch 13/64 loss: 0.33636415004730225
Batch 14/64 loss: 0.33249545097351074
Batch 15/64 loss: 0.3373870849609375
Batch 16/64 loss: 0.3263453245162964
Batch 17/64 loss: 0.33774036169052124
Batch 18/64 loss: 0.33920276165008545
Batch 19/64 loss: 0.3361586332321167
Batch 20/64 loss: 0.33271825313568115
Batch 21/64 loss: 0.33763837814331055
Batch 22/64 loss: 0.33159905672073364
Batch 23/64 loss: 0.33675843477249146
Batch 24/64 loss: 0.3343244791030884
Batch 25/64 loss: 0.33593249320983887
Batch 26/64 loss: 0.3360939621925354
Batch 27/64 loss: 0.33239036798477173
Batch 28/64 loss: 0.33608096837997437
Batch 29/64 loss: 0.33280014991760254
Batch 30/64 loss: 0.33619624376296997
Batch 31/64 loss: 0.3289231061935425
Batch 32/64 loss: 0.33664894104003906
Batch 33/64 loss: 0.3353627324104309
Batch 34/64 loss: 0.3314387798309326
Batch 35/64 loss: 0.3304364085197449
Batch 36/64 loss: 0.3295019268989563
Batch 37/64 loss: 0.3335925340652466
Batch 38/64 loss: 0.33548688888549805
Batch 39/64 loss: 0.33254051208496094
Batch 40/64 loss: 0.3328847885131836
Batch 41/64 loss: 0.33687257766723633
Batch 42/64 loss: 0.3331267237663269
Batch 43/64 loss: 0.33089280128479004
Batch 44/64 loss: 0.3307868242263794
Batch 45/64 loss: 0.33165156841278076
Batch 46/64 loss: 0.3436439633369446
Batch 47/64 loss: 0.33108341693878174
Batch 48/64 loss: 0.3312344551086426
Batch 49/64 loss: 0.3401510715484619
Batch 50/64 loss: 0.33697569370269775
Batch 51/64 loss: 0.33877575397491455
Batch 52/64 loss: 0.33555102348327637
Batch 53/64 loss: 0.3316275477409363
Batch 54/64 loss: 0.3347551226615906
Batch 55/64 loss: 0.34427595138549805
Batch 56/64 loss: 0.3341515064239502
Batch 57/64 loss: 0.328307569026947
Batch 58/64 loss: 0.3359256386756897
Batch 59/64 loss: 0.33223819732666016
Batch 60/64 loss: 0.32870543003082275
Batch 61/64 loss: 0.33365297317504883
Batch 62/64 loss: 0.3339887857437134
Batch 63/64 loss: 0.3356137275695801
Batch 64/64 loss: 0.3352367877960205
Epoch 167  Train loss: 0.3338689458136465  Val loss: 0.34397081984687095
Epoch 168
-------------------------------
Batch 1/64 loss: 0.3339611887931824
Batch 2/64 loss: 0.33120912313461304
Batch 3/64 loss: 0.3336191177368164
Batch 4/64 loss: 0.33089345693588257
Batch 5/64 loss: 0.3284965753555298
Batch 6/64 loss: 0.33135300874710083
Batch 7/64 loss: 0.32703518867492676
Batch 8/64 loss: 0.33388036489486694
Batch 9/64 loss: 0.3337942957878113
Batch 10/64 loss: 0.33279383182525635
Batch 11/64 loss: 0.3363165855407715
Batch 12/64 loss: 0.33793509006500244
Batch 13/64 loss: 0.33860790729522705
Batch 14/64 loss: 0.3365565538406372
Batch 15/64 loss: 0.337896466255188
Batch 16/64 loss: 0.3333611488342285
Batch 17/64 loss: 0.3360852003097534
Batch 18/64 loss: 0.32948601245880127
Batch 19/64 loss: 0.33473384380340576
Batch 20/64 loss: 0.33310484886169434
Batch 21/64 loss: 0.3371548652648926
Batch 22/64 loss: 0.3323206305503845
Batch 23/64 loss: 0.3355281352996826
Batch 24/64 loss: 0.32984459400177
Batch 25/64 loss: 0.33912718296051025
Batch 26/64 loss: 0.3323519825935364
Batch 27/64 loss: 0.33060669898986816
Batch 28/64 loss: 0.33778083324432373
Batch 29/64 loss: 0.3362158536911011
Batch 30/64 loss: 0.33114975690841675
Batch 31/64 loss: 0.33165597915649414
Batch 32/64 loss: 0.33539026975631714
Batch 33/64 loss: 0.33036142587661743
Batch 34/64 loss: 0.33604705333709717
Batch 35/64 loss: 0.3309687376022339
Batch 36/64 loss: 0.32922738790512085
Batch 37/64 loss: 0.33512556552886963
Batch 38/64 loss: 0.33457332849502563
Batch 39/64 loss: 0.3394937515258789
Batch 40/64 loss: 0.3326801657676697
Batch 41/64 loss: 0.330604612827301
Batch 42/64 loss: 0.32962071895599365
Batch 43/64 loss: 0.33578407764434814
Batch 44/64 loss: 0.3315621614456177
Batch 45/64 loss: 0.33259230852127075
Batch 46/64 loss: 0.32794642448425293
Batch 47/64 loss: 0.3331747055053711
Batch 48/64 loss: 0.33518821001052856
Batch 49/64 loss: 0.3403303623199463
Batch 50/64 loss: 0.3327154517173767
Batch 51/64 loss: 0.3328958749771118
Batch 52/64 loss: 0.33381175994873047
Batch 53/64 loss: 0.3318425416946411
Batch 54/64 loss: 0.33013004064559937
Batch 55/64 loss: 0.32962387800216675
Batch 56/64 loss: 0.33012741804122925
Batch 57/64 loss: 0.3293120861053467
Batch 58/64 loss: 0.33336806297302246
Batch 59/64 loss: 0.3319295048713684
Batch 60/64 loss: 0.3373774290084839
Batch 61/64 loss: 0.3374543786048889
Batch 62/64 loss: 0.3306872844696045
Batch 63/64 loss: 0.33457791805267334
Batch 64/64 loss: 0.33058416843414307
Epoch 168  Train loss: 0.33332265638837627  Val loss: 0.34210340222951885
Saving best model, epoch: 168
Epoch 169
-------------------------------
Batch 1/64 loss: 0.33209502696990967
Batch 2/64 loss: 0.3397058844566345
Batch 3/64 loss: 0.3326377868652344
Batch 4/64 loss: 0.33916276693344116
Batch 5/64 loss: 0.32556748390197754
Batch 6/64 loss: 0.33450138568878174
Batch 7/64 loss: 0.32849597930908203
Batch 8/64 loss: 0.3334379196166992
Batch 9/64 loss: 0.3324638605117798
Batch 10/64 loss: 0.334475040435791
Batch 11/64 loss: 0.3304905891418457
Batch 12/64 loss: 0.3330250382423401
Batch 13/64 loss: 0.3283705711364746
Batch 14/64 loss: 0.3344920873641968
Batch 15/64 loss: 0.33477699756622314
Batch 16/64 loss: 0.32899636030197144
Batch 17/64 loss: 0.3371776342391968
Batch 18/64 loss: 0.3265690803527832
Batch 19/64 loss: 0.3278789520263672
Batch 20/64 loss: 0.33071714639663696
Batch 21/64 loss: 0.33345651626586914
Batch 22/64 loss: 0.32766151428222656
Batch 23/64 loss: 0.3370669484138489
Batch 24/64 loss: 0.33090740442276
Batch 25/64 loss: 0.33094924688339233
Batch 26/64 loss: 0.3311312198638916
Batch 27/64 loss: 0.3336591124534607
Batch 28/64 loss: 0.3321254253387451
Batch 29/64 loss: 0.34793704748153687
Batch 30/64 loss: 0.33923256397247314
Batch 31/64 loss: 0.33617663383483887
Batch 32/64 loss: 0.3284069299697876
Batch 33/64 loss: 0.333294153213501
Batch 34/64 loss: 0.32977014780044556
Batch 35/64 loss: 0.33046889305114746
Batch 36/64 loss: 0.33883988857269287
Batch 37/64 loss: 0.3261876106262207
Batch 38/64 loss: 0.33648890256881714
Batch 39/64 loss: 0.3311556577682495
Batch 40/64 loss: 0.33674538135528564
Batch 41/64 loss: 0.3326300382614136
Batch 42/64 loss: 0.3289616107940674
Batch 43/64 loss: 0.3401893377304077
Batch 44/64 loss: 0.33417975902557373
Batch 45/64 loss: 0.3328971266746521
Batch 46/64 loss: 0.331418514251709
Batch 47/64 loss: 0.33286619186401367
Batch 48/64 loss: 0.33497345447540283
Batch 49/64 loss: 0.335299015045166
Batch 50/64 loss: 0.33240073919296265
Batch 51/64 loss: 0.3329516649246216
Batch 52/64 loss: 0.3306899666786194
Batch 53/64 loss: 0.326585054397583
Batch 54/64 loss: 0.33408164978027344
Batch 55/64 loss: 0.3260091543197632
Batch 56/64 loss: 0.33128809928894043
Batch 57/64 loss: 0.33296942710876465
Batch 58/64 loss: 0.3315469026565552
Batch 59/64 loss: 0.33457499742507935
Batch 60/64 loss: 0.33561205863952637
Batch 61/64 loss: 0.330694317817688
Batch 62/64 loss: 0.33482301235198975
Batch 63/64 loss: 0.33909595012664795
Batch 64/64 loss: 0.3307143449783325
Epoch 169  Train loss: 0.3328858445672428  Val loss: 0.3421196421397101
Epoch 170
-------------------------------
Batch 1/64 loss: 0.3353203535079956
Batch 2/64 loss: 0.3328879475593567
Batch 3/64 loss: 0.3412705063819885
Batch 4/64 loss: 0.33389008045196533
Batch 5/64 loss: 0.3311111330986023
Batch 6/64 loss: 0.340834379196167
Batch 7/64 loss: 0.33174431324005127
Batch 8/64 loss: 0.33440685272216797
Batch 9/64 loss: 0.3390474319458008
Batch 10/64 loss: 0.334255576133728
Batch 11/64 loss: 0.3312820792198181
Batch 12/64 loss: 0.33617228269577026
Batch 13/64 loss: 0.3310484290122986
Batch 14/64 loss: 0.33031344413757324
Batch 15/64 loss: 0.3275641202926636
Batch 16/64 loss: 0.33034825325012207
Batch 17/64 loss: 0.33081531524658203
Batch 18/64 loss: 0.33307313919067383
Batch 19/64 loss: 0.336256206035614
Batch 20/64 loss: 0.3284122943878174
Batch 21/64 loss: 0.33384525775909424
Batch 22/64 loss: 0.33318793773651123
Batch 23/64 loss: 0.33164507150650024
Batch 24/64 loss: 0.3304973840713501
Batch 25/64 loss: 0.3300635814666748
Batch 26/64 loss: 0.33454442024230957
Batch 27/64 loss: 0.3293558955192566
Batch 28/64 loss: 0.32885026931762695
Batch 29/64 loss: 0.33594024181365967
Batch 30/64 loss: 0.32999348640441895
Batch 31/64 loss: 0.33140653371810913
Batch 32/64 loss: 0.3345445394515991
Batch 33/64 loss: 0.3397648334503174
Batch 34/64 loss: 0.32770872116088867
Batch 35/64 loss: 0.32434260845184326
Batch 36/64 loss: 0.3295164108276367
Batch 37/64 loss: 0.3306320309638977
Batch 38/64 loss: 0.33422863483428955
Batch 39/64 loss: 0.3350237011909485
Batch 40/64 loss: 0.3305070400238037
Batch 41/64 loss: 0.33716869354248047
Batch 42/64 loss: 0.3331034183502197
Batch 43/64 loss: 0.3342876434326172
Batch 44/64 loss: 0.330979585647583
Batch 45/64 loss: 0.3343849182128906
Batch 46/64 loss: 0.33537232875823975
Batch 47/64 loss: 0.33229953050613403
Batch 48/64 loss: 0.3269641399383545
Batch 49/64 loss: 0.33198559284210205
Batch 50/64 loss: 0.33427321910858154
Batch 51/64 loss: 0.3324805498123169
Batch 52/64 loss: 0.3332565426826477
Batch 53/64 loss: 0.3324993848800659
Batch 54/64 loss: 0.3340693712234497
Batch 55/64 loss: 0.33281075954437256
Batch 56/64 loss: 0.3354220986366272
Batch 57/64 loss: 0.3295236825942993
Batch 58/64 loss: 0.3305387496948242
Batch 59/64 loss: 0.33826231956481934
Batch 60/64 loss: 0.33369094133377075
Batch 61/64 loss: 0.3360866904258728
Batch 62/64 loss: 0.3312627077102661
Batch 63/64 loss: 0.3343164920806885
Batch 64/64 loss: 0.3345448970794678
Epoch 170  Train loss: 0.3328878552305932  Val loss: 0.34208575802570357
Saving best model, epoch: 170
Epoch 171
-------------------------------
Batch 1/64 loss: 0.33207768201828003
Batch 2/64 loss: 0.3379284143447876
Batch 3/64 loss: 0.3312183618545532
Batch 4/64 loss: 0.33042365312576294
Batch 5/64 loss: 0.33183127641677856
Batch 6/64 loss: 0.33495473861694336
Batch 7/64 loss: 0.3362905979156494
Batch 8/64 loss: 0.33269202709198
Batch 9/64 loss: 0.33668655157089233
Batch 10/64 loss: 0.32683712244033813
Batch 11/64 loss: 0.3342171907424927
Batch 12/64 loss: 0.3331298828125
Batch 13/64 loss: 0.32829856872558594
Batch 14/64 loss: 0.335792601108551
Batch 15/64 loss: 0.3298482894897461
Batch 16/64 loss: 0.3335225582122803
Batch 17/64 loss: 0.3277188539505005
Batch 18/64 loss: 0.3249216079711914
Batch 19/64 loss: 0.3330100178718567
Batch 20/64 loss: 0.33152836561203003
Batch 21/64 loss: 0.33369386196136475
Batch 22/64 loss: 0.3319823145866394
Batch 23/64 loss: 0.3321545124053955
Batch 24/64 loss: 0.3329499363899231
Batch 25/64 loss: 0.34195101261138916
Batch 26/64 loss: 0.33266496658325195
Batch 27/64 loss: 0.3312874436378479
Batch 28/64 loss: 0.33003127574920654
Batch 29/64 loss: 0.32591772079467773
Batch 30/64 loss: 0.32920336723327637
Batch 31/64 loss: 0.3366715908050537
Batch 32/64 loss: 0.33362436294555664
Batch 33/64 loss: 0.32905787229537964
Batch 34/64 loss: 0.3359344005584717
Batch 35/64 loss: 0.33330148458480835
Batch 36/64 loss: 0.32613587379455566
Batch 37/64 loss: 0.32854336500167847
Batch 38/64 loss: 0.330702543258667
Batch 39/64 loss: 0.3333313465118408
Batch 40/64 loss: 0.33167004585266113
Batch 41/64 loss: 0.3307587504386902
Batch 42/64 loss: 0.3310626745223999
Batch 43/64 loss: 0.34123241901397705
Batch 44/64 loss: 0.33014369010925293
Batch 45/64 loss: 0.33749914169311523
Batch 46/64 loss: 0.33837050199508667
Batch 47/64 loss: 0.33030349016189575
Batch 48/64 loss: 0.3371657729148865
Batch 49/64 loss: 0.33282899856567383
Batch 50/64 loss: 0.333251953125
Batch 51/64 loss: 0.3359537720680237
Batch 52/64 loss: 0.3354074954986572
Batch 53/64 loss: 0.33292508125305176
Batch 54/64 loss: 0.3330172300338745
Batch 55/64 loss: 0.3271956443786621
Batch 56/64 loss: 0.3284494876861572
Batch 57/64 loss: 0.3312477469444275
Batch 58/64 loss: 0.33287155628204346
Batch 59/64 loss: 0.33565765619277954
Batch 60/64 loss: 0.33551496267318726
Batch 61/64 loss: 0.33532488346099854
Batch 62/64 loss: 0.33840370178222656
Batch 63/64 loss: 0.33862054347991943
Batch 64/64 loss: 0.334153413772583
Epoch 171  Train loss: 0.3328244686126709  Val loss: 0.3423815478164306
Epoch 172
-------------------------------
Batch 1/64 loss: 0.3326425552368164
Batch 2/64 loss: 0.32998591661453247
Batch 3/64 loss: 0.3281388282775879
Batch 4/64 loss: 0.32977330684661865
Batch 5/64 loss: 0.33473777770996094
Batch 6/64 loss: 0.33332955837249756
Batch 7/64 loss: 0.33621853590011597
Batch 8/64 loss: 0.33604711294174194
Batch 9/64 loss: 0.33434903621673584
Batch 10/64 loss: 0.33482128381729126
Batch 11/64 loss: 0.33295321464538574
Batch 12/64 loss: 0.3370850086212158
Batch 13/64 loss: 0.32908177375793457
Batch 14/64 loss: 0.3297402858734131
Batch 15/64 loss: 0.33448219299316406
Batch 16/64 loss: 0.3319917321205139
Batch 17/64 loss: 0.33241844177246094
Batch 18/64 loss: 0.33498072624206543
Batch 19/64 loss: 0.3357642889022827
Batch 20/64 loss: 0.3312556743621826
Batch 21/64 loss: 0.32655274868011475
Batch 22/64 loss: 0.3281307816505432
Batch 23/64 loss: 0.33416253328323364
Batch 24/64 loss: 0.33719420433044434
Batch 25/64 loss: 0.3325294256210327
Batch 26/64 loss: 0.33451753854751587
Batch 27/64 loss: 0.33129167556762695
Batch 28/64 loss: 0.3318901062011719
Batch 29/64 loss: 0.33468329906463623
Batch 30/64 loss: 0.34158486127853394
Batch 31/64 loss: 0.3283795118331909
Batch 32/64 loss: 0.3357257843017578
Batch 33/64 loss: 0.33478057384490967
Batch 34/64 loss: 0.33284837007522583
Batch 35/64 loss: 0.32904601097106934
Batch 36/64 loss: 0.32822513580322266
Batch 37/64 loss: 0.3283633589744568
Batch 38/64 loss: 0.3364684581756592
Batch 39/64 loss: 0.3340723514556885
Batch 40/64 loss: 0.3370547294616699
Batch 41/64 loss: 0.3281213045120239
Batch 42/64 loss: 0.3348798155784607
Batch 43/64 loss: 0.3409767150878906
Batch 44/64 loss: 0.33534061908721924
Batch 45/64 loss: 0.33088093996047974
Batch 46/64 loss: 0.33307021856307983
Batch 47/64 loss: 0.33211827278137207
Batch 48/64 loss: 0.3315469026565552
Batch 49/64 loss: 0.3353393077850342
Batch 50/64 loss: 0.33193063735961914
Batch 51/64 loss: 0.3332996964454651
Batch 52/64 loss: 0.3208078145980835
Batch 53/64 loss: 0.3399880528450012
Batch 54/64 loss: 0.324810266494751
Batch 55/64 loss: 0.3334372043609619
Batch 56/64 loss: 0.32938146591186523
Batch 57/64 loss: 0.3304554224014282
Batch 58/64 loss: 0.3326001763343811
Batch 59/64 loss: 0.32744312286376953
Batch 60/64 loss: 0.3289085626602173
Batch 61/64 loss: 0.3374067544937134
Batch 62/64 loss: 0.3279341459274292
Batch 63/64 loss: 0.3338320255279541
Batch 64/64 loss: 0.336381733417511
Epoch 172  Train loss: 0.33261324634739  Val loss: 0.34180377889744606
Saving best model, epoch: 172
Epoch 173
-------------------------------
Batch 1/64 loss: 0.33291494846343994
Batch 2/64 loss: 0.3345734477043152
Batch 3/64 loss: 0.32879823446273804
Batch 4/64 loss: 0.32833045721054077
Batch 5/64 loss: 0.33525097370147705
Batch 6/64 loss: 0.3331221342086792
Batch 7/64 loss: 0.33498650789260864
Batch 8/64 loss: 0.3325473666191101
Batch 9/64 loss: 0.33719539642333984
Batch 10/64 loss: 0.3277586102485657
Batch 11/64 loss: 0.335071325302124
Batch 12/64 loss: 0.33616459369659424
Batch 13/64 loss: 0.3322354555130005
Batch 14/64 loss: 0.33647245168685913
Batch 15/64 loss: 0.32743513584136963
Batch 16/64 loss: 0.3269549608230591
Batch 17/64 loss: 0.33420050144195557
Batch 18/64 loss: 0.33201026916503906
Batch 19/64 loss: 0.33179235458374023
Batch 20/64 loss: 0.33533161878585815
Batch 21/64 loss: 0.3259398937225342
Batch 22/64 loss: 0.3304750919342041
Batch 23/64 loss: 0.3367553949356079
Batch 24/64 loss: 0.33043503761291504
Batch 25/64 loss: 0.332416296005249
Batch 26/64 loss: 0.3385884761810303
Batch 27/64 loss: 0.3359869718551636
Batch 28/64 loss: 0.32851171493530273
Batch 29/64 loss: 0.33446061611175537
Batch 30/64 loss: 0.33629822731018066
Batch 31/64 loss: 0.33214306831359863
Batch 32/64 loss: 0.3349496126174927
Batch 33/64 loss: 0.3307456970214844
Batch 34/64 loss: 0.33166491985321045
Batch 35/64 loss: 0.3346409797668457
Batch 36/64 loss: 0.332230806350708
Batch 37/64 loss: 0.33441221714019775
Batch 38/64 loss: 0.3286004066467285
Batch 39/64 loss: 0.33372217416763306
Batch 40/64 loss: 0.33558177947998047
Batch 41/64 loss: 0.33293116092681885
Batch 42/64 loss: 0.3267744779586792
Batch 43/64 loss: 0.3320465087890625
Batch 44/64 loss: 0.3249475359916687
Batch 45/64 loss: 0.33145004510879517
Batch 46/64 loss: 0.331839919090271
Batch 47/64 loss: 0.3334481120109558
Batch 48/64 loss: 0.3353426456451416
Batch 49/64 loss: 0.32933658361434937
Batch 50/64 loss: 0.33265411853790283
Batch 51/64 loss: 0.32893693447113037
Batch 52/64 loss: 0.3256210684776306
Batch 53/64 loss: 0.337216854095459
Batch 54/64 loss: 0.33083343505859375
Batch 55/64 loss: 0.33751535415649414
Batch 56/64 loss: 0.3321092128753662
Batch 57/64 loss: 0.3320518732070923
Batch 58/64 loss: 0.33343589305877686
Batch 59/64 loss: 0.33563339710235596
Batch 60/64 loss: 0.33246731758117676
Batch 61/64 loss: 0.3317375183105469
Batch 62/64 loss: 0.32846856117248535
Batch 63/64 loss: 0.329460084438324
Batch 64/64 loss: 0.33052241802215576
Epoch 173  Train loss: 0.332327161583246  Val loss: 0.3418742330213593
Epoch 174
-------------------------------
Batch 1/64 loss: 0.3297949433326721
Batch 2/64 loss: 0.3282245397567749
Batch 3/64 loss: 0.3294244408607483
Batch 4/64 loss: 0.3248840570449829
Batch 5/64 loss: 0.3334357738494873
Batch 6/64 loss: 0.32881486415863037
Batch 7/64 loss: 0.3315936326980591
Batch 8/64 loss: 0.332480788230896
Batch 9/64 loss: 0.32467418909072876
Batch 10/64 loss: 0.3311736583709717
Batch 11/64 loss: 0.33408480882644653
Batch 12/64 loss: 0.3260434865951538
Batch 13/64 loss: 0.33044344186782837
Batch 14/64 loss: 0.33525967597961426
Batch 15/64 loss: 0.33473849296569824
Batch 16/64 loss: 0.336251437664032
Batch 17/64 loss: 0.33029794692993164
Batch 18/64 loss: 0.3299717903137207
Batch 19/64 loss: 0.33164042234420776
Batch 20/64 loss: 0.334763765335083
Batch 21/64 loss: 0.32512664794921875
Batch 22/64 loss: 0.33511805534362793
Batch 23/64 loss: 0.33691614866256714
Batch 24/64 loss: 0.3357727527618408
Batch 25/64 loss: 0.326360821723938
Batch 26/64 loss: 0.3328028917312622
Batch 27/64 loss: 0.32765471935272217
Batch 28/64 loss: 0.33170223236083984
Batch 29/64 loss: 0.33152538537979126
Batch 30/64 loss: 0.3363691568374634
Batch 31/64 loss: 0.3369513750076294
Batch 32/64 loss: 0.33615195751190186
Batch 33/64 loss: 0.3329543471336365
Batch 34/64 loss: 0.33496320247650146
Batch 35/64 loss: 0.3358384370803833
Batch 36/64 loss: 0.3291805386543274
Batch 37/64 loss: 0.33183538913726807
Batch 38/64 loss: 0.32673799991607666
Batch 39/64 loss: 0.3325267434120178
Batch 40/64 loss: 0.3276832103729248
Batch 41/64 loss: 0.3300187587738037
Batch 42/64 loss: 0.33349424600601196
Batch 43/64 loss: 0.3394038677215576
Batch 44/64 loss: 0.33081406354904175
Batch 45/64 loss: 0.3359726071357727
Batch 46/64 loss: 0.33392399549484253
Batch 47/64 loss: 0.33100759983062744
Batch 48/64 loss: 0.32894718647003174
Batch 49/64 loss: 0.3363671898841858
Batch 50/64 loss: 0.33108997344970703
Batch 51/64 loss: 0.33624136447906494
Batch 52/64 loss: 0.32717907428741455
Batch 53/64 loss: 0.3339416980743408
Batch 54/64 loss: 0.33170509338378906
Batch 55/64 loss: 0.33486485481262207
Batch 56/64 loss: 0.3228453993797302
Batch 57/64 loss: 0.3331972360610962
Batch 58/64 loss: 0.3313866853713989
Batch 59/64 loss: 0.3262719511985779
Batch 60/64 loss: 0.33213257789611816
Batch 61/64 loss: 0.32856619358062744
Batch 62/64 loss: 0.33468782901763916
Batch 63/64 loss: 0.3340023159980774
Batch 64/64 loss: 0.3305279016494751
Epoch 174  Train loss: 0.33173530756258496  Val loss: 0.341628933280604
Saving best model, epoch: 174
Epoch 175
-------------------------------
Batch 1/64 loss: 0.33021044731140137
Batch 2/64 loss: 0.33351635932922363
Batch 3/64 loss: 0.3358030319213867
Batch 4/64 loss: 0.3346128463745117
Batch 5/64 loss: 0.33159738779067993
Batch 6/64 loss: 0.3316177725791931
Batch 7/64 loss: 0.32764995098114014
Batch 8/64 loss: 0.32668107748031616
Batch 9/64 loss: 0.32737600803375244
Batch 10/64 loss: 0.32716846466064453
Batch 11/64 loss: 0.3386085033416748
Batch 12/64 loss: 0.33396488428115845
Batch 13/64 loss: 0.3320860266685486
Batch 14/64 loss: 0.33015358448028564
Batch 15/64 loss: 0.32862597703933716
Batch 16/64 loss: 0.3271335959434509
Batch 17/64 loss: 0.32779037952423096
Batch 18/64 loss: 0.3355928659439087
Batch 19/64 loss: 0.33294105529785156
Batch 20/64 loss: 0.3318067789077759
Batch 21/64 loss: 0.3385789394378662
Batch 22/64 loss: 0.33684879541397095
Batch 23/64 loss: 0.32930123805999756
Batch 24/64 loss: 0.3312948942184448
Batch 25/64 loss: 0.3321952819824219
Batch 26/64 loss: 0.3318204879760742
Batch 27/64 loss: 0.33812880516052246
Batch 28/64 loss: 0.327960729598999
Batch 29/64 loss: 0.32515960931777954
Batch 30/64 loss: 0.33021295070648193
Batch 31/64 loss: 0.32908642292022705
Batch 32/64 loss: 0.3299000859260559
Batch 33/64 loss: 0.3344659209251404
Batch 34/64 loss: 0.33515214920043945
Batch 35/64 loss: 0.33331412076950073
Batch 36/64 loss: 0.3324214816093445
Batch 37/64 loss: 0.33399152755737305
Batch 38/64 loss: 0.33000195026397705
Batch 39/64 loss: 0.3302575945854187
Batch 40/64 loss: 0.33186304569244385
Batch 41/64 loss: 0.3357599973678589
Batch 42/64 loss: 0.3337339758872986
Batch 43/64 loss: 0.33362531661987305
Batch 44/64 loss: 0.3300834894180298
Batch 45/64 loss: 0.337904691696167
Batch 46/64 loss: 0.3307316303253174
Batch 47/64 loss: 0.3330744504928589
Batch 48/64 loss: 0.3322162628173828
Batch 49/64 loss: 0.33041083812713623
Batch 50/64 loss: 0.3375098705291748
Batch 51/64 loss: 0.3319075107574463
Batch 52/64 loss: 0.33442604541778564
Batch 53/64 loss: 0.33863604068756104
Batch 54/64 loss: 0.32681941986083984
Batch 55/64 loss: 0.3371013402938843
Batch 56/64 loss: 0.32980799674987793
Batch 57/64 loss: 0.32973694801330566
Batch 58/64 loss: 0.3280124068260193
Batch 59/64 loss: 0.32965534925460815
Batch 60/64 loss: 0.33064091205596924
Batch 61/64 loss: 0.33107876777648926
Batch 62/64 loss: 0.33292829990386963
Batch 63/64 loss: 0.3343557119369507
Batch 64/64 loss: 0.33262670040130615
Epoch 175  Train loss: 0.3320238482718374  Val loss: 0.3416223226953618
Saving best model, epoch: 175
Epoch 176
-------------------------------
Batch 1/64 loss: 0.33115893602371216
Batch 2/64 loss: 0.3317364454269409
Batch 3/64 loss: 0.3324756622314453
Batch 4/64 loss: 0.32893961668014526
Batch 5/64 loss: 0.32915419340133667
Batch 6/64 loss: 0.3312761187553406
Batch 7/64 loss: 0.3319896459579468
Batch 8/64 loss: 0.3341262936592102
Batch 9/64 loss: 0.32856059074401855
Batch 10/64 loss: 0.32822954654693604
Batch 11/64 loss: 0.32736319303512573
Batch 12/64 loss: 0.3319014310836792
Batch 13/64 loss: 0.3256148099899292
Batch 14/64 loss: 0.32957029342651367
Batch 15/64 loss: 0.33558011054992676
Batch 16/64 loss: 0.3342251777648926
Batch 17/64 loss: 0.3334755301475525
Batch 18/64 loss: 0.3346872329711914
Batch 19/64 loss: 0.3312387466430664
Batch 20/64 loss: 0.3345181941986084
Batch 21/64 loss: 0.3356543183326721
Batch 22/64 loss: 0.33650654554367065
Batch 23/64 loss: 0.33095353841781616
Batch 24/64 loss: 0.33007824420928955
Batch 25/64 loss: 0.3300797939300537
Batch 26/64 loss: 0.3331491947174072
Batch 27/64 loss: 0.3409154415130615
Batch 28/64 loss: 0.3355921506881714
Batch 29/64 loss: 0.33069348335266113
Batch 30/64 loss: 0.33747899532318115
Batch 31/64 loss: 0.33431875705718994
Batch 32/64 loss: 0.32951438426971436
Batch 33/64 loss: 0.3368896245956421
Batch 34/64 loss: 0.32757389545440674
Batch 35/64 loss: 0.33360493183135986
Batch 36/64 loss: 0.3255881071090698
Batch 37/64 loss: 0.33358705043792725
Batch 38/64 loss: 0.3403576612472534
Batch 39/64 loss: 0.339709997177124
Batch 40/64 loss: 0.33013272285461426
Batch 41/64 loss: 0.33041948080062866
Batch 42/64 loss: 0.3345964550971985
Batch 43/64 loss: 0.3370550274848938
Batch 44/64 loss: 0.3360128402709961
Batch 45/64 loss: 0.328849732875824
Batch 46/64 loss: 0.3339601159095764
Batch 47/64 loss: 0.33422309160232544
Batch 48/64 loss: 0.33716487884521484
Batch 49/64 loss: 0.333568811416626
Batch 50/64 loss: 0.3270220160484314
Batch 51/64 loss: 0.3383537530899048
Batch 52/64 loss: 0.33872735500335693
Batch 53/64 loss: 0.33111655712127686
Batch 54/64 loss: 0.33319151401519775
Batch 55/64 loss: 0.3285253643989563
Batch 56/64 loss: 0.32684242725372314
Batch 57/64 loss: 0.33445054292678833
Batch 58/64 loss: 0.326457679271698
Batch 59/64 loss: 0.3331034183502197
Batch 60/64 loss: 0.33108651638031006
Batch 61/64 loss: 0.3311023712158203
Batch 62/64 loss: 0.32936131954193115
Batch 63/64 loss: 0.33213841915130615
Batch 64/64 loss: 0.3220338225364685
Epoch 176  Train loss: 0.33234597117293113  Val loss: 0.3416064150144964
Saving best model, epoch: 176
Epoch 177
-------------------------------
Batch 1/64 loss: 0.3264901638031006
Batch 2/64 loss: 0.32836174964904785
Batch 3/64 loss: 0.32944685220718384
Batch 4/64 loss: 0.3292199969291687
Batch 5/64 loss: 0.3268131613731384
Batch 6/64 loss: 0.33393633365631104
Batch 7/64 loss: 0.32859885692596436
Batch 8/64 loss: 0.33759379386901855
Batch 9/64 loss: 0.3256584405899048
Batch 10/64 loss: 0.33222895860671997
Batch 11/64 loss: 0.3359025716781616
Batch 12/64 loss: 0.33393776416778564
Batch 13/64 loss: 0.32941555976867676
Batch 14/64 loss: 0.329174280166626
Batch 15/64 loss: 0.33048170804977417
Batch 16/64 loss: 0.3289409875869751
Batch 17/64 loss: 0.32827579975128174
Batch 18/64 loss: 0.32931995391845703
Batch 19/64 loss: 0.3338996171951294
Batch 20/64 loss: 0.32853591442108154
Batch 21/64 loss: 0.32991862297058105
Batch 22/64 loss: 0.32800137996673584
Batch 23/64 loss: 0.33607518672943115
Batch 24/64 loss: 0.33097171783447266
Batch 25/64 loss: 0.33183056116104126
Batch 26/64 loss: 0.3314797878265381
Batch 27/64 loss: 0.3356434106826782
Batch 28/64 loss: 0.32829296588897705
Batch 29/64 loss: 0.33557403087615967
Batch 30/64 loss: 0.3381580114364624
Batch 31/64 loss: 0.33922696113586426
Batch 32/64 loss: 0.3312053680419922
Batch 33/64 loss: 0.3259251117706299
Batch 34/64 loss: 0.3261452913284302
Batch 35/64 loss: 0.33225274085998535
Batch 36/64 loss: 0.32142317295074463
Batch 37/64 loss: 0.3353734016418457
Batch 38/64 loss: 0.3309648036956787
Batch 39/64 loss: 0.33316731452941895
Batch 40/64 loss: 0.3330117464065552
Batch 41/64 loss: 0.3327345848083496
Batch 42/64 loss: 0.327852725982666
Batch 43/64 loss: 0.3418183922767639
Batch 44/64 loss: 0.3360987901687622
Batch 45/64 loss: 0.33609235286712646
Batch 46/64 loss: 0.32621538639068604
Batch 47/64 loss: 0.3316553831100464
Batch 48/64 loss: 0.32496583461761475
Batch 49/64 loss: 0.3317309617996216
Batch 50/64 loss: 0.3293091058731079
Batch 51/64 loss: 0.33584916591644287
Batch 52/64 loss: 0.3331145644187927
Batch 53/64 loss: 0.3332265615463257
Batch 54/64 loss: 0.3348967432975769
Batch 55/64 loss: 0.3333299160003662
Batch 56/64 loss: 0.33278846740722656
Batch 57/64 loss: 0.33246076107025146
Batch 58/64 loss: 0.3348129987716675
Batch 59/64 loss: 0.3398393988609314
Batch 60/64 loss: 0.3315619230270386
Batch 61/64 loss: 0.33081698417663574
Batch 62/64 loss: 0.3279625177383423
Batch 63/64 loss: 0.32747817039489746
Batch 64/64 loss: 0.3298525810241699
Epoch 177  Train loss: 0.3315274537778368  Val loss: 0.34245145361857726
Epoch 178
-------------------------------
Batch 1/64 loss: 0.32914090156555176
Batch 2/64 loss: 0.33676397800445557
Batch 3/64 loss: 0.33738815784454346
Batch 4/64 loss: 0.3383326530456543
Batch 5/64 loss: 0.338409423828125
Batch 6/64 loss: 0.33153700828552246
Batch 7/64 loss: 0.3311690092086792
Batch 8/64 loss: 0.335188627243042
Batch 9/64 loss: 0.3310350775718689
Batch 10/64 loss: 0.3271331787109375
Batch 11/64 loss: 0.33001232147216797
Batch 12/64 loss: 0.3349720239639282
Batch 13/64 loss: 0.33150792121887207
Batch 14/64 loss: 0.3259945511817932
Batch 15/64 loss: 0.3295844793319702
Batch 16/64 loss: 0.3267258405685425
Batch 17/64 loss: 0.33177220821380615
Batch 18/64 loss: 0.3359839916229248
Batch 19/64 loss: 0.3311882019042969
Batch 20/64 loss: 0.3270453214645386
Batch 21/64 loss: 0.3300377130508423
Batch 22/64 loss: 0.327505886554718
Batch 23/64 loss: 0.32163071632385254
Batch 24/64 loss: 0.32947105169296265
Batch 25/64 loss: 0.3332475423812866
Batch 26/64 loss: 0.3312704563140869
Batch 27/64 loss: 0.33133000135421753
Batch 28/64 loss: 0.3324264883995056
Batch 29/64 loss: 0.33328402042388916
Batch 30/64 loss: 0.3337109684944153
Batch 31/64 loss: 0.33015120029449463
Batch 32/64 loss: 0.332674503326416
Batch 33/64 loss: 0.3326103091239929
Batch 34/64 loss: 0.3297996520996094
Batch 35/64 loss: 0.3317584991455078
Batch 36/64 loss: 0.325711727142334
Batch 37/64 loss: 0.33438336849212646
Batch 38/64 loss: 0.32558417320251465
Batch 39/64 loss: 0.3323776125907898
Batch 40/64 loss: 0.32502996921539307
Batch 41/64 loss: 0.32763445377349854
Batch 42/64 loss: 0.3371926546096802
Batch 43/64 loss: 0.33322179317474365
Batch 44/64 loss: 0.3348618149757385
Batch 45/64 loss: 0.33793413639068604
Batch 46/64 loss: 0.33216917514801025
Batch 47/64 loss: 0.32847243547439575
Batch 48/64 loss: 0.3330979347229004
Batch 49/64 loss: 0.33284538984298706
Batch 50/64 loss: 0.3317786455154419
Batch 51/64 loss: 0.3311009407043457
Batch 52/64 loss: 0.3351815342903137
Batch 53/64 loss: 0.33094990253448486
Batch 54/64 loss: 0.3268088102340698
Batch 55/64 loss: 0.3302105665206909
Batch 56/64 loss: 0.32936233282089233
Batch 57/64 loss: 0.33868396282196045
Batch 58/64 loss: 0.3328895568847656
Batch 59/64 loss: 0.32904696464538574
Batch 60/64 loss: 0.3260573148727417
Batch 61/64 loss: 0.3306657671928406
Batch 62/64 loss: 0.3287534713745117
Batch 63/64 loss: 0.33273088932037354
Batch 64/64 loss: 0.3303729295730591
Epoch 178  Train loss: 0.3313617393082263  Val loss: 0.3404814435034683
Saving best model, epoch: 178
Epoch 179
-------------------------------
Batch 1/64 loss: 0.32708919048309326
Batch 2/64 loss: 0.32557666301727295
Batch 3/64 loss: 0.3245558738708496
Batch 4/64 loss: 0.33388984203338623
Batch 5/64 loss: 0.32494843006134033
Batch 6/64 loss: 0.3290630578994751
Batch 7/64 loss: 0.32992297410964966
Batch 8/64 loss: 0.3319711685180664
Batch 9/64 loss: 0.33360958099365234
Batch 10/64 loss: 0.3333613872528076
Batch 11/64 loss: 0.3249053955078125
Batch 12/64 loss: 0.33083510398864746
Batch 13/64 loss: 0.3312065601348877
Batch 14/64 loss: 0.3330532908439636
Batch 15/64 loss: 0.33031749725341797
Batch 16/64 loss: 0.3313666582107544
Batch 17/64 loss: 0.3290259838104248
Batch 18/64 loss: 0.33555591106414795
Batch 19/64 loss: 0.3296378254890442
Batch 20/64 loss: 0.3377392292022705
Batch 21/64 loss: 0.3295241594314575
Batch 22/64 loss: 0.3311658501625061
Batch 23/64 loss: 0.33730506896972656
Batch 24/64 loss: 0.3322948217391968
Batch 25/64 loss: 0.33023303747177124
Batch 26/64 loss: 0.33659905195236206
Batch 27/64 loss: 0.3323676586151123
Batch 28/64 loss: 0.3301529884338379
Batch 29/64 loss: 0.33042824268341064
Batch 30/64 loss: 0.3270922303199768
Batch 31/64 loss: 0.3260953426361084
Batch 32/64 loss: 0.33453530073165894
Batch 33/64 loss: 0.3305232524871826
Batch 34/64 loss: 0.33070462942123413
Batch 35/64 loss: 0.33377325534820557
Batch 36/64 loss: 0.3314783573150635
Batch 37/64 loss: 0.33736932277679443
Batch 38/64 loss: 0.3287661671638489
Batch 39/64 loss: 0.332963764667511
Batch 40/64 loss: 0.3328038454055786
Batch 41/64 loss: 0.3233816623687744
Batch 42/64 loss: 0.3267325162887573
Batch 43/64 loss: 0.3351932764053345
Batch 44/64 loss: 0.32735222578048706
Batch 45/64 loss: 0.33247679471969604
Batch 46/64 loss: 0.3327409029006958
Batch 47/64 loss: 0.32935404777526855
Batch 48/64 loss: 0.3308364152908325
Batch 49/64 loss: 0.3313860297203064
Batch 50/64 loss: 0.3317490220069885
Batch 51/64 loss: 0.33249330520629883
Batch 52/64 loss: 0.3323976397514343
Batch 53/64 loss: 0.33525407314300537
Batch 54/64 loss: 0.3342021107673645
Batch 55/64 loss: 0.33423101902008057
Batch 56/64 loss: 0.324363112449646
Batch 57/64 loss: 0.3358970880508423
Batch 58/64 loss: 0.33140742778778076
Batch 59/64 loss: 0.3385971784591675
Batch 60/64 loss: 0.3353809118270874
Batch 61/64 loss: 0.33578765392303467
Batch 62/64 loss: 0.3306048512458801
Batch 63/64 loss: 0.3331029415130615
Batch 64/64 loss: 0.3269265294075012
Epoch 179  Train loss: 0.33135568744996013  Val loss: 0.34159986157597544
Epoch 180
-------------------------------
Batch 1/64 loss: 0.3303068280220032
Batch 2/64 loss: 0.3317462205886841
Batch 3/64 loss: 0.33336544036865234
Batch 4/64 loss: 0.33244723081588745
Batch 5/64 loss: 0.3296777606010437
Batch 6/64 loss: 0.33166420459747314
Batch 7/64 loss: 0.3308541178703308
Batch 8/64 loss: 0.3302733898162842
Batch 9/64 loss: 0.32424890995025635
Batch 10/64 loss: 0.3339417576789856
Batch 11/64 loss: 0.3254409432411194
Batch 12/64 loss: 0.3311718702316284
Batch 13/64 loss: 0.32880496978759766
Batch 14/64 loss: 0.33056938648223877
Batch 15/64 loss: 0.32938051223754883
Batch 16/64 loss: 0.3301076292991638
Batch 17/64 loss: 0.3313223123550415
Batch 18/64 loss: 0.3331277370452881
Batch 19/64 loss: 0.32338666915893555
Batch 20/64 loss: 0.33541810512542725
Batch 21/64 loss: 0.3303706645965576
Batch 22/64 loss: 0.3277379274368286
Batch 23/64 loss: 0.33079230785369873
Batch 24/64 loss: 0.3323467969894409
Batch 25/64 loss: 0.33451610803604126
Batch 26/64 loss: 0.32295411825180054
Batch 27/64 loss: 0.3273158073425293
Batch 28/64 loss: 0.3305232524871826
Batch 29/64 loss: 0.3322610855102539
Batch 30/64 loss: 0.3286544680595398
Batch 31/64 loss: 0.33378058671951294
Batch 32/64 loss: 0.32874995470046997
Batch 33/64 loss: 0.33425796031951904
Batch 34/64 loss: 0.3248239755630493
Batch 35/64 loss: 0.3250420093536377
Batch 36/64 loss: 0.3336523771286011
Batch 37/64 loss: 0.332355260848999
Batch 38/64 loss: 0.3277549743652344
Batch 39/64 loss: 0.3284522294998169
Batch 40/64 loss: 0.3265746831893921
Batch 41/64 loss: 0.32945460081100464
Batch 42/64 loss: 0.33423513174057007
Batch 43/64 loss: 0.33123642206192017
Batch 44/64 loss: 0.32996630668640137
Batch 45/64 loss: 0.33439940214157104
Batch 46/64 loss: 0.33451980352401733
Batch 47/64 loss: 0.3295903205871582
Batch 48/64 loss: 0.336092472076416
Batch 49/64 loss: 0.3345099687576294
Batch 50/64 loss: 0.326896607875824
Batch 51/64 loss: 0.3327610492706299
Batch 52/64 loss: 0.3309670686721802
Batch 53/64 loss: 0.32872092723846436
Batch 54/64 loss: 0.3358786106109619
Batch 55/64 loss: 0.33336949348449707
Batch 56/64 loss: 0.3353536128997803
Batch 57/64 loss: 0.3310140371322632
Batch 58/64 loss: 0.32705581188201904
Batch 59/64 loss: 0.33525514602661133
Batch 60/64 loss: 0.3368397355079651
Batch 61/64 loss: 0.329662561416626
Batch 62/64 loss: 0.3337147831916809
Batch 63/64 loss: 0.3285292387008667
Batch 64/64 loss: 0.33453500270843506
Epoch 180  Train loss: 0.33084073580947576  Val loss: 0.34094156964947675
Epoch 181
-------------------------------
Batch 1/64 loss: 0.330533504486084
Batch 2/64 loss: 0.3339749574661255
Batch 3/64 loss: 0.33322757482528687
Batch 4/64 loss: 0.3331705331802368
Batch 5/64 loss: 0.33826059103012085
Batch 6/64 loss: 0.32538455724716187
Batch 7/64 loss: 0.3254271149635315
Batch 8/64 loss: 0.3298623561859131
Batch 9/64 loss: 0.3265712261199951
Batch 10/64 loss: 0.3225584030151367
Batch 11/64 loss: 0.33316123485565186
Batch 12/64 loss: 0.33011651039123535
Batch 13/64 loss: 0.3294805884361267
Batch 14/64 loss: 0.33107876777648926
Batch 15/64 loss: 0.3358943462371826
Batch 16/64 loss: 0.3304067850112915
Batch 17/64 loss: 0.33015209436416626
Batch 18/64 loss: 0.3236963748931885
Batch 19/64 loss: 0.33252882957458496
Batch 20/64 loss: 0.3283580541610718
Batch 21/64 loss: 0.33184748888015747
Batch 22/64 loss: 0.3356608748435974
Batch 23/64 loss: 0.33182018995285034
Batch 24/64 loss: 0.331417441368103
Batch 25/64 loss: 0.3261042833328247
Batch 26/64 loss: 0.33173537254333496
Batch 27/64 loss: 0.3301127552986145
Batch 28/64 loss: 0.333248496055603
Batch 29/64 loss: 0.33235985040664673
Batch 30/64 loss: 0.3335615396499634
Batch 31/64 loss: 0.33475345373153687
Batch 32/64 loss: 0.3303842544555664
Batch 33/64 loss: 0.3247098922729492
Batch 34/64 loss: 0.3329874277114868
Batch 35/64 loss: 0.32743704319000244
Batch 36/64 loss: 0.3297427296638489
Batch 37/64 loss: 0.3330010175704956
Batch 38/64 loss: 0.3310467004776001
Batch 39/64 loss: 0.32907652854919434
Batch 40/64 loss: 0.33606600761413574
Batch 41/64 loss: 0.3349621295928955
Batch 42/64 loss: 0.3335578441619873
Batch 43/64 loss: 0.329184353351593
Batch 44/64 loss: 0.32980334758758545
Batch 45/64 loss: 0.33318090438842773
Batch 46/64 loss: 0.33311283588409424
Batch 47/64 loss: 0.3306776285171509
Batch 48/64 loss: 0.32863396406173706
Batch 49/64 loss: 0.32553577423095703
Batch 50/64 loss: 0.3305433988571167
Batch 51/64 loss: 0.3257978558540344
Batch 52/64 loss: 0.33635812997817993
Batch 53/64 loss: 0.3363117575645447
Batch 54/64 loss: 0.33431822061538696
Batch 55/64 loss: 0.32682764530181885
Batch 56/64 loss: 0.336040198802948
Batch 57/64 loss: 0.33281469345092773
Batch 58/64 loss: 0.33587127923965454
Batch 59/64 loss: 0.3288286328315735
Batch 60/64 loss: 0.32922542095184326
Batch 61/64 loss: 0.32601994276046753
Batch 62/64 loss: 0.3278651237487793
Batch 63/64 loss: 0.3400837182998657
Batch 64/64 loss: 0.33176863193511963
Epoch 181  Train loss: 0.3310635141297883  Val loss: 0.34108024036761414
Epoch 182
-------------------------------
Batch 1/64 loss: 0.3282148838043213
Batch 2/64 loss: 0.3255743980407715
Batch 3/64 loss: 0.33326148986816406
Batch 4/64 loss: 0.3298472762107849
Batch 5/64 loss: 0.3362659215927124
Batch 6/64 loss: 0.3334318995475769
Batch 7/64 loss: 0.32916080951690674
Batch 8/64 loss: 0.33273792266845703
Batch 9/64 loss: 0.3395414352416992
Batch 10/64 loss: 0.32496678829193115
Batch 11/64 loss: 0.32464689016342163
Batch 12/64 loss: 0.3263295888900757
Batch 13/64 loss: 0.3359009623527527
Batch 14/64 loss: 0.32987332344055176
Batch 15/64 loss: 0.3332563042640686
Batch 16/64 loss: 0.32461047172546387
Batch 17/64 loss: 0.3264998197555542
Batch 18/64 loss: 0.32948434352874756
Batch 19/64 loss: 0.32918602228164673
Batch 20/64 loss: 0.3348344564437866
Batch 21/64 loss: 0.3304516077041626
Batch 22/64 loss: 0.33135831356048584
Batch 23/64 loss: 0.33185672760009766
Batch 24/64 loss: 0.33242130279541016
Batch 25/64 loss: 0.3375241756439209
Batch 26/64 loss: 0.3280470371246338
Batch 27/64 loss: 0.3267276883125305
Batch 28/64 loss: 0.3378787040710449
Batch 29/64 loss: 0.3312795162200928
Batch 30/64 loss: 0.33186763525009155
Batch 31/64 loss: 0.33007901906967163
Batch 32/64 loss: 0.3380391597747803
Batch 33/64 loss: 0.3284021019935608
Batch 34/64 loss: 0.3227565288543701
Batch 35/64 loss: 0.3286842107772827
Batch 36/64 loss: 0.32862740755081177
Batch 37/64 loss: 0.33754289150238037
Batch 38/64 loss: 0.33854758739471436
Batch 39/64 loss: 0.3273087739944458
Batch 40/64 loss: 0.3289083242416382
Batch 41/64 loss: 0.33894872665405273
Batch 42/64 loss: 0.331318199634552
Batch 43/64 loss: 0.3320600986480713
Batch 44/64 loss: 0.3294615149497986
Batch 45/64 loss: 0.3364977240562439
Batch 46/64 loss: 0.3306754231452942
Batch 47/64 loss: 0.3289717435836792
Batch 48/64 loss: 0.33036768436431885
Batch 49/64 loss: 0.3303062915802002
Batch 50/64 loss: 0.3263660669326782
Batch 51/64 loss: 0.328769326210022
Batch 52/64 loss: 0.3235313892364502
Batch 53/64 loss: 0.3314553499221802
Batch 54/64 loss: 0.3318169116973877
Batch 55/64 loss: 0.32974421977996826
Batch 56/64 loss: 0.3257715702056885
Batch 57/64 loss: 0.33935004472732544
Batch 58/64 loss: 0.3321181535720825
Batch 59/64 loss: 0.33442652225494385
Batch 60/64 loss: 0.33138442039489746
Batch 61/64 loss: 0.3392212390899658
Batch 62/64 loss: 0.3281082510948181
Batch 63/64 loss: 0.3337227702140808
Batch 64/64 loss: 0.3264343738555908
Epoch 182  Train loss: 0.3310612257789163  Val loss: 0.34063770598971965
Epoch 183
-------------------------------
Batch 1/64 loss: 0.32708436250686646
Batch 2/64 loss: 0.32436490058898926
Batch 3/64 loss: 0.3223269581794739
Batch 4/64 loss: 0.3305409550666809
Batch 5/64 loss: 0.3336544632911682
Batch 6/64 loss: 0.33428770303726196
Batch 7/64 loss: 0.3287220597267151
Batch 8/64 loss: 0.3275641202926636
Batch 9/64 loss: 0.3354465961456299
Batch 10/64 loss: 0.3263927698135376
Batch 11/64 loss: 0.33748555183410645
Batch 12/64 loss: 0.32593977451324463
Batch 13/64 loss: 0.33429956436157227
Batch 14/64 loss: 0.3278345465660095
Batch 15/64 loss: 0.32718896865844727
Batch 16/64 loss: 0.3347472548484802
Batch 17/64 loss: 0.3257557153701782
Batch 18/64 loss: 0.32598936557769775
Batch 19/64 loss: 0.3363546133041382
Batch 20/64 loss: 0.32878512144088745
Batch 21/64 loss: 0.3353116512298584
Batch 22/64 loss: 0.32930421829223633
Batch 23/64 loss: 0.3325861692428589
Batch 24/64 loss: 0.3313414454460144
Batch 25/64 loss: 0.328082799911499
Batch 26/64 loss: 0.3297351598739624
Batch 27/64 loss: 0.32479315996170044
Batch 28/64 loss: 0.3344775438308716
Batch 29/64 loss: 0.33507806062698364
Batch 30/64 loss: 0.32716208696365356
Batch 31/64 loss: 0.3333250880241394
Batch 32/64 loss: 0.3241782784461975
Batch 33/64 loss: 0.328718900680542
Batch 34/64 loss: 0.3386457562446594
Batch 35/64 loss: 0.3313257694244385
Batch 36/64 loss: 0.3261869549751282
Batch 37/64 loss: 0.330722451210022
Batch 38/64 loss: 0.3328595757484436
Batch 39/64 loss: 0.32900571823120117
Batch 40/64 loss: 0.3320881724357605
Batch 41/64 loss: 0.33060240745544434
Batch 42/64 loss: 0.3280295729637146
Batch 43/64 loss: 0.33436769247055054
Batch 44/64 loss: 0.33725714683532715
Batch 45/64 loss: 0.3315171003341675
Batch 46/64 loss: 0.33370673656463623
Batch 47/64 loss: 0.32753902673721313
Batch 48/64 loss: 0.33356744050979614
Batch 49/64 loss: 0.3304221034049988
Batch 50/64 loss: 0.3333991765975952
Batch 51/64 loss: 0.3344575762748718
Batch 52/64 loss: 0.33142995834350586
Batch 53/64 loss: 0.33124423027038574
Batch 54/64 loss: 0.32222938537597656
Batch 55/64 loss: 0.3234087824821472
Batch 56/64 loss: 0.3338470458984375
Batch 57/64 loss: 0.3294943571090698
Batch 58/64 loss: 0.33032864332199097
Batch 59/64 loss: 0.33081328868865967
Batch 60/64 loss: 0.3301734924316406
Batch 61/64 loss: 0.3352019190788269
Batch 62/64 loss: 0.3310115337371826
Batch 63/64 loss: 0.3313276171684265
Batch 64/64 loss: 0.33042335510253906
Epoch 183  Train loss: 0.33055510707930025  Val loss: 0.34151638557820796
Epoch 184
-------------------------------
Batch 1/64 loss: 0.33198559284210205
Batch 2/64 loss: 0.329273521900177
Batch 3/64 loss: 0.33569055795669556
Batch 4/64 loss: 0.33341658115386963
Batch 5/64 loss: 0.32822859287261963
Batch 6/64 loss: 0.3313089609146118
Batch 7/64 loss: 0.32752060890197754
Batch 8/64 loss: 0.33427441120147705
Batch 9/64 loss: 0.33339089155197144
Batch 10/64 loss: 0.32483547925949097
Batch 11/64 loss: 0.33252060413360596
Batch 12/64 loss: 0.33396995067596436
Batch 13/64 loss: 0.33164751529693604
Batch 14/64 loss: 0.3278282880783081
Batch 15/64 loss: 0.3320600986480713
Batch 16/64 loss: 0.33031219244003296
Batch 17/64 loss: 0.32990562915802
Batch 18/64 loss: 0.32252591848373413
Batch 19/64 loss: 0.33161723613739014
Batch 20/64 loss: 0.3282768130302429
Batch 21/64 loss: 0.33273065090179443
Batch 22/64 loss: 0.33600592613220215
Batch 23/64 loss: 0.32861411571502686
Batch 24/64 loss: 0.32964980602264404
Batch 25/64 loss: 0.33331841230392456
Batch 26/64 loss: 0.3254067897796631
Batch 27/64 loss: 0.32469815015792847
Batch 28/64 loss: 0.3328195810317993
Batch 29/64 loss: 0.33434540033340454
Batch 30/64 loss: 0.33128559589385986
Batch 31/64 loss: 0.32198941707611084
Batch 32/64 loss: 0.32673001289367676
Batch 33/64 loss: 0.3284783363342285
Batch 34/64 loss: 0.32783758640289307
Batch 35/64 loss: 0.33276093006134033
Batch 36/64 loss: 0.3330453038215637
Batch 37/64 loss: 0.33008068799972534
Batch 38/64 loss: 0.33191347122192383
Batch 39/64 loss: 0.33740121126174927
Batch 40/64 loss: 0.33370542526245117
Batch 41/64 loss: 0.3252542018890381
Batch 42/64 loss: 0.33280813694000244
Batch 43/64 loss: 0.3267483711242676
Batch 44/64 loss: 0.3326154351234436
Batch 45/64 loss: 0.3280547857284546
Batch 46/64 loss: 0.32515376806259155
Batch 47/64 loss: 0.3282312750816345
Batch 48/64 loss: 0.32968634366989136
Batch 49/64 loss: 0.32525599002838135
Batch 50/64 loss: 0.32770317792892456
Batch 51/64 loss: 0.3261629343032837
Batch 52/64 loss: 0.32798004150390625
Batch 53/64 loss: 0.328855037689209
Batch 54/64 loss: 0.33229291439056396
Batch 55/64 loss: 0.33666348457336426
Batch 56/64 loss: 0.3224157691001892
Batch 57/64 loss: 0.3278146982192993
Batch 58/64 loss: 0.32990145683288574
Batch 59/64 loss: 0.3280959725379944
Batch 60/64 loss: 0.32986390590667725
Batch 61/64 loss: 0.33397895097732544
Batch 62/64 loss: 0.3261435627937317
Batch 63/64 loss: 0.3345312476158142
Batch 64/64 loss: 0.3290212154388428
Epoch 184  Train loss: 0.3299824882956112  Val loss: 0.340864033838318
Epoch 185
-------------------------------
Batch 1/64 loss: 0.33445143699645996
Batch 2/64 loss: 0.3229196071624756
Batch 3/64 loss: 0.33104491233825684
Batch 4/64 loss: 0.3326162099838257
Batch 5/64 loss: 0.3273124694824219
Batch 6/64 loss: 0.3297327160835266
Batch 7/64 loss: 0.32921314239501953
Batch 8/64 loss: 0.321364164352417
Batch 9/64 loss: 0.3281458616256714
Batch 10/64 loss: 0.3289916515350342
Batch 11/64 loss: 0.3319213390350342
Batch 12/64 loss: 0.3302766680717468
Batch 13/64 loss: 0.33068978786468506
Batch 14/64 loss: 0.3282327651977539
Batch 15/64 loss: 0.33098411560058594
Batch 16/64 loss: 0.32876908779144287
Batch 17/64 loss: 0.3310006856918335
Batch 18/64 loss: 0.33138567209243774
Batch 19/64 loss: 0.3253031373023987
Batch 20/64 loss: 0.3310800790786743
Batch 21/64 loss: 0.33016282320022583
Batch 22/64 loss: 0.3289729356765747
Batch 23/64 loss: 0.32472890615463257
Batch 24/64 loss: 0.3301208019256592
Batch 25/64 loss: 0.33305656909942627
Batch 26/64 loss: 0.33420151472091675
Batch 27/64 loss: 0.3341132402420044
Batch 28/64 loss: 0.3336191177368164
Batch 29/64 loss: 0.3347752094268799
Batch 30/64 loss: 0.32783257961273193
Batch 31/64 loss: 0.3319278955459595
Batch 32/64 loss: 0.3314321041107178
Batch 33/64 loss: 0.3291264772415161
Batch 34/64 loss: 0.32934433221817017
Batch 35/64 loss: 0.3366934657096863
Batch 36/64 loss: 0.33362138271331787
Batch 37/64 loss: 0.3303818702697754
Batch 38/64 loss: 0.334079384803772
Batch 39/64 loss: 0.32782071828842163
Batch 40/64 loss: 0.32162731885910034
Batch 41/64 loss: 0.33566296100616455
Batch 42/64 loss: 0.32393646240234375
Batch 43/64 loss: 0.33259034156799316
Batch 44/64 loss: 0.33142638206481934
Batch 45/64 loss: 0.3299657106399536
Batch 46/64 loss: 0.33744901418685913
Batch 47/64 loss: 0.3284587264060974
Batch 48/64 loss: 0.3310234546661377
Batch 49/64 loss: 0.3299379348754883
Batch 50/64 loss: 0.3233538866043091
Batch 51/64 loss: 0.3295302391052246
Batch 52/64 loss: 0.32764744758605957
Batch 53/64 loss: 0.3286064863204956
Batch 54/64 loss: 0.3270910978317261
Batch 55/64 loss: 0.3313889503479004
Batch 56/64 loss: 0.33314502239227295
Batch 57/64 loss: 0.32833027839660645
Batch 58/64 loss: 0.33374959230422974
Batch 59/64 loss: 0.33247119188308716
Batch 60/64 loss: 0.33543968200683594
Batch 61/64 loss: 0.3325538635253906
Batch 62/64 loss: 0.33158689737319946
Batch 63/64 loss: 0.31805723905563354
Batch 64/64 loss: 0.3255457282066345
Epoch 185  Train loss: 0.3300491971128127  Val loss: 0.33991275784076286
Saving best model, epoch: 185
Epoch 186
-------------------------------
Batch 1/64 loss: 0.33817535638809204
Batch 2/64 loss: 0.33019936084747314
Batch 3/64 loss: 0.3250332474708557
Batch 4/64 loss: 0.32881057262420654
Batch 5/64 loss: 0.32872265577316284
Batch 6/64 loss: 0.32867109775543213
Batch 7/64 loss: 0.3271560072898865
Batch 8/64 loss: 0.32684868574142456
Batch 9/64 loss: 0.3360717296600342
Batch 10/64 loss: 0.331831693649292
Batch 11/64 loss: 0.32546162605285645
Batch 12/64 loss: 0.32785677909851074
Batch 13/64 loss: 0.33261823654174805
Batch 14/64 loss: 0.3270905017852783
Batch 15/64 loss: 0.32404083013534546
Batch 16/64 loss: 0.33231252431869507
Batch 17/64 loss: 0.3282606601715088
Batch 18/64 loss: 0.3374432325363159
Batch 19/64 loss: 0.3294020891189575
Batch 20/64 loss: 0.329867959022522
Batch 21/64 loss: 0.32966941595077515
Batch 22/64 loss: 0.3289964199066162
Batch 23/64 loss: 0.33176130056381226
Batch 24/64 loss: 0.3252004384994507
Batch 25/64 loss: 0.3361949920654297
Batch 26/64 loss: 0.3273938298225403
Batch 27/64 loss: 0.325858473777771
Batch 28/64 loss: 0.3357173204421997
Batch 29/64 loss: 0.3265596032142639
Batch 30/64 loss: 0.3300861120223999
Batch 31/64 loss: 0.32462984323501587
Batch 32/64 loss: 0.32758599519729614
Batch 33/64 loss: 0.33131927251815796
Batch 34/64 loss: 0.3355116844177246
Batch 35/64 loss: 0.3343668580055237
Batch 36/64 loss: 0.3247714042663574
Batch 37/64 loss: 0.33812618255615234
Batch 38/64 loss: 0.33014458417892456
Batch 39/64 loss: 0.33244389295578003
Batch 40/64 loss: 0.33738768100738525
Batch 41/64 loss: 0.33075839281082153
Batch 42/64 loss: 0.33234065771102905
Batch 43/64 loss: 0.3318967819213867
Batch 44/64 loss: 0.3258324861526489
Batch 45/64 loss: 0.3259042501449585
Batch 46/64 loss: 0.3338460326194763
Batch 47/64 loss: 0.33490467071533203
Batch 48/64 loss: 0.3200875520706177
Batch 49/64 loss: 0.3285483717918396
Batch 50/64 loss: 0.33552563190460205
Batch 51/64 loss: 0.32520973682403564
Batch 52/64 loss: 0.3313555121421814
Batch 53/64 loss: 0.3299846053123474
Batch 54/64 loss: 0.3320438265800476
Batch 55/64 loss: 0.33072078227996826
Batch 56/64 loss: 0.3270426392555237
Batch 57/64 loss: 0.3314613699913025
Batch 58/64 loss: 0.325064480304718
Batch 59/64 loss: 0.326546311378479
Batch 60/64 loss: 0.3358023762702942
Batch 61/64 loss: 0.3235865831375122
Batch 62/64 loss: 0.3277319669723511
Batch 63/64 loss: 0.3325290083885193
Batch 64/64 loss: 0.323606014251709
Epoch 186  Train loss: 0.32989848922280707  Val loss: 0.34042386459730745
Epoch 187
-------------------------------
Batch 1/64 loss: 0.32928037643432617
Batch 2/64 loss: 0.32711440324783325
Batch 3/64 loss: 0.3290312886238098
Batch 4/64 loss: 0.3255808353424072
Batch 5/64 loss: 0.3303396701812744
Batch 6/64 loss: 0.32799220085144043
Batch 7/64 loss: 0.32688093185424805
Batch 8/64 loss: 0.3279973864555359
Batch 9/64 loss: 0.33349549770355225
Batch 10/64 loss: 0.32870811223983765
Batch 11/64 loss: 0.33895343542099
Batch 12/64 loss: 0.32200920581817627
Batch 13/64 loss: 0.3285015821456909
Batch 14/64 loss: 0.3269479274749756
Batch 15/64 loss: 0.33059054613113403
Batch 16/64 loss: 0.32801878452301025
Batch 17/64 loss: 0.32642149925231934
Batch 18/64 loss: 0.33020055294036865
Batch 19/64 loss: 0.32296091318130493
Batch 20/64 loss: 0.3315310478210449
Batch 21/64 loss: 0.33281099796295166
Batch 22/64 loss: 0.32925915718078613
Batch 23/64 loss: 0.33409011363983154
Batch 24/64 loss: 0.33412909507751465
Batch 25/64 loss: 0.33149540424346924
Batch 26/64 loss: 0.3259766101837158
Batch 27/64 loss: 0.32879453897476196
Batch 28/64 loss: 0.33235472440719604
Batch 29/64 loss: 0.3292544484138489
Batch 30/64 loss: 0.33631062507629395
Batch 31/64 loss: 0.32630693912506104
Batch 32/64 loss: 0.3281792402267456
Batch 33/64 loss: 0.3370387554168701
Batch 34/64 loss: 0.33713841438293457
Batch 35/64 loss: 0.3260229825973511
Batch 36/64 loss: 0.32389652729034424
Batch 37/64 loss: 0.32841193675994873
Batch 38/64 loss: 0.32415592670440674
Batch 39/64 loss: 0.3290454149246216
Batch 40/64 loss: 0.324718177318573
Batch 41/64 loss: 0.32901692390441895
Batch 42/64 loss: 0.3321263790130615
Batch 43/64 loss: 0.3301389217376709
Batch 44/64 loss: 0.32254964113235474
Batch 45/64 loss: 0.3234342336654663
Batch 46/64 loss: 0.3305938243865967
Batch 47/64 loss: 0.33565741777420044
Batch 48/64 loss: 0.33289188146591187
Batch 49/64 loss: 0.32108163833618164
Batch 50/64 loss: 0.3303757905960083
Batch 51/64 loss: 0.32690227031707764
Batch 52/64 loss: 0.3307952880859375
Batch 53/64 loss: 0.3330279588699341
Batch 54/64 loss: 0.32944703102111816
Batch 55/64 loss: 0.33734816312789917
Batch 56/64 loss: 0.3260117769241333
Batch 57/64 loss: 0.3295687437057495
Batch 58/64 loss: 0.33605659008026123
Batch 59/64 loss: 0.3339880704879761
Batch 60/64 loss: 0.32932472229003906
Batch 61/64 loss: 0.3273008465766907
Batch 62/64 loss: 0.3364410400390625
Batch 63/64 loss: 0.32893258333206177
Batch 64/64 loss: 0.3304402828216553
Epoch 187  Train loss: 0.32961236355351464  Val loss: 0.34031677123197573
Epoch 188
-------------------------------
Batch 1/64 loss: 0.33067870140075684
Batch 2/64 loss: 0.32771849632263184
Batch 3/64 loss: 0.32928311824798584
Batch 4/64 loss: 0.32587677240371704
Batch 5/64 loss: 0.3314266800880432
Batch 6/64 loss: 0.330122709274292
Batch 7/64 loss: 0.3308151960372925
Batch 8/64 loss: 0.32549577951431274
Batch 9/64 loss: 0.33023715019226074
Batch 10/64 loss: 0.3282870054244995
Batch 11/64 loss: 0.33404576778411865
Batch 12/64 loss: 0.32341086864471436
Batch 13/64 loss: 0.32788050174713135
Batch 14/64 loss: 0.3308109641075134
Batch 15/64 loss: 0.32558929920196533
Batch 16/64 loss: 0.3333427906036377
Batch 17/64 loss: 0.32500171661376953
Batch 18/64 loss: 0.3272702693939209
Batch 19/64 loss: 0.32974278926849365
Batch 20/64 loss: 0.3247959613800049
Batch 21/64 loss: 0.328122615814209
Batch 22/64 loss: 0.33119630813598633
Batch 23/64 loss: 0.3324240446090698
Batch 24/64 loss: 0.32680338621139526
Batch 25/64 loss: 0.32983970642089844
Batch 26/64 loss: 0.3286423683166504
Batch 27/64 loss: 0.32889342308044434
Batch 28/64 loss: 0.32914459705352783
Batch 29/64 loss: 0.33958899974823
Batch 30/64 loss: 0.33538174629211426
Batch 31/64 loss: 0.330039381980896
Batch 32/64 loss: 0.3387589454650879
Batch 33/64 loss: 0.3272022008895874
Batch 34/64 loss: 0.3302130699157715
Batch 35/64 loss: 0.3299095630645752
Batch 36/64 loss: 0.32646679878234863
Batch 37/64 loss: 0.32916873693466187
Batch 38/64 loss: 0.3295869827270508
Batch 39/64 loss: 0.3316779136657715
Batch 40/64 loss: 0.32379579544067383
Batch 41/64 loss: 0.32794511318206787
Batch 42/64 loss: 0.3321709632873535
Batch 43/64 loss: 0.3248624801635742
Batch 44/64 loss: 0.33188772201538086
Batch 45/64 loss: 0.330647349357605
Batch 46/64 loss: 0.3285846710205078
Batch 47/64 loss: 0.32840263843536377
Batch 48/64 loss: 0.3257675766944885
Batch 49/64 loss: 0.3305656909942627
Batch 50/64 loss: 0.33121395111083984
Batch 51/64 loss: 0.3300212621688843
Batch 52/64 loss: 0.3272198438644409
Batch 53/64 loss: 0.331445574760437
Batch 54/64 loss: 0.32910776138305664
Batch 55/64 loss: 0.3286151885986328
Batch 56/64 loss: 0.32374751567840576
Batch 57/64 loss: 0.32901179790496826
Batch 58/64 loss: 0.32938826084136963
Batch 59/64 loss: 0.326617956161499
Batch 60/64 loss: 0.3342353105545044
Batch 61/64 loss: 0.32548773288726807
Batch 62/64 loss: 0.3258236050605774
Batch 63/64 loss: 0.33765482902526855
Batch 64/64 loss: 0.3221040964126587
Epoch 188  Train loss: 0.32926575670055314  Val loss: 0.33928548716187884
Saving best model, epoch: 188
Epoch 189
-------------------------------
Batch 1/64 loss: 0.32894444465637207
Batch 2/64 loss: 0.33073723316192627
Batch 3/64 loss: 0.33168208599090576
Batch 4/64 loss: 0.32927680015563965
Batch 5/64 loss: 0.3326440453529358
Batch 6/64 loss: 0.32812386751174927
Batch 7/64 loss: 0.32753050327301025
Batch 8/64 loss: 0.3287486433982849
Batch 9/64 loss: 0.32717466354370117
Batch 10/64 loss: 0.3245224952697754
Batch 11/64 loss: 0.32912707328796387
Batch 12/64 loss: 0.32976579666137695
Batch 13/64 loss: 0.32851600646972656
Batch 14/64 loss: 0.32367831468582153
Batch 15/64 loss: 0.3252435326576233
Batch 16/64 loss: 0.33108413219451904
Batch 17/64 loss: 0.3256326913833618
Batch 18/64 loss: 0.3337100148200989
Batch 19/64 loss: 0.33015793561935425
Batch 20/64 loss: 0.3277518153190613
Batch 21/64 loss: 0.32670527696609497
Batch 22/64 loss: 0.32629162073135376
Batch 23/64 loss: 0.3372029662132263
Batch 24/64 loss: 0.3250856399536133
Batch 25/64 loss: 0.32927405834198
Batch 26/64 loss: 0.33163607120513916
Batch 27/64 loss: 0.3295396566390991
Batch 28/64 loss: 0.3288543224334717
Batch 29/64 loss: 0.3235315680503845
Batch 30/64 loss: 0.333507776260376
Batch 31/64 loss: 0.3254346251487732
Batch 32/64 loss: 0.3291131258010864
Batch 33/64 loss: 0.32603925466537476
Batch 34/64 loss: 0.31804561614990234
Batch 35/64 loss: 0.32071614265441895
Batch 36/64 loss: 0.32729947566986084
Batch 37/64 loss: 0.33116793632507324
Batch 38/64 loss: 0.33136290311813354
Batch 39/64 loss: 0.3278540372848511
Batch 40/64 loss: 0.33316612243652344
Batch 41/64 loss: 0.32791000604629517
Batch 42/64 loss: 0.33396267890930176
Batch 43/64 loss: 0.32573825120925903
Batch 44/64 loss: 0.32866597175598145
Batch 45/64 loss: 0.33183443546295166
Batch 46/64 loss: 0.3341267704963684
Batch 47/64 loss: 0.3302456736564636
Batch 48/64 loss: 0.33397120237350464
Batch 49/64 loss: 0.3292989730834961
Batch 50/64 loss: 0.32402873039245605
Batch 51/64 loss: 0.3312264680862427
Batch 52/64 loss: 0.33057546615600586
Batch 53/64 loss: 0.33164048194885254
Batch 54/64 loss: 0.3339717388153076
Batch 55/64 loss: 0.3323923349380493
Batch 56/64 loss: 0.3323424458503723
Batch 57/64 loss: 0.329980731010437
Batch 58/64 loss: 0.3249400854110718
Batch 59/64 loss: 0.3275955319404602
Batch 60/64 loss: 0.3270070552825928
Batch 61/64 loss: 0.327598512172699
Batch 62/64 loss: 0.332813024520874
Batch 63/64 loss: 0.33410805463790894
Batch 64/64 loss: 0.33140069246292114
Epoch 189  Train loss: 0.3291043989798602  Val loss: 0.33963241015922574
Epoch 190
-------------------------------
Batch 1/64 loss: 0.3289775848388672
Batch 2/64 loss: 0.3256416320800781
Batch 3/64 loss: 0.33165526390075684
Batch 4/64 loss: 0.3266342878341675
Batch 5/64 loss: 0.3331444263458252
Batch 6/64 loss: 0.3287324905395508
Batch 7/64 loss: 0.33212774991989136
Batch 8/64 loss: 0.32730692625045776
Batch 9/64 loss: 0.33232301473617554
Batch 10/64 loss: 0.32562458515167236
Batch 11/64 loss: 0.33173853158950806
Batch 12/64 loss: 0.32945406436920166
Batch 13/64 loss: 0.3354575037956238
Batch 14/64 loss: 0.3285779356956482
Batch 15/64 loss: 0.3302069902420044
Batch 16/64 loss: 0.3257483243942261
Batch 17/64 loss: 0.3294529914855957
Batch 18/64 loss: 0.3294750452041626
Batch 19/64 loss: 0.32981520891189575
Batch 20/64 loss: 0.3312948942184448
Batch 21/64 loss: 0.32467663288116455
Batch 22/64 loss: 0.32783931493759155
Batch 23/64 loss: 0.32674622535705566
Batch 24/64 loss: 0.33403080701828003
Batch 25/64 loss: 0.3294672966003418
Batch 26/64 loss: 0.330772340297699
Batch 27/64 loss: 0.3261139392852783
Batch 28/64 loss: 0.33251166343688965
Batch 29/64 loss: 0.32896745204925537
Batch 30/64 loss: 0.3318987488746643
Batch 31/64 loss: 0.32461291551589966
Batch 32/64 loss: 0.32779479026794434
Batch 33/64 loss: 0.3273555636405945
Batch 34/64 loss: 0.3283313512802124
Batch 35/64 loss: 0.32733190059661865
Batch 36/64 loss: 0.3315736651420593
Batch 37/64 loss: 0.32944780588150024
Batch 38/64 loss: 0.3225153684616089
Batch 39/64 loss: 0.3218264579772949
Batch 40/64 loss: 0.33170831203460693
Batch 41/64 loss: 0.33259475231170654
Batch 42/64 loss: 0.32613855600357056
Batch 43/64 loss: 0.3311852216720581
Batch 44/64 loss: 0.3276877999305725
Batch 45/64 loss: 0.32477080821990967
Batch 46/64 loss: 0.327553391456604
Batch 47/64 loss: 0.3333345651626587
Batch 48/64 loss: 0.3224424123764038
Batch 49/64 loss: 0.3276258111000061
Batch 50/64 loss: 0.3279205560684204
Batch 51/64 loss: 0.328890323638916
Batch 52/64 loss: 0.32996320724487305
Batch 53/64 loss: 0.32919496297836304
Batch 54/64 loss: 0.3321436643600464
Batch 55/64 loss: 0.3254960775375366
Batch 56/64 loss: 0.3377380967140198
Batch 57/64 loss: 0.33526062965393066
Batch 58/64 loss: 0.3343532085418701
Batch 59/64 loss: 0.3299229145050049
Batch 60/64 loss: 0.3278697729110718
Batch 61/64 loss: 0.3269004821777344
Batch 62/64 loss: 0.3237706422805786
Batch 63/64 loss: 0.32578980922698975
Batch 64/64 loss: 0.3321434259414673
Epoch 190  Train loss: 0.329044191977557  Val loss: 0.34018199591292547
Epoch 191
-------------------------------
Batch 1/64 loss: 0.3242528438568115
Batch 2/64 loss: 0.33052945137023926
Batch 3/64 loss: 0.33401310443878174
Batch 4/64 loss: 0.3221515417098999
Batch 5/64 loss: 0.328210711479187
Batch 6/64 loss: 0.32806718349456787
Batch 7/64 loss: 0.3264206647872925
Batch 8/64 loss: 0.3311992883682251
Batch 9/64 loss: 0.3277229070663452
Batch 10/64 loss: 0.3283669948577881
Batch 11/64 loss: 0.3294713497161865
Batch 12/64 loss: 0.33266544342041016
Batch 13/64 loss: 0.32538658380508423
Batch 14/64 loss: 0.3286013603210449
Batch 15/64 loss: 0.3347501754760742
Batch 16/64 loss: 0.32336390018463135
Batch 17/64 loss: 0.3274974822998047
Batch 18/64 loss: 0.3311917781829834
Batch 19/64 loss: 0.3316218852996826
Batch 20/64 loss: 0.3277822732925415
Batch 21/64 loss: 0.3302187919616699
Batch 22/64 loss: 0.326121985912323
Batch 23/64 loss: 0.3274502754211426
Batch 24/64 loss: 0.32908737659454346
Batch 25/64 loss: 0.33039170503616333
Batch 26/64 loss: 0.32999658584594727
Batch 27/64 loss: 0.3317866325378418
Batch 28/64 loss: 0.3312280774116516
Batch 29/64 loss: 0.33020472526550293
Batch 30/64 loss: 0.33298617601394653
Batch 31/64 loss: 0.3224745988845825
Batch 32/64 loss: 0.3321060538291931
Batch 33/64 loss: 0.3296056389808655
Batch 34/64 loss: 0.33483296632766724
Batch 35/64 loss: 0.32547032833099365
Batch 36/64 loss: 0.33432984352111816
Batch 37/64 loss: 0.32368767261505127
Batch 38/64 loss: 0.3343158960342407
Batch 39/64 loss: 0.3331407308578491
Batch 40/64 loss: 0.32925695180892944
Batch 41/64 loss: 0.3262277841567993
Batch 42/64 loss: 0.3296865224838257
Batch 43/64 loss: 0.3319946527481079
Batch 44/64 loss: 0.32767558097839355
Batch 45/64 loss: 0.32375967502593994
Batch 46/64 loss: 0.32741373777389526
Batch 47/64 loss: 0.32488536834716797
Batch 48/64 loss: 0.328230619430542
Batch 49/64 loss: 0.3279774785041809
Batch 50/64 loss: 0.33385223150253296
Batch 51/64 loss: 0.3288723826408386
Batch 52/64 loss: 0.3250037431716919
Batch 53/64 loss: 0.3343544006347656
Batch 54/64 loss: 0.32899534702301025
Batch 55/64 loss: 0.3305545449256897
Batch 56/64 loss: 0.3311977982521057
Batch 57/64 loss: 0.32578861713409424
Batch 58/64 loss: 0.3283833861351013
Batch 59/64 loss: 0.3296271562576294
Batch 60/64 loss: 0.3279533386230469
Batch 61/64 loss: 0.329862117767334
Batch 62/64 loss: 0.324191153049469
Batch 63/64 loss: 0.3249446153640747
Batch 64/64 loss: 0.3250420093536377
Epoch 191  Train loss: 0.3288968422833611  Val loss: 0.3401813474307765
Epoch 192
-------------------------------
Batch 1/64 loss: 0.3272084593772888
Batch 2/64 loss: 0.327390193939209
Batch 3/64 loss: 0.32827186584472656
Batch 4/64 loss: 0.3239622116088867
Batch 5/64 loss: 0.3306766748428345
Batch 6/64 loss: 0.3248516321182251
Batch 7/64 loss: 0.32692718505859375
Batch 8/64 loss: 0.3295555114746094
Batch 9/64 loss: 0.3305807113647461
Batch 10/64 loss: 0.3279329538345337
Batch 11/64 loss: 0.3299781084060669
Batch 12/64 loss: 0.33189988136291504
Batch 13/64 loss: 0.3280563950538635
Batch 14/64 loss: 0.326108455657959
Batch 15/64 loss: 0.3298174738883972
Batch 16/64 loss: 0.331270694732666
Batch 17/64 loss: 0.3292287588119507
Batch 18/64 loss: 0.3339046239852905
Batch 19/64 loss: 0.33061647415161133
Batch 20/64 loss: 0.32129228115081787
Batch 21/64 loss: 0.3303415775299072
Batch 22/64 loss: 0.3289039134979248
Batch 23/64 loss: 0.32960081100463867
Batch 24/64 loss: 0.3312460780143738
Batch 25/64 loss: 0.328959584236145
Batch 26/64 loss: 0.32980549335479736
Batch 27/64 loss: 0.3264461159706116
Batch 28/64 loss: 0.32226115465164185
Batch 29/64 loss: 0.32617390155792236
Batch 30/64 loss: 0.3337213397026062
Batch 31/64 loss: 0.32371437549591064
Batch 32/64 loss: 0.3322386145591736
Batch 33/64 loss: 0.32810378074645996
Batch 34/64 loss: 0.3309438228607178
Batch 35/64 loss: 0.326577365398407
Batch 36/64 loss: 0.3289206027984619
Batch 37/64 loss: 0.335504412651062
Batch 38/64 loss: 0.32755011320114136
Batch 39/64 loss: 0.3235601782798767
Batch 40/64 loss: 0.33266013860702515
Batch 41/64 loss: 0.32901668548583984
Batch 42/64 loss: 0.3267648220062256
Batch 43/64 loss: 0.32995641231536865
Batch 44/64 loss: 0.33238863945007324
Batch 45/64 loss: 0.3307468295097351
Batch 46/64 loss: 0.331598699092865
Batch 47/64 loss: 0.33370691537857056
Batch 48/64 loss: 0.3321417570114136
Batch 49/64 loss: 0.32649755477905273
Batch 50/64 loss: 0.33442121744155884
Batch 51/64 loss: 0.32970094680786133
Batch 52/64 loss: 0.32985711097717285
Batch 53/64 loss: 0.32327723503112793
Batch 54/64 loss: 0.3297311067581177
Batch 55/64 loss: 0.3295688033103943
Batch 56/64 loss: 0.32602155208587646
Batch 57/64 loss: 0.3247886896133423
Batch 58/64 loss: 0.3330497741699219
Batch 59/64 loss: 0.32419776916503906
Batch 60/64 loss: 0.3283017873764038
Batch 61/64 loss: 0.332302451133728
Batch 62/64 loss: 0.3285118341445923
Batch 63/64 loss: 0.32782089710235596
Batch 64/64 loss: 0.329600989818573
Epoch 192  Train loss: 0.3289150455418755  Val loss: 0.33976850845559764
Epoch 193
-------------------------------
Batch 1/64 loss: 0.32895946502685547
Batch 2/64 loss: 0.3245219588279724
Batch 3/64 loss: 0.32984375953674316
Batch 4/64 loss: 0.32872694730758667
Batch 5/64 loss: 0.3222199082374573
Batch 6/64 loss: 0.32497549057006836
Batch 7/64 loss: 0.32640254497528076
Batch 8/64 loss: 0.3260469436645508
Batch 9/64 loss: 0.3322291970252991
Batch 10/64 loss: 0.3315994143486023
Batch 11/64 loss: 0.3270571231842041
Batch 12/64 loss: 0.33659815788269043
Batch 13/64 loss: 0.3299142122268677
Batch 14/64 loss: 0.3307018280029297
Batch 15/64 loss: 0.3282202482223511
Batch 16/64 loss: 0.3229180574417114
Batch 17/64 loss: 0.3349155783653259
Batch 18/64 loss: 0.3287200927734375
Batch 19/64 loss: 0.331994891166687
Batch 20/64 loss: 0.3296268582344055
Batch 21/64 loss: 0.3289170265197754
Batch 22/64 loss: 0.31666529178619385
Batch 23/64 loss: 0.32746076583862305
Batch 24/64 loss: 0.3229398727416992
Batch 25/64 loss: 0.3254515528678894
Batch 26/64 loss: 0.3299884796142578
Batch 27/64 loss: 0.32776087522506714
Batch 28/64 loss: 0.3323771357536316
Batch 29/64 loss: 0.3362668752670288
Batch 30/64 loss: 0.33312416076660156
Batch 31/64 loss: 0.3299984931945801
Batch 32/64 loss: 0.3262336254119873
Batch 33/64 loss: 0.33060693740844727
Batch 34/64 loss: 0.32606661319732666
Batch 35/64 loss: 0.3282088041305542
Batch 36/64 loss: 0.32663631439208984
Batch 37/64 loss: 0.3277713656425476
Batch 38/64 loss: 0.3282204866409302
Batch 39/64 loss: 0.32999157905578613
Batch 40/64 loss: 0.32491064071655273
Batch 41/64 loss: 0.32749831676483154
Batch 42/64 loss: 0.32951968908309937
Batch 43/64 loss: 0.3234190344810486
Batch 44/64 loss: 0.33429813385009766
Batch 45/64 loss: 0.3371955156326294
Batch 46/64 loss: 0.33228611946105957
Batch 47/64 loss: 0.3293873071670532
Batch 48/64 loss: 0.32471632957458496
Batch 49/64 loss: 0.3265342712402344
Batch 50/64 loss: 0.3274546265602112
Batch 51/64 loss: 0.3338679075241089
Batch 52/64 loss: 0.3255637288093567
Batch 53/64 loss: 0.32679814100265503
Batch 54/64 loss: 0.3362776041030884
Batch 55/64 loss: 0.33774328231811523
Batch 56/64 loss: 0.3270193338394165
Batch 57/64 loss: 0.3290082812309265
Batch 58/64 loss: 0.32327592372894287
Batch 59/64 loss: 0.329028844833374
Batch 60/64 loss: 0.3263842463493347
Batch 61/64 loss: 0.3193931579589844
Batch 62/64 loss: 0.3289475440979004
Batch 63/64 loss: 0.32765549421310425
Batch 64/64 loss: 0.3246511220932007
Epoch 193  Train loss: 0.3285105999778299  Val loss: 0.3392076307965308
Saving best model, epoch: 193
Epoch 194
-------------------------------
Batch 1/64 loss: 0.3243452310562134
Batch 2/64 loss: 0.3318755626678467
Batch 3/64 loss: 0.3296774625778198
Batch 4/64 loss: 0.33297276496887207
Batch 5/64 loss: 0.3337857723236084
Batch 6/64 loss: 0.32977747917175293
Batch 7/64 loss: 0.3294467329978943
Batch 8/64 loss: 0.3241720199584961
Batch 9/64 loss: 0.3327319025993347
Batch 10/64 loss: 0.32457613945007324
Batch 11/64 loss: 0.3260852098464966
Batch 12/64 loss: 0.33096843957901
Batch 13/64 loss: 0.32578492164611816
Batch 14/64 loss: 0.32817792892456055
Batch 15/64 loss: 0.33030450344085693
Batch 16/64 loss: 0.3270312547683716
Batch 17/64 loss: 0.3364577889442444
Batch 18/64 loss: 0.328433632850647
Batch 19/64 loss: 0.33059465885162354
Batch 20/64 loss: 0.32839852571487427
Batch 21/64 loss: 0.3217201232910156
Batch 22/64 loss: 0.33204835653305054
Batch 23/64 loss: 0.3369563817977905
Batch 24/64 loss: 0.3224056363105774
Batch 25/64 loss: 0.33268946409225464
Batch 26/64 loss: 0.3312046527862549
Batch 27/64 loss: 0.3262495994567871
Batch 28/64 loss: 0.3271753787994385
Batch 29/64 loss: 0.3288991451263428
Batch 30/64 loss: 0.3271366357803345
Batch 31/64 loss: 0.322690486907959
Batch 32/64 loss: 0.3294011354446411
Batch 33/64 loss: 0.3243902325630188
Batch 34/64 loss: 0.326299786567688
Batch 35/64 loss: 0.3245570659637451
Batch 36/64 loss: 0.32787734270095825
Batch 37/64 loss: 0.3278050422668457
Batch 38/64 loss: 0.32877659797668457
Batch 39/64 loss: 0.32868456840515137
Batch 40/64 loss: 0.32839465141296387
Batch 41/64 loss: 0.33119237422943115
Batch 42/64 loss: 0.32150113582611084
Batch 43/64 loss: 0.3247241973876953
Batch 44/64 loss: 0.3257397413253784
Batch 45/64 loss: 0.3259460926055908
Batch 46/64 loss: 0.33119094371795654
Batch 47/64 loss: 0.32841956615448
Batch 48/64 loss: 0.3302000164985657
Batch 49/64 loss: 0.32644474506378174
Batch 50/64 loss: 0.3265504837036133
Batch 51/64 loss: 0.3278403878211975
Batch 52/64 loss: 0.32595688104629517
Batch 53/64 loss: 0.32530635595321655
Batch 54/64 loss: 0.3298187255859375
Batch 55/64 loss: 0.32437193393707275
Batch 56/64 loss: 0.33490508794784546
Batch 57/64 loss: 0.32977020740509033
Batch 58/64 loss: 0.3290698528289795
Batch 59/64 loss: 0.3275746703147888
Batch 60/64 loss: 0.32685935497283936
Batch 61/64 loss: 0.3223940134048462
Batch 62/64 loss: 0.335948646068573
Batch 63/64 loss: 0.33051520586013794
Batch 64/64 loss: 0.3215946555137634
Epoch 194  Train loss: 0.32822583259320726  Val loss: 0.33945180050695883
Epoch 195
-------------------------------
Batch 1/64 loss: 0.323736310005188
Batch 2/64 loss: 0.3381608724594116
Batch 3/64 loss: 0.32360053062438965
Batch 4/64 loss: 0.3246830105781555
Batch 5/64 loss: 0.3266756534576416
Batch 6/64 loss: 0.3296833038330078
Batch 7/64 loss: 0.3274644613265991
Batch 8/64 loss: 0.33839499950408936
Batch 9/64 loss: 0.33253002166748047
Batch 10/64 loss: 0.3226912021636963
Batch 11/64 loss: 0.32037967443466187
Batch 12/64 loss: 0.3232152462005615
Batch 13/64 loss: 0.32839030027389526
Batch 14/64 loss: 0.3322656750679016
Batch 15/64 loss: 0.33155280351638794
Batch 16/64 loss: 0.32813024520874023
Batch 17/64 loss: 0.3250306248664856
Batch 18/64 loss: 0.33257216215133667
Batch 19/64 loss: 0.32676613330841064
Batch 20/64 loss: 0.3285316824913025
Batch 21/64 loss: 0.3245696425437927
Batch 22/64 loss: 0.3234260082244873
Batch 23/64 loss: 0.33556580543518066
Batch 24/64 loss: 0.3298189640045166
Batch 25/64 loss: 0.32401418685913086
Batch 26/64 loss: 0.32906049489974976
Batch 27/64 loss: 0.33058953285217285
Batch 28/64 loss: 0.32647573947906494
Batch 29/64 loss: 0.3283911943435669
Batch 30/64 loss: 0.3268980383872986
Batch 31/64 loss: 0.32922279834747314
Batch 32/64 loss: 0.33008670806884766
Batch 33/64 loss: 0.32785797119140625
Batch 34/64 loss: 0.32206350564956665
Batch 35/64 loss: 0.3297830820083618
Batch 36/64 loss: 0.3310081958770752
Batch 37/64 loss: 0.3232124447822571
Batch 38/64 loss: 0.3342350721359253
Batch 39/64 loss: 0.3281996250152588
Batch 40/64 loss: 0.33138394355773926
Batch 41/64 loss: 0.32719820737838745
Batch 42/64 loss: 0.3233288526535034
Batch 43/64 loss: 0.3255718946456909
Batch 44/64 loss: 0.327971875667572
Batch 45/64 loss: 0.33224600553512573
Batch 46/64 loss: 0.3266356587409973
Batch 47/64 loss: 0.3327903747558594
Batch 48/64 loss: 0.3333125114440918
Batch 49/64 loss: 0.32930445671081543
Batch 50/64 loss: 0.33168482780456543
Batch 51/64 loss: 0.3360704183578491
Batch 52/64 loss: 0.3294535279273987
Batch 53/64 loss: 0.3291161060333252
Batch 54/64 loss: 0.32762497663497925
Batch 55/64 loss: 0.3220946788787842
Batch 56/64 loss: 0.327314555644989
Batch 57/64 loss: 0.32528454065322876
Batch 58/64 loss: 0.32969850301742554
Batch 59/64 loss: 0.3315050005912781
Batch 60/64 loss: 0.3231147527694702
Batch 61/64 loss: 0.3257887363433838
Batch 62/64 loss: 0.32989150285720825
Batch 63/64 loss: 0.3230758309364319
Batch 64/64 loss: 0.32673847675323486
Epoch 195  Train loss: 0.3282423454172471  Val loss: 0.33943162300332713
Epoch 196
-------------------------------
Batch 1/64 loss: 0.33341580629348755
Batch 2/64 loss: 0.32568347454071045
Batch 3/64 loss: 0.3209350109100342
Batch 4/64 loss: 0.32370591163635254
Batch 5/64 loss: 0.3302501440048218
Batch 6/64 loss: 0.3342357873916626
Batch 7/64 loss: 0.32019686698913574
Batch 8/64 loss: 0.3254506587982178
Batch 9/64 loss: 0.33709001541137695
Batch 10/64 loss: 0.3241492509841919
Batch 11/64 loss: 0.3242485523223877
Batch 12/64 loss: 0.32799971103668213
Batch 13/64 loss: 0.32029032707214355
Batch 14/64 loss: 0.3272055983543396
Batch 15/64 loss: 0.3260418176651001
Batch 16/64 loss: 0.3225775361061096
Batch 17/64 loss: 0.3295568823814392
Batch 18/64 loss: 0.3317478895187378
Batch 19/64 loss: 0.32857662439346313
Batch 20/64 loss: 0.32999342679977417
Batch 21/64 loss: 0.32930123805999756
Batch 22/64 loss: 0.3284398913383484
Batch 23/64 loss: 0.329526424407959
Batch 24/64 loss: 0.325386643409729
Batch 25/64 loss: 0.32854586839675903
Batch 26/64 loss: 0.3277973532676697
Batch 27/64 loss: 0.3269444704055786
Batch 28/64 loss: 0.3303849697113037
Batch 29/64 loss: 0.32975804805755615
Batch 30/64 loss: 0.33154261112213135
Batch 31/64 loss: 0.33130908012390137
Batch 32/64 loss: 0.32648634910583496
Batch 33/64 loss: 0.3244246244430542
Batch 34/64 loss: 0.3237917423248291
Batch 35/64 loss: 0.324135422706604
Batch 36/64 loss: 0.32397496700286865
Batch 37/64 loss: 0.3289734125137329
Batch 38/64 loss: 0.3262926936149597
Batch 39/64 loss: 0.3276994228363037
Batch 40/64 loss: 0.3255563974380493
Batch 41/64 loss: 0.33089911937713623
Batch 42/64 loss: 0.3218139410018921
Batch 43/64 loss: 0.3265819549560547
Batch 44/64 loss: 0.3238332271575928
Batch 45/64 loss: 0.31799155473709106
Batch 46/64 loss: 0.3305357098579407
Batch 47/64 loss: 0.32776838541030884
Batch 48/64 loss: 0.32621753215789795
Batch 49/64 loss: 0.3303913474082947
Batch 50/64 loss: 0.330478310585022
Batch 51/64 loss: 0.33545297384262085
Batch 52/64 loss: 0.32586395740509033
Batch 53/64 loss: 0.32589781284332275
Batch 54/64 loss: 0.33510643243789673
Batch 55/64 loss: 0.3324488401412964
Batch 56/64 loss: 0.3297990560531616
Batch 57/64 loss: 0.32427752017974854
Batch 58/64 loss: 0.33188068866729736
Batch 59/64 loss: 0.3318899869918823
Batch 60/64 loss: 0.3287901282310486
Batch 61/64 loss: 0.3259533643722534
Batch 62/64 loss: 0.331302285194397
Batch 63/64 loss: 0.3292173147201538
Batch 64/64 loss: 0.33216071128845215
Epoch 196  Train loss: 0.32779819451126396  Val loss: 0.3385720384079976
Saving best model, epoch: 196
Epoch 197
-------------------------------
Batch 1/64 loss: 0.32740676403045654
Batch 2/64 loss: 0.3265978693962097
Batch 3/64 loss: 0.32785189151763916
Batch 4/64 loss: 0.32705259323120117
Batch 5/64 loss: 0.3231872320175171
Batch 6/64 loss: 0.3234115242958069
Batch 7/64 loss: 0.3297984004020691
Batch 8/64 loss: 0.3269765377044678
Batch 9/64 loss: 0.3283696174621582
Batch 10/64 loss: 0.32300829887390137
Batch 11/64 loss: 0.3254258632659912
Batch 12/64 loss: 0.33345460891723633
Batch 13/64 loss: 0.328666090965271
Batch 14/64 loss: 0.32623934745788574
Batch 15/64 loss: 0.3306719660758972
Batch 16/64 loss: 0.3280779719352722
Batch 17/64 loss: 0.3285883665084839
Batch 18/64 loss: 0.3289734721183777
Batch 19/64 loss: 0.3279949426651001
Batch 20/64 loss: 0.3238542675971985
Batch 21/64 loss: 0.32514387369155884
Batch 22/64 loss: 0.3253304958343506
Batch 23/64 loss: 0.3273959755897522
Batch 24/64 loss: 0.3272284269332886
Batch 25/64 loss: 0.3269171714782715
Batch 26/64 loss: 0.3323397636413574
Batch 27/64 loss: 0.3245912790298462
Batch 28/64 loss: 0.32120776176452637
Batch 29/64 loss: 0.33065634965896606
Batch 30/64 loss: 0.3205326795578003
Batch 31/64 loss: 0.32533490657806396
Batch 32/64 loss: 0.32412755489349365
Batch 33/64 loss: 0.3257144093513489
Batch 34/64 loss: 0.32819080352783203
Batch 35/64 loss: 0.3272780179977417
Batch 36/64 loss: 0.32562029361724854
Batch 37/64 loss: 0.3356156349182129
Batch 38/64 loss: 0.32311785221099854
Batch 39/64 loss: 0.3258708715438843
Batch 40/64 loss: 0.3256879448890686
Batch 41/64 loss: 0.328216016292572
Batch 42/64 loss: 0.3339660167694092
Batch 43/64 loss: 0.32294321060180664
Batch 44/64 loss: 0.32665038108825684
Batch 45/64 loss: 0.3303401470184326
Batch 46/64 loss: 0.3294416069984436
Batch 47/64 loss: 0.33027344942092896
Batch 48/64 loss: 0.3300502300262451
Batch 49/64 loss: 0.3268686532974243
Batch 50/64 loss: 0.32998478412628174
Batch 51/64 loss: 0.33271241188049316
Batch 52/64 loss: 0.32590848207473755
Batch 53/64 loss: 0.3353379964828491
Batch 54/64 loss: 0.32886040210723877
Batch 55/64 loss: 0.3287705183029175
Batch 56/64 loss: 0.32910025119781494
Batch 57/64 loss: 0.33019524812698364
Batch 58/64 loss: 0.33020973205566406
Batch 59/64 loss: 0.32380157709121704
Batch 60/64 loss: 0.32177913188934326
Batch 61/64 loss: 0.3280327320098877
Batch 62/64 loss: 0.32457202672958374
Batch 63/64 loss: 0.3304600715637207
Batch 64/64 loss: 0.33027827739715576
Epoch 197  Train loss: 0.327524603581896  Val loss: 0.33995261839574964
Epoch 198
-------------------------------
Batch 1/64 loss: 0.3249053955078125
Batch 2/64 loss: 0.32608580589294434
Batch 3/64 loss: 0.3338116407394409
Batch 4/64 loss: 0.3243674635887146
Batch 5/64 loss: 0.32862722873687744
Batch 6/64 loss: 0.32654398679733276
Batch 7/64 loss: 0.32430630922317505
Batch 8/64 loss: 0.33525514602661133
Batch 9/64 loss: 0.3283872604370117
Batch 10/64 loss: 0.3276914358139038
Batch 11/64 loss: 0.33933740854263306
Batch 12/64 loss: 0.3236750364303589
Batch 13/64 loss: 0.33013415336608887
Batch 14/64 loss: 0.3281625509262085
Batch 15/64 loss: 0.32495546340942383
Batch 16/64 loss: 0.32455140352249146
Batch 17/64 loss: 0.32761263847351074
Batch 18/64 loss: 0.32234853506088257
Batch 19/64 loss: 0.32252824306488037
Batch 20/64 loss: 0.3276776075363159
Batch 21/64 loss: 0.3268868923187256
Batch 22/64 loss: 0.3311288356781006
Batch 23/64 loss: 0.3294452428817749
Batch 24/64 loss: 0.3227958679199219
Batch 25/64 loss: 0.3231710195541382
Batch 26/64 loss: 0.3295050859451294
Batch 27/64 loss: 0.32955288887023926
Batch 28/64 loss: 0.33796846866607666
Batch 29/64 loss: 0.337799608707428
Batch 30/64 loss: 0.31837713718414307
Batch 31/64 loss: 0.33131080865859985
Batch 32/64 loss: 0.33005285263061523
Batch 33/64 loss: 0.325222373008728
Batch 34/64 loss: 0.3306669592857361
Batch 35/64 loss: 0.33490926027297974
Batch 36/64 loss: 0.3263779878616333
Batch 37/64 loss: 0.3336150050163269
Batch 38/64 loss: 0.32284724712371826
Batch 39/64 loss: 0.32610368728637695
Batch 40/64 loss: 0.32413017749786377
Batch 41/64 loss: 0.32518863677978516
Batch 42/64 loss: 0.32481807470321655
Batch 43/64 loss: 0.3326990008354187
Batch 44/64 loss: 0.3230377435684204
Batch 45/64 loss: 0.32850730419158936
Batch 46/64 loss: 0.32414114475250244
Batch 47/64 loss: 0.32864677906036377
Batch 48/64 loss: 0.325045108795166
Batch 49/64 loss: 0.32968413829803467
Batch 50/64 loss: 0.33101046085357666
Batch 51/64 loss: 0.32239896059036255
Batch 52/64 loss: 0.3251779079437256
Batch 53/64 loss: 0.3281240463256836
Batch 54/64 loss: 0.3278433084487915
Batch 55/64 loss: 0.3253478407859802
Batch 56/64 loss: 0.325808584690094
Batch 57/64 loss: 0.32342803478240967
Batch 58/64 loss: 0.32268089056015015
Batch 59/64 loss: 0.32602936029434204
Batch 60/64 loss: 0.33068525791168213
Batch 61/64 loss: 0.3234352469444275
Batch 62/64 loss: 0.3310936689376831
Batch 63/64 loss: 0.32305586338043213
Batch 64/64 loss: 0.33257555961608887
Epoch 198  Train loss: 0.32753178278605144  Val loss: 0.33852939835119084
Saving best model, epoch: 198
Epoch 199
-------------------------------
Batch 1/64 loss: 0.32969868183135986
Batch 2/64 loss: 0.3236091732978821
Batch 3/64 loss: 0.32429277896881104
Batch 4/64 loss: 0.32469642162323
Batch 5/64 loss: 0.3252960443496704
Batch 6/64 loss: 0.3259110450744629
Batch 7/64 loss: 0.32444918155670166
Batch 8/64 loss: 0.3296823501586914
Batch 9/64 loss: 0.3272368907928467
Batch 10/64 loss: 0.3287421464920044
Batch 11/64 loss: 0.32895737886428833
Batch 12/64 loss: 0.32907021045684814
Batch 13/64 loss: 0.32377099990844727
Batch 14/64 loss: 0.32618260383605957
Batch 15/64 loss: 0.3275004029273987
Batch 16/64 loss: 0.3261592984199524
Batch 17/64 loss: 0.33195745944976807
Batch 18/64 loss: 0.3265358805656433
Batch 19/64 loss: 0.3265427350997925
Batch 20/64 loss: 0.32700514793395996
Batch 21/64 loss: 0.3255341053009033
Batch 22/64 loss: 0.3273977041244507
Batch 23/64 loss: 0.3259347677230835
Batch 24/64 loss: 0.33016085624694824
Batch 25/64 loss: 0.3203917145729065
Batch 26/64 loss: 0.32582753896713257
Batch 27/64 loss: 0.3215070366859436
Batch 28/64 loss: 0.33152318000793457
Batch 29/64 loss: 0.3231295943260193
Batch 30/64 loss: 0.3265559673309326
Batch 31/64 loss: 0.32740914821624756
Batch 32/64 loss: 0.33273375034332275
Batch 33/64 loss: 0.32111507654190063
Batch 34/64 loss: 0.328033983707428
Batch 35/64 loss: 0.3262239694595337
Batch 36/64 loss: 0.3204575777053833
Batch 37/64 loss: 0.3321991562843323
Batch 38/64 loss: 0.326448917388916
Batch 39/64 loss: 0.32635247707366943
Batch 40/64 loss: 0.3299081325531006
Batch 41/64 loss: 0.323495090007782
Batch 42/64 loss: 0.32853180170059204
Batch 43/64 loss: 0.33228451013565063
Batch 44/64 loss: 0.32527709007263184
Batch 45/64 loss: 0.3241661787033081
Batch 46/64 loss: 0.3278059959411621
Batch 47/64 loss: 0.3336517810821533
Batch 48/64 loss: 0.32305359840393066
Batch 49/64 loss: 0.33047086000442505
Batch 50/64 loss: 0.3241109848022461
Batch 51/64 loss: 0.3301069736480713
Batch 52/64 loss: 0.32987117767333984
Batch 53/64 loss: 0.3238736391067505
Batch 54/64 loss: 0.3251118063926697
Batch 55/64 loss: 0.32637691497802734
Batch 56/64 loss: 0.3292337656021118
Batch 57/64 loss: 0.32424622774124146
Batch 58/64 loss: 0.3316236138343811
Batch 59/64 loss: 0.3363655209541321
Batch 60/64 loss: 0.3249779939651489
Batch 61/64 loss: 0.32350218296051025
Batch 62/64 loss: 0.3328660726547241
Batch 63/64 loss: 0.3246150016784668
Batch 64/64 loss: 0.3312693238258362
Epoch 199  Train loss: 0.32706215311499204  Val loss: 0.33868987822450725
Epoch 200
-------------------------------
Batch 1/64 loss: 0.3259989619255066
Batch 2/64 loss: 0.32539689540863037
Batch 3/64 loss: 0.32074952125549316
Batch 4/64 loss: 0.3289680480957031
Batch 5/64 loss: 0.325495183467865
Batch 6/64 loss: 0.32906001806259155
Batch 7/64 loss: 0.3325841426849365
Batch 8/64 loss: 0.3259580731391907
Batch 9/64 loss: 0.32768166065216064
Batch 10/64 loss: 0.32224041223526
Batch 11/64 loss: 0.32436662912368774
Batch 12/64 loss: 0.3241115212440491
Batch 13/64 loss: 0.3272963762283325
Batch 14/64 loss: 0.32942259311676025
Batch 15/64 loss: 0.3287006616592407
Batch 16/64 loss: 0.32281243801116943
Batch 17/64 loss: 0.31974470615386963
Batch 18/64 loss: 0.3270423412322998
Batch 19/64 loss: 0.3254281282424927
Batch 20/64 loss: 0.32524871826171875
Batch 21/64 loss: 0.32748550176620483
Batch 22/64 loss: 0.3311648368835449
Batch 23/64 loss: 0.3310704231262207
Batch 24/64 loss: 0.3200939893722534
Batch 25/64 loss: 0.32041579484939575
Batch 26/64 loss: 0.3200151324272156
Batch 27/64 loss: 0.32905733585357666
Batch 28/64 loss: 0.3309018611907959
Batch 29/64 loss: 0.3318026661872864
Batch 30/64 loss: 0.3270130753517151
Batch 31/64 loss: 0.3294830322265625
Batch 32/64 loss: 0.3309614658355713
Batch 33/64 loss: 0.32837724685668945
Batch 34/64 loss: 0.3260977268218994
Batch 35/64 loss: 0.3287465572357178
Batch 36/64 loss: 0.32708513736724854
Batch 37/64 loss: 0.3265497088432312
Batch 38/64 loss: 0.33467376232147217
Batch 39/64 loss: 0.3244667649269104
Batch 40/64 loss: 0.3252676725387573
Batch 41/64 loss: 0.3199084997177124
Batch 42/64 loss: 0.3289027810096741
Batch 43/64 loss: 0.32997632026672363
Batch 44/64 loss: 0.3301606774330139
Batch 45/64 loss: 0.328865647315979
Batch 46/64 loss: 0.32867521047592163
Batch 47/64 loss: 0.32478225231170654
Batch 48/64 loss: 0.3233448266983032
Batch 49/64 loss: 0.32942765951156616
Batch 50/64 loss: 0.329850435256958
Batch 51/64 loss: 0.33211779594421387
Batch 52/64 loss: 0.32647985219955444
Batch 53/64 loss: 0.3249615430831909
Batch 54/64 loss: 0.3325779438018799
Batch 55/64 loss: 0.32577621936798096
Batch 56/64 loss: 0.330211341381073
Batch 57/64 loss: 0.32857680320739746
Batch 58/64 loss: 0.32594096660614014
Batch 59/64 loss: 0.3199728727340698
Batch 60/64 loss: 0.326443612575531
Batch 61/64 loss: 0.32103651762008667
Batch 62/64 loss: 0.32717186212539673
Batch 63/64 loss: 0.3232182264328003
Batch 64/64 loss: 0.32877492904663086
Epoch 200  Train loss: 0.32680780840855017  Val loss: 0.3391338476200694
Epoch 201
-------------------------------
Batch 1/64 loss: 0.3271118402481079
Batch 2/64 loss: 0.32539963722229004
Batch 3/64 loss: 0.3193052411079407
Batch 4/64 loss: 0.3270469307899475
Batch 5/64 loss: 0.3254193663597107
Batch 6/64 loss: 0.3263273239135742
Batch 7/64 loss: 0.3283233642578125
Batch 8/64 loss: 0.32906556129455566
Batch 9/64 loss: 0.32864058017730713
Batch 10/64 loss: 0.32510679960250854
Batch 11/64 loss: 0.3268950581550598
Batch 12/64 loss: 0.3310709595680237
Batch 13/64 loss: 0.3253828287124634
Batch 14/64 loss: 0.3261789083480835
Batch 15/64 loss: 0.33063942193984985
Batch 16/64 loss: 0.32465213537216187
Batch 17/64 loss: 0.32392871379852295
Batch 18/64 loss: 0.3287654519081116
Batch 19/64 loss: 0.32747215032577515
Batch 20/64 loss: 0.3218821883201599
Batch 21/64 loss: 0.32360613346099854
Batch 22/64 loss: 0.3275367021560669
Batch 23/64 loss: 0.3258708715438843
Batch 24/64 loss: 0.3221883177757263
Batch 25/64 loss: 0.32690805196762085
Batch 26/64 loss: 0.3239952325820923
Batch 27/64 loss: 0.3299661874771118
Batch 28/64 loss: 0.32265639305114746
Batch 29/64 loss: 0.3225215673446655
Batch 30/64 loss: 0.326074481010437
Batch 31/64 loss: 0.3260011672973633
Batch 32/64 loss: 0.3292011022567749
Batch 33/64 loss: 0.3277108669281006
Batch 34/64 loss: 0.323458194732666
Batch 35/64 loss: 0.32958143949508667
Batch 36/64 loss: 0.3250085711479187
Batch 37/64 loss: 0.3292347192764282
Batch 38/64 loss: 0.32219433784484863
Batch 39/64 loss: 0.3202468156814575
Batch 40/64 loss: 0.32710719108581543
Batch 41/64 loss: 0.33014780282974243
Batch 42/64 loss: 0.3256957530975342
Batch 43/64 loss: 0.33730554580688477
Batch 44/64 loss: 0.32195907831192017
Batch 45/64 loss: 0.333463191986084
Batch 46/64 loss: 0.3278769254684448
Batch 47/64 loss: 0.32778310775756836
Batch 48/64 loss: 0.32873594760894775
Batch 49/64 loss: 0.32948851585388184
Batch 50/64 loss: 0.32644957304000854
Batch 51/64 loss: 0.32581108808517456
Batch 52/64 loss: 0.3242456316947937
Batch 53/64 loss: 0.33211708068847656
Batch 54/64 loss: 0.32283520698547363
Batch 55/64 loss: 0.32870203256607056
Batch 56/64 loss: 0.3281902074813843
Batch 57/64 loss: 0.32737791538238525
Batch 58/64 loss: 0.33562564849853516
Batch 59/64 loss: 0.32473790645599365
Batch 60/64 loss: 0.3290673494338989
Batch 61/64 loss: 0.32487547397613525
Batch 62/64 loss: 0.32173800468444824
Batch 63/64 loss: 0.3297877311706543
Batch 64/64 loss: 0.33118343353271484
Epoch 201  Train loss: 0.3267778368557201  Val loss: 0.3385561876690265
Epoch 202
-------------------------------
Batch 1/64 loss: 0.32660770416259766
Batch 2/64 loss: 0.3189884424209595
Batch 3/64 loss: 0.3278537392616272
Batch 4/64 loss: 0.3301694393157959
Batch 5/64 loss: 0.3287976384162903
Batch 6/64 loss: 0.32416319847106934
Batch 7/64 loss: 0.32568174600601196
Batch 8/64 loss: 0.32629311084747314
Batch 9/64 loss: 0.32104915380477905
Batch 10/64 loss: 0.3292275667190552
Batch 11/64 loss: 0.3254135847091675
Batch 12/64 loss: 0.32470887899398804
Batch 13/64 loss: 0.33270442485809326
Batch 14/64 loss: 0.3217160105705261
Batch 15/64 loss: 0.3280891180038452
Batch 16/64 loss: 0.32718896865844727
Batch 17/64 loss: 0.3199728727340698
Batch 18/64 loss: 0.3223111629486084
Batch 19/64 loss: 0.33248472213745117
Batch 20/64 loss: 0.32682347297668457
Batch 21/64 loss: 0.33479398488998413
Batch 22/64 loss: 0.32432687282562256
Batch 23/64 loss: 0.32969343662261963
Batch 24/64 loss: 0.32014262676239014
Batch 25/64 loss: 0.32441627979278564
Batch 26/64 loss: 0.329669713973999
Batch 27/64 loss: 0.3330031633377075
Batch 28/64 loss: 0.3281272053718567
Batch 29/64 loss: 0.3271198272705078
Batch 30/64 loss: 0.3345913290977478
Batch 31/64 loss: 0.32377344369888306
Batch 32/64 loss: 0.3289068937301636
Batch 33/64 loss: 0.327396035194397
Batch 34/64 loss: 0.3261582851409912
Batch 35/64 loss: 0.3228832483291626
Batch 36/64 loss: 0.3271522521972656
Batch 37/64 loss: 0.33073413372039795
Batch 38/64 loss: 0.3281232714653015
Batch 39/64 loss: 0.32768678665161133
Batch 40/64 loss: 0.325348436832428
Batch 41/64 loss: 0.32244038581848145
Batch 42/64 loss: 0.3240528702735901
Batch 43/64 loss: 0.33159899711608887
Batch 44/64 loss: 0.3259701728820801
Batch 45/64 loss: 0.32446491718292236
Batch 46/64 loss: 0.32552528381347656
Batch 47/64 loss: 0.3289494514465332
Batch 48/64 loss: 0.32407939434051514
Batch 49/64 loss: 0.33094775676727295
Batch 50/64 loss: 0.3276898264884949
Batch 51/64 loss: 0.3391760587692261
Batch 52/64 loss: 0.33048200607299805
Batch 53/64 loss: 0.32363057136535645
Batch 54/64 loss: 0.3298304080963135
Batch 55/64 loss: 0.3324958086013794
Batch 56/64 loss: 0.3267905116081238
Batch 57/64 loss: 0.3249443769454956
Batch 58/64 loss: 0.3296504020690918
Batch 59/64 loss: 0.33420032262802124
Batch 60/64 loss: 0.3225829601287842
Batch 61/64 loss: 0.3265186548233032
Batch 62/64 loss: 0.323616623878479
Batch 63/64 loss: 0.3227308392524719
Batch 64/64 loss: 0.3243480920791626
Epoch 202  Train loss: 0.3270575976839252  Val loss: 0.33801896527051106
Saving best model, epoch: 202
Epoch 203
-------------------------------
Batch 1/64 loss: 0.32464367151260376
Batch 2/64 loss: 0.322303831577301
Batch 3/64 loss: 0.32630789279937744
Batch 4/64 loss: 0.32469308376312256
Batch 5/64 loss: 0.32187730073928833
Batch 6/64 loss: 0.32821178436279297
Batch 7/64 loss: 0.32246601581573486
Batch 8/64 loss: 0.32860517501831055
Batch 9/64 loss: 0.32541531324386597
Batch 10/64 loss: 0.33428263664245605
Batch 11/64 loss: 0.32496070861816406
Batch 12/64 loss: 0.32883763313293457
Batch 13/64 loss: 0.3254467248916626
Batch 14/64 loss: 0.32350611686706543
Batch 15/64 loss: 0.32419562339782715
Batch 16/64 loss: 0.3236877918243408
Batch 17/64 loss: 0.3252738118171692
Batch 18/64 loss: 0.3252056837081909
Batch 19/64 loss: 0.32782864570617676
Batch 20/64 loss: 0.3393692970275879
Batch 21/64 loss: 0.3269839286804199
Batch 22/64 loss: 0.33119648694992065
Batch 23/64 loss: 0.3271697759628296
Batch 24/64 loss: 0.3323279023170471
Batch 25/64 loss: 0.327711284160614
Batch 26/64 loss: 0.32144057750701904
Batch 27/64 loss: 0.3254326581954956
Batch 28/64 loss: 0.33525729179382324
Batch 29/64 loss: 0.3248365521430969
Batch 30/64 loss: 0.3320821523666382
Batch 31/64 loss: 0.3244866132736206
Batch 32/64 loss: 0.3230776786804199
Batch 33/64 loss: 0.3222333788871765
Batch 34/64 loss: 0.3312862515449524
Batch 35/64 loss: 0.32579636573791504
Batch 36/64 loss: 0.32515931129455566
Batch 37/64 loss: 0.32337236404418945
Batch 38/64 loss: 0.32525521516799927
Batch 39/64 loss: 0.326681911945343
Batch 40/64 loss: 0.3221876621246338
Batch 41/64 loss: 0.3237565755844116
Batch 42/64 loss: 0.3268975019454956
Batch 43/64 loss: 0.3302329182624817
Batch 44/64 loss: 0.3330122232437134
Batch 45/64 loss: 0.3303263187408447
Batch 46/64 loss: 0.3216327428817749
Batch 47/64 loss: 0.3279097080230713
Batch 48/64 loss: 0.3319120407104492
Batch 49/64 loss: 0.32773643732070923
Batch 50/64 loss: 0.3289521336555481
Batch 51/64 loss: 0.32214856147766113
Batch 52/64 loss: 0.329089879989624
Batch 53/64 loss: 0.32253748178482056
Batch 54/64 loss: 0.32625114917755127
Batch 55/64 loss: 0.3230817914009094
Batch 56/64 loss: 0.3319799304008484
Batch 57/64 loss: 0.33161818981170654
Batch 58/64 loss: 0.3278290033340454
Batch 59/64 loss: 0.32529449462890625
Batch 60/64 loss: 0.3267977237701416
Batch 61/64 loss: 0.32239019870758057
Batch 62/64 loss: 0.32075345516204834
Batch 63/64 loss: 0.3239596486091614
Batch 64/64 loss: 0.32827460765838623
Epoch 203  Train loss: 0.32664157128801535  Val loss: 0.33883169508471933
Epoch 204
-------------------------------
Batch 1/64 loss: 0.3265913128852844
Batch 2/64 loss: 0.329148530960083
Batch 3/64 loss: 0.3294309377670288
Batch 4/64 loss: 0.32314538955688477
Batch 5/64 loss: 0.3274642825126648
Batch 6/64 loss: 0.32729166746139526
Batch 7/64 loss: 0.3256712555885315
Batch 8/64 loss: 0.3257697820663452
Batch 9/64 loss: 0.3243328332901001
Batch 10/64 loss: 0.32354533672332764
Batch 11/64 loss: 0.33349061012268066
Batch 12/64 loss: 0.3279017210006714
Batch 13/64 loss: 0.3286321759223938
Batch 14/64 loss: 0.32605522871017456
Batch 15/64 loss: 0.32212257385253906
Batch 16/64 loss: 0.3184257745742798
Batch 17/64 loss: 0.32205909490585327
Batch 18/64 loss: 0.31913185119628906
Batch 19/64 loss: 0.32626283168792725
Batch 20/64 loss: 0.33368778228759766
Batch 21/64 loss: 0.33140623569488525
Batch 22/64 loss: 0.3319779634475708
Batch 23/64 loss: 0.32443690299987793
Batch 24/64 loss: 0.32343536615371704
Batch 25/64 loss: 0.3305317163467407
Batch 26/64 loss: 0.32913464307785034
Batch 27/64 loss: 0.32111692428588867
Batch 28/64 loss: 0.32433241605758667
Batch 29/64 loss: 0.32509851455688477
Batch 30/64 loss: 0.3233810067176819
Batch 31/64 loss: 0.3235343098640442
Batch 32/64 loss: 0.32552671432495117
Batch 33/64 loss: 0.3299071788787842
Batch 34/64 loss: 0.32940638065338135
Batch 35/64 loss: 0.32142698764801025
Batch 36/64 loss: 0.3249374032020569
Batch 37/64 loss: 0.32631754875183105
Batch 38/64 loss: 0.3261280059814453
Batch 39/64 loss: 0.32423365116119385
Batch 40/64 loss: 0.325290322303772
Batch 41/64 loss: 0.32838505506515503
Batch 42/64 loss: 0.32219070196151733
Batch 43/64 loss: 0.33334338665008545
Batch 44/64 loss: 0.32876038551330566
Batch 45/64 loss: 0.33291399478912354
Batch 46/64 loss: 0.3258572220802307
Batch 47/64 loss: 0.3258288502693176
Batch 48/64 loss: 0.32622474431991577
Batch 49/64 loss: 0.3241676092147827
Batch 50/64 loss: 0.3285856246948242
Batch 51/64 loss: 0.32639235258102417
Batch 52/64 loss: 0.33024609088897705
Batch 53/64 loss: 0.33077311515808105
Batch 54/64 loss: 0.32119160890579224
Batch 55/64 loss: 0.32861781120300293
Batch 56/64 loss: 0.33095288276672363
Batch 57/64 loss: 0.33080095052719116
Batch 58/64 loss: 0.3249816298484802
Batch 59/64 loss: 0.32770252227783203
Batch 60/64 loss: 0.32917118072509766
Batch 61/64 loss: 0.3296375870704651
Batch 62/64 loss: 0.32021427154541016
Batch 63/64 loss: 0.3246331810951233
Batch 64/64 loss: 0.3205412030220032
Epoch 204  Train loss: 0.32648940904467716  Val loss: 0.3381078177710989
Epoch 205
-------------------------------
Batch 1/64 loss: 0.3310236930847168
Batch 2/64 loss: 0.3237433433532715
Batch 3/64 loss: 0.3204296827316284
Batch 4/64 loss: 0.3259887099266052
Batch 5/64 loss: 0.32521188259124756
Batch 6/64 loss: 0.3240599036216736
Batch 7/64 loss: 0.3222234845161438
Batch 8/64 loss: 0.3327234387397766
Batch 9/64 loss: 0.325924277305603
Batch 10/64 loss: 0.32115185260772705
Batch 11/64 loss: 0.3283118009567261
Batch 12/64 loss: 0.3218420147895813
Batch 13/64 loss: 0.32633960247039795
Batch 14/64 loss: 0.3195672035217285
Batch 15/64 loss: 0.32359910011291504
Batch 16/64 loss: 0.32307082414627075
Batch 17/64 loss: 0.33105236291885376
Batch 18/64 loss: 0.3221525549888611
Batch 19/64 loss: 0.32482999563217163
Batch 20/64 loss: 0.326617956161499
Batch 21/64 loss: 0.3283231258392334
Batch 22/64 loss: 0.3227494955062866
Batch 23/64 loss: 0.3315337896347046
Batch 24/64 loss: 0.3225126266479492
Batch 25/64 loss: 0.3259735107421875
Batch 26/64 loss: 0.32775211334228516
Batch 27/64 loss: 0.3254658579826355
Batch 28/64 loss: 0.32720571756362915
Batch 29/64 loss: 0.3268544673919678
Batch 30/64 loss: 0.328995943069458
Batch 31/64 loss: 0.3247193694114685
Batch 32/64 loss: 0.32531434297561646
Batch 33/64 loss: 0.32719093561172485
Batch 34/64 loss: 0.32467949390411377
Batch 35/64 loss: 0.32303446531295776
Batch 36/64 loss: 0.32573747634887695
Batch 37/64 loss: 0.3325643539428711
Batch 38/64 loss: 0.3194652199745178
Batch 39/64 loss: 0.32237184047698975
Batch 40/64 loss: 0.330633282661438
Batch 41/64 loss: 0.32766973972320557
Batch 42/64 loss: 0.3291085958480835
Batch 43/64 loss: 0.3240509629249573
Batch 44/64 loss: 0.3333101272583008
Batch 45/64 loss: 0.3265562057495117
Batch 46/64 loss: 0.3306569457054138
Batch 47/64 loss: 0.3316580653190613
Batch 48/64 loss: 0.3315727710723877
Batch 49/64 loss: 0.32278192043304443
Batch 50/64 loss: 0.32953739166259766
Batch 51/64 loss: 0.32658982276916504
Batch 52/64 loss: 0.32565075159072876
Batch 53/64 loss: 0.32713669538497925
Batch 54/64 loss: 0.3313758373260498
Batch 55/64 loss: 0.3263464570045471
Batch 56/64 loss: 0.32012617588043213
Batch 57/64 loss: 0.319111168384552
Batch 58/64 loss: 0.32114022970199585
Batch 59/64 loss: 0.3301299810409546
Batch 60/64 loss: 0.3256014585494995
Batch 61/64 loss: 0.32293516397476196
Batch 62/64 loss: 0.33121657371520996
Batch 63/64 loss: 0.331551194190979
Batch 64/64 loss: 0.32158660888671875
Epoch 205  Train loss: 0.3261167890885297  Val loss: 0.337970456511704
Saving best model, epoch: 205
Epoch 206
-------------------------------
Batch 1/64 loss: 0.3187750577926636
Batch 2/64 loss: 0.3254997134208679
Batch 3/64 loss: 0.32816487550735474
Batch 4/64 loss: 0.3275028467178345
Batch 5/64 loss: 0.32132136821746826
Batch 6/64 loss: 0.32537174224853516
Batch 7/64 loss: 0.3249553442001343
Batch 8/64 loss: 0.3229990005493164
Batch 9/64 loss: 0.3305542469024658
Batch 10/64 loss: 0.32986271381378174
Batch 11/64 loss: 0.3262441158294678
Batch 12/64 loss: 0.3268359303474426
Batch 13/64 loss: 0.3249891996383667
Batch 14/64 loss: 0.32018721103668213
Batch 15/64 loss: 0.32552528381347656
Batch 16/64 loss: 0.3231600522994995
Batch 17/64 loss: 0.3236095905303955
Batch 18/64 loss: 0.32390153408050537
Batch 19/64 loss: 0.32793593406677246
Batch 20/64 loss: 0.329703688621521
Batch 21/64 loss: 0.3244915008544922
Batch 22/64 loss: 0.33371442556381226
Batch 23/64 loss: 0.32845866680145264
Batch 24/64 loss: 0.32976698875427246
Batch 25/64 loss: 0.32567834854125977
Batch 26/64 loss: 0.3276911973953247
Batch 27/64 loss: 0.3239012360572815
Batch 28/64 loss: 0.32404768466949463
Batch 29/64 loss: 0.3265526294708252
Batch 30/64 loss: 0.3200819492340088
Batch 31/64 loss: 0.32800567150115967
Batch 32/64 loss: 0.3244434595108032
Batch 33/64 loss: 0.33054494857788086
Batch 34/64 loss: 0.3349813222885132
Batch 35/64 loss: 0.32539546489715576
Batch 36/64 loss: 0.32573366165161133
Batch 37/64 loss: 0.32903921604156494
Batch 38/64 loss: 0.3269748091697693
Batch 39/64 loss: 0.33168065547943115
Batch 40/64 loss: 0.3223327398300171
Batch 41/64 loss: 0.32575929164886475
Batch 42/64 loss: 0.3251146674156189
Batch 43/64 loss: 0.32542455196380615
Batch 44/64 loss: 0.3290889263153076
Batch 45/64 loss: 0.32619601488113403
Batch 46/64 loss: 0.3209937810897827
Batch 47/64 loss: 0.32011550664901733
Batch 48/64 loss: 0.3275411128997803
Batch 49/64 loss: 0.31913530826568604
Batch 50/64 loss: 0.3246120810508728
Batch 51/64 loss: 0.32405972480773926
Batch 52/64 loss: 0.32926321029663086
Batch 53/64 loss: 0.3223453760147095
Batch 54/64 loss: 0.33900099992752075
Batch 55/64 loss: 0.32586419582366943
Batch 56/64 loss: 0.3187063932418823
Batch 57/64 loss: 0.324950635433197
Batch 58/64 loss: 0.3277777433395386
Batch 59/64 loss: 0.31882244348526
Batch 60/64 loss: 0.32208824157714844
Batch 61/64 loss: 0.32328683137893677
Batch 62/64 loss: 0.32473093271255493
Batch 63/64 loss: 0.3301161527633667
Batch 64/64 loss: 0.3221661448478699
Epoch 206  Train loss: 0.32576054521635467  Val loss: 0.3382902636970441
Epoch 207
-------------------------------
Batch 1/64 loss: 0.3193246126174927
Batch 2/64 loss: 0.3330957889556885
Batch 3/64 loss: 0.32840561866760254
Batch 4/64 loss: 0.3229209780693054
Batch 5/64 loss: 0.3282968997955322
Batch 6/64 loss: 0.32070422172546387
Batch 7/64 loss: 0.32297229766845703
Batch 8/64 loss: 0.32060956954956055
Batch 9/64 loss: 0.32530367374420166
Batch 10/64 loss: 0.3234144449234009
Batch 11/64 loss: 0.32702112197875977
Batch 12/64 loss: 0.3159393072128296
Batch 13/64 loss: 0.32378512620925903
Batch 14/64 loss: 0.3221285343170166
Batch 15/64 loss: 0.3137328624725342
Batch 16/64 loss: 0.3314253091812134
Batch 17/64 loss: 0.3231862783432007
Batch 18/64 loss: 0.32627832889556885
Batch 19/64 loss: 0.3239620327949524
Batch 20/64 loss: 0.3295230269432068
Batch 21/64 loss: 0.3311278223991394
Batch 22/64 loss: 0.31884825229644775
Batch 23/64 loss: 0.32672345638275146
Batch 24/64 loss: 0.32709479331970215
Batch 25/64 loss: 0.3233935236930847
Batch 26/64 loss: 0.32212018966674805
Batch 27/64 loss: 0.3280268907546997
Batch 28/64 loss: 0.32013070583343506
Batch 29/64 loss: 0.3348959684371948
Batch 30/64 loss: 0.322279155254364
Batch 31/64 loss: 0.32667988538742065
Batch 32/64 loss: 0.3195312023162842
Batch 33/64 loss: 0.3266007900238037
Batch 34/64 loss: 0.32190918922424316
Batch 35/64 loss: 0.3298714756965637
Batch 36/64 loss: 0.3301771879196167
Batch 37/64 loss: 0.3258129358291626
Batch 38/64 loss: 0.324343204498291
Batch 39/64 loss: 0.328011155128479
Batch 40/64 loss: 0.3221930265426636
Batch 41/64 loss: 0.3278515934944153
Batch 42/64 loss: 0.3196983337402344
Batch 43/64 loss: 0.32910746335983276
Batch 44/64 loss: 0.3302098512649536
Batch 45/64 loss: 0.3258713483810425
Batch 46/64 loss: 0.33529043197631836
Batch 47/64 loss: 0.3321201801300049
Batch 48/64 loss: 0.32280611991882324
Batch 49/64 loss: 0.3291105031967163
Batch 50/64 loss: 0.3216903805732727
Batch 51/64 loss: 0.32693541049957275
Batch 52/64 loss: 0.3275582790374756
Batch 53/64 loss: 0.32724976539611816
Batch 54/64 loss: 0.32657110691070557
Batch 55/64 loss: 0.3280078172683716
Batch 56/64 loss: 0.32575589418411255
Batch 57/64 loss: 0.3265897035598755
Batch 58/64 loss: 0.325747549533844
Batch 59/64 loss: 0.3288920521736145
Batch 60/64 loss: 0.32845407724380493
Batch 61/64 loss: 0.33024024963378906
Batch 62/64 loss: 0.3256399631500244
Batch 63/64 loss: 0.327667236328125
Batch 64/64 loss: 0.32586097717285156
Epoch 207  Train loss: 0.3257295982510436  Val loss: 0.3368829898408188
Saving best model, epoch: 207
Epoch 208
-------------------------------
Batch 1/64 loss: 0.3229401111602783
Batch 2/64 loss: 0.32106590270996094
Batch 3/64 loss: 0.3196049928665161
Batch 4/64 loss: 0.32723426818847656
Batch 5/64 loss: 0.3233044147491455
Batch 6/64 loss: 0.321186900138855
Batch 7/64 loss: 0.3259351849555969
Batch 8/64 loss: 0.32142674922943115
Batch 9/64 loss: 0.32907599210739136
Batch 10/64 loss: 0.31901973485946655
Batch 11/64 loss: 0.32009774446487427
Batch 12/64 loss: 0.3250957727432251
Batch 13/64 loss: 0.32694149017333984
Batch 14/64 loss: 0.3301119804382324
Batch 15/64 loss: 0.32289791107177734
Batch 16/64 loss: 0.31610602140426636
Batch 17/64 loss: 0.32953089475631714
Batch 18/64 loss: 0.3229619264602661
Batch 19/64 loss: 0.3211938142776489
Batch 20/64 loss: 0.3262648582458496
Batch 21/64 loss: 0.3357734680175781
Batch 22/64 loss: 0.32928383350372314
Batch 23/64 loss: 0.3274348974227905
Batch 24/64 loss: 0.3261820673942566
Batch 25/64 loss: 0.3204752206802368
Batch 26/64 loss: 0.32925140857696533
Batch 27/64 loss: 0.32465583086013794
Batch 28/64 loss: 0.3255009055137634
Batch 29/64 loss: 0.3280620574951172
Batch 30/64 loss: 0.3238992691040039
Batch 31/64 loss: 0.32687288522720337
Batch 32/64 loss: 0.3199978470802307
Batch 33/64 loss: 0.3261953592300415
Batch 34/64 loss: 0.32301682233810425
Batch 35/64 loss: 0.31932586431503296
Batch 36/64 loss: 0.3203563690185547
Batch 37/64 loss: 0.3225853443145752
Batch 38/64 loss: 0.3249724507331848
Batch 39/64 loss: 0.32544147968292236
Batch 40/64 loss: 0.3261904716491699
Batch 41/64 loss: 0.3222905397415161
Batch 42/64 loss: 0.3273886442184448
Batch 43/64 loss: 0.3269163966178894
Batch 44/64 loss: 0.32854896783828735
Batch 45/64 loss: 0.32984232902526855
Batch 46/64 loss: 0.32595711946487427
Batch 47/64 loss: 0.32536089420318604
Batch 48/64 loss: 0.3271656036376953
Batch 49/64 loss: 0.32928037643432617
Batch 50/64 loss: 0.3251969814300537
Batch 51/64 loss: 0.328912615776062
Batch 52/64 loss: 0.32277911901474
Batch 53/64 loss: 0.32187986373901367
Batch 54/64 loss: 0.3287074565887451
Batch 55/64 loss: 0.3357117176055908
Batch 56/64 loss: 0.32778215408325195
Batch 57/64 loss: 0.3275500535964966
Batch 58/64 loss: 0.33364057540893555
Batch 59/64 loss: 0.32288670539855957
Batch 60/64 loss: 0.3283799886703491
Batch 61/64 loss: 0.3255780339241028
Batch 62/64 loss: 0.3230746388435364
Batch 63/64 loss: 0.3216415047645569
Batch 64/64 loss: 0.321679949760437
Epoch 208  Train loss: 0.32525808250202853  Val loss: 0.3395885675633486
Epoch 209
-------------------------------
Batch 1/64 loss: 0.32615721225738525
Batch 2/64 loss: 0.3341625928878784
Batch 3/64 loss: 0.3330498933792114
Batch 4/64 loss: 0.3260613679885864
Batch 5/64 loss: 0.3231040835380554
Batch 6/64 loss: 0.32355862855911255
Batch 7/64 loss: 0.32225465774536133
Batch 8/64 loss: 0.32058560848236084
Batch 9/64 loss: 0.3249422311782837
Batch 10/64 loss: 0.32482999563217163
Batch 11/64 loss: 0.32327818870544434
Batch 12/64 loss: 0.31980353593826294
Batch 13/64 loss: 0.32295453548431396
Batch 14/64 loss: 0.31959712505340576
Batch 15/64 loss: 0.3312786817550659
Batch 16/64 loss: 0.3297992944717407
Batch 17/64 loss: 0.3206300139427185
Batch 18/64 loss: 0.3191651701927185
Batch 19/64 loss: 0.31869280338287354
Batch 20/64 loss: 0.3189220428466797
Batch 21/64 loss: 0.32514137029647827
Batch 22/64 loss: 0.3300185203552246
Batch 23/64 loss: 0.3244026303291321
Batch 24/64 loss: 0.32876527309417725
Batch 25/64 loss: 0.32695841789245605
Batch 26/64 loss: 0.3220033049583435
Batch 27/64 loss: 0.33196377754211426
Batch 28/64 loss: 0.3297819495201111
Batch 29/64 loss: 0.32517701387405396
Batch 30/64 loss: 0.32038015127182007
Batch 31/64 loss: 0.32252436876296997
Batch 32/64 loss: 0.32566696405410767
Batch 33/64 loss: 0.32555699348449707
Batch 34/64 loss: 0.32610785961151123
Batch 35/64 loss: 0.3299742341041565
Batch 36/64 loss: 0.3233669400215149
Batch 37/64 loss: 0.3182693123817444
Batch 38/64 loss: 0.3321455717086792
Batch 39/64 loss: 0.3203580379486084
Batch 40/64 loss: 0.32658207416534424
Batch 41/64 loss: 0.3270277976989746
Batch 42/64 loss: 0.3335685729980469
Batch 43/64 loss: 0.3164854645729065
Batch 44/64 loss: 0.3215045928955078
Batch 45/64 loss: 0.3277457356452942
Batch 46/64 loss: 0.32827556133270264
Batch 47/64 loss: 0.31912362575531006
Batch 48/64 loss: 0.32418936491012573
Batch 49/64 loss: 0.32194340229034424
Batch 50/64 loss: 0.3342543840408325
Batch 51/64 loss: 0.32787835597991943
Batch 52/64 loss: 0.3259183168411255
Batch 53/64 loss: 0.3271557092666626
Batch 54/64 loss: 0.3297017216682434
Batch 55/64 loss: 0.32309597730636597
Batch 56/64 loss: 0.32760393619537354
Batch 57/64 loss: 0.31813615560531616
Batch 58/64 loss: 0.32768917083740234
Batch 59/64 loss: 0.3263731598854065
Batch 60/64 loss: 0.32486414909362793
Batch 61/64 loss: 0.3209211826324463
Batch 62/64 loss: 0.3370668888092041
Batch 63/64 loss: 0.31972193717956543
Batch 64/64 loss: 0.3262336254119873
Epoch 209  Train loss: 0.3252218480203666  Val loss: 0.33723891170573805
Epoch 210
-------------------------------
Batch 1/64 loss: 0.32544785737991333
Batch 2/64 loss: 0.3236304521560669
Batch 3/64 loss: 0.3276887536048889
Batch 4/64 loss: 0.3273769021034241
Batch 5/64 loss: 0.3275344967842102
Batch 6/64 loss: 0.3257995843887329
Batch 7/64 loss: 0.3193988800048828
Batch 8/64 loss: 0.3228578567504883
Batch 9/64 loss: 0.32545924186706543
Batch 10/64 loss: 0.3186054229736328
Batch 11/64 loss: 0.318797767162323
Batch 12/64 loss: 0.3255476951599121
Batch 13/64 loss: 0.325808584690094
Batch 14/64 loss: 0.3211177587509155
Batch 15/64 loss: 0.3247554898262024
Batch 16/64 loss: 0.3291935920715332
Batch 17/64 loss: 0.33076977729797363
Batch 18/64 loss: 0.31965363025665283
Batch 19/64 loss: 0.33143728971481323
Batch 20/64 loss: 0.32271498441696167
Batch 21/64 loss: 0.3218345642089844
Batch 22/64 loss: 0.322837769985199
Batch 23/64 loss: 0.32463371753692627
Batch 24/64 loss: 0.3281060457229614
Batch 25/64 loss: 0.32209843397140503
Batch 26/64 loss: 0.3233342170715332
Batch 27/64 loss: 0.33248186111450195
Batch 28/64 loss: 0.33009862899780273
Batch 29/64 loss: 0.32681941986083984
Batch 30/64 loss: 0.3260936737060547
Batch 31/64 loss: 0.32485705614089966
Batch 32/64 loss: 0.3208125829696655
Batch 33/64 loss: 0.31677281856536865
Batch 34/64 loss: 0.32860052585601807
Batch 35/64 loss: 0.33120429515838623
Batch 36/64 loss: 0.3278932571411133
Batch 37/64 loss: 0.3204481601715088
Batch 38/64 loss: 0.3255721926689148
Batch 39/64 loss: 0.3255530595779419
Batch 40/64 loss: 0.32503634691238403
Batch 41/64 loss: 0.321956992149353
Batch 42/64 loss: 0.32389670610427856
Batch 43/64 loss: 0.32680004835128784
Batch 44/64 loss: 0.32894301414489746
Batch 45/64 loss: 0.32883697748184204
Batch 46/64 loss: 0.3226117491722107
Batch 47/64 loss: 0.32141268253326416
Batch 48/64 loss: 0.32154738903045654
Batch 49/64 loss: 0.32591938972473145
Batch 50/64 loss: 0.330135703086853
Batch 51/64 loss: 0.3234579563140869
Batch 52/64 loss: 0.3273674249649048
Batch 53/64 loss: 0.3299969434738159
Batch 54/64 loss: 0.32596921920776367
Batch 55/64 loss: 0.32784903049468994
Batch 56/64 loss: 0.3267608880996704
Batch 57/64 loss: 0.3280305862426758
Batch 58/64 loss: 0.3255898952484131
Batch 59/64 loss: 0.3266479969024658
Batch 60/64 loss: 0.319377064704895
Batch 61/64 loss: 0.3212963342666626
Batch 62/64 loss: 0.3262512683868408
Batch 63/64 loss: 0.3299684524536133
Batch 64/64 loss: 0.32216060161590576
Epoch 210  Train loss: 0.32519104013256  Val loss: 0.3372927840632671
Epoch 211
-------------------------------
Batch 1/64 loss: 0.31852495670318604
Batch 2/64 loss: 0.32357871532440186
Batch 3/64 loss: 0.32618463039398193
Batch 4/64 loss: 0.3276159167289734
Batch 5/64 loss: 0.323192834854126
Batch 6/64 loss: 0.3287616968154907
Batch 7/64 loss: 0.3301529884338379
Batch 8/64 loss: 0.32698166370391846
Batch 9/64 loss: 0.32258111238479614
Batch 10/64 loss: 0.3218027353286743
Batch 11/64 loss: 0.3203336000442505
Batch 12/64 loss: 0.3218252658843994
Batch 13/64 loss: 0.32986438274383545
Batch 14/64 loss: 0.3268849849700928
Batch 15/64 loss: 0.3248945474624634
Batch 16/64 loss: 0.33301210403442383
Batch 17/64 loss: 0.32533007860183716
Batch 18/64 loss: 0.3201097249984741
Batch 19/64 loss: 0.33117377758026123
Batch 20/64 loss: 0.3228052854537964
Batch 21/64 loss: 0.3242381811141968
Batch 22/64 loss: 0.33143478631973267
Batch 23/64 loss: 0.32272207736968994
Batch 24/64 loss: 0.32149577140808105
Batch 25/64 loss: 0.3297919034957886
Batch 26/64 loss: 0.3186712861061096
Batch 27/64 loss: 0.3294833302497864
Batch 28/64 loss: 0.3153970241546631
Batch 29/64 loss: 0.32297641038894653
Batch 30/64 loss: 0.32466959953308105
Batch 31/64 loss: 0.3320760726928711
Batch 32/64 loss: 0.3219802975654602
Batch 33/64 loss: 0.32033771276474
Batch 34/64 loss: 0.32619404792785645
Batch 35/64 loss: 0.31836235523223877
Batch 36/64 loss: 0.31647372245788574
Batch 37/64 loss: 0.3241724967956543
Batch 38/64 loss: 0.3181194067001343
Batch 39/64 loss: 0.32972949743270874
Batch 40/64 loss: 0.3233964443206787
Batch 41/64 loss: 0.32302629947662354
Batch 42/64 loss: 0.3249422311782837
Batch 43/64 loss: 0.32206618785858154
Batch 44/64 loss: 0.32556092739105225
Batch 45/64 loss: 0.3316587209701538
Batch 46/64 loss: 0.32284295558929443
Batch 47/64 loss: 0.3236422538757324
Batch 48/64 loss: 0.32571941614151
Batch 49/64 loss: 0.3200477957725525
Batch 50/64 loss: 0.32665812969207764
Batch 51/64 loss: 0.3211960792541504
Batch 52/64 loss: 0.32435691356658936
Batch 53/64 loss: 0.33055418729782104
Batch 54/64 loss: 0.3236963152885437
Batch 55/64 loss: 0.3196720480918884
Batch 56/64 loss: 0.32454466819763184
Batch 57/64 loss: 0.32937097549438477
Batch 58/64 loss: 0.3286222815513611
Batch 59/64 loss: 0.33061206340789795
Batch 60/64 loss: 0.32690244913101196
Batch 61/64 loss: 0.3263394832611084
Batch 62/64 loss: 0.3227923512458801
Batch 63/64 loss: 0.33124005794525146
Batch 64/64 loss: 0.32972419261932373
Epoch 211  Train loss: 0.32487359000187294  Val loss: 0.3365833107958135
Saving best model, epoch: 211
Epoch 212
-------------------------------
Batch 1/64 loss: 0.32370853424072266
Batch 2/64 loss: 0.32092058658599854
Batch 3/64 loss: 0.32438498735427856
Batch 4/64 loss: 0.3212350010871887
Batch 5/64 loss: 0.3263281583786011
Batch 6/64 loss: 0.32190239429473877
Batch 7/64 loss: 0.32875823974609375
Batch 8/64 loss: 0.3260173797607422
Batch 9/64 loss: 0.31810319423675537
Batch 10/64 loss: 0.31934690475463867
Batch 11/64 loss: 0.3305860757827759
Batch 12/64 loss: 0.3266434073448181
Batch 13/64 loss: 0.31984806060791016
Batch 14/64 loss: 0.3253819942474365
Batch 15/64 loss: 0.3240140676498413
Batch 16/64 loss: 0.32489705085754395
Batch 17/64 loss: 0.3244072198867798
Batch 18/64 loss: 0.33185261487960815
Batch 19/64 loss: 0.3167423605918884
Batch 20/64 loss: 0.3242683410644531
Batch 21/64 loss: 0.32391107082366943
Batch 22/64 loss: 0.3317490220069885
Batch 23/64 loss: 0.3244784474372864
Batch 24/64 loss: 0.3175504207611084
Batch 25/64 loss: 0.3215242624282837
Batch 26/64 loss: 0.3264288902282715
Batch 27/64 loss: 0.3293887972831726
Batch 28/64 loss: 0.32478612661361694
Batch 29/64 loss: 0.3273136615753174
Batch 30/64 loss: 0.3303479552268982
Batch 31/64 loss: 0.33457517623901367
Batch 32/64 loss: 0.32502037286758423
Batch 33/64 loss: 0.3181278705596924
Batch 34/64 loss: 0.3255273103713989
Batch 35/64 loss: 0.3256263732910156
Batch 36/64 loss: 0.32352787256240845
Batch 37/64 loss: 0.3304927349090576
Batch 38/64 loss: 0.33248358964920044
Batch 39/64 loss: 0.3225173354148865
Batch 40/64 loss: 0.3247024416923523
Batch 41/64 loss: 0.3222554326057434
Batch 42/64 loss: 0.32460570335388184
Batch 43/64 loss: 0.3214908838272095
Batch 44/64 loss: 0.3164069652557373
Batch 45/64 loss: 0.32694125175476074
Batch 46/64 loss: 0.32614052295684814
Batch 47/64 loss: 0.3205451965332031
Batch 48/64 loss: 0.3309497833251953
Batch 49/64 loss: 0.3254462480545044
Batch 50/64 loss: 0.31958895921707153
Batch 51/64 loss: 0.32269489765167236
Batch 52/64 loss: 0.32218778133392334
Batch 53/64 loss: 0.3255925178527832
Batch 54/64 loss: 0.3252564072608948
Batch 55/64 loss: 0.32632291316986084
Batch 56/64 loss: 0.32345646619796753
Batch 57/64 loss: 0.32871633768081665
Batch 58/64 loss: 0.3245105743408203
Batch 59/64 loss: 0.3241785764694214
Batch 60/64 loss: 0.32083559036254883
Batch 61/64 loss: 0.32298731803894043
Batch 62/64 loss: 0.3316614627838135
Batch 63/64 loss: 0.3344857692718506
Batch 64/64 loss: 0.3260834813117981
Epoch 212  Train loss: 0.32488229765611537  Val loss: 0.3378336212479372
Epoch 213
-------------------------------
Batch 1/64 loss: 0.325669527053833
Batch 2/64 loss: 0.32462769746780396
Batch 3/64 loss: 0.3255646824836731
Batch 4/64 loss: 0.32274484634399414
Batch 5/64 loss: 0.33372795581817627
Batch 6/64 loss: 0.3251854181289673
Batch 7/64 loss: 0.32315075397491455
Batch 8/64 loss: 0.32634830474853516
Batch 9/64 loss: 0.32342028617858887
Batch 10/64 loss: 0.32129740715026855
Batch 11/64 loss: 0.32830381393432617
Batch 12/64 loss: 0.32881975173950195
Batch 13/64 loss: 0.32456153631210327
Batch 14/64 loss: 0.3236679434776306
Batch 15/64 loss: 0.3250576853752136
Batch 16/64 loss: 0.3228965997695923
Batch 17/64 loss: 0.32269853353500366
Batch 18/64 loss: 0.31386470794677734
Batch 19/64 loss: 0.32687652111053467
Batch 20/64 loss: 0.3232883810997009
Batch 21/64 loss: 0.33180463314056396
Batch 22/64 loss: 0.32658010721206665
Batch 23/64 loss: 0.32271671295166016
Batch 24/64 loss: 0.3204687833786011
Batch 25/64 loss: 0.3215458393096924
Batch 26/64 loss: 0.325599730014801
Batch 27/64 loss: 0.32134729623794556
Batch 28/64 loss: 0.32921361923217773
Batch 29/64 loss: 0.32183122634887695
Batch 30/64 loss: 0.3141024708747864
Batch 31/64 loss: 0.32014375925064087
Batch 32/64 loss: 0.3215824365615845
Batch 33/64 loss: 0.32371747493743896
Batch 34/64 loss: 0.32746750116348267
Batch 35/64 loss: 0.3209472894668579
Batch 36/64 loss: 0.32644379138946533
Batch 37/64 loss: 0.3271118402481079
Batch 38/64 loss: 0.32487595081329346
Batch 39/64 loss: 0.32367444038391113
Batch 40/64 loss: 0.3212844133377075
Batch 41/64 loss: 0.32022374868392944
Batch 42/64 loss: 0.3248124122619629
Batch 43/64 loss: 0.33008480072021484
Batch 44/64 loss: 0.3228868246078491
Batch 45/64 loss: 0.321180522441864
Batch 46/64 loss: 0.3209179639816284
Batch 47/64 loss: 0.32503122091293335
Batch 48/64 loss: 0.3253708481788635
Batch 49/64 loss: 0.32906681299209595
Batch 50/64 loss: 0.3266306519508362
Batch 51/64 loss: 0.32108139991760254
Batch 52/64 loss: 0.32508862018585205
Batch 53/64 loss: 0.32797420024871826
Batch 54/64 loss: 0.32748329639434814
Batch 55/64 loss: 0.32273638248443604
Batch 56/64 loss: 0.3235102891921997
Batch 57/64 loss: 0.32043027877807617
Batch 58/64 loss: 0.32600903511047363
Batch 59/64 loss: 0.32396233081817627
Batch 60/64 loss: 0.3264491558074951
Batch 61/64 loss: 0.3243390917778015
Batch 62/64 loss: 0.3242912292480469
Batch 63/64 loss: 0.32808858156204224
Batch 64/64 loss: 0.3171125054359436
Epoch 213  Train loss: 0.32423083525077967  Val loss: 0.3363984421766091
Saving best model, epoch: 213
Epoch 214
-------------------------------
Batch 1/64 loss: 0.31849879026412964
Batch 2/64 loss: 0.3258649706840515
Batch 3/64 loss: 0.31897425651550293
Batch 4/64 loss: 0.32093167304992676
Batch 5/64 loss: 0.32884979248046875
Batch 6/64 loss: 0.3230631947517395
Batch 7/64 loss: 0.32091808319091797
Batch 8/64 loss: 0.32712918519973755
Batch 9/64 loss: 0.3223327398300171
Batch 10/64 loss: 0.32639676332473755
Batch 11/64 loss: 0.327788770198822
Batch 12/64 loss: 0.3232276439666748
Batch 13/64 loss: 0.32504308223724365
Batch 14/64 loss: 0.32557785511016846
Batch 15/64 loss: 0.31986528635025024
Batch 16/64 loss: 0.3164471387863159
Batch 17/64 loss: 0.32290101051330566
Batch 18/64 loss: 0.31924545764923096
Batch 19/64 loss: 0.3246811032295227
Batch 20/64 loss: 0.32898402214050293
Batch 21/64 loss: 0.3200417757034302
Batch 22/64 loss: 0.3228471279144287
Batch 23/64 loss: 0.3214990496635437
Batch 24/64 loss: 0.31752991676330566
Batch 25/64 loss: 0.3226354122161865
Batch 26/64 loss: 0.32128071784973145
Batch 27/64 loss: 0.31931495666503906
Batch 28/64 loss: 0.31839925050735474
Batch 29/64 loss: 0.3221334218978882
Batch 30/64 loss: 0.3299475312232971
Batch 31/64 loss: 0.3172891139984131
Batch 32/64 loss: 0.3232284188270569
Batch 33/64 loss: 0.32197463512420654
Batch 34/64 loss: 0.3274078369140625
Batch 35/64 loss: 0.31656378507614136
Batch 36/64 loss: 0.3200379014015198
Batch 37/64 loss: 0.32689911127090454
Batch 38/64 loss: 0.3217442035675049
Batch 39/64 loss: 0.3239504098892212
Batch 40/64 loss: 0.3293861150741577
Batch 41/64 loss: 0.31943953037261963
Batch 42/64 loss: 0.31524014472961426
Batch 43/64 loss: 0.3241496682167053
Batch 44/64 loss: 0.3229065537452698
Batch 45/64 loss: 0.3293253183364868
Batch 46/64 loss: 0.32298755645751953
Batch 47/64 loss: 0.33172106742858887
Batch 48/64 loss: 0.3229571580886841
Batch 49/64 loss: 0.32147061824798584
Batch 50/64 loss: 0.3190256357192993
Batch 51/64 loss: 0.3252716660499573
Batch 52/64 loss: 0.3217909336090088
Batch 53/64 loss: 0.33410823345184326
Batch 54/64 loss: 0.3209981322288513
Batch 55/64 loss: 0.327162504196167
Batch 56/64 loss: 0.32237666845321655
Batch 57/64 loss: 0.3242787718772888
Batch 58/64 loss: 0.3267856240272522
Batch 59/64 loss: 0.33444178104400635
Batch 60/64 loss: 0.32726383209228516
Batch 61/64 loss: 0.32822370529174805
Batch 62/64 loss: 0.33296120166778564
Batch 63/64 loss: 0.32936787605285645
Batch 64/64 loss: 0.33110231161117554
Epoch 214  Train loss: 0.32381823413512284  Val loss: 0.3373830261099379
Epoch 215
-------------------------------
Batch 1/64 loss: 0.31884801387786865
Batch 2/64 loss: 0.3262268304824829
Batch 3/64 loss: 0.31825143098831177
Batch 4/64 loss: 0.3241755962371826
Batch 5/64 loss: 0.32163238525390625
Batch 6/64 loss: 0.31929755210876465
Batch 7/64 loss: 0.3225538730621338
Batch 8/64 loss: 0.31995534896850586
Batch 9/64 loss: 0.3275741934776306
Batch 10/64 loss: 0.3163241147994995
Batch 11/64 loss: 0.32160717248916626
Batch 12/64 loss: 0.31807756423950195
Batch 13/64 loss: 0.32611775398254395
Batch 14/64 loss: 0.32587385177612305
Batch 15/64 loss: 0.32547521591186523
Batch 16/64 loss: 0.3248329758644104
Batch 17/64 loss: 0.32203948497772217
Batch 18/64 loss: 0.3231487274169922
Batch 19/64 loss: 0.3306618332862854
Batch 20/64 loss: 0.3238559365272522
Batch 21/64 loss: 0.33203256130218506
Batch 22/64 loss: 0.3267384171485901
Batch 23/64 loss: 0.3245921730995178
Batch 24/64 loss: 0.32013505697250366
Batch 25/64 loss: 0.3320828676223755
Batch 26/64 loss: 0.3209567070007324
Batch 27/64 loss: 0.3273165822029114
Batch 28/64 loss: 0.3299446702003479
Batch 29/64 loss: 0.3252776861190796
Batch 30/64 loss: 0.32173585891723633
Batch 31/64 loss: 0.3315497636795044
Batch 32/64 loss: 0.32111525535583496
Batch 33/64 loss: 0.32362353801727295
Batch 34/64 loss: 0.32082319259643555
Batch 35/64 loss: 0.33208394050598145
Batch 36/64 loss: 0.3245803713798523
Batch 37/64 loss: 0.32266759872436523
Batch 38/64 loss: 0.3233613967895508
Batch 39/64 loss: 0.3299652338027954
Batch 40/64 loss: 0.3201817274093628
Batch 41/64 loss: 0.32715630531311035
Batch 42/64 loss: 0.3177722096443176
Batch 43/64 loss: 0.32375025749206543
Batch 44/64 loss: 0.3299078941345215
Batch 45/64 loss: 0.3258225917816162
Batch 46/64 loss: 0.3233954906463623
Batch 47/64 loss: 0.3291501998901367
Batch 48/64 loss: 0.3194822072982788
Batch 49/64 loss: 0.33372920751571655
Batch 50/64 loss: 0.3237614631652832
Batch 51/64 loss: 0.3294898271560669
Batch 52/64 loss: 0.3216943144798279
Batch 53/64 loss: 0.32437336444854736
Batch 54/64 loss: 0.3253500461578369
Batch 55/64 loss: 0.319246768951416
Batch 56/64 loss: 0.32840073108673096
Batch 57/64 loss: 0.3256595730781555
Batch 58/64 loss: 0.322373628616333
Batch 59/64 loss: 0.3236052989959717
Batch 60/64 loss: 0.32560861110687256
Batch 61/64 loss: 0.32547491788864136
Batch 62/64 loss: 0.32560765743255615
Batch 63/64 loss: 0.3228505849838257
Batch 64/64 loss: 0.319146990776062
Epoch 215  Train loss: 0.3243971427281698  Val loss: 0.33696365049204874
Epoch 216
-------------------------------
Batch 1/64 loss: 0.32403016090393066
Batch 2/64 loss: 0.3284996747970581
Batch 3/64 loss: 0.3319559097290039
Batch 4/64 loss: 0.32059019804000854
Batch 5/64 loss: 0.32632720470428467
Batch 6/64 loss: 0.3183741569519043
Batch 7/64 loss: 0.32090264558792114
Batch 8/64 loss: 0.3211333155632019
Batch 9/64 loss: 0.325523316860199
Batch 10/64 loss: 0.31822794675827026
Batch 11/64 loss: 0.3244796395301819
Batch 12/64 loss: 0.3244204521179199
Batch 13/64 loss: 0.31980085372924805
Batch 14/64 loss: 0.3193485736846924
Batch 15/64 loss: 0.3185768127441406
Batch 16/64 loss: 0.32580655813217163
Batch 17/64 loss: 0.3194165825843811
Batch 18/64 loss: 0.32834291458129883
Batch 19/64 loss: 0.32056158781051636
Batch 20/64 loss: 0.3227919936180115
Batch 21/64 loss: 0.32602453231811523
Batch 22/64 loss: 0.3281620740890503
Batch 23/64 loss: 0.31838011741638184
Batch 24/64 loss: 0.31755751371383667
Batch 25/64 loss: 0.3292829990386963
Batch 26/64 loss: 0.32283639907836914
Batch 27/64 loss: 0.3295445442199707
Batch 28/64 loss: 0.3230181932449341
Batch 29/64 loss: 0.3259351849555969
Batch 30/64 loss: 0.33024775981903076
Batch 31/64 loss: 0.3174145221710205
Batch 32/64 loss: 0.32254695892333984
Batch 33/64 loss: 0.32404905557632446
Batch 34/64 loss: 0.32248562574386597
Batch 35/64 loss: 0.32376110553741455
Batch 36/64 loss: 0.32545334100723267
Batch 37/64 loss: 0.3260563611984253
Batch 38/64 loss: 0.32031065225601196
Batch 39/64 loss: 0.3216547966003418
Batch 40/64 loss: 0.3265342116355896
Batch 41/64 loss: 0.32550203800201416
Batch 42/64 loss: 0.3250253200531006
Batch 43/64 loss: 0.32968389987945557
Batch 44/64 loss: 0.3252089023590088
Batch 45/64 loss: 0.32991278171539307
Batch 46/64 loss: 0.3265810012817383
Batch 47/64 loss: 0.3338015079498291
Batch 48/64 loss: 0.31913578510284424
Batch 49/64 loss: 0.32265543937683105
Batch 50/64 loss: 0.3296116590499878
Batch 51/64 loss: 0.31978660821914673
Batch 52/64 loss: 0.3262450695037842
Batch 53/64 loss: 0.32409167289733887
Batch 54/64 loss: 0.32163286209106445
Batch 55/64 loss: 0.32486605644226074
Batch 56/64 loss: 0.3242439031600952
Batch 57/64 loss: 0.32298529148101807
Batch 58/64 loss: 0.3253931999206543
Batch 59/64 loss: 0.32371342182159424
Batch 60/64 loss: 0.3323554992675781
Batch 61/64 loss: 0.32239294052124023
Batch 62/64 loss: 0.3194209933280945
Batch 63/64 loss: 0.33138078451156616
Batch 64/64 loss: 0.32079923152923584
Epoch 216  Train loss: 0.3241818432714425  Val loss: 0.336873486279622
Epoch 217
-------------------------------
Batch 1/64 loss: 0.3234177231788635
Batch 2/64 loss: 0.3239453434944153
Batch 3/64 loss: 0.32412952184677124
Batch 4/64 loss: 0.3273175358772278
Batch 5/64 loss: 0.3201099634170532
Batch 6/64 loss: 0.3289923071861267
Batch 7/64 loss: 0.326813280582428
Batch 8/64 loss: 0.31640946865081787
Batch 9/64 loss: 0.31858670711517334
Batch 10/64 loss: 0.3215622901916504
Batch 11/64 loss: 0.317435622215271
Batch 12/64 loss: 0.3251473307609558
Batch 13/64 loss: 0.3230743408203125
Batch 14/64 loss: 0.3245910406112671
Batch 15/64 loss: 0.3222475051879883
Batch 16/64 loss: 0.318293035030365
Batch 17/64 loss: 0.3282203674316406
Batch 18/64 loss: 0.32109642028808594
Batch 19/64 loss: 0.3212137222290039
Batch 20/64 loss: 0.31650304794311523
Batch 21/64 loss: 0.3227565288543701
Batch 22/64 loss: 0.3229184150695801
Batch 23/64 loss: 0.32039040327072144
Batch 24/64 loss: 0.32722699642181396
Batch 25/64 loss: 0.32180845737457275
Batch 26/64 loss: 0.3235851526260376
Batch 27/64 loss: 0.3193223476409912
Batch 28/64 loss: 0.32482415437698364
Batch 29/64 loss: 0.32531869411468506
Batch 30/64 loss: 0.32509756088256836
Batch 31/64 loss: 0.32317036390304565
Batch 32/64 loss: 0.32414186000823975
Batch 33/64 loss: 0.33145320415496826
Batch 34/64 loss: 0.3243141174316406
Batch 35/64 loss: 0.32154160737991333
Batch 36/64 loss: 0.31990915536880493
Batch 37/64 loss: 0.32800066471099854
Batch 38/64 loss: 0.32913267612457275
Batch 39/64 loss: 0.32439374923706055
Batch 40/64 loss: 0.3222508430480957
Batch 41/64 loss: 0.31995970010757446
Batch 42/64 loss: 0.3262372612953186
Batch 43/64 loss: 0.325710654258728
Batch 44/64 loss: 0.32364213466644287
Batch 45/64 loss: 0.3234543800354004
Batch 46/64 loss: 0.32928287982940674
Batch 47/64 loss: 0.3206251859664917
Batch 48/64 loss: 0.3239128589630127
Batch 49/64 loss: 0.3245025873184204
Batch 50/64 loss: 0.3242102861404419
Batch 51/64 loss: 0.3206087350845337
Batch 52/64 loss: 0.3222237825393677
Batch 53/64 loss: 0.3176122307777405
Batch 54/64 loss: 0.3312220573425293
Batch 55/64 loss: 0.3222087025642395
Batch 56/64 loss: 0.3208705186843872
Batch 57/64 loss: 0.32120275497436523
Batch 58/64 loss: 0.3265796899795532
Batch 59/64 loss: 0.32410407066345215
Batch 60/64 loss: 0.3350895643234253
Batch 61/64 loss: 0.3265336751937866
Batch 62/64 loss: 0.3279147148132324
Batch 63/64 loss: 0.3205881714820862
Batch 64/64 loss: 0.325655996799469
Epoch 217  Train loss: 0.3236580724809684  Val loss: 0.3360242573256345
Saving best model, epoch: 217
Epoch 218
-------------------------------
Batch 1/64 loss: 0.3232712745666504
Batch 2/64 loss: 0.32547229528427124
Batch 3/64 loss: 0.3271141052246094
Batch 4/64 loss: 0.3217727541923523
Batch 5/64 loss: 0.32152312994003296
Batch 6/64 loss: 0.3174390196800232
Batch 7/64 loss: 0.3297837972640991
Batch 8/64 loss: 0.3239349126815796
Batch 9/64 loss: 0.3246787190437317
Batch 10/64 loss: 0.32162368297576904
Batch 11/64 loss: 0.32383453845977783
Batch 12/64 loss: 0.3228679895401001
Batch 13/64 loss: 0.3221571445465088
Batch 14/64 loss: 0.3269011974334717
Batch 15/64 loss: 0.3224791884422302
Batch 16/64 loss: 0.32142800092697144
Batch 17/64 loss: 0.315136194229126
Batch 18/64 loss: 0.31912386417388916
Batch 19/64 loss: 0.3201240301132202
Batch 20/64 loss: 0.32460808753967285
Batch 21/64 loss: 0.3210163116455078
Batch 22/64 loss: 0.32438504695892334
Batch 23/64 loss: 0.3237975239753723
Batch 24/64 loss: 0.31705039739608765
Batch 25/64 loss: 0.31884443759918213
Batch 26/64 loss: 0.32341814041137695
Batch 27/64 loss: 0.3257991075515747
Batch 28/64 loss: 0.31889986991882324
Batch 29/64 loss: 0.3213156461715698
Batch 30/64 loss: 0.32223618030548096
Batch 31/64 loss: 0.3200033903121948
Batch 32/64 loss: 0.3253086805343628
Batch 33/64 loss: 0.32118719816207886
Batch 34/64 loss: 0.3270915746688843
Batch 35/64 loss: 0.31722497940063477
Batch 36/64 loss: 0.3267028331756592
Batch 37/64 loss: 0.319940984249115
Batch 38/64 loss: 0.3246721625328064
Batch 39/64 loss: 0.322418212890625
Batch 40/64 loss: 0.31568408012390137
Batch 41/64 loss: 0.3211827874183655
Batch 42/64 loss: 0.32509589195251465
Batch 43/64 loss: 0.32979917526245117
Batch 44/64 loss: 0.32031625509262085
Batch 45/64 loss: 0.33016419410705566
Batch 46/64 loss: 0.33540767431259155
Batch 47/64 loss: 0.3216906189918518
Batch 48/64 loss: 0.32573723793029785
Batch 49/64 loss: 0.32929134368896484
Batch 50/64 loss: 0.3320204019546509
Batch 51/64 loss: 0.3246428370475769
Batch 52/64 loss: 0.3244478702545166
Batch 53/64 loss: 0.32036447525024414
Batch 54/64 loss: 0.33146607875823975
Batch 55/64 loss: 0.3255995512008667
Batch 56/64 loss: 0.3258751630783081
Batch 57/64 loss: 0.32882970571517944
Batch 58/64 loss: 0.32404226064682007
Batch 59/64 loss: 0.32104337215423584
Batch 60/64 loss: 0.33304262161254883
Batch 61/64 loss: 0.320962131023407
Batch 62/64 loss: 0.33073389530181885
Batch 63/64 loss: 0.32604485750198364
Batch 64/64 loss: 0.326968252658844
Epoch 218  Train loss: 0.3238478003763685  Val loss: 0.33837101938798253
Epoch 219
-------------------------------
Batch 1/64 loss: 0.3279536962509155
Batch 2/64 loss: 0.3248436450958252
Batch 3/64 loss: 0.3166273832321167
Batch 4/64 loss: 0.31914186477661133
Batch 5/64 loss: 0.3246258497238159
Batch 6/64 loss: 0.3267087936401367
Batch 7/64 loss: 0.321811318397522
Batch 8/64 loss: 0.32429248094558716
Batch 9/64 loss: 0.3245052099227905
Batch 10/64 loss: 0.3191816806793213
Batch 11/64 loss: 0.3263164758682251
Batch 12/64 loss: 0.32176274061203003
Batch 13/64 loss: 0.3266695737838745
Batch 14/64 loss: 0.3315880298614502
Batch 15/64 loss: 0.3217885494232178
Batch 16/64 loss: 0.3316805958747864
Batch 17/64 loss: 0.32318270206451416
Batch 18/64 loss: 0.3299376964569092
Batch 19/64 loss: 0.3230823874473572
Batch 20/64 loss: 0.316453218460083
Batch 21/64 loss: 0.32150357961654663
Batch 22/64 loss: 0.328680157661438
Batch 23/64 loss: 0.3250133991241455
Batch 24/64 loss: 0.32592928409576416
Batch 25/64 loss: 0.32271450757980347
Batch 26/64 loss: 0.3215896487236023
Batch 27/64 loss: 0.32687908411026
Batch 28/64 loss: 0.3247419595718384
Batch 29/64 loss: 0.32006025314331055
Batch 30/64 loss: 0.3224942088127136
Batch 31/64 loss: 0.32242751121520996
Batch 32/64 loss: 0.32150959968566895
Batch 33/64 loss: 0.3184279203414917
Batch 34/64 loss: 0.3211458921432495
Batch 35/64 loss: 0.32117223739624023
Batch 36/64 loss: 0.326998233795166
Batch 37/64 loss: 0.3161468505859375
Batch 38/64 loss: 0.31917619705200195
Batch 39/64 loss: 0.32665854692459106
Batch 40/64 loss: 0.32751625776290894
Batch 41/64 loss: 0.3213411569595337
Batch 42/64 loss: 0.3311718702316284
Batch 43/64 loss: 0.32637345790863037
Batch 44/64 loss: 0.3196941614151001
Batch 45/64 loss: 0.3210045099258423
Batch 46/64 loss: 0.32869207859039307
Batch 47/64 loss: 0.3259214162826538
Batch 48/64 loss: 0.3247525691986084
Batch 49/64 loss: 0.32567137479782104
Batch 50/64 loss: 0.323116660118103
Batch 51/64 loss: 0.323449969291687
Batch 52/64 loss: 0.3261222243309021
Batch 53/64 loss: 0.33019351959228516
Batch 54/64 loss: 0.32348257303237915
Batch 55/64 loss: 0.3157541751861572
Batch 56/64 loss: 0.32510608434677124
Batch 57/64 loss: 0.31847476959228516
Batch 58/64 loss: 0.3204169273376465
Batch 59/64 loss: 0.3228435516357422
Batch 60/64 loss: 0.32120680809020996
Batch 61/64 loss: 0.32612037658691406
Batch 62/64 loss: 0.32499486207962036
Batch 63/64 loss: 0.32601457834243774
Batch 64/64 loss: 0.3185785412788391
Epoch 219  Train loss: 0.32366733808143466  Val loss: 0.3371020768516252
Epoch 220
-------------------------------
Batch 1/64 loss: 0.31896376609802246
Batch 2/64 loss: 0.3212140202522278
Batch 3/64 loss: 0.32700514793395996
Batch 4/64 loss: 0.3216356635093689
Batch 5/64 loss: 0.32201045751571655
Batch 6/64 loss: 0.3311500549316406
Batch 7/64 loss: 0.32337868213653564
Batch 8/64 loss: 0.3262364864349365
Batch 9/64 loss: 0.32788336277008057
Batch 10/64 loss: 0.31227660179138184
Batch 11/64 loss: 0.32010501623153687
Batch 12/64 loss: 0.3215506672859192
Batch 13/64 loss: 0.32577311992645264
Batch 14/64 loss: 0.3228250741958618
Batch 15/64 loss: 0.327397882938385
Batch 16/64 loss: 0.31891369819641113
Batch 17/64 loss: 0.31764864921569824
Batch 18/64 loss: 0.3197166919708252
Batch 19/64 loss: 0.3276275396347046
Batch 20/64 loss: 0.32100343704223633
Batch 21/64 loss: 0.3233063220977783
Batch 22/64 loss: 0.3203195333480835
Batch 23/64 loss: 0.31887054443359375
Batch 24/64 loss: 0.3260188698768616
Batch 25/64 loss: 0.32837069034576416
Batch 26/64 loss: 0.3210616111755371
Batch 27/64 loss: 0.32642245292663574
Batch 28/64 loss: 0.3243476152420044
Batch 29/64 loss: 0.32168257236480713
Batch 30/64 loss: 0.317546010017395
Batch 31/64 loss: 0.3163122534751892
Batch 32/64 loss: 0.32480311393737793
Batch 33/64 loss: 0.3234965205192566
Batch 34/64 loss: 0.3203919529914856
Batch 35/64 loss: 0.32177436351776123
Batch 36/64 loss: 0.3211177587509155
Batch 37/64 loss: 0.31387990713119507
Batch 38/64 loss: 0.32769715785980225
Batch 39/64 loss: 0.3281886577606201
Batch 40/64 loss: 0.32808125019073486
Batch 41/64 loss: 0.3274613618850708
Batch 42/64 loss: 0.320697546005249
Batch 43/64 loss: 0.32885295152664185
Batch 44/64 loss: 0.3230767846107483
Batch 45/64 loss: 0.31517529487609863
Batch 46/64 loss: 0.32542622089385986
Batch 47/64 loss: 0.32596445083618164
Batch 48/64 loss: 0.3188213109970093
Batch 49/64 loss: 0.3346065878868103
Batch 50/64 loss: 0.3194032907485962
Batch 51/64 loss: 0.3261018991470337
Batch 52/64 loss: 0.3193507194519043
Batch 53/64 loss: 0.32517796754837036
Batch 54/64 loss: 0.3192436695098877
Batch 55/64 loss: 0.3255666494369507
Batch 56/64 loss: 0.31748801469802856
Batch 57/64 loss: 0.32609450817108154
Batch 58/64 loss: 0.3232959508895874
Batch 59/64 loss: 0.32449615001678467
Batch 60/64 loss: 0.32721078395843506
Batch 61/64 loss: 0.3271150588989258
Batch 62/64 loss: 0.3255436420440674
Batch 63/64 loss: 0.318683922290802
Batch 64/64 loss: 0.3247116804122925
Epoch 220  Train loss: 0.32308068509195365  Val loss: 0.3360707301044792
Epoch 221
-------------------------------
Batch 1/64 loss: 0.31820857524871826
Batch 2/64 loss: 0.3146994113922119
Batch 3/64 loss: 0.31562769412994385
Batch 4/64 loss: 0.32212400436401367
Batch 5/64 loss: 0.31654107570648193
Batch 6/64 loss: 0.32504093647003174
Batch 7/64 loss: 0.3231557011604309
Batch 8/64 loss: 0.32503485679626465
Batch 9/64 loss: 0.32302504777908325
Batch 10/64 loss: 0.32130885124206543
Batch 11/64 loss: 0.3204640746116638
Batch 12/64 loss: 0.32419252395629883
Batch 13/64 loss: 0.3207399845123291
Batch 14/64 loss: 0.32816755771636963
Batch 15/64 loss: 0.3163571357727051
Batch 16/64 loss: 0.3252190351486206
Batch 17/64 loss: 0.3181758522987366
Batch 18/64 loss: 0.3253055214881897
Batch 19/64 loss: 0.3278578519821167
Batch 20/64 loss: 0.3265697956085205
Batch 21/64 loss: 0.32101869583129883
Batch 22/64 loss: 0.3228036165237427
Batch 23/64 loss: 0.32272404432296753
Batch 24/64 loss: 0.31967341899871826
Batch 25/64 loss: 0.32888245582580566
Batch 26/64 loss: 0.32240134477615356
Batch 27/64 loss: 0.32346391677856445
Batch 28/64 loss: 0.3190188407897949
Batch 29/64 loss: 0.32448041439056396
Batch 30/64 loss: 0.3252263069152832
Batch 31/64 loss: 0.3182791471481323
Batch 32/64 loss: 0.32141822576522827
Batch 33/64 loss: 0.32682323455810547
Batch 34/64 loss: 0.3176957368850708
Batch 35/64 loss: 0.31940197944641113
Batch 36/64 loss: 0.3256058692932129
Batch 37/64 loss: 0.3217814564704895
Batch 38/64 loss: 0.3210728168487549
Batch 39/64 loss: 0.32403564453125
Batch 40/64 loss: 0.32959163188934326
Batch 41/64 loss: 0.3202289342880249
Batch 42/64 loss: 0.31855547428131104
Batch 43/64 loss: 0.32653963565826416
Batch 44/64 loss: 0.3211761713027954
Batch 45/64 loss: 0.3277078866958618
Batch 46/64 loss: 0.32490742206573486
Batch 47/64 loss: 0.32128751277923584
Batch 48/64 loss: 0.31737327575683594
Batch 49/64 loss: 0.32070058584213257
Batch 50/64 loss: 0.3200293183326721
Batch 51/64 loss: 0.32031333446502686
Batch 52/64 loss: 0.3274015188217163
Batch 53/64 loss: 0.3310176134109497
Batch 54/64 loss: 0.32547128200531006
Batch 55/64 loss: 0.32566362619400024
Batch 56/64 loss: 0.3152393102645874
Batch 57/64 loss: 0.32627344131469727
Batch 58/64 loss: 0.32089465856552124
Batch 59/64 loss: 0.32697105407714844
Batch 60/64 loss: 0.3231933116912842
Batch 61/64 loss: 0.32365405559539795
Batch 62/64 loss: 0.3260301351547241
Batch 63/64 loss: 0.31873202323913574
Batch 64/64 loss: 0.32056593894958496
Epoch 221  Train loss: 0.3225568677864823  Val loss: 0.33576899439198865
Saving best model, epoch: 221
Epoch 222
-------------------------------
Batch 1/64 loss: 0.32043683528900146
Batch 2/64 loss: 0.32401084899902344
Batch 3/64 loss: 0.3285728693008423
Batch 4/64 loss: 0.32944321632385254
Batch 5/64 loss: 0.32514309883117676
Batch 6/64 loss: 0.3192474842071533
Batch 7/64 loss: 0.3165285587310791
Batch 8/64 loss: 0.32641828060150146
Batch 9/64 loss: 0.3201974630355835
Batch 10/64 loss: 0.32380253076553345
Batch 11/64 loss: 0.31680965423583984
Batch 12/64 loss: 0.3183131217956543
Batch 13/64 loss: 0.3188946843147278
Batch 14/64 loss: 0.3275679349899292
Batch 15/64 loss: 0.3250560760498047
Batch 16/64 loss: 0.3148486614227295
Batch 17/64 loss: 0.3259103298187256
Batch 18/64 loss: 0.3225059509277344
Batch 19/64 loss: 0.3206886649131775
Batch 20/64 loss: 0.32012510299682617
Batch 21/64 loss: 0.31196606159210205
Batch 22/64 loss: 0.31628334522247314
Batch 23/64 loss: 0.3192064166069031
Batch 24/64 loss: 0.31946253776550293
Batch 25/64 loss: 0.3286299705505371
Batch 26/64 loss: 0.3248182535171509
Batch 27/64 loss: 0.32267773151397705
Batch 28/64 loss: 0.3222625255584717
Batch 29/64 loss: 0.32384657859802246
Batch 30/64 loss: 0.3200269937515259
Batch 31/64 loss: 0.3172081708908081
Batch 32/64 loss: 0.31845951080322266
Batch 33/64 loss: 0.3153921961784363
Batch 34/64 loss: 0.326485276222229
Batch 35/64 loss: 0.324832558631897
Batch 36/64 loss: 0.3180392384529114
Batch 37/64 loss: 0.3195875883102417
Batch 38/64 loss: 0.3303946256637573
Batch 39/64 loss: 0.3280184268951416
Batch 40/64 loss: 0.32214438915252686
Batch 41/64 loss: 0.31992673873901367
Batch 42/64 loss: 0.3219009041786194
Batch 43/64 loss: 0.3216410279273987
Batch 44/64 loss: 0.32766300439834595
Batch 45/64 loss: 0.32330358028411865
Batch 46/64 loss: 0.32169294357299805
Batch 47/64 loss: 0.3237261176109314
Batch 48/64 loss: 0.3197646737098694
Batch 49/64 loss: 0.3212430477142334
Batch 50/64 loss: 0.3221242427825928
Batch 51/64 loss: 0.3207368850708008
Batch 52/64 loss: 0.32248133420944214
Batch 53/64 loss: 0.33119070529937744
Batch 54/64 loss: 0.32484591007232666
Batch 55/64 loss: 0.3310837149620056
Batch 56/64 loss: 0.32706427574157715
Batch 57/64 loss: 0.3167964816093445
Batch 58/64 loss: 0.327628493309021
Batch 59/64 loss: 0.3261498212814331
Batch 60/64 loss: 0.32772189378738403
Batch 61/64 loss: 0.3218512535095215
Batch 62/64 loss: 0.32494765520095825
Batch 63/64 loss: 0.33085840940475464
Batch 64/64 loss: 0.3291192650794983
Epoch 222  Train loss: 0.32278347179001454  Val loss: 0.3368793234382708
Epoch 223
-------------------------------
Batch 1/64 loss: 0.32479292154312134
Batch 2/64 loss: 0.32005053758621216
Batch 3/64 loss: 0.32147204875946045
Batch 4/64 loss: 0.3153015375137329
Batch 5/64 loss: 0.32532691955566406
Batch 6/64 loss: 0.3217729330062866
Batch 7/64 loss: 0.32360708713531494
Batch 8/64 loss: 0.3199542760848999
Batch 9/64 loss: 0.32443976402282715
Batch 10/64 loss: 0.3222094774246216
Batch 11/64 loss: 0.32674938440322876
Batch 12/64 loss: 0.3175266981124878
Batch 13/64 loss: 0.322385311126709
Batch 14/64 loss: 0.32059335708618164
Batch 15/64 loss: 0.3265954256057739
Batch 16/64 loss: 0.3172273635864258
Batch 17/64 loss: 0.31506550312042236
Batch 18/64 loss: 0.33021754026412964
Batch 19/64 loss: 0.31661784648895264
Batch 20/64 loss: 0.32206034660339355
Batch 21/64 loss: 0.3270411491394043
Batch 22/64 loss: 0.3271942138671875
Batch 23/64 loss: 0.31854748725891113
Batch 24/64 loss: 0.3228347897529602
Batch 25/64 loss: 0.32070106267929077
Batch 26/64 loss: 0.3266493082046509
Batch 27/64 loss: 0.3323284387588501
Batch 28/64 loss: 0.31781572103500366
Batch 29/64 loss: 0.3237781524658203
Batch 30/64 loss: 0.3213431239128113
Batch 31/64 loss: 0.3180345296859741
Batch 32/64 loss: 0.32075953483581543
Batch 33/64 loss: 0.322390079498291
Batch 34/64 loss: 0.3197598457336426
Batch 35/64 loss: 0.32469993829727173
Batch 36/64 loss: 0.3190777897834778
Batch 37/64 loss: 0.3218435049057007
Batch 38/64 loss: 0.32903605699539185
Batch 39/64 loss: 0.3231922388076782
Batch 40/64 loss: 0.32295453548431396
Batch 41/64 loss: 0.3303377628326416
Batch 42/64 loss: 0.323005735874176
Batch 43/64 loss: 0.330028235912323
Batch 44/64 loss: 0.31951236724853516
Batch 45/64 loss: 0.3196735382080078
Batch 46/64 loss: 0.3185713291168213
Batch 47/64 loss: 0.32214730978012085
Batch 48/64 loss: 0.3203606605529785
Batch 49/64 loss: 0.32359009981155396
Batch 50/64 loss: 0.32546234130859375
Batch 51/64 loss: 0.32041579484939575
Batch 52/64 loss: 0.32140398025512695
Batch 53/64 loss: 0.324509859085083
Batch 54/64 loss: 0.31921911239624023
Batch 55/64 loss: 0.32752859592437744
Batch 56/64 loss: 0.32572734355926514
Batch 57/64 loss: 0.3237786293029785
Batch 58/64 loss: 0.3183090090751648
Batch 59/64 loss: 0.3235403299331665
Batch 60/64 loss: 0.32211512327194214
Batch 61/64 loss: 0.31727075576782227
Batch 62/64 loss: 0.31934940814971924
Batch 63/64 loss: 0.32616275548934937
Batch 64/64 loss: 0.3273317813873291
Epoch 223  Train loss: 0.32253281088436353  Val loss: 0.33588100401396603
Epoch 224
-------------------------------
Batch 1/64 loss: 0.3304925560951233
Batch 2/64 loss: 0.3241257667541504
Batch 3/64 loss: 0.321588397026062
Batch 4/64 loss: 0.33093661069869995
Batch 5/64 loss: 0.32872462272644043
Batch 6/64 loss: 0.3168606162071228
Batch 7/64 loss: 0.3220219612121582
Batch 8/64 loss: 0.31917262077331543
Batch 9/64 loss: 0.31975698471069336
Batch 10/64 loss: 0.32658863067626953
Batch 11/64 loss: 0.3234363794326782
Batch 12/64 loss: 0.328083872795105
Batch 13/64 loss: 0.3175985813140869
Batch 14/64 loss: 0.3255835771560669
Batch 15/64 loss: 0.321493923664093
Batch 16/64 loss: 0.3252262473106384
Batch 17/64 loss: 0.32210880517959595
Batch 18/64 loss: 0.32255589962005615
Batch 19/64 loss: 0.3174591064453125
Batch 20/64 loss: 0.32634246349334717
Batch 21/64 loss: 0.3205578923225403
Batch 22/64 loss: 0.31593865156173706
Batch 23/64 loss: 0.3266160488128662
Batch 24/64 loss: 0.32066869735717773
Batch 25/64 loss: 0.3179718255996704
Batch 26/64 loss: 0.3201051950454712
Batch 27/64 loss: 0.32687342166900635
Batch 28/64 loss: 0.3257334232330322
Batch 29/64 loss: 0.3244001865386963
Batch 30/64 loss: 0.3264637589454651
Batch 31/64 loss: 0.3260871171951294
Batch 32/64 loss: 0.31840211153030396
Batch 33/64 loss: 0.31569623947143555
Batch 34/64 loss: 0.3187119960784912
Batch 35/64 loss: 0.32486480474472046
Batch 36/64 loss: 0.3228710889816284
Batch 37/64 loss: 0.3221139907836914
Batch 38/64 loss: 0.32611584663391113
Batch 39/64 loss: 0.3174179792404175
Batch 40/64 loss: 0.32159531116485596
Batch 41/64 loss: 0.31963568925857544
Batch 42/64 loss: 0.3242337703704834
Batch 43/64 loss: 0.32124650478363037
Batch 44/64 loss: 0.3181261420249939
Batch 45/64 loss: 0.32468533515930176
Batch 46/64 loss: 0.32316118478775024
Batch 47/64 loss: 0.32275688648223877
Batch 48/64 loss: 0.3168160319328308
Batch 49/64 loss: 0.3233841061592102
Batch 50/64 loss: 0.3258974552154541
Batch 51/64 loss: 0.3157691955566406
Batch 52/64 loss: 0.31710898876190186
Batch 53/64 loss: 0.316619873046875
Batch 54/64 loss: 0.3139989376068115
Batch 55/64 loss: 0.32352131605148315
Batch 56/64 loss: 0.32926034927368164
Batch 57/64 loss: 0.3229671120643616
Batch 58/64 loss: 0.32502472400665283
Batch 59/64 loss: 0.32043397426605225
Batch 60/64 loss: 0.3256314992904663
Batch 61/64 loss: 0.3236541152000427
Batch 62/64 loss: 0.3242596387863159
Batch 63/64 loss: 0.324177622795105
Batch 64/64 loss: 0.31306833028793335
Epoch 224  Train loss: 0.32229858683604823  Val loss: 0.33541034279820026
Saving best model, epoch: 224
Epoch 225
-------------------------------
Batch 1/64 loss: 0.3285709619522095
Batch 2/64 loss: 0.3240337371826172
Batch 3/64 loss: 0.33382749557495117
Batch 4/64 loss: 0.3246645927429199
Batch 5/64 loss: 0.32147252559661865
Batch 6/64 loss: 0.32467585802078247
Batch 7/64 loss: 0.32171112298965454
Batch 8/64 loss: 0.31782710552215576
Batch 9/64 loss: 0.32047176361083984
Batch 10/64 loss: 0.3186113238334656
Batch 11/64 loss: 0.31588268280029297
Batch 12/64 loss: 0.3162325620651245
Batch 13/64 loss: 0.3125779628753662
Batch 14/64 loss: 0.31903326511383057
Batch 15/64 loss: 0.32079243659973145
Batch 16/64 loss: 0.3209949731826782
Batch 17/64 loss: 0.32598739862442017
Batch 18/64 loss: 0.3246755599975586
Batch 19/64 loss: 0.32416701316833496
Batch 20/64 loss: 0.3184126615524292
Batch 21/64 loss: 0.3197842836380005
Batch 22/64 loss: 0.3266543745994568
Batch 23/64 loss: 0.3197660446166992
Batch 24/64 loss: 0.330669641494751
Batch 25/64 loss: 0.3215017318725586
Batch 26/64 loss: 0.327225923538208
Batch 27/64 loss: 0.3195212483406067
Batch 28/64 loss: 0.32201218605041504
Batch 29/64 loss: 0.3226924538612366
Batch 30/64 loss: 0.3179160952568054
Batch 31/64 loss: 0.323239803314209
Batch 32/64 loss: 0.31416797637939453
Batch 33/64 loss: 0.31591761112213135
Batch 34/64 loss: 0.323223352432251
Batch 35/64 loss: 0.32163453102111816
Batch 36/64 loss: 0.3257114887237549
Batch 37/64 loss: 0.3230835199356079
Batch 38/64 loss: 0.32417988777160645
Batch 39/64 loss: 0.3247898817062378
Batch 40/64 loss: 0.3259690999984741
Batch 41/64 loss: 0.3220479488372803
Batch 42/64 loss: 0.32573866844177246
Batch 43/64 loss: 0.32280081510543823
Batch 44/64 loss: 0.3217829465866089
Batch 45/64 loss: 0.325691282749176
Batch 46/64 loss: 0.3286306858062744
Batch 47/64 loss: 0.32471609115600586
Batch 48/64 loss: 0.3250514268875122
Batch 49/64 loss: 0.3168787956237793
Batch 50/64 loss: 0.32159388065338135
Batch 51/64 loss: 0.31781303882598877
Batch 52/64 loss: 0.325711727142334
Batch 53/64 loss: 0.3265618085861206
Batch 54/64 loss: 0.32493674755096436
Batch 55/64 loss: 0.32494497299194336
Batch 56/64 loss: 0.3171203136444092
Batch 57/64 loss: 0.3267124891281128
Batch 58/64 loss: 0.3248155117034912
Batch 59/64 loss: 0.3231545686721802
Batch 60/64 loss: 0.31546449661254883
Batch 61/64 loss: 0.31523752212524414
Batch 62/64 loss: 0.3212292194366455
Batch 63/64 loss: 0.3267207741737366
Batch 64/64 loss: 0.314754843711853
Epoch 225  Train loss: 0.32228558437497007  Val loss: 0.3354591942325081
Epoch 226
-------------------------------
Batch 1/64 loss: 0.32056015729904175
Batch 2/64 loss: 0.31932586431503296
Batch 3/64 loss: 0.32841914892196655
Batch 4/64 loss: 0.32203173637390137
Batch 5/64 loss: 0.3205330967903137
Batch 6/64 loss: 0.32180649042129517
Batch 7/64 loss: 0.31805360317230225
Batch 8/64 loss: 0.31918299198150635
Batch 9/64 loss: 0.3187527656555176
Batch 10/64 loss: 0.32695722579956055
Batch 11/64 loss: 0.3207423686981201
Batch 12/64 loss: 0.32133615016937256
Batch 13/64 loss: 0.31817615032196045
Batch 14/64 loss: 0.3209003806114197
Batch 15/64 loss: 0.3175235986709595
Batch 16/64 loss: 0.32302629947662354
Batch 17/64 loss: 0.3237262964248657
Batch 18/64 loss: 0.3171653747558594
Batch 19/64 loss: 0.3203210234642029
Batch 20/64 loss: 0.32405614852905273
Batch 21/64 loss: 0.3222978711128235
Batch 22/64 loss: 0.32025182247161865
Batch 23/64 loss: 0.3127533197402954
Batch 24/64 loss: 0.3263322114944458
Batch 25/64 loss: 0.31849944591522217
Batch 26/64 loss: 0.32293039560317993
Batch 27/64 loss: 0.31712275743484497
Batch 28/64 loss: 0.3204241394996643
Batch 29/64 loss: 0.3259536027908325
Batch 30/64 loss: 0.3213235139846802
Batch 31/64 loss: 0.3219243288040161
Batch 32/64 loss: 0.3201335668563843
Batch 33/64 loss: 0.3196013569831848
Batch 34/64 loss: 0.32904744148254395
Batch 35/64 loss: 0.3234606981277466
Batch 36/64 loss: 0.3157232999801636
Batch 37/64 loss: 0.32177960872650146
Batch 38/64 loss: 0.32374221086502075
Batch 39/64 loss: 0.316057026386261
Batch 40/64 loss: 0.3285641670227051
Batch 41/64 loss: 0.32152652740478516
Batch 42/64 loss: 0.3231765031814575
Batch 43/64 loss: 0.3231104612350464
Batch 44/64 loss: 0.3220289945602417
Batch 45/64 loss: 0.3210536241531372
Batch 46/64 loss: 0.32405924797058105
Batch 47/64 loss: 0.3169513940811157
Batch 48/64 loss: 0.3175976276397705
Batch 49/64 loss: 0.3182792067527771
Batch 50/64 loss: 0.3198815584182739
Batch 51/64 loss: 0.3248955011367798
Batch 52/64 loss: 0.320637047290802
Batch 53/64 loss: 0.3185863494873047
Batch 54/64 loss: 0.32128965854644775
Batch 55/64 loss: 0.3253450393676758
Batch 56/64 loss: 0.3237258195877075
Batch 57/64 loss: 0.3245605230331421
Batch 58/64 loss: 0.3245251178741455
Batch 59/64 loss: 0.3232311010360718
Batch 60/64 loss: 0.323453426361084
Batch 61/64 loss: 0.32235831022262573
Batch 62/64 loss: 0.3215506672859192
Batch 63/64 loss: 0.32815176248550415
Batch 64/64 loss: 0.3235982656478882
Epoch 226  Train loss: 0.3216187266742482  Val loss: 0.33498144477503405
Saving best model, epoch: 226
Epoch 227
-------------------------------
Batch 1/64 loss: 0.3244577646255493
Batch 2/64 loss: 0.31919002532958984
Batch 3/64 loss: 0.32008254528045654
Batch 4/64 loss: 0.3252849578857422
Batch 5/64 loss: 0.3214913606643677
Batch 6/64 loss: 0.32337796688079834
Batch 7/64 loss: 0.3212991952896118
Batch 8/64 loss: 0.31705260276794434
Batch 9/64 loss: 0.31833577156066895
Batch 10/64 loss: 0.3148103356361389
Batch 11/64 loss: 0.3209974765777588
Batch 12/64 loss: 0.3205660581588745
Batch 13/64 loss: 0.3223516345024109
Batch 14/64 loss: 0.32797181606292725
Batch 15/64 loss: 0.3193936347961426
Batch 16/64 loss: 0.3197232484817505
Batch 17/64 loss: 0.31828123331069946
Batch 18/64 loss: 0.31896764039993286
Batch 19/64 loss: 0.32132673263549805
Batch 20/64 loss: 0.3182143568992615
Batch 21/64 loss: 0.3151562809944153
Batch 22/64 loss: 0.327947735786438
Batch 23/64 loss: 0.3167083263397217
Batch 24/64 loss: 0.32314181327819824
Batch 25/64 loss: 0.3168013095855713
Batch 26/64 loss: 0.3182916045188904
Batch 27/64 loss: 0.32164567708969116
Batch 28/64 loss: 0.31878721714019775
Batch 29/64 loss: 0.3265514373779297
Batch 30/64 loss: 0.31816327571868896
Batch 31/64 loss: 0.32615935802459717
Batch 32/64 loss: 0.3273003101348877
Batch 33/64 loss: 0.3197709321975708
Batch 34/64 loss: 0.3255302906036377
Batch 35/64 loss: 0.3237239122390747
Batch 36/64 loss: 0.3234823942184448
Batch 37/64 loss: 0.32251816987991333
Batch 38/64 loss: 0.3202354311943054
Batch 39/64 loss: 0.321763277053833
Batch 40/64 loss: 0.3203713893890381
Batch 41/64 loss: 0.3253988027572632
Batch 42/64 loss: 0.318206787109375
Batch 43/64 loss: 0.3165109157562256
Batch 44/64 loss: 0.3240302801132202
Batch 45/64 loss: 0.32004213333129883
Batch 46/64 loss: 0.3230777978897095
Batch 47/64 loss: 0.3263790011405945
Batch 48/64 loss: 0.32513427734375
Batch 49/64 loss: 0.3214672803878784
Batch 50/64 loss: 0.3254503011703491
Batch 51/64 loss: 0.3205384612083435
Batch 52/64 loss: 0.3204634189605713
Batch 53/64 loss: 0.3197416067123413
Batch 54/64 loss: 0.3237556219100952
Batch 55/64 loss: 0.3207533359527588
Batch 56/64 loss: 0.3209870457649231
Batch 57/64 loss: 0.32991671562194824
Batch 58/64 loss: 0.32493460178375244
Batch 59/64 loss: 0.3261270523071289
Batch 60/64 loss: 0.32647615671157837
Batch 61/64 loss: 0.32047736644744873
Batch 62/64 loss: 0.3219384551048279
Batch 63/64 loss: 0.3242695927619934
Batch 64/64 loss: 0.3126230835914612
Epoch 227  Train loss: 0.32169052268944537  Val loss: 0.33574350449637447
Epoch 228
-------------------------------
Batch 1/64 loss: 0.31492912769317627
Batch 2/64 loss: 0.32593512535095215
Batch 3/64 loss: 0.3219906687736511
Batch 4/64 loss: 0.3252294063568115
Batch 5/64 loss: 0.31095027923583984
Batch 6/64 loss: 0.31846654415130615
Batch 7/64 loss: 0.3169701099395752
Batch 8/64 loss: 0.3155710697174072
Batch 9/64 loss: 0.3208357095718384
Batch 10/64 loss: 0.3184352517127991
Batch 11/64 loss: 0.32138991355895996
Batch 12/64 loss: 0.3212321996688843
Batch 13/64 loss: 0.3181501626968384
Batch 14/64 loss: 0.32431989908218384
Batch 15/64 loss: 0.3146091103553772
Batch 16/64 loss: 0.3200279474258423
Batch 17/64 loss: 0.32124924659729004
Batch 18/64 loss: 0.3249005079269409
Batch 19/64 loss: 0.32459163665771484
Batch 20/64 loss: 0.3211752772331238
Batch 21/64 loss: 0.3225882053375244
Batch 22/64 loss: 0.3274243474006653
Batch 23/64 loss: 0.32881397008895874
Batch 24/64 loss: 0.3127307891845703
Batch 25/64 loss: 0.3177593946456909
Batch 26/64 loss: 0.3263953924179077
Batch 27/64 loss: 0.3262763023376465
Batch 28/64 loss: 0.3197680711746216
Batch 29/64 loss: 0.3210262656211853
Batch 30/64 loss: 0.31278306245803833
Batch 31/64 loss: 0.3223356008529663
Batch 32/64 loss: 0.3250008821487427
Batch 33/64 loss: 0.32607030868530273
Batch 34/64 loss: 0.31365281343460083
Batch 35/64 loss: 0.32160282135009766
Batch 36/64 loss: 0.3215603232383728
Batch 37/64 loss: 0.32284247875213623
Batch 38/64 loss: 0.3170936107635498
Batch 39/64 loss: 0.32600271701812744
Batch 40/64 loss: 0.31963253021240234
Batch 41/64 loss: 0.32485198974609375
Batch 42/64 loss: 0.3270239233970642
Batch 43/64 loss: 0.3208736181259155
Batch 44/64 loss: 0.32182466983795166
Batch 45/64 loss: 0.3184090256690979
Batch 46/64 loss: 0.31775015592575073
Batch 47/64 loss: 0.32185161113739014
Batch 48/64 loss: 0.3324006199836731
Batch 49/64 loss: 0.32591843605041504
Batch 50/64 loss: 0.32478588819503784
Batch 51/64 loss: 0.32759952545166016
Batch 52/64 loss: 0.3276814818382263
Batch 53/64 loss: 0.3227834701538086
Batch 54/64 loss: 0.3163924217224121
Batch 55/64 loss: 0.3135613203048706
Batch 56/64 loss: 0.3279971480369568
Batch 57/64 loss: 0.31528741121292114
Batch 58/64 loss: 0.3197318911552429
Batch 59/64 loss: 0.32979393005371094
Batch 60/64 loss: 0.3204864263534546
Batch 61/64 loss: 0.3245862126350403
Batch 62/64 loss: 0.3229933977127075
Batch 63/64 loss: 0.3225271701812744
Batch 64/64 loss: 0.3275414705276489
Epoch 228  Train loss: 0.3216484224095064  Val loss: 0.3354123492830807
Epoch 229
-------------------------------
Batch 1/64 loss: 0.3275068998336792
Batch 2/64 loss: 0.3214223384857178
Batch 3/64 loss: 0.3186846971511841
Batch 4/64 loss: 0.3209284543991089
Batch 5/64 loss: 0.3150416612625122
Batch 6/64 loss: 0.3256394863128662
Batch 7/64 loss: 0.31927549839019775
Batch 8/64 loss: 0.32028019428253174
Batch 9/64 loss: 0.31972628831863403
Batch 10/64 loss: 0.31785815954208374
Batch 11/64 loss: 0.3170478343963623
Batch 12/64 loss: 0.31636106967926025
Batch 13/64 loss: 0.31655800342559814
Batch 14/64 loss: 0.3218708634376526
Batch 15/64 loss: 0.3221120238304138
Batch 16/64 loss: 0.32189488410949707
Batch 17/64 loss: 0.3156713843345642
Batch 18/64 loss: 0.31770408153533936
Batch 19/64 loss: 0.32118988037109375
Batch 20/64 loss: 0.31835126876831055
Batch 21/64 loss: 0.3147297501564026
Batch 22/64 loss: 0.3214668035507202
Batch 23/64 loss: 0.3154188394546509
Batch 24/64 loss: 0.3262096643447876
Batch 25/64 loss: 0.3175603747367859
Batch 26/64 loss: 0.3202403783798218
Batch 27/64 loss: 0.3181977868080139
Batch 28/64 loss: 0.32396918535232544
Batch 29/64 loss: 0.3257122039794922
Batch 30/64 loss: 0.3237488269805908
Batch 31/64 loss: 0.3196563124656677
Batch 32/64 loss: 0.32226860523223877
Batch 33/64 loss: 0.3345630168914795
Batch 34/64 loss: 0.3213660717010498
Batch 35/64 loss: 0.3290637135505676
Batch 36/64 loss: 0.321697473526001
Batch 37/64 loss: 0.3213806748390198
Batch 38/64 loss: 0.3158167600631714
Batch 39/64 loss: 0.3241448402404785
Batch 40/64 loss: 0.319898784160614
Batch 41/64 loss: 0.33086585998535156
Batch 42/64 loss: 0.32907789945602417
Batch 43/64 loss: 0.3200783133506775
Batch 44/64 loss: 0.3188292980194092
Batch 45/64 loss: 0.33155906200408936
Batch 46/64 loss: 0.3253864645957947
Batch 47/64 loss: 0.3197435140609741
Batch 48/64 loss: 0.31958019733428955
Batch 49/64 loss: 0.3182297945022583
Batch 50/64 loss: 0.31856226921081543
Batch 51/64 loss: 0.32282400131225586
Batch 52/64 loss: 0.3197634220123291
Batch 53/64 loss: 0.32501500844955444
Batch 54/64 loss: 0.31928563117980957
Batch 55/64 loss: 0.3251587152481079
Batch 56/64 loss: 0.32518744468688965
Batch 57/64 loss: 0.32070332765579224
Batch 58/64 loss: 0.32294875383377075
Batch 59/64 loss: 0.3181806206703186
Batch 60/64 loss: 0.32829463481903076
Batch 61/64 loss: 0.32393020391464233
Batch 62/64 loss: 0.3200600743293762
Batch 63/64 loss: 0.31961119174957275
Batch 64/64 loss: 0.3168033957481384
Epoch 229  Train loss: 0.3214543260780035  Val loss: 0.33477178205739183
Saving best model, epoch: 229
Epoch 230
-------------------------------
Batch 1/64 loss: 0.3193545341491699
Batch 2/64 loss: 0.3140879273414612
Batch 3/64 loss: 0.3226454257965088
Batch 4/64 loss: 0.3200194835662842
Batch 5/64 loss: 0.3236809968948364
Batch 6/64 loss: 0.32169193029403687
Batch 7/64 loss: 0.3129711151123047
Batch 8/64 loss: 0.3195458650588989
Batch 9/64 loss: 0.3215975761413574
Batch 10/64 loss: 0.3230295181274414
Batch 11/64 loss: 0.31926804780960083
Batch 12/64 loss: 0.32294368743896484
Batch 13/64 loss: 0.32050764560699463
Batch 14/64 loss: 0.3276599645614624
Batch 15/64 loss: 0.3225405216217041
Batch 16/64 loss: 0.31979286670684814
Batch 17/64 loss: 0.3168666362762451
Batch 18/64 loss: 0.31743186712265015
Batch 19/64 loss: 0.3207118511199951
Batch 20/64 loss: 0.3183583617210388
Batch 21/64 loss: 0.31356745958328247
Batch 22/64 loss: 0.31587183475494385
Batch 23/64 loss: 0.3155595064163208
Batch 24/64 loss: 0.31772303581237793
Batch 25/64 loss: 0.3276253938674927
Batch 26/64 loss: 0.3257834315299988
Batch 27/64 loss: 0.31398987770080566
Batch 28/64 loss: 0.3233144283294678
Batch 29/64 loss: 0.3241446018218994
Batch 30/64 loss: 0.3230154514312744
Batch 31/64 loss: 0.3246626853942871
Batch 32/64 loss: 0.3200122117996216
Batch 33/64 loss: 0.32176488637924194
Batch 34/64 loss: 0.31873732805252075
Batch 35/64 loss: 0.3202480673789978
Batch 36/64 loss: 0.32235419750213623
Batch 37/64 loss: 0.33269059658050537
Batch 38/64 loss: 0.312589168548584
Batch 39/64 loss: 0.32102906703948975
Batch 40/64 loss: 0.31702864170074463
Batch 41/64 loss: 0.32216572761535645
Batch 42/64 loss: 0.3290250897407532
Batch 43/64 loss: 0.3192541003227234
Batch 44/64 loss: 0.32002437114715576
Batch 45/64 loss: 0.3201262950897217
Batch 46/64 loss: 0.3256415128707886
Batch 47/64 loss: 0.3270975351333618
Batch 48/64 loss: 0.31601977348327637
Batch 49/64 loss: 0.32074761390686035
Batch 50/64 loss: 0.322040855884552
Batch 51/64 loss: 0.3182029128074646
Batch 52/64 loss: 0.3258325457572937
Batch 53/64 loss: 0.3169316053390503
Batch 54/64 loss: 0.3192458152770996
Batch 55/64 loss: 0.3249584436416626
Batch 56/64 loss: 0.32093286514282227
Batch 57/64 loss: 0.31894952058792114
Batch 58/64 loss: 0.3183743953704834
Batch 59/64 loss: 0.3213083744049072
Batch 60/64 loss: 0.31726062297821045
Batch 61/64 loss: 0.32598090171813965
Batch 62/64 loss: 0.32344168424606323
Batch 63/64 loss: 0.31686437129974365
Batch 64/64 loss: 0.31336766481399536
Epoch 230  Train loss: 0.32065679021910126  Val loss: 0.33505763302963626
Epoch 231
-------------------------------
Batch 1/64 loss: 0.32457399368286133
Batch 2/64 loss: 0.31513893604278564
Batch 3/64 loss: 0.317571222782135
Batch 4/64 loss: 0.31985706090927124
Batch 5/64 loss: 0.3205876350402832
Batch 6/64 loss: 0.32148391008377075
Batch 7/64 loss: 0.3195483684539795
Batch 8/64 loss: 0.31912755966186523
Batch 9/64 loss: 0.3202955722808838
Batch 10/64 loss: 0.32643187046051025
Batch 11/64 loss: 0.3188563585281372
Batch 12/64 loss: 0.310616135597229
Batch 13/64 loss: 0.3240032196044922
Batch 14/64 loss: 0.3283382058143616
Batch 15/64 loss: 0.3278297185897827
Batch 16/64 loss: 0.33610957860946655
Batch 17/64 loss: 0.32287847995758057
Batch 18/64 loss: 0.3212512731552124
Batch 19/64 loss: 0.31734609603881836
Batch 20/64 loss: 0.31760120391845703
Batch 21/64 loss: 0.31995558738708496
Batch 22/64 loss: 0.32383453845977783
Batch 23/64 loss: 0.3172945976257324
Batch 24/64 loss: 0.3154330253601074
Batch 25/64 loss: 0.32033050060272217
Batch 26/64 loss: 0.3221321105957031
Batch 27/64 loss: 0.31850069761276245
Batch 28/64 loss: 0.32594841718673706
Batch 29/64 loss: 0.32222509384155273
Batch 30/64 loss: 0.3166903257369995
Batch 31/64 loss: 0.3205699920654297
Batch 32/64 loss: 0.3228389024734497
Batch 33/64 loss: 0.3207011818885803
Batch 34/64 loss: 0.31890708208084106
Batch 35/64 loss: 0.3192317485809326
Batch 36/64 loss: 0.3239489793777466
Batch 37/64 loss: 0.3197482228279114
Batch 38/64 loss: 0.3145097494125366
Batch 39/64 loss: 0.3193359375
Batch 40/64 loss: 0.3202285170555115
Batch 41/64 loss: 0.3171415328979492
Batch 42/64 loss: 0.3192194700241089
Batch 43/64 loss: 0.31258219480514526
Batch 44/64 loss: 0.32367533445358276
Batch 45/64 loss: 0.31582266092300415
Batch 46/64 loss: 0.3130059242248535
Batch 47/64 loss: 0.31849926710128784
Batch 48/64 loss: 0.31670475006103516
Batch 49/64 loss: 0.31796056032180786
Batch 50/64 loss: 0.3255038261413574
Batch 51/64 loss: 0.3263446092605591
Batch 52/64 loss: 0.32626593112945557
Batch 53/64 loss: 0.3190866708755493
Batch 54/64 loss: 0.3224707841873169
Batch 55/64 loss: 0.32318824529647827
Batch 56/64 loss: 0.31660032272338867
Batch 57/64 loss: 0.31807732582092285
Batch 58/64 loss: 0.322063684463501
Batch 59/64 loss: 0.3294590711593628
Batch 60/64 loss: 0.3203784227371216
Batch 61/64 loss: 0.330009400844574
Batch 62/64 loss: 0.31875407695770264
Batch 63/64 loss: 0.3155479431152344
Batch 64/64 loss: 0.3151826858520508
Epoch 231  Train loss: 0.32057350009095437  Val loss: 0.335126485201911
Epoch 232
-------------------------------
Batch 1/64 loss: 0.3254162073135376
Batch 2/64 loss: 0.32148420810699463
Batch 3/64 loss: 0.3235410451889038
Batch 4/64 loss: 0.32945162057876587
Batch 5/64 loss: 0.32046234607696533
Batch 6/64 loss: 0.3254604935646057
Batch 7/64 loss: 0.32201337814331055
Batch 8/64 loss: 0.3193841576576233
Batch 9/64 loss: 0.31907224655151367
Batch 10/64 loss: 0.3177143335342407
Batch 11/64 loss: 0.3141922354698181
Batch 12/64 loss: 0.31964927911758423
Batch 13/64 loss: 0.32010185718536377
Batch 14/64 loss: 0.3242626190185547
Batch 15/64 loss: 0.3162729740142822
Batch 16/64 loss: 0.32186365127563477
Batch 17/64 loss: 0.3170440196990967
Batch 18/64 loss: 0.31991004943847656
Batch 19/64 loss: 0.32010889053344727
Batch 20/64 loss: 0.3203684091567993
Batch 21/64 loss: 0.3190597891807556
Batch 22/64 loss: 0.3162722587585449
Batch 23/64 loss: 0.3187439441680908
Batch 24/64 loss: 0.32543474435806274
Batch 25/64 loss: 0.31057465076446533
Batch 26/64 loss: 0.3162536025047302
Batch 27/64 loss: 0.32196366786956787
Batch 28/64 loss: 0.312671422958374
Batch 29/64 loss: 0.31822752952575684
Batch 30/64 loss: 0.3183906078338623
Batch 31/64 loss: 0.32579970359802246
Batch 32/64 loss: 0.32097816467285156
Batch 33/64 loss: 0.3231687545776367
Batch 34/64 loss: 0.3169369697570801
Batch 35/64 loss: 0.326418399810791
Batch 36/64 loss: 0.32472217082977295
Batch 37/64 loss: 0.32146865129470825
Batch 38/64 loss: 0.3139272928237915
Batch 39/64 loss: 0.31857526302337646
Batch 40/64 loss: 0.3233959674835205
Batch 41/64 loss: 0.32325464487075806
Batch 42/64 loss: 0.3240710496902466
Batch 43/64 loss: 0.3187294006347656
Batch 44/64 loss: 0.3209875822067261
Batch 45/64 loss: 0.3219860792160034
Batch 46/64 loss: 0.3182018995285034
Batch 47/64 loss: 0.32366710901260376
Batch 48/64 loss: 0.3271675705909729
Batch 49/64 loss: 0.32565009593963623
Batch 50/64 loss: 0.3156244158744812
Batch 51/64 loss: 0.32036495208740234
Batch 52/64 loss: 0.3323979377746582
Batch 53/64 loss: 0.3177265524864197
Batch 54/64 loss: 0.3209800720214844
Batch 55/64 loss: 0.3245404362678528
Batch 56/64 loss: 0.3227773904800415
Batch 57/64 loss: 0.31845593452453613
Batch 58/64 loss: 0.3142043948173523
Batch 59/64 loss: 0.3153453469276428
Batch 60/64 loss: 0.320736289024353
Batch 61/64 loss: 0.3265041708946228
Batch 62/64 loss: 0.31266987323760986
Batch 63/64 loss: 0.3189535140991211
Batch 64/64 loss: 0.3212021589279175
Epoch 232  Train loss: 0.3205749946482041  Val loss: 0.3343884002711765
Saving best model, epoch: 232
Epoch 233
-------------------------------
Batch 1/64 loss: 0.32196301221847534
Batch 2/64 loss: 0.3257026672363281
Batch 3/64 loss: 0.3219253420829773
Batch 4/64 loss: 0.31796014308929443
Batch 5/64 loss: 0.32204926013946533
Batch 6/64 loss: 0.3237626552581787
Batch 7/64 loss: 0.32153111696243286
Batch 8/64 loss: 0.31754744052886963
Batch 9/64 loss: 0.31479334831237793
Batch 10/64 loss: 0.31635522842407227
Batch 11/64 loss: 0.31804871559143066
Batch 12/64 loss: 0.31932371854782104
Batch 13/64 loss: 0.3195990324020386
Batch 14/64 loss: 0.3137056827545166
Batch 15/64 loss: 0.3129350543022156
Batch 16/64 loss: 0.32194769382476807
Batch 17/64 loss: 0.32318830490112305
Batch 18/64 loss: 0.31945085525512695
Batch 19/64 loss: 0.3200439214706421
Batch 20/64 loss: 0.3307439088821411
Batch 21/64 loss: 0.32130932807922363
Batch 22/64 loss: 0.31905579566955566
Batch 23/64 loss: 0.31950002908706665
Batch 24/64 loss: 0.3213036060333252
Batch 25/64 loss: 0.31648194789886475
Batch 26/64 loss: 0.3155362606048584
Batch 27/64 loss: 0.3279302716255188
Batch 28/64 loss: 0.3144209384918213
Batch 29/64 loss: 0.324368953704834
Batch 30/64 loss: 0.32236552238464355
Batch 31/64 loss: 0.32153892517089844
Batch 32/64 loss: 0.32117027044296265
Batch 33/64 loss: 0.3245992660522461
Batch 34/64 loss: 0.3306255340576172
Batch 35/64 loss: 0.3166680932044983
Batch 36/64 loss: 0.3211928606033325
Batch 37/64 loss: 0.31512022018432617
Batch 38/64 loss: 0.3150438666343689
Batch 39/64 loss: 0.32017016410827637
Batch 40/64 loss: 0.3207134008407593
Batch 41/64 loss: 0.3197287321090698
Batch 42/64 loss: 0.324102520942688
Batch 43/64 loss: 0.3184990882873535
Batch 44/64 loss: 0.3226704001426697
Batch 45/64 loss: 0.31894540786743164
Batch 46/64 loss: 0.3255680203437805
Batch 47/64 loss: 0.32168567180633545
Batch 48/64 loss: 0.32157135009765625
Batch 49/64 loss: 0.3168073296546936
Batch 50/64 loss: 0.3179705739021301
Batch 51/64 loss: 0.3257441520690918
Batch 52/64 loss: 0.30967140197753906
Batch 53/64 loss: 0.3166559934616089
Batch 54/64 loss: 0.32240229845046997
Batch 55/64 loss: 0.32106566429138184
Batch 56/64 loss: 0.32377541065216064
Batch 57/64 loss: 0.32152891159057617
Batch 58/64 loss: 0.3100011348724365
Batch 59/64 loss: 0.32981234788894653
Batch 60/64 loss: 0.3247016668319702
Batch 61/64 loss: 0.320376992225647
Batch 62/64 loss: 0.324556827545166
Batch 63/64 loss: 0.3224823474884033
Batch 64/64 loss: 0.32695358991622925
Epoch 233  Train loss: 0.3205840281411713  Val loss: 0.3356504362473373
Epoch 234
-------------------------------
Batch 1/64 loss: 0.32631051540374756
Batch 2/64 loss: 0.3229385018348694
Batch 3/64 loss: 0.3252820372581482
Batch 4/64 loss: 0.32123661041259766
Batch 5/64 loss: 0.3131449818611145
Batch 6/64 loss: 0.3150104880332947
Batch 7/64 loss: 0.3154057264328003
Batch 8/64 loss: 0.32103443145751953
Batch 9/64 loss: 0.32348448038101196
Batch 10/64 loss: 0.32199203968048096
Batch 11/64 loss: 0.32546210289001465
Batch 12/64 loss: 0.32272815704345703
Batch 13/64 loss: 0.3153928518295288
Batch 14/64 loss: 0.32226258516311646
Batch 15/64 loss: 0.31271594762802124
Batch 16/64 loss: 0.3236790895462036
Batch 17/64 loss: 0.31868892908096313
Batch 18/64 loss: 0.3225122094154358
Batch 19/64 loss: 0.3209291696548462
Batch 20/64 loss: 0.3292461633682251
Batch 21/64 loss: 0.3233439326286316
Batch 22/64 loss: 0.320551335811615
Batch 23/64 loss: 0.32398879528045654
Batch 24/64 loss: 0.3162103295326233
Batch 25/64 loss: 0.31757354736328125
Batch 26/64 loss: 0.3177383542060852
Batch 27/64 loss: 0.31295478343963623
Batch 28/64 loss: 0.3203454613685608
Batch 29/64 loss: 0.3234446048736572
Batch 30/64 loss: 0.3150136470794678
Batch 31/64 loss: 0.3243314027786255
Batch 32/64 loss: 0.3181896209716797
Batch 33/64 loss: 0.3126974105834961
Batch 34/64 loss: 0.3215601444244385
Batch 35/64 loss: 0.3188115954399109
Batch 36/64 loss: 0.32568198442459106
Batch 37/64 loss: 0.3222028613090515
Batch 38/64 loss: 0.31676286458969116
Batch 39/64 loss: 0.32071876525878906
Batch 40/64 loss: 0.32134103775024414
Batch 41/64 loss: 0.3210892081260681
Batch 42/64 loss: 0.3224787712097168
Batch 43/64 loss: 0.311911940574646
Batch 44/64 loss: 0.3212869167327881
Batch 45/64 loss: 0.31534528732299805
Batch 46/64 loss: 0.3237307667732239
Batch 47/64 loss: 0.3211866617202759
Batch 48/64 loss: 0.3271551728248596
Batch 49/64 loss: 0.3212891221046448
Batch 50/64 loss: 0.31591320037841797
Batch 51/64 loss: 0.3214390277862549
Batch 52/64 loss: 0.31732213497161865
Batch 53/64 loss: 0.3175475597381592
Batch 54/64 loss: 0.32161271572113037
Batch 55/64 loss: 0.3148893713951111
Batch 56/64 loss: 0.3211348056793213
Batch 57/64 loss: 0.32226765155792236
Batch 58/64 loss: 0.3067591190338135
Batch 59/64 loss: 0.3137269616127014
Batch 60/64 loss: 0.3231198787689209
Batch 61/64 loss: 0.3238871693611145
Batch 62/64 loss: 0.3238309621810913
Batch 63/64 loss: 0.3161720037460327
Batch 64/64 loss: 0.31833595037460327
Epoch 234  Train loss: 0.31994929991516413  Val loss: 0.33407639740258965
Saving best model, epoch: 234
Epoch 235
-------------------------------
Batch 1/64 loss: 0.325286865234375
Batch 2/64 loss: 0.31580913066864014
Batch 3/64 loss: 0.31518036127090454
Batch 4/64 loss: 0.31793200969696045
Batch 5/64 loss: 0.31886810064315796
Batch 6/64 loss: 0.325824499130249
Batch 7/64 loss: 0.3130725026130676
Batch 8/64 loss: 0.31646478176116943
Batch 9/64 loss: 0.31364428997039795
Batch 10/64 loss: 0.32199859619140625
Batch 11/64 loss: 0.3203003406524658
Batch 12/64 loss: 0.31887227296829224
Batch 13/64 loss: 0.3143377900123596
Batch 14/64 loss: 0.3136545419692993
Batch 15/64 loss: 0.3156420588493347
Batch 16/64 loss: 0.317104697227478
Batch 17/64 loss: 0.31808650493621826
Batch 18/64 loss: 0.3234177231788635
Batch 19/64 loss: 0.3190511465072632
Batch 20/64 loss: 0.3168455958366394
Batch 21/64 loss: 0.31524044275283813
Batch 22/64 loss: 0.3255268931388855
Batch 23/64 loss: 0.32462823390960693
Batch 24/64 loss: 0.32304316759109497
Batch 25/64 loss: 0.3178548812866211
Batch 26/64 loss: 0.3253593444824219
Batch 27/64 loss: 0.3170114755630493
Batch 28/64 loss: 0.31805145740509033
Batch 29/64 loss: 0.3202824592590332
Batch 30/64 loss: 0.3190680146217346
Batch 31/64 loss: 0.3145377039909363
Batch 32/64 loss: 0.3205674886703491
Batch 33/64 loss: 0.3237590789794922
Batch 34/64 loss: 0.3146296739578247
Batch 35/64 loss: 0.3217775225639343
Batch 36/64 loss: 0.31831490993499756
Batch 37/64 loss: 0.3206077218055725
Batch 38/64 loss: 0.31451380252838135
Batch 39/64 loss: 0.32449984550476074
Batch 40/64 loss: 0.3199664354324341
Batch 41/64 loss: 0.32071489095687866
Batch 42/64 loss: 0.32373034954071045
Batch 43/64 loss: 0.31621360778808594
Batch 44/64 loss: 0.31905317306518555
Batch 45/64 loss: 0.3168759346008301
Batch 46/64 loss: 0.3162800669670105
Batch 47/64 loss: 0.3311495780944824
Batch 48/64 loss: 0.32283782958984375
Batch 49/64 loss: 0.31922054290771484
Batch 50/64 loss: 0.3182344436645508
Batch 51/64 loss: 0.3269129991531372
Batch 52/64 loss: 0.32498347759246826
Batch 53/64 loss: 0.32107990980148315
Batch 54/64 loss: 0.3167458772659302
Batch 55/64 loss: 0.3206554055213928
Batch 56/64 loss: 0.321022629737854
Batch 57/64 loss: 0.3313279151916504
Batch 58/64 loss: 0.3237220048904419
Batch 59/64 loss: 0.31451910734176636
Batch 60/64 loss: 0.3176281452178955
Batch 61/64 loss: 0.31448841094970703
Batch 62/64 loss: 0.31886351108551025
Batch 63/64 loss: 0.3191152811050415
Batch 64/64 loss: 0.3178372383117676
Epoch 235  Train loss: 0.31959823346605487  Val loss: 0.33421195372683077
Epoch 236
-------------------------------
Batch 1/64 loss: 0.3172309994697571
Batch 2/64 loss: 0.3161517381668091
Batch 3/64 loss: 0.32239025831222534
Batch 4/64 loss: 0.31461524963378906
Batch 5/64 loss: 0.31208401918411255
Batch 6/64 loss: 0.318605899810791
Batch 7/64 loss: 0.3201385736465454
Batch 8/64 loss: 0.3118174076080322
Batch 9/64 loss: 0.31747591495513916
Batch 10/64 loss: 0.3230341672897339
Batch 11/64 loss: 0.31447410583496094
Batch 12/64 loss: 0.31589198112487793
Batch 13/64 loss: 0.3274887204170227
Batch 14/64 loss: 0.32385683059692383
Batch 15/64 loss: 0.31312698125839233
Batch 16/64 loss: 0.31247997283935547
Batch 17/64 loss: 0.3217807412147522
Batch 18/64 loss: 0.32040244340896606
Batch 19/64 loss: 0.3129143714904785
Batch 20/64 loss: 0.3224940299987793
Batch 21/64 loss: 0.316666841506958
Batch 22/64 loss: 0.31756091117858887
Batch 23/64 loss: 0.3213126063346863
Batch 24/64 loss: 0.3266493082046509
Batch 25/64 loss: 0.3263953924179077
Batch 26/64 loss: 0.32143890857696533
Batch 27/64 loss: 0.321258544921875
Batch 28/64 loss: 0.32294762134552
Batch 29/64 loss: 0.32257944345474243
Batch 30/64 loss: 0.32205092906951904
Batch 31/64 loss: 0.3185865879058838
Batch 32/64 loss: 0.31282174587249756
Batch 33/64 loss: 0.32096946239471436
Batch 34/64 loss: 0.3180657625198364
Batch 35/64 loss: 0.3197478652000427
Batch 36/64 loss: 0.31986916065216064
Batch 37/64 loss: 0.3190308213233948
Batch 38/64 loss: 0.31913721561431885
Batch 39/64 loss: 0.3232611417770386
Batch 40/64 loss: 0.3080323338508606
Batch 41/64 loss: 0.32231640815734863
Batch 42/64 loss: 0.31832945346832275
Batch 43/64 loss: 0.3235524892807007
Batch 44/64 loss: 0.328457772731781
Batch 45/64 loss: 0.318098783493042
Batch 46/64 loss: 0.3195115327835083
Batch 47/64 loss: 0.3152387738227844
Batch 48/64 loss: 0.3231833577156067
Batch 49/64 loss: 0.3170510530471802
Batch 50/64 loss: 0.31887441873550415
Batch 51/64 loss: 0.3261992931365967
Batch 52/64 loss: 0.31540876626968384
Batch 53/64 loss: 0.32188063859939575
Batch 54/64 loss: 0.316353976726532
Batch 55/64 loss: 0.3171999454498291
Batch 56/64 loss: 0.3085750937461853
Batch 57/64 loss: 0.3267371654510498
Batch 58/64 loss: 0.3216968774795532
Batch 59/64 loss: 0.31823861598968506
Batch 60/64 loss: 0.31932079792022705
Batch 61/64 loss: 0.32290059328079224
Batch 62/64 loss: 0.32360363006591797
Batch 63/64 loss: 0.32250893115997314
Batch 64/64 loss: 0.31547248363494873
Epoch 236  Train loss: 0.31935183908425124  Val loss: 0.3357252505227053
Epoch 237
-------------------------------
Batch 1/64 loss: 0.31512361764907837
Batch 2/64 loss: 0.32128363847732544
Batch 3/64 loss: 0.31688082218170166
Batch 4/64 loss: 0.31452685594558716
Batch 5/64 loss: 0.317213237285614
Batch 6/64 loss: 0.31803083419799805
Batch 7/64 loss: 0.3194432258605957
Batch 8/64 loss: 0.32192325592041016
Batch 9/64 loss: 0.3245326280593872
Batch 10/64 loss: 0.31854134798049927
Batch 11/64 loss: 0.3211994171142578
Batch 12/64 loss: 0.3298921585083008
Batch 13/64 loss: 0.31866174936294556
Batch 14/64 loss: 0.32425862550735474
Batch 15/64 loss: 0.31997543573379517
Batch 16/64 loss: 0.3168649673461914
Batch 17/64 loss: 0.3160088062286377
Batch 18/64 loss: 0.3174562454223633
Batch 19/64 loss: 0.32219403982162476
Batch 20/64 loss: 0.3192843198776245
Batch 21/64 loss: 0.3232080936431885
Batch 22/64 loss: 0.3120564818382263
Batch 23/64 loss: 0.32260560989379883
Batch 24/64 loss: 0.31181395053863525
Batch 25/64 loss: 0.314159631729126
Batch 26/64 loss: 0.3176589012145996
Batch 27/64 loss: 0.31908661127090454
Batch 28/64 loss: 0.31294190883636475
Batch 29/64 loss: 0.3195606470108032
Batch 30/64 loss: 0.32138174772262573
Batch 31/64 loss: 0.32114195823669434
Batch 32/64 loss: 0.31717681884765625
Batch 33/64 loss: 0.3211488723754883
Batch 34/64 loss: 0.31881117820739746
Batch 35/64 loss: 0.3202970027923584
Batch 36/64 loss: 0.3217102289199829
Batch 37/64 loss: 0.33365511894226074
Batch 38/64 loss: 0.3296489715576172
Batch 39/64 loss: 0.3203524351119995
Batch 40/64 loss: 0.3198373317718506
Batch 41/64 loss: 0.3249671459197998
Batch 42/64 loss: 0.32224738597869873
Batch 43/64 loss: 0.3228508234024048
Batch 44/64 loss: 0.3158186674118042
Batch 45/64 loss: 0.3213188052177429
Batch 46/64 loss: 0.32101237773895264
Batch 47/64 loss: 0.3242909908294678
Batch 48/64 loss: 0.3257565498352051
Batch 49/64 loss: 0.31787705421447754
Batch 50/64 loss: 0.31939613819122314
Batch 51/64 loss: 0.3167704939842224
Batch 52/64 loss: 0.32265257835388184
Batch 53/64 loss: 0.32034486532211304
Batch 54/64 loss: 0.3175450563430786
Batch 55/64 loss: 0.3163154125213623
Batch 56/64 loss: 0.3290330767631531
Batch 57/64 loss: 0.3216054439544678
Batch 58/64 loss: 0.321030855178833
Batch 59/64 loss: 0.32051241397857666
Batch 60/64 loss: 0.31935906410217285
Batch 61/64 loss: 0.3206080198287964
Batch 62/64 loss: 0.3189975619316101
Batch 63/64 loss: 0.3134809136390686
Batch 64/64 loss: 0.31730735301971436
Epoch 237  Train loss: 0.32005209315056893  Val loss: 0.3337810953048496
Saving best model, epoch: 237
Epoch 238
-------------------------------
Batch 1/64 loss: 0.3219066858291626
Batch 2/64 loss: 0.3270793557167053
Batch 3/64 loss: 0.3219078779220581
Batch 4/64 loss: 0.31613028049468994
Batch 5/64 loss: 0.3154078722000122
Batch 6/64 loss: 0.31672126054763794
Batch 7/64 loss: 0.3193647861480713
Batch 8/64 loss: 0.3181368112564087
Batch 9/64 loss: 0.3175419569015503
Batch 10/64 loss: 0.3146095275878906
Batch 11/64 loss: 0.3172686696052551
Batch 12/64 loss: 0.31948745250701904
Batch 13/64 loss: 0.3176860809326172
Batch 14/64 loss: 0.3164830207824707
Batch 15/64 loss: 0.3164334297180176
Batch 16/64 loss: 0.31486910581588745
Batch 17/64 loss: 0.31486427783966064
Batch 18/64 loss: 0.31934237480163574
Batch 19/64 loss: 0.32598650455474854
Batch 20/64 loss: 0.31538885831832886
Batch 21/64 loss: 0.3160841464996338
Batch 22/64 loss: 0.31659579277038574
Batch 23/64 loss: 0.32655590772628784
Batch 24/64 loss: 0.31759393215179443
Batch 25/64 loss: 0.3232063055038452
Batch 26/64 loss: 0.3218228816986084
Batch 27/64 loss: 0.3170166015625
Batch 28/64 loss: 0.3148424029350281
Batch 29/64 loss: 0.33178460597991943
Batch 30/64 loss: 0.31683897972106934
Batch 31/64 loss: 0.32481276988983154
Batch 32/64 loss: 0.31792330741882324
Batch 33/64 loss: 0.32048290967941284
Batch 34/64 loss: 0.3147926926612854
Batch 35/64 loss: 0.31482183933258057
Batch 36/64 loss: 0.3221510648727417
Batch 37/64 loss: 0.3245398998260498
Batch 38/64 loss: 0.32545042037963867
Batch 39/64 loss: 0.326144278049469
Batch 40/64 loss: 0.3174363374710083
Batch 41/64 loss: 0.31034862995147705
Batch 42/64 loss: 0.3233782649040222
Batch 43/64 loss: 0.311947762966156
Batch 44/64 loss: 0.3214455842971802
Batch 45/64 loss: 0.32330620288848877
Batch 46/64 loss: 0.3245662450790405
Batch 47/64 loss: 0.3195258378982544
Batch 48/64 loss: 0.32107609510421753
Batch 49/64 loss: 0.31859880685806274
Batch 50/64 loss: 0.3266475200653076
Batch 51/64 loss: 0.31651240587234497
Batch 52/64 loss: 0.3126455545425415
Batch 53/64 loss: 0.3186197280883789
Batch 54/64 loss: 0.3191027045249939
Batch 55/64 loss: 0.3198883533477783
Batch 56/64 loss: 0.3214614987373352
Batch 57/64 loss: 0.31970852613449097
Batch 58/64 loss: 0.3207508325576782
Batch 59/64 loss: 0.3139649033546448
Batch 60/64 loss: 0.32326507568359375
Batch 61/64 loss: 0.3186591863632202
Batch 62/64 loss: 0.32142174243927
Batch 63/64 loss: 0.32001161575317383
Batch 64/64 loss: 0.3230555057525635
Epoch 238  Train loss: 0.31947698780134615  Val loss: 0.33385356021500945
Epoch 239
-------------------------------
Batch 1/64 loss: 0.31478703022003174
Batch 2/64 loss: 0.31550467014312744
Batch 3/64 loss: 0.3227077126502991
Batch 4/64 loss: 0.31796693801879883
Batch 5/64 loss: 0.31848442554473877
Batch 6/64 loss: 0.31163132190704346
Batch 7/64 loss: 0.31542646884918213
Batch 8/64 loss: 0.31825536489486694
Batch 9/64 loss: 0.32068777084350586
Batch 10/64 loss: 0.3157649040222168
Batch 11/64 loss: 0.3196291923522949
Batch 12/64 loss: 0.3207350969314575
Batch 13/64 loss: 0.320562481880188
Batch 14/64 loss: 0.31342917680740356
Batch 15/64 loss: 0.3179208040237427
Batch 16/64 loss: 0.31929779052734375
Batch 17/64 loss: 0.31505489349365234
Batch 18/64 loss: 0.31775081157684326
Batch 19/64 loss: 0.31646400690078735
Batch 20/64 loss: 0.321616530418396
Batch 21/64 loss: 0.32010358572006226
Batch 22/64 loss: 0.3200950026512146
Batch 23/64 loss: 0.3260290026664734
Batch 24/64 loss: 0.3229255676269531
Batch 25/64 loss: 0.32002925872802734
Batch 26/64 loss: 0.3201873302459717
Batch 27/64 loss: 0.32316941022872925
Batch 28/64 loss: 0.32403308153152466
Batch 29/64 loss: 0.323955774307251
Batch 30/64 loss: 0.3251592516899109
Batch 31/64 loss: 0.3230718970298767
Batch 32/64 loss: 0.3178877830505371
Batch 33/64 loss: 0.31857573986053467
Batch 34/64 loss: 0.3222119212150574
Batch 35/64 loss: 0.3139611482620239
Batch 36/64 loss: 0.3225182890892029
Batch 37/64 loss: 0.31671416759490967
Batch 38/64 loss: 0.31670325994491577
Batch 39/64 loss: 0.31727540493011475
Batch 40/64 loss: 0.32405757904052734
Batch 41/64 loss: 0.31851303577423096
Batch 42/64 loss: 0.3156495690345764
Batch 43/64 loss: 0.31323564052581787
Batch 44/64 loss: 0.3200141191482544
Batch 45/64 loss: 0.3163142204284668
Batch 46/64 loss: 0.3194841146469116
Batch 47/64 loss: 0.3210688829421997
Batch 48/64 loss: 0.3132258653640747
Batch 49/64 loss: 0.3184623718261719
Batch 50/64 loss: 0.3140553832054138
Batch 51/64 loss: 0.317690372467041
Batch 52/64 loss: 0.31658053398132324
Batch 53/64 loss: 0.3240336775779724
Batch 54/64 loss: 0.3190392255783081
Batch 55/64 loss: 0.32149964570999146
Batch 56/64 loss: 0.3177558183670044
Batch 57/64 loss: 0.32884663343429565
Batch 58/64 loss: 0.3213959336280823
Batch 59/64 loss: 0.3097933530807495
Batch 60/64 loss: 0.32472848892211914
Batch 61/64 loss: 0.31379830837249756
Batch 62/64 loss: 0.32174015045166016
Batch 63/64 loss: 0.3246445059776306
Batch 64/64 loss: 0.3134942650794983
Epoch 239  Train loss: 0.319043645438026  Val loss: 0.33420273446545157
Epoch 240
-------------------------------
Batch 1/64 loss: 0.32268476486206055
Batch 2/64 loss: 0.31236839294433594
Batch 3/64 loss: 0.321663498878479
Batch 4/64 loss: 0.31845569610595703
Batch 5/64 loss: 0.32140201330184937
Batch 6/64 loss: 0.32071900367736816
Batch 7/64 loss: 0.31852275133132935
Batch 8/64 loss: 0.3170856237411499
Batch 9/64 loss: 0.32285940647125244
Batch 10/64 loss: 0.32223081588745117
Batch 11/64 loss: 0.3203490972518921
Batch 12/64 loss: 0.3204362988471985
Batch 13/64 loss: 0.31959837675094604
Batch 14/64 loss: 0.315409779548645
Batch 15/64 loss: 0.3141656517982483
Batch 16/64 loss: 0.3207205533981323
Batch 17/64 loss: 0.31684863567352295
Batch 18/64 loss: 0.30600064992904663
Batch 19/64 loss: 0.32329416275024414
Batch 20/64 loss: 0.3197556138038635
Batch 21/64 loss: 0.3164178133010864
Batch 22/64 loss: 0.3155951499938965
Batch 23/64 loss: 0.32530367374420166
Batch 24/64 loss: 0.3184148073196411
Batch 25/64 loss: 0.31737077236175537
Batch 26/64 loss: 0.3073425889015198
Batch 27/64 loss: 0.32231104373931885
Batch 28/64 loss: 0.31389176845550537
Batch 29/64 loss: 0.3203807473182678
Batch 30/64 loss: 0.3194921016693115
Batch 31/64 loss: 0.3220336437225342
Batch 32/64 loss: 0.316378116607666
Batch 33/64 loss: 0.31965070962905884
Batch 34/64 loss: 0.31922024488449097
Batch 35/64 loss: 0.3164141774177551
Batch 36/64 loss: 0.3151160478591919
Batch 37/64 loss: 0.3186994194984436
Batch 38/64 loss: 0.32277238368988037
Batch 39/64 loss: 0.31947755813598633
Batch 40/64 loss: 0.3212704658508301
Batch 41/64 loss: 0.3161779046058655
Batch 42/64 loss: 0.3244051933288574
Batch 43/64 loss: 0.3196045160293579
Batch 44/64 loss: 0.32237982749938965
Batch 45/64 loss: 0.3133286237716675
Batch 46/64 loss: 0.3182309865951538
Batch 47/64 loss: 0.3171294331550598
Batch 48/64 loss: 0.3238658308982849
Batch 49/64 loss: 0.32316112518310547
Batch 50/64 loss: 0.31477677822113037
Batch 51/64 loss: 0.31611526012420654
Batch 52/64 loss: 0.3212575912475586
Batch 53/64 loss: 0.3162280321121216
Batch 54/64 loss: 0.3178749084472656
Batch 55/64 loss: 0.32553356885910034
Batch 56/64 loss: 0.3201742172241211
Batch 57/64 loss: 0.3185248374938965
Batch 58/64 loss: 0.31897008419036865
Batch 59/64 loss: 0.3262832760810852
Batch 60/64 loss: 0.32461827993392944
Batch 61/64 loss: 0.32448434829711914
Batch 62/64 loss: 0.3204101324081421
Batch 63/64 loss: 0.32034367322921753
Batch 64/64 loss: 0.31362712383270264
Epoch 240  Train loss: 0.3190780045939427  Val loss: 0.33319666295526773
Saving best model, epoch: 240
Epoch 241
-------------------------------
Batch 1/64 loss: 0.3060033321380615
Batch 2/64 loss: 0.31447750329971313
Batch 3/64 loss: 0.3182189464569092
Batch 4/64 loss: 0.318661630153656
Batch 5/64 loss: 0.3157476782798767
Batch 6/64 loss: 0.3269338011741638
Batch 7/64 loss: 0.3162475824356079
Batch 8/64 loss: 0.3199922442436218
Batch 9/64 loss: 0.3169534206390381
Batch 10/64 loss: 0.3170166015625
Batch 11/64 loss: 0.32098817825317383
Batch 12/64 loss: 0.3181559443473816
Batch 13/64 loss: 0.3188103437423706
Batch 14/64 loss: 0.31812167167663574
Batch 15/64 loss: 0.315163254737854
Batch 16/64 loss: 0.3203437328338623
Batch 17/64 loss: 0.32018887996673584
Batch 18/64 loss: 0.3208314776420593
Batch 19/64 loss: 0.3156067132949829
Batch 20/64 loss: 0.3190039396286011
Batch 21/64 loss: 0.314217209815979
Batch 22/64 loss: 0.32031846046447754
Batch 23/64 loss: 0.3159990906715393
Batch 24/64 loss: 0.3238208293914795
Batch 25/64 loss: 0.3227543234825134
Batch 26/64 loss: 0.3132582902908325
Batch 27/64 loss: 0.31850767135620117
Batch 28/64 loss: 0.31797516345977783
Batch 29/64 loss: 0.3157586455345154
Batch 30/64 loss: 0.3276141881942749
Batch 31/64 loss: 0.31253671646118164
Batch 32/64 loss: 0.31567227840423584
Batch 33/64 loss: 0.31746816635131836
Batch 34/64 loss: 0.31942427158355713
Batch 35/64 loss: 0.313043475151062
Batch 36/64 loss: 0.314888596534729
Batch 37/64 loss: 0.31656306982040405
Batch 38/64 loss: 0.3156924843788147
Batch 39/64 loss: 0.3239787817001343
Batch 40/64 loss: 0.3234708309173584
Batch 41/64 loss: 0.32108616828918457
Batch 42/64 loss: 0.31305718421936035
Batch 43/64 loss: 0.31660664081573486
Batch 44/64 loss: 0.31703561544418335
Batch 45/64 loss: 0.3153826594352722
Batch 46/64 loss: 0.31913167238235474
Batch 47/64 loss: 0.3169538974761963
Batch 48/64 loss: 0.31158727407455444
Batch 49/64 loss: 0.32273852825164795
Batch 50/64 loss: 0.3217155933380127
Batch 51/64 loss: 0.3167443871498108
Batch 52/64 loss: 0.3246039152145386
Batch 53/64 loss: 0.3241046667098999
Batch 54/64 loss: 0.3273804187774658
Batch 55/64 loss: 0.32205939292907715
Batch 56/64 loss: 0.3197289705276489
Batch 57/64 loss: 0.315559983253479
Batch 58/64 loss: 0.32151758670806885
Batch 59/64 loss: 0.31712353229522705
Batch 60/64 loss: 0.326285719871521
Batch 61/64 loss: 0.31709474325180054
Batch 62/64 loss: 0.32842981815338135
Batch 63/64 loss: 0.3139704465866089
Batch 64/64 loss: 0.324257493019104
Epoch 241  Train loss: 0.31864347224142037  Val loss: 0.3345238402537054
Epoch 242
-------------------------------
Batch 1/64 loss: 0.32139384746551514
Batch 2/64 loss: 0.31783825159072876
Batch 3/64 loss: 0.31618428230285645
Batch 4/64 loss: 0.3178342580795288
Batch 5/64 loss: 0.31777000427246094
Batch 6/64 loss: 0.30953824520111084
Batch 7/64 loss: 0.31871891021728516
Batch 8/64 loss: 0.3261241316795349
Batch 9/64 loss: 0.3199266195297241
Batch 10/64 loss: 0.32124125957489014
Batch 11/64 loss: 0.3169897794723511
Batch 12/64 loss: 0.3187434673309326
Batch 13/64 loss: 0.32756125926971436
Batch 14/64 loss: 0.31557536125183105
Batch 15/64 loss: 0.3164486885070801
Batch 16/64 loss: 0.3204002380371094
Batch 17/64 loss: 0.3188053369522095
Batch 18/64 loss: 0.317518413066864
Batch 19/64 loss: 0.3135266900062561
Batch 20/64 loss: 0.31408363580703735
Batch 21/64 loss: 0.3106371760368347
Batch 22/64 loss: 0.31778085231781006
Batch 23/64 loss: 0.3201826214790344
Batch 24/64 loss: 0.32555294036865234
Batch 25/64 loss: 0.31360113620758057
Batch 26/64 loss: 0.31942588090896606
Batch 27/64 loss: 0.32110434770584106
Batch 28/64 loss: 0.31648313999176025
Batch 29/64 loss: 0.31935828924179077
Batch 30/64 loss: 0.32182371616363525
Batch 31/64 loss: 0.3234500288963318
Batch 32/64 loss: 0.3224201202392578
Batch 33/64 loss: 0.3193265199661255
Batch 34/64 loss: 0.3144766092300415
Batch 35/64 loss: 0.3203113079071045
Batch 36/64 loss: 0.3198689818382263
Batch 37/64 loss: 0.3262680768966675
Batch 38/64 loss: 0.31912338733673096
Batch 39/64 loss: 0.3214949369430542
Batch 40/64 loss: 0.31444138288497925
Batch 41/64 loss: 0.3165191411972046
Batch 42/64 loss: 0.3179590106010437
Batch 43/64 loss: 0.3169781565666199
Batch 44/64 loss: 0.3315165042877197
Batch 45/64 loss: 0.31155550479888916
Batch 46/64 loss: 0.3147526979446411
Batch 47/64 loss: 0.3213912844657898
Batch 48/64 loss: 0.32034289836883545
Batch 49/64 loss: 0.31707704067230225
Batch 50/64 loss: 0.32982444763183594
Batch 51/64 loss: 0.3141154646873474
Batch 52/64 loss: 0.31592482328414917
Batch 53/64 loss: 0.32457399368286133
Batch 54/64 loss: 0.3207125663757324
Batch 55/64 loss: 0.3185656666755676
Batch 56/64 loss: 0.3126145005226135
Batch 57/64 loss: 0.31206679344177246
Batch 58/64 loss: 0.3211964964866638
Batch 59/64 loss: 0.3176473379135132
Batch 60/64 loss: 0.3217034935951233
Batch 61/64 loss: 0.3129758834838867
Batch 62/64 loss: 0.31680917739868164
Batch 63/64 loss: 0.32570046186447144
Batch 64/64 loss: 0.3210355043411255
Epoch 242  Train loss: 0.31884947617848713  Val loss: 0.3334902465548302
Epoch 243
-------------------------------
Batch 1/64 loss: 0.31074005365371704
Batch 2/64 loss: 0.313477098941803
Batch 3/64 loss: 0.31361615657806396
Batch 4/64 loss: 0.313407838344574
Batch 5/64 loss: 0.32390421628952026
Batch 6/64 loss: 0.3201432228088379
Batch 7/64 loss: 0.31406712532043457
Batch 8/64 loss: 0.3176451325416565
Batch 9/64 loss: 0.32350313663482666
Batch 10/64 loss: 0.31754791736602783
Batch 11/64 loss: 0.31238818168640137
Batch 12/64 loss: 0.32031774520874023
Batch 13/64 loss: 0.31619375944137573
Batch 14/64 loss: 0.3120787739753723
Batch 15/64 loss: 0.3132517337799072
Batch 16/64 loss: 0.32250237464904785
Batch 17/64 loss: 0.31798237562179565
Batch 18/64 loss: 0.31886065006256104
Batch 19/64 loss: 0.3212590217590332
Batch 20/64 loss: 0.3208400011062622
Batch 21/64 loss: 0.3148191571235657
Batch 22/64 loss: 0.3203127980232239
Batch 23/64 loss: 0.3229314684867859
Batch 24/64 loss: 0.319677472114563
Batch 25/64 loss: 0.31754934787750244
Batch 26/64 loss: 0.3195372223854065
Batch 27/64 loss: 0.32193636894226074
Batch 28/64 loss: 0.3273887634277344
Batch 29/64 loss: 0.31797975301742554
Batch 30/64 loss: 0.31337761878967285
Batch 31/64 loss: 0.3189542293548584
Batch 32/64 loss: 0.3187037706375122
Batch 33/64 loss: 0.320487380027771
Batch 34/64 loss: 0.3223564028739929
Batch 35/64 loss: 0.32610398530960083
Batch 36/64 loss: 0.32311296463012695
Batch 37/64 loss: 0.3150310516357422
Batch 38/64 loss: 0.31514912843704224
Batch 39/64 loss: 0.31253498792648315
Batch 40/64 loss: 0.31999289989471436
Batch 41/64 loss: 0.3177559971809387
Batch 42/64 loss: 0.31054675579071045
Batch 43/64 loss: 0.3238067626953125
Batch 44/64 loss: 0.31407153606414795
Batch 45/64 loss: 0.3189983367919922
Batch 46/64 loss: 0.3130660057067871
Batch 47/64 loss: 0.32451462745666504
Batch 48/64 loss: 0.3075523376464844
Batch 49/64 loss: 0.3192155361175537
Batch 50/64 loss: 0.31520628929138184
Batch 51/64 loss: 0.3118598461151123
Batch 52/64 loss: 0.3267101049423218
Batch 53/64 loss: 0.31490278244018555
Batch 54/64 loss: 0.3130617141723633
Batch 55/64 loss: 0.31699466705322266
Batch 56/64 loss: 0.32278215885162354
Batch 57/64 loss: 0.3200339674949646
Batch 58/64 loss: 0.3236809968948364
Batch 59/64 loss: 0.3153883218765259
Batch 60/64 loss: 0.32420164346694946
Batch 61/64 loss: 0.3162968158721924
Batch 62/64 loss: 0.31615501642227173
Batch 63/64 loss: 0.32297325134277344
Batch 64/64 loss: 0.31806421279907227
Epoch 243  Train loss: 0.31811744185055  Val loss: 0.33380047070611385
Epoch 244
-------------------------------
Batch 1/64 loss: 0.3188512325286865
Batch 2/64 loss: 0.32380813360214233
Batch 3/64 loss: 0.3137345314025879
Batch 4/64 loss: 0.32605111598968506
Batch 5/64 loss: 0.3184239864349365
Batch 6/64 loss: 0.31201350688934326
Batch 7/64 loss: 0.31627118587493896
Batch 8/64 loss: 0.3202834725379944
Batch 9/64 loss: 0.3157048225402832
Batch 10/64 loss: 0.31378769874572754
Batch 11/64 loss: 0.3158574104309082
Batch 12/64 loss: 0.31763046979904175
Batch 13/64 loss: 0.3113285303115845
Batch 14/64 loss: 0.32151031494140625
Batch 15/64 loss: 0.3150262236595154
Batch 16/64 loss: 0.3167303204536438
Batch 17/64 loss: 0.312369704246521
Batch 18/64 loss: 0.31564682722091675
Batch 19/64 loss: 0.3125307559967041
Batch 20/64 loss: 0.32432448863983154
Batch 21/64 loss: 0.32437366247177124
Batch 22/64 loss: 0.3206515312194824
Batch 23/64 loss: 0.320526123046875
Batch 24/64 loss: 0.32460933923721313
Batch 25/64 loss: 0.3114032745361328
Batch 26/64 loss: 0.3177871108055115
Batch 27/64 loss: 0.32306551933288574
Batch 28/64 loss: 0.31645631790161133
Batch 29/64 loss: 0.3125934600830078
Batch 30/64 loss: 0.32090139389038086
Batch 31/64 loss: 0.32077276706695557
Batch 32/64 loss: 0.31087827682495117
Batch 33/64 loss: 0.31904804706573486
Batch 34/64 loss: 0.3278310298919678
Batch 35/64 loss: 0.312555730342865
Batch 36/64 loss: 0.32274919748306274
Batch 37/64 loss: 0.31956684589385986
Batch 38/64 loss: 0.3075799345970154
Batch 39/64 loss: 0.3206021189689636
Batch 40/64 loss: 0.3163725733757019
Batch 41/64 loss: 0.31163740158081055
Batch 42/64 loss: 0.32230931520462036
Batch 43/64 loss: 0.311900794506073
Batch 44/64 loss: 0.31401944160461426
Batch 45/64 loss: 0.32235610485076904
Batch 46/64 loss: 0.31424015760421753
Batch 47/64 loss: 0.31301379203796387
Batch 48/64 loss: 0.321540892124176
Batch 49/64 loss: 0.3158780336380005
Batch 50/64 loss: 0.3264758586883545
Batch 51/64 loss: 0.3146873712539673
Batch 52/64 loss: 0.3181889057159424
Batch 53/64 loss: 0.31211376190185547
Batch 54/64 loss: 0.3230167627334595
Batch 55/64 loss: 0.31428098678588867
Batch 56/64 loss: 0.31720757484436035
Batch 57/64 loss: 0.3104114532470703
Batch 58/64 loss: 0.3232882022857666
Batch 59/64 loss: 0.3231923580169678
Batch 60/64 loss: 0.31034255027770996
Batch 61/64 loss: 0.32141411304473877
Batch 62/64 loss: 0.3179647922515869
Batch 63/64 loss: 0.32327038049697876
Batch 64/64 loss: 0.31682825088500977
Epoch 244  Train loss: 0.31768754790810977  Val loss: 0.33440029539193483
Epoch 245
-------------------------------
Batch 1/64 loss: 0.3120919466018677
Batch 2/64 loss: 0.31706613302230835
Batch 3/64 loss: 0.32345420122146606
Batch 4/64 loss: 0.3145095109939575
Batch 5/64 loss: 0.30784690380096436
Batch 6/64 loss: 0.3183477520942688
Batch 7/64 loss: 0.3215230703353882
Batch 8/64 loss: 0.3158912658691406
Batch 9/64 loss: 0.31123363971710205
Batch 10/64 loss: 0.31477296352386475
Batch 11/64 loss: 0.317613422870636
Batch 12/64 loss: 0.3106788396835327
Batch 13/64 loss: 0.3247906565666199
Batch 14/64 loss: 0.3233680725097656
Batch 15/64 loss: 0.32025521993637085
Batch 16/64 loss: 0.3146413564682007
Batch 17/64 loss: 0.3248019218444824
Batch 18/64 loss: 0.3216431140899658
Batch 19/64 loss: 0.3182221055030823
Batch 20/64 loss: 0.32167214155197144
Batch 21/64 loss: 0.32113713026046753
Batch 22/64 loss: 0.31353330612182617
Batch 23/64 loss: 0.3154658079147339
Batch 24/64 loss: 0.31416231393814087
Batch 25/64 loss: 0.3218584656715393
Batch 26/64 loss: 0.3137897253036499
Batch 27/64 loss: 0.32232314348220825
Batch 28/64 loss: 0.3190995454788208
Batch 29/64 loss: 0.3223145008087158
Batch 30/64 loss: 0.31820952892303467
Batch 31/64 loss: 0.3111231327056885
Batch 32/64 loss: 0.3243793845176697
Batch 33/64 loss: 0.31933557987213135
Batch 34/64 loss: 0.3248113989830017
Batch 35/64 loss: 0.3146655559539795
Batch 36/64 loss: 0.31310534477233887
Batch 37/64 loss: 0.3170772194862366
Batch 38/64 loss: 0.3237760663032532
Batch 39/64 loss: 0.3213787078857422
Batch 40/64 loss: 0.3171713948249817
Batch 41/64 loss: 0.31578242778778076
Batch 42/64 loss: 0.3088623285293579
Batch 43/64 loss: 0.32399582862854004
Batch 44/64 loss: 0.3146069645881653
Batch 45/64 loss: 0.32579612731933594
Batch 46/64 loss: 0.31705737113952637
Batch 47/64 loss: 0.3138715624809265
Batch 48/64 loss: 0.3069157600402832
Batch 49/64 loss: 0.31717634201049805
Batch 50/64 loss: 0.3167942762374878
Batch 51/64 loss: 0.3233088254928589
Batch 52/64 loss: 0.31456542015075684
Batch 53/64 loss: 0.3170168399810791
Batch 54/64 loss: 0.31578391790390015
Batch 55/64 loss: 0.3202935457229614
Batch 56/64 loss: 0.31070905923843384
Batch 57/64 loss: 0.3172728419303894
Batch 58/64 loss: 0.31793510913848877
Batch 59/64 loss: 0.32528984546661377
Batch 60/64 loss: 0.3209691047668457
Batch 61/64 loss: 0.32279157638549805
Batch 62/64 loss: 0.31583112478256226
Batch 63/64 loss: 0.32231199741363525
Batch 64/64 loss: 0.3117856979370117
Epoch 245  Train loss: 0.3178340229333616  Val loss: 0.33449422637211906
Epoch 246
-------------------------------
Batch 1/64 loss: 0.3229213356971741
Batch 2/64 loss: 0.3233855962753296
Batch 3/64 loss: 0.3160111904144287
Batch 4/64 loss: 0.32234692573547363
Batch 5/64 loss: 0.3188648819923401
Batch 6/64 loss: 0.31827831268310547
Batch 7/64 loss: 0.31485122442245483
Batch 8/64 loss: 0.3166440725326538
Batch 9/64 loss: 0.315576434135437
Batch 10/64 loss: 0.31258583068847656
Batch 11/64 loss: 0.31952476501464844
Batch 12/64 loss: 0.31033098697662354
Batch 13/64 loss: 0.3157881498336792
Batch 14/64 loss: 0.3167329430580139
Batch 15/64 loss: 0.3208022117614746
Batch 16/64 loss: 0.3171025514602661
Batch 17/64 loss: 0.3181356191635132
Batch 18/64 loss: 0.31880247592926025
Batch 19/64 loss: 0.31209373474121094
Batch 20/64 loss: 0.31614720821380615
Batch 21/64 loss: 0.31741154193878174
Batch 22/64 loss: 0.3136143684387207
Batch 23/64 loss: 0.31865692138671875
Batch 24/64 loss: 0.3185776472091675
Batch 25/64 loss: 0.3201639652252197
Batch 26/64 loss: 0.31718188524246216
Batch 27/64 loss: 0.3179337978363037
Batch 28/64 loss: 0.3121286630630493
Batch 29/64 loss: 0.3162902593612671
Batch 30/64 loss: 0.31607532501220703
Batch 31/64 loss: 0.3212929964065552
Batch 32/64 loss: 0.31554168462753296
Batch 33/64 loss: 0.3225974440574646
Batch 34/64 loss: 0.3172847628593445
Batch 35/64 loss: 0.3128829002380371
Batch 36/64 loss: 0.3172141909599304
Batch 37/64 loss: 0.31565070152282715
Batch 38/64 loss: 0.3108788728713989
Batch 39/64 loss: 0.31667351722717285
Batch 40/64 loss: 0.31787973642349243
Batch 41/64 loss: 0.3133317232131958
Batch 42/64 loss: 0.31462520360946655
Batch 43/64 loss: 0.3120170831680298
Batch 44/64 loss: 0.32495564222335815
Batch 45/64 loss: 0.31870007514953613
Batch 46/64 loss: 0.3261392116546631
Batch 47/64 loss: 0.3162882328033447
Batch 48/64 loss: 0.31643152236938477
Batch 49/64 loss: 0.3179742097854614
Batch 50/64 loss: 0.32040953636169434
Batch 51/64 loss: 0.3147313594818115
Batch 52/64 loss: 0.31705933809280396
Batch 53/64 loss: 0.31860488653182983
Batch 54/64 loss: 0.3163396716117859
Batch 55/64 loss: 0.319061279296875
Batch 56/64 loss: 0.3205289840698242
Batch 57/64 loss: 0.3265339732170105
Batch 58/64 loss: 0.3251664638519287
Batch 59/64 loss: 0.3185614347457886
Batch 60/64 loss: 0.3213282823562622
Batch 61/64 loss: 0.314136266708374
Batch 62/64 loss: 0.3187570571899414
Batch 63/64 loss: 0.3154309391975403
Batch 64/64 loss: 0.3215709328651428
Epoch 246  Train loss: 0.3176650699447183  Val loss: 0.33321894464623886
Epoch 247
-------------------------------
Batch 1/64 loss: 0.3156179189682007
Batch 2/64 loss: 0.3171408772468567
Batch 3/64 loss: 0.3120619058609009
Batch 4/64 loss: 0.31785523891448975
Batch 5/64 loss: 0.3138430118560791
Batch 6/64 loss: 0.31452375650405884
Batch 7/64 loss: 0.3254086375236511
Batch 8/64 loss: 0.32175397872924805
Batch 9/64 loss: 0.31833380460739136
Batch 10/64 loss: 0.3183184266090393
Batch 11/64 loss: 0.32465624809265137
Batch 12/64 loss: 0.31507790088653564
Batch 13/64 loss: 0.31588274240493774
Batch 14/64 loss: 0.3121696710586548
Batch 15/64 loss: 0.31460630893707275
Batch 16/64 loss: 0.3180887699127197
Batch 17/64 loss: 0.313409686088562
Batch 18/64 loss: 0.3215342164039612
Batch 19/64 loss: 0.308845579624176
Batch 20/64 loss: 0.3195319175720215
Batch 21/64 loss: 0.31086188554763794
Batch 22/64 loss: 0.3158724904060364
Batch 23/64 loss: 0.30882638692855835
Batch 24/64 loss: 0.31464362144470215
Batch 25/64 loss: 0.3133590817451477
Batch 26/64 loss: 0.3159133195877075
Batch 27/64 loss: 0.3197785019874573
Batch 28/64 loss: 0.30758100748062134
Batch 29/64 loss: 0.3128244876861572
Batch 30/64 loss: 0.3115159273147583
Batch 31/64 loss: 0.3226754069328308
Batch 32/64 loss: 0.3085351586341858
Batch 33/64 loss: 0.3150175213813782
Batch 34/64 loss: 0.3173357844352722
Batch 35/64 loss: 0.31815600395202637
Batch 36/64 loss: 0.32579922676086426
Batch 37/64 loss: 0.31890082359313965
Batch 38/64 loss: 0.3189206123352051
Batch 39/64 loss: 0.32249653339385986
Batch 40/64 loss: 0.313329815864563
Batch 41/64 loss: 0.31586402654647827
Batch 42/64 loss: 0.31507277488708496
Batch 43/64 loss: 0.3130911588668823
Batch 44/64 loss: 0.3192692995071411
Batch 45/64 loss: 0.31930291652679443
Batch 46/64 loss: 0.3152807950973511
Batch 47/64 loss: 0.3127744197845459
Batch 48/64 loss: 0.31848227977752686
Batch 49/64 loss: 0.3113868236541748
Batch 50/64 loss: 0.3211292028427124
Batch 51/64 loss: 0.3148658871650696
Batch 52/64 loss: 0.3213918209075928
Batch 53/64 loss: 0.31895720958709717
Batch 54/64 loss: 0.3135216236114502
Batch 55/64 loss: 0.3254927396774292
Batch 56/64 loss: 0.319158673286438
Batch 57/64 loss: 0.32785511016845703
Batch 58/64 loss: 0.32208549976348877
Batch 59/64 loss: 0.31709587574005127
Batch 60/64 loss: 0.31578528881073
Batch 61/64 loss: 0.3149949312210083
Batch 62/64 loss: 0.3234901428222656
Batch 63/64 loss: 0.31775784492492676
Batch 64/64 loss: 0.32371318340301514
Epoch 247  Train loss: 0.31698659494811415  Val loss: 0.3332762281919263
Epoch 248
-------------------------------
Batch 1/64 loss: 0.32591861486434937
Batch 2/64 loss: 0.31955593824386597
Batch 3/64 loss: 0.3201819658279419
Batch 4/64 loss: 0.3098641633987427
Batch 5/64 loss: 0.3199452757835388
Batch 6/64 loss: 0.3215687870979309
Batch 7/64 loss: 0.3114498257637024
Batch 8/64 loss: 0.3187915086746216
Batch 9/64 loss: 0.3159627318382263
Batch 10/64 loss: 0.32565784454345703
Batch 11/64 loss: 0.3199288845062256
Batch 12/64 loss: 0.3171485662460327
Batch 13/64 loss: 0.31527912616729736
Batch 14/64 loss: 0.3242543339729309
Batch 15/64 loss: 0.3142576217651367
Batch 16/64 loss: 0.32192957401275635
Batch 17/64 loss: 0.31763511896133423
Batch 18/64 loss: 0.3259885311126709
Batch 19/64 loss: 0.3157004714012146
Batch 20/64 loss: 0.3152464032173157
Batch 21/64 loss: 0.3161197304725647
Batch 22/64 loss: 0.32869577407836914
Batch 23/64 loss: 0.3178867697715759
Batch 24/64 loss: 0.3120969533920288
Batch 25/64 loss: 0.31636351346969604
Batch 26/64 loss: 0.320220947265625
Batch 27/64 loss: 0.3156789541244507
Batch 28/64 loss: 0.3183422088623047
Batch 29/64 loss: 0.3133432865142822
Batch 30/64 loss: 0.31952446699142456
Batch 31/64 loss: 0.312180757522583
Batch 32/64 loss: 0.31610554456710815
Batch 33/64 loss: 0.31537461280822754
Batch 34/64 loss: 0.31936657428741455
Batch 35/64 loss: 0.3165472745895386
Batch 36/64 loss: 0.3214251399040222
Batch 37/64 loss: 0.3123021721839905
Batch 38/64 loss: 0.32021355628967285
Batch 39/64 loss: 0.31176120042800903
Batch 40/64 loss: 0.3245890140533447
Batch 41/64 loss: 0.32046443223953247
Batch 42/64 loss: 0.3134610056877136
Batch 43/64 loss: 0.31620097160339355
Batch 44/64 loss: 0.31513726711273193
Batch 45/64 loss: 0.320529580116272
Batch 46/64 loss: 0.317630410194397
Batch 47/64 loss: 0.3220621347427368
Batch 48/64 loss: 0.31109893321990967
Batch 49/64 loss: 0.3161112070083618
Batch 50/64 loss: 0.3108232617378235
Batch 51/64 loss: 0.3112525939941406
Batch 52/64 loss: 0.31282567977905273
Batch 53/64 loss: 0.31965208053588867
Batch 54/64 loss: 0.3132760524749756
Batch 55/64 loss: 0.31316566467285156
Batch 56/64 loss: 0.32413285970687866
Batch 57/64 loss: 0.315682053565979
Batch 58/64 loss: 0.30706000328063965
Batch 59/64 loss: 0.31915414333343506
Batch 60/64 loss: 0.3195909261703491
Batch 61/64 loss: 0.3135824203491211
Batch 62/64 loss: 0.3135984539985657
Batch 63/64 loss: 0.31414496898651123
Batch 64/64 loss: 0.3117852807044983
Epoch 248  Train loss: 0.31715889888651233  Val loss: 0.3335086144122881
Epoch 249
-------------------------------
Batch 1/64 loss: 0.31141531467437744
Batch 2/64 loss: 0.3125491142272949
Batch 3/64 loss: 0.31604844331741333
Batch 4/64 loss: 0.31662482023239136
Batch 5/64 loss: 0.3161982297897339
Batch 6/64 loss: 0.3218204379081726
Batch 7/64 loss: 0.3176828622817993
Batch 8/64 loss: 0.3148331642150879
Batch 9/64 loss: 0.31103408336639404
Batch 10/64 loss: 0.3205614686012268
Batch 11/64 loss: 0.3199878931045532
Batch 12/64 loss: 0.32106101512908936
Batch 13/64 loss: 0.3141184449195862
Batch 14/64 loss: 0.31726908683776855
Batch 15/64 loss: 0.3191046714782715
Batch 16/64 loss: 0.31543731689453125
Batch 17/64 loss: 0.32018226385116577
Batch 18/64 loss: 0.31551074981689453
Batch 19/64 loss: 0.316317617893219
Batch 20/64 loss: 0.310535728931427
Batch 21/64 loss: 0.3175615072250366
Batch 22/64 loss: 0.3152503967285156
Batch 23/64 loss: 0.3171548843383789
Batch 24/64 loss: 0.3151904344558716
Batch 25/64 loss: 0.3181498050689697
Batch 26/64 loss: 0.3139089345932007
Batch 27/64 loss: 0.31070148944854736
Batch 28/64 loss: 0.31509602069854736
Batch 29/64 loss: 0.3183668851852417
Batch 30/64 loss: 0.3108707666397095
Batch 31/64 loss: 0.31968092918395996
Batch 32/64 loss: 0.31461966037750244
Batch 33/64 loss: 0.32399439811706543
Batch 34/64 loss: 0.3083897829055786
Batch 35/64 loss: 0.3231804370880127
Batch 36/64 loss: 0.3245420455932617
Batch 37/64 loss: 0.3187352418899536
Batch 38/64 loss: 0.3244803547859192
Batch 39/64 loss: 0.31468284130096436
Batch 40/64 loss: 0.3243427872657776
Batch 41/64 loss: 0.3138008117675781
Batch 42/64 loss: 0.3143899440765381
Batch 43/64 loss: 0.31886887550354004
Batch 44/64 loss: 0.3237922787666321
Batch 45/64 loss: 0.3276306986808777
Batch 46/64 loss: 0.32011687755584717
Batch 47/64 loss: 0.3198985457420349
Batch 48/64 loss: 0.31419533491134644
Batch 49/64 loss: 0.3045455813407898
Batch 50/64 loss: 0.31155943870544434
Batch 51/64 loss: 0.3193070888519287
Batch 52/64 loss: 0.3189668655395508
Batch 53/64 loss: 0.31921088695526123
Batch 54/64 loss: 0.32314836978912354
Batch 55/64 loss: 0.3127617835998535
Batch 56/64 loss: 0.32114851474761963
Batch 57/64 loss: 0.3190307021141052
Batch 58/64 loss: 0.3211243748664856
Batch 59/64 loss: 0.32342100143432617
Batch 60/64 loss: 0.3138886094093323
Batch 61/64 loss: 0.3132440447807312
Batch 62/64 loss: 0.3146113157272339
Batch 63/64 loss: 0.32168543338775635
Batch 64/64 loss: 0.3166623115539551
Epoch 249  Train loss: 0.31725547360438927  Val loss: 0.3323535095785082
Saving best model, epoch: 249
Epoch 250
-------------------------------
Batch 1/64 loss: 0.32007086277008057
Batch 2/64 loss: 0.320573091506958
Batch 3/64 loss: 0.3158213496208191
Batch 4/64 loss: 0.3170967698097229
Batch 5/64 loss: 0.3270251154899597
Batch 6/64 loss: 0.31397855281829834
Batch 7/64 loss: 0.31976401805877686
Batch 8/64 loss: 0.3207731246948242
Batch 9/64 loss: 0.30669963359832764
Batch 10/64 loss: 0.310535192489624
Batch 11/64 loss: 0.3127707242965698
Batch 12/64 loss: 0.31717801094055176
Batch 13/64 loss: 0.31076371669769287
Batch 14/64 loss: 0.32372212409973145
Batch 15/64 loss: 0.3129335641860962
Batch 16/64 loss: 0.3236185908317566
Batch 17/64 loss: 0.3144216537475586
Batch 18/64 loss: 0.3226771354675293
Batch 19/64 loss: 0.31865453720092773
Batch 20/64 loss: 0.31797969341278076
Batch 21/64 loss: 0.31554651260375977
Batch 22/64 loss: 0.3183578848838806
Batch 23/64 loss: 0.3181399703025818
Batch 24/64 loss: 0.32119739055633545
Batch 25/64 loss: 0.3160790205001831
Batch 26/64 loss: 0.3181688189506531
Batch 27/64 loss: 0.3234386444091797
Batch 28/64 loss: 0.3211812376976013
Batch 29/64 loss: 0.31705552339553833
Batch 30/64 loss: 0.3186798691749573
Batch 31/64 loss: 0.3218942880630493
Batch 32/64 loss: 0.3146005868911743
Batch 33/64 loss: 0.3112836480140686
Batch 34/64 loss: 0.3200436234474182
Batch 35/64 loss: 0.32177239656448364
Batch 36/64 loss: 0.3226057291030884
Batch 37/64 loss: 0.3046238422393799
Batch 38/64 loss: 0.32115745544433594
Batch 39/64 loss: 0.3159223794937134
Batch 40/64 loss: 0.3085904121398926
Batch 41/64 loss: 0.3190496563911438
Batch 42/64 loss: 0.3130819797515869
Batch 43/64 loss: 0.3144296407699585
Batch 44/64 loss: 0.3175468444824219
Batch 45/64 loss: 0.3150559663772583
Batch 46/64 loss: 0.32303452491760254
Batch 47/64 loss: 0.31798291206359863
Batch 48/64 loss: 0.3141998052597046
Batch 49/64 loss: 0.32013535499572754
Batch 50/64 loss: 0.3153214454650879
Batch 51/64 loss: 0.31674885749816895
Batch 52/64 loss: 0.32486534118652344
Batch 53/64 loss: 0.3137317895889282
Batch 54/64 loss: 0.32147449254989624
Batch 55/64 loss: 0.31016039848327637
Batch 56/64 loss: 0.3235021233558655
Batch 57/64 loss: 0.3082953691482544
Batch 58/64 loss: 0.3110804557800293
Batch 59/64 loss: 0.31659799814224243
Batch 60/64 loss: 0.31430453062057495
Batch 61/64 loss: 0.31542694568634033
Batch 62/64 loss: 0.3093646764755249
Batch 63/64 loss: 0.32167375087738037
Batch 64/64 loss: 0.31237542629241943
Epoch 250  Train loss: 0.31699989216000424  Val loss: 0.3334176777974027
Epoch 251
-------------------------------
Batch 1/64 loss: 0.3143153190612793
Batch 2/64 loss: 0.31415730714797974
Batch 3/64 loss: 0.3190905451774597
Batch 4/64 loss: 0.3161572813987732
Batch 5/64 loss: 0.3187989592552185
Batch 6/64 loss: 0.3127979040145874
Batch 7/64 loss: 0.3112257719039917
Batch 8/64 loss: 0.31308841705322266
Batch 9/64 loss: 0.31943702697753906
Batch 10/64 loss: 0.3169345259666443
Batch 11/64 loss: 0.31387239694595337
Batch 12/64 loss: 0.3145752549171448
Batch 13/64 loss: 0.3158392906188965
Batch 14/64 loss: 0.31139683723449707
Batch 15/64 loss: 0.3132280707359314
Batch 16/64 loss: 0.31295472383499146
Batch 17/64 loss: 0.3105647563934326
Batch 18/64 loss: 0.3104962110519409
Batch 19/64 loss: 0.32144975662231445
Batch 20/64 loss: 0.315682053565979
Batch 21/64 loss: 0.31615614891052246
Batch 22/64 loss: 0.3170022964477539
Batch 23/64 loss: 0.32120800018310547
Batch 24/64 loss: 0.31494784355163574
Batch 25/64 loss: 0.3131793141365051
Batch 26/64 loss: 0.313187837600708
Batch 27/64 loss: 0.32164305448532104
Batch 28/64 loss: 0.3091164231300354
Batch 29/64 loss: 0.3173367977142334
Batch 30/64 loss: 0.32176876068115234
Batch 31/64 loss: 0.3089362382888794
Batch 32/64 loss: 0.3226020932197571
Batch 33/64 loss: 0.3147941827774048
Batch 34/64 loss: 0.31826889514923096
Batch 35/64 loss: 0.3151705861091614
Batch 36/64 loss: 0.3245251178741455
Batch 37/64 loss: 0.31392407417297363
Batch 38/64 loss: 0.31938278675079346
Batch 39/64 loss: 0.32641804218292236
Batch 40/64 loss: 0.3216671943664551
Batch 41/64 loss: 0.3195810317993164
Batch 42/64 loss: 0.3231719732284546
Batch 43/64 loss: 0.3092947006225586
Batch 44/64 loss: 0.3129255771636963
Batch 45/64 loss: 0.31762272119522095
Batch 46/64 loss: 0.32067549228668213
Batch 47/64 loss: 0.3089742660522461
Batch 48/64 loss: 0.3186829090118408
Batch 49/64 loss: 0.31441110372543335
Batch 50/64 loss: 0.31792324781417847
Batch 51/64 loss: 0.31071364879608154
Batch 52/64 loss: 0.31748849153518677
Batch 53/64 loss: 0.3148484230041504
Batch 54/64 loss: 0.31427139043807983
Batch 55/64 loss: 0.31577444076538086
Batch 56/64 loss: 0.32340019941329956
Batch 57/64 loss: 0.31700026988983154
Batch 58/64 loss: 0.31513577699661255
Batch 59/64 loss: 0.32716596126556396
Batch 60/64 loss: 0.31179970502853394
Batch 61/64 loss: 0.31508129835128784
Batch 62/64 loss: 0.31529831886291504
Batch 63/64 loss: 0.321256160736084
Batch 64/64 loss: 0.3118439316749573
Epoch 251  Train loss: 0.31629299065646005  Val loss: 0.33231443740248273
Saving best model, epoch: 251
Epoch 252
-------------------------------
Batch 1/64 loss: 0.3133086562156677
Batch 2/64 loss: 0.3074190020561218
Batch 3/64 loss: 0.3138055205345154
Batch 4/64 loss: 0.313706636428833
Batch 5/64 loss: 0.322030246257782
Batch 6/64 loss: 0.3165735602378845
Batch 7/64 loss: 0.31766223907470703
Batch 8/64 loss: 0.31305426359176636
Batch 9/64 loss: 0.31887930631637573
Batch 10/64 loss: 0.3041306734085083
Batch 11/64 loss: 0.3271900415420532
Batch 12/64 loss: 0.3174472451210022
Batch 13/64 loss: 0.3119314908981323
Batch 14/64 loss: 0.3073521852493286
Batch 15/64 loss: 0.31511861085891724
Batch 16/64 loss: 0.313520610332489
Batch 17/64 loss: 0.31691426038742065
Batch 18/64 loss: 0.3153391480445862
Batch 19/64 loss: 0.3268701434135437
Batch 20/64 loss: 0.3177254796028137
Batch 21/64 loss: 0.31947576999664307
Batch 22/64 loss: 0.30978190898895264
Batch 23/64 loss: 0.31636345386505127
Batch 24/64 loss: 0.31704723834991455
Batch 25/64 loss: 0.30877625942230225
Batch 26/64 loss: 0.317590594291687
Batch 27/64 loss: 0.31697940826416016
Batch 28/64 loss: 0.31483423709869385
Batch 29/64 loss: 0.30910128355026245
Batch 30/64 loss: 0.3217894434928894
Batch 31/64 loss: 0.3183172941207886
Batch 32/64 loss: 0.32596540451049805
Batch 33/64 loss: 0.31159329414367676
Batch 34/64 loss: 0.3174349069595337
Batch 35/64 loss: 0.31606173515319824
Batch 36/64 loss: 0.3099728226661682
Batch 37/64 loss: 0.3121691942214966
Batch 38/64 loss: 0.31429821252822876
Batch 39/64 loss: 0.3179752826690674
Batch 40/64 loss: 0.31911277770996094
Batch 41/64 loss: 0.3113934397697449
Batch 42/64 loss: 0.3180582523345947
Batch 43/64 loss: 0.32727205753326416
Batch 44/64 loss: 0.31523364782333374
Batch 45/64 loss: 0.3170132637023926
Batch 46/64 loss: 0.3238379955291748
Batch 47/64 loss: 0.3152400255203247
Batch 48/64 loss: 0.3171241283416748
Batch 49/64 loss: 0.3211720585823059
Batch 50/64 loss: 0.31098711490631104
Batch 51/64 loss: 0.3128662109375
Batch 52/64 loss: 0.3150833249092102
Batch 53/64 loss: 0.31282925605773926
Batch 54/64 loss: 0.3156071901321411
Batch 55/64 loss: 0.32824742794036865
Batch 56/64 loss: 0.3230854272842407
Batch 57/64 loss: 0.31819117069244385
Batch 58/64 loss: 0.32320475578308105
Batch 59/64 loss: 0.3150593638420105
Batch 60/64 loss: 0.31442296504974365
Batch 61/64 loss: 0.31917625665664673
Batch 62/64 loss: 0.3182467222213745
Batch 63/64 loss: 0.31837499141693115
Batch 64/64 loss: 0.31979501247406006
Epoch 252  Train loss: 0.31648930428074856  Val loss: 0.33302854897640005
Epoch 253
-------------------------------
Batch 1/64 loss: 0.309934139251709
Batch 2/64 loss: 0.31488364934921265
Batch 3/64 loss: 0.31785720586776733
Batch 4/64 loss: 0.31367677450180054
Batch 5/64 loss: 0.3093721866607666
Batch 6/64 loss: 0.310715913772583
Batch 7/64 loss: 0.32518041133880615
Batch 8/64 loss: 0.3101283311843872
Batch 9/64 loss: 0.31760895252227783
Batch 10/64 loss: 0.3260538578033447
Batch 11/64 loss: 0.31111276149749756
Batch 12/64 loss: 0.30974388122558594
Batch 13/64 loss: 0.3122282028198242
Batch 14/64 loss: 0.318331241607666
Batch 15/64 loss: 0.31787580251693726
Batch 16/64 loss: 0.3199116587638855
Batch 17/64 loss: 0.31423133611679077
Batch 18/64 loss: 0.3179631233215332
Batch 19/64 loss: 0.3158397078514099
Batch 20/64 loss: 0.31454527378082275
Batch 21/64 loss: 0.31515049934387207
Batch 22/64 loss: 0.31442856788635254
Batch 23/64 loss: 0.3171350359916687
Batch 24/64 loss: 0.31668925285339355
Batch 25/64 loss: 0.3192315101623535
Batch 26/64 loss: 0.3098820447921753
Batch 27/64 loss: 0.31440824270248413
Batch 28/64 loss: 0.31136655807495117
Batch 29/64 loss: 0.3202962279319763
Batch 30/64 loss: 0.3204840421676636
Batch 31/64 loss: 0.31779706478118896
Batch 32/64 loss: 0.3116191625595093
Batch 33/64 loss: 0.311076283454895
Batch 34/64 loss: 0.3193584680557251
Batch 35/64 loss: 0.3156905174255371
Batch 36/64 loss: 0.32136744260787964
Batch 37/64 loss: 0.31022965908050537
Batch 38/64 loss: 0.3134756088256836
Batch 39/64 loss: 0.32637274265289307
Batch 40/64 loss: 0.3160277009010315
Batch 41/64 loss: 0.31427597999572754
Batch 42/64 loss: 0.30617988109588623
Batch 43/64 loss: 0.32395923137664795
Batch 44/64 loss: 0.31124842166900635
Batch 45/64 loss: 0.32154589891433716
Batch 46/64 loss: 0.3177395462989807
Batch 47/64 loss: 0.3240314722061157
Batch 48/64 loss: 0.3205617070198059
Batch 49/64 loss: 0.31178075075149536
Batch 50/64 loss: 0.3163522481918335
Batch 51/64 loss: 0.31731951236724854
Batch 52/64 loss: 0.3163633346557617
Batch 53/64 loss: 0.30738556385040283
Batch 54/64 loss: 0.3112431764602661
Batch 55/64 loss: 0.3166695237159729
Batch 56/64 loss: 0.30901384353637695
Batch 57/64 loss: 0.31974196434020996
Batch 58/64 loss: 0.31966423988342285
Batch 59/64 loss: 0.3142218589782715
Batch 60/64 loss: 0.3168873190879822
Batch 61/64 loss: 0.3157324194908142
Batch 62/64 loss: 0.31900322437286377
Batch 63/64 loss: 0.31531912088394165
Batch 64/64 loss: 0.3123832941055298
Epoch 253  Train loss: 0.31576170594084496  Val loss: 0.3327647513130686
Epoch 254
-------------------------------
Batch 1/64 loss: 0.3172430992126465
Batch 2/64 loss: 0.3160429000854492
Batch 3/64 loss: 0.3129737377166748
Batch 4/64 loss: 0.31563299894332886
Batch 5/64 loss: 0.3100324273109436
Batch 6/64 loss: 0.3113113045692444
Batch 7/64 loss: 0.3164399266242981
Batch 8/64 loss: 0.3154566287994385
Batch 9/64 loss: 0.3170435428619385
Batch 10/64 loss: 0.31303268671035767
Batch 11/64 loss: 0.3100318908691406
Batch 12/64 loss: 0.30908751487731934
Batch 13/64 loss: 0.3190452456474304
Batch 14/64 loss: 0.32451844215393066
Batch 15/64 loss: 0.3093740940093994
Batch 16/64 loss: 0.3243134021759033
Batch 17/64 loss: 0.3103916645050049
Batch 18/64 loss: 0.32086122035980225
Batch 19/64 loss: 0.31905311346054077
Batch 20/64 loss: 0.31460148096084595
Batch 21/64 loss: 0.3138672113418579
Batch 22/64 loss: 0.32012927532196045
Batch 23/64 loss: 0.3173608183860779
Batch 24/64 loss: 0.31469327211380005
Batch 25/64 loss: 0.3135164976119995
Batch 26/64 loss: 0.3207777738571167
Batch 27/64 loss: 0.312782883644104
Batch 28/64 loss: 0.3213918209075928
Batch 29/64 loss: 0.3202037215232849
Batch 30/64 loss: 0.3103785514831543
Batch 31/64 loss: 0.31955277919769287
Batch 32/64 loss: 0.31041109561920166
Batch 33/64 loss: 0.31443363428115845
Batch 34/64 loss: 0.32393813133239746
Batch 35/64 loss: 0.31641077995300293
Batch 36/64 loss: 0.3155885338783264
Batch 37/64 loss: 0.31539201736450195
Batch 38/64 loss: 0.3161783218383789
Batch 39/64 loss: 0.3236522078514099
Batch 40/64 loss: 0.31824755668640137
Batch 41/64 loss: 0.30963873863220215
Batch 42/64 loss: 0.3145027160644531
Batch 43/64 loss: 0.3180333375930786
Batch 44/64 loss: 0.3148866891860962
Batch 45/64 loss: 0.31590211391448975
Batch 46/64 loss: 0.31742316484451294
Batch 47/64 loss: 0.32498258352279663
Batch 48/64 loss: 0.3172616958618164
Batch 49/64 loss: 0.31275832653045654
Batch 50/64 loss: 0.3109736442565918
Batch 51/64 loss: 0.314902126789093
Batch 52/64 loss: 0.30843091011047363
Batch 53/64 loss: 0.31071531772613525
Batch 54/64 loss: 0.3200867176055908
Batch 55/64 loss: 0.31328272819519043
Batch 56/64 loss: 0.313018798828125
Batch 57/64 loss: 0.3161282539367676
Batch 58/64 loss: 0.32228755950927734
Batch 59/64 loss: 0.31532907485961914
Batch 60/64 loss: 0.3056047558784485
Batch 61/64 loss: 0.3098049759864807
Batch 62/64 loss: 0.3115047216415405
Batch 63/64 loss: 0.31323254108428955
Batch 64/64 loss: 0.31640613079071045
Epoch 254  Train loss: 0.31550416151682537  Val loss: 0.33205004533131915
Saving best model, epoch: 254
Epoch 255
-------------------------------
Batch 1/64 loss: 0.3107722997665405
Batch 2/64 loss: 0.322068452835083
Batch 3/64 loss: 0.31684643030166626
Batch 4/64 loss: 0.31028783321380615
Batch 5/64 loss: 0.31570208072662354
Batch 6/64 loss: 0.3201436996459961
Batch 7/64 loss: 0.317848265171051
Batch 8/64 loss: 0.3158561587333679
Batch 9/64 loss: 0.3131178617477417
Batch 10/64 loss: 0.3147296905517578
Batch 11/64 loss: 0.31070971488952637
Batch 12/64 loss: 0.30999481678009033
Batch 13/64 loss: 0.31480610370635986
Batch 14/64 loss: 0.30780553817749023
Batch 15/64 loss: 0.31004172563552856
Batch 16/64 loss: 0.320920467376709
Batch 17/64 loss: 0.31416547298431396
Batch 18/64 loss: 0.31665897369384766
Batch 19/64 loss: 0.309619665145874
Batch 20/64 loss: 0.31203150749206543
Batch 21/64 loss: 0.3076544404029846
Batch 22/64 loss: 0.31439805030822754
Batch 23/64 loss: 0.3163501024246216
Batch 24/64 loss: 0.31357449293136597
Batch 25/64 loss: 0.31993407011032104
Batch 26/64 loss: 0.31611233949661255
Batch 27/64 loss: 0.3191429376602173
Batch 28/64 loss: 0.3192313313484192
Batch 29/64 loss: 0.3111175298690796
Batch 30/64 loss: 0.311710000038147
Batch 31/64 loss: 0.31450843811035156
Batch 32/64 loss: 0.3163018226623535
Batch 33/64 loss: 0.31951427459716797
Batch 34/64 loss: 0.31854528188705444
Batch 35/64 loss: 0.31295275688171387
Batch 36/64 loss: 0.3122897744178772
Batch 37/64 loss: 0.3177516460418701
Batch 38/64 loss: 0.32097816467285156
Batch 39/64 loss: 0.303006649017334
Batch 40/64 loss: 0.3193020820617676
Batch 41/64 loss: 0.31349825859069824
Batch 42/64 loss: 0.30899518728256226
Batch 43/64 loss: 0.3150991201400757
Batch 44/64 loss: 0.3138595223426819
Batch 45/64 loss: 0.32020246982574463
Batch 46/64 loss: 0.30875498056411743
Batch 47/64 loss: 0.314034104347229
Batch 48/64 loss: 0.3081851005554199
Batch 49/64 loss: 0.31774216890335083
Batch 50/64 loss: 0.3136449456214905
Batch 51/64 loss: 0.32237112522125244
Batch 52/64 loss: 0.31334763765335083
Batch 53/64 loss: 0.31987547874450684
Batch 54/64 loss: 0.32180774211883545
Batch 55/64 loss: 0.3147531747817993
Batch 56/64 loss: 0.31444334983825684
Batch 57/64 loss: 0.3179209232330322
Batch 58/64 loss: 0.3124445676803589
Batch 59/64 loss: 0.3220329284667969
Batch 60/64 loss: 0.31176871061325073
Batch 61/64 loss: 0.31578755378723145
Batch 62/64 loss: 0.313116192817688
Batch 63/64 loss: 0.32342398166656494
Batch 64/64 loss: 0.3240218162536621
Epoch 255  Train loss: 0.31511574165493833  Val loss: 0.3324569074558638
Epoch 256
-------------------------------
Batch 1/64 loss: 0.31381744146347046
Batch 2/64 loss: 0.3079335689544678
Batch 3/64 loss: 0.3092222809791565
Batch 4/64 loss: 0.310994029045105
Batch 5/64 loss: 0.32025468349456787
Batch 6/64 loss: 0.3123067617416382
Batch 7/64 loss: 0.3159117102622986
Batch 8/64 loss: 0.30781418085098267
Batch 9/64 loss: 0.3190649151802063
Batch 10/64 loss: 0.3188472390174866
Batch 11/64 loss: 0.3114446997642517
Batch 12/64 loss: 0.3160873055458069
Batch 13/64 loss: 0.3147585391998291
Batch 14/64 loss: 0.3221123218536377
Batch 15/64 loss: 0.3143649101257324
Batch 16/64 loss: 0.31193095445632935
Batch 17/64 loss: 0.3179972171783447
Batch 18/64 loss: 0.31847959756851196
Batch 19/64 loss: 0.3211517333984375
Batch 20/64 loss: 0.3149353265762329
Batch 21/64 loss: 0.3101893663406372
Batch 22/64 loss: 0.32036763429641724
Batch 23/64 loss: 0.3216133117675781
Batch 24/64 loss: 0.30700135231018066
Batch 25/64 loss: 0.3119591474533081
Batch 26/64 loss: 0.31938886642456055
Batch 27/64 loss: 0.31575125455856323
Batch 28/64 loss: 0.3166881799697876
Batch 29/64 loss: 0.3144639730453491
Batch 30/64 loss: 0.31902384757995605
Batch 31/64 loss: 0.32188141345977783
Batch 32/64 loss: 0.3184250593185425
Batch 33/64 loss: 0.3117011785507202
Batch 34/64 loss: 0.3152740001678467
Batch 35/64 loss: 0.3110504150390625
Batch 36/64 loss: 0.31744760274887085
Batch 37/64 loss: 0.3130643367767334
Batch 38/64 loss: 0.32429516315460205
Batch 39/64 loss: 0.3129398822784424
Batch 40/64 loss: 0.32666921615600586
Batch 41/64 loss: 0.3133086562156677
Batch 42/64 loss: 0.30638962984085083
Batch 43/64 loss: 0.32063156366348267
Batch 44/64 loss: 0.3190012574195862
Batch 45/64 loss: 0.3146345019340515
Batch 46/64 loss: 0.3144751787185669
Batch 47/64 loss: 0.31199926137924194
Batch 48/64 loss: 0.32216572761535645
Batch 49/64 loss: 0.3156759738922119
Batch 50/64 loss: 0.3192124366760254
Batch 51/64 loss: 0.31687986850738525
Batch 52/64 loss: 0.3197975158691406
Batch 53/64 loss: 0.31483811140060425
Batch 54/64 loss: 0.32303738594055176
Batch 55/64 loss: 0.31602567434310913
Batch 56/64 loss: 0.3197810649871826
Batch 57/64 loss: 0.3159254789352417
Batch 58/64 loss: 0.31213927268981934
Batch 59/64 loss: 0.3071974515914917
Batch 60/64 loss: 0.3064153790473938
Batch 61/64 loss: 0.31445515155792236
Batch 62/64 loss: 0.32028889656066895
Batch 63/64 loss: 0.31346023082733154
Batch 64/64 loss: 0.31336188316345215
Epoch 256  Train loss: 0.31562951686335544  Val loss: 0.33630651522338184
Epoch 257
-------------------------------
Batch 1/64 loss: 0.3155509829521179
Batch 2/64 loss: 0.3146020770072937
Batch 3/64 loss: 0.3142129182815552
Batch 4/64 loss: 0.31752270460128784
Batch 5/64 loss: 0.31360840797424316
Batch 6/64 loss: 0.30933570861816406
Batch 7/64 loss: 0.32028651237487793
Batch 8/64 loss: 0.31632059812545776
Batch 9/64 loss: 0.31256479024887085
Batch 10/64 loss: 0.31174570322036743
Batch 11/64 loss: 0.3279350996017456
Batch 12/64 loss: 0.3116034269332886
Batch 13/64 loss: 0.312244176864624
Batch 14/64 loss: 0.3194754123687744
Batch 15/64 loss: 0.3098595142364502
Batch 16/64 loss: 0.31260645389556885
Batch 17/64 loss: 0.3124164938926697
Batch 18/64 loss: 0.31821370124816895
Batch 19/64 loss: 0.3128010034561157
Batch 20/64 loss: 0.30857110023498535
Batch 21/64 loss: 0.3124290704727173
Batch 22/64 loss: 0.32342052459716797
Batch 23/64 loss: 0.31748509407043457
Batch 24/64 loss: 0.3111121654510498
Batch 25/64 loss: 0.3283200263977051
Batch 26/64 loss: 0.31740665435791016
Batch 27/64 loss: 0.3187110424041748
Batch 28/64 loss: 0.3157971501350403
Batch 29/64 loss: 0.32157522439956665
Batch 30/64 loss: 0.318634569644928
Batch 31/64 loss: 0.32182979583740234
Batch 32/64 loss: 0.32187068462371826
Batch 33/64 loss: 0.3074989318847656
Batch 34/64 loss: 0.3159562349319458
Batch 35/64 loss: 0.31676173210144043
Batch 36/64 loss: 0.3141224980354309
Batch 37/64 loss: 0.3242921829223633
Batch 38/64 loss: 0.314974308013916
Batch 39/64 loss: 0.31203389167785645
Batch 40/64 loss: 0.3076324462890625
Batch 41/64 loss: 0.3173532485961914
Batch 42/64 loss: 0.31093811988830566
Batch 43/64 loss: 0.3133419156074524
Batch 44/64 loss: 0.31216394901275635
Batch 45/64 loss: 0.31886398792266846
Batch 46/64 loss: 0.31242334842681885
Batch 47/64 loss: 0.31218421459198
Batch 48/64 loss: 0.31248313188552856
Batch 49/64 loss: 0.32051724195480347
Batch 50/64 loss: 0.31172871589660645
Batch 51/64 loss: 0.30825114250183105
Batch 52/64 loss: 0.3211812973022461
Batch 53/64 loss: 0.3156352639198303
Batch 54/64 loss: 0.31713932752609253
Batch 55/64 loss: 0.31340932846069336
Batch 56/64 loss: 0.31555765867233276
Batch 57/64 loss: 0.3132460117340088
Batch 58/64 loss: 0.3146554231643677
Batch 59/64 loss: 0.3165470361709595
Batch 60/64 loss: 0.3129020929336548
Batch 61/64 loss: 0.3150867223739624
Batch 62/64 loss: 0.3123117685317993
Batch 63/64 loss: 0.3076810836791992
Batch 64/64 loss: 0.3119845390319824
Epoch 257  Train loss: 0.3151832384221694  Val loss: 0.33162960215532494
Saving best model, epoch: 257
Epoch 258
-------------------------------
Batch 1/64 loss: 0.30675339698791504
Batch 2/64 loss: 0.3132580518722534
Batch 3/64 loss: 0.3130429983139038
Batch 4/64 loss: 0.31062060594558716
Batch 5/64 loss: 0.3138614892959595
Batch 6/64 loss: 0.31302326917648315
Batch 7/64 loss: 0.30969977378845215
Batch 8/64 loss: 0.3234905004501343
Batch 9/64 loss: 0.3144139051437378
Batch 10/64 loss: 0.31810832023620605
Batch 11/64 loss: 0.3153808116912842
Batch 12/64 loss: 0.31717491149902344
Batch 13/64 loss: 0.3182678818702698
Batch 14/64 loss: 0.3231382369995117
Batch 15/64 loss: 0.31760895252227783
Batch 16/64 loss: 0.3182640075683594
Batch 17/64 loss: 0.3168811798095703
Batch 18/64 loss: 0.31640684604644775
Batch 19/64 loss: 0.31247419118881226
Batch 20/64 loss: 0.3123600482940674
Batch 21/64 loss: 0.32211315631866455
Batch 22/64 loss: 0.31386470794677734
Batch 23/64 loss: 0.3172895312309265
Batch 24/64 loss: 0.3168492317199707
Batch 25/64 loss: 0.3151381015777588
Batch 26/64 loss: 0.31327855587005615
Batch 27/64 loss: 0.3159604072570801
Batch 28/64 loss: 0.31907665729522705
Batch 29/64 loss: 0.3118351697921753
Batch 30/64 loss: 0.31277740001678467
Batch 31/64 loss: 0.31351733207702637
Batch 32/64 loss: 0.3103165626525879
Batch 33/64 loss: 0.31427913904190063
Batch 34/64 loss: 0.3219531774520874
Batch 35/64 loss: 0.3088514804840088
Batch 36/64 loss: 0.31713783740997314
Batch 37/64 loss: 0.3070333003997803
Batch 38/64 loss: 0.31861162185668945
Batch 39/64 loss: 0.31441205739974976
Batch 40/64 loss: 0.3094552755355835
Batch 41/64 loss: 0.31283098459243774
Batch 42/64 loss: 0.3077430725097656
Batch 43/64 loss: 0.31516551971435547
Batch 44/64 loss: 0.31511908769607544
Batch 45/64 loss: 0.31078481674194336
Batch 46/64 loss: 0.3160533308982849
Batch 47/64 loss: 0.31224560737609863
Batch 48/64 loss: 0.31983447074890137
Batch 49/64 loss: 0.32548487186431885
Batch 50/64 loss: 0.3110223412513733
Batch 51/64 loss: 0.31813371181488037
Batch 52/64 loss: 0.3170565366744995
Batch 53/64 loss: 0.31281447410583496
Batch 54/64 loss: 0.31695854663848877
Batch 55/64 loss: 0.31283867359161377
Batch 56/64 loss: 0.3183647394180298
Batch 57/64 loss: 0.3197803497314453
Batch 58/64 loss: 0.31711989641189575
Batch 59/64 loss: 0.3237267732620239
Batch 60/64 loss: 0.3190420866012573
Batch 61/64 loss: 0.31937509775161743
Batch 62/64 loss: 0.31212329864501953
Batch 63/64 loss: 0.3143458366394043
Batch 64/64 loss: 0.3184245228767395
Epoch 258  Train loss: 0.31536882508034797  Val loss: 0.3333430122264062
Epoch 259
-------------------------------
Batch 1/64 loss: 0.3253917694091797
Batch 2/64 loss: 0.31564903259277344
Batch 3/64 loss: 0.3153553009033203
Batch 4/64 loss: 0.3143311142921448
Batch 5/64 loss: 0.31864500045776367
Batch 6/64 loss: 0.3109742999076843
Batch 7/64 loss: 0.31158870458602905
Batch 8/64 loss: 0.313209593296051
Batch 9/64 loss: 0.3152011036872864
Batch 10/64 loss: 0.30898720026016235
Batch 11/64 loss: 0.3147869110107422
Batch 12/64 loss: 0.3033953309059143
Batch 13/64 loss: 0.3181527853012085
Batch 14/64 loss: 0.3101799488067627
Batch 15/64 loss: 0.3145800828933716
Batch 16/64 loss: 0.3209790587425232
Batch 17/64 loss: 0.3182695508003235
Batch 18/64 loss: 0.31428468227386475
Batch 19/64 loss: 0.3153591752052307
Batch 20/64 loss: 0.3145170211791992
Batch 21/64 loss: 0.3121427297592163
Batch 22/64 loss: 0.3129802942276001
Batch 23/64 loss: 0.32024306058883667
Batch 24/64 loss: 0.31114304065704346
Batch 25/64 loss: 0.3148661255836487
Batch 26/64 loss: 0.3185032606124878
Batch 27/64 loss: 0.3169901371002197
Batch 28/64 loss: 0.32008564472198486
Batch 29/64 loss: 0.3190406560897827
Batch 30/64 loss: 0.31774473190307617
Batch 31/64 loss: 0.313259482383728
Batch 32/64 loss: 0.309099018573761
Batch 33/64 loss: 0.3133506774902344
Batch 34/64 loss: 0.31292057037353516
Batch 35/64 loss: 0.31226611137390137
Batch 36/64 loss: 0.3137819766998291
Batch 37/64 loss: 0.31549543142318726
Batch 38/64 loss: 0.3109654188156128
Batch 39/64 loss: 0.3163064122200012
Batch 40/64 loss: 0.3079797029495239
Batch 41/64 loss: 0.3134258985519409
Batch 42/64 loss: 0.3064645528793335
Batch 43/64 loss: 0.31696295738220215
Batch 44/64 loss: 0.32431167364120483
Batch 45/64 loss: 0.313479483127594
Batch 46/64 loss: 0.3145599365234375
Batch 47/64 loss: 0.316439151763916
Batch 48/64 loss: 0.31264007091522217
Batch 49/64 loss: 0.31517159938812256
Batch 50/64 loss: 0.31207728385925293
Batch 51/64 loss: 0.31654268503189087
Batch 52/64 loss: 0.31170785427093506
Batch 53/64 loss: 0.30932939052581787
Batch 54/64 loss: 0.3162539005279541
Batch 55/64 loss: 0.30802595615386963
Batch 56/64 loss: 0.32062768936157227
Batch 57/64 loss: 0.3114762306213379
Batch 58/64 loss: 0.3185616135597229
Batch 59/64 loss: 0.3161933422088623
Batch 60/64 loss: 0.31982332468032837
Batch 61/64 loss: 0.3131296634674072
Batch 62/64 loss: 0.3149905204772949
Batch 63/64 loss: 0.3171113133430481
Batch 64/64 loss: 0.316048264503479
Epoch 259  Train loss: 0.3146563833835078  Val loss: 0.3324978740764238
Epoch 260
-------------------------------
Batch 1/64 loss: 0.313445508480072
Batch 2/64 loss: 0.31981122493743896
Batch 3/64 loss: 0.3211679458618164
Batch 4/64 loss: 0.31522297859191895
Batch 5/64 loss: 0.3153982162475586
Batch 6/64 loss: 0.3150513172149658
Batch 7/64 loss: 0.3171749711036682
Batch 8/64 loss: 0.3102555274963379
Batch 9/64 loss: 0.31213831901550293
Batch 10/64 loss: 0.31313180923461914
Batch 11/64 loss: 0.3129844665527344
Batch 12/64 loss: 0.31712406873703003
Batch 13/64 loss: 0.31232398748397827
Batch 14/64 loss: 0.311651349067688
Batch 15/64 loss: 0.3133612275123596
Batch 16/64 loss: 0.3155783414840698
Batch 17/64 loss: 0.31416547298431396
Batch 18/64 loss: 0.3157639503479004
Batch 19/64 loss: 0.31340157985687256
Batch 20/64 loss: 0.31126952171325684
Batch 21/64 loss: 0.31890445947647095
Batch 22/64 loss: 0.31369996070861816
Batch 23/64 loss: 0.32340776920318604
Batch 24/64 loss: 0.3116859793663025
Batch 25/64 loss: 0.3170050382614136
Batch 26/64 loss: 0.30779945850372314
Batch 27/64 loss: 0.3198918104171753
Batch 28/64 loss: 0.32012391090393066
Batch 29/64 loss: 0.3124654293060303
Batch 30/64 loss: 0.32550621032714844
Batch 31/64 loss: 0.30834007263183594
Batch 32/64 loss: 0.31384170055389404
Batch 33/64 loss: 0.30866527557373047
Batch 34/64 loss: 0.3133402466773987
Batch 35/64 loss: 0.32179009914398193
Batch 36/64 loss: 0.3133366107940674
Batch 37/64 loss: 0.31367647647857666
Batch 38/64 loss: 0.31176137924194336
Batch 39/64 loss: 0.3090062141418457
Batch 40/64 loss: 0.31115567684173584
Batch 41/64 loss: 0.31676286458969116
Batch 42/64 loss: 0.3249666094779968
Batch 43/64 loss: 0.3117328882217407
Batch 44/64 loss: 0.3158475160598755
Batch 45/64 loss: 0.3128206729888916
Batch 46/64 loss: 0.31143105030059814
Batch 47/64 loss: 0.3154546618461609
Batch 48/64 loss: 0.32006311416625977
Batch 49/64 loss: 0.31525909900665283
Batch 50/64 loss: 0.3171946406364441
Batch 51/64 loss: 0.316190242767334
Batch 52/64 loss: 0.3132767677307129
Batch 53/64 loss: 0.3140586018562317
Batch 54/64 loss: 0.31698334217071533
Batch 55/64 loss: 0.3122842311859131
Batch 56/64 loss: 0.3085625171661377
Batch 57/64 loss: 0.3131577968597412
Batch 58/64 loss: 0.3126019835472107
Batch 59/64 loss: 0.30720043182373047
Batch 60/64 loss: 0.31308215856552124
Batch 61/64 loss: 0.31328868865966797
Batch 62/64 loss: 0.31673115491867065
Batch 63/64 loss: 0.3124026656150818
Batch 64/64 loss: 0.31880635023117065
Epoch 260  Train loss: 0.3146083768676309  Val loss: 0.3313589987066603
Saving best model, epoch: 260
Epoch 261
-------------------------------
Batch 1/64 loss: 0.31688326597213745
Batch 2/64 loss: 0.31326407194137573
Batch 3/64 loss: 0.3185790777206421
Batch 4/64 loss: 0.3045227527618408
Batch 5/64 loss: 0.3115549087524414
Batch 6/64 loss: 0.3200889825820923
Batch 7/64 loss: 0.3164411783218384
Batch 8/64 loss: 0.3151189088821411
Batch 9/64 loss: 0.325331449508667
Batch 10/64 loss: 0.30595695972442627
Batch 11/64 loss: 0.3090965151786804
Batch 12/64 loss: 0.3112807273864746
Batch 13/64 loss: 0.3077315092086792
Batch 14/64 loss: 0.3163601756095886
Batch 15/64 loss: 0.3069119453430176
Batch 16/64 loss: 0.3163560628890991
Batch 17/64 loss: 0.3177534341812134
Batch 18/64 loss: 0.3189142942428589
Batch 19/64 loss: 0.3135606646537781
Batch 20/64 loss: 0.31931638717651367
Batch 21/64 loss: 0.3217455744743347
Batch 22/64 loss: 0.30479884147644043
Batch 23/64 loss: 0.3122514486312866
Batch 24/64 loss: 0.32343077659606934
Batch 25/64 loss: 0.30827540159225464
Batch 26/64 loss: 0.31100308895111084
Batch 27/64 loss: 0.30402445793151855
Batch 28/64 loss: 0.3112429976463318
Batch 29/64 loss: 0.3080620765686035
Batch 30/64 loss: 0.31365692615509033
Batch 31/64 loss: 0.3123618960380554
Batch 32/64 loss: 0.31750041246414185
Batch 33/64 loss: 0.3201035261154175
Batch 34/64 loss: 0.3262717127799988
Batch 35/64 loss: 0.3113267421722412
Batch 36/64 loss: 0.3112425208091736
Batch 37/64 loss: 0.31597280502319336
Batch 38/64 loss: 0.3105648159980774
Batch 39/64 loss: 0.3112887144088745
Batch 40/64 loss: 0.31608283519744873
Batch 41/64 loss: 0.31424248218536377
Batch 42/64 loss: 0.30653977394104004
Batch 43/64 loss: 0.3146170377731323
Batch 44/64 loss: 0.3143301010131836
Batch 45/64 loss: 0.31089699268341064
Batch 46/64 loss: 0.31070566177368164
Batch 47/64 loss: 0.3175692558288574
Batch 48/64 loss: 0.3115638494491577
Batch 49/64 loss: 0.31477802991867065
Batch 50/64 loss: 0.3102375268936157
Batch 51/64 loss: 0.3153526782989502
Batch 52/64 loss: 0.32068949937820435
Batch 53/64 loss: 0.3066554665565491
Batch 54/64 loss: 0.30478620529174805
Batch 55/64 loss: 0.3184087872505188
Batch 56/64 loss: 0.3231525421142578
Batch 57/64 loss: 0.31936466693878174
Batch 58/64 loss: 0.3248213529586792
Batch 59/64 loss: 0.3149973154067993
Batch 60/64 loss: 0.3170757293701172
Batch 61/64 loss: 0.31612837314605713
Batch 62/64 loss: 0.31856924295425415
Batch 63/64 loss: 0.3199443817138672
Batch 64/64 loss: 0.30817556381225586
Epoch 261  Train loss: 0.3142398348041609  Val loss: 0.3316699250047559
Epoch 262
-------------------------------
Batch 1/64 loss: 0.3146597743034363
Batch 2/64 loss: 0.3107874393463135
Batch 3/64 loss: 0.31759995222091675
Batch 4/64 loss: 0.3168930411338806
Batch 5/64 loss: 0.3179064989089966
Batch 6/64 loss: 0.3077772855758667
Batch 7/64 loss: 0.31812798976898193
Batch 8/64 loss: 0.3157120943069458
Batch 9/64 loss: 0.30921560525894165
Batch 10/64 loss: 0.3088468909263611
Batch 11/64 loss: 0.30872905254364014
Batch 12/64 loss: 0.3096979856491089
Batch 13/64 loss: 0.3137282133102417
Batch 14/64 loss: 0.31833046674728394
Batch 15/64 loss: 0.31160968542099
Batch 16/64 loss: 0.31118637323379517
Batch 17/64 loss: 0.3068082332611084
Batch 18/64 loss: 0.31673097610473633
Batch 19/64 loss: 0.31230777502059937
Batch 20/64 loss: 0.3089672327041626
Batch 21/64 loss: 0.30910611152648926
Batch 22/64 loss: 0.31605279445648193
Batch 23/64 loss: 0.3161159157752991
Batch 24/64 loss: 0.30985987186431885
Batch 25/64 loss: 0.32356762886047363
Batch 26/64 loss: 0.3141886591911316
Batch 27/64 loss: 0.3124956488609314
Batch 28/64 loss: 0.3118777871131897
Batch 29/64 loss: 0.3112962245941162
Batch 30/64 loss: 0.3168222904205322
Batch 31/64 loss: 0.31165611743927
Batch 32/64 loss: 0.30761051177978516
Batch 33/64 loss: 0.30844593048095703
Batch 34/64 loss: 0.3121722936630249
Batch 35/64 loss: 0.31227850914001465
Batch 36/64 loss: 0.31342142820358276
Batch 37/64 loss: 0.3137761354446411
Batch 38/64 loss: 0.3169247508049011
Batch 39/64 loss: 0.31483227014541626
Batch 40/64 loss: 0.30547523498535156
Batch 41/64 loss: 0.3187161684036255
Batch 42/64 loss: 0.31681501865386963
Batch 43/64 loss: 0.3143869638442993
Batch 44/64 loss: 0.31683963537216187
Batch 45/64 loss: 0.31235450506210327
Batch 46/64 loss: 0.32551783323287964
Batch 47/64 loss: 0.3051156997680664
Batch 48/64 loss: 0.31956565380096436
Batch 49/64 loss: 0.3122308850288391
Batch 50/64 loss: 0.31296205520629883
Batch 51/64 loss: 0.3120061159133911
Batch 52/64 loss: 0.3104081153869629
Batch 53/64 loss: 0.3092784881591797
Batch 54/64 loss: 0.3187956213951111
Batch 55/64 loss: 0.3138524293899536
Batch 56/64 loss: 0.31423765420913696
Batch 57/64 loss: 0.3169938325881958
Batch 58/64 loss: 0.3199843168258667
Batch 59/64 loss: 0.31780678033828735
Batch 60/64 loss: 0.3087127208709717
Batch 61/64 loss: 0.3169158697128296
Batch 62/64 loss: 0.3128851056098938
Batch 63/64 loss: 0.314766526222229
Batch 64/64 loss: 0.3259807825088501
Epoch 262  Train loss: 0.31371344725290934  Val loss: 0.33311570755804526
Epoch 263
-------------------------------
Batch 1/64 loss: 0.3159673810005188
Batch 2/64 loss: 0.31640470027923584
Batch 3/64 loss: 0.3100653290748596
Batch 4/64 loss: 0.3183772563934326
Batch 5/64 loss: 0.3170124888420105
Batch 6/64 loss: 0.31878697872161865
Batch 7/64 loss: 0.30160337686538696
Batch 8/64 loss: 0.3121681213378906
Batch 9/64 loss: 0.31070876121520996
Batch 10/64 loss: 0.3103986382484436
Batch 11/64 loss: 0.3138240575790405
Batch 12/64 loss: 0.30340075492858887
Batch 13/64 loss: 0.3195425868034363
Batch 14/64 loss: 0.3106495141983032
Batch 15/64 loss: 0.30928343534469604
Batch 16/64 loss: 0.31820815801620483
Batch 17/64 loss: 0.31569206714630127
Batch 18/64 loss: 0.32170671224594116
Batch 19/64 loss: 0.3100602626800537
Batch 20/64 loss: 0.31858110427856445
Batch 21/64 loss: 0.3196455240249634
Batch 22/64 loss: 0.315346896648407
Batch 23/64 loss: 0.3156490921974182
Batch 24/64 loss: 0.31699663400650024
Batch 25/64 loss: 0.31503647565841675
Batch 26/64 loss: 0.31457948684692383
Batch 27/64 loss: 0.3107033371925354
Batch 28/64 loss: 0.3150900602340698
Batch 29/64 loss: 0.31456631422042847
Batch 30/64 loss: 0.3063511252403259
Batch 31/64 loss: 0.31029415130615234
Batch 32/64 loss: 0.31009727716445923
Batch 33/64 loss: 0.31067705154418945
Batch 34/64 loss: 0.31279754638671875
Batch 35/64 loss: 0.312255859375
Batch 36/64 loss: 0.31325483322143555
Batch 37/64 loss: 0.3147980570793152
Batch 38/64 loss: 0.3134527802467346
Batch 39/64 loss: 0.31501251459121704
Batch 40/64 loss: 0.3154069185256958
Batch 41/64 loss: 0.32206839323043823
Batch 42/64 loss: 0.32106536626815796
Batch 43/64 loss: 0.31769096851348877
Batch 44/64 loss: 0.3155094385147095
Batch 45/64 loss: 0.3218792676925659
Batch 46/64 loss: 0.3093705177307129
Batch 47/64 loss: 0.3162076473236084
Batch 48/64 loss: 0.321066677570343
Batch 49/64 loss: 0.30811285972595215
Batch 50/64 loss: 0.30661338567733765
Batch 51/64 loss: 0.31949305534362793
Batch 52/64 loss: 0.309032142162323
Batch 53/64 loss: 0.3113480806350708
Batch 54/64 loss: 0.309675931930542
Batch 55/64 loss: 0.30352163314819336
Batch 56/64 loss: 0.3213467597961426
Batch 57/64 loss: 0.3118901252746582
Batch 58/64 loss: 0.31001174449920654
Batch 59/64 loss: 0.3226128816604614
Batch 60/64 loss: 0.3107602000236511
Batch 61/64 loss: 0.32299375534057617
Batch 62/64 loss: 0.31365978717803955
Batch 63/64 loss: 0.3126260042190552
Batch 64/64 loss: 0.3064209818840027
Epoch 263  Train loss: 0.3139266820514903  Val loss: 0.3325515377152826
Epoch 264
-------------------------------
Batch 1/64 loss: 0.3087770342826843
Batch 2/64 loss: 0.30852264165878296
Batch 3/64 loss: 0.3124008774757385
Batch 4/64 loss: 0.31448835134506226
Batch 5/64 loss: 0.31748664379119873
Batch 6/64 loss: 0.3138856291770935
Batch 7/64 loss: 0.30362069606781006
Batch 8/64 loss: 0.3112178444862366
Batch 9/64 loss: 0.3125033974647522
Batch 10/64 loss: 0.31188833713531494
Batch 11/64 loss: 0.3215881586074829
Batch 12/64 loss: 0.31327736377716064
Batch 13/64 loss: 0.3193446397781372
Batch 14/64 loss: 0.314364492893219
Batch 15/64 loss: 0.3122473955154419
Batch 16/64 loss: 0.3116118907928467
Batch 17/64 loss: 0.31400007009506226
Batch 18/64 loss: 0.31545019149780273
Batch 19/64 loss: 0.3094664216041565
Batch 20/64 loss: 0.31758618354797363
Batch 21/64 loss: 0.3165120482444763
Batch 22/64 loss: 0.31032657623291016
Batch 23/64 loss: 0.3082454204559326
Batch 24/64 loss: 0.3090946674346924
Batch 25/64 loss: 0.31462156772613525
Batch 26/64 loss: 0.3167881965637207
Batch 27/64 loss: 0.3084350824356079
Batch 28/64 loss: 0.30475354194641113
Batch 29/64 loss: 0.3144450783729553
Batch 30/64 loss: 0.3154603838920593
Batch 31/64 loss: 0.31630563735961914
Batch 32/64 loss: 0.31222736835479736
Batch 33/64 loss: 0.3160768747329712
Batch 34/64 loss: 0.31406646966934204
Batch 35/64 loss: 0.3175002932548523
Batch 36/64 loss: 0.31664395332336426
Batch 37/64 loss: 0.31374454498291016
Batch 38/64 loss: 0.31246793270111084
Batch 39/64 loss: 0.31442755460739136
Batch 40/64 loss: 0.3103184700012207
Batch 41/64 loss: 0.31528908014297485
Batch 42/64 loss: 0.31737494468688965
Batch 43/64 loss: 0.32279443740844727
Batch 44/64 loss: 0.31533801555633545
Batch 45/64 loss: 0.3108983039855957
Batch 46/64 loss: 0.30846107006073
Batch 47/64 loss: 0.3202587366104126
Batch 48/64 loss: 0.30720794200897217
Batch 49/64 loss: 0.31450188159942627
Batch 50/64 loss: 0.3102220296859741
Batch 51/64 loss: 0.3134304881095886
Batch 52/64 loss: 0.3135659694671631
Batch 53/64 loss: 0.31709516048431396
Batch 54/64 loss: 0.319915235042572
Batch 55/64 loss: 0.32133591175079346
Batch 56/64 loss: 0.321847140789032
Batch 57/64 loss: 0.3115677833557129
Batch 58/64 loss: 0.31150031089782715
Batch 59/64 loss: 0.3191795349121094
Batch 60/64 loss: 0.31092536449432373
Batch 61/64 loss: 0.3155004382133484
Batch 62/64 loss: 0.3074071407318115
Batch 63/64 loss: 0.3143540620803833
Batch 64/64 loss: 0.31751012802124023
Epoch 264  Train loss: 0.31379283923728796  Val loss: 0.33189630528905545
Epoch 265
-------------------------------
Batch 1/64 loss: 0.31151700019836426
Batch 2/64 loss: 0.3121349811553955
Batch 3/64 loss: 0.31361639499664307
Batch 4/64 loss: 0.30793827772140503
Batch 5/64 loss: 0.31343454122543335
Batch 6/64 loss: 0.3019845485687256
Batch 7/64 loss: 0.31825828552246094
Batch 8/64 loss: 0.31346940994262695
Batch 9/64 loss: 0.31227684020996094
Batch 10/64 loss: 0.3066216707229614
Batch 11/64 loss: 0.3073986768722534
Batch 12/64 loss: 0.31465989351272583
Batch 13/64 loss: 0.3263742923736572
Batch 14/64 loss: 0.31187909841537476
Batch 15/64 loss: 0.3105041980743408
Batch 16/64 loss: 0.30873358249664307
Batch 17/64 loss: 0.31299829483032227
Batch 18/64 loss: 0.30318528413772583
Batch 19/64 loss: 0.3201196789741516
Batch 20/64 loss: 0.31323838233947754
Batch 21/64 loss: 0.31629180908203125
Batch 22/64 loss: 0.3131774663925171
Batch 23/64 loss: 0.3073481321334839
Batch 24/64 loss: 0.316196084022522
Batch 25/64 loss: 0.30657076835632324
Batch 26/64 loss: 0.32536327838897705
Batch 27/64 loss: 0.3219263553619385
Batch 28/64 loss: 0.32014769315719604
Batch 29/64 loss: 0.2992055416107178
Batch 30/64 loss: 0.309731125831604
Batch 31/64 loss: 0.3150532841682434
Batch 32/64 loss: 0.32424795627593994
Batch 33/64 loss: 0.31117355823516846
Batch 34/64 loss: 0.3191033601760864
Batch 35/64 loss: 0.3192945122718811
Batch 36/64 loss: 0.3163679838180542
Batch 37/64 loss: 0.31264132261276245
Batch 38/64 loss: 0.3113689422607422
Batch 39/64 loss: 0.31361567974090576
Batch 40/64 loss: 0.3032575249671936
Batch 41/64 loss: 0.3143240809440613
Batch 42/64 loss: 0.3197447657585144
Batch 43/64 loss: 0.32497966289520264
Batch 44/64 loss: 0.30750733613967896
Batch 45/64 loss: 0.30623918771743774
Batch 46/64 loss: 0.30514436960220337
Batch 47/64 loss: 0.31473034620285034
Batch 48/64 loss: 0.31023335456848145
Batch 49/64 loss: 0.30524492263793945
Batch 50/64 loss: 0.3125506639480591
Batch 51/64 loss: 0.3154573440551758
Batch 52/64 loss: 0.3153896927833557
Batch 53/64 loss: 0.3112470507621765
Batch 54/64 loss: 0.31884169578552246
Batch 55/64 loss: 0.3143894672393799
Batch 56/64 loss: 0.3235588073730469
Batch 57/64 loss: 0.3211655020713806
Batch 58/64 loss: 0.3192232847213745
Batch 59/64 loss: 0.3058037757873535
Batch 60/64 loss: 0.3131048083305359
Batch 61/64 loss: 0.3111898899078369
Batch 62/64 loss: 0.317726194858551
Batch 63/64 loss: 0.31340646743774414
Batch 64/64 loss: 0.320157527923584
Epoch 265  Train loss: 0.3134705337823606  Val loss: 0.33060841584943007
Saving best model, epoch: 265
Epoch 266
-------------------------------
Batch 1/64 loss: 0.30928242206573486
Batch 2/64 loss: 0.31667768955230713
Batch 3/64 loss: 0.3169269561767578
Batch 4/64 loss: 0.3135266900062561
Batch 5/64 loss: 0.3208945393562317
Batch 6/64 loss: 0.3083917498588562
Batch 7/64 loss: 0.3168603181838989
Batch 8/64 loss: 0.30926620960235596
Batch 9/64 loss: 0.3214336633682251
Batch 10/64 loss: 0.3164162039756775
Batch 11/64 loss: 0.3143472671508789
Batch 12/64 loss: 0.30926257371902466
Batch 13/64 loss: 0.31510382890701294
Batch 14/64 loss: 0.31058382987976074
Batch 15/64 loss: 0.3096950054168701
Batch 16/64 loss: 0.31171321868896484
Batch 17/64 loss: 0.3135092854499817
Batch 18/64 loss: 0.3103848695755005
Batch 19/64 loss: 0.3123661279678345
Batch 20/64 loss: 0.31183016300201416
Batch 21/64 loss: 0.31067776679992676
Batch 22/64 loss: 0.3125189542770386
Batch 23/64 loss: 0.3027556538581848
Batch 24/64 loss: 0.31084316968917847
Batch 25/64 loss: 0.31138670444488525
Batch 26/64 loss: 0.2988694906234741
Batch 27/64 loss: 0.31048840284347534
Batch 28/64 loss: 0.3280675411224365
Batch 29/64 loss: 0.3215453028678894
Batch 30/64 loss: 0.3153434991836548
Batch 31/64 loss: 0.31441497802734375
Batch 32/64 loss: 0.3132050037384033
Batch 33/64 loss: 0.31275510787963867
Batch 34/64 loss: 0.32029855251312256
Batch 35/64 loss: 0.3026834726333618
Batch 36/64 loss: 0.31905126571655273
Batch 37/64 loss: 0.3209044337272644
Batch 38/64 loss: 0.30738377571105957
Batch 39/64 loss: 0.3092397451400757
Batch 40/64 loss: 0.30902552604675293
Batch 41/64 loss: 0.3123108148574829
Batch 42/64 loss: 0.3138883113861084
Batch 43/64 loss: 0.3152630925178528
Batch 44/64 loss: 0.3116135597229004
Batch 45/64 loss: 0.3101125955581665
Batch 46/64 loss: 0.31089121103286743
Batch 47/64 loss: 0.3090040683746338
Batch 48/64 loss: 0.31457507610321045
Batch 49/64 loss: 0.3113170862197876
Batch 50/64 loss: 0.31844252347946167
Batch 51/64 loss: 0.3085777759552002
Batch 52/64 loss: 0.3203277587890625
Batch 53/64 loss: 0.3110959529876709
Batch 54/64 loss: 0.31598466634750366
Batch 55/64 loss: 0.3171677589416504
Batch 56/64 loss: 0.31217461824417114
Batch 57/64 loss: 0.31172454357147217
Batch 58/64 loss: 0.32082515954971313
Batch 59/64 loss: 0.30663347244262695
Batch 60/64 loss: 0.3124249577522278
Batch 61/64 loss: 0.32316458225250244
Batch 62/64 loss: 0.31970661878585815
Batch 63/64 loss: 0.31396639347076416
Batch 64/64 loss: 0.30817824602127075
Epoch 266  Train loss: 0.3132903096722622  Val loss: 0.3317236783578224
Epoch 267
-------------------------------
Batch 1/64 loss: 0.3083838224411011
Batch 2/64 loss: 0.32209914922714233
Batch 3/64 loss: 0.3151676654815674
Batch 4/64 loss: 0.31172752380371094
Batch 5/64 loss: 0.31254422664642334
Batch 6/64 loss: 0.3151189684867859
Batch 7/64 loss: 0.3072929382324219
Batch 8/64 loss: 0.313603937625885
Batch 9/64 loss: 0.31109780073165894
Batch 10/64 loss: 0.3070465326309204
Batch 11/64 loss: 0.30694228410720825
Batch 12/64 loss: 0.3215489983558655
Batch 13/64 loss: 0.31617093086242676
Batch 14/64 loss: 0.3147011995315552
Batch 15/64 loss: 0.31547558307647705
Batch 16/64 loss: 0.31189942359924316
Batch 17/64 loss: 0.31594324111938477
Batch 18/64 loss: 0.31457674503326416
Batch 19/64 loss: 0.30801254510879517
Batch 20/64 loss: 0.3099339008331299
Batch 21/64 loss: 0.3152490258216858
Batch 22/64 loss: 0.31783419847488403
Batch 23/64 loss: 0.3139089345932007
Batch 24/64 loss: 0.3154252767562866
Batch 25/64 loss: 0.3123922348022461
Batch 26/64 loss: 0.3081338405609131
Batch 27/64 loss: 0.31429916620254517
Batch 28/64 loss: 0.30950528383255005
Batch 29/64 loss: 0.31230175495147705
Batch 30/64 loss: 0.30516117811203003
Batch 31/64 loss: 0.3091862201690674
Batch 32/64 loss: 0.3194692134857178
Batch 33/64 loss: 0.3079153895378113
Batch 34/64 loss: 0.3126571774482727
Batch 35/64 loss: 0.31349289417266846
Batch 36/64 loss: 0.31364113092422485
Batch 37/64 loss: 0.3148674964904785
Batch 38/64 loss: 0.3095253109931946
Batch 39/64 loss: 0.31865668296813965
Batch 40/64 loss: 0.310776948928833
Batch 41/64 loss: 0.3136698007583618
Batch 42/64 loss: 0.31325197219848633
Batch 43/64 loss: 0.3099633455276489
Batch 44/64 loss: 0.3128514885902405
Batch 45/64 loss: 0.3110225200653076
Batch 46/64 loss: 0.3149116635322571
Batch 47/64 loss: 0.31412941217422485
Batch 48/64 loss: 0.3099304437637329
Batch 49/64 loss: 0.3082941174507141
Batch 50/64 loss: 0.3129678964614868
Batch 51/64 loss: 0.3063313961029053
Batch 52/64 loss: 0.32207202911376953
Batch 53/64 loss: 0.3219068646430969
Batch 54/64 loss: 0.3139330744743347
Batch 55/64 loss: 0.3161768913269043
Batch 56/64 loss: 0.31158876419067383
Batch 57/64 loss: 0.31898415088653564
Batch 58/64 loss: 0.3094809055328369
Batch 59/64 loss: 0.3128678798675537
Batch 60/64 loss: 0.30767977237701416
Batch 61/64 loss: 0.3106236457824707
Batch 62/64 loss: 0.31263935565948486
Batch 63/64 loss: 0.32088690996170044
Batch 64/64 loss: 0.3054225444793701
Epoch 267  Train loss: 0.3129242036856857  Val loss: 0.3309765398707177
Epoch 268
-------------------------------
Batch 1/64 loss: 0.3098587393760681
Batch 2/64 loss: 0.3026915192604065
Batch 3/64 loss: 0.30572307109832764
Batch 4/64 loss: 0.3012438416481018
Batch 5/64 loss: 0.3088669776916504
Batch 6/64 loss: 0.3111492395401001
Batch 7/64 loss: 0.3189668655395508
Batch 8/64 loss: 0.31333303451538086
Batch 9/64 loss: 0.31378108263015747
Batch 10/64 loss: 0.317518413066864
Batch 11/64 loss: 0.31414830684661865
Batch 12/64 loss: 0.307407021522522
Batch 13/64 loss: 0.30904436111450195
Batch 14/64 loss: 0.31760817766189575
Batch 15/64 loss: 0.3082163333892822
Batch 16/64 loss: 0.3153280019760132
Batch 17/64 loss: 0.31808650493621826
Batch 18/64 loss: 0.3098188042640686
Batch 19/64 loss: 0.31428951025009155
Batch 20/64 loss: 0.31139111518859863
Batch 21/64 loss: 0.306954026222229
Batch 22/64 loss: 0.31309056282043457
Batch 23/64 loss: 0.3119741678237915
Batch 24/64 loss: 0.3172731399536133
Batch 25/64 loss: 0.317645788192749
Batch 26/64 loss: 0.31541818380355835
Batch 27/64 loss: 0.31089186668395996
Batch 28/64 loss: 0.3127847909927368
Batch 29/64 loss: 0.3153250217437744
Batch 30/64 loss: 0.31663429737091064
Batch 31/64 loss: 0.3235435485839844
Batch 32/64 loss: 0.30639374256134033
Batch 33/64 loss: 0.3179682493209839
Batch 34/64 loss: 0.3161144256591797
Batch 35/64 loss: 0.3157704472541809
Batch 36/64 loss: 0.316203236579895
Batch 37/64 loss: 0.31059974431991577
Batch 38/64 loss: 0.311712384223938
Batch 39/64 loss: 0.3046049475669861
Batch 40/64 loss: 0.3144567608833313
Batch 41/64 loss: 0.3147420883178711
Batch 42/64 loss: 0.3166377544403076
Batch 43/64 loss: 0.3111393451690674
Batch 44/64 loss: 0.3128737211227417
Batch 45/64 loss: 0.3151336908340454
Batch 46/64 loss: 0.30226731300354004
Batch 47/64 loss: 0.31100940704345703
Batch 48/64 loss: 0.3138396739959717
Batch 49/64 loss: 0.3055911064147949
Batch 50/64 loss: 0.31315410137176514
Batch 51/64 loss: 0.31620216369628906
Batch 52/64 loss: 0.31037116050720215
Batch 53/64 loss: 0.3096439838409424
Batch 54/64 loss: 0.3056117296218872
Batch 55/64 loss: 0.316706120967865
Batch 56/64 loss: 0.30828404426574707
Batch 57/64 loss: 0.3167209029197693
Batch 58/64 loss: 0.3125572204589844
Batch 59/64 loss: 0.3102416396141052
Batch 60/64 loss: 0.31261104345321655
Batch 61/64 loss: 0.312009334564209
Batch 62/64 loss: 0.3075453042984009
Batch 63/64 loss: 0.31575489044189453
Batch 64/64 loss: 0.3185334801673889
Epoch 268  Train loss: 0.31236671536576516  Val loss: 0.33025157410664246
Saving best model, epoch: 268
Epoch 269
-------------------------------
Batch 1/64 loss: 0.313991904258728
Batch 2/64 loss: 0.3074793815612793
Batch 3/64 loss: 0.30728280544281006
Batch 4/64 loss: 0.3136711120605469
Batch 5/64 loss: 0.31610721349716187
Batch 6/64 loss: 0.3122677206993103
Batch 7/64 loss: 0.3078511357307434
Batch 8/64 loss: 0.3130234479904175
Batch 9/64 loss: 0.30895471572875977
Batch 10/64 loss: 0.3176610469818115
Batch 11/64 loss: 0.30810385942459106
Batch 12/64 loss: 0.31456267833709717
Batch 13/64 loss: 0.3166724443435669
Batch 14/64 loss: 0.31882208585739136
Batch 15/64 loss: 0.3193697929382324
Batch 16/64 loss: 0.3113507032394409
Batch 17/64 loss: 0.31177616119384766
Batch 18/64 loss: 0.3084508180618286
Batch 19/64 loss: 0.31524658203125
Batch 20/64 loss: 0.30416566133499146
Batch 21/64 loss: 0.30572324991226196
Batch 22/64 loss: 0.31469935178756714
Batch 23/64 loss: 0.31010913848876953
Batch 24/64 loss: 0.3215116262435913
Batch 25/64 loss: 0.31492841243743896
Batch 26/64 loss: 0.3033950924873352
Batch 27/64 loss: 0.31536954641342163
Batch 28/64 loss: 0.31274259090423584
Batch 29/64 loss: 0.31376171112060547
Batch 30/64 loss: 0.3044281005859375
Batch 31/64 loss: 0.3220139741897583
Batch 32/64 loss: 0.3177608847618103
Batch 33/64 loss: 0.3207888603210449
Batch 34/64 loss: 0.31193453073501587
Batch 35/64 loss: 0.30482232570648193
Batch 36/64 loss: 0.31719040870666504
Batch 37/64 loss: 0.30654841661453247
Batch 38/64 loss: 0.3213992118835449
Batch 39/64 loss: 0.30987441539764404
Batch 40/64 loss: 0.31594568490982056
Batch 41/64 loss: 0.31157493591308594
Batch 42/64 loss: 0.30991363525390625
Batch 43/64 loss: 0.3107975125312805
Batch 44/64 loss: 0.3175855278968811
Batch 45/64 loss: 0.31157636642456055
Batch 46/64 loss: 0.31645774841308594
Batch 47/64 loss: 0.3172455430030823
Batch 48/64 loss: 0.31173574924468994
Batch 49/64 loss: 0.3174407482147217
Batch 50/64 loss: 0.3124431371688843
Batch 51/64 loss: 0.3121578097343445
Batch 52/64 loss: 0.3046082854270935
Batch 53/64 loss: 0.3056151866912842
Batch 54/64 loss: 0.3163009285926819
Batch 55/64 loss: 0.3154359459877014
Batch 56/64 loss: 0.3123982548713684
Batch 57/64 loss: 0.3122459650039673
Batch 58/64 loss: 0.31305992603302
Batch 59/64 loss: 0.3072108030319214
Batch 60/64 loss: 0.3162599205970764
Batch 61/64 loss: 0.31540143489837646
Batch 62/64 loss: 0.31262916326522827
Batch 63/64 loss: 0.3121708631515503
Batch 64/64 loss: 0.3041403889656067
Epoch 269  Train loss: 0.31266085470423977  Val loss: 0.330305761078379
Epoch 270
-------------------------------
Batch 1/64 loss: 0.3147214651107788
Batch 2/64 loss: 0.31096887588500977
Batch 3/64 loss: 0.3134183883666992
Batch 4/64 loss: 0.32058900594711304
Batch 5/64 loss: 0.308854341506958
Batch 6/64 loss: 0.3117680549621582
Batch 7/64 loss: 0.31461620330810547
Batch 8/64 loss: 0.30779433250427246
Batch 9/64 loss: 0.3096752166748047
Batch 10/64 loss: 0.31564879417419434
Batch 11/64 loss: 0.3113926649093628
Batch 12/64 loss: 0.3136099576950073
Batch 13/64 loss: 0.3212682008743286
Batch 14/64 loss: 0.30998867750167847
Batch 15/64 loss: 0.3170745372772217
Batch 16/64 loss: 0.3157848119735718
Batch 17/64 loss: 0.3146974444389343
Batch 18/64 loss: 0.30782437324523926
Batch 19/64 loss: 0.3074667453765869
Batch 20/64 loss: 0.31053435802459717
Batch 21/64 loss: 0.3104745149612427
Batch 22/64 loss: 0.31217241287231445
Batch 23/64 loss: 0.31211012601852417
Batch 24/64 loss: 0.316778302192688
Batch 25/64 loss: 0.3221140503883362
Batch 26/64 loss: 0.312211275100708
Batch 27/64 loss: 0.3137437105178833
Batch 28/64 loss: 0.3115014433860779
Batch 29/64 loss: 0.3142508268356323
Batch 30/64 loss: 0.31524187326431274
Batch 31/64 loss: 0.3287830948829651
Batch 32/64 loss: 0.30898869037628174
Batch 33/64 loss: 0.31577974557876587
Batch 34/64 loss: 0.3078400492668152
Batch 35/64 loss: 0.31067556142807007
Batch 36/64 loss: 0.321549654006958
Batch 37/64 loss: 0.3145638108253479
Batch 38/64 loss: 0.3141658902168274
Batch 39/64 loss: 0.31205040216445923
Batch 40/64 loss: 0.315152108669281
Batch 41/64 loss: 0.31200140714645386
Batch 42/64 loss: 0.3155757188796997
Batch 43/64 loss: 0.31721675395965576
Batch 44/64 loss: 0.31826251745224
Batch 45/64 loss: 0.32045358419418335
Batch 46/64 loss: 0.3032252788543701
Batch 47/64 loss: 0.3129238486289978
Batch 48/64 loss: 0.30884432792663574
Batch 49/64 loss: 0.3118274211883545
Batch 50/64 loss: 0.30554747581481934
Batch 51/64 loss: 0.30825376510620117
Batch 52/64 loss: 0.31299519538879395
Batch 53/64 loss: 0.3113776445388794
Batch 54/64 loss: 0.3100336194038391
Batch 55/64 loss: 0.31424808502197266
Batch 56/64 loss: 0.2997491955757141
Batch 57/64 loss: 0.3193368911743164
Batch 58/64 loss: 0.31259167194366455
Batch 59/64 loss: 0.31182223558425903
Batch 60/64 loss: 0.3070228099822998
Batch 61/64 loss: 0.31768935918807983
Batch 62/64 loss: 0.3123539686203003
Batch 63/64 loss: 0.30965590476989746
Batch 64/64 loss: 0.306148886680603
Epoch 270  Train loss: 0.3129484602049285  Val loss: 0.33078352159650876
Epoch 271
-------------------------------
Batch 1/64 loss: 0.3179968595504761
Batch 2/64 loss: 0.31020915508270264
Batch 3/64 loss: 0.3135836124420166
Batch 4/64 loss: 0.31024813652038574
Batch 5/64 loss: 0.31277942657470703
Batch 6/64 loss: 0.3187037706375122
Batch 7/64 loss: 0.31040000915527344
Batch 8/64 loss: 0.31572186946868896
Batch 9/64 loss: 0.3091275691986084
Batch 10/64 loss: 0.3028923273086548
Batch 11/64 loss: 0.313387393951416
Batch 12/64 loss: 0.31343090534210205
Batch 13/64 loss: 0.3085130453109741
Batch 14/64 loss: 0.3147242069244385
Batch 15/64 loss: 0.31529319286346436
Batch 16/64 loss: 0.3102765679359436
Batch 17/64 loss: 0.30736714601516724
Batch 18/64 loss: 0.3097219467163086
Batch 19/64 loss: 0.30669206380844116
Batch 20/64 loss: 0.3094741106033325
Batch 21/64 loss: 0.3169116973876953
Batch 22/64 loss: 0.31006336212158203
Batch 23/64 loss: 0.31635749340057373
Batch 24/64 loss: 0.30817532539367676
Batch 25/64 loss: 0.30927574634552
Batch 26/64 loss: 0.3147958517074585
Batch 27/64 loss: 0.3044849634170532
Batch 28/64 loss: 0.3180362582206726
Batch 29/64 loss: 0.3099403381347656
Batch 30/64 loss: 0.30517399311065674
Batch 31/64 loss: 0.3094879388809204
Batch 32/64 loss: 0.3102514147758484
Batch 33/64 loss: 0.31473517417907715
Batch 34/64 loss: 0.3062399625778198
Batch 35/64 loss: 0.3058197498321533
Batch 36/64 loss: 0.31534814834594727
Batch 37/64 loss: 0.3104041814804077
Batch 38/64 loss: 0.3107560873031616
Batch 39/64 loss: 0.3222648501396179
Batch 40/64 loss: 0.31680458784103394
Batch 41/64 loss: 0.30213242769241333
Batch 42/64 loss: 0.31026434898376465
Batch 43/64 loss: 0.30498605966567993
Batch 44/64 loss: 0.3015007972717285
Batch 45/64 loss: 0.318210244178772
Batch 46/64 loss: 0.3164469003677368
Batch 47/64 loss: 0.3083614706993103
Batch 48/64 loss: 0.3112051486968994
Batch 49/64 loss: 0.3137972950935364
Batch 50/64 loss: 0.3140414357185364
Batch 51/64 loss: 0.31265437602996826
Batch 52/64 loss: 0.3170905113220215
Batch 53/64 loss: 0.3151421546936035
Batch 54/64 loss: 0.31756144762039185
Batch 55/64 loss: 0.31639254093170166
Batch 56/64 loss: 0.31182336807250977
Batch 57/64 loss: 0.3247718811035156
Batch 58/64 loss: 0.30265986919403076
Batch 59/64 loss: 0.3093409538269043
Batch 60/64 loss: 0.3099128007888794
Batch 61/64 loss: 0.3095710277557373
Batch 62/64 loss: 0.3145580291748047
Batch 63/64 loss: 0.32583528757095337
Batch 64/64 loss: 0.3110013008117676
Epoch 271  Train loss: 0.3119589300716625  Val loss: 0.3304648993351206
Epoch 272
-------------------------------
Batch 1/64 loss: 0.31120508909225464
Batch 2/64 loss: 0.32363784313201904
Batch 3/64 loss: 0.3058452606201172
Batch 4/64 loss: 0.3154974579811096
Batch 5/64 loss: 0.3097728490829468
Batch 6/64 loss: 0.3084360957145691
Batch 7/64 loss: 0.3113710284233093
Batch 8/64 loss: 0.3070032000541687
Batch 9/64 loss: 0.309481680393219
Batch 10/64 loss: 0.3195558190345764
Batch 11/64 loss: 0.303405225276947
Batch 12/64 loss: 0.31462812423706055
Batch 13/64 loss: 0.3091299533843994
Batch 14/64 loss: 0.3108311891555786
Batch 15/64 loss: 0.3036007881164551
Batch 16/64 loss: 0.31618136167526245
Batch 17/64 loss: 0.30934858322143555
Batch 18/64 loss: 0.3147108554840088
Batch 19/64 loss: 0.3098808526992798
Batch 20/64 loss: 0.31029319763183594
Batch 21/64 loss: 0.31399381160736084
Batch 22/64 loss: 0.31226545572280884
Batch 23/64 loss: 0.3168361186981201
Batch 24/64 loss: 0.3146106004714966
Batch 25/64 loss: 0.3084906339645386
Batch 26/64 loss: 0.3099365830421448
Batch 27/64 loss: 0.32009196281433105
Batch 28/64 loss: 0.3132615089416504
Batch 29/64 loss: 0.30788981914520264
Batch 30/64 loss: 0.3110296130180359
Batch 31/64 loss: 0.32009458541870117
Batch 32/64 loss: 0.30581551790237427
Batch 33/64 loss: 0.32046276330947876
Batch 34/64 loss: 0.3132288455963135
Batch 35/64 loss: 0.3125319480895996
Batch 36/64 loss: 0.31662774085998535
Batch 37/64 loss: 0.3144640326499939
Batch 38/64 loss: 0.31271082162857056
Batch 39/64 loss: 0.31157487630844116
Batch 40/64 loss: 0.3102719187736511
Batch 41/64 loss: 0.3107299208641052
Batch 42/64 loss: 0.3075895309448242
Batch 43/64 loss: 0.3168766498565674
Batch 44/64 loss: 0.31470394134521484
Batch 45/64 loss: 0.31864678859710693
Batch 46/64 loss: 0.3165702819824219
Batch 47/64 loss: 0.31700021028518677
Batch 48/64 loss: 0.31244421005249023
Batch 49/64 loss: 0.3143514394760132
Batch 50/64 loss: 0.3195079565048218
Batch 51/64 loss: 0.31452029943466187
Batch 52/64 loss: 0.310296893119812
Batch 53/64 loss: 0.30624985694885254
Batch 54/64 loss: 0.3065497875213623
Batch 55/64 loss: 0.30806928873062134
Batch 56/64 loss: 0.3029731512069702
Batch 57/64 loss: 0.3079192042350769
Batch 58/64 loss: 0.3115832805633545
Batch 59/64 loss: 0.31929171085357666
Batch 60/64 loss: 0.3116776943206787
Batch 61/64 loss: 0.30949872732162476
Batch 62/64 loss: 0.30900466442108154
Batch 63/64 loss: 0.30821841955184937
Batch 64/64 loss: 0.3150830864906311
Epoch 272  Train loss: 0.31216614643732704  Val loss: 0.3328131873583056
Epoch 273
-------------------------------
Batch 1/64 loss: 0.3043307662010193
Batch 2/64 loss: 0.3108738660812378
Batch 3/64 loss: 0.3124158978462219
Batch 4/64 loss: 0.3102980852127075
Batch 5/64 loss: 0.30701005458831787
Batch 6/64 loss: 0.3089480400085449
Batch 7/64 loss: 0.309695839881897
Batch 8/64 loss: 0.3147350549697876
Batch 9/64 loss: 0.31081581115722656
Batch 10/64 loss: 0.32040882110595703
Batch 11/64 loss: 0.30913829803466797
Batch 12/64 loss: 0.30645912885665894
Batch 13/64 loss: 0.30541443824768066
Batch 14/64 loss: 0.30890047550201416
Batch 15/64 loss: 0.31494903564453125
Batch 16/64 loss: 0.30875593423843384
Batch 17/64 loss: 0.30876624584198
Batch 18/64 loss: 0.31334376335144043
Batch 19/64 loss: 0.3225691318511963
Batch 20/64 loss: 0.30140650272369385
Batch 21/64 loss: 0.31936752796173096
Batch 22/64 loss: 0.3145027756690979
Batch 23/64 loss: 0.3276718854904175
Batch 24/64 loss: 0.30640846490859985
Batch 25/64 loss: 0.3074825406074524
Batch 26/64 loss: 0.31542420387268066
Batch 27/64 loss: 0.31008481979370117
Batch 28/64 loss: 0.3075461983680725
Batch 29/64 loss: 0.3031091094017029
Batch 30/64 loss: 0.32004493474960327
Batch 31/64 loss: 0.3158247470855713
Batch 32/64 loss: 0.31255513429641724
Batch 33/64 loss: 0.3163849711418152
Batch 34/64 loss: 0.3088277578353882
Batch 35/64 loss: 0.3151431679725647
Batch 36/64 loss: 0.3196268081665039
Batch 37/64 loss: 0.31439077854156494
Batch 38/64 loss: 0.3203237056732178
Batch 39/64 loss: 0.3150615692138672
Batch 40/64 loss: 0.3117749094963074
Batch 41/64 loss: 0.3134291172027588
Batch 42/64 loss: 0.31764209270477295
Batch 43/64 loss: 0.3093799352645874
Batch 44/64 loss: 0.30849409103393555
Batch 45/64 loss: 0.31057828664779663
Batch 46/64 loss: 0.3147585988044739
Batch 47/64 loss: 0.30962073802948
Batch 48/64 loss: 0.31273365020751953
Batch 49/64 loss: 0.31216657161712646
Batch 50/64 loss: 0.3135988712310791
Batch 51/64 loss: 0.3121013641357422
Batch 52/64 loss: 0.3065378665924072
Batch 53/64 loss: 0.3103786110877991
Batch 54/64 loss: 0.307869553565979
Batch 55/64 loss: 0.31187570095062256
Batch 56/64 loss: 0.31432080268859863
Batch 57/64 loss: 0.31312859058380127
Batch 58/64 loss: 0.30966055393218994
Batch 59/64 loss: 0.31294161081314087
Batch 60/64 loss: 0.3219318389892578
Batch 61/64 loss: 0.31820154190063477
Batch 62/64 loss: 0.30929839611053467
Batch 63/64 loss: 0.3121051788330078
Batch 64/64 loss: 0.310386061668396
Epoch 273  Train loss: 0.3122562244826672  Val loss: 0.3304483452203757
Epoch 274
-------------------------------
Batch 1/64 loss: 0.3073427677154541
Batch 2/64 loss: 0.32071518898010254
Batch 3/64 loss: 0.2959326505661011
Batch 4/64 loss: 0.31318777799606323
Batch 5/64 loss: 0.31855183839797974
Batch 6/64 loss: 0.30857300758361816
Batch 7/64 loss: 0.30422067642211914
Batch 8/64 loss: 0.3136734366416931
Batch 9/64 loss: 0.3127087354660034
Batch 10/64 loss: 0.3191276788711548
Batch 11/64 loss: 0.32118141651153564
Batch 12/64 loss: 0.3132391571998596
Batch 13/64 loss: 0.3104628324508667
Batch 14/64 loss: 0.3131471872329712
Batch 15/64 loss: 0.3074243664741516
Batch 16/64 loss: 0.3114702105522156
Batch 17/64 loss: 0.3067814111709595
Batch 18/64 loss: 0.30147457122802734
Batch 19/64 loss: 0.3042469024658203
Batch 20/64 loss: 0.3179893493652344
Batch 21/64 loss: 0.313564658164978
Batch 22/64 loss: 0.3116716146469116
Batch 23/64 loss: 0.3207830786705017
Batch 24/64 loss: 0.3096315860748291
Batch 25/64 loss: 0.3050525188446045
Batch 26/64 loss: 0.3193123936653137
Batch 27/64 loss: 0.31562912464141846
Batch 28/64 loss: 0.3173597455024719
Batch 29/64 loss: 0.32430458068847656
Batch 30/64 loss: 0.3077127933502197
Batch 31/64 loss: 0.3079272508621216
Batch 32/64 loss: 0.31152963638305664
Batch 33/64 loss: 0.31515127420425415
Batch 34/64 loss: 0.31042206287384033
Batch 35/64 loss: 0.3184254765510559
Batch 36/64 loss: 0.30360567569732666
Batch 37/64 loss: 0.31266939640045166
Batch 38/64 loss: 0.30880069732666016
Batch 39/64 loss: 0.30594104528427124
Batch 40/64 loss: 0.3099597096443176
Batch 41/64 loss: 0.32255303859710693
Batch 42/64 loss: 0.3054443597793579
Batch 43/64 loss: 0.30406540632247925
Batch 44/64 loss: 0.31412273645401
Batch 45/64 loss: 0.3159821033477783
Batch 46/64 loss: 0.313417911529541
Batch 47/64 loss: 0.3038346767425537
Batch 48/64 loss: 0.31974923610687256
Batch 49/64 loss: 0.31461429595947266
Batch 50/64 loss: 0.316753625869751
Batch 51/64 loss: 0.312208890914917
Batch 52/64 loss: 0.30679547786712646
Batch 53/64 loss: 0.3118298053741455
Batch 54/64 loss: 0.31897038221359253
Batch 55/64 loss: 0.30698835849761963
Batch 56/64 loss: 0.31087255477905273
Batch 57/64 loss: 0.30575549602508545
Batch 58/64 loss: 0.30672669410705566
Batch 59/64 loss: 0.3057277202606201
Batch 60/64 loss: 0.31291520595550537
Batch 61/64 loss: 0.3212937116622925
Batch 62/64 loss: 0.31072062253952026
Batch 63/64 loss: 0.3124213218688965
Batch 64/64 loss: 0.30434292554855347
Epoch 274  Train loss: 0.3117321774071338  Val loss: 0.32961705624033083
Saving best model, epoch: 274
Epoch 275
-------------------------------
Batch 1/64 loss: 0.3083294630050659
Batch 2/64 loss: 0.3122701644897461
Batch 3/64 loss: 0.3139435052871704
Batch 4/64 loss: 0.3169771432876587
Batch 5/64 loss: 0.3137263059616089
Batch 6/64 loss: 0.3065826892852783
Batch 7/64 loss: 0.31112468242645264
Batch 8/64 loss: 0.31387388706207275
Batch 9/64 loss: 0.3140164613723755
Batch 10/64 loss: 0.30563652515411377
Batch 11/64 loss: 0.31406593322753906
Batch 12/64 loss: 0.30977338552474976
Batch 13/64 loss: 0.3054478168487549
Batch 14/64 loss: 0.3111279010772705
Batch 15/64 loss: 0.3071941137313843
Batch 16/64 loss: 0.31064164638519287
Batch 17/64 loss: 0.31090670824050903
Batch 18/64 loss: 0.30590879917144775
Batch 19/64 loss: 0.31899988651275635
Batch 20/64 loss: 0.3168247938156128
Batch 21/64 loss: 0.30563753843307495
Batch 22/64 loss: 0.30727481842041016
Batch 23/64 loss: 0.31376540660858154
Batch 24/64 loss: 0.3132222890853882
Batch 25/64 loss: 0.30547595024108887
Batch 26/64 loss: 0.3086860179901123
Batch 27/64 loss: 0.3088322877883911
Batch 28/64 loss: 0.31380677223205566
Batch 29/64 loss: 0.31110185384750366
Batch 30/64 loss: 0.3100985288619995
Batch 31/64 loss: 0.3085838556289673
Batch 32/64 loss: 0.314255952835083
Batch 33/64 loss: 0.3178313970565796
Batch 34/64 loss: 0.31057465076446533
Batch 35/64 loss: 0.31300097703933716
Batch 36/64 loss: 0.3225947618484497
Batch 37/64 loss: 0.30158519744873047
Batch 38/64 loss: 0.30842888355255127
Batch 39/64 loss: 0.31647539138793945
Batch 40/64 loss: 0.3104884624481201
Batch 41/64 loss: 0.3172227144241333
Batch 42/64 loss: 0.322542667388916
Batch 43/64 loss: 0.3064314126968384
Batch 44/64 loss: 0.3179023265838623
Batch 45/64 loss: 0.3156515955924988
Batch 46/64 loss: 0.31591010093688965
Batch 47/64 loss: 0.3073294758796692
Batch 48/64 loss: 0.3109777569770813
Batch 49/64 loss: 0.31244271993637085
Batch 50/64 loss: 0.3206173777580261
Batch 51/64 loss: 0.30707234144210815
Batch 52/64 loss: 0.31978118419647217
Batch 53/64 loss: 0.3122209906578064
Batch 54/64 loss: 0.31382161378860474
Batch 55/64 loss: 0.31138598918914795
Batch 56/64 loss: 0.31318163871765137
Batch 57/64 loss: 0.3125497102737427
Batch 58/64 loss: 0.31092387437820435
Batch 59/64 loss: 0.3134220242500305
Batch 60/64 loss: 0.3158162832260132
Batch 61/64 loss: 0.31547021865844727
Batch 62/64 loss: 0.29753607511520386
Batch 63/64 loss: 0.31918931007385254
Batch 64/64 loss: 0.31265920400619507
Epoch 275  Train loss: 0.3120468487926558  Val loss: 0.3298196124866656
Epoch 276
-------------------------------
Batch 1/64 loss: 0.3054856061935425
Batch 2/64 loss: 0.315030574798584
Batch 3/64 loss: 0.3134685754776001
Batch 4/64 loss: 0.30663764476776123
Batch 5/64 loss: 0.31175661087036133
Batch 6/64 loss: 0.30950403213500977
Batch 7/64 loss: 0.2953963279724121
Batch 8/64 loss: 0.3132227659225464
Batch 9/64 loss: 0.3060787320137024
Batch 10/64 loss: 0.30661672353744507
Batch 11/64 loss: 0.306718111038208
Batch 12/64 loss: 0.3049687147140503
Batch 13/64 loss: 0.31664490699768066
Batch 14/64 loss: 0.3187159299850464
Batch 15/64 loss: 0.31405603885650635
Batch 16/64 loss: 0.31534719467163086
Batch 17/64 loss: 0.30735981464385986
Batch 18/64 loss: 0.3161280155181885
Batch 19/64 loss: 0.3170357942581177
Batch 20/64 loss: 0.3070557117462158
Batch 21/64 loss: 0.31442952156066895
Batch 22/64 loss: 0.31155264377593994
Batch 23/64 loss: 0.32907092571258545
Batch 24/64 loss: 0.31543946266174316
Batch 25/64 loss: 0.31786268949508667
Batch 26/64 loss: 0.30411362648010254
Batch 27/64 loss: 0.3177204132080078
Batch 28/64 loss: 0.31434738636016846
Batch 29/64 loss: 0.30583304166793823
Batch 30/64 loss: 0.30551260709762573
Batch 31/64 loss: 0.3120967745780945
Batch 32/64 loss: 0.30954092741012573
Batch 33/64 loss: 0.31985217332839966
Batch 34/64 loss: 0.3094335198402405
Batch 35/64 loss: 0.31013381481170654
Batch 36/64 loss: 0.3186701536178589
Batch 37/64 loss: 0.3078775405883789
Batch 38/64 loss: 0.3065309524536133
Batch 39/64 loss: 0.31210434436798096
Batch 40/64 loss: 0.3143653869628906
Batch 41/64 loss: 0.3108510971069336
Batch 42/64 loss: 0.3155651092529297
Batch 43/64 loss: 0.30760645866394043
Batch 44/64 loss: 0.31033408641815186
Batch 45/64 loss: 0.305716335773468
Batch 46/64 loss: 0.30711257457733154
Batch 47/64 loss: 0.31039196252822876
Batch 48/64 loss: 0.3135814070701599
Batch 49/64 loss: 0.317099928855896
Batch 50/64 loss: 0.30900371074676514
Batch 51/64 loss: 0.3144545555114746
Batch 52/64 loss: 0.30575668811798096
Batch 53/64 loss: 0.3055230975151062
Batch 54/64 loss: 0.31419944763183594
Batch 55/64 loss: 0.3111730217933655
Batch 56/64 loss: 0.3081575632095337
Batch 57/64 loss: 0.3127938508987427
Batch 58/64 loss: 0.31720399856567383
Batch 59/64 loss: 0.3133823871612549
Batch 60/64 loss: 0.3099737763404846
Batch 61/64 loss: 0.3033640384674072
Batch 62/64 loss: 0.3194541931152344
Batch 63/64 loss: 0.3180977702140808
Batch 64/64 loss: 0.3137516975402832
Epoch 276  Train loss: 0.31152669121237364  Val loss: 0.3296493775246479
Epoch 277
-------------------------------
Batch 1/64 loss: 0.3139498829841614
Batch 2/64 loss: 0.3033949136734009
Batch 3/64 loss: 0.3123306632041931
Batch 4/64 loss: 0.3024711608886719
Batch 5/64 loss: 0.3104066848754883
Batch 6/64 loss: 0.31532084941864014
Batch 7/64 loss: 0.3119586110115051
Batch 8/64 loss: 0.310214102268219
Batch 9/64 loss: 0.3088496923446655
Batch 10/64 loss: 0.3129372000694275
Batch 11/64 loss: 0.3076722025871277
Batch 12/64 loss: 0.3141929507255554
Batch 13/64 loss: 0.3092927932739258
Batch 14/64 loss: 0.30791372060775757
Batch 15/64 loss: 0.30306196212768555
Batch 16/64 loss: 0.30840635299682617
Batch 17/64 loss: 0.3108711242675781
Batch 18/64 loss: 0.31238365173339844
Batch 19/64 loss: 0.304134726524353
Batch 20/64 loss: 0.31453561782836914
Batch 21/64 loss: 0.3062785267829895
Batch 22/64 loss: 0.31065690517425537
Batch 23/64 loss: 0.3095971345901489
Batch 24/64 loss: 0.3092382550239563
Batch 25/64 loss: 0.30748504400253296
Batch 26/64 loss: 0.31976962089538574
Batch 27/64 loss: 0.30849534273147583
Batch 28/64 loss: 0.3115401268005371
Batch 29/64 loss: 0.3079044222831726
Batch 30/64 loss: 0.3152238130569458
Batch 31/64 loss: 0.31086909770965576
Batch 32/64 loss: 0.30933356285095215
Batch 33/64 loss: 0.3111557960510254
Batch 34/64 loss: 0.307323694229126
Batch 35/64 loss: 0.3068174719810486
Batch 36/64 loss: 0.31013596057891846
Batch 37/64 loss: 0.3130519986152649
Batch 38/64 loss: 0.3106958866119385
Batch 39/64 loss: 0.30713391304016113
Batch 40/64 loss: 0.31655460596084595
Batch 41/64 loss: 0.32023316621780396
Batch 42/64 loss: 0.3169940114021301
Batch 43/64 loss: 0.31129777431488037
Batch 44/64 loss: 0.30761754512786865
Batch 45/64 loss: 0.3082796335220337
Batch 46/64 loss: 0.31875079870224
Batch 47/64 loss: 0.3032647371292114
Batch 48/64 loss: 0.3145427703857422
Batch 49/64 loss: 0.3067004680633545
Batch 50/64 loss: 0.31052887439727783
Batch 51/64 loss: 0.3152669668197632
Batch 52/64 loss: 0.3158106803894043
Batch 53/64 loss: 0.30938243865966797
Batch 54/64 loss: 0.3127795457839966
Batch 55/64 loss: 0.304813027381897
Batch 56/64 loss: 0.3058619499206543
Batch 57/64 loss: 0.3055081367492676
Batch 58/64 loss: 0.3171119689941406
Batch 59/64 loss: 0.3108142614364624
Batch 60/64 loss: 0.30574774742126465
Batch 61/64 loss: 0.31303870677948
Batch 62/64 loss: 0.31251323223114014
Batch 63/64 loss: 0.3174934387207031
Batch 64/64 loss: 0.3150695562362671
Epoch 277  Train loss: 0.31065433866837444  Val loss: 0.33098930837362495
Epoch 278
-------------------------------
Batch 1/64 loss: 0.31422698497772217
Batch 2/64 loss: 0.302980899810791
Batch 3/64 loss: 0.30696940422058105
Batch 4/64 loss: 0.30764293670654297
Batch 5/64 loss: 0.31558090448379517
Batch 6/64 loss: 0.3168354034423828
Batch 7/64 loss: 0.30911070108413696
Batch 8/64 loss: 0.3062610626220703
Batch 9/64 loss: 0.30988508462905884
Batch 10/64 loss: 0.3161277770996094
Batch 11/64 loss: 0.3101853132247925
Batch 12/64 loss: 0.3153512477874756
Batch 13/64 loss: 0.3077107071876526
Batch 14/64 loss: 0.31544727087020874
Batch 15/64 loss: 0.3087313175201416
Batch 16/64 loss: 0.3114115595817566
Batch 17/64 loss: 0.3081083297729492
Batch 18/64 loss: 0.3209802508354187
Batch 19/64 loss: 0.32120102643966675
Batch 20/64 loss: 0.30372416973114014
Batch 21/64 loss: 0.3059249520301819
Batch 22/64 loss: 0.31668591499328613
Batch 23/64 loss: 0.31064265966415405
Batch 24/64 loss: 0.31089603900909424
Batch 25/64 loss: 0.31292724609375
Batch 26/64 loss: 0.3191390037536621
Batch 27/64 loss: 0.3015122413635254
Batch 28/64 loss: 0.30510908365249634
Batch 29/64 loss: 0.305217444896698
Batch 30/64 loss: 0.30963802337646484
Batch 31/64 loss: 0.30818307399749756
Batch 32/64 loss: 0.29525846242904663
Batch 33/64 loss: 0.3111770749092102
Batch 34/64 loss: 0.3117847442626953
Batch 35/64 loss: 0.3110544681549072
Batch 36/64 loss: 0.31229186058044434
Batch 37/64 loss: 0.3185076117515564
Batch 38/64 loss: 0.3143969774246216
Batch 39/64 loss: 0.30690938234329224
Batch 40/64 loss: 0.3153679370880127
Batch 41/64 loss: 0.3114691376686096
Batch 42/64 loss: 0.3083248734474182
Batch 43/64 loss: 0.3074502944946289
Batch 44/64 loss: 0.2995985150337219
Batch 45/64 loss: 0.3080238103866577
Batch 46/64 loss: 0.3062441349029541
Batch 47/64 loss: 0.3150101900100708
Batch 48/64 loss: 0.3163212537765503
Batch 49/64 loss: 0.30259251594543457
Batch 50/64 loss: 0.3064323663711548
Batch 51/64 loss: 0.31469815969467163
Batch 52/64 loss: 0.321782648563385
Batch 53/64 loss: 0.3188999891281128
Batch 54/64 loss: 0.3230394124984741
Batch 55/64 loss: 0.3134511709213257
Batch 56/64 loss: 0.3016636371612549
Batch 57/64 loss: 0.3093528747558594
Batch 58/64 loss: 0.3159834146499634
Batch 59/64 loss: 0.32289302349090576
Batch 60/64 loss: 0.30806100368499756
Batch 61/64 loss: 0.3041467070579529
Batch 62/64 loss: 0.3107672929763794
Batch 63/64 loss: 0.3103370666503906
Batch 64/64 loss: 0.31578218936920166
Epoch 278  Train loss: 0.3109721833584355  Val loss: 0.3300532239818901
Epoch 279
-------------------------------
Batch 1/64 loss: 0.30157530307769775
Batch 2/64 loss: 0.3074270486831665
Batch 3/64 loss: 0.30979251861572266
Batch 4/64 loss: 0.3171501159667969
Batch 5/64 loss: 0.31866025924682617
Batch 6/64 loss: 0.31059980392456055
Batch 7/64 loss: 0.3048906922340393
Batch 8/64 loss: 0.3199491500854492
Batch 9/64 loss: 0.3068128228187561
Batch 10/64 loss: 0.3014678359031677
Batch 11/64 loss: 0.3079451322555542
Batch 12/64 loss: 0.3128303289413452
Batch 13/64 loss: 0.30798447132110596
Batch 14/64 loss: 0.3156559467315674
Batch 15/64 loss: 0.31369560956954956
Batch 16/64 loss: 0.3247714042663574
Batch 17/64 loss: 0.30879539251327515
Batch 18/64 loss: 0.30773067474365234
Batch 19/64 loss: 0.3081212043762207
Batch 20/64 loss: 0.3057289123535156
Batch 21/64 loss: 0.30985182523727417
Batch 22/64 loss: 0.3103245496749878
Batch 23/64 loss: 0.31556016206741333
Batch 24/64 loss: 0.3041954040527344
Batch 25/64 loss: 0.3116722106933594
Batch 26/64 loss: 0.31433188915252686
Batch 27/64 loss: 0.3146827220916748
Batch 28/64 loss: 0.30698394775390625
Batch 29/64 loss: 0.3083322048187256
Batch 30/64 loss: 0.30843621492385864
Batch 31/64 loss: 0.312641978263855
Batch 32/64 loss: 0.31299036741256714
Batch 33/64 loss: 0.31506800651550293
Batch 34/64 loss: 0.30390167236328125
Batch 35/64 loss: 0.31758469343185425
Batch 36/64 loss: 0.30852460861206055
Batch 37/64 loss: 0.3110085725784302
Batch 38/64 loss: 0.3144223690032959
Batch 39/64 loss: 0.30907142162323
Batch 40/64 loss: 0.30486953258514404
Batch 41/64 loss: 0.3103000521659851
Batch 42/64 loss: 0.3125115633010864
Batch 43/64 loss: 0.3073866367340088
Batch 44/64 loss: 0.3089456558227539
Batch 45/64 loss: 0.31343430280685425
Batch 46/64 loss: 0.3109322190284729
Batch 47/64 loss: 0.3147618770599365
Batch 48/64 loss: 0.3128349184989929
Batch 49/64 loss: 0.30818021297454834
Batch 50/64 loss: 0.30596113204956055
Batch 51/64 loss: 0.317543625831604
Batch 52/64 loss: 0.3147118091583252
Batch 53/64 loss: 0.3065003752708435
Batch 54/64 loss: 0.30637145042419434
Batch 55/64 loss: 0.3112354278564453
Batch 56/64 loss: 0.3113284111022949
Batch 57/64 loss: 0.30411458015441895
Batch 58/64 loss: 0.3147928714752197
Batch 59/64 loss: 0.310486376285553
Batch 60/64 loss: 0.31849294900894165
Batch 61/64 loss: 0.3104701638221741
Batch 62/64 loss: 0.31004834175109863
Batch 63/64 loss: 0.31200772523880005
Batch 64/64 loss: 0.3126314878463745
Epoch 279  Train loss: 0.31080572979122983  Val loss: 0.3290653003450112
Saving best model, epoch: 279
Epoch 280
-------------------------------
Batch 1/64 loss: 0.30069708824157715
Batch 2/64 loss: 0.31490832567214966
Batch 3/64 loss: 0.3064519166946411
Batch 4/64 loss: 0.3127136826515198
Batch 5/64 loss: 0.30441492795944214
Batch 6/64 loss: 0.3072993755340576
Batch 7/64 loss: 0.31030023097991943
Batch 8/64 loss: 0.3014669418334961
Batch 9/64 loss: 0.3046032190322876
Batch 10/64 loss: 0.31408727169036865
Batch 11/64 loss: 0.30914103984832764
Batch 12/64 loss: 0.3089406490325928
Batch 13/64 loss: 0.3060474395751953
Batch 14/64 loss: 0.3084172010421753
Batch 15/64 loss: 0.31164121627807617
Batch 16/64 loss: 0.3074125051498413
Batch 17/64 loss: 0.30450373888015747
Batch 18/64 loss: 0.3142150044441223
Batch 19/64 loss: 0.30927252769470215
Batch 20/64 loss: 0.31473398208618164
Batch 21/64 loss: 0.3167848587036133
Batch 22/64 loss: 0.3173883557319641
Batch 23/64 loss: 0.3151528835296631
Batch 24/64 loss: 0.3053995370864868
Batch 25/64 loss: 0.3033519983291626
Batch 26/64 loss: 0.31161582469940186
Batch 27/64 loss: 0.31461769342422485
Batch 28/64 loss: 0.32292187213897705
Batch 29/64 loss: 0.3074083924293518
Batch 30/64 loss: 0.3054482340812683
Batch 31/64 loss: 0.312649130821228
Batch 32/64 loss: 0.3079845905303955
Batch 33/64 loss: 0.30605268478393555
Batch 34/64 loss: 0.30598902702331543
Batch 35/64 loss: 0.30529314279556274
Batch 36/64 loss: 0.3137226700782776
Batch 37/64 loss: 0.30876922607421875
Batch 38/64 loss: 0.3161628246307373
Batch 39/64 loss: 0.30885183811187744
Batch 40/64 loss: 0.305292010307312
Batch 41/64 loss: 0.3104487657546997
Batch 42/64 loss: 0.3162038326263428
Batch 43/64 loss: 0.31774377822875977
Batch 44/64 loss: 0.3061336874961853
Batch 45/64 loss: 0.3068389892578125
Batch 46/64 loss: 0.3160063624382019
Batch 47/64 loss: 0.3179810643196106
Batch 48/64 loss: 0.31258344650268555
Batch 49/64 loss: 0.3030816912651062
Batch 50/64 loss: 0.3099081516265869
Batch 51/64 loss: 0.31032848358154297
Batch 52/64 loss: 0.31534141302108765
Batch 53/64 loss: 0.31529831886291504
Batch 54/64 loss: 0.3042982816696167
Batch 55/64 loss: 0.30996793508529663
Batch 56/64 loss: 0.3187057375907898
Batch 57/64 loss: 0.32044899463653564
Batch 58/64 loss: 0.30679261684417725
Batch 59/64 loss: 0.3171898126602173
Batch 60/64 loss: 0.3100193738937378
Batch 61/64 loss: 0.30038368701934814
Batch 62/64 loss: 0.306388258934021
Batch 63/64 loss: 0.31278079748153687
Batch 64/64 loss: 0.31061315536499023
Epoch 280  Train loss: 0.3102738576776841  Val loss: 0.3290734166132216
Epoch 281
-------------------------------
Batch 1/64 loss: 0.31990087032318115
Batch 2/64 loss: 0.31036627292633057
Batch 3/64 loss: 0.306654691696167
Batch 4/64 loss: 0.3123891353607178
Batch 5/64 loss: 0.312314510345459
Batch 6/64 loss: 0.3114873170852661
Batch 7/64 loss: 0.31513047218322754
Batch 8/64 loss: 0.31514161825180054
Batch 9/64 loss: 0.31309962272644043
Batch 10/64 loss: 0.3099595308303833
Batch 11/64 loss: 0.30882006883621216
Batch 12/64 loss: 0.3094468116760254
Batch 13/64 loss: 0.3071821928024292
Batch 14/64 loss: 0.30875343084335327
Batch 15/64 loss: 0.31042546033859253
Batch 16/64 loss: 0.3087778687477112
Batch 17/64 loss: 0.30554091930389404
Batch 18/64 loss: 0.3067842125892639
Batch 19/64 loss: 0.3043491840362549
Batch 20/64 loss: 0.31603705883026123
Batch 21/64 loss: 0.31272780895233154
Batch 22/64 loss: 0.30411219596862793
Batch 23/64 loss: 0.30121588706970215
Batch 24/64 loss: 0.3091537356376648
Batch 25/64 loss: 0.3055570125579834
Batch 26/64 loss: 0.31204646825790405
Batch 27/64 loss: 0.31296253204345703
Batch 28/64 loss: 0.30860573053359985
Batch 29/64 loss: 0.3160827159881592
Batch 30/64 loss: 0.31225132942199707
Batch 31/64 loss: 0.30485039949417114
Batch 32/64 loss: 0.32274025678634644
Batch 33/64 loss: 0.310096800327301
Batch 34/64 loss: 0.3105437755584717
Batch 35/64 loss: 0.3130509853363037
Batch 36/64 loss: 0.3145657777786255
Batch 37/64 loss: 0.3123530149459839
Batch 38/64 loss: 0.31287920475006104
Batch 39/64 loss: 0.3130757808685303
Batch 40/64 loss: 0.3050631284713745
Batch 41/64 loss: 0.3151475191116333
Batch 42/64 loss: 0.3071736693382263
Batch 43/64 loss: 0.3094902038574219
Batch 44/64 loss: 0.3091728687286377
Batch 45/64 loss: 0.31092506647109985
Batch 46/64 loss: 0.30907464027404785
Batch 47/64 loss: 0.30752575397491455
Batch 48/64 loss: 0.30308616161346436
Batch 49/64 loss: 0.3043098449707031
Batch 50/64 loss: 0.3171234130859375
Batch 51/64 loss: 0.30840539932250977
Batch 52/64 loss: 0.3064446449279785
Batch 53/64 loss: 0.3119131326675415
Batch 54/64 loss: 0.30143916606903076
Batch 55/64 loss: 0.3141883611679077
Batch 56/64 loss: 0.3089333772659302
Batch 57/64 loss: 0.31814855337142944
Batch 58/64 loss: 0.3114356994628906
Batch 59/64 loss: 0.3048727512359619
Batch 60/64 loss: 0.31117451190948486
Batch 61/64 loss: 0.314998984336853
Batch 62/64 loss: 0.30334585905075073
Batch 63/64 loss: 0.31199586391448975
Batch 64/64 loss: 0.31307148933410645
Epoch 281  Train loss: 0.31029999770370187  Val loss: 0.3303233993422125
Epoch 282
-------------------------------
Batch 1/64 loss: 0.32143670320510864
Batch 2/64 loss: 0.31077295541763306
Batch 3/64 loss: 0.3117419481277466
Batch 4/64 loss: 0.30561959743499756
Batch 5/64 loss: 0.308333158493042
Batch 6/64 loss: 0.31580960750579834
Batch 7/64 loss: 0.305263876914978
Batch 8/64 loss: 0.30886024236679077
Batch 9/64 loss: 0.30824482440948486
Batch 10/64 loss: 0.3086099624633789
Batch 11/64 loss: 0.3160454034805298
Batch 12/64 loss: 0.3067421317100525
Batch 13/64 loss: 0.30701005458831787
Batch 14/64 loss: 0.3162155747413635
Batch 15/64 loss: 0.3117210865020752
Batch 16/64 loss: 0.3061307668685913
Batch 17/64 loss: 0.30918657779693604
Batch 18/64 loss: 0.3126603364944458
Batch 19/64 loss: 0.3125382661819458
Batch 20/64 loss: 0.31492525339126587
Batch 21/64 loss: 0.31316083669662476
Batch 22/64 loss: 0.3186871409416199
Batch 23/64 loss: 0.30731022357940674
Batch 24/64 loss: 0.30922365188598633
Batch 25/64 loss: 0.30310726165771484
Batch 26/64 loss: 0.31385648250579834
Batch 27/64 loss: 0.31357985734939575
Batch 28/64 loss: 0.31320512294769287
Batch 29/64 loss: 0.30138397216796875
Batch 30/64 loss: 0.3154299259185791
Batch 31/64 loss: 0.32076042890548706
Batch 32/64 loss: 0.3002396821975708
Batch 33/64 loss: 0.3110848665237427
Batch 34/64 loss: 0.31217432022094727
Batch 35/64 loss: 0.303744912147522
Batch 36/64 loss: 0.30989450216293335
Batch 37/64 loss: 0.3147600293159485
Batch 38/64 loss: 0.308072566986084
Batch 39/64 loss: 0.30800318717956543
Batch 40/64 loss: 0.31006479263305664
Batch 41/64 loss: 0.3085970878601074
Batch 42/64 loss: 0.3050405979156494
Batch 43/64 loss: 0.3062458634376526
Batch 44/64 loss: 0.30955076217651367
Batch 45/64 loss: 0.3104989528656006
Batch 46/64 loss: 0.3090056777000427
Batch 47/64 loss: 0.30722856521606445
Batch 48/64 loss: 0.3086695671081543
Batch 49/64 loss: 0.3102349042892456
Batch 50/64 loss: 0.30663228034973145
Batch 51/64 loss: 0.31203359365463257
Batch 52/64 loss: 0.31445324420928955
Batch 53/64 loss: 0.3051185607910156
Batch 54/64 loss: 0.3136744499206543
Batch 55/64 loss: 0.3034154176712036
Batch 56/64 loss: 0.31433093547821045
Batch 57/64 loss: 0.3060418963432312
Batch 58/64 loss: 0.3074338436126709
Batch 59/64 loss: 0.3168659806251526
Batch 60/64 loss: 0.31295245885849
Batch 61/64 loss: 0.30219411849975586
Batch 62/64 loss: 0.3136727809906006
Batch 63/64 loss: 0.3110703229904175
Batch 64/64 loss: 0.3182697296142578
Epoch 282  Train loss: 0.31026315689086914  Val loss: 0.3293199551474188
Epoch 283
-------------------------------
Batch 1/64 loss: 0.3116271495819092
Batch 2/64 loss: 0.31609225273132324
Batch 3/64 loss: 0.3074815273284912
Batch 4/64 loss: 0.3019007444381714
Batch 5/64 loss: 0.31485891342163086
Batch 6/64 loss: 0.31269943714141846
Batch 7/64 loss: 0.306445837020874
Batch 8/64 loss: 0.3168231248855591
Batch 9/64 loss: 0.3135002851486206
Batch 10/64 loss: 0.3025658130645752
Batch 11/64 loss: 0.30135881900787354
Batch 12/64 loss: 0.30491960048675537
Batch 13/64 loss: 0.311659574508667
Batch 14/64 loss: 0.3224918842315674
Batch 15/64 loss: 0.3059488534927368
Batch 16/64 loss: 0.309292197227478
Batch 17/64 loss: 0.3167886734008789
Batch 18/64 loss: 0.3043982982635498
Batch 19/64 loss: 0.3076326847076416
Batch 20/64 loss: 0.3078343868255615
Batch 21/64 loss: 0.30869102478027344
Batch 22/64 loss: 0.30191105604171753
Batch 23/64 loss: 0.31592023372650146
Batch 24/64 loss: 0.3119276762008667
Batch 25/64 loss: 0.30991101264953613
Batch 26/64 loss: 0.3073991537094116
Batch 27/64 loss: 0.31183093786239624
Batch 28/64 loss: 0.31536179780960083
Batch 29/64 loss: 0.3196771740913391
Batch 30/64 loss: 0.3060598373413086
Batch 31/64 loss: 0.30828213691711426
Batch 32/64 loss: 0.3027459383010864
Batch 33/64 loss: 0.3126271963119507
Batch 34/64 loss: 0.30789268016815186
Batch 35/64 loss: 0.3042459487915039
Batch 36/64 loss: 0.3113269805908203
Batch 37/64 loss: 0.3075100779533386
Batch 38/64 loss: 0.3055448532104492
Batch 39/64 loss: 0.32036733627319336
Batch 40/64 loss: 0.30774128437042236
Batch 41/64 loss: 0.3128248453140259
Batch 42/64 loss: 0.3125927448272705
Batch 43/64 loss: 0.31151503324508667
Batch 44/64 loss: 0.3098623752593994
Batch 45/64 loss: 0.3181016445159912
Batch 46/64 loss: 0.3058130741119385
Batch 47/64 loss: 0.30561888217926025
Batch 48/64 loss: 0.3118659257888794
Batch 49/64 loss: 0.3111971616744995
Batch 50/64 loss: 0.3225886821746826
Batch 51/64 loss: 0.31486082077026367
Batch 52/64 loss: 0.3069918751716614
Batch 53/64 loss: 0.3194582462310791
Batch 54/64 loss: 0.30977535247802734
Batch 55/64 loss: 0.3058340549468994
Batch 56/64 loss: 0.30366069078445435
Batch 57/64 loss: 0.3079196810722351
Batch 58/64 loss: 0.30917495489120483
Batch 59/64 loss: 0.3157815933227539
Batch 60/64 loss: 0.30390697717666626
Batch 61/64 loss: 0.30819088220596313
Batch 62/64 loss: 0.30605649948120117
Batch 63/64 loss: 0.3073848485946655
Batch 64/64 loss: 0.30712491273880005
Epoch 283  Train loss: 0.3100331752907996  Val loss: 0.3290867174613926
Epoch 284
-------------------------------
Batch 1/64 loss: 0.3034903407096863
Batch 2/64 loss: 0.30456042289733887
Batch 3/64 loss: 0.306424081325531
Batch 4/64 loss: 0.3093477487564087
Batch 5/64 loss: 0.30901896953582764
Batch 6/64 loss: 0.300788938999176
Batch 7/64 loss: 0.3082811236381531
Batch 8/64 loss: 0.3066866397857666
Batch 9/64 loss: 0.3055086135864258
Batch 10/64 loss: 0.3095337748527527
Batch 11/64 loss: 0.31045061349868774
Batch 12/64 loss: 0.3054206371307373
Batch 13/64 loss: 0.30490946769714355
Batch 14/64 loss: 0.3094949722290039
Batch 15/64 loss: 0.31483960151672363
Batch 16/64 loss: 0.3128952980041504
Batch 17/64 loss: 0.30212295055389404
Batch 18/64 loss: 0.30694711208343506
Batch 19/64 loss: 0.3054642081260681
Batch 20/64 loss: 0.3098219633102417
Batch 21/64 loss: 0.31249523162841797
Batch 22/64 loss: 0.3083155155181885
Batch 23/64 loss: 0.3031921982765198
Batch 24/64 loss: 0.30631864070892334
Batch 25/64 loss: 0.31468576192855835
Batch 26/64 loss: 0.31323909759521484
Batch 27/64 loss: 0.3195638656616211
Batch 28/64 loss: 0.30207061767578125
Batch 29/64 loss: 0.3108271360397339
Batch 30/64 loss: 0.3092123866081238
Batch 31/64 loss: 0.30726200342178345
Batch 32/64 loss: 0.3097856640815735
Batch 33/64 loss: 0.31357020139694214
Batch 34/64 loss: 0.31264740228652954
Batch 35/64 loss: 0.3145928382873535
Batch 36/64 loss: 0.3076398968696594
Batch 37/64 loss: 0.30948716402053833
Batch 38/64 loss: 0.3087177872657776
Batch 39/64 loss: 0.31491148471832275
Batch 40/64 loss: 0.3046802878379822
Batch 41/64 loss: 0.31647342443466187
Batch 42/64 loss: 0.31359201669692993
Batch 43/64 loss: 0.3009376525878906
Batch 44/64 loss: 0.30933088064193726
Batch 45/64 loss: 0.31073546409606934
Batch 46/64 loss: 0.31008851528167725
Batch 47/64 loss: 0.3106337785720825
Batch 48/64 loss: 0.30993854999542236
Batch 49/64 loss: 0.31626808643341064
Batch 50/64 loss: 0.31140339374542236
Batch 51/64 loss: 0.3108842372894287
Batch 52/64 loss: 0.30520129203796387
Batch 53/64 loss: 0.31308239698410034
Batch 54/64 loss: 0.30906617641448975
Batch 55/64 loss: 0.3047882318496704
Batch 56/64 loss: 0.31452691555023193
Batch 57/64 loss: 0.3103342056274414
Batch 58/64 loss: 0.3065360188484192
Batch 59/64 loss: 0.318888783454895
Batch 60/64 loss: 0.31486237049102783
Batch 61/64 loss: 0.31189781427383423
Batch 62/64 loss: 0.31067705154418945
Batch 63/64 loss: 0.31060683727264404
Batch 64/64 loss: 0.3177502155303955
Epoch 284  Train loss: 0.309620226130766  Val loss: 0.33010614880991146
Epoch 285
-------------------------------
Batch 1/64 loss: 0.31259477138519287
Batch 2/64 loss: 0.31064844131469727
Batch 3/64 loss: 0.3102325201034546
Batch 4/64 loss: 0.3038821220397949
Batch 5/64 loss: 0.3125385046005249
Batch 6/64 loss: 0.3121088147163391
Batch 7/64 loss: 0.3095855712890625
Batch 8/64 loss: 0.3150949478149414
Batch 9/64 loss: 0.305916428565979
Batch 10/64 loss: 0.3080071210861206
Batch 11/64 loss: 0.3035316467285156
Batch 12/64 loss: 0.3104388117790222
Batch 13/64 loss: 0.31252479553222656
Batch 14/64 loss: 0.31459784507751465
Batch 15/64 loss: 0.30605947971343994
Batch 16/64 loss: 0.3187066316604614
Batch 17/64 loss: 0.3106215000152588
Batch 18/64 loss: 0.31122398376464844
Batch 19/64 loss: 0.30480533838272095
Batch 20/64 loss: 0.3073667287826538
Batch 21/64 loss: 0.29966723918914795
Batch 22/64 loss: 0.30729812383651733
Batch 23/64 loss: 0.3065159320831299
Batch 24/64 loss: 0.3056720495223999
Batch 25/64 loss: 0.3088958263397217
Batch 26/64 loss: 0.3096967935562134
Batch 27/64 loss: 0.3170562982559204
Batch 28/64 loss: 0.3028913736343384
Batch 29/64 loss: 0.30406665802001953
Batch 30/64 loss: 0.3014458417892456
Batch 31/64 loss: 0.31088030338287354
Batch 32/64 loss: 0.31236326694488525
Batch 33/64 loss: 0.3070046901702881
Batch 34/64 loss: 0.3108102083206177
Batch 35/64 loss: 0.3152307868003845
Batch 36/64 loss: 0.310260534286499
Batch 37/64 loss: 0.31102848052978516
Batch 38/64 loss: 0.3140190839767456
Batch 39/64 loss: 0.3117409944534302
Batch 40/64 loss: 0.30900776386260986
Batch 41/64 loss: 0.3094989061355591
Batch 42/64 loss: 0.3124438524246216
Batch 43/64 loss: 0.30951881408691406
Batch 44/64 loss: 0.30899256467819214
Batch 45/64 loss: 0.3114776611328125
Batch 46/64 loss: 0.30707842111587524
Batch 47/64 loss: 0.3127209544181824
Batch 48/64 loss: 0.29774534702301025
Batch 49/64 loss: 0.31465601921081543
Batch 50/64 loss: 0.3085019588470459
Batch 51/64 loss: 0.30731654167175293
Batch 52/64 loss: 0.2996763586997986
Batch 53/64 loss: 0.306249737739563
Batch 54/64 loss: 0.30478787422180176
Batch 55/64 loss: 0.3069053888320923
Batch 56/64 loss: 0.30813324451446533
Batch 57/64 loss: 0.3094888925552368
Batch 58/64 loss: 0.3161811828613281
Batch 59/64 loss: 0.32103216648101807
Batch 60/64 loss: 0.3114405870437622
Batch 61/64 loss: 0.31345832347869873
Batch 62/64 loss: 0.3161439299583435
Batch 63/64 loss: 0.3136023283004761
Batch 64/64 loss: 0.3104737401008606
Epoch 285  Train loss: 0.3095834449225781  Val loss: 0.32953806841086686
Epoch 286
-------------------------------
Batch 1/64 loss: 0.3060951232910156
Batch 2/64 loss: 0.3084215521812439
Batch 3/64 loss: 0.30401742458343506
Batch 4/64 loss: 0.3080199360847473
Batch 5/64 loss: 0.30525052547454834
Batch 6/64 loss: 0.31067848205566406
Batch 7/64 loss: 0.30656254291534424
Batch 8/64 loss: 0.3037526607513428
Batch 9/64 loss: 0.3158711791038513
Batch 10/64 loss: 0.2992168664932251
Batch 11/64 loss: 0.3136941194534302
Batch 12/64 loss: 0.31226646900177
Batch 13/64 loss: 0.3072061538696289
Batch 14/64 loss: 0.30187851190567017
Batch 15/64 loss: 0.31193220615386963
Batch 16/64 loss: 0.30895012617111206
Batch 17/64 loss: 0.3027285933494568
Batch 18/64 loss: 0.30313825607299805
Batch 19/64 loss: 0.323569118976593
Batch 20/64 loss: 0.31185925006866455
Batch 21/64 loss: 0.3147062063217163
Batch 22/64 loss: 0.3013344407081604
Batch 23/64 loss: 0.30180227756500244
Batch 24/64 loss: 0.31480884552001953
Batch 25/64 loss: 0.30230581760406494
Batch 26/64 loss: 0.31090056896209717
Batch 27/64 loss: 0.3087146282196045
Batch 28/64 loss: 0.3135443329811096
Batch 29/64 loss: 0.3046649098396301
Batch 30/64 loss: 0.3030208349227905
Batch 31/64 loss: 0.30152225494384766
Batch 32/64 loss: 0.30877941846847534
Batch 33/64 loss: 0.30904054641723633
Batch 34/64 loss: 0.31339800357818604
Batch 35/64 loss: 0.3076469898223877
Batch 36/64 loss: 0.3080231547355652
Batch 37/64 loss: 0.29991745948791504
Batch 38/64 loss: 0.3035682439804077
Batch 39/64 loss: 0.3147101402282715
Batch 40/64 loss: 0.3205992579460144
Batch 41/64 loss: 0.3076012134552002
Batch 42/64 loss: 0.31649672985076904
Batch 43/64 loss: 0.31049495935440063
Batch 44/64 loss: 0.3060467839241028
Batch 45/64 loss: 0.3143599033355713
Batch 46/64 loss: 0.30664169788360596
Batch 47/64 loss: 0.3149064779281616
Batch 48/64 loss: 0.31473207473754883
Batch 49/64 loss: 0.31020277738571167
Batch 50/64 loss: 0.3036578893661499
Batch 51/64 loss: 0.313346803188324
Batch 52/64 loss: 0.3089553117752075
Batch 53/64 loss: 0.31024086475372314
Batch 54/64 loss: 0.32489973306655884
Batch 55/64 loss: 0.29843491315841675
Batch 56/64 loss: 0.31577348709106445
Batch 57/64 loss: 0.3077206611633301
Batch 58/64 loss: 0.3084143400192261
Batch 59/64 loss: 0.31600868701934814
Batch 60/64 loss: 0.30639970302581787
Batch 61/64 loss: 0.3114253282546997
Batch 62/64 loss: 0.3145790100097656
Batch 63/64 loss: 0.30808162689208984
Batch 64/64 loss: 0.31138646602630615
Epoch 286  Train loss: 0.3091933844136257  Val loss: 0.32876596971066135
Saving best model, epoch: 286
Epoch 287
-------------------------------
Batch 1/64 loss: 0.32050585746765137
Batch 2/64 loss: 0.30821549892425537
Batch 3/64 loss: 0.30776119232177734
Batch 4/64 loss: 0.30474621057510376
Batch 5/64 loss: 0.3167961835861206
Batch 6/64 loss: 0.3074570298194885
Batch 7/64 loss: 0.3007218837738037
Batch 8/64 loss: 0.31050968170166016
Batch 9/64 loss: 0.30144745111465454
Batch 10/64 loss: 0.3117220401763916
Batch 11/64 loss: 0.30956482887268066
Batch 12/64 loss: 0.3104633092880249
Batch 13/64 loss: 0.3112243413925171
Batch 14/64 loss: 0.3087887763977051
Batch 15/64 loss: 0.31644725799560547
Batch 16/64 loss: 0.31170105934143066
Batch 17/64 loss: 0.3090326189994812
Batch 18/64 loss: 0.3129911422729492
Batch 19/64 loss: 0.30866003036499023
Batch 20/64 loss: 0.3182687759399414
Batch 21/64 loss: 0.29807114601135254
Batch 22/64 loss: 0.31339603662490845
Batch 23/64 loss: 0.3072202205657959
Batch 24/64 loss: 0.3081780672073364
Batch 25/64 loss: 0.3164570927619934
Batch 26/64 loss: 0.30973267555236816
Batch 27/64 loss: 0.3086972236633301
Batch 28/64 loss: 0.3164585828781128
Batch 29/64 loss: 0.3127225637435913
Batch 30/64 loss: 0.31068146228790283
Batch 31/64 loss: 0.3025544285774231
Batch 32/64 loss: 0.2981998324394226
Batch 33/64 loss: 0.31538915634155273
Batch 34/64 loss: 0.3151603937149048
Batch 35/64 loss: 0.30421125888824463
Batch 36/64 loss: 0.3043500781059265
Batch 37/64 loss: 0.3075782060623169
Batch 38/64 loss: 0.30680572986602783
Batch 39/64 loss: 0.31244492530822754
Batch 40/64 loss: 0.30703407526016235
Batch 41/64 loss: 0.31152909994125366
Batch 42/64 loss: 0.3003571629524231
Batch 43/64 loss: 0.30837512016296387
Batch 44/64 loss: 0.30219966173171997
Batch 45/64 loss: 0.30675649642944336
Batch 46/64 loss: 0.307436466217041
Batch 47/64 loss: 0.30806243419647217
Batch 48/64 loss: 0.3132854700088501
Batch 49/64 loss: 0.3047316074371338
Batch 50/64 loss: 0.3113480806350708
Batch 51/64 loss: 0.30445921421051025
Batch 52/64 loss: 0.31115972995758057
Batch 53/64 loss: 0.29695892333984375
Batch 54/64 loss: 0.3234822154045105
Batch 55/64 loss: 0.3137000799179077
Batch 56/64 loss: 0.3106163740158081
Batch 57/64 loss: 0.31106966733932495
Batch 58/64 loss: 0.30730700492858887
Batch 59/64 loss: 0.3102869987487793
Batch 60/64 loss: 0.3116455674171448
Batch 61/64 loss: 0.30655741691589355
Batch 62/64 loss: 0.3087456226348877
Batch 63/64 loss: 0.3037832975387573
Batch 64/64 loss: 0.3148995041847229
Epoch 287  Train loss: 0.3092140653554131  Val loss: 0.3296335362077169
Epoch 288
-------------------------------
Batch 1/64 loss: 0.3164977431297302
Batch 2/64 loss: 0.3113579750061035
Batch 3/64 loss: 0.31156617403030396
Batch 4/64 loss: 0.31368720531463623
Batch 5/64 loss: 0.3037046194076538
Batch 6/64 loss: 0.3129604458808899
Batch 7/64 loss: 0.3087794780731201
Batch 8/64 loss: 0.3045536279678345
Batch 9/64 loss: 0.3035213351249695
Batch 10/64 loss: 0.30682241916656494
Batch 11/64 loss: 0.3092418909072876
Batch 12/64 loss: 0.3054693937301636
Batch 13/64 loss: 0.30782198905944824
Batch 14/64 loss: 0.30441975593566895
Batch 15/64 loss: 0.30080997943878174
Batch 16/64 loss: 0.31289708614349365
Batch 17/64 loss: 0.30472397804260254
Batch 18/64 loss: 0.30126333236694336
Batch 19/64 loss: 0.31012582778930664
Batch 20/64 loss: 0.3170379400253296
Batch 21/64 loss: 0.31386804580688477
Batch 22/64 loss: 0.3073415160179138
Batch 23/64 loss: 0.3102620244026184
Batch 24/64 loss: 0.31057190895080566
Batch 25/64 loss: 0.3059201240539551
Batch 26/64 loss: 0.31037992238998413
Batch 27/64 loss: 0.30368757247924805
Batch 28/64 loss: 0.3079182505607605
Batch 29/64 loss: 0.30672985315322876
Batch 30/64 loss: 0.30610722303390503
Batch 31/64 loss: 0.30730462074279785
Batch 32/64 loss: 0.30860424041748047
Batch 33/64 loss: 0.3042065501213074
Batch 34/64 loss: 0.3036001920700073
Batch 35/64 loss: 0.30679965019226074
Batch 36/64 loss: 0.3063480854034424
Batch 37/64 loss: 0.3031829595565796
Batch 38/64 loss: 0.31156373023986816
Batch 39/64 loss: 0.31433558464050293
Batch 40/64 loss: 0.3198102116584778
Batch 41/64 loss: 0.3085843324661255
Batch 42/64 loss: 0.3067359924316406
Batch 43/64 loss: 0.31825685501098633
Batch 44/64 loss: 0.2985957860946655
Batch 45/64 loss: 0.31497257947921753
Batch 46/64 loss: 0.30332469940185547
Batch 47/64 loss: 0.310030996799469
Batch 48/64 loss: 0.3102109432220459
Batch 49/64 loss: 0.31262195110321045
Batch 50/64 loss: 0.314064621925354
Batch 51/64 loss: 0.30461329221725464
Batch 52/64 loss: 0.30525606870651245
Batch 53/64 loss: 0.31219667196273804
Batch 54/64 loss: 0.3121994733810425
Batch 55/64 loss: 0.3047083616256714
Batch 56/64 loss: 0.30945658683776855
Batch 57/64 loss: 0.3158707618713379
Batch 58/64 loss: 0.31424379348754883
Batch 59/64 loss: 0.30536413192749023
Batch 60/64 loss: 0.3139539957046509
Batch 61/64 loss: 0.3077254295349121
Batch 62/64 loss: 0.31021034717559814
Batch 63/64 loss: 0.3170315623283386
Batch 64/64 loss: 0.3180220127105713
Epoch 288  Train loss: 0.3090909836339016  Val loss: 0.3295743588319759
Epoch 289
-------------------------------
Batch 1/64 loss: 0.3086913824081421
Batch 2/64 loss: 0.3028707504272461
Batch 3/64 loss: 0.316280722618103
Batch 4/64 loss: 0.3095616102218628
Batch 5/64 loss: 0.31454622745513916
Batch 6/64 loss: 0.30785971879959106
Batch 7/64 loss: 0.3051184415817261
Batch 8/64 loss: 0.3206217288970947
Batch 9/64 loss: 0.3143196702003479
Batch 10/64 loss: 0.3062704801559448
Batch 11/64 loss: 0.3103594183921814
Batch 12/64 loss: 0.3044213056564331
Batch 13/64 loss: 0.3064626455307007
Batch 14/64 loss: 0.3050852417945862
Batch 15/64 loss: 0.30597686767578125
Batch 16/64 loss: 0.3081096410751343
Batch 17/64 loss: 0.308407187461853
Batch 18/64 loss: 0.3089292645454407
Batch 19/64 loss: 0.293673574924469
Batch 20/64 loss: 0.30189138650894165
Batch 21/64 loss: 0.3153277635574341
Batch 22/64 loss: 0.32022321224212646
Batch 23/64 loss: 0.30381739139556885
Batch 24/64 loss: 0.3019282817840576
Batch 25/64 loss: 0.31328409910202026
Batch 26/64 loss: 0.29718804359436035
Batch 27/64 loss: 0.30145585536956787
Batch 28/64 loss: 0.3091300129890442
Batch 29/64 loss: 0.3145500421524048
Batch 30/64 loss: 0.3154297471046448
Batch 31/64 loss: 0.31135475635528564
Batch 32/64 loss: 0.30395251512527466
Batch 33/64 loss: 0.3100392818450928
Batch 34/64 loss: 0.3035907745361328
Batch 35/64 loss: 0.30477362871170044
Batch 36/64 loss: 0.30901604890823364
Batch 37/64 loss: 0.3100395202636719
Batch 38/64 loss: 0.31715482473373413
Batch 39/64 loss: 0.30551159381866455
Batch 40/64 loss: 0.3126307725906372
Batch 41/64 loss: 0.30332982540130615
Batch 42/64 loss: 0.31110167503356934
Batch 43/64 loss: 0.3125231862068176
Batch 44/64 loss: 0.30487918853759766
Batch 45/64 loss: 0.30606013536453247
Batch 46/64 loss: 0.31032562255859375
Batch 47/64 loss: 0.30940449237823486
Batch 48/64 loss: 0.3179429769515991
Batch 49/64 loss: 0.30626893043518066
Batch 50/64 loss: 0.3031337857246399
Batch 51/64 loss: 0.30439937114715576
Batch 52/64 loss: 0.30737245082855225
Batch 53/64 loss: 0.3162628412246704
Batch 54/64 loss: 0.3054109811782837
Batch 55/64 loss: 0.3146324157714844
Batch 56/64 loss: 0.31211423873901367
Batch 57/64 loss: 0.31951606273651123
Batch 58/64 loss: 0.31144076585769653
Batch 59/64 loss: 0.30374300479888916
Batch 60/64 loss: 0.3048135042190552
Batch 61/64 loss: 0.30820661783218384
Batch 62/64 loss: 0.3043776750564575
Batch 63/64 loss: 0.31588995456695557
Batch 64/64 loss: 0.31518447399139404
Epoch 289  Train loss: 0.30885323122435926  Val loss: 0.3288089082003459
Epoch 290
-------------------------------
Batch 1/64 loss: 0.3062499761581421
Batch 2/64 loss: 0.3059293031692505
Batch 3/64 loss: 0.31643640995025635
Batch 4/64 loss: 0.30203819274902344
Batch 5/64 loss: 0.3053925037384033
Batch 6/64 loss: 0.3082159757614136
Batch 7/64 loss: 0.3063039779663086
Batch 8/64 loss: 0.30120933055877686
Batch 9/64 loss: 0.30240172147750854
Batch 10/64 loss: 0.3101106882095337
Batch 11/64 loss: 0.3039616346359253
Batch 12/64 loss: 0.29826152324676514
Batch 13/64 loss: 0.3093952536582947
Batch 14/64 loss: 0.3066585063934326
Batch 15/64 loss: 0.30452072620391846
Batch 16/64 loss: 0.3062448501586914
Batch 17/64 loss: 0.3023757338523865
Batch 18/64 loss: 0.30448687076568604
Batch 19/64 loss: 0.3075644373893738
Batch 20/64 loss: 0.3008995056152344
Batch 21/64 loss: 0.29813385009765625
Batch 22/64 loss: 0.3173614740371704
Batch 23/64 loss: 0.3033290505409241
Batch 24/64 loss: 0.30467283725738525
Batch 25/64 loss: 0.3071707487106323
Batch 26/64 loss: 0.3083242177963257
Batch 27/64 loss: 0.30962562561035156
Batch 28/64 loss: 0.3129466772079468
Batch 29/64 loss: 0.302018404006958
Batch 30/64 loss: 0.30752384662628174
Batch 31/64 loss: 0.30546116828918457
Batch 32/64 loss: 0.3096463680267334
Batch 33/64 loss: 0.31743186712265015
Batch 34/64 loss: 0.31597089767456055
Batch 35/64 loss: 0.3073219656944275
Batch 36/64 loss: 0.3119778633117676
Batch 37/64 loss: 0.30701136589050293
Batch 38/64 loss: 0.31357622146606445
Batch 39/64 loss: 0.3116055727005005
Batch 40/64 loss: 0.31849372386932373
Batch 41/64 loss: 0.3060203790664673
Batch 42/64 loss: 0.313946008682251
Batch 43/64 loss: 0.31411200761795044
Batch 44/64 loss: 0.3090428113937378
Batch 45/64 loss: 0.30800241231918335
Batch 46/64 loss: 0.3076639175415039
Batch 47/64 loss: 0.3064956068992615
Batch 48/64 loss: 0.30659979581832886
Batch 49/64 loss: 0.3102026581764221
Batch 50/64 loss: 0.31683480739593506
Batch 51/64 loss: 0.31796133518218994
Batch 52/64 loss: 0.3160300850868225
Batch 53/64 loss: 0.3110276460647583
Batch 54/64 loss: 0.3046513795852661
Batch 55/64 loss: 0.3088751435279846
Batch 56/64 loss: 0.3182187080383301
Batch 57/64 loss: 0.31098783016204834
Batch 58/64 loss: 0.31092381477355957
Batch 59/64 loss: 0.30359143018722534
Batch 60/64 loss: 0.3089935779571533
Batch 61/64 loss: 0.30528783798217773
Batch 62/64 loss: 0.3107064962387085
Batch 63/64 loss: 0.3092789649963379
Batch 64/64 loss: 0.31481432914733887
Epoch 290  Train loss: 0.30854629441803577  Val loss: 0.3291951575639731
Epoch 291
-------------------------------
Batch 1/64 loss: 0.3101952075958252
Batch 2/64 loss: 0.3029845952987671
Batch 3/64 loss: 0.3005828857421875
Batch 4/64 loss: 0.306790292263031
Batch 5/64 loss: 0.2996906042098999
Batch 6/64 loss: 0.3170166015625
Batch 7/64 loss: 0.30619537830352783
Batch 8/64 loss: 0.31317567825317383
Batch 9/64 loss: 0.2988964319229126
Batch 10/64 loss: 0.3085639476776123
Batch 11/64 loss: 0.32382750511169434
Batch 12/64 loss: 0.31706106662750244
Batch 13/64 loss: 0.31725913286209106
Batch 14/64 loss: 0.31273531913757324
Batch 15/64 loss: 0.31677931547164917
Batch 16/64 loss: 0.3036269545555115
Batch 17/64 loss: 0.31205010414123535
Batch 18/64 loss: 0.30939048528671265
Batch 19/64 loss: 0.30929386615753174
Batch 20/64 loss: 0.31241559982299805
Batch 21/64 loss: 0.3074493408203125
Batch 22/64 loss: 0.3087831735610962
Batch 23/64 loss: 0.31118929386138916
Batch 24/64 loss: 0.31043052673339844
Batch 25/64 loss: 0.3057398796081543
Batch 26/64 loss: 0.3038899898529053
Batch 27/64 loss: 0.30715906620025635
Batch 28/64 loss: 0.304484486579895
Batch 29/64 loss: 0.3081512451171875
Batch 30/64 loss: 0.31215810775756836
Batch 31/64 loss: 0.31079208850860596
Batch 32/64 loss: 0.30411505699157715
Batch 33/64 loss: 0.3135901689529419
Batch 34/64 loss: 0.30463743209838867
Batch 35/64 loss: 0.30093204975128174
Batch 36/64 loss: 0.3033280372619629
Batch 37/64 loss: 0.31389737129211426
Batch 38/64 loss: 0.3192828893661499
Batch 39/64 loss: 0.3123575448989868
Batch 40/64 loss: 0.3041267991065979
Batch 41/64 loss: 0.3123204708099365
Batch 42/64 loss: 0.30317914485931396
Batch 43/64 loss: 0.308141827583313
Batch 44/64 loss: 0.3033488392829895
Batch 45/64 loss: 0.3078666925430298
Batch 46/64 loss: 0.3109976649284363
Batch 47/64 loss: 0.3046552538871765
Batch 48/64 loss: 0.3119032382965088
Batch 49/64 loss: 0.3102495074272156
Batch 50/64 loss: 0.312741756439209
Batch 51/64 loss: 0.3125702142715454
Batch 52/64 loss: 0.3110361099243164
Batch 53/64 loss: 0.3145466446876526
Batch 54/64 loss: 0.31711024045944214
Batch 55/64 loss: 0.30562055110931396
Batch 56/64 loss: 0.3101901412010193
Batch 57/64 loss: 0.31103646755218506
Batch 58/64 loss: 0.31268399953842163
Batch 59/64 loss: 0.3051081895828247
Batch 60/64 loss: 0.314405620098114
Batch 61/64 loss: 0.307780921459198
Batch 62/64 loss: 0.30670166015625
Batch 63/64 loss: 0.30557942390441895
Batch 64/64 loss: 0.29937779903411865
Epoch 291  Train loss: 0.30916601489571965  Val loss: 0.3294748192800279
Epoch 292
-------------------------------
Batch 1/64 loss: 0.30368566513061523
Batch 2/64 loss: 0.30407118797302246
Batch 3/64 loss: 0.30839216709136963
Batch 4/64 loss: 0.3053961992263794
Batch 5/64 loss: 0.3033909797668457
Batch 6/64 loss: 0.30915504693984985
Batch 7/64 loss: 0.3062018156051636
Batch 8/64 loss: 0.31336283683776855
Batch 9/64 loss: 0.3231780529022217
Batch 10/64 loss: 0.30991798639297485
Batch 11/64 loss: 0.3088545799255371
Batch 12/64 loss: 0.3053833246231079
Batch 13/64 loss: 0.29706716537475586
Batch 14/64 loss: 0.31031131744384766
Batch 15/64 loss: 0.29912060499191284
Batch 16/64 loss: 0.3104286193847656
Batch 17/64 loss: 0.29962289333343506
Batch 18/64 loss: 0.30250978469848633
Batch 19/64 loss: 0.30812573432922363
Batch 20/64 loss: 0.31281793117523193
Batch 21/64 loss: 0.3031555414199829
Batch 22/64 loss: 0.312788188457489
Batch 23/64 loss: 0.30674058198928833
Batch 24/64 loss: 0.3068739175796509
Batch 25/64 loss: 0.3054991364479065
Batch 26/64 loss: 0.31532585620880127
Batch 27/64 loss: 0.30848801136016846
Batch 28/64 loss: 0.3035165071487427
Batch 29/64 loss: 0.3064563274383545
Batch 30/64 loss: 0.31510114669799805
Batch 31/64 loss: 0.30669140815734863
Batch 32/64 loss: 0.3074040412902832
Batch 33/64 loss: 0.3144986629486084
Batch 34/64 loss: 0.307526171207428
Batch 35/64 loss: 0.31200575828552246
Batch 36/64 loss: 0.31313055753707886
Batch 37/64 loss: 0.31384891271591187
Batch 38/64 loss: 0.3082520365715027
Batch 39/64 loss: 0.32371968030929565
Batch 40/64 loss: 0.30208349227905273
Batch 41/64 loss: 0.305883526802063
Batch 42/64 loss: 0.3136465549468994
Batch 43/64 loss: 0.30832791328430176
Batch 44/64 loss: 0.30183088779449463
Batch 45/64 loss: 0.3241494297981262
Batch 46/64 loss: 0.30590325593948364
Batch 47/64 loss: 0.3063754439353943
Batch 48/64 loss: 0.3062630295753479
Batch 49/64 loss: 0.30302178859710693
Batch 50/64 loss: 0.3067646622657776
Batch 51/64 loss: 0.31444787979125977
Batch 52/64 loss: 0.29782068729400635
Batch 53/64 loss: 0.3060481548309326
Batch 54/64 loss: 0.3016100525856018
Batch 55/64 loss: 0.314414918422699
Batch 56/64 loss: 0.3029323220252991
Batch 57/64 loss: 0.3049643039703369
Batch 58/64 loss: 0.3124734163284302
Batch 59/64 loss: 0.308992862701416
Batch 60/64 loss: 0.30752766132354736
Batch 61/64 loss: 0.309295654296875
Batch 62/64 loss: 0.31188976764678955
Batch 63/64 loss: 0.3033544421195984
Batch 64/64 loss: 0.3148765563964844
Epoch 292  Train loss: 0.3082069939258052  Val loss: 0.32892046494991917
Epoch 293
-------------------------------
Batch 1/64 loss: 0.3052877187728882
Batch 2/64 loss: 0.3065785765647888
Batch 3/64 loss: 0.3098031282424927
Batch 4/64 loss: 0.3019444942474365
Batch 5/64 loss: 0.30288100242614746
Batch 6/64 loss: 0.30381786823272705
Batch 7/64 loss: 0.30891507863998413
Batch 8/64 loss: 0.30883562564849854
Batch 9/64 loss: 0.30755341053009033
Batch 10/64 loss: 0.311043381690979
Batch 11/64 loss: 0.305397629737854
Batch 12/64 loss: 0.30721890926361084
Batch 13/64 loss: 0.30439871549606323
Batch 14/64 loss: 0.3123891353607178
Batch 15/64 loss: 0.3042987585067749
Batch 16/64 loss: 0.3066587448120117
Batch 17/64 loss: 0.3108762502670288
Batch 18/64 loss: 0.30101919174194336
Batch 19/64 loss: 0.31044715642929077
Batch 20/64 loss: 0.30433547496795654
Batch 21/64 loss: 0.3061310052871704
Batch 22/64 loss: 0.30958569049835205
Batch 23/64 loss: 0.30802011489868164
Batch 24/64 loss: 0.3044942021369934
Batch 25/64 loss: 0.31451213359832764
Batch 26/64 loss: 0.3058629631996155
Batch 27/64 loss: 0.30688178539276123
Batch 28/64 loss: 0.31277018785476685
Batch 29/64 loss: 0.29954993724823
Batch 30/64 loss: 0.30594760179519653
Batch 31/64 loss: 0.3036731481552124
Batch 32/64 loss: 0.30336618423461914
Batch 33/64 loss: 0.3118155002593994
Batch 34/64 loss: 0.32390064001083374
Batch 35/64 loss: 0.3099236488342285
Batch 36/64 loss: 0.30672121047973633
Batch 37/64 loss: 0.3154621124267578
Batch 38/64 loss: 0.3107972741127014
Batch 39/64 loss: 0.31350433826446533
Batch 40/64 loss: 0.31079626083374023
Batch 41/64 loss: 0.30905067920684814
Batch 42/64 loss: 0.308094322681427
Batch 43/64 loss: 0.3029751777648926
Batch 44/64 loss: 0.3079802989959717
Batch 45/64 loss: 0.31896793842315674
Batch 46/64 loss: 0.30255335569381714
Batch 47/64 loss: 0.3024104833602905
Batch 48/64 loss: 0.30462586879730225
Batch 49/64 loss: 0.3136329650878906
Batch 50/64 loss: 0.3146197199821472
Batch 51/64 loss: 0.3103434443473816
Batch 52/64 loss: 0.3077062964439392
Batch 53/64 loss: 0.3151731491088867
Batch 54/64 loss: 0.30789393186569214
Batch 55/64 loss: 0.3128286600112915
Batch 56/64 loss: 0.30933886766433716
Batch 57/64 loss: 0.31368523836135864
Batch 58/64 loss: 0.30460095405578613
Batch 59/64 loss: 0.29927968978881836
Batch 60/64 loss: 0.3147158622741699
Batch 61/64 loss: 0.30663353204727173
Batch 62/64 loss: 0.29907751083374023
Batch 63/64 loss: 0.302212119102478
Batch 64/64 loss: 0.3101433515548706
Epoch 293  Train loss: 0.3080537062065274  Val loss: 0.3292150059106833
Epoch 294
-------------------------------
Batch 1/64 loss: 0.30845677852630615
Batch 2/64 loss: 0.2964157462120056
Batch 3/64 loss: 0.3057892322540283
Batch 4/64 loss: 0.31722450256347656
Batch 5/64 loss: 0.30698245763778687
Batch 6/64 loss: 0.3094090223312378
Batch 7/64 loss: 0.3000071048736572
Batch 8/64 loss: 0.302958607673645
Batch 9/64 loss: 0.30359482765197754
Batch 10/64 loss: 0.31016862392425537
Batch 11/64 loss: 0.31922447681427
Batch 12/64 loss: 0.30340564250946045
Batch 13/64 loss: 0.30842864513397217
Batch 14/64 loss: 0.3104584217071533
Batch 15/64 loss: 0.29758119583129883
Batch 16/64 loss: 0.31269311904907227
Batch 17/64 loss: 0.3059554696083069
Batch 18/64 loss: 0.30941522121429443
Batch 19/64 loss: 0.3072397708892822
Batch 20/64 loss: 0.30355334281921387
Batch 21/64 loss: 0.30571621656417847
Batch 22/64 loss: 0.30375397205352783
Batch 23/64 loss: 0.3061644434928894
Batch 24/64 loss: 0.3087425231933594
Batch 25/64 loss: 0.3054962158203125
Batch 26/64 loss: 0.30761510133743286
Batch 27/64 loss: 0.30615735054016113
Batch 28/64 loss: 0.3059438467025757
Batch 29/64 loss: 0.30880075693130493
Batch 30/64 loss: 0.3070710301399231
Batch 31/64 loss: 0.3060387969017029
Batch 32/64 loss: 0.3168342113494873
Batch 33/64 loss: 0.3040335178375244
Batch 34/64 loss: 0.3067502975463867
Batch 35/64 loss: 0.31011104583740234
Batch 36/64 loss: 0.31084227561950684
Batch 37/64 loss: 0.3087503910064697
Batch 38/64 loss: 0.31126856803894043
Batch 39/64 loss: 0.2997673749923706
Batch 40/64 loss: 0.30870503187179565
Batch 41/64 loss: 0.3015449047088623
Batch 42/64 loss: 0.2996417284011841
Batch 43/64 loss: 0.30971336364746094
Batch 44/64 loss: 0.302864670753479
Batch 45/64 loss: 0.31325095891952515
Batch 46/64 loss: 0.30339860916137695
Batch 47/64 loss: 0.31130146980285645
Batch 48/64 loss: 0.305727481842041
Batch 49/64 loss: 0.30562978982925415
Batch 50/64 loss: 0.3143475651741028
Batch 51/64 loss: 0.3181755542755127
Batch 52/64 loss: 0.3120197653770447
Batch 53/64 loss: 0.31062090396881104
Batch 54/64 loss: 0.30052638053894043
Batch 55/64 loss: 0.3055042028427124
Batch 56/64 loss: 0.30261510610580444
Batch 57/64 loss: 0.3109891414642334
Batch 58/64 loss: 0.31509578227996826
Batch 59/64 loss: 0.30796074867248535
Batch 60/64 loss: 0.30696433782577515
Batch 61/64 loss: 0.3135420083999634
Batch 62/64 loss: 0.3102573752403259
Batch 63/64 loss: 0.31594300270080566
Batch 64/64 loss: 0.3088151216506958
Epoch 294  Train loss: 0.30771406070858826  Val loss: 0.33029535586891307
Epoch 295
-------------------------------
Batch 1/64 loss: 0.30263465642929077
Batch 2/64 loss: 0.3028162717819214
Batch 3/64 loss: 0.29656583070755005
Batch 4/64 loss: 0.31372714042663574
Batch 5/64 loss: 0.3100389242172241
Batch 6/64 loss: 0.3060983419418335
Batch 7/64 loss: 0.30749040842056274
Batch 8/64 loss: 0.30817049741744995
Batch 9/64 loss: 0.3126070499420166
Batch 10/64 loss: 0.3066786527633667
Batch 11/64 loss: 0.305383563041687
Batch 12/64 loss: 0.3082538843154907
Batch 13/64 loss: 0.3075343370437622
Batch 14/64 loss: 0.31301623582839966
Batch 15/64 loss: 0.31252801418304443
Batch 16/64 loss: 0.30978071689605713
Batch 17/64 loss: 0.3078194856643677
Batch 18/64 loss: 0.3039019703865051
Batch 19/64 loss: 0.30370843410491943
Batch 20/64 loss: 0.30305254459381104
Batch 21/64 loss: 0.3130316138267517
Batch 22/64 loss: 0.31360888481140137
Batch 23/64 loss: 0.30059635639190674
Batch 24/64 loss: 0.30907708406448364
Batch 25/64 loss: 0.31897616386413574
Batch 26/64 loss: 0.3021349310874939
Batch 27/64 loss: 0.3238943815231323
Batch 28/64 loss: 0.30626213550567627
Batch 29/64 loss: 0.3109360933303833
Batch 30/64 loss: 0.30990034341812134
Batch 31/64 loss: 0.30396944284439087
Batch 32/64 loss: 0.3008524179458618
Batch 33/64 loss: 0.31453096866607666
Batch 34/64 loss: 0.30797481536865234
Batch 35/64 loss: 0.30224311351776123
Batch 36/64 loss: 0.31754153966903687
Batch 37/64 loss: 0.30723387002944946
Batch 38/64 loss: 0.3051968216896057
Batch 39/64 loss: 0.3031400442123413
Batch 40/64 loss: 0.30426907539367676
Batch 41/64 loss: 0.30977773666381836
Batch 42/64 loss: 0.30638718605041504
Batch 43/64 loss: 0.3094055652618408
Batch 44/64 loss: 0.3118017315864563
Batch 45/64 loss: 0.3103097081184387
Batch 46/64 loss: 0.3086158037185669
Batch 47/64 loss: 0.3062286376953125
Batch 48/64 loss: 0.3137284517288208
Batch 49/64 loss: 0.30452626943588257
Batch 50/64 loss: 0.3113560676574707
Batch 51/64 loss: 0.30906713008880615
Batch 52/64 loss: 0.3092973828315735
Batch 53/64 loss: 0.30527377128601074
Batch 54/64 loss: 0.3082934021949768
Batch 55/64 loss: 0.30480676889419556
Batch 56/64 loss: 0.3020649552345276
Batch 57/64 loss: 0.30562126636505127
Batch 58/64 loss: 0.3061492443084717
Batch 59/64 loss: 0.3129308223724365
Batch 60/64 loss: 0.3022576570510864
Batch 61/64 loss: 0.3087393045425415
Batch 62/64 loss: 0.309758722782135
Batch 63/64 loss: 0.3024492859840393
Batch 64/64 loss: 0.3092958331108093
Epoch 295  Train loss: 0.307890130258074  Val loss: 0.32846262262449233
Saving best model, epoch: 295
Epoch 296
-------------------------------
Batch 1/64 loss: 0.2987523674964905
Batch 2/64 loss: 0.31119465827941895
Batch 3/64 loss: 0.3046680688858032
Batch 4/64 loss: 0.30419331789016724
Batch 5/64 loss: 0.3154522776603699
Batch 6/64 loss: 0.3093668222427368
Batch 7/64 loss: 0.30915069580078125
Batch 8/64 loss: 0.3049132823944092
Batch 9/64 loss: 0.30838245153427124
Batch 10/64 loss: 0.3137093782424927
Batch 11/64 loss: 0.30813777446746826
Batch 12/64 loss: 0.31175363063812256
Batch 13/64 loss: 0.30286604166030884
Batch 14/64 loss: 0.30691033601760864
Batch 15/64 loss: 0.31045740842819214
Batch 16/64 loss: 0.30796265602111816
Batch 17/64 loss: 0.31400561332702637
Batch 18/64 loss: 0.30409306287765503
Batch 19/64 loss: 0.30136340856552124
Batch 20/64 loss: 0.3002816438674927
Batch 21/64 loss: 0.3098357319831848
Batch 22/64 loss: 0.30912232398986816
Batch 23/64 loss: 0.3134273290634155
Batch 24/64 loss: 0.31570011377334595
Batch 25/64 loss: 0.3085482120513916
Batch 26/64 loss: 0.30684661865234375
Batch 27/64 loss: 0.3096867799758911
Batch 28/64 loss: 0.3072805404663086
Batch 29/64 loss: 0.3179168701171875
Batch 30/64 loss: 0.3067016005516052
Batch 31/64 loss: 0.3079245686531067
Batch 32/64 loss: 0.2983877658843994
Batch 33/64 loss: 0.30885934829711914
Batch 34/64 loss: 0.31957757472991943
Batch 35/64 loss: 0.3029400110244751
Batch 36/64 loss: 0.3072984218597412
Batch 37/64 loss: 0.3130282759666443
Batch 38/64 loss: 0.3070312738418579
Batch 39/64 loss: 0.31182777881622314
Batch 40/64 loss: 0.3040710687637329
Batch 41/64 loss: 0.3118622303009033
Batch 42/64 loss: 0.31039345264434814
Batch 43/64 loss: 0.2959606647491455
Batch 44/64 loss: 0.2970765233039856
Batch 45/64 loss: 0.31010037660598755
Batch 46/64 loss: 0.3140776753425598
Batch 47/64 loss: 0.30602049827575684
Batch 48/64 loss: 0.305472731590271
Batch 49/64 loss: 0.3068859577178955
Batch 50/64 loss: 0.3131459951400757
Batch 51/64 loss: 0.302203893661499
Batch 52/64 loss: 0.31000077724456787
Batch 53/64 loss: 0.3047405481338501
Batch 54/64 loss: 0.30818164348602295
Batch 55/64 loss: 0.2996046543121338
Batch 56/64 loss: 0.30223631858825684
Batch 57/64 loss: 0.31009525060653687
Batch 58/64 loss: 0.3041929006576538
Batch 59/64 loss: 0.31252211332321167
Batch 60/64 loss: 0.30640709400177
Batch 61/64 loss: 0.3007185459136963
Batch 62/64 loss: 0.300470769405365
Batch 63/64 loss: 0.30510300397872925
Batch 64/64 loss: 0.3072972297668457
Epoch 296  Train loss: 0.30747566503636975  Val loss: 0.3293687301812713
Epoch 297
-------------------------------
Batch 1/64 loss: 0.30554860830307007
Batch 2/64 loss: 0.3128206729888916
Batch 3/64 loss: 0.31774473190307617
Batch 4/64 loss: 0.30662673711776733
Batch 5/64 loss: 0.307353138923645
Batch 6/64 loss: 0.30480194091796875
Batch 7/64 loss: 0.3000931143760681
Batch 8/64 loss: 0.30580592155456543
Batch 9/64 loss: 0.31015968322753906
Batch 10/64 loss: 0.3093050718307495
Batch 11/64 loss: 0.30652928352355957
Batch 12/64 loss: 0.30700474977493286
Batch 13/64 loss: 0.30231428146362305
Batch 14/64 loss: 0.3116639256477356
Batch 15/64 loss: 0.31521832942962646
Batch 16/64 loss: 0.29947108030319214
Batch 17/64 loss: 0.29870355129241943
Batch 18/64 loss: 0.3114579916000366
Batch 19/64 loss: 0.3017977476119995
Batch 20/64 loss: 0.30671000480651855
Batch 21/64 loss: 0.31206274032592773
Batch 22/64 loss: 0.30397897958755493
Batch 23/64 loss: 0.30032670497894287
Batch 24/64 loss: 0.31196659803390503
Batch 25/64 loss: 0.30774879455566406
Batch 26/64 loss: 0.3149845600128174
Batch 27/64 loss: 0.31498944759368896
Batch 28/64 loss: 0.3061738610267639
Batch 29/64 loss: 0.31303679943084717
Batch 30/64 loss: 0.3000154495239258
Batch 31/64 loss: 0.3127669095993042
Batch 32/64 loss: 0.30958104133605957
Batch 33/64 loss: 0.30824029445648193
Batch 34/64 loss: 0.3006933927536011
Batch 35/64 loss: 0.3023566007614136
Batch 36/64 loss: 0.3030911087989807
Batch 37/64 loss: 0.30902135372161865
Batch 38/64 loss: 0.3029435873031616
Batch 39/64 loss: 0.3043607473373413
Batch 40/64 loss: 0.3061906099319458
Batch 41/64 loss: 0.31240689754486084
Batch 42/64 loss: 0.3059007525444031
Batch 43/64 loss: 0.31381428241729736
Batch 44/64 loss: 0.3068521022796631
Batch 45/64 loss: 0.31290435791015625
Batch 46/64 loss: 0.3161771297454834
Batch 47/64 loss: 0.3052743673324585
Batch 48/64 loss: 0.29986172914505005
Batch 49/64 loss: 0.30462437868118286
Batch 50/64 loss: 0.30966490507125854
Batch 51/64 loss: 0.3187732696533203
Batch 52/64 loss: 0.3023596405982971
Batch 53/64 loss: 0.301328182220459
Batch 54/64 loss: 0.29765576124191284
Batch 55/64 loss: 0.29957783222198486
Batch 56/64 loss: 0.30687111616134644
Batch 57/64 loss: 0.3058828115463257
Batch 58/64 loss: 0.29729777574539185
Batch 59/64 loss: 0.30736732482910156
Batch 60/64 loss: 0.30739086866378784
Batch 61/64 loss: 0.3138159513473511
Batch 62/64 loss: 0.3112334609031677
Batch 63/64 loss: 0.3014187812805176
Batch 64/64 loss: 0.29857736825942993
Epoch 297  Train loss: 0.3069497545560201  Val loss: 0.32782747225253445
Saving best model, epoch: 297
Epoch 298
-------------------------------
Batch 1/64 loss: 0.3123425245285034
Batch 2/64 loss: 0.30468523502349854
Batch 3/64 loss: 0.30036091804504395
Batch 4/64 loss: 0.30132514238357544
Batch 5/64 loss: 0.3093442916870117
Batch 6/64 loss: 0.3058735728263855
Batch 7/64 loss: 0.3058156967163086
Batch 8/64 loss: 0.2986876964569092
Batch 9/64 loss: 0.29973191022872925
Batch 10/64 loss: 0.30811554193496704
Batch 11/64 loss: 0.30599814653396606
Batch 12/64 loss: 0.3005170226097107
Batch 13/64 loss: 0.3118252754211426
Batch 14/64 loss: 0.2995181679725647
Batch 15/64 loss: 0.30241072177886963
Batch 16/64 loss: 0.3091568946838379
Batch 17/64 loss: 0.3057377338409424
Batch 18/64 loss: 0.30439597368240356
Batch 19/64 loss: 0.30374693870544434
Batch 20/64 loss: 0.30501675605773926
Batch 21/64 loss: 0.31539595127105713
Batch 22/64 loss: 0.31161636114120483
Batch 23/64 loss: 0.31381088495254517
Batch 24/64 loss: 0.30129289627075195
Batch 25/64 loss: 0.30625343322753906
Batch 26/64 loss: 0.3010801672935486
Batch 27/64 loss: 0.30018383264541626
Batch 28/64 loss: 0.31092023849487305
Batch 29/64 loss: 0.305056095123291
Batch 30/64 loss: 0.3118446469306946
Batch 31/64 loss: 0.30028796195983887
Batch 32/64 loss: 0.3028523921966553
Batch 33/64 loss: 0.30794352293014526
Batch 34/64 loss: 0.3018074631690979
Batch 35/64 loss: 0.3053182363510132
Batch 36/64 loss: 0.29859644174575806
Batch 37/64 loss: 0.30212152004241943
Batch 38/64 loss: 0.30242109298706055
Batch 39/64 loss: 0.30181264877319336
Batch 40/64 loss: 0.3052041530609131
Batch 41/64 loss: 0.30995017290115356
Batch 42/64 loss: 0.3075941801071167
Batch 43/64 loss: 0.3150268793106079
Batch 44/64 loss: 0.30411970615386963
Batch 45/64 loss: 0.31791937351226807
Batch 46/64 loss: 0.3114337921142578
Batch 47/64 loss: 0.31056272983551025
Batch 48/64 loss: 0.30905938148498535
Batch 49/64 loss: 0.3039017915725708
Batch 50/64 loss: 0.31253349781036377
Batch 51/64 loss: 0.2997710108757019
Batch 52/64 loss: 0.30444008111953735
Batch 53/64 loss: 0.3123457431793213
Batch 54/64 loss: 0.29464030265808105
Batch 55/64 loss: 0.3048158288002014
Batch 56/64 loss: 0.30723339319229126
Batch 57/64 loss: 0.308601975440979
Batch 58/64 loss: 0.3057723641395569
Batch 59/64 loss: 0.31147682666778564
Batch 60/64 loss: 0.31241750717163086
Batch 61/64 loss: 0.3137446641921997
Batch 62/64 loss: 0.31033778190612793
Batch 63/64 loss: 0.3132282495498657
Batch 64/64 loss: 0.3039765954017639
Epoch 298  Train loss: 0.3063425220695196  Val loss: 0.32784825215224955
Epoch 299
-------------------------------
Batch 1/64 loss: 0.2995792627334595
Batch 2/64 loss: 0.3011401891708374
Batch 3/64 loss: 0.3107793927192688
Batch 4/64 loss: 0.30777454376220703
Batch 5/64 loss: 0.30643200874328613
Batch 6/64 loss: 0.3149890899658203
Batch 7/64 loss: 0.305919885635376
Batch 8/64 loss: 0.3026559352874756
Batch 9/64 loss: 0.3032602071762085
Batch 10/64 loss: 0.30162739753723145
Batch 11/64 loss: 0.3051931858062744
Batch 12/64 loss: 0.3121452331542969
Batch 13/64 loss: 0.32349300384521484
Batch 14/64 loss: 0.30861198902130127
Batch 15/64 loss: 0.3031051754951477
Batch 16/64 loss: 0.3067812919616699
Batch 17/64 loss: 0.3053619861602783
Batch 18/64 loss: 0.2992434501647949
Batch 19/64 loss: 0.30739712715148926
Batch 20/64 loss: 0.3000791072845459
Batch 21/64 loss: 0.3088064193725586
Batch 22/64 loss: 0.3024998903274536
Batch 23/64 loss: 0.30462902784347534
Batch 24/64 loss: 0.3086097240447998
Batch 25/64 loss: 0.3051087260246277
Batch 26/64 loss: 0.3053234815597534
Batch 27/64 loss: 0.3015119433403015
Batch 28/64 loss: 0.3050612211227417
Batch 29/64 loss: 0.3093583583831787
Batch 30/64 loss: 0.30974292755126953
Batch 31/64 loss: 0.31101107597351074
Batch 32/64 loss: 0.3033205270767212
Batch 33/64 loss: 0.3063725233078003
Batch 34/64 loss: 0.31289350986480713
Batch 35/64 loss: 0.30201900005340576
Batch 36/64 loss: 0.30016833543777466
Batch 37/64 loss: 0.30463457107543945
Batch 38/64 loss: 0.3063727617263794
Batch 39/64 loss: 0.31232738494873047
Batch 40/64 loss: 0.3070790767669678
Batch 41/64 loss: 0.30920565128326416
Batch 42/64 loss: 0.3051518201828003
Batch 43/64 loss: 0.30694878101348877
Batch 44/64 loss: 0.30792009830474854
Batch 45/64 loss: 0.3090702295303345
Batch 46/64 loss: 0.3074495196342468
Batch 47/64 loss: 0.3152642250061035
Batch 48/64 loss: 0.311384916305542
Batch 49/64 loss: 0.3016517162322998
Batch 50/64 loss: 0.30083465576171875
Batch 51/64 loss: 0.3054494857788086
Batch 52/64 loss: 0.30677151679992676
Batch 53/64 loss: 0.30874836444854736
Batch 54/64 loss: 0.3053278923034668
Batch 55/64 loss: 0.3052818775177002
Batch 56/64 loss: 0.3024868965148926
Batch 57/64 loss: 0.3116041421890259
Batch 58/64 loss: 0.30018675327301025
Batch 59/64 loss: 0.3040490746498108
Batch 60/64 loss: 0.31477415561676025
Batch 61/64 loss: 0.3105083703994751
Batch 62/64 loss: 0.31035739183425903
Batch 63/64 loss: 0.3049139976501465
Batch 64/64 loss: 0.3083285093307495
Epoch 299  Train loss: 0.3066511037302952  Val loss: 0.3294276740542802
Epoch 300
-------------------------------
Batch 1/64 loss: 0.302273154258728
Batch 2/64 loss: 0.30424749851226807
Batch 3/64 loss: 0.30888640880584717
Batch 4/64 loss: 0.3121441602706909
Batch 5/64 loss: 0.3146408796310425
Batch 6/64 loss: 0.3027048707008362
Batch 7/64 loss: 0.31090646982192993
Batch 8/64 loss: 0.3121231198310852
Batch 9/64 loss: 0.30508291721343994
Batch 10/64 loss: 0.3051576018333435
Batch 11/64 loss: 0.3116915225982666
Batch 12/64 loss: 0.3087959289550781
Batch 13/64 loss: 0.3116254210472107
Batch 14/64 loss: 0.30102038383483887
Batch 15/64 loss: 0.30175453424453735
Batch 16/64 loss: 0.30673760175704956
Batch 17/64 loss: 0.3046104907989502
Batch 18/64 loss: 0.3167994022369385
Batch 19/64 loss: 0.3020288944244385
Batch 20/64 loss: 0.30917757749557495
Batch 21/64 loss: 0.3106353282928467
Batch 22/64 loss: 0.30213165283203125
Batch 23/64 loss: 0.2964203357696533
Batch 24/64 loss: 0.30762261152267456
Batch 25/64 loss: 0.3054112195968628
Batch 26/64 loss: 0.2990710735321045
Batch 27/64 loss: 0.3062911033630371
Batch 28/64 loss: 0.3036889433860779
Batch 29/64 loss: 0.3026493787765503
Batch 30/64 loss: 0.3101203441619873
Batch 31/64 loss: 0.29282093048095703
Batch 32/64 loss: 0.30922311544418335
Batch 33/64 loss: 0.3013545274734497
Batch 34/64 loss: 0.30899226665496826
Batch 35/64 loss: 0.30762428045272827
Batch 36/64 loss: 0.31100785732269287
Batch 37/64 loss: 0.30719733238220215
Batch 38/64 loss: 0.3071930408477783
Batch 39/64 loss: 0.3052515983581543
Batch 40/64 loss: 0.2994217276573181
Batch 41/64 loss: 0.30809980630874634
Batch 42/64 loss: 0.3076416254043579
Batch 43/64 loss: 0.3065742254257202
Batch 44/64 loss: 0.3047828674316406
Batch 45/64 loss: 0.30902838706970215
Batch 46/64 loss: 0.3114694356918335
Batch 47/64 loss: 0.31043094396591187
Batch 48/64 loss: 0.3105515241622925
Batch 49/64 loss: 0.30431056022644043
Batch 50/64 loss: 0.3106105923652649
Batch 51/64 loss: 0.30994951725006104
Batch 52/64 loss: 0.30873537063598633
Batch 53/64 loss: 0.3063116669654846
Batch 54/64 loss: 0.3060290217399597
Batch 55/64 loss: 0.31712132692337036
Batch 56/64 loss: 0.3057248592376709
Batch 57/64 loss: 0.31059885025024414
Batch 58/64 loss: 0.30460041761398315
Batch 59/64 loss: 0.3041419982910156
Batch 60/64 loss: 0.3015417456626892
Batch 61/64 loss: 0.30365729331970215
Batch 62/64 loss: 0.30590957403182983
Batch 63/64 loss: 0.3122350573539734
Batch 64/64 loss: 0.3101370334625244
Epoch 300  Train loss: 0.30681093253341374  Val loss: 0.3274778869143876
Saving best model, epoch: 300
Epoch 301
-------------------------------
Batch 1/64 loss: 0.3031587600708008
Batch 2/64 loss: 0.30965614318847656
Batch 3/64 loss: 0.31247270107269287
Batch 4/64 loss: 0.297749400138855
Batch 5/64 loss: 0.3046025037765503
Batch 6/64 loss: 0.3020470142364502
Batch 7/64 loss: 0.30483460426330566
Batch 8/64 loss: 0.30561327934265137
Batch 9/64 loss: 0.30107736587524414
Batch 10/64 loss: 0.3034602403640747
Batch 11/64 loss: 0.30726397037506104
Batch 12/64 loss: 0.3024485111236572
Batch 13/64 loss: 0.3077198266983032
Batch 14/64 loss: 0.31329208612442017
Batch 15/64 loss: 0.3047090768814087
Batch 16/64 loss: 0.30782008171081543
Batch 17/64 loss: 0.3049299120903015
Batch 18/64 loss: 0.30494505167007446
Batch 19/64 loss: 0.3083080053329468
Batch 20/64 loss: 0.29974639415740967
Batch 21/64 loss: 0.2981835603713989
Batch 22/64 loss: 0.3066309690475464
Batch 23/64 loss: 0.3029654026031494
Batch 24/64 loss: 0.3020888566970825
Batch 25/64 loss: 0.3118056058883667
Batch 26/64 loss: 0.3000824451446533
Batch 27/64 loss: 0.3000551462173462
Batch 28/64 loss: 0.30514979362487793
Batch 29/64 loss: 0.3074977993965149
Batch 30/64 loss: 0.29964137077331543
Batch 31/64 loss: 0.3021034002304077
Batch 32/64 loss: 0.30493801832199097
Batch 33/64 loss: 0.3134183883666992
Batch 34/64 loss: 0.306484580039978
Batch 35/64 loss: 0.3112834692001343
Batch 36/64 loss: 0.30825984477996826
Batch 37/64 loss: 0.3053091764450073
Batch 38/64 loss: 0.3134165406227112
Batch 39/64 loss: 0.30649471282958984
Batch 40/64 loss: 0.31324243545532227
Batch 41/64 loss: 0.3030064105987549
Batch 42/64 loss: 0.30392688512802124
Batch 43/64 loss: 0.31046974658966064
Batch 44/64 loss: 0.30489683151245117
Batch 45/64 loss: 0.31461918354034424
Batch 46/64 loss: 0.3028540015220642
Batch 47/64 loss: 0.3059064745903015
Batch 48/64 loss: 0.31251442432403564
Batch 49/64 loss: 0.30843645334243774
Batch 50/64 loss: 0.2998535633087158
Batch 51/64 loss: 0.3070613145828247
Batch 52/64 loss: 0.30509763956069946
Batch 53/64 loss: 0.3081914186477661
Batch 54/64 loss: 0.30986863374710083
Batch 55/64 loss: 0.3134709596633911
Batch 56/64 loss: 0.3087334632873535
Batch 57/64 loss: 0.3095158338546753
Batch 58/64 loss: 0.3052615523338318
Batch 59/64 loss: 0.32039517164230347
Batch 60/64 loss: 0.31026262044906616
Batch 61/64 loss: 0.3134317398071289
Batch 62/64 loss: 0.3070030212402344
Batch 63/64 loss: 0.30746257305145264
Batch 64/64 loss: 0.30857783555984497
Epoch 301  Train loss: 0.30664438803990685  Val loss: 0.3287161146242594
Epoch 302
-------------------------------
Batch 1/64 loss: 0.3061361312866211
Batch 2/64 loss: 0.3082842230796814
Batch 3/64 loss: 0.30837178230285645
Batch 4/64 loss: 0.302356481552124
Batch 5/64 loss: 0.3167288899421692
Batch 6/64 loss: 0.31127893924713135
Batch 7/64 loss: 0.3057318329811096
Batch 8/64 loss: 0.3070850372314453
Batch 9/64 loss: 0.3025888204574585
Batch 10/64 loss: 0.3092731237411499
Batch 11/64 loss: 0.321397066116333
Batch 12/64 loss: 0.3068089485168457
Batch 13/64 loss: 0.3034655451774597
Batch 14/64 loss: 0.30331265926361084
Batch 15/64 loss: 0.30596160888671875
Batch 16/64 loss: 0.31438004970550537
Batch 17/64 loss: 0.31269001960754395
Batch 18/64 loss: 0.31083303689956665
Batch 19/64 loss: 0.30748313665390015
Batch 20/64 loss: 0.306851863861084
Batch 21/64 loss: 0.2967008352279663
Batch 22/64 loss: 0.30260592699050903
Batch 23/64 loss: 0.30353283882141113
Batch 24/64 loss: 0.304220974445343
Batch 25/64 loss: 0.29876190423965454
Batch 26/64 loss: 0.3062679171562195
Batch 27/64 loss: 0.3069833517074585
Batch 28/64 loss: 0.30647581815719604
Batch 29/64 loss: 0.30504071712493896
Batch 30/64 loss: 0.30608177185058594
Batch 31/64 loss: 0.31461262702941895
Batch 32/64 loss: 0.3059402108192444
Batch 33/64 loss: 0.3029071092605591
Batch 34/64 loss: 0.3012394905090332
Batch 35/64 loss: 0.31054115295410156
Batch 36/64 loss: 0.31177735328674316
Batch 37/64 loss: 0.3071579337120056
Batch 38/64 loss: 0.3058236837387085
Batch 39/64 loss: 0.31387901306152344
Batch 40/64 loss: 0.3003963828086853
Batch 41/64 loss: 0.3023144006729126
Batch 42/64 loss: 0.29952001571655273
Batch 43/64 loss: 0.3056851625442505
Batch 44/64 loss: 0.3136674165725708
Batch 45/64 loss: 0.31370407342910767
Batch 46/64 loss: 0.3010479211807251
Batch 47/64 loss: 0.3047386407852173
Batch 48/64 loss: 0.3054748773574829
Batch 49/64 loss: 0.3052879571914673
Batch 50/64 loss: 0.30162304639816284
Batch 51/64 loss: 0.3053440451622009
Batch 52/64 loss: 0.30925607681274414
Batch 53/64 loss: 0.3056778907775879
Batch 54/64 loss: 0.3121081590652466
Batch 55/64 loss: 0.3052956461906433
Batch 56/64 loss: 0.3021475672721863
Batch 57/64 loss: 0.3087054491043091
Batch 58/64 loss: 0.3060452938079834
Batch 59/64 loss: 0.30496764183044434
Batch 60/64 loss: 0.30232954025268555
Batch 61/64 loss: 0.3108944892883301
Batch 62/64 loss: 0.3011907935142517
Batch 63/64 loss: 0.3025031089782715
Batch 64/64 loss: 0.30324089527130127
Epoch 302  Train loss: 0.3064929583493401  Val loss: 0.3284542259481764
Epoch 303
-------------------------------
Batch 1/64 loss: 0.30306559801101685
Batch 2/64 loss: 0.3070796728134155
Batch 3/64 loss: 0.29956966638565063
Batch 4/64 loss: 0.296744704246521
Batch 5/64 loss: 0.3082770109176636
Batch 6/64 loss: 0.30590999126434326
Batch 7/64 loss: 0.30202603340148926
Batch 8/64 loss: 0.31247735023498535
Batch 9/64 loss: 0.30494195222854614
Batch 10/64 loss: 0.30440330505371094
Batch 11/64 loss: 0.3017774820327759
Batch 12/64 loss: 0.29996931552886963
Batch 13/64 loss: 0.30449533462524414
Batch 14/64 loss: 0.29927825927734375
Batch 15/64 loss: 0.2993285059928894
Batch 16/64 loss: 0.30897706747055054
Batch 17/64 loss: 0.30143052339553833
Batch 18/64 loss: 0.3037511110305786
Batch 19/64 loss: 0.30945074558258057
Batch 20/64 loss: 0.30348873138427734
Batch 21/64 loss: 0.30384910106658936
Batch 22/64 loss: 0.3172018527984619
Batch 23/64 loss: 0.30617010593414307
Batch 24/64 loss: 0.3060078024864197
Batch 25/64 loss: 0.30878007411956787
Batch 26/64 loss: 0.30562853813171387
Batch 27/64 loss: 0.3036308288574219
Batch 28/64 loss: 0.31227540969848633
Batch 29/64 loss: 0.307880699634552
Batch 30/64 loss: 0.30217164754867554
Batch 31/64 loss: 0.304355263710022
Batch 32/64 loss: 0.31798869371414185
Batch 33/64 loss: 0.3167164921760559
Batch 34/64 loss: 0.3006535768508911
Batch 35/64 loss: 0.30133605003356934
Batch 36/64 loss: 0.3068380355834961
Batch 37/64 loss: 0.30602192878723145
Batch 38/64 loss: 0.31171298027038574
Batch 39/64 loss: 0.3071017265319824
Batch 40/64 loss: 0.3022693395614624
Batch 41/64 loss: 0.3085200786590576
Batch 42/64 loss: 0.3157660961151123
Batch 43/64 loss: 0.30886995792388916
Batch 44/64 loss: 0.3077317476272583
Batch 45/64 loss: 0.30210012197494507
Batch 46/64 loss: 0.30331718921661377
Batch 47/64 loss: 0.2992713451385498
Batch 48/64 loss: 0.3044157028198242
Batch 49/64 loss: 0.30316072702407837
Batch 50/64 loss: 0.30758172273635864
Batch 51/64 loss: 0.2982509732246399
Batch 52/64 loss: 0.3150482177734375
Batch 53/64 loss: 0.3075885772705078
Batch 54/64 loss: 0.3105357885360718
Batch 55/64 loss: 0.3082161545753479
Batch 56/64 loss: 0.3013482689857483
Batch 57/64 loss: 0.3166123032569885
Batch 58/64 loss: 0.3138272762298584
Batch 59/64 loss: 0.3110160827636719
Batch 60/64 loss: 0.30529189109802246
Batch 61/64 loss: 0.3104616403579712
Batch 62/64 loss: 0.31397223472595215
Batch 63/64 loss: 0.30804628133773804
Batch 64/64 loss: 0.3080935478210449
Epoch 303  Train loss: 0.3064635772331088  Val loss: 0.32940209772168977
Epoch 304
-------------------------------
Batch 1/64 loss: 0.31042301654815674
Batch 2/64 loss: 0.30639922618865967
Batch 3/64 loss: 0.3020048141479492
Batch 4/64 loss: 0.3078201413154602
Batch 5/64 loss: 0.30981481075286865
Batch 6/64 loss: 0.31149131059646606
Batch 7/64 loss: 0.303433895111084
Batch 8/64 loss: 0.302851140499115
Batch 9/64 loss: 0.3027614951133728
Batch 10/64 loss: 0.29791927337646484
Batch 11/64 loss: 0.3095821142196655
Batch 12/64 loss: 0.3143165707588196
Batch 13/64 loss: 0.30277693271636963
Batch 14/64 loss: 0.30510127544403076
Batch 15/64 loss: 0.30230748653411865
Batch 16/64 loss: 0.30014026165008545
Batch 17/64 loss: 0.3111528158187866
Batch 18/64 loss: 0.30381709337234497
Batch 19/64 loss: 0.30208534002304077
Batch 20/64 loss: 0.30009883642196655
Batch 21/64 loss: 0.311210036277771
Batch 22/64 loss: 0.3035014867782593
Batch 23/64 loss: 0.30129069089889526
Batch 24/64 loss: 0.302746057510376
Batch 25/64 loss: 0.3017219305038452
Batch 26/64 loss: 0.30455344915390015
Batch 27/64 loss: 0.3067101240158081
Batch 28/64 loss: 0.3072474002838135
Batch 29/64 loss: 0.30314481258392334
Batch 30/64 loss: 0.2983744740486145
Batch 31/64 loss: 0.304130494594574
Batch 32/64 loss: 0.31008708477020264
Batch 33/64 loss: 0.302587628364563
Batch 34/64 loss: 0.3094604015350342
Batch 35/64 loss: 0.3069877028465271
Batch 36/64 loss: 0.2973676919937134
Batch 37/64 loss: 0.30811166763305664
Batch 38/64 loss: 0.3109896779060364
Batch 39/64 loss: 0.3198537230491638
Batch 40/64 loss: 0.30405235290527344
Batch 41/64 loss: 0.3076673746109009
Batch 42/64 loss: 0.31116676330566406
Batch 43/64 loss: 0.3063913583755493
Batch 44/64 loss: 0.29433512687683105
Batch 45/64 loss: 0.2963979244232178
Batch 46/64 loss: 0.30875563621520996
Batch 47/64 loss: 0.30415135622024536
Batch 48/64 loss: 0.304875910282135
Batch 49/64 loss: 0.311437726020813
Batch 50/64 loss: 0.32115066051483154
Batch 51/64 loss: 0.3005008101463318
Batch 52/64 loss: 0.3049800395965576
Batch 53/64 loss: 0.3089054822921753
Batch 54/64 loss: 0.31743836402893066
Batch 55/64 loss: 0.3193548321723938
Batch 56/64 loss: 0.30557167530059814
Batch 57/64 loss: 0.2980143427848816
Batch 58/64 loss: 0.3045489192008972
Batch 59/64 loss: 0.3020642399787903
Batch 60/64 loss: 0.3112518787384033
Batch 61/64 loss: 0.3014855980873108
Batch 62/64 loss: 0.31404727697372437
Batch 63/64 loss: 0.3115333318710327
Batch 64/64 loss: 0.3071894645690918
Epoch 304  Train loss: 0.3061465955248066  Val loss: 0.32897839472465906
Epoch 305
-------------------------------
Batch 1/64 loss: 0.3023015260696411
Batch 2/64 loss: 0.30105340480804443
Batch 3/64 loss: 0.30619633197784424
Batch 4/64 loss: 0.31391268968582153
Batch 5/64 loss: 0.3104485273361206
Batch 6/64 loss: 0.3101661205291748
Batch 7/64 loss: 0.30100953578948975
Batch 8/64 loss: 0.3058115839958191
Batch 9/64 loss: 0.3090583086013794
Batch 10/64 loss: 0.30617403984069824
Batch 11/64 loss: 0.2964153289794922
Batch 12/64 loss: 0.2959039807319641
Batch 13/64 loss: 0.3040938377380371
Batch 14/64 loss: 0.3068549633026123
Batch 15/64 loss: 0.30223602056503296
Batch 16/64 loss: 0.3108198642730713
Batch 17/64 loss: 0.301446795463562
Batch 18/64 loss: 0.30731964111328125
Batch 19/64 loss: 0.30431532859802246
Batch 20/64 loss: 0.2987489104270935
Batch 21/64 loss: 0.30866777896881104
Batch 22/64 loss: 0.30767810344696045
Batch 23/64 loss: 0.29651975631713867
Batch 24/64 loss: 0.30289751291275024
Batch 25/64 loss: 0.307314395904541
Batch 26/64 loss: 0.3023883104324341
Batch 27/64 loss: 0.3120459318161011
Batch 28/64 loss: 0.2992773652076721
Batch 29/64 loss: 0.2954775094985962
Batch 30/64 loss: 0.3105820417404175
Batch 31/64 loss: 0.3081795573234558
Batch 32/64 loss: 0.30815160274505615
Batch 33/64 loss: 0.3100329637527466
Batch 34/64 loss: 0.29939424991607666
Batch 35/64 loss: 0.30899477005004883
Batch 36/64 loss: 0.29710376262664795
Batch 37/64 loss: 0.3077552318572998
Batch 38/64 loss: 0.30861830711364746
Batch 39/64 loss: 0.30839502811431885
Batch 40/64 loss: 0.29967784881591797
Batch 41/64 loss: 0.3074779510498047
Batch 42/64 loss: 0.3051266670227051
Batch 43/64 loss: 0.30511540174484253
Batch 44/64 loss: 0.3067045211791992
Batch 45/64 loss: 0.30181121826171875
Batch 46/64 loss: 0.31684184074401855
Batch 47/64 loss: 0.2942299246788025
Batch 48/64 loss: 0.309648334980011
Batch 49/64 loss: 0.3086615800857544
Batch 50/64 loss: 0.30654847621917725
Batch 51/64 loss: 0.3053232431411743
Batch 52/64 loss: 0.31318199634552
Batch 53/64 loss: 0.3118218183517456
Batch 54/64 loss: 0.30201297998428345
Batch 55/64 loss: 0.3074822425842285
Batch 56/64 loss: 0.30636078119277954
Batch 57/64 loss: 0.30209672451019287
Batch 58/64 loss: 0.3087790012359619
Batch 59/64 loss: 0.30883824825286865
Batch 60/64 loss: 0.3041982650756836
Batch 61/64 loss: 0.31183624267578125
Batch 62/64 loss: 0.3066500425338745
Batch 63/64 loss: 0.3099548816680908
Batch 64/64 loss: 0.3204672932624817
Epoch 305  Train loss: 0.3057959470094419  Val loss: 0.32900627023985296
Epoch 306
-------------------------------
Batch 1/64 loss: 0.31337887048721313
Batch 2/64 loss: 0.30719077587127686
Batch 3/64 loss: 0.29967111349105835
Batch 4/64 loss: 0.30597925186157227
Batch 5/64 loss: 0.30151158571243286
Batch 6/64 loss: 0.3151662349700928
Batch 7/64 loss: 0.31182777881622314
Batch 8/64 loss: 0.29564064741134644
Batch 9/64 loss: 0.30972516536712646
Batch 10/64 loss: 0.30506062507629395
Batch 11/64 loss: 0.30183476209640503
Batch 12/64 loss: 0.2979910373687744
Batch 13/64 loss: 0.306296169757843
Batch 14/64 loss: 0.3059145212173462
Batch 15/64 loss: 0.2941545844078064
Batch 16/64 loss: 0.3016871213912964
Batch 17/64 loss: 0.30294084548950195
Batch 18/64 loss: 0.30363404750823975
Batch 19/64 loss: 0.3059537410736084
Batch 20/64 loss: 0.3021007776260376
Batch 21/64 loss: 0.30770379304885864
Batch 22/64 loss: 0.3071925640106201
Batch 23/64 loss: 0.31906652450561523
Batch 24/64 loss: 0.3151184320449829
Batch 25/64 loss: 0.30366504192352295
Batch 26/64 loss: 0.3076398968696594
Batch 27/64 loss: 0.3104492425918579
Batch 28/64 loss: 0.30591583251953125
Batch 29/64 loss: 0.298062264919281
Batch 30/64 loss: 0.3145303726196289
Batch 31/64 loss: 0.307370126247406
Batch 32/64 loss: 0.3090095520019531
Batch 33/64 loss: 0.3090648651123047
Batch 34/64 loss: 0.3038492202758789
Batch 35/64 loss: 0.2997172474861145
Batch 36/64 loss: 0.3036193251609802
Batch 37/64 loss: 0.31218189001083374
Batch 38/64 loss: 0.30523842573165894
Batch 39/64 loss: 0.31243324279785156
Batch 40/64 loss: 0.3034716844558716
Batch 41/64 loss: 0.3054147958755493
Batch 42/64 loss: 0.3026832342147827
Batch 43/64 loss: 0.3043220043182373
Batch 44/64 loss: 0.305425763130188
Batch 45/64 loss: 0.30740606784820557
Batch 46/64 loss: 0.306148886680603
Batch 47/64 loss: 0.30851686000823975
Batch 48/64 loss: 0.3181806802749634
Batch 49/64 loss: 0.3005937337875366
Batch 50/64 loss: 0.3090040683746338
Batch 51/64 loss: 0.3023090362548828
Batch 52/64 loss: 0.29617923498153687
Batch 53/64 loss: 0.30499517917633057
Batch 54/64 loss: 0.308843731880188
Batch 55/64 loss: 0.2997598648071289
Batch 56/64 loss: 0.30562400817871094
Batch 57/64 loss: 0.3048432469367981
Batch 58/64 loss: 0.3014320135116577
Batch 59/64 loss: 0.30728936195373535
Batch 60/64 loss: 0.3038285970687866
Batch 61/64 loss: 0.3097347021102905
Batch 62/64 loss: 0.29791200160980225
Batch 63/64 loss: 0.3089141845703125
Batch 64/64 loss: 0.30228984355926514
Epoch 306  Train loss: 0.30571039751464246  Val loss: 0.32829193069353135
Epoch 307
-------------------------------
Batch 1/64 loss: 0.3091277480125427
Batch 2/64 loss: 0.3019247055053711
Batch 3/64 loss: 0.30243629217147827
Batch 4/64 loss: 0.30793750286102295
Batch 5/64 loss: 0.3032299280166626
Batch 6/64 loss: 0.3052237629890442
Batch 7/64 loss: 0.31949931383132935
Batch 8/64 loss: 0.3069719076156616
Batch 9/64 loss: 0.3138542175292969
Batch 10/64 loss: 0.30004793405532837
Batch 11/64 loss: 0.31401216983795166
Batch 12/64 loss: 0.31288957595825195
Batch 13/64 loss: 0.3151259422302246
Batch 14/64 loss: 0.30473363399505615
Batch 15/64 loss: 0.29814523458480835
Batch 16/64 loss: 0.303242027759552
Batch 17/64 loss: 0.30580395460128784
Batch 18/64 loss: 0.3029146194458008
Batch 19/64 loss: 0.30362212657928467
Batch 20/64 loss: 0.306862473487854
Batch 21/64 loss: 0.3022426962852478
Batch 22/64 loss: 0.2987528443336487
Batch 23/64 loss: 0.31105077266693115
Batch 24/64 loss: 0.29760217666625977
Batch 25/64 loss: 0.30236053466796875
Batch 26/64 loss: 0.31237339973449707
Batch 27/64 loss: 0.2998398542404175
Batch 28/64 loss: 0.3111242651939392
Batch 29/64 loss: 0.30869799852371216
Batch 30/64 loss: 0.3112528920173645
Batch 31/64 loss: 0.3080008029937744
Batch 32/64 loss: 0.30329036712646484
Batch 33/64 loss: 0.2994650602340698
Batch 34/64 loss: 0.29881513118743896
Batch 35/64 loss: 0.30276918411254883
Batch 36/64 loss: 0.308596670627594
Batch 37/64 loss: 0.3111063241958618
Batch 38/64 loss: 0.2993013262748718
Batch 39/64 loss: 0.2983124256134033
Batch 40/64 loss: 0.313456654548645
Batch 41/64 loss: 0.3031769394874573
Batch 42/64 loss: 0.30564409494400024
Batch 43/64 loss: 0.3032674789428711
Batch 44/64 loss: 0.3053162097930908
Batch 45/64 loss: 0.31068384647369385
Batch 46/64 loss: 0.2933403253555298
Batch 47/64 loss: 0.29994869232177734
Batch 48/64 loss: 0.3063540458679199
Batch 49/64 loss: 0.304337739944458
Batch 50/64 loss: 0.29969799518585205
Batch 51/64 loss: 0.30992454290390015
Batch 52/64 loss: 0.3173065781593323
Batch 53/64 loss: 0.3022977113723755
Batch 54/64 loss: 0.3100179433822632
Batch 55/64 loss: 0.30164992809295654
Batch 56/64 loss: 0.3105660080909729
Batch 57/64 loss: 0.3012515902519226
Batch 58/64 loss: 0.2989261746406555
Batch 59/64 loss: 0.2992056608200073
Batch 60/64 loss: 0.30759143829345703
Batch 61/64 loss: 0.31039756536483765
Batch 62/64 loss: 0.3055729866027832
Batch 63/64 loss: 0.3097105622291565
Batch 64/64 loss: 0.30665111541748047
Epoch 307  Train loss: 0.3056029936846565  Val loss: 0.32778029753170473
Epoch 308
-------------------------------
Batch 1/64 loss: 0.3040207624435425
Batch 2/64 loss: 0.3133309483528137
Batch 3/64 loss: 0.31101834774017334
Batch 4/64 loss: 0.3126298189163208
Batch 5/64 loss: 0.3029513359069824
Batch 6/64 loss: 0.30497002601623535
Batch 7/64 loss: 0.30363380908966064
Batch 8/64 loss: 0.3110743761062622
Batch 9/64 loss: 0.3175930380821228
Batch 10/64 loss: 0.29670077562332153
Batch 11/64 loss: 0.3068693280220032
Batch 12/64 loss: 0.3097180128097534
Batch 13/64 loss: 0.30188703536987305
Batch 14/64 loss: 0.3008540868759155
Batch 15/64 loss: 0.3047330975532532
Batch 16/64 loss: 0.3067052960395813
Batch 17/64 loss: 0.305355966091156
Batch 18/64 loss: 0.3001672029495239
Batch 19/64 loss: 0.30576324462890625
Batch 20/64 loss: 0.3066941499710083
Batch 21/64 loss: 0.30420219898223877
Batch 22/64 loss: 0.2946964502334595
Batch 23/64 loss: 0.30480319261550903
Batch 24/64 loss: 0.3102949857711792
Batch 25/64 loss: 0.3115454912185669
Batch 26/64 loss: 0.29981309175491333
Batch 27/64 loss: 0.30574095249176025
Batch 28/64 loss: 0.30237460136413574
Batch 29/64 loss: 0.304354190826416
Batch 30/64 loss: 0.30726754665374756
Batch 31/64 loss: 0.30150294303894043
Batch 32/64 loss: 0.30551064014434814
Batch 33/64 loss: 0.30737197399139404
Batch 34/64 loss: 0.3025897741317749
Batch 35/64 loss: 0.3004946708679199
Batch 36/64 loss: 0.31138312816619873
Batch 37/64 loss: 0.30789124965667725
Batch 38/64 loss: 0.30714917182922363
Batch 39/64 loss: 0.30517733097076416
Batch 40/64 loss: 0.30365490913391113
Batch 41/64 loss: 0.3009185791015625
Batch 42/64 loss: 0.31533896923065186
Batch 43/64 loss: 0.2951653003692627
Batch 44/64 loss: 0.3116062879562378
Batch 45/64 loss: 0.3105398416519165
Batch 46/64 loss: 0.3055359721183777
Batch 47/64 loss: 0.30652403831481934
Batch 48/64 loss: 0.29769301414489746
Batch 49/64 loss: 0.3047110438346863
Batch 50/64 loss: 0.30549776554107666
Batch 51/64 loss: 0.30275100469589233
Batch 52/64 loss: 0.30619728565216064
Batch 53/64 loss: 0.31125688552856445
Batch 54/64 loss: 0.31012141704559326
Batch 55/64 loss: 0.3004004955291748
Batch 56/64 loss: 0.3075934052467346
Batch 57/64 loss: 0.3063454031944275
Batch 58/64 loss: 0.3099905252456665
Batch 59/64 loss: 0.3082273006439209
Batch 60/64 loss: 0.3094825744628906
Batch 61/64 loss: 0.30961501598358154
Batch 62/64 loss: 0.30855900049209595
Batch 63/64 loss: 0.3004670739173889
Batch 64/64 loss: 0.3117307424545288
Epoch 308  Train loss: 0.3059266730850818  Val loss: 0.32819091474887024
Epoch 309
-------------------------------
Batch 1/64 loss: 0.3022960424423218
Batch 2/64 loss: 0.30076271295547485
Batch 3/64 loss: 0.30370795726776123
Batch 4/64 loss: 0.30598676204681396
Batch 5/64 loss: 0.30591464042663574
Batch 6/64 loss: 0.3063591718673706
Batch 7/64 loss: 0.3104439973831177
Batch 8/64 loss: 0.30553674697875977
Batch 9/64 loss: 0.30228495597839355
Batch 10/64 loss: 0.302221417427063
Batch 11/64 loss: 0.3023492097854614
Batch 12/64 loss: 0.30176103115081787
Batch 13/64 loss: 0.30235856771469116
Batch 14/64 loss: 0.3049699068069458
Batch 15/64 loss: 0.30446285009384155
Batch 16/64 loss: 0.3070176839828491
Batch 17/64 loss: 0.29688239097595215
Batch 18/64 loss: 0.3030824065208435
Batch 19/64 loss: 0.3075082302093506
Batch 20/64 loss: 0.3099168539047241
Batch 21/64 loss: 0.3110257387161255
Batch 22/64 loss: 0.3008202910423279
Batch 23/64 loss: 0.30215752124786377
Batch 24/64 loss: 0.30374598503112793
Batch 25/64 loss: 0.30214595794677734
Batch 26/64 loss: 0.3099571466445923
Batch 27/64 loss: 0.29850590229034424
Batch 28/64 loss: 0.30046701431274414
Batch 29/64 loss: 0.31367528438568115
Batch 30/64 loss: 0.3093754053115845
Batch 31/64 loss: 0.31644731760025024
Batch 32/64 loss: 0.31963807344436646
Batch 33/64 loss: 0.3016662001609802
Batch 34/64 loss: 0.30010104179382324
Batch 35/64 loss: 0.30826228857040405
Batch 36/64 loss: 0.3042488098144531
Batch 37/64 loss: 0.2990034818649292
Batch 38/64 loss: 0.3080267906188965
Batch 39/64 loss: 0.3031070828437805
Batch 40/64 loss: 0.30885374546051025
Batch 41/64 loss: 0.30597221851348877
Batch 42/64 loss: 0.3073413372039795
Batch 43/64 loss: 0.30115097761154175
Batch 44/64 loss: 0.3118259906768799
Batch 45/64 loss: 0.3051607012748718
Batch 46/64 loss: 0.30003678798675537
Batch 47/64 loss: 0.3091212511062622
Batch 48/64 loss: 0.3070060610771179
Batch 49/64 loss: 0.30030250549316406
Batch 50/64 loss: 0.30197083950042725
Batch 51/64 loss: 0.2978098392486572
Batch 52/64 loss: 0.30899834632873535
Batch 53/64 loss: 0.3082304000854492
Batch 54/64 loss: 0.3035362958908081
Batch 55/64 loss: 0.3084544539451599
Batch 56/64 loss: 0.3078014850616455
Batch 57/64 loss: 0.3011801242828369
Batch 58/64 loss: 0.306954026222229
Batch 59/64 loss: 0.3013378381729126
Batch 60/64 loss: 0.3113834261894226
Batch 61/64 loss: 0.3030901551246643
Batch 62/64 loss: 0.3142639398574829
Batch 63/64 loss: 0.30792486667633057
Batch 64/64 loss: 0.30896997451782227
Epoch 309  Train loss: 0.3054060543284697  Val loss: 0.3279640959300536
Epoch 310
-------------------------------
Batch 1/64 loss: 0.31097686290740967
Batch 2/64 loss: 0.29688167572021484
Batch 3/64 loss: 0.3058253526687622
Batch 4/64 loss: 0.3023858666419983
Batch 5/64 loss: 0.2970161437988281
Batch 6/64 loss: 0.3030388355255127
Batch 7/64 loss: 0.316653311252594
Batch 8/64 loss: 0.30661582946777344
Batch 9/64 loss: 0.3051333427429199
Batch 10/64 loss: 0.3041818141937256
Batch 11/64 loss: 0.30315113067626953
Batch 12/64 loss: 0.30174171924591064
Batch 13/64 loss: 0.3022840619087219
Batch 14/64 loss: 0.29832780361175537
Batch 15/64 loss: 0.3063507080078125
Batch 16/64 loss: 0.30350279808044434
Batch 17/64 loss: 0.3132163882255554
Batch 18/64 loss: 0.3022884726524353
Batch 19/64 loss: 0.3092326521873474
Batch 20/64 loss: 0.3020561933517456
Batch 21/64 loss: 0.30797433853149414
Batch 22/64 loss: 0.3005675673484802
Batch 23/64 loss: 0.31077128648757935
Batch 24/64 loss: 0.30847597122192383
Batch 25/64 loss: 0.3086152672767639
Batch 26/64 loss: 0.3053011894226074
Batch 27/64 loss: 0.30877959728240967
Batch 28/64 loss: 0.30481261014938354
Batch 29/64 loss: 0.31010109186172485
Batch 30/64 loss: 0.30342066287994385
Batch 31/64 loss: 0.30208390951156616
Batch 32/64 loss: 0.30852437019348145
Batch 33/64 loss: 0.30123448371887207
Batch 34/64 loss: 0.30382275581359863
Batch 35/64 loss: 0.30714917182922363
Batch 36/64 loss: 0.31262314319610596
Batch 37/64 loss: 0.31031501293182373
Batch 38/64 loss: 0.31188535690307617
Batch 39/64 loss: 0.30535823106765747
Batch 40/64 loss: 0.30336809158325195
Batch 41/64 loss: 0.31495869159698486
Batch 42/64 loss: 0.31554114818573
Batch 43/64 loss: 0.2945667505264282
Batch 44/64 loss: 0.29597413539886475
Batch 45/64 loss: 0.3104758858680725
Batch 46/64 loss: 0.30711567401885986
Batch 47/64 loss: 0.3068934679031372
Batch 48/64 loss: 0.3028733730316162
Batch 49/64 loss: 0.3069561719894409
Batch 50/64 loss: 0.3141367435455322
Batch 51/64 loss: 0.30452775955200195
Batch 52/64 loss: 0.3032761812210083
Batch 53/64 loss: 0.29709166288375854
Batch 54/64 loss: 0.29574036598205566
Batch 55/64 loss: 0.31558287143707275
Batch 56/64 loss: 0.30403101444244385
Batch 57/64 loss: 0.3046450614929199
Batch 58/64 loss: 0.3080930709838867
Batch 59/64 loss: 0.30614548921585083
Batch 60/64 loss: 0.3051832914352417
Batch 61/64 loss: 0.3038327693939209
Batch 62/64 loss: 0.2982766032218933
Batch 63/64 loss: 0.2958184480667114
Batch 64/64 loss: 0.29194629192352295
Epoch 310  Train loss: 0.30520378701827106  Val loss: 0.3288294269456896
Epoch 311
-------------------------------
Batch 1/64 loss: 0.3026975989341736
Batch 2/64 loss: 0.3026167154312134
Batch 3/64 loss: 0.3020161986351013
Batch 4/64 loss: 0.2977169156074524
Batch 5/64 loss: 0.3015843629837036
Batch 6/64 loss: 0.30144286155700684
Batch 7/64 loss: 0.3057745695114136
Batch 8/64 loss: 0.3062748908996582
Batch 9/64 loss: 0.30486780405044556
Batch 10/64 loss: 0.2929331064224243
Batch 11/64 loss: 0.3064897656440735
Batch 12/64 loss: 0.30981898307800293
Batch 13/64 loss: 0.3018885850906372
Batch 14/64 loss: 0.30573976039886475
Batch 15/64 loss: 0.31079888343811035
Batch 16/64 loss: 0.314563512802124
Batch 17/64 loss: 0.30178701877593994
Batch 18/64 loss: 0.308180034160614
Batch 19/64 loss: 0.3014565706253052
Batch 20/64 loss: 0.30380308628082275
Batch 21/64 loss: 0.30905473232269287
Batch 22/64 loss: 0.30691468715667725
Batch 23/64 loss: 0.3047291040420532
Batch 24/64 loss: 0.30030977725982666
Batch 25/64 loss: 0.305084764957428
Batch 26/64 loss: 0.30497610569000244
Batch 27/64 loss: 0.30248355865478516
Batch 28/64 loss: 0.30851101875305176
Batch 29/64 loss: 0.3094465732574463
Batch 30/64 loss: 0.30747365951538086
Batch 31/64 loss: 0.2950093150138855
Batch 32/64 loss: 0.31625258922576904
Batch 33/64 loss: 0.30679643154144287
Batch 34/64 loss: 0.3104531168937683
Batch 35/64 loss: 0.30846869945526123
Batch 36/64 loss: 0.3155069947242737
Batch 37/64 loss: 0.3009577989578247
Batch 38/64 loss: 0.2967485189437866
Batch 39/64 loss: 0.3064916133880615
Batch 40/64 loss: 0.29811644554138184
Batch 41/64 loss: 0.3016698956489563
Batch 42/64 loss: 0.2986569404602051
Batch 43/64 loss: 0.3004990816116333
Batch 44/64 loss: 0.30871737003326416
Batch 45/64 loss: 0.3066139817237854
Batch 46/64 loss: 0.30659019947052
Batch 47/64 loss: 0.3060394525527954
Batch 48/64 loss: 0.3017060160636902
Batch 49/64 loss: 0.2979585528373718
Batch 50/64 loss: 0.30734026432037354
Batch 51/64 loss: 0.29705989360809326
Batch 52/64 loss: 0.2970540523529053
Batch 53/64 loss: 0.2993878126144409
Batch 54/64 loss: 0.3076663017272949
Batch 55/64 loss: 0.3123909831047058
Batch 56/64 loss: 0.3060030937194824
Batch 57/64 loss: 0.3096469044685364
Batch 58/64 loss: 0.3015550374984741
Batch 59/64 loss: 0.3080436587333679
Batch 60/64 loss: 0.3050215244293213
Batch 61/64 loss: 0.31051182746887207
Batch 62/64 loss: 0.30610525608062744
Batch 63/64 loss: 0.296272337436676
Batch 64/64 loss: 0.3037613034248352
Epoch 311  Train loss: 0.3045736179632299  Val loss: 0.3272319569210826
Saving best model, epoch: 311
Epoch 312
-------------------------------
Batch 1/64 loss: 0.3131110668182373
Batch 2/64 loss: 0.29995429515838623
Batch 3/64 loss: 0.3078571557998657
Batch 4/64 loss: 0.29559242725372314
Batch 5/64 loss: 0.299882173538208
Batch 6/64 loss: 0.29732465744018555
Batch 7/64 loss: 0.3079441785812378
Batch 8/64 loss: 0.3003431558609009
Batch 9/64 loss: 0.30073583126068115
Batch 10/64 loss: 0.3026916980743408
Batch 11/64 loss: 0.3034476041793823
Batch 12/64 loss: 0.30273717641830444
Batch 13/64 loss: 0.30588555335998535
Batch 14/64 loss: 0.3049413561820984
Batch 15/64 loss: 0.2911731004714966
Batch 16/64 loss: 0.3053801655769348
Batch 17/64 loss: 0.30742979049682617
Batch 18/64 loss: 0.3036307096481323
Batch 19/64 loss: 0.30087339878082275
Batch 20/64 loss: 0.3015885353088379
Batch 21/64 loss: 0.2998311519622803
Batch 22/64 loss: 0.3047126531600952
Batch 23/64 loss: 0.3124431371688843
Batch 24/64 loss: 0.2975575923919678
Batch 25/64 loss: 0.31008148193359375
Batch 26/64 loss: 0.30243468284606934
Batch 27/64 loss: 0.3053157925605774
Batch 28/64 loss: 0.3046656847000122
Batch 29/64 loss: 0.3036983013153076
Batch 30/64 loss: 0.3028731346130371
Batch 31/64 loss: 0.2988830804824829
Batch 32/64 loss: 0.30397289991378784
Batch 33/64 loss: 0.3055967092514038
Batch 34/64 loss: 0.30158430337905884
Batch 35/64 loss: 0.30133056640625
Batch 36/64 loss: 0.31015127897262573
Batch 37/64 loss: 0.31310081481933594
Batch 38/64 loss: 0.3187798261642456
Batch 39/64 loss: 0.3025634288787842
Batch 40/64 loss: 0.31647664308547974
Batch 41/64 loss: 0.3023373484611511
Batch 42/64 loss: 0.3025233745574951
Batch 43/64 loss: 0.3130553364753723
Batch 44/64 loss: 0.3065387010574341
Batch 45/64 loss: 0.30058562755584717
Batch 46/64 loss: 0.30797111988067627
Batch 47/64 loss: 0.31173956394195557
Batch 48/64 loss: 0.30332279205322266
Batch 49/64 loss: 0.29785048961639404
Batch 50/64 loss: 0.30675560235977173
Batch 51/64 loss: 0.30491048097610474
Batch 52/64 loss: 0.30825287103652954
Batch 53/64 loss: 0.30604827404022217
Batch 54/64 loss: 0.3058275580406189
Batch 55/64 loss: 0.29742205142974854
Batch 56/64 loss: 0.31463736295700073
Batch 57/64 loss: 0.30236172676086426
Batch 58/64 loss: 0.30271685123443604
Batch 59/64 loss: 0.3009113669395447
Batch 60/64 loss: 0.30561959743499756
Batch 61/64 loss: 0.31116783618927
Batch 62/64 loss: 0.30521535873413086
Batch 63/64 loss: 0.311553955078125
Batch 64/64 loss: 0.3026241064071655
Epoch 312  Train loss: 0.3047038513071397  Val loss: 0.32768562282483604
Epoch 313
-------------------------------
Batch 1/64 loss: 0.30703699588775635
Batch 2/64 loss: 0.30488771200180054
Batch 3/64 loss: 0.3058624267578125
Batch 4/64 loss: 0.30527210235595703
Batch 5/64 loss: 0.3055430054664612
Batch 6/64 loss: 0.30447113513946533
Batch 7/64 loss: 0.313856303691864
Batch 8/64 loss: 0.3022247552871704
Batch 9/64 loss: 0.3103983402252197
Batch 10/64 loss: 0.30083292722702026
Batch 11/64 loss: 0.3031306862831116
Batch 12/64 loss: 0.29425835609436035
Batch 13/64 loss: 0.2966986894607544
Batch 14/64 loss: 0.2949642539024353
Batch 15/64 loss: 0.30808037519454956
Batch 16/64 loss: 0.3112872242927551
Batch 17/64 loss: 0.3062098026275635
Batch 18/64 loss: 0.2992284297943115
Batch 19/64 loss: 0.305880069732666
Batch 20/64 loss: 0.2997061014175415
Batch 21/64 loss: 0.30124807357788086
Batch 22/64 loss: 0.30732327699661255
Batch 23/64 loss: 0.2993890643119812
Batch 24/64 loss: 0.31114470958709717
Batch 25/64 loss: 0.3039857745170593
Batch 26/64 loss: 0.2990555763244629
Batch 27/64 loss: 0.3040379285812378
Batch 28/64 loss: 0.3000096082687378
Batch 29/64 loss: 0.30184584856033325
Batch 30/64 loss: 0.306723952293396
Batch 31/64 loss: 0.31228387355804443
Batch 32/64 loss: 0.30916309356689453
Batch 33/64 loss: 0.3102980852127075
Batch 34/64 loss: 0.3129459619522095
Batch 35/64 loss: 0.3108895421028137
Batch 36/64 loss: 0.3066079616546631
Batch 37/64 loss: 0.3062172532081604
Batch 38/64 loss: 0.3073241710662842
Batch 39/64 loss: 0.29992926120758057
Batch 40/64 loss: 0.3075495958328247
Batch 41/64 loss: 0.32381510734558105
Batch 42/64 loss: 0.30796587467193604
Batch 43/64 loss: 0.302504301071167
Batch 44/64 loss: 0.3075891137123108
Batch 45/64 loss: 0.3094732165336609
Batch 46/64 loss: 0.3055613040924072
Batch 47/64 loss: 0.30473965406417847
Batch 48/64 loss: 0.3101145029067993
Batch 49/64 loss: 0.31328022480010986
Batch 50/64 loss: 0.30067312717437744
Batch 51/64 loss: 0.30058884620666504
Batch 52/64 loss: 0.3089040517807007
Batch 53/64 loss: 0.3004814386367798
Batch 54/64 loss: 0.30212438106536865
Batch 55/64 loss: 0.3041365146636963
Batch 56/64 loss: 0.3009955883026123
Batch 57/64 loss: 0.30650651454925537
Batch 58/64 loss: 0.3019567131996155
Batch 59/64 loss: 0.3022092580795288
Batch 60/64 loss: 0.3117407560348511
Batch 61/64 loss: 0.2965301275253296
Batch 62/64 loss: 0.29440587759017944
Batch 63/64 loss: 0.3014991879463196
Batch 64/64 loss: 0.29749083518981934
Epoch 313  Train loss: 0.30492103707556634  Val loss: 0.3262118019189212
Saving best model, epoch: 313
Epoch 314
-------------------------------
Batch 1/64 loss: 0.2983856201171875
Batch 2/64 loss: 0.2962372899055481
Batch 3/64 loss: 0.30003416538238525
Batch 4/64 loss: 0.3046877384185791
Batch 5/64 loss: 0.3079395294189453
Batch 6/64 loss: 0.3012523651123047
Batch 7/64 loss: 0.306354820728302
Batch 8/64 loss: 0.3039512634277344
Batch 9/64 loss: 0.30219775438308716
Batch 10/64 loss: 0.30194705724716187
Batch 11/64 loss: 0.29942941665649414
Batch 12/64 loss: 0.30604052543640137
Batch 13/64 loss: 0.3099254369735718
Batch 14/64 loss: 0.2981732487678528
Batch 15/64 loss: 0.30917787551879883
Batch 16/64 loss: 0.30527830123901367
Batch 17/64 loss: 0.30720770359039307
Batch 18/64 loss: 0.3084806799888611
Batch 19/64 loss: 0.3056720495223999
Batch 20/64 loss: 0.3018747568130493
Batch 21/64 loss: 0.2982581853866577
Batch 22/64 loss: 0.2982736825942993
Batch 23/64 loss: 0.3027534484863281
Batch 24/64 loss: 0.299419641494751
Batch 25/64 loss: 0.3077858090400696
Batch 26/64 loss: 0.3091930150985718
Batch 27/64 loss: 0.3121383786201477
Batch 28/64 loss: 0.30614638328552246
Batch 29/64 loss: 0.30918312072753906
Batch 30/64 loss: 0.30281615257263184
Batch 31/64 loss: 0.3071292042732239
Batch 32/64 loss: 0.3039875030517578
Batch 33/64 loss: 0.30543625354766846
Batch 34/64 loss: 0.3044290542602539
Batch 35/64 loss: 0.31379544734954834
Batch 36/64 loss: 0.2944815158843994
Batch 37/64 loss: 0.31505638360977173
Batch 38/64 loss: 0.30520856380462646
Batch 39/64 loss: 0.30394113063812256
Batch 40/64 loss: 0.2916306257247925
Batch 41/64 loss: 0.3076348304748535
Batch 42/64 loss: 0.3121163845062256
Batch 43/64 loss: 0.30520349740982056
Batch 44/64 loss: 0.3107450008392334
Batch 45/64 loss: 0.3047924041748047
Batch 46/64 loss: 0.30518484115600586
Batch 47/64 loss: 0.30746740102767944
Batch 48/64 loss: 0.3066753149032593
Batch 49/64 loss: 0.30821073055267334
Batch 50/64 loss: 0.2974396347999573
Batch 51/64 loss: 0.30446624755859375
Batch 52/64 loss: 0.2954902648925781
Batch 53/64 loss: 0.3094916343688965
Batch 54/64 loss: 0.30324840545654297
Batch 55/64 loss: 0.30562180280685425
Batch 56/64 loss: 0.30948543548583984
Batch 57/64 loss: 0.308025598526001
Batch 58/64 loss: 0.30136996507644653
Batch 59/64 loss: 0.29974955320358276
Batch 60/64 loss: 0.3028954863548279
Batch 61/64 loss: 0.30038344860076904
Batch 62/64 loss: 0.2978222370147705
Batch 63/64 loss: 0.30831658840179443
Batch 64/64 loss: 0.30681705474853516
Epoch 314  Train loss: 0.30442761720395556  Val loss: 0.3289468906999044
Epoch 315
-------------------------------
Batch 1/64 loss: 0.3152620792388916
Batch 2/64 loss: 0.29860126972198486
Batch 3/64 loss: 0.297518253326416
Batch 4/64 loss: 0.313528835773468
Batch 5/64 loss: 0.3030986785888672
Batch 6/64 loss: 0.3061431050300598
Batch 7/64 loss: 0.3065148591995239
Batch 8/64 loss: 0.3028090000152588
Batch 9/64 loss: 0.3028639554977417
Batch 10/64 loss: 0.29618608951568604
Batch 11/64 loss: 0.30484652519226074
Batch 12/64 loss: 0.305619478225708
Batch 13/64 loss: 0.3023573160171509
Batch 14/64 loss: 0.30779051780700684
Batch 15/64 loss: 0.31390178203582764
Batch 16/64 loss: 0.3061092495918274
Batch 17/64 loss: 0.3061891794204712
Batch 18/64 loss: 0.3030911684036255
Batch 19/64 loss: 0.3015369176864624
Batch 20/64 loss: 0.30637848377227783
Batch 21/64 loss: 0.2965480089187622
Batch 22/64 loss: 0.2996364235877991
Batch 23/64 loss: 0.3042638301849365
Batch 24/64 loss: 0.30643224716186523
Batch 25/64 loss: 0.30057841539382935
Batch 26/64 loss: 0.2921942472457886
Batch 27/64 loss: 0.3014982342720032
Batch 28/64 loss: 0.3016718626022339
Batch 29/64 loss: 0.29960012435913086
Batch 30/64 loss: 0.31445860862731934
Batch 31/64 loss: 0.3063722848892212
Batch 32/64 loss: 0.3014606237411499
Batch 33/64 loss: 0.30046939849853516
Batch 34/64 loss: 0.3081839680671692
Batch 35/64 loss: 0.3033411502838135
Batch 36/64 loss: 0.3042990565299988
Batch 37/64 loss: 0.2927165627479553
Batch 38/64 loss: 0.30817586183547974
Batch 39/64 loss: 0.31040406227111816
Batch 40/64 loss: 0.30867791175842285
Batch 41/64 loss: 0.30659300088882446
Batch 42/64 loss: 0.29776638746261597
Batch 43/64 loss: 0.30066585540771484
Batch 44/64 loss: 0.3042505383491516
Batch 45/64 loss: 0.3103729486465454
Batch 46/64 loss: 0.3030979037284851
Batch 47/64 loss: 0.3009214401245117
Batch 48/64 loss: 0.3036499619483948
Batch 49/64 loss: 0.30043506622314453
Batch 50/64 loss: 0.30716848373413086
Batch 51/64 loss: 0.3070096969604492
Batch 52/64 loss: 0.301738977432251
Batch 53/64 loss: 0.30302244424819946
Batch 54/64 loss: 0.2990037202835083
Batch 55/64 loss: 0.30079972743988037
Batch 56/64 loss: 0.2972177267074585
Batch 57/64 loss: 0.3121858835220337
Batch 58/64 loss: 0.2981381416320801
Batch 59/64 loss: 0.30894899368286133
Batch 60/64 loss: 0.3097243309020996
Batch 61/64 loss: 0.2996169924736023
Batch 62/64 loss: 0.30514729022979736
Batch 63/64 loss: 0.31122612953186035
Batch 64/64 loss: 0.30706602334976196
Epoch 315  Train loss: 0.30400518880170935  Val loss: 0.3272274429445824
Epoch 316
-------------------------------
Batch 1/64 loss: 0.3054434061050415
Batch 2/64 loss: 0.29423511028289795
Batch 3/64 loss: 0.30265283584594727
Batch 4/64 loss: 0.29735898971557617
Batch 5/64 loss: 0.3011879324913025
Batch 6/64 loss: 0.3041115403175354
Batch 7/64 loss: 0.2984272837638855
Batch 8/64 loss: 0.3072513937950134
Batch 9/64 loss: 0.3089354634284973
Batch 10/64 loss: 0.306516170501709
Batch 11/64 loss: 0.31014561653137207
Batch 12/64 loss: 0.3013423681259155
Batch 13/64 loss: 0.3030437231063843
Batch 14/64 loss: 0.31173282861709595
Batch 15/64 loss: 0.299393892288208
Batch 16/64 loss: 0.30172455310821533
Batch 17/64 loss: 0.30865585803985596
Batch 18/64 loss: 0.30753612518310547
Batch 19/64 loss: 0.29777050018310547
Batch 20/64 loss: 0.2990546226501465
Batch 21/64 loss: 0.30896246433258057
Batch 22/64 loss: 0.3018662929534912
Batch 23/64 loss: 0.306149959564209
Batch 24/64 loss: 0.3055691123008728
Batch 25/64 loss: 0.309367299079895
Batch 26/64 loss: 0.311930775642395
Batch 27/64 loss: 0.2987656593322754
Batch 28/64 loss: 0.31854915618896484
Batch 29/64 loss: 0.30338335037231445
Batch 30/64 loss: 0.306812584400177
Batch 31/64 loss: 0.3120070695877075
Batch 32/64 loss: 0.30352771282196045
Batch 33/64 loss: 0.30941152572631836
Batch 34/64 loss: 0.30930596590042114
Batch 35/64 loss: 0.3003305196762085
Batch 36/64 loss: 0.30214977264404297
Batch 37/64 loss: 0.3019014596939087
Batch 38/64 loss: 0.3111945390701294
Batch 39/64 loss: 0.2998933792114258
Batch 40/64 loss: 0.2976219058036804
Batch 41/64 loss: 0.3068854808807373
Batch 42/64 loss: 0.3069648742675781
Batch 43/64 loss: 0.3121175765991211
Batch 44/64 loss: 0.29993486404418945
Batch 45/64 loss: 0.3078005313873291
Batch 46/64 loss: 0.29447394609451294
Batch 47/64 loss: 0.3030691146850586
Batch 48/64 loss: 0.29348576068878174
Batch 49/64 loss: 0.3038954734802246
Batch 50/64 loss: 0.30272209644317627
Batch 51/64 loss: 0.2990841865539551
Batch 52/64 loss: 0.29584723711013794
Batch 53/64 loss: 0.2939486503601074
Batch 54/64 loss: 0.3038477897644043
Batch 55/64 loss: 0.3024238348007202
Batch 56/64 loss: 0.3119436502456665
Batch 57/64 loss: 0.307247519493103
Batch 58/64 loss: 0.30577898025512695
Batch 59/64 loss: 0.299609899520874
Batch 60/64 loss: 0.2992174029350281
Batch 61/64 loss: 0.30178701877593994
Batch 62/64 loss: 0.29726600646972656
Batch 63/64 loss: 0.3085157871246338
Batch 64/64 loss: 0.3055906295776367
Epoch 316  Train loss: 0.3038789234909357  Val loss: 0.32869012638465644
Epoch 317
-------------------------------
Batch 1/64 loss: 0.30691027641296387
Batch 2/64 loss: 0.3033410310745239
Batch 3/64 loss: 0.2986283302307129
Batch 4/64 loss: 0.29627251625061035
Batch 5/64 loss: 0.29676103591918945
Batch 6/64 loss: 0.29590070247650146
Batch 7/64 loss: 0.30042099952697754
Batch 8/64 loss: 0.30264461040496826
Batch 9/64 loss: 0.3009335398674011
Batch 10/64 loss: 0.31843793392181396
Batch 11/64 loss: 0.2972257733345032
Batch 12/64 loss: 0.29990673065185547
Batch 13/64 loss: 0.3009694218635559
Batch 14/64 loss: 0.30507004261016846
Batch 15/64 loss: 0.307712197303772
Batch 16/64 loss: 0.29681968688964844
Batch 17/64 loss: 0.2982103228569031
Batch 18/64 loss: 0.30152571201324463
Batch 19/64 loss: 0.2993239164352417
Batch 20/64 loss: 0.304718554019928
Batch 21/64 loss: 0.3179694414138794
Batch 22/64 loss: 0.31286442279815674
Batch 23/64 loss: 0.30167126655578613
Batch 24/64 loss: 0.3015209436416626
Batch 25/64 loss: 0.3006638288497925
Batch 26/64 loss: 0.3040049076080322
Batch 27/64 loss: 0.303555965423584
Batch 28/64 loss: 0.29265981912612915
Batch 29/64 loss: 0.3048432469367981
Batch 30/64 loss: 0.30927348136901855
Batch 31/64 loss: 0.29750072956085205
Batch 32/64 loss: 0.30225932598114014
Batch 33/64 loss: 0.29900074005126953
Batch 34/64 loss: 0.3032280206680298
Batch 35/64 loss: 0.31098198890686035
Batch 36/64 loss: 0.2985152006149292
Batch 37/64 loss: 0.29579079151153564
Batch 38/64 loss: 0.31134068965911865
Batch 39/64 loss: 0.31253719329833984
Batch 40/64 loss: 0.30375564098358154
Batch 41/64 loss: 0.30878663063049316
Batch 42/64 loss: 0.2991957664489746
Batch 43/64 loss: 0.2942216992378235
Batch 44/64 loss: 0.3099665641784668
Batch 45/64 loss: 0.29695427417755127
Batch 46/64 loss: 0.2989910840988159
Batch 47/64 loss: 0.3095399737358093
Batch 48/64 loss: 0.3109400272369385
Batch 49/64 loss: 0.29669857025146484
Batch 50/64 loss: 0.3150421977043152
Batch 51/64 loss: 0.30449986457824707
Batch 52/64 loss: 0.30679893493652344
Batch 53/64 loss: 0.2935020923614502
Batch 54/64 loss: 0.2949913740158081
Batch 55/64 loss: 0.30542540550231934
Batch 56/64 loss: 0.3069302439689636
Batch 57/64 loss: 0.3199428915977478
Batch 58/64 loss: 0.29923051595687866
Batch 59/64 loss: 0.30144745111465454
Batch 60/64 loss: 0.32038426399230957
Batch 61/64 loss: 0.3054434657096863
Batch 62/64 loss: 0.30392950773239136
Batch 63/64 loss: 0.314494788646698
Batch 64/64 loss: 0.29908114671707153
Epoch 317  Train loss: 0.30364454002941355  Val loss: 0.32843760977086334
Epoch 318
-------------------------------
Batch 1/64 loss: 0.29917091131210327
Batch 2/64 loss: 0.3186753988265991
Batch 3/64 loss: 0.304771363735199
Batch 4/64 loss: 0.3100658059120178
Batch 5/64 loss: 0.30072271823883057
Batch 6/64 loss: 0.3066009283065796
Batch 7/64 loss: 0.3045881390571594
Batch 8/64 loss: 0.29931336641311646
Batch 9/64 loss: 0.310820996761322
Batch 10/64 loss: 0.30586814880371094
Batch 11/64 loss: 0.31197667121887207
Batch 12/64 loss: 0.3029220700263977
Batch 13/64 loss: 0.30344104766845703
Batch 14/64 loss: 0.3005777597427368
Batch 15/64 loss: 0.30093538761138916
Batch 16/64 loss: 0.3100530505180359
Batch 17/64 loss: 0.31246161460876465
Batch 18/64 loss: 0.3047659993171692
Batch 19/64 loss: 0.3024471402168274
Batch 20/64 loss: 0.30438607931137085
Batch 21/64 loss: 0.2973020076751709
Batch 22/64 loss: 0.29806196689605713
Batch 23/64 loss: 0.30352550745010376
Batch 24/64 loss: 0.30409735441207886
Batch 25/64 loss: 0.3060459494590759
Batch 26/64 loss: 0.30733370780944824
Batch 27/64 loss: 0.30346357822418213
Batch 28/64 loss: 0.30418944358825684
Batch 29/64 loss: 0.30581122636795044
Batch 30/64 loss: 0.30066001415252686
Batch 31/64 loss: 0.3080604672431946
Batch 32/64 loss: 0.3023526668548584
Batch 33/64 loss: 0.3052073121070862
Batch 34/64 loss: 0.30568528175354004
Batch 35/64 loss: 0.3041872978210449
Batch 36/64 loss: 0.3019636869430542
Batch 37/64 loss: 0.30601704120635986
Batch 38/64 loss: 0.3066762685775757
Batch 39/64 loss: 0.30266571044921875
Batch 40/64 loss: 0.2929449677467346
Batch 41/64 loss: 0.3028031587600708
Batch 42/64 loss: 0.30320119857788086
Batch 43/64 loss: 0.29410219192504883
Batch 44/64 loss: 0.3020285367965698
Batch 45/64 loss: 0.31161928176879883
Batch 46/64 loss: 0.3139442205429077
Batch 47/64 loss: 0.3133617639541626
Batch 48/64 loss: 0.3040422797203064
Batch 49/64 loss: 0.3009864091873169
Batch 50/64 loss: 0.2991529703140259
Batch 51/64 loss: 0.30201148986816406
Batch 52/64 loss: 0.29516369104385376
Batch 53/64 loss: 0.2970046401023865
Batch 54/64 loss: 0.3070685863494873
Batch 55/64 loss: 0.3118937015533447
Batch 56/64 loss: 0.2974663972854614
Batch 57/64 loss: 0.30730140209198
Batch 58/64 loss: 0.3078821897506714
Batch 59/64 loss: 0.3027380704879761
Batch 60/64 loss: 0.3011069893836975
Batch 61/64 loss: 0.3048548698425293
Batch 62/64 loss: 0.29237985610961914
Batch 63/64 loss: 0.30651748180389404
Batch 64/64 loss: 0.2968202829360962
Epoch 318  Train loss: 0.30403235519633576  Val loss: 0.32763539700164007
Epoch 319
-------------------------------
Batch 1/64 loss: 0.3020728826522827
Batch 2/64 loss: 0.30438339710235596
Batch 3/64 loss: 0.3026779890060425
Batch 4/64 loss: 0.30382418632507324
Batch 5/64 loss: 0.30977892875671387
Batch 6/64 loss: 0.30193793773651123
Batch 7/64 loss: 0.31136554479599
Batch 8/64 loss: 0.3059980273246765
Batch 9/64 loss: 0.3003990054130554
Batch 10/64 loss: 0.30314135551452637
Batch 11/64 loss: 0.30845069885253906
Batch 12/64 loss: 0.3073365092277527
Batch 13/64 loss: 0.3000807762145996
Batch 14/64 loss: 0.3053728938102722
Batch 15/64 loss: 0.2946808934211731
Batch 16/64 loss: 0.2989293932914734
Batch 17/64 loss: 0.3018702268600464
Batch 18/64 loss: 0.3046833872795105
Batch 19/64 loss: 0.29988086223602295
Batch 20/64 loss: 0.296438992023468
Batch 21/64 loss: 0.30878645181655884
Batch 22/64 loss: 0.30198073387145996
Batch 23/64 loss: 0.2952468991279602
Batch 24/64 loss: 0.2993575930595398
Batch 25/64 loss: 0.30634135007858276
Batch 26/64 loss: 0.3020288944244385
Batch 27/64 loss: 0.3158918619155884
Batch 28/64 loss: 0.3060987591743469
Batch 29/64 loss: 0.30843162536621094
Batch 30/64 loss: 0.30465102195739746
Batch 31/64 loss: 0.2988378405570984
Batch 32/64 loss: 0.29792559146881104
Batch 33/64 loss: 0.30049389600753784
Batch 34/64 loss: 0.29668712615966797
Batch 35/64 loss: 0.3070809245109558
Batch 36/64 loss: 0.3142584562301636
Batch 37/64 loss: 0.2929142713546753
Batch 38/64 loss: 0.3057616949081421
Batch 39/64 loss: 0.30203545093536377
Batch 40/64 loss: 0.30574965476989746
Batch 41/64 loss: 0.30364739894866943
Batch 42/64 loss: 0.3111799955368042
Batch 43/64 loss: 0.30198776721954346
Batch 44/64 loss: 0.3040813207626343
Batch 45/64 loss: 0.3109164834022522
Batch 46/64 loss: 0.3021796941757202
Batch 47/64 loss: 0.30122655630111694
Batch 48/64 loss: 0.30516183376312256
Batch 49/64 loss: 0.2960089445114136
Batch 50/64 loss: 0.30454546213150024
Batch 51/64 loss: 0.30881786346435547
Batch 52/64 loss: 0.30270373821258545
Batch 53/64 loss: 0.30748188495635986
Batch 54/64 loss: 0.30744898319244385
Batch 55/64 loss: 0.3034135699272156
Batch 56/64 loss: 0.29290592670440674
Batch 57/64 loss: 0.3045618534088135
Batch 58/64 loss: 0.3114786148071289
Batch 59/64 loss: 0.3072882294654846
Batch 60/64 loss: 0.29843103885650635
Batch 61/64 loss: 0.2909851670265198
Batch 62/64 loss: 0.30733394622802734
Batch 63/64 loss: 0.2962568998336792
Batch 64/64 loss: 0.31140148639678955
Epoch 319  Train loss: 0.3034895415399589  Val loss: 0.32780196228387837
Epoch 320
-------------------------------
Batch 1/64 loss: 0.3015649914741516
Batch 2/64 loss: 0.3001117706298828
Batch 3/64 loss: 0.3000807762145996
Batch 4/64 loss: 0.3063281178474426
Batch 5/64 loss: 0.2981996536254883
Batch 6/64 loss: 0.3091554641723633
Batch 7/64 loss: 0.31031036376953125
Batch 8/64 loss: 0.3073294162750244
Batch 9/64 loss: 0.30712616443634033
Batch 10/64 loss: 0.30196619033813477
Batch 11/64 loss: 0.30587446689605713
Batch 12/64 loss: 0.30372124910354614
Batch 13/64 loss: 0.30305933952331543
Batch 14/64 loss: 0.30652785301208496
Batch 15/64 loss: 0.30439507961273193
Batch 16/64 loss: 0.31023848056793213
Batch 17/64 loss: 0.29865562915802
Batch 18/64 loss: 0.3005307912826538
Batch 19/64 loss: 0.30158185958862305
Batch 20/64 loss: 0.3121528625488281
Batch 21/64 loss: 0.3030402660369873
Batch 22/64 loss: 0.3019205927848816
Batch 23/64 loss: 0.30454713106155396
Batch 24/64 loss: 0.2984461784362793
Batch 25/64 loss: 0.3070213198661804
Batch 26/64 loss: 0.3046548366546631
Batch 27/64 loss: 0.29859280586242676
Batch 28/64 loss: 0.31242603063583374
Batch 29/64 loss: 0.2992509603500366
Batch 30/64 loss: 0.29784953594207764
Batch 31/64 loss: 0.31213414669036865
Batch 32/64 loss: 0.30375707149505615
Batch 33/64 loss: 0.3036876320838928
Batch 34/64 loss: 0.3078296184539795
Batch 35/64 loss: 0.3028358817100525
Batch 36/64 loss: 0.3080415725708008
Batch 37/64 loss: 0.2977449893951416
Batch 38/64 loss: 0.2933805584907532
Batch 39/64 loss: 0.3043348789215088
Batch 40/64 loss: 0.2962164878845215
Batch 41/64 loss: 0.3039284944534302
Batch 42/64 loss: 0.3020282983779907
Batch 43/64 loss: 0.29279839992523193
Batch 44/64 loss: 0.3135361671447754
Batch 45/64 loss: 0.3012961149215698
Batch 46/64 loss: 0.3014305830001831
Batch 47/64 loss: 0.2987019419670105
Batch 48/64 loss: 0.2933279871940613
Batch 49/64 loss: 0.29979050159454346
Batch 50/64 loss: 0.30386704206466675
Batch 51/64 loss: 0.30920952558517456
Batch 52/64 loss: 0.299710750579834
Batch 53/64 loss: 0.29725825786590576
Batch 54/64 loss: 0.318867564201355
Batch 55/64 loss: 0.301596462726593
Batch 56/64 loss: 0.3009220361709595
Batch 57/64 loss: 0.3044142723083496
Batch 58/64 loss: 0.30382221937179565
Batch 59/64 loss: 0.29493701457977295
Batch 60/64 loss: 0.29591095447540283
Batch 61/64 loss: 0.30086320638656616
Batch 62/64 loss: 0.3062170743942261
Batch 63/64 loss: 0.2963443398475647
Batch 64/64 loss: 0.28817588090896606
Epoch 320  Train loss: 0.30280053545446955  Val loss: 0.3276910298468731
Epoch 321
-------------------------------
Batch 1/64 loss: 0.2967398762702942
Batch 2/64 loss: 0.29393041133880615
Batch 3/64 loss: 0.3058537244796753
Batch 4/64 loss: 0.29795777797698975
Batch 5/64 loss: 0.31505048274993896
Batch 6/64 loss: 0.2983419895172119
Batch 7/64 loss: 0.2878352403640747
Batch 8/64 loss: 0.3060712218284607
Batch 9/64 loss: 0.30011457204818726
Batch 10/64 loss: 0.3048245310783386
Batch 11/64 loss: 0.30491483211517334
Batch 12/64 loss: 0.3050432801246643
Batch 13/64 loss: 0.2968289256095886
Batch 14/64 loss: 0.2990710735321045
Batch 15/64 loss: 0.2988489270210266
Batch 16/64 loss: 0.3096277117729187
Batch 17/64 loss: 0.3112108111381531
Batch 18/64 loss: 0.2972038984298706
Batch 19/64 loss: 0.30109816789627075
Batch 20/64 loss: 0.3014698028564453
Batch 21/64 loss: 0.3043803572654724
Batch 22/64 loss: 0.295274019241333
Batch 23/64 loss: 0.3027305603027344
Batch 24/64 loss: 0.30645060539245605
Batch 25/64 loss: 0.29831981658935547
Batch 26/64 loss: 0.29898953437805176
Batch 27/64 loss: 0.3048546314239502
Batch 28/64 loss: 0.3032435178756714
Batch 29/64 loss: 0.3101595640182495
Batch 30/64 loss: 0.30299854278564453
Batch 31/64 loss: 0.3109380006790161
Batch 32/64 loss: 0.30103254318237305
Batch 33/64 loss: 0.2976943254470825
Batch 34/64 loss: 0.2979639768600464
Batch 35/64 loss: 0.3038836717605591
Batch 36/64 loss: 0.31024789810180664
Batch 37/64 loss: 0.31347787380218506
Batch 38/64 loss: 0.30368876457214355
Batch 39/64 loss: 0.2992008328437805
Batch 40/64 loss: 0.3073621988296509
Batch 41/64 loss: 0.30730217695236206
Batch 42/64 loss: 0.30348289012908936
Batch 43/64 loss: 0.30332666635513306
Batch 44/64 loss: 0.29623472690582275
Batch 45/64 loss: 0.299136757850647
Batch 46/64 loss: 0.3063238263130188
Batch 47/64 loss: 0.3018972873687744
Batch 48/64 loss: 0.3026738166809082
Batch 49/64 loss: 0.30621159076690674
Batch 50/64 loss: 0.29544520378112793
Batch 51/64 loss: 0.31436073780059814
Batch 52/64 loss: 0.30381298065185547
Batch 53/64 loss: 0.29789793491363525
Batch 54/64 loss: 0.3040531873703003
Batch 55/64 loss: 0.3077002167701721
Batch 56/64 loss: 0.3029813766479492
Batch 57/64 loss: 0.3035322427749634
Batch 58/64 loss: 0.30388689041137695
Batch 59/64 loss: 0.30393362045288086
Batch 60/64 loss: 0.30480480194091797
Batch 61/64 loss: 0.306713342666626
Batch 62/64 loss: 0.2987820506095886
Batch 63/64 loss: 0.30249685049057007
Batch 64/64 loss: 0.3093869090080261
Epoch 321  Train loss: 0.30296407610762355  Val loss: 0.3283445677396768
Epoch 322
-------------------------------
Batch 1/64 loss: 0.2980351448059082
Batch 2/64 loss: 0.3056459426879883
Batch 3/64 loss: 0.29964929819107056
Batch 4/64 loss: 0.30797135829925537
Batch 5/64 loss: 0.3011021614074707
Batch 6/64 loss: 0.29852867126464844
Batch 7/64 loss: 0.2882964611053467
Batch 8/64 loss: 0.2955489158630371
Batch 9/64 loss: 0.29891669750213623
Batch 10/64 loss: 0.2984910011291504
Batch 11/64 loss: 0.30446863174438477
Batch 12/64 loss: 0.298791766166687
Batch 13/64 loss: 0.3059017062187195
Batch 14/64 loss: 0.29961538314819336
Batch 15/64 loss: 0.29943686723709106
Batch 16/64 loss: 0.30747491121292114
Batch 17/64 loss: 0.30188900232315063
Batch 18/64 loss: 0.293659508228302
Batch 19/64 loss: 0.295274019241333
Batch 20/64 loss: 0.3090248107910156
Batch 21/64 loss: 0.29883116483688354
Batch 22/64 loss: 0.3066737651824951
Batch 23/64 loss: 0.29618775844573975
Batch 24/64 loss: 0.301654577255249
Batch 25/64 loss: 0.3032575845718384
Batch 26/64 loss: 0.3049554228782654
Batch 27/64 loss: 0.31743353605270386
Batch 28/64 loss: 0.30331218242645264
Batch 29/64 loss: 0.313174843788147
Batch 30/64 loss: 0.30086207389831543
Batch 31/64 loss: 0.30254870653152466
Batch 32/64 loss: 0.3110123872756958
Batch 33/64 loss: 0.3045905828475952
Batch 34/64 loss: 0.2994065284729004
Batch 35/64 loss: 0.2989501953125
Batch 36/64 loss: 0.30261337757110596
Batch 37/64 loss: 0.30673301219940186
Batch 38/64 loss: 0.2977699041366577
Batch 39/64 loss: 0.3070172071456909
Batch 40/64 loss: 0.2981341481208801
Batch 41/64 loss: 0.30700117349624634
Batch 42/64 loss: 0.30671679973602295
Batch 43/64 loss: 0.30389583110809326
Batch 44/64 loss: 0.2967991232872009
Batch 45/64 loss: 0.3073704242706299
Batch 46/64 loss: 0.30614590644836426
Batch 47/64 loss: 0.29922473430633545
Batch 48/64 loss: 0.3132234811782837
Batch 49/64 loss: 0.3058176636695862
Batch 50/64 loss: 0.3051072359085083
Batch 51/64 loss: 0.30464959144592285
Batch 52/64 loss: 0.30130815505981445
Batch 53/64 loss: 0.3067810535430908
Batch 54/64 loss: 0.3046942353248596
Batch 55/64 loss: 0.3077544569969177
Batch 56/64 loss: 0.3006473779678345
Batch 57/64 loss: 0.3081291913986206
Batch 58/64 loss: 0.313728392124176
Batch 59/64 loss: 0.2978856563568115
Batch 60/64 loss: 0.3066481947898865
Batch 61/64 loss: 0.30209195613861084
Batch 62/64 loss: 0.3071003556251526
Batch 63/64 loss: 0.3019644021987915
Batch 64/64 loss: 0.300693154335022
Epoch 322  Train loss: 0.30310661138272754  Val loss: 0.3271525074116553
Epoch 323
-------------------------------
Batch 1/64 loss: 0.29909342527389526
Batch 2/64 loss: 0.3020123243331909
Batch 3/64 loss: 0.29663825035095215
Batch 4/64 loss: 0.2983722686767578
Batch 5/64 loss: 0.2988938093185425
Batch 6/64 loss: 0.30203455686569214
Batch 7/64 loss: 0.3051316738128662
Batch 8/64 loss: 0.30533474683761597
Batch 9/64 loss: 0.31043684482574463
Batch 10/64 loss: 0.29567813873291016
Batch 11/64 loss: 0.30261629819869995
Batch 12/64 loss: 0.3033651113510132
Batch 13/64 loss: 0.30176424980163574
Batch 14/64 loss: 0.29662466049194336
Batch 15/64 loss: 0.29918915033340454
Batch 16/64 loss: 0.3061181306838989
Batch 17/64 loss: 0.3125882148742676
Batch 18/64 loss: 0.3122556805610657
Batch 19/64 loss: 0.30194032192230225
Batch 20/64 loss: 0.30447912216186523
Batch 21/64 loss: 0.2949650287628174
Batch 22/64 loss: 0.30475836992263794
Batch 23/64 loss: 0.3007238507270813
Batch 24/64 loss: 0.307170569896698
Batch 25/64 loss: 0.29715192317962646
Batch 26/64 loss: 0.3040304183959961
Batch 27/64 loss: 0.3055979013442993
Batch 28/64 loss: 0.3033881187438965
Batch 29/64 loss: 0.3053154945373535
Batch 30/64 loss: 0.30473947525024414
Batch 31/64 loss: 0.31410449743270874
Batch 32/64 loss: 0.29862475395202637
Batch 33/64 loss: 0.30882418155670166
Batch 34/64 loss: 0.30548572540283203
Batch 35/64 loss: 0.29561495780944824
Batch 36/64 loss: 0.30827367305755615
Batch 37/64 loss: 0.3035174608230591
Batch 38/64 loss: 0.311229944229126
Batch 39/64 loss: 0.30380165576934814
Batch 40/64 loss: 0.3119109869003296
Batch 41/64 loss: 0.30666983127593994
Batch 42/64 loss: 0.30546772480010986
Batch 43/64 loss: 0.2982635498046875
Batch 44/64 loss: 0.3049072027206421
Batch 45/64 loss: 0.31087416410446167
Batch 46/64 loss: 0.29945576190948486
Batch 47/64 loss: 0.30831801891326904
Batch 48/64 loss: 0.3013817071914673
Batch 49/64 loss: 0.30281776189804077
Batch 50/64 loss: 0.3015816807746887
Batch 51/64 loss: 0.3022007942199707
Batch 52/64 loss: 0.31541121006011963
Batch 53/64 loss: 0.2999623417854309
Batch 54/64 loss: 0.3036400079727173
Batch 55/64 loss: 0.2962130308151245
Batch 56/64 loss: 0.30444443225860596
Batch 57/64 loss: 0.299091100692749
Batch 58/64 loss: 0.300571084022522
Batch 59/64 loss: 0.30847370624542236
Batch 60/64 loss: 0.3063693642616272
Batch 61/64 loss: 0.2980109453201294
Batch 62/64 loss: 0.30423325300216675
Batch 63/64 loss: 0.2983057498931885
Batch 64/64 loss: 0.30306297540664673
Epoch 323  Train loss: 0.30349423721724866  Val loss: 0.3271106465165967
Epoch 324
-------------------------------
Batch 1/64 loss: 0.3008807897567749
Batch 2/64 loss: 0.2950202226638794
Batch 3/64 loss: 0.3019068241119385
Batch 4/64 loss: 0.30890679359436035
Batch 5/64 loss: 0.30190885066986084
Batch 6/64 loss: 0.3198009133338928
Batch 7/64 loss: 0.29310035705566406
Batch 8/64 loss: 0.29923689365386963
Batch 9/64 loss: 0.29689866304397583
Batch 10/64 loss: 0.3003734350204468
Batch 11/64 loss: 0.30558061599731445
Batch 12/64 loss: 0.29804718494415283
Batch 13/64 loss: 0.3016020655632019
Batch 14/64 loss: 0.29601478576660156
Batch 15/64 loss: 0.30330049991607666
Batch 16/64 loss: 0.30185753107070923
Batch 17/64 loss: 0.308282732963562
Batch 18/64 loss: 0.30497825145721436
Batch 19/64 loss: 0.3049381375312805
Batch 20/64 loss: 0.3080572485923767
Batch 21/64 loss: 0.29758352041244507
Batch 22/64 loss: 0.3032684922218323
Batch 23/64 loss: 0.3004990816116333
Batch 24/64 loss: 0.29655134677886963
Batch 25/64 loss: 0.30532073974609375
Batch 26/64 loss: 0.30095183849334717
Batch 27/64 loss: 0.2968142032623291
Batch 28/64 loss: 0.3082343339920044
Batch 29/64 loss: 0.30257630348205566
Batch 30/64 loss: 0.3133220672607422
Batch 31/64 loss: 0.3071863055229187
Batch 32/64 loss: 0.29871487617492676
Batch 33/64 loss: 0.30945777893066406
Batch 34/64 loss: 0.30226171016693115
Batch 35/64 loss: 0.30171751976013184
Batch 36/64 loss: 0.2984059453010559
Batch 37/64 loss: 0.3080235719680786
Batch 38/64 loss: 0.3027108311653137
Batch 39/64 loss: 0.298983097076416
Batch 40/64 loss: 0.29843831062316895
Batch 41/64 loss: 0.30097609758377075
Batch 42/64 loss: 0.30055928230285645
Batch 43/64 loss: 0.31385648250579834
Batch 44/64 loss: 0.30734097957611084
Batch 45/64 loss: 0.309717059135437
Batch 46/64 loss: 0.30819106101989746
Batch 47/64 loss: 0.2984082102775574
Batch 48/64 loss: 0.3072052001953125
Batch 49/64 loss: 0.30932629108428955
Batch 50/64 loss: 0.3041127920150757
Batch 51/64 loss: 0.30800384283065796
Batch 52/64 loss: 0.29669296741485596
Batch 53/64 loss: 0.29920172691345215
Batch 54/64 loss: 0.3048574924468994
Batch 55/64 loss: 0.3044578433036804
Batch 56/64 loss: 0.3050307631492615
Batch 57/64 loss: 0.3025575876235962
Batch 58/64 loss: 0.3044712543487549
Batch 59/64 loss: 0.2979375720024109
Batch 60/64 loss: 0.29774218797683716
Batch 61/64 loss: 0.3123612403869629
Batch 62/64 loss: 0.29824376106262207
Batch 63/64 loss: 0.30282098054885864
Batch 64/64 loss: 0.3013685941696167
Epoch 324  Train loss: 0.303087275168475  Val loss: 0.32605838939496334
Saving best model, epoch: 324
Epoch 325
-------------------------------
Batch 1/64 loss: 0.30490434169769287
Batch 2/64 loss: 0.29734373092651367
Batch 3/64 loss: 0.2981293797492981
Batch 4/64 loss: 0.3026266098022461
Batch 5/64 loss: 0.29763340950012207
Batch 6/64 loss: 0.3009253144264221
Batch 7/64 loss: 0.30306005477905273
Batch 8/64 loss: 0.29813051223754883
Batch 9/64 loss: 0.3073684573173523
Batch 10/64 loss: 0.2982064485549927
Batch 11/64 loss: 0.2970705032348633
Batch 12/64 loss: 0.30396586656570435
Batch 13/64 loss: 0.30338066816329956
Batch 14/64 loss: 0.3016538619995117
Batch 15/64 loss: 0.3159382939338684
Batch 16/64 loss: 0.3019742965698242
Batch 17/64 loss: 0.3121277689933777
Batch 18/64 loss: 0.3050825595855713
Batch 19/64 loss: 0.2947431206703186
Batch 20/64 loss: 0.30904340744018555
Batch 21/64 loss: 0.3000146150588989
Batch 22/64 loss: 0.2998150587081909
Batch 23/64 loss: 0.3037012219429016
Batch 24/64 loss: 0.29660189151763916
Batch 25/64 loss: 0.3022674322128296
Batch 26/64 loss: 0.3027011752128601
Batch 27/64 loss: 0.3109353184700012
Batch 28/64 loss: 0.30119752883911133
Batch 29/64 loss: 0.3024325370788574
Batch 30/64 loss: 0.30315887928009033
Batch 31/64 loss: 0.3090382218360901
Batch 32/64 loss: 0.3055986166000366
Batch 33/64 loss: 0.3010925054550171
Batch 34/64 loss: 0.30677878856658936
Batch 35/64 loss: 0.30107277631759644
Batch 36/64 loss: 0.30273300409317017
Batch 37/64 loss: 0.3079330325126648
Batch 38/64 loss: 0.2972082495689392
Batch 39/64 loss: 0.30588650703430176
Batch 40/64 loss: 0.2996335029602051
Batch 41/64 loss: 0.30686336755752563
Batch 42/64 loss: 0.3033560514450073
Batch 43/64 loss: 0.3157370686531067
Batch 44/64 loss: 0.3034103512763977
Batch 45/64 loss: 0.2997572422027588
Batch 46/64 loss: 0.29643702507019043
Batch 47/64 loss: 0.30444371700286865
Batch 48/64 loss: 0.3087724447250366
Batch 49/64 loss: 0.2998582720756531
Batch 50/64 loss: 0.2928966283798218
Batch 51/64 loss: 0.29776787757873535
Batch 52/64 loss: 0.3023255467414856
Batch 53/64 loss: 0.308918833732605
Batch 54/64 loss: 0.30700623989105225
Batch 55/64 loss: 0.3047182559967041
Batch 56/64 loss: 0.3016824722290039
Batch 57/64 loss: 0.30530309677124023
Batch 58/64 loss: 0.30140453577041626
Batch 59/64 loss: 0.3063284754753113
Batch 60/64 loss: 0.3088122606277466
Batch 61/64 loss: 0.3026530146598816
Batch 62/64 loss: 0.29644691944122314
Batch 63/64 loss: 0.30077654123306274
Batch 64/64 loss: 0.3080453872680664
Epoch 325  Train loss: 0.3030559960533591  Val loss: 0.32816825167010333
Epoch 326
-------------------------------
Batch 1/64 loss: 0.2975376844406128
Batch 2/64 loss: 0.3051779866218567
Batch 3/64 loss: 0.2951850891113281
Batch 4/64 loss: 0.297305703163147
Batch 5/64 loss: 0.30248528718948364
Batch 6/64 loss: 0.3023195266723633
Batch 7/64 loss: 0.3092827796936035
Batch 8/64 loss: 0.2981606125831604
Batch 9/64 loss: 0.30308401584625244
Batch 10/64 loss: 0.303962767124176
Batch 11/64 loss: 0.30009543895721436
Batch 12/64 loss: 0.31076669692993164
Batch 13/64 loss: 0.3001331686973572
Batch 14/64 loss: 0.2932891845703125
Batch 15/64 loss: 0.30387866497039795
Batch 16/64 loss: 0.309881329536438
Batch 17/64 loss: 0.2977469563484192
Batch 18/64 loss: 0.2952269911766052
Batch 19/64 loss: 0.3083973526954651
Batch 20/64 loss: 0.30658841133117676
Batch 21/64 loss: 0.30111587047576904
Batch 22/64 loss: 0.29387134313583374
Batch 23/64 loss: 0.31361669301986694
Batch 24/64 loss: 0.29710692167282104
Batch 25/64 loss: 0.305980920791626
Batch 26/64 loss: 0.29408329725265503
Batch 27/64 loss: 0.3010203242301941
Batch 28/64 loss: 0.30817079544067383
Batch 29/64 loss: 0.304262638092041
Batch 30/64 loss: 0.30274122953414917
Batch 31/64 loss: 0.30282390117645264
Batch 32/64 loss: 0.3053785562515259
Batch 33/64 loss: 0.3006199598312378
Batch 34/64 loss: 0.30178624391555786
Batch 35/64 loss: 0.2971036434173584
Batch 36/64 loss: 0.2994612455368042
Batch 37/64 loss: 0.29303455352783203
Batch 38/64 loss: 0.2977791428565979
Batch 39/64 loss: 0.3054547905921936
Batch 40/64 loss: 0.2986716032028198
Batch 41/64 loss: 0.30418384075164795
Batch 42/64 loss: 0.29906994104385376
Batch 43/64 loss: 0.3039177656173706
Batch 44/64 loss: 0.30169814825057983
Batch 45/64 loss: 0.3058973550796509
Batch 46/64 loss: 0.30971163511276245
Batch 47/64 loss: 0.30070263147354126
Batch 48/64 loss: 0.31207287311553955
Batch 49/64 loss: 0.3061187267303467
Batch 50/64 loss: 0.2986191511154175
Batch 51/64 loss: 0.29497218132019043
Batch 52/64 loss: 0.31145572662353516
Batch 53/64 loss: 0.3009052276611328
Batch 54/64 loss: 0.29896724224090576
Batch 55/64 loss: 0.3003292679786682
Batch 56/64 loss: 0.29518163204193115
Batch 57/64 loss: 0.3007427453994751
Batch 58/64 loss: 0.3111346364021301
Batch 59/64 loss: 0.30418622493743896
Batch 60/64 loss: 0.29895448684692383
Batch 61/64 loss: 0.3072469234466553
Batch 62/64 loss: 0.3099439740180969
Batch 63/64 loss: 0.30194395780563354
Batch 64/64 loss: 0.29845714569091797
Epoch 326  Train loss: 0.30221785844541066  Val loss: 0.32846487162449106
Epoch 327
-------------------------------
Batch 1/64 loss: 0.2971404790878296
Batch 2/64 loss: 0.2982335686683655
Batch 3/64 loss: 0.31000781059265137
Batch 4/64 loss: 0.3044997453689575
Batch 5/64 loss: 0.30887800455093384
Batch 6/64 loss: 0.3069111704826355
Batch 7/64 loss: 0.3017446994781494
Batch 8/64 loss: 0.3043096661567688
Batch 9/64 loss: 0.3030959367752075
Batch 10/64 loss: 0.2895275354385376
Batch 11/64 loss: 0.30057084560394287
Batch 12/64 loss: 0.30810606479644775
Batch 13/64 loss: 0.3052072525024414
Batch 14/64 loss: 0.30551040172576904
Batch 15/64 loss: 0.2989761233329773
Batch 16/64 loss: 0.29842865467071533
Batch 17/64 loss: 0.29783153533935547
Batch 18/64 loss: 0.30392277240753174
Batch 19/64 loss: 0.3030741214752197
Batch 20/64 loss: 0.3132505416870117
Batch 21/64 loss: 0.3077346682548523
Batch 22/64 loss: 0.29544734954833984
Batch 23/64 loss: 0.30768609046936035
Batch 24/64 loss: 0.30650484561920166
Batch 25/64 loss: 0.30356138944625854
Batch 26/64 loss: 0.3025270104408264
Batch 27/64 loss: 0.3044329881668091
Batch 28/64 loss: 0.29862868785858154
Batch 29/64 loss: 0.3043819069862366
Batch 30/64 loss: 0.3008803129196167
Batch 31/64 loss: 0.29152023792266846
Batch 32/64 loss: 0.30255401134490967
Batch 33/64 loss: 0.30371618270874023
Batch 34/64 loss: 0.3039918541908264
Batch 35/64 loss: 0.29749608039855957
Batch 36/64 loss: 0.30384087562561035
Batch 37/64 loss: 0.30491435527801514
Batch 38/64 loss: 0.29861992597579956
Batch 39/64 loss: 0.3072859048843384
Batch 40/64 loss: 0.30522680282592773
Batch 41/64 loss: 0.2994786500930786
Batch 42/64 loss: 0.3039616346359253
Batch 43/64 loss: 0.3108829855918884
Batch 44/64 loss: 0.30135655403137207
Batch 45/64 loss: 0.3022523522377014
Batch 46/64 loss: 0.298475980758667
Batch 47/64 loss: 0.3074667453765869
Batch 48/64 loss: 0.29517561197280884
Batch 49/64 loss: 0.3118321895599365
Batch 50/64 loss: 0.29790306091308594
Batch 51/64 loss: 0.30275100469589233
Batch 52/64 loss: 0.2986881732940674
Batch 53/64 loss: 0.30049800872802734
Batch 54/64 loss: 0.29740315675735474
Batch 55/64 loss: 0.3035811185836792
Batch 56/64 loss: 0.302493155002594
Batch 57/64 loss: 0.30086082220077515
Batch 58/64 loss: 0.3029310703277588
Batch 59/64 loss: 0.3055684566497803
Batch 60/64 loss: 0.2993618845939636
Batch 61/64 loss: 0.311948299407959
Batch 62/64 loss: 0.29061710834503174
Batch 63/64 loss: 0.3013342618942261
Batch 64/64 loss: 0.3018401861190796
Epoch 327  Train loss: 0.30248440527448467  Val loss: 0.32826308204546006
Epoch 328
-------------------------------
Batch 1/64 loss: 0.3029879331588745
Batch 2/64 loss: 0.3088337182998657
Batch 3/64 loss: 0.30930227041244507
Batch 4/64 loss: 0.2959815263748169
Batch 5/64 loss: 0.2981468439102173
Batch 6/64 loss: 0.2970097064971924
Batch 7/64 loss: 0.30739903450012207
Batch 8/64 loss: 0.299990177154541
Batch 9/64 loss: 0.30454540252685547
Batch 10/64 loss: 0.30208349227905273
Batch 11/64 loss: 0.29771924018859863
Batch 12/64 loss: 0.29546093940734863
Batch 13/64 loss: 0.2915077805519104
Batch 14/64 loss: 0.2991446256637573
Batch 15/64 loss: 0.30589061975479126
Batch 16/64 loss: 0.3056337833404541
Batch 17/64 loss: 0.30090785026550293
Batch 18/64 loss: 0.2974391579627991
Batch 19/64 loss: 0.2982669472694397
Batch 20/64 loss: 0.29903173446655273
Batch 21/64 loss: 0.30060243606567383
Batch 22/64 loss: 0.29489123821258545
Batch 23/64 loss: 0.29107922315597534
Batch 24/64 loss: 0.3052661418914795
Batch 25/64 loss: 0.30808186531066895
Batch 26/64 loss: 0.3104032874107361
Batch 27/64 loss: 0.30762356519699097
Batch 28/64 loss: 0.30645883083343506
Batch 29/64 loss: 0.30672746896743774
Batch 30/64 loss: 0.3108597993850708
Batch 31/64 loss: 0.30460989475250244
Batch 32/64 loss: 0.3024076223373413
Batch 33/64 loss: 0.3060304522514343
Batch 34/64 loss: 0.31058353185653687
Batch 35/64 loss: 0.30936479568481445
Batch 36/64 loss: 0.3008861541748047
Batch 37/64 loss: 0.30327218770980835
Batch 38/64 loss: 0.3038561940193176
Batch 39/64 loss: 0.3039824962615967
Batch 40/64 loss: 0.30128586292266846
Batch 41/64 loss: 0.308113694190979
Batch 42/64 loss: 0.29749375581741333
Batch 43/64 loss: 0.3068894147872925
Batch 44/64 loss: 0.29485130310058594
Batch 45/64 loss: 0.3115100860595703
Batch 46/64 loss: 0.318195641040802
Batch 47/64 loss: 0.29982566833496094
Batch 48/64 loss: 0.29848384857177734
Batch 49/64 loss: 0.3055095076560974
Batch 50/64 loss: 0.2963660955429077
Batch 51/64 loss: 0.2982748746871948
Batch 52/64 loss: 0.30325061082839966
Batch 53/64 loss: 0.30593228340148926
Batch 54/64 loss: 0.29936033487319946
Batch 55/64 loss: 0.29979270696640015
Batch 56/64 loss: 0.3021278381347656
Batch 57/64 loss: 0.29007136821746826
Batch 58/64 loss: 0.2978605031967163
Batch 59/64 loss: 0.307481050491333
Batch 60/64 loss: 0.3081977367401123
Batch 61/64 loss: 0.2977290749549866
Batch 62/64 loss: 0.30116021633148193
Batch 63/64 loss: 0.30350232124328613
Batch 64/64 loss: 0.30535173416137695
Epoch 328  Train loss: 0.30253411087335325  Val loss: 0.32720970984586734
Epoch 329
-------------------------------
Batch 1/64 loss: 0.2947767972946167
Batch 2/64 loss: 0.30681419372558594
Batch 3/64 loss: 0.2941235303878784
Batch 4/64 loss: 0.29814571142196655
Batch 5/64 loss: 0.303658127784729
Batch 6/64 loss: 0.29782944917678833
Batch 7/64 loss: 0.2978014349937439
Batch 8/64 loss: 0.3018144369125366
Batch 9/64 loss: 0.3000977039337158
Batch 10/64 loss: 0.29904526472091675
Batch 11/64 loss: 0.2955578565597534
Batch 12/64 loss: 0.30334699153900146
Batch 13/64 loss: 0.3000726103782654
Batch 14/64 loss: 0.3065095543861389
Batch 15/64 loss: 0.2981734275817871
Batch 16/64 loss: 0.3011622428894043
Batch 17/64 loss: 0.30800700187683105
Batch 18/64 loss: 0.3030374050140381
Batch 19/64 loss: 0.30029815435409546
Batch 20/64 loss: 0.2993125915527344
Batch 21/64 loss: 0.3075312376022339
Batch 22/64 loss: 0.2975212335586548
Batch 23/64 loss: 0.30148202180862427
Batch 24/64 loss: 0.30862414836883545
Batch 25/64 loss: 0.2995847463607788
Batch 26/64 loss: 0.3014049530029297
Batch 27/64 loss: 0.3023720979690552
Batch 28/64 loss: 0.29358547925949097
Batch 29/64 loss: 0.3011988401412964
Batch 30/64 loss: 0.29964762926101685
Batch 31/64 loss: 0.30295097827911377
Batch 32/64 loss: 0.30214107036590576
Batch 33/64 loss: 0.2949185371398926
Batch 34/64 loss: 0.30208516120910645
Batch 35/64 loss: 0.303899347782135
Batch 36/64 loss: 0.3045274019241333
Batch 37/64 loss: 0.3001142740249634
Batch 38/64 loss: 0.30445945262908936
Batch 39/64 loss: 0.3088666796684265
Batch 40/64 loss: 0.30450117588043213
Batch 41/64 loss: 0.30002933740615845
Batch 42/64 loss: 0.3075411319732666
Batch 43/64 loss: 0.29661208391189575
Batch 44/64 loss: 0.30557018518447876
Batch 45/64 loss: 0.31445538997650146
Batch 46/64 loss: 0.30008453130722046
Batch 47/64 loss: 0.3096346855163574
Batch 48/64 loss: 0.3211604356765747
Batch 49/64 loss: 0.3000359535217285
Batch 50/64 loss: 0.30363428592681885
Batch 51/64 loss: 0.3005589246749878
Batch 52/64 loss: 0.30646878480911255
Batch 53/64 loss: 0.2949899435043335
Batch 54/64 loss: 0.30154359340667725
Batch 55/64 loss: 0.3045670986175537
Batch 56/64 loss: 0.30101656913757324
Batch 57/64 loss: 0.30352216958999634
Batch 58/64 loss: 0.3055539131164551
Batch 59/64 loss: 0.2926550507545471
Batch 60/64 loss: 0.2966468930244446
Batch 61/64 loss: 0.29423534870147705
Batch 62/64 loss: 0.3098994493484497
Batch 63/64 loss: 0.2955804467201233
Batch 64/64 loss: 0.29911601543426514
Epoch 329  Train loss: 0.30182484972710705  Val loss: 0.32639235073758155
Epoch 330
-------------------------------
Batch 1/64 loss: 0.3138108253479004
Batch 2/64 loss: 0.30637896060943604
Batch 3/64 loss: 0.3029865026473999
Batch 4/64 loss: 0.2956277132034302
Batch 5/64 loss: 0.30525755882263184
Batch 6/64 loss: 0.3086426258087158
Batch 7/64 loss: 0.2975846529006958
Batch 8/64 loss: 0.3153795003890991
Batch 9/64 loss: 0.30175650119781494
Batch 10/64 loss: 0.30785512924194336
Batch 11/64 loss: 0.29415249824523926
Batch 12/64 loss: 0.299829363822937
Batch 13/64 loss: 0.3031819462776184
Batch 14/64 loss: 0.2989175319671631
Batch 15/64 loss: 0.29716813564300537
Batch 16/64 loss: 0.3049132823944092
Batch 17/64 loss: 0.30298304557800293
Batch 18/64 loss: 0.29462575912475586
Batch 19/64 loss: 0.29930412769317627
Batch 20/64 loss: 0.3086131811141968
Batch 21/64 loss: 0.2976152300834656
Batch 22/64 loss: 0.29182136058807373
Batch 23/64 loss: 0.3085986375808716
Batch 24/64 loss: 0.3093370199203491
Batch 25/64 loss: 0.2972109913825989
Batch 26/64 loss: 0.30313920974731445
Batch 27/64 loss: 0.30207598209381104
Batch 28/64 loss: 0.3005741834640503
Batch 29/64 loss: 0.30130457878112793
Batch 30/64 loss: 0.3007856607437134
Batch 31/64 loss: 0.30095940828323364
Batch 32/64 loss: 0.3012803792953491
Batch 33/64 loss: 0.30511897802352905
Batch 34/64 loss: 0.30575263500213623
Batch 35/64 loss: 0.29995572566986084
Batch 36/64 loss: 0.30365467071533203
Batch 37/64 loss: 0.29528188705444336
Batch 38/64 loss: 0.2938634157180786
Batch 39/64 loss: 0.30509114265441895
Batch 40/64 loss: 0.3041510581970215
Batch 41/64 loss: 0.2944103479385376
Batch 42/64 loss: 0.2948927879333496
Batch 43/64 loss: 0.29624176025390625
Batch 44/64 loss: 0.2994871735572815
Batch 45/64 loss: 0.3042193651199341
Batch 46/64 loss: 0.304789662361145
Batch 47/64 loss: 0.30358731746673584
Batch 48/64 loss: 0.3014723062515259
Batch 49/64 loss: 0.31445783376693726
Batch 50/64 loss: 0.2925679683685303
Batch 51/64 loss: 0.30663901567459106
Batch 52/64 loss: 0.3031104803085327
Batch 53/64 loss: 0.297199010848999
Batch 54/64 loss: 0.30179131031036377
Batch 55/64 loss: 0.29090332984924316
Batch 56/64 loss: 0.30181246995925903
Batch 57/64 loss: 0.30435824394226074
Batch 58/64 loss: 0.30028867721557617
Batch 59/64 loss: 0.29597896337509155
Batch 60/64 loss: 0.3059096336364746
Batch 61/64 loss: 0.2933698892593384
Batch 62/64 loss: 0.3014777898788452
Batch 63/64 loss: 0.30606698989868164
Batch 64/64 loss: 0.30174410343170166
Epoch 330  Train loss: 0.30161382591023167  Val loss: 0.3277420231566806
Epoch 331
-------------------------------
Batch 1/64 loss: 0.299288809299469
Batch 2/64 loss: 0.30336856842041016
Batch 3/64 loss: 0.3000420928001404
Batch 4/64 loss: 0.3035353422164917
Batch 5/64 loss: 0.30582141876220703
Batch 6/64 loss: 0.3014611005783081
Batch 7/64 loss: 0.3009413480758667
Batch 8/64 loss: 0.2975667715072632
Batch 9/64 loss: 0.30643773078918457
Batch 10/64 loss: 0.30380570888519287
Batch 11/64 loss: 0.30604279041290283
Batch 12/64 loss: 0.2936532497406006
Batch 13/64 loss: 0.3087226152420044
Batch 14/64 loss: 0.3057229518890381
Batch 15/64 loss: 0.3046830892562866
Batch 16/64 loss: 0.30489271879196167
Batch 17/64 loss: 0.30791914463043213
Batch 18/64 loss: 0.30446571111679077
Batch 19/64 loss: 0.2988731861114502
Batch 20/64 loss: 0.3023566007614136
Batch 21/64 loss: 0.2985019087791443
Batch 22/64 loss: 0.29679620265960693
Batch 23/64 loss: 0.3057611584663391
Batch 24/64 loss: 0.3027029037475586
Batch 25/64 loss: 0.304645836353302
Batch 26/64 loss: 0.3073621988296509
Batch 27/64 loss: 0.3036532402038574
Batch 28/64 loss: 0.29976886510849
Batch 29/64 loss: 0.3022015690803528
Batch 30/64 loss: 0.3070566654205322
Batch 31/64 loss: 0.2964470386505127
Batch 32/64 loss: 0.2992224097251892
Batch 33/64 loss: 0.30423521995544434
Batch 34/64 loss: 0.29741203784942627
Batch 35/64 loss: 0.2941269278526306
Batch 36/64 loss: 0.31010663509368896
Batch 37/64 loss: 0.29949045181274414
Batch 38/64 loss: 0.2997325658798218
Batch 39/64 loss: 0.2939804792404175
Batch 40/64 loss: 0.31150174140930176
Batch 41/64 loss: 0.3001992702484131
Batch 42/64 loss: 0.293994665145874
Batch 43/64 loss: 0.30284959077835083
Batch 44/64 loss: 0.29912275075912476
Batch 45/64 loss: 0.3039790987968445
Batch 46/64 loss: 0.3015778064727783
Batch 47/64 loss: 0.31065261363983154
Batch 48/64 loss: 0.28959810733795166
Batch 49/64 loss: 0.3004392981529236
Batch 50/64 loss: 0.2980377674102783
Batch 51/64 loss: 0.3054162859916687
Batch 52/64 loss: 0.3037404417991638
Batch 53/64 loss: 0.29249107837677
Batch 54/64 loss: 0.3070727586746216
Batch 55/64 loss: 0.30226004123687744
Batch 56/64 loss: 0.30149298906326294
Batch 57/64 loss: 0.30238407850265503
Batch 58/64 loss: 0.29185187816619873
Batch 59/64 loss: 0.29970717430114746
Batch 60/64 loss: 0.2977733612060547
Batch 61/64 loss: 0.30248790979385376
Batch 62/64 loss: 0.3118525743484497
Batch 63/64 loss: 0.290708065032959
Batch 64/64 loss: 0.3116178512573242
Epoch 331  Train loss: 0.3017679999856388  Val loss: 0.327210593879018
Epoch 332
-------------------------------
Batch 1/64 loss: 0.2973487377166748
Batch 2/64 loss: 0.3098818063735962
Batch 3/64 loss: 0.30083781480789185
Batch 4/64 loss: 0.30004942417144775
Batch 5/64 loss: 0.30011337995529175
Batch 6/64 loss: 0.3026922941207886
Batch 7/64 loss: 0.3036755323410034
Batch 8/64 loss: 0.3048033118247986
Batch 9/64 loss: 0.29696452617645264
Batch 10/64 loss: 0.3083353042602539
Batch 11/64 loss: 0.3102096915245056
Batch 12/64 loss: 0.2968170642852783
Batch 13/64 loss: 0.3102961778640747
Batch 14/64 loss: 0.29730600118637085
Batch 15/64 loss: 0.29511594772338867
Batch 16/64 loss: 0.3100268840789795
Batch 17/64 loss: 0.29755067825317383
Batch 18/64 loss: 0.29472577571868896
Batch 19/64 loss: 0.3049112558364868
Batch 20/64 loss: 0.2969217300415039
Batch 21/64 loss: 0.2994171380996704
Batch 22/64 loss: 0.2982369661331177
Batch 23/64 loss: 0.2951894998550415
Batch 24/64 loss: 0.29331374168395996
Batch 25/64 loss: 0.29889023303985596
Batch 26/64 loss: 0.2964968681335449
Batch 27/64 loss: 0.29789894819259644
Batch 28/64 loss: 0.308285653591156
Batch 29/64 loss: 0.3108707666397095
Batch 30/64 loss: 0.3082681894302368
Batch 31/64 loss: 0.3013201951980591
Batch 32/64 loss: 0.30148565769195557
Batch 33/64 loss: 0.3032064437866211
Batch 34/64 loss: 0.29534822702407837
Batch 35/64 loss: 0.30240094661712646
Batch 36/64 loss: 0.3071444034576416
Batch 37/64 loss: 0.29423993825912476
Batch 38/64 loss: 0.30197250843048096
Batch 39/64 loss: 0.30180156230926514
Batch 40/64 loss: 0.3091980218887329
Batch 41/64 loss: 0.294330358505249
Batch 42/64 loss: 0.3023529052734375
Batch 43/64 loss: 0.30689966678619385
Batch 44/64 loss: 0.3039247989654541
Batch 45/64 loss: 0.29809725284576416
Batch 46/64 loss: 0.2992202639579773
Batch 47/64 loss: 0.30206072330474854
Batch 48/64 loss: 0.3058580160140991
Batch 49/64 loss: 0.29873502254486084
Batch 50/64 loss: 0.2967382073402405
Batch 51/64 loss: 0.2917572855949402
Batch 52/64 loss: 0.29963934421539307
Batch 53/64 loss: 0.3048133850097656
Batch 54/64 loss: 0.30302441120147705
Batch 55/64 loss: 0.30655014514923096
Batch 56/64 loss: 0.3060792088508606
Batch 57/64 loss: 0.29772377014160156
Batch 58/64 loss: 0.30008912086486816
Batch 59/64 loss: 0.3033558130264282
Batch 60/64 loss: 0.3098323345184326
Batch 61/64 loss: 0.3033882975578308
Batch 62/64 loss: 0.30956774950027466
Batch 63/64 loss: 0.296828031539917
Batch 64/64 loss: 0.3111438751220703
Epoch 332  Train loss: 0.3017693061454623  Val loss: 0.3268886231065206
Epoch 333
-------------------------------
Batch 1/64 loss: 0.2956134080886841
Batch 2/64 loss: 0.29817450046539307
Batch 3/64 loss: 0.3048630952835083
Batch 4/64 loss: 0.3095346689224243
Batch 5/64 loss: 0.3002408742904663
Batch 6/64 loss: 0.2985607385635376
Batch 7/64 loss: 0.30423223972320557
Batch 8/64 loss: 0.30093955993652344
Batch 9/64 loss: 0.3020642399787903
Batch 10/64 loss: 0.30454277992248535
Batch 11/64 loss: 0.3079864978790283
Batch 12/64 loss: 0.29846644401550293
Batch 13/64 loss: 0.2969859838485718
Batch 14/64 loss: 0.2941166162490845
Batch 15/64 loss: 0.2958047389984131
Batch 16/64 loss: 0.29925405979156494
Batch 17/64 loss: 0.29967617988586426
Batch 18/64 loss: 0.29240167140960693
Batch 19/64 loss: 0.3085472583770752
Batch 20/64 loss: 0.30356860160827637
Batch 21/64 loss: 0.2984195947647095
Batch 22/64 loss: 0.3057343363761902
Batch 23/64 loss: 0.30326271057128906
Batch 24/64 loss: 0.3102852702140808
Batch 25/64 loss: 0.29883337020874023
Batch 26/64 loss: 0.2946099638938904
Batch 27/64 loss: 0.3056497573852539
Batch 28/64 loss: 0.30431342124938965
Batch 29/64 loss: 0.30205684900283813
Batch 30/64 loss: 0.30380094051361084
Batch 31/64 loss: 0.3024477958679199
Batch 32/64 loss: 0.2949456572532654
Batch 33/64 loss: 0.29348063468933105
Batch 34/64 loss: 0.29751622676849365
Batch 35/64 loss: 0.29748404026031494
Batch 36/64 loss: 0.29402029514312744
Batch 37/64 loss: 0.3110368847846985
Batch 38/64 loss: 0.30642902851104736
Batch 39/64 loss: 0.3047786355018616
Batch 40/64 loss: 0.3065049648284912
Batch 41/64 loss: 0.30486440658569336
Batch 42/64 loss: 0.3059426546096802
Batch 43/64 loss: 0.3021036386489868
Batch 44/64 loss: 0.30996716022491455
Batch 45/64 loss: 0.3047732710838318
Batch 46/64 loss: 0.2999159097671509
Batch 47/64 loss: 0.3044707775115967
Batch 48/64 loss: 0.309723436832428
Batch 49/64 loss: 0.30581140518188477
Batch 50/64 loss: 0.29310131072998047
Batch 51/64 loss: 0.3004927635192871
Batch 52/64 loss: 0.3036312460899353
Batch 53/64 loss: 0.3050183057785034
Batch 54/64 loss: 0.298844575881958
Batch 55/64 loss: 0.2963772416114807
Batch 56/64 loss: 0.2999037504196167
Batch 57/64 loss: 0.29571372270584106
Batch 58/64 loss: 0.2950553894042969
Batch 59/64 loss: 0.3091370463371277
Batch 60/64 loss: 0.29839378595352173
Batch 61/64 loss: 0.305972158908844
Batch 62/64 loss: 0.29850006103515625
Batch 63/64 loss: 0.29835283756256104
Batch 64/64 loss: 0.2998080849647522
Epoch 333  Train loss: 0.30152325419818654  Val loss: 0.3267555417064129
Epoch 334
-------------------------------
Batch 1/64 loss: 0.29813140630722046
Batch 2/64 loss: 0.3048180937767029
Batch 3/64 loss: 0.2934721112251282
Batch 4/64 loss: 0.2939494848251343
Batch 5/64 loss: 0.30175352096557617
Batch 6/64 loss: 0.3033062219619751
Batch 7/64 loss: 0.30200958251953125
Batch 8/64 loss: 0.2967503070831299
Batch 9/64 loss: 0.301965594291687
Batch 10/64 loss: 0.2959721088409424
Batch 11/64 loss: 0.30204546451568604
Batch 12/64 loss: 0.2969549894332886
Batch 13/64 loss: 0.30539119243621826
Batch 14/64 loss: 0.2984161376953125
Batch 15/64 loss: 0.30241233110427856
Batch 16/64 loss: 0.3064391613006592
Batch 17/64 loss: 0.3054969906806946
Batch 18/64 loss: 0.3009672164916992
Batch 19/64 loss: 0.30660319328308105
Batch 20/64 loss: 0.30385351181030273
Batch 21/64 loss: 0.31011760234832764
Batch 22/64 loss: 0.30422312021255493
Batch 23/64 loss: 0.3003461956977844
Batch 24/64 loss: 0.30044251680374146
Batch 25/64 loss: 0.3035905957221985
Batch 26/64 loss: 0.3023070693016052
Batch 27/64 loss: 0.30273592472076416
Batch 28/64 loss: 0.3005828857421875
Batch 29/64 loss: 0.29866117238998413
Batch 30/64 loss: 0.30017828941345215
Batch 31/64 loss: 0.3045787811279297
Batch 32/64 loss: 0.3014838695526123
Batch 33/64 loss: 0.2945570945739746
Batch 34/64 loss: 0.3073744773864746
Batch 35/64 loss: 0.31171363592147827
Batch 36/64 loss: 0.30262279510498047
Batch 37/64 loss: 0.3040223717689514
Batch 38/64 loss: 0.30268263816833496
Batch 39/64 loss: 0.3021697998046875
Batch 40/64 loss: 0.2930735945701599
Batch 41/64 loss: 0.2968243360519409
Batch 42/64 loss: 0.3085058331489563
Batch 43/64 loss: 0.3015432357788086
Batch 44/64 loss: 0.2998371720314026
Batch 45/64 loss: 0.2951894998550415
Batch 46/64 loss: 0.3032712936401367
Batch 47/64 loss: 0.2996559143066406
Batch 48/64 loss: 0.3056179881095886
Batch 49/64 loss: 0.3047296404838562
Batch 50/64 loss: 0.29944348335266113
Batch 51/64 loss: 0.308796226978302
Batch 52/64 loss: 0.28529512882232666
Batch 53/64 loss: 0.2960361838340759
Batch 54/64 loss: 0.2994312047958374
Batch 55/64 loss: 0.29643601179122925
Batch 56/64 loss: 0.288260817527771
Batch 57/64 loss: 0.3069338798522949
Batch 58/64 loss: 0.30643314123153687
Batch 59/64 loss: 0.2985408306121826
Batch 60/64 loss: 0.29869067668914795
Batch 61/64 loss: 0.3051537275314331
Batch 62/64 loss: 0.3003876209259033
Batch 63/64 loss: 0.29805856943130493
Batch 64/64 loss: 0.3023257255554199
Epoch 334  Train loss: 0.3011449374404608  Val loss: 0.32945860005735944
Epoch 335
-------------------------------
Batch 1/64 loss: 0.3009710907936096
Batch 2/64 loss: 0.30468952655792236
Batch 3/64 loss: 0.3007000684738159
Batch 4/64 loss: 0.30184078216552734
Batch 5/64 loss: 0.302858829498291
Batch 6/64 loss: 0.2956826686859131
Batch 7/64 loss: 0.2982468605041504
Batch 8/64 loss: 0.2997159957885742
Batch 9/64 loss: 0.2939785122871399
Batch 10/64 loss: 0.29586589336395264
Batch 11/64 loss: 0.29943251609802246
Batch 12/64 loss: 0.2897539734840393
Batch 13/64 loss: 0.30475038290023804
Batch 14/64 loss: 0.30435609817504883
Batch 15/64 loss: 0.3002088665962219
Batch 16/64 loss: 0.3058290481567383
Batch 17/64 loss: 0.30964118242263794
Batch 18/64 loss: 0.3044702410697937
Batch 19/64 loss: 0.2908709645271301
Batch 20/64 loss: 0.30329251289367676
Batch 21/64 loss: 0.29992079734802246
Batch 22/64 loss: 0.2989645004272461
Batch 23/64 loss: 0.3045215606689453
Batch 24/64 loss: 0.2971642017364502
Batch 25/64 loss: 0.29724442958831787
Batch 26/64 loss: 0.30174916982650757
Batch 27/64 loss: 0.3067668676376343
Batch 28/64 loss: 0.3035445213317871
Batch 29/64 loss: 0.30520099401474
Batch 30/64 loss: 0.3007977604866028
Batch 31/64 loss: 0.30108165740966797
Batch 32/64 loss: 0.30840611457824707
Batch 33/64 loss: 0.29837363958358765
Batch 34/64 loss: 0.29774224758148193
Batch 35/64 loss: 0.29949718713760376
Batch 36/64 loss: 0.30418860912323
Batch 37/64 loss: 0.30343425273895264
Batch 38/64 loss: 0.2988768219947815
Batch 39/64 loss: 0.29476720094680786
Batch 40/64 loss: 0.2947874069213867
Batch 41/64 loss: 0.31306493282318115
Batch 42/64 loss: 0.3044929504394531
Batch 43/64 loss: 0.29708898067474365
Batch 44/64 loss: 0.3051726818084717
Batch 45/64 loss: 0.30493873357772827
Batch 46/64 loss: 0.30797868967056274
Batch 47/64 loss: 0.30204999446868896
Batch 48/64 loss: 0.29146432876586914
Batch 49/64 loss: 0.3068976402282715
Batch 50/64 loss: 0.30559098720550537
Batch 51/64 loss: 0.2982027530670166
Batch 52/64 loss: 0.30290257930755615
Batch 53/64 loss: 0.30891501903533936
Batch 54/64 loss: 0.2984408736228943
Batch 55/64 loss: 0.30267828702926636
Batch 56/64 loss: 0.29524314403533936
Batch 57/64 loss: 0.2891889214515686
Batch 58/64 loss: 0.2983909249305725
Batch 59/64 loss: 0.3051144480705261
Batch 60/64 loss: 0.29980069398880005
Batch 61/64 loss: 0.3055199384689331
Batch 62/64 loss: 0.30659401416778564
Batch 63/64 loss: 0.29340922832489014
Batch 64/64 loss: 0.3125920295715332
Epoch 335  Train loss: 0.30120424663319306  Val loss: 0.325981602021509
Saving best model, epoch: 335
Epoch 336
-------------------------------
Batch 1/64 loss: 0.2988966703414917
Batch 2/64 loss: 0.29507017135620117
Batch 3/64 loss: 0.2976090908050537
Batch 4/64 loss: 0.3108243942260742
Batch 5/64 loss: 0.3022921085357666
Batch 6/64 loss: 0.30821919441223145
Batch 7/64 loss: 0.2991604804992676
Batch 8/64 loss: 0.29717737436294556
Batch 9/64 loss: 0.3008517026901245
Batch 10/64 loss: 0.30618762969970703
Batch 11/64 loss: 0.30800706148147583
Batch 12/64 loss: 0.3038044571876526
Batch 13/64 loss: 0.29749011993408203
Batch 14/64 loss: 0.29525089263916016
Batch 15/64 loss: 0.30423688888549805
Batch 16/64 loss: 0.29591095447540283
Batch 17/64 loss: 0.29957568645477295
Batch 18/64 loss: 0.30873894691467285
Batch 19/64 loss: 0.29993700981140137
Batch 20/64 loss: 0.2980339527130127
Batch 21/64 loss: 0.29840171337127686
Batch 22/64 loss: 0.29608672857284546
Batch 23/64 loss: 0.29788529872894287
Batch 24/64 loss: 0.2942686080932617
Batch 25/64 loss: 0.2999534606933594
Batch 26/64 loss: 0.29803717136383057
Batch 27/64 loss: 0.3003625273704529
Batch 28/64 loss: 0.29972171783447266
Batch 29/64 loss: 0.30267465114593506
Batch 30/64 loss: 0.29820746183395386
Batch 31/64 loss: 0.29579466581344604
Batch 32/64 loss: 0.306523859500885
Batch 33/64 loss: 0.3008142113685608
Batch 34/64 loss: 0.3000633716583252
Batch 35/64 loss: 0.30402714014053345
Batch 36/64 loss: 0.2963294982910156
Batch 37/64 loss: 0.29955124855041504
Batch 38/64 loss: 0.3041146993637085
Batch 39/64 loss: 0.303882360458374
Batch 40/64 loss: 0.2932414412498474
Batch 41/64 loss: 0.30072033405303955
Batch 42/64 loss: 0.3001319169998169
Batch 43/64 loss: 0.300429105758667
Batch 44/64 loss: 0.2961139678955078
Batch 45/64 loss: 0.29774898290634155
Batch 46/64 loss: 0.28799980878829956
Batch 47/64 loss: 0.2990930676460266
Batch 48/64 loss: 0.29997503757476807
Batch 49/64 loss: 0.2930186986923218
Batch 50/64 loss: 0.2976645231246948
Batch 51/64 loss: 0.3045448660850525
Batch 52/64 loss: 0.31260615587234497
Batch 53/64 loss: 0.31659090518951416
Batch 54/64 loss: 0.3012697100639343
Batch 55/64 loss: 0.3021634817123413
Batch 56/64 loss: 0.30532169342041016
Batch 57/64 loss: 0.2995995879173279
Batch 58/64 loss: 0.2979053258895874
Batch 59/64 loss: 0.3029055595397949
Batch 60/64 loss: 0.3164050579071045
Batch 61/64 loss: 0.30264341831207275
Batch 62/64 loss: 0.31600964069366455
Batch 63/64 loss: 0.29922688007354736
Batch 64/64 loss: 0.3028998374938965
Epoch 336  Train loss: 0.3010898702284869  Val loss: 0.32606315735689145
Epoch 337
-------------------------------
Batch 1/64 loss: 0.30593252182006836
Batch 2/64 loss: 0.3002769351005554
Batch 3/64 loss: 0.29749923944473267
Batch 4/64 loss: 0.3101832866668701
Batch 5/64 loss: 0.3115147352218628
Batch 6/64 loss: 0.30821776390075684
Batch 7/64 loss: 0.30433863401412964
Batch 8/64 loss: 0.3024580478668213
Batch 9/64 loss: 0.28639137744903564
Batch 10/64 loss: 0.3033132553100586
Batch 11/64 loss: 0.3049333095550537
Batch 12/64 loss: 0.3033825159072876
Batch 13/64 loss: 0.2980048656463623
Batch 14/64 loss: 0.2913280725479126
Batch 15/64 loss: 0.30117613077163696
Batch 16/64 loss: 0.3016577959060669
Batch 17/64 loss: 0.2992570400238037
Batch 18/64 loss: 0.30403828620910645
Batch 19/64 loss: 0.30090343952178955
Batch 20/64 loss: 0.2992832660675049
Batch 21/64 loss: 0.2939528226852417
Batch 22/64 loss: 0.2915990948677063
Batch 23/64 loss: 0.3039780855178833
Batch 24/64 loss: 0.2974066138267517
Batch 25/64 loss: 0.2959936261177063
Batch 26/64 loss: 0.30300188064575195
Batch 27/64 loss: 0.29913854598999023
Batch 28/64 loss: 0.29674768447875977
Batch 29/64 loss: 0.31040000915527344
Batch 30/64 loss: 0.2942005395889282
Batch 31/64 loss: 0.2998150587081909
Batch 32/64 loss: 0.29763519763946533
Batch 33/64 loss: 0.2971891164779663
Batch 34/64 loss: 0.3008049726486206
Batch 35/64 loss: 0.30186522006988525
Batch 36/64 loss: 0.30010712146759033
Batch 37/64 loss: 0.3168708086013794
Batch 38/64 loss: 0.3034440279006958
Batch 39/64 loss: 0.2995094060897827
Batch 40/64 loss: 0.29714304208755493
Batch 41/64 loss: 0.30481159687042236
Batch 42/64 loss: 0.2984495162963867
Batch 43/64 loss: 0.31139183044433594
Batch 44/64 loss: 0.3049923777580261
Batch 45/64 loss: 0.29981082677841187
Batch 46/64 loss: 0.2971062660217285
Batch 47/64 loss: 0.2921408414840698
Batch 48/64 loss: 0.30054450035095215
Batch 49/64 loss: 0.3008338212966919
Batch 50/64 loss: 0.3060702085494995
Batch 51/64 loss: 0.30063843727111816
Batch 52/64 loss: 0.2987295389175415
Batch 53/64 loss: 0.29962360858917236
Batch 54/64 loss: 0.30573123693466187
Batch 55/64 loss: 0.298667311668396
Batch 56/64 loss: 0.3044278621673584
Batch 57/64 loss: 0.2987915277481079
Batch 58/64 loss: 0.2989957332611084
Batch 59/64 loss: 0.2926561236381531
Batch 60/64 loss: 0.2998431921005249
Batch 61/64 loss: 0.2976762056350708
Batch 62/64 loss: 0.30062758922576904
Batch 63/64 loss: 0.3020607829093933
Batch 64/64 loss: 0.29963040351867676
Epoch 337  Train loss: 0.3007723471697639  Val loss: 0.3256297824309044
Saving best model, epoch: 337
Epoch 338
-------------------------------
Batch 1/64 loss: 0.30032968521118164
Batch 2/64 loss: 0.30478721857070923
Batch 3/64 loss: 0.297027587890625
Batch 4/64 loss: 0.3032323122024536
Batch 5/64 loss: 0.28877079486846924
Batch 6/64 loss: 0.2999460697174072
Batch 7/64 loss: 0.29590994119644165
Batch 8/64 loss: 0.29443836212158203
Batch 9/64 loss: 0.2989444136619568
Batch 10/64 loss: 0.3002607822418213
Batch 11/64 loss: 0.2992546558380127
Batch 12/64 loss: 0.30913811922073364
Batch 13/64 loss: 0.29476678371429443
Batch 14/64 loss: 0.3066953420639038
Batch 15/64 loss: 0.3000909090042114
Batch 16/64 loss: 0.293270468711853
Batch 17/64 loss: 0.3014453649520874
Batch 18/64 loss: 0.2984834909439087
Batch 19/64 loss: 0.29939353466033936
Batch 20/64 loss: 0.30451053380966187
Batch 21/64 loss: 0.29982686042785645
Batch 22/64 loss: 0.2942667007446289
Batch 23/64 loss: 0.3060097098350525
Batch 24/64 loss: 0.3155500888824463
Batch 25/64 loss: 0.2951256036758423
Batch 26/64 loss: 0.30149632692337036
Batch 27/64 loss: 0.2962639331817627
Batch 28/64 loss: 0.29175513982772827
Batch 29/64 loss: 0.3016829490661621
Batch 30/64 loss: 0.300082802772522
Batch 31/64 loss: 0.30184781551361084
Batch 32/64 loss: 0.294376015663147
Batch 33/64 loss: 0.3051565885543823
Batch 34/64 loss: 0.296905517578125
Batch 35/64 loss: 0.3009662628173828
Batch 36/64 loss: 0.30554819107055664
Batch 37/64 loss: 0.2909768223762512
Batch 38/64 loss: 0.3041752576828003
Batch 39/64 loss: 0.31154125928878784
Batch 40/64 loss: 0.2888256907463074
Batch 41/64 loss: 0.2947511672973633
Batch 42/64 loss: 0.3065309524536133
Batch 43/64 loss: 0.31333065032958984
Batch 44/64 loss: 0.29701757431030273
Batch 45/64 loss: 0.30632340908050537
Batch 46/64 loss: 0.29844748973846436
Batch 47/64 loss: 0.30370593070983887
Batch 48/64 loss: 0.2929724454879761
Batch 49/64 loss: 0.30961132049560547
Batch 50/64 loss: 0.29844892024993896
Batch 51/64 loss: 0.2959370017051697
Batch 52/64 loss: 0.29658693075180054
Batch 53/64 loss: 0.3073747754096985
Batch 54/64 loss: 0.29496657848358154
Batch 55/64 loss: 0.3031700849533081
Batch 56/64 loss: 0.30385255813598633
Batch 57/64 loss: 0.2997859716415405
Batch 58/64 loss: 0.28911811113357544
Batch 59/64 loss: 0.3020249009132385
Batch 60/64 loss: 0.30399900674819946
Batch 61/64 loss: 0.30729198455810547
Batch 62/64 loss: 0.3032507300376892
Batch 63/64 loss: 0.3076293468475342
Batch 64/64 loss: 0.29950475692749023
Epoch 338  Train loss: 0.3004522716297823  Val loss: 0.32634703133933735
Epoch 339
-------------------------------
Batch 1/64 loss: 0.2922801971435547
Batch 2/64 loss: 0.29540860652923584
Batch 3/64 loss: 0.3030890226364136
Batch 4/64 loss: 0.2964400053024292
Batch 5/64 loss: 0.31107544898986816
Batch 6/64 loss: 0.30011212825775146
Batch 7/64 loss: 0.29244959354400635
Batch 8/64 loss: 0.29288995265960693
Batch 9/64 loss: 0.3017847537994385
Batch 10/64 loss: 0.3033708930015564
Batch 11/64 loss: 0.30080652236938477
Batch 12/64 loss: 0.29169386625289917
Batch 13/64 loss: 0.30863893032073975
Batch 14/64 loss: 0.301577627658844
Batch 15/64 loss: 0.3009822368621826
Batch 16/64 loss: 0.29978108406066895
Batch 17/64 loss: 0.30319470167160034
Batch 18/64 loss: 0.3100929260253906
Batch 19/64 loss: 0.30525028705596924
Batch 20/64 loss: 0.2966597080230713
Batch 21/64 loss: 0.2948976755142212
Batch 22/64 loss: 0.309307336807251
Batch 23/64 loss: 0.3029669523239136
Batch 24/64 loss: 0.30079567432403564
Batch 25/64 loss: 0.3020036220550537
Batch 26/64 loss: 0.2961556911468506
Batch 27/64 loss: 0.2990933656692505
Batch 28/64 loss: 0.3023529052734375
Batch 29/64 loss: 0.297008216381073
Batch 30/64 loss: 0.30199992656707764
Batch 31/64 loss: 0.29211878776550293
Batch 32/64 loss: 0.297859251499176
Batch 33/64 loss: 0.2995469570159912
Batch 34/64 loss: 0.3015333414077759
Batch 35/64 loss: 0.2991679906845093
Batch 36/64 loss: 0.30560219287872314
Batch 37/64 loss: 0.2908022403717041
Batch 38/64 loss: 0.2970307469367981
Batch 39/64 loss: 0.3031967878341675
Batch 40/64 loss: 0.30128931999206543
Batch 41/64 loss: 0.28910666704177856
Batch 42/64 loss: 0.2973397970199585
Batch 43/64 loss: 0.30117011070251465
Batch 44/64 loss: 0.29878151416778564
Batch 45/64 loss: 0.292422890663147
Batch 46/64 loss: 0.29980289936065674
Batch 47/64 loss: 0.29942333698272705
Batch 48/64 loss: 0.3149750232696533
Batch 49/64 loss: 0.2967759370803833
Batch 50/64 loss: 0.2984173893928528
Batch 51/64 loss: 0.3082345128059387
Batch 52/64 loss: 0.29780781269073486
Batch 53/64 loss: 0.30045366287231445
Batch 54/64 loss: 0.3000239133834839
Batch 55/64 loss: 0.3033050298690796
Batch 56/64 loss: 0.31266945600509644
Batch 57/64 loss: 0.3033466339111328
Batch 58/64 loss: 0.30693137645721436
Batch 59/64 loss: 0.3073267936706543
Batch 60/64 loss: 0.2966247797012329
Batch 61/64 loss: 0.2986658215522766
Batch 62/64 loss: 0.303725004196167
Batch 63/64 loss: 0.29625403881073
Batch 64/64 loss: 0.2974635362625122
Epoch 339  Train loss: 0.300376306328119  Val loss: 0.32744391800202044
Epoch 340
-------------------------------
Batch 1/64 loss: 0.29366350173950195
Batch 2/64 loss: 0.30054140090942383
Batch 3/64 loss: 0.2975858449935913
Batch 4/64 loss: 0.3011438846588135
Batch 5/64 loss: 0.30633842945098877
Batch 6/64 loss: 0.2980085611343384
Batch 7/64 loss: 0.28913986682891846
Batch 8/64 loss: 0.30683672428131104
Batch 9/64 loss: 0.2978023290634155
Batch 10/64 loss: 0.29046499729156494
Batch 11/64 loss: 0.29624372720718384
Batch 12/64 loss: 0.2997128963470459
Batch 13/64 loss: 0.30897998809814453
Batch 14/64 loss: 0.30596351623535156
Batch 15/64 loss: 0.3083001375198364
Batch 16/64 loss: 0.2997649908065796
Batch 17/64 loss: 0.2968478202819824
Batch 18/64 loss: 0.29916203022003174
Batch 19/64 loss: 0.30175745487213135
Batch 20/64 loss: 0.3040198087692261
Batch 21/64 loss: 0.29367995262145996
Batch 22/64 loss: 0.3009212017059326
Batch 23/64 loss: 0.2898322343826294
Batch 24/64 loss: 0.2998042702674866
Batch 25/64 loss: 0.2982175350189209
Batch 26/64 loss: 0.2981317639350891
Batch 27/64 loss: 0.3112591505050659
Batch 28/64 loss: 0.3007088899612427
Batch 29/64 loss: 0.29929208755493164
Batch 30/64 loss: 0.2999904155731201
Batch 31/64 loss: 0.305922269821167
Batch 32/64 loss: 0.286288857460022
Batch 33/64 loss: 0.28900450468063354
Batch 34/64 loss: 0.299358069896698
Batch 35/64 loss: 0.29445719718933105
Batch 36/64 loss: 0.3060767650604248
Batch 37/64 loss: 0.29788094758987427
Batch 38/64 loss: 0.3018568754196167
Batch 39/64 loss: 0.2973041534423828
Batch 40/64 loss: 0.29499971866607666
Batch 41/64 loss: 0.3027658462524414
Batch 42/64 loss: 0.3041163682937622
Batch 43/64 loss: 0.29431915283203125
Batch 44/64 loss: 0.30191826820373535
Batch 45/64 loss: 0.30124175548553467
Batch 46/64 loss: 0.3056100606918335
Batch 47/64 loss: 0.304645836353302
Batch 48/64 loss: 0.305972695350647
Batch 49/64 loss: 0.3062267303466797
Batch 50/64 loss: 0.2932109832763672
Batch 51/64 loss: 0.2966870069503784
Batch 52/64 loss: 0.29920458793640137
Batch 53/64 loss: 0.29396355152130127
Batch 54/64 loss: 0.29868555068969727
Batch 55/64 loss: 0.2982903718948364
Batch 56/64 loss: 0.31619882583618164
Batch 57/64 loss: 0.30038291215896606
Batch 58/64 loss: 0.2930854558944702
Batch 59/64 loss: 0.3005859851837158
Batch 60/64 loss: 0.29375553131103516
Batch 61/64 loss: 0.29959869384765625
Batch 62/64 loss: 0.30710387229919434
Batch 63/64 loss: 0.30978119373321533
Batch 64/64 loss: 0.3034151792526245
Epoch 340  Train loss: 0.2999557237999112  Val loss: 0.3268979251179908
Epoch 341
-------------------------------
Batch 1/64 loss: 0.3011592626571655
Batch 2/64 loss: 0.30144762992858887
Batch 3/64 loss: 0.30647921562194824
Batch 4/64 loss: 0.295261025428772
Batch 5/64 loss: 0.3065394163131714
Batch 6/64 loss: 0.30042046308517456
Batch 7/64 loss: 0.29588836431503296
Batch 8/64 loss: 0.30195194482803345
Batch 9/64 loss: 0.3027855157852173
Batch 10/64 loss: 0.29971957206726074
Batch 11/64 loss: 0.3007884621620178
Batch 12/64 loss: 0.2957853078842163
Batch 13/64 loss: 0.3047928810119629
Batch 14/64 loss: 0.30777716636657715
Batch 15/64 loss: 0.295740008354187
Batch 16/64 loss: 0.3026270866394043
Batch 17/64 loss: 0.30301129817962646
Batch 18/64 loss: 0.292400598526001
Batch 19/64 loss: 0.3076091408729553
Batch 20/64 loss: 0.2976398468017578
Batch 21/64 loss: 0.29415225982666016
Batch 22/64 loss: 0.29168057441711426
Batch 23/64 loss: 0.30095332860946655
Batch 24/64 loss: 0.3016536235809326
Batch 25/64 loss: 0.2996736764907837
Batch 26/64 loss: 0.3010878562927246
Batch 27/64 loss: 0.2941824197769165
Batch 28/64 loss: 0.30186891555786133
Batch 29/64 loss: 0.308221697807312
Batch 30/64 loss: 0.2954068183898926
Batch 31/64 loss: 0.2939753532409668
Batch 32/64 loss: 0.3034912347793579
Batch 33/64 loss: 0.2959601879119873
Batch 34/64 loss: 0.3063761591911316
Batch 35/64 loss: 0.28691941499710083
Batch 36/64 loss: 0.2950078845024109
Batch 37/64 loss: 0.2969592809677124
Batch 38/64 loss: 0.2990725040435791
Batch 39/64 loss: 0.30309754610061646
Batch 40/64 loss: 0.2955755591392517
Batch 41/64 loss: 0.29617244005203247
Batch 42/64 loss: 0.30032408237457275
Batch 43/64 loss: 0.30019325017929077
Batch 44/64 loss: 0.3075045347213745
Batch 45/64 loss: 0.2919609546661377
Batch 46/64 loss: 0.2971741557121277
Batch 47/64 loss: 0.29258888959884644
Batch 48/64 loss: 0.30902230739593506
Batch 49/64 loss: 0.3062025308609009
Batch 50/64 loss: 0.3040773868560791
Batch 51/64 loss: 0.29803216457366943
Batch 52/64 loss: 0.29585355520248413
Batch 53/64 loss: 0.30994713306427
Batch 54/64 loss: 0.29408055543899536
Batch 55/64 loss: 0.29705196619033813
Batch 56/64 loss: 0.295793354511261
Batch 57/64 loss: 0.30394697189331055
Batch 58/64 loss: 0.2980537414550781
Batch 59/64 loss: 0.3032442331314087
Batch 60/64 loss: 0.3030528426170349
Batch 61/64 loss: 0.30079197883605957
Batch 62/64 loss: 0.30547797679901123
Batch 63/64 loss: 0.3144572973251343
Batch 64/64 loss: 0.3051367402076721
Epoch 341  Train loss: 0.3002195664480621  Val loss: 0.3255671783001562
Saving best model, epoch: 341
Epoch 342
-------------------------------
Batch 1/64 loss: 0.3031437397003174
Batch 2/64 loss: 0.29285454750061035
Batch 3/64 loss: 0.30150800943374634
Batch 4/64 loss: 0.3033598065376282
Batch 5/64 loss: 0.29916590452194214
Batch 6/64 loss: 0.2998858094215393
Batch 7/64 loss: 0.3025592565536499
Batch 8/64 loss: 0.30471348762512207
Batch 9/64 loss: 0.29416656494140625
Batch 10/64 loss: 0.3113252520561218
Batch 11/64 loss: 0.29638826847076416
Batch 12/64 loss: 0.30063462257385254
Batch 13/64 loss: 0.30357825756073
Batch 14/64 loss: 0.29735755920410156
Batch 15/64 loss: 0.2919025421142578
Batch 16/64 loss: 0.29635143280029297
Batch 17/64 loss: 0.29290664196014404
Batch 18/64 loss: 0.30756282806396484
Batch 19/64 loss: 0.2977036237716675
Batch 20/64 loss: 0.29987382888793945
Batch 21/64 loss: 0.30230772495269775
Batch 22/64 loss: 0.2898283004760742
Batch 23/64 loss: 0.29219114780426025
Batch 24/64 loss: 0.304790198802948
Batch 25/64 loss: 0.2946915626525879
Batch 26/64 loss: 0.29940885305404663
Batch 27/64 loss: 0.29626572132110596
Batch 28/64 loss: 0.2995978593826294
Batch 29/64 loss: 0.30434274673461914
Batch 30/64 loss: 0.2933002710342407
Batch 31/64 loss: 0.29839658737182617
Batch 32/64 loss: 0.28899669647216797
Batch 33/64 loss: 0.29964369535446167
Batch 34/64 loss: 0.3028106689453125
Batch 35/64 loss: 0.2969706058502197
Batch 36/64 loss: 0.3073704242706299
Batch 37/64 loss: 0.3161724805831909
Batch 38/64 loss: 0.30433475971221924
Batch 39/64 loss: 0.2964179515838623
Batch 40/64 loss: 0.310050368309021
Batch 41/64 loss: 0.292422890663147
Batch 42/64 loss: 0.2989766597747803
Batch 43/64 loss: 0.29633569717407227
Batch 44/64 loss: 0.3009999990463257
Batch 45/64 loss: 0.3004133701324463
Batch 46/64 loss: 0.30236852169036865
Batch 47/64 loss: 0.30683422088623047
Batch 48/64 loss: 0.2977105379104614
Batch 49/64 loss: 0.3067435026168823
Batch 50/64 loss: 0.30463260412216187
Batch 51/64 loss: 0.30181097984313965
Batch 52/64 loss: 0.2952768802642822
Batch 53/64 loss: 0.2971160411834717
Batch 54/64 loss: 0.29286497831344604
Batch 55/64 loss: 0.3025623559951782
Batch 56/64 loss: 0.29550468921661377
Batch 57/64 loss: 0.2974189519882202
Batch 58/64 loss: 0.29833126068115234
Batch 59/64 loss: 0.3017416000366211
Batch 60/64 loss: 0.29912662506103516
Batch 61/64 loss: 0.30076009035110474
Batch 62/64 loss: 0.30382901430130005
Batch 63/64 loss: 0.3009641170501709
Batch 64/64 loss: 0.30111902952194214
Epoch 342  Train loss: 0.2998496544127371  Val loss: 0.3280440720495899
Epoch 343
-------------------------------
Batch 1/64 loss: 0.3017878532409668
Batch 2/64 loss: 0.3022170066833496
Batch 3/64 loss: 0.2959693670272827
Batch 4/64 loss: 0.3059282898902893
Batch 5/64 loss: 0.3030444383621216
Batch 6/64 loss: 0.2952864170074463
Batch 7/64 loss: 0.3011733889579773
Batch 8/64 loss: 0.3047327995300293
Batch 9/64 loss: 0.2893950343132019
Batch 10/64 loss: 0.29853248596191406
Batch 11/64 loss: 0.2977524995803833
Batch 12/64 loss: 0.30706334114074707
Batch 13/64 loss: 0.2980461120605469
Batch 14/64 loss: 0.2936321496963501
Batch 15/64 loss: 0.30638670921325684
Batch 16/64 loss: 0.3113309144973755
Batch 17/64 loss: 0.29825472831726074
Batch 18/64 loss: 0.3006165027618408
Batch 19/64 loss: 0.30331480503082275
Batch 20/64 loss: 0.29996299743652344
Batch 21/64 loss: 0.2963219881057739
Batch 22/64 loss: 0.2957116365432739
Batch 23/64 loss: 0.2982672452926636
Batch 24/64 loss: 0.29653024673461914
Batch 25/64 loss: 0.29915332794189453
Batch 26/64 loss: 0.3032141923904419
Batch 27/64 loss: 0.3108985424041748
Batch 28/64 loss: 0.29058897495269775
Batch 29/64 loss: 0.3102869391441345
Batch 30/64 loss: 0.30128514766693115
Batch 31/64 loss: 0.2990155816078186
Batch 32/64 loss: 0.2941775918006897
Batch 33/64 loss: 0.29874956607818604
Batch 34/64 loss: 0.2961832284927368
Batch 35/64 loss: 0.29568028450012207
Batch 36/64 loss: 0.3061220645904541
Batch 37/64 loss: 0.29961204528808594
Batch 38/64 loss: 0.29329121112823486
Batch 39/64 loss: 0.29339367151260376
Batch 40/64 loss: 0.2993044853210449
Batch 41/64 loss: 0.3050880432128906
Batch 42/64 loss: 0.29688286781311035
Batch 43/64 loss: 0.2906648516654968
Batch 44/64 loss: 0.29442352056503296
Batch 45/64 loss: 0.3124774098396301
Batch 46/64 loss: 0.3026984930038452
Batch 47/64 loss: 0.3051075339317322
Batch 48/64 loss: 0.3032134175300598
Batch 49/64 loss: 0.2985726594924927
Batch 50/64 loss: 0.3017416000366211
Batch 51/64 loss: 0.29596084356307983
Batch 52/64 loss: 0.2967092990875244
Batch 53/64 loss: 0.29755890369415283
Batch 54/64 loss: 0.311808705329895
Batch 55/64 loss: 0.3016693592071533
Batch 56/64 loss: 0.2947459816932678
Batch 57/64 loss: 0.2976282835006714
Batch 58/64 loss: 0.29863274097442627
Batch 59/64 loss: 0.303610622882843
Batch 60/64 loss: 0.29893219470977783
Batch 61/64 loss: 0.31092655658721924
Batch 62/64 loss: 0.29184842109680176
Batch 63/64 loss: 0.29453325271606445
Batch 64/64 loss: 0.29354918003082275
Epoch 343  Train loss: 0.29988726681354  Val loss: 0.3263199288410829
Epoch 344
-------------------------------
Batch 1/64 loss: 0.30273711681365967
Batch 2/64 loss: 0.2943914532661438
Batch 3/64 loss: 0.2936800718307495
Batch 4/64 loss: 0.2901420593261719
Batch 5/64 loss: 0.2966271638870239
Batch 6/64 loss: 0.31201207637786865
Batch 7/64 loss: 0.29417431354522705
Batch 8/64 loss: 0.3032705783843994
Batch 9/64 loss: 0.297727108001709
Batch 10/64 loss: 0.305433988571167
Batch 11/64 loss: 0.29527783393859863
Batch 12/64 loss: 0.29821455478668213
Batch 13/64 loss: 0.29729562997817993
Batch 14/64 loss: 0.2970563769340515
Batch 15/64 loss: 0.2984194755554199
Batch 16/64 loss: 0.2972859740257263
Batch 17/64 loss: 0.2983517646789551
Batch 18/64 loss: 0.3015904426574707
Batch 19/64 loss: 0.30801689624786377
Batch 20/64 loss: 0.29429876804351807
Batch 21/64 loss: 0.3000904321670532
Batch 22/64 loss: 0.29978638887405396
Batch 23/64 loss: 0.2916942834854126
Batch 24/64 loss: 0.292818546295166
Batch 25/64 loss: 0.30135244131088257
Batch 26/64 loss: 0.30517494678497314
Batch 27/64 loss: 0.2966804504394531
Batch 28/64 loss: 0.3068925738334656
Batch 29/64 loss: 0.2995227575302124
Batch 30/64 loss: 0.29295170307159424
Batch 31/64 loss: 0.3020991086959839
Batch 32/64 loss: 0.30919331312179565
Batch 33/64 loss: 0.2953096628189087
Batch 34/64 loss: 0.3001224398612976
Batch 35/64 loss: 0.30678093433380127
Batch 36/64 loss: 0.30209046602249146
Batch 37/64 loss: 0.30710262060165405
Batch 38/64 loss: 0.2971463203430176
Batch 39/64 loss: 0.2963294982910156
Batch 40/64 loss: 0.3010532855987549
Batch 41/64 loss: 0.3041861653327942
Batch 42/64 loss: 0.29778921604156494
Batch 43/64 loss: 0.2979421019554138
Batch 44/64 loss: 0.30530834197998047
Batch 45/64 loss: 0.29133880138397217
Batch 46/64 loss: 0.3065875768661499
Batch 47/64 loss: 0.3006693124771118
Batch 48/64 loss: 0.30062103271484375
Batch 49/64 loss: 0.2991519570350647
Batch 50/64 loss: 0.30020463466644287
Batch 51/64 loss: 0.2905375361442566
Batch 52/64 loss: 0.2982358932495117
Batch 53/64 loss: 0.3012363314628601
Batch 54/64 loss: 0.3043116331100464
Batch 55/64 loss: 0.30339115858078003
Batch 56/64 loss: 0.3123641014099121
Batch 57/64 loss: 0.30008649826049805
Batch 58/64 loss: 0.29291510581970215
Batch 59/64 loss: 0.3077145218849182
Batch 60/64 loss: 0.29551374912261963
Batch 61/64 loss: 0.29417359828948975
Batch 62/64 loss: 0.300756573677063
Batch 63/64 loss: 0.3021160960197449
Batch 64/64 loss: 0.31714630126953125
Epoch 344  Train loss: 0.30000325464734845  Val loss: 0.3263132830256039
Epoch 345
-------------------------------
Batch 1/64 loss: 0.29014480113983154
Batch 2/64 loss: 0.2957721948623657
Batch 3/64 loss: 0.3068726062774658
Batch 4/64 loss: 0.3031248450279236
Batch 5/64 loss: 0.3055933713912964
Batch 6/64 loss: 0.2973151206970215
Batch 7/64 loss: 0.29031431674957275
Batch 8/64 loss: 0.31279706954956055
Batch 9/64 loss: 0.29938167333602905
Batch 10/64 loss: 0.2994624376296997
Batch 11/64 loss: 0.302937388420105
Batch 12/64 loss: 0.3011934757232666
Batch 13/64 loss: 0.2957247495651245
Batch 14/64 loss: 0.301194965839386
Batch 15/64 loss: 0.30057692527770996
Batch 16/64 loss: 0.3051379919052124
Batch 17/64 loss: 0.30055785179138184
Batch 18/64 loss: 0.3061060905456543
Batch 19/64 loss: 0.3094843626022339
Batch 20/64 loss: 0.3048146963119507
Batch 21/64 loss: 0.29711925983428955
Batch 22/64 loss: 0.30715566873550415
Batch 23/64 loss: 0.28873276710510254
Batch 24/64 loss: 0.29370778799057007
Batch 25/64 loss: 0.29937809705734253
Batch 26/64 loss: 0.3027077913284302
Batch 27/64 loss: 0.30626213550567627
Batch 28/64 loss: 0.3001730442047119
Batch 29/64 loss: 0.3012884259223938
Batch 30/64 loss: 0.2949013113975525
Batch 31/64 loss: 0.2954280972480774
Batch 32/64 loss: 0.2942686080932617
Batch 33/64 loss: 0.301813006401062
Batch 34/64 loss: 0.30103540420532227
Batch 35/64 loss: 0.29458606243133545
Batch 36/64 loss: 0.297554612159729
Batch 37/64 loss: 0.3049135208129883
Batch 38/64 loss: 0.29786133766174316
Batch 39/64 loss: 0.30379223823547363
Batch 40/64 loss: 0.2966698408126831
Batch 41/64 loss: 0.29630541801452637
Batch 42/64 loss: 0.301288366317749
Batch 43/64 loss: 0.2953575849533081
Batch 44/64 loss: 0.298885703086853
Batch 45/64 loss: 0.30085575580596924
Batch 46/64 loss: 0.2955366373062134
Batch 47/64 loss: 0.3046438694000244
Batch 48/64 loss: 0.29799318313598633
Batch 49/64 loss: 0.3046889901161194
Batch 50/64 loss: 0.2923223376274109
Batch 51/64 loss: 0.2996863126754761
Batch 52/64 loss: 0.30343371629714966
Batch 53/64 loss: 0.3126841187477112
Batch 54/64 loss: 0.30777299404144287
Batch 55/64 loss: 0.29415273666381836
Batch 56/64 loss: 0.30639421939849854
Batch 57/64 loss: 0.3011603355407715
Batch 58/64 loss: 0.2957272529602051
Batch 59/64 loss: 0.3039999008178711
Batch 60/64 loss: 0.29849159717559814
Batch 61/64 loss: 0.3081631660461426
Batch 62/64 loss: 0.29345202445983887
Batch 63/64 loss: 0.3003346920013428
Batch 64/64 loss: 0.29512500762939453
Epoch 345  Train loss: 0.3002749901191861  Val loss: 0.3266920277343173
Epoch 346
-------------------------------
Batch 1/64 loss: 0.29313504695892334
Batch 2/64 loss: 0.2920798063278198
Batch 3/64 loss: 0.3002561330795288
Batch 4/64 loss: 0.2962822914123535
Batch 5/64 loss: 0.29904496669769287
Batch 6/64 loss: 0.29437750577926636
Batch 7/64 loss: 0.29034459590911865
Batch 8/64 loss: 0.3095903992652893
Batch 9/64 loss: 0.3050518035888672
Batch 10/64 loss: 0.29405272006988525
Batch 11/64 loss: 0.30512702465057373
Batch 12/64 loss: 0.3002042770385742
Batch 13/64 loss: 0.29411208629608154
Batch 14/64 loss: 0.30028796195983887
Batch 15/64 loss: 0.29977160692214966
Batch 16/64 loss: 0.29480600357055664
Batch 17/64 loss: 0.2999788522720337
Batch 18/64 loss: 0.2999647855758667
Batch 19/64 loss: 0.30244845151901245
Batch 20/64 loss: 0.29629987478256226
Batch 21/64 loss: 0.307364821434021
Batch 22/64 loss: 0.2939683198928833
Batch 23/64 loss: 0.30218493938446045
Batch 24/64 loss: 0.29606252908706665
Batch 25/64 loss: 0.2998540997505188
Batch 26/64 loss: 0.29616957902908325
Batch 27/64 loss: 0.2998239994049072
Batch 28/64 loss: 0.2984302043914795
Batch 29/64 loss: 0.29956531524658203
Batch 30/64 loss: 0.294650673866272
Batch 31/64 loss: 0.29459863901138306
Batch 32/64 loss: 0.2947147488594055
Batch 33/64 loss: 0.2867029905319214
Batch 34/64 loss: 0.2940284013748169
Batch 35/64 loss: 0.3063502311706543
Batch 36/64 loss: 0.29561638832092285
Batch 37/64 loss: 0.29985177516937256
Batch 38/64 loss: 0.2985989451408386
Batch 39/64 loss: 0.29403257369995117
Batch 40/64 loss: 0.2993393540382385
Batch 41/64 loss: 0.3047282099723816
Batch 42/64 loss: 0.30078285932540894
Batch 43/64 loss: 0.29100263118743896
Batch 44/64 loss: 0.30406612157821655
Batch 45/64 loss: 0.29832780361175537
Batch 46/64 loss: 0.302623987197876
Batch 47/64 loss: 0.30531251430511475
Batch 48/64 loss: 0.30361366271972656
Batch 49/64 loss: 0.30391383171081543
Batch 50/64 loss: 0.29717063903808594
Batch 51/64 loss: 0.3078629970550537
Batch 52/64 loss: 0.2981407642364502
Batch 53/64 loss: 0.3018876910209656
Batch 54/64 loss: 0.29923003911972046
Batch 55/64 loss: 0.30471205711364746
Batch 56/64 loss: 0.29155051708221436
Batch 57/64 loss: 0.29691988229751587
Batch 58/64 loss: 0.3058658242225647
Batch 59/64 loss: 0.29780352115631104
Batch 60/64 loss: 0.31304627656936646
Batch 61/64 loss: 0.29963934421539307
Batch 62/64 loss: 0.31177055835723877
Batch 63/64 loss: 0.2980721592903137
Batch 64/64 loss: 0.29191601276397705
Epoch 346  Train loss: 0.29923302940293856  Val loss: 0.3251634428591253
Saving best model, epoch: 346
Epoch 347
-------------------------------
Batch 1/64 loss: 0.3059172034263611
Batch 2/64 loss: 0.30561304092407227
Batch 3/64 loss: 0.2894783020019531
Batch 4/64 loss: 0.30393165349960327
Batch 5/64 loss: 0.2969359755516052
Batch 6/64 loss: 0.2935647964477539
Batch 7/64 loss: 0.2952868342399597
Batch 8/64 loss: 0.2965676784515381
Batch 9/64 loss: 0.30109429359436035
Batch 10/64 loss: 0.28772449493408203
Batch 11/64 loss: 0.2987685203552246
Batch 12/64 loss: 0.29484009742736816
Batch 13/64 loss: 0.29246389865875244
Batch 14/64 loss: 0.29903531074523926
Batch 15/64 loss: 0.2978229522705078
Batch 16/64 loss: 0.2948918342590332
Batch 17/64 loss: 0.30207359790802
Batch 18/64 loss: 0.29159796237945557
Batch 19/64 loss: 0.29834097623825073
Batch 20/64 loss: 0.29615020751953125
Batch 21/64 loss: 0.29489874839782715
Batch 22/64 loss: 0.28971797227859497
Batch 23/64 loss: 0.2901495099067688
Batch 24/64 loss: 0.2971733808517456
Batch 25/64 loss: 0.2961488366127014
Batch 26/64 loss: 0.28171205520629883
Batch 27/64 loss: 0.297876238822937
Batch 28/64 loss: 0.29905033111572266
Batch 29/64 loss: 0.30326616764068604
Batch 30/64 loss: 0.29076409339904785
Batch 31/64 loss: 0.3030087947845459
Batch 32/64 loss: 0.30860912799835205
Batch 33/64 loss: 0.29686033725738525
Batch 34/64 loss: 0.29588496685028076
Batch 35/64 loss: 0.3047757148742676
Batch 36/64 loss: 0.2996830940246582
Batch 37/64 loss: 0.30367588996887207
Batch 38/64 loss: 0.2975727319717407
Batch 39/64 loss: 0.29670852422714233
Batch 40/64 loss: 0.29873859882354736
Batch 41/64 loss: 0.3075496554374695
Batch 42/64 loss: 0.3000227212905884
Batch 43/64 loss: 0.2973811626434326
Batch 44/64 loss: 0.3042740225791931
Batch 45/64 loss: 0.2924783229827881
Batch 46/64 loss: 0.2916610836982727
Batch 47/64 loss: 0.3009757399559021
Batch 48/64 loss: 0.3065594434738159
Batch 49/64 loss: 0.30473262071609497
Batch 50/64 loss: 0.3059605360031128
Batch 51/64 loss: 0.3017197847366333
Batch 52/64 loss: 0.2995150685310364
Batch 53/64 loss: 0.29492008686065674
Batch 54/64 loss: 0.30357158184051514
Batch 55/64 loss: 0.30665409564971924
Batch 56/64 loss: 0.29645276069641113
Batch 57/64 loss: 0.3058208227157593
Batch 58/64 loss: 0.29796355962753296
Batch 59/64 loss: 0.3043321371078491
Batch 60/64 loss: 0.3017396926879883
Batch 61/64 loss: 0.2975853681564331
Batch 62/64 loss: 0.3010439872741699
Batch 63/64 loss: 0.30661439895629883
Batch 64/64 loss: 0.3093454837799072
Epoch 347  Train loss: 0.2988221570557239  Val loss: 0.3267464086771831
Epoch 348
-------------------------------
Batch 1/64 loss: 0.3007620573043823
Batch 2/64 loss: 0.29608142375946045
Batch 3/64 loss: 0.3027949333190918
Batch 4/64 loss: 0.28591984510421753
Batch 5/64 loss: 0.2939227819442749
Batch 6/64 loss: 0.30660438537597656
Batch 7/64 loss: 0.29785633087158203
Batch 8/64 loss: 0.3016238212585449
Batch 9/64 loss: 0.29506468772888184
Batch 10/64 loss: 0.29331785440444946
Batch 11/64 loss: 0.2929788827896118
Batch 12/64 loss: 0.2973787188529968
Batch 13/64 loss: 0.29489195346832275
Batch 14/64 loss: 0.3034709692001343
Batch 15/64 loss: 0.30238205194473267
Batch 16/64 loss: 0.29714691638946533
Batch 17/64 loss: 0.30710792541503906
Batch 18/64 loss: 0.29826438426971436
Batch 19/64 loss: 0.29894083738327026
Batch 20/64 loss: 0.29744982719421387
Batch 21/64 loss: 0.28804779052734375
Batch 22/64 loss: 0.298098623752594
Batch 23/64 loss: 0.2920467257499695
Batch 24/64 loss: 0.3051016330718994
Batch 25/64 loss: 0.29568934440612793
Batch 26/64 loss: 0.28959548473358154
Batch 27/64 loss: 0.3057135343551636
Batch 28/64 loss: 0.308144211769104
Batch 29/64 loss: 0.2977350950241089
Batch 30/64 loss: 0.3016458749771118
Batch 31/64 loss: 0.3001824617385864
Batch 32/64 loss: 0.29829657077789307
Batch 33/64 loss: 0.30733680725097656
Batch 34/64 loss: 0.30043578147888184
Batch 35/64 loss: 0.30641448497772217
Batch 36/64 loss: 0.3034639358520508
Batch 37/64 loss: 0.29948776960372925
Batch 38/64 loss: 0.2991960048675537
Batch 39/64 loss: 0.29548168182373047
Batch 40/64 loss: 0.29757022857666016
Batch 41/64 loss: 0.30368125438690186
Batch 42/64 loss: 0.29837167263031006
Batch 43/64 loss: 0.2977339029312134
Batch 44/64 loss: 0.29692262411117554
Batch 45/64 loss: 0.3018615245819092
Batch 46/64 loss: 0.3131521940231323
Batch 47/64 loss: 0.2956163287162781
Batch 48/64 loss: 0.3037084937095642
Batch 49/64 loss: 0.2977936267852783
Batch 50/64 loss: 0.3026164770126343
Batch 51/64 loss: 0.30640947818756104
Batch 52/64 loss: 0.2902456521987915
Batch 53/64 loss: 0.30237066745758057
Batch 54/64 loss: 0.3024086356163025
Batch 55/64 loss: 0.2965608239173889
Batch 56/64 loss: 0.2914513349533081
Batch 57/64 loss: 0.30568385124206543
Batch 58/64 loss: 0.30841588973999023
Batch 59/64 loss: 0.29355692863464355
Batch 60/64 loss: 0.3006401062011719
Batch 61/64 loss: 0.30018794536590576
Batch 62/64 loss: 0.30861151218414307
Batch 63/64 loss: 0.2953164577484131
Batch 64/64 loss: 0.30422598123550415
Epoch 348  Train loss: 0.29953147453420303  Val loss: 0.3275892707900083
Epoch 349
-------------------------------
Batch 1/64 loss: 0.3059278726577759
Batch 2/64 loss: 0.29679691791534424
Batch 3/64 loss: 0.29979145526885986
Batch 4/64 loss: 0.2920154929161072
Batch 5/64 loss: 0.30159997940063477
Batch 6/64 loss: 0.29731249809265137
Batch 7/64 loss: 0.29242944717407227
Batch 8/64 loss: 0.2997307777404785
Batch 9/64 loss: 0.30070656538009644
Batch 10/64 loss: 0.2958405017852783
Batch 11/64 loss: 0.28948473930358887
Batch 12/64 loss: 0.2999590039253235
Batch 13/64 loss: 0.3015933036804199
Batch 14/64 loss: 0.3052612543106079
Batch 15/64 loss: 0.29973578453063965
Batch 16/64 loss: 0.2973693609237671
Batch 17/64 loss: 0.2905624508857727
Batch 18/64 loss: 0.30292314291000366
Batch 19/64 loss: 0.30135780572891235
Batch 20/64 loss: 0.2951223850250244
Batch 21/64 loss: 0.3012735843658447
Batch 22/64 loss: 0.292852520942688
Batch 23/64 loss: 0.293337345123291
Batch 24/64 loss: 0.2994663715362549
Batch 25/64 loss: 0.29951244592666626
Batch 26/64 loss: 0.2960190176963806
Batch 27/64 loss: 0.30450767278671265
Batch 28/64 loss: 0.29642629623413086
Batch 29/64 loss: 0.3089355230331421
Batch 30/64 loss: 0.2920600175857544
Batch 31/64 loss: 0.3013664484024048
Batch 32/64 loss: 0.29350602626800537
Batch 33/64 loss: 0.2860229015350342
Batch 34/64 loss: 0.3071691393852234
Batch 35/64 loss: 0.298628032207489
Batch 36/64 loss: 0.3066967725753784
Batch 37/64 loss: 0.2935127019882202
Batch 38/64 loss: 0.3103591799736023
Batch 39/64 loss: 0.29274100065231323
Batch 40/64 loss: 0.2993960380554199
Batch 41/64 loss: 0.29733800888061523
Batch 42/64 loss: 0.29648876190185547
Batch 43/64 loss: 0.29339051246643066
Batch 44/64 loss: 0.2950965166091919
Batch 45/64 loss: 0.3070700168609619
Batch 46/64 loss: 0.29185783863067627
Batch 47/64 loss: 0.2942352890968323
Batch 48/64 loss: 0.3085547685623169
Batch 49/64 loss: 0.295027494430542
Batch 50/64 loss: 0.30795496702194214
Batch 51/64 loss: 0.296047568321228
Batch 52/64 loss: 0.3024359941482544
Batch 53/64 loss: 0.30009716749191284
Batch 54/64 loss: 0.3013685941696167
Batch 55/64 loss: 0.29907357692718506
Batch 56/64 loss: 0.30637288093566895
Batch 57/64 loss: 0.30056333541870117
Batch 58/64 loss: 0.30650603771209717
Batch 59/64 loss: 0.30102723836898804
Batch 60/64 loss: 0.3009204864501953
Batch 61/64 loss: 0.29928189516067505
Batch 62/64 loss: 0.28840065002441406
Batch 63/64 loss: 0.319918155670166
Batch 64/64 loss: 0.2920039892196655
Epoch 349  Train loss: 0.29909553761575736  Val loss: 0.3264611062315321
Epoch 350
-------------------------------
Batch 1/64 loss: 0.3030439615249634
Batch 2/64 loss: 0.30830007791519165
Batch 3/64 loss: 0.29029905796051025
Batch 4/64 loss: 0.29546260833740234
Batch 5/64 loss: 0.29515957832336426
Batch 6/64 loss: 0.29878878593444824
Batch 7/64 loss: 0.30096596479415894
Batch 8/64 loss: 0.29995179176330566
Batch 9/64 loss: 0.2977718114852905
Batch 10/64 loss: 0.2957698106765747
Batch 11/64 loss: 0.2975773215293884
Batch 12/64 loss: 0.30366480350494385
Batch 13/64 loss: 0.2977616786956787
Batch 14/64 loss: 0.3005255460739136
Batch 15/64 loss: 0.31361663341522217
Batch 16/64 loss: 0.300362765789032
Batch 17/64 loss: 0.29519975185394287
Batch 18/64 loss: 0.292866587638855
Batch 19/64 loss: 0.3064965605735779
Batch 20/64 loss: 0.29556405544281006
Batch 21/64 loss: 0.29802870750427246
Batch 22/64 loss: 0.2932196259498596
Batch 23/64 loss: 0.29662394523620605
Batch 24/64 loss: 0.30733442306518555
Batch 25/64 loss: 0.29686248302459717
Batch 26/64 loss: 0.2959998846054077
Batch 27/64 loss: 0.2884717583656311
Batch 28/64 loss: 0.30107879638671875
Batch 29/64 loss: 0.3022673726081848
Batch 30/64 loss: 0.2969365119934082
Batch 31/64 loss: 0.2933756113052368
Batch 32/64 loss: 0.29522520303726196
Batch 33/64 loss: 0.30078279972076416
Batch 34/64 loss: 0.30110234022140503
Batch 35/64 loss: 0.3109825849533081
Batch 36/64 loss: 0.3003239035606384
Batch 37/64 loss: 0.2969691753387451
Batch 38/64 loss: 0.31574535369873047
Batch 39/64 loss: 0.28853100538253784
Batch 40/64 loss: 0.28948670625686646
Batch 41/64 loss: 0.2979108691215515
Batch 42/64 loss: 0.3055537939071655
Batch 43/64 loss: 0.2979511022567749
Batch 44/64 loss: 0.2940937876701355
Batch 45/64 loss: 0.30195629596710205
Batch 46/64 loss: 0.30610191822052
Batch 47/64 loss: 0.30756425857543945
Batch 48/64 loss: 0.29676520824432373
Batch 49/64 loss: 0.30472177267074585
Batch 50/64 loss: 0.2965543270111084
Batch 51/64 loss: 0.29404670000076294
Batch 52/64 loss: 0.29636943340301514
Batch 53/64 loss: 0.3055380582809448
Batch 54/64 loss: 0.2906653881072998
Batch 55/64 loss: 0.30160242319107056
Batch 56/64 loss: 0.3116474151611328
Batch 57/64 loss: 0.29393261671066284
Batch 58/64 loss: 0.29565614461898804
Batch 59/64 loss: 0.3009742498397827
Batch 60/64 loss: 0.29791170358657837
Batch 61/64 loss: 0.283466100692749
Batch 62/64 loss: 0.29808300733566284
Batch 63/64 loss: 0.29049211740493774
Batch 64/64 loss: 0.2909713387489319
Epoch 350  Train loss: 0.2987652477096109  Val loss: 0.327292707367861
Epoch 351
-------------------------------
Batch 1/64 loss: 0.29611390829086304
Batch 2/64 loss: 0.29532426595687866
Batch 3/64 loss: 0.29874753952026367
Batch 4/64 loss: 0.29750925302505493
Batch 5/64 loss: 0.30955398082733154
Batch 6/64 loss: 0.292427659034729
Batch 7/64 loss: 0.3016722798347473
Batch 8/64 loss: 0.3000333309173584
Batch 9/64 loss: 0.2977604866027832
Batch 10/64 loss: 0.29935789108276367
Batch 11/64 loss: 0.29540491104125977
Batch 12/64 loss: 0.30010032653808594
Batch 13/64 loss: 0.29484665393829346
Batch 14/64 loss: 0.30267059803009033
Batch 15/64 loss: 0.29938602447509766
Batch 16/64 loss: 0.2898002862930298
Batch 17/64 loss: 0.30023276805877686
Batch 18/64 loss: 0.3061057925224304
Batch 19/64 loss: 0.3031644821166992
Batch 20/64 loss: 0.2938511371612549
Batch 21/64 loss: 0.29657602310180664
Batch 22/64 loss: 0.29081451892852783
Batch 23/64 loss: 0.2946878671646118
Batch 24/64 loss: 0.2980533242225647
Batch 25/64 loss: 0.30882400274276733
Batch 26/64 loss: 0.3005567193031311
Batch 27/64 loss: 0.29949700832366943
Batch 28/64 loss: 0.30668842792510986
Batch 29/64 loss: 0.2909189462661743
Batch 30/64 loss: 0.30008745193481445
Batch 31/64 loss: 0.29331648349761963
Batch 32/64 loss: 0.29604965448379517
Batch 33/64 loss: 0.2981297969818115
Batch 34/64 loss: 0.3045715093612671
Batch 35/64 loss: 0.3005449175834656
Batch 36/64 loss: 0.3032487630844116
Batch 37/64 loss: 0.2994168996810913
Batch 38/64 loss: 0.29548871517181396
Batch 39/64 loss: 0.2992841601371765
Batch 40/64 loss: 0.3008095622062683
Batch 41/64 loss: 0.2992548942565918
Batch 42/64 loss: 0.30604231357574463
Batch 43/64 loss: 0.299701988697052
Batch 44/64 loss: 0.304266095161438
Batch 45/64 loss: 0.29620277881622314
Batch 46/64 loss: 0.3020550012588501
Batch 47/64 loss: 0.2977423667907715
Batch 48/64 loss: 0.2999829649925232
Batch 49/64 loss: 0.30401307344436646
Batch 50/64 loss: 0.29081618785858154
Batch 51/64 loss: 0.3084808588027954
Batch 52/64 loss: 0.3094968795776367
Batch 53/64 loss: 0.2839430570602417
Batch 54/64 loss: 0.29333823919296265
Batch 55/64 loss: 0.2990911602973938
Batch 56/64 loss: 0.2939356565475464
Batch 57/64 loss: 0.3014333248138428
Batch 58/64 loss: 0.30161237716674805
Batch 59/64 loss: 0.30533266067504883
Batch 60/64 loss: 0.2923036217689514
Batch 61/64 loss: 0.29907405376434326
Batch 62/64 loss: 0.29093629121780396
Batch 63/64 loss: 0.29243004322052
Batch 64/64 loss: 0.303615927696228
Epoch 351  Train loss: 0.2988364888172524  Val loss: 0.3262672020807299
Epoch 352
-------------------------------
Batch 1/64 loss: 0.30786895751953125
Batch 2/64 loss: 0.3041725754737854
Batch 3/64 loss: 0.28736722469329834
Batch 4/64 loss: 0.2963588833808899
Batch 5/64 loss: 0.3001028895378113
Batch 6/64 loss: 0.288019061088562
Batch 7/64 loss: 0.2906782627105713
Batch 8/64 loss: 0.29926902055740356
Batch 9/64 loss: 0.30373549461364746
Batch 10/64 loss: 0.30411654710769653
Batch 11/64 loss: 0.29827046394348145
Batch 12/64 loss: 0.28472745418548584
Batch 13/64 loss: 0.2912982106208801
Batch 14/64 loss: 0.29889047145843506
Batch 15/64 loss: 0.29194504022598267
Batch 16/64 loss: 0.29731452465057373
Batch 17/64 loss: 0.29988837242126465
Batch 18/64 loss: 0.2969891428947449
Batch 19/64 loss: 0.3029097318649292
Batch 20/64 loss: 0.307278037071228
Batch 21/64 loss: 0.313524067401886
Batch 22/64 loss: 0.301891565322876
Batch 23/64 loss: 0.29725074768066406
Batch 24/64 loss: 0.30594849586486816
Batch 25/64 loss: 0.3023064136505127
Batch 26/64 loss: 0.3051798343658447
Batch 27/64 loss: 0.2985192537307739
Batch 28/64 loss: 0.3037574887275696
Batch 29/64 loss: 0.29956603050231934
Batch 30/64 loss: 0.2987746000289917
Batch 31/64 loss: 0.29941660165786743
Batch 32/64 loss: 0.28909969329833984
Batch 33/64 loss: 0.29601985216140747
Batch 34/64 loss: 0.2985806465148926
Batch 35/64 loss: 0.2972176671028137
Batch 36/64 loss: 0.298877477645874
Batch 37/64 loss: 0.30143213272094727
Batch 38/64 loss: 0.30349987745285034
Batch 39/64 loss: 0.3005563020706177
Batch 40/64 loss: 0.29232287406921387
Batch 41/64 loss: 0.2951633334159851
Batch 42/64 loss: 0.30548393726348877
Batch 43/64 loss: 0.2947053909301758
Batch 44/64 loss: 0.3048207759857178
Batch 45/64 loss: 0.30255770683288574
Batch 46/64 loss: 0.29777199029922485
Batch 47/64 loss: 0.2918626070022583
Batch 48/64 loss: 0.29631507396698
Batch 49/64 loss: 0.3026219606399536
Batch 50/64 loss: 0.2873189449310303
Batch 51/64 loss: 0.30106842517852783
Batch 52/64 loss: 0.29951393604278564
Batch 53/64 loss: 0.2944769859313965
Batch 54/64 loss: 0.2968129515647888
Batch 55/64 loss: 0.3016921281814575
Batch 56/64 loss: 0.29702889919281006
Batch 57/64 loss: 0.3033309578895569
Batch 58/64 loss: 0.30198222398757935
Batch 59/64 loss: 0.3017977476119995
Batch 60/64 loss: 0.30137842893600464
Batch 61/64 loss: 0.30606526136398315
Batch 62/64 loss: 0.29716038703918457
Batch 63/64 loss: 0.294681191444397
Batch 64/64 loss: 0.29725944995880127
Epoch 352  Train loss: 0.2988783971936095  Val loss: 0.3260293367392419
Epoch 353
-------------------------------
Batch 1/64 loss: 0.3021407127380371
Batch 2/64 loss: 0.2974089980125427
Batch 3/64 loss: 0.29060161113739014
Batch 4/64 loss: 0.2968553900718689
Batch 5/64 loss: 0.30436861515045166
Batch 6/64 loss: 0.2933008670806885
Batch 7/64 loss: 0.2932262420654297
Batch 8/64 loss: 0.2941901683807373
Batch 9/64 loss: 0.29565536975860596
Batch 10/64 loss: 0.3022114038467407
Batch 11/64 loss: 0.29435503482818604
Batch 12/64 loss: 0.294819176197052
Batch 13/64 loss: 0.3066493272781372
Batch 14/64 loss: 0.2947797179222107
Batch 15/64 loss: 0.29448872804641724
Batch 16/64 loss: 0.29973912239074707
Batch 17/64 loss: 0.302590548992157
Batch 18/64 loss: 0.2890207767486572
Batch 19/64 loss: 0.3033141493797302
Batch 20/64 loss: 0.29112255573272705
Batch 21/64 loss: 0.29809701442718506
Batch 22/64 loss: 0.30633699893951416
Batch 23/64 loss: 0.2972555160522461
Batch 24/64 loss: 0.2911403179168701
Batch 25/64 loss: 0.29879581928253174
Batch 26/64 loss: 0.3132103681564331
Batch 27/64 loss: 0.3108481764793396
Batch 28/64 loss: 0.3028528690338135
Batch 29/64 loss: 0.3030956983566284
Batch 30/64 loss: 0.3037840723991394
Batch 31/64 loss: 0.29405510425567627
Batch 32/64 loss: 0.2935659885406494
Batch 33/64 loss: 0.2882143259048462
Batch 34/64 loss: 0.29617929458618164
Batch 35/64 loss: 0.3033186197280884
Batch 36/64 loss: 0.30073511600494385
Batch 37/64 loss: 0.2957765460014343
Batch 38/64 loss: 0.3050587773323059
Batch 39/64 loss: 0.2947574257850647
Batch 40/64 loss: 0.2977368235588074
Batch 41/64 loss: 0.2966510057449341
Batch 42/64 loss: 0.297691285610199
Batch 43/64 loss: 0.2923409342765808
Batch 44/64 loss: 0.2864631414413452
Batch 45/64 loss: 0.29611289501190186
Batch 46/64 loss: 0.29161810874938965
Batch 47/64 loss: 0.30317825078964233
Batch 48/64 loss: 0.30825555324554443
Batch 49/64 loss: 0.3071972727775574
Batch 50/64 loss: 0.3013375401496887
Batch 51/64 loss: 0.2935687303543091
Batch 52/64 loss: 0.3011932373046875
Batch 53/64 loss: 0.2887272238731384
Batch 54/64 loss: 0.29654932022094727
Batch 55/64 loss: 0.29570508003234863
Batch 56/64 loss: 0.29376888275146484
Batch 57/64 loss: 0.3007124662399292
Batch 58/64 loss: 0.3062173128128052
Batch 59/64 loss: 0.30843424797058105
Batch 60/64 loss: 0.30225276947021484
Batch 61/64 loss: 0.30391740798950195
Batch 62/64 loss: 0.3114722967147827
Batch 63/64 loss: 0.3019134998321533
Batch 64/64 loss: 0.296816885471344
Epoch 353  Train loss: 0.2987222669171352  Val loss: 0.3257661320499538
Epoch 354
-------------------------------
Batch 1/64 loss: 0.30522620677948
Batch 2/64 loss: 0.29733729362487793
Batch 3/64 loss: 0.306404709815979
Batch 4/64 loss: 0.3033686876296997
Batch 5/64 loss: 0.296069860458374
Batch 6/64 loss: 0.29947102069854736
Batch 7/64 loss: 0.2974308729171753
Batch 8/64 loss: 0.29621022939682007
Batch 9/64 loss: 0.30151331424713135
Batch 10/64 loss: 0.2894747853279114
Batch 11/64 loss: 0.2978755235671997
Batch 12/64 loss: 0.31245875358581543
Batch 13/64 loss: 0.2907053232192993
Batch 14/64 loss: 0.29633527994155884
Batch 15/64 loss: 0.29699933528900146
Batch 16/64 loss: 0.2914525866508484
Batch 17/64 loss: 0.291561484336853
Batch 18/64 loss: 0.3028215169906616
Batch 19/64 loss: 0.289153516292572
Batch 20/64 loss: 0.3080226182937622
Batch 21/64 loss: 0.28731203079223633
Batch 22/64 loss: 0.2960447072982788
Batch 23/64 loss: 0.2887721061706543
Batch 24/64 loss: 0.2961916923522949
Batch 25/64 loss: 0.2914921045303345
Batch 26/64 loss: 0.30484944581985474
Batch 27/64 loss: 0.29436928033828735
Batch 28/64 loss: 0.29968130588531494
Batch 29/64 loss: 0.301996111869812
Batch 30/64 loss: 0.30275052785873413
Batch 31/64 loss: 0.30104321241378784
Batch 32/64 loss: 0.29771459102630615
Batch 33/64 loss: 0.2958069443702698
Batch 34/64 loss: 0.30703985691070557
Batch 35/64 loss: 0.29932868480682373
Batch 36/64 loss: 0.29549068212509155
Batch 37/64 loss: 0.3020254373550415
Batch 38/64 loss: 0.29524195194244385
Batch 39/64 loss: 0.2898558974266052
Batch 40/64 loss: 0.3101925849914551
Batch 41/64 loss: 0.2907754182815552
Batch 42/64 loss: 0.29683607816696167
Batch 43/64 loss: 0.2938570976257324
Batch 44/64 loss: 0.3059544563293457
Batch 45/64 loss: 0.29750949144363403
Batch 46/64 loss: 0.3028936982154846
Batch 47/64 loss: 0.29764533042907715
Batch 48/64 loss: 0.2991110682487488
Batch 49/64 loss: 0.28646183013916016
Batch 50/64 loss: 0.30268335342407227
Batch 51/64 loss: 0.29991281032562256
Batch 52/64 loss: 0.30209487676620483
Batch 53/64 loss: 0.2965959906578064
Batch 54/64 loss: 0.3028169870376587
Batch 55/64 loss: 0.29081177711486816
Batch 56/64 loss: 0.3011970520019531
Batch 57/64 loss: 0.30557137727737427
Batch 58/64 loss: 0.3068650960922241
Batch 59/64 loss: 0.29215890169143677
Batch 60/64 loss: 0.2926304340362549
Batch 61/64 loss: 0.2954394817352295
Batch 62/64 loss: 0.2980419993400574
Batch 63/64 loss: 0.297565758228302
Batch 64/64 loss: 0.28823214769363403
Epoch 354  Train loss: 0.2980187694231669  Val loss: 0.32432996407407255
Saving best model, epoch: 354
Epoch 355
-------------------------------
Batch 1/64 loss: 0.3116093873977661
Batch 2/64 loss: 0.29121947288513184
Batch 3/64 loss: 0.28697413206100464
Batch 4/64 loss: 0.2987663745880127
Batch 5/64 loss: 0.288953959941864
Batch 6/64 loss: 0.29241907596588135
Batch 7/64 loss: 0.3032701015472412
Batch 8/64 loss: 0.29432225227355957
Batch 9/64 loss: 0.29409587383270264
Batch 10/64 loss: 0.28595924377441406
Batch 11/64 loss: 0.299824595451355
Batch 12/64 loss: 0.30874431133270264
Batch 13/64 loss: 0.29438602924346924
Batch 14/64 loss: 0.296906054019928
Batch 15/64 loss: 0.30209481716156006
Batch 16/64 loss: 0.30031538009643555
Batch 17/64 loss: 0.2939203381538391
Batch 18/64 loss: 0.30016303062438965
Batch 19/64 loss: 0.2955811023712158
Batch 20/64 loss: 0.2902723550796509
Batch 21/64 loss: 0.3050829768180847
Batch 22/64 loss: 0.29471099376678467
Batch 23/64 loss: 0.3038082718849182
Batch 24/64 loss: 0.29289984703063965
Batch 25/64 loss: 0.30774664878845215
Batch 26/64 loss: 0.296203076839447
Batch 27/64 loss: 0.3015322685241699
Batch 28/64 loss: 0.28900521993637085
Batch 29/64 loss: 0.3076525330543518
Batch 30/64 loss: 0.29940444231033325
Batch 31/64 loss: 0.28884613513946533
Batch 32/64 loss: 0.297865629196167
Batch 33/64 loss: 0.29179543256759644
Batch 34/64 loss: 0.29972076416015625
Batch 35/64 loss: 0.2986074686050415
Batch 36/64 loss: 0.2983832359313965
Batch 37/64 loss: 0.29884636402130127
Batch 38/64 loss: 0.3003561496734619
Batch 39/64 loss: 0.28690123558044434
Batch 40/64 loss: 0.2906642556190491
Batch 41/64 loss: 0.2890423536300659
Batch 42/64 loss: 0.2993277311325073
Batch 43/64 loss: 0.3040426969528198
Batch 44/64 loss: 0.3043261766433716
Batch 45/64 loss: 0.29466158151626587
Batch 46/64 loss: 0.29331839084625244
Batch 47/64 loss: 0.3037264943122864
Batch 48/64 loss: 0.28880518674850464
Batch 49/64 loss: 0.30308008193969727
Batch 50/64 loss: 0.29915130138397217
Batch 51/64 loss: 0.29299962520599365
Batch 52/64 loss: 0.302714467048645
Batch 53/64 loss: 0.29568779468536377
Batch 54/64 loss: 0.30402326583862305
Batch 55/64 loss: 0.2961275577545166
Batch 56/64 loss: 0.299930214881897
Batch 57/64 loss: 0.29031848907470703
Batch 58/64 loss: 0.30892515182495117
Batch 59/64 loss: 0.303755521774292
Batch 60/64 loss: 0.3035600185394287
Batch 61/64 loss: 0.29806482791900635
Batch 62/64 loss: 0.30223721265792847
Batch 63/64 loss: 0.29085540771484375
Batch 64/64 loss: 0.30996251106262207
Epoch 355  Train loss: 0.29774092973447314  Val loss: 0.32599152814072024
Epoch 356
-------------------------------
Batch 1/64 loss: 0.30499064922332764
Batch 2/64 loss: 0.2942967414855957
Batch 3/64 loss: 0.30055129528045654
Batch 4/64 loss: 0.29781103134155273
Batch 5/64 loss: 0.30498307943344116
Batch 6/64 loss: 0.29270070791244507
Batch 7/64 loss: 0.3051506280899048
Batch 8/64 loss: 0.29575324058532715
Batch 9/64 loss: 0.28653013706207275
Batch 10/64 loss: 0.30084657669067383
Batch 11/64 loss: 0.291318416595459
Batch 12/64 loss: 0.28855788707733154
Batch 13/64 loss: 0.31139326095581055
Batch 14/64 loss: 0.3021456003189087
Batch 15/64 loss: 0.2961134910583496
Batch 16/64 loss: 0.29828476905822754
Batch 17/64 loss: 0.2932712435722351
Batch 18/64 loss: 0.2999657392501831
Batch 19/64 loss: 0.29005903005599976
Batch 20/64 loss: 0.30000078678131104
Batch 21/64 loss: 0.2934921383857727
Batch 22/64 loss: 0.30909228324890137
Batch 23/64 loss: 0.29788053035736084
Batch 24/64 loss: 0.3035905361175537
Batch 25/64 loss: 0.30015355348587036
Batch 26/64 loss: 0.30076587200164795
Batch 27/64 loss: 0.3072396516799927
Batch 28/64 loss: 0.3126760721206665
Batch 29/64 loss: 0.29480963945388794
Batch 30/64 loss: 0.2945776581764221
Batch 31/64 loss: 0.30129504203796387
Batch 32/64 loss: 0.2951253056526184
Batch 33/64 loss: 0.2986597418785095
Batch 34/64 loss: 0.3051496744155884
Batch 35/64 loss: 0.3002958297729492
Batch 36/64 loss: 0.2942163944244385
Batch 37/64 loss: 0.2910098433494568
Batch 38/64 loss: 0.30253279209136963
Batch 39/64 loss: 0.3025670051574707
Batch 40/64 loss: 0.2987786531448364
Batch 41/64 loss: 0.31069499254226685
Batch 42/64 loss: 0.30152517557144165
Batch 43/64 loss: 0.30130183696746826
Batch 44/64 loss: 0.28558194637298584
Batch 45/64 loss: 0.2947312593460083
Batch 46/64 loss: 0.2863008379936218
Batch 47/64 loss: 0.29386115074157715
Batch 48/64 loss: 0.2948228120803833
Batch 49/64 loss: 0.291542649269104
Batch 50/64 loss: 0.3056814670562744
Batch 51/64 loss: 0.29644036293029785
Batch 52/64 loss: 0.3039630055427551
Batch 53/64 loss: 0.29982614517211914
Batch 54/64 loss: 0.291218638420105
Batch 55/64 loss: 0.3083378076553345
Batch 56/64 loss: 0.3009864091873169
Batch 57/64 loss: 0.30030959844589233
Batch 58/64 loss: 0.29733598232269287
Batch 59/64 loss: 0.30038851499557495
Batch 60/64 loss: 0.2982269525527954
Batch 61/64 loss: 0.29991137981414795
Batch 62/64 loss: 0.29392731189727783
Batch 63/64 loss: 0.30205440521240234
Batch 64/64 loss: 0.2914126515388489
Epoch 356  Train loss: 0.2986064730906019  Val loss: 0.3263804476285718
Epoch 357
-------------------------------
Batch 1/64 loss: 0.2929619550704956
Batch 2/64 loss: 0.29603707790374756
Batch 3/64 loss: 0.297294020652771
Batch 4/64 loss: 0.2846575975418091
Batch 5/64 loss: 0.2933846712112427
Batch 6/64 loss: 0.2985074520111084
Batch 7/64 loss: 0.2929579019546509
Batch 8/64 loss: 0.3032585382461548
Batch 9/64 loss: 0.2940603494644165
Batch 10/64 loss: 0.30076950788497925
Batch 11/64 loss: 0.3025110363960266
Batch 12/64 loss: 0.29684263467788696
Batch 13/64 loss: 0.30052894353866577
Batch 14/64 loss: 0.2940935492515564
Batch 15/64 loss: 0.3033010959625244
Batch 16/64 loss: 0.2976219654083252
Batch 17/64 loss: 0.29514622688293457
Batch 18/64 loss: 0.30852121114730835
Batch 19/64 loss: 0.29622018337249756
Batch 20/64 loss: 0.30203306674957275
Batch 21/64 loss: 0.28302478790283203
Batch 22/64 loss: 0.2942449450492859
Batch 23/64 loss: 0.3047024607658386
Batch 24/64 loss: 0.29695695638656616
Batch 25/64 loss: 0.29792308807373047
Batch 26/64 loss: 0.29258906841278076
Batch 27/64 loss: 0.29222553968429565
Batch 28/64 loss: 0.30261874198913574
Batch 29/64 loss: 0.30235201120376587
Batch 30/64 loss: 0.3044320344924927
Batch 31/64 loss: 0.2985430955886841
Batch 32/64 loss: 0.29275715351104736
Batch 33/64 loss: 0.30099350214004517
Batch 34/64 loss: 0.29844462871551514
Batch 35/64 loss: 0.2966724634170532
Batch 36/64 loss: 0.2921243906021118
Batch 37/64 loss: 0.2995591163635254
Batch 38/64 loss: 0.29689455032348633
Batch 39/64 loss: 0.29702651500701904
Batch 40/64 loss: 0.3013988733291626
Batch 41/64 loss: 0.3028906583786011
Batch 42/64 loss: 0.30036354064941406
Batch 43/64 loss: 0.3020516633987427
Batch 44/64 loss: 0.2929839491844177
Batch 45/64 loss: 0.29143697023391724
Batch 46/64 loss: 0.30942457914352417
Batch 47/64 loss: 0.2958199977874756
Batch 48/64 loss: 0.29863929748535156
Batch 49/64 loss: 0.30330753326416016
Batch 50/64 loss: 0.29677844047546387
Batch 51/64 loss: 0.3097359538078308
Batch 52/64 loss: 0.2958916425704956
Batch 53/64 loss: 0.3051450252532959
Batch 54/64 loss: 0.3032721281051636
Batch 55/64 loss: 0.2943934202194214
Batch 56/64 loss: 0.30187511444091797
Batch 57/64 loss: 0.2988804578781128
Batch 58/64 loss: 0.301672101020813
Batch 59/64 loss: 0.2921915650367737
Batch 60/64 loss: 0.28997647762298584
Batch 61/64 loss: 0.29144448041915894
Batch 62/64 loss: 0.2964121103286743
Batch 63/64 loss: 0.3026463985443115
Batch 64/64 loss: 0.31089645624160767
Epoch 357  Train loss: 0.29814272557987886  Val loss: 0.3252475085537049
Epoch 358
-------------------------------
Batch 1/64 loss: 0.2966969609260559
Batch 2/64 loss: 0.28965306282043457
Batch 3/64 loss: 0.2954583764076233
Batch 4/64 loss: 0.3018016219139099
Batch 5/64 loss: 0.3043797016143799
Batch 6/64 loss: 0.3007449507713318
Batch 7/64 loss: 0.29762059450149536
Batch 8/64 loss: 0.29618382453918457
Batch 9/64 loss: 0.297002911567688
Batch 10/64 loss: 0.29378199577331543
Batch 11/64 loss: 0.2949991226196289
Batch 12/64 loss: 0.2929125428199768
Batch 13/64 loss: 0.3000635504722595
Batch 14/64 loss: 0.29956984519958496
Batch 15/64 loss: 0.2893056273460388
Batch 16/64 loss: 0.2974395751953125
Batch 17/64 loss: 0.28831028938293457
Batch 18/64 loss: 0.2875704765319824
Batch 19/64 loss: 0.2914162278175354
Batch 20/64 loss: 0.29529809951782227
Batch 21/64 loss: 0.2945001721382141
Batch 22/64 loss: 0.3043193817138672
Batch 23/64 loss: 0.30069589614868164
Batch 24/64 loss: 0.2984122633934021
Batch 25/64 loss: 0.2965322732925415
Batch 26/64 loss: 0.3007012605667114
Batch 27/64 loss: 0.29761505126953125
Batch 28/64 loss: 0.30183887481689453
Batch 29/64 loss: 0.3068886995315552
Batch 30/64 loss: 0.29497456550598145
Batch 31/64 loss: 0.2967897653579712
Batch 32/64 loss: 0.2980192303657532
Batch 33/64 loss: 0.2945420742034912
Batch 34/64 loss: 0.29166215658187866
Batch 35/64 loss: 0.2956411838531494
Batch 36/64 loss: 0.3010174036026001
Batch 37/64 loss: 0.2983511686325073
Batch 38/64 loss: 0.2981492877006531
Batch 39/64 loss: 0.2864471673965454
Batch 40/64 loss: 0.2877892851829529
Batch 41/64 loss: 0.30675530433654785
Batch 42/64 loss: 0.30021488666534424
Batch 43/64 loss: 0.2914271354675293
Batch 44/64 loss: 0.28931182622909546
Batch 45/64 loss: 0.31103944778442383
Batch 46/64 loss: 0.2967858910560608
Batch 47/64 loss: 0.30635297298431396
Batch 48/64 loss: 0.2993232011795044
Batch 49/64 loss: 0.29656732082366943
Batch 50/64 loss: 0.29142558574676514
Batch 51/64 loss: 0.2875708341598511
Batch 52/64 loss: 0.29743528366088867
Batch 53/64 loss: 0.30026859045028687
Batch 54/64 loss: 0.2945204973220825
Batch 55/64 loss: 0.3089931607246399
Batch 56/64 loss: 0.29896336793899536
Batch 57/64 loss: 0.3051133155822754
Batch 58/64 loss: 0.29901623725891113
Batch 59/64 loss: 0.2954401969909668
Batch 60/64 loss: 0.30455708503723145
Batch 61/64 loss: 0.29192614555358887
Batch 62/64 loss: 0.2973257899284363
Batch 63/64 loss: 0.3042891025543213
Batch 64/64 loss: 0.29823940992355347
Epoch 358  Train loss: 0.297308223621518  Val loss: 0.3260574420702826
Epoch 359
-------------------------------
Batch 1/64 loss: 0.2970094680786133
Batch 2/64 loss: 0.3011419177055359
Batch 3/64 loss: 0.2959885001182556
Batch 4/64 loss: 0.30483949184417725
Batch 5/64 loss: 0.298772931098938
Batch 6/64 loss: 0.2930567264556885
Batch 7/64 loss: 0.2933911085128784
Batch 8/64 loss: 0.2996542453765869
Batch 9/64 loss: 0.30551469326019287
Batch 10/64 loss: 0.296619176864624
Batch 11/64 loss: 0.2925085425376892
Batch 12/64 loss: 0.2903667688369751
Batch 13/64 loss: 0.30083590745925903
Batch 14/64 loss: 0.3021061420440674
Batch 15/64 loss: 0.30286622047424316
Batch 16/64 loss: 0.2907916307449341
Batch 17/64 loss: 0.29676854610443115
Batch 18/64 loss: 0.3027857542037964
Batch 19/64 loss: 0.29735302925109863
Batch 20/64 loss: 0.31217360496520996
Batch 21/64 loss: 0.29456770420074463
Batch 22/64 loss: 0.2968994379043579
Batch 23/64 loss: 0.2989993095397949
Batch 24/64 loss: 0.2909209728240967
Batch 25/64 loss: 0.29727399349212646
Batch 26/64 loss: 0.30678653717041016
Batch 27/64 loss: 0.2934614419937134
Batch 28/64 loss: 0.29353582859039307
Batch 29/64 loss: 0.2998114824295044
Batch 30/64 loss: 0.3044578433036804
Batch 31/64 loss: 0.3000892400741577
Batch 32/64 loss: 0.29749298095703125
Batch 33/64 loss: 0.29671502113342285
Batch 34/64 loss: 0.29944491386413574
Batch 35/64 loss: 0.29415363073349
Batch 36/64 loss: 0.2973117232322693
Batch 37/64 loss: 0.30531060695648193
Batch 38/64 loss: 0.28213727474212646
Batch 39/64 loss: 0.302127480506897
Batch 40/64 loss: 0.29938173294067383
Batch 41/64 loss: 0.28991425037384033
Batch 42/64 loss: 0.29488885402679443
Batch 43/64 loss: 0.2995181083679199
Batch 44/64 loss: 0.2961493730545044
Batch 45/64 loss: 0.2969507575035095
Batch 46/64 loss: 0.3033856153488159
Batch 47/64 loss: 0.2987629175186157
Batch 48/64 loss: 0.3065084218978882
Batch 49/64 loss: 0.29886817932128906
Batch 50/64 loss: 0.2968926429748535
Batch 51/64 loss: 0.3078145384788513
Batch 52/64 loss: 0.2959786653518677
Batch 53/64 loss: 0.29762041568756104
Batch 54/64 loss: 0.3001610040664673
Batch 55/64 loss: 0.2944459319114685
Batch 56/64 loss: 0.2871149182319641
Batch 57/64 loss: 0.2966940402984619
Batch 58/64 loss: 0.2947530746459961
Batch 59/64 loss: 0.2918283939361572
Batch 60/64 loss: 0.29542624950408936
Batch 61/64 loss: 0.3000626564025879
Batch 62/64 loss: 0.2984919548034668
Batch 63/64 loss: 0.3035099506378174
Batch 64/64 loss: 0.2987816333770752
Epoch 359  Train loss: 0.29796471689261644  Val loss: 0.3261466388849868
Epoch 360
-------------------------------
Batch 1/64 loss: 0.29768431186676025
Batch 2/64 loss: 0.2948821783065796
Batch 3/64 loss: 0.30463922023773193
Batch 4/64 loss: 0.3039628863334656
Batch 5/64 loss: 0.2970186471939087
Batch 6/64 loss: 0.29590773582458496
Batch 7/64 loss: 0.2954655885696411
Batch 8/64 loss: 0.29848945140838623
Batch 9/64 loss: 0.2993010878562927
Batch 10/64 loss: 0.30012112855911255
Batch 11/64 loss: 0.3019102215766907
Batch 12/64 loss: 0.3038814663887024
Batch 13/64 loss: 0.3071836233139038
Batch 14/64 loss: 0.3057659864425659
Batch 15/64 loss: 0.29140526056289673
Batch 16/64 loss: 0.3006640672683716
Batch 17/64 loss: 0.3014752268791199
Batch 18/64 loss: 0.295590877532959
Batch 19/64 loss: 0.2978113293647766
Batch 20/64 loss: 0.294483482837677
Batch 21/64 loss: 0.2963194251060486
Batch 22/64 loss: 0.290971040725708
Batch 23/64 loss: 0.28759896755218506
Batch 24/64 loss: 0.29511988162994385
Batch 25/64 loss: 0.29744064807891846
Batch 26/64 loss: 0.29399430751800537
Batch 27/64 loss: 0.3085298538208008
Batch 28/64 loss: 0.2930339574813843
Batch 29/64 loss: 0.2962719202041626
Batch 30/64 loss: 0.296472430229187
Batch 31/64 loss: 0.2940640449523926
Batch 32/64 loss: 0.2939980626106262
Batch 33/64 loss: 0.29967302083969116
Batch 34/64 loss: 0.2942389249801636
Batch 35/64 loss: 0.29973554611206055
Batch 36/64 loss: 0.307781457901001
Batch 37/64 loss: 0.2895350456237793
Batch 38/64 loss: 0.29187917709350586
Batch 39/64 loss: 0.293076753616333
Batch 40/64 loss: 0.3055201768875122
Batch 41/64 loss: 0.29780399799346924
Batch 42/64 loss: 0.29215824604034424
Batch 43/64 loss: 0.30218505859375
Batch 44/64 loss: 0.29107052087783813
Batch 45/64 loss: 0.2978936433792114
Batch 46/64 loss: 0.3023853898048401
Batch 47/64 loss: 0.3034437894821167
Batch 48/64 loss: 0.3010956645011902
Batch 49/64 loss: 0.3014352321624756
Batch 50/64 loss: 0.2973417043685913
Batch 51/64 loss: 0.2951023578643799
Batch 52/64 loss: 0.28822028636932373
Batch 53/64 loss: 0.299410343170166
Batch 54/64 loss: 0.30570870637893677
Batch 55/64 loss: 0.29237228631973267
Batch 56/64 loss: 0.3060579299926758
Batch 57/64 loss: 0.29429465532302856
Batch 58/64 loss: 0.29311293363571167
Batch 59/64 loss: 0.30505847930908203
Batch 60/64 loss: 0.3042948246002197
Batch 61/64 loss: 0.30518126487731934
Batch 62/64 loss: 0.3000747561454773
Batch 63/64 loss: 0.29238927364349365
Batch 64/64 loss: 0.30834442377090454
Epoch 360  Train loss: 0.29823134249331906  Val loss: 0.325569427300155
Epoch 361
-------------------------------
Batch 1/64 loss: 0.29263514280319214
Batch 2/64 loss: 0.29661762714385986
Batch 3/64 loss: 0.2940530776977539
Batch 4/64 loss: 0.3066197633743286
Batch 5/64 loss: 0.3008265495300293
Batch 6/64 loss: 0.2827576994895935
Batch 7/64 loss: 0.2903714179992676
Batch 8/64 loss: 0.2974879741668701
Batch 9/64 loss: 0.301713764667511
Batch 10/64 loss: 0.2942589521408081
Batch 11/64 loss: 0.2960629463195801
Batch 12/64 loss: 0.29952549934387207
Batch 13/64 loss: 0.2926206588745117
Batch 14/64 loss: 0.2945183515548706
Batch 15/64 loss: 0.2958989143371582
Batch 16/64 loss: 0.29962050914764404
Batch 17/64 loss: 0.292521595954895
Batch 18/64 loss: 0.30840420722961426
Batch 19/64 loss: 0.2969093918800354
Batch 20/64 loss: 0.2928789258003235
Batch 21/64 loss: 0.29274940490722656
Batch 22/64 loss: 0.313130259513855
Batch 23/64 loss: 0.295653760433197
Batch 24/64 loss: 0.2973102331161499
Batch 25/64 loss: 0.2980393171310425
Batch 26/64 loss: 0.2988967299461365
Batch 27/64 loss: 0.2978348731994629
Batch 28/64 loss: 0.2997097373008728
Batch 29/64 loss: 0.306291401386261
Batch 30/64 loss: 0.3040812015533447
Batch 31/64 loss: 0.29588067531585693
Batch 32/64 loss: 0.2980198860168457
Batch 33/64 loss: 0.2910740375518799
Batch 34/64 loss: 0.300686240196228
Batch 35/64 loss: 0.2968013882637024
Batch 36/64 loss: 0.29676657915115356
Batch 37/64 loss: 0.29171228408813477
Batch 38/64 loss: 0.2901648283004761
Batch 39/64 loss: 0.2876221537590027
Batch 40/64 loss: 0.3004247546195984
Batch 41/64 loss: 0.3038792610168457
Batch 42/64 loss: 0.29236191511154175
Batch 43/64 loss: 0.2988460063934326
Batch 44/64 loss: 0.29792600870132446
Batch 45/64 loss: 0.30071109533309937
Batch 46/64 loss: 0.29075467586517334
Batch 47/64 loss: 0.29881608486175537
Batch 48/64 loss: 0.298656165599823
Batch 49/64 loss: 0.2950563430786133
Batch 50/64 loss: 0.30171477794647217
Batch 51/64 loss: 0.30159878730773926
Batch 52/64 loss: 0.2883179783821106
Batch 53/64 loss: 0.30777913331985474
Batch 54/64 loss: 0.2933887243270874
Batch 55/64 loss: 0.2971538305282593
Batch 56/64 loss: 0.30406832695007324
Batch 57/64 loss: 0.29043447971343994
Batch 58/64 loss: 0.3019571304321289
Batch 59/64 loss: 0.30020081996917725
Batch 60/64 loss: 0.298972487449646
Batch 61/64 loss: 0.30512458086013794
Batch 62/64 loss: 0.300170361995697
Batch 63/64 loss: 0.2934739589691162
Batch 64/64 loss: 0.3052062392234802
Epoch 361  Train loss: 0.2975595345684126  Val loss: 0.3264167292421216
Epoch 362
-------------------------------
Batch 1/64 loss: 0.304978609085083
Batch 2/64 loss: 0.30118513107299805
Batch 3/64 loss: 0.2986217737197876
Batch 4/64 loss: 0.2917502522468567
Batch 5/64 loss: 0.29515600204467773
Batch 6/64 loss: 0.29289209842681885
Batch 7/64 loss: 0.29736578464508057
Batch 8/64 loss: 0.2917100191116333
Batch 9/64 loss: 0.2953718304634094
Batch 10/64 loss: 0.29879438877105713
Batch 11/64 loss: 0.29806411266326904
Batch 12/64 loss: 0.2931586503982544
Batch 13/64 loss: 0.2948400378227234
Batch 14/64 loss: 0.3071855306625366
Batch 15/64 loss: 0.29728686809539795
Batch 16/64 loss: 0.29455721378326416
Batch 17/64 loss: 0.3058948516845703
Batch 18/64 loss: 0.2908512353897095
Batch 19/64 loss: 0.29447782039642334
Batch 20/64 loss: 0.28853511810302734
Batch 21/64 loss: 0.2979240417480469
Batch 22/64 loss: 0.2947732210159302
Batch 23/64 loss: 0.29544806480407715
Batch 24/64 loss: 0.30433905124664307
Batch 25/64 loss: 0.2966858744621277
Batch 26/64 loss: 0.30082982778549194
Batch 27/64 loss: 0.2895675301551819
Batch 28/64 loss: 0.2996283769607544
Batch 29/64 loss: 0.29673731327056885
Batch 30/64 loss: 0.29219764471054077
Batch 31/64 loss: 0.2929278612136841
Batch 32/64 loss: 0.29959022998809814
Batch 33/64 loss: 0.2901802062988281
Batch 34/64 loss: 0.29317349195480347
Batch 35/64 loss: 0.30391740798950195
Batch 36/64 loss: 0.29300713539123535
Batch 37/64 loss: 0.3023252487182617
Batch 38/64 loss: 0.29662299156188965
Batch 39/64 loss: 0.29710811376571655
Batch 40/64 loss: 0.2995901107788086
Batch 41/64 loss: 0.2933201789855957
Batch 42/64 loss: 0.3025273084640503
Batch 43/64 loss: 0.29508817195892334
Batch 44/64 loss: 0.2962740659713745
Batch 45/64 loss: 0.29853105545043945
Batch 46/64 loss: 0.2895296812057495
Batch 47/64 loss: 0.2983386516571045
Batch 48/64 loss: 0.3024172782897949
Batch 49/64 loss: 0.2962344288825989
Batch 50/64 loss: 0.299247682094574
Batch 51/64 loss: 0.302653431892395
Batch 52/64 loss: 0.29396605491638184
Batch 53/64 loss: 0.29297852516174316
Batch 54/64 loss: 0.29249370098114014
Batch 55/64 loss: 0.2929975986480713
Batch 56/64 loss: 0.289478063583374
Batch 57/64 loss: 0.3019539713859558
Batch 58/64 loss: 0.2994459867477417
Batch 59/64 loss: 0.3035116195678711
Batch 60/64 loss: 0.30171501636505127
Batch 61/64 loss: 0.304803729057312
Batch 62/64 loss: 0.3032989501953125
Batch 63/64 loss: 0.29856693744659424
Batch 64/64 loss: 0.2890005111694336
Epoch 362  Train loss: 0.2970254673677332  Val loss: 0.32624549390524116
Epoch 363
-------------------------------
Batch 1/64 loss: 0.2926011085510254
Batch 2/64 loss: 0.2888275980949402
Batch 3/64 loss: 0.3157803416252136
Batch 4/64 loss: 0.30114448070526123
Batch 5/64 loss: 0.29113340377807617
Batch 6/64 loss: 0.3040817975997925
Batch 7/64 loss: 0.30442410707473755
Batch 8/64 loss: 0.29335153102874756
Batch 9/64 loss: 0.2980138063430786
Batch 10/64 loss: 0.2891111969947815
Batch 11/64 loss: 0.30281150341033936
Batch 12/64 loss: 0.2983349561691284
Batch 13/64 loss: 0.2987813353538513
Batch 14/64 loss: 0.2978864908218384
Batch 15/64 loss: 0.2903737425804138
Batch 16/64 loss: 0.3020029067993164
Batch 17/64 loss: 0.2999035120010376
Batch 18/64 loss: 0.2838086485862732
Batch 19/64 loss: 0.29159069061279297
Batch 20/64 loss: 0.2852616310119629
Batch 21/64 loss: 0.29648667573928833
Batch 22/64 loss: 0.29492759704589844
Batch 23/64 loss: 0.29656100273132324
Batch 24/64 loss: 0.2936539053916931
Batch 25/64 loss: 0.2889954447746277
Batch 26/64 loss: 0.29913610219955444
Batch 27/64 loss: 0.30447936058044434
Batch 28/64 loss: 0.30019301176071167
Batch 29/64 loss: 0.29834800958633423
Batch 30/64 loss: 0.29878175258636475
Batch 31/64 loss: 0.28229820728302
Batch 32/64 loss: 0.2961745262145996
Batch 33/64 loss: 0.30030858516693115
Batch 34/64 loss: 0.2908537983894348
Batch 35/64 loss: 0.2949775457382202
Batch 36/64 loss: 0.3028639554977417
Batch 37/64 loss: 0.29442793130874634
Batch 38/64 loss: 0.29556262493133545
Batch 39/64 loss: 0.310214638710022
Batch 40/64 loss: 0.2899489402770996
Batch 41/64 loss: 0.31089407205581665
Batch 42/64 loss: 0.3054952621459961
Batch 43/64 loss: 0.2973482012748718
Batch 44/64 loss: 0.3034384250640869
Batch 45/64 loss: 0.3051602244377136
Batch 46/64 loss: 0.3023974895477295
Batch 47/64 loss: 0.29091185331344604
Batch 48/64 loss: 0.28850769996643066
Batch 49/64 loss: 0.30415141582489014
Batch 50/64 loss: 0.3007826805114746
Batch 51/64 loss: 0.3057625889778137
Batch 52/64 loss: 0.3033252954483032
Batch 53/64 loss: 0.30401623249053955
Batch 54/64 loss: 0.284274697303772
Batch 55/64 loss: 0.29966527223587036
Batch 56/64 loss: 0.3018563389778137
Batch 57/64 loss: 0.3029768466949463
Batch 58/64 loss: 0.2994542717933655
Batch 59/64 loss: 0.29966580867767334
Batch 60/64 loss: 0.29358017444610596
Batch 61/64 loss: 0.29767489433288574
Batch 62/64 loss: 0.2940833568572998
Batch 63/64 loss: 0.2957964539527893
Batch 64/64 loss: 0.30512768030166626
Epoch 363  Train loss: 0.2977017054370805  Val loss: 0.3255432160039948
Epoch 364
-------------------------------
Batch 1/64 loss: 0.2970384955406189
Batch 2/64 loss: 0.28762078285217285
Batch 3/64 loss: 0.2971682548522949
Batch 4/64 loss: 0.2938063144683838
Batch 5/64 loss: 0.3006359934806824
Batch 6/64 loss: 0.28350120782852173
Batch 7/64 loss: 0.2912553548812866
Batch 8/64 loss: 0.3051522970199585
Batch 9/64 loss: 0.3032881021499634
Batch 10/64 loss: 0.2919296622276306
Batch 11/64 loss: 0.2994471788406372
Batch 12/64 loss: 0.30891942977905273
Batch 13/64 loss: 0.29988497495651245
Batch 14/64 loss: 0.2956511974334717
Batch 15/64 loss: 0.2838258743286133
Batch 16/64 loss: 0.29967236518859863
Batch 17/64 loss: 0.29499441385269165
Batch 18/64 loss: 0.29722297191619873
Batch 19/64 loss: 0.2907458543777466
Batch 20/64 loss: 0.296623170375824
Batch 21/64 loss: 0.29517608880996704
Batch 22/64 loss: 0.3032069206237793
Batch 23/64 loss: 0.2913926839828491
Batch 24/64 loss: 0.3002523183822632
Batch 25/64 loss: 0.2940322160720825
Batch 26/64 loss: 0.303031325340271
Batch 27/64 loss: 0.29586565494537354
Batch 28/64 loss: 0.30988049507141113
Batch 29/64 loss: 0.2911701202392578
Batch 30/64 loss: 0.30020201206207275
Batch 31/64 loss: 0.29292935132980347
Batch 32/64 loss: 0.29550105333328247
Batch 33/64 loss: 0.29746896028518677
Batch 34/64 loss: 0.30807268619537354
Batch 35/64 loss: 0.29554909467697144
Batch 36/64 loss: 0.3001555800437927
Batch 37/64 loss: 0.29423487186431885
Batch 38/64 loss: 0.2986378073692322
Batch 39/64 loss: 0.28931307792663574
Batch 40/64 loss: 0.29521071910858154
Batch 41/64 loss: 0.30010986328125
Batch 42/64 loss: 0.3022913932800293
Batch 43/64 loss: 0.30605024099349976
Batch 44/64 loss: 0.3022180199623108
Batch 45/64 loss: 0.3087303042411804
Batch 46/64 loss: 0.3090342879295349
Batch 47/64 loss: 0.29984962940216064
Batch 48/64 loss: 0.2961568832397461
Batch 49/64 loss: 0.2978938817977905
Batch 50/64 loss: 0.29800647497177124
Batch 51/64 loss: 0.2953829765319824
Batch 52/64 loss: 0.29438138008117676
Batch 53/64 loss: 0.30060505867004395
Batch 54/64 loss: 0.2975578308105469
Batch 55/64 loss: 0.29789793491363525
Batch 56/64 loss: 0.29505449533462524
Batch 57/64 loss: 0.29400765895843506
Batch 58/64 loss: 0.2970459461212158
Batch 59/64 loss: 0.30286312103271484
Batch 60/64 loss: 0.2953302264213562
Batch 61/64 loss: 0.30052852630615234
Batch 62/64 loss: 0.29951345920562744
Batch 63/64 loss: 0.29330170154571533
Batch 64/64 loss: 0.2830115556716919
Epoch 364  Train loss: 0.2975017552282296  Val loss: 0.32571489458641234
Epoch 365
-------------------------------
Batch 1/64 loss: 0.30181753635406494
Batch 2/64 loss: 0.30569612979888916
Batch 3/64 loss: 0.29525792598724365
Batch 4/64 loss: 0.2931550145149231
Batch 5/64 loss: 0.28973162174224854
Batch 6/64 loss: 0.2864208221435547
Batch 7/64 loss: 0.29089218378067017
Batch 8/64 loss: 0.29357409477233887
Batch 9/64 loss: 0.2951716184616089
Batch 10/64 loss: 0.2938547134399414
Batch 11/64 loss: 0.2906368374824524
Batch 12/64 loss: 0.29753756523132324
Batch 13/64 loss: 0.3001655340194702
Batch 14/64 loss: 0.2905477285385132
Batch 15/64 loss: 0.29532599449157715
Batch 16/64 loss: 0.3007558584213257
Batch 17/64 loss: 0.3010562062263489
Batch 18/64 loss: 0.30110371112823486
Batch 19/64 loss: 0.3020842671394348
Batch 20/64 loss: 0.30119359493255615
Batch 21/64 loss: 0.2897757887840271
Batch 22/64 loss: 0.2994663715362549
Batch 23/64 loss: 0.3033214211463928
Batch 24/64 loss: 0.3028408885002136
Batch 25/64 loss: 0.2957266569137573
Batch 26/64 loss: 0.29385244846343994
Batch 27/64 loss: 0.29268205165863037
Batch 28/64 loss: 0.29262232780456543
Batch 29/64 loss: 0.30425071716308594
Batch 30/64 loss: 0.30724602937698364
Batch 31/64 loss: 0.2953959107398987
Batch 32/64 loss: 0.28930503129959106
Batch 33/64 loss: 0.2973693013191223
Batch 34/64 loss: 0.3005337119102478
Batch 35/64 loss: 0.29217374324798584
Batch 36/64 loss: 0.29248154163360596
Batch 37/64 loss: 0.3012818694114685
Batch 38/64 loss: 0.297632098197937
Batch 39/64 loss: 0.2941015958786011
Batch 40/64 loss: 0.28824877738952637
Batch 41/64 loss: 0.2955561876296997
Batch 42/64 loss: 0.2939065098762512
Batch 43/64 loss: 0.29754960536956787
Batch 44/64 loss: 0.3071770668029785
Batch 45/64 loss: 0.290461003780365
Batch 46/64 loss: 0.3015177845954895
Batch 47/64 loss: 0.29506081342697144
Batch 48/64 loss: 0.2968752384185791
Batch 49/64 loss: 0.29412758350372314
Batch 50/64 loss: 0.2934831976890564
Batch 51/64 loss: 0.3002207279205322
Batch 52/64 loss: 0.29890739917755127
Batch 53/64 loss: 0.30533134937286377
Batch 54/64 loss: 0.29801177978515625
Batch 55/64 loss: 0.2899620532989502
Batch 56/64 loss: 0.28917396068573
Batch 57/64 loss: 0.30545639991760254
Batch 58/64 loss: 0.29305821657180786
Batch 59/64 loss: 0.2914919853210449
Batch 60/64 loss: 0.30774986743927
Batch 61/64 loss: 0.2916799783706665
Batch 62/64 loss: 0.29512935876846313
Batch 63/64 loss: 0.2939807176589966
Batch 64/64 loss: 0.30267333984375
Epoch 365  Train loss: 0.2966142906862147  Val loss: 0.3265133100686614
Epoch 366
-------------------------------
Batch 1/64 loss: 0.29284417629241943
Batch 2/64 loss: 0.2938333749771118
Batch 3/64 loss: 0.2958083748817444
Batch 4/64 loss: 0.29320722818374634
Batch 5/64 loss: 0.30136603116989136
Batch 6/64 loss: 0.2914271950721741
Batch 7/64 loss: 0.29919445514678955
Batch 8/64 loss: 0.3108224868774414
Batch 9/64 loss: 0.2964079976081848
Batch 10/64 loss: 0.2962547540664673
Batch 11/64 loss: 0.29949963092803955
Batch 12/64 loss: 0.2968708276748657
Batch 13/64 loss: 0.29383373260498047
Batch 14/64 loss: 0.29730021953582764
Batch 15/64 loss: 0.2994586229324341
Batch 16/64 loss: 0.2927466034889221
Batch 17/64 loss: 0.29869765043258667
Batch 18/64 loss: 0.2860555648803711
Batch 19/64 loss: 0.2912295460700989
Batch 20/64 loss: 0.29062652587890625
Batch 21/64 loss: 0.30031198263168335
Batch 22/64 loss: 0.29013174772262573
Batch 23/64 loss: 0.2974631190299988
Batch 24/64 loss: 0.3036233186721802
Batch 25/64 loss: 0.2897471785545349
Batch 26/64 loss: 0.30371636152267456
Batch 27/64 loss: 0.2950078248977661
Batch 28/64 loss: 0.29337263107299805
Batch 29/64 loss: 0.3007194995880127
Batch 30/64 loss: 0.28961658477783203
Batch 31/64 loss: 0.2931075096130371
Batch 32/64 loss: 0.30576372146606445
Batch 33/64 loss: 0.3006283640861511
Batch 34/64 loss: 0.30675607919692993
Batch 35/64 loss: 0.307450532913208
Batch 36/64 loss: 0.29198288917541504
Batch 37/64 loss: 0.2995872497558594
Batch 38/64 loss: 0.29735231399536133
Batch 39/64 loss: 0.2930479645729065
Batch 40/64 loss: 0.29522138833999634
Batch 41/64 loss: 0.3047226071357727
Batch 42/64 loss: 0.295998215675354
Batch 43/64 loss: 0.2937058210372925
Batch 44/64 loss: 0.30207180976867676
Batch 45/64 loss: 0.29817724227905273
Batch 46/64 loss: 0.302165150642395
Batch 47/64 loss: 0.29437899589538574
Batch 48/64 loss: 0.30264586210250854
Batch 49/64 loss: 0.3117886781692505
Batch 50/64 loss: 0.29702329635620117
Batch 51/64 loss: 0.29758167266845703
Batch 52/64 loss: 0.2899739146232605
Batch 53/64 loss: 0.29765498638153076
Batch 54/64 loss: 0.29006004333496094
Batch 55/64 loss: 0.2891412377357483
Batch 56/64 loss: 0.29471802711486816
Batch 57/64 loss: 0.28841590881347656
Batch 58/64 loss: 0.2998921871185303
Batch 59/64 loss: 0.30138373374938965
Batch 60/64 loss: 0.2947518229484558
Batch 61/64 loss: 0.304831862449646
Batch 62/64 loss: 0.29144608974456787
Batch 63/64 loss: 0.2921457290649414
Batch 64/64 loss: 0.304707407951355
Epoch 366  Train loss: 0.2970242935068467  Val loss: 0.32638118562010143
Epoch 367
-------------------------------
Batch 1/64 loss: 0.29689300060272217
Batch 2/64 loss: 0.29585981369018555
Batch 3/64 loss: 0.29641979932785034
Batch 4/64 loss: 0.29919207096099854
Batch 5/64 loss: 0.2971998453140259
Batch 6/64 loss: 0.29167377948760986
Batch 7/64 loss: 0.29736047983169556
Batch 8/64 loss: 0.2907453179359436
Batch 9/64 loss: 0.2885364294052124
Batch 10/64 loss: 0.29735493659973145
Batch 11/64 loss: 0.2942693829536438
Batch 12/64 loss: 0.295127809047699
Batch 13/64 loss: 0.3031368851661682
Batch 14/64 loss: 0.2930522561073303
Batch 15/64 loss: 0.31299519538879395
Batch 16/64 loss: 0.3004918098449707
Batch 17/64 loss: 0.3029326796531677
Batch 18/64 loss: 0.2974868416786194
Batch 19/64 loss: 0.2923959493637085
Batch 20/64 loss: 0.28898370265960693
Batch 21/64 loss: 0.29661381244659424
Batch 22/64 loss: 0.2966454029083252
Batch 23/64 loss: 0.299577534198761
Batch 24/64 loss: 0.3044899106025696
Batch 25/64 loss: 0.3023527264595032
Batch 26/64 loss: 0.29724419116973877
Batch 27/64 loss: 0.29061782360076904
Batch 28/64 loss: 0.29372191429138184
Batch 29/64 loss: 0.30606961250305176
Batch 30/64 loss: 0.2898658514022827
Batch 31/64 loss: 0.30061906576156616
Batch 32/64 loss: 0.29004544019699097
Batch 33/64 loss: 0.29611456394195557
Batch 34/64 loss: 0.3023136854171753
Batch 35/64 loss: 0.3063274621963501
Batch 36/64 loss: 0.2974342107772827
Batch 37/64 loss: 0.29877954721450806
Batch 38/64 loss: 0.2894088625907898
Batch 39/64 loss: 0.29571402072906494
Batch 40/64 loss: 0.2838122844696045
Batch 41/64 loss: 0.28642737865448
Batch 42/64 loss: 0.29115748405456543
Batch 43/64 loss: 0.2918775677680969
Batch 44/64 loss: 0.3061351776123047
Batch 45/64 loss: 0.2966599464416504
Batch 46/64 loss: 0.2885020971298218
Batch 47/64 loss: 0.295299232006073
Batch 48/64 loss: 0.29818081855773926
Batch 49/64 loss: 0.2979022264480591
Batch 50/64 loss: 0.3033076524734497
Batch 51/64 loss: 0.2933843731880188
Batch 52/64 loss: 0.29387640953063965
Batch 53/64 loss: 0.2945026755332947
Batch 54/64 loss: 0.2947005033493042
Batch 55/64 loss: 0.29327392578125
Batch 56/64 loss: 0.2901284694671631
Batch 57/64 loss: 0.3038109540939331
Batch 58/64 loss: 0.29624617099761963
Batch 59/64 loss: 0.2905261516571045
Batch 60/64 loss: 0.30837613344192505
Batch 61/64 loss: 0.29950398206710815
Batch 62/64 loss: 0.30867403745651245
Batch 63/64 loss: 0.30276429653167725
Batch 64/64 loss: 0.2975769639015198
Epoch 367  Train loss: 0.2967572752167197  Val loss: 0.3249103891890483
Epoch 368
-------------------------------
Batch 1/64 loss: 0.2956864833831787
Batch 2/64 loss: 0.29099929332733154
Batch 3/64 loss: 0.29040229320526123
Batch 4/64 loss: 0.29035770893096924
Batch 5/64 loss: 0.29867494106292725
Batch 6/64 loss: 0.299899697303772
Batch 7/64 loss: 0.3016846179962158
Batch 8/64 loss: 0.30107223987579346
Batch 9/64 loss: 0.3053542971611023
Batch 10/64 loss: 0.3032299280166626
Batch 11/64 loss: 0.2991136908531189
Batch 12/64 loss: 0.2955360412597656
Batch 13/64 loss: 0.292142391204834
Batch 14/64 loss: 0.2919771671295166
Batch 15/64 loss: 0.30311161279678345
Batch 16/64 loss: 0.3036031126976013
Batch 17/64 loss: 0.28932642936706543
Batch 18/64 loss: 0.303602933883667
Batch 19/64 loss: 0.29563093185424805
Batch 20/64 loss: 0.2889401912689209
Batch 21/64 loss: 0.28713834285736084
Batch 22/64 loss: 0.2978624105453491
Batch 23/64 loss: 0.29292964935302734
Batch 24/64 loss: 0.29857146739959717
Batch 25/64 loss: 0.29891884326934814
Batch 26/64 loss: 0.29606813192367554
Batch 27/64 loss: 0.29448413848876953
Batch 28/64 loss: 0.3088035583496094
Batch 29/64 loss: 0.2887679934501648
Batch 30/64 loss: 0.30464017391204834
Batch 31/64 loss: 0.302528977394104
Batch 32/64 loss: 0.296671986579895
Batch 33/64 loss: 0.2965930700302124
Batch 34/64 loss: 0.3021972179412842
Batch 35/64 loss: 0.29316675662994385
Batch 36/64 loss: 0.29226386547088623
Batch 37/64 loss: 0.29778850078582764
Batch 38/64 loss: 0.2969173192977905
Batch 39/64 loss: 0.3064420223236084
Batch 40/64 loss: 0.297776460647583
Batch 41/64 loss: 0.29053622484207153
Batch 42/64 loss: 0.2944996953010559
Batch 43/64 loss: 0.29865962266921997
Batch 44/64 loss: 0.29654717445373535
Batch 45/64 loss: 0.2927095890045166
Batch 46/64 loss: 0.3047363758087158
Batch 47/64 loss: 0.2929123640060425
Batch 48/64 loss: 0.29933422803878784
Batch 49/64 loss: 0.3024008274078369
Batch 50/64 loss: 0.29297584295272827
Batch 51/64 loss: 0.29317575693130493
Batch 52/64 loss: 0.28619641065597534
Batch 53/64 loss: 0.296359658241272
Batch 54/64 loss: 0.2886948585510254
Batch 55/64 loss: 0.3102990984916687
Batch 56/64 loss: 0.2894667983055115
Batch 57/64 loss: 0.2801114320755005
Batch 58/64 loss: 0.30031782388687134
Batch 59/64 loss: 0.2999986410140991
Batch 60/64 loss: 0.305942177772522
Batch 61/64 loss: 0.29249799251556396
Batch 62/64 loss: 0.2826473116874695
Batch 63/64 loss: 0.30486977100372314
Batch 64/64 loss: 0.30086207389831543
Epoch 368  Train loss: 0.296665303847369  Val loss: 0.32554598649342853
Epoch 369
-------------------------------
Batch 1/64 loss: 0.29761815071105957
Batch 2/64 loss: 0.3002416491508484
Batch 3/64 loss: 0.29759496450424194
Batch 4/64 loss: 0.2995895743370056
Batch 5/64 loss: 0.2926173210144043
Batch 6/64 loss: 0.2962164282798767
Batch 7/64 loss: 0.29184621572494507
Batch 8/64 loss: 0.298753023147583
Batch 9/64 loss: 0.29379355907440186
Batch 10/64 loss: 0.2892197370529175
Batch 11/64 loss: 0.29262053966522217
Batch 12/64 loss: 0.296836793422699
Batch 13/64 loss: 0.29687076807022095
Batch 14/64 loss: 0.2911229133605957
Batch 15/64 loss: 0.29942452907562256
Batch 16/64 loss: 0.30293262004852295
Batch 17/64 loss: 0.2905561923980713
Batch 18/64 loss: 0.2889863848686218
Batch 19/64 loss: 0.2978329062461853
Batch 20/64 loss: 0.29818737506866455
Batch 21/64 loss: 0.29559797048568726
Batch 22/64 loss: 0.3000074625015259
Batch 23/64 loss: 0.28513967990875244
Batch 24/64 loss: 0.29925763607025146
Batch 25/64 loss: 0.2877523899078369
Batch 26/64 loss: 0.2984845042228699
Batch 27/64 loss: 0.29649341106414795
Batch 28/64 loss: 0.3026106357574463
Batch 29/64 loss: 0.29207944869995117
Batch 30/64 loss: 0.29034626483917236
Batch 31/64 loss: 0.2920966148376465
Batch 32/64 loss: 0.3020075559616089
Batch 33/64 loss: 0.2910724878311157
Batch 34/64 loss: 0.28746742010116577
Batch 35/64 loss: 0.29927492141723633
Batch 36/64 loss: 0.302531361579895
Batch 37/64 loss: 0.29261314868927
Batch 38/64 loss: 0.2915739417076111
Batch 39/64 loss: 0.29446929693222046
Batch 40/64 loss: 0.2952902317047119
Batch 41/64 loss: 0.2966439127922058
Batch 42/64 loss: 0.2992282509803772
Batch 43/64 loss: 0.29855775833129883
Batch 44/64 loss: 0.29605352878570557
Batch 45/64 loss: 0.28564202785491943
Batch 46/64 loss: 0.2904106378555298
Batch 47/64 loss: 0.30126285552978516
Batch 48/64 loss: 0.30152976512908936
Batch 49/64 loss: 0.2890368700027466
Batch 50/64 loss: 0.29806697368621826
Batch 51/64 loss: 0.2966347932815552
Batch 52/64 loss: 0.29506945610046387
Batch 53/64 loss: 0.30485498905181885
Batch 54/64 loss: 0.2993220090866089
Batch 55/64 loss: 0.2896956205368042
Batch 56/64 loss: 0.30076485872268677
Batch 57/64 loss: 0.306670606136322
Batch 58/64 loss: 0.29894745349884033
Batch 59/64 loss: 0.3099687099456787
Batch 60/64 loss: 0.30432194471359253
Batch 61/64 loss: 0.2954346537590027
Batch 62/64 loss: 0.29049181938171387
Batch 63/64 loss: 0.2988699674606323
Batch 64/64 loss: 0.3024013042449951
Epoch 369  Train loss: 0.29620876031763416  Val loss: 0.3262893188859999
Epoch 370
-------------------------------
Batch 1/64 loss: 0.29905080795288086
Batch 2/64 loss: 0.3034058213233948
Batch 3/64 loss: 0.30328404903411865
Batch 4/64 loss: 0.29425710439682007
Batch 5/64 loss: 0.29370564222335815
Batch 6/64 loss: 0.2966270446777344
Batch 7/64 loss: 0.28830915689468384
Batch 8/64 loss: 0.2970946431159973
Batch 9/64 loss: 0.2922627925872803
Batch 10/64 loss: 0.2978516221046448
Batch 11/64 loss: 0.30037689208984375
Batch 12/64 loss: 0.29836124181747437
Batch 13/64 loss: 0.29399943351745605
Batch 14/64 loss: 0.29718828201293945
Batch 15/64 loss: 0.29602062702178955
Batch 16/64 loss: 0.297829270362854
Batch 17/64 loss: 0.3010663390159607
Batch 18/64 loss: 0.2809430956840515
Batch 19/64 loss: 0.29183095693588257
Batch 20/64 loss: 0.30444973707199097
Batch 21/64 loss: 0.29045987129211426
Batch 22/64 loss: 0.289916455745697
Batch 23/64 loss: 0.2934268116950989
Batch 24/64 loss: 0.29110968112945557
Batch 25/64 loss: 0.29788631200790405
Batch 26/64 loss: 0.30527985095977783
Batch 27/64 loss: 0.29472339153289795
Batch 28/64 loss: 0.2883898615837097
Batch 29/64 loss: 0.3061695098876953
Batch 30/64 loss: 0.2970874309539795
Batch 31/64 loss: 0.2889641523361206
Batch 32/64 loss: 0.2909678816795349
Batch 33/64 loss: 0.29915398359298706
Batch 34/64 loss: 0.3045583963394165
Batch 35/64 loss: 0.30430132150650024
Batch 36/64 loss: 0.2942620515823364
Batch 37/64 loss: 0.29773879051208496
Batch 38/64 loss: 0.2932337522506714
Batch 39/64 loss: 0.2977079153060913
Batch 40/64 loss: 0.3048880100250244
Batch 41/64 loss: 0.300692081451416
Batch 42/64 loss: 0.2873518466949463
Batch 43/64 loss: 0.29516953229904175
Batch 44/64 loss: 0.29869282245635986
Batch 45/64 loss: 0.2995215654373169
Batch 46/64 loss: 0.29563790559768677
Batch 47/64 loss: 0.2917870283126831
Batch 48/64 loss: 0.2993021011352539
Batch 49/64 loss: 0.30111002922058105
Batch 50/64 loss: 0.2941279411315918
Batch 51/64 loss: 0.306567907333374
Batch 52/64 loss: 0.2939804792404175
Batch 53/64 loss: 0.2923598289489746
Batch 54/64 loss: 0.29817378520965576
Batch 55/64 loss: 0.3014945983886719
Batch 56/64 loss: 0.28919804096221924
Batch 57/64 loss: 0.28837913274765015
Batch 58/64 loss: 0.3051735758781433
Batch 59/64 loss: 0.2949613928794861
Batch 60/64 loss: 0.29541856050491333
Batch 61/64 loss: 0.30007076263427734
Batch 62/64 loss: 0.2951682209968567
Batch 63/64 loss: 0.29840087890625
Batch 64/64 loss: 0.2949787378311157
Epoch 370  Train loss: 0.29650375001570756  Val loss: 0.32652868909114824
Epoch 371
-------------------------------
Batch 1/64 loss: 0.30099689960479736
Batch 2/64 loss: 0.302759051322937
Batch 3/64 loss: 0.29820215702056885
Batch 4/64 loss: 0.2953341603279114
Batch 5/64 loss: 0.2905043959617615
Batch 6/64 loss: 0.29967135190963745
Batch 7/64 loss: 0.30175793170928955
Batch 8/64 loss: 0.2936680316925049
Batch 9/64 loss: 0.28933238983154297
Batch 10/64 loss: 0.30186939239501953
Batch 11/64 loss: 0.2915381193161011
Batch 12/64 loss: 0.29726505279541016
Batch 13/64 loss: 0.2963283658027649
Batch 14/64 loss: 0.290199339389801
Batch 15/64 loss: 0.2942800521850586
Batch 16/64 loss: 0.2998340129852295
Batch 17/64 loss: 0.2880520224571228
Batch 18/64 loss: 0.29025375843048096
Batch 19/64 loss: 0.2925618886947632
Batch 20/64 loss: 0.28646236658096313
Batch 21/64 loss: 0.2872217893600464
Batch 22/64 loss: 0.2966107130050659
Batch 23/64 loss: 0.2935853600502014
Batch 24/64 loss: 0.2917333245277405
Batch 25/64 loss: 0.29930579662323
Batch 26/64 loss: 0.29559028148651123
Batch 27/64 loss: 0.2934550642967224
Batch 28/64 loss: 0.2888840436935425
Batch 29/64 loss: 0.29788684844970703
Batch 30/64 loss: 0.28731679916381836
Batch 31/64 loss: 0.30044758319854736
Batch 32/64 loss: 0.30774009227752686
Batch 33/64 loss: 0.3001713752746582
Batch 34/64 loss: 0.30066508054733276
Batch 35/64 loss: 0.299899697303772
Batch 36/64 loss: 0.2866160273551941
Batch 37/64 loss: 0.28971338272094727
Batch 38/64 loss: 0.29662859439849854
Batch 39/64 loss: 0.3041278123855591
Batch 40/64 loss: 0.296528697013855
Batch 41/64 loss: 0.29573988914489746
Batch 42/64 loss: 0.3002415895462036
Batch 43/64 loss: 0.3038891553878784
Batch 44/64 loss: 0.29292893409729004
Batch 45/64 loss: 0.2989104986190796
Batch 46/64 loss: 0.30826377868652344
Batch 47/64 loss: 0.294842004776001
Batch 48/64 loss: 0.30603253841400146
Batch 49/64 loss: 0.2923082113265991
Batch 50/64 loss: 0.2956269383430481
Batch 51/64 loss: 0.3033297061920166
Batch 52/64 loss: 0.2956061363220215
Batch 53/64 loss: 0.30151641368865967
Batch 54/64 loss: 0.29151594638824463
Batch 55/64 loss: 0.29621249437332153
Batch 56/64 loss: 0.296970009803772
Batch 57/64 loss: 0.2937372922897339
Batch 58/64 loss: 0.30030834674835205
Batch 59/64 loss: 0.29971349239349365
Batch 60/64 loss: 0.2964801788330078
Batch 61/64 loss: 0.2980976104736328
Batch 62/64 loss: 0.2866016626358032
Batch 63/64 loss: 0.30966800451278687
Batch 64/64 loss: 0.3012958765029907
Epoch 371  Train loss: 0.29646293088501574  Val loss: 0.3251685473517454
Epoch 372
-------------------------------
Batch 1/64 loss: 0.29597604274749756
Batch 2/64 loss: 0.2899330258369446
Batch 3/64 loss: 0.2947705388069153
Batch 4/64 loss: 0.29748964309692383
Batch 5/64 loss: 0.29456818103790283
Batch 6/64 loss: 0.2921983003616333
Batch 7/64 loss: 0.2980092763900757
Batch 8/64 loss: 0.3010759949684143
Batch 9/64 loss: 0.2995750904083252
Batch 10/64 loss: 0.2924996614456177
Batch 11/64 loss: 0.303764283657074
Batch 12/64 loss: 0.2958155870437622
Batch 13/64 loss: 0.28841525316238403
Batch 14/64 loss: 0.29418712854385376
Batch 15/64 loss: 0.2997232675552368
Batch 16/64 loss: 0.298811674118042
Batch 17/64 loss: 0.29977238178253174
Batch 18/64 loss: 0.2853207588195801
Batch 19/64 loss: 0.29900282621383667
Batch 20/64 loss: 0.30153918266296387
Batch 21/64 loss: 0.29472482204437256
Batch 22/64 loss: 0.2935025691986084
Batch 23/64 loss: 0.29817861318588257
Batch 24/64 loss: 0.2887645959854126
Batch 25/64 loss: 0.3034973740577698
Batch 26/64 loss: 0.30064284801483154
Batch 27/64 loss: 0.29668182134628296
Batch 28/64 loss: 0.29316723346710205
Batch 29/64 loss: 0.3062596321105957
Batch 30/64 loss: 0.29075032472610474
Batch 31/64 loss: 0.2876892685890198
Batch 32/64 loss: 0.29496002197265625
Batch 33/64 loss: 0.2882354259490967
Batch 34/64 loss: 0.2920132279396057
Batch 35/64 loss: 0.300106406211853
Batch 36/64 loss: 0.29932254552841187
Batch 37/64 loss: 0.2978885769844055
Batch 38/64 loss: 0.30648273229599
Batch 39/64 loss: 0.28613370656967163
Batch 40/64 loss: 0.2862834334373474
Batch 41/64 loss: 0.30000412464141846
Batch 42/64 loss: 0.30596888065338135
Batch 43/64 loss: 0.2918391227722168
Batch 44/64 loss: 0.30006182193756104
Batch 45/64 loss: 0.30090194940567017
Batch 46/64 loss: 0.29417431354522705
Batch 47/64 loss: 0.2930586338043213
Batch 48/64 loss: 0.29639124870300293
Batch 49/64 loss: 0.3053957223892212
Batch 50/64 loss: 0.29110872745513916
Batch 51/64 loss: 0.28836584091186523
Batch 52/64 loss: 0.28685903549194336
Batch 53/64 loss: 0.30121469497680664
Batch 54/64 loss: 0.2922205924987793
Batch 55/64 loss: 0.29485028982162476
Batch 56/64 loss: 0.29638415575027466
Batch 57/64 loss: 0.2903657555580139
Batch 58/64 loss: 0.2908823490142822
Batch 59/64 loss: 0.29251039028167725
Batch 60/64 loss: 0.3016211986541748
Batch 61/64 loss: 0.292995810508728
Batch 62/64 loss: 0.29565656185150146
Batch 63/64 loss: 0.29544901847839355
Batch 64/64 loss: 0.2986934185028076
Epoch 372  Train loss: 0.2956868012746175  Val loss: 0.3245780103395075
Epoch 373
-------------------------------
Batch 1/64 loss: 0.2924429774284363
Batch 2/64 loss: 0.29223883152008057
Batch 3/64 loss: 0.2912256121635437
Batch 4/64 loss: 0.2909047603607178
Batch 5/64 loss: 0.3009566068649292
Batch 6/64 loss: 0.2968325614929199
Batch 7/64 loss: 0.2983516454696655
Batch 8/64 loss: 0.2973368167877197
Batch 9/64 loss: 0.2971259355545044
Batch 10/64 loss: 0.293689489364624
Batch 11/64 loss: 0.29461586475372314
Batch 12/64 loss: 0.2972254753112793
Batch 13/64 loss: 0.2962911128997803
Batch 14/64 loss: 0.2947930097579956
Batch 15/64 loss: 0.29324889183044434
Batch 16/64 loss: 0.2976840138435364
Batch 17/64 loss: 0.30001068115234375
Batch 18/64 loss: 0.29377877712249756
Batch 19/64 loss: 0.2897505760192871
Batch 20/64 loss: 0.2879255414009094
Batch 21/64 loss: 0.29059338569641113
Batch 22/64 loss: 0.29279935359954834
Batch 23/64 loss: 0.29750388860702515
Batch 24/64 loss: 0.29578542709350586
Batch 25/64 loss: 0.304678738117218
Batch 26/64 loss: 0.29062461853027344
Batch 27/64 loss: 0.2941129803657532
Batch 28/64 loss: 0.28850507736206055
Batch 29/64 loss: 0.2895990014076233
Batch 30/64 loss: 0.2925755977630615
Batch 31/64 loss: 0.29431188106536865
Batch 32/64 loss: 0.2920548915863037
Batch 33/64 loss: 0.3069514036178589
Batch 34/64 loss: 0.2960389256477356
Batch 35/64 loss: 0.30449068546295166
Batch 36/64 loss: 0.2976059913635254
Batch 37/64 loss: 0.2920025587081909
Batch 38/64 loss: 0.3081996440887451
Batch 39/64 loss: 0.3059925436973572
Batch 40/64 loss: 0.2996714115142822
Batch 41/64 loss: 0.28780901432037354
Batch 42/64 loss: 0.29849058389663696
Batch 43/64 loss: 0.2938038110733032
Batch 44/64 loss: 0.2995392084121704
Batch 45/64 loss: 0.29646241664886475
Batch 46/64 loss: 0.28874993324279785
Batch 47/64 loss: 0.29636257886886597
Batch 48/64 loss: 0.28916752338409424
Batch 49/64 loss: 0.29794907569885254
Batch 50/64 loss: 0.29289382696151733
Batch 51/64 loss: 0.2953217029571533
Batch 52/64 loss: 0.2986478805541992
Batch 53/64 loss: 0.29032188653945923
Batch 54/64 loss: 0.2953007221221924
Batch 55/64 loss: 0.29822027683258057
Batch 56/64 loss: 0.2960686683654785
Batch 57/64 loss: 0.2997375726699829
Batch 58/64 loss: 0.2833728790283203
Batch 59/64 loss: 0.2960454225540161
Batch 60/64 loss: 0.29920494556427
Batch 61/64 loss: 0.3007538914680481
Batch 62/64 loss: 0.30160677433013916
Batch 63/64 loss: 0.3041645288467407
Batch 64/64 loss: 0.29020142555236816
Epoch 373  Train loss: 0.29565762164545994  Val loss: 0.3257541357446782
Epoch 374
-------------------------------
Batch 1/64 loss: 0.290358304977417
Batch 2/64 loss: 0.3046092987060547
Batch 3/64 loss: 0.3021920323371887
Batch 4/64 loss: 0.2952372431755066
Batch 5/64 loss: 0.29436540603637695
Batch 6/64 loss: 0.2929805517196655
Batch 7/64 loss: 0.3005826473236084
Batch 8/64 loss: 0.299160361289978
Batch 9/64 loss: 0.29435205459594727
Batch 10/64 loss: 0.29682159423828125
Batch 11/64 loss: 0.29742294549942017
Batch 12/64 loss: 0.29950451850891113
Batch 13/64 loss: 0.29461872577667236
Batch 14/64 loss: 0.2942611575126648
Batch 15/64 loss: 0.3000870943069458
Batch 16/64 loss: 0.29238563776016235
Batch 17/64 loss: 0.2847713232040405
Batch 18/64 loss: 0.30001604557037354
Batch 19/64 loss: 0.294894278049469
Batch 20/64 loss: 0.2933995723724365
Batch 21/64 loss: 0.29867637157440186
Batch 22/64 loss: 0.30265629291534424
Batch 23/64 loss: 0.2938627004623413
Batch 24/64 loss: 0.2926272749900818
Batch 25/64 loss: 0.3012257218360901
Batch 26/64 loss: 0.300500750541687
Batch 27/64 loss: 0.2954553961753845
Batch 28/64 loss: 0.2827973961830139
Batch 29/64 loss: 0.2987724542617798
Batch 30/64 loss: 0.2941628098487854
Batch 31/64 loss: 0.2980438470840454
Batch 32/64 loss: 0.2950817346572876
Batch 33/64 loss: 0.30726301670074463
Batch 34/64 loss: 0.293196439743042
Batch 35/64 loss: 0.28849709033966064
Batch 36/64 loss: 0.2888911962509155
Batch 37/64 loss: 0.2902293801307678
Batch 38/64 loss: 0.2982065677642822
Batch 39/64 loss: 0.2900397777557373
Batch 40/64 loss: 0.29843807220458984
Batch 41/64 loss: 0.29810768365859985
Batch 42/64 loss: 0.30067580938339233
Batch 43/64 loss: 0.28773248195648193
Batch 44/64 loss: 0.2886052131652832
Batch 45/64 loss: 0.29089462757110596
Batch 46/64 loss: 0.30041295289993286
Batch 47/64 loss: 0.3015857934951782
Batch 48/64 loss: 0.2892557382583618
Batch 49/64 loss: 0.29199230670928955
Batch 50/64 loss: 0.29689621925354004
Batch 51/64 loss: 0.3027561902999878
Batch 52/64 loss: 0.3026007413864136
Batch 53/64 loss: 0.290116548538208
Batch 54/64 loss: 0.29049116373062134
Batch 55/64 loss: 0.29751360416412354
Batch 56/64 loss: 0.2959938049316406
Batch 57/64 loss: 0.29190850257873535
Batch 58/64 loss: 0.29532188177108765
Batch 59/64 loss: 0.2919130325317383
Batch 60/64 loss: 0.2874911427497864
Batch 61/64 loss: 0.2898396849632263
Batch 62/64 loss: 0.29715144634246826
Batch 63/64 loss: 0.29444438219070435
Batch 64/64 loss: 0.29364585876464844
Epoch 374  Train loss: 0.29528753617230585  Val loss: 0.3243877549761349
Epoch 375
-------------------------------
Batch 1/64 loss: 0.2957243323326111
Batch 2/64 loss: 0.29339075088500977
Batch 3/64 loss: 0.29379546642303467
Batch 4/64 loss: 0.3011205196380615
Batch 5/64 loss: 0.2914503812789917
Batch 6/64 loss: 0.2987273335456848
Batch 7/64 loss: 0.297538161277771
Batch 8/64 loss: 0.2833672761917114
Batch 9/64 loss: 0.2890644073486328
Batch 10/64 loss: 0.29033130407333374
Batch 11/64 loss: 0.2879868745803833
Batch 12/64 loss: 0.29714834690093994
Batch 13/64 loss: 0.2992091178894043
Batch 14/64 loss: 0.29325592517852783
Batch 15/64 loss: 0.3049810528755188
Batch 16/64 loss: 0.29094475507736206
Batch 17/64 loss: 0.29535573720932007
Batch 18/64 loss: 0.2844927906990051
Batch 19/64 loss: 0.30246394872665405
Batch 20/64 loss: 0.3005053997039795
Batch 21/64 loss: 0.29834556579589844
Batch 22/64 loss: 0.29779309034347534
Batch 23/64 loss: 0.29538625478744507
Batch 24/64 loss: 0.2908896803855896
Batch 25/64 loss: 0.30070948600769043
Batch 26/64 loss: 0.29034966230392456
Batch 27/64 loss: 0.2965407371520996
Batch 28/64 loss: 0.30549514293670654
Batch 29/64 loss: 0.28697532415390015
Batch 30/64 loss: 0.28940093517303467
Batch 31/64 loss: 0.3022681474685669
Batch 32/64 loss: 0.2925148010253906
Batch 33/64 loss: 0.30071568489074707
Batch 34/64 loss: 0.29021382331848145
Batch 35/64 loss: 0.2969585657119751
Batch 36/64 loss: 0.3009166717529297
Batch 37/64 loss: 0.2907935380935669
Batch 38/64 loss: 0.2940291166305542
Batch 39/64 loss: 0.30120086669921875
Batch 40/64 loss: 0.2920230031013489
Batch 41/64 loss: 0.2994602918624878
Batch 42/64 loss: 0.30035293102264404
Batch 43/64 loss: 0.29568612575531006
Batch 44/64 loss: 0.2889696955680847
Batch 45/64 loss: 0.2910824418067932
Batch 46/64 loss: 0.2877558469772339
Batch 47/64 loss: 0.2982420325279236
Batch 48/64 loss: 0.2858893871307373
Batch 49/64 loss: 0.2940220832824707
Batch 50/64 loss: 0.3047851324081421
Batch 51/64 loss: 0.287028431892395
Batch 52/64 loss: 0.29742908477783203
Batch 53/64 loss: 0.3008269667625427
Batch 54/64 loss: 0.306286096572876
Batch 55/64 loss: 0.3075413703918457
Batch 56/64 loss: 0.2900356650352478
Batch 57/64 loss: 0.29500532150268555
Batch 58/64 loss: 0.2922884225845337
Batch 59/64 loss: 0.2984210252761841
Batch 60/64 loss: 0.2873290181159973
Batch 61/64 loss: 0.29546570777893066
Batch 62/64 loss: 0.29401350021362305
Batch 63/64 loss: 0.2996078133583069
Batch 64/64 loss: 0.2972186803817749
Epoch 375  Train loss: 0.29529117462681786  Val loss: 0.32418078143162415
Saving best model, epoch: 375
Epoch 376
-------------------------------
Batch 1/64 loss: 0.2902348041534424
Batch 2/64 loss: 0.2884490489959717
Batch 3/64 loss: 0.2848399877548218
Batch 4/64 loss: 0.2923828363418579
Batch 5/64 loss: 0.29138636589050293
Batch 6/64 loss: 0.2887139320373535
Batch 7/64 loss: 0.2955002784729004
Batch 8/64 loss: 0.2967252731323242
Batch 9/64 loss: 0.3170320987701416
Batch 10/64 loss: 0.2845454216003418
Batch 11/64 loss: 0.29487526416778564
Batch 12/64 loss: 0.2884858250617981
Batch 13/64 loss: 0.3034646511077881
Batch 14/64 loss: 0.29933488368988037
Batch 15/64 loss: 0.2997649908065796
Batch 16/64 loss: 0.29989421367645264
Batch 17/64 loss: 0.3008155822753906
Batch 18/64 loss: 0.2948452830314636
Batch 19/64 loss: 0.29424190521240234
Batch 20/64 loss: 0.293257474899292
Batch 21/64 loss: 0.30018651485443115
Batch 22/64 loss: 0.29616081714630127
Batch 23/64 loss: 0.2946357727050781
Batch 24/64 loss: 0.29572904109954834
Batch 25/64 loss: 0.2860475778579712
Batch 26/64 loss: 0.288730263710022
Batch 27/64 loss: 0.29289519786834717
Batch 28/64 loss: 0.29313820600509644
Batch 29/64 loss: 0.28266680240631104
Batch 30/64 loss: 0.2910970449447632
Batch 31/64 loss: 0.301025390625
Batch 32/64 loss: 0.3067219853401184
Batch 33/64 loss: 0.294450044631958
Batch 34/64 loss: 0.28851354122161865
Batch 35/64 loss: 0.29323190450668335
Batch 36/64 loss: 0.29661667346954346
Batch 37/64 loss: 0.2959750294685364
Batch 38/64 loss: 0.2911263704299927
Batch 39/64 loss: 0.3051909804344177
Batch 40/64 loss: 0.2972542643547058
Batch 41/64 loss: 0.3005756139755249
Batch 42/64 loss: 0.2907034158706665
Batch 43/64 loss: 0.2954556941986084
Batch 44/64 loss: 0.2989962697029114
Batch 45/64 loss: 0.2937721014022827
Batch 46/64 loss: 0.29521793127059937
Batch 47/64 loss: 0.2933539152145386
Batch 48/64 loss: 0.2931367754936218
Batch 49/64 loss: 0.2927807569503784
Batch 50/64 loss: 0.2934119701385498
Batch 51/64 loss: 0.3091444969177246
Batch 52/64 loss: 0.2902965545654297
Batch 53/64 loss: 0.29406070709228516
Batch 54/64 loss: 0.29696714878082275
Batch 55/64 loss: 0.29941046237945557
Batch 56/64 loss: 0.2942013740539551
Batch 57/64 loss: 0.2968379259109497
Batch 58/64 loss: 0.2964801788330078
Batch 59/64 loss: 0.30032503604888916
Batch 60/64 loss: 0.2945999503135681
Batch 61/64 loss: 0.2990882992744446
Batch 62/64 loss: 0.2938694953918457
Batch 63/64 loss: 0.30533695220947266
Batch 64/64 loss: 0.29379212856292725
Epoch 376  Train loss: 0.295349814377579  Val loss: 0.3258986962619926
Epoch 377
-------------------------------
Batch 1/64 loss: 0.2932792901992798
Batch 2/64 loss: 0.29492151737213135
Batch 3/64 loss: 0.30079424381256104
Batch 4/64 loss: 0.29376375675201416
Batch 5/64 loss: 0.29403167963027954
Batch 6/64 loss: 0.28808462619781494
Batch 7/64 loss: 0.29515933990478516
Batch 8/64 loss: 0.3003484606742859
Batch 9/64 loss: 0.29705309867858887
Batch 10/64 loss: 0.29748642444610596
Batch 11/64 loss: 0.29289716482162476
Batch 12/64 loss: 0.3022639751434326
Batch 13/64 loss: 0.3083966374397278
Batch 14/64 loss: 0.29821932315826416
Batch 15/64 loss: 0.303195595741272
Batch 16/64 loss: 0.29132574796676636
Batch 17/64 loss: 0.29309260845184326
Batch 18/64 loss: 0.2977510690689087
Batch 19/64 loss: 0.29885149002075195
Batch 20/64 loss: 0.28748393058776855
Batch 21/64 loss: 0.2962927222251892
Batch 22/64 loss: 0.30530524253845215
Batch 23/64 loss: 0.3059399127960205
Batch 24/64 loss: 0.28916555643081665
Batch 25/64 loss: 0.29427778720855713
Batch 26/64 loss: 0.2990896701812744
Batch 27/64 loss: 0.2970684766769409
Batch 28/64 loss: 0.2972472906112671
Batch 29/64 loss: 0.29778456687927246
Batch 30/64 loss: 0.2972300052642822
Batch 31/64 loss: 0.29039692878723145
Batch 32/64 loss: 0.2998239994049072
Batch 33/64 loss: 0.2946324944496155
Batch 34/64 loss: 0.2909504175186157
Batch 35/64 loss: 0.2990533113479614
Batch 36/64 loss: 0.29445838928222656
Batch 37/64 loss: 0.28624916076660156
Batch 38/64 loss: 0.29241347312927246
Batch 39/64 loss: 0.29405874013900757
Batch 40/64 loss: 0.29677456617355347
Batch 41/64 loss: 0.29855597019195557
Batch 42/64 loss: 0.3025319576263428
Batch 43/64 loss: 0.2936323881149292
Batch 44/64 loss: 0.3006622791290283
Batch 45/64 loss: 0.30063390731811523
Batch 46/64 loss: 0.28644800186157227
Batch 47/64 loss: 0.2965831756591797
Batch 48/64 loss: 0.2963970899581909
Batch 49/64 loss: 0.29420483112335205
Batch 50/64 loss: 0.28761494159698486
Batch 51/64 loss: 0.2954363226890564
Batch 52/64 loss: 0.2918081283569336
Batch 53/64 loss: 0.2977398633956909
Batch 54/64 loss: 0.28468775749206543
Batch 55/64 loss: 0.2970294952392578
Batch 56/64 loss: 0.2901849150657654
Batch 57/64 loss: 0.29455631971359253
Batch 58/64 loss: 0.3004714250564575
Batch 59/64 loss: 0.2957296371459961
Batch 60/64 loss: 0.29647135734558105
Batch 61/64 loss: 0.30212920904159546
Batch 62/64 loss: 0.3005768060684204
Batch 63/64 loss: 0.29600608348846436
Batch 64/64 loss: 0.29242247343063354
Epoch 377  Train loss: 0.29593759073930626  Val loss: 0.32720992245624975
Epoch 378
-------------------------------
Batch 1/64 loss: 0.3023186922073364
Batch 2/64 loss: 0.29560112953186035
Batch 3/64 loss: 0.29414498805999756
Batch 4/64 loss: 0.2973219156265259
Batch 5/64 loss: 0.2878760099411011
Batch 6/64 loss: 0.2960439920425415
Batch 7/64 loss: 0.2975229024887085
Batch 8/64 loss: 0.29337310791015625
Batch 9/64 loss: 0.30584073066711426
Batch 10/64 loss: 0.28988420963287354
Batch 11/64 loss: 0.3015490174293518
Batch 12/64 loss: 0.30042409896850586
Batch 13/64 loss: 0.2928999662399292
Batch 14/64 loss: 0.2885928153991699
Batch 15/64 loss: 0.2895033359527588
Batch 16/64 loss: 0.2932945489883423
Batch 17/64 loss: 0.289012610912323
Batch 18/64 loss: 0.30415600538253784
Batch 19/64 loss: 0.29484105110168457
Batch 20/64 loss: 0.302263081073761
Batch 21/64 loss: 0.2937488555908203
Batch 22/64 loss: 0.3013351559638977
Batch 23/64 loss: 0.2917149066925049
Batch 24/64 loss: 0.2950160503387451
Batch 25/64 loss: 0.2977375388145447
Batch 26/64 loss: 0.28986406326293945
Batch 27/64 loss: 0.2953333854675293
Batch 28/64 loss: 0.2915183901786804
Batch 29/64 loss: 0.29879289865493774
Batch 30/64 loss: 0.29460281133651733
Batch 31/64 loss: 0.2901536226272583
Batch 32/64 loss: 0.28766095638275146
Batch 33/64 loss: 0.3150092363357544
Batch 34/64 loss: 0.29538869857788086
Batch 35/64 loss: 0.2928658127784729
Batch 36/64 loss: 0.30270159244537354
Batch 37/64 loss: 0.29720473289489746
Batch 38/64 loss: 0.2964059114456177
Batch 39/64 loss: 0.29087895154953003
Batch 40/64 loss: 0.293215274810791
Batch 41/64 loss: 0.29960060119628906
Batch 42/64 loss: 0.30202651023864746
Batch 43/64 loss: 0.30222344398498535
Batch 44/64 loss: 0.29358726739883423
Batch 45/64 loss: 0.29593193531036377
Batch 46/64 loss: 0.3041924238204956
Batch 47/64 loss: 0.3031027317047119
Batch 48/64 loss: 0.2993870973587036
Batch 49/64 loss: 0.2843426465988159
Batch 50/64 loss: 0.30008161067962646
Batch 51/64 loss: 0.27963948249816895
Batch 52/64 loss: 0.29054558277130127
Batch 53/64 loss: 0.2906090021133423
Batch 54/64 loss: 0.29416942596435547
Batch 55/64 loss: 0.2893573045730591
Batch 56/64 loss: 0.2874438166618347
Batch 57/64 loss: 0.299702525138855
Batch 58/64 loss: 0.2908783555030823
Batch 59/64 loss: 0.29290711879730225
Batch 60/64 loss: 0.2954442501068115
Batch 61/64 loss: 0.29900622367858887
Batch 62/64 loss: 0.3018079996109009
Batch 63/64 loss: 0.2854187488555908
Batch 64/64 loss: 0.2904777526855469
Epoch 378  Train loss: 0.29532356823191924  Val loss: 0.3244181025478848
Epoch 379
-------------------------------
Batch 1/64 loss: 0.2838307023048401
Batch 2/64 loss: 0.29807406663894653
Batch 3/64 loss: 0.28812122344970703
Batch 4/64 loss: 0.2905726432800293
Batch 5/64 loss: 0.28228598833084106
Batch 6/64 loss: 0.29620230197906494
Batch 7/64 loss: 0.2911984920501709
Batch 8/64 loss: 0.298724889755249
Batch 9/64 loss: 0.2908686399459839
Batch 10/64 loss: 0.28975480794906616
Batch 11/64 loss: 0.29474329948425293
Batch 12/64 loss: 0.293231725692749
Batch 13/64 loss: 0.28568190336227417
Batch 14/64 loss: 0.3054647445678711
Batch 15/64 loss: 0.29395854473114014
Batch 16/64 loss: 0.2907137870788574
Batch 17/64 loss: 0.2997702360153198
Batch 18/64 loss: 0.29768532514572144
Batch 19/64 loss: 0.29349321126937866
Batch 20/64 loss: 0.29881131649017334
Batch 21/64 loss: 0.30977606773376465
Batch 22/64 loss: 0.2944558262825012
Batch 23/64 loss: 0.29174113273620605
Batch 24/64 loss: 0.2902524471282959
Batch 25/64 loss: 0.29429471492767334
Batch 26/64 loss: 0.2971789836883545
Batch 27/64 loss: 0.28731024265289307
Batch 28/64 loss: 0.28483128547668457
Batch 29/64 loss: 0.2956312894821167
Batch 30/64 loss: 0.30324602127075195
Batch 31/64 loss: 0.29486632347106934
Batch 32/64 loss: 0.300986647605896
Batch 33/64 loss: 0.2883598208427429
Batch 34/64 loss: 0.2905309200286865
Batch 35/64 loss: 0.2951728105545044
Batch 36/64 loss: 0.3003484606742859
Batch 37/64 loss: 0.2901802062988281
Batch 38/64 loss: 0.3017459511756897
Batch 39/64 loss: 0.30073267221450806
Batch 40/64 loss: 0.284168004989624
Batch 41/64 loss: 0.2943142056465149
Batch 42/64 loss: 0.29924607276916504
Batch 43/64 loss: 0.30123841762542725
Batch 44/64 loss: 0.3021831512451172
Batch 45/64 loss: 0.3069448471069336
Batch 46/64 loss: 0.3024357557296753
Batch 47/64 loss: 0.29534703493118286
Batch 48/64 loss: 0.28326189517974854
Batch 49/64 loss: 0.293196439743042
Batch 50/64 loss: 0.2909584641456604
Batch 51/64 loss: 0.29116290807724
Batch 52/64 loss: 0.30446314811706543
Batch 53/64 loss: 0.2878232002258301
Batch 54/64 loss: 0.3030369281768799
Batch 55/64 loss: 0.2964063882827759
Batch 56/64 loss: 0.28733086585998535
Batch 57/64 loss: 0.28668153285980225
Batch 58/64 loss: 0.3013755679130554
Batch 59/64 loss: 0.29635292291641235
Batch 60/64 loss: 0.2933419346809387
Batch 61/64 loss: 0.2939791679382324
Batch 62/64 loss: 0.28972017765045166
Batch 63/64 loss: 0.30827295780181885
Batch 64/64 loss: 0.2921414375305176
Epoch 379  Train loss: 0.29470082731807934  Val loss: 0.32497996706323523
Epoch 380
-------------------------------
Batch 1/64 loss: 0.2893468141555786
Batch 2/64 loss: 0.29907286167144775
Batch 3/64 loss: 0.29741865396499634
Batch 4/64 loss: 0.2930085062980652
Batch 5/64 loss: 0.28104329109191895
Batch 6/64 loss: 0.29224514961242676
Batch 7/64 loss: 0.2963489890098572
Batch 8/64 loss: 0.28464633226394653
Batch 9/64 loss: 0.29516565799713135
Batch 10/64 loss: 0.28336238861083984
Batch 11/64 loss: 0.3043431043624878
Batch 12/64 loss: 0.2884153127670288
Batch 13/64 loss: 0.28791940212249756
Batch 14/64 loss: 0.2970035672187805
Batch 15/64 loss: 0.3026859760284424
Batch 16/64 loss: 0.29304665327072144
Batch 17/64 loss: 0.28919923305511475
Batch 18/64 loss: 0.30057215690612793
Batch 19/64 loss: 0.29047948122024536
Batch 20/64 loss: 0.29827892780303955
Batch 21/64 loss: 0.29066914319992065
Batch 22/64 loss: 0.29482102394104004
Batch 23/64 loss: 0.2938384413719177
Batch 24/64 loss: 0.3049166798591614
Batch 25/64 loss: 0.3000802993774414
Batch 26/64 loss: 0.3046303987503052
Batch 27/64 loss: 0.28712785243988037
Batch 28/64 loss: 0.3004930019378662
Batch 29/64 loss: 0.29588091373443604
Batch 30/64 loss: 0.3083972930908203
Batch 31/64 loss: 0.29609036445617676
Batch 32/64 loss: 0.2953125834465027
Batch 33/64 loss: 0.2944806218147278
Batch 34/64 loss: 0.2903798222541809
Batch 35/64 loss: 0.2881593704223633
Batch 36/64 loss: 0.3118988871574402
Batch 37/64 loss: 0.28979432582855225
Batch 38/64 loss: 0.2943536043167114
Batch 39/64 loss: 0.2972950339317322
Batch 40/64 loss: 0.29277539253234863
Batch 41/64 loss: 0.29205477237701416
Batch 42/64 loss: 0.3099591135978699
Batch 43/64 loss: 0.2939082384109497
Batch 44/64 loss: 0.30462175607681274
Batch 45/64 loss: 0.2926619052886963
Batch 46/64 loss: 0.2923027276992798
Batch 47/64 loss: 0.2979389429092407
Batch 48/64 loss: 0.30316483974456787
Batch 49/64 loss: 0.2913529872894287
Batch 50/64 loss: 0.29366958141326904
Batch 51/64 loss: 0.28622138500213623
Batch 52/64 loss: 0.2951831817626953
Batch 53/64 loss: 0.29594242572784424
Batch 54/64 loss: 0.29649996757507324
Batch 55/64 loss: 0.298262357711792
Batch 56/64 loss: 0.29200124740600586
Batch 57/64 loss: 0.29446667432785034
Batch 58/64 loss: 0.29140031337738037
Batch 59/64 loss: 0.2890995740890503
Batch 60/64 loss: 0.30309057235717773
Batch 61/64 loss: 0.28955984115600586
Batch 62/64 loss: 0.2900427579879761
Batch 63/64 loss: 0.2893327474594116
Batch 64/64 loss: 0.300656795501709
Epoch 380  Train loss: 0.29495259640263577  Val loss: 0.3244361119581662
Epoch 381
-------------------------------
Batch 1/64 loss: 0.2971845865249634
Batch 2/64 loss: 0.29640305042266846
Batch 3/64 loss: 0.30673450231552124
Batch 4/64 loss: 0.2960197925567627
Batch 5/64 loss: 0.28093522787094116
Batch 6/64 loss: 0.29626691341400146
Batch 7/64 loss: 0.293940007686615
Batch 8/64 loss: 0.2968730926513672
Batch 9/64 loss: 0.29537975788116455
Batch 10/64 loss: 0.2952829599380493
Batch 11/64 loss: 0.3028227686882019
Batch 12/64 loss: 0.2912386655807495
Batch 13/64 loss: 0.29106688499450684
Batch 14/64 loss: 0.29949283599853516
Batch 15/64 loss: 0.2920101284980774
Batch 16/64 loss: 0.2952408790588379
Batch 17/64 loss: 0.2971581220626831
Batch 18/64 loss: 0.2972368597984314
Batch 19/64 loss: 0.2842932939529419
Batch 20/64 loss: 0.2849501371383667
Batch 21/64 loss: 0.28913789987564087
Batch 22/64 loss: 0.29513174295425415
Batch 23/64 loss: 0.2983067035675049
Batch 24/64 loss: 0.29135024547576904
Batch 25/64 loss: 0.29661834239959717
Batch 26/64 loss: 0.2932398319244385
Batch 27/64 loss: 0.2951045036315918
Batch 28/64 loss: 0.2970775365829468
Batch 29/64 loss: 0.2854478359222412
Batch 30/64 loss: 0.2951016426086426
Batch 31/64 loss: 0.2945067882537842
Batch 32/64 loss: 0.2891794443130493
Batch 33/64 loss: 0.2907686233520508
Batch 34/64 loss: 0.2913389205932617
Batch 35/64 loss: 0.28785234689712524
Batch 36/64 loss: 0.2893984317779541
Batch 37/64 loss: 0.2979809641838074
Batch 38/64 loss: 0.30396032333374023
Batch 39/64 loss: 0.28874123096466064
Batch 40/64 loss: 0.28548723459243774
Batch 41/64 loss: 0.2998828887939453
Batch 42/64 loss: 0.2919244170188904
Batch 43/64 loss: 0.3008636236190796
Batch 44/64 loss: 0.30184656381607056
Batch 45/64 loss: 0.3013157248497009
Batch 46/64 loss: 0.30069661140441895
Batch 47/64 loss: 0.29022109508514404
Batch 48/64 loss: 0.2941211462020874
Batch 49/64 loss: 0.288688063621521
Batch 50/64 loss: 0.304176926612854
Batch 51/64 loss: 0.2908874750137329
Batch 52/64 loss: 0.2904956340789795
Batch 53/64 loss: 0.299077570438385
Batch 54/64 loss: 0.29271042346954346
Batch 55/64 loss: 0.30237793922424316
Batch 56/64 loss: 0.29775118827819824
Batch 57/64 loss: 0.29910552501678467
Batch 58/64 loss: 0.2975383996963501
Batch 59/64 loss: 0.2887859344482422
Batch 60/64 loss: 0.2868667244911194
Batch 61/64 loss: 0.29936325550079346
Batch 62/64 loss: 0.31101953983306885
Batch 63/64 loss: 0.2922319173812866
Batch 64/64 loss: 0.28532862663269043
Epoch 381  Train loss: 0.29462284106834263  Val loss: 0.32430910367736293
Epoch 382
-------------------------------
Batch 1/64 loss: 0.29833173751831055
Batch 2/64 loss: 0.2882115840911865
Batch 3/64 loss: 0.28368330001831055
Batch 4/64 loss: 0.30168652534484863
Batch 5/64 loss: 0.3065672516822815
Batch 6/64 loss: 0.3003532886505127
Batch 7/64 loss: 0.29447877407073975
Batch 8/64 loss: 0.290271520614624
Batch 9/64 loss: 0.2917884588241577
Batch 10/64 loss: 0.2873893976211548
Batch 11/64 loss: 0.2977585792541504
Batch 12/64 loss: 0.2998073101043701
Batch 13/64 loss: 0.2868090867996216
Batch 14/64 loss: 0.28732526302337646
Batch 15/64 loss: 0.2997859716415405
Batch 16/64 loss: 0.29486602544784546
Batch 17/64 loss: 0.29505711793899536
Batch 18/64 loss: 0.29213178157806396
Batch 19/64 loss: 0.2978314161300659
Batch 20/64 loss: 0.29487156867980957
Batch 21/64 loss: 0.2960023880004883
Batch 22/64 loss: 0.2970716953277588
Batch 23/64 loss: 0.2940536141395569
Batch 24/64 loss: 0.3019418716430664
Batch 25/64 loss: 0.2931203842163086
Batch 26/64 loss: 0.29402971267700195
Batch 27/64 loss: 0.3044440746307373
Batch 28/64 loss: 0.2942359447479248
Batch 29/64 loss: 0.29745471477508545
Batch 30/64 loss: 0.29753148555755615
Batch 31/64 loss: 0.2894296646118164
Batch 32/64 loss: 0.30465734004974365
Batch 33/64 loss: 0.2861141562461853
Batch 34/64 loss: 0.29523682594299316
Batch 35/64 loss: 0.3142392635345459
Batch 36/64 loss: 0.29264724254608154
Batch 37/64 loss: 0.29628533124923706
Batch 38/64 loss: 0.3014698028564453
Batch 39/64 loss: 0.29164189100265503
Batch 40/64 loss: 0.2939766049385071
Batch 41/64 loss: 0.285402774810791
Batch 42/64 loss: 0.2965550422668457
Batch 43/64 loss: 0.2985870838165283
Batch 44/64 loss: 0.296195387840271
Batch 45/64 loss: 0.2982308864593506
Batch 46/64 loss: 0.2929159998893738
Batch 47/64 loss: 0.28456467390060425
Batch 48/64 loss: 0.29816025495529175
Batch 49/64 loss: 0.2943474054336548
Batch 50/64 loss: 0.29830998182296753
Batch 51/64 loss: 0.2980377674102783
Batch 52/64 loss: 0.2971165180206299
Batch 53/64 loss: 0.2876521348953247
Batch 54/64 loss: 0.29320240020751953
Batch 55/64 loss: 0.2907096743583679
Batch 56/64 loss: 0.2877535820007324
Batch 57/64 loss: 0.292203426361084
Batch 58/64 loss: 0.297268807888031
Batch 59/64 loss: 0.29059767723083496
Batch 60/64 loss: 0.293523371219635
Batch 61/64 loss: 0.2921558618545532
Batch 62/64 loss: 0.3012538552284241
Batch 63/64 loss: 0.292435884475708
Batch 64/64 loss: 0.29827988147735596
Epoch 382  Train loss: 0.29498792676364677  Val loss: 0.3254993809867151
Epoch 383
-------------------------------
Batch 1/64 loss: 0.28907912969589233
Batch 2/64 loss: 0.304301381111145
Batch 3/64 loss: 0.29848408699035645
Batch 4/64 loss: 0.29561907052993774
Batch 5/64 loss: 0.2877929210662842
Batch 6/64 loss: 0.30476850271224976
Batch 7/64 loss: 0.2917490005493164
Batch 8/64 loss: 0.30833321809768677
Batch 9/64 loss: 0.29775869846343994
Batch 10/64 loss: 0.28612470626831055
Batch 11/64 loss: 0.28714412450790405
Batch 12/64 loss: 0.2946101427078247
Batch 13/64 loss: 0.295914888381958
Batch 14/64 loss: 0.2871484160423279
Batch 15/64 loss: 0.29499346017837524
Batch 16/64 loss: 0.30158817768096924
Batch 17/64 loss: 0.2993912696838379
Batch 18/64 loss: 0.29422104358673096
Batch 19/64 loss: 0.2938121557235718
Batch 20/64 loss: 0.2978020906448364
Batch 21/64 loss: 0.2976384162902832
Batch 22/64 loss: 0.29395389556884766
Batch 23/64 loss: 0.3000379800796509
Batch 24/64 loss: 0.29263246059417725
Batch 25/64 loss: 0.2968815565109253
Batch 26/64 loss: 0.30177807807922363
Batch 27/64 loss: 0.296722412109375
Batch 28/64 loss: 0.2917340397834778
Batch 29/64 loss: 0.29248279333114624
Batch 30/64 loss: 0.2935701608657837
Batch 31/64 loss: 0.2889662981033325
Batch 32/64 loss: 0.28734588623046875
Batch 33/64 loss: 0.2913968563079834
Batch 34/64 loss: 0.2951812148094177
Batch 35/64 loss: 0.295462965965271
Batch 36/64 loss: 0.2888461947441101
Batch 37/64 loss: 0.29698067903518677
Batch 38/64 loss: 0.2844266891479492
Batch 39/64 loss: 0.29748284816741943
Batch 40/64 loss: 0.2933311462402344
Batch 41/64 loss: 0.29131948947906494
Batch 42/64 loss: 0.3000833988189697
Batch 43/64 loss: 0.3018617630004883
Batch 44/64 loss: 0.289928138256073
Batch 45/64 loss: 0.30743491649627686
Batch 46/64 loss: 0.2820603847503662
Batch 47/64 loss: 0.30396926403045654
Batch 48/64 loss: 0.29790496826171875
Batch 49/64 loss: 0.29538577795028687
Batch 50/64 loss: 0.29106783866882324
Batch 51/64 loss: 0.29697465896606445
Batch 52/64 loss: 0.29851746559143066
Batch 53/64 loss: 0.291654109954834
Batch 54/64 loss: 0.2836967706680298
Batch 55/64 loss: 0.28909480571746826
Batch 56/64 loss: 0.2907140254974365
Batch 57/64 loss: 0.288910448551178
Batch 58/64 loss: 0.2966458201408386
Batch 59/64 loss: 0.2973952293395996
Batch 60/64 loss: 0.2886818051338196
Batch 61/64 loss: 0.29659295082092285
Batch 62/64 loss: 0.29633641242980957
Batch 63/64 loss: 0.3008972406387329
Batch 64/64 loss: 0.2872844338417053
Epoch 383  Train loss: 0.29458949121774414  Val loss: 0.32360898506190766
Saving best model, epoch: 383
Epoch 384
-------------------------------
Batch 1/64 loss: 0.3028082251548767
Batch 2/64 loss: 0.29606109857559204
Batch 3/64 loss: 0.2900592088699341
Batch 4/64 loss: 0.29000234603881836
Batch 5/64 loss: 0.28765273094177246
Batch 6/64 loss: 0.2991366386413574
Batch 7/64 loss: 0.28296953439712524
Batch 8/64 loss: 0.289096474647522
Batch 9/64 loss: 0.30331915616989136
Batch 10/64 loss: 0.30282533168792725
Batch 11/64 loss: 0.29769498109817505
Batch 12/64 loss: 0.2923860549926758
Batch 13/64 loss: 0.2953455448150635
Batch 14/64 loss: 0.304601788520813
Batch 15/64 loss: 0.29205650091171265
Batch 16/64 loss: 0.2859954237937927
Batch 17/64 loss: 0.28832828998565674
Batch 18/64 loss: 0.28277766704559326
Batch 19/64 loss: 0.2878565192222595
Batch 20/64 loss: 0.2961416244506836
Batch 21/64 loss: 0.2910650968551636
Batch 22/64 loss: 0.29681944847106934
Batch 23/64 loss: 0.2922542095184326
Batch 24/64 loss: 0.29690754413604736
Batch 25/64 loss: 0.29617834091186523
Batch 26/64 loss: 0.3046044111251831
Batch 27/64 loss: 0.28750699758529663
Batch 28/64 loss: 0.3048839569091797
Batch 29/64 loss: 0.3012823462486267
Batch 30/64 loss: 0.3009403347969055
Batch 31/64 loss: 0.29010796546936035
Batch 32/64 loss: 0.3066409230232239
Batch 33/64 loss: 0.2934773564338684
Batch 34/64 loss: 0.29593443870544434
Batch 35/64 loss: 0.291998028755188
Batch 36/64 loss: 0.29640787839889526
Batch 37/64 loss: 0.28817087411880493
Batch 38/64 loss: 0.3018524646759033
Batch 39/64 loss: 0.28693240880966187
Batch 40/64 loss: 0.29968202114105225
Batch 41/64 loss: 0.3002464175224304
Batch 42/64 loss: 0.2949477434158325
Batch 43/64 loss: 0.2926555871963501
Batch 44/64 loss: 0.29331469535827637
Batch 45/64 loss: 0.2959531545639038
Batch 46/64 loss: 0.2834482192993164
Batch 47/64 loss: 0.2942623496055603
Batch 48/64 loss: 0.2866581678390503
Batch 49/64 loss: 0.2872830629348755
Batch 50/64 loss: 0.2949177026748657
Batch 51/64 loss: 0.2928783893585205
Batch 52/64 loss: 0.29311317205429077
Batch 53/64 loss: 0.2918386459350586
Batch 54/64 loss: 0.29016804695129395
Batch 55/64 loss: 0.2889288067817688
Batch 56/64 loss: 0.2941882610321045
Batch 57/64 loss: 0.29757964611053467
Batch 58/64 loss: 0.29700028896331787
Batch 59/64 loss: 0.29589176177978516
Batch 60/64 loss: 0.29616934061050415
Batch 61/64 loss: 0.30286574363708496
Batch 62/64 loss: 0.300952672958374
Batch 63/64 loss: 0.30275487899780273
Batch 64/64 loss: 0.2888065576553345
Epoch 384  Train loss: 0.2945158252529069  Val loss: 0.32693562310995516
Epoch 385
-------------------------------
Batch 1/64 loss: 0.2947167754173279
Batch 2/64 loss: 0.27608340978622437
Batch 3/64 loss: 0.28562867641448975
Batch 4/64 loss: 0.29350340366363525
Batch 5/64 loss: 0.29628151655197144
Batch 6/64 loss: 0.2926618456840515
Batch 7/64 loss: 0.29101377725601196
Batch 8/64 loss: 0.29175031185150146
Batch 9/64 loss: 0.29553425312042236
Batch 10/64 loss: 0.287045419216156
Batch 11/64 loss: 0.28837525844573975
Batch 12/64 loss: 0.29603302478790283
Batch 13/64 loss: 0.2991883158683777
Batch 14/64 loss: 0.29847264289855957
Batch 15/64 loss: 0.3027995824813843
Batch 16/64 loss: 0.291637659072876
Batch 17/64 loss: 0.30017566680908203
Batch 18/64 loss: 0.28966307640075684
Batch 19/64 loss: 0.3022388219833374
Batch 20/64 loss: 0.29742515087127686
Batch 21/64 loss: 0.3091459274291992
Batch 22/64 loss: 0.293571412563324
Batch 23/64 loss: 0.3017193675041199
Batch 24/64 loss: 0.30024170875549316
Batch 25/64 loss: 0.3064884543418884
Batch 26/64 loss: 0.2975461483001709
Batch 27/64 loss: 0.2961314916610718
Batch 28/64 loss: 0.2885690927505493
Batch 29/64 loss: 0.29312044382095337
Batch 30/64 loss: 0.2949882745742798
Batch 31/64 loss: 0.29450881481170654
Batch 32/64 loss: 0.2834552526473999
Batch 33/64 loss: 0.3021966814994812
Batch 34/64 loss: 0.28724390268325806
Batch 35/64 loss: 0.29022467136383057
Batch 36/64 loss: 0.3010510206222534
Batch 37/64 loss: 0.2961358428001404
Batch 38/64 loss: 0.2957909107208252
Batch 39/64 loss: 0.2978585362434387
Batch 40/64 loss: 0.28551244735717773
Batch 41/64 loss: 0.28326666355133057
Batch 42/64 loss: 0.2940850257873535
Batch 43/64 loss: 0.2951458692550659
Batch 44/64 loss: 0.30850374698638916
Batch 45/64 loss: 0.30104994773864746
Batch 46/64 loss: 0.29134076833724976
Batch 47/64 loss: 0.28802669048309326
Batch 48/64 loss: 0.3011396527290344
Batch 49/64 loss: 0.29751455783843994
Batch 50/64 loss: 0.2918608784675598
Batch 51/64 loss: 0.29971277713775635
Batch 52/64 loss: 0.2937757968902588
Batch 53/64 loss: 0.29420554637908936
Batch 54/64 loss: 0.30001235008239746
Batch 55/64 loss: 0.29328644275665283
Batch 56/64 loss: 0.29786980152130127
Batch 57/64 loss: 0.29611384868621826
Batch 58/64 loss: 0.2934250831604004
Batch 59/64 loss: 0.29031383991241455
Batch 60/64 loss: 0.29424095153808594
Batch 61/64 loss: 0.2947630286216736
Batch 62/64 loss: 0.2926104664802551
Batch 63/64 loss: 0.3007535934448242
Batch 64/64 loss: 0.29639267921447754
Epoch 385  Train loss: 0.29491828750161564  Val loss: 0.32433900923253745
Epoch 386
-------------------------------
Batch 1/64 loss: 0.30090630054473877
Batch 2/64 loss: 0.2840408682823181
Batch 3/64 loss: 0.2998250126838684
Batch 4/64 loss: 0.29629814624786377
Batch 5/64 loss: 0.286612868309021
Batch 6/64 loss: 0.30099159479141235
Batch 7/64 loss: 0.29141902923583984
Batch 8/64 loss: 0.288385272026062
Batch 9/64 loss: 0.29349201917648315
Batch 10/64 loss: 0.2901344299316406
Batch 11/64 loss: 0.2956807017326355
Batch 12/64 loss: 0.29315656423568726
Batch 13/64 loss: 0.29017066955566406
Batch 14/64 loss: 0.29168039560317993
Batch 15/64 loss: 0.3019537925720215
Batch 16/64 loss: 0.29618436098098755
Batch 17/64 loss: 0.30161696672439575
Batch 18/64 loss: 0.2951709032058716
Batch 19/64 loss: 0.30229437351226807
Batch 20/64 loss: 0.29284417629241943
Batch 21/64 loss: 0.2888663411140442
Batch 22/64 loss: 0.3021519184112549
Batch 23/64 loss: 0.300439715385437
Batch 24/64 loss: 0.28434860706329346
Batch 25/64 loss: 0.28583598136901855
Batch 26/64 loss: 0.2947859764099121
Batch 27/64 loss: 0.2910463213920593
Batch 28/64 loss: 0.3034862279891968
Batch 29/64 loss: 0.2927113175392151
Batch 30/64 loss: 0.300301194190979
Batch 31/64 loss: 0.29163676500320435
Batch 32/64 loss: 0.29707998037338257
Batch 33/64 loss: 0.2897530794143677
Batch 34/64 loss: 0.2915843725204468
Batch 35/64 loss: 0.29971587657928467
Batch 36/64 loss: 0.2946537137031555
Batch 37/64 loss: 0.2948794364929199
Batch 38/64 loss: 0.2928658723831177
Batch 39/64 loss: 0.2985817790031433
Batch 40/64 loss: 0.288513720035553
Batch 41/64 loss: 0.27901196479797363
Batch 42/64 loss: 0.29668086767196655
Batch 43/64 loss: 0.3020896911621094
Batch 44/64 loss: 0.297454833984375
Batch 45/64 loss: 0.29718267917633057
Batch 46/64 loss: 0.2941642999649048
Batch 47/64 loss: 0.29343652725219727
Batch 48/64 loss: 0.2885579466819763
Batch 49/64 loss: 0.29333996772766113
Batch 50/64 loss: 0.2942636013031006
Batch 51/64 loss: 0.2977476119995117
Batch 52/64 loss: 0.30125224590301514
Batch 53/64 loss: 0.2859278917312622
Batch 54/64 loss: 0.2997811436653137
Batch 55/64 loss: 0.29054689407348633
Batch 56/64 loss: 0.28667598962783813
Batch 57/64 loss: 0.3029216527938843
Batch 58/64 loss: 0.29293692111968994
Batch 59/64 loss: 0.2956833839416504
Batch 60/64 loss: 0.29628026485443115
Batch 61/64 loss: 0.2896021604537964
Batch 62/64 loss: 0.29714447259902954
Batch 63/64 loss: 0.30032068490982056
Batch 64/64 loss: 0.30149179697036743
Epoch 386  Train loss: 0.294513242151223  Val loss: 0.32489517279916613
Epoch 387
-------------------------------
Batch 1/64 loss: 0.29282552003860474
Batch 2/64 loss: 0.29691600799560547
Batch 3/64 loss: 0.29962611198425293
Batch 4/64 loss: 0.2866607904434204
Batch 5/64 loss: 0.29698580503463745
Batch 6/64 loss: 0.2892652750015259
Batch 7/64 loss: 0.2986142039299011
Batch 8/64 loss: 0.28763389587402344
Batch 9/64 loss: 0.29336005449295044
Batch 10/64 loss: 0.3049149513244629
Batch 11/64 loss: 0.2901911735534668
Batch 12/64 loss: 0.3007884621620178
Batch 13/64 loss: 0.2915940284729004
Batch 14/64 loss: 0.28949105739593506
Batch 15/64 loss: 0.28536999225616455
Batch 16/64 loss: 0.28768885135650635
Batch 17/64 loss: 0.2934737205505371
Batch 18/64 loss: 0.28499770164489746
Batch 19/64 loss: 0.29837656021118164
Batch 20/64 loss: 0.2901279926300049
Batch 21/64 loss: 0.29154378175735474
Batch 22/64 loss: 0.2871132493019104
Batch 23/64 loss: 0.27896130084991455
Batch 24/64 loss: 0.30053794384002686
Batch 25/64 loss: 0.29570966958999634
Batch 26/64 loss: 0.2967822551727295
Batch 27/64 loss: 0.2909473180770874
Batch 28/64 loss: 0.2985769510269165
Batch 29/64 loss: 0.29028499126434326
Batch 30/64 loss: 0.29530662298202515
Batch 31/64 loss: 0.3073464035987854
Batch 32/64 loss: 0.2962312698364258
Batch 33/64 loss: 0.2991238236427307
Batch 34/64 loss: 0.3031159043312073
Batch 35/64 loss: 0.29294514656066895
Batch 36/64 loss: 0.3022193908691406
Batch 37/64 loss: 0.2916616201400757
Batch 38/64 loss: 0.287716269493103
Batch 39/64 loss: 0.2974238395690918
Batch 40/64 loss: 0.29437941312789917
Batch 41/64 loss: 0.294802188873291
Batch 42/64 loss: 0.29953932762145996
Batch 43/64 loss: 0.29605233669281006
Batch 44/64 loss: 0.2925267219543457
Batch 45/64 loss: 0.2880009412765503
Batch 46/64 loss: 0.3036922216415405
Batch 47/64 loss: 0.30046892166137695
Batch 48/64 loss: 0.29769212007522583
Batch 49/64 loss: 0.28956615924835205
Batch 50/64 loss: 0.293570339679718
Batch 51/64 loss: 0.29899197816848755
Batch 52/64 loss: 0.293989896774292
Batch 53/64 loss: 0.30045396089553833
Batch 54/64 loss: 0.29538780450820923
Batch 55/64 loss: 0.28946709632873535
Batch 56/64 loss: 0.2868141531944275
Batch 57/64 loss: 0.28733253479003906
Batch 58/64 loss: 0.2957632541656494
Batch 59/64 loss: 0.29226386547088623
Batch 60/64 loss: 0.2943335771560669
Batch 61/64 loss: 0.29473167657852173
Batch 62/64 loss: 0.30367112159729004
Batch 63/64 loss: 0.28592193126678467
Batch 64/64 loss: 0.2942817807197571
Epoch 387  Train loss: 0.29415803586735445  Val loss: 0.32417220491723914
Epoch 388
-------------------------------
Batch 1/64 loss: 0.29692959785461426
Batch 2/64 loss: 0.29941117763519287
Batch 3/64 loss: 0.2887144684791565
Batch 4/64 loss: 0.2971961498260498
Batch 5/64 loss: 0.28894948959350586
Batch 6/64 loss: 0.29001766443252563
Batch 7/64 loss: 0.2901381254196167
Batch 8/64 loss: 0.2869913578033447
Batch 9/64 loss: 0.28866690397262573
Batch 10/64 loss: 0.29019248485565186
Batch 11/64 loss: 0.2964516878128052
Batch 12/64 loss: 0.2972484827041626
Batch 13/64 loss: 0.28769683837890625
Batch 14/64 loss: 0.29470503330230713
Batch 15/64 loss: 0.2901245355606079
Batch 16/64 loss: 0.29985344409942627
Batch 17/64 loss: 0.28974318504333496
Batch 18/64 loss: 0.29488909244537354
Batch 19/64 loss: 0.29687923192977905
Batch 20/64 loss: 0.2983102798461914
Batch 21/64 loss: 0.2981565594673157
Batch 22/64 loss: 0.29621434211730957
Batch 23/64 loss: 0.29170793294906616
Batch 24/64 loss: 0.28913313150405884
Batch 25/64 loss: 0.2834552526473999
Batch 26/64 loss: 0.2966175079345703
Batch 27/64 loss: 0.28895485401153564
Batch 28/64 loss: 0.29317522048950195
Batch 29/64 loss: 0.28955042362213135
Batch 30/64 loss: 0.2951756715774536
Batch 31/64 loss: 0.29624903202056885
Batch 32/64 loss: 0.2913576364517212
Batch 33/64 loss: 0.2895026206970215
Batch 34/64 loss: 0.30084335803985596
Batch 35/64 loss: 0.2947691082954407
Batch 36/64 loss: 0.3063690662384033
Batch 37/64 loss: 0.29437458515167236
Batch 38/64 loss: 0.2952800989151001
Batch 39/64 loss: 0.29327893257141113
Batch 40/64 loss: 0.3011908531188965
Batch 41/64 loss: 0.28899163007736206
Batch 42/64 loss: 0.3027157783508301
Batch 43/64 loss: 0.29500192403793335
Batch 44/64 loss: 0.3150871992111206
Batch 45/64 loss: 0.2916545867919922
Batch 46/64 loss: 0.2929961681365967
Batch 47/64 loss: 0.2914506793022156
Batch 48/64 loss: 0.3075374960899353
Batch 49/64 loss: 0.29450154304504395
Batch 50/64 loss: 0.29037606716156006
Batch 51/64 loss: 0.2934929132461548
Batch 52/64 loss: 0.2879793643951416
Batch 53/64 loss: 0.2877865433692932
Batch 54/64 loss: 0.2913174629211426
Batch 55/64 loss: 0.3014439344406128
Batch 56/64 loss: 0.2918446660041809
Batch 57/64 loss: 0.2832987308502197
Batch 58/64 loss: 0.2980055809020996
Batch 59/64 loss: 0.2966651916503906
Batch 60/64 loss: 0.28571420907974243
Batch 61/64 loss: 0.2885693311691284
Batch 62/64 loss: 0.2986421585083008
Batch 63/64 loss: 0.2940187454223633
Batch 64/64 loss: 0.29767197370529175
Epoch 388  Train loss: 0.2939735106393403  Val loss: 0.325957623134364
Epoch 389
-------------------------------
Batch 1/64 loss: 0.3014014959335327
Batch 2/64 loss: 0.29030853509902954
Batch 3/64 loss: 0.2889810800552368
Batch 4/64 loss: 0.28352850675582886
Batch 5/64 loss: 0.28768599033355713
Batch 6/64 loss: 0.2867845296859741
Batch 7/64 loss: 0.2912507653236389
Batch 8/64 loss: 0.28911054134368896
Batch 9/64 loss: 0.2925097346305847
Batch 10/64 loss: 0.29127466678619385
Batch 11/64 loss: 0.2987927198410034
Batch 12/64 loss: 0.2903982996940613
Batch 13/64 loss: 0.2935903072357178
Batch 14/64 loss: 0.2902885675430298
Batch 15/64 loss: 0.2896498441696167
Batch 16/64 loss: 0.2928406000137329
Batch 17/64 loss: 0.2966259717941284
Batch 18/64 loss: 0.29338133335113525
Batch 19/64 loss: 0.28671932220458984
Batch 20/64 loss: 0.29673320055007935
Batch 21/64 loss: 0.2922985553741455
Batch 22/64 loss: 0.28986304998397827
Batch 23/64 loss: 0.29681313037872314
Batch 24/64 loss: 0.29405033588409424
Batch 25/64 loss: 0.30491507053375244
Batch 26/64 loss: 0.28858447074890137
Batch 27/64 loss: 0.29643940925598145
Batch 28/64 loss: 0.2968655824661255
Batch 29/64 loss: 0.2928217649459839
Batch 30/64 loss: 0.29764556884765625
Batch 31/64 loss: 0.28796470165252686
Batch 32/64 loss: 0.28874439001083374
Batch 33/64 loss: 0.2844369411468506
Batch 34/64 loss: 0.29423987865448
Batch 35/64 loss: 0.2935032248497009
Batch 36/64 loss: 0.29119986295700073
Batch 37/64 loss: 0.28741466999053955
Batch 38/64 loss: 0.295940637588501
Batch 39/64 loss: 0.2932252883911133
Batch 40/64 loss: 0.2967982292175293
Batch 41/64 loss: 0.2986028790473938
Batch 42/64 loss: 0.2958530783653259
Batch 43/64 loss: 0.2960518002510071
Batch 44/64 loss: 0.2896294593811035
Batch 45/64 loss: 0.2989058494567871
Batch 46/64 loss: 0.2932787537574768
Batch 47/64 loss: 0.29797816276550293
Batch 48/64 loss: 0.2947821021080017
Batch 49/64 loss: 0.29614126682281494
Batch 50/64 loss: 0.2920958995819092
Batch 51/64 loss: 0.2966904640197754
Batch 52/64 loss: 0.28762370347976685
Batch 53/64 loss: 0.29139411449432373
Batch 54/64 loss: 0.2809208631515503
Batch 55/64 loss: 0.30404937267303467
Batch 56/64 loss: 0.30363738536834717
Batch 57/64 loss: 0.2873266935348511
Batch 58/64 loss: 0.29038119316101074
Batch 59/64 loss: 0.2985733151435852
Batch 60/64 loss: 0.28630542755126953
Batch 61/64 loss: 0.30600470304489136
Batch 62/64 loss: 0.3015505075454712
Batch 63/64 loss: 0.29788529872894287
Batch 64/64 loss: 0.30462151765823364
Epoch 389  Train loss: 0.29348626206902895  Val loss: 0.3251403320286282
Epoch 390
-------------------------------
Batch 1/64 loss: 0.28330010175704956
Batch 2/64 loss: 0.3030303120613098
Batch 3/64 loss: 0.2953653335571289
Batch 4/64 loss: 0.2889913320541382
Batch 5/64 loss: 0.29593324661254883
Batch 6/64 loss: 0.3023107647895813
Batch 7/64 loss: 0.3005554676055908
Batch 8/64 loss: 0.281571626663208
Batch 9/64 loss: 0.2895740270614624
Batch 10/64 loss: 0.2968783378601074
Batch 11/64 loss: 0.2972809076309204
Batch 12/64 loss: 0.29241472482681274
Batch 13/64 loss: 0.2862768769264221
Batch 14/64 loss: 0.2945441007614136
Batch 15/64 loss: 0.29831600189208984
Batch 16/64 loss: 0.2996050715446472
Batch 17/64 loss: 0.2847055196762085
Batch 18/64 loss: 0.28052908182144165
Batch 19/64 loss: 0.2960397005081177
Batch 20/64 loss: 0.28984856605529785
Batch 21/64 loss: 0.3047513961791992
Batch 22/64 loss: 0.2867680788040161
Batch 23/64 loss: 0.28766942024230957
Batch 24/64 loss: 0.29771333932876587
Batch 25/64 loss: 0.27754414081573486
Batch 26/64 loss: 0.2839069366455078
Batch 27/64 loss: 0.30546075105667114
Batch 28/64 loss: 0.2879142761230469
Batch 29/64 loss: 0.2931332588195801
Batch 30/64 loss: 0.30621349811553955
Batch 31/64 loss: 0.2861390709877014
Batch 32/64 loss: 0.293773889541626
Batch 33/64 loss: 0.293660044670105
Batch 34/64 loss: 0.2881767749786377
Batch 35/64 loss: 0.302187442779541
Batch 36/64 loss: 0.29529452323913574
Batch 37/64 loss: 0.2969169616699219
Batch 38/64 loss: 0.29148703813552856
Batch 39/64 loss: 0.30869609117507935
Batch 40/64 loss: 0.29917752742767334
Batch 41/64 loss: 0.28344523906707764
Batch 42/64 loss: 0.2974344491958618
Batch 43/64 loss: 0.2851821184158325
Batch 44/64 loss: 0.3007667064666748
Batch 45/64 loss: 0.2844575047492981
Batch 46/64 loss: 0.2990357279777527
Batch 47/64 loss: 0.29365360736846924
Batch 48/64 loss: 0.2996518611907959
Batch 49/64 loss: 0.300628125667572
Batch 50/64 loss: 0.29461514949798584
Batch 51/64 loss: 0.30330950021743774
Batch 52/64 loss: 0.2964611053466797
Batch 53/64 loss: 0.29214346408843994
Batch 54/64 loss: 0.2851485013961792
Batch 55/64 loss: 0.2935142517089844
Batch 56/64 loss: 0.2975807189941406
Batch 57/64 loss: 0.29486918449401855
Batch 58/64 loss: 0.29247725009918213
Batch 59/64 loss: 0.2853434085845947
Batch 60/64 loss: 0.29342782497406006
Batch 61/64 loss: 0.3038151264190674
Batch 62/64 loss: 0.2974674701690674
Batch 63/64 loss: 0.29764294624328613
Batch 64/64 loss: 0.28850167989730835
Epoch 390  Train loss: 0.2938369108181374  Val loss: 0.32580875797370046
Epoch 391
-------------------------------
Batch 1/64 loss: 0.2921868562698364
Batch 2/64 loss: 0.29994142055511475
Batch 3/64 loss: 0.2972297668457031
Batch 4/64 loss: 0.2967022657394409
Batch 5/64 loss: 0.28800755739212036
Batch 6/64 loss: 0.2925189733505249
Batch 7/64 loss: 0.29441189765930176
Batch 8/64 loss: 0.2958533763885498
Batch 9/64 loss: 0.296972393989563
Batch 10/64 loss: 0.30586522817611694
Batch 11/64 loss: 0.2851827144622803
Batch 12/64 loss: 0.2927936315536499
Batch 13/64 loss: 0.2997713088989258
Batch 14/64 loss: 0.3017638921737671
Batch 15/64 loss: 0.28452253341674805
Batch 16/64 loss: 0.28962647914886475
Batch 17/64 loss: 0.29507625102996826
Batch 18/64 loss: 0.29497480392456055
Batch 19/64 loss: 0.2888103723526001
Batch 20/64 loss: 0.2908734083175659
Batch 21/64 loss: 0.30413126945495605
Batch 22/64 loss: 0.3072781562805176
Batch 23/64 loss: 0.29288315773010254
Batch 24/64 loss: 0.2871558666229248
Batch 25/64 loss: 0.28178441524505615
Batch 26/64 loss: 0.2896994352340698
Batch 27/64 loss: 0.29724013805389404
Batch 28/64 loss: 0.2961394786834717
Batch 29/64 loss: 0.30309367179870605
Batch 30/64 loss: 0.29907143115997314
Batch 31/64 loss: 0.2927383780479431
Batch 32/64 loss: 0.28593504428863525
Batch 33/64 loss: 0.29739975929260254
Batch 34/64 loss: 0.2908408045768738
Batch 35/64 loss: 0.30505049228668213
Batch 36/64 loss: 0.29002106189727783
Batch 37/64 loss: 0.2940363883972168
Batch 38/64 loss: 0.28570741415023804
Batch 39/64 loss: 0.30201447010040283
Batch 40/64 loss: 0.28799688816070557
Batch 41/64 loss: 0.29004013538360596
Batch 42/64 loss: 0.2900937795639038
Batch 43/64 loss: 0.2980997562408447
Batch 44/64 loss: 0.290774941444397
Batch 45/64 loss: 0.29232096672058105
Batch 46/64 loss: 0.3035217523574829
Batch 47/64 loss: 0.2894928455352783
Batch 48/64 loss: 0.29346227645874023
Batch 49/64 loss: 0.2947613000869751
Batch 50/64 loss: 0.295914888381958
Batch 51/64 loss: 0.2991138696670532
Batch 52/64 loss: 0.28535670042037964
Batch 53/64 loss: 0.29698342084884644
Batch 54/64 loss: 0.2912331819534302
Batch 55/64 loss: 0.3002887964248657
Batch 56/64 loss: 0.2938905358314514
Batch 57/64 loss: 0.30525457859039307
Batch 58/64 loss: 0.2997363209724426
Batch 59/64 loss: 0.2963939905166626
Batch 60/64 loss: 0.2993507981300354
Batch 61/64 loss: 0.2870604395866394
Batch 62/64 loss: 0.2850794196128845
Batch 63/64 loss: 0.29702913761138916
Batch 64/64 loss: 0.2879346013069153
Epoch 391  Train loss: 0.29434521782631967  Val loss: 0.3257406556729189
Epoch 392
-------------------------------
Batch 1/64 loss: 0.29996609687805176
Batch 2/64 loss: 0.29621225595474243
Batch 3/64 loss: 0.2973446249961853
Batch 4/64 loss: 0.29133760929107666
Batch 5/64 loss: 0.29406899213790894
Batch 6/64 loss: 0.2954059839248657
Batch 7/64 loss: 0.2967413663864136
Batch 8/64 loss: 0.2848352789878845
Batch 9/64 loss: 0.28888440132141113
Batch 10/64 loss: 0.2874164581298828
Batch 11/64 loss: 0.2932779788970947
Batch 12/64 loss: 0.2956697940826416
Batch 13/64 loss: 0.2916485071182251
Batch 14/64 loss: 0.29445189237594604
Batch 15/64 loss: 0.29897087812423706
Batch 16/64 loss: 0.28655409812927246
Batch 17/64 loss: 0.3000038266181946
Batch 18/64 loss: 0.2882954478263855
Batch 19/64 loss: 0.2894224524497986
Batch 20/64 loss: 0.2939454913139343
Batch 21/64 loss: 0.29175031185150146
Batch 22/64 loss: 0.2995681166648865
Batch 23/64 loss: 0.2899806499481201
Batch 24/64 loss: 0.2942996025085449
Batch 25/64 loss: 0.2802494168281555
Batch 26/64 loss: 0.29118144512176514
Batch 27/64 loss: 0.28901612758636475
Batch 28/64 loss: 0.29246366024017334
Batch 29/64 loss: 0.2976129651069641
Batch 30/64 loss: 0.2985156178474426
Batch 31/64 loss: 0.2857933044433594
Batch 32/64 loss: 0.2918826937675476
Batch 33/64 loss: 0.29312562942504883
Batch 34/64 loss: 0.2930282950401306
Batch 35/64 loss: 0.294559121131897
Batch 36/64 loss: 0.2891288995742798
Batch 37/64 loss: 0.29559797048568726
Batch 38/64 loss: 0.288948655128479
Batch 39/64 loss: 0.29673177003860474
Batch 40/64 loss: 0.2935534715652466
Batch 41/64 loss: 0.3017246723175049
Batch 42/64 loss: 0.2915043830871582
Batch 43/64 loss: 0.29686713218688965
Batch 44/64 loss: 0.3054770231246948
Batch 45/64 loss: 0.2891947031021118
Batch 46/64 loss: 0.29524701833724976
Batch 47/64 loss: 0.2898939251899719
Batch 48/64 loss: 0.288551926612854
Batch 49/64 loss: 0.2853128910064697
Batch 50/64 loss: 0.2930119037628174
Batch 51/64 loss: 0.29386723041534424
Batch 52/64 loss: 0.28863805532455444
Batch 53/64 loss: 0.30332326889038086
Batch 54/64 loss: 0.2959688901901245
Batch 55/64 loss: 0.29667437076568604
Batch 56/64 loss: 0.28863632678985596
Batch 57/64 loss: 0.2963000535964966
Batch 58/64 loss: 0.3124614953994751
Batch 59/64 loss: 0.294996976852417
Batch 60/64 loss: 0.30058300495147705
Batch 61/64 loss: 0.290935754776001
Batch 62/64 loss: 0.2890448570251465
Batch 63/64 loss: 0.29241275787353516
Batch 64/64 loss: 0.28814852237701416
Epoch 392  Train loss: 0.29346166545269536  Val loss: 0.3237317018082871
Epoch 393
-------------------------------
Batch 1/64 loss: 0.29391586780548096
Batch 2/64 loss: 0.2899930477142334
Batch 3/64 loss: 0.30429887771606445
Batch 4/64 loss: 0.29029911756515503
Batch 5/64 loss: 0.3004719018936157
Batch 6/64 loss: 0.28996360301971436
Batch 7/64 loss: 0.3030434846878052
Batch 8/64 loss: 0.2992587685585022
Batch 9/64 loss: 0.2911947965621948
Batch 10/64 loss: 0.2898080348968506
Batch 11/64 loss: 0.29205578565597534
Batch 12/64 loss: 0.2932640314102173
Batch 13/64 loss: 0.29233789443969727
Batch 14/64 loss: 0.2932366728782654
Batch 15/64 loss: 0.29578256607055664
Batch 16/64 loss: 0.28913289308547974
Batch 17/64 loss: 0.288593053817749
Batch 18/64 loss: 0.28514039516448975
Batch 19/64 loss: 0.3004571199417114
Batch 20/64 loss: 0.29547643661499023
Batch 21/64 loss: 0.3019174337387085
Batch 22/64 loss: 0.29333794116973877
Batch 23/64 loss: 0.30348289012908936
Batch 24/64 loss: 0.27994924783706665
Batch 25/64 loss: 0.287511944770813
Batch 26/64 loss: 0.29200470447540283
Batch 27/64 loss: 0.2963225841522217
Batch 28/64 loss: 0.2965242266654968
Batch 29/64 loss: 0.29404282569885254
Batch 30/64 loss: 0.29927897453308105
Batch 31/64 loss: 0.29153382778167725
Batch 32/64 loss: 0.2841707468032837
Batch 33/64 loss: 0.29454129934310913
Batch 34/64 loss: 0.28902947902679443
Batch 35/64 loss: 0.2875543236732483
Batch 36/64 loss: 0.3008665442466736
Batch 37/64 loss: 0.29157769680023193
Batch 38/64 loss: 0.28477877378463745
Batch 39/64 loss: 0.2832977771759033
Batch 40/64 loss: 0.2930511236190796
Batch 41/64 loss: 0.2936672568321228
Batch 42/64 loss: 0.29413771629333496
Batch 43/64 loss: 0.2976802587509155
Batch 44/64 loss: 0.2953110337257385
Batch 45/64 loss: 0.2891300916671753
Batch 46/64 loss: 0.2966246008872986
Batch 47/64 loss: 0.2866753339767456
Batch 48/64 loss: 0.29848170280456543
Batch 49/64 loss: 0.2947884202003479
Batch 50/64 loss: 0.2897549867630005
Batch 51/64 loss: 0.29541242122650146
Batch 52/64 loss: 0.2983745336532593
Batch 53/64 loss: 0.2867943048477173
Batch 54/64 loss: 0.29713404178619385
Batch 55/64 loss: 0.2990451455116272
Batch 56/64 loss: 0.28848928213119507
Batch 57/64 loss: 0.2975250482559204
Batch 58/64 loss: 0.2916116714477539
Batch 59/64 loss: 0.2986522912979126
Batch 60/64 loss: 0.29058313369750977
Batch 61/64 loss: 0.2950209379196167
Batch 62/64 loss: 0.2834799289703369
Batch 63/64 loss: 0.29023849964141846
Batch 64/64 loss: 0.2999562621116638
Epoch 393  Train loss: 0.29327182045169903  Val loss: 0.3251879100537382
Epoch 394
-------------------------------
Batch 1/64 loss: 0.285730242729187
Batch 2/64 loss: 0.3048660159111023
Batch 3/64 loss: 0.2975132465362549
Batch 4/64 loss: 0.3016270399093628
Batch 5/64 loss: 0.2931012511253357
Batch 6/64 loss: 0.28524190187454224
Batch 7/64 loss: 0.2949134111404419
Batch 8/64 loss: 0.28833794593811035
Batch 9/64 loss: 0.29265058040618896
Batch 10/64 loss: 0.3030521869659424
Batch 11/64 loss: 0.3050411343574524
Batch 12/64 loss: 0.298420786857605
Batch 13/64 loss: 0.30114221572875977
Batch 14/64 loss: 0.2942579388618469
Batch 15/64 loss: 0.28685665130615234
Batch 16/64 loss: 0.30286937952041626
Batch 17/64 loss: 0.29490578174591064
Batch 18/64 loss: 0.2902601957321167
Batch 19/64 loss: 0.2922024726867676
Batch 20/64 loss: 0.287642240524292
Batch 21/64 loss: 0.2865942716598511
Batch 22/64 loss: 0.298054575920105
Batch 23/64 loss: 0.29283249378204346
Batch 24/64 loss: 0.2927893400192261
Batch 25/64 loss: 0.28577786684036255
Batch 26/64 loss: 0.3046741485595703
Batch 27/64 loss: 0.29549533128738403
Batch 28/64 loss: 0.29527920484542847
Batch 29/64 loss: 0.2861452102661133
Batch 30/64 loss: 0.2899625301361084
Batch 31/64 loss: 0.2969680428504944
Batch 32/64 loss: 0.28622907400131226
Batch 33/64 loss: 0.296101450920105
Batch 34/64 loss: 0.3014935851097107
Batch 35/64 loss: 0.2955235242843628
Batch 36/64 loss: 0.2886151075363159
Batch 37/64 loss: 0.29646313190460205
Batch 38/64 loss: 0.28836989402770996
Batch 39/64 loss: 0.2885480523109436
Batch 40/64 loss: 0.2972754240036011
Batch 41/64 loss: 0.29828590154647827
Batch 42/64 loss: 0.2990294098854065
Batch 43/64 loss: 0.290000319480896
Batch 44/64 loss: 0.2987097501754761
Batch 45/64 loss: 0.29415470361709595
Batch 46/64 loss: 0.30573570728302
Batch 47/64 loss: 0.29413139820098877
Batch 48/64 loss: 0.28577589988708496
Batch 49/64 loss: 0.2919020652770996
Batch 50/64 loss: 0.3042866587638855
Batch 51/64 loss: 0.2916834354400635
Batch 52/64 loss: 0.2899453639984131
Batch 53/64 loss: 0.29798388481140137
Batch 54/64 loss: 0.29515206813812256
Batch 55/64 loss: 0.30016952753067017
Batch 56/64 loss: 0.3018307685852051
Batch 57/64 loss: 0.28860270977020264
Batch 58/64 loss: 0.29241931438446045
Batch 59/64 loss: 0.2979695796966553
Batch 60/64 loss: 0.29425233602523804
Batch 61/64 loss: 0.29069215059280396
Batch 62/64 loss: 0.305331826210022
Batch 63/64 loss: 0.2909836173057556
Batch 64/64 loss: 0.28171199560165405
Epoch 394  Train loss: 0.29449627095577763  Val loss: 0.3242294868243109
Epoch 395
-------------------------------
Batch 1/64 loss: 0.29682135581970215
Batch 2/64 loss: 0.2855525016784668
Batch 3/64 loss: 0.28487563133239746
Batch 4/64 loss: 0.28707361221313477
Batch 5/64 loss: 0.2940409779548645
Batch 6/64 loss: 0.30382585525512695
Batch 7/64 loss: 0.2914785146713257
Batch 8/64 loss: 0.29799747467041016
Batch 9/64 loss: 0.2944797873497009
Batch 10/64 loss: 0.2963736653327942
Batch 11/64 loss: 0.3027573823928833
Batch 12/64 loss: 0.2996448278427124
Batch 13/64 loss: 0.29515838623046875
Batch 14/64 loss: 0.2899066209793091
Batch 15/64 loss: 0.2925450801849365
Batch 16/64 loss: 0.2892425060272217
Batch 17/64 loss: 0.29029393196105957
Batch 18/64 loss: 0.2987031936645508
Batch 19/64 loss: 0.29634594917297363
Batch 20/64 loss: 0.3019205331802368
Batch 21/64 loss: 0.3031548261642456
Batch 22/64 loss: 0.2862633466720581
Batch 23/64 loss: 0.29770326614379883
Batch 24/64 loss: 0.29385459423065186
Batch 25/64 loss: 0.2885224223136902
Batch 26/64 loss: 0.29514336585998535
Batch 27/64 loss: 0.2927851676940918
Batch 28/64 loss: 0.29116010665893555
Batch 29/64 loss: 0.282389760017395
Batch 30/64 loss: 0.2950837016105652
Batch 31/64 loss: 0.29242825508117676
Batch 32/64 loss: 0.29025423526763916
Batch 33/64 loss: 0.2956506013870239
Batch 34/64 loss: 0.2885044813156128
Batch 35/64 loss: 0.28822100162506104
Batch 36/64 loss: 0.2961306571960449
Batch 37/64 loss: 0.2964986562728882
Batch 38/64 loss: 0.2866920232772827
Batch 39/64 loss: 0.28845733404159546
Batch 40/64 loss: 0.29143083095550537
Batch 41/64 loss: 0.29294687509536743
Batch 42/64 loss: 0.28367286920547485
Batch 43/64 loss: 0.2872622609138489
Batch 44/64 loss: 0.2914997339248657
Batch 45/64 loss: 0.2869138717651367
Batch 46/64 loss: 0.29910778999328613
Batch 47/64 loss: 0.30084383487701416
Batch 48/64 loss: 0.2924962639808655
Batch 49/64 loss: 0.2949209213256836
Batch 50/64 loss: 0.297374427318573
Batch 51/64 loss: 0.2911924123764038
Batch 52/64 loss: 0.2920188903808594
Batch 53/64 loss: 0.2974836826324463
Batch 54/64 loss: 0.29370200634002686
Batch 55/64 loss: 0.2908271551132202
Batch 56/64 loss: 0.2865011692047119
Batch 57/64 loss: 0.2896791696548462
Batch 58/64 loss: 0.29081499576568604
Batch 59/64 loss: 0.2961157560348511
Batch 60/64 loss: 0.28796929121017456
Batch 61/64 loss: 0.3055575489997864
Batch 62/64 loss: 0.2946394681930542
Batch 63/64 loss: 0.2923088073730469
Batch 64/64 loss: 0.2946321964263916
Epoch 395  Train loss: 0.29311670228546743  Val loss: 0.3237448643982615
Epoch 396
-------------------------------
Batch 1/64 loss: 0.3027225136756897
Batch 2/64 loss: 0.2937120795249939
Batch 3/64 loss: 0.29830503463745117
Batch 4/64 loss: 0.2969364523887634
Batch 5/64 loss: 0.2905774712562561
Batch 6/64 loss: 0.28856581449508667
Batch 7/64 loss: 0.2886829376220703
Batch 8/64 loss: 0.2860121726989746
Batch 9/64 loss: 0.2960538864135742
Batch 10/64 loss: 0.2979313135147095
Batch 11/64 loss: 0.2927510738372803
Batch 12/64 loss: 0.2944769859313965
Batch 13/64 loss: 0.2952413558959961
Batch 14/64 loss: 0.28538763523101807
Batch 15/64 loss: 0.2895249128341675
Batch 16/64 loss: 0.28654688596725464
Batch 17/64 loss: 0.288175106048584
Batch 18/64 loss: 0.27858924865722656
Batch 19/64 loss: 0.29413294792175293
Batch 20/64 loss: 0.2900838851928711
Batch 21/64 loss: 0.29063695669174194
Batch 22/64 loss: 0.2839887738227844
Batch 23/64 loss: 0.30568909645080566
Batch 24/64 loss: 0.2983049154281616
Batch 25/64 loss: 0.29795026779174805
Batch 26/64 loss: 0.2849896550178528
Batch 27/64 loss: 0.29832160472869873
Batch 28/64 loss: 0.2888867259025574
Batch 29/64 loss: 0.31296420097351074
Batch 30/64 loss: 0.2947659492492676
Batch 31/64 loss: 0.28841590881347656
Batch 32/64 loss: 0.29158663749694824
Batch 33/64 loss: 0.2878391742706299
Batch 34/64 loss: 0.29309070110321045
Batch 35/64 loss: 0.2939625382423401
Batch 36/64 loss: 0.2935976982116699
Batch 37/64 loss: 0.29151153564453125
Batch 38/64 loss: 0.2877289056777954
Batch 39/64 loss: 0.2891194820404053
Batch 40/64 loss: 0.2895936965942383
Batch 41/64 loss: 0.28849291801452637
Batch 42/64 loss: 0.2975894808769226
Batch 43/64 loss: 0.28867363929748535
Batch 44/64 loss: 0.29581642150878906
Batch 45/64 loss: 0.29059749841690063
Batch 46/64 loss: 0.3011821508407593
Batch 47/64 loss: 0.28865867853164673
Batch 48/64 loss: 0.3018890619277954
Batch 49/64 loss: 0.2916474938392639
Batch 50/64 loss: 0.30020904541015625
Batch 51/64 loss: 0.2869558334350586
Batch 52/64 loss: 0.2845216989517212
Batch 53/64 loss: 0.2802157402038574
Batch 54/64 loss: 0.2965620160102844
Batch 55/64 loss: 0.29283344745635986
Batch 56/64 loss: 0.2967621088027954
Batch 57/64 loss: 0.2977709174156189
Batch 58/64 loss: 0.2913103699684143
Batch 59/64 loss: 0.2950487732887268
Batch 60/64 loss: 0.2975274324417114
Batch 61/64 loss: 0.30007636547088623
Batch 62/64 loss: 0.2900974750518799
Batch 63/64 loss: 0.30459123849868774
Batch 64/64 loss: 0.2830125093460083
Epoch 396  Train loss: 0.2928414639304666  Val loss: 0.3237301727750457
Epoch 397
-------------------------------
Batch 1/64 loss: 0.29546165466308594
Batch 2/64 loss: 0.2942967414855957
Batch 3/64 loss: 0.29455387592315674
Batch 4/64 loss: 0.2957305908203125
Batch 5/64 loss: 0.2889506220817566
Batch 6/64 loss: 0.2912108898162842
Batch 7/64 loss: 0.2887057065963745
Batch 8/64 loss: 0.30048733949661255
Batch 9/64 loss: 0.2881138324737549
Batch 10/64 loss: 0.28968650102615356
Batch 11/64 loss: 0.2890743613243103
Batch 12/64 loss: 0.28796088695526123
Batch 13/64 loss: 0.29747462272644043
Batch 14/64 loss: 0.30487823486328125
Batch 15/64 loss: 0.30112355947494507
Batch 16/64 loss: 0.2851748466491699
Batch 17/64 loss: 0.28118181228637695
Batch 18/64 loss: 0.3007090091705322
Batch 19/64 loss: 0.30007046461105347
Batch 20/64 loss: 0.2839401960372925
Batch 21/64 loss: 0.2961069345474243
Batch 22/64 loss: 0.2898494005203247
Batch 23/64 loss: 0.29317009449005127
Batch 24/64 loss: 0.2912536859512329
Batch 25/64 loss: 0.2869410514831543
Batch 26/64 loss: 0.2902555465698242
Batch 27/64 loss: 0.28881001472473145
Batch 28/64 loss: 0.28588199615478516
Batch 29/64 loss: 0.29381263256073
Batch 30/64 loss: 0.2976224422454834
Batch 31/64 loss: 0.29219359159469604
Batch 32/64 loss: 0.2940267324447632
Batch 33/64 loss: 0.293729305267334
Batch 34/64 loss: 0.2946939468383789
Batch 35/64 loss: 0.2949262857437134
Batch 36/64 loss: 0.2883751392364502
Batch 37/64 loss: 0.29656708240509033
Batch 38/64 loss: 0.2845193147659302
Batch 39/64 loss: 0.2907371520996094
Batch 40/64 loss: 0.29460638761520386
Batch 41/64 loss: 0.2970849871635437
Batch 42/64 loss: 0.2968448996543884
Batch 43/64 loss: 0.2889420986175537
Batch 44/64 loss: 0.28867650032043457
Batch 45/64 loss: 0.2829430103302002
Batch 46/64 loss: 0.29189515113830566
Batch 47/64 loss: 0.2849421501159668
Batch 48/64 loss: 0.29164838790893555
Batch 49/64 loss: 0.30370306968688965
Batch 50/64 loss: 0.30213356018066406
Batch 51/64 loss: 0.28302478790283203
Batch 52/64 loss: 0.29851973056793213
Batch 53/64 loss: 0.2945079207420349
Batch 54/64 loss: 0.2895039916038513
Batch 55/64 loss: 0.288155734539032
Batch 56/64 loss: 0.29599010944366455
Batch 57/64 loss: 0.2959880828857422
Batch 58/64 loss: 0.2870168089866638
Batch 59/64 loss: 0.2903425693511963
Batch 60/64 loss: 0.29911309480667114
Batch 61/64 loss: 0.2906237840652466
Batch 62/64 loss: 0.3008002042770386
Batch 63/64 loss: 0.29340028762817383
Batch 64/64 loss: 0.3018525242805481
Epoch 397  Train loss: 0.29269105569989073  Val loss: 0.32490688623841274
Epoch 398
-------------------------------
Batch 1/64 loss: 0.2822319269180298
Batch 2/64 loss: 0.2947086691856384
Batch 3/64 loss: 0.28890442848205566
Batch 4/64 loss: 0.2878001928329468
Batch 5/64 loss: 0.30299293994903564
Batch 6/64 loss: 0.29329776763916016
Batch 7/64 loss: 0.2874903678894043
Batch 8/64 loss: 0.28924041986465454
Batch 9/64 loss: 0.2925471067428589
Batch 10/64 loss: 0.2904295325279236
Batch 11/64 loss: 0.28186458349227905
Batch 12/64 loss: 0.2937352657318115
Batch 13/64 loss: 0.2895464301109314
Batch 14/64 loss: 0.2868391275405884
Batch 15/64 loss: 0.2898091673851013
Batch 16/64 loss: 0.2978639602661133
Batch 17/64 loss: 0.30108290910720825
Batch 18/64 loss: 0.2887376546859741
Batch 19/64 loss: 0.288293719291687
Batch 20/64 loss: 0.2835502624511719
Batch 21/64 loss: 0.3005063533782959
Batch 22/64 loss: 0.2867562770843506
Batch 23/64 loss: 0.294277548789978
Batch 24/64 loss: 0.29324769973754883
Batch 25/64 loss: 0.2958836555480957
Batch 26/64 loss: 0.29685091972351074
Batch 27/64 loss: 0.2955360412597656
Batch 28/64 loss: 0.2960434556007385
Batch 29/64 loss: 0.29417872428894043
Batch 30/64 loss: 0.2897036671638489
Batch 31/64 loss: 0.3018565773963928
Batch 32/64 loss: 0.28663182258605957
Batch 33/64 loss: 0.2882404327392578
Batch 34/64 loss: 0.3001851439476013
Batch 35/64 loss: 0.2976899743080139
Batch 36/64 loss: 0.2866532802581787
Batch 37/64 loss: 0.2937893867492676
Batch 38/64 loss: 0.28694820404052734
Batch 39/64 loss: 0.3057308793067932
Batch 40/64 loss: 0.28352057933807373
Batch 41/64 loss: 0.2859545946121216
Batch 42/64 loss: 0.3014603853225708
Batch 43/64 loss: 0.2941489815711975
Batch 44/64 loss: 0.29679399728775024
Batch 45/64 loss: 0.29316526651382446
Batch 46/64 loss: 0.29243701696395874
Batch 47/64 loss: 0.3001493215560913
Batch 48/64 loss: 0.28987932205200195
Batch 49/64 loss: 0.28895139694213867
Batch 50/64 loss: 0.30017638206481934
Batch 51/64 loss: 0.30230236053466797
Batch 52/64 loss: 0.2925673723220825
Batch 53/64 loss: 0.2978318929672241
Batch 54/64 loss: 0.27878689765930176
Batch 55/64 loss: 0.29076164960861206
Batch 56/64 loss: 0.2936279773712158
Batch 57/64 loss: 0.29415977001190186
Batch 58/64 loss: 0.29778361320495605
Batch 59/64 loss: 0.3002128005027771
Batch 60/64 loss: 0.30095213651657104
Batch 61/64 loss: 0.2906220555305481
Batch 62/64 loss: 0.2855093479156494
Batch 63/64 loss: 0.2917729616165161
Batch 64/64 loss: 0.2968541979789734
Epoch 398  Train loss: 0.292828944383883  Val loss: 0.32423074958250697
Epoch 399
-------------------------------
Batch 1/64 loss: 0.28776073455810547
Batch 2/64 loss: 0.28853774070739746
Batch 3/64 loss: 0.29352641105651855
Batch 4/64 loss: 0.2902313470840454
Batch 5/64 loss: 0.28631311655044556
Batch 6/64 loss: 0.2973599433898926
Batch 7/64 loss: 0.29982030391693115
Batch 8/64 loss: 0.2889184355735779
Batch 9/64 loss: 0.3011469841003418
Batch 10/64 loss: 0.287850558757782
Batch 11/64 loss: 0.2866823673248291
Batch 12/64 loss: 0.2950947880744934
Batch 13/64 loss: 0.2887152433395386
Batch 14/64 loss: 0.29444271326065063
Batch 15/64 loss: 0.3055558204650879
Batch 16/64 loss: 0.28994226455688477
Batch 17/64 loss: 0.2894439697265625
Batch 18/64 loss: 0.28786152601242065
Batch 19/64 loss: 0.2918349504470825
Batch 20/64 loss: 0.2902495861053467
Batch 21/64 loss: 0.2961612939834595
Batch 22/64 loss: 0.28705644607543945
Batch 23/64 loss: 0.28833240270614624
Batch 24/64 loss: 0.2930992841720581
Batch 25/64 loss: 0.28362494707107544
Batch 26/64 loss: 0.2946575880050659
Batch 27/64 loss: 0.2858138084411621
Batch 28/64 loss: 0.2903183698654175
Batch 29/64 loss: 0.29453420639038086
Batch 30/64 loss: 0.3040527105331421
Batch 31/64 loss: 0.2964283227920532
Batch 32/64 loss: 0.2870907783508301
Batch 33/64 loss: 0.2916545867919922
Batch 34/64 loss: 0.29246723651885986
Batch 35/64 loss: 0.2943429946899414
Batch 36/64 loss: 0.2972152829170227
Batch 37/64 loss: 0.2863529324531555
Batch 38/64 loss: 0.3024461269378662
Batch 39/64 loss: 0.2896728515625
Batch 40/64 loss: 0.2966651916503906
Batch 41/64 loss: 0.2948265075683594
Batch 42/64 loss: 0.2965388894081116
Batch 43/64 loss: 0.2923785448074341
Batch 44/64 loss: 0.2918853759765625
Batch 45/64 loss: 0.29581665992736816
Batch 46/64 loss: 0.28967368602752686
Batch 47/64 loss: 0.2838045358657837
Batch 48/64 loss: 0.29191458225250244
Batch 49/64 loss: 0.2886122465133667
Batch 50/64 loss: 0.29684776067733765
Batch 51/64 loss: 0.29253315925598145
Batch 52/64 loss: 0.2971803545951843
Batch 53/64 loss: 0.286854088306427
Batch 54/64 loss: 0.30792874097824097
Batch 55/64 loss: 0.3037746548652649
Batch 56/64 loss: 0.2889949083328247
Batch 57/64 loss: 0.29658055305480957
Batch 58/64 loss: 0.29083728790283203
Batch 59/64 loss: 0.2926388382911682
Batch 60/64 loss: 0.2849687337875366
Batch 61/64 loss: 0.30384939908981323
Batch 62/64 loss: 0.2965657711029053
Batch 63/64 loss: 0.2864357829093933
Batch 64/64 loss: 0.2929535508155823
Epoch 399  Train loss: 0.2927754100631265  Val loss: 0.3251837090528298
Epoch 400
-------------------------------
Batch 1/64 loss: 0.2899078130722046
Batch 2/64 loss: 0.30173683166503906
Batch 3/64 loss: 0.295931339263916
Batch 4/64 loss: 0.2947108745574951
Batch 5/64 loss: 0.2954549789428711
Batch 6/64 loss: 0.2777482867240906
Batch 7/64 loss: 0.30258166790008545
Batch 8/64 loss: 0.2886394262313843
Batch 9/64 loss: 0.29542458057403564
Batch 10/64 loss: 0.29187434911727905
Batch 11/64 loss: 0.2910427451133728
Batch 12/64 loss: 0.28917932510375977
Batch 13/64 loss: 0.29724180698394775
Batch 14/64 loss: 0.2909272313117981
Batch 15/64 loss: 0.29103970527648926
Batch 16/64 loss: 0.2903538942337036
Batch 17/64 loss: 0.29780030250549316
Batch 18/64 loss: 0.28641021251678467
Batch 19/64 loss: 0.289681613445282
Batch 20/64 loss: 0.294508695602417
Batch 21/64 loss: 0.2804145812988281
Batch 22/64 loss: 0.28629136085510254
Batch 23/64 loss: 0.2960076332092285
Batch 24/64 loss: 0.29246222972869873
Batch 25/64 loss: 0.28814077377319336
Batch 26/64 loss: 0.29483723640441895
Batch 27/64 loss: 0.287736713886261
Batch 28/64 loss: 0.29084837436676025
Batch 29/64 loss: 0.28610551357269287
Batch 30/64 loss: 0.2852531671524048
Batch 31/64 loss: 0.30172085762023926
Batch 32/64 loss: 0.2984393835067749
Batch 33/64 loss: 0.29456424713134766
Batch 34/64 loss: 0.29124534130096436
Batch 35/64 loss: 0.28833967447280884
Batch 36/64 loss: 0.2988376021385193
Batch 37/64 loss: 0.2885545492172241
Batch 38/64 loss: 0.3055803179740906
Batch 39/64 loss: 0.293451189994812
Batch 40/64 loss: 0.2913925051689148
Batch 41/64 loss: 0.29843491315841675
Batch 42/64 loss: 0.2935876250267029
Batch 43/64 loss: 0.2860218286514282
Batch 44/64 loss: 0.30201566219329834
Batch 45/64 loss: 0.28933626413345337
Batch 46/64 loss: 0.30406028032302856
Batch 47/64 loss: 0.28794926404953003
Batch 48/64 loss: 0.2964709997177124
Batch 49/64 loss: 0.2990081310272217
Batch 50/64 loss: 0.28985339403152466
Batch 51/64 loss: 0.2824932336807251
Batch 52/64 loss: 0.2928823232650757
Batch 53/64 loss: 0.2861964702606201
Batch 54/64 loss: 0.2947534918785095
Batch 55/64 loss: 0.2974417805671692
Batch 56/64 loss: 0.2939022183418274
Batch 57/64 loss: 0.2872547507286072
Batch 58/64 loss: 0.28859567642211914
Batch 59/64 loss: 0.2941766381263733
Batch 60/64 loss: 0.29133427143096924
Batch 61/64 loss: 0.29708975553512573
Batch 62/64 loss: 0.29404717683792114
Batch 63/64 loss: 0.2987056374549866
Batch 64/64 loss: 0.29484856128692627
Epoch 400  Train loss: 0.29269281789368273  Val loss: 0.3254828270767972
Epoch 401
-------------------------------
Batch 1/64 loss: 0.2929726243019104
Batch 2/64 loss: 0.2870367765426636
Batch 3/64 loss: 0.29601073265075684
Batch 4/64 loss: 0.29802370071411133
Batch 5/64 loss: 0.2893643379211426
Batch 6/64 loss: 0.30401670932769775
Batch 7/64 loss: 0.2919299006462097
Batch 8/64 loss: 0.28556525707244873
Batch 9/64 loss: 0.2916126251220703
Batch 10/64 loss: 0.2908281087875366
Batch 11/64 loss: 0.2851402759552002
Batch 12/64 loss: 0.2880669832229614
Batch 13/64 loss: 0.2873222827911377
Batch 14/64 loss: 0.2908245325088501
Batch 15/64 loss: 0.29243671894073486
Batch 16/64 loss: 0.2858428955078125
Batch 17/64 loss: 0.30378830432891846
Batch 18/64 loss: 0.2958834171295166
Batch 19/64 loss: 0.284415602684021
Batch 20/64 loss: 0.28348731994628906
Batch 21/64 loss: 0.29723161458969116
Batch 22/64 loss: 0.2936743497848511
Batch 23/64 loss: 0.30328428745269775
Batch 24/64 loss: 0.28594738245010376
Batch 25/64 loss: 0.2922024130821228
Batch 26/64 loss: 0.3133379817008972
Batch 27/64 loss: 0.2868553400039673
Batch 28/64 loss: 0.3036796450614929
Batch 29/64 loss: 0.2943711280822754
Batch 30/64 loss: 0.2963733673095703
Batch 31/64 loss: 0.28585267066955566
Batch 32/64 loss: 0.2942317724227905
Batch 33/64 loss: 0.29001927375793457
Batch 34/64 loss: 0.29189056158065796
Batch 35/64 loss: 0.28709185123443604
Batch 36/64 loss: 0.2901034951210022
Batch 37/64 loss: 0.28130674362182617
Batch 38/64 loss: 0.28901684284210205
Batch 39/64 loss: 0.2986027002334595
Batch 40/64 loss: 0.2944265604019165
Batch 41/64 loss: 0.2931469678878784
Batch 42/64 loss: 0.2849525809288025
Batch 43/64 loss: 0.2883894443511963
Batch 44/64 loss: 0.3007757067680359
Batch 45/64 loss: 0.28965431451797485
Batch 46/64 loss: 0.29431450366973877
Batch 47/64 loss: 0.2884104251861572
Batch 48/64 loss: 0.29663288593292236
Batch 49/64 loss: 0.2955054044723511
Batch 50/64 loss: 0.29623425006866455
Batch 51/64 loss: 0.2940260171890259
Batch 52/64 loss: 0.29247909784317017
Batch 53/64 loss: 0.30566954612731934
Batch 54/64 loss: 0.2927325367927551
Batch 55/64 loss: 0.29590487480163574
Batch 56/64 loss: 0.2943981885910034
Batch 57/64 loss: 0.2936967611312866
Batch 58/64 loss: 0.2914271354675293
Batch 59/64 loss: 0.2920342683792114
Batch 60/64 loss: 0.28423428535461426
Batch 61/64 loss: 0.2973105311393738
Batch 62/64 loss: 0.2949937582015991
Batch 63/64 loss: 0.2876403331756592
Batch 64/64 loss: 0.29850125312805176
Epoch 401  Train loss: 0.292745236789479  Val loss: 0.32364786654403527
Epoch 402
-------------------------------
Batch 1/64 loss: 0.2886599898338318
Batch 2/64 loss: 0.28251540660858154
Batch 3/64 loss: 0.287447452545166
Batch 4/64 loss: 0.2873331904411316
Batch 5/64 loss: 0.3001238703727722
Batch 6/64 loss: 0.2876460552215576
Batch 7/64 loss: 0.2937333583831787
Batch 8/64 loss: 0.2997695207595825
Batch 9/64 loss: 0.28961896896362305
Batch 10/64 loss: 0.29583173990249634
Batch 11/64 loss: 0.29027652740478516
Batch 12/64 loss: 0.27979516983032227
Batch 13/64 loss: 0.2804974317550659
Batch 14/64 loss: 0.28391945362091064
Batch 15/64 loss: 0.29225510358810425
Batch 16/64 loss: 0.28895580768585205
Batch 17/64 loss: 0.2787021994590759
Batch 18/64 loss: 0.2889355421066284
Batch 19/64 loss: 0.2826606035232544
Batch 20/64 loss: 0.28643274307250977
Batch 21/64 loss: 0.2885032296180725
Batch 22/64 loss: 0.28924500942230225
Batch 23/64 loss: 0.2983435392379761
Batch 24/64 loss: 0.3015110492706299
Batch 25/64 loss: 0.2922833561897278
Batch 26/64 loss: 0.29665452241897583
Batch 27/64 loss: 0.3033868670463562
Batch 28/64 loss: 0.3043217062950134
Batch 29/64 loss: 0.2859433889389038
Batch 30/64 loss: 0.3027527332305908
Batch 31/64 loss: 0.29212772846221924
Batch 32/64 loss: 0.29748404026031494
Batch 33/64 loss: 0.29418087005615234
Batch 34/64 loss: 0.3031761646270752
Batch 35/64 loss: 0.2950095534324646
Batch 36/64 loss: 0.294941246509552
Batch 37/64 loss: 0.2912037968635559
Batch 38/64 loss: 0.2902946472167969
Batch 39/64 loss: 0.3008166551589966
Batch 40/64 loss: 0.2908939719200134
Batch 41/64 loss: 0.2912442088127136
Batch 42/64 loss: 0.28960120677948
Batch 43/64 loss: 0.2884370684623718
Batch 44/64 loss: 0.2912442088127136
Batch 45/64 loss: 0.30106043815612793
Batch 46/64 loss: 0.30778419971466064
Batch 47/64 loss: 0.2874841094017029
Batch 48/64 loss: 0.29299116134643555
Batch 49/64 loss: 0.29430365562438965
Batch 50/64 loss: 0.3019615411758423
Batch 51/64 loss: 0.2942359447479248
Batch 52/64 loss: 0.29571259021759033
Batch 53/64 loss: 0.28683602809906006
Batch 54/64 loss: 0.2928752899169922
Batch 55/64 loss: 0.30652815103530884
Batch 56/64 loss: 0.28398942947387695
Batch 57/64 loss: 0.29014188051223755
Batch 58/64 loss: 0.2941344380378723
Batch 59/64 loss: 0.2924603819847107
Batch 60/64 loss: 0.2930257320404053
Batch 61/64 loss: 0.3000757694244385
Batch 62/64 loss: 0.2958744764328003
Batch 63/64 loss: 0.28585654497146606
Batch 64/64 loss: 0.29605376720428467
Epoch 402  Train loss: 0.29267581163668166  Val loss: 0.32477679736016135
Epoch 403
-------------------------------
Batch 1/64 loss: 0.2905350923538208
Batch 2/64 loss: 0.2988319396972656
Batch 3/64 loss: 0.31217432022094727
Batch 4/64 loss: 0.2903112769126892
Batch 5/64 loss: 0.29061365127563477
Batch 6/64 loss: 0.29324817657470703
Batch 7/64 loss: 0.29251718521118164
Batch 8/64 loss: 0.2857974171638489
Batch 9/64 loss: 0.2904345989227295
Batch 10/64 loss: 0.29699385166168213
Batch 11/64 loss: 0.29533809423446655
Batch 12/64 loss: 0.301760196685791
Batch 13/64 loss: 0.2822068929672241
Batch 14/64 loss: 0.2887793779373169
Batch 15/64 loss: 0.29415345191955566
Batch 16/64 loss: 0.2979997396469116
Batch 17/64 loss: 0.2887505292892456
Batch 18/64 loss: 0.28765547275543213
Batch 19/64 loss: 0.29708951711654663
Batch 20/64 loss: 0.29138636589050293
Batch 21/64 loss: 0.283220112323761
Batch 22/64 loss: 0.29270869493484497
Batch 23/64 loss: 0.2847646474838257
Batch 24/64 loss: 0.2923930883407593
Batch 25/64 loss: 0.291606068611145
Batch 26/64 loss: 0.2900027632713318
Batch 27/64 loss: 0.2903296947479248
Batch 28/64 loss: 0.2964416742324829
Batch 29/64 loss: 0.2895166873931885
Batch 30/64 loss: 0.3017316460609436
Batch 31/64 loss: 0.2819344401359558
Batch 32/64 loss: 0.29747021198272705
Batch 33/64 loss: 0.2828850746154785
Batch 34/64 loss: 0.2856316566467285
Batch 35/64 loss: 0.29407989978790283
Batch 36/64 loss: 0.2927672266960144
Batch 37/64 loss: 0.29532867670059204
Batch 38/64 loss: 0.29442524909973145
Batch 39/64 loss: 0.290371298789978
Batch 40/64 loss: 0.28899085521698
Batch 41/64 loss: 0.28672361373901367
Batch 42/64 loss: 0.29091084003448486
Batch 43/64 loss: 0.2901269197463989
Batch 44/64 loss: 0.29226791858673096
Batch 45/64 loss: 0.297544002532959
Batch 46/64 loss: 0.29470014572143555
Batch 47/64 loss: 0.28624963760375977
Batch 48/64 loss: 0.293282151222229
Batch 49/64 loss: 0.29153650999069214
Batch 50/64 loss: 0.2874079942703247
Batch 51/64 loss: 0.2995096445083618
Batch 52/64 loss: 0.3019031286239624
Batch 53/64 loss: 0.28397858142852783
Batch 54/64 loss: 0.29650628566741943
Batch 55/64 loss: 0.2976102828979492
Batch 56/64 loss: 0.29874539375305176
Batch 57/64 loss: 0.2922697067260742
Batch 58/64 loss: 0.3000295162200928
Batch 59/64 loss: 0.2984856367111206
Batch 60/64 loss: 0.2879860997200012
Batch 61/64 loss: 0.29535043239593506
Batch 62/64 loss: 0.2936486601829529
Batch 63/64 loss: 0.29006075859069824
Batch 64/64 loss: 0.2993162274360657
Epoch 403  Train loss: 0.2926195740699768  Val loss: 0.32539921118221743
Epoch 404
-------------------------------
Batch 1/64 loss: 0.2819126844406128
Batch 2/64 loss: 0.2869277000427246
Batch 3/64 loss: 0.29793113470077515
Batch 4/64 loss: 0.2947770357131958
Batch 5/64 loss: 0.3025891184806824
Batch 6/64 loss: 0.29219114780426025
Batch 7/64 loss: 0.29233795404434204
Batch 8/64 loss: 0.28366756439208984
Batch 9/64 loss: 0.28578615188598633
Batch 10/64 loss: 0.2876323461532593
Batch 11/64 loss: 0.29194915294647217
Batch 12/64 loss: 0.2971530556678772
Batch 13/64 loss: 0.29987597465515137
Batch 14/64 loss: 0.29604506492614746
Batch 15/64 loss: 0.2936621904373169
Batch 16/64 loss: 0.29154276847839355
Batch 17/64 loss: 0.28763461112976074
Batch 18/64 loss: 0.29881715774536133
Batch 19/64 loss: 0.29038524627685547
Batch 20/64 loss: 0.2985180616378784
Batch 21/64 loss: 0.29305195808410645
Batch 22/64 loss: 0.288494348526001
Batch 23/64 loss: 0.2919004559516907
Batch 24/64 loss: 0.2898097038269043
Batch 25/64 loss: 0.2917349338531494
Batch 26/64 loss: 0.29943394660949707
Batch 27/64 loss: 0.2974535822868347
Batch 28/64 loss: 0.3129326105117798
Batch 29/64 loss: 0.30767500400543213
Batch 30/64 loss: 0.302875280380249
Batch 31/64 loss: 0.28649401664733887
Batch 32/64 loss: 0.2842295169830322
Batch 33/64 loss: 0.29963183403015137
Batch 34/64 loss: 0.28741025924682617
Batch 35/64 loss: 0.29601579904556274
Batch 36/64 loss: 0.29800325632095337
Batch 37/64 loss: 0.2892088294029236
Batch 38/64 loss: 0.286512553691864
Batch 39/64 loss: 0.2856234312057495
Batch 40/64 loss: 0.28727054595947266
Batch 41/64 loss: 0.2951958179473877
Batch 42/64 loss: 0.2976086735725403
Batch 43/64 loss: 0.2862222194671631
Batch 44/64 loss: 0.289539098739624
Batch 45/64 loss: 0.2945142388343811
Batch 46/64 loss: 0.29678875207901
Batch 47/64 loss: 0.2947261333465576
Batch 48/64 loss: 0.2800171375274658
Batch 49/64 loss: 0.290179967880249
Batch 50/64 loss: 0.28992241621017456
Batch 51/64 loss: 0.2916972041130066
Batch 52/64 loss: 0.2917857766151428
Batch 53/64 loss: 0.2866221070289612
Batch 54/64 loss: 0.2999953031539917
Batch 55/64 loss: 0.2886451482772827
Batch 56/64 loss: 0.29187917709350586
Batch 57/64 loss: 0.2902177572250366
Batch 58/64 loss: 0.2946935296058655
Batch 59/64 loss: 0.28990328311920166
Batch 60/64 loss: 0.2893369197845459
Batch 61/64 loss: 0.2906031608581543
Batch 62/64 loss: 0.28586679697036743
Batch 63/64 loss: 0.283077597618103
Batch 64/64 loss: 0.29486083984375
Epoch 404  Train loss: 0.2923495189816344  Val loss: 0.3250675514801261
Epoch 405
-------------------------------
Batch 1/64 loss: 0.28621363639831543
Batch 2/64 loss: 0.29552245140075684
Batch 3/64 loss: 0.28740227222442627
Batch 4/64 loss: 0.28271055221557617
Batch 5/64 loss: 0.29023128747940063
Batch 6/64 loss: 0.2853424549102783
Batch 7/64 loss: 0.2880204916000366
Batch 8/64 loss: 0.29340672492980957
Batch 9/64 loss: 0.2910369634628296
Batch 10/64 loss: 0.29182934761047363
Batch 11/64 loss: 0.2910531759262085
Batch 12/64 loss: 0.28856217861175537
Batch 13/64 loss: 0.28431713581085205
Batch 14/64 loss: 0.29108500480651855
Batch 15/64 loss: 0.28770768642425537
Batch 16/64 loss: 0.2812347412109375
Batch 17/64 loss: 0.3032364845275879
Batch 18/64 loss: 0.2974003553390503
Batch 19/64 loss: 0.2937053442001343
Batch 20/64 loss: 0.2943304181098938
Batch 21/64 loss: 0.29104405641555786
Batch 22/64 loss: 0.2889256477355957
Batch 23/64 loss: 0.28434979915618896
Batch 24/64 loss: 0.2902485132217407
Batch 25/64 loss: 0.2906029224395752
Batch 26/64 loss: 0.3003562092781067
Batch 27/64 loss: 0.3020551800727844
Batch 28/64 loss: 0.2927800416946411
Batch 29/64 loss: 0.28634560108184814
Batch 30/64 loss: 0.2947256565093994
Batch 31/64 loss: 0.29259830713272095
Batch 32/64 loss: 0.28603267669677734
Batch 33/64 loss: 0.28751516342163086
Batch 34/64 loss: 0.3080505132675171
Batch 35/64 loss: 0.2808196544647217
Batch 36/64 loss: 0.2902602553367615
Batch 37/64 loss: 0.2962353229522705
Batch 38/64 loss: 0.29416370391845703
Batch 39/64 loss: 0.29782426357269287
Batch 40/64 loss: 0.2958897352218628
Batch 41/64 loss: 0.28839993476867676
Batch 42/64 loss: 0.29418593645095825
Batch 43/64 loss: 0.2964707016944885
Batch 44/64 loss: 0.2898699641227722
Batch 45/64 loss: 0.29027271270751953
Batch 46/64 loss: 0.29394519329071045
Batch 47/64 loss: 0.29516541957855225
Batch 48/64 loss: 0.2932354807853699
Batch 49/64 loss: 0.2939794063568115
Batch 50/64 loss: 0.2985670566558838
Batch 51/64 loss: 0.291719913482666
Batch 52/64 loss: 0.29812997579574585
Batch 53/64 loss: 0.29266417026519775
Batch 54/64 loss: 0.2867639660835266
Batch 55/64 loss: 0.2923532724380493
Batch 56/64 loss: 0.2924187183380127
Batch 57/64 loss: 0.29932987689971924
Batch 58/64 loss: 0.29873335361480713
Batch 59/64 loss: 0.2946799397468567
Batch 60/64 loss: 0.29643917083740234
Batch 61/64 loss: 0.29567527770996094
Batch 62/64 loss: 0.29680007696151733
Batch 63/64 loss: 0.2940276861190796
Batch 64/64 loss: 0.29980015754699707
Epoch 405  Train loss: 0.29245253731222715  Val loss: 0.3248526482647637
Epoch 406
-------------------------------
Batch 1/64 loss: 0.29745662212371826
Batch 2/64 loss: 0.2892523407936096
Batch 3/64 loss: 0.2941652536392212
Batch 4/64 loss: 0.2949144244194031
Batch 5/64 loss: 0.28747665882110596
Batch 6/64 loss: 0.29250067472457886
Batch 7/64 loss: 0.2833653688430786
Batch 8/64 loss: 0.28798389434814453
Batch 9/64 loss: 0.28988319635391235
Batch 10/64 loss: 0.29182493686676025
Batch 11/64 loss: 0.29560643434524536
Batch 12/64 loss: 0.2876247763633728
Batch 13/64 loss: 0.29101383686065674
Batch 14/64 loss: 0.2954326868057251
Batch 15/64 loss: 0.28837186098098755
Batch 16/64 loss: 0.2888549566268921
Batch 17/64 loss: 0.29394257068634033
Batch 18/64 loss: 0.28378164768218994
Batch 19/64 loss: 0.27968084812164307
Batch 20/64 loss: 0.2816331386566162
Batch 21/64 loss: 0.28410428762435913
Batch 22/64 loss: 0.29788362979888916
Batch 23/64 loss: 0.2907443046569824
Batch 24/64 loss: 0.29600489139556885
Batch 25/64 loss: 0.28890711069107056
Batch 26/64 loss: 0.2942394018173218
Batch 27/64 loss: 0.2854480743408203
Batch 28/64 loss: 0.28505802154541016
Batch 29/64 loss: 0.29830628633499146
Batch 30/64 loss: 0.28886228799819946
Batch 31/64 loss: 0.2835903763771057
Batch 32/64 loss: 0.30110496282577515
Batch 33/64 loss: 0.2937537431716919
Batch 34/64 loss: 0.29665470123291016
Batch 35/64 loss: 0.2990090847015381
Batch 36/64 loss: 0.2914130687713623
Batch 37/64 loss: 0.29579758644104004
Batch 38/64 loss: 0.2871314287185669
Batch 39/64 loss: 0.2945300340652466
Batch 40/64 loss: 0.28943848609924316
Batch 41/64 loss: 0.28341180086135864
Batch 42/64 loss: 0.30068695545196533
Batch 43/64 loss: 0.2881014347076416
Batch 44/64 loss: 0.29073429107666016
Batch 45/64 loss: 0.2974891662597656
Batch 46/64 loss: 0.28380298614501953
Batch 47/64 loss: 0.2960158586502075
Batch 48/64 loss: 0.2998009920120239
Batch 49/64 loss: 0.3010406494140625
Batch 50/64 loss: 0.2954229712486267
Batch 51/64 loss: 0.30215781927108765
Batch 52/64 loss: 0.29053741693496704
Batch 53/64 loss: 0.29426413774490356
Batch 54/64 loss: 0.2966156005859375
Batch 55/64 loss: 0.2938234806060791
Batch 56/64 loss: 0.2962077856063843
Batch 57/64 loss: 0.29943329095840454
Batch 58/64 loss: 0.293712317943573
Batch 59/64 loss: 0.2864025831222534
Batch 60/64 loss: 0.2871053218841553
Batch 61/64 loss: 0.2951263189315796
Batch 62/64 loss: 0.29884815216064453
Batch 63/64 loss: 0.29306459426879883
Batch 64/64 loss: 0.2958728075027466
Epoch 406  Train loss: 0.29211699495128557  Val loss: 0.32483040467160673
Epoch 407
-------------------------------
Batch 1/64 loss: 0.2866004705429077
Batch 2/64 loss: 0.29566383361816406
Batch 3/64 loss: 0.2928314805030823
Batch 4/64 loss: 0.2882801294326782
Batch 5/64 loss: 0.29577648639678955
Batch 6/64 loss: 0.28601980209350586
Batch 7/64 loss: 0.2878556251525879
Batch 8/64 loss: 0.2950265407562256
Batch 9/64 loss: 0.28640979528427124
Batch 10/64 loss: 0.29365336894989014
Batch 11/64 loss: 0.27958887815475464
Batch 12/64 loss: 0.29143834114074707
Batch 13/64 loss: 0.2942385673522949
Batch 14/64 loss: 0.2902181148529053
Batch 15/64 loss: 0.29052793979644775
Batch 16/64 loss: 0.2872610092163086
Batch 17/64 loss: 0.2934427261352539
Batch 18/64 loss: 0.2917943000793457
Batch 19/64 loss: 0.29913026094436646
Batch 20/64 loss: 0.29828429222106934
Batch 21/64 loss: 0.30029094219207764
Batch 22/64 loss: 0.29054319858551025
Batch 23/64 loss: 0.2908744215965271
Batch 24/64 loss: 0.2861444354057312
Batch 25/64 loss: 0.2897278070449829
Batch 26/64 loss: 0.3003235459327698
Batch 27/64 loss: 0.28837358951568604
Batch 28/64 loss: 0.2889215350151062
Batch 29/64 loss: 0.29626524448394775
Batch 30/64 loss: 0.29262804985046387
Batch 31/64 loss: 0.2893211841583252
Batch 32/64 loss: 0.2846750020980835
Batch 33/64 loss: 0.2854270935058594
Batch 34/64 loss: 0.2895185947418213
Batch 35/64 loss: 0.2807251811027527
Batch 36/64 loss: 0.293212354183197
Batch 37/64 loss: 0.28973978757858276
Batch 38/64 loss: 0.29039567708969116
Batch 39/64 loss: 0.28562259674072266
Batch 40/64 loss: 0.30261921882629395
Batch 41/64 loss: 0.29668426513671875
Batch 42/64 loss: 0.2909732460975647
Batch 43/64 loss: 0.29408419132232666
Batch 44/64 loss: 0.2947646379470825
Batch 45/64 loss: 0.2892770767211914
Batch 46/64 loss: 0.29494667053222656
Batch 47/64 loss: 0.2930980920791626
Batch 48/64 loss: 0.294136106967926
Batch 49/64 loss: 0.29492664337158203
Batch 50/64 loss: 0.2892630696296692
Batch 51/64 loss: 0.3040946125984192
Batch 52/64 loss: 0.29282331466674805
Batch 53/64 loss: 0.2897247076034546
Batch 54/64 loss: 0.2850898504257202
Batch 55/64 loss: 0.29997313022613525
Batch 56/64 loss: 0.31108391284942627
Batch 57/64 loss: 0.28987449407577515
Batch 58/64 loss: 0.2872552275657654
Batch 59/64 loss: 0.28176069259643555
Batch 60/64 loss: 0.30095720291137695
Batch 61/64 loss: 0.2901315689086914
Batch 62/64 loss: 0.28271758556365967
Batch 63/64 loss: 0.29283589124679565
Batch 64/64 loss: 0.2984159588813782
Epoch 407  Train loss: 0.2918224248231626  Val loss: 0.3239625778394876
Epoch 408
-------------------------------
Batch 1/64 loss: 0.2887457609176636
Batch 2/64 loss: 0.2830525040626526
Batch 3/64 loss: 0.29915666580200195
Batch 4/64 loss: 0.28711867332458496
Batch 5/64 loss: 0.2878161668777466
Batch 6/64 loss: 0.29739516973495483
Batch 7/64 loss: 0.29719215631484985
Batch 8/64 loss: 0.2918693423271179
Batch 9/64 loss: 0.29046177864074707
Batch 10/64 loss: 0.29652243852615356
Batch 11/64 loss: 0.2885921597480774
Batch 12/64 loss: 0.29545414447784424
Batch 13/64 loss: 0.29318559169769287
Batch 14/64 loss: 0.2951980233192444
Batch 15/64 loss: 0.2972748279571533
Batch 16/64 loss: 0.28986847400665283
Batch 17/64 loss: 0.2955901622772217
Batch 18/64 loss: 0.28787821531295776
Batch 19/64 loss: 0.2816711664199829
Batch 20/64 loss: 0.2926926612854004
Batch 21/64 loss: 0.29840171337127686
Batch 22/64 loss: 0.29284369945526123
Batch 23/64 loss: 0.29807770252227783
Batch 24/64 loss: 0.28896981477737427
Batch 25/64 loss: 0.3016611337661743
Batch 26/64 loss: 0.30319690704345703
Batch 27/64 loss: 0.285297155380249
Batch 28/64 loss: 0.2869337797164917
Batch 29/64 loss: 0.28494977951049805
Batch 30/64 loss: 0.2951400876045227
Batch 31/64 loss: 0.2852690815925598
Batch 32/64 loss: 0.28104424476623535
Batch 33/64 loss: 0.2859882712364197
Batch 34/64 loss: 0.27649080753326416
Batch 35/64 loss: 0.2860156297683716
Batch 36/64 loss: 0.29375511407852173
Batch 37/64 loss: 0.29279404878616333
Batch 38/64 loss: 0.29317140579223633
Batch 39/64 loss: 0.28742843866348267
Batch 40/64 loss: 0.296377956867218
Batch 41/64 loss: 0.29946303367614746
Batch 42/64 loss: 0.2954256534576416
Batch 43/64 loss: 0.2967721223831177
Batch 44/64 loss: 0.2938256859779358
Batch 45/64 loss: 0.29198968410491943
Batch 46/64 loss: 0.29320430755615234
Batch 47/64 loss: 0.2990655303001404
Batch 48/64 loss: 0.2854217290878296
Batch 49/64 loss: 0.2945653200149536
Batch 50/64 loss: 0.2913331985473633
Batch 51/64 loss: 0.28944045305252075
Batch 52/64 loss: 0.28744369745254517
Batch 53/64 loss: 0.2970508337020874
Batch 54/64 loss: 0.2859083414077759
Batch 55/64 loss: 0.282039999961853
Batch 56/64 loss: 0.3019951581954956
Batch 57/64 loss: 0.28962594270706177
Batch 58/64 loss: 0.2875184416770935
Batch 59/64 loss: 0.28756946325302124
Batch 60/64 loss: 0.29043495655059814
Batch 61/64 loss: 0.2935992479324341
Batch 62/64 loss: 0.29239630699157715
Batch 63/64 loss: 0.30323851108551025
Batch 64/64 loss: 0.2902180552482605
Epoch 408  Train loss: 0.29172602377685847  Val loss: 0.32396796929467586
Epoch 409
-------------------------------
Batch 1/64 loss: 0.2847866415977478
Batch 2/64 loss: 0.2785269021987915
Batch 3/64 loss: 0.28563565015792847
Batch 4/64 loss: 0.291126012802124
Batch 5/64 loss: 0.29250556230545044
Batch 6/64 loss: 0.2906942367553711
Batch 7/64 loss: 0.28682541847229004
Batch 8/64 loss: 0.2821378707885742
Batch 9/64 loss: 0.2881668210029602
Batch 10/64 loss: 0.29625535011291504
Batch 11/64 loss: 0.29541170597076416
Batch 12/64 loss: 0.2826843857765198
Batch 13/64 loss: 0.2945714592933655
Batch 14/64 loss: 0.2897552251815796
Batch 15/64 loss: 0.2921125888824463
Batch 16/64 loss: 0.2983393669128418
Batch 17/64 loss: 0.29428064823150635
Batch 18/64 loss: 0.29112982749938965
Batch 19/64 loss: 0.28926706314086914
Batch 20/64 loss: 0.2925763726234436
Batch 21/64 loss: 0.2970484495162964
Batch 22/64 loss: 0.29364728927612305
Batch 23/64 loss: 0.29372769594192505
Batch 24/64 loss: 0.2958586812019348
Batch 25/64 loss: 0.2923012971878052
Batch 26/64 loss: 0.2924574613571167
Batch 27/64 loss: 0.29013848304748535
Batch 28/64 loss: 0.298234224319458
Batch 29/64 loss: 0.2885749936103821
Batch 30/64 loss: 0.2833364009857178
Batch 31/64 loss: 0.2883538007736206
Batch 32/64 loss: 0.2909262180328369
Batch 33/64 loss: 0.2868386507034302
Batch 34/64 loss: 0.28390002250671387
Batch 35/64 loss: 0.28958606719970703
Batch 36/64 loss: 0.2956961393356323
Batch 37/64 loss: 0.2948954701423645
Batch 38/64 loss: 0.30107545852661133
Batch 39/64 loss: 0.29744553565979004
Batch 40/64 loss: 0.30478084087371826
Batch 41/64 loss: 0.2909470796585083
Batch 42/64 loss: 0.2972605228424072
Batch 43/64 loss: 0.2831902503967285
Batch 44/64 loss: 0.30931663513183594
Batch 45/64 loss: 0.28601932525634766
Batch 46/64 loss: 0.28075307607650757
Batch 47/64 loss: 0.2878713011741638
Batch 48/64 loss: 0.2872074842453003
Batch 49/64 loss: 0.2899063229560852
Batch 50/64 loss: 0.2866747975349426
Batch 51/64 loss: 0.2766724228858948
Batch 52/64 loss: 0.28680849075317383
Batch 53/64 loss: 0.2918732762336731
Batch 54/64 loss: 0.2955952286720276
Batch 55/64 loss: 0.2989615797996521
Batch 56/64 loss: 0.29877758026123047
Batch 57/64 loss: 0.30157411098480225
Batch 58/64 loss: 0.30224817991256714
Batch 59/64 loss: 0.2915447950363159
Batch 60/64 loss: 0.2923509478569031
Batch 61/64 loss: 0.29130154848098755
Batch 62/64 loss: 0.2911466956138611
Batch 63/64 loss: 0.296930193901062
Batch 64/64 loss: 0.2892404794692993
Epoch 409  Train loss: 0.2915682273752549  Val loss: 0.32617227748497246
Epoch 410
-------------------------------
Batch 1/64 loss: 0.30123889446258545
Batch 2/64 loss: 0.293154239654541
Batch 3/64 loss: 0.2917184829711914
Batch 4/64 loss: 0.2980659008026123
Batch 5/64 loss: 0.29407602548599243
Batch 6/64 loss: 0.286812424659729
Batch 7/64 loss: 0.2900487184524536
Batch 8/64 loss: 0.29440927505493164
Batch 9/64 loss: 0.287730872631073
Batch 10/64 loss: 0.3040659427642822
Batch 11/64 loss: 0.29046767950057983
Batch 12/64 loss: 0.2988715171813965
Batch 13/64 loss: 0.2998688817024231
Batch 14/64 loss: 0.2955608367919922
Batch 15/64 loss: 0.2871546149253845
Batch 16/64 loss: 0.2872490882873535
Batch 17/64 loss: 0.29028719663619995
Batch 18/64 loss: 0.2894928455352783
Batch 19/64 loss: 0.2863268256187439
Batch 20/64 loss: 0.30643177032470703
Batch 21/64 loss: 0.29052066802978516
Batch 22/64 loss: 0.29215502738952637
Batch 23/64 loss: 0.2931075692176819
Batch 24/64 loss: 0.2939295768737793
Batch 25/64 loss: 0.29529571533203125
Batch 26/64 loss: 0.2875187397003174
Batch 27/64 loss: 0.29459112882614136
Batch 28/64 loss: 0.28985220193862915
Batch 29/64 loss: 0.2894684076309204
Batch 30/64 loss: 0.2865828275680542
Batch 31/64 loss: 0.29781484603881836
Batch 32/64 loss: 0.28720569610595703
Batch 33/64 loss: 0.2870500087738037
Batch 34/64 loss: 0.2832533121109009
Batch 35/64 loss: 0.285194456577301
Batch 36/64 loss: 0.2840706706047058
Batch 37/64 loss: 0.2924081087112427
Batch 38/64 loss: 0.2901865243911743
Batch 39/64 loss: 0.28525495529174805
Batch 40/64 loss: 0.2834252715110779
Batch 41/64 loss: 0.29089999198913574
Batch 42/64 loss: 0.2895195484161377
Batch 43/64 loss: 0.2866291403770447
Batch 44/64 loss: 0.2924962639808655
Batch 45/64 loss: 0.29948824644088745
Batch 46/64 loss: 0.28792256116867065
Batch 47/64 loss: 0.28868794441223145
Batch 48/64 loss: 0.30267536640167236
Batch 49/64 loss: 0.28891974687576294
Batch 50/64 loss: 0.30411601066589355
Batch 51/64 loss: 0.2914609909057617
Batch 52/64 loss: 0.28874093294143677
Batch 53/64 loss: 0.28764331340789795
Batch 54/64 loss: 0.2960613965988159
Batch 55/64 loss: 0.29040777683258057
Batch 56/64 loss: 0.2927215099334717
Batch 57/64 loss: 0.29797619581222534
Batch 58/64 loss: 0.29534149169921875
Batch 59/64 loss: 0.28266775608062744
Batch 60/64 loss: 0.2953445315361023
Batch 61/64 loss: 0.2876150608062744
Batch 62/64 loss: 0.2875375747680664
Batch 63/64 loss: 0.29509079456329346
Batch 64/64 loss: 0.2909512519836426
Epoch 410  Train loss: 0.29176620128108005  Val loss: 0.3236441028486822
Epoch 411
-------------------------------
Batch 1/64 loss: 0.2972276210784912
Batch 2/64 loss: 0.2873770594596863
Batch 3/64 loss: 0.28457319736480713
Batch 4/64 loss: 0.29460573196411133
Batch 5/64 loss: 0.30041539669036865
Batch 6/64 loss: 0.28708934783935547
Batch 7/64 loss: 0.2941522002220154
Batch 8/64 loss: 0.2885575294494629
Batch 9/64 loss: 0.296436071395874
Batch 10/64 loss: 0.29045599699020386
Batch 11/64 loss: 0.2842186689376831
Batch 12/64 loss: 0.28719282150268555
Batch 13/64 loss: 0.2988414764404297
Batch 14/64 loss: 0.2938961386680603
Batch 15/64 loss: 0.3025720715522766
Batch 16/64 loss: 0.2905845642089844
Batch 17/64 loss: 0.29077768325805664
Batch 18/64 loss: 0.28585928678512573
Batch 19/64 loss: 0.29736071825027466
Batch 20/64 loss: 0.2993367910385132
Batch 21/64 loss: 0.2935894727706909
Batch 22/64 loss: 0.29641711711883545
Batch 23/64 loss: 0.28830230236053467
Batch 24/64 loss: 0.2892571687698364
Batch 25/64 loss: 0.30338478088378906
Batch 26/64 loss: 0.292646586894989
Batch 27/64 loss: 0.28617966175079346
Batch 28/64 loss: 0.2930476665496826
Batch 29/64 loss: 0.28342926502227783
Batch 30/64 loss: 0.28550779819488525
Batch 31/64 loss: 0.2969017028808594
Batch 32/64 loss: 0.2830207347869873
Batch 33/64 loss: 0.297135591506958
Batch 34/64 loss: 0.286118745803833
Batch 35/64 loss: 0.2920401096343994
Batch 36/64 loss: 0.28569912910461426
Batch 37/64 loss: 0.29139918088912964
Batch 38/64 loss: 0.28849852085113525
Batch 39/64 loss: 0.28876960277557373
Batch 40/64 loss: 0.2905200123786926
Batch 41/64 loss: 0.2950945496559143
Batch 42/64 loss: 0.29317915439605713
Batch 43/64 loss: 0.29654836654663086
Batch 44/64 loss: 0.29935985803604126
Batch 45/64 loss: 0.2934330701828003
Batch 46/64 loss: 0.2925581932067871
Batch 47/64 loss: 0.2898450493812561
Batch 48/64 loss: 0.28555911779403687
Batch 49/64 loss: 0.29856133460998535
Batch 50/64 loss: 0.2879009246826172
Batch 51/64 loss: 0.2954692840576172
Batch 52/64 loss: 0.29260003566741943
Batch 53/64 loss: 0.2926098108291626
Batch 54/64 loss: 0.2860363721847534
Batch 55/64 loss: 0.2903546094894409
Batch 56/64 loss: 0.286415696144104
Batch 57/64 loss: 0.2868267297744751
Batch 58/64 loss: 0.29396581649780273
Batch 59/64 loss: 0.2863682508468628
Batch 60/64 loss: 0.2964748740196228
Batch 61/64 loss: 0.2872276306152344
Batch 62/64 loss: 0.28500163555145264
Batch 63/64 loss: 0.29331517219543457
Batch 64/64 loss: 0.29350292682647705
Epoch 411  Train loss: 0.2915800510668287  Val loss: 0.32346614939240653
Saving best model, epoch: 411
Epoch 412
-------------------------------
Batch 1/64 loss: 0.29759931564331055
Batch 2/64 loss: 0.2926235795021057
Batch 3/64 loss: 0.29307496547698975
Batch 4/64 loss: 0.28508102893829346
Batch 5/64 loss: 0.2879762649536133
Batch 6/64 loss: 0.2906321883201599
Batch 7/64 loss: 0.2919282913208008
Batch 8/64 loss: 0.2978290319442749
Batch 9/64 loss: 0.2989853620529175
Batch 10/64 loss: 0.29501140117645264
Batch 11/64 loss: 0.2940162420272827
Batch 12/64 loss: 0.2963458299636841
Batch 13/64 loss: 0.2824863791465759
Batch 14/64 loss: 0.2927916646003723
Batch 15/64 loss: 0.2906784415245056
Batch 16/64 loss: 0.29863035678863525
Batch 17/64 loss: 0.2812926173210144
Batch 18/64 loss: 0.28520721197128296
Batch 19/64 loss: 0.2912611961364746
Batch 20/64 loss: 0.2904900908470154
Batch 21/64 loss: 0.287578821182251
Batch 22/64 loss: 0.2900024652481079
Batch 23/64 loss: 0.2873342037200928
Batch 24/64 loss: 0.29058361053466797
Batch 25/64 loss: 0.2906830906867981
Batch 26/64 loss: 0.2934379577636719
Batch 27/64 loss: 0.2964886426925659
Batch 28/64 loss: 0.2918340563774109
Batch 29/64 loss: 0.295915424823761
Batch 30/64 loss: 0.28770506381988525
Batch 31/64 loss: 0.28750884532928467
Batch 32/64 loss: 0.2916412949562073
Batch 33/64 loss: 0.29021191596984863
Batch 34/64 loss: 0.2835601568222046
Batch 35/64 loss: 0.2863350510597229
Batch 36/64 loss: 0.2901986241340637
Batch 37/64 loss: 0.29692506790161133
Batch 38/64 loss: 0.2904685139656067
Batch 39/64 loss: 0.28806865215301514
Batch 40/64 loss: 0.2945544719696045
Batch 41/64 loss: 0.2924576997756958
Batch 42/64 loss: 0.2928982973098755
Batch 43/64 loss: 0.29303228855133057
Batch 44/64 loss: 0.2883657217025757
Batch 45/64 loss: 0.2866678237915039
Batch 46/64 loss: 0.29159247875213623
Batch 47/64 loss: 0.29169976711273193
Batch 48/64 loss: 0.29377061128616333
Batch 49/64 loss: 0.29595518112182617
Batch 50/64 loss: 0.29560112953186035
Batch 51/64 loss: 0.2929604649543762
Batch 52/64 loss: 0.28891193866729736
Batch 53/64 loss: 0.28911292552948
Batch 54/64 loss: 0.2917366027832031
Batch 55/64 loss: 0.28464746475219727
Batch 56/64 loss: 0.2820848226547241
Batch 57/64 loss: 0.2884436845779419
Batch 58/64 loss: 0.29463040828704834
Batch 59/64 loss: 0.28363239765167236
Batch 60/64 loss: 0.2933371067047119
Batch 61/64 loss: 0.2876204252243042
Batch 62/64 loss: 0.2910587787628174
Batch 63/64 loss: 0.2929893732070923
Batch 64/64 loss: 0.28742748498916626
Epoch 412  Train loss: 0.2908824376031464  Val loss: 0.32490214756673963
Epoch 413
-------------------------------
Batch 1/64 loss: 0.29234033823013306
Batch 2/64 loss: 0.29378169775009155
Batch 3/64 loss: 0.29448020458221436
Batch 4/64 loss: 0.2788100242614746
Batch 5/64 loss: 0.2786543369293213
Batch 6/64 loss: 0.2861030697822571
Batch 7/64 loss: 0.2867908477783203
Batch 8/64 loss: 0.30911165475845337
Batch 9/64 loss: 0.29350966215133667
Batch 10/64 loss: 0.28627872467041016
Batch 11/64 loss: 0.2892277240753174
Batch 12/64 loss: 0.29229623079299927
Batch 13/64 loss: 0.29349231719970703
Batch 14/64 loss: 0.301303505897522
Batch 15/64 loss: 0.29239797592163086
Batch 16/64 loss: 0.28207457065582275
Batch 17/64 loss: 0.2900022268295288
Batch 18/64 loss: 0.2883189916610718
Batch 19/64 loss: 0.2969856262207031
Batch 20/64 loss: 0.29549849033355713
Batch 21/64 loss: 0.28366005420684814
Batch 22/64 loss: 0.2888878583908081
Batch 23/64 loss: 0.29848551750183105
Batch 24/64 loss: 0.2906590700149536
Batch 25/64 loss: 0.28712618350982666
Batch 26/64 loss: 0.2896420955657959
Batch 27/64 loss: 0.29289543628692627
Batch 28/64 loss: 0.2909473776817322
Batch 29/64 loss: 0.2988412380218506
Batch 30/64 loss: 0.2899119257926941
Batch 31/64 loss: 0.2973548173904419
Batch 32/64 loss: 0.29821640253067017
Batch 33/64 loss: 0.29095399379730225
Batch 34/64 loss: 0.29170656204223633
Batch 35/64 loss: 0.3029930591583252
Batch 36/64 loss: 0.29763323068618774
Batch 37/64 loss: 0.2882283926010132
Batch 38/64 loss: 0.29161298274993896
Batch 39/64 loss: 0.2967330813407898
Batch 40/64 loss: 0.2875273823738098
Batch 41/64 loss: 0.28889989852905273
Batch 42/64 loss: 0.28728556632995605
Batch 43/64 loss: 0.28231245279312134
Batch 44/64 loss: 0.29033440351486206
Batch 45/64 loss: 0.29597944021224976
Batch 46/64 loss: 0.2977985739707947
Batch 47/64 loss: 0.2866920232772827
Batch 48/64 loss: 0.2884739637374878
Batch 49/64 loss: 0.2835087776184082
Batch 50/64 loss: 0.2814605236053467
Batch 51/64 loss: 0.29599428176879883
Batch 52/64 loss: 0.28657251596450806
Batch 53/64 loss: 0.29884397983551025
Batch 54/64 loss: 0.2913234233856201
Batch 55/64 loss: 0.2895525097846985
Batch 56/64 loss: 0.2953963875770569
Batch 57/64 loss: 0.2879951000213623
Batch 58/64 loss: 0.28290581703186035
Batch 59/64 loss: 0.2922174334526062
Batch 60/64 loss: 0.29351675510406494
Batch 61/64 loss: 0.28092414140701294
Batch 62/64 loss: 0.2904183268547058
Batch 63/64 loss: 0.29569506645202637
Batch 64/64 loss: 0.2888868451118469
Epoch 413  Train loss: 0.2910782961284413  Val loss: 0.32487689342695414
Epoch 414
-------------------------------
Batch 1/64 loss: 0.2895890474319458
Batch 2/64 loss: 0.29141032695770264
Batch 3/64 loss: 0.2934856414794922
Batch 4/64 loss: 0.28568047285079956
Batch 5/64 loss: 0.2868225574493408
Batch 6/64 loss: 0.2956134080886841
Batch 7/64 loss: 0.29160821437835693
Batch 8/64 loss: 0.2883545160293579
Batch 9/64 loss: 0.2963113784790039
Batch 10/64 loss: 0.2860381007194519
Batch 11/64 loss: 0.2935934066772461
Batch 12/64 loss: 0.29027730226516724
Batch 13/64 loss: 0.30092930793762207
Batch 14/64 loss: 0.288594126701355
Batch 15/64 loss: 0.28002995252609253
Batch 16/64 loss: 0.29418909549713135
Batch 17/64 loss: 0.2835357189178467
Batch 18/64 loss: 0.29113948345184326
Batch 19/64 loss: 0.29261666536331177
Batch 20/64 loss: 0.28928375244140625
Batch 21/64 loss: 0.28948187828063965
Batch 22/64 loss: 0.28470343351364136
Batch 23/64 loss: 0.28837043046951294
Batch 24/64 loss: 0.2904031276702881
Batch 25/64 loss: 0.28930002450942993
Batch 26/64 loss: 0.28809428215026855
Batch 27/64 loss: 0.29882359504699707
Batch 28/64 loss: 0.29592061042785645
Batch 29/64 loss: 0.30162501335144043
Batch 30/64 loss: 0.2932777404785156
Batch 31/64 loss: 0.2931109666824341
Batch 32/64 loss: 0.2970386743545532
Batch 33/64 loss: 0.29626917839050293
Batch 34/64 loss: 0.28972452878952026
Batch 35/64 loss: 0.28741854429244995
Batch 36/64 loss: 0.29256880283355713
Batch 37/64 loss: 0.2843310832977295
Batch 38/64 loss: 0.286862313747406
Batch 39/64 loss: 0.2951960563659668
Batch 40/64 loss: 0.28985774517059326
Batch 41/64 loss: 0.29489266872406006
Batch 42/64 loss: 0.28834307193756104
Batch 43/64 loss: 0.28461122512817383
Batch 44/64 loss: 0.2988055944442749
Batch 45/64 loss: 0.29764413833618164
Batch 46/64 loss: 0.29724615812301636
Batch 47/64 loss: 0.2931370735168457
Batch 48/64 loss: 0.28912490606307983
Batch 49/64 loss: 0.2894737720489502
Batch 50/64 loss: 0.28634727001190186
Batch 51/64 loss: 0.28939592838287354
Batch 52/64 loss: 0.28715527057647705
Batch 53/64 loss: 0.30489403009414673
Batch 54/64 loss: 0.2893918752670288
Batch 55/64 loss: 0.2850383520126343
Batch 56/64 loss: 0.2899390459060669
Batch 57/64 loss: 0.2879679203033447
Batch 58/64 loss: 0.2885318398475647
Batch 59/64 loss: 0.2894202470779419
Batch 60/64 loss: 0.2928924560546875
Batch 61/64 loss: 0.2945023775100708
Batch 62/64 loss: 0.2870282530784607
Batch 63/64 loss: 0.2974642515182495
Batch 64/64 loss: 0.301819384098053
Epoch 414  Train loss: 0.29131125912946815  Val loss: 0.3251281231129702
Epoch 415
-------------------------------
Batch 1/64 loss: 0.28719234466552734
Batch 2/64 loss: 0.28049761056900024
Batch 3/64 loss: 0.29221850633621216
Batch 4/64 loss: 0.29712408781051636
Batch 5/64 loss: 0.2915496826171875
Batch 6/64 loss: 0.29302358627319336
Batch 7/64 loss: 0.2866790294647217
Batch 8/64 loss: 0.2940460443496704
Batch 9/64 loss: 0.2884872555732727
Batch 10/64 loss: 0.29230040311813354
Batch 11/64 loss: 0.2932468056678772
Batch 12/64 loss: 0.2930324673652649
Batch 13/64 loss: 0.29267746210098267
Batch 14/64 loss: 0.2911805510520935
Batch 15/64 loss: 0.3024740219116211
Batch 16/64 loss: 0.2869097590446472
Batch 17/64 loss: 0.2863973379135132
Batch 18/64 loss: 0.2811165452003479
Batch 19/64 loss: 0.28883296251296997
Batch 20/64 loss: 0.2797905206680298
Batch 21/64 loss: 0.2759658098220825
Batch 22/64 loss: 0.28178274631500244
Batch 23/64 loss: 0.29594433307647705
Batch 24/64 loss: 0.29548388719558716
Batch 25/64 loss: 0.2969893217086792
Batch 26/64 loss: 0.29125821590423584
Batch 27/64 loss: 0.3008638620376587
Batch 28/64 loss: 0.2964039444923401
Batch 29/64 loss: 0.2818950414657593
Batch 30/64 loss: 0.28307467699050903
Batch 31/64 loss: 0.2960212826728821
Batch 32/64 loss: 0.29294395446777344
Batch 33/64 loss: 0.29400599002838135
Batch 34/64 loss: 0.2957456111907959
Batch 35/64 loss: 0.2846946716308594
Batch 36/64 loss: 0.29595279693603516
Batch 37/64 loss: 0.29006075859069824
Batch 38/64 loss: 0.3011048436164856
Batch 39/64 loss: 0.28629326820373535
Batch 40/64 loss: 0.29493582248687744
Batch 41/64 loss: 0.28612375259399414
Batch 42/64 loss: 0.29724597930908203
Batch 43/64 loss: 0.2871595621109009
Batch 44/64 loss: 0.28294670581817627
Batch 45/64 loss: 0.3020733594894409
Batch 46/64 loss: 0.3008749485015869
Batch 47/64 loss: 0.2892172336578369
Batch 48/64 loss: 0.2984205484390259
Batch 49/64 loss: 0.28720808029174805
Batch 50/64 loss: 0.29053056240081787
Batch 51/64 loss: 0.28110837936401367
Batch 52/64 loss: 0.30004698038101196
Batch 53/64 loss: 0.29599231481552124
Batch 54/64 loss: 0.2909151315689087
Batch 55/64 loss: 0.29045790433883667
Batch 56/64 loss: 0.2932261824607849
Batch 57/64 loss: 0.3052161931991577
Batch 58/64 loss: 0.2965073585510254
Batch 59/64 loss: 0.29812145233154297
Batch 60/64 loss: 0.29614508152008057
Batch 61/64 loss: 0.28936487436294556
Batch 62/64 loss: 0.2875339984893799
Batch 63/64 loss: 0.27433621883392334
Batch 64/64 loss: 0.2886464595794678
Epoch 415  Train loss: 0.2912542034597958  Val loss: 0.3227599676941678
Saving best model, epoch: 415
Epoch 416
-------------------------------
Batch 1/64 loss: 0.2912061810493469
Batch 2/64 loss: 0.3006941080093384
Batch 3/64 loss: 0.2908821105957031
Batch 4/64 loss: 0.2931218147277832
Batch 5/64 loss: 0.2878812551498413
Batch 6/64 loss: 0.2950271964073181
Batch 7/64 loss: 0.2898728847503662
Batch 8/64 loss: 0.29124927520751953
Batch 9/64 loss: 0.28926849365234375
Batch 10/64 loss: 0.28850966691970825
Batch 11/64 loss: 0.29326701164245605
Batch 12/64 loss: 0.28666985034942627
Batch 13/64 loss: 0.2867952585220337
Batch 14/64 loss: 0.2927628755569458
Batch 15/64 loss: 0.29791998863220215
Batch 16/64 loss: 0.28607654571533203
Batch 17/64 loss: 0.2912553548812866
Batch 18/64 loss: 0.2920346260070801
Batch 19/64 loss: 0.2917402982711792
Batch 20/64 loss: 0.2938920855522156
Batch 21/64 loss: 0.28999578952789307
Batch 22/64 loss: 0.27989500761032104
Batch 23/64 loss: 0.2935781478881836
Batch 24/64 loss: 0.2912755608558655
Batch 25/64 loss: 0.2873472571372986
Batch 26/64 loss: 0.2837897539138794
Batch 27/64 loss: 0.2861098051071167
Batch 28/64 loss: 0.2919180393218994
Batch 29/64 loss: 0.29723167419433594
Batch 30/64 loss: 0.2968168258666992
Batch 31/64 loss: 0.29008734226226807
Batch 32/64 loss: 0.291816771030426
Batch 33/64 loss: 0.2817460298538208
Batch 34/64 loss: 0.2965824604034424
Batch 35/64 loss: 0.28716200590133667
Batch 36/64 loss: 0.28782278299331665
Batch 37/64 loss: 0.2930574417114258
Batch 38/64 loss: 0.28764045238494873
Batch 39/64 loss: 0.28402358293533325
Batch 40/64 loss: 0.2926012873649597
Batch 41/64 loss: 0.2899177074432373
Batch 42/64 loss: 0.2906763553619385
Batch 43/64 loss: 0.28784215450286865
Batch 44/64 loss: 0.2945520877838135
Batch 45/64 loss: 0.289675235748291
Batch 46/64 loss: 0.29297691583633423
Batch 47/64 loss: 0.28635263442993164
Batch 48/64 loss: 0.3015053868293762
Batch 49/64 loss: 0.2787512540817261
Batch 50/64 loss: 0.2906343936920166
Batch 51/64 loss: 0.2921067476272583
Batch 52/64 loss: 0.2819555997848511
Batch 53/64 loss: 0.29218167066574097
Batch 54/64 loss: 0.29222941398620605
Batch 55/64 loss: 0.2995762825012207
Batch 56/64 loss: 0.303220272064209
Batch 57/64 loss: 0.29099518060684204
Batch 58/64 loss: 0.2866455316543579
Batch 59/64 loss: 0.29266631603240967
Batch 60/64 loss: 0.28709840774536133
Batch 61/64 loss: 0.28905999660491943
Batch 62/64 loss: 0.2774863839149475
Batch 63/64 loss: 0.2884247899055481
Batch 64/64 loss: 0.2940828204154968
Epoch 416  Train loss: 0.2904740036702624  Val loss: 0.3255013522413588
Epoch 417
-------------------------------
Batch 1/64 loss: 0.2892242670059204
Batch 2/64 loss: 0.28788989782333374
Batch 3/64 loss: 0.29487258195877075
Batch 4/64 loss: 0.2939993143081665
Batch 5/64 loss: 0.28361576795578003
Batch 6/64 loss: 0.2914189100265503
Batch 7/64 loss: 0.29037225246429443
Batch 8/64 loss: 0.2935909032821655
Batch 9/64 loss: 0.2903616428375244
Batch 10/64 loss: 0.2848603129386902
Batch 11/64 loss: 0.28331196308135986
Batch 12/64 loss: 0.2954482436180115
Batch 13/64 loss: 0.2807045578956604
Batch 14/64 loss: 0.28331542015075684
Batch 15/64 loss: 0.292153537273407
Batch 16/64 loss: 0.2852442264556885
Batch 17/64 loss: 0.2910038232803345
Batch 18/64 loss: 0.2843998670578003
Batch 19/64 loss: 0.2926807403564453
Batch 20/64 loss: 0.2911497950553894
Batch 21/64 loss: 0.30776888132095337
Batch 22/64 loss: 0.28655004501342773
Batch 23/64 loss: 0.28829240798950195
Batch 24/64 loss: 0.2998446226119995
Batch 25/64 loss: 0.2924102544784546
Batch 26/64 loss: 0.29263073205947876
Batch 27/64 loss: 0.2987610101699829
Batch 28/64 loss: 0.2911596894264221
Batch 29/64 loss: 0.300542414188385
Batch 30/64 loss: 0.29583442211151123
Batch 31/64 loss: 0.2922649383544922
Batch 32/64 loss: 0.29635584354400635
Batch 33/64 loss: 0.2890503406524658
Batch 34/64 loss: 0.28785455226898193
Batch 35/64 loss: 0.3045034408569336
Batch 36/64 loss: 0.2999904155731201
Batch 37/64 loss: 0.28773659467697144
Batch 38/64 loss: 0.29282259941101074
Batch 39/64 loss: 0.2914658784866333
Batch 40/64 loss: 0.28979063034057617
Batch 41/64 loss: 0.2850220203399658
Batch 42/64 loss: 0.2886999249458313
Batch 43/64 loss: 0.28797078132629395
Batch 44/64 loss: 0.2937774658203125
Batch 45/64 loss: 0.2940806746482849
Batch 46/64 loss: 0.2914462089538574
Batch 47/64 loss: 0.28658461570739746
Batch 48/64 loss: 0.2862756848335266
Batch 49/64 loss: 0.2843663692474365
Batch 50/64 loss: 0.28905850648880005
Batch 51/64 loss: 0.2903869152069092
Batch 52/64 loss: 0.27882325649261475
Batch 53/64 loss: 0.2910829782485962
Batch 54/64 loss: 0.3015226721763611
Batch 55/64 loss: 0.29051846265792847
Batch 56/64 loss: 0.28732120990753174
Batch 57/64 loss: 0.288587749004364
Batch 58/64 loss: 0.29638075828552246
Batch 59/64 loss: 0.28892993927001953
Batch 60/64 loss: 0.2975168228149414
Batch 61/64 loss: 0.286979079246521
Batch 62/64 loss: 0.28226953744888306
Batch 63/64 loss: 0.28950393199920654
Batch 64/64 loss: 0.29345011711120605
Epoch 417  Train loss: 0.2908618179022097  Val loss: 0.32502419923998643
Epoch 418
-------------------------------
Batch 1/64 loss: 0.30589723587036133
Batch 2/64 loss: 0.29599761962890625
Batch 3/64 loss: 0.2819807529449463
Batch 4/64 loss: 0.29043006896972656
Batch 5/64 loss: 0.2952975034713745
Batch 6/64 loss: 0.2898821234703064
Batch 7/64 loss: 0.2899221181869507
Batch 8/64 loss: 0.28328847885131836
Batch 9/64 loss: 0.28830164670944214
Batch 10/64 loss: 0.2759200930595398
Batch 11/64 loss: 0.2856491804122925
Batch 12/64 loss: 0.2854698896408081
Batch 13/64 loss: 0.2862342596054077
Batch 14/64 loss: 0.2850414514541626
Batch 15/64 loss: 0.27961230278015137
Batch 16/64 loss: 0.29567646980285645
Batch 17/64 loss: 0.2951952815055847
Batch 18/64 loss: 0.292333722114563
Batch 19/64 loss: 0.29090189933776855
Batch 20/64 loss: 0.28853940963745117
Batch 21/64 loss: 0.2866489887237549
Batch 22/64 loss: 0.3001570701599121
Batch 23/64 loss: 0.29776525497436523
Batch 24/64 loss: 0.292131245136261
Batch 25/64 loss: 0.2875248193740845
Batch 26/64 loss: 0.2880842685699463
Batch 27/64 loss: 0.29369044303894043
Batch 28/64 loss: 0.2833911180496216
Batch 29/64 loss: 0.28672683238983154
Batch 30/64 loss: 0.2924453616142273
Batch 31/64 loss: 0.29396653175354004
Batch 32/64 loss: 0.28647804260253906
Batch 33/64 loss: 0.2782621383666992
Batch 34/64 loss: 0.2798736095428467
Batch 35/64 loss: 0.28628551959991455
Batch 36/64 loss: 0.29270851612091064
Batch 37/64 loss: 0.29460835456848145
Batch 38/64 loss: 0.2856062650680542
Batch 39/64 loss: 0.28656065464019775
Batch 40/64 loss: 0.3026312589645386
Batch 41/64 loss: 0.29737722873687744
Batch 42/64 loss: 0.2880505919456482
Batch 43/64 loss: 0.2892249822616577
Batch 44/64 loss: 0.28883910179138184
Batch 45/64 loss: 0.2870485782623291
Batch 46/64 loss: 0.3029508590698242
Batch 47/64 loss: 0.2952510714530945
Batch 48/64 loss: 0.30438047647476196
Batch 49/64 loss: 0.2900632619857788
Batch 50/64 loss: 0.2846790552139282
Batch 51/64 loss: 0.2990586757659912
Batch 52/64 loss: 0.29966938495635986
Batch 53/64 loss: 0.2913017272949219
Batch 54/64 loss: 0.2836606502532959
Batch 55/64 loss: 0.29059135913848877
Batch 56/64 loss: 0.28837186098098755
Batch 57/64 loss: 0.2941443920135498
Batch 58/64 loss: 0.29155558347702026
Batch 59/64 loss: 0.28338801860809326
Batch 60/64 loss: 0.29736030101776123
Batch 61/64 loss: 0.28712260723114014
Batch 62/64 loss: 0.2887464761734009
Batch 63/64 loss: 0.28055596351623535
Batch 64/64 loss: 0.29320454597473145
Epoch 418  Train loss: 0.2902025634167241  Val loss: 0.32410756808375984
Epoch 419
-------------------------------
Batch 1/64 loss: 0.28405821323394775
Batch 2/64 loss: 0.2908916473388672
Batch 3/64 loss: 0.28480905294418335
Batch 4/64 loss: 0.2810918092727661
Batch 5/64 loss: 0.28487592935562134
Batch 6/64 loss: 0.2800635099411011
Batch 7/64 loss: 0.2911297082901001
Batch 8/64 loss: 0.29631882905960083
Batch 9/64 loss: 0.2870379686355591
Batch 10/64 loss: 0.27991366386413574
Batch 11/64 loss: 0.2950637936592102
Batch 12/64 loss: 0.2897687554359436
Batch 13/64 loss: 0.2926514148712158
Batch 14/64 loss: 0.2908795475959778
Batch 15/64 loss: 0.2844732403755188
Batch 16/64 loss: 0.2907238006591797
Batch 17/64 loss: 0.30995529890060425
Batch 18/64 loss: 0.289371132850647
Batch 19/64 loss: 0.29338276386260986
Batch 20/64 loss: 0.294169545173645
Batch 21/64 loss: 0.2942006587982178
Batch 22/64 loss: 0.28362762928009033
Batch 23/64 loss: 0.29467928409576416
Batch 24/64 loss: 0.29522740840911865
Batch 25/64 loss: 0.27642393112182617
Batch 26/64 loss: 0.2875667214393616
Batch 27/64 loss: 0.2947617769241333
Batch 28/64 loss: 0.2978135347366333
Batch 29/64 loss: 0.2851661443710327
Batch 30/64 loss: 0.29231756925582886
Batch 31/64 loss: 0.2887924909591675
Batch 32/64 loss: 0.2894796133041382
Batch 33/64 loss: 0.3067777752876282
Batch 34/64 loss: 0.2871406078338623
Batch 35/64 loss: 0.28632062673568726
Batch 36/64 loss: 0.2877156734466553
Batch 37/64 loss: 0.2950376868247986
Batch 38/64 loss: 0.2770113945007324
Batch 39/64 loss: 0.2959466576576233
Batch 40/64 loss: 0.2895963788032532
Batch 41/64 loss: 0.2871361970901489
Batch 42/64 loss: 0.28972160816192627
Batch 43/64 loss: 0.28941088914871216
Batch 44/64 loss: 0.3030046224594116
Batch 45/64 loss: 0.2841159701347351
Batch 46/64 loss: 0.2964622974395752
Batch 47/64 loss: 0.2914511561393738
Batch 48/64 loss: 0.2932799458503723
Batch 49/64 loss: 0.2948547601699829
Batch 50/64 loss: 0.28958266973495483
Batch 51/64 loss: 0.2873215675354004
Batch 52/64 loss: 0.2913469672203064
Batch 53/64 loss: 0.2980901002883911
Batch 54/64 loss: 0.2948707342147827
Batch 55/64 loss: 0.29148411750793457
Batch 56/64 loss: 0.2869721055030823
Batch 57/64 loss: 0.29078882932662964
Batch 58/64 loss: 0.2941737771034241
Batch 59/64 loss: 0.2860327959060669
Batch 60/64 loss: 0.29626673460006714
Batch 61/64 loss: 0.28958040475845337
Batch 62/64 loss: 0.2978302240371704
Batch 63/64 loss: 0.2926395535469055
Batch 64/64 loss: 0.2927677631378174
Epoch 419  Train loss: 0.29070160061705347  Val loss: 0.32362715259860064
Epoch 420
-------------------------------
Batch 1/64 loss: 0.29177314043045044
Batch 2/64 loss: 0.294797420501709
Batch 3/64 loss: 0.2873108386993408
Batch 4/64 loss: 0.291357159614563
Batch 5/64 loss: 0.300994336605072
Batch 6/64 loss: 0.2993927001953125
Batch 7/64 loss: 0.2906205654144287
Batch 8/64 loss: 0.2918297052383423
Batch 9/64 loss: 0.28077495098114014
Batch 10/64 loss: 0.2856212854385376
Batch 11/64 loss: 0.28089839220046997
Batch 12/64 loss: 0.2946305274963379
Batch 13/64 loss: 0.27722668647766113
Batch 14/64 loss: 0.28527963161468506
Batch 15/64 loss: 0.30010467767715454
Batch 16/64 loss: 0.281083881855011
Batch 17/64 loss: 0.28006047010421753
Batch 18/64 loss: 0.2937401533126831
Batch 19/64 loss: 0.29455918073654175
Batch 20/64 loss: 0.29136741161346436
Batch 21/64 loss: 0.28944283723831177
Batch 22/64 loss: 0.2927740812301636
Batch 23/64 loss: 0.28488248586654663
Batch 24/64 loss: 0.28876793384552
Batch 25/64 loss: 0.2934539318084717
Batch 26/64 loss: 0.28850603103637695
Batch 27/64 loss: 0.28928864002227783
Batch 28/64 loss: 0.2774541974067688
Batch 29/64 loss: 0.28270870447158813
Batch 30/64 loss: 0.28864145278930664
Batch 31/64 loss: 0.28648310899734497
Batch 32/64 loss: 0.29247844219207764
Batch 33/64 loss: 0.291973352432251
Batch 34/64 loss: 0.29055583477020264
Batch 35/64 loss: 0.2763211727142334
Batch 36/64 loss: 0.2939339876174927
Batch 37/64 loss: 0.301668643951416
Batch 38/64 loss: 0.2935565710067749
Batch 39/64 loss: 0.29182618856430054
Batch 40/64 loss: 0.29486292600631714
Batch 41/64 loss: 0.2917787432670593
Batch 42/64 loss: 0.3054957389831543
Batch 43/64 loss: 0.2900758981704712
Batch 44/64 loss: 0.2851823568344116
Batch 45/64 loss: 0.2939976453781128
Batch 46/64 loss: 0.2895479202270508
Batch 47/64 loss: 0.2966885566711426
Batch 48/64 loss: 0.2945125102996826
Batch 49/64 loss: 0.2912706136703491
Batch 50/64 loss: 0.28772538900375366
Batch 51/64 loss: 0.28489524126052856
Batch 52/64 loss: 0.29034823179244995
Batch 53/64 loss: 0.29225796461105347
Batch 54/64 loss: 0.2896561026573181
Batch 55/64 loss: 0.2957557439804077
Batch 56/64 loss: 0.3008495569229126
Batch 57/64 loss: 0.29095458984375
Batch 58/64 loss: 0.2855570316314697
Batch 59/64 loss: 0.285456120967865
Batch 60/64 loss: 0.2910372018814087
Batch 61/64 loss: 0.2866212725639343
Batch 62/64 loss: 0.2856076955795288
Batch 63/64 loss: 0.29517048597335815
Batch 64/64 loss: 0.29303085803985596
Epoch 420  Train loss: 0.29024657875883814  Val loss: 0.32381202777226764
Epoch 421
-------------------------------
Batch 1/64 loss: 0.3005375862121582
Batch 2/64 loss: 0.2863112688064575
Batch 3/64 loss: 0.2862727642059326
Batch 4/64 loss: 0.29038500785827637
Batch 5/64 loss: 0.2926676869392395
Batch 6/64 loss: 0.2933078408241272
Batch 7/64 loss: 0.2924199104309082
Batch 8/64 loss: 0.2973420023918152
Batch 9/64 loss: 0.29519426822662354
Batch 10/64 loss: 0.29565149545669556
Batch 11/64 loss: 0.29196202754974365
Batch 12/64 loss: 0.29622548818588257
Batch 13/64 loss: 0.2920114994049072
Batch 14/64 loss: 0.28888005018234253
Batch 15/64 loss: 0.28589433431625366
Batch 16/64 loss: 0.2841392755508423
Batch 17/64 loss: 0.28385722637176514
Batch 18/64 loss: 0.2901144027709961
Batch 19/64 loss: 0.28987032175064087
Batch 20/64 loss: 0.29131293296813965
Batch 21/64 loss: 0.2875763177871704
Batch 22/64 loss: 0.2958605885505676
Batch 23/64 loss: 0.2868925929069519
Batch 24/64 loss: 0.28131937980651855
Batch 25/64 loss: 0.2918208837509155
Batch 26/64 loss: 0.2930203676223755
Batch 27/64 loss: 0.2919173240661621
Batch 28/64 loss: 0.288541316986084
Batch 29/64 loss: 0.2759319543838501
Batch 30/64 loss: 0.28480756282806396
Batch 31/64 loss: 0.28973931074142456
Batch 32/64 loss: 0.2895326018333435
Batch 33/64 loss: 0.29075413942337036
Batch 34/64 loss: 0.2827608585357666
Batch 35/64 loss: 0.28964143991470337
Batch 36/64 loss: 0.2887909412384033
Batch 37/64 loss: 0.28717684745788574
Batch 38/64 loss: 0.2970735430717468
Batch 39/64 loss: 0.2892720699310303
Batch 40/64 loss: 0.28750574588775635
Batch 41/64 loss: 0.29241108894348145
Batch 42/64 loss: 0.29259181022644043
Batch 43/64 loss: 0.2930716276168823
Batch 44/64 loss: 0.28402936458587646
Batch 45/64 loss: 0.28874391317367554
Batch 46/64 loss: 0.28860145807266235
Batch 47/64 loss: 0.2932818531990051
Batch 48/64 loss: 0.28858935832977295
Batch 49/64 loss: 0.291165292263031
Batch 50/64 loss: 0.27901244163513184
Batch 51/64 loss: 0.2952422499656677
Batch 52/64 loss: 0.2873615622520447
Batch 53/64 loss: 0.2910010814666748
Batch 54/64 loss: 0.2886865735054016
Batch 55/64 loss: 0.2979304790496826
Batch 56/64 loss: 0.2930426597595215
Batch 57/64 loss: 0.282467246055603
Batch 58/64 loss: 0.29014718532562256
Batch 59/64 loss: 0.30345582962036133
Batch 60/64 loss: 0.2947922945022583
Batch 61/64 loss: 0.2915993928909302
Batch 62/64 loss: 0.29054147005081177
Batch 63/64 loss: 0.28958505392074585
Batch 64/64 loss: 0.2915388345718384
Epoch 421  Train loss: 0.2902007621877334  Val loss: 0.32401908365721555
Epoch 422
-------------------------------
Batch 1/64 loss: 0.2857520580291748
Batch 2/64 loss: 0.28472810983657837
Batch 3/64 loss: 0.28989142179489136
Batch 4/64 loss: 0.29013121128082275
Batch 5/64 loss: 0.283699095249176
Batch 6/64 loss: 0.28837084770202637
Batch 7/64 loss: 0.28907233476638794
Batch 8/64 loss: 0.2890981435775757
Batch 9/64 loss: 0.29236888885498047
Batch 10/64 loss: 0.30188286304473877
Batch 11/64 loss: 0.27267706394195557
Batch 12/64 loss: 0.2827238440513611
Batch 13/64 loss: 0.2867100238800049
Batch 14/64 loss: 0.2875244617462158
Batch 15/64 loss: 0.2879255414009094
Batch 16/64 loss: 0.28393930196762085
Batch 17/64 loss: 0.29007792472839355
Batch 18/64 loss: 0.2907639145851135
Batch 19/64 loss: 0.2802385091781616
Batch 20/64 loss: 0.28626590967178345
Batch 21/64 loss: 0.2999742031097412
Batch 22/64 loss: 0.29039984941482544
Batch 23/64 loss: 0.28976738452911377
Batch 24/64 loss: 0.2847146987915039
Batch 25/64 loss: 0.29135000705718994
Batch 26/64 loss: 0.2993340492248535
Batch 27/64 loss: 0.2953575849533081
Batch 28/64 loss: 0.28220367431640625
Batch 29/64 loss: 0.29432153701782227
Batch 30/64 loss: 0.2869511842727661
Batch 31/64 loss: 0.2857934236526489
Batch 32/64 loss: 0.2873373031616211
Batch 33/64 loss: 0.29435741901397705
Batch 34/64 loss: 0.30376362800598145
Batch 35/64 loss: 0.30236613750457764
Batch 36/64 loss: 0.29710298776626587
Batch 37/64 loss: 0.2912614345550537
Batch 38/64 loss: 0.2802700400352478
Batch 39/64 loss: 0.28445374965667725
Batch 40/64 loss: 0.2901543974876404
Batch 41/64 loss: 0.2920156717300415
Batch 42/64 loss: 0.29172253608703613
Batch 43/64 loss: 0.2834433317184448
Batch 44/64 loss: 0.2957701086997986
Batch 45/64 loss: 0.2954830527305603
Batch 46/64 loss: 0.3010350465774536
Batch 47/64 loss: 0.3038288354873657
Batch 48/64 loss: 0.29707157611846924
Batch 49/64 loss: 0.2895272374153137
Batch 50/64 loss: 0.2873878479003906
Batch 51/64 loss: 0.290402352809906
Batch 52/64 loss: 0.2951858639717102
Batch 53/64 loss: 0.30019044876098633
Batch 54/64 loss: 0.2922865152359009
Batch 55/64 loss: 0.28244084119796753
Batch 56/64 loss: 0.2926791310310364
Batch 57/64 loss: 0.2851269841194153
Batch 58/64 loss: 0.3016514778137207
Batch 59/64 loss: 0.2902648448944092
Batch 60/64 loss: 0.29213738441467285
Batch 61/64 loss: 0.2805664539337158
Batch 62/64 loss: 0.29087507724761963
Batch 63/64 loss: 0.28880131244659424
Batch 64/64 loss: 0.2794545888900757
Epoch 422  Train loss: 0.29026762410706164  Val loss: 0.3262178869181892
Epoch 423
-------------------------------
Batch 1/64 loss: 0.29477745294570923
Batch 2/64 loss: 0.2808724641799927
Batch 3/64 loss: 0.28781235218048096
Batch 4/64 loss: 0.294950008392334
Batch 5/64 loss: 0.29241424798965454
Batch 6/64 loss: 0.2873608469963074
Batch 7/64 loss: 0.2912936210632324
Batch 8/64 loss: 0.30419492721557617
Batch 9/64 loss: 0.29017919301986694
Batch 10/64 loss: 0.28665900230407715
Batch 11/64 loss: 0.2842071056365967
Batch 12/64 loss: 0.28448957204818726
Batch 13/64 loss: 0.2931114435195923
Batch 14/64 loss: 0.29103851318359375
Batch 15/64 loss: 0.28904902935028076
Batch 16/64 loss: 0.2892414331436157
Batch 17/64 loss: 0.2896714210510254
Batch 18/64 loss: 0.2821160554885864
Batch 19/64 loss: 0.29237979650497437
Batch 20/64 loss: 0.2876291275024414
Batch 21/64 loss: 0.2855846881866455
Batch 22/64 loss: 0.2858503460884094
Batch 23/64 loss: 0.2879524230957031
Batch 24/64 loss: 0.2786979675292969
Batch 25/64 loss: 0.2901347875595093
Batch 26/64 loss: 0.290940523147583
Batch 27/64 loss: 0.2947854995727539
Batch 28/64 loss: 0.2926657199859619
Batch 29/64 loss: 0.28836333751678467
Batch 30/64 loss: 0.2947314977645874
Batch 31/64 loss: 0.2822922468185425
Batch 32/64 loss: 0.29269862174987793
Batch 33/64 loss: 0.29321038722991943
Batch 34/64 loss: 0.2966391444206238
Batch 35/64 loss: 0.2801079750061035
Batch 36/64 loss: 0.28801286220550537
Batch 37/64 loss: 0.2852526903152466
Batch 38/64 loss: 0.30108141899108887
Batch 39/64 loss: 0.28788840770721436
Batch 40/64 loss: 0.2829551696777344
Batch 41/64 loss: 0.29419076442718506
Batch 42/64 loss: 0.29372215270996094
Batch 43/64 loss: 0.28188765048980713
Batch 44/64 loss: 0.291861891746521
Batch 45/64 loss: 0.28866440057754517
Batch 46/64 loss: 0.28672993183135986
Batch 47/64 loss: 0.2915031909942627
Batch 48/64 loss: 0.2914136052131653
Batch 49/64 loss: 0.2905123233795166
Batch 50/64 loss: 0.29605764150619507
Batch 51/64 loss: 0.29606521129608154
Batch 52/64 loss: 0.2872442603111267
Batch 53/64 loss: 0.30375808477401733
Batch 54/64 loss: 0.28707200288772583
Batch 55/64 loss: 0.29970884323120117
Batch 56/64 loss: 0.2859286069869995
Batch 57/64 loss: 0.2926074266433716
Batch 58/64 loss: 0.2958698272705078
Batch 59/64 loss: 0.28972893953323364
Batch 60/64 loss: 0.2919536232948303
Batch 61/64 loss: 0.29377663135528564
Batch 62/64 loss: 0.29684942960739136
Batch 63/64 loss: 0.28521621227264404
Batch 64/64 loss: 0.2959538698196411
Epoch 423  Train loss: 0.2903150020861158  Val loss: 0.32383012177608267
Epoch 424
-------------------------------
Batch 1/64 loss: 0.28891825675964355
Batch 2/64 loss: 0.28848475217819214
Batch 3/64 loss: 0.28594040870666504
Batch 4/64 loss: 0.28335946798324585
Batch 5/64 loss: 0.2956458330154419
Batch 6/64 loss: 0.28636759519577026
Batch 7/64 loss: 0.2920268774032593
Batch 8/64 loss: 0.28751814365386963
Batch 9/64 loss: 0.29960107803344727
Batch 10/64 loss: 0.28249871730804443
Batch 11/64 loss: 0.2856757640838623
Batch 12/64 loss: 0.2894887328147888
Batch 13/64 loss: 0.28795695304870605
Batch 14/64 loss: 0.2885107398033142
Batch 15/64 loss: 0.3030785322189331
Batch 16/64 loss: 0.28625714778900146
Batch 17/64 loss: 0.28737640380859375
Batch 18/64 loss: 0.28954750299453735
Batch 19/64 loss: 0.2914689779281616
Batch 20/64 loss: 0.2908738851547241
Batch 21/64 loss: 0.29395318031311035
Batch 22/64 loss: 0.2863234281539917
Batch 23/64 loss: 0.295815646648407
Batch 24/64 loss: 0.2813628911972046
Batch 25/64 loss: 0.28508418798446655
Batch 26/64 loss: 0.2918221354484558
Batch 27/64 loss: 0.28110307455062866
Batch 28/64 loss: 0.2875478267669678
Batch 29/64 loss: 0.29352110624313354
Batch 30/64 loss: 0.29808521270751953
Batch 31/64 loss: 0.287799596786499
Batch 32/64 loss: 0.2891887426376343
Batch 33/64 loss: 0.2978876829147339
Batch 34/64 loss: 0.3019673228263855
Batch 35/64 loss: 0.2950695753097534
Batch 36/64 loss: 0.2920393943786621
Batch 37/64 loss: 0.2915796637535095
Batch 38/64 loss: 0.28755271434783936
Batch 39/64 loss: 0.29230034351348877
Batch 40/64 loss: 0.2859593629837036
Batch 41/64 loss: 0.2930198311805725
Batch 42/64 loss: 0.28596043586730957
Batch 43/64 loss: 0.2889729142189026
Batch 44/64 loss: 0.28587013483047485
Batch 45/64 loss: 0.2875940799713135
Batch 46/64 loss: 0.29471808671951294
Batch 47/64 loss: 0.2913632392883301
Batch 48/64 loss: 0.2972254753112793
Batch 49/64 loss: 0.29532694816589355
Batch 50/64 loss: 0.28339213132858276
Batch 51/64 loss: 0.2869594693183899
Batch 52/64 loss: 0.288934588432312
Batch 53/64 loss: 0.2867657542228699
Batch 54/64 loss: 0.2933223843574524
Batch 55/64 loss: 0.30697107315063477
Batch 56/64 loss: 0.2848615050315857
Batch 57/64 loss: 0.28269636631011963
Batch 58/64 loss: 0.29387569427490234
Batch 59/64 loss: 0.29037153720855713
Batch 60/64 loss: 0.28540611267089844
Batch 61/64 loss: 0.2969930171966553
Batch 62/64 loss: 0.28646039962768555
Batch 63/64 loss: 0.29238539934158325
Batch 64/64 loss: 0.2941737771034241
Epoch 424  Train loss: 0.29030016894434013  Val loss: 0.3237568242443386
Epoch 425
-------------------------------
Batch 1/64 loss: 0.27996277809143066
Batch 2/64 loss: 0.2832271456718445
Batch 3/64 loss: 0.2882176637649536
Batch 4/64 loss: 0.29927146434783936
Batch 5/64 loss: 0.2803225517272949
Batch 6/64 loss: 0.29762059450149536
Batch 7/64 loss: 0.285938024520874
Batch 8/64 loss: 0.29366958141326904
Batch 9/64 loss: 0.29438161849975586
Batch 10/64 loss: 0.29822254180908203
Batch 11/64 loss: 0.28795862197875977
Batch 12/64 loss: 0.28868263959884644
Batch 13/64 loss: 0.28371191024780273
Batch 14/64 loss: 0.2906440496444702
Batch 15/64 loss: 0.28187859058380127
Batch 16/64 loss: 0.2931920289993286
Batch 17/64 loss: 0.2849687337875366
Batch 18/64 loss: 0.28997349739074707
Batch 19/64 loss: 0.2840319871902466
Batch 20/64 loss: 0.28308022022247314
Batch 21/64 loss: 0.2954587936401367
Batch 22/64 loss: 0.2936525344848633
Batch 23/64 loss: 0.2982534170150757
Batch 24/64 loss: 0.2770808935165405
Batch 25/64 loss: 0.2904510498046875
Batch 26/64 loss: 0.286110520362854
Batch 27/64 loss: 0.29927581548690796
Batch 28/64 loss: 0.29159510135650635
Batch 29/64 loss: 0.28442829847335815
Batch 30/64 loss: 0.28711891174316406
Batch 31/64 loss: 0.28842222690582275
Batch 32/64 loss: 0.28784894943237305
Batch 33/64 loss: 0.2837567925453186
Batch 34/64 loss: 0.29002249240875244
Batch 35/64 loss: 0.2813154458999634
Batch 36/64 loss: 0.29211145639419556
Batch 37/64 loss: 0.2937285900115967
Batch 38/64 loss: 0.2996392846107483
Batch 39/64 loss: 0.29048579931259155
Batch 40/64 loss: 0.2830544710159302
Batch 41/64 loss: 0.28958660364151
Batch 42/64 loss: 0.291406512260437
Batch 43/64 loss: 0.29094183444976807
Batch 44/64 loss: 0.2935881018638611
Batch 45/64 loss: 0.2867010831832886
Batch 46/64 loss: 0.2900911569595337
Batch 47/64 loss: 0.2905823588371277
Batch 48/64 loss: 0.2906447649002075
Batch 49/64 loss: 0.2856409549713135
Batch 50/64 loss: 0.2907586097717285
Batch 51/64 loss: 0.301993727684021
Batch 52/64 loss: 0.296720027923584
Batch 53/64 loss: 0.28206729888916016
Batch 54/64 loss: 0.2981833815574646
Batch 55/64 loss: 0.3013238310813904
Batch 56/64 loss: 0.29116135835647583
Batch 57/64 loss: 0.28581559658050537
Batch 58/64 loss: 0.2826577425003052
Batch 59/64 loss: 0.2881157398223877
Batch 60/64 loss: 0.2831835150718689
Batch 61/64 loss: 0.2990220785140991
Batch 62/64 loss: 0.28757530450820923
Batch 63/64 loss: 0.2899547815322876
Batch 64/64 loss: 0.30049335956573486
Epoch 425  Train loss: 0.2898173093795776  Val loss: 0.32358463830554607
Epoch 426
-------------------------------
Batch 1/64 loss: 0.2944052219390869
Batch 2/64 loss: 0.2892732620239258
Batch 3/64 loss: 0.28361475467681885
Batch 4/64 loss: 0.2819153070449829
Batch 5/64 loss: 0.28742074966430664
Batch 6/64 loss: 0.2868109941482544
Batch 7/64 loss: 0.29194843769073486
Batch 8/64 loss: 0.28451108932495117
Batch 9/64 loss: 0.29790210723876953
Batch 10/64 loss: 0.28299272060394287
Batch 11/64 loss: 0.28885936737060547
Batch 12/64 loss: 0.28637999296188354
Batch 13/64 loss: 0.29227733612060547
Batch 14/64 loss: 0.2902355194091797
Batch 15/64 loss: 0.28857946395874023
Batch 16/64 loss: 0.2993183732032776
Batch 17/64 loss: 0.29065388441085815
Batch 18/64 loss: 0.2860304117202759
Batch 19/64 loss: 0.28949469327926636
Batch 20/64 loss: 0.27863872051239014
Batch 21/64 loss: 0.2807137966156006
Batch 22/64 loss: 0.29452216625213623
Batch 23/64 loss: 0.2888709306716919
Batch 24/64 loss: 0.2927786111831665
Batch 25/64 loss: 0.28724658489227295
Batch 26/64 loss: 0.2855064868927002
Batch 27/64 loss: 0.29006826877593994
Batch 28/64 loss: 0.299197256565094
Batch 29/64 loss: 0.31723451614379883
Batch 30/64 loss: 0.2965853214263916
Batch 31/64 loss: 0.2866678833961487
Batch 32/64 loss: 0.2837282419204712
Batch 33/64 loss: 0.2853458523750305
Batch 34/64 loss: 0.28710126876831055
Batch 35/64 loss: 0.2874773144721985
Batch 36/64 loss: 0.29154837131500244
Batch 37/64 loss: 0.28995054960250854
Batch 38/64 loss: 0.2793653607368469
Batch 39/64 loss: 0.2834181785583496
Batch 40/64 loss: 0.2863585948944092
Batch 41/64 loss: 0.2901058793067932
Batch 42/64 loss: 0.2838526964187622
Batch 43/64 loss: 0.2903491258621216
Batch 44/64 loss: 0.293407142162323
Batch 45/64 loss: 0.28743410110473633
Batch 46/64 loss: 0.29106390476226807
Batch 47/64 loss: 0.30255401134490967
Batch 48/64 loss: 0.285007119178772
Batch 49/64 loss: 0.29694104194641113
Batch 50/64 loss: 0.28670573234558105
Batch 51/64 loss: 0.2939326763153076
Batch 52/64 loss: 0.2932621240615845
Batch 53/64 loss: 0.296639621257782
Batch 54/64 loss: 0.2842898368835449
Batch 55/64 loss: 0.2981414794921875
Batch 56/64 loss: 0.28454315662384033
Batch 57/64 loss: 0.29564738273620605
Batch 58/64 loss: 0.28729140758514404
Batch 59/64 loss: 0.29725325107574463
Batch 60/64 loss: 0.29259371757507324
Batch 61/64 loss: 0.28631365299224854
Batch 62/64 loss: 0.2885656952857971
Batch 63/64 loss: 0.28607267141342163
Batch 64/64 loss: 0.2978609800338745
Epoch 426  Train loss: 0.28988723334144145  Val loss: 0.3235268199566713
Epoch 427
-------------------------------
Batch 1/64 loss: 0.28538990020751953
Batch 2/64 loss: 0.28777867555618286
Batch 3/64 loss: 0.28975164890289307
Batch 4/64 loss: 0.29808974266052246
Batch 5/64 loss: 0.29129350185394287
Batch 6/64 loss: 0.28510987758636475
Batch 7/64 loss: 0.2956349849700928
Batch 8/64 loss: 0.2841843366622925
Batch 9/64 loss: 0.2862980365753174
Batch 10/64 loss: 0.28420501947402954
Batch 11/64 loss: 0.2926485538482666
Batch 12/64 loss: 0.27744632959365845
Batch 13/64 loss: 0.2891879081726074
Batch 14/64 loss: 0.295007586479187
Batch 15/64 loss: 0.290205717086792
Batch 16/64 loss: 0.2923933267593384
Batch 17/64 loss: 0.28915703296661377
Batch 18/64 loss: 0.28914594650268555
Batch 19/64 loss: 0.2820701599121094
Batch 20/64 loss: 0.29105889797210693
Batch 21/64 loss: 0.2782193422317505
Batch 22/64 loss: 0.29413264989852905
Batch 23/64 loss: 0.29151809215545654
Batch 24/64 loss: 0.28140008449554443
Batch 25/64 loss: 0.2952497601509094
Batch 26/64 loss: 0.30135297775268555
Batch 27/64 loss: 0.2875797748565674
Batch 28/64 loss: 0.2887364625930786
Batch 29/64 loss: 0.28444409370422363
Batch 30/64 loss: 0.2862463593482971
Batch 31/64 loss: 0.2827848196029663
Batch 32/64 loss: 0.29231882095336914
Batch 33/64 loss: 0.28983330726623535
Batch 34/64 loss: 0.28530770540237427
Batch 35/64 loss: 0.29407942295074463
Batch 36/64 loss: 0.28529202938079834
Batch 37/64 loss: 0.28995364904403687
Batch 38/64 loss: 0.2885854244232178
Batch 39/64 loss: 0.2846602201461792
Batch 40/64 loss: 0.28226524591445923
Batch 41/64 loss: 0.2873803973197937
Batch 42/64 loss: 0.29926514625549316
Batch 43/64 loss: 0.2902867794036865
Batch 44/64 loss: 0.28329575061798096
Batch 45/64 loss: 0.28398317098617554
Batch 46/64 loss: 0.28336942195892334
Batch 47/64 loss: 0.2907329201698303
Batch 48/64 loss: 0.29058581590652466
Batch 49/64 loss: 0.2801448106765747
Batch 50/64 loss: 0.2980368137359619
Batch 51/64 loss: 0.28392094373703003
Batch 52/64 loss: 0.29324764013290405
Batch 53/64 loss: 0.29442960023880005
Batch 54/64 loss: 0.3003218173980713
Batch 55/64 loss: 0.28925472497940063
Batch 56/64 loss: 0.2862950563430786
Batch 57/64 loss: 0.28552740812301636
Batch 58/64 loss: 0.2889310121536255
Batch 59/64 loss: 0.2891944646835327
Batch 60/64 loss: 0.2959200143814087
Batch 61/64 loss: 0.2918119430541992
Batch 62/64 loss: 0.2876235246658325
Batch 63/64 loss: 0.29194825887680054
Batch 64/64 loss: 0.3019993305206299
Epoch 427  Train loss: 0.2891297938776951  Val loss: 0.32352733612060547
Epoch 428
-------------------------------
Batch 1/64 loss: 0.29501694440841675
Batch 2/64 loss: 0.2840702533721924
Batch 3/64 loss: 0.2816329598426819
Batch 4/64 loss: 0.28320276737213135
Batch 5/64 loss: 0.2933415174484253
Batch 6/64 loss: 0.28840744495391846
Batch 7/64 loss: 0.2888987064361572
Batch 8/64 loss: 0.3015822172164917
Batch 9/64 loss: 0.2889178991317749
Batch 10/64 loss: 0.2957932949066162
Batch 11/64 loss: 0.27730000019073486
Batch 12/64 loss: 0.2836265563964844
Batch 13/64 loss: 0.30768001079559326
Batch 14/64 loss: 0.29248595237731934
Batch 15/64 loss: 0.28165972232818604
Batch 16/64 loss: 0.28258347511291504
Batch 17/64 loss: 0.28744035959243774
Batch 18/64 loss: 0.28931570053100586
Batch 19/64 loss: 0.29033803939819336
Batch 20/64 loss: 0.2806541919708252
Batch 21/64 loss: 0.2950160503387451
Batch 22/64 loss: 0.2935246229171753
Batch 23/64 loss: 0.28920912742614746
Batch 24/64 loss: 0.29033589363098145
Batch 25/64 loss: 0.28210777044296265
Batch 26/64 loss: 0.29579222202301025
Batch 27/64 loss: 0.28711962699890137
Batch 28/64 loss: 0.28772997856140137
Batch 29/64 loss: 0.29117292165756226
Batch 30/64 loss: 0.2892816662788391
Batch 31/64 loss: 0.28815144300460815
Batch 32/64 loss: 0.3046950101852417
Batch 33/64 loss: 0.3045930862426758
Batch 34/64 loss: 0.29023879766464233
Batch 35/64 loss: 0.28298431634902954
Batch 36/64 loss: 0.295723557472229
Batch 37/64 loss: 0.293277382850647
Batch 38/64 loss: 0.28971970081329346
Batch 39/64 loss: 0.29808318614959717
Batch 40/64 loss: 0.29638922214508057
Batch 41/64 loss: 0.2878384590148926
Batch 42/64 loss: 0.2935202121734619
Batch 43/64 loss: 0.28955674171447754
Batch 44/64 loss: 0.28992873430252075
Batch 45/64 loss: 0.2950197458267212
Batch 46/64 loss: 0.28594326972961426
Batch 47/64 loss: 0.29764342308044434
Batch 48/64 loss: 0.28643953800201416
Batch 49/64 loss: 0.28835660219192505
Batch 50/64 loss: 0.2930110692977905
Batch 51/64 loss: 0.28193867206573486
Batch 52/64 loss: 0.2909059524536133
Batch 53/64 loss: 0.29342639446258545
Batch 54/64 loss: 0.28469276428222656
Batch 55/64 loss: 0.2883042097091675
Batch 56/64 loss: 0.2826887369155884
Batch 57/64 loss: 0.27876174449920654
Batch 58/64 loss: 0.28428053855895996
Batch 59/64 loss: 0.2922224998474121
Batch 60/64 loss: 0.28498172760009766
Batch 61/64 loss: 0.2935255765914917
Batch 62/64 loss: 0.27902495861053467
Batch 63/64 loss: 0.2956337332725525
Batch 64/64 loss: 0.28129541873931885
Epoch 428  Train loss: 0.2896895759245929  Val loss: 0.3243939776191187
Epoch 429
-------------------------------
Batch 1/64 loss: 0.2837843894958496
Batch 2/64 loss: 0.2909426689147949
Batch 3/64 loss: 0.28128427267074585
Batch 4/64 loss: 0.275661826133728
Batch 5/64 loss: 0.29494667053222656
Batch 6/64 loss: 0.28452998399734497
Batch 7/64 loss: 0.2897881269454956
Batch 8/64 loss: 0.2832179069519043
Batch 9/64 loss: 0.2910158634185791
Batch 10/64 loss: 0.2806730270385742
Batch 11/64 loss: 0.29491084814071655
Batch 12/64 loss: 0.28926801681518555
Batch 13/64 loss: 0.28583693504333496
Batch 14/64 loss: 0.28868865966796875
Batch 15/64 loss: 0.2935008406639099
Batch 16/64 loss: 0.28510111570358276
Batch 17/64 loss: 0.2887189984321594
Batch 18/64 loss: 0.28762286901474
Batch 19/64 loss: 0.2996077537536621
Batch 20/64 loss: 0.28710705041885376
Batch 21/64 loss: 0.2956681251525879
Batch 22/64 loss: 0.28225040435791016
Batch 23/64 loss: 0.29476702213287354
Batch 24/64 loss: 0.2811852693557739
Batch 25/64 loss: 0.29195964336395264
Batch 26/64 loss: 0.2930186986923218
Batch 27/64 loss: 0.2981530427932739
Batch 28/64 loss: 0.2892948389053345
Batch 29/64 loss: 0.28810012340545654
Batch 30/64 loss: 0.2948557734489441
Batch 31/64 loss: 0.29472804069519043
Batch 32/64 loss: 0.29232680797576904
Batch 33/64 loss: 0.28973567485809326
Batch 34/64 loss: 0.282193660736084
Batch 35/64 loss: 0.2868831753730774
Batch 36/64 loss: 0.28692948818206787
Batch 37/64 loss: 0.2819560766220093
Batch 38/64 loss: 0.292665958404541
Batch 39/64 loss: 0.28999584913253784
Batch 40/64 loss: 0.2896343469619751
Batch 41/64 loss: 0.2902212142944336
Batch 42/64 loss: 0.2889418601989746
Batch 43/64 loss: 0.2814929485321045
Batch 44/64 loss: 0.28303372859954834
Batch 45/64 loss: 0.28867560625076294
Batch 46/64 loss: 0.290385365486145
Batch 47/64 loss: 0.28296899795532227
Batch 48/64 loss: 0.2892897129058838
Batch 49/64 loss: 0.29287493228912354
Batch 50/64 loss: 0.29983222484588623
Batch 51/64 loss: 0.2974134683609009
Batch 52/64 loss: 0.28774482011795044
Batch 53/64 loss: 0.2808002233505249
Batch 54/64 loss: 0.2920095920562744
Batch 55/64 loss: 0.29875266551971436
Batch 56/64 loss: 0.29269301891326904
Batch 57/64 loss: 0.2844313383102417
Batch 58/64 loss: 0.29439496994018555
Batch 59/64 loss: 0.2919692397117615
Batch 60/64 loss: 0.2870257496833801
Batch 61/64 loss: 0.2910584807395935
Batch 62/64 loss: 0.292951762676239
Batch 63/64 loss: 0.2878373861312866
Batch 64/64 loss: 0.2984582781791687
Epoch 429  Train loss: 0.2893043585852081  Val loss: 0.3236554930709891
Epoch 430
-------------------------------
Batch 1/64 loss: 0.29267412424087524
Batch 2/64 loss: 0.28893208503723145
Batch 3/64 loss: 0.28663575649261475
Batch 4/64 loss: 0.2898362874984741
Batch 5/64 loss: 0.2841138243675232
Batch 6/64 loss: 0.2906877398490906
Batch 7/64 loss: 0.29550182819366455
Batch 8/64 loss: 0.28230756521224976
Batch 9/64 loss: 0.2848646640777588
Batch 10/64 loss: 0.28734540939331055
Batch 11/64 loss: 0.2891309857368469
Batch 12/64 loss: 0.2832752466201782
Batch 13/64 loss: 0.2811988592147827
Batch 14/64 loss: 0.29986274242401123
Batch 15/64 loss: 0.28350961208343506
Batch 16/64 loss: 0.28819358348846436
Batch 17/64 loss: 0.2951502799987793
Batch 18/64 loss: 0.2898908257484436
Batch 19/64 loss: 0.2885472774505615
Batch 20/64 loss: 0.2885955572128296
Batch 21/64 loss: 0.29420000314712524
Batch 22/64 loss: 0.29154157638549805
Batch 23/64 loss: 0.2780522108078003
Batch 24/64 loss: 0.2960333228111267
Batch 25/64 loss: 0.2864859104156494
Batch 26/64 loss: 0.2902812957763672
Batch 27/64 loss: 0.29169559478759766
Batch 28/64 loss: 0.28809577226638794
Batch 29/64 loss: 0.2766290307044983
Batch 30/64 loss: 0.2839035987854004
Batch 31/64 loss: 0.28349506855010986
Batch 32/64 loss: 0.2901766300201416
Batch 33/64 loss: 0.2876397371292114
Batch 34/64 loss: 0.28850269317626953
Batch 35/64 loss: 0.29373931884765625
Batch 36/64 loss: 0.28386932611465454
Batch 37/64 loss: 0.2891954183578491
Batch 38/64 loss: 0.29991066455841064
Batch 39/64 loss: 0.2962133288383484
Batch 40/64 loss: 0.291841983795166
Batch 41/64 loss: 0.29305219650268555
Batch 42/64 loss: 0.29061567783355713
Batch 43/64 loss: 0.2882605791091919
Batch 44/64 loss: 0.30883097648620605
Batch 45/64 loss: 0.3055981397628784
Batch 46/64 loss: 0.28454113006591797
Batch 47/64 loss: 0.2836242914199829
Batch 48/64 loss: 0.288878858089447
Batch 49/64 loss: 0.29338204860687256
Batch 50/64 loss: 0.2942993640899658
Batch 51/64 loss: 0.2998585104942322
Batch 52/64 loss: 0.28258681297302246
Batch 53/64 loss: 0.2935209274291992
Batch 54/64 loss: 0.2899896502494812
Batch 55/64 loss: 0.29133421182632446
Batch 56/64 loss: 0.29689866304397583
Batch 57/64 loss: 0.2859033942222595
Batch 58/64 loss: 0.286396324634552
Batch 59/64 loss: 0.2930871248245239
Batch 60/64 loss: 0.2843054533004761
Batch 61/64 loss: 0.2878502607345581
Batch 62/64 loss: 0.285011351108551
Batch 63/64 loss: 0.2831767797470093
Batch 64/64 loss: 0.2776579260826111
Epoch 430  Train loss: 0.2894274966389525  Val loss: 0.3240312839701413
Epoch 431
-------------------------------
Batch 1/64 loss: 0.27972859144210815
Batch 2/64 loss: 0.289076566696167
Batch 3/64 loss: 0.28887641429901123
Batch 4/64 loss: 0.2967621088027954
Batch 5/64 loss: 0.2820631265640259
Batch 6/64 loss: 0.29980015754699707
Batch 7/64 loss: 0.2907726764678955
Batch 8/64 loss: 0.29355353116989136
Batch 9/64 loss: 0.2913780212402344
Batch 10/64 loss: 0.29336845874786377
Batch 11/64 loss: 0.29072487354278564
Batch 12/64 loss: 0.28440535068511963
Batch 13/64 loss: 0.291878342628479
Batch 14/64 loss: 0.28969985246658325
Batch 15/64 loss: 0.2862190008163452
Batch 16/64 loss: 0.28321224451065063
Batch 17/64 loss: 0.2877979874610901
Batch 18/64 loss: 0.2988440990447998
Batch 19/64 loss: 0.29440999031066895
Batch 20/64 loss: 0.28263717889785767
Batch 21/64 loss: 0.2877333164215088
Batch 22/64 loss: 0.28580713272094727
Batch 23/64 loss: 0.2997971773147583
Batch 24/64 loss: 0.2960640788078308
Batch 25/64 loss: 0.2803114056587219
Batch 26/64 loss: 0.30065661668777466
Batch 27/64 loss: 0.2829289436340332
Batch 28/64 loss: 0.29212403297424316
Batch 29/64 loss: 0.2965847849845886
Batch 30/64 loss: 0.2937392592430115
Batch 31/64 loss: 0.2928121089935303
Batch 32/64 loss: 0.28528809547424316
Batch 33/64 loss: 0.29163146018981934
Batch 34/64 loss: 0.28909915685653687
Batch 35/64 loss: 0.2890259027481079
Batch 36/64 loss: 0.29594916105270386
Batch 37/64 loss: 0.281158447265625
Batch 38/64 loss: 0.2826128602027893
Batch 39/64 loss: 0.294170618057251
Batch 40/64 loss: 0.28464949131011963
Batch 41/64 loss: 0.28990674018859863
Batch 42/64 loss: 0.2926276922225952
Batch 43/64 loss: 0.30223119258880615
Batch 44/64 loss: 0.285386323928833
Batch 45/64 loss: 0.28791868686676025
Batch 46/64 loss: 0.2958809733390808
Batch 47/64 loss: 0.28690624237060547
Batch 48/64 loss: 0.2837313413619995
Batch 49/64 loss: 0.29688960313796997
Batch 50/64 loss: 0.28606247901916504
Batch 51/64 loss: 0.2928903102874756
Batch 52/64 loss: 0.28428566455841064
Batch 53/64 loss: 0.2872706651687622
Batch 54/64 loss: 0.2835954427719116
Batch 55/64 loss: 0.2964690923690796
Batch 56/64 loss: 0.283794641494751
Batch 57/64 loss: 0.289337158203125
Batch 58/64 loss: 0.27404963970184326
Batch 59/64 loss: 0.2949432134628296
Batch 60/64 loss: 0.27257776260375977
Batch 61/64 loss: 0.29221826791763306
Batch 62/64 loss: 0.2835652828216553
Batch 63/64 loss: 0.3029444217681885
Batch 64/64 loss: 0.27903175354003906
Epoch 431  Train loss: 0.2894448514078178  Val loss: 0.32351178053728086
Epoch 432
-------------------------------
Batch 1/64 loss: 0.2932734489440918
Batch 2/64 loss: 0.29098641872406006
Batch 3/64 loss: 0.28839266300201416
Batch 4/64 loss: 0.2977779507637024
Batch 5/64 loss: 0.2813589572906494
Batch 6/64 loss: 0.2881925702095032
Batch 7/64 loss: 0.2865215539932251
Batch 8/64 loss: 0.2932767868041992
Batch 9/64 loss: 0.27875757217407227
Batch 10/64 loss: 0.2894768714904785
Batch 11/64 loss: 0.2956874370574951
Batch 12/64 loss: 0.2797427177429199
Batch 13/64 loss: 0.29566943645477295
Batch 14/64 loss: 0.29300570487976074
Batch 15/64 loss: 0.2905014753341675
Batch 16/64 loss: 0.2739145755767822
Batch 17/64 loss: 0.2791253328323364
Batch 18/64 loss: 0.29372847080230713
Batch 19/64 loss: 0.2921326756477356
Batch 20/64 loss: 0.29487061500549316
Batch 21/64 loss: 0.29303795099258423
Batch 22/64 loss: 0.28353816270828247
Batch 23/64 loss: 0.305397093296051
Batch 24/64 loss: 0.29364627599716187
Batch 25/64 loss: 0.2828933596611023
Batch 26/64 loss: 0.28255128860473633
Batch 27/64 loss: 0.2836768627166748
Batch 28/64 loss: 0.2884213924407959
Batch 29/64 loss: 0.27903974056243896
Batch 30/64 loss: 0.2941462993621826
Batch 31/64 loss: 0.2943956255912781
Batch 32/64 loss: 0.28727197647094727
Batch 33/64 loss: 0.2917078733444214
Batch 34/64 loss: 0.28971338272094727
Batch 35/64 loss: 0.2962738275527954
Batch 36/64 loss: 0.28212106227874756
Batch 37/64 loss: 0.2770109176635742
Batch 38/64 loss: 0.2956596612930298
Batch 39/64 loss: 0.28923314809799194
Batch 40/64 loss: 0.28439199924468994
Batch 41/64 loss: 0.2798370122909546
Batch 42/64 loss: 0.2779275178909302
Batch 43/64 loss: 0.301754355430603
Batch 44/64 loss: 0.29114437103271484
Batch 45/64 loss: 0.29597270488739014
Batch 46/64 loss: 0.28878962993621826
Batch 47/64 loss: 0.28890514373779297
Batch 48/64 loss: 0.30221617221832275
Batch 49/64 loss: 0.2830500602722168
Batch 50/64 loss: 0.28006064891815186
Batch 51/64 loss: 0.2837674617767334
Batch 52/64 loss: 0.28787803649902344
Batch 53/64 loss: 0.28686845302581787
Batch 54/64 loss: 0.28761231899261475
Batch 55/64 loss: 0.2824211120605469
Batch 56/64 loss: 0.29066669940948486
Batch 57/64 loss: 0.28831303119659424
Batch 58/64 loss: 0.29646313190460205
Batch 59/64 loss: 0.2847733497619629
Batch 60/64 loss: 0.28358280658721924
Batch 61/64 loss: 0.2942865490913391
Batch 62/64 loss: 0.2893267869949341
Batch 63/64 loss: 0.2880065441131592
Batch 64/64 loss: 0.29193878173828125
Epoch 432  Train loss: 0.28867606462216844  Val loss: 0.3232069621790725
Epoch 433
-------------------------------
Batch 1/64 loss: 0.2851502299308777
Batch 2/64 loss: 0.28591156005859375
Batch 3/64 loss: 0.2882993817329407
Batch 4/64 loss: 0.2896909713745117
Batch 5/64 loss: 0.2880149483680725
Batch 6/64 loss: 0.2841060161590576
Batch 7/64 loss: 0.3013572096824646
Batch 8/64 loss: 0.29111891984939575
Batch 9/64 loss: 0.2827526926994324
Batch 10/64 loss: 0.2888200879096985
Batch 11/64 loss: 0.28030186891555786
Batch 12/64 loss: 0.28302866220474243
Batch 13/64 loss: 0.28983765840530396
Batch 14/64 loss: 0.2940177321434021
Batch 15/64 loss: 0.28851598501205444
Batch 16/64 loss: 0.28119415044784546
Batch 17/64 loss: 0.28408002853393555
Batch 18/64 loss: 0.2899130582809448
Batch 19/64 loss: 0.2902284264564514
Batch 20/64 loss: 0.29781198501586914
Batch 21/64 loss: 0.2888987064361572
Batch 22/64 loss: 0.2798888683319092
Batch 23/64 loss: 0.2980082035064697
Batch 24/64 loss: 0.29369521141052246
Batch 25/64 loss: 0.2912665605545044
Batch 26/64 loss: 0.2849017381668091
Batch 27/64 loss: 0.29142361879348755
Batch 28/64 loss: 0.2817174792289734
Batch 29/64 loss: 0.29100602865219116
Batch 30/64 loss: 0.28065037727355957
Batch 31/64 loss: 0.28618574142456055
Batch 32/64 loss: 0.29087138175964355
Batch 33/64 loss: 0.291286826133728
Batch 34/64 loss: 0.2929416298866272
Batch 35/64 loss: 0.2860866189002991
Batch 36/64 loss: 0.2874486446380615
Batch 37/64 loss: 0.2863081097602844
Batch 38/64 loss: 0.28849339485168457
Batch 39/64 loss: 0.28264832496643066
Batch 40/64 loss: 0.2840346693992615
Batch 41/64 loss: 0.28298377990722656
Batch 42/64 loss: 0.29075706005096436
Batch 43/64 loss: 0.2832852005958557
Batch 44/64 loss: 0.2859356999397278
Batch 45/64 loss: 0.28882062435150146
Batch 46/64 loss: 0.2855294346809387
Batch 47/64 loss: 0.2898176908493042
Batch 48/64 loss: 0.30049312114715576
Batch 49/64 loss: 0.2885294556617737
Batch 50/64 loss: 0.2922143340110779
Batch 51/64 loss: 0.3007357120513916
Batch 52/64 loss: 0.288830041885376
Batch 53/64 loss: 0.2854982018470764
Batch 54/64 loss: 0.2829627990722656
Batch 55/64 loss: 0.28953516483306885
Batch 56/64 loss: 0.30121278762817383
Batch 57/64 loss: 0.29105615615844727
Batch 58/64 loss: 0.2957141399383545
Batch 59/64 loss: 0.2804705500602722
Batch 60/64 loss: 0.28769516944885254
Batch 61/64 loss: 0.29136157035827637
Batch 62/64 loss: 0.28650128841400146
Batch 63/64 loss: 0.28992801904678345
Batch 64/64 loss: 0.2904627323150635
Epoch 433  Train loss: 0.28862162758322324  Val loss: 0.323730229921767
Epoch 434
-------------------------------
Batch 1/64 loss: 0.2864212989807129
Batch 2/64 loss: 0.28707635402679443
Batch 3/64 loss: 0.2856419086456299
Batch 4/64 loss: 0.29273927211761475
Batch 5/64 loss: 0.2870919704437256
Batch 6/64 loss: 0.2828218936920166
Batch 7/64 loss: 0.3010708689689636
Batch 8/64 loss: 0.28774493932724
Batch 9/64 loss: 0.2846865653991699
Batch 10/64 loss: 0.29586291313171387
Batch 11/64 loss: 0.2796151638031006
Batch 12/64 loss: 0.28937679529190063
Batch 13/64 loss: 0.2960646152496338
Batch 14/64 loss: 0.2839452624320984
Batch 15/64 loss: 0.2938050627708435
Batch 16/64 loss: 0.28745734691619873
Batch 17/64 loss: 0.28394293785095215
Batch 18/64 loss: 0.29353928565979004
Batch 19/64 loss: 0.2823733687400818
Batch 20/64 loss: 0.29614078998565674
Batch 21/64 loss: 0.28877878189086914
Batch 22/64 loss: 0.2890651226043701
Batch 23/64 loss: 0.29083359241485596
Batch 24/64 loss: 0.2912445068359375
Batch 25/64 loss: 0.28534531593322754
Batch 26/64 loss: 0.28413015604019165
Batch 27/64 loss: 0.28470516204833984
Batch 28/64 loss: 0.28837043046951294
Batch 29/64 loss: 0.29121237993240356
Batch 30/64 loss: 0.29239147901535034
Batch 31/64 loss: 0.2781810760498047
Batch 32/64 loss: 0.28530991077423096
Batch 33/64 loss: 0.28440022468566895
Batch 34/64 loss: 0.2948318123817444
Batch 35/64 loss: 0.29362571239471436
Batch 36/64 loss: 0.29169273376464844
Batch 37/64 loss: 0.300508975982666
Batch 38/64 loss: 0.29891979694366455
Batch 39/64 loss: 0.2922831177711487
Batch 40/64 loss: 0.2949029207229614
Batch 41/64 loss: 0.28088855743408203
Batch 42/64 loss: 0.29790812730789185
Batch 43/64 loss: 0.2895064353942871
Batch 44/64 loss: 0.28101933002471924
Batch 45/64 loss: 0.2825961112976074
Batch 46/64 loss: 0.2915828227996826
Batch 47/64 loss: 0.2892817258834839
Batch 48/64 loss: 0.2813829779624939
Batch 49/64 loss: 0.2886795997619629
Batch 50/64 loss: 0.28928065299987793
Batch 51/64 loss: 0.29581785202026367
Batch 52/64 loss: 0.29339897632598877
Batch 53/64 loss: 0.29725921154022217
Batch 54/64 loss: 0.2929254174232483
Batch 55/64 loss: 0.27585452795028687
Batch 56/64 loss: 0.2945834994316101
Batch 57/64 loss: 0.28210461139678955
Batch 58/64 loss: 0.28475046157836914
Batch 59/64 loss: 0.29150938987731934
Batch 60/64 loss: 0.3049042820930481
Batch 61/64 loss: 0.29215651750564575
Batch 62/64 loss: 0.2843344211578369
Batch 63/64 loss: 0.28883200883865356
Batch 64/64 loss: 0.2873861789703369
Epoch 434  Train loss: 0.2893215525384043  Val loss: 0.3240673644436184
Epoch 435
-------------------------------
Batch 1/64 loss: 0.2797344923019409
Batch 2/64 loss: 0.2909729480743408
Batch 3/64 loss: 0.28363311290740967
Batch 4/64 loss: 0.29031240940093994
Batch 5/64 loss: 0.291461706161499
Batch 6/64 loss: 0.29331207275390625
Batch 7/64 loss: 0.28686147928237915
Batch 8/64 loss: 0.2958197593688965
Batch 9/64 loss: 0.28628718852996826
Batch 10/64 loss: 0.28418219089508057
Batch 11/64 loss: 0.2874929904937744
Batch 12/64 loss: 0.2834795117378235
Batch 13/64 loss: 0.2939961552619934
Batch 14/64 loss: 0.28460007905960083
Batch 15/64 loss: 0.2937730550765991
Batch 16/64 loss: 0.2901129722595215
Batch 17/64 loss: 0.29248642921447754
Batch 18/64 loss: 0.2938194274902344
Batch 19/64 loss: 0.2797410488128662
Batch 20/64 loss: 0.28925561904907227
Batch 21/64 loss: 0.29757022857666016
Batch 22/64 loss: 0.295997679233551
Batch 23/64 loss: 0.29358649253845215
Batch 24/64 loss: 0.2792954444885254
Batch 25/64 loss: 0.288357675075531
Batch 26/64 loss: 0.290111780166626
Batch 27/64 loss: 0.2937151789665222
Batch 28/64 loss: 0.2896217107772827
Batch 29/64 loss: 0.28619658946990967
Batch 30/64 loss: 0.28086745738983154
Batch 31/64 loss: 0.29359984397888184
Batch 32/64 loss: 0.2902359962463379
Batch 33/64 loss: 0.2925809621810913
Batch 34/64 loss: 0.29875004291534424
Batch 35/64 loss: 0.27409493923187256
Batch 36/64 loss: 0.28590893745422363
Batch 37/64 loss: 0.28617197275161743
Batch 38/64 loss: 0.28619277477264404
Batch 39/64 loss: 0.28405332565307617
Batch 40/64 loss: 0.29056644439697266
Batch 41/64 loss: 0.29687774181365967
Batch 42/64 loss: 0.2915372848510742
Batch 43/64 loss: 0.28005099296569824
Batch 44/64 loss: 0.2857509255409241
Batch 45/64 loss: 0.3040142059326172
Batch 46/64 loss: 0.2884712219238281
Batch 47/64 loss: 0.293587327003479
Batch 48/64 loss: 0.2866709232330322
Batch 49/64 loss: 0.28962093591690063
Batch 50/64 loss: 0.28637850284576416
Batch 51/64 loss: 0.28758716583251953
Batch 52/64 loss: 0.2908141016960144
Batch 53/64 loss: 0.2920573353767395
Batch 54/64 loss: 0.2909965515136719
Batch 55/64 loss: 0.28208816051483154
Batch 56/64 loss: 0.29341018199920654
Batch 57/64 loss: 0.3000977635383606
Batch 58/64 loss: 0.2885470390319824
Batch 59/64 loss: 0.2921391725540161
Batch 60/64 loss: 0.2889326810836792
Batch 61/64 loss: 0.289465069770813
Batch 62/64 loss: 0.28961533308029175
Batch 63/64 loss: 0.30405980348587036
Batch 64/64 loss: 0.29170024394989014
Epoch 435  Train loss: 0.2895742075116027  Val loss: 0.3249199699700083
Epoch 436
-------------------------------
Batch 1/64 loss: 0.29536521434783936
Batch 2/64 loss: 0.28377223014831543
Batch 3/64 loss: 0.2919796109199524
Batch 4/64 loss: 0.2840980291366577
Batch 5/64 loss: 0.29092937707901
Batch 6/64 loss: 0.3037978410720825
Batch 7/64 loss: 0.2929156422615051
Batch 8/64 loss: 0.2802680730819702
Batch 9/64 loss: 0.28593677282333374
Batch 10/64 loss: 0.286773145198822
Batch 11/64 loss: 0.28399598598480225
Batch 12/64 loss: 0.28972578048706055
Batch 13/64 loss: 0.28568851947784424
Batch 14/64 loss: 0.2857067584991455
Batch 15/64 loss: 0.284912109375
Batch 16/64 loss: 0.2832466959953308
Batch 17/64 loss: 0.2822229862213135
Batch 18/64 loss: 0.28678297996520996
Batch 19/64 loss: 0.2921271324157715
Batch 20/64 loss: 0.29757416248321533
Batch 21/64 loss: 0.29427820444107056
Batch 22/64 loss: 0.30048227310180664
Batch 23/64 loss: 0.2882159948348999
Batch 24/64 loss: 0.28921300172805786
Batch 25/64 loss: 0.2918398380279541
Batch 26/64 loss: 0.2781686782836914
Batch 27/64 loss: 0.2819162607192993
Batch 28/64 loss: 0.2902546525001526
Batch 29/64 loss: 0.28697627782821655
Batch 30/64 loss: 0.2906672954559326
Batch 31/64 loss: 0.28576695919036865
Batch 32/64 loss: 0.28970038890838623
Batch 33/64 loss: 0.2825005054473877
Batch 34/64 loss: 0.2954861521720886
Batch 35/64 loss: 0.29386377334594727
Batch 36/64 loss: 0.28657764196395874
Batch 37/64 loss: 0.2881743311882019
Batch 38/64 loss: 0.2939739227294922
Batch 39/64 loss: 0.29483866691589355
Batch 40/64 loss: 0.2908133864402771
Batch 41/64 loss: 0.292289137840271
Batch 42/64 loss: 0.29516780376434326
Batch 43/64 loss: 0.2853759527206421
Batch 44/64 loss: 0.289267897605896
Batch 45/64 loss: 0.2960197329521179
Batch 46/64 loss: 0.28422486782073975
Batch 47/64 loss: 0.29452788829803467
Batch 48/64 loss: 0.29150521755218506
Batch 49/64 loss: 0.29577600955963135
Batch 50/64 loss: 0.2886389493942261
Batch 51/64 loss: 0.28754258155822754
Batch 52/64 loss: 0.2841934561729431
Batch 53/64 loss: 0.28201258182525635
Batch 54/64 loss: 0.28799670934677124
Batch 55/64 loss: 0.2870177626609802
Batch 56/64 loss: 0.27771496772766113
Batch 57/64 loss: 0.2869935631752014
Batch 58/64 loss: 0.2812768220901489
Batch 59/64 loss: 0.28495150804519653
Batch 60/64 loss: 0.28258955478668213
Batch 61/64 loss: 0.2822984457015991
Batch 62/64 loss: 0.2888968586921692
Batch 63/64 loss: 0.2944217920303345
Batch 64/64 loss: 0.2955129146575928
Epoch 436  Train loss: 0.2886880313648897  Val loss: 0.3238263466104199
Epoch 437
-------------------------------
Batch 1/64 loss: 0.2992250919342041
Batch 2/64 loss: 0.285976767539978
Batch 3/64 loss: 0.2951620817184448
Batch 4/64 loss: 0.2882536053657532
Batch 5/64 loss: 0.28878772258758545
Batch 6/64 loss: 0.28756123781204224
Batch 7/64 loss: 0.2945162057876587
Batch 8/64 loss: 0.28622496128082275
Batch 9/64 loss: 0.286507248878479
Batch 10/64 loss: 0.2792710065841675
Batch 11/64 loss: 0.289256751537323
Batch 12/64 loss: 0.2899649143218994
Batch 13/64 loss: 0.2974940538406372
Batch 14/64 loss: 0.29158949851989746
Batch 15/64 loss: 0.28392720222473145
Batch 16/64 loss: 0.2827303409576416
Batch 17/64 loss: 0.287821888923645
Batch 18/64 loss: 0.2854732275009155
Batch 19/64 loss: 0.29356300830841064
Batch 20/64 loss: 0.2995830178260803
Batch 21/64 loss: 0.2832857370376587
Batch 22/64 loss: 0.2849835157394409
Batch 23/64 loss: 0.29035693407058716
Batch 24/64 loss: 0.28547441959381104
Batch 25/64 loss: 0.28586411476135254
Batch 26/64 loss: 0.2868788242340088
Batch 27/64 loss: 0.28711915016174316
Batch 28/64 loss: 0.29608219861984253
Batch 29/64 loss: 0.28557533025741577
Batch 30/64 loss: 0.2892799377441406
Batch 31/64 loss: 0.28226399421691895
Batch 32/64 loss: 0.2853802442550659
Batch 33/64 loss: 0.280803918838501
Batch 34/64 loss: 0.2935311794281006
Batch 35/64 loss: 0.3016146421432495
Batch 36/64 loss: 0.29339706897735596
Batch 37/64 loss: 0.290641725063324
Batch 38/64 loss: 0.2897763252258301
Batch 39/64 loss: 0.2935919761657715
Batch 40/64 loss: 0.28525662422180176
Batch 41/64 loss: 0.28873008489608765
Batch 42/64 loss: 0.28049319982528687
Batch 43/64 loss: 0.2802635431289673
Batch 44/64 loss: 0.2923775911331177
Batch 45/64 loss: 0.2898869514465332
Batch 46/64 loss: 0.2861250042915344
Batch 47/64 loss: 0.28037357330322266
Batch 48/64 loss: 0.29477357864379883
Batch 49/64 loss: 0.2824028730392456
Batch 50/64 loss: 0.2890743017196655
Batch 51/64 loss: 0.2844109535217285
Batch 52/64 loss: 0.2916422486305237
Batch 53/64 loss: 0.2860008478164673
Batch 54/64 loss: 0.29638636112213135
Batch 55/64 loss: 0.2853202819824219
Batch 56/64 loss: 0.30265963077545166
Batch 57/64 loss: 0.29407912492752075
Batch 58/64 loss: 0.28472763299942017
Batch 59/64 loss: 0.28663766384124756
Batch 60/64 loss: 0.28145283460617065
Batch 61/64 loss: 0.286943256855011
Batch 62/64 loss: 0.2968084216117859
Batch 63/64 loss: 0.2931060791015625
Batch 64/64 loss: 0.2934420108795166
Epoch 437  Train loss: 0.2889224351621142  Val loss: 0.3240982746750219
Epoch 438
-------------------------------
Batch 1/64 loss: 0.28042447566986084
Batch 2/64 loss: 0.2852323055267334
Batch 3/64 loss: 0.2920328974723816
Batch 4/64 loss: 0.2928258180618286
Batch 5/64 loss: 0.28927290439605713
Batch 6/64 loss: 0.29592353105545044
Batch 7/64 loss: 0.28160202503204346
Batch 8/64 loss: 0.2943003177642822
Batch 9/64 loss: 0.2848573327064514
Batch 10/64 loss: 0.2814578413963318
Batch 11/64 loss: 0.2796691656112671
Batch 12/64 loss: 0.28579795360565186
Batch 13/64 loss: 0.28308427333831787
Batch 14/64 loss: 0.2846517562866211
Batch 15/64 loss: 0.28840118646621704
Batch 16/64 loss: 0.2892158031463623
Batch 17/64 loss: 0.28512561321258545
Batch 18/64 loss: 0.2933247685432434
Batch 19/64 loss: 0.281760573387146
Batch 20/64 loss: 0.2822454571723938
Batch 21/64 loss: 0.2926645278930664
Batch 22/64 loss: 0.2791149616241455
Batch 23/64 loss: 0.28776466846466064
Batch 24/64 loss: 0.29517626762390137
Batch 25/64 loss: 0.2897449731826782
Batch 26/64 loss: 0.2919142246246338
Batch 27/64 loss: 0.2930910587310791
Batch 28/64 loss: 0.2846672534942627
Batch 29/64 loss: 0.29197847843170166
Batch 30/64 loss: 0.2955824136734009
Batch 31/64 loss: 0.29760146141052246
Batch 32/64 loss: 0.2778552770614624
Batch 33/64 loss: 0.28364133834838867
Batch 34/64 loss: 0.2904151678085327
Batch 35/64 loss: 0.28703033924102783
Batch 36/64 loss: 0.28505468368530273
Batch 37/64 loss: 0.2947046756744385
Batch 38/64 loss: 0.28890717029571533
Batch 39/64 loss: 0.2871202230453491
Batch 40/64 loss: 0.28384387493133545
Batch 41/64 loss: 0.29722505807876587
Batch 42/64 loss: 0.2831971049308777
Batch 43/64 loss: 0.28967010974884033
Batch 44/64 loss: 0.29100942611694336
Batch 45/64 loss: 0.2791479825973511
Batch 46/64 loss: 0.28911978006362915
Batch 47/64 loss: 0.2937796115875244
Batch 48/64 loss: 0.2869678735733032
Batch 49/64 loss: 0.2899632453918457
Batch 50/64 loss: 0.28170883655548096
Batch 51/64 loss: 0.28371095657348633
Batch 52/64 loss: 0.2901182174682617
Batch 53/64 loss: 0.296225368976593
Batch 54/64 loss: 0.28985124826431274
Batch 55/64 loss: 0.29405349493026733
Batch 56/64 loss: 0.3005044460296631
Batch 57/64 loss: 0.30334216356277466
Batch 58/64 loss: 0.2814168334007263
Batch 59/64 loss: 0.2824857831001282
Batch 60/64 loss: 0.28048598766326904
Batch 61/64 loss: 0.2826337218284607
Batch 62/64 loss: 0.28131961822509766
Batch 63/64 loss: 0.2865196466445923
Batch 64/64 loss: 0.3015202283859253
Epoch 438  Train loss: 0.2881517760893878  Val loss: 0.32354986974873495
Epoch 439
-------------------------------
Batch 1/64 loss: 0.29141390323638916
Batch 2/64 loss: 0.28451263904571533
Batch 3/64 loss: 0.2822079658508301
Batch 4/64 loss: 0.29789119958877563
Batch 5/64 loss: 0.2777280807495117
Batch 6/64 loss: 0.2806018590927124
Batch 7/64 loss: 0.2911302447319031
Batch 8/64 loss: 0.2911589741706848
Batch 9/64 loss: 0.29204320907592773
Batch 10/64 loss: 0.2911381721496582
Batch 11/64 loss: 0.29181790351867676
Batch 12/64 loss: 0.2861325740814209
Batch 13/64 loss: 0.28488242626190186
Batch 14/64 loss: 0.29567575454711914
Batch 15/64 loss: 0.2857208251953125
Batch 16/64 loss: 0.2825824022293091
Batch 17/64 loss: 0.2860095500946045
Batch 18/64 loss: 0.28939586877822876
Batch 19/64 loss: 0.2847103476524353
Batch 20/64 loss: 0.2817939519882202
Batch 21/64 loss: 0.2895538806915283
Batch 22/64 loss: 0.28641295433044434
Batch 23/64 loss: 0.2876925468444824
Batch 24/64 loss: 0.27868854999542236
Batch 25/64 loss: 0.29719555377960205
Batch 26/64 loss: 0.28086185455322266
Batch 27/64 loss: 0.28436851501464844
Batch 28/64 loss: 0.2774289846420288
Batch 29/64 loss: 0.2936798334121704
Batch 30/64 loss: 0.2956582307815552
Batch 31/64 loss: 0.2874884605407715
Batch 32/64 loss: 0.291049063205719
Batch 33/64 loss: 0.2841265797615051
Batch 34/64 loss: 0.28161096572875977
Batch 35/64 loss: 0.2887001037597656
Batch 36/64 loss: 0.2888295650482178
Batch 37/64 loss: 0.29339683055877686
Batch 38/64 loss: 0.2890012264251709
Batch 39/64 loss: 0.2940519452095032
Batch 40/64 loss: 0.28939592838287354
Batch 41/64 loss: 0.28472816944122314
Batch 42/64 loss: 0.28137636184692383
Batch 43/64 loss: 0.28546303510665894
Batch 44/64 loss: 0.2868082523345947
Batch 45/64 loss: 0.2993577718734741
Batch 46/64 loss: 0.2872818112373352
Batch 47/64 loss: 0.2844315767288208
Batch 48/64 loss: 0.2942636013031006
Batch 49/64 loss: 0.284479022026062
Batch 50/64 loss: 0.2964516282081604
Batch 51/64 loss: 0.28914642333984375
Batch 52/64 loss: 0.2901398539543152
Batch 53/64 loss: 0.28549814224243164
Batch 54/64 loss: 0.2768315076828003
Batch 55/64 loss: 0.2928246855735779
Batch 56/64 loss: 0.2828792929649353
Batch 57/64 loss: 0.2930028438568115
Batch 58/64 loss: 0.2885679006576538
Batch 59/64 loss: 0.28147923946380615
Batch 60/64 loss: 0.3024495840072632
Batch 61/64 loss: 0.298625648021698
Batch 62/64 loss: 0.28297150135040283
Batch 63/64 loss: 0.2906474471092224
Batch 64/64 loss: 0.2906121015548706
Epoch 439  Train loss: 0.28808476550906315  Val loss: 0.3239078423411576
Epoch 440
-------------------------------
Batch 1/64 loss: 0.28935855627059937
Batch 2/64 loss: 0.28905415534973145
Batch 3/64 loss: 0.2793089747428894
Batch 4/64 loss: 0.28275758028030396
Batch 5/64 loss: 0.2853398323059082
Batch 6/64 loss: 0.2918558716773987
Batch 7/64 loss: 0.2770426273345947
Batch 8/64 loss: 0.27947187423706055
Batch 9/64 loss: 0.28365159034729004
Batch 10/64 loss: 0.2806176543235779
Batch 11/64 loss: 0.2901597023010254
Batch 12/64 loss: 0.28301727771759033
Batch 13/64 loss: 0.2894989252090454
Batch 14/64 loss: 0.28927040100097656
Batch 15/64 loss: 0.28601735830307007
Batch 16/64 loss: 0.2877514362335205
Batch 17/64 loss: 0.2884927988052368
Batch 18/64 loss: 0.28715968132019043
Batch 19/64 loss: 0.2895359396934509
Batch 20/64 loss: 0.28492188453674316
Batch 21/64 loss: 0.28514575958251953
Batch 22/64 loss: 0.29082226753234863
Batch 23/64 loss: 0.3023344874382019
Batch 24/64 loss: 0.2844581604003906
Batch 25/64 loss: 0.28435951471328735
Batch 26/64 loss: 0.28437161445617676
Batch 27/64 loss: 0.2920879125595093
Batch 28/64 loss: 0.28442198038101196
Batch 29/64 loss: 0.28246450424194336
Batch 30/64 loss: 0.29653120040893555
Batch 31/64 loss: 0.28639596700668335
Batch 32/64 loss: 0.292320191860199
Batch 33/64 loss: 0.28258007764816284
Batch 34/64 loss: 0.29098963737487793
Batch 35/64 loss: 0.2952529191970825
Batch 36/64 loss: 0.28348100185394287
Batch 37/64 loss: 0.2786705493927002
Batch 38/64 loss: 0.2830810546875
Batch 39/64 loss: 0.283092737197876
Batch 40/64 loss: 0.28723078966140747
Batch 41/64 loss: 0.29285162687301636
Batch 42/64 loss: 0.28812551498413086
Batch 43/64 loss: 0.2950870990753174
Batch 44/64 loss: 0.28711777925491333
Batch 45/64 loss: 0.3082616329193115
Batch 46/64 loss: 0.28570258617401123
Batch 47/64 loss: 0.28944694995880127
Batch 48/64 loss: 0.29273003339767456
Batch 49/64 loss: 0.28224730491638184
Batch 50/64 loss: 0.28602731227874756
Batch 51/64 loss: 0.2958906888961792
Batch 52/64 loss: 0.28368330001831055
Batch 53/64 loss: 0.29881346225738525
Batch 54/64 loss: 0.28641223907470703
Batch 55/64 loss: 0.27809810638427734
Batch 56/64 loss: 0.28958773612976074
Batch 57/64 loss: 0.2819814682006836
Batch 58/64 loss: 0.2849538326263428
Batch 59/64 loss: 0.28517091274261475
Batch 60/64 loss: 0.29525190591812134
Batch 61/64 loss: 0.3071633577346802
Batch 62/64 loss: 0.3021141290664673
Batch 63/64 loss: 0.28953927755355835
Batch 64/64 loss: 0.30469125509262085
Epoch 440  Train loss: 0.28830044152689915  Val loss: 0.32332276314804237
Epoch 441
-------------------------------
Batch 1/64 loss: 0.2977961301803589
Batch 2/64 loss: 0.28527212142944336
Batch 3/64 loss: 0.2827650308609009
Batch 4/64 loss: 0.28582847118377686
Batch 5/64 loss: 0.29701411724090576
Batch 6/64 loss: 0.28040242195129395
Batch 7/64 loss: 0.2922760844230652
Batch 8/64 loss: 0.28698015213012695
Batch 9/64 loss: 0.28682029247283936
Batch 10/64 loss: 0.2965017557144165
Batch 11/64 loss: 0.2847285270690918
Batch 12/64 loss: 0.2935149669647217
Batch 13/64 loss: 0.2761887311935425
Batch 14/64 loss: 0.2972928285598755
Batch 15/64 loss: 0.2859967350959778
Batch 16/64 loss: 0.2819179892539978
Batch 17/64 loss: 0.28406620025634766
Batch 18/64 loss: 0.2889918088912964
Batch 19/64 loss: 0.28484344482421875
Batch 20/64 loss: 0.2908424139022827
Batch 21/64 loss: 0.2834851145744324
Batch 22/64 loss: 0.29186439514160156
Batch 23/64 loss: 0.281909704208374
Batch 24/64 loss: 0.2816888689994812
Batch 25/64 loss: 0.280073881149292
Batch 26/64 loss: 0.2880514860153198
Batch 27/64 loss: 0.27605140209198
Batch 28/64 loss: 0.29695451259613037
Batch 29/64 loss: 0.2850361466407776
Batch 30/64 loss: 0.2884356379508972
Batch 31/64 loss: 0.28495311737060547
Batch 32/64 loss: 0.2853654623031616
Batch 33/64 loss: 0.3052983283996582
Batch 34/64 loss: 0.29513633251190186
Batch 35/64 loss: 0.2883990406990051
Batch 36/64 loss: 0.2837042808532715
Batch 37/64 loss: 0.2911933660507202
Batch 38/64 loss: 0.2898024916648865
Batch 39/64 loss: 0.29374241828918457
Batch 40/64 loss: 0.29224348068237305
Batch 41/64 loss: 0.2810293436050415
Batch 42/64 loss: 0.29495978355407715
Batch 43/64 loss: 0.286653995513916
Batch 44/64 loss: 0.28190016746520996
Batch 45/64 loss: 0.2900352478027344
Batch 46/64 loss: 0.2756804823875427
Batch 47/64 loss: 0.2815724015235901
Batch 48/64 loss: 0.29008418321609497
Batch 49/64 loss: 0.2851172685623169
Batch 50/64 loss: 0.29607653617858887
Batch 51/64 loss: 0.2992492914199829
Batch 52/64 loss: 0.29067444801330566
Batch 53/64 loss: 0.28817427158355713
Batch 54/64 loss: 0.2916792631149292
Batch 55/64 loss: 0.2857029438018799
Batch 56/64 loss: 0.2939891219139099
Batch 57/64 loss: 0.2853912115097046
Batch 58/64 loss: 0.29196178913116455
Batch 59/64 loss: 0.2931396961212158
Batch 60/64 loss: 0.28494900465011597
Batch 61/64 loss: 0.2846107482910156
Batch 62/64 loss: 0.2870420217514038
Batch 63/64 loss: 0.2908918857574463
Batch 64/64 loss: 0.289797306060791
Epoch 441  Train loss: 0.28817792593264113  Val loss: 0.325180880187713
Epoch 442
-------------------------------
Batch 1/64 loss: 0.3016023635864258
Batch 2/64 loss: 0.285886287689209
Batch 3/64 loss: 0.279610276222229
Batch 4/64 loss: 0.2825162410736084
Batch 5/64 loss: 0.28969717025756836
Batch 6/64 loss: 0.29365354776382446
Batch 7/64 loss: 0.29500699043273926
Batch 8/64 loss: 0.29017168283462524
Batch 9/64 loss: 0.29843735694885254
Batch 10/64 loss: 0.2888902425765991
Batch 11/64 loss: 0.28464215993881226
Batch 12/64 loss: 0.28490322828292847
Batch 13/64 loss: 0.28783679008483887
Batch 14/64 loss: 0.2833147644996643
Batch 15/64 loss: 0.28296130895614624
Batch 16/64 loss: 0.2823486328125
Batch 17/64 loss: 0.28769993782043457
Batch 18/64 loss: 0.284562885761261
Batch 19/64 loss: 0.28570258617401123
Batch 20/64 loss: 0.2869008779525757
Batch 21/64 loss: 0.2884601354598999
Batch 22/64 loss: 0.29192209243774414
Batch 23/64 loss: 0.29276150465011597
Batch 24/64 loss: 0.2847082018852234
Batch 25/64 loss: 0.28283751010894775
Batch 26/64 loss: 0.2811915874481201
Batch 27/64 loss: 0.2859276533126831
Batch 28/64 loss: 0.28872156143188477
Batch 29/64 loss: 0.3018232583999634
Batch 30/64 loss: 0.28249984979629517
Batch 31/64 loss: 0.2750094532966614
Batch 32/64 loss: 0.28443485498428345
Batch 33/64 loss: 0.2842608094215393
Batch 34/64 loss: 0.2803107500076294
Batch 35/64 loss: 0.2872486114501953
Batch 36/64 loss: 0.29477202892303467
Batch 37/64 loss: 0.2838174104690552
Batch 38/64 loss: 0.2853966951370239
Batch 39/64 loss: 0.28873109817504883
Batch 40/64 loss: 0.2916215658187866
Batch 41/64 loss: 0.28864437341690063
Batch 42/64 loss: 0.2967650294303894
Batch 43/64 loss: 0.2824690341949463
Batch 44/64 loss: 0.29415810108184814
Batch 45/64 loss: 0.29670506715774536
Batch 46/64 loss: 0.28442245721817017
Batch 47/64 loss: 0.2831454277038574
Batch 48/64 loss: 0.28406596183776855
Batch 49/64 loss: 0.291759729385376
Batch 50/64 loss: 0.2872185707092285
Batch 51/64 loss: 0.29239439964294434
Batch 52/64 loss: 0.2859898805618286
Batch 53/64 loss: 0.2962266206741333
Batch 54/64 loss: 0.28885626792907715
Batch 55/64 loss: 0.2905876636505127
Batch 56/64 loss: 0.2938724756240845
Batch 57/64 loss: 0.2809290885925293
Batch 58/64 loss: 0.2848813533782959
Batch 59/64 loss: 0.2951582670211792
Batch 60/64 loss: 0.29072099924087524
Batch 61/64 loss: 0.28034424781799316
Batch 62/64 loss: 0.2917311191558838
Batch 63/64 loss: 0.28879594802856445
Batch 64/64 loss: 0.2961503863334656
Epoch 442  Train loss: 0.2880746170586231  Val loss: 0.3250133391098468
Epoch 443
-------------------------------
Batch 1/64 loss: 0.29002344608306885
Batch 2/64 loss: 0.29011785984039307
Batch 3/64 loss: 0.2744724154472351
Batch 4/64 loss: 0.2859828472137451
Batch 5/64 loss: 0.2872942090034485
Batch 6/64 loss: 0.2995666265487671
Batch 7/64 loss: 0.2813143730163574
Batch 8/64 loss: 0.28692543506622314
Batch 9/64 loss: 0.2931792736053467
Batch 10/64 loss: 0.2909134030342102
Batch 11/64 loss: 0.29537707567214966
Batch 12/64 loss: 0.2916889786720276
Batch 13/64 loss: 0.2833552360534668
Batch 14/64 loss: 0.2971566915512085
Batch 15/64 loss: 0.28038889169692993
Batch 16/64 loss: 0.28960591554641724
Batch 17/64 loss: 0.2872880697250366
Batch 18/64 loss: 0.28643596172332764
Batch 19/64 loss: 0.2848532199859619
Batch 20/64 loss: 0.2942800521850586
Batch 21/64 loss: 0.288751482963562
Batch 22/64 loss: 0.2919906973838806
Batch 23/64 loss: 0.2797473669052124
Batch 24/64 loss: 0.291343629360199
Batch 25/64 loss: 0.29153013229370117
Batch 26/64 loss: 0.2873484492301941
Batch 27/64 loss: 0.2879211902618408
Batch 28/64 loss: 0.2923624515533447
Batch 29/64 loss: 0.2804110646247864
Batch 30/64 loss: 0.28504765033721924
Batch 31/64 loss: 0.28294193744659424
Batch 32/64 loss: 0.28412747383117676
Batch 33/64 loss: 0.2850325107574463
Batch 34/64 loss: 0.29840779304504395
Batch 35/64 loss: 0.2828335165977478
Batch 36/64 loss: 0.2869616746902466
Batch 37/64 loss: 0.28352558612823486
Batch 38/64 loss: 0.2835710048675537
Batch 39/64 loss: 0.29277485609054565
Batch 40/64 loss: 0.28532588481903076
Batch 41/64 loss: 0.2881655693054199
Batch 42/64 loss: 0.2851846218109131
Batch 43/64 loss: 0.29082000255584717
Batch 44/64 loss: 0.2796367406845093
Batch 45/64 loss: 0.28426796197891235
Batch 46/64 loss: 0.289509117603302
Batch 47/64 loss: 0.288907527923584
Batch 48/64 loss: 0.2867777347564697
Batch 49/64 loss: 0.2860209345817566
Batch 50/64 loss: 0.2823190689086914
Batch 51/64 loss: 0.27738845348358154
Batch 52/64 loss: 0.2923749089241028
Batch 53/64 loss: 0.289752721786499
Batch 54/64 loss: 0.2906387448310852
Batch 55/64 loss: 0.2910827398300171
Batch 56/64 loss: 0.2904435396194458
Batch 57/64 loss: 0.29289841651916504
Batch 58/64 loss: 0.2944319248199463
Batch 59/64 loss: 0.2894008159637451
Batch 60/64 loss: 0.295635461807251
Batch 61/64 loss: 0.29106903076171875
Batch 62/64 loss: 0.2817341089248657
Batch 63/64 loss: 0.286344051361084
Batch 64/64 loss: 0.29332029819488525
Epoch 443  Train loss: 0.2879524824666042  Val loss: 0.3233884310804282
Epoch 444
-------------------------------
Batch 1/64 loss: 0.2867060899734497
Batch 2/64 loss: 0.28136467933654785
Batch 3/64 loss: 0.2894613742828369
Batch 4/64 loss: 0.29525649547576904
Batch 5/64 loss: 0.2957003116607666
Batch 6/64 loss: 0.2978578805923462
Batch 7/64 loss: 0.298606276512146
Batch 8/64 loss: 0.28801095485687256
Batch 9/64 loss: 0.2872253656387329
Batch 10/64 loss: 0.2925065755844116
Batch 11/64 loss: 0.28646349906921387
Batch 12/64 loss: 0.27645182609558105
Batch 13/64 loss: 0.2961180806159973
Batch 14/64 loss: 0.28697335720062256
Batch 15/64 loss: 0.2783159017562866
Batch 16/64 loss: 0.2866458296775818
Batch 17/64 loss: 0.2943624258041382
Batch 18/64 loss: 0.29401642084121704
Batch 19/64 loss: 0.2859511375427246
Batch 20/64 loss: 0.2942899465560913
Batch 21/64 loss: 0.27594101428985596
Batch 22/64 loss: 0.2866482734680176
Batch 23/64 loss: 0.27884048223495483
Batch 24/64 loss: 0.2835514545440674
Batch 25/64 loss: 0.2820579409599304
Batch 26/64 loss: 0.28782516717910767
Batch 27/64 loss: 0.2813279628753662
Batch 28/64 loss: 0.2949067950248718
Batch 29/64 loss: 0.2938227653503418
Batch 30/64 loss: 0.29631686210632324
Batch 31/64 loss: 0.28476810455322266
Batch 32/64 loss: 0.29215532541275024
Batch 33/64 loss: 0.28397369384765625
Batch 34/64 loss: 0.29139822721481323
Batch 35/64 loss: 0.2927708029747009
Batch 36/64 loss: 0.2946479320526123
Batch 37/64 loss: 0.2896326780319214
Batch 38/64 loss: 0.29687660932540894
Batch 39/64 loss: 0.29367756843566895
Batch 40/64 loss: 0.27856433391571045
Batch 41/64 loss: 0.27996504306793213
Batch 42/64 loss: 0.30233198404312134
Batch 43/64 loss: 0.27719348669052124
Batch 44/64 loss: 0.28921377658843994
Batch 45/64 loss: 0.2761535048484802
Batch 46/64 loss: 0.29249274730682373
Batch 47/64 loss: 0.29018521308898926
Batch 48/64 loss: 0.2910884618759155
Batch 49/64 loss: 0.27258503437042236
Batch 50/64 loss: 0.2794376611709595
Batch 51/64 loss: 0.2825050354003906
Batch 52/64 loss: 0.2956635355949402
Batch 53/64 loss: 0.28738826513290405
Batch 54/64 loss: 0.2923020124435425
Batch 55/64 loss: 0.2879261374473572
Batch 56/64 loss: 0.29199492931365967
Batch 57/64 loss: 0.2945935130119324
Batch 58/64 loss: 0.30312579870224
Batch 59/64 loss: 0.27696871757507324
Batch 60/64 loss: 0.29019880294799805
Batch 61/64 loss: 0.2859863042831421
Batch 62/64 loss: 0.28507375717163086
Batch 63/64 loss: 0.2880297899246216
Batch 64/64 loss: 0.2767816185951233
Epoch 444  Train loss: 0.28818789253047866  Val loss: 0.32381145200368877
Epoch 445
-------------------------------
Batch 1/64 loss: 0.285841703414917
Batch 2/64 loss: 0.2835139036178589
Batch 3/64 loss: 0.2862563729286194
Batch 4/64 loss: 0.2847127318382263
Batch 5/64 loss: 0.29422277212142944
Batch 6/64 loss: 0.282184362411499
Batch 7/64 loss: 0.2880547046661377
Batch 8/64 loss: 0.28660130500793457
Batch 9/64 loss: 0.2944489121437073
Batch 10/64 loss: 0.2989753484725952
Batch 11/64 loss: 0.2837439775466919
Batch 12/64 loss: 0.27950429916381836
Batch 13/64 loss: 0.2859398126602173
Batch 14/64 loss: 0.2895488739013672
Batch 15/64 loss: 0.280561625957489
Batch 16/64 loss: 0.28882265090942383
Batch 17/64 loss: 0.28984296321868896
Batch 18/64 loss: 0.297257661819458
Batch 19/64 loss: 0.2818911671638489
Batch 20/64 loss: 0.29071688652038574
Batch 21/64 loss: 0.2759883999824524
Batch 22/64 loss: 0.2996269464492798
Batch 23/64 loss: 0.28530025482177734
Batch 24/64 loss: 0.2874389886856079
Batch 25/64 loss: 0.28825104236602783
Batch 26/64 loss: 0.28281211853027344
Batch 27/64 loss: 0.2878950834274292
Batch 28/64 loss: 0.2819480895996094
Batch 29/64 loss: 0.2952579855918884
Batch 30/64 loss: 0.2880592346191406
Batch 31/64 loss: 0.2847025394439697
Batch 32/64 loss: 0.2832406759262085
Batch 33/64 loss: 0.2899972200393677
Batch 34/64 loss: 0.2821692228317261
Batch 35/64 loss: 0.2883008122444153
Batch 36/64 loss: 0.28840672969818115
Batch 37/64 loss: 0.2919154763221741
Batch 38/64 loss: 0.29268568754196167
Batch 39/64 loss: 0.28388512134552
Batch 40/64 loss: 0.2864672541618347
Batch 41/64 loss: 0.2883901000022888
Batch 42/64 loss: 0.2827644944190979
Batch 43/64 loss: 0.28956305980682373
Batch 44/64 loss: 0.2925156354904175
Batch 45/64 loss: 0.2876090407371521
Batch 46/64 loss: 0.2854952812194824
Batch 47/64 loss: 0.2909731864929199
Batch 48/64 loss: 0.30175888538360596
Batch 49/64 loss: 0.286166787147522
Batch 50/64 loss: 0.2834632992744446
Batch 51/64 loss: 0.28155505657196045
Batch 52/64 loss: 0.2835150957107544
Batch 53/64 loss: 0.2906702756881714
Batch 54/64 loss: 0.28591179847717285
Batch 55/64 loss: 0.2844231128692627
Batch 56/64 loss: 0.29832011461257935
Batch 57/64 loss: 0.29586660861968994
Batch 58/64 loss: 0.28064823150634766
Batch 59/64 loss: 0.287783682346344
Batch 60/64 loss: 0.2880539894104004
Batch 61/64 loss: 0.28885430097579956
Batch 62/64 loss: 0.29065561294555664
Batch 63/64 loss: 0.28810882568359375
Batch 64/64 loss: 0.3034401535987854
Epoch 445  Train loss: 0.2879629413286845  Val loss: 0.3240141846060343
Epoch 446
-------------------------------
Batch 1/64 loss: 0.28489720821380615
Batch 2/64 loss: 0.283463716506958
Batch 3/64 loss: 0.28388798236846924
Batch 4/64 loss: 0.2877134680747986
Batch 5/64 loss: 0.2853325605392456
Batch 6/64 loss: 0.28535985946655273
Batch 7/64 loss: 0.30026358366012573
Batch 8/64 loss: 0.2888396978378296
Batch 9/64 loss: 0.29054921865463257
Batch 10/64 loss: 0.29122495651245117
Batch 11/64 loss: 0.2872222661972046
Batch 12/64 loss: 0.2792050838470459
Batch 13/64 loss: 0.28195858001708984
Batch 14/64 loss: 0.2949521541595459
Batch 15/64 loss: 0.2786511778831482
Batch 16/64 loss: 0.2849392294883728
Batch 17/64 loss: 0.28479599952697754
Batch 18/64 loss: 0.2860778570175171
Batch 19/64 loss: 0.29326677322387695
Batch 20/64 loss: 0.2859419584274292
Batch 21/64 loss: 0.28308647871017456
Batch 22/64 loss: 0.28166598081588745
Batch 23/64 loss: 0.28721797466278076
Batch 24/64 loss: 0.288280189037323
Batch 25/64 loss: 0.27968382835388184
Batch 26/64 loss: 0.28269076347351074
Batch 27/64 loss: 0.2816373109817505
Batch 28/64 loss: 0.2950320243835449
Batch 29/64 loss: 0.3012964725494385
Batch 30/64 loss: 0.29511070251464844
Batch 31/64 loss: 0.28209030628204346
Batch 32/64 loss: 0.2864663600921631
Batch 33/64 loss: 0.2909458875656128
Batch 34/64 loss: 0.2919553518295288
Batch 35/64 loss: 0.286426305770874
Batch 36/64 loss: 0.295837938785553
Batch 37/64 loss: 0.294705331325531
Batch 38/64 loss: 0.2816222906112671
Batch 39/64 loss: 0.2862180471420288
Batch 40/64 loss: 0.289842426776886
Batch 41/64 loss: 0.2883497476577759
Batch 42/64 loss: 0.29557204246520996
Batch 43/64 loss: 0.29361510276794434
Batch 44/64 loss: 0.29477494955062866
Batch 45/64 loss: 0.293948769569397
Batch 46/64 loss: 0.2937946915626526
Batch 47/64 loss: 0.28481394052505493
Batch 48/64 loss: 0.2852909564971924
Batch 49/64 loss: 0.28924036026000977
Batch 50/64 loss: 0.2830442190170288
Batch 51/64 loss: 0.2885136604309082
Batch 52/64 loss: 0.2918306589126587
Batch 53/64 loss: 0.2962881326675415
Batch 54/64 loss: 0.2871074676513672
Batch 55/64 loss: 0.27607905864715576
Batch 56/64 loss: 0.28586292266845703
Batch 57/64 loss: 0.2949230670928955
Batch 58/64 loss: 0.2834252119064331
Batch 59/64 loss: 0.2810520529747009
Batch 60/64 loss: 0.2799391746520996
Batch 61/64 loss: 0.2854100465774536
Batch 62/64 loss: 0.29739558696746826
Batch 63/64 loss: 0.2893933057785034
Batch 64/64 loss: 0.30274462699890137
Epoch 446  Train loss: 0.28811104157391715  Val loss: 0.32398333377444866
Epoch 447
-------------------------------
Batch 1/64 loss: 0.28820300102233887
Batch 2/64 loss: 0.2824370265007019
Batch 3/64 loss: 0.2801889181137085
Batch 4/64 loss: 0.28578412532806396
Batch 5/64 loss: 0.28486108779907227
Batch 6/64 loss: 0.28913259506225586
Batch 7/64 loss: 0.28405624628067017
Batch 8/64 loss: 0.28153741359710693
Batch 9/64 loss: 0.2990427017211914
Batch 10/64 loss: 0.29000723361968994
Batch 11/64 loss: 0.29465198516845703
Batch 12/64 loss: 0.28002405166625977
Batch 13/64 loss: 0.2789829969406128
Batch 14/64 loss: 0.2907918691635132
Batch 15/64 loss: 0.30204182863235474
Batch 16/64 loss: 0.2755376696586609
Batch 17/64 loss: 0.28374868631362915
Batch 18/64 loss: 0.2885441184043884
Batch 19/64 loss: 0.28045332431793213
Batch 20/64 loss: 0.28457701206207275
Batch 21/64 loss: 0.2860555052757263
Batch 22/64 loss: 0.2842908501625061
Batch 23/64 loss: 0.29072296619415283
Batch 24/64 loss: 0.28723931312561035
Batch 25/64 loss: 0.2843738794326782
Batch 26/64 loss: 0.2803797721862793
Batch 27/64 loss: 0.2883908748626709
Batch 28/64 loss: 0.283236026763916
Batch 29/64 loss: 0.28509247303009033
Batch 30/64 loss: 0.28039997816085815
Batch 31/64 loss: 0.2888708710670471
Batch 32/64 loss: 0.282071590423584
Batch 33/64 loss: 0.28853416442871094
Batch 34/64 loss: 0.2907283306121826
Batch 35/64 loss: 0.287678599357605
Batch 36/64 loss: 0.296286940574646
Batch 37/64 loss: 0.2819366455078125
Batch 38/64 loss: 0.2983543872833252
Batch 39/64 loss: 0.28777074813842773
Batch 40/64 loss: 0.2883932590484619
Batch 41/64 loss: 0.30160456895828247
Batch 42/64 loss: 0.28714680671691895
Batch 43/64 loss: 0.281716525554657
Batch 44/64 loss: 0.29035401344299316
Batch 45/64 loss: 0.2936078906059265
Batch 46/64 loss: 0.28359460830688477
Batch 47/64 loss: 0.2891218662261963
Batch 48/64 loss: 0.29004770517349243
Batch 49/64 loss: 0.2851349711418152
Batch 50/64 loss: 0.2828536033630371
Batch 51/64 loss: 0.287173330783844
Batch 52/64 loss: 0.2898728847503662
Batch 53/64 loss: 0.2905707359313965
Batch 54/64 loss: 0.2901880145072937
Batch 55/64 loss: 0.28770560026168823
Batch 56/64 loss: 0.28808730840682983
Batch 57/64 loss: 0.2942652106285095
Batch 58/64 loss: 0.28611528873443604
Batch 59/64 loss: 0.292244553565979
Batch 60/64 loss: 0.2907294034957886
Batch 61/64 loss: 0.29304999113082886
Batch 62/64 loss: 0.28565001487731934
Batch 63/64 loss: 0.28230804204940796
Batch 64/64 loss: 0.2853778600692749
Epoch 447  Train loss: 0.28741313569685994  Val loss: 0.32256590459764617
Saving best model, epoch: 447
Epoch 448
-------------------------------
Batch 1/64 loss: 0.2820662260055542
Batch 2/64 loss: 0.2831634283065796
Batch 3/64 loss: 0.28696155548095703
Batch 4/64 loss: 0.2851995825767517
Batch 5/64 loss: 0.27653324604034424
Batch 6/64 loss: 0.28186750411987305
Batch 7/64 loss: 0.2936261296272278
Batch 8/64 loss: 0.2891775965690613
Batch 9/64 loss: 0.29662734270095825
Batch 10/64 loss: 0.2888221740722656
Batch 11/64 loss: 0.28761547803878784
Batch 12/64 loss: 0.2877872586250305
Batch 13/64 loss: 0.29006528854370117
Batch 14/64 loss: 0.2839711904525757
Batch 15/64 loss: 0.2855488061904907
Batch 16/64 loss: 0.2828637957572937
Batch 17/64 loss: 0.28607022762298584
Batch 18/64 loss: 0.2853837013244629
Batch 19/64 loss: 0.28384244441986084
Batch 20/64 loss: 0.28252267837524414
Batch 21/64 loss: 0.28232550621032715
Batch 22/64 loss: 0.2809802293777466
Batch 23/64 loss: 0.29323434829711914
Batch 24/64 loss: 0.2888205051422119
Batch 25/64 loss: 0.2931993007659912
Batch 26/64 loss: 0.2957925796508789
Batch 27/64 loss: 0.2922787666320801
Batch 28/64 loss: 0.2930147647857666
Batch 29/64 loss: 0.29498088359832764
Batch 30/64 loss: 0.29263556003570557
Batch 31/64 loss: 0.28583747148513794
Batch 32/64 loss: 0.29361391067504883
Batch 33/64 loss: 0.2913593053817749
Batch 34/64 loss: 0.28911489248275757
Batch 35/64 loss: 0.2947739362716675
Batch 36/64 loss: 0.28423207998275757
Batch 37/64 loss: 0.27593934535980225
Batch 38/64 loss: 0.28199946880340576
Batch 39/64 loss: 0.2949839234352112
Batch 40/64 loss: 0.28204333782196045
Batch 41/64 loss: 0.2946810722351074
Batch 42/64 loss: 0.28198593854904175
Batch 43/64 loss: 0.2930731773376465
Batch 44/64 loss: 0.2862814664840698
Batch 45/64 loss: 0.2898901700973511
Batch 46/64 loss: 0.2864571809768677
Batch 47/64 loss: 0.29133403301239014
Batch 48/64 loss: 0.2805224657058716
Batch 49/64 loss: 0.29093027114868164
Batch 50/64 loss: 0.2815910577774048
Batch 51/64 loss: 0.28452932834625244
Batch 52/64 loss: 0.2811667323112488
Batch 53/64 loss: 0.2910274267196655
Batch 54/64 loss: 0.28993725776672363
Batch 55/64 loss: 0.2833637595176697
Batch 56/64 loss: 0.28595948219299316
Batch 57/64 loss: 0.2891530394554138
Batch 58/64 loss: 0.2976747751235962
Batch 59/64 loss: 0.2937953472137451
Batch 60/64 loss: 0.28018736839294434
Batch 61/64 loss: 0.3038088083267212
Batch 62/64 loss: 0.2824366092681885
Batch 63/64 loss: 0.2809599041938782
Batch 64/64 loss: 0.28923845291137695
Epoch 448  Train loss: 0.28766354953541473  Val loss: 0.322611913648258
Epoch 449
-------------------------------
Batch 1/64 loss: 0.2842721939086914
Batch 2/64 loss: 0.29373812675476074
Batch 3/64 loss: 0.282701313495636
Batch 4/64 loss: 0.28052234649658203
Batch 5/64 loss: 0.28553712368011475
Batch 6/64 loss: 0.3034188747406006
Batch 7/64 loss: 0.2775079607963562
Batch 8/64 loss: 0.29022109508514404
Batch 9/64 loss: 0.29071593284606934
Batch 10/64 loss: 0.28488779067993164
Batch 11/64 loss: 0.2876676321029663
Batch 12/64 loss: 0.2778841257095337
Batch 13/64 loss: 0.28577375411987305
Batch 14/64 loss: 0.2889134883880615
Batch 15/64 loss: 0.2855943441390991
Batch 16/64 loss: 0.29132115840911865
Batch 17/64 loss: 0.2742750644683838
Batch 18/64 loss: 0.29671549797058105
Batch 19/64 loss: 0.2902616262435913
Batch 20/64 loss: 0.27964210510253906
Batch 21/64 loss: 0.28502100706100464
Batch 22/64 loss: 0.29660916328430176
Batch 23/64 loss: 0.2923276424407959
Batch 24/64 loss: 0.2889634370803833
Batch 25/64 loss: 0.2813527584075928
Batch 26/64 loss: 0.29620790481567383
Batch 27/64 loss: 0.29063600301742554
Batch 28/64 loss: 0.27623188495635986
Batch 29/64 loss: 0.2885742783546448
Batch 30/64 loss: 0.28691279888153076
Batch 31/64 loss: 0.29805755615234375
Batch 32/64 loss: 0.2944236397743225
Batch 33/64 loss: 0.2919059991836548
Batch 34/64 loss: 0.2966732978820801
Batch 35/64 loss: 0.27722251415252686
Batch 36/64 loss: 0.3001701831817627
Batch 37/64 loss: 0.28723084926605225
Batch 38/64 loss: 0.27239030599594116
Batch 39/64 loss: 0.2863909602165222
Batch 40/64 loss: 0.28073829412460327
Batch 41/64 loss: 0.2838103771209717
Batch 42/64 loss: 0.2938401699066162
Batch 43/64 loss: 0.2899935245513916
Batch 44/64 loss: 0.2748197913169861
Batch 45/64 loss: 0.2948988676071167
Batch 46/64 loss: 0.27943992614746094
Batch 47/64 loss: 0.293725848197937
Batch 48/64 loss: 0.2937912344932556
Batch 49/64 loss: 0.2909461259841919
Batch 50/64 loss: 0.27767860889434814
Batch 51/64 loss: 0.2861025333404541
Batch 52/64 loss: 0.29938197135925293
Batch 53/64 loss: 0.2787892818450928
Batch 54/64 loss: 0.28997939825057983
Batch 55/64 loss: 0.3044748902320862
Batch 56/64 loss: 0.28752684593200684
Batch 57/64 loss: 0.2910655736923218
Batch 58/64 loss: 0.2828737497329712
Batch 59/64 loss: 0.28279685974121094
Batch 60/64 loss: 0.29126787185668945
Batch 61/64 loss: 0.28429603576660156
Batch 62/64 loss: 0.28918612003326416
Batch 63/64 loss: 0.286004900932312
Batch 64/64 loss: 0.28461581468582153
Epoch 449  Train loss: 0.28768257884418263  Val loss: 0.3230106853127889
Epoch 450
-------------------------------
Batch 1/64 loss: 0.29401731491088867
Batch 2/64 loss: 0.2908303737640381
Batch 3/64 loss: 0.28371381759643555
Batch 4/64 loss: 0.2901662588119507
Batch 5/64 loss: 0.2916027307510376
Batch 6/64 loss: 0.2889162302017212
Batch 7/64 loss: 0.28485214710235596
Batch 8/64 loss: 0.28682470321655273
Batch 9/64 loss: 0.2842353582382202
Batch 10/64 loss: 0.2965296506881714
Batch 11/64 loss: 0.295096218585968
Batch 12/64 loss: 0.3000577688217163
Batch 13/64 loss: 0.28433477878570557
Batch 14/64 loss: 0.2884255647659302
Batch 15/64 loss: 0.2915928363800049
Batch 16/64 loss: 0.29441338777542114
Batch 17/64 loss: 0.28485268354415894
Batch 18/64 loss: 0.2917175889015198
Batch 19/64 loss: 0.289935827255249
Batch 20/64 loss: 0.2791407108306885
Batch 21/64 loss: 0.2932854890823364
Batch 22/64 loss: 0.290979266166687
Batch 23/64 loss: 0.2925182580947876
Batch 24/64 loss: 0.29375672340393066
Batch 25/64 loss: 0.2786109447479248
Batch 26/64 loss: 0.29732322692871094
Batch 27/64 loss: 0.29650425910949707
Batch 28/64 loss: 0.2977687120437622
Batch 29/64 loss: 0.280368447303772
Batch 30/64 loss: 0.2876068353652954
Batch 31/64 loss: 0.2851524353027344
Batch 32/64 loss: 0.2836850881576538
Batch 33/64 loss: 0.2841958999633789
Batch 34/64 loss: 0.29268860816955566
Batch 35/64 loss: 0.2882101535797119
Batch 36/64 loss: 0.2818741798400879
Batch 37/64 loss: 0.27926576137542725
Batch 38/64 loss: 0.2918383479118347
Batch 39/64 loss: 0.2920730710029602
Batch 40/64 loss: 0.28596794605255127
Batch 41/64 loss: 0.2914069890975952
Batch 42/64 loss: 0.29401689767837524
Batch 43/64 loss: 0.29590916633605957
Batch 44/64 loss: 0.2849969267845154
Batch 45/64 loss: 0.2879498600959778
Batch 46/64 loss: 0.29062020778656006
Batch 47/64 loss: 0.2856132984161377
Batch 48/64 loss: 0.28183895349502563
Batch 49/64 loss: 0.28453099727630615
Batch 50/64 loss: 0.2940143942832947
Batch 51/64 loss: 0.2917882204055786
Batch 52/64 loss: 0.27957284450531006
Batch 53/64 loss: 0.2774348258972168
Batch 54/64 loss: 0.28489285707473755
Batch 55/64 loss: 0.2783879041671753
Batch 56/64 loss: 0.2839353680610657
Batch 57/64 loss: 0.2939640283584595
Batch 58/64 loss: 0.2875789403915405
Batch 59/64 loss: 0.2753279209136963
Batch 60/64 loss: 0.28431999683380127
Batch 61/64 loss: 0.2796543836593628
Batch 62/64 loss: 0.2903415560722351
Batch 63/64 loss: 0.28678011894226074
Batch 64/64 loss: 0.27671802043914795
Epoch 450  Train loss: 0.2879583494335997  Val loss: 0.3231175593084486
Epoch 451
-------------------------------
Batch 1/64 loss: 0.28766024112701416
Batch 2/64 loss: 0.2878960967063904
Batch 3/64 loss: 0.30050086975097656
Batch 4/64 loss: 0.2900652289390564
Batch 5/64 loss: 0.2937980890274048
Batch 6/64 loss: 0.27838820219039917
Batch 7/64 loss: 0.2954678535461426
Batch 8/64 loss: 0.2829146385192871
Batch 9/64 loss: 0.28502750396728516
Batch 10/64 loss: 0.28954875469207764
Batch 11/64 loss: 0.28314316272735596
Batch 12/64 loss: 0.2779654264450073
Batch 13/64 loss: 0.30024147033691406
Batch 14/64 loss: 0.2859412431716919
Batch 15/64 loss: 0.29299986362457275
Batch 16/64 loss: 0.2864476442337036
Batch 17/64 loss: 0.2875746488571167
Batch 18/64 loss: 0.2761305570602417
Batch 19/64 loss: 0.28772884607315063
Batch 20/64 loss: 0.28801119327545166
Batch 21/64 loss: 0.2771371603012085
Batch 22/64 loss: 0.28564614057540894
Batch 23/64 loss: 0.27833205461502075
Batch 24/64 loss: 0.29075706005096436
Batch 25/64 loss: 0.29095733165740967
Batch 26/64 loss: 0.2919952869415283
Batch 27/64 loss: 0.2839394807815552
Batch 28/64 loss: 0.28439104557037354
Batch 29/64 loss: 0.2873098850250244
Batch 30/64 loss: 0.29090559482574463
Batch 31/64 loss: 0.28691160678863525
Batch 32/64 loss: 0.2795146703720093
Batch 33/64 loss: 0.27623844146728516
Batch 34/64 loss: 0.28382378816604614
Batch 35/64 loss: 0.29561662673950195
Batch 36/64 loss: 0.28954797983169556
Batch 37/64 loss: 0.28247058391571045
Batch 38/64 loss: 0.29368072748184204
Batch 39/64 loss: 0.30122917890548706
Batch 40/64 loss: 0.2894021272659302
Batch 41/64 loss: 0.2950798273086548
Batch 42/64 loss: 0.2851693630218506
Batch 43/64 loss: 0.29448312520980835
Batch 44/64 loss: 0.2965681552886963
Batch 45/64 loss: 0.279543936252594
Batch 46/64 loss: 0.2807788848876953
Batch 47/64 loss: 0.2839195132255554
Batch 48/64 loss: 0.2875708341598511
Batch 49/64 loss: 0.2815527319908142
Batch 50/64 loss: 0.2906290888786316
Batch 51/64 loss: 0.2889174818992615
Batch 52/64 loss: 0.2857590913772583
Batch 53/64 loss: 0.300895094871521
Batch 54/64 loss: 0.28722333908081055
Batch 55/64 loss: 0.29737424850463867
Batch 56/64 loss: 0.2878628969192505
Batch 57/64 loss: 0.29236531257629395
Batch 58/64 loss: 0.2855110168457031
Batch 59/64 loss: 0.2894657254219055
Batch 60/64 loss: 0.28512245416641235
Batch 61/64 loss: 0.2946213483810425
Batch 62/64 loss: 0.2927784323692322
Batch 63/64 loss: 0.2945202589035034
Batch 64/64 loss: 0.2922278642654419
Epoch 451  Train loss: 0.28822182533787744  Val loss: 0.32368265066769525
Epoch 452
-------------------------------
Batch 1/64 loss: 0.2890859842300415
Batch 2/64 loss: 0.28331267833709717
Batch 3/64 loss: 0.2877551317214966
Batch 4/64 loss: 0.2901594638824463
Batch 5/64 loss: 0.2804988622665405
Batch 6/64 loss: 0.2956055998802185
Batch 7/64 loss: 0.2896079421043396
Batch 8/64 loss: 0.30106616020202637
Batch 9/64 loss: 0.2898232340812683
Batch 10/64 loss: 0.2852047085762024
Batch 11/64 loss: 0.2819151282310486
Batch 12/64 loss: 0.28840845823287964
Batch 13/64 loss: 0.2831176519393921
Batch 14/64 loss: 0.29132741689682007
Batch 15/64 loss: 0.28561103343963623
Batch 16/64 loss: 0.2875123620033264
Batch 17/64 loss: 0.29461026191711426
Batch 18/64 loss: 0.2893826365470886
Batch 19/64 loss: 0.2823963165283203
Batch 20/64 loss: 0.29827213287353516
Batch 21/64 loss: 0.2785837650299072
Batch 22/64 loss: 0.2851495146751404
Batch 23/64 loss: 0.2810813784599304
Batch 24/64 loss: 0.2886468172073364
Batch 25/64 loss: 0.2852441072463989
Batch 26/64 loss: 0.2980905771255493
Batch 27/64 loss: 0.2956504225730896
Batch 28/64 loss: 0.28947049379348755
Batch 29/64 loss: 0.2806054949760437
Batch 30/64 loss: 0.28985267877578735
Batch 31/64 loss: 0.2845081090927124
Batch 32/64 loss: 0.2984426021575928
Batch 33/64 loss: 0.2902635335922241
Batch 34/64 loss: 0.2762950658798218
Batch 35/64 loss: 0.289600133895874
Batch 36/64 loss: 0.2882370948791504
Batch 37/64 loss: 0.2858569622039795
Batch 38/64 loss: 0.27689749002456665
Batch 39/64 loss: 0.28502368927001953
Batch 40/64 loss: 0.2914029359817505
Batch 41/64 loss: 0.2875332236289978
Batch 42/64 loss: 0.2856646180152893
Batch 43/64 loss: 0.2801945209503174
Batch 44/64 loss: 0.2758040428161621
Batch 45/64 loss: 0.2840232849121094
Batch 46/64 loss: 0.2960812449455261
Batch 47/64 loss: 0.2860892415046692
Batch 48/64 loss: 0.29618674516677856
Batch 49/64 loss: 0.28182661533355713
Batch 50/64 loss: 0.29384660720825195
Batch 51/64 loss: 0.28086674213409424
Batch 52/64 loss: 0.280498743057251
Batch 53/64 loss: 0.2841278910636902
Batch 54/64 loss: 0.2813544273376465
Batch 55/64 loss: 0.28473877906799316
Batch 56/64 loss: 0.29221785068511963
Batch 57/64 loss: 0.2816145420074463
Batch 58/64 loss: 0.28918886184692383
Batch 59/64 loss: 0.2821321487426758
Batch 60/64 loss: 0.28551262617111206
Batch 61/64 loss: 0.2838627099990845
Batch 62/64 loss: 0.2934108376502991
Batch 63/64 loss: 0.2877103090286255
Batch 64/64 loss: 0.29089295864105225
Epoch 452  Train loss: 0.2871565860860488  Val loss: 0.32338536051950095
Epoch 453
-------------------------------
Batch 1/64 loss: 0.28555619716644287
Batch 2/64 loss: 0.2843904495239258
Batch 3/64 loss: 0.2959533929824829
Batch 4/64 loss: 0.28221797943115234
Batch 5/64 loss: 0.2991575002670288
Batch 6/64 loss: 0.28087735176086426
Batch 7/64 loss: 0.2803029417991638
Batch 8/64 loss: 0.2833658456802368
Batch 9/64 loss: 0.2930920124053955
Batch 10/64 loss: 0.2803650498390198
Batch 11/64 loss: 0.2878567576408386
Batch 12/64 loss: 0.2834285497665405
Batch 13/64 loss: 0.2838067412376404
Batch 14/64 loss: 0.29262518882751465
Batch 15/64 loss: 0.29593968391418457
Batch 16/64 loss: 0.2802966833114624
Batch 17/64 loss: 0.30121850967407227
Batch 18/64 loss: 0.2864340543746948
Batch 19/64 loss: 0.2932162284851074
Batch 20/64 loss: 0.2794339060783386
Batch 21/64 loss: 0.2832065224647522
Batch 22/64 loss: 0.28632086515426636
Batch 23/64 loss: 0.29491281509399414
Batch 24/64 loss: 0.2853069305419922
Batch 25/64 loss: 0.2878078818321228
Batch 26/64 loss: 0.2820237874984741
Batch 27/64 loss: 0.2918287515640259
Batch 28/64 loss: 0.28954780101776123
Batch 29/64 loss: 0.27855217456817627
Batch 30/64 loss: 0.2925378680229187
Batch 31/64 loss: 0.2849453091621399
Batch 32/64 loss: 0.2853299379348755
Batch 33/64 loss: 0.26923471689224243
Batch 34/64 loss: 0.29122501611709595
Batch 35/64 loss: 0.29782140254974365
Batch 36/64 loss: 0.2993849515914917
Batch 37/64 loss: 0.28955990076065063
Batch 38/64 loss: 0.2901860475540161
Batch 39/64 loss: 0.29585814476013184
Batch 40/64 loss: 0.28397130966186523
Batch 41/64 loss: 0.2906467318534851
Batch 42/64 loss: 0.28921228647232056
Batch 43/64 loss: 0.2810347080230713
Batch 44/64 loss: 0.2890061140060425
Batch 45/64 loss: 0.27720004320144653
Batch 46/64 loss: 0.2837144136428833
Batch 47/64 loss: 0.2887303829193115
Batch 48/64 loss: 0.2856270670890808
Batch 49/64 loss: 0.28657007217407227
Batch 50/64 loss: 0.2776799201965332
Batch 51/64 loss: 0.28652095794677734
Batch 52/64 loss: 0.2855401039123535
Batch 53/64 loss: 0.2820095419883728
Batch 54/64 loss: 0.29969698190689087
Batch 55/64 loss: 0.2798462510108948
Batch 56/64 loss: 0.2850446105003357
Batch 57/64 loss: 0.2801308035850525
Batch 58/64 loss: 0.30145227909088135
Batch 59/64 loss: 0.2889103889465332
Batch 60/64 loss: 0.2897496223449707
Batch 61/64 loss: 0.2834247946739197
Batch 62/64 loss: 0.2881045937538147
Batch 63/64 loss: 0.2970171570777893
Batch 64/64 loss: 0.2831695079803467
Epoch 453  Train loss: 0.2873465743719363  Val loss: 0.3237887291154501
Epoch 454
-------------------------------
Batch 1/64 loss: 0.28367090225219727
Batch 2/64 loss: 0.2874460220336914
Batch 3/64 loss: 0.28679192066192627
Batch 4/64 loss: 0.28744274377822876
Batch 5/64 loss: 0.2802712917327881
Batch 6/64 loss: 0.28676700592041016
Batch 7/64 loss: 0.2858487367630005
Batch 8/64 loss: 0.30467456579208374
Batch 9/64 loss: 0.27542853355407715
Batch 10/64 loss: 0.2867200970649719
Batch 11/64 loss: 0.2728106379508972
Batch 12/64 loss: 0.28351956605911255
Batch 13/64 loss: 0.27784544229507446
Batch 14/64 loss: 0.295440137386322
Batch 15/64 loss: 0.2866487503051758
Batch 16/64 loss: 0.2831675410270691
Batch 17/64 loss: 0.289279580116272
Batch 18/64 loss: 0.2978264093399048
Batch 19/64 loss: 0.2816493511199951
Batch 20/64 loss: 0.28213614225387573
Batch 21/64 loss: 0.287129282951355
Batch 22/64 loss: 0.29155421257019043
Batch 23/64 loss: 0.27883803844451904
Batch 24/64 loss: 0.287395179271698
Batch 25/64 loss: 0.28047311305999756
Batch 26/64 loss: 0.2980843186378479
Batch 27/64 loss: 0.28967511653900146
Batch 28/64 loss: 0.2930724024772644
Batch 29/64 loss: 0.28933626413345337
Batch 30/64 loss: 0.28745341300964355
Batch 31/64 loss: 0.28903651237487793
Batch 32/64 loss: 0.29289543628692627
Batch 33/64 loss: 0.29179245233535767
Batch 34/64 loss: 0.2824854850769043
Batch 35/64 loss: 0.2835993766784668
Batch 36/64 loss: 0.28827303647994995
Batch 37/64 loss: 0.27853572368621826
Batch 38/64 loss: 0.28642594814300537
Batch 39/64 loss: 0.2901301383972168
Batch 40/64 loss: 0.2908618450164795
Batch 41/64 loss: 0.2879250645637512
Batch 42/64 loss: 0.29462021589279175
Batch 43/64 loss: 0.2814524173736572
Batch 44/64 loss: 0.281982421875
Batch 45/64 loss: 0.30550646781921387
Batch 46/64 loss: 0.2802398204803467
Batch 47/64 loss: 0.2961350679397583
Batch 48/64 loss: 0.282861590385437
Batch 49/64 loss: 0.2803232669830322
Batch 50/64 loss: 0.2848724126815796
Batch 51/64 loss: 0.2825819253921509
Batch 52/64 loss: 0.289440393447876
Batch 53/64 loss: 0.2802894115447998
Batch 54/64 loss: 0.29960203170776367
Batch 55/64 loss: 0.28716421127319336
Batch 56/64 loss: 0.2870149612426758
Batch 57/64 loss: 0.2871953248977661
Batch 58/64 loss: 0.2839805483818054
Batch 59/64 loss: 0.2834637761116028
Batch 60/64 loss: 0.28323185443878174
Batch 61/64 loss: 0.2868661880493164
Batch 62/64 loss: 0.28826260566711426
Batch 63/64 loss: 0.2825082540512085
Batch 64/64 loss: 0.2828139662742615
Epoch 454  Train loss: 0.28677746478249044  Val loss: 0.3220677986177792
Saving best model, epoch: 454
Epoch 455
-------------------------------
Batch 1/64 loss: 0.2805383801460266
Batch 2/64 loss: 0.2883789539337158
Batch 3/64 loss: 0.2923237085342407
Batch 4/64 loss: 0.2894015908241272
Batch 5/64 loss: 0.29338139295578003
Batch 6/64 loss: 0.2766379117965698
Batch 7/64 loss: 0.2897797226905823
Batch 8/64 loss: 0.2833377718925476
Batch 9/64 loss: 0.2857574224472046
Batch 10/64 loss: 0.2930036783218384
Batch 11/64 loss: 0.2872697114944458
Batch 12/64 loss: 0.28175556659698486
Batch 13/64 loss: 0.28586822748184204
Batch 14/64 loss: 0.284324049949646
Batch 15/64 loss: 0.279927134513855
Batch 16/64 loss: 0.2848484516143799
Batch 17/64 loss: 0.28510451316833496
Batch 18/64 loss: 0.29102200269699097
Batch 19/64 loss: 0.28029555082321167
Batch 20/64 loss: 0.2908104658126831
Batch 21/64 loss: 0.28597939014434814
Batch 22/64 loss: 0.2867213487625122
Batch 23/64 loss: 0.28791165351867676
Batch 24/64 loss: 0.2857382297515869
Batch 25/64 loss: 0.28813135623931885
Batch 26/64 loss: 0.2887589931488037
Batch 27/64 loss: 0.2887091636657715
Batch 28/64 loss: 0.28559768199920654
Batch 29/64 loss: 0.2886533737182617
Batch 30/64 loss: 0.2847937345504761
Batch 31/64 loss: 0.2847510576248169
Batch 32/64 loss: 0.27996039390563965
Batch 33/64 loss: 0.2864198684692383
Batch 34/64 loss: 0.2816460132598877
Batch 35/64 loss: 0.2814725637435913
Batch 36/64 loss: 0.3018296957015991
Batch 37/64 loss: 0.28224629163742065
Batch 38/64 loss: 0.2990298271179199
Batch 39/64 loss: 0.2866091728210449
Batch 40/64 loss: 0.28340452909469604
Batch 41/64 loss: 0.2771819829940796
Batch 42/64 loss: 0.2853652238845825
Batch 43/64 loss: 0.2829517126083374
Batch 44/64 loss: 0.29989373683929443
Batch 45/64 loss: 0.2833724617958069
Batch 46/64 loss: 0.2831938862800598
Batch 47/64 loss: 0.2828187942504883
Batch 48/64 loss: 0.28093039989471436
Batch 49/64 loss: 0.2975125312805176
Batch 50/64 loss: 0.28285646438598633
Batch 51/64 loss: 0.28678858280181885
Batch 52/64 loss: 0.2826153039932251
Batch 53/64 loss: 0.28676724433898926
Batch 54/64 loss: 0.3016818165779114
Batch 55/64 loss: 0.2807217836380005
Batch 56/64 loss: 0.28628069162368774
Batch 57/64 loss: 0.3013576865196228
Batch 58/64 loss: 0.28502845764160156
Batch 59/64 loss: 0.2811448574066162
Batch 60/64 loss: 0.2870931625366211
Batch 61/64 loss: 0.28657519817352295
Batch 62/64 loss: 0.29259270429611206
Batch 63/64 loss: 0.28698253631591797
Batch 64/64 loss: 0.2896900177001953
Epoch 455  Train loss: 0.28676243576349  Val loss: 0.3244969953376403
Epoch 456
-------------------------------
Batch 1/64 loss: 0.28441286087036133
Batch 2/64 loss: 0.2738966941833496
Batch 3/64 loss: 0.28646188974380493
Batch 4/64 loss: 0.2846719026565552
Batch 5/64 loss: 0.2910143733024597
Batch 6/64 loss: 0.2889178991317749
Batch 7/64 loss: 0.2864404320716858
Batch 8/64 loss: 0.2919015884399414
Batch 9/64 loss: 0.2825871706008911
Batch 10/64 loss: 0.2749910354614258
Batch 11/64 loss: 0.2872897982597351
Batch 12/64 loss: 0.28603702783584595
Batch 13/64 loss: 0.2917695641517639
Batch 14/64 loss: 0.29205161333084106
Batch 15/64 loss: 0.28270524740219116
Batch 16/64 loss: 0.28169798851013184
Batch 17/64 loss: 0.28569674491882324
Batch 18/64 loss: 0.28236424922943115
Batch 19/64 loss: 0.2820451259613037
Batch 20/64 loss: 0.2804204225540161
Batch 21/64 loss: 0.2874099016189575
Batch 22/64 loss: 0.2838972806930542
Batch 23/64 loss: 0.28916752338409424
Batch 24/64 loss: 0.28862154483795166
Batch 25/64 loss: 0.2905229926109314
Batch 26/64 loss: 0.2866266369819641
Batch 27/64 loss: 0.2891634702682495
Batch 28/64 loss: 0.29979008436203003
Batch 29/64 loss: 0.2909303307533264
Batch 30/64 loss: 0.2782618999481201
Batch 31/64 loss: 0.2807726263999939
Batch 32/64 loss: 0.29203689098358154
Batch 33/64 loss: 0.29182612895965576
Batch 34/64 loss: 0.2739487886428833
Batch 35/64 loss: 0.2870369553565979
Batch 36/64 loss: 0.2817913889884949
Batch 37/64 loss: 0.2881741523742676
Batch 38/64 loss: 0.28191107511520386
Batch 39/64 loss: 0.28856390714645386
Batch 40/64 loss: 0.28677064180374146
Batch 41/64 loss: 0.28092026710510254
Batch 42/64 loss: 0.3019142746925354
Batch 43/64 loss: 0.28180992603302
Batch 44/64 loss: 0.287184476852417
Batch 45/64 loss: 0.28446274995803833
Batch 46/64 loss: 0.2885127663612366
Batch 47/64 loss: 0.2794807553291321
Batch 48/64 loss: 0.28764885663986206
Batch 49/64 loss: 0.29330694675445557
Batch 50/64 loss: 0.2871556282043457
Batch 51/64 loss: 0.29150015115737915
Batch 52/64 loss: 0.2872161269187927
Batch 53/64 loss: 0.27618128061294556
Batch 54/64 loss: 0.2858668565750122
Batch 55/64 loss: 0.28785932064056396
Batch 56/64 loss: 0.28470802307128906
Batch 57/64 loss: 0.286368727684021
Batch 58/64 loss: 0.2863178253173828
Batch 59/64 loss: 0.28031015396118164
Batch 60/64 loss: 0.3027278184890747
Batch 61/64 loss: 0.28754693269729614
Batch 62/64 loss: 0.29097700119018555
Batch 63/64 loss: 0.2858494520187378
Batch 64/64 loss: 0.2895163297653198
Epoch 456  Train loss: 0.2863931202421001  Val loss: 0.3242035047295167
Epoch 457
-------------------------------
Batch 1/64 loss: 0.279913067817688
Batch 2/64 loss: 0.293401837348938
Batch 3/64 loss: 0.28500765562057495
Batch 4/64 loss: 0.28641414642333984
Batch 5/64 loss: 0.29576575756073
Batch 6/64 loss: 0.2890145778656006
Batch 7/64 loss: 0.2872593402862549
Batch 8/64 loss: 0.284044086933136
Batch 9/64 loss: 0.2736932039260864
Batch 10/64 loss: 0.29285794496536255
Batch 11/64 loss: 0.2812693119049072
Batch 12/64 loss: 0.29346752166748047
Batch 13/64 loss: 0.2947363257408142
Batch 14/64 loss: 0.2850474715232849
Batch 15/64 loss: 0.27917760610580444
Batch 16/64 loss: 0.28864818811416626
Batch 17/64 loss: 0.28044772148132324
Batch 18/64 loss: 0.29202836751937866
Batch 19/64 loss: 0.2874518632888794
Batch 20/64 loss: 0.28762537240982056
Batch 21/64 loss: 0.2809257507324219
Batch 22/64 loss: 0.2864302396774292
Batch 23/64 loss: 0.2837107181549072
Batch 24/64 loss: 0.3009589910507202
Batch 25/64 loss: 0.2829641103744507
Batch 26/64 loss: 0.2852708101272583
Batch 27/64 loss: 0.28924572467803955
Batch 28/64 loss: 0.2893241047859192
Batch 29/64 loss: 0.28269702196121216
Batch 30/64 loss: 0.2914305329322815
Batch 31/64 loss: 0.28972017765045166
Batch 32/64 loss: 0.2884453535079956
Batch 33/64 loss: 0.28463393449783325
Batch 34/64 loss: 0.29143208265304565
Batch 35/64 loss: 0.2894493341445923
Batch 36/64 loss: 0.27964168787002563
Batch 37/64 loss: 0.29214394092559814
Batch 38/64 loss: 0.28755509853363037
Batch 39/64 loss: 0.2865756154060364
Batch 40/64 loss: 0.28687530755996704
Batch 41/64 loss: 0.27727019786834717
Batch 42/64 loss: 0.2950509190559387
Batch 43/64 loss: 0.282953679561615
Batch 44/64 loss: 0.2772313356399536
Batch 45/64 loss: 0.2927777171134949
Batch 46/64 loss: 0.28720980882644653
Batch 47/64 loss: 0.29956942796707153
Batch 48/64 loss: 0.2886689305305481
Batch 49/64 loss: 0.2811638116836548
Batch 50/64 loss: 0.2840629816055298
Batch 51/64 loss: 0.28789031505584717
Batch 52/64 loss: 0.2877957820892334
Batch 53/64 loss: 0.28131139278411865
Batch 54/64 loss: 0.2761201858520508
Batch 55/64 loss: 0.2868505120277405
Batch 56/64 loss: 0.2897099256515503
Batch 57/64 loss: 0.2844839096069336
Batch 58/64 loss: 0.2907438278198242
Batch 59/64 loss: 0.2946385145187378
Batch 60/64 loss: 0.28213804960250854
Batch 61/64 loss: 0.3015292286872864
Batch 62/64 loss: 0.2732483148574829
Batch 63/64 loss: 0.28727638721466064
Batch 64/64 loss: 0.2891364097595215
Epoch 457  Train loss: 0.2869529312732173  Val loss: 0.3234598001663628
Epoch 458
-------------------------------
Batch 1/64 loss: 0.2835294008255005
Batch 2/64 loss: 0.2846759557723999
Batch 3/64 loss: 0.2906709909439087
Batch 4/64 loss: 0.2776627540588379
Batch 5/64 loss: 0.28042203187942505
Batch 6/64 loss: 0.29026830196380615
Batch 7/64 loss: 0.28635191917419434
Batch 8/64 loss: 0.28372740745544434
Batch 9/64 loss: 0.2838631868362427
Batch 10/64 loss: 0.28577733039855957
Batch 11/64 loss: 0.28319644927978516
Batch 12/64 loss: 0.28459763526916504
Batch 13/64 loss: 0.2926251292228699
Batch 14/64 loss: 0.28115248680114746
Batch 15/64 loss: 0.2846699357032776
Batch 16/64 loss: 0.287742018699646
Batch 17/64 loss: 0.2811218500137329
Batch 18/64 loss: 0.29413849115371704
Batch 19/64 loss: 0.28535425662994385
Batch 20/64 loss: 0.27994513511657715
Batch 21/64 loss: 0.28870439529418945
Batch 22/64 loss: 0.29249662160873413
Batch 23/64 loss: 0.28919517993927
Batch 24/64 loss: 0.2841043472290039
Batch 25/64 loss: 0.2863011360168457
Batch 26/64 loss: 0.2840891480445862
Batch 27/64 loss: 0.28248846530914307
Batch 28/64 loss: 0.28114211559295654
Batch 29/64 loss: 0.29433172941207886
Batch 30/64 loss: 0.28105586767196655
Batch 31/64 loss: 0.28730642795562744
Batch 32/64 loss: 0.28671491146087646
Batch 33/64 loss: 0.2893648147583008
Batch 34/64 loss: 0.28832030296325684
Batch 35/64 loss: 0.27904272079467773
Batch 36/64 loss: 0.2940433621406555
Batch 37/64 loss: 0.2989175319671631
Batch 38/64 loss: 0.2854008674621582
Batch 39/64 loss: 0.2884345054626465
Batch 40/64 loss: 0.2874131202697754
Batch 41/64 loss: 0.2812459468841553
Batch 42/64 loss: 0.280123770236969
Batch 43/64 loss: 0.2871561646461487
Batch 44/64 loss: 0.27195674180984497
Batch 45/64 loss: 0.2838304042816162
Batch 46/64 loss: 0.28731805086135864
Batch 47/64 loss: 0.2842642664909363
Batch 48/64 loss: 0.28333836793899536
Batch 49/64 loss: 0.30132466554641724
Batch 50/64 loss: 0.28255027532577515
Batch 51/64 loss: 0.2920682430267334
Batch 52/64 loss: 0.28699541091918945
Batch 53/64 loss: 0.285020112991333
Batch 54/64 loss: 0.2860509157180786
Batch 55/64 loss: 0.2912399172782898
Batch 56/64 loss: 0.28412115573883057
Batch 57/64 loss: 0.286834716796875
Batch 58/64 loss: 0.29422950744628906
Batch 59/64 loss: 0.28226423263549805
Batch 60/64 loss: 0.2866693139076233
Batch 61/64 loss: 0.2915719747543335
Batch 62/64 loss: 0.2946867346763611
Batch 63/64 loss: 0.2931240200996399
Batch 64/64 loss: 0.27369749546051025
Epoch 458  Train loss: 0.28633126698288264  Val loss: 0.3230629516221404
Epoch 459
-------------------------------
Batch 1/64 loss: 0.28059786558151245
Batch 2/64 loss: 0.2840767502784729
Batch 3/64 loss: 0.2942781448364258
Batch 4/64 loss: 0.28632426261901855
Batch 5/64 loss: 0.2800191640853882
Batch 6/64 loss: 0.2814970016479492
Batch 7/64 loss: 0.287303626537323
Batch 8/64 loss: 0.28669220209121704
Batch 9/64 loss: 0.2827436923980713
Batch 10/64 loss: 0.27575933933258057
Batch 11/64 loss: 0.290111780166626
Batch 12/64 loss: 0.29150116443634033
Batch 13/64 loss: 0.2844947576522827
Batch 14/64 loss: 0.28643798828125
Batch 15/64 loss: 0.2846265435218811
Batch 16/64 loss: 0.276542067527771
Batch 17/64 loss: 0.2877393960952759
Batch 18/64 loss: 0.28670525550842285
Batch 19/64 loss: 0.2891664505004883
Batch 20/64 loss: 0.28513872623443604
Batch 21/64 loss: 0.2998514175415039
Batch 22/64 loss: 0.29123181104660034
Batch 23/64 loss: 0.2856929302215576
Batch 24/64 loss: 0.3015192747116089
Batch 25/64 loss: 0.2850295901298523
Batch 26/64 loss: 0.28472644090652466
Batch 27/64 loss: 0.28586673736572266
Batch 28/64 loss: 0.2741747498512268
Batch 29/64 loss: 0.28438353538513184
Batch 30/64 loss: 0.27773553133010864
Batch 31/64 loss: 0.2867535948753357
Batch 32/64 loss: 0.28930163383483887
Batch 33/64 loss: 0.28316211700439453
Batch 34/64 loss: 0.29089027643203735
Batch 35/64 loss: 0.29627281427383423
Batch 36/64 loss: 0.2888064384460449
Batch 37/64 loss: 0.2849463224411011
Batch 38/64 loss: 0.2864622473716736
Batch 39/64 loss: 0.282201886177063
Batch 40/64 loss: 0.29178106784820557
Batch 41/64 loss: 0.2866097688674927
Batch 42/64 loss: 0.2873038053512573
Batch 43/64 loss: 0.2925158739089966
Batch 44/64 loss: 0.28054672479629517
Batch 45/64 loss: 0.2890125513076782
Batch 46/64 loss: 0.2890655994415283
Batch 47/64 loss: 0.2810400724411011
Batch 48/64 loss: 0.28880220651626587
Batch 49/64 loss: 0.27405261993408203
Batch 50/64 loss: 0.2854093909263611
Batch 51/64 loss: 0.2826803922653198
Batch 52/64 loss: 0.2975386381149292
Batch 53/64 loss: 0.2799120545387268
Batch 54/64 loss: 0.2824140191078186
Batch 55/64 loss: 0.28697335720062256
Batch 56/64 loss: 0.28277885913848877
Batch 57/64 loss: 0.28838634490966797
Batch 58/64 loss: 0.2893531322479248
Batch 59/64 loss: 0.2957613468170166
Batch 60/64 loss: 0.28059959411621094
Batch 61/64 loss: 0.2876814603805542
Batch 62/64 loss: 0.2868691086769104
Batch 63/64 loss: 0.28112876415252686
Batch 64/64 loss: 0.29188597202301025
Epoch 459  Train loss: 0.2862415178149354  Val loss: 0.32369555804328
Epoch 460
-------------------------------
Batch 1/64 loss: 0.2892943024635315
Batch 2/64 loss: 0.2839219570159912
Batch 3/64 loss: 0.29050731658935547
Batch 4/64 loss: 0.2921093702316284
Batch 5/64 loss: 0.2928618788719177
Batch 6/64 loss: 0.28064948320388794
Batch 7/64 loss: 0.2759993076324463
Batch 8/64 loss: 0.30077433586120605
Batch 9/64 loss: 0.2736949324607849
Batch 10/64 loss: 0.28793251514434814
Batch 11/64 loss: 0.2906155586242676
Batch 12/64 loss: 0.2939143180847168
Batch 13/64 loss: 0.2842600345611572
Batch 14/64 loss: 0.28354692459106445
Batch 15/64 loss: 0.28232598304748535
Batch 16/64 loss: 0.28362637758255005
Batch 17/64 loss: 0.28207099437713623
Batch 18/64 loss: 0.2956268787384033
Batch 19/64 loss: 0.3000870943069458
Batch 20/64 loss: 0.29131019115448
Batch 21/64 loss: 0.2830784320831299
Batch 22/64 loss: 0.2858346700668335
Batch 23/64 loss: 0.2840583324432373
Batch 24/64 loss: 0.2872347831726074
Batch 25/64 loss: 0.2933872938156128
Batch 26/64 loss: 0.28539973497390747
Batch 27/64 loss: 0.28247976303100586
Batch 28/64 loss: 0.27956855297088623
Batch 29/64 loss: 0.28933608531951904
Batch 30/64 loss: 0.284504771232605
Batch 31/64 loss: 0.281490683555603
Batch 32/64 loss: 0.2816770076751709
Batch 33/64 loss: 0.2949768900871277
Batch 34/64 loss: 0.2742445468902588
Batch 35/64 loss: 0.27841222286224365
Batch 36/64 loss: 0.28922170400619507
Batch 37/64 loss: 0.2856203317642212
Batch 38/64 loss: 0.29036498069763184
Batch 39/64 loss: 0.28283625841140747
Batch 40/64 loss: 0.2868685722351074
Batch 41/64 loss: 0.2907896041870117
Batch 42/64 loss: 0.29558658599853516
Batch 43/64 loss: 0.2866780757904053
Batch 44/64 loss: 0.278322696685791
Batch 45/64 loss: 0.29223549365997314
Batch 46/64 loss: 0.29348838329315186
Batch 47/64 loss: 0.29297006130218506
Batch 48/64 loss: 0.29345107078552246
Batch 49/64 loss: 0.2911725640296936
Batch 50/64 loss: 0.29011964797973633
Batch 51/64 loss: 0.2919580936431885
Batch 52/64 loss: 0.2823837995529175
Batch 53/64 loss: 0.28384315967559814
Batch 54/64 loss: 0.2905706763267517
Batch 55/64 loss: 0.2876625061035156
Batch 56/64 loss: 0.27363741397857666
Batch 57/64 loss: 0.28587067127227783
Batch 58/64 loss: 0.2952021360397339
Batch 59/64 loss: 0.28066718578338623
Batch 60/64 loss: 0.2931690216064453
Batch 61/64 loss: 0.27435874938964844
Batch 62/64 loss: 0.2848208546638489
Batch 63/64 loss: 0.284146785736084
Batch 64/64 loss: 0.28336381912231445
Epoch 460  Train loss: 0.28676632899864046  Val loss: 0.32352544392916754
Epoch 461
-------------------------------
Batch 1/64 loss: 0.2839014530181885
Batch 2/64 loss: 0.27644169330596924
Batch 3/64 loss: 0.29597681760787964
Batch 4/64 loss: 0.28930407762527466
Batch 5/64 loss: 0.286218523979187
Batch 6/64 loss: 0.2845587730407715
Batch 7/64 loss: 0.2836233377456665
Batch 8/64 loss: 0.2793210744857788
Batch 9/64 loss: 0.2861233949661255
Batch 10/64 loss: 0.2880222797393799
Batch 11/64 loss: 0.2814241647720337
Batch 12/64 loss: 0.29687196016311646
Batch 13/64 loss: 0.2796076536178589
Batch 14/64 loss: 0.2850092649459839
Batch 15/64 loss: 0.28666722774505615
Batch 16/64 loss: 0.2881510257720947
Batch 17/64 loss: 0.27889561653137207
Batch 18/64 loss: 0.2900899052619934
Batch 19/64 loss: 0.2823824882507324
Batch 20/64 loss: 0.288308322429657
Batch 21/64 loss: 0.28634804487228394
Batch 22/64 loss: 0.2852964401245117
Batch 23/64 loss: 0.28075891733169556
Batch 24/64 loss: 0.28567951917648315
Batch 25/64 loss: 0.283724308013916
Batch 26/64 loss: 0.2831330895423889
Batch 27/64 loss: 0.2942153811454773
Batch 28/64 loss: 0.28455913066864014
Batch 29/64 loss: 0.2896757125854492
Batch 30/64 loss: 0.2828913927078247
Batch 31/64 loss: 0.28333693742752075
Batch 32/64 loss: 0.27993935346603394
Batch 33/64 loss: 0.2832059860229492
Batch 34/64 loss: 0.29443228244781494
Batch 35/64 loss: 0.28369027376174927
Batch 36/64 loss: 0.2869589328765869
Batch 37/64 loss: 0.28058385848999023
Batch 38/64 loss: 0.2930358648300171
Batch 39/64 loss: 0.2827630043029785
Batch 40/64 loss: 0.2918020486831665
Batch 41/64 loss: 0.2841671109199524
Batch 42/64 loss: 0.2819756865501404
Batch 43/64 loss: 0.29343122243881226
Batch 44/64 loss: 0.2897900342941284
Batch 45/64 loss: 0.28467583656311035
Batch 46/64 loss: 0.2917352318763733
Batch 47/64 loss: 0.28592097759246826
Batch 48/64 loss: 0.28825634717941284
Batch 49/64 loss: 0.29797327518463135
Batch 50/64 loss: 0.2935291528701782
Batch 51/64 loss: 0.2796090245246887
Batch 52/64 loss: 0.30472755432128906
Batch 53/64 loss: 0.29586756229400635
Batch 54/64 loss: 0.28355884552001953
Batch 55/64 loss: 0.2790466547012329
Batch 56/64 loss: 0.281400203704834
Batch 57/64 loss: 0.2896581292152405
Batch 58/64 loss: 0.282323956489563
Batch 59/64 loss: 0.2815099358558655
Batch 60/64 loss: 0.27594947814941406
Batch 61/64 loss: 0.2920723557472229
Batch 62/64 loss: 0.2877753973007202
Batch 63/64 loss: 0.289996862411499
Batch 64/64 loss: 0.290561318397522
Epoch 461  Train loss: 0.286428256595836  Val loss: 0.3232095522159563
Epoch 462
-------------------------------
Batch 1/64 loss: 0.28264951705932617
Batch 2/64 loss: 0.2812594771385193
Batch 3/64 loss: 0.29298049211502075
Batch 4/64 loss: 0.28119003772735596
Batch 5/64 loss: 0.2907641530036926
Batch 6/64 loss: 0.29167890548706055
Batch 7/64 loss: 0.27652502059936523
Batch 8/64 loss: 0.27913999557495117
Batch 9/64 loss: 0.3015419840812683
Batch 10/64 loss: 0.2842094898223877
Batch 11/64 loss: 0.2852899432182312
Batch 12/64 loss: 0.28446531295776367
Batch 13/64 loss: 0.28174686431884766
Batch 14/64 loss: 0.2919771075248718
Batch 15/64 loss: 0.29050779342651367
Batch 16/64 loss: 0.2881770133972168
Batch 17/64 loss: 0.29181647300720215
Batch 18/64 loss: 0.2868829369544983
Batch 19/64 loss: 0.2809833288192749
Batch 20/64 loss: 0.2722485065460205
Batch 21/64 loss: 0.28401756286621094
Batch 22/64 loss: 0.27520835399627686
Batch 23/64 loss: 0.2899971008300781
Batch 24/64 loss: 0.2886543273925781
Batch 25/64 loss: 0.2834385633468628
Batch 26/64 loss: 0.2863808274269104
Batch 27/64 loss: 0.2749514579772949
Batch 28/64 loss: 0.3006492853164673
Batch 29/64 loss: 0.2783544659614563
Batch 30/64 loss: 0.28615498542785645
Batch 31/64 loss: 0.2891885042190552
Batch 32/64 loss: 0.30355125665664673
Batch 33/64 loss: 0.28870677947998047
Batch 34/64 loss: 0.2801079750061035
Batch 35/64 loss: 0.3010542392730713
Batch 36/64 loss: 0.2875319719314575
Batch 37/64 loss: 0.29266834259033203
Batch 38/64 loss: 0.29049158096313477
Batch 39/64 loss: 0.2855401039123535
Batch 40/64 loss: 0.2938503623008728
Batch 41/64 loss: 0.29373645782470703
Batch 42/64 loss: 0.2927483320236206
Batch 43/64 loss: 0.294238805770874
Batch 44/64 loss: 0.290505588054657
Batch 45/64 loss: 0.2968028783798218
Batch 46/64 loss: 0.28028011322021484
Batch 47/64 loss: 0.2815679907798767
Batch 48/64 loss: 0.2910592555999756
Batch 49/64 loss: 0.28539037704467773
Batch 50/64 loss: 0.28645968437194824
Batch 51/64 loss: 0.28492438793182373
Batch 52/64 loss: 0.2919146418571472
Batch 53/64 loss: 0.28778076171875
Batch 54/64 loss: 0.27927637100219727
Batch 55/64 loss: 0.28386998176574707
Batch 56/64 loss: 0.2868790030479431
Batch 57/64 loss: 0.2774384617805481
Batch 58/64 loss: 0.2894461154937744
Batch 59/64 loss: 0.28253525495529175
Batch 60/64 loss: 0.28693437576293945
Batch 61/64 loss: 0.28606945276260376
Batch 62/64 loss: 0.2825582027435303
Batch 63/64 loss: 0.2804868817329407
Batch 64/64 loss: 0.28502988815307617
Epoch 462  Train loss: 0.2867954226101146  Val loss: 0.32444304780861766
Epoch 463
-------------------------------
Batch 1/64 loss: 0.2893567681312561
Batch 2/64 loss: 0.28257089853286743
Batch 3/64 loss: 0.2789880037307739
Batch 4/64 loss: 0.2831452488899231
Batch 5/64 loss: 0.27453553676605225
Batch 6/64 loss: 0.28091299533843994
Batch 7/64 loss: 0.2854959964752197
Batch 8/64 loss: 0.2934412956237793
Batch 9/64 loss: 0.2958083152770996
Batch 10/64 loss: 0.28788959980010986
Batch 11/64 loss: 0.2830578088760376
Batch 12/64 loss: 0.2859765291213989
Batch 13/64 loss: 0.28028666973114014
Batch 14/64 loss: 0.29255038499832153
Batch 15/64 loss: 0.28909915685653687
Batch 16/64 loss: 0.27679651975631714
Batch 17/64 loss: 0.28956711292266846
Batch 18/64 loss: 0.2856619358062744
Batch 19/64 loss: 0.2811546325683594
Batch 20/64 loss: 0.285519003868103
Batch 21/64 loss: 0.2773023843765259
Batch 22/64 loss: 0.2829446792602539
Batch 23/64 loss: 0.2841941714286804
Batch 24/64 loss: 0.28817903995513916
Batch 25/64 loss: 0.2809808850288391
Batch 26/64 loss: 0.2922780513763428
Batch 27/64 loss: 0.2891051173210144
Batch 28/64 loss: 0.28083473443984985
Batch 29/64 loss: 0.2798271179199219
Batch 30/64 loss: 0.28267765045166016
Batch 31/64 loss: 0.2876884937286377
Batch 32/64 loss: 0.2767794132232666
Batch 33/64 loss: 0.2887440323829651
Batch 34/64 loss: 0.2921626567840576
Batch 35/64 loss: 0.2795827388763428
Batch 36/64 loss: 0.288448691368103
Batch 37/64 loss: 0.2921242117881775
Batch 38/64 loss: 0.2952234745025635
Batch 39/64 loss: 0.2956330180168152
Batch 40/64 loss: 0.2826576232910156
Batch 41/64 loss: 0.2938256859779358
Batch 42/64 loss: 0.28727084398269653
Batch 43/64 loss: 0.2841014862060547
Batch 44/64 loss: 0.280905544757843
Batch 45/64 loss: 0.2861896753311157
Batch 46/64 loss: 0.28559350967407227
Batch 47/64 loss: 0.2928900718688965
Batch 48/64 loss: 0.2942929267883301
Batch 49/64 loss: 0.2987644672393799
Batch 50/64 loss: 0.2842344045639038
Batch 51/64 loss: 0.2880731225013733
Batch 52/64 loss: 0.2784150242805481
Batch 53/64 loss: 0.28693199157714844
Batch 54/64 loss: 0.2904304265975952
Batch 55/64 loss: 0.287670373916626
Batch 56/64 loss: 0.28870320320129395
Batch 57/64 loss: 0.28964829444885254
Batch 58/64 loss: 0.2982472777366638
Batch 59/64 loss: 0.28853094577789307
Batch 60/64 loss: 0.28421980142593384
Batch 61/64 loss: 0.2937171459197998
Batch 62/64 loss: 0.2807089686393738
Batch 63/64 loss: 0.28088319301605225
Batch 64/64 loss: 0.29725074768066406
Epoch 463  Train loss: 0.2865312791338154  Val loss: 0.3237382300530922
Epoch 464
-------------------------------
Batch 1/64 loss: 0.3003922700881958
Batch 2/64 loss: 0.28502440452575684
Batch 3/64 loss: 0.29351139068603516
Batch 4/64 loss: 0.28642523288726807
Batch 5/64 loss: 0.2814985513687134
Batch 6/64 loss: 0.28381699323654175
Batch 7/64 loss: 0.2819204330444336
Batch 8/64 loss: 0.29181045293807983
Batch 9/64 loss: 0.282565176486969
Batch 10/64 loss: 0.2778935432434082
Batch 11/64 loss: 0.2868878245353699
Batch 12/64 loss: 0.29911065101623535
Batch 13/64 loss: 0.2932600975036621
Batch 14/64 loss: 0.2872732877731323
Batch 15/64 loss: 0.2802032232284546
Batch 16/64 loss: 0.28745102882385254
Batch 17/64 loss: 0.28625404834747314
Batch 18/64 loss: 0.2913268804550171
Batch 19/64 loss: 0.2828601598739624
Batch 20/64 loss: 0.28669798374176025
Batch 21/64 loss: 0.28314298391342163
Batch 22/64 loss: 0.2921702265739441
Batch 23/64 loss: 0.2845291495323181
Batch 24/64 loss: 0.27965056896209717
Batch 25/64 loss: 0.28821682929992676
Batch 26/64 loss: 0.28142422437667847
Batch 27/64 loss: 0.2856130003929138
Batch 28/64 loss: 0.2891373634338379
Batch 29/64 loss: 0.2840074896812439
Batch 30/64 loss: 0.28192150592803955
Batch 31/64 loss: 0.28108346462249756
Batch 32/64 loss: 0.2927544116973877
Batch 33/64 loss: 0.28753340244293213
Batch 34/64 loss: 0.28188496828079224
Batch 35/64 loss: 0.29123467206954956
Batch 36/64 loss: 0.2807497978210449
Batch 37/64 loss: 0.28501564264297485
Batch 38/64 loss: 0.2889735698699951
Batch 39/64 loss: 0.277443528175354
Batch 40/64 loss: 0.2815662622451782
Batch 41/64 loss: 0.2808142900466919
Batch 42/64 loss: 0.2885459065437317
Batch 43/64 loss: 0.28217482566833496
Batch 44/64 loss: 0.28907322883605957
Batch 45/64 loss: 0.29474031925201416
Batch 46/64 loss: 0.2910938858985901
Batch 47/64 loss: 0.2765410542488098
Batch 48/64 loss: 0.2842118740081787
Batch 49/64 loss: 0.27919769287109375
Batch 50/64 loss: 0.2819613814353943
Batch 51/64 loss: 0.3000967502593994
Batch 52/64 loss: 0.28558456897735596
Batch 53/64 loss: 0.28531479835510254
Batch 54/64 loss: 0.29146331548690796
Batch 55/64 loss: 0.2872065305709839
Batch 56/64 loss: 0.29855185747146606
Batch 57/64 loss: 0.2956109046936035
Batch 58/64 loss: 0.29158830642700195
Batch 59/64 loss: 0.2786402702331543
Batch 60/64 loss: 0.2864518165588379
Batch 61/64 loss: 0.29351598024368286
Batch 62/64 loss: 0.2791198492050171
Batch 63/64 loss: 0.2991112470626831
Batch 64/64 loss: 0.28681421279907227
Epoch 464  Train loss: 0.28674443936815447  Val loss: 0.3227568672285047
Epoch 465
-------------------------------
Batch 1/64 loss: 0.29263198375701904
Batch 2/64 loss: 0.27927160263061523
Batch 3/64 loss: 0.2863578796386719
Batch 4/64 loss: 0.2882833480834961
Batch 5/64 loss: 0.2883622646331787
Batch 6/64 loss: 0.27320247888565063
Batch 7/64 loss: 0.2882463335990906
Batch 8/64 loss: 0.28698867559432983
Batch 9/64 loss: 0.2893819808959961
Batch 10/64 loss: 0.2817322015762329
Batch 11/64 loss: 0.2838287353515625
Batch 12/64 loss: 0.2817862033843994
Batch 13/64 loss: 0.2813318371772766
Batch 14/64 loss: 0.2766810655593872
Batch 15/64 loss: 0.2755739688873291
Batch 16/64 loss: 0.28047358989715576
Batch 17/64 loss: 0.2765094041824341
Batch 18/64 loss: 0.28119421005249023
Batch 19/64 loss: 0.29706335067749023
Batch 20/64 loss: 0.2854877710342407
Batch 21/64 loss: 0.28406935930252075
Batch 22/64 loss: 0.27800309658050537
Batch 23/64 loss: 0.28666114807128906
Batch 24/64 loss: 0.2868638038635254
Batch 25/64 loss: 0.2862788438796997
Batch 26/64 loss: 0.285632848739624
Batch 27/64 loss: 0.2926561236381531
Batch 28/64 loss: 0.28599798679351807
Batch 29/64 loss: 0.2984457015991211
Batch 30/64 loss: 0.29092836380004883
Batch 31/64 loss: 0.28624051809310913
Batch 32/64 loss: 0.2903766632080078
Batch 33/64 loss: 0.29841887950897217
Batch 34/64 loss: 0.2841605544090271
Batch 35/64 loss: 0.2983446717262268
Batch 36/64 loss: 0.2842242121696472
Batch 37/64 loss: 0.2844468951225281
Batch 38/64 loss: 0.2842869758605957
Batch 39/64 loss: 0.2862910032272339
Batch 40/64 loss: 0.2897728681564331
Batch 41/64 loss: 0.29084116220474243
Batch 42/64 loss: 0.2883327007293701
Batch 43/64 loss: 0.2819392681121826
Batch 44/64 loss: 0.2901846170425415
Batch 45/64 loss: 0.2831606864929199
Batch 46/64 loss: 0.28981781005859375
Batch 47/64 loss: 0.2918841242790222
Batch 48/64 loss: 0.28704190254211426
Batch 49/64 loss: 0.2805238962173462
Batch 50/64 loss: 0.2858772873878479
Batch 51/64 loss: 0.2914947271347046
Batch 52/64 loss: 0.2797657251358032
Batch 53/64 loss: 0.2757751941680908
Batch 54/64 loss: 0.2914372682571411
Batch 55/64 loss: 0.28140366077423096
Batch 56/64 loss: 0.28987133502960205
Batch 57/64 loss: 0.2875436544418335
Batch 58/64 loss: 0.287075400352478
Batch 59/64 loss: 0.2922593355178833
Batch 60/64 loss: 0.2779387831687927
Batch 61/64 loss: 0.28859829902648926
Batch 62/64 loss: 0.29159218072891235
Batch 63/64 loss: 0.2816509008407593
Batch 64/64 loss: 0.28805220127105713
Epoch 465  Train loss: 0.28609472115834556  Val loss: 0.3233842179947293
Epoch 466
-------------------------------
Batch 1/64 loss: 0.296836256980896
Batch 2/64 loss: 0.27406978607177734
Batch 3/64 loss: 0.27918577194213867
Batch 4/64 loss: 0.27962660789489746
Batch 5/64 loss: 0.2842984199523926
Batch 6/64 loss: 0.27960336208343506
Batch 7/64 loss: 0.2830238938331604
Batch 8/64 loss: 0.2908278703689575
Batch 9/64 loss: 0.2885998487472534
Batch 10/64 loss: 0.27929258346557617
Batch 11/64 loss: 0.29185789823532104
Batch 12/64 loss: 0.28655320405960083
Batch 13/64 loss: 0.2874220013618469
Batch 14/64 loss: 0.28313279151916504
Batch 15/64 loss: 0.27790069580078125
Batch 16/64 loss: 0.27849280834198
Batch 17/64 loss: 0.2979367971420288
Batch 18/64 loss: 0.27958714962005615
Batch 19/64 loss: 0.29227954149246216
Batch 20/64 loss: 0.2901977300643921
Batch 21/64 loss: 0.28797173500061035
Batch 22/64 loss: 0.28518539667129517
Batch 23/64 loss: 0.27420175075531006
Batch 24/64 loss: 0.2871703505516052
Batch 25/64 loss: 0.28262555599212646
Batch 26/64 loss: 0.2837017774581909
Batch 27/64 loss: 0.28918516635894775
Batch 28/64 loss: 0.27601194381713867
Batch 29/64 loss: 0.2884536385536194
Batch 30/64 loss: 0.28386688232421875
Batch 31/64 loss: 0.2904948592185974
Batch 32/64 loss: 0.2816278338432312
Batch 33/64 loss: 0.27819424867630005
Batch 34/64 loss: 0.30010807514190674
Batch 35/64 loss: 0.2860090136528015
Batch 36/64 loss: 0.28993237018585205
Batch 37/64 loss: 0.2792363166809082
Batch 38/64 loss: 0.2905285954475403
Batch 39/64 loss: 0.28456395864486694
Batch 40/64 loss: 0.28522753715515137
Batch 41/64 loss: 0.2907305955886841
Batch 42/64 loss: 0.28051692247390747
Batch 43/64 loss: 0.28158771991729736
Batch 44/64 loss: 0.2846810221672058
Batch 45/64 loss: 0.28167080879211426
Batch 46/64 loss: 0.28347456455230713
Batch 47/64 loss: 0.28265058994293213
Batch 48/64 loss: 0.283577561378479
Batch 49/64 loss: 0.28698718547821045
Batch 50/64 loss: 0.2884613275527954
Batch 51/64 loss: 0.29194533824920654
Batch 52/64 loss: 0.2858772277832031
Batch 53/64 loss: 0.2853524684906006
Batch 54/64 loss: 0.2885292172431946
Batch 55/64 loss: 0.27861130237579346
Batch 56/64 loss: 0.2906477451324463
Batch 57/64 loss: 0.2799375057220459
Batch 58/64 loss: 0.2917637825012207
Batch 59/64 loss: 0.2918583154678345
Batch 60/64 loss: 0.28759562969207764
Batch 61/64 loss: 0.3005056381225586
Batch 62/64 loss: 0.2864874601364136
Batch 63/64 loss: 0.2911520004272461
Batch 64/64 loss: 0.29267311096191406
Epoch 466  Train loss: 0.2857902554904713  Val loss: 0.32322543654654856
Epoch 467
-------------------------------
Batch 1/64 loss: 0.2857782244682312
Batch 2/64 loss: 0.2945122718811035
Batch 3/64 loss: 0.2930193543434143
Batch 4/64 loss: 0.28470921516418457
Batch 5/64 loss: 0.29372966289520264
Batch 6/64 loss: 0.290412962436676
Batch 7/64 loss: 0.28079092502593994
Batch 8/64 loss: 0.27858495712280273
Batch 9/64 loss: 0.29132622480392456
Batch 10/64 loss: 0.27886807918548584
Batch 11/64 loss: 0.284767746925354
Batch 12/64 loss: 0.29005730152130127
Batch 13/64 loss: 0.2763305902481079
Batch 14/64 loss: 0.28144800662994385
Batch 15/64 loss: 0.27625906467437744
Batch 16/64 loss: 0.281038761138916
Batch 17/64 loss: 0.29240351915359497
Batch 18/64 loss: 0.28401756286621094
Batch 19/64 loss: 0.2868424654006958
Batch 20/64 loss: 0.29588669538497925
Batch 21/64 loss: 0.27436989545822144
Batch 22/64 loss: 0.28743278980255127
Batch 23/64 loss: 0.28260451555252075
Batch 24/64 loss: 0.27941787242889404
Batch 25/64 loss: 0.28590863943099976
Batch 26/64 loss: 0.27838754653930664
Batch 27/64 loss: 0.2901708483695984
Batch 28/64 loss: 0.28313541412353516
Batch 29/64 loss: 0.2822501063346863
Batch 30/64 loss: 0.29497313499450684
Batch 31/64 loss: 0.2831587791442871
Batch 32/64 loss: 0.2844966650009155
Batch 33/64 loss: 0.28886234760284424
Batch 34/64 loss: 0.29269206523895264
Batch 35/64 loss: 0.28193390369415283
Batch 36/64 loss: 0.27907097339630127
Batch 37/64 loss: 0.28033143281936646
Batch 38/64 loss: 0.2764354944229126
Batch 39/64 loss: 0.2931162118911743
Batch 40/64 loss: 0.2943856120109558
Batch 41/64 loss: 0.2867327928543091
Batch 42/64 loss: 0.2805294990539551
Batch 43/64 loss: 0.2835463285446167
Batch 44/64 loss: 0.2820148468017578
Batch 45/64 loss: 0.2945097088813782
Batch 46/64 loss: 0.28404080867767334
Batch 47/64 loss: 0.2869988679885864
Batch 48/64 loss: 0.28833162784576416
Batch 49/64 loss: 0.28477585315704346
Batch 50/64 loss: 0.28703415393829346
Batch 51/64 loss: 0.2839634418487549
Batch 52/64 loss: 0.2903050184249878
Batch 53/64 loss: 0.2871677875518799
Batch 54/64 loss: 0.29454320669174194
Batch 55/64 loss: 0.30690324306488037
Batch 56/64 loss: 0.30322229862213135
Batch 57/64 loss: 0.27359557151794434
Batch 58/64 loss: 0.2807818651199341
Batch 59/64 loss: 0.28001081943511963
Batch 60/64 loss: 0.28253138065338135
Batch 61/64 loss: 0.287742018699646
Batch 62/64 loss: 0.2814251184463501
Batch 63/64 loss: 0.2672625780105591
Batch 64/64 loss: 0.290351927280426
Epoch 467  Train loss: 0.2856415783657747  Val loss: 0.32376858786618995
Epoch 468
-------------------------------
Batch 1/64 loss: 0.28691208362579346
Batch 2/64 loss: 0.2885380983352661
Batch 3/64 loss: 0.2855900526046753
Batch 4/64 loss: 0.27581316232681274
Batch 5/64 loss: 0.27703022956848145
Batch 6/64 loss: 0.2873438596725464
Batch 7/64 loss: 0.285858690738678
Batch 8/64 loss: 0.29190653562545776
Batch 9/64 loss: 0.2924317717552185
Batch 10/64 loss: 0.30304384231567383
Batch 11/64 loss: 0.29465752840042114
Batch 12/64 loss: 0.2803553342819214
Batch 13/64 loss: 0.28309404850006104
Batch 14/64 loss: 0.2792443037033081
Batch 15/64 loss: 0.28514158725738525
Batch 16/64 loss: 0.28764617443084717
Batch 17/64 loss: 0.2839915156364441
Batch 18/64 loss: 0.2863183617591858
Batch 19/64 loss: 0.28675341606140137
Batch 20/64 loss: 0.28466492891311646
Batch 21/64 loss: 0.2838643789291382
Batch 22/64 loss: 0.2782251834869385
Batch 23/64 loss: 0.2872728109359741
Batch 24/64 loss: 0.28408944606781006
Batch 25/64 loss: 0.2849717140197754
Batch 26/64 loss: 0.29061025381088257
Batch 27/64 loss: 0.2943754196166992
Batch 28/64 loss: 0.28190910816192627
Batch 29/64 loss: 0.28970062732696533
Batch 30/64 loss: 0.2950543761253357
Batch 31/64 loss: 0.2834324836730957
Batch 32/64 loss: 0.27629220485687256
Batch 33/64 loss: 0.2780492305755615
Batch 34/64 loss: 0.27695685625076294
Batch 35/64 loss: 0.2743467092514038
Batch 36/64 loss: 0.2856612205505371
Batch 37/64 loss: 0.28386592864990234
Batch 38/64 loss: 0.2864186763763428
Batch 39/64 loss: 0.2913586497306824
Batch 40/64 loss: 0.27780234813690186
Batch 41/64 loss: 0.28042376041412354
Batch 42/64 loss: 0.28699493408203125
Batch 43/64 loss: 0.2885826826095581
Batch 44/64 loss: 0.287961483001709
Batch 45/64 loss: 0.28886842727661133
Batch 46/64 loss: 0.27989906072616577
Batch 47/64 loss: 0.28735536336898804
Batch 48/64 loss: 0.2808278799057007
Batch 49/64 loss: 0.2812126874923706
Batch 50/64 loss: 0.27481698989868164
Batch 51/64 loss: 0.29209280014038086
Batch 52/64 loss: 0.2836686372756958
Batch 53/64 loss: 0.2909122705459595
Batch 54/64 loss: 0.28750836849212646
Batch 55/64 loss: 0.28722232580184937
Batch 56/64 loss: 0.28502368927001953
Batch 57/64 loss: 0.29101479053497314
Batch 58/64 loss: 0.2918081283569336
Batch 59/64 loss: 0.2855159044265747
Batch 60/64 loss: 0.2888016104698181
Batch 61/64 loss: 0.2826937437057495
Batch 62/64 loss: 0.28934264183044434
Batch 63/64 loss: 0.295093297958374
Batch 64/64 loss: 0.28990674018859863
Epoch 468  Train loss: 0.2857359166238822  Val loss: 0.323707962159029
Epoch 469
-------------------------------
Batch 1/64 loss: 0.29574042558670044
Batch 2/64 loss: 0.29004472494125366
Batch 3/64 loss: 0.28357523679733276
Batch 4/64 loss: 0.2864910960197449
Batch 5/64 loss: 0.2752116918563843
Batch 6/64 loss: 0.2802613377571106
Batch 7/64 loss: 0.28282761573791504
Batch 8/64 loss: 0.28337621688842773
Batch 9/64 loss: 0.2786952257156372
Batch 10/64 loss: 0.2836694121360779
Batch 11/64 loss: 0.2729250192642212
Batch 12/64 loss: 0.26908886432647705
Batch 13/64 loss: 0.2871798276901245
Batch 14/64 loss: 0.28266972303390503
Batch 15/64 loss: 0.28597259521484375
Batch 16/64 loss: 0.2885500192642212
Batch 17/64 loss: 0.28918397426605225
Batch 18/64 loss: 0.29496699571609497
Batch 19/64 loss: 0.2784358263015747
Batch 20/64 loss: 0.28838664293289185
Batch 21/64 loss: 0.28593748807907104
Batch 22/64 loss: 0.2948140501976013
Batch 23/64 loss: 0.28068971633911133
Batch 24/64 loss: 0.28418469429016113
Batch 25/64 loss: 0.2846120595932007
Batch 26/64 loss: 0.2896167039871216
Batch 27/64 loss: 0.28650885820388794
Batch 28/64 loss: 0.28499388694763184
Batch 29/64 loss: 0.2840757966041565
Batch 30/64 loss: 0.2881416082382202
Batch 31/64 loss: 0.28413987159729004
Batch 32/64 loss: 0.29023873805999756
Batch 33/64 loss: 0.29112446308135986
Batch 34/64 loss: 0.27590298652648926
Batch 35/64 loss: 0.2824142575263977
Batch 36/64 loss: 0.28365230560302734
Batch 37/64 loss: 0.28359103202819824
Batch 38/64 loss: 0.28718823194503784
Batch 39/64 loss: 0.2862638831138611
Batch 40/64 loss: 0.2944129705429077
Batch 41/64 loss: 0.2759968638420105
Batch 42/64 loss: 0.2919490337371826
Batch 43/64 loss: 0.28200602531433105
Batch 44/64 loss: 0.29955363273620605
Batch 45/64 loss: 0.29148441553115845
Batch 46/64 loss: 0.2903428077697754
Batch 47/64 loss: 0.28479957580566406
Batch 48/64 loss: 0.28558671474456787
Batch 49/64 loss: 0.2768031358718872
Batch 50/64 loss: 0.27921944856643677
Batch 51/64 loss: 0.28848326206207275
Batch 52/64 loss: 0.29255247116088867
Batch 53/64 loss: 0.28624022006988525
Batch 54/64 loss: 0.2908015847206116
Batch 55/64 loss: 0.2877400517463684
Batch 56/64 loss: 0.2923574447631836
Batch 57/64 loss: 0.2854440212249756
Batch 58/64 loss: 0.2878599166870117
Batch 59/64 loss: 0.28319013118743896
Batch 60/64 loss: 0.29142892360687256
Batch 61/64 loss: 0.2838049530982971
Batch 62/64 loss: 0.28788065910339355
Batch 63/64 loss: 0.2839033603668213
Batch 64/64 loss: 0.2894192934036255
Epoch 469  Train loss: 0.2857450854544546  Val loss: 0.3231491350226386
Epoch 470
-------------------------------
Batch 1/64 loss: 0.288602352142334
Batch 2/64 loss: 0.2938666343688965
Batch 3/64 loss: 0.28947412967681885
Batch 4/64 loss: 0.27569228410720825
Batch 5/64 loss: 0.28699564933776855
Batch 6/64 loss: 0.28764891624450684
Batch 7/64 loss: 0.2756534814834595
Batch 8/64 loss: 0.2898827791213989
Batch 9/64 loss: 0.2775484323501587
Batch 10/64 loss: 0.2883192300796509
Batch 11/64 loss: 0.2820817232131958
Batch 12/64 loss: 0.28280025720596313
Batch 13/64 loss: 0.2875649333000183
Batch 14/64 loss: 0.28412920236587524
Batch 15/64 loss: 0.2789875268936157
Batch 16/64 loss: 0.29818230867385864
Batch 17/64 loss: 0.28297901153564453
Batch 18/64 loss: 0.2864645719528198
Batch 19/64 loss: 0.2797930836677551
Batch 20/64 loss: 0.29178881645202637
Batch 21/64 loss: 0.28164154291152954
Batch 22/64 loss: 0.2880665063858032
Batch 23/64 loss: 0.276080846786499
Batch 24/64 loss: 0.2843860387802124
Batch 25/64 loss: 0.28220200538635254
Batch 26/64 loss: 0.2857043147087097
Batch 27/64 loss: 0.27772265672683716
Batch 28/64 loss: 0.2984657287597656
Batch 29/64 loss: 0.2955970764160156
Batch 30/64 loss: 0.28656744956970215
Batch 31/64 loss: 0.2784709334373474
Batch 32/64 loss: 0.2945905923843384
Batch 33/64 loss: 0.27938151359558105
Batch 34/64 loss: 0.2884836792945862
Batch 35/64 loss: 0.2826429605484009
Batch 36/64 loss: 0.2766534090042114
Batch 37/64 loss: 0.28710508346557617
Batch 38/64 loss: 0.28492212295532227
Batch 39/64 loss: 0.28795450925827026
Batch 40/64 loss: 0.27928459644317627
Batch 41/64 loss: 0.27978914976119995
Batch 42/64 loss: 0.2817891836166382
Batch 43/64 loss: 0.2882986068725586
Batch 44/64 loss: 0.27496200799942017
Batch 45/64 loss: 0.28765225410461426
Batch 46/64 loss: 0.2826300859451294
Batch 47/64 loss: 0.28868961334228516
Batch 48/64 loss: 0.28180718421936035
Batch 49/64 loss: 0.2820380926132202
Batch 50/64 loss: 0.280964732170105
Batch 51/64 loss: 0.2949305772781372
Batch 52/64 loss: 0.2904391288757324
Batch 53/64 loss: 0.27812254428863525
Batch 54/64 loss: 0.2836645245552063
Batch 55/64 loss: 0.2858588695526123
Batch 56/64 loss: 0.28869152069091797
Batch 57/64 loss: 0.2785172462463379
Batch 58/64 loss: 0.29313433170318604
Batch 59/64 loss: 0.2892724275588989
Batch 60/64 loss: 0.28659766912460327
Batch 61/64 loss: 0.29256004095077515
Batch 62/64 loss: 0.28633981943130493
Batch 63/64 loss: 0.2938610315322876
Batch 64/64 loss: 0.28189200162887573
Epoch 470  Train loss: 0.2852769966218986  Val loss: 0.3229483976396908
Epoch 471
-------------------------------
Batch 1/64 loss: 0.2930119037628174
Batch 2/64 loss: 0.27953648567199707
Batch 3/64 loss: 0.28989678621292114
Batch 4/64 loss: 0.2829267382621765
Batch 5/64 loss: 0.28956925868988037
Batch 6/64 loss: 0.2916814684867859
Batch 7/64 loss: 0.288421094417572
Batch 8/64 loss: 0.2804766893386841
Batch 9/64 loss: 0.2884953022003174
Batch 10/64 loss: 0.2770044803619385
Batch 11/64 loss: 0.2779577374458313
Batch 12/64 loss: 0.2851683497428894
Batch 13/64 loss: 0.2792925238609314
Batch 14/64 loss: 0.2998843193054199
Batch 15/64 loss: 0.28478527069091797
Batch 16/64 loss: 0.2885938882827759
Batch 17/64 loss: 0.2823446989059448
Batch 18/64 loss: 0.27624571323394775
Batch 19/64 loss: 0.29047513008117676
Batch 20/64 loss: 0.27208125591278076
Batch 21/64 loss: 0.29225558042526245
Batch 22/64 loss: 0.2789062261581421
Batch 23/64 loss: 0.28502559661865234
Batch 24/64 loss: 0.2887915372848511
Batch 25/64 loss: 0.29517698287963867
Batch 26/64 loss: 0.2859543561935425
Batch 27/64 loss: 0.2839866876602173
Batch 28/64 loss: 0.2827000021934509
Batch 29/64 loss: 0.2880781888961792
Batch 30/64 loss: 0.29053300619125366
Batch 31/64 loss: 0.28659987449645996
Batch 32/64 loss: 0.2850804328918457
Batch 33/64 loss: 0.2942485809326172
Batch 34/64 loss: 0.27308154106140137
Batch 35/64 loss: 0.2889662981033325
Batch 36/64 loss: 0.28874671459198
Batch 37/64 loss: 0.28337740898132324
Batch 38/64 loss: 0.284110963344574
Batch 39/64 loss: 0.28332626819610596
Batch 40/64 loss: 0.28873586654663086
Batch 41/64 loss: 0.2806926965713501
Batch 42/64 loss: 0.28777360916137695
Batch 43/64 loss: 0.2856590151786804
Batch 44/64 loss: 0.28592556715011597
Batch 45/64 loss: 0.28926920890808105
Batch 46/64 loss: 0.279554545879364
Batch 47/64 loss: 0.2833397388458252
Batch 48/64 loss: 0.28256791830062866
Batch 49/64 loss: 0.28763437271118164
Batch 50/64 loss: 0.28710150718688965
Batch 51/64 loss: 0.2750817537307739
Batch 52/64 loss: 0.296236515045166
Batch 53/64 loss: 0.2800070643424988
Batch 54/64 loss: 0.2885897159576416
Batch 55/64 loss: 0.288449227809906
Batch 56/64 loss: 0.2819103002548218
Batch 57/64 loss: 0.2859486937522888
Batch 58/64 loss: 0.2816581130027771
Batch 59/64 loss: 0.2733933925628662
Batch 60/64 loss: 0.285345196723938
Batch 61/64 loss: 0.29192137718200684
Batch 62/64 loss: 0.276375949382782
Batch 63/64 loss: 0.2851686477661133
Batch 64/64 loss: 0.29543375968933105
Epoch 471  Train loss: 0.28528173577551746  Val loss: 0.3232900428608111
Epoch 472
-------------------------------
Batch 1/64 loss: 0.27274978160858154
Batch 2/64 loss: 0.2807188034057617
Batch 3/64 loss: 0.282653272151947
Batch 4/64 loss: 0.28112900257110596
Batch 5/64 loss: 0.2859424352645874
Batch 6/64 loss: 0.28166693449020386
Batch 7/64 loss: 0.28927671909332275
Batch 8/64 loss: 0.2783644199371338
Batch 9/64 loss: 0.28010743856430054
Batch 10/64 loss: 0.2790209650993347
Batch 11/64 loss: 0.2810102105140686
Batch 12/64 loss: 0.2897254228591919
Batch 13/64 loss: 0.2760307788848877
Batch 14/64 loss: 0.2989094853401184
Batch 15/64 loss: 0.2929806709289551
Batch 16/64 loss: 0.2780294418334961
Batch 17/64 loss: 0.28169333934783936
Batch 18/64 loss: 0.28362715244293213
Batch 19/64 loss: 0.28924560546875
Batch 20/64 loss: 0.28566688299179077
Batch 21/64 loss: 0.28791379928588867
Batch 22/64 loss: 0.28538763523101807
Batch 23/64 loss: 0.29066920280456543
Batch 24/64 loss: 0.28683972358703613
Batch 25/64 loss: 0.28691232204437256
Batch 26/64 loss: 0.28346097469329834
Batch 27/64 loss: 0.2820207476615906
Batch 28/64 loss: 0.2851525545120239
Batch 29/64 loss: 0.2858828902244568
Batch 30/64 loss: 0.28903400897979736
Batch 31/64 loss: 0.277976393699646
Batch 32/64 loss: 0.2805197834968567
Batch 33/64 loss: 0.2916080951690674
Batch 34/64 loss: 0.28738826513290405
Batch 35/64 loss: 0.28839075565338135
Batch 36/64 loss: 0.3058260679244995
Batch 37/64 loss: 0.28582125902175903
Batch 38/64 loss: 0.27638715505599976
Batch 39/64 loss: 0.2865636348724365
Batch 40/64 loss: 0.2910221815109253
Batch 41/64 loss: 0.27980512380599976
Batch 42/64 loss: 0.28343164920806885
Batch 43/64 loss: 0.29299283027648926
Batch 44/64 loss: 0.2759561538696289
Batch 45/64 loss: 0.3005775809288025
Batch 46/64 loss: 0.2770741581916809
Batch 47/64 loss: 0.30136311054229736
Batch 48/64 loss: 0.28782159090042114
Batch 49/64 loss: 0.2827622890472412
Batch 50/64 loss: 0.2817789316177368
Batch 51/64 loss: 0.28329789638519287
Batch 52/64 loss: 0.27595317363739014
Batch 53/64 loss: 0.2855360507965088
Batch 54/64 loss: 0.28862816095352173
Batch 55/64 loss: 0.298259973526001
Batch 56/64 loss: 0.2804940938949585
Batch 57/64 loss: 0.2887009382247925
Batch 58/64 loss: 0.27910107374191284
Batch 59/64 loss: 0.2881190776824951
Batch 60/64 loss: 0.2874082326889038
Batch 61/64 loss: 0.30240917205810547
Batch 62/64 loss: 0.2945960760116577
Batch 63/64 loss: 0.28134095668792725
Batch 64/64 loss: 0.2823302149772644
Epoch 472  Train loss: 0.2856859948120865  Val loss: 0.32387837265774966
Epoch 473
-------------------------------
Batch 1/64 loss: 0.2792304754257202
Batch 2/64 loss: 0.2959551215171814
Batch 3/64 loss: 0.2893310785293579
Batch 4/64 loss: 0.2927769422531128
Batch 5/64 loss: 0.2807353138923645
Batch 6/64 loss: 0.2889938950538635
Batch 7/64 loss: 0.278492271900177
Batch 8/64 loss: 0.27726173400878906
Batch 9/64 loss: 0.2826719880104065
Batch 10/64 loss: 0.2936354875564575
Batch 11/64 loss: 0.2871502637863159
Batch 12/64 loss: 0.27371716499328613
Batch 13/64 loss: 0.29202234745025635
Batch 14/64 loss: 0.2845095992088318
Batch 15/64 loss: 0.288327693939209
Batch 16/64 loss: 0.2819981575012207
Batch 17/64 loss: 0.27735334634780884
Batch 18/64 loss: 0.2735309600830078
Batch 19/64 loss: 0.282839834690094
Batch 20/64 loss: 0.2987850308418274
Batch 21/64 loss: 0.2915620803833008
Batch 22/64 loss: 0.2928144931793213
Batch 23/64 loss: 0.28902751207351685
Batch 24/64 loss: 0.286548376083374
Batch 25/64 loss: 0.28380709886550903
Batch 26/64 loss: 0.27604907751083374
Batch 27/64 loss: 0.28208136558532715
Batch 28/64 loss: 0.2797950506210327
Batch 29/64 loss: 0.2859957814216614
Batch 30/64 loss: 0.28240811824798584
Batch 31/64 loss: 0.28626978397369385
Batch 32/64 loss: 0.28357410430908203
Batch 33/64 loss: 0.2830789089202881
Batch 34/64 loss: 0.2886071801185608
Batch 35/64 loss: 0.2829005718231201
Batch 36/64 loss: 0.281978964805603
Batch 37/64 loss: 0.28383952379226685
Batch 38/64 loss: 0.2871741056442261
Batch 39/64 loss: 0.2845603823661804
Batch 40/64 loss: 0.287290096282959
Batch 41/64 loss: 0.2879287600517273
Batch 42/64 loss: 0.29503631591796875
Batch 43/64 loss: 0.2792333960533142
Batch 44/64 loss: 0.28559136390686035
Batch 45/64 loss: 0.2864091396331787
Batch 46/64 loss: 0.29264330863952637
Batch 47/64 loss: 0.2781468629837036
Batch 48/64 loss: 0.286935031414032
Batch 49/64 loss: 0.28140342235565186
Batch 50/64 loss: 0.2920920252799988
Batch 51/64 loss: 0.27707386016845703
Batch 52/64 loss: 0.2849302291870117
Batch 53/64 loss: 0.2874736189842224
Batch 54/64 loss: 0.27875667810440063
Batch 55/64 loss: 0.2969619631767273
Batch 56/64 loss: 0.27890270948410034
Batch 57/64 loss: 0.28430163860321045
Batch 58/64 loss: 0.2874079942703247
Batch 59/64 loss: 0.2823033928871155
Batch 60/64 loss: 0.27910393476486206
Batch 61/64 loss: 0.2918126583099365
Batch 62/64 loss: 0.2825589179992676
Batch 63/64 loss: 0.29157817363739014
Batch 64/64 loss: 0.2824404835700989
Epoch 473  Train loss: 0.2851623065331403  Val loss: 0.32364739564685885
Epoch 474
-------------------------------
Batch 1/64 loss: 0.2812643051147461
Batch 2/64 loss: 0.28318047523498535
Batch 3/64 loss: 0.2859693169593811
Batch 4/64 loss: 0.2787562608718872
Batch 5/64 loss: 0.28887271881103516
Batch 6/64 loss: 0.2862884998321533
Batch 7/64 loss: 0.2843036651611328
Batch 8/64 loss: 0.28542113304138184
Batch 9/64 loss: 0.28101789951324463
Batch 10/64 loss: 0.28018856048583984
Batch 11/64 loss: 0.2786341905593872
Batch 12/64 loss: 0.28993314504623413
Batch 13/64 loss: 0.2923353910446167
Batch 14/64 loss: 0.2867918014526367
Batch 15/64 loss: 0.3014180660247803
Batch 16/64 loss: 0.3023006319999695
Batch 17/64 loss: 0.2935730218887329
Batch 18/64 loss: 0.28390687704086304
Batch 19/64 loss: 0.28073859214782715
Batch 20/64 loss: 0.2958565354347229
Batch 21/64 loss: 0.27978622913360596
Batch 22/64 loss: 0.28986310958862305
Batch 23/64 loss: 0.2770642042160034
Batch 24/64 loss: 0.27625787258148193
Batch 25/64 loss: 0.28130435943603516
Batch 26/64 loss: 0.28541016578674316
Batch 27/64 loss: 0.2884773015975952
Batch 28/64 loss: 0.277182936668396
Batch 29/64 loss: 0.2839626669883728
Batch 30/64 loss: 0.2804020643234253
Batch 31/64 loss: 0.28467702865600586
Batch 32/64 loss: 0.2903672456741333
Batch 33/64 loss: 0.28016602993011475
Batch 34/64 loss: 0.28103435039520264
Batch 35/64 loss: 0.2826164960861206
Batch 36/64 loss: 0.28464508056640625
Batch 37/64 loss: 0.29099589586257935
Batch 38/64 loss: 0.2865680456161499
Batch 39/64 loss: 0.2843669652938843
Batch 40/64 loss: 0.28031814098358154
Batch 41/64 loss: 0.278972864151001
Batch 42/64 loss: 0.2883841395378113
Batch 43/64 loss: 0.27845239639282227
Batch 44/64 loss: 0.2848811745643616
Batch 45/64 loss: 0.2964705228805542
Batch 46/64 loss: 0.29395782947540283
Batch 47/64 loss: 0.2944113612174988
Batch 48/64 loss: 0.27697253227233887
Batch 49/64 loss: 0.29140108823776245
Batch 50/64 loss: 0.28706347942352295
Batch 51/64 loss: 0.2803117632865906
Batch 52/64 loss: 0.28479158878326416
Batch 53/64 loss: 0.28367888927459717
Batch 54/64 loss: 0.2846107482910156
Batch 55/64 loss: 0.2903035283088684
Batch 56/64 loss: 0.27894532680511475
Batch 57/64 loss: 0.2775852680206299
Batch 58/64 loss: 0.2835724353790283
Batch 59/64 loss: 0.2830747365951538
Batch 60/64 loss: 0.2863818407058716
Batch 61/64 loss: 0.28585630655288696
Batch 62/64 loss: 0.29028522968292236
Batch 63/64 loss: 0.2719578742980957
Batch 64/64 loss: 0.2925882339477539
Epoch 474  Train loss: 0.2851448059082031  Val loss: 0.32346809442919966
Epoch 475
-------------------------------
Batch 1/64 loss: 0.28118807077407837
Batch 2/64 loss: 0.2841089963912964
Batch 3/64 loss: 0.2813083529472351
Batch 4/64 loss: 0.28477251529693604
Batch 5/64 loss: 0.2836610674858093
Batch 6/64 loss: 0.2874125838279724
Batch 7/64 loss: 0.28362464904785156
Batch 8/64 loss: 0.2822030782699585
Batch 9/64 loss: 0.2768022418022156
Batch 10/64 loss: 0.27392739057540894
Batch 11/64 loss: 0.2705320119857788
Batch 12/64 loss: 0.2808845639228821
Batch 13/64 loss: 0.2895486354827881
Batch 14/64 loss: 0.2937834858894348
Batch 15/64 loss: 0.3014789819717407
Batch 16/64 loss: 0.28440433740615845
Batch 17/64 loss: 0.28623902797698975
Batch 18/64 loss: 0.28328001499176025
Batch 19/64 loss: 0.28762781620025635
Batch 20/64 loss: 0.287556529045105
Batch 21/64 loss: 0.2898184061050415
Batch 22/64 loss: 0.28469085693359375
Batch 23/64 loss: 0.2783491611480713
Batch 24/64 loss: 0.2943689823150635
Batch 25/64 loss: 0.28179800510406494
Batch 26/64 loss: 0.28835630416870117
Batch 27/64 loss: 0.29421889781951904
Batch 28/64 loss: 0.28137630224227905
Batch 29/64 loss: 0.2777998447418213
Batch 30/64 loss: 0.27996790409088135
Batch 31/64 loss: 0.2913133502006531
Batch 32/64 loss: 0.28466737270355225
Batch 33/64 loss: 0.28480952978134155
Batch 34/64 loss: 0.29239606857299805
Batch 35/64 loss: 0.28328341245651245
Batch 36/64 loss: 0.28821879625320435
Batch 37/64 loss: 0.29321253299713135
Batch 38/64 loss: 0.28198766708374023
Batch 39/64 loss: 0.2761818766593933
Batch 40/64 loss: 0.28757017850875854
Batch 41/64 loss: 0.2741129398345947
Batch 42/64 loss: 0.28331029415130615
Batch 43/64 loss: 0.27712738513946533
Batch 44/64 loss: 0.27766406536102295
Batch 45/64 loss: 0.2900848984718323
Batch 46/64 loss: 0.2887662649154663
Batch 47/64 loss: 0.2939508557319641
Batch 48/64 loss: 0.2868257761001587
Batch 49/64 loss: 0.2794613838195801
Batch 50/64 loss: 0.2881004810333252
Batch 51/64 loss: 0.2924118638038635
Batch 52/64 loss: 0.27886223793029785
Batch 53/64 loss: 0.30352914333343506
Batch 54/64 loss: 0.27722978591918945
Batch 55/64 loss: 0.27977466583251953
Batch 56/64 loss: 0.2860538959503174
Batch 57/64 loss: 0.2956596612930298
Batch 58/64 loss: 0.2908855676651001
Batch 59/64 loss: 0.28474175930023193
Batch 60/64 loss: 0.28137969970703125
Batch 61/64 loss: 0.2907571792602539
Batch 62/64 loss: 0.29253625869750977
Batch 63/64 loss: 0.29328203201293945
Batch 64/64 loss: 0.28150397539138794
Epoch 475  Train loss: 0.2854331902429169  Val loss: 0.32363357392373365
Epoch 476
-------------------------------
Batch 1/64 loss: 0.2754077911376953
Batch 2/64 loss: 0.2996101975440979
Batch 3/64 loss: 0.28378456830978394
Batch 4/64 loss: 0.28633642196655273
Batch 5/64 loss: 0.27643752098083496
Batch 6/64 loss: 0.27821826934814453
Batch 7/64 loss: 0.2758709192276001
Batch 8/64 loss: 0.28746891021728516
Batch 9/64 loss: 0.2829914093017578
Batch 10/64 loss: 0.28787243366241455
Batch 11/64 loss: 0.2736596465110779
Batch 12/64 loss: 0.2788277864456177
Batch 13/64 loss: 0.28842270374298096
Batch 14/64 loss: 0.2795224189758301
Batch 15/64 loss: 0.2820337414741516
Batch 16/64 loss: 0.2847198247909546
Batch 17/64 loss: 0.28917181491851807
Batch 18/64 loss: 0.28000563383102417
Batch 19/64 loss: 0.28145527839660645
Batch 20/64 loss: 0.2861327528953552
Batch 21/64 loss: 0.27898943424224854
Batch 22/64 loss: 0.2904247045516968
Batch 23/64 loss: 0.2794177532196045
Batch 24/64 loss: 0.2916100025177002
Batch 25/64 loss: 0.2838176488876343
Batch 26/64 loss: 0.27880144119262695
Batch 27/64 loss: 0.2904772162437439
Batch 28/64 loss: 0.29263854026794434
Batch 29/64 loss: 0.2722984552383423
Batch 30/64 loss: 0.28938794136047363
Batch 31/64 loss: 0.2891676425933838
Batch 32/64 loss: 0.28255534172058105
Batch 33/64 loss: 0.2863718271255493
Batch 34/64 loss: 0.28059959411621094
Batch 35/64 loss: 0.2863525152206421
Batch 36/64 loss: 0.2937641143798828
Batch 37/64 loss: 0.28152644634246826
Batch 38/64 loss: 0.28129124641418457
Batch 39/64 loss: 0.29719120264053345
Batch 40/64 loss: 0.2806621789932251
Batch 41/64 loss: 0.2919940948486328
Batch 42/64 loss: 0.2852591276168823
Batch 43/64 loss: 0.2964475154876709
Batch 44/64 loss: 0.29380810260772705
Batch 45/64 loss: 0.28962433338165283
Batch 46/64 loss: 0.2793402671813965
Batch 47/64 loss: 0.2876546382904053
Batch 48/64 loss: 0.29131948947906494
Batch 49/64 loss: 0.2886018753051758
Batch 50/64 loss: 0.2850186228752136
Batch 51/64 loss: 0.27966225147247314
Batch 52/64 loss: 0.2892572283744812
Batch 53/64 loss: 0.2947818636894226
Batch 54/64 loss: 0.28402388095855713
Batch 55/64 loss: 0.28775060176849365
Batch 56/64 loss: 0.2893228530883789
Batch 57/64 loss: 0.2927209138870239
Batch 58/64 loss: 0.2861630916595459
Batch 59/64 loss: 0.2847785949707031
Batch 60/64 loss: 0.2792288661003113
Batch 61/64 loss: 0.2797502875328064
Batch 62/64 loss: 0.27718985080718994
Batch 63/64 loss: 0.2877647876739502
Batch 64/64 loss: 0.2942376136779785
Epoch 476  Train loss: 0.28529312376882515  Val loss: 0.32335054833454774
Epoch 477
-------------------------------
Batch 1/64 loss: 0.28441959619522095
Batch 2/64 loss: 0.2757441997528076
Batch 3/64 loss: 0.2854312062263489
Batch 4/64 loss: 0.28698551654815674
Batch 5/64 loss: 0.28553247451782227
Batch 6/64 loss: 0.2808496952056885
Batch 7/64 loss: 0.28369057178497314
Batch 8/64 loss: 0.2824169993400574
Batch 9/64 loss: 0.28372645378112793
Batch 10/64 loss: 0.28188377618789673
Batch 11/64 loss: 0.29597002267837524
Batch 12/64 loss: 0.2844432592391968
Batch 13/64 loss: 0.27425074577331543
Batch 14/64 loss: 0.2897263765335083
Batch 15/64 loss: 0.28248459100723267
Batch 16/64 loss: 0.29206758737564087
Batch 17/64 loss: 0.287619948387146
Batch 18/64 loss: 0.28583037853240967
Batch 19/64 loss: 0.2798823118209839
Batch 20/64 loss: 0.2835302948951721
Batch 21/64 loss: 0.28937816619873047
Batch 22/64 loss: 0.28399133682250977
Batch 23/64 loss: 0.278777539730072
Batch 24/64 loss: 0.27627241611480713
Batch 25/64 loss: 0.28862857818603516
Batch 26/64 loss: 0.27551257610321045
Batch 27/64 loss: 0.28570544719696045
Batch 28/64 loss: 0.29057466983795166
Batch 29/64 loss: 0.2920687198638916
Batch 30/64 loss: 0.29193806648254395
Batch 31/64 loss: 0.2789515256881714
Batch 32/64 loss: 0.28613489866256714
Batch 33/64 loss: 0.28975147008895874
Batch 34/64 loss: 0.2978692650794983
Batch 35/64 loss: 0.27883845567703247
Batch 36/64 loss: 0.2912256717681885
Batch 37/64 loss: 0.28034234046936035
Batch 38/64 loss: 0.2830652594566345
Batch 39/64 loss: 0.2809094786643982
Batch 40/64 loss: 0.28511250019073486
Batch 41/64 loss: 0.2885587215423584
Batch 42/64 loss: 0.28981369733810425
Batch 43/64 loss: 0.2765701413154602
Batch 44/64 loss: 0.28240877389907837
Batch 45/64 loss: 0.2832886576652527
Batch 46/64 loss: 0.2863227128982544
Batch 47/64 loss: 0.28915369510650635
Batch 48/64 loss: 0.28600239753723145
Batch 49/64 loss: 0.2852972745895386
Batch 50/64 loss: 0.2847764492034912
Batch 51/64 loss: 0.28926992416381836
Batch 52/64 loss: 0.2776683568954468
Batch 53/64 loss: 0.28597790002822876
Batch 54/64 loss: 0.2866227626800537
Batch 55/64 loss: 0.2848989963531494
Batch 56/64 loss: 0.28184711933135986
Batch 57/64 loss: 0.2865943908691406
Batch 58/64 loss: 0.2764381766319275
Batch 59/64 loss: 0.28123605251312256
Batch 60/64 loss: 0.2905312776565552
Batch 61/64 loss: 0.2822420597076416
Batch 62/64 loss: 0.2876935601234436
Batch 63/64 loss: 0.284900963306427
Batch 64/64 loss: 0.27888745069503784
Epoch 477  Train loss: 0.2846872790187013  Val loss: 0.3235345146910022
Epoch 478
-------------------------------
Batch 1/64 loss: 0.2908252477645874
Batch 2/64 loss: 0.2941476106643677
Batch 3/64 loss: 0.28550922870635986
Batch 4/64 loss: 0.28470849990844727
Batch 5/64 loss: 0.27366042137145996
Batch 6/64 loss: 0.2840169668197632
Batch 7/64 loss: 0.29014211893081665
Batch 8/64 loss: 0.28634387254714966
Batch 9/64 loss: 0.28128552436828613
Batch 10/64 loss: 0.27482861280441284
Batch 11/64 loss: 0.285056471824646
Batch 12/64 loss: 0.29725682735443115
Batch 13/64 loss: 0.2843121290206909
Batch 14/64 loss: 0.27736788988113403
Batch 15/64 loss: 0.2863784432411194
Batch 16/64 loss: 0.28954124450683594
Batch 17/64 loss: 0.27574634552001953
Batch 18/64 loss: 0.2802995443344116
Batch 19/64 loss: 0.2801562547683716
Batch 20/64 loss: 0.2838060259819031
Batch 21/64 loss: 0.2848261594772339
Batch 22/64 loss: 0.2849915027618408
Batch 23/64 loss: 0.279089093208313
Batch 24/64 loss: 0.28582876920700073
Batch 25/64 loss: 0.2953636646270752
Batch 26/64 loss: 0.2886911630630493
Batch 27/64 loss: 0.2835744619369507
Batch 28/64 loss: 0.28518784046173096
Batch 29/64 loss: 0.2794790267944336
Batch 30/64 loss: 0.2844972014427185
Batch 31/64 loss: 0.28008580207824707
Batch 32/64 loss: 0.28672558069229126
Batch 33/64 loss: 0.29216545820236206
Batch 34/64 loss: 0.2972272038459778
Batch 35/64 loss: 0.29400110244750977
Batch 36/64 loss: 0.2829626798629761
Batch 37/64 loss: 0.2891625165939331
Batch 38/64 loss: 0.2866814136505127
Batch 39/64 loss: 0.27855002880096436
Batch 40/64 loss: 0.2868509888648987
Batch 41/64 loss: 0.2848391532897949
Batch 42/64 loss: 0.2795671820640564
Batch 43/64 loss: 0.28393715620040894
Batch 44/64 loss: 0.2901759743690491
Batch 45/64 loss: 0.2793768644332886
Batch 46/64 loss: 0.2894937992095947
Batch 47/64 loss: 0.27621984481811523
Batch 48/64 loss: 0.2709296941757202
Batch 49/64 loss: 0.2861825227737427
Batch 50/64 loss: 0.27998387813568115
Batch 51/64 loss: 0.28076231479644775
Batch 52/64 loss: 0.28377294540405273
Batch 53/64 loss: 0.2924995422363281
Batch 54/64 loss: 0.2855810523033142
Batch 55/64 loss: 0.2820589542388916
Batch 56/64 loss: 0.2796299457550049
Batch 57/64 loss: 0.3034219741821289
Batch 58/64 loss: 0.28751522302627563
Batch 59/64 loss: 0.28649425506591797
Batch 60/64 loss: 0.282550573348999
Batch 61/64 loss: 0.29166507720947266
Batch 62/64 loss: 0.2758667469024658
Batch 63/64 loss: 0.2821924686431885
Batch 64/64 loss: 0.2950313091278076
Epoch 478  Train loss: 0.2849775931414436  Val loss: 0.323213473832894
Epoch 479
-------------------------------
Batch 1/64 loss: 0.2849189043045044
Batch 2/64 loss: 0.29080522060394287
Batch 3/64 loss: 0.2868174910545349
Batch 4/64 loss: 0.29074716567993164
Batch 5/64 loss: 0.2777292728424072
Batch 6/64 loss: 0.28777068853378296
Batch 7/64 loss: 0.289802610874176
Batch 8/64 loss: 0.2761726379394531
Batch 9/64 loss: 0.2852529287338257
Batch 10/64 loss: 0.28214478492736816
Batch 11/64 loss: 0.2865259647369385
Batch 12/64 loss: 0.28645920753479004
Batch 13/64 loss: 0.271740198135376
Batch 14/64 loss: 0.27984166145324707
Batch 15/64 loss: 0.2861288785934448
Batch 16/64 loss: 0.29317665100097656
Batch 17/64 loss: 0.28312915563583374
Batch 18/64 loss: 0.2911831736564636
Batch 19/64 loss: 0.28225964307785034
Batch 20/64 loss: 0.28536367416381836
Batch 21/64 loss: 0.280153751373291
Batch 22/64 loss: 0.2828298807144165
Batch 23/64 loss: 0.28966957330703735
Batch 24/64 loss: 0.2813432216644287
Batch 25/64 loss: 0.2824667692184448
Batch 26/64 loss: 0.2818995714187622
Batch 27/64 loss: 0.2855738401412964
Batch 28/64 loss: 0.2945981025695801
Batch 29/64 loss: 0.2981959581375122
Batch 30/64 loss: 0.28282010555267334
Batch 31/64 loss: 0.2895912528038025
Batch 32/64 loss: 0.2849825620651245
Batch 33/64 loss: 0.28463661670684814
Batch 34/64 loss: 0.28309786319732666
Batch 35/64 loss: 0.27862393856048584
Batch 36/64 loss: 0.2875511646270752
Batch 37/64 loss: 0.2846745252609253
Batch 38/64 loss: 0.2891829013824463
Batch 39/64 loss: 0.2851572036743164
Batch 40/64 loss: 0.2813246250152588
Batch 41/64 loss: 0.2875487208366394
Batch 42/64 loss: 0.27704107761383057
Batch 43/64 loss: 0.2913263440132141
Batch 44/64 loss: 0.27403485774993896
Batch 45/64 loss: 0.2875089645385742
Batch 46/64 loss: 0.27255702018737793
Batch 47/64 loss: 0.2869884967803955
Batch 48/64 loss: 0.29155802726745605
Batch 49/64 loss: 0.285333514213562
Batch 50/64 loss: 0.2847370505332947
Batch 51/64 loss: 0.28191065788269043
Batch 52/64 loss: 0.2903851866722107
Batch 53/64 loss: 0.2874453067779541
Batch 54/64 loss: 0.2713913917541504
Batch 55/64 loss: 0.28838449716567993
Batch 56/64 loss: 0.2930217981338501
Batch 57/64 loss: 0.28365588188171387
Batch 58/64 loss: 0.2837996482849121
Batch 59/64 loss: 0.2920437455177307
Batch 60/64 loss: 0.2869511842727661
Batch 61/64 loss: 0.28376710414886475
Batch 62/64 loss: 0.2879297733306885
Batch 63/64 loss: 0.27469921112060547
Batch 64/64 loss: 0.283708393573761
Epoch 479  Train loss: 0.28491206426246496  Val loss: 0.3235393606920013
Epoch 480
-------------------------------
Batch 1/64 loss: 0.2930196523666382
Batch 2/64 loss: 0.29834121465682983
Batch 3/64 loss: 0.28352808952331543
Batch 4/64 loss: 0.2939980626106262
Batch 5/64 loss: 0.28694188594818115
Batch 6/64 loss: 0.28325557708740234
Batch 7/64 loss: 0.28626734018325806
Batch 8/64 loss: 0.2850015163421631
Batch 9/64 loss: 0.27898359298706055
Batch 10/64 loss: 0.28448712825775146
Batch 11/64 loss: 0.28010958433151245
Batch 12/64 loss: 0.2855043411254883
Batch 13/64 loss: 0.29261744022369385
Batch 14/64 loss: 0.2831641435623169
Batch 15/64 loss: 0.28656065464019775
Batch 16/64 loss: 0.2823922038078308
Batch 17/64 loss: 0.2978050112724304
Batch 18/64 loss: 0.2960670590400696
Batch 19/64 loss: 0.2887653112411499
Batch 20/64 loss: 0.2840794324874878
Batch 21/64 loss: 0.27990442514419556
Batch 22/64 loss: 0.2828023433685303
Batch 23/64 loss: 0.2830824851989746
Batch 24/64 loss: 0.2870146632194519
Batch 25/64 loss: 0.2832498550415039
Batch 26/64 loss: 0.28500795364379883
Batch 27/64 loss: 0.2825280427932739
Batch 28/64 loss: 0.27391839027404785
Batch 29/64 loss: 0.28408241271972656
Batch 30/64 loss: 0.2732086181640625
Batch 31/64 loss: 0.27796727418899536
Batch 32/64 loss: 0.28197401762008667
Batch 33/64 loss: 0.285846471786499
Batch 34/64 loss: 0.29072654247283936
Batch 35/64 loss: 0.27657341957092285
Batch 36/64 loss: 0.28947949409484863
Batch 37/64 loss: 0.2838744521141052
Batch 38/64 loss: 0.2718992233276367
Batch 39/64 loss: 0.2723936438560486
Batch 40/64 loss: 0.28277504444122314
Batch 41/64 loss: 0.2807896137237549
Batch 42/64 loss: 0.2881286144256592
Batch 43/64 loss: 0.29376220703125
Batch 44/64 loss: 0.27898716926574707
Batch 45/64 loss: 0.27934932708740234
Batch 46/64 loss: 0.27585065364837646
Batch 47/64 loss: 0.2834649682044983
Batch 48/64 loss: 0.28853392601013184
Batch 49/64 loss: 0.28051018714904785
Batch 50/64 loss: 0.2811307907104492
Batch 51/64 loss: 0.2831674814224243
Batch 52/64 loss: 0.2809569239616394
Batch 53/64 loss: 0.2800619602203369
Batch 54/64 loss: 0.28276777267456055
Batch 55/64 loss: 0.28567957878112793
Batch 56/64 loss: 0.2870144844055176
Batch 57/64 loss: 0.285663366317749
Batch 58/64 loss: 0.2818613052368164
Batch 59/64 loss: 0.29692161083221436
Batch 60/64 loss: 0.2911338806152344
Batch 61/64 loss: 0.2883484959602356
Batch 62/64 loss: 0.30191344022750854
Batch 63/64 loss: 0.28596752882003784
Batch 64/64 loss: 0.28223663568496704
Epoch 480  Train loss: 0.2847504435801039  Val loss: 0.3235476152184083
Epoch 481
-------------------------------
Batch 1/64 loss: 0.2785557508468628
Batch 2/64 loss: 0.2759760618209839
Batch 3/64 loss: 0.28770655393600464
Batch 4/64 loss: 0.28675907850265503
Batch 5/64 loss: 0.28501737117767334
Batch 6/64 loss: 0.2939225435256958
Batch 7/64 loss: 0.2819312810897827
Batch 8/64 loss: 0.2817472219467163
Batch 9/64 loss: 0.2848501205444336
Batch 10/64 loss: 0.2891223430633545
Batch 11/64 loss: 0.29097121953964233
Batch 12/64 loss: 0.27972662448883057
Batch 13/64 loss: 0.27762389183044434
Batch 14/64 loss: 0.2842501401901245
Batch 15/64 loss: 0.29746317863464355
Batch 16/64 loss: 0.2780219316482544
Batch 17/64 loss: 0.2879183292388916
Batch 18/64 loss: 0.2870672941207886
Batch 19/64 loss: 0.28709113597869873
Batch 20/64 loss: 0.291973352432251
Batch 21/64 loss: 0.2839503884315491
Batch 22/64 loss: 0.28786468505859375
Batch 23/64 loss: 0.29268765449523926
Batch 24/64 loss: 0.28196853399276733
Batch 25/64 loss: 0.2822312116622925
Batch 26/64 loss: 0.28484082221984863
Batch 27/64 loss: 0.2731820344924927
Batch 28/64 loss: 0.284024715423584
Batch 29/64 loss: 0.28202223777770996
Batch 30/64 loss: 0.2855926752090454
Batch 31/64 loss: 0.2879484295845032
Batch 32/64 loss: 0.2829161286354065
Batch 33/64 loss: 0.27635347843170166
Batch 34/64 loss: 0.2854810953140259
Batch 35/64 loss: 0.2789364457130432
Batch 36/64 loss: 0.2795368432998657
Batch 37/64 loss: 0.29236090183258057
Batch 38/64 loss: 0.2792128324508667
Batch 39/64 loss: 0.2854856252670288
Batch 40/64 loss: 0.2844589352607727
Batch 41/64 loss: 0.29070913791656494
Batch 42/64 loss: 0.2817261815071106
Batch 43/64 loss: 0.289078950881958
Batch 44/64 loss: 0.27787113189697266
Batch 45/64 loss: 0.3027532696723938
Batch 46/64 loss: 0.278881311416626
Batch 47/64 loss: 0.30091750621795654
Batch 48/64 loss: 0.289188027381897
Batch 49/64 loss: 0.2867140769958496
Batch 50/64 loss: 0.2900972366333008
Batch 51/64 loss: 0.283413290977478
Batch 52/64 loss: 0.28699803352355957
Batch 53/64 loss: 0.28416121006011963
Batch 54/64 loss: 0.281246542930603
Batch 55/64 loss: 0.2888435125350952
Batch 56/64 loss: 0.2746652364730835
Batch 57/64 loss: 0.2884540557861328
Batch 58/64 loss: 0.29106563329696655
Batch 59/64 loss: 0.28609633445739746
Batch 60/64 loss: 0.2827190160751343
Batch 61/64 loss: 0.28717029094696045
Batch 62/64 loss: 0.28258979320526123
Batch 63/64 loss: 0.27550601959228516
Batch 64/64 loss: 0.27924132347106934
Epoch 481  Train loss: 0.2850046728171554  Val loss: 0.32270552796596513
Epoch 482
-------------------------------
Batch 1/64 loss: 0.2791857123374939
Batch 2/64 loss: 0.2805095314979553
Batch 3/64 loss: 0.28213024139404297
Batch 4/64 loss: 0.2793499231338501
Batch 5/64 loss: 0.2822979688644409
Batch 6/64 loss: 0.28659164905548096
Batch 7/64 loss: 0.2866368889808655
Batch 8/64 loss: 0.28283101320266724
Batch 9/64 loss: 0.29620909690856934
Batch 10/64 loss: 0.2890169620513916
Batch 11/64 loss: 0.27521663904190063
Batch 12/64 loss: 0.2885851263999939
Batch 13/64 loss: 0.2864561080932617
Batch 14/64 loss: 0.2904052138328552
Batch 15/64 loss: 0.2852799892425537
Batch 16/64 loss: 0.28087544441223145
Batch 17/64 loss: 0.296528697013855
Batch 18/64 loss: 0.2923845052719116
Batch 19/64 loss: 0.27815353870391846
Batch 20/64 loss: 0.27842724323272705
Batch 21/64 loss: 0.2757018804550171
Batch 22/64 loss: 0.2751861810684204
Batch 23/64 loss: 0.28072911500930786
Batch 24/64 loss: 0.28145909309387207
Batch 25/64 loss: 0.27546191215515137
Batch 26/64 loss: 0.2796279191970825
Batch 27/64 loss: 0.2821139097213745
Batch 28/64 loss: 0.2751504182815552
Batch 29/64 loss: 0.2860570549964905
Batch 30/64 loss: 0.2839919328689575
Batch 31/64 loss: 0.2977970838546753
Batch 32/64 loss: 0.2799873352050781
Batch 33/64 loss: 0.28923672437667847
Batch 34/64 loss: 0.2838019132614136
Batch 35/64 loss: 0.2883495092391968
Batch 36/64 loss: 0.2853128910064697
Batch 37/64 loss: 0.28527504205703735
Batch 38/64 loss: 0.27937763929367065
Batch 39/64 loss: 0.27719831466674805
Batch 40/64 loss: 0.2847709655761719
Batch 41/64 loss: 0.28868722915649414
Batch 42/64 loss: 0.28525757789611816
Batch 43/64 loss: 0.29508548974990845
Batch 44/64 loss: 0.282352089881897
Batch 45/64 loss: 0.2711576819419861
Batch 46/64 loss: 0.28406816720962524
Batch 47/64 loss: 0.2921023368835449
Batch 48/64 loss: 0.28840065002441406
Batch 49/64 loss: 0.273743212223053
Batch 50/64 loss: 0.2810720205307007
Batch 51/64 loss: 0.27776122093200684
Batch 52/64 loss: 0.2874096632003784
Batch 53/64 loss: 0.2783862352371216
Batch 54/64 loss: 0.27998071908950806
Batch 55/64 loss: 0.28211694955825806
Batch 56/64 loss: 0.2865923047065735
Batch 57/64 loss: 0.282254695892334
Batch 58/64 loss: 0.2876347303390503
Batch 59/64 loss: 0.2864392399787903
Batch 60/64 loss: 0.2797037959098816
Batch 61/64 loss: 0.2857956886291504
Batch 62/64 loss: 0.29123759269714355
Batch 63/64 loss: 0.2925799489021301
Batch 64/64 loss: 0.28882133960723877
Epoch 482  Train loss: 0.2839230364444209  Val loss: 0.323829408363788
Epoch 483
-------------------------------
Batch 1/64 loss: 0.2778078317642212
Batch 2/64 loss: 0.2837108373641968
Batch 3/64 loss: 0.26923656463623047
Batch 4/64 loss: 0.2884792685508728
Batch 5/64 loss: 0.28280436992645264
Batch 6/64 loss: 0.2872915267944336
Batch 7/64 loss: 0.28986406326293945
Batch 8/64 loss: 0.2695232629776001
Batch 9/64 loss: 0.28846466541290283
Batch 10/64 loss: 0.28201520442962646
Batch 11/64 loss: 0.284981906414032
Batch 12/64 loss: 0.2806098461151123
Batch 13/64 loss: 0.27864718437194824
Batch 14/64 loss: 0.28958386182785034
Batch 15/64 loss: 0.2955498695373535
Batch 16/64 loss: 0.27731919288635254
Batch 17/64 loss: 0.2779430150985718
Batch 18/64 loss: 0.2880229949951172
Batch 19/64 loss: 0.2820470929145813
Batch 20/64 loss: 0.2803182601928711
Batch 21/64 loss: 0.27530723810195923
Batch 22/64 loss: 0.279413640499115
Batch 23/64 loss: 0.2928834557533264
Batch 24/64 loss: 0.2805573344230652
Batch 25/64 loss: 0.2768979072570801
Batch 26/64 loss: 0.2736382484436035
Batch 27/64 loss: 0.29877424240112305
Batch 28/64 loss: 0.2884904742240906
Batch 29/64 loss: 0.2853166460990906
Batch 30/64 loss: 0.2728167772293091
Batch 31/64 loss: 0.2788424491882324
Batch 32/64 loss: 0.27952343225479126
Batch 33/64 loss: 0.29820144176483154
Batch 34/64 loss: 0.2723960876464844
Batch 35/64 loss: 0.2880399823188782
Batch 36/64 loss: 0.2779545783996582
Batch 37/64 loss: 0.2903575897216797
Batch 38/64 loss: 0.27303916215896606
Batch 39/64 loss: 0.2790378928184509
Batch 40/64 loss: 0.28676390647888184
Batch 41/64 loss: 0.28401100635528564
Batch 42/64 loss: 0.2928643226623535
Batch 43/64 loss: 0.29209351539611816
Batch 44/64 loss: 0.2984621524810791
Batch 45/64 loss: 0.2915356159210205
Batch 46/64 loss: 0.28093957901000977
Batch 47/64 loss: 0.2888486385345459
Batch 48/64 loss: 0.2924344539642334
Batch 49/64 loss: 0.2949056029319763
Batch 50/64 loss: 0.2975085973739624
Batch 51/64 loss: 0.28460001945495605
Batch 52/64 loss: 0.29117655754089355
Batch 53/64 loss: 0.28526192903518677
Batch 54/64 loss: 0.2776668071746826
Batch 55/64 loss: 0.2825518846511841
Batch 56/64 loss: 0.2815774083137512
Batch 57/64 loss: 0.2824462652206421
Batch 58/64 loss: 0.28917258977890015
Batch 59/64 loss: 0.29249870777130127
Batch 60/64 loss: 0.28426027297973633
Batch 61/64 loss: 0.2778078317642212
Batch 62/64 loss: 0.28454697132110596
Batch 63/64 loss: 0.2894201874732971
Batch 64/64 loss: 0.2992252707481384
Epoch 483  Train loss: 0.28460365767572443  Val loss: 0.3224077714267875
Epoch 484
-------------------------------
Batch 1/64 loss: 0.28599846363067627
Batch 2/64 loss: 0.27616071701049805
Batch 3/64 loss: 0.2912837862968445
Batch 4/64 loss: 0.28657275438308716
Batch 5/64 loss: 0.28786545991897583
Batch 6/64 loss: 0.27792298793792725
Batch 7/64 loss: 0.28685033321380615
Batch 8/64 loss: 0.2744958996772766
Batch 9/64 loss: 0.2813512682914734
Batch 10/64 loss: 0.28520023822784424
Batch 11/64 loss: 0.27680259943008423
Batch 12/64 loss: 0.2878246307373047
Batch 13/64 loss: 0.29316210746765137
Batch 14/64 loss: 0.2963517904281616
Batch 15/64 loss: 0.2862008810043335
Batch 16/64 loss: 0.29911768436431885
Batch 17/64 loss: 0.2860320210456848
Batch 18/64 loss: 0.2718028426170349
Batch 19/64 loss: 0.276623010635376
Batch 20/64 loss: 0.2793676257133484
Batch 21/64 loss: 0.2813425064086914
Batch 22/64 loss: 0.2820870280265808
Batch 23/64 loss: 0.28926414251327515
Batch 24/64 loss: 0.29599320888519287
Batch 25/64 loss: 0.2731752395629883
Batch 26/64 loss: 0.27972090244293213
Batch 27/64 loss: 0.2840908169746399
Batch 28/64 loss: 0.28038322925567627
Batch 29/64 loss: 0.2767680883407593
Batch 30/64 loss: 0.28289783000946045
Batch 31/64 loss: 0.280780553817749
Batch 32/64 loss: 0.28054916858673096
Batch 33/64 loss: 0.29007983207702637
Batch 34/64 loss: 0.2901116609573364
Batch 35/64 loss: 0.2766026258468628
Batch 36/64 loss: 0.28640246391296387
Batch 37/64 loss: 0.2849006652832031
Batch 38/64 loss: 0.2759122848510742
Batch 39/64 loss: 0.283572256565094
Batch 40/64 loss: 0.2801915407180786
Batch 41/64 loss: 0.29386264085769653
Batch 42/64 loss: 0.28941810131073
Batch 43/64 loss: 0.2803291082382202
Batch 44/64 loss: 0.27299052476882935
Batch 45/64 loss: 0.2863394021987915
Batch 46/64 loss: 0.28158634901046753
Batch 47/64 loss: 0.28991127014160156
Batch 48/64 loss: 0.2751048803329468
Batch 49/64 loss: 0.28242355585098267
Batch 50/64 loss: 0.2859154939651489
Batch 51/64 loss: 0.290529727935791
Batch 52/64 loss: 0.2790723443031311
Batch 53/64 loss: 0.2816203832626343
Batch 54/64 loss: 0.28424036502838135
Batch 55/64 loss: 0.28600990772247314
Batch 56/64 loss: 0.27490341663360596
Batch 57/64 loss: 0.27125948667526245
Batch 58/64 loss: 0.28747832775115967
Batch 59/64 loss: 0.2885488271713257
Batch 60/64 loss: 0.29119694232940674
Batch 61/64 loss: 0.29280948638916016
Batch 62/64 loss: 0.2895652651786804
Batch 63/64 loss: 0.29251784086227417
Batch 64/64 loss: 0.29505932331085205
Epoch 484  Train loss: 0.284090059411292  Val loss: 0.32374315634625883
Epoch 485
-------------------------------
Batch 1/64 loss: 0.29655468463897705
Batch 2/64 loss: 0.2805868983268738
Batch 3/64 loss: 0.29113030433654785
Batch 4/64 loss: 0.286498486995697
Batch 5/64 loss: 0.29065370559692383
Batch 6/64 loss: 0.29082751274108887
Batch 7/64 loss: 0.28643620014190674
Batch 8/64 loss: 0.28712528944015503
Batch 9/64 loss: 0.2793128490447998
Batch 10/64 loss: 0.2898138761520386
Batch 11/64 loss: 0.2740226984024048
Batch 12/64 loss: 0.27544403076171875
Batch 13/64 loss: 0.28110527992248535
Batch 14/64 loss: 0.27020132541656494
Batch 15/64 loss: 0.2968980073928833
Batch 16/64 loss: 0.2810046672821045
Batch 17/64 loss: 0.2754114866256714
Batch 18/64 loss: 0.27631163597106934
Batch 19/64 loss: 0.27674204111099243
Batch 20/64 loss: 0.29574406147003174
Batch 21/64 loss: 0.28800880908966064
Batch 22/64 loss: 0.29947084188461304
Batch 23/64 loss: 0.2807301878929138
Batch 24/64 loss: 0.28170108795166016
Batch 25/64 loss: 0.30068832635879517
Batch 26/64 loss: 0.28762364387512207
Batch 27/64 loss: 0.28909021615982056
Batch 28/64 loss: 0.2737586498260498
Batch 29/64 loss: 0.28207457065582275
Batch 30/64 loss: 0.2917311191558838
Batch 31/64 loss: 0.29469436407089233
Batch 32/64 loss: 0.2923424243927002
Batch 33/64 loss: 0.28953778743743896
Batch 34/64 loss: 0.2870734930038452
Batch 35/64 loss: 0.28312426805496216
Batch 36/64 loss: 0.27655982971191406
Batch 37/64 loss: 0.2873387336730957
Batch 38/64 loss: 0.2881927490234375
Batch 39/64 loss: 0.29318249225616455
Batch 40/64 loss: 0.2840065360069275
Batch 41/64 loss: 0.27794086933135986
Batch 42/64 loss: 0.28793013095855713
Batch 43/64 loss: 0.27519869804382324
Batch 44/64 loss: 0.2848285436630249
Batch 45/64 loss: 0.2936534881591797
Batch 46/64 loss: 0.2808504104614258
Batch 47/64 loss: 0.27780842781066895
Batch 48/64 loss: 0.2840946912765503
Batch 49/64 loss: 0.2735130190849304
Batch 50/64 loss: 0.29114973545074463
Batch 51/64 loss: 0.28536468744277954
Batch 52/64 loss: 0.2684926390647888
Batch 53/64 loss: 0.2774754762649536
Batch 54/64 loss: 0.2744410037994385
Batch 55/64 loss: 0.2958220839500427
Batch 56/64 loss: 0.29036325216293335
Batch 57/64 loss: 0.27804189920425415
Batch 58/64 loss: 0.2738475203514099
Batch 59/64 loss: 0.2784513235092163
Batch 60/64 loss: 0.2784077525138855
Batch 61/64 loss: 0.2996929883956909
Batch 62/64 loss: 0.2903386354446411
Batch 63/64 loss: 0.28742867708206177
Batch 64/64 loss: 0.29143673181533813
Epoch 485  Train loss: 0.28480735175749833  Val loss: 0.32206809479756043
Epoch 486
-------------------------------
Batch 1/64 loss: 0.2943904399871826
Batch 2/64 loss: 0.28129714727401733
Batch 3/64 loss: 0.27996647357940674
Batch 4/64 loss: 0.28748762607574463
Batch 5/64 loss: 0.2762243151664734
Batch 6/64 loss: 0.2812734842300415
Batch 7/64 loss: 0.28264492750167847
Batch 8/64 loss: 0.2795138359069824
Batch 9/64 loss: 0.28377479314804077
Batch 10/64 loss: 0.2836647033691406
Batch 11/64 loss: 0.2831932306289673
Batch 12/64 loss: 0.2854071855545044
Batch 13/64 loss: 0.29235023260116577
Batch 14/64 loss: 0.2789093255996704
Batch 15/64 loss: 0.27920275926589966
Batch 16/64 loss: 0.28443020582199097
Batch 17/64 loss: 0.2788712978363037
Batch 18/64 loss: 0.27931851148605347
Batch 19/64 loss: 0.2891507148742676
Batch 20/64 loss: 0.28458166122436523
Batch 21/64 loss: 0.28251951932907104
Batch 22/64 loss: 0.27940618991851807
Batch 23/64 loss: 0.2886084318161011
Batch 24/64 loss: 0.27859359979629517
Batch 25/64 loss: 0.2918747663497925
Batch 26/64 loss: 0.2806006073951721
Batch 27/64 loss: 0.2777935266494751
Batch 28/64 loss: 0.2782769799232483
Batch 29/64 loss: 0.28454166650772095
Batch 30/64 loss: 0.2928546667098999
Batch 31/64 loss: 0.2773458957672119
Batch 32/64 loss: 0.2844425439834595
Batch 33/64 loss: 0.2817593216896057
Batch 34/64 loss: 0.2864111661911011
Batch 35/64 loss: 0.2797953486442566
Batch 36/64 loss: 0.28829753398895264
Batch 37/64 loss: 0.2965720295906067
Batch 38/64 loss: 0.2816791534423828
Batch 39/64 loss: 0.2821347713470459
Batch 40/64 loss: 0.28448963165283203
Batch 41/64 loss: 0.2840297222137451
Batch 42/64 loss: 0.2823787331581116
Batch 43/64 loss: 0.2809460163116455
Batch 44/64 loss: 0.2767702341079712
Batch 45/64 loss: 0.28823792934417725
Batch 46/64 loss: 0.2907681465148926
Batch 47/64 loss: 0.2937314510345459
Batch 48/64 loss: 0.28963345289230347
Batch 49/64 loss: 0.276666522026062
Batch 50/64 loss: 0.28233838081359863
Batch 51/64 loss: 0.2751791477203369
Batch 52/64 loss: 0.2943716049194336
Batch 53/64 loss: 0.2827528715133667
Batch 54/64 loss: 0.28692102432250977
Batch 55/64 loss: 0.27304601669311523
Batch 56/64 loss: 0.2880857586860657
Batch 57/64 loss: 0.29801303148269653
Batch 58/64 loss: 0.2791144847869873
Batch 59/64 loss: 0.2928966283798218
Batch 60/64 loss: 0.27861130237579346
Batch 61/64 loss: 0.2979544401168823
Batch 62/64 loss: 0.28393054008483887
Batch 63/64 loss: 0.28696775436401367
Batch 64/64 loss: 0.280564546585083
Epoch 486  Train loss: 0.28419480510786466  Val loss: 0.32300637288601536
Epoch 487
-------------------------------
Batch 1/64 loss: 0.27359509468078613
Batch 2/64 loss: 0.28180956840515137
Batch 3/64 loss: 0.2883339524269104
Batch 4/64 loss: 0.2781015634536743
Batch 5/64 loss: 0.28734850883483887
Batch 6/64 loss: 0.2868431806564331
Batch 7/64 loss: 0.28275513648986816
Batch 8/64 loss: 0.2969525456428528
Batch 9/64 loss: 0.28347861766815186
Batch 10/64 loss: 0.27896368503570557
Batch 11/64 loss: 0.2884477376937866
Batch 12/64 loss: 0.28043437004089355
Batch 13/64 loss: 0.2813257575035095
Batch 14/64 loss: 0.28027790784835815
Batch 15/64 loss: 0.2830774784088135
Batch 16/64 loss: 0.287597119808197
Batch 17/64 loss: 0.2746610641479492
Batch 18/64 loss: 0.284013032913208
Batch 19/64 loss: 0.2898738384246826
Batch 20/64 loss: 0.28083640336990356
Batch 21/64 loss: 0.2877196669578552
Batch 22/64 loss: 0.2746720314025879
Batch 23/64 loss: 0.28536856174468994
Batch 24/64 loss: 0.280658483505249
Batch 25/64 loss: 0.2773197293281555
Batch 26/64 loss: 0.28343361616134644
Batch 27/64 loss: 0.2735496759414673
Batch 28/64 loss: 0.28406262397766113
Batch 29/64 loss: 0.2893299460411072
Batch 30/64 loss: 0.2789747714996338
Batch 31/64 loss: 0.27869999408721924
Batch 32/64 loss: 0.2781136631965637
Batch 33/64 loss: 0.28672367334365845
Batch 34/64 loss: 0.27691197395324707
Batch 35/64 loss: 0.287105917930603
Batch 36/64 loss: 0.28739267587661743
Batch 37/64 loss: 0.2887643575668335
Batch 38/64 loss: 0.2841012477874756
Batch 39/64 loss: 0.2813680171966553
Batch 40/64 loss: 0.27650541067123413
Batch 41/64 loss: 0.28612762689590454
Batch 42/64 loss: 0.2882136106491089
Batch 43/64 loss: 0.28157132863998413
Batch 44/64 loss: 0.2857097387313843
Batch 45/64 loss: 0.2790009379386902
Batch 46/64 loss: 0.2884942293167114
Batch 47/64 loss: 0.29956281185150146
Batch 48/64 loss: 0.2825039029121399
Batch 49/64 loss: 0.27284592390060425
Batch 50/64 loss: 0.29065585136413574
Batch 51/64 loss: 0.2826685309410095
Batch 52/64 loss: 0.2909192442893982
Batch 53/64 loss: 0.30062317848205566
Batch 54/64 loss: 0.29566264152526855
Batch 55/64 loss: 0.29654788970947266
Batch 56/64 loss: 0.2795153856277466
Batch 57/64 loss: 0.288094162940979
Batch 58/64 loss: 0.2828575372695923
Batch 59/64 loss: 0.27445077896118164
Batch 60/64 loss: 0.2889872193336487
Batch 61/64 loss: 0.28578072786331177
Batch 62/64 loss: 0.29058176279067993
Batch 63/64 loss: 0.28336143493652344
Batch 64/64 loss: 0.29176121950149536
Epoch 487  Train loss: 0.2842832936960108  Val loss: 0.3240262605889966
Epoch 488
-------------------------------
Batch 1/64 loss: 0.28035205602645874
Batch 2/64 loss: 0.27906322479248047
Batch 3/64 loss: 0.2804844379425049
Batch 4/64 loss: 0.2923269271850586
Batch 5/64 loss: 0.2891627550125122
Batch 6/64 loss: 0.28415489196777344
Batch 7/64 loss: 0.2869683504104614
Batch 8/64 loss: 0.2810856103897095
Batch 9/64 loss: 0.2897123098373413
Batch 10/64 loss: 0.2803748846054077
Batch 11/64 loss: 0.2825334072113037
Batch 12/64 loss: 0.28232038021087646
Batch 13/64 loss: 0.2816762328147888
Batch 14/64 loss: 0.2907751798629761
Batch 15/64 loss: 0.2810298204421997
Batch 16/64 loss: 0.27912086248397827
Batch 17/64 loss: 0.28551459312438965
Batch 18/64 loss: 0.2771338224411011
Batch 19/64 loss: 0.2898513674736023
Batch 20/64 loss: 0.2802877426147461
Batch 21/64 loss: 0.2903600335121155
Batch 22/64 loss: 0.2813851833343506
Batch 23/64 loss: 0.280304491519928
Batch 24/64 loss: 0.27910447120666504
Batch 25/64 loss: 0.28268659114837646
Batch 26/64 loss: 0.26743656396865845
Batch 27/64 loss: 0.28305554389953613
Batch 28/64 loss: 0.29085445404052734
Batch 29/64 loss: 0.275718092918396
Batch 30/64 loss: 0.2926926612854004
Batch 31/64 loss: 0.27604585886001587
Batch 32/64 loss: 0.2768007516860962
Batch 33/64 loss: 0.2884622812271118
Batch 34/64 loss: 0.27763378620147705
Batch 35/64 loss: 0.2788506746292114
Batch 36/64 loss: 0.29189616441726685
Batch 37/64 loss: 0.28367286920547485
Batch 38/64 loss: 0.28608107566833496
Batch 39/64 loss: 0.28037887811660767
Batch 40/64 loss: 0.3020087480545044
Batch 41/64 loss: 0.28870803117752075
Batch 42/64 loss: 0.2855456471443176
Batch 43/64 loss: 0.28793638944625854
Batch 44/64 loss: 0.27909135818481445
Batch 45/64 loss: 0.28080111742019653
Batch 46/64 loss: 0.28263747692108154
Batch 47/64 loss: 0.2759491205215454
Batch 48/64 loss: 0.28853368759155273
Batch 49/64 loss: 0.28411662578582764
Batch 50/64 loss: 0.2871357202529907
Batch 51/64 loss: 0.28229576349258423
Batch 52/64 loss: 0.2758607864379883
Batch 53/64 loss: 0.2784616947174072
Batch 54/64 loss: 0.29181182384490967
Batch 55/64 loss: 0.2826065421104431
Batch 56/64 loss: 0.2828848361968994
Batch 57/64 loss: 0.2803419232368469
Batch 58/64 loss: 0.29099977016448975
Batch 59/64 loss: 0.29086923599243164
Batch 60/64 loss: 0.2756415605545044
Batch 61/64 loss: 0.2875266671180725
Batch 62/64 loss: 0.2785247564315796
Batch 63/64 loss: 0.286426842212677
Batch 64/64 loss: 0.30417585372924805
Epoch 488  Train loss: 0.28379917331770355  Val loss: 0.3236277070651759
Epoch 489
-------------------------------
Batch 1/64 loss: 0.2849559783935547
Batch 2/64 loss: 0.2765967845916748
Batch 3/64 loss: 0.28289127349853516
Batch 4/64 loss: 0.28776395320892334
Batch 5/64 loss: 0.2802262306213379
Batch 6/64 loss: 0.29579007625579834
Batch 7/64 loss: 0.2874934673309326
Batch 8/64 loss: 0.2889784574508667
Batch 9/64 loss: 0.2890107035636902
Batch 10/64 loss: 0.2819424867630005
Batch 11/64 loss: 0.28642725944519043
Batch 12/64 loss: 0.2867586612701416
Batch 13/64 loss: 0.2878672480583191
Batch 14/64 loss: 0.28515708446502686
Batch 15/64 loss: 0.27487337589263916
Batch 16/64 loss: 0.2869236469268799
Batch 17/64 loss: 0.28139758110046387
Batch 18/64 loss: 0.28883910179138184
Batch 19/64 loss: 0.292269766330719
Batch 20/64 loss: 0.2893359661102295
Batch 21/64 loss: 0.2741425633430481
Batch 22/64 loss: 0.2872776389122009
Batch 23/64 loss: 0.27768081426620483
Batch 24/64 loss: 0.27912670373916626
Batch 25/64 loss: 0.29151779413223267
Batch 26/64 loss: 0.29591691493988037
Batch 27/64 loss: 0.2830040454864502
Batch 28/64 loss: 0.2888021469116211
Batch 29/64 loss: 0.2832615375518799
Batch 30/64 loss: 0.2776317596435547
Batch 31/64 loss: 0.27925562858581543
Batch 32/64 loss: 0.28005027770996094
Batch 33/64 loss: 0.27647972106933594
Batch 34/64 loss: 0.302761435508728
Batch 35/64 loss: 0.2769114375114441
Batch 36/64 loss: 0.27703481912612915
Batch 37/64 loss: 0.2853160500526428
Batch 38/64 loss: 0.2836456894874573
Batch 39/64 loss: 0.28595060110092163
Batch 40/64 loss: 0.28636109828948975
Batch 41/64 loss: 0.2801553010940552
Batch 42/64 loss: 0.2806973457336426
Batch 43/64 loss: 0.27920204401016235
Batch 44/64 loss: 0.28305429220199585
Batch 45/64 loss: 0.28051841259002686
Batch 46/64 loss: 0.2818169593811035
Batch 47/64 loss: 0.28168147802352905
Batch 48/64 loss: 0.2769209146499634
Batch 49/64 loss: 0.2760620713233948
Batch 50/64 loss: 0.2833588719367981
Batch 51/64 loss: 0.28145354986190796
Batch 52/64 loss: 0.27974724769592285
Batch 53/64 loss: 0.2819085121154785
Batch 54/64 loss: 0.28486430644989014
Batch 55/64 loss: 0.2898441553115845
Batch 56/64 loss: 0.282243013381958
Batch 57/64 loss: 0.27606773376464844
Batch 58/64 loss: 0.2794126868247986
Batch 59/64 loss: 0.2848767042160034
Batch 60/64 loss: 0.2925826907157898
Batch 61/64 loss: 0.28567421436309814
Batch 62/64 loss: 0.2863631844520569
Batch 63/64 loss: 0.276821494102478
Batch 64/64 loss: 0.29812943935394287
Epoch 489  Train loss: 0.2838674830455406  Val loss: 0.3226732791903912
Epoch 490
-------------------------------
Batch 1/64 loss: 0.2892465591430664
Batch 2/64 loss: 0.2797437906265259
Batch 3/64 loss: 0.2842894196510315
Batch 4/64 loss: 0.2780146598815918
Batch 5/64 loss: 0.27620619535446167
Batch 6/64 loss: 0.28138643503189087
Batch 7/64 loss: 0.28737783432006836
Batch 8/64 loss: 0.283100426197052
Batch 9/64 loss: 0.29340219497680664
Batch 10/64 loss: 0.28569960594177246
Batch 11/64 loss: 0.2812669277191162
Batch 12/64 loss: 0.29013365507125854
Batch 13/64 loss: 0.28295308351516724
Batch 14/64 loss: 0.2846020460128784
Batch 15/64 loss: 0.2822641134262085
Batch 16/64 loss: 0.2841857671737671
Batch 17/64 loss: 0.28333884477615356
Batch 18/64 loss: 0.2936074733734131
Batch 19/64 loss: 0.27607327699661255
Batch 20/64 loss: 0.2927079200744629
Batch 21/64 loss: 0.2779902219772339
Batch 22/64 loss: 0.2848976254463196
Batch 23/64 loss: 0.28224122524261475
Batch 24/64 loss: 0.2851524353027344
Batch 25/64 loss: 0.2885897159576416
Batch 26/64 loss: 0.28959864377975464
Batch 27/64 loss: 0.2824472188949585
Batch 28/64 loss: 0.2900998592376709
Batch 29/64 loss: 0.27920764684677124
Batch 30/64 loss: 0.28342515230178833
Batch 31/64 loss: 0.2843579053878784
Batch 32/64 loss: 0.28491032123565674
Batch 33/64 loss: 0.28174716234207153
Batch 34/64 loss: 0.2861837148666382
Batch 35/64 loss: 0.2806297540664673
Batch 36/64 loss: 0.2773030996322632
Batch 37/64 loss: 0.2940211296081543
Batch 38/64 loss: 0.28130781650543213
Batch 39/64 loss: 0.27673929929733276
Batch 40/64 loss: 0.287300705909729
Batch 41/64 loss: 0.28175848722457886
Batch 42/64 loss: 0.2793147563934326
Batch 43/64 loss: 0.2858421206474304
Batch 44/64 loss: 0.28313642740249634
Batch 45/64 loss: 0.2897410988807678
Batch 46/64 loss: 0.2857893705368042
Batch 47/64 loss: 0.27559924125671387
Batch 48/64 loss: 0.2820050120353699
Batch 49/64 loss: 0.29672980308532715
Batch 50/64 loss: 0.2955958843231201
Batch 51/64 loss: 0.2856031656265259
Batch 52/64 loss: 0.2786024212837219
Batch 53/64 loss: 0.27727818489074707
Batch 54/64 loss: 0.2773532271385193
Batch 55/64 loss: 0.27945464849472046
Batch 56/64 loss: 0.2837805151939392
Batch 57/64 loss: 0.2771409749984741
Batch 58/64 loss: 0.28352928161621094
Batch 59/64 loss: 0.2835755944252014
Batch 60/64 loss: 0.29244494438171387
Batch 61/64 loss: 0.27494198083877563
Batch 62/64 loss: 0.2866663932800293
Batch 63/64 loss: 0.276428759098053
Batch 64/64 loss: 0.2854499816894531
Epoch 490  Train loss: 0.2838298143125048  Val loss: 0.32318358794110746
Epoch 491
-------------------------------
Batch 1/64 loss: 0.2857186794281006
Batch 2/64 loss: 0.2792138457298279
Batch 3/64 loss: 0.29195666313171387
Batch 4/64 loss: 0.28062427043914795
Batch 5/64 loss: 0.28644680976867676
Batch 6/64 loss: 0.2902325391769409
Batch 7/64 loss: 0.2784002423286438
Batch 8/64 loss: 0.28344881534576416
Batch 9/64 loss: 0.29960739612579346
Batch 10/64 loss: 0.282725989818573
Batch 11/64 loss: 0.2771393060684204
Batch 12/64 loss: 0.2757827043533325
Batch 13/64 loss: 0.288277804851532
Batch 14/64 loss: 0.2911837100982666
Batch 15/64 loss: 0.27081960439682007
Batch 16/64 loss: 0.2798595428466797
Batch 17/64 loss: 0.27478790283203125
Batch 18/64 loss: 0.2892540693283081
Batch 19/64 loss: 0.27540940046310425
Batch 20/64 loss: 0.2838084101676941
Batch 21/64 loss: 0.2832687497138977
Batch 22/64 loss: 0.2801259756088257
Batch 23/64 loss: 0.2855762243270874
Batch 24/64 loss: 0.2874370217323303
Batch 25/64 loss: 0.2775256037712097
Batch 26/64 loss: 0.2752583622932434
Batch 27/64 loss: 0.28681480884552
Batch 28/64 loss: 0.2890104055404663
Batch 29/64 loss: 0.2911032438278198
Batch 30/64 loss: 0.27081239223480225
Batch 31/64 loss: 0.2820422649383545
Batch 32/64 loss: 0.2838435173034668
Batch 33/64 loss: 0.280556321144104
Batch 34/64 loss: 0.2855479121208191
Batch 35/64 loss: 0.27850770950317383
Batch 36/64 loss: 0.27918124198913574
Batch 37/64 loss: 0.28519976139068604
Batch 38/64 loss: 0.2867470979690552
Batch 39/64 loss: 0.2826904058456421
Batch 40/64 loss: 0.28292548656463623
Batch 41/64 loss: 0.2824273109436035
Batch 42/64 loss: 0.28138697147369385
Batch 43/64 loss: 0.28776466846466064
Batch 44/64 loss: 0.2880438566207886
Batch 45/64 loss: 0.2859700918197632
Batch 46/64 loss: 0.2876465320587158
Batch 47/64 loss: 0.29416972398757935
Batch 48/64 loss: 0.26537024974823
Batch 49/64 loss: 0.27755677700042725
Batch 50/64 loss: 0.2909204363822937
Batch 51/64 loss: 0.28366267681121826
Batch 52/64 loss: 0.2882184386253357
Batch 53/64 loss: 0.28882861137390137
Batch 54/64 loss: 0.28435802459716797
Batch 55/64 loss: 0.27863359451293945
Batch 56/64 loss: 0.28033125400543213
Batch 57/64 loss: 0.28705430030822754
Batch 58/64 loss: 0.2859283685684204
Batch 59/64 loss: 0.28342676162719727
Batch 60/64 loss: 0.2934211492538452
Batch 61/64 loss: 0.2779901623725891
Batch 62/64 loss: 0.28995180130004883
Batch 63/64 loss: 0.2826188802719116
Batch 64/64 loss: 0.28191113471984863
Epoch 491  Train loss: 0.2835448816710827  Val loss: 0.32317855821032704
Epoch 492
-------------------------------
Batch 1/64 loss: 0.28973227739334106
Batch 2/64 loss: 0.28898072242736816
Batch 3/64 loss: 0.28064680099487305
Batch 4/64 loss: 0.2791004180908203
Batch 5/64 loss: 0.28235554695129395
Batch 6/64 loss: 0.28856587409973145
Batch 7/64 loss: 0.2823222279548645
Batch 8/64 loss: 0.2805745005607605
Batch 9/64 loss: 0.27168238162994385
Batch 10/64 loss: 0.2761402130126953
Batch 11/64 loss: 0.28238582611083984
Batch 12/64 loss: 0.2857915163040161
Batch 13/64 loss: 0.27243220806121826
Batch 14/64 loss: 0.2806169390678406
Batch 15/64 loss: 0.28447484970092773
Batch 16/64 loss: 0.28752291202545166
Batch 17/64 loss: 0.2848767042160034
Batch 18/64 loss: 0.281677782535553
Batch 19/64 loss: 0.29243266582489014
Batch 20/64 loss: 0.2811318635940552
Batch 21/64 loss: 0.2791564464569092
Batch 22/64 loss: 0.2938741445541382
Batch 23/64 loss: 0.2858905792236328
Batch 24/64 loss: 0.2872650623321533
Batch 25/64 loss: 0.2860910892486572
Batch 26/64 loss: 0.26601487398147583
Batch 27/64 loss: 0.2878972291946411
Batch 28/64 loss: 0.2787569761276245
Batch 29/64 loss: 0.28473538160324097
Batch 30/64 loss: 0.2921503782272339
Batch 31/64 loss: 0.286379873752594
Batch 32/64 loss: 0.27822554111480713
Batch 33/64 loss: 0.28335845470428467
Batch 34/64 loss: 0.27226191759109497
Batch 35/64 loss: 0.2748227119445801
Batch 36/64 loss: 0.2846025824546814
Batch 37/64 loss: 0.2818262577056885
Batch 38/64 loss: 0.2832224369049072
Batch 39/64 loss: 0.2881591320037842
Batch 40/64 loss: 0.278567910194397
Batch 41/64 loss: 0.2825011610984802
Batch 42/64 loss: 0.27921366691589355
Batch 43/64 loss: 0.27633702754974365
Batch 44/64 loss: 0.2889348268508911
Batch 45/64 loss: 0.286423921585083
Batch 46/64 loss: 0.28604674339294434
Batch 47/64 loss: 0.2800297737121582
Batch 48/64 loss: 0.28249430656433105
Batch 49/64 loss: 0.28569167852401733
Batch 50/64 loss: 0.2911722660064697
Batch 51/64 loss: 0.29036569595336914
Batch 52/64 loss: 0.2845919728279114
Batch 53/64 loss: 0.28353750705718994
Batch 54/64 loss: 0.2935354709625244
Batch 55/64 loss: 0.29146403074264526
Batch 56/64 loss: 0.2854815721511841
Batch 57/64 loss: 0.2750685214996338
Batch 58/64 loss: 0.29932814836502075
Batch 59/64 loss: 0.281965434551239
Batch 60/64 loss: 0.3027205467224121
Batch 61/64 loss: 0.28263700008392334
Batch 62/64 loss: 0.28672724962234497
Batch 63/64 loss: 0.2820158004760742
Batch 64/64 loss: 0.27289336919784546
Epoch 492  Train loss: 0.2837593342743668  Val loss: 0.32184345328930725
Saving best model, epoch: 492
Epoch 493
-------------------------------
Batch 1/64 loss: 0.28266000747680664
Batch 2/64 loss: 0.29322463274002075
Batch 3/64 loss: 0.28682249784469604
Batch 4/64 loss: 0.281343936920166
Batch 5/64 loss: 0.28179627656936646
Batch 6/64 loss: 0.27745091915130615
Batch 7/64 loss: 0.2815612554550171
Batch 8/64 loss: 0.2849121689796448
Batch 9/64 loss: 0.283313512802124
Batch 10/64 loss: 0.2835666537284851
Batch 11/64 loss: 0.28537631034851074
Batch 12/64 loss: 0.28643906116485596
Batch 13/64 loss: 0.2885582447052002
Batch 14/64 loss: 0.2783791422843933
Batch 15/64 loss: 0.2809174060821533
Batch 16/64 loss: 0.2792695164680481
Batch 17/64 loss: 0.27822989225387573
Batch 18/64 loss: 0.2876805067062378
Batch 19/64 loss: 0.28940510749816895
Batch 20/64 loss: 0.2773977518081665
Batch 21/64 loss: 0.2888337969779968
Batch 22/64 loss: 0.28936541080474854
Batch 23/64 loss: 0.289936900138855
Batch 24/64 loss: 0.28135615587234497
Batch 25/64 loss: 0.28800082206726074
Batch 26/64 loss: 0.27795344591140747
Batch 27/64 loss: 0.28133124113082886
Batch 28/64 loss: 0.279341459274292
Batch 29/64 loss: 0.28481370210647583
Batch 30/64 loss: 0.277532696723938
Batch 31/64 loss: 0.27612215280532837
Batch 32/64 loss: 0.2858707904815674
Batch 33/64 loss: 0.2782513499259949
Batch 34/64 loss: 0.2800418734550476
Batch 35/64 loss: 0.2891206741333008
Batch 36/64 loss: 0.2846947908401489
Batch 37/64 loss: 0.2865806818008423
Batch 38/64 loss: 0.28611356019973755
Batch 39/64 loss: 0.2847405672073364
Batch 40/64 loss: 0.30246084928512573
Batch 41/64 loss: 0.28663694858551025
Batch 42/64 loss: 0.28475499153137207
Batch 43/64 loss: 0.29102659225463867
Batch 44/64 loss: 0.27851617336273193
Batch 45/64 loss: 0.2826108932495117
Batch 46/64 loss: 0.2884354591369629
Batch 47/64 loss: 0.275173544883728
Batch 48/64 loss: 0.27881860733032227
Batch 49/64 loss: 0.29063695669174194
Batch 50/64 loss: 0.2853087782859802
Batch 51/64 loss: 0.2818084955215454
Batch 52/64 loss: 0.2881808876991272
Batch 53/64 loss: 0.28569555282592773
Batch 54/64 loss: 0.2808253765106201
Batch 55/64 loss: 0.2783670425415039
Batch 56/64 loss: 0.290073037147522
Batch 57/64 loss: 0.2921043038368225
Batch 58/64 loss: 0.2855736017227173
Batch 59/64 loss: 0.2922631502151489
Batch 60/64 loss: 0.2776968479156494
Batch 61/64 loss: 0.2898561954498291
Batch 62/64 loss: 0.28856825828552246
Batch 63/64 loss: 0.2802925109863281
Batch 64/64 loss: 0.2880948781967163
Epoch 493  Train loss: 0.2843931464587941  Val loss: 0.32495021164622095
Epoch 494
-------------------------------
Batch 1/64 loss: 0.27750885486602783
Batch 2/64 loss: 0.2870025634765625
Batch 3/64 loss: 0.2836464047431946
Batch 4/64 loss: 0.2872340679168701
Batch 5/64 loss: 0.2923818826675415
Batch 6/64 loss: 0.280586838722229
Batch 7/64 loss: 0.2742272615432739
Batch 8/64 loss: 0.2866067886352539
Batch 9/64 loss: 0.28380364179611206
Batch 10/64 loss: 0.2679891586303711
Batch 11/64 loss: 0.2772090435028076
Batch 12/64 loss: 0.27912694215774536
Batch 13/64 loss: 0.2902195453643799
Batch 14/64 loss: 0.27861785888671875
Batch 15/64 loss: 0.2938488721847534
Batch 16/64 loss: 0.28201746940612793
Batch 17/64 loss: 0.2851768732070923
Batch 18/64 loss: 0.2804819345474243
Batch 19/64 loss: 0.292433500289917
Batch 20/64 loss: 0.2842010259628296
Batch 21/64 loss: 0.2913907766342163
Batch 22/64 loss: 0.2847735285758972
Batch 23/64 loss: 0.27666163444519043
Batch 24/64 loss: 0.2787160277366638
Batch 25/64 loss: 0.2919962406158447
Batch 26/64 loss: 0.2695732116699219
Batch 27/64 loss: 0.2883450984954834
Batch 28/64 loss: 0.2810294032096863
Batch 29/64 loss: 0.2912861704826355
Batch 30/64 loss: 0.2743796110153198
Batch 31/64 loss: 0.28768038749694824
Batch 32/64 loss: 0.28771525621414185
Batch 33/64 loss: 0.2856743335723877
Batch 34/64 loss: 0.29099714756011963
Batch 35/64 loss: 0.273439884185791
Batch 36/64 loss: 0.2903730869293213
Batch 37/64 loss: 0.28725165128707886
Batch 38/64 loss: 0.28483009338378906
Batch 39/64 loss: 0.28758704662323
Batch 40/64 loss: 0.2780405879020691
Batch 41/64 loss: 0.2762629985809326
Batch 42/64 loss: 0.2756374478340149
Batch 43/64 loss: 0.2896167039871216
Batch 44/64 loss: 0.28562307357788086
Batch 45/64 loss: 0.28262144327163696
Batch 46/64 loss: 0.28484249114990234
Batch 47/64 loss: 0.28190457820892334
Batch 48/64 loss: 0.2747840881347656
Batch 49/64 loss: 0.2848702669143677
Batch 50/64 loss: 0.28872865438461304
Batch 51/64 loss: 0.2821958065032959
Batch 52/64 loss: 0.2825060486793518
Batch 53/64 loss: 0.2783794403076172
Batch 54/64 loss: 0.29215312004089355
Batch 55/64 loss: 0.27872371673583984
Batch 56/64 loss: 0.28599268198013306
Batch 57/64 loss: 0.27599918842315674
Batch 58/64 loss: 0.27814197540283203
Batch 59/64 loss: 0.28560173511505127
Batch 60/64 loss: 0.2733050584793091
Batch 61/64 loss: 0.28361058235168457
Batch 62/64 loss: 0.28897446393966675
Batch 63/64 loss: 0.2802419662475586
Batch 64/64 loss: 0.2787959575653076
Epoch 494  Train loss: 0.2830725679210588  Val loss: 0.3226236922224772
Epoch 495
-------------------------------
Batch 1/64 loss: 0.27847492694854736
Batch 2/64 loss: 0.2766852378845215
Batch 3/64 loss: 0.28251075744628906
Batch 4/64 loss: 0.2836869955062866
Batch 5/64 loss: 0.27037233114242554
Batch 6/64 loss: 0.2858971357345581
Batch 7/64 loss: 0.2762429714202881
Batch 8/64 loss: 0.28529447317123413
Batch 9/64 loss: 0.2861909866333008
Batch 10/64 loss: 0.28370022773742676
Batch 11/64 loss: 0.2860679626464844
Batch 12/64 loss: 0.28803348541259766
Batch 13/64 loss: 0.2872821092605591
Batch 14/64 loss: 0.29373669624328613
Batch 15/64 loss: 0.29069918394088745
Batch 16/64 loss: 0.2806987762451172
Batch 17/64 loss: 0.27816832065582275
Batch 18/64 loss: 0.2864738702774048
Batch 19/64 loss: 0.280178427696228
Batch 20/64 loss: 0.2819211483001709
Batch 21/64 loss: 0.29076361656188965
Batch 22/64 loss: 0.2749292850494385
Batch 23/64 loss: 0.2829495668411255
Batch 24/64 loss: 0.28099191188812256
Batch 25/64 loss: 0.27731752395629883
Batch 26/64 loss: 0.2815518379211426
Batch 27/64 loss: 0.2854022979736328
Batch 28/64 loss: 0.2767564058303833
Batch 29/64 loss: 0.2962266206741333
Batch 30/64 loss: 0.27954190969467163
Batch 31/64 loss: 0.2756195068359375
Batch 32/64 loss: 0.2806800603866577
Batch 33/64 loss: 0.2865030765533447
Batch 34/64 loss: 0.27983760833740234
Batch 35/64 loss: 0.29052793979644775
Batch 36/64 loss: 0.29122745990753174
Batch 37/64 loss: 0.28985971212387085
Batch 38/64 loss: 0.2970542311668396
Batch 39/64 loss: 0.28919869661331177
Batch 40/64 loss: 0.28253495693206787
Batch 41/64 loss: 0.2827880382537842
Batch 42/64 loss: 0.27713680267333984
Batch 43/64 loss: 0.2865249514579773
Batch 44/64 loss: 0.2784271836280823
Batch 45/64 loss: 0.2855827808380127
Batch 46/64 loss: 0.28392887115478516
Batch 47/64 loss: 0.2809382677078247
Batch 48/64 loss: 0.28396981954574585
Batch 49/64 loss: 0.2849915027618408
Batch 50/64 loss: 0.281297504901886
Batch 51/64 loss: 0.28324389457702637
Batch 52/64 loss: 0.2769310474395752
Batch 53/64 loss: 0.2792089581489563
Batch 54/64 loss: 0.28857702016830444
Batch 55/64 loss: 0.27571427822113037
Batch 56/64 loss: 0.29685062170028687
Batch 57/64 loss: 0.27594542503356934
Batch 58/64 loss: 0.2876622676849365
Batch 59/64 loss: 0.2902339696884155
Batch 60/64 loss: 0.2714965343475342
Batch 61/64 loss: 0.28061747550964355
Batch 62/64 loss: 0.2930328845977783
Batch 63/64 loss: 0.2834911346435547
Batch 64/64 loss: 0.268532395362854
Epoch 495  Train loss: 0.2833220514596677  Val loss: 0.32325932086538206
Epoch 496
-------------------------------
Batch 1/64 loss: 0.2923769950866699
Batch 2/64 loss: 0.2751252055168152
Batch 3/64 loss: 0.2924792766571045
Batch 4/64 loss: 0.28386449813842773
Batch 5/64 loss: 0.2833583354949951
Batch 6/64 loss: 0.28120386600494385
Batch 7/64 loss: 0.2850736379623413
Batch 8/64 loss: 0.2843647599220276
Batch 9/64 loss: 0.2713359594345093
Batch 10/64 loss: 0.2981761693954468
Batch 11/64 loss: 0.28692102432250977
Batch 12/64 loss: 0.2751731872558594
Batch 13/64 loss: 0.27009034156799316
Batch 14/64 loss: 0.2740691900253296
Batch 15/64 loss: 0.2896711826324463
Batch 16/64 loss: 0.2861170172691345
Batch 17/64 loss: 0.27363717555999756
Batch 18/64 loss: 0.28641605377197266
Batch 19/64 loss: 0.28611767292022705
Batch 20/64 loss: 0.27988165616989136
Batch 21/64 loss: 0.29184865951538086
Batch 22/64 loss: 0.2844219207763672
Batch 23/64 loss: 0.288774311542511
Batch 24/64 loss: 0.2867353558540344
Batch 25/64 loss: 0.2817807197570801
Batch 26/64 loss: 0.2829618453979492
Batch 27/64 loss: 0.2820812463760376
Batch 28/64 loss: 0.2790282964706421
Batch 29/64 loss: 0.27990972995758057
Batch 30/64 loss: 0.28295618295669556
Batch 31/64 loss: 0.2839552164077759
Batch 32/64 loss: 0.278975248336792
Batch 33/64 loss: 0.2969716191291809
Batch 34/64 loss: 0.2867131233215332
Batch 35/64 loss: 0.2789038419723511
Batch 36/64 loss: 0.2818107008934021
Batch 37/64 loss: 0.2895383834838867
Batch 38/64 loss: 0.2882567048072815
Batch 39/64 loss: 0.26808786392211914
Batch 40/64 loss: 0.2793923616409302
Batch 41/64 loss: 0.2793121337890625
Batch 42/64 loss: 0.2825930714607239
Batch 43/64 loss: 0.28710317611694336
Batch 44/64 loss: 0.2824934124946594
Batch 45/64 loss: 0.2872732877731323
Batch 46/64 loss: 0.2848351001739502
Batch 47/64 loss: 0.288055419921875
Batch 48/64 loss: 0.289839506149292
Batch 49/64 loss: 0.29011476039886475
Batch 50/64 loss: 0.28896182775497437
Batch 51/64 loss: 0.27813518047332764
Batch 52/64 loss: 0.29053056240081787
Batch 53/64 loss: 0.2825160622596741
Batch 54/64 loss: 0.2699816823005676
Batch 55/64 loss: 0.2841304540634155
Batch 56/64 loss: 0.279340922832489
Batch 57/64 loss: 0.27564167976379395
Batch 58/64 loss: 0.2737613916397095
Batch 59/64 loss: 0.28628814220428467
Batch 60/64 loss: 0.29301416873931885
Batch 61/64 loss: 0.2805008888244629
Batch 62/64 loss: 0.28254806995391846
Batch 63/64 loss: 0.2830842137336731
Batch 64/64 loss: 0.278354287147522
Epoch 496  Train loss: 0.28325297832489016  Val loss: 0.3236834738672394
Epoch 497
-------------------------------
Batch 1/64 loss: 0.28155410289764404
Batch 2/64 loss: 0.27778536081314087
Batch 3/64 loss: 0.2767220139503479
Batch 4/64 loss: 0.2793869972229004
Batch 5/64 loss: 0.2890411615371704
Batch 6/64 loss: 0.2897963523864746
Batch 7/64 loss: 0.27312910556793213
Batch 8/64 loss: 0.2691689133644104
Batch 9/64 loss: 0.27882444858551025
Batch 10/64 loss: 0.2931637763977051
Batch 11/64 loss: 0.284507155418396
Batch 12/64 loss: 0.2859410047531128
Batch 13/64 loss: 0.2801511883735657
Batch 14/64 loss: 0.28969258069992065
Batch 15/64 loss: 0.27972412109375
Batch 16/64 loss: 0.2780205011367798
Batch 17/64 loss: 0.28353428840637207
Batch 18/64 loss: 0.3005834221839905
Batch 19/64 loss: 0.2841103672981262
Batch 20/64 loss: 0.27087098360061646
Batch 21/64 loss: 0.2943844795227051
Batch 22/64 loss: 0.2757132053375244
Batch 23/64 loss: 0.28075921535491943
Batch 24/64 loss: 0.2763686180114746
Batch 25/64 loss: 0.2847088575363159
Batch 26/64 loss: 0.27850770950317383
Batch 27/64 loss: 0.28029972314834595
Batch 28/64 loss: 0.2771420478820801
Batch 29/64 loss: 0.2729274034500122
Batch 30/64 loss: 0.2845187187194824
Batch 31/64 loss: 0.2865636348724365
Batch 32/64 loss: 0.2863870859146118
Batch 33/64 loss: 0.2765679955482483
Batch 34/64 loss: 0.28911924362182617
Batch 35/64 loss: 0.2820848226547241
Batch 36/64 loss: 0.2974430322647095
Batch 37/64 loss: 0.28154969215393066
Batch 38/64 loss: 0.28238022327423096
Batch 39/64 loss: 0.27700430154800415
Batch 40/64 loss: 0.28648602962493896
Batch 41/64 loss: 0.2902946472167969
Batch 42/64 loss: 0.27570629119873047
Batch 43/64 loss: 0.27786874771118164
Batch 44/64 loss: 0.28174781799316406
Batch 45/64 loss: 0.28343749046325684
Batch 46/64 loss: 0.2958008646965027
Batch 47/64 loss: 0.2843289375305176
Batch 48/64 loss: 0.27591240406036377
Batch 49/64 loss: 0.28244876861572266
Batch 50/64 loss: 0.28721582889556885
Batch 51/64 loss: 0.28072476387023926
Batch 52/64 loss: 0.28659749031066895
Batch 53/64 loss: 0.28390204906463623
Batch 54/64 loss: 0.2825230360031128
Batch 55/64 loss: 0.2841147184371948
Batch 56/64 loss: 0.276509165763855
Batch 57/64 loss: 0.2806720733642578
Batch 58/64 loss: 0.29628968238830566
Batch 59/64 loss: 0.2839620113372803
Batch 60/64 loss: 0.27806782722473145
Batch 61/64 loss: 0.2836776375770569
Batch 62/64 loss: 0.2819288969039917
Batch 63/64 loss: 0.28873586654663086
Batch 64/64 loss: 0.2771798372268677
Epoch 497  Train loss: 0.2827760906780467  Val loss: 0.32324636678925084
Epoch 498
-------------------------------
Batch 1/64 loss: 0.2809481620788574
Batch 2/64 loss: 0.28004133701324463
Batch 3/64 loss: 0.28534138202667236
Batch 4/64 loss: 0.2797169089317322
Batch 5/64 loss: 0.27670300006866455
Batch 6/64 loss: 0.2998025417327881
Batch 7/64 loss: 0.29045557975769043
Batch 8/64 loss: 0.28057003021240234
Batch 9/64 loss: 0.279086709022522
Batch 10/64 loss: 0.2837566137313843
Batch 11/64 loss: 0.2815570831298828
Batch 12/64 loss: 0.2810143232345581
Batch 13/64 loss: 0.28242945671081543
Batch 14/64 loss: 0.28755348920822144
Batch 15/64 loss: 0.2769612669944763
Batch 16/64 loss: 0.2791343927383423
Batch 17/64 loss: 0.2689945697784424
Batch 18/64 loss: 0.29071152210235596
Batch 19/64 loss: 0.2852736711502075
Batch 20/64 loss: 0.2817980647087097
Batch 21/64 loss: 0.2814776301383972
Batch 22/64 loss: 0.2883281707763672
Batch 23/64 loss: 0.2840649485588074
Batch 24/64 loss: 0.27844810485839844
Batch 25/64 loss: 0.29103022813796997
Batch 26/64 loss: 0.290916383266449
Batch 27/64 loss: 0.2792378067970276
Batch 28/64 loss: 0.28560584783554077
Batch 29/64 loss: 0.27788424491882324
Batch 30/64 loss: 0.2807713747024536
Batch 31/64 loss: 0.2873353958129883
Batch 32/64 loss: 0.2806991934776306
Batch 33/64 loss: 0.27356988191604614
Batch 34/64 loss: 0.28348076343536377
Batch 35/64 loss: 0.27730458974838257
Batch 36/64 loss: 0.2808871269226074
Batch 37/64 loss: 0.2842746376991272
Batch 38/64 loss: 0.29657697677612305
Batch 39/64 loss: 0.28340309858322144
Batch 40/64 loss: 0.2843092679977417
Batch 41/64 loss: 0.29102349281311035
Batch 42/64 loss: 0.272274911403656
Batch 43/64 loss: 0.2801474332809448
Batch 44/64 loss: 0.28108787536621094
Batch 45/64 loss: 0.30210405588150024
Batch 46/64 loss: 0.2796037197113037
Batch 47/64 loss: 0.28087615966796875
Batch 48/64 loss: 0.2819885015487671
Batch 49/64 loss: 0.29253464937210083
Batch 50/64 loss: 0.2834685444831848
Batch 51/64 loss: 0.27801650762557983
Batch 52/64 loss: 0.2898481488227844
Batch 53/64 loss: 0.2851334810256958
Batch 54/64 loss: 0.27311205863952637
Batch 55/64 loss: 0.27580177783966064
Batch 56/64 loss: 0.2906454801559448
Batch 57/64 loss: 0.29762113094329834
Batch 58/64 loss: 0.28485286235809326
Batch 59/64 loss: 0.28649020195007324
Batch 60/64 loss: 0.2832813262939453
Batch 61/64 loss: 0.2750508189201355
Batch 62/64 loss: 0.2746208906173706
Batch 63/64 loss: 0.2802170515060425
Batch 64/64 loss: 0.279471218585968
Epoch 498  Train loss: 0.2831507493467892  Val loss: 0.32256549965475023
Epoch 499
-------------------------------
Batch 1/64 loss: 0.2851659059524536
Batch 2/64 loss: 0.2861393690109253
Batch 3/64 loss: 0.2824164032936096
Batch 4/64 loss: 0.2826073169708252
Batch 5/64 loss: 0.2792794704437256
Batch 6/64 loss: 0.2753826379776001
Batch 7/64 loss: 0.28074073791503906
Batch 8/64 loss: 0.2804540991783142
Batch 9/64 loss: 0.29137468338012695
Batch 10/64 loss: 0.2856874465942383
Batch 11/64 loss: 0.28293925523757935
Batch 12/64 loss: 0.286285400390625
Batch 13/64 loss: 0.2807321548461914
Batch 14/64 loss: 0.29089534282684326
Batch 15/64 loss: 0.2774285078048706
Batch 16/64 loss: 0.28114861249923706
Batch 17/64 loss: 0.27638494968414307
Batch 18/64 loss: 0.2722259759902954
Batch 19/64 loss: 0.2807561159133911
Batch 20/64 loss: 0.28359490633010864
Batch 21/64 loss: 0.28637319803237915
Batch 22/64 loss: 0.2861335873603821
Batch 23/64 loss: 0.2851765751838684
Batch 24/64 loss: 0.2883477807044983
Batch 25/64 loss: 0.2717784643173218
Batch 26/64 loss: 0.286723256111145
Batch 27/64 loss: 0.28874891996383667
Batch 28/64 loss: 0.28897058963775635
Batch 29/64 loss: 0.2854492664337158
Batch 30/64 loss: 0.30704569816589355
Batch 31/64 loss: 0.2842559814453125
Batch 32/64 loss: 0.2806629538536072
Batch 33/64 loss: 0.281261682510376
Batch 34/64 loss: 0.2809751629829407
Batch 35/64 loss: 0.2781597971916199
Batch 36/64 loss: 0.2757539749145508
Batch 37/64 loss: 0.2887917160987854
Batch 38/64 loss: 0.28044581413269043
Batch 39/64 loss: 0.2743362784385681
Batch 40/64 loss: 0.28235673904418945
Batch 41/64 loss: 0.2941363453865051
Batch 42/64 loss: 0.28425759077072144
Batch 43/64 loss: 0.2893522381782532
Batch 44/64 loss: 0.28205960988998413
Batch 45/64 loss: 0.27538251876831055
Batch 46/64 loss: 0.2822176218032837
Batch 47/64 loss: 0.27789306640625
Batch 48/64 loss: 0.28434014320373535
Batch 49/64 loss: 0.2941279411315918
Batch 50/64 loss: 0.2801700830459595
Batch 51/64 loss: 0.2787458896636963
Batch 52/64 loss: 0.2786160707473755
Batch 53/64 loss: 0.29337918758392334
Batch 54/64 loss: 0.295854389667511
Batch 55/64 loss: 0.2703860402107239
Batch 56/64 loss: 0.2785959243774414
Batch 57/64 loss: 0.27670276165008545
Batch 58/64 loss: 0.2811189889907837
Batch 59/64 loss: 0.2833678722381592
Batch 60/64 loss: 0.2759745121002197
Batch 61/64 loss: 0.28819572925567627
Batch 62/64 loss: 0.28330373764038086
Batch 63/64 loss: 0.27746742963790894
Batch 64/64 loss: 0.2805160880088806
Epoch 499  Train loss: 0.28297128607245053  Val loss: 0.32317641899757776
Epoch 500
-------------------------------
Batch 1/64 loss: 0.28086400032043457
Batch 2/64 loss: 0.27226853370666504
Batch 3/64 loss: 0.2769547700881958
Batch 4/64 loss: 0.279773473739624
Batch 5/64 loss: 0.29213452339172363
Batch 6/64 loss: 0.2794809341430664
Batch 7/64 loss: 0.2752566337585449
Batch 8/64 loss: 0.27346712350845337
Batch 9/64 loss: 0.2818562388420105
Batch 10/64 loss: 0.27748245000839233
Batch 11/64 loss: 0.27714794874191284
Batch 12/64 loss: 0.2763422131538391
Batch 13/64 loss: 0.2957439422607422
Batch 14/64 loss: 0.2809896469116211
Batch 15/64 loss: 0.2820432186126709
Batch 16/64 loss: 0.27914804220199585
Batch 17/64 loss: 0.2849441170692444
Batch 18/64 loss: 0.2898557186126709
Batch 19/64 loss: 0.27706342935562134
Batch 20/64 loss: 0.3025099039077759
Batch 21/64 loss: 0.2751196622848511
Batch 22/64 loss: 0.2763063907623291
Batch 23/64 loss: 0.27684468030929565
Batch 24/64 loss: 0.28347599506378174
Batch 25/64 loss: 0.2873727083206177
Batch 26/64 loss: 0.2885814309120178
Batch 27/64 loss: 0.28533631563186646
Batch 28/64 loss: 0.27599644660949707
Batch 29/64 loss: 0.27897346019744873
Batch 30/64 loss: 0.28692877292633057
Batch 31/64 loss: 0.27862846851348877
Batch 32/64 loss: 0.28298044204711914
Batch 33/64 loss: 0.2778756618499756
Batch 34/64 loss: 0.28654801845550537
Batch 35/64 loss: 0.2952094078063965
Batch 36/64 loss: 0.28785520792007446
Batch 37/64 loss: 0.28424954414367676
Batch 38/64 loss: 0.28899937868118286
Batch 39/64 loss: 0.2802174687385559
Batch 40/64 loss: 0.2782406806945801
Batch 41/64 loss: 0.28252506256103516
Batch 42/64 loss: 0.2840297222137451
Batch 43/64 loss: 0.2774870991706848
Batch 44/64 loss: 0.291140079498291
Batch 45/64 loss: 0.29885900020599365
Batch 46/64 loss: 0.28327715396881104
Batch 47/64 loss: 0.279247522354126
Batch 48/64 loss: 0.2825130224227905
Batch 49/64 loss: 0.288976788520813
Batch 50/64 loss: 0.273473858833313
Batch 51/64 loss: 0.2841334342956543
Batch 52/64 loss: 0.28139156103134155
Batch 53/64 loss: 0.2889317274093628
Batch 54/64 loss: 0.289523720741272
Batch 55/64 loss: 0.2826521396636963
Batch 56/64 loss: 0.2918426990509033
Batch 57/64 loss: 0.2760627269744873
Batch 58/64 loss: 0.28554844856262207
Batch 59/64 loss: 0.2760881185531616
Batch 60/64 loss: 0.28208959102630615
Batch 61/64 loss: 0.27494120597839355
Batch 62/64 loss: 0.2852286696434021
Batch 63/64 loss: 0.2798997163772583
Batch 64/64 loss: 0.28439217805862427
Epoch 500  Train loss: 0.2827329287341997  Val loss: 0.32404676704472285
SLIC undersegmentation error: 0.054052233676975946
SLIC inter-cluster variation: 0.02397972047789259
SLIC number of superpixels: 162588
SLIC superpixels per image: 558.7216494845361
Model loaded
Test metrics:
0.31800055647224085 0.17080549828178693 20.818312809333072 tensor(0.1174, dtype=torch.float64) 0.4099075025693731 1.6937718396711203 48650
Inference time: 0.0031844160401124726 seconds
Relabeled undersegmentation error: 0.09672302405498279
Relabeled inter-cluster variation: 0.06270611603871687
Relabeled mean superpixels count: 283.16494845360825
Original mean superpixels count: 167.18213058419244
Done!
Job id: 420584
Job id: 422893
